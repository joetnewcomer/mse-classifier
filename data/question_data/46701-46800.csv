,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Subfields of the field of complex numbers with finite index rather than the real number field [duplicate],Subfields of the field of complex numbers with finite index rather than the real number field [duplicate],,"This question already has an answer here : Closed 11 years ago . Possible Duplicate: Finiteness of the Algebraic Closure For short, I wonder if there are other fields $F\subset \mathbb{C}$ rather than $\mathbb{R}$, with finite index $[\mathbb{C}:F]$. Since $\mathbb{C}=\mathbb{R}+\mathbb{R}\sqrt{-1}$, we naively hope that if we are given a $p$th primitive unit root then we ""should"" find a subfield $F\subset \mathbb{C}$, such that $F(\omega)=\mathbb{C}$. Applying Zorn's lemma, we do be able to find a maximal subfield $F$ with respect to $\omega\notin F$. And for any finite algebraic extension $E/F$ with $E\subset \mathbb{C}$, we can show that $E/F$ is Golois with cyclic Galois group. Because if $L/F$ is finite Galois then pick an $\sigma\notin Gal(L/F(\omega))$, we obtain $Gal(L/F)=(\sigma)$. However, I do not know how to go forward to get a finite index subfield yet. Just for curiousness. Thanks.","This question already has an answer here : Closed 11 years ago . Possible Duplicate: Finiteness of the Algebraic Closure For short, I wonder if there are other fields $F\subset \mathbb{C}$ rather than $\mathbb{R}$, with finite index $[\mathbb{C}:F]$. Since $\mathbb{C}=\mathbb{R}+\mathbb{R}\sqrt{-1}$, we naively hope that if we are given a $p$th primitive unit root then we ""should"" find a subfield $F\subset \mathbb{C}$, such that $F(\omega)=\mathbb{C}$. Applying Zorn's lemma, we do be able to find a maximal subfield $F$ with respect to $\omega\notin F$. And for any finite algebraic extension $E/F$ with $E\subset \mathbb{C}$, we can show that $E/F$ is Golois with cyclic Galois group. Because if $L/F$ is finite Galois then pick an $\sigma\notin Gal(L/F(\omega))$, we obtain $Gal(L/F)=(\sigma)$. However, I do not know how to go forward to get a finite index subfield yet. Just for curiousness. Thanks.",,"['abstract-algebra', 'galois-theory']"
1,Why $(1-\zeta)$ unit where $\zeta$ is a primitive nth and n divisible by two primes,Why  unit where  is a primitive nth and n divisible by two primes,(1-\zeta) \zeta,"From Chapter VII of Lang's Algebra. The question asks if $n\geq 6$ and $n$ is divisible by at least two primes, show that $1-\zeta$ is a unit in the ring $\mathbb{Z}[\zeta]$ I am having a hard time understanding why this is true. This is in the integral dependence chapter, but that has not given me any inspiration. I have also tried using cyclotonic polynomial to no avail Thanks for any direction.","From Chapter VII of Lang's Algebra. The question asks if $n\geq 6$ and $n$ is divisible by at least two primes, show that $1-\zeta$ is a unit in the ring $\mathbb{Z}[\zeta]$ I am having a hard time understanding why this is true. This is in the integral dependence chapter, but that has not given me any inspiration. I have also tried using cyclotonic polynomial to no avail Thanks for any direction.",,['abstract-algebra']
2,Primitive Element for Field Extension of Rational Functions over Symmetric Rational Functions,Primitive Element for Field Extension of Rational Functions over Symmetric Rational Functions,,"A rational function $f$ in $n$ variables is a ratio of $2$ polynomials, $$f(x_1,...x_n) = \frac{p(x_1,...x_n)}{q(x_1,...x_n)}$$ where $q$ is not identically $0$. The function is called symmetric if $$f(x_1,...,x_n) = f(x_{\sigma(1)},...,x_{\sigma(n)})$$ for any permutation $\sigma$ of $\{1,\ldots,n\}$. Let $F$ denote the field of rational functions and $S$ denote the subfield of symmetric rational functions. Suppose the coefficients of polynomials are all real numbers. Show that $F = S(h)$, where $h = x_1 + 2x_2 + ... + nx_n$. In other words, show that $h$ generates $F$ as a field extension of $S$. Attempt at Solution : Can't seem to get very far with this one. I know that $F$ is  a finite extension of $S$ of degree $n!$ and the Galois group of the extension is $S_n$. Using $h$ and the 1st symmetric function $s_1 = x_1 + x_2 + \ldots + x_n$, we see that $h - s_1 = x_2 + 2x_3 + \ldots (n-1)x_n \in S(h)$. Can't seem to find a good way to use the other symmetric functions $s_2,\ldots, s_n$. Any help would be greatly appreciated. Thank you.","A rational function $f$ in $n$ variables is a ratio of $2$ polynomials, $$f(x_1,...x_n) = \frac{p(x_1,...x_n)}{q(x_1,...x_n)}$$ where $q$ is not identically $0$. The function is called symmetric if $$f(x_1,...,x_n) = f(x_{\sigma(1)},...,x_{\sigma(n)})$$ for any permutation $\sigma$ of $\{1,\ldots,n\}$. Let $F$ denote the field of rational functions and $S$ denote the subfield of symmetric rational functions. Suppose the coefficients of polynomials are all real numbers. Show that $F = S(h)$, where $h = x_1 + 2x_2 + ... + nx_n$. In other words, show that $h$ generates $F$ as a field extension of $S$. Attempt at Solution : Can't seem to get very far with this one. I know that $F$ is  a finite extension of $S$ of degree $n!$ and the Galois group of the extension is $S_n$. Using $h$ and the 1st symmetric function $s_1 = x_1 + x_2 + \ldots + x_n$, we see that $h - s_1 = x_2 + 2x_3 + \ldots (n-1)x_n \in S(h)$. Can't seem to find a good way to use the other symmetric functions $s_2,\ldots, s_n$. Any help would be greatly appreciated. Thank you.",,"['abstract-algebra', 'field-theory', 'galois-theory', 'symmetric-polynomials', 'symmetric-functions']"
3,Annihilators in matrix rings,Annihilators in matrix rings,,Let $R$ be a finite commutative ring. For $n>1$ consider the full matrix ring $M_n(R)$. For a matrix $A\in M_n(R)$ is true that the cardinality of the  left annihilator (in $M_n(R)$) of $A$ equals the cardinality of the right annhilator?,Let $R$ be a finite commutative ring. For $n>1$ consider the full matrix ring $M_n(R)$. For a matrix $A\in M_n(R)$ is true that the cardinality of the  left annihilator (in $M_n(R)$) of $A$ equals the cardinality of the right annhilator?,,"['abstract-algebra', 'matrices', 'finite-rings']"
4,Number of specific partitions of a given set,Number of specific partitions of a given set,,"Let U be the set $U=\{(1,2,3,\ldots,2^m)\}$. Let $A$ and $B$ partitions of $U$, such that $A \cup B$ is the set $U$, and their intersection is empty, and adding the elements of the first set is the same number of the addition of the elements of the second set $B$. How many $A$ and $B$ is there? I mean, if $U=\{1,2,3,4\}$, there exist just a single pair of sets $A$, and $B$. $A=(3,2)$ and $B=(4,1)$, because $3+2=4+1$, i want to know how many $A$ and $B$s exists for bigger sets $U$.","Let U be the set $U=\{(1,2,3,\ldots,2^m)\}$. Let $A$ and $B$ partitions of $U$, such that $A \cup B$ is the set $U$, and their intersection is empty, and adding the elements of the first set is the same number of the addition of the elements of the second set $B$. How many $A$ and $B$ is there? I mean, if $U=\{1,2,3,4\}$, there exist just a single pair of sets $A$, and $B$. $A=(3,2)$ and $B=(4,1)$, because $3+2=4+1$, i want to know how many $A$ and $B$s exists for bigger sets $U$.",,"['abstract-algebra', 'combinatorics', 'elementary-set-theory']"
5,An analogy between subgroups and equivalence relations.,An analogy between subgroups and equivalence relations.,,"I have noticed a certain analogy between subgroups of a group $G$ and equivalence relations on a set $X$ . I would like to know if there's an explanation for this analogy or a common generalization of the two facts I have in mind. Here are the facts. Fact 1. Let $G$ be a group. Then we can multiply subsets of $G$ in a standard way. For two subgroups $R$ and $S$ of $G$ , the product $RS$ is a subgroup of $G$ iff $RS=SR$ . If that is the case, $RS=SR$ is the join of $R$ and $S$ in the lattice of subgroups of $G$ . Fact 2. Let $X$ be a set. Then we can compose binary relations on $X$ in a standard way. For two equivalence relations $\rho$ and $\sigma$ , the composition $\rho\circ\sigma$ is an equivalence relation on $X$ iff $\rho\circ\sigma=\sigma\circ\rho$ . If that is the case, $\rho\circ\sigma=\sigma\circ\rho$ is the join of $\rho$ and $\sigma$ in the lattice of equivalence relations on $X$ .","I have noticed a certain analogy between subgroups of a group and equivalence relations on a set . I would like to know if there's an explanation for this analogy or a common generalization of the two facts I have in mind. Here are the facts. Fact 1. Let be a group. Then we can multiply subsets of in a standard way. For two subgroups and of , the product is a subgroup of iff . If that is the case, is the join of and in the lattice of subgroups of . Fact 2. Let be a set. Then we can compose binary relations on in a standard way. For two equivalence relations and , the composition is an equivalence relation on iff . If that is the case, is the join of and in the lattice of equivalence relations on .",G X G G R S G RS G RS=SR RS=SR R S G X X \rho \sigma \rho\circ\sigma X \rho\circ\sigma=\sigma\circ\rho \rho\circ\sigma=\sigma\circ\rho \rho \sigma X,"['abstract-algebra', 'group-theory']"
6,Towards the solution of the Problem : Field Extension problem beyond $\mathbb C$ (Question 1),Towards the solution of the Problem : Field Extension problem beyond  (Question 1),\mathbb C,"I am posting this problem in order to break the problem in my previous post Field Extension problem beyond $\mathbb C$ . Notation: $M(\mathbb C):=$ Field of all meromorphic functions on $\mathbb C$,  $K:=$ a proper subfield between $\mathbb C$ and $M(\mathbb C)$ Question 1: Let $\sigma\in Aut(K)$ and $c$ is a constant function. Is it true $\sigma(c)$ is again a constant function ? I will post subsequent questions after getting a good answer (either by myself or someone else). Let us try how far we can go!","I am posting this problem in order to break the problem in my previous post Field Extension problem beyond $\mathbb C$ . Notation: $M(\mathbb C):=$ Field of all meromorphic functions on $\mathbb C$,  $K:=$ a proper subfield between $\mathbb C$ and $M(\mathbb C)$ Question 1: Let $\sigma\in Aut(K)$ and $c$ is a constant function. Is it true $\sigma(c)$ is again a constant function ? I will post subsequent questions after getting a good answer (either by myself or someone else). Let us try how far we can go!",,"['abstract-algebra', 'complex-analysis', 'galois-theory']"
7,Integrally closed with roots of identity,Integrally closed with roots of identity,,"Let $\lambda_1,...,\lambda_n$ be roots of unity with $n\geq 2$. Assume that $$\frac{1}{n}\sum_{1}^{n}\lambda_i$$ is integral over $\mathbb{Z}$. Show either $\sum_{1}^{n}\lambda_i=0$ or $\lambda_1=\cdots=\lambda_n$. I only know the basic definition of integral elements, so does there exists a basic proof to the problem?","Let $\lambda_1,...,\lambda_n$ be roots of unity with $n\geq 2$. Assume that $$\frac{1}{n}\sum_{1}^{n}\lambda_i$$ is integral over $\mathbb{Z}$. Show either $\sum_{1}^{n}\lambda_i=0$ or $\lambda_1=\cdots=\lambda_n$. I only know the basic definition of integral elements, so does there exists a basic proof to the problem?",,"['abstract-algebra', 'commutative-algebra']"
8,Extending Galois automorphism to group automorphism,Extending Galois automorphism to group automorphism,,"Let $F \subset K$ be a field extension of degree $n$, then $F^n \cong K$ as $F$-vectorspaces. Now $K^\times$ acts on $F^n$, by multiplication on $K$, and so $K^\times$ embeds into $GL_n(F)$, and every Galois element gives an automorphism of $K^\times$. Question: Under which conditions can it be extended to an automorphism of $GL_n(F)$? How? Cyclic extension, abelian extension, solvalabe extension, general extension? I am mostly interested in the case, where $F$ is a local field. Example $\mathbb{R} \subset \mathbb{C}$: We fix an $\mathbb{R}$-basis $\\{ 1,i \\}$. The multipliaction by $a+ib$ correspond to the matrix  $$ \begin{pmatrix} a & -b \newline b & a \end{pmatrix}.$$ The Galois element is complex conjugation and corresponds to transpose on the above matrices. Can it be extended to the group $GL_2(\mathbb{C})$? Motivation: I am actually hoping for an explanation of the Caley transform introduced here on page 2: http://www.ams.org/mathscinet/search/publdoc.html?pg1=IID&s1=162025&vfpref=html&r=28&mx-pid=237707","Let $F \subset K$ be a field extension of degree $n$, then $F^n \cong K$ as $F$-vectorspaces. Now $K^\times$ acts on $F^n$, by multiplication on $K$, and so $K^\times$ embeds into $GL_n(F)$, and every Galois element gives an automorphism of $K^\times$. Question: Under which conditions can it be extended to an automorphism of $GL_n(F)$? How? Cyclic extension, abelian extension, solvalabe extension, general extension? I am mostly interested in the case, where $F$ is a local field. Example $\mathbb{R} \subset \mathbb{C}$: We fix an $\mathbb{R}$-basis $\\{ 1,i \\}$. The multipliaction by $a+ib$ correspond to the matrix  $$ \begin{pmatrix} a & -b \newline b & a \end{pmatrix}.$$ The Galois element is complex conjugation and corresponds to transpose on the above matrices. Can it be extended to the group $GL_2(\mathbb{C})$? Motivation: I am actually hoping for an explanation of the Caley transform introduced here on page 2: http://www.ams.org/mathscinet/search/publdoc.html?pg1=IID&s1=162025&vfpref=html&r=28&mx-pid=237707",,"['abstract-algebra', 'number-theory', 'algebraic-geometry', 'algebraic-number-theory', 'automorphic-forms']"
9,"What is the module $\operatorname{Hom}(M,N)$ where $R=\mathbb{C}[x]$ and $M=R/(x)$ and $N=R/(x-1)$.",What is the module  where  and  and .,"\operatorname{Hom}(M,N) R=\mathbb{C}[x] M=R/(x) N=R/(x-1)","Here is what I have so far: Consider $\mathbb{C}[x]/(x)$. This ring is all complex coefficient polynomials in $x$, and when quotient by the ideal $(x)$, we are subsituting $0$ for every $x$ in the polynomial, which kills all terms except the zero degree term, thus $\mathbb{C}[x]/(x) \cong \mathbb{C}$. Similarly, when we quotient by the ideal $(x-1)$ we set every $x$ in the polynomial to $1$, and we again have that $\mathbb{C}/(x-1) \cong \mathbb{C}$. Call the module $\mathbb{C}[x]/(x)=M$ and the other $N$. The difference between modules $M$ and $N$ is in the multiplication by the ring $\mathbb{C}[x]=R$. Let $p(x)\in R$ and let $m\in M$ and $n\in N$. $p(x)\cdot m=p(0)m$ while $p(x)\cdot n=p(1)n$. Thus even thought $M$ and $N$ are equivalent set wise they behave differently as modules over the same ring $R$. A homomorphism $\phi \in \operatorname{Hom}(M,N)$ must satisfy for all $m, m' \in M$ and $p, q \in R$, $\phi(p(x)m+q(x)m')=p(x)\phi(m)+q(x)\phi(m')$ Consider the $(1-x)\in R$, we know that $\phi$ is determined by where it send 1, since for any $c\in\mathbb{C}$, $\phi(c)=\phi(1c)=c\phi(1)$ since $\phi$ is homomorphism over $R$. We see that $\phi(1)=\phi((1-0)1)=\phi((1-x)1)=(1-x)\phi(1)=(1-1)\phi(1)=0\phi(1)=0$. Thus there is only the trivial homomorphism and $\operatorname{Hom}(M,N)$ is the zero module. Is this correct? Also,is it usually the case that for a given ring $R$ and two distinct non-unit elements $r, r' \in R$ the module of homomorphisms from the module $R/(r)$ to $R/(r')$ is isomorphic to $R/(\gcd(r,r'))$. For example if $R=\mathbb{Z}$ and $M=R/(8)$ and $N=R/(12)$ then $\operatorname{Hom}(M,N)\cong R/(\gcd(8,12)) = R / (4)$. Thanks!","Here is what I have so far: Consider $\mathbb{C}[x]/(x)$. This ring is all complex coefficient polynomials in $x$, and when quotient by the ideal $(x)$, we are subsituting $0$ for every $x$ in the polynomial, which kills all terms except the zero degree term, thus $\mathbb{C}[x]/(x) \cong \mathbb{C}$. Similarly, when we quotient by the ideal $(x-1)$ we set every $x$ in the polynomial to $1$, and we again have that $\mathbb{C}/(x-1) \cong \mathbb{C}$. Call the module $\mathbb{C}[x]/(x)=M$ and the other $N$. The difference between modules $M$ and $N$ is in the multiplication by the ring $\mathbb{C}[x]=R$. Let $p(x)\in R$ and let $m\in M$ and $n\in N$. $p(x)\cdot m=p(0)m$ while $p(x)\cdot n=p(1)n$. Thus even thought $M$ and $N$ are equivalent set wise they behave differently as modules over the same ring $R$. A homomorphism $\phi \in \operatorname{Hom}(M,N)$ must satisfy for all $m, m' \in M$ and $p, q \in R$, $\phi(p(x)m+q(x)m')=p(x)\phi(m)+q(x)\phi(m')$ Consider the $(1-x)\in R$, we know that $\phi$ is determined by where it send 1, since for any $c\in\mathbb{C}$, $\phi(c)=\phi(1c)=c\phi(1)$ since $\phi$ is homomorphism over $R$. We see that $\phi(1)=\phi((1-0)1)=\phi((1-x)1)=(1-x)\phi(1)=(1-1)\phi(1)=0\phi(1)=0$. Thus there is only the trivial homomorphism and $\operatorname{Hom}(M,N)$ is the zero module. Is this correct? Also,is it usually the case that for a given ring $R$ and two distinct non-unit elements $r, r' \in R$ the module of homomorphisms from the module $R/(r)$ to $R/(r')$ is isomorphic to $R/(\gcd(r,r'))$. For example if $R=\mathbb{Z}$ and $M=R/(8)$ and $N=R/(12)$ then $\operatorname{Hom}(M,N)\cong R/(\gcd(8,12)) = R / (4)$. Thanks!",,"['abstract-algebra', 'ring-theory', 'modules']"
10,Further explanation on proof that associated primes are precisely those belonging to primary modules in reduced decomposition of $0$.,Further explanation on proof that associated primes are precisely those belonging to primary modules in reduced decomposition of .,0,"Consider the following theorem in Chapter X Noetherian Rings and Modules from Lang's Algebra (page 423, third edition): Theorem 3.5. Let $A$ and $M \neq 0$ be Noetherian. The associated primes of $M$ are precisely the primes which belong to the primary submodules in a reduced primary decomposition of $0$ in $M$ . In particular, the set of associated primes of $M$ is finite. Proof: Let $0=Q_1\cap\cdots\cap Q_r$ be a reduced primary decomposition of $0$ in $M$ . There is an injective homomorphism $$ M\to\bigoplus_{i=1}^r M/Q_i. $$ Then every associated prime of $M$ belongs to some $Q_i$ . (1) Conversely, let $N=Q_2\cap\cdots\cap Q_r$ . Then $N\neq 0$ because the decomposition is reduced. Then $$ N=N/(N\cap Q_1)\approx (N+Q_1)/Q_1\subset M/Q_1. $$ Hence $N$ is isomorphic to a submodule of $M/Q_1$ , and consequently has an associated prime which can be none other than the prime $p_1$ belonging to $Q_1$ . (2) I have two questions about this proof I hope somebody can clarify. How does one conclude from the injective homomorphism that every associated prime of $M$ belongs to some $Q_i$ ? I'm aware that a submodule $Q$ of $M$ is primary iff $M/Q$ has exactly one associated prime $p$ , in which case $p$ belongs to $Q$ . I also know that for a submodule $N$ of $M$ , an associated prime of $M$ is associated with $N$ or with $M/N$ , but don't know how to tie it together. Why does $N$ being isomorphic to a submodule of $M/Q_1$ implies that $p_1$ is its associated prime?","Consider the following theorem in Chapter X Noetherian Rings and Modules from Lang's Algebra (page 423, third edition): Theorem 3.5. Let and be Noetherian. The associated primes of are precisely the primes which belong to the primary submodules in a reduced primary decomposition of in . In particular, the set of associated primes of is finite. Proof: Let be a reduced primary decomposition of in . There is an injective homomorphism Then every associated prime of belongs to some . (1) Conversely, let . Then because the decomposition is reduced. Then Hence is isomorphic to a submodule of , and consequently has an associated prime which can be none other than the prime belonging to . (2) I have two questions about this proof I hope somebody can clarify. How does one conclude from the injective homomorphism that every associated prime of belongs to some ? I'm aware that a submodule of is primary iff has exactly one associated prime , in which case belongs to . I also know that for a submodule of , an associated prime of is associated with or with , but don't know how to tie it together. Why does being isomorphic to a submodule of implies that is its associated prime?","A M \neq 0 M 0 M M 0=Q_1\cap\cdots\cap Q_r 0 M 
M\to\bigoplus_{i=1}^r M/Q_i.
 M Q_i N=Q_2\cap\cdots\cap Q_r N\neq 0 
N=N/(N\cap Q_1)\approx (N+Q_1)/Q_1\subset M/Q_1.
 N M/Q_1 p_1 Q_1 M Q_i Q M M/Q p p Q N M M N M/N N M/Q_1 p_1","['abstract-algebra', 'commutative-algebra', 'modules', 'maximal-and-prime-ideals', 'noetherian']"
11,The zero set of sums of polynomials,The zero set of sums of polynomials,,"As I am new to this forum, please correct me if this post is not appropriate. In that case I apologize. Let $P(z)$ and $Q(z)$ be polynomials with coefficients in $\mathbb{C}$, furthermore let $Z(P)$ and $Z(Q)$ denote their zero sets. What can be said about $Z(P+Q)$? Without imposing any further restrictions on $P$ and $Q$. I see that  $Z(P)  \cap   Z(Q) \subset Z(P+Q)$. Or if we additionally assume that one of the polynomials dominates $P+Q$ in the sense that $|P(z)|\geq|P(z)+Q(z)|$  for all $z\in \mathbb{C}$, then clearly also $Z(P)\subset Z(P+Q)$ holds. Without imposing to harsh restrictions (Very vague, I know) on the involved polynomials, what can be said? Lastly, I really appreciate any help from you.","As I am new to this forum, please correct me if this post is not appropriate. In that case I apologize. Let $P(z)$ and $Q(z)$ be polynomials with coefficients in $\mathbb{C}$, furthermore let $Z(P)$ and $Z(Q)$ denote their zero sets. What can be said about $Z(P+Q)$? Without imposing any further restrictions on $P$ and $Q$. I see that  $Z(P)  \cap   Z(Q) \subset Z(P+Q)$. Or if we additionally assume that one of the polynomials dominates $P+Q$ in the sense that $|P(z)|\geq|P(z)+Q(z)|$  for all $z\in \mathbb{C}$, then clearly also $Z(P)\subset Z(P+Q)$ holds. Without imposing to harsh restrictions (Very vague, I know) on the involved polynomials, what can be said? Lastly, I really appreciate any help from you.",,"['abstract-algebra', 'complex-analysis', 'polynomials']"
12,Quickest route to the structure theorem for finitely generated modules over a PID,Quickest route to the structure theorem for finitely generated modules over a PID,,"This is the theorem the title refers to. In his Basic Algebra I , Jacobson proves it by means of a Lemma: Lemma Let $D$ be a PID and $K$ be a submodule of $D^{(n)}$ (the free module of rank $n$). Then $K$ is finitely generated; $K$ is free of rank $\le n$. Question What is the relevance of conclusion 2. to the subsequent proof? I guess it is not needed. Indeed, Jacobson's proof goes as follows. Take a finitely generated module $M$ over the PID $D$ and a generating homomorphism $ \eta\colon D^{(n)} \to M$. Then the kernel $K$ of $\eta$ is finitely generated and we have a relations matrix $A$, whose rows are a set of generators for $K$. We then apply the machinery of Smith normal form to $A$. It seems to me that we made no use of 2. This point guarantees that we can take $A$ of full rank, but that is something we don't need. Am I wrong? Thank you.","This is the theorem the title refers to. In his Basic Algebra I , Jacobson proves it by means of a Lemma: Lemma Let $D$ be a PID and $K$ be a submodule of $D^{(n)}$ (the free module of rank $n$). Then $K$ is finitely generated; $K$ is free of rank $\le n$. Question What is the relevance of conclusion 2. to the subsequent proof? I guess it is not needed. Indeed, Jacobson's proof goes as follows. Take a finitely generated module $M$ over the PID $D$ and a generating homomorphism $ \eta\colon D^{(n)} \to M$. Then the kernel $K$ of $\eta$ is finitely generated and we have a relations matrix $A$, whose rows are a set of generators for $K$. We then apply the machinery of Smith normal form to $A$. It seems to me that we made no use of 2. This point guarantees that we can take $A$ of full rank, but that is something we don't need. Am I wrong? Thank you.",,"['abstract-algebra', 'modules']"
13,Complex roots of an irreducible polynomial,Complex roots of an irreducible polynomial,,"This is a part of a question from a Berkeley prelim exam and I would appreciate a hint, since I can't see a promising approach to this. Let $p$ be an irreducible polynomial over the rationals with a nonzero complex root $a$. Suppose that $a^2$ is also a root of $p$. How would one conclude from this that for any root $b$ of $p$, $b^2$ is also a root of $p$?","This is a part of a question from a Berkeley prelim exam and I would appreciate a hint, since I can't see a promising approach to this. Let $p$ be an irreducible polynomial over the rationals with a nonzero complex root $a$. Suppose that $a^2$ is also a root of $p$. How would one conclude from this that for any root $b$ of $p$, $b^2$ is also a root of $p$?",,"['abstract-algebra', 'polynomials']"
14,Showing that one axiom of the concept group action implies another (similar to group homomorphisms),Showing that one axiom of the concept group action implies another (similar to group homomorphisms),,"[Beware that my question is at the bottom of all this text.] We defined in a group theory course a group action to be a mapping $$\nu:G\times X \rightarrow X,$$ $(G,\cdot)$ group and $X$ some set, such that the axioms $$ \textrm{(GA1)} \ \ \  \nu(1,x)=x$$ and $$ \textrm{(GA2)} \ \ \ \nu(g,\nu(h,x))=\nu(g h, x)$$ hold for every $g,h\in G$ and $x\in X$. We defined a group homomorphism to be a map $$f:G\rightarrow H,$$ such that the axioms $$\textrm{(HOM1)} \ \ \  f(1_G)=1_H $$  and $$\textrm{(HOM2)} \ \ \ f(gh)=f(g)f(h)$$ hold for all $g,h \in G$. Now, obviously, these axioms for the homomorphism aren't minimal, meaning (HOM2) $\Rightarrow$ (HOM1). So, naturally, I asked myself, if the same doesn't happen with the group action axioms, meaning (GA2) $\Rightarrow$ (GA1). Now the thing is, I can show that this is the case by showing that a mapping $\nu$  satisfies (GA2) iff the mapping $$\tau: G\rightarrow X_{\leftrightarrow} ,$$ where $X_{\leftrightarrow}$ is the group  of all bijections on $X$ together with the composition, defined by $$\tau(g)(x)=\nu(g,x),$$ is a homomorphism: $(\tau(g)\circ \tau(h))(x)=\tau(g)(\nu(h,x))=\nu(g,\nu(h,x)),$ which by (GA2) equals $\nu(gh,x)=\tau(gh)(x)$, and $\nu(g,\nu(h,x))=\tau(g)(\tau(h)(x))$ which by (HOM2) equals $\tau(gh)(x)=\nu(gh,x)$ for all $g,h\in G$ and $x\in X$. From that I can now show (GA1) by the following implications: $$ \textrm{(GA2)} \Leftrightarrow \textrm{(HOM2)} \Rightarrow \textrm{(HOM1)}  \Rightarrow \textrm{(GA1)}. $$ Now (finally) my question: Can't I show that (GA1) follows from (GA2) directly ? I tried doing that, but couldn't succeed, because unlike showing  $ \textrm{(HOM2)} \Rightarrow \textrm{(HOM1)}  $ I don't have an thing like an ""inverse to $\nu(1,x)$"" that I can apply upon $\nu(1,\nu(1,x))=\nu(1,x)$ to get $\nu(,x)=1$.","[Beware that my question is at the bottom of all this text.] We defined in a group theory course a group action to be a mapping $$\nu:G\times X \rightarrow X,$$ $(G,\cdot)$ group and $X$ some set, such that the axioms $$ \textrm{(GA1)} \ \ \  \nu(1,x)=x$$ and $$ \textrm{(GA2)} \ \ \ \nu(g,\nu(h,x))=\nu(g h, x)$$ hold for every $g,h\in G$ and $x\in X$. We defined a group homomorphism to be a map $$f:G\rightarrow H,$$ such that the axioms $$\textrm{(HOM1)} \ \ \  f(1_G)=1_H $$  and $$\textrm{(HOM2)} \ \ \ f(gh)=f(g)f(h)$$ hold for all $g,h \in G$. Now, obviously, these axioms for the homomorphism aren't minimal, meaning (HOM2) $\Rightarrow$ (HOM1). So, naturally, I asked myself, if the same doesn't happen with the group action axioms, meaning (GA2) $\Rightarrow$ (GA1). Now the thing is, I can show that this is the case by showing that a mapping $\nu$  satisfies (GA2) iff the mapping $$\tau: G\rightarrow X_{\leftrightarrow} ,$$ where $X_{\leftrightarrow}$ is the group  of all bijections on $X$ together with the composition, defined by $$\tau(g)(x)=\nu(g,x),$$ is a homomorphism: $(\tau(g)\circ \tau(h))(x)=\tau(g)(\nu(h,x))=\nu(g,\nu(h,x)),$ which by (GA2) equals $\nu(gh,x)=\tau(gh)(x)$, and $\nu(g,\nu(h,x))=\tau(g)(\tau(h)(x))$ which by (HOM2) equals $\tau(gh)(x)=\nu(gh,x)$ for all $g,h\in G$ and $x\in X$. From that I can now show (GA1) by the following implications: $$ \textrm{(GA2)} \Leftrightarrow \textrm{(HOM2)} \Rightarrow \textrm{(HOM1)}  \Rightarrow \textrm{(GA1)}. $$ Now (finally) my question: Can't I show that (GA1) follows from (GA2) directly ? I tried doing that, but couldn't succeed, because unlike showing  $ \textrm{(HOM2)} \Rightarrow \textrm{(HOM1)}  $ I don't have an thing like an ""inverse to $\nu(1,x)$"" that I can apply upon $\nu(1,\nu(1,x))=\nu(1,x)$ to get $\nu(,x)=1$.",,['abstract-algebra']
15,Domains with isomorphic field of fractions,Domains with isomorphic field of fractions,,"Given the domain $\mathbb{Q}[r,s,t]/(s^2 - (r-1)(r-2)(r-3), t^2 - (r+1)(r+2)(r+3))$, find a domain $\mathbb{Q}[x,y]/(f)$ with isomorphic field of fractions.","Given the domain $\mathbb{Q}[r,s,t]/(s^2 - (r-1)(r-2)(r-3), t^2 - (r+1)(r+2)(r+3))$, find a domain $\mathbb{Q}[x,y]/(f)$ with isomorphic field of fractions.",,['abstract-algebra']
16,A nonreflexive module isomorphic to its double dual,A nonreflexive module isomorphic to its double dual,,"I know that the definition of reflexive module is that the $R$-module $M$ should be isomomorphic to its double dual $M^{**}$ via the canonical map $M\rightarrow M^{**}$. I'd like to know an example of an $R$-module $M$ such that it's isomorphic to $M^{**}$ but the canonical map $M\rightarrow M^{**}$ is not an isomorphism. Do you have such an example? (I know that for Banach spaces such example exists, but I don't know it.) (I put also the tag banach-spaces, maybe it's helpful to know the example for Banach spaces.)","I know that the definition of reflexive module is that the $R$-module $M$ should be isomomorphic to its double dual $M^{**}$ via the canonical map $M\rightarrow M^{**}$. I'd like to know an example of an $R$-module $M$ such that it's isomorphic to $M^{**}$ but the canonical map $M\rightarrow M^{**}$ is not an isomorphism. Do you have such an example? (I know that for Banach spaces such example exists, but I don't know it.) (I put also the tag banach-spaces, maybe it's helpful to know the example for Banach spaces.)",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'modules', 'banach-spaces']"
17,Artin's proof of the order of $\mathbb Z[i]/(a+bi)$,Artin's proof of the order of,\mathbb Z[i]/(a+bi),"As Ben suggested in my earlier question on the subject , I looked at Artin's proof that $\left|\cdot\right|^2$ is a ""size function"" which makes $\mathbb Z [i]$ into a Euclidean domain. To quote page 398: We divide the complex number b by a: $b=aw$, where $w=x+yi$ a complex number, not necessarily a Gauss integer. The we choose the nearest Gauss integer point $(m,n)$ to $(x,y)$, writing $x=m+x_0,y=n+y_0$, where m,n are integers and $x_0,y_0$ real numbers such that $-1/2\leq x_0,y_0<1/2$. Then $(m+ni)a$ is the required point of $Ra$. For, $\left|x_0 + y_0i\right|^2<1/2$ and $|b-(m+ni)a|^2=|a(x_0+y_0i)|^2<\frac{1}{2}|a|^2$. I have two questions: I assume he's using the notation $\left|a+bi\right|=\sqrt{a^2 + b^2}$. If so, it seems like $\left|x_0 + y_0i\right|^2<1/2$ is not always true since $\left|(-1/2)+(-1/2)i\right|^2=1/2$ He never uses the identity $i^2=-1$, so it seems like this proof could be expanded to all rings $\mathbb Z[x]/(x^2 + a)$, or indeed anything which has a vectorspace-like structure like $\mathbb Z^2$. But I remember hearing that $\mathbb Z[\sqrt{-5}]$ is not Euclidean - why does this proof fail for $x^2 = -5$? EDIT : $\sqrt{-5}\approx 2.2i$ so we can write for example $3i \approx 1.3\sqrt{-5}$. By my understanding, $y_0=.3$ here and the norm $|0+.3|=0^2+.3^2$ is less than one. Furthermore, every $x_0,y_0$ is less than $1/2$, so this norm will always be less than 1, which is all we need. Why doesn't this show that $\mathbb Z[\sqrt{-5}]$ is Euclidean?","As Ben suggested in my earlier question on the subject , I looked at Artin's proof that $\left|\cdot\right|^2$ is a ""size function"" which makes $\mathbb Z [i]$ into a Euclidean domain. To quote page 398: We divide the complex number b by a: $b=aw$, where $w=x+yi$ a complex number, not necessarily a Gauss integer. The we choose the nearest Gauss integer point $(m,n)$ to $(x,y)$, writing $x=m+x_0,y=n+y_0$, where m,n are integers and $x_0,y_0$ real numbers such that $-1/2\leq x_0,y_0<1/2$. Then $(m+ni)a$ is the required point of $Ra$. For, $\left|x_0 + y_0i\right|^2<1/2$ and $|b-(m+ni)a|^2=|a(x_0+y_0i)|^2<\frac{1}{2}|a|^2$. I have two questions: I assume he's using the notation $\left|a+bi\right|=\sqrt{a^2 + b^2}$. If so, it seems like $\left|x_0 + y_0i\right|^2<1/2$ is not always true since $\left|(-1/2)+(-1/2)i\right|^2=1/2$ He never uses the identity $i^2=-1$, so it seems like this proof could be expanded to all rings $\mathbb Z[x]/(x^2 + a)$, or indeed anything which has a vectorspace-like structure like $\mathbb Z^2$. But I remember hearing that $\mathbb Z[\sqrt{-5}]$ is not Euclidean - why does this proof fail for $x^2 = -5$? EDIT : $\sqrt{-5}\approx 2.2i$ so we can write for example $3i \approx 1.3\sqrt{-5}$. By my understanding, $y_0=.3$ here and the norm $|0+.3|=0^2+.3^2$ is less than one. Furthermore, every $x_0,y_0$ is less than $1/2$, so this norm will always be less than 1, which is all we need. Why doesn't this show that $\mathbb Z[\sqrt{-5}]$ is Euclidean?",,"['abstract-algebra', 'ring-theory']"
18,Construction of the monoid of fractions,Construction of the monoid of fractions,,"This question comes from my attempt to solve Exercise 17(b) of Bourbaki, Algebra , Chapter 1, §2. Let $E$ be a commutative monoid (written multiplicatively) and $S$ a submonoid of $E$. Define on $E\times S$ an equivalence relation by $(a,s)\sim(b,t):\Leftrightarrow$ ""$\exists u\in S$ such that $atu=bsu$"". Denote the set $(E\times S)/\sim$ by $\overline{E}$ and the class of $(a,s)$ by $a/s$. For any $a\in E$, let $\epsilon(a)=a/e$. So far so good. The Bourbaki exercise is actually more general (replacing commutativity by weaker assumptions), but, even in this special case, I can't do the next step: Show that there exists on $\overline{E}$ one and only one monoid structure such that $\epsilon$ is a monoid homomorphism and such that, for all $s\in S$, $\epsilon(s)$ is invertible. My problem is with the ""only one"" part. Given a monoid structure $\otimes$ on $\overline{E}$ with those properties, I see no reason why $(a/s)\otimes(b/t)=(ab)/(st)$ or even $(s/e)\otimes(e/s)=e/e$. I couldn't find a counterexample in the case $E=\mathbb{N}$, nor did the search give me any intuition on why the assertion should be true. This commutative case is treated in the text of Bourbaki's Algebra , but there no mention is made of ""only one"". I'm glad for anything that gets me started.","This question comes from my attempt to solve Exercise 17(b) of Bourbaki, Algebra , Chapter 1, §2. Let $E$ be a commutative monoid (written multiplicatively) and $S$ a submonoid of $E$. Define on $E\times S$ an equivalence relation by $(a,s)\sim(b,t):\Leftrightarrow$ ""$\exists u\in S$ such that $atu=bsu$"". Denote the set $(E\times S)/\sim$ by $\overline{E}$ and the class of $(a,s)$ by $a/s$. For any $a\in E$, let $\epsilon(a)=a/e$. So far so good. The Bourbaki exercise is actually more general (replacing commutativity by weaker assumptions), but, even in this special case, I can't do the next step: Show that there exists on $\overline{E}$ one and only one monoid structure such that $\epsilon$ is a monoid homomorphism and such that, for all $s\in S$, $\epsilon(s)$ is invertible. My problem is with the ""only one"" part. Given a monoid structure $\otimes$ on $\overline{E}$ with those properties, I see no reason why $(a/s)\otimes(b/t)=(ab)/(st)$ or even $(s/e)\otimes(e/s)=e/e$. I couldn't find a counterexample in the case $E=\mathbb{N}$, nor did the search give me any intuition on why the assertion should be true. This commutative case is treated in the text of Bourbaki's Algebra , but there no mention is made of ""only one"". I'm glad for anything that gets me started.",,"['abstract-algebra', 'monoid']"
19,Show the $R$-module $R$ is isomorphic to $Rb \times R(1-b)$ where $b$ is an idempotent of a commutative ring with unity,Show the -module  is isomorphic to  where  is an idempotent of a commutative ring with unity,R R Rb \times R(1-b) b,"Let $R$ be a commutative ring with unity and let $B(R)$ be the set of all idempotent elements in $R$. Show for $b\in B(R)$, the $R$-modules $R$ and $Rb \times R(1-b)$ are isomorphic to one another.","Let $R$ be a commutative ring with unity and let $B(R)$ be the set of all idempotent elements in $R$. Show for $b\in B(R)$, the $R$-modules $R$ and $Rb \times R(1-b)$ are isomorphic to one another.",,"['abstract-algebra', 'modules']"
20,Third term in the free Lie ring,Third term in the free Lie ring,,"I'm working with the Lie algebra of the free group: $$\mathscr{L}(F_n) = \oplus_{d=1}^{\infty} \mathscr{L}_d(F_n),$$ where $\mathscr{L}_d(F_n) = \gamma_d(F_n) / \gamma_{d+1}(F_n)$ and $\gamma_d(F_n)$ is the $d$ th term in the lower central series. By a theorem of Magnus and Witt, $\mathscr{L}(F_n) \cong L(\mathbb{Z}^n)$ the free Lie ring. This makes the lower degree terms easy to see: $\mathscr{L}_1(F_n) = F_n / [F_n, F_n] \cong \mathbb{Z}^n = L_1(\mathbb{Z}^n)$ $\mathscr{L}_2(F_n) = [F_n, F_n] / [[F_n, F_n], F_n]$ . This is isomorphic to $L_2(\mathbb{Z}^n)$ , which contains all things you get by bracketing degree 1 terms in $L(\mathbb{Z}^n)$ : $$[x,y] = x \otimes y - y \otimes x,$$ so it's easy to see $L_2(\mathbb{Z}^n) \cong \wedge^2 \mathbb{Z}^n$ . We get the isomorphism $\mathscr{L}_2(F_n) \rightarrow \wedge^2 \mathbb{Z}^n$ by sending $[x,y] \mapsto [x] \wedge [y]$ , where $[x]$ is its abelianization. How can we describe $\mathscr{L}_3(F_n) \cong L_3(\mathbb{Z}^n)$ in a similar way? It would be great to have a description as a $\mathbb{Z}$ -vector space with maps from $\mathscr{L}_3(F_n)$ and $L_3(\mathbb{Z}^n)$ into it.","I'm working with the Lie algebra of the free group: where and is the th term in the lower central series. By a theorem of Magnus and Witt, the free Lie ring. This makes the lower degree terms easy to see: . This is isomorphic to , which contains all things you get by bracketing degree 1 terms in : so it's easy to see . We get the isomorphism by sending , where is its abelianization. How can we describe in a similar way? It would be great to have a description as a -vector space with maps from and into it.","\mathscr{L}(F_n) = \oplus_{d=1}^{\infty} \mathscr{L}_d(F_n), \mathscr{L}_d(F_n) = \gamma_d(F_n) / \gamma_{d+1}(F_n) \gamma_d(F_n) d \mathscr{L}(F_n) \cong L(\mathbb{Z}^n) \mathscr{L}_1(F_n) = F_n / [F_n, F_n] \cong \mathbb{Z}^n = L_1(\mathbb{Z}^n) \mathscr{L}_2(F_n) = [F_n, F_n] / [[F_n, F_n], F_n] L_2(\mathbb{Z}^n) L(\mathbb{Z}^n) [x,y] = x \otimes y - y \otimes x, L_2(\mathbb{Z}^n) \cong \wedge^2 \mathbb{Z}^n \mathscr{L}_2(F_n) \rightarrow \wedge^2 \mathbb{Z}^n [x,y] \mapsto [x] \wedge [y] [x] \mathscr{L}_3(F_n) \cong L_3(\mathbb{Z}^n) \mathbb{Z} \mathscr{L}_3(F_n) L_3(\mathbb{Z}^n)","['abstract-algebra', 'ring-theory', 'lie-groups', 'lie-algebras', 'graded-modules']"
21,When is the center of group contained in the derived subgroup,When is the center of group contained in the derived subgroup,,"Let $N$ be a group. Assume that $N$ is torsion-free, finitely generated and nilpotent. I read somewhere that $$ Z(N) \subset [N,N] \iff N \text{ cannot be written as a direct product of groups } N = A \times B \text{ where }A \text{ is non-trivial abelian.}$$ One implication is clear to me: $\implies$ . I prove it by contraposition: assume $N$ can be decomposed as $A\times B$ where $A$ is non-trivial abelian. Then it is clear that $$ Z(N) = Z(A) \times Z(B) = A\times Z(B).$$ On the other hand, we have that $$ [N,N] = [A,A] \times [B,B] = \{1\} \times [B,B].$$ If we had that $Z(N) \subset [N,N]$ , we would need that $A\subset \{1\}$ , which is clearly not possible as $A$ was non-trivial. So by contraposition, we have proven the first implication. Now my problem is with the other implication. I don't know how I can prove the converse. I don't even know how to go about doing that. My gut suggests contraposition again, but then I have to use the assumption that $Z(N) \not\subset [N,N]$ to somehow construct a direct product decomposition of $N$ which has a non-trivial abelian factor, and I don't see how I can go about doing something like that. Does anyone have any suggestions? Thanks in advance! Edit: I added the assumptions that $N$ is torsion-free, finitely generated and nilpotent. These are the only groups I am interested in in the context of my research.","Let be a group. Assume that is torsion-free, finitely generated and nilpotent. I read somewhere that One implication is clear to me: . I prove it by contraposition: assume can be decomposed as where is non-trivial abelian. Then it is clear that On the other hand, we have that If we had that , we would need that , which is clearly not possible as was non-trivial. So by contraposition, we have proven the first implication. Now my problem is with the other implication. I don't know how I can prove the converse. I don't even know how to go about doing that. My gut suggests contraposition again, but then I have to use the assumption that to somehow construct a direct product decomposition of which has a non-trivial abelian factor, and I don't see how I can go about doing something like that. Does anyone have any suggestions? Thanks in advance! Edit: I added the assumptions that is torsion-free, finitely generated and nilpotent. These are the only groups I am interested in in the context of my research.","N N  Z(N) \subset [N,N] \iff N \text{ cannot be written as a direct product of groups } N = A \times B \text{ where }A \text{ is non-trivial abelian.} \implies N A\times B A  Z(N) = Z(A) \times Z(B) = A\times Z(B).  [N,N] = [A,A] \times [B,B] = \{1\} \times [B,B]. Z(N) \subset [N,N] A\subset \{1\} A Z(N) \not\subset [N,N] N N","['abstract-algebra', 'group-theory', 'direct-product', 'derived-subgroup']"
22,Are the character tables for $Z$-groups known?,Are the character tables for -groups known?,Z,"A $Z$ -group is a group whose Sylow subgroups are all cyclic groups. I know from here that if two $Z$ -groups have the same character table, then they are in fact isomorphic groups. To my understanding, all finite $Z$ -groups are a semidirect product of two cyclic groups of the form $\mathscr{C}_n \rtimes \mathscr{C}_m$ , since they have presentation $\langle a, b \,\vert\, a^n=b^m=1, b^{-1}ab = a^r\rangle$ where $gcd((r-1)n, m)=1$ and $r^n\equiv 1\pmod{m}$ . I know for $n$ odd the dihedral groups $D_{2n}$ , and dicyclic groups $D_{4n}$ are $Z$ -groups, and the character tables are known for all $n$ . Is the character table for all $Z$ -groups known, and where could I find it?","A -group is a group whose Sylow subgroups are all cyclic groups. I know from here that if two -groups have the same character table, then they are in fact isomorphic groups. To my understanding, all finite -groups are a semidirect product of two cyclic groups of the form , since they have presentation where and . I know for odd the dihedral groups , and dicyclic groups are -groups, and the character tables are known for all . Is the character table for all -groups known, and where could I find it?","Z Z Z \mathscr{C}_n \rtimes \mathscr{C}_m \langle a, b \,\vert\, a^n=b^m=1, b^{-1}ab = a^r\rangle gcd((r-1)n, m)=1 r^n\equiv 1\pmod{m} n D_{2n} D_{4n} Z n Z","['abstract-algebra', 'group-theory', 'reference-request', 'sylow-theory']"
23,When does a monoid admit a ring structure?,When does a monoid admit a ring structure?,,"In this question, it is asked when an abelian group admits a ring structure; that is, if $(G,+)$ is an abelian group, then under what conditions is there a binary operation $\cdot$ on $G$ such that $(G,+,\cdot)$ is a ring. (For the purposes of this question, rings are unital.) I am interested in the ""dual"" question of when a monoid admits a ring structure; that is, if $(M,\cdot)$ is a monoid, then under what conditions is there a binary operation $+$ on $M$ such that $(M,+,\cdot)$ is a ring?","In this question, it is asked when an abelian group admits a ring structure; that is, if is an abelian group, then under what conditions is there a binary operation on such that is a ring. (For the purposes of this question, rings are unital.) I am interested in the ""dual"" question of when a monoid admits a ring structure; that is, if is a monoid, then under what conditions is there a binary operation on such that is a ring?","(G,+) \cdot G (G,+,\cdot) (M,\cdot) + M (M,+,\cdot)","['abstract-algebra', 'group-theory', 'ring-theory', 'monoid']"
24,What should the $\mathfrak{sl}(3)$ Chebyshev polynomials be?,What should the  Chebyshev polynomials be?,\mathfrak{sl}(3),"Consider $\mathfrak{sl}_2$ and its fundamental weight $\lambda_1$ . The character of the simple representation $L(n\lambda_1)$ with highest weight $n\lambda_1$ is given by a polynomial in $x=\mathrm{ch}L(\lambda_1)$ . Writing $P_n(x)=\mathrm{ch}L(n\lambda_1)$ , we have a recurrence $P_n(x)=xP_{n-1}(x)-P_{n-2}$ . The first few polynomials are $1,x,x^2-1,x^3-2x\dots$ These are actually the Chebyshev polynomials of the second kind on the interval $[-2,2]$ . Consider the same question for $\mathfrak{sl}_3$ , with simple roots $\alpha_1$ , $\alpha_2$ and corresponding fundamental weights $\lambda_1$ , $\lambda_2$ . Let $x=\mathrm{ch}L(\lambda_1)$ and $y=\mathrm{ch}L(\lambda_2)$ . Let $P_{m,n}(x,y)=\mathrm{ch}L(m\lambda_1+n\lambda_2)$ . What recurrence do the $P_{m,n}(x,y)$ satisfy? Recall that the classical Chebyshev polynomials satisfy $\int_{-2}^2P_m(x)P_n(x)\sqrt{4-x^2}dx=\delta_{m,n}$ . Are the $P_{m, n}$ orthogonal in the way that the Chebyshev polynomials are orthogonal?","Consider and its fundamental weight . The character of the simple representation with highest weight is given by a polynomial in . Writing , we have a recurrence . The first few polynomials are These are actually the Chebyshev polynomials of the second kind on the interval . Consider the same question for , with simple roots , and corresponding fundamental weights , . Let and . Let . What recurrence do the satisfy? Recall that the classical Chebyshev polynomials satisfy . Are the orthogonal in the way that the Chebyshev polynomials are orthogonal?","\mathfrak{sl}_2 \lambda_1 L(n\lambda_1) n\lambda_1 x=\mathrm{ch}L(\lambda_1) P_n(x)=\mathrm{ch}L(n\lambda_1) P_n(x)=xP_{n-1}(x)-P_{n-2} 1,x,x^2-1,x^3-2x\dots [-2,2] \mathfrak{sl}_3 \alpha_1 \alpha_2 \lambda_1 \lambda_2 x=\mathrm{ch}L(\lambda_1) y=\mathrm{ch}L(\lambda_2) P_{m,n}(x,y)=\mathrm{ch}L(m\lambda_1+n\lambda_2) P_{m,n}(x,y) \int_{-2}^2P_m(x)P_n(x)\sqrt{4-x^2}dx=\delta_{m,n} P_{m, n}","['abstract-algebra', 'recurrence-relations', 'lie-algebras', 'chebyshev-polynomials']"
25,Is there a notion of best $\mathbb{K}$-approximations where $\mathbb{K}$ is an algebraic number field?,Is there a notion of best -approximations where  is an algebraic number field?,\mathbb{K} \mathbb{K},"A known approximation of $\pi$ is $\sqrt{2}+\sqrt{3}=\color{green}{3.14}\color{red}{6264...}$ But recently I came across a refinement of this approximation $$\pi\approx\sqrt{2}+\sqrt{3}+\frac{\sqrt{2}-\sqrt{3}}{68}=\color{green}{3.14159}\color{red}{0292...}$$ Knowing this, I tried to find interesting approximations of $\pi$ on $\mathbb{Q}(\sqrt{2},\sqrt{3})$ and I've been able to obtain $$\boxed{\pi\approx\frac{42(132\sqrt{2}+375\sqrt{3}-19^2)}{5\left(\left(5^2+2^2\cdot\sqrt{2}\right)\left(10^2+3^2\cdot\sqrt{3}\right)-2273\right)}=\color{green}{3.1415926535897}\color{red}{63336...}}$$ But this made me thinking: Q: Similar to how we know that the best $\mathbb{Q}$ -aproximations of a given real number $x>0$ are given via the partial fractions of its continued fraction representation, is there any notion of best $\mathbb{K}$ -approximations where $\mathbb{K}$ is an algebraic number field (i.e. a finite field extension of $\mathbb{Q}$ ) like $\mathbb{K}=\mathbb{Q}(\sqrt{2})$ or $\mathbb{K}=\mathbb{Q}(\sqrt{2},\sqrt{3})$ ? I know that, for $\mathbb{Q}$ , we can say that $\frac{a}{b}\in\mathbb{Q}$ is a best approximation of $x>0$ if $$\forall a'/b'\in\mathbb{Q}\text{ with }b'\leq b\text{ we have }\left|x-\frac{a}{b}\right|\leq\left|x-\frac{a'}{b'}\right|$$ However, we can't extend this to (say) $\mathbb{Q}(\sqrt{2})$ naively expressing numbers of $\mathbb{Q}(\sqrt{2})$ as $\frac{a+b\sqrt{2}}{c}$ since $\mathbb{Z}(\sqrt{2})=\{a+b\sqrt{2}:a,b\in\mathbb{Z}\}$ is dense on $\mathbb{R}$ so, for a fixed $c$ , we can find $\frac{a+b\sqrt{2}}{c}$ arbitrarily close to $x>0$ .","A known approximation of is But recently I came across a refinement of this approximation Knowing this, I tried to find interesting approximations of on and I've been able to obtain But this made me thinking: Q: Similar to how we know that the best -aproximations of a given real number are given via the partial fractions of its continued fraction representation, is there any notion of best -approximations where is an algebraic number field (i.e. a finite field extension of ) like or ? I know that, for , we can say that is a best approximation of if However, we can't extend this to (say) naively expressing numbers of as since is dense on so, for a fixed , we can find arbitrarily close to .","\pi \sqrt{2}+\sqrt{3}=\color{green}{3.14}\color{red}{6264...} \pi\approx\sqrt{2}+\sqrt{3}+\frac{\sqrt{2}-\sqrt{3}}{68}=\color{green}{3.14159}\color{red}{0292...} \pi \mathbb{Q}(\sqrt{2},\sqrt{3}) \boxed{\pi\approx\frac{42(132\sqrt{2}+375\sqrt{3}-19^2)}{5\left(\left(5^2+2^2\cdot\sqrt{2}\right)\left(10^2+3^2\cdot\sqrt{3}\right)-2273\right)}=\color{green}{3.1415926535897}\color{red}{63336...}} \mathbb{Q} x>0 \mathbb{K} \mathbb{K} \mathbb{Q} \mathbb{K}=\mathbb{Q}(\sqrt{2}) \mathbb{K}=\mathbb{Q}(\sqrt{2},\sqrt{3}) \mathbb{Q} \frac{a}{b}\in\mathbb{Q} x>0 \forall a'/b'\in\mathbb{Q}\text{ with }b'\leq b\text{ we have }\left|x-\frac{a}{b}\right|\leq\left|x-\frac{a'}{b'}\right| \mathbb{Q}(\sqrt{2}) \mathbb{Q}(\sqrt{2}) \frac{a+b\sqrt{2}}{c} \mathbb{Z}(\sqrt{2})=\{a+b\sqrt{2}:a,b\in\mathbb{Z}\} \mathbb{R} c \frac{a+b\sqrt{2}}{c} x>0","['abstract-algebra', 'number-theory', 'reference-request', 'field-theory', 'diophantine-approximation']"
26,The successor of 0 in an ordered ring,The successor of 0 in an ordered ring,,"The Setup I am investigating properties of the following definition of ordered rings: Let $R$ be a ring. We say $R$ is an ordered ring under the total order relation $\leq$ if, for all $a,b,c \in R$ , $$ (1). a \leq b \text{ implies } a+c \leq b+c, \text{ and} $$ $$(2). 0 \leq a \text{ and } 0\leq b \text{ implies } 0\leq ab. $$ We can also say $R$ is strictly ordered by $\leq$ if the above conditions hold with the strict order $<$ replacing $\leq$ throughout. It's been noted on this post and other places that the two notions of strict/non-strict are separate. I found and proved the following theorem while looking at the order topology of $R$ : Let $(R,\leq)$ be a (nonzero) ordered ring with unity. If $0$ has an immediate successor $\epsilon \in R$ , then $\epsilon\leq1$ , and either $\epsilon^2 = 0$ or $\epsilon^2 = \epsilon$ . The proof is simple: we must have $\epsilon \leq 1$ because otherwise $1 \in (0,\epsilon)$ , a contradiction. But then $0 < \epsilon \leq 1$ implies $0 \leq \epsilon^2 \leq \epsilon$ upon multiplication by $\epsilon$ . The Question In the theorem, $\mathbb{Z}$ is a simple example of the latter case, because the "" $\epsilon$ "" is just $1$ . One can show that this is always so in a discrete strictly ordered ring. I also have an example of the former case: the dual integers $\mathbb{Z}[\epsilon] = \{a+b\epsilon : a,b\in\mathbb{Z}, \epsilon^2 = 0\}$ , together with the lexicographic order. Here $\epsilon$ is the immediate successor of zero. My question is this: Is there an ordered ring $R$ (necessarily non-strictly ordered) such that $0$ has an immediate successor $\epsilon \in R$ with $\epsilon^2 = \epsilon$ and $\epsilon \neq 1$ ? My intuition tells me that the answer is no, but I don't have any evidence to back it. Any insight is appreciated!","The Setup I am investigating properties of the following definition of ordered rings: Let be a ring. We say is an ordered ring under the total order relation if, for all , We can also say is strictly ordered by if the above conditions hold with the strict order replacing throughout. It's been noted on this post and other places that the two notions of strict/non-strict are separate. I found and proved the following theorem while looking at the order topology of : Let be a (nonzero) ordered ring with unity. If has an immediate successor , then , and either or . The proof is simple: we must have because otherwise , a contradiction. But then implies upon multiplication by . The Question In the theorem, is a simple example of the latter case, because the "" "" is just . One can show that this is always so in a discrete strictly ordered ring. I also have an example of the former case: the dual integers , together with the lexicographic order. Here is the immediate successor of zero. My question is this: Is there an ordered ring (necessarily non-strictly ordered) such that has an immediate successor with and ? My intuition tells me that the answer is no, but I don't have any evidence to back it. Any insight is appreciated!","R R \leq a,b,c \in R 
(1). a \leq b \text{ implies } a+c \leq b+c, \text{ and}
 (2). 0 \leq a \text{ and } 0\leq b \text{ implies } 0\leq ab.
 R \leq < \leq R (R,\leq) 0 \epsilon \in R \epsilon\leq1 \epsilon^2 = 0 \epsilon^2 = \epsilon \epsilon \leq 1 1 \in (0,\epsilon) 0 < \epsilon \leq 1 0 \leq \epsilon^2 \leq \epsilon \epsilon \mathbb{Z} \epsilon 1 \mathbb{Z}[\epsilon] = \{a+b\epsilon : a,b\in\mathbb{Z}, \epsilon^2 = 0\} \epsilon R 0 \epsilon \in R \epsilon^2 = \epsilon \epsilon \neq 1","['abstract-algebra', 'ring-theory', 'order-theory']"
27,Is $\mathbb Z$ of finite presentation over $\mathbb F_1$?,Is  of finite presentation over ?,\mathbb Z \mathbb F_1,"I know that there are several proposals for theories of the ""field with one element"", such as Deitmar's, based on ""commutative monoids with zero"" and monoid schemes , or Lorscheid's, based on blueprints . This is not my field at all (I am a theoretical computer scientist), so my understanding of this is extremely superficial and I was not able to figure out whether, within any of these theories, the integers are an algebra of finite presentation over the field with one element. Is this the case? If the current theories do not provide an answer (for example because it is not clear what ""finitely presented"" even means), is there a best guess?  I mean, in a fully working theory of the field with one element, is this expected to be true or not?","I know that there are several proposals for theories of the ""field with one element"", such as Deitmar's, based on ""commutative monoids with zero"" and monoid schemes , or Lorscheid's, based on blueprints . This is not my field at all (I am a theoretical computer scientist), so my understanding of this is extremely superficial and I was not able to figure out whether, within any of these theories, the integers are an algebra of finite presentation over the field with one element. Is this the case? If the current theories do not provide an answer (for example because it is not clear what ""finitely presented"" even means), is there a best guess?  I mean, in a fully working theory of the field with one element, is this expected to be true or not?",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
28,Proving a Ring Commutative,Proving a Ring Commutative,,"Let $(A, +, \cdot)$ be a ring with the following properties a) $1 + 1=0$ ; b) $x^2=0$ for any noninvertible $x$ ; c) $\forall x \in A$ that are invertible, $\exists x' \in Z(A)$ such that $x^2=(x')^2$ . Prove that $A$ is commutative. $1+1=0 \Rightarrow a+a=0 \Rightarrow a=-a\forall a \in A$ Let $a$ and $b$ be two elements in $A$ such that at least one of them is not invertible. Then $ab$ is not invertible, so $(ab)^2=a^2b^2$ . Now let $x$ and $y$ be two invertible elements in $A$ . $xy$ is invertible so there exists $a \in Z(A), (xy)^2=a \Rightarrow x(yx)y=a^2 \Rightarrow yx=x^{-1}a^2y^{-1}$ . Because $a^2$ is in $Z(A)$ it commutes with every element in $A$ , therefore $yx =x^{-1}y^{-1}a^2\Rightarrow (yx)^2=a^2=(xy)^2$ . I feel like $f:A \to A, f(x)=x^2$ should be a homomorphism, but I cannot seem to prove it. I know I should use the fact that $1+1=0$ , but I could not find a meaningful way to use it.","Let be a ring with the following properties a) ; b) for any noninvertible ; c) that are invertible, such that . Prove that is commutative. Let and be two elements in such that at least one of them is not invertible. Then is not invertible, so . Now let and be two invertible elements in . is invertible so there exists . Because is in it commutes with every element in , therefore . I feel like should be a homomorphism, but I cannot seem to prove it. I know I should use the fact that , but I could not find a meaningful way to use it.","(A, +, \cdot) 1 + 1=0 x^2=0 x \forall x \in A \exists x' \in Z(A) x^2=(x')^2 A 1+1=0 \Rightarrow a+a=0 \Rightarrow a=-a\forall a \in A a b A ab (ab)^2=a^2b^2 x y A xy a \in Z(A), (xy)^2=a \Rightarrow x(yx)y=a^2 \Rightarrow yx=x^{-1}a^2y^{-1} a^2 Z(A) A yx =x^{-1}y^{-1}a^2\Rightarrow (yx)^2=a^2=(xy)^2 f:A \to A, f(x)=x^2 1+1=0","['abstract-algebra', 'group-theory', 'ring-theory']"
29,Exact sequence of direct sums of $\mathbb{Q}/\mathbb{Z}$,Exact sequence of direct sums of,\mathbb{Q}/\mathbb{Z},Suppose $$0 \to (\mathbb{Q}/\mathbb{Z})^m \to (\mathbb{Q}/\mathbb{Z})^{m + n} \to (\mathbb{Q}/\mathbb{Z})^n$$ is a left exact sequence of abelian groups. Is it also right-exact (i.e. is $(\mathbb{Q}/\mathbb{Z})^{m + n} \to (\mathbb{Q}/\mathbb{Z})^n$ surjective?) I want to say that the cokernel is finite and therefore $0$ since $(\mathbb{Q}/\mathbb{Z})^n$ has no finite quotients. But how do you get around the fact that these groups are not finitely generated (in which case it would be easy by just looking at ranks)?,Suppose is a left exact sequence of abelian groups. Is it also right-exact (i.e. is surjective?) I want to say that the cokernel is finite and therefore since has no finite quotients. But how do you get around the fact that these groups are not finitely generated (in which case it would be easy by just looking at ranks)?,0 \to (\mathbb{Q}/\mathbb{Z})^m \to (\mathbb{Q}/\mathbb{Z})^{m + n} \to (\mathbb{Q}/\mathbb{Z})^n (\mathbb{Q}/\mathbb{Z})^{m + n} \to (\mathbb{Q}/\mathbb{Z})^n 0 (\mathbb{Q}/\mathbb{Z})^n,"['abstract-algebra', 'commutative-algebra', 'modules', 'abelian-groups', 'exact-sequence']"
30,An indecomposable abelian group $G$ is either torsion or torsion-free,An indecomposable abelian group  is either torsion or torsion-free,G,"I've been self-studying Rotman's An Introduction to the Theory of Groups , and Corollary 10.44 is that ""an indecomposable [abelian] group $G$ is either torsion or torsion-free"". The proof given is as follows: Assume that $0 < tG < G$ . Now $tG$ is not divisible, lest it be a summand of $G$ , so that Corollary 10.43 shows that $G$ has a (cyclic) summand, contradicting indecomposability. The referenced Corollary 10.43 states: A torsion [abelian] group $G$ that is not divisible has a $p$ -primary cyclic direct summand (for some prime $p$ ). Now, in the last step of this proof, I agree that $tG$ has this direct summand (it is the torsion group in the hypothesis of Corollary 10.43), but I am not sure why this implies it is also a summand of the whole group $G$ . I am looking for either an explanation of why this is the case, a different proof of the theorem, or a disproof (since I see from this question that the corresponding statement is not true for general modules over integral domains).","I've been self-studying Rotman's An Introduction to the Theory of Groups , and Corollary 10.44 is that ""an indecomposable [abelian] group is either torsion or torsion-free"". The proof given is as follows: Assume that . Now is not divisible, lest it be a summand of , so that Corollary 10.43 shows that has a (cyclic) summand, contradicting indecomposability. The referenced Corollary 10.43 states: A torsion [abelian] group that is not divisible has a -primary cyclic direct summand (for some prime ). Now, in the last step of this proof, I agree that has this direct summand (it is the torsion group in the hypothesis of Corollary 10.43), but I am not sure why this implies it is also a summand of the whole group . I am looking for either an explanation of why this is the case, a different proof of the theorem, or a disproof (since I see from this question that the corresponding statement is not true for general modules over integral domains).",G 0 < tG < G tG G G G p p tG G,"['abstract-algebra', 'group-theory', 'proof-explanation', 'abelian-groups', 'alternative-proof']"
31,On the number of generators of power of ideal in a local ring,On the number of generators of power of ideal in a local ring,,"let $(R,m)$ be a local ring and let $I,J$ be an ideals of $R$ , let $\mu(I)$ be the minimal number of generators of $I$ . I've proved that $\mu(IJ)\leq\mu(I)$ but somehow this claim does not feel right to me. actually in here the authors go to great length to prove that if $\mu(I^n)\leq n$ , then for every $r>n$ , $\mu(I^r) \leq n$ . while by my proof this is trivial. my proof is: $I/Im$ is vector space over $R/m$ and $(IJ+Im)/Im$ is subspace of $I/Im$ so the dimension of $(IJ+Im)/Im$ is less then or equals $\mu(I)$ so $IJ+Im$ can be generated by $\mu(I)$ elements. let $A$ be a set containing $\mu(I)$ generators of $IJ+Im$ so $(A)=IJ+Im$ and by Nakayama's lemma $(A)=IJ$ . is this right? and if not, where is my mistake?","let be a local ring and let be an ideals of , let be the minimal number of generators of . I've proved that but somehow this claim does not feel right to me. actually in here the authors go to great length to prove that if , then for every , . while by my proof this is trivial. my proof is: is vector space over and is subspace of so the dimension of is less then or equals so can be generated by elements. let be a set containing generators of so and by Nakayama's lemma . is this right? and if not, where is my mistake?","(R,m) I,J R \mu(I) I \mu(IJ)\leq\mu(I) \mu(I^n)\leq n r>n \mu(I^r) \leq n I/Im R/m (IJ+Im)/Im I/Im (IJ+Im)/Im \mu(I) IJ+Im \mu(I) A \mu(I) IJ+Im (A)=IJ+Im (A)=IJ","['abstract-algebra', 'local-rings']"
32,Prove a particular subset of a group is closed under inverse,Prove a particular subset of a group is closed under inverse,,"Let G is a group, $\phi$ is an automorphism, and $ A=\{ g\in G\mid \phi(g)=g^{-1} \}$ . Consider $a \in A$ and $B_a =\{ g\in A\mid ga \in A \}$ . Prove that $g \in B_a$ implies $g^{-1} \in B_a$ . It seems this problem can be solved directly. However, I could not solve it without using centralizer subgroups. This is my solution: Lemma: $A \cap Z(a) =B_a$ , where $Z(a)$ is the centralizer of $a$ . Proof: $g \in B_a \Rightarrow ga \in A \Rightarrow \phi(ga)=(ag)^{-1}$ . Also $\phi(ga)=\phi(g) \phi(a)=g^{-1} a^{-1}=(ga)^{-1}$ . So, $ag=ga$ and $B_a \subset Z(a)$ . Since $B_a \subset Z(a)$ and $B_a \subset A$ , then $A \cap Z(a) =B_a$ . $\blacksquare$ $g \in A$ implies $g^{-1} \in A$ , and $g \in Z(a)$ implies $g^{-1} \in Z(a)$ . Therefore, with using the lemma, $g \in A \cap Z(a)=B_a$ implies $g^{-1} \in B_a$ . Now, I am wondering why I cannot solve it using the following way: $g \in B_a$ implies $ga=ag \in A$ . Also, $ga^{-1}=a^{-1}g$ . Now, in order to prove $g^{-1} \in B_a$ , I only need to prove $g^{-1}a \in A$ or $ga^{-1} \in A$ , but I cannot. Does anyone have another solution or know how to continue this approach?","Let G is a group, is an automorphism, and . Consider and . Prove that implies . It seems this problem can be solved directly. However, I could not solve it without using centralizer subgroups. This is my solution: Lemma: , where is the centralizer of . Proof: . Also . So, and . Since and , then . implies , and implies . Therefore, with using the lemma, implies . Now, I am wondering why I cannot solve it using the following way: implies . Also, . Now, in order to prove , I only need to prove or , but I cannot. Does anyone have another solution or know how to continue this approach?",\phi  A=\{ g\in G\mid \phi(g)=g^{-1} \} a \in A B_a =\{ g\in A\mid ga \in A \} g \in B_a g^{-1} \in B_a A \cap Z(a) =B_a Z(a) a g \in B_a \Rightarrow ga \in A \Rightarrow \phi(ga)=(ag)^{-1} \phi(ga)=\phi(g) \phi(a)=g^{-1} a^{-1}=(ga)^{-1} ag=ga B_a \subset Z(a) B_a \subset Z(a) B_a \subset A A \cap Z(a) =B_a \blacksquare g \in A g^{-1} \in A g \in Z(a) g^{-1} \in Z(a) g \in A \cap Z(a)=B_a g^{-1} \in B_a g \in B_a ga=ag \in A ga^{-1}=a^{-1}g g^{-1} \in B_a g^{-1}a \in A ga^{-1} \in A,"['abstract-algebra', 'group-theory', 'group-isomorphism']"
33,Convex subring is local,Convex subring is local,,"Let $K$ be an ordered field, $R\subseteq K$ a convex subring - that is, for all $a \in K$ , $a \in R$ if $x \leq a \leq y$ for some $x,y \in R$ . Define $I = \{ x \in R: x^{-1} \notin R\}$ . It is clear that if $I$ is an ideal, then $R$ is local. However, I am having some trouble to understand why it is a convex ideal of $R$ . I know that, if $a>1$ and $a \in R$ , then $0 < a^{-1}< 1$ , which implies that $a \notin I$ . I am also unsure of the hypothesis one should assume about $K$ (for example, $K$ may be real closed - or even a model of the theory of the reals as an ordered field). Can someone help me? Edit: For $a \in R$ , assume that $|a|\geq 1/n$ for some $n \in \mathbb{N}$ . If $a>0$ , then $0<a^{-1}\leq n$ which implies $a \notin I$ . If $a<0$ , $-n \leq a^{-1} < 0$ - from which $a^{-1} \notin I$ . Thus, $I \subseteq \{a : |a|<1/n \mbox{ for all } n \}$ .","Let be an ordered field, a convex subring - that is, for all , if for some . Define . It is clear that if is an ideal, then is local. However, I am having some trouble to understand why it is a convex ideal of . I know that, if and , then , which implies that . I am also unsure of the hypothesis one should assume about (for example, may be real closed - or even a model of the theory of the reals as an ordered field). Can someone help me? Edit: For , assume that for some . If , then which implies . If , - from which . Thus, .","K R\subseteq K a \in K a \in R x \leq a \leq y x,y \in R I = \{ x \in R: x^{-1} \notin R\} I R R a>1 a \in R 0 < a^{-1}< 1 a \notin I K K a \in R |a|\geq 1/n n \in \mathbb{N} a>0 0<a^{-1}\leq n a \notin I a<0 -n \leq a^{-1} < 0 a^{-1} \notin I I \subseteq \{a : |a|<1/n \mbox{ for all } n \}","['abstract-algebra', 'commutative-algebra', 'ordered-fields']"
34,Show That Wigner’s Theorem Defines a Surjective Homomorphism $\operatorname{U}(2) \rightarrow \operatorname{SO}(3)$,Show That Wigner’s Theorem Defines a Surjective Homomorphism,\operatorname{U}(2) \rightarrow \operatorname{SO}(3),"Preliminary Knowledge We are working on the finite dimensional Hilbert space $\mathbb{C}^2$ .  The projective Hilbert space is given by $$\mathbb{P}(\mathbb{C}^2)=\big(\mathbb{C}^2 \backslash \{0\}\big)/\mathbb{C}^*, \tag{1}$$ where the equivalence relation $\psi \sim \phi$ is satisfied when $\psi=\lambda \phi$ , for some $\lambda \in \mathbb{C}^*$ and $\psi ,\phi \in \mathbb{C}^2 \backslash \{0\}$ . An important structure is quantum mechanics is the transition probability , which is the map $p:\mathbb{P}(\mathbb{C}^2) \times \mathbb{P}(\mathbb{C}^2) \longrightarrow \mathbb{R}$ defined by $$p([\psi],[\phi])=\frac{|\langle \psi , \phi \rangle |^2}{\langle \psi , \psi \rangle \langle\phi , \phi \rangle}. \tag{2}$$ Furthermore, a quantum mechanical symmetry is defined as an invertible map $f:\mathbb{P}(\mathbb{C}^2) \longrightarrow \mathbb{P}(\mathbb{C}^2)$ which preserves the transition probability: $$p(f([\psi]),f([\phi]))=p([\psi],[\phi]), \quad \text{for} \space [\psi],[\phi] \in \mathbb{P}(\mathbb{C}^2).\tag{3}$$ And finally, Wigner's theorem states that for any quantum mechanical symmetry $f:\mathbb{P}(\mathbb{C}^2) \longrightarrow \mathbb{P}(\mathbb{C}^2)$ there exists a unitary or anti-unitary operator on $\mathbb{C}^2$ that induces $f$ on $\mathbb{P}(\mathbb{C}^2).$ What we know Consider now the set of all one-dimensional projectors in $\mathbb{C}^2$ : $$ \mathbb{E} := \{e \in \operatorname{End}(\mathbb{C}^2) : e^2=e=e^*, 0 \ne e \ne I, \operatorname{dim} \operatorname{im} (e)=1\}, \tag{4}$$ where $I$ is the identity.  By identifying $\mathbb{E}$ with the space of all $2 \times 2$ complex matrices $\operatorname{M}_{2 \times 2}(\mathbb{C})$ with trace $1$ (while excluding the obviously trivial zero and identity matrix), it is straightforward to show that any $e \in \mathbb{E}$ can be written as $$e(\vec{x})=\frac{1}{2}I + \frac{1}{2}\sum_{i=1}^{3}x_i \sigma_i, \quad||\vec{x}||=1, \tag{5}$$ where $\sigma_i$ are the $3$ Pauli matrices.  Equation $(5)$ turns out to define an isomorphism $S^2 \longrightarrow \mathbb{E}$ , and thus $S^2 \cong \mathbb{E}$ .  One can also show that $\mathbb{E} \cong \mathbb{P}(\mathbb{C}^2)$ , and so we have $\mathbb{P}(\mathbb{C}^2) \cong S^2$ .  Then,  by using the formula $p(e,f)=\operatorname{Tr}(ef)$ for any $e,f \in \mathbb{E}$ , we can show that transition probability is given by $$p(\vec{x},\vec{y})=\frac{1}{2}(1+ \langle\vec{x},\vec{y}\rangle), \quad \text{for} \space\vec{x},\vec{y} \in S^2. \tag{6}$$ Next, consider the group of all quantum mechanical symmetries: $$G:= \{f:S^2 \longrightarrow S^2 \space | \space f \space \text{invertible and} \space p(f(\vec{x}),f(\vec{y}))=p(\vec{x},\vec{y}) \space \forall \vec{x},\vec{y} \in S^2\}, \tag{7}$$ as well as the orthogonal group $\operatorname{O}(3)$ , given by $$\operatorname{O}(3; \mathbb{R}) = \{\rho \in \operatorname{GL}(3; \mathbb{R}) \space | \space \langle \rho a, \rho b \rangle = \langle a,b \rangle \space \forall a,b \in \mathbb{R}^3 \}. \tag{8}$$ One can then show that $G \cong \operatorname{O}(3)$ , and hence identify $\operatorname{O}(3)$ with $G$ . The Problem We now restrict to $\operatorname{SO}(3) \subset \operatorname{O}(3)$ .  Show that Wigner's theorem defines a surjective homomorphism $\operatorname{U}(2) \longrightarrow \operatorname{SO}(3)$ sending $u \mapsto R$ defined by $$ue(\vec{x})u^*=e(R(\vec{x})). \tag{9}$$ My Question I do not understand the meaning of equation $(9)$ and I have no idea how to use it; I expected to be given the explicit formula of the homomorphism!  I tried inverting it by using $e^{-1}$ to isolate $R$ , but to no avail.  How then can I show that this map is a homomorphism using equation $(9)$ ? More importantly, I do not see how Wigner's theorem relates to the problem; I'm trying to find a surjective group homomorphism, how can the unitary/anti-unitary operator that induces $f:S^2 \longrightarrow S^2$ help me with that?  The theorem doesn't seem to state anything useful in particular. Any hints/answers will be well appreciated.  Thank you!","Preliminary Knowledge We are working on the finite dimensional Hilbert space .  The projective Hilbert space is given by where the equivalence relation is satisfied when , for some and . An important structure is quantum mechanics is the transition probability , which is the map defined by Furthermore, a quantum mechanical symmetry is defined as an invertible map which preserves the transition probability: And finally, Wigner's theorem states that for any quantum mechanical symmetry there exists a unitary or anti-unitary operator on that induces on What we know Consider now the set of all one-dimensional projectors in : where is the identity.  By identifying with the space of all complex matrices with trace (while excluding the obviously trivial zero and identity matrix), it is straightforward to show that any can be written as where are the Pauli matrices.  Equation turns out to define an isomorphism , and thus .  One can also show that , and so we have .  Then,  by using the formula for any , we can show that transition probability is given by Next, consider the group of all quantum mechanical symmetries: as well as the orthogonal group , given by One can then show that , and hence identify with . The Problem We now restrict to .  Show that Wigner's theorem defines a surjective homomorphism sending defined by My Question I do not understand the meaning of equation and I have no idea how to use it; I expected to be given the explicit formula of the homomorphism!  I tried inverting it by using to isolate , but to no avail.  How then can I show that this map is a homomorphism using equation ? More importantly, I do not see how Wigner's theorem relates to the problem; I'm trying to find a surjective group homomorphism, how can the unitary/anti-unitary operator that induces help me with that?  The theorem doesn't seem to state anything useful in particular. Any hints/answers will be well appreciated.  Thank you!","\mathbb{C}^2 \mathbb{P}(\mathbb{C}^2)=\big(\mathbb{C}^2 \backslash \{0\}\big)/\mathbb{C}^*, \tag{1} \psi \sim \phi \psi=\lambda \phi \lambda \in \mathbb{C}^* \psi ,\phi \in \mathbb{C}^2 \backslash \{0\} p:\mathbb{P}(\mathbb{C}^2) \times \mathbb{P}(\mathbb{C}^2) \longrightarrow \mathbb{R} p([\psi],[\phi])=\frac{|\langle \psi , \phi \rangle |^2}{\langle \psi , \psi \rangle \langle\phi , \phi \rangle}. \tag{2} f:\mathbb{P}(\mathbb{C}^2) \longrightarrow \mathbb{P}(\mathbb{C}^2) p(f([\psi]),f([\phi]))=p([\psi],[\phi]), \quad \text{for} \space [\psi],[\phi] \in \mathbb{P}(\mathbb{C}^2).\tag{3} f:\mathbb{P}(\mathbb{C}^2) \longrightarrow \mathbb{P}(\mathbb{C}^2) \mathbb{C}^2 f \mathbb{P}(\mathbb{C}^2). \mathbb{C}^2  \mathbb{E} := \{e \in \operatorname{End}(\mathbb{C}^2) : e^2=e=e^*, 0 \ne e \ne I, \operatorname{dim} \operatorname{im} (e)=1\}, \tag{4} I \mathbb{E} 2 \times 2 \operatorname{M}_{2 \times 2}(\mathbb{C}) 1 e \in \mathbb{E} e(\vec{x})=\frac{1}{2}I + \frac{1}{2}\sum_{i=1}^{3}x_i \sigma_i, \quad||\vec{x}||=1, \tag{5} \sigma_i 3 (5) S^2 \longrightarrow \mathbb{E} S^2 \cong \mathbb{E} \mathbb{E} \cong \mathbb{P}(\mathbb{C}^2) \mathbb{P}(\mathbb{C}^2) \cong S^2 p(e,f)=\operatorname{Tr}(ef) e,f \in \mathbb{E} p(\vec{x},\vec{y})=\frac{1}{2}(1+ \langle\vec{x},\vec{y}\rangle), \quad \text{for} \space\vec{x},\vec{y} \in S^2. \tag{6} G:= \{f:S^2 \longrightarrow S^2 \space | \space f \space \text{invertible and} \space p(f(\vec{x}),f(\vec{y}))=p(\vec{x},\vec{y}) \space \forall \vec{x},\vec{y} \in S^2\}, \tag{7} \operatorname{O}(3) \operatorname{O}(3; \mathbb{R}) = \{\rho \in \operatorname{GL}(3; \mathbb{R}) \space | \space \langle \rho a, \rho b \rangle = \langle a,b \rangle \space \forall a,b \in \mathbb{R}^3 \}. \tag{8} G \cong \operatorname{O}(3) \operatorname{O}(3) G \operatorname{SO}(3) \subset \operatorname{O}(3) \operatorname{U}(2) \longrightarrow \operatorname{SO}(3) u \mapsto R ue(\vec{x})u^*=e(R(\vec{x})). \tag{9} (9) e^{-1} R (9) f:S^2 \longrightarrow S^2","['abstract-algebra', 'group-theory', 'group-homomorphism', 'quantum-mechanics']"
35,Is there an element-free proof that preimages of radical ideals are radical?,Is there an element-free proof that preimages of radical ideals are radical?,,"Suppose we have a ring homomorphism $\phi:A\rightarrow B$ and an ideal $J\subseteq B$ . I just spent way too much time on an exercise in commutative algebra, because the element-free definition of the radical of $J$ as $$\sqrt{J} = \bigcap \limits_{q\in \operatorname{Spec}B, J\subseteq q} q$$ suggested to me that there might be a discrepancy between $$\phi^{-1}(\sqrt{J}) = \bigcap \limits_{q \in \operatorname{Spec} B, J \subseteq q} \phi^{-1}(q)$$ and $$\sqrt{\phi^{-1}(J)} = \bigcap \limits_{p\in \operatorname{Spec} A, \phi^{-1}(J)\subseteq p} p$$ (the latter intersection appears to be smaller in total) But using the element-wise definition of a radical in terms of powers one can deduce that both sets always coincide! So I am wondering, whether I should have noticed it somehow while working with the element-free definition…","Suppose we have a ring homomorphism and an ideal . I just spent way too much time on an exercise in commutative algebra, because the element-free definition of the radical of as suggested to me that there might be a discrepancy between and (the latter intersection appears to be smaller in total) But using the element-wise definition of a radical in terms of powers one can deduce that both sets always coincide! So I am wondering, whether I should have noticed it somehow while working with the element-free definition…","\phi:A\rightarrow B J\subseteq B J \sqrt{J} = \bigcap \limits_{q\in \operatorname{Spec}B, J\subseteq q} q \phi^{-1}(\sqrt{J}) = \bigcap \limits_{q \in \operatorname{Spec} B, J \subseteq q} \phi^{-1}(q) \sqrt{\phi^{-1}(J)} = \bigcap \limits_{p\in \operatorname{Spec} A, \phi^{-1}(J)\subseteq p} p","['abstract-algebra', 'commutative-algebra', 'ideals', 'radicals']"
36,"$c_n=a^n-b^n$, $S=\{c_1,c_2,...\}$ is finite then $0 \in S$",",  is finite then","c_n=a^n-b^n S=\{c_1,c_2,...\} 0 \in S","Statement: Let $  (R,+,\cdot)  $ be a ring that has at least two invertible elements. Let $a,b$ be two invertible elements such that $$ord(a)=ord(b)=+\infty$$ Let consider the following sequence $$c_n=a^n-b^n$$ Let $S=\{c_1,c_2,...,c_m,...\}$ a set of elements from $R$ . Prove that if $S=\{c_1,c_2,...\}$ is finite then $$0 \in S$$ Attempt: I obtained that: $$a^n-b^n=c_n$$ then $$a^{n+1}-ab^n=ac_n$$ and $$a^{n+1}-b^{n+1}=c_{n+1}$$ then $$(b-a)b^{n}=ac_n-c_{n+1}$$ Since $S$ is finite then $$M=\{ac_n-c_{n+1},n \in \mathbb Z_+\}$$ is finite. So $$\{(b-a)b^n,n \in \mathbb Z_+\}$$ is finite. Then there exists $i$ and $j$ such that $$(b-a)b^i=(b-a)b^j$$ How should I continue with this. I would highly appreciate somebody's help.",Statement: Let be a ring that has at least two invertible elements. Let be two invertible elements such that Let consider the following sequence Let a set of elements from . Prove that if is finite then Attempt: I obtained that: then and then Since is finite then is finite. So is finite. Then there exists and such that How should I continue with this. I would highly appreciate somebody's help.,"  (R,+,\cdot)   a,b ord(a)=ord(b)=+\infty c_n=a^n-b^n S=\{c_1,c_2,...,c_m,...\} R S=\{c_1,c_2,...\} 0 \in S a^n-b^n=c_n a^{n+1}-ab^n=ac_n a^{n+1}-b^{n+1}=c_{n+1} (b-a)b^{n}=ac_n-c_{n+1} S M=\{ac_n-c_{n+1},n \in \mathbb Z_+\} \{(b-a)b^n,n \in \mathbb Z_+\} i j (b-a)b^i=(b-a)b^j","['abstract-algebra', 'ring-theory']"
37,Quotient of the Galois group of a splitting field generated by two roots,Quotient of the Galois group of a splitting field generated by two roots,,"Let $f \in \mathbb{Q}[x]$ be irreducible of degree $p$ , where $p$ is a prime. Let $K$ be the splitting field of $f$ and suppose that there are roots $\alpha$ and $\beta$ of $f$ such that $K = \mathbb{Q}(\alpha,\beta)$ . We regard the Galois group $G = G(K/\mathbb{Q})$ as a subgroup of the symmetric group $S_p$ . It is not hard to show that $p$ divides the order of $G$ and $G$ contains a $p$ -cycle $\sigma$ . Let $H$ the group generated by $\sigma$ , one can use Sylow's third theorem to argue that $H$ is normal in $G$ . Now, I'd like to show that $G/H$ is a cyclic group of order diving $p-1$ . I'm trying to use results from cyclic extension but it is required that the base field contains the $n$ -th roots of unity, which is not true in this case. Any help would be appreciated.","Let be irreducible of degree , where is a prime. Let be the splitting field of and suppose that there are roots and of such that . We regard the Galois group as a subgroup of the symmetric group . It is not hard to show that divides the order of and contains a -cycle . Let the group generated by , one can use Sylow's third theorem to argue that is normal in . Now, I'd like to show that is a cyclic group of order diving . I'm trying to use results from cyclic extension but it is required that the base field contains the -th roots of unity, which is not true in this case. Any help would be appreciated.","f \in \mathbb{Q}[x] p p K f \alpha \beta f K = \mathbb{Q}(\alpha,\beta) G = G(K/\mathbb{Q}) S_p p G G p \sigma H \sigma H G G/H p-1 n","['abstract-algebra', 'group-theory', 'galois-theory', 'sylow-theory']"
38,"Connections between the different characterizations of ideals? (Dedekind's ideal numbers, quotientable subsets, kernels)","Connections between the different characterizations of ideals? (Dedekind's ideal numbers, quotientable subsets, kernels)",,"Two answers here present two very different approaches to motivating ideals. The first presents the historical motivation for ideals, namely Kummer's idea that in some rings like $\mathbb Z[\sqrt{-5}]$ there are somehow ""ideal numbers"" that allow us to factor products like $2 \cdot 3 = 6 = (1+\sqrt{-5})(1-\sqrt{-5})$ further, and more importantly, uniquely. The second presents the completely abstract construction of an ideal $I$ of ring $R$ to be exactly a subset that $a \sim b \iff a-b\in I$ is an equivalence relation s.t. $R/{\sim}$ inherits the ring structure of $R$ ; or as that answer put it, ""Equations in $R$ give corresponding equations between equivalence classes in $R/{\sim}$ "". An answer here phrased this quotient idea as ""You can think of ideals as subsets that behave similarly to zero"". Again in Intuition behind ""ideal"" , Qiaochu Yuan says ""To me ideals are kernels of ring homomorphisms"". This point of view is very connected to the quotient point of view presented above, essentially by the 1st isomorphism theorem . It also makes rigorous the above idea that ""ideals are subsets that behave similarly to zero"", since kernels are literally the set of elements that get mapped to $0$ by a ring homomorphism. My question is how to connect this latter, more ""abstract"" point of view with the historical/Kummer-Dedekind point of view? I don't really have a good intuition/picture for why the set of all elements ""divisible by some (ideal) number"" should be exactly a subset of elements $S$ s.t. we can ""do exactly the same kind of arithmetic"" with cosets $\{r+S\}_{r\in R}$ as we can with elements $\{r\}_{r\in R}$ .","Two answers here present two very different approaches to motivating ideals. The first presents the historical motivation for ideals, namely Kummer's idea that in some rings like there are somehow ""ideal numbers"" that allow us to factor products like further, and more importantly, uniquely. The second presents the completely abstract construction of an ideal of ring to be exactly a subset that is an equivalence relation s.t. inherits the ring structure of ; or as that answer put it, ""Equations in give corresponding equations between equivalence classes in "". An answer here phrased this quotient idea as ""You can think of ideals as subsets that behave similarly to zero"". Again in Intuition behind ""ideal"" , Qiaochu Yuan says ""To me ideals are kernels of ring homomorphisms"". This point of view is very connected to the quotient point of view presented above, essentially by the 1st isomorphism theorem . It also makes rigorous the above idea that ""ideals are subsets that behave similarly to zero"", since kernels are literally the set of elements that get mapped to by a ring homomorphism. My question is how to connect this latter, more ""abstract"" point of view with the historical/Kummer-Dedekind point of view? I don't really have a good intuition/picture for why the set of all elements ""divisible by some (ideal) number"" should be exactly a subset of elements s.t. we can ""do exactly the same kind of arithmetic"" with cosets as we can with elements .",\mathbb Z[\sqrt{-5}] 2 \cdot 3 = 6 = (1+\sqrt{-5})(1-\sqrt{-5}) I R a \sim b \iff a-b\in I R/{\sim} R R R/{\sim} 0 S \{r+S\}_{r\in R} \{r\}_{r\in R},"['abstract-algebra', 'ring-theory', 'algebraic-number-theory', 'ideals', 'intuition']"
39,What is a twisted symmetric group?,What is a twisted symmetric group?,,"I am trying to calculate the total number of subgroups for each subgroup in $S_5$ . I am working on subgroups of order $6$ . From this website , I have stumbled upon a subgroup called ""twisted $S_3$ "". I understand its generating set of a representative subgroup in the context of $S_5$ : it is a $3$ -cycle in $S_5$ , and a double transposition constructed through selecting two elements in the $3$ -cycle and two elements not in the $3$ -cycle (hence why there are $\frac{{5 \choose 2}2!}{2}\frac{{3 \choose 2}1!}{3}\frac{{2 \choose 2}1!}{1}= 10$ elements). What is the twisted symmetric group in general, though?","I am trying to calculate the total number of subgroups for each subgroup in . I am working on subgroups of order . From this website , I have stumbled upon a subgroup called ""twisted "". I understand its generating set of a representative subgroup in the context of : it is a -cycle in , and a double transposition constructed through selecting two elements in the -cycle and two elements not in the -cycle (hence why there are elements). What is the twisted symmetric group in general, though?",S_5 6 S_3 S_5 3 S_5 3 3 \frac{{5 \choose 2}2!}{2}\frac{{3 \choose 2}1!}{3}\frac{{2 \choose 2}1!}{1}= 10,"['abstract-algebra', 'group-theory']"
40,"If $a^2 = b^2$ in a field, then $a = b$ or $a = -b$","If  in a field, then  or",a^2 = b^2 a = b a = -b,"I'm trying to prove that if $a^2 = b^2$ in a field , then $a = b$ or $a = -b$ I know that a field is a commutative, division ring by definition. Hence if $a^2 = b^2$ in a field, then we have $a^2 - b^2 = 0$ where we can say $a^2 - b^2 = (a - b)(a+b)$ because $$(a-b)(a+b) = a^2 +ab - ba - b^2 = a^2 - b^2$$ where $ab = ba$ by commutativity. Hence we can say that $(a - b)(a + b) = 0$ , which is only true if $a - b = 0$ or $a + b = 0$ . If the first is true, then $a = b$ and if the second is true $a = -b$ . Hence proved. Is this the correct approach?","I'm trying to prove that if in a field , then or I know that a field is a commutative, division ring by definition. Hence if in a field, then we have where we can say because where by commutativity. Hence we can say that , which is only true if or . If the first is true, then and if the second is true . Hence proved. Is this the correct approach?",a^2 = b^2 a = b a = -b a^2 = b^2 a^2 - b^2 = 0 a^2 - b^2 = (a - b)(a+b) (a-b)(a+b) = a^2 +ab - ba - b^2 = a^2 - b^2 ab = ba (a - b)(a + b) = 0 a - b = 0 a + b = 0 a = b a = -b,"['abstract-algebra', 'ring-theory', 'field-theory']"
41,Categories of modules and the correct “language”,Categories of modules and the correct “language”,,"Let $R$ be a ring, two $R$ -modules are said to be isomorphic if there exists a linear bijective map between the modules. But the first assumption is the two modules are over the same ring. Is it possible to generalize the term of isomorphic modules into the next case? Let $S$ ( $S\ncong R$ ) be a ring, $M$ be a $R$ module, and $N$ be a $S$ module; if $M$ is isomorphic as groups to $N$ , then of course $M$ heirs a structure of a $S$ module and $N$ heirs a structure of a $R$ module. But although $S\ncong R$ , is it possible to think of $M\cong N$ as modules in some categories? For example, if $M=\Bbb{C}[x,y] \big /\langle x^2+y^2-1 \rangle$ is a $R=\Bbb{C}[x+y]$ module, of course $M\cong \Bbb{C}[x,x^{-1}]$ as groups (moreover as rings but it doesn’t matter), is it true now to think of $M$ as a $\Bbb{C}[x+x^{-1}]$ module?, if not, are there some categories such that $M\cong \Bbb{C}[x,x^{-1}]$ as modules?","Let be a ring, two -modules are said to be isomorphic if there exists a linear bijective map between the modules. But the first assumption is the two modules are over the same ring. Is it possible to generalize the term of isomorphic modules into the next case? Let ( ) be a ring, be a module, and be a module; if is isomorphic as groups to , then of course heirs a structure of a module and heirs a structure of a module. But although , is it possible to think of as modules in some categories? For example, if is a module, of course as groups (moreover as rings but it doesn’t matter), is it true now to think of as a module?, if not, are there some categories such that as modules?","R R S S\ncong R M R N S M N M S N R S\ncong R M\cong N M=\Bbb{C}[x,y] \big /\langle x^2+y^2-1 \rangle R=\Bbb{C}[x+y] M\cong \Bbb{C}[x,x^{-1}] M \Bbb{C}[x+x^{-1}] M\cong \Bbb{C}[x,x^{-1}]","['abstract-algebra', 'category-theory']"
42,Relation between the dimensions of the fixed point and the submodule given by the augmentation ideal,Relation between the dimensions of the fixed point and the submodule given by the augmentation ideal,,"Let $k$ be a field with characteristic $p>0$ , let $G$ be a finite $p$ -group of order $n=p^m$ , and let $W$ be a (left) $k[G]$ -module such that the $\dim_k(W)=n$ . If we denote by $I$ the augmentation ideal of $k[G]$ , then we can consider $IW$ and $W^G$ , two $k$ -submodules of $W$ . My question is: Are $\dim_k(W/IW)$ and $\dim_k(W^G)$ equal? Or, if not equal, at least related? My attempts: I have found some specific example that can emerge in number theory (so with Galois extension of $p$ -adic fields) where this works, but the methods are not easily generalisable. In the general case, my first try was to look if $W^G$ and $IW$ are in direct sum, and their sum gives all $W$ , but this is not true: the trace of $x\in W$ is both in $IW$ and $W^G$ , and not necessarily zero. Maybe something cohomological? Something like $W^G=H^0(k[G],W)$ and $W/W=H_0(k[G],W)$ (we are extending the usual group cohomology in the category of (left) $k[G]$ -modules, for example taking the functors Ext and Tor). But even in the classical case, where we take $Z[G]$ instead of $k[G]$ , the result does not hold. (It holds, for example, if $W$ is induced). In general, I did not find useful sequences involving both homology and cohomology (except for the sequence with Tate groups). So I am out of ideas... Remark: if we need this, we can assume that $W=M/PM$ , where $M$ is an $R$ -module, for $R$ a dvr with residue field $R/P=k$ , and that $\dim_k(W^G)=1$ . In this case, it should be true that $\dim_k(W/IW)=1$ , but I cannot see why also in this easier case.","Let be a field with characteristic , let be a finite -group of order , and let be a (left) -module such that the . If we denote by the augmentation ideal of , then we can consider and , two -submodules of . My question is: Are and equal? Or, if not equal, at least related? My attempts: I have found some specific example that can emerge in number theory (so with Galois extension of -adic fields) where this works, but the methods are not easily generalisable. In the general case, my first try was to look if and are in direct sum, and their sum gives all , but this is not true: the trace of is both in and , and not necessarily zero. Maybe something cohomological? Something like and (we are extending the usual group cohomology in the category of (left) -modules, for example taking the functors Ext and Tor). But even in the classical case, where we take instead of , the result does not hold. (It holds, for example, if is induced). In general, I did not find useful sequences involving both homology and cohomology (except for the sequence with Tate groups). So I am out of ideas... Remark: if we need this, we can assume that , where is an -module, for a dvr with residue field , and that . In this case, it should be true that , but I cannot see why also in this easier case.","k p>0 G p n=p^m W k[G] \dim_k(W)=n I k[G] IW W^G k W \dim_k(W/IW) \dim_k(W^G) p W^G IW W x\in W IW W^G W^G=H^0(k[G],W) W/W=H_0(k[G],W) k[G] Z[G] k[G] W W=M/PM M R R R/P=k \dim_k(W^G)=1 \dim_k(W/IW)=1","['abstract-algebra', 'number-theory', 'modules', 'algebraic-number-theory', 'noncommutative-algebra']"
43,Induced $\frak{g}$-action on exterior power and symmetric power?,Induced -action on exterior power and symmetric power?,\frak{g},"What to show . Let $\frak{g}$ be a Lie algebra and $V$ a $\frak{g}$ -representation. I am supposed to show that for $r \geq 0$ there exists a unique action of $\frak{g}$ on the exterior power $\bigwedge ^r V$ such that  the canonical projection $V^{\otimes r} \rightarrow \bigwedge ^r V$ is a $\frak{g}$ -intertwiner. Here, we consider the tensor product of representations on the left-hand side. Afterwards, I am asked to show the above statement, where the exterior power is replaced by the symmetric power $S^rV$ . What I think . Consider the exterior power. Uniqueness seems easy: The canonical projection is supposed to be a $\frak{g}$ -intertwiner. This forces us to define on equivalence classes of homogenous tensors $x.[v_1 \otimes ... \otimes v_r] := [x. (v_1 \otimes ... \otimes v_r)]$ for $x \in \frak{g}$ . As homogenous tensors span $V^{\otimes r}$ there image under the canonical projection spans $\bigwedge ^r V$ . Hence, the above definition determines the action uniquely. What remains to show is that this map is well-defined, and indeed gives a $\frak{g}$ -action. That is where I am struggling. I have no experience in working with exterior powers. I don’t know what relations I can use. Questions . Any hints? Are well-definedness and the two action properties (bilinearity and the “Lie algebra action property”) the only thing left to show? Many thanks!","What to show . Let be a Lie algebra and a -representation. I am supposed to show that for there exists a unique action of on the exterior power such that  the canonical projection is a -intertwiner. Here, we consider the tensor product of representations on the left-hand side. Afterwards, I am asked to show the above statement, where the exterior power is replaced by the symmetric power . What I think . Consider the exterior power. Uniqueness seems easy: The canonical projection is supposed to be a -intertwiner. This forces us to define on equivalence classes of homogenous tensors for . As homogenous tensors span there image under the canonical projection spans . Hence, the above definition determines the action uniquely. What remains to show is that this map is well-defined, and indeed gives a -action. That is where I am struggling. I have no experience in working with exterior powers. I don’t know what relations I can use. Questions . Any hints? Are well-definedness and the two action properties (bilinearity and the “Lie algebra action property”) the only thing left to show? Many thanks!",\frak{g} V \frak{g} r \geq 0 \frak{g} \bigwedge ^r V V^{\otimes r} \rightarrow \bigwedge ^r V \frak{g} S^rV \frak{g} x.[v_1 \otimes ... \otimes v_r] := [x. (v_1 \otimes ... \otimes v_r)] x \in \frak{g} V^{\otimes r} \bigwedge ^r V \frak{g},"['abstract-algebra', 'representation-theory', 'lie-algebras', 'tensor-products', 'exterior-algebra']"
44,"Since the radical of the ideal $I=(x, y^2)$ in $\mathbb{Q}[x, y]$ is $(x, y)$, then $I$ is a primary ideal that is not a power of a prime ideal.","Since the radical of the ideal  in  is , then  is a primary ideal that is not a power of a prime ideal.","I=(x, y^2) \mathbb{Q}[x, y] (x, y) I","I've been doing the exercises from Section 9.1 of Dummit and Foote and got stuck on the following problem: Show that the radical of the ideal $I=(x, y^2)$ in $\mathbb{Q}[x, y]$ is $(x, y)$ . Deduce that $I$ is a primary ideal that is not a power of a prime ideal. I've done the first part of this exercise, including proving that $I$ is a primary ideal, but I'm not sure why I can deduce from that that $I$ is not a power of a prime ideal. I'm aware that this same exercise has been posted here before, but the OP was stuck on the first part of the problem, which I think I was able to solve. My work so far can be seen below (which I would appreciate if someone could verify): Any element in $(x, y)$ is of the form $f(x, y)=xg(x, y)+yh(x, y)$ , so that $$f^2(x, y)=x^2g^2(x, y)+y^2h^2(x, y)+2xyg(x, y)h(x, y)=x[xg^2(x, y)+2yg(x, y)h(x, y)]+y^2[h^2(x, y)]$$ and, in particular, $f \in \sqrt{(x, y^2)}$ . Conversely, if $f \in \sqrt{(x, y^2)}$ , then $f^n \in (x, y^2)$ for some $n$ . If $f$ had a constant term $c \neq 0$ , then $f^n$ would have $c^n \neq 0$ as its constant term, a contradiction. Hence, $f$ has no constant term, so $f \in (x, y)$ . Thus, $\sqrt{(x, y^2)}=(x, y)$ . To show that $I$ is primary, let $fg \in (x, y^2)$ with $f \not\in (x, y^2)$ . The polynomial $g(x, y)$ then can't have constant term different than zero, because that would mean $fg$ has either a constant term different than zero (in the case $f$ also has such a term) or a term of the form $ay$ for $a \in \mathbb{Q}$ . Hence, $g \in (x, y)$ , so $g^2 \in (x, y^2)$ . With that, I'm not sure why I can conclude that $I$ isn't a power of a prime ideal. I know that the fact that $I$ is primary implies $\sqrt{(x, y^2)}=(x, y)$ is prime, but not sure how to proceed from here. I would particularly appreciate if someone could give me a hint or provide an answer that doesn't use results that come after Section 9.1 of D&F.","I've been doing the exercises from Section 9.1 of Dummit and Foote and got stuck on the following problem: Show that the radical of the ideal in is . Deduce that is a primary ideal that is not a power of a prime ideal. I've done the first part of this exercise, including proving that is a primary ideal, but I'm not sure why I can deduce from that that is not a power of a prime ideal. I'm aware that this same exercise has been posted here before, but the OP was stuck on the first part of the problem, which I think I was able to solve. My work so far can be seen below (which I would appreciate if someone could verify): Any element in is of the form , so that and, in particular, . Conversely, if , then for some . If had a constant term , then would have as its constant term, a contradiction. Hence, has no constant term, so . Thus, . To show that is primary, let with . The polynomial then can't have constant term different than zero, because that would mean has either a constant term different than zero (in the case also has such a term) or a term of the form for . Hence, , so . With that, I'm not sure why I can conclude that isn't a power of a prime ideal. I know that the fact that is primary implies is prime, but not sure how to proceed from here. I would particularly appreciate if someone could give me a hint or provide an answer that doesn't use results that come after Section 9.1 of D&F.","I=(x, y^2) \mathbb{Q}[x, y] (x, y) I I I (x, y) f(x, y)=xg(x, y)+yh(x, y) f^2(x, y)=x^2g^2(x, y)+y^2h^2(x, y)+2xyg(x, y)h(x, y)=x[xg^2(x, y)+2yg(x, y)h(x, y)]+y^2[h^2(x, y)] f \in \sqrt{(x, y^2)} f \in \sqrt{(x, y^2)} f^n \in (x, y^2) n f c \neq 0 f^n c^n \neq 0 f f \in (x, y) \sqrt{(x, y^2)}=(x, y) I fg \in (x, y^2) f \not\in (x, y^2) g(x, y) fg f ay a \in \mathbb{Q} g \in (x, y) g^2 \in (x, y^2) I I \sqrt{(x, y^2)}=(x, y)",['abstract-algebra']
45,Let $|G| = 20$ and $G$ has only two elements of order $4$. Then $G$ is cyclic,Let  and  has only two elements of order . Then  is cyclic,|G| = 20 G 4 G,"Let $|G| = 20$ and $G$ has only two elements of order $4$ . Then $ G$ is cyclic. I was trying to prove this assertion and I was given some hints also. But firstly I don't know about sylow theorems yet. Definition: Let $G$ be a group and $|G|=p^n.q$ , where $(p,q)=1$ . Then every subgroup of order $p^n$ is called sylow $p$ -subgroup. Theorem (Sylow's III): If $N_p$ is the number of sylow $p$ - subgroup of a finite group $G$ ( $|G|= p^n.q$ , where $(p,q)=1$ ). Then $N_p = 1+kp$ , where $k>=0$ and $N_p$ divide $q$ . $( N_p\mid q)$ . Theorem: If there exists only one sylow $p$ -subgroup for each prime $p$ , which divides $|G|$ . Then $G$ is direct product of those sylow $p$ -subgroup. My Attempt : Using these theorems I got to the point to prove that there's only one sylow $5$ -subgroup and it is of order $5$ . Again, for sylow $2$ -subgroups : $$ N_2 = (1+2k)\mid 5$$ Therefore, $k = 0$ or, $2$ If $k=2$ , then there's only $5$ subgroups of order 4 say $H_1,H_2,H_3,H_4,H_5$ . Now, given that there's only two elements of order 4. Let, $|a|=4=|b|$ Then, $\langle a\rangle=\langle b\rangle $ otherwise resulting two more distinct elements $a^3,b^3$ of order 4. Now here I came to a dead end. I know that if I can prove that $k=2$ results in contradiction then my proof is done. But I can't find any ways from here. Any suggestions?","Let and has only two elements of order . Then is cyclic. I was trying to prove this assertion and I was given some hints also. But firstly I don't know about sylow theorems yet. Definition: Let be a group and , where . Then every subgroup of order is called sylow -subgroup. Theorem (Sylow's III): If is the number of sylow - subgroup of a finite group ( , where ). Then , where and divide . . Theorem: If there exists only one sylow -subgroup for each prime , which divides . Then is direct product of those sylow -subgroup. My Attempt : Using these theorems I got to the point to prove that there's only one sylow -subgroup and it is of order . Again, for sylow -subgroups : Therefore, or, If , then there's only subgroups of order 4 say . Now, given that there's only two elements of order 4. Let, Then, otherwise resulting two more distinct elements of order 4. Now here I came to a dead end. I know that if I can prove that results in contradiction then my proof is done. But I can't find any ways from here. Any suggestions?","|G| = 20 G 4  G G |G|=p^n.q (p,q)=1 p^n p N_p p G |G|= p^n.q (p,q)=1 N_p = 1+kp k>=0 N_p q ( N_p\mid q) p p |G| G p 5 5 2  N_2 = (1+2k)\mid 5 k = 0 2 k=2 5 H_1,H_2,H_3,H_4,H_5 |a|=4=|b| \langle a\rangle=\langle b\rangle  a^3,b^3 k=2","['abstract-algebra', 'group-theory', 'finite-groups', 'cyclic-groups', 'sylow-theory']"
46,Maximal ideal with given condition,Maximal ideal with given condition,,"I am reading the proof by B. Banaschewski of ""Krull implies Zorn."" I am having difficulties filling in the details in one of the steps. We start with a partition $\mathfrak U$ of an arbitrary set $E$ . A subset $X$ of $E$ is called spread if $X\cap C$ has at most one element for each $C\in\mathfrak U$ . Let $\mathfrak S$ be the set of all spreads. We consider the ring $R=\mathbb Q[E]$ of polynomials with elements of $E$ as indeterminates. Set $T=\bigcup_{X\in\mathfrak S}\langle X\rangle_R$ and $U=R-T$ , where $\langle X\rangle_R$ denotes the smallest ideal in $R$ containing $X$ . One may prove that $U$ is closed under multiplication. (Since it hasn't been used elsewhere, this information may be important for the answer of my subsequent question.) Next, let $R_0=R\left[\frac 1 u\mid u\in U\right]$ , which has a maximal ideal $M$ under assumption of Krull's Theorem. Let $H=M\cap R$ . Clearly, $H$ is an ideal of $R$ which is contained in $T$ . Apparently, $H$ is maximal (with respect to inclusion) as such. More precisely, if $I\supseteq H$ is an ideal of $R$ which is contained in $T$ , then $I=H$ . I'm having difficulties to see why $H$ is maximal. My idea was to pick an ideal $I\supsetneq H$ of $R$ , and to prove that some $u\in U$ belongs to $I$ .","I am reading the proof by B. Banaschewski of ""Krull implies Zorn."" I am having difficulties filling in the details in one of the steps. We start with a partition of an arbitrary set . A subset of is called spread if has at most one element for each . Let be the set of all spreads. We consider the ring of polynomials with elements of as indeterminates. Set and , where denotes the smallest ideal in containing . One may prove that is closed under multiplication. (Since it hasn't been used elsewhere, this information may be important for the answer of my subsequent question.) Next, let , which has a maximal ideal under assumption of Krull's Theorem. Let . Clearly, is an ideal of which is contained in . Apparently, is maximal (with respect to inclusion) as such. More precisely, if is an ideal of which is contained in , then . I'm having difficulties to see why is maximal. My idea was to pick an ideal of , and to prove that some belongs to .",\mathfrak U E X E X\cap C C\in\mathfrak U \mathfrak S R=\mathbb Q[E] E T=\bigcup_{X\in\mathfrak S}\langle X\rangle_R U=R-T \langle X\rangle_R R X U R_0=R\left[\frac 1 u\mid u\in U\right] M H=M\cap R H R T H I\supseteq H R T I=H H I\supsetneq H R u\in U I,"['abstract-algebra', 'ring-theory', 'ideals']"
47,how Bisimulations correspond to internal equality on the final coalgebra?,how Bisimulations correspond to internal equality on the final coalgebra?,,"From the paper ""Towards a mathematical operational semantics"" by Turi & Plotkin LICS (1997), in Definition 4.1,  I read : The greatest $B$ -bisimulation $\sim$ is the terminal span over two $B$ -coalgebras. Right after the $\textit{internal equality}$ of a $B$ -coalgebra $(X,\alpha)$ is defined as the kernel pair over the identity $id_X$ on the carrier $X$ . I am assuming that means the pullback $X \times_X X$ over $X$ along the identity $id_X$ . In Set , when bisimilarity is defined over the terminal $B$ -coalgebra, say streams over labels $L$ ( $L^\omega$ ), this coincides with equality (over streams). This is an easy proof. However, for a generic endofunctor $B$ and from the categorical definitions of bisimilarity and equality I cannot seem to be able to prove it. The paper does not seem to introduce any useful assumption at this point. Any suggestions?","From the paper ""Towards a mathematical operational semantics"" by Turi & Plotkin LICS (1997), in Definition 4.1,  I read : The greatest -bisimulation is the terminal span over two -coalgebras. Right after the of a -coalgebra is defined as the kernel pair over the identity on the carrier . I am assuming that means the pullback over along the identity . In Set , when bisimilarity is defined over the terminal -coalgebra, say streams over labels ( ), this coincides with equality (over streams). This is an easy proof. However, for a generic endofunctor and from the categorical definitions of bisimilarity and equality I cannot seem to be able to prove it. The paper does not seem to introduce any useful assumption at this point. Any suggestions?","B \sim B \textit{internal equality} B (X,\alpha) id_X X X \times_X X X id_X B L L^\omega B","['abstract-algebra', 'category-theory', 'computer-science']"
48,Module of differentials of an extension of Dedekind domains is cyclic,Module of differentials of an extension of Dedekind domains is cyclic,,"Let 𝐴 be a Dedekind domain with fraction field 𝐾, 𝐿|𝐾 a finite separable field extension and 𝐵 the integral closure of 𝐴 in 𝐿. Assume that all the residue field extensions are separable. In the proof of Serre's ""Local Fields"", chapter III, Proposition 14 (page 59), it is stated that in order to show that the module of differentials $Ω_{𝐵|𝐴}$ is cyclic we can assume that 𝐴 is local and complete. (See this question. ) I understand the reduction to the local case, but I don't understand the reduction to the complete case. I tried to use that the canonical map from $A_p$ to its $p$ -adic completion is faithfully flat but I didn't arrive to the desired conclusion. In particular, I don't understand why, if $Ω_{𝐵'/𝐴'}$ is cyclic with with annihilator the different ideal of B' over A' [where A' and B' denote the $p$ -adic completion of the DVRs A and B respectively], then $Ω_{𝐵/𝐴}$ is cyclic with annihilator the different ideal of B over A. Can you give me some details? Thank you very much.","Let 𝐴 be a Dedekind domain with fraction field 𝐾, 𝐿|𝐾 a finite separable field extension and 𝐵 the integral closure of 𝐴 in 𝐿. Assume that all the residue field extensions are separable. In the proof of Serre's ""Local Fields"", chapter III, Proposition 14 (page 59), it is stated that in order to show that the module of differentials is cyclic we can assume that 𝐴 is local and complete. (See this question. ) I understand the reduction to the local case, but I don't understand the reduction to the complete case. I tried to use that the canonical map from to its -adic completion is faithfully flat but I didn't arrive to the desired conclusion. In particular, I don't understand why, if is cyclic with with annihilator the different ideal of B' over A' [where A' and B' denote the -adic completion of the DVRs A and B respectively], then is cyclic with annihilator the different ideal of B over A. Can you give me some details? Thank you very much.",Ω_{𝐵|𝐴} A_p p Ω_{𝐵'/𝐴'} p Ω_{𝐵/𝐴},"['abstract-algebra', 'number-theory', 'algebraic-number-theory', 'dedekind-domain']"
49,Show that $a$ and $b$ have no greatest common divisor in $\mathbb{Z}[\sqrt-5]$,Show that  and  have no greatest common divisor in,a b \mathbb{Z}[\sqrt-5],"Show that in the ring $R=\mathbb{Z}[\sqrt{-5}]$ , $a=3\cdot 7 \cdot(1+2\sqrt{-5})$ and $b=(1+2\sqrt{-5})\cdot 7\cdot(1+2\sqrt{-5})$ have no greatest common divisor. Since $N(a)=3^3\cdot 7^3$ and $N(b)=3^2\cdot 7^4$ so it is clear that any common divisor of $a$ and $b$ must have norm dividing $3^2\cdot 7^3$ . Now we will get many possibilities. Am I on right track or there is some other smart way to solve this problem?","Show that in the ring , and have no greatest common divisor. Since and so it is clear that any common divisor of and must have norm dividing . Now we will get many possibilities. Am I on right track or there is some other smart way to solve this problem?",R=\mathbb{Z}[\sqrt{-5}] a=3\cdot 7 \cdot(1+2\sqrt{-5}) b=(1+2\sqrt{-5})\cdot 7\cdot(1+2\sqrt{-5}) N(a)=3^3\cdot 7^3 N(b)=3^2\cdot 7^4 a b 3^2\cdot 7^3,"['abstract-algebra', 'ring-theory']"
50,"Localizing C[x,y]/(xy) to get a direct product of Laurent polynomials.","Localizing C[x,y]/(xy) to get a direct product of Laurent polynomials.",,"I am trying to show $$\left(\mathbb C[x,y]/(xy)\right)_{x+y}\cong \mathbb C[x^{\pm 1}] \times \mathbb C[y^{\pm 1}].$$ In class, my professor did the example $$\left(\mathbb C[x,y]/(xy)\right)_{x} \cong \mathbb C[x^{\pm 1}]$$ by using the fact that $A_f \cong A[t]/(tf - 1)$ for a commutative ring $A$ . I am trying to mimic this approach. I get that $$\left(\mathbb C[x,y]/(xy)\right)_{x+y} \cong \left(\mathbb C[x,y]/(xy)\right)[t]/(t(x+y)-1)$$ $$=\mathbb C[x,y,t]/(xy, t(x+y) - 1).$$ I am not really sure how to simplify this quotient to get what I need. I would really appreciate any help! Thanks.","I am trying to show In class, my professor did the example by using the fact that for a commutative ring . I am trying to mimic this approach. I get that I am not really sure how to simplify this quotient to get what I need. I would really appreciate any help! Thanks.","\left(\mathbb C[x,y]/(xy)\right)_{x+y}\cong \mathbb C[x^{\pm 1}] \times \mathbb C[y^{\pm 1}]. \left(\mathbb C[x,y]/(xy)\right)_{x} \cong \mathbb C[x^{\pm 1}] A_f \cong A[t]/(tf - 1) A \left(\mathbb C[x,y]/(xy)\right)_{x+y} \cong \left(\mathbb C[x,y]/(xy)\right)[t]/(t(x+y)-1) =\mathbb C[x,y,t]/(xy, t(x+y) - 1).","['abstract-algebra', 'ring-theory', 'commutative-algebra']"
51,When do intermediate fields being Galois imply entire extension is Galois?,When do intermediate fields being Galois imply entire extension is Galois?,,"Let $k \subset K$ be Galois. The Fundamental Theorem of Galois Theory gives us a criteria for when any intermediate field $k \subset E \subset K$ is Galois over our base field $k$ . Also, it is in general not true that if $k \subset E$ and $E \subset K$ are both Galois, then $k \subset K$ will be Galois. For example, take $k = \mathbb{Q}, E = \mathbb{Q}[\sqrt{2}]$ , and $K = \mathbb{Q}[\sqrt[4]{2}]$ . However, are there any minimal restrictions we can put on on the extensions $k \subset E \subset K$ such that when $E$ is Galois over $k$ and $K$ is Galois over $E$ that guarantees us $K$ being Galois over $k$ ?","Let be Galois. The Fundamental Theorem of Galois Theory gives us a criteria for when any intermediate field is Galois over our base field . Also, it is in general not true that if and are both Galois, then will be Galois. For example, take , and . However, are there any minimal restrictions we can put on on the extensions such that when is Galois over and is Galois over that guarantees us being Galois over ?","k \subset K k \subset E \subset K k k \subset E E \subset K k \subset K k = \mathbb{Q}, E = \mathbb{Q}[\sqrt{2}] K = \mathbb{Q}[\sqrt[4]{2}] k \subset E \subset K E k K E K k","['abstract-algebra', 'galois-theory']"
52,Does a finitely generated faithful module over an Artinian ring contain a regular element?,Does a finitely generated faithful module over an Artinian ring contain a regular element?,,"In the text Nicholson -- Introduction to Abstract Algebra, 4th Ed (2012) the claim of exercise $8(b)$ of exercise set $11.1$ is: If $R$ is a left artinian ring with $1\ne 0$ , and $M$ is a finitely generated left $R$ -module such that $\text{ann}(M)=0$ , then $M$ has a submodule isomorphic to $R$ . But in my answer to $\;\;\;\;\;$ How to show $\operatorname{ann}(M) = \operatorname{ann}(X)$. I gave a counterexample to the above claim. I wonder if the claim could be repaired by assuming as an additional hypothesis that $R$ is commutative. Question: If $R$ is a commutative artinian ring with $1\ne 0$ , and $M$ is a finitely generated $R$ -module such that $\text{ann}(M)=0$ , must $M$ have a submodule isomorphic to $R$ ? Two special cases: The answer is ""yes"" if $R$ is a field. $\\[4pt]$ $R$ is finite. That's as far as I've got.","In the text Nicholson -- Introduction to Abstract Algebra, 4th Ed (2012) the claim of exercise of exercise set is: If is a left artinian ring with , and is a finitely generated left -module such that , then has a submodule isomorphic to . But in my answer to How to show $\operatorname{ann}(M) = \operatorname{ann}(X)$. I gave a counterexample to the above claim. I wonder if the claim could be repaired by assuming as an additional hypothesis that is commutative. Question: If is a commutative artinian ring with , and is a finitely generated -module such that , must have a submodule isomorphic to ? Two special cases: The answer is ""yes"" if is a field. is finite. That's as far as I've got.",8(b) 11.1 R 1\ne 0 M R \text{ann}(M)=0 M R \;\;\;\;\; R R 1\ne 0 M R \text{ann}(M)=0 M R R \\[4pt] R,"['abstract-algebra', 'commutative-algebra', 'modules', 'noncommutative-algebra', 'artinian']"
53,Showing that every automorphism of $S_3$ is a conjugation without using the orders of the elements,Showing that every automorphism of  is a conjugation without using the orders of the elements,S_3,"I'd like to demonstrate that every automorphism of $S_3$ is a conjugation but without looking at the order of the elements. My attempt is the following : I've already proved that there is an injective homomorphism $f : Aut(S_3) \hookrightarrow S_3$ and also that the conjugation map $Ad$ is an automorphism. Now let's consider $g : S_3 \longrightarrow Aut(S_3)$ such as $g(\sigma) = Ad(\sigma)$ . It is easy to prove that $g$ is an injective homomorphism. Let $\psi$ be in $Aut(S_3)$ and $\sigma$ be in $S_3$ . Thus we have : $$g \circ f : Aut(S3) \hookrightarrow S_3 \hookrightarrow Aut(S_3)$$ $$ (g \circ f)(\psi) = g(\sigma) = Ad(\sigma)$$ Because of the two injections, we can deduce that $S_3 \cong Aut(S_3)$ and thus $g \circ f$ is an automorphism. I think it also proves that there is as much elements in $Aut(S_3)$ than conjugations by the elements of $S_3$ . Therefore, as the set of conjugations by the elements of $S_3$ is a subset of $Aut(S_3)$ we can deduce that every automorphism of $S_3$ is a conjugation. I'm not quite sure about what I said. Could you please help me ? Thanks a lot.","I'd like to demonstrate that every automorphism of is a conjugation but without looking at the order of the elements. My attempt is the following : I've already proved that there is an injective homomorphism and also that the conjugation map is an automorphism. Now let's consider such as . It is easy to prove that is an injective homomorphism. Let be in and be in . Thus we have : Because of the two injections, we can deduce that and thus is an automorphism. I think it also proves that there is as much elements in than conjugations by the elements of . Therefore, as the set of conjugations by the elements of is a subset of we can deduce that every automorphism of is a conjugation. I'm not quite sure about what I said. Could you please help me ? Thanks a lot.",S_3 f : Aut(S_3) \hookrightarrow S_3 Ad g : S_3 \longrightarrow Aut(S_3) g(\sigma) = Ad(\sigma) g \psi Aut(S_3) \sigma S_3 g \circ f : Aut(S3) \hookrightarrow S_3 \hookrightarrow Aut(S_3)  (g \circ f)(\psi) = g(\sigma) = Ad(\sigma) S_3 \cong Aut(S_3) g \circ f Aut(S_3) S_3 S_3 Aut(S_3) S_3,"['abstract-algebra', 'group-theory', 'permutations', 'group-homomorphism', 'automorphism-group']"
54,"What is a Gauge symmetry, intuitively (string theory)?","What is a Gauge symmetry, intuitively (string theory)?",,"I'm writing an essay for a popular (but mathematically mature) audience on the history of mathematical physics, wherein I have a section devoted to string theory. Unfortunately, neither I (nor my audience) have the background to understand the material, however (remaining in theme with the rest of the paper) I'd like to present something substantial and quantitative (i.e. be able to present some sort of hands-on mathematical concept(s)). While I lack the necessary foundations (I've followed the traditional undergraduate Calculus sequence, and have some number theory and group theory) I feel that I have the mathematical maturity to understand the concepts. I keep coming across these vague references to ""symmetries"" and ""Gauge symmetries"", and the notation $SU(n)$ . In my extensive search, I've come across only very advanced/terse material, or very watered down and vague material (which is to be expected, I suppose). What are ""symmetries"" and ""Gauge symmetries""? What is this notation (which I've seen extensively even in popular books for the general population, without much explanation): $SU(n)$ ? Why are these symmetries important (particularly as they relate to string theory?).","I'm writing an essay for a popular (but mathematically mature) audience on the history of mathematical physics, wherein I have a section devoted to string theory. Unfortunately, neither I (nor my audience) have the background to understand the material, however (remaining in theme with the rest of the paper) I'd like to present something substantial and quantitative (i.e. be able to present some sort of hands-on mathematical concept(s)). While I lack the necessary foundations (I've followed the traditional undergraduate Calculus sequence, and have some number theory and group theory) I feel that I have the mathematical maturity to understand the concepts. I keep coming across these vague references to ""symmetries"" and ""Gauge symmetries"", and the notation . In my extensive search, I've come across only very advanced/terse material, or very watered down and vague material (which is to be expected, I suppose). What are ""symmetries"" and ""Gauge symmetries""? What is this notation (which I've seen extensively even in popular books for the general population, without much explanation): ? Why are these symmetries important (particularly as they relate to string theory?).",SU(n) SU(n),"['abstract-algebra', 'mathematical-physics', 'gauge-theory', 'string-theory']"
55,Characterization of a virtually nilpotent group,Characterization of a virtually nilpotent group,,Let $G$ be a group that has an increasing sequence of subgroups $G_i \le G_{i+1}$ satisfying the following properties. (a) $G=\bigcup_{i\ge 1} G_i$ . (b) Each $G_i$ contains a nilpotent subgroup $N_i$ such that $[G_i:N_i] \le k$ for some constant $k$ independent of $i$ . Can we find a nilpotent subgroup $N \le G$ such that $[G:N]<\infty$ ?,Let be a group that has an increasing sequence of subgroups satisfying the following properties. (a) . (b) Each contains a nilpotent subgroup such that for some constant independent of . Can we find a nilpotent subgroup such that ?,G G_i \le G_{i+1} G=\bigcup_{i\ge 1} G_i G_i N_i [G_i:N_i] \le k k i N \le G [G:N]<\infty,"['abstract-algebra', 'group-theory', 'nilpotent-groups']"
56,Defining an automorphism of $G/N$ using the automorphism defined on $G$.,Defining an automorphism of  using the automorphism defined on .,G/N G,"This is a problem from Herstein and I do know that there is a similar question uploaded already, but I felt something strange with some assumptions of the question: ""Let $G$ be a group, and $T$ be an automorphism of $G$ . If $N$ is a normal subgroup of $G$ such that $T(N) \subset N$ , then show how you could use $T$ to define an automorphism of $G/N$ .""  I have just tried the most natural mapping $\phi : G/N \to G/N$ defined by $\phi(gN) = T(g)N$ , and succeeded in showing that $\phi$ is in fact a well-defined onto homomorphism. What is left is, to show that, $\phi$ is injective. I felt that if $T(N) =N$ was the case, then $\phi$ is clearly an automorphism. But in general, $T(N) \neq N$ unless $G$ is finite(or with more lenient case, $[G:N] <\infty$ . If $[G:N]$ was finite, I could have just make use of pigeonhole principle so that $\phi$ is the desired mapping.) I wonder if there is any other method to show that $\phi$ is injective, or we could have defined another new mapping, or the question has failed to add the finiteness of $G$ (or $[G:N]$ ). Any helps or comments will be appreciated. Thanks!","This is a problem from Herstein and I do know that there is a similar question uploaded already, but I felt something strange with some assumptions of the question: ""Let be a group, and be an automorphism of . If is a normal subgroup of such that , then show how you could use to define an automorphism of .""  I have just tried the most natural mapping defined by , and succeeded in showing that is in fact a well-defined onto homomorphism. What is left is, to show that, is injective. I felt that if was the case, then is clearly an automorphism. But in general, unless is finite(or with more lenient case, . If was finite, I could have just make use of pigeonhole principle so that is the desired mapping.) I wonder if there is any other method to show that is injective, or we could have defined another new mapping, or the question has failed to add the finiteness of (or ). Any helps or comments will be appreciated. Thanks!",G T G N G T(N) \subset N T G/N \phi : G/N \to G/N \phi(gN) = T(g)N \phi \phi T(N) =N \phi T(N) \neq N G [G:N] <\infty [G:N] \phi \phi G [G:N],"['abstract-algebra', 'group-isomorphism', 'automorphism-group']"
57,Technicality in proof of $\binom{m+n}{l} = \sum_{k=0}^l \binom{m}{k}\binom{n}{l-k}$,Technicality in proof of,\binom{m+n}{l} = \sum_{k=0}^l \binom{m}{k}\binom{n}{l-k},"This is from Analysis I by Herbert Amann, Joachim Escher. I want to make sure I understand everything correctly, so I'm sorry if this seems nitpicky. After introducing formal power series $R[X]$ (functions in $R^{\mathbb{N}}$ ) of a ring $R$ with unity and polynomials as a subring of $R[X]$ , there is a proof of the identity $$\binom{m+n}{l} = \sum_{k=0}^l \binom{m}{k}\binom{n}{l-k},\quad l,m,n\in\mathbb N$$ as an application of $R[X]$ being a ring. Let $X$ denote the polynomial with $x_1=1$ and $x_i=0$ for $i\neq 1$ . Their proof is as follows: Since $X$ and $1\in R[X]$ commute, we can use the binomial theorem for rings to compute $$(1+X)^j=\sum_{i=0}^j\binom{j}{i}X^i,\quad j\in\mathbb{N}.$$ Now we compute the two sides of $(1+X)^m(1+X)^n=(1+X)^{m+n}$ . We have $$\begin{align}(1+X)^m(1+X)^n &= \left(\sum_{k=0}^m\binom{m}{k}X^k\right)\left(\sum_{j=0}^n\binom{n}{j}X^j\right)\\ &=\sum_l\left( \sum_{k=0}^l\binom{m}{k}\binom{n}{l-k} \right)X^l\end{align}\tag{A}$$ where the second equality is the definition of multiplication of polynomials. Also $$(1+X)^{m+n}=\sum_{l=0}^{m+n}\binom{m+n}{l}X^l.\tag{B}$$ Comparing coefficients in (A) and (B) gives the identity. My issue is that the binomial coefficients which lie in $\mathbb N$ are not technically the coefficients of the polynomial, which lie in $R$ . Given $r\in R$ and $n\in\mathbb N$ , $n\cdot r$ is the $n$ -fold sum of $r$ . So, for example, isn't the $l$ th coefficient of the polynomial in (B) really $\binom{m+n}{l}\cdot 1_R$ ? Then the proof is really asserting that $$\binom{m+n}{l}\cdot 1_R = \sum_{k=0}^l \binom{m}{k}\binom{n}{l-k}\cdot 1_R$$ for any ring $R$ . If my understanding is correct so far, I think letting $R=\mathbb Z$ recovers the original identity since $n\cdot 1_{\mathbb Z}=n$ . It's just that the integers haven't been introduced yet.","This is from Analysis I by Herbert Amann, Joachim Escher. I want to make sure I understand everything correctly, so I'm sorry if this seems nitpicky. After introducing formal power series (functions in ) of a ring with unity and polynomials as a subring of , there is a proof of the identity as an application of being a ring. Let denote the polynomial with and for . Their proof is as follows: Since and commute, we can use the binomial theorem for rings to compute Now we compute the two sides of . We have where the second equality is the definition of multiplication of polynomials. Also Comparing coefficients in (A) and (B) gives the identity. My issue is that the binomial coefficients which lie in are not technically the coefficients of the polynomial, which lie in . Given and , is the -fold sum of . So, for example, isn't the th coefficient of the polynomial in (B) really ? Then the proof is really asserting that for any ring . If my understanding is correct so far, I think letting recovers the original identity since . It's just that the integers haven't been introduced yet.","R[X] R^{\mathbb{N}} R R[X] \binom{m+n}{l} = \sum_{k=0}^l \binom{m}{k}\binom{n}{l-k},\quad l,m,n\in\mathbb N R[X] X x_1=1 x_i=0 i\neq 1 X 1\in R[X] (1+X)^j=\sum_{i=0}^j\binom{j}{i}X^i,\quad j\in\mathbb{N}. (1+X)^m(1+X)^n=(1+X)^{m+n} \begin{align}(1+X)^m(1+X)^n &= \left(\sum_{k=0}^m\binom{m}{k}X^k\right)\left(\sum_{j=0}^n\binom{n}{j}X^j\right)\\
&=\sum_l\left( \sum_{k=0}^l\binom{m}{k}\binom{n}{l-k} \right)X^l\end{align}\tag{A} (1+X)^{m+n}=\sum_{l=0}^{m+n}\binom{m+n}{l}X^l.\tag{B} \mathbb N R r\in R n\in\mathbb N n\cdot r n r l \binom{m+n}{l}\cdot 1_R \binom{m+n}{l}\cdot 1_R = \sum_{k=0}^l \binom{m}{k}\binom{n}{l-k}\cdot 1_R R R=\mathbb Z n\cdot 1_{\mathbb Z}=n","['abstract-algebra', 'ring-theory', 'binomial-coefficients']"
58,Invariant $SU(3)$ subgroup for ${\bf 8}$ in ${\bf 3}^* \otimes {\bf 3} ={\bf 1} \oplus {\bf 8}$,Invariant  subgroup for  in,SU(3) {\bf 8} {\bf 3}^* \otimes {\bf 3} ={\bf 1} \oplus {\bf 8},"This question concerns finding an invariant subgroup of a total group $G$ . Warm-Up Toy Example (which I already solved) : Let us take $G=SU(2)$ as a special unitary group. Let us take $$u \text{ as }  {\bf 2} \text{ of } G=SU(2)$$ has the fundamental representation ${\bf 2}$ (two complex components) of $G=SU(2)$ . There is also the complex conjugate representation $u^*$ , but in this case, ${\bf 2}^*={\bf 2}$ still. Now we can combine two fundamental representations to form $$ {\bf 2} \otimes {\bf 2} = {\bf 2}^* \otimes {\bf 2} ={\bf 1} \oplus {\bf 3}. $$ Where $$ {\bf 2} \otimes {\bf 2} = {\bf 2}^* \otimes {\bf 2} =u^{*T} (n^j \sigma^j) u. $$ Again $*$ is complex conjugation, and $T$ is the transpose. with $\sigma^j$ of $j=0,1,2,3$ and https://en.wikipedia.org/wiki/Pauli_matrices $$ \sigma^0=\begin{pmatrix}       1&0\\       0&1     \end{pmatrix}, \sigma^1=\begin{pmatrix}       0&1\\       1&0     \end{pmatrix}, \sigma^2=\begin{pmatrix}       0&-i\\       i&0     \end{pmatrix}, \sigma^3=\begin{pmatrix}       1 &0\\       0 &-1     \end{pmatrix}. $$ So for a fix $j$ , $u^{*T} (n^j \sigma^j) u$ outputs a scalar number. Here we can define a scalar (for some coefficient $n^0$ ) $$ {\bf 1} \text{ as } V^0 := u^{*T} (n^0 \sigma^0) u $$ and a 3-vector  (for some coefficient $n^1,n^2,n^3$ ) $$ {\bf 3} \text{ as } V^j := \Big( u^{*T} (n^1 \sigma^1) u, \quad u^{*T} (n^2 \sigma^2) u, \quad u^{*T} (n^3 \sigma^3) u\Big) $$ (warm-up 1) If we choose to look at ${\bf 1}$ as $V^0$ with a fixed $n^0$ coefficient, we can ask: What are the subgroup of $SU(2)$ which acts on $u \mapsto u'=\exp(i \theta^a \sigma^a) u$ makes the ${\bf 1}$ as $V^0:= u^{*T} (n^0 \sigma^0) u$ invariant? Answer : The full $SU(2)$ makes $V^0$ invariant. Since under $SU(2)$ transformation: $$V^0:= u^{*T} (n^0 \sigma^0) u  \mapsto {V^0}'= {u'}^{*T} (n^0 ) u' = u^{*T} \exp(-i \theta^a \sigma^a)  (n^0 \sigma^0) \exp(i \theta^a \sigma^a) u  = u^{*T}   (n^0 ) u = V^0$$ for arbitrary $\theta^j$ , thus the full $SU(2)$ . In short, there is a fibration structure: $$ \text{stablizer $\hookrightarrow$ total $G$ $\to$ orbit}. $$ From the $SU(2)$ view: $$ SU(2)\hookrightarrow SU(2) \to pt $$ (warm-up 2) If we choose to look at ${\bf 3}$ as $V^j$ with a fixed coefficient $n^1,n^2,n^3$ coefficient, we can ask: What are the subgroup of $SU(2)$ which acts on $u \mapsto u'=\exp(i \theta^a \sigma^a) u$ makes the ${\bf 3}$ as $V^j := \big(u^{*T} (n^j \sigma^j) u\big)$ with $j=1,2,3$ invariant? Answer : Only the $U(1)$ subgroup of $SU(2)$ makes $V^j$ invariant. Since under $SU(2)$ transformation: $$V^j:= u^{*T} (n^j \sigma^j) u  \mapsto {V^j}'= {u'}^{*T} (n^j \sigma^j) u' = u^{*T} \exp(-i \theta^a \sigma^a)  (n^j \sigma^j) \exp(i \theta^a \sigma^a) u.  $$ The $V^j$ is a 3-vector on an $S^2$ sphere. while the $SU(2)$ acts on $u$ becomes effectively as $SO(3)$ acts on $V^j$ on the $S^2$ sphere. With a fixed coefficient $n^1,n^2,n^3$ coefficient, only when the $SO(3)$ subgroup that makes the $V^j$ 3-vector on an $S^2$ sphere invariant would be the desired subgroup, which is the $U(1)$ subgroup. In short, there is a fibration structure: $$ \text{stablizer $\hookrightarrow$ total $G$ $\to$ orbit}. $$ From the $SO(3)$ view: $$ U(1)\hookrightarrow SO(3) \to S^2 $$ From the $SU(2)$ view: $$ Spin(2)\hookrightarrow SU(2) \to S^2 $$ such that $Spin(2)/\mathbb{Z}_2=U(1)$ . Serious Puzzle : Let us take $G=SU(3)$ as a special unitary group. Let us take $$u \text{ as }  {\bf 3} \text{ of } G=SU(3)$$ has the fundamental representation ${\bf 3}$ (three complex components) of $G=SU(3)$ . There is also the complex conjugate representation $u^*$ , but in this case, ${\bf 3}^*$ which is distinct from ${\bf 3}$ . Now we can combine two fundamental representations to form $$ {\bf 3}^* \otimes {\bf 3} ={\bf 1} \oplus {\bf 8}. $$ We can take $$ {\bf 3}^* \otimes {\bf 3} =u^{*T} (n^j \lambda_j) u. $$ with the https://en.wikipedia.org/wiki/Gell-Mann_matrices : $\lambda_0 = \begin{pmatrix}   1 & 0 & 0 \\  0 &1  & 0 \\ 0 & 0 & 1 \end{pmatrix}$ , $\lambda_1 = \begin{pmatrix} 0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix}$ , $\lambda_2 = \begin{pmatrix} 0 & -i & 0 \\ i & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix}$ , $\lambda_3 = \begin{pmatrix} 1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 0 \end{pmatrix}$ , $\lambda_4 = \begin{pmatrix} 0 & 0 & 1 \\ 0 & 0 & 0 \\ 1 & 0 & 0 \end{pmatrix}$ , $\lambda_5 = \begin{pmatrix} 0 & 0 & -i \\ 0 & 0 & 0 \\ i & 0 & 0 \end{pmatrix}$ , $\lambda_6 = \begin{pmatrix} 0 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & 1 & 0 \end{pmatrix}$ , $\lambda_7 = \begin{pmatrix} 0 & 0 & 0 \\ 0 & 0 & -i \\ 0 & i & 0 \end{pmatrix}$ , $\lambda_8 = \frac{1}{\sqrt{3}} \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & -2 \end{pmatrix}$ with $j=1,2,3, \dots, 8$ (warm-up 3) If we choose to look at ${\bf 1}$ as $V^0$ with a fixed $n^0$ coefficient, we can ask: What are the subgroup of $SU(3)$ which acts on $u \mapsto u'=\exp(i \theta^a \lambda_a) u$ makes the ${\bf 1}$ as $V^0:= u^{*T} (n^0 \lambda_0) u$ invariant? The answer shall be the full $SU(3)$ . (FINALY NOW Puzzle)If we choose to look at ${\bf 8}$ as $V^j$ with a fixed coefficient $n^1,n^2,n^3,\dots, n^8$ coefficient, we can ask: What are the subgroup of $SU(3)$ which acts on $u \mapsto u'=\exp(i \theta^a \lambda_a) u$ makes the ${\bf 8}$ as $V^j := \big(u^{*T} (n^j \lambda_j) u\big)$ with $j=1,2,3, \dots, 8$ invariant?","This question concerns finding an invariant subgroup of a total group . Warm-Up Toy Example (which I already solved) : Let us take as a special unitary group. Let us take has the fundamental representation (two complex components) of . There is also the complex conjugate representation , but in this case, still. Now we can combine two fundamental representations to form Where Again is complex conjugation, and is the transpose. with of and https://en.wikipedia.org/wiki/Pauli_matrices So for a fix , outputs a scalar number. Here we can define a scalar (for some coefficient ) and a 3-vector  (for some coefficient ) (warm-up 1) If we choose to look at as with a fixed coefficient, we can ask: What are the subgroup of which acts on makes the as invariant? Answer : The full makes invariant. Since under transformation: for arbitrary , thus the full . In short, there is a fibration structure: From the view: (warm-up 2) If we choose to look at as with a fixed coefficient coefficient, we can ask: What are the subgroup of which acts on makes the as with invariant? Answer : Only the subgroup of makes invariant. Since under transformation: The is a 3-vector on an sphere. while the acts on becomes effectively as acts on on the sphere. With a fixed coefficient coefficient, only when the subgroup that makes the 3-vector on an sphere invariant would be the desired subgroup, which is the subgroup. In short, there is a fibration structure: From the view: From the view: such that . Serious Puzzle : Let us take as a special unitary group. Let us take has the fundamental representation (three complex components) of . There is also the complex conjugate representation , but in this case, which is distinct from . Now we can combine two fundamental representations to form We can take with the https://en.wikipedia.org/wiki/Gell-Mann_matrices : , , , , , , , , with (warm-up 3) If we choose to look at as with a fixed coefficient, we can ask: What are the subgroup of which acts on makes the as invariant? The answer shall be the full . (FINALY NOW Puzzle)If we choose to look at as with a fixed coefficient coefficient, we can ask: What are the subgroup of which acts on makes the as with invariant?","G G=SU(2) u \text{ as } 
{\bf 2} \text{ of } G=SU(2) {\bf 2} G=SU(2) u^* {\bf 2}^*={\bf 2} 
{\bf 2} \otimes {\bf 2} = {\bf 2}^*
\otimes {\bf 2} ={\bf 1} \oplus {\bf 3}.
 
{\bf 2} \otimes {\bf 2} = {\bf 2}^*
\otimes {\bf 2} =u^{*T} (n^j \sigma^j) u.
 * T \sigma^j j=0,1,2,3 
\sigma^0=\begin{pmatrix}
      1&0\\
      0&1
    \end{pmatrix},
\sigma^1=\begin{pmatrix}
      0&1\\
      1&0
    \end{pmatrix},
\sigma^2=\begin{pmatrix}
      0&-i\\
      i&0
    \end{pmatrix},
\sigma^3=\begin{pmatrix}
      1 &0\\
      0 &-1
    \end{pmatrix}.
 j u^{*T} (n^j \sigma^j) u n^0 
{\bf 1} \text{ as } V^0 := u^{*T} (n^0 \sigma^0) u
 n^1,n^2,n^3 
{\bf 3} \text{ as } V^j := \Big( u^{*T} (n^1 \sigma^1) u, \quad u^{*T} (n^2 \sigma^2) u, \quad u^{*T} (n^3 \sigma^3) u\Big)
 {\bf 1} V^0 n^0 SU(2) u \mapsto u'=\exp(i \theta^a \sigma^a) u {\bf 1} V^0:= u^{*T} (n^0 \sigma^0) u SU(2) V^0 SU(2) V^0:= u^{*T} (n^0 \sigma^0) u  \mapsto
{V^0}'=
{u'}^{*T} (n^0 ) u' = u^{*T} \exp(-i \theta^a \sigma^a) 
(n^0 \sigma^0) \exp(i \theta^a \sigma^a) u 
=
u^{*T}  
(n^0 ) u = V^0 \theta^j SU(2) 
\text{stablizer \hookrightarrow total G \to orbit}.
 SU(2) 
SU(2)\hookrightarrow SU(2) \to pt
 {\bf 3} V^j n^1,n^2,n^3 SU(2) u \mapsto u'=\exp(i \theta^a \sigma^a) u {\bf 3} V^j := \big(u^{*T} (n^j \sigma^j) u\big) j=1,2,3 U(1) SU(2) V^j SU(2) V^j:= u^{*T} (n^j \sigma^j) u  \mapsto
{V^j}'=
{u'}^{*T} (n^j \sigma^j) u' = u^{*T} \exp(-i \theta^a \sigma^a) 
(n^j \sigma^j) \exp(i \theta^a \sigma^a) u. 
 V^j S^2 SU(2) u SO(3) V^j S^2 n^1,n^2,n^3 SO(3) V^j S^2 U(1) 
\text{stablizer \hookrightarrow total G \to orbit}.
 SO(3) 
U(1)\hookrightarrow SO(3) \to S^2
 SU(2) 
Spin(2)\hookrightarrow SU(2) \to S^2
 Spin(2)/\mathbb{Z}_2=U(1) G=SU(3) u \text{ as } 
{\bf 3} \text{ of } G=SU(3) {\bf 3} G=SU(3) u^* {\bf 3}^* {\bf 3} 
{\bf 3}^* \otimes {\bf 3} ={\bf 1} \oplus {\bf 8}.
 
{\bf 3}^*
\otimes {\bf 3} =u^{*T} (n^j \lambda_j) u.
 \lambda_0 = \begin{pmatrix}   1 & 0 & 0 \\  0 &1  & 0 \\ 0 & 0 & 1 \end{pmatrix} \lambda_1 = \begin{pmatrix} 0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix} \lambda_2 = \begin{pmatrix} 0 & -i & 0 \\ i & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix} \lambda_3 = \begin{pmatrix} 1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 0 \end{pmatrix} \lambda_4 = \begin{pmatrix} 0 & 0 & 1 \\ 0 & 0 & 0 \\ 1 & 0 & 0 \end{pmatrix} \lambda_5 = \begin{pmatrix} 0 & 0 & -i \\ 0 & 0 & 0 \\ i & 0 & 0 \end{pmatrix} \lambda_6 = \begin{pmatrix} 0 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & 1 & 0 \end{pmatrix} \lambda_7 = \begin{pmatrix} 0 & 0 & 0 \\ 0 & 0 & -i \\ 0 & i & 0 \end{pmatrix} \lambda_8 = \frac{1}{\sqrt{3}} \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & -2 \end{pmatrix} j=1,2,3, \dots, 8 {\bf 1} V^0 n^0 SU(3) u \mapsto u'=\exp(i \theta^a \lambda_a) u {\bf 1} V^0:= u^{*T} (n^0 \lambda_0) u SU(3) {\bf 8} V^j n^1,n^2,n^3,\dots, n^8 SU(3) u \mapsto u'=\exp(i \theta^a \lambda_a) u {\bf 8} V^j := \big(u^{*T} (n^j \lambda_j) u\big) j=1,2,3, \dots, 8","['abstract-algebra', 'differential-geometry', 'representation-theory', 'lie-groups', 'invariant-theory']"
59,"$G$-modules, Group invariants and Tor functor","-modules, Group invariants and Tor functor",G,"Let $M$ be a $G$ -module. Then functoriality induces a natural $G$ -module structure on $\text{Tor}_i(M,N)$ , where $N$ is any abelian group. My question is, what can we say about $$\text{Tor}_i(M,N)^G.$$ Is there some way to discribe this using $M^G$ ? For example, if we assume that $M=\mathbb{Z}/n$ , then $$\text{Tor}_1(\mathbb{Z}/n,N)^G=\left(N[n]\right)^G=\left(N^G\right)[n]=N[n]=\text{Tor}_1(\mathbb{Z}/n,N).$$ I'm most interested in ""nice"" criteria for the vanishing of $\text{Tor}_i(M,N)^G.$","Let be a -module. Then functoriality induces a natural -module structure on , where is any abelian group. My question is, what can we say about Is there some way to discribe this using ? For example, if we assume that , then I'm most interested in ""nice"" criteria for the vanishing of","M G G \text{Tor}_i(M,N) N \text{Tor}_i(M,N)^G. M^G M=\mathbb{Z}/n \text{Tor}_1(\mathbb{Z}/n,N)^G=\left(N[n]\right)^G=\left(N^G\right)[n]=N[n]=\text{Tor}_1(\mathbb{Z}/n,N). \text{Tor}_i(M,N)^G.","['abstract-algebra', 'group-cohomology', 'derived-functors']"
60,"Computation of $\mathrm{Ext}_R(R[x^{-1}],M)$",Computation of,"\mathrm{Ext}_R(R[x^{-1}],M)","Let $x$ be an element of a commutative ring $R$ . It seems that the following statements are true: Let us write $R[x^{-1}]$ as the direct limit $$R[x^{-1}]\simeq \varinjlim(R\xrightarrow{x} R\cdots ).$$ Let $M$ be an $R$ -module. Let $TM$ denote the tower $$( \cdots \rightarrow M \xrightarrow{x} M \xrightarrow{x} M). $$ Then $$\mathrm{Ext}^1_R(R[x^{-1}],M) \simeq {\lim}^1 TM$$ For $i\ge 2$ , we have $$ \mathrm{Ext}^i_R(R[x^{-1}],M) \simeq 0 $$ How does one prove each of these statements? For the 2nd point I wonder if there is a simple projective resolution.","Let be an element of a commutative ring . It seems that the following statements are true: Let us write as the direct limit Let be an -module. Let denote the tower Then For , we have How does one prove each of these statements? For the 2nd point I wonder if there is a simple projective resolution.","x R R[x^{-1}] R[x^{-1}]\simeq \varinjlim(R\xrightarrow{x} R\cdots ). M R TM ( \cdots \rightarrow M \xrightarrow{x} M \xrightarrow{x} M).  \mathrm{Ext}^1_R(R[x^{-1}],M) \simeq {\lim}^1 TM i\ge 2  \mathrm{Ext}^i_R(R[x^{-1}],M) \simeq 0 ","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'modules', 'homological-algebra']"
61,The quotient of a quotient group by another quotient group,The quotient of a quotient group by another quotient group,,"Let $G$ , $M$ , and $N$ be the cyclic groups given by $$ G \colon= \left\langle  a \colon  a^{12} = e  \right\rangle = \left\{  e = a^0, a, a^2, \ldots, a^{11}  \right\}, $$ $$ M \colon= \left\langle a^2 \right\rangle = \left\{  e, a^2, a^4, a^6, a^8, a^{10}  \right\}, $$ and $$ N \colon= \left\langle a^6 \right\rangle = \left\{  e, a^6  \right\}. $$ Then of course $M$ is a normal subgroup of $G$ , and of course $N$ is a normal subgroup of both $G$ and $M$ . Thus the quotient groups $G/M$ , $G/N$ , and $M/N$ are well-defined. In fact, we have $$ \begin{align} G/M &= \left\{  M, aM, a^3M, a^5M, a^7M, a^9M, a^{11}M  \right\} \\ &= \left\{ M, aM  \right\} \\ &= \left\{ \, \left\{  e, a^2, a^4, a^6, a^8, a^{10}  \right\}, \, \left\{  a, a^3, a^5, a^7, a^9, a^{11} \right\} \, \right\}, \end{align} $$ $$ \begin{align} G/N &= \left\{  N, aN, a^2N, a^3N, a^4N, a^5N, a^7N, a^8N, a^9N, a^{10}N, a^{11}N  \right\} \\ &= \left\{  N, aN, a^2N, a^3N, a^4N, a^5N  \right\} \\ &= \left\{ \, \left\{ e, a^6 \right\}, \, \left\{ a, a^7 \right\}, \, \left\{ a^2, a^8 \right\}, \, \left\{ a^3, a^9 \right\}, \, \left\{ a^4, a^{10} \right\},  \, \left\{ a^5, a^{11} \right\} \, \right\}, \end{align} $$ and $$ \begin{align} M/N &= \left\{  N, a^2N, a^4N, a^8 N, a^{10}N  \right\} \\ &= \left\{  N, a^2N, a^4 N  \right\} \\ &= \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\}. \end{align} $$ Furthermore, as $M$ is a normal subgroup of $G$ , so the quotient group $M/N$ is a normal subgroup of the quotient group $G/N$ . Therefore we can consider the quotient group $(G/N)/(M/N)$ . Now my question is, is the following construction valid? We first note that $$ \begin{align} \left\{ a, a^7 \right\} (M/N) &= \left\{ a, a^7 \right\} \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\} \\  &= \left\{ \, \left\{ a, a^7 \right\} \left\{ e, a^6 \right\}, \, \left\{ a, a^7 \right\} \left\{  a^2, a^8  \right\}, \, \left\{ a, a^7 \right\} \left\{  a^4, a^{10}  \right\} \, \right\} \\ &= \left\{ \, \left\{ a, a^7 \right\}, \, \left\{ a^3, a^9  \right\}, \,  \left\{ a^5, a^{11} \right\} \, \right\}. \end{align} $$ And also $$ \begin{align} \left\{ a^3, a^9 \right\} (M/N) &= \left\{ a^3, a^9 \right\} \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\} \\  &= \left\{ \, \left\{ a^3, a^9 \right\} \left\{ e, a^6 \right\}, \, \left\{ a^3, a^9 \right\} \left\{  a^2, a^8  \right\}, \, \left\{ a^3, a^9 \right\} \left\{  a^4, a^{10}  \right\} \, \right\} \\ &= \left\{ \, \left\{ a^3, a^9 \right\}, \, \left\{ a^5, a^{11} \right\}, \, \left\{ a, a^7 \right\} \, \right\} \\ &= \left\{ \, \left\{ a, a^7 \right\}, \, \left\{ a^3, a^9 \right\}, \, \left\{ a^5, a^{11} \right\} \, \right\}. \end{align} $$ Thus we have shown that $$  \left\{ a, a^7 \right\} (M/N) = \left\{ a^3, a^9 \right\} (M/N). $$ Similarly we can show that $$  \left\{ a, a^7 \right\} (M/N) = \left\{ a^5, a^{11} \right\} (M/N). $$ Using the calculations above, we find that $$ \begin{align} (G/N)/(M/N) &= \left\{ \ M/N, \ \left\{ a, a^7 \right\} (M/N) , \  \left\{ a^3, a^9 \right\}(M/N), \  \left\{ a^5, a^{11} \right\} (M/N) \ \right\} \\ &= \left\{ \ M/N, \  \left\{ a, a^7 \right\} (M/N)  \ \right\} \\ &= \left\{ \  \left\{ \, \left\{ e, a^6  \right\}, \, \left\{ a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\}, \ \left\{ a, a^7 \right\}  \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \,  \left\{  a^4, a^{10}  \right\} \, \right\} \ \right\} \\ &= \left\{ \  \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \,  \left\{  a^4, a^{10}  \right\} \, \right\}, \  \left\{ \,  \left\{ a, a^7 \right\} \left\{  e, a^6  \right\}, \,  \left\{ a, a^7 \right\} \left\{ a^2, a^8  \right\}, \, \left\{ a, a^7 \right\} \left\{  a^4, a^{10}  \right\} \, \right\}   \ \right\} \\ &= \left\{ \  \left\{ \, \left\{  e, a^6  \right\}, \,  \left\{  a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\},  \   \left\{ \,  \left\{ a, a^7 \right\}, \, \left\{ a^3, a^9 \right\}, \, \left\{ a^5, a^{11} \right\}   \, \right\}  \ \right\}. \end{align} $$ Of course the quotient group $(G/N)/(M/N)$ is isomorphic to the quotient group $G/M$ . Is my construction correct? Is each and every detail of my calculation above correct? Or, have I made any errors or logical / mathematical mistakes? Last but not the leat, is my typesetting logically correct and clear enough as well? Or, is there a better way of presenting the work above?","Let , , and be the cyclic groups given by and Then of course is a normal subgroup of , and of course is a normal subgroup of both and . Thus the quotient groups , , and are well-defined. In fact, we have and Furthermore, as is a normal subgroup of , so the quotient group is a normal subgroup of the quotient group . Therefore we can consider the quotient group . Now my question is, is the following construction valid? We first note that And also Thus we have shown that Similarly we can show that Using the calculations above, we find that Of course the quotient group is isomorphic to the quotient group . Is my construction correct? Is each and every detail of my calculation above correct? Or, have I made any errors or logical / mathematical mistakes? Last but not the leat, is my typesetting logically correct and clear enough as well? Or, is there a better way of presenting the work above?","G M N 
G \colon= \left\langle  a \colon  a^{12} = e  \right\rangle = \left\{  e = a^0, a, a^2, \ldots, a^{11}  \right\},
 
M \colon= \left\langle a^2 \right\rangle = \left\{  e, a^2, a^4, a^6, a^8, a^{10}  \right\},
 
N \colon= \left\langle a^6 \right\rangle = \left\{  e, a^6  \right\}.
 M G N G M G/M G/N M/N 
\begin{align}
G/M &= \left\{  M, aM, a^3M, a^5M, a^7M, a^9M, a^{11}M  \right\} \\
&= \left\{ M, aM  \right\} \\
&= \left\{ \, \left\{  e, a^2, a^4, a^6, a^8, a^{10}  \right\}, \, \left\{  a, a^3, a^5, a^7, a^9, a^{11} \right\} \, \right\},
\end{align}
 
\begin{align}
G/N &= \left\{  N, aN, a^2N, a^3N, a^4N, a^5N, a^7N, a^8N, a^9N, a^{10}N, a^{11}N  \right\} \\
&= \left\{  N, aN, a^2N, a^3N, a^4N, a^5N  \right\} \\
&= \left\{ \, \left\{ e, a^6 \right\}, \, \left\{ a, a^7 \right\}, \, \left\{ a^2, a^8 \right\}, \, \left\{ a^3, a^9 \right\}, \, \left\{ a^4, a^{10} \right\},  \, \left\{ a^5, a^{11} \right\} \, \right\},
\end{align}
 
\begin{align}
M/N &= \left\{  N, a^2N, a^4N, a^8 N, a^{10}N  \right\} \\
&= \left\{  N, a^2N, a^4 N  \right\} \\
&= \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\}.
\end{align}
 M G M/N G/N (G/N)/(M/N) 
\begin{align}
\left\{ a, a^7 \right\} (M/N) &= \left\{ a, a^7 \right\} \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\} \\ 
&= \left\{ \, \left\{ a, a^7 \right\} \left\{ e, a^6 \right\}, \, \left\{ a, a^7 \right\} \left\{  a^2, a^8  \right\}, \, \left\{ a, a^7 \right\} \left\{  a^4, a^{10}  \right\} \, \right\} \\
&= \left\{ \, \left\{ a, a^7 \right\}, \, \left\{ a^3, a^9  \right\}, \,  \left\{ a^5, a^{11} \right\} \, \right\}.
\end{align}
 
\begin{align}
\left\{ a^3, a^9 \right\} (M/N) &= \left\{ a^3, a^9 \right\} \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\} \\ 
&= \left\{ \, \left\{ a^3, a^9 \right\} \left\{ e, a^6 \right\}, \, \left\{ a^3, a^9 \right\} \left\{  a^2, a^8  \right\}, \, \left\{ a^3, a^9 \right\} \left\{  a^4, a^{10}  \right\} \, \right\} \\
&= \left\{ \, \left\{ a^3, a^9 \right\}, \, \left\{ a^5, a^{11} \right\}, \, \left\{ a, a^7 \right\} \, \right\} \\
&= \left\{ \, \left\{ a, a^7 \right\}, \, \left\{ a^3, a^9 \right\}, \, \left\{ a^5, a^{11} \right\} \, \right\}.
\end{align}
  
\left\{ a, a^7 \right\} (M/N) = \left\{ a^3, a^9 \right\} (M/N).
  
\left\{ a, a^7 \right\} (M/N) = \left\{ a^5, a^{11} \right\} (M/N).
 
\begin{align}
(G/N)/(M/N) &= \left\{ \ M/N, \ \left\{ a, a^7 \right\} (M/N) , \  \left\{ a^3, a^9 \right\}(M/N), \  \left\{ a^5, a^{11} \right\} (M/N) \ \right\} \\
&= \left\{ \ M/N, \  \left\{ a, a^7 \right\} (M/N)  \ \right\} \\
&= \left\{ \  \left\{ \, \left\{ e, a^6  \right\}, \, \left\{ a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\}, \ \left\{ a, a^7 \right\}  \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \,  \left\{  a^4, a^{10}  \right\} \, \right\} \ \right\} \\
&= \left\{ \  \left\{ \, \left\{  e, a^6  \right\}, \, \left\{  a^2, a^8  \right\}, \,  \left\{  a^4, a^{10}  \right\} \, \right\}, \  \left\{ \,  \left\{ a, a^7 \right\} \left\{  e, a^6  \right\}, \,  \left\{ a, a^7 \right\} \left\{ a^2, a^8  \right\}, \, \left\{ a, a^7 \right\} \left\{  a^4, a^{10}  \right\} \, \right\}   \ \right\} \\
&= \left\{ \  \left\{ \, \left\{  e, a^6  \right\}, \,  \left\{  a^2, a^8  \right\}, \, \left\{  a^4, a^{10}  \right\} \, \right\},  \   \left\{ \,  \left\{ a, a^7 \right\}, \, \left\{ a^3, a^9 \right\}, \, \left\{ a^5, a^{11} \right\}   \, \right\}  \ \right\}.
\end{align}
 (G/N)/(M/N) G/M","['abstract-algebra', 'group-theory', 'finite-groups', 'normal-subgroups', 'quotient-group']"
62,Confusion on the kernel and image of boundary map in terms of computing simplicial homology.,Confusion on the kernel and image of boundary map in terms of computing simplicial homology.,,"I am learning simplicial homology, and I have a confusion on the computation. I understand that the boundary map  the boundary map $\partial_{n}:C_{n}(X)\longrightarrow C_{n-1}(X)$ takes the form $$\partial\langle V_{0},\cdots, V_{n}\rangle=\sum_{i=0}^{n}(-1)^{i}\langle V_{0},\cdots,\widehat{V}_{i},\cdots, V_{n}\rangle,$$ where $\widehat{V}_{i}$ means you kick out $V_{i}$ coordinate and keep other coordinates and $\langle V_{0},\cdots, V_{n}\rangle$ is the vertices of $n-$ dimensional simplex $\Delta^{n}$ . I also know how to prove that $\partial_{n}\circ \partial_{n+1}=0$ so that you have a chain complex. Then the simplicial homology is defined by $$H_{k}(X)=\ker(\partial_{k})/Im(\partial_{k+1}).$$ However, I don't know how to compute the $\ker$ and $Im$ . For instance, let us take the $2-$ dimensional torus $\mathbb{T}^{2}$ as an example: Consider the well-known triangulation of $\mathbb{T}^{2}$ , see here: Computing the first simplical homology group of the torus $H_1(T)$ We have $9$ copies of $\Delta^{0}$ , $8$ copies of $\Delta^{1}$ and $18$ copies of $\Delta^{2}$ . Thus, $C_{2}(X)=\mathbb{Z}^{18}$ , $C_{1}(X)=\mathbb{Z}^{8}$ and $C_{0}(X)=\mathbb{Z}^{9}$ . Hence, we have chain complex $$C_{2}(X)=\mathbb{Z}^{18}\longrightarrow_{\partial_{2}} C_{1}(X)=\mathbb{Z}^{8}\longrightarrow_{\partial_{1}}C_{0}(X)=\mathbb{Z}^{9}.$$ Now, we compute the $\partial_{2}$ and $\partial_{1}$ , we have $$\partial_{2}\langle V_{0},V_{1},V_{2}\rangle=\langle V_{1},V_{2}\rangle -\langle V_{0}, V_{2}\rangle+\langle V_{1}, V_{2}\rangle$$ and $$\partial_{1}\langle V_{0}, V_{1}\rangle=\langle V_{1}\rangle-\langle V_{0}\rangle.$$ But then, what is the image and kernel of $\partial_{1}$ and $\partial_{2}$ ? Thank you! Edit 1: (Update) As comments pointed out, the group is so large since the simplex is complicated, and thus we need to use sage to compute it. However, the point is that I don't understand how to write down the matrix representation of $\partial_{1}$ and $\partial_{2}$ . Let me reduce this simplex to this: The simplex is from Hatcher's book. Then he argued that: There is one vertex, three edges $a,b,c$ and two $2-$ simplices U and L. Then $\partial_{1}=0$ and $\partial_{2}U=a+b-c=\partial_{2}L$ , and $\{a,b, a+b-c\}$ is a basis for $\Delta_{1}(T)$ , it follows that $H_{1}(T)=\mathbb{Z}\oplus\mathbb{Z}$ . Since there are no $3-$ simplices, $H_{2}(T)=\ker\partial_{2}$ , which is infinite cyclic generated by $U-L$ . I don't understand how he got $\partial_{1}=0$ . Given my computation above, $\partial_{1}\langle V_{0},V_{1}\rangle=\langle V_{1}\rangle-\langle V_{0}\rangle$ why $0$ ? I also don't understand how he saw that $\{a,b,a+b-c\}$ is the basis for $\Delta_{1}(T)$ . Finally, how to compute $\ker\partial_{2}$ ?","I am learning simplicial homology, and I have a confusion on the computation. I understand that the boundary map  the boundary map takes the form where means you kick out coordinate and keep other coordinates and is the vertices of dimensional simplex . I also know how to prove that so that you have a chain complex. Then the simplicial homology is defined by However, I don't know how to compute the and . For instance, let us take the dimensional torus as an example: Consider the well-known triangulation of , see here: Computing the first simplical homology group of the torus $H_1(T)$ We have copies of , copies of and copies of . Thus, , and . Hence, we have chain complex Now, we compute the and , we have and But then, what is the image and kernel of and ? Thank you! Edit 1: (Update) As comments pointed out, the group is so large since the simplex is complicated, and thus we need to use sage to compute it. However, the point is that I don't understand how to write down the matrix representation of and . Let me reduce this simplex to this: The simplex is from Hatcher's book. Then he argued that: There is one vertex, three edges and two simplices U and L. Then and , and is a basis for , it follows that . Since there are no simplices, , which is infinite cyclic generated by . I don't understand how he got . Given my computation above, why ? I also don't understand how he saw that is the basis for . Finally, how to compute ?","\partial_{n}:C_{n}(X)\longrightarrow C_{n-1}(X) \partial\langle V_{0},\cdots, V_{n}\rangle=\sum_{i=0}^{n}(-1)^{i}\langle V_{0},\cdots,\widehat{V}_{i},\cdots, V_{n}\rangle, \widehat{V}_{i} V_{i} \langle V_{0},\cdots, V_{n}\rangle n- \Delta^{n} \partial_{n}\circ \partial_{n+1}=0 H_{k}(X)=\ker(\partial_{k})/Im(\partial_{k+1}). \ker Im 2- \mathbb{T}^{2} \mathbb{T}^{2} 9 \Delta^{0} 8 \Delta^{1} 18 \Delta^{2} C_{2}(X)=\mathbb{Z}^{18} C_{1}(X)=\mathbb{Z}^{8} C_{0}(X)=\mathbb{Z}^{9} C_{2}(X)=\mathbb{Z}^{18}\longrightarrow_{\partial_{2}} C_{1}(X)=\mathbb{Z}^{8}\longrightarrow_{\partial_{1}}C_{0}(X)=\mathbb{Z}^{9}. \partial_{2} \partial_{1} \partial_{2}\langle V_{0},V_{1},V_{2}\rangle=\langle V_{1},V_{2}\rangle -\langle V_{0}, V_{2}\rangle+\langle V_{1}, V_{2}\rangle \partial_{1}\langle V_{0}, V_{1}\rangle=\langle V_{1}\rangle-\langle V_{0}\rangle. \partial_{1} \partial_{2} \partial_{1} \partial_{2} a,b,c 2- \partial_{1}=0 \partial_{2}U=a+b-c=\partial_{2}L \{a,b, a+b-c\} \Delta_{1}(T) H_{1}(T)=\mathbb{Z}\oplus\mathbb{Z} 3- H_{2}(T)=\ker\partial_{2} U-L \partial_{1}=0 \partial_{1}\langle V_{0},V_{1}\rangle=\langle V_{1}\rangle-\langle V_{0}\rangle 0 \{a,b,a+b-c\} \Delta_{1}(T) \ker\partial_{2}","['abstract-algebra', 'algebraic-topology', 'homology-cohomology', 'geometric-topology']"
63,A summary and \or reference to the theory of REAL representation theory,A summary and \or reference to the theory of REAL representation theory,,"In fulton and harris there is a short discussion of real representations which is unsatisfactory to me. In $\mathbb{C}$ we have a great theory- We know how many irreducible representations there are We have a simple relation about their dimensions that in particular bounds the dimensions of irreducible nicely Most importantly, we have characters which are great tools to let us decompose a given representation to irreducible ones. I want to understand what the analogs of those are in $\mathbb{R}$ . Attempt My attempts give 'algorithms' to solve those questions, but I'd prefer formulas if that makes sense (like the number of conjugacy classes, etc). 1/2. We can use Artin Wedderburn and the Frobenius theorem to know the group algebra breaks up to a sum of $M_{n\times n}(D)$ for $D$ one of $\mathbb{R},\mathbb{C},\mathbb{H}$ . That gives us good bounds on the irreducible representations and I guess a 'formula' that instead of just their dimensions and amount, involves $Dim Hom_\mathbb{R}(V,V)$ 3. Suppose you found all complex representations. The cheapest attempt is to say okay to understand a real representation $V$ I'll complexify it to $V'$ . Then if $V = \oplus V_i$ then $V' = \oplus V_i '$ , though the other direction is not true, so I have a technical way to decompose a representation assuming I know the complex ones, by going over all subsets of the summands of the decomposition of $V'$ and see if their sum comes from some $W \otimes \mathbb{C}$ for $W$ a subspace of $V$ . Fulton-Harris gives a criterion to when a represenation is real (complexified of real), but that isn't the same as checking for me if the sum comes from some $W \otimes \mathbb{C}$ , so I don't even understand why this criterion is important. What are more accurate\systematic things one can say or good references?","In fulton and harris there is a short discussion of real representations which is unsatisfactory to me. In we have a great theory- We know how many irreducible representations there are We have a simple relation about their dimensions that in particular bounds the dimensions of irreducible nicely Most importantly, we have characters which are great tools to let us decompose a given representation to irreducible ones. I want to understand what the analogs of those are in . Attempt My attempts give 'algorithms' to solve those questions, but I'd prefer formulas if that makes sense (like the number of conjugacy classes, etc). 1/2. We can use Artin Wedderburn and the Frobenius theorem to know the group algebra breaks up to a sum of for one of . That gives us good bounds on the irreducible representations and I guess a 'formula' that instead of just their dimensions and amount, involves 3. Suppose you found all complex representations. The cheapest attempt is to say okay to understand a real representation I'll complexify it to . Then if then , though the other direction is not true, so I have a technical way to decompose a representation assuming I know the complex ones, by going over all subsets of the summands of the decomposition of and see if their sum comes from some for a subspace of . Fulton-Harris gives a criterion to when a represenation is real (complexified of real), but that isn't the same as checking for me if the sum comes from some , so I don't even understand why this criterion is important. What are more accurate\systematic things one can say or good references?","\mathbb{C} \mathbb{R} M_{n\times n}(D) D \mathbb{R},\mathbb{C},\mathbb{H} Dim Hom_\mathbb{R}(V,V) V V' V = \oplus V_i V' = \oplus V_i ' V' W \otimes \mathbb{C} W V W \otimes \mathbb{C}","['abstract-algebra', 'finite-groups', 'representation-theory']"
64,Difference between a Reduced Residue Class and a Reduced Residue System,Difference between a Reduced Residue Class and a Reduced Residue System,,"Currently studying Dirichlets proof of Primes in arithmetic progressions. Is there a difference between a Reduced Residue Class and a Reduced Residue System? Any subset $R$ of the integers is called a reduced residue system modulo $n$ if: $\gcd(r, n) = 1$ for each $r$ contained in $R$ ; $R$ contains $\phi(n)$ elements; no two elements of $R$ are congruent modulo $n$ . For example, if a reduced residue system for $12$ is $a = \{1,5,7,11\}$ , and we have also $\{13,17,19,23\}$ , would the reduced residue class be the general description of this? e.g all the terms that are equal to the terms in $a \mod 12$ ? Is the reduced residue class the same as the set of all congruence classes?","Currently studying Dirichlets proof of Primes in arithmetic progressions. Is there a difference between a Reduced Residue Class and a Reduced Residue System? Any subset of the integers is called a reduced residue system modulo if: for each contained in ; contains elements; no two elements of are congruent modulo . For example, if a reduced residue system for is , and we have also , would the reduced residue class be the general description of this? e.g all the terms that are equal to the terms in ? Is the reduced residue class the same as the set of all congruence classes?","R n \gcd(r, n) = 1 r R R \phi(n) R n 12 a = \{1,5,7,11\} \{13,17,19,23\} a \mod 12","['abstract-algebra', 'number-theory']"
65,Galois group of residue field extension,Galois group of residue field extension,,"Let $E$ and $K$ be number fields, so that $E/K$ is normal, $G:= \textrm{Gal}(E/K)$ , $\mathcal{O}_E$ and $\mathcal{O}_K$ their respective rings of integers. The theory of Artin $L$ -series relies on the fact that for any prime ideal $\mathfrak{p} \subset \mathcal{O}_K$ , if $\mathfrak{P} \subset \mathcal{O}_E$ is a prime above $\mathfrak{p}$ , and $G_{\mathfrak{P}}$ and $I_{\mathfrak{P}}$ are the corresponding decomposition and inertia subgroups, then we have the following isomorphism: $$ G_{\mathfrak{P}}/I_{\mathfrak{P}} \cong \textrm{Gal}\left( (\mathcal{O}_E/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p}) \right) $$ But is this Galois group even well-defined for all prime ideals? In Proposition 9.4, ch. I, §9, of $\textit{Algebraic Number Theory}$ , Neukirch proves that $(\mathcal{O}_E/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p})$ is normal for any prime $\mathfrak{p} \subset \mathcal{O}_K$ and any choice of $\mathfrak{P} \subset \mathcal{O}_E$ above $\mathfrak{p}$ . He then goes on to show that there is a surjective homomorphism $$G_{\mathfrak{P}} \to \textrm{Gal}\left( (\mathcal{O}_E/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p}) \right)$$ and defines the inertia group to be the kernel of said homomorphism, thereby establishing the aforementioned isomorphism. Now we know that if $\mathfrak{p} \subset \mathcal{O}_K$ is unramified over $\mathcal{O}_E$ , then $(\mathcal{O}_E/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p})$ must be separable. But if $\mathfrak{p}$ ramifies over $\mathcal{O}_E$ , how can we know that the corresponding residue field extension is separable? Thank you for your attention.","Let and be number fields, so that is normal, , and their respective rings of integers. The theory of Artin -series relies on the fact that for any prime ideal , if is a prime above , and and are the corresponding decomposition and inertia subgroups, then we have the following isomorphism: But is this Galois group even well-defined for all prime ideals? In Proposition 9.4, ch. I, §9, of , Neukirch proves that is normal for any prime and any choice of above . He then goes on to show that there is a surjective homomorphism and defines the inertia group to be the kernel of said homomorphism, thereby establishing the aforementioned isomorphism. Now we know that if is unramified over , then must be separable. But if ramifies over , how can we know that the corresponding residue field extension is separable? Thank you for your attention.",E K E/K G:= \textrm{Gal}(E/K) \mathcal{O}_E \mathcal{O}_K L \mathfrak{p} \subset \mathcal{O}_K \mathfrak{P} \subset \mathcal{O}_E \mathfrak{p} G_{\mathfrak{P}} I_{\mathfrak{P}}  G_{\mathfrak{P}}/I_{\mathfrak{P}} \cong \textrm{Gal}\left( (\mathcal{O}_E/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p}) \right)  \textit{Algebraic Number Theory} (\mathcal{O}_E/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p}) \mathfrak{p} \subset \mathcal{O}_K \mathfrak{P} \subset \mathcal{O}_E \mathfrak{p} G_{\mathfrak{P}} \to \textrm{Gal}\left( (\mathcal{O}_E/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p}) \right) \mathfrak{p} \subset \mathcal{O}_K \mathcal{O}_E (\mathcal{O}_E/\mathfrak{P})/(\mathcal{O}_K/\mathfrak{p}) \mathfrak{p} \mathcal{O}_E,"['abstract-algebra', 'group-theory', 'ring-theory', 'galois-theory', 'algebraic-number-theory']"
66,Does $\alpha=\beta f \Rightarrow f$ isomorphism?,Does  isomorphism?,\alpha=\beta f \Rightarrow f,"For a positive integer $n$ , let be: $K$ and $H$ finite groups of order $n$ ; $S_n$ the symmetric group of degree $n$ ; $\alpha\colon K \hookrightarrow S_n$ and $\beta\colon H \hookrightarrow S_n$ embeddings; $f\colon K \rightarrow H$ bijection. Does $\alpha=\beta f \Rightarrow f$ isomorphism? If not in general, is that true for some conditions on $\alpha$ and $\beta$ ? Edit based on @Matthias Klupsch's hint: $(\beta f)(xy)=\beta(f(xy))$ ; but $\beta f$ and $\beta$ are, in particular, homomorphisms, so: $(\beta f)(xy)=((\beta f)(x))((\beta f)(y))=(\beta(f(x))(\beta(f(y))=\beta(f(x)f(y))$ ; therefore, $\beta(f(xy))=\beta(f(x)f(y))$ ; but $\beta$ is injective, so $f(xy)=f(x)f(y)$ , and $f$ is homomorphism and hence isomorphism.","For a positive integer , let be: and finite groups of order ; the symmetric group of degree ; and embeddings; bijection. Does isomorphism? If not in general, is that true for some conditions on and ? Edit based on @Matthias Klupsch's hint: ; but and are, in particular, homomorphisms, so: ; therefore, ; but is injective, so , and is homomorphism and hence isomorphism.",n K H n S_n n \alpha\colon K \hookrightarrow S_n \beta\colon H \hookrightarrow S_n f\colon K \rightarrow H \alpha=\beta f \Rightarrow f \alpha \beta (\beta f)(xy)=\beta(f(xy)) \beta f \beta (\beta f)(xy)=((\beta f)(x))((\beta f)(y))=(\beta(f(x))(\beta(f(y))=\beta(f(x)f(y)) \beta(f(xy))=\beta(f(x)f(y)) \beta f(xy)=f(x)f(y) f,"['abstract-algebra', 'group-theory']"
67,Construct a field having 49 elements,Construct a field having 49 elements,,"I am working on this problem from Herstein's book, Abstract Algebra, 3rd edition. One question asks to construct a field of 49 elements. It gives a hint to use the ring of Gaussian integers and a maximal ideal. This is what I have so far. All rings are assumed to have a unit and be commutative. Let R=Z[i] , M:= {a+bi| 7|a and 7|b} Its pretty easy to show M is an ideal of R. To show M is maximal, suppose $\exists$ N $\subset$ R, where N is an ideal and M $\subsetneq$ N. So $\exists$ a+bi $\in$ N s.t 7 $\not|$ a or 7 $\not|$ b.  so using modular arithmetic we get that $$a^2 + b^2\equiv 1,2,3,4,5,6\pmod7$$ . Therefore letting t = $a^2 + b^2 $ , $\exists$ p,q $\in$$\mathbb{Z}$ such that  7p + tq = 1 Since N is an ideal and 7 and t are in N, 1 is also in N so it is the whole ring. So M is maximal and R/M is a field. To show that it has 49 elements, I dont know if what I'm doing is correct. I constructed a group homomorphism from the additive group property of R/M to the group $\mathbb{Z}$$_7$$\times$$\mathbb{Z}$$_7$ $\phi$ :R $\rightarrow$$\mathbb{Z}$$_7$$\times$$\mathbb{Z}$$_7$ a+bi $\rightarrow$ ( $\bar a$ , $\bar b$ ). This map is surjective and a group homomorphism The kernel of this map is also M. So by the first homomorphism theorem for groups I get that R/M $\cong$ $\mathbb{Z}$$_7$$\times$$\mathbb{Z}$$_7$ as groups, therefore |R/M| = 49 Is it correct to do this, view the field as a group and construct a function to find out how many elemnts it has?","I am working on this problem from Herstein's book, Abstract Algebra, 3rd edition. One question asks to construct a field of 49 elements. It gives a hint to use the ring of Gaussian integers and a maximal ideal. This is what I have so far. All rings are assumed to have a unit and be commutative. Let R=Z[i] , M:= {a+bi| 7|a and 7|b} Its pretty easy to show M is an ideal of R. To show M is maximal, suppose N R, where N is an ideal and M N. So a+bi N s.t 7 a or 7 b.  so using modular arithmetic we get that . Therefore letting t = , p,q such that  7p + tq = 1 Since N is an ideal and 7 and t are in N, 1 is also in N so it is the whole ring. So M is maximal and R/M is a field. To show that it has 49 elements, I dont know if what I'm doing is correct. I constructed a group homomorphism from the additive group property of R/M to the group :R a+bi ( , ). This map is surjective and a group homomorphism The kernel of this map is also M. So by the first homomorphism theorem for groups I get that R/M as groups, therefore |R/M| = 49 Is it correct to do this, view the field as a group and construct a function to find out how many elemnts it has?","\exists \subset \subsetneq \exists \in \not| \not| a^2 + b^2\equiv 1,2,3,4,5,6\pmod7 a^2 + b^2  \exists \in\mathbb{Z} \mathbb{Z}_7\times\mathbb{Z}_7 \phi \rightarrow\mathbb{Z}_7\times\mathbb{Z}_7 \rightarrow \bar a \bar b \cong \mathbb{Z}_7\times\mathbb{Z}_7",['abstract-algebra']
68,Subnormal subgroups of the generalized Fitting subgroup,Subnormal subgroups of the generalized Fitting subgroup,,"Let $G$ be some finite group. A component of a finite groups is a quasisimple subnormal subgroup. The layer $E(G)$ is the subgroup generated by all components of $G$ , let $F(G)$ denote the Fitting subgroup , then $$  F^*(G) = F(G) E(G) $$ is called the generalized Fitting subgroup of $G$ . Let $L$ be some subnormal subgroup of $G$ in $F^*(G)$ , then $L = (L\cap F(G))(L \cap E(G))$ and $L \cap E(G)$ is a product of components of $G$ . This statement is taken from Kurzweil/Stellmacher, Theorie der endlichen Gruppen (page 130). But why is it true? I tried to prove it, or  to understand a very concise sentence given after the statement. But it confuses me. Every component of $L$ is a component of $G$ , hence $E(L) \le E(G)$ and also $F(L) \le F(G)$ as $L$ is subnormal.  Now $E/Z(E)$ is a direct product of simple non-abelian groups, and as $F^*(G)$ is a central product we have $$  F^*(G) / Z(F^*(G)) \cong F(G) / Z(F(G)) \times E(G) / Z(E). $$ So I tried to deduce the statement by looking at the quotient $LZ(F^*(G)) / Z(F^*(G))$ and write it as a product using that it embedds into a direct product where the first part is nilpoent, and the second a product of simple non-abelian groups, from which the subnormal subgroups have an easy form as direct product of a subset of the factors. But I do not get it. So could someone please supply a proof of the claim?","Let be some finite group. A component of a finite groups is a quasisimple subnormal subgroup. The layer is the subgroup generated by all components of , let denote the Fitting subgroup , then is called the generalized Fitting subgroup of . Let be some subnormal subgroup of in , then and is a product of components of . This statement is taken from Kurzweil/Stellmacher, Theorie der endlichen Gruppen (page 130). But why is it true? I tried to prove it, or  to understand a very concise sentence given after the statement. But it confuses me. Every component of is a component of , hence and also as is subnormal.  Now is a direct product of simple non-abelian groups, and as is a central product we have So I tried to deduce the statement by looking at the quotient and write it as a product using that it embedds into a direct product where the first part is nilpoent, and the second a product of simple non-abelian groups, from which the subnormal subgroups have an easy form as direct product of a subset of the factors. But I do not get it. So could someone please supply a proof of the claim?","G E(G) G F(G) 
 F^*(G) = F(G) E(G)
 G L G F^*(G) L = (L\cap F(G))(L \cap E(G)) L \cap E(G) G L G E(L) \le E(G) F(L) \le F(G) L E/Z(E) F^*(G) 
 F^*(G) / Z(F^*(G)) \cong F(G) / Z(F(G)) \times E(G) / Z(E).
 LZ(F^*(G)) / Z(F^*(G))","['abstract-algebra', 'group-theory', 'finite-groups']"
69,Finding a Galois Extension,Finding a Galois Extension,,"My question is part of a larger problem: I'm supposed to find the minimal polynomial over $\mathbb{Q}$ of $1 + \sqrt[3]{2} + \sqrt[3]{4}$ ""using the automorphisms of the corresponding Galois extension."" After talking to my professor, I know that the Galois group I'm looking for is $S_3$ . However, I don't know how to ascertain what the Galois extension is with the information I've been given.","My question is part of a larger problem: I'm supposed to find the minimal polynomial over of ""using the automorphisms of the corresponding Galois extension."" After talking to my professor, I know that the Galois group I'm looking for is . However, I don't know how to ascertain what the Galois extension is with the information I've been given.",\mathbb{Q} 1 + \sqrt[3]{2} + \sqrt[3]{4} S_3,"['abstract-algebra', 'field-theory', 'galois-theory']"
70,"Is there an isomorphism $\text{Hom}_R(R \otimes_k V, R \otimes_k W) \cong R \otimes_k W \otimes_k V^*$?",Is there an isomorphism ?,"\text{Hom}_R(R \otimes_k V, R \otimes_k W) \cong R \otimes_k W \otimes_k V^*","Suppose that $R = k[x_1, \dots, x_n]$ , $G$ is a finite group acting on $R$ , and $V$ and $W$ are finite dimensional $G$ -modules (perhaps one-dimensional?). Is there an isomorphism (of $kG$ -modules?) $$ \text{Hom}_R(R \otimes_k V, R \otimes_k W) \cong R \otimes_k W \otimes_k V^*? $$ Here I'm viewing $R \otimes_k V$ and $R \otimes_k W$ as left $R$ -modules in the usual ring-theoretic way. Whenever $kG$ acts on a tensor product, the action splits over the tensor. Unless I'm getting confused, $\text{Hom}_R(R \otimes_k V, R \otimes_k W)$ is a left $kG$ -module via $$ (g \cdot \phi)(r \otimes v) = g \cdot \phi(g^{-1} \cdot(r \otimes v)) = g \cdot \phi((g^{-1} \cdot r) \otimes (g^{-1} \cdot v)). $$ I tried using hom-tensor adjunction, but it's not clear to me if that holds here (tensoring $kG$ -modules seems slightly different to tensoring modules over rings).","Suppose that , is a finite group acting on , and and are finite dimensional -modules (perhaps one-dimensional?). Is there an isomorphism (of -modules?) Here I'm viewing and as left -modules in the usual ring-theoretic way. Whenever acts on a tensor product, the action splits over the tensor. Unless I'm getting confused, is a left -module via I tried using hom-tensor adjunction, but it's not clear to me if that holds here (tensoring -modules seems slightly different to tensoring modules over rings).","R = k[x_1, \dots, x_n] G R V W G kG 
\text{Hom}_R(R \otimes_k V, R \otimes_k W) \cong R \otimes_k W \otimes_k V^*?
 R \otimes_k V R \otimes_k W R kG \text{Hom}_R(R \otimes_k V, R \otimes_k W) kG 
(g \cdot \phi)(r \otimes v) = g \cdot \phi(g^{-1} \cdot(r \otimes v)) = g \cdot \phi((g^{-1} \cdot r) \otimes (g^{-1} \cdot v)).
 kG","['abstract-algebra', 'group-theory', 'ring-theory', 'representation-theory']"
71,How show the distributivity of Heyting algebra,How show the distributivity of Heyting algebra,,I want to show the following distributivity of Heyting algebra $x \rightarrow (y \land z) = (x \rightarrow y) \land (x \rightarrow z) \tag{0}$ using only the below four laws $x \rightarrow x = 1 \tag{1}$ $x \land (x \rightarrow y) = x \land y \tag{2}$ $y \land (x \rightarrow y) = y \tag{3}$ $(x \rightarrow (y \land x)) = x \rightarrow y \tag{4}$ and the fact derived from the lattice which have 0 and 1. How to show the distributivity (0)?,I want to show the following distributivity of Heyting algebra using only the below four laws and the fact derived from the lattice which have 0 and 1. How to show the distributivity (0)?,x \rightarrow (y \land z) = (x \rightarrow y) \land (x \rightarrow z) \tag{0} x \rightarrow x = 1 \tag{1} x \land (x \rightarrow y) = x \land y \tag{2} y \land (x \rightarrow y) = y \tag{3} (x \rightarrow (y \land x)) = x \rightarrow y \tag{4},"['abstract-algebra', 'logic', 'foundations', 'heyting-algebra']"
72,Ring Homomorphism determined by a 6th root of unity,Ring Homomorphism determined by a 6th root of unity,,"I am working on the following problem : Let $K$ denote the algebraic closure of the 5 element field $F_5$ . Let $f: F_5[x] \longrightarrow K$ be the ring homomorphism determined by $f(x) = \omega$ , where $\omega$ is a primitive 6th root of 1 in $K$ . a) What is $f(3x^{50} - 2x^{45} +2)$ ? b) Find the dimension, over $F_5$ , of the image of $f$ . c) Find the kernel of $f$ . I think I've got a good grasp on part a). We use basic properties that any ring homomorphism satisfies: $f(3x^{50} - 2x^{45} + 2) = f(3x^{50}) - f(2x^{45}) + f(2)$ = $3[f(x)]^{50} - 2[f(x)]^{45} + f(2)$ = $3(\omega^{50}) - 2(\omega^{45}) + f(2)$ = $3(\omega^2) - 2(\omega^3) + f(2)$ (using that $\omega^6 = 1$ ) = $3 \cdot \omega^2 - 2 \cdot \omega^3$ My only question here is, am I justified in saying $f(2) = 0$ , since the homomorphism is determined completely by $f(x) = \omega$ ? b) I'm not sure about this part. I thought of using the rank-nullity theorem, but since $F_5[x]$ is not finite-dimensional, I don't know of a clever way to use this to determine the dimension of the image. Is there some other way here to determine the dimension of the image? c) I know of the identity $1 + \omega + \omega^2 + ... + \omega^{n-1} = 0$ , where $\omega$ is an nth root of unity. But, how can I take $f$ of an element in $F_5[x]$ and obtain $1 + \omega + ... + \omega^5$ , if I don't know what $f(1)$ is ? I can only deduce what $f(0)$ is, since a ring homomorphism sends identity elements to identity elements. Also, after, if possible, I can find what element in $F_5[x]$ gets sent to $1 + \omega + ... + \omega^5 = 0$ , is there any other element of $F_5[x]$ that can get send to $0$ by $f$ , besides $0$ ? Or is the kernel only consisting of $0$ and the element mapping to $1 + \omega + .. + \omega^5$ ? Thanks!","I am working on the following problem : Let denote the algebraic closure of the 5 element field . Let be the ring homomorphism determined by , where is a primitive 6th root of 1 in . a) What is ? b) Find the dimension, over , of the image of . c) Find the kernel of . I think I've got a good grasp on part a). We use basic properties that any ring homomorphism satisfies: = = = (using that ) = My only question here is, am I justified in saying , since the homomorphism is determined completely by ? b) I'm not sure about this part. I thought of using the rank-nullity theorem, but since is not finite-dimensional, I don't know of a clever way to use this to determine the dimension of the image. Is there some other way here to determine the dimension of the image? c) I know of the identity , where is an nth root of unity. But, how can I take of an element in and obtain , if I don't know what is ? I can only deduce what is, since a ring homomorphism sends identity elements to identity elements. Also, after, if possible, I can find what element in gets sent to , is there any other element of that can get send to by , besides ? Or is the kernel only consisting of and the element mapping to ? Thanks!",K F_5 f: F_5[x] \longrightarrow K f(x) = \omega \omega K f(3x^{50} - 2x^{45} +2) F_5 f f f(3x^{50} - 2x^{45} + 2) = f(3x^{50}) - f(2x^{45}) + f(2) 3[f(x)]^{50} - 2[f(x)]^{45} + f(2) 3(\omega^{50}) - 2(\omega^{45}) + f(2) 3(\omega^2) - 2(\omega^3) + f(2) \omega^6 = 1 3 \cdot \omega^2 - 2 \cdot \omega^3 f(2) = 0 f(x) = \omega F_5[x] 1 + \omega + \omega^2 + ... + \omega^{n-1} = 0 \omega f F_5[x] 1 + \omega + ... + \omega^5 f(1) f(0) F_5[x] 1 + \omega + ... + \omega^5 = 0 F_5[x] 0 f 0 0 1 + \omega + .. + \omega^5,"['abstract-algebra', 'ring-theory', 'complex-numbers', 'ring-homomorphism']"
73,How to prove the sequence of $p_n(x)$ are all integer polynomials on x?,How to prove the sequence of  are all integer polynomials on x?,p_n(x),"for $x \in \mathbb R ,|x|< \frac12$ define: $A_n(x)$ solution of the relation: $A_{n+1}(x) = \frac{x^2}{1-A_n(x)}$ $A_0(x) = 0$ (I found that $A_n(x) = 2x^2 \cdot \frac{(1+\sqrt{1-4x^2})^n - (1 - \sqrt{1-4x^2})^n}{(1+\sqrt{1-4x^2})^{n+1} - (1 - \sqrt{1-4x^2})^{n+1}}$ ) prove that the sequence: $p_0(x)=1$ $p_{n+1}(x) = p_n(x) \cdot (1-x^2 - A_n(x))$ consists of integer polynomials in $x$",for define: solution of the relation: (I found that ) prove that the sequence: consists of integer polynomials in,"x \in \mathbb R ,|x|< \frac12 A_n(x) A_{n+1}(x) = \frac{x^2}{1-A_n(x)} A_0(x) = 0 A_n(x) = 2x^2 \cdot \frac{(1+\sqrt{1-4x^2})^n - (1 - \sqrt{1-4x^2})^n}{(1+\sqrt{1-4x^2})^{n+1} - (1 - \sqrt{1-4x^2})^{n+1}} p_0(x)=1 p_{n+1}(x) = p_n(x) \cdot (1-x^2 - A_n(x)) x","['abstract-algebra', 'algebra-precalculus', 'number-theory', 'polynomials', 'recurrence-relations']"
74,Do we ever need irrational coefficients to generate a rational?,Do we ever need irrational coefficients to generate a rational?,,"Three easier warm-up questions and then The Real Question... Question 1: Do there exist numbers $p$ and $q$ in $\mathbb Q$ such that in order to have $pr=q$ we must have that $r$ is irrational? Answer to Question 1: No. Either $p=q=0$ , in which case $r$ can be anything, or $q\neq0$ , in which case $r=\frac qp$ is the only solution, and this is rational. Question 2: Do there exist polynomials $p(x)$ and $q(x)$ in $\mathbb Q[x]$ such that in order to have $p(x)r(x)=q(x)$ we must have that $r(x)$ has at least one irrational coefficient? Answer to Question 2: No. Actually, given that $q(x)\in\mathbb Q[x]$ is nonzero, it is not possible for $q(x)$ to be expressed as the product of $p(x)$ and some polynomial $r(x)$ unless $r(x)$ has strictly rational coefficients.  This is less obvious than the situation with the previous question. Question 3: Do there exist polynomials $p_1(x),\ldots,p_k(x)$ and $q(x)$ in $\mathbb Q[x]$ such that in order to have $$p_1(x)r_1(x)+\cdots +p_k(x)r_k(x) = q(x)$$ at least one of $r_1(x),\ldots,r_k(x)$ must have at least one irrational coefficient? That is, $q(x)$ has rational coefficients, and can be expressed as a linear combination of some specific other polynomials that have rational coefficients, but only by multiplying them by some polynomials that do not have rational coefficients. Is such a situation possible? This is the same as asking: Is it possible to start with polynomials in $\mathbb Q[x]$ , allow them to generate an ideal in $\mathbb R[x]$ , and then find within that ideal some polynomial in $\mathbb Q[x]$ which would not have appeared had the ideal been generated over $\mathbb Q[x]$ instead? Perhaps the first two warm-up questions were misleading; in each of those cases, we rule out the multiplier being irrational altogether.  That is, we show that only a rational multiplier is possible.  But in the third question, certainly it is possible that the multipliers $r_i(x)$ could live outside of $\mathbb Q[x]$ .  The question is, can some choice of the $p_i(x)$ and $q(x)$ ever force that to happen? Note: This has already been pointed out in the comments, so I might as well acknowledge it: For the sake of simplicity, I am intentionally neglecting instances like $p=0$ and $q=1$ (in Question 1) or $p(x)=x^2$ and $q(x)=x$ (in Question 2) in which the condition is impossible and therefore (technically/vacuously) implies anything. Answer to Question 3: (added later) I think I can answer Question 3.  Consider the ideal generated by the $p_i(x)$ in $\mathbb R[x]$ .  Since $\mathbb R[x]$ is a PID, this ideal is principal.  Now I think it suffices (by Question 2, actually) to show that the generator of this ideal can be taken in $\mathbb Q[x]$ .  But the most natural generator is the $\rm gcd$ of all the polynomials $p_i(x)$ , and this is in fact in $\mathbb Q[x]$ .  So every polynomial in this ideal is a multiple of this generator, which is rational, and hence by Question 2 every rational polynomial in the ideal is a rational multiple of the generator, and hence has to be in the ideal that the $p_i(x)$ would generate over $\mathbb Q[x]$ . Since I have (I think) answered Question 3, let me move on to... The Real Question: If in Question 3 we replace $\mathbb Q[x]$ and $\mathbb R[x]$ by $\mathbb Q[x_1,\ldots,x_k]$ and $\mathbb R[x_1,\ldots,x_k]$ , does that change the answer?","Three easier warm-up questions and then The Real Question... Question 1: Do there exist numbers and in such that in order to have we must have that is irrational? Answer to Question 1: No. Either , in which case can be anything, or , in which case is the only solution, and this is rational. Question 2: Do there exist polynomials and in such that in order to have we must have that has at least one irrational coefficient? Answer to Question 2: No. Actually, given that is nonzero, it is not possible for to be expressed as the product of and some polynomial unless has strictly rational coefficients.  This is less obvious than the situation with the previous question. Question 3: Do there exist polynomials and in such that in order to have at least one of must have at least one irrational coefficient? That is, has rational coefficients, and can be expressed as a linear combination of some specific other polynomials that have rational coefficients, but only by multiplying them by some polynomials that do not have rational coefficients. Is such a situation possible? This is the same as asking: Is it possible to start with polynomials in , allow them to generate an ideal in , and then find within that ideal some polynomial in which would not have appeared had the ideal been generated over instead? Perhaps the first two warm-up questions were misleading; in each of those cases, we rule out the multiplier being irrational altogether.  That is, we show that only a rational multiplier is possible.  But in the third question, certainly it is possible that the multipliers could live outside of .  The question is, can some choice of the and ever force that to happen? Note: This has already been pointed out in the comments, so I might as well acknowledge it: For the sake of simplicity, I am intentionally neglecting instances like and (in Question 1) or and (in Question 2) in which the condition is impossible and therefore (technically/vacuously) implies anything. Answer to Question 3: (added later) I think I can answer Question 3.  Consider the ideal generated by the in .  Since is a PID, this ideal is principal.  Now I think it suffices (by Question 2, actually) to show that the generator of this ideal can be taken in .  But the most natural generator is the of all the polynomials , and this is in fact in .  So every polynomial in this ideal is a multiple of this generator, which is rational, and hence by Question 2 every rational polynomial in the ideal is a rational multiple of the generator, and hence has to be in the ideal that the would generate over . Since I have (I think) answered Question 3, let me move on to... The Real Question: If in Question 3 we replace and by and , does that change the answer?","p q \mathbb Q pr=q r p=q=0 r q\neq0 r=\frac qp p(x) q(x) \mathbb Q[x] p(x)r(x)=q(x) r(x) q(x)\in\mathbb Q[x] q(x) p(x) r(x) r(x) p_1(x),\ldots,p_k(x) q(x) \mathbb Q[x] p_1(x)r_1(x)+\cdots +p_k(x)r_k(x) = q(x) r_1(x),\ldots,r_k(x) q(x) \mathbb Q[x] \mathbb R[x] \mathbb Q[x] \mathbb Q[x] r_i(x) \mathbb Q[x] p_i(x) q(x) p=0 q=1 p(x)=x^2 q(x)=x p_i(x) \mathbb R[x] \mathbb R[x] \mathbb Q[x] \rm gcd p_i(x) \mathbb Q[x] p_i(x) \mathbb Q[x] \mathbb Q[x] \mathbb R[x] \mathbb Q[x_1,\ldots,x_k] \mathbb R[x_1,\ldots,x_k]","['real-analysis', 'abstract-algebra', 'polynomials', 'modules']"
75,Proof of the Structure theorem of finitely generated graded modules over graded PID's [duplicate],Proof of the Structure theorem of finitely generated graded modules over graded PID's [duplicate],,"This question already has answers here : Decomposition of finitely generated graded modules over PID (2 answers) Closed 2 years ago . I am looking for a proof of the structure theorem of finitely generated graded modules over graded PID's: Let $R$ be a graded PID and $M$ be a finitely generated graded module over $R$ . Then $M$ decomposes uniquely as $$M \cong \bigoplus_{i=1}^n \Sigma^{\alpha_i} R\  \oplus\  \bigoplus_{j=1}^m \Sigma^{\gamma_i} R/d_j R$$ where $d_j \in R$ are homogeneous elements so that $d_j \mid d_{j+1}$ , $\alpha_i, \gamma_j \in \mathbb{Z}$ and $\Sigma^\alpha$ denotes an $\alpha$ -shift upwards in grading. But i can't find anything. Does anybody know where i could find a proof of this theorem? I know how to proof the usual structure theorem of finitely generated modules, is there an easy way to translate this result to the graded case ? I would guess that one obtains $M \cong R^n\ \oplus\ \bigoplus_{j=1}^m R/d_j R$ by the usal structure theorem , but the isomorphism is just a usal isomorphism of modules. To get a graded isomorphism one has to eventually shift the terms on the right side in grading.","This question already has answers here : Decomposition of finitely generated graded modules over PID (2 answers) Closed 2 years ago . I am looking for a proof of the structure theorem of finitely generated graded modules over graded PID's: Let be a graded PID and be a finitely generated graded module over . Then decomposes uniquely as where are homogeneous elements so that , and denotes an -shift upwards in grading. But i can't find anything. Does anybody know where i could find a proof of this theorem? I know how to proof the usual structure theorem of finitely generated modules, is there an easy way to translate this result to the graded case ? I would guess that one obtains by the usal structure theorem , but the isomorphism is just a usal isomorphism of modules. To get a graded isomorphism one has to eventually shift the terms on the right side in grading.","R M R M M \cong \bigoplus_{i=1}^n \Sigma^{\alpha_i} R\  \oplus\  \bigoplus_{j=1}^m \Sigma^{\gamma_i} R/d_j R d_j \in R d_j \mid d_{j+1} \alpha_i, \gamma_j \in \mathbb{Z} \Sigma^\alpha \alpha M \cong R^n\ \oplus\ \bigoplus_{j=1}^m R/d_j R","['abstract-algebra', 'modules', 'graded-modules']"
76,Proving the Generalized Bezout Theorem,Proving the Generalized Bezout Theorem,,"I am trying to prove the higher-dimensional analogue of Bezout theorem. It states the following: Suppose $F_1,...,F_n\in k[X_1,...,X_{n+1}]$ are homogenous polynomials of degrees $d_1,...,d_n$ , and let $C_1,...,C_n\subseteq \mathbb{P}_n$ be their zero loci. Suppose in addition that they have no factor in common. Then their intersection number is given by: \begin{align*} \dim \Gamma(C_1\cap C_2\cap ...\cap C_n)=d_1...d_n\end{align*} For $n=2$ (which is the Bezout theorem we know and love), a fairly well known way to prove it is as follows. Suppose $C_1\cap C_2\subseteq\mathbb{A}_2$ , so none of their intersection happens in $l_{\infty}=Z(X_3)$ . This can be accomplished through coordinate transformations. Letting, $f_1,f_2$ be the dehomogenized versions of $F_1$ and $F_2$ it suffices to prove that: \begin{align*}\dim k[x_1,x_2]/(f_1,f_2)=d_1d_2\end{align*} For $t\geqslant d_1+d_2$ , let $R_t\subseteq k[x_1,x_2]$ be the set of polynomials of degree at most $t$ . If we prove that $\dim R_t/(f_1,f_2)=d_1d_2$ for all $t\geqslant d_1+d_2$ , then it follows immediately that $\dim k[x_1,x_2]/(f_1,f_2)=d_1d_2$ as well. This on its turn can be accomplished by proving $\dim R_t/(f_1,f_2)$ only depends on the degrees of $f_1$ and $f_2$ , and compute the dimension using easy examples (like $f_1=x_1^{d_1}$ and $f_2=x_2^{d_2}$ ). In order to do so, we prove that there exist an exact sequence: \begin{align*} 0\xrightarrow{}R_{t-d_1-d_2}\xrightarrow{\alpha_1}R_{t-d_1}\oplus R_{t-d_2}\xrightarrow{\alpha_2}R_t\xrightarrow{\pi} R_t/(f_1,f_2)\xrightarrow{}0\end{align*} Define the maps by $\alpha_1(g)=(f_2g,f_1g)$ and $\alpha_2(g_1,g_2)=f_1g_1-f_2g_2$ , and let $\pi$ be the projection. It remains to prove we obtain an exact sequence. It is immediate that $\alpha_1$ is injective, $\pi$ is surjective, and $\alpha_2\alpha_1=0$ and $\pi\alpha_2=0$ . To prove $\ker(\alpha_2)\subseteq\text{im}(\alpha_1)$ , let $(g_1,g_2)\in\ker (\alpha_2)$ . Then $f_1g_1-f_2g_2=0$ , so $f_1g_1=f_2g_2$ . Since $f_1$ and $f_2$ have no prime factors in common, for each prime factor $\pi\mid f_1$ , we must have $\pi\mid g_2$ . As such, $f_1\mid g_2$ . Likewise, $f_2\mid g_1$ . Obviously, $g_2/f_1=g_1/f_2$ . As such, there exist a $h$ such that $(g_1,g_2)=(hf_2,hf_1)$ . We also have $\deg(h)\leqslant t-d_1-d_2$ , otherwise $\deg (g_1)>t-d_1$ . So $(g_1,g_2)\in\text{im}(\alpha_1)$ . To prove $\ker(\pi)\subseteq \text{im}(\alpha_2)$ , let $g\in \ker(\pi)$ . Then there exist $u_1,u_2\in k[x_1,x_2]$ such that $h_1f_1+h_2f_2=g$ . Assume that $\deg(h_1), \deg(h_2)$ are minimal . It remains to prove $\deg(h_1)\leqslant t-d_1$ and $\deg(h_2)\leqslant t-d_2$ . Suppose $\deg(h_1)>t-d_1$ . Then the lead terms of $h_1f_1$ and $-h_2f_2$ are the same. Letting $H_1, H_2$ be the homogenized versions of $h_1,h_2$ , and for any $p\in k[X_1,X_2,X_3]$ , let $p^*=p[X_1,X_2,0]$ . Then we have: $F_1^*H_1^*+F_2^*H_2^*=0$ . As $F_1,F_2$ don't intersect on $l_{\infty}$ , $F_1^*$ and $F_2^*$ are coprime, so $F_1^*\mid H_2^*$ and $F_2^*\mid H_1^*$ . Letting $Q=H_1^*/F_2^*$ , we have $-Q=H_2^*/F_1$ . Write $H_1=QF_2+R_1$ and $H_2=-QF_1+R_2$ . Then $R_1$ and $R_2$ are $0$ on $l_{\infty}$ . As such, $X_3\mid R_1,R_2$ . But that means that for their restrictions $r_1,r_2$ on $\textbf{A}_2$ , we have: \begin{align*} \deg(r_1)<\deg(h_1); \deg(r_2)<\deg(h_2)\end{align*} In addition, we have $R_1F_1+R_2F_2=H_1F_1+H_2F_2$ . That means that $g=r_1f_1+r_2f_2$ . This is a contradiction to the minimality of the degrees of $h_1,h_2$ . So I want to repeat this technique for $n>2$ . Take the assumption that $C_1\cap ...\cap C_n\subseteq \textbf{A}_n$ , so it suffices to prove that $\dim k[x_1,...,x_n]/(f_1,...,f_n)=d_1...d_n$ . Letting $R_t=k[x_1,...,x_n]_{\deg\leqslant t}$ , we want to prove $\dim R_t/(f_1,...,f_n)=d_1...d_n$ for $t\geqslant d_1+...+d_n$ . In order to do so, for any $S\subseteq \{1,...,n\}$ , let $R_{t,S}=R_{t_S}$ with $t_S=t-\sum_{i\in \{1,...,n\}\setminus S}d_i$ . We obtain the following sequence: \begin{align*} 0\xrightarrow{} \prod_{|S|=0} R_{t,S}\xrightarrow{\alpha_1}\prod_{|S|=1}R_{t,S}\xrightarrow{\alpha_2}...\xrightarrow{\alpha_{n}}\prod_{|S|=n}R_{t,S}=R_t\xrightarrow{\pi}R_t/(f_1,...,f_n)\xrightarrow{}0\end{align*} Again, $\pi$ is just the projection. For each $i$ , $\alpha_i$ is the sum of maps in the form $\beta_{S,k}$ with $|S|=i-1$ and $k\notin S$ . Such $\beta_{S,k}$ is given by: \begin{align*} \beta_{S,k}: R_{S,t}\to R_{S\cup\{k\},t}; g\mapsto\begin{cases} -gf_k&\text{ if }|S_{<k}|\text{ is odd}\\ gf_k&\text{ if }|S_{<k}|\text{ is even}\end{cases}\end{align*} The question is: how do I prove that this sequence is exact? It is again obvious that $\alpha_1$ is injective, $\pi$ is surjective and $\pi\alpha_n=0$ . It is also fairly easy to see $\alpha_{i+1}\alpha_{i}=0$ since $\beta_{S\cup\{k\},l}\beta_{S,k}+\beta_{S\cup\{l\},k}\beta_{S,l}=0$ .","I am trying to prove the higher-dimensional analogue of Bezout theorem. It states the following: Suppose are homogenous polynomials of degrees , and let be their zero loci. Suppose in addition that they have no factor in common. Then their intersection number is given by: For (which is the Bezout theorem we know and love), a fairly well known way to prove it is as follows. Suppose , so none of their intersection happens in . This can be accomplished through coordinate transformations. Letting, be the dehomogenized versions of and it suffices to prove that: For , let be the set of polynomials of degree at most . If we prove that for all , then it follows immediately that as well. This on its turn can be accomplished by proving only depends on the degrees of and , and compute the dimension using easy examples (like and ). In order to do so, we prove that there exist an exact sequence: Define the maps by and , and let be the projection. It remains to prove we obtain an exact sequence. It is immediate that is injective, is surjective, and and . To prove , let . Then , so . Since and have no prime factors in common, for each prime factor , we must have . As such, . Likewise, . Obviously, . As such, there exist a such that . We also have , otherwise . So . To prove , let . Then there exist such that . Assume that are minimal . It remains to prove and . Suppose . Then the lead terms of and are the same. Letting be the homogenized versions of , and for any , let . Then we have: . As don't intersect on , and are coprime, so and . Letting , we have . Write and . Then and are on . As such, . But that means that for their restrictions on , we have: In addition, we have . That means that . This is a contradiction to the minimality of the degrees of . So I want to repeat this technique for . Take the assumption that , so it suffices to prove that . Letting , we want to prove for . In order to do so, for any , let with . We obtain the following sequence: Again, is just the projection. For each , is the sum of maps in the form with and . Such is given by: The question is: how do I prove that this sequence is exact? It is again obvious that is injective, is surjective and . It is also fairly easy to see since .","F_1,...,F_n\in k[X_1,...,X_{n+1}] d_1,...,d_n C_1,...,C_n\subseteq \mathbb{P}_n \begin{align*}
\dim \Gamma(C_1\cap C_2\cap ...\cap C_n)=d_1...d_n\end{align*} n=2 C_1\cap C_2\subseteq\mathbb{A}_2 l_{\infty}=Z(X_3) f_1,f_2 F_1 F_2 \begin{align*}\dim
k[x_1,x_2]/(f_1,f_2)=d_1d_2\end{align*} t\geqslant d_1+d_2 R_t\subseteq k[x_1,x_2] t \dim R_t/(f_1,f_2)=d_1d_2 t\geqslant d_1+d_2 \dim k[x_1,x_2]/(f_1,f_2)=d_1d_2 \dim R_t/(f_1,f_2) f_1 f_2 f_1=x_1^{d_1} f_2=x_2^{d_2} \begin{align*}
0\xrightarrow{}R_{t-d_1-d_2}\xrightarrow{\alpha_1}R_{t-d_1}\oplus
R_{t-d_2}\xrightarrow{\alpha_2}R_t\xrightarrow{\pi}
R_t/(f_1,f_2)\xrightarrow{}0\end{align*} \alpha_1(g)=(f_2g,f_1g) \alpha_2(g_1,g_2)=f_1g_1-f_2g_2 \pi \alpha_1 \pi \alpha_2\alpha_1=0 \pi\alpha_2=0 \ker(\alpha_2)\subseteq\text{im}(\alpha_1) (g_1,g_2)\in\ker (\alpha_2) f_1g_1-f_2g_2=0 f_1g_1=f_2g_2 f_1 f_2 \pi\mid f_1 \pi\mid g_2 f_1\mid g_2 f_2\mid g_1 g_2/f_1=g_1/f_2 h (g_1,g_2)=(hf_2,hf_1) \deg(h)\leqslant t-d_1-d_2 \deg (g_1)>t-d_1 (g_1,g_2)\in\text{im}(\alpha_1) \ker(\pi)\subseteq \text{im}(\alpha_2) g\in \ker(\pi) u_1,u_2\in k[x_1,x_2] h_1f_1+h_2f_2=g \deg(h_1), \deg(h_2) \deg(h_1)\leqslant t-d_1 \deg(h_2)\leqslant t-d_2 \deg(h_1)>t-d_1 h_1f_1 -h_2f_2 H_1, H_2 h_1,h_2 p\in k[X_1,X_2,X_3] p^*=p[X_1,X_2,0] F_1^*H_1^*+F_2^*H_2^*=0 F_1,F_2 l_{\infty} F_1^* F_2^* F_1^*\mid H_2^* F_2^*\mid H_1^* Q=H_1^*/F_2^* -Q=H_2^*/F_1 H_1=QF_2+R_1 H_2=-QF_1+R_2 R_1 R_2 0 l_{\infty} X_3\mid R_1,R_2 r_1,r_2 \textbf{A}_2 \begin{align*} \deg(r_1)<\deg(h_1); \deg(r_2)<\deg(h_2)\end{align*} R_1F_1+R_2F_2=H_1F_1+H_2F_2 g=r_1f_1+r_2f_2 h_1,h_2 n>2 C_1\cap ...\cap C_n\subseteq \textbf{A}_n \dim k[x_1,...,x_n]/(f_1,...,f_n)=d_1...d_n R_t=k[x_1,...,x_n]_{\deg\leqslant t} \dim R_t/(f_1,...,f_n)=d_1...d_n t\geqslant d_1+...+d_n S\subseteq \{1,...,n\} R_{t,S}=R_{t_S} t_S=t-\sum_{i\in \{1,...,n\}\setminus S}d_i \begin{align*} 0\xrightarrow{} \prod_{|S|=0} R_{t,S}\xrightarrow{\alpha_1}\prod_{|S|=1}R_{t,S}\xrightarrow{\alpha_2}...\xrightarrow{\alpha_{n}}\prod_{|S|=n}R_{t,S}=R_t\xrightarrow{\pi}R_t/(f_1,...,f_n)\xrightarrow{}0\end{align*} \pi i \alpha_i \beta_{S,k} |S|=i-1 k\notin S \beta_{S,k} \begin{align*} \beta_{S,k}: R_{S,t}\to R_{S\cup\{k\},t}; g\mapsto\begin{cases} -gf_k&\text{ if }|S_{<k}|\text{ is odd}\\ gf_k&\text{ if }|S_{<k}|\text{ is even}\end{cases}\end{align*} \alpha_1 \pi \pi\alpha_n=0 \alpha_{i+1}\alpha_{i}=0 \beta_{S\cup\{k\},l}\beta_{S,k}+\beta_{S\cup\{l\},k}\beta_{S,l}=0","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'intersection-theory']"
77,How to prove finite abelian group is direct sum of cyclic groups by using matrices over Euclidean domain?,How to prove finite abelian group is direct sum of cyclic groups by using matrices over Euclidean domain?,,"Exercise from Algebra, Chapter $0$ by Aluffi: Prove using this proposition: I'm totally lost as to how to begin. How would we relate finite abelian groups to this theorem dealing with matrices over a Euclidean Domain? My only guess to start would be to let $R=\mathbb Z$ (since abelian groups are $\mathbb Z$ -modules). I know also that $M_{m,n}(\mathbb Z) \cong \mathrm{Hom}_{\mathbb Z-\mathrm{Mod}}(\mathbb Z^n, \mathbb Z^m)$ (which is itself a $\mathbb Z$ -module). Am I on the right track? Any ideas on how to go about this?","Exercise from Algebra, Chapter by Aluffi: Prove using this proposition: I'm totally lost as to how to begin. How would we relate finite abelian groups to this theorem dealing with matrices over a Euclidean Domain? My only guess to start would be to let (since abelian groups are -modules). I know also that (which is itself a -module). Am I on the right track? Any ideas on how to go about this?","0 R=\mathbb Z \mathbb Z M_{m,n}(\mathbb Z) \cong \mathrm{Hom}_{\mathbb Z-\mathrm{Mod}}(\mathbb Z^n, \mathbb Z^m) \mathbb Z","['abstract-algebra', 'group-theory', 'ring-theory', 'modules', 'abelian-groups']"
78,exercise about some field extensions,exercise about some field extensions,,"Let $E = \mathbb{C}(x, y, z)$ , $F = \mathbb{C}(x^2y, y^2z, z^2x)$ , $L$ the subfield of $E$ fixed by $S_3$ , and $K = F \cap L$ .   Then, (1) Is $E/F$ Galois? And what is its Galois group $G$ ? (2) What is $[E:K]$ ? (3) Calculate the number of intermediate fields of $L/K$ . Here is what I have tried: Since $E = F(x)$ and $x^9 \in F$ , for $\sigma_i : x \mapsto \zeta^i x$ , $G = \{ \sigma_i \}_{i=0, \dots, 8}$ (where $\zeta$ is a primitive 9th root of unity). And $\operatorname{Gal}(E/K) = H := \left< S_3, G\right>$ (the group generated by these two groups). But I don't understand what is this group, and its cardinality.","Let , , the subfield of fixed by , and .   Then, (1) Is Galois? And what is its Galois group ? (2) What is ? (3) Calculate the number of intermediate fields of . Here is what I have tried: Since and , for , (where is a primitive 9th root of unity). And (the group generated by these two groups). But I don't understand what is this group, and its cardinality.","E = \mathbb{C}(x, y, z) F = \mathbb{C}(x^2y, y^2z, z^2x) L E S_3 K = F \cap L E/F G [E:K] L/K E = F(x) x^9 \in F \sigma_i : x \mapsto \zeta^i x G = \{ \sigma_i \}_{i=0, \dots, 8} \zeta \operatorname{Gal}(E/K) = H := \left< S_3, G\right>","['abstract-algebra', 'field-theory', 'galois-theory']"
79,Is there a formula for $[F_n : V_{\{x^3\}}(F_n)]$?,Is there a formula for ?,[F_n : V_{\{x^3\}}(F_n)],"Suppose $F_n$ is a free group of rank $n$ . It is a rather well known fact, that $b_3(n) = [F_n : V_{\{x^3\}}(F_n)]$ is finite for all $n \in \mathbb{N}$ .  Is there a some sort of formula for $b_3(n)$ ? Here $V_Q$ is the verbal subgroup for the collection of group words $Q$ . The solution of a similar problem for $b_2(n) = [F_n : V_{\{x^2\}}(F_n)]$ is quite obvious: $b_2(n) = 2^n$ (as $C_2^n$ is the only $n$ -generated group of exponent $2$ ) However, similar considerations do not work for $b_3$ (as, for example $C_3 \times C_3$ and $UT(3, 3)$ are both $2$ -generated groups with exponent $3$ , but have different orders). However, using that method a lower bound can be constructed: $$b_3(n) = [F_n : V_{\{x^3\}}(F_n)] \geq [F_n : V_{\{x^3, [x, y]\}}(F_n)] = 3^n$$ Attempting to find an upper bound on $b_3(n)$ by counting cube-free words (something similar can also be done to $b_2(n)$ ) is doomed to fail too, as even for $n = 2$ , there are infinitely many of them: For what $n$ is $W_n$ finite?","Suppose is a free group of rank . It is a rather well known fact, that is finite for all .  Is there a some sort of formula for ? Here is the verbal subgroup for the collection of group words . The solution of a similar problem for is quite obvious: (as is the only -generated group of exponent ) However, similar considerations do not work for (as, for example and are both -generated groups with exponent , but have different orders). However, using that method a lower bound can be constructed: Attempting to find an upper bound on by counting cube-free words (something similar can also be done to ) is doomed to fail too, as even for , there are infinitely many of them: For what $n$ is $W_n$ finite?","F_n n b_3(n) = [F_n : V_{\{x^3\}}(F_n)] n \in \mathbb{N} b_3(n) V_Q Q b_2(n) = [F_n : V_{\{x^2\}}(F_n)] b_2(n) = 2^n C_2^n n 2 b_3 C_3 \times C_3 UT(3, 3) 2 3 b_3(n) = [F_n : V_{\{x^3\}}(F_n)] \geq [F_n : V_{\{x^3, [x, y]\}}(F_n)] = 3^n b_3(n) b_2(n) n = 2","['abstract-algebra', 'group-theory', 'free-groups', 'combinatorial-group-theory', 'verbal-subgroups']"
80,Proof of separability of polynomials without derivatives,Proof of separability of polynomials without derivatives,,"Is there a known proof without differentiating that proves that all irreducible polynomials over $\mathbb{Q}$ are separable? (Or even better, for all fields of characteristic $0$ .) EDIT: As people seem to question this thread; I do know a proof with derivatives - my motivation for one without is simply curiosity. Multiple approaches are always nice.","Is there a known proof without differentiating that proves that all irreducible polynomials over are separable? (Or even better, for all fields of characteristic .) EDIT: As people seem to question this thread; I do know a proof with derivatives - my motivation for one without is simply curiosity. Multiple approaches are always nice.",\mathbb{Q} 0,"['abstract-algebra', 'polynomials', 'field-theory', 'alternative-proof', 'separable-extension']"
81,Center is a normal subgroup of G,Center is a normal subgroup of G,,"This is a problem from Herstein's Topics in Algebra. I have already shown the above result using the definition of normal subgroup. But now I want to prove it by constructing a homomorphism such that kernel is center of the group G. How can I construct such homomorphism? I was thinking of going like this. Given a $g$ in $G$ construct $E_g(x)=g x g^{-1}$ So given each element we have a transformation. Set of transformations like this form a group with inverse given by $E_{g^{-1}}$ . Kernel consist of all those elements for which $E_g$ is identity. In other words, $E_g(x)=x$ or $g x g^{-1}=x$ or $gx=xg $ for all $x$ . That is $g$ commutes with everything in $G$ . Am I going into the right direction. Edit: I became interested in proving the result through homomorphism approach as problem is in section 2.7 which is titled homomorphisms. Herstein must be expecting us to take this route.","This is a problem from Herstein's Topics in Algebra. I have already shown the above result using the definition of normal subgroup. But now I want to prove it by constructing a homomorphism such that kernel is center of the group G. How can I construct such homomorphism? I was thinking of going like this. Given a in construct So given each element we have a transformation. Set of transformations like this form a group with inverse given by . Kernel consist of all those elements for which is identity. In other words, or or for all . That is commutes with everything in . Am I going into the right direction. Edit: I became interested in proving the result through homomorphism approach as problem is in section 2.7 which is titled homomorphisms. Herstein must be expecting us to take this route.",g G E_g(x)=g x g^{-1} E_{g^{-1}} E_g E_g(x)=x g x g^{-1}=x gx=xg  x g G,"['abstract-algebra', 'group-theory', 'group-isomorphism']"
82,Associated Graded Algebra,Associated Graded Algebra,,"I'm trying to work through Exercise III.27 of Lang's Algebra : Let $A$ be a filtered algebra, $A=\bigcup_{j\geq 0}A_{j}$ . For $j\geq 0$ , define $R_{j}=A_{j}/A_{j-1}$ , with $A_{-1}=\{0\}$ . Let $R=\bigoplus_{j\geq 0}R_{j}$ . Define a natural product on $R$ making $R$ into a graded algebra. My Attempt : I believe that the product is defined by $$(x+A_{n-1})(y+A_{m-1})=xy+A_{n+m-1}$$ for all $x\in A_{n}$ and all $y\in A_{m}$ . Then $R$ is clearly a direct sum of subspaces and $R_{j}R_{k}\subset R_{j+k}$ for all $j$ and $k$ , since $$ \frac{A_{j}}{A_{j-1}}\cdot\frac{A_{k}}{A_{k-1}}\subset\frac{A_{j+k}}{A_{j+k-1}}$$ (in the above containment, we use the fact that $xy\in A_{j+k}$ if $x\in A_{j}$ and $y\in A_{k}$ ; Also, $A_{j-1} \cdot A_{k-1} \subset A_{j+k-1}$ ). Hence, $R$ is a graded algebra. My Questions: Does this argument look okay? In particular, how can I show that the product is well-defined? Thanks in advance for any suggestions.","I'm trying to work through Exercise III.27 of Lang's Algebra : Let be a filtered algebra, . For , define , with . Let . Define a natural product on making into a graded algebra. My Attempt : I believe that the product is defined by for all and all . Then is clearly a direct sum of subspaces and for all and , since (in the above containment, we use the fact that if and ; Also, ). Hence, is a graded algebra. My Questions: Does this argument look okay? In particular, how can I show that the product is well-defined? Thanks in advance for any suggestions.","A A=\bigcup_{j\geq 0}A_{j} j\geq 0 R_{j}=A_{j}/A_{j-1} A_{-1}=\{0\} R=\bigoplus_{j\geq 0}R_{j} R R (x+A_{n-1})(y+A_{m-1})=xy+A_{n+m-1} x\in A_{n} y\in A_{m} R R_{j}R_{k}\subset R_{j+k} j k 
\frac{A_{j}}{A_{j-1}}\cdot\frac{A_{k}}{A_{k-1}}\subset\frac{A_{j+k}}{A_{j+k-1}} xy\in A_{j+k} x\in A_{j} y\in A_{k} A_{j-1} \cdot A_{k-1} \subset A_{j+k-1} R","['abstract-algebra', 'algebras', 'graded-algebras']"
83,Maximality of an ideal for showing that an algebra is in fact a field,Maximality of an ideal for showing that an algebra is in fact a field,,"I have an algebra $A$ over the field $F$ , with the finite dimensionality $n$ as a vector space over $F$ . I can also assume that $A$ is an integral domain. Assuming that $v_1,...,v_n$ is a spanning list of vectors and that $v_1=1$ , I believe I can represent $A$ as $F[v_1,v_2,...,v_n]/I$ where $$I=\left(v_1-1,\ v_iv_j\ \forall\ 2\leq i,j\leq n\right).$$ Now, I'd hope to show that $A$ is a field by proving the maximality of $I$ , but I can't figure out how to show that.","I have an algebra over the field , with the finite dimensionality as a vector space over . I can also assume that is an integral domain. Assuming that is a spanning list of vectors and that , I believe I can represent as where Now, I'd hope to show that is a field by proving the maximality of , but I can't figure out how to show that.","A F n F A v_1,...,v_n v_1=1 A F[v_1,v_2,...,v_n]/I I=\left(v_1-1,\ v_iv_j\ \forall\ 2\leq i,j\leq n\right). A I","['abstract-algebra', 'field-theory', 'ideals', 'maximal-and-prime-ideals']"
84,About the definition of coinduction of a module,About the definition of coinduction of a module,,"If $G$ is a group, $H$ a subgroup, and $N$ a left $\mathbb{Z}[H]-$ module, I've learned the following construction: $$\mathrm{coInd}_H^G(N) = \mathrm{Hom}_{\mathbb{Z}[H]}(\mathbb{Z}[G], N)$$ where $\mathbb{Z}[G]$ is given the structure of a left $\mathbb{Z}[H]$ -module setting $$h\cdot x = xh^{-1}$$ for every $x\in G$ and $h\in H$ . Then one makes $\mathrm{coInd}_H^G(N)$ a left $\mathbb{Z}[G]$ -module declaring that for every $g\in G$ and $\varphi\in\mathrm{coInd}_H^G(N)$ $$(g\cdot\varphi)(x) = \varphi(g^{-1}x).$$ Is there some reason why we are taking all those inverses instead of just defining, in a way that looks more natural to me, the $H$ -structure on $\mathbb{Z}[G]$ setting $h\cdot x = hx$ and then the $G-$ structure on $\mathrm{coInd}_H^G(N)$ setting $(g\cdot\varphi)(x) = \varphi(xg)$ ? I think the two definitions are equivalent: if $\varphi\in\mathrm{coInd}_H^G(N)$ one can define $\psi:\mathbb{Z}[G]\to N$ such that $\psi(x) = \varphi(x^{-1})$ for every $x\in G$ . Now $\psi$ is an element of the coinduced module constructed following the second definition, and the map sending every $\varphi$ to the corresponding $\psi$ gives an isomorphism. Am I wrong? If not, why is the first definition preferred over the second?","If is a group, a subgroup, and a left module, I've learned the following construction: where is given the structure of a left -module setting for every and . Then one makes a left -module declaring that for every and Is there some reason why we are taking all those inverses instead of just defining, in a way that looks more natural to me, the -structure on setting and then the structure on setting ? I think the two definitions are equivalent: if one can define such that for every . Now is an element of the coinduced module constructed following the second definition, and the map sending every to the corresponding gives an isomorphism. Am I wrong? If not, why is the first definition preferred over the second?","G H N \mathbb{Z}[H]- \mathrm{coInd}_H^G(N) = \mathrm{Hom}_{\mathbb{Z}[H]}(\mathbb{Z}[G], N) \mathbb{Z}[G] \mathbb{Z}[H] h\cdot x = xh^{-1} x\in G h\in H \mathrm{coInd}_H^G(N) \mathbb{Z}[G] g\in G \varphi\in\mathrm{coInd}_H^G(N) (g\cdot\varphi)(x) = \varphi(g^{-1}x). H \mathbb{Z}[G] h\cdot x = hx G- \mathrm{coInd}_H^G(N) (g\cdot\varphi)(x) = \varphi(xg) \varphi\in\mathrm{coInd}_H^G(N) \psi:\mathbb{Z}[G]\to N \psi(x) = \varphi(x^{-1}) x\in G \psi \varphi \psi","['abstract-algebra', 'modules', 'representation-theory', 'definition']"
85,The automorphism group of $S_6$ is isomorphic to a semidirect prodct,The automorphism group of  is isomorphic to a semidirect prodct,S_6,On this document an outer automorphism of $S_6$ is constructed. I would like to use this construction to prove that $\mathrm{Aut}(S_6)\cong S_6\rtimes_\varphi\mathbb{Z}_2$ . The idea would be to find an outer automorphism of order 2. If $F$ is the outer automorphism constructed in the document above then I can prove that the order of $F$ is even. Any outer automorphism is of the form $F\gamma_\sigma$ for some inner automorphism $\gamma_\sigma$ . I can also prove that $F^2$ is inner so $F^2=\gamma_\tau$ . I think one needs to use $\tau$ to construct $\sigma$ so that $F\gamma_\sigma$ has order 2. This is basically the approach used in this paper . But it seems to me the the construction of the outer automorphism done in the paper is a bit different than the construction I am interested in. I feel like there should be a way to modify Rotman's argument to make it work for the first construction. Any ideas?,On this document an outer automorphism of is constructed. I would like to use this construction to prove that . The idea would be to find an outer automorphism of order 2. If is the outer automorphism constructed in the document above then I can prove that the order of is even. Any outer automorphism is of the form for some inner automorphism . I can also prove that is inner so . I think one needs to use to construct so that has order 2. This is basically the approach used in this paper . But it seems to me the the construction of the outer automorphism done in the paper is a bit different than the construction I am interested in. I feel like there should be a way to modify Rotman's argument to make it work for the first construction. Any ideas?,S_6 \mathrm{Aut}(S_6)\cong S_6\rtimes_\varphi\mathbb{Z}_2 F F F\gamma_\sigma \gamma_\sigma F^2 F^2=\gamma_\tau \tau \sigma F\gamma_\sigma,"['abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups', 'automorphism-group']"
86,"If S is a normal subgroup, identify the quotient group G/S. What are the $\varphi(G)$'s?","If S is a normal subgroup, identify the quotient group G/S. What are the 's?",\varphi(G),"The following is an exercise from Artin's Algebra: (Kiefer Sutherland's voice) Let G be the group of upper triangular real matrices $\begin{bmatrix} a & b\\  0 & d \end{bmatrix}$ with a and d different from zero. For each of the following subsets, determine whether or not S is a subgroup, and whether or not S is a normal subgroup. If S is a normal subgroup, identify the quotient group $G/S$ . (i) S is the subset defined by b = O. (ii) S is the subset defined by d = 1. (iii) S is the subset defined by a = d. The following questions are related: How the quotient group of following matrix group looks like? Proving that $G/N$ is an abelian group I found a solution by Blake Griffith linked here . The following is a screenshot of the solution: The following are my questions: How is $S$ is the $\ker$ for iii? I computed the kernel to be $$\begin{bmatrix} x_{11} & x_{12}\\  0 & x_{22} \end{bmatrix}$$ where $x_{21} = 0, x_{12} \in \mathbb R, x_{11} \ne 0 \ne x_{22}$ . But how do we conclude $x_{11} = x_{22}$ ? I think I'm missing something slightly because the solution was (ii) was incredibly inventing: Is this correction to ii correct? For ii, we set $$\varphi(X)=X\pmatrix{\frac{1}{x_{11}}&\frac{x_{12}}{x_{11}}\\0&1}=\pmatrix{1&2x_{12}\\  \frac{x_{21}}{x_{11}}&\frac{x_{21}x_{12}}{x_{11}}+x_{22}}=\pmatrix{1&0\\0&1}$$ to get $S$ . It was pointed out this is wrong, but I think I can correct this. For ii, we set $$\varphi(X)=X\pmatrix{\frac{1}{x_{11}}&\frac{-x_{12}}{x_{11}}\\0&1}=\pmatrix{1&0\\  \frac{x_{21}}{x_{11}}&\frac{-x_{21}x_{12}}{x_{11}}+x_{22}}=\pmatrix{1&0\\0&1}$$ to get $S$ . Does the $G'$ matter? I think it doesn't, but I want to confirm. What are the $\varphi(G)$ 's? For ii, I think $\varphi(G)$ is all of $d \ne 0, b \in \mathbb R$ in $$\begin{bmatrix} a & b\\  0 & d \end{bmatrix}\begin{bmatrix} \frac 1 a & \frac b a \\  0 & 1 \end{bmatrix}=\begin{bmatrix} 1 & 2b\\  0 & d \end{bmatrix}$$ For iii, I think $\varphi(G)=I_2$ because $$\begin{bmatrix} a & b\\  0 & d \end{bmatrix}\begin{bmatrix} \frac 1 a & \frac b {-ad} \\  0 & \frac{1}{d} \end{bmatrix}=\begin{bmatrix} 1 & 0\\  0 & 1 \end{bmatrix}$$ What does it mean that $\varphi(G)$ is just the identity of $G'$ ? $|G/S|=1$ I think","The following is an exercise from Artin's Algebra: (Kiefer Sutherland's voice) Let G be the group of upper triangular real matrices with a and d different from zero. For each of the following subsets, determine whether or not S is a subgroup, and whether or not S is a normal subgroup. If S is a normal subgroup, identify the quotient group . (i) S is the subset defined by b = O. (ii) S is the subset defined by d = 1. (iii) S is the subset defined by a = d. The following questions are related: How the quotient group of following matrix group looks like? Proving that is an abelian group I found a solution by Blake Griffith linked here . The following is a screenshot of the solution: The following are my questions: How is is the for iii? I computed the kernel to be where . But how do we conclude ? I think I'm missing something slightly because the solution was (ii) was incredibly inventing: Is this correction to ii correct? For ii, we set to get . It was pointed out this is wrong, but I think I can correct this. For ii, we set to get . Does the matter? I think it doesn't, but I want to confirm. What are the 's? For ii, I think is all of in For iii, I think because What does it mean that is just the identity of ? I think","\begin{bmatrix}
a & b\\ 
0 & d
\end{bmatrix} G/S G/N S \ker \begin{bmatrix}
x_{11} & x_{12}\\ 
0 & x_{22}
\end{bmatrix} x_{21} = 0, x_{12} \in \mathbb R, x_{11} \ne 0 \ne x_{22} x_{11} = x_{22} \varphi(X)=X\pmatrix{\frac{1}{x_{11}}&\frac{x_{12}}{x_{11}}\\0&1}=\pmatrix{1&2x_{12}\\
 \frac{x_{21}}{x_{11}}&\frac{x_{21}x_{12}}{x_{11}}+x_{22}}=\pmatrix{1&0\\0&1} S \varphi(X)=X\pmatrix{\frac{1}{x_{11}}&\frac{-x_{12}}{x_{11}}\\0&1}=\pmatrix{1&0\\
 \frac{x_{21}}{x_{11}}&\frac{-x_{21}x_{12}}{x_{11}}+x_{22}}=\pmatrix{1&0\\0&1} S G' \varphi(G) \varphi(G) d \ne 0, b \in \mathbb R \begin{bmatrix}
a & b\\ 
0 & d
\end{bmatrix}\begin{bmatrix}
\frac 1 a & \frac b a \\ 
0 & 1
\end{bmatrix}=\begin{bmatrix}
1 & 2b\\ 
0 & d
\end{bmatrix} \varphi(G)=I_2 \begin{bmatrix}
a & b\\ 
0 & d
\end{bmatrix}\begin{bmatrix}
\frac 1 a & \frac b {-ad} \\ 
0 & \frac{1}{d}
\end{bmatrix}=\begin{bmatrix}
1 & 0\\ 
0 & 1
\end{bmatrix} \varphi(G) G' |G/S|=1","['abstract-algebra', 'matrices']"
87,"$R$ is a unital commutative ring, $M$ and $N$ are $R$-modules. If $f:M \to N$ is $R$-linear, then is it true that $M= \ker(f) \oplus \text{im}(f)$?","is a unital commutative ring,  and  are -modules. If  is -linear, then is it true that ?",R M N R f:M \to N R M= \ker(f) \oplus \text{im}(f),"Let $R$ be a commutative ring with unity.  Prove or disprove: for $R$ -modules $M$ and $N$ , if $f:M \to N$ is $R$ -linear, then $M= \ker(f) \oplus \operatorname{im}(f)$ . My attempt: Let $f : \Bbb Z/4\Bbb Z \to \Bbb Z/2\Bbb Z$ be defined by $f(\bar{n}) = \overline{2n}$ . Then, $\operatorname{im}(f) = \Bbb Z/2\Bbb Z$ and $\ker(f) = \{\bar{0},\bar{2}\} \cong \Bbb Z/2\Bbb Z$ (as $\Bbb Z$ -modules). But clearly, $\Bbb Z/4\Bbb Z  \not\cong \Bbb Z/2\Bbb Z \oplus \Bbb Z/ 2\Bbb Z$ . Is my answer correct? If there are any mistakes, please point out.","Let be a commutative ring with unity.  Prove or disprove: for -modules and , if is -linear, then . My attempt: Let be defined by . Then, and (as -modules). But clearly, . Is my answer correct? If there are any mistakes, please point out.","R R M N f:M \to N R M= \ker(f) \oplus \operatorname{im}(f) f : \Bbb Z/4\Bbb Z \to \Bbb Z/2\Bbb Z f(\bar{n}) = \overline{2n} \operatorname{im}(f) = \Bbb Z/2\Bbb Z \ker(f) = \{\bar{0},\bar{2}\} \cong \Bbb Z/2\Bbb Z \Bbb Z \Bbb Z/4\Bbb Z  \not\cong \Bbb Z/2\Bbb Z \oplus \Bbb Z/ 2\Bbb Z",['abstract-algebra']
88,"What is the relation between 'the order of $x^k = n/{\gcd(k,n)}$' and Lagrange's Theorem?",What is the relation between 'the order of ' and Lagrange's Theorem?,"x^k = n/{\gcd(k,n)}","Algebra by Michael Artin Cor 2.8.11 to Lagrange's Theorem (Theorem 2.8.9). Question: What is the relation between Cor 2.8.11 and the order of $x^k$ given by $n/{\gcd(k,n)}$ (in the text, this is in the 3rd bullet point of Prop 2.4.3 )? (*) I was thinking something like $1=\gcd(k,p)$ for all $1 \le k < p$, so somehow the order of the non-identity elements of a group of prime order would be shown to be $p/{\gcd(k,p)} = p/1 = p$. I think this would be a way to show Cor 2.8.11 without Cor 2.8.10 to Lagrange's Theorem (Theorem 2.8.9), Lagrange's Theorem itself (Theorem 2.8.9) or even the Counting Formula (Formula 2.8.8). Or perhaps it's more the converse: that Cor 2.8.11 implies 3rd bullet of Prop 2.4.3 in the case that $n$ is prime? (*) Prop 2.4.3 Proposition 2.4.3 Let $x$ be an element of finite order $n$ in a group, and let $k$ be an integer that is written as $k = nq + r$ where $q$ and $r$ are integers and $r$ is in the range $0 \leq r < n$. $x^k = x^r$. $x^k = 1$ if and only if $r = 0$. Let $d$ be the greatest common divisor of $k$ and $n$.   The order of $x^k$ is equal to $n/d$.","Algebra by Michael Artin Cor 2.8.11 to Lagrange's Theorem (Theorem 2.8.9). Question: What is the relation between Cor 2.8.11 and the order of $x^k$ given by $n/{\gcd(k,n)}$ (in the text, this is in the 3rd bullet point of Prop 2.4.3 )? (*) I was thinking something like $1=\gcd(k,p)$ for all $1 \le k < p$, so somehow the order of the non-identity elements of a group of prime order would be shown to be $p/{\gcd(k,p)} = p/1 = p$. I think this would be a way to show Cor 2.8.11 without Cor 2.8.10 to Lagrange's Theorem (Theorem 2.8.9), Lagrange's Theorem itself (Theorem 2.8.9) or even the Counting Formula (Formula 2.8.8). Or perhaps it's more the converse: that Cor 2.8.11 implies 3rd bullet of Prop 2.4.3 in the case that $n$ is prime? (*) Prop 2.4.3 Proposition 2.4.3 Let $x$ be an element of finite order $n$ in a group, and let $k$ be an integer that is written as $k = nq + r$ where $q$ and $r$ are integers and $r$ is in the range $0 \leq r < n$. $x^k = x^r$. $x^k = 1$ if and only if $r = 0$. Let $d$ be the greatest common divisor of $k$ and $n$.   The order of $x^k$ is equal to $n/d$.",,"['abstract-algebra', 'group-theory', 'elementary-number-theory', 'alternative-proof', 'cyclic-groups']"
89,"Describe $\mathbb{R}[x]/(x^{2}+ax+b)$ where $a,b \in \mathbb{R}$",Describe  where,"\mathbb{R}[x]/(x^{2}+ax+b) a,b \in \mathbb{R}","So obviously using quadractic formula, we have three cases for the roots which depends on the discriminant. I am not sure if I am right on this but, Case 1: $a^{2}-4b>0$. Then we have two distinct real roots so this factors as $$\mathbb{R}[x]/(x-\alpha) \oplus \mathbb{R}[x]/(x-\beta).$$ (My guess here is since $\alpha$ and $\beta$ are different, these two ideals are comaximal so I can apply the Chinese Remainder Theorem). But this is isomorphic to $$\mathbb{R} \oplus \mathbb{R}.$$ Case 2: $a^{2}-4b < 0$. In this case, we have a complex root so we have an extension of degree $2$. But obviously whatever root we have, this is contained in $\mathbb{R}[i]\cong \mathbb{C}$ so we must have this is $\mathbb{C}$ by the tower law since $\mathbb{R}[i]$ is also a degree $2$ extension of $\mathbb{R}$. Case 3: $a^{2}-4b=0$. Then we have a real root with multiplicity $2$. I am not sure what this is as if we have the root is $\alpha$, we get $$\mathbb{R}[x]/(x-\alpha)^{2}$$ Since these roots are the same, $(x-\alpha)$ and $(x-\alpha)$ are not comaximal I believe so I don't know what this ring is.","So obviously using quadractic formula, we have three cases for the roots which depends on the discriminant. I am not sure if I am right on this but, Case 1: $a^{2}-4b>0$. Then we have two distinct real roots so this factors as $$\mathbb{R}[x]/(x-\alpha) \oplus \mathbb{R}[x]/(x-\beta).$$ (My guess here is since $\alpha$ and $\beta$ are different, these two ideals are comaximal so I can apply the Chinese Remainder Theorem). But this is isomorphic to $$\mathbb{R} \oplus \mathbb{R}.$$ Case 2: $a^{2}-4b < 0$. In this case, we have a complex root so we have an extension of degree $2$. But obviously whatever root we have, this is contained in $\mathbb{R}[i]\cong \mathbb{C}$ so we must have this is $\mathbb{C}$ by the tower law since $\mathbb{R}[i]$ is also a degree $2$ extension of $\mathbb{R}$. Case 3: $a^{2}-4b=0$. Then we have a real root with multiplicity $2$. I am not sure what this is as if we have the root is $\alpha$, we get $$\mathbb{R}[x]/(x-\alpha)^{2}$$ Since these roots are the same, $(x-\alpha)$ and $(x-\alpha)$ are not comaximal I believe so I don't know what this ring is.",,"['abstract-algebra', 'polynomials', 'field-theory', 'extension-field', 'irreducible-polynomials']"
90,$H \leq \mathbb{Z}_q^n$ and $H \cong \mathbb{Z}_q^m$ implies that $\mathbb{Z}_q^n / H \cong \mathbb{Z}_q^{n-m}$,and  implies that,H \leq \mathbb{Z}_q^n H \cong \mathbb{Z}_q^m \mathbb{Z}_q^n / H \cong \mathbb{Z}_q^{n-m},"Given a pair of positive integers $n,q$ and a subgroup $H \leq \mathbb{Z}_q^n$ such that $H \cong \mathbb{Z}_q^m$ for a positive   integer $m < n$ then show that    $$  \mathbb{Z}_q^n / H \cong \mathbb{Z}_q^{n-m}.$$ This is a problem I came up with trying to generalize the trivial case when $q$ is a prime number (It is trivial because in this case a $\mathbb{Z}_q$- module is a vector space). I actually found a proof but I believe it's way too long for such a statement so I'm not asking for hints or suggestions: my question is if somebody is able to find a better proof (even a sketch would be fine).","Given a pair of positive integers $n,q$ and a subgroup $H \leq \mathbb{Z}_q^n$ such that $H \cong \mathbb{Z}_q^m$ for a positive   integer $m < n$ then show that    $$  \mathbb{Z}_q^n / H \cong \mathbb{Z}_q^{n-m}.$$ This is a problem I came up with trying to generalize the trivial case when $q$ is a prime number (It is trivial because in this case a $\mathbb{Z}_q$- module is a vector space). I actually found a proof but I believe it's way too long for such a statement so I'm not asking for hints or suggestions: my question is if somebody is able to find a better proof (even a sketch would be fine).",,"['abstract-algebra', 'finite-groups', 'modules']"
91,If $A$ is absolutely flat then every primary ideal is maximal,If  is absolutely flat then every primary ideal is maximal,A,"Given the ring $A$ is commutative with an identity element. If $A$ is absolutely flat (i.e. each $A$-module is flat) then every primary ideal is maximal. This exercise 4.3 comes from the classical text of Atiyah-Macdonald : introduction to the commutative algebra. Attempt: Suppose $\mathfrak{q}$ is a primary ideal in $A$ and fix an $x\in A-\mathfrak{q}.$ Then $\bar{x}\in A/\mathfrak{q}$ is non-zero since $x\not\in\mathfrak{q}$ Recall that $A$ is absolutely flat $\Longleftrightarrow$ every principal ideal is idempotent. Then as $x\in\langle x\rangle=\langle x^{2}\rangle$, we have $x=ax^{2}$ for some $a\in A$ and hence $x(ax-1)=0\in\mathfrak{q}$ and we thus have $(ax-1)^{n}\in\mathfrak{q}$ for some integer $n>0$ since $x\not\in\mathfrak{q}.$ Therefore, we get that $(ax-1)^{n}=\bar{0}$ in $A/\mathfrak{q}$. It follows that $\bar{a}\bar{x}-\bar{1}\in A/\mathfrak{q}$ is nilpotent and thus $\bar{a}\bar{x}=(\bar{a}\bar{x}-\bar{1})+\bar{1}\in A/\mathfrak{q}$ is unit which implies $\bar{x}\in A/\mathfrak{q}$ is unit. Therefore, $A/\mathfrak{q}$ is a field. It follows that $\mathfrak{q}$ must be a maximal ideal in $A$. I am not very sure if my proof is valid. Any suggestion or comment I will be grateful.","Given the ring $A$ is commutative with an identity element. If $A$ is absolutely flat (i.e. each $A$-module is flat) then every primary ideal is maximal. This exercise 4.3 comes from the classical text of Atiyah-Macdonald : introduction to the commutative algebra. Attempt: Suppose $\mathfrak{q}$ is a primary ideal in $A$ and fix an $x\in A-\mathfrak{q}.$ Then $\bar{x}\in A/\mathfrak{q}$ is non-zero since $x\not\in\mathfrak{q}$ Recall that $A$ is absolutely flat $\Longleftrightarrow$ every principal ideal is idempotent. Then as $x\in\langle x\rangle=\langle x^{2}\rangle$, we have $x=ax^{2}$ for some $a\in A$ and hence $x(ax-1)=0\in\mathfrak{q}$ and we thus have $(ax-1)^{n}\in\mathfrak{q}$ for some integer $n>0$ since $x\not\in\mathfrak{q}.$ Therefore, we get that $(ax-1)^{n}=\bar{0}$ in $A/\mathfrak{q}$. It follows that $\bar{a}\bar{x}-\bar{1}\in A/\mathfrak{q}$ is nilpotent and thus $\bar{a}\bar{x}=(\bar{a}\bar{x}-\bar{1})+\bar{1}\in A/\mathfrak{q}$ is unit which implies $\bar{x}\in A/\mathfrak{q}$ is unit. Therefore, $A/\mathfrak{q}$ is a field. It follows that $\mathfrak{q}$ must be a maximal ideal in $A$. I am not very sure if my proof is valid. Any suggestion or comment I will be grateful.",,"['abstract-algebra', 'proof-verification', 'commutative-algebra']"
92,Proving that $\operatorname{Tor}_n^R$ is a bifunctor,Proving that  is a bifunctor,\operatorname{Tor}_n^R,"$\newcommand{\Tor}{\operatorname{Tor}}$ Ex10.2 pg 615: For a ring $R$ and fixed $k \ge 0$, prove that $\Tor_n^R(-,-)$ is a bifunctor. I am aware of this post. I am also not satisfied with the answer. I am unfamilar with total complexes, and I still don't see how the argument writes out. Concerns: There must be a choice of projective resolution here. $P,Q$ be resolutions of $A,B$. Suppose $P'$ is another resolution of $A$, then we can show we have $\mathbb{Z}$-isomoprhisms.   $$\Tor_n^R(A,B) \cong \Tor_n^R(A,B)'$$ In Rotman's homological algebra , we defined $\Tor$ as derived functor of right tensor, whislt $\operatorname{tor}$ as derived functor of left tensor. Hence, $\Tor$ is only a functor in its first argument, and how does make sense of an induced morphism $\Tor_n^R(A,B) \rightarrow \Tor_n^R(A,B')$ from $B\rightarrow B'$ ? I was thinking we may use the isomorphism $\Tor_n(A,B) \cong \operatorname{tor}_n(A,B)$. But isomoprhism is terribly (for me) obscured in the proof: Theorem 6.32, pg 355 . How should one approach? May someone also elaborate on using total complexes? Ok: so I have defined my own ""induced morphisms"". This is the proof I came up with. I wonder if it is right. I don't like it as it requires pointwise element chase - is this inevitable?","$\newcommand{\Tor}{\operatorname{Tor}}$ Ex10.2 pg 615: For a ring $R$ and fixed $k \ge 0$, prove that $\Tor_n^R(-,-)$ is a bifunctor. I am aware of this post. I am also not satisfied with the answer. I am unfamilar with total complexes, and I still don't see how the argument writes out. Concerns: There must be a choice of projective resolution here. $P,Q$ be resolutions of $A,B$. Suppose $P'$ is another resolution of $A$, then we can show we have $\mathbb{Z}$-isomoprhisms.   $$\Tor_n^R(A,B) \cong \Tor_n^R(A,B)'$$ In Rotman's homological algebra , we defined $\Tor$ as derived functor of right tensor, whislt $\operatorname{tor}$ as derived functor of left tensor. Hence, $\Tor$ is only a functor in its first argument, and how does make sense of an induced morphism $\Tor_n^R(A,B) \rightarrow \Tor_n^R(A,B')$ from $B\rightarrow B'$ ? I was thinking we may use the isomorphism $\Tor_n(A,B) \cong \operatorname{tor}_n(A,B)$. But isomoprhism is terribly (for me) obscured in the proof: Theorem 6.32, pg 355 . How should one approach? May someone also elaborate on using total complexes? Ok: so I have defined my own ""induced morphisms"". This is the proof I came up with. I wonder if it is right. I don't like it as it requires pointwise element chase - is this inevitable?",,"['abstract-algebra', 'modules', 'homological-algebra', 'graded-modules']"
93,Saturated Addition Over Tri-state Pulser Input: What kind of algebraic structure is this?,Saturated Addition Over Tri-state Pulser Input: What kind of algebraic structure is this?,,"I'm currently working with a ""tri-state pulser"" in an engineering context. To excite a response from this device, one provides a voltage sequence consisting of elements from $\{-1,0,1\}$. For example, a valid input looks something like this: One can write out the shape of this input as a sequence: $(-1,1,0,0,-1,0,1)$. In general if we restrict valid inputs to be of length $L$, then a valid input is a tuple of the form $\{-1,0,1\}^L$. I've been self-learning some algebra on the side, and was realizing that these valid inputs start to look like a vector space. To illustrate in the case of $L=3$: we can sometimes add these inputs nicely element-wise: $(0,1,-1) + (1,0,1) = (1,1,0)$ we have an additive neutral element $(0,0,0)$ we can multiply inputs element-wise by scalars from $(-1,1,0)$ under element-wise addition each element has an ""inverse"" in the sense that another sequence exists that sends it to the neutral element (but elements are not invertible) But we have a problem here! This is because we can't specify an input bigger than $1$ in absolute value to the pulser. We can model the pulser input as saturating so that the input $(1,-1) + (1,-1) = (1,-1)$. This implies that we do not have have associativity, as $-1+(1+1) = -1 + 1 = 0$ but $(-1+1)+1 = 0+1 = 1$. Upon realizing this, I began to wonder if there was some other acceptable way of defining the group operation to both faithfully model the tri-state pulser but also get an actual group structure. Inputs are really a sort of ""direct sum"" of individual inputs, and so we can consider the problem at the individual input level. Unfortunately, there is only one unique group (up to isomorphism) with three elements, and this is the cyclic group $\mathbb{Z}/3\mathbb{Z}$. Unfortunately, it makes no physical sense to say that providing a very high input voltage level (ex. $6$) to the pulser should be the same thing as providing zero voltage to the pulser. So the cyclic group doesn't seem to provide a good model. So we have a structure that superficially looks like a vector space, where: ""addition"" is commutative, but not associative ""addition"" has an additive neutral, and ""inverses"" exist multiplication by a scalar is defined, has identity, and is distributive What algebraic object is this? (Parenthetical follow-up: Is group theory really the right tool to try and understand this structure? Any introductory book or course note recommendations on the fields of mathematics that study these weird structures are appreciated).","I'm currently working with a ""tri-state pulser"" in an engineering context. To excite a response from this device, one provides a voltage sequence consisting of elements from $\{-1,0,1\}$. For example, a valid input looks something like this: One can write out the shape of this input as a sequence: $(-1,1,0,0,-1,0,1)$. In general if we restrict valid inputs to be of length $L$, then a valid input is a tuple of the form $\{-1,0,1\}^L$. I've been self-learning some algebra on the side, and was realizing that these valid inputs start to look like a vector space. To illustrate in the case of $L=3$: we can sometimes add these inputs nicely element-wise: $(0,1,-1) + (1,0,1) = (1,1,0)$ we have an additive neutral element $(0,0,0)$ we can multiply inputs element-wise by scalars from $(-1,1,0)$ under element-wise addition each element has an ""inverse"" in the sense that another sequence exists that sends it to the neutral element (but elements are not invertible) But we have a problem here! This is because we can't specify an input bigger than $1$ in absolute value to the pulser. We can model the pulser input as saturating so that the input $(1,-1) + (1,-1) = (1,-1)$. This implies that we do not have have associativity, as $-1+(1+1) = -1 + 1 = 0$ but $(-1+1)+1 = 0+1 = 1$. Upon realizing this, I began to wonder if there was some other acceptable way of defining the group operation to both faithfully model the tri-state pulser but also get an actual group structure. Inputs are really a sort of ""direct sum"" of individual inputs, and so we can consider the problem at the individual input level. Unfortunately, there is only one unique group (up to isomorphism) with three elements, and this is the cyclic group $\mathbb{Z}/3\mathbb{Z}$. Unfortunately, it makes no physical sense to say that providing a very high input voltage level (ex. $6$) to the pulser should be the same thing as providing zero voltage to the pulser. So the cyclic group doesn't seem to provide a good model. So we have a structure that superficially looks like a vector space, where: ""addition"" is commutative, but not associative ""addition"" has an additive neutral, and ""inverses"" exist multiplication by a scalar is defined, has identity, and is distributive What algebraic object is this? (Parenthetical follow-up: Is group theory really the right tool to try and understand this structure? Any introductory book or course note recommendations on the fields of mathematics that study these weird structures are appreciated).",,"['abstract-algebra', 'reference-request', 'mathematical-modeling', 'universal-algebra']"
94,Only one group having $\mathbf{M}_3$ as its lattice of subgroups,Only one group having  as its lattice of subgroups,\mathbf{M}_3,"The problem. Consider the lattice $\mathbf{M}_3$ below Clearly, this is the lattice of subgroups of $\mathbb{Z}_2^2$ (isomorphic to the Klein four-group $\mathbf{V}_4$), taking $A = \langle (0,1) \rangle$, $B = \langle (1,0) \rangle$ and $C = \langle (1,1) \rangle$. I want to show that, up to isomorphism, this is the only group $G$ having $\mathbf{M}_3$ as its lattice of subgroups. My solution. To start with, clearly $G$ is finite. In this case, since  $$A \cap B = B \cap C = C \cap A = \{1\},$$ we have that $$|AB| = |A|\cdot |B|, \quad |BC| = |B|\cdot|C|, \quad |CA|=|C|\cdot|A|,$$ and $$|G| = (|A|-1) + (|B|-1) + (|C|-1) + 1 = |A|+|B|+|C|-2.$$ Since $A,B,C$ are minimal, they are cyclic of prime orders, $p_A, p_B, p_C$. First case. Suppose that $p_A, p_B, p_C$ are all different. As conjugate subgroups are isomorphic, it follows that $A,B,C \triangleleft G$, whence $AB, BC, CA \leq G$ and thus, in our specific case, $AB=BC=CA = G$, yielding $$|G| = p_Ap_B = p_Bp_C = p_Cp_A,$$ whence $p_A=p_B=p_C$, a contradiction with the hypothesis. Second case. Suppose $p_A \neq p_B=p_C$. In this case $A \triangleleft G$, whence $AB, AC \leq G$ and $|G| = |A|\cdot|B| = p_Ap_B$. By the First Theorem of Sylow, $G$ has a Sylow $p_B$-subgroup $P$ of order $p_B$. Necessarily $P=B$ or $P=C$ and since $|B|=|C|$, they both are Sylow  $p_B$-subgroups of $G$ and $n_{p_B}=2$. By the Third Theorem of Sylow, $n_{p_B} | p_A$, whence $p_A=2$ and $|G|=2p_B$.  So  $$p_B^2 = |BC| \leq 2p_B,$$ whence $p_B \leq 2$ and thus, $p_A=p_B=p_C=2$, again, a contradiction. Third case. Suppose that $p_A=p_B=p_C=p$. If $q \neq p$ is another prime number dividing $|G|$, then $G$ has a Sylow $q$-subgroup, which is a contradiction because all proper non-trivial subgroups of $G$ have order $p$. Hence $$|G|=p^r,$$ for some $r>1$ (it can't be $r=1$ because $G$ has non-trivial proper subgroups). $$r \geq 2 \quad\text{because}\quad p^2 = |AB| \leq |G|,$$ $$r \leq 3 \quad\text{because}\quad |G| \leq |A|\cdot |B|\cdot|C|.$$ Recall that, in this case, $|G|=3p-2$. If $|G|=p^3$, then $$0 = p^3 -3p + 2 = (p+2)(p-1)^2,$$ whence $p=-2$, which is, of course, impossible; or $p=1$ which is not a prime (and $G$ would be trivial). Therefore $|G|=p^2$ and  $$0 = p^2 - 3p + 2 = (p - 1)(p - 2),$$ yielding $p=2$, since, again, $G$ is not trivial. So $|A|=|B|=|C|=2$ and thus $G$ is an exponent $2$ group, whence abelian and having order $4$. This is enough to fully determine $G$. My questions. I suspect that there is a much simpler proof, without going through all those cases and using elementary group theory (but I'm not claiming this one's advanced...). I would welcome a concise (and elementary) proof even if you don't want to take the time to read through all the above. Anyway, is this all right? Thanks in advance!","The problem. Consider the lattice $\mathbf{M}_3$ below Clearly, this is the lattice of subgroups of $\mathbb{Z}_2^2$ (isomorphic to the Klein four-group $\mathbf{V}_4$), taking $A = \langle (0,1) \rangle$, $B = \langle (1,0) \rangle$ and $C = \langle (1,1) \rangle$. I want to show that, up to isomorphism, this is the only group $G$ having $\mathbf{M}_3$ as its lattice of subgroups. My solution. To start with, clearly $G$ is finite. In this case, since  $$A \cap B = B \cap C = C \cap A = \{1\},$$ we have that $$|AB| = |A|\cdot |B|, \quad |BC| = |B|\cdot|C|, \quad |CA|=|C|\cdot|A|,$$ and $$|G| = (|A|-1) + (|B|-1) + (|C|-1) + 1 = |A|+|B|+|C|-2.$$ Since $A,B,C$ are minimal, they are cyclic of prime orders, $p_A, p_B, p_C$. First case. Suppose that $p_A, p_B, p_C$ are all different. As conjugate subgroups are isomorphic, it follows that $A,B,C \triangleleft G$, whence $AB, BC, CA \leq G$ and thus, in our specific case, $AB=BC=CA = G$, yielding $$|G| = p_Ap_B = p_Bp_C = p_Cp_A,$$ whence $p_A=p_B=p_C$, a contradiction with the hypothesis. Second case. Suppose $p_A \neq p_B=p_C$. In this case $A \triangleleft G$, whence $AB, AC \leq G$ and $|G| = |A|\cdot|B| = p_Ap_B$. By the First Theorem of Sylow, $G$ has a Sylow $p_B$-subgroup $P$ of order $p_B$. Necessarily $P=B$ or $P=C$ and since $|B|=|C|$, they both are Sylow  $p_B$-subgroups of $G$ and $n_{p_B}=2$. By the Third Theorem of Sylow, $n_{p_B} | p_A$, whence $p_A=2$ and $|G|=2p_B$.  So  $$p_B^2 = |BC| \leq 2p_B,$$ whence $p_B \leq 2$ and thus, $p_A=p_B=p_C=2$, again, a contradiction. Third case. Suppose that $p_A=p_B=p_C=p$. If $q \neq p$ is another prime number dividing $|G|$, then $G$ has a Sylow $q$-subgroup, which is a contradiction because all proper non-trivial subgroups of $G$ have order $p$. Hence $$|G|=p^r,$$ for some $r>1$ (it can't be $r=1$ because $G$ has non-trivial proper subgroups). $$r \geq 2 \quad\text{because}\quad p^2 = |AB| \leq |G|,$$ $$r \leq 3 \quad\text{because}\quad |G| \leq |A|\cdot |B|\cdot|C|.$$ Recall that, in this case, $|G|=3p-2$. If $|G|=p^3$, then $$0 = p^3 -3p + 2 = (p+2)(p-1)^2,$$ whence $p=-2$, which is, of course, impossible; or $p=1$ which is not a prime (and $G$ would be trivial). Therefore $|G|=p^2$ and  $$0 = p^2 - 3p + 2 = (p - 1)(p - 2),$$ yielding $p=2$, since, again, $G$ is not trivial. So $|A|=|B|=|C|=2$ and thus $G$ is an exponent $2$ group, whence abelian and having order $4$. This is enough to fully determine $G$. My questions. I suspect that there is a much simpler proof, without going through all those cases and using elementary group theory (but I'm not claiming this one's advanced...). I would welcome a concise (and elementary) proof even if you don't want to take the time to read through all the above. Anyway, is this all right? Thanks in advance!",,"['abstract-algebra', 'group-theory', 'proof-verification']"
95,Show: If some $x_i \neq x_1$ occurs as $\sigma(x_1)$ for a $\sigma \in$ Gal$ (E:F)$ then each $x_i\neq x_1$ occurs as $\sigma(x_1)$,Show: If some  occurs as  for a  Gal then each  occurs as,x_i \neq x_1 \sigma(x_1) \sigma \in  (E:F) x_i\neq x_1 \sigma(x_1),"I'm currently studying Galois Theory (or am trying to do so), and since almost two weeks I try over and over again to solve a particular question from a textbook (J. Stillwell, Elements of Algebra, p. 132). Task: Consider the extension $E=F(x_1)$ of $ F=\mathbb{Q}(a_0,...,a_4)$. $x_1$ is a root of the quintic $x^5+a_4 x^4 + ... + a_0 =0$ (the other four roots being depicted as $x_2$ to $x_5$). Show (i) $\sigma \in$ Gal$(E:F)$ is determined by the value $\sigma(x_1)$. (ii) $\sigma(x_1)$ is a root of $x^5+a_4 x^4 + ... + a_0 =0$, hence $|$Gal$(E:F)| <= 5$. (iii) If some $x_i \neq x_1$ occurs as $\sigma(x_1)$ for a $\sigma \in $ Gal$ (E:F)$ then each $x_i\neq x_1$ occurs as $\sigma(x_1)$ It turned out that irreducibility of the quintic over F, although not stated explicitly, is absolutely necessary for claim (iii) to be true, see comments below. I had little trouble to show (i) and (ii), but (iii) is giving me a headache permanently. Here is what I tried: ==================================================================== (Trial A) Suppose $\sigma(x_1) = x_2$, and $\sigma \in $ Gal$(E:F)$. Then: $\Rightarrow \sigma(f) = f $ for all $ f\in F$ by definition of Galois Groups, and $x_i \in E$ since $\sigma$ is an automorphism on E. $\Rightarrow $ There must be a rational function $q$ of $x_2$ with $x_1 = q(x_2)$, because $x_1$ must be the result for one $\sigma(q(x_1)) = q(\sigma(x_1)) = q(x_2)$ $\Rightarrow x_2 = \sigma(x_1)=\sigma(q(x_2)) = q(x_1)$ and thus: $\sigma^2(x_1)=\sigma(x_2)=q(\sigma(x_1))=q(x_2)=x_1$. Thus $\sigma$ is its own inverse. This was not correct, see comment below.  Thus the next conclusion is wrong, also. $\Rightarrow $ Now $\{1,\sigma\}$ is closed under multiplication, it is easy to see that it is a group. Although I don't know whether it actually *is* the Galois-Group of E over F, it could be. At least I don't see a reason from here why it shouldn't be fine, or why I would have to include more $x_i$ necessarily. EDIT#2: From this point I tried to construct a counterexample to the statement to be shown, in order to see which are the obstacles. If I have two roots $x_1$ and $x_2$ with a corresponding automorphism, I can choose the other three roots as definitely lying outside of $\mathbb{Q}(a_0,...,a_4,x_1)$. Then with $ (x-x_1)(x-x_2)(x-x_3)(x-x_4)(x-x_5)$ I have a polynomial with three roots outside of $E$, contradicting the statement to be shown. Reason: if $x_i \notin  E$ there cannot be an automorphism $\sigma \in $ Gal$ (E:F)$ with $\sigma(e) = x_i$ for some $e \in E$. However, the field $F=\mathbb{Q}(a_0, ...a_4)$ is determined by the choice of $x_3, x_4$ and $x_5$, via the $a_i$. Thus it is still possible that I cannot find roots outside $F$ just by this feedback behavior. This would again point towards some argument of the kind: Because two roots are fixed, the others will be in $\mathbb{Q}(a_0, ...a_4)$ since they can be calculated by $x_1$, $x_2$ and the $a_i$. What to do from here...? ==================================================================== (Trial B) The next try was to go over the symmetric elementary polynomials $a_1,...,a_4$. If I assumed two roots $x_1$ and $x_2$ to lie in $E$, is it possible to calculate the other roots from the $a_i$? Well, it seems to be. That means that with $x_1$ and $x_2$ in $E$ all the others would lie in $E$, too, and it remains to show that the corresponding automorphisms exist. But I only could hack it with mathematica, and the result is rather complicated. I doubt that this was the authors intention. Additionally, I cannot see why then it shouldn't be possible to calculate four roots out of $x_1$, with the five elementary polynomials. EDIT#1: I discovered a serious misinterpretation in my Trial B. I can compute expressions $f(a_0, ...,a_4)$ for each $x_3, x_4$ and $x_5$, respectively. But they contain $\sqrt{}$ and $\sqrt[3]{}$ operations, and thus are not in $E = \mathbb{Q}(a_0,...,a_4,x_1)$. If I'm right, this rules out Trial B as an appropriate way to show what is asked. It must have something to do with the automorphisms in general, some symmetry-argument maybe, but I don't know. As I see it according to the solution of Jyrki, the a_i do indeed determine which x_i are in E and what the automorphisms are.  But this is shown via the general properties of E, not by direct calculation. Please, can someone help me?","I'm currently studying Galois Theory (or am trying to do so), and since almost two weeks I try over and over again to solve a particular question from a textbook (J. Stillwell, Elements of Algebra, p. 132). Task: Consider the extension $E=F(x_1)$ of $ F=\mathbb{Q}(a_0,...,a_4)$. $x_1$ is a root of the quintic $x^5+a_4 x^4 + ... + a_0 =0$ (the other four roots being depicted as $x_2$ to $x_5$). Show (i) $\sigma \in$ Gal$(E:F)$ is determined by the value $\sigma(x_1)$. (ii) $\sigma(x_1)$ is a root of $x^5+a_4 x^4 + ... + a_0 =0$, hence $|$Gal$(E:F)| <= 5$. (iii) If some $x_i \neq x_1$ occurs as $\sigma(x_1)$ for a $\sigma \in $ Gal$ (E:F)$ then each $x_i\neq x_1$ occurs as $\sigma(x_1)$ It turned out that irreducibility of the quintic over F, although not stated explicitly, is absolutely necessary for claim (iii) to be true, see comments below. I had little trouble to show (i) and (ii), but (iii) is giving me a headache permanently. Here is what I tried: ==================================================================== (Trial A) Suppose $\sigma(x_1) = x_2$, and $\sigma \in $ Gal$(E:F)$. Then: $\Rightarrow \sigma(f) = f $ for all $ f\in F$ by definition of Galois Groups, and $x_i \in E$ since $\sigma$ is an automorphism on E. $\Rightarrow $ There must be a rational function $q$ of $x_2$ with $x_1 = q(x_2)$, because $x_1$ must be the result for one $\sigma(q(x_1)) = q(\sigma(x_1)) = q(x_2)$ $\Rightarrow x_2 = \sigma(x_1)=\sigma(q(x_2)) = q(x_1)$ and thus: $\sigma^2(x_1)=\sigma(x_2)=q(\sigma(x_1))=q(x_2)=x_1$. Thus $\sigma$ is its own inverse. This was not correct, see comment below.  Thus the next conclusion is wrong, also. $\Rightarrow $ Now $\{1,\sigma\}$ is closed under multiplication, it is easy to see that it is a group. Although I don't know whether it actually *is* the Galois-Group of E over F, it could be. At least I don't see a reason from here why it shouldn't be fine, or why I would have to include more $x_i$ necessarily. EDIT#2: From this point I tried to construct a counterexample to the statement to be shown, in order to see which are the obstacles. If I have two roots $x_1$ and $x_2$ with a corresponding automorphism, I can choose the other three roots as definitely lying outside of $\mathbb{Q}(a_0,...,a_4,x_1)$. Then with $ (x-x_1)(x-x_2)(x-x_3)(x-x_4)(x-x_5)$ I have a polynomial with three roots outside of $E$, contradicting the statement to be shown. Reason: if $x_i \notin  E$ there cannot be an automorphism $\sigma \in $ Gal$ (E:F)$ with $\sigma(e) = x_i$ for some $e \in E$. However, the field $F=\mathbb{Q}(a_0, ...a_4)$ is determined by the choice of $x_3, x_4$ and $x_5$, via the $a_i$. Thus it is still possible that I cannot find roots outside $F$ just by this feedback behavior. This would again point towards some argument of the kind: Because two roots are fixed, the others will be in $\mathbb{Q}(a_0, ...a_4)$ since they can be calculated by $x_1$, $x_2$ and the $a_i$. What to do from here...? ==================================================================== (Trial B) The next try was to go over the symmetric elementary polynomials $a_1,...,a_4$. If I assumed two roots $x_1$ and $x_2$ to lie in $E$, is it possible to calculate the other roots from the $a_i$? Well, it seems to be. That means that with $x_1$ and $x_2$ in $E$ all the others would lie in $E$, too, and it remains to show that the corresponding automorphisms exist. But I only could hack it with mathematica, and the result is rather complicated. I doubt that this was the authors intention. Additionally, I cannot see why then it shouldn't be possible to calculate four roots out of $x_1$, with the five elementary polynomials. EDIT#1: I discovered a serious misinterpretation in my Trial B. I can compute expressions $f(a_0, ...,a_4)$ for each $x_3, x_4$ and $x_5$, respectively. But they contain $\sqrt{}$ and $\sqrt[3]{}$ operations, and thus are not in $E = \mathbb{Q}(a_0,...,a_4,x_1)$. If I'm right, this rules out Trial B as an appropriate way to show what is asked. It must have something to do with the automorphisms in general, some symmetry-argument maybe, but I don't know. As I see it according to the solution of Jyrki, the a_i do indeed determine which x_i are in E and what the automorphisms are.  But this is shown via the general properties of E, not by direct calculation. Please, can someone help me?",,"['abstract-algebra', 'group-theory', 'permutations', 'galois-theory', 'quintics']"
96,Given normal subgroup $\cong \mathbb{Z}$ and Quotient $\cong\mathbb{Z}/n\mathbb{Z}$ determine $G$.,Given normal subgroup  and Quotient  determine .,\cong \mathbb{Z} \cong\mathbb{Z}/n\mathbb{Z} G,"Let $N$ be a subgroup of $G$ isomorphic to $\mathbb{Z}$. suppose $G/N$ is isomorphic to $\mathbb{Z}/n\mathbb{Z}$. prove that if $n$ is odd, $G$ is abelian. I’ve reduced the problem to showing that if $N$ is central, then $G$ is abelian simply by playing around with the elements. But from there I’m kind of stuck. My main issue is that I cannot find an example of what goes wrong when $n$ is not odd. The only examples for $G$ and $N$ that I can think of are the usual $\mathbb{Z}$ and $n\mathbb{Z}$ respectively, and direct sums like $\mathbb{Z}\times \mathbb{Z}/n\mathbb{Z}$ and $\mathbb{Z}\times ${1}$ respectively. Any help is appreciated.","Let $N$ be a subgroup of $G$ isomorphic to $\mathbb{Z}$. suppose $G/N$ is isomorphic to $\mathbb{Z}/n\mathbb{Z}$. prove that if $n$ is odd, $G$ is abelian. I’ve reduced the problem to showing that if $N$ is central, then $G$ is abelian simply by playing around with the elements. But from there I’m kind of stuck. My main issue is that I cannot find an example of what goes wrong when $n$ is not odd. The only examples for $G$ and $N$ that I can think of are the usual $\mathbb{Z}$ and $n\mathbb{Z}$ respectively, and direct sums like $\mathbb{Z}\times \mathbb{Z}/n\mathbb{Z}$ and $\mathbb{Z}\times ${1}$ respectively. Any help is appreciated.",,"['abstract-algebra', 'group-theory']"
97,Ring homomorphism from $Z_m$ to $Z_n$ where $a^2=a$ but $a\neq\phi(1)$.,Ring homomorphism from  to  where  but .,Z_m Z_n a^2=a a\neq\phi(1),"Suppose $\phi$ is a ring homomorphism from $Z_m$ to $Z_n$. Prove if $\phi(1)=a$ then $a^2=a$. Give an example to show the converse is false. The first part I found easy enough. $$a^2=\phi(1)^2=\phi(1^2)=a$$ Now I have trouble to negate the converse. Here is the initial statement: $$\forall\phi:Z_m\rightarrow Z_n,\quad\forall a\in Z_n,\quad\phi(1)=a\implies a^2=a\tag{1}$$ Converse of $(1)$: $$\forall\phi:Z_m\rightarrow Z_n,\quad\forall a\in Z_n,\quad a^2=a\implies\phi(1)=a\tag{2}$$ Negation of $(2)$: $$\exists\phi:Z_m\rightarrow Z_n,\quad\exists a\in Z_n,\quad a^2=a\land\phi(1)\neq a\tag{3}$$ which is what we prove. Choose the homomorphism $\phi:x\mapsto x\cdot1$. $\phi(1)=1$. Choose $a=0=0^2$. We have negated $(3)$. Yeah?","Suppose $\phi$ is a ring homomorphism from $Z_m$ to $Z_n$. Prove if $\phi(1)=a$ then $a^2=a$. Give an example to show the converse is false. The first part I found easy enough. $$a^2=\phi(1)^2=\phi(1^2)=a$$ Now I have trouble to negate the converse. Here is the initial statement: $$\forall\phi:Z_m\rightarrow Z_n,\quad\forall a\in Z_n,\quad\phi(1)=a\implies a^2=a\tag{1}$$ Converse of $(1)$: $$\forall\phi:Z_m\rightarrow Z_n,\quad\forall a\in Z_n,\quad a^2=a\implies\phi(1)=a\tag{2}$$ Negation of $(2)$: $$\exists\phi:Z_m\rightarrow Z_n,\quad\exists a\in Z_n,\quad a^2=a\land\phi(1)\neq a\tag{3}$$ which is what we prove. Choose the homomorphism $\phi:x\mapsto x\cdot1$. $\phi(1)=1$. Choose $a=0=0^2$. We have negated $(3)$. Yeah?",,[]
98,Isomorphically comparing normal subgroups and their quotient groups,Isomorphically comparing normal subgroups and their quotient groups,,"1 . Find a finite group G and two normal subgroups A and B such that $A \cong B$ but $G/A \ncong G/B$. Let $G=\mathbb{Z}_4 \times \mathbb{Z}_2$ (which is abelian), $A= \langle(2,0)\rangle$ and $B=\langle(0,1)\rangle$. Then $(1,0)+B$ has order 4, hence $G/B$ is cyclic; whereas $G/A = \{A, (1,0)+A, (0,1)+A, (1,1)+A \}$ is not cyclic because every non-zero element has order $2$. Therefore $G/A \ncong G/B$. 2 . Find a finite group G and two normal subgroups A and B such that $A \ncong B$ but $G/A \cong G/B$. Let $G=D_4$ the dihedral group with $8$ elements, then both $A=\langle \rho_{\pi/2} \rangle$ and $B=\langle\rho_\pi, \iota, \iota_{\pi}\rangle$ have order $4$, hence they have index $2$ which implies that they are normal and that their quotient groups are isomorphic, but $B$ is not cyclic so $A\ncong B$. Note that $\rho_\theta$ indicates the rotation of an angle $\theta$ counterclockwise, while $\iota_\theta$ is the reflection through the line that form an angle $\theta/2$ with the x-axis. Do you think these solutions are correct?","1 . Find a finite group G and two normal subgroups A and B such that $A \cong B$ but $G/A \ncong G/B$. Let $G=\mathbb{Z}_4 \times \mathbb{Z}_2$ (which is abelian), $A= \langle(2,0)\rangle$ and $B=\langle(0,1)\rangle$. Then $(1,0)+B$ has order 4, hence $G/B$ is cyclic; whereas $G/A = \{A, (1,0)+A, (0,1)+A, (1,1)+A \}$ is not cyclic because every non-zero element has order $2$. Therefore $G/A \ncong G/B$. 2 . Find a finite group G and two normal subgroups A and B such that $A \ncong B$ but $G/A \cong G/B$. Let $G=D_4$ the dihedral group with $8$ elements, then both $A=\langle \rho_{\pi/2} \rangle$ and $B=\langle\rho_\pi, \iota, \iota_{\pi}\rangle$ have order $4$, hence they have index $2$ which implies that they are normal and that their quotient groups are isomorphic, but $B$ is not cyclic so $A\ncong B$. Note that $\rho_\theta$ indicates the rotation of an angle $\theta$ counterclockwise, while $\iota_\theta$ is the reflection through the line that form an angle $\theta/2$ with the x-axis. Do you think these solutions are correct?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'examples-counterexamples']"
99,A characterization for idempotent lifting property,A characterization for idempotent lifting property,,"Let $I$ be an ideal in a commutative ring $R$ with $1$ and let $g+I$ be an idempotent element of $R/I$. We say that this idempotent can be lifted  modulo $I$ in case there is an idempotent $e^2=e\in R$ such that $g + I = e + I$ ($g-e\in I$). Question: Is there any characterization for $I$ under which idempotents  lift modulo $I$, that is, every idempotent of $R/I$ lifts modulo $I$? And is there any comprehensive reference for this property?","Let $I$ be an ideal in a commutative ring $R$ with $1$ and let $g+I$ be an idempotent element of $R/I$. We say that this idempotent can be lifted  modulo $I$ in case there is an idempotent $e^2=e\in R$ such that $g + I = e + I$ ($g-e\in I$). Question: Is there any characterization for $I$ under which idempotents  lift modulo $I$, that is, every idempotent of $R/I$ lifts modulo $I$? And is there any comprehensive reference for this property?",,"['abstract-algebra', 'algebraic-geometry', 'ring-theory', 'commutative-algebra', 'idempotents']"
