,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Integral $\int_0^1 \frac{2x-1}{1+x-x^2}\left(4\ln x\ln(1+x)-\ln^2(1+x)\right)dx$,Integral,\int_0^1 \frac{2x-1}{1+x-x^2}\left(4\ln x\ln(1+x)-\ln^2(1+x)\right)dx,"The following problem was posted earlier this year by Cornel Ioan Valean: Prove that $$I=\int_0^1 \frac{2x-1}{1+x-x^2}\left(4\ln x\ln(1+x)-\ln^2(1+x)\right)dx=\frac{127}{20}\zeta(3)-\frac{8\pi^2}{5}\ln(\varphi)$$ My idea was to consider the following integral: $$\mathcal J(a)=\int_0^1 \frac{2x-1}{1+x-x^2}\ln(a+x)\ln(1+x)dx$$ So $I=4\mathcal J(0)-\mathcal J(1)$ . In order to evaluate $\mathcal J(a)$ I tried to apply Feynman's trick: $$\mathcal J'(a)=\int_0^1 \frac{\ln(1+x)}{a+x}\frac{dx}{\varphi-x}-\int_0^1 \frac{\ln(1+x)}{a+x}\frac{dx}{\frac{1}{\varphi}+x},\quad \varphi=\frac{1+\sqrt 5}{2}$$ $$\small =\frac{1}{a+\varphi}\int_0^1 \frac{\ln(1+x)}{a+x}dx+\frac{1}{a+\varphi}\int_0^1 \frac{\ln(1+x)}{\varphi-x}dx+\frac{1}{a-\frac{1}{\varphi}}\int_0^1 \frac{\ln(1+x)}{a+x}dx-\frac{1}{a-\frac{1}{\varphi}}\int_0^1 \frac{\ln(1+x)}{\frac{1}{\varphi}+x}dx$$ But I gave up on this idea after I realised that: $$\int_0^1 \frac{\ln(1+x)}{t+x}dx=\ln 2\ln \left(\frac{t+1}{t-1}\right)+\operatorname{Li}_2\left(\frac{2}{1-t}\right)-\operatorname{Li}_2\left(\frac{1}{1-t}\right)$$ Where $\operatorname{Li}_2(x)$ is the Dilogarithm. Other methods weren't promising either, such as the substitution $x=\frac{1-t}{1+t}$ , to combine the integral with it's sister one that has the denominator $1-x+x^2$ , or to integrate by parts which gives: $$\small 2I=2\int_0^1 \frac{\ln(1+x-x^2)\ln x}{1+x}dx+2\int_0^1 \frac{\ln(1+x-x^2)\ln(1+x)}{x}dx-\int_0^1 \frac{\ln(1+x-x^2)\ln (1+x)}{1+x}dx$$ I believe that the factor of $4$ plays a big role into obtain nicely this result and one shouldn't split the integral into two parts, but I had no success and I would appreciate some help.","The following problem was posted earlier this year by Cornel Ioan Valean: Prove that My idea was to consider the following integral: So . In order to evaluate I tried to apply Feynman's trick: But I gave up on this idea after I realised that: Where is the Dilogarithm. Other methods weren't promising either, such as the substitution , to combine the integral with it's sister one that has the denominator , or to integrate by parts which gives: I believe that the factor of plays a big role into obtain nicely this result and one shouldn't split the integral into two parts, but I had no success and I would appreciate some help.","I=\int_0^1 \frac{2x-1}{1+x-x^2}\left(4\ln x\ln(1+x)-\ln^2(1+x)\right)dx=\frac{127}{20}\zeta(3)-\frac{8\pi^2}{5}\ln(\varphi) \mathcal J(a)=\int_0^1 \frac{2x-1}{1+x-x^2}\ln(a+x)\ln(1+x)dx I=4\mathcal J(0)-\mathcal J(1) \mathcal J(a) \mathcal J'(a)=\int_0^1 \frac{\ln(1+x)}{a+x}\frac{dx}{\varphi-x}-\int_0^1 \frac{\ln(1+x)}{a+x}\frac{dx}{\frac{1}{\varphi}+x},\quad \varphi=\frac{1+\sqrt 5}{2} \small =\frac{1}{a+\varphi}\int_0^1 \frac{\ln(1+x)}{a+x}dx+\frac{1}{a+\varphi}\int_0^1 \frac{\ln(1+x)}{\varphi-x}dx+\frac{1}{a-\frac{1}{\varphi}}\int_0^1 \frac{\ln(1+x)}{a+x}dx-\frac{1}{a-\frac{1}{\varphi}}\int_0^1 \frac{\ln(1+x)}{\frac{1}{\varphi}+x}dx \int_0^1 \frac{\ln(1+x)}{t+x}dx=\ln 2\ln \left(\frac{t+1}{t-1}\right)+\operatorname{Li}_2\left(\frac{2}{1-t}\right)-\operatorname{Li}_2\left(\frac{1}{1-t}\right) \operatorname{Li}_2(x) x=\frac{1-t}{1+t} 1-x+x^2 \small 2I=2\int_0^1 \frac{\ln(1+x-x^2)\ln x}{1+x}dx+2\int_0^1 \frac{\ln(1+x-x^2)\ln(1+x)}{x}dx-\int_0^1 \frac{\ln(1+x-x^2)\ln (1+x)}{1+x}dx 4","['integration', 'definite-integrals', 'logarithms', 'closed-form']"
1,"If $\Phi\geq 0$ is non-decreasing, does $\int_1^\infty \frac{\Phi(x)}{x^2}\,dx=\infty$ imply $\int_0^\infty e^{-\Phi(x)}\,dx<\infty$?","If  is non-decreasing, does  imply ?","\Phi\geq 0 \int_1^\infty \frac{\Phi(x)}{x^2}\,dx=\infty \int_0^\infty e^{-\Phi(x)}\,dx<\infty","Q. Suppose $\Phi : [0, \infty) \to [0, \infty)$ is a non-decreasing function. If $$ \int_{1}^{\infty} \frac{\Phi(x)}{x^2} \, \mathrm{d}x = \infty, $$ then does the inequality $$ \int_{0}^{\infty} e^{-\Phi(x)} \, \mathrm{d}x < \infty $$ hold? This question is motivated by this posting , but it became a statement of independent interest to me. I suspect that the statement is true, based on a naive observation that a higher growth rate of $\Phi$ is in favor of both conditions and a slower growth rate is against them. One obvious observation is that $\Phi(x)$ must tend to $\infty$ as $x \to \infty$ . But, to be honest, I have no clue as to where I should start. So I would like to invite you to this strange yet interesting problem! Edit. The user @Sungjin Kim showed that the answer is false by providing a family of counter-examples. Here is a simplification of his answer: For each strictly increasing sequence $(b_k)_{k=1}^{\infty}$ in $[1, \infty)$ , let $$ \Phi(t) = \sum_{k \mathop{:} b_k \leq t} b_k = \sum_{k=1}^{\infty} b_k \mathbf{1}_{[b_k, \infty)}(t). $$ Then it follows that $$ \int_{1}^{\infty} \frac{\Phi(t)}{t^2} \, \mathrm{d}t = \sum_{k=1}^{\infty} b_k \int_{b_k}^{\infty} \frac{\mathrm{d}t}{t^2} = \sum_{k=1}^{\infty} 1 = \infty. $$ On the other hand, since $\Phi(t) = \sum_{l=1}^{k} b_l$ for each $t \in [b_k, b_{k+1})$ , \begin{align*} \int_{0}^{\infty} e^{-\Phi(t)} \, \mathrm{d}t \geq \sum_{k=1}^{\infty} \int_{b_k}^{b_{k+1}} e^{-\Phi(t)} \, \mathrm{d}t = \sum_{k=1}^{\infty} (b_{k+1} - b_k) e^{-\sum_{l=1}^{k} b_l}. \end{align*} So by choosing $(b_{k+1})$ so that it satisfies $(b_{k+1} - b_k) e^{-\sum_{l=1}^{k} b_l} \geq 1$ for each $k$ , we have $$ \int_{0}^{\infty} e^{-\Phi(t)} \, \mathrm{d}t = \infty. $$","Q. Suppose is a non-decreasing function. If then does the inequality hold? This question is motivated by this posting , but it became a statement of independent interest to me. I suspect that the statement is true, based on a naive observation that a higher growth rate of is in favor of both conditions and a slower growth rate is against them. One obvious observation is that must tend to as . But, to be honest, I have no clue as to where I should start. So I would like to invite you to this strange yet interesting problem! Edit. The user @Sungjin Kim showed that the answer is false by providing a family of counter-examples. Here is a simplification of his answer: For each strictly increasing sequence in , let Then it follows that On the other hand, since for each , So by choosing so that it satisfies for each , we have","\Phi : [0, \infty) \to [0, \infty)  \int_{1}^{\infty} \frac{\Phi(x)}{x^2} \, \mathrm{d}x = \infty,   \int_{0}^{\infty} e^{-\Phi(x)} \, \mathrm{d}x < \infty  \Phi \Phi(x) \infty x \to \infty (b_k)_{k=1}^{\infty} [1, \infty)  \Phi(t) = \sum_{k \mathop{:} b_k \leq t} b_k = \sum_{k=1}^{\infty} b_k \mathbf{1}_{[b_k, \infty)}(t).   \int_{1}^{\infty} \frac{\Phi(t)}{t^2} \, \mathrm{d}t
= \sum_{k=1}^{\infty} b_k \int_{b_k}^{\infty} \frac{\mathrm{d}t}{t^2}
= \sum_{k=1}^{\infty} 1
= \infty.  \Phi(t) = \sum_{l=1}^{k} b_l t \in [b_k, b_{k+1}) \begin{align*}
\int_{0}^{\infty} e^{-\Phi(t)} \, \mathrm{d}t
\geq \sum_{k=1}^{\infty} \int_{b_k}^{b_{k+1}} e^{-\Phi(t)} \, \mathrm{d}t
= \sum_{k=1}^{\infty} (b_{k+1} - b_k) e^{-\sum_{l=1}^{k} b_l}.
\end{align*} (b_{k+1}) (b_{k+1} - b_k) e^{-\sum_{l=1}^{k} b_l} \geq 1 k  \int_{0}^{\infty} e^{-\Phi(t)} \, \mathrm{d}t = \infty. ","['integration', 'analysis']"
2,"$\int_{- \infty}^{\infty} \frac{f(x)}{1+\exp{g(x)}}dx=\int_{0}^{\infty} f(x) dx$ for $f(x)=f(-x),~g(x)=-g(-x)$ - are there other formulas like that?",for  - are there other formulas like that?,"\int_{- \infty}^{\infty} \frac{f(x)}{1+\exp{g(x)}}dx=\int_{0}^{\infty} f(x) dx f(x)=f(-x),~g(x)=-g(-x)","If $f(x)$ any even function, integrable on $(0,\infty)$ and $g(x)$ any odd function, then we have: $$\int_{- \infty}^{\infty} \frac{f(x)}{1+e^{g(x)}}dx=\int_{0}^{\infty} f(x) dx \tag{1}$$ The proof is elementary: $$I(a)=\int_{- \infty}^{\infty} \frac{f(x)}{a+e^{g(x)}}dx$$ $$I(1/a)=\int_{- \infty}^{\infty} \frac{f(x)}{1/a+e^{g(x)}}dx=a \int_{- \infty}^{\infty} \frac{e^{-g(x)}f(x)}{e^{-g(x)}+a}dx= \\ = a \int_{- \infty}^{\infty} f(x)dx-a^2\int_{- \infty}^{\infty} \frac{f(x)}{a+e^{g(x)}}dx$$ $$\frac{1}{a} I(1/a)+aI(a)=\int_{- \infty}^{\infty} f(x)dx$$ $$I(1)=\int_{0}^{\infty} f(x)dx$$ With this formula we can write some crazy looking integrals to scare people, like: $$\int_{- \infty}^{\infty} \frac{e^{-x^2}}{1+e^{\sin (\sinh x)+x^3-\arctan x}}dx=\frac{\sqrt{\pi}}{2}$$ To be fair, it might also be useful for some quatum statistics applications (i.e. Fermi-Dirac distribution). I want to know, what other formulas like $(1)$ exist? Maybe with the exponential function, or some other functions I also know of Glasser's Theorem , but I wonder if some more interesting cases exist. To be more specific, I mean the non-trivial formulas of the following kind: $$\int_{a}^b g(x) f(x) dx=k \int_{A}^B f(x) dx$$ With $k$ being some constant, independent on $f(x)$, $f(x)$ is a general function (with some restricitions), $g(x)$ is some interesting function. $A,B$ might be different from $a,b$, but also should not depend on $f(x)$.","If $f(x)$ any even function, integrable on $(0,\infty)$ and $g(x)$ any odd function, then we have: $$\int_{- \infty}^{\infty} \frac{f(x)}{1+e^{g(x)}}dx=\int_{0}^{\infty} f(x) dx \tag{1}$$ The proof is elementary: $$I(a)=\int_{- \infty}^{\infty} \frac{f(x)}{a+e^{g(x)}}dx$$ $$I(1/a)=\int_{- \infty}^{\infty} \frac{f(x)}{1/a+e^{g(x)}}dx=a \int_{- \infty}^{\infty} \frac{e^{-g(x)}f(x)}{e^{-g(x)}+a}dx= \\ = a \int_{- \infty}^{\infty} f(x)dx-a^2\int_{- \infty}^{\infty} \frac{f(x)}{a+e^{g(x)}}dx$$ $$\frac{1}{a} I(1/a)+aI(a)=\int_{- \infty}^{\infty} f(x)dx$$ $$I(1)=\int_{0}^{\infty} f(x)dx$$ With this formula we can write some crazy looking integrals to scare people, like: $$\int_{- \infty}^{\infty} \frac{e^{-x^2}}{1+e^{\sin (\sinh x)+x^3-\arctan x}}dx=\frac{\sqrt{\pi}}{2}$$ To be fair, it might also be useful for some quatum statistics applications (i.e. Fermi-Dirac distribution). I want to know, what other formulas like $(1)$ exist? Maybe with the exponential function, or some other functions I also know of Glasser's Theorem , but I wonder if some more interesting cases exist. To be more specific, I mean the non-trivial formulas of the following kind: $$\int_{a}^b g(x) f(x) dx=k \int_{A}^B f(x) dx$$ With $k$ being some constant, independent on $f(x)$, $f(x)$ is a general function (with some restricitions), $g(x)$ is some interesting function. $A,B$ might be different from $a,b$, but also should not depend on $f(x)$.",,"['integration', 'definite-integrals', 'exponential-function']"
3,Alternative and more direct proof that an integral is independent of a parameter,Alternative and more direct proof that an integral is independent of a parameter,,"I'm looking for alternative ways to calculate the integral $$ \int\limits_0^\infty\frac{\tanh(\alpha x)}{\tanh(\pi x)}\sin(2\alpha x^2)\,dx=\frac{1}{4},\qquad \alpha>0.\tag {*} $$ It was derived in a lengthy calculation using roundabout method from Fourier transform of a function of two variables. However, it seems like the integral (*) might have a simple proof? Note that when $\alpha=\pi$ , the the integral reduces to Fresnel integral $$ \int\limits_0^\infty\sin(2\pi x^2)\,dx=\frac{1}{4}. $$ Thus if one could prove that it is independent of the parameter $\alpha$ , then its value could be found.","I'm looking for alternative ways to calculate the integral It was derived in a lengthy calculation using roundabout method from Fourier transform of a function of two variables. However, it seems like the integral (*) might have a simple proof? Note that when , the the integral reduces to Fresnel integral Thus if one could prove that it is independent of the parameter , then its value could be found.","
\int\limits_0^\infty\frac{\tanh(\alpha x)}{\tanh(\pi x)}\sin(2\alpha x^2)\,dx=\frac{1}{4},\qquad \alpha>0.\tag {*}
 \alpha=\pi 
\int\limits_0^\infty\sin(2\pi x^2)\,dx=\frac{1}{4}.
 \alpha","['integration', 'definite-integrals', 'contour-integration', 'alternative-proof', 'trigonometric-integrals']"
4,Difficult integral for a marginal distribution,Difficult integral for a marginal distribution,,"I am trying to derive a marginal probability distribution for $y$ , and failed, having tried all methods to solve the following integral: $$ \operatorname{p}\left(y\right) = \int_0^{1/\sqrt{\,2\pi\,}}\!\!\!\! \frac{\sqrt{2/\pi}\,\,\mathrm{e}^{-y/\left(2z\right)}}{\sqrt{y\, z}\,\, \sqrt{-\log \left(2\pi\,z^2\right)}} \,\mathrm{d}z\quad \mbox{with}\quad y>0. $$ It is easy to verify that $$\int_0^\infty \int_0^{\frac{1}{\sqrt{2 \pi }}} \frac{\sqrt{\frac{2}{\pi }} e^{-\frac{y}{2 \,z}}}{\sqrt{y\, z} \sqrt{-\log \left(2 \pi \, z^2\right)}} \, \mathrm{d}z \,\mathrm{d}y=1$$ After some work, figured out that, remarkably, we can get the fist moment, $\mathbb{E}(y)=\frac{1}{2 \sqrt{\pi }}$ and $\mathbb{E}(y^2)=\frac{\sqrt{3}}{2 \pi }$ without the density.","I am trying to derive a marginal probability distribution for , and failed, having tried all methods to solve the following integral: It is easy to verify that After some work, figured out that, remarkably, we can get the fist moment, and without the density.","y 
\operatorname{p}\left(y\right) =
\int_0^{1/\sqrt{\,2\pi\,}}\!\!\!\!
\frac{\sqrt{2/\pi}\,\,\mathrm{e}^{-y/\left(2z\right)}}{\sqrt{y\, z}\,\, \sqrt{-\log \left(2\pi\,z^2\right)}}
\,\mathrm{d}z\quad \mbox{with}\quad y>0.
 \int_0^\infty \int_0^{\frac{1}{\sqrt{2 \pi }}} \frac{\sqrt{\frac{2}{\pi }} e^{-\frac{y}{2 \,z}}}{\sqrt{y\, z} \sqrt{-\log \left(2 \pi \, z^2\right)}} \, \mathrm{d}z \,\mathrm{d}y=1 \mathbb{E}(y)=\frac{1}{2 \sqrt{\pi }} \mathbb{E}(y^2)=\frac{\sqrt{3}}{2 \pi }","['integration', 'probability-theory', 'probability-distributions', 'definite-integrals', 'marginal-distribution']"
5,Is there a way to deal with this singularity in numerical integration?,Is there a way to deal with this singularity in numerical integration?,,"I would like to compute numerically, e.g., using the standard method of trapezes the following definite integral over the interface $[0,1]$ : $$ I = \int_0^1 \frac{f(x)}{\sqrt{1-x^2}} \, \mathrm{d} x \, ,  $$ where $f(x)$ is continuous in the interval [0,1].  It can readily be shown analytically that the integral is well convergent.  However, when proceeding numerically, difficulties arise since the integrand diverges at the upper limit of integration for $x=1$ . I was wondering whether there exists a procedure that can help to remove the singularity in this integral. Any help is highly appreciated Thank you, hartmut","I would like to compute numerically, e.g., using the standard method of trapezes the following definite integral over the interface : where is continuous in the interval [0,1].  It can readily be shown analytically that the integral is well convergent.  However, when proceeding numerically, difficulties arise since the integrand diverges at the upper limit of integration for . I was wondering whether there exists a procedure that can help to remove the singularity in this integral. Any help is highly appreciated Thank you, hartmut","[0,1] 
I = \int_0^1 \frac{f(x)}{\sqrt{1-x^2}} \, \mathrm{d} x \, , 
 f(x) x=1","['integration', 'definite-integrals', 'numerical-methods', 'improper-integrals']"
6,Relationship between Catalan's constant and $\pi$,Relationship between Catalan's constant and,\pi,"How related are $G$ (Catalan's constant) and $\pi$ ? I seem to encounter $G$ a lot when computing definite integrals involving logarithms and trig functions. Example: It is well known that $$G=\int_0^{\pi/4}\log\cot x\,\mathrm{d}x$$ So we see that $$G=\int_0^{\pi/4}\log\sin(x+\pi/2)\,\mathrm{d}x-\int_0^{\pi/4}\log\sin x\,\mathrm{d}x$$ So we set out on the evaluation of $$L(\phi)=\int_0^\phi\log\sin x\,\mathrm{d}x,\qquad \phi\in(0,\pi)$$ we recall that $$\sin x=x\prod_{n\geq1}\frac{\pi^2n^2-x^2}{\pi^2n^2}$$ Applying $\log$ on both sides, $$\log\sin x=\log x+\sum_{n\geq1}\log\frac{\pi^2n^2-x^2}{\pi^2n^2}$$ integrating both sides from $0$ to $\phi$ , $$L(\phi)=\phi(\log\phi-3)+\sum_{n\geq1}\phi\log\frac{\pi^2n^2-\phi^2}{\pi^2n^2}+\pi n\log\frac{\pi n+\phi}{\pi n-\phi}$$ With the substitution $u=x+\pi/2$ , $$ \begin{align} \int_0^\phi \log\cos x\,\mathrm{d}x=&\int_0^{\phi}\log\sin(x+\pi/2)\,\mathrm{d}x\\ =&\int_{\pi/2}^{\phi+\pi/2}\log\sin x\,\mathrm{d}x\\ =&\int_{0}^{\phi+\pi/2}\log\sin x\,\mathrm{d}x-\int_{0}^{\pi/2}\log\sin x\,\mathrm{d}x\\ =&L(\phi+\pi/2)+\frac\pi2\log2 \end{align} $$ So $$G=L\bigg(\frac{3\pi}4\bigg)-L\bigg(\frac\pi4\bigg)+\frac\pi2\log2$$ And after a lot of algebra, $$G=\frac\pi4\bigg(\log\frac{27\pi^2}{16}+2\log2-6\bigg)+\pi\sum_{n\geq1}\bigg[\frac14\log\frac{(16n^2-9)^3}{256n^4(16n^2-1)}+n\log\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg]$$ So yeah I guess I found a series for $G$ in terms of $\pi$ , but are there any other sort of these representations of $G$ in terms of $\pi$ ? really important edit As it turns out, the series $$\frac\pi4\bigg(\log\frac{27\pi^2}{16}+2\log2-6\bigg)+\pi\sum_{n\geq1}\bigg[\frac14\log\frac{(16n^2-9)^3}{256n^4(16n^2-1)}+n\log\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg]$$ does not converge, however it is a simple fix, and the series $$G=\frac\pi4\bigg(\log\frac{3\pi\sqrt{3}}2-1\bigg)+\pi\sum_{n\geq1}\bigg[\frac14\log\frac{(16n^2-9)^3}{256n^4(16n^2-1)}+n\log\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}-1\bigg]$$ does converge to $G$ . Quite amazingly, we can use this to find a really neat infinite product identity. Here's how. Using the rules of exponents and logarithms, we may see that $$\frac{G}\pi+\frac12-\log\bigg(3^{3/4}\sqrt{\frac\pi2}\bigg)=\sum_{n\geq1}\log\bigg[\frac1{4en}\bigg(\frac{(16n^2-9)^3}{16n^2-1}\bigg)^{1/4}\bigg(\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg)^n\bigg]$$ Then using the fact that $$\log\prod_{i}a_i=\sum_{i}\log a_i$$ We have $$\frac{G}\pi+\frac12-\log\bigg(3^{3/4}\sqrt{\frac\pi2}\bigg)=\log\bigg[\prod_{n\geq1}\frac1{4en}\bigg(\frac{(16n^2-9)^3}{16n^2-1}\bigg)^{1/4}\bigg(\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg)^n\bigg]$$ Then taking $\exp$ on both sides, $$\prod_{n\geq1}\frac1{4en}\bigg(\frac{(16n^2-9)^3}{16n^2-1}\bigg)^{1/4}\bigg(\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg)^n=\sqrt{\frac{2e}{3\pi\sqrt{3}}}e^{G/\pi}$$ Or perhaps more aesthetically, $$\prod_{n\geq1}\frac1{4en}\bigg(\frac{(16n^2-9)^3}{16n^2-1}\bigg)^{1/4}\bigg(\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg)^n=\sqrt{\frac{2}{3\pi\sqrt{3}}}\exp\bigg(\frac{G}{\pi}+\frac12\bigg)$$","How related are (Catalan's constant) and ? I seem to encounter a lot when computing definite integrals involving logarithms and trig functions. Example: It is well known that So we see that So we set out on the evaluation of we recall that Applying on both sides, integrating both sides from to , With the substitution , So And after a lot of algebra, So yeah I guess I found a series for in terms of , but are there any other sort of these representations of in terms of ? really important edit As it turns out, the series does not converge, however it is a simple fix, and the series does converge to . Quite amazingly, we can use this to find a really neat infinite product identity. Here's how. Using the rules of exponents and logarithms, we may see that Then using the fact that We have Then taking on both sides, Or perhaps more aesthetically,","G \pi G G=\int_0^{\pi/4}\log\cot x\,\mathrm{d}x G=\int_0^{\pi/4}\log\sin(x+\pi/2)\,\mathrm{d}x-\int_0^{\pi/4}\log\sin x\,\mathrm{d}x L(\phi)=\int_0^\phi\log\sin x\,\mathrm{d}x,\qquad \phi\in(0,\pi) \sin x=x\prod_{n\geq1}\frac{\pi^2n^2-x^2}{\pi^2n^2} \log \log\sin x=\log x+\sum_{n\geq1}\log\frac{\pi^2n^2-x^2}{\pi^2n^2} 0 \phi L(\phi)=\phi(\log\phi-3)+\sum_{n\geq1}\phi\log\frac{\pi^2n^2-\phi^2}{\pi^2n^2}+\pi n\log\frac{\pi n+\phi}{\pi n-\phi} u=x+\pi/2 
\begin{align}
\int_0^\phi \log\cos x\,\mathrm{d}x=&\int_0^{\phi}\log\sin(x+\pi/2)\,\mathrm{d}x\\
=&\int_{\pi/2}^{\phi+\pi/2}\log\sin x\,\mathrm{d}x\\
=&\int_{0}^{\phi+\pi/2}\log\sin x\,\mathrm{d}x-\int_{0}^{\pi/2}\log\sin x\,\mathrm{d}x\\
=&L(\phi+\pi/2)+\frac\pi2\log2
\end{align}
 G=L\bigg(\frac{3\pi}4\bigg)-L\bigg(\frac\pi4\bigg)+\frac\pi2\log2 G=\frac\pi4\bigg(\log\frac{27\pi^2}{16}+2\log2-6\bigg)+\pi\sum_{n\geq1}\bigg[\frac14\log\frac{(16n^2-9)^3}{256n^4(16n^2-1)}+n\log\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg] G \pi G \pi \frac\pi4\bigg(\log\frac{27\pi^2}{16}+2\log2-6\bigg)+\pi\sum_{n\geq1}\bigg[\frac14\log\frac{(16n^2-9)^3}{256n^4(16n^2-1)}+n\log\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg] G=\frac\pi4\bigg(\log\frac{3\pi\sqrt{3}}2-1\bigg)+\pi\sum_{n\geq1}\bigg[\frac14\log\frac{(16n^2-9)^3}{256n^4(16n^2-1)}+n\log\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}-1\bigg] G \frac{G}\pi+\frac12-\log\bigg(3^{3/4}\sqrt{\frac\pi2}\bigg)=\sum_{n\geq1}\log\bigg[\frac1{4en}\bigg(\frac{(16n^2-9)^3}{16n^2-1}\bigg)^{1/4}\bigg(\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg)^n\bigg] \log\prod_{i}a_i=\sum_{i}\log a_i \frac{G}\pi+\frac12-\log\bigg(3^{3/4}\sqrt{\frac\pi2}\bigg)=\log\bigg[\prod_{n\geq1}\frac1{4en}\bigg(\frac{(16n^2-9)^3}{16n^2-1}\bigg)^{1/4}\bigg(\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg)^n\bigg] \exp \prod_{n\geq1}\frac1{4en}\bigg(\frac{(16n^2-9)^3}{16n^2-1}\bigg)^{1/4}\bigg(\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg)^n=\sqrt{\frac{2e}{3\pi\sqrt{3}}}e^{G/\pi} \prod_{n\geq1}\frac1{4en}\bigg(\frac{(16n^2-9)^3}{16n^2-1}\bigg)^{1/4}\bigg(\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\bigg)^n=\sqrt{\frac{2}{3\pi\sqrt{3}}}\exp\bigg(\frac{G}{\pi}+\frac12\bigg)","['integration', 'sequences-and-series', 'pi', 'constants', 'catalans-constant']"
7,List of functions not integrable in elementary terms,List of functions not integrable in elementary terms,,"When teaching integration to beginning calculus students I always tell them that some integrals are ""impossible"" (with a bit of expansion on what that actually means).  However I must admit that the examples I give mostly come from ""folklore"" or guesswork. Can anyone point me to a list (not a complete list of course!) of fairly simple elementary functions whose antiderivatives are not elementary?  I'm thinking of things like $\exp(x^2)$ which is the standard example, $\sin(\exp(-x))$ perhaps, things like this, not hugely complicated formulae.","When teaching integration to beginning calculus students I always tell them that some integrals are ""impossible"" (with a bit of expansion on what that actually means).  However I must admit that the examples I give mostly come from ""folklore"" or guesswork. Can anyone point me to a list (not a complete list of course!) of fairly simple elementary functions whose antiderivatives are not elementary?  I'm thinking of things like $\exp(x^2)$ which is the standard example, $\sin(\exp(-x))$ perhaps, things like this, not hugely complicated formulae.",,"['integration', 'reference-request', 'elementary-functions']"
8,If $\int_0^x f \ dm$ is zero everywhere then $f$ is zero almost everywhere,If  is zero everywhere then  is zero almost everywhere,\int_0^x f \ dm f,I have been thinking on and off about a problem for some time now. It is inspired by an exam problem which I solved but I wanted to find an alternative solution. The object was to prove that some sequence of functions converges weakly to zero in $L^2$. I managed to show (with some help) that the limit $f$ (of a subsequence) satisfies $\int_0^x f \ dm=0$ for all $x>0 $. From this I want to conclude that $f=0$ a.e. I can do this with the fundamental theorem of calculus in its Lebesgue version but there ought to be a more elementary proof. Can someone here help me out?,I have been thinking on and off about a problem for some time now. It is inspired by an exam problem which I solved but I wanted to find an alternative solution. The object was to prove that some sequence of functions converges weakly to zero in $L^2$. I managed to show (with some help) that the limit $f$ (of a subsequence) satisfies $\int_0^x f \ dm=0$ for all $x>0 $. From this I want to conclude that $f=0$ a.e. I can do this with the fundamental theorem of calculus in its Lebesgue version but there ought to be a more elementary proof. Can someone here help me out?,,"['integration', 'measure-theory', 'lebesgue-integral']"
9,How to show that the Laurent series of the Riemann Zeta function has $\gamma$ as its constant term?,How to show that the Laurent series of the Riemann Zeta function has  as its constant term?,\gamma,"I mean the Laurent series at $s=1$. I want to do it by proving $\displaystyle \int_0^\infty \frac{2t}{(t^2+1)(e^{\pi t}+1)} dt = \ln 2 - \gamma$, based on the integral formula given in Wikipedia . But I cannot solve this integral except by using Mathematica. Tried complex analytic ways but no luck. Any suggestions? Thanks for your attention!","I mean the Laurent series at $s=1$. I want to do it by proving $\displaystyle \int_0^\infty \frac{2t}{(t^2+1)(e^{\pi t}+1)} dt = \ln 2 - \gamma$, based on the integral formula given in Wikipedia . But I cannot solve this integral except by using Mathematica. Tried complex analytic ways but no luck. Any suggestions? Thanks for your attention!",,"['integration', 'analytic-number-theory', 'riemann-zeta']"
10,Integral $\int_0^\infty\frac{dx}{\sqrt{1+\exp\left(\frac\pi2\left(x^2-\frac1{x^2}\right)\right) }}=\sqrt{\frac\pi2}$,Integral,\int_0^\infty\frac{dx}{\sqrt{1+\exp\left(\frac\pi2\left(x^2-\frac1{x^2}\right)\right) }}=\sqrt{\frac\pi2},"Someone posted the integral on a local chat group $$ \int_0^\infty\frac{dx}{\sqrt{1+\exp\left(\dfrac\pi2\left(x^2-\dfrac1{x^2}\right)\right) }}=\sqrt{\frac\pi2} $$ It is interesting that the integrand is quite messy but the result is neat. Using CAS, I checked that the integral holds with high precision. The first thing that came into my mind was the Glasser's master theorem , but it is not in an acceptable form. I also tried substituting $\dfrac{x^4-1}{2x^2}=t$ but the integral becomes even worse. $$ \int_{-\infty}^\infty\frac{\sqrt{\sqrt{t^2+1}+t}}{\sqrt{e^{\pi  t}+1} \sqrt{t^2+1}}dt=\sqrt{2\pi} $$ Are there any ways to work out the integral? Or perhaps there is an approach to find the result magically? Any help would be appreciated.","Someone posted the integral on a local chat group It is interesting that the integrand is quite messy but the result is neat. Using CAS, I checked that the integral holds with high precision. The first thing that came into my mind was the Glasser's master theorem , but it is not in an acceptable form. I also tried substituting but the integral becomes even worse. Are there any ways to work out the integral? Or perhaps there is an approach to find the result magically? Any help would be appreciated.","
\int_0^\infty\frac{dx}{\sqrt{1+\exp\left(\dfrac\pi2\left(x^2-\dfrac1{x^2}\right)\right) }}=\sqrt{\frac\pi2}
 \dfrac{x^4-1}{2x^2}=t 
\int_{-\infty}^\infty\frac{\sqrt{\sqrt{t^2+1}+t}}{\sqrt{e^{\pi  t}+1} \sqrt{t^2+1}}dt=\sqrt{2\pi}
",['integration']
11,Volume integral of the curl of a vector field,Volume integral of the curl of a vector field,,"I am having hard time recalling some of the theorems of vector calculus. I want to calculate the volume integral of the curl of a vector field, which would give a vector as the answer. Is there any formula? As far as I can recall, maybe I can write $$\int \nabla \times \vec{A} \ \mathrm{d}V=\int \vec{A} \times \hat{n}\, \mathrm{d}\sigma,$$ where $d\sigma$ is the enclosing boundary. Is this right? But more importantly, what does it follow from? Does this follow directly from one of the integral theorems, or how can it be proved independantly?","I am having hard time recalling some of the theorems of vector calculus. I want to calculate the volume integral of the curl of a vector field, which would give a vector as the answer. Is there any formula? As far as I can recall, maybe I can write where is the enclosing boundary. Is this right? But more importantly, what does it follow from? Does this follow directly from one of the integral theorems, or how can it be proved independantly?","\int \nabla \times \vec{A} \ \mathrm{d}V=\int \vec{A} \times \hat{n}\, \mathrm{d}\sigma, d\sigma",['multivariable-calculus']
12,Can a function that has uncountable many points of discontinuity be integrable?,Can a function that has uncountable many points of discontinuity be integrable?,,"First of all, I would like to show you how we defined Riemann-integrals and Lebesgue-integrals to make sure that we are talking about the same: Riemann-intregrability Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a function. $$O(Z):=\sum_{k=1}^n(x_k-x_{k-1})\cdot\sup_{x_{k-1}<x<x_k}f(x)$$ $$U(Z):=\sum_{k=1}^n(x_k-x_{k-1})\cdot\inf_{x_{k-1}<x<x_k}f(x)$$ $$\overline{\int_a^b}f(x)\,\mathrm dx:=\inf_ZO(Z) := \inf \{ O(Z) : Z \mbox{ is a segmentation of } [a,b] \}$$ $$\underline{\int_a^b}f(x)\,\mathrm dx:=\sup_ZU(Z):= \sup \{ U(Z) : Z \mbox{ is a segmentation of } [a,b] \}$$ $f$ is called Riemann-integrable over $[a, b] \subset \mathbb{R} :\Leftrightarrow \underline{\int_a^b}f(x)\,\mathrm dx=\overline{\int_a^b}f(x)\,\mathrm dx$ This is the image that we had in mind when we introduced the Riemann-integral: Lebesgue-integrability Let $\emptyset \neq X \in \mathfrak{B}_d$ be and $f:X \rightarrow [0;\infty)$ be a simple function with normal form $f=\sum_{j=1}^m y_j \mathbb{1}_{A_j}$. The Lebesgue-integral is defined as $$\int_X f(x) dx := \sum_{j=1}^m y_j \lambda_d(A_j)$$ My question Does any function with uncountably infinte many points of discontinuity exist, that is Riemann-integrable / Lebesgue-integrable? If not, why? Related The following function has a countably infinite number of points of discontinuity and it is Riemann-integrable ( source ): $f:[0,1] \rightarrow \mathbb{R}$ which is defined as $$f(x)=\begin{cases} 1& \text{ if } \exists n \in \mathbb{N}: x=\frac{1}{n}\\ 0& \text{ otherwise} \end{cases}$$ And $\int_0^1 f(x) \mathrm{d}x = 0$","First of all, I would like to show you how we defined Riemann-integrals and Lebesgue-integrals to make sure that we are talking about the same: Riemann-intregrability Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a function. $$O(Z):=\sum_{k=1}^n(x_k-x_{k-1})\cdot\sup_{x_{k-1}<x<x_k}f(x)$$ $$U(Z):=\sum_{k=1}^n(x_k-x_{k-1})\cdot\inf_{x_{k-1}<x<x_k}f(x)$$ $$\overline{\int_a^b}f(x)\,\mathrm dx:=\inf_ZO(Z) := \inf \{ O(Z) : Z \mbox{ is a segmentation of } [a,b] \}$$ $$\underline{\int_a^b}f(x)\,\mathrm dx:=\sup_ZU(Z):= \sup \{ U(Z) : Z \mbox{ is a segmentation of } [a,b] \}$$ $f$ is called Riemann-integrable over $[a, b] \subset \mathbb{R} :\Leftrightarrow \underline{\int_a^b}f(x)\,\mathrm dx=\overline{\int_a^b}f(x)\,\mathrm dx$ This is the image that we had in mind when we introduced the Riemann-integral: Lebesgue-integrability Let $\emptyset \neq X \in \mathfrak{B}_d$ be and $f:X \rightarrow [0;\infty)$ be a simple function with normal form $f=\sum_{j=1}^m y_j \mathbb{1}_{A_j}$. The Lebesgue-integral is defined as $$\int_X f(x) dx := \sum_{j=1}^m y_j \lambda_d(A_j)$$ My question Does any function with uncountably infinte many points of discontinuity exist, that is Riemann-integrable / Lebesgue-integrable? If not, why? Related The following function has a countably infinite number of points of discontinuity and it is Riemann-integrable ( source ): $f:[0,1] \rightarrow \mathbb{R}$ which is defined as $$f(x)=\begin{cases} 1& \text{ if } \exists n \in \mathbb{N}: x=\frac{1}{n}\\ 0& \text{ otherwise} \end{cases}$$ And $\int_0^1 f(x) \mathrm{d}x = 0$",,"['integration', 'lebesgue-integral']"
13,When to use $y = \frac{1 + x}{1 - x}$ when evaluating definite integrals,When to use  when evaluating definite integrals,y = \frac{1 + x}{1 - x},"When evaluating definite and indefinite integrals, there are times in which the integrand presents itself to be solvable using a definite method: be it a transformation, substitution, series, etc. For instance, the general method for integrals involving rational functions of trigonometric functions is to employ the Weirerstrauss Substitution. Now, on this site I mainly primarily focus on integrals and I've observed that the substitution of $y = \frac{1 + x}{1 - x}$ is used when the bounds of a definite integral are $0,1$ . Is this part of a generalised method? and if so, does it have name? And if not, is it possible to get some examples of integrals where this method is favourable.","When evaluating definite and indefinite integrals, there are times in which the integrand presents itself to be solvable using a definite method: be it a transformation, substitution, series, etc. For instance, the general method for integrals involving rational functions of trigonometric functions is to employ the Weirerstrauss Substitution. Now, on this site I mainly primarily focus on integrals and I've observed that the substitution of is used when the bounds of a definite integral are . Is this part of a generalised method? and if so, does it have name? And if not, is it possible to get some examples of integrals where this method is favourable.","y = \frac{1 + x}{1 - x} 0,1",['integration']
14,Derivative and calculus over sets such as the rational numbers,Derivative and calculus over sets such as the rational numbers,,"I am interested in the derivative of a function defined on a subset $S$ of $[0, 1]$ . The subset in question is dense in $[0, 1]$ but has Lebesgue measure zero. My actual question can be found at the bottom of this post. There has been a few questions on the subject, but none leading to something interesting as far as I am concerned. See here , here (concept of arithmetic derivative) and also here (Minkowski's question mark function, related to the material discussed here.) Generally these discussions lead to some kind of non-sense math. Here it is the opposite. I have a framework that does work as far as applications and computations are concerned, but I have a hard time putting it into some sound mathematical framework. It would have to be some kind of non-standard calculus. Perhaps the simplest example (though I have plenty of other similar cases) is as follows. Let $Z$ be a random variable defined as follows: $$Z = \sum_{k=1}^\infty \frac{X_k}{2^k}$$ where the $X_k$ 's are identically and independently distributed with a Bernouilli $(p)$ distribution. Thus $P(X_k = 1) = p$ and $P(X_k = 0) = 1-p$ . Here $0 < p < 1$ . In short, the $X_k$ 's are the binary digits of the random number $Z$ . There are two cases. Case $p=\frac{1}{2}$ In this case, $Z$ has a uniform distribution on $S$ , where $S$ is the set of normal numbers in $[0, 1]$ . It is known that $S$ has Lebesgue measure $1$ , and that $S$ is dense in $[0, 1]$ . Yet it is full of holes (no rational number is is a normal number due to their periodicity, thus the $X_k$ 's are not independent for rational numbers.) This is the simplest case. One might wonder if the density $f_Z$ (the derivative of the distribution $F_Z$ ) exists. Yet $f_Z(z) = 1$ if $z \in S$ works perfectly well for all purposes. It can easily be extended to $f_Z(z) = 1$ if $z \in [0, 1]$ . Let us denote the extended function as $\tilde{f}_Z$ . You can compute all the moments using the extended $\tilde{f}_Z$ and get the right answer. If $s$ is a positive real number, then $$E(Z^s) = \int_0^1 z^s \tilde{f}_Z(z) dz = \frac{1}{s+1}.$$ You could argue that $\tilde{f}_Z$ (and thus $f_Z$ ) can be obtained by inverting the above functional equation, using some kind of Laplace transform. So we can bypass the concept of derivative entirely, it seems. Case $p\neq \frac{1}{2}$ Now we are dealing with a hard nut to crack, and a wildly chaotic system: $Z$ 's support domain is a set $S'$ that is a subset of non-normal numbers in $[0, 1]$ . This set $S'$ has now Lebesgue measure zero, yet it is dense in $[0, 1]$ . For the distribution, it is not a problem: even discrete random variables have a distribution $F_Z$ defined for all positive real numbers: $F_Z(z) = P(Z \leq z)$ . The issue is with the density $f_Z = dF_Z/dz$ . It sounds either it should be zero everywhere or not exist. My guess is that you might be able to define a new, workable concept of density. In the neighborhood of every point $z \in S'$ , it looks like $g(z,h) = (F_Z(z+h) - F_Z(z))/h$ oscillates infinitely many times with no limit as $h\rightarrow 0$ , yet these oscillations are bounded most of the time, perhaps leading to the fact that averaging $g(z, h)$ around $h = 0$ , using smaller and smaller values of $h$ , could provide a sound definition for the density $f_Z$ . Again, despite the chaotic nature of the system (see how the the would-be density could potentially look like in the picture below) all the following quantities exist and can be computed exactly and then confirmed by empirical evidence, even though the integrals below may not make sense: $$E(Z) = \int_{0}^{1} z f_Z(z) dz = p \\ E(Z^2) = \int_{0}^{1} z^2 f_Z(z) dz =\frac{p}{3}(1+2p)\\ E(Z^3) = \int_{0}^{1} z^3 f_Z(z) dz =\frac{p}{7}(1+4p+2p^2)\\ E(Z^4) = \int_{0}^{1} z^4 f_Z(z) dz =\frac{p}{105}(7+46p + 44p^2+8p^3) $$ Indeed, a general formula for $E(Z^s) = \int_0^1 z^s f_Z(z)dz$ is available for $s \geq 0$ , defined by the following functional equation (see here ): $$E(Z^s) = \frac{p}{2^s-1+p}\cdot E((1+Z)^s) .$$ In other words, we would have, under some appropriate calculus theory with a sound definition of integral and derivative: $$\int_{S'}z^s f_Z(z)dz  = \frac{p}{2^s-1+p}\cdot\int_{S'}(1+z)^s f_Z(z) dz .$$ Here is how the density $f_Z$ , if properly defined, could look like for $p=0.75$ (see here and here ): Below is the empirical percentile distribution, for this particular $Z$ : Other related problems If instead, we consider the model $Z = X_1 + X_1 X_2 + X_1 X_2 X_3 + \cdots$ with $X$ Bernouilli $(p)$ , then $Z$ has a geometric distribution of parameter $1-p$ , see section 2.2 in this article . This system is also equivalent to the binary numeration system discussed so far: see section 5 in the same article. It results in $Z$ having a standard, well-known discrete distribution. But if this time $P(X=-0.5) = 0.5 = P(X=0.5)$ then $Z$ is uniform on a subset $S$ of $[-1, 1]$ , with $S$ also full of holes. Here is another interesting model: $$Z=\sqrt{X_1+\sqrt{X_2+\sqrt{X_3+\cdots}}}$$ The distribution for $X$ is as follows: $$P(X=0) = \frac{1}{2}, P(X=1) = \frac{1}{1 + \sqrt{5}}, P(X=2) = \frac{3 - \sqrt{5}}{4} \mbox{ } (\star)$$ This corresponds to a different numeration system, and the choice for $X$ 's distribution is not arbitrary, see here : in short, it makes the system smoother and possibly easier to solve. To the contrary $P(X=0) = P(X=1)=$ $P(X=2)= \frac{1}{3}$ yields a far more chaotic system, and the case $P(X=0) =$ $P(X=1) = \frac{1}{2}$ is so wild that the support domain of $Z$ has huge gaps, very visible to the naked eye. Normal numbers in the nested square root system are very different from normal numbers in the binary numeration system. The successive digits have a very specific auto-correlation structure, and the digits $0, 1, 2$ are not evenly distributed for normal numbers in that system. It is clear that if we assume that the $X_k$ 's are i.i.d, then $Z$ is not a normal number in that system. Yet we get a very good approximation for $F_Z$ , much smoother (at least visually) than in the binary numeration system investigated earlier, with $p\neq \frac{1}{2}$ . In particular, $F_Z$ is very well approximated by a log function, see chart below. Here the blue line is the empirical distribution for $Z$ , the red line is the log approximation. And below is a spectacular chart, featuring the approximation error $\epsilon(z) = F_Z(z) -\log_2(z)$ . It's a fractal! (source: see section 2.2 in this article ). In short, it is no more differentiable than a Brownian motion, and technically, the derivative $f_Z$ does not exist. Yet all moments of $Z$ can be computed exactly from the functional equation attached to that system ( $F_{Z^2}=F_{X+Z}$ ) and confirmed empirically. Even though the distribution looks smooth to the naked eye, we are dealing here with a very chaotic system in disguise. Again we need non-standard calculus to handle the density, whose support is a dense set of Lebesgue measure zero in $[1, 2]$ . Since fractals are nowhere differentiable, $f_Z$ does not exist. Yet one could imagine a ""density"" that would look like $f_Z(z)=\frac{1}{z\log 2}$ for $z\in [1,2]$ . My question Is there an existing theory to handle this type of density-like-substance? Following some advice, I also posted this question on MathOverflow, here .","I am interested in the derivative of a function defined on a subset of . The subset in question is dense in but has Lebesgue measure zero. My actual question can be found at the bottom of this post. There has been a few questions on the subject, but none leading to something interesting as far as I am concerned. See here , here (concept of arithmetic derivative) and also here (Minkowski's question mark function, related to the material discussed here.) Generally these discussions lead to some kind of non-sense math. Here it is the opposite. I have a framework that does work as far as applications and computations are concerned, but I have a hard time putting it into some sound mathematical framework. It would have to be some kind of non-standard calculus. Perhaps the simplest example (though I have plenty of other similar cases) is as follows. Let be a random variable defined as follows: where the 's are identically and independently distributed with a Bernouilli distribution. Thus and . Here . In short, the 's are the binary digits of the random number . There are two cases. Case In this case, has a uniform distribution on , where is the set of normal numbers in . It is known that has Lebesgue measure , and that is dense in . Yet it is full of holes (no rational number is is a normal number due to their periodicity, thus the 's are not independent for rational numbers.) This is the simplest case. One might wonder if the density (the derivative of the distribution ) exists. Yet if works perfectly well for all purposes. It can easily be extended to if . Let us denote the extended function as . You can compute all the moments using the extended and get the right answer. If is a positive real number, then You could argue that (and thus ) can be obtained by inverting the above functional equation, using some kind of Laplace transform. So we can bypass the concept of derivative entirely, it seems. Case Now we are dealing with a hard nut to crack, and a wildly chaotic system: 's support domain is a set that is a subset of non-normal numbers in . This set has now Lebesgue measure zero, yet it is dense in . For the distribution, it is not a problem: even discrete random variables have a distribution defined for all positive real numbers: . The issue is with the density . It sounds either it should be zero everywhere or not exist. My guess is that you might be able to define a new, workable concept of density. In the neighborhood of every point , it looks like oscillates infinitely many times with no limit as , yet these oscillations are bounded most of the time, perhaps leading to the fact that averaging around , using smaller and smaller values of , could provide a sound definition for the density . Again, despite the chaotic nature of the system (see how the the would-be density could potentially look like in the picture below) all the following quantities exist and can be computed exactly and then confirmed by empirical evidence, even though the integrals below may not make sense: Indeed, a general formula for is available for , defined by the following functional equation (see here ): In other words, we would have, under some appropriate calculus theory with a sound definition of integral and derivative: Here is how the density , if properly defined, could look like for (see here and here ): Below is the empirical percentile distribution, for this particular : Other related problems If instead, we consider the model with Bernouilli , then has a geometric distribution of parameter , see section 2.2 in this article . This system is also equivalent to the binary numeration system discussed so far: see section 5 in the same article. It results in having a standard, well-known discrete distribution. But if this time then is uniform on a subset of , with also full of holes. Here is another interesting model: The distribution for is as follows: This corresponds to a different numeration system, and the choice for 's distribution is not arbitrary, see here : in short, it makes the system smoother and possibly easier to solve. To the contrary yields a far more chaotic system, and the case is so wild that the support domain of has huge gaps, very visible to the naked eye. Normal numbers in the nested square root system are very different from normal numbers in the binary numeration system. The successive digits have a very specific auto-correlation structure, and the digits are not evenly distributed for normal numbers in that system. It is clear that if we assume that the 's are i.i.d, then is not a normal number in that system. Yet we get a very good approximation for , much smoother (at least visually) than in the binary numeration system investigated earlier, with . In particular, is very well approximated by a log function, see chart below. Here the blue line is the empirical distribution for , the red line is the log approximation. And below is a spectacular chart, featuring the approximation error . It's a fractal! (source: see section 2.2 in this article ). In short, it is no more differentiable than a Brownian motion, and technically, the derivative does not exist. Yet all moments of can be computed exactly from the functional equation attached to that system ( ) and confirmed empirically. Even though the distribution looks smooth to the naked eye, we are dealing here with a very chaotic system in disguise. Again we need non-standard calculus to handle the density, whose support is a dense set of Lebesgue measure zero in . Since fractals are nowhere differentiable, does not exist. Yet one could imagine a ""density"" that would look like for . My question Is there an existing theory to handle this type of density-like-substance? Following some advice, I also posted this question on MathOverflow, here .","S [0, 1] [0, 1] Z Z = \sum_{k=1}^\infty \frac{X_k}{2^k} X_k (p) P(X_k = 1) = p P(X_k = 0) = 1-p 0 < p < 1 X_k Z p=\frac{1}{2} Z S S [0, 1] S 1 S [0, 1] X_k f_Z F_Z f_Z(z) = 1 z \in S f_Z(z) = 1 z \in [0, 1] \tilde{f}_Z \tilde{f}_Z s E(Z^s) = \int_0^1 z^s \tilde{f}_Z(z) dz = \frac{1}{s+1}. \tilde{f}_Z f_Z p\neq \frac{1}{2} Z S' [0, 1] S' [0, 1] F_Z F_Z(z) = P(Z \leq z) f_Z = dF_Z/dz z \in S' g(z,h) = (F_Z(z+h) - F_Z(z))/h h\rightarrow 0 g(z, h) h = 0 h f_Z E(Z) = \int_{0}^{1} z f_Z(z) dz = p \\
E(Z^2) = \int_{0}^{1} z^2 f_Z(z) dz =\frac{p}{3}(1+2p)\\
E(Z^3) = \int_{0}^{1} z^3 f_Z(z) dz =\frac{p}{7}(1+4p+2p^2)\\
E(Z^4) = \int_{0}^{1} z^4 f_Z(z) dz =\frac{p}{105}(7+46p + 44p^2+8p^3)
 E(Z^s) = \int_0^1 z^s f_Z(z)dz s \geq 0 E(Z^s) = \frac{p}{2^s-1+p}\cdot E((1+Z)^s) . \int_{S'}z^s f_Z(z)dz  = \frac{p}{2^s-1+p}\cdot\int_{S'}(1+z)^s f_Z(z) dz . f_Z p=0.75 Z Z = X_1 + X_1 X_2 + X_1 X_2 X_3 + \cdots X (p) Z 1-p Z P(X=-0.5) = 0.5 = P(X=0.5) Z S [-1, 1] S Z=\sqrt{X_1+\sqrt{X_2+\sqrt{X_3+\cdots}}} X P(X=0) = \frac{1}{2}, P(X=1) = \frac{1}{1 + \sqrt{5}}, P(X=2) = \frac{3 - \sqrt{5}}{4} \mbox{ } (\star) X P(X=0) = P(X=1)= P(X=2)= \frac{1}{3} P(X=0) = P(X=1) = \frac{1}{2} Z 0, 1, 2 X_k Z F_Z p\neq \frac{1}{2} F_Z Z \epsilon(z) = F_Z(z) -\log_2(z) f_Z Z F_{Z^2}=F_{X+Z} [1, 2] f_Z f_Z(z)=\frac{1}{z\log 2} z\in [1,2]","['integration', 'probability-theory', 'measure-theory', 'derivatives', 'probability-distributions']"
15,"Is there a set $A \subset [0,1]$ such that $\int_{A \times A^\text{c}} \frac{\mathrm{d} x \, \mathrm{d} y}{\lvert x - y\vert}=\infty$?",Is there a set  such that ?,"A \subset [0,1] \int_{A \times A^\text{c}} \frac{\mathrm{d} x \, \mathrm{d} y}{\lvert x - y\vert}=\infty","The above question came up when I was trying to find a counterexample related to this problem. Clearly, the integral of $(x,y) \mapsto \lvert x-y \rvert^{-1}$ over $[0,1]^2$ is divergent. When integrating over a subset of the form $A \times A^\text{c}$ with Lebesgue measurable $A \subset [0,1]$ (and $A^\text{c} = [0,1] \setminus A$ ), however, the result is generally finite. I would like to know whether this is true for every $A$ . My thoughts so far: For the simple interval $A = [0,1/2]$ the integral has the finite value $\log(2)$ . The integrand is only singular near the point $(1/2,1/2)$ , which is not enough to make the two-dimensional integral diverge. The same is true if $A$ is a union of finitely many intervals. Therefore, in order to make the integral large we need 'a lot' of points $(x,y) \in A \times A^\text{c}$ for which $\lvert x - y \rvert$ is small. This can be achieved by choosing $A = [0,1] \cap \mathbb{Q}$ , but of course the integral is simply zero  in this case because $A \times A^\text{c}$ is a Lebesgue null set. Thus we also need to ensure that both $A$ and $A^\text{c}$ have positive measure. We can let $A$ be the fat Cantor set to fulfil both requirements: $A$ and $A^\text{c}$ have Lebesgue measure $\frac{1}{2}$ each and there is an infinite number of points on the diagonal of $[0,1]^2$ near which the integrand diverges. I have tried to show that the integral is finite/infinite using the sequence of simpler sets defined in the iterative construction of $A$ , but the corresponding integrals become complicated rather fast and it seems like I am stuck at this point. Question: Can we prove that $\int \limits_{A \times A^\text{c}} \frac{\mathrm{d} x \, \mathrm{d} y}{\lvert x - y\vert} < \infty$ holds for every Lebesgue measurable $A \subset [0,1]$ or find a counterexample?","The above question came up when I was trying to find a counterexample related to this problem. Clearly, the integral of over is divergent. When integrating over a subset of the form with Lebesgue measurable (and ), however, the result is generally finite. I would like to know whether this is true for every . My thoughts so far: For the simple interval the integral has the finite value . The integrand is only singular near the point , which is not enough to make the two-dimensional integral diverge. The same is true if is a union of finitely many intervals. Therefore, in order to make the integral large we need 'a lot' of points for which is small. This can be achieved by choosing , but of course the integral is simply zero  in this case because is a Lebesgue null set. Thus we also need to ensure that both and have positive measure. We can let be the fat Cantor set to fulfil both requirements: and have Lebesgue measure each and there is an infinite number of points on the diagonal of near which the integrand diverges. I have tried to show that the integral is finite/infinite using the sequence of simpler sets defined in the iterative construction of , but the corresponding integrals become complicated rather fast and it seems like I am stuck at this point. Question: Can we prove that holds for every Lebesgue measurable or find a counterexample?","(x,y) \mapsto \lvert x-y \rvert^{-1} [0,1]^2 A \times A^\text{c} A \subset [0,1] A^\text{c} = [0,1] \setminus A A A = [0,1/2] \log(2) (1/2,1/2) A (x,y) \in A \times A^\text{c} \lvert x - y \rvert A = [0,1] \cap \mathbb{Q} A \times A^\text{c} A A^\text{c} A A A^\text{c} \frac{1}{2} [0,1]^2 A \int \limits_{A \times A^\text{c}} \frac{\mathrm{d} x \, \mathrm{d} y}{\lvert x - y\vert} < \infty A \subset [0,1]","['integration', 'lebesgue-integral', 'lebesgue-measure']"
16,Closed not exact form on $\mathbb{R}^n\setminus\{0\}$,Closed not exact form on,\mathbb{R}^n\setminus\{0\},"I'd like to construct a closed but not exact $n-1$-form $\omega$ on $\mathbb{R}^n\setminus\{0\}$ in analogy to the winding form: $$\frac{x~dy-y~dx}{x^2+y^2}$$ I think something like $$\omega=\frac{\sum_{i=1}^n x_i(\star dx_i)}{(x_1^2+\dots+x_n^2)^{n/2}}$$ should probably work. $\star$ is the hodge star operator, for example $\star dx_1=dx_2\wedge\dots\wedge dx_n$ and $\star dx_2=-dx_1\wedge dx_3\wedge\dots\wedge dx_n$. $\omega$ is closed since $$d\omega=\sum_{i=1}^nd\left(\frac{ x_i}{(x_1^2+\dots+x_n^2)^{n/2}}\right)\wedge\star dx_i=\sum_{i=1}^n \frac{(\sum x_j^2)^{n/2}-n x_i^2 (\sum x_j^2)^{n/2-1}}{(\sum x_j^2)^{n}} dx_1\wedge\dots\wedge dx_n=0$$ Now it remains to show that $\omega$ is not exact. I guess a direct computation is not the way to do it. I thought about assuming that there exists $d\eta=\omega$ and then using Stoke's theorem to get the contradiction $0\not=\int_{S^{n-1}}\omega=\int_\emptyset                                                                      \eta=0$. Two questions about this: Is the general argument correct? How to prove $0\not=\int_{S^{n-1}}\omega$? I guess a direct computation using generalized sphere coordinates is rather tedious.","I'd like to construct a closed but not exact $n-1$-form $\omega$ on $\mathbb{R}^n\setminus\{0\}$ in analogy to the winding form: $$\frac{x~dy-y~dx}{x^2+y^2}$$ I think something like $$\omega=\frac{\sum_{i=1}^n x_i(\star dx_i)}{(x_1^2+\dots+x_n^2)^{n/2}}$$ should probably work. $\star$ is the hodge star operator, for example $\star dx_1=dx_2\wedge\dots\wedge dx_n$ and $\star dx_2=-dx_1\wedge dx_3\wedge\dots\wedge dx_n$. $\omega$ is closed since $$d\omega=\sum_{i=1}^nd\left(\frac{ x_i}{(x_1^2+\dots+x_n^2)^{n/2}}\right)\wedge\star dx_i=\sum_{i=1}^n \frac{(\sum x_j^2)^{n/2}-n x_i^2 (\sum x_j^2)^{n/2-1}}{(\sum x_j^2)^{n}} dx_1\wedge\dots\wedge dx_n=0$$ Now it remains to show that $\omega$ is not exact. I guess a direct computation is not the way to do it. I thought about assuming that there exists $d\eta=\omega$ and then using Stoke's theorem to get the contradiction $0\not=\int_{S^{n-1}}\omega=\int_\emptyset                                                                      \eta=0$. Two questions about this: Is the general argument correct? How to prove $0\not=\int_{S^{n-1}}\omega$? I guess a direct computation using generalized sphere coordinates is rather tedious.",,"['differential-geometry', 'integration', 'differential-topology', 'differential-forms']"
17,Evaluate the double sum $\sum_{m=1}^{\infty}\sum_{n=1}^{m-1}\frac{ 1}{m n\left(m^2-n^2\right)^2}$,Evaluate the double sum,\sum_{m=1}^{\infty}\sum_{n=1}^{m-1}\frac{ 1}{m n\left(m^2-n^2\right)^2},"As a follow up of this nice question I am interested in $$ S_1=\sum_{m=1}^{\infty}\sum_{n=1}^{m-1}\frac{  1}{m n\left(m^2-n^2\right)^2} $$ Furthermore, I would be also very grateful for a solution to $$ S_2=\sum_{m=1}^{\infty}\sum_{n=m+1}^{\infty}\frac{  1}{m n\left(m^2-n^2\right)^2} $$ Following my answer in the question mentioned above and the numerical experiments of @Vladimir Reshetnikov it's very likely that at least $$ S_1+S_2 = \frac{a}{b}\pi^6 $$ I think both sums may be evaluated by using partial fraction decomposition and the integral representation of the Polygamma function but I don't know how exactly and I guess there could be a much more efficient route.","As a follow up of this nice question I am interested in $$ S_1=\sum_{m=1}^{\infty}\sum_{n=1}^{m-1}\frac{  1}{m n\left(m^2-n^2\right)^2} $$ Furthermore, I would be also very grateful for a solution to $$ S_2=\sum_{m=1}^{\infty}\sum_{n=m+1}^{\infty}\frac{  1}{m n\left(m^2-n^2\right)^2} $$ Following my answer in the question mentioned above and the numerical experiments of @Vladimir Reshetnikov it's very likely that at least $$ S_1+S_2 = \frac{a}{b}\pi^6 $$ I think both sums may be evaluated by using partial fraction decomposition and the integral representation of the Polygamma function but I don't know how exactly and I guess there could be a much more efficient route.",,"['integration', 'sequences-and-series', 'special-functions']"
18,"A rigorous meaning of ""induced measure""?","A rigorous meaning of ""induced measure""?",,"In my readings I often come across terms like ""induced measure"" or ""induced Lebesgue measure"". For example: $$\int_{\mathbb{B}^n}u\frac{\partial v}{\partial x_j}\;dx = \int_{\mathbb{S}^{n-1}}uv\frac{x_j}{|x|}\;d\sigma - \int_{\mathbb{B}^n}v\frac{\partial u}{\partial x_j}\;dx$$ where $d\sigma$ denotes the induced Lebesgue measure on the sphere. Unfortunately though, I've never really seen anyone give a rigorous definition to this phrase. Sure, in the above example, we understand how to parametrize the $n$ ball, $\mathbb{B}^n$, and the $n-1$ sphere, $\mathbb{S}^{n-1}$, and so the integrals are easy to compute and not very confusing. Sometimes, however, it appears in the context of a general hypersurface in $\mathbb{R}^n$ (say $\Sigma$, with integrals involving $d\Sigma$), or when integrating over a subset (submanifold) of some higher-dimensional  space. In a completely general setting like this, I am at a little bit of a loss when it comes to understanding  how these separate ""surface"" measures or ""induced"" measures are really defined, when I'm lacking an explicit parametrization. It also doesn't help that traditional vector calculus classes seem to always fall short of doing anything past 3 dimensions. For example, I've never seen a class teach its students how to carry out a (2-D) surface integral in anything except $\mathbb{R}^3$; so they would have no idea how to go about finding the surface area of, say a Clifford Torus in $\mathbb{R}^4$. And in general, I've never seen them address a general technique for integrating over an $n$-dimensional body, embedded in $n<m$-dimensional space. It seems like everything they're taught is in terms of the cross product, which fails to be of any use in $\mathbb{R}^{n>3}$. Now I realize that at least some of the hypersurface examples from calculus, that I've mentioned above, can be addressed using the generalized Stokes' theorem: $\int_{D}\text{d}\omega = \int_{\partial D}\omega$. But it seems to me that when we are getting to the realm of measure theory, higher-level analysis, and Riemannian geometry, the word ""induced"" is probably thrown around for a good reason. Let me clarify what I mean: If we are on a Riemannian manifold $M$, then its metric $g$ defines a volume element for the the manifold, $dV_g = \sqrt{\det g}\;dV$, where $dV$ is the Euclidean measure for your coordinate patch in $\mathbb{R}^n$. If we then consider an immersed submanifold $N\hookrightarrow M$, we have a rigourous definition for the induced metric that $N$ inherits from $M$. If we have a topological space $(X,\tau)$, then it induces a subspace topology on any subset $Y\subset X$, $\tau_Y = \{Y\cap U : U\in\tau\}$. Similarly for any subset $Y\subset X$ of a $\sigma$-algebra $(X,\Sigma)$, we have the sub-$\sigma$-algebra $(Y,\Sigma_Y), \Sigma_Y = \{Y\cap A : A\in\Sigma\}$. In these settings, the word "" induced "" has a very specific meaning, and essentially boils down to the idea of a subset inheriting some sort of property from a larger set it belongs to. So it would make sense that there should be some concrete way of having a measure space induce some kind of measure on a subset of itself. At first glance, since a measure space $(X,\Sigma,\mu)$ can give rise to a sub-$\sigma$-algebra (as mentioned above) then you might want to simply take the restriction of $\mu$ to these subsets in $\Sigma_Y$. But the problem is that any subset $E$, without full dimension, will of course have measure zero, $\mu(E)=0$. So this would make for a lousy way to define integration over this subset. So maybe we only concern ourselves with Riemannian manifolds, and just define the induced measure as the one that arrises from the induced metric of some parent manifold. But this seems limiting for a couple reasons: Integration is now limited to Riemannian manifolds, and no longer over a general measure space. For example, while integration with respect to the counting measure makes sense over $\mathbb{N}$, I can't see any way to interpret this as integration over a Riemannian manifold; and so the question of how the counting measure ""induces"" another measure would be meaningless. If we consider a (smooth) subset $S\subset\mathbb{R}^n$, we can build a measure space on $S$ from scratch, similar to how we build the Lebesgue measure on $\mathbb{R}^n$ in measure theory. My question then is: are we always able to realize integration (with respect to this measure) over $S$ as integration with respect to some induced metric, by considering $S\subset M$, for some manifold $(M,g)$? To me, a measure (and anything that it induces) should be in the spirit of measurable sets, and not be restricted to differential manifolds. The Lebesgue measure $\mu$ in $\mathbb{R}^3$ gives us the volume of the unit ball as $\frac{4}{3}\pi$; shouldn't $\mu$ induce a measure on $\mathbb{S}^2$, to give us $4\pi$ surface area? And whatever method we choose, shouldn't it apply to abstract measures as well, not just Lebesgue measure?","In my readings I often come across terms like ""induced measure"" or ""induced Lebesgue measure"". For example: $$\int_{\mathbb{B}^n}u\frac{\partial v}{\partial x_j}\;dx = \int_{\mathbb{S}^{n-1}}uv\frac{x_j}{|x|}\;d\sigma - \int_{\mathbb{B}^n}v\frac{\partial u}{\partial x_j}\;dx$$ where $d\sigma$ denotes the induced Lebesgue measure on the sphere. Unfortunately though, I've never really seen anyone give a rigorous definition to this phrase. Sure, in the above example, we understand how to parametrize the $n$ ball, $\mathbb{B}^n$, and the $n-1$ sphere, $\mathbb{S}^{n-1}$, and so the integrals are easy to compute and not very confusing. Sometimes, however, it appears in the context of a general hypersurface in $\mathbb{R}^n$ (say $\Sigma$, with integrals involving $d\Sigma$), or when integrating over a subset (submanifold) of some higher-dimensional  space. In a completely general setting like this, I am at a little bit of a loss when it comes to understanding  how these separate ""surface"" measures or ""induced"" measures are really defined, when I'm lacking an explicit parametrization. It also doesn't help that traditional vector calculus classes seem to always fall short of doing anything past 3 dimensions. For example, I've never seen a class teach its students how to carry out a (2-D) surface integral in anything except $\mathbb{R}^3$; so they would have no idea how to go about finding the surface area of, say a Clifford Torus in $\mathbb{R}^4$. And in general, I've never seen them address a general technique for integrating over an $n$-dimensional body, embedded in $n<m$-dimensional space. It seems like everything they're taught is in terms of the cross product, which fails to be of any use in $\mathbb{R}^{n>3}$. Now I realize that at least some of the hypersurface examples from calculus, that I've mentioned above, can be addressed using the generalized Stokes' theorem: $\int_{D}\text{d}\omega = \int_{\partial D}\omega$. But it seems to me that when we are getting to the realm of measure theory, higher-level analysis, and Riemannian geometry, the word ""induced"" is probably thrown around for a good reason. Let me clarify what I mean: If we are on a Riemannian manifold $M$, then its metric $g$ defines a volume element for the the manifold, $dV_g = \sqrt{\det g}\;dV$, where $dV$ is the Euclidean measure for your coordinate patch in $\mathbb{R}^n$. If we then consider an immersed submanifold $N\hookrightarrow M$, we have a rigourous definition for the induced metric that $N$ inherits from $M$. If we have a topological space $(X,\tau)$, then it induces a subspace topology on any subset $Y\subset X$, $\tau_Y = \{Y\cap U : U\in\tau\}$. Similarly for any subset $Y\subset X$ of a $\sigma$-algebra $(X,\Sigma)$, we have the sub-$\sigma$-algebra $(Y,\Sigma_Y), \Sigma_Y = \{Y\cap A : A\in\Sigma\}$. In these settings, the word "" induced "" has a very specific meaning, and essentially boils down to the idea of a subset inheriting some sort of property from a larger set it belongs to. So it would make sense that there should be some concrete way of having a measure space induce some kind of measure on a subset of itself. At first glance, since a measure space $(X,\Sigma,\mu)$ can give rise to a sub-$\sigma$-algebra (as mentioned above) then you might want to simply take the restriction of $\mu$ to these subsets in $\Sigma_Y$. But the problem is that any subset $E$, without full dimension, will of course have measure zero, $\mu(E)=0$. So this would make for a lousy way to define integration over this subset. So maybe we only concern ourselves with Riemannian manifolds, and just define the induced measure as the one that arrises from the induced metric of some parent manifold. But this seems limiting for a couple reasons: Integration is now limited to Riemannian manifolds, and no longer over a general measure space. For example, while integration with respect to the counting measure makes sense over $\mathbb{N}$, I can't see any way to interpret this as integration over a Riemannian manifold; and so the question of how the counting measure ""induces"" another measure would be meaningless. If we consider a (smooth) subset $S\subset\mathbb{R}^n$, we can build a measure space on $S$ from scratch, similar to how we build the Lebesgue measure on $\mathbb{R}^n$ in measure theory. My question then is: are we always able to realize integration (with respect to this measure) over $S$ as integration with respect to some induced metric, by considering $S\subset M$, for some manifold $(M,g)$? To me, a measure (and anything that it induces) should be in the spirit of measurable sets, and not be restricted to differential manifolds. The Lebesgue measure $\mu$ in $\mathbb{R}^3$ gives us the volume of the unit ball as $\frac{4}{3}\pi$; shouldn't $\mu$ induce a measure on $\mathbb{S}^2$, to give us $4\pi$ surface area? And whatever method we choose, shouldn't it apply to abstract measures as well, not just Lebesgue measure?",,"['integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
19,Closed form (or an ODE) for the integral $\int_0^\infty \frac{1+z^2}{1+z^4} \frac{z^p}{1+z^{2p}} dz$,Closed form (or an ODE) for the integral,\int_0^\infty \frac{1+z^2}{1+z^4} \frac{z^p}{1+z^{2p}} dz,"Is there a closed form for: $$I(p)=\int_0^\infty \frac{1+z^2}{1+z^4} \frac{z^p}{1+z^{2p}} dz$$ The integral has a number of nice properties: $$I(p)=I(-p)$$ $$I(p)=2\int_0^1 \frac{1+z^2}{1+z^4} \frac{z^p}{1+z^{2p}} dz=2\int_1^\infty \frac{1+z^2}{1+z^4} \frac{z^p}{1+z^{2p}} dz$$ $$I(p)=\int_{0}^{\infty} \frac{\cosh y}{\cosh 2y} \frac{dy}{\cosh p y}$$ I'm pretty sure it has a closed form expression for every rational $p$, because then we will be able to get a rational function under the integral either directly or with a simple substitution. Some examples of closed form expressions: $$I(0)=\frac{\pi}{2 \sqrt{2}}$$ $$I(1)=\frac{\pi}{4}$$ $$I(2)=\frac{\pi}{4 \sqrt{2}}$$ $$I(3)=\left(\frac{2}{3 \sqrt{3}}-\frac{1}{4} \right)\pi$$ $$I(4)=\left(\sqrt{\frac{1}{2} \left(1+\frac{1}{\sqrt{2}}\right)}-\frac{1}{\sqrt{2}} \right)\frac{\pi}{2}$$ $$I(5)=\left(\frac{\sqrt{10(5+\sqrt{5})}}{25}-\frac{1}{4} \right)\pi$$ $$I \left( \frac{1}{2} \right)=\left(\sqrt{1+\frac{1}{\sqrt{2}}}-1 \right)\pi$$ $$I \left( \frac{1}{3} \right)=\left(\frac{1}{\sqrt{3}}-\frac{1}{4} \right)\pi$$ $$I \left( \frac{1}{4} \right)=\left(2-\sqrt{2+\sqrt{2-\sqrt{2}}}\right)\pi$$ $$I \left( \frac{1}{5} \right)=\left(\frac{2\sqrt{5}-1}{4}-\frac{1}{2}\sqrt{2-\frac{2}{\sqrt{5}}}\right)\pi$$ Some not very nice closed forms also appear: $$I \left( \frac{2}{7} \right)=\frac{ \pi}{8}  \left(7 \sqrt{2}+ 4 \sin ^3\left(\frac{\pi }{14}\right) \sin \left(\frac{3 \pi }{14}\right) \csc ^6\left(\frac{\pi }{7}\right) \times \\ \times \left(48 \sin ^2\left(\frac{\pi }{14}\right) \sin \left(\frac{5 \pi }{28}\right) \sin ^2\left(\frac{3 \pi }{14}\right)-4 \sin \left(\frac{\pi }{28}\right) \sin \left(\frac{3 \pi }{14}\right)+\sin \left(\frac{\pi }{14}\right) \times \\ \times \left(2 \sin \left(\frac{3 \pi }{28}\right)-\sin \left(\frac{3 \pi }{14}\right) \left(2 \csc \left(\frac{\pi }{28}\right)+\csc \left(\frac{3 \pi }{28}\right)-3 \csc \left(\frac{5 \pi }{28}\right)\right)\right)\right)\right)$$ Because we can only consider the case $z<1$ a series solution is possible, but the series contain the polygamma function and it's not very useful. A similar integral has a simple closed form: $$\int_0^{\infty } \frac{1+z^2}{1+z^4} z^p \, dz=\frac{\pi}{4}   \left(\csc \left(\frac{\pi}{4}   (p+1)\right)+\sec \left(\frac{\pi}{4}  (p+1)\right)\right)$$ This strongly hints on the Beta function, however the series expansion of the original integral will not work, beacuse the limits will be either $\int_0^1$ or $\int_1^\infty$, thus even the series of trigonometric functions doesn't seem possible here. Mathematica gives: $$\int_0^1 \frac{1+z^2}{1+z^4} z^p \, dz=\frac{1}{8} \left(\psi \left(\frac{p+5}{8}\right)+\psi\left(\frac{p+7}{8}\right)-\psi\left(\frac{p+1}{8}\right)-\psi \left(\frac{p+3}{8}\right)\right)$$ Is a closed form possible for $I(p)$ for general $p$, not represented as an infinite series of polygamma functions, but something nicer? Maybe contour integration can help here? As a separate question, could it be possible to find an ODE for $I(p)$ as a function? It would be almost as good as a closed form to me. The motivation is this question . An asymptotic series for $p \to 0$ (obtained by integration of the Taylor series by term) starts as: $$I(p) \approx \frac{\pi}{2 \sqrt{2}} \left( 1-\frac{3 \pi ^2 p^2}{32}+\frac{95 \pi ^4 p^4}{2048}-\frac{18727 \pi ^6 p^6}{327680}+\frac{23151383 \pi ^8 p^8}{176160768}-\dots \right)=$$ $$=\sum_{n=0}^m (-1)^n \frac{A000364(n) A000281(n)}{(2n)!} \frac{\pi^{2n}}{4^{2n}}p^{2n}$$ The numerator is a product of A000364 and A000281 . However, this series does not converge - the numerator grows faster than the denominator for all $p$ as far as I can see. Update: Thanks to this great answer we can state the following: $$I(p)=\frac{\sqrt{2}}{p}I \left( \frac{2}{p} \right)$$ From this functional equation we can see that $p=\sqrt{2}$ is a special value.","Is there a closed form for: $$I(p)=\int_0^\infty \frac{1+z^2}{1+z^4} \frac{z^p}{1+z^{2p}} dz$$ The integral has a number of nice properties: $$I(p)=I(-p)$$ $$I(p)=2\int_0^1 \frac{1+z^2}{1+z^4} \frac{z^p}{1+z^{2p}} dz=2\int_1^\infty \frac{1+z^2}{1+z^4} \frac{z^p}{1+z^{2p}} dz$$ $$I(p)=\int_{0}^{\infty} \frac{\cosh y}{\cosh 2y} \frac{dy}{\cosh p y}$$ I'm pretty sure it has a closed form expression for every rational $p$, because then we will be able to get a rational function under the integral either directly or with a simple substitution. Some examples of closed form expressions: $$I(0)=\frac{\pi}{2 \sqrt{2}}$$ $$I(1)=\frac{\pi}{4}$$ $$I(2)=\frac{\pi}{4 \sqrt{2}}$$ $$I(3)=\left(\frac{2}{3 \sqrt{3}}-\frac{1}{4} \right)\pi$$ $$I(4)=\left(\sqrt{\frac{1}{2} \left(1+\frac{1}{\sqrt{2}}\right)}-\frac{1}{\sqrt{2}} \right)\frac{\pi}{2}$$ $$I(5)=\left(\frac{\sqrt{10(5+\sqrt{5})}}{25}-\frac{1}{4} \right)\pi$$ $$I \left( \frac{1}{2} \right)=\left(\sqrt{1+\frac{1}{\sqrt{2}}}-1 \right)\pi$$ $$I \left( \frac{1}{3} \right)=\left(\frac{1}{\sqrt{3}}-\frac{1}{4} \right)\pi$$ $$I \left( \frac{1}{4} \right)=\left(2-\sqrt{2+\sqrt{2-\sqrt{2}}}\right)\pi$$ $$I \left( \frac{1}{5} \right)=\left(\frac{2\sqrt{5}-1}{4}-\frac{1}{2}\sqrt{2-\frac{2}{\sqrt{5}}}\right)\pi$$ Some not very nice closed forms also appear: $$I \left( \frac{2}{7} \right)=\frac{ \pi}{8}  \left(7 \sqrt{2}+ 4 \sin ^3\left(\frac{\pi }{14}\right) \sin \left(\frac{3 \pi }{14}\right) \csc ^6\left(\frac{\pi }{7}\right) \times \\ \times \left(48 \sin ^2\left(\frac{\pi }{14}\right) \sin \left(\frac{5 \pi }{28}\right) \sin ^2\left(\frac{3 \pi }{14}\right)-4 \sin \left(\frac{\pi }{28}\right) \sin \left(\frac{3 \pi }{14}\right)+\sin \left(\frac{\pi }{14}\right) \times \\ \times \left(2 \sin \left(\frac{3 \pi }{28}\right)-\sin \left(\frac{3 \pi }{14}\right) \left(2 \csc \left(\frac{\pi }{28}\right)+\csc \left(\frac{3 \pi }{28}\right)-3 \csc \left(\frac{5 \pi }{28}\right)\right)\right)\right)\right)$$ Because we can only consider the case $z<1$ a series solution is possible, but the series contain the polygamma function and it's not very useful. A similar integral has a simple closed form: $$\int_0^{\infty } \frac{1+z^2}{1+z^4} z^p \, dz=\frac{\pi}{4}   \left(\csc \left(\frac{\pi}{4}   (p+1)\right)+\sec \left(\frac{\pi}{4}  (p+1)\right)\right)$$ This strongly hints on the Beta function, however the series expansion of the original integral will not work, beacuse the limits will be either $\int_0^1$ or $\int_1^\infty$, thus even the series of trigonometric functions doesn't seem possible here. Mathematica gives: $$\int_0^1 \frac{1+z^2}{1+z^4} z^p \, dz=\frac{1}{8} \left(\psi \left(\frac{p+5}{8}\right)+\psi\left(\frac{p+7}{8}\right)-\psi\left(\frac{p+1}{8}\right)-\psi \left(\frac{p+3}{8}\right)\right)$$ Is a closed form possible for $I(p)$ for general $p$, not represented as an infinite series of polygamma functions, but something nicer? Maybe contour integration can help here? As a separate question, could it be possible to find an ODE for $I(p)$ as a function? It would be almost as good as a closed form to me. The motivation is this question . An asymptotic series for $p \to 0$ (obtained by integration of the Taylor series by term) starts as: $$I(p) \approx \frac{\pi}{2 \sqrt{2}} \left( 1-\frac{3 \pi ^2 p^2}{32}+\frac{95 \pi ^4 p^4}{2048}-\frac{18727 \pi ^6 p^6}{327680}+\frac{23151383 \pi ^8 p^8}{176160768}-\dots \right)=$$ $$=\sum_{n=0}^m (-1)^n \frac{A000364(n) A000281(n)}{(2n)!} \frac{\pi^{2n}}{4^{2n}}p^{2n}$$ The numerator is a product of A000364 and A000281 . However, this series does not converge - the numerator grows faster than the denominator for all $p$ as far as I can see. Update: Thanks to this great answer we can state the following: $$I(p)=\frac{\sqrt{2}}{p}I \left( \frac{2}{p} \right)$$ From this functional equation we can see that $p=\sqrt{2}$ is a special value.",,"['integration', 'ordinary-differential-equations', 'definite-integrals', 'closed-form', 'gamma-function']"
20,Closed form of $\int_0^\pi \frac{\sin(x)}{\sqrt{x^3+x+1}} dx$,Closed form of,\int_0^\pi \frac{\sin(x)}{\sqrt{x^3+x+1}} dx,"I'm looking for a closed-form expression for the value of this integral: $$I=\int_0^\pi \frac{\sin(x)}{\sqrt{x^3+x+1}} dx$$ The graph of the integrand looks like this: $\hskip 2.4 in$ Numerically, the area is $0.875044...$ for which the Inverse Symbolic Calculator doesn't produce anything promising. My CAS finds neither an antiderivative nor a closed form for the definite integral, and my own manipulations haven't really got me anywhere either.","I'm looking for a closed-form expression for the value of this integral: $$I=\int_0^\pi \frac{\sin(x)}{\sqrt{x^3+x+1}} dx$$ The graph of the integrand looks like this: $\hskip 2.4 in$ Numerically, the area is $0.875044...$ for which the Inverse Symbolic Calculator doesn't produce anything promising. My CAS finds neither an antiderivative nor a closed form for the definite integral, and my own manipulations haven't really got me anywhere either.",,['integration']
21,"Asymptotic analysis of the integral $\int_0^1 \exp\{n (t+\log t) + \sqrt{n} wt\}\,dt$",Asymptotic analysis of the integral,"\int_0^1 \exp\{n (t+\log t) + \sqrt{n} wt\}\,dt","The integral I'm trying to study is $$ F(n) = \int_0^1 \exp\left\{n(t+\log t)+\sqrt{n}wt\right\}\,dt, \tag{1} $$ where $w$ is a fixed complex number with $\Re(w) < 0$ and $\Im(w) > 0$.  As I'll indicate below, I ""expect"" an asymptotic expression of the form $$ F(n) \sim A e^{n+\sqrt{n}w} n^{-1}. $$ My first attempt at estimating $(1)$ was to try to address the problem of the oscillatory integrand.  I set out to mimic the method of steepest descent and deform the contour of integration so that the imaginary part of the argument $f(n,t) = n(t+\log t)+\sqrt{n}wt$ was constant. The image below shows where $\Re(f(n,t)) = \text{const.}$ (thick lines), where $\Im(f(n,t)) = \text{const.}$ (thin lines), and the interval $(0,1)$ (red line).  The parameter $n$ has been fixed at $10$. By Cauchy's theorem I can deform the contour $(0,1)$ to the contour $C_n$, on which $$ \Im(f(n,t)) = \sqrt{n}\Im(w), $$ shown in red below. Thus I have $$ \begin{align} F(n) &= \int_{C_n} \exp\left\{n(t+\log t)+\sqrt{n}wt\right\}\,dt \\      &= \int_{C_n} \exp\left\{\Re\left(n(t+\log t)+\sqrt{n}wt\right) + \sqrt{n}\Im(w)\right\}\,dt \\      &= e^{\sqrt{n}\Im(w)} \int_{C_n} \exp\left\{n(\Re(t)+\log |t|)+\sqrt{n}\Re(wt)\right\}\,dt, \end{align} $$ so that at least now I'm dealing with a real integral.  However, I don't know where to go from here.  It's clear that $C_n \to (0,1)$ as $n \to \infty$, so I think the last integral above could be asymptotic to $$ \int_0^1 \exp\left\{n(\Re(t)+\log |t|)+\sqrt{n}\Re(wt)\right\}\,dt = \int_0^1 \exp\left\{n(t+\log t)+\sqrt{n}\Re(w)t\right\}\,dt, \tag{2} $$ but I don't know how to bound the ""error"" $$ \int_{E_n} \exp\left\{n(\Re(t)+\log |t|)+\sqrt{n}\Re(wt)\right\}\,dt, $$ where $E_n$ is the closed loop $C_n \cup -(0,1)$, shown below. If this error is sufficiently small, I could see if I could apply the general ideas of the standard Laplace method to the real integral $(2)$, though it's not of the usual form.  My guess would be that $$ \int_0^1 \exp\left\{n(t+\log t)+\sqrt{n}\Re(w)t\right\}\,dt \sim A e^{n+\sqrt{n}\Re(w)} n^{-1} $$ since the largest contribution to the integral comes from a neighborhood of $t=1$. Any help would be greatly appreciated.","The integral I'm trying to study is $$ F(n) = \int_0^1 \exp\left\{n(t+\log t)+\sqrt{n}wt\right\}\,dt, \tag{1} $$ where $w$ is a fixed complex number with $\Re(w) < 0$ and $\Im(w) > 0$.  As I'll indicate below, I ""expect"" an asymptotic expression of the form $$ F(n) \sim A e^{n+\sqrt{n}w} n^{-1}. $$ My first attempt at estimating $(1)$ was to try to address the problem of the oscillatory integrand.  I set out to mimic the method of steepest descent and deform the contour of integration so that the imaginary part of the argument $f(n,t) = n(t+\log t)+\sqrt{n}wt$ was constant. The image below shows where $\Re(f(n,t)) = \text{const.}$ (thick lines), where $\Im(f(n,t)) = \text{const.}$ (thin lines), and the interval $(0,1)$ (red line).  The parameter $n$ has been fixed at $10$. By Cauchy's theorem I can deform the contour $(0,1)$ to the contour $C_n$, on which $$ \Im(f(n,t)) = \sqrt{n}\Im(w), $$ shown in red below. Thus I have $$ \begin{align} F(n) &= \int_{C_n} \exp\left\{n(t+\log t)+\sqrt{n}wt\right\}\,dt \\      &= \int_{C_n} \exp\left\{\Re\left(n(t+\log t)+\sqrt{n}wt\right) + \sqrt{n}\Im(w)\right\}\,dt \\      &= e^{\sqrt{n}\Im(w)} \int_{C_n} \exp\left\{n(\Re(t)+\log |t|)+\sqrt{n}\Re(wt)\right\}\,dt, \end{align} $$ so that at least now I'm dealing with a real integral.  However, I don't know where to go from here.  It's clear that $C_n \to (0,1)$ as $n \to \infty$, so I think the last integral above could be asymptotic to $$ \int_0^1 \exp\left\{n(\Re(t)+\log |t|)+\sqrt{n}\Re(wt)\right\}\,dt = \int_0^1 \exp\left\{n(t+\log t)+\sqrt{n}\Re(w)t\right\}\,dt, \tag{2} $$ but I don't know how to bound the ""error"" $$ \int_{E_n} \exp\left\{n(\Re(t)+\log |t|)+\sqrt{n}\Re(wt)\right\}\,dt, $$ where $E_n$ is the closed loop $C_n \cup -(0,1)$, shown below. If this error is sufficiently small, I could see if I could apply the general ideas of the standard Laplace method to the real integral $(2)$, though it's not of the usual form.  My guess would be that $$ \int_0^1 \exp\left\{n(t+\log t)+\sqrt{n}\Re(w)t\right\}\,dt \sim A e^{n+\sqrt{n}\Re(w)} n^{-1} $$ since the largest contribution to the integral comes from a neighborhood of $t=1$. Any help would be greatly appreciated.",,"['complex-analysis', 'integration', 'asymptotics']"
22,A problem for the New Year [closed],A problem for the New Year [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question What better to start the year than a dazzling integral? $$\int_{0}^{\infty}\left[1+\left(\frac{2013}{x+2013}+\cdots +\frac{2}{x+2}+\frac{1}{x+1}-x\right)^{2014}\,\right]^{-1}\,dx$$ Happy New Year to the mathematical community! (I am not too familiar with the posting policies on this site, hopefully this is not a major breach of rules)","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question What better to start the year than a dazzling integral? $$\int_{0}^{\infty}\left[1+\left(\frac{2013}{x+2013}+\cdots +\frac{2}{x+2}+\frac{1}{x+1}-x\right)^{2014}\,\right]^{-1}\,dx$$ Happy New Year to the mathematical community! (I am not too familiar with the posting policies on this site, hopefully this is not a major breach of rules)",,"['integration', 'recreational-mathematics', 'improper-integrals']"
23,A way of evaluating integrals without doing anything?,A way of evaluating integrals without doing anything?,,"The user known as sos440 posted this: $$\begin{align*} \sum_{n=0}^\infty \frac{r^n}{n!} \int_0^\infty x^n e^{-x} \; dx & = \int_{0}^\infty \sum_{n=0}^\infty \frac{(rx)^n}{n!} e^{-x} \; dx = \int_0^\infty e^{-(1 - r)x} \; dx \\ & = \frac{1}{1 - r} = \sum_{n=0}^\infty r^n \end{align*}$$ (citing Tonelli's theorem to justify interchanging the sum and the integral), and concluded that $$ \frac{1}{n!}\int_0^\infty x^n e^{-x}\,dx=1. $$ Is this a very isolated thing or just an instance of something generally useful for some much broader class of integrals? (Obviously, what is seen below is generally true, but how generally is it useful?) $$ \sum_{n=0}^\infty r^n \int_A f_n(x)\,dx = \int_A \sum_{n=0}^\infty \big( r^nf_n(x) \big) \, dx = \int_A g(r,x) \, dx = h(r) = \sum_{n=0}^\infty c_n r^n $$ $$ \therefore \int_A f_n(x)\,dx = c_n. $$","The user known as sos440 posted this: $$\begin{align*} \sum_{n=0}^\infty \frac{r^n}{n!} \int_0^\infty x^n e^{-x} \; dx & = \int_{0}^\infty \sum_{n=0}^\infty \frac{(rx)^n}{n!} e^{-x} \; dx = \int_0^\infty e^{-(1 - r)x} \; dx \\ & = \frac{1}{1 - r} = \sum_{n=0}^\infty r^n \end{align*}$$ (citing Tonelli's theorem to justify interchanging the sum and the integral), and concluded that $$ \frac{1}{n!}\int_0^\infty x^n e^{-x}\,dx=1. $$ Is this a very isolated thing or just an instance of something generally useful for some much broader class of integrals? (Obviously, what is seen below is generally true, but how generally is it useful?) $$ \sum_{n=0}^\infty r^n \int_A f_n(x)\,dx = \int_A \sum_{n=0}^\infty \big( r^nf_n(x) \big) \, dx = \int_A g(r,x) \, dx = h(r) = \sum_{n=0}^\infty c_n r^n $$ $$ \therefore \int_A f_n(x)\,dx = c_n. $$",,"['integration', 'definite-integrals']"
24,Calculate $\int_{0}^\infty\frac{dx}{\left(1+\frac{x^3}{1^3}\right)\left(1+\frac{x^3}{2^3}\right)\left(1+\frac{x^3}{3^3}\right)\ldots}$,Calculate,\int_{0}^\infty\frac{dx}{\left(1+\frac{x^3}{1^3}\right)\left(1+\frac{x^3}{2^3}\right)\left(1+\frac{x^3}{3^3}\right)\ldots},"I'm interested in the integral $$ I=\int_{0}^\infty\frac{dx}{\left(1+\frac{x^3}{1^3}\right)\left(1+\frac{x^3}{2^3}\right)\left(1+\frac{x^3}{3^3}\right)\ldots}.\tag{1} $$ So far I have been able to reduce this integral to an integral of an elementary function in the hope that it will be more tractable $$ I=\frac{8\pi}{\sqrt{3}}\int_{-\infty}^\infty\frac{e^{ix\sqrt{3}}\ dx}{\left(e^x+e^{-x}+e^{ix\sqrt{3}}\right)^3},\tag{2} $$ using the approach from this question . In that question it was also proved that $$ \int_{-\infty}^\infty\frac{dx}{\left(e^x+e^{-x}+e^{ix\sqrt{3}}\right)^2}=\frac{1}{3},\tag{3} $$ which gives some indication that the integral in the right hand side of $(2)$ might be calculable. Also note that the integrand in $(1)$ can be expressed as  $$ \Gamma(x+1)\left|\Gamma\left(1+e^{\frac{2\pi i}{3}}x\right)\right|^2. $$ Bending the contour of integration in the integral on the RHS of $(2)$ one obtains an alternative representation $$ I=8\pi\int_0^\infty\frac{e^{x\sqrt{3}}~dx}{\left(2\cos x+e^{x\sqrt{3}}\right)^3}.\tag{4} $$ There are some calculable integrals containing the infinite product $\prod\limits_{k=1}^\infty\left(1+\frac{x^3}{k^3}\right)$, e.g. $$ \int_{0}^\infty\frac{\left(1-e^{\pi\sqrt{3}x}\cos\pi x\right)e^{-\frac{2\pi}{\sqrt{3}}x}\ dx}{x\left(1+\frac{x^3}{1^3}\right)\left(1+\frac{x^3}{2^3}\right)\left(1+\frac{x^3}{3^3}\right)\ldots}=0. $$ Q: Is it possible to calculate $(1)$ in closed form?","I'm interested in the integral $$ I=\int_{0}^\infty\frac{dx}{\left(1+\frac{x^3}{1^3}\right)\left(1+\frac{x^3}{2^3}\right)\left(1+\frac{x^3}{3^3}\right)\ldots}.\tag{1} $$ So far I have been able to reduce this integral to an integral of an elementary function in the hope that it will be more tractable $$ I=\frac{8\pi}{\sqrt{3}}\int_{-\infty}^\infty\frac{e^{ix\sqrt{3}}\ dx}{\left(e^x+e^{-x}+e^{ix\sqrt{3}}\right)^3},\tag{2} $$ using the approach from this question . In that question it was also proved that $$ \int_{-\infty}^\infty\frac{dx}{\left(e^x+e^{-x}+e^{ix\sqrt{3}}\right)^2}=\frac{1}{3},\tag{3} $$ which gives some indication that the integral in the right hand side of $(2)$ might be calculable. Also note that the integrand in $(1)$ can be expressed as  $$ \Gamma(x+1)\left|\Gamma\left(1+e^{\frac{2\pi i}{3}}x\right)\right|^2. $$ Bending the contour of integration in the integral on the RHS of $(2)$ one obtains an alternative representation $$ I=8\pi\int_0^\infty\frac{e^{x\sqrt{3}}~dx}{\left(2\cos x+e^{x\sqrt{3}}\right)^3}.\tag{4} $$ There are some calculable integrals containing the infinite product $\prod\limits_{k=1}^\infty\left(1+\frac{x^3}{k^3}\right)$, e.g. $$ \int_{0}^\infty\frac{\left(1-e^{\pi\sqrt{3}x}\cos\pi x\right)e^{-\frac{2\pi}{\sqrt{3}}x}\ dx}{x\left(1+\frac{x^3}{1^3}\right)\left(1+\frac{x^3}{2^3}\right)\left(1+\frac{x^3}{3^3}\right)\ldots}=0. $$ Q: Is it possible to calculate $(1)$ in closed form?",,"['integration', 'definite-integrals', 'special-functions', 'gamma-function', 'infinite-product']"
25,Why doesn't integrating the area of the square give the volume of the cube?,Why doesn't integrating the area of the square give the volume of the cube?,,"I had a calculus course this semester in which I was taught that the integration of the area gives the size (volume): $$V = \int\limits_a^b {A(x)dx}$$ But this doesn't seem to work with the square. Since the size of the area of the square is $x^2$ then $A(x) = {x^2}$, then: $$V = \int\limits_{ - r}^r {{x^2}dx}  = \left[ {\frac{{{x^3}}}{3}} \right]_{ - r}^r = \frac{{{r^3}}}{3} - \frac{{ - {r^3}}}{3} = \frac{2}{3}{r^3}$$ It's clear that this is not the volume of the cube. Why is this the case? Am I misunderstanding something?","I had a calculus course this semester in which I was taught that the integration of the area gives the size (volume): $$V = \int\limits_a^b {A(x)dx}$$ But this doesn't seem to work with the square. Since the size of the area of the square is $x^2$ then $A(x) = {x^2}$, then: $$V = \int\limits_{ - r}^r {{x^2}dx}  = \left[ {\frac{{{x^3}}}{3}} \right]_{ - r}^r = \frac{{{r^3}}}{3} - \frac{{ - {r^3}}}{3} = \frac{2}{3}{r^3}$$ It's clear that this is not the volume of the cube. Why is this the case? Am I misunderstanding something?",,[]
26,"A simple way to evaluate $\int_{-a}^a \frac{x^2}{x^4+1} \, \mathrm dx$?",A simple way to evaluate ?,"\int_{-a}^a \frac{x^2}{x^4+1} \, \mathrm dx","I am currently trying to show that $\int_{-\infty}^\infty \cos(x^2) \, \mathrm dx = \sqrt{\frac{\pi}{2}}$ and the last integral I have to evaluate is $$\int_{-a}^a \frac{x^2}{x^4+1} \, \mathrm dx.$$ Now of course I'm familiar with wolframalpha, however the way it solves this integral seems very awkward and also not elegant to me, even though the function to me looks quite simple. So, is there a simpler way to solve this integral or is the way described on wolframalpha already (one of) the simplest approach(es)? I ask this because often wolframalpha doesn't see tricks (occurred to me when I wanted to find a formula for the n-th derivative of some function) which a human eye might see. Thanks for any answers in advance.","I am currently trying to show that $\int_{-\infty}^\infty \cos(x^2) \, \mathrm dx = \sqrt{\frac{\pi}{2}}$ and the last integral I have to evaluate is $$\int_{-a}^a \frac{x^2}{x^4+1} \, \mathrm dx.$$ Now of course I'm familiar with wolframalpha, however the way it solves this integral seems very awkward and also not elegant to me, even though the function to me looks quite simple. So, is there a simpler way to solve this integral or is the way described on wolframalpha already (one of) the simplest approach(es)? I ask this because often wolframalpha doesn't see tricks (occurred to me when I wanted to find a formula for the n-th derivative of some function) which a human eye might see. Thanks for any answers in advance.",,"['integration', 'analysis', 'definite-integrals']"
27,"Integrate: $ \int_0^\infty \frac{\log(x)}{(1+x^2)^2} \, dx $ without using complex analysis methods",Integrate:  without using complex analysis methods," \int_0^\infty \frac{\log(x)}{(1+x^2)^2} \, dx ","Can this integral be solved without using any complex analysis methods: $$ \int_0^\infty \frac{\log(x)}{(1+x^2)^2} \, dx $$ Thanks.","Can this integral be solved without using any complex analysis methods: $$ \int_0^\infty \frac{\log(x)}{(1+x^2)^2} \, dx $$ Thanks.",,"['integration', 'improper-integrals']"
28,How can I compute the integral $\int_{0}^{\infty} \frac{dt}{1+t^4}$?,How can I compute the integral ?,\int_{0}^{\infty} \frac{dt}{1+t^4},"I have to compute this integral $$\int_{0}^{\infty} \frac{dt}{1+t^4}$$ to solve a problem in a homework. I have tried in many ways, but I'm stuck. A search in the web reveals me that it can be do it by methods of complex analysis. But I have not taken this course yet. Thanks for any help.","I have to compute this integral $$\int_{0}^{\infty} \frac{dt}{1+t^4}$$ to solve a problem in a homework. I have tried in many ways, but I'm stuck. A search in the web reveals me that it can be do it by methods of complex analysis. But I have not taken this course yet. Thanks for any help.",,"['analysis', 'integration']"
29,$\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} d\alpha d\beta=(0.9999999913...)(\pi/2)$? Seriously?,? Seriously?,\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} d\alpha d\beta=(0.9999999913...)(\pi/2),"In the diagram, $\alpha$ and $\beta$ are independent uniformly random real numbers in $\left(0,\frac{\pi}{2}\right)$ . What is $\mathbb{E}(h)$ ? Superimposing a cartesian coordinate system, the equations of the lines are $y=(\tan\alpha)x$ and $y=(-\tan\beta)(x-1)$ , so the $y$ -coordinate of their intersection is $\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta}$ . So we have $$\mathbb{E}(h)=\frac{4}{\pi^2}\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} d\alpha d\beta$$ Desmos says $I=\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} d\alpha d\beta$ is $(0.9999999913...)(\frac{\pi}{2})$ . Is that a computer error, and the result is exactly $\frac{\pi}{2}$ ? I don't know how to evaluate the integral. Wolfram evaluates the inside integral but doesn't evaluate both integrals . If Desmos is not very reliable, then maybe my earlier weird conjecture is actually true. (This question was inspired by a question about random points in a square.) Edit : In the comments, @G.Gare notes that Mathematica says the integral $I$ is exactly $\pi/2$ . Can we prove it? Maybe an intuitive geometrical argument? Edit2: I seek to generalize this result here .","In the diagram, and are independent uniformly random real numbers in . What is ? Superimposing a cartesian coordinate system, the equations of the lines are and , so the -coordinate of their intersection is . So we have Desmos says is . Is that a computer error, and the result is exactly ? I don't know how to evaluate the integral. Wolfram evaluates the inside integral but doesn't evaluate both integrals . If Desmos is not very reliable, then maybe my earlier weird conjecture is actually true. (This question was inspired by a question about random points in a square.) Edit : In the comments, @G.Gare notes that Mathematica says the integral is exactly . Can we prove it? Maybe an intuitive geometrical argument? Edit2: I seek to generalize this result here .","\alpha \beta \left(0,\frac{\pi}{2}\right) \mathbb{E}(h) y=(\tan\alpha)x y=(-\tan\beta)(x-1) y \frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} \mathbb{E}(h)=\frac{4}{\pi^2}\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} d\alpha d\beta I=\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} d\alpha d\beta (0.9999999913...)(\frac{\pi}{2}) \frac{\pi}{2} I \pi/2","['integration', 'geometry', 'definite-integrals', 'expected-value', 'conjectures']"
30,Integrate $\int\sqrt\frac{\sin(x-a)}{\sin(x+a)}dx$,Integrate,\int\sqrt\frac{\sin(x-a)}{\sin(x+a)}dx,"Integrate   $$I=\int\sqrt\frac{\sin(x-a)}{\sin(x+a)}dx$$ Let $$\begin{align}u^2=\frac{\sin(x-a)}{\sin(x+a)}\implies 2udu&=\frac{\sin(x+a)\cos(x-a)-\sin(x-a)\cos(x+a)}{\sin^2(x+a)}dx\\2udu&=\frac{\sin((x+a)-(x-a))}{\sin^2(x+a)}dx\\ 2udu&=\frac{\sin(2a)}{\sin^2(x+a)}dx\end{align}$$ Now:  $$\begin{align}u^2&=\frac{\sin(x+a-2a)}{\sin(x+a)} \\u^2&=\frac{\sin(x+a)\cos(2a)-\cos(x+a)\sin(2a)}{\sin(x+a)} \\u^2&=\cos(2a)-\sin(2a)\cot(x+a) \\\cot(x+a)&=(\cos(2a)-u^2)\csc(2a) \\\csc^2(x+a)=\cot^2(x+a)+1&=(\cos(2a)-u^2)^2\csc^2(2a)+1 \\\csc^2(x+a)&=\frac{\cos^2(2a)+u^4-2u^2\cos2(2a)+\sin^2(2a)}{\csc^2(2a)} \\\sin^2(x+a)&=\frac{\sin^2(2a)}{u^4-2u^2\cos(2a)+1}\end{align}$$ Now: $$\begin{align} I&=\int u.\frac{2udu\sin^2(x+a)}{\sin(2a)}\\ I&=\int\frac2{\sin(2a)}.u^2.\frac{\sin^2(2a)}{u^4-2u^2\cos(2a)+1}du \\I&=2\sin(2a)\int\frac{u^2}{u^4-2ku^2+1}du\quad k:=\cos 2a \\\frac If&=\int\frac{2+u^{-2}-u^{-2}}{u^2-2k+u^{-2}}du=\int\frac{1+u^{-2}}{u^2-2k+u^{-2}}du+\int\frac{1-u^{-2}}{u^2-2k+u^{-2}}du\quad \\f:=\sin(2a) \\&=\int\frac{d(u-u^{-1})}{(u-u^{-1})^2+2-2k}+\int\frac{d(u+u^{-1})}{(u+u^{-1})^2-2-2k}\end{align}$$ Now: $2-2k=2(1-\cos 2a)=4\sin^24a,2+2k=2(1+\cos 2a)=4\cos^24a$ So: $$I=\sin2a\left(\frac1{2\sin4a}\arctan\left(\frac{u-u^{-1}}{2\sin(4a)}\right)+\frac1{4\cos4a}\ln\left|\frac{u+u^{-1}-2\cos 4a}{u+u^{-1}+2\cos 4a}\right|\right)+C$$ Or: $$I=\frac1{4\cos2a}\arctan\left(\frac{-\sin a\cos x}{\sin4a\sqrt{\sin(x+a)\sin(x-a)}}\right)+\frac{\sin2a}{4\cos 4a}\ln\left|\frac{\sin x\cos a-\cos4a\sqrt{\sin(x+a)\sin(x-a)}}{\sin x\cos a+\cos4a\sqrt{\sin(x+a)\sin(x-a)}}\right|+C$$ But the textbook answer is: $$\cos a\arccos\left(\frac{\cos x}{\cos a}\right)-\sin a\ln(\sin x+\sqrt{\sin^2x-\sin^2a})+c$$","Integrate   $$I=\int\sqrt\frac{\sin(x-a)}{\sin(x+a)}dx$$ Let $$\begin{align}u^2=\frac{\sin(x-a)}{\sin(x+a)}\implies 2udu&=\frac{\sin(x+a)\cos(x-a)-\sin(x-a)\cos(x+a)}{\sin^2(x+a)}dx\\2udu&=\frac{\sin((x+a)-(x-a))}{\sin^2(x+a)}dx\\ 2udu&=\frac{\sin(2a)}{\sin^2(x+a)}dx\end{align}$$ Now:  $$\begin{align}u^2&=\frac{\sin(x+a-2a)}{\sin(x+a)} \\u^2&=\frac{\sin(x+a)\cos(2a)-\cos(x+a)\sin(2a)}{\sin(x+a)} \\u^2&=\cos(2a)-\sin(2a)\cot(x+a) \\\cot(x+a)&=(\cos(2a)-u^2)\csc(2a) \\\csc^2(x+a)=\cot^2(x+a)+1&=(\cos(2a)-u^2)^2\csc^2(2a)+1 \\\csc^2(x+a)&=\frac{\cos^2(2a)+u^4-2u^2\cos2(2a)+\sin^2(2a)}{\csc^2(2a)} \\\sin^2(x+a)&=\frac{\sin^2(2a)}{u^4-2u^2\cos(2a)+1}\end{align}$$ Now: $$\begin{align} I&=\int u.\frac{2udu\sin^2(x+a)}{\sin(2a)}\\ I&=\int\frac2{\sin(2a)}.u^2.\frac{\sin^2(2a)}{u^4-2u^2\cos(2a)+1}du \\I&=2\sin(2a)\int\frac{u^2}{u^4-2ku^2+1}du\quad k:=\cos 2a \\\frac If&=\int\frac{2+u^{-2}-u^{-2}}{u^2-2k+u^{-2}}du=\int\frac{1+u^{-2}}{u^2-2k+u^{-2}}du+\int\frac{1-u^{-2}}{u^2-2k+u^{-2}}du\quad \\f:=\sin(2a) \\&=\int\frac{d(u-u^{-1})}{(u-u^{-1})^2+2-2k}+\int\frac{d(u+u^{-1})}{(u+u^{-1})^2-2-2k}\end{align}$$ Now: $2-2k=2(1-\cos 2a)=4\sin^24a,2+2k=2(1+\cos 2a)=4\cos^24a$ So: $$I=\sin2a\left(\frac1{2\sin4a}\arctan\left(\frac{u-u^{-1}}{2\sin(4a)}\right)+\frac1{4\cos4a}\ln\left|\frac{u+u^{-1}-2\cos 4a}{u+u^{-1}+2\cos 4a}\right|\right)+C$$ Or: $$I=\frac1{4\cos2a}\arctan\left(\frac{-\sin a\cos x}{\sin4a\sqrt{\sin(x+a)\sin(x-a)}}\right)+\frac{\sin2a}{4\cos 4a}\ln\left|\frac{\sin x\cos a-\cos4a\sqrt{\sin(x+a)\sin(x-a)}}{\sin x\cos a+\cos4a\sqrt{\sin(x+a)\sin(x-a)}}\right|+C$$ But the textbook answer is: $$\cos a\arccos\left(\frac{\cos x}{\cos a}\right)-\sin a\ln(\sin x+\sqrt{\sin^2x-\sin^2a})+c$$",,['integration']
31,How closely can we estimate $\sum_{i=0}^n \sqrt{i}$,How closely can we estimate,\sum_{i=0}^n \sqrt{i},By looking at an integral and bounding the error?,By looking at an integral and bounding the error?,,"['sequences-and-series', 'integration']"
32,Solve this integral for free WiFi,Solve this integral for free WiFi,,"I saw this today, I checked in Mathematica and the integral comes out to $\pi$ , but I have no idea how to solve it. FREE Wi-Fi: The Wi-Fi password is the first $10$ digits of the answer. $$\int_{-2}^2\left(x^3\cos\frac x2+\frac12\right)\sqrt{4-x^2}\ dx$$","I saw this today, I checked in Mathematica and the integral comes out to , but I have no idea how to solve it. FREE Wi-Fi: The Wi-Fi password is the first digits of the answer.",\pi 10 \int_{-2}^2\left(x^3\cos\frac x2+\frac12\right)\sqrt{4-x^2}\ dx,"['integration', 'definite-integrals']"
33,Derivative of double integral with respect to upper limits,Derivative of double integral with respect to upper limits,,"How do I perform the following? $$\frac{d}{dx} \int_0^x \int_0^x f(y,z) \;dy\; dz$$ Help/hints would be appreciated. The Leibniz rule for integration does not seem to be applicable.","How do I perform the following? $$\frac{d}{dx} \int_0^x \int_0^x f(y,z) \;dy\; dz$$ Help/hints would be appreciated. The Leibniz rule for integration does not seem to be applicable.",,"['integration', 'derivatives']"
34,Why does 'The King Property' of integration work?,Why does 'The King Property' of integration work?,,"Today I learned about something known as the king's property which really helps in solving integrals and I wanted to know why does this property work. I dont know if this terminology is used elsewhere , so what im talking about is this property $$ \int_a^b f(x)dx = \int_a^b f(a+b-x)dx $$","Today I learned about something known as the king's property which really helps in solving integrals and I wanted to know why does this property work. I dont know if this terminology is used elsewhere , so what im talking about is this property", \int_a^b f(x)dx = \int_a^b f(a+b-x)dx ,"['integration', 'definite-integrals']"
35,Computing $\int_0^\infty\frac1{(x+1)(x+2)\cdots(x+n)}\mathrm dx $,Computing,\int_0^\infty\frac1{(x+1)(x+2)\cdots(x+n)}\mathrm dx ,I would like to compute: $$\int_0^\infty\frac1{(x+1)(x+2)\cdots(x+n)}\mathrm dx $$ $$ n\geq 2$$ So my question is how can I find the partial fraction expansion of $$\frac1{(x+1)(x+2)\cdots(x+n)}\ ?$$,I would like to compute: So my question is how can I find the partial fraction expansion of,\int_0^\infty\frac1{(x+1)(x+2)\cdots(x+n)}\mathrm dx   n\geq 2 \frac1{(x+1)(x+2)\cdots(x+n)}\ ?,"['analysis', 'integration', 'improper-integrals', 'partial-fractions']"
36,Almost Stirling's Approximation,Almost Stirling's Approximation,,"I need to prove the following bound $$n! \le e \sqrt n \left( \frac n e \right)^n$$ I can bound $\ln 1 + \ln 2 + \dots + \ln n$ as a Riemann sum with the function $\ln(n+1)$ and the trapezoidal rule: $$(\ln 1)/2 + \sum_{i=2}^n \ln i \ + (\ln(n+1))/2 < \int_0^n \ln (x+1) dx $$ Integrating I get the bound $$n! < \left( \frac{n+1}{e} \right)^n \sqrt{n+1}$$ As $n$ goes to infinity, my bound and the required bound get arbitrarily close (for $n=1$, the error is about $4\%$), but the one I need to prove is slightly tighter. How can I modify my bound to get the required bound?","I need to prove the following bound $$n! \le e \sqrt n \left( \frac n e \right)^n$$ I can bound $\ln 1 + \ln 2 + \dots + \ln n$ as a Riemann sum with the function $\ln(n+1)$ and the trapezoidal rule: $$(\ln 1)/2 + \sum_{i=2}^n \ln i \ + (\ln(n+1))/2 < \int_0^n \ln (x+1) dx $$ Integrating I get the bound $$n! < \left( \frac{n+1}{e} \right)^n \sqrt{n+1}$$ As $n$ goes to infinity, my bound and the required bound get arbitrarily close (for $n=1$, the error is about $4\%$), but the one I need to prove is slightly tighter. How can I modify my bound to get the required bound?",,"['integration', 'approximation', 'factorial', 'upper-lower-bounds']"
37,Reverse Cauchy Schwarz for integrals,Reverse Cauchy Schwarz for integrals,,"Let $f,g$ be two continuous positive functions over $[a,b]$ Let $m_1$ and $M_1$ be the minimum and maximum of $f$ Let $m_2$ and $M_2$ be the minimum and maximum of $g$ Prove that $$\sqrt{\int_a^bf^2 \int_a^b g^2}\leq \frac{1}{2}\left(\sqrt{\frac{M_1M_2}{m_1m_2}}+\sqrt{\frac{m_1m_2}{M_1M_2}}\right)\int_a^bfg$$ I can't make any significant progress on this one... Thanks for any hint.",Let be two continuous positive functions over Let and be the minimum and maximum of Let and be the minimum and maximum of Prove that I can't make any significant progress on this one... Thanks for any hint.,"f,g [a,b] m_1 M_1 f m_2 M_2 g \sqrt{\int_a^bf^2 \int_a^b g^2}\leq \frac{1}{2}\left(\sqrt{\frac{M_1M_2}{m_1m_2}}+\sqrt{\frac{m_1m_2}{M_1M_2}}\right)\int_a^bfg","['integration', 'inequality', 'integral-inequality']"
38,Computing $\int_{-\infty}^\infty \frac{\sin x}{x} \mathrm{d}x$ with residue calculus,Computing  with residue calculus,\int_{-\infty}^\infty \frac{\sin x}{x} \mathrm{d}x,"This refers back to $\int_{-\infty}^\infty \frac{\sin x}{x} \mathrm{d}x = \frac\pi2$ already posted. How do I arrive at $\frac\pi2$ using the residue theorem ? I'm at the following point: $$\int \frac{e^{iz}}{z} - \int \frac{e^{iz}}{z},$$ and I would appreciate any help.",This refers back to already posted. How do I arrive at using the residue theorem ? I'm at the following point: and I would appreciate any help.,"\int_{-\infty}^\infty \frac{\sin x}{x} \mathrm{d}x = \frac\pi2 \frac\pi2 \int \frac{e^{iz}}{z} - \int \frac{e^{iz}}{z},","['integration', 'complex-analysis', 'definite-integrals', 'improper-integrals', 'residue-calculus']"
39,A lucky proof for the Basel problem.,A lucky proof for the Basel problem.,,"I'll modify this part since I want the proof to be here. $$\sum_{n=1}^\infty \frac{1}{n^2}=\frac43\sum_{n=0}^\infty \frac{1}{(2n+1)^2}=-\frac43\sum_{n=0}^\infty \int_0^1 x^{2n}\ln x dx=\frac43\int_0^1 \frac{\ln x}{x^2-1}dx$$ $$\int_0^1 \frac{\ln x}{x^2-1}dx\overset{x\rightarrow \frac{1}{x}}=\int_1^\infty \frac{\ln x}{x^2-1}dx\Rightarrow \sum_{n=1}^\infty \frac{1}{n^2}=\frac23 \int_0^\infty \frac{\ln x}{(x+1)(x-1)}dx$$ $$=\frac23 I(1,-1)=\frac23 \frac{\ln^2 (1)-\ln^2(-1)}{2(1-(-1))}=\frac23 \frac{\pi^2}{4}=\frac{\pi^2}{6}$$ Where we considered the following integral: $$I(a,b)=\int_0^\infty \frac{\ln x}{(x+a)(x+b)}dx\overset{x\rightarrow  \frac{ab}{x}}=\int_0^\infty \frac{\ln\left(\frac{ab}{x}\right)}{(x+a)(x+b)}dx$$ Summing up the two integrals from above gives: $$2I(a,b)=\ln(ab)\int_0^\infty \frac{1}{(x+a)(x+b)}dx=\frac{\ln(ab)}{a-b}\ln\left(\frac{x+b}{x+a}\right)\bigg|_0^\infty $$ $$\Rightarrow I(a,b)=\frac{\ln(ab)}{2}\frac{\ln\left(\frac{a}{b}\right)}{a-b}=\frac{\ln^2 a-\ln^2 b}{2(a-b)}$$ From here we know that: $$\int_0^\infty \frac{\ln x}{(x+a)(x-1)}dx=\frac{\ln^2 a+\pi^2}{2(a+1)} $$ Also by plugging $b=-1$ in $I(a,b)$ we get: $$I(a,-1)=\int_0^\infty \frac{\ln x}{(x+a)(x-1)}dx=\frac{\ln^2a -\ln^2 (-1)}{2(a-(-1))}=\frac{\ln^2 a+\pi^2 }{2(a+1)}$$ We already know that this is true from the linked post, but let's ignore it, since the linked post uses the Basel problem to prove the result. Can someone prove rigorously that we are allowed to plug in $b=-1$ in order to get the correct result?","I'll modify this part since I want the proof to be here. Where we considered the following integral: Summing up the two integrals from above gives: From here we know that: Also by plugging in we get: We already know that this is true from the linked post, but let's ignore it, since the linked post uses the Basel problem to prove the result. Can someone prove rigorously that we are allowed to plug in in order to get the correct result?","\sum_{n=1}^\infty \frac{1}{n^2}=\frac43\sum_{n=0}^\infty \frac{1}{(2n+1)^2}=-\frac43\sum_{n=0}^\infty \int_0^1 x^{2n}\ln x dx=\frac43\int_0^1 \frac{\ln x}{x^2-1}dx \int_0^1 \frac{\ln x}{x^2-1}dx\overset{x\rightarrow \frac{1}{x}}=\int_1^\infty \frac{\ln x}{x^2-1}dx\Rightarrow \sum_{n=1}^\infty \frac{1}{n^2}=\frac23 \int_0^\infty \frac{\ln x}{(x+1)(x-1)}dx =\frac23 I(1,-1)=\frac23 \frac{\ln^2 (1)-\ln^2(-1)}{2(1-(-1))}=\frac23 \frac{\pi^2}{4}=\frac{\pi^2}{6} I(a,b)=\int_0^\infty \frac{\ln x}{(x+a)(x+b)}dx\overset{x\rightarrow  \frac{ab}{x}}=\int_0^\infty \frac{\ln\left(\frac{ab}{x}\right)}{(x+a)(x+b)}dx 2I(a,b)=\ln(ab)\int_0^\infty \frac{1}{(x+a)(x+b)}dx=\frac{\ln(ab)}{a-b}\ln\left(\frac{x+b}{x+a}\right)\bigg|_0^\infty  \Rightarrow I(a,b)=\frac{\ln(ab)}{2}\frac{\ln\left(\frac{a}{b}\right)}{a-b}=\frac{\ln^2 a-\ln^2 b}{2(a-b)} \int_0^\infty \frac{\ln x}{(x+a)(x-1)}dx=\frac{\ln^2 a+\pi^2}{2(a+1)}  b=-1 I(a,b) I(a,-1)=\int_0^\infty \frac{\ln x}{(x+a)(x-1)}dx=\frac{\ln^2a -\ln^2 (-1)}{2(a-(-1))}=\frac{\ln^2 a+\pi^2 }{2(a+1)} b=-1","['integration', 'sequences-and-series', 'proof-verification', 'improper-integrals']"
40,Evaluate $\int \frac{(x^2-1)(x^2+3)}{x^4-2x^3-6x-1}dx$ using elementary methods,Evaluate  using elementary methods,\int \frac{(x^2-1)(x^2+3)}{x^4-2x^3-6x-1}dx,"I found this problem while doing some integration from my problem practice book (unkown name). It said to evaluate it using elementary methods. Please help me evaluating the following integral using elementary methods $$\int \frac{(x^2-1)(x^2+3)}{x^4-2x^3-6x-1} \, dx.$$ I tried to factorize the denominator but it failed. I can't think of any substitution too. I tried to input this at wolfram alpha, and it showed the answer as a summation of a complex function formed using complex cube roots of unity. Substitution of $x=\sec\theta$ also failed. I am continuously thinking of this but I'm not getting how to start it. If I succeed I will post it. It will be great if someone could give a beautiful solution to this problem preferably using elementary methods. I am a high school student in India. I know how to evaluate elementary integrals .","I found this problem while doing some integration from my problem practice book (unkown name). It said to evaluate it using elementary methods. Please help me evaluating the following integral using elementary methods I tried to factorize the denominator but it failed. I can't think of any substitution too. I tried to input this at wolfram alpha, and it showed the answer as a summation of a complex function formed using complex cube roots of unity. Substitution of also failed. I am continuously thinking of this but I'm not getting how to start it. If I succeed I will post it. It will be great if someone could give a beautiful solution to this problem preferably using elementary methods. I am a high school student in India. I know how to evaluate elementary integrals .","\int \frac{(x^2-1)(x^2+3)}{x^4-2x^3-6x-1} \, dx. x=\sec\theta","['integration', 'indefinite-integrals']"
41,"Proving $\int_{\sqrt{\frac{3}{5}}}^1 \frac{\arctan (x)}{\sqrt{2 x^2-1} \left(3 x^2-1\right)} \, dx=\frac{3 \pi ^2}{160}$",Proving,"\int_{\sqrt{\frac{3}{5}}}^1 \frac{\arctan (x)}{\sqrt{2 x^2-1} \left(3 x^2-1\right)} \, dx=\frac{3 \pi ^2}{160}","How to prove $$\int_{\sqrt{3/5}}^1 \frac{\arctan (x)}{\sqrt{2 x^2-1} \left(3 x^2-1\right)} \, dx=\frac{3\pi^2}{160}$$ I found the integral neat enough but also tough. Is it somehow related to the Ahmed integral $?$ Any help will be appreciated. Update: Please see the link under @pisco's answer for further reference.",How to prove I found the integral neat enough but also tough. Is it somehow related to the Ahmed integral Any help will be appreciated. Update: Please see the link under @pisco's answer for further reference.,"\int_{\sqrt{3/5}}^1 \frac{\arctan (x)}{\sqrt{2 x^2-1} \left(3 x^2-1\right)} \, dx=\frac{3\pi^2}{160} ?","['integration', 'definite-integrals', 'special-functions', 'closed-form']"
42,On the evalution of an infinite sum,On the evalution of an infinite sum,,"I wish to show that $$\sum_{n = 0}^\infty (-1)^n \left [\frac{2n + 1/2}{(2n + 1/2)^2 + 1} + \frac{2n + 3/2}{(2n + 3/2)^2 + 1} \right] = \frac{\pi}{\sqrt{2}} \frac{\cosh \left (\frac{\pi}{2} \right )}{\cosh (\pi)}.$$ The reason I wish to find such a sum is as follows. The question here called for the evaluation (I have added its value) of $$\int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx = \frac{\pi}{\sqrt{2}} \frac{\cosh \left (\frac{\pi}{2} \right )}{\cosh (\pi)}.$$ As one of the comments, the OP remarked that they would like to see different approaches to the evaluation of the integral so I thought I would try my hand at one that does not rely on contour integration and the residue theorem. My approach was as follows: \begin{align} \int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx &= \int_0^1 \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx + \int_1^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx\\ &= \int_0^1 \frac{\cos (\ln x) (x + 1)}{\sqrt{x} (1 + x^2)} \, dx, \end{align} after a substitution of $x \mapsto 1/x$ has been enforced in the second of the integrals. Now if we enforce a substitution of $x \mapsto e^{-x}$ one arrives at $$\int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx = \int_0^\infty \frac{\cos x \cosh (x/2)}{\cosh x} \, dx.$$ Writing the hyperbolic functions in terms of exponentials we have \begin{align} \int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx &= \int_0^\infty \frac{\cos x (e^{-x/2} + e^{-3x/2})}{1 + e^{-2x}} \, dx\\ &= \text{Re} \sum_{n = 0}^\infty (-1)^n \int_0^\infty \left [e^{-(2n + 1/2 - i) x} + e^{-(2n + 3/2 - i)x} \right ] \, dx\\ &= \text{Re} \sum_{n = 0}^\infty (-1)^n \left [\frac{1}{2n + 1/2 - i} + \frac{1}{2n + 3/2 - i} \right ] \tag1\\ &= \sum_{n = 0}^\infty (-1)^n \left [\frac{2n + 1/2}{(2n + 1/2)^2 + 1} + \frac{2n + 3/2}{(2n + 3/2)^2 + 1} \right], \end{align} which brings me to my sum. Some thoughts on finding this sum Rewriting the sum $S$ in (1) as follows: \begin{align} S &= \text{Re} \cdot \frac{1}{4} \sum_{n = 0}^\infty \left [\frac{1}{n + 1/8 - i/4} + \frac{1}{n + 3/8 - i/4} - \frac{1}{n + 5/8 - i/4} - \frac{1}{n + 7/8 - i/4} \right ]\\ &= \text{Re} \cdot \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 7/8 - i/4} \right ) + \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 5/8 - i/4} \right )\\ & \qquad - \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 3/8 - i/4} \right ) - \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 1/8 - i/4} \right )\\ &= \frac{1}{4} \text{Re} \left [\psi \left (\frac{7}{8} - \frac{i}{4} \right ) + \psi \left (\frac{5}{8} - \frac{i}{4} \right ) - \psi \left (\frac{3}{8} - \frac{i}{4} \right ) - \psi \left (\frac{1}{8} - \frac{i}{4} \right ) \right ].  \end{align} Here $\psi (z)$ is the digamma function. I was rather hoping to use the reflexion formula for the digamma function, but alas it does not seem to take me any closer to a final real solution. Final thought While it would be nice to see how to evaluate this sum, perhaps my approach was not the best so alternative methods to evaluate the integral that avoid this sum and does not rely on contour integration would also be welcome.","I wish to show that The reason I wish to find such a sum is as follows. The question here called for the evaluation (I have added its value) of As one of the comments, the OP remarked that they would like to see different approaches to the evaluation of the integral so I thought I would try my hand at one that does not rely on contour integration and the residue theorem. My approach was as follows: after a substitution of has been enforced in the second of the integrals. Now if we enforce a substitution of one arrives at Writing the hyperbolic functions in terms of exponentials we have which brings me to my sum. Some thoughts on finding this sum Rewriting the sum in (1) as follows: Here is the digamma function. I was rather hoping to use the reflexion formula for the digamma function, but alas it does not seem to take me any closer to a final real solution. Final thought While it would be nice to see how to evaluate this sum, perhaps my approach was not the best so alternative methods to evaluate the integral that avoid this sum and does not rely on contour integration would also be welcome.","\sum_{n = 0}^\infty (-1)^n \left [\frac{2n + 1/2}{(2n + 1/2)^2 + 1} + \frac{2n + 3/2}{(2n + 3/2)^2 + 1} \right] = \frac{\pi}{\sqrt{2}} \frac{\cosh \left (\frac{\pi}{2} \right )}{\cosh (\pi)}. \int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx = \frac{\pi}{\sqrt{2}} \frac{\cosh \left (\frac{\pi}{2} \right )}{\cosh (\pi)}. \begin{align}
\int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx &= \int_0^1 \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx + \int_1^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx\\
&= \int_0^1 \frac{\cos (\ln x) (x + 1)}{\sqrt{x} (1 + x^2)} \, dx,
\end{align} x \mapsto 1/x x \mapsto e^{-x} \int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx = \int_0^\infty \frac{\cos x \cosh (x/2)}{\cosh x} \, dx. \begin{align}
\int_0^\infty \frac{\sqrt{x} \cos (\ln x)}{x^2 + 1} \, dx &= \int_0^\infty \frac{\cos x (e^{-x/2} + e^{-3x/2})}{1 + e^{-2x}} \, dx\\
&= \text{Re} \sum_{n = 0}^\infty (-1)^n \int_0^\infty \left [e^{-(2n + 1/2 - i) x} + e^{-(2n + 3/2 - i)x} \right ] \, dx\\
&= \text{Re} \sum_{n = 0}^\infty (-1)^n \left [\frac{1}{2n + 1/2 - i} + \frac{1}{2n + 3/2 - i} \right ] \tag1\\
&= \sum_{n = 0}^\infty (-1)^n \left [\frac{2n + 1/2}{(2n + 1/2)^2 + 1} + \frac{2n + 3/2}{(2n + 3/2)^2 + 1} \right],
\end{align} S \begin{align}
S &= \text{Re} \cdot \frac{1}{4} \sum_{n = 0}^\infty \left [\frac{1}{n + 1/8 - i/4} + \frac{1}{n + 3/8 - i/4} - \frac{1}{n + 5/8 - i/4} - \frac{1}{n + 7/8 - i/4} \right ]\\
&= \text{Re} \cdot \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 7/8 - i/4} \right ) + \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 5/8 - i/4} \right )\\
& \qquad - \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 3/8 - i/4} \right ) - \frac{1}{4} \sum_{n = 0}^\infty \left (\frac{1}{n + 1} - \frac{1}{n + 1/8 - i/4} \right )\\
&= \frac{1}{4} \text{Re} \left [\psi \left (\frac{7}{8} - \frac{i}{4} \right ) + \psi \left (\frac{5}{8} - \frac{i}{4} \right ) - \psi \left (\frac{3}{8} - \frac{i}{4} \right ) - \psi \left (\frac{1}{8} - \frac{i}{4} \right ) \right ]. 
\end{align} \psi (z)","['integration', 'sequences-and-series', 'definite-integrals', 'improper-integrals', 'closed-form']"
43,"Integral $\int_0^\frac{\pi}{2} x^2\sqrt{\tan x}\,\mathrm dx$",Integral,"\int_0^\frac{\pi}{2} x^2\sqrt{\tan x}\,\mathrm dx","Last year I wondered about this integral: $$\int_0^\frac{\pi}{2} x^2\sqrt{\tan x}\,\mathrm dx$$ That is because it looks very similar to this integral and this one . Surprisingly the result is quite nice and an approach can be  found here . $$\boxed{\int_0^\frac{\pi}{2} x^2\sqrt{\tan x}\,\mathrm dx=\frac{\sqrt{2}\pi(5\pi^2+12\pi\ln 2 - 12\ln^22)}{96}}$$ Although the approach there is quite skillful, I believed that an elementary approach can be found for this integral. Here is my idea. First we will consider the following two integrals: $$I=\int_0^\frac{\pi}{2} x^2\sqrt{\tan x}\,\mathrm dx \,;\quad J=\int_0^\frac{\pi}{2} x^2\sqrt{\cot x}\,\mathrm dx$$ $$\Rightarrow I=\frac12 \left((I-J)+(I+J)\right)$$ Thust we need to evaluate the sum and the difference of those two from above. I also saw from here that the ""sister"" integral differs only by a minus sign: $$\boxed{\int_0^\frac{\pi}{2} x^2\sqrt{\cot x}\,\mathrm dx=\frac{\sqrt{2}\pi(5\pi^2-12\pi\ln 2 - 12\ln^22)}{96}}$$ Thus using those two boxed answer we expect to find: $$I-J=\frac{\pi^2 \ln  2}{2\sqrt 2};\quad I+J=\frac{5\pi^3}{24\sqrt 2}-\frac{\pi \ln^2 2}{2\sqrt 2}\tag1$$ $$I-J=\int_0^\frac{\pi}{2} x^2\left(\sqrt{\tan x}-\sqrt{\cot x}\right)\,\mathrm dx=\sqrt 2\int_0^\frac{\pi}{2} x^2 \cdot \frac{\sin x-\cos x}{\sqrt{\sin (2x)}}dx$$ $$=-\sqrt 2\int_0^\frac{\pi}{2} x^2 \left(\operatorname{arccosh}(\sin x+\cos x) \right)'dx=2\sqrt 2 \int_0^\frac{\pi}{2} x\operatorname{arccosh} (\sin x+\cos x)dx$$ Let us also denote the last integral with $I_1$ and do a $\frac{\pi}{2}-x=x$ substitution: $$I_1=\int_0^\frac{\pi}{2} x\operatorname{arccosh} (\sin x+\cos x)dx=\int_0^\frac{\pi}{2} \left(\frac{\pi}{2}-x\right)\operatorname{arccosh} (\sin x+\cos x)dx$$ $$2I_1=\frac{\pi}{2} \int_0^\frac{\pi}{2} \operatorname{arccosh} (\sin x+\cos x)dx\Rightarrow I-J=\frac{\pi}{\sqrt 2}\int_0^\frac{\pi}{2} \operatorname{arccosh} (\sin x+\cos x)dx$$ By using $(1)$ we can easily deduce that: $$\bbox[10pt,#000, border:2px solid green ]{\color{orange}{\int_0^\frac{\pi}{2} \operatorname{arccosh} (\sin x+\cos x)dx=\frac{\pi}{2}\ln 2}}$$ Doing something similar for $I+J$ we get: $$I+J=\int_0^\frac{\pi}{2} x^2\left(\sqrt{\tan x}+\sqrt{\cot x}\right)\,\mathrm dx=\sqrt 2\int_0^\frac{\pi}{2} x^2 \cdot \frac{\sin x+\cos x}{\sqrt{\sin (2x)}}dx$$ $$=\sqrt 2 \int_0^\frac{\pi}{2} x^2 \left( \arcsin \left(\sin x-\cos x\right)\right)'dx=\frac{\pi^3 \sqrt 2}{8}-2\sqrt 2 \int_0^\frac{\pi}{2} x \arcsin \left(\sin x-\cos x\right)dx$$ Unfortunately, we're not lucky this time and the substitution used for $I-J$ doesn't help in this case.  Of course using $(1)$ we can again  deduce that: $$\bbox[10pt,#000, border:2px solid green ]{\color{red}{\int_0^\frac{\pi}{2} x \arcsin \left(\sin x-\cos x\right)dx=\frac{\pi^3}{96}+\frac{\pi}{8}\ln^2 2}}$$ In the meantime I found  a way for the first one, mainly using: $$\frac{\arctan x}{x}=\int_0^1 \frac{dy}{1+x^2y^2}$$ Let us denote: $$I_1=\int_0^\frac{\pi}{2} \operatorname{arccosh} (\sin x+\cos x)dx\overset{IBP}= \int_0^\frac{\pi}{2} x \cdot \frac{\sin x-\cos x}{\sqrt{\sin(2x)}}dx$$ $$\overset{\tan x\rightarrow x}=\frac{1}{\sqrt 2}\int_0^\infty \frac{\arctan x}{1+x^2}\frac{x-1}{\sqrt x}dx=\frac1{\sqrt 2}\int_0^\infty \int_0^1 \frac{dy}{1+x^2y^2} \frac{\sqrt x(x-1)}{1+x^2}dx$$ $$=\frac1{\sqrt 2}\int_0^1 \int_0^\infty \frac{1}{1+y^2x^2} \frac{\sqrt x(x-1)}{1+x^2} dxdy$$ $$=\frac{1}{\sqrt 2}\int_0^1 \frac{{\pi}}{\sqrt 2}\left(\frac{2}{y^2-1}-\frac{1}{\sqrt y (y^2-1)}-\frac{\sqrt y}{y^2-1}\right)dy=\frac{\pi}{2}\ln 2$$ Although the integral in the third row looks quite unpleasant, it can be done quite elementary. Sadly a similar approach for the second one is madness, because we would have: $$I_2=\int_0^1 \int_0^1 \int_0^\infty \frac{\sqrt x (x+1)}{1+x^2}\frac{1}{1+y^2x^2}\frac{1}{1+z^2x^2} dxdydz$$ But atleast it gives hope that an elementary approach exists. For this question I would like to see an elementary approach (without relying on special functions) for the second integral (red one). If possible please avoid contour integration, although this might be included in elementary .","Last year I wondered about this integral: That is because it looks very similar to this integral and this one . Surprisingly the result is quite nice and an approach can be  found here . Although the approach there is quite skillful, I believed that an elementary approach can be found for this integral. Here is my idea. First we will consider the following two integrals: Thust we need to evaluate the sum and the difference of those two from above. I also saw from here that the ""sister"" integral differs only by a minus sign: Thus using those two boxed answer we expect to find: Let us also denote the last integral with and do a substitution: By using we can easily deduce that: Doing something similar for we get: Unfortunately, we're not lucky this time and the substitution used for doesn't help in this case.  Of course using we can again  deduce that: In the meantime I found  a way for the first one, mainly using: Let us denote: Although the integral in the third row looks quite unpleasant, it can be done quite elementary. Sadly a similar approach for the second one is madness, because we would have: But atleast it gives hope that an elementary approach exists. For this question I would like to see an elementary approach (without relying on special functions) for the second integral (red one). If possible please avoid contour integration, although this might be included in elementary .","\int_0^\frac{\pi}{2} x^2\sqrt{\tan x}\,\mathrm dx \boxed{\int_0^\frac{\pi}{2} x^2\sqrt{\tan x}\,\mathrm dx=\frac{\sqrt{2}\pi(5\pi^2+12\pi\ln 2 - 12\ln^22)}{96}} I=\int_0^\frac{\pi}{2} x^2\sqrt{\tan x}\,\mathrm dx \,;\quad J=\int_0^\frac{\pi}{2} x^2\sqrt{\cot x}\,\mathrm dx \Rightarrow I=\frac12 \left((I-J)+(I+J)\right) \boxed{\int_0^\frac{\pi}{2} x^2\sqrt{\cot x}\,\mathrm dx=\frac{\sqrt{2}\pi(5\pi^2-12\pi\ln 2 - 12\ln^22)}{96}} I-J=\frac{\pi^2 \ln  2}{2\sqrt 2};\quad I+J=\frac{5\pi^3}{24\sqrt 2}-\frac{\pi \ln^2 2}{2\sqrt 2}\tag1 I-J=\int_0^\frac{\pi}{2} x^2\left(\sqrt{\tan x}-\sqrt{\cot x}\right)\,\mathrm dx=\sqrt 2\int_0^\frac{\pi}{2} x^2 \cdot \frac{\sin x-\cos x}{\sqrt{\sin (2x)}}dx =-\sqrt 2\int_0^\frac{\pi}{2} x^2 \left(\operatorname{arccosh}(\sin x+\cos x) \right)'dx=2\sqrt 2 \int_0^\frac{\pi}{2} x\operatorname{arccosh} (\sin x+\cos x)dx I_1 \frac{\pi}{2}-x=x I_1=\int_0^\frac{\pi}{2} x\operatorname{arccosh} (\sin x+\cos x)dx=\int_0^\frac{\pi}{2} \left(\frac{\pi}{2}-x\right)\operatorname{arccosh} (\sin x+\cos x)dx 2I_1=\frac{\pi}{2} \int_0^\frac{\pi}{2} \operatorname{arccosh} (\sin x+\cos x)dx\Rightarrow I-J=\frac{\pi}{\sqrt 2}\int_0^\frac{\pi}{2} \operatorname{arccosh} (\sin x+\cos x)dx (1) \bbox[10pt,#000, border:2px solid green ]{\color{orange}{\int_0^\frac{\pi}{2} \operatorname{arccosh} (\sin x+\cos x)dx=\frac{\pi}{2}\ln 2}} I+J I+J=\int_0^\frac{\pi}{2} x^2\left(\sqrt{\tan x}+\sqrt{\cot x}\right)\,\mathrm dx=\sqrt 2\int_0^\frac{\pi}{2} x^2 \cdot \frac{\sin x+\cos x}{\sqrt{\sin (2x)}}dx =\sqrt 2 \int_0^\frac{\pi}{2} x^2 \left( \arcsin \left(\sin x-\cos x\right)\right)'dx=\frac{\pi^3 \sqrt 2}{8}-2\sqrt 2 \int_0^\frac{\pi}{2} x \arcsin \left(\sin x-\cos x\right)dx I-J (1) \bbox[10pt,#000, border:2px solid green ]{\color{red}{\int_0^\frac{\pi}{2} x \arcsin \left(\sin x-\cos x\right)dx=\frac{\pi^3}{96}+\frac{\pi}{8}\ln^2 2}} \frac{\arctan x}{x}=\int_0^1 \frac{dy}{1+x^2y^2} I_1=\int_0^\frac{\pi}{2} \operatorname{arccosh} (\sin x+\cos x)dx\overset{IBP}= \int_0^\frac{\pi}{2} x \cdot \frac{\sin x-\cos x}{\sqrt{\sin(2x)}}dx \overset{\tan x\rightarrow x}=\frac{1}{\sqrt 2}\int_0^\infty \frac{\arctan x}{1+x^2}\frac{x-1}{\sqrt x}dx=\frac1{\sqrt 2}\int_0^\infty \int_0^1 \frac{dy}{1+x^2y^2} \frac{\sqrt x(x-1)}{1+x^2}dx =\frac1{\sqrt 2}\int_0^1 \int_0^\infty \frac{1}{1+y^2x^2} \frac{\sqrt x(x-1)}{1+x^2} dxdy =\frac{1}{\sqrt 2}\int_0^1 \frac{{\pi}}{\sqrt 2}\left(\frac{2}{y^2-1}-\frac{1}{\sqrt y (y^2-1)}-\frac{\sqrt y}{y^2-1}\right)dy=\frac{\pi}{2}\ln 2 I_2=\int_0^1 \int_0^1 \int_0^\infty \frac{\sqrt x (x+1)}{1+x^2}\frac{1}{1+y^2x^2}\frac{1}{1+z^2x^2} dxdydz","['integration', 'definite-integrals', 'closed-form', 'alternative-proof']"
44,Prove that $\lim_{m\to\infty} \sum_{n=0}^{m} \frac{(-1)^n}{n!} \binom{m}{n}=0$.,Prove that .,\lim_{m\to\infty} \sum_{n=0}^{m} \frac{(-1)^n}{n!} \binom{m}{n}=0,"The problem from the statement is the hardest part of the problem A. 810 from KMaL contest November 2021 (the deadline was 10 December). After the deadline, I noticed that if $r_0=1$ : $$\begin{align}  \sum_{n=0}^m r_n&=\sum_{t=0}^m\sum_{n=t}^m\frac{(-1)^t}{(t+1)!}\binom{n}t\\&= \sum_{t=0}^m\frac{(-1)^t}{(t+1)!}\sum_{n=t}^m \binom{n}{t}\\&=\sum_{t=0}^m\frac{(-1)^t}{(t+1)!}\binom{m+1}{t+1}. \end{align} $$ Therefore the KMaL problem is equivalent to $$\begin{align}  &\lim_{m\to\infty}\sum_{n=0}^m r_n=1\Leftrightarrow\\&\lim_{m\to\infty}\sum_{t=0}^m\frac{(-1)^t}{(t+1)!}\binom{m+1}{t+1}=1\Leftrightarrow\\ &\lim_{n\to\infty}\sum_{t=1}^{m+1}\frac{(-1)^t}{t!}\binom{m+1}t=-1 \end{align} $$ which equivalent to $\displaystyle \lim_{m\to\infty} \sum_{n=0}^{m} \frac{(-1)^n}{n!} \binom{m}{n} = 0$ and I cannot prove this affirmation. My ideas: To study the function $f_m:\mathbb{R}\to\mathbb{R},$ $f_m(x)=\sum\limits_{n=0}^m (-1)^n\binom{m}{n}\frac{x^{n}}{n!}$ . To use Cauchy product of two series.","The problem from the statement is the hardest part of the problem A. 810 from KMaL contest November 2021 (the deadline was 10 December). After the deadline, I noticed that if : Therefore the KMaL problem is equivalent to which equivalent to and I cannot prove this affirmation. My ideas: To study the function . To use Cauchy product of two series.","r_0=1 \begin{align}  \sum_{n=0}^m r_n&=\sum_{t=0}^m\sum_{n=t}^m\frac{(-1)^t}{(t+1)!}\binom{n}t\\&=
\sum_{t=0}^m\frac{(-1)^t}{(t+1)!}\sum_{n=t}^m
\binom{n}{t}\\&=\sum_{t=0}^m\frac{(-1)^t}{(t+1)!}\binom{m+1}{t+1}. \end{align}  \begin{align}  &\lim_{m\to\infty}\sum_{n=0}^m r_n=1\Leftrightarrow\\&\lim_{m\to\infty}\sum_{t=0}^m\frac{(-1)^t}{(t+1)!}\binom{m+1}{t+1}=1\Leftrightarrow\\
&\lim_{n\to\infty}\sum_{t=1}^{m+1}\frac{(-1)^t}{t!}\binom{m+1}t=-1 \end{align}  \displaystyle \lim_{m\to\infty} \sum_{n=0}^{m}
\frac{(-1)^n}{n!} \binom{m}{n} = 0 f_m:\mathbb{R}\to\mathbb{R}, f_m(x)=\sum\limits_{n=0}^m
(-1)^n\binom{m}{n}\frac{x^{n}}{n!}","['integration', 'sequences-and-series', 'limits', 'contest-math', 'binomial-coefficients']"
45,Calculate $\int_0^1\frac{\log^2(1+x)\log(x)\log(1-x)}{1-x}dx$,Calculate,\int_0^1\frac{\log^2(1+x)\log(x)\log(1-x)}{1-x}dx,"Prove that: $$ I=\int_0^1\frac{\log^2(1+x)\log(x)\log(1-x)}{1-x}dx=\frac{7}{2}\zeta(3){\log^22}-\frac{\pi^2}{6}{\log^32}-\frac{\pi^2}{2}\zeta(3)+{6}\zeta(5)-\frac{\pi^4}{48}\ln2  $$  Using integration by parts: $$u=\log^2(1+x) \log x$$ thus $$du=\left[\frac{\log^2(1+x)}{x}+2\frac{\log x\log(1+x)}{1+x}\right]\,dx,  v=\log^2(1-x)$$  We have:   $$I= \left[-\frac{1}{2} \log^2(1-x)  \log x \log^2(1+x)\right]^1_0+\frac{1}{2} \int^1_0 \log^2(1-x) \log^2(1+x) \frac{dx}{x} + \int^1_0 \log x \log(1+x) \log^2(1-x) \frac{dx}{1+x}$$ How to calculate these last two integrals?","Prove that: $$ I=\int_0^1\frac{\log^2(1+x)\log(x)\log(1-x)}{1-x}dx=\frac{7}{2}\zeta(3){\log^22}-\frac{\pi^2}{6}{\log^32}-\frac{\pi^2}{2}\zeta(3)+{6}\zeta(5)-\frac{\pi^4}{48}\ln2  $$  Using integration by parts: $$u=\log^2(1+x) \log x$$ thus $$du=\left[\frac{\log^2(1+x)}{x}+2\frac{\log x\log(1+x)}{1+x}\right]\,dx,  v=\log^2(1-x)$$  We have:   $$I= \left[-\frac{1}{2} \log^2(1-x)  \log x \log^2(1+x)\right]^1_0+\frac{1}{2} \int^1_0 \log^2(1-x) \log^2(1+x) \frac{dx}{x} + \int^1_0 \log x \log(1+x) \log^2(1-x) \frac{dx}{1+x}$$ How to calculate these last two integrals?",,"['integration', 'definite-integrals', 'improper-integrals', 'special-functions', 'harmonic-numbers']"
46,"How to prove $ \prod_{n=1}^{\infty} \left(1+\frac{2}{n}\right)^{(-1)^{n+1}n} \,= \frac{\pi}{2e}$",How to prove," \prod_{n=1}^{\infty} \left(1+\frac{2}{n}\right)^{(-1)^{n+1}n} \,= \frac{\pi}{2e}","How can I prove that $$ \prod_{n=1}^{\infty} \left(1+\frac{2}{n}\right)^{\large{(-1)^{n+1}n}} \,= \frac{\pi}{2e}$$ The result is given here (result 48). The source: Prudnikov et al. 1986, p. 757 is given, however I have been unable to find the book online. Some of my attempts include : Multiplying known infinite products for $\frac{\pi}{2}$ and $\frac{1}{e}$ $$ \frac{\pi}{2} = \frac{2\cdot2\cdot4\cdot4\cdot6\cdot6\cdots}{1\cdot3\cdot3\cdot5\cdot5\cdot7\cdots} $$ $$ \frac{1}{e} =  \frac{1}{2} \left(\frac{3}{4}\right)^{\large{\frac{1}{4}}}\left(\frac{5\cdot7}{6\cdot8}\right)^{\large{\frac{1}{4}}} \cdots$$ as well as others given in https://arxiv.org/pdf/1005.2712.pdf Trying to find the partial products from ${n=1} $ to $k $ , Mathematica Gives: $$\scriptsize{ \frac{\exp\left(2\left(-\zeta(-1,k+\frac{1}{2})^{(1,0)}+\zeta(-1,k+\frac{3}{2})^{(1,0)}+\zeta(-1,k+1)^{(1,0)}-\zeta(-1,k+2)^{(1,0)}\right)\right)\pi\, \Gamma(k+2)^2}{2\,\Gamma(k+\frac{3}{2})^2}} $$ However, I have been unsuccessful producing partial products on my own. Taking the $\ln$ of the product to try to find the partial sums; Trying to transform the following integral into infinite product. $$\int_{0}^{\infty} \frac{\cos(x)}{1+x^2} = \frac{\pi}{2e} $$ From what I have seen in some papers, the partial products are found, then the Stirling's Approximation is used to find the limit. Question: How can I prove the value of the given Infinite Product? Proofs or hints are both welcome. Thank you kindly for your help and time.","How can I prove that The result is given here (result 48). The source: Prudnikov et al. 1986, p. 757 is given, however I have been unable to find the book online. Some of my attempts include : Multiplying known infinite products for and as well as others given in https://arxiv.org/pdf/1005.2712.pdf Trying to find the partial products from to , Mathematica Gives: However, I have been unsuccessful producing partial products on my own. Taking the of the product to try to find the partial sums; Trying to transform the following integral into infinite product. From what I have seen in some papers, the partial products are found, then the Stirling's Approximation is used to find the limit. Question: How can I prove the value of the given Infinite Product? Proofs or hints are both welcome. Thank you kindly for your help and time."," \prod_{n=1}^{\infty} \left(1+\frac{2}{n}\right)^{\large{(-1)^{n+1}n}} \,= \frac{\pi}{2e} \frac{\pi}{2} \frac{1}{e}  \frac{\pi}{2} = \frac{2\cdot2\cdot4\cdot4\cdot6\cdot6\cdots}{1\cdot3\cdot3\cdot5\cdot5\cdot7\cdots}   \frac{1}{e} =  \frac{1}{2} \left(\frac{3}{4}\right)^{\large{\frac{1}{4}}}\left(\frac{5\cdot7}{6\cdot8}\right)^{\large{\frac{1}{4}}} \cdots {n=1}  k  \scriptsize{ \frac{\exp\left(2\left(-\zeta(-1,k+\frac{1}{2})^{(1,0)}+\zeta(-1,k+\frac{3}{2})^{(1,0)}+\zeta(-1,k+1)^{(1,0)}-\zeta(-1,k+2)^{(1,0)}\right)\right)\pi\, \Gamma(k+2)^2}{2\,\Gamma(k+\frac{3}{2})^2}}  \ln \int_{0}^{\infty} \frac{\cos(x)}{1+x^2} = \frac{\pi}{2e} ","['integration', 'sequences-and-series', 'infinite-product']"
47,Integral of differential form and integral of measure,Integral of differential form and integral of measure,,"I am trying to understand the relations and differences between integral of differential form and integral of measure. From Wikipedia : On a general differentiable manifold (without additional structure),   differential forms cannot be integrated over subsets of the manifold;   this distinction is key to the distinction between differential forms,   which are integrated over chains, and measures, which are integrated   over subsets. Isn't a chain a manifold, and therefore a subset of a manifold? Why is that ""differential forms cannot be integrated over subsets of the manifold""? Is integral of a differential form defined in terms of Lebesgue integral via parameterization of the chain, as like here $$\int_S \omega =\int_D \sum a_{i_1,\dots,i_k}(S({\mathbf u})) \frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}\,du^1\ldots du^k $$ So can one say that integral of a differential form is not a different integration method from Lebesgue integral? Thanks and regards!","I am trying to understand the relations and differences between integral of differential form and integral of measure. From Wikipedia : On a general differentiable manifold (without additional structure),   differential forms cannot be integrated over subsets of the manifold;   this distinction is key to the distinction between differential forms,   which are integrated over chains, and measures, which are integrated   over subsets. Isn't a chain a manifold, and therefore a subset of a manifold? Why is that ""differential forms cannot be integrated over subsets of the manifold""? Is integral of a differential form defined in terms of Lebesgue integral via parameterization of the chain, as like here $$\int_S \omega =\int_D \sum a_{i_1,\dots,i_k}(S({\mathbf u})) \frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}\,du^1\ldots du^k $$ So can one say that integral of a differential form is not a different integration method from Lebesgue integral? Thanks and regards!",,"['integration', 'differential-geometry', 'measure-theory']"
48,Integral for function of square,Integral for function of square,,"Let $f:[0,\infty) \rightarrow \mathbb R$ be a strictly positive, decreasing, differentiable function, such that  $$f(0) = 1, \quad \lim_{x\rightarrow \infty} f(x) = 0$$ and $$\frac{1}{f(x)^2} = \frac{1}{f(x^2)} + 2x^2$$ If $\int_0^\infty f(x)\,dx$ exists, show that $$\int_0^\infty f(x^2) \,dx = \frac{1}{\sqrt2}\int_0^\infty f(x)\,dx$$","Let $f:[0,\infty) \rightarrow \mathbb R$ be a strictly positive, decreasing, differentiable function, such that  $$f(0) = 1, \quad \lim_{x\rightarrow \infty} f(x) = 0$$ and $$\frac{1}{f(x)^2} = \frac{1}{f(x^2)} + 2x^2$$ If $\int_0^\infty f(x)\,dx$ exists, show that $$\int_0^\infty f(x^2) \,dx = \frac{1}{\sqrt2}\int_0^\infty f(x)\,dx$$",,"['analysis', 'integration']"
49,Evaluation of $\sum_{x=0}^\infty e^{-x^2}$,Evaluation of,\sum_{x=0}^\infty e^{-x^2},"Most of us are aware of the classic Gaussian Integral $$\int_0^\infty e^{-x^2}\, dx=\frac{\sqrt{\pi}}{2}$$ I would be interested in evaluating the similar sum $$\sum_{x=0}^\infty e^{-x^2}$$ Now, because $\exp(-\lfloor x \rfloor^2) \ge \exp(-x)$, we find $$\sum_{x=0}^\infty e^{-x^2}= \int_0^\infty e^{-\lfloor x \rfloor^2}\, dx \ge \int_0^\infty e^{-x^2}\, dx=\frac{\sqrt{\pi}}{2}$$ Does a closed form for this sum exist?  If so, what would it be?  I would be very interested in how a closed form would be found for this function.","Most of us are aware of the classic Gaussian Integral $$\int_0^\infty e^{-x^2}\, dx=\frac{\sqrt{\pi}}{2}$$ I would be interested in evaluating the similar sum $$\sum_{x=0}^\infty e^{-x^2}$$ Now, because $\exp(-\lfloor x \rfloor^2) \ge \exp(-x)$, we find $$\sum_{x=0}^\infty e^{-x^2}= \int_0^\infty e^{-\lfloor x \rfloor^2}\, dx \ge \int_0^\infty e^{-x^2}\, dx=\frac{\sqrt{\pi}}{2}$$ Does a closed form for this sum exist?  If so, what would it be?  I would be very interested in how a closed form would be found for this function.",,"['sequences-and-series', 'integration', 'special-functions', 'closed-form']"
50,"Evaluate $\int_0^1\arcsin^2(\frac{\sqrt{-x}}{2}) (\log^3 x) (\frac{8}{1+x}+\frac{1}{x}) \, dx$",Evaluate,"\int_0^1\arcsin^2(\frac{\sqrt{-x}}{2}) (\log^3 x) (\frac{8}{1+x}+\frac{1}{x}) \, dx","Here is an interesting integral, which is equivalent to the title $$\tag{1}\int_0^1 \log ^2\left(\sqrt{\frac{x}{4}+1}-\sqrt{\frac{x}{4}}\right) (\log ^3x) \left(\frac{8}{1+x}+\frac{1}{x}\right) \, dx = \frac{5 \pi ^6}{1134}-\frac{22 \zeta (3)^2}{5}$$ Question: how to prove $(1)$ ? Using power expansion of $\log^2(\sqrt{x+1}-\sqrt{x})$ , we can derive an equivalent form of $(1)$ : $$\tag{2}\sum _{n=1}^{\infty } \frac{1}{n^2 \binom{2 n}{n}} \left(8 \sum _{j=1}^n \frac{(-1)^j}{j^4}+\frac{(-1)^n}{n^4}\right)=-\frac{22 \zeta (3)^2}{15}-\frac{97 \pi ^6}{34020}$$ Letting $\sqrt{\frac{x}{4}+1}-\sqrt{\frac{x}{4}}=\sqrt{u+1}$ gives $$\tag{3}\int_0^{\phi} \log^2 (1+u) \log^3\left(\frac{u^2}{1+u}\right)  \frac{(u+2)(9 u^2+u+1)}{u (u+1) (u^2+u+1)} du = \frac{10 \pi ^6}{567}-\frac{88 \zeta (3)^2}{5}$$ with $\phi = (\sqrt{5}+1)/2$ . But all these variations look equally difficult. Any idea is welcomed.","Here is an interesting integral, which is equivalent to the title Question: how to prove ? Using power expansion of , we can derive an equivalent form of : Letting gives with . But all these variations look equally difficult. Any idea is welcomed.","\tag{1}\int_0^1 \log ^2\left(\sqrt{\frac{x}{4}+1}-\sqrt{\frac{x}{4}}\right) (\log ^3x) \left(\frac{8}{1+x}+\frac{1}{x}\right) \, dx = \frac{5 \pi ^6}{1134}-\frac{22 \zeta (3)^2}{5} (1) \log^2(\sqrt{x+1}-\sqrt{x}) (1) \tag{2}\sum _{n=1}^{\infty } \frac{1}{n^2 \binom{2 n}{n}} \left(8 \sum _{j=1}^n \frac{(-1)^j}{j^4}+\frac{(-1)^n}{n^4}\right)=-\frac{22 \zeta (3)^2}{15}-\frac{97 \pi ^6}{34020} \sqrt{\frac{x}{4}+1}-\sqrt{\frac{x}{4}}=\sqrt{u+1} \tag{3}\int_0^{\phi} \log^2 (1+u) \log^3\left(\frac{u^2}{1+u}\right)  \frac{(u+2)(9 u^2+u+1)}{u (u+1) (u^2+u+1)} du = \frac{10 \pi ^6}{567}-\frac{88 \zeta (3)^2}{5} \phi = (\sqrt{5}+1)/2","['integration', 'sequences-and-series', 'definite-integrals', 'polylogarithm']"
51,What is the point of Riemann-Stieltjes integration?,What is the point of Riemann-Stieltjes integration?,,"My book on complex analysis dedicates an entire chapter to this integral in order to motivate/define complex line integrals. Having spent a semester on integration theory, I am not to keen on learning about yet another integral when I am perfectly satisfied with the Lebesgue integral. My understanding is that the Riemann-Stieltjes integral is just a generalization of the Riemann integral. I simply don't see why I need it for this course or why I would ever need it at all. Some insight would be greatly appreciated.","My book on complex analysis dedicates an entire chapter to this integral in order to motivate/define complex line integrals. Having spent a semester on integration theory, I am not to keen on learning about yet another integral when I am perfectly satisfied with the Lebesgue integral. My understanding is that the Riemann-Stieltjes integral is just a generalization of the Riemann integral. I simply don't see why I need it for this course or why I would ever need it at all. Some insight would be greatly appreciated.",,"['analysis', 'integration']"
52,Summing a divergent series,Summing a divergent series,,"In doing an integral, I used an ""illegitimate"" Taylor expansion to obtain a divergent series $$\int_{-\infty}^\infty\frac{e^{-x^2}}{1+x^2}dx=\sum_{n=0}^\infty\,(-1)^n\!\int_{-\infty}^\infty x^{2n}e^{-x^2}dx=\sum_{n=0}^\infty(-1)^n\,\Gamma\!\left(n+\frac{1}{2}\right),$$ while the correct way of doing the integral is \begin{align} \int_{-\infty}^\infty\frac{e^{-x^2}}{1+x^2}dx&=e\int_{-\infty}^\infty dx\int_1^\infty e^{-\beta(1+x^2)}d\beta=e\int_1^\infty\sqrt{\frac{\pi}{\beta}}e^{-\beta}d\beta=e\pi\,\mathrm{erfc}(1). \end{align} Using the Borel summation of the divergent series, I also managed to obtain $$\boxed{\sum_{n=0}^\infty(-1)^n\,\Gamma\!\left(n+\frac{1}{2}\right)=e\pi\,\mathrm{erfc}(1).}$$ But I have trouble understanding what it means. If I interpret the series as giving an asymptotic expansion of some function, i.e., $$\pi x\,e^{x^2}\mathrm{erfc}(x)\sim\sum_{n=0}^\infty\frac{(-1)^n}{x^{2n}}\Gamma\!\left(n+\frac{1}{2}\right),\quad x\rightarrow+\infty,$$ to be evaluated at $x=1$, the trouble is $\,\pi x\,e^{x^2}\mathrm{erfc}(x)+Ce^{-x}$ would give the same asymptotic expansion at $\,x\rightarrow+\infty\,$ but an arbitrarily different value at $\,x=1$. If I introduce a convergence factor such as $\,e^{-\epsilon n^2}$ and evaluate numerically $$\lim_{\epsilon\rightarrow 0^+}\sum_{n=0}^\infty(-1)^{n\,}\Gamma\!\left(n+\frac{1}{2}\right)\!e^{-\epsilon n^2}=1.3433,$$ I get a number very close to $e\pi\,\mathrm{erfc}(1)$. But is there a way to show that the limit is unchanged (if it exists) when $\,e^{-\epsilon n^2}$ is replaced by some other convergence factor $f_\epsilon(n)$ that satisfies $$\lim_{\epsilon\rightarrow 0^+}f_\epsilon(n)=1,\;\forall n\in\mathbb{N}\quad\mbox{ and }\quad\lim_{n\rightarrow\infty}f_{\epsilon}(n)=0,\;\forall\epsilon>0?$$ I wish someone can show me how to proceed from this updated question.","In doing an integral, I used an ""illegitimate"" Taylor expansion to obtain a divergent series $$\int_{-\infty}^\infty\frac{e^{-x^2}}{1+x^2}dx=\sum_{n=0}^\infty\,(-1)^n\!\int_{-\infty}^\infty x^{2n}e^{-x^2}dx=\sum_{n=0}^\infty(-1)^n\,\Gamma\!\left(n+\frac{1}{2}\right),$$ while the correct way of doing the integral is \begin{align} \int_{-\infty}^\infty\frac{e^{-x^2}}{1+x^2}dx&=e\int_{-\infty}^\infty dx\int_1^\infty e^{-\beta(1+x^2)}d\beta=e\int_1^\infty\sqrt{\frac{\pi}{\beta}}e^{-\beta}d\beta=e\pi\,\mathrm{erfc}(1). \end{align} Using the Borel summation of the divergent series, I also managed to obtain $$\boxed{\sum_{n=0}^\infty(-1)^n\,\Gamma\!\left(n+\frac{1}{2}\right)=e\pi\,\mathrm{erfc}(1).}$$ But I have trouble understanding what it means. If I interpret the series as giving an asymptotic expansion of some function, i.e., $$\pi x\,e^{x^2}\mathrm{erfc}(x)\sim\sum_{n=0}^\infty\frac{(-1)^n}{x^{2n}}\Gamma\!\left(n+\frac{1}{2}\right),\quad x\rightarrow+\infty,$$ to be evaluated at $x=1$, the trouble is $\,\pi x\,e^{x^2}\mathrm{erfc}(x)+Ce^{-x}$ would give the same asymptotic expansion at $\,x\rightarrow+\infty\,$ but an arbitrarily different value at $\,x=1$. If I introduce a convergence factor such as $\,e^{-\epsilon n^2}$ and evaluate numerically $$\lim_{\epsilon\rightarrow 0^+}\sum_{n=0}^\infty(-1)^{n\,}\Gamma\!\left(n+\frac{1}{2}\right)\!e^{-\epsilon n^2}=1.3433,$$ I get a number very close to $e\pi\,\mathrm{erfc}(1)$. But is there a way to show that the limit is unchanged (if it exists) when $\,e^{-\epsilon n^2}$ is replaced by some other convergence factor $f_\epsilon(n)$ that satisfies $$\lim_{\epsilon\rightarrow 0^+}f_\epsilon(n)=1,\;\forall n\in\mathbb{N}\quad\mbox{ and }\quad\lim_{n\rightarrow\infty}f_{\epsilon}(n)=0,\;\forall\epsilon>0?$$ I wish someone can show me how to proceed from this updated question.",,"['integration', 'divergent-series']"
53,Why are the fundamental theorems of calculus usually associated to the Riemann Integral?,Why are the fundamental theorems of calculus usually associated to the Riemann Integral?,,"I am writing a ""textbook"" on Analysis, and I've reached the time I must talk about integrals. I prefer to approach directly the Lebesgue Integral theory. This question is not about the status of this opinion: it has been already extensively discussed in this website and in mathoverflow. My question is rather: why do we associate ""calculations"" with the riemann integral? Specifically, why is it common sense that the Fundamental Theorems of Calculus we see when we first study calculus are best understood in the riemann-integral framework? I give an example of this opinion: From a conceptual standpoint, I think that there are three things one asks of an approach to integration 1) An easily accessible geometric interpretation 2) A readily available computational toolbox (e.g. the fundamental theorem of calculus) 3) A flexible theory The Lebesgue integral is absolutely unrivaled in (3), but it is actually quite obtuse from the other two points of view. Basic results like the Lebesgue differentiation theorem and the change of variables formula are not at all transparent from the Lebesgue point of view, and geometrically it is no better than the Riemann integral. The Cauchy integral is great if you only care about (2), but it is abysmal at (1) and (3). The Riemann integral, for all its faults, strikes a pretty good balance between (1) and (2). It is even known to enjoy an occasional technical advantage over the Lebesgue theory; for instance, one must invent the theory of distributions to make sense of the Cauchy principal value of an improper integral in the Lebesgue theory if I recall correctly. this can be seen here. My point is: the fundamental theorems of calculus (as stated in calculus) can be demonstrated without ever touching the concept of riemann-integration. We, thus, have the so-asked tool of calculation without ever having to appeal to the riemann-integral theory. I illustrate my claim: [First Fundamental Theorem of Calculus] Let $f:[a,b]\rightarrow \mathbb{R}$ be an integrable function. Then: $$F(x):= \int_{[a,x]} f d\mu $$ is continuous in $[a,b]$. Furthermore, if $f$ is continuous at $x_0 \in (a,b)$, then $F$ is differentiable at $x_0$, and $$F'(x_0)=f(x_0)$$ Proof: To prove continuity, fix $x_0 \in [a,b]$. Take a sequence $x_n$ that converges to $x_0$. We will prove $F(x_n) \rightarrow F(x_0)$ $F(x_n)=\int_{[a,x_n]} f d\mu=\int_{[a,b]}f \chi_{[a,x_n]} d\mu$ It is easy to see that $f \chi_{[a,x_n]} \rightarrow  f \chi_{[a,x_0]}$ pointwise. Therefore, since the sequence $f \chi_{[a,x_n]}$ is dominated by $|f|$, it follows by Lebesgue's Dominated Convergence Theorem that: $\lim F(x_n)=F(x_0)$ This proves continuity. For the second part, we must prove that $\lim_{x \rightarrow x_0}\frac{F(x)-F(x_0)}{x-x_0}=f(x_0)$. We will prove that the right-handed limit is $f(x_0)$, and the left-handed limit is analogous. Suppose $f$ is continuous at $x_0$. Take an arbitrary $\epsilon >0$. There exists a $\delta>0$ such that $|x-x_0| < \delta \implies f(x_0)-\epsilon<f(x)<f(x_0)+\epsilon$. Therefore, if $0<x-x_0 <\delta$, since $$\frac{F(x)-F(x_0)}{x-x_0}=\frac{\int_{[x_0,x]}f(x)}{x-x_0}$$ we have: $$ \frac{\int_{[x_0,x]}(f(x_0)-\epsilon)}{x-x_0}\leq \frac{\int_{[x_0,x]}f(x)}{x-x_0} \leq \frac{\int_{[x_0,x]}(f(x_0)+\epsilon)}{x-x_0} \implies$$ $$ f(x_0)-\epsilon\leq \frac{\int_{[x_0,x]}f(x)}{x-x_0} \leq f(x_0)+\epsilon$$ Therefore, taking any sequence $x_n \rightarrow x_0$ from the right. We have: $$ f(x_0)-\epsilon\leq \limsup \frac{\int_{[x_0,x_n]}f(x_n)}{x_n-x_0} \leq f(x_0)+\epsilon$$ $$ f(x_0)-\epsilon\leq \liminf \frac{\int_{[x_0,x_n]}f(x_n)}{x_n-x_0} \leq f(x_0)+\epsilon$$ Since $\epsilon >0$ is arbitrary: $\lim \frac{\int_{[x_0,x_n]}f(x_n)}{x_n-x_0}=f(x_0)$ This holds for every sequence $x_n \rightarrow x_0$ from the right. Then, $\lim_{x \rightarrow x_0^+}\frac{F(x)-F(x_0)}{x-x_0}=f(x_0)$. As said before, the left-handed limit is analogous. $\blacksquare$ [Second Fundamental Theorem of Calculus] If $f$ is a continuous function on $[a,b]$ and there exists a differentiable function $F$ on $[a,b]$ such that $F'=f$, then: $$\int_{[a,b]}f d\mu=F(b)-F(a)$$ Proof: Fix $n \in \mathbb{N}$ and divide $[a,b]$ in $2^n$ parts: $[a,a+\frac{b-a}{2^n}],...,[a+\frac{(2^n-1)(b-a)}{2^n} ,b]$. Call $x_k:=a+\frac{k(b-a)}{2^n}$, and $[x_{k-1},x_k]$ the $k$-th part. By the mean value theorem there exists, for each part $k$-th part, a number $t_k$ such that: $F(x_k)-F(x_{k-1})=f(t_k)(x-x_{k-1})$ Choose such a $t_k$ for every $k$-th part. Therefore: $$\displaystyle F(b)-F(a)=\sum_{k=1}^{2^n}F(x_k)-F(x_{k-1})=\sum_{k=1}^{2^n}f(t_k)(x-x_{k-1})$$ Now, define: $$\displaystyle f_n:=\sum_{k=1}^{2^n}f(t_k)\chi_{[x_{k-1},x_k]}$$ Doing this for every $n \in \mathbb{N}$, we arrive at a sequence $f_n$ of functions which converge pointwise to $f$, as is easily verified (Here we use continuity of $f$). By construction, for every $n \in \mathbb{N}$, we will have: $$\displaystyle F(b)-F(a)=\int_{[a,b]}f_n d\mu$$ Now, note that $f_n \leq M$ for some $M \in \mathbb{R}$, since $f$ is bounded and $f_n$ is defined piecewisely with values of $f$. Therefore, by Lebesgue's Dominated Convergence Theorem, we have: $$\displaystyle F(b)-F(a)=\lim \int_{[a,b]}f_n d\mu= \int_{[a,b]}f d\mu$$ $\blacksquare$ Therefore, I end with two questions: Are there flaws in the proofs above? If not (or if they are easily repaired), why is the opinion I asked so mainstream?","I am writing a ""textbook"" on Analysis, and I've reached the time I must talk about integrals. I prefer to approach directly the Lebesgue Integral theory. This question is not about the status of this opinion: it has been already extensively discussed in this website and in mathoverflow. My question is rather: why do we associate ""calculations"" with the riemann integral? Specifically, why is it common sense that the Fundamental Theorems of Calculus we see when we first study calculus are best understood in the riemann-integral framework? I give an example of this opinion: From a conceptual standpoint, I think that there are three things one asks of an approach to integration 1) An easily accessible geometric interpretation 2) A readily available computational toolbox (e.g. the fundamental theorem of calculus) 3) A flexible theory The Lebesgue integral is absolutely unrivaled in (3), but it is actually quite obtuse from the other two points of view. Basic results like the Lebesgue differentiation theorem and the change of variables formula are not at all transparent from the Lebesgue point of view, and geometrically it is no better than the Riemann integral. The Cauchy integral is great if you only care about (2), but it is abysmal at (1) and (3). The Riemann integral, for all its faults, strikes a pretty good balance between (1) and (2). It is even known to enjoy an occasional technical advantage over the Lebesgue theory; for instance, one must invent the theory of distributions to make sense of the Cauchy principal value of an improper integral in the Lebesgue theory if I recall correctly. this can be seen here. My point is: the fundamental theorems of calculus (as stated in calculus) can be demonstrated without ever touching the concept of riemann-integration. We, thus, have the so-asked tool of calculation without ever having to appeal to the riemann-integral theory. I illustrate my claim: [First Fundamental Theorem of Calculus] Let $f:[a,b]\rightarrow \mathbb{R}$ be an integrable function. Then: $$F(x):= \int_{[a,x]} f d\mu $$ is continuous in $[a,b]$. Furthermore, if $f$ is continuous at $x_0 \in (a,b)$, then $F$ is differentiable at $x_0$, and $$F'(x_0)=f(x_0)$$ Proof: To prove continuity, fix $x_0 \in [a,b]$. Take a sequence $x_n$ that converges to $x_0$. We will prove $F(x_n) \rightarrow F(x_0)$ $F(x_n)=\int_{[a,x_n]} f d\mu=\int_{[a,b]}f \chi_{[a,x_n]} d\mu$ It is easy to see that $f \chi_{[a,x_n]} \rightarrow  f \chi_{[a,x_0]}$ pointwise. Therefore, since the sequence $f \chi_{[a,x_n]}$ is dominated by $|f|$, it follows by Lebesgue's Dominated Convergence Theorem that: $\lim F(x_n)=F(x_0)$ This proves continuity. For the second part, we must prove that $\lim_{x \rightarrow x_0}\frac{F(x)-F(x_0)}{x-x_0}=f(x_0)$. We will prove that the right-handed limit is $f(x_0)$, and the left-handed limit is analogous. Suppose $f$ is continuous at $x_0$. Take an arbitrary $\epsilon >0$. There exists a $\delta>0$ such that $|x-x_0| < \delta \implies f(x_0)-\epsilon<f(x)<f(x_0)+\epsilon$. Therefore, if $0<x-x_0 <\delta$, since $$\frac{F(x)-F(x_0)}{x-x_0}=\frac{\int_{[x_0,x]}f(x)}{x-x_0}$$ we have: $$ \frac{\int_{[x_0,x]}(f(x_0)-\epsilon)}{x-x_0}\leq \frac{\int_{[x_0,x]}f(x)}{x-x_0} \leq \frac{\int_{[x_0,x]}(f(x_0)+\epsilon)}{x-x_0} \implies$$ $$ f(x_0)-\epsilon\leq \frac{\int_{[x_0,x]}f(x)}{x-x_0} \leq f(x_0)+\epsilon$$ Therefore, taking any sequence $x_n \rightarrow x_0$ from the right. We have: $$ f(x_0)-\epsilon\leq \limsup \frac{\int_{[x_0,x_n]}f(x_n)}{x_n-x_0} \leq f(x_0)+\epsilon$$ $$ f(x_0)-\epsilon\leq \liminf \frac{\int_{[x_0,x_n]}f(x_n)}{x_n-x_0} \leq f(x_0)+\epsilon$$ Since $\epsilon >0$ is arbitrary: $\lim \frac{\int_{[x_0,x_n]}f(x_n)}{x_n-x_0}=f(x_0)$ This holds for every sequence $x_n \rightarrow x_0$ from the right. Then, $\lim_{x \rightarrow x_0^+}\frac{F(x)-F(x_0)}{x-x_0}=f(x_0)$. As said before, the left-handed limit is analogous. $\blacksquare$ [Second Fundamental Theorem of Calculus] If $f$ is a continuous function on $[a,b]$ and there exists a differentiable function $F$ on $[a,b]$ such that $F'=f$, then: $$\int_{[a,b]}f d\mu=F(b)-F(a)$$ Proof: Fix $n \in \mathbb{N}$ and divide $[a,b]$ in $2^n$ parts: $[a,a+\frac{b-a}{2^n}],...,[a+\frac{(2^n-1)(b-a)}{2^n} ,b]$. Call $x_k:=a+\frac{k(b-a)}{2^n}$, and $[x_{k-1},x_k]$ the $k$-th part. By the mean value theorem there exists, for each part $k$-th part, a number $t_k$ such that: $F(x_k)-F(x_{k-1})=f(t_k)(x-x_{k-1})$ Choose such a $t_k$ for every $k$-th part. Therefore: $$\displaystyle F(b)-F(a)=\sum_{k=1}^{2^n}F(x_k)-F(x_{k-1})=\sum_{k=1}^{2^n}f(t_k)(x-x_{k-1})$$ Now, define: $$\displaystyle f_n:=\sum_{k=1}^{2^n}f(t_k)\chi_{[x_{k-1},x_k]}$$ Doing this for every $n \in \mathbb{N}$, we arrive at a sequence $f_n$ of functions which converge pointwise to $f$, as is easily verified (Here we use continuity of $f$). By construction, for every $n \in \mathbb{N}$, we will have: $$\displaystyle F(b)-F(a)=\int_{[a,b]}f_n d\mu$$ Now, note that $f_n \leq M$ for some $M \in \mathbb{R}$, since $f$ is bounded and $f_n$ is defined piecewisely with values of $f$. Therefore, by Lebesgue's Dominated Convergence Theorem, we have: $$\displaystyle F(b)-F(a)=\lim \int_{[a,b]}f_n d\mu= \int_{[a,b]}f d\mu$$ $\blacksquare$ Therefore, I end with two questions: Are there flaws in the proofs above? If not (or if they are easily repaired), why is the opinion I asked so mainstream?",,"['integration', 'analysis', 'soft-question']"
54,"Evaluating $\int{ \frac{\arctan\sqrt{x^{2}-1}}{\sqrt{x^{2}+x}}} \,dx$",Evaluating,"\int{ \frac{\arctan\sqrt{x^{2}-1}}{\sqrt{x^{2}+x}}} \,dx","How to integrate? $$\int{ \frac{\arctan\sqrt{x^{2}-1}}{\sqrt{x^{2}+x}}}\, dx$$ I have no idea how to do it. Tried to get some information from wiki, but its too hard :|","How to integrate? $$\int{ \frac{\arctan\sqrt{x^{2}-1}}{\sqrt{x^{2}+x}}}\, dx$$ I have no idea how to do it. Tried to get some information from wiki, but its too hard :|",,"['integration', 'trigonometry', 'indefinite-integrals']"
55,Why are some non elementary integrals defined and others are not?,Why are some non elementary integrals defined and others are not?,,"Why are some integrals that cannot be integrated in elementary terms defined and given names, while others arent? Based on what criteria are they chosen? Applicability to real life? And what is the point if we cannot solve them? For example: $$\int\frac{\sin(x)}{x}\,dx=\text{Si}(x), \quad -\int_{-x}^\infty \frac{e^{-t}}{t}\,dt=\text{Ei}(x), \quad \int \cos\left(x^2\right)\,dx = \sqrt{\frac\pi2} \text{C}\left( \sqrt{\frac2\pi}x\right)$$ while others like  $$\int x^x \,dx$$ are not defined.","Why are some integrals that cannot be integrated in elementary terms defined and given names, while others arent? Based on what criteria are they chosen? Applicability to real life? And what is the point if we cannot solve them? For example: $$\int\frac{\sin(x)}{x}\,dx=\text{Si}(x), \quad -\int_{-x}^\infty \frac{e^{-t}}{t}\,dt=\text{Ei}(x), \quad \int \cos\left(x^2\right)\,dx = \sqrt{\frac\pi2} \text{C}\left( \sqrt{\frac2\pi}x\right)$$ while others like  $$\int x^x \,dx$$ are not defined.",,['integration']
56,Differentiating Definite Integral,Differentiating Definite Integral,,I think $\frac{d}{dx} \int f(x) dx = f(x)$ right? So $\frac{d}{dx} \int^b_a f(x) dx = [f(x)]^b_a = f(a)-f(b)$? But why when: $$f(x) = \int^{x^3}_{x^2} \sqrt{7+2e^{3t-3}}$$ then $$f'(x) = \color{red}{(x^3)'}\sqrt{7+2e^{3x-3}} - \color{red}{(x^2)'}\sqrt{7+2e^{3x-3}}$$ Where did the $(x^3)'$ and $(x^2)'$ come from?,I think $\frac{d}{dx} \int f(x) dx = f(x)$ right? So $\frac{d}{dx} \int^b_a f(x) dx = [f(x)]^b_a = f(a)-f(b)$? But why when: $$f(x) = \int^{x^3}_{x^2} \sqrt{7+2e^{3t-3}}$$ then $$f'(x) = \color{red}{(x^3)'}\sqrt{7+2e^{3x-3}} - \color{red}{(x^2)'}\sqrt{7+2e^{3x-3}}$$ Where did the $(x^3)'$ and $(x^2)'$ come from?,,"['integration', 'derivatives', 'leibniz-integral-rule']"
57,Evaluate the integral $\int_{0}^{\infty} \frac{1}{(1+x^2)\cosh{(ax)}}dx$,Evaluate the integral,\int_{0}^{\infty} \frac{1}{(1+x^2)\cosh{(ax)}}dx,"The problem is : Evaluate the integral $$\int_{0}^{\infty} \frac{1}{(1+x^2)\cosh{(ax)}}dx$$ I have tried expand $\frac{1}{\cosh{ax}}$ and give the result in the following way: First, note that $$\frac{1}{\cosh{(ax)}}=\frac{2e^{-ax}}{e^{-2ax}+1}=\sum_{n=0}^{\infty}2(-1)^n e^{-(2n+1)ax}$$     Secondly, we consider $f(a)=\int_{0}^{\infty} \frac{e^{ax}}{1+x^2}dx$ Some calculation results in $f''(a)+f(a)=\int_{0}^{\infty}e^{ax}dx=-\frac{1}{a}$ We substitute $f(a)=u(a)e^{ia}$ into former result and thus $ (u'(a) e^{2ia})'=-\frac{e^{ia}}{a}.$ Let $E(a)=\int_{0}^{a} \frac{e^{it}}{t}dt=\mbox{Ei}(ia)$ where $\mbox{Ei}(x)$ is the Exponential integral then $$u'(a)= -e^{-2ia} E(a)+c_1 e^{-2ia}.$$ Hence  \begin{align*}u(a) &=\frac{1}{2i} e^{-2ia}E(a) - \frac{1}{2i}\int_{0}^{a} \frac{e^{-it}}{t}dt-\frac{1}{2i}c_1 e^{-2ia} +c_2 \\ &=\frac{1}{2i} e^{-2ia}E(a) -\frac{1}{2i}E(-a)-\frac{1}{2i}c_1 e^{-2ia} +c_2\end{align*}     We conclude that $$ f(a)=\frac{e^{-ia} \mbox{Ei}(ia)-e^{ia}\mbox{Ei}(-ia)}{2i}+c_1 e^{-ia}+c_2 e^{ia}$$ But I got stuck here, I cannot figure out $c_1$ as well as $c_2$. Also, even $c_1$ and $c_2$ are known, I cannot use the summation to get result for the original question. Is there other way to tackle this problem? Or can I modify my method to make it feasible to get the desired result? Thanks for your attention!","The problem is : Evaluate the integral $$\int_{0}^{\infty} \frac{1}{(1+x^2)\cosh{(ax)}}dx$$ I have tried expand $\frac{1}{\cosh{ax}}$ and give the result in the following way: First, note that $$\frac{1}{\cosh{(ax)}}=\frac{2e^{-ax}}{e^{-2ax}+1}=\sum_{n=0}^{\infty}2(-1)^n e^{-(2n+1)ax}$$     Secondly, we consider $f(a)=\int_{0}^{\infty} \frac{e^{ax}}{1+x^2}dx$ Some calculation results in $f''(a)+f(a)=\int_{0}^{\infty}e^{ax}dx=-\frac{1}{a}$ We substitute $f(a)=u(a)e^{ia}$ into former result and thus $ (u'(a) e^{2ia})'=-\frac{e^{ia}}{a}.$ Let $E(a)=\int_{0}^{a} \frac{e^{it}}{t}dt=\mbox{Ei}(ia)$ where $\mbox{Ei}(x)$ is the Exponential integral then $$u'(a)= -e^{-2ia} E(a)+c_1 e^{-2ia}.$$ Hence  \begin{align*}u(a) &=\frac{1}{2i} e^{-2ia}E(a) - \frac{1}{2i}\int_{0}^{a} \frac{e^{-it}}{t}dt-\frac{1}{2i}c_1 e^{-2ia} +c_2 \\ &=\frac{1}{2i} e^{-2ia}E(a) -\frac{1}{2i}E(-a)-\frac{1}{2i}c_1 e^{-2ia} +c_2\end{align*}     We conclude that $$ f(a)=\frac{e^{-ia} \mbox{Ei}(ia)-e^{ia}\mbox{Ei}(-ia)}{2i}+c_1 e^{-ia}+c_2 e^{ia}$$ But I got stuck here, I cannot figure out $c_1$ as well as $c_2$. Also, even $c_1$ and $c_2$ are known, I cannot use the summation to get result for the original question. Is there other way to tackle this problem? Or can I modify my method to make it feasible to get the desired result? Thanks for your attention!",,"['integration', 'definite-integrals', 'improper-integrals']"
58,Ways to prove $ \int_0^\pi \frac{\sin^2 nx}{\sin^2 x} dx= n\pi$,Ways to prove, \int_0^\pi \frac{\sin^2 nx}{\sin^2 x} dx= n\pi,"In how many ways can we prove the following theorem? $$I(n):= \int_0^\pi \frac{\sin^2 nx}{\sin^2 x} dx= n\pi$$ where $n$ is a nonnegative integer. The proof I found is by considering $I(n+1)-I(n)$ , which can be reduced to $$ g(n):= \int_0^\pi \frac{\sin(2 n x) \cos x}{\sin x}dx $$ I then showed that $g(n)=g(n+1)$ , with $g(n) = ng(1) = n\pi$ . This completes the proof. I was wondering if there is a more direct way to prove it. By 'direct' I mean without deriving auxiliary recursions.","In how many ways can we prove the following theorem? where is a nonnegative integer. The proof I found is by considering , which can be reduced to I then showed that , with . This completes the proof. I was wondering if there is a more direct way to prove it. By 'direct' I mean without deriving auxiliary recursions.","I(n):= \int_0^\pi \frac{\sin^2 nx}{\sin^2 x} dx= n\pi n I(n+1)-I(n) 
g(n):= \int_0^\pi \frac{\sin(2 n x) \cos x}{\sin x}dx
 g(n)=g(n+1) g(n) = ng(1) = n\pi","['integration', 'trigonometry', 'definite-integrals', 'trigonometric-integrals']"
59,Solving what Mathematica could not,Solving what Mathematica could not,,"Right, so as the final step of my project draws near and after having made a bad layout sort of question, I am posting a new one very clear and unambiguous. I need to find this specific definite integral which Mathematica could not solve: $$  \int_{x=0}^\pi \frac{\cos \frac{x}{2}}{\sqrt{1 + A \sin^2 \frac{x}{2}}} \sin \left( \frac{1+A}{\sqrt{A}} \omega \tanh^{-1} \frac{\cos \frac{x}{2}}{\sqrt{1 + A \sin^2 \frac{x}{2}}} \right) \, dx.$$ where $ 0<A<1 $ and $ \omega > 0 $ are parameters of the problem. I tried to use a substitution of the argument of the hyperbolic arctan but that seemed to make it worse. I was posting here in the hopes of receiving help, if someone could tell me if it is at all possible to solve it analytically via a trick of sorts or a clever substitution, or maybe it is an elliptic integral in disguise. I thank all helpers. ** My question on the Melnikov integral can be found here I just used trig identities to soften it up","Right, so as the final step of my project draws near and after having made a bad layout sort of question, I am posting a new one very clear and unambiguous. I need to find this specific definite integral which Mathematica could not solve: $$  \int_{x=0}^\pi \frac{\cos \frac{x}{2}}{\sqrt{1 + A \sin^2 \frac{x}{2}}} \sin \left( \frac{1+A}{\sqrt{A}} \omega \tanh^{-1} \frac{\cos \frac{x}{2}}{\sqrt{1 + A \sin^2 \frac{x}{2}}} \right) \, dx.$$ where $ 0<A<1 $ and $ \omega > 0 $ are parameters of the problem. I tried to use a substitution of the argument of the hyperbolic arctan but that seemed to make it worse. I was posting here in the hopes of receiving help, if someone could tell me if it is at all possible to solve it analytically via a trick of sorts or a clever substitution, or maybe it is an elliptic integral in disguise. I thank all helpers. ** My question on the Melnikov integral can be found here I just used trig identities to soften it up",,"['integration', 'definite-integrals', 'elliptic-integrals']"
60,Evaluating $\int_0^1 \frac{\arctan x \log x}{1+x}dx$,Evaluating,\int_0^1 \frac{\arctan x \log x}{1+x}dx,"In order to compute, in an elementary way , $\displaystyle \int_0^1 \frac{x \arctan x \log \left( 1-x^2\right)}{1+x^2}dx$ (see Evaluating $\int_0^1 \frac{x \arctan x \log \left( 1-x^2\right)}{1+x^2}dx$ ) i need to show, in a simple way , that: $\displaystyle \int_0^1 \dfrac{\arctan x \log x}{1+x}dx=\dfrac{G\ln 2}{2}-\dfrac{\pi^3}{64}$ $G$ is the Catalan's constant.","In order to compute, in an elementary way , $\displaystyle \int_0^1 \frac{x \arctan x \log \left( 1-x^2\right)}{1+x^2}dx$ (see Evaluating $\int_0^1 \frac{x \arctan x \log \left( 1-x^2\right)}{1+x^2}dx$ ) i need to show, in a simple way , that: $\displaystyle \int_0^1 \dfrac{\arctan x \log x}{1+x}dx=\dfrac{G\ln 2}{2}-\dfrac{\pi^3}{64}$ $G$ is the Catalan's constant.",,"['integration', 'definite-integrals', 'harmonic-numbers']"
61,General condition that Riemann and Lebesgue integrals are the same,General condition that Riemann and Lebesgue integrals are the same,,"I'd like to know that when Riemann integral and Lebesgue integral are the same in general. I know that a bounded Riemann integrable function on a closed interval is Lebesgue integrable and two integrals are the same. However, I want to know as general as possible condition for two integrals to be the same. For example, in terms of improper integrals, unbounded functions and $\mathbb R^n$ space. Any answer would be helpful. Thank you.","I'd like to know that when Riemann integral and Lebesgue integral are the same in general. I know that a bounded Riemann integrable function on a closed interval is Lebesgue integrable and two integrals are the same. However, I want to know as general as possible condition for two integrals to be the same. For example, in terms of improper integrals, unbounded functions and space. Any answer would be helpful. Thank you.",\mathbb R^n,"['integration', 'multivariable-calculus', 'improper-integrals', 'lebesgue-integral', 'riemann-sum']"
62,Simple proof of integration in polar coordinates?,Simple proof of integration in polar coordinates?,,"In every example I saw of integration in polar coordinates the  Jacobian determinant is used, not that I have a problem with the Jacobian, but I wondered if there's a simpler way to show this which will also give me some more intuition about the Jacobian. If I try to simply write the differentials: \begin{align} x & = r \cos \theta\\ y & = r \sin \theta\\ dx & = dr \cos \theta - r \sin \theta\ d\theta\\ dy & = dr \sin \theta + r \cos \theta\ d\theta\\ \end{align} In a double integral you integrate $dxdy$, so if I try to plug in the results I'll get something which is not $r d\theta dr$ \begin{align} dxdy & = \left(dr \cos \theta - r \sin \theta\ d\theta \right) \left( dr \sin \theta + r \cos \theta\ d\theta\right)\\ & = dr^2 \cos \theta \sin \theta  - r^2 d\theta^2 \cos \theta\ \sin\ \theta + r\ dr\ d\theta\ (\cos^2 \theta\ - \sin^2\theta ) \end{align} I don't think I can go anywhere from here, I'm not sure if it's just a calculation mistake or the entire logic is bad. How do I get this right? Thanx :)","In every example I saw of integration in polar coordinates the  Jacobian determinant is used, not that I have a problem with the Jacobian, but I wondered if there's a simpler way to show this which will also give me some more intuition about the Jacobian. If I try to simply write the differentials: \begin{align} x & = r \cos \theta\\ y & = r \sin \theta\\ dx & = dr \cos \theta - r \sin \theta\ d\theta\\ dy & = dr \sin \theta + r \cos \theta\ d\theta\\ \end{align} In a double integral you integrate $dxdy$, so if I try to plug in the results I'll get something which is not $r d\theta dr$ \begin{align} dxdy & = \left(dr \cos \theta - r \sin \theta\ d\theta \right) \left( dr \sin \theta + r \cos \theta\ d\theta\right)\\ & = dr^2 \cos \theta \sin \theta  - r^2 d\theta^2 \cos \theta\ \sin\ \theta + r\ dr\ d\theta\ (\cos^2 \theta\ - \sin^2\theta ) \end{align} I don't think I can go anywhere from here, I'm not sure if it's just a calculation mistake or the entire logic is bad. How do I get this right? Thanx :)",,"['differential-geometry', 'integration', 'coordinate-systems', 'polar-coordinates']"
63,"What is $\int_0^1 \frac{\log \left(1-x^2\right) \sin ^{-1}(x)^2}{x^2} \, dx$?",What is ?,"\int_0^1 \frac{\log \left(1-x^2\right) \sin ^{-1}(x)^2}{x^2} \, dx","I encountered the integral $$\int_0^1 \frac{\log \left(1-x^2\right) \sin ^{-1}(x)^2}{x^2} \, dx = -0.9393323982...$$ while researching the evaluation of harmonic sums. Mathematica 11 is not able to evaluate this integral, and is not able to evaluate the underlying indefinite integral. I considered using the Maclaurin series for the expression $\sin ^{-1}(x)^2$ to evaluate this integral. Using this Maclaurin series, it is easily seen that the problem of evaluating the above integral is equivalent to the problem of evaluating the series $$\sum _{n=1}^{\infty } \frac{2^{2 n-1} H_{n-\frac{1}{2}}}{(1-2 n) n^2 \binom{2 n}{n}}=-0.9393323982...$$ which Mathematica 11 is not able to evaluate directly. I also considered using the Maclaurin series for the expression $\log \left(1-x^2\right)$ to evaluate the above integral. Using this Macluarin series, it is easily seen that this integral is equal to $$\frac{1}{4} \left(16 \pi  C-\pi ^3-\pi ^2 \log (4)\right)+\sum _{n=1}^{\infty } \frac{\, _3F_2\left(\frac{1}{2},\frac{1}{2},1;\frac{3}{2},n+1;1\right)}{n^2-2 n^3}=-0.939332...,$$ but Mathematica is unable to evaluate the above infinite series. What is a closed-form evaluation of $\int_0^1 \frac{\log \left(1-x^2\right) \sin ^{-1}(x)^2}{x^2} \, dx$? What techniques can be applied to evaluate this definite integral?","I encountered the integral $$\int_0^1 \frac{\log \left(1-x^2\right) \sin ^{-1}(x)^2}{x^2} \, dx = -0.9393323982...$$ while researching the evaluation of harmonic sums. Mathematica 11 is not able to evaluate this integral, and is not able to evaluate the underlying indefinite integral. I considered using the Maclaurin series for the expression $\sin ^{-1}(x)^2$ to evaluate this integral. Using this Maclaurin series, it is easily seen that the problem of evaluating the above integral is equivalent to the problem of evaluating the series $$\sum _{n=1}^{\infty } \frac{2^{2 n-1} H_{n-\frac{1}{2}}}{(1-2 n) n^2 \binom{2 n}{n}}=-0.9393323982...$$ which Mathematica 11 is not able to evaluate directly. I also considered using the Maclaurin series for the expression $\log \left(1-x^2\right)$ to evaluate the above integral. Using this Macluarin series, it is easily seen that this integral is equal to $$\frac{1}{4} \left(16 \pi  C-\pi ^3-\pi ^2 \log (4)\right)+\sum _{n=1}^{\infty } \frac{\, _3F_2\left(\frac{1}{2},\frac{1}{2},1;\frac{3}{2},n+1;1\right)}{n^2-2 n^3}=-0.939332...,$$ but Mathematica is unable to evaluate the above infinite series. What is a closed-form evaluation of $\int_0^1 \frac{\log \left(1-x^2\right) \sin ^{-1}(x)^2}{x^2} \, dx$? What techniques can be applied to evaluate this definite integral?",,"['integration', 'definite-integrals', 'logarithms', 'closed-form']"
64,Integrate Form $du / (a^2 + u^2)^{3/2}$,Integrate Form,du / (a^2 + u^2)^{3/2},"How does one integrate  $$\int \dfrac{du}{(a^2 + u^2)^{3/2}}\  ?$$ The table of integrals here: http://teachers.sduhsd.k12.ca.us/abrown/classes/CalculusC/IntegralTablesStewart.pdf Gives it as: $$\frac{u}{a^2 ( a^2 + u^2)^{1/2}}\ .$$ I'm getting back into calculus and very rusty. I'd like to be comfortable with some of the proofs behind various fundamental ""Table of Integrals"" integrals. Looking at it, the substitution rule seems like the method of choice. What is the strategy here for choosing a substitution? It has a form similar to many trigonometric integrals, but the final result seems to suggest that they're not necessary in this case.","How does one integrate  $$\int \dfrac{du}{(a^2 + u^2)^{3/2}}\  ?$$ The table of integrals here: http://teachers.sduhsd.k12.ca.us/abrown/classes/CalculusC/IntegralTablesStewart.pdf Gives it as: $$\frac{u}{a^2 ( a^2 + u^2)^{1/2}}\ .$$ I'm getting back into calculus and very rusty. I'd like to be comfortable with some of the proofs behind various fundamental ""Table of Integrals"" integrals. Looking at it, the substitution rule seems like the method of choice. What is the strategy here for choosing a substitution? It has a form similar to many trigonometric integrals, but the final result seems to suggest that they're not necessary in this case.",,['integration']
65,Jacobian for a Cartesian to Polar-Coordinate Transformation,Jacobian for a Cartesian to Polar-Coordinate Transformation,,"I have a simple doubt about the Jacobian and substitutions of the variables in the integral. suppose I have substituted $x=r \cos\theta$ and $y=r \sin\theta$ in an integral to go from cartesian to polar-coordinate. If I use simple area rule or the standard jacobian method, I will get $dx dy=r dr d\theta$. At the same time, using the direct method, $dx=dr \cos\theta-r\sin\theta\; d\theta, \quad $ $dy=dr \sin\theta+r\cos\theta \;d\theta \quad $. Then I find $\bf{dxdy}$ by simply taking the product  and neglecting the second order differential, I will get  $dxdy=rdrd\theta(cos^{2}\theta-sin^{2}\theta)$. Both results are different. Here there is a missing negative sign and I don't understand it well. This negative sign comes from the evaluation of the determinant, due to its off-diagonal product term of the Jacobian matrix. Hence the right result is  $dxdy=rdrd\theta(cos^{2}\theta+sin^{2}\theta)=rdrd\theta$. I don't understand, why the contradiction comes here ???","I have a simple doubt about the Jacobian and substitutions of the variables in the integral. suppose I have substituted $x=r \cos\theta$ and $y=r \sin\theta$ in an integral to go from cartesian to polar-coordinate. If I use simple area rule or the standard jacobian method, I will get $dx dy=r dr d\theta$. At the same time, using the direct method, $dx=dr \cos\theta-r\sin\theta\; d\theta, \quad $ $dy=dr \sin\theta+r\cos\theta \;d\theta \quad $. Then I find $\bf{dxdy}$ by simply taking the product  and neglecting the second order differential, I will get  $dxdy=rdrd\theta(cos^{2}\theta-sin^{2}\theta)$. Both results are different. Here there is a missing negative sign and I don't understand it well. This negative sign comes from the evaluation of the determinant, due to its off-diagonal product term of the Jacobian matrix. Hence the right result is  $dxdy=rdrd\theta(cos^{2}\theta+sin^{2}\theta)=rdrd\theta$. I don't understand, why the contradiction comes here ???",,"['integration', 'coordinate-systems', 'polar-coordinates']"
66,What is the expected area of a triangle in which each side is a random real number between $0$ and $1$?,What is the expected area of a triangle in which each side is a random real number between  and ?,0 1,"Let $a,b,c$ be three independent uniformly random real numbers between $0$ and $1$ . Given that there exists a triangle with side lengths $a,b,c$ , what is the expected area of the triangle? Using Heron's formula , the area is $\frac14\sqrt{(a+b+c)(-a+b+c)(a-b+c)(a+b-c)}$ . The expected area should be a triple integral with respect to $a,b,c$ , but I don't know how to set up the limits of integration. Previously I was able to set up an integral to answer a related question: ""What is the expected area of a random triangle with perimeter $1$ ?"" I tried to utilize my approach there, by asking ""What is the expected area of a random triangle with perimeter $p$ ?"" and then integrating from $p=0$ to $p=3$ . But each value of $p$ has a different ""weight"", so I think I should somehow take into account the distribution of $p$ , but I'm not sure how. Then, for the anti-derivative, I'm not sure what substitution would disengage $a,b,c$ to allow for indefinite integration. A simulation with $10^7$ trials yields an average area of $0.11600$ .","Let be three independent uniformly random real numbers between and . Given that there exists a triangle with side lengths , what is the expected area of the triangle? Using Heron's formula , the area is . The expected area should be a triple integral with respect to , but I don't know how to set up the limits of integration. Previously I was able to set up an integral to answer a related question: ""What is the expected area of a random triangle with perimeter ?"" I tried to utilize my approach there, by asking ""What is the expected area of a random triangle with perimeter ?"" and then integrating from to . But each value of has a different ""weight"", so I think I should somehow take into account the distribution of , but I'm not sure how. Then, for the anti-derivative, I'm not sure what substitution would disengage to allow for indefinite integration. A simulation with trials yields an average area of .","a,b,c 0 1 a,b,c \frac14\sqrt{(a+b+c)(-a+b+c)(a-b+c)(a+b-c)} a,b,c 1 p p=0 p=3 p p a,b,c 10^7 0.11600","['integration', 'geometry', 'triangles', 'expected-value', 'area']"
67,Integral $\int_{-\infty}^{\infty} \arctan(e^x) \arctan(e^{-x})dx=\frac{7}{4}\zeta(3)$,Integral,\int_{-\infty}^{\infty} \arctan(e^x) \arctan(e^{-x})dx=\frac{7}{4}\zeta(3),"How to prove that $$\int_{-\infty}^{\infty} \arctan(e^x) \arctan(e^{-x})\rm dx=\frac{7}{4}\zeta(3)?$$ This integral appeared while attempting to solve an unanswered question, namely: Closed form of :$ \int_{-\infty}^{\infty}\arctan\left(e^{-x^2 \text{erf}(x)}\right)\,\arctan\left(e^{x^2\text{erf(x)}}\right)\,dx $ I happened to find that $$\int_{-\infty}^{\infty} \arctan(e^x) ~\arctan(e^{-x})~dx=\frac{7}{4}\zeta(3).$$ How can you work out the answer on the right by hand? I guess that there could be multiple approaches to solve this one.","How to prove that This integral appeared while attempting to solve an unanswered question, namely: Closed form of :$ \int_{-\infty}^{\infty}\arctan\left(e^{-x^2 \text{erf}(x)}\right)\,\arctan\left(e^{x^2\text{erf(x)}}\right)\,dx $ I happened to find that How can you work out the answer on the right by hand? I guess that there could be multiple approaches to solve this one.",\int_{-\infty}^{\infty} \arctan(e^x) \arctan(e^{-x})\rm dx=\frac{7}{4}\zeta(3)? \int_{-\infty}^{\infty} \arctan(e^x) ~\arctan(e^{-x})~dx=\frac{7}{4}\zeta(3).,"['integration', 'definite-integrals', 'improper-integrals', 'riemann-zeta', 'trigonometric-integrals']"
68,"On the integral $\int_{-\pi/2}^{\pi/2}\sin(x/\sin(x/\sin(x/\sin\cdots)))\,dx$",On the integral,"\int_{-\pi/2}^{\pi/2}\sin(x/\sin(x/\sin(x/\sin\cdots)))\,dx","This question is the final one out of the set (see I and II ), I promise! Consider $f_1(x)=\sin(x)$ and $f_2(x)=\sin\left(\frac x{f_1(x)}\right)$ such that $f_n$ satisfies the relation $$f_n(x)=\sin\left(\frac x{f_{n-1}(x)}\right).$$ To what value does $$L:=\lim_{k\to\infty}\int_{-\pi/2}^{\pi/2} f_{2k-1}(x)\,dx$$ converge, for $k=1,2,\cdots$ ? Here is a very nice graph showing the likely convergence of $f_n$ : The $R^2$ value is extremely close to $1$ , and the best fit curve is given by the equation $$y=\frac{0.2091}{e^x-0.5226}+2.411$$ which implies that $$L\approx2.411$$ Are there any analytic techniques to prove this?","This question is the final one out of the set (see I and II ), I promise! Consider and such that satisfies the relation To what value does converge, for ? Here is a very nice graph showing the likely convergence of : The value is extremely close to , and the best fit curve is given by the equation which implies that Are there any analytic techniques to prove this?","f_1(x)=\sin(x) f_2(x)=\sin\left(\frac x{f_1(x)}\right) f_n f_n(x)=\sin\left(\frac x{f_{n-1}(x)}\right). L:=\lim_{k\to\infty}\int_{-\pi/2}^{\pi/2} f_{2k-1}(x)\,dx k=1,2,\cdots f_n R^2 1 y=\frac{0.2091}{e^x-0.5226}+2.411 L\approx2.411","['integration', 'limits', 'convergence-divergence', 'regression']"
69,Derive Fourier transform of sinc function,Derive Fourier transform of sinc function,,"We know that the Fourier transform of the sinc function is the rectangular function (or top hat). However, I'm at a loss as to how to prove it. Most textbooks and online sources start with the rectangular function, show that $$\int_{-\infty}^\infty \text{rect}(x)e^{i\omega x}dx=\int_{-1/2}^{1/2}e^{i\omega x}dx=\left.\frac{e^{i\omega x}}{i\omega}\right\vert_{-1/2}^{1/2}=\text{sinc}(\omega/2)$$ and then just invoke duality and claim that the Fourier transform of the sinc function is the rectangular function. Is there any way of deriving this directly? i.e., starting with the sinc function? I've tried, but I'm not sure as to how to proceed. I know that the sinc is not Lebesgue integrable and only improper Riemann integrable. Some vague recollection of these being important in the Fourier transform hinders my thought process. Can someone clear things up for me?","We know that the Fourier transform of the sinc function is the rectangular function (or top hat). However, I'm at a loss as to how to prove it. Most textbooks and online sources start with the rectangular function, show that $$\int_{-\infty}^\infty \text{rect}(x)e^{i\omega x}dx=\int_{-1/2}^{1/2}e^{i\omega x}dx=\left.\frac{e^{i\omega x}}{i\omega}\right\vert_{-1/2}^{1/2}=\text{sinc}(\omega/2)$$ and then just invoke duality and claim that the Fourier transform of the sinc function is the rectangular function. Is there any way of deriving this directly? i.e., starting with the sinc function? I've tried, but I'm not sure as to how to proceed. I know that the sinc is not Lebesgue integrable and only improper Riemann integrable. Some vague recollection of these being important in the Fourier transform hinders my thought process. Can someone clear things up for me?",,['integration']
70,Show that $\int\limits_0^1 \left(x^{x}\right)^{\left(x^{x}\right)^{\left(x^{x}\right)^{\left(x^{x}\right)^{}}}}\ \mathrm{d}x=\frac{\pi^2}{12}$.,Show that .,\int\limits_0^1 \left(x^{x}\right)^{\left(x^{x}\right)^{\left(x^{x}\right)^{\left(x^{x}\right)^{}}}}\ \mathrm{d}x=\frac{\pi^2}{12},How can it be shown that $$\lim_{p\to\infty}I(p)= \lim_{p \to \infty}\int^{1}_0 (x^x)^{\scriptscriptstyle {(x^x)^{(x^x)^{(x^x)^{(x^x)^{(x^x)...(p \; times)}}}}}} dx= \frac{\pi^2}{12}$$ $I(1)=\int^{1}_0 x^x dx=\sum_{n=0} ^{\infty} \frac{1}{n!}\int^{1}_0 \ln(x)^nx^n dx$ also $\int^{1}_0 \ln(x)^nx^n dx=(-1)^n (1+n)^{-1-n}n!$ . I don't know how to calculate $I(p)$ beyond $p=1.$ Note: This integral was proposed on Romanian Mathematical Magazine and two solutions can be found here .,How can it be shown that also . I don't know how to calculate beyond Note: This integral was proposed on Romanian Mathematical Magazine and two solutions can be found here .,\lim_{p\to\infty}I(p)= \lim_{p \to \infty}\int^{1}_0 (x^x)^{\scriptscriptstyle {(x^x)^{(x^x)^{(x^x)^{(x^x)^{(x^x)...(p \; times)}}}}}} dx= \frac{\pi^2}{12} I(1)=\int^{1}_0 x^x dx=\sum_{n=0} ^{\infty} \frac{1}{n!}\int^{1}_0 \ln(x)^nx^n dx \int^{1}_0 \ln(x)^nx^n dx=(-1)^n (1+n)^{-1-n}n! I(p) p=1.,"['integration', 'limits', 'definite-integrals', 'pi', 'tetration']"
71,how to calculate integral of square of a function,how to calculate integral of square of a function,,"When doing differentiation, I know that if $f$ is a function on $x$, then $$ { d \over dx } f^2 = 2 f {df \over dx} $$ so the opposite in integration is also clear: $$ \int 2 f { df \over dx } dx = f^2 $$ I also know that $$ \int x^2 dx = { x^3 \over 3} $$ But I'm not sure as to how I can evaluate: $$ \int f^2 dx $$ I mean is there any identity for this? That the above is equal to another function of $f$ (such as $f^3 \over 3$ times something)? Is there any method to find this? I googled some but perhaps I wasn't using proper search terms so I didn't get any clear results so I'm asking here. [I hope my question is clear enough :-(]","When doing differentiation, I know that if $f$ is a function on $x$, then $$ { d \over dx } f^2 = 2 f {df \over dx} $$ so the opposite in integration is also clear: $$ \int 2 f { df \over dx } dx = f^2 $$ I also know that $$ \int x^2 dx = { x^3 \over 3} $$ But I'm not sure as to how I can evaluate: $$ \int f^2 dx $$ I mean is there any identity for this? That the above is equal to another function of $f$ (such as $f^3 \over 3$ times something)? Is there any method to find this? I googled some but perhaps I wasn't using proper search terms so I didn't get any clear results so I'm asking here. [I hope my question is clear enough :-(]",,['integration']
72,How to integrate $\int_{0}^{1} \frac{1-x}{1+x} \frac{dx}{\sqrt{x^4 + ax^2 + 1}}$?,How to integrate ?,\int_{0}^{1} \frac{1-x}{1+x} \frac{dx}{\sqrt{x^4 + ax^2 + 1}},"The question is how to show the identity $$ \int_{0}^{1} \frac{1-x}{1+x} \cdot \frac{dx}{\sqrt{x^4 + ax^2 + 1}} = \frac{1}{\sqrt{a+2}} \log\left( 1 + \frac{\sqrt{a+2}}{2} \right), \tag{$a>-2$} $$ I checked this numerically for several cases, but even Mathematica 11 could not manage this symbolically for general $a$, except for some special cases like $a = 0, 1, 2$. Addendum. Here are some backgrounds and my ideas: This integral came from my personal attempt to find the pattern for the integral $$ J(a, b) := \int_{0}^{1} \frac{1-x}{1+x} \cdot \frac{dx}{\sqrt{1 + ax^2 + bx^4}}. $$ This drew my attention as we have the following identity $$ \int_{0}^{\infty} \frac{x}{x+1} \cdot \frac{dx}{\sqrt{4x^4 + 8x^3 + 12x^2 + 8x + 1}} = J(6,-3), $$ where the LHS is the integral from this question . So establishing the claim in this question amounts to showing that $J(6,-3) = \frac{1}{2}\log 3 - \frac{1}{3}\log 2$, though I am skeptical that $J(a, b)$ has a nice closed form for every pair of parameters $(a, b)$. A possible idea is to write \begin{align*} &\int_{0}^{1} \frac{1-x}{1+x} \cdot \frac{dx}{\sqrt{x^4 + ax^2 + 1}} \\ &\hspace{5em}= \int_{0}^{1} \frac{(x^{-2} + 1) - 2x^{-1}}{x^{-1} - x} \cdot \frac{dx}{\sqrt{(x^{-1} - x)^2 + a + 2}} \end{align*} This follows from a simple algebraic manipulation. This suggests that we might be able to apply Glasser's master theorem, though in a less trivial way. I do not believe that this is particularly hard, but I literally have not enough time to think about this now. So I guess it is a good time to seek help.","The question is how to show the identity $$ \int_{0}^{1} \frac{1-x}{1+x} \cdot \frac{dx}{\sqrt{x^4 + ax^2 + 1}} = \frac{1}{\sqrt{a+2}} \log\left( 1 + \frac{\sqrt{a+2}}{2} \right), \tag{$a>-2$} $$ I checked this numerically for several cases, but even Mathematica 11 could not manage this symbolically for general $a$, except for some special cases like $a = 0, 1, 2$. Addendum. Here are some backgrounds and my ideas: This integral came from my personal attempt to find the pattern for the integral $$ J(a, b) := \int_{0}^{1} \frac{1-x}{1+x} \cdot \frac{dx}{\sqrt{1 + ax^2 + bx^4}}. $$ This drew my attention as we have the following identity $$ \int_{0}^{\infty} \frac{x}{x+1} \cdot \frac{dx}{\sqrt{4x^4 + 8x^3 + 12x^2 + 8x + 1}} = J(6,-3), $$ where the LHS is the integral from this question . So establishing the claim in this question amounts to showing that $J(6,-3) = \frac{1}{2}\log 3 - \frac{1}{3}\log 2$, though I am skeptical that $J(a, b)$ has a nice closed form for every pair of parameters $(a, b)$. A possible idea is to write \begin{align*} &\int_{0}^{1} \frac{1-x}{1+x} \cdot \frac{dx}{\sqrt{x^4 + ax^2 + 1}} \\ &\hspace{5em}= \int_{0}^{1} \frac{(x^{-2} + 1) - 2x^{-1}}{x^{-1} - x} \cdot \frac{dx}{\sqrt{(x^{-1} - x)^2 + a + 2}} \end{align*} This follows from a simple algebraic manipulation. This suggests that we might be able to apply Glasser's master theorem, though in a less trivial way. I do not believe that this is particularly hard, but I literally have not enough time to think about this now. So I guess it is a good time to seek help.",,"['integration', 'definite-integrals']"
73,"Compute Double Sum $\sum_{n,m=1}^{\infty}\frac{(-1)^{n-1}}{n^2+m^2}=\frac{\pi^2}{24}+\frac{\pi \ln(2)}{8}$",Compute Double Sum,"\sum_{n,m=1}^{\infty}\frac{(-1)^{n-1}}{n^2+m^2}=\frac{\pi^2}{24}+\frac{\pi \ln(2)}{8}","EDIT After a long search, it seems that the solution is related to Jacobi elliptical functions. For instance, if we try using this itegral representation $$\boxed{\frac{1}{m^2+ n^2}=\int_{0}^{\infty}e^{-(m^2+n^2)t}dt}$$ We end up with sums of the following form, which as far as I found, are related to Jacobi elliptical functions. $$\sum_{m=1}^{\infty}e^{-m^2t}$$ Another strategy would be starting with the following identity $$\boxed{\sum_{n=1}^{\infty}\frac{(-1)^n}{m^2+n^2}=\frac{\pi \mathrm{csch}(\pi m)}{2m}-\frac{1}{2m^2}}$$ Also leads to evaluate a sum of the form below, which also belongs to the elliptical functions family $$\sum_{m=1}^{\infty}\frac{1}{m \sinh(\pi m)}$$ Even the infinite product $$\prod_{k=1}^{\infty} \Big(1+e^{-\pi k2} \Big)$$ seems to be related to these special functions! First attempt $$\boxed{\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}\frac{(-1)^{n-1}}{n^2+m^2}=\frac{\pi^2}{24}+\frac{\pi \ln(2)}{8}}$$ Consider $$S=\sum_{n,m=1}^{\infty}\frac{(-1)^{n-1}}{n^2+m^2}$$ $$S=-\sum_{n=1}^{\infty}(-1)^n\sum_{m=1}^{\infty}\frac{1}{n^2+m^2}$$ Recall $$\boxed{\sum_{m=1}^{\infty}\frac{1}{n^2+m^2}=\frac{\pi \coth(\pi n)}{2n}-\frac{1}{2n^2}}$$ $$S=-\sum_{n=1}^{\infty}(-1)^n\frac{\pi \coth(\pi n)}{2n}-\frac{1}{2}\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n^2}$$ $$S=-\frac{\pi}{2}\sum_{n=1}^{\infty}(-1)^n\frac{ \coth(\pi n)}{n}-\frac{\pi^2}{24}$$ Also $$\boxed{\coth(\pi n)-1=\frac{2}{e^{2 \pi n}-1}}$$ $$S=-\frac{\pi}{2}\sum_{n=1}^{\infty}\frac{(-1)^n}{n} \bigg\{\frac{2}{e^{2 \pi n}-1}+1 \bigg\}-\frac{\pi^2}{24}$$ $$S=-{\pi}\sum_{n=1}^{\infty}\frac{(-1)^n}{n} \bigg\{\frac{1}{e^{2 \pi n}-1}\bigg\}-\frac{\pi}{2}\sum_{n=1}^{\infty}\frac{(-1)^n}{n}-\frac{\pi^2}{24}$$ $$S=-{\pi}\sum_{n=1}^{\infty}\frac{(-1)^n}{n} \bigg\{\frac{1}{e^{2 \pi n}-1}\bigg\}+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ $$S=-{\pi}\sum_{n=1}^{\infty}\frac{(-1)^ne^{-2 \pi n}}{n}\sum_{k=0}^{\infty}e^{-2 \pi n k} +\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ $$S=-\pi\sum_{k=0}^{\infty}\sum_{n=1}^{\infty}\frac{(-1)^ne^{-2 \pi n(k+1)}}{n}+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ $$S=\pi\sum_{k=1}^{\infty}\ln(1+e^{-2\pi k})+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ $$S=\pi\ln(\prod_{k=1}^{\infty}1+\big(e^{-\pi k}\big)^2)+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24}$$ From this point on, I cant finish. Any help is welcome. Second attempt I tried the method suggest bellow by @NoName, but I still missing one factor $\frac{1}{4}$ before the $\log(2)$ . I suspect that this method fails because $\sum_{m=1}^{\infty}\frac{1}{m}\sin(mt)=\frac{\pi}{2}-\frac{t}{2}$ is only valid betweem $0$ and $2 \pi$ . $$S=\sum_{n=1}^{\infty}(-1)^{n+1}\sum_{m=1}^{\infty}\frac{1}{n^2+m^2}$$ rewrite $$\frac{1}{n^2+m^2}=\frac{1}{m}\int_{0}^{\infty}\sin(mt)e^{-nt}dt$$ $$S=\sum_{n=1}^{\infty}(-1)^{n+1}\sum_{m=1}^{\infty}\frac{1}{m}\int_{0}^{\infty}\sin(mt)e^{-nt}dt$$ $$S=\int_{0}^{\infty}\sum_{n=1}^{\infty}(-1)^{n+1}e^{-nt} \Big\{\sum_{m=1}^{\infty}\frac{1}{m}\sin(mt) \Big \}dt$$ $$S=\int_{0}^{\infty}\sum_{n=1}^{\infty}(-1)^{n+1}e^{-nt} \Big\{ \frac{\pi}{2}-\frac{t}{2} \Big \}dt$$ $$S=\sum_{n=1}^{\infty}(-1)^{n+1}\int_{0}^{\infty}e^{-nt} \Big\{ \frac{\pi}{2}-\frac{t}{2} \Big \}dt$$ $$S=\sum_{n=1}^{\infty}(-1)^{n+1} \Big\{ \frac{\pi}{2n}-\frac{1}{2n^2}\Big \}$$ $$S=\frac{\pi}{2}\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}-\frac{1}{2}\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^2}$$ $$S=\frac{\pi \log(2)}{2}+ \frac{\pi^2}{24}$$","EDIT After a long search, it seems that the solution is related to Jacobi elliptical functions. For instance, if we try using this itegral representation We end up with sums of the following form, which as far as I found, are related to Jacobi elliptical functions. Another strategy would be starting with the following identity Also leads to evaluate a sum of the form below, which also belongs to the elliptical functions family Even the infinite product seems to be related to these special functions! First attempt Consider Recall Also From this point on, I cant finish. Any help is welcome. Second attempt I tried the method suggest bellow by @NoName, but I still missing one factor before the . I suspect that this method fails because is only valid betweem and . rewrite","\boxed{\frac{1}{m^2+ n^2}=\int_{0}^{\infty}e^{-(m^2+n^2)t}dt} \sum_{m=1}^{\infty}e^{-m^2t} \boxed{\sum_{n=1}^{\infty}\frac{(-1)^n}{m^2+n^2}=\frac{\pi \mathrm{csch}(\pi m)}{2m}-\frac{1}{2m^2}} \sum_{m=1}^{\infty}\frac{1}{m \sinh(\pi m)} \prod_{k=1}^{\infty} \Big(1+e^{-\pi k2} \Big) \boxed{\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}\frac{(-1)^{n-1}}{n^2+m^2}=\frac{\pi^2}{24}+\frac{\pi \ln(2)}{8}} S=\sum_{n,m=1}^{\infty}\frac{(-1)^{n-1}}{n^2+m^2} S=-\sum_{n=1}^{\infty}(-1)^n\sum_{m=1}^{\infty}\frac{1}{n^2+m^2} \boxed{\sum_{m=1}^{\infty}\frac{1}{n^2+m^2}=\frac{\pi \coth(\pi n)}{2n}-\frac{1}{2n^2}} S=-\sum_{n=1}^{\infty}(-1)^n\frac{\pi \coth(\pi n)}{2n}-\frac{1}{2}\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n^2} S=-\frac{\pi}{2}\sum_{n=1}^{\infty}(-1)^n\frac{ \coth(\pi n)}{n}-\frac{\pi^2}{24} \boxed{\coth(\pi n)-1=\frac{2}{e^{2 \pi n}-1}} S=-\frac{\pi}{2}\sum_{n=1}^{\infty}\frac{(-1)^n}{n} \bigg\{\frac{2}{e^{2 \pi n}-1}+1 \bigg\}-\frac{\pi^2}{24} S=-{\pi}\sum_{n=1}^{\infty}\frac{(-1)^n}{n} \bigg\{\frac{1}{e^{2 \pi n}-1}\bigg\}-\frac{\pi}{2}\sum_{n=1}^{\infty}\frac{(-1)^n}{n}-\frac{\pi^2}{24} S=-{\pi}\sum_{n=1}^{\infty}\frac{(-1)^n}{n} \bigg\{\frac{1}{e^{2 \pi n}-1}\bigg\}+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24} S=-{\pi}\sum_{n=1}^{\infty}\frac{(-1)^ne^{-2 \pi n}}{n}\sum_{k=0}^{\infty}e^{-2 \pi n k} +\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24} S=-\pi\sum_{k=0}^{\infty}\sum_{n=1}^{\infty}\frac{(-1)^ne^{-2 \pi n(k+1)}}{n}+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24} S=\pi\sum_{k=1}^{\infty}\ln(1+e^{-2\pi k})+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24} S=\pi\ln(\prod_{k=1}^{\infty}1+\big(e^{-\pi k}\big)^2)+\frac{\pi \ln(2)}{2}-\frac{\pi^2}{24} \frac{1}{4} \log(2) \sum_{m=1}^{\infty}\frac{1}{m}\sin(mt)=\frac{\pi}{2}-\frac{t}{2} 0 2 \pi S=\sum_{n=1}^{\infty}(-1)^{n+1}\sum_{m=1}^{\infty}\frac{1}{n^2+m^2} \frac{1}{n^2+m^2}=\frac{1}{m}\int_{0}^{\infty}\sin(mt)e^{-nt}dt S=\sum_{n=1}^{\infty}(-1)^{n+1}\sum_{m=1}^{\infty}\frac{1}{m}\int_{0}^{\infty}\sin(mt)e^{-nt}dt S=\int_{0}^{\infty}\sum_{n=1}^{\infty}(-1)^{n+1}e^{-nt} \Big\{\sum_{m=1}^{\infty}\frac{1}{m}\sin(mt) \Big \}dt S=\int_{0}^{\infty}\sum_{n=1}^{\infty}(-1)^{n+1}e^{-nt} \Big\{ \frac{\pi}{2}-\frac{t}{2} \Big \}dt S=\sum_{n=1}^{\infty}(-1)^{n+1}\int_{0}^{\infty}e^{-nt} \Big\{ \frac{\pi}{2}-\frac{t}{2} \Big \}dt S=\sum_{n=1}^{\infty}(-1)^{n+1} \Big\{ \frac{\pi}{2n}-\frac{1}{2n^2}\Big \} S=\frac{\pi}{2}\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}-\frac{1}{2}\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^2} S=\frac{\pi \log(2)}{2}+ \frac{\pi^2}{24}","['integration', 'sequences-and-series']"
74,Formula for $\int_0^\infty \frac{\log(1+x^2)}{\sqrt{(a^2+x^2)(b^2+x^2)}}dx$,Formula for,\int_0^\infty \frac{\log(1+x^2)}{\sqrt{(a^2+x^2)(b^2+x^2)}}dx,"Is it possible to express the following integral in terms of known special functions? $$I(a,b)=\int_0^\infty \frac{\log(1+x^2)}{\sqrt{(a^2+x^2)(b^2+x^2)}}dx$$ I have managed to solve the special case when $b=1$ and $a>1$. $$I(a,1)=\frac{\pi}{2a}K\left(\frac{1}{a} \right)+\frac{\log(a^2-1)}{2a}K\left( \sqrt{1-\frac{1}{a^2}}\right) $$ where $K(k)$ is the complete elliptic integral of the first kind . (Please refer to this answer for it's derivation) Unfortunately, I was not able to solve any other case. Is it possible to express $I(a,b)$ in terms of complete elliptic integrals? Update Using the substitution $x\mapsto1/x$, it can be shown that $$I(a,b)=\frac{1}{ab}I\left(\frac{1}{a},\frac{1}{b}\right)+\frac{\log(ab)}{b}K\left( \frac{\sqrt{b^2-a^2}}{b}\right) \quad b>a$$","Is it possible to express the following integral in terms of known special functions? $$I(a,b)=\int_0^\infty \frac{\log(1+x^2)}{\sqrt{(a^2+x^2)(b^2+x^2)}}dx$$ I have managed to solve the special case when $b=1$ and $a>1$. $$I(a,1)=\frac{\pi}{2a}K\left(\frac{1}{a} \right)+\frac{\log(a^2-1)}{2a}K\left( \sqrt{1-\frac{1}{a^2}}\right) $$ where $K(k)$ is the complete elliptic integral of the first kind . (Please refer to this answer for it's derivation) Unfortunately, I was not able to solve any other case. Is it possible to express $I(a,b)$ in terms of complete elliptic integrals? Update Using the substitution $x\mapsto1/x$, it can be shown that $$I(a,b)=\frac{1}{ab}I\left(\frac{1}{a},\frac{1}{b}\right)+\frac{\log(ab)}{b}K\left( \frac{\sqrt{b^2-a^2}}{b}\right) \quad b>a$$",,"['integration', 'analysis', 'definite-integrals', 'closed-form', 'elliptic-integrals']"
75,How to prove $\int_0^1x\ln^2(1+x)\ln(\frac{x^2}{1+x})\frac{dx}{1+x^2}$,How to prove,\int_0^1x\ln^2(1+x)\ln(\frac{x^2}{1+x})\frac{dx}{1+x^2},"How to prove $$\int_0^1x\ln^2(1+x)\ln\left(\frac{x^2}{1+x}\right)\frac{dx}{1+x^2}=-\frac{7}{32}\cdot\zeta{(3)}\ln2+\frac{3\pi^2}{128}\cdot\ln^22-\frac{1}{64}\cdot\ln^42-\frac{13\pi^4}{46080}$$ The substitution $$x=\frac{1-y}{1+y}$$ leads to calculate the integrals that are unknown: $$\int_0^1y\ln(1-y)\ln^2(1+y)\frac{dy}{1+y^2}, \int_0^1\frac{y\ln^3(1+y)}{1+y^2}dy$$ For the moment,I do not see how to calculate this integral.","How to prove The substitution leads to calculate the integrals that are unknown: For the moment,I do not see how to calculate this integral.","\int_0^1x\ln^2(1+x)\ln\left(\frac{x^2}{1+x}\right)\frac{dx}{1+x^2}=-\frac{7}{32}\cdot\zeta{(3)}\ln2+\frac{3\pi^2}{128}\cdot\ln^22-\frac{1}{64}\cdot\ln^42-\frac{13\pi^4}{46080} x=\frac{1-y}{1+y} \int_0^1y\ln(1-y)\ln^2(1+y)\frac{dy}{1+y^2}, \int_0^1\frac{y\ln^3(1+y)}{1+y^2}dy","['integration', 'definite-integrals', 'polylogarithm']"
76,"Interesing, hard limit with sum, involving $\pi$","Interesing, hard limit with sum, involving",\pi,"Yesterday I was boring so I decided to derive formula for area of circle with integrals. Very good exercise, I think, because I forgot many, many things about integrals. So I started with: $$\int_{-r}^{r} \sqrt{r^2-x^2}dx$$ but I didn't have any clue how to count indefinite integral $\int\sqrt{r^2-x^2}dx$ (is it even possible? today I only found method for counting definite integral above with trigonometric substitution, but this does not apply in general), so I decided to use Riemann's theorem, since I only need to count definite integral. And everything was going well, till something extremely interesting happend. The last step I need to do is to find this limit: $$\lim_{n \to +\infty}\frac{1}{n}\sum_{k=1}^{n}\sqrt{\frac{k}{n}\cdot\frac{n-k}{n}}$$ Surprisingly it is equal to $\frac{\pi}{8}$, and it is mindblowing ;-) but I only know that because I know formula for area of circle which I'm trying to derive. But without knowing it, is it possible to calculate this limit with relatively simple methods? I really, really want to to this in order to award my attempts. Can anybody help?","Yesterday I was boring so I decided to derive formula for area of circle with integrals. Very good exercise, I think, because I forgot many, many things about integrals. So I started with: $$\int_{-r}^{r} \sqrt{r^2-x^2}dx$$ but I didn't have any clue how to count indefinite integral $\int\sqrt{r^2-x^2}dx$ (is it even possible? today I only found method for counting definite integral above with trigonometric substitution, but this does not apply in general), so I decided to use Riemann's theorem, since I only need to count definite integral. And everything was going well, till something extremely interesting happend. The last step I need to do is to find this limit: $$\lim_{n \to +\infty}\frac{1}{n}\sum_{k=1}^{n}\sqrt{\frac{k}{n}\cdot\frac{n-k}{n}}$$ Surprisingly it is equal to $\frac{\pi}{8}$, and it is mindblowing ;-) but I only know that because I know formula for area of circle which I'm trying to derive. But without knowing it, is it possible to calculate this limit with relatively simple methods? I really, really want to to this in order to award my attempts. Can anybody help?",,"['integration', 'limits']"
77,"Complex analysis - Finding $\int_0^\infty \frac{x\cos\left(\frac{1}{x^2}\right)}{x^4 + 4}\,dx$",Complex analysis - Finding,"\int_0^\infty \frac{x\cos\left(\frac{1}{x^2}\right)}{x^4 + 4}\,dx","I want to use complex analysis to solve this integral: $$ I = \int_0^\infty \frac{x\cos\left(\frac{1}{x^2}\right)}{x^4 + 4}\,dx$$ I'm having trouble because I get two different results with two different methods. First of all, I applied the change of variables $\displaystyle y = \frac{2}{x^2}$ to get that $\displaystyle I = \frac{1}{4} \int_0^\infty \frac{\cos(\frac{y}{2})}{y^2 + 1}dy = \frac{1}{4} \Re \left( \int_0^\infty \frac{e^{iy/2}}{y^2 + 1}dy \right)$ which is a well known integral and is equal to $\displaystyle \frac{\pi}{2\sqrt e}$ . So $\displaystyle I = \frac{\pi}{8\sqrt e}$ . This is the correct result. (For those who don't know, the integral can be solved using Feynman's Trick or Jordan's Lemma with a suitable contour in the upper half plane.) Now, let's say that I want to solve the integral without making any change of variables or others tricks. I just want to solve it using the residue theorem with a quarter of circle of radius $\displaystyle R \to \infty$ and center $\displaystyle C = (0,0)$ in the first quadrant as a contour. Let's call this contour $\displaystyle \gamma$ . So I want to find $\displaystyle J =\oint_\gamma \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz$ and how it is related to I. Let's find J. $\displaystyle J =\int_0^\infty \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz + \int_{Arc} \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz + \int_{i\infty}^{i0} \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz$ , where Arc is parametrized by $\displaystyle z(\theta) = R e^{i\theta}$ for $\displaystyle \theta \in \left [0,\frac{\pi}{2} \right]$ . The first integral is obviously I and so is the third ( use the change of variables $\displaystyle z \to -iz$ ). Let's call the second integral $\displaystyle I_{Arc}$ . EDIT: After a comment I decided to work on the third piece: $\displaystyle Q = \int_{i\infty}^{i0} \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz$ using the change of variables $\displaystyle q = -iz$ $\displaystyle Q = \int_{\infty}^{0} \frac{iq\cos\left(\frac{1}{(iq)^2}\right)}{(iq)^4 + 4}idq = -\int_{\infty}^{0} \frac{q\cos\left(\frac{-1}{q^2}\right)}{(iq)^4 + 4}dq = \int_{0}^{\infty} \frac{q\cos\left(\frac{1}{q^2}\right)}{q^4 + 4}dq = I $ Now, I would like to show that $\displaystyle I_{Arc} \to 0$ as $\displaystyle R \to \infty$ . $\displaystyle \mid I_{Arc} \mid = \left| \int_0^{\frac{\pi}{2}} \frac{R e^{i\theta} \cos\left(\frac{1}{R^2 e^{i2\theta}}\right)}{R^4 e^{i4\theta} + 4} R e^{i\theta} i d\theta \right| \leq \int_0^{\frac{\pi}{2}} \left|  \frac{R^2 \cos\left(\frac{1}{R^2 e^{i2\theta}}\right)}{R^4 e^{i4\theta} + 4} \right| d\theta \leq \frac{3R^2}{R^3} \int_0^{\frac{\pi}{2}} d\theta = \frac{1}{R}\frac{3\pi}{2} \to 0$ as $\displaystyle R \to \infty$ Where I used: $\displaystyle \left| \cos\left(\frac{1}{R^2 e^{i2\theta}}\right) \right| =  \left| \frac{ \exp\left(\frac{i\cos(2\theta) + \sin(2\theta)}{R^2} \right) + \exp\left(\frac{-i\cos(2\theta) - \sin(2\theta)}{R^2} \right) }{2} \right| \leq \left| \frac{ \exp\left(\frac{\sin(2\theta)}{R^2} \right)}{2} \right| + \left| \frac{ \exp\left(\frac{-\sin(2\theta)}{R^2} \right)}{2} \right| \leq \exp\left(\frac{\sin(2\theta)}{R^2} \right) \leq 3$ since R is definitely bigger than 1. Also $\displaystyle \mid R^4e^{i4\theta} + 4 \mid = \sqrt{(R^4\cos4\theta + 4)^2 + R^4\sin^24\theta} = \sqrt{R^8 + 16 + 8R^4\cos4\theta} \ge \sqrt{R^8 + 8R^4\cos4\theta} \ge \sqrt{R^8 - 8R^4} \ge R^3$ . Which is true if $\displaystyle R >> 1$ . So I changed how I bounded $\displaystyle  \mid I_{Arc} \mid$ So, it stands to reason that $\displaystyle J = 2I$ and $\displaystyle J = 2\pi i \sum\operatorname{Res}(f,z_k)$ , but the only pole inside the region bounded by $\displaystyle \gamma $ is $\displaystyle z = 1 + i$ , so after some algebra, one can find that $\displaystyle J = \frac{\pi}{8}\cosh\frac{1}{2}$ . So, $\displaystyle I = \frac{\pi}{8} \left(\sqrt{e} + \frac{1}{\sqrt{e}} \right)$ . What I am doing wrong? (I know that I may have written too much, but please don't bash me too harshly, this is my first time writing a question). EDIT: For those who don't want to read the comments. $\displaystyle z = 0$ is an essential singularity, so as the singularity is on the contour I need to make a detour around $\displaystyle z = 0$ . For example I can use the path parametrized by $\displaystyle \sigma(\theta) = \epsilon e^{i\theta}$ for $\displaystyle \theta \in \left[0,\frac{\pi}{2}\right]$ and $\displaystyle \epsilon << 1$ which contributes to the value of $\displaystyle J$ . But, now the curve is oriented clock-wise. So, $\displaystyle J = 2I + $ this contribution. After I calculate this contribution I will edit the question again. Final EDIT ( I suppose ): Calculating this contribution is just like calculating manually $I_{Arc}$ but in the limit of $R \to 0$ , I also suppose that this is not analytically doable, I guess that a simple Monte Carlo Integration technique could help. Anyway, this contribution should make things work. The moral of the story is to trust in the power of analysis and to do things in a smart way just like I did in the first part of this question.","I want to use complex analysis to solve this integral: I'm having trouble because I get two different results with two different methods. First of all, I applied the change of variables to get that which is a well known integral and is equal to . So . This is the correct result. (For those who don't know, the integral can be solved using Feynman's Trick or Jordan's Lemma with a suitable contour in the upper half plane.) Now, let's say that I want to solve the integral without making any change of variables or others tricks. I just want to solve it using the residue theorem with a quarter of circle of radius and center in the first quadrant as a contour. Let's call this contour . So I want to find and how it is related to I. Let's find J. , where Arc is parametrized by for . The first integral is obviously I and so is the third ( use the change of variables ). Let's call the second integral . EDIT: After a comment I decided to work on the third piece: using the change of variables Now, I would like to show that as . as Where I used: since R is definitely bigger than 1. Also . Which is true if . So I changed how I bounded So, it stands to reason that and , but the only pole inside the region bounded by is , so after some algebra, one can find that . So, . What I am doing wrong? (I know that I may have written too much, but please don't bash me too harshly, this is my first time writing a question). EDIT: For those who don't want to read the comments. is an essential singularity, so as the singularity is on the contour I need to make a detour around . For example I can use the path parametrized by for and which contributes to the value of . But, now the curve is oriented clock-wise. So, this contribution. After I calculate this contribution I will edit the question again. Final EDIT ( I suppose ): Calculating this contribution is just like calculating manually but in the limit of , I also suppose that this is not analytically doable, I guess that a simple Monte Carlo Integration technique could help. Anyway, this contribution should make things work. The moral of the story is to trust in the power of analysis and to do things in a smart way just like I did in the first part of this question."," I = \int_0^\infty \frac{x\cos\left(\frac{1}{x^2}\right)}{x^4 + 4}\,dx \displaystyle y = \frac{2}{x^2} \displaystyle I = \frac{1}{4} \int_0^\infty \frac{\cos(\frac{y}{2})}{y^2 + 1}dy = \frac{1}{4} \Re \left( \int_0^\infty \frac{e^{iy/2}}{y^2 + 1}dy \right) \displaystyle \frac{\pi}{2\sqrt e} \displaystyle I = \frac{\pi}{8\sqrt e} \displaystyle R \to \infty \displaystyle C = (0,0) \displaystyle \gamma \displaystyle J =\oint_\gamma \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz \displaystyle J =\int_0^\infty \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz + \int_{Arc} \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz + \int_{i\infty}^{i0} \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz \displaystyle z(\theta) = R e^{i\theta} \displaystyle \theta \in \left [0,\frac{\pi}{2} \right] \displaystyle z \to -iz \displaystyle I_{Arc} \displaystyle Q = \int_{i\infty}^{i0} \frac{z\cos(\frac{1}{z^2})}{z^4 + 4}dz \displaystyle q = -iz \displaystyle Q = \int_{\infty}^{0} \frac{iq\cos\left(\frac{1}{(iq)^2}\right)}{(iq)^4 + 4}idq = -\int_{\infty}^{0} \frac{q\cos\left(\frac{-1}{q^2}\right)}{(iq)^4 + 4}dq = \int_{0}^{\infty} \frac{q\cos\left(\frac{1}{q^2}\right)}{q^4 + 4}dq = I  \displaystyle I_{Arc} \to 0 \displaystyle R \to \infty \displaystyle \mid I_{Arc} \mid = \left| \int_0^{\frac{\pi}{2}} \frac{R e^{i\theta} \cos\left(\frac{1}{R^2 e^{i2\theta}}\right)}{R^4 e^{i4\theta} + 4} R e^{i\theta} i d\theta \right| \leq
\int_0^{\frac{\pi}{2}} \left|  \frac{R^2 \cos\left(\frac{1}{R^2 e^{i2\theta}}\right)}{R^4 e^{i4\theta} + 4} \right| d\theta \leq \frac{3R^2}{R^3} \int_0^{\frac{\pi}{2}} d\theta = \frac{1}{R}\frac{3\pi}{2} \to 0 \displaystyle R \to \infty \displaystyle \left| \cos\left(\frac{1}{R^2 e^{i2\theta}}\right) \right| = 
\left| \frac{ \exp\left(\frac{i\cos(2\theta) + \sin(2\theta)}{R^2} \right) + \exp\left(\frac{-i\cos(2\theta) - \sin(2\theta)}{R^2} \right) }{2} \right| \leq
\left| \frac{ \exp\left(\frac{\sin(2\theta)}{R^2} \right)}{2} \right| + \left| \frac{ \exp\left(\frac{-\sin(2\theta)}{R^2} \right)}{2} \right| \leq \exp\left(\frac{\sin(2\theta)}{R^2} \right) \leq 3 \displaystyle \mid R^4e^{i4\theta} + 4 \mid = \sqrt{(R^4\cos4\theta + 4)^2 + R^4\sin^24\theta} = \sqrt{R^8 + 16 + 8R^4\cos4\theta} \ge \sqrt{R^8 + 8R^4\cos4\theta} \ge \sqrt{R^8 - 8R^4} \ge R^3 \displaystyle R >> 1 \displaystyle  \mid I_{Arc} \mid \displaystyle J = 2I \displaystyle J = 2\pi i \sum\operatorname{Res}(f,z_k) \displaystyle \gamma  \displaystyle z = 1 + i \displaystyle J = \frac{\pi}{8}\cosh\frac{1}{2} \displaystyle I = \frac{\pi}{8} \left(\sqrt{e} + \frac{1}{\sqrt{e}} \right) \displaystyle z = 0 \displaystyle z = 0 \displaystyle \sigma(\theta) = \epsilon e^{i\theta} \displaystyle \theta \in \left[0,\frac{\pi}{2}\right] \displaystyle \epsilon << 1 \displaystyle J \displaystyle J = 2I +  I_{Arc} R \to 0","['integration', 'complex-analysis', 'contour-integration']"
78,What is the integral of $e^{a \cdot x+b \cdot y}$ evaluated over the Koch Curve,What is the integral of  evaluated over the Koch Curve,e^{a \cdot x+b \cdot y},"What is  $$\int_{K} e^{a \cdot x+ b \cdot y} \mu(x,y)$$ where $K$ is the Koch curve and $\mu(x,y)$ is a uniform measure look here . Attempt: I can evaluate the integral numerically and I have derived a method to integrate $e^x$ over some cantor sets, look here . When I tried using that method to integrate the Koch Curve, I end up unable to express the integral in direct terms of its self. Here's a proof that integration can be done over the Koch Curve... Information: I'd like a symbolic answer if its available, but infinite series/products for this integral are great too. If there's a reference that actually handles this specific function over fractals and derives a symbolic result, that's good to. Also feel free to change $K$ to any other (non-trivial of course ;) ) variant of the Koch curve if that makes it easier to compute. I warn only that because the goal is to integrate over any fractal rather than just one or two special examples, you shouldn't pick needlessly trivial examples... Motivation: The derivation of this result allows for integration over a fractal, however the actual reason this is useful, is because of the usefulness of the exponential function. For instance, the concept of average temperature over a fractal is a very interesting concept. $e^x$ type functions allow for rudimentary temperature fields to be constructed and theoretically integrated over fractals. $e^x$ type functions are useful for many kinds of problems, but they seem to be difficult to integrate over fractals. In addition, developing a theory for integrals over fractals, requires a large library of results, and $e^x$ should definitely be included in that list of integrable functions.","What is  $$\int_{K} e^{a \cdot x+ b \cdot y} \mu(x,y)$$ where $K$ is the Koch curve and $\mu(x,y)$ is a uniform measure look here . Attempt: I can evaluate the integral numerically and I have derived a method to integrate $e^x$ over some cantor sets, look here . When I tried using that method to integrate the Koch Curve, I end up unable to express the integral in direct terms of its self. Here's a proof that integration can be done over the Koch Curve... Information: I'd like a symbolic answer if its available, but infinite series/products for this integral are great too. If there's a reference that actually handles this specific function over fractals and derives a symbolic result, that's good to. Also feel free to change $K$ to any other (non-trivial of course ;) ) variant of the Koch curve if that makes it easier to compute. I warn only that because the goal is to integrate over any fractal rather than just one or two special examples, you shouldn't pick needlessly trivial examples... Motivation: The derivation of this result allows for integration over a fractal, however the actual reason this is useful, is because of the usefulness of the exponential function. For instance, the concept of average temperature over a fractal is a very interesting concept. $e^x$ type functions allow for rudimentary temperature fields to be constructed and theoretically integrated over fractals. $e^x$ type functions are useful for many kinds of problems, but they seem to be difficult to integrate over fractals. In addition, developing a theory for integrals over fractals, requires a large library of results, and $e^x$ should definitely be included in that list of integrable functions.",,"['integration', 'measure-theory', 'recurrence-relations', 'fractal-analysis']"
79,A generalization of an integral related with $\zeta(2)$,A generalization of an integral related with,\zeta(2),"It is well-known that: $$ \int_{0}^{+\infty}\frac{x}{e^{x}-1}\,dx = \zeta(2) = \sum_{n\geq 1}\frac{1}{n^2} \tag{1}$$ but what is known about   $$ I_2 = \int_{0}^{+\infty}\frac{x^2}{e^x-1-x}\,dx \tag{2} $$   or   $$ I_n = \int_{0}^{+\infty}\frac{x^n}{e^x-\sum\limits_{k=0}^{n-1}\frac{x^k}{k!}}\,dx \tag{3}$$   ? They seem pretty hard to tackle through the usual geometric series approach or the residue theorem, but it would be interesting to find some sharp bounds, too. An approximation that came to my mind is, for instance: $$ I_n \approx \int_{0}^{+\infty} n! e^{-\frac{z}{n+1}}\,dz = (n+1)!$$ but it does not seem so tight. A better approximation is: $$ \exp\left(-\frac{x}{n+1}-\frac{x^2}{2(n+1)^2}\right)\leq \frac{\frac{x^n}{n!}}{\sum_{m>n}\frac{x^m}{m!}}\leq\exp\left(-\frac{x}{n+1}-\frac{nx^2} {2(n+1)^2(n+2)}\right)$$ but that just improves the previous approximation by a constant factor. The previous inequality has a nice side effect. From $\frac{x}{e^x-1}\approx\exp\left(-\frac{x}{2}-\frac{x^2}{24}\right)$ it follows that: $$ \int_{0}^{+\infty}\left(-\frac{1}{2}-\frac{x}{12}\right)\frac{x}{e^x-1}\,dx \approx \int_{0}^{+\infty}\left(-\frac{1}{2}-\frac{x}{12}\right)\exp\left(-\frac{x}{2}-\frac{x^2}{24}\right)\,dx = -1,$$ or: $$ \frac{\zeta(2)}{2!}+\frac{\zeta(3)}{3!}\approx 1.$$","It is well-known that: $$ \int_{0}^{+\infty}\frac{x}{e^{x}-1}\,dx = \zeta(2) = \sum_{n\geq 1}\frac{1}{n^2} \tag{1}$$ but what is known about   $$ I_2 = \int_{0}^{+\infty}\frac{x^2}{e^x-1-x}\,dx \tag{2} $$   or   $$ I_n = \int_{0}^{+\infty}\frac{x^n}{e^x-\sum\limits_{k=0}^{n-1}\frac{x^k}{k!}}\,dx \tag{3}$$   ? They seem pretty hard to tackle through the usual geometric series approach or the residue theorem, but it would be interesting to find some sharp bounds, too. An approximation that came to my mind is, for instance: $$ I_n \approx \int_{0}^{+\infty} n! e^{-\frac{z}{n+1}}\,dz = (n+1)!$$ but it does not seem so tight. A better approximation is: $$ \exp\left(-\frac{x}{n+1}-\frac{x^2}{2(n+1)^2}\right)\leq \frac{\frac{x^n}{n!}}{\sum_{m>n}\frac{x^m}{m!}}\leq\exp\left(-\frac{x}{n+1}-\frac{nx^2} {2(n+1)^2(n+2)}\right)$$ but that just improves the previous approximation by a constant factor. The previous inequality has a nice side effect. From $\frac{x}{e^x-1}\approx\exp\left(-\frac{x}{2}-\frac{x^2}{24}\right)$ it follows that: $$ \int_{0}^{+\infty}\left(-\frac{1}{2}-\frac{x}{12}\right)\frac{x}{e^x-1}\,dx \approx \int_{0}^{+\infty}\left(-\frac{1}{2}-\frac{x}{12}\right)\exp\left(-\frac{x}{2}-\frac{x^2}{24}\right)\,dx = -1,$$ or: $$ \frac{\zeta(2)}{2!}+\frac{\zeta(3)}{3!}\approx 1.$$",,"['integration', 'riemann-zeta', 'approximation-theory']"
80,Finding the Center of Mass of a disk when a part of it is cut out.,Finding the Center of Mass of a disk when a part of it is cut out.,,"From a uniform disk of radius $R$ a circular disk of radius $\frac{R}{2}$ is being cut out. The center of the ""cut out"" disk is at $R/2$ from the venter of the original disk. We have to find the center of mass of leftover body. I thought that we should set up a coordinate system with the center of original disk as the origin. The formula for center of mass is $$ \vec{R}_{CM} = \frac{1}{M_{tot}} \int \vec{r} ~dm$$ I thought of creating another identical region (identical to what is being cut out) on the left of $O$ . Like this By symmetry, any position vector $\vec{r}$ outside the encircled region (on the left) will have it's counter-part and hence it will cancel up. So, we need to worry only about the integral inside the circular region, even there by symmetry we know that $\vec{R}_{CM}$ will lie on the axis joining their centers (let's call the line joining all three centers as $x$ -axis and the line perpendicular to this line as $y$ -axis). If we use the polar coordinate then we have $$ R_{CM} = \frac{1}{M_{tot}} 2\int \int r \cos \theta \sigma   dA\\ \text{(I have written $2r\cos \theta$ because that's the thing we would get when we add any two}\\  \text{vectors in that encircled region, $\sigma$ is the mass per unit area, and $dA$ is the area element)}\\ R_{CM} = \frac{1}{M_{tot}}2 \sigma \int_{r=0}^{R} \int_{\theta=0} r \cos \theta ~dA $$ But the problem is that I don't know the upper limit of $\theta$ , I worked hard but it seemed a little different in this case. We can use our ordinary cartesian system, $$ R_{CM} = \frac{1}{M_{tot}} 2\sigma \int \int x dx dy$$ the limit of $x$ will be (I think) $0$ to $R$ and we can get $y$ as $$ (x-R/2)^2 + y^2 = R^2/4 \\ y= \sqrt{ x^2 - Rx}$$ So, we have $$ R_{CM} = \frac{1}{M_{tot}} 2\sigma \int_{x=0}^{R} \int_{y=0}^{\sqrt{x^2-Rx}} x dy dx\\ R_{CM} = \frac{1}{M_{tot}} 2\sigma \int_{x=0}^{R} x\sqrt{x^2-Rx} ~dx $$ I don't know how to carry out that last integral. The answer to this question is "" $R/6$ to the left of O"" but where am I mistaking? Can someone help me out?","From a uniform disk of radius a circular disk of radius is being cut out. The center of the ""cut out"" disk is at from the venter of the original disk. We have to find the center of mass of leftover body. I thought that we should set up a coordinate system with the center of original disk as the origin. The formula for center of mass is I thought of creating another identical region (identical to what is being cut out) on the left of . Like this By symmetry, any position vector outside the encircled region (on the left) will have it's counter-part and hence it will cancel up. So, we need to worry only about the integral inside the circular region, even there by symmetry we know that will lie on the axis joining their centers (let's call the line joining all three centers as -axis and the line perpendicular to this line as -axis). If we use the polar coordinate then we have But the problem is that I don't know the upper limit of , I worked hard but it seemed a little different in this case. We can use our ordinary cartesian system, the limit of will be (I think) to and we can get as So, we have I don't know how to carry out that last integral. The answer to this question is "" to the left of O"" but where am I mistaking? Can someone help me out?","R \frac{R}{2} R/2 
\vec{R}_{CM} = \frac{1}{M_{tot}} \int \vec{r} ~dm O \vec{r} \vec{R}_{CM} x y 
R_{CM} = \frac{1}{M_{tot}} 2\int \int r \cos \theta \sigma   dA\\
\text{(I have written 2r\cos \theta because that's the thing we would get when we add any two}\\
 \text{vectors in that encircled region, \sigma is the mass per unit area, and dA is the area element)}\\
R_{CM} = \frac{1}{M_{tot}}2 \sigma \int_{r=0}^{R} \int_{\theta=0} r \cos \theta ~dA
 \theta 
R_{CM} = \frac{1}{M_{tot}} 2\sigma \int \int x dx dy x 0 R y 
(x-R/2)^2 + y^2 = R^2/4 \\
y= \sqrt{ x^2 - Rx} 
R_{CM} = \frac{1}{M_{tot}} 2\sigma \int_{x=0}^{R} \int_{y=0}^{\sqrt{x^2-Rx}} x dy dx\\
R_{CM} = \frac{1}{M_{tot}} 2\sigma \int_{x=0}^{R} x\sqrt{x^2-Rx} ~dx
 R/6","['integration', 'multivariable-calculus', 'physics', 'multiple-integral']"
81,"Why does the ""separation of variables"" method for DEs work? [duplicate]","Why does the ""separation of variables"" method for DEs work? [duplicate]",,"This question already has answers here : What am I doing when I separate the variables of a differential equation? (5 answers) Closed 8 years ago . Heyho, I am using the separation-of-variables method for quite a while now, but what was always bothering me a bit, is why is it possible to do those operations. I'll give a concrete example (source Wikipedia): $$\frac{dy}{dx}=xy^2 + x \Rightarrow \frac{dy}{1+y^2} = x \:dx \Rightarrow \int{\frac{dy}{1+y^2}} = \int{x \:dx} \Rightarrow \cdots$$ and so on. My problem lies in step 2. Why can I just treat the differential operator like a variable?","This question already has answers here : What am I doing when I separate the variables of a differential equation? (5 answers) Closed 8 years ago . Heyho, I am using the separation-of-variables method for quite a while now, but what was always bothering me a bit, is why is it possible to do those operations. I'll give a concrete example (source Wikipedia): $$\frac{dy}{dx}=xy^2 + x \Rightarrow \frac{dy}{1+y^2} = x \:dx \Rightarrow \int{\frac{dy}{1+y^2}} = \int{x \:dx} \Rightarrow \cdots$$ and so on. My problem lies in step 2. Why can I just treat the differential operator like a variable?",,['mathematical-physics']
82,"Integration of $\int_0^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx$ by means of complex analysis",Integration of  by means of complex analysis,"\int_0^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx","Dear all: this time I have the integral $$\int_0^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx$$and we must try to solve it using complex integration, residues, Cauchy's Theorem and the whole lot. (BTW, does anyone have any idea whether this integral can be solved without complex functions?) $\underline{\text{What I did}}$: Letting $\,\gamma\,$ be the integration path containing the segments $$\begin{align}(i)&\,\,\text{the real interval} \,[-R\,,\,-\epsilon]\\(ii)&\,\,\text{the ""little"" half circle} \,\{z\;|\;z=\epsilon e^{i\theta}\,,\,\theta\in [0,\pi]\}\\(iii)&\,\,\text{ the real interval}\,[\epsilon\,,\,R]\\(iv)&\,\,\text{ and the ""big"" half circle}\,\{z\;|\;z=R e^{i\theta}\,,\,\theta\in [0,\pi]\}\end{align}$$ we take the integral $$I:=\oint_\gamma\frac{1-e^{iz}}{z^2(z^2+1)}\,dz$$ As the only pole of this function within $\,\gamma\,$ is the simple one $\,z=i\,$ (for $\,\epsilon<1<R\,$, say), and $$\,\operatorname{Res}_{z=i}\left(\frac{1-e^{iz}}{z^2(z^2+1)}\right)=\lim_{z\to i}\frac{1-e^{iz}}{z^2(z+i)}=\frac{e^{-1}-1}{2i}$$We get from the Cauchy's residue theorem $$\displaystyle{I=2\pi i\,\frac{e^{-1}-1}{2i}=\pi\left(\frac{1}{e}-1\right)}$$ We now pass to evaluate the above integral on each segment of $\,\gamma\,$ described above:$$\text{on}\,(iv)\,\text{it is easy:}\,\left|\frac{1-e^{iz}}{z^2(z^2+1)}\right|\leq\frac{1+e^{-R\cos\theta}}{R^4}\xrightarrow[R\to\infty]{} 0$$ On $\,(i)\,,\,(iii)\,$ together and letting $\,R\to \infty\,$ we get $\,\displaystyle{\int_{-\infty}^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx}\,$ , which isn't a problem as the integrand function is even. So here comes the problem : on $\,(ii)\,$ we have:$$z=\epsilon e^{i\theta}\Longrightarrow dz=\epsilon ie^{i\theta}d\theta\,,\,0\leq\theta\leq \pi\,\,\text{but going from left to right, so}$$$$\oint_{z=\epsilon e^{i\theta}}\frac{1-e^{iz}}{z^2(z^2+1)}\,dz=\int_\pi^0\frac{1-e^{i\epsilon e^{i\theta}}}{\epsilon^2e^{2i\theta}\left(\epsilon^2e^{2i\theta}+1\right)}\,\epsilon ie^{i\theta}\,d\theta$$ Now, the only thing I could came up with to evaluate the above integral when $\,\epsilon\to 0\,$ is to get the limit into the integral, getting $$\lim_{\epsilon\to 0}\frac{1-e^{i\epsilon e^{i\theta}}}{\epsilon e^{i\theta}\left(\epsilon^2 e^{2i\theta}+1\right)}=-i\Longrightarrow \int_\pi^0\frac{1-e^{i\epsilon e^{i\theta}}}{\epsilon^2e^{2i\theta}\left(\epsilon^2e^{2i\theta}+1\right)}\,\epsilon ie^{i\theta}\,d\theta\xrightarrow [\epsilon\to 0]{} -\pi$$applying L'Hospital, so the final result is$$\pi\left(\frac{1}{e}-1\right)=I\xrightarrow [R\to\infty\,,\,\epsilon\to 0]{} \int_{-\infty}^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx-\pi$$from which we get the value of $\,\displaystyle{\frac{\pi}{2e}}\,$ for our integral, which is correct (at least according to Wolframalpha), yet... How can I justify the introduction of the limit into the integral?? The only way that seems to me possible (if at all) is to substitute $$\epsilon\to\frac{1}{\delta}$$ to get an indefinite integral with upper limit equal to $\,\infty\,$ inj $\,(ii)\,$ above and then use the dominated convergence theorem (or perhaps the monotone one). My question is two fold: Is the substitution just described what can put me out of my misery in this case? , and: Is it possible to justify the passage of the limit into the integral without making the substitution and, thus, without resourcing to an indefinite integral with infinite upper limit? Thank you to anyone investing he/his time just to read this question, and of course any ideas, corrections will be deeply appreciated.","Dear all: this time I have the integral $$\int_0^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx$$and we must try to solve it using complex integration, residues, Cauchy's Theorem and the whole lot. (BTW, does anyone have any idea whether this integral can be solved without complex functions?) $\underline{\text{What I did}}$: Letting $\,\gamma\,$ be the integration path containing the segments $$\begin{align}(i)&\,\,\text{the real interval} \,[-R\,,\,-\epsilon]\\(ii)&\,\,\text{the ""little"" half circle} \,\{z\;|\;z=\epsilon e^{i\theta}\,,\,\theta\in [0,\pi]\}\\(iii)&\,\,\text{ the real interval}\,[\epsilon\,,\,R]\\(iv)&\,\,\text{ and the ""big"" half circle}\,\{z\;|\;z=R e^{i\theta}\,,\,\theta\in [0,\pi]\}\end{align}$$ we take the integral $$I:=\oint_\gamma\frac{1-e^{iz}}{z^2(z^2+1)}\,dz$$ As the only pole of this function within $\,\gamma\,$ is the simple one $\,z=i\,$ (for $\,\epsilon<1<R\,$, say), and $$\,\operatorname{Res}_{z=i}\left(\frac{1-e^{iz}}{z^2(z^2+1)}\right)=\lim_{z\to i}\frac{1-e^{iz}}{z^2(z+i)}=\frac{e^{-1}-1}{2i}$$We get from the Cauchy's residue theorem $$\displaystyle{I=2\pi i\,\frac{e^{-1}-1}{2i}=\pi\left(\frac{1}{e}-1\right)}$$ We now pass to evaluate the above integral on each segment of $\,\gamma\,$ described above:$$\text{on}\,(iv)\,\text{it is easy:}\,\left|\frac{1-e^{iz}}{z^2(z^2+1)}\right|\leq\frac{1+e^{-R\cos\theta}}{R^4}\xrightarrow[R\to\infty]{} 0$$ On $\,(i)\,,\,(iii)\,$ together and letting $\,R\to \infty\,$ we get $\,\displaystyle{\int_{-\infty}^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx}\,$ , which isn't a problem as the integrand function is even. So here comes the problem : on $\,(ii)\,$ we have:$$z=\epsilon e^{i\theta}\Longrightarrow dz=\epsilon ie^{i\theta}d\theta\,,\,0\leq\theta\leq \pi\,\,\text{but going from left to right, so}$$$$\oint_{z=\epsilon e^{i\theta}}\frac{1-e^{iz}}{z^2(z^2+1)}\,dz=\int_\pi^0\frac{1-e^{i\epsilon e^{i\theta}}}{\epsilon^2e^{2i\theta}\left(\epsilon^2e^{2i\theta}+1\right)}\,\epsilon ie^{i\theta}\,d\theta$$ Now, the only thing I could came up with to evaluate the above integral when $\,\epsilon\to 0\,$ is to get the limit into the integral, getting $$\lim_{\epsilon\to 0}\frac{1-e^{i\epsilon e^{i\theta}}}{\epsilon e^{i\theta}\left(\epsilon^2 e^{2i\theta}+1\right)}=-i\Longrightarrow \int_\pi^0\frac{1-e^{i\epsilon e^{i\theta}}}{\epsilon^2e^{2i\theta}\left(\epsilon^2e^{2i\theta}+1\right)}\,\epsilon ie^{i\theta}\,d\theta\xrightarrow [\epsilon\to 0]{} -\pi$$applying L'Hospital, so the final result is$$\pi\left(\frac{1}{e}-1\right)=I\xrightarrow [R\to\infty\,,\,\epsilon\to 0]{} \int_{-\infty}^\infty\frac{1-\cos x}{x^2(x^2+1)}\,dx-\pi$$from which we get the value of $\,\displaystyle{\frac{\pi}{2e}}\,$ for our integral, which is correct (at least according to Wolframalpha), yet... How can I justify the introduction of the limit into the integral?? The only way that seems to me possible (if at all) is to substitute $$\epsilon\to\frac{1}{\delta}$$ to get an indefinite integral with upper limit equal to $\,\infty\,$ inj $\,(ii)\,$ above and then use the dominated convergence theorem (or perhaps the monotone one). My question is two fold: Is the substitution just described what can put me out of my misery in this case? , and: Is it possible to justify the passage of the limit into the integral without making the substitution and, thus, without resourcing to an indefinite integral with infinite upper limit? Thank you to anyone investing he/his time just to read this question, and of course any ideas, corrections will be deeply appreciated.",,"['integration', 'complex-analysis', 'complex-integration']"
83,Is the Riemann integral of a strictly positive function positive?,Is the Riemann integral of a strictly positive function positive?,,"In the proof here a strictly positive function in $(0,\pi)$ is integrated over this interval and the integral is claimed as a positive number. It seems intuitively obvious as the area enclosed by a continuous function's graph lying entirely above the x-axis and the x-axis should not be zero. But how can I prove this formally? If the function is positive over a closed interval apparently the result is not true (link goes to page 147 in Theories of Integration by Kurtz and Swarz). This has further confused me. Can someone please clarify my doubt. Thanks",In the proof here a strictly positive function in is integrated over this interval and the integral is claimed as a positive number. It seems intuitively obvious as the area enclosed by a continuous function's graph lying entirely above the x-axis and the x-axis should not be zero. But how can I prove this formally? If the function is positive over a closed interval apparently the result is not true (link goes to page 147 in Theories of Integration by Kurtz and Swarz). This has further confused me. Can someone please clarify my doubt. Thanks,"(0,\pi)",['integration']
84,How to evaluate this integral? (relating to binomial),How to evaluate this integral? (relating to binomial),,"I saw some result that some article used, (without proving) that stated:$$\int_0^1 p^k (1-p)^{n-k} \mathrm{d}p = \frac{k!(n-k)!}{(n+1)!}$$ But I was wondering, how would you integrate it? How did this integral come about? Is it something to do with the binomial distribution?","I saw some result that some article used, (without proving) that stated:$$\int_0^1 p^k (1-p)^{n-k} \mathrm{d}p = \frac{k!(n-k)!}{(n+1)!}$$ But I was wondering, how would you integrate it? How did this integral come about? Is it something to do with the binomial distribution?",,['integration']
85,How to do integral $\int_{-\infty}^{\infty} x^4 e^{-x^2/2}dx$,How to do integral,\int_{-\infty}^{\infty} x^4 e^{-x^2/2}dx,Can someone show me a simple way to do integral $\int_{-\infty}^{\infty} x^4 e^{-x^2/2}dx$? I am working on something related to the moments of normal distribution and require the evaluation of the above integral. I can get the answer from W/A or Mathematica but I want to learn how to do this manually.,Can someone show me a simple way to do integral $\int_{-\infty}^{\infty} x^4 e^{-x^2/2}dx$? I am working on something related to the moments of normal distribution and require the evaluation of the above integral. I can get the answer from W/A or Mathematica but I want to learn how to do this manually.,,"['integration', 'definite-integrals']"
86,How to calculate $I=\frac{1}{2}\int_{0}^{\frac{\pi }{2}}\frac{\ln(\sin y)\ln(\cos y)}{\sin y\cos y}dy$?,How to calculate ?,I=\frac{1}{2}\int_{0}^{\frac{\pi }{2}}\frac{\ln(\sin y)\ln(\cos y)}{\sin y\cos y}dy,How do I integrate this guy? I've been stuck on this for hours.. $$I=\frac{1}{2}\int_{0}^{\frac{\pi }{2}}\frac{\ln(\sin y)\ln(\cos y)}{\sin y\cos y}dy$$,How do I integrate this guy? I've been stuck on this for hours.. $$I=\frac{1}{2}\int_{0}^{\frac{\pi }{2}}\frac{\ln(\sin y)\ln(\cos y)}{\sin y\cos y}dy$$,,"['integration', 'trigonometry', 'logarithms', 'problem-solving']"
87,How to decide whether Lebesgue integral or Riemann integral?,How to decide whether Lebesgue integral or Riemann integral?,,"Very often I feel very uncomfortable in dealing with integrals, since  I am wondering whether the given integral is meant as a (improper) Riemann integral or Lebesgue integral? For instance, the Gamma function is often defined by the Euler integral $$\Gamma(z)=\int\limits_{0}^{\infty} t^{z-1}e^{-t}dt $$ but it is not stated whether one should consider the integral as a Lebesgue integral or Riemann integral. It feels more comfortable to deal with Lebesgue integration, since one can use then Lebesgue theorem etc. Is there a rule of thumb how to decide if it is Riemann or Lebesgue integral? Best wishes","Very often I feel very uncomfortable in dealing with integrals, since  I am wondering whether the given integral is meant as a (improper) Riemann integral or Lebesgue integral? For instance, the Gamma function is often defined by the Euler integral but it is not stated whether one should consider the integral as a Lebesgue integral or Riemann integral. It feels more comfortable to deal with Lebesgue integration, since one can use then Lebesgue theorem etc. Is there a rule of thumb how to decide if it is Riemann or Lebesgue integral? Best wishes",\Gamma(z)=\int\limits_{0}^{\infty} t^{z-1}e^{-t}dt ,"['integration', 'lebesgue-integral', 'riemann-integration']"
88,"Integrating $\int_0^{\pi/2} \frac{\sin^2 ax}{\sin^2 x}\,dx$",Integrating,"\int_0^{\pi/2} \frac{\sin^2 ax}{\sin^2 x}\,dx","I am looking for ways to evaluate: $$\int_0^{\pi/2} \frac{\sin^2 ax}{\sin^2 x}\,dx$$ where, $a$ is any positive real-number. (Real-analytic or complex integration techniques, either will do.) Sidenote to down/close votes: It was discussed in SE chat room 36 yesterday (incase you haven't checked robjohn's comment) and I decided to post it on main so that robjohn can share his awesome solution!","I am looking for ways to evaluate: $$\int_0^{\pi/2} \frac{\sin^2 ax}{\sin^2 x}\,dx$$ where, $a$ is any positive real-number. (Real-analytic or complex integration techniques, either will do.) Sidenote to down/close votes: It was discussed in SE chat room 36 yesterday (incase you haven't checked robjohn's comment) and I decided to post it on main so that robjohn can share his awesome solution!",,"['integration', 'definite-integrals']"
89,"Integral $\int_0^1 \log \left(\Gamma\left(x+\alpha\right)\right)\,{\rm d}x=\frac{\log\left( 2 \pi\right)}{2}+\alpha \log\left(\alpha\right) -\alpha$",Integral,"\int_0^1 \log \left(\Gamma\left(x+\alpha\right)\right)\,{\rm d}x=\frac{\log\left( 2 \pi\right)}{2}+\alpha \log\left(\alpha\right) -\alpha","Hi I am trying to prove$$ I:=\int_0^1 \log\left(\,\Gamma\left(x+\alpha\right)\,\right)\,{\rm d}x =\frac{\log\left(2\pi\right)}{2}+\alpha \log\left(\alpha\right) -\alpha\,,\qquad \alpha \geq 0. $$ I am not sure whether to use an integral representation or to somehow use the Euler reflection formula $$ \Gamma(z)\Gamma(1-z)=\frac{\pi}{\sin \pi z} $$ since a previous post used  that to solve  this kind of integral.  Other than this method, we can use the integral representation  $$ \Gamma(t)=\int_0^\infty x^{t-1} e^{-x}\, dx. $$ Also note $\Gamma(n)=(n-1)!$.","Hi I am trying to prove$$ I:=\int_0^1 \log\left(\,\Gamma\left(x+\alpha\right)\,\right)\,{\rm d}x =\frac{\log\left(2\pi\right)}{2}+\alpha \log\left(\alpha\right) -\alpha\,,\qquad \alpha \geq 0. $$ I am not sure whether to use an integral representation or to somehow use the Euler reflection formula $$ \Gamma(z)\Gamma(1-z)=\frac{\pi}{\sin \pi z} $$ since a previous post used  that to solve  this kind of integral.  Other than this method, we can use the integral representation  $$ \Gamma(t)=\int_0^\infty x^{t-1} e^{-x}\, dx. $$ Also note $\Gamma(n)=(n-1)!$.",,"['integration', 'complex-analysis', 'definite-integrals', 'special-functions', 'gamma-function']"
90,Integrate $\frac{R}{4 \pi^2}\int_{-\pi}^{\pi}\int_{-\pi}^{\pi} \frac{1-\cos(mx+ny)}{2-(\cos x + \cos y)} dx dy $,Integrate,\frac{R}{4 \pi^2}\int_{-\pi}^{\pi}\int_{-\pi}^{\pi} \frac{1-\cos(mx+ny)}{2-(\cos x + \cos y)} dx dy ,"As in the title: let $m,n\in\mathbb{Z}$. Integrate: $$ \frac{R}{4 \pi^2}\int_{-\pi}^{\pi}\int_{-\pi}^{\pi} \frac{1-\cos(mx+ny)}{2-(\cos x + \cos y)} dx dy $$  For me, it's quite a difficult problem. Any hints? $R$ is a constant.","As in the title: let $m,n\in\mathbb{Z}$. Integrate: $$ \frac{R}{4 \pi^2}\int_{-\pi}^{\pi}\int_{-\pi}^{\pi} \frac{1-\cos(mx+ny)}{2-(\cos x + \cos y)} dx dy $$  For me, it's quite a difficult problem. Any hints? $R$ is a constant.",,['integration']
91,What is the volume of the $3$-dimensional elliptope?,What is the volume of the -dimensional elliptope?,3,"My question Compute the following double integral analytically $$\int_{-1}^1 \int_{-1}^1 2 \sqrt{x^2 y^2 - x^2 - y^2 + 1} \,\, \mathrm{d} x \mathrm{d} y$$ Background The $3$ -dimensional elliptope is the spectrahedron defined as follows $$\mathcal E_3 := \Bigg\{ (x_{12}, x_{13}, x_{23}) \in \mathbb R^3 : \begin{bmatrix} 1 & x_{12} & x_{13}\\ x_{12} & 1 & x_{23}\\ x_{13} & x_{23} & 1\end{bmatrix} \succeq 0 \Bigg\}$$ Using Sylvester's criterion for positive semidefiniteness (i.e., all $2^3-1 = 7$ principal minors are nonnegative), we obtain $1 \geq 0$ (three times), the three quadratic inequalities $$1 - x_{12}^2 \geq 0 \qquad \qquad \qquad 1 - x_{13}^2 \geq 0 \qquad \qquad \qquad 1 - x_{23}^2 \geq 0$$ and the cubic inequality. $$\det \begin{bmatrix} 1 & x_{12} & x_{13}\\ x_{12} & 1 & x_{23}\\ x_{13} & x_{23} & 1\end{bmatrix} = 1 + 2 x_{12} x_{13} x_{23} - x_{12}^2 - x_{13}^2 - x_{23}^2 \geq 0$$ Thus, $\mathcal E_3$ is contained in the cube $[-1,1]^3$ . Borrowing the pretty figure in Eisenberg-Nagy & Laurent & Varvitsiotis, here is an illustration of $\mathcal E_3$ What is the volume of $\mathcal E_3$ ? Motivation Why is $\mathcal E_3$ interesting? Why bother? Because $\mathcal E_3$ gives us the set of $3 \times 3$ correlation matrices . My work For convenience, $$x := x_{12} \qquad\qquad\qquad y := x_{13} \qquad\qquad\qquad z := x_{23}$$ I started with sheer brute force. Using Haskell, I discretized the cube $[-1,1]^3$ and counted the number of points inside the elliptope. I got an estimate of the volume of $\approx 4.92$ . I then focused on the cubic surface of the elliptope $$\det \begin{bmatrix} 1 & x & y\\ x & 1 & z\\ y & z & 1\end{bmatrix} = 1 + 2 x y z - x^2 - y^2 - z^2 = 0$$ which I rewrote as follows $$z^2 - (2 x y) z + (x^2 + y^2 - 1) = 0$$ Using the quadratic formula, I obtained $$z = x y \pm \sqrt{x^2 y^2 - x^2 - y^2 + 1}$$ Integrating using Wolfram Alpha , $$\int_{-1}^1 \int_{-1}^1 2 \sqrt{x^2 y^2 - x^2 - y^2 + 1} \,\, \mathrm{d} x \mathrm{d} y = \cdots \color{gray}{\text{(magic happens)}} \cdots = \color{blue}{\frac{\pi^2}{2} \approx 4.9348}$$ I still would like to compute the double integral analytically. I converted to cylindrical coordinates, but did not get anywhere. Other people's work This is the same value Johnson & Nvdal obtained in the 1990s: Thus, the volume is $$\left(\frac{\pi}{4}\right)^2 2^3 = \frac{\pi^2}{2}$$ However, I do not understand their work. I do not know what Schur parameters are. Haskell code Here's the script: -- discretization step delta = 2**(-9)   -- discretize the cube [-1,1] x [-1,1] x [-1,1] grid1D = [-1,-1+delta..1] grid3D = [ (x,y,z) | x <- grid1D, y <- grid1D, z <- grid1D ]   -- find points inside the 3D elliptope points = filter (\(x,y,z)->1+2*x*y*z-x**2-y**2-z**2>=0) grid3D   -- find percentage of points inside the elliptope p = (fromIntegral (length points)) / (1 + (2 / delta))**3 After loading the script: *Main> delta 1.953125e-3 *Main> p 0.6149861105903861 *Main> p*(2**3) 4.919888884723089 Hence, approximately $61\%$ of the grid's points are inside the elliptope, which gives us a volume of approximately $4.92$ . A new Buffon's needle A symmetric $3 \times 3$ matrix with $1$ 's on the main diagonal realizations of the random variable whose PDF is uniform over $[-1,1]$ on the entries off the main diagonal is positive semidefinite (and, thus, a correlation matrix) with probability $\left(\frac{\pi}{4}\right)^2$ . Estimating the probability, we estimate $\pi$ . Using the estimate given by the Haskell script: *Main> 4 * sqrt 0.6149861105903861 3.1368420058151125 References Cynthia Vinzant, What is a... Spectrahedron? , Notices of the AMS, Volume 61, Number 5, May 2014. Grigoriy Blekherman, Pablo A. Parrilo, Rekha R. Thomas, Semidefinite Optimization and Convex Algebraic Geometry , SIAM, March 2013. Marianna Eisenberg-Nagy, Monique Laurent, Antonios Varvitsiotis, Complexity of the positive semidefinite matrix completion problem with a rank constraint , arXiv:1203.6602. C. R. Johnson, G. Nvdal, The probability that a (partial) matrix is positive semidefinite , in Recent Progress in Operator Theory , International Workshop on Operator Theory and Applications, IWOTA 95, Regensburg, July 31August 4, 1995.","My question Compute the following double integral analytically Background The -dimensional elliptope is the spectrahedron defined as follows Using Sylvester's criterion for positive semidefiniteness (i.e., all principal minors are nonnegative), we obtain (three times), the three quadratic inequalities and the cubic inequality. Thus, is contained in the cube . Borrowing the pretty figure in Eisenberg-Nagy & Laurent & Varvitsiotis, here is an illustration of What is the volume of ? Motivation Why is interesting? Why bother? Because gives us the set of correlation matrices . My work For convenience, I started with sheer brute force. Using Haskell, I discretized the cube and counted the number of points inside the elliptope. I got an estimate of the volume of . I then focused on the cubic surface of the elliptope which I rewrote as follows Using the quadratic formula, I obtained Integrating using Wolfram Alpha , I still would like to compute the double integral analytically. I converted to cylindrical coordinates, but did not get anywhere. Other people's work This is the same value Johnson & Nvdal obtained in the 1990s: Thus, the volume is However, I do not understand their work. I do not know what Schur parameters are. Haskell code Here's the script: -- discretization step delta = 2**(-9)   -- discretize the cube [-1,1] x [-1,1] x [-1,1] grid1D = [-1,-1+delta..1] grid3D = [ (x,y,z) | x <- grid1D, y <- grid1D, z <- grid1D ]   -- find points inside the 3D elliptope points = filter (\(x,y,z)->1+2*x*y*z-x**2-y**2-z**2>=0) grid3D   -- find percentage of points inside the elliptope p = (fromIntegral (length points)) / (1 + (2 / delta))**3 After loading the script: *Main> delta 1.953125e-3 *Main> p 0.6149861105903861 *Main> p*(2**3) 4.919888884723089 Hence, approximately of the grid's points are inside the elliptope, which gives us a volume of approximately . A new Buffon's needle A symmetric matrix with 's on the main diagonal realizations of the random variable whose PDF is uniform over on the entries off the main diagonal is positive semidefinite (and, thus, a correlation matrix) with probability . Estimating the probability, we estimate . Using the estimate given by the Haskell script: *Main> 4 * sqrt 0.6149861105903861 3.1368420058151125 References Cynthia Vinzant, What is a... Spectrahedron? , Notices of the AMS, Volume 61, Number 5, May 2014. Grigoriy Blekherman, Pablo A. Parrilo, Rekha R. Thomas, Semidefinite Optimization and Convex Algebraic Geometry , SIAM, March 2013. Marianna Eisenberg-Nagy, Monique Laurent, Antonios Varvitsiotis, Complexity of the positive semidefinite matrix completion problem with a rank constraint , arXiv:1203.6602. C. R. Johnson, G. Nvdal, The probability that a (partial) matrix is positive semidefinite , in Recent Progress in Operator Theory , International Workshop on Operator Theory and Applications, IWOTA 95, Regensburg, July 31August 4, 1995.","\int_{-1}^1 \int_{-1}^1 2 \sqrt{x^2 y^2 - x^2 - y^2 + 1} \,\, \mathrm{d} x \mathrm{d} y 3 \mathcal E_3 := \Bigg\{ (x_{12}, x_{13}, x_{23}) \in \mathbb R^3 : \begin{bmatrix} 1 & x_{12} & x_{13}\\ x_{12} & 1 & x_{23}\\ x_{13} & x_{23} & 1\end{bmatrix} \succeq 0 \Bigg\} 2^3-1 = 7 1 \geq 0 1 - x_{12}^2 \geq 0 \qquad \qquad \qquad 1 - x_{13}^2 \geq 0 \qquad \qquad \qquad 1 - x_{23}^2 \geq 0 \det \begin{bmatrix} 1 & x_{12} & x_{13}\\ x_{12} & 1 & x_{23}\\ x_{13} & x_{23} & 1\end{bmatrix} = 1 + 2 x_{12} x_{13} x_{23} - x_{12}^2 - x_{13}^2 - x_{23}^2 \geq 0 \mathcal E_3 [-1,1]^3 \mathcal E_3 \mathcal E_3 \mathcal E_3 \mathcal E_3 3 \times 3 x := x_{12} \qquad\qquad\qquad y := x_{13} \qquad\qquad\qquad z := x_{23} [-1,1]^3 \approx 4.92 \det \begin{bmatrix} 1 & x & y\\ x & 1 & z\\ y & z & 1\end{bmatrix} = 1 + 2 x y z - x^2 - y^2 - z^2 = 0 z^2 - (2 x y) z + (x^2 + y^2 - 1) = 0 z = x y \pm \sqrt{x^2 y^2 - x^2 - y^2 + 1} \int_{-1}^1 \int_{-1}^1 2 \sqrt{x^2 y^2 - x^2 - y^2 + 1} \,\, \mathrm{d} x \mathrm{d} y = \cdots \color{gray}{\text{(magic happens)}} \cdots = \color{blue}{\frac{\pi^2}{2} \approx 4.9348} \left(\frac{\pi}{4}\right)^2 2^3 = \frac{\pi^2}{2} 61\% 4.92 3 \times 3 1 [-1,1] \left(\frac{\pi}{4}\right)^2 \pi","['integration', 'volume', 'linear-matrix-inequality', 'spectrahedra', 'semialgebraic-geometry']"
92,Recursive Integration over Piecewise Polynomials: Closed form?,Recursive Integration over Piecewise Polynomials: Closed form?,,"Is there a closed form to the following recursive integration? $$ f_0(x) = \begin{cases} 1/2 & |x|<1 \\ 0 & |x|\geq1 \end{cases} \\ f_n(x) = 2\int_{-1}^x(f_{n-1}(2t+1)-f_{n-1}(2t-1))\mathrm{d}t $$ It's very clear that this converges against some function and that quite rapidly, as seen in this image, showing the first 8 terms: Furthermore, the derivatives of it have some very special properties. Note how the (renormalized) derivatives consist of repeated and rescaled functions of the previous degree which is obviously a result of the definition of the recursive integral: EDIT I found the following likely Fourier transform of the expression above. I do not have a formal proof but it holds for all terms I tried it with (first 11). $$ \mathcal{F}_x\left[f_n(x)\right](t)=\frac{1}{\sqrt{2\pi}}\frac{2^n \sin \left(2^{-n} t\right)}{t} \prod _{k=1}^n \frac{2^{k} \sin \left(2^{-k} t\right)}{t} $$ Here an image of how that looks like (first 10 terms in Interval $[-8\pi,8\pi]$ ): With this, my question alternatively becomes: What, if there is one, is the closed form inverse fourier transform of $\mathcal{F}_x\left[f_n(x)\right](t)=\frac{1}{\sqrt{2\pi}}\frac{2^n \sin \left(2^{-n} t\right)}{t} \prod _{k=1}^n \frac{2^{k} \sin \left(2^{-k} t\right)}{t}$ , especially for the case $n\rightarrow\infty$ ? As a side note, it turns out, that this particular product is a particular Browein integral (Wikipedia) using as a sequence $a_k = 2^{-k}$ which exactly sums to 1. The extra term in the front makes this true for the finite sequence as well. In the limit $k \to \infty$ , that term just becomes $1$ , not changing the product at all. It is therefore just a finite depth correction.","Is there a closed form to the following recursive integration? It's very clear that this converges against some function and that quite rapidly, as seen in this image, showing the first 8 terms: Furthermore, the derivatives of it have some very special properties. Note how the (renormalized) derivatives consist of repeated and rescaled functions of the previous degree which is obviously a result of the definition of the recursive integral: EDIT I found the following likely Fourier transform of the expression above. I do not have a formal proof but it holds for all terms I tried it with (first 11). Here an image of how that looks like (first 10 terms in Interval ): With this, my question alternatively becomes: What, if there is one, is the closed form inverse fourier transform of , especially for the case ? As a side note, it turns out, that this particular product is a particular Browein integral (Wikipedia) using as a sequence which exactly sums to 1. The extra term in the front makes this true for the finite sequence as well. In the limit , that term just becomes , not changing the product at all. It is therefore just a finite depth correction.","
f_0(x) =
\begin{cases}
1/2 & |x|<1 \\
0 & |x|\geq1
\end{cases}
\\
f_n(x) = 2\int_{-1}^x(f_{n-1}(2t+1)-f_{n-1}(2t-1))\mathrm{d}t
  \mathcal{F}_x\left[f_n(x)\right](t)=\frac{1}{\sqrt{2\pi}}\frac{2^n \sin \left(2^{-n} t\right)}{t} \prod _{k=1}^n \frac{2^{k} \sin \left(2^{-k} t\right)}{t}  [-8\pi,8\pi] \mathcal{F}_x\left[f_n(x)\right](t)=\frac{1}{\sqrt{2\pi}}\frac{2^n \sin \left(2^{-n} t\right)}{t} \prod _{k=1}^n \frac{2^{k} \sin \left(2^{-k} t\right)}{t} n\rightarrow\infty a_k = 2^{-k} k \to \infty 1","['integration', 'polynomials', 'fourier-analysis', 'recurrence-relations', 'recursion']"
93,"On the integral $\int_0^\pi\sin(x+\sin(x+\sin(x+\cdots)))\,dx$",On the integral,"\int_0^\pi\sin(x+\sin(x+\sin(x+\cdots)))\,dx","This question came into my head when I did a course on Fourier series. However, this is not an infinite sum of sines, but an infinite recurrence of sines in a sum. Consider $f_1(x)=\sin(x)$ and $f_2(x)=\sin(x+f_1(x))$ such that $f_n$ satisfies the relation $$f_n(x)=\sin(x+f_{n-1}(x)).$$ To what value does $$L:=\lim_{n\to\infty}\int_0^\pi f_n(x)\,dx$$ converge? Since it is impossible to evaluate the integrals directly, we begin by considering the first few values of $n$ . A pattern clearly emerges. $$I_1=\int_0^\pi f_1(x)\,dx=2\quad\quad\quad I_2=1.376527...\\I_3=2.188188...\quad\quad\quad\quad\quad I_4=1.625516...\\ I_5=2.179090...\quad\quad\quad\quad\quad I_6=1.732942...\\ I_7=2.155900...\quad\quad\quad\quad\quad I_8=1.927035...$$ For odd values of $n$ , $I_n$ decreases monotonically (except $n=1$ ) and for even values of $n$ , $I_n$ increases monotonically.  These two observations have led me to claim that $L=I_1=2$ . Is it possible to prove/disprove this claim?","This question came into my head when I did a course on Fourier series. However, this is not an infinite sum of sines, but an infinite recurrence of sines in a sum. Consider and such that satisfies the relation To what value does converge? Since it is impossible to evaluate the integrals directly, we begin by considering the first few values of . A pattern clearly emerges. For odd values of , decreases monotonically (except ) and for even values of , increases monotonically.  These two observations have led me to claim that . Is it possible to prove/disprove this claim?","f_1(x)=\sin(x) f_2(x)=\sin(x+f_1(x)) f_n f_n(x)=\sin(x+f_{n-1}(x)). L:=\lim_{n\to\infty}\int_0^\pi f_n(x)\,dx n I_1=\int_0^\pi f_1(x)\,dx=2\quad\quad\quad I_2=1.376527...\\I_3=2.188188...\quad\quad\quad\quad\quad I_4=1.625516...\\ I_5=2.179090...\quad\quad\quad\quad\quad I_6=1.732942...\\ I_7=2.155900...\quad\quad\quad\quad\quad I_8=1.927035... n I_n n=1 n I_n L=I_1=2","['integration', 'limits', 'convergence-divergence']"
94,"The function $f(x) = \int_0^\infty \frac{x^t}{\Gamma(t+1)} \, dt$",The function,"f(x) = \int_0^\infty \frac{x^t}{\Gamma(t+1)} \, dt","Does anyone know if this function has a name? I came up with it by looking at the power series for $e^z$, changing the summation to an integral, and substituting the gamma function for the factorial function.","Does anyone know if this function has a name? I came up with it by looking at the power series for $e^z$, changing the summation to an integral, and substituting the gamma function for the factorial function.",,"['analysis', 'integration', 'special-functions']"
95,Dirac delta function of non-linear multivariable arguments,Dirac delta function of non-linear multivariable arguments,,"How does one compute a dirac delta function with a multivariable argument? For example, compute: $$ \int^{\infty}_{-\infty}{\rm d}x\,{\rm d}y\, \delta\left(x^{2} + y^{2} - 4\right) \delta\left(\left[x - 1\right]^{2} + y^{2} -4\right){\rm f}\left(x,y\right). $$ If we constrain the two delta functions we'll get two intersecting circles, and it seems reasonable to state that we evaluate $f(x,y)$ at the intersecting points, but I feel like there should be some extra identities. Since for single variable  $$\delta(f(x))=\sum_i \frac{\delta(x-x_i)}{|f'(x)|},$$ is there a multivariable generalization to be aware of?","How does one compute a dirac delta function with a multivariable argument? For example, compute: $$ \int^{\infty}_{-\infty}{\rm d}x\,{\rm d}y\, \delta\left(x^{2} + y^{2} - 4\right) \delta\left(\left[x - 1\right]^{2} + y^{2} -4\right){\rm f}\left(x,y\right). $$ If we constrain the two delta functions we'll get two intersecting circles, and it seems reasonable to state that we evaluate $f(x,y)$ at the intersecting points, but I feel like there should be some extra identities. Since for single variable  $$\delta(f(x))=\sum_i \frac{\delta(x-x_i)}{|f'(x)|},$$ is there a multivariable generalization to be aware of?",,"['integration', 'definite-integrals', 'improper-integrals', 'distribution-theory', 'dirac-delta']"
96,"How to prove $\int_0^1\frac{x^3\arctan x}{(3-x^2)^2}\frac{\mathrm dx}{\sqrt{1-x^2}}=\frac{\pi\sqrt{2}}{192}\left(18-\pi-6\sqrt{3}\,\right)$?",How to prove ?,"\int_0^1\frac{x^3\arctan x}{(3-x^2)^2}\frac{\mathrm dx}{\sqrt{1-x^2}}=\frac{\pi\sqrt{2}}{192}\left(18-\pi-6\sqrt{3}\,\right)","How to prove the following result? $$\int_0^1\frac{x^3\arctan x}{(3-x^2)^2}\frac{\mathrm dx}{\sqrt{1-x^2}}=\frac{\pi\sqrt{2}}{192}\left(18-\pi-6\sqrt{3}\,\right)$$ For my part no idea?","How to prove the following result? $$\int_0^1\frac{x^3\arctan x}{(3-x^2)^2}\frac{\mathrm dx}{\sqrt{1-x^2}}=\frac{\pi\sqrt{2}}{192}\left(18-\pi-6\sqrt{3}\,\right)$$ For my part no idea?",,"['integration', 'definite-integrals', 'improper-integrals']"
97,Various $p$-adic integrals,Various -adic integrals,p,"Here are three (possibly different) definitions of $p$-adic integrals that I have encountered during my self-studies. First of all, here is what Vladimirov, Volovich and Zelenov write at the beginning of their book on mathematical physics: As the field $\mathbb Q_p$ is a locally compact commutative group with   respect to addition then in $\mathbb Q_p$ there exists the Haar   measure, a positive measure $dx$ which is invariant to shifts. We   normalize the measure $dx$ such that $\int_{|x|_p \le 1} dx = 1.$   Under such agreement the measure is unique. For any compact $K \subseteq \mathbb Q_p$ the measure $dx$ defines a positive linear   continuous functional on $C(K)$ by the formula $\int_K f(x) dx$. A   function $f \in \mathcal L^1_{\textrm{loc}}$ is called integrable on   $\mathbb Q_p$ if there exists $$\lim_{N \to \infty} \int_{B(N)} f(x)dx = \lim_{N \to \infty} \sum_{\gamma = -N}^\infty \int_{S(-\gamma)} f(x) dx.$$ Their denote by $B(N)$ the set $\{x \in \mathbb Q_p : |x|_p \le p^N \}$ and $S(\gamma)$ is defined as $B(\gamma) \setminus B(\gamma-1)$. Next we have the famous Volkenborn integral, described as follows by Robert: We say that $f$ is strictly differentiable at a point $a \in X$ - and   denote this property by $f \in \mathcal S^1(a)$ - if the difference   quotients $[f(x) - f(y)]/(x-y)$ have a limit as $(x, y) \to (a,a)$   ($x$ and $y$ remaining distinct). By the way, $\mathcal S^1(X) := \bigcap_{a \in X} \mathcal S^1(a)$.   The Volkenborn integral of a function $f \in \mathcal S^1(\mathbb Z_p)$ is by definition $$\int_{\mathbb Z_p} f(x) dx = \lim_{n \to  \infty} \frac{1}{p^n} \sum_{j=0}^{p^n-1} f(j).$$ Finally a quote from Koblitz book ""$p$-adic numbers, analysis and $\zeta$-functions"": Now let $X$ be a compact-open subset of $\mathbb Q_p$. A $p$-adic distribution $\mu$ on $X$ is a $\mathbb Q_p$-linear vector space homomorphism from the $\mathbb Q_p$-vector space of locally constant functions on $X$ to $\mathbb Q_p$. Later he states that for $p$-adic measures (distributions that are bounded on compact-open subsets by some constant) and continuous functions $f$ there is a reasonable way to define $\mu(f) =: \int_X f \mu$. Cassels is confusing me even more as he mentions Shnirelman. So, here are my actual questions: Do these ultrametric integrals have real analogues like: being a limit of Riemannian sums or an operation inverse to differentiation? Are they compatible to each other? Is any of them a generalization of the others? What are the positive and negative attributes of the cited definitions? Where can I find an exhaustive table of integrals? I'm mainly interested in something similar to https://www.tug.org/texshowcase/cheat.pdf . Can we somehow imitate the Lebesgue integration theory?","Here are three (possibly different) definitions of $p$-adic integrals that I have encountered during my self-studies. First of all, here is what Vladimirov, Volovich and Zelenov write at the beginning of their book on mathematical physics: As the field $\mathbb Q_p$ is a locally compact commutative group with   respect to addition then in $\mathbb Q_p$ there exists the Haar   measure, a positive measure $dx$ which is invariant to shifts. We   normalize the measure $dx$ such that $\int_{|x|_p \le 1} dx = 1.$   Under such agreement the measure is unique. For any compact $K \subseteq \mathbb Q_p$ the measure $dx$ defines a positive linear   continuous functional on $C(K)$ by the formula $\int_K f(x) dx$. A   function $f \in \mathcal L^1_{\textrm{loc}}$ is called integrable on   $\mathbb Q_p$ if there exists $$\lim_{N \to \infty} \int_{B(N)} f(x)dx = \lim_{N \to \infty} \sum_{\gamma = -N}^\infty \int_{S(-\gamma)} f(x) dx.$$ Their denote by $B(N)$ the set $\{x \in \mathbb Q_p : |x|_p \le p^N \}$ and $S(\gamma)$ is defined as $B(\gamma) \setminus B(\gamma-1)$. Next we have the famous Volkenborn integral, described as follows by Robert: We say that $f$ is strictly differentiable at a point $a \in X$ - and   denote this property by $f \in \mathcal S^1(a)$ - if the difference   quotients $[f(x) - f(y)]/(x-y)$ have a limit as $(x, y) \to (a,a)$   ($x$ and $y$ remaining distinct). By the way, $\mathcal S^1(X) := \bigcap_{a \in X} \mathcal S^1(a)$.   The Volkenborn integral of a function $f \in \mathcal S^1(\mathbb Z_p)$ is by definition $$\int_{\mathbb Z_p} f(x) dx = \lim_{n \to  \infty} \frac{1}{p^n} \sum_{j=0}^{p^n-1} f(j).$$ Finally a quote from Koblitz book ""$p$-adic numbers, analysis and $\zeta$-functions"": Now let $X$ be a compact-open subset of $\mathbb Q_p$. A $p$-adic distribution $\mu$ on $X$ is a $\mathbb Q_p$-linear vector space homomorphism from the $\mathbb Q_p$-vector space of locally constant functions on $X$ to $\mathbb Q_p$. Later he states that for $p$-adic measures (distributions that are bounded on compact-open subsets by some constant) and continuous functions $f$ there is a reasonable way to define $\mu(f) =: \int_X f \mu$. Cassels is confusing me even more as he mentions Shnirelman. So, here are my actual questions: Do these ultrametric integrals have real analogues like: being a limit of Riemannian sums or an operation inverse to differentiation? Are they compatible to each other? Is any of them a generalization of the others? What are the positive and negative attributes of the cited definitions? Where can I find an exhaustive table of integrals? I'm mainly interested in something similar to https://www.tug.org/texshowcase/cheat.pdf . Can we somehow imitate the Lebesgue integration theory?",,"['integration', 'measure-theory', 'lebesgue-integral', 'p-adic-number-theory']"
98,Proving that $\int_0^1 \frac{\log^2(x)\tanh^{-1}(x)}{1+x^2}dx=\beta(4)-\frac{\pi^2}{12}G$,Proving that,\int_0^1 \frac{\log^2(x)\tanh^{-1}(x)}{1+x^2}dx=\beta(4)-\frac{\pi^2}{12}G,I am trying to prove that $$I=\int_0^1 \frac{\log^2(x)\tanh^{-1}(x)}{1+x^2}dx=\beta(4)-\frac{\pi^2}{12}G$$ where $\beta(s)$ is the Dirichlet Beta function and $G$ is the Catalan's constant . I managed to derive the following series involving polygamma functions but it doesn't seem to be of much help. $$ \begin{align*} I &=\frac{1}{64}\sum_{n=0}^\infty \frac{\psi_2 \left(\frac{n}{2}+1 \right) -\psi_2\left(\frac{n+1}{2} \right)}{2n+1}  \\ &= \frac{1}{8}\sum_{n=1}^\infty \frac{\psi_2(n)}{2n-1}-\frac{1}{32}\sum_{n=1}^\infty\frac{\psi_2\left(\frac{n}{2}\right)}{2n-1} \end{align*} $$ Numerical calculations show that $I \approx 0.235593$.,I am trying to prove that $$I=\int_0^1 \frac{\log^2(x)\tanh^{-1}(x)}{1+x^2}dx=\beta(4)-\frac{\pi^2}{12}G$$ where $\beta(s)$ is the Dirichlet Beta function and $G$ is the Catalan's constant . I managed to derive the following series involving polygamma functions but it doesn't seem to be of much help. $$ \begin{align*} I &=\frac{1}{64}\sum_{n=0}^\infty \frac{\psi_2 \left(\frac{n}{2}+1 \right) -\psi_2\left(\frac{n+1}{2} \right)}{2n+1}  \\ &= \frac{1}{8}\sum_{n=1}^\infty \frac{\psi_2(n)}{2n-1}-\frac{1}{32}\sum_{n=1}^\infty\frac{\psi_2\left(\frac{n}{2}\right)}{2n-1} \end{align*} $$ Numerical calculations show that $I \approx 0.235593$.,,"['integration', 'definite-integrals', 'special-functions', 'polylogarithm']"
99,Why does integral and the imaginary part commute?,Why does integral and the imaginary part commute?,,"I have many a times encountered (and used myself) the following technique: $$\int \sin x \mathrm{d}x = \int \operatorname{Im}(e^{ix}) \mathrm{d}x = \operatorname{Im} \left( \int e^{ix} \mathrm{d}x \right) = \operatorname{Im}( -ie^{ix}) + C = -\cos x + C$$ Not only in this case, but I've used this kind of transform many a times, instinctively, to solve many of those monster trig integrals (and it works like a miracle) but never justified it. Why and how is this interchange of integral and imaginary part justified? At first, I thought it might be always true that we can do such a type of interchange anywhere, so, I tried the following: $\operatorname{Im}(f(z)) = f(\operatorname{Im}(z))$. But this is clearly not true, as the LHS is always real but RHS can be, possibly, complex too. Second thoughts. I realized that we are dealing with operators here and not functions really. Both integral and imaginary parts are operators. So we have a composition of operators and we are willing to check when do these operators commute? I couldn't really make out any further conclusions from here and am stuck with the following questions: When and why is the following true: $\int \operatorname{Im}(f(z)) \mathrm{d}z= \operatorname{Im} \left( \int f(z) \mathrm{d}z \right)$? (Provided that $f$ is integrable) Is it always true? (Because like I've used it so many times and never found any counter example) Edit : I am unfamiliar with integration of complex-valued functions but what I have in mind is that while doing such a thing, I tend to think of $i$ as just as some constant (Ah! I hope this doesn't sounds like really weird), as I stated in the example in the beginning. To be more precise, I have something of like this in my mind: because a complex-valued function $f(z)$ can be thought of as $f(z) = f(x+iy) = u(x,y) + iv(x,y)$ where $u$ and $v$ are real-valued functions and we can now use our definition for integration of real-valued functions as $$\int f(z) \mathrm{d}z = \int (u(x,y) + iv(x,y)) \mathrm{d}(x+iy) = \left(\int u\mathrm{d}x - \int v\mathrm{d}y\right) +i\left(\int v\mathrm{d}x + \int u\mathrm{d}y\right)$$","I have many a times encountered (and used myself) the following technique: $$\int \sin x \mathrm{d}x = \int \operatorname{Im}(e^{ix}) \mathrm{d}x = \operatorname{Im} \left( \int e^{ix} \mathrm{d}x \right) = \operatorname{Im}( -ie^{ix}) + C = -\cos x + C$$ Not only in this case, but I've used this kind of transform many a times, instinctively, to solve many of those monster trig integrals (and it works like a miracle) but never justified it. Why and how is this interchange of integral and imaginary part justified? At first, I thought it might be always true that we can do such a type of interchange anywhere, so, I tried the following: $\operatorname{Im}(f(z)) = f(\operatorname{Im}(z))$. But this is clearly not true, as the LHS is always real but RHS can be, possibly, complex too. Second thoughts. I realized that we are dealing with operators here and not functions really. Both integral and imaginary parts are operators. So we have a composition of operators and we are willing to check when do these operators commute? I couldn't really make out any further conclusions from here and am stuck with the following questions: When and why is the following true: $\int \operatorname{Im}(f(z)) \mathrm{d}z= \operatorname{Im} \left( \int f(z) \mathrm{d}z \right)$? (Provided that $f$ is integrable) Is it always true? (Because like I've used it so many times and never found any counter example) Edit : I am unfamiliar with integration of complex-valued functions but what I have in mind is that while doing such a thing, I tend to think of $i$ as just as some constant (Ah! I hope this doesn't sounds like really weird), as I stated in the example in the beginning. To be more precise, I have something of like this in my mind: because a complex-valued function $f(z)$ can be thought of as $f(z) = f(x+iy) = u(x,y) + iv(x,y)$ where $u$ and $v$ are real-valued functions and we can now use our definition for integration of real-valued functions as $$\int f(z) \mathrm{d}z = \int (u(x,y) + iv(x,y)) \mathrm{d}(x+iy) = \left(\int u\mathrm{d}x - \int v\mathrm{d}y\right) +i\left(\int v\mathrm{d}x + \int u\mathrm{d}y\right)$$",,"['integration', 'complex-numbers']"
