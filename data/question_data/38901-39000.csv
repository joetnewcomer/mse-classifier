,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Permutation module of $S_n$,Permutation module of,S_n,"Let $G=S_n$ and let $V$ be the permutation module of $G$ with basis $\{x_1,\ldots,x_n\}.$ Let $\lambda, \mu \in \mathbb{C}$ to allow one to define a $\mathbb{C}G$-homomorphism $\rho:V \to V$ by $$\rho(x_j):=\lambda x_j+\mu\sum_{i \neq j}x_i.$$ By using the above fact or otherwise, how can we prove that $V$ is the direct sum of two non-isomorphic irreducible $\mathbb{C}G$ -submodules? I tried to prove this by construction. A familiar irreducible submodule in this case is the $1$-dimensional space $U:=\operatorname{span}\{x_1+\cdots+x_n\}$. I intend to find another $(n-1)$-dimensional submodule $W$  which makes $V=U\oplus W$ hold, but it's hard to do so. Is there a way to use the fact instead of a random construction?","Let $G=S_n$ and let $V$ be the permutation module of $G$ with basis $\{x_1,\ldots,x_n\}.$ Let $\lambda, \mu \in \mathbb{C}$ to allow one to define a $\mathbb{C}G$-homomorphism $\rho:V \to V$ by $$\rho(x_j):=\lambda x_j+\mu\sum_{i \neq j}x_i.$$ By using the above fact or otherwise, how can we prove that $V$ is the direct sum of two non-isomorphic irreducible $\mathbb{C}G$ -submodules? I tried to prove this by construction. A familiar irreducible submodule in this case is the $1$-dimensional space $U:=\operatorname{span}\{x_1+\cdots+x_n\}$. I intend to find another $(n-1)$-dimensional submodule $W$  which makes $V=U\oplus W$ hold, but it's hard to do so. Is there a way to use the fact instead of a random construction?",,"['abstract-algebra', 'representation-theory', 'modules']"
1,What is an automorphism group?,What is an automorphism group?,,"I'm studying field theory on my own, and I am stuck in the definition of an automorphism and automorphism group. Could you give me examples, like the $Aut(\mathbb Z_7)$? How they are computed?","I'm studying field theory on my own, and I am stuck in the definition of an automorphism and automorphism group. Could you give me examples, like the $Aut(\mathbb Z_7)$? How they are computed?",,['abstract-algebra']
2,Edge coloring of the cube,Edge coloring of the cube,,"We have a cube and we are coloring its edges. There are three colors available. We say that the two colorings are the same if one can obtain a second by turning cube and permuting colors. Find the number of different colorings. Any ideas? I've found Pólya enumeration theorem , but it's difficult to understand for me, also this approach does not take into account the permutation of colors...","We have a cube and we are coloring its edges. There are three colors available. We say that the two colorings are the same if one can obtain a second by turning cube and permuting colors. Find the number of different colorings. Any ideas? I've found Pólya enumeration theorem , but it's difficult to understand for me, also this approach does not take into account the permutation of colors...",,"['abstract-algebra', 'combinatorics', 'coloring']"
3,Category of Field has no initial object,Category of Field has no initial object,,Why the category of Field has no initial object? (see page $47$ of Category Theory by Horst Herrlich and George E. Strecker ),Why the category of Field has no initial object? (see page of Category Theory by Horst Herrlich and George E. Strecker ),47,"['abstract-algebra', 'field-theory', 'category-theory']"
4,Are groups with all the same Hom sets already isomorphic?,Are groups with all the same Hom sets already isomorphic?,,"I was thinking about the following: Say we got two groups $A$ and $B$, and we know that for any group C, there is a bijection $$Hom(A,C) \to Hom(B,C).$$ Are $A$ and $B$ already isomorphic? If the family of bijections was natural in $C$, this follows from Yoneda's lemma. But does it hold anyway without naturality, just from the cardinalities? I would suspect no but in simple cases (finitely generated). I'd like to hear any thoughts on how to come up with a proof or counterexample. Also, does the answer change when we consider the contravariant case with an identification $Hom(C,A) \to Hom(C,B)$?","I was thinking about the following: Say we got two groups $A$ and $B$, and we know that for any group C, there is a bijection $$Hom(A,C) \to Hom(B,C).$$ Are $A$ and $B$ already isomorphic? If the family of bijections was natural in $C$, this follows from Yoneda's lemma. But does it hold anyway without naturality, just from the cardinalities? I would suspect no but in simple cases (finitely generated). I'd like to hear any thoughts on how to come up with a proof or counterexample. Also, does the answer change when we consider the contravariant case with an identification $Hom(C,A) \to Hom(C,B)$?",,"['abstract-algebra', 'group-theory', 'category-theory']"
5,A Characterization of Categories with a Conservative Forgetful Functor to SET,A Characterization of Categories with a Conservative Forgetful Functor to SET,,"Examples of categories over $\bf{Set}$ such that the forgetful functor is conservative include the ""algebraic"" categories of groups, rings, modules, monoids, etc., but does not include the ""higher-order"" categories of topological spaces, smooth manifolds, schemes, etc. or some ""relational"" categories like posets. Is there any intrinsic characterization of the difference in behavior here? Do we know that certain classes of categories always have conservative forgetful functors to $\bf{Set}$? I'd be particularly interested in a model-theoretic description (i.e. something like the fact that the first examples are categories of models of an algebraic first order theory while the later ones are not), but I'd also be interested in a description in terms of categorical properties. EDIT : As pointed out in the answers, it's often possible to give a conservative faithful functor to $\bf{Set}$. However, these aren't the ""underlying set"" forgetful functors; they include extra information. Maybe the question becomes more interesting if we require the functor to be ""canonical"". This doesn't make much sense in terms of categories alone, but perhaps it does in terms of model theory: given a (perhaps higher-order) theory $\mathbb{T}$, when is the forgetful functor $\text{MOD-}\mathbb{T}(\bf{Set}) \rightarrow \bf{Set}$ conservative?","Examples of categories over $\bf{Set}$ such that the forgetful functor is conservative include the ""algebraic"" categories of groups, rings, modules, monoids, etc., but does not include the ""higher-order"" categories of topological spaces, smooth manifolds, schemes, etc. or some ""relational"" categories like posets. Is there any intrinsic characterization of the difference in behavior here? Do we know that certain classes of categories always have conservative forgetful functors to $\bf{Set}$? I'd be particularly interested in a model-theoretic description (i.e. something like the fact that the first examples are categories of models of an algebraic first order theory while the later ones are not), but I'd also be interested in a description in terms of categorical properties. EDIT : As pointed out in the answers, it's often possible to give a conservative faithful functor to $\bf{Set}$. However, these aren't the ""underlying set"" forgetful functors; they include extra information. Maybe the question becomes more interesting if we require the functor to be ""canonical"". This doesn't make much sense in terms of categories alone, but perhaps it does in terms of model theory: given a (perhaps higher-order) theory $\mathbb{T}$, when is the forgetful functor $\text{MOD-}\mathbb{T}(\bf{Set}) \rightarrow \bf{Set}$ conservative?",,"['abstract-algebra', 'logic', 'category-theory', 'model-theory']"
6,Question About Notation In Field Theory $F(x)$ vs. $F[x]$,Question About Notation In Field Theory  vs.,F(x) F[x],"I have a question about notation specifically square brackets $[$ and round brackets $($. My textbook doesn't explain any of this and I cannot find a reliable source online to confirm the difference. So my question is: What is the difference between round brackets and square brackets in terms of notation in Field Theory? For example, I see $F(x)$ and $F[x]$ in my textbook and I've always assumed they were the same thing. But apparently they're not. Is there ever a time they're the same? I wanted to know the difference, it may be a silly question but it's something I want to make sure I understand.","I have a question about notation specifically square brackets $[$ and round brackets $($. My textbook doesn't explain any of this and I cannot find a reliable source online to confirm the difference. So my question is: What is the difference between round brackets and square brackets in terms of notation in Field Theory? For example, I see $F(x)$ and $F[x]$ in my textbook and I've always assumed they were the same thing. But apparently they're not. Is there ever a time they're the same? I wanted to know the difference, it may be a silly question but it's something I want to make sure I understand.",,"['abstract-algebra', 'field-theory', 'notation']"
7,Quintic polynomial with Galois Group $A_5$,Quintic polynomial with Galois Group,A_5,"A recent question asks what makes degree 5 special when considering the roots of polynomials with integer coefficients etc. One answer is that the Galois Group of $S_5$ is not solvable. What I am looking for is the most straightforward example (with proof) of a polynomial with integer coefficients and Galois Group $A_5$. Such an object ought to be standard ... if I ever knew one, I have forgotten it.","A recent question asks what makes degree 5 special when considering the roots of polynomials with integer coefficients etc. One answer is that the Galois Group of $S_5$ is not solvable. What I am looking for is the most straightforward example (with proof) of a polynomial with integer coefficients and Galois Group $A_5$. Such an object ought to be standard ... if I ever knew one, I have forgotten it.",,"['abstract-algebra', 'galois-theory']"
8,Converse to Hilbert basis theorem,Converse to Hilbert basis theorem,,"Prove the converse to Hilbert basis theoren: If the polynomial ring $R[x]$ is Noetherian, then $R$ is noetherian.","Prove the converse to Hilbert basis theoren: If the polynomial ring $R[x]$ is Noetherian, then $R$ is noetherian.",,"['abstract-algebra', 'ring-theory', 'noetherian']"
9,Number of homomorphisms between two arbitrary groups [duplicate],Number of homomorphisms between two arbitrary groups [duplicate],,"This question already has an answer here : Strategy for determining the number of homomorphisms between two Groups (1 answer) Closed last year . How many homomorphisms are there from $A_5$ to $S_4$ ? This is how I tried to solve it. If there is a homomorphism from $A_5$ to $S_4$ , then order of element of $S_4$ should divide the order of its preimage. Now what are the possible order of elements in $S_4$ .1,2,3 and 4. Since $A_5$ contains (12345), which is of order 5.. what could be image of (12345). Definitely Identity element which is of order 1. Similarly all 5 cycles must be mapped to identity.  There are 24 elements of 5 cycles. 24 elements out of 60 are mapped to identity .. now only two types of homomorphisms are possible. either 30:1mapping  or 60:1 mapping.  Consider (12)(34) which belongs to $A_5$ . It's image can be element of order 2 or identity.there are 15 elements of order 2 . suppose these 15 elements are mapped to some element 'g' of order 2 of $S_4$ , you need another 15 elements to get mapped to 'g' to have 30 :1 mapping. Other type of elements left in $A_5$ is of order 3. None of them can be mapped to g. hence 15 elements of order 2 should be mapped to identity .. so ,  (24+15=39) elements mapped to identity.As mentioned earlier it should be 30 :1 or 60:1 mapping. So it must be 60:1 mapping.Hence a trivial homomorphism. Answer is 1. I wanted to know is there any other technique which can be used to find number of homomorphism in the above question ? In general, how to find number of homomorphism  between any two arbitrary groups ?","This question already has an answer here : Strategy for determining the number of homomorphisms between two Groups (1 answer) Closed last year . How many homomorphisms are there from to ? This is how I tried to solve it. If there is a homomorphism from to , then order of element of should divide the order of its preimage. Now what are the possible order of elements in .1,2,3 and 4. Since contains (12345), which is of order 5.. what could be image of (12345). Definitely Identity element which is of order 1. Similarly all 5 cycles must be mapped to identity.  There are 24 elements of 5 cycles. 24 elements out of 60 are mapped to identity .. now only two types of homomorphisms are possible. either 30:1mapping  or 60:1 mapping.  Consider (12)(34) which belongs to . It's image can be element of order 2 or identity.there are 15 elements of order 2 . suppose these 15 elements are mapped to some element 'g' of order 2 of , you need another 15 elements to get mapped to 'g' to have 30 :1 mapping. Other type of elements left in is of order 3. None of them can be mapped to g. hence 15 elements of order 2 should be mapped to identity .. so ,  (24+15=39) elements mapped to identity.As mentioned earlier it should be 30 :1 or 60:1 mapping. So it must be 60:1 mapping.Hence a trivial homomorphism. Answer is 1. I wanted to know is there any other technique which can be used to find number of homomorphism in the above question ? In general, how to find number of homomorphism  between any two arbitrary groups ?",A_5 S_4 A_5 S_4 S_4 S_4 A_5 A_5 S_4 A_5,"['abstract-algebra', 'group-theory', 'finite-groups', 'group-homomorphism', 'permutation-cycles']"
10,"What is the field of fractions of $\mathbb{Q}[x,y]/(x^2+y^2)$?",What is the field of fractions of ?,"\mathbb{Q}[x,y]/(x^2+y^2)","What is the field of fractions of $\mathbb{Q}[x,y]/(x^2+y^2)$? Remarks: (1) I think it is clear that $\mathbb{Q}[x,y]/(x^2+y^2)$ is an integral domain;  indeed, $x^2+y^2 \in \mathbb{Q}[x,y]$ is irreducible (by considerations of degrees) hence prime. (2) The field of fractions of $\mathbb{Q}[x,y]/(x^2+y^2-1)$ is isomorphic to $\mathbb{Q}(t)$, see this question and also this question .","What is the field of fractions of $\mathbb{Q}[x,y]/(x^2+y^2)$? Remarks: (1) I think it is clear that $\mathbb{Q}[x,y]/(x^2+y^2)$ is an integral domain;  indeed, $x^2+y^2 \in \mathbb{Q}[x,y]$ is irreducible (by considerations of degrees) hence prime. (2) The field of fractions of $\mathbb{Q}[x,y]/(x^2+y^2-1)$ is isomorphic to $\mathbb{Q}(t)$, see this question and also this question .",,"['abstract-algebra', 'ring-theory', 'commutative-algebra']"
11,"Sigma-Algebra: Is it an Algebra, Field, or Something Else?","Sigma-Algebra: Is it an Algebra, Field, or Something Else?",,"The Wikipedia page for $\sigma$-algebra says this set is called a ""sigma-algebra"" by some, and called a ""sigma-field"" by others. I'm writing a paper on measure theory, where the topic of sigma-algebra comes up, and wanted to use the correct term. So, I need to figure out which term is more appropriate: field or algebra? I recall from abstract algebra that the definition of a field is a commutative ring (which itself is a triple $(S,+,\times)$ where $+:S\times S \to S$ and $\times: S \times S \to S$ are binary operators satisfying a number of properties), so that every nonzero element has a multiplicative inverse. The classic example of a field is the rational numbers, $\mathbb{Q}$. The definition of an algebra, however, I do not recall learning. Wikipedia says an algebra is a vector space (which is itself a triple $(S,+,\cdot)$ where $+:S\times S \to S$ and $\cdot: \mathbb{R} \times S \to S$ are operators satisfying a number of properties) equipped with a bilinear product (what is this?). Now, I can't immediately see how EITHER of these definitions relate to a $\sigma$-algebra. Let's look at the definition. A collect $\Sigma$ of subsets of $S$ is a $\sigma$-algebra in $S$ if $S \in \Sigma$, $\Sigma$ is closed under complementation, and $\Sigma$ is closed under countable unions. So, we have the definitions of field, algebra and $\sigma$-algebra in front of us. I can't see how $\sigma$-algebra relates to either algebra or field. And back to the original question -- which name is more appropriate: ""sigma-algebra"" or ""sigma-field""? Thanks! Edit As an additional question: When defining the $\sigma$-blank, would it be rigorous to define an algebra first, and then teach $\sigma$-algebra as an example (special case) of an algebra? Edit 2 Thank you JHance for the awesome answer! With the new construction, let's show all the necessary properties are satisfied: Additive properties: $(A \cup B) - (A \cap B) = (B \cup A) - (B \cap A)$ (commutativity: $A+B=B+A$) $(A \cup 0) - (A \cap 0) = A - 0 =A$ (additive identity: $A+0=A$) $(A \cup A) - (A \cap A) = A - A =\emptyset$ (additive inverse: $A+A^{-1}=A$) Multiplicative properties: $A \cap B = B \cap A$ (commutativity: $A \times B = B \times A$) $(A \cap B) \cap C) = A \cap (B \cap C)$ (associativity: $(A \times B) \times C = A \times (B \times C)$) $A \cap X = A$ (multiplicative identity: $A \times 1 = A$) $A \cap \emptyset = \emptyset$ (that is, $A \times 0 = 0$) Distributive: $((A \cup B) - (A \cap B)) \cap C =...$","The Wikipedia page for $\sigma$-algebra says this set is called a ""sigma-algebra"" by some, and called a ""sigma-field"" by others. I'm writing a paper on measure theory, where the topic of sigma-algebra comes up, and wanted to use the correct term. So, I need to figure out which term is more appropriate: field or algebra? I recall from abstract algebra that the definition of a field is a commutative ring (which itself is a triple $(S,+,\times)$ where $+:S\times S \to S$ and $\times: S \times S \to S$ are binary operators satisfying a number of properties), so that every nonzero element has a multiplicative inverse. The classic example of a field is the rational numbers, $\mathbb{Q}$. The definition of an algebra, however, I do not recall learning. Wikipedia says an algebra is a vector space (which is itself a triple $(S,+,\cdot)$ where $+:S\times S \to S$ and $\cdot: \mathbb{R} \times S \to S$ are operators satisfying a number of properties) equipped with a bilinear product (what is this?). Now, I can't immediately see how EITHER of these definitions relate to a $\sigma$-algebra. Let's look at the definition. A collect $\Sigma$ of subsets of $S$ is a $\sigma$-algebra in $S$ if $S \in \Sigma$, $\Sigma$ is closed under complementation, and $\Sigma$ is closed under countable unions. So, we have the definitions of field, algebra and $\sigma$-algebra in front of us. I can't see how $\sigma$-algebra relates to either algebra or field. And back to the original question -- which name is more appropriate: ""sigma-algebra"" or ""sigma-field""? Thanks! Edit As an additional question: When defining the $\sigma$-blank, would it be rigorous to define an algebra first, and then teach $\sigma$-algebra as an example (special case) of an algebra? Edit 2 Thank you JHance for the awesome answer! With the new construction, let's show all the necessary properties are satisfied: Additive properties: $(A \cup B) - (A \cap B) = (B \cup A) - (B \cap A)$ (commutativity: $A+B=B+A$) $(A \cup 0) - (A \cap 0) = A - 0 =A$ (additive identity: $A+0=A$) $(A \cup A) - (A \cap A) = A - A =\emptyset$ (additive inverse: $A+A^{-1}=A$) Multiplicative properties: $A \cap B = B \cap A$ (commutativity: $A \times B = B \times A$) $(A \cap B) \cap C) = A \cap (B \cap C)$ (associativity: $(A \times B) \times C = A \times (B \times C)$) $A \cap X = A$ (multiplicative identity: $A \times 1 = A$) $A \cap \emptyset = \emptyset$ (that is, $A \times 0 = 0$) Distributive: $((A \cup B) - (A \cap B)) \cap C =...$",,"['abstract-algebra', 'field-theory']"
12,Let $G$ be any abelian group and $a\in{G}$. Show there exists a homomorphism $f:G\rightarrow{\mathbb{Q}/\mathbb{Z}}$ such that $f(a)\neq{0}$.,Let  be any abelian group and . Show there exists a homomorphism  such that .,G a\in{G} f:G\rightarrow{\mathbb{Q}/\mathbb{Z}} f(a)\neq{0},"Let $G$ be any abelian group and $a\in{G}$. Show there exists a homomorphism $f:G\rightarrow{\mathbb{Q}/\mathbb{Z}}$ such that $f(a)\neq{0}$. I can prove this question (I think) if I use the fact that $\mathbb{Q}/\mathbb{Z}$ is an injective abelian group: just define $f$ on the cyclic subgroup generated by $a$ and extend to $G$ via injectivity. However, I feel there should be a more 'elementary' way to prove this result, I just can't see one yet. One of my friends suggested using Zorn's Lemma, but I haven't done much with this information yet.","Let $G$ be any abelian group and $a\in{G}$. Show there exists a homomorphism $f:G\rightarrow{\mathbb{Q}/\mathbb{Z}}$ such that $f(a)\neq{0}$. I can prove this question (I think) if I use the fact that $\mathbb{Q}/\mathbb{Z}$ is an injective abelian group: just define $f$ on the cyclic subgroup generated by $a$ and extend to $G$ via injectivity. However, I feel there should be a more 'elementary' way to prove this result, I just can't see one yet. One of my friends suggested using Zorn's Lemma, but I haven't done much with this information yet.",,"['abstract-algebra', 'homological-algebra']"
13,Is the set of subrings of $\mathbb Z[X]$ countable?,Is the set of subrings of  countable?,\mathbb Z[X],"Initially, I was trying to look at the subrings of $\mathbb{Z}[X]$ . Since I have failed hard, I have tried to at least count them. So I have tried to build an injection from $\{0,1\}^\mathbb{N}$ to the set of subrings of $\mathbb{Z}[X]$ . Since $\{0,1\}^\mathbb{N}$ is uncountable, we would have the set of subrings of $\mathbb{Z}[X]$ uncountable too. By associating the sequence $(e_n)_{n\in\mathbb{N}}$ to the ring $\mathbb{Z}[1,p_1 e_1 X²,p_2 e_2 X^3,...]$ where $p_k$ is the $k$ -th prime number and $e_k\in\{0,1\}$ , it fails; for instance $\mathbb{Z}[1,2X²,3X^3,7X^5]$ is equal to $\mathbb{Z}[1,2X²,3X^3,7X^5,23X^{10}]$ because $X^{10}\in \mathbb{Z}[1,2X²,3X^3,7X^5]$ since $X^{10}=(7X^5 - (2X² * 3X^3))^2$ . I am unable to repair it, maybe it is flawed from the start. Actually, I do not even know if the set of subrings of $\mathbb{Z}[X]$ is uncountable. If possible I would like a proof or a reference to a proof see since I am curious about its countability.","Initially, I was trying to look at the subrings of . Since I have failed hard, I have tried to at least count them. So I have tried to build an injection from to the set of subrings of . Since is uncountable, we would have the set of subrings of uncountable too. By associating the sequence to the ring where is the -th prime number and , it fails; for instance is equal to because since . I am unable to repair it, maybe it is flawed from the start. Actually, I do not even know if the set of subrings of is uncountable. If possible I would like a proof or a reference to a proof see since I am curious about its countability.","\mathbb{Z}[X] \{0,1\}^\mathbb{N} \mathbb{Z}[X] \{0,1\}^\mathbb{N} \mathbb{Z}[X] (e_n)_{n\in\mathbb{N}} \mathbb{Z}[1,p_1 e_1 X²,p_2 e_2 X^3,...] p_k k e_k\in\{0,1\} \mathbb{Z}[1,2X²,3X^3,7X^5] \mathbb{Z}[1,2X²,3X^3,7X^5,23X^{10}] X^{10}\in \mathbb{Z}[1,2X²,3X^3,7X^5] X^{10}=(7X^5 - (2X² * 3X^3))^2 \mathbb{Z}[X]","['abstract-algebra', 'combinatorics', 'ring-theory', 'integers', 'polynomial-rings']"
14,The automorphism group of the real line with standard topology,The automorphism group of the real line with standard topology,,"How much is known about the automorphism group of the real line with the standard topology? I have been unable to find a reference for this question. Any information about $\mathrm{Aut}(\mathbb R)$ or its subgroups would be appreciated. The only subgroups I'm aware of are the isometry group $\mathrm{Iso}(\mathbb R)$ and the subgroups of $\mathrm{Iso}(\mathbb R)$. Edits 4/25/14: Just so it's clear, by ""the automorphism group $\mathrm{Aut}(\mathbb R)$"" I mean the set of all homeomorphisms $f : \mathbb R \to \mathbb R$ under function composition. So my main question is: What are some interesting subgroups of $\mathrm{Aut}(\mathbb R)$ which are not contained in $\mathrm{Iso}(\mathbb R)$?","How much is known about the automorphism group of the real line with the standard topology? I have been unable to find a reference for this question. Any information about $\mathrm{Aut}(\mathbb R)$ or its subgroups would be appreciated. The only subgroups I'm aware of are the isometry group $\mathrm{Iso}(\mathbb R)$ and the subgroups of $\mathrm{Iso}(\mathbb R)$. Edits 4/25/14: Just so it's clear, by ""the automorphism group $\mathrm{Aut}(\mathbb R)$"" I mean the set of all homeomorphisms $f : \mathbb R \to \mathbb R$ under function composition. So my main question is: What are some interesting subgroups of $\mathrm{Aut}(\mathbb R)$ which are not contained in $\mathrm{Iso}(\mathbb R)$?",,"['abstract-algebra', 'general-topology', 'reference-request']"
15,free groups: $F_X\cong F_Y\Rightarrow|X|=|Y|$,free groups:,F_X\cong F_Y\Rightarrow|X|=|Y|,"I'm reading Grillet's Abstract Algebra. Let $F_X$ denote the free group on the set $X$. I noticed on wiki the claim $$F_X\cong\!\!F_Y\Leftrightarrow|X|=|Y|.$$ How can I prove the right implication (find a bijection $f:X\rightarrow Y$), i.e. that the rank is an invariant of free groups? I am hoping for a simple and short proof , having all the tools of Grillet at hand. Rotman (Advanced Modern Algebra, p.305) proves it only for $|X|<\infty$, Bogopolski's (Introduction to Group Theory, p.55) proof seems (unnecessarily?) complicated, and Lyndon & Schupp's (Combinatorial Group Theory, p.1) proof I don't yet understand. It's the very first proposition in the book; in the proof, they say: The subgroup $N$ of $F$ generated by   all squares of elements in $F$ is   normal, and $F/N$ is an elementary   abelian $2$-group of rank $|X|$. (If   $X$ is finite, $|F/N|=2^{|X|}$ finite;   if $|X|$ is infinite, $|F/N|=|X|$). $\square$ Is $N:=\langle w^2;w\in F\rangle$? What is an abelian $2$-group? Elementary? What and how does the above quote really prove? I'm guessing a free abelian group on $X$ is $\langle X|[X,X]\rangle\cong\bigoplus\limits_{x\in X} \mathbb{Z}$? Can an isomorphism $\varphi:F_X\rightarrow F_Y$ not preserve the length of words? At least one letter words?","I'm reading Grillet's Abstract Algebra. Let $F_X$ denote the free group on the set $X$. I noticed on wiki the claim $$F_X\cong\!\!F_Y\Leftrightarrow|X|=|Y|.$$ How can I prove the right implication (find a bijection $f:X\rightarrow Y$), i.e. that the rank is an invariant of free groups? I am hoping for a simple and short proof , having all the tools of Grillet at hand. Rotman (Advanced Modern Algebra, p.305) proves it only for $|X|<\infty$, Bogopolski's (Introduction to Group Theory, p.55) proof seems (unnecessarily?) complicated, and Lyndon & Schupp's (Combinatorial Group Theory, p.1) proof I don't yet understand. It's the very first proposition in the book; in the proof, they say: The subgroup $N$ of $F$ generated by   all squares of elements in $F$ is   normal, and $F/N$ is an elementary   abelian $2$-group of rank $|X|$. (If   $X$ is finite, $|F/N|=2^{|X|}$ finite;   if $|X|$ is infinite, $|F/N|=|X|$). $\square$ Is $N:=\langle w^2;w\in F\rangle$? What is an abelian $2$-group? Elementary? What and how does the above quote really prove? I'm guessing a free abelian group on $X$ is $\langle X|[X,X]\rangle\cong\bigoplus\limits_{x\in X} \mathbb{Z}$? Can an isomorphism $\varphi:F_X\rightarrow F_Y$ not preserve the length of words? At least one letter words?",,"['abstract-algebra', 'group-theory', 'group-isomorphism', 'free-groups', 'group-presentation']"
16,"Prove that $2$, $3$, $1+ \sqrt{-5}$, and $1-\sqrt{-5}$ are irreducible in $\mathbb{Z}[\sqrt{-5}]$.","Prove that , , , and  are irreducible in .",2 3 1+ \sqrt{-5} 1-\sqrt{-5} \mathbb{Z}[\sqrt{-5}],"So the Norm for an element $\alpha = a + b\sqrt{-5}$ in $\mathbb{Z}[\sqrt{-5}]$ is defined as $N(\alpha) = a^2 + 5b^2$ and so i argue by contradiction assume there exists $\alpha$ such that $N(\alpha) = 2$ and so $a^2+5b^2 = 2$ , however, since $b^2$ and $a^2$ are both positive integers then $b=0$ and $a=\sqrt{2}$ however $a$ must be an integer and so no such $\alpha$ exists, same goes for $3$. I already proved that $N(\alpha\beta) = N(\alpha)N(\beta)$ for all $\alpha,\beta\in\mathbb{Z}[\sqrt{-5}]$. if $\alpha\mid\beta$ in $\mathbb{Z}[\sqrt{-5}]$, then $N(\alpha)\mid N(\beta)$ in $\mathbb{Z}$. $\alpha\in\mathbb{Z}[\sqrt{-5}]$ is a unit if and only if $N(\alpha)=1$. Show that there are no elements in $\mathbb{Z}[\sqrt{-5}]$ with $N(\alpha)=2$ or $N(\alpha)=3$. (I proved it above) Now I need to prove that $2$, $3$, $1+ \sqrt{-5}$, and $1-\sqrt{-5}$ are irreducible. So I also argue by contradiction, assume $1 + \sqrt{-5}$ is reducible then there must exists Non unit elements $\alpha,\beta \in \mathbb{Z}[\sqrt{-5}]$ such that $\alpha\beta = 1 + \sqrt{-5} $ and so $N(\alpha\beta) =N(\alpha)N(\beta)= N(1 + \sqrt{-5}) = 6$ but we already know that $N(\alpha) \neq 2$ or $3$ and so $N(\alpha) = 6$ and $N(\beta) = 1$ or vice verse , in any case this contradicts the fact that both $\alpha$ and $\beta$ are both non units.I just want to make sure i am on the right track here. And how can i prove that $2$, $3$, $1+ \sqrt{-5}$, and $1-\sqrt{-5}$ are not associate to each other.","So the Norm for an element $\alpha = a + b\sqrt{-5}$ in $\mathbb{Z}[\sqrt{-5}]$ is defined as $N(\alpha) = a^2 + 5b^2$ and so i argue by contradiction assume there exists $\alpha$ such that $N(\alpha) = 2$ and so $a^2+5b^2 = 2$ , however, since $b^2$ and $a^2$ are both positive integers then $b=0$ and $a=\sqrt{2}$ however $a$ must be an integer and so no such $\alpha$ exists, same goes for $3$. I already proved that $N(\alpha\beta) = N(\alpha)N(\beta)$ for all $\alpha,\beta\in\mathbb{Z}[\sqrt{-5}]$. if $\alpha\mid\beta$ in $\mathbb{Z}[\sqrt{-5}]$, then $N(\alpha)\mid N(\beta)$ in $\mathbb{Z}$. $\alpha\in\mathbb{Z}[\sqrt{-5}]$ is a unit if and only if $N(\alpha)=1$. Show that there are no elements in $\mathbb{Z}[\sqrt{-5}]$ with $N(\alpha)=2$ or $N(\alpha)=3$. (I proved it above) Now I need to prove that $2$, $3$, $1+ \sqrt{-5}$, and $1-\sqrt{-5}$ are irreducible. So I also argue by contradiction, assume $1 + \sqrt{-5}$ is reducible then there must exists Non unit elements $\alpha,\beta \in \mathbb{Z}[\sqrt{-5}]$ such that $\alpha\beta = 1 + \sqrt{-5} $ and so $N(\alpha\beta) =N(\alpha)N(\beta)= N(1 + \sqrt{-5}) = 6$ but we already know that $N(\alpha) \neq 2$ or $3$ and so $N(\alpha) = 6$ and $N(\beta) = 1$ or vice verse , in any case this contradicts the fact that both $\alpha$ and $\beta$ are both non units.I just want to make sure i am on the right track here. And how can i prove that $2$, $3$, $1+ \sqrt{-5}$, and $1-\sqrt{-5}$ are not associate to each other.",,"['abstract-algebra', 'number-theory', 'ring-theory', 'algebraic-number-theory', 'divisibility']"
17,If $|G| = p^n$ then $G$ has a subgroup of order $p^m$ for all $0\le m <n.$,If  then  has a subgroup of order  for all,|G| = p^n G p^m 0\le m <n.,"Prove that if $|G| = p^n$ then $G$ has a subgroup of order $p^m$ for all $0\le m <n.$ Since $G$ is of prime-power order I know $|Z(G)| \ne e$ so there is an $a\in Z(G)$ with order $p$ such that $p \mid |Z(G)|$. Now, the subgroup generated by is normal since it's a subgroup of the center. How can I get this normal subgroup to be less than $n$?","Prove that if $|G| = p^n$ then $G$ has a subgroup of order $p^m$ for all $0\le m <n.$ Since $G$ is of prime-power order I know $|Z(G)| \ne e$ so there is an $a\in Z(G)$ with order $p$ such that $p \mid |Z(G)|$. Now, the subgroup generated by is normal since it's a subgroup of the center. How can I get this normal subgroup to be less than $n$?",,"['abstract-algebra', 'group-theory', 'p-groups']"
18,Proofs of The Fundamental Theorem of Symmetric Polynomials,Proofs of The Fundamental Theorem of Symmetric Polynomials,,"I have been considering a few proofs of this theorem, and I noticed that a few of them (for example Proof 1 , and Proof 2 ) prove the theorem first for homogeneous symmetric polynomials and then generalise it. However I have seen other proofs which don't seem to require this step (e.g. Proof 3 ) and it seems to me superfluous. Could anyone explain why so many proofs include this step and/or if it is necessary?","I have been considering a few proofs of this theorem, and I noticed that a few of them (for example Proof 1 , and Proof 2 ) prove the theorem first for homogeneous symmetric polynomials and then generalise it. However I have seen other proofs which don't seem to require this step (e.g. Proof 3 ) and it seems to me superfluous. Could anyone explain why so many proofs include this step and/or if it is necessary?",,"['abstract-algebra', 'symmetric-polynomials']"
19,Showing $1+p$ is an element of order $p^{n-1}$ in $(\mathbb{Z}/p^n\mathbb{Z})^\times$,Showing  is an element of order  in,1+p p^{n-1} (\mathbb{Z}/p^n\mathbb{Z})^\times,"I'm trying to work through Dummit & Foote, but I've gotten stuck on the following question: Let $p$ be an odd prime and let $n$ be a positive integer. Use the   binomial theorem to show that $(1+p)^{p^{n-1}} \equiv 1\bmod{p^n}$ but   $(1+p)^{p^{n-2}} \not \equiv 1\bmod{p^n}$. Deduce that $1+p$ is an   element of order $p^{n-1}$ in the multiplicative group   $(\mathbb{Z}/p^n\mathbb{Z})^\times$. The trouble I'm having is mostly with respect to the first implication, since I'm not completely confident with what I've done so far.  I started by letting $m = p^{n-1}$ and $a_i = {m\choose i}/m$. I then ended up with  \begin{align*} (1+p)^m = \sum_{k=0}^{m} {m\choose k}p^k &= 1 + {m \choose 1}p + {m \choose 2}p^2 + \cdots + {m \choose m-1}p^{m-1} + p^m\\ &= 1 + mp + a_2mp^2 + a_3mp^3 + \cdots + a_{m-1}mp^{m-1}+ p^m\\ & = 1 + p^n + a_2p^{n+1} + a_3p^{n+2} + \cdots + p^m\\ &= 1 + p^n(1+ a_2p + a_3p^2+ \cdots + p^{m-n})\\ &\equiv 1 \bmod{p^n} \end{align*} ...but based on some numerical tests I did, the $a_i$'s aren't necessarily integers, so this doesn't work. Would someone please point out what I'm missing here? For the second implication, I can see a clean application of Euler's theorem starts things off. To finish, I'd like to show that no power of $(1+p)$ less than $(1+p)^{p^{n-1}}$ is congruent to $1\bmod{p^n}$, but I'm not sure how knowing the first part plays into this. Any pointers would be appreciated.","I'm trying to work through Dummit & Foote, but I've gotten stuck on the following question: Let $p$ be an odd prime and let $n$ be a positive integer. Use the   binomial theorem to show that $(1+p)^{p^{n-1}} \equiv 1\bmod{p^n}$ but   $(1+p)^{p^{n-2}} \not \equiv 1\bmod{p^n}$. Deduce that $1+p$ is an   element of order $p^{n-1}$ in the multiplicative group   $(\mathbb{Z}/p^n\mathbb{Z})^\times$. The trouble I'm having is mostly with respect to the first implication, since I'm not completely confident with what I've done so far.  I started by letting $m = p^{n-1}$ and $a_i = {m\choose i}/m$. I then ended up with  \begin{align*} (1+p)^m = \sum_{k=0}^{m} {m\choose k}p^k &= 1 + {m \choose 1}p + {m \choose 2}p^2 + \cdots + {m \choose m-1}p^{m-1} + p^m\\ &= 1 + mp + a_2mp^2 + a_3mp^3 + \cdots + a_{m-1}mp^{m-1}+ p^m\\ & = 1 + p^n + a_2p^{n+1} + a_3p^{n+2} + \cdots + p^m\\ &= 1 + p^n(1+ a_2p + a_3p^2+ \cdots + p^{m-n})\\ &\equiv 1 \bmod{p^n} \end{align*} ...but based on some numerical tests I did, the $a_i$'s aren't necessarily integers, so this doesn't work. Would someone please point out what I'm missing here? For the second implication, I can see a clean application of Euler's theorem starts things off. To finish, I'd like to show that no power of $(1+p)$ less than $(1+p)^{p^{n-1}}$ is congruent to $1\bmod{p^n}$, but I'm not sure how knowing the first part plays into this. Any pointers would be appreciated.",,"['abstract-algebra', 'modular-arithmetic']"
20,Unital homomorphism,Unital homomorphism,,What is a unital homomorphism? Why are they important?,What is a unital homomorphism? Why are they important?,,"['abstract-algebra', 'terminology', 'definition']"
21,Show a free group has no relations directly from the universal property,Show a free group has no relations directly from the universal property,,"The free group is often defined by its universal property. A group $F$ is said to be free on a subset $S$ with inclusion map $\iota : S \rightarrow F$ if for every group $G$ and set map $\phi:S \rightarrow G$ there exists a unique homomorphism $\overline{\phi}:F \rightarrow G$ such that $\overline{\phi} \circ \iota (s) = \phi (s)$ $ \forall s \in S$ . It is said that the existence of $\overline{\phi}$ is what determines there are no relations. My question is (without defining the (free) group of reduced words) can you show there are no relations just by picking groups G to map into? That is, can you show no reduced words on $S^{\pm1}$ (excluding the empty word) are equal to the identity element  in the free group? Example attempt: Suppose the reduced word $w$ is not the empty word, so it contains some letter $a$ . Suppose adding all the powers of $a$ in the word $w$ gives the integer $k$ . Define the set map $\phi : S \rightarrow \mathbb{Z}/( \lvert k \rvert +1)\mathbb{Z} $ by $\phi (s) = \left\{      \begin{array}{@{}l@{\thinspace}l}        0  & \text{ if } s \neq a\\        1 & \text{ if } s = a\\      \end{array}    \right.$ then the homomorphism from $F$ to $\mathbb{Z}/( \lvert k \rvert +1)\mathbb{Z}$ extending the set map $\phi$ sends $w$ to $k$ . As homomorphisms preserve group identities, and k is not the identity in $\mathbb{Z}/( \lvert k \rvert +1)\mathbb{Z}$ , then $w$ is not the identity in $F$ . This was my first idea, but fails because it misses the case where $k=0$ .","The free group is often defined by its universal property. A group is said to be free on a subset with inclusion map if for every group and set map there exists a unique homomorphism such that . It is said that the existence of is what determines there are no relations. My question is (without defining the (free) group of reduced words) can you show there are no relations just by picking groups G to map into? That is, can you show no reduced words on (excluding the empty word) are equal to the identity element  in the free group? Example attempt: Suppose the reduced word is not the empty word, so it contains some letter . Suppose adding all the powers of in the word gives the integer . Define the set map by then the homomorphism from to extending the set map sends to . As homomorphisms preserve group identities, and k is not the identity in , then is not the identity in . This was my first idea, but fails because it misses the case where .","F S \iota : S \rightarrow F G \phi:S \rightarrow G \overline{\phi}:F \rightarrow G \overline{\phi} \circ \iota (s) = \phi (s)  \forall s \in S \overline{\phi} S^{\pm1} w a a w k \phi : S \rightarrow \mathbb{Z}/( \lvert k \rvert +1)\mathbb{Z}  \phi (s) = \left\{
     \begin{array}{@{}l@{\thinspace}l}
       0  & \text{ if } s \neq a\\
       1 & \text{ if } s = a\\
     \end{array}
   \right. F \mathbb{Z}/( \lvert k \rvert +1)\mathbb{Z} \phi w k \mathbb{Z}/( \lvert k \rvert +1)\mathbb{Z} w F k=0","['abstract-algebra', 'group-theory', 'free-groups', 'combinatorial-group-theory', 'universal-property']"
22,$M$ is projective iff $M$ is locally free,is projective iff  is locally free,M M,"How to prove this theorem? A finitely presented module is projective iff it is locally free (the localization at every prime ideal is free over the localized ring). This is given right after the statement that a finitely generated module over a local ring is free. How to use it? If $M$ is a finitely presented projective module, then its localization $M_P$ is a module over a local ring. Is the localization again projective? If so, the statement I mentioned can be applied. For the other direction, the hint says to use that if $S$ is flat over $R$ and $M$ is finitely presented, then there is an isomorphism $$S\otimes_R Hom_R(M,N)\to Hom_S(S\otimes_R M, S\otimes_R N)$$ More specifically, the hint is to show that for any surjection $\phi: F\to M$ , the map $Hom_R(M,F)\to Hom_R(M,M)$ is also a surjection. But not only don't I see how to deduce that from the above, but also I'm not sure why this is enough to show.","How to prove this theorem? A finitely presented module is projective iff it is locally free (the localization at every prime ideal is free over the localized ring). This is given right after the statement that a finitely generated module over a local ring is free. How to use it? If is a finitely presented projective module, then its localization is a module over a local ring. Is the localization again projective? If so, the statement I mentioned can be applied. For the other direction, the hint says to use that if is flat over and is finitely presented, then there is an isomorphism More specifically, the hint is to show that for any surjection , the map is also a surjection. But not only don't I see how to deduce that from the above, but also I'm not sure why this is enough to show.","M M_P S R M S\otimes_R Hom_R(M,N)\to Hom_S(S\otimes_R M, S\otimes_R N) \phi: F\to M Hom_R(M,F)\to Hom_R(M,M)","['abstract-algebra', 'commutative-algebra', 'modules', 'projective-module']"
23,"Finite dimensional division algebras over the reals other than $\mathbb{R},\mathbb{C},\mathbb{H},$ or $\mathbb{O}$",Finite dimensional division algebras over the reals other than  or,"\mathbb{R},\mathbb{C},\mathbb{H}, \mathbb{O}","Have all the finite-dimensional division algebras over the reals been discovered/classified? The are many layman accessible sources on the web describing different properties of such algebras, but all the ones I have come across seem to stop short of fully restricting them to $\mathbb{R},\mathbb{C},\mathbb{H},$ or $\mathbb{O}$, yet do not mention the existence of anything beyond those four. The wikipedia page on division algebras mentions that any finite-dimensional division algebra over the reals must be of dimension 1, 2, 4, or 8.   It also mentions the only finite-dimensional division algebras over the real numbers which are alternative algebras are the real numbers themselves, the complex numbers, the quaternions, and the octonions. (And this claims we don't even need the finite-dimensional qualifier for the last statement.) Hurwitz's theorem tells us that these are also the only normed unital division algebras over the reals. So any finite dimensional division algebra over the reals other than $\mathbb{R},\mathbb{C},\mathbb{H},$ or $\mathbb{O}$ cannot have a norm if it is unital, nor have a matrix representation, nor even be alternative.  Are there any known examples?  Have all the possibilities been classified?","Have all the finite-dimensional division algebras over the reals been discovered/classified? The are many layman accessible sources on the web describing different properties of such algebras, but all the ones I have come across seem to stop short of fully restricting them to $\mathbb{R},\mathbb{C},\mathbb{H},$ or $\mathbb{O}$, yet do not mention the existence of anything beyond those four. The wikipedia page on division algebras mentions that any finite-dimensional division algebra over the reals must be of dimension 1, 2, 4, or 8.   It also mentions the only finite-dimensional division algebras over the real numbers which are alternative algebras are the real numbers themselves, the complex numbers, the quaternions, and the octonions. (And this claims we don't even need the finite-dimensional qualifier for the last statement.) Hurwitz's theorem tells us that these are also the only normed unital division algebras over the reals. So any finite dimensional division algebra over the reals other than $\mathbb{R},\mathbb{C},\mathbb{H},$ or $\mathbb{O}$ cannot have a norm if it is unital, nor have a matrix representation, nor even be alternative.  Are there any known examples?  Have all the possibilities been classified?",,"['abstract-algebra', 'real-numbers', 'division-algebras']"
24,Prove the increasing union of ideals is an ideal,Prove the increasing union of ideals is an ideal,,prove that $I_{1} \subseteq I_{2} \subseteq I_{3} \subseteq....$ are ideals of $R$ then $\bigcup_{n =1} I_n$ is an ideal of $R$. I am having a hard time picture this in my mind. Help anyone.,prove that $I_{1} \subseteq I_{2} \subseteq I_{3} \subseteq....$ are ideals of $R$ then $\bigcup_{n =1} I_n$ is an ideal of $R$. I am having a hard time picture this in my mind. Help anyone.,,"['abstract-algebra', 'ring-theory', 'ideals']"
25,Irrational solutions to some equations in two variables,Irrational solutions to some equations in two variables,,"The next statement is a conjecture of mine, so I dont know if it's true (though quite sure): Let $x,y$ be irrational numbers such that $x^4+y^4=1$. Prove (or disprove) that $x^5+y^5$ is irrational or $x^6+y^6$ is irrational (or both of them are irrational). Edit: just to remove any doubt, my meaning is to prove that at least one of the numbers $x^5+y^5$ and $x^6+y^6$ has to be irrational.","The next statement is a conjecture of mine, so I dont know if it's true (though quite sure): Let $x,y$ be irrational numbers such that $x^4+y^4=1$. Prove (or disprove) that $x^5+y^5$ is irrational or $x^6+y^6$ is irrational (or both of them are irrational). Edit: just to remove any doubt, my meaning is to prove that at least one of the numbers $x^5+y^5$ and $x^6+y^6$ has to be irrational.",,"['abstract-algebra', 'number-theory']"
26,Total ordering on the free group,Total ordering on the free group,,"The free groups can be totally (bi-)ordered. This paper shows how to do it (page 4). In short, you embed the group in multiplicative structure of the ring of power series in non-commuting variables, order those and transfer the ordering back to the free group via the inverse of the embedding. Is it possible to explain this order intrinsically, without reference to power series in non-commuting variables? It would be enough for me to understand this order for the free group on two generators. In particular, what is the positive cone of this ordered group? In terms of the power series representation it's the series in which the first non-zero coefficient is negative. But how do you see this in a word on $\{x,y\}$?","The free groups can be totally (bi-)ordered. This paper shows how to do it (page 4). In short, you embed the group in multiplicative structure of the ring of power series in non-commuting variables, order those and transfer the ordering back to the free group via the inverse of the embedding. Is it possible to explain this order intrinsically, without reference to power series in non-commuting variables? It would be enough for me to understand this order for the free group on two generators. In particular, what is the positive cone of this ordered group? In terms of the power series representation it's the series in which the first non-zero coefficient is negative. But how do you see this in a word on $\{x,y\}$?",,"['abstract-algebra', 'group-theory', 'order-theory', 'noncommutative-algebra', 'free-groups']"
27,"Find intermediate fields of $\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, | \, \mathbb{Q}(i)$",Find intermediate fields of,"\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, | \, \mathbb{Q}(i)","This is the problem I am facing: Compute the intermediate fields of the extension $K | \mathbb{Q}(i)$   where $K = \mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i)$ and find the   intermediate fields $M$ such that $M | \mathbb{Q}(i)$ is a Galois   extension. What I have done: I start by thinking about the grade of the extension $[\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, : \, \mathbb{Q}(i)]$ $[\mathbb{Q}(\sqrt{3},i) \, : \, \mathbb{Q}(i)] = 2$ because the irreducible polinomial of $\sqrt{3}$ over $\mathbb{Q}(i)$ is $x^2 -3$ (since $\sqrt{3} \notin \mathbb{Q}(i)$ $[\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, : \, \mathbb{Q}(\sqrt{3},i)] = 3$ because the irreducible polinomial of $\sqrt[3]{2}$ over $\mathbb{Q}(\sqrt{3},i)$ is $x^3 -2$ (*) Hence, $[\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, : \, \mathbb{Q}(i)] =[\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, : \, \mathbb{Q}(\sqrt{3},i)] * [\mathbb{Q}(\sqrt{3},i) \, : \, \mathbb{Q}(i)] = 3 * 2 = 6$ Now, a $\mathbb{Q}(i) $-base for $\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i)$ is $\{ 1, \sqrt[3]{2} \, \xi , \sqrt[3]{2} \, \xi^2, \sqrt{3} ,\sqrt{3}  \sqrt[3]{2} \, \xi , \sqrt{3} \sqrt[3]{2} \, \xi^2 \}$ The non-linear elements whose images fix every $\sigma \in \textrm{Gal}(\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, | \, \mathbb{Q}(i))$ are: $$ \sqrt{3} \to \pm \sqrt{3}$$ $$ \sqrt[3]{2} \to \{\sqrt[3]{2}, \sqrt[3]{2} \, \xi, \sqrt[3]{2} \, \xi ^2 \}$$ The extension $\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, | \, \mathbb{Q}(i)$ is a Galois extension (it is normal(splitting field of $(x^3-2)(x^2-3)$, separable (char($\mathbb{Q}(i)$) = 0) and finite) so $| \textrm{Gal}(\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, | \, \mathbb{Q}(i)) | = 6$ which means that all the options are valid. I am stuck here, how can I determine the Galois group, and the normal subgroups (and then, how to extract the matching fields for those subgroups?) (*) How to show justify this?","This is the problem I am facing: Compute the intermediate fields of the extension $K | \mathbb{Q}(i)$   where $K = \mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i)$ and find the   intermediate fields $M$ such that $M | \mathbb{Q}(i)$ is a Galois   extension. What I have done: I start by thinking about the grade of the extension $[\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, : \, \mathbb{Q}(i)]$ $[\mathbb{Q}(\sqrt{3},i) \, : \, \mathbb{Q}(i)] = 2$ because the irreducible polinomial of $\sqrt{3}$ over $\mathbb{Q}(i)$ is $x^2 -3$ (since $\sqrt{3} \notin \mathbb{Q}(i)$ $[\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, : \, \mathbb{Q}(\sqrt{3},i)] = 3$ because the irreducible polinomial of $\sqrt[3]{2}$ over $\mathbb{Q}(\sqrt{3},i)$ is $x^3 -2$ (*) Hence, $[\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, : \, \mathbb{Q}(i)] =[\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, : \, \mathbb{Q}(\sqrt{3},i)] * [\mathbb{Q}(\sqrt{3},i) \, : \, \mathbb{Q}(i)] = 3 * 2 = 6$ Now, a $\mathbb{Q}(i) $-base for $\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i)$ is $\{ 1, \sqrt[3]{2} \, \xi , \sqrt[3]{2} \, \xi^2, \sqrt{3} ,\sqrt{3}  \sqrt[3]{2} \, \xi , \sqrt{3} \sqrt[3]{2} \, \xi^2 \}$ The non-linear elements whose images fix every $\sigma \in \textrm{Gal}(\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, | \, \mathbb{Q}(i))$ are: $$ \sqrt{3} \to \pm \sqrt{3}$$ $$ \sqrt[3]{2} \to \{\sqrt[3]{2}, \sqrt[3]{2} \, \xi, \sqrt[3]{2} \, \xi ^2 \}$$ The extension $\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, | \, \mathbb{Q}(i)$ is a Galois extension (it is normal(splitting field of $(x^3-2)(x^2-3)$, separable (char($\mathbb{Q}(i)$) = 0) and finite) so $| \textrm{Gal}(\mathbb{Q}(\sqrt[3]{2}, \sqrt{3},i) \, | \, \mathbb{Q}(i)) | = 6$ which means that all the options are valid. I am stuck here, how can I determine the Galois group, and the normal subgroups (and then, how to extract the matching fields for those subgroups?) (*) How to show justify this?",,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field']"
28,What's the use of composition series in group theory?,What's the use of composition series in group theory?,,"I'm going through Dummit & Foote, and I stumbled upon a definition of composition series (for groups) and Jordan-Holder theorem.  I get the ''it's something like a factoring of a group'' intuition that authors try to give, but that's a little bit too vague for me. There are no exercises (after that chapter) where we use composition series to prove something interesting about groups (that kind of exercises usually illuminates definitions that seem unnecessary at first). Factoring of an integer can give us a lot of information about that number, but I can't really see what kind of information composition series and composition factors give us... Can someone make this clearer for me? Give more motivation to this definition or some examples of usage of composition series?","I'm going through Dummit & Foote, and I stumbled upon a definition of composition series (for groups) and Jordan-Holder theorem.  I get the ''it's something like a factoring of a group'' intuition that authors try to give, but that's a little bit too vague for me. There are no exercises (after that chapter) where we use composition series to prove something interesting about groups (that kind of exercises usually illuminates definitions that seem unnecessary at first). Factoring of an integer can give us a lot of information about that number, but I can't really see what kind of information composition series and composition factors give us... Can someone make this clearer for me? Give more motivation to this definition or some examples of usage of composition series?",,"['abstract-algebra', 'group-theory']"
29,On 'backslash-forward slash' notation,On 'backslash-forward slash' notation,,"I am curious about a notation that I have seen, but I have only seen it in contexts beyond my current level of ability and so haven't learned its meaning.  Also, it's often difficult to search for the meaning of notations.  It appears to be group theoretic in nature. The notation uses a backslash followed by a forward slash, like so: $\text{SL}_n\mathbb{Z} \setminus \text{SL}_n\mathbb{R} \,/ \,\text{SO}(n)$. Of course it may be a 'set minus' followed by a 'modded by', but I'm not so sure.  So what's the meaning of this notation, and in what contexts is it most often used?  Thanks.","I am curious about a notation that I have seen, but I have only seen it in contexts beyond my current level of ability and so haven't learned its meaning.  Also, it's often difficult to search for the meaning of notations.  It appears to be group theoretic in nature. The notation uses a backslash followed by a forward slash, like so: $\text{SL}_n\mathbb{Z} \setminus \text{SL}_n\mathbb{R} \,/ \,\text{SO}(n)$. Of course it may be a 'set minus' followed by a 'modded by', but I'm not so sure.  So what's the meaning of this notation, and in what contexts is it most often used?  Thanks.",,"['abstract-algebra', 'group-theory', 'notation', 'terminology', 'lie-groups']"
30,"Universal property of free module, ""converse""","Universal property of free module, ""converse""",,"Let $F$ be a free $R$-module with a basis $B$. We know that $B$ satisfies the following property: For any $R$-module $M$ and any $g:B\rightarrow M$, there exists a unique $R$-map $\varphi:F\rightarrow M$ that extends $g$. Now suppose that $F$ is any $R$-module and $B$ is any subset of $F$. If $B$ satisfies the above property, is $B$ a basis of $F$? I think this is true for vector spaces. If $B$ doesn't span $F$ then there is no unique extension of $g$, and if $B$ is linearly dependent then the extension might not exist at all. But I'm having trouble extending my reasoning to modules, due to the lack of division and the presence of torsion elements.","Let $F$ be a free $R$-module with a basis $B$. We know that $B$ satisfies the following property: For any $R$-module $M$ and any $g:B\rightarrow M$, there exists a unique $R$-map $\varphi:F\rightarrow M$ that extends $g$. Now suppose that $F$ is any $R$-module and $B$ is any subset of $F$. If $B$ satisfies the above property, is $B$ a basis of $F$? I think this is true for vector spaces. If $B$ doesn't span $F$ then there is no unique extension of $g$, and if $B$ is linearly dependent then the extension might not exist at all. But I'm having trouble extending my reasoning to modules, due to the lack of division and the presence of torsion elements.",,"['abstract-algebra', 'modules']"
31,Book(s) Request to Prepare for Algebraic Number Theory,Book(s) Request to Prepare for Algebraic Number Theory,,"I would appreciate suggestions for books to enhance my learning in algebra so as to be able to read Samuel's ""Algebraic Theory of Numbers"" and eventually at least begin Neukirch's ""Algebraic Number Theory."" By way of background, I have gone through B. Gross's Harvard lectures on algebra several times. They were correlated to Artin, and included factoring and quadratic number fields, but did not cover modules or fields. Nor Galois Theory. So I would like to get a good exposure to those areas that are particularly germane to ANT. (E.g. Artin does not have anything on perfect fields and only mentions algebraic closure in a short paragraph before the Fundamental Theory of Algebra. Thanks very much.","I would appreciate suggestions for books to enhance my learning in algebra so as to be able to read Samuel's ""Algebraic Theory of Numbers"" and eventually at least begin Neukirch's ""Algebraic Number Theory."" By way of background, I have gone through B. Gross's Harvard lectures on algebra several times. They were correlated to Artin, and included factoring and quadratic number fields, but did not cover modules or fields. Nor Galois Theory. So I would like to get a good exposure to those areas that are particularly germane to ANT. (E.g. Artin does not have anything on perfect fields and only mentions algebraic closure in a short paragraph before the Fundamental Theory of Algebra. Thanks very much.",,['abstract-algebra']
32,Can one avoid AC in the proof that in Noetherian rings there is a maximal element for each set?,Can one avoid AC in the proof that in Noetherian rings there is a maximal element for each set?,,"More specifically, I just want to prove that in a Noetherian (even Dedekind) ring, every ideal in contained in a maximal ideal. Is the axiom oh choice needed here? The usual proofs (for general rings use Zorn's lemma; for Noetherian rings one can build an infinite ascending chain if there is no maximal element) seem to rely on it. If the axiom of dependent choice can be avoided as well, even better.","More specifically, I just want to prove that in a Noetherian (even Dedekind) ring, every ideal in contained in a maximal ideal. Is the axiom oh choice needed here? The usual proofs (for general rings use Zorn's lemma; for Noetherian rings one can build an infinite ascending chain if there is no maximal element) seem to rely on it. If the axiom of dependent choice can be avoided as well, even better.",,"['abstract-algebra', 'axiom-of-choice']"
33,No group of order 36 is simple,No group of order 36 is simple,,"Fraleigh(7ed) Example37.14 No group of order 36 is simple. Such a group $G$ has either $1$ or $4$ subgroups of order $9$. If there is only one such subgroup, it is normal in $G$. If there are four such subgroups, let $H$ and $K$ be two of them. $H \cap K$ must have at least $3$ elements, or $HK$ would have to have $81$ elements, from $|HK|=|H||K|/|H\cap K|$. Thus the normalizer of $H \cap K$ has as order a multiple of $>1$ of $9$ and a divisor of $36$; hence the order must be either $18$ or $36$. If the order is $18$, the normalizer is then of index $2$ and therefore is normal in $G$. If the order is $36$, then $ H \cap K$ is normal in $G$. I don't understand the highlighted sentence. It must be from that $N(H \cap K) \supset H$ (or $K$), but why $H\cap K$ is normal in $H$ or $K$? I guess it must be from the first Sylow thoerem(below). But the first Sylow theorem seems to state that $H\cap K$ is a normal subgroup of a subgroup of order $9$ , not necessariliy $H$ or $K$, maybe other than $H$ and $K$. How can I conclude that $H \cap K$ is a normal subgroup of $H$ or $K$? First Sylow Theorem Let $G$ be a finite group and let $|G|=p^n m$ where $n\ge1$ and where $p$ does not divide $m$. Then 1. $G$ contains a subgroup of order $p^i$ for each $i$ where $1 \le i \le n$ 2. every subgroup $H$ of $G$ of order $p^i$ is a normal subgroup of a subgroup of order $p^{i+1}$ for $1\le i<n$ Edit: It was very easy. By the first Sylow theorem, $H \cap K$ is a normal subgroup of a subgroup of order $9$, not necessarily $H$ or $K$. But it is still true that $N(H \cap K)$ contains a subgroup of order $9$, so $N(H\cap K)$ has as order a multiple of $9$.","Fraleigh(7ed) Example37.14 No group of order 36 is simple. Such a group $G$ has either $1$ or $4$ subgroups of order $9$. If there is only one such subgroup, it is normal in $G$. If there are four such subgroups, let $H$ and $K$ be two of them. $H \cap K$ must have at least $3$ elements, or $HK$ would have to have $81$ elements, from $|HK|=|H||K|/|H\cap K|$. Thus the normalizer of $H \cap K$ has as order a multiple of $>1$ of $9$ and a divisor of $36$; hence the order must be either $18$ or $36$. If the order is $18$, the normalizer is then of index $2$ and therefore is normal in $G$. If the order is $36$, then $ H \cap K$ is normal in $G$. I don't understand the highlighted sentence. It must be from that $N(H \cap K) \supset H$ (or $K$), but why $H\cap K$ is normal in $H$ or $K$? I guess it must be from the first Sylow thoerem(below). But the first Sylow theorem seems to state that $H\cap K$ is a normal subgroup of a subgroup of order $9$ , not necessariliy $H$ or $K$, maybe other than $H$ and $K$. How can I conclude that $H \cap K$ is a normal subgroup of $H$ or $K$? First Sylow Theorem Let $G$ be a finite group and let $|G|=p^n m$ where $n\ge1$ and where $p$ does not divide $m$. Then 1. $G$ contains a subgroup of order $p^i$ for each $i$ where $1 \le i \le n$ 2. every subgroup $H$ of $G$ of order $p^i$ is a normal subgroup of a subgroup of order $p^{i+1}$ for $1\le i<n$ Edit: It was very easy. By the first Sylow theorem, $H \cap K$ is a normal subgroup of a subgroup of order $9$, not necessarily $H$ or $K$. But it is still true that $N(H \cap K)$ contains a subgroup of order $9$, so $N(H\cap K)$ has as order a multiple of $9$.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
34,The Mittag-Leffler condition and $\varprojlim^1$,The Mittag-Leffler condition and,\varprojlim^1,"Recall that an inverse system of abelian groups $$\cdots \rightarrow G_2 \stackrel{\alpha_2}{\rightarrow} G_1 \stackrel{\alpha_1}{\rightarrow} G_0$$ is said to satisfy the Mittag-Leffler condition if, for each $i$, there exists a number $N$ such that the image of $G_{i+n} \rightarrow G_i$ is invariant for all $n \geq N$ (the map is obviously the composition $\alpha_{i+n} \circ \cdots \circ \alpha_{i+1}$). I'm trying to show that, given a system that satisfies this condition, $\varprojlim^1G_i = 0$. Recall that $\varprojlim^1 G_i$ is defined to be the cokernel of the map $$\delta \colon \prod_i G_i \rightarrow \prod_i G_i$$ given by $(\ldots, g_i, \ldots) \mapsto (\ldots, g_i - \alpha_{i+1}(g_{i+1}), \ldots)$. I've spent a half-hour trying to show that $\delta$ is surjective, but I haven't gotten very far with it. I don't actually need this result right now - all the morphisms in the inverse system i'm consider are surjective, and it's trivial to show that $\varprojlim^1$ dies in this case - so I'm just going to leave it and move on for now, but does anybody have a proof they could share? I feel as if it only needs a little thought brought to bear on it, but thought is a rare commodity on Friday afternoons... $\ddot \smile$","Recall that an inverse system of abelian groups $$\cdots \rightarrow G_2 \stackrel{\alpha_2}{\rightarrow} G_1 \stackrel{\alpha_1}{\rightarrow} G_0$$ is said to satisfy the Mittag-Leffler condition if, for each $i$, there exists a number $N$ such that the image of $G_{i+n} \rightarrow G_i$ is invariant for all $n \geq N$ (the map is obviously the composition $\alpha_{i+n} \circ \cdots \circ \alpha_{i+1}$). I'm trying to show that, given a system that satisfies this condition, $\varprojlim^1G_i = 0$. Recall that $\varprojlim^1 G_i$ is defined to be the cokernel of the map $$\delta \colon \prod_i G_i \rightarrow \prod_i G_i$$ given by $(\ldots, g_i, \ldots) \mapsto (\ldots, g_i - \alpha_{i+1}(g_{i+1}), \ldots)$. I've spent a half-hour trying to show that $\delta$ is surjective, but I haven't gotten very far with it. I don't actually need this result right now - all the morphisms in the inverse system i'm consider are surjective, and it's trivial to show that $\varprojlim^1$ dies in this case - so I'm just going to leave it and move on for now, but does anybody have a proof they could share? I feel as if it only needs a little thought brought to bear on it, but thought is a rare commodity on Friday afternoons... $\ddot \smile$",,['abstract-algebra']
35,"Why are Lie algebras ""rigid"" objects?","Why are Lie algebras ""rigid"" objects?",,"I read the following motivation for quantum groups on wikipedia : The discovery of quantum groups was quite unexpected, since it was known for a long time that compact groups and semisimple Lie algebras are ""rigid"" objects, in other words, they cannot be ""deformed"". Why is that? Could one point me towards the concerned theorems?","I read the following motivation for quantum groups on wikipedia : The discovery of quantum groups was quite unexpected, since it was known for a long time that compact groups and semisimple Lie algebras are ""rigid"" objects, in other words, they cannot be ""deformed"". Why is that? Could one point me towards the concerned theorems?",,"['abstract-algebra', 'soft-question', 'lie-groups', 'lie-algebras']"
36,Some basic book to start with modules?,Some basic book to start with modules?,,"I am very interested in studying modules, which I have studied algebra, is basic theory of groups and rings, of Hungerford and Dummit. I was reading the Dummit the module, but I still struggled a bit in the section and the tensor product of exact sequences, as in the book of Atiyah. They know a simple book to begin with?","I am very interested in studying modules, which I have studied algebra, is basic theory of groups and rings, of Hungerford and Dummit. I was reading the Dummit the module, but I still struggled a bit in the section and the tensor product of exact sequences, as in the book of Atiyah. They know a simple book to begin with?",,"['abstract-algebra', 'reference-request', 'modules', 'book-recommendation']"
37,Hom of finitely generated modules over a noetherian ring,Hom of finitely generated modules over a noetherian ring,,"This is an exercise from Rotman, An Introduction to Homological Algebra , which I've been thinking now and then for a few days and I haven't solved it yet. I've decided to ask here because it is bugging me and I don't have any friends also studying this subject (in case it is of any use, I'm an undergraduate). Let $R$ be a commutative noetherian ring. If $A$, $B$ are finitely generated $R$-modules, then $\operatorname{Hom}_R(A,B)$ is a finitely generated $R$-module. Here's what I've thought as of yet (maybe the problem is that I haven't been trying to apply the useful theorems...): First of all, since $R$ is noetherian, it suffices to inject $\operatorname{Hom}_R(A,B)$ into some finitely generated module (in noetherian rings, submodules of f.g. are f.g.). Now, since $R$ is commutative (or since $R$ is noetherian), a finitely generated $R$-module is a quotient of $R^n$ for some $n$. Then let us write $A\simeq \frac{R^n}{I}$ and $B\simeq \frac{R^m}{J}$. Now we've got: $\operatorname{Hom}_R(A,B)\simeq \operatorname{Hom}_R\left(\frac{R^n}{I},\frac{R^m}{J}\right)$. If I had $\operatorname{Hom}_R\left(\frac{R^n}{I},\frac{R^m}{J}\right) \hookrightarrow \operatorname{Hom}_R(R^n, R^m)$ (this is what I tend to think is the wrong direction, but a interesting question-rising path nevertheless) then it would be over since $\operatorname{Hom}_R(R^n, R^m)\simeq R^{nm}$ which is finitely generated. So I ask myself: can I see $\frac{R^n}{I}$ as a submodule of $R^n$? Because if I could, then doing the same thing for $R^m$ and passing it to the hom, then it would be over. Now, this would be true if the sequence $$0\to I\hookrightarrow R^n\to \frac{R^n}{I} \to 0$$ split. But this (of course) doesn't always happen. But if I somehow had the third module to be projective, or the first one to be injective, then it would happen. But why would, for example, be $\frac{R^n}{I}$ be projective? And this is where I got stuck. I'm sorry if this is overly detailed, but I remember reading that it is always good, when asking about a textbook question, to add what you've thought up to that moment. Also, even if my thoughts don't lead to the solution, I would like to know if they are correct!","This is an exercise from Rotman, An Introduction to Homological Algebra , which I've been thinking now and then for a few days and I haven't solved it yet. I've decided to ask here because it is bugging me and I don't have any friends also studying this subject (in case it is of any use, I'm an undergraduate). Let $R$ be a commutative noetherian ring. If $A$, $B$ are finitely generated $R$-modules, then $\operatorname{Hom}_R(A,B)$ is a finitely generated $R$-module. Here's what I've thought as of yet (maybe the problem is that I haven't been trying to apply the useful theorems...): First of all, since $R$ is noetherian, it suffices to inject $\operatorname{Hom}_R(A,B)$ into some finitely generated module (in noetherian rings, submodules of f.g. are f.g.). Now, since $R$ is commutative (or since $R$ is noetherian), a finitely generated $R$-module is a quotient of $R^n$ for some $n$. Then let us write $A\simeq \frac{R^n}{I}$ and $B\simeq \frac{R^m}{J}$. Now we've got: $\operatorname{Hom}_R(A,B)\simeq \operatorname{Hom}_R\left(\frac{R^n}{I},\frac{R^m}{J}\right)$. If I had $\operatorname{Hom}_R\left(\frac{R^n}{I},\frac{R^m}{J}\right) \hookrightarrow \operatorname{Hom}_R(R^n, R^m)$ (this is what I tend to think is the wrong direction, but a interesting question-rising path nevertheless) then it would be over since $\operatorname{Hom}_R(R^n, R^m)\simeq R^{nm}$ which is finitely generated. So I ask myself: can I see $\frac{R^n}{I}$ as a submodule of $R^n$? Because if I could, then doing the same thing for $R^m$ and passing it to the hom, then it would be over. Now, this would be true if the sequence $$0\to I\hookrightarrow R^n\to \frac{R^n}{I} \to 0$$ split. But this (of course) doesn't always happen. But if I somehow had the third module to be projective, or the first one to be injective, then it would happen. But why would, for example, be $\frac{R^n}{I}$ be projective? And this is where I got stuck. I'm sorry if this is overly detailed, but I remember reading that it is always good, when asking about a textbook question, to add what you've thought up to that moment. Also, even if my thoughts don't lead to the solution, I would like to know if they are correct!",,"['abstract-algebra', 'modules', 'homological-algebra']"
38,An abelian subgroup of symmetric group,An abelian subgroup of symmetric group,,"PROBLEM: Let $G$ be an abelian subgroup of the symmetric group $S_n$ and $p_1, . . . , p_k$ be all prime divisors of $|G|$. Prove that $n≥p_1 +···+p_k$. QUESTION: How do you solve this problem. I've thought about using the Sylow theorems but I can't seem to get the final inequality.","PROBLEM: Let $G$ be an abelian subgroup of the symmetric group $S_n$ and $p_1, . . . , p_k$ be all prime divisors of $|G|$. Prove that $n≥p_1 +···+p_k$. QUESTION: How do you solve this problem. I've thought about using the Sylow theorems but I can't seem to get the final inequality.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups']"
39,Are There Always More Conjugacy Classes in the Kernel of a Morphism to $\Bbb Z_2$ than Not?,Are There Always More Conjugacy Classes in the Kernel of a Morphism to  than Not?,\Bbb Z_2,"Let $G$ be a finite group and let $\phi:G\to\Bbb Z_2$ be a homomorphism to the group with two elements. Is it always the case that there are at least as many conjugacy classes in the kernel of $\phi$ as conjugacy classes not in the kernel of $\phi$ ? I've tried a little bit of messing around algebraically and written down some exact sequences of $G$ -modules to try to apply the methods of group cohomology, but I haven't gotten anything to work. My inspiration here is the special case when $G$ is the symmetric group $S_n$ and $\phi$ is the sign homomorphism. In this case conjugacy classes of $G$ correspond to partitions, and the problem becomes about counting partitions of $n$ with an even number of even parts versus an odd number of even parts. I was able to prove (via generating functions and also bijectively) that the number of partitions of $n$ with an even number of even parts minus the number of partitions of $n$ with an odd number of even parts is equal to the number of partitions of $n$ with all parts odd and distinct. I could not find a reference for this fact after some googling, so I would be interested to know if this is a well-known partition identity. I'm also interested in possible extensions of this problem where $\Bbb Z_2$ is replaced by another group $H$ (possibly required to be abelian).","Let be a finite group and let be a homomorphism to the group with two elements. Is it always the case that there are at least as many conjugacy classes in the kernel of as conjugacy classes not in the kernel of ? I've tried a little bit of messing around algebraically and written down some exact sequences of -modules to try to apply the methods of group cohomology, but I haven't gotten anything to work. My inspiration here is the special case when is the symmetric group and is the sign homomorphism. In this case conjugacy classes of correspond to partitions, and the problem becomes about counting partitions of with an even number of even parts versus an odd number of even parts. I was able to prove (via generating functions and also bijectively) that the number of partitions of with an even number of even parts minus the number of partitions of with an odd number of even parts is equal to the number of partitions of with all parts odd and distinct. I could not find a reference for this fact after some googling, so I would be interested to know if this is a well-known partition identity. I'm also interested in possible extensions of this problem where is replaced by another group (possibly required to be abelian).",G \phi:G\to\Bbb Z_2 \phi \phi G G S_n \phi G n n n n \Bbb Z_2 H,"['abstract-algebra', 'combinatorics', 'group-theory', 'finite-groups', 'group-cohomology']"
40,Weibel HA Exercise 1.5.9,Weibel HA Exercise 1.5.9,,I cannot solve the following problem from Weibel: Let $f:B\to C$ be a map of chain complexes. Show that the natural maps $\alpha : \ker(f)[-1]\to \operatorname{cone}(f)$ and $\beta: \operatorname{cone}(f)\to \operatorname{coker}(f)$ give rise to a long exact sequence:   $$\cdots \to H_{n-1}(\ker(f))\to H_n(\operatorname{cone}(f))\to H_n(\operatorname{coker}(f))\to H_{n-2}(\ker(f)) \to \cdots$$ Any help is appreciated!,I cannot solve the following problem from Weibel: Let $f:B\to C$ be a map of chain complexes. Show that the natural maps $\alpha : \ker(f)[-1]\to \operatorname{cone}(f)$ and $\beta: \operatorname{cone}(f)\to \operatorname{coker}(f)$ give rise to a long exact sequence:   $$\cdots \to H_{n-1}(\ker(f))\to H_n(\operatorname{cone}(f))\to H_n(\operatorname{coker}(f))\to H_{n-2}(\ker(f)) \to \cdots$$ Any help is appreciated!,,"['abstract-algebra', 'homological-algebra']"
41,Must this rng be a ring?,Must this rng be a ring?,,A rng is a ring without the assumption that the ring contains an identity. Consider a finite rng $\mathbf{R}$. I am investigating conditions that get close forcing an identity but not quite. The closest condition I can think of is the following: If $a\in \mathbf{R}$ is non-zero then there is $b\in\mathbf{R}$ such that $ab\neq  0$ I am finding myself unable to prove that $\mathbf{R}$ must/need-not have a multiplicative identity i.e. be a ring. Are there well-known results/examples that deal with this sort of condition?,A rng is a ring without the assumption that the ring contains an identity. Consider a finite rng $\mathbf{R}$. I am investigating conditions that get close forcing an identity but not quite. The closest condition I can think of is the following: If $a\in \mathbf{R}$ is non-zero then there is $b\in\mathbf{R}$ such that $ab\neq  0$ I am finding myself unable to prove that $\mathbf{R}$ must/need-not have a multiplicative identity i.e. be a ring. Are there well-known results/examples that deal with this sort of condition?,,"['abstract-algebra', 'ring-theory', 'rngs']"
42,Number of elements of order $2$ in $S_n$,Number of elements of order  in,2 S_n,How many elements of order $2$ are there in $S_n$? Using combinatorics I arrived at this: For $n$ even ($n=2k$) there are ${n\choose2}+{n\choose 2}{n-2\choose 2}\dfrac{1}{2!}+{n\choose 2} {n-2\choose 2}{n-4\choose 2}\dfrac{1}{3!}+\cdots+{n\choose 2}{n-2\choose 2}{n-4\choose 2}\cdots{2\choose 2}\dfrac{1}{k!}$. For $n$ odd ($n=2k+1$) there are ${n\choose 2}+{n\choose 2}{n-2\choose 2}\dfrac{1}{2!}+{n\choose 2}{n-2\choose 2}{n-4\choose 2}\dfrac{1}{3!}+\cdots+{n\choose 2}{n-2\choose 2}{n-4\choose 2}\cdots{3\choose 2}\dfrac{1}{k!}$ But how do I find the sums? Seems like I have to use induction. But not quite upto there. Thanks for the help!!,How many elements of order $2$ are there in $S_n$? Using combinatorics I arrived at this: For $n$ even ($n=2k$) there are ${n\choose2}+{n\choose 2}{n-2\choose 2}\dfrac{1}{2!}+{n\choose 2} {n-2\choose 2}{n-4\choose 2}\dfrac{1}{3!}+\cdots+{n\choose 2}{n-2\choose 2}{n-4\choose 2}\cdots{2\choose 2}\dfrac{1}{k!}$. For $n$ odd ($n=2k+1$) there are ${n\choose 2}+{n\choose 2}{n-2\choose 2}\dfrac{1}{2!}+{n\choose 2}{n-2\choose 2}{n-4\choose 2}\dfrac{1}{3!}+\cdots+{n\choose 2}{n-2\choose 2}{n-4\choose 2}\cdots{3\choose 2}\dfrac{1}{k!}$ But how do I find the sums? Seems like I have to use induction. But not quite upto there. Thanks for the help!!,,"['abstract-algebra', 'combinatorics', 'group-theory', 'permutations']"
43,"Let $G$ be abelian, $H$ and $K$ subgroups of orders $n$, $m$. Then G has subgroup of order $\operatorname{lcm}(n,m)$.","Let  be abelian,  and  subgroups of orders , . Then G has subgroup of order .","G H K n m \operatorname{lcm}(n,m)","Let $G$ be abelian, $H$ and $K$ subgroups of orders $n$, $m$. Then G   has subgroup of order $\operatorname{lcm}(n,m)$. This is a statement that my lecturer mentioned in my (beginners') Abstract Algebra class. I'm not sure I understand why it's true. What I have so far: Use the abelian group structure theorem on $\langle H, K\rangle$ (finite group generated by $H$ and $K$). Then $\langle H,K\rangle=C_{a_1}C_{a_2}\dotsm$ and $n, m |\langle H,K\rangle$. Which means it's also true that $\operatorname{lcm}(n,m)|\langle H,K\rangle$. Can I leverage this to say there's a subgroup of order $\operatorname{lcm}(n,m)$?","Let $G$ be abelian, $H$ and $K$ subgroups of orders $n$, $m$. Then G   has subgroup of order $\operatorname{lcm}(n,m)$. This is a statement that my lecturer mentioned in my (beginners') Abstract Algebra class. I'm not sure I understand why it's true. What I have so far: Use the abelian group structure theorem on $\langle H, K\rangle$ (finite group generated by $H$ and $K$). Then $\langle H,K\rangle=C_{a_1}C_{a_2}\dotsm$ and $n, m |\langle H,K\rangle$. Which means it's also true that $\operatorname{lcm}(n,m)|\langle H,K\rangle$. Can I leverage this to say there's a subgroup of order $\operatorname{lcm}(n,m)$?",,"['abstract-algebra', 'group-theory']"
44,Rings of integers are noetherian (question about a specific proof),Rings of integers are noetherian (question about a specific proof),,"I'm reading Neukirch's book about Algebraic number theory and I totally fail to understand something. At one point he proves that the ring of integers $\mathcal{O}_K$ of a number field $K$ is noetherian in the following manner: ""every ideal is a finitely generated $\mathbb{Z}$-module by (2.10) and therefore a fortiori a finitely generated $\mathcal{O}_K$-module."" Now 2.10 is the claim that for an integrally closed, principle ideal domain A, F its field of fractions, L a finite separable extension of F and B the integral closure of A in L, we have that ""every finitely generated B-submodule $M\ne 0$ of L is a free A-module of rank $[L:F]$"". I fail to see how 2.10 is used here. I guess in our case $F=\mathbb{Q}, L=K, A=\mathbb{Z}, B=\mathcal{O}_K$. So I know that every finitely generated $\mathcal{O}_K$ submodule (in other words, ideal) is a free $\mathbb{Z}$-module, which is additional information; but how can I assume that the ideal is finitely generated in the first place? That's what I need to prove!","I'm reading Neukirch's book about Algebraic number theory and I totally fail to understand something. At one point he proves that the ring of integers $\mathcal{O}_K$ of a number field $K$ is noetherian in the following manner: ""every ideal is a finitely generated $\mathbb{Z}$-module by (2.10) and therefore a fortiori a finitely generated $\mathcal{O}_K$-module."" Now 2.10 is the claim that for an integrally closed, principle ideal domain A, F its field of fractions, L a finite separable extension of F and B the integral closure of A in L, we have that ""every finitely generated B-submodule $M\ne 0$ of L is a free A-module of rank $[L:F]$"". I fail to see how 2.10 is used here. I guess in our case $F=\mathbb{Q}, L=K, A=\mathbb{Z}, B=\mathcal{O}_K$. So I know that every finitely generated $\mathcal{O}_K$ submodule (in other words, ideal) is a free $\mathbb{Z}$-module, which is additional information; but how can I assume that the ideal is finitely generated in the first place? That's what I need to prove!",,"['abstract-algebra', 'algebraic-number-theory']"
45,When is the ring homomorphism $\mathbb{Z} \to R$ an epimorphism?,When is the ring homomorphism  an epimorphism?,\mathbb{Z} \to R,"For every ring $R$ there exists a unique ring homomorphism $f: \mathbb{Z} \to R$ .  For which rings is this an epimorphism? The only examples I know are the subrings of $\mathbb{Q}$ and the quotient rings of $\mathbb{Z}$ , namely the rings $\mathbb{Z}/\langle n \rangle$ .  Are these all, or are there more? Three characterizations of epimorphisms of commutative rings are listed here: Epimorphisms of rings , The Stacks Project. Maybe one will help. (Why I'm interested: an object in a category is subterminal if its unique morphism to the terminal object is a monomorphism.  Since $\mathbb{Z}$ is initial in $\mathrm{Ring}$ , here I am asking what are the subterminal objects in $\mathrm{Ring}^{\rm op}$ .)","For every ring there exists a unique ring homomorphism .  For which rings is this an epimorphism? The only examples I know are the subrings of and the quotient rings of , namely the rings .  Are these all, or are there more? Three characterizations of epimorphisms of commutative rings are listed here: Epimorphisms of rings , The Stacks Project. Maybe one will help. (Why I'm interested: an object in a category is subterminal if its unique morphism to the terminal object is a monomorphism.  Since is initial in , here I am asking what are the subterminal objects in .)",R f: \mathbb{Z} \to R \mathbb{Q} \mathbb{Z} \mathbb{Z}/\langle n \rangle \mathbb{Z} \mathrm{Ring} \mathrm{Ring}^{\rm op},"['abstract-algebra', 'ring-theory']"
46,Can $\mathbb{R}^{+}$ be divided into two disjoint sets so that each set is closed under both addition and multiplication?,Can  be divided into two disjoint sets so that each set is closed under both addition and multiplication?,\mathbb{R}^{+},"Can $\mathbb{R}^{+}$ be divided into two disjoint nonempty sets so that each set is closed under both addition and multiplication? I know if we only require both sets to be closed under addition then this can be done. For example, this post gives an answer. Thank you very much!","Can be divided into two disjoint nonempty sets so that each set is closed under both addition and multiplication? I know if we only require both sets to be closed under addition then this can be done. For example, this post gives an answer. Thank you very much!",\mathbb{R}^{+},"['abstract-algebra', 'set-theory', 'real-numbers', 'axiom-of-choice']"
47,Splitting of Automorphism Group,Splitting of Automorphism Group,,"It is well-known that for any group $G$ there is an exact sequence $0 \rightarrow \text{Inn}(G) \rightarrow \text{Aut}(G) \rightarrow \text{Out}(G) \rightarrow 0$. Does this sequence always split, i.e. is it always true that $\text{Aut}(G)$ is a semidirect product of $\text{Inn}(G)$ and $\text{Out}(G)$? I suspect not, but have not yet come across a counterexample. Thanks in advance!","It is well-known that for any group $G$ there is an exact sequence $0 \rightarrow \text{Inn}(G) \rightarrow \text{Aut}(G) \rightarrow \text{Out}(G) \rightarrow 0$. Does this sequence always split, i.e. is it always true that $\text{Aut}(G)$ is a semidirect product of $\text{Inn}(G)$ and $\text{Out}(G)$? I suspect not, but have not yet come across a counterexample. Thanks in advance!",,"['abstract-algebra', 'group-theory']"
48,Generators for the intersection of two ideals,Generators for the intersection of two ideals,,"Let $I=\langle a_1,\dots, a_s\rangle, J=\langle b_1,\dots, b_t\rangle$ be ideals of arbitrary commutative ring. Then we know that  $I+J=\langle a_1,\dots, a_s, b_1,\dots, b_t\rangle, IJ=\langle\{a_ib_j \mid 1 \leq i \leq s, 1\leq j \leq t\}\rangle$. Also $IJ\subseteq I\cap J \subseteq I+J$. I wonder about the generators of $I\cap J$. Is it possible that know the generators? Or is it finitely generated?","Let $I=\langle a_1,\dots, a_s\rangle, J=\langle b_1,\dots, b_t\rangle$ be ideals of arbitrary commutative ring. Then we know that  $I+J=\langle a_1,\dots, a_s, b_1,\dots, b_t\rangle, IJ=\langle\{a_ib_j \mid 1 \leq i \leq s, 1\leq j \leq t\}\rangle$. Also $IJ\subseteq I\cap J \subseteq I+J$. I wonder about the generators of $I\cap J$. Is it possible that know the generators? Or is it finitely generated?",,"['abstract-algebra', 'commutative-algebra', 'ideals']"
49,A Nontrivial Subgroup of a Solvable Group,A Nontrivial Subgroup of a Solvable Group,,"Question: Let $G$ be a solvable group, and let $H$ be a nontrivial normal subgroup of $G$. Prove that there exists a nontrivial subgroup $A$ of $H$ that is Abelian and normal in $G$. [ref: this is exercise 11 on page 106 of [DF] := Dummit and Foote's Abstract Algebra , 3rd edition] UPDATE: I cannot use the derived series of a group (the concept is not introduced in [DF] until some 90 pages later), and the use of a commutator subgroup is questionable.","Question: Let $G$ be a solvable group, and let $H$ be a nontrivial normal subgroup of $G$. Prove that there exists a nontrivial subgroup $A$ of $H$ that is Abelian and normal in $G$. [ref: this is exercise 11 on page 106 of [DF] := Dummit and Foote's Abstract Algebra , 3rd edition] UPDATE: I cannot use the derived series of a group (the concept is not introduced in [DF] until some 90 pages later), and the use of a commutator subgroup is questionable.",,"['abstract-algebra', 'group-theory']"
50,An expression that vanishes over every field,An expression that vanishes over every field,,"In this question , Jack Schmidt asks to prove a certain identity for $2\times 2$ matrices A and B. In fact he asks to show that tr(AABABB−AABBAB) = 0. In an answer by user7406, he shows that 3 times this expression must be 0, solving the problem at least when the characteristic of the ground field isn't 3. In a comment by Mariano Suárez-Alvarez he tells us a computercalculation show that it is in fact identically zero. This made me wonder whether or not this is a surprise. I think the proper way to state the problem is as follows: Let $\varphi \colon \mathbb Z\langle x_1,\dots x_n\rangle\to \mathbb Q [x_1,\dots,x_n]$ be the morphism from the free non-commutative ring over these variables to the polynomialring. Let $\Phi \colon \mathbb Z\langle x_1,\dots,x_n\rangle \to k[x_1,\dots,x_n]$ be the corresponding morphism by sending every element to 'itself' the ususal way. Here are my questions: Is it true that if $\varphi(x)=0$ then $\Phi(x) = 0$? My guess is it is because one can construct $\psi$ such that $\Phi = \psi\circ \varphi$. Does this indeed settle the original problem for characteristic 3 from the solution by user7406, thereby bypassing von Neumann or am I really missing something? [I first asked this question in a comment to the post by user7406, but I deleted that because I didn't want to hijack the other question.]","In this question , Jack Schmidt asks to prove a certain identity for $2\times 2$ matrices A and B. In fact he asks to show that tr(AABABB−AABBAB) = 0. In an answer by user7406, he shows that 3 times this expression must be 0, solving the problem at least when the characteristic of the ground field isn't 3. In a comment by Mariano Suárez-Alvarez he tells us a computercalculation show that it is in fact identically zero. This made me wonder whether or not this is a surprise. I think the proper way to state the problem is as follows: Let $\varphi \colon \mathbb Z\langle x_1,\dots x_n\rangle\to \mathbb Q [x_1,\dots,x_n]$ be the morphism from the free non-commutative ring over these variables to the polynomialring. Let $\Phi \colon \mathbb Z\langle x_1,\dots,x_n\rangle \to k[x_1,\dots,x_n]$ be the corresponding morphism by sending every element to 'itself' the ususal way. Here are my questions: Is it true that if $\varphi(x)=0$ then $\Phi(x) = 0$? My guess is it is because one can construct $\psi$ such that $\Phi = \psi\circ \varphi$. Does this indeed settle the original problem for characteristic 3 from the solution by user7406, thereby bypassing von Neumann or am I really missing something? [I first asked this question in a comment to the post by user7406, but I deleted that because I didn't want to hijack the other question.]",,['abstract-algebra']
51,Examples of a monad in a monoid (i.e. category with one object)?,Examples of a monad in a monoid (i.e. category with one object)?,,"I've been trying to figure out what having a monad in a monoid (i.e. a category with one object) would mean. As far as I can tell it would be a homomorphism (functor) $T : M → M$, with two elements (natural transformation components) $\eta, \mu : M$, such that $\forall x. \eta x = T(x) \eta$ $\forall x. \mu T(T(x)) = T(x) \mu$ $\mu \eta$ = $\mu T(\eta)$ = 1 $\mu T(\mu) = \mu \mu$ The identity monad $T(x) = x$, with $\eta = \mu = 1$, is an obvious example for any monoid. But no other examples really come to mind... These laws seem a bit strange. Are there any interesting examples, or any good intuition for what the laws would mean?","I've been trying to figure out what having a monad in a monoid (i.e. a category with one object) would mean. As far as I can tell it would be a homomorphism (functor) $T : M → M$, with two elements (natural transformation components) $\eta, \mu : M$, such that $\forall x. \eta x = T(x) \eta$ $\forall x. \mu T(T(x)) = T(x) \mu$ $\mu \eta$ = $\mu T(\eta)$ = 1 $\mu T(\mu) = \mu \mu$ The identity monad $T(x) = x$, with $\eta = \mu = 1$, is an obvious example for any monoid. But no other examples really come to mind... These laws seem a bit strange. Are there any interesting examples, or any good intuition for what the laws would mean?",,"['abstract-algebra', 'category-theory', 'monoid', 'monads']"
52,Galois Theory and Galois Groups,Galois Theory and Galois Groups,,"Show that $\mathbb{Q}[x]/\langle x^{3}-2\rangle = [{a + b\alpha + c\alpha^{2}: a, b, c \in \mathbb{Q}, \alpha^{3} = 2}]$ is not a Galois extension of $\mathbb{Q}$. In particular, show that every automorphism of $\mathbb{Q}[x]/\langle x^{3}-2\rangle$ that fixes $\mathbb{Q}$ also fixes all of $\mathbb{Q}[x]/\langle x^{3}-2\rangle$. To do this, we'll use the following approach. Let $\varphi$ be an automorphism of $\mathbb{Q}[x]/\langle x^{3}-2\rangle$ that fixes $\mathbb{Q}$, i.e. that satisfies $\varphi(a) = a$  $\forall a \in \mathbb{Q}$. We want to show that $\varphi$ is necessarily the identity automorphism, namely the function $e$, given by $e(\beta) = \beta$ $\forall \beta\in\mathbb{Q}[x]/\langle x^{3}-2\rangle$. Part a. We want to show that $\varphi = e$, namely that $\varphi(\beta) = \beta$ for all $\beta$ of the form $a+b\alpha+c\alpha^{2}$ where $a,b,c \in \mathbb{Q}$ and $\alpha^{3} = 2$. Show that to do this, it suffices to show that $\varphi(\alpha) = \alpha$. $\bf{Thoughts:}$ So this is what I have so far, and I wasn't sure if I had to actually show that $\varphi(\alpha) = \alpha$. Let K = $\mathbb{Q}[x]/\langle x^{3}-2\rangle$ and Let F = $\mathbb{Q}$. Let $\varphi$ be any automorphism of K that fixes F. $\varphi$ is defined to be $\varphi: K\to K$ such that $\forall \beta$, $\beta = a+b\alpha+c\alpha^{2}$, where $a,b,c\in F$ and $\alpha^{3} = 2$. Show $\varphi(\beta)= \beta$. $\varphi(\beta) = \varphi(a+b\alpha+c\alpha^{2}) = \varphi(a) +\varphi(b\alpha)+\varphi(c\alpha^{2}) = a+b\varphi(\alpha)+c\varphi(\alpha^{2})$ (since a,b,c are in F, which is the fixed field). I'm not sure if I actually have to show that $\varphi(\alpha) = \alpha$, because then $\varphi(\beta) = \beta$, which for this part of the problem is what we're trying to show, I think. Any help would be greatly appreciated. Part b: Show that [$\varphi(\alpha)]^{3} = 2$. Once we have this then we can conclude that $\beta^{3} = 2$ has only one solution $\beta\in K$. $\bf{Thoughts:}$ I already showed that [$\varphi(\alpha)]^{3} = 2$ by using that fact that since it's an automorphism, so then we can bring the power of 3 into the automorphism so that it's actually: $\varphi(\alpha^{3}) = \varphi(2) = 2$ since $2 \in F$, which is the fixed field. Then this part is done. Part c: To show that there is only one cube root of 2 in K, factor $\beta^{3} - 2 = \beta^{3} - \alpha^{3} = (\beta -\alpha)(\beta^{2}+\alpha\beta+\alpha^{2})$. Conclude that it suffices to show that $\beta^{2}+\alpha\beta+\alpha^{2}\ne 0$ for all $\beta \in K$. $\bf{Thoughts:}$ So I wrote the factoring out, and concluded that the only way for that to happen was if $\beta -\alpha = 0$, implying that $\beta = \alpha$ $\textit{or}$ $\beta^{2}+\alpha\beta+\alpha^{2} = 0$ for all $\beta\in K$. So then this part is done. Part d: By way of contradiction, show that if $\exists \beta \in K$ such that $\beta^{2}+\alpha\beta+\alpha^{2} = 0$, then writing $\beta$ as $\beta = a+b\alpha+c\alpha^{2}$, we necessarily have $$\ 0 = a^{2}+2c(1+2b),\\ 0 = a(1+2b)+2c^{2},\\ 0 = 1+b+b^{2}+2ac$$ Show that there are no rational numbers $a$, $b$, and $c$ which satisfy these equations. (which this ends the entire proof cuz it shows that $\varphi = e$) $\bf{Thoughts:}$ I understand what we're supposed to do for this part of the problem, but I'm not sure how to start showing that there are no rational numbers which satisfy these equations. Thanks, in advance, for the help. Sorry those three equations aren't centered, I'm not entirely sure how to do that in Latex quite yet, and what I did try didn't work.","Show that $\mathbb{Q}[x]/\langle x^{3}-2\rangle = [{a + b\alpha + c\alpha^{2}: a, b, c \in \mathbb{Q}, \alpha^{3} = 2}]$ is not a Galois extension of $\mathbb{Q}$. In particular, show that every automorphism of $\mathbb{Q}[x]/\langle x^{3}-2\rangle$ that fixes $\mathbb{Q}$ also fixes all of $\mathbb{Q}[x]/\langle x^{3}-2\rangle$. To do this, we'll use the following approach. Let $\varphi$ be an automorphism of $\mathbb{Q}[x]/\langle x^{3}-2\rangle$ that fixes $\mathbb{Q}$, i.e. that satisfies $\varphi(a) = a$  $\forall a \in \mathbb{Q}$. We want to show that $\varphi$ is necessarily the identity automorphism, namely the function $e$, given by $e(\beta) = \beta$ $\forall \beta\in\mathbb{Q}[x]/\langle x^{3}-2\rangle$. Part a. We want to show that $\varphi = e$, namely that $\varphi(\beta) = \beta$ for all $\beta$ of the form $a+b\alpha+c\alpha^{2}$ where $a,b,c \in \mathbb{Q}$ and $\alpha^{3} = 2$. Show that to do this, it suffices to show that $\varphi(\alpha) = \alpha$. $\bf{Thoughts:}$ So this is what I have so far, and I wasn't sure if I had to actually show that $\varphi(\alpha) = \alpha$. Let K = $\mathbb{Q}[x]/\langle x^{3}-2\rangle$ and Let F = $\mathbb{Q}$. Let $\varphi$ be any automorphism of K that fixes F. $\varphi$ is defined to be $\varphi: K\to K$ such that $\forall \beta$, $\beta = a+b\alpha+c\alpha^{2}$, where $a,b,c\in F$ and $\alpha^{3} = 2$. Show $\varphi(\beta)= \beta$. $\varphi(\beta) = \varphi(a+b\alpha+c\alpha^{2}) = \varphi(a) +\varphi(b\alpha)+\varphi(c\alpha^{2}) = a+b\varphi(\alpha)+c\varphi(\alpha^{2})$ (since a,b,c are in F, which is the fixed field). I'm not sure if I actually have to show that $\varphi(\alpha) = \alpha$, because then $\varphi(\beta) = \beta$, which for this part of the problem is what we're trying to show, I think. Any help would be greatly appreciated. Part b: Show that [$\varphi(\alpha)]^{3} = 2$. Once we have this then we can conclude that $\beta^{3} = 2$ has only one solution $\beta\in K$. $\bf{Thoughts:}$ I already showed that [$\varphi(\alpha)]^{3} = 2$ by using that fact that since it's an automorphism, so then we can bring the power of 3 into the automorphism so that it's actually: $\varphi(\alpha^{3}) = \varphi(2) = 2$ since $2 \in F$, which is the fixed field. Then this part is done. Part c: To show that there is only one cube root of 2 in K, factor $\beta^{3} - 2 = \beta^{3} - \alpha^{3} = (\beta -\alpha)(\beta^{2}+\alpha\beta+\alpha^{2})$. Conclude that it suffices to show that $\beta^{2}+\alpha\beta+\alpha^{2}\ne 0$ for all $\beta \in K$. $\bf{Thoughts:}$ So I wrote the factoring out, and concluded that the only way for that to happen was if $\beta -\alpha = 0$, implying that $\beta = \alpha$ $\textit{or}$ $\beta^{2}+\alpha\beta+\alpha^{2} = 0$ for all $\beta\in K$. So then this part is done. Part d: By way of contradiction, show that if $\exists \beta \in K$ such that $\beta^{2}+\alpha\beta+\alpha^{2} = 0$, then writing $\beta$ as $\beta = a+b\alpha+c\alpha^{2}$, we necessarily have $$\ 0 = a^{2}+2c(1+2b),\\ 0 = a(1+2b)+2c^{2},\\ 0 = 1+b+b^{2}+2ac$$ Show that there are no rational numbers $a$, $b$, and $c$ which satisfy these equations. (which this ends the entire proof cuz it shows that $\varphi = e$) $\bf{Thoughts:}$ I understand what we're supposed to do for this part of the problem, but I'm not sure how to start showing that there are no rational numbers which satisfy these equations. Thanks, in advance, for the help. Sorry those three equations aren't centered, I'm not entirely sure how to do that in Latex quite yet, and what I did try didn't work.",,['abstract-algebra']
53,How to factor in cubic extensions?,How to factor in cubic extensions?,,"Working within the field $K=\mathbb{Q}(\sqrt[3]{n})$, for any cube root of $n$, how does one factor the unramified rational prime ideals $(p)$? For starters, I'm relatively new to this and not too sure I completely understand factoring in these extensions, and so I'll instead talk about factoring $x^3-n$ over $\mathbb{F}_{p}$. Assuming for simplicity that $\mathcal{O}^{K}=\mathbb{Z}(\sqrt[3]{n})$, it's obvious that if $p \equiv 2 \pmod{3}$, then $x^3-n=0$ has exactly one solution in $\mathbb{F}_{p}$. For $p \equiv 1 \pmod{3}$, I have no clue what is supposed to be done. I know that there must be three solutions or no solutions, but getting there is the problem. All I've been able to think of that might be key to figuring this out is assigning the Frobenius a conjugacy clas s of $S_{3}$ due to the fact that $\mid\rho(p)\mid=\chi_{3}(p)$, where $\rho(p)$ is some representation of an element within the conjugacy class and $\chi_{3}(p)$ is the non-trivial Dirichlet Character of modulus 3. This seems nice since it  alludes to working within $\mathbb{Z}(\frac{-1+\sqrt{-3}}{2})$ for the answer, and for one case, $\mathbb{Q}(\sqrt[3]{2})$, the solution does indeed involve $\mathbb{Z}(\frac{-1+\sqrt{-3}}{2})$ (understanding how this connection is made is difficult).","Working within the field $K=\mathbb{Q}(\sqrt[3]{n})$, for any cube root of $n$, how does one factor the unramified rational prime ideals $(p)$? For starters, I'm relatively new to this and not too sure I completely understand factoring in these extensions, and so I'll instead talk about factoring $x^3-n$ over $\mathbb{F}_{p}$. Assuming for simplicity that $\mathcal{O}^{K}=\mathbb{Z}(\sqrt[3]{n})$, it's obvious that if $p \equiv 2 \pmod{3}$, then $x^3-n=0$ has exactly one solution in $\mathbb{F}_{p}$. For $p \equiv 1 \pmod{3}$, I have no clue what is supposed to be done. I know that there must be three solutions or no solutions, but getting there is the problem. All I've been able to think of that might be key to figuring this out is assigning the Frobenius a conjugacy clas s of $S_{3}$ due to the fact that $\mid\rho(p)\mid=\chi_{3}(p)$, where $\rho(p)$ is some representation of an element within the conjugacy class and $\chi_{3}(p)$ is the non-trivial Dirichlet Character of modulus 3. This seems nice since it  alludes to working within $\mathbb{Z}(\frac{-1+\sqrt{-3}}{2})$ for the answer, and for one case, $\mathbb{Q}(\sqrt[3]{2})$, the solution does indeed involve $\mathbb{Z}(\frac{-1+\sqrt{-3}}{2})$ (understanding how this connection is made is difficult).",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory', 'maximal-and-prime-ideals', 'cubic-reciprocity']"
54,Hochschild homology - motivation and examples,Hochschild homology - motivation and examples,,"I'm currently trying to learn about Hochschild homology of differential graded algebras. After reading the definition, the notion of Hochschild homology is somewhat unmotivated and myterious to me. What is the motivation to define Hochschild homology and what are some nice examples? I'm particularly interested in the Hochschild homology of truncated polynomial algebras $$k[x]/(x^{n+1})$$ where $k$ is a field of characteristic zero and $x$ is of some degree $d$. Are there any nice references for Hochschild homology?","I'm currently trying to learn about Hochschild homology of differential graded algebras. After reading the definition, the notion of Hochschild homology is somewhat unmotivated and myterious to me. What is the motivation to define Hochschild homology and what are some nice examples? I'm particularly interested in the Hochschild homology of truncated polynomial algebras $$k[x]/(x^{n+1})$$ where $k$ is a field of characteristic zero and $x$ is of some degree $d$. Are there any nice references for Hochschild homology?",,"['abstract-algebra', 'homological-algebra', 'hochschild-cohomology']"
55,"Have I found a counterexample to Noether-Skolem? (No, but I am confused...)","Have I found a counterexample to Noether-Skolem? (No, but I am confused...)",,"I was toying around with central simple algebras over a field $K$ today and thought that I should try to verify Noether-Skolem's theorem that any automorphism of such must be inner. So, let us take $K = \mathbb{Q}[\sqrt{5}]$, and the quaternion algebra $(1,-4)_K$, i.e. $i_1^2=1$,$j_1^2=-4$ and $i_1j_1=-j_1i_1$. Now, we can see that this is isomorphic to $M_2(K)$, the matrix ring, where the isomorphism is given by $$j_1 \rightarrow \pmatrix{0 & -4 \\ 1 & 0},$$ $$i_1 \rightarrow \pmatrix{1 & 0 \\ 0 & -1 }.$$ Call $\psi$ the isomorphism $(1,-4)_K \rightarrow M_2(K)$.  Now, we can see that as a quaternion algebra, $(1,-4)_K \cong (1,1)$ ( call the generators here for $i_2$ , $j_2$) by the isomorphism $$i_1 \rightarrow i_2,$$ $$j_1 \rightarrow j_2(1+i_2)$$ and we call this isomorphism by $\phi$. Now, $(1,1)_K$ is isomorphic to $M_2(K)$ as well, let  $\sigma:(1,1)_K \rightarrow M_2(K)$ be the isomorphism (which is of the same ""form"" as $\psi$). Now, this induces an automorphism: $\sigma \circ \phi \circ \psi^{-1}: M_2(K) \rightarrow M_2(K)$, which takes  $$e= \pmatrix{1 & 0 \\ 0 & -1 }$$ onto itself and takes $$f= \pmatrix{0 & -4 \\ 1 & 0}$$ onto $\sigma(j(1+i))$. Now, I can not get this to be an inner automorphism! I get that all entries must be zero, and this is clearly nonsense. So please, mathstackexchange, before I lose my mind (that's an exaggeration, but it is annoying), how can this be resolved? Update (A concrete description of $\sigma(j(i+1))$ In the comments I got asked whether I could write out what $\sigma(j(i+1))$ was. I left it out on purpose, since I believe this might be where the error lies. However, this is how my thinking goes: $$\sigma(j(i+1))= \sigma(j)\sigma(i+1) = \pmatrix{0 & 1 \\ 1 & 0 } [ \pmatrix{1 & 0 \\ 0 & -1 } + \pmatrix{1 & 0 \\ 0 & 1}].$$ Multiplying this, I get $$\pmatrix{ 0 & 0 \\ 2 & 0 }.$$ So if we assume that we have an inner automorphism: we should have $$\pmatrix{a & 0 \\ 0 & b } \pmatrix{0 & -4 \\ 1 & 0 } = \pmatrix{0 & 0 \\ 2 & 0} \pmatrix{a & 0 \\ 0 & b}$$ but this can not hold! So, some of my assumptions should be wrong, or some step, but I really can't see which one. I suspect that it lies in the step where I multiply by a norm. But it should hold, but maybe my isomorphism isn't an isomorphism. But there should be one, and I am quite sure that that one is correct!","I was toying around with central simple algebras over a field $K$ today and thought that I should try to verify Noether-Skolem's theorem that any automorphism of such must be inner. So, let us take $K = \mathbb{Q}[\sqrt{5}]$, and the quaternion algebra $(1,-4)_K$, i.e. $i_1^2=1$,$j_1^2=-4$ and $i_1j_1=-j_1i_1$. Now, we can see that this is isomorphic to $M_2(K)$, the matrix ring, where the isomorphism is given by $$j_1 \rightarrow \pmatrix{0 & -4 \\ 1 & 0},$$ $$i_1 \rightarrow \pmatrix{1 & 0 \\ 0 & -1 }.$$ Call $\psi$ the isomorphism $(1,-4)_K \rightarrow M_2(K)$.  Now, we can see that as a quaternion algebra, $(1,-4)_K \cong (1,1)$ ( call the generators here for $i_2$ , $j_2$) by the isomorphism $$i_1 \rightarrow i_2,$$ $$j_1 \rightarrow j_2(1+i_2)$$ and we call this isomorphism by $\phi$. Now, $(1,1)_K$ is isomorphic to $M_2(K)$ as well, let  $\sigma:(1,1)_K \rightarrow M_2(K)$ be the isomorphism (which is of the same ""form"" as $\psi$). Now, this induces an automorphism: $\sigma \circ \phi \circ \psi^{-1}: M_2(K) \rightarrow M_2(K)$, which takes  $$e= \pmatrix{1 & 0 \\ 0 & -1 }$$ onto itself and takes $$f= \pmatrix{0 & -4 \\ 1 & 0}$$ onto $\sigma(j(1+i))$. Now, I can not get this to be an inner automorphism! I get that all entries must be zero, and this is clearly nonsense. So please, mathstackexchange, before I lose my mind (that's an exaggeration, but it is annoying), how can this be resolved? Update (A concrete description of $\sigma(j(i+1))$ In the comments I got asked whether I could write out what $\sigma(j(i+1))$ was. I left it out on purpose, since I believe this might be where the error lies. However, this is how my thinking goes: $$\sigma(j(i+1))= \sigma(j)\sigma(i+1) = \pmatrix{0 & 1 \\ 1 & 0 } [ \pmatrix{1 & 0 \\ 0 & -1 } + \pmatrix{1 & 0 \\ 0 & 1}].$$ Multiplying this, I get $$\pmatrix{ 0 & 0 \\ 2 & 0 }.$$ So if we assume that we have an inner automorphism: we should have $$\pmatrix{a & 0 \\ 0 & b } \pmatrix{0 & -4 \\ 1 & 0 } = \pmatrix{0 & 0 \\ 2 & 0} \pmatrix{a & 0 \\ 0 & b}$$ but this can not hold! So, some of my assumptions should be wrong, or some step, but I really can't see which one. I suspect that it lies in the step where I multiply by a norm. But it should hold, but maybe my isomorphism isn't an isomorphism. But there should be one, and I am quite sure that that one is correct!",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
56,Is there a more elementary proof of this special case of Riemann-Roch?,Is there a more elementary proof of this special case of Riemann-Roch?,,"I'm looking for an elementary proof of the fact that $\ell(nP) = \dim L(nP) = n$, where $L(nP)$ is the linear (Riemann-Roch) space of certain rational functions associated to the divisor $nP$, where $n > 0$ is an integer and $P$ is a point on a curve of genus 1. This fact is used to prove that every elliptic curve is isomorphic to a curve given by a Weierstrass equation. See for instance Silverman, The Arithmetic of Elliptic Curves, p. 59, Proposition 3.1.(a). I know that it's a corollary to the Riemann-Roch theorem (it follows from the corollary that says if $\deg D > 2g - 2$ then $\ell(D) = \deg D + 1 - g$). The proof of the full Riemann-Roch theorem still looks a little intimidating to me, so I'm hoping someone can provide a more elementary proof of this special case, perhaps by making the relevant simplifications in the proof of the Riemann-Roch theorem. Thanks in advance.","I'm looking for an elementary proof of the fact that $\ell(nP) = \dim L(nP) = n$, where $L(nP)$ is the linear (Riemann-Roch) space of certain rational functions associated to the divisor $nP$, where $n > 0$ is an integer and $P$ is a point on a curve of genus 1. This fact is used to prove that every elliptic curve is isomorphic to a curve given by a Weierstrass equation. See for instance Silverman, The Arithmetic of Elliptic Curves, p. 59, Proposition 3.1.(a). I know that it's a corollary to the Riemann-Roch theorem (it follows from the corollary that says if $\deg D > 2g - 2$ then $\ell(D) = \deg D + 1 - g$). The proof of the full Riemann-Roch theorem still looks a little intimidating to me, so I'm hoping someone can provide a more elementary proof of this special case, perhaps by making the relevant simplifications in the proof of the Riemann-Roch theorem. Thanks in advance.",,"['abstract-algebra', 'algebraic-geometry', 'elliptic-curves']"
57,The generalized quaternion group $\Bbb H_n$,The generalized quaternion group,\Bbb H_n,"Let $\omega$ be a $2^n$-th primitive root of unity. Let $$R=\begin{pmatrix}\omega & 0\\0&\omega^{-1}\end{pmatrix}$$ and $$S=\begin{pmatrix}0&-1\\1&0\end{pmatrix}$$ Define the subgroup $\langle S,R\rangle =\Bbb H_n$ to be the generalized quaternion group, in $\rm{SL}(2,\Bbb C)$. I have to find the order and list all elements of $\Bbb H_n$. Observe that: $$R^{2^n}=1$$ $$S^2=-1$$ $$SR=R^{-1}S$$ $$S^{-1}R=R^{-1}S^{-1}$$ We can put the last two as $SRSR=RSRS=-1$. I think this suffices to find the order and list the elements. Indeed,  given any string, we can get all the $S$ to the right of the string and all the $R$ consequently to the left using the $3^{\rm rd}$ and $4^{\rm th}$ relations, ending up with something of the form  $$R^jS^i$$ CORRECTED Now, since $\omega$ is a primitive $2^n$-th root of unity, we can let $j$ range over $1\leq j\leq 2^n$ to get all possible powers $R^j$ for $j\in \Bbb Z$. On the other hand since $S^2=-1,S^3=-S,S^4=1$, and $R^{2^{n-1}}=-1,R^{2^n}=1$, we must restrict $i$ to $0,1$. Thus the order is $2\times 2^n=2^{n+1}$. NOTE The relations above look pretty similar to those in $D_n$; namely for $R$ a rotation of $2\pi /n$ radians and $S$ a reflection, we have $R^n=1$, $S^2=1$, $SRS=R^{-1}$ and also $D_n=\langle R,S\rangle $. Any comment on this?","Let $\omega$ be a $2^n$-th primitive root of unity. Let $$R=\begin{pmatrix}\omega & 0\\0&\omega^{-1}\end{pmatrix}$$ and $$S=\begin{pmatrix}0&-1\\1&0\end{pmatrix}$$ Define the subgroup $\langle S,R\rangle =\Bbb H_n$ to be the generalized quaternion group, in $\rm{SL}(2,\Bbb C)$. I have to find the order and list all elements of $\Bbb H_n$. Observe that: $$R^{2^n}=1$$ $$S^2=-1$$ $$SR=R^{-1}S$$ $$S^{-1}R=R^{-1}S^{-1}$$ We can put the last two as $SRSR=RSRS=-1$. I think this suffices to find the order and list the elements. Indeed,  given any string, we can get all the $S$ to the right of the string and all the $R$ consequently to the left using the $3^{\rm rd}$ and $4^{\rm th}$ relations, ending up with something of the form  $$R^jS^i$$ CORRECTED Now, since $\omega$ is a primitive $2^n$-th root of unity, we can let $j$ range over $1\leq j\leq 2^n$ to get all possible powers $R^j$ for $j\in \Bbb Z$. On the other hand since $S^2=-1,S^3=-S,S^4=1$, and $R^{2^{n-1}}=-1,R^{2^n}=1$, we must restrict $i$ to $0,1$. Thus the order is $2\times 2^n=2^{n+1}$. NOTE The relations above look pretty similar to those in $D_n$; namely for $R$ a rotation of $2\pi /n$ radians and $S$ a reflection, we have $R^n=1$, $S^2=1$, $SRS=R^{-1}$ and also $D_n=\langle R,S\rangle $. Any comment on this?",,"['abstract-algebra', 'group-theory', 'quaternions']"
58,Algebraic structures associated to flexagons?,Algebraic structures associated to flexagons?,,"Flexagons strike me as objects that would admit investigation in a first course in modern algebra. I'm surprised to be unable to find a reference discussing flexagons using modern algebra language. Could someone please provide a reference? Perhaps the reason is that the ""motions"" between ""states"" of a flexagon might not form a common algebraic object like a group, although these motions and states admit a Cayley graph-like state diagram, an example of which can be seen here . The first part of my question is an odd pedagogical one, in that the flexagon is what draws students in, and would be the gateway to teaching topics in introductory modern algebra: Question A: Do flexagons admit study by algebraic structures with well-developed theories, e.g. groups, or do they simply appear as an isolated oddity? This suggests a second part of the question, which I think is really only a rephrasing of A: Question B: Does the ""algebraic structure"" found in the study of flexagons appear in any serious, or at least more mainstream, mathematics? I should mention this post , although it also doesn't employ group theory in any satisfying way.","Flexagons strike me as objects that would admit investigation in a first course in modern algebra. I'm surprised to be unable to find a reference discussing flexagons using modern algebra language. Could someone please provide a reference? Perhaps the reason is that the ""motions"" between ""states"" of a flexagon might not form a common algebraic object like a group, although these motions and states admit a Cayley graph-like state diagram, an example of which can be seen here . The first part of my question is an odd pedagogical one, in that the flexagon is what draws students in, and would be the gateway to teaching topics in introductory modern algebra: Question A: Do flexagons admit study by algebraic structures with well-developed theories, e.g. groups, or do they simply appear as an isolated oddity? This suggests a second part of the question, which I think is really only a rephrasing of A: Question B: Does the ""algebraic structure"" found in the study of flexagons appear in any serious, or at least more mainstream, mathematics? I should mention this post , although it also doesn't employ group theory in any satisfying way.",,"['abstract-algebra', 'group-theory', 'reference-request', 'recreational-mathematics', 'education']"
59,"Why do free monoids have a ""trivial"" automorphism group and free groups don't?","Why do free monoids have a ""trivial"" automorphism group and free groups don't?",,"Let $X$ be a set and $M$ the free monoid over $X$. Then an automorphism $f$ of $M$ satisfies $f(X)=X$ and so $\text{Aut}(M)$ is canonically isomorphic to $\mathfrak{S}_X$. My Proof : For every word $w\in M$, let $l(w)$ be the length of $w$. We can show by induction on $l(w)$ that $l(f(w))\geq l(w)$. Since the same is true for $f^{-1}$, we have $l(f(w))=l(w)$ and the special case $l(w)=1$ is all we need to finish the proof. I have almost no formal knowledge of category theory, but I try to think categorically whenever possible. Since the proposition above can be formulated in categorical language, I assumed there would be an easy proof using only the universal property of $M$. But then I realized that the analogous statement for groups is not true. For example, $\mathbf{Z}$, the free group over a one element set, has two automorphisms. The reason the above proof breaks down is that there we had a (monoid) homomorphism $l:M\rightarrow\mathbf{N}$ with $l(X)=\{1\}$, and such a mapping does not exist if $M$ is the free group over $X$. Questions: Is there a name for (a theory about) the property of categories that the automorphism groups of free objects coincide with the permutation groups of the underlying sets? Is there a ""deeper"" reason that the category of monoids has this property and the category of groups does not?","Let $X$ be a set and $M$ the free monoid over $X$. Then an automorphism $f$ of $M$ satisfies $f(X)=X$ and so $\text{Aut}(M)$ is canonically isomorphic to $\mathfrak{S}_X$. My Proof : For every word $w\in M$, let $l(w)$ be the length of $w$. We can show by induction on $l(w)$ that $l(f(w))\geq l(w)$. Since the same is true for $f^{-1}$, we have $l(f(w))=l(w)$ and the special case $l(w)=1$ is all we need to finish the proof. I have almost no formal knowledge of category theory, but I try to think categorically whenever possible. Since the proposition above can be formulated in categorical language, I assumed there would be an easy proof using only the universal property of $M$. But then I realized that the analogous statement for groups is not true. For example, $\mathbf{Z}$, the free group over a one element set, has two automorphisms. The reason the above proof breaks down is that there we had a (monoid) homomorphism $l:M\rightarrow\mathbf{N}$ with $l(X)=\{1\}$, and such a mapping does not exist if $M$ is the free group over $X$. Questions: Is there a name for (a theory about) the property of categories that the automorphism groups of free objects coincide with the permutation groups of the underlying sets? Is there a ""deeper"" reason that the category of monoids has this property and the category of groups does not?",,"['abstract-algebra', 'category-theory', 'universal-algebra']"
60,On the relationship between the commutators of a Lie group and its Lie algebra,On the relationship between the commutators of a Lie group and its Lie algebra,,"I was trying to teach myself some basic Lie theory, and I came across this statement on Mathworld , relating the commutator of a group, $\alpha\beta\alpha^{-1}\beta^{-1}$, to the commutator of its Lie algebra, $[A,B] = AB-BA$: For instance, let $A$ and $B$ be square matrices, and let $\alpha(s)$ and $\beta(t)$ be paths in the Lie group of nonsingular matrices which satisfy   $$\begin{align}   \alpha(0)=\beta(0)    &=    I    \\   \left.\frac{\partial\alpha}{\partial s}\right|_{s=0}    &=    A    \\   \left.\frac{\partial\beta}{\partial s}\right|_{s=0}    &=    B, \end{align}$$   then   $$\left.\frac{\partial}{\partial s}\frac{\partial}{\partial t}\alpha(s)\beta(t)\alpha^{-1}(s)\beta^{-1}(t)\right|_{(s=0,t=0)}=2[A,B].$$ When I tried to derive this for myself, using the fact that $$\left.\frac{\partial\alpha^{-1}}{\partial s}\right|_{s=0} = \left.-\alpha^{-1}\frac{\partial\alpha}{\partial s}\alpha^{-1}\right|_{s=0} = -A,$$ I expanded the expression to get $$\left.\frac{\partial}{\partial s}\frac{\partial}{\partial t}\alpha\beta\alpha^{-1}\beta^{-1}\right|_{(s=0,t=0)}$$ $$=\left.\left( \frac{\partial\alpha}{\partial s}\frac{\partial\beta}{\partial t}\alpha^{-1}\beta^{-1} + \alpha\frac{\partial\beta}{\partial t}\frac{\partial\alpha^{-1}}{\partial s}\beta^{-1} + \frac{\partial\alpha}{\partial s}\beta\alpha^{-1}\frac{\partial\beta^{-1}}{\partial t} + \alpha\beta\frac{\partial\alpha^{-1}}{\partial s}\frac{\partial\beta^{-1}}{\partial t} \right)\right|_{(s=0,t=0)}$$ $$=AB - BA - AB + AB$$ $$=[A,B].$$ The difference is that the factor of 2 is missing. This seems to agree with the lecture notes I found on MIT OCW , which state (in Ch. 2, PDF 1) that if $X, Y \in \mathfrak{g}$, $\exp(-tX)\exp(-tY)\exp(tX)\exp(tY) = \exp\{t^2[X,Y]+O(t^3)\}$. Since this is not my area of expertise, I wanted to make sure I got things right before I contacted MathWorld about a typo. Have I done something wrong somewhere, or is the MathWorld statement actually an error?","I was trying to teach myself some basic Lie theory, and I came across this statement on Mathworld , relating the commutator of a group, $\alpha\beta\alpha^{-1}\beta^{-1}$, to the commutator of its Lie algebra, $[A,B] = AB-BA$: For instance, let $A$ and $B$ be square matrices, and let $\alpha(s)$ and $\beta(t)$ be paths in the Lie group of nonsingular matrices which satisfy   $$\begin{align}   \alpha(0)=\beta(0)    &=    I    \\   \left.\frac{\partial\alpha}{\partial s}\right|_{s=0}    &=    A    \\   \left.\frac{\partial\beta}{\partial s}\right|_{s=0}    &=    B, \end{align}$$   then   $$\left.\frac{\partial}{\partial s}\frac{\partial}{\partial t}\alpha(s)\beta(t)\alpha^{-1}(s)\beta^{-1}(t)\right|_{(s=0,t=0)}=2[A,B].$$ When I tried to derive this for myself, using the fact that $$\left.\frac{\partial\alpha^{-1}}{\partial s}\right|_{s=0} = \left.-\alpha^{-1}\frac{\partial\alpha}{\partial s}\alpha^{-1}\right|_{s=0} = -A,$$ I expanded the expression to get $$\left.\frac{\partial}{\partial s}\frac{\partial}{\partial t}\alpha\beta\alpha^{-1}\beta^{-1}\right|_{(s=0,t=0)}$$ $$=\left.\left( \frac{\partial\alpha}{\partial s}\frac{\partial\beta}{\partial t}\alpha^{-1}\beta^{-1} + \alpha\frac{\partial\beta}{\partial t}\frac{\partial\alpha^{-1}}{\partial s}\beta^{-1} + \frac{\partial\alpha}{\partial s}\beta\alpha^{-1}\frac{\partial\beta^{-1}}{\partial t} + \alpha\beta\frac{\partial\alpha^{-1}}{\partial s}\frac{\partial\beta^{-1}}{\partial t} \right)\right|_{(s=0,t=0)}$$ $$=AB - BA - AB + AB$$ $$=[A,B].$$ The difference is that the factor of 2 is missing. This seems to agree with the lecture notes I found on MIT OCW , which state (in Ch. 2, PDF 1) that if $X, Y \in \mathfrak{g}$, $\exp(-tX)\exp(-tY)\exp(tX)\exp(tY) = \exp\{t^2[X,Y]+O(t^3)\}$. Since this is not my area of expertise, I wanted to make sure I got things right before I contacted MathWorld about a typo. Have I done something wrong somewhere, or is the MathWorld statement actually an error?",,['abstract-algebra']
61,Proof that a finite separable extension has only finite many intermediate fields,Proof that a finite separable extension has only finite many intermediate fields,,Let $E/F$ be finite separable extension. Is there any proof of the fact that there are only finitely many intermediate fields without using primitive element theorem or fundamental theorem of Galois theory?,Let $E/F$ be finite separable extension. Is there any proof of the fact that there are only finitely many intermediate fields without using primitive element theorem or fundamental theorem of Galois theory?,,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field']"
62,Tensor product of monoids and arbitrary algebraic structures,Tensor product of monoids and arbitrary algebraic structures,,"Question. Do you know a specific example which demonstrates that the tensor product of monoids (as defined below) is not associative? Let $C$ be the category of algebraic structures of a fixed type, and let us denote by $|~|$ the underlying functor $C \to \mathsf{Set}$. For $M,N \in C$ we have a functor $\mathrm{BiHom}(M,N;-) : C \to \mathsf{Set}$ which sends an object $K \in C$ to the set of bihomomorphisms $M \times N \to K$, i.e. maps $|M| \times |N| \to |K|$ which are homomorphisms in each variable when the other one is fixed. Then one can show as usual that $\mathrm{BiHom}(M,N;-)$ is representable and call the universal bihomomorphism $M \times N \to M \otimes N$ the tensor product of $M,N$. This is a straight forward generalization of the well-known case $C=\mathsf{Mod}(R)$ for a commutative ring $R$. Actually, this is a special case of a more general tensor product in concrete categories, studied in the paper ""Tensor products and bimorphisms"", Canad. Math. Bull. 19 (1976) 385-401, by B. Banaschewski and E. Nelson. Here are some examples: For $C=\mathsf{Set}$, the tensor product equals the usual cartesian product. This is also true for $C=\mathsf{Set}_*$. For $C=\mathsf{Grp}$, we get $G \otimes H \cong G^{\mathsf{ab}} \otimes_{\mathbb{Z}} H^{\mathsf{ab}}$, using the Eckmann-Hilton argument . (This differs from the ""tensor product of groups"" studied in the literature). The case $C=\mathsf{CMon}$ is very similar to the well-known case $C=\mathsf{Ab}$ and is spelled out here ; namely, we have internal homs and therefore a hom-tensor-adjunction. The same is true for $C=\mathsf{Mod}(\Lambda)$ for a commutative algebraic monad $\Lambda$, see here , Section 5.3. Note that the tensor product is commutative, and that it commutes with filtered colimits in each variable. However, the case $C=\mathsf{Grp}$ shows that it does not have to commute with coproducts. In particular, tensoring with some object is no left adjoint. Also, the free object on one generator is not a unit in general: Let us consider $C=\mathsf{Mon}$. Then, we have $\mathbb{N} \otimes M = M / \{ (mn)^p = m^p n^p \}_{m,n \in M, p \in \mathbb{N}}$ The usual proof of the associativity of the tensor product breaks down: There is a map $\beta : M \times (N \otimes K) \to (M \otimes N) \otimes K$ mapping $(m, n \otimes k) \mapsto (m \otimes n) \otimes k$, which is a homomorphism in the second variable. But what about the first variable? The equation $\beta(mm',t) = \beta(m,t) \beta(m',t)$ is clear if $t \in N \otimes K$ is a pure tensor. But for $t=(n \otimes k) (n' \otimes k')$ we end up with the unlikely equation $((m \otimes n) \otimes k) ((m' \otimes n) \otimes k) ((m \otimes n') \otimes k') ((m' \otimes n') \otimes k')$ $=((m \otimes n) \otimes k)  ((m \otimes n') \otimes k') ((m' \otimes n) \otimes k) ((m' \otimes n') \otimes k')$","Question. Do you know a specific example which demonstrates that the tensor product of monoids (as defined below) is not associative? Let $C$ be the category of algebraic structures of a fixed type, and let us denote by $|~|$ the underlying functor $C \to \mathsf{Set}$. For $M,N \in C$ we have a functor $\mathrm{BiHom}(M,N;-) : C \to \mathsf{Set}$ which sends an object $K \in C$ to the set of bihomomorphisms $M \times N \to K$, i.e. maps $|M| \times |N| \to |K|$ which are homomorphisms in each variable when the other one is fixed. Then one can show as usual that $\mathrm{BiHom}(M,N;-)$ is representable and call the universal bihomomorphism $M \times N \to M \otimes N$ the tensor product of $M,N$. This is a straight forward generalization of the well-known case $C=\mathsf{Mod}(R)$ for a commutative ring $R$. Actually, this is a special case of a more general tensor product in concrete categories, studied in the paper ""Tensor products and bimorphisms"", Canad. Math. Bull. 19 (1976) 385-401, by B. Banaschewski and E. Nelson. Here are some examples: For $C=\mathsf{Set}$, the tensor product equals the usual cartesian product. This is also true for $C=\mathsf{Set}_*$. For $C=\mathsf{Grp}$, we get $G \otimes H \cong G^{\mathsf{ab}} \otimes_{\mathbb{Z}} H^{\mathsf{ab}}$, using the Eckmann-Hilton argument . (This differs from the ""tensor product of groups"" studied in the literature). The case $C=\mathsf{CMon}$ is very similar to the well-known case $C=\mathsf{Ab}$ and is spelled out here ; namely, we have internal homs and therefore a hom-tensor-adjunction. The same is true for $C=\mathsf{Mod}(\Lambda)$ for a commutative algebraic monad $\Lambda$, see here , Section 5.3. Note that the tensor product is commutative, and that it commutes with filtered colimits in each variable. However, the case $C=\mathsf{Grp}$ shows that it does not have to commute with coproducts. In particular, tensoring with some object is no left adjoint. Also, the free object on one generator is not a unit in general: Let us consider $C=\mathsf{Mon}$. Then, we have $\mathbb{N} \otimes M = M / \{ (mn)^p = m^p n^p \}_{m,n \in M, p \in \mathbb{N}}$ The usual proof of the associativity of the tensor product breaks down: There is a map $\beta : M \times (N \otimes K) \to (M \otimes N) \otimes K$ mapping $(m, n \otimes k) \mapsto (m \otimes n) \otimes k$, which is a homomorphism in the second variable. But what about the first variable? The equation $\beta(mm',t) = \beta(m,t) \beta(m',t)$ is clear if $t \in N \otimes K$ is a pure tensor. But for $t=(n \otimes k) (n' \otimes k')$ we end up with the unlikely equation $((m \otimes n) \otimes k) ((m' \otimes n) \otimes k) ((m \otimes n') \otimes k') ((m' \otimes n') \otimes k')$ $=((m \otimes n) \otimes k)  ((m \otimes n') \otimes k') ((m' \otimes n) \otimes k) ((m' \otimes n') \otimes k')$",,"['abstract-algebra', 'category-theory', 'tensor-products', 'monoid', 'universal-property']"
63,"How ""bad"" can presentation of the trivial group get?","How ""bad"" can presentation of the trivial group get?",,"These questions are sort of preliminary questions and reference requests for a project I am doing. Lets say, for concreteness, that $R$ is a set of words in the free group of rank two and that $\langle a,b \mid R \rangle$ is the trivial group. How ""bad"" can $R$ be? I guess my ideal ""bad"" is that $R$ is infinite and if $\varnothing \neq T \subseteq R $ , then $\langle a,b \mid R \setminus T \rangle$ is not the trivial group. Also how would one go about finding/constructing these ""bad"" $R$ , maybe for finitely generated group in general. I guess a more general question: Let $R_{\text {fam}}$ be a countable family of disjoint sets of words in the free group generated by the set $S$ such that $\langle S \mid \cup R_{\text{fam}} \rangle $ is the trivial group; How ""bad"" can $R_{\text{fam}}$ be? The ""bad"" here is essentially the same except looking at $\cup (R_{\text{fam}}\setminus T)$ where $T$ is some non empty subset of $R_\text{fam}$ . I am mostly looking for an answer to the specific example and references for these sorts of questions. There are plenty of variations, maybe looking at  finite $\langle S|R \rangle$ and looking at how bad that $R$ can get, also looking at ""preloaded"" $R$ , that is $R$ has to have certain relations.","These questions are sort of preliminary questions and reference requests for a project I am doing. Lets say, for concreteness, that is a set of words in the free group of rank two and that is the trivial group. How ""bad"" can be? I guess my ideal ""bad"" is that is infinite and if , then is not the trivial group. Also how would one go about finding/constructing these ""bad"" , maybe for finitely generated group in general. I guess a more general question: Let be a countable family of disjoint sets of words in the free group generated by the set such that is the trivial group; How ""bad"" can be? The ""bad"" here is essentially the same except looking at where is some non empty subset of . I am mostly looking for an answer to the specific example and references for these sorts of questions. There are plenty of variations, maybe looking at  finite and looking at how bad that can get, also looking at ""preloaded"" , that is has to have certain relations.","R \langle a,b \mid R \rangle R R \varnothing \neq T \subseteq R  \langle a,b \mid R \setminus T \rangle R R_{\text {fam}} S \langle S \mid \cup R_{\text{fam}} \rangle  R_{\text{fam}} \cup (R_{\text{fam}}\setminus T) T R_\text{fam} \langle S|R \rangle R R R","['abstract-algebra', 'group-theory']"
64,A group of order $120$ cannot be simple,A group of order  cannot be simple,120,"We know that: Theorem: If a simple group $G$ has a proper subgroup $H$ such that $[G:H]=n$ then $G\hookrightarrow A_n$. This fact can help us to prove that any group $G$ of order $120$ is not simple . In fact, since $n_5(G)=6$ then $[G:N_G(P)]=6$ where $P\in Syl_5(G)$ and so $A_6$ has a subgroup of order $120$ which is impossible. My question is: Can we prove that $G$ of order $120$ is not simple without employing the theorem? Thanks.","We know that: Theorem: If a simple group $G$ has a proper subgroup $H$ such that $[G:H]=n$ then $G\hookrightarrow A_n$. This fact can help us to prove that any group $G$ of order $120$ is not simple . In fact, since $n_5(G)=6$ then $[G:N_G(P)]=6$ where $P\in Syl_5(G)$ and so $A_6$ has a subgroup of order $120$ which is impossible. My question is: Can we prove that $G$ of order $120$ is not simple without employing the theorem? Thanks.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
65,The set of all permutations of indices such that the new series converges to the same limit forms a group?,The set of all permutations of indices such that the new series converges to the same limit forms a group?,,Let $\sum_{i = 1}^{\infty} a_i = s \in \mathbb{C}$ be a convergent series of complex numbers.  Then the set of all permutations $\sigma \in\operatorname{Perm}(\mathbb{N})$ such that $\sum_{i=1}^{\infty} a_{\sigma(i)} = s$  forms a group?  Seems nontrivial to prove if it is true.,Let $\sum_{i = 1}^{\infty} a_i = s \in \mathbb{C}$ be a convergent series of complex numbers.  Then the set of all permutations $\sigma \in\operatorname{Perm}(\mathbb{N})$ such that $\sum_{i=1}^{\infty} a_{\sigma(i)} = s$  forms a group?  Seems nontrivial to prove if it is true.,,"['abstract-algebra', 'sequences-and-series', 'group-theory', 'convergence-divergence']"
66,An undergraduate level example where the set of commutators is proper in the derived subgroup.,An undergraduate level example where the set of commutators is proper in the derived subgroup.,,"The derived subgroup is the subgroup generated by the set of all commutators of a group $G$. I always used to forget that ""generated by"" part.  Soon I will be teaching a group theory course and wish to prevent students from making the same mistake. Is there an easy example, presentable to beginning group theory students, of a group in which the set of commutators is proper in the derived subgroup? I am aware of this question, but the students I will be talking to will be below the level of wreath products, so the paper linked there isn't of any use.  Is there perhaps an example in the infinite groups which would be easier to understand?","The derived subgroup is the subgroup generated by the set of all commutators of a group $G$. I always used to forget that ""generated by"" part.  Soon I will be teaching a group theory course and wish to prevent students from making the same mistake. Is there an easy example, presentable to beginning group theory students, of a group in which the set of commutators is proper in the derived subgroup? I am aware of this question, but the students I will be talking to will be below the level of wreath products, so the paper linked there isn't of any use.  Is there perhaps an example in the infinite groups which would be easier to understand?",,"['abstract-algebra', 'group-theory', 'examples-counterexamples']"
67,"Unsolvability of a Quintic and its link with ""Simplicity"" of $A_{5}$","Unsolvability of a Quintic and its link with ""Simplicity"" of",A_{5},"At the outset I must mention that I don't have a fairly working knowledge of Galois Theory (but do have some idea of group theory in the sense that I can understand normal subgroups). I read the proof of unsolvability of a general quintic via radicals from  J P Tignol's ""Galois Theory of Algebraic Equations"". Here he discusses the proof by Abel and goes on to establish the following theorem (see details in my blog post ): Theorem : Let $x_{1}, x_{2}, \ldots x_{n}$ be indeterminates and let  elements $a, b$ be in field $K = \mathbb{C}(x_{1}, x_{2}, \ldots, x_{n})$ such that $a = b^{p}$ for some prime number $p$. Let $n \geq 5$ and define permutations $\sigma, \tau$ such that $\sigma$ permutes $x_{1}, x_{2}, x_{3}$ cyclically and $\tau$ permutes $x_{3}, x_{4}, x_{5}$ cyclically. If $a$ in invariant under both $\sigma, \tau$ then so is $b$. Because of the equation $a = b^{p}$ the above theorem implies that when $n \geq 5$ there are some symmetries (invariance under $\sigma, \tau$) which remain even after taking radicals. Thus starting with the elementary symmetric function $s_{1}, s_{2}, \ldots, s_{n}$ of the indeterminates $x_{i}$ the process of taking radicals will preserve the symmetries related to $\sigma, \tau$. On the other hand each one of the indeterminates $x_{1}, x_{2}, x_{3}, x_{4}, x_{5}$ is changed via at least one of $\sigma$ and $\tau$. Thus the field $K$ has elements which are changed by $\sigma, \tau$ but any element of a radical extension of $F = \mathbb{C}(s_{1}, s_{2}, \ldots, s_{n})$ is invariant under $\sigma, \tau$ and hence it is not possible to get to $K$ from $F$ via radical extensions. On the other hand most modern treatments of unsolvability of quintic base it on the simplicity of alternating group $A_{5}$. Understanding the above mentioned theorem in Tignol's book is quite easy (simple algebraic manipulation) but its not same as regards to simplicity of $A_{5}$. Is simplicity of $A_{5}$ somehow linked with the above basic theorem? What I need is a proper link between properties of $A_{5}$ and the above theorem. What is so special about elements $\sigma = (1,2,3), \tau = (3,4,5)$ of $A_{5}$? And why don't we have such permutations when $n < 5$ whose symmetries are preserved when taking radicals. Update : I think I need to clarify my point very clearly. The message of the theorem described above is that for $n \geq 5$ there exists a set $P$ of permutations on $n$ symbols such that $P$ includes at least one non-identity permutation and the process of root extraction preserves the symmetries induced by the permutations of $P$. For $n < 5$ root extraction preserves the symmetries induced only by the identity permutation (trivially). My real problem is that I am unable to map this simple concept with the comparatively difficult concept of unsolvability / simplicity of $A_{5}$. There is a feeling that probably the solvability of polynomials is a much simpler concept than the solvability of groups (as least as far the general polynomials with indeterminate coefficients are concerned). At the same time this feeling is crushed by the theorem of Galois that ""a polynomial is solvable by radicals if and only if its galois group is solvable"" so that these concepts are at the same level of depth/difficulty. If it helps, I checked Tignol's book and he mentions that the theorem mentioned above is by Paolo Ruffini and he gives the reference: P. Ruffini, Opere Matematiche (3 vols), E. Bortolotti, ed., Ed. Cremonese  della Casa Editrice Perrella, Roma, 1953-1954. The result is available in pages 162-170 in vol 2. Further Update : I am not getting the kind of answer I need. Perhaps I need to provide a context in the language of Galois Theory. Let's assume fields to be of characteristic $0$ in what follows. Let $f(x) \in F[x]$ be a polynomial and $K$ be splitting field of $f$. Galois theory says that the galois group of $f$ (over field $F$) is the set of automorphisms of $K$ which leave $F$ fixed. Also if $L$ is another field with $F \subseteq L \subseteq K$ then galois group of $f$ over $L$ is a subgroup of its galois group over $F$. Also note that the galois group can be viewed as a subgroup of the group of permutations of roots of polynomial $f(x)$. It is further known that when the field $L$ is obtained by adjoining all roots of an irreducible polynomial $p(x) \in F[x]$ (of degree $k$) so that $L = F(\alpha_{1}, \dots, \alpha_{k})$ and $p(\alpha_{i}) = 0$ for $i = 1, 2, \dots, k$ then the galois group $Gal(K/L)$ is a normal subgroup of $Gal(K/F)$. This case is relevant when $L$ is a radical extension of $F$. In our case $F = \mathbb{C}(s_{1}, \dots, s_{n}), K = \mathbb{C}(x_{1}, \dots, x_{n})$ and we are directly able to find a set of permutations of $x_{i}$ which leave every element of $L$ fixed where $L$ is a radical extension of $F$. Hence if $L$ is any radical extension of $F$ with $F \subseteq L \subseteq K$ then $Gal(K/L)$ contains two permutations $\sigma, \tau$ given above. Since radical extensions correspond to a chain of reducing (getting smaller in size) normal subgroups of $S_{n}$, this shows that the series can never get to the trivial group consisting of identity. In my opinion the theorem by Paolo Ruffini provides a very direct and easily accessible proof of unsolvability of the $S_{5}, A_{5}$ and it is so unlike the usual proofs of unsolvability of $A_{5}$. Let me know if my views are correct.","At the outset I must mention that I don't have a fairly working knowledge of Galois Theory (but do have some idea of group theory in the sense that I can understand normal subgroups). I read the proof of unsolvability of a general quintic via radicals from  J P Tignol's ""Galois Theory of Algebraic Equations"". Here he discusses the proof by Abel and goes on to establish the following theorem (see details in my blog post ): Theorem : Let $x_{1}, x_{2}, \ldots x_{n}$ be indeterminates and let  elements $a, b$ be in field $K = \mathbb{C}(x_{1}, x_{2}, \ldots, x_{n})$ such that $a = b^{p}$ for some prime number $p$. Let $n \geq 5$ and define permutations $\sigma, \tau$ such that $\sigma$ permutes $x_{1}, x_{2}, x_{3}$ cyclically and $\tau$ permutes $x_{3}, x_{4}, x_{5}$ cyclically. If $a$ in invariant under both $\sigma, \tau$ then so is $b$. Because of the equation $a = b^{p}$ the above theorem implies that when $n \geq 5$ there are some symmetries (invariance under $\sigma, \tau$) which remain even after taking radicals. Thus starting with the elementary symmetric function $s_{1}, s_{2}, \ldots, s_{n}$ of the indeterminates $x_{i}$ the process of taking radicals will preserve the symmetries related to $\sigma, \tau$. On the other hand each one of the indeterminates $x_{1}, x_{2}, x_{3}, x_{4}, x_{5}$ is changed via at least one of $\sigma$ and $\tau$. Thus the field $K$ has elements which are changed by $\sigma, \tau$ but any element of a radical extension of $F = \mathbb{C}(s_{1}, s_{2}, \ldots, s_{n})$ is invariant under $\sigma, \tau$ and hence it is not possible to get to $K$ from $F$ via radical extensions. On the other hand most modern treatments of unsolvability of quintic base it on the simplicity of alternating group $A_{5}$. Understanding the above mentioned theorem in Tignol's book is quite easy (simple algebraic manipulation) but its not same as regards to simplicity of $A_{5}$. Is simplicity of $A_{5}$ somehow linked with the above basic theorem? What I need is a proper link between properties of $A_{5}$ and the above theorem. What is so special about elements $\sigma = (1,2,3), \tau = (3,4,5)$ of $A_{5}$? And why don't we have such permutations when $n < 5$ whose symmetries are preserved when taking radicals. Update : I think I need to clarify my point very clearly. The message of the theorem described above is that for $n \geq 5$ there exists a set $P$ of permutations on $n$ symbols such that $P$ includes at least one non-identity permutation and the process of root extraction preserves the symmetries induced by the permutations of $P$. For $n < 5$ root extraction preserves the symmetries induced only by the identity permutation (trivially). My real problem is that I am unable to map this simple concept with the comparatively difficult concept of unsolvability / simplicity of $A_{5}$. There is a feeling that probably the solvability of polynomials is a much simpler concept than the solvability of groups (as least as far the general polynomials with indeterminate coefficients are concerned). At the same time this feeling is crushed by the theorem of Galois that ""a polynomial is solvable by radicals if and only if its galois group is solvable"" so that these concepts are at the same level of depth/difficulty. If it helps, I checked Tignol's book and he mentions that the theorem mentioned above is by Paolo Ruffini and he gives the reference: P. Ruffini, Opere Matematiche (3 vols), E. Bortolotti, ed., Ed. Cremonese  della Casa Editrice Perrella, Roma, 1953-1954. The result is available in pages 162-170 in vol 2. Further Update : I am not getting the kind of answer I need. Perhaps I need to provide a context in the language of Galois Theory. Let's assume fields to be of characteristic $0$ in what follows. Let $f(x) \in F[x]$ be a polynomial and $K$ be splitting field of $f$. Galois theory says that the galois group of $f$ (over field $F$) is the set of automorphisms of $K$ which leave $F$ fixed. Also if $L$ is another field with $F \subseteq L \subseteq K$ then galois group of $f$ over $L$ is a subgroup of its galois group over $F$. Also note that the galois group can be viewed as a subgroup of the group of permutations of roots of polynomial $f(x)$. It is further known that when the field $L$ is obtained by adjoining all roots of an irreducible polynomial $p(x) \in F[x]$ (of degree $k$) so that $L = F(\alpha_{1}, \dots, \alpha_{k})$ and $p(\alpha_{i}) = 0$ for $i = 1, 2, \dots, k$ then the galois group $Gal(K/L)$ is a normal subgroup of $Gal(K/F)$. This case is relevant when $L$ is a radical extension of $F$. In our case $F = \mathbb{C}(s_{1}, \dots, s_{n}), K = \mathbb{C}(x_{1}, \dots, x_{n})$ and we are directly able to find a set of permutations of $x_{i}$ which leave every element of $L$ fixed where $L$ is a radical extension of $F$. Hence if $L$ is any radical extension of $F$ with $F \subseteq L \subseteq K$ then $Gal(K/L)$ contains two permutations $\sigma, \tau$ given above. Since radical extensions correspond to a chain of reducing (getting smaller in size) normal subgroups of $S_{n}$, this shows that the series can never get to the trivial group consisting of identity. In my opinion the theorem by Paolo Ruffini provides a very direct and easily accessible proof of unsolvability of the $S_{5}, A_{5}$ and it is so unlike the usual proofs of unsolvability of $A_{5}$. Let me know if my views are correct.",,"['abstract-algebra', 'galois-theory']"
68,Galois group for $x^6-7x^2+7$,Galois group for,x^6-7x^2+7,"What is the galois group for $x^6-7x^2+7$? My approach: first consider $x^3-7x+7$, it is irreducible by Esenstein, and its discriminant is a square, hence the galois group for this polynomial is$A_3$, and the splitting field for it is$Q(x_1)$ where $x_1$ is a root for $x^3-7x+7$, $[Q(x_1):Q]=3$ The problem I am having now is to find $[L:Q]$ where $L$ is the splitting field for $x^6-7x^2+7$ I know it is at least 6, and at most 24, since $[L:Q(x_1)]$ is at most 8 and at least 2.( Adjoin the square root of the three roots of $x^3-7x+7$ gives $L$ and $[L:Q(x_1)]=8$ when the three square roots are independent) If I know $[L:Q]$ then I also know $|Gal(L/Q)|$ and moreover I know it is transitive and contains $A_3$ as a normal subgroup, then I should be able to compute $Gal(L/Q)$","What is the galois group for $x^6-7x^2+7$? My approach: first consider $x^3-7x+7$, it is irreducible by Esenstein, and its discriminant is a square, hence the galois group for this polynomial is$A_3$, and the splitting field for it is$Q(x_1)$ where $x_1$ is a root for $x^3-7x+7$, $[Q(x_1):Q]=3$ The problem I am having now is to find $[L:Q]$ where $L$ is the splitting field for $x^6-7x^2+7$ I know it is at least 6, and at most 24, since $[L:Q(x_1)]$ is at most 8 and at least 2.( Adjoin the square root of the three roots of $x^3-7x+7$ gives $L$ and $[L:Q(x_1)]=8$ when the three square roots are independent) If I know $[L:Q]$ then I also know $|Gal(L/Q)|$ and moreover I know it is transitive and contains $A_3$ as a normal subgroup, then I should be able to compute $Gal(L/Q)$",,['abstract-algebra']
69,$\mathbb{Q}(\sqrt{23})$ is not a Euclidean number field.,is not a Euclidean number field.,\mathbb{Q}(\sqrt{23}),"The problem I'm facing is that of the tittle: Problem. Prove that $\mathbb{Q}(\sqrt{23})$ is not a Euclidean number field. Since $23\not\equiv 1\pmod{4}$, it must be shown that $\mathbb{Z}[\sqrt{23}]$ is not a Euclidean domain. I know how to show that it is not norm-Euclidean, but it still could be Euclidean with a different function. The only way I know how to prove that a domain is not Euclidean is by using Motzkin's theorem: Theorem. A domain $D$ is Euclidean if and only if   $\bigcap\limits_{i\in\mathbb{N}} P_0^{(i)} = \emptyset$. Here $P_0^{(0)} = P_0 := D\setminus\{0\}$ and we define recursively $P^{(i+1)}_0 := (P^{(i)}_0)'$ for all $i\in\mathbb{N}$, where for any $P\subseteq D$ the derived set $P'$ of $P$ is given by $P' := \{b\in P\, ;\, \exists a\in D\text{ such that }a+bD\subseteq P\}$. It works well for imaginary quadratic fields since they have only $1$ and $-1$ as units: Considering $K := \mathbb{Q}(\sqrt{d})$ for $d < -11$ it can be shown that $P_0^{(i)} = A\setminus\{0, 1, -1\}$ for all integers $i\ge 1$, where $A$ is the ring of integers of $K$, hence by Motzkin theorem $K$ is not Euclidean. But in $\mathbb{Q}(\sqrt{23})$ we have too many units and I can't even determine $P_0''$.","The problem I'm facing is that of the tittle: Problem. Prove that $\mathbb{Q}(\sqrt{23})$ is not a Euclidean number field. Since $23\not\equiv 1\pmod{4}$, it must be shown that $\mathbb{Z}[\sqrt{23}]$ is not a Euclidean domain. I know how to show that it is not norm-Euclidean, but it still could be Euclidean with a different function. The only way I know how to prove that a domain is not Euclidean is by using Motzkin's theorem: Theorem. A domain $D$ is Euclidean if and only if   $\bigcap\limits_{i\in\mathbb{N}} P_0^{(i)} = \emptyset$. Here $P_0^{(0)} = P_0 := D\setminus\{0\}$ and we define recursively $P^{(i+1)}_0 := (P^{(i)}_0)'$ for all $i\in\mathbb{N}$, where for any $P\subseteq D$ the derived set $P'$ of $P$ is given by $P' := \{b\in P\, ;\, \exists a\in D\text{ such that }a+bD\subseteq P\}$. It works well for imaginary quadratic fields since they have only $1$ and $-1$ as units: Considering $K := \mathbb{Q}(\sqrt{d})$ for $d < -11$ it can be shown that $P_0^{(i)} = A\setminus\{0, 1, -1\}$ for all integers $i\ge 1$, where $A$ is the ring of integers of $K$, hence by Motzkin theorem $K$ is not Euclidean. But in $\mathbb{Q}(\sqrt{23})$ we have too many units and I can't even determine $P_0''$.",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
70,Group of order $p^{n}$ has normal subgroups of order $p^{k}$,Group of order  has normal subgroups of order,p^{n} p^{k},"Q: Prove that a subgroup of order $p^n$ has a normal subgroup of order $p^{k}$ for all $0\leq k \leq n$. Attempt at a proof: We proceed by Induction. This is obviously true for $n=1, 2$. Suppose it is true for $m \leq n-1$. Now, take the group $G$ of order $p^{n}$. Since it is a $p$-group, it has a non-trivial center by the Conjugacy Class equation. This center then has a subgroup of $K$ order $p$ by Cauchy's theorem for example. Since this subgroup is contained in the center, it is normal in $G$. Take the quotient $G/K$ which now has order $p^{n-1}$ hence by the induction hypothesis has subgroups $\bar{H_{k}}$ of order $p^{k}$ for $0\leq k \leq n-1$, which are normal in $G/K$. By the lattice isomorphism theorem, the lattice of $G$ has corresponding groups $H_{k}$ which are normal in $G$. The index of each such subgroup is $|G:H_{k}|=|G/K: \bar{H_k}|=p^{n-1-k}$, hence $H_{k}$ has order $p^{k+1}$ in $G$ as desired. Does this look okay?","Q: Prove that a subgroup of order $p^n$ has a normal subgroup of order $p^{k}$ for all $0\leq k \leq n$. Attempt at a proof: We proceed by Induction. This is obviously true for $n=1, 2$. Suppose it is true for $m \leq n-1$. Now, take the group $G$ of order $p^{n}$. Since it is a $p$-group, it has a non-trivial center by the Conjugacy Class equation. This center then has a subgroup of $K$ order $p$ by Cauchy's theorem for example. Since this subgroup is contained in the center, it is normal in $G$. Take the quotient $G/K$ which now has order $p^{n-1}$ hence by the induction hypothesis has subgroups $\bar{H_{k}}$ of order $p^{k}$ for $0\leq k \leq n-1$, which are normal in $G/K$. By the lattice isomorphism theorem, the lattice of $G$ has corresponding groups $H_{k}$ which are normal in $G$. The index of each such subgroup is $|G:H_{k}|=|G/K: \bar{H_k}|=p^{n-1-k}$, hence $H_{k}$ has order $p^{k+1}$ in $G$ as desired. Does this look okay?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory', 'p-groups']"
71,The equivalence classes of $N\sim M\Leftrightarrow G/N\cong G/M$.,The equivalence classes of .,N\sim M\Leftrightarrow G/N\cong G/M,"Let $G$ be a finite group.  Given some $N\unlhd G$, define $$\mathfrak{C}_N:=\{M\unlhd G : G/M \cong G/N\}.$$ How are the subgroups in $\mathfrak{C}_N$ related?  Is there some other description of $\mathfrak{C}_N$? Would there be a more direct way to compute this set than computing $G/N$, then computing $G/M$ for every (appropriate order) $M\unlhd G$ and checking for isomorphism? For an example of what I mean by ""more direct,"" say I wanted all conjugates of some $g\in G$.  I could check each $g^\prime \in G$ to see if there exists an $x$ so that $g^\prime=g^x$, but it would be much easier to just compute $g^x$ for all $x\in G$ (or all $x$ in a transversal of $C_G(g)$ in $G$, if we have that information).  If possible, I'd like to do a similar thing to compute $\mathfrak{C}_N$. Motivation: I am running a computational experiment having to do with this problem (which is becoming somewhat of an obsession) that requires computing the complete partition of the set of normal subgroups of $G$ under $M\sim N \Leftrightarrow M\in \mathfrak{C}_N$.  If $M,N\unlhd G$ are related by an outer automorphism, then surely $M\sim N$, but converse is not necessarily true.  So, we could start by computing $N^{\operatorname{Out}(G)}$ for each $N\unlhd G$, but we would still have to check whether $N\sim M$ between each of those sets, so this is not much of an improvement. EDIT : By the way, if this is too tough for general $G$ as @MartinBrandenburg suggests, I would still be interested to hear an answer for any of the following restricted cases: $p$-groups, nilpotent groups, solvable groups.","Let $G$ be a finite group.  Given some $N\unlhd G$, define $$\mathfrak{C}_N:=\{M\unlhd G : G/M \cong G/N\}.$$ How are the subgroups in $\mathfrak{C}_N$ related?  Is there some other description of $\mathfrak{C}_N$? Would there be a more direct way to compute this set than computing $G/N$, then computing $G/M$ for every (appropriate order) $M\unlhd G$ and checking for isomorphism? For an example of what I mean by ""more direct,"" say I wanted all conjugates of some $g\in G$.  I could check each $g^\prime \in G$ to see if there exists an $x$ so that $g^\prime=g^x$, but it would be much easier to just compute $g^x$ for all $x\in G$ (or all $x$ in a transversal of $C_G(g)$ in $G$, if we have that information).  If possible, I'd like to do a similar thing to compute $\mathfrak{C}_N$. Motivation: I am running a computational experiment having to do with this problem (which is becoming somewhat of an obsession) that requires computing the complete partition of the set of normal subgroups of $G$ under $M\sim N \Leftrightarrow M\in \mathfrak{C}_N$.  If $M,N\unlhd G$ are related by an outer automorphism, then surely $M\sim N$, but converse is not necessarily true.  So, we could start by computing $N^{\operatorname{Out}(G)}$ for each $N\unlhd G$, but we would still have to check whether $N\sim M$ between each of those sets, so this is not much of an improvement. EDIT : By the way, if this is too tough for general $G$ as @MartinBrandenburg suggests, I would still be interested to hear an answer for any of the following restricted cases: $p$-groups, nilpotent groups, solvable groups.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'p-groups', 'computational-algebra']"
72,Flatness of subring,Flatness of subring,,"Let $R$ be a ring with 1, not necessarily commutative, with no zero divisors. Suppose $S$ is a flat extension of $R$. What additional assumptions, if any, would allow us to assert that a subring $R \subseteq T \subseteq S$ must also be flat over $R$? I'm interested in seeing relevant (counter-)examples, as well as any necessary or sufficient conditions you can think of.","Let $R$ be a ring with 1, not necessarily commutative, with no zero divisors. Suppose $S$ is a flat extension of $R$. What additional assumptions, if any, would allow us to assert that a subring $R \subseteq T \subseteq S$ must also be flat over $R$? I'm interested in seeing relevant (counter-)examples, as well as any necessary or sufficient conditions you can think of.",,"['abstract-algebra', 'ring-theory', 'modules', 'flatness']"
73,Modules over Completion,Modules over Completion,,"I have the following question. Let $R$ be a commutative ring with unit, and let $\hat{R}$ denote its completion (w.r.t. any ideal $I$). Let $M$ be an $\hat{R}$-module. Is $M= N\otimes_R \hat{R}$ for some $R$-module $N$?","I have the following question. Let $R$ be a commutative ring with unit, and let $\hat{R}$ denote its completion (w.r.t. any ideal $I$). Let $M$ be an $\hat{R}$-module. Is $M= N\otimes_R \hat{R}$ for some $R$-module $N$?",,"['abstract-algebra', 'commutative-algebra']"
74,'Galois Resolvent' and elementary symmetric polynomials in a paper by Noether,'Galois Resolvent' and elementary symmetric polynomials in a paper by Noether,,"In Emmy Noether's 1915 paper ""Der Endlichkeitssatz der Invarianten endlicher Gruppen"", I saw the notion of a 'Galois resolvent', which I don't quite understand. Google didn't really help me with that, since it seems to be different from what I have found to this notion. Let me try to translate what happens there: We have a finite group $H$ of invertible $n\times n$-matrices $A_1,\dots,A_h$, where $A_k=(a_{ij}^{(k)})$, with entries in some field $K$ of characteristic $0$ (I'm actually not 100% sure if this is sufficient, in a later paper she talks about 'übliche Zahlkörper'). Then $H$ acts on the polynomial ring $K[x_1,\dots,x_n]$, where we set $x=(x_1,\dots,x_n)^T$, via $$(A_k,x)\mapsto A_k\cdot x,$$ and we denote $A_k\cdot x$ also by $x^{(k)}$. Since one of the $A_k$ is the identity, there is a $k$ such that $x^{(k)}=x$. Now a polynomial invariant of $G$ is some $f\in K[x_1,...,x_n]$ for which $A_k\cdot f=f$ for all $k$. In other words, we have $$f(x)=f(x^{(1)})=\dots=f(x^{(h)})=\frac{1}{h}\sum_{k=1}^hf(x^{(k)}).$$ Now comes the part where I'm stuck, I try to translate it as good as I can: This formula expresses that $f$ is a a polynomial, symmetric function in the $x^{(k)}$. The theorem about symmetric functions of ""Größenreihen"" (I don't know how to translate this) says that $f$ can be represented in a polynomial way by the elementary symmetric functions of these ""Reihen"" (series), that is, by the coefficients $G_{\alpha,\alpha_1,\dots,\alpha_n}(x)$ of the ""Galois resolvent"": \begin{align*}\phi(z,u)&=\prod_{k=1}^h(z+u_1x_1^{(k)}+\dots+u_nx_n^{(k)})\\&=z^h+\sum G_{\alpha,\alpha_1,\dots,\alpha_n}(x)z^\alpha u_1^{\alpha_1}\cdots u_n^{\alpha_n}\begin{pmatrix}(\alpha+\alpha_1+\dots+\alpha_n=h)\\\alpha\neq h\end{pmatrix},\end{align*} where the $G_{\alpha,\alpha_1,\dots,\alpha_n}(x)$ are invariants of degree $\alpha_1+\dots+\alpha_n$ in the $x_i$. I actually don't have any idea where $u,z$ come from. I thought there was a nice expression for the elementary symmetric polynomials, and that they are coefficients of a much simpler polynomial. The theorem mentioned above isn't referenced further, I guess the main theorem on symmetric polynomials is meant, but I fail to get the connection to this strange formula. I'd be glad if someone could help me out here, and explain where this 'Galois resolvent' comes from and what's the connection to the 'usual' stuff about symmetric polynomials. Thank you very much in advance!","In Emmy Noether's 1915 paper ""Der Endlichkeitssatz der Invarianten endlicher Gruppen"", I saw the notion of a 'Galois resolvent', which I don't quite understand. Google didn't really help me with that, since it seems to be different from what I have found to this notion. Let me try to translate what happens there: We have a finite group $H$ of invertible $n\times n$-matrices $A_1,\dots,A_h$, where $A_k=(a_{ij}^{(k)})$, with entries in some field $K$ of characteristic $0$ (I'm actually not 100% sure if this is sufficient, in a later paper she talks about 'übliche Zahlkörper'). Then $H$ acts on the polynomial ring $K[x_1,\dots,x_n]$, where we set $x=(x_1,\dots,x_n)^T$, via $$(A_k,x)\mapsto A_k\cdot x,$$ and we denote $A_k\cdot x$ also by $x^{(k)}$. Since one of the $A_k$ is the identity, there is a $k$ such that $x^{(k)}=x$. Now a polynomial invariant of $G$ is some $f\in K[x_1,...,x_n]$ for which $A_k\cdot f=f$ for all $k$. In other words, we have $$f(x)=f(x^{(1)})=\dots=f(x^{(h)})=\frac{1}{h}\sum_{k=1}^hf(x^{(k)}).$$ Now comes the part where I'm stuck, I try to translate it as good as I can: This formula expresses that $f$ is a a polynomial, symmetric function in the $x^{(k)}$. The theorem about symmetric functions of ""Größenreihen"" (I don't know how to translate this) says that $f$ can be represented in a polynomial way by the elementary symmetric functions of these ""Reihen"" (series), that is, by the coefficients $G_{\alpha,\alpha_1,\dots,\alpha_n}(x)$ of the ""Galois resolvent"": \begin{align*}\phi(z,u)&=\prod_{k=1}^h(z+u_1x_1^{(k)}+\dots+u_nx_n^{(k)})\\&=z^h+\sum G_{\alpha,\alpha_1,\dots,\alpha_n}(x)z^\alpha u_1^{\alpha_1}\cdots u_n^{\alpha_n}\begin{pmatrix}(\alpha+\alpha_1+\dots+\alpha_n=h)\\\alpha\neq h\end{pmatrix},\end{align*} where the $G_{\alpha,\alpha_1,\dots,\alpha_n}(x)$ are invariants of degree $\alpha_1+\dots+\alpha_n$ in the $x_i$. I actually don't have any idea where $u,z$ come from. I thought there was a nice expression for the elementary symmetric polynomials, and that they are coefficients of a much simpler polynomial. The theorem mentioned above isn't referenced further, I guess the main theorem on symmetric polynomials is meant, but I fail to get the connection to this strange formula. I'd be glad if someone could help me out here, and explain where this 'Galois resolvent' comes from and what's the connection to the 'usual' stuff about symmetric polynomials. Thank you very much in advance!",,"['abstract-algebra', 'terminology', 'invariant-theory', 'symmetric-polynomials']"
75,"Ideal in an Artinian Ring $I=aR=Rb$, prove $I=Ra=bR$","Ideal in an Artinian Ring , prove",I=aR=Rb I=Ra=bR,"Let $R$ be an Artinian Ring and suppose there exists $a,b\in R$ s.t. $I=aR=Rb$, then prove $I=bR=Ra$. (You may assume that a right Artinian Ring is Right Noetherian). I've managed to get $Ra$, $bR$ contained in $I$ without using the fact that it's Artinian. The hint confuses me because I'm not sure how to make a useful ascending chain to use the fact that it's right Noetherian.","Let $R$ be an Artinian Ring and suppose there exists $a,b\in R$ s.t. $I=aR=Rb$, then prove $I=bR=Ra$. (You may assume that a right Artinian Ring is Right Noetherian). I've managed to get $Ra$, $bR$ contained in $I$ without using the fact that it's Artinian. The hint confuses me because I'm not sure how to make a useful ascending chain to use the fact that it's right Noetherian.",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
76,Understanding $(x)=(y)$ in rings that aren't domains,Understanding  in rings that aren't domains,(x)=(y),"Suppose $R$ is a commutative ring with $1$ . I would like to get a better understanding of the equivalence relation on $R$ $$x\sim y\iff(x)=(y)\iff\exists u,v\in R,~x=uy~\text{ and }~y=vx$$ where $(x)$ is the principal ideal generated by $x$ . Let us also write $$x\approx y\iff \exists u\in R^\times,~x=uy$$ Clearly $x\approx y\implies x\sim y$ holds in any ring. Question 1. Is there a nice description of $\sim$ equivalence classes as unions of $\approx$ equivalence classes ? When $R$ is a domain these two equivalence relations are identical. But some non domains also satisfy this property, for instance all rings $\Bbb{Z}/n\Bbb{Z}$ have this property, too. Below we prove moregenerally that rings of the form $R/\mathfrak{a}$ for $R$ PID have this property. This raises the question: Question 2. Can one characterize the rings $R$ in which the relations $\sim$ and $\approx$ are identical? One can make some simple observations, for instance $\sim$ equivalence classes agree with $\approx$ equivalence classes when $x$ is $0$ , a unit or irreducible. If $x$ is cancellable in the sense that $xu=0\implies u=0$ then the equivalence classes agree, too. If $x\sim y$ and $x$ is nilpotent, then $y$ is nilpotent and $x$ and $y$ have the same nilpotency index, but I'm not sure they are necessarily $\approx$ -equivalent. Question 3. For what types of elements of $R$ do the $\sim$ and $\approx$ equivalence classes agree ? When $R$ is a domain one has that $x$ is irreducible if and only if $(x)$ is maximal in the set of proper principal ideals of $R$ . In a general ring ""irreducible implies maximal"" holds. Question 4. What can be said about $x$ if $(x)$ is maximal in the set of principal ideals $<(1)$ ? Finally, in order to build intuition, I would like to see some examples of non domains where the relations $\approx$ and $\sim$ agree and examples where they disagree. Question 5. What are some good examples of non domains where the relations $\approx$ and $\sim$ agree? Where they disagree? Generalizing the example $\Bbb{Z}/n\Bbb{Z}$ of rings where $\approx~=~\sim$ The fact that the $\sim$ and $\approx$ define the same equivalence relation in the rings $\Bbb{Z}/n\Bbb{Z}$ can be generalized: Lemma. Let $R$ be a PID and $\mathfrak{a}<(1)$ a proper ideal of $R$ . Then $\sim$ and $\approx$ are identical in the quotient ring $R/\mathfrak{a}$ . I'm sure there is a more straightforward proof of this, but here goes. Proof. Since $R$ is a domain there is nothing to prove for $\mathfrak{a}=(0)$ . Suppose $(0)<\mathfrak{a}<(1)$ and let $x$ be a generator: $\mathfrak{a}=(x)$ . Since PIDs are UFDs we can factor $x$ as a product of irreducibles $x=\prod_{i=1}^np_i^{m_i}$ , and so $\mathfrak{a}=(x)=\prod_{i=1}^n\big(p_i^{m_i}\big)$ . Since irreducibles are primes in UFDs and nonzero prime ideals are maximal in PIDs, the nonzero prime ideals $(p_i)=\sqrt{\big(p_i^{m_i}\big)}$ are maximal, pairwise distinct and therefore pairwise coprime. It follows that the ideals $(p_i^{m_i})$ are pairwise coprime. The chinese remainder theorem yields $$R/\mathfrak{a}\simeq\prod_{i=1}^nR/\big(p_i^{m_i}\big)$$ Now for any family of rings $(R_i)_{i\in I}$ we have $$\Big(\prod_{i\in I}R_i\Big)^\times=\prod_{i\in I}R_i^\times$$ and for any rings $R_1,\dots,R_n$ the ideals of the product ring are products of ideals: $$ \begin{array}{ccc} \displaystyle \left\{ \text{ideals of } \displaystyle\prod_{i=1}^n R_i \right\} &=& \displaystyle \left\{ \displaystyle\prod_{i=1}^n \mathfrak{a}_i \text{ for ideals }\mathfrak{a}_i\subset R_i \right\} \\ \style{display: inline-block; transform: rotate(-90deg)}{\subseteq} && \style{display: inline-block; transform: rotate(-90deg)}{\subseteq} \\ \displaystyle \left\{ \text{principal ideals of } \displaystyle\prod_{i=1}^n R_i \right\} &=& \displaystyle \left\{ \displaystyle\prod_{i=1}^n \mathfrak{a}_i \text{ for principal ideals }\mathfrak{a}_i\subset R_i \right\} \end{array}$$ These two elementary propositions show that it is enough to prove that $\sim$ and $\approx$ are equal for quotient rings of the form $R/(p^n)$ for primes $p$ and positive $n$ . Thus, let $p$ be a prime of $R$ and $n\geq 1$ a positive integer. The ring $R/(p^n)$ is local and artinian (because noetherian and zero dimensional) and all its ideals are principal. The proof of Theorem 8.5 in Atiyah-MacDonald shows that all its only ideals are the $(0)<\mathfrak{m}^{n-1}<\cdots<\mathfrak{m}<(1)$ for $k=0,\dots,n$ where $\mathfrak{m}=(p)/(p^n)$ . Now suppose $(x)=(y)$ . Then for some $k$ , $(x)=\mathfrak{m}^k$ and so there exists $u$ with $x=up^k$ . Since $\mathfrak{m}$ is the only prime ideal in $R/(p^n)$ we have $\sqrt{(0)}=\mathfrak{m}$ and $R/(p^n)=\Big(R/(p^n)\Big)^\times\sqcup \mathfrak{m}$ . Therefore, if $u$ were noninvertible it would belong to $\mathfrak{m}$ and so $x\in(p^{k+1})$ whence $(x)\subseteq\mathfrak{m}^{k+1}<\mathfrak{m}^k$ which is a contradiction. Therefore $u$ is invertible. Similarly there exists $v$ invertible with $y=vp^k$ and so $x$ and $y$ are associates. The paper referenced by @HansLundmark actually contains the preceding and generalizes it: $\sim$ and $\approx$ agree for all quasilocal rings, i.e. rings with only finitely many maximal ideals: Since the maximal ideals of $R/\mathfrak{a}$ are precisely the $(p_i)/\mathfrak{a}$ , $i=1,\dots,n$ , quotients of PIDs are quasilocal and thus have the property that $\sim$ and $\approx$ are identical.","Suppose is a commutative ring with . I would like to get a better understanding of the equivalence relation on where is the principal ideal generated by . Let us also write Clearly holds in any ring. Question 1. Is there a nice description of equivalence classes as unions of equivalence classes ? When is a domain these two equivalence relations are identical. But some non domains also satisfy this property, for instance all rings have this property, too. Below we prove moregenerally that rings of the form for PID have this property. This raises the question: Question 2. Can one characterize the rings in which the relations and are identical? One can make some simple observations, for instance equivalence classes agree with equivalence classes when is , a unit or irreducible. If is cancellable in the sense that then the equivalence classes agree, too. If and is nilpotent, then is nilpotent and and have the same nilpotency index, but I'm not sure they are necessarily -equivalent. Question 3. For what types of elements of do the and equivalence classes agree ? When is a domain one has that is irreducible if and only if is maximal in the set of proper principal ideals of . In a general ring ""irreducible implies maximal"" holds. Question 4. What can be said about if is maximal in the set of principal ideals ? Finally, in order to build intuition, I would like to see some examples of non domains where the relations and agree and examples where they disagree. Question 5. What are some good examples of non domains where the relations and agree? Where they disagree? Generalizing the example of rings where The fact that the and define the same equivalence relation in the rings can be generalized: Lemma. Let be a PID and a proper ideal of . Then and are identical in the quotient ring . I'm sure there is a more straightforward proof of this, but here goes. Proof. Since is a domain there is nothing to prove for . Suppose and let be a generator: . Since PIDs are UFDs we can factor as a product of irreducibles , and so . Since irreducibles are primes in UFDs and nonzero prime ideals are maximal in PIDs, the nonzero prime ideals are maximal, pairwise distinct and therefore pairwise coprime. It follows that the ideals are pairwise coprime. The chinese remainder theorem yields Now for any family of rings we have and for any rings the ideals of the product ring are products of ideals: These two elementary propositions show that it is enough to prove that and are equal for quotient rings of the form for primes and positive . Thus, let be a prime of and a positive integer. The ring is local and artinian (because noetherian and zero dimensional) and all its ideals are principal. The proof of Theorem 8.5 in Atiyah-MacDonald shows that all its only ideals are the for where . Now suppose . Then for some , and so there exists with . Since is the only prime ideal in we have and . Therefore, if were noninvertible it would belong to and so whence which is a contradiction. Therefore is invertible. Similarly there exists invertible with and so and are associates. The paper referenced by @HansLundmark actually contains the preceding and generalizes it: and agree for all quasilocal rings, i.e. rings with only finitely many maximal ideals: Since the maximal ideals of are precisely the , , quotients of PIDs are quasilocal and thus have the property that and are identical.","R 1 R x\sim y\iff(x)=(y)\iff\exists u,v\in R,~x=uy~\text{ and }~y=vx (x) x x\approx y\iff \exists u\in R^\times,~x=uy x\approx y\implies x\sim y \sim \approx R \Bbb{Z}/n\Bbb{Z} R/\mathfrak{a} R R \sim \approx \sim \approx x 0 x xu=0\implies u=0 x\sim y x y x y \approx R \sim \approx R x (x) R x (x) <(1) \approx \sim \approx \sim \Bbb{Z}/n\Bbb{Z} \approx~=~\sim \sim \approx \Bbb{Z}/n\Bbb{Z} R \mathfrak{a}<(1) R \sim \approx R/\mathfrak{a} R \mathfrak{a}=(0) (0)<\mathfrak{a}<(1) x \mathfrak{a}=(x) x x=\prod_{i=1}^np_i^{m_i} \mathfrak{a}=(x)=\prod_{i=1}^n\big(p_i^{m_i}\big) (p_i)=\sqrt{\big(p_i^{m_i}\big)} (p_i^{m_i}) R/\mathfrak{a}\simeq\prod_{i=1}^nR/\big(p_i^{m_i}\big) (R_i)_{i\in I} \Big(\prod_{i\in I}R_i\Big)^\times=\prod_{i\in I}R_i^\times R_1,\dots,R_n 
\begin{array}{ccc}
\displaystyle
\left\{
\text{ideals of }
\displaystyle\prod_{i=1}^n R_i
\right\}
&=&
\displaystyle
\left\{
\displaystyle\prod_{i=1}^n \mathfrak{a}_i
\text{ for ideals }\mathfrak{a}_i\subset R_i
\right\}
\\
\style{display: inline-block; transform: rotate(-90deg)}{\subseteq}
&&
\style{display: inline-block; transform: rotate(-90deg)}{\subseteq}
\\
\displaystyle
\left\{
\text{principal ideals of }
\displaystyle\prod_{i=1}^n R_i
\right\}
&=&
\displaystyle
\left\{
\displaystyle\prod_{i=1}^n \mathfrak{a}_i
\text{ for principal ideals }\mathfrak{a}_i\subset R_i
\right\}
\end{array} \sim \approx R/(p^n) p n p R n\geq 1 R/(p^n) (0)<\mathfrak{m}^{n-1}<\cdots<\mathfrak{m}<(1) k=0,\dots,n \mathfrak{m}=(p)/(p^n) (x)=(y) k (x)=\mathfrak{m}^k u x=up^k \mathfrak{m} R/(p^n) \sqrt{(0)}=\mathfrak{m} R/(p^n)=\Big(R/(p^n)\Big)^\times\sqcup \mathfrak{m} u \mathfrak{m} x\in(p^{k+1}) (x)\subseteq\mathfrak{m}^{k+1}<\mathfrak{m}^k u v y=vp^k x y \sim \approx R/\mathfrak{a} (p_i)/\mathfrak{a} i=1,\dots,n \sim \approx","['abstract-algebra', 'ring-theory', 'ideals']"
77,UFD containg a special element,UFD containg a special element,,"Does anyone know an example of a unique factorization domain $R$ that is (i) not a Dedekind domain (or equivalently, not a principal ideal domain) and (ii) contains some irreducible element $r \in R$ such that the quotient $R/rR$ is finite? I am grateful for any suggestions.","Does anyone know an example of a unique factorization domain $R$ that is (i) not a Dedekind domain (or equivalently, not a principal ideal domain) and (ii) contains some irreducible element $r \in R$ such that the quotient $R/rR$ is finite? I am grateful for any suggestions.",,['abstract-algebra']
78,Rings with noncommutative addition,Rings with noncommutative addition,,"I was wondering if ""rings"" with noncommutative addition are studied at all? Of course, if a ring $R$ has a $1$, then for all $a, b\in R$, $a+a+b+b=(1+1)a+(1+1)b=(1+1)(a+b)=(a+b)+(a+b)=a+b+a+b$, from which it follows from cancellation that $a+b=b+a$. Thus, rings with $1$ automatically must have commutative addition. So, are there interesting, necessarily non-unital, ""rings"" with noncommutative addition? Of course, you can take any non-abelian group and make such a ""ring"" by having all multiplications give the additive identity. Are there more interesting examples?","I was wondering if ""rings"" with noncommutative addition are studied at all? Of course, if a ring $R$ has a $1$, then for all $a, b\in R$, $a+a+b+b=(1+1)a+(1+1)b=(1+1)(a+b)=(a+b)+(a+b)=a+b+a+b$, from which it follows from cancellation that $a+b=b+a$. Thus, rings with $1$ automatically must have commutative addition. So, are there interesting, necessarily non-unital, ""rings"" with noncommutative addition? Of course, you can take any non-abelian group and make such a ""ring"" by having all multiplications give the additive identity. Are there more interesting examples?",,"['abstract-algebra', 'ring-theory']"
79,Prove: The pre-image of an ideal is an ideal.,Prove: The pre-image of an ideal is an ideal.,,"Let $\phi : R \to S$ be a homomorphism. If $N$ is an ideal of $S$, then $\phi ^{-1} (N)$ is an ideal of $R$.","Let $\phi : R \to S$ be a homomorphism. If $N$ is an ideal of $S$, then $\phi ^{-1} (N)$ is an ideal of $R$.",,"['abstract-algebra', 'ring-theory', 'ideals']"
80,Give an example of a UFD having a subring which is not a UFD.,Give an example of a UFD having a subring which is not a UFD.,,"Give an example of a UFD having a subring which is not a UFD. I thought of $\mathbb{Z}[\sqrt{2},\sqrt{3}]$. Could you please explain my question. I am trying grasp the concepts, need help.","Give an example of a UFD having a subring which is not a UFD. I thought of $\mathbb{Z}[\sqrt{2},\sqrt{3}]$. Could you please explain my question. I am trying grasp the concepts, need help.",,"['abstract-algebra', 'algebraic-number-theory']"
81,Examples of abelian subgroups of non-abelian groups.,Examples of abelian subgroups of non-abelian groups.,,I'm searching for examples of abelian subgroups of non-abelian groups. Please enlighten me.,I'm searching for examples of abelian subgroups of non-abelian groups. Please enlighten me.,,"['abstract-algebra', 'group-theory', 'examples-counterexamples', 'abelian-groups']"
82,"In general, what techniques can be used to show that 2 groups are not isomorphic?","In general, what techniques can be used to show that 2 groups are not isomorphic?",,"Say I have 2 groups $G$ and $H$, what techniques can be used to show that they are not isomorphic? A simple one I can think of is proving that their order is different, thus showing there cannot be a bijection in between the 2. However I am interested in other approaches as well.","Say I have 2 groups $G$ and $H$, what techniques can be used to show that they are not isomorphic? A simple one I can think of is proving that their order is different, thus showing there cannot be a bijection in between the 2. However I am interested in other approaches as well.",,"['abstract-algebra', 'group-theory', 'group-isomorphism']"
83,Why does Gaussian elimination sometimes work in rings where it should not?,Why does Gaussian elimination sometimes work in rings where it should not?,,"I think it's best to illustrate this with an example. Take for instance the ring of integers modulo $6$ . If I have the system of equations: $$ \begin{aligned} 2x + 2y &= 4 \\ 3x + 4y &= 3 \end{aligned} $$ I divide the first equation by $2$ : $$ \begin{aligned} x +  y &= 2 \\ 3x + 4y &= 3 \end{aligned} $$ Subtract $3$ times the first equation from the 2nd equation to arrive at a solution for $y$ : $$ \begin{aligned} x + y &= 2 \\ 0 + y &= 3 \end{aligned} $$ Thus, $y = 3$ and $x = 5$ . From my understanding, this should be not possible as in ${\Bbb Z}_6$ there is no equivalence to $\frac12$ as $2$ does not have a multiplicative inverse in this ring, but yet I get a solution that works. The best answer I have is that this is just a particular example in which dividing by $2$ was possible from construction, even if it makes no sense in the ring. I know I can invent situations where this would not be possible, for instance, if equation 1 was: $$ 1x +3y = 1 $$ I'm curious if there is anything else at play here, or if it's just luck of construction that an answer could be found.","I think it's best to illustrate this with an example. Take for instance the ring of integers modulo . If I have the system of equations: I divide the first equation by : Subtract times the first equation from the 2nd equation to arrive at a solution for : Thus, and . From my understanding, this should be not possible as in there is no equivalence to as does not have a multiplicative inverse in this ring, but yet I get a solution that works. The best answer I have is that this is just a particular example in which dividing by was possible from construction, even if it makes no sense in the ring. I know I can invent situations where this would not be possible, for instance, if equation 1 was: I'm curious if there is anything else at play here, or if it's just luck of construction that an answer could be found.",6  \begin{aligned} 2x + 2y &= 4 \\ 3x + 4y &= 3 \end{aligned}  2  \begin{aligned} x +  y &= 2 \\ 3x + 4y &= 3 \end{aligned}  3 y  \begin{aligned} x + y &= 2 \\ 0 + y &= 3 \end{aligned}  y = 3 x = 5 {\Bbb Z}_6 \frac12 2 2  1x +3y = 1 ,"['abstract-algebra', 'ring-theory', 'modular-arithmetic', 'gaussian-elimination', 'finite-rings']"
84,Is there a set which is a group with respect to both addition and multiplication?,Is there a set which is a group with respect to both addition and multiplication?,,"Since addition requires 0 as it's identity and 0 has no inverse under multiplication this would seem to suggest that it is impossible but I am unable to prove it or find an example. Perhaps the rules are different enough under complex numbers, quaternions, or octonions to allow such a set to be possible.","Since addition requires 0 as it's identity and 0 has no inverse under multiplication this would seem to suggest that it is impossible but I am unable to prove it or find an example. Perhaps the rules are different enough under complex numbers, quaternions, or octonions to allow such a set to be possible.",,['abstract-algebra']
85,Noetherian property for exact sequence,Noetherian property for exact sequence,,"Let $0 \to M' \xrightarrow{\alpha} M \xrightarrow{\beta} M'' \to 0$ be an exact sequence of $A$-modules. Then $M$ is Noetherian is equivalent to $M'$ and $M''$ are Noetherian. For the ''$\Leftarrow$'' case:  I guess if we let $(L_n)_{n\geq 1}$ be an ascending chain of submodules of $M$, then $(\alpha ^{-1}(L_n))_{n\geq 1}$ is a chain in $M'$, and $(\beta(L_n))_{n\geq 1}$ is a chain in  $M''$. For large $n$ both these chains are stationary. Then why we know the chain $(L_n)$ is stationary? Thanks!","Let $0 \to M' \xrightarrow{\alpha} M \xrightarrow{\beta} M'' \to 0$ be an exact sequence of $A$-modules. Then $M$ is Noetherian is equivalent to $M'$ and $M''$ are Noetherian. For the ''$\Leftarrow$'' case:  I guess if we let $(L_n)_{n\geq 1}$ be an ascending chain of submodules of $M$, then $(\alpha ^{-1}(L_n))_{n\geq 1}$ is a chain in $M'$, and $(\beta(L_n))_{n\geq 1}$ is a chain in  $M''$. For large $n$ both these chains are stationary. Then why we know the chain $(L_n)$ is stationary? Thanks!",,"['abstract-algebra', 'exact-sequence', 'noetherian']"
86,"In a ring, result of multiple (of ""addition"" operation) is not the same as result of multiplication, correct?","In a ring, result of multiple (of ""addition"" operation) is not the same as result of multiplication, correct?",,"In a ring, a multiple for addition is written as $na$ to stand for $(a + a + ... + a)$. This is not necessarily the same as $n * a$ (the ""multiplication"" operation).  Is that correct? Multiple is only the same as multiplication for specific rings such as Integers.  Is that right? I suspect the answer to be the case but I have never seen a proof one way or the other. Thanks","In a ring, a multiple for addition is written as $na$ to stand for $(a + a + ... + a)$. This is not necessarily the same as $n * a$ (the ""multiplication"" operation).  Is that correct? Multiple is only the same as multiplication for specific rings such as Integers.  Is that right? I suspect the answer to be the case but I have never seen a proof one way or the other. Thanks",,['abstract-algebra']
87,About G-Sets (or group actions).,About G-Sets (or group actions).,,"I've been studying group theory for two months, and we're now on ""Actions on a group G"". The definition we were given was this: Definition (Group action): Let $G$ be a group. Let $X$ be a set. We say that $G$ acts on the set $X$ if exists a map   \begin{equation} G \times X \to X\\ (g,x)\to gx, \end{equation}   such that: ($i$) $ex=x$, $\forall x \in X$ ($ii$) $g(hx)=(gh)x$, $\forall g,h\in G, \forall x \in X$. I tried to understand intuitively everything about group theory, but I'm not capable of understand this. Why group actions are important? Is there an intuitive way to understand them? Thank you.","I've been studying group theory for two months, and we're now on ""Actions on a group G"". The definition we were given was this: Definition (Group action): Let $G$ be a group. Let $X$ be a set. We say that $G$ acts on the set $X$ if exists a map   \begin{equation} G \times X \to X\\ (g,x)\to gx, \end{equation}   such that: ($i$) $ex=x$, $\forall x \in X$ ($ii$) $g(hx)=(gh)x$, $\forall g,h\in G, \forall x \in X$. I tried to understand intuitively everything about group theory, but I'm not capable of understand this. Why group actions are important? Is there an intuitive way to understand them? Thank you.",,"['abstract-algebra', 'group-theory']"
88,Classification of groups of order 30 [duplicate],Classification of groups of order 30 [duplicate],,This question already has answers here : How many non isomorphic groups of order 30 are there? (2 answers) Closed 10 years ago . How do I find all the groups of order 30? That is I need to find all the groups with cardinality 30. I know Sylow theorems.,This question already has answers here : How many non isomorphic groups of order 30 are there? (2 answers) Closed 10 years ago . How do I find all the groups of order 30? That is I need to find all the groups with cardinality 30. I know Sylow theorems.,,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory', 'semidirect-product']"
89,If $x^3 =x$ then $6x=0$ in a ring,If  then  in a ring,x^3 =x 6x=0,"Let $R$ be a ring with unity where $$x^3=x,\;\;\; \forall x \in R$$ How do I prove that $$x+x+x+x+x+x=0$$","Let $R$ be a ring with unity where $$x^3=x,\;\;\; \forall x \in R$$ How do I prove that $$x+x+x+x+x+x=0$$",,"['abstract-algebra', 'ring-theory']"
90,$R^n \cong R^m$ iff $n=m$,iff,R^n \cong R^m n=m,"How can i show that two $R$-modules of finite rank are isomorphic if and only if they have the same rank, i.e., $R^n \cong R^m$ iff $n=m$.","How can i show that two $R$-modules of finite rank are isomorphic if and only if they have the same rank, i.e., $R^n \cong R^m$ iff $n=m$.",,"['abstract-algebra', 'commutative-algebra', 'modules']"
91,Irreducibility of $f(x)=x^4+3x^3-9x^2+7x+27$,Irreducibility of,f(x)=x^4+3x^3-9x^2+7x+27,"Question at hand is: Is $x^4+3x^3-9x^2+7x+27$ irreducible in $\Bbb Q$ and/or $\Bbb Z$. This is for an exam, reasoning is trivial, but no calculators in hand. Clearly, if there is a rational root, they are integers by Rational Root theorem and since $f$ is monic. I am aware of Rational root theorem, which narrows down the options to $\pm1,\pm3,\pm9,\pm27$, and clearly, no roots. Eisenstein's Irreducibility Criteria, not helping here, thanks to $x$'s coefficient $7$ Cohn's Irreducibility test: $12197$ is a prime, too large a number to prove that its a prime by hand. Descartes Rule of signs: at most 2 (or 0) positive/negative roots. Close enough. None of which are helping me in any way since I can't use a calculator. These are the solutions I tried: Alpha says all roots are complex. Made me search if there's some way to determine if all roots are complex, reaching nowhere. Check if there are any easy prime generation functions like Euler's, and if lucky 12197 falls in that list, the best I got is Euler's, $n^2+n+41, 1\le n<40$, and biggest such is $1601$, not helping. Are there any better ways to determine if this polynomial is irreducible over $\Bbb Q$, without using calculators?","Question at hand is: Is $x^4+3x^3-9x^2+7x+27$ irreducible in $\Bbb Q$ and/or $\Bbb Z$. This is for an exam, reasoning is trivial, but no calculators in hand. Clearly, if there is a rational root, they are integers by Rational Root theorem and since $f$ is monic. I am aware of Rational root theorem, which narrows down the options to $\pm1,\pm3,\pm9,\pm27$, and clearly, no roots. Eisenstein's Irreducibility Criteria, not helping here, thanks to $x$'s coefficient $7$ Cohn's Irreducibility test: $12197$ is a prime, too large a number to prove that its a prime by hand. Descartes Rule of signs: at most 2 (or 0) positive/negative roots. Close enough. None of which are helping me in any way since I can't use a calculator. These are the solutions I tried: Alpha says all roots are complex. Made me search if there's some way to determine if all roots are complex, reaching nowhere. Check if there are any easy prime generation functions like Euler's, and if lucky 12197 falls in that list, the best I got is Euler's, $n^2+n+41, 1\le n<40$, and biggest such is $1601$, not helping. Are there any better ways to determine if this polynomial is irreducible over $\Bbb Q$, without using calculators?",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials', 'rational-numbers']"
92,Why don't we take clopen maps as morphisms of the category of topological spaces?,Why don't we take clopen maps as morphisms of the category of topological spaces?,,"Here, by clopen maps I mean a function mapping an open set into an open set and a closed set into a closed set. We say continuous maps are the morphisms of the category of the topological spaces. But isn't it more natural to consider clopen maps instead of continuous maps? For example, we say group homomorphisms are the morphisms, and a group homomorphism $h:G\rightarrow H$ preserves the group structure of ""$G$"" in ""$H$"". On the other hand, in some sense, a continuous map $f:X\rightarrow Y$ preserve the topological structure of ""$Y$"" in ""$X$"". The direction is reversed. I am wondering if there is any good explanation for this. Thanks!","Here, by clopen maps I mean a function mapping an open set into an open set and a closed set into a closed set. We say continuous maps are the morphisms of the category of the topological spaces. But isn't it more natural to consider clopen maps instead of continuous maps? For example, we say group homomorphisms are the morphisms, and a group homomorphism $h:G\rightarrow H$ preserves the group structure of ""$G$"" in ""$H$"". On the other hand, in some sense, a continuous map $f:X\rightarrow Y$ preserve the topological structure of ""$Y$"" in ""$X$"". The direction is reversed. I am wondering if there is any good explanation for this. Thanks!",,"['abstract-algebra', 'general-topology', 'category-theory', 'morphism']"
93,"In a ring, how do we prove that a * 0 = 0?","In a ring, how do we prove that a * 0 = 0?",,"In a ring, I was trying to prove that for all $a$, $a0 = 0$. But I found that this depended on a lemma, that is, for all $a$ and $b$, $a(-b) = -ab = (-a)b$. I am wondering how to prove these directly from the definition of a ring. Many thanks!","In a ring, I was trying to prove that for all $a$, $a0 = 0$. But I found that this depended on a lemma, that is, for all $a$ and $b$, $a(-b) = -ab = (-a)b$. I am wondering how to prove these directly from the definition of a ring. Many thanks!",,"['abstract-algebra', 'ring-theory', 'rngs']"
94,Is $\mathbb{Z}[\sqrt{15}]$ a UFD?,Is  a UFD?,\mathbb{Z}[\sqrt{15}],"Let $R=\mathbb{Z}[\sqrt{15}]=\{a+b\sqrt{15}:a,b\in\mathbb{Z}\}$. How do I show that $(3,\sqrt{15})$ is a maximal ideal but not a principal ideal? How do I show that $(3,\sqrt{15})^2$ is a principal ideal? How do I show that $R$ is (not) a UFD? What I have done: If $(3,\sqrt{15})$ is a maximal ideal, then I must show that $R/(3,\sqrt{15})$ is a field. I thought that this holds:$R/(3,\sqrt{15})=\mathbb{Z}/3\mathbb{Z}$. Is this correct? How do I proceed from here? I know that $(3,\sqrt{15})^2=(9,3\sqrt{15},15)$. How can I use this? I'm afraid that I don't know where to start with this one. Maybe one of the statements above can help? Thanks for taking the time!","Let $R=\mathbb{Z}[\sqrt{15}]=\{a+b\sqrt{15}:a,b\in\mathbb{Z}\}$. How do I show that $(3,\sqrt{15})$ is a maximal ideal but not a principal ideal? How do I show that $(3,\sqrt{15})^2$ is a principal ideal? How do I show that $R$ is (not) a UFD? What I have done: If $(3,\sqrt{15})$ is a maximal ideal, then I must show that $R/(3,\sqrt{15})$ is a field. I thought that this holds:$R/(3,\sqrt{15})=\mathbb{Z}/3\mathbb{Z}$. Is this correct? How do I proceed from here? I know that $(3,\sqrt{15})^2=(9,3\sqrt{15},15)$. How can I use this? I'm afraid that I don't know where to start with this one. Maybe one of the statements above can help? Thanks for taking the time!",,"['abstract-algebra', 'ring-theory', 'ideals', 'unique-factorization-domains']"
95,Dimension of $\mathbb{Q}\otimes_{\mathbb{Z}} \mathbb{Q}$ as a vector space over $\mathbb{Q}$,Dimension of  as a vector space over,\mathbb{Q}\otimes_{\mathbb{Z}} \mathbb{Q} \mathbb{Q},"The following problem was subject of examination that was taken place in June. The document is here . Problem 1 states: The tensor product $\mathbb{Q}\otimes_{\mathbb Z}\mathbb{Q}$ is a vector space   over $\mathbb{Q}$ by multiplication in the left factor, i.e.   $\lambda(x\otimes y)=(\lambda x)\otimes y$ for $\lambda, x,  y\in\mathbb{Q}$. What is the dimension of   $\mathbb{Q}\otimes_{\mathbb{Z}}\mathbb{Q}$ as a vector space over   $\mathbb{Q}$? I only know the definition of tensor product for modules (via universal property). How does one go about calculating dimension of such a vector space? Thanks!","The following problem was subject of examination that was taken place in June. The document is here . Problem 1 states: The tensor product $\mathbb{Q}\otimes_{\mathbb Z}\mathbb{Q}$ is a vector space   over $\mathbb{Q}$ by multiplication in the left factor, i.e.   $\lambda(x\otimes y)=(\lambda x)\otimes y$ for $\lambda, x,  y\in\mathbb{Q}$. What is the dimension of   $\mathbb{Q}\otimes_{\mathbb{Z}}\mathbb{Q}$ as a vector space over   $\mathbb{Q}$? I only know the definition of tensor product for modules (via universal property). How does one go about calculating dimension of such a vector space? Thanks!",,"['abstract-algebra', 'vector-spaces', 'tensor-products']"
96,Why does a group homomorphism preserve more structure than a monoid homomorphism while satisfying fewer equations,Why does a group homomorphism preserve more structure than a monoid homomorphism while satisfying fewer equations,,"Is there a deeper (categorical) reason for this? On the one hand a group homomorphism $\phi:(G,\cdot)\to (H,\star)$ preserves 'results of operations' as well as the identity element and inverse elements, but satisfies only one equation: $$\forall g_1,g_2\in G:\phi(g_2\cdot g_1)=\phi(g_2)\star\phi(g_1)$$ while if $\phi$ was a monoid homomorphism instead, it would only preserve the first two things, but need to satisfy the additional equation $$\phi(e_G)=e_H$$ I know how to prove algebraically that a group homomorphism preserves all the mentioned structure, that's not the question. I do not understand why it preserves more structure than the monoid homomorphism, while at the same time having less 'algebraic conditions'. EDIT: I think what really gives me trouble is that going 'in the natural order' from semigroups to monoids to groups, one starts with one equation for semigroup-homomorphisms, then adds an additional equation for monoid-homomorphisms, and then for group-homomorphisms one goes back to one equation. This seems strange to me.","Is there a deeper (categorical) reason for this? On the one hand a group homomorphism $\phi:(G,\cdot)\to (H,\star)$ preserves 'results of operations' as well as the identity element and inverse elements, but satisfies only one equation: $$\forall g_1,g_2\in G:\phi(g_2\cdot g_1)=\phi(g_2)\star\phi(g_1)$$ while if $\phi$ was a monoid homomorphism instead, it would only preserve the first two things, but need to satisfy the additional equation $$\phi(e_G)=e_H$$ I know how to prove algebraically that a group homomorphism preserves all the mentioned structure, that's not the question. I do not understand why it preserves more structure than the monoid homomorphism, while at the same time having less 'algebraic conditions'. EDIT: I think what really gives me trouble is that going 'in the natural order' from semigroups to monoids to groups, one starts with one equation for semigroup-homomorphisms, then adds an additional equation for monoid-homomorphisms, and then for group-homomorphisms one goes back to one equation. This seems strange to me.",,"['abstract-algebra', 'group-theory', 'category-theory', 'group-homomorphism', 'monoid']"
97,"any $2$-dimensional rep of a finite, non-abelian simple group is trivial","any -dimensional rep of a finite, non-abelian simple group is trivial",2,"Let $G$ be a finite, non-abelian simple group. How would I go about proving that any $2$-dimensional representation of $G$ is trivial? If it helps, I know how to do it when we're considering $1$-dimensional representations.","Let $G$ be a finite, non-abelian simple group. How would I go about proving that any $2$-dimensional representation of $G$ is trivial? If it helps, I know how to do it when we're considering $1$-dimensional representations.",,"['abstract-algebra', 'group-theory', 'representation-theory']"
98,"Compute $\operatorname{Hom}_{\mathbb{Z}} ( \mathbb{Q}, \mathbb{Z})$",Compute,"\operatorname{Hom}_{\mathbb{Z}} ( \mathbb{Q}, \mathbb{Z})","I think this question could be a little idiot, however I could not solve this after some hours. I need to find all homomorphism between the additive group $\mathbb{Q}$ and the additive group $\mathbb{Z}$, i.e., $\operatorname{Hom}_{\mathbb{Z}}  ( \mathbb{Q}, \mathbb{Z})$. I tried to find a good set of generators for $\mathbb{Q}$, however none of them  satisfied a general homomorphism.","I think this question could be a little idiot, however I could not solve this after some hours. I need to find all homomorphism between the additive group $\mathbb{Q}$ and the additive group $\mathbb{Z}$, i.e., $\operatorname{Hom}_{\mathbb{Z}}  ( \mathbb{Q}, \mathbb{Z})$. I tried to find a good set of generators for $\mathbb{Q}$, however none of them  satisfied a general homomorphism.",,"['abstract-algebra', 'homological-algebra']"
99,Why is it that the congruence relations usually correspond to some type of subobject?,Why is it that the congruence relations usually correspond to some type of subobject?,,"From the perspective of universal algebra, quotient structures of algebraic structures are built using congruence relations . If $A$ is an algebraic structure (a set with a bunch of operations on the set) und $R$ congruence relation on a set, then the quotient $A/R$ is well-defined and it will be an algebraic structure of the same type. Now, as it turns out, in particular algebraic categories, these congruence relations on $A$ correspond exactly to some type of subobject of $A$ . For instance, the congruence relations on a ring correspond precisely to the ideals of that ring; the congruence relations on a group correspond precisely to the normal subgroups of that group; the congruence relations on a module correspond precisely to the submodules of that module. Why is it that the congruence relations usually correspond to some type of subobject? Is this a general phenomenon that can be generalized to all algebraic structures (as studied in this generality by universal algebra)?","From the perspective of universal algebra, quotient structures of algebraic structures are built using congruence relations . If is an algebraic structure (a set with a bunch of operations on the set) und congruence relation on a set, then the quotient is well-defined and it will be an algebraic structure of the same type. Now, as it turns out, in particular algebraic categories, these congruence relations on correspond exactly to some type of subobject of . For instance, the congruence relations on a ring correspond precisely to the ideals of that ring; the congruence relations on a group correspond precisely to the normal subgroups of that group; the congruence relations on a module correspond precisely to the submodules of that module. Why is it that the congruence relations usually correspond to some type of subobject? Is this a general phenomenon that can be generalized to all algebraic structures (as studied in this generality by universal algebra)?",A R A/R A A,"['abstract-algebra', 'category-theory', 'soft-question', 'ideals', 'universal-algebra']"
