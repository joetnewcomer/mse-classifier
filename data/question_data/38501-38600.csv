,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Clarifications regarding Lagrange resolvent,Clarifications regarding Lagrange resolvent,,"I'm trying to understand the technique used by Lagrange to solve cubic and quartic equations. I have read that the Lagrange resolvent for the cubic is $$ x_1+\omega x_2+ \omega^2 x_3 $$ where $\omega$ is the principal cubic root of 1. My question is: Why isn't the resolvent for the quartic $$ x_1+\omega x_2 +\omega^2 x_3 +\omega^3 x_4 $$ where $\omega$ is the principal quartic root of 1? Why did Lagrange use $x_1-x_2+x_3-x_4$? Is there an intuitive explanation? More generally, is there an intuitive way to understand Lagrange resolvent?","I'm trying to understand the technique used by Lagrange to solve cubic and quartic equations. I have read that the Lagrange resolvent for the cubic is $$ x_1+\omega x_2+ \omega^2 x_3 $$ where $\omega$ is the principal cubic root of 1. My question is: Why isn't the resolvent for the quartic $$ x_1+\omega x_2 +\omega^2 x_3 +\omega^3 x_4 $$ where $\omega$ is the principal quartic root of 1? Why did Lagrange use $x_1-x_2+x_3-x_4$? Is there an intuitive explanation? More generally, is there an intuitive way to understand Lagrange resolvent?",,"['abstract-algebra', 'polynomials', 'galois-theory', 'quartics']"
1,What's With The Diagonal Morphism?,What's With The Diagonal Morphism?,,"Given a morphism $X \to Y$ of schemes, we can construct a diagonal morphism $\delta: X \to X \times_Y X$ via the universal property of the fiber product applied to the identity map $X \to X$. Recently, I've been puzzled (shocked even) by how many different properties or results about schemes can be phrased in terms of the diagonal morphism. Does anyone have intuition as to why this map is so important and why this should be the case? In particular, I've been thinking about the following collection of statements: 1) Separatedness: We say a morphism $\pi: X \to Y$ is separated if the diagonal morphism is a closed embedding. 2) Quasi-separatedness: $\pi: X \to Y$ is quasi-separated if the diagonal morphism is quasi-compact. 3) Cancellation Property: If $P$ is a class of morphisms preserved by base change and composition and we have the maps $\pi: X \to Y, \rho: Y \to Z, \tau: X \to Z$, then if the diagonal $Y \to Y \times_Z Y$ and $\tau$ are in $P$, so is $\pi$. 4) $\pi: X \to Y$ is universally injective if it is injective after any base change. $\pi$ is universally injective iff the diagonal morphism is surjective. This is apparently the analog for schemes of a purely inseparable extension of fields. 5) Given $\pi: X \to Y$ the relative cotangent sheaf $\Omega_{X/Y}$ is the conormal sheaf of the diagonal morphism. 6) $B$ is a separable $A$-algebra if $B$ is projective as a $B \otimes_A B$-module. 7) If $\pi: X \to Y$ is locally finite type, then $\pi$ is unramified iff the diagonal is an open immersion.","Given a morphism $X \to Y$ of schemes, we can construct a diagonal morphism $\delta: X \to X \times_Y X$ via the universal property of the fiber product applied to the identity map $X \to X$. Recently, I've been puzzled (shocked even) by how many different properties or results about schemes can be phrased in terms of the diagonal morphism. Does anyone have intuition as to why this map is so important and why this should be the case? In particular, I've been thinking about the following collection of statements: 1) Separatedness: We say a morphism $\pi: X \to Y$ is separated if the diagonal morphism is a closed embedding. 2) Quasi-separatedness: $\pi: X \to Y$ is quasi-separated if the diagonal morphism is quasi-compact. 3) Cancellation Property: If $P$ is a class of morphisms preserved by base change and composition and we have the maps $\pi: X \to Y, \rho: Y \to Z, \tau: X \to Z$, then if the diagonal $Y \to Y \times_Z Y$ and $\tau$ are in $P$, so is $\pi$. 4) $\pi: X \to Y$ is universally injective if it is injective after any base change. $\pi$ is universally injective iff the diagonal morphism is surjective. This is apparently the analog for schemes of a purely inseparable extension of fields. 5) Given $\pi: X \to Y$ the relative cotangent sheaf $\Omega_{X/Y}$ is the conormal sheaf of the diagonal morphism. 6) $B$ is a separable $A$-algebra if $B$ is projective as a $B \otimes_A B$-module. 7) If $\pi: X \to Y$ is locally finite type, then $\pi$ is unramified iff the diagonal is an open immersion.",,"['abstract-algebra', 'algebraic-geometry', 'soft-question', 'schemes']"
2,When does $(ab)^n = a^n b^n$ imply a group is abelian?,When does  imply a group is abelian?,(ab)^n = a^n b^n,"Suppose the identity $(ab)^n = a^n b^n$ holds in a group for some $n\in\mathbb{Z}$. For which $n$ does this necessarily imply the group is abelian? For example, when $n=-1$ or $n=2$, the group must be abelian. Are there any other such $n$, or can we construct a non-abelian group with this property for all $n\neq -1, 2$?","Suppose the identity $(ab)^n = a^n b^n$ holds in a group for some $n\in\mathbb{Z}$. For which $n$ does this necessarily imply the group is abelian? For example, when $n=-1$ or $n=2$, the group must be abelian. Are there any other such $n$, or can we construct a non-abelian group with this property for all $n\neq -1, 2$?",,"['abstract-algebra', 'group-theory']"
3,"$x^n = x$ implies commutativity, a universal algebraic proof?","implies commutativity, a universal algebraic proof?",x^n = x,"I read in an answer on MO that Nathan Jacobson had given a universal algebraic proof that a ring satisfying the equation $x^n=x$ is commutative. The sketch given in the answer is very clear : wlog one may assume that $R$ is subdirectly irreducible, as a result of a general result in universal algebra (that is, it has a minimum nonzero ideal). Then one proves that a subdirectly irreducible ring satisfying the equation is a finite (skew, a priori) field, and one concludes from Wedderburn's theorem that it's commutative. But I'm having trouble with the interesting step, that is A subdirectly irreducible ring satisfying the equation $x^n=x$ for some $n\geq 2$ is a finite division ring I had the folliwing idea : since $R$ has no nilpotent elements it should be a subdirect product of integral domains satisfying the same equations - however I know this property for commutative rings, and it relies on the well-known fact that $\displaystyle\bigcap\{p, p\in \mathrm{Spec}R\} = \{x, x$ is nilpotent $\}$ - and I don't know whether this is true for noncommutative rings. As a matter of fact I'm pretty much convinced that it's not true (in $M_n(K)$, $K$ a field, $n\geq 2$, the set of nilpotent elements isn't a bilateral ideal - indeed there are no nontrivial ones). So unless this idea can be saved by the specifics of the situation, I can't go any further with it. What I also noticed (I don't know if that can help though) is that $I^2 = I$, if $I$ denotes the minimum nonzero ideal. I can also sort of make a connection with Wedderburn's theorem by studying the case where $Z(R)$ (the center) is a field; and so $R$ is a $Z(R)$-vector space. Then, it's a finite field. I can't yet see why $Z(R)$ would be finite dimensional (this would probably help a lot). Am I anywhere near the right direction ? Can anyone give some hints to solve this ? (If possible - I know sometimes it's not- I'd rather see some hints than a full solution; and also if someone has read the article in question and saw that the proof in question was longer than what an MS answer can suggest, I'd also like to know haha) EDIT: Here's the MO question : https://mathoverflow.net/questions/30220/abstract-thought-vs-calculation The answer I'm mentioning should be recognizable","I read in an answer on MO that Nathan Jacobson had given a universal algebraic proof that a ring satisfying the equation $x^n=x$ is commutative. The sketch given in the answer is very clear : wlog one may assume that $R$ is subdirectly irreducible, as a result of a general result in universal algebra (that is, it has a minimum nonzero ideal). Then one proves that a subdirectly irreducible ring satisfying the equation is a finite (skew, a priori) field, and one concludes from Wedderburn's theorem that it's commutative. But I'm having trouble with the interesting step, that is A subdirectly irreducible ring satisfying the equation $x^n=x$ for some $n\geq 2$ is a finite division ring I had the folliwing idea : since $R$ has no nilpotent elements it should be a subdirect product of integral domains satisfying the same equations - however I know this property for commutative rings, and it relies on the well-known fact that $\displaystyle\bigcap\{p, p\in \mathrm{Spec}R\} = \{x, x$ is nilpotent $\}$ - and I don't know whether this is true for noncommutative rings. As a matter of fact I'm pretty much convinced that it's not true (in $M_n(K)$, $K$ a field, $n\geq 2$, the set of nilpotent elements isn't a bilateral ideal - indeed there are no nontrivial ones). So unless this idea can be saved by the specifics of the situation, I can't go any further with it. What I also noticed (I don't know if that can help though) is that $I^2 = I$, if $I$ denotes the minimum nonzero ideal. I can also sort of make a connection with Wedderburn's theorem by studying the case where $Z(R)$ (the center) is a field; and so $R$ is a $Z(R)$-vector space. Then, it's a finite field. I can't yet see why $Z(R)$ would be finite dimensional (this would probably help a lot). Am I anywhere near the right direction ? Can anyone give some hints to solve this ? (If possible - I know sometimes it's not- I'd rather see some hints than a full solution; and also if someone has read the article in question and saw that the proof in question was longer than what an MS answer can suggest, I'd also like to know haha) EDIT: Here's the MO question : https://mathoverflow.net/questions/30220/abstract-thought-vs-calculation The answer I'm mentioning should be recognizable",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra', 'universal-algebra']"
4,What is this algebraic object called?,What is this algebraic object called?,,"I was playing around with the following object: Let $Q$ be a set with a binary operator $\cdot$ obeying the axioms: $a \cdot a = a$ (idempotence) $a \cdot (b \cdot c) = (a \cdot b) \cdot (a \cdot c)$ (left self-distributivity) Examples of this would be group conjugation, semilattices, and quandles in knot theory. Does this general algebraic object have a name, and has it been studied?","I was playing around with the following object: Let $Q$ be a set with a binary operator $\cdot$ obeying the axioms: $a \cdot a = a$ (idempotence) $a \cdot (b \cdot c) = (a \cdot b) \cdot (a \cdot c)$ (left self-distributivity) Examples of this would be group conjugation, semilattices, and quandles in knot theory. Does this general algebraic object have a name, and has it been studied?",,"['abstract-algebra', 'magma']"
5,"Centralizer, Normalizer and Stabilizer - intuition","Centralizer, Normalizer and Stabilizer - intuition",,What is the motivation/intuition behind these concepts? What notion/property of a group do they capture? Or what is the scenario of application. Thanks.,What is the motivation/intuition behind these concepts? What notion/property of a group do they capture? Or what is the scenario of application. Thanks.,,"['abstract-algebra', 'group-theory', 'intuition']"
6,How many strategies are there for this puzzle where one of n logicians must call his own hat's color among n?,How many strategies are there for this puzzle where one of n logicians must call his own hat's color among n?,,"$n$ logicians are wearing hats which can be of $n$ different colors. Each logician can see the colors of all hats except his own. The logicians must simultaneously call out a color; they win if at least one calls the color of his own hat. Mathematically, a strategy is an element of $(C^{n-1} \to C)^n$ where $C$ is the set of hat colors ($\mathrm{card}(C) = n$); a strategy $(d_0,\ldots,d_{n-1})$ is given by the decision procedures of each logician, where logician $k$ calls out $d_k(h_0, \ldots, h_{k-1}, h_{k+1}, \ldots, h_{n-1})$ when the hat colors are $(h_0, \ldots, h_{n-1})$. One winning strategy for this classic puzzle is having numbered the logicians and the colors, each logician calls the color that is his own number minus the sum of the hat colors that he sees (all modulo $n$). Then whoever has the number corresponding to the sum of the colors is calling out his own hat's color. This isn't the only solution. (Hint: the case $n=2$ is easy. Now concentrate on $n=4$ and try to reduce it to the previous case.) You can rephrase the strategy above this way: let $h_0, \ldots, h_{n-1}$ be the hat colors of logicians $0, \ldots, n-1$; logician $k$ calls out the value of $h_k$ that makes the equation $h_0 + \ldots + h_{n-1} = k$ true. More generally, equip the set of colors $C = \{c_0, \ldots, c_{n-1}\}$ with any group structure $(C, *)$, and assign each logician a unique color $\ell_k$; then a winning strategy is for each logician $k$ to solve the equation $h_0 * h_1 * \ldots * h_{n-1} = \ell_k$ for $h_k$ and call out the solution. Hence every group structure leads to a winning strategy. Are the strategies presented above are all there is? If not, is there a reasonable way to describe the collection of all winning strategies, such as relating them to another well-known mathematical structure? For example, how many distinct strategies are there for a given $n$?","$n$ logicians are wearing hats which can be of $n$ different colors. Each logician can see the colors of all hats except his own. The logicians must simultaneously call out a color; they win if at least one calls the color of his own hat. Mathematically, a strategy is an element of $(C^{n-1} \to C)^n$ where $C$ is the set of hat colors ($\mathrm{card}(C) = n$); a strategy $(d_0,\ldots,d_{n-1})$ is given by the decision procedures of each logician, where logician $k$ calls out $d_k(h_0, \ldots, h_{k-1}, h_{k+1}, \ldots, h_{n-1})$ when the hat colors are $(h_0, \ldots, h_{n-1})$. One winning strategy for this classic puzzle is having numbered the logicians and the colors, each logician calls the color that is his own number minus the sum of the hat colors that he sees (all modulo $n$). Then whoever has the number corresponding to the sum of the colors is calling out his own hat's color. This isn't the only solution. (Hint: the case $n=2$ is easy. Now concentrate on $n=4$ and try to reduce it to the previous case.) You can rephrase the strategy above this way: let $h_0, \ldots, h_{n-1}$ be the hat colors of logicians $0, \ldots, n-1$; logician $k$ calls out the value of $h_k$ that makes the equation $h_0 + \ldots + h_{n-1} = k$ true. More generally, equip the set of colors $C = \{c_0, \ldots, c_{n-1}\}$ with any group structure $(C, *)$, and assign each logician a unique color $\ell_k$; then a winning strategy is for each logician $k$ to solve the equation $h_0 * h_1 * \ldots * h_{n-1} = \ell_k$ for $h_k$ and call out the solution. Hence every group structure leads to a winning strategy. Are the strategies presented above are all there is? If not, is there a reasonable way to describe the collection of all winning strategies, such as relating them to another well-known mathematical structure? For example, how many distinct strategies are there for a given $n$?",,"['combinatorics', 'abstract-algebra', 'puzzle']"
7,Integrals of a Hopf algebra: Why that name?,Integrals of a Hopf algebra: Why that name?,,"1. Context: The notion of an integral Let $H$ be a Hopf algebra over a field $\mathbb k$ . We call its $\mathbb k$ -linear subspace $$  I_l(H)= \{x \in H; h \cdot x=\epsilon(h)x \quad for \>all\>h\in H\} $$ the space of left integrals. In other words, $I_l(H)$ is the space of left invariants for $H$ acting on itself by multiplication. In a similar manner one can define (the space of) right (co)integrals. Integrals seem to have a wide range of applications. For instance, they appear in a strong ""(Hopf algebra) version"" of Maschke's theorem, i.e. they are related to the semisimplicity of a Hopf algebra. 2. Question Why are integrals called integrals? Specifically, I think I overheard someone saying that they can be related to the notion of an integral in calculus. How so?","1. Context: The notion of an integral Let be a Hopf algebra over a field . We call its -linear subspace the space of left integrals. In other words, is the space of left invariants for acting on itself by multiplication. In a similar manner one can define (the space of) right (co)integrals. Integrals seem to have a wide range of applications. For instance, they appear in a strong ""(Hopf algebra) version"" of Maschke's theorem, i.e. they are related to the semisimplicity of a Hopf algebra. 2. Question Why are integrals called integrals? Specifically, I think I overheard someone saying that they can be related to the notion of an integral in calculus. How so?","H \mathbb k \mathbb k 
 I_l(H)= \{x \in H; h \cdot x=\epsilon(h)x \quad for \>all\>h\in H\}
 I_l(H) H","['abstract-algebra', 'soft-question', 'modules', 'terminology', 'hopf-algebras']"
8,Enumerating Bianchi circles,Enumerating Bianchi circles,,"Background: Katherine Stange describes Schmidt arrangements in ""Visualising the arithmetic of imaginary quadratic fields"", arXiv:1410.0417 . Given an imaginary quadratic field $K$, we study the Bianchi group $\mathrm{PSL}_2(\mathcal{O}_K)$, which is the group of Möbius transformations with coefficients in the ring of integers of $K$. The image of $\mathbb R$ under a group element is called a $K$-Bianchi circle, and the set of $K$-Bianchi circles is called a Schmidt arrangement. Here's an example from Stange's image gallery , taking $K=\mathbb Q(\sqrt{-7})$ and drawing all circles with curvature up to $30\sqrt 7$ that intersect the fundamental domain of $\mathcal{O}_K$: My question: How can I recreate such images for arbitrary $K$, starting from rational integer arithmetic? What algorithms would I need to write C++ code from scratch to enumerate a Schmidt arrangement? (I prefer not to pull a Sage package off the shelf.) It's a straightforward task to implement the basic arithmetic operations of $K$, $\mathcal{O}_K$, and $\mathrm{GL}_2(\mathcal{O}_K)$. Then, a brute-force approach is to generate lots of matrices in $\mathrm{GL}_2(\mathcal{O}_K)$, check if each has determinant $1$, and if so, draw the appropriate circle. There are many problems with this brute-force approach: It wastes most of its time inspecting matrices without determinant $1$, especially as we search for large-norm coefficients and high-curvature circles. It also wastes time on circles that are outside the bounds of the illustration. It revisits many group elements that generate the same circle. We should quotient out the stabilizer of $\mathbb R$, namely the modular group $\mathrm{PSL}_2(\mathbb Z)$. It's unclear how many matrices need to be tested before we can say that we've enumerated all the circles in a diagram like Stange's. Whenever I reach for a more clever approach, I'm slowed down by the fact that $\mathcal{O}_K$ isn't necessarily a unique factorization domain, and even when it is, it isn't necessarily Euclidean. How can we enumerate something like $\mathrm{PSL}_2(\mathcal{O}_K)$ with reasonable efficiency when $K$ is so unruly? Edit: To explain my last remark, we're looking for matrices $\pmatrix{a&b\\c&d}$ with coefficients in $\mathcal{O}_K$ where $ad-bc=1$. Each row and column of such a matrix consists of two coprime numbers. How does one enumerate pairs of coprime numbers in a non-Euclidean ring? (Or is this the wrong sub-problem to tackle?)","Background: Katherine Stange describes Schmidt arrangements in ""Visualising the arithmetic of imaginary quadratic fields"", arXiv:1410.0417 . Given an imaginary quadratic field $K$, we study the Bianchi group $\mathrm{PSL}_2(\mathcal{O}_K)$, which is the group of Möbius transformations with coefficients in the ring of integers of $K$. The image of $\mathbb R$ under a group element is called a $K$-Bianchi circle, and the set of $K$-Bianchi circles is called a Schmidt arrangement. Here's an example from Stange's image gallery , taking $K=\mathbb Q(\sqrt{-7})$ and drawing all circles with curvature up to $30\sqrt 7$ that intersect the fundamental domain of $\mathcal{O}_K$: My question: How can I recreate such images for arbitrary $K$, starting from rational integer arithmetic? What algorithms would I need to write C++ code from scratch to enumerate a Schmidt arrangement? (I prefer not to pull a Sage package off the shelf.) It's a straightforward task to implement the basic arithmetic operations of $K$, $\mathcal{O}_K$, and $\mathrm{GL}_2(\mathcal{O}_K)$. Then, a brute-force approach is to generate lots of matrices in $\mathrm{GL}_2(\mathcal{O}_K)$, check if each has determinant $1$, and if so, draw the appropriate circle. There are many problems with this brute-force approach: It wastes most of its time inspecting matrices without determinant $1$, especially as we search for large-norm coefficients and high-curvature circles. It also wastes time on circles that are outside the bounds of the illustration. It revisits many group elements that generate the same circle. We should quotient out the stabilizer of $\mathbb R$, namely the modular group $\mathrm{PSL}_2(\mathbb Z)$. It's unclear how many matrices need to be tested before we can say that we've enumerated all the circles in a diagram like Stange's. Whenever I reach for a more clever approach, I'm slowed down by the fact that $\mathcal{O}_K$ isn't necessarily a unique factorization domain, and even when it is, it isn't necessarily Euclidean. How can we enumerate something like $\mathrm{PSL}_2(\mathcal{O}_K)$ with reasonable efficiency when $K$ is so unruly? Edit: To explain my last remark, we're looking for matrices $\pmatrix{a&b\\c&d}$ with coefficients in $\mathcal{O}_K$ where $ad-bc=1$. Each row and column of such a matrix consists of two coprime numbers. How does one enumerate pairs of coprime numbers in a non-Euclidean ring? (Or is this the wrong sub-problem to tackle?)",,"['abstract-algebra', 'algebraic-number-theory', 'visualization', 'computational-algebra', 'quadratic-integer-rings']"
9,Perfect closure is perfect,Perfect closure is perfect,,"I've been self-studying inseparable extensions and there's something that seems obvious to everybody but not to me. Let's clear out some definitions that are not so universal: Let $K$ be a field and $f\in K[X]$ a polynomial. We say it is separable if all its roots are distinct over its splitting field. We say it is purely inseparable if it has only one root over its splitting field, and this root is multiple. A field extension $F\subset K$ is purely inseparable (resp. separable ) if every element of $K$ is the root of a purely inseparable (resp. *separable) polynomial in $F[X]$. A field K is perfect if every irreducible polynomial over K is separable. Let $F\subset K$ be a field extension of characteristic $p$. The perfect closure , or purely inseparable closure of $F$ in $K$ is the greatest intermediate field that is purely inseparable over $F$. We will denote it by $K^p_F$ We can prove that $K^p_F$ consists of all the elements $\alpha\in K$ such that there is $n\in \mathbb{N}$ such that $\alpha^{p^n}\in F$. Another property that may be useful is that an irreducible polynomial over a field of characteristic $p$ splits on its splitting field like this: $$f(X)= a_0(X-a_1)^{p^n} \dots (X-a_r)^{p^n}$$ where the $a_1,\dots,a_r$ are pairwise distinct. Now, why is it true that $K^p_F$ is a perfect field? Please try to prove it only using these definitions and properties. EDIT: I have also proved that A field is perfect iff every finite extension is separable, iff every algebraic    extension is separable. which may come in handy.","I've been self-studying inseparable extensions and there's something that seems obvious to everybody but not to me. Let's clear out some definitions that are not so universal: Let $K$ be a field and $f\in K[X]$ a polynomial. We say it is separable if all its roots are distinct over its splitting field. We say it is purely inseparable if it has only one root over its splitting field, and this root is multiple. A field extension $F\subset K$ is purely inseparable (resp. separable ) if every element of $K$ is the root of a purely inseparable (resp. *separable) polynomial in $F[X]$. A field K is perfect if every irreducible polynomial over K is separable. Let $F\subset K$ be a field extension of characteristic $p$. The perfect closure , or purely inseparable closure of $F$ in $K$ is the greatest intermediate field that is purely inseparable over $F$. We will denote it by $K^p_F$ We can prove that $K^p_F$ consists of all the elements $\alpha\in K$ such that there is $n\in \mathbb{N}$ such that $\alpha^{p^n}\in F$. Another property that may be useful is that an irreducible polynomial over a field of characteristic $p$ splits on its splitting field like this: $$f(X)= a_0(X-a_1)^{p^n} \dots (X-a_r)^{p^n}$$ where the $a_1,\dots,a_r$ are pairwise distinct. Now, why is it true that $K^p_F$ is a perfect field? Please try to prove it only using these definitions and properties. EDIT: I have also proved that A field is perfect iff every finite extension is separable, iff every algebraic    extension is separable. which may come in handy.",,"['abstract-algebra', 'field-theory']"
10,What is the correct notion of unique factorization in a ring?,What is the correct notion of unique factorization in a ring?,,"I was recently writing some notes on basic commutative ring theory, and was trying to convince myself why it was a good idea to study integral domains when it comes to unique factorization. If $R$ is a commutative ring, and $a$ is a zero divisor, we cannot expect $a$ generally to have unique factorization in the ordinary sense, seen for example by the fact that $2*4=2$ in $\mathbb{Z}/6\mathbb{Z}$. But this only makes me think that instead of focusing on domains, we should just focus on element that aren't zero divisors. Indeed, we can let $R_z$ be the set of elements that aren't zero divisors. Then if $R$ is nontrivial, $R_z$ is a commutative monoid under multiplication that contains the units. Moreover $R_z$ has the nice property that any if $a_1\dots a_n = b$ is some factorization of $b \in R_z$, then all the $a_i$ are in $R_z$. In this setting, we can say that $R$ having unique factorization means that $R_z/R^\times$ is a free commutative monoid. In the case that $R$ is a domain, this agrees with the definition of a UFD. Now standard arguments about factorization of nonzero elements in domains seem to work just as well for $R_z$. For example in a Noetherian ring, every element of $R_z$ can be factored into some irreducibles times a unit. Similarly, the proof seems to go through that principle ideal rings are unique factorization rings (in my sense). So my questions are: Is what I'm saying correct? If so, why do we normally restrict to domains when many arguments go through for arbitrary rings with no more effort (as long as we are willing to ignore zero-divisors)? Are there other natural generalizations of unique factorization of elements of a ring for which analogous theorems can be proven without more difficulty? By looking at this question, I found this and this , which did have examples of generalizations of unique factorization to more general rings. The first one essentially considers a tame type of ring where zero divisors are not so bad in terms of factorization, and my impression of the second one is that it exerts a lot of effort trying to generalize the notion of unique factorization to the extent that it becomes significantly more complicated. Any suggestions are appreciated.","I was recently writing some notes on basic commutative ring theory, and was trying to convince myself why it was a good idea to study integral domains when it comes to unique factorization. If $R$ is a commutative ring, and $a$ is a zero divisor, we cannot expect $a$ generally to have unique factorization in the ordinary sense, seen for example by the fact that $2*4=2$ in $\mathbb{Z}/6\mathbb{Z}$. But this only makes me think that instead of focusing on domains, we should just focus on element that aren't zero divisors. Indeed, we can let $R_z$ be the set of elements that aren't zero divisors. Then if $R$ is nontrivial, $R_z$ is a commutative monoid under multiplication that contains the units. Moreover $R_z$ has the nice property that any if $a_1\dots a_n = b$ is some factorization of $b \in R_z$, then all the $a_i$ are in $R_z$. In this setting, we can say that $R$ having unique factorization means that $R_z/R^\times$ is a free commutative monoid. In the case that $R$ is a domain, this agrees with the definition of a UFD. Now standard arguments about factorization of nonzero elements in domains seem to work just as well for $R_z$. For example in a Noetherian ring, every element of $R_z$ can be factored into some irreducibles times a unit. Similarly, the proof seems to go through that principle ideal rings are unique factorization rings (in my sense). So my questions are: Is what I'm saying correct? If so, why do we normally restrict to domains when many arguments go through for arbitrary rings with no more effort (as long as we are willing to ignore zero-divisors)? Are there other natural generalizations of unique factorization of elements of a ring for which analogous theorems can be proven without more difficulty? By looking at this question, I found this and this , which did have examples of generalizations of unique factorization to more general rings. The first one essentially considers a tame type of ring where zero divisors are not so bad in terms of factorization, and my impression of the second one is that it exerts a lot of effort trying to generalize the notion of unique factorization to the extent that it becomes significantly more complicated. Any suggestions are appreciated.",,"['abstract-algebra', 'ring-theory', 'prime-factorization', 'unique-factorization-domains']"
11,Strategy for determining the number of homomorphisms between two Groups,Strategy for determining the number of homomorphisms between two Groups,,"The Gallian Abstract Algebra text has a number of exercises of the form 'Determine the number of homomorphisms between two groups $G$ and $H$'. It is pointed out that, in the case of a cyclic $G$, determining the image of a generator of $G$ under a homomorphism $\phi$ suffices to specify the entire mapping, since $\phi(g^n)=\phi(g)^n$ for any $g \in G$. Hence determining the number of homomorphisms simplifies to counting generators of $H$ and applying Lagrange's Theorem. Are there any other useful properties of homomorphisms that can be used as tricks for this type of problem or just general strategies when counting maps between $\textbf{non-cyclic groups}$? Two examples I see in the text exercises are: (1): Determine all homomorphisms from $S_3$ to $G$, where $G$ is Abelian. (2): Determine the number of homomorphisms from $Z_p\oplus Z_p\to Z_p$, where $p$ is prime ($Z_p$ being a subgroup of the additive integers). Thanks in advance!","The Gallian Abstract Algebra text has a number of exercises of the form 'Determine the number of homomorphisms between two groups $G$ and $H$'. It is pointed out that, in the case of a cyclic $G$, determining the image of a generator of $G$ under a homomorphism $\phi$ suffices to specify the entire mapping, since $\phi(g^n)=\phi(g)^n$ for any $g \in G$. Hence determining the number of homomorphisms simplifies to counting generators of $H$ and applying Lagrange's Theorem. Are there any other useful properties of homomorphisms that can be used as tricks for this type of problem or just general strategies when counting maps between $\textbf{non-cyclic groups}$? Two examples I see in the text exercises are: (1): Determine all homomorphisms from $S_3$ to $G$, where $G$ is Abelian. (2): Determine the number of homomorphisms from $Z_p\oplus Z_p\to Z_p$, where $p$ is prime ($Z_p$ being a subgroup of the additive integers). Thanks in advance!",,"['abstract-algebra', 'group-theory']"
12,Basic counterexample re: preimages of ideals,Basic counterexample re: preimages of ideals,,"I'm trying to think of an example of a homomorphism of commutative rings $f:A\rightarrow B$ and ideals $I,J$ of $B$ such that $f^{-1}(I)+f^{-1}(J)$ is not a preimage of any ideal of $B$.  I can't seem to come up with one... anyone know one? Edit: To clear up some basic facts / head off some mistakes: As Arturo points out, we can assume $f$ is an inclusion.  Perhaps I should have written the question in terms of inclusions in the first place, but, eh. No, $f^{-1}(I)+f^{-1}(J)$ is not equal to $f^{-1}(I+J)$ in general.  A counterexample would be the inclusion of $\mathbb{C}$ in $\mathbb{C}[x]$; consider $(x)$ and $(1-x)$. To show an ideal $K\subseteq A$ is not a preimage of any ideal of $B$, it suffices to show that it's not equal to $f^{-1}(Bf(K))$.","I'm trying to think of an example of a homomorphism of commutative rings $f:A\rightarrow B$ and ideals $I,J$ of $B$ such that $f^{-1}(I)+f^{-1}(J)$ is not a preimage of any ideal of $B$.  I can't seem to come up with one... anyone know one? Edit: To clear up some basic facts / head off some mistakes: As Arturo points out, we can assume $f$ is an inclusion.  Perhaps I should have written the question in terms of inclusions in the first place, but, eh. No, $f^{-1}(I)+f^{-1}(J)$ is not equal to $f^{-1}(I+J)$ in general.  A counterexample would be the inclusion of $\mathbb{C}$ in $\mathbb{C}[x]$; consider $(x)$ and $(1-x)$. To show an ideal $K\subseteq A$ is not a preimage of any ideal of $B$, it suffices to show that it's not equal to $f^{-1}(Bf(K))$.",,"['abstract-algebra', 'commutative-algebra', 'examples-counterexamples']"
13,Continuations in mathematics: nice examples?,Continuations in mathematics: nice examples?,,"I wondered whether continuations, used in computer science, occur as natural and interesting mathematical structures, perhaps as algebraic (in the theory of monoids?), model-theoretic or type theoretic structures, of some kind. Continuations as I understand them are monads (which in turn are monoids). More precisely, suppose that our monad maps types of some kind to other types. Let $\alpha, \beta$ be types and $\rightarrow$ be a mapping between types, and let $a : \alpha \hspace{0.2cm}$ (or $b: \beta)$ indicate that $a\hspace{0.2cm}$ (or $b$) is an expression of type $\alpha \hspace{0.2cm}$ (or $\beta)$. Then a continuation monad is a structure $\thinspace(\mathbb{M}, \eta, ⋆)\thinspace$, with $\eta$ the unit and ⋆  the binary operation of the monoid) such that: $$\mathbb{M} \thinspace α = (α → ω) → ω, \hspace{1cm} ∀α$$ $$η(a) = λc. c(a) : \mathbb{M} \thinspace α \hspace{1cm} ∀a : α $$ $$m ⋆ k = λc. m (λa. k(a)(c)): \mathbb{M}\thinspace β \hspace{1cm} ∀m : \mathbb{M}\thinspace α, k : α → \mathbb{M}\thinspace β . $$ Continuation monads have been used to effect a mapping that is available in full second order logic (discussed in two previous questions on this site: Principal ultrafilters and The existence of a function between the individuals of the domain and the set of all subsets of the domain in SOL ) from an individual in  a domain to the principle ultrafilter containing that individual (see for example https://arxiv.org/abs/cs/0205026 ). In type theoretic terms we thus map an individual of type $e$ (the type of individuals) to something of type $(e → t) → t$ (the type of sets of sets), matching the original treatment of English quantification by Montague (1974). However, I wondered whether the particular type of monad that continuations exemplify occurs in mathematical structures that mathematicians study. Perhaps there are interesting structures, for example involving ultrafilters that are examples of continuations. The following link discusses the relation between continuations and the Yoneda embedding: https://reperiendi.wordpress.com/2007/12/19/the-continuation-passing-transform-and-the-yoneda-embedding/ However, I would be particularly interested in examples of mathematical structures that act like continuations in fields such as algebra (perhaps in the theory of monoids?), set theory or model theory (and outside of category theory).","I wondered whether continuations, used in computer science, occur as natural and interesting mathematical structures, perhaps as algebraic (in the theory of monoids?), model-theoretic or type theoretic structures, of some kind. Continuations as I understand them are monads (which in turn are monoids). More precisely, suppose that our monad maps types of some kind to other types. Let $\alpha, \beta$ be types and $\rightarrow$ be a mapping between types, and let $a : \alpha \hspace{0.2cm}$ (or $b: \beta)$ indicate that $a\hspace{0.2cm}$ (or $b$) is an expression of type $\alpha \hspace{0.2cm}$ (or $\beta)$. Then a continuation monad is a structure $\thinspace(\mathbb{M}, \eta, ⋆)\thinspace$, with $\eta$ the unit and ⋆  the binary operation of the monoid) such that: $$\mathbb{M} \thinspace α = (α → ω) → ω, \hspace{1cm} ∀α$$ $$η(a) = λc. c(a) : \mathbb{M} \thinspace α \hspace{1cm} ∀a : α $$ $$m ⋆ k = λc. m (λa. k(a)(c)): \mathbb{M}\thinspace β \hspace{1cm} ∀m : \mathbb{M}\thinspace α, k : α → \mathbb{M}\thinspace β . $$ Continuation monads have been used to effect a mapping that is available in full second order logic (discussed in two previous questions on this site: Principal ultrafilters and The existence of a function between the individuals of the domain and the set of all subsets of the domain in SOL ) from an individual in  a domain to the principle ultrafilter containing that individual (see for example https://arxiv.org/abs/cs/0205026 ). In type theoretic terms we thus map an individual of type $e$ (the type of individuals) to something of type $(e → t) → t$ (the type of sets of sets), matching the original treatment of English quantification by Montague (1974). However, I wondered whether the particular type of monad that continuations exemplify occurs in mathematical structures that mathematicians study. Perhaps there are interesting structures, for example involving ultrafilters that are examples of continuations. The following link discusses the relation between continuations and the Yoneda embedding: https://reperiendi.wordpress.com/2007/12/19/the-continuation-passing-transform-and-the-yoneda-embedding/ However, I would be particularly interested in examples of mathematical structures that act like continuations in fields such as algebra (perhaps in the theory of monoids?), set theory or model theory (and outside of category theory).",,"['abstract-algebra', 'category-theory', 'model-theory', 'monads']"
14,Can extending a finite ground field make modules isomorphic?,Can extending a finite ground field make modules isomorphic?,,"$\def\Hom{\mathrm{Hom}}$Let $k$ be a field, $A$ a $k$-algebra and let $M$ and $N$ be $A$-modules, finite dimensional over $k$. Let $K$ be an extension of $k$, so $A \otimes K$ is a $K$-algebra and $M \otimes K$ and $N \otimes K$ are $A \otimes K$ modules. I would like to say that, if $M \otimes K \cong N \otimes K$, then $M \cong N$. When $k$ is infinite, there is a very easy proof. The $K$-vector space $\Hom_{A\otimes K}(M\otimes K, N \otimes K)$ is simply $\Hom_{A}(M,N) \otimes K$. Saying $M \cong N$ means that there is a matrix in $\Hom_{A}(M, N)$ with nonzero determinant. If the polynomial $\det( \ )$ is nonzero somewhere after extending scalars, then it is already nonzero over $k$. But, over a finite field, this argument is broken. If $M$ and $N$ were dimension $3$ over $k = \mathbb{F}_2$, and $\Hom(M,N)$ consisted of those matrices of the form $\left( \begin{smallmatrix} x & 0 & 0 \\ 0 & y & 0 \\ 0 & 0 & x-y \end{smallmatrix} \right)$, then this matrix is singular for any $(x,y) \in k^2$, but in extension fields it can be invertible. Nonetheless, I think I have an argument that the statement is true for finite fields as well. Has anyone seen this statement before? Is there an easy proof I missed?","$\def\Hom{\mathrm{Hom}}$Let $k$ be a field, $A$ a $k$-algebra and let $M$ and $N$ be $A$-modules, finite dimensional over $k$. Let $K$ be an extension of $k$, so $A \otimes K$ is a $K$-algebra and $M \otimes K$ and $N \otimes K$ are $A \otimes K$ modules. I would like to say that, if $M \otimes K \cong N \otimes K$, then $M \cong N$. When $k$ is infinite, there is a very easy proof. The $K$-vector space $\Hom_{A\otimes K}(M\otimes K, N \otimes K)$ is simply $\Hom_{A}(M,N) \otimes K$. Saying $M \cong N$ means that there is a matrix in $\Hom_{A}(M, N)$ with nonzero determinant. If the polynomial $\det( \ )$ is nonzero somewhere after extending scalars, then it is already nonzero over $k$. But, over a finite field, this argument is broken. If $M$ and $N$ were dimension $3$ over $k = \mathbb{F}_2$, and $\Hom(M,N)$ consisted of those matrices of the form $\left( \begin{smallmatrix} x & 0 & 0 \\ 0 & y & 0 \\ 0 & 0 & x-y \end{smallmatrix} \right)$, then this matrix is singular for any $(x,y) \in k^2$, but in extension fields it can be invertible. Nonetheless, I think I have an argument that the statement is true for finite fields as well. Has anyone seen this statement before? Is there an easy proof I missed?",,"['abstract-algebra', 'modules', 'finite-fields']"
15,Group of order $pq$ is not simple,Group of order  is not simple,pq,Is the following correct way of showing that there is no simple group of order $pq$ where $p$ and $q$ are distinct primes? If $|G|=n=pq$ then the only two Sylow subgroups are of order $p$ and $q$. From Sylow's third theorem we know that $n_p | q$ which means that $n_p=1$ or $n_p=q$. If $n_p=1$ then we are done (by a corollary of Sylow's theorem) If $n_p=q$ then we have accounted for $q(p-1)=pq-q$ elements of $G$ and so there is only one group of order $q$ and again we are done. Is that correct?,Is the following correct way of showing that there is no simple group of order $pq$ where $p$ and $q$ are distinct primes? If $|G|=n=pq$ then the only two Sylow subgroups are of order $p$ and $q$. From Sylow's third theorem we know that $n_p | q$ which means that $n_p=1$ or $n_p=q$. If $n_p=1$ then we are done (by a corollary of Sylow's theorem) If $n_p=q$ then we have accounted for $q(p-1)=pq-q$ elements of $G$ and so there is only one group of order $q$ and again we are done. Is that correct?,,"['abstract-algebra', 'group-theory']"
16,Does there exist an infinite non-abelian group such that all of its proper subgroups become cyclic?,Does there exist an infinite non-abelian group such that all of its proper subgroups become cyclic?,,"We have simple examples of finite groups (that may be abelian or not) that are not cyclic but all their proper subgroups are cyclic (e.g. Klein's $4$ -group and $S_3$ respectively for abelian and non-abelian). In recent times, I have been able to produce a few examples of infinite abelian groups that are not cyclic but all their proper subgroups are cyclic. But currently, I am pondering whether the same can also be said for some infinite non-abelian group or not, precisely, does there exist an infinite non-abelian group such that all of its proper subgroups become cyclic? And if there do exist such groups, what can be an example? And if possible , it will be very much helpful if someone can give a general algorithm for constructing such a group.","We have simple examples of finite groups (that may be abelian or not) that are not cyclic but all their proper subgroups are cyclic (e.g. Klein's -group and respectively for abelian and non-abelian). In recent times, I have been able to produce a few examples of infinite abelian groups that are not cyclic but all their proper subgroups are cyclic. But currently, I am pondering whether the same can also be said for some infinite non-abelian group or not, precisely, does there exist an infinite non-abelian group such that all of its proper subgroups become cyclic? And if there do exist such groups, what can be an example? And if possible , it will be very much helpful if someone can give a general algorithm for constructing such a group.",4 S_3,['abstract-algebra']
17,What's next for me?,What's next for me?,,"I'm in my last year of undergrad, and I would like to do original research for my senior thesis.  I am already published in finite group theory and am looking for a new topic to study. I have taken the graduate algebra sequence at my university, which was primarily galois theory and representation theory.  I didn't find Galois theory very interesting (I guess I don't understand the motivation.)  Representation theory was cool, but I must admit my intuitive grasp on modules and abstract linear algebra is not yet perfect.  I've also taken real and complex analysis, combinatorics, cryptography, number theory, and a lot of physics.  I pretty much unilaterally do not enjoy physics or analysis.  The others were pretty neat.  I performed well in all but the analysis classes. A few of the topics I've bookmarked which seem interesting, in no particular order: algebraic graph theory, knot theory, noncommutative ring theory, module theory, lie theory, tessellations/tilings, homology,  combinatorial game theory, fusion systems, algebraic combinatorics.  (I have no idea what background you need for any of these, or whether I would actually like them- they just sounded like possibilities.)  Do any of these seem suitable? Given my interests and background, what would be a good area of math for me to look into next? An ideal answer would suggest an area of math and include one or more small subtopics which could help inspire me to want to learn that area.  For example, ""Noncommutative ring theory is the perfect next step for you. You should explore commuting graphs."" To be clear I'm not looking for specific problems like ""prove that xxx is true.""  I am more looking for recommendations which fit my mathematical tastes, contain a few somewhat unstudied topics where I might find some ""low hanging apple"" research problems, and would be reasonably accessible for someone with my background. EDIT: To  those who think I shouldn't even be asking this question, please let me reiterate what I have said in the comments.  First, nobody at my school works in algebra, so I can't just ask a prof. Second, if you believe it would be better for me to study an advanced topic without trying to do original research, please let me reiterate that it is okay if I do not produce original results for the thesis.  I can just write an expository paper on what I've been reading.  Again, I have already done independent research, so I know from experience that it is a good motivator for me to have a topic to relate everything back to when I am exploring a new subject.  An open topic is just a ""carrot on a stick"" to motivate my study habits.  Finally, I am just looking for a bunch of suggestions- I don't have to do any of them if they aren't a good fit.  Thanks for reading.","I'm in my last year of undergrad, and I would like to do original research for my senior thesis.  I am already published in finite group theory and am looking for a new topic to study. I have taken the graduate algebra sequence at my university, which was primarily galois theory and representation theory.  I didn't find Galois theory very interesting (I guess I don't understand the motivation.)  Representation theory was cool, but I must admit my intuitive grasp on modules and abstract linear algebra is not yet perfect.  I've also taken real and complex analysis, combinatorics, cryptography, number theory, and a lot of physics.  I pretty much unilaterally do not enjoy physics or analysis.  The others were pretty neat.  I performed well in all but the analysis classes. A few of the topics I've bookmarked which seem interesting, in no particular order: algebraic graph theory, knot theory, noncommutative ring theory, module theory, lie theory, tessellations/tilings, homology,  combinatorial game theory, fusion systems, algebraic combinatorics.  (I have no idea what background you need for any of these, or whether I would actually like them- they just sounded like possibilities.)  Do any of these seem suitable? Given my interests and background, what would be a good area of math for me to look into next? An ideal answer would suggest an area of math and include one or more small subtopics which could help inspire me to want to learn that area.  For example, ""Noncommutative ring theory is the perfect next step for you. You should explore commuting graphs."" To be clear I'm not looking for specific problems like ""prove that xxx is true.""  I am more looking for recommendations which fit my mathematical tastes, contain a few somewhat unstudied topics where I might find some ""low hanging apple"" research problems, and would be reasonably accessible for someone with my background. EDIT: To  those who think I shouldn't even be asking this question, please let me reiterate what I have said in the comments.  First, nobody at my school works in algebra, so I can't just ask a prof. Second, if you believe it would be better for me to study an advanced topic without trying to do original research, please let me reiterate that it is okay if I do not produce original results for the thesis.  I can just write an expository paper on what I've been reading.  Again, I have already done independent research, so I know from experience that it is a good motivator for me to have a topic to relate everything back to when I am exploring a new subject.  An open topic is just a ""carrot on a stick"" to motivate my study habits.  Finally, I am just looking for a bunch of suggestions- I don't have to do any of them if they aren't a good fit.  Thanks for reading.",,"['abstract-algebra', 'combinatorics', 'reference-request', 'soft-question', 'advice']"
18,different definitions of Hopf algebras,different definitions of Hopf algebras,,"(i). In the book Algebraic Topology, A. Hatcher, p. 283 ， the notion Hopf algebra is defined as follows: (ii). However, in the book Bialgebras and Hopf algebras, J.P. May , the notion Hopf algebra is defined as follows: Question: why the definition in (ii) is much more complicated than the definition in (i)? Are the two definitions of Hopf algebra in (i) and (ii) equivalent or different? I do not understand the definition in (ii). Another question: for an $H$-space (we can strengthen to topological monoid up to homotopy) $X$ and coefficient ring $R$, will the homology $$ H_*(X;R) $$ be a Hopf algebra according to the definition in (ii)?","(i). In the book Algebraic Topology, A. Hatcher, p. 283 ， the notion Hopf algebra is defined as follows: (ii). However, in the book Bialgebras and Hopf algebras, J.P. May , the notion Hopf algebra is defined as follows: Question: why the definition in (ii) is much more complicated than the definition in (i)? Are the two definitions of Hopf algebra in (i) and (ii) equivalent or different? I do not understand the definition in (ii). Another question: for an $H$-space (we can strengthen to topological monoid up to homotopy) $X$ and coefficient ring $R$, will the homology $$ H_*(X;R) $$ be a Hopf algebra according to the definition in (ii)?",,"['abstract-algebra', 'ring-theory', 'algebraic-topology', 'homology-cohomology', 'hopf-algebras']"
19,The order of subgroup generated by two distinct elements of order 2,The order of subgroup generated by two distinct elements of order 2,,"$G$ is a group of order $2$6. If $x$ and $y$ are two distinct elements of order $2$, what could the order of $\langle x,y\rangle$ be? By Lagrange's theorem, $\langle x\rangle$ and $\langle y\rangle$ are subgroups of $\langle x,y\rangle$, so order $\langle x,y\rangle$ has to be divisible by $2$. $\langle x,y\rangle$ is a subgroup of $G$, so the possibilities are $2$, $13$, $26$. Since $13$ is not divisible by $2$, and $x,y$ have order $2$, so $x,y$ are not identities and hence order of $\langle x,y\rangle = 26$. Is something wrong with my proof? I couldnt think of any example though...","$G$ is a group of order $2$6. If $x$ and $y$ are two distinct elements of order $2$, what could the order of $\langle x,y\rangle$ be? By Lagrange's theorem, $\langle x\rangle$ and $\langle y\rangle$ are subgroups of $\langle x,y\rangle$, so order $\langle x,y\rangle$ has to be divisible by $2$. $\langle x,y\rangle$ is a subgroup of $G$, so the possibilities are $2$, $13$, $26$. Since $13$ is not divisible by $2$, and $x,y$ have order $2$, so $x,y$ are not identities and hence order of $\langle x,y\rangle = 26$. Is something wrong with my proof? I couldnt think of any example though...",,"['abstract-algebra', 'group-theory', 'proof-verification', 'finite-groups']"
20,Is every field of characteristic zero a divisible group (under addition)?,Is every field of characteristic zero a divisible group (under addition)?,,"I am convinced about this, directly from the definition, but I found it strange that I could not find a reference. Every field of characteristic zero contains $\mathbb{Q}$ and hence given and natural number $n$ and any element field element, say $g$, we can write $f=g*\frac{1}{n}$ and then, $nf=g$. Am I doing something wrong here?","I am convinced about this, directly from the definition, but I found it strange that I could not find a reference. Every field of characteristic zero contains $\mathbb{Q}$ and hence given and natural number $n$ and any element field element, say $g$, we can write $f=g*\frac{1}{n}$ and then, $nf=g$. Am I doing something wrong here?",,"['abstract-algebra', 'group-theory']"
21,Cardinal numbers of right factors of a group,Cardinal numbers of right factors of a group,,"Let $A$ and $B$ be subsets of a group $G$ . The product $AB$ is called direct (and we denote it by $A \cdot B$ , e.g., see this ) if the representation of each element $x$ of $AB$ as $x=ab$ , $a\in A$ , $b\in B$ is unique (equivalently $A^{-1}A \cap BB^{-1}=\{1\}$ , where $A^{-1}:=\{ a^{-1}:a\in A\}$ ). Question. Let $G$ be a group and $A,B,C$ be subsets such that $G=A \cdot B=A \cdot C$ . Then, is it true that $|B|=|C|$ ? ( $|.|$ denotes the cardinal number) Discussion. If $G$ is finite, then the answer is positive, since $|A \cdot B|=|A||B|=|A||C|$ . If $1\in A$ (without loss of generality) and $A^{-1}A \subseteq AA^{-1}$ , then we can define an injective (projection) map from $B$ to $C$ and also $C$ to $B$ . Therefore, if there is a negative answer, it should be through infinite non-abelian groups $G$ (and infinite subsets $A$ with $A^{-1}A \nsubseteq AA^{-1}$ ). Also see $AA^{-1} \subseteq A^{-1}A$ for every infinite subset $A$ of $G$ .","Let and be subsets of a group . The product is called direct (and we denote it by , e.g., see this ) if the representation of each element of as , , is unique (equivalently , where ). Question. Let be a group and be subsets such that . Then, is it true that ? ( denotes the cardinal number) Discussion. If is finite, then the answer is positive, since . If (without loss of generality) and , then we can define an injective (projection) map from to and also to . Therefore, if there is a negative answer, it should be through infinite non-abelian groups (and infinite subsets with ). Also see $AA^{-1} \subseteq A^{-1}A$ for every infinite subset $A$ of $G$ .","A B G AB A \cdot B x AB x=ab a\in A b\in B A^{-1}A \cap BB^{-1}=\{1\} A^{-1}:=\{ a^{-1}:a\in A\} G A,B,C G=A \cdot B=A \cdot C |B|=|C| |.| G |A \cdot B|=|A||B|=|A||C| 1\in A A^{-1}A \subseteq AA^{-1} B C C B G A A^{-1}A \nsubseteq AA^{-1}","['abstract-algebra', 'group-theory', 'infinite-groups']"
22,Was Atiyah's proof of the odd order (Feit-Thompson) theorem false?,Was Atiyah's proof of the odd order (Feit-Thompson) theorem false?,,"I read last year that Atiyah thought he had found a proof of the odd order theorem of only 12 pages, using $K$-theory, and that people were trying to figure out if it was correct or not. But I never heard about it afterwards. Did people actually go through it? Was it correct or not?","I read last year that Atiyah thought he had found a proof of the odd order theorem of only 12 pages, using $K$-theory, and that people were trying to figure out if it was correct or not. But I never heard about it afterwards. Did people actually go through it? Was it correct or not?",,"['abstract-algebra', 'group-theory', 'algebraic-topology', 'finite-groups', 'k-theory']"
23,What is the most general algebraic structure that a finite set has?,What is the most general algebraic structure that a finite set has?,,"For an object $X$ in a category with finite products, define its endomorphism Lawvere theory to be the Lawvere theory generated by $X$: its $n$-ary operations are given by $\text{Hom}(X^n, X)$, and so accordingly it describes the most general algebraic structure that $X$ possesses. Some quick examples: The endomorphism Lawvere theory of the abelian group $\mathbb{Z}$ is the Lawvere theory of abelian groups. (This is specific to abelian groups.) The endomorphism Lawvere theory of the set $2 = \{ 0, 1 \}$ is the Lawvere theory of Boolean algebras, or equivalently Boolean rings. This recently came up here . The endomorphism Lawvere theory of Sierpinski space is, I believe, the Lawvere theory of (bounded) distributive lattices, although I haven't checked this. As an interesting generalization of the second example, the endomorphism Lawvere theory of the set $3 = \{ 0, 1, 2 \}$ is the Lawvere theory of a ternary generalization of Boolean rings: $\mathbb{F}_3$-algebras such that every element $x$ satisfies $x^3 = x$. This follows from the fact that every ternary function $3^n \to 3$ can be represented as a polynomial over $\mathbb{F}_3$ which is unique if we require that the degree of the polynomial in each variable is at most $2$, or equivalently if we impose the relation $x^3 = x$ on each variable. Unfortunately, I'm not sure how to continue this pattern: that is, What is the endomorphism Lawvere theory of the finite set $4 = \{ 0, 1, 2, 3 \}$? Of any finite set? (An answer should be a description in terms of generators and relations - some operations that generate all the others under composition and product, and the axioms they satisfy - which is ideally related to familiar algebraic structures such as rings.) I am only confident I know the answer for a finite set of prime size $p$, which again generalizes the Boolean case: it should be $\mathbb{F}_p$-algebras such that every element satisfies $x^p = x$.","For an object $X$ in a category with finite products, define its endomorphism Lawvere theory to be the Lawvere theory generated by $X$: its $n$-ary operations are given by $\text{Hom}(X^n, X)$, and so accordingly it describes the most general algebraic structure that $X$ possesses. Some quick examples: The endomorphism Lawvere theory of the abelian group $\mathbb{Z}$ is the Lawvere theory of abelian groups. (This is specific to abelian groups.) The endomorphism Lawvere theory of the set $2 = \{ 0, 1 \}$ is the Lawvere theory of Boolean algebras, or equivalently Boolean rings. This recently came up here . The endomorphism Lawvere theory of Sierpinski space is, I believe, the Lawvere theory of (bounded) distributive lattices, although I haven't checked this. As an interesting generalization of the second example, the endomorphism Lawvere theory of the set $3 = \{ 0, 1, 2 \}$ is the Lawvere theory of a ternary generalization of Boolean rings: $\mathbb{F}_3$-algebras such that every element $x$ satisfies $x^3 = x$. This follows from the fact that every ternary function $3^n \to 3$ can be represented as a polynomial over $\mathbb{F}_3$ which is unique if we require that the degree of the polynomial in each variable is at most $2$, or equivalently if we impose the relation $x^3 = x$ on each variable. Unfortunately, I'm not sure how to continue this pattern: that is, What is the endomorphism Lawvere theory of the finite set $4 = \{ 0, 1, 2, 3 \}$? Of any finite set? (An answer should be a description in terms of generators and relations - some operations that generate all the others under composition and product, and the axioms they satisfy - which is ideally related to familiar algebraic structures such as rings.) I am only confident I know the answer for a finite set of prime size $p$, which again generalizes the Boolean case: it should be $\mathbb{F}_p$-algebras such that every element satisfies $x^p = x$.",,"['abstract-algebra', 'ring-theory', 'universal-algebra']"
24,Polynomials with same image on the rationals?,Polynomials with same image on the rationals?,,"I am struggling with this problem: If $P_1$ and $P_2$ are two polynomials such that $P_1(\mathbb{Q})=P_2(\mathbb{Q})$, show that $P_1(x)=P_2(ax+b)$ for some constants $a,b$. Here is what I have done. First, taking a linearly independent basis over $\mathbb{Q}$ and expressing the coefficients with it, you can reduce the problem to that of rational polynomials $P_1,P_2$. If both are of odd degree , you can translate both polynomials so that near $x=0$, they are asymptotic to $kx$ for some $k$. Make them integer polynomials too (by multiplying them by a large enough number). Then evaluate $P_1(\frac{1}{q})$ for large primes $q$; then $P_2$ has to ""catch up"" with the denominator, so that $P_1(\frac{1}{q})=P_2(\frac{p}{kq})$. Constraints on $k$ quickly show that $P_1=P_2$. (I will not write all the details.) I have, however, a technical difficulty with polynomials of even degree . They tend to positive infinity in both directions, and I cannot be sure that ""these"" large values of $x$ correspond to those, which would allow me to equate neighbourhoods and run the above argument. Or have I missed the best strategy by miles?","I am struggling with this problem: If $P_1$ and $P_2$ are two polynomials such that $P_1(\mathbb{Q})=P_2(\mathbb{Q})$, show that $P_1(x)=P_2(ax+b)$ for some constants $a,b$. Here is what I have done. First, taking a linearly independent basis over $\mathbb{Q}$ and expressing the coefficients with it, you can reduce the problem to that of rational polynomials $P_1,P_2$. If both are of odd degree , you can translate both polynomials so that near $x=0$, they are asymptotic to $kx$ for some $k$. Make them integer polynomials too (by multiplying them by a large enough number). Then evaluate $P_1(\frac{1}{q})$ for large primes $q$; then $P_2$ has to ""catch up"" with the denominator, so that $P_1(\frac{1}{q})=P_2(\frac{p}{kq})$. Constraints on $k$ quickly show that $P_1=P_2$. (I will not write all the details.) I have, however, a technical difficulty with polynomials of even degree . They tend to positive infinity in both directions, and I cannot be sure that ""these"" large values of $x$ correspond to those, which would allow me to equate neighbourhoods and run the above argument. Or have I missed the best strategy by miles?",,"['abstract-algebra', 'number-theory', 'polynomials']"
25,Algebraically closed fields of characteristic $0$ and $\mathbb{C}$,Algebraically closed fields of characteristic  and,0 \mathbb{C},"Let $k$ be an algebraically closed field of characteristic $0$ . Then I have heard that if $k$ has cardinality no greater than that of $\mathbb{C}$ , then there is an embedding $k\hookrightarrow\mathbb{C}$ . Firstly, does anyone have a reference of this statement? Secondly, suppose $k$ is larger than $\mathbb{C}$ (cardinality-wise). Must there exist an embedding $\mathbb{C}\hookrightarrow k$ ? Lastly, suppose again $k$ is larger than $\mathbb{C}$ , and let $x\in k$ . Must there exist an embedding $\mathbb{C}\hookrightarrow k$ with $x$ in its image? Does anyone have any references for these facts?","Let be an algebraically closed field of characteristic . Then I have heard that if has cardinality no greater than that of , then there is an embedding . Firstly, does anyone have a reference of this statement? Secondly, suppose is larger than (cardinality-wise). Must there exist an embedding ? Lastly, suppose again is larger than , and let . Must there exist an embedding with in its image? Does anyone have any references for these facts?",k 0 k \mathbb{C} k\hookrightarrow\mathbb{C} k \mathbb{C} \mathbb{C}\hookrightarrow k k \mathbb{C} x\in k \mathbb{C}\hookrightarrow k x,"['abstract-algebra', 'algebraic-geometry', 'field-theory']"
26,Character theory of $2$-Frobenius groups.,Character theory of -Frobenius groups.,2,"Edit Summary : I've posted this on MO and received a partial answer there.  Can anybody help me expand on this? Definition. Let $G$ be a finite group and $F_1=\text{Fit}\,G$ and $F_2/F=\text{Fit}\left(G/F_1\right)$ .  If $F_2$ is a Frobenius group with kernel $F_1$ and $G/F_1$ is a Frobenius group with kernel $F_2/F_1$ , we say that $G$ is $2$ -Frobenius . Easy example of a $2$ -Frobenius group is $S_4$ , where a $2$ -cycle acts fixed point freely on the $3$ -cycles, and the $3$ cycles act fixed point freely on the $4$ -cycles.  In general it's easy to make $2$ -Frobenius groups like this by selecting cyclic groups of appropriate orders, but there are other examples too.  One can interpret also this by taking a faithful representation of a Frobenius group over a finite field with $0$ -dimensional fixed point space from the kernel. Question 1: I've seen some theorems about characters of Frobenius groups in Huppert's and Isaccs' character theory books, but nothing specifically about $2$ -Frobenius groups.  In fact there is a specific formula for the characters of a Frobenius group $G=FH$ with kernel $F$ : The characters of $G=FH$ are The characters in $\text{Irr}\,H$ are characters of $G$ with $F$ in their kernel. Define an action of $H$ on $\text{Irr}\,F$ by $\phi^h(f)=\phi(f^{h^{-1}})$ .  The orbits of $H$ on $\text{Irr}\,F$ are $\{\phi_1=1_F\},\{\phi^h_j|h\in H\}$ for $j=2,\ldots,(1+|\text{Irr}\,F|-1)/|H|$ .  Then the $\phi_j^G$ are irreducible on $G$ . (Thus, a corollary: $|\text{Irr}\,G|=|\text{Irr}\,H|+\frac{|\text{Irr}\,F|-1}{|H|}$ .) Could this be adapted to describe the characters of $2$ -Frobenius groups?  I'm particularly interested in Frobenius groups where $F_1$ and $G/F_2$ are $p$ -groups and $F_2/F_1$ is a $q$ -group (for distinct $p$ , $q$ ). Question 2: Is there any information out there in the literature about characters of $2$ -Frobenius groups? (Maybe some papers?) If not, can anyone think of other Frobenius group character theorems that could be adapted smoothly to $2$ -Frobenius groups?  Doesn't matter how tedious or specific; anything to help me understand this type of group better.","Edit Summary : I've posted this on MO and received a partial answer there.  Can anybody help me expand on this? Definition. Let be a finite group and and .  If is a Frobenius group with kernel and is a Frobenius group with kernel , we say that is -Frobenius . Easy example of a -Frobenius group is , where a -cycle acts fixed point freely on the -cycles, and the cycles act fixed point freely on the -cycles.  In general it's easy to make -Frobenius groups like this by selecting cyclic groups of appropriate orders, but there are other examples too.  One can interpret also this by taking a faithful representation of a Frobenius group over a finite field with -dimensional fixed point space from the kernel. Question 1: I've seen some theorems about characters of Frobenius groups in Huppert's and Isaccs' character theory books, but nothing specifically about -Frobenius groups.  In fact there is a specific formula for the characters of a Frobenius group with kernel : The characters of are The characters in are characters of with in their kernel. Define an action of on by .  The orbits of on are for .  Then the are irreducible on . (Thus, a corollary: .) Could this be adapted to describe the characters of -Frobenius groups?  I'm particularly interested in Frobenius groups where and are -groups and is a -group (for distinct , ). Question 2: Is there any information out there in the literature about characters of -Frobenius groups? (Maybe some papers?) If not, can anyone think of other Frobenius group character theorems that could be adapted smoothly to -Frobenius groups?  Doesn't matter how tedious or specific; anything to help me understand this type of group better.","G F_1=\text{Fit}\,G F_2/F=\text{Fit}\left(G/F_1\right) F_2 F_1 G/F_1 F_2/F_1 G 2 2 S_4 2 3 3 4 2 0 2 G=FH F G=FH \text{Irr}\,H G F H \text{Irr}\,F \phi^h(f)=\phi(f^{h^{-1}}) H \text{Irr}\,F \{\phi_1=1_F\},\{\phi^h_j|h\in H\} j=2,\ldots,(1+|\text{Irr}\,F|-1)/|H| \phi_j^G G |\text{Irr}\,G|=|\text{Irr}\,H|+\frac{|\text{Irr}\,F|-1}{|H|} 2 F_1 G/F_2 p F_2/F_1 q p q 2 2","['abstract-algebra', 'group-theory', 'representation-theory', 'finite-groups', 'characters']"
27,What does it mean when I say that addition/multiplication for an equivalence relation is well defined?,What does it mean when I say that addition/multiplication for an equivalence relation is well defined?,,"I have trouble understanding this concept. Why is it necessary to prove that addition or multiplication is well defined in equivalence classes? My understanding of equivalence classes is that it must be reflexive, symmetric and transitive. Doesn't proving it automatically imply that addition and multiplication can be done? Why the additional need to prove that it is 'well defined'? Apologies if this question is too trivial; my understanding of this topic is limited.","I have trouble understanding this concept. Why is it necessary to prove that addition or multiplication is well defined in equivalence classes? My understanding of equivalence classes is that it must be reflexive, symmetric and transitive. Doesn't proving it automatically imply that addition and multiplication can be done? Why the additional need to prove that it is 'well defined'? Apologies if this question is too trivial; my understanding of this topic is limited.",,"['abstract-algebra', 'modular-arithmetic', 'relations', 'equivalence-relations']"
28,$\mathbb R^3$ is not a field,is not a field,\mathbb R^3,"I'm trying to prove that $\mathbb R^3$ is not a field with component-wise multiplication and sum defined. I think it's weird, because every properties of a field are inherit from $\mathbb R$. Anyone can help? Thanks","I'm trying to prove that $\mathbb R^3$ is not a field with component-wise multiplication and sum defined. I think it's weird, because every properties of a field are inherit from $\mathbb R$. Anyone can help? Thanks",,"['abstract-algebra', 'field-theory']"
29,Show that every ideal of the ring $\mathbb Z$ is principal,Show that every ideal of the ring  is principal,\mathbb Z,Let $\mathbb Z$ be the ring of integers. The question asks to show  that every ideal of $\mathbb Z$ is principal. I beg someone to help me because it is a new concept to me.,Let $\mathbb Z$ be the ring of integers. The question asks to show  that every ideal of $\mathbb Z$ is principal. I beg someone to help me because it is a new concept to me.,,"['abstract-algebra', 'ring-theory', 'ideals', 'principal-ideal-domains']"
30,Is there a ring homomorphism $M_2(\mathbb Z)\to \mathbb Z$?,Is there a ring homomorphism ?,M_2(\mathbb Z)\to \mathbb Z,"I have the following problem: Is it possible to construct ring homomorphism from $M_2(\mathbb Z)\to \mathbb Z$ , or in other words, a homomorphism from ring of all $2\times2$ matrices over the integers into integers? I tried determinant, trace and mapping that maps matrix to it's element in the position $(1,1)$ but none of that obviously works, which led me to believe there might not be such a homomorphism. Determinant doesn't work because it is obviously not a linear map.  Trace doesn't work because it doesn't respect multiplication.  And the mapping to the position $(1,1)$ also doesn't work because $$\begin{pmatrix}1&1\\1&1\end{pmatrix}\begin{pmatrix}1&1\\1&1\end{pmatrix}=\begin{pmatrix}2&2\\2&2\end{pmatrix}.$$","I have the following problem: Is it possible to construct ring homomorphism from , or in other words, a homomorphism from ring of all matrices over the integers into integers? I tried determinant, trace and mapping that maps matrix to it's element in the position but none of that obviously works, which led me to believe there might not be such a homomorphism. Determinant doesn't work because it is obviously not a linear map.  Trace doesn't work because it doesn't respect multiplication.  And the mapping to the position also doesn't work because","M_2(\mathbb Z)\to \mathbb Z 2\times2 (1,1) (1,1) \begin{pmatrix}1&1\\1&1\end{pmatrix}\begin{pmatrix}1&1\\1&1\end{pmatrix}=\begin{pmatrix}2&2\\2&2\end{pmatrix}.","['abstract-algebra', 'matrices', 'ring-theory', 'ring-homomorphism']"
31,What is a field?,What is a field?,,"I've always wondered about what a field is meant to represent. For example, group automorphisns naturally represent symmetry in many areas. I'm not looking for a solid answer, just an idea.","I've always wondered about what a field is meant to represent. For example, group automorphisns naturally represent symmetry in many areas. I'm not looking for a solid answer, just an idea.",,"['abstract-algebra', 'soft-question', 'field-theory']"
32,Non-zero prime ideals in the ring of all algebraic integers,Non-zero prime ideals in the ring of all algebraic integers,,"Let $\mathcal{O}$ be the ring of all algebraic integers: elements of $\mathbb{C}$ which occur as zeros of monic polynomials with coefficients in $\mathbb{Z}$. It is known that $\mathcal{O}$ is a Bezout domain : any finitely generated ideal is a principal ideal. In addition, $\mathcal{O}$ has no irreducible elements, since any $x \in \mathcal{O}$ which is not a unit can be written as $x = \sqrt{x}\cdot\sqrt{x}$, where $\sqrt{x}$ is also not a unit in $\mathcal{O}$. My question is: Does $\mathcal{O}$ have any prime ideal other than $(0)$?","Let $\mathcal{O}$ be the ring of all algebraic integers: elements of $\mathbb{C}$ which occur as zeros of monic polynomials with coefficients in $\mathbb{Z}$. It is known that $\mathcal{O}$ is a Bezout domain : any finitely generated ideal is a principal ideal. In addition, $\mathcal{O}$ has no irreducible elements, since any $x \in \mathcal{O}$ which is not a unit can be written as $x = \sqrt{x}\cdot\sqrt{x}$, where $\sqrt{x}$ is also not a unit in $\mathcal{O}$. My question is: Does $\mathcal{O}$ have any prime ideal other than $(0)$?",,"['abstract-algebra', 'commutative-algebra', 'algebraic-number-theory']"
33,When will a group be Abelian?,When will a group be Abelian?,,"My Attempt: $1.$ $G$ is abelian if and only if the mapping $g\mapsto g^{-1}$ is an isomorphism on the group $G$ . $2.$ If $G$ is finite and every irreducible character is linear then $G$ is abelian. $3.$ If $\operatorname{Aut}(G)$ acts on the set $G-\{e\}$ transitively then $G$ is abelian. $4.$ If $\mathbb Z_2$ acts by automorphism on a finite group $G$ fixed point freely then $G$ is abelian. $5.$ If $\forall a,b\in G$ $ ab=ba$ then $G$ is Abelian. My Question: The above are the things which I already use to show a group  will be Abelian. Is/are there any other way(s) to show a group $G$ to be Abelian?",My Attempt: is abelian if and only if the mapping is an isomorphism on the group . If is finite and every irreducible character is linear then is abelian. If acts on the set transitively then is abelian. If acts by automorphism on a finite group fixed point freely then is abelian. If then is Abelian. My Question: The above are the things which I already use to show a group  will be Abelian. Is/are there any other way(s) to show a group to be Abelian?,"1. G g\mapsto g^{-1} G 2. G G 3. \operatorname{Aut}(G) G-\{e\} G 4. \mathbb Z_2 G G 5. \forall a,b\in G  ab=ba G G","['abstract-algebra', 'group-theory', 'abelian-groups', 'big-list']"
34,Show that $x^4 + 8$ is irreducible over Z,Show that  is irreducible over Z,x^4 + 8,Is there an easy way to show that $x^4+8$ is irreducible over $\mathbb Z$ without trying to write it as a product of  polynomials of lower degrees?,Is there an easy way to show that $x^4+8$ is irreducible over $\mathbb Z$ without trying to write it as a product of  polynomials of lower degrees?,,"['abstract-algebra', 'irreducible-polynomials']"
35,"If a ring is Noetherian, then every subring is finitely generated?","If a ring is Noetherian, then every subring is finitely generated?",,"Let $R$ be a commutative ring with $1$, and let $K$ be a field. We know that $R$ is Noetherian iff every ideal of $R$ is finitely generated as an ideal. Question 1: If $R$ is Noetherian, is every subring of $R$ finitely generated as a ring? Is there a simple (counter)example, preferrably in $R:=K[x_1,\ldots,x_n]$? Question 2: if $f:K[x_1,\ldots,x_n]\rightarrow K[y_1,\ldots,y_n]$ is a ring homomorphism, can $\mathrm{Im}(f)$ be nonfinitely generated (as a ring)? $K$ is any field that can be implemented in computer algebra systems, such as finite fields and $\mathbb{Q}$.","Let $R$ be a commutative ring with $1$, and let $K$ be a field. We know that $R$ is Noetherian iff every ideal of $R$ is finitely generated as an ideal. Question 1: If $R$ is Noetherian, is every subring of $R$ finitely generated as a ring? Is there a simple (counter)example, preferrably in $R:=K[x_1,\ldots,x_n]$? Question 2: if $f:K[x_1,\ldots,x_n]\rightarrow K[y_1,\ldots,y_n]$ is a ring homomorphism, can $\mathrm{Im}(f)$ be nonfinitely generated (as a ring)? $K$ is any field that can be implemented in computer algebra systems, such as finite fields and $\mathbb{Q}$.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'noetherian']"
36,Why is it necessary for a ring to have multiplicative identity?,Why is it necessary for a ring to have multiplicative identity?,,"I have read earlier that in a ring $(R,+,.)$ the following needs to hold: $(R,+)$ is an abelian group multiplication is associative and closed left and right distribution laws hold. However, I recently came across the fact that every ring has to have a multiplicative identity. Can anyone please clarify this? Is it needed for the ring to have a multiplicative identity? (In fact it was mentioned that it is one of the reasons why $ker(f)$ is not a subring where $f$ is a ring homomorphism as the additive identity and the multiplicative identity are not usually in the same subset.) Further in 2 different places I have noticed that there is a difference on whether the mapping $f(1) \to 1$ is a necessary condition for $f$ to be a ring homomorphism. I think this is also related to my doubt as to whether the multiplicative identity is in fact a necessary condition for defining a ring.","I have read earlier that in a ring $(R,+,.)$ the following needs to hold: $(R,+)$ is an abelian group multiplication is associative and closed left and right distribution laws hold. However, I recently came across the fact that every ring has to have a multiplicative identity. Can anyone please clarify this? Is it needed for the ring to have a multiplicative identity? (In fact it was mentioned that it is one of the reasons why $ker(f)$ is not a subring where $f$ is a ring homomorphism as the additive identity and the multiplicative identity are not usually in the same subset.) Further in 2 different places I have noticed that there is a difference on whether the mapping $f(1) \to 1$ is a necessary condition for $f$ to be a ring homomorphism. I think this is also related to my doubt as to whether the multiplicative identity is in fact a necessary condition for defining a ring.",,"['abstract-algebra', 'ring-theory', 'terminology', 'definition', 'rngs']"
37,Proving that free modules are flat (without appealing projective modules),Proving that free modules are flat (without appealing projective modules),,"Suppose $R\neq 0$ is a commutative ring with $1$. Let $M$ be a free $R$-module. I would like to prove that $M$ is a flat $R$-module. Everywhere I have looked (mostly online) this is proved by first proving that every free module is projective, and then proving that every projective module is flat. Unfortunately, Atiyah & Macdonald's ""Introduction to Commutative Algebra"" (Chapter 2) does not discuss projective modules. But the result that every free module is flat comes very handy in the exercises. So my question is, Is it possible to prove that every free module is flat just by   definitions and without appealing to projective modules? Thanks!","Suppose $R\neq 0$ is a commutative ring with $1$. Let $M$ be a free $R$-module. I would like to prove that $M$ is a flat $R$-module. Everywhere I have looked (mostly online) this is proved by first proving that every free module is projective, and then proving that every projective module is flat. Unfortunately, Atiyah & Macdonald's ""Introduction to Commutative Algebra"" (Chapter 2) does not discuss projective modules. But the result that every free module is flat comes very handy in the exercises. So my question is, Is it possible to prove that every free module is flat just by   definitions and without appealing to projective modules? Thanks!",,"['abstract-algebra', 'commutative-algebra', 'modules', 'homological-algebra']"
38,Distinguishing Inner Automorphisms,Distinguishing Inner Automorphisms,,"Given an automorphism $f$ of a group $G$, is there some way to determine whether or not $f$ is inner? What are some techniques for doing this? If $G$ is finite, this can clearly be done by brute force. This isn't a very insightful answer though, and not the sort of answer I'm hoping to get. Rather, I would like to acquire a better understanding of what properties distinguish inner automorphisms from other automorphisms.","Given an automorphism $f$ of a group $G$, is there some way to determine whether or not $f$ is inner? What are some techniques for doing this? If $G$ is finite, this can clearly be done by brute force. This isn't a very insightful answer though, and not the sort of answer I'm hoping to get. Rather, I would like to acquire a better understanding of what properties distinguish inner automorphisms from other automorphisms.",,"['abstract-algebra', 'group-theory']"
39,Anti-isomorphisms,Anti-isomorphisms,,"Definition : Let $G,H$ be groups and $f: G \to H$ a function such that $f(gh) =f(h)f(g)$ for any $g,h \in G$. Then we call $f$ an antihomomorphism. (Note the swapped order of $f(h)$ and $f(g)$.) I was deriving some properties of antihomomorphisms and I found that there were a lot of similarities with the usual homomorphisms: For example, for any antihomomorphism $f: G \to H$, we have: $f(e_G) = e_H$ $f(g^{-1}) = f(g)^{-1}$ If we define $ker f$ in the usual way (i.e. $ker f = \{g \in G|f(g) = e_H\}$), we have: $f$ injective $\iff ker f = \{e_G\}$ $ker f \unlhd G$ If we denote the existence of a bijective antihomomorphism between $2$ groups with $\asymp$, we have: $G/ker f \asymp Im(f)$ Also interesting: $G \asymp H$ and $H \asymp F \Rightarrow G \cong F$ I know that the existence of an isomorphism between $2$ groups means that both groups have exactly the same structure. So my question is: From a group theoretic point of view, what is the use of bijective   antihomomorphisms (= anti-isomorphisms) between 2 groups. Can we give   it an interpretation like we have for regular isomorphisms?","Definition : Let $G,H$ be groups and $f: G \to H$ a function such that $f(gh) =f(h)f(g)$ for any $g,h \in G$. Then we call $f$ an antihomomorphism. (Note the swapped order of $f(h)$ and $f(g)$.) I was deriving some properties of antihomomorphisms and I found that there were a lot of similarities with the usual homomorphisms: For example, for any antihomomorphism $f: G \to H$, we have: $f(e_G) = e_H$ $f(g^{-1}) = f(g)^{-1}$ If we define $ker f$ in the usual way (i.e. $ker f = \{g \in G|f(g) = e_H\}$), we have: $f$ injective $\iff ker f = \{e_G\}$ $ker f \unlhd G$ If we denote the existence of a bijective antihomomorphism between $2$ groups with $\asymp$, we have: $G/ker f \asymp Im(f)$ Also interesting: $G \asymp H$ and $H \asymp F \Rightarrow G \cong F$ I know that the existence of an isomorphism between $2$ groups means that both groups have exactly the same structure. So my question is: From a group theoretic point of view, what is the use of bijective   antihomomorphisms (= anti-isomorphisms) between 2 groups. Can we give   it an interpretation like we have for regular isomorphisms?",,"['abstract-algebra', 'group-theory']"
40,"Why the group $\langle x,y\mid x^2=y^2\rangle $ is not free?",Why the group  is not free?,"\langle x,y\mid x^2=y^2\rangle ","Why is the group $G= \langle x,y\mid x^2=y^2\rangle $ not free? I can't find any reason like an element of finite order or some subgroup of it that is not free etc.","Why is the group $G= \langle x,y\mid x^2=y^2\rangle $ not free? I can't find any reason like an element of finite order or some subgroup of it that is not free etc.",,"['abstract-algebra', 'free-groups', 'group-presentation']"
41,Prove that the center of a group is a normal subgroup [closed],Prove that the center of a group is a normal subgroup [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $G$ be a group. We define $H=\{h\in G\mid \forall g\in G: hg=gh\},$ the center of $G$ . Prove that $H$ is a (normal) subgroup of $G$ .","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let be a group. We define the center of . Prove that is a (normal) subgroup of .","G H=\{h\in G\mid \forall g\in G: hg=gh\}, G H G","['abstract-algebra', 'group-theory', 'normal-subgroups']"
42,How to learn commutative algebra?,How to learn commutative algebra?,,"I want to learn commutative algebra from scratch. I was wondering, as you are experts in mathematics, what you think is the best way to learn commutative algebra? Is there any video course available for commutative algebra? Will there be some online course for commutative algebra on some website like Coursera, etc? I know noncommutative algebra up to the Artin-Wedderburn Theorem. Also, I know group theory up to the Sylow theorems and Galois Theory. I also know some basic topology. I'm new to this site so I don't know what tags I should add for this question. Please feel free to edit my question. Edit 1 : I want to learn commutative algebra for learning Algebraic Geometry.","I want to learn commutative algebra from scratch. I was wondering, as you are experts in mathematics, what you think is the best way to learn commutative algebra? Is there any video course available for commutative algebra? Will there be some online course for commutative algebra on some website like Coursera, etc? I know noncommutative algebra up to the Artin-Wedderburn Theorem. Also, I know group theory up to the Sylow theorems and Galois Theory. I also know some basic topology. I'm new to this site so I don't know what tags I should add for this question. Please feel free to edit my question. Edit 1 : I want to learn commutative algebra for learning Algebraic Geometry.",,"['abstract-algebra', 'reference-request', 'commutative-algebra', 'soft-question', 'book-recommendation']"
43,Cannot become ring because distribution law does not hold,Cannot become ring because distribution law does not hold,,"Commutative ring with unit is defined as $(R,+,\times)$ , where $(R,+)$ is abelian group and $(R,\times)$ is commutative multiplicative monoid with $1$ and $+$ and $\times$ satisfies distributive law. Could you give me an example $(R,+,\times)$ cannnot be a ring because $+$ and $\times$ does not satisfy distributive law although $(R，+)$ is abelian group and $(R,\times)$ is commutative multiplicative monoid with $1$ .","Commutative ring with unit is defined as , where is abelian group and is commutative multiplicative monoid with and and satisfies distributive law. Could you give me an example cannnot be a ring because and does not satisfy distributive law although is abelian group and is commutative multiplicative monoid with .","(R,+,\times) (R,+) (R,\times) 1 + \times (R,+,\times) + \times (R，+) (R,\times) 1","['abstract-algebra', 'group-theory', 'ring-theory', 'abelian-groups', 'monoid']"
44,Integral domain that is not a factorization domain,Integral domain that is not a factorization domain,,"I am looking for rings that are integral domains but not factorization domains, that is, rings in which it is not possible to express a nonzero nonunit element as a product of irreducible elements. Do you know any example?","I am looking for rings that are integral domains but not factorization domains, that is, rings in which it is not possible to express a nonzero nonunit element as a product of irreducible elements. Do you know any example?",,"['abstract-algebra', 'ring-theory']"
45,Why are Artinian rings of Krull dimension 0?,Why are Artinian rings of Krull dimension 0?,,"Why are Artinian rings of Krull dimension 0? As in the example of $\mathbb{Z}/(6)$, the ideal $\mathbb{Z}/(2)$ is prime, I think. So, Artinian rings may contain prime ideals. But why does not the primes ideal contain other prime ideals properly? Another question is that, when a ring is of Krull dimension 0, is it necessarily Artinian? Thanks.","Why are Artinian rings of Krull dimension 0? As in the example of $\mathbb{Z}/(6)$, the ideal $\mathbb{Z}/(2)$ is prime, I think. So, Artinian rings may contain prime ideals. But why does not the primes ideal contain other prime ideals properly? Another question is that, when a ring is of Krull dimension 0, is it necessarily Artinian? Thanks.",,"['abstract-algebra', 'krull-dimension']"
46,Ring of polynomials as a module over symmetric polynomials,Ring of polynomials as a module over symmetric polynomials,,"Consider the ring of polynomials $\mathbb{k} [x_1, x_2, \ldots , x_n]$ as a module over the ring of symmetric polynomials $\Lambda_{\mathbb{k}}$. Is $\mathbb{k} [x_1, x_2, \ldots , x_n]$ a free $\Lambda_{\mathbb{k}}$-module?   Can you write down ""good"" generators explicitly? (I think that it has to be something very classical in representation theory). Comment: My initial question was whether this module flat. But since all flat Noetherian modules over polynomial ring are free (correct me if it is wrong), it is the same question. There is much more general question, which seems unlikely to have good answer. Let $G$ be a finite group and $V$ finite dimensional representation of G. Consider projection $p: V \rightarrow V/G$. When is $p$ flat?","Consider the ring of polynomials $\mathbb{k} [x_1, x_2, \ldots , x_n]$ as a module over the ring of symmetric polynomials $\Lambda_{\mathbb{k}}$. Is $\mathbb{k} [x_1, x_2, \ldots , x_n]$ a free $\Lambda_{\mathbb{k}}$-module?   Can you write down ""good"" generators explicitly? (I think that it has to be something very classical in representation theory). Comment: My initial question was whether this module flat. But since all flat Noetherian modules over polynomial ring are free (correct me if it is wrong), it is the same question. There is much more general question, which seems unlikely to have good answer. Let $G$ be a finite group and $V$ finite dimensional representation of G. Consider projection $p: V \rightarrow V/G$. When is $p$ flat?",,"['abstract-algebra', 'algebraic-geometry', 'modules', 'representation-theory', 'symmetric-polynomials']"
47,Is the ideal generated by irreducible element in principal ideal domain maximal? [duplicate],Is the ideal generated by irreducible element in principal ideal domain maximal? [duplicate],,"This question already has answers here : Closed 12 years ago . Possible Duplicate: Proving that an ideal in a PID is maximal if and only if it is generated by an irreducible I am trying to see whether the ideal generated by irreducible element in a principal ideal domain (PID) is maximal ideal. Suppose r is irreducible in a PID say D Let I be an ideal of D containing ( r ) the ideal generated by r Since D is a principal ideal domain, there exist s in D such that I =( s ), therefore ( r ) is a subset of ( s ). So, r = st , for some t in D but r is irreducible, this implies that s or t is a unit. If s is a unit then I = ( s )= D . If t is a unit then ( r )= I =( s ). But I am not sure this is true, because I do not have reason for saying ( r )= I =( s ), so that I can conclude and say ( r ) is maximal. I need a little help for this. Thanks","This question already has answers here : Closed 12 years ago . Possible Duplicate: Proving that an ideal in a PID is maximal if and only if it is generated by an irreducible I am trying to see whether the ideal generated by irreducible element in a principal ideal domain (PID) is maximal ideal. Suppose r is irreducible in a PID say D Let I be an ideal of D containing ( r ) the ideal generated by r Since D is a principal ideal domain, there exist s in D such that I =( s ), therefore ( r ) is a subset of ( s ). So, r = st , for some t in D but r is irreducible, this implies that s or t is a unit. If s is a unit then I = ( s )= D . If t is a unit then ( r )= I =( s ). But I am not sure this is true, because I do not have reason for saying ( r )= I =( s ), so that I can conclude and say ( r ) is maximal. I need a little help for this. Thanks",,['abstract-algebra']
48,"How does Hilbert's Nullstellensatz generalize the ""fundamental theorem of algebra""?","How does Hilbert's Nullstellensatz generalize the ""fundamental theorem of algebra""?",,"What is Hilbert's Nullstellensatz in the sense of the generalization of ""fundamental theorem of algebra""? I've seen that in some texts it was referred to as the generalization of the fundamental theorem of algebra in several variables. How exactly does Hilbert's Nullstellensatz relate to the fundamental theorem of algebra? Also could you please provide some examples to show that it is related?","What is Hilbert's Nullstellensatz in the sense of the generalization of ""fundamental theorem of algebra""? I've seen that in some texts it was referred to as the generalization of the fundamental theorem of algebra in several variables. How exactly does Hilbert's Nullstellensatz relate to the fundamental theorem of algebra? Also could you please provide some examples to show that it is related?",,"['abstract-algebra', 'algebraic-geometry', 'polynomials', 'commutative-algebra']"
49,$p = x^2 + xy + y^2$ if and only if $p \equiv 1 \text{ mod }3$?,if and only if ?,p = x^2 + xy + y^2 p \equiv 1 \text{ mod }3,"For a prime number $p \neq 3$, do we have that$$p = x^2 + xy + y^2$$for some $x$, $y \in \mathbb{Z}$ if and only if$$p \equiv 1 \text{ mod }3?$$I suspect this is true from looking at the example$$7 = 2^2  + 2 \times 1 + 1^2.$$Here is a thought I have so far that might be helpful towards solving this: I know that $$\mathbb{Z}[(1 + \sqrt{-3})/2]$$is a PID. But I am not sure what do from here. Could anybody help?","For a prime number $p \neq 3$, do we have that$$p = x^2 + xy + y^2$$for some $x$, $y \in \mathbb{Z}$ if and only if$$p \equiv 1 \text{ mod }3?$$I suspect this is true from looking at the example$$7 = 2^2  + 2 \times 1 + 1^2.$$Here is a thought I have so far that might be helpful towards solving this: I know that $$\mathbb{Z}[(1 + \sqrt{-3})/2]$$is a PID. But I am not sure what do from here. Could anybody help?",,"['abstract-algebra', 'number-theory']"
50,Construct a non-abelian group of order 75,Construct a non-abelian group of order 75,,"I am trying to use a semi-direct product to construct a non-abelian group of order 75 (Ex 5.5.8 in Dummit & Foote). Using the third Sylow theorem, we get $n_5=1$ so the subgroup of order $25$ is normal. Hence it makes sense to use the following semi-direct product: $$ (\text{Sylow }5\text{-subgroup})\rtimes(\text{Sylow }3\text{-subgroup}) $$ There are two groups of order $25$ , either $\mathbb{Z}/5\mathbb{Z}\times \mathbb{Z}/5\mathbb{Z}$ or $\mathbb{Z}/25\mathbb{Z}$ . In order to use the semi-direct product, I need a homomorphism from $\mathbb{Z}/3\mathbb{Z}$ to one of these. The automorphism group of $\mathbb{Z}/25\mathbb{Z}$ is $C_{20}$ so we can't use this group (since $3\nmid 20$ ). My questions are: $$ \begin{split}&1&) \text{ What is } \mathrm{Aut}\left(\mathbb{Z}/5\mathbb{Z}\times \mathbb{Z}/5\mathbb{Z}\right)? \\ &2&) \text{ How can we construct a non-trivial homomorphism } \phi:\mathbb{Z}/3\mathbb{Z}\to \mathrm{Aut}(\mathbb{Z}/5\mathbb{Z}\times \mathbb{Z}/5\mathbb{Z}) \end{split} $$","I am trying to use a semi-direct product to construct a non-abelian group of order 75 (Ex 5.5.8 in Dummit & Foote). Using the third Sylow theorem, we get so the subgroup of order is normal. Hence it makes sense to use the following semi-direct product: There are two groups of order , either or . In order to use the semi-direct product, I need a homomorphism from to one of these. The automorphism group of is so we can't use this group (since ). My questions are:","n_5=1 25 
(\text{Sylow }5\text{-subgroup})\rtimes(\text{Sylow }3\text{-subgroup})
 25 \mathbb{Z}/5\mathbb{Z}\times \mathbb{Z}/5\mathbb{Z} \mathbb{Z}/25\mathbb{Z} \mathbb{Z}/3\mathbb{Z} \mathbb{Z}/25\mathbb{Z} C_{20} 3\nmid 20 
\begin{split}&1&) \text{ What is } \mathrm{Aut}\left(\mathbb{Z}/5\mathbb{Z}\times \mathbb{Z}/5\mathbb{Z}\right)? \\ &2&) \text{ How can we construct a non-trivial homomorphism } \phi:\mathbb{Z}/3\mathbb{Z}\to \mathrm{Aut}(\mathbb{Z}/5\mathbb{Z}\times \mathbb{Z}/5\mathbb{Z}) \end{split}
","['abstract-algebra', 'group-theory']"
51,What is the name for a function whose codomain and domain are equal?,What is the name for a function whose codomain and domain are equal?,,"What do we call a function whose domain and co-domain are the same set? Edit: While i expressed my question in terms of functions, domains and codomains, i was actually interested in the most abstract mathematical formulation for similar structures. Thus i accepted as the correct answer endomorphism that, being at the level of category theory, answers rather the question: What do we call a morphism from a mathematical object to itself? I could find this out just after getting some answers","What do we call a function whose domain and co-domain are the same set? Edit: While i expressed my question in terms of functions, domains and codomains, i was actually interested in the most abstract mathematical formulation for similar structures. Thus i accepted as the correct answer endomorphism that, being at the level of category theory, answers rather the question: What do we call a morphism from a mathematical object to itself? I could find this out just after getting some answers",,"['abstract-algebra', 'functions', 'category-theory', 'terminology']"
52,In which algebraic setting can I state (and prove) the binomial theorem?,In which algebraic setting can I state (and prove) the binomial theorem?,,"In a book on algebra I'm currently working with a proof that uses the binomial theorem for $(x+y)^m$ where $x,y$ are elements of some arbitrary field $k$. This looks strange to me, so I did some research on the Internet, but all pages which state (and prove) this theorem never specify what $x$ and $y$ are. A binomial coefficient is defined by faculties and fractions of integers. This is not evaluable in a general field that does not extend the integers like $\mathbb Q$. We can use the map $$\mathbb Z \to k,\quad n\mapsto \sum_1^n 1$$ to get a representation of the integers in $k$, but this is only a group, and it is not clear (to me), why the inverses of these internal representations in $k$ are internal integers as well (so that we could define the binomial coefficient via internal integers). A further question would be, whether we can weaken the requirements from general fields to (not necessarily general) rings. Except for the definition of binomial coefficients, we don't need inverses in the statement, so maybe this is possible as well in some cases (of course this works for all rings that we obtain via a forgetful functor from a field, but I mean rings that are not fields).","In a book on algebra I'm currently working with a proof that uses the binomial theorem for $(x+y)^m$ where $x,y$ are elements of some arbitrary field $k$. This looks strange to me, so I did some research on the Internet, but all pages which state (and prove) this theorem never specify what $x$ and $y$ are. A binomial coefficient is defined by faculties and fractions of integers. This is not evaluable in a general field that does not extend the integers like $\mathbb Q$. We can use the map $$\mathbb Z \to k,\quad n\mapsto \sum_1^n 1$$ to get a representation of the integers in $k$, but this is only a group, and it is not clear (to me), why the inverses of these internal representations in $k$ are internal integers as well (so that we could define the binomial coefficient via internal integers). A further question would be, whether we can weaken the requirements from general fields to (not necessarily general) rings. Except for the definition of binomial coefficients, we don't need inverses in the statement, so maybe this is possible as well in some cases (of course this works for all rings that we obtain via a forgetful functor from a field, but I mean rings that are not fields).",,"['abstract-algebra', 'ring-theory', 'binomial-theorem']"
53,Dedekind domain with a finite number of prime ideals is principal,Dedekind domain with a finite number of prime ideals is principal,,"I am reading a proof of this result that uses the Chinese Remainder Theorem on (the finite number of) prime ideals $P_i$. In order to apply CRT we should assume that the prime ideals are coprime, i.e. the ring is equal to $P_h + P_k$ for $h \neq k$, but I can't see it. How does it follow?","I am reading a proof of this result that uses the Chinese Remainder Theorem on (the finite number of) prime ideals $P_i$. In order to apply CRT we should assume that the prime ideals are coprime, i.e. the ring is equal to $P_h + P_k$ for $h \neq k$, but I can't see it. How does it follow?",,"['abstract-algebra', 'ring-theory']"
54,An ideal that is radical but not prime.,An ideal that is radical but not prime.,,"I'm preparing for an exam and, as part of this preparation, I'm looking for an ideal $I$ in an integral domain $R$ that is radical but not prime. Here is an example I'm fooling around with: Let $R=\mathbb{R}[x]$ and let $I=(x(x-1))$. I'm having trouble showing that this ideal is in fact radical. My intuition is to consider the quotient ring $\mathbb{R}[x]/(x(x-1))$ and determine if it is reduced, that is, whether or not it has trivial nilradical. However, this has only led me in circles so far. $(x(x-1))$ is clearly not a prime ideal, so it suffices to show it's radical. Any help would be appreciated.","I'm preparing for an exam and, as part of this preparation, I'm looking for an ideal $I$ in an integral domain $R$ that is radical but not prime. Here is an example I'm fooling around with: Let $R=\mathbb{R}[x]$ and let $I=(x(x-1))$. I'm having trouble showing that this ideal is in fact radical. My intuition is to consider the quotient ring $\mathbb{R}[x]/(x(x-1))$ and determine if it is reduced, that is, whether or not it has trivial nilradical. However, this has only led me in circles so far. $(x(x-1))$ is clearly not a prime ideal, so it suffices to show it's radical. Any help would be appreciated.",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals', 'examples-counterexamples']"
55,"How to prove a commutative, with unit, Noetherian ring $A$ only has finitely many minimal prime ideals via the following step?","How to prove a commutative, with unit, Noetherian ring  only has finitely many minimal prime ideals via the following step?",A,"How to prove a commutative, with unit, Noetherian ring $A$ only has finitely many minimal prime ideals via the following step? I have proved: Step. All radical ideals of Noetherian ring $A$ can be expressed as an intersection of finitely many prime ideals. How to continue?","How to prove a commutative, with unit, Noetherian ring $A$ only has finitely many minimal prime ideals via the following step? I have proved: Step. All radical ideals of Noetherian ring $A$ can be expressed as an intersection of finitely many prime ideals. How to continue?",,"['abstract-algebra', 'commutative-algebra']"
56,"Show that G is a group, if G is finite, the operation is associative, and cancellation law holds","Show that G is a group, if G is finite, the operation is associative, and cancellation law holds",,"Let $G$ be a non-empty finite set with an associative binary operation so that cancellation law holds, i.e. $ab=ac$ or $ba=ca$ implies $b=c$, for any choices of $a,b,c$ in $G$. Assume that there is an identity element $e$ in $G$. Show that $G$ is a group. Proof : To show $G$ is a group, conditions must hold. Suppose that $ab=ac$, then $b=eb=(a^{-1}a)b =a^{-1}(ab)=a^{-1}(ac) =(a^{-1}a)c=ec=c$. So left cancellation holds in $G$. 2) Suppose $ba=ca$, then $b=be=b(aa^{-1}) =(ba)a^{-1}=(ca)a^{-1} =c(aa^{-1})=ce=c$. So right cancellation holds in $G$. 3) If $a$ exists in $G$ then $aa^{-1}=a^{-1}a=e$, where $a$ is an inverse of $a^{-1}$. Since inverses are unique, $(a^{-1})^{-1}=a$. 4) Let $x$ be the inverse of $ab$. Then $(ab)x=e$. By associativity we have $a(bx)=aa^{-1}$. Through left cancellation we have  $bx=a^{-1}bx=ea^{-1}=b(b^{-1}a^{-1})$ and $x=b^{-1}a^{-1}$. Thus $(ab)^{-1}=b^{-1}a^{-1}$. So all conditions hold, $G$ is a group. Is this proof correct? I know to show $G$ is a group these conditions have to be met. This is all I have to show right?","Let $G$ be a non-empty finite set with an associative binary operation so that cancellation law holds, i.e. $ab=ac$ or $ba=ca$ implies $b=c$, for any choices of $a,b,c$ in $G$. Assume that there is an identity element $e$ in $G$. Show that $G$ is a group. Proof : To show $G$ is a group, conditions must hold. Suppose that $ab=ac$, then $b=eb=(a^{-1}a)b =a^{-1}(ab)=a^{-1}(ac) =(a^{-1}a)c=ec=c$. So left cancellation holds in $G$. 2) Suppose $ba=ca$, then $b=be=b(aa^{-1}) =(ba)a^{-1}=(ca)a^{-1} =c(aa^{-1})=ce=c$. So right cancellation holds in $G$. 3) If $a$ exists in $G$ then $aa^{-1}=a^{-1}a=e$, where $a$ is an inverse of $a^{-1}$. Since inverses are unique, $(a^{-1})^{-1}=a$. 4) Let $x$ be the inverse of $ab$. Then $(ab)x=e$. By associativity we have $a(bx)=aa^{-1}$. Through left cancellation we have  $bx=a^{-1}bx=ea^{-1}=b(b^{-1}a^{-1})$ and $x=b^{-1}a^{-1}$. Thus $(ab)^{-1}=b^{-1}a^{-1}$. So all conditions hold, $G$ is a group. Is this proof correct? I know to show $G$ is a group these conditions have to be met. This is all I have to show right?",,"['abstract-algebra', 'group-theory', 'solution-verification']"
57,Symmetric Group $S_n$ is complete,Symmetric Group  is complete,S_n,"I am just checking some properties of the symmetric group and found on Wikipedia the statement that ""Conversely, for $n \neq 6$ , $S_n$ has no outer automorphisms, and for $n \neq 2$ it has no center, so for $n \neq 2, 6$ it is a complete group, as discussed in automorphism group, below."" I could show that $Z(S_n)=1$ but do you know an easy proof for $\mathrm{Aut}(S_n)=\mathrm{Inn}(S_n)$ ?","I am just checking some properties of the symmetric group and found on Wikipedia the statement that ""Conversely, for , has no outer automorphisms, and for it has no center, so for it is a complete group, as discussed in automorphism group, below."" I could show that but do you know an easy proof for ?","n \neq 6 S_n n \neq 2 n \neq 2, 6 Z(S_n)=1 \mathrm{Aut}(S_n)=\mathrm{Inn}(S_n)","['abstract-algebra', 'group-theory']"
58,Classical number theoretic applications of the $p$-adic numbers,Classical number theoretic applications of the -adic numbers,p,"I am sure we can all agree that the $p$ -adic numbers are highly fascinating objects in their own right - just as the closely related theory of valuations. Having independently read up on the $p$ -adic numbers for a few weeks now, I have so far only seen one application of them to what I would call classical number theory - namely the proof given in Serre's Cours d'arithmétique that a natural number is expressible as the sum of $\leq 3$ squares if and only if it is not of the form $4^a(8b-1)$ for some $a,b \in \mathbb{N}$ . Since I have a tendency to appreciate the value of the higher theories of mathematics in proportion to their applications to elementary number theory, I immediately found myself wondering if there are any other applications. So my question to the community is: What are the most delightful applications of the $p$ -adic numbers and the theory of valuations to elementary number theory? Many thanks. P.s.: I am aware that there are already several posts on the forum about the applications of the $p$ -adic numbers, but none that refers to elementary number theory specifically. Edit: I agree that I have been too vague in what I mean by ""elementary number theory"", so I will try to be a little more specific: By a classical ""elementary"" number theoretic proposition, I mean a number theoretic proposition that Fermat might have come up with. Thus, the above proposition about the sum of three squares is an elementary number theoretic proposition, as is e.g. Fermat's Last Theorem and the Twin Prime Conjecture, while e.g. the BSD Conjecture or the Class Number Problem are not. Edit 2: Thank you for all the answers below - they are all excellent! In case anyone should come up with another one, I should like to say that bonus-points are given for results that have so far only been proven using the theory of $p$ -adic numbers, or whose proof using $p$ -adic numbers is far more conceptual and insightful than the original / more elementary one.","I am sure we can all agree that the -adic numbers are highly fascinating objects in their own right - just as the closely related theory of valuations. Having independently read up on the -adic numbers for a few weeks now, I have so far only seen one application of them to what I would call classical number theory - namely the proof given in Serre's Cours d'arithmétique that a natural number is expressible as the sum of squares if and only if it is not of the form for some . Since I have a tendency to appreciate the value of the higher theories of mathematics in proportion to their applications to elementary number theory, I immediately found myself wondering if there are any other applications. So my question to the community is: What are the most delightful applications of the -adic numbers and the theory of valuations to elementary number theory? Many thanks. P.s.: I am aware that there are already several posts on the forum about the applications of the -adic numbers, but none that refers to elementary number theory specifically. Edit: I agree that I have been too vague in what I mean by ""elementary number theory"", so I will try to be a little more specific: By a classical ""elementary"" number theoretic proposition, I mean a number theoretic proposition that Fermat might have come up with. Thus, the above proposition about the sum of three squares is an elementary number theoretic proposition, as is e.g. Fermat's Last Theorem and the Twin Prime Conjecture, while e.g. the BSD Conjecture or the Class Number Problem are not. Edit 2: Thank you for all the answers below - they are all excellent! In case anyone should come up with another one, I should like to say that bonus-points are given for results that have so far only been proven using the theory of -adic numbers, or whose proof using -adic numbers is far more conceptual and insightful than the original / more elementary one.","p p \leq 3 4^a(8b-1) a,b \in \mathbb{N} p p p p","['abstract-algebra', 'number-theory', 'elementary-number-theory', 'p-adic-number-theory', 'valuation-theory']"
59,Isomorphic quotient groups $\frac{G}{H} \cong \frac{G}{K}$ imply $H \cong K$?,Isomorphic quotient groups  imply ?,\frac{G}{H} \cong \frac{G}{K} H \cong K,"I know that given a group $G$ and two normal subgroups $H,K \subset G$ then it is not true that: ""if $H \cong K$ then $ \frac{G}{H} \cong \frac{G}{K} $ (the counterexample is quite easy with products of cyclic groups) "" My question is: Is the converse true? i.e. Given that $\frac{G}{H} \cong \frac{G}{K}$ then $H \cong K$ ? I feel that the answer is no, but I can't think of an example.","I know that given a group $G$ and two normal subgroups $H,K \subset G$ then it is not true that: ""if $H \cong K$ then $ \frac{G}{H} \cong \frac{G}{K} $ (the counterexample is quite easy with products of cyclic groups) "" My question is: Is the converse true? i.e. Given that $\frac{G}{H} \cong \frac{G}{K}$ then $H \cong K$ ? I feel that the answer is no, but I can't think of an example.",,"['abstract-algebra', 'group-theory']"
60,A finite group which has a unique subgroup of order $d$ for each $d\mid n$.,A finite group which has a unique subgroup of order  for each .,d d\mid n,"Problem Suppose G is a finite group of order $n$ which has a unique subgroup of order $d$ for each $d\mid n$. Prove that $G$ must be a cyclic group. My idea:   I try to prove it by induction. Let $p|n$ be a prime. Then by condition, there exists a unique subgroup $H$ of order $n/p$. Since $|gHg^{-1}|=|H|$, we must have $gHg^{-1}=H$ by the uniqueness part of the condition. So, H is a normal subgroup. Now, $|G/H|=p$ and thus $G/H=\langle x\rangle$ where $x^p \in H$. However, I cannot continue. My another idea is that first consider the case when $|G|$ is a power of some prime $p$. But, it still doesn't work.","Problem Suppose G is a finite group of order $n$ which has a unique subgroup of order $d$ for each $d\mid n$. Prove that $G$ must be a cyclic group. My idea:   I try to prove it by induction. Let $p|n$ be a prime. Then by condition, there exists a unique subgroup $H$ of order $n/p$. Since $|gHg^{-1}|=|H|$, we must have $gHg^{-1}=H$ by the uniqueness part of the condition. So, H is a normal subgroup. Now, $|G/H|=p$ and thus $G/H=\langle x\rangle$ where $x^p \in H$. However, I cannot continue. My another idea is that first consider the case when $|G|$ is a power of some prime $p$. But, it still doesn't work.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'cyclic-groups']"
61,The description of abelian Lie groups,The description of abelian Lie groups,,"Question. Classify all abelian connected Lie groups. There is a problem in my problem sheet which asks me to describe all abelian connected Lie groups (moreover this is the first problem so it should be rather easy). I don't understand how this description should look. They mean description up to an isomorphism (of Lie groups), don't they? I can list some abelian connected (real) Lie groups: $\mathbb{R}^n$ , $\mathbb{C}_{\ne 0}$ (as a real group under multiplication), $S^1$ (i.e. $\big\{z\in\mathbb{C}: |z|=1\big\}$ ), also some different finite products. Could you help me to classify them?","Question. Classify all abelian connected Lie groups. There is a problem in my problem sheet which asks me to describe all abelian connected Lie groups (moreover this is the first problem so it should be rather easy). I don't understand how this description should look. They mean description up to an isomorphism (of Lie groups), don't they? I can list some abelian connected (real) Lie groups: , (as a real group under multiplication), (i.e. ), also some different finite products. Could you help me to classify them?",\mathbb{R}^n \mathbb{C}_{\ne 0} S^1 \big\{z\in\mathbb{C}: |z|=1\big\},"['abstract-algebra', 'lie-groups', 'lie-algebras', 'abelian-groups']"
62,"Prove that $\operatorname{Hom}_{\Bbb{Z}}(\Bbb{Q},\Bbb{Z}) = 0$ and show that $\Bbb{Q}$ is not a projective $\Bbb{Z}$-module.",Prove that  and show that  is not a projective -module.,"\operatorname{Hom}_{\Bbb{Z}}(\Bbb{Q},\Bbb{Z}) = 0 \Bbb{Q} \Bbb{Z}","1) Prove that $\operatorname{Hom}_{\Bbb{Z}}(\Bbb{Q},\Bbb{Z}) = 0$. 2) Show that $\Bbb{Q}$ is not a projective $\Bbb{Z}$-module. 1) We know that $\Bbb{Q}$ is an injective $\Bbb{Z}$-module. This implies that every short exact sequence $$0 \rightarrow \Bbb{Q} \xrightarrow{f} A \xrightarrow{g} B \rightarrow 0$$ is split exact. In particular, $$0 \rightarrow \Bbb{Q} \xrightarrow{f}  \Bbb{Z} \xrightarrow{g} A \rightarrow 0$$ is split exact. But this implies that we have a homomorphism $k: \Bbb{Z} \rightarrow \Bbb{Q}$  such that $kf = 1_{\Bbb{Q}}$. So we need to look at what possible homomorphisms we could have from $\Bbb{Z}$ to $\Bbb{Q}$. Since $\Bbb{Z}$ is cyclic, the homomorphism $k$ is determined by where it sends $1$. Suppose that we send $1$ to $q \in \Bbb{Q}$ such that $q \not= 1$ and $q \not= 0$. Let $m \in \Bbb{Z}$. Then $$k(m) = mk(1) = mq$$ But then $$qmq = k(1)k(m) \not= k(m) = mq$$ So either $1 \in \Bbb{Z}$ must be sent to $1 \in \Bbb{Q}$ or $k$ can be the trivial homomorphism. But if $1_{\Bbb{Z}}$ is sent to $1_{\Bbb{Q}}$, then $k$ must be the inclusion map. However in order to for $kf = 1_{\Bbb{Q}}$ to hold, $f$ must also sent $z$ to $z$ for all $z \in \Bbb{Q}$. But if that's the case, then for any $a/b \in \Bbb{Q}$ where $b \not= 0, 1$, we have (for $n \in \Bbb{Z}$) $$f(a/b) = n = f(n)$$ and this contradicts the fact that $f$ must be injective (since the sequence is exact). So the only possible $\Bbb{Z}$-module map from $\Bbb{Z}$ to $\Bbb{Q}$ is $0$. Do you think my answer is correct? 2) I was wondering if anybody could give a hint on this one, because I couldn't really get started. Thanks in advance.","1) Prove that $\operatorname{Hom}_{\Bbb{Z}}(\Bbb{Q},\Bbb{Z}) = 0$. 2) Show that $\Bbb{Q}$ is not a projective $\Bbb{Z}$-module. 1) We know that $\Bbb{Q}$ is an injective $\Bbb{Z}$-module. This implies that every short exact sequence $$0 \rightarrow \Bbb{Q} \xrightarrow{f} A \xrightarrow{g} B \rightarrow 0$$ is split exact. In particular, $$0 \rightarrow \Bbb{Q} \xrightarrow{f}  \Bbb{Z} \xrightarrow{g} A \rightarrow 0$$ is split exact. But this implies that we have a homomorphism $k: \Bbb{Z} \rightarrow \Bbb{Q}$  such that $kf = 1_{\Bbb{Q}}$. So we need to look at what possible homomorphisms we could have from $\Bbb{Z}$ to $\Bbb{Q}$. Since $\Bbb{Z}$ is cyclic, the homomorphism $k$ is determined by where it sends $1$. Suppose that we send $1$ to $q \in \Bbb{Q}$ such that $q \not= 1$ and $q \not= 0$. Let $m \in \Bbb{Z}$. Then $$k(m) = mk(1) = mq$$ But then $$qmq = k(1)k(m) \not= k(m) = mq$$ So either $1 \in \Bbb{Z}$ must be sent to $1 \in \Bbb{Q}$ or $k$ can be the trivial homomorphism. But if $1_{\Bbb{Z}}$ is sent to $1_{\Bbb{Q}}$, then $k$ must be the inclusion map. However in order to for $kf = 1_{\Bbb{Q}}$ to hold, $f$ must also sent $z$ to $z$ for all $z \in \Bbb{Q}$. But if that's the case, then for any $a/b \in \Bbb{Q}$ where $b \not= 0, 1$, we have (for $n \in \Bbb{Z}$) $$f(a/b) = n = f(n)$$ and this contradicts the fact that $f$ must be injective (since the sequence is exact). So the only possible $\Bbb{Z}$-module map from $\Bbb{Z}$ to $\Bbb{Q}$ is $0$. Do you think my answer is correct? 2) I was wondering if anybody could give a hint on this one, because I couldn't really get started. Thanks in advance.",,"['abstract-algebra', 'modules']"
63,Historical textbook on group theory/algebra,Historical textbook on group theory/algebra,,"Recently I have started reading about some of the history of mathematics in order to better understand things. A lot of ideas in algebra come from trying to understand the problem of finding solutions to polynomials in terms of radicals, which is solved by the Abel-Ruffini theorem and Galois theory. I was wondering if there's a textbook (or history book which emphasizes the mathematics) that goes vaguely in chronological order or explicitly presents theorems and concepts in their historical context. Alternatively, if you think it would be better to attempt to read the original papers (Abel's famous quote about reading the masters comes to mind), such as the works of the mathematicians mentioned in this wikipedia article , how would I go about doing so? EDIT: while researching some of the recommended books, I found this interesting list (pdf) of references. The inspiration for this question came from asking myself ""why would someone bother/think of defining a normal subgroup in the first place?"" (although I already know the answer) and hence I am asking about Galois theory, but really this question works for any area of mathematics and perhaps someone should open a community wiki question for that.","Recently I have started reading about some of the history of mathematics in order to better understand things. A lot of ideas in algebra come from trying to understand the problem of finding solutions to polynomials in terms of radicals, which is solved by the Abel-Ruffini theorem and Galois theory. I was wondering if there's a textbook (or history book which emphasizes the mathematics) that goes vaguely in chronological order or explicitly presents theorems and concepts in their historical context. Alternatively, if you think it would be better to attempt to read the original papers (Abel's famous quote about reading the masters comes to mind), such as the works of the mathematicians mentioned in this wikipedia article , how would I go about doing so? EDIT: while researching some of the recommended books, I found this interesting list (pdf) of references. The inspiration for this question came from asking myself ""why would someone bother/think of defining a normal subgroup in the first place?"" (although I already know the answer) and hence I am asking about Galois theory, but really this question works for any area of mathematics and perhaps someone should open a community wiki question for that.",,"['abstract-algebra', 'math-history']"
64,Finding a Galois extension of $\Bbb Q$ of degree $3$,Finding a Galois extension of  of degree,\Bbb Q 3,"I want to find a Galois extension $K/\mathbb{Q}$ such that $[K:\mathbb{Q}]=3$. I thought about this for a while, but haven't been able to come up with one yet. What I tried so far: (i) Taking a separable polynomial $f\in\mathbb{Q}[x]$ of degree three and considering its splitting field. (ii) Looking at the splitting fields of primitive roots of unity. The second one doesn't work because the splitting field over such a root has as degree a value in the range of Euler's totient function, and this doesn't contain three. The first approach also didn't work. I tried polynomials of the form $(x-\sqrt{p})(x-\sqrt{q})(x-\sqrt{r})$ for primes, but those have degree $8$. I then tried 'third roots' $\alpha$, but the minimal polynomials of those have complex as well as real roots, so the simple extensions $K(\alpha)$ aren't normal unless they're trivial. Could anyone please give me a hint on what else to try.","I want to find a Galois extension $K/\mathbb{Q}$ such that $[K:\mathbb{Q}]=3$. I thought about this for a while, but haven't been able to come up with one yet. What I tried so far: (i) Taking a separable polynomial $f\in\mathbb{Q}[x]$ of degree three and considering its splitting field. (ii) Looking at the splitting fields of primitive roots of unity. The second one doesn't work because the splitting field over such a root has as degree a value in the range of Euler's totient function, and this doesn't contain three. The first approach also didn't work. I tried polynomials of the form $(x-\sqrt{p})(x-\sqrt{q})(x-\sqrt{r})$ for primes, but those have degree $8$. I then tried 'third roots' $\alpha$, but the minimal polynomials of those have complex as well as real roots, so the simple extensions $K(\alpha)$ aren't normal unless they're trivial. Could anyone please give me a hint on what else to try.",,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field']"
65,A name for this property?,A name for this property?,,"Let $*$ be an operation such that $(xy)^* = y^*x^*$, e.g. if $x,y$ are $2\times2$ matrices and $*$ is ""take the inverse"" or if $x,y$ are operators and if $*$ is the adjoint. Is there a name for such a property ?","Let $*$ be an operation such that $(xy)^* = y^*x^*$, e.g. if $x,y$ are $2\times2$ matrices and $*$ is ""take the inverse"" or if $x,y$ are operators and if $*$ is the adjoint. Is there a name for such a property ?",,"['abstract-algebra', 'terminology', 'binary-operations']"
66,Understanding Lagrange's Theorem (Group Theory),Understanding Lagrange's Theorem (Group Theory),,"I am beginning with Abstract Algebra and I'm trying to understand Lagrange's Theorem. The theorem reads For any finite group $G$, the order of every subgroup $H$ of $G$ should divide the order of $G$. It seems simple and I've used it to solve some exercices but I believe I'm missing the essence of it. Is there an example that can help me understand it better, or visualize it? Is there a geometric interpretation?","I am beginning with Abstract Algebra and I'm trying to understand Lagrange's Theorem. The theorem reads For any finite group $G$, the order of every subgroup $H$ of $G$ should divide the order of $G$. It seems simple and I've used it to solve some exercices but I believe I'm missing the essence of it. Is there an example that can help me understand it better, or visualize it? Is there a geometric interpretation?",,"['abstract-algebra', 'group-theory']"
67,Proof of the polynomial division algorithm,Proof of the polynomial division algorithm,,"The theorem which I am referring to states: for any $f, g$ there exist $q, r$ such that $f(x)=g(x)q(x)+r(x)$ with the degree of $r$ less than the degree of $g$ if $g$ is monic. The book I am using remarks that it can be proven via induction on the degree of $g$, but leaves the proof to the reader. Unfortunately, this reader is not clever enough to get it. The base case is fairly clear, but I'm completely stuck after that. Any hints?","The theorem which I am referring to states: for any $f, g$ there exist $q, r$ such that $f(x)=g(x)q(x)+r(x)$ with the degree of $r$ less than the degree of $g$ if $g$ is monic. The book I am using remarks that it can be proven via induction on the degree of $g$, but leaves the proof to the reader. Unfortunately, this reader is not clever enough to get it. The base case is fairly clear, but I'm completely stuck after that. Any hints?",,"['abstract-algebra', 'polynomials', 'induction']"
68,Number systems violating easy primes,Number systems violating easy primes,,Many students are surprised to learn that the definition of prime is not generally “only divisible by 1 and itself” for general number systems. What are some examples of numbers systems for which $p|ab$ implies either $p|a$ or $p|b$ is not equivalent to the definition $p$ only is divisible by 1 and itself? And explicit constructions if violating numbers in these systems?,Many students are surprised to learn that the definition of prime is not generally “only divisible by 1 and itself” for general number systems. What are some examples of numbers systems for which $p|ab$ implies either $p|a$ or $p|b$ is not equivalent to the definition $p$ only is divisible by 1 and itself? And explicit constructions if violating numbers in these systems?,,['abstract-algebra']
69,Smith Normal Form and classification of factor groups according to the theorem of finitely generated abelian groups,Smith Normal Form and classification of factor groups according to the theorem of finitely generated abelian groups,,"With reference to this question, it was mentioned in the comments that these problems could be solved using the Smith Normal Form . However, I am unable to extract an exact method from the Wikipedia article alone, and further searching yields few general examples. I am asking for an example where the algorithm is used to classify a factor group.","With reference to this question, it was mentioned in the comments that these problems could be solved using the Smith Normal Form . However, I am unable to extract an exact method from the Wikipedia article alone, and further searching yields few general examples. I am asking for an example where the algorithm is used to classify a factor group.",,"['abstract-algebra', 'group-theory', 'smith-normal-form']"
70,Do all Groups have a representation?,Do all Groups have a representation?,,I know that many kind of groups can be represented by matrices; for example: rotation groups can be represented by matrices.  Especially all elements of rotation groups can be represented by orthogonal matrices with determinant positive one. Also Permutation group can be represented by matrices. But I need to know: are there any kind of group which can not be represented by matrices? Or is there any kind of group which does not have a representation? Can you show me sample?,I know that many kind of groups can be represented by matrices; for example: rotation groups can be represented by matrices.  Especially all elements of rotation groups can be represented by orthogonal matrices with determinant positive one. Also Permutation group can be represented by matrices. But I need to know: are there any kind of group which can not be represented by matrices? Or is there any kind of group which does not have a representation? Can you show me sample?,,"['abstract-algebra', 'group-theory', 'representation-theory']"
71,Additive group of rationals has no minimal generating set,Additive group of rationals has no minimal generating set,,"In a comment to Arturo Magidin's answer to this question , Jack Schmidt says that the additive group of the rationals has no minimal generating set. Why does $(\mathbb{Q},+)$ have no minimal generating set?","In a comment to Arturo Magidin's answer to this question , Jack Schmidt says that the additive group of the rationals has no minimal generating set. Why does $(\mathbb{Q},+)$ have no minimal generating set?",,"['abstract-algebra', 'group-theory', 'number-theory', 'abelian-groups', 'rational-numbers']"
72,Is it always possible to create a intuition for abstract algebra theorems?,Is it always possible to create a intuition for abstract algebra theorems?,,"I am a Ph.D student in computer science, and I work on graph isomorphism. My research work requires some level of mathematics (mostly group theory ). I have done basic level abstract algebra course. I try to write down the theorems on peace of paper and try to understand them; I usually repeat this process four five times. Some time by doing this I understand the theorem and its proof, but there are times when I find it difficult. The biggest problem I have faced is that theorems related to abstract algebra are really abstract I mean there is no way to create an intuition (Is it true ?). My question : How to create an intuition for abstract algebra theorems? For Example","I am a Ph.D student in computer science, and I work on graph isomorphism. My research work requires some level of mathematics (mostly group theory ). I have done basic level abstract algebra course. I try to write down the theorems on peace of paper and try to understand them; I usually repeat this process four five times. Some time by doing this I understand the theorem and its proof, but there are times when I find it difficult. The biggest problem I have faced is that theorems related to abstract algebra are really abstract I mean there is no way to create an intuition (Is it true ?). My question : How to create an intuition for abstract algebra theorems? For Example",,"['abstract-algebra', 'group-theory']"
73,A finite Monoid $M$ is a group if and only if it has only one idempotent element,A finite Monoid  is a group if and only if it has only one idempotent element,M,"Suppose that $(M,*)$ is a finite Monoid. Prove that $M$ is a group if and only if there is only a single idempotent element in $M$, namely $e$. One direction is obvious, because if $M$ is a group then $x^2=x$ implies $x=e$, but the other direction has been challenging me for over an hour, so I decided to ask it here.","Suppose that $(M,*)$ is a finite Monoid. Prove that $M$ is a group if and only if there is only a single idempotent element in $M$, namely $e$. One direction is obvious, because if $M$ is a group then $x^2=x$ implies $x=e$, but the other direction has been challenging me for over an hour, so I decided to ask it here.",,"['abstract-algebra', 'group-theory', 'monoid']"
74,Finite group for which $|\{x:x^m=e\}|\leq m$ for all $m$ is cyclic. [duplicate],Finite group for which  for all  is cyclic. [duplicate],|\{x:x^m=e\}|\leq m m,"This question already has answers here : If $x^m=e$ has at most $m$ solutions for any $m\in \mathbb{N}$, then $G$ is cyclic (8 answers) Closed 4 years ago . Let $G$ be a finite group. For each positive integer $m$, if $x^{m}=e$ has at most $m$ solutions in $G$, $G$ is cyclic. What I have thought is that $n=\sum_{d\mid n}\phi(d)$ can be used to solve this and showing that $|G|$ order element in $G$ exists is enough.","This question already has answers here : If $x^m=e$ has at most $m$ solutions for any $m\in \mathbb{N}$, then $G$ is cyclic (8 answers) Closed 4 years ago . Let $G$ be a finite group. For each positive integer $m$, if $x^{m}=e$ has at most $m$ solutions in $G$, $G$ is cyclic. What I have thought is that $n=\sum_{d\mid n}\phi(d)$ can be used to solve this and showing that $|G|$ order element in $G$ exists is enough.",,"['abstract-algebra', 'finite-groups']"
75,Outer Automorphisms of $S_n$,Outer Automorphisms of,S_n,"There are a lots of questions (and several good explanations) on understanding the non-trivial outer automorphism of $S_6$. What I haven't seen, though, is a good explanation of why there are no such outer automorphisms for $n\neq 6$. Wikipedia makes a passing mention of this fact here . In particular, they have this cryptic claim: For every symmetric group other than $S_6$, there is no other conjugacy class of elements of order 2 with the same number of elements as the class of transpositions. This seems like the natural thing to prove, given the knowledge that you can construct an outer automorphism of $S_6$ which takes transpositions to products of three transpositions (i.e. things like $(12)\mapsto (12)(34)(56)$.) Also, the second reason Wikipedia gives doesn't feel very intuitive to me. My question, then, is how does one justify the original (quoted) statement above? Here is the naive computation of sizes of conjugacy classes: We need to show that when $n, k\neq 6,3$ $$\frac{n!}{2^k k! (n-2k)!}\neq\frac{n!}{2(n-2)!},$$which is equivalent to $$2^k k!(n-2k)!\neq 2(n-2)!$$ What I want to say is something like, if $n{-}2$ is bigger than $k$, then there is always some factor on the RHS that doesn't appear in the LHS (except when it is a power of two). Will this type of analysis get me anywhere, or is there a better way to think about this?","There are a lots of questions (and several good explanations) on understanding the non-trivial outer automorphism of $S_6$. What I haven't seen, though, is a good explanation of why there are no such outer automorphisms for $n\neq 6$. Wikipedia makes a passing mention of this fact here . In particular, they have this cryptic claim: For every symmetric group other than $S_6$, there is no other conjugacy class of elements of order 2 with the same number of elements as the class of transpositions. This seems like the natural thing to prove, given the knowledge that you can construct an outer automorphism of $S_6$ which takes transpositions to products of three transpositions (i.e. things like $(12)\mapsto (12)(34)(56)$.) Also, the second reason Wikipedia gives doesn't feel very intuitive to me. My question, then, is how does one justify the original (quoted) statement above? Here is the naive computation of sizes of conjugacy classes: We need to show that when $n, k\neq 6,3$ $$\frac{n!}{2^k k! (n-2k)!}\neq\frac{n!}{2(n-2)!},$$which is equivalent to $$2^k k!(n-2k)!\neq 2(n-2)!$$ What I want to say is something like, if $n{-}2$ is bigger than $k$, then there is always some factor on the RHS that doesn't appear in the LHS (except when it is a power of two). Will this type of analysis get me anywhere, or is there a better way to think about this?",,"['abstract-algebra', 'symmetric-groups']"
76,Prove that an infinite ring with finite quotient rings is an integral domain,Prove that an infinite ring with finite quotient rings is an integral domain,,"How can we show that if $R$ is an infinite commutative ring and $R/I$ is finite for every nonzero $I \unlhd R$, then $R$ is an integral domain? I tried proceeding by contradiction: assume $a$,$b$ $\in R \backslash \{0\}$ and $ab=0$; then $R/(a)$ and $R/(b)$ must be finite, say $R/(a)=\{k_i + (a) : 1 \leq i \leq m\}$ and $R/(b)=\{l_j + (b) : 1 \leq j \leq n\}$. Does this mean $R$ must be finite? Or what about using the fact that $R/(a,b)$ finite? Thanks for any help with this!","How can we show that if $R$ is an infinite commutative ring and $R/I$ is finite for every nonzero $I \unlhd R$, then $R$ is an integral domain? I tried proceeding by contradiction: assume $a$,$b$ $\in R \backslash \{0\}$ and $ab=0$; then $R/(a)$ and $R/(b)$ must be finite, say $R/(a)=\{k_i + (a) : 1 \leq i \leq m\}$ and $R/(b)=\{l_j + (b) : 1 \leq j \leq n\}$. Does this mean $R$ must be finite? Or what about using the fact that $R/(a,b)$ finite? Thanks for any help with this!",,"['abstract-algebra', 'ring-theory', 'integral-domain']"
77,How to see that the polynomial $4x^2 - 3x^7$ is a permutation of the elements of $\mathbb{Z}/{11}\mathbb{Z}$,How to see that the polynomial  is a permutation of the elements of,4x^2 - 3x^7 \mathbb{Z}/{11}\mathbb{Z},"This is from Rotman's Group Theory book, although I don't have the specific reference right now, as the book is with a friend. He asks to show that $\alpha (x) = 4x^2 - 3x^7$ is a permutation of the elements of $\mathbb{Z}_{11} = \mathbb{Z} / 11\mathbb{Z}$. I can show this by brute force calculation, but I feel there must be some more elegant way to show this. I looked at the Wikipedia page on permutation polynomials , which, based on a quick perusal, seemed to suggest that it is not an easy question when the degree of the polynomial is greater than 2. It also mentioned the Dickson polynomials, but unless I am missing something, the polynomial in the question isn't a Dickson polynomial. I understand that there might not be a general method for this type of question, but even if someone can help me understand this particular example better, I would appreciate it. In particular, what I'd like to know is: is there a nice way to build a permutation polynomial given some quotient of $\mathbb{Z}$ to be permuted? can we say something about the inverse of the polynomial -- is it also a polynomial? How is it related to the initial polynomial? is there some faster way than plugging in to see that this polynomial must act as a permutation on $\mathbb{Z}_{11}$? what other sets $\mathbb{Z}_{n}$ will be permuted by this polynomial? How can we see this? Answers to any or all of these questions, or explanations why there are not good answers, would be much appreciated. Thanks! p.s. this is my first post, so please feel free to edit/re-tag as necessary as I am not yet sure how this all works.","This is from Rotman's Group Theory book, although I don't have the specific reference right now, as the book is with a friend. He asks to show that $\alpha (x) = 4x^2 - 3x^7$ is a permutation of the elements of $\mathbb{Z}_{11} = \mathbb{Z} / 11\mathbb{Z}$. I can show this by brute force calculation, but I feel there must be some more elegant way to show this. I looked at the Wikipedia page on permutation polynomials , which, based on a quick perusal, seemed to suggest that it is not an easy question when the degree of the polynomial is greater than 2. It also mentioned the Dickson polynomials, but unless I am missing something, the polynomial in the question isn't a Dickson polynomial. I understand that there might not be a general method for this type of question, but even if someone can help me understand this particular example better, I would appreciate it. In particular, what I'd like to know is: is there a nice way to build a permutation polynomial given some quotient of $\mathbb{Z}$ to be permuted? can we say something about the inverse of the polynomial -- is it also a polynomial? How is it related to the initial polynomial? is there some faster way than plugging in to see that this polynomial must act as a permutation on $\mathbb{Z}_{11}$? what other sets $\mathbb{Z}_{n}$ will be permuted by this polynomial? How can we see this? Answers to any or all of these questions, or explanations why there are not good answers, would be much appreciated. Thanks! p.s. this is my first post, so please feel free to edit/re-tag as necessary as I am not yet sure how this all works.",,"['abstract-algebra', 'group-theory', 'polynomials', 'permutations']"
78,Can we construct a group with exactly $k$ Sylow-Subgroups?,Can we construct a group with exactly  Sylow-Subgroups?,k,"Inspired by the answers given by these three questions ( here , here , and here ), what is the general solution for constructing a group with a specific number of Sylow subgroups? That is, given a prime $p$ and a positive integer $n\equiv1\pmod p$ , is it always possible to construct a group $G$ with exactly $n$ subgroups of order $p$ ? For example, is it possible to construct a group with exactly $15$ subgroups of order $7$ , or exactly $35$ subgroups of order $17$ ? From Hölder's Theorem (Theorem 19 here ), if there is at least one prime $q \mid n$ such that $q \neq 1\pmod p$ , then we can conclude that $g=|G|$ cannot be squarefree. At the same time, it is not a necessary condition that every prime $q\mid n$ is congruent to $1\pmod p$ . In our example with $n=15$ and $p=7$ , we know that $g$ cannot be square-free. From the Sylow Theorems, $np \mid g$ , so $g$ is a multiple of $105$ . However, $g$ is at least $315$ because of the requirement that $g$ must not be square-free. That is as far as I can get with constructing such groups. Edit: Derek's answer suggests that the answer to my original question is false in general. That is, it is not always possible to construct a group with $n$ subgroups of order $p$ , even when $n$ is restricted to $1\pmod p$ . How would one prove this? Secondly, under what conditions would there exist a group with exactly $n$ $p$ -Sylow subgroups?","Inspired by the answers given by these three questions ( here , here , and here ), what is the general solution for constructing a group with a specific number of Sylow subgroups? That is, given a prime and a positive integer , is it always possible to construct a group with exactly subgroups of order ? For example, is it possible to construct a group with exactly subgroups of order , or exactly subgroups of order ? From Hölder's Theorem (Theorem 19 here ), if there is at least one prime such that , then we can conclude that cannot be squarefree. At the same time, it is not a necessary condition that every prime is congruent to . In our example with and , we know that cannot be square-free. From the Sylow Theorems, , so is a multiple of . However, is at least because of the requirement that must not be square-free. That is as far as I can get with constructing such groups. Edit: Derek's answer suggests that the answer to my original question is false in general. That is, it is not always possible to construct a group with subgroups of order , even when is restricted to . How would one prove this? Secondly, under what conditions would there exist a group with exactly -Sylow subgroups?",p n\equiv1\pmod p G n p 15 7 35 17 q \mid n q \neq 1\pmod p g=|G| q\mid n 1\pmod p n=15 p=7 g np \mid g g 105 g 315 g n p n 1\pmod p n p,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
79,Showing the product of two normal subgroups is normal [closed],Showing the product of two normal subgroups is normal [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Prove that if $H$ or $K$ are normal subgroups then $HK=\{hk\mid h\in H,k\in K\}$ is a subgroup.  Then if both are normal subgroups, prove that HK is normal.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Prove that if $H$ or $K$ are normal subgroups then $HK=\{hk\mid h\in H,k\in K\}$ is a subgroup.  Then if both are normal subgroups, prove that HK is normal.",,"['abstract-algebra', 'normal-subgroups']"
80,Example of two prime ideals whose intersection of the squares not equal to the square of the intersection,Example of two prime ideals whose intersection of the squares not equal to the square of the intersection,,"In this topic the OP raised the following question: Let $R$ be a commutative noetherian ring and $\mathfrak p,\mathfrak q \in \operatorname{Spec}(R)$. Is it true that $(\mathfrak p\cap \mathfrak q)^2=\mathfrak p^2 \cap \mathfrak q^2$? Obviously, we always have $(\mathfrak p\cap \mathfrak q)^2 \subseteq \mathfrak p^2 \cap \mathfrak q^2$ and there is no reason to think that, in general, the converse holds. What remained unsolved in that topic is to Give an example of prime ideals $\mathfrak p,\mathfrak q$ (in a noetherian ring) such that $$(\mathfrak p\cap \mathfrak q)^2 \neq \mathfrak p^2 \cap \mathfrak q^2.$$ Edit. It would be nice to have such an example for $R$ a noetherian integral domain .","In this topic the OP raised the following question: Let $R$ be a commutative noetherian ring and $\mathfrak p,\mathfrak q \in \operatorname{Spec}(R)$. Is it true that $(\mathfrak p\cap \mathfrak q)^2=\mathfrak p^2 \cap \mathfrak q^2$? Obviously, we always have $(\mathfrak p\cap \mathfrak q)^2 \subseteq \mathfrak p^2 \cap \mathfrak q^2$ and there is no reason to think that, in general, the converse holds. What remained unsolved in that topic is to Give an example of prime ideals $\mathfrak p,\mathfrak q$ (in a noetherian ring) such that $$(\mathfrak p\cap \mathfrak q)^2 \neq \mathfrak p^2 \cap \mathfrak q^2.$$ Edit. It would be nice to have such an example for $R$ a noetherian integral domain .",,['abstract-algebra']
81,Why any field is a principal ideal domain?,Why any field is a principal ideal domain?,,"Why any field is a principal ideal domain? According to the definition of P.I.D , first, a ring's ideal can be generated from a single element; second, this ring has no zero-divisor. This two conditions make a ring P.I.D. But how to prove any field is P.I.D?","Why any field is a principal ideal domain? According to the definition of P.I.D , first, a ring's ideal can be generated from a single element; second, this ring has no zero-divisor. This two conditions make a ring P.I.D. But how to prove any field is P.I.D?",,"['abstract-algebra', 'ring-theory', 'field-theory', 'ideals', 'principal-ideal-domains']"
82,Construct algebraic closure of $\mathbb{Q}$,Construct algebraic closure of,\mathbb{Q},"In abstract algebra lecture, the lecturer wants to construct an algebraic closure of $\mathbb{Q}$. The construction is as follow: Suppose $\mathbb{Q_1}=\mathbb{Q}$. Let $\mathbb{Q}_2$ be the set which contains $\mathbb{Q}_1$ and all roots of polynomials which have degree less than or equal to $1$. Some for $\mathbb{Q}_3$ which contains $\mathbb{Q}_2$ and all roots of polynomial which have degree less than or equal to $2$. In general , $\mathbb{Q}_n$ is the set which contains $\mathbb{Q}_{n-1}$ and all roots of polynomials which have degree less than oe equal to $n-1$. Take $E=\cup_{n \geq 1} \;\mathbb{Q}_n$ Claim: $E$ is an algebraic extension of $\mathbb{Q}$ Let $\alpha \in E$. Then $\alpha \in \mathbb{Q}_n$ for some $n$. By the contruction, we know that $\mathbb{Q}_n$ is an algebraic extension of $\mathbb{Q}_{n-1}$ and $\mathbb{Q}_{n-1}$ is an algebraic extension of $\mathbb{Q}_{n-2}$. By using transitivity of algebraic extension, we have $\mathbb{Q}_n$ is an algebraic extension of $\mathbb{Q}$. Hence, $\alpha$ is algebraic over $\mathbb{Q}$. Claim: $E$ is algebraically closed Let $f \in E[X]$. Then $f(X)=a_0+a_1X+...+a_nX^n$ where $a_i \in E$ for all $1 \leq i \leq n$. Then $a_i \in \mathbb{Q}_m$ for some $m$. Choose $t$ large enough such that all $a_i \in \mathbb{Q}_t$. Then by the construction , $f$ has root in $\mathbb{Q}_{t+1} \subset E$ Hence, $E$ is an algebraic closure of $\mathbb{Q}$. Can anyone help me to check whether I got the proof correct or not. Because I not sure whether I leave out some details.","In abstract algebra lecture, the lecturer wants to construct an algebraic closure of $\mathbb{Q}$. The construction is as follow: Suppose $\mathbb{Q_1}=\mathbb{Q}$. Let $\mathbb{Q}_2$ be the set which contains $\mathbb{Q}_1$ and all roots of polynomials which have degree less than or equal to $1$. Some for $\mathbb{Q}_3$ which contains $\mathbb{Q}_2$ and all roots of polynomial which have degree less than or equal to $2$. In general , $\mathbb{Q}_n$ is the set which contains $\mathbb{Q}_{n-1}$ and all roots of polynomials which have degree less than oe equal to $n-1$. Take $E=\cup_{n \geq 1} \;\mathbb{Q}_n$ Claim: $E$ is an algebraic extension of $\mathbb{Q}$ Let $\alpha \in E$. Then $\alpha \in \mathbb{Q}_n$ for some $n$. By the contruction, we know that $\mathbb{Q}_n$ is an algebraic extension of $\mathbb{Q}_{n-1}$ and $\mathbb{Q}_{n-1}$ is an algebraic extension of $\mathbb{Q}_{n-2}$. By using transitivity of algebraic extension, we have $\mathbb{Q}_n$ is an algebraic extension of $\mathbb{Q}$. Hence, $\alpha$ is algebraic over $\mathbb{Q}$. Claim: $E$ is algebraically closed Let $f \in E[X]$. Then $f(X)=a_0+a_1X+...+a_nX^n$ where $a_i \in E$ for all $1 \leq i \leq n$. Then $a_i \in \mathbb{Q}_m$ for some $m$. Choose $t$ large enough such that all $a_i \in \mathbb{Q}_t$. Then by the construction , $f$ has root in $\mathbb{Q}_{t+1} \subset E$ Hence, $E$ is an algebraic closure of $\mathbb{Q}$. Can anyone help me to check whether I got the proof correct or not. Because I not sure whether I leave out some details.",,"['abstract-algebra', 'field-theory']"
83,Automorphism groups and symmetric groups,Automorphism groups and symmetric groups,,"Looking on the Wikipedia page for automorphism ; in the examples it first states that in set theory, the automorphism of a set $X$ is an arbitrary permutation of the elements of $X$, and these form the automorphism group, also known as the symmetric group, on $X$. However on the page Automorphisms of the symmetric and alternating groups , $ \operatorname{Aut}(S_n) = S_n $ except in the cases where $n=1,2,6$. So is the statement on the automorphism page incorrect when it says that all automorphism groups on $X$ are also known as symmetric groups, as not all of them are when for example $X=S_n$?","Looking on the Wikipedia page for automorphism ; in the examples it first states that in set theory, the automorphism of a set $X$ is an arbitrary permutation of the elements of $X$, and these form the automorphism group, also known as the symmetric group, on $X$. However on the page Automorphisms of the symmetric and alternating groups , $ \operatorname{Aut}(S_n) = S_n $ except in the cases where $n=1,2,6$. So is the statement on the automorphism page incorrect when it says that all automorphism groups on $X$ are also known as symmetric groups, as not all of them are when for example $X=S_n$?",,"['abstract-algebra', 'group-theory', 'terminology']"
84,Each element of a ring is either a unit or a nilpotent element iff the ring has a unique prime ideal,Each element of a ring is either a unit or a nilpotent element iff the ring has a unique prime ideal,,Let $R$ be a ring. Prove that each element of $R$ is either a unit or a nilpotent element iff the ring $R$ has a unique prime ideal. Help me some hints.,Let $R$ be a ring. Prove that each element of $R$ is either a unit or a nilpotent element iff the ring $R$ has a unique prime ideal. Help me some hints.,,"['abstract-algebra', 'ring-theory']"
85,The algebraic closure of a finite field and its Galois group,The algebraic closure of a finite field and its Galois group,,"$F$ is an extension field of a field $K$. Let $F$  be an algebraic closure of $\mathbb{Z}_p $ ($p$ prime). Show that $(i)$ $F$ is algebraic Galois over $\mathbb{Z}_p$ $(ii)$  The map $\alpha:F\rightarrow F$ given by $u\mapsto u^p$ is a nonidentiy $\mathbb{Z}_p$-automorphism of $F$. $(iii)$  The subgroup $H=\langle \alpha \rangle$ is a proper subgroup of Aut$(F/\mathbb{Z}_p)$ where the fixed field is $\mathbb{Z}_p$, which is also the fixed field of Aut$(F/\mathbb{Z}_p)$ by $(i).$ So, here is my attempt for (i). Let  $S \subset \mathbb{Z}_p[x])$ of monic polynomials of the form $x^{p^n}-x$.  Then for all $f\in S$, gcd$(f,f^{\prime})=1$(i.e, the polynomials are separble) and $F=\mathbb{Z}_p(a\in F:f(a)=0)$. So $(F/\mathbb{Z}_p)$ is Galois. I'd be glad if I could get assistance for (ii) and (iii) as well.  Thanks. ADDED: Attempt at (iii). but I know that since $F/\mathbb{Z}_p$ is a finite Galois extension, its fixed field is $\mathbb{Z}_p$ hints... The field $\mathbb{Z}_p$ must be contained in $F$. For $a\in \mathbb{Z}_p$, $\alpha(a)=a^p=a$. Thus the polynomial $x^p-x$ has $p$ zeros in $F$, namely, the elements of $\mathbb{Z}_p$. But the elements fixed under $\alpha$ are precisely the zeros in $F$ of $x^p-x$. Hence the fixed field of $\alpha$ is $\mathbb{Z}_p$ which is also the fixed field of Aut$(F/\mathbb{Z}_p)$. Left to show that $H$ is a proper subgroup... If it helps I know that the order of $\langle \alpha \rangle $ is $n$...","$F$ is an extension field of a field $K$. Let $F$  be an algebraic closure of $\mathbb{Z}_p $ ($p$ prime). Show that $(i)$ $F$ is algebraic Galois over $\mathbb{Z}_p$ $(ii)$  The map $\alpha:F\rightarrow F$ given by $u\mapsto u^p$ is a nonidentiy $\mathbb{Z}_p$-automorphism of $F$. $(iii)$  The subgroup $H=\langle \alpha \rangle$ is a proper subgroup of Aut$(F/\mathbb{Z}_p)$ where the fixed field is $\mathbb{Z}_p$, which is also the fixed field of Aut$(F/\mathbb{Z}_p)$ by $(i).$ So, here is my attempt for (i). Let  $S \subset \mathbb{Z}_p[x])$ of monic polynomials of the form $x^{p^n}-x$.  Then for all $f\in S$, gcd$(f,f^{\prime})=1$(i.e, the polynomials are separble) and $F=\mathbb{Z}_p(a\in F:f(a)=0)$. So $(F/\mathbb{Z}_p)$ is Galois. I'd be glad if I could get assistance for (ii) and (iii) as well.  Thanks. ADDED: Attempt at (iii). but I know that since $F/\mathbb{Z}_p$ is a finite Galois extension, its fixed field is $\mathbb{Z}_p$ hints... The field $\mathbb{Z}_p$ must be contained in $F$. For $a\in \mathbb{Z}_p$, $\alpha(a)=a^p=a$. Thus the polynomial $x^p-x$ has $p$ zeros in $F$, namely, the elements of $\mathbb{Z}_p$. But the elements fixed under $\alpha$ are precisely the zeros in $F$ of $x^p-x$. Hence the fixed field of $\alpha$ is $\mathbb{Z}_p$ which is also the fixed field of Aut$(F/\mathbb{Z}_p)$. Left to show that $H$ is a proper subgroup... If it helps I know that the order of $\langle \alpha \rangle $ is $n$...",,['abstract-algebra']
86,Why these 'elementary' facts do not solve the Inverse Galois Problem?,Why these 'elementary' facts do not solve the Inverse Galois Problem?,,"Since every finite group $G$ is isomorphic to a subgroup of $S_{n}$ and according to the first answer on this question there is always (for all $n\geq 1$) a finite Galois extension $K/\mathbb{Q}$ with $\operatorname{Gal}(K/\mathbb{Q})\cong S_{n}$, doesn't the Fundamental Theorem of Galois Theory gives a positive answer to the Inverse Galois Problem? Where is the obvious point I am missing? Thanks!","Since every finite group $G$ is isomorphic to a subgroup of $S_{n}$ and according to the first answer on this question there is always (for all $n\geq 1$) a finite Galois extension $K/\mathbb{Q}$ with $\operatorname{Gal}(K/\mathbb{Q})\cong S_{n}$, doesn't the Fundamental Theorem of Galois Theory gives a positive answer to the Inverse Galois Problem? Where is the obvious point I am missing? Thanks!",,"['abstract-algebra', 'group-theory', 'galois-theory']"
87,"$A\subseteq B\subseteq C$ ring extensions, $A\subseteq C$ finite/finitely-generated $\Rightarrow$ $A\subseteq B$ finite/finitely-generated?","ring extensions,  finite/finitely-generated   finite/finitely-generated?",A\subseteq B\subseteq C A\subseteq C \Rightarrow A\subseteq B,"Let $A\subseteq B\subseteq C$ be commutative unital rings. Recall that the extension $A \subseteq B$ is finite / of finite type / integral , when $B$ is a finitely generated $R$-module / when $B$ is a finitely generated $A$-algebra / when $\forall b \in B$ $\exists$ monic polynomial $f \in A[x]$ with $f(b)=0$. Notation $_AB$ means ""$A$-module $B$"". We know that $A\subseteq C$ is integral iff $A\subseteq B$ and $B\subseteq C$ are integral (Grillet, Abstract Algebra , 7.3.3). Do we also have the following: $A\subseteq C$ is finite $\Leftrightarrow$ $A\subseteq B$ and $B\subseteq C$ are finite. $A\subseteq C$ is of finite type $\Leftrightarrow$ $A\subseteq B$ and $B\subseteq C$ are of finite type. I'm having problems with ($A\subseteq C$ finite $\Rightarrow$ $A\subseteq B$ finite) and with ($A\subseteq C$ of finite type $\Rightarrow$ $A\subseteq B$ of finite type). If $_AB$ is a direct summand of $_AC$ (for example when $A$ is a field), i.e. $_AC= _A B\oplus _A B'$ for some submodule $B'$ of $C$, then $C=Ac_1+\cdots+Ac_n$ implies $c_i=b_i+b'_i$ for some $b_i\in B$ and $b'_i \in B$, hence $B = Ab_1 + \cdots + Ab_n$. But what if $_AB$ is not a direct summand of $_AC$? And what about the 'finite type' case?","Let $A\subseteq B\subseteq C$ be commutative unital rings. Recall that the extension $A \subseteq B$ is finite / of finite type / integral , when $B$ is a finitely generated $R$-module / when $B$ is a finitely generated $A$-algebra / when $\forall b \in B$ $\exists$ monic polynomial $f \in A[x]$ with $f(b)=0$. Notation $_AB$ means ""$A$-module $B$"". We know that $A\subseteq C$ is integral iff $A\subseteq B$ and $B\subseteq C$ are integral (Grillet, Abstract Algebra , 7.3.3). Do we also have the following: $A\subseteq C$ is finite $\Leftrightarrow$ $A\subseteq B$ and $B\subseteq C$ are finite. $A\subseteq C$ is of finite type $\Leftrightarrow$ $A\subseteq B$ and $B\subseteq C$ are of finite type. I'm having problems with ($A\subseteq C$ finite $\Rightarrow$ $A\subseteq B$ finite) and with ($A\subseteq C$ of finite type $\Rightarrow$ $A\subseteq B$ of finite type). If $_AB$ is a direct summand of $_AC$ (for example when $A$ is a field), i.e. $_AC= _A B\oplus _A B'$ for some submodule $B'$ of $C$, then $C=Ac_1+\cdots+Ac_n$ implies $c_i=b_i+b'_i$ for some $b_i\in B$ and $b'_i \in B$, hence $B = Ab_1 + \cdots + Ab_n$. But what if $_AB$ is not a direct summand of $_AC$? And what about the 'finite type' case?",,"['abstract-algebra', 'commutative-algebra']"
88,Question about UFD,Question about UFD,,"I want to know some examples with the following properies. Let $R$ be a domain such that every non unit element $x$ is a product of finite irreducible elements, but $R$ is not a UFD, and there is some element $y\in R$ such that $y$ has two distinct factorizations with different lengths. Textbooks tell me, $\mathbb{Z}[\sqrt{-5}]$ is a non-UFD since $6=2\cdot3=(1+\sqrt{-5})(1-\sqrt{-5})$ . Since $\mathbb{Z}[\sqrt{-5}]$ is Noetherian, then it is easy to show that every non unit element is a product of finite irreducible elements. But I donot know if every two factorizations of any given element of $\mathbb{Z}[\sqrt{-5}]$ have the same lengths ? That is to ask if this is an example? More, what about general algebraic integer domains ? What is the famous (easy understood) example that a atomic domain is not a HFD (any two factorizations of any given $x$ have the same length)? Thanks.","I want to know some examples with the following properies. Let be a domain such that every non unit element is a product of finite irreducible elements, but is not a UFD, and there is some element such that has two distinct factorizations with different lengths. Textbooks tell me, is a non-UFD since . Since is Noetherian, then it is easy to show that every non unit element is a product of finite irreducible elements. But I donot know if every two factorizations of any given element of have the same lengths ? That is to ask if this is an example? More, what about general algebraic integer domains ? What is the famous (easy understood) example that a atomic domain is not a HFD (any two factorizations of any given have the same length)? Thanks.",R x R y\in R y \mathbb{Z}[\sqrt{-5}] 6=2\cdot3=(1+\sqrt{-5})(1-\sqrt{-5}) \mathbb{Z}[\sqrt{-5}] \mathbb{Z}[\sqrt{-5}] x,"['abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
89,"Is there a name for, or notable structure that uses, weird ""distributive laws"" such as $a\times(b+c)=b\times a+c\times a$?","Is there a name for, or notable structure that uses, weird ""distributive laws"" such as ?",a\times(b+c)=b\times a+c\times a,"Consider the following ""multiplication"" over ""addition"": $$ a \times (b + c) $$ The distributive law in common notion is the left distributive law: $$ a \times (b + c) = a \times b + a \times c $$ But what if?: $$ a \times (b + c) = b \times a + c \times a $$ $$ a \times (b + c) = a \times b + c \times a $$ $$ a \times (b + c) = b \times a + a \times c $$ Are there any name for these? I guess they're ""anti"", ""exo"", and ""endo"" distributive, respectively. Are there any notable algebraic structure with any of these laws?","Consider the following ""multiplication"" over ""addition"": The distributive law in common notion is the left distributive law: But what if?: Are there any name for these? I guess they're ""anti"", ""exo"", and ""endo"" distributive, respectively. Are there any notable algebraic structure with any of these laws?","
a \times (b + c)
 
a \times (b + c) = a \times b + a \times c
 
a \times (b + c) = b \times a + c \times a
 
a \times (b + c) = a \times b + c \times a
 
a \times (b + c) = b \times a + a \times c
",['abstract-algebra']
90,Finite-order elements of $\text{GL}_4(\mathbb{Q})$,Finite-order elements of,\text{GL}_4(\mathbb{Q}),"I'm currently studying for my qualifying exams in algebra, and I have not been able to solve the following problem: Determine all possible positive integers $n$ such that there exists an element in $\text{GL}_4(\mathbb{Q})$ of order $n$ . I've been playing around with various canonical forms, but I just can't figure it out.  Can anyone help me?","I'm currently studying for my qualifying exams in algebra, and I have not been able to solve the following problem: Determine all possible positive integers such that there exists an element in of order . I've been playing around with various canonical forms, but I just can't figure it out.  Can anyone help me?",n \text{GL}_4(\mathbb{Q}) n,"['abstract-algebra', 'group-theory', 'totient-function', 'cyclotomic-polynomials', 'linear-groups']"
91,Proposition 5.21 in Atiyah-MacDonald,Proposition 5.21 in Atiyah-MacDonald,,"There's just one step in this proof I can't see for the life of me. Set up: We have a field K and an algebraically closed field $\Omega$.  $(B, g)$ is maximal in the set $\Sigma$ of ordered pairs $(A, f)$ where $A$ is a subring of K and $f$ a homomorphism into $\Omega$, where $\Sigma$ has the partial order $(A, f) \leq (A', f')$ if $A$ is a subring of $A'$ and $f'|_{A} = f$.  The overall claim is that $(B, g)$ is a valuation of $K$.  We let $M$ be the unique maximal ideal of $B$ (which exists).  We take $x \in K$ with $x \neq 0$ and may assume that $M[x]$ is not the unit ideal of $B' = B[x]$(by a lemma) and so is contained in some maximal ideal $M'$.  Let $k = B/M$ and $k' = B'/M'$. The claim I don't understand: Since $k' = k[\bar{x}]$ for $\bar{x}$ the image of x in k' (which I see), $\bar{x}$ is algebraic over k.","There's just one step in this proof I can't see for the life of me. Set up: We have a field K and an algebraically closed field $\Omega$.  $(B, g)$ is maximal in the set $\Sigma$ of ordered pairs $(A, f)$ where $A$ is a subring of K and $f$ a homomorphism into $\Omega$, where $\Sigma$ has the partial order $(A, f) \leq (A', f')$ if $A$ is a subring of $A'$ and $f'|_{A} = f$.  The overall claim is that $(B, g)$ is a valuation of $K$.  We let $M$ be the unique maximal ideal of $B$ (which exists).  We take $x \in K$ with $x \neq 0$ and may assume that $M[x]$ is not the unit ideal of $B' = B[x]$(by a lemma) and so is contained in some maximal ideal $M'$.  Let $k = B/M$ and $k' = B'/M'$. The claim I don't understand: Since $k' = k[\bar{x}]$ for $\bar{x}$ the image of x in k' (which I see), $\bar{x}$ is algebraic over k.",,"['abstract-algebra', 'commutative-algebra']"
92,"Is there a group $G$ and subgroup $H$, such that there exists $g\in G$ with $gHg^{-1} \subset H$ and $|H:gHg^{-1}|$ is infinite?","Is there a group  and subgroup , such that there exists  with  and  is infinite?",G H g\in G gHg^{-1} \subset H |H:gHg^{-1}|,"Question (asking on behalf of my friend who studies abstract algebra): Is there a group $G$ and subgroup $H$ , such that there exists $g\in G$ with $gHg^{-1} \subset H$ and $|H:gHg^{-1}|$ is infinite? ( I incline to think this is true.) For such an example to exist, $H$ (and hence $G$ ) must be infinite and a non-normal subgroup of $G$ . At first, it seems easy. However, I really don't know many types of infinite nonabelian groups (perhaps only the general linear group ${GL}_n(F)$ and the group of bijections). Thanks for your slightest effort.","Question (asking on behalf of my friend who studies abstract algebra): Is there a group and subgroup , such that there exists with and is infinite? ( I incline to think this is true.) For such an example to exist, (and hence ) must be infinite and a non-normal subgroup of . At first, it seems easy. However, I really don't know many types of infinite nonabelian groups (perhaps only the general linear group and the group of bijections). Thanks for your slightest effort.",G H g\in G gHg^{-1} \subset H |H:gHg^{-1}| H G G {GL}_n(F),"['abstract-algebra', 'group-theory', 'examples-counterexamples', 'infinite-groups']"
93,"Putnam 2007 A5: Finite group $n$ elements order $p$, prove either $n=0$ or $p$ divides $n+1$","Putnam 2007 A5: Finite group  elements order , prove either  or  divides",n p n=0 p n+1,"Putnam 2007 Question A5: ""Suppose that a finite group has exactly $n$ elements of order $p$, where $p$ is a prime. Prove that either $n=0$ or $p$ divides $n+1$."" I split this problem into two cases: where $p$ divides $|G|=m$, and where $p$ does not divide $m$. The latter case is trivial - by Lagrange's Theorem, $n=0$ as the order of an element must divide the order of the group. The first case appears more complicated and my idea is to use Sylow Theory, and I came across an interesting solution using this on https://blogs.haverford.edu/mathproblemsolving/files/2010/05/Putnam-2007-Solutions.pdf : ""There are 1 + kp Sylow p-subgroups and, because they are all conjugate and every element of order p is contained in some Sylow p-subroup, they partition the n elements of order p into 1 + kp equal-size collections. The number of elements of order p in any p-group is always one less than a power of p, implying n + 1 ≡ (1 + kp)(-1) + 1 ≡ 0 modulo p."" The places I am stuck are: 1) Why the fact that all Sylow p-subgroups being conjugate and every element of order $p$ contained in some Sylow p-subgroup (I understand why both these facts are true), implies that the Sylow p-subgroups partition the $n$ elements of order $p$ into $1+kp$ equal-size collections - heck I don't even understand what is meant by this... 2) Why the number of elements of order $p$ in any p-group is always one less than a power of p. If anyone has other ways to show that $p$ dividing $m$ implies that $p$ divides $n+1$, that would also be greatly appreciated :) Thanks","Putnam 2007 Question A5: ""Suppose that a finite group has exactly $n$ elements of order $p$, where $p$ is a prime. Prove that either $n=0$ or $p$ divides $n+1$."" I split this problem into two cases: where $p$ divides $|G|=m$, and where $p$ does not divide $m$. The latter case is trivial - by Lagrange's Theorem, $n=0$ as the order of an element must divide the order of the group. The first case appears more complicated and my idea is to use Sylow Theory, and I came across an interesting solution using this on https://blogs.haverford.edu/mathproblemsolving/files/2010/05/Putnam-2007-Solutions.pdf : ""There are 1 + kp Sylow p-subgroups and, because they are all conjugate and every element of order p is contained in some Sylow p-subroup, they partition the n elements of order p into 1 + kp equal-size collections. The number of elements of order p in any p-group is always one less than a power of p, implying n + 1 ≡ (1 + kp)(-1) + 1 ≡ 0 modulo p."" The places I am stuck are: 1) Why the fact that all Sylow p-subgroups being conjugate and every element of order $p$ contained in some Sylow p-subgroup (I understand why both these facts are true), implies that the Sylow p-subgroups partition the $n$ elements of order $p$ into $1+kp$ equal-size collections - heck I don't even understand what is meant by this... 2) Why the number of elements of order $p$ in any p-group is always one less than a power of p. If anyone has other ways to show that $p$ dividing $m$ implies that $p$ divides $n+1$, that would also be greatly appreciated :) Thanks",,"['abstract-algebra', 'group-theory', 'finite-groups', 'contest-math', 'sylow-theory']"
94,direct product commutes with tensor product?,direct product commutes with tensor product?,,"Let $(A_i)_{i\in I}$ be a family of right $R$-modules and $M$ be a left $R$-module, where $I$ is an index set. The natural homomorphism $$\varphi:(\prod_{i\in I}A_i)\otimes_RM\to \prod_{i\in I}(A_i\otimes_RM)$$ given by $(a_i)\otimes m\mapsto(a_i\otimes m)$ is not always a bijection. It is  easy to obtain $\varphi$ is a surjection provided $M$ is finitely generated. If we assume that $M$ is finitely presented, can we prove $\varphi$ is a bijection?","Let $(A_i)_{i\in I}$ be a family of right $R$-modules and $M$ be a left $R$-module, where $I$ is an index set. The natural homomorphism $$\varphi:(\prod_{i\in I}A_i)\otimes_RM\to \prod_{i\in I}(A_i\otimes_RM)$$ given by $(a_i)\otimes m\mapsto(a_i\otimes m)$ is not always a bijection. It is  easy to obtain $\varphi$ is a surjection provided $M$ is finitely generated. If we assume that $M$ is finitely presented, can we prove $\varphi$ is a bijection?",,"['abstract-algebra', 'ring-theory', 'modules', 'tensor-products']"
95,How is the quotient group related to the direct product group?,How is the quotient group related to the direct product group?,,"I'm trying to understand what the relation is between the direct product and the quotient group. If we let $H$ be a normal subgroup of a group $G$, then it is not too difficult to show that the set of all cosets of $H$ in $G$ forms a quotient group $G/H$: \begin{equation} G/H = \{ g H \mid g \in G \} \end{equation} On the other hand, the Cartesian product of two groups $G$ and $H$ is defined as: \begin{equation} G \times H = \{ (g,h) \mid g \in G \text{ and } h \in H \} \end{equation} where $(g,h)$ denotes the set of ordered pairs. The direct product operation on this set is defined as: \begin{equation} (g_1,h_1)(g_2,h_2) = (g_1g_2,h_1h_2) \in G \times H \end{equation} and it is easy to see that the direct product forms a group. Is the following statement true: \begin{equation} K = G \times H \implies G \simeq K / (\{e_G \} \times H) \end{equation} If so, under what conditions is it true? And how can we see it is true (or false)? Edit 26/03 : Up to this point, I believe I have found a method (see below) of showing the isomorphism relation. I would be really grateful if someone could tell me whether this proof is correct or not. Let us identity the elements of $h \in H$ with element of $K$ by setting $h \equiv (e_G,h)$. The elements of $K/H$ are as usual defined by: \begin{equation} K/H = \{ (g,h) H \mid g \in G \text{ and } h \in H \} \end{equation} Since $h_1H=H$ for some $h_1 \in H$, we have: \begin{equation} (g,h)H = (g',h')H \iff g=g' \text{ and } h' = h h_1 \tag{1} \end{equation} and so without loss of generality we can write every element of $K/H$ in the form $(g,e_H)H$. Now, let the map: \begin{equation} f : G \to K/H \end{equation} be defined by: \begin{equation} f(g) = (g,e_H) H \tag{2} \end{equation} The map is one-to-one. This can be seen by equation $(1)$, because if: \begin{equation} f(g) = f(g') \end{equation} then: \begin{equation} (g,e_H) H = (g',e_H) H \implies g=g' \end{equation} Furthermore, the map is trivially onto: \begin{equation} \forall (g,h) H \in K/H \; \exists \; g \in G \; , \; f(g)=(g,h) H \end{equation} and thus the map is bijective. Finally, the map is also a homomorphism, because: \begin{equation} f(gg') = (gg',e_H) H = (g,e_H)(g',e_H) H = (g,e_H)(g',e_H) HH = (g,e_H) H (g',e_H) H = f(g) f(g') \end{equation} and so $f$ is a isomorphism. Thus, by definition of equation $(2)$, we have shown that $G  \simeq K/H$. Any input is much appreciated.","I'm trying to understand what the relation is between the direct product and the quotient group. If we let $H$ be a normal subgroup of a group $G$, then it is not too difficult to show that the set of all cosets of $H$ in $G$ forms a quotient group $G/H$: \begin{equation} G/H = \{ g H \mid g \in G \} \end{equation} On the other hand, the Cartesian product of two groups $G$ and $H$ is defined as: \begin{equation} G \times H = \{ (g,h) \mid g \in G \text{ and } h \in H \} \end{equation} where $(g,h)$ denotes the set of ordered pairs. The direct product operation on this set is defined as: \begin{equation} (g_1,h_1)(g_2,h_2) = (g_1g_2,h_1h_2) \in G \times H \end{equation} and it is easy to see that the direct product forms a group. Is the following statement true: \begin{equation} K = G \times H \implies G \simeq K / (\{e_G \} \times H) \end{equation} If so, under what conditions is it true? And how can we see it is true (or false)? Edit 26/03 : Up to this point, I believe I have found a method (see below) of showing the isomorphism relation. I would be really grateful if someone could tell me whether this proof is correct or not. Let us identity the elements of $h \in H$ with element of $K$ by setting $h \equiv (e_G,h)$. The elements of $K/H$ are as usual defined by: \begin{equation} K/H = \{ (g,h) H \mid g \in G \text{ and } h \in H \} \end{equation} Since $h_1H=H$ for some $h_1 \in H$, we have: \begin{equation} (g,h)H = (g',h')H \iff g=g' \text{ and } h' = h h_1 \tag{1} \end{equation} and so without loss of generality we can write every element of $K/H$ in the form $(g,e_H)H$. Now, let the map: \begin{equation} f : G \to K/H \end{equation} be defined by: \begin{equation} f(g) = (g,e_H) H \tag{2} \end{equation} The map is one-to-one. This can be seen by equation $(1)$, because if: \begin{equation} f(g) = f(g') \end{equation} then: \begin{equation} (g,e_H) H = (g',e_H) H \implies g=g' \end{equation} Furthermore, the map is trivially onto: \begin{equation} \forall (g,h) H \in K/H \; \exists \; g \in G \; , \; f(g)=(g,h) H \end{equation} and thus the map is bijective. Finally, the map is also a homomorphism, because: \begin{equation} f(gg') = (gg',e_H) H = (g,e_H)(g',e_H) H = (g,e_H)(g',e_H) HH = (g,e_H) H (g',e_H) H = f(g) f(g') \end{equation} and so $f$ is a isomorphism. Thus, by definition of equation $(2)$, we have shown that $G  \simeq K/H$. Any input is much appreciated.",,"['abstract-algebra', 'group-theory']"
96,The set of all nilpotent elements is an ideal,The set of all nilpotent elements is an ideal,,"Given that R is commutative ring with unity, I want show that set of all nilpotent elements is an ideal of R. I know how to show ideal if set is given but here set is not given to me. Can anyone help me?","Given that R is commutative ring with unity, I want show that set of all nilpotent elements is an ideal of R. I know how to show ideal if set is given but here set is not given to me. Can anyone help me?",,"['abstract-algebra', 'ideals']"
97,"$p$ prime, Group of order $p^n$ is cyclic iff it is an abelian group having a unique subgroup of order $p$","prime, Group of order  is cyclic iff it is an abelian group having a unique subgroup of order",p p^n p,"I've just read from An introduction to the theory of groups from Rotman's the following theorem: Theorem 2.19. Let $p$ be a prime. A group $G$ of order $p^n$ is cyclic   if and only if it is an abelian group having a unique subgroup of order $p$. Proof Necessity follows at once from Lemma 2.15. For the converse, let    $a \in G$ have largest order, say $p^k$ (it follows that $g^{p^k} = 1$ for   all $g \in G$). Of course, the unique subgroup $H$ of order $p$ is a subgroup   of $\langle a\rangle$. If $\langle a\rangle$ is a proper subgroup of $G$,   then there is $x \in G$ with $x \not \in \langle a\rangle$ but with   $x^p \in \langle a\rangle$; let $x^p = a^l$. If $k = 1$, then $x^p = 1$ and   $x \in H \subset \langle a\rangle$, a contradiction; we may, therefore,   assume that $k>1$. Now $$1 = x^{p^k}=(x^p)^{p^{k-1}}=a^{lp^{k-1}},$$   so that $l = pm$ for some integer $m$, by Exercise 2.13. Hence,   $x^p = a^{mp}$, and so $1 = x^{-p}a^{mp}$. Since $G$ is abelian,   $x^{-p}a^{mp} = (x^{-1}a^m)^p$, and so   $x^{-1}a^m \in H \subset \langle a\rangle$.   This gives $x \in \langle a\rangle$, a contradiction. Therefore,   $G = \langle a\rangle$ and hence is cyclic. As usual, there is some trivial part of the proof which I don't understand: I don't see why ""If $\langle a\rangle$ is a proper subgroup of $G$, then there is $x \in G$ with $x \not \in \langle a\rangle$ but with $x^p \in \langle a\rangle$"", I understand the rest of the proof. I would appreciate if someone could explain to me that statement.","I've just read from An introduction to the theory of groups from Rotman's the following theorem: Theorem 2.19. Let $p$ be a prime. A group $G$ of order $p^n$ is cyclic   if and only if it is an abelian group having a unique subgroup of order $p$. Proof Necessity follows at once from Lemma 2.15. For the converse, let    $a \in G$ have largest order, say $p^k$ (it follows that $g^{p^k} = 1$ for   all $g \in G$). Of course, the unique subgroup $H$ of order $p$ is a subgroup   of $\langle a\rangle$. If $\langle a\rangle$ is a proper subgroup of $G$,   then there is $x \in G$ with $x \not \in \langle a\rangle$ but with   $x^p \in \langle a\rangle$; let $x^p = a^l$. If $k = 1$, then $x^p = 1$ and   $x \in H \subset \langle a\rangle$, a contradiction; we may, therefore,   assume that $k>1$. Now $$1 = x^{p^k}=(x^p)^{p^{k-1}}=a^{lp^{k-1}},$$   so that $l = pm$ for some integer $m$, by Exercise 2.13. Hence,   $x^p = a^{mp}$, and so $1 = x^{-p}a^{mp}$. Since $G$ is abelian,   $x^{-p}a^{mp} = (x^{-1}a^m)^p$, and so   $x^{-1}a^m \in H \subset \langle a\rangle$.   This gives $x \in \langle a\rangle$, a contradiction. Therefore,   $G = \langle a\rangle$ and hence is cyclic. As usual, there is some trivial part of the proof which I don't understand: I don't see why ""If $\langle a\rangle$ is a proper subgroup of $G$, then there is $x \in G$ with $x \not \in \langle a\rangle$ but with $x^p \in \langle a\rangle$"", I understand the rest of the proof. I would appreciate if someone could explain to me that statement.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'cyclic-groups']"
98,Maximal ideals in $C^\infty(\mathbb{R})$,Maximal ideals in,C^\infty(\mathbb{R}),"I know that for a compact manifold $M$ any maximal ideal in the algebra $C^\infty(M)$ of smooth functions on $M$ is of the form $\mathfrak{m}_p=\{f\in C^\infty(M)|f(p)=0\}$. For example, the proof is in the answer to this question . Is that true for non-compact manifolds? For example, for $M=\mathbb{R}$? I don't think so, but I can't figure out a counterexample. Do you know any example of a maximal ideal in $C^\infty(\mathbb{R})$ which is not of the form $\mathfrak{m}_p$? Thank you very much! Edit: Thank you very much for pointing out the maximal ideal, containing the ideal of compactly-supported functions. Does anyone know how to describe it?","I know that for a compact manifold $M$ any maximal ideal in the algebra $C^\infty(M)$ of smooth functions on $M$ is of the form $\mathfrak{m}_p=\{f\in C^\infty(M)|f(p)=0\}$. For example, the proof is in the answer to this question . Is that true for non-compact manifolds? For example, for $M=\mathbb{R}$? I don't think so, but I can't figure out a counterexample. Do you know any example of a maximal ideal in $C^\infty(\mathbb{R})$ which is not of the form $\mathfrak{m}_p$? Thank you very much! Edit: Thank you very much for pointing out the maximal ideal, containing the ideal of compactly-supported functions. Does anyone know how to describe it?",,"['abstract-algebra', 'functions', 'ring-theory', 'examples-counterexamples', 'ideals']"
99,"If a subring of a ring R has identity, does R also have the identity?","If a subring of a ring R has identity, does R also have the identity?",,"I know it does not make sense that if a subring of a ring $R$ is commutative, then $R$ is also commutative. (For example, the set consisting of the matrices whose all entries except (1,1)-entry are zero, is a subring of ring of 2x2 real matrices.) I also considered the case of a ring containing a subring with identity, but I had no ideas. Maybe it seems that it does not make sense, either. Who give me some examples supporting my guess?","I know it does not make sense that if a subring of a ring $R$ is commutative, then $R$ is also commutative. (For example, the set consisting of the matrices whose all entries except (1,1)-entry are zero, is a subring of ring of 2x2 real matrices.) I also considered the case of a ring containing a subring with identity, but I had no ideas. Maybe it seems that it does not make sense, either. Who give me some examples supporting my guess?",,"['abstract-algebra', 'ring-theory']"
