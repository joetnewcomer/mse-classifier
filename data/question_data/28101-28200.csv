,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"joint distribution, discrete and continuous random variables","joint distribution, discrete and continuous random variables",,"This may be trivial, but if X is a random variable uniformly distributed over $[0,1]$ and Y is a discrete random variable such that $\mathbb{P} (Y=y_1) = \lambda \in (0,1]$ and $\mathbb{P} (Y=y_2) = 1 - \lambda$. Now I am seeking to compute the expectation of (a linear function) of the random variable X conditional on Y. Is this possible? Can we think of a ""joint distribution"" of two random variables where one random variable has a continuous density function and the other is discrete? Thank you","This may be trivial, but if X is a random variable uniformly distributed over $[0,1]$ and Y is a discrete random variable such that $\mathbb{P} (Y=y_1) = \lambda \in (0,1]$ and $\mathbb{P} (Y=y_2) = 1 - \lambda$. Now I am seeking to compute the expectation of (a linear function) of the random variable X conditional on Y. Is this possible? Can we think of a ""joint distribution"" of two random variables where one random variable has a continuous density function and the other is discrete? Thank you",,"['probability', 'probability-distributions', 'uniform-distribution']"
1,What is a formal definition of 'randomness'?,What is a formal definition of 'randomness'?,,What is a rigorous mathematical/logical definition of 'randomness'? Under what conditions can we truthfully apply the predicate 'is random'?,What is a rigorous mathematical/logical definition of 'randomness'? Under what conditions can we truthfully apply the predicate 'is random'?,,"['probability', 'statistics', 'random']"
2,What are my chances in a Most Excellent Adventure?,What are my chances in a Most Excellent Adventure?,,"Most Excellent Adventure is a home brew roleplaying game system based on the Bill & Ted Films, plays gnarly air guitar riff . In this game system, when you draw from your dice pool you need to connect the results as a phone number on your phone pad: Here one person has rolled 4, 2, 8, 3, 8, and 2, dialling 3-2-2-4-8-8. The other 7, 4, 6, 3, 9, and 4, only dialling 4-4-7 or 3-6-9. And the longest number wins. How do I work out my chance for success (or chance of a certain phone number length) from this system? I've tried enumerating the chance of getting a two digit number depending on which number you rolled first (each of the first ones is $1/10$) and I get: $4/10$ $6/10$ $4/10$ $6/10$ $9/10$ $6/10$ $5/10$ $7/10$ $5/10$ $4/10$ But then, how do I follow each different 'route' of probabilities? I could imagine drawing a probability tree with ten branches and up to 12 levels, but that seems excessive. I could draw up a table (with blanks for non-telephonable combinations), but that would get hard to follow after the first table or so). I've tried to consider combinatrics, but I've gotten myself confused over nPr and nCr notation and not getting the right numbers in there. Is there an easier way to calculate the probabilities?","Most Excellent Adventure is a home brew roleplaying game system based on the Bill & Ted Films, plays gnarly air guitar riff . In this game system, when you draw from your dice pool you need to connect the results as a phone number on your phone pad: Here one person has rolled 4, 2, 8, 3, 8, and 2, dialling 3-2-2-4-8-8. The other 7, 4, 6, 3, 9, and 4, only dialling 4-4-7 or 3-6-9. And the longest number wins. How do I work out my chance for success (or chance of a certain phone number length) from this system? I've tried enumerating the chance of getting a two digit number depending on which number you rolled first (each of the first ones is $1/10$) and I get: $4/10$ $6/10$ $4/10$ $6/10$ $9/10$ $6/10$ $5/10$ $7/10$ $5/10$ $4/10$ But then, how do I follow each different 'route' of probabilities? I could imagine drawing a probability tree with ten branches and up to 12 levels, but that seems excessive. I could draw up a table (with blanks for non-telephonable combinations), but that would get hard to follow after the first table or so). I've tried to consider combinatrics, but I've gotten myself confused over nPr and nCr notation and not getting the right numbers in there. Is there an easier way to calculate the probabilities?",,['probability']
3,Lottery Math (different combinations),Lottery Math (different combinations),,"In my country, Brazil, we have a lottery game called ""Mega-Sena"". You can choose from 6 (cheapest set) to 15 (most expensive set) numbers from a total of 60. *Blue: Chosen numbers; *Green: Amount of chosen numbers. Every week they have a new contest where are drawn 6 numbers from 1 to 60, no repeated numbers ( give a look ). Any gambler who hits 6 numbers wins. Gambling with only 6 numbers, odds are: $\binom{n}{k}=\frac{n!}{k!(n-k)!}$ $\binom{60}{6}=1:50,063,860$ Gambling with 15 numbers, odds are: $\frac{\binom{60}{6}}{\binom{15}{6}} \approx 1 : 10,003$ The cost of the set of 06 numbers is \$1.00. $\binom{60}{6}$ * \$1.00 = 50,063,860 * \$1.00 = $50,063,860.00 The cost of the set of 15 numbers is \$5,005.00. $\frac{\binom{60}{6}}{\binom{15}{6}}$ * \$5,005.00 = 10,002.7692308 * \$5,005.00 = $50,063,860.00 Based on the cost, no gambler have any advantage over another one. The odds vs cost are the same. When you choose a set having over 6 numbers (7 to 15), the lottery understands that you want all combinations of 6 numbers based on the chosen numbers. e.g.: 01-02-03-04-05-06-07 Gambling with the above set of 7 numbers is the same as gambling with all the sets of 6 numbers below: 01-02-03-04-05-06 01-03-04-05-06-07 01-02-04-05-06-07 01-02-03-05-06-07 01-02-03-04-06-07 01-02-03-04-05-07 02-03-04-05-06-07 The question: I know that I can win for sure choosing 50,063,860 different sets with 6 numbers each. But can I guarantee winning this lottery by choosing 10,003 different sets of 15 numbers each? How? If no, what is the minimum required sets/combinations to have a guaranteed victory (remember, you can choose sets from 6 to 15 numbers each)?","In my country, Brazil, we have a lottery game called ""Mega-Sena"". You can choose from 6 (cheapest set) to 15 (most expensive set) numbers from a total of 60. *Blue: Chosen numbers; *Green: Amount of chosen numbers. Every week they have a new contest where are drawn 6 numbers from 1 to 60, no repeated numbers ( give a look ). Any gambler who hits 6 numbers wins. Gambling with only 6 numbers, odds are: $\binom{n}{k}=\frac{n!}{k!(n-k)!}$ $\binom{60}{6}=1:50,063,860$ Gambling with 15 numbers, odds are: $\frac{\binom{60}{6}}{\binom{15}{6}} \approx 1 : 10,003$ The cost of the set of 06 numbers is \$1.00. $\binom{60}{6}$ * \$1.00 = 50,063,860 * \$1.00 = $50,063,860.00 The cost of the set of 15 numbers is \$5,005.00. $\frac{\binom{60}{6}}{\binom{15}{6}}$ * \$5,005.00 = 10,002.7692308 * \$5,005.00 = $50,063,860.00 Based on the cost, no gambler have any advantage over another one. The odds vs cost are the same. When you choose a set having over 6 numbers (7 to 15), the lottery understands that you want all combinations of 6 numbers based on the chosen numbers. e.g.: 01-02-03-04-05-06-07 Gambling with the above set of 7 numbers is the same as gambling with all the sets of 6 numbers below: 01-02-03-04-05-06 01-03-04-05-06-07 01-02-04-05-06-07 01-02-03-05-06-07 01-02-03-04-06-07 01-02-03-04-05-07 02-03-04-05-06-07 The question: I know that I can win for sure choosing 50,063,860 different sets with 6 numbers each. But can I guarantee winning this lottery by choosing 10,003 different sets of 15 numbers each? How? If no, what is the minimum required sets/combinations to have a guaranteed victory (remember, you can choose sets from 6 to 15 numbers each)?",,"['probability', 'combinatorics', 'combinations']"
4,Probability of choosing ace of spades before any club,Probability of choosing ace of spades before any club,,"From a deck of $52$ cards, cards are picked one by one, randomly and without replacement. What is the probability that no club is extracted before the ace of spades? I think using total probability for solve this $$P(B)=P(A_1)P(B\mid A_1)+\ldots+P(A_n)P(B\mid A_n)$$ But I am not sure how to solve this. Can someone help me?","From a deck of $52$ cards, cards are picked one by one, randomly and without replacement. What is the probability that no club is extracted before the ace of spades? I think using total probability for solve this $$P(B)=P(A_1)P(B\mid A_1)+\ldots+P(A_n)P(B\mid A_n)$$ But I am not sure how to solve this. Can someone help me?",,"['probability', 'card-games']"
5,Probability problem: cars on the road,Probability problem: cars on the road,,"I heard this problem, so I might be missing pieces. Imagine there are two cities separated by a very long road. The road has only one lane, so cars cannot overtake each other. $N$ cars are released from one of the cities, the cars travel at constant speeds $V$ chosen at random and independently from a probability distribution $P(V)$. What is the expected number of groups of cars arriving simultaneously at the other city? P.S.: Supposedly, this was a Princeton physics qualifier problem, if that makes a difference.","I heard this problem, so I might be missing pieces. Imagine there are two cities separated by a very long road. The road has only one lane, so cars cannot overtake each other. $N$ cars are released from one of the cities, the cars travel at constant speeds $V$ chosen at random and independently from a probability distribution $P(V)$. What is the expected number of groups of cars arriving simultaneously at the other city? P.S.: Supposedly, this was a Princeton physics qualifier problem, if that makes a difference.",,['probability']
6,Probability of getting two pair in poker,Probability of getting two pair in poker,,"I was looking at this website http://www.cwu.edu/~glasbys/POKER.HTM and I read the explanation for how to calculate the probability of getting a full house.  To me, the logic basically looked like you figure out the number of possible ranks and multiply by the number of ways to choose the cards from that given rank. In other words, for a full house $P=$ $$\frac{{13\choose1}{4\choose3}{12\choose1}{4\choose2}}{52\choose5}$$ Following this logic, I tried to calculate the probability of getting two pair.  My (incorrect) logic was that there are 13 possible ranks for the first pair and $4\choose2$ ways to choose two cards from that rank, 12 possible ranks for the second pair and $4\choose2$ ways to choose two cards from that rank, and 11 possible ranks for last card and $4\choose1$ ways to choose a card from that rank. So I tried $P=$ $$\frac{{13\choose1}{4\choose2}{12\choose1}{4\choose2}{11\choose1}{4\choose1}}{52\choose5}$$ Obviously my solution was incorrect.  I read explanation and the correct answer is $P=$ $$\frac{{13\choose2}{4\choose2}{4\choose2}{11\choose1}{4\choose1}}{52\choose5}$$ I'm still a bit fuzzy on where I went wrong though.  Can anyone help me understand this problem a little better?  Thank you very much for your help.","I was looking at this website http://www.cwu.edu/~glasbys/POKER.HTM and I read the explanation for how to calculate the probability of getting a full house.  To me, the logic basically looked like you figure out the number of possible ranks and multiply by the number of ways to choose the cards from that given rank. In other words, for a full house $P=$ $$\frac{{13\choose1}{4\choose3}{12\choose1}{4\choose2}}{52\choose5}$$ Following this logic, I tried to calculate the probability of getting two pair.  My (incorrect) logic was that there are 13 possible ranks for the first pair and $4\choose2$ ways to choose two cards from that rank, 12 possible ranks for the second pair and $4\choose2$ ways to choose two cards from that rank, and 11 possible ranks for last card and $4\choose1$ ways to choose a card from that rank. So I tried $P=$ $$\frac{{13\choose1}{4\choose2}{12\choose1}{4\choose2}{11\choose1}{4\choose1}}{52\choose5}$$ Obviously my solution was incorrect.  I read explanation and the correct answer is $P=$ $$\frac{{13\choose2}{4\choose2}{4\choose2}{11\choose1}{4\choose1}}{52\choose5}$$ I'm still a bit fuzzy on where I went wrong though.  Can anyone help me understand this problem a little better?  Thank you very much for your help.",,"['probability', 'combinatorics', 'poker']"
7,Calculation of the Covariance of Gaussian Mixtures,Calculation of the Covariance of Gaussian Mixtures,,"I have a Gaussian mixture model, given by: $$ X \sim \sum_{i = 1}^M \alpha_i N_p(\mu_i, C_i) $$ such that $\sum_{i=1}^M\alpha_i =1 $ . Is there a way I can compute the overall covariance matrix if $x$ ? I would like to say "" $X$ has a covariance matrix given by $C$ "".","I have a Gaussian mixture model, given by: such that . Is there a way I can compute the overall covariance matrix if ? I would like to say "" has a covariance matrix given by "".","
X \sim \sum_{i = 1}^M \alpha_i N_p(\mu_i, C_i)
 \sum_{i=1}^M\alpha_i =1  x X C","['probability', 'probability-distributions', 'normal-distribution']"
8,How many rolls do I need to determine if my dice are fair?,How many rolls do I need to determine if my dice are fair?,,"Roughly how many times do I need to roll a 6-sided die to feel confident that it's giving ""fair"" results? What about a 10-sided or 20-sided die? Note that I will be actually manually rolling physical dice, this isn't just a textbook exercise. I'd like to minimize how long it takes me to perform this experiment with each die :) I know this depends on my expected ""confidence level"" (95%? 99%?) If I choose a 95% confidence, for example, does that imply that 1 out of 20 fair dice will fail this test? Or that a single fair dice would fail the test 1 out of 20 times? If so, that sounds fairly high. Are there standard techniques for doing this kind of a test? Edit: It is beyond the scope of the math-focused question I've asked here, but I've explained more about the overall testing scenario over on the stats site here: https://stats.stackexchange.com/questions/14301/designing-a-test-for-a-psychic-who-says-he-can-influence-dice-rolls/14302#14302","Roughly how many times do I need to roll a 6-sided die to feel confident that it's giving ""fair"" results? What about a 10-sided or 20-sided die? Note that I will be actually manually rolling physical dice, this isn't just a textbook exercise. I'd like to minimize how long it takes me to perform this experiment with each die :) I know this depends on my expected ""confidence level"" (95%? 99%?) If I choose a 95% confidence, for example, does that imply that 1 out of 20 fair dice will fail this test? Or that a single fair dice would fail the test 1 out of 20 times? If so, that sounds fairly high. Are there standard techniques for doing this kind of a test? Edit: It is beyond the scope of the math-focused question I've asked here, but I've explained more about the overall testing scenario over on the stats site here: https://stats.stackexchange.com/questions/14301/designing-a-test-for-a-psychic-who-says-he-can-influence-dice-rolls/14302#14302",,"['probability', 'statistics', 'dice']"
9,What does the value of a probability density function (PDF) at some x indicate?,What does the value of a probability density function (PDF) at some x indicate?,,"I understand that the probability mass function of a discrete random-variable X is $y=g(x)$. This means $P(X=x_0) = g(x_0)$. Now, a probability density function of of a continuous random variable X is $y=f(x)$. Wikipedia defines this function $y$ to mean In probability theory, a probability density function (pdf), or density of a continuous random variable, is a function that describes the relative likelihood for this random variable to take on a given value. I am confused about the meaning of 'relative likelihood' because it certainly does not mean probability! The probability $P(X<x_0)$ is given by some integral of the pdf. So what does $f(x_0)$ indicate? It gives a real number, but isn't the relative likelihood of a specific value for a CRV always zero?","I understand that the probability mass function of a discrete random-variable X is $y=g(x)$. This means $P(X=x_0) = g(x_0)$. Now, a probability density function of of a continuous random variable X is $y=f(x)$. Wikipedia defines this function $y$ to mean In probability theory, a probability density function (pdf), or density of a continuous random variable, is a function that describes the relative likelihood for this random variable to take on a given value. I am confused about the meaning of 'relative likelihood' because it certainly does not mean probability! The probability $P(X<x_0)$ is given by some integral of the pdf. So what does $f(x_0)$ indicate? It gives a real number, but isn't the relative likelihood of a specific value for a CRV always zero?",,"['probability', 'statistics', 'random-variables']"
10,Independence of a random variable $X$ from itself,Independence of a random variable  from itself,X,"In our lecture on probability, my professor made the comment that ""a random variable X is not independent from itself."" (Here he was specifically talking about discrete random variables.) I asked him why that was true. (My intuition for two counterexamples are $X \equiv 0$ and $X$ s.t. $$m_X(x) = \begin{cases}1, &\text{ if } x = x_0\\ 0, &\text{ if }x \neq x_0.)\end{cases}$$ In these cases, it seems that $\mathbb{P}(X \leq x_1 , X \leq x_2) = \mathbb{P}(X \leq x_1) \cdot \mathbb{P}(X \leq x_2)$. My professor's response was, ""The independence from or dependence of $X$ on itself depends on the definition of the joint distribution function $m_{X,X}$, which is essentially arbitrary."" Can someone help me to understand this?","In our lecture on probability, my professor made the comment that ""a random variable X is not independent from itself."" (Here he was specifically talking about discrete random variables.) I asked him why that was true. (My intuition for two counterexamples are $X \equiv 0$ and $X$ s.t. $$m_X(x) = \begin{cases}1, &\text{ if } x = x_0\\ 0, &\text{ if }x \neq x_0.)\end{cases}$$ In these cases, it seems that $\mathbb{P}(X \leq x_1 , X \leq x_2) = \mathbb{P}(X \leq x_1) \cdot \mathbb{P}(X \leq x_2)$. My professor's response was, ""The independence from or dependence of $X$ on itself depends on the definition of the joint distribution function $m_{X,X}$, which is essentially arbitrary."" Can someone help me to understand this?",,"['probability', 'random-variables']"
11,What do $\bigcup_{n=1}^\infty S_n$ and $\bigcap_{n=1}^\infty S_n$ mean?,What do  and  mean?,\bigcup_{n=1}^\infty S_n \bigcap_{n=1}^\infty S_n,"In some cases, we will have to consider the union or the intersection of several, even infinitely many sets, defined in the obvious way. For example, if for every positive integer $n$, we are given a set $S_n$, then   $$\bbox[border:1px solid red]{\bigcup_{n=1}^\infty S_n}=S_1\cup S_2\cup\cdots=\{x\mid x\in S_n\text{ for some }n\},$$   and   $$\bigcap_{n=1}^\infty S_n=S_1\cap S_2\cap\cdots=\{x\mid x\in S_n\text{ for all }n\}.$$   Two sets are said to be disjoint if their intersection is empty. More generally, several sets are said to be disjoint if no two of them have a common element. A collection of sets is said to be a partition of a set $S$ if the sets in the collection are disjoint and their union is $S$. Normally what I know is that you can make a union or an intersection between only two sets. In this expression, there is a big union of sets. I'm asking about the meaning of this expression – what does it mean? What does the infinity sign do at the top? Things are even more complicated with De Morgan's laws, which use the same expression: Two particularly useful properties are given by De Morgan's laws which state that   $$\left(\bigcup_nS_n\right)^c=\bigcap_nS_n^c,\quad\quad\quad\quad\left(\bigcap_nS_n\right)^c=\bigcup_nS_n^c.$$ Anyone who can explain to me the expression or De Morgan's laws would be much appreciated.","In some cases, we will have to consider the union or the intersection of several, even infinitely many sets, defined in the obvious way. For example, if for every positive integer $n$, we are given a set $S_n$, then   $$\bbox[border:1px solid red]{\bigcup_{n=1}^\infty S_n}=S_1\cup S_2\cup\cdots=\{x\mid x\in S_n\text{ for some }n\},$$   and   $$\bigcap_{n=1}^\infty S_n=S_1\cap S_2\cap\cdots=\{x\mid x\in S_n\text{ for all }n\}.$$   Two sets are said to be disjoint if their intersection is empty. More generally, several sets are said to be disjoint if no two of them have a common element. A collection of sets is said to be a partition of a set $S$ if the sets in the collection are disjoint and their union is $S$. Normally what I know is that you can make a union or an intersection between only two sets. In this expression, there is a big union of sets. I'm asking about the meaning of this expression – what does it mean? What does the infinity sign do at the top? Things are even more complicated with De Morgan's laws, which use the same expression: Two particularly useful properties are given by De Morgan's laws which state that   $$\left(\bigcup_nS_n\right)^c=\bigcap_nS_n^c,\quad\quad\quad\quad\left(\bigcap_nS_n\right)^c=\bigcup_nS_n^c.$$ Anyone who can explain to me the expression or De Morgan's laws would be much appreciated.",,"['probability', 'statistics', 'elementary-set-theory', 'notation']"
12,Random Dental Floss Odds,Random Dental Floss Odds,,"Awhile back I bought 2 identical rolls of dental floss, each with 50 uses, and picked them randomly.  Tonight, the one I picked hit the 50 use mark.  What is the expected number of uses in the remaining roll? With a 100000 case brute force, I get an expected answer of 8 uses.  Neat, so I have maybe a week. What is the non-brute force answer?","Awhile back I bought 2 identical rolls of dental floss, each with 50 uses, and picked them randomly.  Tonight, the one I picked hit the 50 use mark.  What is the expected number of uses in the remaining roll? With a 100000 case brute force, I get an expected answer of 8 uses.  Neat, so I have maybe a week. What is the non-brute force answer?",,['probability']
13,Probability of random sphere lying inside the unit ball,Probability of random sphere lying inside the unit ball,,"Let $n\geq2$ . Let $B\subseteq\mathbb{R}^n$ be the unit ball. Randomly choose $n+1$ points of $B$ (uniformly and independently). Then (almost surely) there will be a unique hypersphere $S$ passing through all $n+1$ points. What is the probability that $S\subseteq B$ ? When $n=2$ , the probability seems to be exactly $40\%$ .","Let . Let be the unit ball. Randomly choose points of (uniformly and independently). Then (almost surely) there will be a unique hypersphere passing through all points. What is the probability that ? When , the probability seems to be exactly .",n\geq2 B\subseteq\mathbb{R}^n n+1 B S n+1 S\subseteq B n=2 40\%,"['probability', 'geometry', 'spheres', 'geometric-probability']"
14,What is the probability that a solitaire game be winnable?,What is the probability that a solitaire game be winnable?,,"By ""solitaire"", let us mean Klondike solitaire of the form ""Draw 3 cards, Re-Deal infinite"". What is the probability that a solitaire game be winnable? Or equivalently, what is the number of solvable games ? When I came up with the question, it seemed a pretty reasonable thing to ask, and I thought ""surely it must have been answered"". I have no probability formation (save for an introductory undergraduate-level course), but anyway I started thinking on how could the problem be tackled. Immediately my interest shifted from the answer to the above question, to the methods involved in answering it. I couldn't even begin to figure out how would one go solving this problem! How does one even begin to find the number of solvable games? In the same wikipedia link, it is stated that For a ""standard"" game of Klondike (of the form: Draw 3, Re-Deal Infinite, Win 52) the number of solvable games (assuming all cards are known) is between 82-91.5%. The number of unplayable games is 0.25% and the number of games that cannot be won is between 8.5-18%. The reference for the thresholds is this paper by Ronald Bjarnason, Prasad Tadepalli and Alan Fern. It came as a surprise to me that the answer is not really known, and that there are only estimates. I tried reading the paper, but I'm too far away from those lines of thinking to understand what they're talking about. There seems to be some programming going around, but what is the big idea behind their approach to the question? I would like to end this question with a couple of lines from the paper (emphasis by me): Klondike Solitaire has become an almost ubiquitous computer application, available to hundreds of millions of users worldwide on all major operating systems, yet theoreticians have struggled with this game, referring to the   inability to calculate the odds of winning a randomly dealt game as “ one of the embarrassments of applied mathematics ” (Yan et al., 2005).","By ""solitaire"", let us mean Klondike solitaire of the form ""Draw 3 cards, Re-Deal infinite"". What is the probability that a solitaire game be winnable? Or equivalently, what is the number of solvable games ? When I came up with the question, it seemed a pretty reasonable thing to ask, and I thought ""surely it must have been answered"". I have no probability formation (save for an introductory undergraduate-level course), but anyway I started thinking on how could the problem be tackled. Immediately my interest shifted from the answer to the above question, to the methods involved in answering it. I couldn't even begin to figure out how would one go solving this problem! How does one even begin to find the number of solvable games? In the same wikipedia link, it is stated that For a ""standard"" game of Klondike (of the form: Draw 3, Re-Deal Infinite, Win 52) the number of solvable games (assuming all cards are known) is between 82-91.5%. The number of unplayable games is 0.25% and the number of games that cannot be won is between 8.5-18%. The reference for the thresholds is this paper by Ronald Bjarnason, Prasad Tadepalli and Alan Fern. It came as a surprise to me that the answer is not really known, and that there are only estimates. I tried reading the paper, but I'm too far away from those lines of thinking to understand what they're talking about. There seems to be some programming going around, but what is the big idea behind their approach to the question? I would like to end this question with a couple of lines from the paper (emphasis by me): Klondike Solitaire has become an almost ubiquitous computer application, available to hundreds of millions of users worldwide on all major operating systems, yet theoreticians have struggled with this game, referring to the   inability to calculate the odds of winning a randomly dealt game as “ one of the embarrassments of applied mathematics ” (Yan et al., 2005).",,"['probability', 'recreational-mathematics', 'card-games']"
15,Show two random variables have same distribution,Show two random variables have same distribution,,"Let X, Y be two non-negative random variables satisfying the condition $\mathbb{E}[X^\alpha] = \mathbb{E}[Y^\alpha]$ for all $\alpha \in (0, 1/2)$. How can one show that X and Y are equal in distribution? Edit: (only if you find this helpful) $\mathbb{E}[X], \mathbb{E}[Y]$ also exist, but a priori one does not know whether they are equal or not. If you believe that the claim is wrong, I would also be happy to see counterexamples, or at least some intuitive explanations.","Let X, Y be two non-negative random variables satisfying the condition $\mathbb{E}[X^\alpha] = \mathbb{E}[Y^\alpha]$ for all $\alpha \in (0, 1/2)$. How can one show that X and Y are equal in distribution? Edit: (only if you find this helpful) $\mathbb{E}[X], \mathbb{E}[Y]$ also exist, but a priori one does not know whether they are equal or not. If you believe that the claim is wrong, I would also be happy to see counterexamples, or at least some intuitive explanations.",,"['probability', 'probability-theory']"
16,Example of two dependent random variables that satisfy $E[f(X)f(Y)]=Ef(X)Ef(Y)$ for every $f$,Example of two dependent random variables that satisfy  for every,E[f(X)f(Y)]=Ef(X)Ef(Y) f,"Does anyone have an example of two dependent random variables, that satisfy this relation? $E[f(X)f(Y)]=E[f(X)]E[f(Y)]$ for every function $f(t)$. Thanks. *edit: I still couldn't find an example. I think one should be of two identically distributed variables, since all the ""moments"" need to be independent: $Ex^iy^i=Ex^iEy^i$. That's plum hard...","Does anyone have an example of two dependent random variables, that satisfy this relation? $E[f(X)f(Y)]=E[f(X)]E[f(Y)]$ for every function $f(t)$. Thanks. *edit: I still couldn't find an example. I think one should be of two identically distributed variables, since all the ""moments"" need to be independent: $Ex^iy^i=Ex^iEy^i$. That's plum hard...",,"['probability', 'statistics']"
17,Distribution of the sum of squared independent normal random variables.,Distribution of the sum of squared independent normal random variables.,,"The sum of squares of $k$ independent standard normal random variables $\sim\chi^2_k$ I read here that if I have $k$ i.i.d normal random variables where $X_i\sim\mathcal{N}(0,\sigma^2)$ then $X_1^2+X_2^2+\dots+X_k^2\sim\sigma^2\chi^2_k$. How do I go about obtaining the pdf? If I have $k$ independent normal random variables where $X_i\sim\mathcal{N}(0,\sigma_i^2)$ then what is the distribution of $X_1^2+X_2^2+\dots+X_k^2$?","The sum of squares of $k$ independent standard normal random variables $\sim\chi^2_k$ I read here that if I have $k$ i.i.d normal random variables where $X_i\sim\mathcal{N}(0,\sigma^2)$ then $X_1^2+X_2^2+\dots+X_k^2\sim\sigma^2\chi^2_k$. How do I go about obtaining the pdf? If I have $k$ independent normal random variables where $X_i\sim\mathcal{N}(0,\sigma_i^2)$ then what is the distribution of $X_1^2+X_2^2+\dots+X_k^2$?",,"['probability', 'probability-distributions', 'normal-distribution']"
18,Memoryless property and geometric distribution,Memoryless property and geometric distribution,,"Suppose $X$ is a random variable taking values in $\mathbb N_0$ with the memoryless property,i.e., for each pair of number $s,t \in \mathbb N$, $$P(X\geq s+t\mid X>t)=P(X\geq s)$$ Show that a random variable $X$ with values in $\mathbb N_0$ has the memoryless property if and only if $X \sim \text{Geometric}(p)$ of parameter $p=P(X=1)$. I could show that if $X \sim \text{Geometric}(p)$ (for an arbitrary parameter $p$), then $X$ has the memoryless property. I'll write that part of the answer: $$P(X\geq s)=\sum_{i=s}^{\infty} P(X=i)$$$$=\sum_{i=s}^{\infty} (1-p)^{i-1}p$$$$=\sum_{i=0}^{\infty} (1-p)^{i-1}p-\sum_{i=0}^{s-1}(1-p)^{i-1}p$$$$=\frac{p}{1-p}(\frac{1}{1-(1-p)}-\frac{1-(1-p)^s}{1-(1-p)})$$$$=(1-p)^{s-1}.$$ Similarly, $$P(X\geq s+t\mid X>t)=\dfrac{P((X\geq s+t)\cap (X>t))}{P(X>t)}$$$$=\dfrac{P(X\geq s+t)}{P(X>t)}.$$ After calculating the probability of the numerator and the probability of the denominator, one can arrive to the same expression $$\dfrac{P(X\geq s+t)}{P(X>t)}=(1-p)^{s-1}.$$ So from here one deduces that the geometric random variable has the memoryless property. I got stuck trying to show the other implication: Let $s \in \mathbb N, t=1$, let $E=\{X>1\}$, then $$P(X\geq k+1)=P(X \geq k+1\mid X>1)P(X>1)+P(X\geq k+1 \mid X \leq 1)P(X \leq 1).$$ Since the probability $P(X\geq k+1 \mid X \leq 1)=0$, then $$P(X\geq k+1)=P(X \geq k+1\mid X>1)P(X>1)$$ Using the hypothesis, we have $$P(X \geq k+1)=P(X \geq k+1\mid X>1)P(X>1)=P(X \geq k)P(X>1)$$ I got stuck at that point, I want to conclude that $P(X=k)=(1-p)^{k-1}p$, where $p=P(X=1)$. I would appreciate some help.","Suppose $X$ is a random variable taking values in $\mathbb N_0$ with the memoryless property,i.e., for each pair of number $s,t \in \mathbb N$, $$P(X\geq s+t\mid X>t)=P(X\geq s)$$ Show that a random variable $X$ with values in $\mathbb N_0$ has the memoryless property if and only if $X \sim \text{Geometric}(p)$ of parameter $p=P(X=1)$. I could show that if $X \sim \text{Geometric}(p)$ (for an arbitrary parameter $p$), then $X$ has the memoryless property. I'll write that part of the answer: $$P(X\geq s)=\sum_{i=s}^{\infty} P(X=i)$$$$=\sum_{i=s}^{\infty} (1-p)^{i-1}p$$$$=\sum_{i=0}^{\infty} (1-p)^{i-1}p-\sum_{i=0}^{s-1}(1-p)^{i-1}p$$$$=\frac{p}{1-p}(\frac{1}{1-(1-p)}-\frac{1-(1-p)^s}{1-(1-p)})$$$$=(1-p)^{s-1}.$$ Similarly, $$P(X\geq s+t\mid X>t)=\dfrac{P((X\geq s+t)\cap (X>t))}{P(X>t)}$$$$=\dfrac{P(X\geq s+t)}{P(X>t)}.$$ After calculating the probability of the numerator and the probability of the denominator, one can arrive to the same expression $$\dfrac{P(X\geq s+t)}{P(X>t)}=(1-p)^{s-1}.$$ So from here one deduces that the geometric random variable has the memoryless property. I got stuck trying to show the other implication: Let $s \in \mathbb N, t=1$, let $E=\{X>1\}$, then $$P(X\geq k+1)=P(X \geq k+1\mid X>1)P(X>1)+P(X\geq k+1 \mid X \leq 1)P(X \leq 1).$$ Since the probability $P(X\geq k+1 \mid X \leq 1)=0$, then $$P(X\geq k+1)=P(X \geq k+1\mid X>1)P(X>1)$$ Using the hypothesis, we have $$P(X \geq k+1)=P(X \geq k+1\mid X>1)P(X>1)=P(X \geq k)P(X>1)$$ I got stuck at that point, I want to conclude that $P(X=k)=(1-p)^{k-1}p$, where $p=P(X=1)$. I would appreciate some help.",,"['probability', 'probability-distributions']"
19,Challenging probability problem (AMC 12B Problem 18) - Are the AoPS solutions incomplete/wrong?,Challenging probability problem (AMC 12B Problem 18) - Are the AoPS solutions incomplete/wrong?,,"The problem A frog makes $3$ jumps, each exactly $1$ meter long. The directions of the jumps are chosen independently at random. What is the probability that the frog's final position is no more than $1$ meter from its starting position? Background This problem comes from the AMC $12$ in the year $2010$ . The contest is an invitational test in the US for secondary school to qualify for the Olympiad. It involves $25$ questions in $75$ minutes and problems can be solved without calculus. I didn't get very far in my attempt, so I ultimately searched and found contributed solutions on the Art of Problem Solving . I don't understand ""solution $1$ "" and I am pretty sure ""solution $2$ "" is incorrect. Possible solution $1$ : random additions/subtractions Let $a$ , $b$ , and $c$ be complex numbers of magnitude one and let the frog start on the origin. Consider the 4 equally likely options of adding or subtracting $b$ and $c$ $$ {|a+b+c|,|a+b-c|,|a-b+c|,|a-b-c|} $$ The AoPS solution states ""it is relatively easy"" to show exactly $1$ of these has magnitude $1$ or less. If so, then out of $4$ possible options, there would be $1$ with magnitude $1$ or less, so the probability would be $1/4$ (the corrrect answer is indeed $1/4$ , but this method does not satisfy me yet). I did not understand this step, and someone asked the same question in a previous thread . It's not obvious to me, and I have no clue how you would go about showing this. Is there an inequality that will help? I don't see how to simplify it. Also the official solution is much more complicated (see sketch below), which makes me think this solution is either elegant and overlooked or it is coincidentally the correct number but not the correct method. (Upon further thought, it seems $a = (1, 0), b = (0, 1), c = (-1, 0)$ would be a counter-example as $|a + b + c| = 1 = |a - b + c|$ so both are within 1.) Possible solution 2: geometric probability The solution goes like this. Suppose the first jump is from the origin. So to be $1$ unit from the starting point, you need to be in the unit circle. The next two jumps can be $2$ units after the first jump, equally likely to be in any angle. So the sample space of ending points is a circle of radius $2$ centered at the point of the first jump. This circle is also tangent to the unit circle. Thus the sample space has an area of $4\pi$ , of which the area of the unit circle is $\pi$ . Hence the probability is $1/4$ . I am pretty sure this method is incorrect because I simulated $2$ jumps numerically. You do get a circle of $2$ , but not all points are equally likely. There is clustering to the center of the circle and the circumference of the circle. Plus if this method was true, it would seem that $3$ jumps should be a circle of radius $3$ , but that would imply a totally different answer of $1/9$ . The official solution I found a pdf on the following website, see problem $18$ : http://web2.slc.qc.ca/sh/Contest/AMC12_2010B-S.pdf Let me try to summarize the method... The idea is to set coordinates so the first jump is $(0, 0)$ and the second jump is $(1, 0)$ . Let the starting point be $(\cos \alpha, \sin \alpha)$ and then the location after the third jump is $(1 + \cos \beta, \sin \beta)$ . It is not too hard to work out the condition for the third point to be within $1$ unit of the first point. Ignoring the measure $0$ cases of $\alpha = 0$ and $\alpha = \pi$ , we need $\alpha \leq \beta \leq \pi$ . We can limit to $0 \leq \alpha \leq \pi$ since the other half works out the same by symmetry. And we have $0 \leq \beta \leq 2\pi$ . (Check out this interactive graph on Desmos to see why $\alpha \leq \beta \leq \pi$ : https://www.desmos.com/calculator/egwegf8utr ) Considering a rectangle $(\alpha, \beta)$ where all angles are equally likely, the sample space is the rectangle of area $2\pi$ . The event to be within 1 is a triangle with area $\pi/2$ , so the desired probability is $1/4$ . Are the AoPS solutions incomplete? I would love if their ""solution $1$ "" is correct as it's much easier to compute and it be more reasonable for an average time allotment of $3$ minutes/problem. (Honestly you could give me unlimited time and I'm not sure I would have produced the official solution.) What do you guys think? Disclosure I run the YouTube channel MindYourDecisions , and am considering this problem. If I make a video I'll credit anyone who offers helpful answers.","The problem A frog makes jumps, each exactly meter long. The directions of the jumps are chosen independently at random. What is the probability that the frog's final position is no more than meter from its starting position? Background This problem comes from the AMC in the year . The contest is an invitational test in the US for secondary school to qualify for the Olympiad. It involves questions in minutes and problems can be solved without calculus. I didn't get very far in my attempt, so I ultimately searched and found contributed solutions on the Art of Problem Solving . I don't understand ""solution "" and I am pretty sure ""solution "" is incorrect. Possible solution : random additions/subtractions Let , , and be complex numbers of magnitude one and let the frog start on the origin. Consider the 4 equally likely options of adding or subtracting and The AoPS solution states ""it is relatively easy"" to show exactly of these has magnitude or less. If so, then out of possible options, there would be with magnitude or less, so the probability would be (the corrrect answer is indeed , but this method does not satisfy me yet). I did not understand this step, and someone asked the same question in a previous thread . It's not obvious to me, and I have no clue how you would go about showing this. Is there an inequality that will help? I don't see how to simplify it. Also the official solution is much more complicated (see sketch below), which makes me think this solution is either elegant and overlooked or it is coincidentally the correct number but not the correct method. (Upon further thought, it seems would be a counter-example as so both are within 1.) Possible solution 2: geometric probability The solution goes like this. Suppose the first jump is from the origin. So to be unit from the starting point, you need to be in the unit circle. The next two jumps can be units after the first jump, equally likely to be in any angle. So the sample space of ending points is a circle of radius centered at the point of the first jump. This circle is also tangent to the unit circle. Thus the sample space has an area of , of which the area of the unit circle is . Hence the probability is . I am pretty sure this method is incorrect because I simulated jumps numerically. You do get a circle of , but not all points are equally likely. There is clustering to the center of the circle and the circumference of the circle. Plus if this method was true, it would seem that jumps should be a circle of radius , but that would imply a totally different answer of . The official solution I found a pdf on the following website, see problem : http://web2.slc.qc.ca/sh/Contest/AMC12_2010B-S.pdf Let me try to summarize the method... The idea is to set coordinates so the first jump is and the second jump is . Let the starting point be and then the location after the third jump is . It is not too hard to work out the condition for the third point to be within unit of the first point. Ignoring the measure cases of and , we need . We can limit to since the other half works out the same by symmetry. And we have . (Check out this interactive graph on Desmos to see why : https://www.desmos.com/calculator/egwegf8utr ) Considering a rectangle where all angles are equally likely, the sample space is the rectangle of area . The event to be within 1 is a triangle with area , so the desired probability is . Are the AoPS solutions incomplete? I would love if their ""solution "" is correct as it's much easier to compute and it be more reasonable for an average time allotment of minutes/problem. (Honestly you could give me unlimited time and I'm not sure I would have produced the official solution.) What do you guys think? Disclosure I run the YouTube channel MindYourDecisions , and am considering this problem. If I make a video I'll credit anyone who offers helpful answers.","3 1 1 12 2010 25 75 1 2 1 a b c b c  {|a+b+c|,|a+b-c|,|a-b+c|,|a-b-c|}  1 1 4 1 1 1/4 1/4 a = (1, 0), b = (0, 1), c = (-1, 0) |a + b + c| = 1 = |a - b + c| 1 2 2 4\pi \pi 1/4 2 2 3 3 1/9 18 (0, 0) (1, 0) (\cos \alpha, \sin \alpha) (1 + \cos \beta, \sin \beta) 1 0 \alpha = 0 \alpha = \pi \alpha \leq \beta \leq \pi 0 \leq \alpha \leq \pi 0 \leq \beta \leq 2\pi \alpha \leq \beta \leq \pi (\alpha, \beta) 2\pi \pi/2 1/4 1 3","['probability', 'contest-math']"
20,Black and white shirts puzzle,Black and white shirts puzzle,,"I’m not familiar enough with probability to be able to even begin to approach this myself, but this puzzle has been plaguing me. Assume I have $m$ black shirts and $n$ white shirts, where $m > n$ . Black shirts have durability $d \ge 0$ , and white shirts have durability $u \ge 0$ . (Feel free to pick better variable names) Every day, I pick out a random shirt to wear. Once I run out of either color of shirt, I wash all my dirty shirts of both colors and start over. Clean shirts do not get washed. Whenever a shirt gets washed, its durability goes down by one. Immediately after washing, if the durability of a shirt goes below 0, it must be thrown out. What is the probability on day $x$ that I throw out the last of one color of shirt, having at least one of the other color still available? Or more casually, after how many days is it likely (for some likelihood) that I have thrown out the last of one color of shirt? What is the probability that I throw out all my white shirts before all my black shirts?","I’m not familiar enough with probability to be able to even begin to approach this myself, but this puzzle has been plaguing me. Assume I have black shirts and white shirts, where . Black shirts have durability , and white shirts have durability . (Feel free to pick better variable names) Every day, I pick out a random shirt to wear. Once I run out of either color of shirt, I wash all my dirty shirts of both colors and start over. Clean shirts do not get washed. Whenever a shirt gets washed, its durability goes down by one. Immediately after washing, if the durability of a shirt goes below 0, it must be thrown out. What is the probability on day that I throw out the last of one color of shirt, having at least one of the other color still available? Or more casually, after how many days is it likely (for some likelihood) that I have thrown out the last of one color of shirt? What is the probability that I throw out all my white shirts before all my black shirts?",m n m > n d \ge 0 u \ge 0 x,"['probability', 'puzzle']"
21,Confusing probability question,Confusing probability question,,"I have got a task, which seems a quite confusing for me. It is simple: In a market, they sell eggs in egg holders, they store $10$ of them in each. There is $60$% chance, that all of the eggs are ok, $30$% chance, that exactly $1$ of them is broken, and $10$% chance, that exactly $2$ of them are broken(it is random, which one is broken). We buy an egg holder, and after we grab our first egg, we are sad, because it is broken. What is the probability, that there is one more broken egg in our holder? The ""logical"" way would be: $30$% of them have $1$ broken egg, $10$% of them have $2$, so, to have $2$ broken, the chance must be $\frac14$. But I am not really sure if that is the correct approach, since the broken egg can be anywhere, getting a broken one for first may be not that easy, or is that independent?(Maybe, I could use Bayes Theorem somehow)? Any help appreciated.","I have got a task, which seems a quite confusing for me. It is simple: In a market, they sell eggs in egg holders, they store $10$ of them in each. There is $60$% chance, that all of the eggs are ok, $30$% chance, that exactly $1$ of them is broken, and $10$% chance, that exactly $2$ of them are broken(it is random, which one is broken). We buy an egg holder, and after we grab our first egg, we are sad, because it is broken. What is the probability, that there is one more broken egg in our holder? The ""logical"" way would be: $30$% of them have $1$ broken egg, $10$% of them have $2$, so, to have $2$ broken, the chance must be $\frac14$. But I am not really sure if that is the correct approach, since the broken egg can be anywhere, getting a broken one for first may be not that easy, or is that independent?(Maybe, I could use Bayes Theorem somehow)? Any help appreciated.",,"['probability', 'statistics', 'bayes-theorem']"
22,Why is there a preference to use the cumulative distribution function to characterise a random variable instead of the probability density function?,Why is there a preference to use the cumulative distribution function to characterise a random variable instead of the probability density function?,,"Perhaps this is but a subtlety but I've noticed that in quite a few definitions in statistics and probability, definitions regarding the distribution of a variable or a sample of data choose to use the cumulative distribution function to characterise random variables as following a specific distribution as opposed to using the probability density function. E.g with the Kolmogorov Smirnov test, we look at the difference between cdfs and not pdfs. Is there a specific reason for this ?","Perhaps this is but a subtlety but I've noticed that in quite a few definitions in statistics and probability, definitions regarding the distribution of a variable or a sample of data choose to use the cumulative distribution function to characterise random variables as following a specific distribution as opposed to using the probability density function. E.g with the Kolmogorov Smirnov test, we look at the difference between cdfs and not pdfs. Is there a specific reason for this ?",,"['probability', 'statistics', 'probability-distributions']"
23,What is the expected value of the largest of the three dice rolls?,What is the expected value of the largest of the three dice rolls?,,"You toss a fair die three times. What is the expected value of the largest of the three outcomes? My approach is the following: calculate the probability of outcome when $\max=6$, which is $$P(\text{at least one $6$ of the three rolls}) = 1 - P(\text{no }6) = 1 - (5/6)^3$$ and then calculate the probability of outcome when $\max=5$, which is $$P(\text{at least one $5$ of the three rolls & $5$ is max}) = 1 - P(\text{no $5$ & $5$ is max}) = 1 - (4/6)^3.$$ I wonder if this approach is right.","You toss a fair die three times. What is the expected value of the largest of the three outcomes? My approach is the following: calculate the probability of outcome when $\max=6$, which is $$P(\text{at least one $6$ of the three rolls}) = 1 - P(\text{no }6) = 1 - (5/6)^3$$ and then calculate the probability of outcome when $\max=5$, which is $$P(\text{at least one $5$ of the three rolls & $5$ is max}) = 1 - P(\text{no $5$ & $5$ is max}) = 1 - (4/6)^3.$$ I wonder if this approach is right.",,['probability']
24,What is $\operatorname{Var}(X - Y)$?,What is ?,\operatorname{Var}(X - Y),"I am working on a problem from probability theory and am a little bit stuck. I know that the formula for $\operatorname{Var}(X + Y)$ is $$\operatorname{Var}(X) + \operatorname{Var}(Y) + 2\operatorname{Cov}(X,Y)$$ Does this mean that for $\operatorname{Var}(X - Y)$ it is just: $$\operatorname{Var}(X) - \operatorname{Var}(Y) - 2\operatorname{Cov}(X,Y)$$ ?",I am working on a problem from probability theory and am a little bit stuck. I know that the formula for is Does this mean that for it is just: ?,"\operatorname{Var}(X + Y) \operatorname{Var}(X) + \operatorname{Var}(Y) + 2\operatorname{Cov}(X,Y) \operatorname{Var}(X - Y) \operatorname{Var}(X) - \operatorname{Var}(Y) - 2\operatorname{Cov}(X,Y)","['probability', 'probability-theory']"
25,Probability of $5$ fair coin flips having strictly more heads than $4$ fair coin flips,Probability of  fair coin flips having strictly more heads than  fair coin flips,5 4,"Person A has 5 fair coins and Person B has 4 fair coins. Person A wins   only if he flips more heads than B does. What is the probability of A   winning? When I initially thought about the problem, I thought of it as if both had 4 coins, then they would on average get the same number of heads. If Person A had one more coin, then it would be a 50/50 shot for Person A to have more each time. But the more I think about this, its making less sense to me as an explanation, or at least it is incomplete. Logically as I think about it if you have 2 people with the same amount of coins, they both have the same chance of winning, although that percent is less than 50 for each person because of the chance of them tying. When you give a person an extra coin, that reduces the probability of tying by half (one half is tie when the guy flips tails with his extra and the other half is when the guy flips and gets heads and get an extra point). I'm not sure how to justify the thought that the original percentage of winning + the extra gain from the tie scenarios given by the extra coin = 50%. I guess I'm just looking for any tips on how to think about this problem so I can more fully understand it. Thanks","Person A has 5 fair coins and Person B has 4 fair coins. Person A wins   only if he flips more heads than B does. What is the probability of A   winning? When I initially thought about the problem, I thought of it as if both had 4 coins, then they would on average get the same number of heads. If Person A had one more coin, then it would be a 50/50 shot for Person A to have more each time. But the more I think about this, its making less sense to me as an explanation, or at least it is incomplete. Logically as I think about it if you have 2 people with the same amount of coins, they both have the same chance of winning, although that percent is less than 50 for each person because of the chance of them tying. When you give a person an extra coin, that reduces the probability of tying by half (one half is tie when the guy flips tails with his extra and the other half is when the guy flips and gets heads and get an extra point). I'm not sure how to justify the thought that the original percentage of winning + the extra gain from the tie scenarios given by the extra coin = 50%. I guess I'm just looking for any tips on how to think about this problem so I can more fully understand it. Thanks",,"['probability', 'recreational-mathematics']"
26,How to perform a fair coin toss experiment over phone?,How to perform a fair coin toss experiment over phone?,,"I was recently asked this question by my friend. Suppose the two individuals participating in a toss are not near each other, but could communicate over a telephone. How does one construct a fair coin toss experiment that is mutually agreeable to both of them? They can't agree on a function of quantities like the time or the telephone number, as these decide the winner a priori (before the experiment is conducted). I suggested they disconnect the call and try again; whoever manages to reach the other first is the winner. But the state machine involved here is a bit complicated to get the simple (0.5,0.5) probabilities. PS: They do not trust each other, so one of them can't toss a fair coin and convey its outcome to the other. Both of them throwing simultaneously also doesn't work, as the second person has the incentive to lie when they are communicating the results to each other.","I was recently asked this question by my friend. Suppose the two individuals participating in a toss are not near each other, but could communicate over a telephone. How does one construct a fair coin toss experiment that is mutually agreeable to both of them? They can't agree on a function of quantities like the time or the telephone number, as these decide the winner a priori (before the experiment is conducted). I suggested they disconnect the call and try again; whoever manages to reach the other first is the winner. But the state machine involved here is a bit complicated to get the simple (0.5,0.5) probabilities. PS: They do not trust each other, so one of them can't toss a fair coin and convey its outcome to the other. Both of them throwing simultaneously also doesn't work, as the second person has the incentive to lie when they are communicating the results to each other.",,"['probability', 'puzzle']"
27,"A standard 6-sided fair die is rolled until the last 3 rolls are strictly ascending. What is probability that the first such roll is a 1,2,3, or 4?","A standard 6-sided fair die is rolled until the last 3 rolls are strictly ascending. What is probability that the first such roll is a 1,2,3, or 4?",,"A standard $6$ -sided fair die is rolled until the last $3$ rolls are strictly ascending. What is probability that the first such roll is a $1$ , $2$ , $3$ , or $4$ ? My attempt We can investigate the $3-$ roll (when there are exactly $3$ rolls), the $4-$ roll, the $5-$ roll, the $n-$ roll. I did that via SQL, basically n times a cartesian product of a table with digits $1-6$ , with some constraints in place. There are $20$ ascending triplets that can be thrown. Starting with $1: 123, 124, 125, 126, 134, 135, 136, 145, 146, 156$ I call those triplets $T_1$ . There are $10$ $T_1$ ‘s. Likewise $T_2$ : $234, 235, 236, 245, 246, 256$ . There are 6 $T_2$ ’s. $T_3$ : $345, 346, 356$ . There are $3$ $T_3$ 's. $T_4: 456$ . There is only one $T_4$ . We can start with the $3-$ roll: The probability of a $3-$ roll is $\frac{20}{216}=\frac{5}{54}$ . Each triplet has the same probability of being rolled. So the probability of each triplet is $\frac{1}{20}$ . The $4-$ roll. Not any digit can be the first digit. For instance ' $456$ ' can't be prepended by ' $1$ ' or ' $2$ ' or ' $3$ ', as that would have resulted in a $3-$ roll. If we break it down we have $6$ digits before a $T_1$ , $5$ digits before a $T_2$ , $4$ digits before a $T_4$ . In total $6*20+5*6+4*3+3*1=105$ quartets. Of those $6$ belong to a specific $T_1$ , $5$ to a specific $T_2$ , $4$ to a specific $T_3$ , $3$ to a specific $T_4$ . The probabilities of a specific $T_1$ is $\frac{6}{105}; T_2: \frac{5}{105}; T_3:\frac{4}{105}, T_4: \frac{3}{105}$ . The probability of a $4 -$ roll happening is $ \frac{105}{6^4}=\frac{35}{432}$ For the $5-$ roll we can prepend any digit, so there will be 6*105 quintets and $6*6^4$ total ways, so the probability is still $\frac{6.105}{6.6^4}=\frac{105}{6^4}=\frac{35}{432}$ . The probabilities of a specific $T_1$ is $\frac{6.6}{6.105}=\frac{6}{20}$ ; $T_2$ : $\frac{6.5}{6*105}=\frac{5}{105}$ ; $T_3$ : $\frac{6.4}{6*105}=\frac{4}{105}$ , $T_4$ : $\frac{6.3}{6.105}=\frac{3}{105}$ . All probabilities are the same compared the $4-$ roll. Now look at the $6-$ roll. Like with the $4-$ roll not all digits can be prepended. An sql query tells me there are $3381$ ways to have an 6-roll and that makes the probability $\frac{3381}{6^6}=\frac{1127}{15552}$ .  To tie them into the T-groups I've reworked the formula's from the $5-$ roll to $6-\frac{\frac{20}{36}}{\frac{2217}{12}}$ for a $T_1$ ; $5-\frac{\frac{20}{36}}{\frac{2217}{12}}$ for a $T_2$ ; $4-\frac{\frac{20}{36}}{\frac{2217}{12}}$ for a $T_3$ ; $3-\frac{\frac{19}{36}}{\frac{2217}{12}}$ for a $T_4$ . This is all matching up. The formula's, just as the sql yield, $1960$ $T_1$ 's, $960$ $T_2$ 's, $372$ $T_3$ 's, $89$ $T_4$ 's$. Now the $7-$ roll, and this is where I get stuck. I assumed/hoped we could still use the formulas from the $6-$ roll, and I assumed they could be used for the $nth-$ roll, where $N>6$ . But in the $7-$ roll up to the $10-$ roll (the $10-$ roll is the last one I checked), the T-groups are not 'hit' by the invalid paths proportionally. Although there's only a slight deviation, this means we can't use the formula's from the $6-$ roll, and we can't get a precise answer on our question. So this whole approach seems flawed. Is there another way or a better approach, is what I'd like to know.","A standard -sided fair die is rolled until the last rolls are strictly ascending. What is probability that the first such roll is a , , , or ? My attempt We can investigate the roll (when there are exactly rolls), the roll, the roll, the roll. I did that via SQL, basically n times a cartesian product of a table with digits , with some constraints in place. There are ascending triplets that can be thrown. Starting with I call those triplets . There are ‘s. Likewise : . There are 6 ’s. : . There are 's. . There is only one . We can start with the roll: The probability of a roll is . Each triplet has the same probability of being rolled. So the probability of each triplet is . The roll. Not any digit can be the first digit. For instance ' ' can't be prepended by ' ' or ' ' or ' ', as that would have resulted in a roll. If we break it down we have digits before a , digits before a , digits before a . In total quartets. Of those belong to a specific , to a specific , to a specific , to a specific . The probabilities of a specific is . The probability of a roll happening is For the roll we can prepend any digit, so there will be 6*105 quintets and total ways, so the probability is still . The probabilities of a specific is ; : ; : , : . All probabilities are the same compared the roll. Now look at the roll. Like with the roll not all digits can be prepended. An sql query tells me there are ways to have an 6-roll and that makes the probability .  To tie them into the T-groups I've reworked the formula's from the roll to for a ; for a ; for a ; for a . This is all matching up. The formula's, just as the sql yield, 's, 's, 's, 's$. Now the roll, and this is where I get stuck. I assumed/hoped we could still use the formulas from the roll, and I assumed they could be used for the roll, where . But in the roll up to the roll (the roll is the last one I checked), the T-groups are not 'hit' by the invalid paths proportionally. Although there's only a slight deviation, this means we can't use the formula's from the roll, and we can't get a precise answer on our question. So this whole approach seems flawed. Is there another way or a better approach, is what I'd like to know.","6 3 1 2 3 4 3- 3 4- 5- n- 1-6 20 1: 123, 124, 125, 126, 134, 135, 136, 145, 146, 156 T_1 10 T_1 T_2 234, 235, 236, 245, 246, 256 T_2 T_3 345, 346, 356 3 T_3 T_4: 456 T_4 3- 3- \frac{20}{216}=\frac{5}{54} \frac{1}{20} 4- 456 1 2 3 3- 6 T_1 5 T_2 4 T_4 6*20+5*6+4*3+3*1=105 6 T_1 5 T_2 4 T_3 3 T_4 T_1 \frac{6}{105}; T_2: \frac{5}{105}; T_3:\frac{4}{105}, T_4: \frac{3}{105} 4 -  \frac{105}{6^4}=\frac{35}{432} 5- 6*6^4 \frac{6.105}{6.6^4}=\frac{105}{6^4}=\frac{35}{432} T_1 \frac{6.6}{6.105}=\frac{6}{20} T_2 \frac{6.5}{6*105}=\frac{5}{105} T_3 \frac{6.4}{6*105}=\frac{4}{105} T_4 \frac{6.3}{6.105}=\frac{3}{105} 4- 6- 4- 3381 \frac{3381}{6^6}=\frac{1127}{15552} 5- 6-\frac{\frac{20}{36}}{\frac{2217}{12}} T_1 5-\frac{\frac{20}{36}}{\frac{2217}{12}} T_2 4-\frac{\frac{20}{36}}{\frac{2217}{12}} T_3 3-\frac{\frac{19}{36}}{\frac{2217}{12}} T_4 1960 T_1 960 T_2 372 T_3 89 T_4 7- 6- nth- N>6 7- 10- 10- 6-","['probability', 'dice']"
28,Example for finitely additive but not countably additive probability measure,Example for finitely additive but not countably additive probability measure,,"A probability measure defined on a sample space $\Omega$ has the following properties: For each $E \subset \Omega$, $0 \le P(E) \le 1$ $P(\Omega) = 1$ If $E_1$ and $E_2$ are disjoint subsets $P(E_1 \cup E_2) = P(E_1) + P(E_2)$ The above definition defines a measure that is finitely additive (by induction) but not necessarily countably additive. What is a probability measure that would be finitely additive but not countably additive (for a countable sample space  $\Omega$)? The example that I have seen most commonly on forums (this and elsewhere) is to set $P(E) = 0$ if $E$ is finite and $P(E) = 1$ if $E$ is co-finite. But that is not a probability measure as defined above since it is not defined on every subset of $\Omega$. So an example of such a probability measure, or what is the reasoning that a finitely additive probability measure is not always countably additive?","A probability measure defined on a sample space $\Omega$ has the following properties: For each $E \subset \Omega$, $0 \le P(E) \le 1$ $P(\Omega) = 1$ If $E_1$ and $E_2$ are disjoint subsets $P(E_1 \cup E_2) = P(E_1) + P(E_2)$ The above definition defines a measure that is finitely additive (by induction) but not necessarily countably additive. What is a probability measure that would be finitely additive but not countably additive (for a countable sample space  $\Omega$)? The example that I have seen most commonly on forums (this and elsewhere) is to set $P(E) = 0$ if $E$ is finite and $P(E) = 1$ if $E$ is co-finite. But that is not a probability measure as defined above since it is not defined on every subset of $\Omega$. So an example of such a probability measure, or what is the reasoning that a finitely additive probability measure is not always countably additive?",,"['probability', 'measure-theory', 'set-theory']"
29,Everything in the Power Set is measurable?,Everything in the Power Set is measurable?,,"Im taking a class in graduate probability. My background is in engineering (very used to math in an applied sense). I am also taking an undergraduate class in real analysis along side (should have taken it before, but I couldn't) I have a couple of questions: We're spending time looking at measurable functions on measurable sets. The definition of a ""measurable set"" is one who lies in a sigma algebra. My conceptual understanding of a sigma algebra (I  know the technical def: countable additivity, etc.) is the resolution with which we understand a certain space - the sets that can be measured - even more simply: the sets we can actually use .     We say a sigma algebra is the ""domain"" of our measure. In other words, a (prob) measure can't measure just any old arbitrary set/sets of set. We define a sigma algebra to handle this, and say our measure operates over this sigma algebra. However, the power set is actually  a sigma algebra (the largest one, according to our definition), and yet not every element of the power set is measurable? I'm having a little trouble reconciling my conceptual understanding of a sigma algebra (the behave good-measurable sets) with its actual def (which  gives us the power set dilemma). How does the Borel Sigma Algebra fit into this conceptual understanding? How about non measurable sets? Is there a concept of the largest sigma algebra of only measurable sets, which is a subset of the power set?","Im taking a class in graduate probability. My background is in engineering (very used to math in an applied sense). I am also taking an undergraduate class in real analysis along side (should have taken it before, but I couldn't) I have a couple of questions: We're spending time looking at measurable functions on measurable sets. The definition of a ""measurable set"" is one who lies in a sigma algebra. My conceptual understanding of a sigma algebra (I  know the technical def: countable additivity, etc.) is the resolution with which we understand a certain space - the sets that can be measured - even more simply: the sets we can actually use .     We say a sigma algebra is the ""domain"" of our measure. In other words, a (prob) measure can't measure just any old arbitrary set/sets of set. We define a sigma algebra to handle this, and say our measure operates over this sigma algebra. However, the power set is actually  a sigma algebra (the largest one, according to our definition), and yet not every element of the power set is measurable? I'm having a little trouble reconciling my conceptual understanding of a sigma algebra (the behave good-measurable sets) with its actual def (which  gives us the power set dilemma). How does the Borel Sigma Algebra fit into this conceptual understanding? How about non measurable sets? Is there a concept of the largest sigma algebra of only measurable sets, which is a subset of the power set?",,"['probability', 'measure-theory']"
30,"probability distribution of coverage of a set after $X$ independently, randomly selected members of the set","probability distribution of coverage of a set after  independently, randomly selected members of the set",X,"I have a set of numbers where I am randomly and independently selecting elements within a set .  After a number of these random element selections I want to know the coverage of the elements in the set. Coverage being how many elements from the set have been selected at least once divided by the total number of elements in the set. To restate this: what is the probability distribution of the different coverage values on a set after $X$ randomly, independently selected elements of the set?","I have a set of numbers where I am randomly and independently selecting elements within a set .  After a number of these random element selections I want to know the coverage of the elements in the set. Coverage being how many elements from the set have been selected at least once divided by the total number of elements in the set. To restate this: what is the probability distribution of the different coverage values on a set after $X$ randomly, independently selected elements of the set?",,"['probability', 'statistics', 'probability-distributions']"
31,"Definition of the total variation distance: $ V(P,Q) = \frac{1}{2} \int |p-q|d\nu$?",Definition of the total variation distance: ?," V(P,Q) = \frac{1}{2} \int |p-q|d\nu","let $P,Q$ be two probability measures on $(\Omega, \mathscr {F})$, and let $\nu$ be a $\sigma$-finite measure on the same event space such that $P \ll v, Q \ll v$. Define $\frac{dP}{dv}=p$, $\frac{dQ}{dv}=q$. The total variation distance between P and Q is then: $$ V(P,Q) = \sup_{A \in \mathscr{F}}|P(A) - Q(A)|= \sup_A \bigg| \int_A(p-q )d\nu \bigg|  $$ I'm confused about the following, we may write: $$ V(P,Q) = \frac{1}{2} \int |p-q|d\nu $$ First, how can we bring the absolute value inside the integral and get rid of the supremum, and second, what region are we integrating over now? This statement is made frequently in the book: Introduction to nonparametric Estimation - Tsybakov","let $P,Q$ be two probability measures on $(\Omega, \mathscr {F})$, and let $\nu$ be a $\sigma$-finite measure on the same event space such that $P \ll v, Q \ll v$. Define $\frac{dP}{dv}=p$, $\frac{dQ}{dv}=q$. The total variation distance between P and Q is then: $$ V(P,Q) = \sup_{A \in \mathscr{F}}|P(A) - Q(A)|= \sup_A \bigg| \int_A(p-q )d\nu \bigg|  $$ I'm confused about the following, we may write: $$ V(P,Q) = \frac{1}{2} \int |p-q|d\nu $$ First, how can we bring the absolute value inside the integral and get rid of the supremum, and second, what region are we integrating over now? This statement is made frequently in the book: Introduction to nonparametric Estimation - Tsybakov",,"['probability', 'probability-theory', 'measure-theory']"
32,What's the General Expression For Probability of a Failed Gift Exchange Draw,What's the General Expression For Probability of a Failed Gift Exchange Draw,,"My family does a gift exchange every year at Christmas. There are five couples and we draw names from a hat. If a person draws their own name, or the name of their spouse, all the names go back in a hat and we re-draw names. This happens maybe 7 times out of 8. Using a computer, I know that the probability of this happening is 1 - (440192 / 10!) or about 88%. (It's been too long since I took combinatorics) What's a general expression for n couples? Edit Oct 19, 2011: I was so impressed with the answer, I wrote a blog post about it: http://michaeljswart.com/2011/10/secret-santa-as-a-puzzle/","My family does a gift exchange every year at Christmas. There are five couples and we draw names from a hat. If a person draws their own name, or the name of their spouse, all the names go back in a hat and we re-draw names. This happens maybe 7 times out of 8. Using a computer, I know that the probability of this happening is 1 - (440192 / 10!) or about 88%. (It's been too long since I took combinatorics) What's a general expression for n couples? Edit Oct 19, 2011: I was so impressed with the answer, I wrote a blog post about it: http://michaeljswart.com/2011/10/secret-santa-as-a-puzzle/",,"['probability', 'combinatorics', 'derangements']"
33,Stars in the universe - probability of mutual nearest neighbors,Stars in the universe - probability of mutual nearest neighbors,,"If the stars are distributed randomly within the universe, what is the probability for a star to be the nearest neighbor of a star that is its nearest neighbor? What if the number of spatial dimensions is higher than 3 or even grows without limit? PS. I am interested in the asymptotic behavior with the number of stars growing without bound. PPS. It's a well-known problem (the ""birds on a wire problem"" in higher dimensions) and I know the answers. However, no idea how to solve this analytically.","If the stars are distributed randomly within the universe, what is the probability for a star to be the nearest neighbor of a star that is its nearest neighbor? What if the number of spatial dimensions is higher than 3 or even grows without limit? PS. I am interested in the asymptotic behavior with the number of stars growing without bound. PPS. It's a well-known problem (the ""birds on a wire problem"" in higher dimensions) and I know the answers. However, no idea how to solve this analytically.",,['probability']
34,What is the probability of this exact same Champions League draw?,What is the probability of this exact same Champions League draw?,,"As you can see here , there has been a strange coincidence with the UEFA Champions League draw. The real draw which took place today, ended up being exactly the same as the rehearsal draw which took place yesterday. Considering the following rules, what is the probability of this? Group stage winners: Group A - Paris St. Germain (FRA) Group B - Schalke 04 (GER) Group C - Malaga (ESP) Group D - Borussia Dortmund (GER) Group E - Juventus (ITA) Group F - Bayern Munich (GER) Group G - Barcelona (ESP) Group H - Manchester United (ENG) Group stage runner-ups: Group A - Porto (POR) Group B - Arsenal (ENG) Group C - AC Milan (ITA) Group D - Real Madrid (ESP) Group E - Shakhtar Donetsk (UKR) Group F - Valencia (ESP) Group G - Celtic (SCO) Group H - Galatasaray (TUR) Winners from the group stage were seeded but they could not be drawn against a team who they played in the group stage, or another team from their association.","As you can see here , there has been a strange coincidence with the UEFA Champions League draw. The real draw which took place today, ended up being exactly the same as the rehearsal draw which took place yesterday. Considering the following rules, what is the probability of this? Group stage winners: Group A - Paris St. Germain (FRA) Group B - Schalke 04 (GER) Group C - Malaga (ESP) Group D - Borussia Dortmund (GER) Group E - Juventus (ITA) Group F - Bayern Munich (GER) Group G - Barcelona (ESP) Group H - Manchester United (ENG) Group stage runner-ups: Group A - Porto (POR) Group B - Arsenal (ENG) Group C - AC Milan (ITA) Group D - Real Madrid (ESP) Group E - Shakhtar Donetsk (UKR) Group F - Valencia (ESP) Group G - Celtic (SCO) Group H - Galatasaray (TUR) Winners from the group stage were seeded but they could not be drawn against a team who they played in the group stage, or another team from their association.",,"['probability', 'combinatorics']"
35,Fubini's theorem for conditional expectations,Fubini's theorem for conditional expectations,,"I need to prove that if $E \int_a^b |X_u|\,du = \int_a^b E|X_u|\,du$ is finite then: $$E\left[\left.\int_a^b X_u\,du \;\right|\; \mathcal{G}\right] = \int_a^b E[X_u \mid \mathcal{G}]\,du.$$ I just dont have any idea how to approach this problem.","I need to prove that if $E \int_a^b |X_u|\,du = \int_a^b E|X_u|\,du$ is finite then: $$E\left[\left.\int_a^b X_u\,du \;\right|\; \mathcal{G}\right] = \int_a^b E[X_u \mid \mathcal{G}]\,du.$$ I just dont have any idea how to approach this problem.",,"['probability', 'probability-theory', 'stochastic-processes', 'conditional-expectation']"
36,Proof of analogue of the Cauchy-Schwarz inequality for random variables,Proof of analogue of the Cauchy-Schwarz inequality for random variables,,"The Cauchy-Schwarz inequality tells us that for two vectors $u$ and $v$ in an inner product space, $$\lvert (u,v)\rvert \leq \lVert u\rVert \lVert v \rVert$$ with the equality holding iff one vector is a constant multiplier of the other. Prove the analogue of the Cauchy-Schwarz inequality for random variables: $$\lvert E[XY]\rvert \leq \sqrt{E[X^2]} \sqrt{E[Y^2]}$$ (Hint: Use the fact that $E[ (\alpha X + Y)^2 ] \geq 0$ for all real (constants) $\alpha$)","The Cauchy-Schwarz inequality tells us that for two vectors $u$ and $v$ in an inner product space, $$\lvert (u,v)\rvert \leq \lVert u\rVert \lVert v \rVert$$ with the equality holding iff one vector is a constant multiplier of the other. Prove the analogue of the Cauchy-Schwarz inequality for random variables: $$\lvert E[XY]\rvert \leq \sqrt{E[X^2]} \sqrt{E[Y^2]}$$ (Hint: Use the fact that $E[ (\alpha X + Y)^2 ] \geq 0$ for all real (constants) $\alpha$)",,"['probability', 'inequality', 'random-variables']"
37,Probability of a random binary string containing a long run of 1s?,Probability of a random binary string containing a long run of 1s?,,"For some fixed $n$, let $p_n$ be the probability that a random infinite binary string contains a run of consecutive $1$s, containing $n$ more $1$s than the total number appearing before the run. For example, if $n=2$, the binary string $010010111100...$ is of the sort we're looking for, but the string $01001011100...$ is not (yet). Call a run of $1$s that is sufficiently long, like the four $1$s in the first string, a satisfying run . Is there any reasonably nice way to compute $p_n$? Here's what I know: We can compute the expected number of satisfying runs in a string. Suppose a satisfying run begins after $k$ preliminary bits. If $k=0$, this occurs with probability $2^{-n}$; otherwise, it occurs with probability $\sum_{i=0}^{k-1} {k-1 \choose i} 2^{-n-k-i}=2^{-n-k}\left(\frac{3}{2}\right)^k$. Summing over all $k$, we get that the expected number of satisfying runs is $3(2^{-n})$, and so $p_n<3(2^{-n})$. You could extend this argument to compute $p_n$ by inclusion-exclusion, but it looks to me like it'd be incredibly ugly. In fact, $3(2^{-n})$ is a pretty good estimate for $p_n$, since the probability of a given string having multiple satisfying runs is so low. By conditioning on the location of the first $0$ in the string, we can get a recurrence relation: $p_n=2^{-n+1}+\sum_{i=1}^{n-1} 2^{-i+1}p_{n+i}$. This is not sufficient to compute $p_n$ on its own, even given some initial values -- the largest index that appears in it is $p_{2n-1}$, so if you try to use it recursively you'll never learn anything about $p_n$ for $n$ even. You might be able to get something out of it by repeatedly substituting it into itself (in the form I've given it in, with the smallest coefficient singled out), and using the bound from 1. to make some kind of limit argument, but this also looks nasty to me. Thoughts? (This originally comes from this Magic: the Gathering scenario, but I hope I've managed to successfully de- Magic it.)","For some fixed $n$, let $p_n$ be the probability that a random infinite binary string contains a run of consecutive $1$s, containing $n$ more $1$s than the total number appearing before the run. For example, if $n=2$, the binary string $010010111100...$ is of the sort we're looking for, but the string $01001011100...$ is not (yet). Call a run of $1$s that is sufficiently long, like the four $1$s in the first string, a satisfying run . Is there any reasonably nice way to compute $p_n$? Here's what I know: We can compute the expected number of satisfying runs in a string. Suppose a satisfying run begins after $k$ preliminary bits. If $k=0$, this occurs with probability $2^{-n}$; otherwise, it occurs with probability $\sum_{i=0}^{k-1} {k-1 \choose i} 2^{-n-k-i}=2^{-n-k}\left(\frac{3}{2}\right)^k$. Summing over all $k$, we get that the expected number of satisfying runs is $3(2^{-n})$, and so $p_n<3(2^{-n})$. You could extend this argument to compute $p_n$ by inclusion-exclusion, but it looks to me like it'd be incredibly ugly. In fact, $3(2^{-n})$ is a pretty good estimate for $p_n$, since the probability of a given string having multiple satisfying runs is so low. By conditioning on the location of the first $0$ in the string, we can get a recurrence relation: $p_n=2^{-n+1}+\sum_{i=1}^{n-1} 2^{-i+1}p_{n+i}$. This is not sufficient to compute $p_n$ on its own, even given some initial values -- the largest index that appears in it is $p_{2n-1}$, so if you try to use it recursively you'll never learn anything about $p_n$ for $n$ even. You might be able to get something out of it by repeatedly substituting it into itself (in the form I've given it in, with the smallest coefficient singled out), and using the bound from 1. to make some kind of limit argument, but this also looks nasty to me. Thoughts? (This originally comes from this Magic: the Gathering scenario, but I hope I've managed to successfully de- Magic it.)",,"['probability', 'recurrence-relations']"
38,Interpretation of $\frac{22}{7}-\pi$,Interpretation of,\frac{22}{7}-\pi,"Integral and series proofs that $\frac{22}{7}>\pi$ We can prove that $\frac{22}{7}$ exceeds $\pi$ by using Dalzell integral $$\int_0^1 \frac{x^4(1-x)^4}{1+x^2}dx=\frac{22}{7}-\pi$$ or its equivalent series $$\sum_{k=1}^{\infty} \frac{240}{(4k+1)(4k+2)(4k+3)(4k+5)(4k+6)(4k+7)}=\frac{22}{7}-\pi$$ (see Series and integrals for inequalities and approximations to $\pi$ ) Equivalent expressions This series may be written in terms of factorials, binomial coefficients or Beta integrals as $$\begin{align} \frac{22}{7}-\pi &= 3840\sum_{k=1}^\infty \frac{(k+2)!(4k)!}{(4k+8)!k!} \\ &= \frac{4}{21} \sum_{k=1}^\infty \frac{{k+2 \choose 2}}{{4k+8\choose 8}} \\ &= \frac{16}{21} \sum_{k=1}^\infty \frac{B(4k+1,8)}{B(k+1,2)} \end{align} $$ (see A series to prove $\frac{22}{7}-\pi>0$ ) Can $\frac{22}{7}-\pi$ be given a combinatorial or probabilistic interpretation? Some situations where $\pi$ appears are Buffon's needle or the probability that two random integers are relatively prime . See also $\pi$ in random phenomena by Boris Gourévitch and Occorrenze in calcolo delle probabilità e statistica by Mauro Fiorentini.","Integral and series proofs that $\frac{22}{7}>\pi$ We can prove that $\frac{22}{7}$ exceeds $\pi$ by using Dalzell integral $$\int_0^1 \frac{x^4(1-x)^4}{1+x^2}dx=\frac{22}{7}-\pi$$ or its equivalent series $$\sum_{k=1}^{\infty} \frac{240}{(4k+1)(4k+2)(4k+3)(4k+5)(4k+6)(4k+7)}=\frac{22}{7}-\pi$$ (see Series and integrals for inequalities and approximations to $\pi$ ) Equivalent expressions This series may be written in terms of factorials, binomial coefficients or Beta integrals as $$\begin{align} \frac{22}{7}-\pi &= 3840\sum_{k=1}^\infty \frac{(k+2)!(4k)!}{(4k+8)!k!} \\ &= \frac{4}{21} \sum_{k=1}^\infty \frac{{k+2 \choose 2}}{{4k+8\choose 8}} \\ &= \frac{16}{21} \sum_{k=1}^\infty \frac{B(4k+1,8)}{B(k+1,2)} \end{align} $$ (see A series to prove $\frac{22}{7}-\pi>0$ ) Can $\frac{22}{7}-\pi$ be given a combinatorial or probabilistic interpretation? Some situations where $\pi$ appears are Buffon's needle or the probability that two random integers are relatively prime . See also $\pi$ in random phenomena by Boris Gourévitch and Occorrenze in calcolo delle probabilità e statistica by Mauro Fiorentini.",,"['probability', 'sequences-and-series', 'combinatorics', 'inequality', 'pi']"
39,3 other extensions of the Secretary Problem,3 other extensions of the Secretary Problem,,"In the classical secretary problem (also known as Marriage, Sultan's Dowry, Gogol problems), There are $n$ candidates ordered from the best to the worst (no ties).  We know $n$ . The candidates arrive sequentially in random order (uniform distribution). We can only determine the relative ranks as they arrive (and can not know the absolute ranks). We can either accept or reject a candidate. When a candidate is rejected she cannot be recalled. We want to choose the very best candidate and have to find the optimal strategy and its probability of success. There are a lot of extensions of this problem (for example: $n$ is not known, not uniform distribution for $k$ less than $n$ , to select the $k$ best candidates, etc.). Mike gave us very useful information about an extension (to select the $2,4,k$ best) in his answer to the "" Generalization of the Sultan's dowry problem "". In these 3 new extensions (with 1,2,3,4 as in the Classical Secretary problem) , we have to to find the optimal strategy and its probability of success if: Problem 1: We want to choose the very best OR the worst (only one selection). Problem 2: We want to choose the median candidate (only one selection). Problem 3: We want to choose the very best AND the worst  (two selections).","In the classical secretary problem (also known as Marriage, Sultan's Dowry, Gogol problems), There are candidates ordered from the best to the worst (no ties).  We know . The candidates arrive sequentially in random order (uniform distribution). We can only determine the relative ranks as they arrive (and can not know the absolute ranks). We can either accept or reject a candidate. When a candidate is rejected she cannot be recalled. We want to choose the very best candidate and have to find the optimal strategy and its probability of success. There are a lot of extensions of this problem (for example: is not known, not uniform distribution for less than , to select the best candidates, etc.). Mike gave us very useful information about an extension (to select the best) in his answer to the "" Generalization of the Sultan's dowry problem "". In these 3 new extensions (with 1,2,3,4 as in the Classical Secretary problem) , we have to to find the optimal strategy and its probability of success if: Problem 1: We want to choose the very best OR the worst (only one selection). Problem 2: We want to choose the median candidate (only one selection). Problem 3: We want to choose the very best AND the worst  (two selections).","n n n k n k 2,4,k",['probability']
40,Generalized nontransitive dice,Generalized nontransitive dice,,"Let $X_1, \ldots, X_n$ be a collection of random variables. Consider the directed graph with vertex set $\{ 1, 2, \ldots, n \}$ where there is a directed edge $i \to j$ if $\mathbb{P}(X_i > X_j) > \frac{1}{2}$. Question 1: What directed graphs can arise in this way? Certainly they must be simple and have no loops. Is that the only restriction? Alternatively, $\mathbb{P}(X_i > X_j) > \frac{1}{2}$ defines an irreflexive antisymmetric relation on $\{ 1, 2, ... n \}$. Which such relations arise in this way? Question 2: Does the answer change if we require the $X_i$ to all be defined on a finite sample space? Question 3: What if we require the $X_i$ to be independent? It is known (see nontransitive dice ) that this graph can have directed cycles even if the $X_i$ are independent; in particular, the corresponding relation need not be transitive.","Let $X_1, \ldots, X_n$ be a collection of random variables. Consider the directed graph with vertex set $\{ 1, 2, \ldots, n \}$ where there is a directed edge $i \to j$ if $\mathbb{P}(X_i > X_j) > \frac{1}{2}$. Question 1: What directed graphs can arise in this way? Certainly they must be simple and have no loops. Is that the only restriction? Alternatively, $\mathbb{P}(X_i > X_j) > \frac{1}{2}$ defines an irreflexive antisymmetric relation on $\{ 1, 2, ... n \}$. Which such relations arise in this way? Question 2: Does the answer change if we require the $X_i$ to all be defined on a finite sample space? Question 3: What if we require the $X_i$ to be independent? It is known (see nontransitive dice ) that this graph can have directed cycles even if the $X_i$ are independent; in particular, the corresponding relation need not be transitive.",,"['probability', 'graph-theory', 'dice', 'directed-graphs']"
41,Answered: With what probability do $4$ points placed uniformly randomly in the unit square of $\mathbb{R}^2$ form a convex/concave quadrilateral?,Answered: With what probability do  points placed uniformly randomly in the unit square of  form a convex/concave quadrilateral?,4 \mathbb{R}^2,"I have this problem that I've struggled with for a while. If you place $4$ points randomly into a unit square (uniform distribution in both $x$ and $y$), with what probability will this shape be convex if the $4$ points are connected in some order? Equivalently, with what probability will there be a point inside the triangle with the largest area with vertices at the other $3$ points. In particular I am interested in the answer for when this area of support is $\mathbb{R}^2$ and is uniform. I ran a simulation and found that on a unit square the answer is about $71\%$ concave. On a unit circle picking polar co-ordinates r and theta from uniform random distributions results in a a probability of concavity of $68\%$. When the distribution for r is altered so that each point in the circle is equally likely then this falls to $51\%$. Any advice or links for a possible answer or whether this is even possible would be appreciated. EDIT: It turns out this problem is the same as Sylvester's 4 point problem. Alas I am 150 years too late. Thanks to all who helped. Only one person gave an answer, not quite correct but I award the bounty to them anyway for their efforts.","I have this problem that I've struggled with for a while. If you place $4$ points randomly into a unit square (uniform distribution in both $x$ and $y$), with what probability will this shape be convex if the $4$ points are connected in some order? Equivalently, with what probability will there be a point inside the triangle with the largest area with vertices at the other $3$ points. In particular I am interested in the answer for when this area of support is $\mathbb{R}^2$ and is uniform. I ran a simulation and found that on a unit square the answer is about $71\%$ concave. On a unit circle picking polar co-ordinates r and theta from uniform random distributions results in a a probability of concavity of $68\%$. When the distribution for r is altered so that each point in the circle is equally likely then this falls to $51\%$. Any advice or links for a possible answer or whether this is even possible would be appreciated. EDIT: It turns out this problem is the same as Sylvester's 4 point problem. Alas I am 150 years too late. Thanks to all who helped. Only one person gave an answer, not quite correct but I award the bounty to them anyway for their efforts.",,"['probability', 'uniform-distribution']"
42,"The good, the bad and the ugly with conditional probability/expectation","The good, the bad and the ugly with conditional probability/expectation",,"I thought that I understand conditional probability and expectation until I saw this question: The problem for conditional expectation. Basically, it is given that: $$(X,Y)\sim f(x,y)=\begin{cases} 2xy &\text{ if $0<x<2y<2$} \\ 0 &\text{ otherwise } \end{cases}$$ And it is asked to find $E[Y|X=aY]$ Background: The good I understand Method 2, where one would write: $E[Y|X=aY]=E\left[Y|\frac{X}{Y}=a\right]=E[Y]=\frac{4}{5}$ $\frac{X}{Y}=a$ is dropped from expectation after proving that $Y$ and $\frac{X}{Y}$ are independent using the transformation $(X,Y)\to(X/Y,Y)$ I also (kind of) understand Method 1 in the answer, with conditioning on $Y$ (although my intuition tells me the result is correct only because $Y$ and $X/Y$ are independent): $$E[Y|X=aY]=\int_0^1E[Y|X=aY,Y=y]f_Y(y)\,dy=\int_0^1yf_Y(y)\,dy=E[Y]=\frac{4}{5}$$ But when I try my own intuitive approaches, I'm getting stuck. Question 1: The Bad I interpret the conditional pdf $f_{Y|X}(y|t)=Cf_{Y,X}(y,t)$ as sectioning the joint pdf surface with the plane $y=t$ and scaling the resulting curve to a pdf. My intuition tells me that the conditional pdf of $Y$ given $X=aY$ should similarly be found by sectioning the joint pdf with the plane $x=ay$ and scaling to a pdf. The pdf would be $Cf(ay,y)=Cay^2=3y^2, 0<y<1$ , and the conditional expectation: $E[Y|X=aY]=\int_0^13y^3\,dy=\frac{3}{4}$ What am I missing here? Question 2: The Ugly I'm trying now to do the same thing as in Method 1, but condition on $X$ rather than on $Y$ : $$E[Y|X=aY]=E[X/a|X=aY]=\frac{1}{a}E[X|X=aY]\\=\frac{1}{a}\int_0^aE[X|X=aY,X=x]f_X(x)\,dx=\frac{1}{a}\int_0^a xf_X(x)\,dx$$ Which is something very ugly depending on $a$ , instead of $4/5$ . Again, many thanks for anybody who could point out the mistakes in my thinking.","I thought that I understand conditional probability and expectation until I saw this question: The problem for conditional expectation. Basically, it is given that: And it is asked to find Background: The good I understand Method 2, where one would write: is dropped from expectation after proving that and are independent using the transformation I also (kind of) understand Method 1 in the answer, with conditioning on (although my intuition tells me the result is correct only because and are independent): But when I try my own intuitive approaches, I'm getting stuck. Question 1: The Bad I interpret the conditional pdf as sectioning the joint pdf surface with the plane and scaling the resulting curve to a pdf. My intuition tells me that the conditional pdf of given should similarly be found by sectioning the joint pdf with the plane and scaling to a pdf. The pdf would be , and the conditional expectation: What am I missing here? Question 2: The Ugly I'm trying now to do the same thing as in Method 1, but condition on rather than on : Which is something very ugly depending on , instead of . Again, many thanks for anybody who could point out the mistakes in my thinking.","(X,Y)\sim f(x,y)=\begin{cases}
2xy &\text{ if 0<x<2y<2} \\
0 &\text{ otherwise }
\end{cases} E[Y|X=aY] E[Y|X=aY]=E\left[Y|\frac{X}{Y}=a\right]=E[Y]=\frac{4}{5} \frac{X}{Y}=a Y \frac{X}{Y} (X,Y)\to(X/Y,Y) Y Y X/Y E[Y|X=aY]=\int_0^1E[Y|X=aY,Y=y]f_Y(y)\,dy=\int_0^1yf_Y(y)\,dy=E[Y]=\frac{4}{5} f_{Y|X}(y|t)=Cf_{Y,X}(y,t) y=t Y X=aY x=ay Cf(ay,y)=Cay^2=3y^2, 0<y<1 E[Y|X=aY]=\int_0^13y^3\,dy=\frac{3}{4} X Y E[Y|X=aY]=E[X/a|X=aY]=\frac{1}{a}E[X|X=aY]\\=\frac{1}{a}\int_0^aE[X|X=aY,X=x]f_X(x)\,dx=\frac{1}{a}\int_0^a xf_X(x)\,dx a 4/5","['probability', 'conditional-probability']"
43,Probability that a random pair of points are opposite corners of a square in an $n\times n$ integer lattice,Probability that a random pair of points are opposite corners of a square in an  integer lattice,n\times n,"Question: Find the probability that a random pair of lattice points are opposite corners of a square in an $n\times n$ integer lattice. Note: By a square in a lattice, I mean a square whose vertices are all lattice points. Motivation: I have a messy proof that the solution is $\frac13$. The proof relies on calculating the total number of squares in each $n\times n$ lattice, but I want to know if there is some neat argument which avoids that method. There's reason to think there might be since the result is independent of $n$. Background: First notice that in an $n\times n$ integer lattice, there are more squares than the obvious axis-aligned squares, for example the following: With some calculation, one can find that the total number of squares in this grid is  $$\sum\limits_{k=1}^nk^2(n-k)=\frac{(n-1)n^2(n+1)}{12}$$ I noticed that this can also be written as $\dfrac{n^2 \choose 2}{6}$, which led me to the combinatorial interpretation of picking corners of a square. Once we know that the number of squares is $\frac{1}{6}$-th of the number of pairs of points, the claimed solution of $\frac13$ is an immediate consequence (as each square has two pairs of opposite corners). However,  I've searched for the past week and failed to discover a proof without relying on counting all the squares. Source: I thought of this question while trying to write problems for a math competition.","Question: Find the probability that a random pair of lattice points are opposite corners of a square in an $n\times n$ integer lattice. Note: By a square in a lattice, I mean a square whose vertices are all lattice points. Motivation: I have a messy proof that the solution is $\frac13$. The proof relies on calculating the total number of squares in each $n\times n$ lattice, but I want to know if there is some neat argument which avoids that method. There's reason to think there might be since the result is independent of $n$. Background: First notice that in an $n\times n$ integer lattice, there are more squares than the obvious axis-aligned squares, for example the following: With some calculation, one can find that the total number of squares in this grid is  $$\sum\limits_{k=1}^nk^2(n-k)=\frac{(n-1)n^2(n+1)}{12}$$ I noticed that this can also be written as $\dfrac{n^2 \choose 2}{6}$, which led me to the combinatorial interpretation of picking corners of a square. Once we know that the number of squares is $\frac{1}{6}$-th of the number of pairs of points, the claimed solution of $\frac13$ is an immediate consequence (as each square has two pairs of opposite corners). However,  I've searched for the past week and failed to discover a proof without relying on counting all the squares. Source: I thought of this question while trying to write problems for a math competition.",,"['probability', 'combinatorics', 'geometry', 'integer-lattices']"
44,Maximum of Polynomials in the Unit Circle,Maximum of Polynomials in the Unit Circle,,"Let $z_{1},z_{2},\ldots,z_{n}$ be i.i.d random points in the unit circle ($|z_i|=1$) with uniform distribution of their angles. Consider the random polynomial $P(z)$ given by $$ P(z)=\prod_{i=1}^{n}(z-z_i). $$ Let $m$ be the maximum absolute value of $P(z)$ on the unit circle $m=\max\{|P(z)|:|z|=1\}$. How can I estimate $m$? More specifically, I would like to prove that there exist $\alpha>0$ such that the following holds almost surely as $n\to\infty$ $$ m\geq e^{\alpha\sqrt{n}}. $$ Any idea of what can be useful here?","Let $z_{1},z_{2},\ldots,z_{n}$ be i.i.d random points in the unit circle ($|z_i|=1$) with uniform distribution of their angles. Consider the random polynomial $P(z)$ given by $$ P(z)=\prod_{i=1}^{n}(z-z_i). $$ Let $m$ be the maximum absolute value of $P(z)$ on the unit circle $m=\max\{|P(z)|:|z|=1\}$. How can I estimate $m$? More specifically, I would like to prove that there exist $\alpha>0$ such that the following holds almost surely as $n\to\infty$ $$ m\geq e^{\alpha\sqrt{n}}. $$ Any idea of what can be useful here?",,"['probability', 'complex-analysis', 'approximation']"
45,"Probability: 6 Dice are rolled. Which is more likely, that you get exactly one 6, or that you get 6 different numbers?","Probability: 6 Dice are rolled. Which is more likely, that you get exactly one 6, or that you get 6 different numbers?",,"Here's the question: 6 Dice are rolled. Which is more likely, that you get exactly one 6, or that you get 6 different numbers? Here's what I've done: The number of possible outcomes is $6^6 = 46656$. The probability of rolling exactly one 6 = $\frac{1}{6}\times(\frac{5}{6})^5 = \frac{3125}{46656}$ The probability of getting six different numbers is: $C(6,1)\times C(5,1)\times C(4,1)\times C(3,1)\times C(2,1)\times C(1,1) = \frac{720}{46656}$ Therefore if everything I've said above is true, then it is more likely that you will roll exactly one six. However I'm really not sure about the last part. Is this correct way to solve this type of problem and can the combinations part be simplified? EDIT: Since I'm also looking for a better idea of how to solve this type of problem, rather than just this specific case, so could you please include how to solve this problem for rolling 5 dice, as well as/or instead of 6 dice in your answer, so that I can see the pattern of what is happening? Many thanks.","Here's the question: 6 Dice are rolled. Which is more likely, that you get exactly one 6, or that you get 6 different numbers? Here's what I've done: The number of possible outcomes is $6^6 = 46656$. The probability of rolling exactly one 6 = $\frac{1}{6}\times(\frac{5}{6})^5 = \frac{3125}{46656}$ The probability of getting six different numbers is: $C(6,1)\times C(5,1)\times C(4,1)\times C(3,1)\times C(2,1)\times C(1,1) = \frac{720}{46656}$ Therefore if everything I've said above is true, then it is more likely that you will roll exactly one six. However I'm really not sure about the last part. Is this correct way to solve this type of problem and can the combinations part be simplified? EDIT: Since I'm also looking for a better idea of how to solve this type of problem, rather than just this specific case, so could you please include how to solve this problem for rolling 5 dice, as well as/or instead of 6 dice in your answer, so that I can see the pattern of what is happening? Many thanks.",,"['probability', 'combinatorics']"
46,Probability of random integer's digits summing to 12,Probability of random integer's digits summing to 12,,"What is the probability that a random integer between 1 and 9999 will have digits that sum to 12? As a user suggested, I could make a spreadsheet and count them, but is there a quicker way to do this?","What is the probability that a random integer between 1 and 9999 will have digits that sum to 12? As a user suggested, I could make a spreadsheet and count them, but is there a quicker way to do this?",,"['probability', 'combinatorics', 'contest-math']"
47,Birthday-coverage problem,Birthday-coverage problem,,"I heard an interesting question recently: What is the minimum number of people required to make it more likely than not that all 365 possible birthdays are covered? Monte Carlo simulation suggests 2287 ($\pm 1$, I think).  More generally, with $p$ people, what is the probability that for each of the 365 days of the year, there is at least one person in the group with that birthday?  (Yes, ignoring the leap-day.)","I heard an interesting question recently: What is the minimum number of people required to make it more likely than not that all 365 possible birthdays are covered? Monte Carlo simulation suggests 2287 ($\pm 1$, I think).  More generally, with $p$ people, what is the probability that for each of the 365 days of the year, there is at least one person in the group with that birthday?  (Yes, ignoring the leap-day.)",,"['probability', 'median', 'coupon-collector']"
48,4 cards are drawn from a pack without replacement. What is the probability of getting all 4 from different suits?,4 cards are drawn from a pack without replacement. What is the probability of getting all 4 from different suits?,,"4 cards are drawn from a pack without replacement. What is the probability of getting all 4 from different suits? Here's how I tried to solve: For the first draw, we have 52 cards, and we have to pick one suit. So, probability for this is $\frac{13}{52}$. For the second draw, only 51 cards are left. The second suit has to be selected, so there are 13 cards from that suit. The probability is $\frac{13}{51}$. Similarly, the third and fourth draw have probabilities $\frac{13}{50}$ and $\frac{13}{49}$ respectively. Since the draws are independent, the total probability becomes $$\frac{13}{52} \times \frac{13}{51} \times \frac{13}{50} \times \frac{13}{49}$$ But my book says the answer is $\frac{{13\choose 1} \times {13 \choose 1} \times {13\choose1} \times {13\choose1}}{52 \choose 4}$. My answer differs by a factor of $4!$. What did I do wrong?","4 cards are drawn from a pack without replacement. What is the probability of getting all 4 from different suits? Here's how I tried to solve: For the first draw, we have 52 cards, and we have to pick one suit. So, probability for this is $\frac{13}{52}$. For the second draw, only 51 cards are left. The second suit has to be selected, so there are 13 cards from that suit. The probability is $\frac{13}{51}$. Similarly, the third and fourth draw have probabilities $\frac{13}{50}$ and $\frac{13}{49}$ respectively. Since the draws are independent, the total probability becomes $$\frac{13}{52} \times \frac{13}{51} \times \frac{13}{50} \times \frac{13}{49}$$ But my book says the answer is $\frac{{13\choose 1} \times {13 \choose 1} \times {13\choose1} \times {13\choose1}}{52 \choose 4}$. My answer differs by a factor of $4!$. What did I do wrong?",,"['probability', 'combinatorics']"
49,another balls and bins question,another balls and bins question,,"I've seen many variations of this problem but I can't find a good, thorough explanation on how to solve it. I'm not just looking for a solution, but a step-by-step explanation on how to derive the solution. So the problem at hand is: You have m balls and n bins. Consider throwing each ball into a bin uniformly and at random. What is the expected number of bins that are empty, in terms of m and n? What is the expected number of bins that contain exactly 1 ball, in terms of m and n? How would I approach solving this problem? Thanks!","I've seen many variations of this problem but I can't find a good, thorough explanation on how to solve it. I'm not just looking for a solution, but a step-by-step explanation on how to derive the solution. So the problem at hand is: You have m balls and n bins. Consider throwing each ball into a bin uniformly and at random. What is the expected number of bins that are empty, in terms of m and n? What is the expected number of bins that contain exactly 1 ball, in terms of m and n? How would I approach solving this problem? Thanks!",,['probability']
50,Why is stopping time defined as a random variable?,Why is stopping time defined as a random variable?,,"I've been given a crash course in stochastic processes and martingales for the purposes of a semester project on them. The guy I'm working with has been, I feel, a little vague in the definition of stopping times, and I can't seem to find anything on Wikipedia or Google that clarifies the issue for me. My problem is that stopping times are defined as random variables. But given the motivation for the concept of stopping times (aren't they basically meant to represent betting strategies?), that doesn't at all seem like how I would personally define stopping times. I would define a stopping time as a, in some sense, predicate , or a two valued function, that maps sequences of values to either STOP or NOT STOP. So given a sequence of values (representing the values of the stochastic process up to the present), the function tells you whether or not to stop. But instead, a stopping time is given by Wikipedia as: A stopping time with respect to a sequence of random variables $X_1, X_2, X_3,\ldots$ is a random variable $\tau$ with the property that for each $t$, the occurrence or non-occurrence of the event $\{\tau = t\}$ depends only on the values of $X_1, X_2, X_3, \ldots, X_t$. I can't see at all how to relate that to the notion of stopping times as betting strategies. If stopping time is a random variable with respect to a given sequence of values, doesn't that mean it's not a ""determined"" strategy? That sounds like you look at how much money you've made/lost so far, and then based on both that and the result of a coin flip (or something), decide whether or not to stop playing. I'm sure I'm wildly misunderstanding either the definition, the motivation, or both. Please avoid dipping too deeply into measure theory or filtrations, if possible.","I've been given a crash course in stochastic processes and martingales for the purposes of a semester project on them. The guy I'm working with has been, I feel, a little vague in the definition of stopping times, and I can't seem to find anything on Wikipedia or Google that clarifies the issue for me. My problem is that stopping times are defined as random variables. But given the motivation for the concept of stopping times (aren't they basically meant to represent betting strategies?), that doesn't at all seem like how I would personally define stopping times. I would define a stopping time as a, in some sense, predicate , or a two valued function, that maps sequences of values to either STOP or NOT STOP. So given a sequence of values (representing the values of the stochastic process up to the present), the function tells you whether or not to stop. But instead, a stopping time is given by Wikipedia as: A stopping time with respect to a sequence of random variables $X_1, X_2, X_3,\ldots$ is a random variable $\tau$ with the property that for each $t$, the occurrence or non-occurrence of the event $\{\tau = t\}$ depends only on the values of $X_1, X_2, X_3, \ldots, X_t$. I can't see at all how to relate that to the notion of stopping times as betting strategies. If stopping time is a random variable with respect to a given sequence of values, doesn't that mean it's not a ""determined"" strategy? That sounds like you look at how much money you've made/lost so far, and then based on both that and the result of a coin flip (or something), decide whether or not to stop playing. I'm sure I'm wildly misunderstanding either the definition, the motivation, or both. Please avoid dipping too deeply into measure theory or filtrations, if possible.",,"['probability', 'stochastic-processes', 'martingales', 'stopping-times']"
51,how to find the expected number of boxes with no balls,how to find the expected number of boxes with no balls,,"If you have 10 balls and 5 boxes what is the expected number of boxes with no balls. The probability that each ball goes independently into box $i$ is $p_i$ with the $\sum_{i=1}^5 p_i =1$. Also, what is the expected number of boxes that have exactly one ball. For part 1, isn't the answer related to the number of solutions to the equation $x_1+x_2+x_3+x_4+x_5 = 10$ where all the $x$s can take on nonnegative integers? And for the second part, isn't it the number of only positive solutions?","If you have 10 balls and 5 boxes what is the expected number of boxes with no balls. The probability that each ball goes independently into box $i$ is $p_i$ with the $\sum_{i=1}^5 p_i =1$. Also, what is the expected number of boxes that have exactly one ball. For part 1, isn't the answer related to the number of solutions to the equation $x_1+x_2+x_3+x_4+x_5 = 10$ where all the $x$s can take on nonnegative integers? And for the second part, isn't it the number of only positive solutions?",,['probability']
52,Comparing two exponential random variables,Comparing two exponential random variables,,"Let $A$ and $B$ be independent random variables drawn from the exponential distribution with parameters $\lambda_A<\lambda_B$. What is the probability that $A<B$? I'm of course aware of the probability density function and the cumulative distribution function of the exponential random variable , but I'm not sure how to use it to answer this question. Also, there seems to be no such formula on the Wikipedia page.","Let $A$ and $B$ be independent random variables drawn from the exponential distribution with parameters $\lambda_A<\lambda_B$. What is the probability that $A<B$? I'm of course aware of the probability density function and the cumulative distribution function of the exponential random variable , but I'm not sure how to use it to answer this question. Also, there seems to be no such formula on the Wikipedia page.",,"['probability', 'random-variables']"
53,Does the square of uniform distribution have density function?,Does the square of uniform distribution have density function?,,"$X\sim U[0,1]$ and $Y\sim U[-1,1]$ are two uniform-distributed R.V.'s. Are $X^2$ and $Y^2$ still uniform? Do they have explicit probability density funtion?","$X\sim U[0,1]$ and $Y\sim U[-1,1]$ are two uniform-distributed R.V.'s. Are $X^2$ and $Y^2$ still uniform? Do they have explicit probability density funtion?",,['probability']
54,What's the probability of getting 1000 heads in a row?,What's the probability of getting 1000 heads in a row?,,"I'm reading The Master Algorithm by Pedro Domingos and I'm having a hard time understanding something he wrote on page 74: ""If you do a million runs of a thousand coin flips, it's practically certain that at least one run will come up all heads."" My intuition tells me this is false. My understanding of probability would indicate that the chance of encountering $1000$ heads in a row after trying $1000000$ times is: $$\frac{1}{2^{1000}} *1000000$$ which is minuscule and hardly ""practically certain."" Is my understanding correct, or am I missing something?","I'm reading The Master Algorithm by Pedro Domingos and I'm having a hard time understanding something he wrote on page 74: ""If you do a million runs of a thousand coin flips, it's practically certain that at least one run will come up all heads."" My intuition tells me this is false. My understanding of probability would indicate that the chance of encountering $1000$ heads in a row after trying $1000000$ times is: $$\frac{1}{2^{1000}} *1000000$$ which is minuscule and hardly ""practically certain."" Is my understanding correct, or am I missing something?",,[]
55,How do you compute numerically the Earth mover's distance (EMD)?,How do you compute numerically the Earth mover's distance (EMD)?,,"I was trying to compute numerically (write a program) that calculated the EMD for two probability distribution $p_X$ and $q_X$. However, I had a hard time finding an outline of how to exactly compute such a distance. I was wondering if there existed a closed form equation for EMD or if there existed an outline of an algorithm to compute it. Just like there is very compact equation for say, the KL-divergence $D(p_X||q_X) = \sum_{x \in X}p_X(x) log\frac{p_X(x)}{q_X(x)}$ Is there one such equation for EMD or an algorithm for EMD such that it can be easily numerically computed? What I have found so far is the following, that $EMD(p_X,q_X)$ between distributions $p_X$ and $q_X$ is: $$EMD(P,Q) = \frac{\sum^m_{i=1}\sum^n_{j=1} f_{ij}d_{ij}}{\sum^m_{i=1}\sum^b_{j=1} f_{ij}}$$ However, to find $d_{ij}$ one needs to define some distance measure I guess and to find $f_{ij}$ one needs to solve the transportation linear programming defined in: http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/RUBNER/emd.htm#RUBNER98A Isn't there a solution to the transportation problem such that there is an easy way of evaluating EMD? Also, I found a wikipedia section to compute it but, the pseudo-code was to ambiguous for me to understand how to actually compute the EMD. If someone understands that section better and can explain it, it would awesome! Here is the link http://en.wikipedia.org/wiki/Earth_mover's_distance or you can just see the pseudo-code right here: The Pseudo-code/wikipedia section: If the domain D is discrete, the EMD can be computed by solving an instance transportation problem, which can be solved by the so-called Hungarian algorithm. In particular, if D is a one-dimensional array of ""bins"" the EMD can be efficiently computed by scanning the array and keeping track of how much dirt needs to be transported between consecutive bins. For example: $EMD_0 = 0 \\$ $EMD_{i+1} = ( A_i + EMD_i ) - B_i \\$ $TotalDistance = \sum | EMD_i | \\$ I guess what I don't understand is what $A_i$ and $B_i$ are and when the algorithm even stops running. Its just to unclear to me what its doing and I guess I don't understand EMD well enough to derive it myself (If I could I would!) As an extension to my question, is it a problem if the sample space for the probability distributions is infinite? I probably won't accept answer that are not as general as possible, but an answer clarifying what wikipedia article is trying to say, would definitively get an up vote.","I was trying to compute numerically (write a program) that calculated the EMD for two probability distribution $p_X$ and $q_X$. However, I had a hard time finding an outline of how to exactly compute such a distance. I was wondering if there existed a closed form equation for EMD or if there existed an outline of an algorithm to compute it. Just like there is very compact equation for say, the KL-divergence $D(p_X||q_X) = \sum_{x \in X}p_X(x) log\frac{p_X(x)}{q_X(x)}$ Is there one such equation for EMD or an algorithm for EMD such that it can be easily numerically computed? What I have found so far is the following, that $EMD(p_X,q_X)$ between distributions $p_X$ and $q_X$ is: $$EMD(P,Q) = \frac{\sum^m_{i=1}\sum^n_{j=1} f_{ij}d_{ij}}{\sum^m_{i=1}\sum^b_{j=1} f_{ij}}$$ However, to find $d_{ij}$ one needs to define some distance measure I guess and to find $f_{ij}$ one needs to solve the transportation linear programming defined in: http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/RUBNER/emd.htm#RUBNER98A Isn't there a solution to the transportation problem such that there is an easy way of evaluating EMD? Also, I found a wikipedia section to compute it but, the pseudo-code was to ambiguous for me to understand how to actually compute the EMD. If someone understands that section better and can explain it, it would awesome! Here is the link http://en.wikipedia.org/wiki/Earth_mover's_distance or you can just see the pseudo-code right here: The Pseudo-code/wikipedia section: If the domain D is discrete, the EMD can be computed by solving an instance transportation problem, which can be solved by the so-called Hungarian algorithm. In particular, if D is a one-dimensional array of ""bins"" the EMD can be efficiently computed by scanning the array and keeping track of how much dirt needs to be transported between consecutive bins. For example: $EMD_0 = 0 \\$ $EMD_{i+1} = ( A_i + EMD_i ) - B_i \\$ $TotalDistance = \sum | EMD_i | \\$ I guess what I don't understand is what $A_i$ and $B_i$ are and when the algorithm even stops running. Its just to unclear to me what its doing and I guess I don't understand EMD well enough to derive it myself (If I could I would!) As an extension to my question, is it a problem if the sample space for the probability distributions is infinite? I probably won't accept answer that are not as general as possible, but an answer clarifying what wikipedia article is trying to say, would definitively get an up vote.",,"['probability', 'probability-theory', 'probability-distributions']"
56,Understanding the chain rule in probability theory,Understanding the chain rule in probability theory,,"When my teacher told us about the chain rule I found it quite easy, but when I am trying to prove something based on this rule I kind of get confused about what are the allowed forms of this rule. For example, I can't understand why I can say: $$ p(x,y\mid z)=p(y\mid z)p(x\mid y,z) $$ I can not understand how one can end up to this equation from the general rule! Can you please help how to think correctly about this rule? I found this post useful for my question: Is order of variables important in probability chain rule","When my teacher told us about the chain rule I found it quite easy, but when I am trying to prove something based on this rule I kind of get confused about what are the allowed forms of this rule. For example, I can't understand why I can say: $$ p(x,y\mid z)=p(y\mid z)p(x\mid y,z) $$ I can not understand how one can end up to this equation from the general rule! Can you please help how to think correctly about this rule? I found this post useful for my question: Is order of variables important in probability chain rule",,"['probability', 'chain-rule']"
57,"What is the probability that $\sum_{k=1}^\infty u_k>1$, if $u_1=$ random real number in $(0,1)$, and $u_k=$ random real number in $(0,u_{k-1})$?","What is the probability that , if  random real number in , and  random real number in ?","\sum_{k=1}^\infty u_k>1 u_1= (0,1) u_k= (0,u_{k-1})","Let $u_1=$ i.i.d. $\text{Uniform}(0,1)$ -variable. Let $u_k=$ i.i.d. $\text{Uniform}(0,u_{k-1})$ -variable for $k>1$ . What is the probability that $\sum\limits_{k=1}^\infty u_k>1$ ? The expectation of $\sum\limits_{k=1}^\infty u_k$ is $1$ . This can be shown as follows. For $a_i=$ i.i.d. $\text{Uniform}(0,1)$ -variable, we have: $$E\left(\sum\limits_{k=1}^\infty u_k\right)=E\left(\sum\limits_{k=1}^\infty \left(\prod\limits_{i=1}^k a_i\right)\right)=\sum\limits_{k=1}^\infty \left(\prod\limits_{i=1}^k E(a_i)\right)=\sum\limits_{k=1}^\infty \left(\prod\limits_{i=1}^k \left(\frac12\right)\right)=1$$ An Excel simulation suggests that $P\left(\sum\limits_{k=1}^{50} u_k>1\right)$ and $P\left(\sum\limits_{k=1}^{100} u_k>1\right)$ are both roughly $0.44$ . Other than that, I do not know how to approach this problem. Context: This question was inspired by another question involving the sum of random real numbers.","Let i.i.d. -variable. Let i.i.d. -variable for . What is the probability that ? The expectation of is . This can be shown as follows. For i.i.d. -variable, we have: An Excel simulation suggests that and are both roughly . Other than that, I do not know how to approach this problem. Context: This question was inspired by another question involving the sum of random real numbers.","u_1= \text{Uniform}(0,1) u_k= \text{Uniform}(0,u_{k-1}) k>1 \sum\limits_{k=1}^\infty u_k>1 \sum\limits_{k=1}^\infty u_k 1 a_i= \text{Uniform}(0,1) E\left(\sum\limits_{k=1}^\infty u_k\right)=E\left(\sum\limits_{k=1}^\infty \left(\prod\limits_{i=1}^k a_i\right)\right)=\sum\limits_{k=1}^\infty \left(\prod\limits_{i=1}^k E(a_i)\right)=\sum\limits_{k=1}^\infty \left(\prod\limits_{i=1}^k \left(\frac12\right)\right)=1 P\left(\sum\limits_{k=1}^{50} u_k>1\right) P\left(\sum\limits_{k=1}^{100} u_k>1\right) 0.44","['probability', 'sequences-and-series', 'random-variables']"
58,Probability distribution for the remainder of a fixed integer,Probability distribution for the remainder of a fixed integer,,"In the ""Notes"" section of Modern Computer Algebra by Joachim Von Zur Gathen, there is a quick throwaway remark that says: Dirichlet also proves the fact, surprising at first sight, that for fixed $a$ in a division the remainder $r = a \operatorname{rem} b$, with $0 \leq r < b$, is more likely to be smaller than $b/2$ than larger: If $p_a$ denotes the probability for the former, where $1 \leq b \leq a$ is chosen uniformly at random, then $p_a$ is asymptotically $2 - \ln{4} \approx 61.37\%$. The note ends there and nothing is said about it again. This fact does surprise me, and I've tried to look it up, but all my searches for ""Dirichlet"" and ""probability"" together end up being dominated by talks of Dirichlet stochastic processes (which, I assume, is unrelated). Does anybody have a reference or proof for this result?","In the ""Notes"" section of Modern Computer Algebra by Joachim Von Zur Gathen, there is a quick throwaway remark that says: Dirichlet also proves the fact, surprising at first sight, that for fixed $a$ in a division the remainder $r = a \operatorname{rem} b$, with $0 \leq r < b$, is more likely to be smaller than $b/2$ than larger: If $p_a$ denotes the probability for the former, where $1 \leq b \leq a$ is chosen uniformly at random, then $p_a$ is asymptotically $2 - \ln{4} \approx 61.37\%$. The note ends there and nothing is said about it again. This fact does surprise me, and I've tried to look it up, but all my searches for ""Dirichlet"" and ""probability"" together end up being dominated by talks of Dirichlet stochastic processes (which, I assume, is unrelated). Does anybody have a reference or proof for this result?",,"['number-theory', 'probability']"
59,Probability of tossing a fair coin with at least $k$ consecutive heads,Probability of tossing a fair coin with at least  consecutive heads,k,"Tossing a fair coin for $N$ times and we get a result series as $HTHTHHTT\dots~$, Here '$H$' denotes 'head'  and '$T$' denotes 'tail' for a specific tossing each time. What is the probability that the length of the longest streak of consecutive heads is greater than or equal to $k$? (that is we have a $HHHH\dots~$, which is the substring of our tossing result, and whose length is greater than or equal to $k$) I came up with a recursive solution (though not quite sure), but cannot find a closed form solution. Here is my solution. Denote $P(N,k)$ as the probability for tossing the coin $N$ times, and the longest continuous heads is greater or equal than $k$. Then (For $N>k$) $$ P(N,k)=P(N-1,k)+\Big(1-P(N-k-1,k)\Big)\left(\frac{1}{2}\right)^{k+1}   $$","Tossing a fair coin for $N$ times and we get a result series as $HTHTHHTT\dots~$, Here '$H$' denotes 'head'  and '$T$' denotes 'tail' for a specific tossing each time. What is the probability that the length of the longest streak of consecutive heads is greater than or equal to $k$? (that is we have a $HHHH\dots~$, which is the substring of our tossing result, and whose length is greater than or equal to $k$) I came up with a recursive solution (though not quite sure), but cannot find a closed form solution. Here is my solution. Denote $P(N,k)$ as the probability for tossing the coin $N$ times, and the longest continuous heads is greater or equal than $k$. Then (For $N>k$) $$ P(N,k)=P(N-1,k)+\Big(1-P(N-k-1,k)\Big)\left(\frac{1}{2}\right)^{k+1}   $$",,['probability']
60,Consecutive birthdays probability,Consecutive birthdays probability,,"Let $n$ be a number of people. At least two of them may be born on the same day of the year with probability: $$1-\prod_{i=0}^{n-1} \frac{365-i}{365}$$ But what is the probability that at least two of them are born on two consecutive days of the year (considering December 31st and January 1st also consecutive)? It seems a good approximation is: $$1-\prod_{i=0}^{n-1} \frac{365-2 \times i}{365}$$ However, simulating pseudo-random integers with Python, the 99%-confidence intervals may be slightly different. So do you have any closed formula? Results of the simulation with Python. Here are 99%-confidence intervals below: Number of people:  1    Lower bound: 0.0        Upper bound: 0.0 Number of people:  2    Lower bound: 0.00528    Upper bound: 0.00567 Number of people:  3    Lower bound: 0.01591    Upper bound: 0.01657 Number of people:  4    Lower bound: 0.03185    Upper bound: 0.03277 Number of people:  5    Lower bound: 0.0528     Upper bound: 0.05397 Number of people:  6    Lower bound: 0.07819    Upper bound: 0.07959 Number of people:  7    Lower bound: 0.10844    Upper bound: 0.11006 Number of people:  8    Lower bound: 0.14183    Upper bound: 0.14364 Number of people:  9    Lower bound: 0.17887    Upper bound: 0.18086 Number of people: 10    Lower bound: 0.21816    Upper bound: 0.2203 Number of people: 11    Lower bound: 0.25956    Upper bound: 0.26183 Number of people: 12    Lower bound: 0.30306    Upper bound: 0.30544 Number of people: 13    Lower bound: 0.34678    Upper bound: 0.34925 Number of people: 14    Lower bound: 0.39144    Upper bound: 0.39397 Number of people: 15    Lower bound: 0.43633    Upper bound: 0.4389 Number of people: 16    Lower bound: 0.48072    Upper bound: 0.48331 Number of people: 17    Lower bound: 0.52476    Upper bound: 0.52734 I give here some results with a tweaked approximation formula, using Wolfram Alpha : $$\left( 1 - \frac{n-1}{2 \times 365 + n-1} \right) \times \left( 1-\prod_{i=0}^{n-1} \frac{365-2 \times i}{365} \right)$$ However, this is just a tweak, ans is clearly wrong for $n=33$ since: Number of people: 33    My guess: 0.91407 Number of people: 33    Lower bound: 0.94328    Upper bound: 0.94447 Thanks to Jacopo Notarstefano, leonbloy, and Moron , here is the (correct) formula: $$ 1-\sum_{k=1}^{n}\frac{1}{365^{n-k}k}\left(\prod_{i=1}^{k-1}\frac{365-\left(k+i\right)}{365\times i}\right)\sum_{j=0}^{k-1}\left(-1\right)^{j}C_{k}^{j}\left(k-j\right)^{n} $$ And here are the results of the computations using this formula with Python: Number of people:  1    Probability: 0.0 Number of people:  2    Probability: 0.005479452 Number of people:  3    Probability: 0.016348283 Number of people:  4    Probability: 0.032428609 Number of people:  5    Probability: 0.053459591 Number of people:  6    Probability: 0.079104502 Number of people:  7    Probability: 0.108959718 Number of people:  8    Probability: 0.14256532 Number of people:  9    Probability: 0.179416899 Number of people: 10    Probability: 0.218978144 Number of people: 11    Probability: 0.260693782 Number of people: 12    Probability: 0.304002428 Number of people: 13    Probability: 0.34834893 Number of people: 14    Probability: 0.393195856 Number of people: 15    Probability: 0.438033789 Number of people: 16    Probability: 0.482390182 Number of people: 17    Probability: 0.525836596 Number of people: 18    Probability: 0.567994209 Number of people: 19    Probability: 0.608537602 Number of people: 20    Probability: 0.647196551 Number of people: 21    Probability: 0.683756966 Number of people: 22    Probability: 0.718059191 Number of people: 23    Probability: 0.749995532 Number of people: 24    Probability: 0.779509664 Number of people: 25    Probability: 0.806569056 Number of people: 26    Probability: 0.831211564 Number of people: 27    Probability: 0.853561895 Number of people: 28    Probability: 0.873571839 Number of people: 29    Probability: 0.892014392 Number of people: 30    Probability: 0.906106867 Number of people: 31    Probability: 0.919063161 Number of people: 32    Probability: 0.928791992 Number of people: 33    Probability: 0.944659069","Let $n$ be a number of people. At least two of them may be born on the same day of the year with probability: $$1-\prod_{i=0}^{n-1} \frac{365-i}{365}$$ But what is the probability that at least two of them are born on two consecutive days of the year (considering December 31st and January 1st also consecutive)? It seems a good approximation is: $$1-\prod_{i=0}^{n-1} \frac{365-2 \times i}{365}$$ However, simulating pseudo-random integers with Python, the 99%-confidence intervals may be slightly different. So do you have any closed formula? Results of the simulation with Python. Here are 99%-confidence intervals below: Number of people:  1    Lower bound: 0.0        Upper bound: 0.0 Number of people:  2    Lower bound: 0.00528    Upper bound: 0.00567 Number of people:  3    Lower bound: 0.01591    Upper bound: 0.01657 Number of people:  4    Lower bound: 0.03185    Upper bound: 0.03277 Number of people:  5    Lower bound: 0.0528     Upper bound: 0.05397 Number of people:  6    Lower bound: 0.07819    Upper bound: 0.07959 Number of people:  7    Lower bound: 0.10844    Upper bound: 0.11006 Number of people:  8    Lower bound: 0.14183    Upper bound: 0.14364 Number of people:  9    Lower bound: 0.17887    Upper bound: 0.18086 Number of people: 10    Lower bound: 0.21816    Upper bound: 0.2203 Number of people: 11    Lower bound: 0.25956    Upper bound: 0.26183 Number of people: 12    Lower bound: 0.30306    Upper bound: 0.30544 Number of people: 13    Lower bound: 0.34678    Upper bound: 0.34925 Number of people: 14    Lower bound: 0.39144    Upper bound: 0.39397 Number of people: 15    Lower bound: 0.43633    Upper bound: 0.4389 Number of people: 16    Lower bound: 0.48072    Upper bound: 0.48331 Number of people: 17    Lower bound: 0.52476    Upper bound: 0.52734 I give here some results with a tweaked approximation formula, using Wolfram Alpha : $$\left( 1 - \frac{n-1}{2 \times 365 + n-1} \right) \times \left( 1-\prod_{i=0}^{n-1} \frac{365-2 \times i}{365} \right)$$ However, this is just a tweak, ans is clearly wrong for $n=33$ since: Number of people: 33    My guess: 0.91407 Number of people: 33    Lower bound: 0.94328    Upper bound: 0.94447 Thanks to Jacopo Notarstefano, leonbloy, and Moron , here is the (correct) formula: $$ 1-\sum_{k=1}^{n}\frac{1}{365^{n-k}k}\left(\prod_{i=1}^{k-1}\frac{365-\left(k+i\right)}{365\times i}\right)\sum_{j=0}^{k-1}\left(-1\right)^{j}C_{k}^{j}\left(k-j\right)^{n} $$ And here are the results of the computations using this formula with Python: Number of people:  1    Probability: 0.0 Number of people:  2    Probability: 0.005479452 Number of people:  3    Probability: 0.016348283 Number of people:  4    Probability: 0.032428609 Number of people:  5    Probability: 0.053459591 Number of people:  6    Probability: 0.079104502 Number of people:  7    Probability: 0.108959718 Number of people:  8    Probability: 0.14256532 Number of people:  9    Probability: 0.179416899 Number of people: 10    Probability: 0.218978144 Number of people: 11    Probability: 0.260693782 Number of people: 12    Probability: 0.304002428 Number of people: 13    Probability: 0.34834893 Number of people: 14    Probability: 0.393195856 Number of people: 15    Probability: 0.438033789 Number of people: 16    Probability: 0.482390182 Number of people: 17    Probability: 0.525836596 Number of people: 18    Probability: 0.567994209 Number of people: 19    Probability: 0.608537602 Number of people: 20    Probability: 0.647196551 Number of people: 21    Probability: 0.683756966 Number of people: 22    Probability: 0.718059191 Number of people: 23    Probability: 0.749995532 Number of people: 24    Probability: 0.779509664 Number of people: 25    Probability: 0.806569056 Number of people: 26    Probability: 0.831211564 Number of people: 27    Probability: 0.853561895 Number of people: 28    Probability: 0.873571839 Number of people: 29    Probability: 0.892014392 Number of people: 30    Probability: 0.906106867 Number of people: 31    Probability: 0.919063161 Number of people: 32    Probability: 0.928791992 Number of people: 33    Probability: 0.944659069",,"['probability', 'combinatorics']"
61,P.d.f of the absolute value of a normally distributed variable,P.d.f of the absolute value of a normally distributed variable,,"I came across this question as an exercise, had a brief idea, but didn't know how to proceed. Let $X \sim N(0, 1)$ . What is the p.d.f of $|X|$ ? I know the final p.d.f looks just like the right half of the original pdf, but extended vertically for a factor of 2. Could someone please show mathematically what the p.d.f of variable |X| is going to be, and explain briefly? Thank you.","I came across this question as an exercise, had a brief idea, but didn't know how to proceed. Let . What is the p.d.f of ? I know the final p.d.f looks just like the right half of the original pdf, but extended vertically for a factor of 2. Could someone please show mathematically what the p.d.f of variable |X| is going to be, and explain briefly? Thank you.","X \sim N(0, 1) |X|","['probability', 'normal-distribution']"
62,Difference between a joint probability and the probability of an intersection,Difference between a joint probability and the probability of an intersection,,"Is the joint probability $p(X=x,Y=y)$ equivalent to $p(X=x \cap Y=y )$? If it is, why do we use two different notations?","Is the joint probability $p(X=x,Y=y)$ equivalent to $p(X=x \cap Y=y )$? If it is, why do we use two different notations?",,['probability']
63,how to show convergence in probability imply convergence a.s. in this case?,how to show convergence in probability imply convergence a.s. in this case?,,"Assume that  $X_1,\cdots,X_n$ are independent r.v., not necessarily iid, Let $S_n=X_1+\cdots+X_n$, suppose that $S_n$ converges in probability, how can we show that $S_n$ converges a.s.?","Assume that  $X_1,\cdots,X_n$ are independent r.v., not necessarily iid, Let $S_n=X_1+\cdots+X_n$, suppose that $S_n$ converges in probability, how can we show that $S_n$ converges a.s.?",,"['probability', 'probability-theory']"
64,Probability of getting a $7$ in Minesweeper,Probability of getting a  in Minesweeper,7,"Let's say you have a $30$ by $16$ grid and $99$ mines. What is the probability of having at least one empty block surrounded by exactly $7$ mines? For the sake of this question, assume that the mines are generated randomly.","Let's say you have a $30$ by $16$ grid and $99$ mines. What is the probability of having at least one empty block surrounded by exactly $7$ mines? For the sake of this question, assume that the mines are generated randomly.",,['probability']
65,2D Random Walk Hitting Time,2D Random Walk Hitting Time,,"Suppose there is a grid $[1,N]^2$ . A person standing at some initial point $(x_0,y_0)$ walk randomly within the grid. At each location, he/she walks to a neighboring location with equal probability (e.g., for an interior point, the probability is $\frac{1}{4}$ ; for a corner, it's $\frac{1}{2}$ .). Suppose there are $m$ absorbing barriers $B=\{(x_1,y_1),\cdots,(x_m,y_m)\}$ inside the grid. Once the person is on a barrier, the random walk process stops. I'd like to ask how to calculate the hitting probability and the expected number of steps for each barrier. Edit: The problem can be transformed into a Markov chain. But the expected hitting time for each absorbing state is still not easy to calculate.","Suppose there is a grid . A person standing at some initial point walk randomly within the grid. At each location, he/she walks to a neighboring location with equal probability (e.g., for an interior point, the probability is ; for a corner, it's .). Suppose there are absorbing barriers inside the grid. Once the person is on a barrier, the random walk process stops. I'd like to ask how to calculate the hitting probability and the expected number of steps for each barrier. Edit: The problem can be transformed into a Markov chain. But the expected hitting time for each absorbing state is still not easy to calculate.","[1,N]^2 (x_0,y_0) \frac{1}{4} \frac{1}{2} m B=\{(x_1,y_1),\cdots,(x_m,y_m)\}","['probability', 'markov-chains', 'random-walk']"
66,Is the set $\{ (X_n)_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence} \}$ measurable?,Is the set  measurable?,\{ (X_n)_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence} \},"Given a measurable space $(\Omega, \mathcal{A})$ and $\mathcal{A}/\mathcal{B}(\mathbb{R})$ -measurable maps $X_n : \Omega \to \mathbb{R}$ , $n \in \mathbb{N}$ , is the set $$ A:= \{\omega \in \Omega | (X_n(\omega))_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence} \} $$ in $\mathcal{A}$ ? My intuitive answer was yes. But I have been struggling to show this. Basically, the problem is that there are uncountably many subsequences. To clarify: A sequence of real numbers $(a_n)_{n \in \mathbb{N}}$ is nondecreasing if $a_n \leq a_{n+1}$ for all $n \in \mathbb{N}$ . Here are some ways of trying to show the measurability that don't work. Trying to write $A$ as $$ B:= \bigcap_{n \in \mathbb{N}}\bigcup_{k \geq n}\bigcup_{l > k}\{X_k \leq X_l\} $$ doesn't work, because $B$ doesn't have to be in $A$ , see the sequence $-1,-1,-2,-2,-3,-3,\dots$ Defining, for all $k \in \mathbb{N}$ , the random variables $T_0^k := k$ , and then recursively $$ T_{j+1}^k := \inf\{n \geq T_j^k|X_n \geq X_{T_j^k}\} $$ and then considering the set $$ C:= \bigcup_{k \in \mathbb{N}}\bigcap_{j \in \mathbb{N}}\{T_j^k < \infty\} $$ doesn't work, because $A$ doesn't have to be in $C$ , see the sequence $0,\frac12,0,\frac13,0,\frac14,0,\dots$ Considering the sets $$ S_k =  \{(X_n)_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence of length } k \} $$ and arguing that $A = \bigcap S_k$ . In fact the reverse inclusion does not hold as can be seen by the sequence: $$1,1+1/2,$$ $$0,0+\frac{1}{2}, \; 0+\frac{3}{4},$$ $$-1,-1+\frac{1}{2},-1+\frac{3}{4},-1+\frac{7}{8},$$ $$-2,-2+\frac{1}{2},-2+\frac{3}{4},-2+\frac{7}{8}, -2+\frac{15}{16}, \ldots$$ Update : I still don't know the answer to this question. However, I feel like if $A$ was always measurable, it shouldn't be so difficult to find a proof. For showing non-measurability, I have tried the following. Let $X_n$ be iid $U([0,1])$ distributed. Now if we assume that $A$ is measurable, then $A$ is also in the terminal $\sigma$ -algebra $\mathcal{T}_\infty$ of the $X_n$ . Now if we define $$ B := \{\omega \in \Omega | (X_n(\omega))_{n \in \mathbb{N}} \text{ has a nonincreasing subsequence} \}, $$ then we have $P(A \cup B) = 1$ because every sequence of real numbers has a monotone subsequence, and $P(A) = P(B)$ because the $X_n$ are $U([0,1])$ -distributed. This gives us $P(A) > 0$ , and thus $P(A) = 1$ because $A \in \mathcal{T}_\infty$ . So all you would have to do to find a contradiction is to find a set of strictly positive measure where $(X_n)$ doesn't have a nondecreasing subsequence. Update : George Lowther has given an extensive answer. To sum up: We can use the lemma in his answer to show that our set $A$ need not be in $\mathcal{A}$ , but is always analytic which means in particular that, given any probability measure $P$ on $(\Omega, \mathcal{A})$ , we can always assign a meaningful measure to $A$ because $A$ is in the completion of $\mathcal{A}$ w.r.t. $P$ . Here is how we use the lemma: Given any measurable space $(\Omega,\mathcal{A})$ and $A$ as above, the first implication of the lemma directly implies that $A$ is analytic. To show that $A$ need not be in $\mathcal{A}$ , we construct a counterexample. Let $(\Omega,\mathcal{A}) = (\mathbb{R},\mathcal{B}(\mathbb{R}))$ . Then there exists a set $A \subseteq \Omega$ that is analytic but is not in $\mathcal{A}$ . Now the second implication of the lemma tells us that we can construct a sequence $(X_n)_{n \in \mathbb{N}}$ of random variables such that $$ A = \{\omega \in \Omega | (X_n(\omega))_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence} \}. $$","Given a measurable space and -measurable maps , , is the set in ? My intuitive answer was yes. But I have been struggling to show this. Basically, the problem is that there are uncountably many subsequences. To clarify: A sequence of real numbers is nondecreasing if for all . Here are some ways of trying to show the measurability that don't work. Trying to write as doesn't work, because doesn't have to be in , see the sequence Defining, for all , the random variables , and then recursively and then considering the set doesn't work, because doesn't have to be in , see the sequence Considering the sets and arguing that . In fact the reverse inclusion does not hold as can be seen by the sequence: Update : I still don't know the answer to this question. However, I feel like if was always measurable, it shouldn't be so difficult to find a proof. For showing non-measurability, I have tried the following. Let be iid distributed. Now if we assume that is measurable, then is also in the terminal -algebra of the . Now if we define then we have because every sequence of real numbers has a monotone subsequence, and because the are -distributed. This gives us , and thus because . So all you would have to do to find a contradiction is to find a set of strictly positive measure where doesn't have a nondecreasing subsequence. Update : George Lowther has given an extensive answer. To sum up: We can use the lemma in his answer to show that our set need not be in , but is always analytic which means in particular that, given any probability measure on , we can always assign a meaningful measure to because is in the completion of w.r.t. . Here is how we use the lemma: Given any measurable space and as above, the first implication of the lemma directly implies that is analytic. To show that need not be in , we construct a counterexample. Let . Then there exists a set that is analytic but is not in . Now the second implication of the lemma tells us that we can construct a sequence of random variables such that","(\Omega, \mathcal{A}) \mathcal{A}/\mathcal{B}(\mathbb{R}) X_n : \Omega \to \mathbb{R} n \in \mathbb{N} 
A:= \{\omega \in \Omega | (X_n(\omega))_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence} \}
 \mathcal{A} (a_n)_{n \in \mathbb{N}} a_n \leq a_{n+1} n \in \mathbb{N} A 
B:= \bigcap_{n \in \mathbb{N}}\bigcup_{k \geq n}\bigcup_{l > k}\{X_k \leq X_l\}
 B A -1,-1,-2,-2,-3,-3,\dots k \in \mathbb{N} T_0^k := k 
T_{j+1}^k := \inf\{n \geq T_j^k|X_n \geq X_{T_j^k}\}
 
C:= \bigcup_{k \in \mathbb{N}}\bigcap_{j \in \mathbb{N}}\{T_j^k < \infty\}
 A C 0,\frac12,0,\frac13,0,\frac14,0,\dots 
S_k =  \{(X_n)_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence of length } k \}
 A = \bigcap S_k 1,1+1/2, 0,0+\frac{1}{2}, \; 0+\frac{3}{4}, -1,-1+\frac{1}{2},-1+\frac{3}{4},-1+\frac{7}{8}, -2,-2+\frac{1}{2},-2+\frac{3}{4},-2+\frac{7}{8}, -2+\frac{15}{16}, \ldots A X_n U([0,1]) A A \sigma \mathcal{T}_\infty X_n 
B := \{\omega \in \Omega | (X_n(\omega))_{n \in \mathbb{N}} \text{ has a nonincreasing subsequence} \},
 P(A \cup B) = 1 P(A) = P(B) X_n U([0,1]) P(A) > 0 P(A) = 1 A \in \mathcal{T}_\infty (X_n) A \mathcal{A} P (\Omega, \mathcal{A}) A A \mathcal{A} P (\Omega,\mathcal{A}) A A A \mathcal{A} (\Omega,\mathcal{A}) = (\mathbb{R},\mathcal{B}(\mathbb{R})) A \subseteq \Omega \mathcal{A} (X_n)_{n \in \mathbb{N}} 
A = \{\omega \in \Omega | (X_n(\omega))_{n \in \mathbb{N}} \text{ has a nondecreasing subsequence} \}.
","['probability', 'probability-theory', 'measure-theory', 'stochastic-processes']"
67,Gambler's fallacy and the Law of large numbers,Gambler's fallacy and the Law of large numbers,,"Can someone explain me, how the Law of large numbers and the Gambler's Fallacy do not contradict. The Gambler's Fallacy says, that there is no memory in randomness and any sequence of events has the same probability as any other sequence. However, the Law of large numbers says, that given enough repetitions a certain event will likely happen. To my understanding, these two kinda contradict each other because one says that you can not predict any random event but the other one says so (given enough repetitions of course). For example imagine a series of coin tosses where the coin comes up heads a million times. The Gambler's fallacy says that the chance for the next toss to be tails is still 1/2. However the law of large numbers says, that since enough repetitions of tosses have come up heads, the next toss is more likely to be tails. (Which is definitely wrong?)","Can someone explain me, how the Law of large numbers and the Gambler's Fallacy do not contradict. The Gambler's Fallacy says, that there is no memory in randomness and any sequence of events has the same probability as any other sequence. However, the Law of large numbers says, that given enough repetitions a certain event will likely happen. To my understanding, these two kinda contradict each other because one says that you can not predict any random event but the other one says so (given enough repetitions of course). For example imagine a series of coin tosses where the coin comes up heads a million times. The Gambler's fallacy says that the chance for the next toss to be tails is still 1/2. However the law of large numbers says, that since enough repetitions of tosses have come up heads, the next toss is more likely to be tails. (Which is definitely wrong?)",,"['probability', 'law-of-large-numbers', 'gambling']"
68,What is the probability of having a pentagon in 6 points,What is the probability of having a pentagon in 6 points,,"If the probability that $5$ random points in the plane whose horizontal coordinate and vertical coordinate are uniformly distributed on the interval $\left(0,1\right)$ occur to be the vertices of a convex pentagon is $\frac{49}{144}$, what is the probability that a subset of $6$ random points in the plane whose horizontal coordinate and vertical coordinate are uniformly distributed on the interval $\left(0,1\right)$ occurs to be the vertices of a convex pentagon? Thanks a lot.","If the probability that $5$ random points in the plane whose horizontal coordinate and vertical coordinate are uniformly distributed on the interval $\left(0,1\right)$ occur to be the vertices of a convex pentagon is $\frac{49}{144}$, what is the probability that a subset of $6$ random points in the plane whose horizontal coordinate and vertical coordinate are uniformly distributed on the interval $\left(0,1\right)$ occurs to be the vertices of a convex pentagon? Thanks a lot.",,"['probability', 'combinatorics', 'geometry', 'convex-analysis', 'geometric-probability']"
69,Shooting bullets [duplicate],Shooting bullets [duplicate],,"This question already has answers here : Colliding Bullets (5 answers) Closed 8 years ago . This is from http://domino.research.ibm.com/Comm/wwwr_ponder.nsf/challenges/May2014.html Every second, a gun shoots a bullet in the same direction at a random constant speed between 0 and 1. The speeds of the bullets are independent uniform random variables. Each bullet keeps the exact same speed and when two bullets collide, they are both annihilated. After shooting $n$ bullets, prove that the probability that eventually all the bullets will be annihilated is zero if $n$ is odd and $\prod_{i=1}^{n/2} \frac{2i-1}{2i}$ when $n$ is even. I tried to write recursion without success and Markov chain's but I don't see how them helps here. The case of $n\equiv 1 \pmod 2$ seems to be trivial.","This question already has answers here : Colliding Bullets (5 answers) Closed 8 years ago . This is from http://domino.research.ibm.com/Comm/wwwr_ponder.nsf/challenges/May2014.html Every second, a gun shoots a bullet in the same direction at a random constant speed between 0 and 1. The speeds of the bullets are independent uniform random variables. Each bullet keeps the exact same speed and when two bullets collide, they are both annihilated. After shooting $n$ bullets, prove that the probability that eventually all the bullets will be annihilated is zero if $n$ is odd and $\prod_{i=1}^{n/2} \frac{2i-1}{2i}$ when $n$ is even. I tried to write recursion without success and Markov chain's but I don't see how them helps here. The case of $n\equiv 1 \pmod 2$ seems to be trivial.",,['probability']
70,7 friends are going to the cinema. They will be sitting in a row with 7 seats. What is the probability that John and Mary don't sit together?,7 friends are going to the cinema. They will be sitting in a row with 7 seats. What is the probability that John and Mary don't sit together?,,"To watch a movie, John, Mary and 5 friends will sit randomly in a row with 7 seats. What is the probability John and Mary won't sit together? $$(\mathbf A)\ \frac{2\times5!}{7!}\qquad(\mathbf B)\ \frac{5!}{7!}\qquad(\mathbf C)\ \frac27\qquad(\mathbf D)\ \frac57$$ I did: $$1-\left(6\cdot 2\cdot\left(\frac{2}{7}\cdot\frac{1}{6}\right)\right) = \frac{3}{7}$$ But my book states the solution is D). I tried not multiplying by 2 and I get D), however I don't know exactly why the 2 is wrong. You can make 2 permutations with Mary(M) and John(J), MJ and JM. Then if you imagine the 2 of them as a block of 2 seats they can sit in $^6C_1=6$ places. Why doesn't my book count those 2 permutations of JM and MJ?","To watch a movie, John, Mary and 5 friends will sit randomly in a row with 7 seats. What is the probability John and Mary won't sit together? I did: But my book states the solution is D). I tried not multiplying by 2 and I get D), however I don't know exactly why the 2 is wrong. You can make 2 permutations with Mary(M) and John(J), MJ and JM. Then if you imagine the 2 of them as a block of 2 seats they can sit in places. Why doesn't my book count those 2 permutations of JM and MJ?",(\mathbf A)\ \frac{2\times5!}{7!}\qquad(\mathbf B)\ \frac{5!}{7!}\qquad(\mathbf C)\ \frac27\qquad(\mathbf D)\ \frac57 1-\left(6\cdot 2\cdot\left(\frac{2}{7}\cdot\frac{1}{6}\right)\right) = \frac{3}{7} ^6C_1=6,"['probability', 'combinatorics']"
71,"You are given 8 fair coins and flip all of them at once. Then, you can reflip as many coins as you want. What is optimal expected number of heads?","You are given 8 fair coins and flip all of them at once. Then, you can reflip as many coins as you want. What is optimal expected number of heads?",,"The problem is as in the title, where assume optimal play in the second round to maximize number of heads (so in the second round we do not reflip coins with heads in the first round). I know how to solve it by conditioning on the first outcome (the number of heads in the first round of the game). However, it ultimately leads to some binomial sums with binomials. Intuitively, I expect 4 heads on first flip, then I have 4 coins left which I flip and expect 2 heads from in the second round. In total, I get 6 heads. Is it possible to justify this line of reasoning formally?","The problem is as in the title, where assume optimal play in the second round to maximize number of heads (so in the second round we do not reflip coins with heads in the first round). I know how to solve it by conditioning on the first outcome (the number of heads in the first round of the game). However, it ultimately leads to some binomial sums with binomials. Intuitively, I expect 4 heads on first flip, then I have 4 coins left which I flip and expect 2 heads from in the second round. In total, I get 6 heads. Is it possible to justify this line of reasoning formally?",,['probability']
72,We roll a six-sided die ten times. What is the probability that the total of all ten rolls is divisible by 6?,We roll a six-sided die ten times. What is the probability that the total of all ten rolls is divisible by 6?,,"So the question is really hard I think. I tried using a simple way by calculating the probability of each combination that makes a sum divisible by six, but it would take forever. Does anyone have any ideas? Suppose that we roll a six-sided die ten times. What is the probability that the total of all ten rolls is divisible by six?","So the question is really hard I think. I tried using a simple way by calculating the probability of each combination that makes a sum divisible by six, but it would take forever. Does anyone have any ideas? Suppose that we roll a six-sided die ten times. What is the probability that the total of all ten rolls is divisible by six?",,"['probability', 'dice']"
73,Intuition for probability of drawing first ball = probability of drawing second ball,Intuition for probability of drawing first ball = probability of drawing second ball,,"From 2011 Stat 110 : A jar contains r red balls and g green balls, where r and g are fixed positive integers. A ball is drawn from the jar randomly (with all possibilities equally likely), and then a second ball is drawn randomly. Explain intuitively why the probability of the second ball being green is the same as the probability of the first ball being green. I can show this is true algebraically, but what are some intuitive explanations?","From 2011 Stat 110 : A jar contains r red balls and g green balls, where r and g are fixed positive integers. A ball is drawn from the jar randomly (with all possibilities equally likely), and then a second ball is drawn randomly. Explain intuitively why the probability of the second ball being green is the same as the probability of the first ball being green. I can show this is true algebraically, but what are some intuitive explanations?",,"['probability', 'intuition']"
74,Funny(?) Probability Problem [duplicate],Funny(?) Probability Problem [duplicate],,"This question already has answers here : Famous puzzle: Girl/Boy proportion problem (Sum of infinite series) (7 answers) Closed 7 years ago . So I ran accross the following problem today on a forum: ""In an attempt to reduce male birth rates, feminists have passed a law   which forces families to stop having children after their first male   child. After this law is passed, what is the expected ratio of male   children to female children?"" It's unclear whether families are supposed to continue having children until their first male child or if they may stop at any earlier point, but let's assume the former. Let's also assume that everybody obeys the law, and that either sex has an equal chance of being born. I thought I had a simple solution, because the problem is logically equivalent to the following process: Generate N infinite random sequences of boys and girls Cut each sequence after the first occurrence of a boy Concatenate the results and measure the ratio of boys to girls This is equivalent to generating a random sequence of boys and girls by stopping at each boy but then continuing again (up to N times), so the only difference from a normal random sequence is that this sequence always ends with a boy. However, if N grows to infinity, it seems like this last element (which can never be reached) becomes irrelevant, so the ratio of boys and girls should be 1:1 like in a normal infinite random sequence. This seems perfectly logical to me, but a few people kept insisting that it is wrong, ranting about ""biased estimators"" and claiming that the real ratio will be biased in favor of females. Is my reasoning flawed? If so, why? [EDIT] Contrary to some suggestions, I don't think this question is a duplicate. It asks about the validity of a particular approach to solving the problem, not just for a solution.","This question already has answers here : Famous puzzle: Girl/Boy proportion problem (Sum of infinite series) (7 answers) Closed 7 years ago . So I ran accross the following problem today on a forum: ""In an attempt to reduce male birth rates, feminists have passed a law   which forces families to stop having children after their first male   child. After this law is passed, what is the expected ratio of male   children to female children?"" It's unclear whether families are supposed to continue having children until their first male child or if they may stop at any earlier point, but let's assume the former. Let's also assume that everybody obeys the law, and that either sex has an equal chance of being born. I thought I had a simple solution, because the problem is logically equivalent to the following process: Generate N infinite random sequences of boys and girls Cut each sequence after the first occurrence of a boy Concatenate the results and measure the ratio of boys to girls This is equivalent to generating a random sequence of boys and girls by stopping at each boy but then continuing again (up to N times), so the only difference from a normal random sequence is that this sequence always ends with a boy. However, if N grows to infinity, it seems like this last element (which can never be reached) becomes irrelevant, so the ratio of boys and girls should be 1:1 like in a normal infinite random sequence. This seems perfectly logical to me, but a few people kept insisting that it is wrong, ranting about ""biased estimators"" and claiming that the real ratio will be biased in favor of females. Is my reasoning flawed? If so, why? [EDIT] Contrary to some suggestions, I don't think this question is a duplicate. It asks about the validity of a particular approach to solving the problem, not just for a solution.",,['probability']
75,What makes random variables exchangeable and what is implied by exchangeability?,What makes random variables exchangeable and what is implied by exchangeability?,,"Consider a $d$-dimensional random vector$\ X=(X_j)$. $\ X$ is called exchangeable if $\ (X_1,\ldots,X_d)\mathrel{\overset d =} ({X_{{j_1}}},\ldots,X_{j_d})$ for any permutation$\ j_1,\ldots, j_d$. If$\ X_j$ are iid,$\ X$ is exchangeable. The converse is false (correct me if I'm wrong). What can we say about just identically distributed $\ X_j$? What can we say about $\ X_j$ if we know that$\ X$ is exchangeable?","Consider a $d$-dimensional random vector$\ X=(X_j)$. $\ X$ is called exchangeable if $\ (X_1,\ldots,X_d)\mathrel{\overset d =} ({X_{{j_1}}},\ldots,X_{j_d})$ for any permutation$\ j_1,\ldots, j_d$. If$\ X_j$ are iid,$\ X$ is exchangeable. The converse is false (correct me if I'm wrong). What can we say about just identically distributed $\ X_j$? What can we say about $\ X_j$ if we know that$\ X$ is exchangeable?",,['probability']
76,"Show $\mathbb{E}[f(X)g(X)] \geq \mathbb{E}[f(X)]\mathbb{E}[g(X)]$ for $f,g$ bounded, nondecreasing","Show  for  bounded, nondecreasing","\mathbb{E}[f(X)g(X)] \geq \mathbb{E}[f(X)]\mathbb{E}[g(X)] f,g","Let $X$ be a random variable and let $g,f$ be real-valued, nondecreasing, and bounded. Show that $\mathbb{E}[f(X)g(X)]\geq \mathbb{E}[f(X)]\mathbb{E}[g(X)]$ Having a hard time seeing where to start for some reasons, any hints? I managed to write: $\mathbb{E}[f(X)g(X)] = \frac{1}{4}\mathbb{E}[(f(X)+g(X))^2 - (f(X)-g(X))^2]$ But I'm not sure if this is in the right direction or not.","Let $X$ be a random variable and let $g,f$ be real-valued, nondecreasing, and bounded. Show that $\mathbb{E}[f(X)g(X)]\geq \mathbb{E}[f(X)]\mathbb{E}[g(X)]$ Having a hard time seeing where to start for some reasons, any hints? I managed to write: $\mathbb{E}[f(X)g(X)] = \frac{1}{4}\mathbb{E}[(f(X)+g(X))^2 - (f(X)-g(X))^2]$ But I'm not sure if this is in the right direction or not.",,"['probability', 'probability-distributions']"
77,What is a sample path of a stochastic process,What is a sample path of a stochastic process,,"Given a probability space ($\Omega, \mathcal{F}, P$) and a measurable space ($S,\Sigma$), and an S-valued stochastic process { $X_t : t \in T$ }(assume every $X_t$ is i.i.d). What does a sample paths mean?  From the definition, it's 'the function on $T$ to the range of the process which assigns to each $t$ the value $X_t(\omega)$, where $\omega$ is a previously given fixed point in the domain of the process. But if the $\omega$ is fixed, then the value of each $X_t$ should be the same, which seems not true. What's the problem here?","Given a probability space ($\Omega, \mathcal{F}, P$) and a measurable space ($S,\Sigma$), and an S-valued stochastic process { $X_t : t \in T$ }(assume every $X_t$ is i.i.d). What does a sample paths mean?  From the definition, it's 'the function on $T$ to the range of the process which assigns to each $t$ the value $X_t(\omega)$, where $\omega$ is a previously given fixed point in the domain of the process. But if the $\omega$ is fixed, then the value of each $X_t$ should be the same, which seems not true. What's the problem here?",,"['probability', 'stochastic-processes']"
78,Probability of of an event happening at least once in a sequence of independent events?,Probability of of an event happening at least once in a sequence of independent events?,,"I want to find the probability of flipping heads at least once if you flip a coin two times. The possible outcomes (we don't care about the order) are (each equally likely) $TT$ , $TH$ , $HT$ , $HH$ . Three out of four have an $H$ in them, so the probability is $\large \frac 34$ . Is this correct? Is there a better and efficient way (especially when dealing with a higher number of flips? Please use only very basic terminology and concepts from probability because I've never taken a class. Thanks.","I want to find the probability of flipping heads at least once if you flip a coin two times. The possible outcomes (we don't care about the order) are (each equally likely) , , , . Three out of four have an in them, so the probability is . Is this correct? Is there a better and efficient way (especially when dealing with a higher number of flips? Please use only very basic terminology and concepts from probability because I've never taken a class. Thanks.",TT TH HT HH H \large \frac 34,['probability']
79,Roadmap to SPDEs,Roadmap to SPDEs,,"I'm trying to learn about the Kushner-Stratonovich-Pardoux equations in filtering theory. I'm familiar with Itô calculus at the level of Øksendal's book (but struggle with much of Karatzas and Shreve, for example). My PDE theory is pretty weak. I know about the Fokker-Planck equations, and that's about it. My guess is that before I begin reading, I'll need to learn a significant amount of classical PDE theory. I would appreciate any recommendations for PDE textbooks that emphasize material that will be useful in the study of SPDEs. If someone could recommend a gentle introduction to SPDEs to go with it, I would be very grateful. Many thanks.","I'm trying to learn about the Kushner-Stratonovich-Pardoux equations in filtering theory. I'm familiar with Itô calculus at the level of Øksendal's book (but struggle with much of Karatzas and Shreve, for example). My PDE theory is pretty weak. I know about the Fokker-Planck equations, and that's about it. My guess is that before I begin reading, I'll need to learn a significant amount of classical PDE theory. I would appreciate any recommendations for PDE textbooks that emphasize material that will be useful in the study of SPDEs. If someone could recommend a gentle introduction to SPDEs to go with it, I would be very grateful. Many thanks.",,"['probability', 'partial-differential-equations', 'reference-request', 'stochastic-processes']"
80,"In a deck of cards, do a queen and a non-queen have equal chances of being the card that follows the first queen?","In a deck of cards, do a queen and a non-queen have equal chances of being the card that follows the first queen?",,"I encountered the following problem: From a shuffled deck the cards are flipped one by one until a queen shows up. Then again a card is flipped. Is it more likely that this card is the Jack of Spades or the Queen of Hearts? I managed to solve this by first finding the probability that the card will be the Jack of Spades under the extra condition that the rank of the Jack of Spades is $n$ . If $J_s$ denotes the event that the Jack of Spades is the card and $N$ denotes the rank of the Jack of Spades then: $$P(J_s\mid N=n)=\binom{52-n}3\times\binom{51}4^{-1}$$ This because under condition $N=n$ there are $\binom{51}4$ possibilities for the $4$ queens of which $\binom{52-n}3$ are favorable. Applying the hockey stick identity and the law of total probability we then find: $$P(J_s)=\frac1{52}$$ From this it can be deduced easily that also $P(Q_h)=\frac1{52}$ so apparantly the chances are equal. This amazed me because I could not find an explaining symmetry for that. My question arises from the fact that I am simply not satisfied with this solution and is: Could someone give me a ""nicer"" solution that avoids calculations and rests on something like a smart perspective of the case? I just feel that a nicer and more direct solution can be found. Thank you for taking notice of my question, which is purely an effort to enrich my intuitions on probability. Edit Thank you for comments already, but if you have a real answer then please do not hesitate to provide one. And preferably a complete one. Also: more perspectives will  imply a larger enrichment of my intuition. Thank you in advance.","I encountered the following problem: From a shuffled deck the cards are flipped one by one until a queen shows up. Then again a card is flipped. Is it more likely that this card is the Jack of Spades or the Queen of Hearts? I managed to solve this by first finding the probability that the card will be the Jack of Spades under the extra condition that the rank of the Jack of Spades is . If denotes the event that the Jack of Spades is the card and denotes the rank of the Jack of Spades then: This because under condition there are possibilities for the queens of which are favorable. Applying the hockey stick identity and the law of total probability we then find: From this it can be deduced easily that also so apparantly the chances are equal. This amazed me because I could not find an explaining symmetry for that. My question arises from the fact that I am simply not satisfied with this solution and is: Could someone give me a ""nicer"" solution that avoids calculations and rests on something like a smart perspective of the case? I just feel that a nicer and more direct solution can be found. Thank you for taking notice of my question, which is purely an effort to enrich my intuitions on probability. Edit Thank you for comments already, but if you have a real answer then please do not hesitate to provide one. And preferably a complete one. Also: more perspectives will  imply a larger enrichment of my intuition. Thank you in advance.",n J_s N P(J_s\mid N=n)=\binom{52-n}3\times\binom{51}4^{-1} N=n \binom{51}4 4 \binom{52-n}3 P(J_s)=\frac1{52} P(Q_h)=\frac1{52},"['probability', 'combinatorics', 'intuition', 'alternative-proof', 'card-games']"
81,Examples of analysis results using probability theory,Examples of analysis results using probability theory,,"Sometimes, nice results from analysis appear unexpectedly in probability theory. Here are a couple of examples: $1.$ If $Z \sim \mathcal{N}(0,1)$, then $Z^2 \sim \Gamma(1/2,2)$ When we want to prove this, we find that $Z^2$ has density function $x \mapsto \sqrt{2\pi}^{-1} x^{-1/2} e^{-x/2}$ for $x \geq 0$ and comparing this to the density function of the gamma $(1/2,2)$ distribution, and using the fact that $\int_{-\infty}^{+ \infty} f(x)dx = 1$ for a density function $f$, it follows that $\boxed{\Gamma(1/2) = \sqrt{\pi}}$ $2.$ If $X \sim \Gamma(\alpha_1, \beta), Y \sim \Gamma( \alpha_2, \beta)$ and $X,Y$ are independent, then $X+Y \sim\Gamma(\alpha_1 + \alpha_2, \beta)$ While proving this, one can find the identity $$\boxed{\int_0^1 u^{\alpha_1 -1}(1-u)^{\alpha_2 -1}du = \frac{\Gamma(\alpha_1)\Gamma(\alpha_2)}{\Gamma(\alpha_1 + \alpha_2)}}$$ So my question is: what are other examples where we can find interesting results from analysis (or other other branches of mathematics) using probability theory?","Sometimes, nice results from analysis appear unexpectedly in probability theory. Here are a couple of examples: $1.$ If $Z \sim \mathcal{N}(0,1)$, then $Z^2 \sim \Gamma(1/2,2)$ When we want to prove this, we find that $Z^2$ has density function $x \mapsto \sqrt{2\pi}^{-1} x^{-1/2} e^{-x/2}$ for $x \geq 0$ and comparing this to the density function of the gamma $(1/2,2)$ distribution, and using the fact that $\int_{-\infty}^{+ \infty} f(x)dx = 1$ for a density function $f$, it follows that $\boxed{\Gamma(1/2) = \sqrt{\pi}}$ $2.$ If $X \sim \Gamma(\alpha_1, \beta), Y \sim \Gamma( \alpha_2, \beta)$ and $X,Y$ are independent, then $X+Y \sim\Gamma(\alpha_1 + \alpha_2, \beta)$ While proving this, one can find the identity $$\boxed{\int_0^1 u^{\alpha_1 -1}(1-u)^{\alpha_2 -1}du = \frac{\Gamma(\alpha_1)\Gamma(\alpha_2)}{\Gamma(\alpha_1 + \alpha_2)}}$$ So my question is: what are other examples where we can find interesting results from analysis (or other other branches of mathematics) using probability theory?",,"['probability', 'analysis']"
82,Existence of the law of a random variable,Existence of the law of a random variable,,"Here is the definition of the law of a random variable. Let $X$ be a random variable on $(\Omega,\mathcal{F}, \mathbb{P})$. Then, the law of $X$, denoted by $L_{X}$, is a probability measure on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ such that for all $B \in \mathcal{B}$, $L_X(B) = \mathbb{P}(X \in B)$, where $\mathcal{B}$ denotes the Borel set of $\mathbb{R}$. I understand the definition, but what I am wondering is that, how do we know such $L_X$ as in this definition exist? Can we construct one explicitly? or do we know, by some theorem, that at least one $L_X$ exists?","Here is the definition of the law of a random variable. Let $X$ be a random variable on $(\Omega,\mathcal{F}, \mathbb{P})$. Then, the law of $X$, denoted by $L_{X}$, is a probability measure on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ such that for all $B \in \mathcal{B}$, $L_X(B) = \mathbb{P}(X \in B)$, where $\mathcal{B}$ denotes the Borel set of $\mathbb{R}$. I understand the definition, but what I am wondering is that, how do we know such $L_X$ as in this definition exist? Can we construct one explicitly? or do we know, by some theorem, that at least one $L_X$ exists?",,"['probability', 'probability-theory']"
83,A mysterious limit: probability that a triangle captures the centre of a circle.,A mysterious limit: probability that a triangle captures the centre of a circle.,,"On a circle, choose $6n$ $(n\in\mathbb{Z^+})$ uniformly random points and label them $a_0,a_1,a_2,\dots,a_{6n-1}$ going anticlockwise, with $a_0$ chosen randomly. Draw three chords: Chord $a_0 a_{3n}$ Chord $a_n a_{4n}$ Chord $a_{2n} a_{5n}$ Here is an example with $n=5$ . The rightmost point is $a_0$ . The centre of the circle is shown. Let $P(n)=$ probability that the triangle formed by the three chords contains the centre of the circle. What is $\lim\limits_{n\to\infty}P(n)$ ? Intuition When I came up with this question, I had no intuition as to whether $P(n)$ should increase or decrease, as $n$ increases. Intuitively, as $n$ increases, the expected area of the triangle should decrease, which tends to make $P(n)$ decrease. But at the same time, the triangle should ""get closer"" to the circle's centre (e.g. the expectation of the distance between the triangle's centroid and the circle's centre, should decrease), which tends to make $P(n$ ) increase. It was not clear to me which of these opposing factors should dominate. Simulations Simulations, with $5\times10^6$ sets of three chords for each value of $n$ , yielded the following estimated probabilities: $P(1)\approx 0.0625\space$ (I prove that $P(1)=\frac{1}{16}$ below.) $P(2)\approx 0.0741\overset{?}{=}\frac{2}{27}$ $P(3)\approx 0.0786$ $P(4)\approx 0.0809$ $P(5)\approx 0.0824$ $P(6)\approx 0.0832$ $P(10)\approx 0.0849$ I also got $P(100)\approx 0.0872$ based on a simulation with $10^6$ sets of three chords. I tried to get an approximation for $P(1000)$ , but my computer started overheating (I'm using Excel for my simulations). Here is a plot of estimated $P(n)$ against $n$ . So as $n$ increases, it seems that $P(n)$ is approaching some number strictly between $0$ and $1$ . Due to the naturalness of my question's geometric construction, I suspect that $\lim\limits_{n\to\infty}P(n)$ has a closed form, and it should be an interesting number worth finding. I also suspect that $P(n)$ is a rational sequence. My attempt I have only been able to prove that $P(1)=\frac{1}{16}$ . Here is my proof. Suppose that: When we choose the six random points on the circle, instead of having a continuous distribution of points to choose from, we have $2k$ evenly spaced points to choose from, where $k$ is a large integer. The circumference of the circle is $2k$ . A point can be chosen more than once. Let $x=$ distance from $a_0$ to $a_3$ along the circle going anticlockwise. Let $y=$ distance from $a_2$ to $a_5$ along the circle going anticlockwise. Let $z=$ distance from $a_1$ to $a_4$ along the circle going anticlockwise. If the triangle contains the centre of the circle, then either $x\le k$ and $y\le k$ and $z\ge k$ , or $x\ge k$ and $y\ge k$ and $z\le k$ . These two configurations are shown respectively below, where $a_0$ is the rightmost point in each diagram. By symmetry, each of these happens with equal probability, so we have: $$P(1)=2\times P(x\le k \land y\le k\land z\ge k)$$ To see these distances more clearly, imagine cutting the circle at $a_0$ and straightening the circle into a line segment, so that the points from left to right are $a_0, a_1, a_2, a_3, a_4, a_5$ . To understand the next part, it may be easier to first work with specific numbers, so let's suppose $k=100$ , and suppose $\color{red}{x=10}$ . Then $90\le y \le 100$ . If $y=90$ , there is only $\color{blue}{1}$ possible combination of locations for $a_1$ and $a_4$ (because we require $z\ge 100$ ). If $y=91$ then there are $(1)+(1+2)=\color{blue}{4}$ possible combinations of locations for $a_1$ and $a_4$ . If $y=92$ then there are $(1)+(1+2)+(1+2+3)=\color{blue}{10}$ possible combinations of locations for $a_1$ and $a_4$ . $\cdots$ If $y=100$ then there are $(1)+(1+2)+(1+2+3)+\cdots+(1+2+3+\cdots+11)=\color{blue}{286}$ possible combinations for $a_1$ and $a_4$ . So for $\color{red}{x=10}$ , the total number of possible combinations for $a_1$ and $a_4$ is $\color{blue}{1+4+10+\dots+286}=1001$ . The numbers $1,4,10,\dots,286$ are the tetrahedral numbers . The sum of the first $x+1$ tetrahedral numbers is $\binom{x+4}{4}$ . So the total number of combinations of $a_1, a_2, a_3, a_4, a_5$ that satisfy $(x\le k \land y\le k\land z\ge k)$ is $\sum\limits_{x=0}^{k}\binom{x+4}{4}$ . So the probability that $(x\le k \land y\le k\land z\ge k)$ is $\sum\limits_{x=0}^{k}\binom{x+4}{4}$ divided by the total number of ways to choose $a_1, a_2, a_3, a_4, a_5$ , which is $\binom{2k}{5}$ . To change from a discrete back to a continuous distribution of available points along the circle, we take the limit as $k\to\infty$ . Remembering that $P(1)=2\times P(x\le k \land y\le k\land z\ge k)$ , we have: $\begin{align} P(1)&=2\lim\limits_{k\to\infty}\frac{\sum\limits_{x=0}^k\binom{x+4}{4}}{\binom{2k}{5}}\\ &=2\lim\limits_{k\to\infty}\frac{\sum\limits_{x=0}^k\frac{x^4}{4!}}{\frac{2^5}{5!}k^5}\\ &=2\lim\limits_{k\to\infty}\frac{\frac{1}{4!}\cdot\frac{1}{5}k^5}{\frac{2^5}{5!}k^5}\\ &=\frac{1}{16} \end{align}$","On a circle, choose uniformly random points and label them going anticlockwise, with chosen randomly. Draw three chords: Chord Chord Chord Here is an example with . The rightmost point is . The centre of the circle is shown. Let probability that the triangle formed by the three chords contains the centre of the circle. What is ? Intuition When I came up with this question, I had no intuition as to whether should increase or decrease, as increases. Intuitively, as increases, the expected area of the triangle should decrease, which tends to make decrease. But at the same time, the triangle should ""get closer"" to the circle's centre (e.g. the expectation of the distance between the triangle's centroid and the circle's centre, should decrease), which tends to make ) increase. It was not clear to me which of these opposing factors should dominate. Simulations Simulations, with sets of three chords for each value of , yielded the following estimated probabilities: (I prove that below.) I also got based on a simulation with sets of three chords. I tried to get an approximation for , but my computer started overheating (I'm using Excel for my simulations). Here is a plot of estimated against . So as increases, it seems that is approaching some number strictly between and . Due to the naturalness of my question's geometric construction, I suspect that has a closed form, and it should be an interesting number worth finding. I also suspect that is a rational sequence. My attempt I have only been able to prove that . Here is my proof. Suppose that: When we choose the six random points on the circle, instead of having a continuous distribution of points to choose from, we have evenly spaced points to choose from, where is a large integer. The circumference of the circle is . A point can be chosen more than once. Let distance from to along the circle going anticlockwise. Let distance from to along the circle going anticlockwise. Let distance from to along the circle going anticlockwise. If the triangle contains the centre of the circle, then either and and , or and and . These two configurations are shown respectively below, where is the rightmost point in each diagram. By symmetry, each of these happens with equal probability, so we have: To see these distances more clearly, imagine cutting the circle at and straightening the circle into a line segment, so that the points from left to right are . To understand the next part, it may be easier to first work with specific numbers, so let's suppose , and suppose . Then . If , there is only possible combination of locations for and (because we require ). If then there are possible combinations of locations for and . If then there are possible combinations of locations for and . If then there are possible combinations for and . So for , the total number of possible combinations for and is . The numbers are the tetrahedral numbers . The sum of the first tetrahedral numbers is . So the total number of combinations of that satisfy is . So the probability that is divided by the total number of ways to choose , which is . To change from a discrete back to a continuous distribution of available points along the circle, we take the limit as . Remembering that , we have:","6n (n\in\mathbb{Z^+}) a_0,a_1,a_2,\dots,a_{6n-1} a_0 a_0 a_{3n} a_n a_{4n} a_{2n} a_{5n} n=5 a_0 P(n)= \lim\limits_{n\to\infty}P(n) P(n) n n P(n) P(n 5\times10^6 n P(1)\approx 0.0625\space P(1)=\frac{1}{16} P(2)\approx 0.0741\overset{?}{=}\frac{2}{27} P(3)\approx 0.0786 P(4)\approx 0.0809 P(5)\approx 0.0824 P(6)\approx 0.0832 P(10)\approx 0.0849 P(100)\approx 0.0872 10^6 P(1000) P(n) n n P(n) 0 1 \lim\limits_{n\to\infty}P(n) P(n) P(1)=\frac{1}{16} 2k k 2k x= a_0 a_3 y= a_2 a_5 z= a_1 a_4 x\le k y\le k z\ge k x\ge k y\ge k z\le k a_0 P(1)=2\times P(x\le k \land y\le k\land z\ge k) a_0 a_0, a_1, a_2, a_3, a_4, a_5 k=100 \color{red}{x=10} 90\le y \le 100 y=90 \color{blue}{1} a_1 a_4 z\ge 100 y=91 (1)+(1+2)=\color{blue}{4} a_1 a_4 y=92 (1)+(1+2)+(1+2+3)=\color{blue}{10} a_1 a_4 \cdots y=100 (1)+(1+2)+(1+2+3)+\cdots+(1+2+3+\cdots+11)=\color{blue}{286} a_1 a_4 \color{red}{x=10} a_1 a_4 \color{blue}{1+4+10+\dots+286}=1001 1,4,10,\dots,286 x+1 \binom{x+4}{4} a_1, a_2, a_3, a_4, a_5 (x\le k \land y\le k\land z\ge k) \sum\limits_{x=0}^{k}\binom{x+4}{4} (x\le k \land y\le k\land z\ge k) \sum\limits_{x=0}^{k}\binom{x+4}{4} a_1, a_2, a_3, a_4, a_5 \binom{2k}{5} k\to\infty P(1)=2\times P(x\le k \land y\le k\land z\ge k) \begin{align}
P(1)&=2\lim\limits_{k\to\infty}\frac{\sum\limits_{x=0}^k\binom{x+4}{4}}{\binom{2k}{5}}\\
&=2\lim\limits_{k\to\infty}\frac{\sum\limits_{x=0}^k\frac{x^4}{4!}}{\frac{2^5}{5!}k^5}\\
&=2\lim\limits_{k\to\infty}\frac{\frac{1}{4!}\cdot\frac{1}{5}k^5}{\frac{2^5}{5!}k^5}\\
&=\frac{1}{16}
\end{align}","['probability', 'integration', 'limits', 'circles', 'geometric-probability']"
84,Intuitive explanation of variance and moment in Probability,Intuitive explanation of variance and moment in Probability,,"While I understand the intuition behind expectation, I don't really understand the meaning of variance and moment. What is a good way to think of those two terms?","While I understand the intuition behind expectation, I don't really understand the meaning of variance and moment. What is a good way to think of those two terms?",,"['probability', 'intuition', 'probability-theory']"
85,On clarifying the relationship between distribution functions in measure theory and probability theory,On clarifying the relationship between distribution functions in measure theory and probability theory,,"I recently found myself confusing concepts from measure theory and probability theory, so I'd like to get an idea for what I'm misunderstanding. This definition is what started it all: A sequence $\{X_{n}\}$ of random variables converges in distribution to $X$ if $$\lim_{n \to \infty} F_{n}(x) = F(x)$$ for every number $x \in \mathbb{R}$ at which $F$ is continuous. Concerns: 1) Recalling that random variables are really just measurable functions, am I to understand that each distinct measurable function is associated with a unique Distribution Function by which its probability content is evaluated? I was always under the impression that we use the Lebesgue measure (and its corresponding Distribution Function) to calculate the probability of random variables we encounter in general (except in abstract spaces). Is this just flat out wrong? 2) I also know that for any increasing, right-continuous function $F: \mathbb{R} \to \mathbb{R}$, there is a unique Borel measure $\mu_{F}$ such that $\mu_{F}((a,b]) = F(b) - F(a)$ for all $a,b$. Conversely, given a Borel measure on $\mathbb{R}$ that is finite and bounded on all Borel sets, we can uniquely associate it with a real-valued, right-continuous and increasing function. Okay, so by Littlewood's principles, we know that measurable functions are nearly continuous. So this could justify associating each random variable $X_{n}$ with a unique Distribution Function $F_{n}$. But random variables (i.e., measurable functions) don't have to be increasing, so that adds to my confusion. Short Summary: 1) To calculate the probability of a generic real-valued random variable, do we just use the CDF associated with Lebesgue measure, or does the random variable have its own CDF? 2) If we can associate a CDF to a general random variable, how is this done is the function is not increasing?","I recently found myself confusing concepts from measure theory and probability theory, so I'd like to get an idea for what I'm misunderstanding. This definition is what started it all: A sequence $\{X_{n}\}$ of random variables converges in distribution to $X$ if $$\lim_{n \to \infty} F_{n}(x) = F(x)$$ for every number $x \in \mathbb{R}$ at which $F$ is continuous. Concerns: 1) Recalling that random variables are really just measurable functions, am I to understand that each distinct measurable function is associated with a unique Distribution Function by which its probability content is evaluated? I was always under the impression that we use the Lebesgue measure (and its corresponding Distribution Function) to calculate the probability of random variables we encounter in general (except in abstract spaces). Is this just flat out wrong? 2) I also know that for any increasing, right-continuous function $F: \mathbb{R} \to \mathbb{R}$, there is a unique Borel measure $\mu_{F}$ such that $\mu_{F}((a,b]) = F(b) - F(a)$ for all $a,b$. Conversely, given a Borel measure on $\mathbb{R}$ that is finite and bounded on all Borel sets, we can uniquely associate it with a real-valued, right-continuous and increasing function. Okay, so by Littlewood's principles, we know that measurable functions are nearly continuous. So this could justify associating each random variable $X_{n}$ with a unique Distribution Function $F_{n}$. But random variables (i.e., measurable functions) don't have to be increasing, so that adds to my confusion. Short Summary: 1) To calculate the probability of a generic real-valued random variable, do we just use the CDF associated with Lebesgue measure, or does the random variable have its own CDF? 2) If we can associate a CDF to a general random variable, how is this done is the function is not increasing?",,"['probability', 'measure-theory', 'probability-theory']"
86,Probability that the sum of three integer numbers (from 1 to 100) is more than 100,Probability that the sum of three integer numbers (from 1 to 100) is more than 100,,"I have an urn with $100$ balls. Each ball has a number in it, from $1$ to $100$. I take three balls from the urn without putting the balls again in the urn. I sum the three numbers obtained. What's the probability that the sum of the three numbers is more than $100$? How to explain the procedure to calculate this probability?","I have an urn with $100$ balls. Each ball has a number in it, from $1$ to $100$. I take three balls from the urn without putting the balls again in the urn. I sum the three numbers obtained. What's the probability that the sum of the three numbers is more than $100$? How to explain the procedure to calculate this probability?",,"['probability', 'combinatorics', 'conditional-probability']"
87,How many times do I roll an unfair die to determine its bias?,How many times do I roll an unfair die to determine its bias?,,"This question comes from computer security, but I'll distill it into a probability question: I have a biased die with 96 sides.  95 sides are equiprobable, each having a 1% chance of landing up.  The remaining side, side X, has a 5% chance. All sides look identical; I want to identify side X.  My best strategy is obviously to roll it a bunch of times and take the majority, but my question is this: how many rolls are needed until Pr{X is majority result} > p for any given p > 1/2?","This question comes from computer security, but I'll distill it into a probability question: I have a biased die with 96 sides.  95 sides are equiprobable, each having a 1% chance of landing up.  The remaining side, side X, has a 5% chance. All sides look identical; I want to identify side X.  My best strategy is obviously to roll it a bunch of times and take the majority, but my question is this: how many rolls are needed until Pr{X is majority result} > p for any given p > 1/2?",,"['probability', 'dice']"
88,recurrence relation arising from Magic the Gathering scenario [duplicate],recurrence relation arising from Magic the Gathering scenario [duplicate],,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Probability of a random binary string containing a long run of 1s? EDIT : Cocopuffs below has partially answered the question, but the critical base case $L=2$ to his inductive argument is missing and it's not obvious how to fill the gap. This original problem is described in this thread at community.wizards.com. It originated as a question about a Magic: the Gathering scenario, but I will rephrase it here in general audience terms. Suppose you have \$0, and your friend has \$L. You start flipping coins. Every time you flip heads, you win \$2 and your friend wins \$1. Every time you flip tails, you lose all of your money. What is the probability you will eventually have (at least) as much money as your friend? As outlined in the thread above, the probability $p(L)$ of you eventually matching your friend is given by the recurrence relation $$p(L) = \frac{1}{2^{L-1}} + \sum_{i=1}^{L-1} \frac{p(L+i)}{2^i}.$$ Other than the trivial observation that $p(L) = 1$ is a solution to this recurrence, I haven't been able to make headway. How do I prove this solution is unique (and therefore the right one)?","This question already has answers here : Closed 11 years ago . Possible Duplicate: Probability of a random binary string containing a long run of 1s? EDIT : Cocopuffs below has partially answered the question, but the critical base case $L=2$ to his inductive argument is missing and it's not obvious how to fill the gap. This original problem is described in this thread at community.wizards.com. It originated as a question about a Magic: the Gathering scenario, but I will rephrase it here in general audience terms. Suppose you have \$0, and your friend has \$L. You start flipping coins. Every time you flip heads, you win \$2 and your friend wins \$1. Every time you flip tails, you lose all of your money. What is the probability you will eventually have (at least) as much money as your friend? As outlined in the thread above, the probability $p(L)$ of you eventually matching your friend is given by the recurrence relation $$p(L) = \frac{1}{2^{L-1}} + \sum_{i=1}^{L-1} \frac{p(L+i)}{2^i}.$$ Other than the trivial observation that $p(L) = 1$ is a solution to this recurrence, I haven't been able to make headway. How do I prove this solution is unique (and therefore the right one)?",,"['probability', 'recurrence-relations']"
89,How small the probability $\Bbb{P}(X_1+X_2 +\dots +X_n < n + 1)$ can be if $\Bbb{E}(X_i) = 1$?,How small the probability  can be if ?,\Bbb{P}(X_1+X_2 +\dots +X_n < n + 1) \Bbb{E}(X_i) = 1,"Let $X_1, X_2, \dots, X_n$ be $n$ nonnegative independent identically   distributed random variables with the same expectation:  $$\forall 1 \le i \le n: \quad \Bbb{E}(X_i) = 1$$ How small the probability $\Bbb{P}(X_1+X_2 +\dots +X_n < n + 1)$ can   be? Ideally, for the fixed $n$, we need to find an infimum of this probability over all possible distributions of $X_i$ and then see if the lower bound can ever be achieved. The natural idea is to rewrite the probability in question in the following form: $$\Bbb{P}\left(\dfrac{X_1+X_2 +\dots +X_n}{n} < 1 + \dfrac{1}{n}\right)$$ Here appears the average of $X_1, X_2, \dots, X_n$, but I'm not sure what can be done next. I'm also interested in solving the generalized version of the problem for random variables that are not necessarily identically distributed. Any suggestions, hints on how to approach this problem, and useful comments would be greatly appreciated.","Let $X_1, X_2, \dots, X_n$ be $n$ nonnegative independent identically   distributed random variables with the same expectation:  $$\forall 1 \le i \le n: \quad \Bbb{E}(X_i) = 1$$ How small the probability $\Bbb{P}(X_1+X_2 +\dots +X_n < n + 1)$ can   be? Ideally, for the fixed $n$, we need to find an infimum of this probability over all possible distributions of $X_i$ and then see if the lower bound can ever be achieved. The natural idea is to rewrite the probability in question in the following form: $$\Bbb{P}\left(\dfrac{X_1+X_2 +\dots +X_n}{n} < 1 + \dfrac{1}{n}\right)$$ Here appears the average of $X_1, X_2, \dots, X_n$, but I'm not sure what can be done next. I'm also interested in solving the generalized version of the problem for random variables that are not necessarily identically distributed. Any suggestions, hints on how to approach this problem, and useful comments would be greatly appreciated.",,"['probability', 'optimization', 'upper-lower-bounds']"
90,What is the intuition for using sigma algebras to define probability spaces?,What is the intuition for using sigma algebras to define probability spaces?,,"When I was taught probability in school, we studied basic events like coin flips $\lbrace H,T\rbrace$ or rolling a die $\lbrace 1,2,3,4,5,6\rbrace$. Let's take coin flips as an example. Suppose $\Omega =\lbrace H,T\rbrace$. $\mathcal{F} =\lbrace \emptyset,\lbrace H\rbrace,\lbrace T\rbrace, \lbrace H,T\rbrace \rbrace$. Then $\emptyset,\Omega \in \mathcal{F}$ Closed under complementation (e.g. if $A = \lbrace H\rbrace$ then $A^c = \lbrace T\rbrace$ and both are in $\mathcal{F}$) Closed under countable unions (e.g. $A = \emptyset \cup \lbrace H\rbrace = \lbrace H\rbrace \in \mathcal{F}$) So I get how it works in these simple examples. But I don't get why all this fancy terminology is necessary. Why do I need this elaborate structure to be able to describe a coin flip? Isn't it enough just to have the event set $\Omega$ and a function $\Bbb P$ that can map each event onto a number? Why do I need the sigma algebra?","When I was taught probability in school, we studied basic events like coin flips $\lbrace H,T\rbrace$ or rolling a die $\lbrace 1,2,3,4,5,6\rbrace$. Let's take coin flips as an example. Suppose $\Omega =\lbrace H,T\rbrace$. $\mathcal{F} =\lbrace \emptyset,\lbrace H\rbrace,\lbrace T\rbrace, \lbrace H,T\rbrace \rbrace$. Then $\emptyset,\Omega \in \mathcal{F}$ Closed under complementation (e.g. if $A = \lbrace H\rbrace$ then $A^c = \lbrace T\rbrace$ and both are in $\mathcal{F}$) Closed under countable unions (e.g. $A = \emptyset \cup \lbrace H\rbrace = \lbrace H\rbrace \in \mathcal{F}$) So I get how it works in these simple examples. But I don't get why all this fancy terminology is necessary. Why do I need this elaborate structure to be able to describe a coin flip? Isn't it enough just to have the event set $\Omega$ and a function $\Bbb P$ that can map each event onto a number? Why do I need the sigma algebra?",,"['probability', 'probability-theory']"
91,(Elementary) Markov property of the Brownian motion,(Elementary) Markov property of the Brownian motion,,"Let $B=(B_t)_{t\ge 0}$ be a Brownian motion on a probability space $(\Omega,\mathcal A,\operatorname{P})$, i.e. $B$ is a real-valued stochastic process with $B_0=0$ almost surely $B$ has independent and stationary increments $B_t\sim\mathcal{N}_{0,\;t}$ $B$ is almost surely continuous Here, stationary increments means, that $$B_{s+t}-B_t\sim B_s\;\;\;\text{for all }s,t\ge 0\;.$$  It's easy to verify, that $B$ has the following property: $(B_{s+t}-B_t)_{s\ge 0}$ is a Brownian motion independent of $(B_s)_{s\le t}$, for all $s<t$. Some people call this property Markov property . However, the definition of the elementary Markov property , that I know, is as follows: Let $I\subseteq\mathbb{R}$ and $E$ be a Polish space. A stochastic process $X=(X_t)_{t\in I}$ with values in $E$ has the elementary Markov property $:\Leftrightarrow$ $$\operatorname{P}\left[X_t\in A\mid\mathcal{F}_s\right]=\operatorname{P}\left[X_t\in A\mid X_s\right]\;\;\;\text{for all }A\in\mathcal{B}(E)\text{ and }s,t\in I\text{ with }s\le t\;,$$ where $(\mathcal{F}_t)_{t\in I})$ is the filtration generated by $X$ and $\mathcal{B}(E)$ is the Borel $\sigma$-algebra on $E$. In the case of the Brownian motion $B$: Can we show, that both properties are equivalent or one implies the other?","Let $B=(B_t)_{t\ge 0}$ be a Brownian motion on a probability space $(\Omega,\mathcal A,\operatorname{P})$, i.e. $B$ is a real-valued stochastic process with $B_0=0$ almost surely $B$ has independent and stationary increments $B_t\sim\mathcal{N}_{0,\;t}$ $B$ is almost surely continuous Here, stationary increments means, that $$B_{s+t}-B_t\sim B_s\;\;\;\text{for all }s,t\ge 0\;.$$  It's easy to verify, that $B$ has the following property: $(B_{s+t}-B_t)_{s\ge 0}$ is a Brownian motion independent of $(B_s)_{s\le t}$, for all $s<t$. Some people call this property Markov property . However, the definition of the elementary Markov property , that I know, is as follows: Let $I\subseteq\mathbb{R}$ and $E$ be a Polish space. A stochastic process $X=(X_t)_{t\in I}$ with values in $E$ has the elementary Markov property $:\Leftrightarrow$ $$\operatorname{P}\left[X_t\in A\mid\mathcal{F}_s\right]=\operatorname{P}\left[X_t\in A\mid X_s\right]\;\;\;\text{for all }A\in\mathcal{B}(E)\text{ and }s,t\in I\text{ with }s\le t\;,$$ where $(\mathcal{F}_t)_{t\in I})$ is the filtration generated by $X$ and $\mathcal{B}(E)$ is the Borel $\sigma$-algebra on $E$. In the case of the Brownian motion $B$: Can we show, that both properties are equivalent or one implies the other?",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
92,What is the intuition of why convergence in distribution does not imply convergence in probability,What is the intuition of why convergence in distribution does not imply convergence in probability,,"For me its very counter intuitive (that convergence in Probability and Distribution are not the same), because, conceptually, if two random variables have the same distribution, then they should be considered the same random variable. I know this is wrong. I am not sure why but its wrong (hence the question). Maybe, does it mean they are the same (isomorphic) w.r.t. to their pdf/cdf/pmf? Anyway, I want to understand why I am wrong and fix my mathematical intuition. The reason I am complaining is because I am completely aware of a counter example. In fact I will provide it in the appendix of this question, however, even after seeing the counter example, I am not sure I could have come up with it. In fact even after seeing a counter example, it still feels wrong. I was wondering if someone could provide a way of how one would come up with such a counter example (or maybe a counter example that is much more obvious), or maybe explain to me why it should be obvious that one can come up with such a counter example. Appendix: Recall the definitions of convergence in distribution and convergence in probability: Convergence in distribution (D): $$ \lim_{n \rightarrow \infty} | F_{X_n}(x) - F(x)| = 0, \forall x \in X$$ Convergence in probability (P) for sufficiently large $N$ and $\forall \epsilon > 0$: $$ \lim_{n \rightarrow \infty} Pr[ | X_n - X | \geq \epsilon]= 0$$ i.e. if one goes sufficiently far the sequence of random variables, then, $X_n$ will converge to $X$ (in probability). I will show the counter example for: $$D \not\implies P$$ Consider a Bernoulli random variable $X$ with probability of success $\frac{1}{2}$. Now define $X_n$ to be equal to $X$, i.e. $$X_n = X$$ Therefore, obviously since they are the same r.v. they have the same distribution. Now define: $$Y = 1 - X$$ Obviously, $Y$ has the same distribution as $X$ and hence, also as $X_n$. So $X_N$ converges in distribution to $Y$. But, do they converge in probability? If they do then: $$ \lim_{n \rightarrow \infty} Pr[ | X_n - Y | \geq \epsilon]= 0$$ i.e. we want their difference to be larger than $\epsilon$ very rarely (in fact we want that event to have zero probability zero as n goes to infinity). Let's figure out the distance between these two random variables $X_n$ and $Y$: $$| X_n - Y | = |X_N - (1 - X)| = |X -  1 + X| = |2X - 1| = 1$$ Therefore, their distance is always 1, no matter what. We want their distance to be very far for any $\epsilon$, but notice that for the choice of $\epsilon = \frac{1}{2}$, that the distance between $| X_n - Y | = 1$ is indeed greater than the tolerable threshold (i.e. $1 = | X_n - Y | > \epsilon = \frac{1}{2} $ with probability 1). So for sure their distance is more than $\epsilon$. It doesn't matter what value of $n$ we choose (i.e. it doesn't matter how far we go down the sequence), they are for sure too far apart. More precisely: $$ \lim_{n \rightarrow \infty}Pr[ | X_n - Y | \geq \epsilon ] = Pr[ 1 \geq \frac{1}{2} ] = 1 $$ which is the opposite of what we need for convergence in probability. End of counter example.","For me its very counter intuitive (that convergence in Probability and Distribution are not the same), because, conceptually, if two random variables have the same distribution, then they should be considered the same random variable. I know this is wrong. I am not sure why but its wrong (hence the question). Maybe, does it mean they are the same (isomorphic) w.r.t. to their pdf/cdf/pmf? Anyway, I want to understand why I am wrong and fix my mathematical intuition. The reason I am complaining is because I am completely aware of a counter example. In fact I will provide it in the appendix of this question, however, even after seeing the counter example, I am not sure I could have come up with it. In fact even after seeing a counter example, it still feels wrong. I was wondering if someone could provide a way of how one would come up with such a counter example (or maybe a counter example that is much more obvious), or maybe explain to me why it should be obvious that one can come up with such a counter example. Appendix: Recall the definitions of convergence in distribution and convergence in probability: Convergence in distribution (D): $$ \lim_{n \rightarrow \infty} | F_{X_n}(x) - F(x)| = 0, \forall x \in X$$ Convergence in probability (P) for sufficiently large $N$ and $\forall \epsilon > 0$: $$ \lim_{n \rightarrow \infty} Pr[ | X_n - X | \geq \epsilon]= 0$$ i.e. if one goes sufficiently far the sequence of random variables, then, $X_n$ will converge to $X$ (in probability). I will show the counter example for: $$D \not\implies P$$ Consider a Bernoulli random variable $X$ with probability of success $\frac{1}{2}$. Now define $X_n$ to be equal to $X$, i.e. $$X_n = X$$ Therefore, obviously since they are the same r.v. they have the same distribution. Now define: $$Y = 1 - X$$ Obviously, $Y$ has the same distribution as $X$ and hence, also as $X_n$. So $X_N$ converges in distribution to $Y$. But, do they converge in probability? If they do then: $$ \lim_{n \rightarrow \infty} Pr[ | X_n - Y | \geq \epsilon]= 0$$ i.e. we want their difference to be larger than $\epsilon$ very rarely (in fact we want that event to have zero probability zero as n goes to infinity). Let's figure out the distance between these two random variables $X_n$ and $Y$: $$| X_n - Y | = |X_N - (1 - X)| = |X -  1 + X| = |2X - 1| = 1$$ Therefore, their distance is always 1, no matter what. We want their distance to be very far for any $\epsilon$, but notice that for the choice of $\epsilon = \frac{1}{2}$, that the distance between $| X_n - Y | = 1$ is indeed greater than the tolerable threshold (i.e. $1 = | X_n - Y | > \epsilon = \frac{1}{2} $ with probability 1). So for sure their distance is more than $\epsilon$. It doesn't matter what value of $n$ we choose (i.e. it doesn't matter how far we go down the sequence), they are for sure too far apart. More precisely: $$ \lim_{n \rightarrow \infty}Pr[ | X_n - Y | \geq \epsilon ] = Pr[ 1 \geq \frac{1}{2} ] = 1 $$ which is the opposite of what we need for convergence in probability. End of counter example.",,"['probability', 'probability-theory']"
93,Probability of iid random variables to be equal?,Probability of iid random variables to be equal?,,"Suppose $X_1$ and $X_2$ are iid random variables. I want to determine $P(X_1=X_2)$. If they are integer-valued random variables, then $$P(X_1=X_2) = \sum_{i \in \mathbb{Z}} P_{X_1,X_2}(i,i) = \sum_{i \in \mathbb{Z}} P_{X_1}(i)^2. $$ If they are continuous random variables, then $$P(X_1=X_2) = \int_{x \in \mathbb{R}} f_{X_1,X_2}(x,x) dx  = \int_{x \in \mathbb{R}} f_{X_1}(x)^2 dx. $$ But when  $X_1$ and $X_2$ are uniformly distributed over $[0,1)$, $$P(X_1=X_2)   = \int_{x \in \mathbb{R}} f_{X_1}(x)^2 dx = \int_{x \in [0,1)} 1 dx = 1. $$ Intuitively it is not possible, since $P(X_1\neq X_2) > 0$. So is there some mistake I have made? Thanks!","Suppose $X_1$ and $X_2$ are iid random variables. I want to determine $P(X_1=X_2)$. If they are integer-valued random variables, then $$P(X_1=X_2) = \sum_{i \in \mathbb{Z}} P_{X_1,X_2}(i,i) = \sum_{i \in \mathbb{Z}} P_{X_1}(i)^2. $$ If they are continuous random variables, then $$P(X_1=X_2) = \int_{x \in \mathbb{R}} f_{X_1,X_2}(x,x) dx  = \int_{x \in \mathbb{R}} f_{X_1}(x)^2 dx. $$ But when  $X_1$ and $X_2$ are uniformly distributed over $[0,1)$, $$P(X_1=X_2)   = \int_{x \in \mathbb{R}} f_{X_1}(x)^2 dx = \int_{x \in [0,1)} 1 dx = 1. $$ Intuitively it is not possible, since $P(X_1\neq X_2) > 0$. So is there some mistake I have made? Thanks!",,['probability']
94,Probability that the centroid of a triangle is inside its incircle,Probability that the centroid of a triangle is inside its incircle,,"Question : The vertices of triangles are uniformly distributed on the circumference of a circle. What is the probability that the centroid is inside the incricle. Simulations with $10^{10}$ trails give a value of $0.457982$ . It is interesting to note that this agrees with $\displaystyle \frac{G}{2}$ to six decimal places where $G$ is the Catalan's constant . Julia source code: using Random  inside = 0 step = 10^7 target = step count = 0  function rand_triangle()     angles = sort(2π * rand(3))     cos_angles = cos.(angles)     sin_angles = sin.(angles)     x_vertices = cos_angles     y_vertices = sin_angles     return x_vertices, y_vertices end  function incenter(xv, yv)     a = sqrt((xv[2] - xv[3])^2 + (yv[2] - yv[3])^2)     b = sqrt((xv[1] - xv[3])^2 + (yv[1] - yv[3])^2)     c = sqrt((xv[1] - xv[2])^2 + (yv[1] - yv[2])^2)     s = (a + b + c) / 2     incenter_x = (a * xv[1] + b * xv[2] + c * xv[3]) / (a + b + c)     incenter_y = (a * yv[1] + b * yv[2] + c * yv[3]) / (a + b + c)     incircle_radius = sqrt(s * (s - a) * (s - b) * (s - c)) / s     return incenter_x, incenter_y, incircle_radius end  while true     count += 1     x_vertices, y_vertices = rand_triangle()     centroid_x = sum(x_vertices) / 3     centroid_y = sum(y_vertices) / 3     incenter_x, incenter_y, incircle_radius = incenter(x_vertices, y_vertices)     centroid_inside = sqrt((centroid_x - incenter_x)^2 + (centroid_y - incenter_y)^2) <= incircle_radius     inside += centroid_inside     if count == target         println(count, "" "", inside, "" "", inside / count)         target += step     end end","Question : The vertices of triangles are uniformly distributed on the circumference of a circle. What is the probability that the centroid is inside the incricle. Simulations with trails give a value of . It is interesting to note that this agrees with to six decimal places where is the Catalan's constant . Julia source code: using Random  inside = 0 step = 10^7 target = step count = 0  function rand_triangle()     angles = sort(2π * rand(3))     cos_angles = cos.(angles)     sin_angles = sin.(angles)     x_vertices = cos_angles     y_vertices = sin_angles     return x_vertices, y_vertices end  function incenter(xv, yv)     a = sqrt((xv[2] - xv[3])^2 + (yv[2] - yv[3])^2)     b = sqrt((xv[1] - xv[3])^2 + (yv[1] - yv[3])^2)     c = sqrt((xv[1] - xv[2])^2 + (yv[1] - yv[2])^2)     s = (a + b + c) / 2     incenter_x = (a * xv[1] + b * xv[2] + c * xv[3]) / (a + b + c)     incenter_y = (a * yv[1] + b * yv[2] + c * yv[3]) / (a + b + c)     incircle_radius = sqrt(s * (s - a) * (s - b) * (s - c)) / s     return incenter_x, incenter_y, incircle_radius end  while true     count += 1     x_vertices, y_vertices = rand_triangle()     centroid_x = sum(x_vertices) / 3     centroid_y = sum(y_vertices) / 3     incenter_x, incenter_y, incircle_radius = incenter(x_vertices, y_vertices)     centroid_inside = sqrt((centroid_x - incenter_x)^2 + (centroid_y - incenter_y)^2) <= incircle_radius     inside += centroid_inside     if count == target         println(count, "" "", inside, "" "", inside / count)         target += step     end end",10^{10} 0.457982 \displaystyle \frac{G}{2} G,"['probability', 'integration', 'geometry', 'triangles', 'geometric-probability']"
95,Probability of $ax^2 + bx + c = 0$ having real solutions,Probability of  having real solutions,ax^2 + bx + c = 0,"$a$, $b$, $c$ are random integer numbers between $1$ and $100$ (including $1$ and $100$, and uniformly distributed). What is the probability that the equation $ax^2 + bx + c = 0$ has real solutions? This is from a final high school math exam, and I don't know how to get the answer without using computer.","$a$, $b$, $c$ are random integer numbers between $1$ and $100$ (including $1$ and $100$, and uniformly distributed). What is the probability that the equation $ax^2 + bx + c = 0$ has real solutions? This is from a final high school math exam, and I don't know how to get the answer without using computer.",,"['probability', 'roots', 'quadratics']"
96,Do moments define distributions?,Do moments define distributions?,,"Do moments define distributions? Suppose I have two random variables $X$ and $Y$ . If I know $E\left[X^k\right] = E\left[Y^k\right]$ for every $k \in \mathbb N$ , can I say that $X$ and $Y$ have the same distribution?","Do moments define distributions? Suppose I have two random variables and . If I know for every , can I say that and have the same distribution?",X Y E\left[X^k\right] = E\left[Y^k\right] k \in \mathbb N X Y,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'moment-problem']"
97,"Probability to choose specific item in a ""weighted sampling without replacement"" experiment","Probability to choose specific item in a ""weighted sampling without replacement"" experiment",,"Given $n$ items with weight $w_n$ each -- what is the probability that item $i$ is chosen in a $k$-out-of-$n$ ""weighted random sampling without replacement"" experiment? Can a closed-form solution that depends only on $w_i / w_\cdot$ be derived ($w_\cdot = \sum_j w_j$.)? EDIT : A solution that depends only on $w_i / w_\cdot$ is impossible. Assume $n=3$, $i=1$, $w_1 = 1$, and two cases: (1) $w_2 = 1, w_3 = 1 + \varepsilon$, (2) $w_2 = 2, w_3 = \varepsilon > 0$. In case (1) the probability is almost $2/3$, in case (2) it is almost $1$, but in both cases $w_1 = 1$ and $w_\cdot = 3 + \varepsilon$. What I have tried so far to solve the problem: Let $P^n_k(w, i)$ be the probability that item $i$ is chosen in an $k$-out-of-$n$ experiment with weight vector $w$. In the first draw, the item is chosen with probability $w_i / w_\cdot$. Otherwise, we are looking for the probability to choose this item in a $k-1$-out-of-$n-1$ experiment, with the same weight vector except for the item that has been selected. Hence: $$ P^n_k(w, i) = w_i / w_\cdot + \sum_{j \neq i} w_j / w_\cdot \cdot P^{n-1}_{k-1}(w - j, i) $$ $$ = w_\cdot^{-1} \left( w_i + \sum_{j \neq i} w_j \cdot P^{n-1}_{k-1}(w - j, i) \right) $$ with $w-j$ being ""the vector $w$ without the $j$th element"". How to solve this recurrence relation? (If it is correct at all...)","Given $n$ items with weight $w_n$ each -- what is the probability that item $i$ is chosen in a $k$-out-of-$n$ ""weighted random sampling without replacement"" experiment? Can a closed-form solution that depends only on $w_i / w_\cdot$ be derived ($w_\cdot = \sum_j w_j$.)? EDIT : A solution that depends only on $w_i / w_\cdot$ is impossible. Assume $n=3$, $i=1$, $w_1 = 1$, and two cases: (1) $w_2 = 1, w_3 = 1 + \varepsilon$, (2) $w_2 = 2, w_3 = \varepsilon > 0$. In case (1) the probability is almost $2/3$, in case (2) it is almost $1$, but in both cases $w_1 = 1$ and $w_\cdot = 3 + \varepsilon$. What I have tried so far to solve the problem: Let $P^n_k(w, i)$ be the probability that item $i$ is chosen in an $k$-out-of-$n$ experiment with weight vector $w$. In the first draw, the item is chosen with probability $w_i / w_\cdot$. Otherwise, we are looking for the probability to choose this item in a $k-1$-out-of-$n-1$ experiment, with the same weight vector except for the item that has been selected. Hence: $$ P^n_k(w, i) = w_i / w_\cdot + \sum_{j \neq i} w_j / w_\cdot \cdot P^{n-1}_{k-1}(w - j, i) $$ $$ = w_\cdot^{-1} \left( w_i + \sum_{j \neq i} w_j \cdot P^{n-1}_{k-1}(w - j, i) \right) $$ with $w-j$ being ""the vector $w$ without the $j$th element"". How to solve this recurrence relation? (If it is correct at all...)",,"['probability', 'probability-theory', 'sampling']"
98,Understanding what $\sqrt{p}$ means for an event of probability $p$,Understanding what  means for an event of probability,\sqrt{p} p,"Say I have a random event $E$ with probability $p$. There is a natural interpretation in terms of $E$ for the probability $p^2$: it's the probability that $E$ occurs twice if I perform two independent trials. Is there a similar interpretation for the probability $\sqrt{p}$? More generally, given $x \in ]0, 1[$, is there an interpretation of $p^x$?","Say I have a random event $E$ with probability $p$. There is a natural interpretation in terms of $E$ for the probability $p^2$: it's the probability that $E$ occurs twice if I perform two independent trials. Is there a similar interpretation for the probability $\sqrt{p}$? More generally, given $x \in ]0, 1[$, is there an interpretation of $p^x$?",,"['probability', 'soft-question', 'intuition']"
99,"Take a random walk on Pascal's triangle, without revisits: Does the final number have infinite expectation?","Take a random walk on Pascal's triangle, without revisits: Does the final number have infinite expectation?",,"Let's take a random walk on Pascal's triangle, starting at the top. Each number is in a regular hexagon. At each step, we can move to any adjacent hexagon with equal probability, but we cannot revisit a hexagon. The walk ends when we cannot move. Here is an example in which the final number is $15$ . Does the final number have infinite expectation? ( Paradoxically , a random variable whose possible values are all finite, can have infinite expectation.) My thoughts I suspect the answer is yes, because as we move down Pascal's triangle, the numbers quickly become very large. But I don't know how this could be proved. After some step, if we find ourselves in ""open territory"" (no previously visited hexagons nearby), then there is a sequence of five moves that would end the walk. This is illustrated by this image provided by @Stef in the comments: (The first red line segment after the blue line segment could have been in any other direction, so we don't count that one.) The probability of such a sequence would be $\left(\frac{1}{5}\right)\left(\frac{1}{5}\right)\left(\frac{1}{5}\right)\left(\frac{1}{5}\right)\left(\frac{1}{4}\right)=\frac{1}{2500}$ . Using the expectation of a geometric distribution , the expected number of steps in a walk would be roughly $2500$ . I believe, but am not sure, that the expected row number at the end would be on the order of $\sqrt{2500}=50$ . (This rough analysis ignores several factors, for example the effect of the boundaries of the triangle.) But sometimes our walk would go much deeper than the expected depth. The numbers in the triangle increase very quickly. Generally speaking, if the numbers increase faster than the probabilities of reaching them decrease, then the expectation of the final number could be infinite. Context This is one of several questions about Pascal's triangle that I've asked recently, for example: Does the interior of Pascal's triangle contain three consecutive integers? I tried to kill the central binomial coefficients, but they came back Conjecture: In Pascal's triangle with $n$ rows, the proportion of numbers less than the centre number approaches $e^{-1/\pi}$ as $n\to\infty$ . . Sometimes I am more interested in the methods used to answer the questions, than the answers themselves (but I am still curious what the answer is!). Many of my questions initially seemed almost unapproachable to me, but then turned out to have a rational explanation.","Let's take a random walk on Pascal's triangle, starting at the top. Each number is in a regular hexagon. At each step, we can move to any adjacent hexagon with equal probability, but we cannot revisit a hexagon. The walk ends when we cannot move. Here is an example in which the final number is . Does the final number have infinite expectation? ( Paradoxically , a random variable whose possible values are all finite, can have infinite expectation.) My thoughts I suspect the answer is yes, because as we move down Pascal's triangle, the numbers quickly become very large. But I don't know how this could be proved. After some step, if we find ourselves in ""open territory"" (no previously visited hexagons nearby), then there is a sequence of five moves that would end the walk. This is illustrated by this image provided by @Stef in the comments: (The first red line segment after the blue line segment could have been in any other direction, so we don't count that one.) The probability of such a sequence would be . Using the expectation of a geometric distribution , the expected number of steps in a walk would be roughly . I believe, but am not sure, that the expected row number at the end would be on the order of . (This rough analysis ignores several factors, for example the effect of the boundaries of the triangle.) But sometimes our walk would go much deeper than the expected depth. The numbers in the triangle increase very quickly. Generally speaking, if the numbers increase faster than the probabilities of reaching them decrease, then the expectation of the final number could be infinite. Context This is one of several questions about Pascal's triangle that I've asked recently, for example: Does the interior of Pascal's triangle contain three consecutive integers? I tried to kill the central binomial coefficients, but they came back Conjecture: In Pascal's triangle with rows, the proportion of numbers less than the centre number approaches as . . Sometimes I am more interested in the methods used to answer the questions, than the answers themselves (but I am still curious what the answer is!). Many of my questions initially seemed almost unapproachable to me, but then turned out to have a rational explanation.",15 \left(\frac{1}{5}\right)\left(\frac{1}{5}\right)\left(\frac{1}{5}\right)\left(\frac{1}{5}\right)\left(\frac{1}{4}\right)=\frac{1}{2500} 2500 \sqrt{2500}=50 n e^{-1/\pi} n\to\infty,"['probability', 'binomial-coefficients', 'expected-value', 'random-walk', 'conjectures']"
