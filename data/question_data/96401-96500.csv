,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Lipschitz functions (Theorem 1.4 of Condenser Capacities and Symmetrization in Geometric Function Theory),Lipschitz functions (Theorem 1.4 of Condenser Capacities and Symmetrization in Geometric Function Theory),,"I am struggling to understand the second part of the following proof of Theorem 1.4 of the book ""Condenser Capacities and Symmetrization in Geometric Function Theory"" by Vladimir N. Dubinin (in what follows $U(z_0,r) \subset \mathbb{C}$ is the open disk of radius $r > 0$ and centre $z_0$ , $\text{Lip}(S)$ refers to the Lipschitz continuous real-valued functions on the set $S \subset \mathbb{C}$ and all the results referred to in the proof of Theorem 1.4 have been provided below the proof of Theorem 1.4): $\textbf{Theorem 1.4 and proof}$ That is, I do not understand what the author means by ""Repeating the above reasoning for each connected component and taking account of Theorem 1.3 we obtain $v(\phi(z)) \in \text{Lip}(\overline{U(z_0,r)})$ "" where this sentence occurs in the image below: The results used in the proof of Theorem 1.4 are Theorem 1.3 and Lemma 1.1, and Theorem 1.1 which are given below for reference. $\textbf{Lemma 1.1 and proof}$ $\textbf{Theorem 1.3 and proof}$ $\textbf{Theorem 1.1 and proof}$ Theorem 1.1 says that a function $v$ defined on a compact planar set $E$ is Lipschitz on $E$ if and only if it is locally Lipschitz on $E$ , that is if and only if there is a collection of open sets $U_{i}$ covering $E$ , such that $v \in \text{Lip}(U_{i} \cap E)$ for every $i$ . $\textbf{What I think is going on:}$ What seems to be happening is that each connected component $C_j$ of $U(z_0,r) \cap B$ should contain $z_0$ on its boundary, and $z_0$ should be contained on an analytic arc of $\partial B$ which forms part of the boundary of $C_j$ . Therefore we should be in an analogous situation to when we assumed $U(z_0,r) \cap B$ were connected, because under these assumptions we should be able to extend $\phi \restriction C_j$ analytically to a small open disk around $z_0$ for each connected component $C_j$ of $U(z_0,r) \cap B$ , and then apply Theorem 1.3 as the author implies. $\textbf{Where I have difficulty understanding:}$ : However, there are several things that I am totally lost on. The first of which being, how do we know for sure that each connected component $C_j$ of $U(z_0,r) \cap B$ has as part of its boundary, an analytic arc containing $z_0$ (more precisely, it seems it is possible to lose analyticity at $z_0$ , e.g. if two curves at $z_0$ form the boundary and have different tangent vectors at $z_0$ )? Moreover, what is a suitable definition of ""boundary consist of finitely many piecewise analytic curves"" (I am assuming the definition coincides with the definition I provide in $\textbf{Edit 3}$ of this post ). It would be great if anyone could shed light on why what the author seems to be doing can be done.","I am struggling to understand the second part of the following proof of Theorem 1.4 of the book ""Condenser Capacities and Symmetrization in Geometric Function Theory"" by Vladimir N. Dubinin (in what follows is the open disk of radius and centre , refers to the Lipschitz continuous real-valued functions on the set and all the results referred to in the proof of Theorem 1.4 have been provided below the proof of Theorem 1.4): That is, I do not understand what the author means by ""Repeating the above reasoning for each connected component and taking account of Theorem 1.3 we obtain "" where this sentence occurs in the image below: The results used in the proof of Theorem 1.4 are Theorem 1.3 and Lemma 1.1, and Theorem 1.1 which are given below for reference. Theorem 1.1 says that a function defined on a compact planar set is Lipschitz on if and only if it is locally Lipschitz on , that is if and only if there is a collection of open sets covering , such that for every . What seems to be happening is that each connected component of should contain on its boundary, and should be contained on an analytic arc of which forms part of the boundary of . Therefore we should be in an analogous situation to when we assumed were connected, because under these assumptions we should be able to extend analytically to a small open disk around for each connected component of , and then apply Theorem 1.3 as the author implies. : However, there are several things that I am totally lost on. The first of which being, how do we know for sure that each connected component of has as part of its boundary, an analytic arc containing (more precisely, it seems it is possible to lose analyticity at , e.g. if two curves at form the boundary and have different tangent vectors at )? Moreover, what is a suitable definition of ""boundary consist of finitely many piecewise analytic curves"" (I am assuming the definition coincides with the definition I provide in of this post ). It would be great if anyone could shed light on why what the author seems to be doing can be done.","U(z_0,r) \subset \mathbb{C} r > 0 z_0 \text{Lip}(S) S \subset \mathbb{C} \textbf{Theorem 1.4 and proof} v(\phi(z)) \in \text{Lip}(\overline{U(z_0,r)}) \textbf{Lemma 1.1 and proof} \textbf{Theorem 1.3 and proof} \textbf{Theorem 1.1 and proof} v E E E U_{i} E v \in \text{Lip}(U_{i} \cap E) i \textbf{What I think is going on:} C_j U(z_0,r) \cap B z_0 z_0 \partial B C_j U(z_0,r) \cap B \phi \restriction C_j z_0 C_j U(z_0,r) \cap B \textbf{Where I have difficulty understanding:} C_j U(z_0,r) \cap B z_0 z_0 z_0 z_0 \textbf{Edit 3}","['complex-analysis', 'analysis', 'lipschitz-functions', 'plane-curves', 'analytic-continuation']"
1,How can we reconcile the exponential function with the fundamental theorem of algebra?,How can we reconcile the exponential function with the fundamental theorem of algebra?,,"For the purposes of this question let's consider the exponential function to be an infinite polynomial (the limit as $n$ goes to infinity of an $n$ th degree polynomial). It stands to reason then that we might expect an infinite polynomial to have infinitely many roots, and this does hold for many other infinite series like the sine and cosine. Let us define: $$\exp_n(x) = \sum_{k=0}^n \frac{x^k}{k!}$$ so that we have $\exp(x) = \exp_{\infty}(x)$ . All $\exp_n(x)$ for finite $n$ are $n$ th-degree polynomials with $n$ -complex roots, so  let us write: $$\exp_n(x) = \frac{1}{n!} \prod_{i=1}^n (x-r_i)$$ My question is this: as $n$ $\to$ $\infty$ , what happens to these $r_i$ ? Numerically I have determined that only odd $n$ have real roots, and as we take the odd partial sums of the exponential function, the real root gets closer and closer to $-\infty$ , which concurs with what I expect. But how do we account for the multiplicities? Do all complex roots of the partial sums go to $-\infty$ , and if so, how can we show that (bonus points for a visualization if possible)?","For the purposes of this question let's consider the exponential function to be an infinite polynomial (the limit as goes to infinity of an th degree polynomial). It stands to reason then that we might expect an infinite polynomial to have infinitely many roots, and this does hold for many other infinite series like the sine and cosine. Let us define: so that we have . All for finite are th-degree polynomials with -complex roots, so  let us write: My question is this: as , what happens to these ? Numerically I have determined that only odd have real roots, and as we take the odd partial sums of the exponential function, the real root gets closer and closer to , which concurs with what I expect. But how do we account for the multiplicities? Do all complex roots of the partial sums go to , and if so, how can we show that (bonus points for a visualization if possible)?",n n \exp_n(x) = \sum_{k=0}^n \frac{x^k}{k!} \exp(x) = \exp_{\infty}(x) \exp_n(x) n n n \exp_n(x) = \frac{1}{n!} \prod_{i=1}^n (x-r_i) n \to \infty r_i n -\infty -\infty,"['sequences-and-series', 'complex-analysis', 'taylor-expansion']"
2,Fourier series of a particular elliptic function,Fourier series of a particular elliptic function,,"There is an established result that the Fourier expansion of a particular ratio of Jacobi elliptic theta functions: $$\frac{\theta_1(x+y)\theta_1'(0)}{\theta_1(x)\theta_1(y)} = \cot(x)+\cot(y)+4\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}q^{2mn}\sin(2my+2nx)$$ where $|\Im(x)| <|\Im(\pi\tau)|$ and $|\Im(y)| <|\Im(\pi\tau)|$ c.f. Whittaker and Watson 5th edition page 515 Example 21.13. One can evaluate the integrals in $x$ and $y$ for the Fourier coefficient by considering contour integrals about the parallelogram in the complex plane with vertices at $\left\{\pm \dfrac{\pi}{2}, \pm\dfrac{\pi}{2}+\pi\tau\right\}$ and arrive at the result by computing the sum. I am interested in evaluating the Fourier expansion for the following ratio of Jacobi elliptic theta functions: $$\frac{\theta_4(x+y)\theta_1'(0)}{\theta_4(x)\theta_4(y)}=\sum_{m,n}e^{2inx+2imy}A_{m,n}$$ where $$A_{m,n} = \frac{1}{\pi^2}\int_{-\pi/2}^{\pi/2}\mathrm{d}ye^{-2imy}\int_{-\pi/2}^{\pi/2}\mathrm{d}x e^{-2inx } \frac{\theta_4(x+y)\theta_1'(0)}{\theta_4(x)\theta_4(y)}$$ I can evaluate the integral with respect to $x$ by considering the parallelogram contour as before, giving $$A_{m,n} = \frac{2i}{\pi}\int_{-\pi/2}^{\pi/2}\mathrm{d}ye^{-2imy} \frac{q^{-n}e^{-iy}}{1-q^{-2n}e^{-2iy}} \frac{\theta_1(y)}{\theta_4(y)}$$ However, if I try to compute this integral using the same method I instead generate the following recurrence relation: $$ A_{m,n} - q^{-2m}A_{m,n+1} = -4\frac{\theta_4(0)}{\theta_1'(0)} \frac{q^{-m}q^{-(n+\frac{1}{2})}}{1-q^{-(2n+1)}}$$ This seems simple, but I do not have an explicit boundary condition to solve this difference relation. I can see that the original function is symmetric under interchange of $x\leftrightarrow y$ and $x\rightarrow -x, y\rightarrow-y$ simultaneously, which may imply $A_{m,n}=A_{n,m}$ and $A_{m,n}=A_{-m,-n}$ respectively, but I can't seem to reconcile this with the difference equation. Any help would be greatly appreciated!","There is an established result that the Fourier expansion of a particular ratio of Jacobi elliptic theta functions: where and c.f. Whittaker and Watson 5th edition page 515 Example 21.13. One can evaluate the integrals in and for the Fourier coefficient by considering contour integrals about the parallelogram in the complex plane with vertices at and arrive at the result by computing the sum. I am interested in evaluating the Fourier expansion for the following ratio of Jacobi elliptic theta functions: where I can evaluate the integral with respect to by considering the parallelogram contour as before, giving However, if I try to compute this integral using the same method I instead generate the following recurrence relation: This seems simple, but I do not have an explicit boundary condition to solve this difference relation. I can see that the original function is symmetric under interchange of and simultaneously, which may imply and respectively, but I can't seem to reconcile this with the difference equation. Any help would be greatly appreciated!","\frac{\theta_1(x+y)\theta_1'(0)}{\theta_1(x)\theta_1(y)} = \cot(x)+\cot(y)+4\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}q^{2mn}\sin(2my+2nx) |\Im(x)| <|\Im(\pi\tau)| |\Im(y)| <|\Im(\pi\tau)| x y \left\{\pm \dfrac{\pi}{2}, \pm\dfrac{\pi}{2}+\pi\tau\right\} \frac{\theta_4(x+y)\theta_1'(0)}{\theta_4(x)\theta_4(y)}=\sum_{m,n}e^{2inx+2imy}A_{m,n} A_{m,n} = \frac{1}{\pi^2}\int_{-\pi/2}^{\pi/2}\mathrm{d}ye^{-2imy}\int_{-\pi/2}^{\pi/2}\mathrm{d}x e^{-2inx } \frac{\theta_4(x+y)\theta_1'(0)}{\theta_4(x)\theta_4(y)} x A_{m,n} = \frac{2i}{\pi}\int_{-\pi/2}^{\pi/2}\mathrm{d}ye^{-2imy} \frac{q^{-n}e^{-iy}}{1-q^{-2n}e^{-2iy}} \frac{\theta_1(y)}{\theta_4(y)}  A_{m,n} - q^{-2m}A_{m,n+1} = -4\frac{\theta_4(0)}{\theta_1'(0)} \frac{q^{-m}q^{-(n+\frac{1}{2})}}{1-q^{-(2n+1)}} x\leftrightarrow y x\rightarrow -x, y\rightarrow-y A_{m,n}=A_{n,m} A_{m,n}=A_{-m,-n}","['complex-analysis', 'recurrence-relations', 'fourier-series', 'elliptic-functions']"
3,Characterization of function with $n$-th derivative bounded by $n!$,Characterization of function with -th derivative bounded by,n n!,"Given a $f \in C^\infty_0(\mathbb{R}^n)$ (the set of smooth functions that vanishes at infinity) is in general false that its derivative are bounded, also if the function is bounded (see e.g. $f(x)=\frac{\sin(e^x-1)}{x}$ ). For polynomial we know that $P_n^{(n)}(x)=Cn!$ where $C$ is a constant. There is some similar estimation for some subclass of $C^\infty_0$ functions i.e. is it possible to characterize in some way the functions such that for any $n > N_0$ $$ \sup_{x \in \mathbb{R}^n}f^{(n)}(x) \le n! M^n $$ where $N_0$ and $M$ are constants? EDIT: the function $ f(x):= e^{-|x|^2}  $ satisfies all the conditions so not only the polynomial satisfies this inequality. Is it true also for all the compactly supported functions on $\mathbb{R}^n$ ?","Given a (the set of smooth functions that vanishes at infinity) is in general false that its derivative are bounded, also if the function is bounded (see e.g. ). For polynomial we know that where is a constant. There is some similar estimation for some subclass of functions i.e. is it possible to characterize in some way the functions such that for any where and are constants? EDIT: the function satisfies all the conditions so not only the polynomial satisfies this inequality. Is it true also for all the compactly supported functions on ?","f \in C^\infty_0(\mathbb{R}^n) f(x)=\frac{\sin(e^x-1)}{x} P_n^{(n)}(x)=Cn! C C^\infty_0 n > N_0 
\sup_{x \in \mathbb{R}^n}f^{(n)}(x) \le n! M^n
 N_0 M 
f(x):= e^{-|x|^2} 
 \mathbb{R}^n","['real-analysis', 'complex-analysis', 'functions', 'exponential-function', 'estimation']"
4,Limit of the sum of cosine,Limit of the sum of cosine,,"I want to find the value of $$\sum_{k=0}^\infty \cos\left[\left(k+\frac{1}{2}\right)\pi x\right]\cos\left[\left(k+\frac{1}{2}\right)\pi t\right].$$ I think it should relate to delta function because we can use a trig identity to get: $$\sum_{k=0}^\infty \frac{1}{2}\left(\cos\left[\left(k+\frac{1}{2}\right)\pi(t+x)\right]-\cos\left[\left(k+\frac{1}{2}\right)\pi(t-x)\right]\right)$$ , but how to deal with the $\frac{1}{2}\pi (t+x)$ ?","I want to find the value of I think it should relate to delta function because we can use a trig identity to get: , but how to deal with the ?",\sum_{k=0}^\infty \cos\left[\left(k+\frac{1}{2}\right)\pi x\right]\cos\left[\left(k+\frac{1}{2}\right)\pi t\right]. \sum_{k=0}^\infty \frac{1}{2}\left(\cos\left[\left(k+\frac{1}{2}\right)\pi(t+x)\right]-\cos\left[\left(k+\frac{1}{2}\right)\pi(t-x)\right]\right) \frac{1}{2}\pi (t+x),"['real-analysis', 'complex-analysis', 'limits', 'dirac-delta']"
5,Discussion on the Conditions for Pointwise/Uniform Convergence of Fourier Serieses.,Discussion on the Conditions for Pointwise/Uniform Convergence of Fourier Serieses.,,"My book isn't very clear about the conditions for pointwise/uniform convergence of fourier series; so, after a bit of search, here I am with a summary of what I found. Please, it would be very appreciated if someone could discuss or check the validity of any of these points: Let's suppose that the function $\left[f(x)\right]$ has left-and-right derivatives in the point $\left[x_0\right]$ , and is here continuos, then its fourier series converges to $\left[f(x_0)\right]$ . Can somebody assure that this statement holds even if such derivatives are not equal? Let's suppose that the function $\left[f(x) \in C^1([-L,+L])\right]$ , then its fourier series converges pointwise over the whole segment. Can somebody assure that this convergence is also uniform? Let's suppose that $\left[\sum_{n=-\infty}^{+\infty} c_ne^{inx}\right]$ is the fourier series of the function $\left[f(x)\right]$ ; if $\left[\sum_{n=-\infty}^{+\infty} |c_n| \lt \infty\right]$ then the series converges absolutely, and therefore uniformly. (NOTE: this is a consequence of m-test.) Let's suppose that the function $\left[f(x)\right]$ has bounded variation over the segment $\left[-\pi, +\pi\right]$ , or its first derivative is such that $\left[\;|f'(x)|\le K\;\right]$ (otherwise it is lipshitz, or more generally it is $\alpha$ -holder with $0 \le \alpha \le 1$ ), then its fourier series converges uniformly. Note that this statement holds for $2\pi$ -periodic functions (or at least this is what I found). Can somebody assure that this statement holds even over a generic segment $\left[a,b\right]$ ? Moreover the condition of periodicity has to be contextualized with $\left[\; \lim_{x\to a^+}f(x)=\lim_{x\to b^-}f(x) \;\right]$ . Let's suppose that the function $\left[f(x)\right]$ is periodic with bounded variation over a certain segment; then its fourier series converges pointwise to $\left[\lim_{\epsilon\to 0} \frac{f(x+\epsilon)+f(x-\epsilon)}{2}\right]$ . In particular, if the function is continuous in $\left[(x)\right]$ , then its fourier series converges pointwise to $\left[f(x)\right]$ . Moreover, if the function is continuous everywhere over the segment, then its fourier series converges uniformly to $\left[f(x)\right]$ . Can somebody discuss about the periodicity condition? Is that necessary? Let's suppose that the function $\left[f(x) \in L^p, \;p\gt1 \right]$ ; then its fourier series converges for ""almost every"" $\left[(x)\right]$ . Can somebody assure that this type of convergence is a ""pointwise-one""? In addition to those, there is a very personal question I beg you to answer... Let's suppose that I'm asked to find the fourier series of some kind of function, over a certain segment $\left[a,b\right]$ . Let's say that I'm not interested in studying the properties of the function; instead, I'm required to solve the integral: $$\tilde b_n = \frac{1}{\sqrt{b-a}}\int_a^b dx \, f(x)e^{-i \frac{2n\pi}{b-a} x} \; \lt \infty \quad \vert \quad \forall \; n \in \mathbb{Z}$$ whose results are the coefficients for the function's fourier series: $$f(x) = \sum_{n=-\infty}^{+\infty} \tilde b_n \frac{e^{i \frac{2n\pi}{b-a} x}}{\sqrt{b-a}}$$ Why doesn't the simple existence of the fourier series coefficients imply the pointwise convergence of the series itself to the given function in the given segment?","My book isn't very clear about the conditions for pointwise/uniform convergence of fourier series; so, after a bit of search, here I am with a summary of what I found. Please, it would be very appreciated if someone could discuss or check the validity of any of these points: Let's suppose that the function has left-and-right derivatives in the point , and is here continuos, then its fourier series converges to . Can somebody assure that this statement holds even if such derivatives are not equal? Let's suppose that the function , then its fourier series converges pointwise over the whole segment. Can somebody assure that this convergence is also uniform? Let's suppose that is the fourier series of the function ; if then the series converges absolutely, and therefore uniformly. (NOTE: this is a consequence of m-test.) Let's suppose that the function has bounded variation over the segment , or its first derivative is such that (otherwise it is lipshitz, or more generally it is -holder with ), then its fourier series converges uniformly. Note that this statement holds for -periodic functions (or at least this is what I found). Can somebody assure that this statement holds even over a generic segment ? Moreover the condition of periodicity has to be contextualized with . Let's suppose that the function is periodic with bounded variation over a certain segment; then its fourier series converges pointwise to . In particular, if the function is continuous in , then its fourier series converges pointwise to . Moreover, if the function is continuous everywhere over the segment, then its fourier series converges uniformly to . Can somebody discuss about the periodicity condition? Is that necessary? Let's suppose that the function ; then its fourier series converges for ""almost every"" . Can somebody assure that this type of convergence is a ""pointwise-one""? In addition to those, there is a very personal question I beg you to answer... Let's suppose that I'm asked to find the fourier series of some kind of function, over a certain segment . Let's say that I'm not interested in studying the properties of the function; instead, I'm required to solve the integral: whose results are the coefficients for the function's fourier series: Why doesn't the simple existence of the fourier series coefficients imply the pointwise convergence of the series itself to the given function in the given segment?","\left[f(x)\right] \left[x_0\right] \left[f(x_0)\right] \left[f(x) \in C^1([-L,+L])\right] \left[\sum_{n=-\infty}^{+\infty} c_ne^{inx}\right] \left[f(x)\right] \left[\sum_{n=-\infty}^{+\infty} |c_n| \lt \infty\right] \left[f(x)\right] \left[-\pi, +\pi\right] \left[\;|f'(x)|\le K\;\right] \alpha 0 \le \alpha \le 1 2\pi \left[a,b\right] \left[\; \lim_{x\to a^+}f(x)=\lim_{x\to b^-}f(x) \;\right] \left[f(x)\right] \left[\lim_{\epsilon\to 0} \frac{f(x+\epsilon)+f(x-\epsilon)}{2}\right] \left[(x)\right] \left[f(x)\right] \left[f(x)\right] \left[f(x) \in L^p, \;p\gt1 \right] \left[(x)\right] \left[a,b\right] \tilde b_n = \frac{1}{\sqrt{b-a}}\int_a^b dx \, f(x)e^{-i \frac{2n\pi}{b-a} x} \; \lt \infty \quad \vert \quad \forall \; n \in \mathbb{Z} f(x) = \sum_{n=-\infty}^{+\infty} \tilde b_n \frac{e^{i \frac{2n\pi}{b-a} x}}{\sqrt{b-a}}","['calculus', 'sequences-and-series', 'complex-analysis', 'convergence-divergence', 'fourier-analysis']"
6,Nonstandard Complex Analysis?,Nonstandard Complex Analysis?,,I recently discovered Nonstandard Analysis and am slowly working my way through Kelsier's textbook and Foundations companion.  However while I have found plenty of stuff about real nonstandard analysis I have not been able to discover anything about complex nonstandard analysis.  Would anyone be able to recommend any such resources to add to my reading list once I am done with Kelsier's book?,I recently discovered Nonstandard Analysis and am slowly working my way through Kelsier's textbook and Foundations companion.  However while I have found plenty of stuff about real nonstandard analysis I have not been able to discover anything about complex nonstandard analysis.  Would anyone be able to recommend any such resources to add to my reading list once I am done with Kelsier's book?,,"['complex-analysis', 'reference-request', 'book-recommendation', 'nonstandard-analysis', 'infinitesimals']"
7,I need help solving this differential delay equation (inverse Laplace transform problem),I need help solving this differential delay equation (inverse Laplace transform problem),,"Let us consider a differential delay equation (DDE) with $a,b\in\mathbb{R}$ : $$ \frac{d}{dt}y(t)=ay(t)+bH(t-1)y(t-1),~0\le t<\infty, $$ where $H(t)=\int_{-\infty}^t\delta(t')dt'$ is the Heaviside step function. Let $\hat{y}(s)=\int_0^{\infty}e^{-st}y(t)dt$ be the Laplace transform of $y(t)$ . i). Find $\hat{y}(s)$ and, using the inverse Laplace transform, solve the given DDE. Here is what I have tried so far : $$ \begin{aligned} \mathcal{L}\left(\frac{d}{dt}y(t)\right)(s)&=\mathcal{L}\left(ay(t)+bH(t-1)y(t-1)\right)(s)\\ s\hat{y}(s)-y(0^{-})&=a\hat{y}(s)+be^{-s}\hat{y}(s), \end{aligned} $$ therefore $$ \begin{aligned} s\hat{y}(s)-a\hat{y}(s)-be^{-s}\hat{y}(s)&=y(0^{-})\\ \hat{y}(s)\left(s-a-be^{-s}\right)&=y(0^{-})\\ \hat{y}(s)&=\frac{y(0^{-})}{s-a-be^{-s}}\\ y(t)&=\mathcal{L}^{-1}\left(\hat{y}(s)\right)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}e^{st}\hat{y}(s)ds\\ &=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{y(0^{-})e^{st}}{s-a-be^{-s}}ds\\ &=\frac{y(0^{-})}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{e^{st}}{s-a-be^{-s}}ds \end{aligned} $$ I need help: I don't know how to get the exact value of the inverse Laplace transform of $\hat{y}(s)$","Let us consider a differential delay equation (DDE) with : where is the Heaviside step function. Let be the Laplace transform of . i). Find and, using the inverse Laplace transform, solve the given DDE. Here is what I have tried so far : therefore I need help: I don't know how to get the exact value of the inverse Laplace transform of","a,b\in\mathbb{R} 
\frac{d}{dt}y(t)=ay(t)+bH(t-1)y(t-1),~0\le t<\infty,
 H(t)=\int_{-\infty}^t\delta(t')dt' \hat{y}(s)=\int_0^{\infty}e^{-st}y(t)dt y(t) \hat{y}(s) 
\begin{aligned}
\mathcal{L}\left(\frac{d}{dt}y(t)\right)(s)&=\mathcal{L}\left(ay(t)+bH(t-1)y(t-1)\right)(s)\\
s\hat{y}(s)-y(0^{-})&=a\hat{y}(s)+be^{-s}\hat{y}(s),
\end{aligned}
 
\begin{aligned}
s\hat{y}(s)-a\hat{y}(s)-be^{-s}\hat{y}(s)&=y(0^{-})\\
\hat{y}(s)\left(s-a-be^{-s}\right)&=y(0^{-})\\
\hat{y}(s)&=\frac{y(0^{-})}{s-a-be^{-s}}\\
y(t)&=\mathcal{L}^{-1}\left(\hat{y}(s)\right)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}e^{st}\hat{y}(s)ds\\
&=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{y(0^{-})e^{st}}{s-a-be^{-s}}ds\\
&=\frac{y(0^{-})}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{e^{st}}{s-a-be^{-s}}ds
\end{aligned}
 \hat{y}(s)","['complex-analysis', 'ordinary-differential-equations', 'partial-differential-equations', 'laplace-transform', 'inverse-laplace']"
8,Complex integral \[ \int_{0}^{+\infty}\frac{e^{\cos(x)}\cos\left(\sin\left(x\right)\right)}{a^{2}+x^{2}}dx. \],Complex integral \[ \int_{0}^{+\infty}\frac{e^{\cos(x)}\cos\left(\sin\left(x\right)\right)}{a^{2}+x^{2}}dx. \],,"I am trying to solve this real integral using complex integration with semi circle. To do this with semicircle I noticed that the function is even, so $\int_{-\infty}^{+\infty}f\left(x\right)dx=2\int_{0}^{+\infty}f\left(x\right)dx$ . $$ \int_{0}^{+\infty}\frac{e^{\cos(x)}\cos\left(\sin\left(x\right)\right)}{a^{2}+x^{2}}dx. $$ I observe the function $\displaystyle f\left(z\right)=\frac{e^{e^{iz}}}{a^{2}+z^{2}}$ . Because I want to solve the integral using semi circle, only pole $z=ia$ is inside the circle. The residue in that pole is $\frac{e^{e^{-a}}}{i2a}$ and the value of integral is $$\int_{C_{R}}f\left(z\right)dz+\int_{-R}^{R}f\left(z\right)dz=2\pi i\cdot\frac{e^{e^{-a}}}{i2a}=\frac{\pi e^{e^{-a}}}{a}.$$ Now I want to solve the integral $\int_{C_{R}}f\left(z\right)dz$ : With the identity $z=Re^{i\theta}$ we have $dz=Rie^{i\theta}d\theta$ . Now: \begin{align*} \left|\int_{C_{R}}f\left(z\right)dz\right| & \leq\int_{C_{R}}\left|f\left(z\right)\right|dz\\  & \leq\int_{0}^{\pi}\left|\frac{e^{e^{i\cdot Re^{i\theta}}}}{a^{2}+R^{2}e^{i2\theta}}\cdot R\right|\cdot{\left|ie^{i\theta}\right|}\cdot d\theta\\  & =\int_{0}^{\pi}\left|\frac{e^{e^{i\cdot Re^{i\theta}}}}{a^{2}+R^{2}e^{i2\theta}}\cdot R\right|\cdot d\theta. \end{align*} I use $R^{2}=\left|R^{2}e^{i2\theta}\right|=\left|R^{2}e^{i2\theta}+a^{2}-a^{2}\right|\leq\left|R^{2}e^{i2\theta}+a^{2}\right|+\left|-a^{2}\right|$ thus $$\left|R^{2}e^{i2\theta}+a^{2}\right|\geq R^{2}-a^{2}\,\,\Rightarrow\,\,\frac{1}{\left|R^{2}e^{i2\theta}+a^{2}\right|}\leq\frac{1}{R^{2}-a^{2}}.$$ Now \begin{align*} \left|\int_{C_{R}}f\left(z\right)dz\right| & \leq\int_{0}^{\pi}\frac{\left|e^{e^{i\cdot Re^{i\theta}}}\right|R}{R^{2}-a^{2}}\cdot d\theta\\  & =\frac{R}{R^{2}-a^{2}}\int_{0}^{\pi}\left|e^{e^{i\cdot Re^{i\theta}}}\right|d\theta=\frac{R}{R^{2}-a^{2}}\int_{0}^{\pi}\left|e^{e^{iR\left(\cos\theta+i\sin\theta\right)}}\right|d\theta\\  & =\frac{R}{R^{2}-a^{2}}\int_{0}^{\pi}\left|e^{e^{iR\cos\theta}\cdot e^{-R\sin\theta}}\right|d\theta \end{align*} I don't know what to do with the last integral. Colud someone help me?","I am trying to solve this real integral using complex integration with semi circle. To do this with semicircle I noticed that the function is even, so . I observe the function . Because I want to solve the integral using semi circle, only pole is inside the circle. The residue in that pole is and the value of integral is Now I want to solve the integral : With the identity we have . Now: I use thus Now I don't know what to do with the last integral. Colud someone help me?","\int_{-\infty}^{+\infty}f\left(x\right)dx=2\int_{0}^{+\infty}f\left(x\right)dx 
\int_{0}^{+\infty}\frac{e^{\cos(x)}\cos\left(\sin\left(x\right)\right)}{a^{2}+x^{2}}dx.
 \displaystyle f\left(z\right)=\frac{e^{e^{iz}}}{a^{2}+z^{2}} z=ia \frac{e^{e^{-a}}}{i2a} \int_{C_{R}}f\left(z\right)dz+\int_{-R}^{R}f\left(z\right)dz=2\pi i\cdot\frac{e^{e^{-a}}}{i2a}=\frac{\pi e^{e^{-a}}}{a}. \int_{C_{R}}f\left(z\right)dz z=Re^{i\theta} dz=Rie^{i\theta}d\theta \begin{align*}
\left|\int_{C_{R}}f\left(z\right)dz\right| & \leq\int_{C_{R}}\left|f\left(z\right)\right|dz\\
 & \leq\int_{0}^{\pi}\left|\frac{e^{e^{i\cdot Re^{i\theta}}}}{a^{2}+R^{2}e^{i2\theta}}\cdot R\right|\cdot{\left|ie^{i\theta}\right|}\cdot d\theta\\
 & =\int_{0}^{\pi}\left|\frac{e^{e^{i\cdot Re^{i\theta}}}}{a^{2}+R^{2}e^{i2\theta}}\cdot R\right|\cdot d\theta.
\end{align*} R^{2}=\left|R^{2}e^{i2\theta}\right|=\left|R^{2}e^{i2\theta}+a^{2}-a^{2}\right|\leq\left|R^{2}e^{i2\theta}+a^{2}\right|+\left|-a^{2}\right| \left|R^{2}e^{i2\theta}+a^{2}\right|\geq R^{2}-a^{2}\,\,\Rightarrow\,\,\frac{1}{\left|R^{2}e^{i2\theta}+a^{2}\right|}\leq\frac{1}{R^{2}-a^{2}}. \begin{align*}
\left|\int_{C_{R}}f\left(z\right)dz\right| & \leq\int_{0}^{\pi}\frac{\left|e^{e^{i\cdot Re^{i\theta}}}\right|R}{R^{2}-a^{2}}\cdot d\theta\\
 & =\frac{R}{R^{2}-a^{2}}\int_{0}^{\pi}\left|e^{e^{i\cdot Re^{i\theta}}}\right|d\theta=\frac{R}{R^{2}-a^{2}}\int_{0}^{\pi}\left|e^{e^{iR\left(\cos\theta+i\sin\theta\right)}}\right|d\theta\\
 & =\frac{R}{R^{2}-a^{2}}\int_{0}^{\pi}\left|e^{e^{iR\cos\theta}\cdot e^{-R\sin\theta}}\right|d\theta
\end{align*}","['complex-analysis', 'complex-integration']"
9,Laurent Series for $\frac{z}{(z+2)(z+1)}$,Laurent Series for,\frac{z}{(z+2)(z+1)},"I need to find a Laurent series of $ f(z) = \frac{z}{(z+2)(z+1)}$ centered at $z_0 = -2$ The partial fractions of $f$ is $ \frac{2}{(z+2)} - \frac{1}{(z+1)} $ Now, $\frac{1}{(z+1)} = \frac{1}{(z+2)-1} =  \frac{-1}{1 -(z+2)} = - \frac{1}{1 -(z+2)} = - \sum_{n=0}^{\infty} (z+2)^n $ . So we have the Laurent Series $ \frac{2}{(z+2)} + \sum_{n=0}^{\infty} (z+2)^n $ centered at $z_0 = -2$ . The function has a pole of order 1. Its my resolution correct?","I need to find a Laurent series of centered at The partial fractions of is Now, . So we have the Laurent Series centered at . The function has a pole of order 1. Its my resolution correct?", f(z) = \frac{z}{(z+2)(z+1)} z_0 = -2 f  \frac{2}{(z+2)} - \frac{1}{(z+1)}  \frac{1}{(z+1)} = \frac{1}{(z+2)-1} =  \frac{-1}{1 -(z+2)} = - \frac{1}{1 -(z+2)} = - \sum_{n=0}^{\infty} (z+2)^n   \frac{2}{(z+2)} + \sum_{n=0}^{\infty} (z+2)^n  z_0 = -2,"['complex-analysis', 'solution-verification']"
10,Relevance of Complex Coordinate Geometry [closed],Relevance of Complex Coordinate Geometry [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 1 year ago . This post was edited and submitted for review 1 year ago and failed to reopen the post: Original close reason(s) were not resolved Improve this question I have been studying complex numbers (but not Calculus with them). So I have understood Arithmetic with Complex Numbers: Add, Subtract, Multiply, Divide, Exponentiate Forms of Complex Numbers: Rectangular, Polar, Exponential Roots of Unity and their basic properties Complex Plane/Argand Diagram For example, I have learnt that the general equation of a circle is $$az\overline{z}+\overline{B}z+B\overline{z}+c=0$$ And the condition for three points to form an equilateral triangle in the complex plane is: $$z_1^2 + z_2^2 + z_3^2 = z_1z_2 + z_1z_3 + z_2z_3$$ I know that as I go forward, I will learn about lines , and ellipses , parallelograms and quadrilaterals in the complex plane, with their related equations, and properties. Such questions tend to get asked in entrance exams and contest math (both of which interest me). I know that complex numbers get used in: Electrical Engineering, and that they are useful in dealing with waves/oscillations Solving contest math problems (say tiling with dominoes, or in generating functions) However, I wanted to know, where else in math will I make use of complex coordinate geometry(circles, lines, ellipses, etc). That is, what are the applications of complex coordinate geometry?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 1 year ago . This post was edited and submitted for review 1 year ago and failed to reopen the post: Original close reason(s) were not resolved Improve this question I have been studying complex numbers (but not Calculus with them). So I have understood Arithmetic with Complex Numbers: Add, Subtract, Multiply, Divide, Exponentiate Forms of Complex Numbers: Rectangular, Polar, Exponential Roots of Unity and their basic properties Complex Plane/Argand Diagram For example, I have learnt that the general equation of a circle is And the condition for three points to form an equilateral triangle in the complex plane is: I know that as I go forward, I will learn about lines , and ellipses , parallelograms and quadrilaterals in the complex plane, with their related equations, and properties. Such questions tend to get asked in entrance exams and contest math (both of which interest me). I know that complex numbers get used in: Electrical Engineering, and that they are useful in dealing with waves/oscillations Solving contest math problems (say tiling with dominoes, or in generating functions) However, I wanted to know, where else in math will I make use of complex coordinate geometry(circles, lines, ellipses, etc). That is, what are the applications of complex coordinate geometry?",az\overline{z}+\overline{B}z+B\overline{z}+c=0 z_1^2 + z_2^2 + z_3^2 = z_1z_2 + z_1z_3 + z_2z_3,"['complex-analysis', 'complex-numbers', 'soft-question', 'contest-math']"
11,Self contained exposition of second order Fuchsian ODEs,Self contained exposition of second order Fuchsian ODEs,,"I am teaching a graduate course in Complex Analysis.  I would like students to give an oral presentation at the end of the term on a topic which we did not cover in the lecture.  So I am putting together a list of textbook chapters and expository papers on various topics. One topic which I think is very nice, and uses many of the tools we will cover in the course, is the theory of second order Fuchsian ODEs.  However, I have been unable to find an exposition of this topic which is ""self contained"" in the sense that it is relatively short (10 to 15 pages) and assumes only the background of a one semester complex analysis course (basically they will know all the machinery leading up to the Residue theorem). Can anyone recommend such a resource?","I am teaching a graduate course in Complex Analysis.  I would like students to give an oral presentation at the end of the term on a topic which we did not cover in the lecture.  So I am putting together a list of textbook chapters and expository papers on various topics. One topic which I think is very nice, and uses many of the tools we will cover in the course, is the theory of second order Fuchsian ODEs.  However, I have been unable to find an exposition of this topic which is ""self contained"" in the sense that it is relatively short (10 to 15 pages) and assumes only the background of a one semester complex analysis course (basically they will know all the machinery leading up to the Residue theorem). Can anyone recommend such a resource?",,"['complex-analysis', 'ordinary-differential-equations', 'reference-request', 'monodromy']"
12,Integrating $\int^{\infty}_0\frac{x^n}{e^x-1}\text{ d}x$ using contour integration only,Integrating  using contour integration only,\int^{\infty}_0\frac{x^n}{e^x-1}\text{ d}x,"I have the integral $$I=\int^{\infty}_0\frac{x^n}{e^x-1}\text{ d}x$$ for real $n>0$ that I want to evaluate only with contour integration. (I already know the identity that $\Gamma(s)\zeta(s)=\int^{\infty}_0\frac{x^{s-1}}{\exp(x)-1}\text{ d}x$ ) I let $$f(z)=\frac{z^n}{e^z-1}$$ noting that there is a removable singularity at $0$ , and poles every $z=2\pi im$ for $m\in\mathbb{Z}, m\neq0$ . As a result, I set up the following contour $\mathcal{C}$ shown below, where I would take the limit as $R\rightarrow+\infty$ and $\epsilon\rightarrow+0$ . By the Residue theorem, $$\oint_{\mathcal{C}}f(z)\text{ d}z=\int_{\text{Right}}+\int_{\text{Top}}+\int_{\text{Left}}+\int_{\text{Bottom}}+\int_rf(z)\text{ d}z=0$$ Parameterizing the integrals yields $$\int^{2\pi}_0\frac{(R+iy)^n}{e^R e^{iy}-1}i\text{ d}y + \int^{\epsilon}_{R}\frac{(2\pi i+x)^n}{e^{2\pi i}e^x-1}\text{ d}x + \int^{0}_{2\pi-\epsilon}\frac{(iy)^n}{e^{iy}-1}i\text{ d}y + \int^{R}_0\frac{x^n}{e^x-1}\text{ d}x + \int^{-\frac\pi 2}_{0}\frac{(2\pi i+\epsilon e^{i\theta})^n}{e^{2\pi i}e^{\epsilon e^{i\theta}}-1}i\epsilon e^{i\theta}\text{ d}\theta=0$$ Since $f(z)$ approaches $0$ as $\Re(z)$ becomes large, $\int_{\text{Right}}f(z)\text{ d}z=\int^{2\pi}_0\frac{(R+iy)^n}{e^r e^{iy}-1}i\text{ d}y$ should go to $0$ . More rigorously, I moved the limit as $R\rightarrow +\infty$ inside (the function should uniformly converge I think so this is legal?) and indeed it would go to $0$ . $\int_{\text{Bottom}}f(z)\text{ d}z=I$ so we can ignore that for now. I'm thinking that we possibly could use a Laurent series for $\int_rf(z)\text{ d}z=\int^{-\frac\pi 2}_{0}\frac{(2\pi i+\epsilon e^{i\theta})^n}{e^{2\pi i}e^{\epsilon e^{i\theta}}-1}i\epsilon e^{i\theta}\text{ d}\theta$ since we're taking the limit $\epsilon\rightarrow +0$ but honestly I'm not sure how. If I directly take the limit $\epsilon\rightarrow +0$ of the integrand, Wolfram Alpha tells me it's equal to $(2\pi i)^n$ , which would mean the entire integral is equal to $2^{n-1}(i\pi)^{n+1}$ , but since it's such a complicated function I'm not sure if it uniformly converges on those bounds and thus if it is legal or not... I also tried using the Cauchy-Schwartz Inequality on $\int_{\text{Left}}f(z)\text{ d}z=\int^{0}_{2\pi-\epsilon}\frac{(iy)^n}{e^{iy}-1}i\text{ d}y$ where $$\left|\int^{0}_{2\pi}\frac{(iy)^n}{e^{iy}-1}i\text{ d}y\right|\le \int^{0}_{2\pi-\epsilon}\frac{\left|i^n\right|\left|y^n\right|}{\left|e^{iy}-1\right|}|i|\text{ d}y = \int^{0}_{2\pi-\epsilon}\frac{y^n}{\left|e^{iy}-1\right|}\text{ d}y\le \int^{0}_{2\pi-\epsilon}\frac{y^n}{\left|\left|e^{iy}\right|-\left|1\right|\right|}\text{ d}y$$ where the last part follows from $\frac{1}{|a-b|}\le\frac{1}{||a|-|b||}$ but this makes the denominator $0$ which is illegal so I probably did something wrong here. So in the end, I would have the following equation: $$I-\int^{\infty}_{0}\frac{(2\pi i+x)^n}{e^x-1}\text{ d}x - \int^{2\pi}_{0}\frac{(iy)^n}{e^{iy}-1}i\text{ d}y=2^{n-1} (i\pi)^{n+1}$$ And... I'm stuck. If anyone can help it would be really appreciated! Thanks in advance! :D","I have the integral for real that I want to evaluate only with contour integration. (I already know the identity that ) I let noting that there is a removable singularity at , and poles every for . As a result, I set up the following contour shown below, where I would take the limit as and . By the Residue theorem, Parameterizing the integrals yields Since approaches as becomes large, should go to . More rigorously, I moved the limit as inside (the function should uniformly converge I think so this is legal?) and indeed it would go to . so we can ignore that for now. I'm thinking that we possibly could use a Laurent series for since we're taking the limit but honestly I'm not sure how. If I directly take the limit of the integrand, Wolfram Alpha tells me it's equal to , which would mean the entire integral is equal to , but since it's such a complicated function I'm not sure if it uniformly converges on those bounds and thus if it is legal or not... I also tried using the Cauchy-Schwartz Inequality on where where the last part follows from but this makes the denominator which is illegal so I probably did something wrong here. So in the end, I would have the following equation: And... I'm stuck. If anyone can help it would be really appreciated! Thanks in advance! :D","I=\int^{\infty}_0\frac{x^n}{e^x-1}\text{ d}x n>0 \Gamma(s)\zeta(s)=\int^{\infty}_0\frac{x^{s-1}}{\exp(x)-1}\text{ d}x f(z)=\frac{z^n}{e^z-1} 0 z=2\pi im m\in\mathbb{Z}, m\neq0 \mathcal{C} R\rightarrow+\infty \epsilon\rightarrow+0 \oint_{\mathcal{C}}f(z)\text{ d}z=\int_{\text{Right}}+\int_{\text{Top}}+\int_{\text{Left}}+\int_{\text{Bottom}}+\int_rf(z)\text{ d}z=0 \int^{2\pi}_0\frac{(R+iy)^n}{e^R e^{iy}-1}i\text{ d}y + \int^{\epsilon}_{R}\frac{(2\pi i+x)^n}{e^{2\pi i}e^x-1}\text{ d}x + \int^{0}_{2\pi-\epsilon}\frac{(iy)^n}{e^{iy}-1}i\text{ d}y + \int^{R}_0\frac{x^n}{e^x-1}\text{ d}x + \int^{-\frac\pi 2}_{0}\frac{(2\pi i+\epsilon e^{i\theta})^n}{e^{2\pi i}e^{\epsilon e^{i\theta}}-1}i\epsilon e^{i\theta}\text{ d}\theta=0 f(z) 0 \Re(z) \int_{\text{Right}}f(z)\text{ d}z=\int^{2\pi}_0\frac{(R+iy)^n}{e^r e^{iy}-1}i\text{ d}y 0 R\rightarrow +\infty 0 \int_{\text{Bottom}}f(z)\text{ d}z=I \int_rf(z)\text{ d}z=\int^{-\frac\pi 2}_{0}\frac{(2\pi i+\epsilon e^{i\theta})^n}{e^{2\pi i}e^{\epsilon e^{i\theta}}-1}i\epsilon e^{i\theta}\text{ d}\theta \epsilon\rightarrow +0 \epsilon\rightarrow +0 (2\pi i)^n 2^{n-1}(i\pi)^{n+1} \int_{\text{Left}}f(z)\text{ d}z=\int^{0}_{2\pi-\epsilon}\frac{(iy)^n}{e^{iy}-1}i\text{ d}y \left|\int^{0}_{2\pi}\frac{(iy)^n}{e^{iy}-1}i\text{ d}y\right|\le \int^{0}_{2\pi-\epsilon}\frac{\left|i^n\right|\left|y^n\right|}{\left|e^{iy}-1\right|}|i|\text{ d}y = \int^{0}_{2\pi-\epsilon}\frac{y^n}{\left|e^{iy}-1\right|}\text{ d}y\le \int^{0}_{2\pi-\epsilon}\frac{y^n}{\left|\left|e^{iy}\right|-\left|1\right|\right|}\text{ d}y \frac{1}{|a-b|}\le\frac{1}{||a|-|b||} 0 I-\int^{\infty}_{0}\frac{(2\pi i+x)^n}{e^x-1}\text{ d}x - \int^{2\pi}_{0}\frac{(iy)^n}{e^{iy}-1}i\text{ d}y=2^{n-1} (i\pi)^{n+1}","['integration', 'complex-analysis', 'improper-integrals', 'contour-integration', 'complex-integration']"
13,Find all analytic bijections $f: \mathbb{C} \to \mathbb{C}$. Justify that there are no other analytic bijections besides those you found.,Find all analytic bijections . Justify that there are no other analytic bijections besides those you found.,f: \mathbb{C} \to \mathbb{C},"This is a question from a previous complex analysis qualifying exam. I'm working problems to study for my own upcoming qual. I'd like to know if my solution below is correct and complete or not. Thanks! Problem: Find all analytic bijections $f: \mathbb{C} \to \mathbb{C}$ . Justify that there are no other analytic bijections besides those you found. Attempted Solution: (1) Since we're looking for analytic functions on the whole complex plane, we are considering only functions which are entire. (2) A constant function is neither injective nor surjective, so clearly it is not a bijection. By Liouville's Theorem, any bounded entire function is constant. Thus, such a bijection must have a singularity at infinity since it is analytic everywhere else. (3) The singularity at infinity must be either a pole or an essential singularity. If there is an essential singularity at infinity, then by the Great Picard theorem, in any neighborhood of infinity, the function attains every value in $C$ (with at most one exception), so these functions would be ""infinity-to-1"". Thus, not bijections. (4) Finally, we are left with entire functions that have a pole at infinity. Any such function is a polynomial (since it can be written as a power series), but polynomials of degree $n$ are $n$ -to-1 functions. Thus, the only functions that are 1-to-1 are 1st degree polynomials or linear functions of the form $f(z) = \alpha z + \beta$ with $\alpha \neq 0$ . Update to include suggestion by @Greg Martin: (5) We have shown that if an entire function is a bijection, then it is linear. It remains only to show that if a function is linear, then it is an analytic bijection. We know that any polynomial is analytic. We have that a function $f(z)=\alpha z + \beta, \; \alpha\neq 0$ is injective if $f(z)=f(w) \implies z=w$ . This is straightforward as $$ \alpha z + \beta = \alpha w + \beta \implies z = w $$ by simply subtracting off $\beta$ and dividing both sides by $\alpha \neq 0$ . Then we have that $f$ is surjective if, for every $w \in \mathbb{C}$ , there exists a $z \in \mathbb{C}$ such that $f(z)=w$ . One can see that $$\alpha z + \beta = w \quad \implies z = \frac{w-\beta}{\alpha}, \; \alpha\neq 0. $$ Thus, for any $w$ there exists such a $z$ , and $f(z)$ is an analytic bijection.","This is a question from a previous complex analysis qualifying exam. I'm working problems to study for my own upcoming qual. I'd like to know if my solution below is correct and complete or not. Thanks! Problem: Find all analytic bijections . Justify that there are no other analytic bijections besides those you found. Attempted Solution: (1) Since we're looking for analytic functions on the whole complex plane, we are considering only functions which are entire. (2) A constant function is neither injective nor surjective, so clearly it is not a bijection. By Liouville's Theorem, any bounded entire function is constant. Thus, such a bijection must have a singularity at infinity since it is analytic everywhere else. (3) The singularity at infinity must be either a pole or an essential singularity. If there is an essential singularity at infinity, then by the Great Picard theorem, in any neighborhood of infinity, the function attains every value in (with at most one exception), so these functions would be ""infinity-to-1"". Thus, not bijections. (4) Finally, we are left with entire functions that have a pole at infinity. Any such function is a polynomial (since it can be written as a power series), but polynomials of degree are -to-1 functions. Thus, the only functions that are 1-to-1 are 1st degree polynomials or linear functions of the form with . Update to include suggestion by @Greg Martin: (5) We have shown that if an entire function is a bijection, then it is linear. It remains only to show that if a function is linear, then it is an analytic bijection. We know that any polynomial is analytic. We have that a function is injective if . This is straightforward as by simply subtracting off and dividing both sides by . Then we have that is surjective if, for every , there exists a such that . One can see that Thus, for any there exists such a , and is an analytic bijection.","f: \mathbb{C} \to \mathbb{C} C n n f(z) = \alpha z + \beta \alpha \neq 0 f(z)=\alpha z + \beta, \; \alpha\neq 0 f(z)=f(w) \implies z=w  \alpha z + \beta = \alpha w + \beta \implies z = w  \beta \alpha \neq 0 f w \in \mathbb{C} z \in \mathbb{C} f(z)=w \alpha z + \beta = w \quad \implies z = \frac{w-\beta}{\alpha}, \; \alpha\neq 0.  w z f(z)","['complex-analysis', 'solution-verification', 'analytic-functions']"
14,Prove $f$ is a polynomial,Prove  is a polynomial,f,"Let $f$ be defined on $\mathbb{C}$ be holomorphic. Suppose there exists and $n \in \mathbb{Z}^+$ such that $$\int_{\partial B_1(0)}\frac{f(z)}{(z-a)^n}=0$$ for all $a \in B_1(0)$ . prove $f$ is a polynomial. Here is what I have, by corollary of Cauchy's theorem we have that $$f^{(n-1)}(a)(2 \pi  i)/(n-1)!=0$$ Which implies $f^{(n-1)}(a)=0$ and this implies $f$ is a polynomial since its derivative at some point eventually is zero, specially on some finite radius ball.","Let be defined on be holomorphic. Suppose there exists and such that for all . prove is a polynomial. Here is what I have, by corollary of Cauchy's theorem we have that Which implies and this implies is a polynomial since its derivative at some point eventually is zero, specially on some finite radius ball.",f \mathbb{C} n \in \mathbb{Z}^+ \int_{\partial B_1(0)}\frac{f(z)}{(z-a)^n}=0 a \in B_1(0) f f^{(n-1)}(a)(2 \pi  i)/(n-1)!=0 f^{(n-1)}(a)=0 f,"['complex-analysis', 'solution-verification']"
15,Conditions and correct interpretation of Borel summation,Conditions and correct interpretation of Borel summation,,"Hello to the community. In my line of research (theoretical particle physics) it is customary to apply the strategy of Borel summation to infinite power series in order to find closed forms and/or numerical estimates. However, I have the feeling things are often not done very rigurously, so I want to see if the mathematicians here can help me understand how it works. I have a power series $R(x)\equiv\sum^{\infty}_{n=1}r_nx^n$ that I rewritte using the integral definition of the gamma function as $$R(x)=\sum^{\infty}_{n=1}\frac{r_{n+1}}{n!}x^{n+1}\int_{0}^{\infty}e^{-t}t^n.$$ So far so good, but now people do two things. The sum and the integral cannot be in general interchanged, so they define the Borel sum of the series as $$ R_B(x)\equiv\int_{0}^{\infty}e^{-t}\sum^{\infty}_{n=0}\frac{r_{n+1}}{n!}x^{n+1}t^n. $$ They are only interested in $x>0$ , so they define $u\equiv xt$ and rewrite $R_B$ as (the integration limits remain unaltered) $$ R_B(x)\equiv\int_{0}^{\infty}e^{-u/x}\sum^{\infty}_{n=0}\frac{r_{n+1}}{n!}u^n. $$ The series in the integrand is referred to as the Borel transform of the original series and denoted as $B[R(x)](u)$ . In my field, this strategy is tipically used for series where $r_n$ diverges factorially for large $n$ . Since the series is (or is related to) a physical magnitude, we assume that, despite divergent, the series must constitute an asymptotic expansion of some unknown function. We perform the Borel transform of the series, sum the result up, and then perform the integral, and the result is interpreted as an estimate of the said unknown function. My questions are: When is $R_B(x)$ equal to $R(x)$ ? This is, when can the sum and the integral be interchanged? If $B[R(x)](u)=\sum^{\infty}_{n=0}\frac{r_{n+1}}{n!}u^n$ converges for $|u|<r<\infty$ can we still integrate the result from $u=0$ to $\infty$ ? If the original series has a finite convergence radius, how is $R_B(x)$ going to carry that information? There is an example in wikipedia on how Borel summation is applied to the geometric series $\sum_{n=0}^\infty x^n$ . The original series is converges to $1/(1-x)$ for $|x|<1$ , and the integral returns the same expression but under the weaker condition $\mathrm{Re}(x)<1$ . It says then that Borel summation provides ""an analytical contnuation of the known result "" $1/(1-x)$ "". What does this mean exactly? Thanks in advance!","Hello to the community. In my line of research (theoretical particle physics) it is customary to apply the strategy of Borel summation to infinite power series in order to find closed forms and/or numerical estimates. However, I have the feeling things are often not done very rigurously, so I want to see if the mathematicians here can help me understand how it works. I have a power series that I rewritte using the integral definition of the gamma function as So far so good, but now people do two things. The sum and the integral cannot be in general interchanged, so they define the Borel sum of the series as They are only interested in , so they define and rewrite as (the integration limits remain unaltered) The series in the integrand is referred to as the Borel transform of the original series and denoted as . In my field, this strategy is tipically used for series where diverges factorially for large . Since the series is (or is related to) a physical magnitude, we assume that, despite divergent, the series must constitute an asymptotic expansion of some unknown function. We perform the Borel transform of the series, sum the result up, and then perform the integral, and the result is interpreted as an estimate of the said unknown function. My questions are: When is equal to ? This is, when can the sum and the integral be interchanged? If converges for can we still integrate the result from to ? If the original series has a finite convergence radius, how is going to carry that information? There is an example in wikipedia on how Borel summation is applied to the geometric series . The original series is converges to for , and the integral returns the same expression but under the weaker condition . It says then that Borel summation provides ""an analytical contnuation of the known result "" "". What does this mean exactly? Thanks in advance!","R(x)\equiv\sum^{\infty}_{n=1}r_nx^n R(x)=\sum^{\infty}_{n=1}\frac{r_{n+1}}{n!}x^{n+1}\int_{0}^{\infty}e^{-t}t^n. 
R_B(x)\equiv\int_{0}^{\infty}e^{-t}\sum^{\infty}_{n=0}\frac{r_{n+1}}{n!}x^{n+1}t^n.
 x>0 u\equiv xt R_B 
R_B(x)\equiv\int_{0}^{\infty}e^{-u/x}\sum^{\infty}_{n=0}\frac{r_{n+1}}{n!}u^n.
 B[R(x)](u) r_n n R_B(x) R(x) B[R(x)](u)=\sum^{\infty}_{n=0}\frac{r_{n+1}}{n!}u^n |u|<r<\infty u=0 \infty R_B(x) \sum_{n=0}^\infty x^n 1/(1-x) |x|<1 \mathrm{Re}(x)<1 1/(1-x)","['real-analysis', 'sequences-and-series', 'complex-analysis', 'asymptotics', 'power-series']"
16,Maximizing an absolute value of some complex polynomial.,Maximizing an absolute value of some complex polynomial.,,"Let $ \lambda \in \mathbb{C} $ be any complex number, $ R > 0 $ some positive real. I want to find maxima of absolute value of some polynomial on the circle: $$ \max (|x-1| |x-\lambda|) = \max| x^2 - (\lambda + 1)x + \lambda | = \max|P(x)|, $$ where $ |x| = R\ $ and $\ P(x) = x^2 - (\lambda + 1)x + \lambda $ . It is not hard to find maximal value for concrete values of $R$ , but I want it as function of $R$ and $\lambda$ . I tried two things. Firstly, polar coordinates: $ x = R e^{i \phi} $ , $\lambda = L e^{i\psi} $ . After some calculations I got the following equation: $$ (L^2 + R^2) \sin(\phi) + L(1 + R^2) \sin(\phi - \psi) - 2LR\sin(2\phi - \psi) = 0. $$ We have to solve it for $\phi$ . I don't know, how to do it (neither does Wolframalpha). Secondly, I notice that if $x_m$ is the point of maxima on the circle, then $$ Arg \frac{P(x_m)}{P'(x_m)} = Arg (x_m). $$ The reason is that in other way we could step a little inside the cirle and increase the $ |P(x)| $ (it is almost obvious if you draw the picture). But that would be contrary to the maximum modulus principle ( $ P(x) $ is holomorphic). That gives us folowing: $$ \frac{x_m^2 - (\lambda+1)x_m + \lambda}{2x_m^2 - (\lambda+1)x_m} \in \mathbb{R}_+. $$ And again, I do not know, what can you do next. Maybe there is some geometry approach?","Let be any complex number, some positive real. I want to find maxima of absolute value of some polynomial on the circle: where and . It is not hard to find maximal value for concrete values of , but I want it as function of and . I tried two things. Firstly, polar coordinates: , . After some calculations I got the following equation: We have to solve it for . I don't know, how to do it (neither does Wolframalpha). Secondly, I notice that if is the point of maxima on the circle, then The reason is that in other way we could step a little inside the cirle and increase the (it is almost obvious if you draw the picture). But that would be contrary to the maximum modulus principle ( is holomorphic). That gives us folowing: And again, I do not know, what can you do next. Maybe there is some geometry approach?"," \lambda \in \mathbb{C}   R > 0   \max (|x-1| |x-\lambda|) = \max| x^2 - (\lambda + 1)x + \lambda | = \max|P(x)|,   |x| = R\  \ P(x) = x^2 - (\lambda + 1)x + \lambda  R R \lambda  x = R e^{i \phi}  \lambda = L e^{i\psi}   (L^2 + R^2) \sin(\phi) + L(1 + R^2) \sin(\phi - \psi) - 2LR\sin(2\phi - \psi) = 0.  \phi x_m  Arg \frac{P(x_m)}{P'(x_m)} = Arg (x_m).   |P(x)|   P(x)   \frac{x_m^2 - (\lambda+1)x_m + \lambda}{2x_m^2 - (\lambda+1)x_m} \in \mathbb{R}_+. ","['complex-analysis', 'geometry', 'optimization', 'complex-numbers', 'analytic-geometry']"
17,Expressing $ \sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}} \left \lfloor x^{1/n}-1 \right \rfloor$ in terms of the nontrivial zeros of $\zeta(s)$,Expressing  in terms of the nontrivial zeros of, \sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}} \left \lfloor x^{1/n}-1 \right \rfloor \zeta(s),"Let $\left \lfloor \cdot \right \rfloor$ be the floor function. Is there a way to express the function $A(x)$ given by : $$A(x)=\sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}} \left \lfloor x^{1/n}-1 \right \rfloor\;\;\;\;\; (x \geqslant 2)$$ in terms of the nontrivial zeros of the Riemann zeta function? The motivation behind the question is that there is a somewhat similar situation with [the second Chebyshev function $\psi(x)$ ][1], where we have the formula: $$\log\left(\left \lfloor x \right \rfloor !\right )=\sum_{n=1}^{\infty}\psi\left(\frac{x}{n} \right )$$ and by Mbius inversion, we have : $$\psi(x)=\sum_{n=1}^{\infty}\mu(n)\log\left(\left \lfloor \frac{x}{n} \right \rfloor !\right )=x-\sum_{\rho}\frac{x^{\rho}}{\rho}-\log(2\pi)-\frac{1}{2}\log(1-x^{-2})$$ So, on the LHS we have a summation in terms of a trivial number-theoretic function - $\log\left \lfloor x \right \rfloor !$ - that terminates at a finite $n$ , and on the RHS we have a Fourier series in terms of the nontrivial zeros of zeta. My attempt: We won't deal with the smooth part of $A(x)$ , as it's quite easy to obtain. The oscillatory part is given by: $$f(x)=\sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}}\left \{ x^{1/n} \right \}$$ For convenience,  we replace f(x) by the function $g(x)$ : $$g(x)=f\left(e^{x}\right)-\frac{3}{\pi^{2}}=\sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}}p\left(e^{x/n}\right)$$ where $p(\cdot)$ is the sawtooth function, which has the Fourier expansion : $$p\left(e^{x/n}\right)=-\sum_{m=1}^{\infty}\frac{1}{2\pi i m}\left(\exp(2\pi i me^{x/n} )-\exp(-2\pi i me^{x/n} )\right)$$ $$=-\sum_{m=1}^{\infty}\frac{1}{2\pi i m}\left(\exp\left(2\pi i m\left(e^{x/n}-1\right)\right) -\exp\left(-2\pi i m\left(e^{x/n}-1\right)\right) \right)$$ Assuming we can reverse the order of the summation - i have no proof! - we have that : $$g(x)=\sum_{m=1}^{\infty}\frac{\phi(m,x)}{m}$$ where we define : $$\phi(m,x)=-\frac{1}{2\pi i }\sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}}\left(\exp\left(2\pi i m\left(e^{x/n}-1\right)\right) -\exp\left(-2\pi i m\left(e^{x/n}-1\right)\right) \right)$$ Using the generating function of the [Touchard polynomials][2] $T_{k}(\cdot)$ , we have : $$\frac{1}{2\pi i}\left(\exp\left(2\pi i m\left(e^{x/n}-1\right)\right) -\exp\left(-2\pi i m\left(e^{x/n}-1\right)\right) \right)=\frac{1}{\pi}\sum_{k=0}^{\infty}\frac{\tilde{T}_{k}(2\pi m)}{k!}\left(\frac{x}{n}\right)^{k}$$ Where we define : $$\tilde{T}_{k}(2\pi m)=\frac{1}{2i}\left(T_{k}(2\pi i m)-T_{k}(-2\pi i m)\right)=\sum_{l=0}^{\infty}\frac{(2\pi m)^{l}}{l!}l^{k}\sin\left(\frac{\pi l}{2}\right)$$ Thus : $$\phi(m,x)=-\frac{1}{\pi}\sum_{k=0}^{\infty}\frac{\tilde{T}_{k}(2\pi m)}{\zeta(k+2)k!}x^{k}=-\frac{1}{\pi}\sum_{k=0}^{\infty}\frac{(-1)^{k}\tilde{T}_{k}(2\pi m)}{\zeta(k+2)k!}(-x)^{k}$$ Making use of Ramanujan's master theorem, we have for some vertical strip in the complex $s$ plane : $$\int_{0}^{\infty}\phi(x,m)x^{s-1}dx=-\frac{1}{\pi}\frac{\Gamma(s)G_{m}(s)}{\zeta(2-s)}$$ where we define the Dirichlet-Taylor series : $$G_{m}(s)=(-1)^{-s}\sum_{l=1}^{\infty}\frac{(2\pi m)^{l}}{l^{s}l!}\sin\left(\frac{\pi l }{2}\right)$$ Now, by Millin inversion theorem, we have : $$\phi(m,x)=-\frac{1}{2\pi^{2} i }\int_{\gamma-i\infty}^{\gamma+i\infty}\frac{\Gamma(s)G_{m}(s)}{\zeta(2-s)}x^{-s}ds$$ The function $G_{m}(s)$ is clearly holomorphic. and if one shifts the path of integration properly, the contributions to the resulting series come only from the nontrivial zeros of $\zeta(2-s)$ Is this line of thought legit? [1]: https://mathworld.wolfram.com/MangoldtFunction.html [2]: https://en.wikipedia.org/wiki/Touchard_polynomials","Let be the floor function. Is there a way to express the function given by : in terms of the nontrivial zeros of the Riemann zeta function? The motivation behind the question is that there is a somewhat similar situation with [the second Chebyshev function ][1], where we have the formula: and by Mbius inversion, we have : So, on the LHS we have a summation in terms of a trivial number-theoretic function - - that terminates at a finite , and on the RHS we have a Fourier series in terms of the nontrivial zeros of zeta. My attempt: We won't deal with the smooth part of , as it's quite easy to obtain. The oscillatory part is given by: For convenience,  we replace f(x) by the function : where is the sawtooth function, which has the Fourier expansion : Assuming we can reverse the order of the summation - i have no proof! - we have that : where we define : Using the generating function of the [Touchard polynomials][2] , we have : Where we define : Thus : Making use of Ramanujan's master theorem, we have for some vertical strip in the complex plane : where we define the Dirichlet-Taylor series : Now, by Millin inversion theorem, we have : The function is clearly holomorphic. and if one shifts the path of integration properly, the contributions to the resulting series come only from the nontrivial zeros of Is this line of thought legit? [1]: https://mathworld.wolfram.com/MangoldtFunction.html [2]: https://en.wikipedia.org/wiki/Touchard_polynomials","\left \lfloor \cdot \right \rfloor A(x) A(x)=\sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}} \left \lfloor x^{1/n}-1 \right \rfloor\;\;\;\;\; (x \geqslant 2) \psi(x) \log\left(\left \lfloor x \right \rfloor !\right )=\sum_{n=1}^{\infty}\psi\left(\frac{x}{n} \right ) \psi(x)=\sum_{n=1}^{\infty}\mu(n)\log\left(\left \lfloor \frac{x}{n} \right \rfloor !\right )=x-\sum_{\rho}\frac{x^{\rho}}{\rho}-\log(2\pi)-\frac{1}{2}\log(1-x^{-2}) \log\left \lfloor x \right \rfloor ! n A(x) f(x)=\sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}}\left \{ x^{1/n} \right \} g(x) g(x)=f\left(e^{x}\right)-\frac{3}{\pi^{2}}=\sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}}p\left(e^{x/n}\right) p(\cdot) p\left(e^{x/n}\right)=-\sum_{m=1}^{\infty}\frac{1}{2\pi i m}\left(\exp(2\pi i me^{x/n} )-\exp(-2\pi i me^{x/n} )\right) =-\sum_{m=1}^{\infty}\frac{1}{2\pi i m}\left(\exp\left(2\pi i m\left(e^{x/n}-1\right)\right) -\exp\left(-2\pi i m\left(e^{x/n}-1\right)\right) \right) g(x)=\sum_{m=1}^{\infty}\frac{\phi(m,x)}{m} \phi(m,x)=-\frac{1}{2\pi i }\sum_{n=1}^{\infty}\frac{\mu(n)}{n^{2}}\left(\exp\left(2\pi i m\left(e^{x/n}-1\right)\right) -\exp\left(-2\pi i m\left(e^{x/n}-1\right)\right) \right) T_{k}(\cdot) \frac{1}{2\pi i}\left(\exp\left(2\pi i m\left(e^{x/n}-1\right)\right) -\exp\left(-2\pi i m\left(e^{x/n}-1\right)\right) \right)=\frac{1}{\pi}\sum_{k=0}^{\infty}\frac{\tilde{T}_{k}(2\pi m)}{k!}\left(\frac{x}{n}\right)^{k} \tilde{T}_{k}(2\pi m)=\frac{1}{2i}\left(T_{k}(2\pi i m)-T_{k}(-2\pi i m)\right)=\sum_{l=0}^{\infty}\frac{(2\pi m)^{l}}{l!}l^{k}\sin\left(\frac{\pi l}{2}\right) \phi(m,x)=-\frac{1}{\pi}\sum_{k=0}^{\infty}\frac{\tilde{T}_{k}(2\pi m)}{\zeta(k+2)k!}x^{k}=-\frac{1}{\pi}\sum_{k=0}^{\infty}\frac{(-1)^{k}\tilde{T}_{k}(2\pi m)}{\zeta(k+2)k!}(-x)^{k} s \int_{0}^{\infty}\phi(x,m)x^{s-1}dx=-\frac{1}{\pi}\frac{\Gamma(s)G_{m}(s)}{\zeta(2-s)} G_{m}(s)=(-1)^{-s}\sum_{l=1}^{\infty}\frac{(2\pi m)^{l}}{l^{s}l!}\sin\left(\frac{\pi l }{2}\right) \phi(m,x)=-\frac{1}{2\pi^{2} i }\int_{\gamma-i\infty}^{\gamma+i\infty}\frac{\Gamma(s)G_{m}(s)}{\zeta(2-s)}x^{-s}ds G_{m}(s) \zeta(2-s)","['complex-analysis', 'fourier-series', 'analytic-number-theory']"
18,Integral of the Laurent series with Bessel function coefficients,Integral of the Laurent series with Bessel function coefficients,,"I'm trying to integrate a function of the following form, where $A$ and $B$ are both positive: $$\int_0^{\infty}\exp\left(\frac{A}{2}\left(\frac{B}{1+x^2}-\frac{1+x^2}{B}\right)\right)dx.$$ My first inclination was to put it into Laurent series form, which I eventually discovered was $$\int_0^{\infty} \sum_{k=-\infty}^{\infty} J_k(A)\left(\frac{B} {1+x^2}\right)^kdx.$$ Where $J_n(x)$ is the $n$ th order Bessel function of the first kind. Integrating the series directly was useless. Then, I thought I could try out a complex representation. I know this function is even, and with some basic analysis of the Laurent series shows that if I integrate around a semi circle of radius $R$ pointed up from the $x$ -axis, the integral around the contour should be: $$\oint_C\exp\left(\frac{A}{2}\left(\frac{B}{1+x^2}-\frac{1+x^2}{B}\right)\right)dx = J_1(A)B\pi.$$ I figured I could take the limit as $R$ increased without bound and get my answer, but swiftly realized that the circular contour does not seem to die off to zero as $R$ increases without bound. My question is either: what is the value of the following integral $$\lim_{R \to \infty}Ri\int_0^\pi\exp\left(\frac{A}{2}\left(\frac{B}{1+R^2e^{2\theta i}}-\frac{1+R^2e^{2\theta i}}{B}\right)\right)e^{\theta i}d\theta.$$ Or How else can I evaluate the initial integral? A numerical solution is fine, so long as it covers $A$ and $B$ being both large and close to zero.","I'm trying to integrate a function of the following form, where and are both positive: My first inclination was to put it into Laurent series form, which I eventually discovered was Where is the th order Bessel function of the first kind. Integrating the series directly was useless. Then, I thought I could try out a complex representation. I know this function is even, and with some basic analysis of the Laurent series shows that if I integrate around a semi circle of radius pointed up from the -axis, the integral around the contour should be: I figured I could take the limit as increased without bound and get my answer, but swiftly realized that the circular contour does not seem to die off to zero as increases without bound. My question is either: what is the value of the following integral Or How else can I evaluate the initial integral? A numerical solution is fine, so long as it covers and being both large and close to zero.",A B \int_0^{\infty}\exp\left(\frac{A}{2}\left(\frac{B}{1+x^2}-\frac{1+x^2}{B}\right)\right)dx. \int_0^{\infty} \sum_{k=-\infty}^{\infty} J_k(A)\left(\frac{B} {1+x^2}\right)^kdx. J_n(x) n R x \oint_C\exp\left(\frac{A}{2}\left(\frac{B}{1+x^2}-\frac{1+x^2}{B}\right)\right)dx = J_1(A)B\pi. R R \lim_{R \to \infty}Ri\int_0^\pi\exp\left(\frac{A}{2}\left(\frac{B}{1+R^2e^{2\theta i}}-\frac{1+R^2e^{2\theta i}}{B}\right)\right)e^{\theta i}d\theta. A B,"['complex-analysis', 'definite-integrals', 'numerical-methods', 'contour-integration', 'bessel-functions']"
19,Solutions to nonlinear PDE derived from the Dirichlet energy in the stereographic plane,Solutions to nonlinear PDE derived from the Dirichlet energy in the stereographic plane,,"Define a complex valued function $z$ in the stereographic plane and let $z=z(s,s^{*})$ for $s$ a complex valued variable and $*$ denoting the complex conjugate. Define the Dirichlet energy as $$ \int \frac{\lvert z_s \rvert^{2} + \lvert z_{s^{*}} \rvert^{2}}{(1 + \lvert z \rvert^{2})^{2}} \ ds ds^*. $$ Minimizing this with respect to $z^*$ we find that $z$ must satisfy the following nonlinear PDE: $$(1 + \lvert z \rvert^{2}) z_{s s^*} = 2 z^{*} z_s z_{s^{*}}. $$ Some simple solutions to this are $z = f(s)$ or $z = g(s^{*})$ for arbitrary functions $f, g$ . Are there other known solutions to this equation? Edit added: Are these solutions related to the spherical harmonics? If so, how can we compose two solutions in the stereographic plane to find another solution? I see reference to this equation here , but cannot find other useful references. Any tips on work that has been done on this equation are appreciated.","Define a complex valued function in the stereographic plane and let for a complex valued variable and denoting the complex conjugate. Define the Dirichlet energy as Minimizing this with respect to we find that must satisfy the following nonlinear PDE: Some simple solutions to this are or for arbitrary functions . Are there other known solutions to this equation? Edit added: Are these solutions related to the spherical harmonics? If so, how can we compose two solutions in the stereographic plane to find another solution? I see reference to this equation here , but cannot find other useful references. Any tips on work that has been done on this equation are appreciated.","z z=z(s,s^{*}) s *  \int \frac{\lvert z_s \rvert^{2} + \lvert z_{s^{*}} \rvert^{2}}{(1 + \lvert z \rvert^{2})^{2}} \ ds ds^*.  z^* z (1 + \lvert z \rvert^{2}) z_{s s^*} = 2 z^{*} z_s z_{s^{*}}.  z = f(s) z = g(s^{*}) f, g","['complex-analysis', 'differential-geometry', 'partial-differential-equations']"
20,Show that $\operatorname{Log}\left ( 1+\frac{1}{z} \right )=\operatorname{Log}(z+1)-\operatorname{Log}(z)$,Show that,\operatorname{Log}\left ( 1+\frac{1}{z} \right )=\operatorname{Log}(z+1)-\operatorname{Log}(z),"It is well-known that whenever $a,b$ are non-zero complex numbers, then $\operatorname{Log}(a/b)=\operatorname{Log}(a)-\operatorname{Log}(b)+2\pi i k$ for some integer $k$ . Here $\operatorname{Log}$ denotes the principal logarithm. I read somewhere without explanation that $$ \operatorname{Log}\left ( 1+\frac{1}{z} \right )=\operatorname{Log}(z+1)-\operatorname{Log}(z)\tag{*} $$ for all $z\in \mathbb{C}\setminus (-\infty,0]$ . Is this valid in general? If so, why? I checked it myself to insert some values of $z$ in $\mathbb{C}\setminus (-\infty,0]$ and compare on both sides, and they look good. However, I can't seem to prove it in general, or that $k$ should be $0$ in that case (where $a=z+1$ and $b=z$ ). Update : I have tried a slightly different way, though I might err: Write $x=a+ib$ , then $$ \frac{z+1}{z}=1+\frac{a}{a^2+b^2}+i\frac{-b}{a^2+b^2}.\tag{**} $$ If $a>0$ , (*) is valid, as equality holds whenever $\Re z+1,\Re z>0$ . If $a=0$ , then (**) is reduced to $1-i/b$ , so $\operatorname{Log}(\frac{z+1}{z})=\ln|1-i/b|+\arctan(-1/b)$ , while $\operatorname{Log}(z+1)-\operatorname{Log}(z)=\ln|1-i/b|+\arctan(b)-\operatorname{Arg}(ib)$ . $\qquad$ If $b>0$ , then the latter would be equal to $\ln|1-i/b|+\arctan(b)-\pi/2$ . $\qquad$ For $b<0$ , we would instead get $\ln|1-i/b|+\arctan(b)+\pi/2$ . In both cases, I suspect that $\arctan(-1/b)$ is equal to $\arctan(b)-\pi/2$ for $b>0$ and equal to $\arctan(b)+\pi/2$ for $b<0$ . I checked it with Graph calculator, and left hand side and right hand side seem to coincide. How to prove it rigorously? See update 2 below. If $a<0$ , replace $a$ by $-a'$ for $a'>0$ , then (*) is still valid for $a'>0$ . Update 2 : Define $f(x)=\arctan(-1/x)-\arctan(x)$ for $x\neq 0$ . Then, we see that $f'(x)=0$ , so $f$ must surely be constant. But, since $f(1)=-\pi/2$ , it follows that $f(x)=-\pi/2$ for all $x\neq 0$ . But, this is not entirely true, as $f(x)$ is $\pi/2$ for negative $x$ . Where is the flaw in my argument?","It is well-known that whenever are non-zero complex numbers, then for some integer . Here denotes the principal logarithm. I read somewhere without explanation that for all . Is this valid in general? If so, why? I checked it myself to insert some values of in and compare on both sides, and they look good. However, I can't seem to prove it in general, or that should be in that case (where and ). Update : I have tried a slightly different way, though I might err: Write , then If , (*) is valid, as equality holds whenever . If , then (**) is reduced to , so , while . If , then the latter would be equal to . For , we would instead get . In both cases, I suspect that is equal to for and equal to for . I checked it with Graph calculator, and left hand side and right hand side seem to coincide. How to prove it rigorously? See update 2 below. If , replace by for , then (*) is still valid for . Update 2 : Define for . Then, we see that , so must surely be constant. But, since , it follows that for all . But, this is not entirely true, as is for negative . Where is the flaw in my argument?","a,b \operatorname{Log}(a/b)=\operatorname{Log}(a)-\operatorname{Log}(b)+2\pi i k k \operatorname{Log} 
\operatorname{Log}\left ( 1+\frac{1}{z} \right )=\operatorname{Log}(z+1)-\operatorname{Log}(z)\tag{*}
 z\in \mathbb{C}\setminus (-\infty,0] z \mathbb{C}\setminus (-\infty,0] k 0 a=z+1 b=z x=a+ib 
\frac{z+1}{z}=1+\frac{a}{a^2+b^2}+i\frac{-b}{a^2+b^2}.\tag{**}
 a>0 \Re z+1,\Re z>0 a=0 1-i/b \operatorname{Log}(\frac{z+1}{z})=\ln|1-i/b|+\arctan(-1/b) \operatorname{Log}(z+1)-\operatorname{Log}(z)=\ln|1-i/b|+\arctan(b)-\operatorname{Arg}(ib) \qquad b>0 \ln|1-i/b|+\arctan(b)-\pi/2 \qquad b<0 \ln|1-i/b|+\arctan(b)+\pi/2 \arctan(-1/b) \arctan(b)-\pi/2 b>0 \arctan(b)+\pi/2 b<0 a<0 a -a' a'>0 a'>0 f(x)=\arctan(-1/x)-\arctan(x) x\neq 0 f'(x)=0 f f(1)=-\pi/2 f(x)=-\pi/2 x\neq 0 f(x) \pi/2 x","['complex-analysis', 'logarithms']"
21,Solution verification. Extension of a series,Solution verification. Extension of a series,,"I'm trying to follow this argument but with a slight difference: Continuation of series using Cahen-Mellin integral. I start with $\Phi(s)=\sum_{n=1}^\infty e^{-n^s},$ which converges iff $s>0$ is real. Applying the Mellin inversion theorem we have that: $$e^{\frac{1}{\ln(x)}}=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{2K_1(2\sqrt{z})}{\sqrt{z}}x^{-z}~dz$$ Where $K$ is a modified Bessel function of the second kind. Then letting $x=e^{-n^{-s}}$ we have: $$\Phi(s)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{2K_1(2\sqrt{z})}{\sqrt{z}}\bigg(\sum_{n=1}^\infty e^{zn^{-s}}\bigg)~dz$$ Am I on the right track? How do I get to the solution?",I'm trying to follow this argument but with a slight difference: Continuation of series using Cahen-Mellin integral. I start with which converges iff is real. Applying the Mellin inversion theorem we have that: Where is a modified Bessel function of the second kind. Then letting we have: Am I on the right track? How do I get to the solution?,"\Phi(s)=\sum_{n=1}^\infty e^{-n^s}, s>0 e^{\frac{1}{\ln(x)}}=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{2K_1(2\sqrt{z})}{\sqrt{z}}x^{-z}~dz K x=e^{-n^{-s}} \Phi(s)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{2K_1(2\sqrt{z})}{\sqrt{z}}\bigg(\sum_{n=1}^\infty e^{zn^{-s}}\bigg)~dz","['sequences-and-series', 'complex-analysis', 'solution-verification', 'contour-integration', 'residue-calculus']"
22,Do both real and imaginary roots of a cubic equation need to continuous?,Do both real and imaginary roots of a cubic equation need to continuous?,,"I have a cubic equation: $X^3-UX^2-KX-L=0$ (1) with $X=1-E+U$ , $K=4(1-\gamma^2-\lambda^2)$ , $L=4\gamma^2U$ . I solve Eq. (1) for the variable $E$ numerically for $U=2$ and different sets of parameter $\gamma =$ 0.1, 0.25, and 0.45 and plot real and imaginary parts of $E$ against $\lambda$ . The real parts of the solutions for $X$ and $E$ differ by a constant shift for a fixed value of $U$ while the imaginary parts remain identical. See the plots below. The plots plot all the roots or solutions. They are colored with three different colors by looking at the possible continuity of the roots or the solutions (here stressed on the continuity of the imaginary parts). Here we see for the first case $\gamma = 0.1$ , the continuity in the real parts of $E$ (Re $E$ ) break down while the imaginary parts (Im $E$ ) remain continuous for all parameter values of $\gamma$ . Since the solutions are found for discrete values of $\lambda$ , we may think that extreme left and right of the cyan and blue curves of the first plot can be interchanged and hence made Re $E$ continuous all the way. However, that may lead Im $E$ to be discontinuous for other parameter values of $\gamma$ (I can add images if further clarity is needed). How can we interpret or understand this? Or is there something fundamentally wrong? The alternative coloring for the first two plots could be the following (in this sense all the curves appear continuous function of $\lambda$ ). Real part: Imaginary part: Though the above fixes the continuity issue, it appears that all three curves do not smoothly evolve with parameter $\gamma$ . Experts' opinions awaited.","I have a cubic equation: (1) with , , . I solve Eq. (1) for the variable numerically for and different sets of parameter 0.1, 0.25, and 0.45 and plot real and imaginary parts of against . The real parts of the solutions for and differ by a constant shift for a fixed value of while the imaginary parts remain identical. See the plots below. The plots plot all the roots or solutions. They are colored with three different colors by looking at the possible continuity of the roots or the solutions (here stressed on the continuity of the imaginary parts). Here we see for the first case , the continuity in the real parts of (Re ) break down while the imaginary parts (Im ) remain continuous for all parameter values of . Since the solutions are found for discrete values of , we may think that extreme left and right of the cyan and blue curves of the first plot can be interchanged and hence made Re continuous all the way. However, that may lead Im to be discontinuous for other parameter values of (I can add images if further clarity is needed). How can we interpret or understand this? Or is there something fundamentally wrong? The alternative coloring for the first two plots could be the following (in this sense all the curves appear continuous function of ). Real part: Imaginary part: Though the above fixes the continuity issue, it appears that all three curves do not smoothly evolve with parameter . Experts' opinions awaited.",X^3-UX^2-KX-L=0 X=1-E+U K=4(1-\gamma^2-\lambda^2) L=4\gamma^2U E U=2 \gamma = E \lambda X E U \gamma = 0.1 E E E \gamma \lambda E E \gamma \lambda \gamma,"['complex-analysis', 'complex-numbers', 'continuity', 'roots']"
23,Use contour integration to calculate $\int_{-\infty}^{+\infty} \frac{\sin^2(x)}{x^2+a^2}dx$,Use contour integration to calculate,\int_{-\infty}^{+\infty} \frac{\sin^2(x)}{x^2+a^2}dx,"Use contour integration to calculate the integral $\int_{-\infty}^{+\infty} \frac{\sin^2(x)}{x^2+a^2}dx$ with $a>0$ For this I have a solution (where they expand $\sin^2(x) = \frac{1}{2}(1-\cos(2x))$ and then put $\sin^2(x) = \frac{1}{2}\Re(1-e^{2it})$ . But when I first attempted it I tried it with the function $$f(z) = \frac{\sin^2(z)}{z^2+a^2}.$$ I know that the poles are $+ia,-ia$ . Consider a contour integral which is a halfcircle on the upperhalf plane, $\gamma_R = [-R,R] \cup C_R$ . With the residue formula $\int_{\gamma_R}f(z) dz$ gives me $\frac{\pi}{a}(\sinh(a))^2$ . But I'm having troubles with getting $\int_{C_R} f(z)dz \leq 0$ . I first tried this \begin{align} \big|\int_{C_R} f(z)dz\big| &\leq \int_{C_R}\big|\frac{\sin^2(x)}{x^2+a^2}\big|dz\\ &\leq \int_{C_R}\big|\frac{1}{x^2+a^2}\big|dz \end{align} But apparently $sin(z)\nleq 1$ for $z \in \mathbb{C}$ . My question is, is it possible to find an estimate with this complex function so that I can get $\int_{C_R} f(z)dz \leq 0$ ? Or do I have to use the formula $\sin^2(x) = \frac{1}{2}(1-\cos(2x))$ ?","Use contour integration to calculate the integral with For this I have a solution (where they expand and then put . But when I first attempted it I tried it with the function I know that the poles are . Consider a contour integral which is a halfcircle on the upperhalf plane, . With the residue formula gives me . But I'm having troubles with getting . I first tried this But apparently for . My question is, is it possible to find an estimate with this complex function so that I can get ? Or do I have to use the formula ?","\int_{-\infty}^{+\infty} \frac{\sin^2(x)}{x^2+a^2}dx a>0 \sin^2(x) = \frac{1}{2}(1-\cos(2x)) \sin^2(x) = \frac{1}{2}\Re(1-e^{2it}) f(z) = \frac{\sin^2(z)}{z^2+a^2}. +ia,-ia \gamma_R = [-R,R] \cup C_R \int_{\gamma_R}f(z) dz \frac{\pi}{a}(\sinh(a))^2 \int_{C_R} f(z)dz \leq 0 \begin{align}
\big|\int_{C_R} f(z)dz\big| &\leq \int_{C_R}\big|\frac{\sin^2(x)}{x^2+a^2}\big|dz\\
&\leq \int_{C_R}\big|\frac{1}{x^2+a^2}\big|dz
\end{align} sin(z)\nleq 1 z \in \mathbb{C} \int_{C_R} f(z)dz \leq 0 \sin^2(x) = \frac{1}{2}(1-\cos(2x))","['complex-analysis', 'complex-numbers', 'contour-integration', 'complex-integration']"
24,Complex eigenvalues of a polynomial-valued matrix,Complex eigenvalues of a polynomial-valued matrix,,"I'm working on the following problem: Let $A(z)$ be an $n \times n$ matrix whose entries $A_{ij}(z)$ are polynomials in $z$ . Let $\lambda_j(z), j = 1,\dots,n$ be the eigenvalues of $A(z)$ . If $\lambda_j(z_0)$ is a simple eigenvalue, show that $\lambda_j(z)$ is holomorphic in a neighborhood of $z_0$ . If $\lambda_j(z_0)$ has multiplicity $p$ , show that there is a representation $\lambda_j(z) = \sum_{k=0}^{\infty} c_k (z - z_0)^{\frac{k}{l}}$ for some $1 \leqslant l \leqslant p$ . Let $P(z,w) = \det (A(z) - wI)$ , then $P$ is a polynomial in $z,w$ . If $\lambda_j(z_0)$ is simple, then $P(z,\lambda_j(z_0)) = 0$ and $\frac{\partial P}{\partial w}(z_0, \lambda_j(z_0)) \neq 0$ . By the implicit function theorem, $\lambda_j(z)$ is holomorphic in a neighborhood of $z_0$ . For the second part, I'm trying to apply the IFT to the $(p-1)$ -th derivative of $P$ , but can't argue why $\lambda_j(z)$ admits the desired power series representation. Any insight would be appreciated.","I'm working on the following problem: Let be an matrix whose entries are polynomials in . Let be the eigenvalues of . If is a simple eigenvalue, show that is holomorphic in a neighborhood of . If has multiplicity , show that there is a representation for some . Let , then is a polynomial in . If is simple, then and . By the implicit function theorem, is holomorphic in a neighborhood of . For the second part, I'm trying to apply the IFT to the -th derivative of , but can't argue why admits the desired power series representation. Any insight would be appreciated.","A(z) n \times n A_{ij}(z) z \lambda_j(z), j = 1,\dots,n A(z) \lambda_j(z_0) \lambda_j(z) z_0 \lambda_j(z_0) p \lambda_j(z) = \sum_{k=0}^{\infty} c_k (z - z_0)^{\frac{k}{l}} 1 \leqslant l \leqslant p P(z,w) = \det (A(z) - wI) P z,w \lambda_j(z_0) P(z,\lambda_j(z_0)) = 0 \frac{\partial P}{\partial w}(z_0, \lambda_j(z_0)) \neq 0 \lambda_j(z) z_0 (p-1) P \lambda_j(z)",['complex-analysis']
25,Showing that $\lim_{x\to 0}-\frac{1}{x}+\sum_{j=0}^\infty(2j+1)e^{-j(j+1)x}=\frac{1}{3}$,Showing that,\lim_{x\to 0}-\frac{1}{x}+\sum_{j=0}^\infty(2j+1)e^{-j(j+1)x}=\frac{1}{3},"In finding the rotational partition function for a $C_{\infty v}$ molecule , one comes across the function \begin{equation} Z(x)=\sum_{j=0}^\infty(2j+1)e^{-j(j+1)x} \end{equation} Surprisingly, this admits the Laurent series \begin{equation} Z(x)=\frac{1}{x}+\frac{1}{3}+\frac{1}{15}x+\frac{4}{315}x^2+\frac{1}{315}x^3+\ldots \end{equation} The first term is generally found as the approximation \begin{equation} Z(x)\approx \int_0^\infty(2j+1)e^{-j(j+1)x}dj=\frac{1}{x}\quad\quad\quad\text{for }x\ll1, \end{equation} and the rest of the terms can be found by the Euler-Maclaurin formula . However, the Euler Maclaurin formula is a bit complicated, and I haven't figured out how to use it correctly to find the expansion of $Z(x)$ . I am interested primarily in proving the value of the constant term \begin{equation} \lim_{x\to 0}\left(Z(x)-\frac{1}{x}\right)=\frac{1}{3}. \end{equation} I've tried expanding the exponentials as a Taylor series, but the constant terms end up adding to infinity, and I can't figure out how to annihilate them with an expansion of $\frac{1}{x}.$ Considering the $\frac{1}{x}$ term in the Laurent series for $Z(x)$ , I figure that this problem might be able to be solved with Pade approximants, or Cauchy's integral formula.","In finding the rotational partition function for a molecule , one comes across the function Surprisingly, this admits the Laurent series The first term is generally found as the approximation and the rest of the terms can be found by the Euler-Maclaurin formula . However, the Euler Maclaurin formula is a bit complicated, and I haven't figured out how to use it correctly to find the expansion of . I am interested primarily in proving the value of the constant term I've tried expanding the exponentials as a Taylor series, but the constant terms end up adding to infinity, and I can't figure out how to annihilate them with an expansion of Considering the term in the Laurent series for , I figure that this problem might be able to be solved with Pade approximants, or Cauchy's integral formula.","C_{\infty v} \begin{equation}
Z(x)=\sum_{j=0}^\infty(2j+1)e^{-j(j+1)x}
\end{equation} \begin{equation}
Z(x)=\frac{1}{x}+\frac{1}{3}+\frac{1}{15}x+\frac{4}{315}x^2+\frac{1}{315}x^3+\ldots
\end{equation} \begin{equation}
Z(x)\approx \int_0^\infty(2j+1)e^{-j(j+1)x}dj=\frac{1}{x}\quad\quad\quad\text{for }x\ll1,
\end{equation} Z(x) \begin{equation}
\lim_{x\to 0}\left(Z(x)-\frac{1}{x}\right)=\frac{1}{3}.
\end{equation} \frac{1}{x}. \frac{1}{x} Z(x)","['real-analysis', 'sequences-and-series', 'complex-analysis', 'limits']"
26,multiplicative extension of the almost complex structure $I$,multiplicative extension of the almost complex structure,I,"I was reading Huybrechts complex geometry book,in page 28-29 there is a linear operator defined as follows $\mathbf{I}: \bigwedge^{*} V_{\mathbb{C}} \rightarrow \bigwedge^{*} V_{\mathbb{C}}$ such that: $$\mathbf{I}=\sum_{p, q} i^{p-q} \cdot \Pi^{p, q}$$ with $\Pi^{p,q}$ is the natural projection on to the form of bidgree $(p,q)$ . Then in Lemma1.2.4,we try to show fundamental form $\omega(x,y)  = <I(x),y>$ over Eucliean vector space $V$ with compatible almost complex structure $I$ is type (1,1).Using the arguement as below: Since $$ (\mathbf{I} \omega)(v, w)=\omega(\mathbf{I}(v), \mathbf{I}(w))=\langle I(I(v)), I(w)\rangle=\omega(v, w) $$ one finds $\mathbf{I}(\omega)=\omega$ , i.e. $\omega \in \Lambda^{1,1} V_{\mathbb{C}}^{*}$ . I don't really understant the $\mathbf{I}$ ,can someone explain this operator a little bit,why it can used to check the type of $\omega$ ? I know since $\omega = \omega_{0,2}+\omega_{1,1} + \omega_{2,0}$ after taking $\mathbf{I}\omega = -\omega_{0,1} + \omega_{1,1} - \omega_{2,0}$ which means it only has $(1,1)$ component.","I was reading Huybrechts complex geometry book,in page 28-29 there is a linear operator defined as follows such that: with is the natural projection on to the form of bidgree . Then in Lemma1.2.4,we try to show fundamental form over Eucliean vector space with compatible almost complex structure is type (1,1).Using the arguement as below: Since one finds , i.e. . I don't really understant the ,can someone explain this operator a little bit,why it can used to check the type of ? I know since after taking which means it only has component.","\mathbf{I}: \bigwedge^{*} V_{\mathbb{C}} \rightarrow \bigwedge^{*} V_{\mathbb{C}} \mathbf{I}=\sum_{p, q} i^{p-q} \cdot \Pi^{p, q} \Pi^{p,q} (p,q) \omega(x,y)  = <I(x),y> V I 
(\mathbf{I} \omega)(v, w)=\omega(\mathbf{I}(v), \mathbf{I}(w))=\langle I(I(v)), I(w)\rangle=\omega(v, w)
 \mathbf{I}(\omega)=\omega \omega \in \Lambda^{1,1} V_{\mathbb{C}}^{*} \mathbf{I} \omega \omega = \omega_{0,2}+\omega_{1,1} + \omega_{2,0} \mathbf{I}\omega = -\omega_{0,1} + \omega_{1,1} - \omega_{2,0} (1,1)","['linear-algebra', 'complex-analysis', 'differential-geometry', 'almost-complex']"
27,What is the integration contour used to compute the Fourier transform of $(1- e^{-x})^{-1}$?,What is the integration contour used to compute the Fourier transform of ?,(1- e^{-x})^{-1},"I'm reading ""Modular Groups of Quantum Fields in Thermal States"" by Borchers and Yngvason, and on page 19 I find: Let's call $x=\beta p \in \mathbb{R}$ , so I'm interested in the Fourier transform of $(1-e^{-x})^{-1}$ . I have tried a contour that avoids the origin with a small arc (in the upper-half plane)  and closing with a large arc also in the upper half-plane, but the contribution from the small arc does not vanish, and this contour would also have infinite contributions from the residues at $2 \pi i n$ , with $n$ a positive integer. I have also tried with a rectangular contour, of width $2L$ and height $2\pi$ , with its lower horizontal segment an $\epsilon$ distance below the real axis (so to avoid the pole at the origin). The integrals along the horizontal segments can be related, and the integral along the left vertical segment goes to zero for $L\rightarrow \infty$ , but the right vertical segment still contributes to the contour integral. So, any suggestions on other possible contours?","I'm reading ""Modular Groups of Quantum Fields in Thermal States"" by Borchers and Yngvason, and on page 19 I find: Let's call , so I'm interested in the Fourier transform of . I have tried a contour that avoids the origin with a small arc (in the upper-half plane)  and closing with a large arc also in the upper half-plane, but the contribution from the small arc does not vanish, and this contour would also have infinite contributions from the residues at , with a positive integer. I have also tried with a rectangular contour, of width and height , with its lower horizontal segment an distance below the real axis (so to avoid the pole at the origin). The integrals along the horizontal segments can be related, and the integral along the left vertical segment goes to zero for , but the right vertical segment still contributes to the contour integral. So, any suggestions on other possible contours?",x=\beta p \in \mathbb{R} (1-e^{-x})^{-1} 2 \pi i n n 2L 2\pi \epsilon L\rightarrow \infty,"['complex-analysis', 'fourier-transform']"
28,How to solve $\sum_{n=-\infty}^\infty\frac{y^2}{[(x-n\pi)^2+y^2]^{3/2}}$?,How to solve ?,\sum_{n=-\infty}^\infty\frac{y^2}{[(x-n\pi)^2+y^2]^{3/2}},"I need to solve this sum: $$\sum_{n=-\infty}^\infty\frac{y^2}{[(x-n\pi)^2+y^2]^{3/2}}.$$ Do you have any ideas for how I could do this? I know that this sum: $$\sum_{n=-\infty}^\infty\frac{y}{(x-n\pi)^2+y^2},$$ can be simplified by using the following identities (see this Wikipedia article ): $$\cot(x+iy) = \sum_{n=-\infty}^\infty\frac{1}{x-n\pi + iy},$$ $$\sum_{n=-\infty}^\infty\frac{y}{(x-n\pi)^2+y^2}=\frac{i}{2}\sum_{n=-\infty}^\infty\frac{1}{x-n\pi+iy}-\frac{1}{x-n\pi-iy}.$$ Hence, $$\begin{aligned} \sum_{n=-\infty}^\infty\frac{y}{(x-n\pi)^2+y^2}&=\frac{i}{2}[\cot(x+iy)-\cot(x-iy)] \\ &=\frac{\sinh(2y)}{\cosh(2y)-\cos(2x)}. \end{aligned}$$ Do you know if a similar trick can be used to solve the original sum?","I need to solve this sum: Do you have any ideas for how I could do this? I know that this sum: can be simplified by using the following identities (see this Wikipedia article ): Hence, Do you know if a similar trick can be used to solve the original sum?","\sum_{n=-\infty}^\infty\frac{y^2}{[(x-n\pi)^2+y^2]^{3/2}}. \sum_{n=-\infty}^\infty\frac{y}{(x-n\pi)^2+y^2}, \cot(x+iy) = \sum_{n=-\infty}^\infty\frac{1}{x-n\pi + iy}, \sum_{n=-\infty}^\infty\frac{y}{(x-n\pi)^2+y^2}=\frac{i}{2}\sum_{n=-\infty}^\infty\frac{1}{x-n\pi+iy}-\frac{1}{x-n\pi-iy}. \begin{aligned}
\sum_{n=-\infty}^\infty\frac{y}{(x-n\pi)^2+y^2}&=\frac{i}{2}[\cot(x+iy)-\cot(x-iy)] \\
&=\frac{\sinh(2y)}{\cosh(2y)-\cos(2x)}.
\end{aligned}","['complex-analysis', 'trigonometry', 'complex-numbers', 'summation', 'electromagnetism']"
29,Is there a complex equivalent of the convolution product?,Is there a complex equivalent of the convolution product?,,"For two continuous real-valued functions $(f,g),$ the convolution product is defined as $$h(t)=(f*g) = \int_{-\infty}^{+\infty} f(\lambda )g(t-\lambda ) \, d\lambda $$ So for two complex valued functions $f(z)$ and $g(z)$ the convolution product would look something like: $$h(z)=(f*g)=\int_{z\in \Gamma} f(\omega)g(z-\omega) \, d\omega$$ where $\Gamma$ is a closed contour containing singularities. Now if $f$ and $g$ are entire functions then $h(z) = 0$ so this would only be useful for meromorphic functions with isolated singularities.",For two continuous real-valued functions the convolution product is defined as So for two complex valued functions and the convolution product would look something like: where is a closed contour containing singularities. Now if and are entire functions then so this would only be useful for meromorphic functions with isolated singularities.,"(f,g), h(t)=(f*g) = \int_{-\infty}^{+\infty} f(\lambda )g(t-\lambda ) \, d\lambda  f(z) g(z) h(z)=(f*g)=\int_{z\in \Gamma} f(\omega)g(z-\omega) \, d\omega \Gamma f g h(z) = 0","['integration', 'complex-analysis', 'analysis', 'convolution']"
30,Infinite series identity via integrating doubly connected domain,Infinite series identity via integrating doubly connected domain,,"I am having some trouble obtaining the correct answer to the following problem.  I would appreciate it if someone could point out where I went wrong in my computations. This problem occurs as exercise 1020 in A Collection of Problems On Complex Analysis by  L. I. Volkovyski, et. al. Problem: Prove that $$\sum_{n=1}^{\infty}\frac{n}{(n^2-3)\sqrt{4n^2-3}} = \int_{0}^{\sqrt{3}/2}\frac{x\cot(\pi x)}{(3-x^2)\sqrt{3-4x^2}}\mathrm{d}x+\frac{1}{6}\cot(\pi(2-\sqrt{3}))$$ Hint:  Use the integral \begin{equation}     \int_C\frac{z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z \end{equation} over the contour $C$ bounding the doubly connected domain given in figure where the small circular arcs are centered around $z=\pm\sqrt{3}/2$ and the large circular arc is of radius $n/2$ centered at the origin.  (The book doesn't actually specify the orientation of the contours.) Attempt at a Solution: First of all, I don't believe the book's suggested radius of the outer circle is correct if you take $n$ to be an arbitrary integer, as $\cot(\pi z)$ is not bounded on $\vert{z}\vert=k$ for $k\in\mathbb{Z}$ .  I'm also not sure why they write $\cot(\pi(2-\sqrt{3}))$ instead of $-\cot(\pi\sqrt{3})$ . The answer I obtain is close but off by a factor of $\pi$ for the last term and $2\pi$ for the integral term.  In particular, I get \begin{equation}  \sum_{k=1}^{\infty}\frac{k}{(k^2-3)\sqrt{4k^2-3}}  = 2\pi \int_{0}^{\sqrt{3}/2}\frac{t\cot(\pi t)}{(3-t^2)\sqrt{3-4t^2}}\mathrm{d}t - \frac{\pi}{6}\cot(\pi\sqrt{3}) \end{equation} The factor of pi arises because the residues of $\cot(\pi z)$ at the integers is $1/\pi$ while the factor of two on the integral comes from the fact that integrating over the dog bone contour results in two integrals from $-\sqrt{3}/2$ to $\sqrt{3}/2$ , one each from the bottom and top segments, and these simplify to a single integral over $0$ to $\sqrt{3}/2$ multiplied by 4, due to the integrand being an even function. I would love to know where I went wrong! Proof: Diverging from the hint slightly, we consider the integral \begin{equation}     \int_C\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z \end{equation} over the contour bounding the doubly connected domain.  To integrate over the doubly connected domain we will use the following fact. Proposition: If $D$ is a doubly connected domain with boundary curves $C_1$ and $C_2$ oriented in the same direction and if f is analytic in a domain containing $D$ and its boundary, then \begin{equation}     \int_{C_1}f(z)\mathrm{d}z = \int_{C_2}f(z)\mathrm{d}z \end{equation} Before beginning with integration, we need to select a branch of $\sqrt{4z^2-3}$ which is analytic in the complex plane slit from $-\sqrt{3}/2$ to $\sqrt{3}/2$ .  To do this we may factor the polynomial in the square root and choose a branch for each of the square roots of linear factors.  We define the branch of $\sqrt{2z-\sqrt{3}}$ to be such that $-\pi<\arg{(2z-\sqrt{3})}\leq \pi$ and the branch of $\sqrt{2z+\sqrt{3}}$ to be such that $-\pi<\arg{(2z+\sqrt{3})}\leq \pi$ . Recall that the complex logarithm $\log(z)$ is defined as \begin{equation}     \log(z)=\log(\vert{z}\vert)+i\arg(z) \end{equation} Thus the complex square root function is given by \begin{equation}     \sqrt{z}=e^{\frac{1}{2}(\log(\vert{z}\vert)+i\arg(z))}=\sqrt{\vert{z}\vert}e^{i\frac{1}{2}\arg(z)} \end{equation} This shows that \begin{equation}     \sqrt{4z^2-3} = \sqrt{\vert{4z^2-3}\vert}e^{i\frac{1}{2}(\arg{(2z-\sqrt{3})}+\arg{(2z+\sqrt{3})})} \end{equation} where $-2\pi < \arg{(2z-\sqrt{3})}+\arg{(2z+\sqrt{3})} \leq 2\pi$ .  We would like to show that $\sqrt{4z^2-3}$ is continuous across the branch cut below $z=-\sqrt{3}/2$ .  To do this let $z = -t$ where $t>\sqrt{3}/2$ and consider the points $-t+i\varepsilon$ and $-t-i\varepsilon$ above and below the real axis for $\varepsilon$ real and tending to $0$ .  For the point above we see that \begin{align}     \lim_{\varepsilon\to 0}\sqrt{4(-t+i\varepsilon)^2-3} &= \lim_{\varepsilon\to 0}\sqrt{\vert{4(-t+i\varepsilon)^2-3}\vert}e^{i\frac{1}{2}(\arg{(2(-t+i\varepsilon)-\sqrt{3})}+\arg{(2(-t+i\varepsilon)+\sqrt{3})})} \\     &= \sqrt{4t^2-3}e^{i\frac{1}{2}(\pi+\pi)} \\     &= -\sqrt{4t^2-3} \end{align} For the point below we have \begin{align}     \lim_{\varepsilon\to 0}\sqrt{4(-t-i\varepsilon)^2-3} &= \lim_{\varepsilon\to 0}\sqrt{\vert{4(-t-i\varepsilon)^2-3}\vert}e^{i\frac{1}{2}(\arg{(2(-t-i\varepsilon)-\sqrt{3})}+\arg{(2(-t-i\varepsilon)+\sqrt{3})})} \\     &= \sqrt{4t^2-3}e^{i\frac{1}{2}(-\pi-\pi)} \\     &= -\sqrt{4t^2-3} \end{align} Thus $\sqrt{4z^2-3}$ is in fact continuous across the branch cut.  To show that $1/\sqrt{4z^2-3}$ is holomorphic in $D$ we integrate along any circle in $D$ , splitting it in half along the real line.  By continuity the integrals along the segments on the branch cut annihilate each other, and since the integrals along the half circles are 0 the integral along the whole circle vanishes as well.  Thus, by Morera's Theorem $1/\sqrt{4z^2-3}$ is holomorphic in $D$ . Let us denote the circular contour of radius $N+1/2$ as $C_N$ and denote the interior dog bone contour by $D$ .  The the above proposition shows that \begin{equation}     \int_{C_N}f(z)\mathrm{d}z = \int_{D}f(z)\mathrm{d}z \end{equation} if we traverse each contour in the counterclockwise direction.  Beginning with the circular contour, by parameterizing we see that \begin{equation}     \int_{C_N}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = \pi i(N+1/2)^2\int_{0}^{2\pi}\frac{e^{2it}\cot(\pi (N+1/2)e^{it})}{((N+1/2)^2e^{2it}-3)\sqrt{4(N+1/2)^2e^{2it}-3}}\mathrm{d}t \end{equation} Taking the absolute value of both sides we have \begin{align}     \bigg\vert{\int_{C_N}\frac{\pi z\cot(z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z}\bigg\vert &\leq \pi (n+1/2)^2\bigg\vert{\int_{0}^{2\pi}\frac{e^{2it}\cot(\pi (N+1/2)e^{it})}{((N+1/2)^2e^{2it}-3)\sqrt{4(N+1/2)^2e^{2it}-3}}\mathrm{d}t}\bigg\vert \\     &\leq \pi(n+1/2)^2\coth^2(\pi/2)\int_{0}^{2\pi}\bigg\vert{\frac{1}{((N+1/2)^2e^{2it}-3)\sqrt{4(N+1/2)^2e^{2it}-3}}}\bigg\vert\mathrm{d}t \\     &\leq  \frac{\pi^2\coth^2(\pi/2)}{n+1/2} \end{align} Thus \begin{equation}     \lim_{N\to\infty}\int_{C_N}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = 0 \end{equation} On the other hand the contour encloses the poles at $z=\pm \sqrt{3}$ as well as the poles of cotangent at $z\in \mathbb{Z}$ except for $z = 0$ .  Therefore the residue theorem shows that \begin{equation}     \frac{1}{2\pi i}\int_{C_N}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = \sum_{k=-N}^{N}\underset{{z=k}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) + \underset{{z=\pm \sqrt{3}}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) \end{equation} With this in mind we first evaluate the residues at $\pm \sqrt{3}$ , finding that \begin{align}     \underset{{z=\sqrt{3}}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) &= \lim_{z\to\sqrt{3}}(z-\sqrt{3})\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}} \\     &= \lim_{z\to\sqrt{3}}\frac{\pi z\cot(\pi z)}{(z+\sqrt{3})\sqrt{\vert{4z^2-3}\vert}e^{i\frac{1}{2}(\arg{(2z-\sqrt{3})}+\arg{(2z+\sqrt{3})})}} \\     &= \frac{\pi}{6}\frac{\cot(\pi\sqrt{3})}{e^{i\frac{1}{2}(\arg{(\sqrt{3})}+\arg{(3\sqrt{3})})}} \\     &= \frac{\pi}{6}\frac{\cot(\pi\sqrt{3})}{e^{i\frac{1}{2}(0+0)}} \\     &= \frac{\pi}{6}\cot(\pi\sqrt{3}) \end{align} Likewise the residue at $z=-\sqrt{3}$ is given by \begin{align}     \underset{{z=-\sqrt{3}}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) &= \lim_{z\to-\sqrt{3}}(z+\sqrt{3})\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}} \\     &= \lim_{z\to-\sqrt{3}}\frac{\pi z\cot(\pi z)}{(z-\sqrt{3})\sqrt{\vert{4z^2-3}\vert}e^{i\frac{1}{2}(\arg{(2z-\sqrt{3})}+\arg{(2z+\sqrt{3})})}} \\     &= \frac{\pi}{6}\frac{\cot(-\pi\sqrt{3})}{e^{i\frac{1}{2}(\arg{(-3\sqrt{3})}+\arg{(-\sqrt{3})})}} \\     &= -\frac{\pi}{6}\frac{\cot(\pi\sqrt{3})}{e^{i\frac{1}{2}(\pi+\pi)}} \\     &= \frac{\pi}{6}\cot(\pi\sqrt{3}) \end{align} Similarly evaluating the residues at $z = \pm k$ for $k \in \mathbb{Z}_{>0}$ we find that \begin{equation}     \underset{{z=k}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) = \frac{k}{(k^2-3)\sqrt{4k^2-3}} \end{equation} and \begin{equation}     \underset{{z=-k}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) = \frac{k}{(k^2-3)\sqrt{4k^2-3}} \end{equation} Therefore, we find that \begin{equation}     \frac{1}{2\pi i}\int_{C_N}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = 2\sum_{k=1}^{N}\frac{k}{(k^2-3)\sqrt{4k^2-3}} + \frac{\pi}{3}\cot(\pi\sqrt{3}) \end{equation} Taking the limit as $N\to \infty$ and using Cauchy's Theorem for multiply connected domains gives \begin{equation}  2\sum_{k=1}^{\infty}\frac{k}{(k^2-3)\sqrt{4k^2-3}} + \frac{\pi}{3}\cot(\pi\sqrt{3}) = \int_{D}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z \end{equation} Next we break up the dog bone contour into four parts \begin{equation}     \int_{D}=\int_{C_{\varepsilon}^{-}}+\int_{\Gamma_{\varepsilon}^{-}}+\int_{\Gamma_{\varepsilon}^{+}}+\int_{C_{\varepsilon}^{+}} \end{equation} Where $C_{\varepsilon}^{-}$ and $C_{\varepsilon}^{+}$ denotes the circular arcs of radius $\varepsilon$ traversed in the counter clockwise direction and centered at $-\sqrt{3}/2$ and $\sqrt{3}/2$ respectively, and $\Gamma_{\varepsilon}^{-}$ and $\Gamma_{\varepsilon}^{+}$ are the lines a distance of $\varepsilon$ below and above the real line respectively. It is not difficult to show that the integrals along the small circular arcs $C_{\varepsilon}^{-}$ and $C_{\varepsilon}^{+}$ vanish as $\varepsilon \to 0$ .  On the other hand the integrals along the lines above and below the real axis can be evaluated as \begin{align}     \lim_{\varepsilon \to 0}\int_{\Gamma_{\varepsilon}^{+}}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z &=  \lim_{\varepsilon \to 0}\int_{\sqrt{3}/2}^{-\sqrt{3}/2}\frac{\pi (t+i\varepsilon)\cot(\pi (t+i\varepsilon))}{((t+i\varepsilon)^2-3)\sqrt{4(t+i\varepsilon)^2-3}}\mathrm{d}t \\     &= -2i\int_{0}^{\sqrt{3}/2}\frac{\pi t\cot(\pi t)}{(t^2-3)\sqrt{4t^2-3}}\mathrm{d}t \end{align} and \begin{align}     \lim_{\varepsilon \to 0}\int_{\Gamma_{\varepsilon}^{-}}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z &=  \lim_{\varepsilon \to 0}\int_{-\sqrt{3}/2}^{\sqrt{3}/2}\frac{\pi (t-i\varepsilon)\cot(\pi (t-i\varepsilon))}{((t-i\varepsilon)^2-3)\sqrt{4(t-i\varepsilon)^2-3}}\mathrm{d}t \\     &= -2i\int_{0}^{\sqrt{3}/2}\frac{\pi t\cot(\pi t)}{(t^2-3)\sqrt{4t^2-3}}\mathrm{d}t \end{align} Where we have used the fact that for $-\sqrt{3}/2<x<\sqrt{3}/2$ we have on the line above the real axis \begin{align}      \lim_{\varepsilon \to 0}\sqrt{\vert{4(-x+i\varepsilon)^2-3}\vert}e^{i\frac{1}{2}(\arg{(2(-x+i\varepsilon)-\sqrt{3})}+\arg{(2(-x+i\varepsilon)+\sqrt{3})})}      &= \sqrt{4x^2-3}e^{i\frac{1}{2}(\pi+0)} \\     &= i\sqrt{4x^2-3} \end{align} Likewise below the real axis we find that \begin{align}      \lim_{\varepsilon \to 0}\sqrt{\vert{4(-x-i\varepsilon)^2-3}\vert}e^{i\frac{1}{2}(\arg{(2(-x-i\varepsilon)-\sqrt{3})}+\arg{(2(-x-i\varepsilon)+\sqrt{3})})}      &= \sqrt{4x^2-3}e^{i\frac{1}{2}(-\pi+0)} \\     &= -i\sqrt{4x^2-3} \end{align} Putting this all together the integral over the contour $D$ becomes \begin{align}     \int_{D}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = -4i\int_{0}^{\sqrt{3}/2}\frac{\pi t\cot(\pi t)}{(t^2-3)\sqrt{4t^2-3}}\mathrm{d}t \end{align} giving in the end \begin{equation}  \sum_{k=1}^{\infty}\frac{k}{(k^2-3)\sqrt{4k^2-3}}  = 2\int_{0}^{\sqrt{3}/2}\frac{\pi t\cot(\pi t)}{(3-t^2)\sqrt{3-4t^2}}\mathrm{d}t - \frac{\pi}{6}\cot(\pi\sqrt{3}) \end{equation}","I am having some trouble obtaining the correct answer to the following problem.  I would appreciate it if someone could point out where I went wrong in my computations. This problem occurs as exercise 1020 in A Collection of Problems On Complex Analysis by  L. I. Volkovyski, et. al. Problem: Prove that Hint:  Use the integral over the contour bounding the doubly connected domain given in figure where the small circular arcs are centered around and the large circular arc is of radius centered at the origin.  (The book doesn't actually specify the orientation of the contours.) Attempt at a Solution: First of all, I don't believe the book's suggested radius of the outer circle is correct if you take to be an arbitrary integer, as is not bounded on for .  I'm also not sure why they write instead of . The answer I obtain is close but off by a factor of for the last term and for the integral term.  In particular, I get The factor of pi arises because the residues of at the integers is while the factor of two on the integral comes from the fact that integrating over the dog bone contour results in two integrals from to , one each from the bottom and top segments, and these simplify to a single integral over to multiplied by 4, due to the integrand being an even function. I would love to know where I went wrong! Proof: Diverging from the hint slightly, we consider the integral over the contour bounding the doubly connected domain.  To integrate over the doubly connected domain we will use the following fact. Proposition: If is a doubly connected domain with boundary curves and oriented in the same direction and if f is analytic in a domain containing and its boundary, then Before beginning with integration, we need to select a branch of which is analytic in the complex plane slit from to .  To do this we may factor the polynomial in the square root and choose a branch for each of the square roots of linear factors.  We define the branch of to be such that and the branch of to be such that . Recall that the complex logarithm is defined as Thus the complex square root function is given by This shows that where .  We would like to show that is continuous across the branch cut below .  To do this let where and consider the points and above and below the real axis for real and tending to .  For the point above we see that For the point below we have Thus is in fact continuous across the branch cut.  To show that is holomorphic in we integrate along any circle in , splitting it in half along the real line.  By continuity the integrals along the segments on the branch cut annihilate each other, and since the integrals along the half circles are 0 the integral along the whole circle vanishes as well.  Thus, by Morera's Theorem is holomorphic in . Let us denote the circular contour of radius as and denote the interior dog bone contour by .  The the above proposition shows that if we traverse each contour in the counterclockwise direction.  Beginning with the circular contour, by parameterizing we see that Taking the absolute value of both sides we have Thus On the other hand the contour encloses the poles at as well as the poles of cotangent at except for .  Therefore the residue theorem shows that With this in mind we first evaluate the residues at , finding that Likewise the residue at is given by Similarly evaluating the residues at for we find that and Therefore, we find that Taking the limit as and using Cauchy's Theorem for multiply connected domains gives Next we break up the dog bone contour into four parts Where and denotes the circular arcs of radius traversed in the counter clockwise direction and centered at and respectively, and and are the lines a distance of below and above the real line respectively. It is not difficult to show that the integrals along the small circular arcs and vanish as .  On the other hand the integrals along the lines above and below the real axis can be evaluated as and Where we have used the fact that for we have on the line above the real axis Likewise below the real axis we find that Putting this all together the integral over the contour becomes giving in the end","\sum_{n=1}^{\infty}\frac{n}{(n^2-3)\sqrt{4n^2-3}} = \int_{0}^{\sqrt{3}/2}\frac{x\cot(\pi x)}{(3-x^2)\sqrt{3-4x^2}}\mathrm{d}x+\frac{1}{6}\cot(\pi(2-\sqrt{3})) \begin{equation}
    \int_C\frac{z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z
\end{equation} C z=\pm\sqrt{3}/2 n/2 n \cot(\pi z) \vert{z}\vert=k k\in\mathbb{Z} \cot(\pi(2-\sqrt{3})) -\cot(\pi\sqrt{3}) \pi 2\pi \begin{equation}
 \sum_{k=1}^{\infty}\frac{k}{(k^2-3)\sqrt{4k^2-3}}  = 2\pi \int_{0}^{\sqrt{3}/2}\frac{t\cot(\pi t)}{(3-t^2)\sqrt{3-4t^2}}\mathrm{d}t - \frac{\pi}{6}\cot(\pi\sqrt{3})
\end{equation} \cot(\pi z) 1/\pi -\sqrt{3}/2 \sqrt{3}/2 0 \sqrt{3}/2 \begin{equation}
    \int_C\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z
\end{equation} D C_1 C_2 D \begin{equation}
    \int_{C_1}f(z)\mathrm{d}z = \int_{C_2}f(z)\mathrm{d}z
\end{equation} \sqrt{4z^2-3} -\sqrt{3}/2 \sqrt{3}/2 \sqrt{2z-\sqrt{3}} -\pi<\arg{(2z-\sqrt{3})}\leq \pi \sqrt{2z+\sqrt{3}} -\pi<\arg{(2z+\sqrt{3})}\leq \pi \log(z) \begin{equation}
    \log(z)=\log(\vert{z}\vert)+i\arg(z)
\end{equation} \begin{equation}
    \sqrt{z}=e^{\frac{1}{2}(\log(\vert{z}\vert)+i\arg(z))}=\sqrt{\vert{z}\vert}e^{i\frac{1}{2}\arg(z)}
\end{equation} \begin{equation}
    \sqrt{4z^2-3} = \sqrt{\vert{4z^2-3}\vert}e^{i\frac{1}{2}(\arg{(2z-\sqrt{3})}+\arg{(2z+\sqrt{3})})}
\end{equation} -2\pi < \arg{(2z-\sqrt{3})}+\arg{(2z+\sqrt{3})} \leq 2\pi \sqrt{4z^2-3} z=-\sqrt{3}/2 z = -t t>\sqrt{3}/2 -t+i\varepsilon -t-i\varepsilon \varepsilon 0 \begin{align}
    \lim_{\varepsilon\to 0}\sqrt{4(-t+i\varepsilon)^2-3} &= \lim_{\varepsilon\to 0}\sqrt{\vert{4(-t+i\varepsilon)^2-3}\vert}e^{i\frac{1}{2}(\arg{(2(-t+i\varepsilon)-\sqrt{3})}+\arg{(2(-t+i\varepsilon)+\sqrt{3})})} \\
    &= \sqrt{4t^2-3}e^{i\frac{1}{2}(\pi+\pi)} \\
    &= -\sqrt{4t^2-3}
\end{align} \begin{align}
    \lim_{\varepsilon\to 0}\sqrt{4(-t-i\varepsilon)^2-3} &= \lim_{\varepsilon\to 0}\sqrt{\vert{4(-t-i\varepsilon)^2-3}\vert}e^{i\frac{1}{2}(\arg{(2(-t-i\varepsilon)-\sqrt{3})}+\arg{(2(-t-i\varepsilon)+\sqrt{3})})} \\
    &= \sqrt{4t^2-3}e^{i\frac{1}{2}(-\pi-\pi)} \\
    &= -\sqrt{4t^2-3}
\end{align} \sqrt{4z^2-3} 1/\sqrt{4z^2-3} D D 1/\sqrt{4z^2-3} D N+1/2 C_N D \begin{equation}
    \int_{C_N}f(z)\mathrm{d}z = \int_{D}f(z)\mathrm{d}z
\end{equation} \begin{equation}
    \int_{C_N}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = \pi i(N+1/2)^2\int_{0}^{2\pi}\frac{e^{2it}\cot(\pi (N+1/2)e^{it})}{((N+1/2)^2e^{2it}-3)\sqrt{4(N+1/2)^2e^{2it}-3}}\mathrm{d}t
\end{equation} \begin{align}
    \bigg\vert{\int_{C_N}\frac{\pi z\cot(z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z}\bigg\vert &\leq \pi (n+1/2)^2\bigg\vert{\int_{0}^{2\pi}\frac{e^{2it}\cot(\pi (N+1/2)e^{it})}{((N+1/2)^2e^{2it}-3)\sqrt{4(N+1/2)^2e^{2it}-3}}\mathrm{d}t}\bigg\vert \\
    &\leq \pi(n+1/2)^2\coth^2(\pi/2)\int_{0}^{2\pi}\bigg\vert{\frac{1}{((N+1/2)^2e^{2it}-3)\sqrt{4(N+1/2)^2e^{2it}-3}}}\bigg\vert\mathrm{d}t \\
    &\leq  \frac{\pi^2\coth^2(\pi/2)}{n+1/2}
\end{align} \begin{equation}
    \lim_{N\to\infty}\int_{C_N}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = 0
\end{equation} z=\pm \sqrt{3} z\in \mathbb{Z} z = 0 \begin{equation}
    \frac{1}{2\pi i}\int_{C_N}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = \sum_{k=-N}^{N}\underset{{z=k}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) + \underset{{z=\pm \sqrt{3}}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right)
\end{equation} \pm \sqrt{3} \begin{align}
    \underset{{z=\sqrt{3}}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) &= \lim_{z\to\sqrt{3}}(z-\sqrt{3})\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}} \\
    &= \lim_{z\to\sqrt{3}}\frac{\pi z\cot(\pi z)}{(z+\sqrt{3})\sqrt{\vert{4z^2-3}\vert}e^{i\frac{1}{2}(\arg{(2z-\sqrt{3})}+\arg{(2z+\sqrt{3})})}} \\
    &= \frac{\pi}{6}\frac{\cot(\pi\sqrt{3})}{e^{i\frac{1}{2}(\arg{(\sqrt{3})}+\arg{(3\sqrt{3})})}} \\
    &= \frac{\pi}{6}\frac{\cot(\pi\sqrt{3})}{e^{i\frac{1}{2}(0+0)}} \\
    &= \frac{\pi}{6}\cot(\pi\sqrt{3})
\end{align} z=-\sqrt{3} \begin{align}
    \underset{{z=-\sqrt{3}}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) &= \lim_{z\to-\sqrt{3}}(z+\sqrt{3})\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}} \\
    &= \lim_{z\to-\sqrt{3}}\frac{\pi z\cot(\pi z)}{(z-\sqrt{3})\sqrt{\vert{4z^2-3}\vert}e^{i\frac{1}{2}(\arg{(2z-\sqrt{3})}+\arg{(2z+\sqrt{3})})}} \\
    &= \frac{\pi}{6}\frac{\cot(-\pi\sqrt{3})}{e^{i\frac{1}{2}(\arg{(-3\sqrt{3})}+\arg{(-\sqrt{3})})}} \\
    &= -\frac{\pi}{6}\frac{\cot(\pi\sqrt{3})}{e^{i\frac{1}{2}(\pi+\pi)}} \\
    &= \frac{\pi}{6}\cot(\pi\sqrt{3})
\end{align} z = \pm k k \in \mathbb{Z}_{>0} \begin{equation}
    \underset{{z=k}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) = \frac{k}{(k^2-3)\sqrt{4k^2-3}}
\end{equation} \begin{equation}
    \underset{{z=-k}}{\mathrm{res}}\left(\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\right) = \frac{k}{(k^2-3)\sqrt{4k^2-3}}
\end{equation} \begin{equation}
    \frac{1}{2\pi i}\int_{C_N}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = 2\sum_{k=1}^{N}\frac{k}{(k^2-3)\sqrt{4k^2-3}} + \frac{\pi}{3}\cot(\pi\sqrt{3})
\end{equation} N\to \infty \begin{equation}
 2\sum_{k=1}^{\infty}\frac{k}{(k^2-3)\sqrt{4k^2-3}} + \frac{\pi}{3}\cot(\pi\sqrt{3}) = \int_{D}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z
\end{equation} \begin{equation}
    \int_{D}=\int_{C_{\varepsilon}^{-}}+\int_{\Gamma_{\varepsilon}^{-}}+\int_{\Gamma_{\varepsilon}^{+}}+\int_{C_{\varepsilon}^{+}}
\end{equation} C_{\varepsilon}^{-} C_{\varepsilon}^{+} \varepsilon -\sqrt{3}/2 \sqrt{3}/2 \Gamma_{\varepsilon}^{-} \Gamma_{\varepsilon}^{+} \varepsilon C_{\varepsilon}^{-} C_{\varepsilon}^{+} \varepsilon \to 0 \begin{align}
    \lim_{\varepsilon \to 0}\int_{\Gamma_{\varepsilon}^{+}}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z &=  \lim_{\varepsilon \to 0}\int_{\sqrt{3}/2}^{-\sqrt{3}/2}\frac{\pi (t+i\varepsilon)\cot(\pi (t+i\varepsilon))}{((t+i\varepsilon)^2-3)\sqrt{4(t+i\varepsilon)^2-3}}\mathrm{d}t \\
    &= -2i\int_{0}^{\sqrt{3}/2}\frac{\pi t\cot(\pi t)}{(t^2-3)\sqrt{4t^2-3}}\mathrm{d}t
\end{align} \begin{align}
    \lim_{\varepsilon \to 0}\int_{\Gamma_{\varepsilon}^{-}}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z &=  \lim_{\varepsilon \to 0}\int_{-\sqrt{3}/2}^{\sqrt{3}/2}\frac{\pi (t-i\varepsilon)\cot(\pi (t-i\varepsilon))}{((t-i\varepsilon)^2-3)\sqrt{4(t-i\varepsilon)^2-3}}\mathrm{d}t \\
    &= -2i\int_{0}^{\sqrt{3}/2}\frac{\pi t\cot(\pi t)}{(t^2-3)\sqrt{4t^2-3}}\mathrm{d}t
\end{align} -\sqrt{3}/2<x<\sqrt{3}/2 \begin{align}
     \lim_{\varepsilon \to 0}\sqrt{\vert{4(-x+i\varepsilon)^2-3}\vert}e^{i\frac{1}{2}(\arg{(2(-x+i\varepsilon)-\sqrt{3})}+\arg{(2(-x+i\varepsilon)+\sqrt{3})})} 
    &= \sqrt{4x^2-3}e^{i\frac{1}{2}(\pi+0)} \\
    &= i\sqrt{4x^2-3}
\end{align} \begin{align}
     \lim_{\varepsilon \to 0}\sqrt{\vert{4(-x-i\varepsilon)^2-3}\vert}e^{i\frac{1}{2}(\arg{(2(-x-i\varepsilon)-\sqrt{3})}+\arg{(2(-x-i\varepsilon)+\sqrt{3})})} 
    &= \sqrt{4x^2-3}e^{i\frac{1}{2}(-\pi+0)} \\
    &= -i\sqrt{4x^2-3}
\end{align} D \begin{align}
    \int_{D}\frac{\pi z\cot(\pi z)}{(z^2-3)\sqrt{4z^2-3}}\mathrm{d}z = -4i\int_{0}^{\sqrt{3}/2}\frac{\pi t\cot(\pi t)}{(t^2-3)\sqrt{4t^2-3}}\mathrm{d}t
\end{align} \begin{equation}
 \sum_{k=1}^{\infty}\frac{k}{(k^2-3)\sqrt{4k^2-3}}  = 2\int_{0}^{\sqrt{3}/2}\frac{\pi t\cot(\pi t)}{(3-t^2)\sqrt{3-4t^2}}\mathrm{d}t - \frac{\pi}{6}\cot(\pi\sqrt{3})
\end{equation}","['sequences-and-series', 'complex-analysis', 'complex-integration']"
31,Imaginary order differential equations,Imaginary order differential equations,,"I would like to find the solution of the imaginary order differential equation $y^{(2i)}+y^{(i)}+y=0$ I started with the Fourier transform differintegral as it seemed more suitable than the Riemann-Liouville fractional derivative,  as I saw on this post: ( Imaginary-Order Derivative ): $$f^{(s)}(x)=\dfrac{1}{2\pi}\displaystyle\int_{-\infty}^{+\infty} e^{- i \omega x}(-i \omega)^s \displaystyle\int_{-\infty}^{+\infty}f(t)e^{i\omega t}dt \, d\omega.$$ Then I applied it to the equation,  including $y(x)=y^{(0)}(x)$ : $$f^{(s)}(x)=\dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)(-i\omega)^{s}dtd\omega,$$ and got to $$\dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)(-i\omega)^{2i}dtd\omega + \dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)(-i\omega)^{i}dtd\omega +\dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)(-i\omega)^{0}dtd\omega$$ $$\dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)((-i\omega)^{2i}+(-i\omega)^{i}+(-i\omega)^{0})dtd\omega=0.$$ taking the derivative of both sides doesn't help to get any solutions besides $y=0$ . Any help would be appreciated.","I would like to find the solution of the imaginary order differential equation I started with the Fourier transform differintegral as it seemed more suitable than the Riemann-Liouville fractional derivative,  as I saw on this post: ( Imaginary-Order Derivative ): Then I applied it to the equation,  including : and got to taking the derivative of both sides doesn't help to get any solutions besides . Any help would be appreciated.","y^{(2i)}+y^{(i)}+y=0 f^{(s)}(x)=\dfrac{1}{2\pi}\displaystyle\int_{-\infty}^{+\infty} e^{- i \omega x}(-i \omega)^s \displaystyle\int_{-\infty}^{+\infty}f(t)e^{i\omega t}dt \, d\omega. y(x)=y^{(0)}(x) f^{(s)}(x)=\dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)(-i\omega)^{s}dtd\omega, \dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)(-i\omega)^{2i}dtd\omega + \dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)(-i\omega)^{i}dtd\omega +\dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)(-i\omega)^{0}dtd\omega \dfrac{1}{2\pi} \displaystyle\int_{-\infty}^{\infty} \displaystyle\int_{-\infty}^{\infty}e^{i\omega(t-x)}y(t)((-i\omega)^{2i}+(-i\omega)^{i}+(-i\omega)^{0})dtd\omega=0. y=0","['complex-analysis', 'fractional-calculus']"
32,Conditions for Ramanujan's Master Theorem,Conditions for Ramanujan's Master Theorem,,"I would like to apply Ramanujan's Master Theorem (RMT) to formally justify some integrals that I have been using. The source for the proof of the RMT that I have is Hardy's book on Ramanujan's work. The formal statement of the RMT can be found in https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.4327&rep=rep1&type=pdf as Theorem 3.2. In Hardy's book, he says that the growth condition on $\varphi$ (and in particular the requirement $A < \pi$ ) is 'natural', but insufficient in many practical applications, where apparently $A=\pi$ is the best bound available. In almost all practical applications I have seen, the formal statement of the RMT is more or less ignored and it is applied 'blindly' to derive a bunch of interesting integrals. How can one generically check that the growth condition on $\varphi$ is satisfied? Is there a simpler condition which implies this kind of growth? Specifically, I am interested in proving entry 3.252-10 in Gradsteyn & Rhyzik: http://fisica.ciens.ucv.ve/~svincenz/TISPISGIMR.pdf If I expand the function $$f(x) = \frac{1}{(1+2x\cos t +x^2)^{\alpha_2}}; \quad (\alpha_2 >0)  $$ in terms of Gegenbauer polynomials and 'blindly' apply the RMT, I get the correct answer (after some trivial manipulations and using the generalized definition of Gegenbauer polynomials in terms of ${}_2F_1$ , which can also be found in the above link). To meet the conditions of the RMT, I would need to prove that the function $$ \phi(s) = C^{\alpha_2}_{s}(\cos t) $$ satisfies said growth condition as a function of $s$ , where $0 < t < \pi$ . I don't know how to approach this. Edit: for completeness' sake, the growth condition reads: for some $0<\delta<1$ and $s=v+iw$ in the half-plane $v \geq -\delta$ we have $$|\phi(v+iw)| \leq C \exp(Pv + A|w|)$$ for some $P$ and $A<\pi$ . Any help is appreciated!","I would like to apply Ramanujan's Master Theorem (RMT) to formally justify some integrals that I have been using. The source for the proof of the RMT that I have is Hardy's book on Ramanujan's work. The formal statement of the RMT can be found in https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.4327&rep=rep1&type=pdf as Theorem 3.2. In Hardy's book, he says that the growth condition on (and in particular the requirement ) is 'natural', but insufficient in many practical applications, where apparently is the best bound available. In almost all practical applications I have seen, the formal statement of the RMT is more or less ignored and it is applied 'blindly' to derive a bunch of interesting integrals. How can one generically check that the growth condition on is satisfied? Is there a simpler condition which implies this kind of growth? Specifically, I am interested in proving entry 3.252-10 in Gradsteyn & Rhyzik: http://fisica.ciens.ucv.ve/~svincenz/TISPISGIMR.pdf If I expand the function in terms of Gegenbauer polynomials and 'blindly' apply the RMT, I get the correct answer (after some trivial manipulations and using the generalized definition of Gegenbauer polynomials in terms of , which can also be found in the above link). To meet the conditions of the RMT, I would need to prove that the function satisfies said growth condition as a function of , where . I don't know how to approach this. Edit: for completeness' sake, the growth condition reads: for some and in the half-plane we have for some and . Any help is appreciated!",\varphi A < \pi A=\pi \varphi f(x) = \frac{1}{(1+2x\cos t +x^2)^{\alpha_2}}; \quad (\alpha_2 >0)   {}_2F_1  \phi(s) = C^{\alpha_2}_{s}(\cos t)  s 0 < t < \pi 0<\delta<1 s=v+iw v \geq -\delta |\phi(v+iw)| \leq C \exp(Pv + A|w|) P A<\pi,"['complex-analysis', 'definite-integrals', 'asymptotics', 'mellin-transform']"
33,The closure of meromorphic functions under composition,The closure of meromorphic functions under composition,,"It is well-known that composing meromorphic functions on $\mathbb C$ does not necessarily result in a meromorphic function (e.g., $\exp\circ\frac1x$ , which has an essential singularity at $x=0$ .) Question: What is the ""closure"" of the meromorphic functions under composition? That is, what is the minimal extension field $K$ of the field $\mathcal M(\mathbb C)$ such that for each $f,g\in K\setminus\mathbb C$ , we have $f\circ g\in K$ . My nave guess would be the field of holomorphic functions defined on $\mathbb C\setminus I$ , for some zero-dimensional complex analytic subset $I$ . Such a field will be certainly closed under composition, but I am not sure how to prove/disprove it is minimal . Here, I view meromorphic functions as entire functions $f\colon\mathbb C_\infty\setminus\{\infty\}\to\mathbb C_\infty$ , where $\mathbb C_\infty:=\mathbb C\cup\{\infty\}$ is the Riemann sphere. Then, we can define the composition of entire functions $f\colon\mathbb C_\infty\setminus I\to\mathbb C_\infty$ and $g\colon\mathbb C_\infty\setminus J\to\mathbb C_\infty$ with $f\circ g\colon \mathbb C_\infty\setminus(J\cup g^{-1}(I))\to\mathbb C_\infty:z\mapsto f(g(z))$ .","It is well-known that composing meromorphic functions on does not necessarily result in a meromorphic function (e.g., , which has an essential singularity at .) Question: What is the ""closure"" of the meromorphic functions under composition? That is, what is the minimal extension field of the field such that for each , we have . My nave guess would be the field of holomorphic functions defined on , for some zero-dimensional complex analytic subset . Such a field will be certainly closed under composition, but I am not sure how to prove/disprove it is minimal . Here, I view meromorphic functions as entire functions , where is the Riemann sphere. Then, we can define the composition of entire functions and with .","\mathbb C \exp\circ\frac1x x=0 K \mathcal M(\mathbb C) f,g\in K\setminus\mathbb C f\circ g\in K \mathbb C\setminus I I f\colon\mathbb C_\infty\setminus\{\infty\}\to\mathbb C_\infty \mathbb C_\infty:=\mathbb C\cup\{\infty\} f\colon\mathbb C_\infty\setminus I\to\mathbb C_\infty g\colon\mathbb C_\infty\setminus J\to\mathbb C_\infty f\circ g\colon \mathbb C_\infty\setminus(J\cup g^{-1}(I))\to\mathbb C_\infty:z\mapsto f(g(z))","['complex-analysis', 'meromorphic-functions']"
34,Rational approximation to complex function involving arctan and sqrt,Rational approximation to complex function involving arctan and sqrt,,"I'm dealing with the following type of function where $\omega_a$ , $\gamma$ and $a$ are parameters: $$ f(\omega)\propto \sqrt{\omega_\textrm{a}-\omega-\textrm{i}\gamma}\; \arctan\left(\frac{a}{\sqrt{\omega_\textrm{a}-\omega-\textrm{i}\gamma}}\right) $$ Im currently thinking of ways to approximate this function by a rational function (in $\omega$ ). The issue I'm having is that the quantities under the square root as well as in the arctan are complex. I've really no idea how to do it - I didn't hear any functional analysis but I feel like it has to do something with analytical continuation. I would be happy about any tips how to approach the problem! What I did first was trying to ignore that the arguments are complex-valued, so I did some Taylor expansion, Pad-approximation and such, but then the real and imaginary part of the approximant were completely different from the original function. I've stumbled upon this representation of the arcus tanges for complex arguments (taken from wikipedia): $$ \arctan(a+b\,\mathrm i) = \left\{ \begin{array}{ll} \displaystyle \frac12\,\left(\arctan \frac{a^2+b^2-1}{2a} + \frac\pi2\,\textrm{sgn}(a) \right)  & \; a\neq0 \\ 0  & \; a=0,\, |b|\leq1 \\ \displaystyle \frac\pi2\,\textrm{sgn}(b)  & \; a=0,\, |b|>1 \\ \end{array} \right\} \\ + \mathrm i \cdot \frac12\,\operatorname{artanh} \frac{2b}{a^2+b^2+1} $$ But since the argument in my function $f(\omega)$ involves a square root I do have a lot of terms to the power of $\frac{1}{2}$ , $\frac{3}{2}$ and so on. Regarding the range of values of $\omega \in [\omega_L, \omega_U]$ I can say that $\omega_L<\omega_a<\omega_U$ but it is not really restricted. Typical values are: $10^{15} <\omega < 10^{16},\;\omega_a = 3\cdot 10^{15}$ and $a=5\cdot10^{7}$ . With these values we have $$     \max_\omega \Re\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}} \right) \approx 1.385 \qquad\qquad     \min_\omega \Re\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}}\right) \approx 0.625 $$ $$     \max_\omega \Im\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}}\right) \approx 0.0152 \qquad\qquad     \min_\omega \Im\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}}\right) \approx 0.0150 $$","I'm dealing with the following type of function where , and are parameters: Im currently thinking of ways to approximate this function by a rational function (in ). The issue I'm having is that the quantities under the square root as well as in the arctan are complex. I've really no idea how to do it - I didn't hear any functional analysis but I feel like it has to do something with analytical continuation. I would be happy about any tips how to approach the problem! What I did first was trying to ignore that the arguments are complex-valued, so I did some Taylor expansion, Pad-approximation and such, but then the real and imaginary part of the approximant were completely different from the original function. I've stumbled upon this representation of the arcus tanges for complex arguments (taken from wikipedia): But since the argument in my function involves a square root I do have a lot of terms to the power of , and so on. Regarding the range of values of I can say that but it is not really restricted. Typical values are: and . With these values we have","\omega_a \gamma a 
f(\omega)\propto \sqrt{\omega_\textrm{a}-\omega-\textrm{i}\gamma}\; \arctan\left(\frac{a}{\sqrt{\omega_\textrm{a}-\omega-\textrm{i}\gamma}}\right)
 \omega 
\arctan(a+b\,\mathrm i) = \left\{
\begin{array}{ll} \displaystyle
\frac12\,\left(\arctan \frac{a^2+b^2-1}{2a} + \frac\pi2\,\textrm{sgn}(a) \right)
 & \; a\neq0 \\
0
 & \; a=0,\, |b|\leq1 \\ \displaystyle
\frac\pi2\,\textrm{sgn}(b)
 & \; a=0,\, |b|>1 \\
\end{array} \right\} \\
+ \mathrm i \cdot \frac12\,\operatorname{artanh} \frac{2b}{a^2+b^2+1}
 f(\omega) \frac{1}{2} \frac{3}{2} \omega \in [\omega_L, \omega_U] \omega_L<\omega_a<\omega_U 10^{15} <\omega < 10^{16},\;\omega_a = 3\cdot 10^{15} a=5\cdot10^{7} 
    \max_\omega \Re\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}} \right) \approx 1.385 \qquad\qquad
    \min_\omega \Re\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}}\right) \approx 0.625
 
    \max_\omega \Im\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}}\right) \approx 0.0152 \qquad\qquad
    \min_\omega \Im\left(\cfrac{a}{\sqrt{\omega_a+\omega+\textrm{i}\gamma}}\right) \approx 0.0150
","['complex-analysis', 'approximation', 'rational-functions']"
35,Number of zeroes of $f'$ given number of zeroes of $f$.,Number of zeroes of  given number of zeroes of .,f' f,"Suppose that $f$ is a non-constant, smooth, complex valued function on $\mathbb{C}$ with $\Gamma=\{z\in \mathbb{C}: \lvert f(z)\rvert=7\}$ a smooth, closed, simple curve. Let $G$ be the enclosed domain and suppose that $f$ is analytic on $G$ . It is easy to show using the maximum principle that $f$ must have at least one zero in $G$ . Now suppose also that $f'\equiv \frac{\partial f}{\partial z}$ has no zeroes on $\Gamma$ and that $f$ has $m$ zeroes in $G$ counting multiplicity. How many zeroes must $f'$ have? I think that the answer has to be $m-1$ .  My approach was to try to use the argument principle. I don't exactly see how to get a handle on $\int_{\Gamma} \frac{f''}{f'}dz$ . Next I thought about parameterizing $\Gamma$ as $\gamma(t)$ for $a\leq t\leq b$ with $\lvert \gamma'(t)\rvert =1$ and trying to use $f'(\gamma(t))=\frac{\frac{d}{dt}f(\gamma(t))}{\gamma'(t)}$ , then computing the change in argument around $\Gamma$ . This sort of made sense to me as I'm pretty convinced that the change in argument of $\frac{d}{dt}f(\gamma(t))$ is the same as the change in argument of $f(\gamma(t))$ , but I couldn't prove that and even with this fact the proof is quite hand wavy. Anyway if someone has a more elegant approach, please share!","Suppose that is a non-constant, smooth, complex valued function on with a smooth, closed, simple curve. Let be the enclosed domain and suppose that is analytic on . It is easy to show using the maximum principle that must have at least one zero in . Now suppose also that has no zeroes on and that has zeroes in counting multiplicity. How many zeroes must have? I think that the answer has to be .  My approach was to try to use the argument principle. I don't exactly see how to get a handle on . Next I thought about parameterizing as for with and trying to use , then computing the change in argument around . This sort of made sense to me as I'm pretty convinced that the change in argument of is the same as the change in argument of , but I couldn't prove that and even with this fact the proof is quite hand wavy. Anyway if someone has a more elegant approach, please share!",f \mathbb{C} \Gamma=\{z\in \mathbb{C}: \lvert f(z)\rvert=7\} G f G f G f'\equiv \frac{\partial f}{\partial z} \Gamma f m G f' m-1 \int_{\Gamma} \frac{f''}{f'}dz \Gamma \gamma(t) a\leq t\leq b \lvert \gamma'(t)\rvert =1 f'(\gamma(t))=\frac{\frac{d}{dt}f(\gamma(t))}{\gamma'(t)} \Gamma \frac{d}{dt}f(\gamma(t)) f(\gamma(t)),['complex-analysis']
36,Generalizing complex derivative as Frchet/Gateaux derivative,Generalizing complex derivative as Frchet/Gateaux derivative,,"So it is well-known that complex differentiability of a function $f:\mathbb{C}\rightarrow\mathbb{C}$ is equivalent to the function being Frchet/Gateaux differentiable and the component functions (obtained by regarding $\mathbb{C}$ as a 2-dimensional vector space over $\mathbb{R}$ ) satisfying the Cauchy-Riemann equations, i.e. the Frchet/Gateaux derivative at $c\in\mathbb{C}$ should be a linear operator representing multiplication by a complex number and thus be of the form $$f'(c) = \begin{pmatrix}a&-b\\b&a\end{pmatrix}.$$ The fact that the ""directional derivatives"" are required to coincide for all directions in complex analysis leads to a very rigid, yet rich theory. So, related to the above point of view, I wondered if there is a more general theory in which functions on an algebra with Frchet/Gateaux derivatives that are represented by multiplication operators play an important role? And if so, whether this theory is as rich as complex analysis?","So it is well-known that complex differentiability of a function is equivalent to the function being Frchet/Gateaux differentiable and the component functions (obtained by regarding as a 2-dimensional vector space over ) satisfying the Cauchy-Riemann equations, i.e. the Frchet/Gateaux derivative at should be a linear operator representing multiplication by a complex number and thus be of the form The fact that the ""directional derivatives"" are required to coincide for all directions in complex analysis leads to a very rigid, yet rich theory. So, related to the above point of view, I wondered if there is a more general theory in which functions on an algebra with Frchet/Gateaux derivatives that are represented by multiplication operators play an important role? And if so, whether this theory is as rich as complex analysis?",f:\mathbb{C}\rightarrow\mathbb{C} \mathbb{C} \mathbb{R} c\in\mathbb{C} f'(c) = \begin{pmatrix}a&-b\\b&a\end{pmatrix}.,"['complex-analysis', 'frechet-derivative', 'gateaux-derivative']"
37,Fundamental Difference between the Real and the Complex,Fundamental Difference between the Real and the Complex,,"I am an undergraduate student studying Complex Analysis. Since holomorphic functions have properties that differentiable functions on a real line do not have in general (i.e. Taylors Thoerem, Open Mapping Property, etc.), I come into question about what property of complex plane results in this nice results on holomorphic functions. In my textbook, written by Silverman, most of the properties come from the Taylors Thoerem. Thus my question might converge to, what difference between real line and complex plane makes every holomorphic function has their power series expansion? In my first sight, I thought about the difference on an integral (on real line) and the line integral (on complex plane), but this seems not very fundamental, since real multivariable functions also might not have the power series expansion. I think the difference is related to their algebraic, or topological properties, but it is hard to reveal it for me. It will be glad if someone give me an insight.","I am an undergraduate student studying Complex Analysis. Since holomorphic functions have properties that differentiable functions on a real line do not have in general (i.e. Taylors Thoerem, Open Mapping Property, etc.), I come into question about what property of complex plane results in this nice results on holomorphic functions. In my textbook, written by Silverman, most of the properties come from the Taylors Thoerem. Thus my question might converge to, what difference between real line and complex plane makes every holomorphic function has their power series expansion? In my first sight, I thought about the difference on an integral (on real line) and the line integral (on complex plane), but this seems not very fundamental, since real multivariable functions also might not have the power series expansion. I think the difference is related to their algebraic, or topological properties, but it is hard to reveal it for me. It will be glad if someone give me an insight.",,"['complex-analysis', 'analysis']"
38,"Solutions to $\Gamma(z,1)^2 + \Gamma(z,1) = 0 $?",Solutions to ?,"\Gamma(z,1)^2 + \Gamma(z,1) = 0 ","Let $\Gamma(z,1) $ be the well-known incomplete gamma function : $\int_1^{\infty} e^{-t} t^{z-1} dt $ Now I am curious to find solutions to $$\Gamma(z,1)^2 + \Gamma(z,1) = 0 $$ We can ofcourse reduce this too all complex solutions of either $$\Gamma(z,1) = 0 $$ or $$\Gamma(z,1) = -1 $$ I heard that this function is an entire function so the equation $\Gamma(z,1)^2 + \Gamma(z,1) = 0 $ must have solutions. I think that $\Gamma(z,1) = 0 $ has no (finite) solutions. I assume most solutions to $\Gamma(z,1) = -1 $ must have $-3 < Re(z) < 3 $ due to the functional equation this function satisfies. ( $\Gamma(z+1,1) = z \Gamma(z,1) + e^{-1} $ ) I know a bit about complex analysis and contour integrals. But I have no efficient method to find the zero's. I would like to have the values and some insight into them. How far are the zero's apart from eachother ? Im aware of another identity for strictly real $z < 1$ : $$ \Gamma(z,1)=\frac{e^{z-1}}{\Gamma(1-z)} \int_0^\infty \frac{e^{-t} t^{-z}}{1+t} dt$$ Not sure if that could help. I was only able to find $t=4.86853..+5.66062..i$ and its complex conjugate as solutions to $\Gamma(t,1) = -1$ edit : Perhaps the following limits might be helpful : $$ \lim_{x \to +\infty} Re(x^2 \Gamma(1+e+x i,1)  ) = -1$$ $$ \lim_{x \to +\infty} Im(x \Gamma(1+e+ x i,1) ) = e^{-1} i $$",Let be the well-known incomplete gamma function : Now I am curious to find solutions to We can ofcourse reduce this too all complex solutions of either or I heard that this function is an entire function so the equation must have solutions. I think that has no (finite) solutions. I assume most solutions to must have due to the functional equation this function satisfies. ( ) I know a bit about complex analysis and contour integrals. But I have no efficient method to find the zero's. I would like to have the values and some insight into them. How far are the zero's apart from eachother ? Im aware of another identity for strictly real : Not sure if that could help. I was only able to find and its complex conjugate as solutions to edit : Perhaps the following limits might be helpful :,"\Gamma(z,1)  \int_1^{\infty} e^{-t} t^{z-1} dt  \Gamma(z,1)^2 + \Gamma(z,1) = 0  \Gamma(z,1) = 0  \Gamma(z,1) = -1  \Gamma(z,1)^2 + \Gamma(z,1) = 0  \Gamma(z,1) = 0  \Gamma(z,1) = -1  -3 < Re(z) < 3  \Gamma(z+1,1) = z \Gamma(z,1) + e^{-1}  z < 1  \Gamma(z,1)=\frac{e^{z-1}}{\Gamma(1-z)} \int_0^\infty \frac{e^{-t} t^{-z}}{1+t} dt t=4.86853..+5.66062..i \Gamma(t,1) = -1  \lim_{x \to +\infty} Re(x^2 \Gamma(1+e+x i,1)  ) = -1  \lim_{x \to +\infty} Im(x \Gamma(1+e+ x i,1) ) = e^{-1} i ","['complex-analysis', 'roots', 'special-functions', 'functional-equations', 'gamma-function']"
39,What can we say about the number of unique roots of an infinite family of polynomials?,What can we say about the number of unique roots of an infinite family of polynomials?,,"Context: I saw the following problem on a discord server I'm in Now, this is an obvious meme, but it's a really interesting question so I started working on it with some other people in a math discord. A fairly elementary simplification of the problem is to define the family of polynomials $p_1(c) = c$ , $p_2(c) = c^2 + c$ , $p_3(c) = \left(c^2 + c\right)^2 + c$ , where, in general $p_n = p_{n - 1}^2 + c$ . If $c_0 \in \mathbb{C}$ is a root of any $p_n$ , then $c_0$ only kills finitely many people, because iteratively applying $f$ with that choice of $c$ eventually returns you to $0$ . However, this only gets you a subset of all the values of $c$ that work; in particular, this only gives you the values of $c$ which result in a loop that passes through $0$ , which not all loops will. For example, choosing $c = -2$ gives the loop $0, -2, 2, 2, 2, 2, ...$ , so $-2$ solves the original problem but won't be the root of any $p_i$ . We can make sure we have all the solutions by considering the roots to a difference of two of the $p_i$ , since if $c$ is a root to $p_n(x) - p_m(x)$ where $n \neq m$ , then clearly there is a cycle because two distinct numbers of iterations of $f$ return the same output. At this point, we got stuck, and there are two natural questions (1) What can we say about the roots of these polynomials? Are there infinitely many distinct roots? Are these uniformly bounded, and if not, are they nicely bounded by some function of $n$ ? Are the roots all isolated, or are there accumulation points? And of course, the original problem: (2) Is there a nice way to describe the set of all $c$ which are a root of some $p_i$ or which are the root of some $p_i - p_j$ for $i \neq j$ ? I've tagged the question abstract-algebra and dynamical-systems because the questions about the roots seems algebraic, and the original problem seems like a dynamical systems problem. Please let me know if there are other tags which fit better.","Context: I saw the following problem on a discord server I'm in Now, this is an obvious meme, but it's a really interesting question so I started working on it with some other people in a math discord. A fairly elementary simplification of the problem is to define the family of polynomials , , , where, in general . If is a root of any , then only kills finitely many people, because iteratively applying with that choice of eventually returns you to . However, this only gets you a subset of all the values of that work; in particular, this only gives you the values of which result in a loop that passes through , which not all loops will. For example, choosing gives the loop , so solves the original problem but won't be the root of any . We can make sure we have all the solutions by considering the roots to a difference of two of the , since if is a root to where , then clearly there is a cycle because two distinct numbers of iterations of return the same output. At this point, we got stuck, and there are two natural questions (1) What can we say about the roots of these polynomials? Are there infinitely many distinct roots? Are these uniformly bounded, and if not, are they nicely bounded by some function of ? Are the roots all isolated, or are there accumulation points? And of course, the original problem: (2) Is there a nice way to describe the set of all which are a root of some or which are the root of some for ? I've tagged the question abstract-algebra and dynamical-systems because the questions about the roots seems algebraic, and the original problem seems like a dynamical systems problem. Please let me know if there are other tags which fit better.","p_1(c) = c p_2(c) = c^2 + c p_3(c) = \left(c^2 + c\right)^2 + c p_n = p_{n - 1}^2 + c c_0 \in \mathbb{C} p_n c_0 f c 0 c c 0 c = -2 0, -2, 2, 2, 2, 2, ... -2 p_i p_i c p_n(x) - p_m(x) n \neq m f n c p_i p_i - p_j i \neq j","['complex-analysis', 'polynomials', 'dynamical-systems', 'fractals']"
40,Question about pinch singularities,Question about pinch singularities,,"I am reading the book ""Analytic S-matrix"" by Eden,Landshoff, Olive and Polkinghorne. In Sec.2, they discuss the different kinds of singularities of a function $f(z)$ defined as an integral of an analytic function $g(z,\omega)$ in the complex $\omega-$ plane along some closed contour $\mathcal{C}$ , i.e. $$ f(z) = \int_\mathcal{C}\, d\omega\, g(z,\omega)\,. $$ It is assumed that we know the singularities of $g(z,\omega)$ . They discuss the case of pinch singularities, i.e. those singularities that approach the contour from the opposite sides and eventually coincide. As an example, they consider $$ f(z) = \int_0^1 \frac{d\omega}{(\omega-z)(\omega-a)} $$ where the contour is not really specified. This is already strange... shouldn't they specify the contour? Their result is $$ f(z) = \frac{1}{z-a}\log{\left[\frac{a(1-z)}{(1-a)z}\right]}\,,\qquad(a>1) $$ To perform this integral, I was thinking to take the parameterization $\omega(t) = \sqrt{t} e^{i \arccos{\sqrt{t}}}$ where $t\in [0,1]$ . This parameterization actually selects the path of a semi-cicle in the upper-half complex $\omega-$ plane, running from $\omega=0$ to $\omega=1$ . The integral then can be computed as $$ f(z) = \int_0^1 dt \frac{d\omega(t)}{dt}\frac{1}{(\omega(t)-z)(\omega(t)-a)} $$ If $z=a>1$ or $z=a<0$ , the singularities of the integrand lie outside my integration path, and the integral is perfectly convergent. Under Eq.(2.1.5) of their book, the authors write the singularity at $z=a$ is only encountered on encircling one of the logarithmic singularities, so that now $\log{1}$ is $\pm 2\pi i$ instead of zero and no longer cancels the pole. Can anyone explain to me what they mean by the last sentence? It is not clear to me which kind of contour can give a singularity at $z=a$ .","I am reading the book ""Analytic S-matrix"" by Eden,Landshoff, Olive and Polkinghorne. In Sec.2, they discuss the different kinds of singularities of a function defined as an integral of an analytic function in the complex plane along some closed contour , i.e. It is assumed that we know the singularities of . They discuss the case of pinch singularities, i.e. those singularities that approach the contour from the opposite sides and eventually coincide. As an example, they consider where the contour is not really specified. This is already strange... shouldn't they specify the contour? Their result is To perform this integral, I was thinking to take the parameterization where . This parameterization actually selects the path of a semi-cicle in the upper-half complex plane, running from to . The integral then can be computed as If or , the singularities of the integrand lie outside my integration path, and the integral is perfectly convergent. Under Eq.(2.1.5) of their book, the authors write the singularity at is only encountered on encircling one of the logarithmic singularities, so that now is instead of zero and no longer cancels the pole. Can anyone explain to me what they mean by the last sentence? It is not clear to me which kind of contour can give a singularity at .","f(z) g(z,\omega) \omega- \mathcal{C} 
f(z) = \int_\mathcal{C}\, d\omega\, g(z,\omega)\,.
 g(z,\omega) 
f(z) = \int_0^1 \frac{d\omega}{(\omega-z)(\omega-a)}
 
f(z) = \frac{1}{z-a}\log{\left[\frac{a(1-z)}{(1-a)z}\right]}\,,\qquad(a>1)
 \omega(t) = \sqrt{t} e^{i \arccos{\sqrt{t}}} t\in [0,1] \omega- \omega=0 \omega=1 
f(z) = \int_0^1 dt \frac{d\omega(t)}{dt}\frac{1}{(\omega(t)-z)(\omega(t)-a)}
 z=a>1 z=a<0 z=a \log{1} \pm 2\pi i z=a","['complex-analysis', 'contour-integration', 'singularity', 'singular-integrals']"
41,Writing the Real Part of Complex Integrand,Writing the Real Part of Complex Integrand,,"I'm having a hard time to understand how's Eq. $(6.73)$ become Eq. $(6.75)$ . It's taken from Numerical Methods for Laplace Transform Inversion by Cohen. Here's the problem: [...]. The basis of their formulation is, like Talbot, that the inverse transform is given by $$f(t)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}e^{st}\bar f(s)ds.\tag{6.71}$$ The contour is deformed by means of the path $$s(\theta)=r\theta(\cot\theta+i),\quad-\pi<\theta<\pi,\tag{6.72}$$ where $r$ is a parameter. This path only involves one parameter whereas Talbot's consisted of two. Integration over the deformed path yields $$f(t)=\frac{1}{2\pi i}\int_{-\pi}^\pi e^{ts(\theta)}\bar f(s(\theta))s'(\theta)d\theta.\tag{6.73}$$ Differentiating (6.72) we have $s'(\theta)=ir(1+i\sigma(\theta))$ , where $$\sigma(\theta)=\theta+(\theta\cot\theta-1)\cot\theta.\tag{6.74}$$ We find $$f(t)=\frac{r}{\pi}\int_0^\pi\Re\Bigl[e^{ts(\theta)}\bar f(s(\theta))(1+i\sigma(\theta))\Bigr]d\theta.\tag{6.75}$$ As you can see there, i'm confused about where the $\Re$ got from. And i have 2 speculations about this. Speculation 1 (The idea is originated from my friend, so let me rewrite what he said) Regarding the integral: $s(\theta)$ on $(-\pi,\,\pi)$ is symmetric about $\theta=0$ (i don't understand this part). So we can integrate on $\theta\in (0,\pi)$ and multiply by $2$ in the denominator of the constant (outside the integral). The factor $ir$ in $s'(\theta)$ cancels the $i$ in the constant and gives it $r$ in the numerator. Assuming $f(t)$ is a real-valued function, $f(t)=\Re f(t)$ . For Riemann integrable functions $g(z)$ , we have $\Re \int g(z)\Bbb dz = \int \Re g(z) \Bbb dz$ . Hence, since $f(t)$ is equal to an integral, we can take $\Re$ on both sides and move the real part symbol inside the integral. Speculation 2 (This is my own idea) By letting the whole integrand with $\Lambda$ for simplification purpose (i'm not performing change of variable here, just for a simplification). Then we can consider: $$\begin{align} \int_{-\pi}^{\pi} \Lambda\,\Bbb d\Lambda &= \int_{-\pi}^{0} \Lambda\,\Bbb d\Lambda + \int_{0}^{\pi} \Lambda\,\Bbb d\Lambda\\ &= -\int_{0}^{-\pi} \Lambda\,\Bbb d\Lambda + \int_{0}^{\pi} \Lambda\,\Bbb d\Lambda\\ &= \int_{0}^{\pi} \overline{\Lambda}\,\Bbb d\overline{\Lambda} + \int_{0}^{\pi} \Lambda\,\Bbb d\Lambda\\ &= 2\int_{0}^{\pi}\Re \Lambda\,\Bbb d \Lambda \end{align}$$ The last expression is considering this property : $z + \overline{z} = 2\Re z$ , where $\overline{z}$ is the conjugate of $z$ . But i'm not really sure if i can consider the third line is valid about the conjugate? And by the way. The first equation on the picture is the formula for finding the Inverse Laplace Transform of $f(t)$ (real-valued) and the Laplace transform that what i'm talking is one-sided Laplace Transform. Are both speculations correct? Is my speculation is correct? If not, please provide the correct interpretation behind the story of Eq. $(6.73)$ become Eq. $(6.75)$ . Please kindly to help me, i really need your help. Thanks in advance!","I'm having a hard time to understand how's Eq. become Eq. . It's taken from Numerical Methods for Laplace Transform Inversion by Cohen. Here's the problem: [...]. The basis of their formulation is, like Talbot, that the inverse transform is given by The contour is deformed by means of the path where is a parameter. This path only involves one parameter whereas Talbot's consisted of two. Integration over the deformed path yields Differentiating (6.72) we have , where We find As you can see there, i'm confused about where the got from. And i have 2 speculations about this. Speculation 1 (The idea is originated from my friend, so let me rewrite what he said) Regarding the integral: on is symmetric about (i don't understand this part). So we can integrate on and multiply by in the denominator of the constant (outside the integral). The factor in cancels the in the constant and gives it in the numerator. Assuming is a real-valued function, . For Riemann integrable functions , we have . Hence, since is equal to an integral, we can take on both sides and move the real part symbol inside the integral. Speculation 2 (This is my own idea) By letting the whole integrand with for simplification purpose (i'm not performing change of variable here, just for a simplification). Then we can consider: The last expression is considering this property : , where is the conjugate of . But i'm not really sure if i can consider the third line is valid about the conjugate? And by the way. The first equation on the picture is the formula for finding the Inverse Laplace Transform of (real-valued) and the Laplace transform that what i'm talking is one-sided Laplace Transform. Are both speculations correct? Is my speculation is correct? If not, please provide the correct interpretation behind the story of Eq. become Eq. . Please kindly to help me, i really need your help. Thanks in advance!","(6.73) (6.75) f(t)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}e^{st}\bar f(s)ds.\tag{6.71} s(\theta)=r\theta(\cot\theta+i),\quad-\pi<\theta<\pi,\tag{6.72} r f(t)=\frac{1}{2\pi i}\int_{-\pi}^\pi e^{ts(\theta)}\bar f(s(\theta))s'(\theta)d\theta.\tag{6.73} s'(\theta)=ir(1+i\sigma(\theta)) \sigma(\theta)=\theta+(\theta\cot\theta-1)\cot\theta.\tag{6.74} f(t)=\frac{r}{\pi}\int_0^\pi\Re\Bigl[e^{ts(\theta)}\bar f(s(\theta))(1+i\sigma(\theta))\Bigr]d\theta.\tag{6.75} \Re s(\theta) (-\pi,\,\pi) \theta=0 \theta\in (0,\pi) 2 ir s'(\theta) i r f(t) f(t)=\Re f(t) g(z) \Re \int g(z)\Bbb dz = \int \Re g(z) \Bbb dz f(t) \Re \Lambda \begin{align}
\int_{-\pi}^{\pi} \Lambda\,\Bbb d\Lambda &= \int_{-\pi}^{0} \Lambda\,\Bbb d\Lambda + \int_{0}^{\pi} \Lambda\,\Bbb d\Lambda\\
&= -\int_{0}^{-\pi} \Lambda\,\Bbb d\Lambda + \int_{0}^{\pi} \Lambda\,\Bbb d\Lambda\\
&= \int_{0}^{\pi} \overline{\Lambda}\,\Bbb d\overline{\Lambda} + \int_{0}^{\pi} \Lambda\,\Bbb d\Lambda\\
&= 2\int_{0}^{\pi}\Re \Lambda\,\Bbb d \Lambda
\end{align} z + \overline{z} = 2\Re z \overline{z} z f(t) (6.73) (6.75)","['complex-analysis', 'laplace-transform', 'contour-integration', 'riemann-integration', 'inverse-laplace']"
42,Generalization of Schwarz's Lemma,Generalization of Schwarz's Lemma,,"I am reading Lectures on Riemann Surfaces by Otto Forster. He says: (p.110) The following lemma may be viewed as a generalization of Schwarz's lemma. Let $D,D'$ be a pair of open subsets of $\mathbb{C}$ , where $D$ is a relatively compact subset of $D'$ . For any $\varepsilon>0$ , there is a closed vector space $A\subset L^2(D,\mathcal{O})$ , of finite codimension, with $$ \lVert f\rVert_{L^2(D')}\leq \varepsilon \lVert f\rVert_{L^2(D)}$$ He has already shown that $L^2(D,\mathcal{O})$ , the space of holomorphic functions on $D$ , forms a Hilbert space under the inner product $\iint f\overline{g}dxdy$ thus the ""closed"" comment. What does he mean when he says this generalizes Schwarz's lemma? How is this related to Schwarz's lemma?","I am reading Lectures on Riemann Surfaces by Otto Forster. He says: (p.110) The following lemma may be viewed as a generalization of Schwarz's lemma. Let be a pair of open subsets of , where is a relatively compact subset of . For any , there is a closed vector space , of finite codimension, with He has already shown that , the space of holomorphic functions on , forms a Hilbert space under the inner product thus the ""closed"" comment. What does he mean when he says this generalizes Schwarz's lemma? How is this related to Schwarz's lemma?","D,D' \mathbb{C} D D' \varepsilon>0 A\subset L^2(D,\mathcal{O})  \lVert f\rVert_{L^2(D')}\leq \varepsilon \lVert f\rVert_{L^2(D)} L^2(D,\mathcal{O}) D \iint f\overline{g}dxdy",['complex-analysis']
43,Show that $e^z = z + \lambda$ has exactly $m + n$ solution in a horizontal strip.,Show that  has exactly  solution in a horizontal strip.,e^z = z + \lambda m + n,"Suppose $\lambda \in \mathbb{C}$ , show that for sufficient large $m$ and $n$ , then the equation $e^z = z + \lambda$ has exactly $m + n$ solutions in the horizontal strip $\{- 2 \pi im < \operatorname{Im} z < 2 \pi i n\}$ . I tried to compute the increase in the argument of $f(z) = e^z - z + \lambda$ around the rectangle with vertices $R-2\pi im$ , $R + 2 \pi in$ , $-R + 2 \pi in$ and $-R + 2 \pi im$ . When $R$ is sufficiently large, $f(x) \approx e^z$ , but then I got that the increase in the argument around the rectangle is $4\pi (m + n)$ . So what I did wrong?","Suppose , show that for sufficient large and , then the equation has exactly solutions in the horizontal strip . I tried to compute the increase in the argument of around the rectangle with vertices , , and . When is sufficiently large, , but then I got that the increase in the argument around the rectangle is . So what I did wrong?",\lambda \in \mathbb{C} m n e^z = z + \lambda m + n \{- 2 \pi im < \operatorname{Im} z < 2 \pi i n\} f(z) = e^z - z + \lambda R-2\pi im R + 2 \pi in -R + 2 \pi in -R + 2 \pi im R f(x) \approx e^z 4\pi (m + n),['complex-analysis']
44,zero set of complex analytic functions has zero measure,zero set of complex analytic functions has zero measure,,"Based on the answer here , the following result is clear: ``Given a complex analytic function $f(x)$ with $x$ is in an open connected set $D  \subseteq    \mathbb{C}^n$ , the zero set $$F = \{x \in D | f(x) = 0\}$$ has $2n$ -dimensional Lebesgue measure zero"" Now consider a slightly different situation: A complex analytic function $g(z)$ with $z \in D \times V$ , where $D$ is an open connected subset of $\mathbb{C}^n$ and $V$ is an open connected subset of $\mathbb{R}^m$ . Is it true that the zero set of $g(z)$ $$F_2 = \{z \in D \times V | g(z) = 0\}$$ has $(2n+m)$ -dimensional Lebesgue measure? How to prove ( or to modify the proof in this book , Corollary 10, p.9. to obtain) the above result?","Based on the answer here , the following result is clear: ``Given a complex analytic function with is in an open connected set , the zero set has -dimensional Lebesgue measure zero"" Now consider a slightly different situation: A complex analytic function with , where is an open connected subset of and is an open connected subset of . Is it true that the zero set of has -dimensional Lebesgue measure? How to prove ( or to modify the proof in this book , Corollary 10, p.9. to obtain) the above result?","f(x) x D  \subseteq 
  \mathbb{C}^n F = \{x \in D | f(x) = 0\} 2n g(z) z \in D \times V D \mathbb{C}^n V \mathbb{R}^m g(z) F_2 = \{z \in D \times V | g(z) = 0\} (2n+m)","['complex-analysis', 'analytic-functions']"
45,Closed form of a complicated series,Closed form of a complicated series,,"Consider the series $$\sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}f(s,k+1+\delta)$$ Where $|G_{m+1}|$ are the absolute Gregory's coefficients, $0<\delta<1$ and : $$f(s,x)=\frac{x^{-s}}{2\pi i}\left[x^{\frac{2\pi i}{\log j}}\Phi\left(x^{\frac{2\pi i}{\log j}},1,1-\frac{\log j}{2\pi i}s\right)-x^{-\frac{2\pi i}{\log j}}\Phi\left(x^{-\frac{2\pi i}{\log j}},1,1+\frac{\log j}{2\pi i}s\right)\right]$$ where $\Phi(\cdot,\cdot)$ is the Lerch transcendent, $s\in \mathbb{C}$ , and $j\in \mathbb{Z^{+}}$ . I'm seeking a closed form for this series. I tried expanding $f(s,x)$ as : $$f(s,x)=\frac{x^{-s}}{s\log j}+x^{-s}\sum_{l\in \mathbb{Z}}\frac{x^{\frac{2\pi i l}{\log j}}}{2\pi i l-s\log j}\;\;\;\;\;(A)$$ and i know how to evaluate: $$\sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}(k+1+\delta)^{z}\;\;\;\;z\in \mathbb{C}$$ but the resulting series (A) is only conditionally converging, and i can't reverse the order of the summation. Any help is highly appreciated. EDIT : we have that : $$\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}e^{-kx}=(1-e^{x})(1-e^{-x})^{m}+e^{x}$$ Using the generating function of Gregory coefficients : $$\frac{y}{\log(1+y)}=1+\sum_{m=1}^{\infty}G_{m}y^{m}\;\;\;\;\;|y|<1$$ we have : $$\sum_{m=0}^{\infty}|G_{m+1}|(1-e^{-x})^{m}=\frac{1}{1-e^{-x}}-\frac{1}{x}$$ Thus : $$\sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}e^{-kx}=\frac{e^{x}-1}{x}$$ Where we used : $$\sum_{m=0}^{\infty}|G_{m+1}|=1$$ Now we have : $$(1+\delta+k)^{-z}=\frac{1}{\Gamma(z)}\int_{0}^{\infty}e^{-(1+\delta+k)x}x^{z-1}dx\;\;\;\;\Re(z)>0$$ Thus : $$\sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}(1+\delta+k)^{-z}=\frac{1}{\Gamma(z)}\int_{0}^{\infty}(e^{-\delta x}-e^{-(1+\delta)x})x^{z-2}dx$$ $$=\frac{1}{\Gamma(z)}\left(\delta^{1-z}\Gamma(z-1)-(1+\delta)^{1-z}\Gamma(z-1)\right)=\frac{1}{z-1}\left(\delta^{1-z}-(1+\delta)^{1-z}\right)$$ But it can be easily verified that the series above converges everywhere. Thus : $$\sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}(1+\delta+k)^{z}=\frac{1}{z+1}\left[(1+\delta)^{1+z}-\delta^{1+z}\right]\;\;\;z\in \mathbb{C}$$","Consider the series Where are the absolute Gregory's coefficients, and : where is the Lerch transcendent, , and . I'm seeking a closed form for this series. I tried expanding as : and i know how to evaluate: but the resulting series (A) is only conditionally converging, and i can't reverse the order of the summation. Any help is highly appreciated. EDIT : we have that : Using the generating function of Gregory coefficients : we have : Thus : Where we used : Now we have : Thus : But it can be easily verified that the series above converges everywhere. Thus :","\sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}f(s,k+1+\delta) |G_{m+1}| 0<\delta<1 f(s,x)=\frac{x^{-s}}{2\pi i}\left[x^{\frac{2\pi i}{\log j}}\Phi\left(x^{\frac{2\pi i}{\log j}},1,1-\frac{\log j}{2\pi i}s\right)-x^{-\frac{2\pi i}{\log j}}\Phi\left(x^{-\frac{2\pi i}{\log j}},1,1+\frac{\log j}{2\pi i}s\right)\right] \Phi(\cdot,\cdot) s\in \mathbb{C} j\in \mathbb{Z^{+}} f(s,x) f(s,x)=\frac{x^{-s}}{s\log j}+x^{-s}\sum_{l\in \mathbb{Z}}\frac{x^{\frac{2\pi i l}{\log j}}}{2\pi i l-s\log j}\;\;\;\;\;(A) \sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}(k+1+\delta)^{z}\;\;\;\;z\in \mathbb{C} \sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}e^{-kx}=(1-e^{x})(1-e^{-x})^{m}+e^{x} \frac{y}{\log(1+y)}=1+\sum_{m=1}^{\infty}G_{m}y^{m}\;\;\;\;\;|y|<1 \sum_{m=0}^{\infty}|G_{m+1}|(1-e^{-x})^{m}=\frac{1}{1-e^{-x}}-\frac{1}{x} \sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}e^{-kx}=\frac{e^{x}-1}{x} \sum_{m=0}^{\infty}|G_{m+1}|=1 (1+\delta+k)^{-z}=\frac{1}{\Gamma(z)}\int_{0}^{\infty}e^{-(1+\delta+k)x}x^{z-1}dx\;\;\;\;\Re(z)>0 \sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}(1+\delta+k)^{-z}=\frac{1}{\Gamma(z)}\int_{0}^{\infty}(e^{-\delta x}-e^{-(1+\delta)x})x^{z-2}dx =\frac{1}{\Gamma(z)}\left(\delta^{1-z}\Gamma(z-1)-(1+\delta)^{1-z}\Gamma(z-1)\right)=\frac{1}{z-1}\left(\delta^{1-z}-(1+\delta)^{1-z}\right) \sum_{m=0}^{\infty}|G_{m+1}|\sum_{k=0}^{m}(-1)^{k}\binom{m+1}{k+1}(1+\delta+k)^{z}=\frac{1}{z+1}\left[(1+\delta)^{1+z}-\delta^{1+z}\right]\;\;\;z\in \mathbb{C}","['sequences-and-series', 'complex-analysis', 'special-functions']"
46,What can we say about $\frac{1}{2(1-z)}-\sum_{n=0}^\infty\{n\sqrt{2}\}z^n$ in the vicinity of $z=1$?,What can we say about  in the vicinity of ?,\frac{1}{2(1-z)}-\sum_{n=0}^\infty\{n\sqrt{2}\}z^n z=1,"Let $\{x\}$ denote the fractional part of $x$ , what can we say about $$\frac{1}{2(1-z)}-\sum_{n=0}^\infty\{n\sqrt{2}\}z^n$$ in the vicinity of $z=1$ ? It seems that there is no limit, but the partial sums seem bounded.","Let denote the fractional part of , what can we say about in the vicinity of ? It seems that there is no limit, but the partial sums seem bounded.",\{x\} x \frac{1}{2(1-z)}-\sum_{n=0}^\infty\{n\sqrt{2}\}z^n z=1,"['complex-analysis', 'asymptotics', 'ergodic-theory']"
47,For which $a$ does the equation $f(z) = f(az) $ has a non constant solution $f$,For which  does the equation  has a non constant solution,a f(z) = f(az)  f,"For which $a \in \mathbb{C} -\ \{0,1\}$ does the equation $f(z) = f(az) $ has a non constant solution $f$ with $f$ being analytical in a neighborhood of $0$. My attempt: First, we can see that any such solution must satisfy: $f(z)=f(a^kz)$ for all $k \in \mathbb{N} $. If $|a|<1$: The series $z_{k} = a^k$ converges to 0 which is an accumulation point, and $f(z_i)=f(z_j)$ for all $i, j\in \mathbb{N} $. Thus $f$ must be constant. If $|a|=1$: For all $a \neq 1$ , $f$ must be constant on any circle around $0$, so again $f$ must be constant. My quesions are: Am I correct with my consclusions? Also, I'm stuck in the case where $|a|>1$. Any ideas? Thanks","For which $a \in \mathbb{C} -\ \{0,1\}$ does the equation $f(z) = f(az) $ has a non constant solution $f$ with $f$ being analytical in a neighborhood of $0$. My attempt: First, we can see that any such solution must satisfy: $f(z)=f(a^kz)$ for all $k \in \mathbb{N} $. If $|a|<1$: The series $z_{k} = a^k$ converges to 0 which is an accumulation point, and $f(z_i)=f(z_j)$ for all $i, j\in \mathbb{N} $. Thus $f$ must be constant. If $|a|=1$: For all $a \neq 1$ , $f$ must be constant on any circle around $0$, so again $f$ must be constant. My quesions are: Am I correct with my consclusions? Also, I'm stuck in the case where $|a|>1$. Any ideas? Thanks",,['complex-analysis']
48,Use Mittag-Leffler to prove Weierstrass Factorization Theorem,Use Mittag-Leffler to prove Weierstrass Factorization Theorem,,"Use the Mittag-Leffler theorem to prove the following:  Let $(a_n)$ be a sequence in a simply connected domain $D \subset \mathbb{C}$ that does not have an accumulation point in $D$.  Prove that there exists a holomorphic function $f$ so that its zero set equals $(a_n)$ counting multiplicity. In particular, do not use the Weierstrass Factorization Theorem, Weierstrass Products, or Blaschke Products in your answer. I have no idea how to do this problem.  Can someone help?","Use the Mittag-Leffler theorem to prove the following:  Let $(a_n)$ be a sequence in a simply connected domain $D \subset \mathbb{C}$ that does not have an accumulation point in $D$.  Prove that there exists a holomorphic function $f$ so that its zero set equals $(a_n)$ counting multiplicity. In particular, do not use the Weierstrass Factorization Theorem, Weierstrass Products, or Blaschke Products in your answer. I have no idea how to do this problem.  Can someone help?",,"['complex-analysis', 'analytic-functions']"
49,Weierstrass's elliptic function's expansion,Weierstrass's elliptic function's expansion,,"I'm studying about elliptic functions. In Bergman's book (The Kernel function and conformal mapping - page 10), the author gave an expansion of the Weierstrass's $\wp$ function : $$\wp(u) = - \frac{\eta_1}{w_1}+(\frac{\pi}{2w_1})^2\frac{1}{\sin^2(\pi u/2w_1)}-2(\frac{\pi}{w_1})^2\sum_{n=1}^{\infty}\frac{nq^{2n}}{1-q^{2n}}\cos(\frac{n\pi u}{w_1})$$ where $w_1$ , $w_2$ are periods, $q = \exp(i\pi w_2/w_1)$ and $2\eta_1$ is the increment of Weierstrass's zeta function related to the period $w_1$ (this means $\zeta (z+2w_1) = \zeta(z)+2\eta_1$ , for more information, can see here . I do not know how to figure out this formula from the original formula : $$\wp(u)=\frac{1}{u^2}+\sum_{(m,n)\neq (0,0)} ((\frac{1}{u+mw_1+nw_2})^2-(\frac{1}{mw_1+nw_2})^2)$$ Any hints would be appreciated.","I'm studying about elliptic functions. In Bergman's book (The Kernel function and conformal mapping - page 10), the author gave an expansion of the Weierstrass's function : where , are periods, and is the increment of Weierstrass's zeta function related to the period (this means , for more information, can see here . I do not know how to figure out this formula from the original formula : Any hints would be appreciated.","\wp \wp(u) = - \frac{\eta_1}{w_1}+(\frac{\pi}{2w_1})^2\frac{1}{\sin^2(\pi u/2w_1)}-2(\frac{\pi}{w_1})^2\sum_{n=1}^{\infty}\frac{nq^{2n}}{1-q^{2n}}\cos(\frac{n\pi u}{w_1}) w_1 w_2 q = \exp(i\pi w_2/w_1) 2\eta_1 w_1 \zeta (z+2w_1) = \zeta(z)+2\eta_1 \wp(u)=\frac{1}{u^2}+\sum_{(m,n)\neq (0,0)} ((\frac{1}{u+mw_1+nw_2})^2-(\frac{1}{mw_1+nw_2})^2)","['complex-analysis', 'elliptic-functions']"
50,Factorization in formal power series versus in convergent power series over the complexes,Factorization in formal power series versus in convergent power series over the complexes,,"Let $R=\mathbb C\{x_1,...,x_n\}\subset S=\mathbb C [[x_1,...,x_n]]$ denote the ring of convergent, respectively formal, power series over $\mathbb C$ . Suppose $f\in R$ is irreducible in $R$ . Does it remain irreducible in $S$ ?","Let denote the ring of convergent, respectively formal, power series over . Suppose is irreducible in . Does it remain irreducible in ?","R=\mathbb C\{x_1,...,x_n\}\subset S=\mathbb C [[x_1,...,x_n]] \mathbb C f\in R R S","['complex-analysis', 'algebraic-geometry', 'several-complex-variables']"
51,About the Elliptical Function $\mathrm{sn}(z)$,About the Elliptical Function,\mathrm{sn}(z),"In the picture below, the symmetry principle was used to show that the rectangle of Figure $36$ a is mapped onto Figure $36$ b. I did that. Shortly thereafter the function $\mathrm{sn}( \alpha \cdot z)$ is considered, where $\alpha$ is such that $\mathrm{sn}(\alpha \cdot K) = 1$ . Then, it claims that with this condition on $\alpha$ , the function $\mathrm{sn}(\alpha \cdot z)$ maps Figure $36$ a onto the upper half-plane. I can't see why this statement is true. I had some ideas but none with success, if someone could give me a light, I would be grateful. Idea $1$ : Since the function $\mathrm{sn}(z)$ is analytical, in particular, continuous, then it maps boundary to boundary, and connected set to connected set. Thus, it is enough to show that the boundary of the interior of the rectangle is mapped to the real axis, but I couldn't do it. The other idea was to remember that, by definition, the function $\mathrm{sn}(z)$ maps the interior of the rectangle with vertices $-K, K, K+iK' \hspace{1mm} \mbox{and} \hspace{1mm} -K+iK'$ onto the upper half-plane. Thus, if the function $\mathrm{sn}(\alpha \cdot z)$ is considered, it maps the inside of the rectangle with vertices $- \dfrac{K}{\alpha}, \dfrac{K}{\alpha}, \dfrac{K+iK'}{\alpha} \hspace{1mm} \mbox{and} \hspace{1mm} -\dfrac{K+iK'}{\alpha}$ onto the upper half-plane. My idea was to show that this last rectangle and the rectangle of Figure 36a are the same. I think I should use the condition $\mathrm{sn}(\alpha \cdot K) = 1$ to conclude this fact but I couldn't do it. Applying the symmetry principle to an inversion of the rectangle in Fig $34$ a with respect to its upper side, we find that the function $w=\mathrm{sn}(z;q)$ maps the rectangle of Fig. $36$ a onto the full $w$ -plane which is furnished with a slit as indicated in Fig. $36$ b. Consider now the function $\mathrm{sn}(\alpha z)$ (where $\alpha$ is such that $\mathrm{sn}(\alpha K=1)$ ) which maps the rectangle in Fig. $36$ a onto the upper half-plane.","In the picture below, the symmetry principle was used to show that the rectangle of Figure a is mapped onto Figure b. I did that. Shortly thereafter the function is considered, where is such that . Then, it claims that with this condition on , the function maps Figure a onto the upper half-plane. I can't see why this statement is true. I had some ideas but none with success, if someone could give me a light, I would be grateful. Idea : Since the function is analytical, in particular, continuous, then it maps boundary to boundary, and connected set to connected set. Thus, it is enough to show that the boundary of the interior of the rectangle is mapped to the real axis, but I couldn't do it. The other idea was to remember that, by definition, the function maps the interior of the rectangle with vertices onto the upper half-plane. Thus, if the function is considered, it maps the inside of the rectangle with vertices onto the upper half-plane. My idea was to show that this last rectangle and the rectangle of Figure 36a are the same. I think I should use the condition to conclude this fact but I couldn't do it. Applying the symmetry principle to an inversion of the rectangle in Fig a with respect to its upper side, we find that the function maps the rectangle of Fig. a onto the full -plane which is furnished with a slit as indicated in Fig. b. Consider now the function (where is such that ) which maps the rectangle in Fig. a onto the upper half-plane.","36 36 \mathrm{sn}( \alpha \cdot z) \alpha \mathrm{sn}(\alpha \cdot K) = 1 \alpha \mathrm{sn}(\alpha \cdot z) 36 1 \mathrm{sn}(z) \mathrm{sn}(z) -K, K, K+iK' \hspace{1mm} \mbox{and} \hspace{1mm} -K+iK' \mathrm{sn}(\alpha \cdot z) - \dfrac{K}{\alpha}, \dfrac{K}{\alpha}, \dfrac{K+iK'}{\alpha} \hspace{1mm} \mbox{and} \hspace{1mm} -\dfrac{K+iK'}{\alpha} \mathrm{sn}(\alpha \cdot K) = 1 34 w=\mathrm{sn}(z;q) 36 w 36 \mathrm{sn}(\alpha z) \alpha \mathrm{sn}(\alpha K=1) 36",['complex-analysis']
52,Dirichlet problem in unbounded domain,Dirichlet problem in unbounded domain,,"In bounded domains of $\mathbb{R}^2$ , the Dirichlet problem has a unique solution: the equation $\triangle u=0$ with prescribed boundary value has a unique solution. This is not true if the domain is unbounded. Is there any result for existence and uniqueness for unbounded domains under further assumptions on the domain and the function? If there is a reference where this question is treated it would be of help.","In bounded domains of , the Dirichlet problem has a unique solution: the equation with prescribed boundary value has a unique solution. This is not true if the domain is unbounded. Is there any result for existence and uniqueness for unbounded domains under further assumptions on the domain and the function? If there is a reference where this question is treated it would be of help.",\mathbb{R}^2 \triangle u=0,"['complex-analysis', 'reference-request', 'harmonic-functions', 'elliptic-equations', 'potential-theory']"
53,Laurent expansion of square root,Laurent expansion of square root,,"I have the following two part problem: (a) Prove that $(z^2 - 1)^{-1}$ has an analytic square root in $\mathbb{C} - [-1,1]$ (b) Find the Laurent expansion of an analytic square root from part (a) on a domain $\{a: |z| > 1 \}$ , centered at $z = 0$ . For part (a), I note that the mobius transformation $F(z) = \frac{z-i}{z+i}$ maps the $\mathbb{C} - [-1,1]$ onto $\mathbb{C}-(-\infty,0]$ . Since $\mathbb{C} - (-\infty,0]$ is simply connected and $F$ is nonzero on $\mathbb{C} - [-1,1]$ , we can define a single-valued analytic branch of $\sqrt{F(z)}$ on $\mathbb{C} - [-1,1]$ . Then, by a quick computation $$G(z) = \frac{1}{(z+i)^2\sqrt{F(z)}}$$ is an analytic square root of $(z^2 - 1)^{-1}$ in $\mathbb{C} - [-1,1]$ . However, I do not know how to go about part (b). Any help would be appreciated.","I have the following two part problem: (a) Prove that has an analytic square root in (b) Find the Laurent expansion of an analytic square root from part (a) on a domain , centered at . For part (a), I note that the mobius transformation maps the onto . Since is simply connected and is nonzero on , we can define a single-valued analytic branch of on . Then, by a quick computation is an analytic square root of in . However, I do not know how to go about part (b). Any help would be appreciated.","(z^2 - 1)^{-1} \mathbb{C} - [-1,1] \{a: |z| > 1 \} z = 0 F(z) = \frac{z-i}{z+i} \mathbb{C} - [-1,1] \mathbb{C}-(-\infty,0] \mathbb{C} - (-\infty,0] F \mathbb{C} - [-1,1] \sqrt{F(z)} \mathbb{C} - [-1,1] G(z) = \frac{1}{(z+i)^2\sqrt{F(z)}} (z^2 - 1)^{-1} \mathbb{C} - [-1,1]","['complex-analysis', 'laurent-series', 'analytic-functions', 'branch-cuts']"
54,A growth rate principle for entire functions,A growth rate principle for entire functions,,"Suppose $\widehat{f}(\xi) = O(e^{-a|\xi|^p})$ as $|\xi| \rightarrow \infty$ and $p>1$ . Then, show that $f$ is entire and $$ |f(z)| \leq Be^{a|z|^q}  $$ where $p$ and $q$ are conjugate and $$\widehat{f}(\xi) = \int_{\mathbb{R}} f(x) e^{-2 \pi i x \xi} dx $$ Some background: This is problem 1, Ch.4 in Stein's complex analysis . I came across it after some preliminary reading on uncertainty principles and harmonic analysis. Edit : I originally labelled this post ""An uncertainty type principle for entire functions"". Although it doesn't appear to imply anything about the concentration of a function near a point, there is a similar theme in the sense of establishing a relationship between the growth/decay rates of a (entire) function and its Fourier transform. It should also be mentioned that as $p \rightarrow \infty$ , $\widehat{f}$ becomes compactly supported and this result implies $f$ has growth order $q \rightarrow 1^+$ , which is one direction of the Paley-Weiner theorem. Work thus far : If we define $$f_n(z) = \int_{-n}^n \widehat{f}(\xi) e^{2 \pi i z \xi} d \xi$$ then $f_n$ is holomorphic for all $n$ and the rapid decay rate of $\widehat{f}$ immediately gives us that $f_n(z)$ converges uniformly to $f(z) = \int_{\mathbb{R}} \widehat{f}(\xi)e^{2 \pi i z \xi} d \xi $ , making $f$ entire. Now, \begin{align*} |f(z)| & \leq \left|  \int_{\mathbb{R}} \widehat{f}(\xi) e^{2 \pi i z \xi} d \xi \right| \\ & \leq \int_{\mathbb{R}} A e^{-a|\xi|^p} |e^{2 \pi i z \xi}| d \xi \\ & \leq A \int_{\mathbb{R}} e^{-a|\xi|^p + 2 \pi |z||\xi|} d \xi \\ \end{align*} We may select $N$ large such that $\int_{|\xi| > N} e^{-a|\xi|^p + 2 \pi |z||\xi|} d \xi \leq 1  $ . Then we have $$ |f(z)| \leq A \int_{-N}^N e^{-a|\xi|^p + 2\pi |z||\xi|} d \xi + 1 \leq \tilde{A} \int_{-N}^N e^{|z|^q} d \xi = A' N e^{|z|^q}  $$ where we are using Young's inequality $ |z||\xi| \leq |\xi|^p/p + |z|^q/q \leq |\xi|^p + |z|^q  $ . The constant $\tilde{A} = A' \cdot N$ depends on $N$ (which in turn depends on $z$ ). We should be able to do better and get a global constant independent of $N$ . Edit: per the comment from user @Shalop, we can make use of ""Young's inequality with $\epsilon$ "", which appears in the appendix of Evan's PDE book. For $\epsilon > 0$ given, we may replace $|\xi|$ with $|\xi \epsilon|$ and $|z|$ with $|z/\epsilon|$ to obtain \begin{align*} |\epsilon \xi| |\frac{z}{\epsilon}| \leq \frac{1}{p} \epsilon^p |\xi|^p + \frac{|z|^q}{\epsilon^q q} \leq \epsilon^p |\xi|^p + C(\epsilon) |z|^q \leq \frac{a}{2} |\xi|^p + C(\epsilon) |z|^q  \end{align*} Therefore, \begin{align*} |f(z)| & \leq A \int_{\mathbb{R}} e^{-a|\xi|^p + 2 \pi |z||\xi|} d \xi \\ & \leq A \int_{\mathbb{R}} e^{-a|\xi|^p + \frac{a}{2} |\xi|^p + c|z|^q} d \xi \\ & = A e^{c|z|^q} \int_{\mathbb{R}} e^{-\frac{a}{2}|\xi|^p} d \xi \\ & = B e^{c|z|^q} \\ \end{align*}","Suppose as and . Then, show that is entire and where and are conjugate and Some background: This is problem 1, Ch.4 in Stein's complex analysis . I came across it after some preliminary reading on uncertainty principles and harmonic analysis. Edit : I originally labelled this post ""An uncertainty type principle for entire functions"". Although it doesn't appear to imply anything about the concentration of a function near a point, there is a similar theme in the sense of establishing a relationship between the growth/decay rates of a (entire) function and its Fourier transform. It should also be mentioned that as , becomes compactly supported and this result implies has growth order , which is one direction of the Paley-Weiner theorem. Work thus far : If we define then is holomorphic for all and the rapid decay rate of immediately gives us that converges uniformly to , making entire. Now, We may select large such that . Then we have where we are using Young's inequality . The constant depends on (which in turn depends on ). We should be able to do better and get a global constant independent of . Edit: per the comment from user @Shalop, we can make use of ""Young's inequality with "", which appears in the appendix of Evan's PDE book. For given, we may replace with and with to obtain Therefore,","\widehat{f}(\xi) = O(e^{-a|\xi|^p}) |\xi| \rightarrow \infty p>1 f  |f(z)| \leq Be^{a|z|^q}   p q \widehat{f}(\xi) = \int_{\mathbb{R}} f(x) e^{-2 \pi i x \xi} dx  p \rightarrow \infty \widehat{f} f q \rightarrow 1^+ f_n(z) = \int_{-n}^n \widehat{f}(\xi) e^{2 \pi i z \xi} d \xi f_n n \widehat{f} f_n(z) f(z) = \int_{\mathbb{R}} \widehat{f}(\xi)e^{2 \pi i z \xi} d \xi  f \begin{align*}
|f(z)| & \leq \left|  \int_{\mathbb{R}} \widehat{f}(\xi) e^{2 \pi i z \xi} d \xi \right| \\
& \leq \int_{\mathbb{R}} A e^{-a|\xi|^p} |e^{2 \pi i z \xi}| d \xi \\
& \leq A \int_{\mathbb{R}} e^{-a|\xi|^p + 2 \pi |z||\xi|} d \xi \\
\end{align*} N \int_{|\xi| > N} e^{-a|\xi|^p + 2 \pi |z||\xi|} d \xi \leq 1    |f(z)| \leq A \int_{-N}^N e^{-a|\xi|^p + 2\pi |z||\xi|} d \xi + 1 \leq \tilde{A} \int_{-N}^N e^{|z|^q} d \xi = A' N e^{|z|^q}    |z||\xi| \leq |\xi|^p/p + |z|^q/q \leq |\xi|^p + |z|^q   \tilde{A} = A' \cdot N N z N \epsilon \epsilon > 0 |\xi| |\xi \epsilon| |z| |z/\epsilon| \begin{align*}
|\epsilon \xi| |\frac{z}{\epsilon}| \leq \frac{1}{p} \epsilon^p |\xi|^p + \frac{|z|^q}{\epsilon^q q} \leq \epsilon^p |\xi|^p + C(\epsilon) |z|^q \leq \frac{a}{2} |\xi|^p + C(\epsilon) |z|^q 
\end{align*} \begin{align*}
|f(z)| & \leq A \int_{\mathbb{R}} e^{-a|\xi|^p + 2 \pi |z||\xi|} d \xi \\
& \leq A \int_{\mathbb{R}} e^{-a|\xi|^p + \frac{a}{2} |\xi|^p + c|z|^q} d \xi \\
& = A e^{c|z|^q} \int_{\mathbb{R}} e^{-\frac{a}{2}|\xi|^p} d \xi \\
& = B e^{c|z|^q} \\
\end{align*}","['complex-analysis', 'fourier-analysis']"
55,Positive self dual Fourier eigenfuctions,Positive self dual Fourier eigenfuctions,,"Some of the ""basic"" Fourier eigenfuctions encountered in real and complex analysis are $$ e^{-\pi x^2}, \quad \frac{1}{\cosh{\pi x}} $$ What are some other (smooth) functions fixed under the Fourier transform which have different decay rates than the above two functions? (1) For $f\in{\mathcal{S}(\mathbb{R})}$ , define $$\widehat{f}(\xi) = \int_{\mathbb{R}} f(x) e^{-2 \pi i x \xi} dx $$ Some background: It is possible to generate additional Fourier eigenfuctions by means of various iterative processes. A classical example are the Hermite functions , which may be given by $$h_k(x) = (-1)^k e^{x^2/2} \frac{d^k}{dx^k} \left( e^{-x^2} \right) $$ $h_0(\sqrt{2 \pi} x) = e^{-\pi x^2}$ and it turns out that $H_k(x) = h_k(\sqrt{2 \pi} x) $ are Fourier eigenfuctions with eigenvalue $(-i)^k$ . So, if $\widehat{f} = f$ , then it is possible to write $$ f \sim \sum_m a_{4m}H_{4m} $$ It appears difficult to find the/any correct combination of Hermite functions which create a +1 function satisfying (1). Alternatively, if we set $ \gamma(x) $ equal to $e^{-\pi x^2} $ or $ \mathrm{sech}\pi x$ from above, then for $a > 1$ , the functions $\gamma(x)$ , $a\gamma(ax) + \gamma(x/a) $ , and $a\gamma(ax) + \gamma(x/a) - (1+a)\gamma(x) $ are +1 eigenfunctions due directly to the dilation property $ f(\delta x) \longrightarrow 1/ \delta \widehat{f}(\xi / \delta) $ . The following plot shows these three functions with $ \gamma(x) = \mathrm{sech} \pi x $ and $a=1.5$ . Although $a \gamma(ax) + \gamma(x/a)$ is another eigenfunction, it's not fundamentally different from $\gamma(x)$ . One ""problem"" (at least in my case) with $ a\gamma(ax) + \gamma(x/a) - (1+a)\gamma(x)$ (in green) is that it oscillates. The higher order Hermite functions also oscillate before decaying rapidly. $\mathrm{sech} \pi x$ decays like $e^{-|x|}$ while the Hermite functions, which take the form $e^{-x^2/2} P(x)$ (P a ploynomial) decay like $e^{-|x|^2}$ . I'm wondering if there are other +1 (self-dual) functions which decay at different rates . In a sense, I'm trying to reverse an iteration or generating relation, and one possible avenue may be to consider functions of the form $$ \int_1^\infty (a\gamma(ax) + \gamma(x/a) - (1+a)\gamma(x)) d \sigma (a) $$ where $\sigma$ is a (positive?) measure on $(1,\infty)$ . However, it appears that pinning down any particular such measures which make the integral converge is difficult.","Some of the ""basic"" Fourier eigenfuctions encountered in real and complex analysis are What are some other (smooth) functions fixed under the Fourier transform which have different decay rates than the above two functions? (1) For , define Some background: It is possible to generate additional Fourier eigenfuctions by means of various iterative processes. A classical example are the Hermite functions , which may be given by and it turns out that are Fourier eigenfuctions with eigenvalue . So, if , then it is possible to write It appears difficult to find the/any correct combination of Hermite functions which create a +1 function satisfying (1). Alternatively, if we set equal to or from above, then for , the functions , , and are +1 eigenfunctions due directly to the dilation property . The following plot shows these three functions with and . Although is another eigenfunction, it's not fundamentally different from . One ""problem"" (at least in my case) with (in green) is that it oscillates. The higher order Hermite functions also oscillate before decaying rapidly. decays like while the Hermite functions, which take the form (P a ploynomial) decay like . I'm wondering if there are other +1 (self-dual) functions which decay at different rates . In a sense, I'm trying to reverse an iteration or generating relation, and one possible avenue may be to consider functions of the form where is a (positive?) measure on . However, it appears that pinning down any particular such measures which make the integral converge is difficult."," e^{-\pi x^2}, \quad \frac{1}{\cosh{\pi x}}  f\in{\mathcal{S}(\mathbb{R})} \widehat{f}(\xi) = \int_{\mathbb{R}} f(x) e^{-2 \pi i x \xi} dx  h_k(x) = (-1)^k e^{x^2/2} \frac{d^k}{dx^k} \left( e^{-x^2} \right)  h_0(\sqrt{2 \pi} x) = e^{-\pi x^2} H_k(x) = h_k(\sqrt{2 \pi} x)  (-i)^k \widehat{f} = f  f \sim \sum_m a_{4m}H_{4m}   \gamma(x)  e^{-\pi x^2}   \mathrm{sech}\pi x a > 1 \gamma(x) a\gamma(ax) + \gamma(x/a)  a\gamma(ax) + \gamma(x/a) - (1+a)\gamma(x)   f(\delta x) \longrightarrow 1/ \delta \widehat{f}(\xi / \delta)   \gamma(x) = \mathrm{sech} \pi x  a=1.5 a \gamma(ax) + \gamma(x/a) \gamma(x)  a\gamma(ax) + \gamma(x/a) - (1+a)\gamma(x) \mathrm{sech} \pi x e^{-|x|} e^{-x^2/2} P(x) e^{-|x|^2}  \int_1^\infty (a\gamma(ax) + \gamma(x/a) - (1+a)\gamma(x)) d \sigma (a)  \sigma (1,\infty)","['real-analysis', 'complex-analysis', 'harmonic-analysis']"
56,"Prove that $F^{(n)}(z)=\int_{X}\frac{\partial^n f}{\partial z^n}(x,z)\,\mathrm{d}\mu(x)$",Prove that,"F^{(n)}(z)=\int_{X}\frac{\partial^n f}{\partial z^n}(x,z)\,\mathrm{d}\mu(x)","This is taken from Problem 4.13 by Christian Berg's Complex Analysis . See also post , not a duplicate! I will copy the problem to show the whole context: src) 4.13. (Requires basic measure theory). Let $(X,\mathbb{E},\mu)$ be a measurable space and let $G\subseteq\mathbb{C}$ be open. Assume that $f:X\times G\to\mathbb{C}$ satisfies () $\forall x \in X$ : $f(x,\cdot)\in\mathcal{H}(G)$ . () $\forall z \in G$ : $f(\cdot,z)$ is measurable on $X$ . () There exists a measurable function $g:X\to[0,\infty]$ satisfying $\int g\,\mathrm{d}\mu<\infty$ , such taht $$\left|f(x,z)\right|\leq g(x) \quad\text{for}\quad x\in X, \ z \in G.$$ $\mathbf{1^{\circ}}$ Prove that $\frac{\partial f}{\partial z}(\cdot, z)$ is measurable for each $z \in G$ . $\mathbf{2^{\circ}}$ Assume that $\overline{K(z_0,r)}\subseteq G$ . Prove that $$ \left| \frac{\partial f}{\partial z}(x,z)\right|\leq\frac{4}{r}g(x), \quad z\in K(z_0,r/2), \ x \in X.$$ and that $$\frac{1}{h} (f(x,z_0+h)-f(x,z_0)) = \int_{0}^{1} \frac{\partial f}{\partial z}(x, z_0+th)\,\mathrm{d}t, \quad 0<|h|<r, \ x \in X. $$ $\mathbf{3^{\circ}}$ Prove that $$ F(z) = \int_{X} f(x, z) \, \mathrm{d}\mu(x), \quad z \in G, $$ is holomorphic in $G$ and $$ F'(z) = \int_{X} \frac{\partial f}{\partial x}(x, z) \, \mathrm{d}\mu(x), \quad z \in G.$$ Remark. Notice that () can be replaced by local conditions: For each $a \in G$ there exists a disc $K(a, r)\subseteq G$ and a ""majorant"" $g$ , both depending on $a$ such taht $$\left| f(x, z) \right| \leq g(x) \quad\text{for}\quad x \in X, \ z \in K(a, r).$$ $\color{red}{\blacksquare[}$ Notice also that in this version the results can be applied to $\frac{\partial f}{\partial z}$ , so the final conclusion is that we can differentiate the integral infinitely often by differentiating under the integral sign: $$ F^{(n)}(z) = \int \frac{\partial^n f}{\partial z^n}(x,z) \, \mathrm{d}\mu(x), \quad z \in G, \ n \in \mathbb{N}. \tag*{$\color{red}{]\blacksquare}$} $$ I have solved this problem. The question is right ind the end, see the red part I have marked. I do not know how it is reached? Seems like one should prove it by induction. If I put $$h(x,z):=\frac{\partial f}{\partial z}(x,z) \quad\text{for}\quad (x,z)\in X\times G, $$ then $h$ clearly satisfies the two first points, but I do not know how to prove the last point (iii). Thank you for your time!","This is taken from Problem 4.13 by Christian Berg's Complex Analysis . See also post , not a duplicate! I will copy the problem to show the whole context: src) 4.13. (Requires basic measure theory). Let be a measurable space and let be open. Assume that satisfies () : . () : is measurable on . () There exists a measurable function satisfying , such taht Prove that is measurable for each . Assume that . Prove that and that Prove that is holomorphic in and Remark. Notice that () can be replaced by local conditions: For each there exists a disc and a ""majorant"" , both depending on such taht Notice also that in this version the results can be applied to , so the final conclusion is that we can differentiate the integral infinitely often by differentiating under the integral sign: I have solved this problem. The question is right ind the end, see the red part I have marked. I do not know how it is reached? Seems like one should prove it by induction. If I put then clearly satisfies the two first points, but I do not know how to prove the last point (iii). Thank you for your time!","(X,\mathbb{E},\mu) G\subseteq\mathbb{C} f:X\times G\to\mathbb{C} \forall x \in X f(x,\cdot)\in\mathcal{H}(G) \forall z \in G f(\cdot,z) X g:X\to[0,\infty] \int g\,\mathrm{d}\mu<\infty \left|f(x,z)\right|\leq g(x) \quad\text{for}\quad x\in X, \ z \in G. \mathbf{1^{\circ}} \frac{\partial f}{\partial z}(\cdot, z) z \in G \mathbf{2^{\circ}} \overline{K(z_0,r)}\subseteq G  \left| \frac{\partial f}{\partial z}(x,z)\right|\leq\frac{4}{r}g(x), \quad z\in K(z_0,r/2), \ x \in X. \frac{1}{h} (f(x,z_0+h)-f(x,z_0)) = \int_{0}^{1} \frac{\partial f}{\partial z}(x, z_0+th)\,\mathrm{d}t, \quad 0<|h|<r, \ x \in X.  \mathbf{3^{\circ}}  F(z) = \int_{X} f(x, z) \, \mathrm{d}\mu(x), \quad z \in G,  G  F'(z) = \int_{X} \frac{\partial f}{\partial x}(x, z) \, \mathrm{d}\mu(x), \quad z \in G. a \in G K(a, r)\subseteq G g a \left| f(x, z) \right| \leq g(x) \quad\text{for}\quad x \in X, \ z \in K(a, r). \color{red}{\blacksquare[} \frac{\partial f}{\partial z}  F^{(n)}(z) = \int \frac{\partial^n f}{\partial z^n}(x,z) \, \mathrm{d}\mu(x), \quad z \in G, \ n \in \mathbb{N}. \tag*{\color{red}{]\blacksquare}}  h(x,z):=\frac{\partial f}{\partial z}(x,z) \quad\text{for}\quad (x,z)\in X\times G,  h","['complex-analysis', 'measure-theory', 'proof-explanation', 'lebesgue-integral']"
57,Evaluate $\int_{-\infty}^{\infty} \frac{\sin{\left(t\pi x^2\right)}}{\sinh^2{\left(\pi x\right)}} \; \mathrm{d}x$,Evaluate,\int_{-\infty}^{\infty} \frac{\sin{\left(t\pi x^2\right)}}{\sinh^2{\left(\pi x\right)}} \; \mathrm{d}x,"Evaluate $$\int_{-\infty}^{\infty} \frac{\sin{\left(t\pi x^2\right)}}{\sinh^2{\left(\pi x\right)}} \; \mathrm{d}x$$ I converted $\sinh{(x)}$ to exponential form and considered Imaginary part of the numerator: $$4\Im{\left(\int_{-\infty}^{\infty} \frac{e^{2 \pi x}e^{t\pi x^2}}{{\left(e^{2 \pi x} -1\right)}^2} \; \mathrm{d}x\right)}$$ I think a semi circle contour in upper quadrants would work.  Residues are at $x=k \cdot i, k \in \mathbb{N}$ including $0i$ .  Where I calculated the residues to be $$-\frac{2t}{\pi} \sum_{n=0}^{\infty} ne^{-n^2 \pi i t}$$ I dont know what to do from here (closed form) or maybe my work is wrong?  Ideas or tips please.",Evaluate I converted to exponential form and considered Imaginary part of the numerator: I think a semi circle contour in upper quadrants would work.  Residues are at including .  Where I calculated the residues to be I dont know what to do from here (closed form) or maybe my work is wrong?  Ideas or tips please.,"\int_{-\infty}^{\infty} \frac{\sin{\left(t\pi x^2\right)}}{\sinh^2{\left(\pi x\right)}} \; \mathrm{d}x \sinh{(x)} 4\Im{\left(\int_{-\infty}^{\infty} \frac{e^{2 \pi x}e^{t\pi x^2}}{{\left(e^{2 \pi x} -1\right)}^2} \; \mathrm{d}x\right)} x=k \cdot i, k \in \mathbb{N} 0i -\frac{2t}{\pi} \sum_{n=0}^{\infty} ne^{-n^2 \pi i t}",['integration']
58,"$\int_0^\infty\frac{x^2+3}{x^4+1}\,dx$ via contour integration?",via contour integration?,"\int_0^\infty\frac{x^2+3}{x^4+1}\,dx","I want to calculate $\displaystyle I=\int_0^\infty\frac{x^2+3}{x^4+1}\;dx$ using contour integration. I've obtained the correct answer of $I=\sqrt{2}\pi$ below, but I would appreciate if someone could verify my proof. Let $\displaystyle f(z) = \frac{z^2+3}{z^4+1}$ ; and let $C$ be the semicircle with boundary diameter on the real line (say from $-R$ to $R$ ) in the upper half plane. Now, $f(z)$ has four simple poles at $z = \pm i^{\frac{1}{2}}, \pm i^{\frac{3}{2}}$ . The two poles at $z =  i^{\frac{1}{2}},  i^{\frac{3}{2}}$ lie on the upper half plane, and the sum of the residues of $f$ at these poles is $-\sqrt{2}i$ . So $$\displaystyle \oint_C f(z)\,dz=\int_{-R}^{R} f(z) \, dz +\int_{\text{Arc}} f(z)\, {dz} $$ So by the Residue theorem $$-i\sqrt{2}\cdot 2i\pi=\int_{-R}^{R} f(z) \, dz +\int_{\text{Arc}} f(z)\, {dz} $$ Thus $$2\sqrt{2}\pi=\int_{-R}^{R} f(z) \, dz +\int_{\text{Arc}} f(z)\, {dz} $$ I tried to show that the arc integral goes to $0$ as follows $$\bigg|\int_{\text{Arc}} f(z)\, {dz} \bigg| \le  \int_{\text{Arc}} |f(z)|\, {dz} \le \frac{R^2-3}{R^4-1} \cdot \pi R \to 0,  ~\text{as} ~ R \to \infty $$ Because $|z|^4=\left|z^4\right| = \left|z^4+1-1\right| \le \left|z^4+1\right|+1  $ So $\displaystyle |{z^4+1}| \le |z|^4-1 = R^4-1 $ , similarly $|z|^2 = |z^2+3-3| \le |z^2+3|+3 \implies |z^2+3|\le |z|^2-3 = R^2-3 $ And the length of the arc is $\pi R$ combining altogether we get $$\displaystyle \bigg|\int_{\text{arc}}\frac{z^2+3}{z^4+1} \,d{z}\bigg|  \le \frac{(R^2-3)\cdot \pi R }{R^4-1}$$ Which goes to zero as $R \to \infty$ . So the arc integral goes to $0$ as $R \to 0$ . Therefore $\displaystyle \int_{-\infty}^{\infty} \frac{z^2+3}{z^4+1}\,{dz} = 2\sqrt{2}\pi $ so that $I = \sqrt{2}\pi$ since the integrand is even. Is this correct?","I want to calculate using contour integration. I've obtained the correct answer of below, but I would appreciate if someone could verify my proof. Let ; and let be the semicircle with boundary diameter on the real line (say from to ) in the upper half plane. Now, has four simple poles at . The two poles at lie on the upper half plane, and the sum of the residues of at these poles is . So So by the Residue theorem Thus I tried to show that the arc integral goes to as follows Because So , similarly And the length of the arc is combining altogether we get Which goes to zero as . So the arc integral goes to as . Therefore so that since the integrand is even. Is this correct?","\displaystyle I=\int_0^\infty\frac{x^2+3}{x^4+1}\;dx I=\sqrt{2}\pi \displaystyle f(z) = \frac{z^2+3}{z^4+1} C -R R f(z) z = \pm i^{\frac{1}{2}}, \pm i^{\frac{3}{2}} z =  i^{\frac{1}{2}},  i^{\frac{3}{2}} f -\sqrt{2}i \displaystyle \oint_C f(z)\,dz=\int_{-R}^{R} f(z) \, dz +\int_{\text{Arc}} f(z)\, {dz}  -i\sqrt{2}\cdot 2i\pi=\int_{-R}^{R} f(z) \, dz +\int_{\text{Arc}} f(z)\, {dz}  2\sqrt{2}\pi=\int_{-R}^{R} f(z) \, dz +\int_{\text{Arc}} f(z)\, {dz}  0 \bigg|\int_{\text{Arc}} f(z)\, {dz} \bigg| \le  \int_{\text{Arc}} |f(z)|\, {dz} \le \frac{R^2-3}{R^4-1} \cdot \pi R \to 0,  ~\text{as} ~ R \to \infty  |z|^4=\left|z^4\right| = \left|z^4+1-1\right| \le \left|z^4+1\right|+1   \displaystyle |{z^4+1}| \le |z|^4-1 = R^4-1  |z|^2 = |z^2+3-3| \le |z^2+3|+3 \implies |z^2+3|\le |z|^2-3 = R^2-3  \pi R \displaystyle \bigg|\int_{\text{arc}}\frac{z^2+3}{z^4+1} \,d{z}\bigg|  \le \frac{(R^2-3)\cdot \pi R }{R^4-1} R \to \infty 0 R \to 0 \displaystyle \int_{-\infty}^{\infty} \frac{z^2+3}{z^4+1}\,{dz} = 2\sqrt{2}\pi  I = \sqrt{2}\pi","['complex-analysis', 'definite-integrals', 'solution-verification', 'contour-integration']"
59,Proving $F(z)=\prod _{k=0}^{\infty}\text{sinc} \left(\frac{\pi z}{2 k+1}\right) $ belongs to Schwartz space,Proving  belongs to Schwartz space,F(z)=\prod _{k=0}^{\infty}\text{sinc} \left(\frac{\pi z}{2 k+1}\right) ,Denote $$F(z)=\prod _{k=0}^{\infty}\text{sinc} \left(\frac{\pi z}{2 k+1}\right)=\prod _{n=1}^{\infty } \cos \left(\frac{\pi z}{2 n}\right)$$ How can we prove $F\in S(\mathbb{R})$ (Schwartz space) ? I've already shown that $F(z)$ is entire and rapidly decreasing in strip $|\Im(z)|r$ for $r>0$ . Background: This arises from solving Borwein integrals via Fourier transform.,Denote How can we prove (Schwartz space) ? I've already shown that is entire and rapidly decreasing in strip for . Background: This arises from solving Borwein integrals via Fourier transform.,F(z)=\prod _{k=0}^{\infty}\text{sinc} \left(\frac{\pi z}{2 k+1}\right)=\prod _{n=1}^{\infty } \cos \left(\frac{\pi z}{2 n}\right) F\in S(\mathbb{R}) F(z) |\Im(z)|r r>0,"['complex-analysis', 'fourier-analysis', 'fourier-transform']"
60,Show that polynomial $X^{n+1}-aX^n+aX-1$ has only roots of module $1$,Show that polynomial  has only roots of module,X^{n+1}-aX^n+aX-1 1,"I gave an exercise to a student the other day, thinking I had a simple solution for it, but it seems that my solution was just bullshit (at least, not conclusive). Well, at least, I warned her I wasn't sure of my solution :-) Here it is : $a\in[-1,1]$ , show that all roots of polynomial $P=X^{n+1}-aX^n+aX-1$ have modulus $1$ (I try different ways of expressing the problem, tell me which one is better english...). It is easy to see that roots of $P$ are $1$ , $-1$ for some special cases, and complex not real roots $z_i$ such that $\overline{z_i}$ is also a root, as $P$ is kind of reciprocal, $z$ root implies $\frac1z$ is also a root$. All the other things I tried are not conclusive. For example, $a\in[-1,1]$ may be translated as $a=\cos\theta$ for some $\theta\in\mathbb R$ , but I don't see how to use this. I tried some rewriting, but nothing seems to work. I tried to work on the modulus of a root, tried the relations roots-coefficients... I'm quite stuck here. Could you help me please ? Thanks.","I gave an exercise to a student the other day, thinking I had a simple solution for it, but it seems that my solution was just bullshit (at least, not conclusive). Well, at least, I warned her I wasn't sure of my solution :-) Here it is : , show that all roots of polynomial have modulus (I try different ways of expressing the problem, tell me which one is better english...). It is easy to see that roots of are , for some special cases, and complex not real roots such that is also a root, as is kind of reciprocal, root implies is also a root$. All the other things I tried are not conclusive. For example, may be translated as for some , but I don't see how to use this. I tried some rewriting, but nothing seems to work. I tried to work on the modulus of a root, tried the relations roots-coefficients... I'm quite stuck here. Could you help me please ? Thanks.","a\in[-1,1] P=X^{n+1}-aX^n+aX-1 1 P 1 -1 z_i \overline{z_i} P z \frac1z a\in[-1,1] a=\cos\theta \theta\in\mathbb R","['algebra-precalculus', 'polynomials']"
61,Riemann Surface of $z=\sqrt{w}$,Riemann Surface of,z=\sqrt{w},"Today I started learning about Riemann surfaces. In Gamelin's Complex Analysis , Gamelin states that the Riemann surface of $z=\sqrt{w}$ is ""essentially a sphere with two punctures corresponding to $0$ and $\infty$ ."" How is this true? The surface does not look like a sphere to me.","Today I started learning about Riemann surfaces. In Gamelin's Complex Analysis , Gamelin states that the Riemann surface of is ""essentially a sphere with two punctures corresponding to and ."" How is this true? The surface does not look like a sphere to me.",z=\sqrt{w} 0 \infty,"['complex-analysis', 'riemann-surfaces']"
62,Compute $ \oint_{C_{o}} \frac{1}{\sin \left(\frac{1}{z}\right)} d z-\oint_{C_{i}} \frac{1}{\sin \left(\frac{1}{z}\right)} \mathrm d z $,Compute, \oint_{C_{o}} \frac{1}{\sin \left(\frac{1}{z}\right)} d z-\oint_{C_{i}} \frac{1}{\sin \left(\frac{1}{z}\right)} \mathrm d z ,"Compute the integral $$ \oint_{C_{o}} \frac{1}{\sin \left(\frac{1}{z}\right)} d z-\oint_{C_{i}} \frac{1}{\sin \left(\frac{1}{z}\right)} \mathrm d z $$ where the outer circle, $C_{o},$ is the unit circle and the inner circle, $C_{i},$ is the circle of radius $1 / 10$ centered at the origin. (HINT: What region is enclosed by these two curves?) I've adapted the power series of the given function from the Maclaurin series for the sine: $\left(\frac{1}{x} - \frac{1}{x^3} \frac{1}{3!} + \frac{1}{x^5} \frac{1}{5!} - \right)^{-1}$ . If I were to sketch this region I would find that this is the annular region less than radius R=1 and greater than radius r= $\frac{1}{10}$ , making the region $\frac{1}{10}<|z|<1$ . I believe the outer circle would be the Maclaurin series of the function given $|z|<1$ minus the inner circle which would be a Laurent series since $|z|>\frac{1}{10}$ . Are there any flaws in my thinking of which I should be aware? I feel as if I'm missing a small piece in order to correctly arrange these steps. Clarification: I'm aware I take the residues of each and multiply them by $2\pi i$ . I omitted these steps for clarity.","Compute the integral where the outer circle, is the unit circle and the inner circle, is the circle of radius centered at the origin. (HINT: What region is enclosed by these two curves?) I've adapted the power series of the given function from the Maclaurin series for the sine: . If I were to sketch this region I would find that this is the annular region less than radius R=1 and greater than radius r= , making the region . I believe the outer circle would be the Maclaurin series of the function given minus the inner circle which would be a Laurent series since . Are there any flaws in my thinking of which I should be aware? I feel as if I'm missing a small piece in order to correctly arrange these steps. Clarification: I'm aware I take the residues of each and multiply them by . I omitted these steps for clarity.","
\oint_{C_{o}} \frac{1}{\sin \left(\frac{1}{z}\right)} d z-\oint_{C_{i}} \frac{1}{\sin \left(\frac{1}{z}\right)} \mathrm d z
 C_{o}, C_{i}, 1 / 10 \left(\frac{1}{x} - \frac{1}{x^3} \frac{1}{3!} + \frac{1}{x^5} \frac{1}{5!} - \right)^{-1} \frac{1}{10} \frac{1}{10}<|z|<1 |z|<1 |z|>\frac{1}{10} 2\pi i",['complex-analysis']
63,Growth of holomorphic functions,Growth of holomorphic functions,,"Let $f$ be an entire function and define $$M(r)=\max\limits_{|z|\le r}|f(z)|=\max\limits_{|z|=r}|f(z)|.$$ Similarly, also define $$m_0(r)=\min\limits_{|z|\le r} |f(z)|,\hspace{5mm} m(r)=\min\limits_{|z|=r}|f(z)|.$$ I was thinking about what we can say about the functions $M(r), m_0(r)$ and $m(r)$ as $r\to\infty.$ For example, by the maximum modulus principle, we know that $M(r)$ is actually increasing. Therefore the limit $\lim\limits_{r\to\infty}M(r)$ exists. It is also clear that if $M(r)\to c<\infty$ then (Liouville's theorem) $f$ must be a constant.It follows that $M(r)\to \infty.$ In fact, for polynomials it is each to check that $M(r)\approx r^n$ as $r\to \infty.$ Moreover, if $\frac{M(r)}{r^n}\to c<\infty$ then using Cauchy's estimate we can show that $f$ must be a polynomial. If $f$ is non-polynomial entire function then it is clear that $M(r)/r^n\to \infty$ for every $n\ge 0.$ My question is can we strengthen it furthre? For example can we say that for a non-polynomial entire function $f,$ we must have $M(r)\approx e^{r}$ or $M(r)\geq Ce^{r^{1-\epsilon}}$ for every $\epsilon>0?$ Now coming to $m_0(r)$ and $m(r).$ We note that $m_0(r)$ is decresing and hence the limit exists, but it is not very interesting. If $f$ has any zero in the plane then $m_0(r)=0$ for all $r$ sufficiently large and therefore the limit will be zero. On the other hand, if $f$ does not have any zero and $f$ is non-constant then $f$ must go arbitrary close to $0$ by picard's theorem. It follows that $m_0(r)\to 0.$ In other words, $m_0(r)\to c<\infty,$ and $c\neq 0$ if and only if $f$ is a constant. The most interesting one is $m(r).$ Let us start with a simple case. If $f$ is a polynomial (of degree $n\ge 1$ ) then $m(r)\approx r^n$ for suffiently large $r.$ Therefore, the limit $m(r)\to \infty.$ Moreover, $\frac{m(r)}{r^n}\to c\neq 0.$ If $f$ is not a polynomial and $f$ does not have a zero then it is very similar to $m_0(r)$ and $m(r)\to 0.$ In general, for a non-polynomial entire function $f,$ we know that the infinity is an essential singularity. In particular, there exists a sequence $z_n\to \infty$ such that $|f(z_n)|\to 0.$ This tells us that $m(|z_n|)\to 0.$ In particular, if $\lim m(r)$ exists, then it must be $0.$ But, I am not able to establish the existence of limit of $m(r).$ Does the limit $\lim\limits_{r\to \infty}m(r)$ always exist? Can we make a more refined statement about the behavior of $m(r)?$ For example, if $f$ has $n$ zeroes in the complex plane can we say that $m(r)\to 0$ like $r^{-n}?$ (I am not hoping this statement to be true, it is just for the illustration of the kind of statement I want to make about $m(r).$ )","Let be an entire function and define Similarly, also define I was thinking about what we can say about the functions and as For example, by the maximum modulus principle, we know that is actually increasing. Therefore the limit exists. It is also clear that if then (Liouville's theorem) must be a constant.It follows that In fact, for polynomials it is each to check that as Moreover, if then using Cauchy's estimate we can show that must be a polynomial. If is non-polynomial entire function then it is clear that for every My question is can we strengthen it furthre? For example can we say that for a non-polynomial entire function we must have or for every Now coming to and We note that is decresing and hence the limit exists, but it is not very interesting. If has any zero in the plane then for all sufficiently large and therefore the limit will be zero. On the other hand, if does not have any zero and is non-constant then must go arbitrary close to by picard's theorem. It follows that In other words, and if and only if is a constant. The most interesting one is Let us start with a simple case. If is a polynomial (of degree ) then for suffiently large Therefore, the limit Moreover, If is not a polynomial and does not have a zero then it is very similar to and In general, for a non-polynomial entire function we know that the infinity is an essential singularity. In particular, there exists a sequence such that This tells us that In particular, if exists, then it must be But, I am not able to establish the existence of limit of Does the limit always exist? Can we make a more refined statement about the behavior of For example, if has zeroes in the complex plane can we say that like (I am not hoping this statement to be true, it is just for the illustration of the kind of statement I want to make about )","f M(r)=\max\limits_{|z|\le r}|f(z)|=\max\limits_{|z|=r}|f(z)|. m_0(r)=\min\limits_{|z|\le r} |f(z)|,\hspace{5mm} m(r)=\min\limits_{|z|=r}|f(z)|. M(r), m_0(r) m(r) r\to\infty. M(r) \lim\limits_{r\to\infty}M(r) M(r)\to c<\infty f M(r)\to \infty. M(r)\approx r^n r\to \infty. \frac{M(r)}{r^n}\to c<\infty f f M(r)/r^n\to \infty n\ge 0. f, M(r)\approx e^{r} M(r)\geq Ce^{r^{1-\epsilon}} \epsilon>0? m_0(r) m(r). m_0(r) f m_0(r)=0 r f f f 0 m_0(r)\to 0. m_0(r)\to c<\infty, c\neq 0 f m(r). f n\ge 1 m(r)\approx r^n r. m(r)\to \infty. \frac{m(r)}{r^n}\to c\neq 0. f f m_0(r) m(r)\to 0. f, z_n\to \infty |f(z_n)|\to 0. m(|z_n|)\to 0. \lim m(r) 0. m(r). \lim\limits_{r\to \infty}m(r) m(r)? f n m(r)\to 0 r^{-n}? m(r).","['complex-analysis', 'analysis', 'entire-functions']"
64,Confusion about the proof of Poincar lemma for Currents,Confusion about the proof of Poincar lemma for Currents,,"In Demailly's ""Complex Analytic and Differential Geometry"" page 20 2.D.4, he proves the Poincar lemma for Currents. The theorem states as follows: Let $\Omega\subset\mathbb R^m$ be a starshaped open subset,and $T$ is a closed current of degree $q$ and order $s$ ,then there exists a current $S$ of degree $q-1$ and of order $\leq s$ ,satisfying $dS=T$ on $\Omega$ . The most useful approach to prove this theorem is first show the fact that every closed current is cohomologous to a smooth form. (A) In the proof of (A) ,he claims if $\Theta$ and all its derivatives are currents of order $0$ , then $\Theta$ is smooth. I know currents of order $0$ on manifold can be considered as differential forms with measure coefficients, but how can we get this claim? Any suggestion and references are appreciated, thanks a lot!","In Demailly's ""Complex Analytic and Differential Geometry"" page 20 2.D.4, he proves the Poincar lemma for Currents. The theorem states as follows: Let be a starshaped open subset,and is a closed current of degree and order ,then there exists a current of degree and of order ,satisfying on . The most useful approach to prove this theorem is first show the fact that every closed current is cohomologous to a smooth form. (A) In the proof of (A) ,he claims if and all its derivatives are currents of order , then is smooth. I know currents of order on manifold can be considered as differential forms with measure coefficients, but how can we get this claim? Any suggestion and references are appreciated, thanks a lot!",\Omega\subset\mathbb R^m T q s S q-1 \leq s dS=T \Omega \Theta 0 \Theta 0,"['complex-analysis', 'differential-geometry', 'algebraic-topology', 'complex-geometry', 'geometric-measure-theory']"
65,Find every $z$s that fit $\cos(z) = -2$,Find every s that fit,z \cos(z) = -2,"I couldn't find any, I tried to write $\cos(z)$ as $\cos(x)\cos(iy)-\sin(x)\sin(iy)$ which then gave me $\cos(x)\cosh(y) - i\sin(x)\sinh(y) = -2$ $\sin(x)=0$ so that imaginary part become $0$ now we have to find $\cosh(y) = -2$ which is not true for no $y$ . is it right or i made a mistake in my substitutions?","I couldn't find any, I tried to write as which then gave me so that imaginary part become now we have to find which is not true for no . is it right or i made a mistake in my substitutions?",\cos(z) \cos(x)\cos(iy)-\sin(x)\sin(iy) \cos(x)\cosh(y) - i\sin(x)\sinh(y) = -2 \sin(x)=0 0 \cosh(y) = -2 y,['complex-numbers']
66,ANOVA with complex numbers,ANOVA with complex numbers,,"I want to analyze my data with respect to their within- and between-group variance (an ANOVA analysis). While I am familiar with the typical approach for real numbers, I have in my case complex numbers at hand (coherence values within a signal processing project). Can ANOVA be implemented in the canonical manner for complex numbers? Does the use of the F-statistic requires to transform the terms relevant for an ANOVA to real numbers?","I want to analyze my data with respect to their within- and between-group variance (an ANOVA analysis). While I am familiar with the typical approach for real numbers, I have in my case complex numbers at hand (coherence values within a signal processing project). Can ANOVA be implemented in the canonical manner for complex numbers? Does the use of the F-statistic requires to transform the terms relevant for an ANOVA to real numbers?",,"['complex-analysis', 'analysis', 'statistics']"
67,Existence of four dimensional subspace of $\mathbb{C}^3$,Existence of four dimensional subspace of,\mathbb{C}^3,"Let $f:\mathbb{C}\rightarrow\mathbb{C}^3$ defined by $f=(e^{f_1},-e^{f_1},e^{f_3})$ where $f_1,f_3:\mathbb{C}\rightarrow\mathbb{C}$ are holomorphic. $\DeclareMathOperator{\Span}{Span}$ We identify $\mathbb{C}^3$ to $\mathbb{R}^6$ : ( $z_1,z_2,z_3)=(x_1,y_1,x_2,y_2,x_3,y_3$ ). Let $H_1$ , $H_2$ , $H_3$ and $H_4$ be four hyperplanes in $\mathbb{C}^3$ , defined by; $$\begin{array}{ccc} &H_1=&\Span_\mathbb{R}\big[(1,0,0,0,0,0);(0,1,0,0,0,0)\big],\\ &H_2=&\Span_\mathbb{R}\big[(0,0,1,0,0,0);(0,0,0,1,0,0)\big],\\ &H_3=& \Span_\mathbb{R}\big[(0,0,0,0,1,0);(0,0,0,0,0,1)\big],\\ &H_4=&\Span_\mathbb{R}\big[(1,0,1,0,1,0);(0,1,0,1,0,1)\big].\\ \end{array}$$ $\textbf{Question}$ : Is there a real subspace, H, of real dimension four such that $\Span_{\mathbb{R}}(H_i,H_ j, H^\perp)= \mathbb{R}^6$ for all $i\neq j$ , $~~~~i,j \in \lbrace 1,2,3,4\rbrace,$ and such that $f$ avoid H? I tried the four dimensional subspace : $$\textbf{(H)} \  \left\{\begin{array}{ccllll} X_1-X_2&=&0 & \\  X_1-X_3&=&0&\\ \end{array}\right. $$ $f$ avoid this subspace, but $H^\perp=\Span_\mathbb{R}\big[(-1,0,-1,0,0,0);(-1,0,0,0,-1,0)\big]$ does not satisfies the condition $\Span_\mathbb{R}(H_i,H_j,H^\perp)=\mathbb{R}^6$ for all $j\neq k,~~j,k\in\lbrace 1,...,4\rbrace$ \ I tried also the following four dimensional subspace: $$H=\left\{\begin{array}{cllll} 2y_1+x_2+y_2+y_3&=&0\\ ~~\\  x_1+2x_2+2x_3+y_2&=&0 \\ \end{array}\right.$$ Then $H^\perp=\Span_\mathbb{R}\big[(0,2,1,1,0,1);(1,0,2,1,2,0)\big]$ , which of course satisfies the condition $\Span_\mathbb{R}(H^\perp,H_j,H_k)=\mathbb{R}^6$ for all $j\neq k,~~j,k\in\lbrace 1,...,4\rbrace$ , but $f$ does not avoid This subspace. ask me please for more information.","Let defined by where are holomorphic. We identify to : ( ). Let , , and be four hyperplanes in , defined by; : Is there a real subspace, H, of real dimension four such that for all , and such that avoid H? I tried the four dimensional subspace : avoid this subspace, but does not satisfies the condition for all \ I tried also the following four dimensional subspace: Then , which of course satisfies the condition for all , but does not avoid This subspace. ask me please for more information.","f:\mathbb{C}\rightarrow\mathbb{C}^3 f=(e^{f_1},-e^{f_1},e^{f_3}) f_1,f_3:\mathbb{C}\rightarrow\mathbb{C} \DeclareMathOperator{\Span}{Span} \mathbb{C}^3 \mathbb{R}^6 z_1,z_2,z_3)=(x_1,y_1,x_2,y_2,x_3,y_3 H_1 H_2 H_3 H_4 \mathbb{C}^3 \begin{array}{ccc}
&H_1=&\Span_\mathbb{R}\big[(1,0,0,0,0,0);(0,1,0,0,0,0)\big],\\
&H_2=&\Span_\mathbb{R}\big[(0,0,1,0,0,0);(0,0,0,1,0,0)\big],\\
&H_3=& \Span_\mathbb{R}\big[(0,0,0,0,1,0);(0,0,0,0,0,1)\big],\\
&H_4=&\Span_\mathbb{R}\big[(1,0,1,0,1,0);(0,1,0,1,0,1)\big].\\
\end{array} \textbf{Question} \Span_{\mathbb{R}}(H_i,H_ j, H^\perp)= \mathbb{R}^6 i\neq j ~~~~i,j \in \lbrace 1,2,3,4\rbrace, f \textbf{(H)} \  \left\{\begin{array}{ccllll}
X_1-X_2&=&0 & \\
 X_1-X_3&=&0&\\
\end{array}\right.
 f H^\perp=\Span_\mathbb{R}\big[(-1,0,-1,0,0,0);(-1,0,0,0,-1,0)\big] \Span_\mathbb{R}(H_i,H_j,H^\perp)=\mathbb{R}^6 j\neq k,~~j,k\in\lbrace 1,...,4\rbrace H=\left\{\begin{array}{cllll}
2y_1+x_2+y_2+y_3&=&0\\
~~\\
 x_1+2x_2+2x_3+y_2&=&0 \\
\end{array}\right. H^\perp=\Span_\mathbb{R}\big[(0,2,1,1,0,1);(1,0,2,1,2,0)\big] \Span_\mathbb{R}(H^\perp,H_j,H_k)=\mathbb{R}^6 j\neq k,~~j,k\in\lbrace 1,...,4\rbrace f","['complex-analysis', 'algebraic-geometry', 'complex-geometry']"
68,Proof of the Three Utilities Problem with Complex Analysis?,Proof of the Three Utilities Problem with Complex Analysis?,,"A very famous problem is the following: The Three Utilities Problem. There are three houses and three utilities: You must draw a line from each house to each utility, without the lines ever crossing. Can you connect the houses to the utilities? The answer is no, and this can be proved in several ways. The most popular ones perhaps are using Jordan Curve Theorem or Graph Theory. I found this problem in a list of relatively difficult exercises of Complex Analysis, and I was wondering if anyone can help or provide a reference. I suspect that, if such a solution exists, it should be using index numbers.","A very famous problem is the following: The Three Utilities Problem. There are three houses and three utilities: You must draw a line from each house to each utility, without the lines ever crossing. Can you connect the houses to the utilities? The answer is no, and this can be proved in several ways. The most popular ones perhaps are using Jordan Curve Theorem or Graph Theory. I found this problem in a list of relatively difficult exercises of Complex Analysis, and I was wondering if anyone can help or provide a reference. I suspect that, if such a solution exists, it should be using index numbers.",,"['complex-analysis', 'graph-theory', 'reference-request']"
69,How to guarantee that a certain polynomial has all its zeros in the unit Disk,How to guarantee that a certain polynomial has all its zeros in the unit Disk,,"I am considering two polynomials with real coefficients $P$ and $Q$ such that $\deg P<\deg Q$ and we assume that all the zeros of $Q$ belong to the open unit disk $D(0,1)$ . Let $$\lambda = \inf\left\{\frac{|Q(e^{it})|}{|P(e^{it})|}:t\in\mathbb{R}\right\}>0$$ By Rouchs theorem if $\alpha\in(-\lambda,\lambda)$ and $m$ is a nonnegative integer, then we have $$\forall\,t\in\mathbb{R},\quad |\alpha| |P(e^{it})|<|e^{imt}Q(e^{it})|.$$ Consequently, the polynomial $R_{\alpha,m}\triangleq X^m Q(X)-\alpha P(X)$ has all its zeros in $D(0,1)$ . Now, consider the set $$A_m=\{\alpha\in \mathbb{R}:R_{\alpha,m}\hbox{ has all its zeros in $D(0,1)$}\}$$ We know that $A_m$ contains $(-\lambda,\lambda)$ . But my question is the following: Is $A_m$ an interval for $m\ge m_0$ for some $m_0$ ? (preferably $m_0=0$ .)","I am considering two polynomials with real coefficients and such that and we assume that all the zeros of belong to the open unit disk . Let By Rouchs theorem if and is a nonnegative integer, then we have Consequently, the polynomial has all its zeros in . Now, consider the set We know that contains . But my question is the following: Is an interval for for some ? (preferably .)","P Q \deg P<\deg Q Q D(0,1) \lambda = \inf\left\{\frac{|Q(e^{it})|}{|P(e^{it})|}:t\in\mathbb{R}\right\}>0 \alpha\in(-\lambda,\lambda) m \forall\,t\in\mathbb{R},\quad
|\alpha| |P(e^{it})|<|e^{imt}Q(e^{it})|. R_{\alpha,m}\triangleq X^m Q(X)-\alpha P(X) D(0,1) A_m=\{\alpha\in \mathbb{R}:R_{\alpha,m}\hbox{ has all its zeros in D(0,1)}\} A_m (-\lambda,\lambda) A_m m\ge m_0 m_0 m_0=0","['complex-analysis', 'polynomials']"
70,Expansion of Complex Functions,Expansion of Complex Functions,,"I apologize for my unusual terminology, but my math training in this field is rather lacking, and not entirely in English. Consider the set of complex functions that are holomorphic except for a finite or countably infinite set of isolated singularities (either poles or essential singularities).  I break these functions up into tiers, where the tier can be written in shorthand as a subscript of T followed by the level tier.  Let a ""tier-0"" function be a nonzero constant function.  Let a ""tier-1"" function be any complex function that can be written as $f_{T1}(z)=f_{T0}\prod_i(1-\frac{z}{\sigma_i})^{\mu_i}$ , where $\mu_i$ is the multiplicity of a zero $\sigma_i$ if it is positive, and is the order of a pole $\sigma_i$ if it is negative.  Let a ""tier-2"" function be any complex function that can be written in the form $f_{T2}(z)=f_{T1}e^{\prod_j(1-\frac{z}{\sigma_j})^{\mu_j}}$ .  Let a ""tier-3"" function be any complex function that can be written in the form $f_{T3}(z)=f_{T2}e^{e^{\prod_k(1-\frac{z}{\sigma_k})^{\mu_k}}}$ , and so on for higher tiers. Are the following statements correct: 1) The sum or product of a tier A and a tier B function, where $A>B$ is always going to be a tier A function.  The sum or product of two tier A functions is a tier B function, where $A\geq B$ . 2) The derivative of a tier A function for $A\geq 2$ will always be a tier A function.  The derivative of a tier 1 function can be either a tier 1 or a tier 0 function. 3) The integral of a tier A function for $A\geq 1$ will always be a tier A function. 4) Every complex function that is analytic everywhere except for a finite or countably infinite number of isolated singularities can be expressed as a tier A function for some finite tier A. EDIT: For each of the product notations, if $\sigma_n=0$ , then the term in the product is $\sigma_n^{\mu_n}$","I apologize for my unusual terminology, but my math training in this field is rather lacking, and not entirely in English. Consider the set of complex functions that are holomorphic except for a finite or countably infinite set of isolated singularities (either poles or essential singularities).  I break these functions up into tiers, where the tier can be written in shorthand as a subscript of T followed by the level tier.  Let a ""tier-0"" function be a nonzero constant function.  Let a ""tier-1"" function be any complex function that can be written as , where is the multiplicity of a zero if it is positive, and is the order of a pole if it is negative.  Let a ""tier-2"" function be any complex function that can be written in the form .  Let a ""tier-3"" function be any complex function that can be written in the form , and so on for higher tiers. Are the following statements correct: 1) The sum or product of a tier A and a tier B function, where is always going to be a tier A function.  The sum or product of two tier A functions is a tier B function, where . 2) The derivative of a tier A function for will always be a tier A function.  The derivative of a tier 1 function can be either a tier 1 or a tier 0 function. 3) The integral of a tier A function for will always be a tier A function. 4) Every complex function that is analytic everywhere except for a finite or countably infinite number of isolated singularities can be expressed as a tier A function for some finite tier A. EDIT: For each of the product notations, if , then the term in the product is",f_{T1}(z)=f_{T0}\prod_i(1-\frac{z}{\sigma_i})^{\mu_i} \mu_i \sigma_i \sigma_i f_{T2}(z)=f_{T1}e^{\prod_j(1-\frac{z}{\sigma_j})^{\mu_j}} f_{T3}(z)=f_{T2}e^{e^{\prod_k(1-\frac{z}{\sigma_k})^{\mu_k}}} A>B A\geq B A\geq 2 A\geq 1 \sigma_n=0 \sigma_n^{\mu_n},"['complex-analysis', 'weierstrass-factorization']"
71,Showing the nth roots of unity satisfy two properties,Showing the nth roots of unity satisfy two properties,,"Assuming $_0,_1,...,_n$ are the $n^{th}$ roots of unity, I am asked to show $$(x_0)(x_1)(x_{n1}) =x^n1$$ and $$\sum^{n1}_{a=0}_a= 0$$ I understand that by definition, the $n^{th}$ roots of unity are the roots of the polynomial $x^n-1$ . I'm not sure I know the properties of the roots of unity well enough to even know where to begin. Thank you.","Assuming are the roots of unity, I am asked to show and I understand that by definition, the roots of unity are the roots of the polynomial . I'm not sure I know the properties of the roots of unity well enough to even know where to begin. Thank you.","_0,_1,...,_n n^{th} (x_0)(x_1)(x_{n1}) =x^n1 \sum^{n1}_{a=0}_a= 0 n^{th} x^n-1","['complex-analysis', 'roots-of-unity']"
72,Generalizing the Runge approximation theorem for Riemann Surfaces: approximating by nonvanishing functions,Generalizing the Runge approximation theorem for Riemann Surfaces: approximating by nonvanishing functions,,"The Runge approximation theorem for open Riemann Surfaces says the following. If $X$ is an open Riemann surface and $Y \subset X$ is a Runge subset, i.e., $X \setminus Y$ has no relatively compact connected components, then any holomorphic function on $f:Y \to \mathbb{C}$ can be approximated, uniformly on compact subsets of $Y$ , by holomorphic functions on $X$ . My question is the following. Say $f$ on $Y$ is nonvanishing, i.e., $f:Y \to \mathbb{C}\setminus \{0\}$ . Can $f$ be approximated, uniformly on compact subsets of $Y$ , by nonvanishing holomorphic functions $X \to \mathbb{C}\setminus \{0\}$ ? Obviously this problem is easy if I could lift the function $f$ with respect to the exponential map, but in general we can't do that. We can obviously locally lift, i.e. lift $f$ on neighbourhoods of every point of $Y$ , but I'm not sure how that could be useful. Does anyone have any ideas? Edit: to avoid topological obstructions, we may assume that $f$ can be extended to a continuous nonvanishing function on $X$ .","The Runge approximation theorem for open Riemann Surfaces says the following. If is an open Riemann surface and is a Runge subset, i.e., has no relatively compact connected components, then any holomorphic function on can be approximated, uniformly on compact subsets of , by holomorphic functions on . My question is the following. Say on is nonvanishing, i.e., . Can be approximated, uniformly on compact subsets of , by nonvanishing holomorphic functions ? Obviously this problem is easy if I could lift the function with respect to the exponential map, but in general we can't do that. We can obviously locally lift, i.e. lift on neighbourhoods of every point of , but I'm not sure how that could be useful. Does anyone have any ideas? Edit: to avoid topological obstructions, we may assume that can be extended to a continuous nonvanishing function on .",X Y \subset X X \setminus Y f:Y \to \mathbb{C} Y X f Y f:Y \to \mathbb{C}\setminus \{0\} f Y X \to \mathbb{C}\setminus \{0\} f f Y f X,"['complex-analysis', 'algebraic-topology', 'complex-geometry', 'riemann-surfaces', 'approximation-theory']"
73,On a proof of Cauchy's theorem,On a proof of Cauchy's theorem,,"I am reading various reviews of Ablowitz and Fokas' Complex Variables: Introduction and Applications . In one review , the reviewer wrote that the authors' proof (which will be replicated below) of Cauchy-Goursat theorem is simply wrong. However, to my knowledge, the more or less identical proofs have been used in many books, such as Brown and Churchill's Complex Variables and Applications , 8/e (2004, pp.152-156), Moore and Hadlock's Complex Analysis (1991, p.68), James Kelly's Graduate Mathematical Physics (2006, pp. 29-31) as well as Krishna's Complex Analysis (2010, pp.293-295) written by Vasishtha et al. . Here are my questions: Is the proof really wrong? If this proof is correct, is it a good one? It seems that this proof is fairly shorter than many others (such as Priestley's or Bak and Newman's). Below are the statement and proof of the theorem that appear on pp.105-108 of the second edition of Ablowitz and Fokas' text. (A more detailed proof in the same spirit with very similar wordings can be found in Brown and Churchill's textbook.) Theorem 2.7.1 (Cauchy-Goursat) If a function $f(z)$ is analytic at all points interior to and on a simple closed contour, then $$\oint_C f(z)dz=0.\tag{2.7.1}$$ Proof Consider a finite region $R$ consisting of points on and within a simple closed contour $C$ . We form a square mesh over the region $R$ by drawing lines parallel to the $x$ and $y$ axes such that we have a finite number of square subregions in which each point of $R$ lies in at least one subregion. If a particular square contains points not in $R$ , we delete these points. Such partial squares will occur at the boundary (see Figure 2.7.1). We can refine this mesh by dividing each square in half again and again and redefine partial squares as above. We do this until the length of the diagonal of each square is sufficiently small. We note that the integral around the contour $C$ can be replaced by a sum of integrals around the boundary of each square or partial square $$\oint_C f(z)dz = \sum_{j=1}^n \oint_{C_j} f(z)dz\tag{2.7.2}$$ where it is noted that all interior contours will mutually cancel because each inner side of a square is covered twice in opposite directions. Introduce the following equality: $$f(z)=f(z_j)+(z-z_j)f'(z_j)+(z-z_j)\tilde{f}_j(z)\tag{2.7.3a}$$ where $$\tilde{f}(z)=\left(\frac{f(z)-f(z_j)}{z-z_j}\right)-f'(z_j)\tag{2.7.3b}$$ We remark that $$\oint_{C_j}dz=0, \quad \oint_{C_j}(z-z_j)dz=0\tag{2.7.4}$$ which can be established either by direct integration or from the known anti-derivatives: $$1=\frac{d}{dz}z, \quad (z-z_j)=\frac{d^2}{dz^2}\frac{(z-z_j)^2}{2}, \quad\ldots$$ then using the results of Theorem 2.4.1... (Remark by question asker: theorem 2.4.1 here refers to the contour integral analogue of the fundamental theorem of calculus, i.e. $\int_C f(z)dz = F(z_2)-F(z_1)$ when $F$ is an analytic function with a continuous derivative $f$ in a domain $D$ and $C$ is a contour lying inside $D$ with endpoints $z_1$ and $z_2$ .) ... Then, it follows that \begin{align} \left|\oint_C f(z)dz\right| &\leq \sum_{j=1}^n \left|\oint_{C_j}f(z)dz\right|\\ &= \sum_{j=1}^n \left|\oint_{C_j}(z-z_j)\tilde{f}_j(z)dz\right|\\ &\leq \sum_{j=1}^n \oint_{C_j}|z-z_j|\left|\tilde{f}_j(z)\right|dz\tag{2.7.5} \end{align} It can be established (remark by question asker: see Brown and Churchill for details) the mesh can be refined sufficiently such that $$\left|\tilde{f}_j(z)\right|=\left|\frac{f(z)-f(z_j)}{z-z_j}-f'(z_j)\right|<\epsilon\tag{2.7.6}$$ Calling the area of each square $A_j$ , we observe the geometric fact that $$|z-z_j|\leq\sqrt{2A_j}\tag{2.7.7}$$ Thus, using Theorem 2.4.2 (remark by question asker: i.e. the M-L formula) for all interior squares, we have $$\oint_{C_j}|z-z_j|\left|\tilde{f}_j(z)\right|dz \leq (\sqrt{2A_j})\epsilon(4\sqrt{A_j})=4\sqrt{2}\epsilon A_j\tag{2.7.8}$$ and for all boundary squares, the following upper bound holds: $$\oint_{C_j}|z-z_j|\left|\tilde{f}_j(z)\right|dz \leq (\sqrt{2A_j})\epsilon(4\sqrt{A_j}+L_j)\tag{2.7.9}$$ where $L_j$ is the length of the portion of the contour in the partial square $C_j$ . Then $\oint_C f(z)dz$ is obtained by adding over all such contributions Eqs. $(2.7.8)$ and $(2.7.9)$ . Calling $A=\sum A_j,\ L=\sum L_j$ , quantity $A$ being the area of the square mesh bounded by the contour $C$ and $L$ the length of the contour $C$ , we have $$\oint_C f(z)dz \leq \left(4\sqrt{2}A+\sqrt{2AL}\right)\epsilon\tag{2.7.10}$$ We can refine our mesh indefinitely so as to be able to choose $\epsilon$ as small as we wish. Hence the integral $\oint_C f(z)dz$ must be zero. $\ {}_\blacksquare$","I am reading various reviews of Ablowitz and Fokas' Complex Variables: Introduction and Applications . In one review , the reviewer wrote that the authors' proof (which will be replicated below) of Cauchy-Goursat theorem is simply wrong. However, to my knowledge, the more or less identical proofs have been used in many books, such as Brown and Churchill's Complex Variables and Applications , 8/e (2004, pp.152-156), Moore and Hadlock's Complex Analysis (1991, p.68), James Kelly's Graduate Mathematical Physics (2006, pp. 29-31) as well as Krishna's Complex Analysis (2010, pp.293-295) written by Vasishtha et al. . Here are my questions: Is the proof really wrong? If this proof is correct, is it a good one? It seems that this proof is fairly shorter than many others (such as Priestley's or Bak and Newman's). Below are the statement and proof of the theorem that appear on pp.105-108 of the second edition of Ablowitz and Fokas' text. (A more detailed proof in the same spirit with very similar wordings can be found in Brown and Churchill's textbook.) Theorem 2.7.1 (Cauchy-Goursat) If a function is analytic at all points interior to and on a simple closed contour, then Proof Consider a finite region consisting of points on and within a simple closed contour . We form a square mesh over the region by drawing lines parallel to the and axes such that we have a finite number of square subregions in which each point of lies in at least one subregion. If a particular square contains points not in , we delete these points. Such partial squares will occur at the boundary (see Figure 2.7.1). We can refine this mesh by dividing each square in half again and again and redefine partial squares as above. We do this until the length of the diagonal of each square is sufficiently small. We note that the integral around the contour can be replaced by a sum of integrals around the boundary of each square or partial square where it is noted that all interior contours will mutually cancel because each inner side of a square is covered twice in opposite directions. Introduce the following equality: where We remark that which can be established either by direct integration or from the known anti-derivatives: then using the results of Theorem 2.4.1... (Remark by question asker: theorem 2.4.1 here refers to the contour integral analogue of the fundamental theorem of calculus, i.e. when is an analytic function with a continuous derivative in a domain and is a contour lying inside with endpoints and .) ... Then, it follows that It can be established (remark by question asker: see Brown and Churchill for details) the mesh can be refined sufficiently such that Calling the area of each square , we observe the geometric fact that Thus, using Theorem 2.4.2 (remark by question asker: i.e. the M-L formula) for all interior squares, we have and for all boundary squares, the following upper bound holds: where is the length of the portion of the contour in the partial square . Then is obtained by adding over all such contributions Eqs. and . Calling , quantity being the area of the square mesh bounded by the contour and the length of the contour , we have We can refine our mesh indefinitely so as to be able to choose as small as we wish. Hence the integral must be zero.","f(z) \oint_C f(z)dz=0.\tag{2.7.1} R C R x y R R C \oint_C f(z)dz = \sum_{j=1}^n \oint_{C_j} f(z)dz\tag{2.7.2} f(z)=f(z_j)+(z-z_j)f'(z_j)+(z-z_j)\tilde{f}_j(z)\tag{2.7.3a} \tilde{f}(z)=\left(\frac{f(z)-f(z_j)}{z-z_j}\right)-f'(z_j)\tag{2.7.3b} \oint_{C_j}dz=0, \quad \oint_{C_j}(z-z_j)dz=0\tag{2.7.4} 1=\frac{d}{dz}z, \quad (z-z_j)=\frac{d^2}{dz^2}\frac{(z-z_j)^2}{2}, \quad\ldots \int_C f(z)dz = F(z_2)-F(z_1) F f D C D z_1 z_2 \begin{align}
\left|\oint_C f(z)dz\right|
&\leq \sum_{j=1}^n \left|\oint_{C_j}f(z)dz\right|\\
&= \sum_{j=1}^n \left|\oint_{C_j}(z-z_j)\tilde{f}_j(z)dz\right|\\
&\leq \sum_{j=1}^n \oint_{C_j}|z-z_j|\left|\tilde{f}_j(z)\right|dz\tag{2.7.5}
\end{align} \left|\tilde{f}_j(z)\right|=\left|\frac{f(z)-f(z_j)}{z-z_j}-f'(z_j)\right|<\epsilon\tag{2.7.6} A_j |z-z_j|\leq\sqrt{2A_j}\tag{2.7.7} \oint_{C_j}|z-z_j|\left|\tilde{f}_j(z)\right|dz \leq (\sqrt{2A_j})\epsilon(4\sqrt{A_j})=4\sqrt{2}\epsilon A_j\tag{2.7.8} \oint_{C_j}|z-z_j|\left|\tilde{f}_j(z)\right|dz \leq (\sqrt{2A_j})\epsilon(4\sqrt{A_j}+L_j)\tag{2.7.9} L_j C_j \oint_C f(z)dz (2.7.8) (2.7.9) A=\sum A_j,\ L=\sum L_j A C L C \oint_C f(z)dz \leq \left(4\sqrt{2}A+\sqrt{2AL}\right)\epsilon\tag{2.7.10} \epsilon \oint_C f(z)dz \ {}_\blacksquare","['complex-analysis', 'solution-verification']"
74,Second Kummer Function,Second Kummer Function,,"Background: I am trying to solve the radial Schroedinger equation in the form: \begin{align} \frac{\partial^2 P}{\partial r^2} + 2 \left(E + \frac{Z}{r} - \frac{l(l+1)}{2r^2}\right) P = 0 \end{align} Where $E = \frac{1}{2n^2}$ , $n = 1,2,3, \dotsc$ , $Z=1$ and $l = 0,1,2, \dotsc, n-1$ . In the derivation of the radial equation one finds that the solutions can have the following asymptotic behavior: \begin{align} \lim_{r \rightarrow 0} P(r) &= \begin{cases} r^{-l} \\ r^{l+1} \end{cases} \\ \lim_{r\rightarrow \infty} P(r) &= \begin{cases} e^{\lambda r} \\ e^{-\lambda r} \end{cases}, \lambda = \sqrt{-2E} = \frac{1}{n} \end{align} Question: To find the physical (regular) solution, which is normalizable, one usually proceeds with the ansatz $P(r) = r^{l+1} e^{-\lambda r} F(r)$ , $\lambda = \sqrt{-2E} = \frac{1}{n}$ . This leads to a Kummer differential equation for F(z): \begin{align} &z F''(z) + (c-z)F'(z) - a F(z) = 0\\ &a = (l+1)-n, c = 2(l+1), z=\frac{2}{n} r   \end{align} Solutions to this equation are called confluent hypergeometric functions or Kummer functions of the first M(a,c,z) and second kind U(a,c,z) (which is sometimes also referred to as Tricomi's functions). I am concerned with the irregular solution, which should not be normalizable at it diverges at the origin (and for large r). However, the chosen ansatz leads to negative or zero parameter $a$ . From my understanding, for example the irregular solution corresponding to the 1s-orbital $(n=1, l=0)$ should be expressible as $Q(r) := r  e^{-r}  U(0, 2, 2r)$ . But $U(0, 2, 2r)  = 1$ . Hence, this is not a linearly independent solution to $X(r) = r e^{-r} M(0,2,2r) = r e^{-r}$ . How can one construct the second linear independent solution to this parameters of the Kummer equation? I thought the choice of the ansatz, using the asymptotic behaviour, should be arbitrary (despite a particular choice might be advantageous) as in the end there is a second order ode which has two solutions. Other choices lead to equally problematic (?!) parameters, except the choice $P(r) = r^{l+1} e^{-\lambda r} F(r)$ , for which one gets $a=n+l+1$ , $b=2(l+1)$ and $z = -\frac{2}{n}r$ . For this choice I found a irregular solution, however, the negative argument is kind of problematic. Despite not being implemented in a lot of numerical packages to evaluate the U function, consulting Wolfram Alpha or for example the mpmath package in python the U function is imaginary in the regime of interest (1s: $U(2,2,-2) \approx  -0.3 + i 1.155$ ). I consulted Morse & Feshbach [1] for an expression, but the derivation of a formula for integer $c$ starts with formula (5.3.59) under the restriction $0<\phi<\pi$ which I interpreted as being defined as $z=|z| e^{i\phi}$ and, hence, the exclusion of negative arugments (?!). The formula in the end leads to something similar to DLMF 13.2.9. where I can not find such restrictions. What is the right expression for irregular function U(a,c,z) in this parameter regime of the Kummer equation? Why is it complex for integer a (I suspect the logarithm) and how does it satisfy the Wronskian $PQ' - P' Q = 1$ with this non zero imaginary part (I did a short test and it seemed not to hold, but maybe I was not careful enough)?","Background: I am trying to solve the radial Schroedinger equation in the form: Where , , and . In the derivation of the radial equation one finds that the solutions can have the following asymptotic behavior: Question: To find the physical (regular) solution, which is normalizable, one usually proceeds with the ansatz , . This leads to a Kummer differential equation for F(z): Solutions to this equation are called confluent hypergeometric functions or Kummer functions of the first M(a,c,z) and second kind U(a,c,z) (which is sometimes also referred to as Tricomi's functions). I am concerned with the irregular solution, which should not be normalizable at it diverges at the origin (and for large r). However, the chosen ansatz leads to negative or zero parameter . From my understanding, for example the irregular solution corresponding to the 1s-orbital should be expressible as . But . Hence, this is not a linearly independent solution to . How can one construct the second linear independent solution to this parameters of the Kummer equation? I thought the choice of the ansatz, using the asymptotic behaviour, should be arbitrary (despite a particular choice might be advantageous) as in the end there is a second order ode which has two solutions. Other choices lead to equally problematic (?!) parameters, except the choice , for which one gets , and . For this choice I found a irregular solution, however, the negative argument is kind of problematic. Despite not being implemented in a lot of numerical packages to evaluate the U function, consulting Wolfram Alpha or for example the mpmath package in python the U function is imaginary in the regime of interest (1s: ). I consulted Morse & Feshbach [1] for an expression, but the derivation of a formula for integer starts with formula (5.3.59) under the restriction which I interpreted as being defined as and, hence, the exclusion of negative arugments (?!). The formula in the end leads to something similar to DLMF 13.2.9. where I can not find such restrictions. What is the right expression for irregular function U(a,c,z) in this parameter regime of the Kummer equation? Why is it complex for integer a (I suspect the logarithm) and how does it satisfy the Wronskian with this non zero imaginary part (I did a short test and it seemed not to hold, but maybe I was not careful enough)?","\begin{align}
\frac{\partial^2 P}{\partial r^2} + 2 \left(E + \frac{Z}{r} - \frac{l(l+1)}{2r^2}\right) P = 0
\end{align} E = \frac{1}{2n^2} n = 1,2,3, \dotsc Z=1 l = 0,1,2, \dotsc, n-1 \begin{align}
\lim_{r \rightarrow 0} P(r) &= \begin{cases} r^{-l} \\
r^{l+1}
\end{cases} \\
\lim_{r\rightarrow \infty} P(r) &= \begin{cases} e^{\lambda r} \\
e^{-\lambda r}
\end{cases}, \lambda = \sqrt{-2E} = \frac{1}{n}
\end{align} P(r) = r^{l+1} e^{-\lambda r} F(r) \lambda = \sqrt{-2E} = \frac{1}{n} \begin{align}
&z F''(z) + (c-z)F'(z) - a F(z) = 0\\ &a = (l+1)-n, c = 2(l+1), z=\frac{2}{n} r  
\end{align} a (n=1, l=0) Q(r) := r  e^{-r}  U(0, 2, 2r) U(0, 2, 2r)  = 1 X(r) = r e^{-r} M(0,2,2r) = r e^{-r} P(r) = r^{l+1} e^{-\lambda r} F(r) a=n+l+1 b=2(l+1) z = -\frac{2}{n}r U(2,2,-2) \approx  -0.3 + i 1.155 c 0<\phi<\pi z=|z| e^{i\phi} PQ' - P' Q = 1","['complex-analysis', 'hypergeometric-function', 'wronskian']"
75,I need contacts to help me,I need contacts to help me,,Are there groups maybe here that will read a particular mathematics text at a certain pace and discuss the more difficult pages? I am struggling with Visual Complex Functions - by Wegert. Great if there was people who are reading this or have done that I could turn too for help.,Are there groups maybe here that will read a particular mathematics text at a certain pace and discuss the more difficult pages? I am struggling with Visual Complex Functions - by Wegert. Great if there was people who are reading this or have done that I could turn too for help.,,['complex-analysis']
76,Expansion of the Mittag-Leffler function $E_{s}(x^{s})$,Expansion of the Mittag-Leffler function,E_{s}(x^{s}),"I want to find an expansion of the Mittag-Leffler function $E_{s}(x^{s})$ of the form : $$E_{s}(x^{s})=\sum_{n=0}^{\infty}f_{n}(x)g_{n}(s)\;\;\;\;\;(\Im(x)=\Im(s)=0)$$ I first defind the function $\Omega(x,s)$ : $$\Omega(x,s)=sE_{s}(x^{s})-s-(e^{x}-1)=\sum_{n=1}^{\infty}\frac{x^{ns}}{n\Gamma(ns)}-\frac{x^{n}}{n!}$$ The reason for the introduction of the term $e^{x}-1$ is to extend the domain of convergence of the Laplace transform of $\Omega(x,s)$ , which is given by : $$\int_{0}^{\infty}\Omega(x,s)e^{-zx}dx=\frac{s}{z(z^{s}-1)}-\frac{1}{z(z-1)}$$ Applying the Bromwich inversion formula, we obtain : $$\Omega(x,s)=\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\left[\frac{s}{z(z^{s}-1)}-\frac{1}{z(z-1)} \right ]e^{zx}dz\;\;\;\;(c>0)$$ Making the change of variables $z=e^{y}$ , we obtain : $$\Omega(x,s)=\frac{1}{2\pi i }\int_{\Gamma}\left(\frac{s}{e^{sy}-1}-\frac{1}{e^{y}-1} \right )e^{xe^{y}}dy$$ Where the path $\Gamma$ is the map from $\Re(z)=c\;$ by the log function.  Using the fact that : $$e^{x(e^{y}-1)}=\sum_{n=0}^{\infty}\frac{\phi_{n}(x)}{n!}y^{n}$$ $\phi_{n}(x)$ being the nth order Bell polynomial We obtain : $$\Omega(x,s)=\frac{1}{2\pi i }\sum_{n=0}^{\infty}\frac{e^{x}\phi_{n}(x)}{n!}\int_{\Gamma}\left(\frac{s}{e^{sy}-1}-\frac{1}{e^{y}-1} \right )y^{n}dy $$ Now, i am a bit confused on how to do the integrals above. Any help is highly appreciated.","I want to find an expansion of the Mittag-Leffler function of the form : I first defind the function : The reason for the introduction of the term is to extend the domain of convergence of the Laplace transform of , which is given by : Applying the Bromwich inversion formula, we obtain : Making the change of variables , we obtain : Where the path is the map from by the log function.  Using the fact that : being the nth order Bell polynomial We obtain : Now, i am a bit confused on how to do the integrals above. Any help is highly appreciated.","E_{s}(x^{s}) E_{s}(x^{s})=\sum_{n=0}^{\infty}f_{n}(x)g_{n}(s)\;\;\;\;\;(\Im(x)=\Im(s)=0) \Omega(x,s) \Omega(x,s)=sE_{s}(x^{s})-s-(e^{x}-1)=\sum_{n=1}^{\infty}\frac{x^{ns}}{n\Gamma(ns)}-\frac{x^{n}}{n!} e^{x}-1 \Omega(x,s) \int_{0}^{\infty}\Omega(x,s)e^{-zx}dx=\frac{s}{z(z^{s}-1)}-\frac{1}{z(z-1)} \Omega(x,s)=\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\left[\frac{s}{z(z^{s}-1)}-\frac{1}{z(z-1)}
\right ]e^{zx}dz\;\;\;\;(c>0) z=e^{y} \Omega(x,s)=\frac{1}{2\pi i }\int_{\Gamma}\left(\frac{s}{e^{sy}-1}-\frac{1}{e^{y}-1} \right )e^{xe^{y}}dy \Gamma \Re(z)=c\; e^{x(e^{y}-1)}=\sum_{n=0}^{\infty}\frac{\phi_{n}(x)}{n!}y^{n} \phi_{n}(x) \Omega(x,s)=\frac{1}{2\pi i }\sum_{n=0}^{\infty}\frac{e^{x}\phi_{n}(x)}{n!}\int_{\Gamma}\left(\frac{s}{e^{sy}-1}-\frac{1}{e^{y}-1} \right )y^{n}dy
","['complex-analysis', 'laplace-transform', 'inverse-laplace']"
77,Continuity of a differential of a Banach-valued holomorphic map,Continuity of a differential of a Banach-valued holomorphic map,,"Let $U$ be an open set in $\mathbb{C}^{n}$ let $F$ be a Banach space (in my case even a dual Banach space), and let $\varphi:U\to F$ be a holomorphic map. I seem to be able to prove that the differential map $D\varphi:U\times\mathbb{C}^{n}\to F$ defined by $$D\varphi (z,v)= \lim\limits_{t\to 0}\frac{\varphi(z+tv)-\varphi(z)}{t}$$ is holomorphic. Is there a reference for this assertion? I tried to look into some sources on infinite-dimensional holomorphicity and could not find such a statement, but some of those sources are rather complicated, and so it is likely I missed it.","Let be an open set in let be a Banach space (in my case even a dual Banach space), and let be a holomorphic map. I seem to be able to prove that the differential map defined by is holomorphic. Is there a reference for this assertion? I tried to look into some sources on infinite-dimensional holomorphicity and could not find such a statement, but some of those sources are rather complicated, and so it is likely I missed it.","U \mathbb{C}^{n} F \varphi:U\to F D\varphi:U\times\mathbb{C}^{n}\to F D\varphi (z,v)= \lim\limits_{t\to 0}\frac{\varphi(z+tv)-\varphi(z)}{t}","['complex-analysis', 'reference-request', 'complex-geometry', 'several-complex-variables']"
78,How to show these moments are determined?,How to show these moments are determined?,,"I'm given a sequence of moments $$ S_k=\int_{1}^{\infty}x^k \exp \left(\frac{-x}{\log(x)}\right)dx $$ and I'm told that this sequence is determined. However, I can't find a way to show this. I tried starting out by using Carleman's Condition, i.e. showing that $$\sum_{k=1}^{\infty} \frac{1}{S_{2k}^{1/(2k)}}=\infty.$$ Attempting this method has actually led me to believe the above sum might converge: so I wouldn't be able to use this condition to conclude ""determinance"". In any case, I wish to determine the convergence or divergence of the above series. My attempts to show this is by finding sequences such that $$A_k \leq S_k \leq B_k$$ and finding $f$ and $g$ so that $A_k=\int_{1}^{\infty}x^kfdx$ and $B_k=\int_{1}^{\infty}x^kgdx$ - and $A_k$ and $B_k$ are convergent series for each $k$ . I tried find functions that are either above or below $\frac{-x}{\log(x)}$ to get $f$ and $g$ . What kind of $f$ and/or $g$ could I use here? $\textbf{Edit (3)}:$ Attempt 2 on getting an upper bound is by taking the intervals $\big[ e^i, e^{i+1} \big]$ and having that $$\int_{1}^{\infty}x^k \exp \left(\frac{-x}{\log(x)}\right)dx \leq \sum_{i=0}^{\infty}\exp \left( (i+1)k-\frac{\exp \left( i+1 \right) }{i+1} \right) \left( e^{i+1} - e^{i} \right) \\ = \frac{e-1}{e}\sum_{i=0}^{\infty} \exp \left( (i+1)k-\frac{\exp \left( i+1 \right) }{i+1} +(i+1)\right)$$ Assuming $k \geq 5$ , we have that $$\frac{e^{i+1}}{(i+1)(k+1)} - (i+1) \geq i$$ for every $i \geq k.$ So we can split the sum into $$\sum_{i=0}^{k-1} \exp \left( (i+1)k-\frac{\exp \left( i+1 \right) }{i+1} +(i+1)\right) + \sum_{i=k}^{\infty} \exp \left( -(k+1)\right) ^ {\frac{e^{i+1}}{(i+1)(k+1)} - (i+1)} \\ \leq k * max_{0 \leq i \leq k-1} \exp \left( (i+1)(k+1)-\frac{\exp \left( i+1 \right) }{i+1} \right) + \sum_{i=k}^{\infty} \exp \left( -(k+1)\right)^{i}$$ The right-most sum is geometric and less than 1 for any $k \geq 5$ . One can calculate that the maximum is attained for $i$ such that $\frac{ie^{i+1}}{{(i+1)}^2}=k+1$ . Hence,  the exponent of the maximum becomes $$(i+1)(k+1)-\frac{(i+1)(k+1) }{i} = (i-\frac{1}{i})(k+1)$$ for our given $i$ , and this is $O(k log(k))$ . Hence, our sum overall is $O(k^2k^k)$ , or subsequently $O(k^{2k})$ with plenty of room to spare. Hence by the Stielje's condition for moments on a half-line we have that $S_k$ is determined. Does this look right?","I'm given a sequence of moments and I'm told that this sequence is determined. However, I can't find a way to show this. I tried starting out by using Carleman's Condition, i.e. showing that Attempting this method has actually led me to believe the above sum might converge: so I wouldn't be able to use this condition to conclude ""determinance"". In any case, I wish to determine the convergence or divergence of the above series. My attempts to show this is by finding sequences such that and finding and so that and - and and are convergent series for each . I tried find functions that are either above or below to get and . What kind of and/or could I use here? Attempt 2 on getting an upper bound is by taking the intervals and having that Assuming , we have that for every So we can split the sum into The right-most sum is geometric and less than 1 for any . One can calculate that the maximum is attained for such that . Hence,  the exponent of the maximum becomes for our given , and this is . Hence, our sum overall is , or subsequently with plenty of room to spare. Hence by the Stielje's condition for moments on a half-line we have that is determined. Does this look right?","
S_k=\int_{1}^{\infty}x^k \exp \left(\frac{-x}{\log(x)}\right)dx
 \sum_{k=1}^{\infty} \frac{1}{S_{2k}^{1/(2k)}}=\infty. A_k \leq S_k \leq B_k f g A_k=\int_{1}^{\infty}x^kfdx B_k=\int_{1}^{\infty}x^kgdx A_k B_k k \frac{-x}{\log(x)} f g f g \textbf{Edit (3)}: \big[ e^i, e^{i+1} \big] \int_{1}^{\infty}x^k \exp \left(\frac{-x}{\log(x)}\right)dx \leq \sum_{i=0}^{\infty}\exp \left( (i+1)k-\frac{\exp \left( i+1 \right) }{i+1} \right) \left( e^{i+1} - e^{i} \right) \\ = \frac{e-1}{e}\sum_{i=0}^{\infty} \exp \left( (i+1)k-\frac{\exp \left( i+1 \right) }{i+1} +(i+1)\right) k \geq 5 \frac{e^{i+1}}{(i+1)(k+1)} - (i+1) \geq i i \geq k. \sum_{i=0}^{k-1} \exp \left( (i+1)k-\frac{\exp \left( i+1 \right) }{i+1} +(i+1)\right) + \sum_{i=k}^{\infty} \exp \left( -(k+1)\right) ^ {\frac{e^{i+1}}{(i+1)(k+1)} - (i+1)} \\ \leq k * max_{0 \leq i \leq k-1} \exp \left( (i+1)(k+1)-\frac{\exp \left( i+1 \right) }{i+1} \right) + \sum_{i=k}^{\infty} \exp \left( -(k+1)\right)^{i} k \geq 5 i \frac{ie^{i+1}}{{(i+1)}^2}=k+1 (i+1)(k+1)-\frac{(i+1)(k+1) }{i} = (i-\frac{1}{i})(k+1) i O(k log(k)) O(k^2k^k) O(k^{2k}) S_k","['complex-analysis', 'probability-theory', 'proof-verification', 'improper-integrals', 'moment-problem']"
79,Conformal automorphism of unit disk that interchanges two given points,Conformal automorphism of unit disk that interchanges two given points,,"Let $a$ and $b$ be distinct points in the unit disk $D$ . Show that there exists a conformal automorphism $f$ of $D$ that interchanges $a$ and $b$ ; that is, $f(a) = b$ and $f(b) = a$ . Idea: we know that $g(z)=\frac{\alpha-z}{1-\bar{\alpha}z}$ interchanges $0$ and $\alpha$ and by composition we can find out the map $f(a) = b$ for any $a$ and $b$ in the unit disk $D$ . But how can I get the other way by the same map? Thanks.","Let and be distinct points in the unit disk . Show that there exists a conformal automorphism of that interchanges and ; that is, and . Idea: we know that interchanges and and by composition we can find out the map for any and in the unit disk . But how can I get the other way by the same map? Thanks.",a b D f D a b f(a) = b f(b) = a g(z)=\frac{\alpha-z}{1-\bar{\alpha}z} 0 \alpha f(a) = b a b D,"['complex-analysis', 'conformal-geometry', 'mobius-transformation', 'automorphism-group']"
80,"Complex-analytic argument that $\mathrm{SL}(2,\mathbb R)$ acts isometrically on $\mathbb H^2 \subseteq \mathbb C$",Complex-analytic argument that  acts isometrically on,"\mathrm{SL}(2,\mathbb R) \mathbb H^2 \subseteq \mathbb C","Let $\mathbb H^2 := \left\{ z = x+iy \in \mathbb C : y > 0\right\}$ , equipped with the hyperbolic Riemannian metric $\breve{g} = \frac 1{y^2}\left(dx^2 + dy^2\right)$ . It is a classical result that the group $\mathrm{SL}(2,\mathbb R)$ acts on $\mathbb H^2$ isometrically via $$ \left(\begin{array}{cc} a & b \\ c & d \end{array}\right) \cdot z = \frac{az+b}{cz+d} $$ Denote $\theta_A(z) = A\cdot z$ for $A \in \mathrm{SL}(2,\mathbb R)$ . Then it is straightforward to calculate $$ \frac{d}{dz}\theta_A(z) = \frac 1{(cz+d)^2}.  $$ Problem: Find a complex-analytic proof using $\frac{d}{dz}\theta_A(z)$ to show $\theta_A : \mathbb H^2 \to \mathbb H^2$ is an isometry. I have the following argument in real Cartesian coordinates: $\theta_A$ becomes $\theta_A(x,y) = \big( u(x,y),\: v(x,y)\big)$ , where $$ u(x,y) = \frac{(ax+b)(cx+d)+acy^2}{(cx+d)^2+c^2y^2},\qquad v(x,y) = \frac y{(cx+d)^2+c^2y^2} $$ Since $\theta_A : \mathbb H^2 \to \mathbb H^2$ is a holomorphic function, $u$ and $v$ satisfy the Cauchy-Riemann equations, so the differential of the map $\theta_A : \mathbb H^2 \to \mathbb H^2$ (considering $\mathbb H^2 \subset \mathbb R^2$ ) satisfies: \begin{align*} d(\theta_A)_z &= \left(\begin{array}{cc} u_x & u_y \\ v_x & v_y \end{array}\right) = \left(\begin{array}{cc} v_y & -v_x \\ v_x & v_y \end{array}\right) \\ &= \frac 1{\left((cx+d)^2+c^2y^2\right)^2}\left(\begin{array}{cc} (cx+d)^2-c^2y^2 & 2cy(cx+d) \\ -2cy(cx+d) & (cx+d)^2 - c^2 y^2 \end{array}\right)  \end{align*} Therefore if we let $\left\{ \partial_x, \partial_y\right\}$ denote the standard coordinate frame induced by the identity coordinates $\mathbb H^2 \hookrightarrow \mathbb R^2$ , it's a starightforward calculation to show $$ \theta_A^*\breve g(\partial_x, \partial y) = 0, \qquad \theta_A^* \breve g(\partial_x, \partial_x) = \theta_A^* \breve g(\partial_y, \partial_y) = \frac 1{y^2}, $$ whence it follows that $\theta_A^* \breve{g} = \breve{g}$ , so $\theta_A$ is a Riemannian isometry. However: I'm trying to develop comfort and familiarity with complex one-forms and Riemannian geometry of complex surfaces, so I would like to know what the details would be in order to use $\theta_A'(z) = (cz+d)^{-2}$ to show $\theta_A$ is an isometry, without falling back to Cartesian coordinates. I'd also like to avoid using geodesics if possible, in favor of using complex differential forms and complex coordinate frames (i.e. $\left\{ dz, d\overline z\right\}$ and $\left\{\partial/\partial z, \partial/\partial\overline z\right\}$ respectively). Any insights on what this flavor of argument would look like? EDIT: See comments for a solution.","Let , equipped with the hyperbolic Riemannian metric . It is a classical result that the group acts on isometrically via Denote for . Then it is straightforward to calculate Problem: Find a complex-analytic proof using to show is an isometry. I have the following argument in real Cartesian coordinates: becomes , where Since is a holomorphic function, and satisfy the Cauchy-Riemann equations, so the differential of the map (considering ) satisfies: Therefore if we let denote the standard coordinate frame induced by the identity coordinates , it's a starightforward calculation to show whence it follows that , so is a Riemannian isometry. However: I'm trying to develop comfort and familiarity with complex one-forms and Riemannian geometry of complex surfaces, so I would like to know what the details would be in order to use to show is an isometry, without falling back to Cartesian coordinates. I'd also like to avoid using geodesics if possible, in favor of using complex differential forms and complex coordinate frames (i.e. and respectively). Any insights on what this flavor of argument would look like? EDIT: See comments for a solution.","\mathbb H^2 := \left\{ z = x+iy \in \mathbb C : y > 0\right\} \breve{g} = \frac 1{y^2}\left(dx^2 + dy^2\right) \mathrm{SL}(2,\mathbb R) \mathbb H^2 
\left(\begin{array}{cc}
a & b \\ c & d
\end{array}\right) \cdot z = \frac{az+b}{cz+d}
 \theta_A(z) = A\cdot z A \in \mathrm{SL}(2,\mathbb R) 
\frac{d}{dz}\theta_A(z) = \frac 1{(cz+d)^2}. 
 \frac{d}{dz}\theta_A(z) \theta_A : \mathbb H^2 \to \mathbb H^2 \theta_A \theta_A(x,y) = \big( u(x,y),\: v(x,y)\big) 
u(x,y) = \frac{(ax+b)(cx+d)+acy^2}{(cx+d)^2+c^2y^2},\qquad v(x,y) = \frac y{(cx+d)^2+c^2y^2}
 \theta_A : \mathbb H^2 \to \mathbb H^2 u v \theta_A : \mathbb H^2 \to \mathbb H^2 \mathbb H^2 \subset \mathbb R^2 \begin{align*}
d(\theta_A)_z &= \left(\begin{array}{cc}
u_x & u_y \\ v_x & v_y
\end{array}\right) = \left(\begin{array}{cc}
v_y & -v_x \\ v_x & v_y
\end{array}\right) \\
&= \frac 1{\left((cx+d)^2+c^2y^2\right)^2}\left(\begin{array}{cc}
(cx+d)^2-c^2y^2 & 2cy(cx+d) \\ -2cy(cx+d) & (cx+d)^2 - c^2 y^2
\end{array}\right) 
\end{align*} \left\{ \partial_x, \partial_y\right\} \mathbb H^2 \hookrightarrow \mathbb R^2 
\theta_A^*\breve g(\partial_x, \partial y) = 0, \qquad \theta_A^* \breve g(\partial_x, \partial_x) = \theta_A^* \breve g(\partial_y, \partial_y) = \frac 1{y^2},
 \theta_A^* \breve{g} = \breve{g} \theta_A \theta_A'(z) = (cz+d)^{-2} \theta_A \left\{ dz, d\overline z\right\} \left\{\partial/\partial z, \partial/\partial\overline z\right\}","['complex-analysis', 'differential-geometry', 'lie-groups', 'riemannian-geometry', 'hyperbolic-geometry']"
81,Estimating a nonlinear function,Estimating a nonlinear function,,"Let $F$ be a function in $C(\mathbb{C},\mathbb{C})$ with $F(x)=|x|^\mu x$ , where $\mu>0$ . I can show that that there exists a constant $C$ such that $$ |F(x)-F(y)|\le C(|x|^\mu+|y|^\mu)|x-y| $$ for all $x,y\in\mathbb{C}$ and $\mu>0$ . However, I am wondering if it's also possible to prove something similar for a function $G_j\in C(\mathbb{C}^n, \mathbb{C})$ such that $$ G_j(x_1,\dots,x_n)=\left(\sum_{k=1}^n |x_k|^2\right)^\mu x_j. $$ I would expect to get a similar result, i.e. $$ |G_j(x_1,\dots,x_n)-G_j(y_1,\ldots,y_n)|\le C\left(\sum_{k=1}^n |x_k|^{2\mu}+\sum_{k=1}^n |y_k|^{2\mu}\right)|x_j-y_j| $$ for all $\mu>0$ , $x_1,\ldots,x_n, y_1,\ldots,y_n \in \mathbb{C}$ , and for all $j\in\{1,\ldots,n\}$ . Unfortunately, I wasn't able to show this. What can we say about $|G_j(x_1,\dots,x_n)-G_j(y_1,\ldots,y_n)|$ ?","Let be a function in with , where . I can show that that there exists a constant such that for all and . However, I am wondering if it's also possible to prove something similar for a function such that I would expect to get a similar result, i.e. for all , , and for all . Unfortunately, I wasn't able to show this. What can we say about ?","F C(\mathbb{C},\mathbb{C}) F(x)=|x|^\mu x \mu>0 C 
|F(x)-F(y)|\le C(|x|^\mu+|y|^\mu)|x-y|
 x,y\in\mathbb{C} \mu>0 G_j\in C(\mathbb{C}^n, \mathbb{C}) 
G_j(x_1,\dots,x_n)=\left(\sum_{k=1}^n |x_k|^2\right)^\mu x_j.
 
|G_j(x_1,\dots,x_n)-G_j(y_1,\ldots,y_n)|\le C\left(\sum_{k=1}^n |x_k|^{2\mu}+\sum_{k=1}^n |y_k|^{2\mu}\right)|x_j-y_j|
 \mu>0 x_1,\ldots,x_n, y_1,\ldots,y_n \in \mathbb{C} j\in\{1,\ldots,n\} |G_j(x_1,\dots,x_n)-G_j(y_1,\ldots,y_n)|","['calculus', 'complex-analysis', 'analysis', 'inequality']"
82,Removable singularity in $\phi(\vec{x})=\int \left[\phi\frac{\partial (\ln r)}{\partial n} -\ln(r) \frac{\partial \phi}{\partial n}\right] ds$,Removable singularity in,\phi(\vec{x})=\int \left[\phi\frac{\partial (\ln r)}{\partial n} -\ln(r) \frac{\partial \phi}{\partial n}\right] ds,"If I have the following integral equation $$\phi(\vec{x})=\frac{1}{\pi}\int \left[\phi\frac{\partial (\ln r)}{\partial n} -\ln(r) \frac{\partial \phi}{\partial n}\right] ds$$ An approximate solution of $\phi$ is obtained numerically by dividing the boundary into a finite number of segments ,N. So we can write $$\phi(\vec x_j)=\sum_{i=1}^{N}\left[\phi(\vec x_i)\frac{\partial \ln(r_{ij})}{\partial n} -\ln(r_{ij})\frac{\partial \phi}{\partial n}(\vec x_i)\right]\Delta s_i $$ Where $\Delta s_j$ represents the boundary segment length and $r_{ij}$ is the distance between the $i^{th}$ and the $j^{th}$ segment So it's easy to write $$\frac{\partial \ln(r_{ij})}{\partial n}=\frac{1}{r_{ij}}\left[-\frac{(x_i -x_j)}{r_{ij}}(\frac{\Delta y}{\Delta x})_j +\frac{(y_i -y_j)}{r_{ij}}(\frac{\Delta x}{\Delta y})_j\right]\Delta s_j$$ And $$Z_{ij}=\ln(r_{ij})\Delta s_j$$ Prove that $$\lim_{j \to i} \frac{\partial \ln(r_{ij})}{\partial n}=\left[\frac{(-x_{ss} y_s + x_s y_{ss})_i}{2}\right]\Delta s_i$$ My try $$\lim_{j \to i} \frac{\partial \ln(r_{ij})}{\partial n}=\lim_{h\to 0}\frac{-(x_i -x_{i+h})(y'_{i+h})+(y_i - y_{i+h})(x'_{i+h})}{(x_i -x_{i+h})^2 +(y_i -y_{i+h})^2}$$ Using $$x_{i+h}=x_i +h x'_i +(h^2/2)  x''_i$$ and $$x'_{i+h}=x'_i +hx''_i$$ Hence we get the required result My question How to prove that $$\lim_{j \to i} Z_{ij} = \left[\ln(\frac{\Delta s_i}{2})-1\right]\Delta s_i$$ Thanks in advance .","If I have the following integral equation An approximate solution of is obtained numerically by dividing the boundary into a finite number of segments ,N. So we can write Where represents the boundary segment length and is the distance between the and the segment So it's easy to write And Prove that My try Using and Hence we get the required result My question How to prove that Thanks in advance .",\phi(\vec{x})=\frac{1}{\pi}\int \left[\phi\frac{\partial (\ln r)}{\partial n} -\ln(r) \frac{\partial \phi}{\partial n}\right] ds \phi \phi(\vec x_j)=\sum_{i=1}^{N}\left[\phi(\vec x_i)\frac{\partial \ln(r_{ij})}{\partial n} -\ln(r_{ij})\frac{\partial \phi}{\partial n}(\vec x_i)\right]\Delta s_i  \Delta s_j r_{ij} i^{th} j^{th} \frac{\partial \ln(r_{ij})}{\partial n}=\frac{1}{r_{ij}}\left[-\frac{(x_i -x_j)}{r_{ij}}(\frac{\Delta y}{\Delta x})_j +\frac{(y_i -y_j)}{r_{ij}}(\frac{\Delta x}{\Delta y})_j\right]\Delta s_j Z_{ij}=\ln(r_{ij})\Delta s_j \lim_{j \to i} \frac{\partial \ln(r_{ij})}{\partial n}=\left[\frac{(-x_{ss} y_s + x_s y_{ss})_i}{2}\right]\Delta s_i \lim_{j \to i} \frac{\partial \ln(r_{ij})}{\partial n}=\lim_{h\to 0}\frac{-(x_i -x_{i+h})(y'_{i+h})+(y_i - y_{i+h})(x'_{i+h})}{(x_i -x_{i+h})^2 +(y_i -y_{i+h})^2} x_{i+h}=x_i +h x'_i +(h^2/2)  x''_i x'_{i+h}=x'_i +hx''_i \lim_{j \to i} Z_{ij} = \left[\ln(\frac{\Delta s_i}{2})-1\right]\Delta s_i,"['real-analysis', 'complex-analysis', 'limits', 'numerical-methods', 'approximation']"
83,Convergence of $\sum_{n=1}^\infty \frac{z^n}{2^n(1-z^n)}$,Convergence of,\sum_{n=1}^\infty \frac{z^n}{2^n(1-z^n)},"I'm solving the following problem: Find the maximal open set, $\Omega,$ where the following series converges: $$\sum_{n=1}^\infty \dfrac{z^n}{2^n(1-z^n)}.$$ Extra: Prove that the series define a holomorphic function in $\Omega.$ I conclude that a possible election is $\Omega = \mathbb{C} \setminus \partial \mathbb{D}$ doing the following: Let $z \in \bar{B}(0,r)$ with $r < 1.$ We know that $|z|\leq r.$ Furthermore we have that \begin{align*} |f_n(z)|=\bigg| \frac{z^n}{2^n(1-z^n)} \bigg| &= \frac{|z^n|}{2^n|1-z^n|} \leq \frac{|z^n|}{2^n|1-|z|^n|}\\ &= \frac{|z|^n}{2^n(1-|z|^n)} \leq \frac{r^n}{2^n(1-r^n)} \leq \frac{1}{2^n(1-r^n)} = a_n. \end{align*} The series $\sum_{n=1}^\infty a_n < +\infty$ since $$\lim_{n \rightarrow \infty}   \frac{a_n}{1/2^n} = \lim_{n \rightarrow \infty} \frac{1}{1-r^n} = 1.$$ We conclude that the original series is absolutely convergent. Let $z \in \mathbb{C} \setminus {B}(0,r)$ with $r > 1.$ Hence $r \leq |z|$ and we have that \begin{align*} |f_n(z)|=\bigg| \frac{z^n}{2^n(1-z^n)} \bigg| &= \frac{|z^n|}{2^n|1-z^n|} = \frac{1}{2^n|1/|z^n|-z^n/|z^n||}\\ &\leq \frac{1}{2^n|1-1/|z^n||} = \frac{1}{2^n(1-1/|z^n|)} \leq \frac{1}{2^n(1-1/r^n)} = b_n. \end{align*} As above, comparing with $\sum_{n = 1}^{\infty} 1/2^n$ we conclude the absolute convergence of the original series. The Weierstrass M-criterion gives us the uniform convergence of the series and we conclude that the series define a holomorphic function in $\Omega = \mathbb{C} \setminus \partial\mathbb{D}.$ I can't decide if the series converges for some $z \in \partial \mathbb{D}$ and I hope someone could help me. Thanks everyone!","I'm solving the following problem: Find the maximal open set, where the following series converges: Extra: Prove that the series define a holomorphic function in I conclude that a possible election is doing the following: Let with We know that Furthermore we have that The series since We conclude that the original series is absolutely convergent. Let with Hence and we have that As above, comparing with we conclude the absolute convergence of the original series. The Weierstrass M-criterion gives us the uniform convergence of the series and we conclude that the series define a holomorphic function in I can't decide if the series converges for some and I hope someone could help me. Thanks everyone!","\Omega, \sum_{n=1}^\infty \dfrac{z^n}{2^n(1-z^n)}. \Omega. \Omega = \mathbb{C} \setminus \partial \mathbb{D} z \in \bar{B}(0,r) r < 1. |z|\leq r. \begin{align*}
|f_n(z)|=\bigg| \frac{z^n}{2^n(1-z^n)} \bigg| &= \frac{|z^n|}{2^n|1-z^n|} \leq \frac{|z^n|}{2^n|1-|z|^n|}\\ &= \frac{|z|^n}{2^n(1-|z|^n)} \leq \frac{r^n}{2^n(1-r^n)} \leq \frac{1}{2^n(1-r^n)} = a_n.
\end{align*} \sum_{n=1}^\infty a_n < +\infty \lim_{n \rightarrow \infty} 
 \frac{a_n}{1/2^n} = \lim_{n \rightarrow \infty} \frac{1}{1-r^n} = 1. z \in \mathbb{C} \setminus {B}(0,r) r > 1. r \leq |z| \begin{align*}
|f_n(z)|=\bigg| \frac{z^n}{2^n(1-z^n)} \bigg| &= \frac{|z^n|}{2^n|1-z^n|} = \frac{1}{2^n|1/|z^n|-z^n/|z^n||}\\ &\leq \frac{1}{2^n|1-1/|z^n||} = \frac{1}{2^n(1-1/|z^n|)} \leq \frac{1}{2^n(1-1/r^n)} = b_n.
\end{align*} \sum_{n = 1}^{\infty} 1/2^n \Omega = \mathbb{C} \setminus \partial\mathbb{D}. z \in \partial \mathbb{D}","['sequences-and-series', 'complex-analysis', 'convergence-divergence', 'uniform-convergence']"
84,Multiplication in Deligne cohomology: explicit formula for p = q= 1,Multiplication in Deligne cohomology: explicit formula for p = q= 1,,"In the very beginning of [1] the geometric meaning of Deligne cohomology $H^q(X, \mathbb{Z}(p))_D$ and multiplicative structure on it is being discussed. In particular, it is not hard to see that $H^q(X, \mathbb{Z}(1))$ can be canonically identified with $H^{q-1}(X, \mathcal{O}^{\times}_X)$ . The group $H^2(X, \mathbb{Z}(2))_D$ is identified with the group of holomorphic rank $1$ bundles with holomorphic connection (group structure is given by tensor product) The $\cup$ -multiplication gives us a map $$ H^1(X, \mathbb{Z}(1))_D \otimes H^1(X, \mathbb{Z}(1))_D = H^0(X, \mathcal{O}^{\times}_X) \otimes H^0(X, \mathcal{O}^{\times}_X) \to H^2(X, \mathbb{Z}(2))_D $$ In other words, given two nowhere vanishing holomorphic functions $f$ and $g$ on $X$ we obtain a holomorphic line bundle with holomorphic connection on $X$ . Though in [1] the explicit formula for this in terms of hech cocycles is given, I am looking for another description of the same operation. First of all, observe that each pair of functions $f, g \in H^0(X, \mathcal{O}^{\times}_X)$ define a holomorphic map $F_{f,g} \colon X \to (\mathbb{C}^{\times})^2$ . Following Esnault and Viehweg,  denote the resulting line bundle with holomorphic connection $f \cup g$ by $r(f, g)$ . Then it seems clear from functoriality reasons that $$r(f, g) = F_{f,g}^*r(z,w),$$ where $z$ and $w$ are coordinate functions on $\mathbb{C}^{\times}\times \mathbb{C}^{\times}$ . Thus, I'd be happy to understand, what $r(z, w)$ is. Since $(\mathbb{C}^{\times})^2$ is a product of two Stein manifolds, there are no non-trivial holomorphic line bundles. Therefore, the only ''interesting'' part of $r(z,w)$ is the holomorphic connection. Any holomorphic connection on trivial bundle is given by $\nabla = d + \eta$ , where $\eta$ is a holomorphic $1$ -form. So my questions are: What is this $1$ -form $\eta$ on $\mathbb{C}^{\times} \times \mathbb{C}^{\times}$ ? It seems to me, that $\frac{dz}{z} - \frac{dw}{w}$ would be nice (at least, if this is the case, it satisfies the properties of $r(f, g)$ given in [1]), however I'm not able do deduce this explicitly form Esnault-Viehweg formulas. From my speculations it follows that the underlying line bundle for any $r(f,g)$ is trivial. Is this at least true? If not, than where is my mistake? Thank you for any comments! [1] -- H. Esnault, E. Viehweg. Deligne-Beilinson cohomology. in: Beilinson's Conjectures on Special Values of L-Functions ( Ed.: Rapoport, Schappacher, Schneider ). Perspectives in Math. 4, Academic Press (1988) 43 - 91  ( http://page.mi.fu-berlin.de/esnault/preprints/ec/deligne_beilinson.pdf )","In the very beginning of [1] the geometric meaning of Deligne cohomology and multiplicative structure on it is being discussed. In particular, it is not hard to see that can be canonically identified with . The group is identified with the group of holomorphic rank bundles with holomorphic connection (group structure is given by tensor product) The -multiplication gives us a map In other words, given two nowhere vanishing holomorphic functions and on we obtain a holomorphic line bundle with holomorphic connection on . Though in [1] the explicit formula for this in terms of hech cocycles is given, I am looking for another description of the same operation. First of all, observe that each pair of functions define a holomorphic map . Following Esnault and Viehweg,  denote the resulting line bundle with holomorphic connection by . Then it seems clear from functoriality reasons that where and are coordinate functions on . Thus, I'd be happy to understand, what is. Since is a product of two Stein manifolds, there are no non-trivial holomorphic line bundles. Therefore, the only ''interesting'' part of is the holomorphic connection. Any holomorphic connection on trivial bundle is given by , where is a holomorphic -form. So my questions are: What is this -form on ? It seems to me, that would be nice (at least, if this is the case, it satisfies the properties of given in [1]), however I'm not able do deduce this explicitly form Esnault-Viehweg formulas. From my speculations it follows that the underlying line bundle for any is trivial. Is this at least true? If not, than where is my mistake? Thank you for any comments! [1] -- H. Esnault, E. Viehweg. Deligne-Beilinson cohomology. in: Beilinson's Conjectures on Special Values of L-Functions ( Ed.: Rapoport, Schappacher, Schneider ). Perspectives in Math. 4, Academic Press (1988) 43 - 91  ( http://page.mi.fu-berlin.de/esnault/preprints/ec/deligne_beilinson.pdf )","H^q(X, \mathbb{Z}(p))_D H^q(X, \mathbb{Z}(1)) H^{q-1}(X, \mathcal{O}^{\times}_X) H^2(X, \mathbb{Z}(2))_D 1 \cup 
H^1(X, \mathbb{Z}(1))_D \otimes H^1(X, \mathbb{Z}(1))_D = H^0(X, \mathcal{O}^{\times}_X) \otimes H^0(X, \mathcal{O}^{\times}_X) \to H^2(X, \mathbb{Z}(2))_D
 f g X X f, g \in H^0(X, \mathcal{O}^{\times}_X) F_{f,g} \colon X \to (\mathbb{C}^{\times})^2 f \cup g r(f, g) r(f, g) = F_{f,g}^*r(z,w), z w \mathbb{C}^{\times}\times \mathbb{C}^{\times} r(z, w) (\mathbb{C}^{\times})^2 r(z,w) \nabla = d + \eta \eta 1 1 \eta \mathbb{C}^{\times} \times \mathbb{C}^{\times} \frac{dz}{z} - \frac{dw}{w} r(f, g) r(f,g)","['complex-analysis', 'algebraic-geometry', 'complex-geometry', 'holomorphic-bundles']"
85,Laurent series of $f(z)=\frac{4z-z^2}{(z^2-4)(z+1)}$ in different annulus,Laurent series of  in different annulus,f(z)=\frac{4z-z^2}{(z^2-4)(z+1)},"Given $f(z)=\dfrac{4z-z^2}{(z^2-4)(z+1)}$ I need to find the Laurent series in the annulus: $A_{1,2}(0),\;A_{2,\infty}(0),\;A_{0,1}(-1)$ I found the following partial fractions: $f(z)=\dfrac{-3}{(z+2)}+\dfrac{1}{3(z-2)}+\dfrac{5}{3(z+3)}$ , the power series of these fractions are: $\dfrac{-3}{(z+2)}=\displaystyle{\frac{-3}{2}\sum_{n=0}^\infty \left( \frac{-z}{2} \right)^n} $ $\dfrac{1}{3(z-2)}=\displaystyle{\frac{-1}{6}\sum_{n=0}^\infty \left( \frac{-z}{2} \right)^n} $ $\dfrac{5}{3(z+1)}=\displaystyle{\frac{5}{3}\sum_{n=0}^\infty \left( -z \right)^n} $ and the principle parts are: $\dfrac{-3}{(z+2)}=\displaystyle{\frac{-3}{2}\sum_{n=0}^\infty \left( \frac{1}{-2z} \right)^n} $ $\dfrac{1}{3(z-2)}=\displaystyle{\frac{-1}{6}\sum_{n=0}^\infty \left( \frac{1}{-2z} \right)^n} $ $\dfrac{5}{3(z+1)}=\displaystyle{\frac{5}{3}\sum_{n=0}^\infty \left( \frac{1}{-z} \right)^n} $ In the first annuli I take the principle part only of $\dfrac{5}{3(z+1)}$ , in the second annuli I take the principle part of all fraction. About the third one, I have $0<\vert z-1\vert<1$ , I denoted $w=z-1$ and then I took the power series for all fractions and simply switched the $w$ back to $z-1$ at the end. Is it the right way of doing it? I received $\displaystyle{\frac{-3}{2}\sum_{n=0}^\infty \left( \frac{1-z}{2} \right)^n - \frac{1}{6}\sum_{n=0}^\infty \left( \frac{1-z}{2} \right)^n + \frac{5}{3}\sum_{n=0}^\infty \left( 1-z \right)^n}$","Given I need to find the Laurent series in the annulus: I found the following partial fractions: , the power series of these fractions are: and the principle parts are: In the first annuli I take the principle part only of , in the second annuli I take the principle part of all fraction. About the third one, I have , I denoted and then I took the power series for all fractions and simply switched the back to at the end. Is it the right way of doing it? I received","f(z)=\dfrac{4z-z^2}{(z^2-4)(z+1)} A_{1,2}(0),\;A_{2,\infty}(0),\;A_{0,1}(-1) f(z)=\dfrac{-3}{(z+2)}+\dfrac{1}{3(z-2)}+\dfrac{5}{3(z+3)} \dfrac{-3}{(z+2)}=\displaystyle{\frac{-3}{2}\sum_{n=0}^\infty \left( \frac{-z}{2} \right)^n}  \dfrac{1}{3(z-2)}=\displaystyle{\frac{-1}{6}\sum_{n=0}^\infty \left( \frac{-z}{2} \right)^n}  \dfrac{5}{3(z+1)}=\displaystyle{\frac{5}{3}\sum_{n=0}^\infty \left( -z \right)^n}  \dfrac{-3}{(z+2)}=\displaystyle{\frac{-3}{2}\sum_{n=0}^\infty \left( \frac{1}{-2z} \right)^n}  \dfrac{1}{3(z-2)}=\displaystyle{\frac{-1}{6}\sum_{n=0}^\infty \left( \frac{1}{-2z} \right)^n}  \dfrac{5}{3(z+1)}=\displaystyle{\frac{5}{3}\sum_{n=0}^\infty \left( \frac{1}{-z} \right)^n}  \dfrac{5}{3(z+1)} 0<\vert z-1\vert<1 w=z-1 w z-1 \displaystyle{\frac{-3}{2}\sum_{n=0}^\infty \left( \frac{1-z}{2} \right)^n - \frac{1}{6}\sum_{n=0}^\infty \left( \frac{1-z}{2} \right)^n + \frac{5}{3}\sum_{n=0}^\infty \left( 1-z \right)^n}","['complex-analysis', 'power-series', 'laurent-series']"
86,$\frac{\partial }{\partial z}$ and $\frac{\partial }{\partial \bar z}$: Wirtinger derivative?,and : Wirtinger derivative?,\frac{\partial }{\partial z} \frac{\partial }{\partial \bar z},"I am studying the following notations: $$ \frac{\partial}{\partial z} = \frac{1}{2}\left(\frac{\partial}{\partial x} - i\frac{\partial}{\partial y}\right),\qquad \frac{\partial}{\partial\bar{z}} = \frac{1}{2}\left(\frac{\partial}{\partial x} + i\frac{\partial}{\partial y}\right). \tag{1} $$ It might be obtained if we would use the chain rule (I don't know if it is right). Note that, for $z=x+iy,$ $x=\frac{z+ \bar z}{2}~\hbox{and}~y=\frac{z-\bar z}{2i}=-\frac{i}{2}(z-\bar z).$ Then $$ \frac{\partial x}{\partial z}=\frac{1}{2},~\frac{\partial x}{\partial \bar z}=\frac{1}{2},~\frac{\partial y}{\partial z}=-\frac{i}{2},~\frac{\partial y}{\partial \bar z}=\frac{i}{2}. $$ Let $f(x,y)=u(x,y)+iv(x,y)$ .  Then $\hat f(z,\bar z)=u(x,y)+iv(x,y),$ and \begin{eqnarray*} \frac{\partial \hat f}{\partial z}=\frac{\partial f}{\partial z} &=&\frac{\partial u}{\partial x}\frac{\partial x}{\partial z}+\frac{\partial u}{\partial y}\frac{\partial y}{\partial z}+i\left[\frac{\partial v}{\partial x}\frac{\partial x}{\partial z}+\frac{\partial v}{\partial y}\frac{\partial y}{\partial z}\right] \\ &=& \frac{1}{2}[u_x -i u_y +i(v_x-iv_y)] \\  &=& \frac{1}{2}\left[ u_x+iv_x-i(u_y+iv_y)\right] =\frac{1}{2} (f_x-i f_y), \end{eqnarray*} where $f_x=u_x+iv_x$ and $f_y=u_y+iv_y.$ Similarly, \begin{eqnarray*} \frac{\partial f}{\partial \bar z} &=&\frac{1}{2}(f_x+i f_y) =\frac{1}{2}\left[ u_x-v_y +i(u_y+v_x)\right]. \end{eqnarray*} First Question. Are the above assertions true or just give the intuition for $(1)$ ? Using $(1)$ , it is easy to check that $$ \frac{\partial z}{\partial z} = \frac{\partial \bar{z}}{\partial \bar{z}} = 1,\qquad \frac{\partial \bar{z}}{\partial z} = \frac{\partial z}{\partial \bar{z}} = 0. $$ Second question. I don't know if the following assertions are true: $$ \frac{\partial}{\partial z} f(x,y) = D_{1}\hat f(z, \bar{z}),\qquad \frac{\partial}{\partial \bar{z}} f(x,y) = D_{2}\hat f(z, \bar{z}), $$ If they are true, how to prove them? Is it easy or do I know something more complicated? It seems that this question is related to the first one. May I use the chain rule used above? If so, I can understand all of it. I would be grateful if you give any comments for my questions. Thanks in advance.","I am studying the following notations: It might be obtained if we would use the chain rule (I don't know if it is right). Note that, for Then Let .  Then and where and Similarly, First Question. Are the above assertions true or just give the intuition for ? Using , it is easy to check that Second question. I don't know if the following assertions are true: If they are true, how to prove them? Is it easy or do I know something more complicated? It seems that this question is related to the first one. May I use the chain rule used above? If so, I can understand all of it. I would be grateful if you give any comments for my questions. Thanks in advance.","
\frac{\partial}{\partial z} = \frac{1}{2}\left(\frac{\partial}{\partial x} - i\frac{\partial}{\partial y}\right),\qquad
\frac{\partial}{\partial\bar{z}} = \frac{1}{2}\left(\frac{\partial}{\partial x} + i\frac{\partial}{\partial y}\right).
\tag{1}
 z=x+iy, x=\frac{z+ \bar z}{2}~\hbox{and}~y=\frac{z-\bar z}{2i}=-\frac{i}{2}(z-\bar z). 
\frac{\partial x}{\partial z}=\frac{1}{2},~\frac{\partial x}{\partial \bar z}=\frac{1}{2},~\frac{\partial y}{\partial z}=-\frac{i}{2},~\frac{\partial y}{\partial \bar z}=\frac{i}{2}.
 f(x,y)=u(x,y)+iv(x,y) \hat f(z,\bar z)=u(x,y)+iv(x,y), \begin{eqnarray*}
\frac{\partial \hat f}{\partial z}=\frac{\partial f}{\partial z}
&=&\frac{\partial u}{\partial x}\frac{\partial x}{\partial z}+\frac{\partial u}{\partial y}\frac{\partial y}{\partial z}+i\left[\frac{\partial v}{\partial x}\frac{\partial x}{\partial z}+\frac{\partial v}{\partial y}\frac{\partial y}{\partial z}\right] \\
&=& \frac{1}{2}[u_x -i u_y +i(v_x-iv_y)] \\ 
&=& \frac{1}{2}\left[ u_x+iv_x-i(u_y+iv_y)\right] =\frac{1}{2} (f_x-i f_y),
\end{eqnarray*} f_x=u_x+iv_x f_y=u_y+iv_y. \begin{eqnarray*}
\frac{\partial f}{\partial \bar z}
&=&\frac{1}{2}(f_x+i f_y) =\frac{1}{2}\left[ u_x-v_y +i(u_y+v_x)\right].
\end{eqnarray*} (1) (1) 
\frac{\partial z}{\partial z} = \frac{\partial \bar{z}}{\partial \bar{z}} = 1,\qquad
\frac{\partial \bar{z}}{\partial z} = \frac{\partial z}{\partial \bar{z}} = 0.
 
\frac{\partial}{\partial z} f(x,y) = D_{1}\hat f(z, \bar{z}),\qquad
\frac{\partial}{\partial \bar{z}} f(x,y) = D_{2}\hat f(z, \bar{z}),
",['complex-analysis']
87,Contour integral of square root on its Riemann surface,Contour integral of square root on its Riemann surface,,"Consider a branch of the square root function $f(z)=z^{1/2}, z\in\mathbb{C}$ with $Im \thinspace {f(z)}>=0$ , i.e. $f(re^{i\phi}):=\sqrt{r}e^{i(\phi \thinspace mod  \thinspace 2\pi)/2}.$ The function is not holomorphic at the origin and has a discontinuity on the non-negative real axis. Consequently, the contour integral of the function along the unit circle doesn't vanish.  If we extend the function to it's Riemann surface then we'll get a single-valued continuous function, (informally $F(re^{i\phi})=\sqrt{r}e^{i\phi/2}$ ).  The contour integral along the ""double unit circle"" $z(\phi)=e^{i\phi}, \phi\in{[0,4\pi]}$ on the Riemann surface now vanishes. I suspect this will be true for any other closed curve on the Riemann surface. Is there a way to understand this in context of the residue theorem, suitably generalized to Riemann surfaces? Is it correct to say that the origin has now become an isolated (essential) singularity whose residue is zero and hence the integral of the function along any closed curve on the Riemann surface must always vanish?","Consider a branch of the square root function with , i.e. The function is not holomorphic at the origin and has a discontinuity on the non-negative real axis. Consequently, the contour integral of the function along the unit circle doesn't vanish.  If we extend the function to it's Riemann surface then we'll get a single-valued continuous function, (informally ).  The contour integral along the ""double unit circle"" on the Riemann surface now vanishes. I suspect this will be true for any other closed curve on the Riemann surface. Is there a way to understand this in context of the residue theorem, suitably generalized to Riemann surfaces? Is it correct to say that the origin has now become an isolated (essential) singularity whose residue is zero and hence the integral of the function along any closed curve on the Riemann surface must always vanish?","f(z)=z^{1/2}, z\in\mathbb{C} Im \thinspace {f(z)}>=0 f(re^{i\phi}):=\sqrt{r}e^{i(\phi \thinspace mod  \thinspace 2\pi)/2}. F(re^{i\phi})=\sqrt{r}e^{i\phi/2} z(\phi)=e^{i\phi}, \phi\in{[0,4\pi]}","['complex-analysis', 'residue-calculus', 'riemann-surfaces']"
88,Analyticity of this function $\sqrt{\coth^2(a\ z) + \coth^2(b\ z) - c}$,Analyticity of this function,\sqrt{\coth^2(a\ z) + \coth^2(b\ z) - c},"I want to determine the domain of analyticity of this function: $$f(z) =\sqrt{\coth^2(a\ z) + \coth^2(b\  z) - c}$$ And $$c \in ]0,1]$$ Where $$a,b \in \mathbb{Z} - \mathbb{Z}^+$$ and $a , b$ finite say $a,b \in [-1000 , 0]$ Suppose instead i took that $$f(z)=\sqrt{\coth^2(- \ z) + \coth^2(-3\  z) - 1}$$ Letting $$w={\coth^2(- \ z) + \coth^2(-3\  z) - 1}$$ And finding when $w=0$ is that engough to find the branch points . Is that enugh or we must see how is $Arg({\coth^2(- \ z) + \coth^2(-3\  z) - 1})$ behave ? If so , How can i see that ? Ok , I Don't see where is the problem ? If for example we have $$f(z)=\sqrt{\coth(z)}=\sqrt{\frac{\cosh(z)}{\sinh(z)}}=\sqrt{1+\frac{2}{e^{2z}-1}}$$ We get Roots $$ z= \frac{1}{2} i(2\pi n + \pi) \ \ , z \in \mathbb{Z}$$ Does that mean that we have infinite branch points ? including 0 So Where is the $\sqrt{\coth(z)} $ is Analytic ? Than you !","I want to determine the domain of analyticity of this function: And Where and finite say Suppose instead i took that Letting And finding when is that engough to find the branch points . Is that enugh or we must see how is behave ? If so , How can i see that ? Ok , I Don't see where is the problem ? If for example we have We get Roots Does that mean that we have infinite branch points ? including 0 So Where is the is Analytic ? Than you !","f(z) =\sqrt{\coth^2(a\ z) + \coth^2(b\  z) - c} c \in ]0,1] a,b \in \mathbb{Z} - \mathbb{Z}^+ a , b a,b \in [-1000 , 0] f(z)=\sqrt{\coth^2(- \ z) + \coth^2(-3\  z) - 1} w={\coth^2(- \ z) + \coth^2(-3\  z) - 1} w=0 Arg({\coth^2(- \ z) + \coth^2(-3\  z) - 1}) f(z)=\sqrt{\coth(z)}=\sqrt{\frac{\cosh(z)}{\sinh(z)}}=\sqrt{1+\frac{2}{e^{2z}-1}}  z= \frac{1}{2} i(2\pi n + \pi) \ \ , z \in \mathbb{Z} \sqrt{\coth(z)} ","['real-analysis', 'complex-analysis', 'analytic-functions']"
89,Problem in my Proof (If $\hat{f}=0$ then $f=0$) (pass derivative from integral),Problem in my Proof (If  then ) (pass derivative from integral),\hat{f}=0 f=0,"I need idea about my problem but if you have another type proof please give a hint not a whole solution. Problem : Let $f\in L^{2}[-1,1], \; \hat{f}\in L^{2}(\mathbb{R})$ and $Q_{c}\hat{f}=0.$ i.e. $\int_{-c}^{c}f(x)e^{-2\pi ixt}dx=0.$ Prove that $f=0.$ What I have done: the overall idea is to use Plancherel theorem, i.e. $\Vert f\Vert_{2}=\Vert \hat{f}\Vert_{2}.$ I want to prove that $\hat{f}(t)=0$ for all $t.$ For this, I see that $\vert\hat{f}(t)\vert\leq \int_{-1}^{1}\vert f(x)\vert dx<\infty.$ Now, I want to prove that $\hat{f}(t)$ is analytic so that I can use Liouville theorem and proving that $\hat{f}=0.$ For the analyticity, I see that $e^{2\pi ixt}$ is analytic. But I can't use Leibniz integral rule because of my integrand ( $f(x)e^{-2\pi ixt}$ ) in $\hat{f}$ is not necessarily continuous.","I need idea about my problem but if you have another type proof please give a hint not a whole solution. Problem : Let and i.e. Prove that What I have done: the overall idea is to use Plancherel theorem, i.e. I want to prove that for all For this, I see that Now, I want to prove that is analytic so that I can use Liouville theorem and proving that For the analyticity, I see that is analytic. But I can't use Leibniz integral rule because of my integrand ( ) in is not necessarily continuous.","f\in L^{2}[-1,1], \; \hat{f}\in L^{2}(\mathbb{R}) Q_{c}\hat{f}=0. \int_{-c}^{c}f(x)e^{-2\pi ixt}dx=0. f=0. \Vert f\Vert_{2}=\Vert \hat{f}\Vert_{2}. \hat{f}(t)=0 t. \vert\hat{f}(t)\vert\leq \int_{-1}^{1}\vert f(x)\vert dx<\infty. \hat{f}(t) \hat{f}=0. e^{2\pi ixt} f(x)e^{-2\pi ixt} \hat{f}","['real-analysis', 'complex-analysis', 'analysis', 'fourier-analysis']"
90,Solving a variant of the Poisson Boltzmann equation,Solving a variant of the Poisson Boltzmann equation,,"The following is an equation I've derived in my personal research: $$ \frac{d^2V}{dx^2}=e^{\alpha x} \sinh(V) $$ I'm looking to solve it explicitly for V(x). It's a variant of the Poisson-Boltzmann equation, which has the form $ \frac{d^2V}{dx^2}= \sinh(V) $ , and can be solved by multiplying both sides by $ \frac{dV}{dx} $ and integrating, rearranging and integrating again. I've tried several methods, changes of variables, separation of variables, integration by parts, etc. The best I can do is a change of variable, $ y=e^{\alpha x} $ which yields: $$ \alpha^2(V_{yy} \cdot y +V_v) = \sinh(V)  $$ OR equivalently... $$ \alpha^2 \frac{d}{dy}(yV_y) = \sinh(V)  $$ But again I can't get any further than this. A) Can it be solved explicitly? If so, how? B) Is there a name for this equation so I can find other information on it and it's properties? I have a suspicion that some change to a complex variable and contour integrals might be involved in solving this but I can't be sure since I took a took an introductory complex analysis class almost 10 years ago.","The following is an equation I've derived in my personal research: I'm looking to solve it explicitly for V(x). It's a variant of the Poisson-Boltzmann equation, which has the form , and can be solved by multiplying both sides by and integrating, rearranging and integrating again. I've tried several methods, changes of variables, separation of variables, integration by parts, etc. The best I can do is a change of variable, which yields: OR equivalently... But again I can't get any further than this. A) Can it be solved explicitly? If so, how? B) Is there a name for this equation so I can find other information on it and it's properties? I have a suspicion that some change to a complex variable and contour integrals might be involved in solving this but I can't be sure since I took a took an introductory complex analysis class almost 10 years ago.", \frac{d^2V}{dx^2}=e^{\alpha x} \sinh(V)   \frac{d^2V}{dx^2}= \sinh(V)   \frac{dV}{dx}   y=e^{\alpha x}   \alpha^2(V_{yy} \cdot y +V_v) = \sinh(V)    \alpha^2 \frac{d}{dy}(yV_y) = \sinh(V)  ,"['complex-analysis', 'ordinary-differential-equations', 'poissons-equation']"
91,surjectivity of an operator which is defined on some set of analytic functions,surjectivity of an operator which is defined on some set of analytic functions,,"For a fixed function $h\in H(\mathbb{D})$ and a fixed complex number $$ let $f$ (It is analytic) be a solution of $$(I  C)f = h.$$ Using Taylor expansions, it is easy to see that the operator $(I  C)$ is bijective unless $1/$ is a positive integer and that the range of the operator $((1/n)I  C), n  Z^{+}$ , does not contain the function $zz^n1$ . My question how do you conclude the fact using Taylor expansion??? Sorry $C$ is the Cesaro operator $$Cf (z) = \frac{1}{z}\int_{0}^z\frac{f ()}{1}d.$$","For a fixed function and a fixed complex number let (It is analytic) be a solution of Using Taylor expansions, it is easy to see that the operator is bijective unless is a positive integer and that the range of the operator , does not contain the function . My question how do you conclude the fact using Taylor expansion??? Sorry is the Cesaro operator","h\in H(\mathbb{D})  f (I  C)f = h. (I  C) 1/ ((1/n)I  C), n  Z^{+} zz^n1 C Cf (z) = \frac{1}{z}\int_{0}^z\frac{f ()}{1}d.","['complex-analysis', 'banach-spaces']"
92,Is there a holomorphic function such that $(f(z))^3=z-z^2$,Is there a holomorphic function such that,(f(z))^3=z-z^2,"Is there a holomorphic function $f:C-[0,1]$ such that $(f(z))^3=z-z^2$ for all $z\in C-[0,1]$ My intuition tells me that not really, for instance $$(z-z^2)^{\frac{1}{3}}$$ does not have a unique branch on this set, but I do not know how to formally prove it.","Is there a holomorphic function such that for all My intuition tells me that not really, for instance does not have a unique branch on this set, but I do not know how to formally prove it.","f:C-[0,1] (f(z))^3=z-z^2 z\in C-[0,1] (z-z^2)^{\frac{1}{3}}","['complex-analysis', 'complex-numbers']"
93,What are the minor and major arcs in the Circle method (Hardy & Littlewood)?,What are the minor and major arcs in the Circle method (Hardy & Littlewood)?,,"I was wondering if somebody would be so kind as to graphically show what are the minor and major arcs in the Circle method? In this example , extract below, I've attempted a simple diagram to show what is going on but it is clearly incomplete (I've now edited it to reflect comments). Extract problem: given $k \in \mathbb{N}$ , determine the number of possible representations of n $\in$ N as a sum of exactly $k$ natural numbers. Please correct the diagram below and show the major and minor arcs.","I was wondering if somebody would be so kind as to graphically show what are the minor and major arcs in the Circle method? In this example , extract below, I've attempted a simple diagram to show what is going on but it is clearly incomplete (I've now edited it to reflect comments). Extract problem: given , determine the number of possible representations of n N as a sum of exactly natural numbers. Please correct the diagram below and show the major and minor arcs.",k \in \mathbb{N} \in k,"['complex-analysis', 'number-theory', 'analytic-number-theory']"
94,Elliptic function with essential singularity,Elliptic function with essential singularity,,"The Jacobi theta function, $\theta(u;\tau)$ (in some convention which will be implicit below), has the following elliptic transformation behavior: $$ \theta(u+ m + n \tau;\tau) = (-1)^{m+n} e^{2 \pi i (-n u - \frac{1}{2} n^2 \tau)} \theta(u,\tau) $$ In particular, this means that $\log \theta(u;\tau)$ picks up a linear shift under such a transformation.  Then if we take two derivatives with respect to $u$ , $(\log \theta(u;\tau))''$ , this kills this linear piece and we find an elliptic function with a double pole at $u=0$ , which is precisely the Weierstrass p-function.  On the other hand, if we take a single derivative, $(\log \theta(u;\tau))' = \theta'(u;\tau)/\theta(u;\tau)$ , we get a function  with a single simple pole at $u=0$ , but this can still pick up shifts by integer multiples of $2 \pi i$ under elliptic transformations.  Then it is natural to consider the exponential: $$ f(u) = \exp \bigg(\frac{\theta'(u;\tau)}{\theta(u;\tau)} \bigg) $$ Then $f(u)$ is an elliptic  function with an essential singularity at $u=0$ .  I was wondering if this function (or its log) has any special name or significance in the study of elliptic functions.","The Jacobi theta function, (in some convention which will be implicit below), has the following elliptic transformation behavior: In particular, this means that picks up a linear shift under such a transformation.  Then if we take two derivatives with respect to , , this kills this linear piece and we find an elliptic function with a double pole at , which is precisely the Weierstrass p-function.  On the other hand, if we take a single derivative, , we get a function  with a single simple pole at , but this can still pick up shifts by integer multiples of under elliptic transformations.  Then it is natural to consider the exponential: Then is an elliptic  function with an essential singularity at .  I was wondering if this function (or its log) has any special name or significance in the study of elliptic functions.","\theta(u;\tau)  \theta(u+ m + n \tau;\tau) = (-1)^{m+n} e^{2 \pi i (-n u - \frac{1}{2} n^2 \tau)} \theta(u,\tau)  \log \theta(u;\tau) u (\log \theta(u;\tau))'' u=0 (\log \theta(u;\tau))' = \theta'(u;\tau)/\theta(u;\tau) u=0 2 \pi i  f(u) = \exp \bigg(\frac{\theta'(u;\tau)}{\theta(u;\tau)} \bigg)  f(u) u=0",['complex-analysis']
95,Difference between germs of holomorphic functions and the functions themselves?,Difference between germs of holomorphic functions and the functions themselves?,,"I'm learning about the space of germs of holomorphic functions. As far as I understand we define the space $\mathcal{O}_x$ to be the set of ""germs"" i.e. equivalence classes of functions that coincide on a certian neighbourhood of the point $x$ . I haven't seen this addressed anywhere so this may be a silly question, but doesn't the identity principle imply that each such germ contains only one function, in any meaningful way? I suppose you could of course define two functions $f$ , $g$ so that they are both the same but one has a smaller domain, or they have disconnected domains and differ on some different components. So i suppose my question is this: It seems like the identity principle implies that two holomorphic functions have the same germ only if they are ""essentially the same"", i.e. can be extended to the same function on some connected domain? Am I wrong in saying this? And if not, doesnt this make the distinction between holomorphic germs and functions a bit pointless, since each of these equivalence classes would only really contain one function?","I'm learning about the space of germs of holomorphic functions. As far as I understand we define the space to be the set of ""germs"" i.e. equivalence classes of functions that coincide on a certian neighbourhood of the point . I haven't seen this addressed anywhere so this may be a silly question, but doesn't the identity principle imply that each such germ contains only one function, in any meaningful way? I suppose you could of course define two functions , so that they are both the same but one has a smaller domain, or they have disconnected domains and differ on some different components. So i suppose my question is this: It seems like the identity principle implies that two holomorphic functions have the same germ only if they are ""essentially the same"", i.e. can be extended to the same function on some connected domain? Am I wrong in saying this? And if not, doesnt this make the distinction between holomorphic germs and functions a bit pointless, since each of these equivalence classes would only really contain one function?",\mathcal{O}_x x f g,"['complex-analysis', 'germs']"
96,Equation in integral form,Equation in integral form,,"I've been working with this equation where the unknown factor is the function $f$ that can be complex: $$1 = f(\vec{x})\int_{\mathbb{R}^3}\ d^3y\ \frac{f(\vec{y})}{|\vec{x} - \vec{y}|^4}$$ Is there any way to solve this equation without using the trial-error method, i.e., without testing different forms for $f$ ? Anyway, can you see any solution? Thanks in advance!","I've been working with this equation where the unknown factor is the function that can be complex: Is there any way to solve this equation without using the trial-error method, i.e., without testing different forms for ? Anyway, can you see any solution? Thanks in advance!",f 1 = f(\vec{x})\int_{\mathbb{R}^3}\ d^3y\ \frac{f(\vec{y})}{|\vec{x} - \vec{y}|^4} f,"['calculus', 'integration', 'complex-analysis', 'multivariable-calculus', 'indefinite-integrals']"
97,Simple question on power series,Simple question on power series,,"Suppose $\{a_n\}$ is a sequence of complex numbers such that $a_n$ is of unit length if it is not equal to $0$ . Can we conclude that, $F(z) = \sum_{n=0}^\infty a_n z^n$ has continuous extension on an open arc of the unit circle if and only if $F(z)$ has analytic continuation across this open arc?","Suppose is a sequence of complex numbers such that is of unit length if it is not equal to . Can we conclude that, has continuous extension on an open arc of the unit circle if and only if has analytic continuation across this open arc?",\{a_n\} a_n 0 F(z) = \sum_{n=0}^\infty a_n z^n F(z),"['sequences-and-series', 'complex-analysis']"
98,Complex analysis integral of the normal distribution,Complex analysis integral of the normal distribution,,"I am looking at the expectation of a normal distribution with respect to a function of $x$ . To simplify the problem, I considered the following integral: \begin{equation} \int_{-\infty}^\infty \frac{e^{-x^2}}{1+ae^{-x}} \ dx. \end{equation} To solve this, I considered the complex integral: \begin{equation} \oint_C \frac{e^{-z^2}}{1+ae^{-z}} \ dz, \end{equation} with the contour $C = C_1 + C_R$ where $C_1: z = x$ with $x \in [-R,R]$ and $C_R: z = R e^{i \theta}$ , with $\theta \in [0,\pi]$ . First I considered the $C_R$ part: \begin{align} \int_0^\pi \frac{e^{-R^2 e^{2i \theta}}}{1 + a e^{-R e^{i \theta}}} i R e^{i \theta} d \theta \end{align} The standard argument here is to consider $R \to \infty$ and show that this integral hopefully decays to 0. However, $e^{-R^2 e^{2i \theta}}$ changes to positive at $\pi/2$ and so this integral actually grows. If instead, I consider the rectangular contour with $C_1: z = x$ as before, $C_2: z = R + iy$ , with $y \in [0,2\pi]$ , $C_3: z = x + i(2\pi)$ and $C_4: z = -R + iy$ , we can show that the integrals $C_2$ and $C_4$ decay to zero \begin{align} \int_0^{2\pi} \frac{e^{-(R+iy)^2}}{1+ae^{-(R+iy)}} i \ dy \stackrel{R \to \infty}{\to} 0. \end{align} Hence we are left with the pole at $z_0 = \ln a + i\pi$ which can be computed from Cauchy's integral formula $$\oint \frac{f(z) \ dz}{g(z)(z-z_0)} = 2\pi i \frac{f(z_0)}{g'(z_0)} = 2\pi i e^{-z_0^2}$$ . The $C_1$ integral is the original integral. However the third integral is slightly different. Is there anyway to proceed here, or does someone have another way to evaluate this integral analytically? $$\int_{C_3} = e^{4 \pi^2} \int_R^{-R} \frac{e^{-x^2}e^{-4 \pi i x}}{1 + a e^{-x}} \ dx = -e^{4 \pi^2} \int_{-R}^{R} \frac{e^{-x^2}e^{-4 \pi i x}}{1 + a e^{-x}} \ dx $$","I am looking at the expectation of a normal distribution with respect to a function of . To simplify the problem, I considered the following integral: To solve this, I considered the complex integral: with the contour where with and , with . First I considered the part: The standard argument here is to consider and show that this integral hopefully decays to 0. However, changes to positive at and so this integral actually grows. If instead, I consider the rectangular contour with as before, , with , and , we can show that the integrals and decay to zero Hence we are left with the pole at which can be computed from Cauchy's integral formula . The integral is the original integral. However the third integral is slightly different. Is there anyway to proceed here, or does someone have another way to evaluate this integral analytically?","x \begin{equation}
\int_{-\infty}^\infty \frac{e^{-x^2}}{1+ae^{-x}} \ dx.
\end{equation} \begin{equation}
\oint_C \frac{e^{-z^2}}{1+ae^{-z}} \ dz,
\end{equation} C = C_1 + C_R C_1: z = x x \in [-R,R] C_R: z = R e^{i \theta} \theta \in [0,\pi] C_R \begin{align}
\int_0^\pi \frac{e^{-R^2 e^{2i \theta}}}{1 + a e^{-R e^{i \theta}}} i R e^{i \theta} d \theta
\end{align} R \to \infty e^{-R^2 e^{2i \theta}} \pi/2 C_1: z = x C_2: z = R + iy y \in [0,2\pi] C_3: z = x + i(2\pi) C_4: z = -R + iy C_2 C_4 \begin{align}
\int_0^{2\pi} \frac{e^{-(R+iy)^2}}{1+ae^{-(R+iy)}} i \ dy \stackrel{R \to \infty}{\to} 0.
\end{align} z_0 = \ln a + i\pi \oint \frac{f(z) \ dz}{g(z)(z-z_0)} = 2\pi i \frac{f(z_0)}{g'(z_0)} = 2\pi i e^{-z_0^2} C_1 \int_{C_3} = e^{4 \pi^2} \int_R^{-R} \frac{e^{-x^2}e^{-4 \pi i x}}{1 + a e^{-x}} \ dx = -e^{4 \pi^2} \int_{-R}^{R} \frac{e^{-x^2}e^{-4 \pi i x}}{1 + a e^{-x}} \ dx ",['complex-analysis']
99,Problem in Hythothesis of a given problem,Problem in Hythothesis of a given problem,,Let $f$ be a meromorphic function in a neighborhood of the closed unit disk $\bar{\mathbb{D}}$ . Suppose that $f$ is holomorphic in $\mathbb{D}$ and $$ f(z) = \sum_{n=0}^\infty a_n z^n $$ for $z \in \mathbb{D}$ . Prove that if $f$ has a pole on the unit circle $\mathbb{T}$ then the above power series diverges at any $z \in \mathbb{T}$ . This question has been posted before and has a solution. My question is what if I don't assume that $f$ be a meromorphic function in a neighborhood of the closed unit disk $\bar{\mathbb{D}}$ . The solution posted also does not use this hypothesis. Can I assume that the statement is redundant? How does it affect the problem?,Let be a meromorphic function in a neighborhood of the closed unit disk . Suppose that is holomorphic in and for . Prove that if has a pole on the unit circle then the above power series diverges at any . This question has been posted before and has a solution. My question is what if I don't assume that be a meromorphic function in a neighborhood of the closed unit disk . The solution posted also does not use this hypothesis. Can I assume that the statement is redundant? How does it affect the problem?,f \bar{\mathbb{D}} f \mathbb{D}  f(z) = \sum_{n=0}^\infty a_n z^n  z \in \mathbb{D} f \mathbb{T} z \in \mathbb{T} f \bar{\mathbb{D}},['complex-analysis']
