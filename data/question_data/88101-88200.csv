,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Are there such things as ""function bundles"", analogous to vector bundles?","Are there such things as ""function bundles"", analogous to vector bundles?",,"I am interested in whether or not the typical vector bundle construction can be extended to cases where each fiber is an infinite dimensional vector space, possibly with other structure associated with it. I have tried to search along these lines but I am not sure if the answers I have found fully answer my question. This is motivated by the following problem, for context. I have a smooth manifold $M$ (actually, in my case $M$ is just $\mathbb{R}^n$ so it is trivially a manifold). At each point in $M$ , I want to be able to associate a function $f: [a,b] \to \mathbb{R}$ such that I have a ""function field"" on the manifold. If I were dealing with finite dimensional vectors as opposed to functions, I could do this by defining, for example, the tangent bundle $TM$ and vector fields would be a smooth section of the bundle. To provide more context, I have also have a functional $L(v)[\cdot]$ indexed by $v \in \mathbb{R}^n$ , and I want to choose the specific $f$ at each point that will maximize this functional. This seems to me to be defining a section of a ""function bundle"" of sorts, which would be useful to me as I am hoping to be able to compute information about the $f$ at nearby points given the $f$ associated with one point, i.e. to ""move along the section"" in a well defined way. I apologize if this is too vague of a question. I have spent some time searching and have not encounter a construct quite like this. I am aware that you can have Banach bundles in which each fiber is infinite dimensional, but the examples of that I have seen are such that both the base space and the fibers are infinite dimensional Banach spaces. In my case the base space is finite dimensional. I would appreciate even just a pointer in the right direction, i.e. some sources or keywords to follow up on. Thank you very much.","I am interested in whether or not the typical vector bundle construction can be extended to cases where each fiber is an infinite dimensional vector space, possibly with other structure associated with it. I have tried to search along these lines but I am not sure if the answers I have found fully answer my question. This is motivated by the following problem, for context. I have a smooth manifold (actually, in my case is just so it is trivially a manifold). At each point in , I want to be able to associate a function such that I have a ""function field"" on the manifold. If I were dealing with finite dimensional vectors as opposed to functions, I could do this by defining, for example, the tangent bundle and vector fields would be a smooth section of the bundle. To provide more context, I have also have a functional indexed by , and I want to choose the specific at each point that will maximize this functional. This seems to me to be defining a section of a ""function bundle"" of sorts, which would be useful to me as I am hoping to be able to compute information about the at nearby points given the associated with one point, i.e. to ""move along the section"" in a well defined way. I apologize if this is too vague of a question. I have spent some time searching and have not encounter a construct quite like this. I am aware that you can have Banach bundles in which each fiber is infinite dimensional, but the examples of that I have seen are such that both the base space and the fibers are infinite dimensional Banach spaces. In my case the base space is finite dimensional. I would appreciate even just a pointer in the right direction, i.e. some sources or keywords to follow up on. Thank you very much.","M M \mathbb{R}^n M f: [a,b] \to \mathbb{R} TM L(v)[\cdot] v \in \mathbb{R}^n f f f","['functional-analysis', 'differential-geometry', 'vector-bundles']"
1,Self-adjoint operators and analytic semigroups,Self-adjoint operators and analytic semigroups,,"Let $A$ be a self-adjoint operator on a Hilbert space such that $A$ is the generator of a $C_0$ -semigroup $(T_t)_{t\ge 0}$ . Must $(T_t)_{t\ge 0}$ be analytic? I know that self-adjoint operators on Hilbert space generate a bounded analytic semigroup if and only if they are sectorial. However, I was wondering if we're already given a self-adjoint operator is a generator, can we then guarantee that the semigroup would be analytic? I haven't been able to locate a counter-example.","Let be a self-adjoint operator on a Hilbert space such that is the generator of a -semigroup . Must be analytic? I know that self-adjoint operators on Hilbert space generate a bounded analytic semigroup if and only if they are sectorial. However, I was wondering if we're already given a self-adjoint operator is a generator, can we then guarantee that the semigroup would be analytic? I haven't been able to locate a counter-example.",A A C_0 (T_t)_{t\ge 0} (T_t)_{t\ge 0},"['functional-analysis', 'operator-theory', 'semigroup-of-operators']"
2,"show that $|\langle b,v\rangle|\leq \frac{1}{2\alpha}\|b\|^2 +\frac{\alpha}{2}\|v\|^2$.",show that .,"|\langle b,v\rangle|\leq \frac{1}{2\alpha}\|b\|^2 +\frac{\alpha}{2}\|v\|^2","Let H be hilbert space $A:H\to H$ and $J:H\to \mathbb R$ $A$ symetric $\langle Ax,x\rangle=\langle x,Ax\rangle$ and coercive $\exists \alpha >0$ such that $\langle Ax,x\rangle\ge \alpha \|x\|$ let $b\in H$ s.t we have $J(v)=\frac 12 \langle Ax,x\rangle -\langle b,v\rangle$ Show that $J$ is continuous and show that $|\langle b,v\rangle|\leq \frac{1}{2\alpha}\|b\|^2 +\frac{\alpha}{2}\|v\|^2$ . I proved that $J$ is bounded from below so continuous ? and I dont know how to prove the second question.",Let H be hilbert space and symetric and coercive such that let s.t we have Show that is continuous and show that . I proved that is bounded from below so continuous ? and I dont know how to prove the second question.,"A:H\to H J:H\to \mathbb R A \langle Ax,x\rangle=\langle x,Ax\rangle \exists \alpha >0 \langle Ax,x\rangle\ge \alpha \|x\| b\in H J(v)=\frac 12 \langle Ax,x\rangle -\langle b,v\rangle J |\langle b,v\rangle|\leq \frac{1}{2\alpha}\|b\|^2 +\frac{\alpha}{2}\|v\|^2 J","['functional-analysis', 'hilbert-spaces']"
3,Bounding the Hilbert-Schmidt norm of a certain linear operator,Bounding the Hilbert-Schmidt norm of a certain linear operator,,"This is a follow up to the post A bound for the Hilbert-Schmidt norm of a linear operator without using commutivity or simultaneous diagonalizability Consider an infinite dimensional separable Hilbert space $\mathcal{H}$ , and let $A$ , $B_m$ , and $L$ denote linear, compact operators. Suppose further that $\|B_m\|_{op} \le \rho^m$ for some $0<\rho < 1$ , and $L$ is symmetric and positive definite, so that the spectral theorem gives $$ L(\cdot) = \sum_{\ell=1}^\infty \lambda_\ell \langle \phi_\ell,\cdot\rangle \phi_\ell, \;\; \sum_{\ell=1}^\infty \lambda_\ell < \infty. $$ We define a pseudo-inverse of $L$ as $$ L^{-1}\pi_n(\cdot) = \sum_{\ell=1}^n \frac{ \langle \phi_\ell,\cdot\rangle}{\lambda_\ell} \phi_\ell. $$ ( $\pi_n$ is the projection onto $span(\phi_1,...,\phi_n)$ ). We assume that $$ D = \sum_{\ell=1}^\infty \frac{ \|A(\phi_{\ell})\|^2}{\lambda_\ell} < \infty. $$ What I want to then show is that $$ \xi_m =\|L^{1/2}B_mL^{-1}\pi_n A^* \|_{HS}^2 = \sum_{j=1}^\infty \|L^{1/2}B_mL^{-1}\pi_n A^*(\phi_j)\|^2 \le Const. \rho^m. $$ It is relatively easy to show this if $B_m$ and $L^{1/2}$ commute, but in general it is not true. https://math.stackexchange.com/users/22016/stephen-montgomery-smith devised a very nice counter example to this. My question now is: is it possible to establish this bound if instead $B_m = R^m$ , where $R$ is a linear operator satisfying $\|R\|_{op}<1$ ? This seems more likely to hold now since, in reference to the counter example devised by @Stephen Montgomery-Smith, the range space for $B_m$ cannot be shifting around as before to meet spaces with larger eigenvalues. Any ideas by you smart folks are much appreciated!","This is a follow up to the post A bound for the Hilbert-Schmidt norm of a linear operator without using commutivity or simultaneous diagonalizability Consider an infinite dimensional separable Hilbert space , and let , , and denote linear, compact operators. Suppose further that for some , and is symmetric and positive definite, so that the spectral theorem gives We define a pseudo-inverse of as ( is the projection onto ). We assume that What I want to then show is that It is relatively easy to show this if and commute, but in general it is not true. https://math.stackexchange.com/users/22016/stephen-montgomery-smith devised a very nice counter example to this. My question now is: is it possible to establish this bound if instead , where is a linear operator satisfying ? This seems more likely to hold now since, in reference to the counter example devised by @Stephen Montgomery-Smith, the range space for cannot be shifting around as before to meet spaces with larger eigenvalues. Any ideas by you smart folks are much appreciated!","\mathcal{H} A B_m L \|B_m\|_{op} \le \rho^m 0<\rho < 1 L 
L(\cdot) = \sum_{\ell=1}^\infty \lambda_\ell \langle \phi_\ell,\cdot\rangle \phi_\ell, \;\; \sum_{\ell=1}^\infty \lambda_\ell < \infty.
 L 
L^{-1}\pi_n(\cdot) = \sum_{\ell=1}^n \frac{ \langle \phi_\ell,\cdot\rangle}{\lambda_\ell} \phi_\ell.
 \pi_n span(\phi_1,...,\phi_n) 
D = \sum_{\ell=1}^\infty \frac{ \|A(\phi_{\ell})\|^2}{\lambda_\ell} < \infty.
 
\xi_m =\|L^{1/2}B_mL^{-1}\pi_n A^* \|_{HS}^2 = \sum_{j=1}^\infty \|L^{1/2}B_mL^{-1}\pi_n A^*(\phi_j)\|^2 \le Const. \rho^m.
 B_m L^{1/2} B_m = R^m R \|R\|_{op}<1 B_m","['real-analysis', 'functional-analysis', 'operator-theory']"
4,Almost Dominated Convergence Exercise (not Generalized Dominated Convergence Theorem),Almost Dominated Convergence Exercise (not Generalized Dominated Convergence Theorem),,"I just had a question regarding an exercise from Tao's Intro to Measure Theory (Exercise 1.4.46). The question is as follows: Let $(X, B, \mu)$ be a measure space, and let $f_1, f_2, ...: X \to C$ be a sequence of measurable functions that converge pointwise $\mu-a.e.$ to a measurable limit $f: X \to C$ . Suppose that there is an unsigned absolutely integrable function $G, g_1, g_2, ... : X \to [0, +\infty]$ such that $|f_n|$ are pointwise a.e.  bounded by $G + g_n$ , and that $\int_X g_n d\mu \to 0$ as $n \to \infty$ . Show that $\lim_{n\to\infty} \int_X f_n d\mu \to \int_X f d\mu$ . I've seen the generalized Dominated Convergence Theorem before, but I'm having some serious trouble trying to figure out how to proceed, since the convergence of the g_n integrals to zero only implies the convergence of g_n in measure, and doesn't directly imply anything regarding the pointwise convergence of g_n (I'm thinking about the typewriter function). My current direction is that I'd like to find something out regarding the pointwise convergence of the g_n's so that I appropriately use Fatou's lemma. So I suppose my questions are, is there a way to show that the g_n's converge pointwise to 0? Considering the assumptions in the question, I feel like any sequence of functions bounded by another sequence of functions whose integrals converge to zero, but do not converge pointwise, cannot itself converge pointwise. If this is not the right direction, .. is convergence in measure supposed to be enough? If both of these are not the right direction, please provide a small hint as to the correct direction... thanks!","I just had a question regarding an exercise from Tao's Intro to Measure Theory (Exercise 1.4.46). The question is as follows: Let be a measure space, and let be a sequence of measurable functions that converge pointwise to a measurable limit . Suppose that there is an unsigned absolutely integrable function such that are pointwise a.e.  bounded by , and that as . Show that . I've seen the generalized Dominated Convergence Theorem before, but I'm having some serious trouble trying to figure out how to proceed, since the convergence of the g_n integrals to zero only implies the convergence of g_n in measure, and doesn't directly imply anything regarding the pointwise convergence of g_n (I'm thinking about the typewriter function). My current direction is that I'd like to find something out regarding the pointwise convergence of the g_n's so that I appropriately use Fatou's lemma. So I suppose my questions are, is there a way to show that the g_n's converge pointwise to 0? Considering the assumptions in the question, I feel like any sequence of functions bounded by another sequence of functions whose integrals converge to zero, but do not converge pointwise, cannot itself converge pointwise. If this is not the right direction, .. is convergence in measure supposed to be enough? If both of these are not the right direction, please provide a small hint as to the correct direction... thanks!","(X, B, \mu) f_1, f_2, ...: X \to C \mu-a.e. f: X \to C G, g_1, g_2, ... : X \to [0, +\infty] |f_n| G + g_n \int_X g_n d\mu \to 0 n \to \infty \lim_{n\to\infty} \int_X f_n d\mu \to \int_X f d\mu","['real-analysis', 'integration', 'functional-analysis', 'limits', 'measure-theory']"
5,How can I show by using Hahn Banach separation theorem?,How can I show by using Hahn Banach separation theorem?,,"The convex hull of a set of points S in n dimensions is the intersection of all convex sets containing $S$ . For $N$ points $p_1, ..., p_N$ , the convex hull $C$ is then given by the expression $$ C = \left\{ \sum_{j=1}^ N \lambda _j p_j : \lambda _j \geq 0 \quad \text{for all} \, j \, \text{and} \, \sum_{j=1}^ N \lambda _j =1  \right\}. $$ Let $F$ be a real Banach space, $\mu$ be a Borel probability measure on a compact Hausdorff space $X$ , and let $ f : X \rightarrow F$ be a continuous mapping. Let linear continuous functionals $ \phi _1 , \ldots ,\phi_n \in F'$ and $$ \nu_j = \int _{X}\phi_j \circ f d\mu \quad \textrm{for} \; j = 1,\ldots,n.$$ Let $ T \in L({F; \mathbb{R}^n})$ be defined by $$ Ty := (\phi_1(y),\ldots\phi_n(y)) \quad \textrm{for every} \; y \in F. $$ How can I  show that  by using the Hahn-Banach separation theorem, $$ (\nu_1,\ldots \nu_n) \in co(T\circ f(X)) = T(co(f(X))), $$ where $co(B)$ denotes the convex hull of the set B ?","The convex hull of a set of points S in n dimensions is the intersection of all convex sets containing . For points , the convex hull is then given by the expression Let be a real Banach space, be a Borel probability measure on a compact Hausdorff space , and let be a continuous mapping. Let linear continuous functionals and Let be defined by How can I  show that  by using the Hahn-Banach separation theorem, where denotes the convex hull of the set B ?","S N p_1, ..., p_N C  C = \left\{ \sum_{j=1}^ N \lambda _j p_j : \lambda _j \geq 0 \quad \text{for all} \, j \, \text{and} \, \sum_{j=1}^ N \lambda _j =1  \right\}.  F \mu X  f : X \rightarrow F  \phi _1 , \ldots ,\phi_n \in F'  \nu_j = \int _{X}\phi_j \circ f d\mu \quad \textrm{for} \; j = 1,\ldots,n.  T \in L({F; \mathbb{R}^n})  Ty := (\phi_1(y),\ldots\phi_n(y)) \quad \textrm{for every} \; y \in F.   (\nu_1,\ldots \nu_n) \in co(T\circ f(X)) = T(co(f(X))),  co(B)","['complex-analysis', 'functional-analysis', 'banach-spaces', 'multilinear-algebra']"
6,Unital $C^\ast$-algebra $\mathcal{A}$ with positive elements $\mathcal{A}$.,Unital -algebra  with positive elements .,C^\ast \mathcal{A} \mathcal{A},"We are given a unital $C^\ast$ -algebra $\mathcal{A}$ where the positive elements of $\mathcal{A}$ are defined to be self-adjoint $A\in\mathcal{A}$ with $\sigma(A)\subseteq[0;+\infty[$ . Denoting the collection of positive elements $\mathcal{A}_+$ and set $\mathcal{A}_-=\{A|-A\in\mathcal{A}_+\}$ . In the following I want to show that $\mathcal{A}_{-} \cap \mathcal{A}_{+}=\{0\}$ . Idea: We have $\sigma(A)\subseteq[0;+\infty[$ and also $\sigma(-A)\subseteq[0;+\infty[$ . Now this implies that $\sigma(A)=\{0\}$ which holds if $A=0$ and therefore one can conclude that $\mathcal{A}_+\cap\mathcal{A}_-=\{0\}$ . Am I on the right track? If no, then how can one actually show $\mathcal{A}_{-} \cap \mathcal{A}_{+}=\{0\}$ ?","We are given a unital -algebra where the positive elements of are defined to be self-adjoint with . Denoting the collection of positive elements and set . In the following I want to show that . Idea: We have and also . Now this implies that which holds if and therefore one can conclude that . Am I on the right track? If no, then how can one actually show ?",C^\ast \mathcal{A} \mathcal{A} A\in\mathcal{A} \sigma(A)\subseteq[0;+\infty[ \mathcal{A}_+ \mathcal{A}_-=\{A|-A\in\mathcal{A}_+\} \mathcal{A}_{-} \cap \mathcal{A}_{+}=\{0\} \sigma(A)\subseteq[0;+\infty[ \sigma(-A)\subseteq[0;+\infty[ \sigma(A)=\{0\} A=0 \mathcal{A}_+\cap\mathcal{A}_-=\{0\} \mathcal{A}_{-} \cap \mathcal{A}_{+}=\{0\},"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'self-adjoint-operators', 'functional-calculus']"
7,Well-posedness of BVP for Poisson's equation,Well-posedness of BVP for Poisson's equation,,"Consider the BVP, \begin{eqnarray} -\Delta u&=&f \quad \text{ in } \Omega \subset \mathbb{R}^d,\\ u&=&g \quad \text{ on } \partial\Omega. \end{eqnarray} The well-known weak formulation of the above BVP is to look for $u\in H^1(\mathbb{R}^d)$ satisfying \begin{eqnarray} -\int\limits_{\mathbb{R}^d} \sum\limits_{i=1}^du_{x_i}v_{x_i} dx = \int\limits_{\mathbb{R}^d} fv dx \quad \text{ for all } v \in H^1_0(\mathbb{R}^d). \quad \quad \quad \quad \quad \quad \quad \quad (1) \end{eqnarray} Why don't we consider the a more weaker (but more intuitive) definition: $u\in L^2(\mathbb{R}^d)$ and satisfies the following weak formulation \begin{eqnarray} -\int\limits_{\mathbb{R}^d}u \Delta\phi dx =\int\limits_{\mathbb{R}^d} f\phi dx\quad \text{ for all } \phi\in C^2_c(\mathbb{R}^d). \quad \quad \quad \quad \quad  \quad \quad \quad \quad \quad \quad(2) \end{eqnarray} Is it because of non uniqueness? If so, can wee explicitly construct two different $L^2$ functions satisfying the weak formulation(2)? P.S.: Clearly weak solution in $H^1(\mathbb{R}^d)$ satisfying (1) will automatically satisfy (2). So existence is not an issue at all.","Consider the BVP, The well-known weak formulation of the above BVP is to look for satisfying Why don't we consider the a more weaker (but more intuitive) definition: and satisfies the following weak formulation Is it because of non uniqueness? If so, can wee explicitly construct two different functions satisfying the weak formulation(2)? P.S.: Clearly weak solution in satisfying (1) will automatically satisfy (2). So existence is not an issue at all.","\begin{eqnarray}
-\Delta u&=&f \quad \text{ in } \Omega \subset \mathbb{R}^d,\\
u&=&g \quad \text{ on } \partial\Omega.
\end{eqnarray} u\in H^1(\mathbb{R}^d) \begin{eqnarray}
-\int\limits_{\mathbb{R}^d} \sum\limits_{i=1}^du_{x_i}v_{x_i} dx = \int\limits_{\mathbb{R}^d} fv dx \quad \text{ for all } v \in H^1_0(\mathbb{R}^d). \quad \quad \quad \quad \quad \quad \quad \quad (1)
\end{eqnarray} u\in L^2(\mathbb{R}^d) \begin{eqnarray}
-\int\limits_{\mathbb{R}^d}u \Delta\phi dx =\int\limits_{\mathbb{R}^d} f\phi dx\quad \text{ for all } \phi\in C^2_c(\mathbb{R}^d). \quad \quad \quad \quad \quad  \quad \quad \quad \quad \quad \quad(2)
\end{eqnarray} L^2 H^1(\mathbb{R}^d)","['functional-analysis', 'analysis', 'partial-differential-equations', 'boundary-value-problem']"
8,"Is there a normed space $W$ such that $W=X\oplus Y$, with $X$ not closed and such that $W$ is homeomorphic to $X\times Y$?","Is there a normed space  such that , with  not closed and such that  is homeomorphic to ?",W W=X\oplus Y X W X\times Y,"If $W$ is a normed space, $X,Y$ are vector subspaces with the subspace topology, $X$ is not closed and $X\oplus Y=W$ in the algebraic sense, then the map $X\times Y\to W$ , $(x,y)\mapsto x+y$ is bijective and continuous, but not a homeomorphism. If $W$ is Banach, then the stronger conclusion holds that $X\times Y$ is not homeomorphic to $W$ , as a consequence of the fact that Banach spaces cannot be homeomorphic to non-Banach normed spaces (e.g. here ). I believe that it should be possible to find a normed space $W$ with a non-closed subspace $X$ and another subspace $Y$ such that $X\oplus Y=W$ and $X\times Y$ is homeomorphic to $W$ . However,  I cannot find such an example.","If is a normed space, are vector subspaces with the subspace topology, is not closed and in the algebraic sense, then the map , is bijective and continuous, but not a homeomorphism. If is Banach, then the stronger conclusion holds that is not homeomorphic to , as a consequence of the fact that Banach spaces cannot be homeomorphic to non-Banach normed spaces (e.g. here ). I believe that it should be possible to find a normed space with a non-closed subspace and another subspace such that and is homeomorphic to . However,  I cannot find such an example.","W X,Y X X\oplus Y=W X\times Y\to W (x,y)\mapsto x+y W X\times Y W W X Y X\oplus Y=W X\times Y W","['functional-analysis', 'normed-spaces', 'examples-counterexamples', 'topological-vector-spaces']"
9,Frechet derivative of Integral operator,Frechet derivative of Integral operator,,"In the following let $g(x,r,u)$ be a continuous function $g:[a,b]\times \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ . Furthermore we assume that the partial derivative $\frac{\partial g}{\partial u}$ exists and is also continuous. Now I want to calculate the Frechet derivative $DG$ of the operator $G: \mathcal{C}[a,b] \rightarrow \mathcal{C}[a,b]$ defined by: $$G(u)(x) = u(x) - \int_{a}^{b} g(x,s,u(s)) ds$$ As a guess for $DG$ I use the Gateaux derivative of $G(u)(x)$ . Which I calculate according to the definition as follows: $$\frac{1}{t}\left(G(u+th)-G(u)\right) = h(x) - \frac{1}{t}\int_{a}^{b}g\left(x,s,u(s)+th(s)\right)-g\left(x,s,u(s)\right)$$ Now we can do a Taylor expansion of the integrand in the third argument: $$g(x,s, z(t)) = g(x,s,z(0)) + \frac{\partial g(x,s,u(s))}{\partial z}\dot{z}(0) \left(z(t)-z(0)\right) + \mathcal{O}(t^{2})$$ Where $z(t) = u(s) + th(s)$ . Using this expansion in the above integral we end up with the following expression for the Gateaux derivative: $$\lim\limits_{t\to 0}\frac{1}{t}\left(G(u+th)-G(u)\right) = h(x) -\int_{a}^{b}\frac{\partial g}{\partial u}h(s)^{2} ds$$ Now we have to show that: $$\lim\limits_{\lVert h \rVert \rightarrow 0}\frac{\lVert G(u+h) - G(u) - DG(u) \rVert}{\lVert h \rVert} = 0$$ Using the Gateaux derivative from above for $DG$ and working out the numerator I get: $$\lVert G(u+h) - G(u) - DG(u) \rVert = \lVert \int_{a}^{b}\frac{\partial g}{\partial u} h(s)^{2} ds ~ - ~ \int_{a}^{b} \left(g\left(x,s,u(s)+h(s)\right) - g(x,s,u(s))\right) ds  \rVert$$ For the first term I can  use: $\lVert \int_{a}^{b}\frac{\partial g}{\partial u} h(s)^{2} ds \rVert \leq \lVert h\rVert^{2} \int_{a}^{b}\frac{\partial g}{\partial u} ds$ And the fact the the partial derivative is continuous, hence bounded on $[a,b]$ am I right? But I can't see how to proceed with the second term. Above $\lVert . \rVert$ is the sup-norm. Is this the right way to calculate $DG$ or am I completely wrong with my approach?","In the following let be a continuous function . Furthermore we assume that the partial derivative exists and is also continuous. Now I want to calculate the Frechet derivative of the operator defined by: As a guess for I use the Gateaux derivative of . Which I calculate according to the definition as follows: Now we can do a Taylor expansion of the integrand in the third argument: Where . Using this expansion in the above integral we end up with the following expression for the Gateaux derivative: Now we have to show that: Using the Gateaux derivative from above for and working out the numerator I get: For the first term I can  use: And the fact the the partial derivative is continuous, hence bounded on am I right? But I can't see how to proceed with the second term. Above is the sup-norm. Is this the right way to calculate or am I completely wrong with my approach?","g(x,r,u) g:[a,b]\times \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R} \frac{\partial g}{\partial u} DG G: \mathcal{C}[a,b] \rightarrow \mathcal{C}[a,b] G(u)(x) = u(x) - \int_{a}^{b} g(x,s,u(s)) ds DG G(u)(x) \frac{1}{t}\left(G(u+th)-G(u)\right) = h(x) - \frac{1}{t}\int_{a}^{b}g\left(x,s,u(s)+th(s)\right)-g\left(x,s,u(s)\right) g(x,s, z(t)) = g(x,s,z(0)) + \frac{\partial g(x,s,u(s))}{\partial z}\dot{z}(0) \left(z(t)-z(0)\right) + \mathcal{O}(t^{2}) z(t) = u(s) + th(s) \lim\limits_{t\to 0}\frac{1}{t}\left(G(u+th)-G(u)\right) = h(x) -\int_{a}^{b}\frac{\partial g}{\partial u}h(s)^{2} ds \lim\limits_{\lVert h \rVert \rightarrow 0}\frac{\lVert G(u+h) - G(u) - DG(u) \rVert}{\lVert h \rVert} = 0 DG \lVert G(u+h) - G(u) - DG(u) \rVert = \lVert \int_{a}^{b}\frac{\partial g}{\partial u} h(s)^{2} ds ~ - ~ \int_{a}^{b} \left(g\left(x,s,u(s)+h(s)\right) - g(x,s,u(s))\right) ds  \rVert \lVert \int_{a}^{b}\frac{\partial g}{\partial u} h(s)^{2} ds \rVert \leq \lVert h\rVert^{2} \int_{a}^{b}\frac{\partial g}{\partial u} ds [a,b] \lVert . \rVert DG","['functional-analysis', 'banach-spaces', 'calculus-of-variations', 'frechet-derivative']"
10,Construct an Injective and onto unbounded operator.,Construct an Injective and onto unbounded operator.,,"i was study functional analysis and i found a interesting problem. Let $X$ an infinite dimensional normed space. Construct an operator $T: X \rightarrow X$ such that $T$ is injective and onto. Also, we can define a new norm on $X$ given by $\| x \|_{T} = \| T(x) \| $ . Prove that $(X,\|  \cdot\|)$ , $(X,\| \cdot \|_{T})$ are isometric. My attemp: I was trying to define the operator $T$ in the usual form of the books, take a Hamel Basis $(x_{i})_{i \in I}$ ,and WLOG suppose $\|x_{i}\|=1$ for any $i \in I$ then take countable subsequence $J = \{j_{1},j_{2},\dots\}$ of $I$ . And define then as follows: $T(x_{ji}) = ix_{ji}$ , and $T(x_{i})=0$ if $i \in I-J$ . Then we can extend the function and we see that is unbouded. The problem is that, in this way $T$ is neither injective nor onto. At this point i do not how to redefine the function to be bijective. Any help is welcome, thanks!","i was study functional analysis and i found a interesting problem. Let an infinite dimensional normed space. Construct an operator such that is injective and onto. Also, we can define a new norm on given by . Prove that , are isometric. My attemp: I was trying to define the operator in the usual form of the books, take a Hamel Basis ,and WLOG suppose for any then take countable subsequence of . And define then as follows: , and if . Then we can extend the function and we see that is unbouded. The problem is that, in this way is neither injective nor onto. At this point i do not how to redefine the function to be bijective. Any help is welcome, thanks!","X T: X \rightarrow X T X \| x \|_{T} = \| T(x) \|  (X,\|  \cdot\|) (X,\| \cdot \|_{T}) T (x_{i})_{i \in I} \|x_{i}\|=1 i \in I J = \{j_{1},j_{2},\dots\} I T(x_{ji}) = ix_{ji} T(x_{i})=0 i \in I-J T","['functional-analysis', 'analysis', 'normed-spaces', 'operator-theory', 'unbounded-operators']"
11,"Spectrum of Hardy operators on $L^p[0,1]$",Spectrum of Hardy operators on,"L^p[0,1]","Let $Hf(x)=\frac{1}{x}\int_0^x f(t)dt$ denote the well-known (continuous) Hardy (someone called Cesáro) operators. For $1<p<+\infty$ , it can shown that $H$ is bounded on $L^p[0,+\infty)$ with operator norm $\frac{p}{p-1}$ . It is also true that $H$ is bounded on $L^p[0,1]$ with the same norm. For the spectrum, when $p=2$ , Brown, Halmos and Shields (1965) proved that $H$ are both respectively unitary equivalent to certain shift operators and hence deduce that $$\sigma(H,L^2[0,\infty))=\{\lambda: |\lambda-1|=1\}$$ and $$\sigma(H,L^2[0,1])=\{\lambda:|\lambda-1|\leq 1\}.$$ Tow years later, Boyd proved that $\sigma(H,L^p[0,+\infty)=\{\lambda: |\lambda-\frac{p}{2(p-1)}|=\frac{p}{2(p-1)}\}$ . It is reasonable to guess $$\sigma(H,L^p[0,1])=\{\lambda: |\lambda-\frac{p}{2(p-1)}|\leq\frac{p}{2(p-1)}\}.$$ But I have not find references up to now. Is anyone know some references about this? Of course one can show the spectrum of $H$ on $L^p[0,1]$ directly.","Let denote the well-known (continuous) Hardy (someone called Cesáro) operators. For , it can shown that is bounded on with operator norm . It is also true that is bounded on with the same norm. For the spectrum, when , Brown, Halmos and Shields (1965) proved that are both respectively unitary equivalent to certain shift operators and hence deduce that and Tow years later, Boyd proved that . It is reasonable to guess But I have not find references up to now. Is anyone know some references about this? Of course one can show the spectrum of on directly.","Hf(x)=\frac{1}{x}\int_0^x f(t)dt 1<p<+\infty H L^p[0,+\infty) \frac{p}{p-1} H L^p[0,1] p=2 H \sigma(H,L^2[0,\infty))=\{\lambda: |\lambda-1|=1\} \sigma(H,L^2[0,1])=\{\lambda:|\lambda-1|\leq 1\}. \sigma(H,L^p[0,+\infty)=\{\lambda: |\lambda-\frac{p}{2(p-1)}|=\frac{p}{2(p-1)}\} \sigma(H,L^p[0,1])=\{\lambda: |\lambda-\frac{p}{2(p-1)}|\leq\frac{p}{2(p-1)}\}. H L^p[0,1]","['functional-analysis', 'reference-request', 'operator-theory', 'spectral-theory']"
12,Plot of Fourier series involving prime,Plot of Fourier series involving prime,,"So, I was playing with Fourier series just for fun and got a weird idea. I'm sure that someone have think of this series before $f(x) = \displaystyle\sum_{n=1}^{\infty} {{\frac {(-1)^n} {p_n}}\sin(p_nx)}$ Where $p_n$ is the n-th prime number This is the plot involving first 20 prime numbers using desmos. I have 2 questions regarding this series. Is this plot smooth and/or analytics in the limit? Does anyone know how to plot this function? I try using python, but couldn't really figure out how to do it.","So, I was playing with Fourier series just for fun and got a weird idea. I'm sure that someone have think of this series before Where is the n-th prime number This is the plot involving first 20 prime numbers using desmos. I have 2 questions regarding this series. Is this plot smooth and/or analytics in the limit? Does anyone know how to plot this function? I try using python, but couldn't really figure out how to do it.",f(x) = \displaystyle\sum_{n=1}^{\infty} {{\frac {(-1)^n} {p_n}}\sin(p_nx)} p_n,"['real-analysis', 'functional-analysis', 'graphing-functions', 'python']"
13,Computing derivative with respect to a function,Computing derivative with respect to a function,,"Consider the functional $$ \begin{align*} J\colon (X:= C^{1}( [ 0, 1]))\to \mathbb{R}, \quad J[ f] = \int_{ 0}^{1} f'( x)^{2}\mathrm{~d}x  .\end{align*} $$ The task asks to compute $\frac{\partial }{\partial f} J $ . So far I haven't encounted functionals, so I tried to endow $X$ with the infinity norm and consider some pertubation function $h \in X$ . One has $$ \begin{align*} J[ f + h] - J[f] = \int_{ 0}^{1} f'( x)h'( x)\mathrm{~d}x  + \int_{ 0}^{1} h'( x)^{2}\mathrm{~d}x  .\end{align*} $$ With the above computation wanted to try to exploit the linearity of the differentiation/integral operator, but didn't succeed to bring it into the desired form $$ \begin{align*} J[ f + h] = J[ f] + \mathrm{D}J\!\left( f\right)( h) + o(h ) .\end{align*} $$ I would suspsect $$ \begin{align*} \mathrm{D}J\!\left( f\right)( h) = \int_{ 0}^{1} f'( x) h'( x)\mathrm{~d}x ,  \quad \int_{ 0}^{1} h'( x)^{2}\mathrm{~d}x \in o( h ) \end{align*} $$ but I don't even know whether this is a fruitful approach to solve this task.","Consider the functional The task asks to compute . So far I haven't encounted functionals, so I tried to endow with the infinity norm and consider some pertubation function . One has With the above computation wanted to try to exploit the linearity of the differentiation/integral operator, but didn't succeed to bring it into the desired form I would suspsect but I don't even know whether this is a fruitful approach to solve this task.","
\begin{align*}
J\colon (X:= C^{1}( [ 0, 1]))\to \mathbb{R}, \quad J[ f] = \int_{ 0}^{1} f'( x)^{2}\mathrm{~d}x 
.\end{align*}
 \frac{\partial }{\partial f} J  X h \in X 
\begin{align*}
J[ f + h] - J[f]
= \int_{ 0}^{1} f'( x)h'( x)\mathrm{~d}x 
+ \int_{ 0}^{1} h'( x)^{2}\mathrm{~d}x 
.\end{align*}
 
\begin{align*}
J[ f + h] = J[ f] + \mathrm{D}J\!\left( f\right)( h) + o(h )
.\end{align*}
 
\begin{align*}
\mathrm{D}J\!\left( f\right)( h) = \int_{ 0}^{1} f'( x) h'( x)\mathrm{~d}x , 
\quad \int_{ 0}^{1} h'( x)^{2}\mathrm{~d}x \in o( h )
\end{align*}
","['real-analysis', 'calculus', 'functional-analysis']"
14,$A^{\frac{1}{n}}$ converges strongly to a projection onto $(\ker{A})^{\perp}$,converges strongly to a projection onto,A^{\frac{1}{n}} (\ker{A})^{\perp},"I want to show the following: Let $H$ be a Hilbert space, let $A\in\mathbb{B}(H)_{+}$ be a positive operator, and let $P$ be a projection onto $(\ker{A})^{\perp}$ (i.e. $(\ker{A})^{\perp}=\{x\in H\mid Px=x\}$ ). Then, $\{A^{\frac{1}{n}}\}_{n=1}^{\infty}$ converges strongly to $P$ . First, I tried to the proof for $x\in (\ker{A})^{\perp}$ . In other words, I want to show $$ \|A^{\frac{1}{n}}x-Px\|=\|A^{\frac{1}{n}}x-x\|=\|(A^{\frac{1}{n}}-I)x\|\to0\quad(x\in (\ker{A})^{\perp}).$$ It's embarrassing, but I can't prove $\|(A^{\frac{1}{n}}-I)x\|\to0$ . Also, I don't know how to prove for $x\notin(\ker{A})^{\perp}$ . Please teach me that proof, thank you.","I want to show the following: Let be a Hilbert space, let be a positive operator, and let be a projection onto (i.e. ). Then, converges strongly to . First, I tried to the proof for . In other words, I want to show It's embarrassing, but I can't prove . Also, I don't know how to prove for . Please teach me that proof, thank you.",H A\in\mathbb{B}(H)_{+} P (\ker{A})^{\perp} (\ker{A})^{\perp}=\{x\in H\mid Px=x\} \{A^{\frac{1}{n}}\}_{n=1}^{\infty} P x\in (\ker{A})^{\perp}  \|A^{\frac{1}{n}}x-Px\|=\|A^{\frac{1}{n}}x-x\|=\|(A^{\frac{1}{n}}-I)x\|\to0\quad(x\in (\ker{A})^{\perp}). \|(A^{\frac{1}{n}}-I)x\|\to0 x\notin(\ker{A})^{\perp},"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'projection']"
15,$L^{p}$ convergence equivalent condition,convergence equivalent condition,L^{p},"I have to show that for $p\in[0,\infty)$ , $f_{n},f\in L^{p}(\mathbb{R})$ , (i) $f_n\rightarrow f$ in $L^{p}([-N,N])$ for all $N\in \mathbb{N}$ and (ii) $\lvert\lvert f_{n}\rvert\rvert \rightarrow \lvert\lvert f\rvert\rvert$ implies $f_{n}\rightarrow f$ in $L^{p}(\mathbb{R})$ . My approach was to first deconstruct $\lvert\lvert f_{n}-f\rvert\rvert_{p}^{p}$ as $$ \lvert\lvert f_{n}-f\rvert\rvert_{p}^{p}=\int_{-\infty}^{-N}\lvert f_{n}-f\rvert^{p}+\int_{-N}^{N}\lvert f_{n}-f\rvert^{p}+\int_{N}^{\infty}\lvert f_{n}-f\rvert^{p}. $$ (The integral is taken w.r.t. the Lebesgue measure). By (i) we know that the above decomposition is valid for all $N\in \mathbb{N}$ and as we take the limit $n\rightarrow \infty$ , the middle term vanishes. The problem is how to get an upper bound $\epsilon_{n}$ for the left and right integral s.t. $\epsilon_{n}\rightarrow 0$ as $n\rightarrow \infty$ . I don't see how we could use (ii) for that. I tried to show that  for all $n$ sufficiently large we get an $N^{*}$ such that the left and right integral are bounded and that this bound approaches $0$ as $n \rightarrow \infty$ , but didn't succeed. Could anyone help?","I have to show that for , , (i) in for all and (ii) implies in . My approach was to first deconstruct as (The integral is taken w.r.t. the Lebesgue measure). By (i) we know that the above decomposition is valid for all and as we take the limit , the middle term vanishes. The problem is how to get an upper bound for the left and right integral s.t. as . I don't see how we could use (ii) for that. I tried to show that  for all sufficiently large we get an such that the left and right integral are bounded and that this bound approaches as , but didn't succeed. Could anyone help?","p\in[0,\infty) f_{n},f\in L^{p}(\mathbb{R}) f_n\rightarrow f L^{p}([-N,N]) N\in \mathbb{N} \lvert\lvert f_{n}\rvert\rvert \rightarrow \lvert\lvert f\rvert\rvert f_{n}\rightarrow f L^{p}(\mathbb{R}) \lvert\lvert f_{n}-f\rvert\rvert_{p}^{p} 
\lvert\lvert f_{n}-f\rvert\rvert_{p}^{p}=\int_{-\infty}^{-N}\lvert f_{n}-f\rvert^{p}+\int_{-N}^{N}\lvert f_{n}-f\rvert^{p}+\int_{N}^{\infty}\lvert f_{n}-f\rvert^{p}.
 N\in \mathbb{N} n\rightarrow \infty \epsilon_{n} \epsilon_{n}\rightarrow 0 n\rightarrow \infty n N^{*} 0 n \rightarrow \infty","['real-analysis', 'functional-analysis', 'lebesgue-integral', 'lp-spaces']"
16,"The dual of $L^p(X,\mu)$, where $1<p<\infty$ and $\mu$ is a positive measure","The dual of , where  and  is a positive measure","L^p(X,\mu) 1<p<\infty \mu","Note. The functions are intended to have real values. Theorem. Let $(X,\mathcal{A},\mu)$ a $\sigma-$ finite measure space and let $p\in [1,\infty)$ . For all $F\in \left(L^p(X)\right)^*$ exists a unique function $f\in L^q(X)$ , where $q$ is the conjugate exponent of $p$ , such that $$F(g)=\int_X gf\;d\mu\quad\forall g\in L^p(X);$$ moreover we have $$\rVert F \lVert_{(L^p(\mu))^*}=\rVert f \lVert_q.$$ If $\mu$ is only a positive measure, then the above theorem also holds for $1<p< \infty$ . I want to prove this using the following steps. Definition A set $E\in\mathcal{A}$ is said $\sigma-$ finite if exists a sequence $\{E_n\}\subseteq \mathcal{A}$ such that $E=\cup E_n$ and $\mu(E_n)<\infty$ for all $n\in\mathbb{N}$ . Let $$\Sigma=\left\{E\in\mathcal{A}\;|\; E\;\text{is}\;\sigma-\text{finite}\right\}$$ Claim $1$ . Let $F\in (L^p)^*$ , for all $E\in\Sigma$ exists a unique function $f_E\in L^q$ with $f_E|_{X\setminus E}=0$ such that $F(g)=\int_X gf_E\;d\mu$ for all $g\in L^p(X)$ . My proof for claim $1$ . Consider the measure $\mu_E(A):=\mu(A\cap E)$ for $A\in\mathcal{A}$ , then $\mu_E$ is $\sigma-$ finite measure on $\mathcal{A}\cap E$ and for the Theorem, exists a unique $f\in L^q(E)$ such that $F(g)=\int_E gf\;d\mu_E$ for all $g\in L^p (E)$ . Defining $$f_E(x)=f(x)\chi_E$$ we have that $$F(g)=\int_X gf_E\;d\mu\quad \forall g\in L^p(X)$$ Claim 2. If $E,E'\in\Sigma$ and $E\subseteq E'$ , then $f_E=f_E'$ a.e in $E$ . My proof for claim $2$ . It doesn't exist because I can't come to a conclusion. Let $$\lambda (E)=\int_X\lvert f_E \rvert^q\;d\mu\quad\forall E\in\Sigma:$$ Claim 3. $\lambda$ is an increasing function with respect to inclusion. My proof for claim $3$ . For the Claim $2$ we have that $$\lambda(E)=\int_X\lvert f_E\rvert^q\;d\mu=\int_E \lvert f_E\rvert^q\;d\mu=\int_E \lvert f_E'\rvert^q\;d\mu\le \int_{E^{'}} \lvert f_E\rvert^q\;d\mu=\lambda(E')$$ Claim 4. $\lambda$ it is limited from above My proof for claim $4$ . It doesn't exist because I can't come to a conclusion. We choose a sequence $\{E_n\}\in\Sigma$ such that $\lambda(E_n)\to m:=\sup_\Sigma \lambda(E)$ : Claim 5. $H=\bigcup_{n=1}^\infty E_n\in \Sigma$ and then $\lambda(H)=m$ . My proof for claim $5$ . It doesn't exist because I can't come to a conclusion. Claim 6. Defining $f=f_H$ we have that $f=f_E$ a.e in $E$ for all $E\in\Sigma$ . My proof for claim $6$ . It doesn't exist because I can't come to a conclusion. Claim 7. If $g\in L^q$ , defininf $N=\{x\in X\;|\;g(x)\ne 0\}$ , result that $N\in\Sigma$ and $F(g)=\int_X gf_{N\cup H}\;d\mu=\int_X gf\;d\mu.$ My proof for claim $7$ . It doesn't exist because I can't come to a conclusion. Question. I am aware of the fact that I have done little, but I would be grateful for any valuable hints you will give me. Thank you.","Note. The functions are intended to have real values. Theorem. Let a finite measure space and let . For all exists a unique function , where is the conjugate exponent of , such that moreover we have If is only a positive measure, then the above theorem also holds for . I want to prove this using the following steps. Definition A set is said finite if exists a sequence such that and for all . Let Claim . Let , for all exists a unique function with such that for all . My proof for claim . Consider the measure for , then is finite measure on and for the Theorem, exists a unique such that for all . Defining we have that Claim 2. If and , then a.e in . My proof for claim . It doesn't exist because I can't come to a conclusion. Let Claim 3. is an increasing function with respect to inclusion. My proof for claim . For the Claim we have that Claim 4. it is limited from above My proof for claim . It doesn't exist because I can't come to a conclusion. We choose a sequence such that : Claim 5. and then . My proof for claim . It doesn't exist because I can't come to a conclusion. Claim 6. Defining we have that a.e in for all . My proof for claim . It doesn't exist because I can't come to a conclusion. Claim 7. If , defininf , result that and My proof for claim . It doesn't exist because I can't come to a conclusion. Question. I am aware of the fact that I have done little, but I would be grateful for any valuable hints you will give me. Thank you.","(X,\mathcal{A},\mu) \sigma- p\in [1,\infty) F\in \left(L^p(X)\right)^* f\in L^q(X) q p F(g)=\int_X gf\;d\mu\quad\forall g\in L^p(X); \rVert F \lVert_{(L^p(\mu))^*}=\rVert f \lVert_q. \mu 1<p< \infty E\in\mathcal{A} \sigma- \{E_n\}\subseteq \mathcal{A} E=\cup E_n \mu(E_n)<\infty n\in\mathbb{N} \Sigma=\left\{E\in\mathcal{A}\;|\; E\;\text{is}\;\sigma-\text{finite}\right\} 1 F\in (L^p)^* E\in\Sigma f_E\in L^q f_E|_{X\setminus E}=0 F(g)=\int_X gf_E\;d\mu g\in L^p(X) 1 \mu_E(A):=\mu(A\cap E) A\in\mathcal{A} \mu_E \sigma- \mathcal{A}\cap E f\in L^q(E) F(g)=\int_E gf\;d\mu_E g\in L^p (E) f_E(x)=f(x)\chi_E F(g)=\int_X gf_E\;d\mu\quad \forall g\in L^p(X) E,E'\in\Sigma E\subseteq E' f_E=f_E' E 2 \lambda (E)=\int_X\lvert f_E \rvert^q\;d\mu\quad\forall E\in\Sigma: \lambda 3 2 \lambda(E)=\int_X\lvert f_E\rvert^q\;d\mu=\int_E \lvert f_E\rvert^q\;d\mu=\int_E \lvert f_E'\rvert^q\;d\mu\le \int_{E^{'}} \lvert f_E\rvert^q\;d\mu=\lambda(E') \lambda 4 \{E_n\}\in\Sigma \lambda(E_n)\to m:=\sup_\Sigma \lambda(E) H=\bigcup_{n=1}^\infty E_n\in \Sigma \lambda(H)=m 5 f=f_H f=f_E E E\in\Sigma 6 g\in L^q N=\{x\in X\;|\;g(x)\ne 0\} N\in\Sigma F(g)=\int_X gf_{N\cup H}\;d\mu=\int_X gf\;d\mu. 7","['real-analysis', 'functional-analysis', 'measure-theory', 'proof-writing', 'proof-explanation']"
17,A characterization of the Euclidean norm,A characterization of the Euclidean norm,,"Suppose that a norm $||\cdot||$ on $\mathbb{R}^2$ has the following property: Whenever norm one vectors $x$ and $y$ satisfy $||x+y||=||x-y||$ then $||x+y||=||x-y||=\sqrt{2}$ . Does it follow that $||\cdot||=||\cdot||_2$ , the Euclidean norm on $\mathbb{R}^2$ ? I tried to show that the parallelogram identity holds for this norm, thus implying it is Euclidean, but without success. I don't know how to deal with vectors of norm one that are not $\sqrt{2}$ apart. I expect this to be true, I would be surprised by a counterexample. There is no source that I am aware of for this question. I am trying to understand isometric properties of Hilbert spaces, and this two dimensional version seems like a natural question to me.","Suppose that a norm on has the following property: Whenever norm one vectors and satisfy then . Does it follow that , the Euclidean norm on ? I tried to show that the parallelogram identity holds for this norm, thus implying it is Euclidean, but without success. I don't know how to deal with vectors of norm one that are not apart. I expect this to be true, I would be surprised by a counterexample. There is no source that I am aware of for this question. I am trying to understand isometric properties of Hilbert spaces, and this two dimensional version seems like a natural question to me.",||\cdot|| \mathbb{R}^2 x y ||x+y||=||x-y|| ||x+y||=||x-y||=\sqrt{2} ||\cdot||=||\cdot||_2 \mathbb{R}^2 \sqrt{2},"['linear-algebra', 'functional-analysis', 'geometry', 'linear-transformations', 'normed-spaces']"
18,"Let $X$ be a Banach Space.Prove that, $X$ is strictly convex iff every points of $S(X)$ is exposed points of $B(X)$.","Let  be a Banach Space.Prove that,  is strictly convex iff every points of  is exposed points of .",X X S(X) B(X),"Some definitions- $X$ is said to be strictly convex or rotund if for all $x,y\in S(X),\ x\ne y$ we have $\left\lVert\frac{x+y}{2}\right\rVert<1$ A point $x_0\in B(X)$ is said to be a exposed point of $B(X)$ if $\exists f\in X^*$ such that $f(x_0)>f(x)\ \forall x\in B(X),\ x\ne x_0$ Here $S(X)=\{x\in X: \lVert x\rVert=1\}$ and $B(X)=\{x\in X: \lVert x\rVert\le 1\}$ . We are asked to prove the followings are equivalent- $X$ is rotund. All points of $S(X)$ are exposed points of $B(X)$ . I've proved $(2)\implies (1)$ . If $X$ is not rotund, then $\exists x,y\in S(X),\ x\ne y$ such that $\frac{x+y}{2}\in S(X)$ , hence $\frac{x+y}{2}$ is exposed point of $B(X)$ . This implies $\exists f\in X^*$ such that $f\left(\frac{x+y}{2}\right)>f(z)\ \forall z\in B(X), z\ne \frac{x+y}{2}$ . In particular, $f\left(\frac{x+y}{2}\right)>f(x)\implies f(y)>f(x)$ and $f\left(\frac{x+y}{2}\right)>f(y)\implies f(x)>f(y)$ , contradiction. But I'm unable to prove the converse. I tried to do it using Hahn-Banach, Separation Theorem but not getting it. Can anyone help me in this regard? Thanks for your help in advance.","Some definitions- is said to be strictly convex or rotund if for all we have A point is said to be a exposed point of if such that Here and . We are asked to prove the followings are equivalent- is rotund. All points of are exposed points of . I've proved . If is not rotund, then such that , hence is exposed point of . This implies such that . In particular, and , contradiction. But I'm unable to prove the converse. I tried to do it using Hahn-Banach, Separation Theorem but not getting it. Can anyone help me in this regard? Thanks for your help in advance.","X x,y\in S(X),\ x\ne y \left\lVert\frac{x+y}{2}\right\rVert<1 x_0\in B(X) B(X) \exists f\in X^* f(x_0)>f(x)\ \forall x\in B(X),\ x\ne x_0 S(X)=\{x\in X: \lVert x\rVert=1\} B(X)=\{x\in X: \lVert x\rVert\le 1\} X S(X) B(X) (2)\implies (1) X \exists x,y\in S(X),\ x\ne y \frac{x+y}{2}\in S(X) \frac{x+y}{2} B(X) \exists f\in X^* f\left(\frac{x+y}{2}\right)>f(z)\ \forall z\in B(X), z\ne \frac{x+y}{2} f\left(\frac{x+y}{2}\right)>f(x)\implies f(y)>f(x) f\left(\frac{x+y}{2}\right)>f(y)\implies f(x)>f(y)","['functional-analysis', 'normed-spaces', 'convex-analysis', 'banach-spaces']"
19,Does inverse mapping theorem holds for an incomplete subspace of a Banach space?,Does inverse mapping theorem holds for an incomplete subspace of a Banach space?,,"Let $l^1$ be the space of all absolutely convergent series, and $$f:l^1\to l^1$$ be a $C^1$ (or $C^\infty$ if it is necessary) mapping satisfying $$f(0)=0$$ $$\nabla f(0) = I$$ then the inverse mapping theorem guarantees that $f$ has a $C^1$ inverse map $f^{-1}$ in a small ball $B$ centered at $0$ . My question is that if $X$ is an subspace of $l^1$ and $f(X)\subset X$ , does $f^{-1}(B\cap X)\subset X$ holds? In the case when $X$ is a closed subspace of $l^1$ , its easy because we can just use the inverse mapping on $X$ . However if $X$ is not closed, I have no idea, since the proof of the inverse mapping theorem uses contraction mapping theorem, which does not hold for incomplete space.","Let be the space of all absolutely convergent series, and be a (or if it is necessary) mapping satisfying then the inverse mapping theorem guarantees that has a inverse map in a small ball centered at . My question is that if is an subspace of and , does holds? In the case when is a closed subspace of , its easy because we can just use the inverse mapping on . However if is not closed, I have no idea, since the proof of the inverse mapping theorem uses contraction mapping theorem, which does not hold for incomplete space.",l^1 f:l^1\to l^1 C^1 C^\infty f(0)=0 \nabla f(0) = I f C^1 f^{-1} B 0 X l^1 f(X)\subset X f^{-1}(B\cap X)\subset X X l^1 X X,['functional-analysis']
20,"Weak convergence in $L^{∞}[0,1]$ implies strong convergence in $L^{p}[0,1]$",Weak convergence in  implies strong convergence in,"L^{∞}[0,1] L^{p}[0,1]","I'm trying to solve an exercise in Rudin's Functional Analysis. It is the problem 19 in Chapter 11. The problem is: If $f_n\in L^{∞}[0,1]$ and converges to $0$ in the weak topology of $L^{∞}[0,1]$ , then $\int_0^1|f_n|^p\to 0$ for any $p\in (0,∞)$ . I have tried to use Gelfand Transform that Rudin mentioned in 11.13(f), which maps $L^{∞}[0,1]$ isometrically to $C(\Delta)$ as Banach Spaces, where $\Delta$ is the maximal ideal space. This approach seems to be hopeful because continuous functions are good, but I failed despite a few hours effort. Another trial is to solve this just for p=2, but I did not proceed any more, too. I think the conclusion of this problem is very powerful so I want to know how to solve it very much. So please tell me anything if you have an idea or some relative materials, thank you very much!","I'm trying to solve an exercise in Rudin's Functional Analysis. It is the problem 19 in Chapter 11. The problem is: If and converges to in the weak topology of , then for any . I have tried to use Gelfand Transform that Rudin mentioned in 11.13(f), which maps isometrically to as Banach Spaces, where is the maximal ideal space. This approach seems to be hopeful because continuous functions are good, but I failed despite a few hours effort. Another trial is to solve this just for p=2, but I did not proceed any more, too. I think the conclusion of this problem is very powerful so I want to know how to solve it very much. So please tell me anything if you have an idea or some relative materials, thank you very much!","f_n\in L^{∞}[0,1] 0 L^{∞}[0,1] \int_0^1|f_n|^p\to 0 p\in (0,∞) L^{∞}[0,1] C(\Delta) \Delta","['real-analysis', 'functional-analysis', 'analysis', 'banach-spaces', 'banach-algebras']"
21,Understanding a proof on a special case of Riesz's representation theorem,Understanding a proof on a special case of Riesz's representation theorem,,"Let $(S,\mathscr{S},\mu)$ be a measure space and $L:\mathcal{L}^2(\mu)\to\mathbb{R}$ be a linear map satisfying $|Lf|\leq C\left\|f\right\|_{2},\forall f\in\mathcal{L}^2(\mu)$ for some fixed constant $C\geq0$ . Then there exists an a.e. unique element $g\in\mathcal{L}^2(\mu)$ such that $$ Lf=\int fg\mathsf{d}\mu,\forall f\in\mathcal{L}^2(\mu). $$ I am reading a proof to this proposition from here (Proposition 5.11). The first part is basically showing that there exists $\hat{g}\in\mathcal{L}^2$ such that $\hat{g}\perp f,\forall f\in\ker L$ . This is the part that really confuses me. My questions include: Does the existence of a sequence of $f_n\in\ker{L}$ such that $\left\|f_n-h\right\|\to\inf_{f\in\ker L}\left\|f-h\right\|$ , as argued by the author at the very beginning, use the closedness of $\ker{L}$ ? Since $\ker L$ is closed and $\mathcal{L}^2$ is complete, is it true that the $\hat{f}$ as defined in the proof should be an element of $\ker L$ as well? Why is it true that $\hat{g}\perp f,\forall f\in\ker L$ ? The writer skips that part (he said ""directly follows"") but I am not able to see it. Thank you!","Let be a measure space and be a linear map satisfying for some fixed constant . Then there exists an a.e. unique element such that I am reading a proof to this proposition from here (Proposition 5.11). The first part is basically showing that there exists such that . This is the part that really confuses me. My questions include: Does the existence of a sequence of such that , as argued by the author at the very beginning, use the closedness of ? Since is closed and is complete, is it true that the as defined in the proof should be an element of as well? Why is it true that ? The writer skips that part (he said ""directly follows"") but I am not able to see it. Thank you!","(S,\mathscr{S},\mu) L:\mathcal{L}^2(\mu)\to\mathbb{R} |Lf|\leq C\left\|f\right\|_{2},\forall f\in\mathcal{L}^2(\mu) C\geq0 g\in\mathcal{L}^2(\mu) 
Lf=\int fg\mathsf{d}\mu,\forall f\in\mathcal{L}^2(\mu).
 \hat{g}\in\mathcal{L}^2 \hat{g}\perp f,\forall f\in\ker L f_n\in\ker{L} \left\|f_n-h\right\|\to\inf_{f\in\ker L}\left\|f-h\right\| \ker{L} \ker L \mathcal{L}^2 \hat{f} \ker L \hat{g}\perp f,\forall f\in\ker L","['real-analysis', 'functional-analysis', 'analysis', 'measure-theory']"
22,Prerequisites for Bourbaki spectral theory (French),Prerequisites for Bourbaki spectral theory (French),,"I am considering reading Bourbaki's text Théories spectrales (Springer, French, 2nd Ed.) and was wondering what the prerequisites are. Currently I am familiar with their texts on the Theory of Sets, General Topology (Chaps 1-4 and 5-10), Topological Vector Spaces, Algebra I (Chaps 1-3), and Integration (Chaps 1-6 and 7-9). Do I also need familiarity with their text on Commutative Algebra ? Thanks.","I am considering reading Bourbaki's text Théories spectrales (Springer, French, 2nd Ed.) and was wondering what the prerequisites are. Currently I am familiar with their texts on the Theory of Sets, General Topology (Chaps 1-4 and 5-10), Topological Vector Spaces, Algebra I (Chaps 1-3), and Integration (Chaps 1-6 and 7-9). Do I also need familiarity with their text on Commutative Algebra ? Thanks.",,"['functional-analysis', 'spectral-theory']"
23,Lemma $3$ in Commutators of Operators by Paul R. Halmos,Lemma  in Commutators of Operators by Paul R. Halmos,3,"I need help understanding the proof of Lemma $3$ in the paper Commutators of Operators by Paul R. Halmos. Lemma $3$ . Every Hermitian operator on an infinite-dimensional Hilbert space leaves invariant at least one large subspace with a large orthogonal complement. A subspace $H$ of a Hilbert space is large if $H$ contains infinitely many orthogonal copies of its orthogonal complement, or, in other words, if $\dim H \ge \aleph_0 \dim (H^\perp)$ . Proof. The underlying Hilbert space, if it is not already separable, can be expressed as a direct sum of separable, infinite-dimensional subspaces invariant under the given operator. There is, therefore, no loss of generality in restricting attention to separable Hilbert spaces. Q1. I understand that $\mathcal H$ can be written as an uncountable direct sum of separable subspaces, but why does it suffice to consider the separable case? Suppose $A \in \mathcal B(H)$ is Hermitian and $\mathcal H = \bigoplus_{n=1}^\infty \mathcal H_n$ where $\{\mathcal H_n\}_{n=1}^\infty$ is a family of $A$ -invariant separable subspaces of $\mathcal H$ . So, $A_i:= A\vert_{\mathcal H_i}: \mathcal H_i \to \mathcal H_i$ is also Hermitian for every $i\ge 1$ . Assuming we have worked out the separable case; for every $i\ge 1$ there exists a large $A_i$ -invariant subspace $M_i \le H_i$ such that $H_i - M_i$ (orthogonal complement in $H_i$ ) is also large. Consider $M = \bigoplus_{n=1}^\infty M_i$ . It is clear that $M$ is $A$ -invariant. How do I show that $M$ and $M^\perp$ are also large? If $A$ is Hermitian and $E$ is the spectral measure of $A$ , and if, for every Borel subset $M$ of the real line, $E(M) = \mathbf{0}$ or $\mathbf{I}$ , then $A$ is a scalar multiple of $\mathbf{I}$ . It follows easily that if, for every $M$ , the dimension of the range of $E(M)$ is finite or co-finite, then $A$ differs from a scalar multiple of $\mathbf{I}$ by a finite-dimensional operator. In the contrary case both $E(M)$ and $\mathbf{I} - E(M)$ have infinite-dimensional ranges for some $M$ . In either case, the conclusion of the lemma is obvious. Q2. Could someone please explain the details of the above proof? It seems very cryptic and not at all straightforward. Thank you! Related Posts : When is a subspace of a Hilbert space large?","I need help understanding the proof of Lemma in the paper Commutators of Operators by Paul R. Halmos. Lemma . Every Hermitian operator on an infinite-dimensional Hilbert space leaves invariant at least one large subspace with a large orthogonal complement. A subspace of a Hilbert space is large if contains infinitely many orthogonal copies of its orthogonal complement, or, in other words, if . Proof. The underlying Hilbert space, if it is not already separable, can be expressed as a direct sum of separable, infinite-dimensional subspaces invariant under the given operator. There is, therefore, no loss of generality in restricting attention to separable Hilbert spaces. Q1. I understand that can be written as an uncountable direct sum of separable subspaces, but why does it suffice to consider the separable case? Suppose is Hermitian and where is a family of -invariant separable subspaces of . So, is also Hermitian for every . Assuming we have worked out the separable case; for every there exists a large -invariant subspace such that (orthogonal complement in ) is also large. Consider . It is clear that is -invariant. How do I show that and are also large? If is Hermitian and is the spectral measure of , and if, for every Borel subset of the real line, or , then is a scalar multiple of . It follows easily that if, for every , the dimension of the range of is finite or co-finite, then differs from a scalar multiple of by a finite-dimensional operator. In the contrary case both and have infinite-dimensional ranges for some . In either case, the conclusion of the lemma is obvious. Q2. Could someone please explain the details of the above proof? It seems very cryptic and not at all straightforward. Thank you! Related Posts : When is a subspace of a Hilbert space large?",3 3 H H \dim H \ge \aleph_0 \dim (H^\perp) \mathcal H A \in \mathcal B(H) \mathcal H = \bigoplus_{n=1}^\infty \mathcal H_n \{\mathcal H_n\}_{n=1}^\infty A \mathcal H A_i:= A\vert_{\mathcal H_i}: \mathcal H_i \to \mathcal H_i i\ge 1 i\ge 1 A_i M_i \le H_i H_i - M_i H_i M = \bigoplus_{n=1}^\infty M_i M A M M^\perp A E A M E(M) = \mathbf{0} \mathbf{I} A \mathbf{I} M E(M) A \mathbf{I} E(M) \mathbf{I} - E(M) M,"['functional-analysis', 'proof-explanation', 'operator-theory', 'hilbert-spaces']"
24,Exercise 4.1.4 from Brown and Ozawa,Exercise 4.1.4 from Brown and Ozawa,,"The question is to show the following: Let $(\mathcal{A},\alpha)$ and $(\mathcal{B},\beta)$ be $\Gamma$ - $C^*$ -algebras. Let $\varphi:\mathcal{A}\to \mathcal{B}$ be a c.c.p map which is $\Gamma$ -equivariant. Show that the map $\tilde{\varphi}: C_c(\Gamma,\mathcal{A})\to C_c(\Gamma,\mathcal{B})$ , defined by $$\tilde{\varphi}\left(\sum_s a_ss\right)=\sum_s\varphi(a_s)s$$ extends to a continuous map from $\mathcal{A}\rtimes_{\alpha,r}\Gamma$ into $\mathcal{B}\rtimes_{\alpha,r}\Gamma$ . Of course, such a map is going to be $\Gamma$ -equivariant since it is $\Gamma$ -equivariant at the level of $C_c(\Gamma,\mathcal{A})$ . I want to know if $\Gamma$ -equivariance is necessary for this map to be continuous or not? It is clear that if I remove the assumption of $\Gamma$ -equivariance of $\varphi:\mathcal{A}\to \mathcal{B}$ , the map $\tilde{\varphi}$ is no longer going to be $\Gamma$ -equivariant. I am concerned with the continuity of this map. Here is my attempt at the proof: Without any loss of generality, assume that $\mathcal{A}$ and $\mathcal{B}$ have a faithful covariant representation inside $\mathbb{B}(\mathcal{H})$ and $\mathbb{B}(\mathcal{K})$ respectively. Using Fell’s absorption principle, we can view $\mathcal{A}\rtimes_{\alpha,r}\Gamma$ and $\mathcal{B}\rtimes_{\beta,r}\Gamma$ as sub-algebras of $\mathbb{B}(\mathcal{H})\otimes C_r^*(\Gamma)$ and $\mathbb{B}(\mathcal{K})\otimes C_r^*(\Gamma)$ respectively. Using Arveson’s Extension theorem, we can view $\varphi$ as a c.c.p map from $\mathbb{B}(\mathcal{H})\to\mathbb{B}(\mathcal{K})$ which I denote by $\varphi$ again. Now, let us observe that $\tilde{\varphi}$ is nothing but the map $\varphi\otimes\text{id}|_{\mathcal{A}\rtimes_{\alpha,r}\Gamma}$ . Please let me know if I missed something here. Thank you for the help.","The question is to show the following: Let and be - -algebras. Let be a c.c.p map which is -equivariant. Show that the map , defined by extends to a continuous map from into . Of course, such a map is going to be -equivariant since it is -equivariant at the level of . I want to know if -equivariance is necessary for this map to be continuous or not? It is clear that if I remove the assumption of -equivariance of , the map is no longer going to be -equivariant. I am concerned with the continuity of this map. Here is my attempt at the proof: Without any loss of generality, assume that and have a faithful covariant representation inside and respectively. Using Fell’s absorption principle, we can view and as sub-algebras of and respectively. Using Arveson’s Extension theorem, we can view as a c.c.p map from which I denote by again. Now, let us observe that is nothing but the map . Please let me know if I missed something here. Thank you for the help.","(\mathcal{A},\alpha) (\mathcal{B},\beta) \Gamma C^* \varphi:\mathcal{A}\to \mathcal{B} \Gamma \tilde{\varphi}: C_c(\Gamma,\mathcal{A})\to C_c(\Gamma,\mathcal{B}) \tilde{\varphi}\left(\sum_s a_ss\right)=\sum_s\varphi(a_s)s \mathcal{A}\rtimes_{\alpha,r}\Gamma \mathcal{B}\rtimes_{\alpha,r}\Gamma \Gamma \Gamma C_c(\Gamma,\mathcal{A}) \Gamma \Gamma \varphi:\mathcal{A}\to \mathcal{B} \tilde{\varphi} \Gamma \mathcal{A} \mathcal{B} \mathbb{B}(\mathcal{H}) \mathbb{B}(\mathcal{K}) \mathcal{A}\rtimes_{\alpha,r}\Gamma \mathcal{B}\rtimes_{\beta,r}\Gamma \mathbb{B}(\mathcal{H})\otimes C_r^*(\Gamma) \mathbb{B}(\mathcal{K})\otimes C_r^*(\Gamma) \varphi \mathbb{B}(\mathcal{H})\to\mathbb{B}(\mathcal{K}) \varphi \tilde{\varphi} \varphi\otimes\text{id}|_{\mathcal{A}\rtimes_{\alpha,r}\Gamma}","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
25,Proof of the Spectral Theorem for Normal Operators,Proof of the Spectral Theorem for Normal Operators,,"I am reading Invariant Subspaces by H. Radjavi and P. Rosenthal. I need help understanding the proof of the spectral theorem for normal operators, as stated below. Theorem . If $A$ is a normal operator on a separable space, then there exists a finite measure space $(X,\mu)$ and $h\in L^\infty(X,\mu)$ such that $A$ is unitarily equivalent to the operator $M_h$ on $L^2(X,\mu)$ . I will reproduce the proof here, and ask questions simultaneously. I understand the proof in the case where $A\in \mathcal B(\mathcal H)$ has a cyclic vector $f$ , i.e. $\bigvee_{m,n = 0}^\infty \{A^n(A^*)^m f\} = \mathcal H$ , where $\bigvee$ denotes the closed linear span . So, let us move to the general case directly. Proof. Since for any $f\in \mathcal H$ , $\bigvee_{m,n = 0}^\infty \{A^n(A^*)^m f\}$ reduces $A$ , Zorn's lemma implies that there exists a collection $\{M_n\}_{n=1}^\infty$ of pairwise-orthogonal subspaces of $\mathcal H$ such that $\mathcal H = \bigoplus_{n=1}^\infty M_n$ , each $M_n$ reduces $A$ , and $A\vert_{M_n}$ has a cyclic vector for each $n$ (the fact that the collection is countable follows from separability of $\mathcal H$ ). How exactly is Zorn's lemma being used here, to produce the required collection of subspaces? It would be helpful if someone could provide the details. By the cyclic case, for each $n$ , there is a finite measure $\mu_n$ on $X_n:= \sigma(A\vert_{M_n})$ such that $A\vert_{M_n}$ is unitarily equivalent to $M_z$ on $L^2(X_n,\mu_n)$ . We can assume $\mu_n(X_n) \le 2^{-n}$ . Let $h_n(z) = z$ for all $z\in X_n$ . Then, $A$ is unitarily equivalent to $\bigoplus_{n=1}^\infty M_{h_n}$ on the space $\bigoplus_{n=1}^\infty L^2(X_n,\mu_n)$ . We must show how to regard $\bigoplus_{n=1}^\infty L^2(X_n,\mu_n)$ as $L^2(X,\mu)$ in such a way that $\bigoplus_{n=1}^\infty M_{h_n}$ is unitarily equivalent to $M_h$ on $L^2(X,\mu)$ for some $h$ . Relabel the elements of the sets $\{X_n\}$ to make the sets pairwise disjoint, and then let $X = \bigcup_{n=1}^\infty X_n$ . Define the measurable subsets of $X$ as the subsets which are countable unions of measurable subsets of the $\{X_n\}$ , and if $S = \bigcup_{n=1}^\infty S_n$ is a measurable set with $S_n \subset X_n$ for every $n$ , define $\mu(S) := \sum_{n=1}^\infty \mu_n(S_n)$ . Then, $(X,\mu)$ is a finite measure space. If we define $h$ on $X$ by $h(x) = h_n(x)$ for all $x\in X_n$ , then $h\in L^\infty(X,\mu)$ (in fact $\|h\|_\infty = \|A\|$ ). How is $\|h\|_\infty = \|A\|$ ? I believe this has something to do with $\|T\| = r(T)$ (the spectral radius) for normal operators $T\in \mathcal B(\mathcal H)$ . It is easily verified that $M_h$ on $L^2(X,\mu)$ is unitarily equivalent to $\bigoplus_{n=1}^\infty M_{h_n}$ , and hence to $A$ . Could someone please help me with explicit details of the above verification? I'm confused primarily because $\bigoplus_{n=1}^\infty M_{h_n}$ is not an operator on $L^2(X,\mu)$ , but on $\bigoplus_{n=1}^\infty L^2(X_n,\mu_n)$ . I understand that we are identifying $L^2(X,\mu)$ and $\bigoplus_{n=1}^\infty L^2(X_n,\mu_n)$ using the recipe above; but I am not clear about how to proceed. Thank you very much! Please let me know if any of the notations is not clear.","I am reading Invariant Subspaces by H. Radjavi and P. Rosenthal. I need help understanding the proof of the spectral theorem for normal operators, as stated below. Theorem . If is a normal operator on a separable space, then there exists a finite measure space and such that is unitarily equivalent to the operator on . I will reproduce the proof here, and ask questions simultaneously. I understand the proof in the case where has a cyclic vector , i.e. , where denotes the closed linear span . So, let us move to the general case directly. Proof. Since for any , reduces , Zorn's lemma implies that there exists a collection of pairwise-orthogonal subspaces of such that , each reduces , and has a cyclic vector for each (the fact that the collection is countable follows from separability of ). How exactly is Zorn's lemma being used here, to produce the required collection of subspaces? It would be helpful if someone could provide the details. By the cyclic case, for each , there is a finite measure on such that is unitarily equivalent to on . We can assume . Let for all . Then, is unitarily equivalent to on the space . We must show how to regard as in such a way that is unitarily equivalent to on for some . Relabel the elements of the sets to make the sets pairwise disjoint, and then let . Define the measurable subsets of as the subsets which are countable unions of measurable subsets of the , and if is a measurable set with for every , define . Then, is a finite measure space. If we define on by for all , then (in fact ). How is ? I believe this has something to do with (the spectral radius) for normal operators . It is easily verified that on is unitarily equivalent to , and hence to . Could someone please help me with explicit details of the above verification? I'm confused primarily because is not an operator on , but on . I understand that we are identifying and using the recipe above; but I am not clear about how to proceed. Thank you very much! Please let me know if any of the notations is not clear.","A (X,\mu) h\in L^\infty(X,\mu) A M_h L^2(X,\mu) A\in \mathcal B(\mathcal H) f \bigvee_{m,n = 0}^\infty \{A^n(A^*)^m f\} = \mathcal H \bigvee f\in \mathcal H \bigvee_{m,n = 0}^\infty \{A^n(A^*)^m f\} A \{M_n\}_{n=1}^\infty \mathcal H \mathcal H = \bigoplus_{n=1}^\infty M_n M_n A A\vert_{M_n} n \mathcal H n \mu_n X_n:= \sigma(A\vert_{M_n}) A\vert_{M_n} M_z L^2(X_n,\mu_n) \mu_n(X_n) \le 2^{-n} h_n(z) = z z\in X_n A \bigoplus_{n=1}^\infty M_{h_n} \bigoplus_{n=1}^\infty L^2(X_n,\mu_n) \bigoplus_{n=1}^\infty L^2(X_n,\mu_n) L^2(X,\mu) \bigoplus_{n=1}^\infty M_{h_n} M_h L^2(X,\mu) h \{X_n\} X = \bigcup_{n=1}^\infty X_n X \{X_n\} S = \bigcup_{n=1}^\infty S_n S_n \subset X_n n \mu(S) := \sum_{n=1}^\infty \mu_n(S_n) (X,\mu) h X h(x) = h_n(x) x\in X_n h\in L^\infty(X,\mu) \|h\|_\infty = \|A\| \|h\|_\infty = \|A\| \|T\| = r(T) T\in \mathcal B(\mathcal H) M_h L^2(X,\mu) \bigoplus_{n=1}^\infty M_{h_n} A \bigoplus_{n=1}^\infty M_{h_n} L^2(X,\mu) \bigoplus_{n=1}^\infty L^2(X_n,\mu_n) L^2(X,\mu) \bigoplus_{n=1}^\infty L^2(X_n,\mu_n)","['functional-analysis', 'proof-explanation', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
26,Banach space $\mathbb{C}^2$ with different norm,Banach space  with different norm,\mathbb{C}^2,"Let $(\mathbb{C}^2,\|\cdot\|)$ be the Banach space over $\mathbb{C}$ with $\|(z_1,z_2)\|=\max\{|z_1|,|z_2|\}$ for any $(z_1,z_2)\in\mathbb{C}^2$ . Let $w_1=(1,1)$ and $w_2=(1,0)$ . Then show that there is NO linear isometry on $\mathbb{C}^2$ which maps $w_1$ to $w_2$ . The above problem looks very simple, and it may have a totally trivial solution but I am unable to prove it. My Attempt : It is immediate that $\|\cdot\|$ does not satisfy the parallelogram law on $\mathbb{C}^2$ . So there does not exist any inner product on $\mathbb{C}^2$ which induces $\|\cdot\|$ . I also noticed that the set $\{w_1,w_2\}$ is a basis of $\mathbb{C}^2$ over $\mathbb{C}$ . If there exists a linear isometry $T$ on $\mathbb{C}^2$ such that $T(w_1)=w_2$ then $T$ is an isometric isomorphism. Now I am not able to proceed further and obtain contradiction.","Let be the Banach space over with for any . Let and . Then show that there is NO linear isometry on which maps to . The above problem looks very simple, and it may have a totally trivial solution but I am unable to prove it. My Attempt : It is immediate that does not satisfy the parallelogram law on . So there does not exist any inner product on which induces . I also noticed that the set is a basis of over . If there exists a linear isometry on such that then is an isometric isomorphism. Now I am not able to proceed further and obtain contradiction.","(\mathbb{C}^2,\|\cdot\|) \mathbb{C} \|(z_1,z_2)\|=\max\{|z_1|,|z_2|\} (z_1,z_2)\in\mathbb{C}^2 w_1=(1,1) w_2=(1,0) \mathbb{C}^2 w_1 w_2 \|\cdot\| \mathbb{C}^2 \mathbb{C}^2 \|\cdot\| \{w_1,w_2\} \mathbb{C}^2 \mathbb{C} T \mathbb{C}^2 T(w_1)=w_2 T","['functional-analysis', 'banach-spaces']"
27,Continuous dependence on the right-hand side of a nonlinear PDE,Continuous dependence on the right-hand side of a nonlinear PDE,,"Let $x \in \Omega$ ( $\Omega \subset \mathbb{R}^2$ is a bounded set with a sufficiently smooth boundary) and let us suppose that we have a PDE defined as $$\begin{cases} \dfrac{\partial u(t,x)}{\partial t} &= A(u(t,x)) + F(u(t,x)),\\[10pt] u(t,x)|_{\partial \Omega} &= 0, \end{cases}$$ in which $A$ is a linear operator (which does not depend on either $t$ or $x$ so it is basically a matrix) and $F$ is a nonlinear operator with some nice properties (bounded, Lipschitz property, etc.) which describes the spatial dependence. We know that this equation has a unique solution. What are the usual techniques to show that the solution of this problem depends continuously on the right-hand side, meaning that if we consider the modified problem $$\begin{cases} \dfrac{\partial u_{\varepsilon}(t,x)}{\partial t} & = A(u_{\varepsilon}(t,x)) + F(u_{\varepsilon}t,x)) + \varepsilon,\\[10pt] u_{\varepsilon}(t,x)|_{\partial \Omega} &= 0, \end{cases}$$ then $\Vert u - u_{\varepsilon} \Vert \rightarrow 0$ as $\varepsilon \rightarrow 0$ ? I have tried to use the variation of parameters formula (the operator semigroup version) but to no avail. I would be grateful even for some references since usually ""continuous dependence"" means the one considering the initial value, and not the right-hand side one.","Let ( is a bounded set with a sufficiently smooth boundary) and let us suppose that we have a PDE defined as in which is a linear operator (which does not depend on either or so it is basically a matrix) and is a nonlinear operator with some nice properties (bounded, Lipschitz property, etc.) which describes the spatial dependence. We know that this equation has a unique solution. What are the usual techniques to show that the solution of this problem depends continuously on the right-hand side, meaning that if we consider the modified problem then as ? I have tried to use the variation of parameters formula (the operator semigroup version) but to no avail. I would be grateful even for some references since usually ""continuous dependence"" means the one considering the initial value, and not the right-hand side one.","x \in \Omega \Omega \subset \mathbb{R}^2 \begin{cases}
\dfrac{\partial u(t,x)}{\partial t} &= A(u(t,x)) + F(u(t,x)),\\[10pt]
u(t,x)|_{\partial \Omega} &= 0,
\end{cases} A t x F \begin{cases}
\dfrac{\partial u_{\varepsilon}(t,x)}{\partial t} & = A(u_{\varepsilon}(t,x)) + F(u_{\varepsilon}t,x)) + \varepsilon,\\[10pt]
u_{\varepsilon}(t,x)|_{\partial \Omega} &= 0,
\end{cases} \Vert u - u_{\varepsilon} \Vert \rightarrow 0 \varepsilon \rightarrow 0","['functional-analysis', 'partial-differential-equations', 'semigroup-of-operators']"
28,Weak convergence and convergence in measure,Weak convergence and convergence in measure,,"Let $\Omega \subset \mathbb{R}^n$ be an open set and let $1 < p < \infty$ . Consider a sequence $(f_n)_n \subset L^p(\Omega)$ and $f \in L^p(\Omega)$ such that $f_n$ converges to $f$ weakly in $L^p(\Omega)$ . Let $g_n: \Omega \rightarrow \mathbb{R}$ and $g: \Omega \rightarrow \mathbb{R}$ be measurable functions such that $g_n \rightarrow g$ in measure and $||g_n||_{L^\infty} \le C$ , $\forall n$ and for some constant $C > 0$ . Prove that $g \in L^\infty (\Omega)$ and $f_n g_n \rightharpoonup fg$ in $L^p(\Omega)$ . $\textbf{Note}$ : $g_n \rightarrow g$ in measure if $\forall \epsilon > 0$ , $\mu\{x \in \Omega : |g_n(x) - g(x)| > \epsilon\} \rightarrow 0$ , where $\mu$ in this case denotes Lebesgue measure. Here is my attempt. Since $g_n \rightarrow g$ in measure, there exists a subsequence $(g_{n_k})_k$ such that $g_{n_k} \rightarrow g$ a.e. in $\Omega$ . It follows that $|g_{n_k}(x)| \rightarrow |g(x)|$ for a.e. $x \in \Omega$ . By hypothesis, $|g_{n_k}(x)|\le ||g_{n_k}||_{L^{\infty}} \le C$ for all $k \in \mathbb{N}$ $\Rightarrow$ $|g(x)| \le C$ for a.e. $x \in \Omega$ . This implies that $g \in L^{\infty}(\Omega)$ . We aim to prove that $f_n g_n \rightharpoonup fg$ in $L^p(\Omega)$ $\Longleftrightarrow$ $\forall \phi \in L^q(\Omega)$ (where $\frac{1}{p} + \frac{1}{q} = 1$ ) , $\int_{\Omega} f_n g_n \phi dx \rightarrow \int_{\Omega} fg \phi dx$ . First of all, let us check $f_n g_n \in L^p(\Omega)$ . $||f_n g_n||_{L^p}^p = \int_{\Omega} |f_n g_n|^p dx \le ||g_n||_{L^{\infty}}^p ||f_n||_{L^p}^p < \infty$ since, by hypothesis, $f_n \in L^p(\Omega), g_n \in L^\infty(\Omega), \, \forall n$ . (The same argument holds true also for $fg$ ). Note that $f_n g_n - fg = (f_n -f)g_n + f (g_n - g)$ . Then $|\int_{\Omega} f_n g_n \phi dx - \int_{\Omega} fg \phi dx| = |\int_{\Omega} (f_n g_n -fg) \phi dx| \le |\int_{\Omega} (f_n-f) g_n \phi dx| + |\int_{\Omega} f(g_n -g) \phi dx|$ . Let us focus on the first integral on the right hand-side of the expression above. $|\int_{\Omega} (f_n-f) g_n \phi dx| \le ||g_n||_{L^{\infty}} |\int_{\Omega} (f_n-f) \phi dx| \le C |\int_{\Omega} (f_n-f) \phi dx| \rightarrow 0$ , since $f_n \rightharpoonup f $ . Let $\epsilon > 0$ and define $A_{\epsilon} := \{x \in \Omega: |g_n(x) - g(x)| < \epsilon\}$ . Convergence in measure implies that $|\int_{\Omega} f(g_n -g) \phi dx| \le |\int_{A_{\epsilon}} f(g_n - g) \phi dx| + |\int_{\Omega \setminus A_{\epsilon}} f(g_n -g) \phi dx| < \epsilon \int_{A_{\epsilon}} |f| \phi dx + \int_{\Omega \setminus A_{\epsilon}} |f(g_n -g) \phi| dx$ $< \epsilon \int_{\Omega} |f| \phi dx + \int_{\Omega \setminus A_{\epsilon}} |f(g_n -g) \phi| dx$ . The second integral tends to zero for $n \rightarrow \infty$ because $g_n \rightarrow g$ in measure (which means that $\mu(\Omega \setminus A_{\epsilon}) \rightarrow 0$ , the thesis is a consequence of the absolute continuity of the integral), while $\int_{\Omega} |f| \phi dx$ is merely a constant. If anyone could check the above reasoning, it would be greatly appreciated.","Let be an open set and let . Consider a sequence and such that converges to weakly in . Let and be measurable functions such that in measure and , and for some constant . Prove that and in . : in measure if , , where in this case denotes Lebesgue measure. Here is my attempt. Since in measure, there exists a subsequence such that a.e. in . It follows that for a.e. . By hypothesis, for all for a.e. . This implies that . We aim to prove that in (where ) , . First of all, let us check . since, by hypothesis, . (The same argument holds true also for ). Note that . Then . Let us focus on the first integral on the right hand-side of the expression above. , since . Let and define . Convergence in measure implies that . The second integral tends to zero for because in measure (which means that , the thesis is a consequence of the absolute continuity of the integral), while is merely a constant. If anyone could check the above reasoning, it would be greatly appreciated.","\Omega \subset \mathbb{R}^n 1 < p < \infty (f_n)_n \subset L^p(\Omega) f \in L^p(\Omega) f_n f L^p(\Omega) g_n: \Omega \rightarrow \mathbb{R} g: \Omega \rightarrow \mathbb{R} g_n \rightarrow g ||g_n||_{L^\infty} \le C \forall n C > 0 g \in L^\infty (\Omega) f_n g_n \rightharpoonup fg L^p(\Omega) \textbf{Note} g_n \rightarrow g \forall \epsilon > 0 \mu\{x \in \Omega : |g_n(x) - g(x)| > \epsilon\} \rightarrow 0 \mu g_n \rightarrow g (g_{n_k})_k g_{n_k} \rightarrow g \Omega |g_{n_k}(x)| \rightarrow |g(x)| x \in \Omega |g_{n_k}(x)|\le ||g_{n_k}||_{L^{\infty}} \le C k \in \mathbb{N} \Rightarrow |g(x)| \le C x \in \Omega g \in L^{\infty}(\Omega) f_n g_n \rightharpoonup fg L^p(\Omega) \Longleftrightarrow \forall \phi \in L^q(\Omega) \frac{1}{p} + \frac{1}{q} = 1 \int_{\Omega} f_n g_n \phi dx \rightarrow \int_{\Omega} fg \phi dx f_n g_n \in L^p(\Omega) ||f_n g_n||_{L^p}^p = \int_{\Omega} |f_n g_n|^p dx \le ||g_n||_{L^{\infty}}^p ||f_n||_{L^p}^p < \infty f_n \in L^p(\Omega), g_n \in L^\infty(\Omega), \, \forall n fg f_n g_n - fg = (f_n -f)g_n + f (g_n - g) |\int_{\Omega} f_n g_n \phi dx - \int_{\Omega} fg \phi dx| = |\int_{\Omega} (f_n g_n -fg) \phi dx| \le |\int_{\Omega} (f_n-f) g_n \phi dx| + |\int_{\Omega} f(g_n -g) \phi dx| |\int_{\Omega} (f_n-f) g_n \phi dx| \le ||g_n||_{L^{\infty}} |\int_{\Omega} (f_n-f) \phi dx| \le C |\int_{\Omega} (f_n-f) \phi dx| \rightarrow 0 f_n \rightharpoonup f  \epsilon > 0 A_{\epsilon} := \{x \in \Omega: |g_n(x) - g(x)| < \epsilon\} |\int_{\Omega} f(g_n -g) \phi dx| \le |\int_{A_{\epsilon}} f(g_n - g) \phi dx| + |\int_{\Omega \setminus A_{\epsilon}} f(g_n -g) \phi dx| < \epsilon \int_{A_{\epsilon}} |f| \phi dx + \int_{\Omega \setminus A_{\epsilon}} |f(g_n -g) \phi| dx < \epsilon \int_{\Omega} |f| \phi dx + \int_{\Omega \setminus A_{\epsilon}} |f(g_n -g) \phi| dx n \rightarrow \infty g_n \rightarrow g \mu(\Omega \setminus A_{\epsilon}) \rightarrow 0 \int_{\Omega} |f| \phi dx","['functional-analysis', 'measure-theory', 'weak-convergence', 'sequence-of-function']"
29,"Restriction of fractional Sobolev ""function"" of negative order to subset","Restriction of fractional Sobolev ""function"" of negative order to subset",,"Assume $ U\subset V\subset \mathbb{R}^n$ are bounded open subsets with smooth boundary. We define $H^{-s}(\Omega)=(H_0^{s}(\Omega))'$ for $s>0$ . It is straightforward to show that $\left. v\right|_{U}\in H^s(U)$ for all $v\in H^s(V)$ when $s\geq 0$ and that this is continuous. However, it is not clear to me how this should work for negative orders. I think I would need a continuous extension map $\iota: H_0^s(U)\rightarrow H_0^s(V)$ , then I could set $\left. v\right|_{U}=v\circ \iota $ for $v\in H^{-s}(V).$ Intuitively I would define $\iota$ as the extension by $0$ , but when looking this up  in ""Non-Homogeneous Boundary Value Problems and Applications"" by Lions and Magenes I saw, that extension by $0$ , $H_0^s(\Omega)\rightarrow H^s(\mathbb{R}^n)$ is only continuous for $s \not = \text{integer}+\frac{1}{2}.$ This is probably due to the fact $H_0^{\frac{1}{2}}(\Omega)=H^{\frac{1}{2}}(\Omega)$ for Lipschitz domains, e.g. $1\in H_0^{\frac{1}{2}}(\Omega)$ , but indicator functions are not in $H^{\frac{1}{2}}$ . So is there any other obvious way this works?","Assume are bounded open subsets with smooth boundary. We define for . It is straightforward to show that for all when and that this is continuous. However, it is not clear to me how this should work for negative orders. I think I would need a continuous extension map , then I could set for Intuitively I would define as the extension by , but when looking this up  in ""Non-Homogeneous Boundary Value Problems and Applications"" by Lions and Magenes I saw, that extension by , is only continuous for This is probably due to the fact for Lipschitz domains, e.g. , but indicator functions are not in . So is there any other obvious way this works?", U\subset V\subset \mathbb{R}^n H^{-s}(\Omega)=(H_0^{s}(\Omega))' s>0 \left. v\right|_{U}\in H^s(U) v\in H^s(V) s\geq 0 \iota: H_0^s(U)\rightarrow H_0^s(V) \left. v\right|_{U}=v\circ \iota  v\in H^{-s}(V). \iota 0 0 H_0^s(\Omega)\rightarrow H^s(\mathbb{R}^n) s \not = \text{integer}+\frac{1}{2}. H_0^{\frac{1}{2}}(\Omega)=H^{\frac{1}{2}}(\Omega) 1\in H_0^{\frac{1}{2}}(\Omega) H^{\frac{1}{2}},"['functional-analysis', 'sobolev-spaces', 'fractional-sobolev-spaces', 'interpolation-theory']"
30,Is the multiplier algebra $M(K(H)\otimes C(X))$ isomorphic to $M(K(H))\otimes C(X)$?,Is the multiplier algebra  isomorphic to ?,M(K(H)\otimes C(X)) M(K(H))\otimes C(X),"In the survey article by Maes and Van Daele in the beginning of section 5, after Def. 5.1, the following claim is made (I will use different notation here, but wanted to give the reference nonetheless): Let $H$ be a Hilbert Space, $X$ be a compact hausdorff space and $K(H)$ denote the compact operators on H. Given any $C^\ast$ -algebra $A$ , we denote its multiplier algebra by $M(A)$ . Then we can identify elements in $M(K(H)\otimes C(X)\otimes C(X))$ with strictly continuous functions from $X\times X$ to $B(H)$ . I have two questions regarding this: The way that I understand this is that we identify $C(X)\otimes C(X)$ with $C(X\times X)$ (which I'm fine with) and then, somehow, get that $M(K(H) \otimes C(X\times X)\simeq M(K(H))\otimes C(X\times X)$ . Why does that hold? Is it true in general that for any $C^\ast$ -algebra $A$ , we have $M(A\otimes C(X))\simeq M(A)\otimes C(X)$ ? Or is this something more specific about the compact operators? Am I correct in assuming that this is the intended route and we conclude the claim by identifying $M(K(H))$ with $B(H)$ (and $M(K(H))\otimes C(X)$ with the continuous functions from $X$ to $M(K(H))$ , but that is something that I at least know how to do)? I have read in several places that the multiplier algebra of $K(H)$ is $B(H)$ equipped with the $\sigma$ -stop $^\ast$ -topology. What is a good reference for that? From my understanding the multiplier algebra of a $C^\ast$ -algebra $A$ should again be a $C^\ast$ -algebra with respect to the norm $$\lVert \cdot\rVert_{M(A)} \colon = \sup_{a\in A} \max\{l_a(\cdot), r_a(\cdot)\},$$ where $l_a(x)\colon= \lVert xa\rVert\lVert a\rVert$ and $r_a(x)\colon=\lVert ax\rVert\lVert a\rVert$ . So what exactly do people mean when they say that we can identify $B(H)$ equipped with the  with the multiplier algebra of $K(H)$ ? They certainly cannot be isomorphic as $C^\ast$ -algebras, as that would imply equality of the two norms by uniqueness of norms that turn an algebra into a $C^\ast$ -algebra. What properties does this identification of $M(K(H))$ and $B(H)$ preserve? In what sense can they be identified? I'd be extraordinarily happy for any good reference on the topic that allows me to digest and understand what is going on in the Maes and Van Daele article. Thanks in advance!","In the survey article by Maes and Van Daele in the beginning of section 5, after Def. 5.1, the following claim is made (I will use different notation here, but wanted to give the reference nonetheless): Let be a Hilbert Space, be a compact hausdorff space and denote the compact operators on H. Given any -algebra , we denote its multiplier algebra by . Then we can identify elements in with strictly continuous functions from to . I have two questions regarding this: The way that I understand this is that we identify with (which I'm fine with) and then, somehow, get that . Why does that hold? Is it true in general that for any -algebra , we have ? Or is this something more specific about the compact operators? Am I correct in assuming that this is the intended route and we conclude the claim by identifying with (and with the continuous functions from to , but that is something that I at least know how to do)? I have read in several places that the multiplier algebra of is equipped with the -stop -topology. What is a good reference for that? From my understanding the multiplier algebra of a -algebra should again be a -algebra with respect to the norm where and . So what exactly do people mean when they say that we can identify equipped with the  with the multiplier algebra of ? They certainly cannot be isomorphic as -algebras, as that would imply equality of the two norms by uniqueness of norms that turn an algebra into a -algebra. What properties does this identification of and preserve? In what sense can they be identified? I'd be extraordinarily happy for any good reference on the topic that allows me to digest and understand what is going on in the Maes and Van Daele article. Thanks in advance!","H X K(H) C^\ast A M(A) M(K(H)\otimes C(X)\otimes C(X)) X\times X B(H) C(X)\otimes C(X) C(X\times X) M(K(H) \otimes C(X\times X)\simeq M(K(H))\otimes C(X\times X) C^\ast A M(A\otimes C(X))\simeq M(A)\otimes C(X) M(K(H)) B(H) M(K(H))\otimes C(X) X M(K(H)) K(H) B(H) \sigma ^\ast C^\ast A C^\ast \lVert \cdot\rVert_{M(A)} \colon = \sup_{a\in A} \max\{l_a(\cdot), r_a(\cdot)\}, l_a(x)\colon= \lVert xa\rVert\lVert a\rVert r_a(x)\colon=\lVert ax\rVert\lVert a\rVert B(H) K(H) C^\ast C^\ast M(K(H)) B(H)","['functional-analysis', 'operator-theory', 'c-star-algebras', 'quantum-groups']"
31,Do the elements of this series converge to zero?,Do the elements of this series converge to zero?,,"Let $\{a_n\}\subset [0,\infty )$ . It is well know that if $$\sum_{n \in \mathbb{N}}a_n < \infty$$ then we must have: $a_n \to 0$ as $n \to \infty$ . Now suppose that $a_n=a_n(u)$ with $\{a_n\}\subset [0,\infty )$ and $u \in U$ fixed in  some metric space $U$ (possibly infinite dimensional). Asssume the following condition: there exists $C>0$ such that $$\sum_{n \in \mathbb{N}}a_n(u) < C$$ for every $u \in U$ . I remark that $C$ is independent of $u$ . Can I conclude that $\sup_{u} |a_n(u)| \to 0$ ? Or do I need to assume that $U$ is compact?",Let . It is well know that if then we must have: as . Now suppose that with and fixed in  some metric space (possibly infinite dimensional). Asssume the following condition: there exists such that for every . I remark that is independent of . Can I conclude that ? Or do I need to assume that is compact?,"\{a_n\}\subset [0,\infty ) \sum_{n \in \mathbb{N}}a_n < \infty a_n \to 0 n \to \infty a_n=a_n(u) \{a_n\}\subset [0,\infty ) u \in U U C>0 \sum_{n \in \mathbb{N}}a_n(u) < C u \in U C u \sup_{u} |a_n(u)| \to 0 U","['sequences-and-series', 'functional-analysis', 'uniform-convergence', 'divergent-series']"
32,Concrete realization of quotient $C^*$-algebra,Concrete realization of quotient -algebra,C^*,"Let $A$ be a $C^*$ -subalgebra of the bounded operators $B(H)$ on some Hilbert space $H$ . Let $J$ be a proper closed $2$ -sided ideal of $A$ . Then one knows that $A/J$ is another $C^*$ -algebra. By the Gelfand-Naimark theorem, one also knows that $A/J$ is $*$ -isomorphic to a $C^*$ -subalgebra of $B(H')$ for some Hilbert space $H'$ . Question: Is there a ""natural"" choice of $H'$ ? This seems like a natural and basic question, but having looked around a bit, it seems that an answer may not be straightforward. In particular, in the case where $A=B(H)$ and $J=K(H)$ for $H$ separable, the Gelfand-Naimark-Segal construction gives a non-separable example of $H'$ . But I would be interested if there are any references where this is discussed further.","Let be a -subalgebra of the bounded operators on some Hilbert space . Let be a proper closed -sided ideal of . Then one knows that is another -algebra. By the Gelfand-Naimark theorem, one also knows that is -isomorphic to a -subalgebra of for some Hilbert space . Question: Is there a ""natural"" choice of ? This seems like a natural and basic question, but having looked around a bit, it seems that an answer may not be straightforward. In particular, in the case where and for separable, the Gelfand-Naimark-Segal construction gives a non-separable example of . But I would be interested if there are any references where this is discussed further.",A C^* B(H) H J 2 A A/J C^* A/J * C^* B(H') H' H' A=B(H) J=K(H) H H',"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'operator-algebras', 'quotient-spaces']"
33,Calculating SVD for some integral operators,Calculating SVD for some integral operators,,"I am currently trying to analytically find SVD for operators $T_1, T_2: L^2\big([0;1]\big) \to L^2\big([0;1]\big)$ using definition, where: $(T_1f)(x) = \int_0^x f(y) \ dy$ $(T_2f)(x) = \int_0^1 K(x,y) f(y) \ dy$ , where $K(x,y) = \begin{cases} x(y-1), x < y \\ y(x-1), x \ge y \end{cases} $ These are compact operators. We can easily find their adjoint: $(T_1^\dagger f)(x) = \int_x^1 f(y) \ dy$ $(T_2^\dagger f)(x) = \int_0^1 K(y,x) f(y) \ dy$ Now I have to obtain eigenvalues and eigenvectors of $T_1^\dagger T_1$ and $T_2^\dagger T_2$ . In first case we have $\int_t^1 \int_0^x f(y) \ dy \ dx= \lambda f(t) $ $\int_1^t\int_0^x f(y) \ dy \ dx = -\lambda f(t) $ . Now can I take $f \in C\big([0;1] \big)$ . Then I have $F(t) = \int_1^t\int_0^x f(y) \ dy \ dx$ and $F \in C^2\big([0;1] \big).$ I can rewrite my problem as $ \begin{cases} F''(t) + \frac{1}{\lambda}F(t) = 0 \\ F(1) = F'(0) = 0 \end{cases}$ . But am I able to obtain solution for $f \in L^2\big([0;1] \big)$ (using e.g. density $ C\big([0;1] \big)$ in $L^2\big([0;1] \big)$ )? Second equation is $\int_0^1 K(x,t) \int_0^1 K(x,y) f(y) \ dy \ dx= \lambda f(t)$ . When I write out integral on left side of equation I will obtain \begin{equation*}\int_0^1 K(x,t) \Bigg( \int_x^1 x(y-1) f(y) \ dy + \int_0^x y(x-1) f(y) \ dy \Bigg) \ dx = \lambda f(t)\end{equation*} \begin{equation*}\int_0^1 K(x,t) \Bigg( x \int_0^1 y f(y) \ dy - x \int_x^1 f(y) \ dy - \int_0^x y f(y) \ dy \Bigg) \ dx = \lambda f(t)\end{equation*} Now outer integral can be rewritten in the same way. What I get is equation with nine double integrals on the left.  Here to be fair I am not sure how reduce problem to differential form or maybe how to write out those integrals to obtain  simpler problem. I would be grateful for any hints with this two operators.","I am currently trying to analytically find SVD for operators using definition, where: , where These are compact operators. We can easily find their adjoint: Now I have to obtain eigenvalues and eigenvectors of and . In first case we have . Now can I take . Then I have and I can rewrite my problem as . But am I able to obtain solution for (using e.g. density in )? Second equation is . When I write out integral on left side of equation I will obtain Now outer integral can be rewritten in the same way. What I get is equation with nine double integrals on the left.  Here to be fair I am not sure how reduce problem to differential form or maybe how to write out those integrals to obtain  simpler problem. I would be grateful for any hints with this two operators.","T_1, T_2: L^2\big([0;1]\big) \to L^2\big([0;1]\big) (T_1f)(x) = \int_0^x f(y) \ dy (T_2f)(x) = \int_0^1 K(x,y) f(y) \ dy K(x,y) = \begin{cases} x(y-1), x < y \\ y(x-1), x \ge y \end{cases}  (T_1^\dagger f)(x) = \int_x^1 f(y) \ dy (T_2^\dagger f)(x) = \int_0^1 K(y,x) f(y) \ dy T_1^\dagger T_1 T_2^\dagger T_2 \int_t^1 \int_0^x f(y) \ dy \ dx= \lambda f(t)  \int_1^t\int_0^x f(y) \ dy \ dx = -\lambda f(t)  f \in C\big([0;1] \big) F(t) = \int_1^t\int_0^x f(y) \ dy \ dx F \in C^2\big([0;1] \big).  \begin{cases} F''(t) + \frac{1}{\lambda}F(t) = 0 \\ F(1) = F'(0) = 0 \end{cases} f \in L^2\big([0;1] \big)  C\big([0;1] \big) L^2\big([0;1] \big) \int_0^1 K(x,t) \int_0^1 K(x,y) f(y) \ dy \ dx= \lambda f(t) \begin{equation*}\int_0^1 K(x,t) \Bigg( \int_x^1 x(y-1) f(y) \ dy + \int_0^x y(x-1) f(y) \ dy \Bigg) \ dx = \lambda f(t)\end{equation*} \begin{equation*}\int_0^1 K(x,t) \Bigg( x \int_0^1 y f(y) \ dy - x \int_x^1 f(y) \ dy - \int_0^x y f(y) \ dy \Bigg) \ dx = \lambda f(t)\end{equation*}","['functional-analysis', 'operator-theory', 'inverse-problems']"
34,$H_0^1(\mathbb{R}^d \setminus \{0\}) = H^1(\mathbb{R}^d \setminus \{0\})$ for $d = 2$,for,H_0^1(\mathbb{R}^d \setminus \{0\}) = H^1(\mathbb{R}^d \setminus \{0\}) d = 2,"In remark 17 of the book [1], it is stated that $$H_0^1(\mathbb{R}^d \setminus \{0\}) = H^1(\mathbb{R}^d \setminus \{0\}) \tag{1} $$ for all spatial dimensions $d \geq 2$ . Here $H_0^1(\mathbb{R}^d \setminus \{0\})$ is defined to be the closure of $C_c^{\infty}(\mathbb{R}^d \setminus \{0\})$ in $H^1(\mathbb{R}^d \setminus \{0\})$ . I think I am able to prove this for $d \geq 3$ . In my proof I make use of the fact that, for $d \geq 3$ , $$\frac{n^2}{n^d} \rightarrow 0 \qquad \textrm{as } n \rightarrow \infty$$ Clearly this argument doesn't work with $d=2$ . Does anybody know how $H_0^1(\mathbb{R}^d \setminus \{0\}) = H^1(\mathbb{R}^d \setminus \{0\})$ can be proven in the $d=2$ case? Here is my attempted proof. Introduce a cut-off function $\eta \in C_c^{\infty}(\mathbb{R}^d)$ such that $0 \leq \eta \leq 1$ and $$ \eta(x) = \begin{cases} 1 & \textrm{ if } |x| \leq 1, \\ 0 & \textrm{ if } |x| \geq 2. \end{cases} $$ Let $\eta_n(x) = \eta(nx)$ . Then, to prove $(1)$ , it suffices to show that for any $u \in H^1(\mathbb{R}^d \setminus \{0\})$ we have $$ \| \eta_n u \|_{H^1(\mathbb{R}^d \setminus \{0\})} \rightarrow 0.$$ However, note that $H^1(\mathbb{R}^d \setminus \{0\})  \cap L^{\infty}(\mathbb{R}^d \setminus \{0\})$ is dense in $H^1(\mathbb{R}^d \setminus \{0\})$ (see e.g. Item 3 of Remark 1.27 in https://math.aalto.fi/~jkkinnun/files/sobolev_spaces.pdf ). Therefore, we can assume without loss of generality that $u \in H^1(\mathbb{R}^d \setminus \{0\})  \cap L^{\infty}(\mathbb{R}^d \setminus \{0\})$ . Now, using dominated convergence, it is easily checked that $$ \| \eta_n u \|_{L^2(\mathbb{R}^d \setminus \{0\})} \rightarrow 0, \\ \| \eta_n (\nabla u) \|_{L^2(\mathbb{R}^d \setminus \{0\})} \rightarrow 0. $$ Therefore, since $\nabla (\eta_n u) = (\nabla \eta_n) u + \eta_n (\nabla u)$ , it remains to show that $$ \| (\nabla \eta_n) u \|_{L^2(\mathbb{R}^d \setminus \{0\})} \rightarrow 0. $$ However, because $u \in L^{\infty}(\mathbb{R}^d \setminus \{0\})$ we have $$ \| (\nabla \eta_n) u \|_{L^2(\mathbb{R}^d \setminus \{0\})}  \leq  \| \nabla \eta_n \|_{L^2(\mathbb{R}^d \setminus \{0\})}  \| u \|_{L^{\infty}(\mathbb{R}^d \setminus \{0\})}  $$ and therefore it suffices to show that $$ \| \nabla \eta_n \|_{L^2(\mathbb{R}^d \setminus \{0\})}  \rightarrow 0. $$ Let $B_n = \{ x \in \mathbb{R}^d : \| x\|\ \leq 2/n \}$ . We see that $$ \| \nabla \eta_n \|_{L^2(\mathbb{R}^d \setminus \{0\})}^2 = \int_{B_n} \| \nabla \eta_n \|^2 \leq n^2  \| \nabla \eta \|_{L^{\infty}(\mathbb{R}^d \setminus \{0\})} \int_{B_n} 1 \leq C \frac{n^2}{n^d}. $$ Thus if $d \geq 3$ we get $\| \nabla \eta_n \|_{L^2(\mathbb{R}^d \setminus \{0\})}  \rightarrow 0$ as desired, completing the proof. [1]: Brezis, Haim , Functional analysis, Sobolev spaces and partial differential equations , Universitext. New York, NY: Springer (ISBN 978-0-387-70913-0/pbk; 978-0-387-70914-7/ebook). xiii, 599 p. (2011). ZBL1220.46002 .","In remark 17 of the book [1], it is stated that for all spatial dimensions . Here is defined to be the closure of in . I think I am able to prove this for . In my proof I make use of the fact that, for , Clearly this argument doesn't work with . Does anybody know how can be proven in the case? Here is my attempted proof. Introduce a cut-off function such that and Let . Then, to prove , it suffices to show that for any we have However, note that is dense in (see e.g. Item 3 of Remark 1.27 in https://math.aalto.fi/~jkkinnun/files/sobolev_spaces.pdf ). Therefore, we can assume without loss of generality that . Now, using dominated convergence, it is easily checked that Therefore, since , it remains to show that However, because we have and therefore it suffices to show that Let . We see that Thus if we get as desired, completing the proof. [1]: Brezis, Haim , Functional analysis, Sobolev spaces and partial differential equations , Universitext. New York, NY: Springer (ISBN 978-0-387-70913-0/pbk; 978-0-387-70914-7/ebook). xiii, 599 p. (2011). ZBL1220.46002 .","H_0^1(\mathbb{R}^d \setminus \{0\}) = H^1(\mathbb{R}^d \setminus \{0\})
\tag{1}
 d \geq 2 H_0^1(\mathbb{R}^d \setminus \{0\}) C_c^{\infty}(\mathbb{R}^d \setminus \{0\}) H^1(\mathbb{R}^d \setminus \{0\}) d \geq 3 d \geq 3 \frac{n^2}{n^d} \rightarrow 0 \qquad \textrm{as } n \rightarrow \infty d=2 H_0^1(\mathbb{R}^d \setminus \{0\}) = H^1(\mathbb{R}^d \setminus \{0\}) d=2 \eta \in C_c^{\infty}(\mathbb{R}^d) 0 \leq \eta \leq 1 
\eta(x) = \begin{cases}
1 & \textrm{ if } |x| \leq 1, \\
0 & \textrm{ if } |x| \geq 2.
\end{cases}
 \eta_n(x) = \eta(nx) (1) u \in H^1(\mathbb{R}^d \setminus \{0\})  \| \eta_n u \|_{H^1(\mathbb{R}^d \setminus \{0\})} \rightarrow 0. H^1(\mathbb{R}^d \setminus \{0\}) 
\cap L^{\infty}(\mathbb{R}^d \setminus \{0\}) H^1(\mathbb{R}^d \setminus \{0\}) u \in H^1(\mathbb{R}^d \setminus \{0\}) 
\cap L^{\infty}(\mathbb{R}^d \setminus \{0\}) 
\| \eta_n u \|_{L^2(\mathbb{R}^d \setminus \{0\})} \rightarrow 0, \\
\| \eta_n (\nabla u) \|_{L^2(\mathbb{R}^d \setminus \{0\})} \rightarrow 0.
 \nabla (\eta_n u) = (\nabla \eta_n) u + \eta_n (\nabla u) 
\| (\nabla \eta_n) u \|_{L^2(\mathbb{R}^d \setminus \{0\})} \rightarrow 0.
 u \in L^{\infty}(\mathbb{R}^d \setminus \{0\}) 
\| (\nabla \eta_n) u \|_{L^2(\mathbb{R}^d \setminus \{0\})} 
\leq 
\| \nabla \eta_n \|_{L^2(\mathbb{R}^d \setminus \{0\})} 
\| u \|_{L^{\infty}(\mathbb{R}^d \setminus \{0\})} 
 
\| \nabla \eta_n \|_{L^2(\mathbb{R}^d \setminus \{0\})} 
\rightarrow 0.
 B_n = \{ x \in \mathbb{R}^d : \| x\|\ \leq 2/n \} 
\| \nabla \eta_n \|_{L^2(\mathbb{R}^d \setminus \{0\})}^2
= \int_{B_n} \| \nabla \eta_n \|^2
\leq n^2  \| \nabla \eta \|_{L^{\infty}(\mathbb{R}^d \setminus \{0\})}
\int_{B_n} 1
\leq C \frac{n^2}{n^d}.
 d \geq 3 \| \nabla \eta_n \|_{L^2(\mathbb{R}^d \setminus \{0\})} 
\rightarrow 0","['functional-analysis', 'sobolev-spaces']"
35,Infinitesimal Generator of semigroup for markov chain,Infinitesimal Generator of semigroup for markov chain,,"In Wikipedia the definition of generator of a semigroup is given as follows For a Feller process $(X_t)_{t\ge0}$ with Feller Semigroup $T=(T_t)_{t\ge0}$ and state space $E$ we define the generator $(A,D(A))$ by: $$D(A)=\left\{f\in C_\infty :\lim_{t↓0}\frac{T_tf-f}{t}\text{exists as a uniform limit}\right\},$$ I saw another definition of infinitsimal generator in context of markov chains which says that if $$d\phi(X_t)=A \phi(X_t)dt+dM_t$$ where $M_t$ is a martingale and $\phi \in C_c^{\infty}(\mathcal{X})$ and { $X_t$ } is a markov chain on $\mathcal{X}$ then A is the infinitesimal generator. Are these two definitions equivalent?",In Wikipedia the definition of generator of a semigroup is given as follows For a Feller process with Feller Semigroup and state space we define the generator by: I saw another definition of infinitsimal generator in context of markov chains which says that if where is a martingale and and { } is a markov chain on then A is the infinitesimal generator. Are these two definitions equivalent?,"(X_t)_{t\ge0} T=(T_t)_{t\ge0} E (A,D(A)) D(A)=\left\{f\in C_\infty :\lim_{t↓0}\frac{T_tf-f}{t}\text{exists as a uniform limit}\right\}, d\phi(X_t)=A \phi(X_t)dt+dM_t M_t \phi \in C_c^{\infty}(\mathcal{X}) X_t \mathcal{X}","['functional-analysis', 'group-theory', 'stochastic-processes', 'markov-chains', 'semigroup-of-operators']"
36,A question on the directional derivative in a real Banach space,A question on the directional derivative in a real Banach space,,"Let $K$ be a convex and compact set in the real Banach space $(\mathbb{R}^n, |\cdot|_{\infty})$ . Here, the max-norm is defined as $|v|_{\infty}=\max_{i}|v_{i}|$ and the distance function $d_{K}(\cdot)$ is defined to be $d_{K}(x):=\inf_{y \in K}|x-y|_{\infty}$ . Let us use the notation $D_{K}(x;v)$ to denote the directional derivative of $d_{K}(x)$ with respect to the direction $v \in \mathbb{R}^{n}$ , i.e., $$D_{K}(x;v):=\lim_{h \to 0^{+}}\frac{d_{K}(x+hv)-d_{K}(x)}{h}$$ Then the question that I want to ask is: If $x$ is a point in $\mathbb{R}^{n}-K$ with $D_{K}(x;v) \leq 0$ for some $v \in \mathbb{R}^{n}$ , then is it possible that there exists a sequence $\{ x_{n} \}$ in $\mathbb{R}^{n}-K$ and $\epsilon>0$ such that $x_{n}$ converges to $x$ and $D_{K}(x_{n};v) \geq \epsilon$ for all $n \in \mathbb{N}$ ? I provide some remarks and my opinions related to this question. If the ambient space was just a Euclidean space, i.e., $(\mathbb{R}^{n},|\cdot|_{2})$ , then the answer of this question is obviously NO. The reason is that the directional derivative $D_{K}(x;v)$ is continuous with respect to both $x$ and $v$ since $d_{K}(\cdot)$ is continuously differentiable ( $C^{1}$ ). I checked that this question also fails if $K$ is convex polytope. So, I guess that this statement is false for general convex and compact set $K$ in the real Banach space $(\mathbb{R}^{n}, |\cdot|_{\infty})$ but I don't have an idea to derive a contradiction for such a general set. I really appreciate that you read and answer my question.","Let be a convex and compact set in the real Banach space . Here, the max-norm is defined as and the distance function is defined to be . Let us use the notation to denote the directional derivative of with respect to the direction , i.e., Then the question that I want to ask is: If is a point in with for some , then is it possible that there exists a sequence in and such that converges to and for all ? I provide some remarks and my opinions related to this question. If the ambient space was just a Euclidean space, i.e., , then the answer of this question is obviously NO. The reason is that the directional derivative is continuous with respect to both and since is continuously differentiable ( ). I checked that this question also fails if is convex polytope. So, I guess that this statement is false for general convex and compact set in the real Banach space but I don't have an idea to derive a contradiction for such a general set. I really appreciate that you read and answer my question.","K (\mathbb{R}^n, |\cdot|_{\infty}) |v|_{\infty}=\max_{i}|v_{i}| d_{K}(\cdot) d_{K}(x):=\inf_{y \in K}|x-y|_{\infty} D_{K}(x;v) d_{K}(x) v \in \mathbb{R}^{n} D_{K}(x;v):=\lim_{h \to 0^{+}}\frac{d_{K}(x+hv)-d_{K}(x)}{h} x \mathbb{R}^{n}-K D_{K}(x;v) \leq 0 v \in \mathbb{R}^{n} \{ x_{n} \} \mathbb{R}^{n}-K \epsilon>0 x_{n} x D_{K}(x_{n};v) \geq \epsilon n \in \mathbb{N} (\mathbb{R}^{n},|\cdot|_{2}) D_{K}(x;v) x v d_{K}(\cdot) C^{1} K K (\mathbb{R}^{n}, |\cdot|_{\infty})","['real-analysis', 'functional-analysis', 'convex-analysis', 'convex-geometry', 'set-valued-analysis']"
37,Question 2.18 from Brezis: Would someone help me to understand a solution given to this question?,Question 2.18 from Brezis: Would someone help me to understand a solution given to this question?,,"I underlined parts of the solution where I'm struggling with. Would someone help me with this? In (Part 1) I did not understand the equality in (1), because from the theory, for me $$N(A^*)=\{v\in D(A^*):  A^*v=0 \in E^*)\}\subset    F^*$$ So, how can I find the equality in part 1, from this equality above? In (Part 2), the doubts in (2) are: First of all, why $A$ being closed implies that $G(A)$ is a Banach subspace of $E\bigoplus F$ ?(I tried to explain using the closed graph theorem, but it did not work). Secondly, I did not understand why there exists a continuous linear functional such that $f|_{G(A)}\equiv 0$ ? Finally, I did not understand why $f(v,0)=1$ ? In topic (3) underlined, the doubts are: why $f\longrightarrow (0,f)$ is a bounded linear map? (Who is the domain and the codomain of $f$ ?) Also, why $f(0, Av_n)\longrightarrow 0?$ At topic (4) underlined, I did not understand why $\displaystyle\lim_{n\rightarrow \infty} f(v_n, Av_n)-f(0, Av_n)$ is going to be zero?","I underlined parts of the solution where I'm struggling with. Would someone help me with this? In (Part 1) I did not understand the equality in (1), because from the theory, for me So, how can I find the equality in part 1, from this equality above? In (Part 2), the doubts in (2) are: First of all, why being closed implies that is a Banach subspace of ?(I tried to explain using the closed graph theorem, but it did not work). Secondly, I did not understand why there exists a continuous linear functional such that ? Finally, I did not understand why ? In topic (3) underlined, the doubts are: why is a bounded linear map? (Who is the domain and the codomain of ?) Also, why At topic (4) underlined, I did not understand why is going to be zero?","N(A^*)=\{v\in D(A^*):  A^*v=0 \in E^*)\}\subset
   F^* A G(A) E\bigoplus F f|_{G(A)}\equiv 0 f(v,0)=1 f\longrightarrow (0,f) f f(0, Av_n)\longrightarrow 0? \displaystyle\lim_{n\rightarrow \infty} f(v_n, Av_n)-f(0, Av_n)","['functional-analysis', 'banach-spaces', 'adjoint-operators', 'closed-graph']"
38,Can a positive definite second order elliptic operator over an unbounded domain give rise to a compact semigroup?,Can a positive definite second order elliptic operator over an unbounded domain give rise to a compact semigroup?,,"Let $A$ denote some positive definite second order elliptic operator which is defined over $L^2(\Omega)$ with domain $D(A) = H^{2m}(\Omega) \cap H^{m}_{0}(\Omega)$ . Here $\Omega$ is a bounded domain in $R^m$ . Assume that the coefficient functions of $A$ are nice enough, then it can be shown that the semigroup generated by $A$ is compact. Now what if $\Omega$ is $[0, \infty)$ ? Is it possible that $A$ can still generate compact semigroup, if replacing the function spaces in the bounded case by some weighted function spaces? If so, are there any references please?","Let denote some positive definite second order elliptic operator which is defined over with domain . Here is a bounded domain in . Assume that the coefficient functions of are nice enough, then it can be shown that the semigroup generated by is compact. Now what if is ? Is it possible that can still generate compact semigroup, if replacing the function spaces in the bounded case by some weighted function spaces? If so, are there any references please?","A L^2(\Omega) D(A) = H^{2m}(\Omega) \cap H^{m}_{0}(\Omega) \Omega R^m A A \Omega [0, \infty) A","['functional-analysis', 'partial-differential-equations', 'operator-theory', 'compact-operators']"
39,"Schauder basis in $L^2([0,1] \times [0,1], \mathbb{R}^2)$",Schauder basis in,"L^2([0,1] \times [0,1], \mathbb{R}^2)","Consider $L^2([0,1],\mathbb{R})$ . Then, $1, \sqrt{2} cos(2 \pi j x), \sqrt{2} sin(2 \pi j x ), \quad j =1,2,...$ is a Schauder basis on $L^2([0,1], \mathbb{R})$ . I am curious, how does this generalize in the case $L^2([0,1] \times [0,1], \mathbb{R}^2)$ ? Thanks","Consider . Then, is a Schauder basis on . I am curious, how does this generalize in the case ? Thanks","L^2([0,1],\mathbb{R}) 1, \sqrt{2} cos(2 \pi j x), \sqrt{2} sin(2 \pi j x ), \quad j =1,2,... L^2([0,1], \mathbb{R}) L^2([0,1] \times [0,1], \mathbb{R}^2)","['functional-analysis', 'hilbert-spaces', 'orthonormal', 'schauder-basis']"
40,Is ultraproduct of separable Hilbert space is separable?,Is ultraproduct of separable Hilbert space is separable?,,"Let $(H_n)_n$ be a sequence of separable Hilbert spaces and $\omega$ be a free ultrafilter. Is it true that $\Pi_{\omega}H_n$ is also separable? Note that $\Pi_{\omega}H_n$ is the quotient space $\mathcal{l}^{\infty}(\mathbb{N},H_n)/I$ , where $I=\{(x_n)_n\in\mathcal{l}^{\infty}(\mathbb{N},H_n):\ \lim_{n\rightarrow\omega}\|x_n\|=0 \}.$ If we take each $H_n=\mathbb{C}$ , Then $\mathcal{l}^{\infty}(\mathbb{N},H_n)=\mathcal{l}^{\infty}(\mathbb{N})$ , which is non separable. What about $I= \{(x_n)_n\in\mathcal{l}^{\infty}(\mathbb{N}):\ \lim_{n\rightarrow\omega}|x_n|=0 \}$ . Is it separable?","Let be a sequence of separable Hilbert spaces and be a free ultrafilter. Is it true that is also separable? Note that is the quotient space , where If we take each , Then , which is non separable. What about . Is it separable?","(H_n)_n \omega \Pi_{\omega}H_n \Pi_{\omega}H_n \mathcal{l}^{\infty}(\mathbb{N},H_n)/I I=\{(x_n)_n\in\mathcal{l}^{\infty}(\mathbb{N},H_n):\ \lim_{n\rightarrow\omega}\|x_n\|=0 \}. H_n=\mathbb{C} \mathcal{l}^{\infty}(\mathbb{N},H_n)=\mathcal{l}^{\infty}(\mathbb{N}) I= \{(x_n)_n\in\mathcal{l}^{\infty}(\mathbb{N}):\ \lim_{n\rightarrow\omega}|x_n|=0 \}","['functional-analysis', 'set-theory', 'hilbert-spaces', 'operator-algebras']"
41,Best constant in Weak-$L^p$-triangle inequality,Best constant in Weak--triangle inequality,L^p,"What is the best constant $C_p$ in the ""triangle inequality"" $$ \| f + g \|_{p,\infty} \le C_p ( \|f\|_{p,\infty} + \|g\|_{p,\infty})$$ for the weak $L^p$ spaces ? Here, I am mostly interested in the case $p \in [1,\infty)$ . Typical proofs show $C_p \le 2$ and I have an example proving $C_p \ge 2^{1/p}$ . Moreover, in the limit case $p = \infty$ we have $C_\infty = 1$ , which gives the clue that maybe $C_p = 2^{1/p}$ is correct.","What is the best constant in the ""triangle inequality"" for the weak spaces ? Here, I am mostly interested in the case . Typical proofs show and I have an example proving . Moreover, in the limit case we have , which gives the clue that maybe is correct.","C_p 
\| f + g \|_{p,\infty} \le C_p ( \|f\|_{p,\infty} + \|g\|_{p,\infty}) L^p p \in [1,\infty) C_p \le 2 C_p \ge 2^{1/p} p = \infty C_\infty = 1 C_p = 2^{1/p}","['functional-analysis', 'measure-theory', 'weak-lp-spaces']"
42,"integration by parts in Sobolev space $W^{1,1}(\mathbb R^d)$",integration by parts in Sobolev space,"W^{1,1}(\mathbb R^d)","Let $f,g\in W^{1,1}(\mathbb R^d)$ such that: $$ \int_{\mathbb R^d}|\nabla f|\,|g|\,<\infty\,,\quad \int_{\mathbb R^d}|f|\,|\nabla g| <\infty \,.$$ Can I say that: $$ \int_{\mathbb R^d} \nabla\!f\ g \,=\, -\int_{\mathbb R^d} f\;\nabla g \quad?$$ I remember this holds true if $f,g\in W^{1,2}(\mathbb R^d)$ . Can this hypothesis be replaced by my weaker hypothesis?",Let such that: Can I say that: I remember this holds true if . Can this hypothesis be replaced by my weaker hypothesis?,"f,g\in W^{1,1}(\mathbb R^d)  \int_{\mathbb R^d}|\nabla f|\,|g|\,<\infty\,,\quad \int_{\mathbb R^d}|f|\,|\nabla g| <\infty \,.  \int_{\mathbb R^d} \nabla\!f\ g \,=\, -\int_{\mathbb R^d} f\;\nabla g \quad? f,g\in W^{1,2}(\mathbb R^d)","['functional-analysis', 'sobolev-spaces', 'weak-derivatives']"
43,$\varphi(A(x))$ continuous $\Rightarrow$ $A$ continuous?,continuous   continuous?,\varphi(A(x)) \Rightarrow A,"Let's define linear operator: $$A \colon X \rightarrow Y$$ between normed spaces $X$ and $Y$ . Also consider linear, continuous operator: $$B\colon Y' \rightarrow X'$$ such that $B(\varphi(x)) = \varphi(A(x))$ for $\varphi \in Y', \; x \in X$ . I want to prove that if $B$ is well defined then $A$ is continuous and $\|A\| = \|B\|$ . My work so far Continuity of $B$ : $$\|B(\varphi(x))\| \le \|B\| \cdot \|\varphi(x)\| \le \|B\| \cdot \|\varphi\| \cdot \|x\|$$ Continuity of $\varphi$ : $$\|B(\varphi(x))\| = \|\varphi(A(x))\| \le \|\varphi\|\cdot \|A(x)\|$$ And here out of these two inequalities I tried somehow to obtain that $\|A(x)\| \le \|B\| \cdot\|x\|$ , and $\|B\|$ is the smallest constant $M \ge 0$ for such $\|A(x)\| \le M \|x\|$ . Also my other idea was to use Hahn-Banach theorem, becuase in thesis there is continuity and equality of norms, however I wasn't able to use it. Could you please give me a hint how to end this proof?","Let's define linear operator: between normed spaces and . Also consider linear, continuous operator: such that for . I want to prove that if is well defined then is continuous and . My work so far Continuity of : Continuity of : And here out of these two inequalities I tried somehow to obtain that , and is the smallest constant for such . Also my other idea was to use Hahn-Banach theorem, becuase in thesis there is continuity and equality of norms, however I wasn't able to use it. Could you please give me a hint how to end this proof?","A \colon X \rightarrow Y X Y B\colon Y' \rightarrow X' B(\varphi(x)) = \varphi(A(x)) \varphi \in Y', \; x \in X B A \|A\| = \|B\| B \|B(\varphi(x))\| \le \|B\| \cdot \|\varphi(x)\| \le \|B\| \cdot \|\varphi\| \cdot \|x\| \varphi \|B(\varphi(x))\| = \|\varphi(A(x))\| \le \|\varphi\|\cdot \|A(x)\| \|A(x)\| \le \|B\| \cdot\|x\| \|B\| M \ge 0 \|A(x)\| \le M \|x\|","['real-analysis', 'functional-analysis', 'operator-theory', 'normed-spaces']"
44,Douglas' Lemma for Bounded operators on Hilbert Space,Douglas' Lemma for Bounded operators on Hilbert Space,,"Here is the original paper. There are a few steps (practically all of them) I don't understand: If $A=BC$ , then $AA^* = BCC^*B^* = \|C\|^2BB^* - B(\|C\|^2\mathbb I - CC^*)B^* \le  \|C\|^2BB^* $ Why the $\le$ sign? In general, the notation $X \le Y$ is meaningful if the operator $Y-X$ is positive, namely $Y-X \ge 0$ . In this case, $B(\|C\|^2\mathbb I - CC^*)B^* \ge 0$ ? If we suppose ${\rm ran}A \subset {\rm ran}B$ , then we can define an operator $C_1$ on $\scr H$ as follows: for $f \in \scr H \dots $ there exists $h \in  \{\ker B \}^\perp$ for which $Bh = Af$ . Set $C_1 f = h.$ Why should such an $h$ exists? I mean what does $\{\ker B \}^\perp \equiv  \overline {{\rm ran } B^*}$ have to do with $ { \rm ran}B$ ? $\dots$ because $\ker B$ is closed, it follows that $h \in  \{\ker B \}^\perp$ so that $Bh = Af$ . Hence $C_1$ has been shown to be bounded. The purpose was to show the graph of $C_1$ is closed. No idea how he proved it this way. Define a mapping $D : {\rm ran}B^* \to {\rm ran}A^*$ so that $D(B^*f)=A^*f$ . Then $D$ is well defined since $\|D(B^*f)\|^2 \le \dots \le \lambda^2\|B^*f\|^2$ . Is an operator well-defined just because it is bounded? Remark : this more recent article starts exactly with Douglas lemma, except it uses $A^*A$ and $B^*B$ instead of $AA^*$ and $BB^*$ of the original paper. These are clearly not the same operators, since $A$ and $B$ are not supposed to be normal in the first place, just bounded. So? Which one is true?","Here is the original paper. There are a few steps (practically all of them) I don't understand: If , then Why the sign? In general, the notation is meaningful if the operator is positive, namely . In this case, ? If we suppose , then we can define an operator on as follows: for there exists for which . Set Why should such an exists? I mean what does have to do with ? because is closed, it follows that so that . Hence has been shown to be bounded. The purpose was to show the graph of is closed. No idea how he proved it this way. Define a mapping so that . Then is well defined since . Is an operator well-defined just because it is bounded? Remark : this more recent article starts exactly with Douglas lemma, except it uses and instead of and of the original paper. These are clearly not the same operators, since and are not supposed to be normal in the first place, just bounded. So? Which one is true?","A=BC AA^* = BCC^*B^* = \|C\|^2BB^* - B(\|C\|^2\mathbb I - CC^*)B^* \le  \|C\|^2BB^*  \le X \le Y Y-X Y-X \ge 0 B(\|C\|^2\mathbb I - CC^*)B^* \ge 0 {\rm ran}A \subset {\rm ran}B C_1 \scr H f \in \scr H \dots  h \in  \{\ker B \}^\perp Bh = Af C_1 f = h. h \{\ker B \}^\perp \equiv 
\overline {{\rm ran } B^*}  { \rm ran}B \dots \ker B h \in  \{\ker B \}^\perp Bh = Af C_1 C_1 D : {\rm ran}B^* \to {\rm ran}A^* D(B^*f)=A^*f D \|D(B^*f)\|^2 \le \dots \le \lambda^2\|B^*f\|^2 A^*A B^*B AA^* BB^* A B","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
45,"Weak convergence in $L^2(\mathbb{R}^3,L_{loc}^2(\mathbb{R}^3))$ thanks to diagonal extraction.",Weak convergence in  thanks to diagonal extraction.,"L^2(\mathbb{R}^3,L_{loc}^2(\mathbb{R}^3))","Let $f_n$ be a sequence bounded in $L^2(\mathbb{R}^3,L_{loc}^2(\mathbb{R}^3))$ which means that, for any bounded set in $\mathbb{R}^3$ , one has for any $n>0$ $$\int_{\mathbb{R}^3} \int_{B} |f_n(x,y)|^2 \ dx dy \leq M$$ with a constant $M$ independent of $n$ . I would like to prove that, up a to an extraction $\sigma$ , $(f_{\sigma(n)})_n$ weakly converges toward $f$ in $L^2(\mathbb{R}^3,L_{loc}^2(\mathbb{R}^3))$ . Using Banach-Alaoglu, I know that there exists an extraction $\sigma_B$ , depending on the set $B$ , such that $(f_{\sigma_B(n)})_n$ weakly converges toward $f_B$ in $L^2(\mathbb{R}^3,L^2(B))$ . I know the classic procedure is to use diagonal extraction to get the result, but as I am unfamiliar with the method I don't know how to prove the result. Does anyone know how to justify properly this property or know a reference that explains how to deal with it ? Any help is welcomed.","Let be a sequence bounded in which means that, for any bounded set in , one has for any with a constant independent of . I would like to prove that, up a to an extraction , weakly converges toward in . Using Banach-Alaoglu, I know that there exists an extraction , depending on the set , such that weakly converges toward in . I know the classic procedure is to use diagonal extraction to get the result, but as I am unfamiliar with the method I don't know how to prove the result. Does anyone know how to justify properly this property or know a reference that explains how to deal with it ? Any help is welcomed.","f_n L^2(\mathbb{R}^3,L_{loc}^2(\mathbb{R}^3)) \mathbb{R}^3 n>0 \int_{\mathbb{R}^3} \int_{B} |f_n(x,y)|^2 \ dx dy \leq M M n \sigma (f_{\sigma(n)})_n f L^2(\mathbb{R}^3,L_{loc}^2(\mathbb{R}^3)) \sigma_B B (f_{\sigma_B(n)})_n f_B L^2(\mathbb{R}^3,L^2(B))","['functional-analysis', 'reference-request', 'lp-spaces']"
46,Application of Fatou's Lemma to $H^1$ function,Application of Fatou's Lemma to  function,H^1,"Suppose $D_1$ is a unit disk in $\mathbb{R}^2$ and $u_n \in H^1(D_1;\mathbb{R})$ . We assume further that $\|u_n\|_{H^1} <1$ and $u_n = 0$ on $A:=\big\{(x_1,x_2) : x_1 \in [-1,1] \hspace{2pt} \text{ and } \hspace{2pt} x_2=0 \big\}$ $\mathcal{H}^1$ -almost everywhere (this is possible by trace theorem). Here $\mathcal{H}^1$ is the one-dimensional Hausdroff measure. It is clear that there is a limiting map $u_\infty \in H^1(D_1;\mathbb{R})$ such that $u_n$ converges to $u_\infty$ weakly in $H^1(D_1)$ , up to a subsequence. By Fatou's Lemma, $$ \int_0^1 \liminf_{n} \int_0^{2\pi} |\nabla u_n|^2 r d\theta dr \leq \liminf_{n} \int_0^1 \int_0^{2\pi} |\nabla u_n|^2 r d\theta dr <1.$$ Therefore, we can find a positive number $R \in (1/2,1)$ such that $$ \begin{split} \int_0^{2\pi} |\partial_\theta u_\infty(R,\theta)|^2 R^{-1} d\theta & \leq\liminf_{n} \int_0^{2\pi} |\partial_\theta u_n(R,\theta)|^2 R^{-1} d\theta \\ & =\liminf_{n} \int_0^{2\pi} |\nabla u_n|^2 \Big|_{r=R} R d\theta <1. \end{split} $$ We can obtain that $$ \int_0^{2\pi} |\partial_\theta u_n(R,\theta)|^2 d\theta < 4 \hspace{10pt} \text{for all $n$ large enough.}\label{1}\tag{1} $$ My question is, can we also find a positive number $\sigma \in (1/2,1)$ such the above inequality \eqref{1} holds and $u_n=0$ at the point $(\sigma,0)$ for all $n$ large? I am trying to use the equi-continuity of $u_n$ . Using \eqref{1} and the fundamental theorem of calculus, we see that $u_n$ is equi-continuous  on $\partial D_{R}$ . Since $$ | u_n(R,\theta_1) - u_n(R,\theta_2)| \leq |\theta_1 - \theta_2|^{1/2} \left(\int_0^{2\pi} |\partial_\theta u_n(R,\theta)|^2 d\theta\right)^{1/2} < 4 |\theta_1 - \theta_2|^{1/2}.$$ But I do know how to get the desired result.","Suppose is a unit disk in and . We assume further that and on -almost everywhere (this is possible by trace theorem). Here is the one-dimensional Hausdroff measure. It is clear that there is a limiting map such that converges to weakly in , up to a subsequence. By Fatou's Lemma, Therefore, we can find a positive number such that We can obtain that My question is, can we also find a positive number such the above inequality \eqref{1} holds and at the point for all large? I am trying to use the equi-continuity of . Using \eqref{1} and the fundamental theorem of calculus, we see that is equi-continuous  on . Since But I do know how to get the desired result.","D_1 \mathbb{R}^2 u_n \in H^1(D_1;\mathbb{R}) \|u_n\|_{H^1} <1 u_n = 0 A:=\big\{(x_1,x_2) : x_1 \in [-1,1] \hspace{2pt} \text{ and } \hspace{2pt} x_2=0 \big\} \mathcal{H}^1 \mathcal{H}^1 u_\infty \in H^1(D_1;\mathbb{R}) u_n u_\infty H^1(D_1)  \int_0^1 \liminf_{n} \int_0^{2\pi} |\nabla u_n|^2 r d\theta dr
\leq \liminf_{n} \int_0^1 \int_0^{2\pi} |\nabla u_n|^2 r d\theta dr
<1. R \in (1/2,1) 
\begin{split}
\int_0^{2\pi} |\partial_\theta u_\infty(R,\theta)|^2 R^{-1} d\theta
& \leq\liminf_{n} \int_0^{2\pi} |\partial_\theta u_n(R,\theta)|^2 R^{-1} d\theta \\
& =\liminf_{n} \int_0^{2\pi} |\nabla u_n|^2 \Big|_{r=R} R d\theta <1.
\end{split}
 
\int_0^{2\pi} |\partial_\theta u_n(R,\theta)|^2 d\theta < 4 \hspace{10pt} \text{for all n large enough.}\label{1}\tag{1}
 \sigma \in (1/2,1) u_n=0 (\sigma,0) n u_n u_n \partial D_{R}  | u_n(R,\theta_1) - u_n(R,\theta_2)| \leq |\theta_1 - \theta_2|^{1/2} \left(\int_0^{2\pi} |\partial_\theta u_n(R,\theta)|^2 d\theta\right)^{1/2} < 4 |\theta_1 - \theta_2|^{1/2}.","['functional-analysis', 'sobolev-spaces']"
47,"Integration is a compact operator on $L^p([0, 1])$",Integration is a compact operator on,"L^p([0, 1])","Let $p \in [1, \infty]$ . I want to prove that this integral operator is compact: $$ T_p: L^p([0, 1]) \to L^p([0, 1]), \quad T(f(x)) := \int_0^x f(t)dt $$ I can prove it for $L_1$ case and I can prove the following facts: $L_p([0, 1]) \subset L_1([0, 1])$ for any p (including $\infty$ ) Jensen's inequality (for convex $\phi(t) = t^p$ ) gives me $\lVert x \rVert_1^p \leq \lVert x \rVert_p^p$ for all $x \in B_{1, L_p([0, 1])}$ hence $B_{1, L_p} \subset B_{1, L_1}$ $\forall x \in L_p([0, 1])$ , $T_p(x) = T_1(x)$ (in sence of inclusion in (1)), hence we can say that $T_p(B_{1, L_p}) \subset T_1(B_{1, L_1})$ What I want to say: Compact operator send unit ball to totally bounded set. $\forall p \in [1, \infty)$ , $T_p(B_{1, L_p}) \subset T_1(B_{1, L_1})$ and last one - totally bounded. Hence - the first one set is also totally bounded Is it a correct way to proof compactness of integral operator $T_p$ ? Here are 3 open questions I can't fix right now: $T_1(B_{1, L_1})$ totally bounded, but for fix $\epsilon > 0$ we can't take epsilon-net from $T_1(B_{1, L_1})$ and say it is also epsilon-net for $T_p(B_{1, L_p})$ , since first epsilon-net consists from element from $L_1$ and last one should consists from element from $L_p$ . Do we have some density conditions on $L_p$ inside $L_1$ ? I saw only this Why is $L^{1} \cap L^{\infty}$ dense is in $L^{p}$? First epsilon-net also use norm from $L_1$ , so even if $L_p$ dense in $L_1$ (all spaces take place on interval $[0, 1]$ ), we need equivalence of norms in both spaces (I know, that norm in $L_p$ and $L_q$ doesn't equivalent untill $p \neq q$ : Are all the norms of $L^p$ space equivalent? but thats true for functions on real line, in my example functions defined on interval $[0, 1]$ , so maybe in that smaller space they equivalent?) I didn't fully ""proof"" case when $p = \infty$ , I can't give an easy proof of balls inclusion from (2) Can you give any hint how I can fix my proof of compactness? Or maybe some countreexamples/hints how I can proof main statement about compactness of $T_p$ ?","Let . I want to prove that this integral operator is compact: I can prove it for case and I can prove the following facts: for any p (including ) Jensen's inequality (for convex ) gives me for all hence , (in sence of inclusion in (1)), hence we can say that What I want to say: Compact operator send unit ball to totally bounded set. , and last one - totally bounded. Hence - the first one set is also totally bounded Is it a correct way to proof compactness of integral operator ? Here are 3 open questions I can't fix right now: totally bounded, but for fix we can't take epsilon-net from and say it is also epsilon-net for , since first epsilon-net consists from element from and last one should consists from element from . Do we have some density conditions on inside ? I saw only this Why is $L^{1} \cap L^{\infty}$ dense is in $L^{p}$? First epsilon-net also use norm from , so even if dense in (all spaces take place on interval ), we need equivalence of norms in both spaces (I know, that norm in and doesn't equivalent untill : Are all the norms of $L^p$ space equivalent? but thats true for functions on real line, in my example functions defined on interval , so maybe in that smaller space they equivalent?) I didn't fully ""proof"" case when , I can't give an easy proof of balls inclusion from (2) Can you give any hint how I can fix my proof of compactness? Or maybe some countreexamples/hints how I can proof main statement about compactness of ?","p \in [1, \infty] 
T_p: L^p([0, 1]) \to L^p([0, 1]), \quad T(f(x)) := \int_0^x f(t)dt
 L_1 L_p([0, 1]) \subset L_1([0, 1]) \infty \phi(t) = t^p \lVert x \rVert_1^p \leq \lVert x \rVert_p^p x \in B_{1, L_p([0, 1])} B_{1, L_p} \subset B_{1, L_1} \forall x \in L_p([0, 1]) T_p(x) = T_1(x) T_p(B_{1, L_p}) \subset T_1(B_{1, L_1}) \forall p \in [1, \infty) T_p(B_{1, L_p}) \subset T_1(B_{1, L_1}) T_p T_1(B_{1, L_1}) \epsilon > 0 T_1(B_{1, L_1}) T_p(B_{1, L_p}) L_1 L_p L_p L_1 L_1 L_p L_1 [0, 1] L_p L_q p \neq q [0, 1] p = \infty T_p","['functional-analysis', 'lp-spaces', 'compact-operators', 'integral-operators']"
48,Projection of an non-increasing sequence of closed convex subsets of a Hilbert space [Haim Brezis Exercise 5.5],Projection of an non-increasing sequence of closed convex subsets of a Hilbert space [Haim Brezis Exercise 5.5],,"This question comes from the Exercise 5.5 of Haim Brezis' Functional analysis, and a related but unsolved post is here: Prove that for every $f$ in $H$, the sequence $u_n$ which is the projection of $f$ on $K_n$ converges to a limit . The question can be described as follows: Let $(K_{n})_{n=1}^{\infty}$ be a family of non-increasing sequence of closed convex set in a Hilbert space $H$ with $K:=\bigcap_{n}K_{n}\neq\varnothing$ . The book has ensured that $K$ is also closed and convex. Let $P_{K_{n}}$ be the projection onto $K_{n}$ , i.e. the map that to $x\in H$ associate the unique point $y=P_{K_{n}}x\in K_{n}$ such that $$\|x-y\|=dist(x,K_{n})=\inf_{z\in K_{n}}\|x-z\|.$$ This property has been ensured by the Hilbert projection theorem. Then, show that for all $x\in H$ , $$\lim_{n\rightarrow\infty}\|P_{K_{n}}x-P_{k}x\|=0.$$ I have deleted my attempt and some edit because they contain several mistakes. I just wrote a proof, so I will directly post it below.","This question comes from the Exercise 5.5 of Haim Brezis' Functional analysis, and a related but unsolved post is here: Prove that for every $f$ in $H$, the sequence $u_n$ which is the projection of $f$ on $K_n$ converges to a limit . The question can be described as follows: Let be a family of non-increasing sequence of closed convex set in a Hilbert space with . The book has ensured that is also closed and convex. Let be the projection onto , i.e. the map that to associate the unique point such that This property has been ensured by the Hilbert projection theorem. Then, show that for all , I have deleted my attempt and some edit because they contain several mistakes. I just wrote a proof, so I will directly post it below.","(K_{n})_{n=1}^{\infty} H K:=\bigcap_{n}K_{n}\neq\varnothing K P_{K_{n}} K_{n} x\in H y=P_{K_{n}}x\in K_{n} \|x-y\|=dist(x,K_{n})=\inf_{z\in K_{n}}\|x-z\|. x\in H \lim_{n\rightarrow\infty}\|P_{K_{n}}x-P_{k}x\|=0.","['real-analysis', 'functional-analysis', 'analysis', 'convex-analysis', 'hilbert-spaces']"
49,Reference: Covariance operator is compact,Reference: Covariance operator is compact,,"I am looking for a reference for the following theorem: Let $(X,\Vert \cdot \Vert)$ be a separable Banach space and $C: X^{\ast} \rightarrow X \subseteq X^{\ast \ast}, f \mapsto \int_X f(x) \cdot - ~ d\mu(x) =: q(f, -)$ be the covariance operator of a Gaussian measure on $X$ . Then $X$ is compact, where $X^{\ast}$ carries the operator norm topology and $X$ the norm topology. For finite dimension this is trivial. For a separable Hilbert spaces one can even show that $C$ is trace class by choosing an orthonormal basis $\{e_n \}_{n \in \mathbb{N}}$ and $$\int_H \Vert x \Vert_H^2 d \mu(x) = \sum_{n = 1}^{\infty} \int_H \langle x, e_n \rangle^2 d \mu(x) = \sum_{n = 1}^{\infty} q(e_n, e_n) = \sum_{n = 1}^{\infty} \langle C e_n, e_n \rangle = \text{tr} ~ C$$ In his notes on SPDE, Martin Hairer gives the following hint: Proceed by contradiction by first showing that if $C$ wasn’t compact, then it would be possible to find a constant $c > 0$ and a sequence of elements $(f_n)_{n \in \mathbb{N}}$ such that $\Vert f_n \Vert = 1$ , $q(f_k, f_n) = 0$ for any $k \neq n$ and $q(f_n, f_n) \geq c$ for every $n \geq 1$ . Conclude that if this was the case, then the law of large numbers applied to the sequence of random variables $(f_n)_{n \in \mathbb{N}}$ would imply that $\sup_{n \in \mathbb{N}} f_n(x) = \infty$ for $\mu$ -almost every $x \in X$ , thus obtaining a contradiction with the fact that $\sup_{n \in \mathbb{N}} \vert f_n(x) \vert \leq \Vert x \Vert < \infty$ for $\mu$ -almost every $x \in X$ .","I am looking for a reference for the following theorem: Let be a separable Banach space and be the covariance operator of a Gaussian measure on . Then is compact, where carries the operator norm topology and the norm topology. For finite dimension this is trivial. For a separable Hilbert spaces one can even show that is trace class by choosing an orthonormal basis and In his notes on SPDE, Martin Hairer gives the following hint: Proceed by contradiction by first showing that if wasn’t compact, then it would be possible to find a constant and a sequence of elements such that , for any and for every . Conclude that if this was the case, then the law of large numbers applied to the sequence of random variables would imply that for -almost every , thus obtaining a contradiction with the fact that for -almost every .","(X,\Vert \cdot \Vert) C: X^{\ast} \rightarrow X \subseteq X^{\ast \ast}, f \mapsto \int_X f(x) \cdot - ~ d\mu(x) =: q(f, -) X X X^{\ast} X C \{e_n \}_{n \in \mathbb{N}} \int_H \Vert x \Vert_H^2 d \mu(x) = \sum_{n = 1}^{\infty} \int_H \langle x, e_n \rangle^2 d \mu(x) = \sum_{n = 1}^{\infty} q(e_n, e_n) = \sum_{n = 1}^{\infty} \langle C e_n, e_n \rangle = \text{tr} ~ C C c > 0 (f_n)_{n \in \mathbb{N}} \Vert f_n \Vert = 1 q(f_k, f_n) = 0 k \neq n q(f_n, f_n) \geq c n \geq 1 (f_n)_{n \in \mathbb{N}} \sup_{n \in \mathbb{N}} f_n(x) = \infty \mu x \in X \sup_{n \in \mathbb{N}} \vert f_n(x) \vert \leq \Vert x \Vert < \infty \mu x \in X","['functional-analysis', 'probability-theory', 'compact-operators', 'gaussian-measure']"
50,Normed Space $L^2$ and Vector Space $l^2$,Normed Space  and Vector Space,L^2 l^2,"I am really confused about $L^2$ -Space and $l^2$ -Space. Can anybody explain what is the difference between the $L^p$ and $l^p$ space? Also in $L^p$ -Spaces, we see that $L^2 \subset L^1$ (for $L^2[(0,T_f)], T_f >0 $ ). On the other hand for $l^p$ -Spaces, we see that $l^1 \subseteq l^2$ . How can we show that $l^1 \subseteq l^2$ ? I don't understand why(/how) does the subset sign change for the two different cases. Thanks in advance.","I am really confused about -Space and -Space. Can anybody explain what is the difference between the and space? Also in -Spaces, we see that (for ). On the other hand for -Spaces, we see that . How can we show that ? I don't understand why(/how) does the subset sign change for the two different cases. Thanks in advance.","L^2 l^2 L^p l^p L^p L^2 \subset L^1 L^2[(0,T_f)], T_f >0  l^p l^1 \subseteq l^2 l^1 \subseteq l^2","['functional-analysis', 'normed-spaces']"
51,Essential spectrum of operators whose resolvent difference is compact,Essential spectrum of operators whose resolvent difference is compact,,"Suppose that $T,S$ are densely defined, closed (unbounded) operators on a separable Hilbert space such that there exists $z \in \mathbb C$ in the intersection of resolvent sets of $T$ and $S$ for which $(T-z)^{-1}-(S-z)^{-1}$ is compact. Does it follow that $T$ and $S$ have the same essential spectrum? Remark: in the application I have in mind $S-T$ is unbounded and domains of $S$ and $T$ are not necessarily equal.","Suppose that are densely defined, closed (unbounded) operators on a separable Hilbert space such that there exists in the intersection of resolvent sets of and for which is compact. Does it follow that and have the same essential spectrum? Remark: in the application I have in mind is unbounded and domains of and are not necessarily equal.","T,S z \in \mathbb C T S (T-z)^{-1}-(S-z)^{-1} T S S-T S T","['functional-analysis', 'operator-theory', 'spectral-theory', 'compact-operators']"
52,The operator $U$ is unitary,The operator  is unitary,U,"If $A$ is a selft-adjoint operator, then the operator $U$ defined by \begin{eqnarray*} U=(A-iI)(A+iI)^{-1} \end{eqnarray*} Is unitary. I know if $U$ is unitary then $U^{*}U=UU^{*}=I$ But when i tried to compute: \begin{eqnarray*} U^{*}U&=&{((A+iI)^{-1})}^{*}(A-iI)^{*}(A-iI)(A+iI)^{-1}\\\ &=&{((A+iI)^{-1})}^{*}(A^{*}-iI^{*})(A-iI)(A+iI)^{-1} \end{eqnarray*} or I tried to compute $UU^{*}$ : \begin{eqnarray*} UU^{*}&=&{(A-iI)(A+iI)^{-1}((A+iI)^{-1})}^{*}(A-iI)^{*}\\\ &=&{(A-iI)(A+iI)^{-1}((A+iI)^{-1})}^{*}(A^{*}-iI^{*}) \end{eqnarray*} I don't know how can I continue with the hypothesis that $A$ is selft-adjoin operator and the way that I have to treat the adjoint inverse. Can you give some hint to continue? Thank you","If is a selft-adjoint operator, then the operator defined by Is unitary. I know if is unitary then But when i tried to compute: or I tried to compute : I don't know how can I continue with the hypothesis that is selft-adjoin operator and the way that I have to treat the adjoint inverse. Can you give some hint to continue? Thank you","A U \begin{eqnarray*}
U=(A-iI)(A+iI)^{-1}
\end{eqnarray*} U U^{*}U=UU^{*}=I \begin{eqnarray*}
U^{*}U&=&{((A+iI)^{-1})}^{*}(A-iI)^{*}(A-iI)(A+iI)^{-1}\\\
&=&{((A+iI)^{-1})}^{*}(A^{*}-iI^{*})(A-iI)(A+iI)^{-1}
\end{eqnarray*} UU^{*} \begin{eqnarray*}
UU^{*}&=&{(A-iI)(A+iI)^{-1}((A+iI)^{-1})}^{*}(A-iI)^{*}\\\
&=&{(A-iI)(A+iI)^{-1}((A+iI)^{-1})}^{*}(A^{*}-iI^{*})
\end{eqnarray*} A","['functional-analysis', 'analysis', 'operator-theory', 'self-adjoint-operators']"
53,For discrete group $G$ and $H\leq G$. Show that $G$ also satisfies the Folner condition if $H$ satisfies it and $[G:H]<\infty$. [closed],For discrete group  and . Show that  also satisfies the Folner condition if  satisfies it and . [closed],G H\leq G G H [G:H]<\infty,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question A finitely generated group $G=\langle S \rangle$ is said to have the Folner condition if $\forall \varepsilon>0$ , there exists a finite subset $F\subset G$ such that $$\#((S\cup S^{-1})F\setminus F)<\varepsilon\# F,$$ where $\#S$ is the cardinality of a set $S$ . Or equivalently, $\forall\varepsilon>0$ , for any finite $T\subset G$ , there exists a finite $F\subset G$ such that $$\#(TF\setminus F)<\varepsilon\#F.$$ Let $G$ be a discrete group and let H be a subgroup of $G$ . Suppose that the index $[G:H]$ is finite and that $H$ satisfies the Folner condition. Prove that $G$ also satisfies the Folner condition.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question A finitely generated group is said to have the Folner condition if , there exists a finite subset such that where is the cardinality of a set . Or equivalently, , for any finite , there exists a finite such that Let be a discrete group and let H be a subgroup of . Suppose that the index is finite and that satisfies the Folner condition. Prove that also satisfies the Folner condition.","G=\langle S \rangle \forall \varepsilon>0 F\subset G \#((S\cup S^{-1})F\setminus F)<\varepsilon\# F, \#S S \forall\varepsilon>0 T\subset G F\subset G \#(TF\setminus F)<\varepsilon\#F. G G [G:H] H G","['functional-analysis', 'group-theory', 'geometric-group-theory', 'amenability', 'geometric-functional-analysis']"
54,Is the set of essentially bounded and not-necessarily-measurable functions a Banach space?,Is the set of essentially bounded and not-necessarily-measurable functions a Banach space?,,"Suppose that $(\Omega, \mathcal{F}, \mu)$ is a probability space and for $f : \Omega \to \mathbb{R}$ define $$\DeclareMathOperator{esssup}{ess\,sup} \esssup f = \inf_{A : \mu(A) = 0} \sup_{x \notin A} f(x). $$ To me it seems that a short elementary argument shows that for measurable $f$ this agrees with the usual definition of the essential supremum, yet there is nothing in the definition that requires $f$ to be measurable. Is it true that the set of equivalences classes of a.e. equal, bounded $\mathbb{R}$ -valued functions on $\Omega$ is a Banach space when equipped with the norm $\|f\| = \esssup |f|$ ?","Suppose that is a probability space and for define To me it seems that a short elementary argument shows that for measurable this agrees with the usual definition of the essential supremum, yet there is nothing in the definition that requires to be measurable. Is it true that the set of equivalences classes of a.e. equal, bounded -valued functions on is a Banach space when equipped with the norm ?","(\Omega, \mathcal{F}, \mu) f : \Omega \to \mathbb{R} \DeclareMathOperator{esssup}{ess\,sup}
\esssup f = \inf_{A : \mu(A) = 0} \sup_{x \notin A} f(x).
 f f \mathbb{R} \Omega \|f\| = \esssup |f|","['functional-analysis', 'measure-theory']"
55,"Compact operator $T_{A,B}$",Compact operator,"T_{A,B}","Let $A,B \in \mathcal{B}(X)$ where $X$ is a Banach space. Define $T_{A,B}: \mathcal{B}(X) \rightarrow \mathcal{B}(X)$ by $T_{A,B}(S)=ASB$ . Prove that if $A$ and $B$ are compact then $T_{A,B}$ is compact. I consider a bounded sequence $\{S_n\}$ in $\mathcal{B}(X)$ but I can't find a subsequence of $T_{A,B}(S_n)$ such that is convergent. Any hint?",Let where is a Banach space. Define by . Prove that if and are compact then is compact. I consider a bounded sequence in but I can't find a subsequence of such that is convergent. Any hint?,"A,B \in \mathcal{B}(X) X T_{A,B}: \mathcal{B}(X) \rightarrow \mathcal{B}(X) T_{A,B}(S)=ASB A B T_{A,B} \{S_n\} \mathcal{B}(X) T_{A,B}(S_n)","['functional-analysis', 'compact-operators']"
56,Extension of trace preserving $*$-homomorphisms on dense subalgebras of von Neumann algebras.,Extension of trace preserving -homomorphisms on dense subalgebras of von Neumann algebras.,*,"Let $(\mathcal{M}, \tau)$ be a tracial von Neumann algebra, that is, $\tau$ is a faithful normal trace on $\mathcal{M}$ . Let $S$ be a WOT dense unital $*$ -subalgebra of $\mathcal{M}$ . Given another tracial von Neumann algebra $(\mathcal{N}, \nu)$ and an algebraic $*$ -homomorphism $\varphi: S \to \mathcal{N}$ that preserves the trace ( $\nu \circ \varphi =\tau$ ), can we always extend $\varphi$ to a a trace preserving $*$ -homomrphism from $\mathcal{M}$ to $\mathcal{N}$ ? This situation has arised many times when dealing with separable von Neumann algebras, where $\varphi$ is defined on some countable dense subalgebra, and one would like to extend to all of $\mathcal{M}$ (for example, when $\mathcal{M} = L(\Gamma)$ for some countable group $\Gamma$ , and $S$ is the algebra generated by the canonical unitaries $\{u_\gamma \vert \gamma \in \Gamma\}$ ). Yet for some reason, in the literature I encountered, this is often ignored or considered as trivial. My approach for explaining this was using the 2-norms induced by the traces $\Vert x \Vert_{2,\tau} = \tau (x^*x), \; \Vert \cdot \Vert_{2, \nu}$ , which turn out to be complete on the unit balls of $\mathcal{M, N}$ , and capture the WOT density of $S$ . However, I hit a severe roadblock since I do not assume $\varphi$ respects the operator norm in any way, and I do not see how in general trace preservation should say something about this. Any reference or help will be greatly appreciated.","Let be a tracial von Neumann algebra, that is, is a faithful normal trace on . Let be a WOT dense unital -subalgebra of . Given another tracial von Neumann algebra and an algebraic -homomorphism that preserves the trace ( ), can we always extend to a a trace preserving -homomrphism from to ? This situation has arised many times when dealing with separable von Neumann algebras, where is defined on some countable dense subalgebra, and one would like to extend to all of (for example, when for some countable group , and is the algebra generated by the canonical unitaries ). Yet for some reason, in the literature I encountered, this is often ignored or considered as trivial. My approach for explaining this was using the 2-norms induced by the traces , which turn out to be complete on the unit balls of , and capture the WOT density of . However, I hit a severe roadblock since I do not assume respects the operator norm in any way, and I do not see how in general trace preservation should say something about this. Any reference or help will be greatly appreciated.","(\mathcal{M}, \tau) \tau \mathcal{M} S * \mathcal{M} (\mathcal{N}, \nu) * \varphi: S \to \mathcal{N} \nu \circ \varphi =\tau \varphi * \mathcal{M} \mathcal{N} \varphi \mathcal{M} \mathcal{M} = L(\Gamma) \Gamma S \{u_\gamma \vert \gamma \in \Gamma\} \Vert x \Vert_{2,\tau} = \tau (x^*x), \; \Vert \cdot \Vert_{2, \nu} \mathcal{M, N} S \varphi","['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
57,Derivative of trace function,Derivative of trace function,,"$\DeclareMathOperator{\tr}{tr}$ Let $A,B$ be self-adjoint matrices and $f$ be a real differentiable function on $\mathbb{R}$ with derivative $f'$ . Then why is it true that $$ \left.\ \frac{d}{dt}\right|_0 \tr f(A+tB)=\tr (f'(A)B) $$ This is used in the Klein's inequality . However, I'm not sure why exactly this is true in general. It's pretty clear why it's true for polnomials since we can use the commutation relation of the trace function, but it's harder to justify in general. I also checked the linked reference (E. Carlen, Trace Inequalities and Quantum Entropy: An Introductory Course, Contemp. Math. 529 (2010) 73–140) with no luck, as the author didn't give much explanation. EDIT : After some further thought, let me provide an incomplete proof of what I got so far. Hopefully someone with better knowledge can finish the proof. For simplicity, let $\lambda_i(A)$ denote the eigenvalues of $A$ in descending order, i.e., $\lambda_1(A) \ge \cdots \ge \lambda_d (A)$ . Then $$ \tr \left( \frac{f(A+tB)-f(A)}{t}\right) = \sum_i \frac{1}{t}[f(\lambda_i(A+tB)-f(\lambda_i(A))] $$ Notice that by Weyl's inequality (stability of eigenvalues), we see that $|\lambda_i(A+tB)-\lambda_i(A)|\le t||B||$ . Hence, using an $\epsilon,\delta$ arguement, we can replace the above with $$ \sum_i \frac{1}{t}(\lambda_i(A+tB)-\lambda_i(A)) f'(\lambda_i(A)) $$ Now first assume that $A$ has a simple spectrum, then $A+tB$ is also simple for sufficiently small $t$ . Then by Hadarmard's variation formula, we see that $$ \frac{1}{t}(\lambda_i(A+tB)-\lambda_i(A)) \to \langle i|B| i\rangle $$ where $|i\rangle$ is the corresponding eigenvector (unique up to phase since we are assuming that $A$ is simple) to $\lambda_i(A)$ . Plugging all this back in, we see that the formula at least holds when $A$ is simple. EDIT 2 . I think I now have a way of dealing with degenerate eigenvalues. I will provide a sketch and fill in the details later (if someone else doesn't point out an error). Let $\lambda_1 (A)=\cdots =\lambda_r(A)$ be the degenerate eigenvalues. Then for sufficiently small $t$ , the eigenvalues $\lambda_i (A+tB),i=1,...,r$ will not touch the other eigenvalues (Weyl's inequality again). Let us use the Riesz projector $$ P_A =\frac{1}{2\pi i} \oint_\Gamma \frac{dz}{A-z} $$ where $\Gamma$ is some ""smooth"" contour around the $\lambda_1 (A)=\cdots =\lambda_r(A)$ and its interior does not contain any other eigenvalues. By Weyl's inequality, we can assume that $\lambda_i(A+tB),i=1,...,r$ are still in the interior of $\Gamma$ for sufficiently small $t$ . Notice that $$ \frac{d}{dt} \Big|_0 \tr {((A+tB)P_{A+tB})} = \tr(BP_A) $$ where I got some inspiration from @Ruy's comment and used the fact that \begin{align} \frac{d}{dt}\Big|_0 \tr{(A(P_{A+tB}-P_A))}&=\tr A\oint_\Gamma \frac{dz}{(z-A)^2}B \\ &= \sum_{i=1}^r \oint_\Gamma \lambda_i(A)\frac{1}{(z-\lambda_i(A))^2} dz \langle i|B|i\rangle \\ &=0 \end{align} Hence, if we combine this with the previous part, we see that the equality holds. My proof is a little convoluted, so I would still hope to see a more straightforward approach","Let be self-adjoint matrices and be a real differentiable function on with derivative . Then why is it true that This is used in the Klein's inequality . However, I'm not sure why exactly this is true in general. It's pretty clear why it's true for polnomials since we can use the commutation relation of the trace function, but it's harder to justify in general. I also checked the linked reference (E. Carlen, Trace Inequalities and Quantum Entropy: An Introductory Course, Contemp. Math. 529 (2010) 73–140) with no luck, as the author didn't give much explanation. EDIT : After some further thought, let me provide an incomplete proof of what I got so far. Hopefully someone with better knowledge can finish the proof. For simplicity, let denote the eigenvalues of in descending order, i.e., . Then Notice that by Weyl's inequality (stability of eigenvalues), we see that . Hence, using an arguement, we can replace the above with Now first assume that has a simple spectrum, then is also simple for sufficiently small . Then by Hadarmard's variation formula, we see that where is the corresponding eigenvector (unique up to phase since we are assuming that is simple) to . Plugging all this back in, we see that the formula at least holds when is simple. EDIT 2 . I think I now have a way of dealing with degenerate eigenvalues. I will provide a sketch and fill in the details later (if someone else doesn't point out an error). Let be the degenerate eigenvalues. Then for sufficiently small , the eigenvalues will not touch the other eigenvalues (Weyl's inequality again). Let us use the Riesz projector where is some ""smooth"" contour around the and its interior does not contain any other eigenvalues. By Weyl's inequality, we can assume that are still in the interior of for sufficiently small . Notice that where I got some inspiration from @Ruy's comment and used the fact that Hence, if we combine this with the previous part, we see that the equality holds. My proof is a little convoluted, so I would still hope to see a more straightforward approach","\DeclareMathOperator{\tr}{tr} A,B f \mathbb{R} f' 
\left.\ \frac{d}{dt}\right|_0 \tr f(A+tB)=\tr (f'(A)B)
 \lambda_i(A) A \lambda_1(A) \ge \cdots \ge \lambda_d (A) 
\tr \left( \frac{f(A+tB)-f(A)}{t}\right) = \sum_i \frac{1}{t}[f(\lambda_i(A+tB)-f(\lambda_i(A))]
 |\lambda_i(A+tB)-\lambda_i(A)|\le t||B|| \epsilon,\delta 
\sum_i \frac{1}{t}(\lambda_i(A+tB)-\lambda_i(A)) f'(\lambda_i(A))
 A A+tB t 
\frac{1}{t}(\lambda_i(A+tB)-\lambda_i(A)) \to \langle i|B| i\rangle
 |i\rangle A \lambda_i(A) A \lambda_1 (A)=\cdots =\lambda_r(A) t \lambda_i (A+tB),i=1,...,r 
P_A =\frac{1}{2\pi i} \oint_\Gamma \frac{dz}{A-z}
 \Gamma \lambda_1 (A)=\cdots =\lambda_r(A) \lambda_i(A+tB),i=1,...,r \Gamma t 
\frac{d}{dt} \Big|_0 \tr {((A+tB)P_{A+tB})} = \tr(BP_A)
 \begin{align}
\frac{d}{dt}\Big|_0 \tr{(A(P_{A+tB}-P_A))}&=\tr A\oint_\Gamma \frac{dz}{(z-A)^2}B \\
&= \sum_{i=1}^r \oint_\Gamma \lambda_i(A)\frac{1}{(z-\lambda_i(A))^2} dz \langle i|B|i\rangle \\
&=0
\end{align}","['real-analysis', 'functional-analysis']"
58,Can all linear operators be represented as matrices? (In infinite dimension.),Can all linear operators be represented as matrices? (In infinite dimension.),,"Old title : Components of unbounded endomorphism wrt Schauder basis? Changed for discoverarbility. In finite-dimensional linear algebra, given an endomorphism $T$ and a basis $\boldsymbol{e}_i$ , we can easily find a matrix representation of $T$ : $$  T(v)  = T(\sum_i v^i \, \boldsymbol{e}_i)  \overset{*}{=} \sum_i T(v^i \, \boldsymbol{e}_i)  = \sum_i v^i T(\boldsymbol{e}_i)  =: \sum_{i,j} v^i \, T_{ij} \, \boldsymbol{e}_j $$ Let us now assume that $X$ is a separable Banach space with a Schauder basis $\{\boldsymbol{e_i}\}_{i \in \mathbb{N}}$ and $T: X \to X$ is an unbounded linear operator. If we try to replicate the previous equation, the sum will become infinite, and since for unbounded operators $T(\lim_n v_n) = \lim_n T(v_n)$ doesn't hold, the equality $(\overset{*}{=})$ above doesn't hold. This would seem to indicate that unbounded operators don't have a coordinate representation in a Schauder basis, at least not in the same sense as bounded operators do. Or is there a simple generalization that I just don't see? If we now consider $X$ to be a separable Hilbert space and $\boldsymbol{e}_i$ an orthonormal basis, we know that it's isomorphic to $\ell_2$ with basis: $$   \begin{pmatrix}1\\0\\0\\\vdots\end{pmatrix},   \begin{pmatrix}0\\1\\0\\\vdots\end{pmatrix},   \begin{pmatrix}0\\0\\1\\\vdots\end{pmatrix},   \;\dots $$ This means that either the endomorphisms on the space of „infinite column vectors“ aren't always „infinite matrices“, or that my previous conclusion about the „non-representability“ of unbounded operators was wrong. Which of these is true? In summary, these are my questions: Is it possible to represent an unbounded operator using its coordinates wrt. a Schauder basis of a separable Banach/Hilbert space? If yes, how? If no, are there other practical ways to represent it? (Eg. using Hamel basis? Or as an integral kernel on $L^p$ ?) Are all operators on $\ell_2$ „infinite matrices“?","Old title : Components of unbounded endomorphism wrt Schauder basis? Changed for discoverarbility. In finite-dimensional linear algebra, given an endomorphism and a basis , we can easily find a matrix representation of : Let us now assume that is a separable Banach space with a Schauder basis and is an unbounded linear operator. If we try to replicate the previous equation, the sum will become infinite, and since for unbounded operators doesn't hold, the equality above doesn't hold. This would seem to indicate that unbounded operators don't have a coordinate representation in a Schauder basis, at least not in the same sense as bounded operators do. Or is there a simple generalization that I just don't see? If we now consider to be a separable Hilbert space and an orthonormal basis, we know that it's isomorphic to with basis: This means that either the endomorphisms on the space of „infinite column vectors“ aren't always „infinite matrices“, or that my previous conclusion about the „non-representability“ of unbounded operators was wrong. Which of these is true? In summary, these are my questions: Is it possible to represent an unbounded operator using its coordinates wrt. a Schauder basis of a separable Banach/Hilbert space? If yes, how? If no, are there other practical ways to represent it? (Eg. using Hamel basis? Or as an integral kernel on ?) Are all operators on „infinite matrices“?","T \boldsymbol{e}_i T 
 T(v)
 = T(\sum_i v^i \, \boldsymbol{e}_i)
 \overset{*}{=} \sum_i T(v^i \, \boldsymbol{e}_i)
 = \sum_i v^i T(\boldsymbol{e}_i)
 =: \sum_{i,j} v^i \, T_{ij} \, \boldsymbol{e}_j
 X \{\boldsymbol{e_i}\}_{i \in \mathbb{N}} T: X \to X T(\lim_n v_n) = \lim_n T(v_n) (\overset{*}{=}) X \boldsymbol{e}_i \ell_2 
  \begin{pmatrix}1\\0\\0\\\vdots\end{pmatrix},
  \begin{pmatrix}0\\1\\0\\\vdots\end{pmatrix},
  \begin{pmatrix}0\\0\\1\\\vdots\end{pmatrix},
  \;\dots
 L^p \ell_2","['linear-algebra', 'functional-analysis', 'hilbert-spaces', 'banach-spaces', 'schauder-basis']"
59,Compute the $n$-fold iteration of an indefinite integral operator using integration by parts and induction.,Compute the -fold iteration of an indefinite integral operator using integration by parts and induction.,n,"Consider the following integral operator $T:L^2([0,2])\longrightarrow L^{2}([0,2])$ defined by $$(Tf)(x)=\int_0^x f(y)\,dy.$$ Page 230 of Peter Lax's functional analysis claimed that the $n$ -fold iterate of $T$ is given by the formula: $$(T^n f)(x)=\dfrac{1}{(n-1)!}\int_0^x (x-r)^{n-1}f(r) \, dr, \text{ for } x\in [0,1].$$ And he said that this can be proved using induction and integration by parts. So I followed his instruction:  Suppose this holds for a fixed $n$ , and we prove it is true for $n+1$ . By definition, for $x\in [0,1]$ , \begin{align*} & (T^{n+1}f)(x)=T((T^{n}f)(x))=\int_0^x (T^{n}f)(y) \, dy \\[8pt] = {} &\int_0^x \Big(\frac{1}{(n-1)!}\int_0^y(y-r)^{n-1}f(r) \, dr\Big) \, dy\\[8pt] = {} & \frac{1}{(n-1)!}\int_0^x \int_0^y (y-r)^{n-1}f(r) \,dr\,dy. \end{align*} For fixed $y\in [0,1]$ , we deal with the inner integral $\int_0^y (y-r)^{n-1} f(r) \, dr$ .  Consider $u:=f(r)$ so that $du=f'(r) \, dr$ , and $dv:=(y-r)^{n-1} \, dr$ so that $v=-\frac{1}{n}(y-r)^{n}.$ Then, using integration by parts, we have $$\int_{0}^{y}(y-r)^{n-1}f(r) \, dr=-\frac{1}{n}(y-r)^n f(r)+\int_0^1\frac{1}{n}(y-r)^n f'(r) \, dr.$$ Then, I focused on $\frac{1}{n}\int_0^1 (y-r)^{n}f'(r) \, dr$ . Consider $dv:=f'(r)\,dr$ so that $f(r)=v$ , and $u:=(y-r)^{n}$ so that $du=-n(y-r)^{n-1} \, dr.$ Using integration by parts, we have $$\dfrac{1}{n} \int_0^1 (y-r)^{n}f'(r) \, dr = \frac{1}{n}(y-r)^n f(r)+\frac{1}{n}\cdot n\int_0^1 (y-r)^{n-1} \, dr.$$ So if we plug this back into above, it seems I just proved $0=0$ . What should I do? Did I even have a wrong start? Thank you!","Consider the following integral operator defined by Page 230 of Peter Lax's functional analysis claimed that the -fold iterate of is given by the formula: And he said that this can be proved using induction and integration by parts. So I followed his instruction:  Suppose this holds for a fixed , and we prove it is true for . By definition, for , For fixed , we deal with the inner integral .  Consider so that , and so that Then, using integration by parts, we have Then, I focused on . Consider so that , and so that Using integration by parts, we have So if we plug this back into above, it seems I just proved . What should I do? Did I even have a wrong start? Thank you!","T:L^2([0,2])\longrightarrow L^{2}([0,2]) (Tf)(x)=\int_0^x f(y)\,dy. n T (T^n f)(x)=\dfrac{1}{(n-1)!}\int_0^x (x-r)^{n-1}f(r) \, dr, \text{ for } x\in [0,1]. n n+1 x\in [0,1] \begin{align*}
& (T^{n+1}f)(x)=T((T^{n}f)(x))=\int_0^x (T^{n}f)(y) \, dy \\[8pt]
= {} &\int_0^x \Big(\frac{1}{(n-1)!}\int_0^y(y-r)^{n-1}f(r) \, dr\Big) \, dy\\[8pt]
= {} & \frac{1}{(n-1)!}\int_0^x \int_0^y (y-r)^{n-1}f(r) \,dr\,dy.
\end{align*} y\in [0,1] \int_0^y (y-r)^{n-1} f(r) \, dr u:=f(r) du=f'(r) \, dr dv:=(y-r)^{n-1} \, dr v=-\frac{1}{n}(y-r)^{n}. \int_{0}^{y}(y-r)^{n-1}f(r) \, dr=-\frac{1}{n}(y-r)^n f(r)+\int_0^1\frac{1}{n}(y-r)^n f'(r) \, dr. \frac{1}{n}\int_0^1 (y-r)^{n}f'(r) \, dr dv:=f'(r)\,dr f(r)=v u:=(y-r)^{n} du=-n(y-r)^{n-1} \, dr. \dfrac{1}{n} \int_0^1 (y-r)^{n}f'(r) \, dr = \frac{1}{n}(y-r)^n f(r)+\frac{1}{n}\cdot n\int_0^1 (y-r)^{n-1} \, dr. 0=0","['real-analysis', 'integration', 'functional-analysis', 'operator-theory']"
60,exact meaning of uniform integrability for empirical distributions,exact meaning of uniform integrability for empirical distributions,,"Suppose we have $n$ non-negative integer-valued random variables $X_1,\ldots,X_n$ and consider the empirical distribution $$Q := \frac{1}{n}\sum_{i=1}^n \delta_{X_i}.$$ We equip any probability mass function $q \in \mathcal{P}(\mathbb{Z}_+)$ with the usual $\ell^1$ norm $\|q\|:= \sum_{k=0}^\infty q_k$ . I am confused on the precise meaning of the statement that the empirical distribution $Q$ is uniformly integrable (notice that $Q$ depends on $n$ ). In the typical setting, we say that a collection of random variables $(X_n~\colon n \in \mathbb N)$ is U.I. (Uniformly Integrable) if there exists some $K >0$ so that $\sup_{n\in \mathbb N} \mathbb{E}(|X_n|\mathbf{1}_{|X_n| \geq K}) < \epsilon$ for each pre-fixed $\epsilon > 0$ . But how does this general definition translates into the aforementioned setting really bothers me... Thanks for any help!","Suppose we have non-negative integer-valued random variables and consider the empirical distribution We equip any probability mass function with the usual norm . I am confused on the precise meaning of the statement that the empirical distribution is uniformly integrable (notice that depends on ). In the typical setting, we say that a collection of random variables is U.I. (Uniformly Integrable) if there exists some so that for each pre-fixed . But how does this general definition translates into the aforementioned setting really bothers me... Thanks for any help!","n X_1,\ldots,X_n Q := \frac{1}{n}\sum_{i=1}^n \delta_{X_i}. q \in \mathcal{P}(\mathbb{Z}_+) \ell^1 \|q\|:= \sum_{k=0}^\infty q_k Q Q n (X_n~\colon n \in \mathbb N) K >0 \sup_{n\in \mathbb N} \mathbb{E}(|X_n|\mathbf{1}_{|X_n| \geq K}) < \epsilon \epsilon > 0","['real-analysis', 'functional-analysis', 'probability-theory']"
61,Proving Positivity of Extension of Linear Functional on $C(X)$,Proving Positivity of Extension of Linear Functional on,C(X),"Question I am currently working through Royden's proof that any continuous linear operator $L$ on $C(X)$ can be written as the difference of two positive linear functionals on $C(X)$ , where $X$ is a compact Hausdorff space equipped with the maximum norm. The proof starts by showing that $L_+ : C(X) \to \mathbb{R}$ with $$ L_+(f) := \sup_{0 \leq \psi \leq f}L(\psi)$$ is a non-negative functional when restricted to the non-negative elements of $C(X)$ . To extend this definition to arbitrary $f \in C(X)$ , Royden starts by choosing $M \geq 0$ such that $f + M \geq 0$ (which can be done since $f$ is bounded). He then shows that $L_+(f+M) - L_+(M)$ is independent of the choice of $M$ , and accordingly defines $L_+(f)$ to be this value. He then claims that under this definition, ""clearly $L_+(f):C(X) \to \mathbb{R}$ is positive."" I am having a hard time showing this last fact, and would appreciate any insight into how to show this. My work so far My best approach has been to split $f = f^+ - f^-$ . Then \begin{align} L_+(f + M) - L_+(M) &= L_+(f^+ - f^- + M) - L_+(M) \\ &= L_+(f^+) - L_+(M) + L_+(M-f^-). \end{align} The second step follows from The linearity of $L_+$ when restricted to non-negative functions on $C(X)$ $f^- \leq M$ since $f + M \geq 0$ $f^+$ and $f^-$ are in $C(X)$ and non-negative. Now the third term on the RHS is non-negative by construction of $L_+$ thus far. However, I can't quite demonstrate whether the difference of the first and second terms is also non-negative. Please let me know if I can provide any additional information. Thanks!","Question I am currently working through Royden's proof that any continuous linear operator on can be written as the difference of two positive linear functionals on , where is a compact Hausdorff space equipped with the maximum norm. The proof starts by showing that with is a non-negative functional when restricted to the non-negative elements of . To extend this definition to arbitrary , Royden starts by choosing such that (which can be done since is bounded). He then shows that is independent of the choice of , and accordingly defines to be this value. He then claims that under this definition, ""clearly is positive."" I am having a hard time showing this last fact, and would appreciate any insight into how to show this. My work so far My best approach has been to split . Then The second step follows from The linearity of when restricted to non-negative functions on since and are in and non-negative. Now the third term on the RHS is non-negative by construction of thus far. However, I can't quite demonstrate whether the difference of the first and second terms is also non-negative. Please let me know if I can provide any additional information. Thanks!","L C(X) C(X) X L_+ : C(X) \to \mathbb{R}  L_+(f) := \sup_{0 \leq \psi \leq f}L(\psi) C(X) f \in C(X) M \geq 0 f + M \geq 0 f L_+(f+M) - L_+(M) M L_+(f) L_+(f):C(X) \to \mathbb{R} f = f^+ - f^- \begin{align}
L_+(f + M) - L_+(M) &= L_+(f^+ - f^- + M) - L_+(M) \\
&= L_+(f^+) - L_+(M) + L_+(M-f^-).
\end{align} L_+ C(X) f^- \leq M f + M \geq 0 f^+ f^- C(X) L_+",['functional-analysis']
62,"Unitisation of an algebra: Is the norm $\text{max}\lbrace\|a\|_A,|\lambda|\rbrace$ submultiplicative?",Unitisation of an algebra: Is the norm  submultiplicative?,"\text{max}\lbrace\|a\|_A,|\lambda|\rbrace","I feel as if I may have missed something really obvious here. It says in my notes that if $A$ is an algebra (over $\mathbb{C}$ ), then its unitisation $A^1:=A\times\mathbb{C}$ is a unital algebra with respect to the multiplication $$(a,\lambda)(b,\mu):=(ab+\lambda b+\mu a,\lambda\mu)$$ and that if $A$ is a normed algebra (with submultiplicative norm $\|\cdot\|_A$ ), this becomes a normed algebra with respect to the norm $$\|(a,\lambda)\|_\infty:=\text{max}\lbrace\|a\|_A,|\lambda|\rbrace$$ To prove that $\|\cdot\|_\infty$ is submultiplicative, we have to prove that $$\text{max}\lbrace\|ab+\lambda b+\mu a\|_A,|\lambda|\,|\mu|\rbrace\leq\text{max}\lbrace\|a\|_A,|\lambda|\rbrace\text{max}\lbrace\|b\|_A,|\mu|\rbrace.$$ If $\|ab+\lambda b+\mu a\|_A\leq|\lambda|\,|\mu|$ , then this is obvious, but what about if $\|ab+\lambda b+\mu a\|_A>|\lambda|\,|\mu|$ ? EDIT: Just to clarify, I'm not 100% sure if this result is true or not, it just seems to implicitly suggest that it is true in notes I am reading.","I feel as if I may have missed something really obvious here. It says in my notes that if is an algebra (over ), then its unitisation is a unital algebra with respect to the multiplication and that if is a normed algebra (with submultiplicative norm ), this becomes a normed algebra with respect to the norm To prove that is submultiplicative, we have to prove that If , then this is obvious, but what about if ? EDIT: Just to clarify, I'm not 100% sure if this result is true or not, it just seems to implicitly suggest that it is true in notes I am reading.","A \mathbb{C} A^1:=A\times\mathbb{C} (a,\lambda)(b,\mu):=(ab+\lambda b+\mu a,\lambda\mu) A \|\cdot\|_A \|(a,\lambda)\|_\infty:=\text{max}\lbrace\|a\|_A,|\lambda|\rbrace \|\cdot\|_\infty \text{max}\lbrace\|ab+\lambda b+\mu a\|_A,|\lambda|\,|\mu|\rbrace\leq\text{max}\lbrace\|a\|_A,|\lambda|\rbrace\text{max}\lbrace\|b\|_A,|\mu|\rbrace. \|ab+\lambda b+\mu a\|_A\leq|\lambda|\,|\mu| \|ab+\lambda b+\mu a\|_A>|\lambda|\,|\mu|","['functional-analysis', 'normed-spaces', 'banach-algebras', 'algebras']"
63,Spectral theory and Taylor expansion in quantum mechanics for unbounded operators,Spectral theory and Taylor expansion in quantum mechanics for unbounded operators,,"I am reading spectral theory and quantum mechanics. We know that for an unbounded self-adjoint operator $A$ , operator-valued functions such as $\exp(iAt)$ , $t\in\mathbb{R}$ can be defined using spectral theorems. It seems to me that there does not exist a Taylor expansion for the exponentiation here i.e. we cannot write \begin{equation}  \exp(iAt) = \sum_n \frac{(iAt)^n}{n!}. \end{equation} However, in quantum mechanics, people always consider the case of Taylor expanding to obtain a perturbation theory. How is perturbation theory consistent with the spectral theory? Take, for example, the following simple (1+1)D Schrodinger Hamiltonian: \begin{equation} H = \frac{\hat{p}^2}{2m} + V(x) =: H_0 + V, \end{equation} where $\hat{p} = - i \hbar \partial_x$ and some (unbounded) potential $V(x)$ . How could we justify the expansion of an $U$ -matrix: \begin{equation}  U(t) := \exp(i H_0 t /\hbar )\exp(-i H t / \hbar) \to \sum_n \frac{(iVt/\hbar)^n}{n!},  \end{equation} in general?","I am reading spectral theory and quantum mechanics. We know that for an unbounded self-adjoint operator , operator-valued functions such as , can be defined using spectral theorems. It seems to me that there does not exist a Taylor expansion for the exponentiation here i.e. we cannot write However, in quantum mechanics, people always consider the case of Taylor expanding to obtain a perturbation theory. How is perturbation theory consistent with the spectral theory? Take, for example, the following simple (1+1)D Schrodinger Hamiltonian: where and some (unbounded) potential . How could we justify the expansion of an -matrix: in general?","A \exp(iAt) t\in\mathbb{R} \begin{equation}
 \exp(iAt) = \sum_n \frac{(iAt)^n}{n!}.
\end{equation} \begin{equation}
H = \frac{\hat{p}^2}{2m} + V(x) =: H_0 + V,
\end{equation} \hat{p} = - i \hbar \partial_x V(x) U \begin{equation}
 U(t) := \exp(i H_0 t /\hbar )\exp(-i H t / \hbar) \to \sum_n \frac{(iVt/\hbar)^n}{n!}, 
\end{equation}","['functional-analysis', 'spectral-theory', 'quantum-mechanics']"
64,A problem on Left Hilbert algebra.,A problem on Left Hilbert algebra.,,"I got stuck with the following problem while going through Section 10.1 from the book 'Lectures on von Neumann Algebras' by Strătilă and Zsidó. Let $\mathfrak{A}$ be a complex algebra with involution, which is also endowed with a scalar product $\langle\cdot | \cdot\rangle$ . We denote by $\xi\mapsto\xi^{\text{#}}$ the involution in $\mathfrak{A}$ and by $\mathscr{H}$ the Hilbert space obtained by the completion of $\mathfrak{A}$ . We denote by $\mathfrak{A}^2$ the vector space generated by the elements of the form $\xi\eta,\,\xi,\,\eta\in\mathfrak{A}$ . One says that $\mathfrak{A}$ is a left Hilbert algebra if $\mathfrak{A}\ni\eta\mapsto\xi\eta\in\mathfrak{A}$ is continuous, for any $\xi\in\mathfrak{A}$ . $\langle\xi\eta_1|\eta_2\rangle=\langle\eta_1|\xi^{\text{#}}\eta_2\rangle$ for any $\xi,\,\eta_1,\,\eta_2\in\mathfrak{A}$ . $\mathfrak{A}^2$ is dense in $\mathfrak{A}$ . $\mathscr{H}\supseteq\mathfrak{A}\ni\xi\mapsto\xi^{\text{#}}\in\mathscr{H}$ is a preclosed antilinear operator. In accordance with $1$ , for any $\xi\in\mathfrak{A}$ , one define $L_{\xi}\in\mathscr{B}(\mathscr{H})$ by the formula $L_{\xi}(\eta)=\xi\eta,\,\eta\in\mathfrak{A}$ . Problem: Prove that $I\in\overline{\{L_{\xi}:\xi\in\mathfrak{A}\}}^{so}$ , where $I$ is the identity map on $\mathscr{H}$ defined by $I(\eta)=\eta,\,\eta\in\mathfrak{A}$ . The authors say that it follows from property $3$ , but I am not getting how to argue that. Thanks in advance for any help.","I got stuck with the following problem while going through Section 10.1 from the book 'Lectures on von Neumann Algebras' by Strătilă and Zsidó. Let be a complex algebra with involution, which is also endowed with a scalar product . We denote by the involution in and by the Hilbert space obtained by the completion of . We denote by the vector space generated by the elements of the form . One says that is a left Hilbert algebra if is continuous, for any . for any . is dense in . is a preclosed antilinear operator. In accordance with , for any , one define by the formula . Problem: Prove that , where is the identity map on defined by . The authors say that it follows from property , but I am not getting how to argue that. Thanks in advance for any help.","\mathfrak{A} \langle\cdot | \cdot\rangle \xi\mapsto\xi^{\text{#}} \mathfrak{A} \mathscr{H} \mathfrak{A} \mathfrak{A}^2 \xi\eta,\,\xi,\,\eta\in\mathfrak{A} \mathfrak{A} \mathfrak{A}\ni\eta\mapsto\xi\eta\in\mathfrak{A} \xi\in\mathfrak{A} \langle\xi\eta_1|\eta_2\rangle=\langle\eta_1|\xi^{\text{#}}\eta_2\rangle \xi,\,\eta_1,\,\eta_2\in\mathfrak{A} \mathfrak{A}^2 \mathfrak{A} \mathscr{H}\supseteq\mathfrak{A}\ni\xi\mapsto\xi^{\text{#}}\in\mathscr{H} 1 \xi\in\mathfrak{A} L_{\xi}\in\mathscr{B}(\mathscr{H}) L_{\xi}(\eta)=\xi\eta,\,\eta\in\mathfrak{A} I\in\overline{\{L_{\xi}:\xi\in\mathfrak{A}\}}^{so} I \mathscr{H} I(\eta)=\eta,\,\eta\in\mathfrak{A} 3","['functional-analysis', 'operator-algebras', 'von-neumann-algebras']"
65,"$M$ subset of $L^2[0,1]$ that is closed and convex",subset of  that is closed and convex,"M L^2[0,1]","Let $M = \{ f \in L^2[0,1]: f([0,1]) \subset [0,1] \hspace{2mm}a.e.\}$ . Show that $M$ is a closed and convex set. My idea for it to be closed is similar to that of sequences, so I say: Let $f \in \overline M$ and let's see what $f \in M$ . Since $f \in \overline M$ there is a sequence $(f_k)^{\infty}_{k=1}$ such that $f_k \to f$ , when $k \to \infty$ , and every $f_k \in M$ . Now, we have that $\forall \epsilon > 0$ , $ \exists N(\epsilon) > 0$ such that $k> N \to \displaystyle\int^1_0 |f_k - f|^2 d\mu < \frac{\epsilon^2}{\sqrt{3}}$ . Finally by triangular inequality and $\phi(t) = |t|^2$ is increasing $$ \displaystyle\int^1_0 |f_k - f_l|^2 d\mu \le \displaystyle\int^1_0 |f_k - f^{(N)}_k|^2 d\mu + \displaystyle\int^1_0 |f^{(N)}_k - f^{(N)}_l|^2 d\mu + \displaystyle\int^1_0 |f^{(N)}_l - f_l|^2 d\mu < \epsilon^2 $$ Is my proof ok? also I do not know if convexity is inherited from what $\phi(t) = |t|^2$ is convex and increasing","Let . Show that is a closed and convex set. My idea for it to be closed is similar to that of sequences, so I say: Let and let's see what . Since there is a sequence such that , when , and every . Now, we have that , such that . Finally by triangular inequality and is increasing Is my proof ok? also I do not know if convexity is inherited from what is convex and increasing","M = \{ f \in L^2[0,1]: f([0,1]) \subset [0,1] \hspace{2mm}a.e.\} M f \in \overline M f \in M f \in \overline M (f_k)^{\infty}_{k=1} f_k \to f k \to \infty f_k \in M \forall \epsilon > 0  \exists N(\epsilon) > 0 k> N \to \displaystyle\int^1_0 |f_k - f|^2 d\mu < \frac{\epsilon^2}{\sqrt{3}} \phi(t) = |t|^2 
\displaystyle\int^1_0 |f_k - f_l|^2 d\mu \le \displaystyle\int^1_0 |f_k - f^{(N)}_k|^2 d\mu + \displaystyle\int^1_0 |f^{(N)}_k - f^{(N)}_l|^2 d\mu + \displaystyle\int^1_0 |f^{(N)}_l - f_l|^2 d\mu < \epsilon^2
 \phi(t) = |t|^2","['functional-analysis', 'measure-theory']"
66,Is every bounded operator part of a $C_0$-semigroup?,Is every bounded operator part of a -semigroup?,C_0,"Let $X$ be a Banach space and $B \in \mathcal{B}(X)$ be a bounded linear operator on $X$ . Is there necessarily a $C_0$ -semigroup $T$ such that $B = T(t)$ for some $t$ ? There might be something obvious I'm missing, but I'm not sure of a good way to approach this problem. The most obvious idea to me would be using some sort of functional calculus for bounded operators that lets you apply a logarithm, and would hopefully result in a (not necessarily bounded) generator for the desired semigroup. I am not aware of any such functional calculus though. I also can't think of a trivial ""natural exponential progression"" from the identity map to $B$ . As far as counter examples go, I know of few theorems that force specific behaviors of $C_0$ -semigroups. An obvious one to try is the $0$ operator. At least on $X = C_0[0,1)$ , though, the translation semigroup is nilpotent. This is not a homework problem or anything, just something I got curious about.","Let be a Banach space and be a bounded linear operator on . Is there necessarily a -semigroup such that for some ? There might be something obvious I'm missing, but I'm not sure of a good way to approach this problem. The most obvious idea to me would be using some sort of functional calculus for bounded operators that lets you apply a logarithm, and would hopefully result in a (not necessarily bounded) generator for the desired semigroup. I am not aware of any such functional calculus though. I also can't think of a trivial ""natural exponential progression"" from the identity map to . As far as counter examples go, I know of few theorems that force specific behaviors of -semigroups. An obvious one to try is the operator. At least on , though, the translation semigroup is nilpotent. This is not a homework problem or anything, just something I got curious about.","X B \in \mathcal{B}(X) X C_0 T B = T(t) t B C_0 0 X = C_0[0,1)","['functional-analysis', 'operator-theory', 'banach-spaces']"
67,Spectral Theorem for unbounded self adjoint operators,Spectral Theorem for unbounded self adjoint operators,,"So I've been working on the Spectral Theorem for self adjoint unbounded Operators with the Book by Rudin and got to a problem: Let $(X,\mathcal{A})$ be a measure space, $H$ a complex Hilbert space and $P:\mathcal{A}\rightarrow B(H)$ a resolution of the identity. Then, to every measurable function $f:X\rightarrow\mathbb{C}$ there exists a densely defined operator $\Psi(f)$ in $H$ , with domain $D(\Psi(f)) = \{x\in H: \int_{X} \vert f(\lambda) \vert^{2} \ d\langle P(\lambda)x,x\rangle < \infty\}$ , which is characterized by $$\langle \Psi(f)x,y\rangle = \int_{X} f(\lambda) \ d\langle P(\lambda)x,y\rangle$$ for all $x\in D(\Psi(f))$ and $y\in H$ . My problem is the following theorem: In the above situation, if $D(\Psi(f)) = H$ then $f$ is essentially bounded. $\textbf{Proof:}$ Since $\Psi(f)$ is a closed operator, the closed graph theorem implies $\Psi(f)\in B(H)$ . If $f_{n} = f\chi_{A_{n}}$ for $A_{n} = \{x\in X : \vert f(x)\vert \leq n\}$ and $n\in\mathbb{N}$ , then it follows $$\Vert f_{n}\Vert_{\infty} = \Vert \Psi(f_{n})\Vert = \Vert \Psi(f)\Psi(\chi_{A_{n}}) \Vert \leq\Vert \Psi(f) \Vert,$$ since $\Vert\Psi(\chi_{A_{n}})\Vert = \Vert \chi_{A_{n}} \Vert_{\infty}\leq 1$ . Thus $\Vert f \Vert_{\infty} \leq \Vert\Psi(f)\Vert$ and $f$ is essentially bounded. I don't know how we can conclude that $\Vert f \Vert_{\infty} \leq \Vert \Psi(f)\Vert$ , since $f_{n}\rightarrow f$ only pointwise. I also know that $\Vert \Psi(f_{n}) \Vert$ converges to $\Vert\Psi(f)\Vert$ but I can't see how that could help me. I would appreciate any help.","So I've been working on the Spectral Theorem for self adjoint unbounded Operators with the Book by Rudin and got to a problem: Let be a measure space, a complex Hilbert space and a resolution of the identity. Then, to every measurable function there exists a densely defined operator in , with domain , which is characterized by for all and . My problem is the following theorem: In the above situation, if then is essentially bounded. Since is a closed operator, the closed graph theorem implies . If for and , then it follows since . Thus and is essentially bounded. I don't know how we can conclude that , since only pointwise. I also know that converges to but I can't see how that could help me. I would appreciate any help.","(X,\mathcal{A}) H P:\mathcal{A}\rightarrow B(H) f:X\rightarrow\mathbb{C} \Psi(f) H D(\Psi(f)) = \{x\in H: \int_{X} \vert f(\lambda) \vert^{2} \ d\langle P(\lambda)x,x\rangle < \infty\} \langle \Psi(f)x,y\rangle = \int_{X} f(\lambda) \ d\langle P(\lambda)x,y\rangle x\in D(\Psi(f)) y\in H D(\Psi(f)) = H f \textbf{Proof:} \Psi(f) \Psi(f)\in B(H) f_{n} = f\chi_{A_{n}} A_{n} = \{x\in X : \vert f(x)\vert \leq n\} n\in\mathbb{N} \Vert f_{n}\Vert_{\infty} = \Vert \Psi(f_{n})\Vert = \Vert \Psi(f)\Psi(\chi_{A_{n}}) \Vert \leq\Vert \Psi(f) \Vert, \Vert\Psi(\chi_{A_{n}})\Vert = \Vert \chi_{A_{n}} \Vert_{\infty}\leq 1 \Vert f \Vert_{\infty} \leq \Vert\Psi(f)\Vert f \Vert f \Vert_{\infty} \leq \Vert \Psi(f)\Vert f_{n}\rightarrow f \Vert \Psi(f_{n}) \Vert \Vert\Psi(f)\Vert","['functional-analysis', 'spectral-theory']"
68,Absolutely convergent doubles sums in Banach spaces,Absolutely convergent doubles sums in Banach spaces,,"Let $X$ a Banach space and $x_{ij} : \mathbb{N} \times \mathbb{N} \to X$ . Suppose $\sum_i \sum_j \|x_{ij}\| < \infty$ . Then it is easy to show that the following series are convergent: $$\sum_j x_{ij}, \sum_i x_{ij}, \sum_i \sum_j x_{ij}, \sum_j \sum_i x_{ij}.$$ Then I want to know if: $$\sum_i \sum_j x_{ij} = \sum_j \sum_i x_{ij}.$$ This would be a direct corollary of a Fubini-Tonelli type theorem for Bochner integrals, but I can't find a reference on that. So if someone could point me to a reference to such a theorem for Bochner integrals, that'd be ideal (or let me know if/why such a theorem doesn't exist). But also a direct proof of the above would work.","Let a Banach space and . Suppose . Then it is easy to show that the following series are convergent: Then I want to know if: This would be a direct corollary of a Fubini-Tonelli type theorem for Bochner integrals, but I can't find a reference on that. So if someone could point me to a reference to such a theorem for Bochner integrals, that'd be ideal (or let me know if/why such a theorem doesn't exist). But also a direct proof of the above would work.","X x_{ij} : \mathbb{N} \times \mathbb{N} \to X \sum_i \sum_j \|x_{ij}\| < \infty \sum_j x_{ij}, \sum_i x_{ij}, \sum_i \sum_j x_{ij}, \sum_j \sum_i x_{ij}. \sum_i \sum_j x_{ij} = \sum_j \sum_i x_{ij}.","['real-analysis', 'functional-analysis', 'lebesgue-integral', 'banach-spaces']"
69,Motivation and Application of the Fourier Series,Motivation and Application of the Fourier Series,,"I am currently reading some material on the Fourier series. The main motivation of course is to write a periodic function as a series involving cosine and sine functions, which we understand much about. It turns out that we have some nice convergence results regarding the Fourier series and the function which we wish to compute the series for. Now the texts I am reading show that it is possible to derive solutions for PDE's by applying Fourier series methods, however, the text does not mention when such an application will work. So I am curious to find out when can someone use Fourier series methods to find solutions of PDE's? Also given a PDE is it always possible to re-write the PDE for the Fourier series? For example, suppose we consider $-\Delta u+u=f$ in $\Omega\subset\mathbb{R}^{N}$ with zero boundary conditions. What conditions must be satisfied so that $\hat{-\Delta u}+\hat{u}=\hat{f}$ in $\Omega\subset\mathbb{R}^{N}$ makes sense, with appropriate boundary conditions? Is it sufficient to take the periodic extension of, $\tilde{u}$ , on the appropriate domain $\tilde{\Omega}$ , and hence we can always consider the ""transformed"" PDE? Is it necessary for the differential operator to have eigenfunctions which form an orthonormal basis of $L^{2}(\Omega)$ ? I understand that for any periodic function one can always take the Fourier series. However, it is not clear to me under what conditions one can consider solutions of a PDE  as a Fourier series and more specifically, when one can consider the ""transformed"" PDE.","I am currently reading some material on the Fourier series. The main motivation of course is to write a periodic function as a series involving cosine and sine functions, which we understand much about. It turns out that we have some nice convergence results regarding the Fourier series and the function which we wish to compute the series for. Now the texts I am reading show that it is possible to derive solutions for PDE's by applying Fourier series methods, however, the text does not mention when such an application will work. So I am curious to find out when can someone use Fourier series methods to find solutions of PDE's? Also given a PDE is it always possible to re-write the PDE for the Fourier series? For example, suppose we consider in with zero boundary conditions. What conditions must be satisfied so that in makes sense, with appropriate boundary conditions? Is it sufficient to take the periodic extension of, , on the appropriate domain , and hence we can always consider the ""transformed"" PDE? Is it necessary for the differential operator to have eigenfunctions which form an orthonormal basis of ? I understand that for any periodic function one can always take the Fourier series. However, it is not clear to me under what conditions one can consider solutions of a PDE  as a Fourier series and more specifically, when one can consider the ""transformed"" PDE.",-\Delta u+u=f \Omega\subset\mathbb{R}^{N} \hat{-\Delta u}+\hat{u}=\hat{f} \Omega\subset\mathbb{R}^{N} \tilde{u} \tilde{\Omega} L^{2}(\Omega),"['functional-analysis', 'partial-differential-equations', 'fourier-analysis', 'fourier-series']"
70,Are lattice operations continuous in the Lipschitz norm?,Are lattice operations continuous in the Lipschitz norm?,,"Denote by $Lip_0(X)$ the set of all Lipschitz functions on a metric space $X$ vanishing at some base point $e \in X$ . The norm in $Lip_0$ is defined as fololows $$ \|f\|_{Lip_0} := Lip(f), $$ where $Lip(f)$ denotes the Lipschitz constant. With pointwise operations $f \vee g := \max\{f,g\}$ and $f \wedge g := \min\{f,g\}$ the space $Lip_0$ becomes a Lipschitz lattice , in which the following condition holds $$ \|f \vee g\|_{Lip_0} \leq \max\{\|f\|_{Lip_0},\|g\|_{Lip_0}\}. $$ The Banach lattice condition $|f| \leq |g| \implies \|f\| \leq \|g\|$ , however, fails. (Nik Weaver. Lipschitz Algebras, 2nd ed.) Question . Are operations $f_+ := f \vee 0$ , $f_- := (-f) \vee 0$ and $|f| := f \vee (-f)$ continuous in the $Lip_0$ norm, i.e. does, e.g., $$ \|f_+ - g_+\|_{Lip_0} \leq C\|f - g\|_{Lip_0} $$ hold? I have searched a lot for either a proof or a counterexample, but couldn't find anything. Any help will be appreciated.","Denote by the set of all Lipschitz functions on a metric space vanishing at some base point . The norm in is defined as fololows where denotes the Lipschitz constant. With pointwise operations and the space becomes a Lipschitz lattice , in which the following condition holds The Banach lattice condition , however, fails. (Nik Weaver. Lipschitz Algebras, 2nd ed.) Question . Are operations , and continuous in the norm, i.e. does, e.g., hold? I have searched a lot for either a proof or a counterexample, but couldn't find anything. Any help will be appreciated.","Lip_0(X) X e \in X Lip_0 
\|f\|_{Lip_0} := Lip(f),
 Lip(f) f \vee g := \max\{f,g\} f \wedge g := \min\{f,g\} Lip_0 
\|f \vee g\|_{Lip_0} \leq \max\{\|f\|_{Lip_0},\|g\|_{Lip_0}\}.
 |f| \leq |g| \implies \|f\| \leq \|g\| f_+ := f \vee 0 f_- := (-f) \vee 0 |f| := f \vee (-f) Lip_0 
\|f_+ - g_+\|_{Lip_0} \leq C\|f - g\|_{Lip_0}
","['functional-analysis', 'lipschitz-functions', 'vector-lattices']"
71,Continuity concerning family of projections,Continuity concerning family of projections,,"Let $X$ be a compact topological space, $H$ be a complex Hilbert space and endow $F(H)$ , the space of bounded Fredholm operators in $H$ , with the uniform norm topology (inherited from $B(H)$ ). Let $T: X\to F(H)$ , $x\mapsto T_x$ , be a continuous map. There exists a closed subspace $V\subseteq H$ of finite codimension, i.e. $\dim H/V<\infty$ , such that $V\cap \ker T_x = \{0\}$ for all $x\in X$ . I have proved that $H/T(V) = \bigsqcup\limits_{x\in X} H/T_x(V)$ is a vector bundle over $X$ (of finite rank). In particular, $\dim H/T_x(V)$ is independent of $x$ (here we can assume connectedness of $x$ ). For $x\in X$ , let $P_x: H\to H$ be the orthogonal projection onto $T_x(V)$ . In order to induce a specific map of bundles (see here for details), I need to check the continuity of the map $X\times H\to H$ given by $(x,u)\mapsto P_x(u)$ . Question: Is $(x,u)\mapsto P_x(u)$ continuous? Looking at the inequality $$ \|P_y(v)-P_x(u)\| \leq \|P_y(v-u)\| + \|(P_y-P_x)(u)\|$$ we conclude it suffices to prove that $x\mapsto P_x$ is continuous when one gives $B(H)$ the strong operator topology, but I could not prove it. Any help is appreciated. Thanks in advance!","Let be a compact topological space, be a complex Hilbert space and endow , the space of bounded Fredholm operators in , with the uniform norm topology (inherited from ). Let , , be a continuous map. There exists a closed subspace of finite codimension, i.e. , such that for all . I have proved that is a vector bundle over (of finite rank). In particular, is independent of (here we can assume connectedness of ). For , let be the orthogonal projection onto . In order to induce a specific map of bundles (see here for details), I need to check the continuity of the map given by . Question: Is continuous? Looking at the inequality we conclude it suffices to prove that is continuous when one gives the strong operator topology, but I could not prove it. Any help is appreciated. Thanks in advance!","X H F(H) H B(H) T: X\to F(H) x\mapsto T_x V\subseteq H \dim H/V<\infty V\cap \ker T_x = \{0\} x\in X H/T(V) = \bigsqcup\limits_{x\in X} H/T_x(V) X \dim H/T_x(V) x x x\in X P_x: H\to H T_x(V) X\times H\to H (x,u)\mapsto P_x(u) (x,u)\mapsto P_x(u)  \|P_y(v)-P_x(u)\| \leq \|P_y(v-u)\| + \|(P_y-P_x)(u)\| x\mapsto P_x B(H)","['functional-analysis', 'continuity', 'operator-theory', 'hilbert-spaces']"
72,Calculating a Fréchet derivative,Calculating a Fréchet derivative,,"Let $I$ be a set, and let $B(I)$ be the space of bounded, real-valued functions on $I$ equipped with the sup-norm. Let $\phi: \mathbb R \to \mathbb R$ be bounded and continuously differentiable everywhere. Finally, let $S: B(I) \to \mathbb R$ be linear and continuous. Define $\Phi: B(I) \to \mathbb R$ by $\Phi(x) = S(\phi \circ x)$ . Is $\Phi$ Fréchet differentiable at every $x \in B(I)$ , and if so is it the case that $\Phi'(x) = S(\phi' \circ x)$ ? I can show that the function $x \mapsto S(\phi' \circ x)$ is linear and bounded, using the corresponding facts about $\phi'$ and $S$ , but I'm not sure I can show that this function satisfies the definition of the Fréchet derivative. I have to show, for every $x \in B(I)$ , that $$\lim_{\| h \|_\infty \to 0} \frac{| \Phi (x + h) - \Phi(x) -  S(\phi' \circ h) |}{\| h \|_\infty} = 0,\tag{1}$$ where $\| \cdot \|_\infty$ is the sup-norm on $B(I)$ . Now, by the definition of $\Phi$ and the linearity of $S$ $$ \frac{\Phi (x + h) - \Phi(x) -  S(\phi' \circ h)}{\|h\|_\infty} =  \frac{S(\phi \circ (x+h)) - S(\phi \circ x) -  S(\phi' \circ h)}{\|h\|_\infty}  = S\Big(\frac{[\phi \circ(x+h)] - [\phi \circ x] - [\phi' \circ h]}{\|h\|_\infty} \Big).$$ From here I would like to argue that as $\|h\|_\infty \to 0$ , $$\frac{[\phi \circ(x+h)] - [\phi \circ x] - [\phi' \circ h]}{\|h\|_\infty} \to 0, \tag{2}$$ and then use the continuity of $S$ to conclude. I haven't convinced myself that (2) holds however.","Let be a set, and let be the space of bounded, real-valued functions on equipped with the sup-norm. Let be bounded and continuously differentiable everywhere. Finally, let be linear and continuous. Define by . Is Fréchet differentiable at every , and if so is it the case that ? I can show that the function is linear and bounded, using the corresponding facts about and , but I'm not sure I can show that this function satisfies the definition of the Fréchet derivative. I have to show, for every , that where is the sup-norm on . Now, by the definition of and the linearity of From here I would like to argue that as , and then use the continuity of to conclude. I haven't convinced myself that (2) holds however.","I B(I) I \phi: \mathbb R \to \mathbb R S: B(I) \to \mathbb R \Phi: B(I) \to \mathbb R \Phi(x) = S(\phi \circ x) \Phi x \in B(I) \Phi'(x) = S(\phi' \circ x) x \mapsto S(\phi' \circ x) \phi' S x \in B(I) \lim_{\| h \|_\infty \to 0} \frac{| \Phi (x + h) - \Phi(x) -  S(\phi' \circ h) |}{\| h \|_\infty} = 0,\tag{1} \| \cdot \|_\infty B(I) \Phi S  \frac{\Phi (x + h) - \Phi(x) -  S(\phi' \circ h)}{\|h\|_\infty} =  \frac{S(\phi \circ (x+h)) - S(\phi \circ x) -  S(\phi' \circ h)}{\|h\|_\infty}  = S\Big(\frac{[\phi \circ(x+h)] - [\phi \circ x] - [\phi' \circ h]}{\|h\|_\infty} \Big). \|h\|_\infty \to 0 \frac{[\phi \circ(x+h)] - [\phi \circ x] - [\phi' \circ h]}{\|h\|_\infty} \to 0, \tag{2} S","['real-analysis', 'functional-analysis', 'derivatives', 'frechet-derivative']"
73,Weak Topology and the induced topology,Weak Topology and the induced topology,,"Given a normed space $E$ with a subspace $M$ , it is known that the weak topology on $M$ is the same as the induced topology of the weak topology on $E$ . Why is this the case? From the Hahn-Banach theorem, we can extend the linear functionals on $M$ to $E$ . So my intuition is that any element in the weak topology on $M$ is in the induced topology of the weak topology on $E$ . But why does the other way also hold? I am not really clear how to work with a linear functional on $E$ which cannot be obtained by extending a linear functional on $M$ .","Given a normed space with a subspace , it is known that the weak topology on is the same as the induced topology of the weak topology on . Why is this the case? From the Hahn-Banach theorem, we can extend the linear functionals on to . So my intuition is that any element in the weak topology on is in the induced topology of the weak topology on . But why does the other way also hold? I am not really clear how to work with a linear functional on which cannot be obtained by extending a linear functional on .",E M M E M E M E E M,"['functional-analysis', 'weak-topology']"
74,Expression for the Clarke subdifferential of a weakly convex function,Expression for the Clarke subdifferential of a weakly convex function,,"Let $\gamma\in\left]0,+\infty\right[$ , let $f$ be a proper, convex, lower semicontinuous function from a real Hilbert space $\mathcal{X}$ to $\left]-\infty,+\infty\right]$ , and set $g=f-\frac{\gamma}{2}\|\cdot\|^2$ . Then $g$ is weakly convex. I'm looking for a reference characterizing for which $x\in\mathcal{X}$ the following holds \begin{equation} \partial_{Clarke} g(x) = \partial_{convex} f(x) - \gamma x. \tag{*} \end{equation} where $\partial_{Clarke}$ is the Clarke subdifferential, $$\partial_{convex} f(x) = \left\{ u \in \mathcal{X} \mid (\forall y \in \mathcal{X}) \quad \langle y - x \mid u \rangle + f(x)\leq f(y) \right\},$$ and the righthand side in (*) denotes Minkowski subtraction. I know that $(\nabla \frac{\gamma}{2}\|\cdot\|^2) (x) = \gamma x$ and that $\partial_{convex}$ coincides with $\partial_{Clarke}$ on convex functions. However, I am only working with a weakly convex function. I've perused Rockafellar/Wets but not found much. I'm actually not entirely positive that (*) is true everywhere, e.g. it may fail on the boundary of the domain of $g$ . Any relevant info is greatly appreciated! EDIT: I think it would suffice to find a reference for when the sum rule holds for Clarke subdifferentials. I believe that $\partial_{Clarke}g(x)\supset\partial_{convex}f(x)-\gamma x$ , so it would suffice to show the reverse inclusion.","Let , let be a proper, convex, lower semicontinuous function from a real Hilbert space to , and set . Then is weakly convex. I'm looking for a reference characterizing for which the following holds where is the Clarke subdifferential, and the righthand side in (*) denotes Minkowski subtraction. I know that and that coincides with on convex functions. However, I am only working with a weakly convex function. I've perused Rockafellar/Wets but not found much. I'm actually not entirely positive that (*) is true everywhere, e.g. it may fail on the boundary of the domain of . Any relevant info is greatly appreciated! EDIT: I think it would suffice to find a reference for when the sum rule holds for Clarke subdifferentials. I believe that , so it would suffice to show the reverse inclusion.","\gamma\in\left]0,+\infty\right[ f \mathcal{X} \left]-\infty,+\infty\right] g=f-\frac{\gamma}{2}\|\cdot\|^2 g x\in\mathcal{X} \begin{equation}
\partial_{Clarke} g(x) = \partial_{convex} f(x) - \gamma x. \tag{*}
\end{equation} \partial_{Clarke} \partial_{convex} f(x) = \left\{ u \in \mathcal{X} \mid (\forall y \in \mathcal{X}) \quad \langle y - x \mid u \rangle + f(x)\leq f(y) \right\}, (\nabla \frac{\gamma}{2}\|\cdot\|^2) (x) = \gamma x \partial_{convex} \partial_{Clarke} g \partial_{Clarke}g(x)\supset\partial_{convex}f(x)-\gamma x","['functional-analysis', 'reference-request', 'convex-analysis', 'non-smooth-analysis']"
75,When do quadratically integrable functions vanish at infinity?,When do quadratically integrable functions vanish at infinity?,,"In quantum mechanics we use quadratically integrable functions ( $\psi \in L^2$ ). This means $$ \int_{-\infty}^\infty |\psi(x)|^2 \mathrm{d}x < \infty. $$ I'm interested in the question when those function vanish at infinity, i.e. $$ \lim_{x \rightarrow \pm \infty} \psi(x) = 0. $$ I know that this is not the case for every function in $L^2$ , see for example this answer or this answer . I found in a similar question something interesting : Suppose $f : \mathbf R \to \mathbf R$ is uniformly continuous, and $f\in L^p$ for some $p\geq 1$ . Then $|f(x)|\to 0$ as $|x| \to \infty$ . Another interesting answer is this one . My questions are: How can one prove the given statement? What are other cases where quadratically integrable functions vanish at infinity? Which cases are relevant in physics (for quantum mechanics)? Edit: My first question was answered in the comments by @reuns. My remaining question is: What criteria (beside uniform continuity) do exist, so that quadratically integrable functions vanish (or not) at infinity?","In quantum mechanics we use quadratically integrable functions ( ). This means I'm interested in the question when those function vanish at infinity, i.e. I know that this is not the case for every function in , see for example this answer or this answer . I found in a similar question something interesting : Suppose is uniformly continuous, and for some . Then as . Another interesting answer is this one . My questions are: How can one prove the given statement? What are other cases where quadratically integrable functions vanish at infinity? Which cases are relevant in physics (for quantum mechanics)? Edit: My first question was answered in the comments by @reuns. My remaining question is: What criteria (beside uniform continuity) do exist, so that quadratically integrable functions vanish (or not) at infinity?",\psi \in L^2  \int_{-\infty}^\infty |\psi(x)|^2 \mathrm{d}x < \infty.   \lim_{x \rightarrow \pm \infty} \psi(x) = 0.  L^2 f : \mathbf R \to \mathbf R f\in L^p p\geq 1 |f(x)|\to 0 |x| \to \infty,"['integration', 'functional-analysis', 'functions', 'quantum-mechanics']"
76,Continuous path of Fredholm operators,Continuous path of Fredholm operators,,"Let $H$ be a (infinite dimensional) Hilbert space and denote by $\mathcal{F}(H)$ the semigroup of bounded Fredholm operators in $H$ . Let $S,T\in\mathcal{F}(H)$ and let $I=id_{H}$ be the identity map in $H$ . I know that $ST\oplus I$ and $S\oplus T$ are both elements of $\mathcal{F}(H\oplus H)$ and that they have the same index. Question. How can one explicitly construct a continuous map $\alpha\colon[0,1]\to\mathcal{F}(H\oplus H)$ such that $\alpha(0) = ST\oplus I$ and $\alpha(1)=S\oplus T$ ? Writing $A\oplus B = \begin{bmatrix} A & 0 \\ 0 & B \end{bmatrix}$ , I already notice that $$\alpha(t) = \begin{bmatrix} ST & 0 \\ 0 & I \end{bmatrix} \begin{bmatrix} \cos(\pi t/2) & -\sin(\pi t/2) \\ \sin(\pi t/2) & \cos(\pi t/2) \end{bmatrix} \begin{bmatrix} I & 0 \\ 0 & S^{-1} \end{bmatrix} \begin{bmatrix} \cos(\pi t/2) & \sin(\pi t/2) \\ -\sin(\pi t/2) & \cos(\pi t/2) \end{bmatrix} \begin{bmatrix} I & 0 \\ 0 & S \end{bmatrix}$$ seems to do the job, though I do not know how to check that $\alpha(t)\in\mathcal{F}(H\oplus H)$ for all $t\in[0,1]$ . Besides, in the above formula I've assumed that $S$ is invertible, and I could not find a solution without that assumption. Any ideas? Thanks in advance.","Let be a (infinite dimensional) Hilbert space and denote by the semigroup of bounded Fredholm operators in . Let and let be the identity map in . I know that and are both elements of and that they have the same index. Question. How can one explicitly construct a continuous map such that and ? Writing , I already notice that seems to do the job, though I do not know how to check that for all . Besides, in the above formula I've assumed that is invertible, and I could not find a solution without that assumption. Any ideas? Thanks in advance.","H \mathcal{F}(H) H S,T\in\mathcal{F}(H) I=id_{H} H ST\oplus I S\oplus T \mathcal{F}(H\oplus H) \alpha\colon[0,1]\to\mathcal{F}(H\oplus H) \alpha(0) = ST\oplus I \alpha(1)=S\oplus T A\oplus B = \begin{bmatrix} A & 0 \\ 0 & B \end{bmatrix} \alpha(t) = \begin{bmatrix} ST & 0 \\ 0 & I \end{bmatrix}
\begin{bmatrix} \cos(\pi t/2) & -\sin(\pi t/2) \\ \sin(\pi t/2) & \cos(\pi t/2) \end{bmatrix}
\begin{bmatrix} I & 0 \\ 0 & S^{-1} \end{bmatrix}
\begin{bmatrix} \cos(\pi t/2) & \sin(\pi t/2) \\ -\sin(\pi t/2) & \cos(\pi t/2) \end{bmatrix}
\begin{bmatrix} I & 0 \\ 0 & S \end{bmatrix} \alpha(t)\in\mathcal{F}(H\oplus H) t\in[0,1] S","['functional-analysis', 'analysis', 'operator-theory', 'hilbert-spaces']"
77,Understanding the Proof of the Hyperplane Separation Theorem,Understanding the Proof of the Hyperplane Separation Theorem,,"Am reading Wiki's proof of the Hyperplane Separation Theorem and am having trouble with the last part of the proof. Let me give you the structure of the argument and explain precisely where I have problem. Theorem. Let $A$ and $B$ be two disjoint nonempty convex subsets of $\mathbb{R}^n$ . Then there exist a nonzero vector $v$ and a real number $c$ such that $$ \langle x,v\rangle \geq c,{\text{ and }}\langle y,v\rangle \leq c $$ for all $x \in A$ and $y \in B$ . The proof begins with a Lemma, the proof of which I understand: Lemma. Let $K$ be a nonempty closed convex subset of $\mathbb{R}^n$ . Then there exists a unique vector in $K$ of minimum norm (length). Thus, given disjoint nonempty convex sets $A$ , $B$ we can let $$K=A-B$$ which is nonempty and convex. Hence so is its closure $\bar{K}$ . We can therefore apply the Lemma to obtain a vector $v \in \bar{K}$ of minimum norm. One can then show that (see Wiki's article) $$ \langle z,v\rangle \geq |v|^{2}$$ for all $z  \in K$ or equivalently $\langle x-y,v\rangle \geq |v|^{2}$ for all $x \in A$ and $y \in B$ . If $v$ is nonzero we are done because $$\inf _{x\in A}\langle x,v\rangle \geq |v|^{2}+\sup _{y\in B}\langle y,v\rangle $$ so taking $c=|v|^{2}+\sup _{y\in B}\langle y,v\rangle$ does what is wanted. Now, the last paragraph of the proof deals with the general case (where $v=0$ is possible) by dividing into two cases. Case 1. We assume that the interior of $K$ is nonempty. The article then reads “ The interior can be exhausted by a nested sequence of nonempty compact convex subsets $K_{1}\subset K_{2}\subset K_{3}\subset \cdots$ ”. I suppose it means we can find such a sequence with $K^\circ=\cup_{n \in \mathbb{N}} K_n$ . My first question is: How can I construct such a sequence explicitly? Since $K^\circ$ is nonempty my idea is to let $K_1=\bar{B}(z_0)$ be a closed ball centered at some $z_0\in K^\circ$ with $\bar{B}(z_0) \subset K$ . But I don't know how to define $K_2$ from there... Case 2. The interior of $K$ is empty. The article then reads “The affine set that $K$ spans has dimension less than that of the whole space. Consequently $K$ is contained in some hyperplane $\langle \cdot ,v\rangle =c$ ”. My second question is : How can I show that $\text{span}(K)$ has dimension less than $n$ ? I can show that any subspace of $\mathbb{R}^n$ of dimension less than $n$ is included in a hyperplane of the form $\{ x \in \mathbb{R}^n : \langle x ,v\rangle =0 \}$ for some nonzero vector $v$ . Hence in this second this case I believe we have $c=0$ . Am I correct? Thanks a lot for your help.","Am reading Wiki's proof of the Hyperplane Separation Theorem and am having trouble with the last part of the proof. Let me give you the structure of the argument and explain precisely where I have problem. Theorem. Let and be two disjoint nonempty convex subsets of . Then there exist a nonzero vector and a real number such that for all and . The proof begins with a Lemma, the proof of which I understand: Lemma. Let be a nonempty closed convex subset of . Then there exists a unique vector in of minimum norm (length). Thus, given disjoint nonempty convex sets , we can let which is nonempty and convex. Hence so is its closure . We can therefore apply the Lemma to obtain a vector of minimum norm. One can then show that (see Wiki's article) for all or equivalently for all and . If is nonzero we are done because so taking does what is wanted. Now, the last paragraph of the proof deals with the general case (where is possible) by dividing into two cases. Case 1. We assume that the interior of is nonempty. The article then reads “ The interior can be exhausted by a nested sequence of nonempty compact convex subsets ”. I suppose it means we can find such a sequence with . My first question is: How can I construct such a sequence explicitly? Since is nonempty my idea is to let be a closed ball centered at some with . But I don't know how to define from there... Case 2. The interior of is empty. The article then reads “The affine set that spans has dimension less than that of the whole space. Consequently is contained in some hyperplane ”. My second question is : How can I show that has dimension less than ? I can show that any subspace of of dimension less than is included in a hyperplane of the form for some nonzero vector . Hence in this second this case I believe we have . Am I correct? Thanks a lot for your help.","A B \mathbb{R}^n v c  \langle x,v\rangle \geq c,{\text{ and }}\langle y,v\rangle \leq c  x \in A y \in B K \mathbb{R}^n K A B K=A-B \bar{K} v \in \bar{K}  \langle z,v\rangle \geq |v|^{2} z  \in K \langle x-y,v\rangle \geq |v|^{2} x \in A y \in B v \inf _{x\in A}\langle x,v\rangle \geq |v|^{2}+\sup _{y\in B}\langle y,v\rangle  c=|v|^{2}+\sup _{y\in B}\langle y,v\rangle v=0 K K_{1}\subset K_{2}\subset K_{3}\subset \cdots K^\circ=\cup_{n \in \mathbb{N}} K_n K^\circ K_1=\bar{B}(z_0) z_0\in K^\circ \bar{B}(z_0) \subset K K_2 K K K \langle \cdot ,v\rangle =c \text{span}(K) n \mathbb{R}^n n \{ x \in \mathbb{R}^n : \langle x ,v\rangle =0 \} v c=0","['real-analysis', 'linear-algebra', 'functional-analysis', 'normed-spaces']"
78,Unitarily equivalent multiplication operators,Unitarily equivalent multiplication operators,,"Let $A$ be the operator given by $Ax(t)=\sin(t)\,x(t)$ in $L_2[0,2\pi]$ , and $B$ the operator given by $Bx(t)=\sin(t)\,x(t)$ in $L_2[-2\pi,2\pi]$ . Are these operators unitarily equivalent?","Let be the operator given by in , and the operator given by in . Are these operators unitarily equivalent?","A Ax(t)=\sin(t)\,x(t) L_2[0,2\pi] B Bx(t)=\sin(t)\,x(t) L_2[-2\pi,2\pi]","['functional-analysis', 'operator-theory', 'spectral-theory']"
79,The Spectrum of the operator in C[0;1],The Spectrum of the operator in C[0;1],,"I have an operator $ Ax(t) = \int_{0}^{t^2} x(s)ds $ in $ C [0;1] $ . I need to find spectrum of this operator. $ A $ is a compact operator, so the spectrum consists of 0 and eigenvalues.  As I understand there is no eigenvalues, so spectrum = 0. But I don't know how to prove that there is no eigenvalues in spectrum. Would be very glad for any help!","I have an operator in . I need to find spectrum of this operator. is a compact operator, so the spectrum consists of 0 and eigenvalues.  As I understand there is no eigenvalues, so spectrum = 0. But I don't know how to prove that there is no eigenvalues in spectrum. Would be very glad for any help!", Ax(t) = \int_{0}^{t^2} x(s)ds   C [0;1]   A ,"['functional-analysis', 'operator-theory', 'spectral-theory']"
80,Understanding a Measure-valued (Bochner?) Integral,Understanding a Measure-valued (Bochner?) Integral,,"Let $X$ be a compact metric space, and let $\mathcal P(X)$ be the (compact, metrisable) space of Borel probability measures on $X$ . Similarly, $\mathcal P (\mathcal P (X))$ is the space of Borel probability measures on $\mathcal P (X)$ . I want to make sense of the integral $$ \int_{\mathcal P(X)} \mu \,\mathrm d \mathcal \tau (\mu) \tag{INT}\label{INT} $$ where $\tau \in \mathcal P (\mathcal P (X))$ . Is there an elementary definition of this integral? (See the end of the question for an elaboration of what I mean by ""elementary"".) It seems one way to interpret \eqref{INT} is to view it as a Bochner integral , by considering $\mathcal P(X)$ as a (compact, convex) subset of the Banach space of finite signed Borel measures on $X$ with the total variation norm. One property of the Bochner integral is that, for any bounded operator $T\colon \mathcal P(X) \to Y$ where $Y$ is another Banach space, we have that $$ \int_{\mathcal P (X)} T\mu\,\mathrm d\tau (\mu) = T \left( \int_{\mathcal P(X)} \mu \,\mathrm d \mathcal \tau (\mu) \right). \tag{*}\label{*} $$ In particular, suppose that $Y = L(C(X),\mathbb R)$ , the space of bounded linear functionals on $C(X)$ , and $T$ is the operator given by $$ \mu \mapsto \left(\begin{align*} C(X) &\to \mathbb R \\ f &\mapsto \int_X f(x) \,\mathrm d \mu(x) \end{align*}\right). $$ Then, we can parse \eqref{*} as $$ \int_X f(x) \, \mathrm d \mu_0 (x) = \int_{\mathcal P(X)} \int_X f(x) \,\mathrm d \mu(x) \,\mathrm d \tau (\mu) \tag{+} \label{+} $$ for each $f \in C(X)$ , where $\mu_0$ is just the value of \eqref{INT}. Hopefully, everything I've said so far is correct. (Please do point out mistakes if there are any.) If so, can I take \eqref{+} as the definition of \eqref{INT}? That is, I would like to define \eqref{INT} as the $\mu_0 \in \mathcal P(X)$ that satisfies \eqref{+} for each $f \in C(X)$ . Do I lose any important properties of the integral by using this definition? I am looking for a definition of \eqref{INT} without too much additional machinery, beyond what you would see in a typical introductory measure theory or functional analysis course. I was hoping \eqref{+} would do, but I am also open to alternative suggestions. Additionally, if anyone can recommend a nice, readable reference for this material, I'd appreciate that as well. An ideal reference would be one that's accessible to someone who only knows a little measure theory and functional analysis, but I'll take what I can get.","Let be a compact metric space, and let be the (compact, metrisable) space of Borel probability measures on . Similarly, is the space of Borel probability measures on . I want to make sense of the integral where . Is there an elementary definition of this integral? (See the end of the question for an elaboration of what I mean by ""elementary"".) It seems one way to interpret \eqref{INT} is to view it as a Bochner integral , by considering as a (compact, convex) subset of the Banach space of finite signed Borel measures on with the total variation norm. One property of the Bochner integral is that, for any bounded operator where is another Banach space, we have that In particular, suppose that , the space of bounded linear functionals on , and is the operator given by Then, we can parse \eqref{*} as for each , where is just the value of \eqref{INT}. Hopefully, everything I've said so far is correct. (Please do point out mistakes if there are any.) If so, can I take \eqref{+} as the definition of \eqref{INT}? That is, I would like to define \eqref{INT} as the that satisfies \eqref{+} for each . Do I lose any important properties of the integral by using this definition? I am looking for a definition of \eqref{INT} without too much additional machinery, beyond what you would see in a typical introductory measure theory or functional analysis course. I was hoping \eqref{+} would do, but I am also open to alternative suggestions. Additionally, if anyone can recommend a nice, readable reference for this material, I'd appreciate that as well. An ideal reference would be one that's accessible to someone who only knows a little measure theory and functional analysis, but I'll take what I can get.","X \mathcal P(X) X \mathcal P (\mathcal P (X)) \mathcal P (X)  \int_{\mathcal P(X)} \mu \,\mathrm d \mathcal \tau (\mu) \tag{INT}\label{INT}  \tau \in \mathcal P (\mathcal P (X)) \mathcal P(X) X T\colon \mathcal P(X) \to Y Y  \int_{\mathcal P (X)} T\mu\,\mathrm d\tau (\mu) = T \left( \int_{\mathcal P(X)} \mu \,\mathrm d \mathcal \tau (\mu) \right). \tag{*}\label{*}  Y = L(C(X),\mathbb R) C(X) T  \mu \mapsto \left(\begin{align*} C(X) &\to \mathbb R \\ f &\mapsto \int_X f(x) \,\mathrm d \mu(x) \end{align*}\right).   \int_X f(x) \, \mathrm d \mu_0 (x) = \int_{\mathcal P(X)} \int_X f(x) \,\mathrm d \mu(x) \,\mathrm d \tau (\mu) \tag{+} \label{+}  f \in C(X) \mu_0 \mu_0 \in \mathcal P(X) f \in C(X)","['integration', 'functional-analysis', 'measure-theory', 'reference-request', 'convex-analysis']"
81,(Regularized) Dual Representation of Wasserstein-1 metric,(Regularized) Dual Representation of Wasserstein-1 metric,,"Consider $\mathbb{R}^d$ , the $d$ -dimensional Euclidean space. Let $W_1$ be the $1^{st}$ Wasserstein distance between probability measures $\mu, \nu$ $$W_1(\mu, \nu) = \inf_{\gamma \in \Gamma(\mu, \nu)} \int \|x-y\|_2d\gamma(x,y),$$ where $\Gamma(\mu, \nu)$ is the set of all measures on $\mathbb{R}^d \times \mathbb{R}^d$ with marginals $\mu, \nu$ . It is well known that $W_1$ has the following dual representation $$W_1(\mu, \nu) = \sup_{\|f\|_{\text{Lip}} \leq 1} \int f(x)d(\mu-\nu)(x),$$ where $\|f\|_{\text{Lip}} = \sup_{x\neq y} \frac{|f(x)-f(y)|}{\|x-y\|_2}.$ I'm interested in understanding a slight variant of this dual objective $$\sup_{f} \left[\int f(x)d(\mu-\nu)(x) - \frac{M}{2}\|f\|_{\text{Lip}}^2\right],$$ where $M>0$ is a constant. Note that the earlier objective has a constraint on the Lipschitz constant, whereas the latter one has a regularization penalty on the  Lipschitz constant. Is the maximum of the above objective related to the $W_1$ metric? Can we obtain a closed-form expression for the maximum?","Consider , the -dimensional Euclidean space. Let be the Wasserstein distance between probability measures where is the set of all measures on with marginals . It is well known that has the following dual representation where I'm interested in understanding a slight variant of this dual objective where is a constant. Note that the earlier objective has a constraint on the Lipschitz constant, whereas the latter one has a regularization penalty on the  Lipschitz constant. Is the maximum of the above objective related to the metric? Can we obtain a closed-form expression for the maximum?","\mathbb{R}^d d W_1 1^{st} \mu, \nu W_1(\mu, \nu) = \inf_{\gamma \in \Gamma(\mu, \nu)} \int \|x-y\|_2d\gamma(x,y), \Gamma(\mu, \nu) \mathbb{R}^d \times \mathbb{R}^d \mu, \nu W_1 W_1(\mu, \nu) = \sup_{\|f\|_{\text{Lip}} \leq 1} \int f(x)d(\mu-\nu)(x), \|f\|_{\text{Lip}} = \sup_{x\neq y} \frac{|f(x)-f(y)|}{\|x-y\|_2}. \sup_{f} \left[\int f(x)d(\mu-\nu)(x) - \frac{M}{2}\|f\|_{\text{Lip}}^2\right], M>0 W_1","['functional-analysis', 'measure-theory', 'convex-optimization', 'optimal-transport']"
82,Understanding an application of the Cauchy–Schwarz inequality,Understanding an application of the Cauchy–Schwarz inequality,,"Here is the link to the solution: Why should we use the uniform boundedness principle here? And here is the solution: First let's show a simpler version (1-dimensional): If $\sum_i a_i x_i < \infty$ all for $x\in\ell^2$ , then $a\in \ell^2$ . You can prove this claim using uniform boundedness principle, or you can just use Riesz Representation Theorem. See [this post][1]. Now, let's go back to your problem. It follows from the claim above that each row of $A$ is in $\ell_2$ . Define $T_N$ to be the restriction of $A$ onto the first $N$ rows, that is, $$T_N x = \left(\sum_j a_{1j}x_j,\sum_j a_{2j}x_j,\dots,\sum_j a_{Nj}x_j,0,0,\dots,\right).$$ We claim that $\|T_N\| < \infty$ . Note that $$\|T_Nx\|_2^2 = \sum_{i=1}^N \left|\sum_j a_{ij}x_j\right|^2 \leq \sum_{i=1}^N\left(\sum_j |a_{ij}|^2 \right)\left(\sum_j |x_j|^2 \right) \leq \|x\|_2^2\cdot \sum_{i=1}^N\sum_{j=1}^\infty |a_{ij}|^2,$$ thus $$\|T_N\| \leq \left(\sum_{i=1}^N\sum_{j=1}^\infty |a_{ij}|^2\right)^{1/2}.$$ (Note that the infinite sum over $j$ is finite because of the claim at the beginning.) Now, for each fixed $x$ , observe that $\|T_Nx\|_2$ is uniformly bounded by $\|Ax\|_2$ (since $\|T_Nx\|_2$ is just part of the sum for $\|Ax\|_2<\infty$ ). It follows from the uniform boundedness principle that $\sup_N \|T_N\|<\infty$ . Note that $\|Ax\|_2 = \lim_{N\to\infty} \|T_Nx\|_2 \leq (\sup_N \|T_N\|)\|x\|$ , which implies that $A$ is bounded and $\|A\| \leq \sup_N \|T_N\|$ . But I do not understand this step: $\sum_{i=1}^N \left|\sum_j a_{ij}x_j\right|^2 \leq \sum_{i=1}^N\left(\sum_j |a_{ij}|^2 \right)\left(\sum_j |x_j|^2 \right)$ I know that this is by Cauchy-Schwartz, but should not $a_{ij}x_j$ be inside an absolute value to apply Cauchy Schwartz?","Here is the link to the solution: Why should we use the uniform boundedness principle here? And here is the solution: First let's show a simpler version (1-dimensional): If all for , then . You can prove this claim using uniform boundedness principle, or you can just use Riesz Representation Theorem. See [this post][1]. Now, let's go back to your problem. It follows from the claim above that each row of is in . Define to be the restriction of onto the first rows, that is, We claim that . Note that thus (Note that the infinite sum over is finite because of the claim at the beginning.) Now, for each fixed , observe that is uniformly bounded by (since is just part of the sum for ). It follows from the uniform boundedness principle that . Note that , which implies that is bounded and . But I do not understand this step: I know that this is by Cauchy-Schwartz, but should not be inside an absolute value to apply Cauchy Schwartz?","\sum_i a_i x_i < \infty x\in\ell^2 a\in \ell^2 A \ell_2 T_N A N T_N x = \left(\sum_j a_{1j}x_j,\sum_j a_{2j}x_j,\dots,\sum_j a_{Nj}x_j,0,0,\dots,\right). \|T_N\| < \infty \|T_Nx\|_2^2 = \sum_{i=1}^N \left|\sum_j a_{ij}x_j\right|^2 \leq \sum_{i=1}^N\left(\sum_j |a_{ij}|^2 \right)\left(\sum_j |x_j|^2 \right) \leq \|x\|_2^2\cdot \sum_{i=1}^N\sum_{j=1}^\infty |a_{ij}|^2, \|T_N\| \leq \left(\sum_{i=1}^N\sum_{j=1}^\infty |a_{ij}|^2\right)^{1/2}. j x \|T_Nx\|_2 \|Ax\|_2 \|T_Nx\|_2 \|Ax\|_2<\infty \sup_N \|T_N\|<\infty \|Ax\|_2 = \lim_{N\to\infty} \|T_Nx\|_2 \leq (\sup_N \|T_N\|)\|x\| A \|A\| \leq \sup_N \|T_N\| \sum_{i=1}^N \left|\sum_j a_{ij}x_j\right|^2 \leq \sum_{i=1}^N\left(\sum_j |a_{ij}|^2 \right)\left(\sum_j |x_j|^2 \right) a_{ij}x_j","['real-analysis', 'functional-analysis']"
83,Misunderstanding Lax-Milgram,Misunderstanding Lax-Milgram,,"I think I misunderstand the Lax-Milgram theorem. Suppose that I have a bilinear form $a$ satisfying the conditions of the Lax-Milgram theorem on a Hilbert space H. Then it must satisfy the same conditions on every Hilbert subspace of H. Therefore, the variational problem a(u,v)=l(v), where the linear form $l$ is continuous on H, has a unique solution on every Hilbert subspace of H. But from the point of view of PDE Hilbert subspaces are just additional conditions on the function. For example, let us consider the Poisson equation $\Delta u=f$ on a bounded domain $\Omega$ . This problem has a unique solution on $H^1_0(\Omega)$ by Lax-Milgram. Let's take a hyperplane $H$ in $H^1_0(\Omega)$ defined by $H=\{v\in H^1_0(\Omega)~|~\int_\Omega v=0\}$ . Then once again by Lax-Milgram there's a unique solution $u'$ on $H$ . But it must be the same solution since $u$ is unique. So we get that for any solution $u$ of $\Delta u=f$ on $H^1_0(\Omega)$ one has $\int_\Omega u=0$ which is not true. Where is the mistake? Thank you!","I think I misunderstand the Lax-Milgram theorem. Suppose that I have a bilinear form satisfying the conditions of the Lax-Milgram theorem on a Hilbert space H. Then it must satisfy the same conditions on every Hilbert subspace of H. Therefore, the variational problem a(u,v)=l(v), where the linear form is continuous on H, has a unique solution on every Hilbert subspace of H. But from the point of view of PDE Hilbert subspaces are just additional conditions on the function. For example, let us consider the Poisson equation on a bounded domain . This problem has a unique solution on by Lax-Milgram. Let's take a hyperplane in defined by . Then once again by Lax-Milgram there's a unique solution on . But it must be the same solution since is unique. So we get that for any solution of on one has which is not true. Where is the mistake? Thank you!",a l \Delta u=f \Omega H^1_0(\Omega) H H^1_0(\Omega) H=\{v\in H^1_0(\Omega)~|~\int_\Omega v=0\} u' H u u \Delta u=f H^1_0(\Omega) \int_\Omega u=0,"['functional-analysis', 'partial-differential-equations']"
84,Every nonzero element in a Banach space has a norming extreme point,Every nonzero element in a Banach space has a norming extreme point,,"For any Banach space $F,$ let $B_F$ be the closed unit ball of $F,$ that is, $B_F = \{x\in F: \|x\| \leq 1\}.$ Also, let $ext B_F$ be the set of extreme points of $B_F$ (Recall that $x$ is an extreme point of $B_F$ if $x = \frac{1}{2}(x_1+x_2)$ for some $x_1,x_2\in B_F$ implies that $x= x_1=x_2.)$ Let $F^*$ be the continuous dual space of $F.$ Question: Let $F$ be a Banach space and $x\in F\setminus\{0\}.$ Is it true that there exists $x^*\in ext B_{F^*}$ such that $x^*(x) = \|x\|?$ I think it is true. Assume that $\|x\| = 1.$ Consider $$S = \{x^*\in B_{F^*}: x^*(x) = 1\}.$$ By Hahn-Banach Theorem, $S$ is nonempty.  Clearly $S$ is convex. I would like to show that $S$ is weak-star closed in $B_{F^*}$ so that it is weak-star compact (Banach-Alaoglu states that $B_{F^*}$ is weak-star compact). Then by Krein-Milman Theorem, $S$ has an extreme point, say $z^*.$ It is easy to see that $z^*$ is also an extreme point of $B_{F^*}.$ Such $z^*$ is our desired bounded linear functional. However, I am not sure how to show that $S$ is weak-star closed. Any hint is appreciated.","For any Banach space let be the closed unit ball of that is, Also, let be the set of extreme points of (Recall that is an extreme point of if for some implies that Let be the continuous dual space of Question: Let be a Banach space and Is it true that there exists such that I think it is true. Assume that Consider By Hahn-Banach Theorem, is nonempty.  Clearly is convex. I would like to show that is weak-star closed in so that it is weak-star compact (Banach-Alaoglu states that is weak-star compact). Then by Krein-Milman Theorem, has an extreme point, say It is easy to see that is also an extreme point of Such is our desired bounded linear functional. However, I am not sure how to show that is weak-star closed. Any hint is appreciated.","F, B_F F, B_F = \{x\in F: \|x\| \leq 1\}. ext B_F B_F x B_F x = \frac{1}{2}(x_1+x_2) x_1,x_2\in B_F x= x_1=x_2.) F^* F. F x\in F\setminus\{0\}. x^*\in ext B_{F^*} x^*(x) = \|x\|? \|x\| = 1. S = \{x^*\in B_{F^*}: x^*(x) = 1\}. S S S B_{F^*} B_{F^*} S z^*. z^* B_{F^*}. z^* S","['functional-analysis', 'banach-spaces', 'hahn-banach-theorem']"
85,I need help proving a result regarding multipliers for the HK integral,I need help proving a result regarding multipliers for the HK integral,,"A function $g:[a,b]\rightarrow \mathbb{R}$ is said to be of bounded variation on $[a,b]$ if $$ \sup\left\{\sum_{i=1}^n|g(x_i)-g(x_{i-1})|:a = x_0 <\ldots<x_n = b\right\}<+\infty. $$ If $g:[a,b]\rightarrow\mathbb{R}$ is of bounded variation on $[a,b]$ and $f:[a,b]\rightarrow \mathbb{R}$ is HK integrable on $[a,b]$ then $fg$ is HK integrable on $[a,b]$ . I have found proof of this that I am content with. I need help in proving or disproving the following statement: Let $g:[a,b] \rightarrow \mathbb{R}$ be a function. Then $fg$ is HK integrable on $[a,b]$ for all HK integrable functions $f:[a,b]\rightarrow \mathbb{R}$ if and only if $\exists g_0:[a,b]\rightarrow\mathbb{R}$ such that $g_0$ is of bounded variation on $[a,b]$ and $g_0 = g$ everywhere except for a set of Lebesgue measure $0$ . If my claim is wrong, please let me know.","A function is said to be of bounded variation on if If is of bounded variation on and is HK integrable on then is HK integrable on . I have found proof of this that I am content with. I need help in proving or disproving the following statement: Let be a function. Then is HK integrable on for all HK integrable functions if and only if such that is of bounded variation on and everywhere except for a set of Lebesgue measure . If my claim is wrong, please let me know.","g:[a,b]\rightarrow \mathbb{R} [a,b] 
\sup\left\{\sum_{i=1}^n|g(x_i)-g(x_{i-1})|:a = x_0 <\ldots<x_n = b\right\}<+\infty.
 g:[a,b]\rightarrow\mathbb{R} [a,b] f:[a,b]\rightarrow \mathbb{R} [a,b] fg [a,b] g:[a,b] \rightarrow \mathbb{R} fg [a,b] f:[a,b]\rightarrow \mathbb{R} \exists
g_0:[a,b]\rightarrow\mathbb{R} g_0 [a,b] g_0 = g 0","['real-analysis', 'integration', 'functional-analysis', 'analysis', 'gauge-integral']"
86,How can I solve a differential equation using Fourier transform?,How can I solve a differential equation using Fourier transform?,,"Could anyone please explain me how to solve differential equations using Fourier transform, distributions and Schwarz's spaces? I would be so grateful if you could help with a practical example -where i is the imaginary unit, i.e. $\sqrt{-1}$ (in theory I think I understood how it works but cannot actually solve any) \begin{equation} \frac{d^2u}{dx^2}+2i\frac{du}{dx}+4u=0 \end{equation} I tried to understand the passages but get stuck after applying the Fourier transform and transforming derivatives into multiplication by polynomials; in the example above, I get: \begin{equation} \left(-k^2-2k+4 \right) \hat{u}=0  \end{equation} At this point, I suppose I should think about a linear combination of $\delta$ and derivatives: $ \sum_{n}c_n\delta^{\left(n\right)}$ , since I have a distributional equation supported in zero. But I am not sure how to compute the coefficients and whether the method is right.","Could anyone please explain me how to solve differential equations using Fourier transform, distributions and Schwarz's spaces? I would be so grateful if you could help with a practical example -where i is the imaginary unit, i.e. (in theory I think I understood how it works but cannot actually solve any) I tried to understand the passages but get stuck after applying the Fourier transform and transforming derivatives into multiplication by polynomials; in the example above, I get: At this point, I suppose I should think about a linear combination of and derivatives: , since I have a distributional equation supported in zero. But I am not sure how to compute the coefficients and whether the method is right.","\sqrt{-1} \begin{equation}
\frac{d^2u}{dx^2}+2i\frac{du}{dx}+4u=0
\end{equation} \begin{equation}
\left(-k^2-2k+4 \right) \hat{u}=0 
\end{equation} \delta  \sum_{n}c_n\delta^{\left(n\right)}","['functional-analysis', 'ordinary-differential-equations', 'analysis', 'distribution-theory']"
87,Fourier Transform of indicator function of a cuboid,Fourier Transform of indicator function of a cuboid,,"In a proof of the Riemann-Lebesgue lemma I encountered the Fourier transform of the characteristic function $f$ of a cuboid $\prod_{k = 1}^{n} [a_k, b_k]$ . My lecture notes claim that $$ \mathcal{F}(f(\xi)) =\frac{1}{(2 \pi)^{\frac{n}{2}}} \prod_{i = 1}^{n} \frac{e^{-i \langle b_i, \xi \rangle} - e^{-i \langle a_i, \xi \rangle}}{i \xi_i}. $$ Besides the horrible misuse of $i$ as index (I presume the $i$ in the denominator is the imaginary unit) I don't think this is correct, as for one, $a_i, b_i \in \mathbb{R}$ , so taking their scalar product with $\xi \in \mathbb{R}^n$ doesn't make so much sense. Also, this doesn't work for $\xi_k = 0$ . If $\xi_k = 0$ for some $k \in \{1, \ldots, n\}$ , the corresponding factor is just $1$ , right? My approach to calculate $\mathcal{F}(f(\xi))$ would be as follows \begin{align} (2 \pi)^{-\frac{n}{2}}\int_{a_1}^{b_1} \ldots \int_{a_n}^{b_n} e^{-i \langle x, \xi \rangle} d x_1 \ldots d x_n & = (2 \pi)^{-\frac{n}{2}} \int_{a_1}^{b_1} \ldots \int_{a_n}^{b_n} \exp\left(-i \sum_{j = 1}^{n} x_j \xi_j\right) d x_1 \ldots d x_n \\ & = (2 \pi)^{-\frac{n}{2}} \prod_{k = 1}^{n} \int_{a_k}^{b_k} e^{-i x_k \xi_k} d x_k \\ & = (2 \pi)^{-\frac{n}{2}}\prod_{k = 1}^{n} \frac{i(e^{-i b_k \xi_k} - e^{-i a_k \xi_k})}{\xi_k}. \end{align} Questions Is the result from the lecture notes correct? If not, is it just a typo that can be easily fixed? Is my calculation correct?","In a proof of the Riemann-Lebesgue lemma I encountered the Fourier transform of the characteristic function of a cuboid . My lecture notes claim that Besides the horrible misuse of as index (I presume the in the denominator is the imaginary unit) I don't think this is correct, as for one, , so taking their scalar product with doesn't make so much sense. Also, this doesn't work for . If for some , the corresponding factor is just , right? My approach to calculate would be as follows Questions Is the result from the lecture notes correct? If not, is it just a typo that can be easily fixed? Is my calculation correct?","f \prod_{k = 1}^{n} [a_k, b_k] 
\mathcal{F}(f(\xi))
=\frac{1}{(2 \pi)^{\frac{n}{2}}} \prod_{i = 1}^{n} \frac{e^{-i \langle b_i, \xi \rangle} - e^{-i \langle a_i, \xi \rangle}}{i \xi_i}.
 i i a_i, b_i \in \mathbb{R} \xi \in \mathbb{R}^n \xi_k = 0 \xi_k = 0 k \in \{1, \ldots, n\} 1 \mathcal{F}(f(\xi)) \begin{align}
(2 \pi)^{-\frac{n}{2}}\int_{a_1}^{b_1} \ldots \int_{a_n}^{b_n} e^{-i \langle x, \xi \rangle} d x_1 \ldots d x_n
& = (2 \pi)^{-\frac{n}{2}} \int_{a_1}^{b_1} \ldots \int_{a_n}^{b_n} \exp\left(-i \sum_{j = 1}^{n} x_j \xi_j\right) d x_1 \ldots d x_n \\
& = (2 \pi)^{-\frac{n}{2}} \prod_{k = 1}^{n} \int_{a_k}^{b_k} e^{-i x_k \xi_k} d x_k \\
& = (2 \pi)^{-\frac{n}{2}}\prod_{k = 1}^{n} \frac{i(e^{-i b_k \xi_k} - e^{-i a_k \xi_k})}{\xi_k}.
\end{align}","['functional-analysis', 'fourier-analysis', 'proof-explanation', 'fourier-transform', 'solution-verification']"
88,Continuity of the distance from one dimensional subspaces in Banach spaces,Continuity of the distance from one dimensional subspaces in Banach spaces,,"Let $X$ be a Banach space, call $S_X$ its unit sphere and let $x\in X$ be fixed. Is it true that the function $f:S_X\rightarrow\mathbb{R}$ given by $y\mapsto\Vert x+\langle y\rangle\Vert$ (i.e. the distance of $x$ from the subspace spanned by $y$ ) is continuous? So far I only managed to prove its upper semicontinuity. If $\{y_n\} \subset S_X$ is a sequence of vectors converging to some $y\in S_X$ , observe that for each $n$ and each scalar $t$ one has $\Vert x+\langle y_n\rangle\Vert\leq\Vert x-ty_n\Vert$ . Passing to the limit on both sides one gets: $$ \limsup_{n\to+\infty}\Vert x+\langle y_n\rangle\Vert\leq\Vert x-ty\Vert $$ Finally, taking the infimum on the right side over all scalars $t$ leads to the formula: $$ \limsup_{n\to+\infty}\Vert x+\langle y_n\rangle\Vert\leq\Vert x+\langle y\rangle \Vert $$ Which proves the upper semicontinuity. What about lower semicontinuity? Any suggestion or help is much appreciated.","Let be a Banach space, call its unit sphere and let be fixed. Is it true that the function given by (i.e. the distance of from the subspace spanned by ) is continuous? So far I only managed to prove its upper semicontinuity. If is a sequence of vectors converging to some , observe that for each and each scalar one has . Passing to the limit on both sides one gets: Finally, taking the infimum on the right side over all scalars leads to the formula: Which proves the upper semicontinuity. What about lower semicontinuity? Any suggestion or help is much appreciated.",X S_X x\in X f:S_X\rightarrow\mathbb{R} y\mapsto\Vert x+\langle y\rangle\Vert x y \{y_n\} \subset S_X y\in S_X n t \Vert x+\langle y_n\rangle\Vert\leq\Vert x-ty_n\Vert  \limsup_{n\to+\infty}\Vert x+\langle y_n\rangle\Vert\leq\Vert x-ty\Vert  t  \limsup_{n\to+\infty}\Vert x+\langle y_n\rangle\Vert\leq\Vert x+\langle y\rangle \Vert ,"['functional-analysis', 'banach-spaces', 'normed-spaces', 'quotient-spaces']"
89,Norm topology and weak topology induce the same Borel sigma algebra on a Hilbert space,Norm topology and weak topology induce the same Borel sigma algebra on a Hilbert space,,"Let $H$ be a separable Hilbert space. Then the weak topology and the norm topology induce the same Borel sigma-algebra on $H$ . I suspect there is something wrong with the following argument, but I'm not sure what it is: Since the weak topology is weaker than the norm topology and $H$ is separable it suffices to show the Borel sigma algebra induced by the weak topology contains all closed balls. We have an isometric isomorphism from $H$ to its dual space given by $x \to \left<x, \cdot\right>$ , from which we see that the weak and weak star topologies coincide. Then by the Banach-Alaoglu theorem any closed ball $B = \{x\in H : \Vert x - y \Vert \leq r\}$ is compact in the weak topology, which implies $B$ is closed in the weak topology since it's Hausdorff.","Let be a separable Hilbert space. Then the weak topology and the norm topology induce the same Borel sigma-algebra on . I suspect there is something wrong with the following argument, but I'm not sure what it is: Since the weak topology is weaker than the norm topology and is separable it suffices to show the Borel sigma algebra induced by the weak topology contains all closed balls. We have an isometric isomorphism from to its dual space given by , from which we see that the weak and weak star topologies coincide. Then by the Banach-Alaoglu theorem any closed ball is compact in the weak topology, which implies is closed in the weak topology since it's Hausdorff.","H H H H x \to \left<x, \cdot\right> B = \{x\in H : \Vert x - y \Vert \leq r\} B","['functional-analysis', 'proof-verification', 'hilbert-spaces', 'borel-sets']"
90,Is every finite rank operator a linear combination of rank one projections?,Is every finite rank operator a linear combination of rank one projections?,,"Let $X$ be a Banach space and let $F(X)\subseteq B(X)$ be the subset of finite rank operators. Let $u\in F(X)$ , must $u$ be a linear combination of rank one projections? I know this result is true for Hilbert spaces, but I suspect it fails in general even though I don't have a counterexample.","Let be a Banach space and let be the subset of finite rank operators. Let , must be a linear combination of rank one projections? I know this result is true for Hilbert spaces, but I suspect it fails in general even though I don't have a counterexample.",X F(X)\subseteq B(X) u\in F(X) u,"['functional-analysis', 'banach-spaces']"
91,"Norm $||.||$ on $C(X)$ is equivalent to $||.||_{\infty}$ norm if evaluation linear functionals on $(C(X),||.||)$ is continuous.",Norm  on  is equivalent to  norm if evaluation linear functionals on  is continuous.,"||.|| C(X) ||.||_{\infty} (C(X),||.||)","Let $X$ be compact Hausdorff space. Let $||.||$ be a norm on $C(X)$ which makes it into a Banach space and also assume that the linear functional $\lambda_x$ given by $\lambda_x(f)=f(x)$ is continuous for each $x$ .  Show that there exist positive constants $A, B$ such that $$A||f||_{\infty}\le ||f|| \le B||f||_{\infty}.$$ I was trying to show that $f\to f$ is a bounded linear map from $(C(X),||.||)$ to $C(X)$ equipped with the sup norm. The map $f\to f$ is clearly one to one and onto, therefore open mapping theorem will give me the desired result. In order to show the continuity of the above map, I observe that $$|f(x)|=|\lambda_x(f)|\le ||\lambda_x|| ||f||.$$ I would want to supremum over all $x$ in both sides so that I can get the sup norm in LHS. But my issue is that I do not know a uniform bound on Norms of functionals $\lambda_x$ . I do not know how to by pass this, I have a feeling that Uniform boundedness principle can be useful to get a uniform bound on the Norms of these functionals but I am unable to carry out the task. Any help in this regard or any other way to attack this problem would be appreciated.","Let be compact Hausdorff space. Let be a norm on which makes it into a Banach space and also assume that the linear functional given by is continuous for each .  Show that there exist positive constants such that I was trying to show that is a bounded linear map from to equipped with the sup norm. The map is clearly one to one and onto, therefore open mapping theorem will give me the desired result. In order to show the continuity of the above map, I observe that I would want to supremum over all in both sides so that I can get the sup norm in LHS. But my issue is that I do not know a uniform bound on Norms of functionals . I do not know how to by pass this, I have a feeling that Uniform boundedness principle can be useful to get a uniform bound on the Norms of these functionals but I am unable to carry out the task. Any help in this regard or any other way to attack this problem would be appreciated.","X ||.|| C(X) \lambda_x \lambda_x(f)=f(x) x A, B A||f||_{\infty}\le ||f|| \le B||f||_{\infty}. f\to f (C(X),||.||) C(X) f\to f |f(x)|=|\lambda_x(f)|\le ||\lambda_x|| ||f||. x \lambda_x","['real-analysis', 'functional-analysis']"
92,Norm of a block of matrix operator,Norm of a block of matrix operator,,"Let $(\mathcal{H}_1,\langle \cdot\mid \cdot\rangle_1), (\mathcal{H}_2,\langle \cdot\mid \cdot\rangle_2), \cdots, (\mathcal{H}_d,\langle \cdot\mid \cdot\rangle_d)$ be complex Hilbert spaces and let $\mathbb{H}=\oplus_{i=1}^d\mathcal{H}_k$ . Let $\mathbb{T}= (T_{ij})_{d \times d}$ be an operator matrix on $\mathcal{B}(\oplus_{i=1}^d\mathcal{H}_k)$ and $\tilde{\mathbb{T}} = (\|T_{ij} \|_{\mathcal{B}(\mathcal{H}_j,\mathcal{H}_i)})_{d\times d}$ its block-norm matrix.   Why $$\|\mathbb{T}\|_{\mathcal{B}(\oplus_{i=1}^d\mathcal{H}_k)} \leq \| \tilde{\mathbb{T}} \|?$$ Attempt: Let $x=(x_1,\cdots,x_d)\in \oplus_{i=1}^d\mathcal{H}_k$ . Then, $$ \|\mathbb{T}x\|^2=\sum_k\left\|\sum_jT_{kj}x_j\right\|_k^2\leq\sum_k\left(\sum_j\|T_{kj}\|_{\mathcal{B}(\mathcal{H}_j,\mathcal{H}_k)}\,\|x_j\|_j\right)^2 . $$ On the other hand, $$\| \tilde{\mathbb{T}} \|=\sup_{\|x\|_{\mathbb{R}^d}}\| \tilde{\mathbb{T}}x\|.$$ For all $x=(x_1,\cdots,x_d)\in \mathbb{R}^d$ we have $$ \|\tilde{\mathbb{T}}x\|^2=\sum_k\left|\sum_j\|T_{kj}\|x_j\right|^2. $$","Let be complex Hilbert spaces and let . Let be an operator matrix on and its block-norm matrix.   Why Attempt: Let . Then, On the other hand, For all we have","(\mathcal{H}_1,\langle \cdot\mid \cdot\rangle_1), (\mathcal{H}_2,\langle \cdot\mid \cdot\rangle_2), \cdots, (\mathcal{H}_d,\langle \cdot\mid \cdot\rangle_d) \mathbb{H}=\oplus_{i=1}^d\mathcal{H}_k \mathbb{T}= (T_{ij})_{d \times d} \mathcal{B}(\oplus_{i=1}^d\mathcal{H}_k) \tilde{\mathbb{T}} = (\|T_{ij} \|_{\mathcal{B}(\mathcal{H}_j,\mathcal{H}_i)})_{d\times d} \|\mathbb{T}\|_{\mathcal{B}(\oplus_{i=1}^d\mathcal{H}_k)} \leq \| \tilde{\mathbb{T}} \|? x=(x_1,\cdots,x_d)\in \oplus_{i=1}^d\mathcal{H}_k 
\|\mathbb{T}x\|^2=\sum_k\left\|\sum_jT_{kj}x_j\right\|_k^2\leq\sum_k\left(\sum_j\|T_{kj}\|_{\mathcal{B}(\mathcal{H}_j,\mathcal{H}_k)}\,\|x_j\|_j\right)^2
.
 \| \tilde{\mathbb{T}} \|=\sup_{\|x\|_{\mathbb{R}^d}}\| \tilde{\mathbb{T}}x\|. x=(x_1,\cdots,x_d)\in \mathbb{R}^d 
\|\tilde{\mathbb{T}}x\|^2=\sum_k\left|\sum_j\|T_{kj}\|x_j\right|^2.
","['functional-analysis', 'operator-theory']"
93,How to show that a mapping is a 2-Lipschitz retraction from $l_\infty$ to $c_0$?,How to show that a mapping is a 2-Lipschitz retraction from  to ?,l_\infty c_0,"In the book ""Geometric Nonlinear Functional Analysis"" by Benyamini and Lindenstrauss, I came across an example (Example 1.5) in which the authors construct a retraction from $l_\infty$ to $c_0$ (both equipped with the supremum metric) and claim it is a Lipschitz mapping with constant 2. I give the definition below For a sequence $x=(x_n)_{n\in\mathbb N}\in l_\infty$ , denote $d(x)=\limsup|x_n|$ . We define $r:l_\infty\to c_0$ as follows. For $x=(x_n)_{n\in\mathbb N}$ and $n\in\mathbb N$ $$r(x)_n = \begin{cases} 0 &, |x_n|<d(x) \\                       (|x_n|-d(x))sign(x_n)&, |x_n|\geq d(x).\end{cases}$$ I can see why it is a well-defined retraction. However I cannot obtain the Lipschitzness at constant 2. Could you please give a solution or a hint?","In the book ""Geometric Nonlinear Functional Analysis"" by Benyamini and Lindenstrauss, I came across an example (Example 1.5) in which the authors construct a retraction from to (both equipped with the supremum metric) and claim it is a Lipschitz mapping with constant 2. I give the definition below For a sequence , denote . We define as follows. For and I can see why it is a well-defined retraction. However I cannot obtain the Lipschitzness at constant 2. Could you please give a solution or a hint?","l_\infty c_0 x=(x_n)_{n\in\mathbb N}\in l_\infty d(x)=\limsup|x_n| r:l_\infty\to c_0 x=(x_n)_{n\in\mathbb N} n\in\mathbb N r(x)_n = \begin{cases} 0 &, |x_n|<d(x) \\
                      (|x_n|-d(x))sign(x_n)&, |x_n|\geq d(x).\end{cases}","['functional-analysis', 'metric-spaces', 'lipschitz-functions', 'retraction']"
94,Showing that the $T: \operatorname{dom}(T) \to \ell^{2}$ is closed,Showing that the  is closed,T: \operatorname{dom}(T) \to \ell^{2},"Let $T:\operatorname{dom}(T) \to \ell^{2}$ where $T(x^{n})=(mx_{m}^{n})_{m \in \mathbb N}$ Let $\operatorname{dom}(T):=\{x^{n}\in \ell^{2}: (mx_{m}^{n})_{m \in \mathbb N} \in \ell^{²}\}$ Determine whether $T$ is closed or not: Initially I attempted to show that $T$ is closed, by assuming a $(x^{n})_{n} \subseteq \ell^{2}$ where $x^{n}\xrightarrow{n \to \infty, \vert \vert \cdot \vert \vert_{2}} x$ and $T(x^{n})\xrightarrow {n \to \infty, \vert \vert \cdot \vert \vert_{2}}y$ . In order to show that $x \in \operatorname{dom}(T)$ , note that from $x^{n}\xrightarrow{n \to \infty, \vert \vert \cdot \vert \vert_{2}} x$ that it follows: $\lim\limits_{m \to \infty}x^{m}_{i}=x_{i}$ for all $ i \in \mathbb N$ and hence let $N \in \mathbb N$ arbitrary: First question: convergence in $\ell^{p}, 1\leq p<\infty$ of $(x^{n})_{n}$ to $x$ does imply convergence in each respective   coordinate, correct? $\sum\limits_{i=1}^{N} \vert x_{i} \vert^{2}=\lim\limits_{m\to \infty}\sum\limits_{i=1}^{N} \vert x_{i}^{m} \vert^{2}\leq\lim\limits_{m\to \infty}\vert\vert x^{m}\vert\vert_{2}^{2}$ , but this estimate does not help me. So, I now believe that it may not be closed. Any ideas on showing that it is not closed.","Let where Let Determine whether is closed or not: Initially I attempted to show that is closed, by assuming a where and . In order to show that , note that from that it follows: for all and hence let arbitrary: First question: convergence in of to does imply convergence in each respective   coordinate, correct? , but this estimate does not help me. So, I now believe that it may not be closed. Any ideas on showing that it is not closed.","T:\operatorname{dom}(T) \to \ell^{2} T(x^{n})=(mx_{m}^{n})_{m \in \mathbb N} \operatorname{dom}(T):=\{x^{n}\in \ell^{2}: (mx_{m}^{n})_{m \in \mathbb N} \in \ell^{²}\} T T (x^{n})_{n} \subseteq \ell^{2} x^{n}\xrightarrow{n \to \infty, \vert \vert \cdot \vert \vert_{2}} x T(x^{n})\xrightarrow {n \to \infty, \vert \vert \cdot \vert \vert_{2}}y x \in \operatorname{dom}(T) x^{n}\xrightarrow{n \to \infty, \vert \vert \cdot \vert \vert_{2}} x \lim\limits_{m \to \infty}x^{m}_{i}=x_{i}  i \in \mathbb N N \in \mathbb N \ell^{p}, 1\leq p<\infty (x^{n})_{n} x \sum\limits_{i=1}^{N} \vert x_{i} \vert^{2}=\lim\limits_{m\to \infty}\sum\limits_{i=1}^{N} \vert x_{i}^{m} \vert^{2}\leq\lim\limits_{m\to \infty}\vert\vert x^{m}\vert\vert_{2}^{2}","['real-analysis', 'functional-analysis', 'operator-theory', 'lp-spaces', 'closed-graph']"
95,Tensor product of holomorphic functions and density,Tensor product of holomorphic functions and density,,"Let $\Omega_1, \Omega_2$ be two open subsets of $\mathbb{C}.$ Is the image of $$\Phi : \mathcal{O}(\Omega_1) \times \mathcal{O}(\Omega_2) \to \mathcal{O}(\Omega_1 \times \Omega_2), (f,g)\mapsto ((z,w) \mapsto f(z)g(w))$$ dense in $\mathcal{O}(\Omega_1 \times \Omega_2)$ ? (Here the topology is the uniform convergence on compact subsets.) I know the result for test functions but I wonder if it is true for holomorphic functions. Maybe with some extra-conditions on the open subsets ? Thanks for any help/suggestion.",Let be two open subsets of Is the image of dense in ? (Here the topology is the uniform convergence on compact subsets.) I know the result for test functions but I wonder if it is true for holomorphic functions. Maybe with some extra-conditions on the open subsets ? Thanks for any help/suggestion.,"\Omega_1, \Omega_2 \mathbb{C}. \Phi : \mathcal{O}(\Omega_1) \times \mathcal{O}(\Omega_2) \to \mathcal{O}(\Omega_1 \times \Omega_2), (f,g)\mapsto ((z,w) \mapsto f(z)g(w)) \mathcal{O}(\Omega_1 \times \Omega_2)","['complex-analysis', 'functional-analysis']"
96,"Schwartz space, Gaussian measures and integration over paths","Schwartz space, Gaussian measures and integration over paths",,"I'm studying the Wiener measure motivated by the path integral in quantum mechanics. For that I'm using the book by Glimm & Jaffe ""Quantum Physics: a Functional Integral Point of View"" that deals with it from that perspective. Now, I'm having a problem in understanding a part of the book, that I think might be just a notation problem. The notations I'm used to For me $\mathscr{S}(\mathbb{R}^d)$ , the space of Schwartz functions, is the space of smooth functions $f : \mathbb{R}^d\to \mathbb{R}$ with the property that: $$\sup_{x\in \mathbb{R}^d}x^\alpha D^\beta f(x)<\infty,\quad \alpha,\beta \ \text{multi-indices}.$$ Similarly, for me $\mathscr{S}'(\mathbb{R}^d)$ means the space of continuous linear functionals on $\mathscr{S}(\mathbb{R}^d)$ . I know then that we have: $$\mathscr{S}(\mathbb{R}^d)\subset \mathscr{S}'(\mathbb{R}^d),$$ so that $\mathscr{S}'(\mathbb{R}^d)$ can be seen as an enlargement of $\mathscr{S}(\mathbb{R}^d)$ .The key point is: in what I'm used to a Schwartz distribution is a linear functional acting on $f : \mathbb{R^d}\to \mathbb{R}$ maps which can be seen as a more general class of such maps . What Glimm and Jaffe seem to do My issue is that Glimm & Jaffe talks many times about constructing gaussian measures (and in particular the Wiener measure) on the space of Schwartz distributions. In particular, since $\mathscr{S}(\mathbb{R}^d)\subset \mathscr{S}'(\mathbb{R}^d)$ this measure allows to integrate over functions $f : \mathbb{R}^d\to \mathbb{R}$ . These are not paths by any means. Let me make my issue crystal clear: my issue is not on working with the dual. This seems a standard thing to do to deal with singular objects. Furthermore, later on one could see how to restrict the measure to the original space. My issue is that the original space here is a space of functions $f : \mathbb{R}^d\to \mathbb{R}$ while paths must be functions $f: [a,b]\to \mathbb{R}^d$ . So I ask: how the Schwartz space relates to paths in Glimm & Jaffe treatment? How one integration over paths (Wiener measure) can be related with an integration over real-valued functions? Is it perhaps another Schwartz space of functions, whose elements are indeed paths, and hence another Schwartz distribution space, whose elements are linear functionals on paths?","I'm studying the Wiener measure motivated by the path integral in quantum mechanics. For that I'm using the book by Glimm & Jaffe ""Quantum Physics: a Functional Integral Point of View"" that deals with it from that perspective. Now, I'm having a problem in understanding a part of the book, that I think might be just a notation problem. The notations I'm used to For me , the space of Schwartz functions, is the space of smooth functions with the property that: Similarly, for me means the space of continuous linear functionals on . I know then that we have: so that can be seen as an enlargement of .The key point is: in what I'm used to a Schwartz distribution is a linear functional acting on maps which can be seen as a more general class of such maps . What Glimm and Jaffe seem to do My issue is that Glimm & Jaffe talks many times about constructing gaussian measures (and in particular the Wiener measure) on the space of Schwartz distributions. In particular, since this measure allows to integrate over functions . These are not paths by any means. Let me make my issue crystal clear: my issue is not on working with the dual. This seems a standard thing to do to deal with singular objects. Furthermore, later on one could see how to restrict the measure to the original space. My issue is that the original space here is a space of functions while paths must be functions . So I ask: how the Schwartz space relates to paths in Glimm & Jaffe treatment? How one integration over paths (Wiener measure) can be related with an integration over real-valued functions? Is it perhaps another Schwartz space of functions, whose elements are indeed paths, and hence another Schwartz distribution space, whose elements are linear functionals on paths?","\mathscr{S}(\mathbb{R}^d) f : \mathbb{R}^d\to \mathbb{R} \sup_{x\in \mathbb{R}^d}x^\alpha D^\beta f(x)<\infty,\quad \alpha,\beta \ \text{multi-indices}. \mathscr{S}'(\mathbb{R}^d) \mathscr{S}(\mathbb{R}^d) \mathscr{S}(\mathbb{R}^d)\subset \mathscr{S}'(\mathbb{R}^d), \mathscr{S}'(\mathbb{R}^d) \mathscr{S}(\mathbb{R}^d) f : \mathbb{R^d}\to \mathbb{R} \mathscr{S}(\mathbb{R}^d)\subset \mathscr{S}'(\mathbb{R}^d) f : \mathbb{R}^d\to \mathbb{R} f : \mathbb{R}^d\to \mathbb{R} f: [a,b]\to \mathbb{R}^d","['functional-analysis', 'measure-theory', 'definition', 'wiener-measure']"
97,Two questions on the Fourier transform for $\mathcal{L}_2(\mathbb R)$-functions.,Two questions on the Fourier transform for -functions.,\mathcal{L}_2(\mathbb R),"I have read that for $f\in\mathcal{L}_2(\mathbb R)$ , its Fourier transform need not coincide with the familiar form for $\mathcal{L}_1(\mathbb R)$ -functions, on account that this integral might not exist . For $g\in\mathcal{L}_1(\mathbb R)$ the 'familiar form' of its Fourier transform I take to be: $$\hat g(t)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty \exp(-ist)g(s)\text{d}s,$$ for $t\in\mathbb R$ . What are examples of $f\in \mathcal{L}_2(\mathbb R)$ for which this idea is exemplified? That is to say, for whom the above integral representation need not exist; the more accessible the example, the better. To circumvent this, for $f\in \mathcal{L}_2(\mathbb R)$ we can take as the expression for its Fourier transform $$\hat f(t)=\lim_{N\to\infty}\int_{-N}^N\exp(-ist)f(s)\text{d}s.$$ The limit here is with respect to the $\mathcal{L}_2(\mathbb R)$ -norm. With regards to this, I have read that this representation is on account of the Dominated Convergence Theorem . How is it, exactly, that the Dominated Convergence Theorem has been applied to give us this workable form of the Fourier transform for $f\in\mathcal{L}_2(\mathbb R)$ ? Also, how does it allow us to avoid the convergence issues of the 'familiar form' first considered?","I have read that for , its Fourier transform need not coincide with the familiar form for -functions, on account that this integral might not exist . For the 'familiar form' of its Fourier transform I take to be: for . What are examples of for which this idea is exemplified? That is to say, for whom the above integral representation need not exist; the more accessible the example, the better. To circumvent this, for we can take as the expression for its Fourier transform The limit here is with respect to the -norm. With regards to this, I have read that this representation is on account of the Dominated Convergence Theorem . How is it, exactly, that the Dominated Convergence Theorem has been applied to give us this workable form of the Fourier transform for ? Also, how does it allow us to avoid the convergence issues of the 'familiar form' first considered?","f\in\mathcal{L}_2(\mathbb R) \mathcal{L}_1(\mathbb R) g\in\mathcal{L}_1(\mathbb R) \hat g(t)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty \exp(-ist)g(s)\text{d}s, t\in\mathbb R f\in \mathcal{L}_2(\mathbb R) f\in \mathcal{L}_2(\mathbb R) \hat f(t)=\lim_{N\to\infty}\int_{-N}^N\exp(-ist)f(s)\text{d}s. \mathcal{L}_2(\mathbb R) f\in\mathcal{L}_2(\mathbb R)","['integration', 'functional-analysis', 'fourier-analysis', 'fourier-transform']"
98,Adjoint of a linear isomorphic functional is an isomorphism,Adjoint of a linear isomorphic functional is an isomorphism,,"I have this exercise to solve: Let $E$ and $F$ be normed spaces and let $T \in L(E,F)$ , where $L(E,F)$ denotes the set of all bounded linear operators from $E$ to $F$ . $T^*$ is the dual operator of $T$ with $T^*: F^* \to E^*$ and $T^*\varphi=\varphi \circ T$ . Assume $T$ is an isomorphism, i.e. $T$ is bijective and $T^{-1}\in L(F,E)$ . Prove that $T^*$ is also an isomorphism and $(T^*)^{-1}=(T^{-1})^*$ . My work Proof of $(T^*)^{-1}=(T^{-1})^*$ : We know that $(T \circ G)^*= T^*\circ G^*$ since $((T \circ G)^*\varphi)(x)=\varphi((T\circ G)(x))=(G^*\varphi)(Tx)=((T^*\circ G^*)\varphi)(x)$ Now plug in $T^*$ and $(T^{-1})^*$ to the equation, we have: $T^*\circ (T^{-1})^* = (T\circ T^{-1})^*= Id^* = Id$ and $(T^{-1})^* \circ T^* = (T^{-1}\circ T)^*= Id^* = Id$ Hence, $(T^*)^{-1}=(T^{-1})^*$ . Proof of isomorphism: Injectivity: Let $\varphi$ and $\psi \in F^*$ . Let $T^*\varphi=T^*\psi$ then we have $\varphi \circ T=\psi \circ T$ . Here can I conclude that since $T$ bijective we have $\varphi = \psi$ ? It remains to prove the surjectivity and I'm still struggling with this part.","I have this exercise to solve: Let and be normed spaces and let , where denotes the set of all bounded linear operators from to . is the dual operator of with and . Assume is an isomorphism, i.e. is bijective and . Prove that is also an isomorphism and . My work Proof of : We know that since Now plug in and to the equation, we have: and Hence, . Proof of isomorphism: Injectivity: Let and . Let then we have . Here can I conclude that since bijective we have ? It remains to prove the surjectivity and I'm still struggling with this part.","E F T \in L(E,F) L(E,F) E F T^* T T^*: F^* \to E^* T^*\varphi=\varphi \circ T T T T^{-1}\in L(F,E) T^* (T^*)^{-1}=(T^{-1})^* (T^*)^{-1}=(T^{-1})^* (T \circ G)^*= T^*\circ G^* ((T \circ G)^*\varphi)(x)=\varphi((T\circ G)(x))=(G^*\varphi)(Tx)=((T^*\circ G^*)\varphi)(x) T^* (T^{-1})^* T^*\circ (T^{-1})^* = (T\circ T^{-1})^*= Id^* = Id (T^{-1})^* \circ T^* = (T^{-1}\circ T)^*= Id^* = Id (T^*)^{-1}=(T^{-1})^* \varphi \psi \in F^* T^*\varphi=T^*\psi \varphi \circ T=\psi \circ T T \varphi = \psi","['functional-analysis', 'normed-spaces', 'dual-spaces']"
99,Every surjective isometry on a Hilbert space is indeed a unitary operator,Every surjective isometry on a Hilbert space is indeed a unitary operator,,"I have a little bit confused on unitary operators and surjective isometries on a Hilbert space. I think it is quite clear that A operator is unitary if and only if it is a surjective isometry . However, according to the first line of the 2nd page of https://link.springer.com/article/10.1007/BF02761592 (or first paragraph of the 2nd page of https://core.ac.uk/download/pdf/82282502.pdf ), there are more surjective isometries on a Hilbert space onto itself than unitary operators. Is it a contradiction or did I misunderstand something?","I have a little bit confused on unitary operators and surjective isometries on a Hilbert space. I think it is quite clear that A operator is unitary if and only if it is a surjective isometry . However, according to the first line of the 2nd page of https://link.springer.com/article/10.1007/BF02761592 (or first paragraph of the 2nd page of https://core.ac.uk/download/pdf/82282502.pdf ), there are more surjective isometries on a Hilbert space onto itself than unitary operators. Is it a contradiction or did I misunderstand something?",,"['functional-analysis', 'metric-spaces', 'hilbert-spaces', 'operator-algebras', 'isometry']"
