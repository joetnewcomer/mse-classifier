,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Assigning values to divergent series,Assigning values to divergent series,,"I have been looking at divergent series on wikipedia and other sources and it seems people give finite ""values"" to specific ones. I understand that these values sometimes reflect the algebraic properties of the series in question, but do not actually represent what the series converges to, which is infinity. Why is it usefull to assign values to divergent series? The only theory I could come up with, is this: Say you have 2 divergent series, series' A and B, and you assign each a value, Series ($A= \sum_{n=0}^\infty a_n$), which I assigned the value Q and series ($B= \sum_{n=0}^\infty b_n$ ), which I assigned the value P But it just so happens that series $C=A-B= \sum_{n=0}^\infty (a_n-b_n)$ converges. Could that imply that the actual value of series $C$ is the difference of the two assigned values to $A$ and $B$, that is $\sum_{n=0}^\infty (a_n-b_n)=Q-P$ ? If so, then that would make some sense to me, as to why people sometimes assign values to divergent series.","I have been looking at divergent series on wikipedia and other sources and it seems people give finite ""values"" to specific ones. I understand that these values sometimes reflect the algebraic properties of the series in question, but do not actually represent what the series converges to, which is infinity. Why is it usefull to assign values to divergent series? The only theory I could come up with, is this: Say you have 2 divergent series, series' A and B, and you assign each a value, Series ($A= \sum_{n=0}^\infty a_n$), which I assigned the value Q and series ($B= \sum_{n=0}^\infty b_n$ ), which I assigned the value P But it just so happens that series $C=A-B= \sum_{n=0}^\infty (a_n-b_n)$ converges. Could that imply that the actual value of series $C$ is the difference of the two assigned values to $A$ and $B$, that is $\sum_{n=0}^\infty (a_n-b_n)=Q-P$ ? If so, then that would make some sense to me, as to why people sometimes assign values to divergent series.",,"['sequences-and-series', 'divergent-series']"
1,Interchange finite and infinite sum,Interchange finite and infinite sum,,"Under which condition is it valid to interchange a finite and an infinite sum? We have used $$\sum_{x \in I} \sum_{y=0}^{\infty} f_{x,y}= \sum_{y=0}^{\infty} \sum_{x \in I} f_{x,y}$$ for a finite set $I$. Is this always valid or only under certain circumstances? Under which conditions would it be valid for an infinite (countable) set $I$? Thank you very much.","Under which condition is it valid to interchange a finite and an infinite sum? We have used $$\sum_{x \in I} \sum_{y=0}^{\infty} f_{x,y}= \sum_{y=0}^{\infty} \sum_{x \in I} f_{x,y}$$ for a finite set $I$. Is this always valid or only under certain circumstances? Under which conditions would it be valid for an infinite (countable) set $I$? Thank you very much.",,"['sequences-and-series', 'summation']"
2,How to prove this inequality $x^2_{n}\le\frac{8}{3}$,How to prove this inequality,x^2_{n}\le\frac{8}{3},"let sequence $\{x_{n}\}$ such $x_{1}=0,x_{2}=1$ ,and $$x_{n+1}=\left(1+\dfrac{1}{n}\right)x_{n}-x_{n-1},n\ge 2$$ show that $$x^2_{n}\le\dfrac{8}{3}$$ This problem it seem interesting,and $$x_{n+1}-x_{n}=\dfrac{1}{n}x_{n}-x_{n-1}$$ so we have $$x_{n+1}-x_{1}=\sum_{k=1}^{n}\dfrac{x_{k}}{k}-\sum_{k=1}^{n-1}x_{k}$$ where $x_{0}=-1$ It seem this problem very interesting,I guess this $\dfrac{8}{3}$ maybe is not best constant,But is stronger constant","let sequence such ,and show that This problem it seem interesting,and so we have where It seem this problem very interesting,I guess this maybe is not best constant,But is stronger constant","\{x_{n}\} x_{1}=0,x_{2}=1 x_{n+1}=\left(1+\dfrac{1}{n}\right)x_{n}-x_{n-1},n\ge 2 x^2_{n}\le\dfrac{8}{3} x_{n+1}-x_{n}=\dfrac{1}{n}x_{n}-x_{n-1} x_{n+1}-x_{1}=\sum_{k=1}^{n}\dfrac{x_{k}}{k}-\sum_{k=1}^{n-1}x_{k} x_{0}=-1 \dfrac{8}{3}","['sequences-and-series', 'inequality']"
3,Equivalent definitions of unconditional convergence,Equivalent definitions of unconditional convergence,,"I am across two definitions for unconditional convergence for which it is not immediately obvious to me that they are equivalent. Here are the definitions. Throughout, $\frak{X}$ will denote a Banach space. Definition 1. Given a series $\sum x_n$ in $\frak{X}$, we say that this series converges unconditionally to $x$ if for every $\varepsilon>0$, there is a finite subset $J\subseteq \mathbb{N}$ such that for every finite subset $I$ such that $J\subseteq I\subseteq\mathbb{N}$ one has $\|x - \sum_{i\in I}x_i\|<\varepsilon$. Definition 2. A series $\sum x_n$ in $\frak{X}$ is said to converge unconditionally to $x$ if for any permutation $\sigma:\mathbb{N}\to \mathbb{N}$, the series $\sum x_{\sigma(n)}$ converges to $x$. I was wondering how one might go about proving that these two definitions are equivalent.","I am across two definitions for unconditional convergence for which it is not immediately obvious to me that they are equivalent. Here are the definitions. Throughout, $\frak{X}$ will denote a Banach space. Definition 1. Given a series $\sum x_n$ in $\frak{X}$, we say that this series converges unconditionally to $x$ if for every $\varepsilon>0$, there is a finite subset $J\subseteq \mathbb{N}$ such that for every finite subset $I$ such that $J\subseteq I\subseteq\mathbb{N}$ one has $\|x - \sum_{i\in I}x_i\|<\varepsilon$. Definition 2. A series $\sum x_n$ in $\frak{X}$ is said to converge unconditionally to $x$ if for any permutation $\sigma:\mathbb{N}\to \mathbb{N}$, the series $\sum x_{\sigma(n)}$ converges to $x$. I was wondering how one might go about proving that these two definitions are equivalent.",,"['sequences-and-series', 'functional-analysis', 'convergence-divergence', 'banach-spaces']"
4,Existence of $A$ such that $ \lim_{x\to\infty}\operatorname{poly}(x) e^{-x} \sum_{n\in A} \frac{x^n}{n!}=1 $,Existence of  such that,A  \lim_{x\to\infty}\operatorname{poly}(x) e^{-x} \sum_{n\in A} \frac{x^n}{n!}=1 ,"I want to know if there exists a set $A \subseteq \mathbb{N}$ such that $$ \lim_{x\to\infty} x^2 e^{-x} \sum_{n\in A} \dfrac{x^n}{n!}=1 $$ More generally, the question will be the existence of a set $A$ that $$ \lim_{x\to\infty}\operatorname{poly}(x) e^{-x} \sum_{n\in A} \dfrac{x^n}{n!}=1 $$ When $A$ is finite, it is obvious that the limit must be $0$ . But when $A$ is infinite, the structure of $A$ can be very complex, and I don't know how to proceed further.","I want to know if there exists a set such that More generally, the question will be the existence of a set that When is finite, it is obvious that the limit must be . But when is infinite, the structure of can be very complex, and I don't know how to proceed further.","A \subseteq \mathbb{N} 
\lim_{x\to\infty} x^2 e^{-x} \sum_{n\in A} \dfrac{x^n}{n!}=1
 A 
\lim_{x\to\infty}\operatorname{poly}(x) e^{-x} \sum_{n\in A} \dfrac{x^n}{n!}=1
 A 0 A A","['sequences-and-series', 'limits', 'analysis']"
5,What loops are possible when doing this function to the rationals?,What loops are possible when doing this function to the rationals?,,"What loops are possible when doing this function to the rationals? Let's define this function on a simplified fraction $\frac{a}{b}$ . $$f\left(\frac{a}{b}\right)=\frac{a+b}{b+1}$$ I started this with $f(\frac{2}{3})=\frac{5}{4}$ then i did the function again and got this sequence of numbers $\frac{2}{3},\frac{5}{4},\frac{9}{5},\frac{7}{3},\frac{5}{2},\frac{7}{3},\dots$ I saw that is starts to loop with $\frac{7}{3},\frac{5}{2}$ Another loop is $\frac{1}{1}$ , a one cycle. Another loop I found was $\frac{2}{1},\frac{3}{2},\frac{5}{3}$ . My first question is: from starting from any rational number does it all ways end in a loop or does it ever go to infinity? And my second question is: what sizes of loops are possible? If the three loops I stated are the only loops prove it Dark made a post related What are the possible loops when doing this a type of function to the rationals?","What loops are possible when doing this function to the rationals? Let's define this function on a simplified fraction . I started this with then i did the function again and got this sequence of numbers I saw that is starts to loop with Another loop is , a one cycle. Another loop I found was . My first question is: from starting from any rational number does it all ways end in a loop or does it ever go to infinity? And my second question is: what sizes of loops are possible? If the three loops I stated are the only loops prove it Dark made a post related What are the possible loops when doing this a type of function to the rationals?","\frac{a}{b} f\left(\frac{a}{b}\right)=\frac{a+b}{b+1} f(\frac{2}{3})=\frac{5}{4} \frac{2}{3},\frac{5}{4},\frac{9}{5},\frac{7}{3},\frac{5}{2},\frac{7}{3},\dots \frac{7}{3},\frac{5}{2} \frac{1}{1} \frac{2}{1},\frac{3}{2},\frac{5}{3}",['sequences-and-series']
6,Formula for the harmonic series $H_n = \sum_{k=1}^n 1/k$ due to Gregorio Fontana.,Formula for the harmonic series  due to Gregorio Fontana.,H_n = \sum_{k=1}^n 1/k,"My question was inspired by this stackexchange question. For the last 90 minutes I have been trying to prove this formula due to Gregorio Fontana : $$H_n = \gamma + \log n + {1 \over 2n} - \sum_{k=2}^\infty { (k-1)! C_k \over n(n+1)\ldots(n+k-1)}, \qquad \textrm{ for } n=1,2,3,\ldots,$$ where $H_n = \sum\limits_{k=1}^n 1/k$ and the coefficients $C_k$ are the Gregory coefficients given by $${ z \over \log(1-z)} = \sum_{n=0}^\infty C_k z^k \qquad \textrm{ for } |z|<1.$$ It's a bit frustrating as it's something I recall proving as a student many years ago. I have a vague recollection that I began with something like: $$H_n = \int_0^1 {1-(1-x)^n \over x } \textrm{d}x,$$ but my attempts to follow on from there have failed. Can you help?",My question was inspired by this stackexchange question. For the last 90 minutes I have been trying to prove this formula due to Gregorio Fontana : where and the coefficients are the Gregory coefficients given by It's a bit frustrating as it's something I recall proving as a student many years ago. I have a vague recollection that I began with something like: but my attempts to follow on from there have failed. Can you help?,"H_n = \gamma + \log n + {1 \over 2n} - \sum_{k=2}^\infty { (k-1)! C_k \over n(n+1)\ldots(n+k-1)},
\qquad \textrm{ for } n=1,2,3,\ldots, H_n = \sum\limits_{k=1}^n 1/k C_k { z \over \log(1-z)} = \sum_{n=0}^\infty C_k z^k \qquad \textrm{ for } |z|<1. H_n = \int_0^1 {1-(1-x)^n \over x } \textrm{d}x,","['sequences-and-series', 'harmonic-numbers']"
7,Convergence of series $\sum\limits_{k=1}^\infty\frac{1}{X_1+\dots+X_k}$ with $(X_k)$ i.i.d. non integrable,Convergence of series  with  i.i.d. non integrable,\sum\limits_{k=1}^\infty\frac{1}{X_1+\dots+X_k} (X_k),"Pick a sequence $X_1$, $X_2$, $\dots$, of i.i.d. random variables taking values in positive integers with $\mathbb{P}(X_i=n)=\frac{1}{n}-\frac{1}{n+1}=\frac{1}{n(n+1)}$ for every positive integer $n$. Q: Does the sum $\frac{1}{X_1}+\frac{1}{X_1+X_2}+\frac{1}{X_1+X_2+X_3}+\dots=\sum\limits_{k=1}^\infty\frac{1}{X_1+\dots+X_k}$ converge a.s.? In other words, is it finite a.s.? Some remarks: 1. Some slick computations using the generating function of $X_i$ show that the expected value of the sum is $+\infty$, so it gives us no information. 2. For any fixed $i$, eventually every denominator $X_1+\dots+X_k$ becomes much larger than $X_i$. So convergence of the sum is independent of $X_i$ (more precisely of $(X_1,\dots,X_i)$ jointly) and by Kolmogorov's 0-1 law either the sum converges a.s. or it diverges a.s. 3. Notice that $\mathbb{E}[X_i]=+\infty$, so by the strong law of large numbers (applied to suitable truncations of the $X_i$'s) we have $\frac{X_1+\dots+X_k}{k}\to +\infty$ a.s. So, if we rewrite our series as $\sum_{k=1}^\infty\frac{1}{k}\left(\frac{X_1+\dots+X_k}{k}\right)^{-1}$, we can conclude that it grows slower than the harmonic series. 4. Easy estimates show that the problem is equivalent to the convergence of $\sum\limits_{k=1}^\infty \frac{1}{t_1^{-1}+\dots+t_k^{-1}}$, where $(t_i)_{i\ge 1}$ is a sequence of independent uniform random variables on $(0,1)$. 5. If we use the $t_i's$, we can rewrite the sum as $\sum\limits_{k=1}^\infty\frac{1}{k} HM(t_1,\dots,t_k)$, where $HM$ denotes the harmonic mean. The inequality $HM\le GM$ ($GM$ is the geometric mean) does not help, since by the strong law of large numbers we get $\sum\limits_{k=1}^\infty\frac{1}{k} GM(t_1,\dots,t_k)\sim\sum\limits_{k=1}^\infty\frac{\alpha}{k}=+\infty$ where $\alpha:=\exp\left(\int_0^1 \log t\,dt\right)=\frac{1}{e}$. I do not know the origin of the problem, but it is interesting as it seems to require sharp estimates to solve it. Any idea is appreciated.","Pick a sequence $X_1$, $X_2$, $\dots$, of i.i.d. random variables taking values in positive integers with $\mathbb{P}(X_i=n)=\frac{1}{n}-\frac{1}{n+1}=\frac{1}{n(n+1)}$ for every positive integer $n$. Q: Does the sum $\frac{1}{X_1}+\frac{1}{X_1+X_2}+\frac{1}{X_1+X_2+X_3}+\dots=\sum\limits_{k=1}^\infty\frac{1}{X_1+\dots+X_k}$ converge a.s.? In other words, is it finite a.s.? Some remarks: 1. Some slick computations using the generating function of $X_i$ show that the expected value of the sum is $+\infty$, so it gives us no information. 2. For any fixed $i$, eventually every denominator $X_1+\dots+X_k$ becomes much larger than $X_i$. So convergence of the sum is independent of $X_i$ (more precisely of $(X_1,\dots,X_i)$ jointly) and by Kolmogorov's 0-1 law either the sum converges a.s. or it diverges a.s. 3. Notice that $\mathbb{E}[X_i]=+\infty$, so by the strong law of large numbers (applied to suitable truncations of the $X_i$'s) we have $\frac{X_1+\dots+X_k}{k}\to +\infty$ a.s. So, if we rewrite our series as $\sum_{k=1}^\infty\frac{1}{k}\left(\frac{X_1+\dots+X_k}{k}\right)^{-1}$, we can conclude that it grows slower than the harmonic series. 4. Easy estimates show that the problem is equivalent to the convergence of $\sum\limits_{k=1}^\infty \frac{1}{t_1^{-1}+\dots+t_k^{-1}}$, where $(t_i)_{i\ge 1}$ is a sequence of independent uniform random variables on $(0,1)$. 5. If we use the $t_i's$, we can rewrite the sum as $\sum\limits_{k=1}^\infty\frac{1}{k} HM(t_1,\dots,t_k)$, where $HM$ denotes the harmonic mean. The inequality $HM\le GM$ ($GM$ is the geometric mean) does not help, since by the strong law of large numbers we get $\sum\limits_{k=1}^\infty\frac{1}{k} GM(t_1,\dots,t_k)\sim\sum\limits_{k=1}^\infty\frac{\alpha}{k}=+\infty$ where $\alpha:=\exp\left(\int_0^1 \log t\,dt\right)=\frac{1}{e}$. I do not know the origin of the problem, but it is interesting as it seems to require sharp estimates to solve it. Any idea is appreciated.",,"['sequences-and-series', 'probability-theory', 'probability-limit-theorems']"
8,Greatest number of non-attacking moves that queens can make on an $n \times n$ chess board.,Greatest number of non-attacking moves that queens can make on an  chess board.,n \times n,"I'm trying to extend my OEIS sequence A275815 : Maximum total number of possible moves that any number of queens of the same color can make on an $n \times n$ chessboard. I have computed the first five terms by brute force, and examples of each are given below. For $n \geq 6$ , Alec Jones has conjectured that $A275815(n) = 8(n-2)^2$ , which is achieved by placing $4n - 4$ queens around the border of the board—but this has not been proven. Alec's heuristic is based on summing the number of queens that can move to each empty square (which is no more than 8) instead of summing the number of moves each individual queen can make. Any thoughts on how to begin to prove this conjecture? Examples: A $2\times 2$ chess board can ""host"" 4 queen moves: $a1 \to b1$ $a1 \to b2$ $a2 \to b1$ $a2 \to b2$ A $3 \times 3$ board can host 17 moves: (The queen at a3 has three moves, the queen at a2 has four moves, and the queens at b1 and c3 each have five moves.) A $4 \times 4$ board can host 40 moves: And a $5 \times 5$ board can host 76 moves:","I'm trying to extend my OEIS sequence A275815 : Maximum total number of possible moves that any number of queens of the same color can make on an chessboard. I have computed the first five terms by brute force, and examples of each are given below. For , Alec Jones has conjectured that , which is achieved by placing queens around the border of the board—but this has not been proven. Alec's heuristic is based on summing the number of queens that can move to each empty square (which is no more than 8) instead of summing the number of moves each individual queen can make. Any thoughts on how to begin to prove this conjecture? Examples: A chess board can ""host"" 4 queen moves: A board can host 17 moves: (The queen at a3 has three moves, the queen at a2 has four moves, and the queens at b1 and c3 each have five moves.) A board can host 40 moves: And a board can host 76 moves:",n \times n n \geq 6 A275815(n) = 8(n-2)^2 4n - 4 2\times 2 a1 \to b1 a1 \to b2 a2 \to b1 a2 \to b2 3 \times 3 4 \times 4 5 \times 5,"['sequences-and-series', 'combinatorics', 'puzzle', 'oeis', 'chessboard']"
9,A problem posed by Ramanujan involving $\sum e^{-5\pi n^2}$,A problem posed by Ramanujan involving,\sum e^{-5\pi n^2},"While going through the list of problems posed by Ramanujan in Journal of Indian Mathematical Society I came across this problem involving theta functions: Prove that $$\frac{1}{2}+\sum_{n=1}^{\infty} e^{-\pi n^2x}\cos(\pi n^2\sqrt{1-x^2})=\frac{\sqrt{2}+\sqrt{1+x}}{\sqrt{1-x}}\sum_{n=1}^{\infty}e^{-\pi n^2x}\sin(\pi n^2\sqrt{1-x^2})$$ and deduce the following: ${\displaystyle \frac{1}{2}+\sum_{n=1}^{\infty} e^{-\pi n^2}=\sqrt{5\sqrt{5}-10}\left(\frac{1}{2}+\sum_{n=1}^{\infty} e^{-5\pi n^2}\right)} $ ${\displaystyle \sum_{n=1}^{\infty} e^{-\pi n^2}\left(\pi n^2-\frac{1}{4}\right)=\frac{1}{8}} $ The sums in above problem are clearly based on theta functions and we use a simplified notation here to define them. If $\tau$ is any complex number with positive imaginary part then we define $$\vartheta(\tau) =\sum_{n\in\mathbb {Z}} e^{\pi i\tau n^2}$$ and one of the key properties of theta function defined above is $$\vartheta(\tau) =(-i\tau) ^{-1/2}\vartheta(-1/\tau)$$ Ramanujan's first formula probably assumes that $x\in(0,1)$ and hence one can write $x=\cos t$ with $t\in(0,\pi/2)$ and we can consider the complex number $\tau=\sin t +i\cos t$ which clearly has positive imaginary part. The choice of $\tau$ in this manner is done because it gives us $$(-i\tau) ^{-1/2}=\cos(t/2) +i\sin(t/2)=\sqrt{\frac{1+x}{2}}+i\sqrt{\frac{1-x}{2}}$$ and $$-1/\tau=-\sin t+i\cos t=-\sqrt{1-x^2}+ix$$ Using this value of $\tau$ in the transformation formula for theta functions we get $$1+2A+2iB=\frac{\sqrt{1+x}+i\sqrt{1-x}}{\sqrt{2}}(1+2A-2iB)$$ where $$A=\sum_{n=1}^{\infty}e^{-\pi n^2x}\cos(\pi n^2\sqrt{1-x^2}),B=\sum_{n=1}^{\infty} e^{-\pi n^2x}\sin(\pi n^2\sqrt{1-x^2})$$ and equating real parts we get $$1+2A=(1+2A)\sqrt {\frac{1+x}{2}}+2B\sqrt{\frac{1-x}{2}}$$ or $$\frac{1}{2}+A=\frac{\sqrt{2}+\sqrt{1+x}}{\sqrt{1-x}}B$$ In this manner the key formula of Ramanujan is established. Out of the next two corollaries I was able to prove the second one easily by dividing the main formula by $\sqrt{1-x^2}$ and then taking limits as $x\to 1^{-}$ . The first one dealing with $\sum e^{-5\pi n^2}$ was really looking difficult to obtain. My question is How to obtain the first corollary dealing with $\sum e^{-5\pi n^2}$ from the main formula of Ramanujan? Since the formula appears to be using $x\in(0,1)$ I don't see a way to put $x=5$ . Even if one does that both sides will contain the sums involving $\sum e^{-5\pi n^2}$ and it appears rather mysterious to obtain a link between $\sum e^{-\pi n^2}$ and $\sum e^{-5\pi n^2}$ . The link between these two sums can be obtained using a modular equation of degree 5, but the calculations involved are tedious (for this technique in action see this answer which evaluates $\sum_{n\in\mathbb {Z}} e^{-3\pi n^2}$ ). I was therefore hoping for some easier approach as indicated by Ramanujan. Maybe I am mising something obvious here.","While going through the list of problems posed by Ramanujan in Journal of Indian Mathematical Society I came across this problem involving theta functions: Prove that and deduce the following: The sums in above problem are clearly based on theta functions and we use a simplified notation here to define them. If is any complex number with positive imaginary part then we define and one of the key properties of theta function defined above is Ramanujan's first formula probably assumes that and hence one can write with and we can consider the complex number which clearly has positive imaginary part. The choice of in this manner is done because it gives us and Using this value of in the transformation formula for theta functions we get where and equating real parts we get or In this manner the key formula of Ramanujan is established. Out of the next two corollaries I was able to prove the second one easily by dividing the main formula by and then taking limits as . The first one dealing with was really looking difficult to obtain. My question is How to obtain the first corollary dealing with from the main formula of Ramanujan? Since the formula appears to be using I don't see a way to put . Even if one does that both sides will contain the sums involving and it appears rather mysterious to obtain a link between and . The link between these two sums can be obtained using a modular equation of degree 5, but the calculations involved are tedious (for this technique in action see this answer which evaluates ). I was therefore hoping for some easier approach as indicated by Ramanujan. Maybe I am mising something obvious here.","\frac{1}{2}+\sum_{n=1}^{\infty} e^{-\pi n^2x}\cos(\pi n^2\sqrt{1-x^2})=\frac{\sqrt{2}+\sqrt{1+x}}{\sqrt{1-x}}\sum_{n=1}^{\infty}e^{-\pi n^2x}\sin(\pi n^2\sqrt{1-x^2}) {\displaystyle \frac{1}{2}+\sum_{n=1}^{\infty} e^{-\pi n^2}=\sqrt{5\sqrt{5}-10}\left(\frac{1}{2}+\sum_{n=1}^{\infty} e^{-5\pi n^2}\right)}  {\displaystyle \sum_{n=1}^{\infty} e^{-\pi n^2}\left(\pi n^2-\frac{1}{4}\right)=\frac{1}{8}}  \tau \vartheta(\tau) =\sum_{n\in\mathbb {Z}} e^{\pi i\tau n^2} \vartheta(\tau) =(-i\tau) ^{-1/2}\vartheta(-1/\tau) x\in(0,1) x=\cos t t\in(0,\pi/2) \tau=\sin t +i\cos t \tau (-i\tau) ^{-1/2}=\cos(t/2) +i\sin(t/2)=\sqrt{\frac{1+x}{2}}+i\sqrt{\frac{1-x}{2}} -1/\tau=-\sin t+i\cos t=-\sqrt{1-x^2}+ix \tau 1+2A+2iB=\frac{\sqrt{1+x}+i\sqrt{1-x}}{\sqrt{2}}(1+2A-2iB) A=\sum_{n=1}^{\infty}e^{-\pi n^2x}\cos(\pi n^2\sqrt{1-x^2}),B=\sum_{n=1}^{\infty} e^{-\pi n^2x}\sin(\pi n^2\sqrt{1-x^2}) 1+2A=(1+2A)\sqrt {\frac{1+x}{2}}+2B\sqrt{\frac{1-x}{2}} \frac{1}{2}+A=\frac{\sqrt{2}+\sqrt{1+x}}{\sqrt{1-x}}B \sqrt{1-x^2} x\to 1^{-} \sum e^{-5\pi n^2} \sum e^{-5\pi n^2} x\in(0,1) x=5 \sum e^{-5\pi n^2} \sum e^{-\pi n^2} \sum e^{-5\pi n^2} \sum_{n\in\mathbb {Z}} e^{-3\pi n^2}","['sequences-and-series', 'theta-functions']"
10,Is there any other way to prove this fact? (non-existence of slowest diverging series),Is there any other way to prove this fact? (non-existence of slowest diverging series),,"Let $a_n>0$ and $S_n=\sum_{k=1}^{n}a_n$. If $\lim_{n \rightarrow \infty}S_n = +\infty$, then $\sum_{n=1}^{\infty}\frac{a_n}{S_n}=+\infty$. I think this is an important example because it tells us that there exists no series which diverge slowest. So I want to verify this fact in different aspect. I know a method which uses Cauchy's Theorem. For any $n \in \bf N$ , choose a sufficiently large $p \in \bf{N}$. we have $$\sum_{k=n+1}^{n+p}\frac{a_k}{S_k}\geq \frac{S_{n+p}-S_{n}}{S_{n+p}}\geq \frac{1}{2}$$ Is there any other approach to it? Thanks very much.","Let $a_n>0$ and $S_n=\sum_{k=1}^{n}a_n$. If $\lim_{n \rightarrow \infty}S_n = +\infty$, then $\sum_{n=1}^{\infty}\frac{a_n}{S_n}=+\infty$. I think this is an important example because it tells us that there exists no series which diverge slowest. So I want to verify this fact in different aspect. I know a method which uses Cauchy's Theorem. For any $n \in \bf N$ , choose a sufficiently large $p \in \bf{N}$. we have $$\sum_{k=n+1}^{n+p}\frac{a_k}{S_k}\geq \frac{S_{n+p}-S_{n}}{S_{n+p}}\geq \frac{1}{2}$$ Is there any other approach to it? Thanks very much.",,['sequences-and-series']
11,"How is this a number sequence $58, 26, 16, 14, 10$",How is this a number sequence,"58, 26, 16, 14, 10","I recently had a IQ Test taken and we all got stuck on the same question. The question was: What comes next in the following sequence? $$58, 26, 16, 14,\_\_$$ The answer given in the answer sheet was $10$. My question is why? What pattern exists in those numbers?","I recently had a IQ Test taken and we all got stuck on the same question. The question was: What comes next in the following sequence? $$58, 26, 16, 14,\_\_$$ The answer given in the answer sheet was $10$. My question is why? What pattern exists in those numbers?",,"['sequences-and-series', 'puzzle', 'pattern-recognition']"
12,Whether a square can be traversed in finite time,Whether a square can be traversed in finite time,,"You are at point $C$ inside square $ABCD$ in the Cartesian plane, in which $A=(0,0), B=(0,1), C=(1,1), D=(1,0)$ . You want to get to vertex $A$ . However, your “speed” in $\frac{\text{units}}{\text{sec}}$ is everywhere equal to your y-coordinate. Can you get from $C$ to $A$ in finite time? If you can, what is the minimal time required for the journey? A friend asked me this as a challenge recently out of what I think was a calculus textbook. I haven’t found any concrete way of resolving the question one way or another (or even modeling it properly), but most of my intuition says that the voyage should not be possible in finite time. Specifically, it seems to me that this problem is somehow related to the fact that the harmonic series, as well as the integral of the harmonic series, diverges. On the other hand, perhaps this problem is like Zeno’s paradoxes- an infinite number of decreasing steps adding up to something finite. On solving the problem itself, I know that one can simplify whether it can be done in finite time to whether going straight down from $B$ to $A$ can be done in finite time. On minimizing the time taken (if it exists), I have no idea how to determine how to test infinite functions from $(1,1)$ to $(0,0)$ for their “speed”s, although I conjecture ones that are nowhere concave up should always be faster. $y=\sqrt{x}$","You are at point inside square in the Cartesian plane, in which . You want to get to vertex . However, your “speed” in is everywhere equal to your y-coordinate. Can you get from to in finite time? If you can, what is the minimal time required for the journey? A friend asked me this as a challenge recently out of what I think was a calculus textbook. I haven’t found any concrete way of resolving the question one way or another (or even modeling it properly), but most of my intuition says that the voyage should not be possible in finite time. Specifically, it seems to me that this problem is somehow related to the fact that the harmonic series, as well as the integral of the harmonic series, diverges. On the other hand, perhaps this problem is like Zeno’s paradoxes- an infinite number of decreasing steps adding up to something finite. On solving the problem itself, I know that one can simplify whether it can be done in finite time to whether going straight down from to can be done in finite time. On minimizing the time taken (if it exists), I have no idea how to determine how to test infinite functions from to for their “speed”s, although I conjecture ones that are nowhere concave up should always be faster.","C ABCD A=(0,0), B=(0,1), C=(1,1), D=(1,0) A \frac{\text{units}}{\text{sec}} C A B A (1,1) (0,0) y=\sqrt{x}","['sequences-and-series', 'ordinary-differential-equations', 'optimization', 'definite-integrals']"
13,What does $\sum_{k=0}^\infty \frac{k}{2^k}$ converge to?,What does  converge to?,\sum_{k=0}^\infty \frac{k}{2^k},This problem comes from another equation on another question ( this one) . I tried to split it in half but I found out that $$\sum_{k=0}^\infty \frac{k}{2^k}$$ can't be divided. Knowing that $$\sum_{k=0}^\infty x^k=\frac{1}{1-x}$$ I wrote that $$\sum_{k=0}^\infty \frac{k}{2^k}=\sum_{k=0}^\infty \left(\frac{\sqrt[k] k}{2}\right)^k=\frac{1}{1-\frac{\sqrt k}{2}}=\frac{2}{2-\sqrt[k] k}$$ But that's not what I wanted. Could anyone help me?,This problem comes from another equation on another question ( this one) . I tried to split it in half but I found out that can't be divided. Knowing that I wrote that But that's not what I wanted. Could anyone help me?,\sum_{k=0}^\infty \frac{k}{2^k} \sum_{k=0}^\infty x^k=\frac{1}{1-x} \sum_{k=0}^\infty \frac{k}{2^k}=\sum_{k=0}^\infty \left(\frac{\sqrt[k] k}{2}\right)^k=\frac{1}{1-\frac{\sqrt k}{2}}=\frac{2}{2-\sqrt[k] k},['sequences-and-series']
14,Infinite Series $\sum 1/(n(n+1))$,Infinite Series,\sum 1/(n(n+1)),"I am confused on the following series: $$\sum\limits_{n=1}^{\infty}\frac{1}{n(n+1)} = 1$$ My calculator reveals that the answer found when evaluating this series is 1. However, I am not sure how it arrives at this conclusion. I understand that partial fractions will be used to create the following equation. I just don't understand how to proceed with the problem. $$\sum\limits_{n=1}^{\infty}\left(\frac{1}{n}-\frac{1}{n+1}\right) = 1$$","I am confused on the following series: My calculator reveals that the answer found when evaluating this series is 1. However, I am not sure how it arrives at this conclusion. I understand that partial fractions will be used to create the following equation. I just don't understand how to proceed with the problem.",\sum\limits_{n=1}^{\infty}\frac{1}{n(n+1)} = 1 \sum\limits_{n=1}^{\infty}\left(\frac{1}{n}-\frac{1}{n+1}\right) = 1,['sequences-and-series']
15,"If $\sum_{1}^{\infty}(a_n)^3$ diverges, does $\sum_{1}^{\infty}(a_n)$?","If  diverges, does ?",\sum_{1}^{\infty}(a_n)^3 \sum_{1}^{\infty}(a_n),"Per the title, if $\sum_{1}^{\infty}(a_n)^3$ diverges, does this imply that $\sum_{1}^{\infty}(a_n)$ diverges? I'd appreciate hints (!) for dealing with this excercise. EDIT Per the contrapositive, it is not given that $a_n$ converges absolutely, or that it is nonnegative for all $n$. Thank you!","Per the title, if $\sum_{1}^{\infty}(a_n)^3$ diverges, does this imply that $\sum_{1}^{\infty}(a_n)$ diverges? I'd appreciate hints (!) for dealing with this excercise. EDIT Per the contrapositive, it is not given that $a_n$ converges absolutely, or that it is nonnegative for all $n$. Thank you!",,"['sequences-and-series', 'divergent-series']"
16,What is wrong with the sum of these two series?,What is wrong with the sum of these two series?,,"Could anyone help me to find the mistake in the following problem? Based on the formula of the sum of a geometric series: \begin{equation} 1 + x + x^{2} + \cdots + x^{n} + \cdots = \frac{1}{1 - x} \end{equation} \begin{equation} 1 + \frac{1}{x} + \frac{1}{x^{2}} + \cdots + \frac{1}{x^{n}} + \cdots = \frac{1}{1 - 1/x} = \frac{x}{x-1} \end{equation} Adding both equations \begin{equation} 2 + x + \frac{1}{x} + x^{2} + \frac{1}{x^{2}} + \cdots + x^{n} + \frac{1}{x^{n}} + \cdots = \frac{1}{1 - x} + \frac{x}{x-1} = \frac{1-x}{1-x} = 1 \end{equation} So, \begin{equation} 2 + x + \frac{1}{x} + x^{2} + \frac{1}{x^{2}} + \cdots + x^{n} + \frac{1}{x^{n}} + \cdots = 1 \end{equation} And the left side is always bigger than $2$ for $x>0$. What is wrong?? Thanks in advance","Could anyone help me to find the mistake in the following problem? Based on the formula of the sum of a geometric series: \begin{equation} 1 + x + x^{2} + \cdots + x^{n} + \cdots = \frac{1}{1 - x} \end{equation} \begin{equation} 1 + \frac{1}{x} + \frac{1}{x^{2}} + \cdots + \frac{1}{x^{n}} + \cdots = \frac{1}{1 - 1/x} = \frac{x}{x-1} \end{equation} Adding both equations \begin{equation} 2 + x + \frac{1}{x} + x^{2} + \frac{1}{x^{2}} + \cdots + x^{n} + \frac{1}{x^{n}} + \cdots = \frac{1}{1 - x} + \frac{x}{x-1} = \frac{1-x}{1-x} = 1 \end{equation} So, \begin{equation} 2 + x + \frac{1}{x} + x^{2} + \frac{1}{x^{2}} + \cdots + x^{n} + \frac{1}{x^{n}} + \cdots = 1 \end{equation} And the left side is always bigger than $2$ for $x>0$. What is wrong?? Thanks in advance",,"['sequences-and-series', 'paradoxes', 'geometric-series']"
17,Evaluate a limit involving a definite integral,Evaluate a limit involving a definite integral,,Let $(I_n)_{n \geq 1}$ be a sequence such that:  $$I_n = \int_0^1 \frac{x^n}{4x + 5} dx$$  Evaluate the following limit: $$\lim_{n \to \infty} nI_n$$ All I've been able to find is that $(I_n)$ is decreasing and converges to $0$. Thank you!,Let $(I_n)_{n \geq 1}$ be a sequence such that:  $$I_n = \int_0^1 \frac{x^n}{4x + 5} dx$$  Evaluate the following limit: $$\lim_{n \to \infty} nI_n$$ All I've been able to find is that $(I_n)$ is decreasing and converges to $0$. Thank you!,,"['sequences-and-series', 'limits', 'definite-integrals']"
18,How to prove Chebyshev's result: $\sum_{p\leq n} \frac{\log p}{p} \sim\log n $ as $n\to\infty$?,How to prove Chebyshev's result:  as ?,\sum_{p\leq n} \frac{\log p}{p} \sim\log n  n\to\infty,"I saw reference to this result of Chebyshev's: $$\sum_{p\leq n} \frac{\log p}{p} \sim \log n \text{ as }n \to \infty,$$ and its relation to the Prime Number Theorem. I'm looking into an information-theory proof by Kontoyiannis I was wondering if anyone could give me a sense for how difficult or involved the usual proof is. I don't really need to see the whole thing in detail, more wondering about the general difficulty/complexity of the result. Thanks!","I saw reference to this result of Chebyshev's: $$\sum_{p\leq n} \frac{\log p}{p} \sim \log n \text{ as }n \to \infty,$$ and its relation to the Prime Number Theorem. I'm looking into an information-theory proof by Kontoyiannis I was wondering if anyone could give me a sense for how difficult or involved the usual proof is. I don't really need to see the whole thing in detail, more wondering about the general difficulty/complexity of the result. Thanks!",,"['sequences-and-series', 'number-theory', 'prime-numbers', 'analytic-number-theory']"
19,"Why does every ""fibonacci like"" series converge to $\phi$?","Why does every ""fibonacci like"" series converge to ?",\phi,"It's is well known that the ratio of side-by-side fibonacci numbers converge to $\phi$. But it seems by my calculations, that if one starts with any pair of numbers one will also get a ratio that converges to $\phi$. Say for example if one starts with $3$ and $4$ we get: 4   1,333333333 7   1,75 11  1,571428571 18  1,636363636 29  1,611111111 47  1,620689655 76  1,617021277 123 1,618421053 199 1,617886179 322 1,618090452 521 1,618012422 843 1,618042226 where the series is on the left and the ratio is side-by-side numbers are on the right. I'm quite curious to know why this happens. Anyone?","It's is well known that the ratio of side-by-side fibonacci numbers converge to $\phi$. But it seems by my calculations, that if one starts with any pair of numbers one will also get a ratio that converges to $\phi$. Say for example if one starts with $3$ and $4$ we get: 4   1,333333333 7   1,75 11  1,571428571 18  1,636363636 29  1,611111111 47  1,620689655 76  1,617021277 123 1,618421053 199 1,617886179 322 1,618090452 521 1,618012422 843 1,618042226 where the series is on the left and the ratio is side-by-side numbers are on the right. I'm quite curious to know why this happens. Anyone?",,"['sequences-and-series', 'recurrence-relations', 'fibonacci-numbers', 'golden-ratio']"
20,When is an accumulation point not the limit of some sequence in a topological space?,When is an accumulation point not the limit of some sequence in a topological space?,,"In a general topological space $(X,\tau)$ we define an accumulation point $x_0$ of a set $A$ to be a point such that any open neighbourhood about $x_0$ intersects $A$. Now it is certainly true that if a sequence $x_n\in A$ tends to some limit $x \in X$, $x$ must be an accumulation point of $A$ since $x_n$ lies in any open neighbourhood of $x$ for all $n$ sufficiently large, and so lies in the intersection of this open neighbourhood and $A$. What I would like to know is: Are there any (preferably elementary) examples of a topological space with a subset $A$ that has an accumulation point which is not the limit of any sequence in $A$. I would also appreciate information on any conditions on a space which imply that any accumulation point of $A$ is the limit of some sequence in $A$. For example, if $X$ is first countable (e.g. any metric space) then it is easy to show that any accumulation point of $A$ must be the limit of some sequence of points in $A$. Intuitively this is because for a given point $x$, we can find a nested sequence of open sets that ""get smaller"" and can eventually be contained in any open neighbourhood of $x$, so these nested open sets ""contract around $x$, allowing us to find such a sequence.","In a general topological space $(X,\tau)$ we define an accumulation point $x_0$ of a set $A$ to be a point such that any open neighbourhood about $x_0$ intersects $A$. Now it is certainly true that if a sequence $x_n\in A$ tends to some limit $x \in X$, $x$ must be an accumulation point of $A$ since $x_n$ lies in any open neighbourhood of $x$ for all $n$ sufficiently large, and so lies in the intersection of this open neighbourhood and $A$. What I would like to know is: Are there any (preferably elementary) examples of a topological space with a subset $A$ that has an accumulation point which is not the limit of any sequence in $A$. I would also appreciate information on any conditions on a space which imply that any accumulation point of $A$ is the limit of some sequence in $A$. For example, if $X$ is first countable (e.g. any metric space) then it is easy to show that any accumulation point of $A$ must be the limit of some sequence of points in $A$. Intuitively this is because for a given point $x$, we can find a nested sequence of open sets that ""get smaller"" and can eventually be contained in any open neighbourhood of $x$, so these nested open sets ""contract around $x$, allowing us to find such a sequence.",,"['general-topology', 'sequences-and-series']"
21,If the positive series $\sum a_n$ diverges and $s_n=\sum\limits_{k\leqslant n}a_k$ then $\sum \frac{a_n}{s_n}$ diverges as well,If the positive series  diverges and  then  diverges as well,\sum a_n s_n=\sum\limits_{k\leqslant n}a_k \sum \frac{a_n}{s_n},"So I've been trying to figure out how to prove the following. Let $(a_n)$ be a sequence of positive numbers such that $\sum\limits_{n=1}^\infty a_n =\infty$, and define $s_n=\sum\limits_{i=1}^n a_i$. Then $\sum\limits_{n=1}^\infty\frac{a_n}{s_n} =\infty$ as well. I can prove it by comparing it to $\int_1^\infty \frac{1}{x} \, dx $ if the sequence $a_n$ is bounded by some $M$, but that's as far as I've been able to get.","So I've been trying to figure out how to prove the following. Let $(a_n)$ be a sequence of positive numbers such that $\sum\limits_{n=1}^\infty a_n =\infty$, and define $s_n=\sum\limits_{i=1}^n a_i$. Then $\sum\limits_{n=1}^\infty\frac{a_n}{s_n} =\infty$ as well. I can prove it by comparing it to $\int_1^\infty \frac{1}{x} \, dx $ if the sequence $a_n$ is bounded by some $M$, but that's as far as I've been able to get.",,"['sequences-and-series', 'divergent-series']"
22,"Why is this allowed? (""Fourier's Trick""; finding the coefficients in a Fourier Series)","Why is this allowed? (""Fourier's Trick""; finding the coefficients in a Fourier Series)",,"In my textbook ( Introduction to Electrodynamics , D. Griffiths), we derive the equation for some strange potential function. Eventually, we get to this (for $n \in \mathbb{Z}^+$ ): $$ V_0(y) = \sum_{n=0}^{\infty} C_n\sin{\frac{n\pi}{a}y} \tag{3.31}$$ Here's where things go awry for me. ... how do we actually determine the coefficients $C_n$ , buried as they are in that infinite sum? The device for accomplishing this is so lovely it deserves a name—I call it Fourier's trick , though it seems Euler had used essentially the same idea somewhat earlier. Here's how it goes: Multiply Eq. 3.31 by $\sin{n'\pi y/a}$ (where $n'$ is a positive integer), and integrate from 0 to a: $$ \displaystyle \sum_{n=0}^{\infty} C_n \int_0^a\sin{\frac{n\pi}{a}y} \sin{\frac{n'\pi}{a}y} dy ~~~=~~~ \int_0^a V_0(y)\sin{\frac{n'\pi}{a}y} dy$$ The answer understandably comes out to something very nice and convenient. But... why is this something you can do? There's no obvious reason for why that doesn't intrinsically change the problem (in the same way that I can say ""Multiply both sides by $0$ . You've successfully reduced the problem to zero. Well done!) (While typing out the above, I suspect that it has something to do with the inner product of a function and an orthonormal basis? The infinite $\sin$ functions create an orthonormal basis, and taking that integral over all possible values effectively extracts the coefficients for each basis function. When it is suggested that we multiply by $\sin{\frac{n'\pi}{a}y}$ and integrate, this isn't changing the basis at all, it's just (sneakily) extracting the coefficients, which only exist when $n = n'$ (because the $\sin$ functions are all orthogonal). It's like taking the coefficients of a basis with itself... right? I think this may be one of those cases where, in the process of asking the question, I figure out the answer—but this is all fairly new to me, and I'd like to ask it anyway for confirmation and, possibly, a clearer explanation).","In my textbook ( Introduction to Electrodynamics , D. Griffiths), we derive the equation for some strange potential function. Eventually, we get to this (for ): Here's where things go awry for me. ... how do we actually determine the coefficients , buried as they are in that infinite sum? The device for accomplishing this is so lovely it deserves a name—I call it Fourier's trick , though it seems Euler had used essentially the same idea somewhat earlier. Here's how it goes: Multiply Eq. 3.31 by (where is a positive integer), and integrate from 0 to a: The answer understandably comes out to something very nice and convenient. But... why is this something you can do? There's no obvious reason for why that doesn't intrinsically change the problem (in the same way that I can say ""Multiply both sides by . You've successfully reduced the problem to zero. Well done!) (While typing out the above, I suspect that it has something to do with the inner product of a function and an orthonormal basis? The infinite functions create an orthonormal basis, and taking that integral over all possible values effectively extracts the coefficients for each basis function. When it is suggested that we multiply by and integrate, this isn't changing the basis at all, it's just (sneakily) extracting the coefficients, which only exist when (because the functions are all orthogonal). It's like taking the coefficients of a basis with itself... right? I think this may be one of those cases where, in the process of asking the question, I figure out the answer—but this is all fairly new to me, and I'd like to ask it anyway for confirmation and, possibly, a clearer explanation).",n \in \mathbb{Z}^+  V_0(y) = \sum_{n=0}^{\infty} C_n\sin{\frac{n\pi}{a}y} \tag{3.31} C_n \sin{n'\pi y/a} n'  \displaystyle \sum_{n=0}^{\infty} C_n \int_0^a\sin{\frac{n\pi}{a}y} \sin{\frac{n'\pi}{a}y} dy ~~~=~~~ \int_0^a V_0(y)\sin{\frac{n'\pi}{a}y} dy 0 \sin \sin{\frac{n'\pi}{a}y} n = n' \sin,"['sequences-and-series', 'summation', 'physics', 'fourier-series']"
23,Do these series converge to logarithms?,Do these series converge to logarithms?,,"It is well known that $$1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\frac{1}{5}... =\log(2).$$ If we consider the array: $T(n,k) = -(n-1)\; \text{ if }\; n|k, \;\text{ else } \;1,$ Starting: $$\displaystyle T = \left(   \begin{array}{ccccccc}   +0&+0&+0&+0&+0&+0&+0&\cdots \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&-2&+1&+1&-2&+1 \\ +1&+1&+1&-3&+1&+1&+1 \\ +1&+1&+1&+1&-4&+1&+1 \\ +1&+1&+1&+1&+1&-5&+1 \\ +1&+1&+1&+1&+1&+1&-6 \\ \vdots&&&&&&&\ddots \end{array}   \right)$$ Is it true that $\displaystyle \log(n)=\sum\limits_{k=1}^{\infty}\frac{T(n,k)}{k}$$\;$?","It is well known that $$1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\frac{1}{5}... =\log(2).$$ If we consider the array: $T(n,k) = -(n-1)\; \text{ if }\; n|k, \;\text{ else } \;1,$ Starting: $$\displaystyle T = \left(   \begin{array}{ccccccc}   +0&+0&+0&+0&+0&+0&+0&\cdots \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&-2&+1&+1&-2&+1 \\ +1&+1&+1&-3&+1&+1&+1 \\ +1&+1&+1&+1&-4&+1&+1 \\ +1&+1&+1&+1&+1&-5&+1 \\ +1&+1&+1&+1&+1&+1&-6 \\ \vdots&&&&&&&\ddots \end{array}   \right)$$ Is it true that $\displaystyle \log(n)=\sum\limits_{k=1}^{\infty}\frac{T(n,k)}{k}$$\;$?",,"['sequences-and-series', 'logarithms']"
24,A closed form for the sum $\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots$,A closed form for the sum,\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots,"I watched this YouTube video that calculates the sum $$\frac{1}{3\cdot4}+\frac{1\cdot2}{3\cdot4\cdot5}+\frac{1\cdot2\cdot3}{3\cdot4\cdot5\cdot6}+\cdots=\frac16$$ then they ask, as a challenge to the viewer, what is the value of the sum $$\frac{17}{75\cdot76}+\frac{17\cdot18}{75\cdot76\cdot77}+\frac{17\cdot18\cdot19}{75\cdot76\cdot77\cdot78}+\cdots$$ This got me thinking about a way to generalise this type of sum, i.e. how can one calculate the value of the sum $$\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots$$ where $a,b\in\mathbb{N}$ and $a\lt b$ . We can rewrite this sum as $$\begin{align} \frac{(b-1)!}{(a-1)!}\sum_{n=0}^\infty\frac{(a+n)!}{(b+n)!} &=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\sum_{n=0}^\infty\frac{(a+n)!\cdot(b-a)!}{(b+n)!}\\ &=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\sum_{n=0}^\infty\frac1{\binom{b+n}{b-a}}\\ &=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\left(\sum_{n=b-a}^\infty\frac1{\binom{n}{b-a}}-\sum_{n=b-a}^{b-1}\frac1{\binom{n}{b-a}}\right)\\ \end{align}$$ So this effectively simplifies down to the following problem: How can we evaluate the sum $$\sum_{n=k}^\infty \frac1{\binom{n}{k}}$$ for $k\in\mathbb{N}\setminus\{1\}$ in a closed form? Numerically it appears that the solution is $$\boxed{\sum_{n=k}^\infty \frac1{\binom{n}{k}}=\frac{k}{k-1}}$$ which would mean that a closed form for our sum is $$\boxed{\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\left(\frac{b-a}{b-a-1}-\sum_{n=b-a}^{b-1}\frac1{\binom{n}{b-a}}\right)}$$ testing this solution for our example gives $$\begin{align} \frac{17}{75\cdot76}+\frac{17\cdot18}{75\cdot76\cdot77}+\frac{17\cdot18\cdot19}{75\cdot76\cdot77\cdot78}+\cdots &=\frac1{75}\left(\frac{17}{76}+\frac{17\cdot18}{76\cdot77}+\frac{17\cdot18\cdot19}{76\cdot77\cdot78}+\cdots\right)\\ &=\frac1{75}\left(\frac{(76-1)!}{(17-1)!\cdot(76-17)!}\left(\frac{76-17}{76-17-1}-\sum_{n=76-17}^{76-1}\frac1{\binom{n}{76-17}}\right)\right)\\ &=114000634335804\left(\frac{59}{58}-\sum_{n=59}^{75}\frac1{\binom{n}{59}}\right)\\ &=114000634335804\left(\frac{59}{58}-\frac{1023230845711831}{1005887950021800}\right)\\ &=114000634335804\left(\frac1{29170750550632200}\right)\\ &=\frac{17}{4350}\\ \end{align}$$ which seems to agree with numerical evaluation, but how do I prove this result? Edit: There is actually a much better closed form for this result as follows $$\boxed{\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots=\frac{a}{b-a-1}}$$ which is found in the supplied answers.","I watched this YouTube video that calculates the sum then they ask, as a challenge to the viewer, what is the value of the sum This got me thinking about a way to generalise this type of sum, i.e. how can one calculate the value of the sum where and . We can rewrite this sum as So this effectively simplifies down to the following problem: How can we evaluate the sum for in a closed form? Numerically it appears that the solution is which would mean that a closed form for our sum is testing this solution for our example gives which seems to agree with numerical evaluation, but how do I prove this result? Edit: There is actually a much better closed form for this result as follows which is found in the supplied answers.","\frac{1}{3\cdot4}+\frac{1\cdot2}{3\cdot4\cdot5}+\frac{1\cdot2\cdot3}{3\cdot4\cdot5\cdot6}+\cdots=\frac16 \frac{17}{75\cdot76}+\frac{17\cdot18}{75\cdot76\cdot77}+\frac{17\cdot18\cdot19}{75\cdot76\cdot77\cdot78}+\cdots \frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots a,b\in\mathbb{N} a\lt b \begin{align}
\frac{(b-1)!}{(a-1)!}\sum_{n=0}^\infty\frac{(a+n)!}{(b+n)!}
&=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\sum_{n=0}^\infty\frac{(a+n)!\cdot(b-a)!}{(b+n)!}\\
&=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\sum_{n=0}^\infty\frac1{\binom{b+n}{b-a}}\\
&=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\left(\sum_{n=b-a}^\infty\frac1{\binom{n}{b-a}}-\sum_{n=b-a}^{b-1}\frac1{\binom{n}{b-a}}\right)\\
\end{align} \sum_{n=k}^\infty \frac1{\binom{n}{k}} k\in\mathbb{N}\setminus\{1\} \boxed{\sum_{n=k}^\infty \frac1{\binom{n}{k}}=\frac{k}{k-1}} \boxed{\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots=\frac{(b-1)!}{(a-1)!\cdot(b-a)!}\left(\frac{b-a}{b-a-1}-\sum_{n=b-a}^{b-1}\frac1{\binom{n}{b-a}}\right)} \begin{align}
\frac{17}{75\cdot76}+\frac{17\cdot18}{75\cdot76\cdot77}+\frac{17\cdot18\cdot19}{75\cdot76\cdot77\cdot78}+\cdots
&=\frac1{75}\left(\frac{17}{76}+\frac{17\cdot18}{76\cdot77}+\frac{17\cdot18\cdot19}{76\cdot77\cdot78}+\cdots\right)\\
&=\frac1{75}\left(\frac{(76-1)!}{(17-1)!\cdot(76-17)!}\left(\frac{76-17}{76-17-1}-\sum_{n=76-17}^{76-1}\frac1{\binom{n}{76-17}}\right)\right)\\
&=114000634335804\left(\frac{59}{58}-\sum_{n=59}^{75}\frac1{\binom{n}{59}}\right)\\
&=114000634335804\left(\frac{59}{58}-\frac{1023230845711831}{1005887950021800}\right)\\
&=114000634335804\left(\frac1{29170750550632200}\right)\\
&=\frac{17}{4350}\\
\end{align} \boxed{\frac{a}{b}+\frac{a\cdot(a+1)}{b\cdot(b+1)}+\frac{a\cdot(a+1)\cdot(a+2)}{b\cdot(b+1)\cdot(b+2)}+\cdots=\frac{a}{b-a-1}}","['sequences-and-series', 'binomial-coefficients', 'closed-form', 'fractions']"
25,"If $\sum\limits_{n=1}^{\infty}\frac{1}{p(n)}\in\mathbb{Q}$, is $\sum\limits_{n=1}^{\infty}\frac{n}{p(n)}\in\mathbb{Q}$?","If , is ?",\sum\limits_{n=1}^{\infty}\frac{1}{p(n)}\in\mathbb{Q} \sum\limits_{n=1}^{\infty}\frac{n}{p(n)}\in\mathbb{Q},"Suppose $p(n)$ is a polynomial with rational coefficients and rational roots of degree at least $3$. If we know  $$\sum_{n=1}^{\infty}\frac{1}{p(n)}\in\mathbb{Q}$$ are we able to infer that $$\sum_{n=1}^{\infty}\frac{n}{p(n)}\in\mathbb{Q}?$$ I've tried several approaches to proving (or disproving) this to include the following: -Looking for counterexamples -Generating functions -Residues -Partial fraction decomposition but nothing has yielded any positive or negative results. Any tips, terms, papers, methods, or generally topics that I could look into would also be welcome. Edit: As noted by Carl Schildkraut below, if this is true, then we would automatically know that $\zeta(2k+1)$ was irrational. Since this seems to greatly increase the potential difficulty, I offer the following modification in order to simplify it: Suppose $p(n)$ is a polynomial with rational coefficients, rational roots, $\deg(P)\geq 3$, and every root has order $1$. If we know  $$\sum_{n=1}^{\infty}\frac{1}{p(n)}\in\mathbb{Q}$$ are we able to infer that $$\sum_{n=1}^{\infty}\frac{n}{p(n)}\in\mathbb{Q}?$$","Suppose $p(n)$ is a polynomial with rational coefficients and rational roots of degree at least $3$. If we know  $$\sum_{n=1}^{\infty}\frac{1}{p(n)}\in\mathbb{Q}$$ are we able to infer that $$\sum_{n=1}^{\infty}\frac{n}{p(n)}\in\mathbb{Q}?$$ I've tried several approaches to proving (or disproving) this to include the following: -Looking for counterexamples -Generating functions -Residues -Partial fraction decomposition but nothing has yielded any positive or negative results. Any tips, terms, papers, methods, or generally topics that I could look into would also be welcome. Edit: As noted by Carl Schildkraut below, if this is true, then we would automatically know that $\zeta(2k+1)$ was irrational. Since this seems to greatly increase the potential difficulty, I offer the following modification in order to simplify it: Suppose $p(n)$ is a polynomial with rational coefficients, rational roots, $\deg(P)\geq 3$, and every root has order $1$. If we know  $$\sum_{n=1}^{\infty}\frac{1}{p(n)}\in\mathbb{Q}$$ are we able to infer that $$\sum_{n=1}^{\infty}\frac{n}{p(n)}\in\mathbb{Q}?$$",,"['sequences-and-series', 'complex-analysis', 'number-theory', 'polynomials', 'generating-functions']"
26,Show that the sequence $a_{n+1}=a_{n}+\dfrac{a^2_{n}}{n^2}$ is upper bounded,Show that the sequence  is upper bounded,a_{n+1}=a_{n}+\dfrac{a^2_{n}}{n^2},"Let $\{a_{n}\}$ be defined with $a_{1}\in(0,1)$, and  $$a_{n+1}=a_{n}+\dfrac{a^2_{n}}{n^2}$$ for all $n\gt 0$.  Show that the sequence is  upper bounded. My idea: since  $$a_{n+1}=a_{n}\left(1+\dfrac{a_{n}}{n^2}\right)$$ then $$\dfrac{1}{a_{n+1}}=\dfrac{1}{a_{n}}-\dfrac{1}{a_{n}+n^2}$$ then $$\dfrac{1}{a_{n}}-\dfrac{1}{a_{n+1}}=\dfrac{1}{a_{n}+n^2}$$ so $$\dfrac{1}{a_{1}}-\dfrac{1}{a_{n+1}}=\sum_{i=1}^{n}\dfrac{1}{a_{i}+i^2}$$ since $$a_{n+1}>a_{n}\Longrightarrow \dfrac{1}{a_{i}+i^2}<\dfrac{1}{a_{1}+i^2}$$ so $$\dfrac{1}{a_{n+1}}>\dfrac{1}{a_{1}}-\left(\dfrac{1}{1+a_{1}}+\dfrac{1}{2^2+a_{1}}+\cdots+\dfrac{1}{a_{1}+n^2}\right)$$ But the RHS might be $\lt0$ for a sufficiently large starting value; for instance, with $a_{1}=\dfrac{99}{100}$ then $$\dfrac{1}{a_{1}}-\left(\dfrac{1}{1+a_{1}}+\dfrac{1}{2^2+a_{1}}+\cdots+\dfrac{1}{a_{1}+n^2}\right)<0,n\to\infty$$ see: so this method won't let me bound the series and I don't know what else to do.","Let $\{a_{n}\}$ be defined with $a_{1}\in(0,1)$, and  $$a_{n+1}=a_{n}+\dfrac{a^2_{n}}{n^2}$$ for all $n\gt 0$.  Show that the sequence is  upper bounded. My idea: since  $$a_{n+1}=a_{n}\left(1+\dfrac{a_{n}}{n^2}\right)$$ then $$\dfrac{1}{a_{n+1}}=\dfrac{1}{a_{n}}-\dfrac{1}{a_{n}+n^2}$$ then $$\dfrac{1}{a_{n}}-\dfrac{1}{a_{n+1}}=\dfrac{1}{a_{n}+n^2}$$ so $$\dfrac{1}{a_{1}}-\dfrac{1}{a_{n+1}}=\sum_{i=1}^{n}\dfrac{1}{a_{i}+i^2}$$ since $$a_{n+1}>a_{n}\Longrightarrow \dfrac{1}{a_{i}+i^2}<\dfrac{1}{a_{1}+i^2}$$ so $$\dfrac{1}{a_{n+1}}>\dfrac{1}{a_{1}}-\left(\dfrac{1}{1+a_{1}}+\dfrac{1}{2^2+a_{1}}+\cdots+\dfrac{1}{a_{1}+n^2}\right)$$ But the RHS might be $\lt0$ for a sufficiently large starting value; for instance, with $a_{1}=\dfrac{99}{100}$ then $$\dfrac{1}{a_{1}}-\left(\dfrac{1}{1+a_{1}}+\dfrac{1}{2^2+a_{1}}+\cdots+\dfrac{1}{a_{1}+n^2}\right)<0,n\to\infty$$ see: so this method won't let me bound the series and I don't know what else to do.",,['sequences-and-series']
27,Intuition for the Frobenius method,Intuition for the Frobenius method,,"I'm teaching a differential equations class now and I am hoping to give a reason for the Frobenius series method beyond simply ""we guess these solutions"".  Now, for the Euler equation $$t^n x^{(n)}(t) + a_{n - 1} t^{n - 1} x^{(n - 1)}(t) + \dots + a_0 x(t) = 0$$ there is a good, easy explanation for why the fundamental solutions are of the form $x(t) = t^r$, where $r$ solves the indicial equation and repeated roots are handled by multiplying by powers of $\ln t$: just make the change of variables $s = \ln t$ and verify that this makes $t^n x^{(n)}(t)$ a constant-coefficient linear combination of the $x^{(k)}(s)$'s, and copy down the solutions to a constant-coefficient linear equation: $s^k e^{rs}$, with $k$ less than the multiplicity of $r$ as a root of the characteristic polynomial, which turns out here to be exactly the indicial polynomial. But there isn't an apparent generalization of this analogy to arbitrary differential equations with regular singular points, $$t^n x^{(n)}(t) + a_{n - 1}(t) t^{n - 1} x^{(n - 1)}(t) + \dots + a_0(t) x(t) = 0,$$ with the $a_i(t)$ analytic around $t = 0$.  You can make the same change of variables and render the equation non-singular, but it will: still have variable coefficients; even if you got the solutions as power series, the substitution $s = \ln t$ would make them into series in $\ln t$, which is not desirable; when two roots differ by an integer then one of the solutions won't even be of the desired form; when there's a repeated root, the second solution looks like $$x_2(t) = x_1(t) \ln t + x^r v(t),$$ where $v(t)$ is some other power series, anyway, which is not what you'd get from the change of variables in any obvious way.  Now, it is true that there is the following relationship between $x_1(t)$ and $v(t)$: $$x_1(t) = \sum_{i = 0}^\infty b_i(r) t^{n + r} \qquad     v(t) = \sum_{i = 0}^\infty b_i'(r) t^{n + r}$$ where we differentiate the coefficients with respect to $r$, considered somehow as a continuous variable. So, my question: Is there some connection, via a transform, change of variables, or approximation, that produces the Frobenius method by analogy with non-singular equations?  Perhaps just when the roots of the indicial polynomial do not differ by integers?","I'm teaching a differential equations class now and I am hoping to give a reason for the Frobenius series method beyond simply ""we guess these solutions"".  Now, for the Euler equation $$t^n x^{(n)}(t) + a_{n - 1} t^{n - 1} x^{(n - 1)}(t) + \dots + a_0 x(t) = 0$$ there is a good, easy explanation for why the fundamental solutions are of the form $x(t) = t^r$, where $r$ solves the indicial equation and repeated roots are handled by multiplying by powers of $\ln t$: just make the change of variables $s = \ln t$ and verify that this makes $t^n x^{(n)}(t)$ a constant-coefficient linear combination of the $x^{(k)}(s)$'s, and copy down the solutions to a constant-coefficient linear equation: $s^k e^{rs}$, with $k$ less than the multiplicity of $r$ as a root of the characteristic polynomial, which turns out here to be exactly the indicial polynomial. But there isn't an apparent generalization of this analogy to arbitrary differential equations with regular singular points, $$t^n x^{(n)}(t) + a_{n - 1}(t) t^{n - 1} x^{(n - 1)}(t) + \dots + a_0(t) x(t) = 0,$$ with the $a_i(t)$ analytic around $t = 0$.  You can make the same change of variables and render the equation non-singular, but it will: still have variable coefficients; even if you got the solutions as power series, the substitution $s = \ln t$ would make them into series in $\ln t$, which is not desirable; when two roots differ by an integer then one of the solutions won't even be of the desired form; when there's a repeated root, the second solution looks like $$x_2(t) = x_1(t) \ln t + x^r v(t),$$ where $v(t)$ is some other power series, anyway, which is not what you'd get from the change of variables in any obvious way.  Now, it is true that there is the following relationship between $x_1(t)$ and $v(t)$: $$x_1(t) = \sum_{i = 0}^\infty b_i(r) t^{n + r} \qquad     v(t) = \sum_{i = 0}^\infty b_i'(r) t^{n + r}$$ where we differentiate the coefficients with respect to $r$, considered somehow as a continuous variable. So, my question: Is there some connection, via a transform, change of variables, or approximation, that produces the Frobenius method by analogy with non-singular equations?  Perhaps just when the roots of the indicial polynomial do not differ by integers?",,"['sequences-and-series', 'ordinary-differential-equations', 'intuition']"
28,Sequence of positive integers.,Sequence of positive integers.,,An infinite sequence of increasing positive integers is given with bounded first differences. Prove that there are elements $a$ and $b$ in the sequence such that $\dfrac{a}{b}$ is a positive integer. I think maybe computing the Natural Density of the sequence would lead to some contradiction. But don't know if it exists. Any help will be appreciated. Thanks.,An infinite sequence of increasing positive integers is given with bounded first differences. Prove that there are elements and in the sequence such that is a positive integer. I think maybe computing the Natural Density of the sequence would lead to some contradiction. But don't know if it exists. Any help will be appreciated. Thanks.,a b \dfrac{a}{b},"['sequences-and-series', 'elementary-number-theory', 'analytic-number-theory']"
29,"recurrence relation, all terms of the sequence positive","recurrence relation, all terms of the sequence positive",,"Let $a_1=a$ , $a_2=\frac{1}{a}-a$ , $a_{n+1}=\frac{n}{a_n}-a_n-a_{n-1}$ for $n=2,3,4,...$ . Find all $a$ such that $(a_n)$ is a sequence of positive reals. My attempt was to look at $a_3=\frac{3a^2-1}{a-a^3}$ , $a_4=\frac{8a^3-4a}{3a^4-4a^2+1}$ and a few more, $a_1>0$ gives $a>0$ , $a_2>0$ gives $a\in(0,1)$ , $a_3>0$ gives $a\in(\frac{1}{\sqrt{3}},1)$ , but this probably doesn't give important information and further terms are nasty.","Let , , for . Find all such that is a sequence of positive reals. My attempt was to look at , and a few more, gives , gives , gives , but this probably doesn't give important information and further terms are nasty.","a_1=a a_2=\frac{1}{a}-a a_{n+1}=\frac{n}{a_n}-a_n-a_{n-1} n=2,3,4,... a (a_n) a_3=\frac{3a^2-1}{a-a^3} a_4=\frac{8a^3-4a}{3a^4-4a^2+1} a_1>0 a>0 a_2>0 a\in(0,1) a_3>0 a\in(\frac{1}{\sqrt{3}},1)","['sequences-and-series', 'recurrence-relations']"
30,Uniform convergence of series $\sum\limits_{n=2}^\infty\frac{\sin n x}{n\log n}$,Uniform convergence of series,\sum\limits_{n=2}^\infty\frac{\sin n x}{n\log n},Using Dirichlet series test I proved that the series $\displaystyle\sum\limits_{n=2}^\infty\frac{\sin n x}{n\log n}$ converges for all $x\in\mathbb{R}$. How to determine whether this series converges uniformly on $\mathbb{R}$?,Using Dirichlet series test I proved that the series $\displaystyle\sum\limits_{n=2}^\infty\frac{\sin n x}{n\log n}$ converges for all $x\in\mathbb{R}$. How to determine whether this series converges uniformly on $\mathbb{R}$?,,"['sequences-and-series', 'convergence-divergence']"
31,Nature of the series $\sum\limits_{n}(g_n/p_n)^\alpha$ with $(p_n)$ primes and $(g_n)$ prime gaps,Nature of the series  with  primes and  prime gaps,\sum\limits_{n}(g_n/p_n)^\alpha (p_n) (g_n),"Let $p_n$ denote the $n$th prime number and $g_n=p_{n+1}-p_n$ the $n$th prime number gap. This is to ask for which values of $\alpha$ the series $S_\alpha$ converges or diverges, where $$S_\alpha=\sum_n\left(\frac{g_n}{p_n}\right)^\alpha.$$ Context: The obvious lower bound $g_n\geqslant1$ shows that $S_\alpha$ diverges for every $\alpha\leqslant1$. It is known (see the WP page ) that $g_n\lt (p_n)^\theta$ for every large enough $n$, for every $\theta\gt\frac34$, hence $S_\alpha$ converges for every $\alpha\gt4$. Various unproven results, such as Cramér's conjecture that $g_n=O\left((\log p_n)^2\right)$, would imply that $S_\alpha$ is finite if and only if $\alpha\gt1$. An answer for $\alpha=2$ would solve (and in fact would be equivalent to a solution of) this other question . Edit: @GregMartin's answer below yields naturally the more general result that the series $$S_{\alpha,\beta}=\sum_n\frac{g_n^\beta}{p_n^\alpha}$$ converges for every $$\alpha\gt\max\{1,\tfrac5{18}\beta+\tfrac{13}{18}\}.$$ For example, two convergent series are $$\sum_n\frac{g_n^2}{p_n^{4/3}},\qquad\sum_n\frac{g_n^4}{p_n^2}.$$ Actually, an asymptotic control $$ \sum_{n\colon p_n \le x} g_n^2 \leqslant x^{1+\gamma}, $$ for some $\gamma$ in $(0,1)$ (Heath-Brown's result used by @GregMartin being the case of every $\gamma\gt\frac5{18}$) would yield the convergence of $S_{\alpha,\beta}$ for every $(\alpha,\beta)$ such that $$\alpha-1\gt\gamma\cdot(\beta-1)_+.$$","Let $p_n$ denote the $n$th prime number and $g_n=p_{n+1}-p_n$ the $n$th prime number gap. This is to ask for which values of $\alpha$ the series $S_\alpha$ converges or diverges, where $$S_\alpha=\sum_n\left(\frac{g_n}{p_n}\right)^\alpha.$$ Context: The obvious lower bound $g_n\geqslant1$ shows that $S_\alpha$ diverges for every $\alpha\leqslant1$. It is known (see the WP page ) that $g_n\lt (p_n)^\theta$ for every large enough $n$, for every $\theta\gt\frac34$, hence $S_\alpha$ converges for every $\alpha\gt4$. Various unproven results, such as Cramér's conjecture that $g_n=O\left((\log p_n)^2\right)$, would imply that $S_\alpha$ is finite if and only if $\alpha\gt1$. An answer for $\alpha=2$ would solve (and in fact would be equivalent to a solution of) this other question . Edit: @GregMartin's answer below yields naturally the more general result that the series $$S_{\alpha,\beta}=\sum_n\frac{g_n^\beta}{p_n^\alpha}$$ converges for every $$\alpha\gt\max\{1,\tfrac5{18}\beta+\tfrac{13}{18}\}.$$ For example, two convergent series are $$\sum_n\frac{g_n^2}{p_n^{4/3}},\qquad\sum_n\frac{g_n^4}{p_n^2}.$$ Actually, an asymptotic control $$ \sum_{n\colon p_n \le x} g_n^2 \leqslant x^{1+\gamma}, $$ for some $\gamma$ in $(0,1)$ (Heath-Brown's result used by @GregMartin being the case of every $\gamma\gt\frac5{18}$) would yield the convergence of $S_{\alpha,\beta}$ for every $(\alpha,\beta)$ such that $$\alpha-1\gt\gamma\cdot(\beta-1)_+.$$",,"['sequences-and-series', 'number-theory', 'prime-numbers']"
32,an integer sum of products of tangents,an integer sum of products of tangents,,"This question arose from my initial attempts at answering this question . I later found a way to transform the desired sum into a sum of squares of tangents, but before I did, I found numerically that apparently $$ \sum_{l=1}^n\tan\frac{jl\pi}{2n+1}\tan\frac{kl\pi}{2n+1}=m_{jkn}(2n+1) $$ with integer factors $m_{jkn}$, for which I haven't been able to find an explanation. If $j$ or $k$ is coprime to $2n+1$, we can sum over $jl$ or $kl$ instead, so most cases (in particular all for $2n+1$ prime) can be reduced to the case $j=1$. Here are the numerically determined factors $m_{1kn}$ for $n\le18$ (with $n$ increasing downward and $k$ increasing to the right): $$ \begin{array}{r|rr} &1&2&3&4&5&6&7&8&9&10&11&12&13&14&15&16&17&18\\\hline1&1\\ 2&2&0\\ 3&3&-1&1\\ 4&4&0&1&0\\ 5&5&-1&1&1&1\\ 6&6&0&2&-2&0&0\\ 7&7&-1&2&-1&1&0&1\\ 8&8&0&2&0&2&2&2&0\\ 9&9&-1&3&1&1&-3&1&-1&1\\ 10&10&0&3&-2&2&-1&1&0&1&0\\ 11&11&-1&3&-1&1&-1&1&3&-1&1&1\\ 12&12&0&4&0&2&0&0&-4&0&0&0&0\\ 13&13&-1&4&1&3&0&1&-1&1&1&3&0&1\\ 14&14&0&4&-2&2&2&2&0&2&4&0&0&2&0\\ 15&15&-1&5&-1&3&-3&3&-1&3&-5&1&1&1&-1&1\\ 16&16&0&5&0&2&-1&2&0&1&-2&1&1&-2&-2&1&0\\ 17&17&-1&5&1&3&-1&2&-1&1&-1&1&5&1&0&1&1&1\\ 18&18&0&6&-2&4&0&2&0&2&-2&2&-6&0&0&4&2&0&0\\ \end{array} $$ (See also the table in this answer to the other question, which shows the case $j=k+1$; in that case the rows of the table sum to $0$ because of the identity that's the subject of the other question.) The values $m_{11n}=n$ reflect the sum of squares of tangents that I determined in my answer to the other question. I have no explanation for the remaining values. I've tried using the product formula for the tangent; multiplying by a third tangent to use the triple tangent product formula; and finding a polynomial whose roots are the products being summed; but none of that worked out. This vaguely reminds me of character theory; the values $\tan\frac{kl\pi}{2n+1}$ for fixed $k$ are like characters, and their dot products are integer multiples of the ""group order"" $2n+1$; though if they were characters the dot products couldn't be negative. I'd appreciate any insight into this phenomenon, and of course ideally a way to calculate the $m_{jkn}$. [ Update: ] I've verified the periodicities that Brian observed in comments up to $n=250$: $$m_{1,k,n+k} = m_{1kn}+[k \text{ odd}]\;,$$ $$m_{1,k+4d+2,k+4d+2+d}=m_{1,k,k+d}\;,$$ where the bracket is the Iverson bracket .","This question arose from my initial attempts at answering this question . I later found a way to transform the desired sum into a sum of squares of tangents, but before I did, I found numerically that apparently $$ \sum_{l=1}^n\tan\frac{jl\pi}{2n+1}\tan\frac{kl\pi}{2n+1}=m_{jkn}(2n+1) $$ with integer factors $m_{jkn}$, for which I haven't been able to find an explanation. If $j$ or $k$ is coprime to $2n+1$, we can sum over $jl$ or $kl$ instead, so most cases (in particular all for $2n+1$ prime) can be reduced to the case $j=1$. Here are the numerically determined factors $m_{1kn}$ for $n\le18$ (with $n$ increasing downward and $k$ increasing to the right): $$ \begin{array}{r|rr} &1&2&3&4&5&6&7&8&9&10&11&12&13&14&15&16&17&18\\\hline1&1\\ 2&2&0\\ 3&3&-1&1\\ 4&4&0&1&0\\ 5&5&-1&1&1&1\\ 6&6&0&2&-2&0&0\\ 7&7&-1&2&-1&1&0&1\\ 8&8&0&2&0&2&2&2&0\\ 9&9&-1&3&1&1&-3&1&-1&1\\ 10&10&0&3&-2&2&-1&1&0&1&0\\ 11&11&-1&3&-1&1&-1&1&3&-1&1&1\\ 12&12&0&4&0&2&0&0&-4&0&0&0&0\\ 13&13&-1&4&1&3&0&1&-1&1&1&3&0&1\\ 14&14&0&4&-2&2&2&2&0&2&4&0&0&2&0\\ 15&15&-1&5&-1&3&-3&3&-1&3&-5&1&1&1&-1&1\\ 16&16&0&5&0&2&-1&2&0&1&-2&1&1&-2&-2&1&0\\ 17&17&-1&5&1&3&-1&2&-1&1&-1&1&5&1&0&1&1&1\\ 18&18&0&6&-2&4&0&2&0&2&-2&2&-6&0&0&4&2&0&0\\ \end{array} $$ (See also the table in this answer to the other question, which shows the case $j=k+1$; in that case the rows of the table sum to $0$ because of the identity that's the subject of the other question.) The values $m_{11n}=n$ reflect the sum of squares of tangents that I determined in my answer to the other question. I have no explanation for the remaining values. I've tried using the product formula for the tangent; multiplying by a third tangent to use the triple tangent product formula; and finding a polynomial whose roots are the products being summed; but none of that worked out. This vaguely reminds me of character theory; the values $\tan\frac{kl\pi}{2n+1}$ for fixed $k$ are like characters, and their dot products are integer multiples of the ""group order"" $2n+1$; though if they were characters the dot products couldn't be negative. I'd appreciate any insight into this phenomenon, and of course ideally a way to calculate the $m_{jkn}$. [ Update: ] I've verified the periodicities that Brian observed in comments up to $n=250$: $$m_{1,k,n+k} = m_{1kn}+[k \text{ odd}]\;,$$ $$m_{1,k+4d+2,k+4d+2+d}=m_{1,k,k+d}\;,$$ where the bracket is the Iverson bracket .",,"['sequences-and-series', 'trigonometry']"
33,Nontrivial subsequences of the harmonic series that diverge on the order of $\log(\log(\log(n)))$.,Nontrivial subsequences of the harmonic series that diverge on the order of .,\log(\log(\log(n))),"It is common knowledge that $$\sum_{\text{Integer}}^\infty \frac{1}{n} \sim \log(n),$$ and that $$\sum_{\text{Prime}}^\infty \frac{1}{p} \sim \log(\log(n)).$$ I am looking for another subseries of the harmonic series that diverges with some number of iterated logarithms like $$\sum_{??}^\infty \frac{1}{q} \sim \log(\log(\log(n))).$$ For convenience this will be called ""third order"" divergence. I am specifically looking for a series that is not trivial. A trivial example would be a series that is constructed so that terms are only added when the cumulative sum is less than $\log(\log(\log(\log (n)))$. The more ""natural"" the better (although I realize that this is subjective). Any answers could include the reciprocal of primes of the form $4n+1$, all twin primes, all odd perfect numbers, etc. The only other thing needed would be to show the order of divergence. I am also looking for verification/disproof of the current conjectured answer. Thank you. Bounty rules: I am looking for a proof or significant demonstration of a series that exhibits this behavior. It is not only limited to ""third order"" logarithms and can be any ""order"" greater than $2$. I have decided to accept and bounty Winther's answer even though it would not be considered ""natural"". I believe that the proof is correct and it generalizes to any order of logarithm. It also provides a good explanation as to why the prime series diverges by second order logarithms. Even though the question is answered I would still accept the submission of other ""more natural"" series if any of them happen to pop up.","It is common knowledge that $$\sum_{\text{Integer}}^\infty \frac{1}{n} \sim \log(n),$$ and that $$\sum_{\text{Prime}}^\infty \frac{1}{p} \sim \log(\log(n)).$$ I am looking for another subseries of the harmonic series that diverges with some number of iterated logarithms like $$\sum_{??}^\infty \frac{1}{q} \sim \log(\log(\log(n))).$$ For convenience this will be called ""third order"" divergence. I am specifically looking for a series that is not trivial. A trivial example would be a series that is constructed so that terms are only added when the cumulative sum is less than $\log(\log(\log(\log (n)))$. The more ""natural"" the better (although I realize that this is subjective). Any answers could include the reciprocal of primes of the form $4n+1$, all twin primes, all odd perfect numbers, etc. The only other thing needed would be to show the order of divergence. I am also looking for verification/disproof of the current conjectured answer. Thank you. Bounty rules: I am looking for a proof or significant demonstration of a series that exhibits this behavior. It is not only limited to ""third order"" logarithms and can be any ""order"" greater than $2$. I have decided to accept and bounty Winther's answer even though it would not be considered ""natural"". I believe that the proof is correct and it generalizes to any order of logarithm. It also provides a good explanation as to why the prime series diverges by second order logarithms. Even though the question is answered I would still accept the submission of other ""more natural"" series if any of them happen to pop up.",,['sequences-and-series']
34,"How to prove the sequence $\{a_n\}$ is unbounded, which satisfies the recurrence relation $a_{n+1}=\ln |a_n|$?","How to prove the sequence  is unbounded, which satisfies the recurrence relation ?",\{a_n\} a_{n+1}=\ln |a_n|,"When I browsed Zhihu (a Chinese Q&A community), I met this question. That is Let $\{a_n\}$ be recursive s.t. $$a_1=2,\ a_{n+1}=\ln |a_n|(n\in \Bbb N).$$ Show that $\{a_n\}$ is unbounded. I want to investigate a subsequence $\{a_{t_n}\}$ of $\{a_n\}$ , where $t_n$ is greatest integer satisfying $$a_{t_n}=\min_{1\leqslant k\leqslant n}a_k.$$ Thus $a_{t_n}\to -A(<0),n\to \infty$ . However, it helps little with the origin question. So how can I solve it ?","When I browsed Zhihu (a Chinese Q&A community), I met this question. That is Let be recursive s.t. Show that is unbounded. I want to investigate a subsequence of , where is greatest integer satisfying Thus . However, it helps little with the origin question. So how can I solve it ?","\{a_n\} a_1=2,\ a_{n+1}=\ln |a_n|(n\in \Bbb N). \{a_n\} \{a_{t_n}\} \{a_n\} t_n a_{t_n}=\min_{1\leqslant k\leqslant n}a_k. a_{t_n}\to -A(<0),n\to \infty","['sequences-and-series', 'dynamical-systems']"
35,Sum the series $\sum_{n = 0}^{\infty} (-1)^{n}\{(2n + 1)^{7}\cosh((2n + 1)\pi\sqrt{3}/2)\}^{-1}$,Sum the series,\sum_{n = 0}^{\infty} (-1)^{n}\{(2n + 1)^{7}\cosh((2n + 1)\pi\sqrt{3}/2)\}^{-1},"In one of his letters to G. H. Hardy, Ramanujan gave the following sum $$\dfrac{1}{1^{7}\cosh\left(\dfrac{\pi\sqrt{3}}{2}\right)} - \dfrac{1}{3^{7}\cosh\left(\dfrac{3\pi\sqrt{3}}{2}\right)} + \dfrac{1}{5^{7}\cosh\left(\dfrac{5\pi\sqrt{3}}{2}\right)} - \cdots = \frac{\pi^{7}}{23040}\tag{1}$$ or using $\sum $ notation $$\sum_{n = 0}^{\infty} \dfrac{(-1)^{n}}{(2n + 1)^{7}\cosh\left(\dfrac{(2n + 1)\pi\sqrt{3}}{2}\right)} = \frac{\pi^{7}}{23040}$$ Since $\cosh y = (e^{y} + e^{-y})/2$ we can see that the sum is equal to $$S = 2\sum_{n = 0}^{\infty}\dfrac{(-1)^{n}\exp\left(-\dfrac{(2n + 1)\pi\sqrt{3}}{2}\right)}{(2n + 1)^{7}\left\{1 + \exp\left(-(2n + 1)\pi\sqrt{3}\right)\right\}}$$ Putting $$q = \exp\left(-\pi\sqrt{3}\right)$$ we get the sum as $$S = 2\sum_{n = 0}^{\infty}\frac{(-1)^{n}q^{n + 1/2}}{(2n + 1)^{7}(1 + q^{2n + 1})}$$ We can then use $$\dfrac{q^{n + 1/2}}{1 + q^{2n + 1}} = \frac{q^{n + 1/2} - q^{3(n + 1/2)}}{1 - q^{4n + 2}}$$ and hope to use the Ramanujan functions $P, Q, R$ given by $$P(q) = 1 - 24\sum_{n = 1}^{\infty}\frac{nq^{2n}}{1 - q^{2n}}\\ Q(q) = 1 + 240\sum_{n = 1}^{\infty}\frac{n^{3}q^{2n}}{1 - q^{2n}}\\ R(q) = 1 - 504\sum_{n = 1}^{\infty}\frac{n^{5}q^{2n}}{1 - q^{2n}}$$ to calculate the sum $S$ in terms of $P, Q, R$. However the stumbling block is the term $(2n + 1)^{7}$ appearing in the denominator. Therefore I am not sure if the functions $P, Q, R$ can be used in the evaluation of sum $S$. Please let me know if there are any other approaches to calculate the sum $S$. Update : While going through Ramanujan's Notebooks Vol 3 (by Bruce C. Berndt) I found the proof for the above sum. But he uses a highly non-obvious formula (also discovered by Ramanujan) $$\frac{u^{6n}}{\cos u\cos(\omega u)\cos(\omega^{2}u)} = 12\sum_{k = 0}^{\infty}\dfrac{(-1)^{k}\left\{\left(k + \dfrac{1}{2}\right)\pi\right\}^{6n + 5}}{\left[\left\{\left(k + \dfrac{1}{2}\right)\pi\right\}^{6} - u^{6}\right]\cosh\left\{\left(k + \dfrac{1}{2}\right)\pi\sqrt{3}\right\}}\tag{2}$$ where $\omega$ is a primitive cube root of unity. Berndt goes on to say that Ramanujan probably obtained this formula $(2)$ via partial fractions and says that it can be obtained by a routine procedure with somewhat lengthy calculation. The method of partial fractions is used to express a rational function (for the purpose of integrating them) in the form of a sum of finite terms which can be integrated via standard formulas. I am nor sure how that could be extended to any general function (which is not rational) and thereby produce a series. Berndt says ""the sum $(1)$ can be obtained by putting $n = 0$ in $(2)$ and then equating coefficients of $u^{6}$ on both sides"". This part requires some reasonable amount of calculation, but it is not so difficult. I want to understand the technique of partial fractions as applied to general functions (may be with some requirement of continuity and differentiability) and its proper justification so that I can provide a proof of formula $(2)$ for myself and thereby have a complete proof of the Ramanujan's sum $(1)$.","In one of his letters to G. H. Hardy, Ramanujan gave the following sum $$\dfrac{1}{1^{7}\cosh\left(\dfrac{\pi\sqrt{3}}{2}\right)} - \dfrac{1}{3^{7}\cosh\left(\dfrac{3\pi\sqrt{3}}{2}\right)} + \dfrac{1}{5^{7}\cosh\left(\dfrac{5\pi\sqrt{3}}{2}\right)} - \cdots = \frac{\pi^{7}}{23040}\tag{1}$$ or using $\sum $ notation $$\sum_{n = 0}^{\infty} \dfrac{(-1)^{n}}{(2n + 1)^{7}\cosh\left(\dfrac{(2n + 1)\pi\sqrt{3}}{2}\right)} = \frac{\pi^{7}}{23040}$$ Since $\cosh y = (e^{y} + e^{-y})/2$ we can see that the sum is equal to $$S = 2\sum_{n = 0}^{\infty}\dfrac{(-1)^{n}\exp\left(-\dfrac{(2n + 1)\pi\sqrt{3}}{2}\right)}{(2n + 1)^{7}\left\{1 + \exp\left(-(2n + 1)\pi\sqrt{3}\right)\right\}}$$ Putting $$q = \exp\left(-\pi\sqrt{3}\right)$$ we get the sum as $$S = 2\sum_{n = 0}^{\infty}\frac{(-1)^{n}q^{n + 1/2}}{(2n + 1)^{7}(1 + q^{2n + 1})}$$ We can then use $$\dfrac{q^{n + 1/2}}{1 + q^{2n + 1}} = \frac{q^{n + 1/2} - q^{3(n + 1/2)}}{1 - q^{4n + 2}}$$ and hope to use the Ramanujan functions $P, Q, R$ given by $$P(q) = 1 - 24\sum_{n = 1}^{\infty}\frac{nq^{2n}}{1 - q^{2n}}\\ Q(q) = 1 + 240\sum_{n = 1}^{\infty}\frac{n^{3}q^{2n}}{1 - q^{2n}}\\ R(q) = 1 - 504\sum_{n = 1}^{\infty}\frac{n^{5}q^{2n}}{1 - q^{2n}}$$ to calculate the sum $S$ in terms of $P, Q, R$. However the stumbling block is the term $(2n + 1)^{7}$ appearing in the denominator. Therefore I am not sure if the functions $P, Q, R$ can be used in the evaluation of sum $S$. Please let me know if there are any other approaches to calculate the sum $S$. Update : While going through Ramanujan's Notebooks Vol 3 (by Bruce C. Berndt) I found the proof for the above sum. But he uses a highly non-obvious formula (also discovered by Ramanujan) $$\frac{u^{6n}}{\cos u\cos(\omega u)\cos(\omega^{2}u)} = 12\sum_{k = 0}^{\infty}\dfrac{(-1)^{k}\left\{\left(k + \dfrac{1}{2}\right)\pi\right\}^{6n + 5}}{\left[\left\{\left(k + \dfrac{1}{2}\right)\pi\right\}^{6} - u^{6}\right]\cosh\left\{\left(k + \dfrac{1}{2}\right)\pi\sqrt{3}\right\}}\tag{2}$$ where $\omega$ is a primitive cube root of unity. Berndt goes on to say that Ramanujan probably obtained this formula $(2)$ via partial fractions and says that it can be obtained by a routine procedure with somewhat lengthy calculation. The method of partial fractions is used to express a rational function (for the purpose of integrating them) in the form of a sum of finite terms which can be integrated via standard formulas. I am nor sure how that could be extended to any general function (which is not rational) and thereby produce a series. Berndt says ""the sum $(1)$ can be obtained by putting $n = 0$ in $(2)$ and then equating coefficients of $u^{6}$ on both sides"". This part requires some reasonable amount of calculation, but it is not so difficult. I want to understand the technique of partial fractions as applied to general functions (may be with some requirement of continuity and differentiability) and its proper justification so that I can provide a proof of formula $(2)$ for myself and thereby have a complete proof of the Ramanujan's sum $(1)$.",,['sequences-and-series']
36,"Ways of choosing $16$ integers from first $150$ integers such that there is no $(a,b,c,d)$ for which $a+b=c+d$",Ways of choosing  integers from first  integers such that there is no  for which,"16 150 (a,b,c,d) a+b=c+d","Here is a problem I found out recently: In how many ways one can choose $16$ distinct positive integers from first $150$ positive integers such that there are no $4$ distinct ones $(a,b,c,d)$ for which $a+b=c+d$ ? My approach: If $a+b=c+d$ , then $a-c=d-b$ . There are $149$ differences from the first $150$ positive integers. We have to choose $\binom{16}{2}=120$ differences. So, the answer is $\binom{149}{120}$ . I'm confused with my approach. Edit: My solution is not correct . So, what is the correct solution to the problem? And I noticed that it is hard to find out such $16$ integers. So, if choosing $16$ such numbers is not possible , how to prove that? Any helpful approach is welcome. Source : The problem is self-made and inspired from a problem from the book 102 Combinatorial Problems: From The Training of The USA IMO Team by Titu Andreescu and Zuming Feng .","Here is a problem I found out recently: In how many ways one can choose distinct positive integers from first positive integers such that there are no distinct ones for which ? My approach: If , then . There are differences from the first positive integers. We have to choose differences. So, the answer is . I'm confused with my approach. Edit: My solution is not correct . So, what is the correct solution to the problem? And I noticed that it is hard to find out such integers. So, if choosing such numbers is not possible , how to prove that? Any helpful approach is welcome. Source : The problem is self-made and inspired from a problem from the book 102 Combinatorial Problems: From The Training of The USA IMO Team by Titu Andreescu and Zuming Feng .","16 150 4 (a,b,c,d) a+b=c+d a+b=c+d a-c=d-b 149 150 \binom{16}{2}=120 \binom{149}{120} 16 16","['sequences-and-series', 'combinatorics']"
37,Can $e^x$ be expressed as a linear combination of $(1 + \frac x n)^n$?,Can  be expressed as a linear combination of ?,e^x (1 + \frac x n)^n,"Can $e^x$ be expressed as a linear combination of $(1 + \frac x n)^n$ ? In other words, does there exist an infinite sequence $(a_k)_{k \in \mathbb N_0}$ such that $$e^x = a_0 + \sum_{1 \leq k < \infty} a_k \left(1 + \frac x k\right)^k$$ for all $x \in \mathbb R$ ? Call the series on the right $s(x)$ . I can answer the question in the negative when the series is absolutely convergent. In the conditionally convergent case, I'm not so sure. My thoughts were to use the fact that: $$e^{x - \frac{x^2}{2k}} \leq (1+ \frac x k)^k \leq e^{x}$$ and use the lower bound when $a_k$ is negative, and the upper bound when $a_k$ is positive. This gets stuck because it's not always the case that if some $b_k$ is a decaying sequence then $\sum_{k} \frac{b_k}{k}$ is convergent. The strengthened inequality $$e^{x - \frac{x^2}{2k}} \leq (1+ \frac x k)^k \leq e^{x - \frac{x^2}{2k} + \frac{x^3}{3k^2}}$$ looks like it might make more progress... [EDIT 2019/08/14 14:00 GMT] This is the solution in the absolutely convergent case, given by lemmas 1 and 2 : Definition : Let $s(x) = a_0 + \sum_{1 \leq k < \infty} a_k \left(1 + \frac x k\right)^k$ . Lemmas and proofs follow: Lemma 1 : If $s(x)$ converges absolutely for some $x\geq 0$ , then $s(x)$ converges absolutely for all $x \geq 0$ . Proof Pick an $x_0 \geq 0$ for which $s(x_0)$ converges absolutely. By the condition stated in the lemma, the series $\sum_{1 \leq k < \infty} |a_k| \left|1 + \frac {x_0} k\right|^k$ must converge. We also observe that $|a_k| \leq |a_k| \left|1 + \frac {x_0} k\right|^k$ is true for all $k$ . So by the Direct Comparison Test, the series $\sum_{0 \leq k < \infty} |a_k|$ must also converge. In other words, $s(0)$ is absolutely convergent. Consider now any $x \geq 0$ . The series $\sum_{0 \leq k < \infty} |a_k| e^{x}$ converges because it is equal to $e^{x} \sum_{0 \leq k < \infty} |a_k|$ , which we proved to be convergent in the previous paragraph. We observe that $|a_k| \left|1 + \frac {x} k\right|^k \leq |a_k| e^{x}$ is true for all $k$ . So by the Direct Comparison Test, the series $|a_0| + \sum_{1 \leq k < \infty} |a_k| \left|1 + \frac {x} k\right|^k$ must also converge. So by the definition of absolute convergence, we have that $a_0 + \sum_{1 \leq k < \infty} a_k \left(1 + \frac x k\right)^k=s(x)$ converges absolutely, where $x \geq 0$ was arbitrary. $\blacksquare$ Lemma 2 : If $s(x)$ converges absolutely when $x \geq 0$ , then for large enough $x$ we have that $e^x > s(x)$ . Proof Let $z_n(x) = |a_0| + \sum_{1 \leq k < n} |a_k| \left(1 + \frac x k\right)^k$ . Pick some $\epsilon < \frac 1 2$ . Observe that there must be a large enough $n$ such that $z_\infty(0) - z_n(0) \leq \epsilon$ . Using the triangle inequality, we have that: $$\begin{aligned} |s(x)| &\leq z_\infty(x)\\ &\leq z_n(x) + (z_\infty(x) - z_n(x))\\ \end{aligned}$$ Since $z_n(x)$ is a polynomial, there is a large enough $X$ such that all $x \geq X$ it's true $z_n(x) < \epsilon \cdot e^x$ . So we have that $$\begin{aligned} |s(x)| &<\epsilon\cdot e^x + (z_\infty(x) - z_n(x))\\ &\leq \epsilon\cdot e^x + (z_\infty(0) - z_n(0)) e^x\\ &\leq \epsilon\cdot e^x + \epsilon\cdot e^x\\ & = 2\epsilon \cdot e^x\\ &< e^x. \end{aligned}$$ The claim above that $z_\infty(x) - z_n(x) \leq (z_\infty(0) - z_n(0)) e^x$ follows from $$\begin{aligned} &|a_k| \left(1 + \frac x k\right)^k \leq |a_k| e^x\\ \implies &\sum_{k \geq {n+1}}\left(1 + \frac x k\right)^k \leq \sum_{k \geq {n+1}}|a_k| e^x\\ \implies & z_\infty(x) - z_n(x) \leq (z_\infty(0) - z_n(0)) e^x \end{aligned}$$ We are done. $\blacksquare$","Can be expressed as a linear combination of ? In other words, does there exist an infinite sequence such that for all ? Call the series on the right . I can answer the question in the negative when the series is absolutely convergent. In the conditionally convergent case, I'm not so sure. My thoughts were to use the fact that: and use the lower bound when is negative, and the upper bound when is positive. This gets stuck because it's not always the case that if some is a decaying sequence then is convergent. The strengthened inequality looks like it might make more progress... [EDIT 2019/08/14 14:00 GMT] This is the solution in the absolutely convergent case, given by lemmas 1 and 2 : Definition : Let . Lemmas and proofs follow: Lemma 1 : If converges absolutely for some , then converges absolutely for all . Proof Pick an for which converges absolutely. By the condition stated in the lemma, the series must converge. We also observe that is true for all . So by the Direct Comparison Test, the series must also converge. In other words, is absolutely convergent. Consider now any . The series converges because it is equal to , which we proved to be convergent in the previous paragraph. We observe that is true for all . So by the Direct Comparison Test, the series must also converge. So by the definition of absolute convergence, we have that converges absolutely, where was arbitrary. Lemma 2 : If converges absolutely when , then for large enough we have that . Proof Let . Pick some . Observe that there must be a large enough such that . Using the triangle inequality, we have that: Since is a polynomial, there is a large enough such that all it's true . So we have that The claim above that follows from We are done.","e^x (1 + \frac x n)^n (a_k)_{k \in \mathbb N_0} e^x = a_0 + \sum_{1 \leq k < \infty} a_k \left(1 + \frac x k\right)^k x \in \mathbb R s(x) e^{x - \frac{x^2}{2k}} \leq (1+ \frac x k)^k \leq e^{x} a_k a_k b_k \sum_{k} \frac{b_k}{k} e^{x - \frac{x^2}{2k}} \leq (1+ \frac x k)^k \leq e^{x - \frac{x^2}{2k} + \frac{x^3}{3k^2}} s(x) = a_0 + \sum_{1 \leq k < \infty} a_k \left(1 + \frac x k\right)^k s(x) x\geq 0 s(x) x \geq 0 x_0 \geq 0 s(x_0) \sum_{1 \leq k < \infty} |a_k| \left|1 + \frac {x_0} k\right|^k |a_k| \leq |a_k| \left|1 + \frac {x_0} k\right|^k k \sum_{0 \leq k < \infty} |a_k| s(0) x \geq 0 \sum_{0 \leq k < \infty} |a_k| e^{x} e^{x} \sum_{0 \leq k < \infty} |a_k| |a_k| \left|1 + \frac {x} k\right|^k \leq |a_k| e^{x} k |a_0| + \sum_{1 \leq k < \infty} |a_k| \left|1 + \frac {x} k\right|^k a_0 + \sum_{1 \leq k < \infty} a_k \left(1 + \frac x k\right)^k=s(x) x \geq 0 \blacksquare s(x) x \geq 0 x e^x > s(x) z_n(x) = |a_0| + \sum_{1 \leq k < n} |a_k| \left(1 + \frac x k\right)^k \epsilon < \frac 1 2 n z_\infty(0) - z_n(0) \leq \epsilon \begin{aligned}
|s(x)| &\leq z_\infty(x)\\
&\leq z_n(x) + (z_\infty(x) - z_n(x))\\
\end{aligned} z_n(x) X x \geq X z_n(x) < \epsilon \cdot e^x \begin{aligned}
|s(x)| &<\epsilon\cdot e^x + (z_\infty(x) - z_n(x))\\
&\leq \epsilon\cdot e^x + (z_\infty(0) - z_n(0)) e^x\\
&\leq \epsilon\cdot e^x + \epsilon\cdot e^x\\
& = 2\epsilon \cdot e^x\\
&< e^x.
\end{aligned} z_\infty(x) - z_n(x) \leq (z_\infty(0) - z_n(0)) e^x \begin{aligned}
&|a_k| \left(1 + \frac x k\right)^k \leq |a_k| e^x\\
\implies &\sum_{k \geq {n+1}}\left(1 + \frac x k\right)^k \leq \sum_{k \geq {n+1}}|a_k| e^x\\
\implies & z_\infty(x) - z_n(x) \leq (z_\infty(0) - z_n(0)) e^x
\end{aligned} \blacksquare","['sequences-and-series', 'exponential-function', 'conditional-convergence']"
38,Series which are not Fourier Series,Series which are not Fourier Series,,"How to show that $$ \sum_{n=2}^\infty \frac{\sin{(nx)}}{\log n} $$ not the Fourier series of any function? I have shown that the series is convergent by Dirichlet test. Let $a(n)=\frac{1}{\log n}$. What is $\sum (a(n))^2$, to apply Parseval's theorem?","How to show that $$ \sum_{n=2}^\infty \frac{\sin{(nx)}}{\log n} $$ not the Fourier series of any function? I have shown that the series is convergent by Dirichlet test. Let $a(n)=\frac{1}{\log n}$. What is $\sum (a(n))^2$, to apply Parseval's theorem?",,"['sequences-and-series', 'convergence-divergence', 'fourier-series']"
39,Find the sum of the series $\sum \frac{1}{n(n+1)(n+2)}$,Find the sum of the series,\sum \frac{1}{n(n+1)(n+2)},I got this question in my maths paper Test the condition for convergence of $$\sum_{n=1}^\infty \frac{1}{n(n+1)(n+2)}$$   and find the sum if it exists. I managed to show that the series converges but I was unable to find the sum. Any help/hint will go a long way. Thank you.,I got this question in my maths paper Test the condition for convergence of $$\sum_{n=1}^\infty \frac{1}{n(n+1)(n+2)}$$   and find the sum if it exists. I managed to show that the series converges but I was unable to find the sum. Any help/hint will go a long way. Thank you.,,['sequences-and-series']
40,Sum of series $\sum \limits_{k=1}^{\infty}\frac{\sin^3 3^k}{3^k}$,Sum of series,\sum \limits_{k=1}^{\infty}\frac{\sin^3 3^k}{3^k},Calculate the following sum: $$\sum \limits_{k=1}^{\infty}\dfrac{\sin^3 3^k}{3^k}$$ Unfortunately I have no idea how to handle with this problem. Could anyone show it solution?,Calculate the following sum: $$\sum \limits_{k=1}^{\infty}\dfrac{\sin^3 3^k}{3^k}$$ Unfortunately I have no idea how to handle with this problem. Could anyone show it solution?,,['sequences-and-series']
41,Where did the negative answer come from?,Where did the negative answer come from?,,"The question is to evaluate $\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\cdots }}}}$ $$x=\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\cdots }}}}$$ $$x^2=2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\cdots }}}}$$ $$x^2=2+x$$ $$x^2-x-2=0$$ $$(x-2)(x+1)=0$$ $$x=2,-1$$ because $x$ is positive $x=2$ is the answer. but where did the $x=-1$ come from ?","The question is to evaluate $\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\cdots }}}}$ $$x=\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\cdots }}}}$$ $$x^2=2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\cdots }}}}$$ $$x^2=2+x$$ $$x^2-x-2=0$$ $$(x-2)(x+1)=0$$ $$x=2,-1$$ because $x$ is positive $x=2$ is the answer. but where did the $x=-1$ come from ?",,"['sequences-and-series', 'algebra-precalculus', 'limits', 'nested-radicals']"
42,Evaluating $ \lim\limits_{n\to\infty} \sum_{k=1}^{n^2} \frac{n}{n^2+k^2} $,Evaluating, \lim\limits_{n\to\infty} \sum_{k=1}^{n^2} \frac{n}{n^2+k^2} ,How would you evaluate the following series? $$\lim_{n\to\infty} \sum_{k=1}^{n^2} \frac{n}{n^2+k^2} $$ Thanks.,How would you evaluate the following series? $$\lim_{n\to\infty} \sum_{k=1}^{n^2} \frac{n}{n^2+k^2} $$ Thanks.,,"['sequences-and-series', 'limits']"
43,Method of proof of $\sum\limits_{n=1}^{\infty}\tfrac{\coth n\pi}{n^7}=\tfrac{19}{56700}\pi^7$,Method of proof of,\sum\limits_{n=1}^{\infty}\tfrac{\coth n\pi}{n^7}=\tfrac{19}{56700}\pi^7,"The following formula was stated by Ramanujan: $$\sum\limits_{n=1}^{\infty}\frac{\coth n\pi}{n^7}=\frac{19\pi^7}{56700}$$ Does anybody know the method of proof of this formula? I know that typically Ramanujan used extensively methods of divergent series, but I cannot see how to attempt a proof of this result. It looks somehow like a relatively simple result, but I can't see what methods might be used to obtain it.","The following formula was stated by Ramanujan: $$\sum\limits_{n=1}^{\infty}\frac{\coth n\pi}{n^7}=\frac{19\pi^7}{56700}$$ Does anybody know the method of proof of this formula? I know that typically Ramanujan used extensively methods of divergent series, but I cannot see how to attempt a proof of this result. It looks somehow like a relatively simple result, but I can't see what methods might be used to obtain it.",,"['sequences-and-series', 'trigonometry']"
44,Infinite Series: Fibonacci/ $2^n$ [duplicate],Infinite Series: Fibonacci/  [duplicate],2^n,"This question already has answers here : How to prove the Fibonacci sum $\sum \limits_{n=0}^{\infty}\frac{F_n}{p^n} = \frac{p}{p^2-p-1}$ (3 answers) Closed 7 years ago . I presented the following problem to some of my students recently (from Senior Mathematical Challenge - edited by Gardiner) In the Fibonacci sequence $1, 1, 2, 3, 5, 8, 13, 21, 34, 55,\ldots$ each term after the first two is the sum of the two previous terms. What is the sum to infinity of the series: $$\frac{1}{2} + \frac{1}{4}+ \frac{2}{8} + \frac{3}{16} + \frac{5}{32} +\frac{8}{64} + \frac{13}{128} +\frac{21}{256} +\frac{34}{512}+ \frac{55}{1024} + \cdots$$ Now, I solved this using an infinite geometric matrix series (incorporating the matrix version of the relation $a_n= \frac{a_{n-1}}{2}+ \frac{a_{n-2}}{4}$ ), and my students, after much hinting on my part, googled the necessary string to stumble across Binet's formula (which allows one to split the series into two simple, if rather messy, geometrics). Both of these are good methods, but neither really seems plausible for a challenge set for 15-18 year olds under exam conditions. So how is one supposed to do it?","This question already has answers here : How to prove the Fibonacci sum $\sum \limits_{n=0}^{\infty}\frac{F_n}{p^n} = \frac{p}{p^2-p-1}$ (3 answers) Closed 7 years ago . I presented the following problem to some of my students recently (from Senior Mathematical Challenge - edited by Gardiner) In the Fibonacci sequence each term after the first two is the sum of the two previous terms. What is the sum to infinity of the series: Now, I solved this using an infinite geometric matrix series (incorporating the matrix version of the relation ), and my students, after much hinting on my part, googled the necessary string to stumble across Binet's formula (which allows one to split the series into two simple, if rather messy, geometrics). Both of these are good methods, but neither really seems plausible for a challenge set for 15-18 year olds under exam conditions. So how is one supposed to do it?","1, 1, 2, 3, 5, 8, 13, 21, 34, 55,\ldots \frac{1}{2} + \frac{1}{4}+ \frac{2}{8} + \frac{3}{16} + \frac{5}{32} +\frac{8}{64} + \frac{13}{128} +\frac{21}{256} +\frac{34}{512}+ \frac{55}{1024} + \cdots a_n= \frac{a_{n-1}}{2}+ \frac{a_{n-2}}{4}","['sequences-and-series', 'education', 'fibonacci-numbers']"
45,$\sum_{p \in \mathcal P} \frac1{p\ln p}$ converges or diverges?,converges or diverges?,\sum_{p \in \mathcal P} \frac1{p\ln p},"We will denote the set of prime numbers with $\mathcal P$ . We know that the sum $$\sum_{n=1}^{\infty}\frac1n \hspace{3mm} \text{and} \hspace{3mm} \sum_{n=2}^{\infty}\frac1{n\ln n}$$ diverges. It is also known that $$\sum_{p \in \mathcal P} \frac1p$$ also diverges, where the sum runs over the $p$ primes. How could we decide whether $$\sum_{p \in \mathcal P} \frac1{p\ln p}$$ converges or not?","We will denote the set of prime numbers with . We know that the sum diverges. It is also known that also diverges, where the sum runs over the primes. How could we decide whether converges or not?",\mathcal P \sum_{n=1}^{\infty}\frac1n \hspace{3mm} \text{and} \hspace{3mm} \sum_{n=2}^{\infty}\frac1{n\ln n} \sum_{p \in \mathcal P} \frac1p p \sum_{p \in \mathcal P} \frac1{p\ln p},"['sequences-and-series', 'number-theory', 'convergence-divergence', 'prime-numbers']"
46,A double sum $\sum \limits_{n=1}^{n=\infty}\left(\sum \limits_{k=n}^{k=n^2}\frac{1}{k^2}\right)$,A double sum,\sum \limits_{n=1}^{n=\infty}\left(\sum \limits_{k=n}^{k=n^2}\frac{1}{k^2}\right),How to evaluate $\displaystyle\sum_{n=1}^{n=\infty}\left(\sum_{k=n}^{k=n^2}\frac{1}{k^2}\right)$?,How to evaluate $\displaystyle\sum_{n=1}^{n=\infty}\left(\sum_{k=n}^{k=n^2}\frac{1}{k^2}\right)$?,,"['sequences-and-series', 'convergence-divergence']"
47,How slowly can a series grow to be convergent?,How slowly can a series grow to be convergent?,,"This may be a poorly worded question, but I hope to flesh out my ideas well. The takeaway here is this: some series diverge to infinity while others converge to a fixed value. Take the two classical examples: the harmonic series and the Basel Problem $$\displaystyle\sum_{n=1}^\infty \frac{1}{n}= \infty \, , \hspace{0.6cm} \displaystyle\sum_{n=1}^\infty\frac{1}{n^2} = \frac{\pi^2}{6}$$ On one end, we have a divergent series, whereas on the other end, we have a convergent series, both series of which seem eerily similar, except for the square in the latter. A question I might raise would be: at what ""rate of growth"" (loosely speaking) does a series have to grow to tip over from the point of convergence to sudden, chaotic divergence? Yes, in Calculus, you learn about various convergence tests that allow one to test whether a given series is convergent, but I am wondering if there is a famous ""rate of growth"" that a series must ""exceed"" in order to indisputably diverge.","This may be a poorly worded question, but I hope to flesh out my ideas well. The takeaway here is this: some series diverge to infinity while others converge to a fixed value. Take the two classical examples: the harmonic series and the Basel Problem On one end, we have a divergent series, whereas on the other end, we have a convergent series, both series of which seem eerily similar, except for the square in the latter. A question I might raise would be: at what ""rate of growth"" (loosely speaking) does a series have to grow to tip over from the point of convergence to sudden, chaotic divergence? Yes, in Calculus, you learn about various convergence tests that allow one to test whether a given series is convergent, but I am wondering if there is a famous ""rate of growth"" that a series must ""exceed"" in order to indisputably diverge.","\displaystyle\sum_{n=1}^\infty \frac{1}{n}= \infty \, , \hspace{0.6cm} \displaystyle\sum_{n=1}^\infty\frac{1}{n^2} = \frac{\pi^2}{6}","['sequences-and-series', 'convergence-divergence']"
48,How to either prove or disprove if it is possible to arrange a series of numbers such the sum of any two adjacent number adds up to a prime number,How to either prove or disprove if it is possible to arrange a series of numbers such the sum of any two adjacent number adds up to a prime number,,"I'm wondering if it's possible to write a theorem to prove or disprove the possibility of arranging a sequence of numbers (1,2,...n) such that the sum of any two numbers adds up to a prime number. An Example: Input: Say n=7. The sequence is 1,2,3,4,5,6,7 Output: 7,6,5,2,1,4,3 Here are a few numbers where a program I wrote seems to fail for n=71 solution sequence: 36 37 52 61 18 19 54 55 58 45 56 11 26 27 44 53 60 67 6 7 10 13 30 31 48 49 64 3 4 15 16 21 22 25 28 33 34 39 40 43 46 51 62 65 66 71 2 5 8 9 14 17 20 23 24 29 32 35 38 41 42 47 50 63 68 69 70 1 12 59   But unable to fit: 57   n=50 solution sequence: 19 12 49 30 31 48 11 50 3 4 15 38 41 42 47 6 7 10 13 18 23 24 29 32 35 44 45 2 5 8 9 14 17 20 21 22 25 28 33 34 39 40 43 46 1 36  But unable to fit: 37 27 26 16 Successful attempts: n=17 3 4 7 10 13 6 11 12 17 2 5 8 9 14 15 16   n=25 23 24 19 12 11 18 25 6 7 10 13 16 3 4 15 2 5 8 9 14 17 20 21 22 1 Here is the program (very dirty I warn you!) I wrote to be able to generate the above output. Hint: Change max to the number you want and try it out.","I'm wondering if it's possible to write a theorem to prove or disprove the possibility of arranging a sequence of numbers (1,2,...n) such that the sum of any two numbers adds up to a prime number. An Example: Input: Say n=7. The sequence is 1,2,3,4,5,6,7 Output: 7,6,5,2,1,4,3 Here are a few numbers where a program I wrote seems to fail for n=71 solution sequence: 36 37 52 61 18 19 54 55 58 45 56 11 26 27 44 53 60 67 6 7 10 13 30 31 48 49 64 3 4 15 16 21 22 25 28 33 34 39 40 43 46 51 62 65 66 71 2 5 8 9 14 17 20 23 24 29 32 35 38 41 42 47 50 63 68 69 70 1 12 59   But unable to fit: 57   n=50 solution sequence: 19 12 49 30 31 48 11 50 3 4 15 38 41 42 47 6 7 10 13 18 23 24 29 32 35 44 45 2 5 8 9 14 17 20 21 22 25 28 33 34 39 40 43 46 1 36  But unable to fit: 37 27 26 16 Successful attempts: n=17 3 4 7 10 13 6 11 12 17 2 5 8 9 14 15 16   n=25 23 24 19 12 11 18 25 6 7 10 13 16 3 4 15 2 5 8 9 14 17 20 21 22 1 Here is the program (very dirty I warn you!) I wrote to be able to generate the above output. Hint: Change max to the number you want and try it out.",,"['sequences-and-series', 'prime-numbers', 'summation', 'primality-test']"
49,Mystery about $\sum_{n\geqslant 1}2^{-n!}$,Mystery about,\sum_{n\geqslant 1}2^{-n!},"I was playing with some series when Wolfram told me that  $$\sum_{n\geqslant 1}2^{-n!}=0.765625059604644775390625\color{Red}{000000000000}752316384526264\ldots$$ and my eyes obviously stopped at the red area. Twelve decimal places! Similarly, $$\begin{align} \sum_{n\geqslant 1}4^{-n!} &= 0.31274414(\cdots)1337890625\color{Red}{000000000000000000000000}565979\ldots \\ \sum_{n\geqslant 1}8^{-n!} &= 0.140628814(\cdots)625\color{Red}{000000000000000000000000000000000000}42579598\ldots \end{align}$$ where I omitted $30$ digits and $60$ digits respectively. Is it a coincidence or is there a deeper reason? Why are these numbers so well approximated?","I was playing with some series when Wolfram told me that  $$\sum_{n\geqslant 1}2^{-n!}=0.765625059604644775390625\color{Red}{000000000000}752316384526264\ldots$$ and my eyes obviously stopped at the red area. Twelve decimal places! Similarly, $$\begin{align} \sum_{n\geqslant 1}4^{-n!} &= 0.31274414(\cdots)1337890625\color{Red}{000000000000000000000000}565979\ldots \\ \sum_{n\geqslant 1}8^{-n!} &= 0.140628814(\cdots)625\color{Red}{000000000000000000000000000000000000}42579598\ldots \end{align}$$ where I omitted $30$ digits and $60$ digits respectively. Is it a coincidence or is there a deeper reason? Why are these numbers so well approximated?",,"['sequences-and-series', 'number-theory']"
50,On the general form of the family $\sum_{n=1}^\infty \frac{n^{k}}{e^{2n\pi}-1} $,On the general form of the family,\sum_{n=1}^\infty \frac{n^{k}}{e^{2n\pi}-1} ,"I. $k=4n+3.\;$ From this post , one knows that $$\sum_{n=1}^\infty \frac{n^{3}}{e^{2n\pi}-1} = \frac{\Gamma\big(\tfrac{1}{4}\big)^8}{2^{10}\cdot5\,\pi^6}-\frac{1}{240}$$ and a Mathematica session reveals $$\sum_{n=1}^\infty  \frac{n^{7}}{e^{2n\pi}-1} =\frac{3\,\Gamma\big(\tfrac{1}{4}\big)^{16}}{2^{17}\cdot5\,\pi^{12}}-\frac{1}{480}$$ $$\sum_{n=1}^\infty  \frac{n^{11}}{e^{2n\pi}-1} =\frac{189\,\Gamma\big(\tfrac{1}{4}\big)^{24}}{2^{22}\cdot5\cdot13\,\pi^{18}}-\frac{691}{65520}$$ and so on. The $691$ is a clue that Bernoulli numbers are involved. II. $k=4n+1.\;$ It evaluates to a rational number, $$\sum_{n=1}^\infty  \frac{n^{5}}{e^{2n\pi}-1} =\frac{1}{504}$$ $$\sum_{n=1}^\infty  \frac{n^{9}}{e^{2n\pi}-1} =\frac{1}{264}$$ $$\sum_{n=1}^\infty  \frac{n^{13}}{e^{2n\pi}-1} =\frac{1}{24}$$ etc, with the last mentioned in this post . Q: What are the general forms of I and II in terms of the Bernoulli numbers? (And a reference to Ramanujan's Notebooks, if possible.) (Note: 2019 edit to 2016 post) Since the $\Gamma(n)$ /pi ratio involved has a simple form in terms of the elliptic integral singular value $K(k_n)$ , turns out it was just the case $\tau=\sqrt{-1}$ , $$\beta_1=\frac{\Gamma\big(\tfrac14\big)^8}{2^8\pi^6}=\left(\frac{K(k_1)}{\pi}\right)^4$$ By analogy, the case $\tau=\sqrt{-3}$ , $$\color{red}{\beta_3}=\frac{3\Gamma\big(\tfrac13\big)^{12}}{2^9\cdot2^{1/3}\,\pi^8}=\left(\frac{K(k_3)}{\pi}\right)^4$$ So alternatively, $$\sum_{n=1}^\infty \frac{n^{3}}{e^{2\pi\,n}-1} = \frac1{20}\beta_1-\frac{1}{240}$$ $$\sum_{n=1}^\infty  \frac{n^{7}}{e^{2\pi\,n}-1} =\frac{3}{10}{\beta_1}^2-\frac{1}{480}$$ and a quick test showed, $$\sum_{n=1}^\infty \frac{n^{3}}{e^{2\pi\sqrt3\,n}-1} = \frac{1}{16}\color{red}{\beta_3}-\frac{1}{240}$$ $$\sum_{n=1}^\infty \frac{n^{7}}{e^{2\pi\sqrt3\,n}-1} = \frac{17}{32}\color{red}{{\beta_3}^2}-\frac{1}{480}$$ and so on.","I. From this post , one knows that and a Mathematica session reveals and so on. The is a clue that Bernoulli numbers are involved. II. It evaluates to a rational number, etc, with the last mentioned in this post . Q: What are the general forms of I and II in terms of the Bernoulli numbers? (And a reference to Ramanujan's Notebooks, if possible.) (Note: 2019 edit to 2016 post) Since the /pi ratio involved has a simple form in terms of the elliptic integral singular value , turns out it was just the case , By analogy, the case , So alternatively, and a quick test showed, and so on.","k=4n+3.\; \sum_{n=1}^\infty \frac{n^{3}}{e^{2n\pi}-1} = \frac{\Gamma\big(\tfrac{1}{4}\big)^8}{2^{10}\cdot5\,\pi^6}-\frac{1}{240} \sum_{n=1}^\infty  \frac{n^{7}}{e^{2n\pi}-1} =\frac{3\,\Gamma\big(\tfrac{1}{4}\big)^{16}}{2^{17}\cdot5\,\pi^{12}}-\frac{1}{480} \sum_{n=1}^\infty  \frac{n^{11}}{e^{2n\pi}-1} =\frac{189\,\Gamma\big(\tfrac{1}{4}\big)^{24}}{2^{22}\cdot5\cdot13\,\pi^{18}}-\frac{691}{65520} 691 k=4n+1.\; \sum_{n=1}^\infty  \frac{n^{5}}{e^{2n\pi}-1} =\frac{1}{504} \sum_{n=1}^\infty  \frac{n^{9}}{e^{2n\pi}-1} =\frac{1}{264} \sum_{n=1}^\infty  \frac{n^{13}}{e^{2n\pi}-1} =\frac{1}{24} \Gamma(n) K(k_n) \tau=\sqrt{-1} \beta_1=\frac{\Gamma\big(\tfrac14\big)^8}{2^8\pi^6}=\left(\frac{K(k_1)}{\pi}\right)^4 \tau=\sqrt{-3} \color{red}{\beta_3}=\frac{3\Gamma\big(\tfrac13\big)^{12}}{2^9\cdot2^{1/3}\,\pi^8}=\left(\frac{K(k_3)}{\pi}\right)^4 \sum_{n=1}^\infty \frac{n^{3}}{e^{2\pi\,n}-1} = \frac1{20}\beta_1-\frac{1}{240} \sum_{n=1}^\infty  \frac{n^{7}}{e^{2\pi\,n}-1} =\frac{3}{10}{\beta_1}^2-\frac{1}{480} \sum_{n=1}^\infty \frac{n^{3}}{e^{2\pi\sqrt3\,n}-1} = \frac{1}{16}\color{red}{\beta_3}-\frac{1}{240} \sum_{n=1}^\infty \frac{n^{7}}{e^{2\pi\sqrt3\,n}-1} = \frac{17}{32}\color{red}{{\beta_3}^2}-\frac{1}{480}","['sequences-and-series', 'closed-form', 'gamma-function', 'bernoulli-numbers']"
51,How to calculate: $\sum_{n=1}^{\infty} n a^n$ [duplicate],How to calculate:  [duplicate],\sum_{n=1}^{\infty} n a^n,"This question already has answers here : How can I evaluate $\sum_{n=0}^\infty(n+1)x^n$? (24 answers) Closed 11 years ago . I've tried to calculate this sum: $$\sum_{n=1}^{\infty} n a^n$$ The point of this is to try to work out the ""mean"" term in an exponentially decaying average. I've done the following: $$\text{let }x = \sum_{n=1}^{\infty} n a^n$$ $$x = a + a \sum_{n=1}^{\infty} (n+1) a^n$$ $$x = a + a (\sum_{n=1}^{\infty} n a^n + \sum_{n=1}^{\infty} a^n)$$ $$x = a + a (x + \sum_{n=1}^{\infty} a^n)$$ $$x = a + ax + a\sum_{n=1}^{\infty} a^n$$ $$(1-a)x = a + a\sum_{n=1}^{\infty} a^n$$ Lets try to work out the $\sum_{n=1}^{\infty} a^n$ part: $$let y = \sum_{n=1}^{\infty} a^n$$ $$y = a + a \sum_{n=1}^{\infty} a^n$$ $$y = a + ay$$ $$y - ay = a$$ $$y(1-a) = a$$ $$y = a/(1-a)$$ Substitute y back in: $$(1-a)x = a + a*(a/(1-a))$$ $$(1-a)^2 x = a(1-a) + a^2$$ $$(1-a)^2 x = a - a^2 + a^2$$ $$(1-a)^2 x = a$$ $$x = a/(1-a)^2$$ Is this right, and if so is there a shorter way? Edit: To actually calculate the ""mean"" term of a exponential moving average we need to keep in mind that terms are weighted at the level of $(1-a)$. i.e. for $a=1$ there is no decay, for $a=0$ only the most recent term counts. So the above result we need to multiply by $(1-a)$ to get the result: Exponential moving average ""mean term"" = $a/(1-a)$ This gives the results, for $a=0$, the mean term is the ""0th term"" (none other are used) whereas for $a=0.5$ the mean term is the ""1st term"" (i.e. after the current term).","This question already has answers here : How can I evaluate $\sum_{n=0}^\infty(n+1)x^n$? (24 answers) Closed 11 years ago . I've tried to calculate this sum: $$\sum_{n=1}^{\infty} n a^n$$ The point of this is to try to work out the ""mean"" term in an exponentially decaying average. I've done the following: $$\text{let }x = \sum_{n=1}^{\infty} n a^n$$ $$x = a + a \sum_{n=1}^{\infty} (n+1) a^n$$ $$x = a + a (\sum_{n=1}^{\infty} n a^n + \sum_{n=1}^{\infty} a^n)$$ $$x = a + a (x + \sum_{n=1}^{\infty} a^n)$$ $$x = a + ax + a\sum_{n=1}^{\infty} a^n$$ $$(1-a)x = a + a\sum_{n=1}^{\infty} a^n$$ Lets try to work out the $\sum_{n=1}^{\infty} a^n$ part: $$let y = \sum_{n=1}^{\infty} a^n$$ $$y = a + a \sum_{n=1}^{\infty} a^n$$ $$y = a + ay$$ $$y - ay = a$$ $$y(1-a) = a$$ $$y = a/(1-a)$$ Substitute y back in: $$(1-a)x = a + a*(a/(1-a))$$ $$(1-a)^2 x = a(1-a) + a^2$$ $$(1-a)^2 x = a - a^2 + a^2$$ $$(1-a)^2 x = a$$ $$x = a/(1-a)^2$$ Is this right, and if so is there a shorter way? Edit: To actually calculate the ""mean"" term of a exponential moving average we need to keep in mind that terms are weighted at the level of $(1-a)$. i.e. for $a=1$ there is no decay, for $a=0$ only the most recent term counts. So the above result we need to multiply by $(1-a)$ to get the result: Exponential moving average ""mean term"" = $a/(1-a)$ This gives the results, for $a=0$, the mean term is the ""0th term"" (none other are used) whereas for $a=0.5$ the mean term is the ""1st term"" (i.e. after the current term).",,['sequences-and-series']
52,Can you use the sum formula for a geometric series starting at any point?,Can you use the sum formula for a geometric series starting at any point?,,"Wherever I see the sum of a infinite geometric series with $|r|<1$ being derived the series always starts at $n = 0$, or $n = 1$, the basic form is $$a + ar + ar^2 + ar^3 + ... $$ And the sum is $\frac{a}{1-r}$ Does that still apply for a geometric series that starts at say n = 101, so $$ar^{100} + ar^{101} + ar^{102} +... $$","Wherever I see the sum of a infinite geometric series with $|r|<1$ being derived the series always starts at $n = 0$, or $n = 1$, the basic form is $$a + ar + ar^2 + ar^3 + ... $$ And the sum is $\frac{a}{1-r}$ Does that still apply for a geometric series that starts at say n = 101, so $$ar^{100} + ar^{101} + ar^{102} +... $$",,['sequences-and-series']
53,Sum of Harmonic numbers $\sum\limits_{n=1}^{\infty} \frac{H_n^{(2)}}{2^nn^2}$,Sum of Harmonic numbers,\sum\limits_{n=1}^{\infty} \frac{H_n^{(2)}}{2^nn^2},"Finding the closed form of: $$\sum\limits_{n=1}^{\infty} \frac{H_n^{(2)}}{2^nn^2}$$ where, $\displaystyle H_n^{(2)} = \sum\limits_{k=1}^{n}\frac{1}{k^2}$ It appears when we try to determine the summation $\displaystyle \sum_{n=1}^\infty\frac{H_n}{n^3\,2^n}$, using the generating function: \begin{align} \sum_{n=1}^{\infty} \frac{H_n}{n^3} \, x^{n} &= - \frac{1}{2} \, \sum_{n=1}^{\infty}\frac{1}{n^2} \, \sum_{k=1}^{n} \frac{(1-x)^k}{k^2} - \frac{\zeta(2)}{2} \, \operatorname{Li}_2(x) + \frac{7 \, \zeta(4)}{8} - \frac{1}{4} \, \operatorname{Li}_2^2(1-x) + \frac{\zeta^2(2)}{4} + \operatorname{Li}_4(x) \\ & \hspace{5mm} + \frac{1}{4} \, \log^2 x \, \log^2(1-x) + \frac{1}{2}\log x \, \log (1-x) \, \operatorname{Li}_2(1-x) + \zeta(3) \, \log x - \log x \,  \operatorname{Li}_2(1-x) \end{align} when we write, $\displaystyle \sum\limits_{n=1}^{\infty}\frac{1}{n^2}\sum\limits_{k=1}^{n}\frac{(1-x)^k}{k^2} = \zeta(2)\operatorname{Li}_2(1-x) + \operatorname{Li}_4(1-x) - \sum\limits_{n=1}^{\infty} \frac{H_n^{(2)}}{n^2}(1-x)^n$ Combined with Cleo's closed form here , I know what the closed form should be, but how do I derive the result ?","Finding the closed form of: $$\sum\limits_{n=1}^{\infty} \frac{H_n^{(2)}}{2^nn^2}$$ where, $\displaystyle H_n^{(2)} = \sum\limits_{k=1}^{n}\frac{1}{k^2}$ It appears when we try to determine the summation $\displaystyle \sum_{n=1}^\infty\frac{H_n}{n^3\,2^n}$, using the generating function: \begin{align} \sum_{n=1}^{\infty} \frac{H_n}{n^3} \, x^{n} &= - \frac{1}{2} \, \sum_{n=1}^{\infty}\frac{1}{n^2} \, \sum_{k=1}^{n} \frac{(1-x)^k}{k^2} - \frac{\zeta(2)}{2} \, \operatorname{Li}_2(x) + \frac{7 \, \zeta(4)}{8} - \frac{1}{4} \, \operatorname{Li}_2^2(1-x) + \frac{\zeta^2(2)}{4} + \operatorname{Li}_4(x) \\ & \hspace{5mm} + \frac{1}{4} \, \log^2 x \, \log^2(1-x) + \frac{1}{2}\log x \, \log (1-x) \, \operatorname{Li}_2(1-x) + \zeta(3) \, \log x - \log x \,  \operatorname{Li}_2(1-x) \end{align} when we write, $\displaystyle \sum\limits_{n=1}^{\infty}\frac{1}{n^2}\sum\limits_{k=1}^{n}\frac{(1-x)^k}{k^2} = \zeta(2)\operatorname{Li}_2(1-x) + \operatorname{Li}_4(1-x) - \sum\limits_{n=1}^{\infty} \frac{H_n^{(2)}}{n^2}(1-x)^n$ Combined with Cleo's closed form here , I know what the closed form should be, but how do I derive the result ?",,"['sequences-and-series', 'closed-form', 'harmonic-numbers']"
54,"What is the relationship between 1/7, 1/11, 1/13, and the number 1001?","What is the relationship between 1/7, 1/11, 1/13, and the number 1001?",,"Here is what we have: 1/7 = 0.142857... 1/11 = 0.090909... 1/13 = 0.076923... Notice that if you add the first three digits to the next three digits, you always get 999: 142 + 857 = 999 090 + 909 = 999 076 + 923 = 999 Oddly, the same thing happens with 2/7 , 2/11 , 2/13 , and so on, as the numerator increases: adding the first three digits to the next three digit results in 999. OK. Multiplying the denominators 7 x 11 x 13 results in 1001. What is the relationship between the fraction series x/7, x/11, x/13 , and the result of multiplying the denominators? (This is taken from an example in the book ""Ten Ways to Destroy the Imagination of Your Child"" by Anthony Esolen . The examples above are presented separately, and the reader is encouraged to be imaginative in discovering how they are related. After almost 20 years of playing math/CS games, I suppose I still have no imagination to solve this kind of thing.)","Here is what we have: 1/7 = 0.142857... 1/11 = 0.090909... 1/13 = 0.076923... Notice that if you add the first three digits to the next three digits, you always get 999: 142 + 857 = 999 090 + 909 = 999 076 + 923 = 999 Oddly, the same thing happens with 2/7 , 2/11 , 2/13 , and so on, as the numerator increases: adding the first three digits to the next three digit results in 999. OK. Multiplying the denominators 7 x 11 x 13 results in 1001. What is the relationship between the fraction series x/7, x/11, x/13 , and the result of multiplying the denominators? (This is taken from an example in the book ""Ten Ways to Destroy the Imagination of Your Child"" by Anthony Esolen . The examples above are presented separately, and the reader is encouraged to be imaginative in discovering how they are related. After almost 20 years of playing math/CS games, I suppose I still have no imagination to solve this kind of thing.)",,"['sequences-and-series', 'recreational-mathematics', 'puzzle']"
55,Does $\sum_{n=1}^\infty \frac{\cos{(\sqrt{n})}}{n}$ converge?,Does  converge?,\sum_{n=1}^\infty \frac{\cos{(\sqrt{n})}}{n},"The series is: $$\sum_{n=1}^\infty \frac{\cos(\sqrt{n})}{n}$$ Considering it isn't always positive, I replace $\frac{\cos{\sqrt{n}}}{n}$ with its absolute value and I find that: $$\vert \frac{\cos{\sqrt{n}}}{n}\vert\gt \frac{\cos^2{\sqrt{n}}}{n}=\frac{\ 1+\cos{2\sqrt{n}}}{2n}=\frac{1}{2n}+\frac{\cos{2\sqrt{n}}}{2n}$$ if $\sum_{n=1}^\infty \vert\frac{\cos{\sqrt{n}}}{n}\vert $ converges, then $\sum_{n=1}^\infty \frac{\cos{\sqrt{n}}}{n}$ converges.Using Comparison test,we can draw the conclusion that $\sum_{n=1}^\infty\frac{1}{2n}$ converges , which is impossible. So I get that $\sum_{n=1}^\infty \frac{\cos{\sqrt{n}}}{n}$ absolutely diverges. But I can't figure out whether $\sum_{n=1}^\infty \frac{\cos{\sqrt{n}}}{n}$ converges or not. I have tried Dirichlet's test, but I can't figure out whether $$S_{n}=\sum_{k=1}^n \cos{\sqrt{k}}$$ is bounded. (This is my first time to ask question.Maybe there exist some mistakes in my conclusion.Thanks. :)","The series is: Considering it isn't always positive, I replace with its absolute value and I find that: if converges, then converges.Using Comparison test,we can draw the conclusion that converges , which is impossible. So I get that absolutely diverges. But I can't figure out whether converges or not. I have tried Dirichlet's test, but I can't figure out whether is bounded. (This is my first time to ask question.Maybe there exist some mistakes in my conclusion.Thanks. :)",\sum_{n=1}^\infty \frac{\cos(\sqrt{n})}{n} \frac{\cos{\sqrt{n}}}{n} \vert \frac{\cos{\sqrt{n}}}{n}\vert\gt \frac{\cos^2{\sqrt{n}}}{n}=\frac{\ 1+\cos{2\sqrt{n}}}{2n}=\frac{1}{2n}+\frac{\cos{2\sqrt{n}}}{2n} \sum_{n=1}^\infty \vert\frac{\cos{\sqrt{n}}}{n}\vert  \sum_{n=1}^\infty \frac{\cos{\sqrt{n}}}{n} \sum_{n=1}^\infty\frac{1}{2n} \sum_{n=1}^\infty \frac{\cos{\sqrt{n}}}{n} \sum_{n=1}^\infty \frac{\cos{\sqrt{n}}}{n} S_{n}=\sum_{k=1}^n \cos{\sqrt{k}},"['sequences-and-series', 'analysis', 'trigonometry']"
56,Series of logarithms $\sum\limits_{k=1}^\infty \ln(k)$ (Ramanujan summation?),Series of logarithms  (Ramanujan summation?),\sum\limits_{k=1}^\infty \ln(k),"I had this question earlier, so to say as a ""standalone"" problem, but now it pops up in context of an analysis with the lngamma -function. As well as we can convert the question of sums of like powers $Su_p(n)=1^p+2^p+3^p+\cdots+n^p$ in terms of the Hurwitz-zeta $Su_p(n) = \zeta(p,1)-\zeta(p,n+1)$ (and solve using the Bernoulli-polynomials) I try to express this for sums of logarithms (and powers of logarithms) : $$ Sl_p(n) = \ln(1)^p+\ln(2)^p+\cdots+\ln(n)^p $$ I have seemingly proper coefficients for power series which allow that computations/approximations. The result is always found by the difference of $ Sl_p(n)-Sl_p(1) $ . Here the power series has zero as constant term. However, to have the analogue to the Hurwitz-zeta I should have the constant term the ""value"" for the infinite sum $ Sl_p(\infty) $ instead. (This cancels properly if I formulate the sum of (powers of) logarithms always as that difference $ Sl_p(n)-Sl_p(1) $) And also, I'd like that this agreed conceptually more to the notion: $$ \begin{array} {rll} Sl_p(n)-Sl_p(1) &=& T_p(0)-T_p(n) \\\  & =&  (\ln(1)+\ln(2)+\ln(3)+\cdots) \\\   & & - (\ln(n+1)+\ln(n+2)+\ln(n+2)+\cdots) \end{array} $$ as this agrees more with the idea of the Hurwitz-zeta-difference. But this requires, that $T_p(0)$ represents the (infinite) sum of the $p$'th powers of the logarithms, and the constant in the power series of $T_p(0)$ must contain just such a value. Let's talk about the first powers of the logs $p=1 $ first and denote the assumed sum as $L_1$ : $ L_1 = \lim_{n\to \infty} T_1(0) $ [update 2] I think, thanks to the hint of J.M., I can answer Q1 myself now; only Q2 remains somehow vague - besides a simple empirical heuristic I did still not get the formally correct approach to the constant term/integral-definition in the Ramanujan summation - but this is now only a side problem here (however it would be nice to get help also for this question). With the help of the knowledge about the derivatives of the zeta at zero the relevant part of the problem could now satisfyingly be solved, so I put it here in an answer to my own question, see that answer below.... Final remark/conclusion: it is interesting, that the power series for the lngamma pops up here ""automatically"" - we need no other uniqueness criterion for the argument, that the (Eulerian) gamma-function gives ""the correct"" interpolation for the factorial problem. It is just the result of the construction of an operator for the ""indefinite summation"" (which was the comceptual goal from where the problem/question arose initially) In the following I keep the rest of the original question although the approach to the Ramanujan summation contains an error [end Update 2] I tried to give sense to that divergent series by replacing the powers of $x$ in the Mercator series for $ \ln(1+x) $ by appropriate zetas at negative integer arguments. If I understand things correctly then this is similar to the method of Ramanujan summation, where the Bernoulli numbers are just replaced by the according zeta-values (appropriately scaled). With this I got then an approximation of $$L_1 \approx -0.0810614667953 $$ which seems a rather ""random"" value... By searching in other online sources I got the suggestion ( OEIS ), that this is also $$ \int_1^2 \ln(\Gamma(t)) \; dt \approx -0.08106146679532725821967026 $$ With this my power series for $T_1(x)$ begins like $ \qquad \small \begin{array} {l}  - & 0.0810614667953 \\  - & 0.577215664902x \\  + & 0.533859200973x^2 \\  + & 0.325578788221x^3 \\  + & 0.125274140308x^4 \\  + & 0.0337256506589x^5 \\  + & 0.00685935357296x^6 \\  + & 0.00117260810356x^7 \\  + & O(x^8)  \end{array}  $ The other coefficients occur also in the power series for $f(x)=\ln(\Gamma(\exp(x)) $ Also, $L_1$ seem to satisfy the following expression:  $$ \exp(L_1) = {\sqrt{(2\pi)} \over e} \approx 0.9221370088957891168791517 $$ The questions are: $\qquad$ Q1 : Is that value $-0.0801\ldots$ a meaningful (or even correct) representation for the infinite sum of logarithms? $\qquad$ Q2 : Did I reproduce the Ramanujan summation correctly here? [update 1] : J.M. mentions the relation to $ y= - \zeta'(0) \approx 0.918938533205 $ where the representation of the derivative of zeta at 0 equals formally just the sum of logarithms. Now my $L_1$ and the $y$ are related by $L_1 = y - 1$. So I expect some error in my derivation which leads just to that unit difference...","I had this question earlier, so to say as a ""standalone"" problem, but now it pops up in context of an analysis with the lngamma -function. As well as we can convert the question of sums of like powers $Su_p(n)=1^p+2^p+3^p+\cdots+n^p$ in terms of the Hurwitz-zeta $Su_p(n) = \zeta(p,1)-\zeta(p,n+1)$ (and solve using the Bernoulli-polynomials) I try to express this for sums of logarithms (and powers of logarithms) : $$ Sl_p(n) = \ln(1)^p+\ln(2)^p+\cdots+\ln(n)^p $$ I have seemingly proper coefficients for power series which allow that computations/approximations. The result is always found by the difference of $ Sl_p(n)-Sl_p(1) $ . Here the power series has zero as constant term. However, to have the analogue to the Hurwitz-zeta I should have the constant term the ""value"" for the infinite sum $ Sl_p(\infty) $ instead. (This cancels properly if I formulate the sum of (powers of) logarithms always as that difference $ Sl_p(n)-Sl_p(1) $) And also, I'd like that this agreed conceptually more to the notion: $$ \begin{array} {rll} Sl_p(n)-Sl_p(1) &=& T_p(0)-T_p(n) \\\  & =&  (\ln(1)+\ln(2)+\ln(3)+\cdots) \\\   & & - (\ln(n+1)+\ln(n+2)+\ln(n+2)+\cdots) \end{array} $$ as this agrees more with the idea of the Hurwitz-zeta-difference. But this requires, that $T_p(0)$ represents the (infinite) sum of the $p$'th powers of the logarithms, and the constant in the power series of $T_p(0)$ must contain just such a value. Let's talk about the first powers of the logs $p=1 $ first and denote the assumed sum as $L_1$ : $ L_1 = \lim_{n\to \infty} T_1(0) $ [update 2] I think, thanks to the hint of J.M., I can answer Q1 myself now; only Q2 remains somehow vague - besides a simple empirical heuristic I did still not get the formally correct approach to the constant term/integral-definition in the Ramanujan summation - but this is now only a side problem here (however it would be nice to get help also for this question). With the help of the knowledge about the derivatives of the zeta at zero the relevant part of the problem could now satisfyingly be solved, so I put it here in an answer to my own question, see that answer below.... Final remark/conclusion: it is interesting, that the power series for the lngamma pops up here ""automatically"" - we need no other uniqueness criterion for the argument, that the (Eulerian) gamma-function gives ""the correct"" interpolation for the factorial problem. It is just the result of the construction of an operator for the ""indefinite summation"" (which was the comceptual goal from where the problem/question arose initially) In the following I keep the rest of the original question although the approach to the Ramanujan summation contains an error [end Update 2] I tried to give sense to that divergent series by replacing the powers of $x$ in the Mercator series for $ \ln(1+x) $ by appropriate zetas at negative integer arguments. If I understand things correctly then this is similar to the method of Ramanujan summation, where the Bernoulli numbers are just replaced by the according zeta-values (appropriately scaled). With this I got then an approximation of $$L_1 \approx -0.0810614667953 $$ which seems a rather ""random"" value... By searching in other online sources I got the suggestion ( OEIS ), that this is also $$ \int_1^2 \ln(\Gamma(t)) \; dt \approx -0.08106146679532725821967026 $$ With this my power series for $T_1(x)$ begins like $ \qquad \small \begin{array} {l}  - & 0.0810614667953 \\  - & 0.577215664902x \\  + & 0.533859200973x^2 \\  + & 0.325578788221x^3 \\  + & 0.125274140308x^4 \\  + & 0.0337256506589x^5 \\  + & 0.00685935357296x^6 \\  + & 0.00117260810356x^7 \\  + & O(x^8)  \end{array}  $ The other coefficients occur also in the power series for $f(x)=\ln(\Gamma(\exp(x)) $ Also, $L_1$ seem to satisfy the following expression:  $$ \exp(L_1) = {\sqrt{(2\pi)} \over e} \approx 0.9221370088957891168791517 $$ The questions are: $\qquad$ Q1 : Is that value $-0.0801\ldots$ a meaningful (or even correct) representation for the infinite sum of logarithms? $\qquad$ Q2 : Did I reproduce the Ramanujan summation correctly here? [update 1] : J.M. mentions the relation to $ y= - \zeta'(0) \approx 0.918938533205 $ where the representation of the derivative of zeta at 0 equals formally just the sum of logarithms. Now my $L_1$ and the $y$ are related by $L_1 = y - 1$. So I expect some error in my derivation which leads just to that unit difference...",,"['sequences-and-series', 'special-functions', 'logarithms', 'divergent-series']"
57,Rigorous proof that $\frac{1}{3} = 0.333\ldots$,Rigorous proof that,\frac{1}{3} = 0.333\ldots,"I'm a PreCalculus student trying to find a rigorous proof that $\displaystyle\frac{1}{3} = 0.333\ldots$, but I couldn't find it. I think (just think) that this proof would start by proving that $\displaystyle\sum_{i=1}^{\infty}3\cdot10^{-i} = \frac{1}{3}$. My guesses (assuming that proving that $\displaystyle\sum_{i=1}^{\infty}\left(\frac{1}{10}\right)^i$ converges is trivial): $\displaystyle\sum_{i=1}^{\infty}3\cdot10^{-i} = 3\cdot\sum_{i = 1}^{\infty}10^{-i} = 3\cdot\sum_{i=1}^{\infty}\left(\frac{1}{10}\right)^i = 3\cdot\left(\frac{1}{1 - \frac{1}{10}}-1\right) = 3\cdot\left(\frac{10}{9}-1\right) = \frac{1}{3}$. Questions: is this completely rigorous? Which flaws could be found in this proof? How can I improve it? PS. I'm not sure how to tag this. Feel free to edit, if necessary.","I'm a PreCalculus student trying to find a rigorous proof that $\displaystyle\frac{1}{3} = 0.333\ldots$, but I couldn't find it. I think (just think) that this proof would start by proving that $\displaystyle\sum_{i=1}^{\infty}3\cdot10^{-i} = \frac{1}{3}$. My guesses (assuming that proving that $\displaystyle\sum_{i=1}^{\infty}\left(\frac{1}{10}\right)^i$ converges is trivial): $\displaystyle\sum_{i=1}^{\infty}3\cdot10^{-i} = 3\cdot\sum_{i = 1}^{\infty}10^{-i} = 3\cdot\sum_{i=1}^{\infty}\left(\frac{1}{10}\right)^i = 3\cdot\left(\frac{1}{1 - \frac{1}{10}}-1\right) = 3\cdot\left(\frac{10}{9}-1\right) = \frac{1}{3}$. Questions: is this completely rigorous? Which flaws could be found in this proof? How can I improve it? PS. I'm not sure how to tag this. Feel free to edit, if necessary.",,"['algebra-precalculus', 'sequences-and-series']"
58,How can I prove my conjecture for the coefficients in $t(x)=\log(1+\exp(x)) $?,How can I prove my conjecture for the coefficients in ?,t(x)=\log(1+\exp(x)) ,"I'm considering the transfer-function $$ t(x) = \log(1 + \exp(x)) $$ and find the beginning of the power series (simply using Pari/GP) as $$ t(x) = \log(2) + 1/2 x + 1/8 x^2 – 1/192 x^4 + 1/2880 x^6 - \ldots $$ Examining the pattern of the coefficients I find the much likely composition $$ t(x) = \sum_{k=0}^\infty {\eta(1-k) \over k! }x^k $$ where $ \eta() $ is the Dirichlet eta-(or ""alternating zeta"") function. I'm using this definition in further computations and besides the convincing simplicitiness of the pattern the results are always meaningful. However, I've no idea how I could prove this description of the coefficients. Q: Does someone has a source or an idea, how to do such a proof on oneself?","I'm considering the transfer-function $$ t(x) = \log(1 + \exp(x)) $$ and find the beginning of the power series (simply using Pari/GP) as $$ t(x) = \log(2) + 1/2 x + 1/8 x^2 – 1/192 x^4 + 1/2880 x^6 - \ldots $$ Examining the pattern of the coefficients I find the much likely composition $$ t(x) = \sum_{k=0}^\infty {\eta(1-k) \over k! }x^k $$ where $ \eta() $ is the Dirichlet eta-(or ""alternating zeta"") function. I'm using this definition in further computations and besides the convincing simplicitiness of the pattern the results are always meaningful. However, I've no idea how I could prove this description of the coefficients. Q: Does someone has a source or an idea, how to do such a proof on oneself?",,"['sequences-and-series', 'number-theory', 'reference-request', 'dirichlet-series']"
59,Why can't $\sqrt{2}^{\sqrt{2}{^\sqrt{2}{^\cdots}}}>2$?,Why can't ?,\sqrt{2}^{\sqrt{2}{^\sqrt{2}{^\cdots}}}>2,"So we have$$\sqrt{2}^{\sqrt{2}{^\sqrt{2}{^\cdots}}}=x\\\sqrt{2}^x=x$$where $x=2$ heuristically seems like a good solution. However, $x=4$ seems like an equally good solution. I was told in passing that $x$ was bounded at $2$, but I'm not sure how to show this. Update It would seem that the crux of this problem is whether the sequence $a_n$ converges or diverges, where $a_0=1$ and $a_{n+1}=\sqrt{2}^{a_n}$.","So we have$$\sqrt{2}^{\sqrt{2}{^\sqrt{2}{^\cdots}}}=x\\\sqrt{2}^x=x$$where $x=2$ heuristically seems like a good solution. However, $x=4$ seems like an equally good solution. I was told in passing that $x$ was bounded at $2$, but I'm not sure how to show this. Update It would seem that the crux of this problem is whether the sequence $a_n$ converges or diverges, where $a_0=1$ and $a_{n+1}=\sqrt{2}^{a_n}$.",,"['sequences-and-series', 'analysis', 'limits', 'convergence-divergence']"
60,"Intuitively, why is the Euler-Mascheroni constant near $\sqrt{1/3}$?","Intuitively, why is the Euler-Mascheroni constant near ?",\sqrt{1/3},"Questions that ask for ""intuitive"" reasons are admittedly subjective, but I suspect some people will find this interesting. Some time ago, I was struck by the coincidence that the Euler-Mascheroni constant $\gamma$ is close to the square root of $1/3$ . (Their numerical values are about $0.57722$ and $0.57735$ respectively.) Is there any informal or intuitive reason for this? For example, can we find a series converging to $\gamma$ and a series converging to $\sqrt{1/3}$ whose terms are close to each other? An example of the kind of argument I have in mind can be found in Noam Elkies' list of one-page papers , where he gives a ""reason"" that $\pi$ is slightly less than $\sqrt{10}$ . (Essentially, take $\sum\frac1{n^2}=\pi^2/6$ as known, and then bound that series above by a telescoping series whose sum is $10/6$ .) There are lots of ways to get series that converge quickly to $\sqrt{1/3}$ . For example, taking advantage of the fact that $(4/7)^2\approx1/3$ , we can write $$ \sqrt{\frac{1}{3}}=(\frac{16}{48})^{1/2} =(\frac{16}{49}\cdot\frac{49}{48})^{1/2}=\frac{4}{7}(1+\frac{1}{48})^{1/2} $$ which we can expand as a binomial series, so $\frac{4}{7}\cdot\frac{97}{96}$ is an example of a good approximation to $\sqrt{1/3}$ . Can we also get good approximations to $\gamma$ by using series that converge quickly, and can we find the ""right"" pair of series that shows ""why"" $\gamma$ is slightly less than $\sqrt{1/3}$ ? Another type of argument that's out there , showing ""why"" $\pi$ is slightly less than $22/7$ , involves a particular definite integral of a ""small"" function that evaluates to $\frac{22}{7}-\pi$ . So, are there any definite integrals of ""small"" functions that evaluate to $\sqrt{\frac13}-\gamma$ or $\frac13-\gamma^2$ ?","Questions that ask for ""intuitive"" reasons are admittedly subjective, but I suspect some people will find this interesting. Some time ago, I was struck by the coincidence that the Euler-Mascheroni constant is close to the square root of . (Their numerical values are about and respectively.) Is there any informal or intuitive reason for this? For example, can we find a series converging to and a series converging to whose terms are close to each other? An example of the kind of argument I have in mind can be found in Noam Elkies' list of one-page papers , where he gives a ""reason"" that is slightly less than . (Essentially, take as known, and then bound that series above by a telescoping series whose sum is .) There are lots of ways to get series that converge quickly to . For example, taking advantage of the fact that , we can write which we can expand as a binomial series, so is an example of a good approximation to . Can we also get good approximations to by using series that converge quickly, and can we find the ""right"" pair of series that shows ""why"" is slightly less than ? Another type of argument that's out there , showing ""why"" is slightly less than , involves a particular definite integral of a ""small"" function that evaluates to . So, are there any definite integrals of ""small"" functions that evaluate to or ?","\gamma 1/3 0.57722 0.57735 \gamma \sqrt{1/3} \pi \sqrt{10} \sum\frac1{n^2}=\pi^2/6 10/6 \sqrt{1/3} (4/7)^2\approx1/3 
\sqrt{\frac{1}{3}}=(\frac{16}{48})^{1/2}
=(\frac{16}{49}\cdot\frac{49}{48})^{1/2}=\frac{4}{7}(1+\frac{1}{48})^{1/2}
 \frac{4}{7}\cdot\frac{97}{96} \sqrt{1/3} \gamma \gamma \sqrt{1/3} \pi 22/7 \frac{22}{7}-\pi \sqrt{\frac13}-\gamma \frac13-\gamma^2","['sequences-and-series', 'number-theory', 'approximation', 'euler-mascheroni-constant']"
61,Sequences where $\sum\limits_{n=k}^{\infty}{a_n}=\sum\limits_{n=k}^{\infty}{a_n^2}$,Sequences where,\sum\limits_{n=k}^{\infty}{a_n}=\sum\limits_{n=k}^{\infty}{a_n^2},"I was recently looking at the series $\sum_{n=1}^{\infty}{\sin{n}\over{n}}$ , for which the value quite cleanly comes out to be ${1\over2}(\pi-1)$ , which is a rather cool closed form. I then wondered what would happen to the value of the series if all the terms in the series were squared. Turns out... nothing happens! $\displaystyle\sum_{n=1}^{\infty}{\left({\sin{n}\over{n}}\right)}^2=\sum_{n=1}^{\infty}{\sin{n}\over{n}}={1\over2}(\pi-1)$ . This is a rather cool result, and I was wondering if there are any other simple series that share this property? Or, more generalized, series for which raising the terms to the power $m$ yields the same result as raising them to the power $p$ .","I was recently looking at the series , for which the value quite cleanly comes out to be , which is a rather cool closed form. I then wondered what would happen to the value of the series if all the terms in the series were squared. Turns out... nothing happens! . This is a rather cool result, and I was wondering if there are any other simple series that share this property? Or, more generalized, series for which raising the terms to the power yields the same result as raising them to the power .",\sum_{n=1}^{\infty}{\sin{n}\over{n}} {1\over2}(\pi-1) \displaystyle\sum_{n=1}^{\infty}{\left({\sin{n}\over{n}}\right)}^2=\sum_{n=1}^{\infty}{\sin{n}\over{n}}={1\over2}(\pi-1) m p,"['sequences-and-series', 'trigonometry', 'square-numbers', 'sums-of-squares']"
62,"Does $\sum_{n=1}^\infty n^{-1-|\sin n|^a}$ converge for some $a\in(0,1)$?",Does  converge for some ?,"\sum_{n=1}^\infty n^{-1-|\sin n|^a} a\in(0,1)","The divergence of the series $\sum_{n=1}^\infty n^{-1-|\sin n|}$ is proved here . An inmediate consequence is that if $a\ge1$ then $\sum_{n=1}^\infty n^{-1-|\sin n|^a}$ also diverges. My question is: is there some $a\in(0,1)$ such that $$ \sum_{n=1}^\infty \frac{1}{n^{1+|\sin n|^a}}<\infty? $$ I have tried to adapt the proof given in the above link, but I have been unable to do it.  On the other hand, it can be adapted to prove that $$ \sum_{n=1}^\infty \frac{1}{n^{1+b|\sin n|}}=\infty\quad\forall b>0. $$","The divergence of the series $\sum_{n=1}^\infty n^{-1-|\sin n|}$ is proved here . An inmediate consequence is that if $a\ge1$ then $\sum_{n=1}^\infty n^{-1-|\sin n|^a}$ also diverges. My question is: is there some $a\in(0,1)$ such that $$ \sum_{n=1}^\infty \frac{1}{n^{1+|\sin n|^a}}<\infty? $$ I have tried to adapt the proof given in the above link, but I have been unable to do it.  On the other hand, it can be adapted to prove that $$ \sum_{n=1}^\infty \frac{1}{n^{1+b|\sin n|}}=\infty\quad\forall b>0. $$",,"['sequences-and-series', 'convergence-divergence']"
63,Alternating Harmonic Series Spin-off,Alternating Harmonic Series Spin-off,,"We know that the series $\sum (-1)^n/n$ converges, and clearly every other alternating harmonic series with the sign changing every two or more terms such as $$\left(1+\frac{1}{2}+\frac{1}{3}\right)-\left(\frac{1}{4}+\frac{1}{5}+\frac{1}{6}\right)+\left(\frac{1}{7}+\frac{1}{8}+\frac{1}{9}\right)-\cdots$$ must converge. My question here is that does the series below also converge? $$\sum\frac{\textrm{sgn}(\sin(n))}{n}\quad\textrm{or}\quad\sum\frac{\sin(n)}{n|\sin(n)|}$$ Loosely speaking, the sign changes every $\pi$ terms. I'd be surprised if it doesn't converge. Wolfram Mathematica, after a couple of minutes of computing, concluded the series diverges but I can't really trust it. My first approach (assuming the series converges) was that if we bundle up terms with the same sign like the example above every bundle must have three or four terms, and since the first three terms of all bundles make an alternating series I was going to fiddle with the remaining fourth terms but they don't make an alternating series so I guess there's no point in this approach. edit: I don't think we can use Dirichlet's test with $$b_n=\textrm{sgn}(\sin(n)).$$ The alternating cycle here is $\pi$ and I don't believe it would bound the series. For example if the cycle was a number very slightly smaller than $3+1/4$ , then $B_n$ (sum of $b_n$ ) would get larger and larger every four bundles for some time. I believe this should happen for $\pi$ as well since it is irrational. I'm not entirely sure why but $|B_n|\leq3$ for most small $n$ though I guess it's because $\pi-3$ is slightly smaller than $1/7$ ? Anyway $B_{312\ 692}=4$ , $B_{625\ 381}=5$ , $B_{938\ 070}=6$ , $B_{166\ 645\ 135}=-7$ , and $B_{824\ 054\ 044}=8$ . $|B_n|$ does not hit $9$ up to $n=1\ 000\ 000\ 000$ with $B_{1\ 000\ 000\ 000}=-2$ .","We know that the series converges, and clearly every other alternating harmonic series with the sign changing every two or more terms such as must converge. My question here is that does the series below also converge? Loosely speaking, the sign changes every terms. I'd be surprised if it doesn't converge. Wolfram Mathematica, after a couple of minutes of computing, concluded the series diverges but I can't really trust it. My first approach (assuming the series converges) was that if we bundle up terms with the same sign like the example above every bundle must have three or four terms, and since the first three terms of all bundles make an alternating series I was going to fiddle with the remaining fourth terms but they don't make an alternating series so I guess there's no point in this approach. edit: I don't think we can use Dirichlet's test with The alternating cycle here is and I don't believe it would bound the series. For example if the cycle was a number very slightly smaller than , then (sum of ) would get larger and larger every four bundles for some time. I believe this should happen for as well since it is irrational. I'm not entirely sure why but for most small though I guess it's because is slightly smaller than ? Anyway , , , , and . does not hit up to with .",\sum (-1)^n/n \left(1+\frac{1}{2}+\frac{1}{3}\right)-\left(\frac{1}{4}+\frac{1}{5}+\frac{1}{6}\right)+\left(\frac{1}{7}+\frac{1}{8}+\frac{1}{9}\right)-\cdots \sum\frac{\textrm{sgn}(\sin(n))}{n}\quad\textrm{or}\quad\sum\frac{\sin(n)}{n|\sin(n)|} \pi b_n=\textrm{sgn}(\sin(n)). \pi 3+1/4 B_n b_n \pi |B_n|\leq3 n \pi-3 1/7 B_{312\ 692}=4 B_{625\ 381}=5 B_{938\ 070}=6 B_{166\ 645\ 135}=-7 B_{824\ 054\ 044}=8 |B_n| 9 n=1\ 000\ 000\ 000 B_{1\ 000\ 000\ 000}=-2,['sequences-and-series']
64,Show that $f(z)=\sum_{n=0}^{\infty}z^{2^n}$ can't be analytically continued past the unit disk.,Show that  can't be analytically continued past the unit disk.,f(z)=\sum_{n=0}^{\infty}z^{2^n},"I'm reading the problems of Stein and Shakarchi's Complex Analysis, Chapter 2 Problem 1 asks to show that $$f(z)=\sum_{n=0}^{\infty}z^{2^n}$$ cannot be analytically continued past the unit disk. (Hint: Suppose $\theta =\frac{2\pi p}{2^k}$ for $p,k$ positive integers, let $z=re^{i\theta}$ and show $\mid f(z)\mid\rightarrow\infty$ as $r \rightarrow1$ ). I understand from the hint they want me to ""pepper"" the unit circle with points where the power expansion explodes so that it is dense with poles. I do not understand why they choose such particular points, but I assume that in retrospect it will show that those are the ones that I can show divergence for the easiest and are dense in the unit circle, so plowing ahead: $$\lim_{r \rightarrow 1}\left| \sum_{n=0}^\infty r^{2^n}e^{ i2\pi p 2^{n-k}}\right| = \left| \sum_{n=0}^k e^{ \frac{i2\pi p}{2^{k-n}}} + \sum_{n=k+1}^\infty e^{ i2\pi p2^{n-k}} \right|  $$ Where do I go from here? Is there some oversimplification of these sinusoids that I'm not seeing? Furthermore, once I manage to show this explodes, if I show that these numbers are dense on the unit circle I'm done, right? Any insight is much appreciated.","I'm reading the problems of Stein and Shakarchi's Complex Analysis, Chapter 2 Problem 1 asks to show that cannot be analytically continued past the unit disk. (Hint: Suppose for positive integers, let and show as ). I understand from the hint they want me to ""pepper"" the unit circle with points where the power expansion explodes so that it is dense with poles. I do not understand why they choose such particular points, but I assume that in retrospect it will show that those are the ones that I can show divergence for the easiest and are dense in the unit circle, so plowing ahead: Where do I go from here? Is there some oversimplification of these sinusoids that I'm not seeing? Furthermore, once I manage to show this explodes, if I show that these numbers are dense on the unit circle I'm done, right? Any insight is much appreciated.","f(z)=\sum_{n=0}^{\infty}z^{2^n} \theta =\frac{2\pi p}{2^k} p,k z=re^{i\theta} \mid f(z)\mid\rightarrow\infty r \rightarrow1 \lim_{r \rightarrow 1}\left| \sum_{n=0}^\infty r^{2^n}e^{ i2\pi p 2^{n-k}}\right| = \left| \sum_{n=0}^k e^{ \frac{i2\pi p}{2^{k-n}}} + \sum_{n=k+1}^\infty e^{ i2\pi p2^{n-k}} \right|  ","['sequences-and-series', 'complex-analysis', 'divergent-series', 'analytic-continuation', 'analytic-functions']"
65,Mathematical Explanation of Mathematica Summation ${\sum_{n=1}^{\infty}\frac{(2n-1)!}{(2n+2)!}\zeta(2n)}$,Mathematical Explanation of Mathematica Summation,{\sum_{n=1}^{\infty}\frac{(2n-1)!}{(2n+2)!}\zeta(2n)},"From a mathematical point of view, what phenomena that most likely Mathematica Wolfram encountered when calculating : $$ \sum_{n=1}^{\infty}\frac{(2n-1)!}{(2n+2)!}\zeta(2n)\,=\,\color{red}{\frac{2\log(2\pi)-3}{8}+\frac{\zeta(3)}{8\pi^2}} $$ which is incorrect. While calculating the sum from this question , I noticed that Wolfram result is containing ${\small\,\frac{\zeta(3)}{8\pi^2}\,}$ , which is incorrect. Although I realized that this could be a bug, I started to wonder if there are any logical explanation behind this miscalculation! Has Wolfram algorithm encountered something similar to Riemann Rearrangement Theorem ? Doing more investigations, it turns-out that Wolfram is incorrectly miscalculating the closed form of an entire class of zeta summation, except the last case which is correct. $$ \small \begin{align} \sum_{n=1}^{\infty}\frac{\zeta(\alpha\,n)}{(n+a)(n+b)\dots} &= \sum_{n=1}^{\infty}\left[A\frac{\zeta(\alpha\,n)}{n+a}+B\frac{\zeta(\alpha\,n)}{n+b}+\dots\right] = \\ C+\,\sum_{n=1}^{\infty}\frac{\zeta(\alpha\,n)-1}{(n+a)(n+b)\dots} &= \color{darkgreen}{\sum_{n=1}^{\infty}\left[A\frac{\zeta(\alpha\,n)-1}{n+a}+B\frac{\zeta(\alpha\,n)-1}{n+b}+\dots\right]\,+C} \end{align} $$ And with the appearance of this case (the last correct closed form), I believe there is a mathematical explanation regarding a correct summation method or algorithm that gives a kind of systematic incorrect closed form if it applied in a certain way. Appreciating if someone can explore this and alert us regardless of any bug that may exist in any math app . Thanks.","From a mathematical point of view, what phenomena that most likely Mathematica Wolfram encountered when calculating : which is incorrect. While calculating the sum from this question , I noticed that Wolfram result is containing , which is incorrect. Although I realized that this could be a bug, I started to wonder if there are any logical explanation behind this miscalculation! Has Wolfram algorithm encountered something similar to Riemann Rearrangement Theorem ? Doing more investigations, it turns-out that Wolfram is incorrectly miscalculating the closed form of an entire class of zeta summation, except the last case which is correct. And with the appearance of this case (the last correct closed form), I believe there is a mathematical explanation regarding a correct summation method or algorithm that gives a kind of systematic incorrect closed form if it applied in a certain way. Appreciating if someone can explore this and alert us regardless of any bug that may exist in any math app . Thanks."," \sum_{n=1}^{\infty}\frac{(2n-1)!}{(2n+2)!}\zeta(2n)\,=\,\color{red}{\frac{2\log(2\pi)-3}{8}+\frac{\zeta(3)}{8\pi^2}}  {\small\,\frac{\zeta(3)}{8\pi^2}\,}  \small \begin{align} \sum_{n=1}^{\infty}\frac{\zeta(\alpha\,n)}{(n+a)(n+b)\dots} &= \sum_{n=1}^{\infty}\left[A\frac{\zeta(\alpha\,n)}{n+a}+B\frac{\zeta(\alpha\,n)}{n+b}+\dots\right] = \\ C+\,\sum_{n=1}^{\infty}\frac{\zeta(\alpha\,n)-1}{(n+a)(n+b)\dots} &= \color{darkgreen}{\sum_{n=1}^{\infty}\left[A\frac{\zeta(\alpha\,n)-1}{n+a}+B\frac{\zeta(\alpha\,n)-1}{n+b}+\dots\right]\,+C} \end{align} ","['sequences-and-series', 'summation', 'riemann-zeta', 'wolfram-alpha']"
66,Another Ramanujan's formula dealing with $\coth^{2}(5\pi)$,Another Ramanujan's formula dealing with,\coth^{2}(5\pi),"Ramanujan mentions in one of his letters to Hardy that $$\frac{1^{5}}{e^{2\pi} - 1}\cdot\frac{1}{2500 + 1^{4}} + \frac{2^{5}}{e^{4\pi} - 1}\cdot\frac{1}{2500 + 2^{4}} + \cdots = \frac{123826979}{6306456} - \frac{25\pi}{4}\coth^{2}(5\pi)$$ If we put $q = e^{-\pi}$ we can see that the series is given by $$\sum_{n = 1}^{\infty}\frac{n^{5}q^{2n}}{1 - q^{2n}}\cdot\frac{1}{2500 + n^{4}}$$ While I am aware of the sum $$\sum_{n = 1}^{\infty}\frac{n^{5}q^{2n}}{1 - q^{2n}} = \frac{1 - R(q^{2})}{504}$$ and the Ramanujan function $R(q^{2})$ can be expressed in terms of $k, K$ as $$R(q^{2}) = \left(\frac{2K}{\pi}\right)^{6}(1 + k^{2})(1 - 2k^{2})\left(1 - \frac{k^{2}}{2}\right)$$ (see the derivation of this formula here ). For $q = e^{-\pi}$ we have $k = 1/\sqrt{2}$ so that $R(q^{2}) = 0$ and hence $\sum_{n = 1}^{\infty}n^{5}q^{2n}/(1 - q^{2n}) = 1/504$. But getting the factor $1/(2500 + n^{4})$ seems really difficult. Any ideas on whether we can get this factor by integration/differentiation (plus some algebraic games) from the series $\sum n^{5}q^{2n}/(1 - q^{2n})$? Further Update : We have $$n^{4} + 2500 = (n^{2} + 50)^{2} - 100n^{2} = (n^{2} - 10n + 50)(n^{2} + 10n + 50)$$ so that $$n^{4} + 2500 = (n - 5 - 5i)(n - 5 + 5i)(n + 5 - 5i)(n + 5 + 5i)$$ so I believe we can do a partial fraction decomposition of $1/(n^{4} + 2500)$ but still I need to find a way to sum $\sum n^{5}q^{2n}/(1 - q^{2n})\cdot 1/(n + a)$ i.e. the problem is now simplified to getting a linear factor like $1/(n + a)$ somehow. Latest Update : I asked this question at MathOverflow ( https://mathoverflow.net/q/173356/15540 ) and got a very beautiful answer.","Ramanujan mentions in one of his letters to Hardy that $$\frac{1^{5}}{e^{2\pi} - 1}\cdot\frac{1}{2500 + 1^{4}} + \frac{2^{5}}{e^{4\pi} - 1}\cdot\frac{1}{2500 + 2^{4}} + \cdots = \frac{123826979}{6306456} - \frac{25\pi}{4}\coth^{2}(5\pi)$$ If we put $q = e^{-\pi}$ we can see that the series is given by $$\sum_{n = 1}^{\infty}\frac{n^{5}q^{2n}}{1 - q^{2n}}\cdot\frac{1}{2500 + n^{4}}$$ While I am aware of the sum $$\sum_{n = 1}^{\infty}\frac{n^{5}q^{2n}}{1 - q^{2n}} = \frac{1 - R(q^{2})}{504}$$ and the Ramanujan function $R(q^{2})$ can be expressed in terms of $k, K$ as $$R(q^{2}) = \left(\frac{2K}{\pi}\right)^{6}(1 + k^{2})(1 - 2k^{2})\left(1 - \frac{k^{2}}{2}\right)$$ (see the derivation of this formula here ). For $q = e^{-\pi}$ we have $k = 1/\sqrt{2}$ so that $R(q^{2}) = 0$ and hence $\sum_{n = 1}^{\infty}n^{5}q^{2n}/(1 - q^{2n}) = 1/504$. But getting the factor $1/(2500 + n^{4})$ seems really difficult. Any ideas on whether we can get this factor by integration/differentiation (plus some algebraic games) from the series $\sum n^{5}q^{2n}/(1 - q^{2n})$? Further Update : We have $$n^{4} + 2500 = (n^{2} + 50)^{2} - 100n^{2} = (n^{2} - 10n + 50)(n^{2} + 10n + 50)$$ so that $$n^{4} + 2500 = (n - 5 - 5i)(n - 5 + 5i)(n + 5 - 5i)(n + 5 + 5i)$$ so I believe we can do a partial fraction decomposition of $1/(n^{4} + 2500)$ but still I need to find a way to sum $\sum n^{5}q^{2n}/(1 - q^{2n})\cdot 1/(n + a)$ i.e. the problem is now simplified to getting a linear factor like $1/(n + a)$ somehow. Latest Update : I asked this question at MathOverflow ( https://mathoverflow.net/q/173356/15540 ) and got a very beautiful answer.",,['sequences-and-series']
67,Convergence of the series $\sum_{n=1}^\infty \frac{(\sin n)^n}{n}$.,Convergence of the series .,\sum_{n=1}^\infty \frac{(\sin n)^n}{n},"Please determine whether the series  $\displaystyle\sum_{n=1}^\infty \frac{(\sin n)^n}{n}$ converges. (Note: In Mathematica, the result tends to converge. Moreover, this is a problem mis-copied from Advanced Calculus Exam, so we don't know the difficulty of the problem [Maybe it can be solved in college mathematics]. )","Please determine whether the series  $\displaystyle\sum_{n=1}^\infty \frac{(\sin n)^n}{n}$ converges. (Note: In Mathematica, the result tends to converge. Moreover, this is a problem mis-copied from Advanced Calculus Exam, so we don't know the difficulty of the problem [Maybe it can be solved in college mathematics]. )",,"['sequences-and-series', 'limits']"
68,How to prove convergence of polynomials in $e$ (Euler's number),How to prove convergence of polynomials in  (Euler's number),e,"These polynomials in $e$ converge to 2$$f(i)=e^i - i \sum_{k=1}^{i-1}\frac{(i-k)^{k-1}{e^{i-k}}{(-1)^{k+1}}}{k!}, \text{ where } i>1$$ This function goes to 2. I've calculated this with sage math tool . $$f(\infty) = 2$$ for example, $$f(2)=e^2-2e=1.95249244... $$ $$f(3)=e^3-3e^2+\frac{3}2e=1.99579136... $$ $$f(4)=e^4-4e^3+4e^2-\frac{2}3e=2.000038... $$ $$...$$ $$f(10)=\newcommand{\Bold}[1]{\mathbf{#1}}-\frac{1}{36288} \, e + \frac{2}{63} \, e^{2} - \frac{81}{56} \, e^{3} + \frac{128}{9} \, e^{4} - \frac{625}{12} \, e^{5} + 90 \, e^{6} - \frac{245}{3} \, e^{7} + 40 \, e^{8} - 10 \, e^{9} + e^{10} = 2.00000000...$$ Isn't this interesting? These polynomials in e (2.71828182845904523536...) converge to 2. However , I have no idea how to mathematically prove this . I guess this would have been already proved, but I have no idea where I can find the proof. I would greatly appreciate it if you can give me some tips or the proof of this convergence. For more information, this function $f(i)$ is from a different function $h_i(x),\text{ when } x = 1$ of an original problem $$ f(i) = h_i(1)$$ so proving the convergence of the above polynominals will be the same as proving $h_\infty(1) = 2$ I have recently found that the general form of $h_i(x)$ function  $$h_i(x) = (-1)^{i+1} e^x \left[\frac{1}{(i-1)!}{x}^{i-1} - \sum_{k=1}^{i-1}\left(α(k)\frac{{x}^{i-1-k}(-1)^{k+1}}{(i-1-k)!}\right)\right] - α(i-1),$$ where  $$α(j) = \sum_{k=0}^{j-1}\frac{(j-k)^k}{k!}e^{j-k}(-1)^k$$ update list I have found this: $ f(i)=α(i)−α(i−1) $ I have found a new property of $α(i)$, when $i > 1$,  $$ α(i) = \sum_{k=0}^{i-2} \left( e \space α(k+1)\space\frac{(-1)^{i+k+2}}{(i-k-2)!} \right) + \frac{(-1)^{i+1} \space e}{(i-1)!},$$ where $α(1) = e$.","These polynomials in $e$ converge to 2$$f(i)=e^i - i \sum_{k=1}^{i-1}\frac{(i-k)^{k-1}{e^{i-k}}{(-1)^{k+1}}}{k!}, \text{ where } i>1$$ This function goes to 2. I've calculated this with sage math tool . $$f(\infty) = 2$$ for example, $$f(2)=e^2-2e=1.95249244... $$ $$f(3)=e^3-3e^2+\frac{3}2e=1.99579136... $$ $$f(4)=e^4-4e^3+4e^2-\frac{2}3e=2.000038... $$ $$...$$ $$f(10)=\newcommand{\Bold}[1]{\mathbf{#1}}-\frac{1}{36288} \, e + \frac{2}{63} \, e^{2} - \frac{81}{56} \, e^{3} + \frac{128}{9} \, e^{4} - \frac{625}{12} \, e^{5} + 90 \, e^{6} - \frac{245}{3} \, e^{7} + 40 \, e^{8} - 10 \, e^{9} + e^{10} = 2.00000000...$$ Isn't this interesting? These polynomials in e (2.71828182845904523536...) converge to 2. However , I have no idea how to mathematically prove this . I guess this would have been already proved, but I have no idea where I can find the proof. I would greatly appreciate it if you can give me some tips or the proof of this convergence. For more information, this function $f(i)$ is from a different function $h_i(x),\text{ when } x = 1$ of an original problem $$ f(i) = h_i(1)$$ so proving the convergence of the above polynominals will be the same as proving $h_\infty(1) = 2$ I have recently found that the general form of $h_i(x)$ function  $$h_i(x) = (-1)^{i+1} e^x \left[\frac{1}{(i-1)!}{x}^{i-1} - \sum_{k=1}^{i-1}\left(α(k)\frac{{x}^{i-1-k}(-1)^{k+1}}{(i-1-k)!}\right)\right] - α(i-1),$$ where  $$α(j) = \sum_{k=0}^{j-1}\frac{(j-k)^k}{k!}e^{j-k}(-1)^k$$ update list I have found this: $ f(i)=α(i)−α(i−1) $ I have found a new property of $α(i)$, when $i > 1$,  $$ α(i) = \sum_{k=0}^{i-2} \left( e \space α(k+1)\space\frac{(-1)^{i+k+2}}{(i-k-2)!} \right) + \frac{(-1)^{i+1} \space e}{(i-1)!},$$ where $α(1) = e$.",,"['sequences-and-series', 'convergence-divergence', 'power-series', 'proof-writing']"
69,Example of an infinite sequence of irrational numbers converging to a rational number?,Example of an infinite sequence of irrational numbers converging to a rational number?,,"Are there any nice examples of infinite sequences of irrational numbers converging to rational numbers? One idea I had was the sequence: $ 0.1001000010000001\cdots,0.1101000110000001\cdots,\cdots,0.1111000110000001\cdots,$ etc. Where the first term in the sequence has ones in the place $i^2$ positions to the right of the decimal point. $(i=1,2,3,\dots)$ For the second term, we keep all the ones from the first term and add one in place of the first zero after the decimal point. We then add ones $i^3$ places after the decimal point. (The logical sum 1+1=1, i.e a number $i^2=j^3$ spaces after the decimal place has the value 1). It is clear that this will converge to $1/9$, and I don't think the decimal expansion repeats at all.","Are there any nice examples of infinite sequences of irrational numbers converging to rational numbers? One idea I had was the sequence: $ 0.1001000010000001\cdots,0.1101000110000001\cdots,\cdots,0.1111000110000001\cdots,$ etc. Where the first term in the sequence has ones in the place $i^2$ positions to the right of the decimal point. $(i=1,2,3,\dots)$ For the second term, we keep all the ones from the first term and add one in place of the first zero after the decimal point. We then add ones $i^3$ places after the decimal point. (The logical sum 1+1=1, i.e a number $i^2=j^3$ spaces after the decimal place has the value 1). It is clear that this will converge to $1/9$, and I don't think the decimal expansion repeats at all.",,['sequences-and-series']
70,"Sequence that is neither increasing, nor decreasing, yet converges to 1","Sequence that is neither increasing, nor decreasing, yet converges to 1",,"Give an example of a sequence which is neither increasing after a while, nor decreasing after a while, yet which converges to 1. My solution: $1.01,\ .99,\ 1.001,\ .999,\ 1.0001,\ .9999,\ \text{etc}\dots$ Does that satisfy all the conditions? Also, judging by the instructions, do you think I would have to define that sequence? In which case, I could do $\{x_n\} = 1 + .01^n$ for odd $n$ and $1 - .01^n$ for even $n$ (which would change the sequence, but just increases the rate at which it approaches $1$). The definition of an increasing sequence used is the next term being bigger than OR equal to the preceding term. And dually for decreasing.","Give an example of a sequence which is neither increasing after a while, nor decreasing after a while, yet which converges to 1. My solution: $1.01,\ .99,\ 1.001,\ .999,\ 1.0001,\ .9999,\ \text{etc}\dots$ Does that satisfy all the conditions? Also, judging by the instructions, do you think I would have to define that sequence? In which case, I could do $\{x_n\} = 1 + .01^n$ for odd $n$ and $1 - .01^n$ for even $n$ (which would change the sequence, but just increases the rate at which it approaches $1$). The definition of an increasing sequence used is the next term being bigger than OR equal to the preceding term. And dually for decreasing.",,['sequences-and-series']
71,Prove that the infinite sum $\sum_{n=1}^{\infty} \frac{F_{n}}{ 10 ^ n }$ converges to a rational number,Prove that the infinite sum  converges to a rational number,\sum_{n=1}^{\infty} \frac{F_{n}}{ 10 ^ n },How do you prove that the following infinite sum \begin{align}      &0.1 \\+\;&0.01 \\+\;&0.002 \\+\;&0.0003 \\+\;&0.00005 \\+\;&0.000008 \\+\;&0.0000013 \\ \;&\quad\vdots \end{align} converges to a rational number? Notice that the above sum can be written as $$\sum_{n=1}^{\infty} \frac{F_{n}}{ 10 ^  n }$$ where $F_{n} $ is a Fibonacci sequence.,How do you prove that the following infinite sum \begin{align}      &0.1 \\+\;&0.01 \\+\;&0.002 \\+\;&0.0003 \\+\;&0.00005 \\+\;&0.000008 \\+\;&0.0000013 \\ \;&\quad\vdots \end{align} converges to a rational number? Notice that the above sum can be written as $$\sum_{n=1}^{\infty} \frac{F_{n}}{ 10 ^  n }$$ where $F_{n} $ is a Fibonacci sequence.,,"['sequences-and-series', 'convergence-divergence', 'fibonacci-numbers']"
72,Upper limit of summation index lower than lower limit?,Upper limit of summation index lower than lower limit?,,How does one evaluate something like the following? $$\sum_{k=0}^{-1}\left( 5\times 2^k \right)$$ When I type this into Mathematica it returns 0. Can someone explain why this is?,How does one evaluate something like the following? $$\sum_{k=0}^{-1}\left( 5\times 2^k \right)$$ When I type this into Mathematica it returns 0. Can someone explain why this is?,,['sequences-and-series']
73,Proving that $\frac{\pi^{3}}{32}=1-\sum_{k=1}^{\infty}\frac{2k(2k+1)\zeta(2k+2)}{4^{2k+2}}$,Proving that,\frac{\pi^{3}}{32}=1-\sum_{k=1}^{\infty}\frac{2k(2k+1)\zeta(2k+2)}{4^{2k+2}},After numerical analysis it seems that $$ \frac{\pi^{3}}{32}=1-\sum_{k=1}^{\infty}\frac{2k(2k+1)\zeta(2k+2)}{4^{2k+2}} $$ Could someone prove the validity of such identity?,After numerical analysis it seems that $$ \frac{\pi^{3}}{32}=1-\sum_{k=1}^{\infty}\frac{2k(2k+1)\zeta(2k+2)}{4^{2k+2}} $$ Could someone prove the validity of such identity?,,"['sequences-and-series', 'riemann-zeta', 'pi', 'constants']"
74,Infinite sum of reciprocals of pentagonal numbers,Infinite sum of reciprocals of pentagonal numbers,,"How do I find this sum: $$\sum_{n=1}^\infty \frac{1}{p(n)}$$ where $p(n)=\dfrac{n(3n-1)}{2}$ is the $n$th pentagonal number? I know it is a convergent series, but I don't know if the sum can be found in closed form.","How do I find this sum: $$\sum_{n=1}^\infty \frac{1}{p(n)}$$ where $p(n)=\dfrac{n(3n-1)}{2}$ is the $n$th pentagonal number? I know it is a convergent series, but I don't know if the sum can be found in closed form.",,"['sequences-and-series', 'number-theory', 'convergence-divergence', 'closed-form']"
75,Generalisation of the identity $\sum\limits_{k=1}^n {k^3} = \bigg(\sum\limits_{k=1}^n k\bigg)^2$,Generalisation of the identity,\sum\limits_{k=1}^n {k^3} = \bigg(\sum\limits_{k=1}^n k\bigg)^2,"Are there any generalisations of the identity $\sum\limits_{k=1}^n {k^3} = \bigg(\sum\limits_{k=1}^n k\bigg)^2$ ? For example can $\sum {k^m} = \left(\sum k\right)^n$ be valid for anything other than $m=3 , n=2$ ? If not, is there a deeper reason for this identity to be true only for the case $m=3 , n=2$?","Are there any generalisations of the identity $\sum\limits_{k=1}^n {k^3} = \bigg(\sum\limits_{k=1}^n k\bigg)^2$ ? For example can $\sum {k^m} = \left(\sum k\right)^n$ be valid for anything other than $m=3 , n=2$ ? If not, is there a deeper reason for this identity to be true only for the case $m=3 , n=2$?",,['sequences-and-series']
76,"How to prove that $1+2=3, 4+5+6=7+8,... $ ad infinitum?",How to prove that  ad infinitum?,"1+2=3, 4+5+6=7+8,... ","Given this set of equations: $$ 1+2=3\\ 4+5+6=7+8\\ 9+10+11+12=13+14+15\\ \ldots $$ How can I prove that this is true for all continuations of this sequence? I would put it in the form of: $$ (k,m)\in \{n^2,n|\in\Bbb N\}\\ \sum_{i=k}^{k+m} i=\sum_{i=k+m+1}^{k+2m}i $$ However, I have problems in formulating and solving the inductions step, which I think should be to go from $n$ to $n+1$","Given this set of equations: $$ 1+2=3\\ 4+5+6=7+8\\ 9+10+11+12=13+14+15\\ \ldots $$ How can I prove that this is true for all continuations of this sequence? I would put it in the form of: $$ (k,m)\in \{n^2,n|\in\Bbb N\}\\ \sum_{i=k}^{k+m} i=\sum_{i=k+m+1}^{k+2m}i $$ However, I have problems in formulating and solving the inductions step, which I think should be to go from $n$ to $n+1$",,"['sequences-and-series', 'summation']"
77,Intuitive ways to get formula of cubic sum,Intuitive ways to get formula of cubic sum,,"Is there an intuitive way to get cubic sum? From this post: combination of quadratic and cubic series and Wikipedia: Faulhaber formula , I get $$1^3 + 2^3 + \dots + n^3 = \frac{n^2(n+1)^2}{4}$$ I think the cubic sum is squaring the arithmetic sum $$1^3 + 2^3 + \dots + n^3 = (1  + 2 + \dots + n)^2$$ But how to prove it? Please help me. Grazie!","Is there an intuitive way to get cubic sum? From this post: combination of quadratic and cubic series and Wikipedia: Faulhaber formula , I get $$1^3 + 2^3 + \dots + n^3 = \frac{n^2(n+1)^2}{4}$$ I think the cubic sum is squaring the arithmetic sum $$1^3 + 2^3 + \dots + n^3 = (1  + 2 + \dots + n)^2$$ But how to prove it? Please help me. Grazie!",,"['sequences-and-series', 'algebra-precalculus', 'summation']"
78,Peculiar Sum regarding the Reciprocal Binomial Coefficients,Peculiar Sum regarding the Reciprocal Binomial Coefficients,,"Whilst playing around on Wolfram Alpha, I typed in the sum $$\sum_{x=0}^\infty \frac{1}{\binom{2x}{x}}=\frac{2}{27}(18+\pi\sqrt 3)$$ I'm not sure how to derive the answer. My first instinct was to expand the binomial coefficient to get $$\sum_{x=0}^\infty \frac{x!^2}{(2x)!}$$ and then to try using a Taylor Series to get the answer. I thought that if I could find a function $f(n)$ with $$f(n)=\sum_{x=0}^\infty \frac{x!^2n^x}{(2x)!}$$ Then my sum would be equal to $f(1)$. How do I find such a function? EDIT: I continued on this path and realized that I can use this to set up a recurrence relation for $f^{(x)}(0)$: $$f^{(0)}(0)=1$$ $$f^{(x)}(0)=\frac{x^2}{2x(2x-1)}f^{(x-1)}(0)$$ However, I'm not sure how this helps me find $f(1)$... Am I on the right track? Can somebody help me finish what I started, or point me towards a better method of calculating this sum? Thanks!","Whilst playing around on Wolfram Alpha, I typed in the sum $$\sum_{x=0}^\infty \frac{1}{\binom{2x}{x}}=\frac{2}{27}(18+\pi\sqrt 3)$$ I'm not sure how to derive the answer. My first instinct was to expand the binomial coefficient to get $$\sum_{x=0}^\infty \frac{x!^2}{(2x)!}$$ and then to try using a Taylor Series to get the answer. I thought that if I could find a function $f(n)$ with $$f(n)=\sum_{x=0}^\infty \frac{x!^2n^x}{(2x)!}$$ Then my sum would be equal to $f(1)$. How do I find such a function? EDIT: I continued on this path and realized that I can use this to set up a recurrence relation for $f^{(x)}(0)$: $$f^{(0)}(0)=1$$ $$f^{(x)}(0)=\frac{x^2}{2x(2x-1)}f^{(x-1)}(0)$$ However, I'm not sure how this helps me find $f(1)$... Am I on the right track? Can somebody help me finish what I started, or point me towards a better method of calculating this sum? Thanks!",,"['sequences-and-series', 'definite-integrals', 'summation', 'binomial-coefficients', 'closed-form']"
79,Understanding this pattern behind the Fibonacci sequence,Understanding this pattern behind the Fibonacci sequence,,"To be honest, I'm pretty awful at mathematics however, when up till 6AM I do like to do random things throughout the night to keep me occupied. Tonight, I began playing with the Fibonacci sequence in the Python programming language. I understand that the Fibonacci sequence is just adding the previous two numbers together to produce your next value so I defined a function to spit out the sequence up to the 200th number like so, def fib(n):     a, b = 0, 1     i=1     while i < 200:         print(""ITERATION: "" + str(i))         a, b = b, a + b         print(a)         i += 1 print(fib(1)) What I found interesting is a pattern I came across when adding up the total amount of numbers before the sequence added the next digit. (see picture A.) PICTURE A: from there, I added up the number ""sets"" and the pattern emerged.(see picture B.) PICTURE B: This pattern continued, I went up to the 22nd ""set"" of numbers and the whole pattern was like so: 1   2   1   3   1   4   1   5   1   2   1   4   1   4   1   3   1   4   1   3   1   4 I found it interesting that the numbers added a digit sequentially by either 4 or mainly 5 integers and how the overall pattern that emerged out of the ""sets"" appeared to become less stable after the 8th set which was ironically 5; 1   2   1   3   1   4   1   5 forgive me if this seems obvious or silly, but like I said, I'm pretty bad at math. Can anyone explain why this pattern emerges and a little bit more in depth on what the fibonacci sequence can be used for?","To be honest, I'm pretty awful at mathematics however, when up till 6AM I do like to do random things throughout the night to keep me occupied. Tonight, I began playing with the Fibonacci sequence in the Python programming language. I understand that the Fibonacci sequence is just adding the previous two numbers together to produce your next value so I defined a function to spit out the sequence up to the 200th number like so, def fib(n):     a, b = 0, 1     i=1     while i < 200:         print(""ITERATION: "" + str(i))         a, b = b, a + b         print(a)         i += 1 print(fib(1)) What I found interesting is a pattern I came across when adding up the total amount of numbers before the sequence added the next digit. (see picture A.) PICTURE A: from there, I added up the number ""sets"" and the pattern emerged.(see picture B.) PICTURE B: This pattern continued, I went up to the 22nd ""set"" of numbers and the whole pattern was like so: 1   2   1   3   1   4   1   5   1   2   1   4   1   4   1   3   1   4   1   3   1   4 I found it interesting that the numbers added a digit sequentially by either 4 or mainly 5 integers and how the overall pattern that emerged out of the ""sets"" appeared to become less stable after the 8th set which was ironically 5; 1   2   1   3   1   4   1   5 forgive me if this seems obvious or silly, but like I said, I'm pretty bad at math. Can anyone explain why this pattern emerges and a little bit more in depth on what the fibonacci sequence can be used for?",,"['sequences-and-series', 'discrete-mathematics', 'fibonacci-numbers', 'pattern-recognition']"
80,Property of sum $\sum_{k=1}^{+\infty}\frac{(2k+1)^{4n+1}}{1+\exp{((2k+1)\pi)}}$,Property of sum,\sum_{k=1}^{+\infty}\frac{(2k+1)^{4n+1}}{1+\exp{((2k+1)\pi)}},"Is it true that for all $n\in\mathbb{N}$, \begin{align}f(n)=\sum_{k=1}^{+\infty}\frac{(2k+1)^{4n+1}}{1+\exp{((2k+1)\pi)}}\end{align} is always rational. I have calculated via Mathematica, which says \begin{align}f(0)=\frac{1}{24},f(1)=\frac{31}{504},f(2)=\frac{511}{264},f(3)=\frac{8191}{24}\end{align} But I couldn't find the pattern or formula behind these numbers, Thanks for your help!","Is it true that for all $n\in\mathbb{N}$, \begin{align}f(n)=\sum_{k=1}^{+\infty}\frac{(2k+1)^{4n+1}}{1+\exp{((2k+1)\pi)}}\end{align} is always rational. I have calculated via Mathematica, which says \begin{align}f(0)=\frac{1}{24},f(1)=\frac{31}{504},f(2)=\frac{511}{264},f(3)=\frac{8191}{24}\end{align} But I couldn't find the pattern or formula behind these numbers, Thanks for your help!",,"['sequences-and-series', 'analysis', 'special-functions']"
81,"A conjectured result for $\sum_{n=1}^\infty\frac{(-1)^n\,H_{n/5}}n$",A conjectured result for,"\sum_{n=1}^\infty\frac{(-1)^n\,H_{n/5}}n","Let $H_q$ denote harmonic numbers (generalized to a non-integer index $q$): $$H_q=\sum_{k=1}^\infty\left(\frac1k-\frac1{k+q}\right)=\int_0^1\frac{1-x^q}{1-x}dx=\gamma+\psi(q+1),\tag1$$ where $\psi(z)=\Gamma'(z)/\Gamma(z)$ is the digamma function . My goal is to evaluate the following series: $$\mathcal S_m=\sum_{n=1}^\infty\frac{(-1)^n\,H_{n/m}}n.\tag2$$ Using the integral representation from $(1)$ we can get equivalent integral forms: $$\mathcal S_m=\int_0^1\frac{\ln(1+\sqrt[m]x)-\ln2}{1-x}\,dx=m\int_0^1\frac{\ln(1+z)-\ln2}{1-z^m}\,z^{m-1}dz.\tag3$$ Here are some simple cases: $$\begin{align}&\mathcal S_1=\frac{\ln^22}2-\frac{\pi^2}{12}\hspace{7.7em}\color{maroon}{\mathcal S_2=\ln^22-\frac{\pi^2}{12}}\\\\&\color{blue}{\mathcal S_3=\frac{3\ln^22}2-\frac{\pi^2}9+\frac12\,\operatorname{Li}_2\!\left(\tfrac14\right)}\hspace{2em}\color{green}{\mathcal S_4=\frac{7\ln^22}4-\frac{5\pi^2}{48}}\end{align}\tag4$$ For $\mathcal S_5$ the integral can be found using Mathematica (there is even a closed-form antiderivative, so it should be possible in principle to prove it by differentiation), but the result takes tens of thousands characters to write down (you can see it here ), and Mathematica cannot do much simplification on it ( here is a simplified result). But I was able to conjecture a much simpler closed form that fits numerically with a high precision: $$\mathcal S_5\stackrel{\color{gray}?}=\frac{\ln^22}2-\frac{\ln^25}4+\ln2\cdot\ln5-\frac12\,\operatorname{Li}_2\!\left(\tfrac15\right)-\operatorname{Li}_2\!\left(\frac{\sqrt5-1}2\right)\tag{$\diamond$}$$ I hope there is a way to prove this result manually without going through huge intermediate expressions, but so far I have not found it.","Let $H_q$ denote harmonic numbers (generalized to a non-integer index $q$): $$H_q=\sum_{k=1}^\infty\left(\frac1k-\frac1{k+q}\right)=\int_0^1\frac{1-x^q}{1-x}dx=\gamma+\psi(q+1),\tag1$$ where $\psi(z)=\Gamma'(z)/\Gamma(z)$ is the digamma function . My goal is to evaluate the following series: $$\mathcal S_m=\sum_{n=1}^\infty\frac{(-1)^n\,H_{n/m}}n.\tag2$$ Using the integral representation from $(1)$ we can get equivalent integral forms: $$\mathcal S_m=\int_0^1\frac{\ln(1+\sqrt[m]x)-\ln2}{1-x}\,dx=m\int_0^1\frac{\ln(1+z)-\ln2}{1-z^m}\,z^{m-1}dz.\tag3$$ Here are some simple cases: $$\begin{align}&\mathcal S_1=\frac{\ln^22}2-\frac{\pi^2}{12}\hspace{7.7em}\color{maroon}{\mathcal S_2=\ln^22-\frac{\pi^2}{12}}\\\\&\color{blue}{\mathcal S_3=\frac{3\ln^22}2-\frac{\pi^2}9+\frac12\,\operatorname{Li}_2\!\left(\tfrac14\right)}\hspace{2em}\color{green}{\mathcal S_4=\frac{7\ln^22}4-\frac{5\pi^2}{48}}\end{align}\tag4$$ For $\mathcal S_5$ the integral can be found using Mathematica (there is even a closed-form antiderivative, so it should be possible in principle to prove it by differentiation), but the result takes tens of thousands characters to write down (you can see it here ), and Mathematica cannot do much simplification on it ( here is a simplified result). But I was able to conjecture a much simpler closed form that fits numerically with a high precision: $$\mathcal S_5\stackrel{\color{gray}?}=\frac{\ln^22}2-\frac{\ln^25}4+\ln2\cdot\ln5-\frac12\,\operatorname{Li}_2\!\left(\tfrac15\right)-\operatorname{Li}_2\!\left(\frac{\sqrt5-1}2\right)\tag{$\diamond$}$$ I hope there is a way to prove this result manually without going through huge intermediate expressions, but so far I have not found it.",,"['sequences-and-series', 'definite-integrals', 'closed-form', 'harmonic-numbers', 'polylogarithm']"
82,Does this sequence $a(n) = \frac{1}{n^3\sin(n)}$ converge,Does this sequence  converge,a(n) = \frac{1}{n^3\sin(n)},"Does the sequence $$a(n) = \frac{1}{n^3\sin(n)}$$ converge ? I tried all possible standard calculus approaches but to no avail ... edit: I tried using the root theorem and the limit of the $\frac{a_{n+1}}{a_{n}}$ which kinda got me nowhere  ... Then I followed it with trying to prove that $n^3\cdot \sin(n)$ has no lower bound $K > 0$ by checking the behavior of the function $|n^3\cdot \sin(n)|$ and concluding that at some point the integer value of $n$ will bring me the value of function, which will be between $0$ and $K$ , but I failed to give a rigorous proof of that conclusion","Does the sequence converge ? I tried all possible standard calculus approaches but to no avail ... edit: I tried using the root theorem and the limit of the which kinda got me nowhere  ... Then I followed it with trying to prove that has no lower bound by checking the behavior of the function and concluding that at some point the integer value of will bring me the value of function, which will be between and , but I failed to give a rigorous proof of that conclusion",a(n) = \frac{1}{n^3\sin(n)} \frac{a_{n+1}}{a_{n}} n^3\cdot \sin(n) K > 0 |n^3\cdot \sin(n)| n 0 K,"['sequences-and-series', 'limits', 'convergence-divergence']"
83,How does the Herglotz trick work?,How does the Herglotz trick work?,,"There is a series representation as partial fraction expansion where just translated reciprocal functions are summed up, such that the poles of the cotangent function and the reciprocal functions match:      $$ \pi \cdot \cot (\pi x) = \lim_{N\to\infty}\sum_{n=-N}^N \frac{1}{x+n}. $$   This identity can be proven with the Herglotz trick. Sounds funny, especially when you understand german (sorry Gustav ;-), but how does it work?","There is a series representation as partial fraction expansion where just translated reciprocal functions are summed up, such that the poles of the cotangent function and the reciprocal functions match:      $$ \pi \cdot \cot (\pi x) = \lim_{N\to\infty}\sum_{n=-N}^N \frac{1}{x+n}. $$   This identity can be proven with the Herglotz trick. Sounds funny, especially when you understand german (sorry Gustav ;-), but how does it work?",,"['sequences-and-series', 'trigonometry']"
84,Another question on almost sure and convergence in probability,Another question on almost sure and convergence in probability,,"Convergence in probability implies convergence on a subsequence almost surely. But this means we fix a subsequence, such that $X_{n_k}$ converges for almost every $\omega$, right? The subsequence we pick does not depend on the $\omega$ right?","Convergence in probability implies convergence on a subsequence almost surely. But this means we fix a subsequence, such that $X_{n_k}$ converges for almost every $\omega$, right? The subsequence we pick does not depend on the $\omega$ right?",,"['sequences-and-series', 'probability-theory', 'convergence-divergence', 'borel-cantelli-lemmas']"
85,Infinite zeros in infinite series,Infinite zeros in infinite series,,"The problem: Given that $$\frac{\pi}{4} = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} + \ldots $$ Prove $$\frac{\pi}{3} = 1 + \frac{1}{5} - \frac{1}{7} - \frac{1}{11} + \frac{1}{13} + \frac{1}{17} + \ldots$$ My solution: We know $$ \begin{align} \frac{\pi}{4} & = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} -\frac{1}{11} + \frac{1}{13} - \frac{1}{15} + \ldots \\ \\ \frac{\pi}{12} & = \frac{1}{3} - \frac{1}{9} + \frac{1}{15} - \frac{1}{21} + \frac{1}{27} -\frac{1}{33} + \frac{1}{39} - \frac{1}{45} + \ldots\\ \\ & = 0 + \frac{1}{3} + 0 + 0 - \frac{1}{9} + 0 + 0 + \frac{1}{15} + 0 + 0 - \frac{1}{21} \end{align} $$ now add them together: $$ \begin{align} \frac{\pi}{4} + \frac{\pi}{12} & = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} - \frac{1}{11} + \frac{1}{13} - \frac{1}{15} + \ldots \\ \\ & + 0 + \frac{1}{3} + 0 + 0 - \frac{1}{9} + 0 + 0 + \frac{1}{15} + \ldots \\ \end{align} $$ and we will get: $$ \begin{align} \frac{\pi}{3} & = 1 + 0 + \frac{1}{5} - \frac{1}{7} + 0 -\frac{1}{11} + \frac{1}{13} + 0 + \ldots \\ & =  1 + \frac{1}{5} - \frac{1}{7} -\frac{1}{11} + \frac{1}{13} + \ldots \end{align} $$ My questions: I inserted/removed infinite zeros into/from the series, is that OK? My solution relies on the fact that $\Sigma a_n + \Sigma b_n = \Sigma (a_n + b_n)$ and $k \Sigma a_n = \Sigma k a_n$. Is this always true for convergent infinite series? If so, why is it? (yeah I know this is a stupid question, but since I'm adding infinite terms up, I'd better pay some attention.) Bouns question: Can I arbitrarily (arbitrariness isn't infinity, you know) insert/remove zeros into/from a convergent infinite series, without changing its convergence value?","The problem: Given that $$\frac{\pi}{4} = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} + \ldots $$ Prove $$\frac{\pi}{3} = 1 + \frac{1}{5} - \frac{1}{7} - \frac{1}{11} + \frac{1}{13} + \frac{1}{17} + \ldots$$ My solution: We know $$ \begin{align} \frac{\pi}{4} & = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} -\frac{1}{11} + \frac{1}{13} - \frac{1}{15} + \ldots \\ \\ \frac{\pi}{12} & = \frac{1}{3} - \frac{1}{9} + \frac{1}{15} - \frac{1}{21} + \frac{1}{27} -\frac{1}{33} + \frac{1}{39} - \frac{1}{45} + \ldots\\ \\ & = 0 + \frac{1}{3} + 0 + 0 - \frac{1}{9} + 0 + 0 + \frac{1}{15} + 0 + 0 - \frac{1}{21} \end{align} $$ now add them together: $$ \begin{align} \frac{\pi}{4} + \frac{\pi}{12} & = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} - \frac{1}{11} + \frac{1}{13} - \frac{1}{15} + \ldots \\ \\ & + 0 + \frac{1}{3} + 0 + 0 - \frac{1}{9} + 0 + 0 + \frac{1}{15} + \ldots \\ \end{align} $$ and we will get: $$ \begin{align} \frac{\pi}{3} & = 1 + 0 + \frac{1}{5} - \frac{1}{7} + 0 -\frac{1}{11} + \frac{1}{13} + 0 + \ldots \\ & =  1 + \frac{1}{5} - \frac{1}{7} -\frac{1}{11} + \frac{1}{13} + \ldots \end{align} $$ My questions: I inserted/removed infinite zeros into/from the series, is that OK? My solution relies on the fact that $\Sigma a_n + \Sigma b_n = \Sigma (a_n + b_n)$ and $k \Sigma a_n = \Sigma k a_n$. Is this always true for convergent infinite series? If so, why is it? (yeah I know this is a stupid question, but since I'm adding infinite terms up, I'd better pay some attention.) Bouns question: Can I arbitrarily (arbitrariness isn't infinity, you know) insert/remove zeros into/from a convergent infinite series, without changing its convergence value?",,"['sequences-and-series', 'convergence-divergence', 'summation', 'fourier-series', 'infinity']"
86,Baffled by resolving number list,Baffled by resolving number list,,"My son's Maths homework was to do with number patterns/sequences. ""What is the nth term?"". He'd done very well, but the last sequence was something like this: 19,77,265,715,1607,3169 He was adamant that he didn't have a technique for solving it and that it must be a ""fake"" question. However, something about the numbers looked like there could be a pattern so I did a bit of investigating. I put them into a spreadsheet and found the differences between consecutive numbers: 58, 188, 450, 892, 1562 No clues. I decided to find the differences of this list: 130, 262, 442, 670 They appear to be getting less diverse with each step: 132, 180, 228 Then: 48, 48 I found that I could generate a list like this using a formula: $$\begin{align}ax^n+bx^p+cx^q+dx+y\end{align}$$ I can have as many power terms as I like but difference always resolves after a number of steps equal to the highest power. Can anyone explain what's happening here please? I am not a Mathematician, so please keep it as simple as possible .","My son's Maths homework was to do with number patterns/sequences. ""What is the nth term?"". He'd done very well, but the last sequence was something like this: 19,77,265,715,1607,3169 He was adamant that he didn't have a technique for solving it and that it must be a ""fake"" question. However, something about the numbers looked like there could be a pattern so I did a bit of investigating. I put them into a spreadsheet and found the differences between consecutive numbers: 58, 188, 450, 892, 1562 No clues. I decided to find the differences of this list: 130, 262, 442, 670 They appear to be getting less diverse with each step: 132, 180, 228 Then: 48, 48 I found that I could generate a list like this using a formula: $$\begin{align}ax^n+bx^p+cx^q+dx+y\end{align}$$ I can have as many power terms as I like but difference always resolves after a number of steps equal to the highest power. Can anyone explain what's happening here please? I am not a Mathematician, so please keep it as simple as possible .",,['sequences-and-series']
87,"Why does Khinchin's constant ""work""?","Why does Khinchin's constant ""work""?",,"I apologize if I missed an existing question on this, perhaps with a different spelling of Khinchin's name. I feel like I'm missing something basic. From Wikipedia , almost all real numbers have a continued fraction representation whose terms have a geometric mean of $K_0=2.685...$ From the definition of ""almost all"", I would understand that there is an at-most-countable set of counter-examples, ie real numbers with continued fraction representations whose terms have a different geometric mean. But I also see here that continued fractions provide a homeomorphism between real numbers and and sequences of positive integers, seemingly confirming the intuition that the two sets should be isomorphic. This seems to imply that there should be only a countable number of positive integer sequences with a geometric mean different from Khinchin's constant. But this seems preposterous! If nothing else, we should be able to generate uncountably many sequences with a geometric mean of $2K_0$, by simply doubling the terms of any ""normal"" sequence with a mean of $K_0$. Where did I go wrong?","I apologize if I missed an existing question on this, perhaps with a different spelling of Khinchin's name. I feel like I'm missing something basic. From Wikipedia , almost all real numbers have a continued fraction representation whose terms have a geometric mean of $K_0=2.685...$ From the definition of ""almost all"", I would understand that there is an at-most-countable set of counter-examples, ie real numbers with continued fraction representations whose terms have a different geometric mean. But I also see here that continued fractions provide a homeomorphism between real numbers and and sequences of positive integers, seemingly confirming the intuition that the two sets should be isomorphic. This seems to imply that there should be only a countable number of positive integer sequences with a geometric mean different from Khinchin's constant. But this seems preposterous! If nothing else, we should be able to generate uncountably many sequences with a geometric mean of $2K_0$, by simply doubling the terms of any ""normal"" sequence with a mean of $K_0$. Where did I go wrong?",,"['sequences-and-series', 'continued-fractions']"
88,Different proofs of $\lim\limits_{n \rightarrow \infty} n \int_0^1 \frac{x^n - (1-x)^n}{2x-1} \mathrm dx= 2$,Different proofs of,\lim\limits_{n \rightarrow \infty} n \int_0^1 \frac{x^n - (1-x)^n}{2x-1} \mathrm dx= 2,"It can be shown that $$ n \int_0^1 \frac{x^n - (1-x)^n}{2x-1} \mathrm dx = \sum_{k=0}^{n-1} {n-1 \choose k}^{-1}$$ (For instance see my answer here .) It can also be shown that $$\lim_{n \to \infty} \ \sum_{k=0}^{n-1} {n-1 \choose k}^{-1} = 2$$ (For instance see Qiaochu's answer here .) Combining those two shows that $$ \lim_{n \to \infty} \ n \int_0^1 \frac{x^n - (1-x)^n}{2x-1} \mathrm dx  = 2$$ Is there a different, (preferably analytic) proof of this fact? Please do feel free to add a proof which is not analytic.","It can be shown that $$ n \int_0^1 \frac{x^n - (1-x)^n}{2x-1} \mathrm dx = \sum_{k=0}^{n-1} {n-1 \choose k}^{-1}$$ (For instance see my answer here .) It can also be shown that $$\lim_{n \to \infty} \ \sum_{k=0}^{n-1} {n-1 \choose k}^{-1} = 2$$ (For instance see Qiaochu's answer here .) Combining those two shows that $$ \lim_{n \to \infty} \ n \int_0^1 \frac{x^n - (1-x)^n}{2x-1} \mathrm dx  = 2$$ Is there a different, (preferably analytic) proof of this fact? Please do feel free to add a proof which is not analytic.",,"['analysis', 'sequences-and-series']"
89,"Cover $\{1,2,...,100\}$ with minimum number of geometric progressions?",Cover  with minimum number of geometric progressions?,"\{1,2,...,100\}","In another question, posted here by jordan , we are asked whether it is possible to cover the numbers $\{1,2,\ldots,100\}$ with $20$ geometric sequences of real numbers. Naturally, we would like to extend the question: Problem: What is the minimum number $n$ of geometric progressions $A_1, A_2,\ldots,A_{n}$ of rational* numbers such that $$ \{1,2,\ldots,100\} \subseteq A_1 \cup A_2\cup \ldots\cup A_{n}? $$ In the other question, 6005 obtained a lower bound of $31 \leq n$ with an argument about square free integers. We can also obtain an upper bound of $43$ as follows. Consider these $5$ sequences: $[1, 2, 4, 8, 16, 32, 64]$ and $[6, 12, 24, 48, 96]$ and $[5, 10, 20, 40, 80]$ and $[3, 9, 27, 81]$ and $[7, 21, 63]$ . Together, these cover $7 + 5 + 5 + 4 + 3 = 24$ terms. The remaining $76$ terms can be covered in at most $38$ sequences, by an argument made here . So we have the bound: $$31 \leq n \leq 43$$ Can anyone do better? *We need only consider rational ratios by arguments made in answers to the original question. (Update) We have a winner!! Thanks to the cumulative efforts of the answerers below, we have arrived at $n = 36$ . The upper bound is thanks to jpvee, and the lower bound is due to san. Hooray!","In another question, posted here by jordan , we are asked whether it is possible to cover the numbers with geometric sequences of real numbers. Naturally, we would like to extend the question: Problem: What is the minimum number of geometric progressions of rational* numbers such that In the other question, 6005 obtained a lower bound of with an argument about square free integers. We can also obtain an upper bound of as follows. Consider these sequences: and and and and . Together, these cover terms. The remaining terms can be covered in at most sequences, by an argument made here . So we have the bound: Can anyone do better? *We need only consider rational ratios by arguments made in answers to the original question. (Update) We have a winner!! Thanks to the cumulative efforts of the answerers below, we have arrived at . The upper bound is thanks to jpvee, and the lower bound is due to san. Hooray!","\{1,2,\ldots,100\} 20 n A_1, A_2,\ldots,A_{n} 
\{1,2,\ldots,100\} \subseteq A_1 \cup A_2\cup \ldots\cup A_{n}?
 31 \leq n 43 5 [1, 2, 4, 8, 16, 32, 64] [6, 12, 24, 48, 96] [5, 10, 20, 40, 80] [3, 9, 27, 81] [7, 21, 63] 7 + 5 + 5 + 4 + 3 = 24 76 38 31 \leq n \leq 43 n = 36","['sequences-and-series', 'combinatorics', 'number-theory', 'elementary-number-theory', 'geometric-progressions']"
90,The set of all infinite binary sequences,The set of all infinite binary sequences,,"Let's assume that there exists the set $S$ of all possible infinite binary sequences $s_i$ : $$S=\{s_1,s_2,\ldots s_i \ldots\}$$ The sequences $s_i$ are such as $\{1,1,1,1,\ldots\}$ , $\{0,0,0,0,\ldots\}$ , $\{0,1,0,1,\ldots\}$ etc. Following the Cantor's diagonal argument we can construct a sequence $s_0$ that is not in the set $S$ . So there is a contradiction because we had assumed that the set $S$ contains ALL such infinite sequences of $1$ 's or $0$ 's. If we add the $s_0$ to $S$ , then we can again construct another $s_0'$ that will not be in the set $S$ , and so on. Where's the problem with my reasoning? How do we define/construct the set that contains all such sequences?","Let's assume that there exists the set of all possible infinite binary sequences : The sequences are such as , , etc. Following the Cantor's diagonal argument we can construct a sequence that is not in the set . So there is a contradiction because we had assumed that the set contains ALL such infinite sequences of 's or 's. If we add the to , then we can again construct another that will not be in the set , and so on. Where's the problem with my reasoning? How do we define/construct the set that contains all such sequences?","S s_i S=\{s_1,s_2,\ldots s_i \ldots\} s_i \{1,1,1,1,\ldots\} \{0,0,0,0,\ldots\} \{0,1,0,1,\ldots\} s_0 S S 1 0 s_0 S s_0' S","['sequences-and-series', 'elementary-set-theory', 'paradoxes']"
91,"Closed form for $\sum_{n=0}^\infty\frac{\Gamma\left(n+\tfrac14\right)}{2^n\,(4n+1)^2\,n!}$",Closed form for,"\sum_{n=0}^\infty\frac{\Gamma\left(n+\tfrac14\right)}{2^n\,(4n+1)^2\,n!}","I was experimenting with hypergeometric-like series and discovered the following conjecture (so far confirmed by more than $5000$ decimal digits): $$\sum_{n=0}^\infty\frac{\Gamma\!\left(n+\tfrac14\right)}{2^n\,(4n+1)^2\,n!}\stackrel{\color{gray}?}=$$ $$\frac{\Gamma\!\left(\tfrac14\right)\sqrt[4]2}{192}\left[\vphantom{\huge|}6\sqrt{2}\left(2\pi\ln2-\ln^22-8\operatorname{Li}_2\left(\tfrac1{\sqrt2}\right)\right)+3\psi^{(1)}\!\left(\tfrac18\right)-48G+\left(\vphantom{\large|}7\sqrt2-6\right)\pi^2\right]$$ where $G$ is the Catalan constant , $\operatorname{Li}_2(x)$ is the dilogarithm and $\psi^{(1)}(x)$ is the trigamma function. Could you suggest any ideas how to prove it? To see what approach I use to find conjectures like this, see my another question . Update: I've found a generalization of this conjecture. See the corresponding Mathematica expression here . Hopefully, it can be simplified.","I was experimenting with hypergeometric-like series and discovered the following conjecture (so far confirmed by more than decimal digits): where is the Catalan constant , is the dilogarithm and is the trigamma function. Could you suggest any ideas how to prove it? To see what approach I use to find conjectures like this, see my another question . Update: I've found a generalization of this conjecture. See the corresponding Mathematica expression here . Hopefully, it can be simplified.","5000 \sum_{n=0}^\infty\frac{\Gamma\!\left(n+\tfrac14\right)}{2^n\,(4n+1)^2\,n!}\stackrel{\color{gray}?}= \frac{\Gamma\!\left(\tfrac14\right)\sqrt[4]2}{192}\left[\vphantom{\huge|}6\sqrt{2}\left(2\pi\ln2-\ln^22-8\operatorname{Li}_2\left(\tfrac1{\sqrt2}\right)\right)+3\psi^{(1)}\!\left(\tfrac18\right)-48G+\left(\vphantom{\large|}7\sqrt2-6\right)\pi^2\right] G \operatorname{Li}_2(x) \psi^{(1)}(x)","['sequences-and-series', 'hypergeometric-function', 'polylogarithm', 'experimental-mathematics', 'polygamma']"
92,Summation of infinite series with hyperbolic sine,Summation of infinite series with hyperbolic sine,,"The following is a conjecture. I would like to prove that $$\sum_{n=0}^\infty \frac{1}{(2n+1)\operatorname{sinh}((2n+1)\pi)}=\frac{\log(2)}{8}.$$ Both sides agree to at least $100$ digits, so I suspect the identity is true. I have thought about expanding $1/\operatorname{sinh}$ as a series and switching the summation, but I can't get this to work.","The following is a conjecture. I would like to prove that $$\sum_{n=0}^\infty \frac{1}{(2n+1)\operatorname{sinh}((2n+1)\pi)}=\frac{\log(2)}{8}.$$ Both sides agree to at least $100$ digits, so I suspect the identity is true. I have thought about expanding $1/\operatorname{sinh}$ as a series and switching the summation, but I can't get this to work.",,['sequences-and-series']
93,How to find $\sum_{n=0}^{\infty}(-1)^{n}\left(\frac{1}{n+1}-\frac{1}{n+2}+\frac{1}{n+3}-\cdots\right)^{2}$,How to find,\sum_{n=0}^{\infty}(-1)^{n}\left(\frac{1}{n+1}-\frac{1}{n+2}+\frac{1}{n+3}-\cdots\right)^{2},"Find the value $$\sum\limits_{n=0}^{\infty}(-1)^{n}\left(\frac{1}{n+1}-\frac{1}{n+2}+\frac{1}{n+3}-\cdots\right)^{2}.$$ This problem is from this and I am interested in this problem, but I can't solve it. Here is my idea: $$(-1)^{k-1}\dfrac{1}{n+k}=(-1)^{-n}\int_{0}^{-1}x^{n+k-1}dx$$ so \begin{align*}\sum\limits_{n=0}^{\infty}(-1)^{n}\left(\frac{1}{n+1}-\frac{1}{n+2}+\frac{1}{n+3}-\cdots\right)^{2}&=\sum_{n=0}^{\infty}(-1)^n\left(\sum_{k=1}^{\infty}(-1)^n\int_{0}^{-1}x^{n+k-1}dx\right)^2\\ &=\sum_{n=0}^{\infty}(-1)^n\left(\int_{0}^{-1}\sum_{k=1}^{\infty}x^{n+k-1}dx\right)^2\\ &=\sum_{n=0}^{\infty}(-1)^n\left(\int_{0}^{-1}\dfrac{x^n}{1-x} dx \right)^2. \end{align*}","Find the value This problem is from this and I am interested in this problem, but I can't solve it. Here is my idea: so","\sum\limits_{n=0}^{\infty}(-1)^{n}\left(\frac{1}{n+1}-\frac{1}{n+2}+\frac{1}{n+3}-\cdots\right)^{2}. (-1)^{k-1}\dfrac{1}{n+k}=(-1)^{-n}\int_{0}^{-1}x^{n+k-1}dx \begin{align*}\sum\limits_{n=0}^{\infty}(-1)^{n}\left(\frac{1}{n+1}-\frac{1}{n+2}+\frac{1}{n+3}-\cdots\right)^{2}&=\sum_{n=0}^{\infty}(-1)^n\left(\sum_{k=1}^{\infty}(-1)^n\int_{0}^{-1}x^{n+k-1}dx\right)^2\\
&=\sum_{n=0}^{\infty}(-1)^n\left(\int_{0}^{-1}\sum_{k=1}^{\infty}x^{n+k-1}dx\right)^2\\
&=\sum_{n=0}^{\infty}(-1)^n\left(\int_{0}^{-1}\dfrac{x^n}{1-x} dx \right)^2.
\end{align*}","['sequences-and-series', 'summation']"
94,What would be the value of $\sum\limits_{n=0}^\infty \frac{1}{an^2+bn+c}$,What would be the value of,\sum\limits_{n=0}^\infty \frac{1}{an^2+bn+c},"I would like to evaluate the sum $$\sum_{n=0}^\infty \frac{1}{an^2+bn+c}$$ Here is my attempt: Letting $$f(z)=\frac{1}{az^2+bz+c}$$ The poles of $f(z)$ are located at $$z_0 = \frac{-b+\sqrt{b^2-4ac}}{2a}$$ and $$z_1 = \frac{-b-\sqrt{b^2-4ac}}{2a}$$ Then $$ b_0=\operatorname*{Res}_{z=z_0}\,\pi \cot (\pi z)f(z)= \lim_{z \to z_0} \frac{(z-z_0)\pi\cot (\pi z)}{az^2+bz+c}= \lim_{z \to z_0} \frac{\pi\cot (\pi z)+(z_0-z)\pi^2\csc^2 (\pi z)}{2az+b} $$ Using L'Hopital's rule. Continuing, we have the limit is $$ \lim_{z \to z_0} \frac{\pi\cot (\pi z)+(z_0-z)\pi^2\csc^2 (\pi z)}{2az+b}= \frac{\pi\cot (\pi z_0)}{2az_0+b} $$ For $z_0 \ne 0$ Similarly, we find $$b_1=\operatorname*{Res}_{z=z_1}\,\pi \cot (\pi z)f(z)=\frac{\pi\cot (\pi z_1)}{2az_1+b}$$ Then $$\sum_{n=-\infty}^\infty \frac{1}{an^2+bn+c} = -(b_0+b_1)=\\ -\pi\left( \frac{\cot (\pi z_0)}{2az_0+b} + \frac{\cot (\pi z_1)}{2az_1+b}\right)=  -\pi\left( \frac{\cot (\pi z_0)}{\sqrt{b^2-4ac}} + \frac{\cot (\pi z_1)}{-\sqrt{b^2-4ac}}\right)= \frac{-\pi(\cot (\pi z_0)-\cot (\pi z_1))}{\sqrt{b^2-4ac}}= \frac{\pi(\cot (\pi z_1)-\cot (\pi z_0))}{\sqrt{b^2-4ac}} $$ Then we have $$\sum_{n=0}^\infty \frac{1}{an^2+bn+c} = \frac{\pi(\cot (\pi z_1)-\cot (\pi z_0))}{2\sqrt{b^2-4ac}}$$ Is this correct?  I feel like I made a mistake somewhere.  Could someone correct me?  Is there an easier way to evaluate this sum?","I would like to evaluate the sum $$\sum_{n=0}^\infty \frac{1}{an^2+bn+c}$$ Here is my attempt: Letting $$f(z)=\frac{1}{az^2+bz+c}$$ The poles of $f(z)$ are located at $$z_0 = \frac{-b+\sqrt{b^2-4ac}}{2a}$$ and $$z_1 = \frac{-b-\sqrt{b^2-4ac}}{2a}$$ Then $$ b_0=\operatorname*{Res}_{z=z_0}\,\pi \cot (\pi z)f(z)= \lim_{z \to z_0} \frac{(z-z_0)\pi\cot (\pi z)}{az^2+bz+c}= \lim_{z \to z_0} \frac{\pi\cot (\pi z)+(z_0-z)\pi^2\csc^2 (\pi z)}{2az+b} $$ Using L'Hopital's rule. Continuing, we have the limit is $$ \lim_{z \to z_0} \frac{\pi\cot (\pi z)+(z_0-z)\pi^2\csc^2 (\pi z)}{2az+b}= \frac{\pi\cot (\pi z_0)}{2az_0+b} $$ For $z_0 \ne 0$ Similarly, we find $$b_1=\operatorname*{Res}_{z=z_1}\,\pi \cot (\pi z)f(z)=\frac{\pi\cot (\pi z_1)}{2az_1+b}$$ Then $$\sum_{n=-\infty}^\infty \frac{1}{an^2+bn+c} = -(b_0+b_1)=\\ -\pi\left( \frac{\cot (\pi z_0)}{2az_0+b} + \frac{\cot (\pi z_1)}{2az_1+b}\right)=  -\pi\left( \frac{\cot (\pi z_0)}{\sqrt{b^2-4ac}} + \frac{\cot (\pi z_1)}{-\sqrt{b^2-4ac}}\right)= \frac{-\pi(\cot (\pi z_0)-\cot (\pi z_1))}{\sqrt{b^2-4ac}}= \frac{\pi(\cot (\pi z_1)-\cot (\pi z_0))}{\sqrt{b^2-4ac}} $$ Then we have $$\sum_{n=0}^\infty \frac{1}{an^2+bn+c} = \frac{\pi(\cot (\pi z_1)-\cot (\pi z_0))}{2\sqrt{b^2-4ac}}$$ Is this correct?  I feel like I made a mistake somewhere.  Could someone correct me?  Is there an easier way to evaluate this sum?",,"['sequences-and-series', 'complex-analysis', 'quadratics']"
95,Is $\sum_{n=1}^{\infty}{\frac{\sin(nx)}n}$ continuous?,Is  continuous?,\sum_{n=1}^{\infty}{\frac{\sin(nx)}n},"Considering the infinite series $\sum_{n=1}^{\infty}{\frac{\sin(nx)}n}$ , I can show that  it is not convergent uniformly by Cauchy's criterion and that it is convergent for every $x$ by Dirichlet's test.  But I don't know how to judge whether it is continuous. Could you tell me the answer and why? Thank you in advance!","Considering the infinite series $\sum_{n=1}^{\infty}{\frac{\sin(nx)}n}$ , I can show that  it is not convergent uniformly by Cauchy's criterion and that it is convergent for every $x$ by Dirichlet's test.  But I don't know how to judge whether it is continuous. Could you tell me the answer and why? Thank you in advance!",,"['sequences-and-series', 'fourier-analysis', 'continuity', 'fourier-series']"
96,Repertoire Method Clarification Required ( Concrete Mathematics ),Repertoire Method Clarification Required ( Concrete Mathematics ),,"In the book Concrete Mathematics , chapter 2, section 2.2 -- sums and recurrences, page 26 (2nd edition), the authors talk about the following example: Given the general recurrence $$ R(0) = \alpha $$ $$ R(n) = R(n-1) + \beta + \epsilon n $$ The authors generalize the recurrence relation to: $$ R(n) = A(n)\alpha + B(n)\beta + C(n)\epsilon $$ Employing the Repertoire Method, the authors plug in simple functions of $n$ in order to determine $A(n), B(n), C(n)$. So they discover: Setting $R(n) = 1$ implies $\alpha = 1, \beta = 0, \epsilon = 0 \implies A(n) = 1$. Setting $R(n) = n$ implies $\alpha = 0, \beta = 1, \epsilon = 0 \implies B(n) = n$. Setting $R(n) = n^2$ implies $\alpha = 0, \beta = -1, \epsilon = 0 \implies C(n) = \frac{n^2 + n}{2}$. Values for the first couple of terms of the recurrence: $$ \begin{eqnarray*} R(0) &=& \alpha  \\ R(1) &=& \alpha  +   \beta + \epsilon  \\ R(2) &=& \alpha  + 2\beta +  3\epsilon  \\ R(3) &=& \alpha  + 3\beta +  6\epsilon  \\ R(4) &=& \alpha  + 4\beta + 10\epsilon  \\ R(5) &=& \alpha  + 5\beta + 15\epsilon  \end{eqnarray*} $$ I do not understand what is the process through which the values for $\alpha$, $\beta$, and $\epsilon$ are implied. I would like some help with that. Where exactly do we look and what do we math them against to see what they have to be?","In the book Concrete Mathematics , chapter 2, section 2.2 -- sums and recurrences, page 26 (2nd edition), the authors talk about the following example: Given the general recurrence $$ R(0) = \alpha $$ $$ R(n) = R(n-1) + \beta + \epsilon n $$ The authors generalize the recurrence relation to: $$ R(n) = A(n)\alpha + B(n)\beta + C(n)\epsilon $$ Employing the Repertoire Method, the authors plug in simple functions of $n$ in order to determine $A(n), B(n), C(n)$. So they discover: Setting $R(n) = 1$ implies $\alpha = 1, \beta = 0, \epsilon = 0 \implies A(n) = 1$. Setting $R(n) = n$ implies $\alpha = 0, \beta = 1, \epsilon = 0 \implies B(n) = n$. Setting $R(n) = n^2$ implies $\alpha = 0, \beta = -1, \epsilon = 0 \implies C(n) = \frac{n^2 + n}{2}$. Values for the first couple of terms of the recurrence: $$ \begin{eqnarray*} R(0) &=& \alpha  \\ R(1) &=& \alpha  +   \beta + \epsilon  \\ R(2) &=& \alpha  + 2\beta +  3\epsilon  \\ R(3) &=& \alpha  + 3\beta +  6\epsilon  \\ R(4) &=& \alpha  + 4\beta + 10\epsilon  \\ R(5) &=& \alpha  + 5\beta + 15\epsilon  \end{eqnarray*} $$ I do not understand what is the process through which the values for $\alpha$, $\beta$, and $\epsilon$ are implied. I would like some help with that. Where exactly do we look and what do we math them against to see what they have to be?",,"['sequences-and-series', 'recurrence-relations']"
97,"Looking for a closed form for a ${}_4 F_3\left(\ldots,1\right)$",Looking for a closed form for a,"{}_4 F_3\left(\ldots,1\right)","This question originates from this recent question of Paramanand Singh about a series computed by Ramanujan, probably related to elliptic integrals and Legendre functions. Is there a closed form for   $$ {}_4 F_3\left(\tfrac{1}{2},\tfrac{1}{2},\tfrac{1}{2},\tfrac{1}{2};1,1,1;1\right)=\sum_{n\geq 0}\left[\frac{1}{4^n}\binom{2n}{n}\right]^4=\frac{8}{\pi^3}\int_{0}^{\frac{1}{2}}\frac{K(m)^2}{\sqrt{m(1-m)}}\,dm $$   ? Many proofs of $\sum_{n\geq 0}\left[\frac{1}{4^n}\binom{2n}{n}\right]^3=\frac{\pi}{\Gamma\left(\frac{3}{4}\right)^4}$ are well-known, for instance through Clausen formula or Fourier-Legendre series expansions (pages 27-28 here ). Such methods do not seem to apply smoothly for computing a closed form for the RHS, neither Parseval's identity applied to $$ \sum_{n\geq 0}\left[\frac{1}{4^n}\binom{2n}{n}\right]^2 e^{ni\theta} = \frac{2}{\pi}\,K(e^{i\theta})$$ where $e^{i\theta}$ is regarded as the elliptic modulus. Suggestions are welcome.","This question originates from this recent question of Paramanand Singh about a series computed by Ramanujan, probably related to elliptic integrals and Legendre functions. Is there a closed form for   $$ {}_4 F_3\left(\tfrac{1}{2},\tfrac{1}{2},\tfrac{1}{2},\tfrac{1}{2};1,1,1;1\right)=\sum_{n\geq 0}\left[\frac{1}{4^n}\binom{2n}{n}\right]^4=\frac{8}{\pi^3}\int_{0}^{\frac{1}{2}}\frac{K(m)^2}{\sqrt{m(1-m)}}\,dm $$   ? Many proofs of $\sum_{n\geq 0}\left[\frac{1}{4^n}\binom{2n}{n}\right]^3=\frac{\pi}{\Gamma\left(\frac{3}{4}\right)^4}$ are well-known, for instance through Clausen formula or Fourier-Legendre series expansions (pages 27-28 here ). Such methods do not seem to apply smoothly for computing a closed form for the RHS, neither Parseval's identity applied to $$ \sum_{n\geq 0}\left[\frac{1}{4^n}\binom{2n}{n}\right]^2 e^{ni\theta} = \frac{2}{\pi}\,K(e^{i\theta})$$ where $e^{i\theta}$ is regarded as the elliptic modulus. Suggestions are welcome.",,"['sequences-and-series', 'special-functions', 'closed-form', 'hypergeometric-function', 'elliptic-integrals']"
98,Show that $\sum\limits_{n\ge1}\frac1{n^2}=\sum\limits_{n\ge1}\frac3{n^2\binom{2n}n}$ without actually evaluating both series,Show that  without actually evaluating both series,\sum\limits_{n\ge1}\frac1{n^2}=\sum\limits_{n\ge1}\frac3{n^2\binom{2n}n},"$$\sum\limits_{n\ge1}\frac1{n^2}=\sum\limits_{n\ge1}\frac3{n^2\binom{2n}n}\tag1$$ Note that $(1)$ holds since the LHS is given by $\zeta(2)$ whereas the RHS by $6\arcsin^2 1$ which both equal $\dfrac{\pi^2}6$ as it is well-known. However, I am interested in proving $(1)$ without actually evaluating both series. I am aware of an elegant approach contributed by Markus Scheuer as an answer to Different methods to compute Basel problem . Although this answers my question partially I am looking for different attempts. For example within Jack D'Aurizio 's notes there is a way proposed exploiting creative telescoping $($ see page $5$ f. $)$ , which I do not understand completely (yet). Hence I have come across a proof of a similar equality concerning $\zeta(3)$ on AoPS given by pprime I am confident that there are in fact other possible methods. I would like to see attempts of proving $(1)$ besides the ones mentioned which do not rely on actually showing that they both equal $\dfrac{\pi^2}6$ . Preferably these should be in the spirit of Markus Scheuer 's or Jack D'Aurizio 's approaches rather than the one similar by pprime . Thanks in advance! EDIT I I have found another interesting approach, again by Jack D'Aurizio , which can be found here utilizing harmonic sums and creative telescoping in combination. EDIT II As pointed out by Zacky on page $31$ of Jack 's notes another method can be found which makes it three possibilities provided by Jack alone. Quite impressive!","Note that holds since the LHS is given by whereas the RHS by which both equal as it is well-known. However, I am interested in proving without actually evaluating both series. I am aware of an elegant approach contributed by Markus Scheuer as an answer to Different methods to compute Basel problem . Although this answers my question partially I am looking for different attempts. For example within Jack D'Aurizio 's notes there is a way proposed exploiting creative telescoping see page f. , which I do not understand completely (yet). Hence I have come across a proof of a similar equality concerning on AoPS given by pprime I am confident that there are in fact other possible methods. I would like to see attempts of proving besides the ones mentioned which do not rely on actually showing that they both equal . Preferably these should be in the spirit of Markus Scheuer 's or Jack D'Aurizio 's approaches rather than the one similar by pprime . Thanks in advance! EDIT I I have found another interesting approach, again by Jack D'Aurizio , which can be found here utilizing harmonic sums and creative telescoping in combination. EDIT II As pointed out by Zacky on page of Jack 's notes another method can be found which makes it three possibilities provided by Jack alone. Quite impressive!",\sum\limits_{n\ge1}\frac1{n^2}=\sum\limits_{n\ge1}\frac3{n^2\binom{2n}n}\tag1 (1) \zeta(2) 6\arcsin^2 1 \dfrac{\pi^2}6 (1) ( 5 ) \zeta(3) (1) \dfrac{\pi^2}6 31,"['sequences-and-series', 'alternative-proof']"
99,Showing that $a_{n+1}=\frac{n}{a_n}-a_n-a_{n-1}$ with $a_0 = 0$ and $a_1=2\Gamma(\frac34)\big/\Gamma(\frac14)$ stays positive for $n\geq1$.,Showing that  with  and  stays positive for .,a_{n+1}=\frac{n}{a_n}-a_n-a_{n-1} a_0 = 0 a_1=2\Gamma(\frac34)\big/\Gamma(\frac14) n\geq1,"This posting consists of several mildly-related questions, motivated from this posting . The main object is the following sequence. $$a_0 = 0, \qquad a_1 = x, \qquad a_{n+1} = \frac{n}{a_n} - a_n - a_{n-1}. \tag{*}$$ Question 1. Numerical experiment suggests that there is a unique value of $x$ for which $a_n > 0$ for all $n \geq 1$ . Can we prove/disprove this? If we write $I_n = \{ x \in \mathbb{R} : a_1 > 0, \cdots, a_n > 0\}$ , then obviously $I_n$ is a nested sequence of open sets that begins with $I_1 = (0, \infty)$ . Moreover, the experiment suggests that $I_n$ are all intervals, and the endpoints of $I_n$ are adjacent poles of $a_{n+1}$ and $a_{n+1}$ is strictly monotone on $I_n$ . Provided this is correct, we easily see that there is a unique zero of $a_{n+1}$ on $I_{n+1}$ , which then determines $I_{n+1}$ . Question 2. The same experiment also suggests that the value of such unique $x$ is $$ \frac{\operatorname{AGM}(1,\sqrt{2})}{\sqrt{\pi}} = \frac{2\Gamma\left(\frac{3}{4}\right)}{\Gamma\left(\frac{1}{4}\right)} \approx 0.675978240067284728995\cdots.$$ At this point, I completely have no idea why this value arises, but I have checked that this is correct up to hundreds of digits. (I progressively refined the range of $x$ so that $a_n$ stays positive for a longer time.) Again, will it ever have a chance to be proved? My original suspicion was that we may rearrange the recurrence relation to obtain continued fraction, but it was of no avail. To be honest, I have never seen this type of problem, and will be glad if I can learn anything new about it. Question 3. Given that the above question seems to bold to answer, perhaps we may consider its variants: (Variant 1) $a_0 = 0$ , $a_1 = x$ , and $a_{n+1} = \frac{n}{a_n} - a_n - p a_{n-1}$ , where $p \in \mathbb{R}$ . (Variant 2) $a_0 = 0$ , $a_1 = x$ , and $a_{n+1} = \frac{1}{a_n} - a_n - a_{n-1}$ . (Variant 3) $a_0 = 0$ , $a_1 = x$ , and $a_{n+1} = \frac{n^2}{a_n} - a_n - a_{n-1}$ . Again, in each case, numerical experiment suggests that there is a unique $x$ for which $(a_n)_{n\geq 1}$ stays positive. Moreover, For Variant 1, it seems that $x = 1/\sqrt{3}$ for $p = -2$ but I have no guess for general $p$ , even when it is an integer. For Variant 2, it is conjectured that $x = 4/3\sqrt{3}$ . For Variant 3, we can check that $x = 1/\sqrt{3}$ is such one. Indeed, we find that $a_n = n/\sqrt{3}$ solves the recurrence relation. Then we may ask whether the version of Question 1-2 can be proved for these variants. Progress. I managed to answer Question 1 . Check this answer .","This posting consists of several mildly-related questions, motivated from this posting . The main object is the following sequence. Question 1. Numerical experiment suggests that there is a unique value of for which for all . Can we prove/disprove this? If we write , then obviously is a nested sequence of open sets that begins with . Moreover, the experiment suggests that are all intervals, and the endpoints of are adjacent poles of and is strictly monotone on . Provided this is correct, we easily see that there is a unique zero of on , which then determines . Question 2. The same experiment also suggests that the value of such unique is At this point, I completely have no idea why this value arises, but I have checked that this is correct up to hundreds of digits. (I progressively refined the range of so that stays positive for a longer time.) Again, will it ever have a chance to be proved? My original suspicion was that we may rearrange the recurrence relation to obtain continued fraction, but it was of no avail. To be honest, I have never seen this type of problem, and will be glad if I can learn anything new about it. Question 3. Given that the above question seems to bold to answer, perhaps we may consider its variants: (Variant 1) , , and , where . (Variant 2) , , and . (Variant 3) , , and . Again, in each case, numerical experiment suggests that there is a unique for which stays positive. Moreover, For Variant 1, it seems that for but I have no guess for general , even when it is an integer. For Variant 2, it is conjectured that . For Variant 3, we can check that is such one. Indeed, we find that solves the recurrence relation. Then we may ask whether the version of Question 1-2 can be proved for these variants. Progress. I managed to answer Question 1 . Check this answer .","a_0 = 0, \qquad a_1 = x, \qquad a_{n+1} = \frac{n}{a_n} - a_n - a_{n-1}. \tag{*} x a_n > 0 n \geq 1 I_n = \{ x \in \mathbb{R} : a_1 > 0, \cdots, a_n > 0\} I_n I_1 = (0, \infty) I_n I_n a_{n+1} a_{n+1} I_n a_{n+1} I_{n+1} I_{n+1} x  \frac{\operatorname{AGM}(1,\sqrt{2})}{\sqrt{\pi}}
= \frac{2\Gamma\left(\frac{3}{4}\right)}{\Gamma\left(\frac{1}{4}\right)}
\approx 0.675978240067284728995\cdots. x a_n a_0 = 0 a_1 = x a_{n+1} = \frac{n}{a_n} - a_n - p a_{n-1} p \in \mathbb{R} a_0 = 0 a_1 = x a_{n+1} = \frac{1}{a_n} - a_n - a_{n-1} a_0 = 0 a_1 = x a_{n+1} = \frac{n^2}{a_n} - a_n - a_{n-1} x (a_n)_{n\geq 1} x = 1/\sqrt{3} p = -2 p x = 4/3\sqrt{3} x = 1/\sqrt{3} a_n = n/\sqrt{3}","['sequences-and-series', 'analysis']"
