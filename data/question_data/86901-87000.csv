,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Relationship of the support of a test function with the support of distribution.,Relationship of the support of a test function with the support of distribution.,,"Let $\phi\in D(\Omega)$ and $f\in D'(\Omega)$. If $\phi$ is $0$ in a neighbourhood of $\operatorname{supp}(f)$, then how will we prove that $\langle f, \phi \rangle$ is also $0$? Will it be sufficient if $\phi$ vanishes on $\operatorname{supp}(f)$? Definition of $\operatorname{supp}(f)$: Let $f$ be a distribution, and $U$ an open set in $\Bbb R^n$ such that, for all test functions $\phi$ with the support of $\phi$ contained in $U$, $f(\phi) = 0$. Then $f$ is said to vanish on $U$. Hence we can define the support of $f$ as the complement of the largest open set on which $f$ vanishes. Alternatively, we can say $\operatorname{supp}(f)$ is the subset of $\Bbb R^n$ such that $x \in \operatorname{supp}(f)$, if and only if for all neighbourhoods $\mathcal U$ of $x$, there is $\phi \in D(\mathcal U)$ such that $\langle f, \phi\rangle \neq 0$.","Let $\phi\in D(\Omega)$ and $f\in D'(\Omega)$. If $\phi$ is $0$ in a neighbourhood of $\operatorname{supp}(f)$, then how will we prove that $\langle f, \phi \rangle$ is also $0$? Will it be sufficient if $\phi$ vanishes on $\operatorname{supp}(f)$? Definition of $\operatorname{supp}(f)$: Let $f$ be a distribution, and $U$ an open set in $\Bbb R^n$ such that, for all test functions $\phi$ with the support of $\phi$ contained in $U$, $f(\phi) = 0$. Then $f$ is said to vanish on $U$. Hence we can define the support of $f$ as the complement of the largest open set on which $f$ vanishes. Alternatively, we can say $\operatorname{supp}(f)$ is the subset of $\Bbb R^n$ such that $x \in \operatorname{supp}(f)$, if and only if for all neighbourhoods $\mathcal U$ of $x$, there is $\phi \in D(\mathcal U)$ such that $\langle f, \phi\rangle \neq 0$.",,"['functional-analysis', 'distribution-theory']"
1,"Is $C^{k,\alpha}(\mathbb R^n)$ reflexive?",Is  reflexive?,"C^{k,\alpha}(\mathbb R^n)","Here $C^{k,\alpha}(\mathbb R^n)$ refers to the usual Banach space of functions  that are $k$ times continuously differentiable, have bounded derivatives, and whose $k$th derivatives have finite Hoelder norm, with Hoelder exponent $\alpha$. Motivation: I am taking an introductory functional analysis class, and I wonder if the  Banach-Alaoglu theorem can be used to prove the Arzela-Ascoli theorem.","Here $C^{k,\alpha}(\mathbb R^n)$ refers to the usual Banach space of functions  that are $k$ times continuously differentiable, have bounded derivatives, and whose $k$th derivatives have finite Hoelder norm, with Hoelder exponent $\alpha$. Motivation: I am taking an introductory functional analysis class, and I wonder if the  Banach-Alaoglu theorem can be used to prove the Arzela-Ascoli theorem.",,['functional-analysis']
2,Is the inclusion map of $\ell^1$ into $\ell^2$ a closed map?,Is the inclusion map of  into  a closed map?,\ell^1 \ell^2,"In particular, I'm interested in the subset $\{x : \lVert x\rVert_1 \ge 1\}$ inside $\ell^2$. Is this a closed subset? thank you!","In particular, I'm interested in the subset $\{x : \lVert x\rVert_1 \ge 1\}$ inside $\ell^2$. Is this a closed subset? thank you!",,"['functional-analysis', 'lp-spaces']"
3,Inverse of inverse of function?,Inverse of inverse of function?,,What is the inverse of inverse of a function (I assume the original function is invertible)? Is this the original function? Is it always true?,What is the inverse of inverse of a function (I assume the original function is invertible)? Is this the original function? Is it always true?,,"['functional-analysis', 'functions', 'inverse']"
4,$\sigma(x)$ has no hole in the algebra of polynomials,has no hole in the algebra of polynomials,\sigma(x),Let $A$ be a unital banach algebra generated by two elements $1$ and $x$. Then it seems $\sigma(x)$ cannot have holes. At least this is true in the case for disk algebras. This amounts to prove that $\mathbb{C}\backslash\sigma(x)$ is connected. I tried something but failed. Can somebody give a hint? Thanks!,Let $A$ be a unital banach algebra generated by two elements $1$ and $x$. Then it seems $\sigma(x)$ cannot have holes. At least this is true in the case for disk algebras. This amounts to prove that $\mathbb{C}\backslash\sigma(x)$ is connected. I tried something but failed. Can somebody give a hint? Thanks!,,"['functional-analysis', 'banach-spaces', 'operator-theory', 'spectral-theory', 'banach-algebras']"
5,Minimal projections in a C* algebra,Minimal projections in a C* algebra,,"Let $e$ be a projection in a C* algebra $A$.  Is $eAe= \mathbb{C}e$ equivalent to the nonexistence of any projection in between $e$ and $0$?  I know it is true if $A$ is a Von Neumann algebra because then you can use the Borel functional calculus.  Takesaki states that the definition of minimality of a projection is $eAe= \mathbb{C}e$ ""because it means"" that there are no projections in between $e$ and $0$.  I can't tell if ""because it means"" means ""implies"" or ""is equivalent to.""","Let $e$ be a projection in a C* algebra $A$.  Is $eAe= \mathbb{C}e$ equivalent to the nonexistence of any projection in between $e$ and $0$?  I know it is true if $A$ is a Von Neumann algebra because then you can use the Borel functional calculus.  Takesaki states that the definition of minimality of a projection is $eAe= \mathbb{C}e$ ""because it means"" that there are no projections in between $e$ and $0$.  I can't tell if ""because it means"" means ""implies"" or ""is equivalent to.""",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
6,Is $f$ injective in $W$?,Is  injective in ?,f W,"If $\|f(x)-f(y)\|\geqslant \frac 1{2} \|x-y\|$ for any $x, y \in W$ then $f$ is injective in $W$ How to prove this? If that inequality is right is it mean that the images are equal or not?","If $\|f(x)-f(y)\|\geqslant \frac 1{2} \|x-y\|$ for any $x, y \in W$ then $f$ is injective in $W$ How to prove this? If that inequality is right is it mean that the images are equal or not?",,['functional-analysis']
7,"Nonexistence of a certain norm on $C[0,1]$",Nonexistence of a certain norm on,"C[0,1]","Question: Let $X=C[0,1]$, show that there is no such norm $\lVert\cdot\rVert_*$ on $X$ that for any series $\{f_n\}_{n=1}^{\infty}\subset X$, $$\lim_{n\to\infty}\lVert f_n\rVert_*\to 0\Longleftrightarrow \lim_{n\to\infty}f_n(t)=0,\quad\forall t\in[0,1]$$ ============ I've tried to define a new norm (supposing such $\lVert\cdot\rVert_*$ exists): $$\lVert f\rVert_+=\lVert f\rVert_*+\max_{t\in[0,1]}|f(t)|=\lVert f\rVert_*+\lVert f\rVert_C$$ it is easy to show that $\lVert\cdot\rVert_+$ is a complete norm on $X$ (so is $\lVert\cdot\rVert_C$), and this implies $\lVert\cdot\rVert_+$ and $\lVert\cdot\rVert_C$ are equivalent norms, so there is a constant $M$ s.t. $$\lVert f\rVert_*\leq M\lVert f\rVert_C,\quad f\in X$$ and I got stuck at the above inequality (or maybe it is useless).","Question: Let $X=C[0,1]$, show that there is no such norm $\lVert\cdot\rVert_*$ on $X$ that for any series $\{f_n\}_{n=1}^{\infty}\subset X$, $$\lim_{n\to\infty}\lVert f_n\rVert_*\to 0\Longleftrightarrow \lim_{n\to\infty}f_n(t)=0,\quad\forall t\in[0,1]$$ ============ I've tried to define a new norm (supposing such $\lVert\cdot\rVert_*$ exists): $$\lVert f\rVert_+=\lVert f\rVert_*+\max_{t\in[0,1]}|f(t)|=\lVert f\rVert_*+\lVert f\rVert_C$$ it is easy to show that $\lVert\cdot\rVert_+$ is a complete norm on $X$ (so is $\lVert\cdot\rVert_C$), and this implies $\lVert\cdot\rVert_+$ and $\lVert\cdot\rVert_C$ are equivalent norms, so there is a constant $M$ s.t. $$\lVert f\rVert_*\leq M\lVert f\rVert_C,\quad f\in X$$ and I got stuck at the above inequality (or maybe it is useless).",,['functional-analysis']
8,Explicit examples of functions with flow?,Explicit examples of functions with flow?,,"Let's say that $f(x)=f^{1}(x)$ and that $f(f(x))=f^{2}(x)$. Moreover, $f^{n}(x)$ is the n-th iterate of $f(x)$, for $n \in \mathbb{N}$. I'm curious about extending iteration to larger number sets. For $n \in \mathbb{R}$, there's the concept flow (I think?). I don't understand the Wikipedia-article on this subject very well, though. I was hoping for some nice, concrete examples of iterated functions extended to the real or even complex numbers with which I might understand things better. If we take $f(x) = x^2 +3$, for example, what would $f^{\sqrt(2)}(x)$ be? Or, even more ambitiously, say that $g(x)=e^x$ How do we find $g^{\pi^2 + 3i}(x)$? Thanks, Max Muller Editorial to the moderators: perhaps this should be CW?","Let's say that $f(x)=f^{1}(x)$ and that $f(f(x))=f^{2}(x)$. Moreover, $f^{n}(x)$ is the n-th iterate of $f(x)$, for $n \in \mathbb{N}$. I'm curious about extending iteration to larger number sets. For $n \in \mathbb{R}$, there's the concept flow (I think?). I don't understand the Wikipedia-article on this subject very well, though. I was hoping for some nice, concrete examples of iterated functions extended to the real or even complex numbers with which I might understand things better. If we take $f(x) = x^2 +3$, for example, what would $f^{\sqrt(2)}(x)$ be? Or, even more ambitiously, say that $g(x)=e^x$ How do we find $g^{\pi^2 + 3i}(x)$? Thanks, Max Muller Editorial to the moderators: perhaps this should be CW?",,"['big-list', 'functional-analysis']"
9,Closed range of $T^*T$ for Hilbert space map.,Closed range of  for Hilbert space map.,T^*T,"Earlier today, I came across a paper that stated (but did not prove!) the following theorem. Theorem : Let $T:A \rightarrow B$ be a bounded linear Hilbert space map. Then the following are equivalent. $T$ has closed range; $T^*$ has closed range; $T^*T$ has closed range. The equivalence of (1) and (2) easily follows from the closed range theorem for Banach spaces. I have also managed to show that (1) + (2) implies 3 by using the identity $\text{image}(T) = \ker(T^*)^\perp$ , which holds when $T$ has closed range. This identity allows you to show that if $T$ has closed range, then $T^*T$ and $T^*$ have the same range. I am struggling to show that (3) implies the other conditions though. It seems like there should be a way to maybe take advantage of the fact that $\ker(T^*T) = \ker(T)$ and $\ker(T^*T)^\perp = \text{image}(T^*T)$ (since $T^*T$ has closed range). But I’m not seeing how to put the pieces together. If anyone has a reference for this result, or knows how to prove it, I’d appreciate it!","Earlier today, I came across a paper that stated (but did not prove!) the following theorem. Theorem : Let be a bounded linear Hilbert space map. Then the following are equivalent. has closed range; has closed range; has closed range. The equivalence of (1) and (2) easily follows from the closed range theorem for Banach spaces. I have also managed to show that (1) + (2) implies 3 by using the identity , which holds when has closed range. This identity allows you to show that if has closed range, then and have the same range. I am struggling to show that (3) implies the other conditions though. It seems like there should be a way to maybe take advantage of the fact that and (since has closed range). But I’m not seeing how to put the pieces together. If anyone has a reference for this result, or knows how to prove it, I’d appreciate it!",T:A \rightarrow B T T^* T^*T \text{image}(T) = \ker(T^*)^\perp T T T^*T T^* \ker(T^*T) = \ker(T) \ker(T^*T)^\perp = \text{image}(T^*T) T^*T,"['functional-analysis', 'hilbert-spaces']"
10,Is there a linear operator $T$ such that $T(x^n) =f(n)x^{n-1}$? [closed],Is there a linear operator  such that ? [closed],T T(x^n) =f(n)x^{n-1},"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 3 months ago . Improve this question When I first learnt calculus I was so surprised to learn that there is a meaningful mathematical operator $D$ that $$ D(x^n)= n x^{n-1}. $$ It seems to be a very random thing to multiply the exponent by the function and subtract one from the exponent to get the correct result. Again, this sounded very strange for me when I first learnt about derivatives, I mean if I was asked before I learnt the calculus of $D$ I would have dismissed this as a random useless property. Back then I thought about this question: is there a mathematical operator $T$ such that $$ T(x^n) =f(n)x^{n-1}\;? $$ After $6$ years now I remembered the question and I modified it as follows: can a linear operator $T$ defined on the vector space of all vector space of all polynomials and power series be such that $$ T(x^n) =f(n)x^{n-1}\quad \ n \ne 0  $$ for any continuous $f$ on $\mathbb{R}$ and can this operator be represented via known linear operator(s) (derivatives, integrals, etc. ), and known functions and $f$ ? After some thought I think the answer is no. Even a simple function like $f(x)=c\ne 0$ is very  hard to find and I couldn't find such representation.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 3 months ago . Improve this question When I first learnt calculus I was so surprised to learn that there is a meaningful mathematical operator that It seems to be a very random thing to multiply the exponent by the function and subtract one from the exponent to get the correct result. Again, this sounded very strange for me when I first learnt about derivatives, I mean if I was asked before I learnt the calculus of I would have dismissed this as a random useless property. Back then I thought about this question: is there a mathematical operator such that After years now I remembered the question and I modified it as follows: can a linear operator defined on the vector space of all vector space of all polynomials and power series be such that for any continuous on and can this operator be represented via known linear operator(s) (derivatives, integrals, etc. ), and known functions and ? After some thought I think the answer is no. Even a simple function like is very  hard to find and I couldn't find such representation.","D 
D(x^n)= n x^{n-1}.
 D T 
T(x^n) =f(n)x^{n-1}\;?
 6 T 
T(x^n) =f(n)x^{n-1}\quad \ n \ne 0 
 f \mathbb{R} f f(x)=c\ne 0","['real-analysis', 'calculus', 'functional-analysis', 'operator-theory']"
11,Papa Rudin $6.16$ theorem.,Papa Rudin  theorem.,6.16,"There is the theorem: Suppose $1\leq p \lt \infty $ , $\mu$ is a $\sigma$ -finite positive measure on $X$ , and $\phi$ is a bounded linear functional on $L^{p}(\mu)$ . Then there is a unique $g \in L^{q}(\mu)$ , where $q$ is the exponent conjugate to $p$ , such that $$\phi(f) = \int_{X} fg \ d\mu \ \ (f \in L^{p}(\mu)). $$ Moreover, if $\Phi$ and $g$ are related as mentioned above, we have $$ ||\phi|| = ||g||_{q} . $$ There is the proof: The uniqueness of $g$ is clear, for if $g$ and $g’$ satisfy the relation with $\phi$ , then the integral of $g-g’$ over any measurable set $E$ of finite measure is $0$ ( as we see by taking $\chi_{E}$ for $f$ ), and the $\sigma$ -finiteness of $\mu$ implies therefore that $g - g’ = 0$ a.e. Next, if the relation between $g$ and $\phi$ holds, Hölder‘s inequality implies $$ ||\phi|| \leq ||g||_{q} . $$ I don’t understand how does Hölder’s inequality imply the last inequality. Any help would be appreciated.","There is the theorem: Suppose , is a -finite positive measure on , and is a bounded linear functional on . Then there is a unique , where is the exponent conjugate to , such that Moreover, if and are related as mentioned above, we have There is the proof: The uniqueness of is clear, for if and satisfy the relation with , then the integral of over any measurable set of finite measure is ( as we see by taking for ), and the -finiteness of implies therefore that a.e. Next, if the relation between and holds, Hölder‘s inequality implies I don’t understand how does Hölder’s inequality imply the last inequality. Any help would be appreciated.",1\leq p \lt \infty  \mu \sigma X \phi L^{p}(\mu) g \in L^{q}(\mu) q p \phi(f) = \int_{X} fg \ d\mu \ \ (f \in L^{p}(\mu)).  \Phi g  ||\phi|| = ||g||_{q} .  g g g’ \phi g-g’ E 0 \chi_{E} f \sigma \mu g - g’ = 0 g \phi  ||\phi|| \leq ||g||_{q} . ,"['real-analysis', 'functional-analysis', 'analysis', 'measure-theory', 'normed-spaces']"
12,Any $\ell^2$-closed subspace of $\ell^2 \cap \ell^1$ is finite-dimensional,Any -closed subspace of  is finite-dimensional,\ell^2 \ell^2 \cap \ell^1,"Let $X$ be a closed subspace of $\ell^2$ such that $X$ is contained in $\ell^1$ . It is easy to show that the inclusion operator $J \colon X \hookrightarrow \ell^1$ is closed, hence, by the closed graph theorem $J$ is bounded. Is it true that $X$ is automatically finite dimensional? I would really appreciate any hints.","Let be a closed subspace of such that is contained in . It is easy to show that the inclusion operator is closed, hence, by the closed graph theorem is bounded. Is it true that is automatically finite dimensional? I would really appreciate any hints.",X \ell^2 X \ell^1 J \colon X \hookrightarrow \ell^1 J X,"['functional-analysis', 'closed-graph']"
13,"If $\{\|T^n\|:n\in\mathbb{Z}\}$ is bounded for an invertible operator $T$ over a Hilbert space, must $T$ be conjugate to an orthogonal operator?","If  is bounded for an invertible operator  over a Hilbert space, must  be conjugate to an orthogonal operator?",\{\|T^n\|:n\in\mathbb{Z}\} T T,"Suppose that $A$ is a invertible matrix with complex entries such that $\{\|A^n\|:n\in\mathbb{Z}\}$ is bounded. We consider the Jordan normal form of $A$ . It is well known that \begin{align*} &\begin{pmatrix} x & 1 & 0 &\cdots & 0 & 0\\ 0 & x & 1 &\cdots & 0 & 0\\ \vdots & \vdots & \vdots &\ddots & \vdots & \vdots\\ 0 & 0 & 0 &\cdots & x & 1\\ 0 & 0 & 0 &\cdots & 0 & x\\ \end{pmatrix}^n_{d\times d} = \begin{pmatrix} x^n & (x^n)' & (x^n)'' &\cdots & (x^n)^{(d-2)} & (x^n)^{(d-1)}\\ 0 & x^n & (x^n)' &\cdots & (x^n)^{(d-3)} & (x^n)^{(d-2)}\\ \vdots & \vdots & \vdots &\ddots & \vdots & \vdots\\ 0 & 0 & 0 &\cdots & x^n & (x^n)'\\ 0 & 0 & 0 &\cdots & 0 & x^n\\ \end{pmatrix}\\ =&\begin{pmatrix} x^n & nx^{n-1} & n(n-1)x^{n-2} &\cdots & n\cdots(n-(d-2)+1)x^{n-(d-2)} & n\cdots(n-(d-1)+1)x^{n-(d-1)}\\ 0 & x^n & nx^{n-1} &\cdots & n\cdots(n-(d-3)+1)x^{n-(d-3)} & n\cdots(n-(d-2)+1)x^{n-(d-2)}\\ \vdots & \vdots & \vdots &\ddots & \vdots & \vdots\\ 0 & 0 & 0 &\cdots & x^n & nx^{n-1}\\ 0 & 0 & 0 &\cdots & 0 & x^n\\ \end{pmatrix},\quad n\in\mathbb{Z}, \end{align*} so the $n$ -th power of a size- $d$ Jordan block with digonal element $x$ has $\ell^1$ or $\ell^\infty$ norm $$ |x|^n+n|x|^{n-1}+\cdots+n\cdots(n-(d-1)+1)|x|^{n-(d-1)}, $$ and this number is bounded with respect to $n$ if and only if $|x|=1$ and $d=1$ , so the Jordan form of $A$ is a unitary matrix. What happens in infinite dimension? Let $V$ be a Hilbert space and $T\in\operatorname{GL}(V)$ (in the sense that $T$ is invertible and $T$ , $T^{-1}$ are continuous). If $\{\|T^n\|:n\in\mathbb{Z}\}$ is bounded, must $T$ be conjugated to an orthogonal operator? Also, if $V$ is merely a Banach space, could there be anything interesting to be said?","Suppose that is a invertible matrix with complex entries such that is bounded. We consider the Jordan normal form of . It is well known that so the -th power of a size- Jordan block with digonal element has or norm and this number is bounded with respect to if and only if and , so the Jordan form of is a unitary matrix. What happens in infinite dimension? Let be a Hilbert space and (in the sense that is invertible and , are continuous). If is bounded, must be conjugated to an orthogonal operator? Also, if is merely a Banach space, could there be anything interesting to be said?","A \{\|A^n\|:n\in\mathbb{Z}\} A \begin{align*}
&\begin{pmatrix}
x & 1 & 0 &\cdots & 0 & 0\\
0 & x & 1 &\cdots & 0 & 0\\
\vdots & \vdots & \vdots &\ddots & \vdots & \vdots\\
0 & 0 & 0 &\cdots & x & 1\\
0 & 0 & 0 &\cdots & 0 & x\\
\end{pmatrix}^n_{d\times d} = \begin{pmatrix}
x^n & (x^n)' & (x^n)'' &\cdots & (x^n)^{(d-2)} & (x^n)^{(d-1)}\\
0 & x^n & (x^n)' &\cdots & (x^n)^{(d-3)} & (x^n)^{(d-2)}\\
\vdots & \vdots & \vdots &\ddots & \vdots & \vdots\\
0 & 0 & 0 &\cdots & x^n & (x^n)'\\
0 & 0 & 0 &\cdots & 0 & x^n\\
\end{pmatrix}\\
=&\begin{pmatrix}
x^n & nx^{n-1} & n(n-1)x^{n-2} &\cdots & n\cdots(n-(d-2)+1)x^{n-(d-2)} & n\cdots(n-(d-1)+1)x^{n-(d-1)}\\
0 & x^n & nx^{n-1} &\cdots & n\cdots(n-(d-3)+1)x^{n-(d-3)} & n\cdots(n-(d-2)+1)x^{n-(d-2)}\\
\vdots & \vdots & \vdots &\ddots & \vdots & \vdots\\
0 & 0 & 0 &\cdots & x^n & nx^{n-1}\\
0 & 0 & 0 &\cdots & 0 & x^n\\
\end{pmatrix},\quad n\in\mathbb{Z},
\end{align*} n d x \ell^1 \ell^\infty 
|x|^n+n|x|^{n-1}+\cdots+n\cdots(n-(d-1)+1)|x|^{n-(d-1)},
 n |x|=1 d=1 A V T\in\operatorname{GL}(V) T T T^{-1} \{\|T^n\|:n\in\mathbb{Z}\} T V","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'banach-spaces', 'orthogonality']"
14,Show this bounded linear operator is injective,Show this bounded linear operator is injective,,"Let $X=C([0,1])$ with the $\sup$ norm and let $T: X \to X$ given by $$ Tf(t) = f(t) + \int_0^t f(s) \,\mathrm{d}s. $$ I already showed that $T$ is a bounded linear operator with $\|T\|=2$ .  The problem asks me to show that $T$ is injective. What I tried was to show $\ker T = \{0\}$ , which means the equation $Tf(t)=0$ , or \begin{equation} \tag{1} f(t) + \int_0^t f(s) \,\mathrm{d}s = 0 \end{equation} for all $t \in [0,1]$ has a unique solution $f \equiv 0$ .  Differentiating both sides with respect to $t$ gives the ODE: $$ f'(t) + f(t) = 0, $$ which has a solution $f(t)=Ce^{-t}$ , where $C$ is a constant.  Since equation $(1)$ gives $f(0)=0$ , we must have $C=0$ , and equation $Tf(t)=0$ has a solution $f \equiv 0$ . However, I'm not sure how to show $f = 0$ is the unique solution to $(1)$ (or maybe it must be from the general solution to the ODE). I wonder if differentiation can be done in this case because $f$ is only continuous, not a $C^1$ function. Is there other way to solve this problem like assuming $Tf = Tg$ and showing $f=g$ (I was stuck on this)? Does it have something to do with the Hahn-Banach Theorem, (I don't know the space and the operator)? Thank you.","Let with the norm and let given by I already showed that is a bounded linear operator with .  The problem asks me to show that is injective. What I tried was to show , which means the equation , or for all has a unique solution .  Differentiating both sides with respect to gives the ODE: which has a solution , where is a constant.  Since equation gives , we must have , and equation has a solution . However, I'm not sure how to show is the unique solution to (or maybe it must be from the general solution to the ODE). I wonder if differentiation can be done in this case because is only continuous, not a function. Is there other way to solve this problem like assuming and showing (I was stuck on this)? Does it have something to do with the Hahn-Banach Theorem, (I don't know the space and the operator)? Thank you.","X=C([0,1]) \sup T: X \to X 
Tf(t) = f(t) + \int_0^t f(s) \,\mathrm{d}s.
 T \|T\|=2 T \ker T = \{0\} Tf(t)=0 \begin{equation} \tag{1}
f(t) + \int_0^t f(s) \,\mathrm{d}s = 0
\end{equation} t \in [0,1] f \equiv 0 t 
f'(t) + f(t) = 0,
 f(t)=Ce^{-t} C (1) f(0)=0 C=0 Tf(t)=0 f \equiv 0 f = 0 (1) f C^1 Tf = Tg f=g",['functional-analysis']
15,Integral inequality involving modulus,Integral inequality involving modulus,,"Suppose $f,g \in C^{1}([0,1])$ with $f(x) \ge c > 0$ and $g$ can take negative values. Question: Is it true that $$ \left| \int_{0}^{1} f(x)g(x)~dx \right| \ge  c \left| \int_{0}^{1}g(x)~dx\right| $$ I think that it could be false if we take a $g$ which is oscillating and $f$ chosen appropriately so that  the integral of the product is $0$ but the integral of $g$ is non-zero (the oscillation will have to be so that the area bounded by the curve and the x-axis in the region where it is negative must be larger than the area where it is positive). I am not entirely sure if my intuition is correct however so I would appreciate a counterexample or a proof. Thank you!",Suppose with and can take negative values. Question: Is it true that I think that it could be false if we take a which is oscillating and chosen appropriately so that  the integral of the product is but the integral of is non-zero (the oscillation will have to be so that the area bounded by the curve and the x-axis in the region where it is negative must be larger than the area where it is positive). I am not entirely sure if my intuition is correct however so I would appreciate a counterexample or a proof. Thank you!,"f,g \in C^{1}([0,1]) f(x) \ge c > 0 g  \left| \int_{0}^{1} f(x)g(x)~dx \right| \ge  c \left| \int_{0}^{1}g(x)~dx\right|  g f 0 g","['real-analysis', 'calculus', 'functional-analysis', 'analysis']"
16,The Volterra Operator and the distance between a point and its range,The Volterra Operator and the distance between a point and its range,,"Let $V:L^2[0,1]\to L^2[0,1]$ be the Volterra operator given by $f\mapsto V(f)$ where $$V(f)(t)=\int_0^tf(s)ds,\ \forall t\in[0,1].$$ My question is: Is it true that for for each $d>0$ small there exists $f\in L^2[0,1]$ such that $$\parallel V(f)-f\parallel_{L^2[0,1]}<d\ \ \text{and}\ \ \parallel f\parallel_{L^2[0,1]}\ge\sqrt{d}\    \ \ ?$$ I've tried to find functions such that $V(f)$ is similar to $f$ so that $\parallel V(f)-f\parallel_{L^2[0,1]}$ is small (such as $f(t)=e^t$ or something like that) but it didn't help in anything. Any help will be appreciated! Thank you so much.",Let be the Volterra operator given by where My question is: Is it true that for for each small there exists such that I've tried to find functions such that is similar to so that is small (such as or something like that) but it didn't help in anything. Any help will be appreciated! Thank you so much.,"V:L^2[0,1]\to L^2[0,1] f\mapsto V(f) V(f)(t)=\int_0^tf(s)ds,\ \forall t\in[0,1]. d>0 f\in L^2[0,1] \parallel V(f)-f\parallel_{L^2[0,1]}<d\ \ \text{and}\ \ \parallel f\parallel_{L^2[0,1]}\ge\sqrt{d}\  
 \ \ ? V(f) f \parallel V(f)-f\parallel_{L^2[0,1]} f(t)=e^t",['functional-analysis']
17,Is the space of compact linear operators on a separable Banach space separable?,Is the space of compact linear operators on a separable Banach space separable?,,"let $K(X)$ denote the space of compact linear operators on a separable Banach space $X$ to itself. It is a known result that $K(X)$ is a closed subspace of $L(X)$ , the space of linear operators on $X$ to itself, endowed with the operator norm. Is it also known whether $K(X)$ is separable?","let denote the space of compact linear operators on a separable Banach space to itself. It is a known result that is a closed subspace of , the space of linear operators on to itself, endowed with the operator norm. Is it also known whether is separable?",K(X) X K(X) L(X) X K(X),"['functional-analysis', 'compact-operators']"
18,Find a bounded operator $T$ with spectrum $\sigma(T) = \mathbb{C}$,Find a bounded operator  with spectrum,T \sigma(T) = \mathbb{C},"I have been stuck at question 10B.5 from Axler's Measure, Integration and Real Analysis (MIRA) for a long time. Could anyone please give me some hints or post a solution? The exercise reads Give an example of a bounded operator $T$ on a normed vector space such that for every $\alpha \in F$ , the operator $T− \alpha I$ is not invertible. Here, $F$ is either $\mathbb{R}$ or $\mathbb{C}$ . If the vector space is a Banach space, then $T − \alpha I$ is invertible for $\alpha > \|T\|$ (this is result 10.35b in the book), so I have been considering non-complete spaces. But I haven't had any luck so far. Thank you in advance!","I have been stuck at question 10B.5 from Axler's Measure, Integration and Real Analysis (MIRA) for a long time. Could anyone please give me some hints or post a solution? The exercise reads Give an example of a bounded operator on a normed vector space such that for every , the operator is not invertible. Here, is either or . If the vector space is a Banach space, then is invertible for (this is result 10.35b in the book), so I have been considering non-complete spaces. But I haven't had any luck so far. Thank you in advance!",T \alpha \in F T− \alpha I F \mathbb{R} \mathbb{C} T − \alpha I \alpha > \|T\|,"['functional-analysis', 'operator-theory', 'spectral-theory']"
19,$U$ unitary: $\mathbb{T}\ne\sigma(U)$. Prove $\forall\varepsilon>0$ there exists a polynomial $p(z)$ such that $\|U^{-1}-p(U)\|<\varepsilon.$,unitary: . Prove  there exists a polynomial  such that,U \mathbb{T}\ne\sigma(U) \forall\varepsilon>0 p(z) \|U^{-1}-p(U)\|<\varepsilon.,Let $U$ be a unitary operator: $\mathbb{T}=\{\lambda:|\lambda|=1\}\setminus\sigma(U)\ne\varnothing$ (the spectrum does not cover the whole circle). Prove that $\forall\varepsilon>0$ there exists a polynomial $p(z)=\sum\limits_{i=0}^Nc_iz^i$ such that $\|U^{-1}-p(U)\|<\varepsilon.$ What can I say is that $\exists\lambda\in\mathbb{T}: U-\lambda I$ is invertible. It feels like functional calculus for unitary operators must be useful. Can you please help me? Any hint is appreciate.,Let be a unitary operator: (the spectrum does not cover the whole circle). Prove that there exists a polynomial such that What can I say is that is invertible. It feels like functional calculus for unitary operators must be useful. Can you please help me? Any hint is appreciate.,U \mathbb{T}=\{\lambda:|\lambda|=1\}\setminus\sigma(U)\ne\varnothing \forall\varepsilon>0 p(z)=\sum\limits_{i=0}^Nc_iz^i \|U^{-1}-p(U)\|<\varepsilon. \exists\lambda\in\mathbb{T}: U-\lambda I,"['functional-analysis', 'polynomials', 'operator-theory', 'spectral-theory', 'functional-calculus']"
20,Proving that operator is linear if it is unitary and surjective,Proving that operator is linear if it is unitary and surjective,,"Let $X$ be unitary space. Show that surjective operator $T: X\to X$ such that $\langle Tx, Ty\rangle = \langle x, y \rangle \forall x, y \in X$ is linear. The only thing I was able to conclude (trivial stuff) is that $$ \langle Tx, Ty\rangle = \langle x, y \rangle \implies \langle Tx, Tx\rangle = \langle x, x \rangle \implies \sqrt{\langle Tx, Tx\rangle} = \sqrt{\langle x, x \rangle} \\ \implies \| Tx\| = \|x\| $$ so $T$ is isometry. To show that it is linear I want to have: $$ T(ax) = aT(x) \\ T(x+y) = T(x)+T(y) $$",Let be unitary space. Show that surjective operator such that is linear. The only thing I was able to conclude (trivial stuff) is that so is isometry. To show that it is linear I want to have:,"X T: X\to X \langle Tx, Ty\rangle = \langle x, y \rangle \forall x, y \in X 
\langle Tx, Ty\rangle = \langle x, y \rangle \implies \langle Tx, Tx\rangle = \langle x, x \rangle \implies \sqrt{\langle Tx, Tx\rangle} = \sqrt{\langle x, x \rangle} \\
\implies \| Tx\| = \|x\|
 T 
T(ax) = aT(x) \\
T(x+y) = T(x)+T(y)
","['functional-analysis', 'operator-theory']"
21,the minimum of the sum of two convex functions,the minimum of the sum of two convex functions,,"Context: Here is a question jump into my mind, when I met a problem in 1-dim case, I'm wondering if there is a generalization to higher dimensional $\mathbb R^n$ space: Is the following statement true or false? If it's false, please give counter-example, if it's true, please prove that: Suppose $f, g$ are two convex function $\mathbb R^n \rightarrow \mathbb R$ with unique minimum in $\mathbb R^n$ . The minimum of function $f$ is denoted as $\vec{x^{(1)}}$ ; the minimum of function $g$ is denoted as $\vec{x^{(2)}}$ . Suppose $\vec{x^*}$ is the minimum of $f + g$ , then we have \begin{align} \min \{\vec{x^{(1)}_j}, \vec{x^{(2)}_j} \} \leq \vec{x^*_j} \leq \max \{\vec{x^{(1)}_j}, \vec{x^{(2)}_j} \} ~~~~~~~~~~\forall 1 \leq j \leq n. \end{align} For $1$ dim case, the above statement is of course true; but what if in the high dimensions case $n \geq 2$ ?","Context: Here is a question jump into my mind, when I met a problem in 1-dim case, I'm wondering if there is a generalization to higher dimensional space: Is the following statement true or false? If it's false, please give counter-example, if it's true, please prove that: Suppose are two convex function with unique minimum in . The minimum of function is denoted as ; the minimum of function is denoted as . Suppose is the minimum of , then we have For dim case, the above statement is of course true; but what if in the high dimensions case ?","\mathbb R^n f, g \mathbb R^n \rightarrow \mathbb R \mathbb R^n f \vec{x^{(1)}} g \vec{x^{(2)}} \vec{x^*} f + g \begin{align}
\min \{\vec{x^{(1)}_j}, \vec{x^{(2)}_j} \} \leq \vec{x^*_j} \leq \max \{\vec{x^{(1)}_j}, \vec{x^{(2)}_j} \} ~~~~~~~~~~\forall 1 \leq j \leq n.
\end{align} 1 n \geq 2","['functional-analysis', 'analysis', 'optimization', 'convex-optimization']"
22,"How well can the function $f(x_1,x_2)$ be approximated by $f_1(x_1)+f_2(x_2)$?",How well can the function  be approximated by ?,"f(x_1,x_2) f_1(x_1)+f_2(x_2)","Is it possible to find the upper bound of the following quantity? $\min_{f_1,f_2}\int_0^1\int_0^1|f^*(x_1,x_2)-f_1(x_1)-f_2(x_2)|^2dx_1dx_2$ . where $f_1,f_2$ can be any continous functions. For example, $\min_{f_1,f_2}\int_0^1\int_0^1|x_1x_2-f_1(x_1)-f_2(x_2)|^2dx_1dx_2$ . Are there any related works in the literature? Any comments are welcome.","Is it possible to find the upper bound of the following quantity? . where can be any continous functions. For example, . Are there any related works in the literature? Any comments are welcome.","\min_{f_1,f_2}\int_0^1\int_0^1|f^*(x_1,x_2)-f_1(x_1)-f_2(x_2)|^2dx_1dx_2 f_1,f_2 \min_{f_1,f_2}\int_0^1\int_0^1|x_1x_2-f_1(x_1)-f_2(x_2)|^2dx_1dx_2","['calculus', 'functional-analysis']"
23,Does localisation of a faithful retraction induce an isomorphism between adjointables of Hilbert modules?,Does localisation of a faithful retraction induce an isomorphism between adjointables of Hilbert modules?,,"The title is quite a mouthful, so let me develop some context. All of this is from the book on Hilbert Modules by C. Lance. If $A$ is a $C^*$ -algebra, $M(A)$ its multiplier algebra and $B$ a sub-algebra of $M(A)$ then a positive linear map $\tau: A\to B$ is called a retraction if: For all $a\in A, b\in B$ : $\tau(ab)= \tau(a)b$ $\tau(A)$ is dense in $B$ relative to the strict topology. There is an approximate identity $e_\alpha$ in $A$ so that $\tau(e_\alpha)$ converges to a projection in $B$ . A retraction is additionally called faithful if $\tau(a)>0$ for all positive $a>0$ in $A$ . If $E$ is a Hilbert $A$ -module and $\tau: A\to B$ is a faithful retraction one can also give $E$ the structure of a Hilbert $B$ module via: $$x\cdot b := \lim_\alpha x\cdot e_\alpha \cdot b,\qquad \langle x,y\rangle_\tau := \tau(\langle x,y\rangle) \quad\text{for all $x,y\in E$, $b\in B$}.$$ Any adjointable map (wrt $\langle \cdot,\cdot\rangle$ ) $t:E\to E$ is also adjointable wrt $\langle\cdot,\cdot\rangle_\tau$ , giving a $*$ -morphism $$\pi_\tau:\mathcal L_A(E, \langle \cdot,\cdot\rangle)\to \mathcal L_B(E, \langle\cdot,\cdot\rangle_\tau),$$ $\pi_\tau$ is called the localisation of $\tau$ . In the above case of a faithful retraction this map is clearly injective. On page 58 of his book Lance remarks without comment that it is actually an isomorphism. Is the localisation $\pi_\tau$ also surjective for faithful $\tau$ ? I think a simple (finite dimensional) counter-example is possible, but the above book is quite well regarded and it would be strange to have such an error, so I do not trust my counter-example.","The title is quite a mouthful, so let me develop some context. All of this is from the book on Hilbert Modules by C. Lance. If is a -algebra, its multiplier algebra and a sub-algebra of then a positive linear map is called a retraction if: For all : is dense in relative to the strict topology. There is an approximate identity in so that converges to a projection in . A retraction is additionally called faithful if for all positive in . If is a Hilbert -module and is a faithful retraction one can also give the structure of a Hilbert module via: Any adjointable map (wrt ) is also adjointable wrt , giving a -morphism is called the localisation of . In the above case of a faithful retraction this map is clearly injective. On page 58 of his book Lance remarks without comment that it is actually an isomorphism. Is the localisation also surjective for faithful ? I think a simple (finite dimensional) counter-example is possible, but the above book is quite well regarded and it would be strange to have such an error, so I do not trust my counter-example.","A C^* M(A) B M(A) \tau: A\to B a\in A, b\in B \tau(ab)= \tau(a)b \tau(A) B e_\alpha A \tau(e_\alpha) B \tau(a)>0 a>0 A E A \tau: A\to B E B x\cdot b := \lim_\alpha x\cdot e_\alpha \cdot b,\qquad \langle x,y\rangle_\tau := \tau(\langle x,y\rangle) \quad\text{for all x,y\in E, b\in B}. \langle \cdot,\cdot\rangle t:E\to E \langle\cdot,\cdot\rangle_\tau * \pi_\tau:\mathcal L_A(E, \langle \cdot,\cdot\rangle)\to \mathcal L_B(E, \langle\cdot,\cdot\rangle_\tau), \pi_\tau \tau \pi_\tau \tau","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras', 'hilbert-modules']"
24,Find the supremum of the following set (differential inequalities),Find the supremum of the following set (differential inequalities),,"Let $X=\Bbb{R}^{\Bbb{R}}\cap C^{2}$ that is the set of all functions $f:\Bbb{R}\to\Bbb{R}$ for which the second derivative exists on $\Bbb{R}$ . Let $$  A_f = \Vert f \Vert_\infty = \sup \{ |f(x)| : x \in \Bbb R \} \, ,\\  B_f = \Vert f' \Vert_\infty = \sup \{ |f'(x)| : x \in \Bbb R \} \, , \\  C_f = \Vert f'' \Vert_\infty = \sup \{ |f''(x)| : x \in \Bbb R \} \, . $$ The task is to find $$  M = \sup \left\{ \frac{B_f^2}{A_f \, C_f} : f \in X; A_f, C_f < \infty \right\} \, . $$ Very rough approximations that ignore the limits in definitions of derivatives indicate that the answer might be $\infty$ but that doesn't sit right with my intuition and I haven't been able to find an array of functions for which $\dfrac{B_f^2}{A_f\, C_f}$ could get arbitrarily large. Any hints would be appreciated. EDIT: In Prove $\sup \left| f'\left( x\right) \right| ^{2}\leqslant 4\sup \left| f\left( x\right) \right| \sup \left| f''\left( x\right) \right| $ the upper bound $M \le 4$ is proven. An example of a function with $M=4$ would be sufficient :)",Let that is the set of all functions for which the second derivative exists on . Let The task is to find Very rough approximations that ignore the limits in definitions of derivatives indicate that the answer might be but that doesn't sit right with my intuition and I haven't been able to find an array of functions for which could get arbitrarily large. Any hints would be appreciated. EDIT: In Prove $\sup \left| f'\left( x\right) \right| ^{2}\leqslant 4\sup \left| f\left( x\right) \right| \sup \left| f''\left( x\right) \right| $ the upper bound is proven. An example of a function with would be sufficient :),"X=\Bbb{R}^{\Bbb{R}}\cap C^{2} f:\Bbb{R}\to\Bbb{R} \Bbb{R} 
 A_f = \Vert f \Vert_\infty = \sup \{ |f(x)| : x \in \Bbb R \} \, ,\\
 B_f = \Vert f' \Vert_\infty = \sup \{ |f'(x)| : x \in \Bbb R \} \, , \\
 C_f = \Vert f'' \Vert_\infty = \sup \{ |f''(x)| : x \in \Bbb R \} \, .
 
 M = \sup \left\{ \frac{B_f^2}{A_f \, C_f} : f \in X; A_f, C_f < \infty \right\} \, .
 \infty \dfrac{B_f^2}{A_f\, C_f} M \le 4 M=4","['real-analysis', 'calculus', 'functional-analysis']"
25,Intuition behind spectral radius,Intuition behind spectral radius,,"Let $V$ be a normed vector space, and let $T : V \to V$ be a bounded linear operator. Then the spectral radius of $T$ , call it $r(T)$ is defined to be $\lim_{n \geq 1} \|T^n\|^\frac{1}{n}$ , where $\|\cdot\|$ is the canonical operator norm. I would like to know what does this definition tell us intuitively. For finite-dimensional linear operators, we can treat them as matrices and it is simply the largest absolute value of the eigenvalues (as a result of Gelfand's formula). I see it intuitively as the largest extent in which $T$ ""expands"" the vectors in $V$ . However, in the infinite-dimensional case, there may not be any eigenvalues, so I'm not sure how to tweak my intuition for this case. If possible, I would also like to have an explanation of the intuition behind Gelfand's formula. That is, why is the max of $|\lambda_i|$ , the set of eigenvalues, precisely $\lim_{n \geq 1}\|T^n\|^\frac{1}{n}$ ? Any help is appreciated.","Let be a normed vector space, and let be a bounded linear operator. Then the spectral radius of , call it is defined to be , where is the canonical operator norm. I would like to know what does this definition tell us intuitively. For finite-dimensional linear operators, we can treat them as matrices and it is simply the largest absolute value of the eigenvalues (as a result of Gelfand's formula). I see it intuitively as the largest extent in which ""expands"" the vectors in . However, in the infinite-dimensional case, there may not be any eigenvalues, so I'm not sure how to tweak my intuition for this case. If possible, I would also like to have an explanation of the intuition behind Gelfand's formula. That is, why is the max of , the set of eigenvalues, precisely ? Any help is appreciated.",V T : V \to V T r(T) \lim_{n \geq 1} \|T^n\|^\frac{1}{n} \|\cdot\| T V |\lambda_i| \lim_{n \geq 1}\|T^n\|^\frac{1}{n},"['functional-analysis', 'intuition', 'spectral-theory', 'spectral-radius']"
26,Exact solution $\int_0^1 u'v'=v(1/2)$,Exact solution,\int_0^1 u'v'=v(1/2),"This question concerns a variational form of the Laplace equation with homogeneous Dirichlet boundary conditions: $$-u''=f \text{ on } [0,1], u(0)=u(1)=0.$$ Let $V=H^1_0(\Omega), \Omega=[0,1]$ and $f\in H^{-1}(\Omega)$ . Solve $$u\in H_0^1(\Omega) \text{  such that   } \int_{0}^1 u'v'=f_i(v) \text{ for all } v\in H_0^1(\Omega)$$ for i ) $f_1(v)=\int_0^1 v(x)dx, v\in H_0^1(\Omega)$ ii) $f_2(v)=v(\frac12), v\in H_0^1(\Omega)$ For the first one I integrated by parts to get $-\int_0^1 u''v=\int_0^1 v$ so $u''=-1$ and $u(x)=-x^2/2+x/2$ using the boundary conditions. How can I tackle the second one?",This question concerns a variational form of the Laplace equation with homogeneous Dirichlet boundary conditions: Let and . Solve for i ) ii) For the first one I integrated by parts to get so and using the boundary conditions. How can I tackle the second one?,"-u''=f \text{ on } [0,1], u(0)=u(1)=0. V=H^1_0(\Omega), \Omega=[0,1] f\in H^{-1}(\Omega) u\in H_0^1(\Omega) \text{  such that   } \int_{0}^1 u'v'=f_i(v) \text{ for all } v\in H_0^1(\Omega) f_1(v)=\int_0^1 v(x)dx, v\in H_0^1(\Omega) f_2(v)=v(\frac12), v\in H_0^1(\Omega) -\int_0^1 u''v=\int_0^1 v u''=-1 u(x)=-x^2/2+x/2","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'weak-derivatives']"
27,"A point such that can't be ""stably"" approximated","A point such that can't be ""stably"" approximated",,"Let $T:X\to Y$ be linear and continuous between Banach spaces $X,Y$ .   Suppose that $\overline{T(X)}=Y$ and $T(X)\neq Y$ . Claim : there exists   a $y\in Y$ , such that for every $x_n$ with $Tx_n\to y$ , $$\|x_n\|\to  \infty,\quad n\to \infty.$$ Since $T(X)\neq Y$ , $T$ is not surjective and therefore not an open mapping. I think I have to find a contradiction to this but not getting anywhere.","Let be linear and continuous between Banach spaces .   Suppose that and . Claim : there exists   a , such that for every with , Since , is not surjective and therefore not an open mapping. I think I have to find a contradiction to this but not getting anywhere.","T:X\to Y X,Y \overline{T(X)}=Y T(X)\neq Y y\in Y x_n Tx_n\to y \|x_n\|\to
 \infty,\quad n\to \infty. T(X)\neq Y T",[]
28,Is $0$ the only vector in the kernel of every bounded linear functional?,Is  the only vector in the kernel of every bounded linear functional?,0,"Let $X$ is a normed vector space, and let $x_0\in X$ have the property that for every bounded linear functional $f:X\rightarrow K$ , $f(x_0)=0$ .  Then does $x_0=0$ ? I think the answer is clearly yes, but I'm not sure how to prove it.    How do you construct a bounded linear functional which is nonzero on a given nonzero vector?","Let is a normed vector space, and let have the property that for every bounded linear functional , .  Then does ? I think the answer is clearly yes, but I'm not sure how to prove it.    How do you construct a bounded linear functional which is nonzero on a given nonzero vector?",X x_0\in X f:X\rightarrow K f(x_0)=0 x_0=0,"['linear-algebra', 'functional-analysis', 'operator-theory', 'linear-transformations', 'normed-spaces']"
29,Motivation: Open Mapping Theorem,Motivation: Open Mapping Theorem,,"One of the Fundamental Theorems in Functional Analysis is the Open Mapping Theorem . Theorem. Let $X,Y$ be Banach spaces and $T \in L(X,Y)$ . Then $T$ is surjective if and only if it is open. I'd love to see some motivation on this theorem (not a proof!). Why should it be true? How was it discovered? Perhaps the problem is that one (at least in the beginning of mathematical studies) not often thinks about open maps - but I find it fascinating that people saw a connection between surjectivity and open maps.",One of the Fundamental Theorems in Functional Analysis is the Open Mapping Theorem . Theorem. Let be Banach spaces and . Then is surjective if and only if it is open. I'd love to see some motivation on this theorem (not a proof!). Why should it be true? How was it discovered? Perhaps the problem is that one (at least in the beginning of mathematical studies) not often thinks about open maps - but I find it fascinating that people saw a connection between surjectivity and open maps.,"X,Y T \in L(X,Y) T","['functional-analysis', 'banach-spaces', 'open-map']"
30,Question about Bounded Operators,Question about Bounded Operators,,"Let $H$ be a separable Hilbert Space. Suppose $B$ is a linear map with the property that if $u_n \to u$ and $B(u_n) \to v$, then $v=B(u)$. Show that $B$ is bounded. So the issue here is to get some sequence that $B$ will be continuous on and then proceed by some sort of scaling, but I don't see how to find such a sequence...perhaps involving the basis? Any tips helpful.","Let $H$ be a separable Hilbert Space. Suppose $B$ is a linear map with the property that if $u_n \to u$ and $B(u_n) \to v$, then $v=B(u)$. Show that $B$ is bounded. So the issue here is to get some sequence that $B$ will be continuous on and then proceed by some sort of scaling, but I don't see how to find such a sequence...perhaps involving the basis? Any tips helpful.",,"['real-analysis', 'functional-analysis', 'analysis']"
31,Sequence of functions converge uniformly on every closed bounded interval,Sequence of functions converge uniformly on every closed bounded interval,,"Suppose $\{f_n\}$ is a sequence of functions on $\mathbb R$ and that for any $a,b\in\mathbb R$, the sequence of restricted functions $f_n |_{[a,b]}\rightarrow f_{[a,b]}$ uniformly. (My notation here is not great). Is it possible to use the $f_{[a,b]}$ and piece them together to find a function $f$ such that $f_n \rightarrow f$ uniformly on $\mathbb R$? I think it's true that $f_{[a,b]}$ and $f_{[c,d]}$ have to agree on the intersection of $[a,b]$ and $[c,d]$. Not sure whether this is enough though. It's reminding me a lot of presheaves. Is this possible? How does one (dis)prove it?","Suppose $\{f_n\}$ is a sequence of functions on $\mathbb R$ and that for any $a,b\in\mathbb R$, the sequence of restricted functions $f_n |_{[a,b]}\rightarrow f_{[a,b]}$ uniformly. (My notation here is not great). Is it possible to use the $f_{[a,b]}$ and piece them together to find a function $f$ such that $f_n \rightarrow f$ uniformly on $\mathbb R$? I think it's true that $f_{[a,b]}$ and $f_{[c,d]}$ have to agree on the intersection of $[a,b]$ and $[c,d]$. Not sure whether this is enough though. It's reminding me a lot of presheaves. Is this possible? How does one (dis)prove it?",,"['functional-analysis', 'analysis', 'uniform-convergence']"
32,"$C[a,b]$ is not Banach under Lp norm",is not Banach under Lp norm,"C[a,b]","$\|f\|_p=\biggr(\int_{a}^b|f|^pdx\biggr)^{1/p}$ -Generally we choose $\mathbb R$ as field- I am trying to show $C[a,b]$ is not Banach under $\|.\|_p$ norm. 1) First I need to show $$ f_n(x) = \begin{cases} 0,  & \text{if $a\le x\le c-(1/n)$} \\ nx-nc+1, & \text{if $c-(1/n)\lt x \le c$}\\ 1,  & \text{if $c\lt x \le b$} \end{cases}$$ is a Cauchy Sequence i.e. $$\biggr(\int_{a}^b|f_n-f_m|^pdx\biggr)^{1/p} \lt \varepsilon$$  for $\forall \varepsilon \lt 0$ Let $m \gt n\Rightarrow 1/n \gt 1/m \Rightarrow c-(1/m) \gt c-(1/n) $ $$\|f_n-f_m\|_p=\biggr(\int_{a}^b|f_n(x)-f_m(x)|^pdx\biggr)^{1/p}=$$ $$\biggl(\int_{c-(1/n)}^{c-(1/m)}|nx-nc+1|^pdx+\int_{c-(1/m)}^{c}|(m-n)c+(n-m)x|^pdx\biggl)^{1/p}$$ I have calculated $$\int_{c-(1/n)}^{c-(1/m)}|nx-nc+1|^pdx =\frac{(-1-(n/m)^{p+1}}{n(p+1)}$$ Since $|nx-nc+1|= nc-nx+1$  $(x\le c)$ but I am not sure about other absolute value. $\biggr(|(m-n)c+(n-m)x|=?\biggr)$ After calculating how can I show  $$\biggl(\int_{c-(1/n)}^{c-(1/m)}|nx-nc+1|^pdx+\int_{c-(1/m)}^{c}|(m-n)c+(n-m)x|^pdx\biggl)^{1/p} \lt \varepsilon$$  ?? 2) My other question about that: we know that $f_n(x)\rightarrow g(x)$ where    $$ g(x) = \begin{cases} 0,  & \text{if $a\le x\le c$} \\ 1,  & \text{if $c\lt x \le b$} \end{cases}$$ and $g(x) \notin C[a,b]$ I think, I should show $\biggr(\int_{a}^b|f_n(x)-g(x)|^pdx\biggr)^{1/p} \to 0$ There is a note under question ""use Minkowski inequality"" . I guess I should use this inequality for showing $\biggr(\int_{a}^b|f_n(x)-g(x)|^pdx\biggr)^{1/p} \to 0$. Should I write $\biggr(\int_{a}^b|f_n(x)-g(x)|^pdx\biggr)^{1/p} \le\biggr(\int_{a}^b|f_n(x)|^pdx\biggr)^{1/p} + \biggr(\int_{a}^b|-g(x)|^pdx\biggr)^{1/p}$ or should I write integrals for $[a,c-(1/n)],[c-(1/n),c-(1/m)]$ etc. ? Could you fix my mistakes and warn me about unnecessary things?I have functional analysis midterm tomorrow.Your helps are very important for me Thanks","$\|f\|_p=\biggr(\int_{a}^b|f|^pdx\biggr)^{1/p}$ -Generally we choose $\mathbb R$ as field- I am trying to show $C[a,b]$ is not Banach under $\|.\|_p$ norm. 1) First I need to show $$ f_n(x) = \begin{cases} 0,  & \text{if $a\le x\le c-(1/n)$} \\ nx-nc+1, & \text{if $c-(1/n)\lt x \le c$}\\ 1,  & \text{if $c\lt x \le b$} \end{cases}$$ is a Cauchy Sequence i.e. $$\biggr(\int_{a}^b|f_n-f_m|^pdx\biggr)^{1/p} \lt \varepsilon$$  for $\forall \varepsilon \lt 0$ Let $m \gt n\Rightarrow 1/n \gt 1/m \Rightarrow c-(1/m) \gt c-(1/n) $ $$\|f_n-f_m\|_p=\biggr(\int_{a}^b|f_n(x)-f_m(x)|^pdx\biggr)^{1/p}=$$ $$\biggl(\int_{c-(1/n)}^{c-(1/m)}|nx-nc+1|^pdx+\int_{c-(1/m)}^{c}|(m-n)c+(n-m)x|^pdx\biggl)^{1/p}$$ I have calculated $$\int_{c-(1/n)}^{c-(1/m)}|nx-nc+1|^pdx =\frac{(-1-(n/m)^{p+1}}{n(p+1)}$$ Since $|nx-nc+1|= nc-nx+1$  $(x\le c)$ but I am not sure about other absolute value. $\biggr(|(m-n)c+(n-m)x|=?\biggr)$ After calculating how can I show  $$\biggl(\int_{c-(1/n)}^{c-(1/m)}|nx-nc+1|^pdx+\int_{c-(1/m)}^{c}|(m-n)c+(n-m)x|^pdx\biggl)^{1/p} \lt \varepsilon$$  ?? 2) My other question about that: we know that $f_n(x)\rightarrow g(x)$ where    $$ g(x) = \begin{cases} 0,  & \text{if $a\le x\le c$} \\ 1,  & \text{if $c\lt x \le b$} \end{cases}$$ and $g(x) \notin C[a,b]$ I think, I should show $\biggr(\int_{a}^b|f_n(x)-g(x)|^pdx\biggr)^{1/p} \to 0$ There is a note under question ""use Minkowski inequality"" . I guess I should use this inequality for showing $\biggr(\int_{a}^b|f_n(x)-g(x)|^pdx\biggr)^{1/p} \to 0$. Should I write $\biggr(\int_{a}^b|f_n(x)-g(x)|^pdx\biggr)^{1/p} \le\biggr(\int_{a}^b|f_n(x)|^pdx\biggr)^{1/p} + \biggr(\int_{a}^b|-g(x)|^pdx\biggr)^{1/p}$ or should I write integrals for $[a,c-(1/n)],[c-(1/n),c-(1/m)]$ etc. ? Could you fix my mistakes and warn me about unnecessary things?I have functional analysis midterm tomorrow.Your helps are very important for me Thanks",,"['calculus', 'functional-analysis', 'analysis', 'normed-spaces']"
33,Existence of sequence converges in L1 to $f$ but converges to $0$ pointwisely a.e.,Existence of sequence converges in L1 to  but converges to  pointwisely a.e.,f 0,"Problem: Show that there a sequence of measurable function $(f_{n})$ such that $f_{n}\geq 0,$ and $f_{n} \to 0$ pointwise a.e., and $\forall f \in C[0,1]$, $$ \lim_{n \to \infty}\int_{0}^{1}f(x)f_{n}(x)dx = \int_{0}^{1}f(x)dx$$ Actually, what I found is that $\int_{0}^{1}f_{n} \to 1$ as $n \to \infty$. Also since $C[0,1]=C_{c}[0,1]$ is dense in $L^{1}$, the above limit holds for every $L_{1}$ function. However, I cannot proceed further. If you have some hint of this question, it will be greatly helpful for my thinking.","Problem: Show that there a sequence of measurable function $(f_{n})$ such that $f_{n}\geq 0,$ and $f_{n} \to 0$ pointwise a.e., and $\forall f \in C[0,1]$, $$ \lim_{n \to \infty}\int_{0}^{1}f(x)f_{n}(x)dx = \int_{0}^{1}f(x)dx$$ Actually, what I found is that $\int_{0}^{1}f_{n} \to 1$ as $n \to \infty$. Also since $C[0,1]=C_{c}[0,1]$ is dense in $L^{1}$, the above limit holds for every $L_{1}$ function. However, I cannot proceed further. If you have some hint of this question, it will be greatly helpful for my thinking.",,"['real-analysis', 'functional-analysis']"
34,Weak convergence in Hilbert space and $\|x\|=\liminf\|x_n\|$ implies strong convergence.,Weak convergence in Hilbert space and  implies strong convergence.,\|x\|=\liminf\|x_n\|,"The norm is (sequentially) weakly lower-semicontinuous: if  $x_n$ converges weakly to $x$, then  $\Vert x\Vert \leq \liminf_{n\to \infty}\Vert x_n\Vert$ , and this inequality is strict whenever the convergence is not strong. This is from wikipedia and now I wonder how to prove the last statement. Thanks a lot.","The norm is (sequentially) weakly lower-semicontinuous: if  $x_n$ converges weakly to $x$, then  $\Vert x\Vert \leq \liminf_{n\to \infty}\Vert x_n\Vert$ , and this inequality is strict whenever the convergence is not strong. This is from wikipedia and now I wonder how to prove the last statement. Thanks a lot.",,"['functional-analysis', 'hilbert-spaces']"
35,Intuition/Motivation behind resolutions to the identity,Intuition/Motivation behind resolutions to the identity,,"In Functional Analysis by Rudin the theory of bounded linear operators on Hilbert space is developed. All of a sudden (at least to me) a resolution to the identity is introduced, which is a function from a sigma algebra to the space of bounded linear operators ${\cal B}(H)$ which satisfies the conditions given in this link . Is there any process of reasoning which would lead one to defining such a map? Alternatively, is there a perspective in which this map is a natural one to define?","In Functional Analysis by Rudin the theory of bounded linear operators on Hilbert space is developed. All of a sudden (at least to me) a resolution to the identity is introduced, which is a function from a sigma algebra to the space of bounded linear operators ${\cal B}(H)$ which satisfies the conditions given in this link . Is there any process of reasoning which would lead one to defining such a map? Alternatively, is there a perspective in which this map is a natural one to define?",,"['functional-analysis', 'spectral-theory']"
36,Test whether the function $\frac{x}{2}+\frac{1}{x}$ is contraction or NOT,Test whether the function  is contraction or NOT,\frac{x}{2}+\frac{1}{x},"Let , $X=\{x\in \Bbb R: x\ge 1\}$. Define a map $f:X\to X$ by $\displaystyle f(x)=\frac{x}{2}+\frac{1}{x}$ for all $x\in X$. Examine if $f$ is contraction map or not w.r.t. usual metric on $\Bbb R$. Find the smallest $\lambda$, as contraction constant. We have $|f(x)-f(y)|=\left |\left(\frac{1}{2}-\frac{1}{xy}\right)(x-y)\right |\le |x-y|.\left(\frac{1}{2}+\frac{1}{|xy|}\right)\le \frac{3}{2}|x-y|$ From here how I can say that $f$ is a contraction map ? As, $x,y\ge 1$ so , $1/xy \le 1$. If we take $x,y\in X$ such that $1/xy=1/4$ then the constant $\lambda=1/2+1/4=3/4<1$. But $f$ to be contraction we have to show for all $x,y\in X$ , $|f(x)-f(y)|\le \lambda|x-y|$. So why I will take $x,y$ such that $1/xy=1/4$ ?","Let , $X=\{x\in \Bbb R: x\ge 1\}$. Define a map $f:X\to X$ by $\displaystyle f(x)=\frac{x}{2}+\frac{1}{x}$ for all $x\in X$. Examine if $f$ is contraction map or not w.r.t. usual metric on $\Bbb R$. Find the smallest $\lambda$, as contraction constant. We have $|f(x)-f(y)|=\left |\left(\frac{1}{2}-\frac{1}{xy}\right)(x-y)\right |\le |x-y|.\left(\frac{1}{2}+\frac{1}{|xy|}\right)\le \frac{3}{2}|x-y|$ From here how I can say that $f$ is a contraction map ? As, $x,y\ge 1$ so , $1/xy \le 1$. If we take $x,y\in X$ such that $1/xy=1/4$ then the constant $\lambda=1/2+1/4=3/4<1$. But $f$ to be contraction we have to show for all $x,y\in X$ , $|f(x)-f(y)|\le \lambda|x-y|$. So why I will take $x,y$ such that $1/xy=1/4$ ?",,"['real-analysis', 'functional-analysis', 'analysis', 'metric-spaces']"
37,Complete orthonormal and countable set in a Hilbert space,Complete orthonormal and countable set in a Hilbert space,,"$\{x_n\}$ is a complete orthonormal countable set in a Hilbert space and $\{y_n\}$ is a countable set. It is known that $\underset {n\ge 1} \sum ||x_n-y_n||<1 $. I need to show that $\{y_n\}$  is also complete (not necessarily orthonormal). I tried to use Parseval's identity  and another facts which are equivalent to say that an orthonormal system is complete, but no results.","$\{x_n\}$ is a complete orthonormal countable set in a Hilbert space and $\{y_n\}$ is a countable set. It is known that $\underset {n\ge 1} \sum ||x_n-y_n||<1 $. I need to show that $\{y_n\}$  is also complete (not necessarily orthonormal). I tried to use Parseval's identity  and another facts which are equivalent to say that an orthonormal system is complete, but no results.",,"['functional-analysis', 'hilbert-spaces']"
38,Weak derivative of a given function,Weak derivative of a given function,,"$\def\d{\mathrm{d}}$Find the weak derivative of the following function:   $$u(x)=\begin{cases}x; & x\in(0,1]\\2; & x\in (1,2]\end{cases}.$$ We have,\begin{align*} \int_0^2v(x)\phi(x)\,\d x&=\int_0^2 u'(x)\phi(x)\,\d x=-\int_0^2 u(x)\phi'(x)\,\d x\\ &=-\int_0^1x\phi'(x)\,\d x-\int_1^22\phi'(x)\,\d x. \end{align*} Then how I can proceed to find the weak derivative of $u(x)$?","$\def\d{\mathrm{d}}$Find the weak derivative of the following function:   $$u(x)=\begin{cases}x; & x\in(0,1]\\2; & x\in (1,2]\end{cases}.$$ We have,\begin{align*} \int_0^2v(x)\phi(x)\,\d x&=\int_0^2 u'(x)\phi(x)\,\d x=-\int_0^2 u(x)\phi'(x)\,\d x\\ &=-\int_0^1x\phi'(x)\,\d x-\int_1^22\phi'(x)\,\d x. \end{align*} Then how I can proceed to find the weak derivative of $u(x)$?",,"['functional-analysis', 'analysis', 'weak-derivatives']"
39,Regarding locally integrable functions as distributions,Regarding locally integrable functions as distributions,,"I am currently studying distribution theory, with an eye towards PDEs, and have a question on regarding locally integrable functions as distributions. Suppose $u\in L^1_{\mathrm{loc}}(\Omega).$  Then we can map $u$ to the space of distributions $D'(\Omega)$ by $$T(u)=I_u\in D'(\Omega),$$ where the  distribution $I_u$ is defined by $$\langle I_u,\phi\rangle:=\int_{\mathbb{R}^n}\!f(x)\phi(x)\ \mathrm{d}x.$$  Given this definition, it is technically not correct to say $u\in D'(\Omega).$  Nonetheless, many textbooks consider $u$ to be a distribution.  Salsa (PDEs in Action, pp. 375) even goes as far as to say $L^1_{\mathrm{loc}}(\Omega)\hookrightarrow D'(\Omega)$, which seems to assume $L^1_{\mathrm{loc}}(\Omega)\subset D'(\Omega)$.  Furthermore, this would imply $$|| u||_{D'(\Omega)}\le C ||u ||_{L^1_{\mathrm{loc}}(\Omega)},$$ but what meaning can be assigned the the left hand side of the above equation if $u\not\in D'(\Omega)$? As far as I can tell, when one writes $L^1_{\mathrm{loc}}(\Omega)\hookrightarrow D'(\Omega)$, to mean that the mapping $T:L^{1}_{\mathrm{loc}}(\Omega)\to D'(\Omega)$ is injective, and $\mathrm{im}(T)\hookrightarrow D'(\Omega)$? The only thing I can think of is that this is just an abuse of notation, tolerated so one can write $$\Delta u=f,$$ and understand $u$ as a distribution.  This would be more comfortable and convenient than writing $$\Delta I_u=f.$$ Am I thinking along the right lines? Am I crazy?  I have done some searching, but most sources just seem to brush this off by saying they ""regard"" (?) $u$ as a distribution.  I would very much appreciate any help offered.","I am currently studying distribution theory, with an eye towards PDEs, and have a question on regarding locally integrable functions as distributions. Suppose $u\in L^1_{\mathrm{loc}}(\Omega).$  Then we can map $u$ to the space of distributions $D'(\Omega)$ by $$T(u)=I_u\in D'(\Omega),$$ where the  distribution $I_u$ is defined by $$\langle I_u,\phi\rangle:=\int_{\mathbb{R}^n}\!f(x)\phi(x)\ \mathrm{d}x.$$  Given this definition, it is technically not correct to say $u\in D'(\Omega).$  Nonetheless, many textbooks consider $u$ to be a distribution.  Salsa (PDEs in Action, pp. 375) even goes as far as to say $L^1_{\mathrm{loc}}(\Omega)\hookrightarrow D'(\Omega)$, which seems to assume $L^1_{\mathrm{loc}}(\Omega)\subset D'(\Omega)$.  Furthermore, this would imply $$|| u||_{D'(\Omega)}\le C ||u ||_{L^1_{\mathrm{loc}}(\Omega)},$$ but what meaning can be assigned the the left hand side of the above equation if $u\not\in D'(\Omega)$? As far as I can tell, when one writes $L^1_{\mathrm{loc}}(\Omega)\hookrightarrow D'(\Omega)$, to mean that the mapping $T:L^{1}_{\mathrm{loc}}(\Omega)\to D'(\Omega)$ is injective, and $\mathrm{im}(T)\hookrightarrow D'(\Omega)$? The only thing I can think of is that this is just an abuse of notation, tolerated so one can write $$\Delta u=f,$$ and understand $u$ as a distribution.  This would be more comfortable and convenient than writing $$\Delta I_u=f.$$ Am I thinking along the right lines? Am I crazy?  I have done some searching, but most sources just seem to brush this off by saying they ""regard"" (?) $u$ as a distribution.  I would very much appreciate any help offered.",,"['functional-analysis', 'partial-differential-equations', 'distribution-theory']"
40,Can we always approximate (by below) any continuous function by smooth functions?,Can we always approximate (by below) any continuous function by smooth functions?,,"Let $f\in C\left(\left[0,1\right]\right)$ be a continuous function. Does always exist a sequence of smooth functions $f_{j}\in C^{\infty}\left(\left[0,1\right]\right)$ such that $f_{j}\left(x\right)\leq f\left(x\right)$ for any $x\in\left[0,1\right]$ and $f_{j}$ converges uniformly to $f$ on $\left[0,1\right]?$ Thank you.","Let $f\in C\left(\left[0,1\right]\right)$ be a continuous function. Does always exist a sequence of smooth functions $f_{j}\in C^{\infty}\left(\left[0,1\right]\right)$ such that $f_{j}\left(x\right)\leq f\left(x\right)$ for any $x\in\left[0,1\right]$ and $f_{j}$ converges uniformly to $f$ on $\left[0,1\right]?$ Thank you.",,"['real-analysis', 'functional-analysis']"
41,Consequence of the Hahn-Banach Theorem,Consequence of the Hahn-Banach Theorem,,"From wikipedia's page on the Hahn-Banach Theorem: If $V$ is a normed vector space with linear subspace $U$ (not necessarily closed) and if $z$ is an element of $V$ not in the closure of $U$, then there exists a continuous linear map $ψ : V → K$ with $ψ(x) = 0$ for all $x$ in $U$, $ψ(z) = 1$, and $||ψ|| = dist(z, U)^{−1}.$ How is this a consequence of the Hahn-Banach Theorem?","From wikipedia's page on the Hahn-Banach Theorem: If $V$ is a normed vector space with linear subspace $U$ (not necessarily closed) and if $z$ is an element of $V$ not in the closure of $U$, then there exists a continuous linear map $ψ : V → K$ with $ψ(x) = 0$ for all $x$ in $U$, $ψ(z) = 1$, and $||ψ|| = dist(z, U)^{−1}.$ How is this a consequence of the Hahn-Banach Theorem?",,"['functional-analysis', 'vector-spaces']"
42,Hamel basis of an infinite dimensional space,Hamel basis of an infinite dimensional space,,"I couldn't grasp the concept in Kreyszig's ""Introductory Functional Analysis with Applications"" book that every vector space $X\neq\{0\}$ has a basis . Before that it's said that if $X$ is any vector space, not necessarily finite dimensional, and $B$ is a linearly independent subset of $X$ which spans $X$, then $B$ is called a basis (or Hamel basis) for $X$. Hence if $B$ is a basis for $X$, then every nonzero $x\in X$ has a unique representation as a linear combination of (finitely many!) elements of $B$ with nonzero scalars as coefficients. How can any infinite dimensional space has a finite basis?","I couldn't grasp the concept in Kreyszig's ""Introductory Functional Analysis with Applications"" book that every vector space $X\neq\{0\}$ has a basis . Before that it's said that if $X$ is any vector space, not necessarily finite dimensional, and $B$ is a linearly independent subset of $X$ which spans $X$, then $B$ is called a basis (or Hamel basis) for $X$. Hence if $B$ is a basis for $X$, then every nonzero $x\in X$ has a unique representation as a linear combination of (finitely many!) elements of $B$ with nonzero scalars as coefficients. How can any infinite dimensional space has a finite basis?",,"['functional-analysis', 'vector-spaces']"
43,"Prove $T$ is surjective if $(Tx,x)\geq k(x,x)$ in Hilbert space",Prove  is surjective if  in Hilbert space,"T (Tx,x)\geq k(x,x)","Suppose $H$ is a Hilbert space, and $T$ is a continuous operator satisfies  $$(Tx,x)\geq k(x,x), k>0,x\in H$$ How to prove that $T$ is onto?","Suppose $H$ is a Hilbert space, and $T$ is a continuous operator satisfies  $$(Tx,x)\geq k(x,x), k>0,x\in H$$ How to prove that $T$ is onto?",,['functional-analysis']
44,"If $1\leq p < r \leq \infty$ , then $\| x \|_p \geq \| x \|_r $ [duplicate]","If  , then  [duplicate]",1\leq p < r \leq \infty \| x \|_p \geq \| x \|_r ,"This question already has an answer here : Relations between p norms (1 answer) Closed 7 years ago . This post was edited and submitted for review 2 years ago and failed to reopen the post: Original close reason(s) were not resolved For $1\leq p \leq \infty$ , let $\| \cdot \|_p $ be the $\mathcal{\ell_p}$ norm on $\mathbb{R}^n$ . I need to show that if $1\leq p < r \leq \infty$ , then $\| x \|_p \geq \| x \|_r $ . I have tried Holder's inequality and Minkowski inequality here but they didn't solve my purpose. I am completely stuck at this point. .....","This question already has an answer here : Relations between p norms (1 answer) Closed 7 years ago . This post was edited and submitted for review 2 years ago and failed to reopen the post: Original close reason(s) were not resolved For , let be the norm on . I need to show that if , then . I have tried Holder's inequality and Minkowski inequality here but they didn't solve my purpose. I am completely stuck at this point. .....",1\leq p \leq \infty \| \cdot \|_p  \mathcal{\ell_p} \mathbb{R}^n 1\leq p < r \leq \infty \| x \|_p \geq \| x \|_r ,"['functional-analysis', 'inequality', 'normed-spaces']"
45,"Let $H$ be hilbert and $T$ a BLO, such that $T:H\rightarrow H$. Prove that $\langle T(x),x \rangle = 0$ implies $T = 0$. [duplicate]","Let  be hilbert and  a BLO, such that . Prove that  implies . [duplicate]","H T T:H\rightarrow H \langle T(x),x \rangle = 0 T = 0","This question already has an answer here : Prove that if $\langle Tx,x\rangle =0$ for all $x \in X$, then $T = 0$ (1 answer) Closed 3 years ago . Let $H$ be hilbert and $T$ a BLO, such that $T:H\rightarrow H$. Prove that $\langle T(x),x \rangle = 0$ implies $T = 0$. Any hints to tackle this problem? i tried writing x as $x = u + v$ where $u \in Y$ and $v \in Y^T$ for some closed linear subspace of $H$, but i did not see somethins smart. Is it maybe smart to try using the contra positive?","This question already has an answer here : Prove that if $\langle Tx,x\rangle =0$ for all $x \in X$, then $T = 0$ (1 answer) Closed 3 years ago . Let $H$ be hilbert and $T$ a BLO, such that $T:H\rightarrow H$. Prove that $\langle T(x),x \rangle = 0$ implies $T = 0$. Any hints to tackle this problem? i tried writing x as $x = u + v$ where $u \in Y$ and $v \in Y^T$ for some closed linear subspace of $H$, but i did not see somethins smart. Is it maybe smart to try using the contra positive?",,['functional-analysis']
46,Semi-finite trace on a von Neumann algebra: Equivalent definitions,Semi-finite trace on a von Neumann algebra: Equivalent definitions,,"Let $(N,\tau)$ be a semi-finite von Neumann algebra. This means that $\tau$ is a normal, faithful and semi-finite trace. Normality means that $\tau(x) = \sup_i \tau(x_i)$ if $x \in N_+$ is the limit of an increasing net $x_i$ in $N_+$. With $\tau$ one associates the following sets: $$ N_\tau^+ := \{x \in N_+ : \tau(x) < \infty \} $$ and  $$  \mathscr L_\tau^1(N) := \{ x \in N : \tau(\lvert x \rvert) < \infty \}. $$ The latter set is in fact a $*$-ideal and equals the complex linear span of $N_\tau^+$. I read a few definitions of semi-finiteness and I wonder if these are all equivalent. Lets recall a few definitions: Every $0 \neq x \in N_+$ majorizes some $0 \neq y \in N_\tau^+$. (Takesaki: Theory of Operator Algebras I, p. 309) $\tau(x) = \sup \{ \tau(y) : y \leq x, \ y \in N_\tau^+ \}$ for $x \in N_+$. (Dixmier: von Neumann algebras p. 93) The $\sigma$-weak (=ultra weak) closure of $N_\tau^+$ equals $N_+$. (A. M. Bimkchentaev: On a Property of $L^p$ Spaces on Semifinite von Neumann Algebras) For all $x \in N_+$ there exists an increasing net $x_\alpha$ in $N_\tau^+$ with strong (SOT) limit $x$. (Edward Nelson: Notes on Non-commutative Integration) I hope that all these definitions are equivalent for a normal tracial weight $\tau$ on a von Neumann algebra. By tracial I mean that $\tau(x^*x) = \tau(xx^*)$ for all $x \in N$. I am also wondering if the normality may be dropped to see the equivalence. Maybe the following result is helpful (Haagerup): A weight on a von Neumann algebra is normal iff it is ultra weakly lower semi-continuous.","Let $(N,\tau)$ be a semi-finite von Neumann algebra. This means that $\tau$ is a normal, faithful and semi-finite trace. Normality means that $\tau(x) = \sup_i \tau(x_i)$ if $x \in N_+$ is the limit of an increasing net $x_i$ in $N_+$. With $\tau$ one associates the following sets: $$ N_\tau^+ := \{x \in N_+ : \tau(x) < \infty \} $$ and  $$  \mathscr L_\tau^1(N) := \{ x \in N : \tau(\lvert x \rvert) < \infty \}. $$ The latter set is in fact a $*$-ideal and equals the complex linear span of $N_\tau^+$. I read a few definitions of semi-finiteness and I wonder if these are all equivalent. Lets recall a few definitions: Every $0 \neq x \in N_+$ majorizes some $0 \neq y \in N_\tau^+$. (Takesaki: Theory of Operator Algebras I, p. 309) $\tau(x) = \sup \{ \tau(y) : y \leq x, \ y \in N_\tau^+ \}$ for $x \in N_+$. (Dixmier: von Neumann algebras p. 93) The $\sigma$-weak (=ultra weak) closure of $N_\tau^+$ equals $N_+$. (A. M. Bimkchentaev: On a Property of $L^p$ Spaces on Semifinite von Neumann Algebras) For all $x \in N_+$ there exists an increasing net $x_\alpha$ in $N_\tau^+$ with strong (SOT) limit $x$. (Edward Nelson: Notes on Non-commutative Integration) I hope that all these definitions are equivalent for a normal tracial weight $\tau$ on a von Neumann algebra. By tracial I mean that $\tau(x^*x) = \tau(xx^*)$ for all $x \in N$. I am also wondering if the normality may be dropped to see the equivalence. Maybe the following result is helpful (Haagerup): A weight on a von Neumann algebra is normal iff it is ultra weakly lower semi-continuous.",,"['functional-analysis', 'operator-theory']"
47,How to define $f(0)$ when $f$ is a function in $L^2$?,How to define  when  is a function in ?,f(0) f L^2,"Any function $f$ in $L^2$ is a actually an equivalence class and has properties that only hold ""almost everywhere."" But it would be convenient to speak of the value of $f$ at certain points like $f(0)$. Is there a meaningful way of defining this?","Any function $f$ in $L^2$ is a actually an equivalence class and has properties that only hold ""almost everywhere."" But it would be convenient to speak of the value of $f$ at certain points like $f(0)$. Is there a meaningful way of defining this?",,['functional-analysis']
48,Uniform unboundedness of linear operators,Uniform unboundedness of linear operators,,"Question: Suppose that $(T_k)_{k=1}^{\infty}$ is a sequence of invertible linear operators on $\mathbb{R}^n$. Suppose that $\forall x \in \mathbb{R}^{n}\setminus \{0\}$, we have $$\lim_{k\to\infty} \|T_k x\| = \infty .$$ Let $\mathbb{S}^{n-1}$ denote the unit sphere. Then does it follow that $$\lim_{k\to \infty} \inf_{x \in \mathbb{S}^{n-1}}\|T_k x\| = \infty? $$ Stated another way, is the sequence uniformly unbounded on the unit sphere? Some of my thoughts so far: (1) My question seems almost (but not quite) the converse of the Banach-Steinhaus theorem in the special setting of finite-dimensional vector spaces. (2) Uniform unboundedness in the above question is equivalent to convergence of the sequence $$\lim_{k\to\infty} \sup_{x \in \mathbb{S}^{n-1}} \frac{1}{\|T_k x\|} = 0.$$ If I could prove that the sequence $(1/\|T_k x\|)_{n=1}^{\infty}$ (with $x$ in the unit sphere) was uniformly bounded and equicontinuous , then the Arzelà–Ascoli theorem together with pointwise convergence of $(1/\|T_k x\|)_{k=1}^{\infty}$ to zero would imply the result. (3) Since we are working in $\mathbb{R}^n$, for each $k \in \mathbb{N}$ we may write $T_k$ in terms of its singular value decomposition (SVD) : $T_k = U_k \Sigma_k V_k^T$. If $\|T_k x\|$ did not tend uniformly to $\infty$ on the unit sphere, then the smallest singular values of $\Sigma_k$ would have to be bounded, say, by $K > 0$. Denoting by $v_k^n$ the last column of $V_k$, we then have that $\forall k: \|T_k v_k^n\| < K$. Compactness of $\mathbb{S}^{n-1}$ would then allow me to extract a convergent subsequence from $(v_k^n)_{k=1}^\infty$, but I'm not sure how to make this useful. (4) A geometric interpretation of my question is the following. For each $k$, the image of the unit sphere $T_k(\mathbb{S}^{n-1})$ is an ellipsoid $E_k$. The hypothesis that $\forall x \in \mathbb{R}^n\setminus \{0\}: \lim_{k\to \infty} \|T_k x\| = \infty$ implies that for any point $x \in \mathbb{S}^{n-1}$, the sequence of points $T_k x \in E_k$ grows unbounded in norm. It then seems geometrically intuitive to me that this can only happen if the length of the smallest ""semi-axis"" of the ellipsoids $E_k$ tend to $\infty$, which is equivalent to saying that $\lim_{k\to \infty} \inf_{x \in \mathbb{S}^{n-1}}\|T_k x\| = \infty. $ However, I haven't been able to turn this into a proof, and perhaps my intuition is misguided. Why I care: I am reading the book Normally Hyperbolic Invariant Manifolds in Dynamical Systems by Stephen Wiggins. In deriving equation 3.5 while proving Lemma 3.1.1 , he seems to be asserting the validity of the inference I am asking about.","Question: Suppose that $(T_k)_{k=1}^{\infty}$ is a sequence of invertible linear operators on $\mathbb{R}^n$. Suppose that $\forall x \in \mathbb{R}^{n}\setminus \{0\}$, we have $$\lim_{k\to\infty} \|T_k x\| = \infty .$$ Let $\mathbb{S}^{n-1}$ denote the unit sphere. Then does it follow that $$\lim_{k\to \infty} \inf_{x \in \mathbb{S}^{n-1}}\|T_k x\| = \infty? $$ Stated another way, is the sequence uniformly unbounded on the unit sphere? Some of my thoughts so far: (1) My question seems almost (but not quite) the converse of the Banach-Steinhaus theorem in the special setting of finite-dimensional vector spaces. (2) Uniform unboundedness in the above question is equivalent to convergence of the sequence $$\lim_{k\to\infty} \sup_{x \in \mathbb{S}^{n-1}} \frac{1}{\|T_k x\|} = 0.$$ If I could prove that the sequence $(1/\|T_k x\|)_{n=1}^{\infty}$ (with $x$ in the unit sphere) was uniformly bounded and equicontinuous , then the Arzelà–Ascoli theorem together with pointwise convergence of $(1/\|T_k x\|)_{k=1}^{\infty}$ to zero would imply the result. (3) Since we are working in $\mathbb{R}^n$, for each $k \in \mathbb{N}$ we may write $T_k$ in terms of its singular value decomposition (SVD) : $T_k = U_k \Sigma_k V_k^T$. If $\|T_k x\|$ did not tend uniformly to $\infty$ on the unit sphere, then the smallest singular values of $\Sigma_k$ would have to be bounded, say, by $K > 0$. Denoting by $v_k^n$ the last column of $V_k$, we then have that $\forall k: \|T_k v_k^n\| < K$. Compactness of $\mathbb{S}^{n-1}$ would then allow me to extract a convergent subsequence from $(v_k^n)_{k=1}^\infty$, but I'm not sure how to make this useful. (4) A geometric interpretation of my question is the following. For each $k$, the image of the unit sphere $T_k(\mathbb{S}^{n-1})$ is an ellipsoid $E_k$. The hypothesis that $\forall x \in \mathbb{R}^n\setminus \{0\}: \lim_{k\to \infty} \|T_k x\| = \infty$ implies that for any point $x \in \mathbb{S}^{n-1}$, the sequence of points $T_k x \in E_k$ grows unbounded in norm. It then seems geometrically intuitive to me that this can only happen if the length of the smallest ""semi-axis"" of the ellipsoids $E_k$ tend to $\infty$, which is equivalent to saying that $\lim_{k\to \infty} \inf_{x \in \mathbb{S}^{n-1}}\|T_k x\| = \infty. $ However, I haven't been able to turn this into a proof, and perhaps my intuition is misguided. Why I care: I am reading the book Normally Hyperbolic Invariant Manifolds in Dynamical Systems by Stephen Wiggins. In deriving equation 3.5 while proving Lemma 3.1.1 , he seems to be asserting the validity of the inference I am asking about.",,"['real-analysis', 'linear-algebra', 'functional-analysis', 'dynamical-systems']"
49,Application of Banach-Steinhaus theorem,Application of Banach-Steinhaus theorem,,"Let  $(x_n)$ be a sequence in a Banach space $E$ such that $\sum_{j=1}^{\infty} |\varphi (x_j) |<\infty$, $\forall \varphi \in E'.$ Then $\sup \limits_{\|\varphi\| \leq 1} \sum_{j=1}^{\infty}|\varphi (x_j)| <\infty $. My attempt: For all $n \in \mathbb{N}$, define $f_n: E' \to \mathbb{K}$, $f_n(\varphi) = \sum_{j=1}^{n} \varphi (x_j)$. ($\mathbb{K} = \mathbb{R}$ or $\mathbb{C}$) Each $f_n$ is a continuous linear functional, since: $$|f_n(\varphi)| = \bigg| \sum_{j=1}^{n} \varphi (x_j) \bigg| \leq  \sum_{j=1}^{n} |\varphi (x_j)| \leq \sum_{j=1}^{n} \|\varphi\|\|x_j\| =  (n \max \{\|x_j\|\} ) \|\varphi\|$$ For each $\varphi \in E'$, $(|f_n(\varphi)|)$ is bounded since $$|f_n(\varphi)|  \leq \sum_{j=1}^{n} |\varphi (x_j)| \leq  \sum_{j=1}^{\infty} |\varphi (x_j)| = M_\varphi \in \mathbb{R}  $$ By Banach-Steinhaus theorem, there exists $M>0$ such that $\sup \limits_{n \in \mathbb{N}}  \|f_n\|<M$. For all $n \in \mathbb{N}$, we have: $$M> \|f_n\| = \sup \limits_{\|\varphi\| \leq 1} |f_n(\varphi)| =  \sup \limits_{\|\varphi\| \leq 1} \bigg|\sum_{j=1}^{n}\varphi (x_j)\bigg| $$ Then $$\sup \limits_{\|\varphi\| \leq 1} \bigg|\sum_{j=1}^{\infty}\varphi (x_j)\bigg| \leq M $$ Unfortunately, this is not  what we want to prove. How can I fix it?","Let  $(x_n)$ be a sequence in a Banach space $E$ such that $\sum_{j=1}^{\infty} |\varphi (x_j) |<\infty$, $\forall \varphi \in E'.$ Then $\sup \limits_{\|\varphi\| \leq 1} \sum_{j=1}^{\infty}|\varphi (x_j)| <\infty $. My attempt: For all $n \in \mathbb{N}$, define $f_n: E' \to \mathbb{K}$, $f_n(\varphi) = \sum_{j=1}^{n} \varphi (x_j)$. ($\mathbb{K} = \mathbb{R}$ or $\mathbb{C}$) Each $f_n$ is a continuous linear functional, since: $$|f_n(\varphi)| = \bigg| \sum_{j=1}^{n} \varphi (x_j) \bigg| \leq  \sum_{j=1}^{n} |\varphi (x_j)| \leq \sum_{j=1}^{n} \|\varphi\|\|x_j\| =  (n \max \{\|x_j\|\} ) \|\varphi\|$$ For each $\varphi \in E'$, $(|f_n(\varphi)|)$ is bounded since $$|f_n(\varphi)|  \leq \sum_{j=1}^{n} |\varphi (x_j)| \leq  \sum_{j=1}^{\infty} |\varphi (x_j)| = M_\varphi \in \mathbb{R}  $$ By Banach-Steinhaus theorem, there exists $M>0$ such that $\sup \limits_{n \in \mathbb{N}}  \|f_n\|<M$. For all $n \in \mathbb{N}$, we have: $$M> \|f_n\| = \sup \limits_{\|\varphi\| \leq 1} |f_n(\varphi)| =  \sup \limits_{\|\varphi\| \leq 1} \bigg|\sum_{j=1}^{n}\varphi (x_j)\bigg| $$ Then $$\sup \limits_{\|\varphi\| \leq 1} \bigg|\sum_{j=1}^{\infty}\varphi (x_j)\bigg| \leq M $$ Unfortunately, this is not  what we want to prove. How can I fix it?",,['functional-analysis']
50,An example of smooth compactly supported function with everywhere non-vanishing Fourier transform,An example of smooth compactly supported function with everywhere non-vanishing Fourier transform,,"I am trying to find an explicit example of smooth real-valued compactly supported function $u$ in $\mathbb R^n$, $n \geq 2$, such that its Fourier transform $\widehat u$ does not have zeros. By the Paley-Wiener characterization theorem it is sufficient to find an entire function $U$ on $\mathbb C^n$ such that: for any $N$ there exists $C_N$ such that $$    |U(z)| \leq C_N (1+|z|)^{-N} e^{B|\mathop{\mathrm{Im}} z|} $$ for some $B > 0$; $U(z) \neq 0$ for $z \in \mathbb R^n$. $U(z) = \overline{U(-z)}$, $z \in \mathbb R^n$. On the other hand, by the Wiener $L^1$-approximation theorem it is sufficient to find a smooth compactly real-valued function $u$ in $\mathbb R^n$ such that the span of its shifts $u_a = u(\cdot-a)$, $a \in \mathbb R^n$, is dense in $L^1(\mathbb R^n)$. Please, help me.","I am trying to find an explicit example of smooth real-valued compactly supported function $u$ in $\mathbb R^n$, $n \geq 2$, such that its Fourier transform $\widehat u$ does not have zeros. By the Paley-Wiener characterization theorem it is sufficient to find an entire function $U$ on $\mathbb C^n$ such that: for any $N$ there exists $C_N$ such that $$    |U(z)| \leq C_N (1+|z|)^{-N} e^{B|\mathop{\mathrm{Im}} z|} $$ for some $B > 0$; $U(z) \neq 0$ for $z \in \mathbb R^n$. $U(z) = \overline{U(-z)}$, $z \in \mathbb R^n$. On the other hand, by the Wiener $L^1$-approximation theorem it is sufficient to find a smooth compactly real-valued function $u$ in $\mathbb R^n$ such that the span of its shifts $u_a = u(\cdot-a)$, $a \in \mathbb R^n$, is dense in $L^1(\mathbb R^n)$. Please, help me.",,"['functional-analysis', 'fourier-analysis', 'examples-counterexamples']"
51,Compact operator in Hilbert spaces reach the maximum in the sphere.,Compact operator in Hilbert spaces reach the maximum in the sphere.,,"I found the following question in my textbook: (QUESTION) Let $\mathcal{H}$ a Hilbert space and $T: \mathcal{H} \rightarrow \mathcal{H}$ a compact operator. Show that exists $x \neq 0$ in $\mathcal{H}$, such that $\|Tx\| = \|T\|\|x\|$ A few days ago, I found a similar question in another textbook, but I had $f: \mathcal{H} \rightarrow \mathbb{R}$ bounded. This one, I can use Hanh-Banach theorem to show that exists $x \in \mathcal{H}$, such that $f(x) = \|f\| \|x\|$. Thanks.","I found the following question in my textbook: (QUESTION) Let $\mathcal{H}$ a Hilbert space and $T: \mathcal{H} \rightarrow \mathcal{H}$ a compact operator. Show that exists $x \neq 0$ in $\mathcal{H}$, such that $\|Tx\| = \|T\|\|x\|$ A few days ago, I found a similar question in another textbook, but I had $f: \mathcal{H} \rightarrow \mathbb{R}$ bounded. This one, I can use Hanh-Banach theorem to show that exists $x \in \mathcal{H}$, such that $f(x) = \|f\| \|x\|$. Thanks.",,"['functional-analysis', 'hilbert-spaces', 'compact-operators']"
52,Polarization of quadratic form yields sesquilinear form,Polarization of quadratic form yields sesquilinear form,,How does polarisation of any quadratic form $Q: V \to \mathbb{C}$ on a complex vector space $V$ yields a sesquilinear form?,How does polarisation of any quadratic form on a complex vector space yields a sesquilinear form?,Q: V \to \mathbb{C} V,"['functional-analysis', 'hilbert-spaces', 'quadratic-forms', 'sesquilinear-forms']"
53,Find the norm of the following operator.,Find the norm of the following operator.,,"Take $X=C([0,1])$ with the uniform norm, $\|f\|=\sup_{x\in[0,1]}|f(x)|$, and define the operator $T:X\to X$ by,   $$T(f)(x)=f(x)-\int_0^1f(s)ds$$   Find $\|T\|$. I was hoping to solve this problem using directly the definition of the operator norm, namely, $$\|T\|=\sup\{\|Tx\|:x\in X,\|x\|\le1\}=\{\frac{\|Tx\|}{\|x\|}:x\in X, x\neq0\}$$ However I am not sure how to begin. I have already shown that $T$ in this case is a bounded linear operator, being bounded above by $k=2$, in the sense that, $$\|Tf\|\le2\|f\|,\,\,\,\forall f\in X$$ The solution we done in class involved constructing a sequence of functions $(f_n)_n^\infty\subset X$ such that $Tf_n\to2$. Is there any way to find $\|T\|$ without constructing such a sequence, by using the definition of the operator norm?","Take $X=C([0,1])$ with the uniform norm, $\|f\|=\sup_{x\in[0,1]}|f(x)|$, and define the operator $T:X\to X$ by,   $$T(f)(x)=f(x)-\int_0^1f(s)ds$$   Find $\|T\|$. I was hoping to solve this problem using directly the definition of the operator norm, namely, $$\|T\|=\sup\{\|Tx\|:x\in X,\|x\|\le1\}=\{\frac{\|Tx\|}{\|x\|}:x\in X, x\neq0\}$$ However I am not sure how to begin. I have already shown that $T$ in this case is a bounded linear operator, being bounded above by $k=2$, in the sense that, $$\|Tf\|\le2\|f\|,\,\,\,\forall f\in X$$ The solution we done in class involved constructing a sequence of functions $(f_n)_n^\infty\subset X$ such that $Tf_n\to2$. Is there any way to find $\|T\|$ without constructing such a sequence, by using the definition of the operator norm?",,"['real-analysis', 'functional-analysis', 'continuity', 'operator-theory', 'normed-spaces']"
54,Examples for the Kuratowski–Fréchet theorem,Examples for the Kuratowski–Fréchet theorem,,I was wondering what kind of applications or basic exercises we can create with this powerful result https://en.wikipedia.org/wiki/Kuratowski_embedding Thanks in advance!,I was wondering what kind of applications or basic exercises we can create with this powerful result https://en.wikipedia.org/wiki/Kuratowski_embedding Thanks in advance!,,"['functional-analysis', 'banach-spaces']"
55,Is $f(x)=e^x \cdot \cos(e^x)$ a tempered distribution?,Is  a tempered distribution?,f(x)=e^x \cdot \cos(e^x),Let $f(x)=e^x \cdot \cos(e^x)$. Define $$T_f(\varphi)=\int_{-\infty}^{+\infty} f(x) \cdot \varphi(x) \ .$$  I would like to know if $T_f$ defined with the formula above defines a tempered distribution (in the sense of the definition given here ).,Let $f(x)=e^x \cdot \cos(e^x)$. Define $$T_f(\varphi)=\int_{-\infty}^{+\infty} f(x) \cdot \varphi(x) \ .$$  I would like to know if $T_f$ defined with the formula above defines a tempered distribution (in the sense of the definition given here ).,,"['functional-analysis', 'distribution-theory']"
56,Can a metrizable TVS be induced by a non-translation invariant metric?,Can a metrizable TVS be induced by a non-translation invariant metric?,,"Is it possible to have a topological vector space $(X, \tau)$ with its topology induced by a metric $d$ which is not translation invariant? I'm asking this because in Rudin's 'Functional Analysis' Theorem 1.28, he automatically assumed the metric of a metrizable TVS is translation invariant (he defined a metrizable TVS to be one which topology can be induced by a metric, no requirement on the metric being translation invariant or not). It seems that Rudin is usually careful about his assumptions, so I wonder if I'm missing something?","Is it possible to have a topological vector space $(X, \tau)$ with its topology induced by a metric $d$ which is not translation invariant? I'm asking this because in Rudin's 'Functional Analysis' Theorem 1.28, he automatically assumed the metric of a metrizable TVS is translation invariant (he defined a metrizable TVS to be one which topology can be induced by a metric, no requirement on the metric being translation invariant or not). It seems that Rudin is usually careful about his assumptions, so I wonder if I'm missing something?",,"['functional-analysis', 'topological-vector-spaces']"
57,$C(K)$ is reflexive if and only if $K$ is finite,is reflexive if and only if  is finite,C(K) K,"Let $C(K)$ be the set of all continuous complex valued functions on a compact Hausdorff space $K$ . Is it true that $K$ must be finite if $C(K)$ is reflexive? To me it seems true, but I don't know how to prove it. As $C(K)$ is reflexive then we have canonical isometry onto $C(K)^{**}$ . How does that help?","Let be the set of all continuous complex valued functions on a compact Hausdorff space . Is it true that must be finite if is reflexive? To me it seems true, but I don't know how to prove it. As is reflexive then we have canonical isometry onto . How does that help?",C(K) K K C(K) C(K) C(K)^{**},"['real-analysis', 'functional-analysis', 'continuity', 'banach-spaces', 'reflexive-space']"
58,$ l^1$ not reflexive,not reflexive, l^1,"Define $ \phi:l^1\to (l^\infty)^*  $ by  $$ \phi(a_0,a_1,a_2...)(b_0,b_1,b_2...)=\sum_{n=0}^\infty a_nb_n.$$ Prove that $\phi$ is not onto. Here, $(a_0,a_1,a_2...) \in l^1 $ and $(b_0,b_1,b_2...)\in l^\infty$ Clearly $\phi$ is bounded linear map which could be shown very easily by taking out sup of $(b_0,b_1,b_2...)$. But i don't have any idea to show it is not onto. Anyone help would be appreciated.","Define $ \phi:l^1\to (l^\infty)^*  $ by  $$ \phi(a_0,a_1,a_2...)(b_0,b_1,b_2...)=\sum_{n=0}^\infty a_nb_n.$$ Prove that $\phi$ is not onto. Here, $(a_0,a_1,a_2...) \in l^1 $ and $(b_0,b_1,b_2...)\in l^\infty$ Clearly $\phi$ is bounded linear map which could be shown very easily by taking out sup of $(b_0,b_1,b_2...)$. But i don't have any idea to show it is not onto. Anyone help would be appreciated.",,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
59,Reference for Harmonic Analysis?,Reference for Harmonic Analysis?,,"I'm looking primarily for references for Harmonic Analysis. I'm mostly considering Doran&Fell or Deitmar, but I have access to lectures using Stein as well.  The important thing is covering Unitary representation theory of locally compact groups, in particular Abelian and compact groups, and the Gelfand transformation. I'd also like to ask for the prerequisites of the recomended references (in particular, I have not studied spectral theory, so if that is a necessity I'd appreciate references on that to prepare the ground for Harmonic Analysis).","I'm looking primarily for references for Harmonic Analysis. I'm mostly considering Doran&Fell or Deitmar, but I have access to lectures using Stein as well.  The important thing is covering Unitary representation theory of locally compact groups, in particular Abelian and compact groups, and the Gelfand transformation. I'd also like to ask for the prerequisites of the recomended references (in particular, I have not studied spectral theory, so if that is a necessity I'd appreciate references on that to prepare the ground for Harmonic Analysis).",,"['functional-analysis', 'representation-theory', 'spectral-theory', 'harmonic-analysis', 'locally-compact-groups']"
60,Homogeneous Sobolev space is a Hilbert space,Homogeneous Sobolev space is a Hilbert space,,"I am reading a book and I have some questions about the proof.  The book wants to show $H^s(\mathbb{R}^d)$ is a Hilbert space iff $s<\frac{d}{2}$. $H^s(\mathbb{R}^d)$ is the homogeneous Sobolev space. For the case $s\geq\frac{d}{2}$, he defines a norm $$N:u\to||\hat{u}||_{L^1(B(0,1))}+||u||_{H^s}$$ He says $H^s(\mathbb{R}^d,N)$ is a Banach space.If we assume that $H^s(\mathbb{R}^d,H^s)$ is also complete then by Banach's theorem, there would be a constant $C$ such that $N(u)\leq C||u||_{H^s}$. Here is my question. How we know $H^s(\mathbb{R}^d,N)$ is a Banach space? I don't think it is easy to check, maybe there is some way but I don't know. And why the Banach's theorem can be applied here? I don't think it is a finite dimensional space. Thanks for any help!","I am reading a book and I have some questions about the proof.  The book wants to show $H^s(\mathbb{R}^d)$ is a Hilbert space iff $s<\frac{d}{2}$. $H^s(\mathbb{R}^d)$ is the homogeneous Sobolev space. For the case $s\geq\frac{d}{2}$, he defines a norm $$N:u\to||\hat{u}||_{L^1(B(0,1))}+||u||_{H^s}$$ He says $H^s(\mathbb{R}^d,N)$ is a Banach space.If we assume that $H^s(\mathbb{R}^d,H^s)$ is also complete then by Banach's theorem, there would be a constant $C$ such that $N(u)\leq C||u||_{H^s}$. Here is my question. How we know $H^s(\mathbb{R}^d,N)$ is a Banach space? I don't think it is easy to check, maybe there is some way but I don't know. And why the Banach's theorem can be applied here? I don't think it is a finite dimensional space. Thanks for any help!",,"['functional-analysis', 'hilbert-spaces', 'sobolev-spaces']"
61,"Badly formed question? $\|x\|=1=\|y\|$ and $\|x+y\|=\|x\|+\|y\|$, there is a line segment in the unit sphere","Badly formed question?  and , there is a line segment in the unit sphere",\|x\|=1=\|y\| \|x+y\|=\|x\|+\|y\|,"Show that if a normed linear space $X$ contains linearly independent vectors $x$ and $y$ such that $\|x\|=1$ and $\|y\|=1$ with $\|x+y\|=\|x\|+\|y\|$, then there is a line segment contained in the unit sphere of $X$. Now since the unit sphere in $X$ is defined as $X=\{a\in X: \|a\|=1\}$, and this means that $x,y$ both lie on the unit sphere of $X$. But $\|x+y\|=2$ and hence they must lie on opposite ends of the sphere, and hence form a straight line through the origin. But then these two vectors aren't linearly independent? Is this question badly formed or what am I missing?","Show that if a normed linear space $X$ contains linearly independent vectors $x$ and $y$ such that $\|x\|=1$ and $\|y\|=1$ with $\|x+y\|=\|x\|+\|y\|$, then there is a line segment contained in the unit sphere of $X$. Now since the unit sphere in $X$ is defined as $X=\{a\in X: \|a\|=1\}$, and this means that $x,y$ both lie on the unit sphere of $X$. But $\|x+y\|=2$ and hence they must lie on opposite ends of the sphere, and hence form a straight line through the origin. But then these two vectors aren't linearly independent? Is this question badly formed or what am I missing?",,"['linear-algebra', 'functional-analysis']"
62,Banach spaces containing copies of $\ell^1$,Banach spaces containing copies of,\ell^1,Why is it important that a Banach spaces $X$ contains (or not) copies of the space $\ell^1$? I always hear talk about it but I don't know its importance. Could someone explain this?,Why is it important that a Banach spaces $X$ contains (or not) copies of the space $\ell^1$? I always hear talk about it but I don't know its importance. Could someone explain this?,,"['functional-analysis', 'banach-spaces', 'motivation']"
63,A Banach space of (Hamel) dimension $\kappa$ exists if and only if $\kappa^{\aleph_0}=\kappa$,A Banach space of (Hamel) dimension  exists if and only if,\kappa \kappa^{\aleph_0}=\kappa,"A Banach space of (Hamel) dimension $\kappa$ exists if and only if $\kappa^{\aleph_0}=\kappa$. How will we prove the converse implication. One sided implication for Hilbert Space is proved in question: Can you equip every vector space with a Hilbert space structure? If we don't assume Axiom of Choice, and we have a Banach space with (Hamel Basis B existence given). Will it be true $B^\Bbb N$ equinumerous with $B$? Note: $B^\Bbb N$ is not empty as $B$ is specified.","A Banach space of (Hamel) dimension $\kappa$ exists if and only if $\kappa^{\aleph_0}=\kappa$. How will we prove the converse implication. One sided implication for Hilbert Space is proved in question: Can you equip every vector space with a Hilbert space structure? If we don't assume Axiom of Choice, and we have a Banach space with (Hamel Basis B existence given). Will it be true $B^\Bbb N$ equinumerous with $B$? Note: $B^\Bbb N$ is not empty as $B$ is specified.",,"['functional-analysis', 'banach-spaces', 'axiom-of-choice']"
64,One of these two operators is not invertible,One of these two operators is not invertible,,"I have a Hilbert space $H$ and a bounded self-adjoint operator $T$ on it with $||T||=1$. I've been trying to show that at least one of $I+T, I-T$ are not invertible, but I haven't been able to make any progress yet. Any suggestions would be appreciated.","I have a Hilbert space $H$ and a bounded self-adjoint operator $T$ on it with $||T||=1$. I've been trying to show that at least one of $I+T, I-T$ are not invertible, but I haven't been able to make any progress yet. Any suggestions would be appreciated.",,"['real-analysis', 'functional-analysis', 'hilbert-spaces']"
65,"If $X$ is an inner product space, then is its completion a Hilbert space?","If  is an inner product space, then is its completion a Hilbert space?",X,I have trouble finding a way to prove that the completion of an inner product space $X$ is a Hilbert space. How do I know that the norm on the completion of $X$ is induced by an inner product? Thanks for the help!,I have trouble finding a way to prove that the completion of an inner product space is a Hilbert space. How do I know that the norm on the completion of is induced by an inner product? Thanks for the help!,X X,"['functional-analysis', 'hilbert-spaces', 'inner-products']"
66,Hamel basis and Banach spaces,Hamel basis and Banach spaces,,Suppose $X$ is a linear space and $X$ has a Hamel basis with uncountable number of  elements. Does there exist a norm on $X$ such that $X$ is a Banach space with respect to this norm?,Suppose $X$ is a linear space and $X$ has a Hamel basis with uncountable number of  elements. Does there exist a norm on $X$ such that $X$ is a Banach space with respect to this norm?,,"['functional-analysis', 'banach-spaces']"
67,The closed unit ball is not compact in infinite dimension spaces. Why?,The closed unit ball is not compact in infinite dimension spaces. Why?,,"We know that in finite dimension spaces the closed unit ball is compact, that is if H is a finite dimension space, then there exists an $u$ in the closed unit ball in H and $T \in \mathcal{L}(H, \mathbb{R})$ such that $||T|| = |T u|$. Why doesn't it happen in infinite dimension spaces? For example, let $H = C([a, b])$ with the sup norm. Why doesn't exist an element $u$ in the closed unit ball in $C([a, b])$ such that $T u = ||T||$? Thank you!","We know that in finite dimension spaces the closed unit ball is compact, that is if H is a finite dimension space, then there exists an $u$ in the closed unit ball in H and $T \in \mathcal{L}(H, \mathbb{R})$ such that $||T|| = |T u|$. Why doesn't it happen in infinite dimension spaces? For example, let $H = C([a, b])$ with the sup norm. Why doesn't exist an element $u$ in the closed unit ball in $C([a, b])$ such that $T u = ||T||$? Thank you!",,"['functional-analysis', 'operator-theory']"
68,inequality regarding norm of linear operator,inequality regarding norm of linear operator,,"Let $T$ be a linear operator on a vector space $X$. For $x\in X$, I know there's the inequality that $$||Tx||<||T||||x||$$ Yet I'm wondering what are those norms. Are they arbitrary? especially on the right hand side there's operator norm and vector norm, how do we cooperate that? Thank you!","Let $T$ be a linear operator on a vector space $X$. For $x\in X$, I know there's the inequality that $$||Tx||<||T||||x||$$ Yet I'm wondering what are those norms. Are they arbitrary? especially on the right hand side there's operator norm and vector norm, how do we cooperate that? Thank you!",,"['linear-algebra', 'functional-analysis']"
69,Fourier transform and dual vector space,Fourier transform and dual vector space,,"In Serre's A Course In Arithmetic , it says the following: I don't know what it is talking about, I know the definition of $f'$, but what is This is in the last sentence refered to? $f'$ is a function on $V$, not $V'$. So what is such rapid decreasing function $g$ that have domain on $V'$? BTW, it would be helpful if someone can also explained such measure $\mu$ is $invariant$ by what function?","In Serre's A Course In Arithmetic , it says the following: I don't know what it is talking about, I know the definition of $f'$, but what is This is in the last sentence refered to? $f'$ is a function on $V$, not $V'$. So what is such rapid decreasing function $g$ that have domain on $V'$? BTW, it would be helpful if someone can also explained such measure $\mu$ is $invariant$ by what function?",,"['real-analysis', 'functional-analysis', 'fourier-analysis', 'analytic-number-theory']"
70,On Fredholm operator on Hilbert spaces,On Fredholm operator on Hilbert spaces,,"Let $u: H \to H'$ be a continuous linear operator and $H,H'$ be Hilbert spaces. Let $u^\ast$ denotes its adjoint. By definition, an operator $u$ is called Fredholm if and only if $\ker u$ has finite dimension and $\mathrm{im}(u)$ has finite codimension. My book states that ""...$u$ is Fredholm if and only if $u(H)$ is closed and $\ker u$ and $\ker u^\ast$ are both finite dimensional"" I am not sure but I beleive that closedness of $u(H)$ is redundant, that is, the following is true: $u$ is Fredholm if and only if $\ker u$ and $\ker u^\ast$ are finite-dimensional. My proof: $\implies$: If $u$ is Fredholm then by definition $\ker u$ is finite dimensional. Also, $(u(H))^\bot =\ker u^\ast$. If $V$ is a vector space and $U$ a subspace then the dimension of all complements of $U$ are equal, in particular, equal to the orthogonal complement. Hence $\ker u^\ast$ is finite dimensional. $\Longleftarrow$: Let $\ker u$ and $\ker u^\ast$ be finite dimensional. By the same argument as before, $u(H)$ has finite codimension. Since $\ker u$ is finite dimensional it follows that $u$ is Fredholm. Where is the mistake in my proof? What am I missing here?","Let $u: H \to H'$ be a continuous linear operator and $H,H'$ be Hilbert spaces. Let $u^\ast$ denotes its adjoint. By definition, an operator $u$ is called Fredholm if and only if $\ker u$ has finite dimension and $\mathrm{im}(u)$ has finite codimension. My book states that ""...$u$ is Fredholm if and only if $u(H)$ is closed and $\ker u$ and $\ker u^\ast$ are both finite dimensional"" I am not sure but I beleive that closedness of $u(H)$ is redundant, that is, the following is true: $u$ is Fredholm if and only if $\ker u$ and $\ker u^\ast$ are finite-dimensional. My proof: $\implies$: If $u$ is Fredholm then by definition $\ker u$ is finite dimensional. Also, $(u(H))^\bot =\ker u^\ast$. If $V$ is a vector space and $U$ a subspace then the dimension of all complements of $U$ are equal, in particular, equal to the orthogonal complement. Hence $\ker u^\ast$ is finite dimensional. $\Longleftarrow$: Let $\ker u$ and $\ker u^\ast$ be finite dimensional. By the same argument as before, $u(H)$ has finite codimension. Since $\ker u$ is finite dimensional it follows that $u$ is Fredholm. Where is the mistake in my proof? What am I missing here?",,['functional-analysis']
71,Convergence in inner product space,Convergence in inner product space,,"Let $X$ be an inner product space. If $x_n\to x$, $y_n\to y$ (in norm), then $(x_n,y_n)\to(x,y)$ (in modulus).","Let $X$ be an inner product space. If $x_n\to x$, $y_n\to y$ (in norm), then $(x_n,y_n)\to(x,y)$ (in modulus).",,"['functional-analysis', 'inner-products']"
72,How to prove the sum of RKHS (Reproducing Kernel Hilbert Space)?,How to prove the sum of RKHS (Reproducing Kernel Hilbert Space)?,,"$k,k_1$ and $k_2$ are kernels on $\mathcal{X}\times\mathcal{X}$, and $k=k_1+k_2$, then we have the following properties for the RKHS (Reproducing Kernel Hilbert Space) $\mathcal{H}$, $\mathcal{H}_1$ and $\mathcal{H}_2$: $$\mathcal{H}=\mathcal{H}_1+\mathcal{H}_2=\left\{f_1+f_2:f_1\in \mathcal{H}_1, f_2\in\mathcal{H}_2\right\}(1)$$ and for any $f\in \mathcal{H}$, $$ ||f||^2_{\mathcal{H}}=\min_{f_1,f_2}\left\{||f_1||^2_{\mathcal{H_1}}+||f_2||^2_{\mathcal{H_2}}:f_1+f_2=f\right\}(2)$$ Could someone help to prove (1) or (2)?","$k,k_1$ and $k_2$ are kernels on $\mathcal{X}\times\mathcal{X}$, and $k=k_1+k_2$, then we have the following properties for the RKHS (Reproducing Kernel Hilbert Space) $\mathcal{H}$, $\mathcal{H}_1$ and $\mathcal{H}_2$: $$\mathcal{H}=\mathcal{H}_1+\mathcal{H}_2=\left\{f_1+f_2:f_1\in \mathcal{H}_1, f_2\in\mathcal{H}_2\right\}(1)$$ and for any $f\in \mathcal{H}$, $$ ||f||^2_{\mathcal{H}}=\min_{f_1,f_2}\left\{||f_1||^2_{\mathcal{H_1}}+||f_2||^2_{\mathcal{H_2}}:f_1+f_2=f\right\}(2)$$ Could someone help to prove (1) or (2)?",,"['functional-analysis', 'hilbert-spaces']"
73,Derivative of Fourier transform: $F[f]'=F[-ixf(x)]$,Derivative of Fourier transform:,F[f]'=F[-ixf(x)],"Let us define the Fourier transform of the Lebesgue-summable function $f\in L_1(\mathbb{R},\mu_x)$ as $F[f](\lambda)=\int_{\mathbb{R}}f(x) e^{-i\lambda x} d\mu_x$, where $\mu_x$ is the Lebesgue linear measure. Kolmogorov-Fomin's (p. 430 here ) states that, if $x\mapsto xf(x)$ is Lebesgue-summable too, then the Fourier transform is differentiable and$$\frac{d}{d\lambda}F[f](\lambda)=-i\int_{\mathbb{R}}x f(x) e^{-i\lambda x} d\mu_x$$ EDIT : I would be very grateful to the people having voted to close the question, and to anybody else, if they explained how to use the question linked as a duplicate to prove this equality , which I am not able to do. I am trying to teach myself and cannot afford university for the moment and have not got the sufficient mathematical ability to understand how that result implies this equality. I heartily thank you all!!! Previous trial of mine which may or may not be useful to prove the given equality: In order to prove the statement to myself I had thought that the fact that if the sequence $\{\varphi_n\}\subset L_1(\mathbb{R},\mu_x)$ converges to $\varphi$ with respect to the metric of $L_1(\mathbb{R},\mu_x)$, then $F[f_n]\xrightarrow{n\to\infty} F[f]$, but I cannot apply it. In fact I see that the derivative $F[f]'(\lambda)$ can be seen, if we define $\varphi_n(x)=f(x)\frac{e^{-ih_n x}-1}{h_n}$, where $\{h_n\}$ converges to 0, as the limit $$\lim_n \int_{\mathbb{R}}f(x)\frac{e^{-i(\lambda+h_n)x}-e^{-i\lambda x}}{h_n}d\mu_x=\lim_n \int_{\mathbb{R}} f(x) \frac{e^{-ih_n x}-1}{h_n} e^{-i\lambda x} d\mu_x$$$$=\lim_n F[\varphi_n](\lambda)$$but I cannot prove that $\int_{\mathbb{R}} f(x) \frac{e^{-ih_n x}-1}{h_n} e^{-i\lambda x} d\mu_x$ converges to $-i\int_{\mathbb{R}}x f(x) e^{-i\lambda x} d\mu_x$. I thought about Lebesgue's dominated convergence theorem, but I am not convinced at all that we can majorate $|\varphi_n(x)|$ with a summable function and I am not sure this is the right path to prove the desired equality... P.S.: I assume that the equality holds for any $f\in L_1(\mathbb{R},\mu_x)$ because the book does not specify any other conditions, but it is perfectly in the style of the book to state theorems valid only under certain conditions without explicitly declare them. So, if you noticed that some other condition is needed...","Let us define the Fourier transform of the Lebesgue-summable function $f\in L_1(\mathbb{R},\mu_x)$ as $F[f](\lambda)=\int_{\mathbb{R}}f(x) e^{-i\lambda x} d\mu_x$, where $\mu_x$ is the Lebesgue linear measure. Kolmogorov-Fomin's (p. 430 here ) states that, if $x\mapsto xf(x)$ is Lebesgue-summable too, then the Fourier transform is differentiable and$$\frac{d}{d\lambda}F[f](\lambda)=-i\int_{\mathbb{R}}x f(x) e^{-i\lambda x} d\mu_x$$ EDIT : I would be very grateful to the people having voted to close the question, and to anybody else, if they explained how to use the question linked as a duplicate to prove this equality , which I am not able to do. I am trying to teach myself and cannot afford university for the moment and have not got the sufficient mathematical ability to understand how that result implies this equality. I heartily thank you all!!! Previous trial of mine which may or may not be useful to prove the given equality: In order to prove the statement to myself I had thought that the fact that if the sequence $\{\varphi_n\}\subset L_1(\mathbb{R},\mu_x)$ converges to $\varphi$ with respect to the metric of $L_1(\mathbb{R},\mu_x)$, then $F[f_n]\xrightarrow{n\to\infty} F[f]$, but I cannot apply it. In fact I see that the derivative $F[f]'(\lambda)$ can be seen, if we define $\varphi_n(x)=f(x)\frac{e^{-ih_n x}-1}{h_n}$, where $\{h_n\}$ converges to 0, as the limit $$\lim_n \int_{\mathbb{R}}f(x)\frac{e^{-i(\lambda+h_n)x}-e^{-i\lambda x}}{h_n}d\mu_x=\lim_n \int_{\mathbb{R}} f(x) \frac{e^{-ih_n x}-1}{h_n} e^{-i\lambda x} d\mu_x$$$$=\lim_n F[\varphi_n](\lambda)$$but I cannot prove that $\int_{\mathbb{R}} f(x) \frac{e^{-ih_n x}-1}{h_n} e^{-i\lambda x} d\mu_x$ converges to $-i\int_{\mathbb{R}}x f(x) e^{-i\lambda x} d\mu_x$. I thought about Lebesgue's dominated convergence theorem, but I am not convinced at all that we can majorate $|\varphi_n(x)|$ with a summable function and I am not sure this is the right path to prove the desired equality... P.S.: I assume that the equality holds for any $f\in L_1(\mathbb{R},\mu_x)$ because the book does not specify any other conditions, but it is perfectly in the style of the book to state theorems valid only under certain conditions without explicitly declare them. So, if you noticed that some other condition is needed...",,"['real-analysis', 'functional-analysis', 'fourier-analysis', 'lebesgue-integral']"
74,Bounded operators that are not closed.,Bounded operators that are not closed.,,"If a bounded operator, say $A:D(A)\to X$, have $D(A)=X$ then it is closed. Can anybody construct an example of a bounded linear operator, without resorting and restricting to $D(A)=X$, that is not closed? Please give the examples including densely defined operators, Thanks in advance.","If a bounded operator, say $A:D(A)\to X$, have $D(A)=X$ then it is closed. Can anybody construct an example of a bounded linear operator, without resorting and restricting to $D(A)=X$, that is not closed? Please give the examples including densely defined operators, Thanks in advance.",,['functional-analysis']
75,Bounded approximate identities in one-sided ideals of $L_1(G)$,Bounded approximate identities in one-sided ideals of,L_1(G),"Let $G$ be a locally compact group and consider its $L_1$-group algebra, that is, $L_1(G)$. It is easily seen that $L_1(G)$ has a two-sided bounded approximate identity: just use a basis of compact neigbourhoods of $e\in G$ to construct one. My question is whether of the same is true for closed right/left ideals of $L_1(G)$? Does every closed one-sided ideal of $L_1(G)$ contain a bounded one-sided approximate identity? I know that left/right they are right/left-translation invariant subspaces of $L_1(G)$ but it is not clear to me if it helps. What if we assume that the group is amenable?","Let $G$ be a locally compact group and consider its $L_1$-group algebra, that is, $L_1(G)$. It is easily seen that $L_1(G)$ has a two-sided bounded approximate identity: just use a basis of compact neigbourhoods of $e\in G$ to construct one. My question is whether of the same is true for closed right/left ideals of $L_1(G)$? Does every closed one-sided ideal of $L_1(G)$ contain a bounded one-sided approximate identity? I know that left/right they are right/left-translation invariant subspaces of $L_1(G)$ but it is not clear to me if it helps. What if we assume that the group is amenable?",,"['functional-analysis', 'harmonic-analysis', 'banach-algebras', 'locally-compact-groups', 'amenability']"
76,How does one prove that a space is dense in another under some norm?,How does one prove that a space is dense in another under some norm?,,"This question arose while studying chapter 1 of Reed & Simon's book 'Methods of Modern Mathematical Physics' . It is about exercise 1.10 in particular. In this exercise, the following is asked (I reproduce all the relevant information given in the chapter): Let $x_0,\dots,x_n$ be a partition of the interval $[a,b]$ , $x_0=a, x_n=b$ . Let $\chi_i(x)$ be the characteristic function of $[x_{i-1},x_i)$ except for $\chi_n(x)$ which is the char. function of $[x_{n-1},x_n]$ . A function on $[a,b]$ of the form $\sum_{i=1}^n s_i\chi_i(x)$ is called a step function. The set of all step functions for all possible finite partitions of $[a,b]$ is a normed linear space with the norm $$\left\|\sum_{i=1}^n s_i\chi_i(x)\right\|_\infty=\sup_{x\ \in\ [a,b]}\left|\sum_{i=1}^n s_i\chi_i(x)\right|=\max_{i=1,\dots,n}\{s_i\}$$ We denote this space by $S[a,b]$ . Exercise 10: Prove that $S[a,b]$ is dense in the norm $\|\cdot\|_\infty$ in $PC[a,b]$ , the space of all possible bounded piecewise continuous functions on $[a,b]$ . The definition of 'dense' was given earlier in the book: Definition: A set $B$ in a metric space $M$ is called dense if every $x\in M$ is a limit of elements of $B$ . I am quite confused about what one is supposed to do to solve the exercise: Is it asking me to show that the $\|\cdot\|_\infty$ -norm of any function in $PC[a,b]$ is the limit of the $\|\cdot\|_\infty$ -norm of some function in $S[a,b]$ ? That statement seems trivial since, with these definitions, the $\|\cdot\|_\infty$ -norm of a bounded function is just its supremum, so any step function with a suitably chosen highest $s_i$ has the same $\|\cdot\|_\infty$ -norm (or am I missing something here?). Is it something else (plausibly something involving the metric naturally induced by this norm: $d(f,g)=\|f-g\|_\infty$ ?) that I would have to show instead?","This question arose while studying chapter 1 of Reed & Simon's book 'Methods of Modern Mathematical Physics' . It is about exercise 1.10 in particular. In this exercise, the following is asked (I reproduce all the relevant information given in the chapter): Let be a partition of the interval , . Let be the characteristic function of except for which is the char. function of . A function on of the form is called a step function. The set of all step functions for all possible finite partitions of is a normed linear space with the norm We denote this space by . Exercise 10: Prove that is dense in the norm in , the space of all possible bounded piecewise continuous functions on . The definition of 'dense' was given earlier in the book: Definition: A set in a metric space is called dense if every is a limit of elements of . I am quite confused about what one is supposed to do to solve the exercise: Is it asking me to show that the -norm of any function in is the limit of the -norm of some function in ? That statement seems trivial since, with these definitions, the -norm of a bounded function is just its supremum, so any step function with a suitably chosen highest has the same -norm (or am I missing something here?). Is it something else (plausibly something involving the metric naturally induced by this norm: ?) that I would have to show instead?","x_0,\dots,x_n [a,b] x_0=a, x_n=b \chi_i(x) [x_{i-1},x_i) \chi_n(x) [x_{n-1},x_n] [a,b] \sum_{i=1}^n s_i\chi_i(x) [a,b] \left\|\sum_{i=1}^n s_i\chi_i(x)\right\|_\infty=\sup_{x\ \in\ [a,b]}\left|\sum_{i=1}^n s_i\chi_i(x)\right|=\max_{i=1,\dots,n}\{s_i\} S[a,b] S[a,b] \|\cdot\|_\infty PC[a,b] [a,b] B M x\in M B \|\cdot\|_\infty PC[a,b] \|\cdot\|_\infty S[a,b] \|\cdot\|_\infty s_i \|\cdot\|_\infty d(f,g)=\|f-g\|_\infty","['real-analysis', 'functional-analysis']"
77,Finding domain of $f \circ g$,Finding domain of,f \circ g,"I am having a small question, please don't close this before answering, I just want to know whether its a matter of convention or not. If $f(x) = \dfrac{1}{x}$ and $g(x) = \dfrac{1}{x}$ $ $ Then $f \circ g = x$ $ $ I think domain of $f \circ g $ is $\mathbb{R} - \left\{0\right\}$ $ $ But many ppl I know are having an opinion that domain is $\mathbb{R}$ $ $ Which is true, OR is it just a matter of convention.","I am having a small question, please don't close this before answering, I just want to know whether its a matter of convention or not. If $f(x) = \dfrac{1}{x}$ and $g(x) = \dfrac{1}{x}$ $ $ Then $f \circ g = x$ $ $ I think domain of $f \circ g $ is $\mathbb{R} - \left\{0\right\}$ $ $ But many ppl I know are having an opinion that domain is $\mathbb{R}$ $ $ Which is true, OR is it just a matter of convention.",,"['calculus', 'algebra-precalculus', 'number-theory', 'functional-analysis', 'functions']"
78,Topological Vector Space: $\dim V=n\implies V\cong\mathbb{K}^n$,Topological Vector Space:,\dim V=n\implies V\cong\mathbb{K}^n,Let $V$ be a finite dimensional Hausdorff topological vector space. Prove that it is is isomorphic to the Euclidean vector space of the same dimension: $$\dim V=n\implies V\cong\mathbb{K}^n$$,Let $V$ be a finite dimensional Hausdorff topological vector space. Prove that it is is isomorphic to the Euclidean vector space of the same dimension: $$\dim V=n\implies V\cong\mathbb{K}^n$$,,"['functional-analysis', 'topological-vector-spaces']"
79,What is the dual space in the strong operator topology?,What is the dual space in the strong operator topology?,,"Let $X$ be a Banach space, the strong operator topology on the space of bounded linear operators $\mathcal{B}(X)$ is defined by the family of continuous semi-norms $A\to\|Ax\|$, $x\in X$. What is the dual space to $\mathcal{B}(X)$ in this topology? Can it be identified with something recognizable at least when $X$ is Hilbert or reflexive? For the weak operator topology I think that the dual space can be identified with the space of finite rank operators. I'll appreciate any references. I am also interested in similar questions for the ultraweak and the ultrastrong topologies.","Let $X$ be a Banach space, the strong operator topology on the space of bounded linear operators $\mathcal{B}(X)$ is defined by the family of continuous semi-norms $A\to\|Ax\|$, $x\in X$. What is the dual space to $\mathcal{B}(X)$ in this topology? Can it be identified with something recognizable at least when $X$ is Hilbert or reflexive? For the weak operator topology I think that the dual space can be identified with the space of finite rank operators. I'll appreciate any references. I am also interested in similar questions for the ultraweak and the ultrastrong topologies.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'banach-spaces']"
80,Does $L^2$ strong convergence and bounded $L^\infty$ imply convergence in $L^\infty$ along subsequences?,Does  strong convergence and bounded  imply convergence in  along subsequences?,L^2 L^\infty L^\infty,"Take a sequence of functions $f_n \in L^2([0,1])$ such that $f_n \rightarrow f$ in $L^2([0,1])$ (convergence in $L^2$ norm) and $|f_n|_{L^\infty},|f|_{L^\infty} <R$ (uniformly bounded in $L^\infty$ norm). Question: Do we get from this that there is a subsequence $f_{n_k}$ such that $f_{n_k} \rightarrow f$ in $L^\infty$ norm? If not: Are there any assumptions such that this is true?","Take a sequence of functions $f_n \in L^2([0,1])$ such that $f_n \rightarrow f$ in $L^2([0,1])$ (convergence in $L^2$ norm) and $|f_n|_{L^\infty},|f|_{L^\infty} <R$ (uniformly bounded in $L^\infty$ norm). Question: Do we get from this that there is a subsequence $f_{n_k}$ such that $f_{n_k} \rightarrow f$ in $L^\infty$ norm? If not: Are there any assumptions such that this is true?",,"['functional-analysis', 'functions', 'convergence-divergence']"
81,Show that $\log(x)$ is a Bounded Mean Oscillation (BMO),Show that  is a Bounded Mean Oscillation (BMO),\log(x),"As an extension of our class notes, we were asked to show that the function $w =\log(x)$ is a Bounded Mean Oscillation (BMO). First off, I believe our professor made a mistake, and really wanted us to show that $w = \log|x|$ was a BMO, just to keep everything real. That being said, by the John-Nirenburg Lemma, a function $w$ is a bounded mean oscillation (BMO) if $\displaystyle \frac{1}{|B_{r}|}\int_{B_{r}}|w-\overline{w}_{B_{r}}|\leq C$, where $B_{r}$ is a ball of radius $r$, $\displaystyle \overline{w}_{B_{r}}$ is the average value of $w$ over the ball of radius $r$ (so $\displaystyle \overline{w}_{B_{r}}$ can also be written as $\displaystyle \frac{1}{|B_{r}|}\int_{B_{r}}|w|$), and $C$ is a constant. I would like to do and understand this exercise, but so far, all I've been able to do is set it up.  I figured that since $\displaystyle w = \log|x|$, then $\displaystyle \frac{1}{|B_{r}|}\int_{B_{r}}\left|\,\log|x|-\frac{1}{|B_{r}|}\int_{B_{r}}\log|x|\, \right|$. I'm not sure how to manipulate this expression in order to show that it is $\leq C$.  Should I add and subtract some quantities? Should I try to introduce some exponentials?  I think the two integrals are tripping me up a bit, as well.  So, any suggestions and/or assistance you could offer would be much appreciated :) Thank you in advance!","As an extension of our class notes, we were asked to show that the function $w =\log(x)$ is a Bounded Mean Oscillation (BMO). First off, I believe our professor made a mistake, and really wanted us to show that $w = \log|x|$ was a BMO, just to keep everything real. That being said, by the John-Nirenburg Lemma, a function $w$ is a bounded mean oscillation (BMO) if $\displaystyle \frac{1}{|B_{r}|}\int_{B_{r}}|w-\overline{w}_{B_{r}}|\leq C$, where $B_{r}$ is a ball of radius $r$, $\displaystyle \overline{w}_{B_{r}}$ is the average value of $w$ over the ball of radius $r$ (so $\displaystyle \overline{w}_{B_{r}}$ can also be written as $\displaystyle \frac{1}{|B_{r}|}\int_{B_{r}}|w|$), and $C$ is a constant. I would like to do and understand this exercise, but so far, all I've been able to do is set it up.  I figured that since $\displaystyle w = \log|x|$, then $\displaystyle \frac{1}{|B_{r}|}\int_{B_{r}}\left|\,\log|x|-\frac{1}{|B_{r}|}\int_{B_{r}}\log|x|\, \right|$. I'm not sure how to manipulate this expression in order to show that it is $\leq C$.  Should I add and subtract some quantities? Should I try to introduce some exponentials?  I think the two integrals are tripping me up a bit, as well.  So, any suggestions and/or assistance you could offer would be much appreciated :) Thank you in advance!",,['analysis']
82,Multiplication operator has no no eigenvalues,Multiplication operator has no no eigenvalues,,"Statement: Let $M_x$ denote the multiplicative operator acting on $L^2([0,1], \, dx)$ by $M_x(f) = xf$. Show that $M_x$ has no eigenvalues Attempt: Let $M_x(f) = xf$ then we should have $M_x(f) = \lambda f$ then we get $M_x(f) = \lambda f \Rightarrow xf = \lambda f \Rightarrow xf-\lambda f \Rightarrow (x-\lambda)f = 0$ Now $f \neq 0$ so that implies that $(x-\lambda) = 0$ but this is achieved when $x = \lambda$, so I don't see how it doesn't have eigenvalue, when we achieve the desired result.","Statement: Let $M_x$ denote the multiplicative operator acting on $L^2([0,1], \, dx)$ by $M_x(f) = xf$. Show that $M_x$ has no eigenvalues Attempt: Let $M_x(f) = xf$ then we should have $M_x(f) = \lambda f$ then we get $M_x(f) = \lambda f \Rightarrow xf = \lambda f \Rightarrow xf-\lambda f \Rightarrow (x-\lambda)f = 0$ Now $f \neq 0$ so that implies that $(x-\lambda) = 0$ but this is achieved when $x = \lambda$, so I don't see how it doesn't have eigenvalue, when we achieve the desired result.",,"['analysis', 'functional-analysis', 'operator-theory', 'spectral-theory']"
83,generalization of Banach fixed-point theorem on short maps?,generalization of Banach fixed-point theorem on short maps?,,"If  $ \ T:X \longrightarrow X \ $  is contraction, then using Banach fixed-point theorem we know that the fixed point exists and all other points converge to that point. But what happens if $T$ is not contraction? Let $\quad X = (0, \infty) \quad $ and $ \quad Tx = \sqrt{x} \quad $ for all $x \in X$. Distance between any arbitrary points $ x,y \in X$ is always (strictly! (if $x \neq y$)) decreasing when we transform they using T, but because Lipschitz constant is not $ < 1 $, but equal $1$, we don't have contraction. But still, the fixed-point exists (it is equal $1$) and all other points converge to $1$, even if we don't have Banach fixed-point theorem. Are there some theories, or generalizations of the Banach's theorem, that allows us to say something about transformations like mentioned one, while it does not meet conditions of normal Banach's theorem? P.S. Sorry for mz half-baked english, feel free to edit if you spot some irregularities. Edit: Like Eric Towers said it is not strictly decreasing, my mistake, but still, all $(T^{n}x)$ sequences are Cauchy sequences.","If  $ \ T:X \longrightarrow X \ $  is contraction, then using Banach fixed-point theorem we know that the fixed point exists and all other points converge to that point. But what happens if $T$ is not contraction? Let $\quad X = (0, \infty) \quad $ and $ \quad Tx = \sqrt{x} \quad $ for all $x \in X$. Distance between any arbitrary points $ x,y \in X$ is always (strictly! (if $x \neq y$)) decreasing when we transform they using T, but because Lipschitz constant is not $ < 1 $, but equal $1$, we don't have contraction. But still, the fixed-point exists (it is equal $1$) and all other points converge to $1$, even if we don't have Banach fixed-point theorem. Are there some theories, or generalizations of the Banach's theorem, that allows us to say something about transformations like mentioned one, while it does not meet conditions of normal Banach's theorem? P.S. Sorry for mz half-baked english, feel free to edit if you spot some irregularities. Edit: Like Eric Towers said it is not strictly decreasing, my mistake, but still, all $(T^{n}x)$ sequences are Cauchy sequences.",,"['functional-analysis', 'metric-spaces', 'fixed-point-theorems']"
84,Spectral Mapping Theorem,Spectral Mapping Theorem,,Spectral mapping theorem is as follows: https://math.uc.edu/~halpern/Matrix.methods/Homatrixmethods/Spectralmappingthm.pdf Is Spectral mapping theorem true for point spectrum ?,Spectral mapping theorem is as follows: https://math.uc.edu/~halpern/Matrix.methods/Homatrixmethods/Spectralmappingthm.pdf Is Spectral mapping theorem true for point spectrum ?,,"['analysis', 'functional-analysis', 'operator-theory', 'spectral-theory']"
85,Banach space with cardinality bigger than $\mathfrak{c}$.,Banach space with cardinality bigger than .,\mathfrak{c},"By using the information contained in this post , we have that the cardinality of every Banach space is equal to its dimension, which in turn, is bigger or equal to $\mathfrak{c}$. In my area of study, I have always beem studying spaces like $W^{1,p}$ for $p\in (1,\infty)$ which are separable. Moreover, the space that I know which are not separable is $L^\infty$, but I don't know how to calculate its cardinality. My question is: Is there a example of a Banach space with cardinality bigger than $\mathfrak{c}$? Remark: I'm not used to study those things, hence, if I have posted something stupid here, please neglect it.","By using the information contained in this post , we have that the cardinality of every Banach space is equal to its dimension, which in turn, is bigger or equal to $\mathfrak{c}$. In my area of study, I have always beem studying spaces like $W^{1,p}$ for $p\in (1,\infty)$ which are separable. Moreover, the space that I know which are not separable is $L^\infty$, but I don't know how to calculate its cardinality. My question is: Is there a example of a Banach space with cardinality bigger than $\mathfrak{c}$? Remark: I'm not used to study those things, hence, if I have posted something stupid here, please neglect it.",,"['functional-analysis', 'banach-spaces', 'cardinals']"
86,reference request: proof that group characters are a basis for $L^2$,reference request: proof that group characters are a basis for,L^2,"I know the following must be very standard, but I haven't found it in any of the functional analysis books to which I have access.  Do you know where I can find a self-contained proof?: If $G$ is a compact Hausdorff abelian topological group, the set of characters (i.e. continuous homomorphisms $G \rightarrow S^1$) form a Hilbert basis for $L^2(G)$.","I know the following must be very standard, but I haven't found it in any of the functional analysis books to which I have access.  Do you know where I can find a self-contained proof?: If $G$ is a compact Hausdorff abelian topological group, the set of characters (i.e. continuous homomorphisms $G \rightarrow S^1$) form a Hilbert basis for $L^2(G)$.",,"['group-theory', 'functional-analysis', 'reference-request', 'representation-theory', 'topological-groups']"
87,Eigenfunctions of Laplacian and orthonormal basis (with different inner products),Eigenfunctions of Laplacian and orthonormal basis (with different inner products),,Suppose I have $L^2(\Omega)$ which has two inner products that are both norm-equivalent. The eigenfunctions of the Laplacian $\Delta$ we know forms an orthonormal basis of $L^2(\Omega)$ -- with respect to which inner product? Both of them? How is that? Is it because they're both norm equivalent?,Suppose I have $L^2(\Omega)$ which has two inner products that are both norm-equivalent. The eigenfunctions of the Laplacian $\Delta$ we know forms an orthonormal basis of $L^2(\Omega)$ -- with respect to which inner product? Both of them? How is that? Is it because they're both norm equivalent?,,"['functional-analysis', 'partial-differential-equations', 'hilbert-spaces']"
88,Normal operator matrix norm,Normal operator matrix norm,,"I have some troubles to show that the operator norm of a normal operator is always equal to its largest eigenvalue, how can I proof this? Does anybody of you have a hint? My problem is, that I do not know where to use that this operator is normal?","I have some troubles to show that the operator norm of a normal operator is always equal to its largest eigenvalue, how can I proof this? Does anybody of you have a hint? My problem is, that I do not know where to use that this operator is normal?",,['linear-algebra']
89,Normal $T\in B(H)$ has a nontrivial invariant subspace,Normal  has a nontrivial invariant subspace,T\in B(H),I am wondering if the following is true: Every normal $T\in B(H)$ has a nontrivial invariant subspace if $\dim(H)>1$?,I am wondering if the following is true: Every normal $T\in B(H)$ has a nontrivial invariant subspace if $\dim(H)>1$?,,"['functional-analysis', 'vector-spaces', 'operator-theory', 'hilbert-spaces']"
90,"‎‎If $A$ contains ‎an ‎idempotent $e‎$ (‎‎$‎e‎\neq ‎‎0,1‎‎$‎) , then $‎\Omega(A)‎$ ‎is ‎disconnected","‎‎If  contains ‎an ‎idempotent  (‎‎‎) , then  ‎is ‎disconnected","A e‎ ‎e‎\neq ‎‎0,1‎‎ ‎\Omega(A)‎","If $A$‎ ‎be a‎ ‎unital ‎abelian ‎Banach ‎algebra ‎and ‎contains ‎an ‎idempotent $e$‎ ‎(that ‎is ‎‎$‎e=‎e‎^{‎2‎}‎‎$‎) ‎other ‎than $0$‎ ‎and $1$‎ ,‎ ‎then help me to show that ‎‎$‎\Omega(A)‎$ ‎is ‎disconnected.‎ $‎\Omega(A)‎$ is the set of characters on $A$, that is, the set of non-zero homomorphisms from $A$ to $\Bbb C$.","If $A$‎ ‎be a‎ ‎unital ‎abelian ‎Banach ‎algebra ‎and ‎contains ‎an ‎idempotent $e$‎ ‎(that ‎is ‎‎$‎e=‎e‎^{‎2‎}‎‎$‎) ‎other ‎than $0$‎ ‎and $1$‎ ,‎ ‎then help me to show that ‎‎$‎\Omega(A)‎$ ‎is ‎disconnected.‎ $‎\Omega(A)‎$ is the set of characters on $A$, that is, the set of non-zero homomorphisms from $A$ to $\Bbb C$.",,"['functional-analysis', 'operator-theory', 'banach-algebras', 'connectedness']"
91,Bounded operators on separable Hilbert spaces,Bounded operators on separable Hilbert spaces,,Let $H$ be a separable Hilbert space. Show that every bounded operator from $H$ to itself can be approximated in the strong operator topology by a sequence of finite rank operators. Im not sure what the strong operator topology implies (that the evaluation map for the operator is continuous?) Is it enough to show to use projection to some subspace of some orthogonal sequence?,Let $H$ be a separable Hilbert space. Show that every bounded operator from $H$ to itself can be approximated in the strong operator topology by a sequence of finite rank operators. Im not sure what the strong operator topology implies (that the evaluation map for the operator is continuous?) Is it enough to show to use projection to some subspace of some orthogonal sequence?,,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
92,Weakly Cauchy sequences need not be weakly convergent,Weakly Cauchy sequences need not be weakly convergent,,"A sequence $(x_n)$ in a Banach space $X$ is called weakly Cauchy if for every $\ell \in X'$ the sequence $(\ell(x_n))$ is Cauchy in the scalar field. I want to show that weakly Cauchy sequences are not necessarily weakly convergent. This seems to be the case for Hilbert spaces On the limits of weakly convergent subsequences , whats the difference?","A sequence $(x_n)$ in a Banach space $X$ is called weakly Cauchy if for every $\ell \in X'$ the sequence $(\ell(x_n))$ is Cauchy in the scalar field. I want to show that weakly Cauchy sequences are not necessarily weakly convergent. This seems to be the case for Hilbert spaces On the limits of weakly convergent subsequences , whats the difference?",,"['functional-analysis', 'banach-spaces', 'weakly-cauchy-sequences']"
93,Steps in Proof of Convolution Theorem,Steps in Proof of Convolution Theorem,,"I am reading a proof of the Convolution Theorem and don't understand this part: $$\int |f(z)|\int |g(z-x)| \, dx \, dz = \int|f(z)|\|g\|_1$$ Why does $\int |g(z-x)|dx = \|g\|_1$ ?","I am reading a proof of the Convolution Theorem and don't understand this part: $$\int |f(z)|\int |g(z-x)| \, dx \, dz = \int|f(z)|\|g\|_1$$ Why does $\int |g(z-x)|dx = \|g\|_1$ ?",,['functional-analysis']
94,Riesz basis in Hilbert space,Riesz basis in Hilbert space,,"We know that a collection of vectors $\{x_{k}\}$ in a Hilbert space called Riesz basis if it is an image of orthonormal for H under invertible linear transformation. How to prove that there is constants $A,B$ such that for all $x\in H$ $$ A||x||^2\leq\sum_{k}\langle x,x_k \rangle^2\leq B||x||^2? $$","We know that a collection of vectors $\{x_{k}\}$ in a Hilbert space called Riesz basis if it is an image of orthonormal for H under invertible linear transformation. How to prove that there is constants $A,B$ such that for all $x\in H$ $$ A||x||^2\leq\sum_{k}\langle x,x_k \rangle^2\leq B||x||^2? $$",,"['functional-analysis', 'hilbert-spaces']"
95,Countably dimensional Hilbert Spaces?,Countably dimensional Hilbert Spaces?,,"I have seen a simple proof that no Banach space over $\mathbb{R}$ can be of countably infinite dimension.  However since the space of all square integrable functions on the unit interval forms a Hilbert space, and all Hilbert Spaces are Banach, this space must not be of countable dimension.  However we know that each point has a unique decomposition as a sum complex exponentials $e^{2n\pi}$ were $n\in\mathbb{Z}$.  Thus these complex exponentials form a basis.  But since there is a countable number of such exponentials there must be a contradiction.  Where is that contradiction?","I have seen a simple proof that no Banach space over $\mathbb{R}$ can be of countably infinite dimension.  However since the space of all square integrable functions on the unit interval forms a Hilbert space, and all Hilbert Spaces are Banach, this space must not be of countable dimension.  However we know that each point has a unique decomposition as a sum complex exponentials $e^{2n\pi}$ were $n\in\mathbb{Z}$.  Thus these complex exponentials form a basis.  But since there is a countable number of such exponentials there must be a contradiction.  Where is that contradiction?",,"['functional-analysis', 'vector-spaces', 'hilbert-spaces']"
96,Frechet derivative,Frechet derivative,,"I want to find the Fréchet derivative of the following functional: $$ \begin{align} F : C[-1,1] &\rightarrow \mathbb{R}\\ x &\mapsto x(0)\int_0^1 \sin\ x(t) \, dt. \end{align} $$ How can I do it?","I want to find the Fréchet derivative of the following functional: $$ \begin{align} F : C[-1,1] &\rightarrow \mathbb{R}\\ x &\mapsto x(0)\int_0^1 \sin\ x(t) \, dt. \end{align} $$ How can I do it?",,"['functional-analysis', 'derivatives']"
97,Question about Sobolev embedding theorem,Question about Sobolev embedding theorem,,"The Sobolev embedding theorem as stated in my notes says that if we have $k > l + d/2$ then we can continuously extend the inclusion $C^\infty(\mathbb T^d) \hookrightarrow C^l(\mathbb T^d)$ to $H^k(\mathbb T^d) \hookrightarrow C^l(\mathbb T^d)$. We define $H^k$ to be the closure of $C^\infty$ with respect to the Sobolev norm, see my previous question for the definition . What I'm confused about is, why we need the condition $k > l + d/2$. What exactly does it give us? If $H^k$ is the closure of $C^\infty$ we already get that if $T$ is any continuous linear operator $C^\infty \to C^l$ we can extend it to all of $H^k$. What am I missing? Thanks for your help.","The Sobolev embedding theorem as stated in my notes says that if we have $k > l + d/2$ then we can continuously extend the inclusion $C^\infty(\mathbb T^d) \hookrightarrow C^l(\mathbb T^d)$ to $H^k(\mathbb T^d) \hookrightarrow C^l(\mathbb T^d)$. We define $H^k$ to be the closure of $C^\infty$ with respect to the Sobolev norm, see my previous question for the definition . What I'm confused about is, why we need the condition $k > l + d/2$. What exactly does it give us? If $H^k$ is the closure of $C^\infty$ we already get that if $T$ is any continuous linear operator $C^\infty \to C^l$ we can extend it to all of $H^k$. What am I missing? Thanks for your help.",,"['functional-analysis', 'banach-spaces', 'sobolev-spaces']"
98,"A linearly independent, countable dense subset of $l^2(\mathbb{N})$ [duplicate]","A linearly independent, countable dense subset of  [duplicate]",l^2(\mathbb{N}),This question already has answers here : Closed 11 years ago . Possible Duplicate: Does there exist a linear independent and dense subset? I am looking for an example of a countable dense subset of the Hilbert space $l^2(\mathbb{N})$ consisting of linearly independent vectors,This question already has answers here : Closed 11 years ago . Possible Duplicate: Does there exist a linear independent and dense subset? I am looking for an example of a countable dense subset of the Hilbert space $l^2(\mathbb{N})$ consisting of linearly independent vectors,,"['functional-analysis', 'hilbert-spaces']"
99,"How can I show that $f_n$= $\frac 1n\sum\limits_{i=1}^{n^2} e^{ikt}$ converges weakly to $0$ in $L^2[-π,π] $",How can I show that =  converges weakly to  in,"f_n \frac 1n\sum\limits_{i=1}^{n^2} e^{ikt} 0 L^2[-π,π] ","How can I show that  $$ f_n=\frac{1}{n}\sum\limits_{k=1}^{n^2} e^{ikt} $$ converges weakly to $0$ in $L^2[-π,π] $ and that the sequence $$ \left\Vert \frac{1}{n}(f_1+f_2+...+f_n)\right\Vert_2 $$ does not converge to $0$ ? Thank you in advance.","How can I show that  $$ f_n=\frac{1}{n}\sum\limits_{k=1}^{n^2} e^{ikt} $$ converges weakly to $0$ in $L^2[-π,π] $ and that the sequence $$ \left\Vert \frac{1}{n}(f_1+f_2+...+f_n)\right\Vert_2 $$ does not converge to $0$ ? Thank you in advance.",,"['functional-analysis', 'convergence-divergence']"
