,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is a subsequence of an exchangeable sequence exchangeable?,Is a subsequence of an exchangeable sequence exchangeable?,,"Consider a finite sequence of random variables $X_1,...,X_n$ (1) SUFF COND: Suppose $X_1,...,X_n$ are exchangeable, meaning that the joint probability distribution of $X_1,...,X_n$ is equivalent to the joint probability distribution of $X_{\varphi(1)},...,X_{\varphi(n)}$ for any finite permutation $\varphi$ over $1,...,n$. Does this imply exchangeability of the elements of every finite subsequence? (2) NEC COND: Does exchangeability of the elements of every finite subsequence implies exchangeability of the elements of the whole sequence? I know that for infinite sequences the answer to both questions is yes. I don't know how to solve the finite case","Consider a finite sequence of random variables $X_1,...,X_n$ (1) SUFF COND: Suppose $X_1,...,X_n$ are exchangeable, meaning that the joint probability distribution of $X_1,...,X_n$ is equivalent to the joint probability distribution of $X_{\varphi(1)},...,X_{\varphi(n)}$ for any finite permutation $\varphi$ over $1,...,n$. Does this imply exchangeability of the elements of every finite subsequence? (2) NEC COND: Does exchangeability of the elements of every finite subsequence implies exchangeability of the elements of the whole sequence? I know that for infinite sequences the answer to both questions is yes. I don't know how to solve the finite case",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'random']"
1,posterior probability of bag given ball (evidence),posterior probability of bag given ball (evidence),,"Question: Given the distribution of the coloured balls in three different bags: - Bag A: 1 Red 2 Black 2 Blue - Bag B: 2 Red 4 Black 4 Blue - Bag C: 10 Red 2 Black 3 Green we carry out two independent experiments: 1) pick a bag, then pick a ball from the chosen bag. 2) pick a ball uniformly and random from all of the 30 balls. We observe that the ball is red (for both experiment). Now, we want to find the posterior probability of ball was taken from bag C given the ball chosen is Red for each of the experiment (i.e. P(Bag C | Red)). My attempt: For Experiment 1: Using Bayes Rule we have: P(Bag C | Red) = P(Bag C and Red) / P(Red) From the distribution, we have P(BagC, Red) = 10/30 Now,P(Red) = (by law of total probability) sum of conditional probability of     P(Red | Bag X) * P(Bag X)  = P(Red|BagC)*P(BagC) + P(Red|BagB)*P(BagB) + P(Red|BagA)*P(BagA) = (1/3)(10/15) + (1/3)(2/10) + (1/3)(1/5)  = 16/45  And hence P(BagC|Red) = (10/30) / (16/45) = 15/16 ??? For Experiment 2: this is the part where i am confuse, because intuitively, i dont not see the difference between both question! But i slept over it and think maybe the difference is in the way we calculate P(red), and thats why the following answer: So using the same formula above, but with difference calculation of the probability of getting a red ball from the bag: P(Red) = total number of red / total number of balls = 13/30 Hence, P(BagC|Red)  = P(Red, BagC) / P(Red)  = (10/30) / (13/30)  = 10/13 Intuitively, i thought my answer made sense because if we were to choose a bag first, the probability of the red ball coming from bag C will be larger since the proportion of red balls in bag C is significantly higher. In comparison, if we pick randomly from the pool of 30 balls, the contribution of C into the pool is higher as well (10/13 red balls from C). I am not entirely sure if my approach is correct here, and would wish that you can validate my answers. EDIT: Rectify the error pointed out in the comments","Question: Given the distribution of the coloured balls in three different bags: - Bag A: 1 Red 2 Black 2 Blue - Bag B: 2 Red 4 Black 4 Blue - Bag C: 10 Red 2 Black 3 Green we carry out two independent experiments: 1) pick a bag, then pick a ball from the chosen bag. 2) pick a ball uniformly and random from all of the 30 balls. We observe that the ball is red (for both experiment). Now, we want to find the posterior probability of ball was taken from bag C given the ball chosen is Red for each of the experiment (i.e. P(Bag C | Red)). My attempt: For Experiment 1: Using Bayes Rule we have: P(Bag C | Red) = P(Bag C and Red) / P(Red) From the distribution, we have P(BagC, Red) = 10/30 Now,P(Red) = (by law of total probability) sum of conditional probability of     P(Red | Bag X) * P(Bag X)  = P(Red|BagC)*P(BagC) + P(Red|BagB)*P(BagB) + P(Red|BagA)*P(BagA) = (1/3)(10/15) + (1/3)(2/10) + (1/3)(1/5)  = 16/45  And hence P(BagC|Red) = (10/30) / (16/45) = 15/16 ??? For Experiment 2: this is the part where i am confuse, because intuitively, i dont not see the difference between both question! But i slept over it and think maybe the difference is in the way we calculate P(red), and thats why the following answer: So using the same formula above, but with difference calculation of the probability of getting a red ball from the bag: P(Red) = total number of red / total number of balls = 13/30 Hence, P(BagC|Red)  = P(Red, BagC) / P(Red)  = (10/30) / (13/30)  = 10/13 Intuitively, i thought my answer made sense because if we were to choose a bag first, the probability of the red ball coming from bag C will be larger since the proportion of red balls in bag C is significantly higher. In comparison, if we pick randomly from the pool of 30 balls, the contribution of C into the pool is higher as well (10/13 red balls from C). I am not entirely sure if my approach is correct here, and would wish that you can validate my answers. EDIT: Rectify the error pointed out in the comments",,"['probability', 'bayes-theorem']"
2,Determining the values a random variable takes,Determining the values a random variable takes,,"Let $(X_n)$ be IID bernoulli random variables and set $$Y_n = \sum_{i=1}^n \frac{X_i}{2^i}$$ I am trying to show this converges weakly to the uniform distribution on $[0,1]$. I am given a hint that I should first show what values it takes, and find it's distrubtion function. I found solutions online which state $Y_n$ takes values $k/2^n$ for $0 \leq k \leq 2^n - 1$ each with probability $1/2^n$ - I can't see this. Could someone please explain why this is so","Let $(X_n)$ be IID bernoulli random variables and set $$Y_n = \sum_{i=1}^n \frac{X_i}{2^i}$$ I am trying to show this converges weakly to the uniform distribution on $[0,1]$. I am given a hint that I should first show what values it takes, and find it's distrubtion function. I found solutions online which state $Y_n$ takes values $k/2^n$ for $0 \leq k \leq 2^n - 1$ each with probability $1/2^n$ - I can't see this. Could someone please explain why this is so",,"['real-analysis', 'probability', 'probability-theory', 'probability-distributions']"
3,"Intuitive understanding of the ""Multiplication Rule""?","Intuitive understanding of the ""Multiplication Rule""?",,"I apologize in advance that this question has a long set-up. In the set up I am presenting how I currently understand the material, and the actual question is if my understanding is correct and applicable to more types of questions. I am referring to the rule $$P(A \text{ and } B)=P(A) \cdot P(B|A)$$ Or just $$P(A \text{ and } B)=P(A) \cdot P(B)$$ If the events are independent. I will be using absolute value bars as notation for the size of a set (i.e. $|\{z_1, z_2, ...z_n\}|=n$) I feel like I understand this rule for the most part when we have $2$ independent events. For example, rolling an even number on a standard dice and flipping ""tails"" with a coin. The way I understand this is as follows: $$ \dfrac{ \text{Desired outcomes}}{\text{Total Outcomes}} = \dfrac{|\{2T, 4T, 6T\}|}{|\{1H, 1T, 2H, 2T,...,6H, 6T\}|} =   \dfrac{|\{2, 4, 6 \}|}{|\{1, 2, 3, 4, 5, 6\}|} \cdot \dfrac{ |\{T\}|}{|\{H, T\}|}$$ When it comes to two dependent events, it mostly makes sense but I don't think I've completely internalized it. For example, if the question asks: ""Find the probability of drawing a king, and then a queen from a deck of cards without replacement."" I have a little bit of trouble making sense of this one in the context of one deck, so I just pretend that we have two decks, one with $52$ cards and the other with $51$ cards (with the king of diamonds missing), and I reduce the problem to drawing a king and a queen in sequence from the two decks. I think I can make sense of it the same way I made sense of the dice and the coin: $$ \dfrac{ \text{Desired outcomes}}{\text{Total Outcomes}} = \dfrac{|\{K_{clubs}Q_{clubs}, K_{clubs}Q_{spades},...,K_{diamonds}Q_{diamonds}\}|}{|\{Ace_{clubs}Ace_{clubs}, Ace_{clubs}Ace_{spades},..., K_{diamonds}K_{hearts} \}|} =   \dfrac{|\{K_{clubs}, K_{spades}, K_{hearts}, K_{diamond} \}|}{|\{Ace_{clubs}, Ace_{spades},...K_{diamonds}\}|} \cdot \dfrac{ |\{ Q_{clubs}, ... Q_{diamond}  \}|}{| \{Ace_{clubs}, Ace_{spades},...K_{hearts} \}|}$$ However, what really gives me trouble is when we have just one event. For example ""15,000 U.S. medical school seniors applied to residency programs in 2009. Of those, 93% were matched with residency positions. 82% of those seniors matched with residency positions were matched with one of their top $3$ choices. Find the probability that a randomly selected student was matched with a residency position and that it was one of their top $3$ choices."" This problem is easy to solve from an  ""algebraic"": $$\dfrac{.82 \cdot(\text{n. of students who got a residency position})}{\text{total number of students}}=\dfrac{.82(.93 \cdot 15,000)}{15,000} $$ However, when I tried to tackle this one like I did the card problem, everything collapsed. Without loss of generality, we let students $s_1$ to $s_{13950}$ be the students who got residency positions, and let students $s_1$ to $s_{11439}$ be the students who got matched with one of their top $3$ choices. If I try to multiply like I did with the cards problem, the results just don't make sense to me (even though I know it gives me the right answer): $$\dfrac{|\{s_1,...,s_{13950}\}|}{|\{s_1,...,s_{15000}\}|} \cdot \dfrac{|\{s_1,...,s_{11439}\}|}{|\{ s_1,...s_{13950} \}|} = \dfrac{|\{s_1s_1, s_1s_2,...,s_{13950}s_{11439} \}|}{|\{s_1s_1,...,s_{15000}s_{13950}\}|}$$ My questions are: Is my understanding fine for independent events? Can it be applied to dependent events (like with the card problem)? Can it be applied to problems containing only $1$ choice (like the last problem)?","I apologize in advance that this question has a long set-up. In the set up I am presenting how I currently understand the material, and the actual question is if my understanding is correct and applicable to more types of questions. I am referring to the rule $$P(A \text{ and } B)=P(A) \cdot P(B|A)$$ Or just $$P(A \text{ and } B)=P(A) \cdot P(B)$$ If the events are independent. I will be using absolute value bars as notation for the size of a set (i.e. $|\{z_1, z_2, ...z_n\}|=n$) I feel like I understand this rule for the most part when we have $2$ independent events. For example, rolling an even number on a standard dice and flipping ""tails"" with a coin. The way I understand this is as follows: $$ \dfrac{ \text{Desired outcomes}}{\text{Total Outcomes}} = \dfrac{|\{2T, 4T, 6T\}|}{|\{1H, 1T, 2H, 2T,...,6H, 6T\}|} =   \dfrac{|\{2, 4, 6 \}|}{|\{1, 2, 3, 4, 5, 6\}|} \cdot \dfrac{ |\{T\}|}{|\{H, T\}|}$$ When it comes to two dependent events, it mostly makes sense but I don't think I've completely internalized it. For example, if the question asks: ""Find the probability of drawing a king, and then a queen from a deck of cards without replacement."" I have a little bit of trouble making sense of this one in the context of one deck, so I just pretend that we have two decks, one with $52$ cards and the other with $51$ cards (with the king of diamonds missing), and I reduce the problem to drawing a king and a queen in sequence from the two decks. I think I can make sense of it the same way I made sense of the dice and the coin: $$ \dfrac{ \text{Desired outcomes}}{\text{Total Outcomes}} = \dfrac{|\{K_{clubs}Q_{clubs}, K_{clubs}Q_{spades},...,K_{diamonds}Q_{diamonds}\}|}{|\{Ace_{clubs}Ace_{clubs}, Ace_{clubs}Ace_{spades},..., K_{diamonds}K_{hearts} \}|} =   \dfrac{|\{K_{clubs}, K_{spades}, K_{hearts}, K_{diamond} \}|}{|\{Ace_{clubs}, Ace_{spades},...K_{diamonds}\}|} \cdot \dfrac{ |\{ Q_{clubs}, ... Q_{diamond}  \}|}{| \{Ace_{clubs}, Ace_{spades},...K_{hearts} \}|}$$ However, what really gives me trouble is when we have just one event. For example ""15,000 U.S. medical school seniors applied to residency programs in 2009. Of those, 93% were matched with residency positions. 82% of those seniors matched with residency positions were matched with one of their top $3$ choices. Find the probability that a randomly selected student was matched with a residency position and that it was one of their top $3$ choices."" This problem is easy to solve from an  ""algebraic"": $$\dfrac{.82 \cdot(\text{n. of students who got a residency position})}{\text{total number of students}}=\dfrac{.82(.93 \cdot 15,000)}{15,000} $$ However, when I tried to tackle this one like I did the card problem, everything collapsed. Without loss of generality, we let students $s_1$ to $s_{13950}$ be the students who got residency positions, and let students $s_1$ to $s_{11439}$ be the students who got matched with one of their top $3$ choices. If I try to multiply like I did with the cards problem, the results just don't make sense to me (even though I know it gives me the right answer): $$\dfrac{|\{s_1,...,s_{13950}\}|}{|\{s_1,...,s_{15000}\}|} \cdot \dfrac{|\{s_1,...,s_{11439}\}|}{|\{ s_1,...s_{13950} \}|} = \dfrac{|\{s_1s_1, s_1s_2,...,s_{13950}s_{11439} \}|}{|\{s_1s_1,...,s_{15000}s_{13950}\}|}$$ My questions are: Is my understanding fine for independent events? Can it be applied to dependent events (like with the card problem)? Can it be applied to problems containing only $1$ choice (like the last problem)?",,"['probability', 'statistics', 'intuition']"
4,A more game related stats question,A more game related stats question,,"There are an infinite amount of true-false questions. My goal is to get to 100 points. A correct answer will give me 1 point, and if I have 2 questions correct in a row, the any correct questions that are proceded by  2 correct questions will give me an additional point. So it's like a winning streak.  (Example: right, wrong, wrong, right, right, right , wrong. I receive 5 points) A incorrect answer will have no penalty except ending the bonus streak. The question is, if I completely guess all the questions, so 50%, how many questions do I expect to play in order to get to 100 points? Thanks all!","There are an infinite amount of true-false questions. My goal is to get to 100 points. A correct answer will give me 1 point, and if I have 2 questions correct in a row, the any correct questions that are proceded by  2 correct questions will give me an additional point. So it's like a winning streak.  (Example: right, wrong, wrong, right, right, right , wrong. I receive 5 points) A incorrect answer will have no penalty except ending the bonus streak. The question is, if I completely guess all the questions, so 50%, how many questions do I expect to play in order to get to 100 points? Thanks all!",,"['probability', 'combinatorics', 'statistics']"
5,Absolute continuity on limit,Absolute continuity on limit,,"In probability space $(\Omega,\mathcal{F},P)$, we have random variable $X$ that maps $\Omega$ into $R$. Assume $\mathbb{E}{|X|}<\infty$ and let $A_n$ be a sequence in $\mathcal{F}$ satysfying $\lim_{n \to \infty} P(A_n)=0$. Prove that $\lim_{n \to \infty} \int_{A_n} X dP =0$. I have proved it when we know $\lim_{n \to \infty} A_n$ exists: $\lim_{n \to \infty} \int_{A_n} X dP = \lim_{n \to \infty} \int_{\Omega} 1_{A_n}X dP $ Since  $|X 1_{A_n}| \leq |X|$ , we can use Dominated convergence theorem. Therefore, $\lim_{n \to \infty} \int_{A_n} X dP = \int_{\Omega} \lim_{n \to \infty}  1_{A_n}X dP  = \int_{\Omega}   1_{ \lim_{n \to \infty} A_n}X dP  = \int_{\lim_{n \to \infty} A_n}   X dP $ Then, by absolute continuity, I have claimed that $\lim_{n \to \infty} P(A_n)=0$ yields $\lim_{n \to \infty} \int_{A_n} X dP =0$. But, how we can prove this when we don't know $\lim_{n \to \infty} A_n$ exists?","In probability space $(\Omega,\mathcal{F},P)$, we have random variable $X$ that maps $\Omega$ into $R$. Assume $\mathbb{E}{|X|}<\infty$ and let $A_n$ be a sequence in $\mathcal{F}$ satysfying $\lim_{n \to \infty} P(A_n)=0$. Prove that $\lim_{n \to \infty} \int_{A_n} X dP =0$. I have proved it when we know $\lim_{n \to \infty} A_n$ exists: $\lim_{n \to \infty} \int_{A_n} X dP = \lim_{n \to \infty} \int_{\Omega} 1_{A_n}X dP $ Since  $|X 1_{A_n}| \leq |X|$ , we can use Dominated convergence theorem. Therefore, $\lim_{n \to \infty} \int_{A_n} X dP = \int_{\Omega} \lim_{n \to \infty}  1_{A_n}X dP  = \int_{\Omega}   1_{ \lim_{n \to \infty} A_n}X dP  = \int_{\lim_{n \to \infty} A_n}   X dP $ Then, by absolute continuity, I have claimed that $\lim_{n \to \infty} P(A_n)=0$ yields $\lim_{n \to \infty} \int_{A_n} X dP =0$. But, how we can prove this when we don't know $\lim_{n \to \infty} A_n$ exists?",,"['probability', 'measure-theory', 'lebesgue-integral']"
6,How many different ways can 64 players be paired?,How many different ways can 64 players be paired?,,"Suppose that there are 64 players in an arena. In how many ways can   the players be paired up (i.e. 32 different games)? I think the answer would be: $$\frac{\prod_{n=0}^{31} {64-2n\choose 2}}{32!}$$ I am not sure if this is a correct expression though, can anyone confirm? If it is, are there any simpler expression than the one I provided?","Suppose that there are 64 players in an arena. In how many ways can   the players be paired up (i.e. 32 different games)? I think the answer would be: $$\frac{\prod_{n=0}^{31} {64-2n\choose 2}}{32!}$$ I am not sure if this is a correct expression though, can anyone confirm? If it is, are there any simpler expression than the one I provided?",,"['probability', 'combinatorics', 'combinations']"
7,"Let $X|Y = y\sim\text{Poisson}(y)$ and $Y\sim\text{Gamma}(\alpha, \lambda)$. Find $f_X(x)$.",Let  and . Find .,"X|Y = y\sim\text{Poisson}(y) Y\sim\text{Gamma}(\alpha, \lambda) f_X(x)","Question: Let $X|Y = y\sim\text{Poisson}(y)$ and $Y\sim\text{Gamma}(\alpha, \lambda)$. Find join density $f_{X,Y}(x,y)$ and find the probability density function of $X$ (simplify until there are no integrals). Answer: So, I believe that the joint density function for this will be:  $$f_{X}(x|y) \cdot f_{Y}(y) = f_{X,Y}(x,y) = \frac{y^x \cdot e^{-y}}{x!} \cdot \frac{\lambda e^{-\lambda y}(\lambda y)^{\alpha-1}}{\Gamma(\alpha)}.$$ Next, in order to find the pdf of $X$, I need to  $$\int_{-\infty}^{\infty} f_{X,Y}(x,y)\,dy.$$ I tried to use integration by parts, but I couldn't find any answer. Does anyone know the approach to integrating $f_{X,Y}(x,y)\,dy$?","Question: Let $X|Y = y\sim\text{Poisson}(y)$ and $Y\sim\text{Gamma}(\alpha, \lambda)$. Find join density $f_{X,Y}(x,y)$ and find the probability density function of $X$ (simplify until there are no integrals). Answer: So, I believe that the joint density function for this will be:  $$f_{X}(x|y) \cdot f_{Y}(y) = f_{X,Y}(x,y) = \frac{y^x \cdot e^{-y}}{x!} \cdot \frac{\lambda e^{-\lambda y}(\lambda y)^{\alpha-1}}{\Gamma(\alpha)}.$$ Next, in order to find the pdf of $X$, I need to  $$\int_{-\infty}^{\infty} f_{X,Y}(x,y)\,dy.$$ I tried to use integration by parts, but I couldn't find any answer. Does anyone know the approach to integrating $f_{X,Y}(x,y)\,dy$?",,"['probability', 'probability-distributions', 'poisson-distribution', 'gamma-distribution']"
8,Prove $\sum_{i=1}^{\infty}P[A{\cap}C{\cap}Bi] = P[A{\cap}C]$.,Prove .,\sum_{i=1}^{\infty}P[A{\cap}C{\cap}Bi] = P[A{\cap}C],How to prove this mathematically rather than using venn diagram?   $$\sum_{i=1}^{\infty}P[A{\cap}C{\cap}Bi] = P[A{\cap}C]$$   where $B_i$ is the partition of $C$ (not $S$). $A$ and $C$ are arbitrary sets. I have proved that  $$A{\cap}C = A{\cap}C{\cap}C = A{\cap}C{\cap}\left({\bigcup_{i=1}^{\infty}}B_i\right) = {\bigcup_{i=1}^{\infty}}(A{\cap}C{\cap}B_i).$$ Thus $$P(A{\cap}C) = P\left({\bigcup_{i=1}^{\infty}}(A{\cap}C{\cap}B_i)\right)$$ Then I need to apply the axiom of probability/measure to get the summation out. However how do I know each $A{\cap}C{\cap}B_i$ are disjoint with each other using a formal proof instead of Venn diagram?,How to prove this mathematically rather than using venn diagram?   $$\sum_{i=1}^{\infty}P[A{\cap}C{\cap}Bi] = P[A{\cap}C]$$   where $B_i$ is the partition of $C$ (not $S$). $A$ and $C$ are arbitrary sets. I have proved that  $$A{\cap}C = A{\cap}C{\cap}C = A{\cap}C{\cap}\left({\bigcup_{i=1}^{\infty}}B_i\right) = {\bigcup_{i=1}^{\infty}}(A{\cap}C{\cap}B_i).$$ Thus $$P(A{\cap}C) = P\left({\bigcup_{i=1}^{\infty}}(A{\cap}C{\cap}B_i)\right)$$ Then I need to apply the axiom of probability/measure to get the summation out. However how do I know each $A{\cap}C{\cap}B_i$ are disjoint with each other using a formal proof instead of Venn diagram?,,"['probability', 'probability-theory']"
9,"If $X$ is a non-negative r.v., and $E(X\mathbb{1}_{X>t}) \leq \frac{2}{t}$, show $E(X\mathbb{1}_{E}) \leq \sqrt{8P(E)}$ for any $E \in \mathcal{F}$?","If  is a non-negative r.v., and , show  for any ?",X E(X\mathbb{1}_{X>t}) \leq \frac{2}{t} E(X\mathbb{1}_{E}) \leq \sqrt{8P(E)} E \in \mathcal{F},"Suppose that $X$ is a non-negative r.v. on $(\Omega, \mathcal{F}, \mathrm{P})$ where for $t>0$, it is true that $\mathbb{E}(X\mathbb{1}_{X>t}) \leq \frac{2}{t}$. I want to show that for any $E \in \mathcal{F}$, we have that: $$ \mathbb{E}(X\mathbb{1}_{E}) \leq \sqrt{8\mathrm{P}(E)} $$ Any idea that comes to mind is Markov's inequality. However, I am not sure how to manipulate what is given that my expectation on the left is bounded above by $\frac{2}{t}$. Could anyone give a hint? Thanks.","Suppose that $X$ is a non-negative r.v. on $(\Omega, \mathcal{F}, \mathrm{P})$ where for $t>0$, it is true that $\mathbb{E}(X\mathbb{1}_{X>t}) \leq \frac{2}{t}$. I want to show that for any $E \in \mathcal{F}$, we have that: $$ \mathbb{E}(X\mathbb{1}_{E}) \leq \sqrt{8\mathrm{P}(E)} $$ Any idea that comes to mind is Markov's inequality. However, I am not sure how to manipulate what is given that my expectation on the left is bounded above by $\frac{2}{t}$. Could anyone give a hint? Thanks.",,"['probability', 'probability-theory', 'inequality', 'stochastic-processes']"
10,"""Self-referential"" probability mass functions","""Self-referential"" probability mass functions",,"I am currently self-studying information theory from ""Quantum Information Theory"" by Mark M. Wilde. He uses a kind of notation that I don't understand at all. I will explain the problem using quotations from the book: Let $p_X(x)$ be the probability mass function associated with random variable $X$, so that the probability of realization $x$ is $p_X(x)$... So far, so good. The random variable $X$ can produce different numbers, and if it produces (say) $0.5$ with probability $0.25$, then $p_X(0.5)=0.25$. I start to fall to pieces a little latter, when the author begins to write things like $p_X(X)$. I'm not sure how to read this notation. It seems to be saying that the random variable has itself as an output? The author goes on to write: There is nothing wrong mathematically here with having a random variable $X$ as the argument to the density function $p_X$, though this expression may seem self-referential at first. And later, when introducing the same notation again: It may seem strange at first glance that $X$, the argument of the probability mass function $p_X$ is itself a random variable, but this type of expression is perfectly well-defined mathematically. But how is it defined ? That's my question. I'm not looking for a rigorous answer, but a wordy explanation of how I can read/interpret such an expression, and maybe a simple example, would be truly appreciated.","I am currently self-studying information theory from ""Quantum Information Theory"" by Mark M. Wilde. He uses a kind of notation that I don't understand at all. I will explain the problem using quotations from the book: Let $p_X(x)$ be the probability mass function associated with random variable $X$, so that the probability of realization $x$ is $p_X(x)$... So far, so good. The random variable $X$ can produce different numbers, and if it produces (say) $0.5$ with probability $0.25$, then $p_X(0.5)=0.25$. I start to fall to pieces a little latter, when the author begins to write things like $p_X(X)$. I'm not sure how to read this notation. It seems to be saying that the random variable has itself as an output? The author goes on to write: There is nothing wrong mathematically here with having a random variable $X$ as the argument to the density function $p_X$, though this expression may seem self-referential at first. And later, when introducing the same notation again: It may seem strange at first glance that $X$, the argument of the probability mass function $p_X$ is itself a random variable, but this type of expression is perfectly well-defined mathematically. But how is it defined ? That's my question. I'm not looking for a rigorous answer, but a wordy explanation of how I can read/interpret such an expression, and maybe a simple example, would be truly appreciated.",,"['probability', 'probability-theory', 'probability-distributions', 'information-theory']"
11,How many 13 hand cards have one ace?,How many 13 hand cards have one ace?,,"I know the answer is ${4 \choose 1}{48 \choose 12}/{52 \choose 13}$. But I have trouble rationalizing it. Why is it not ${13 \choose 1}{4 \choose 1}{48 \choose 12}/{52 \choose 13}$ as in choose which of the $13$ spots the ace goes into and then choosing which of the $4$ aces and then choosing the rest of the twelve hands? I know it's wrong, but why is it wrong to think like this? Sorry I am really bad at combinatorics. Thanks.","I know the answer is ${4 \choose 1}{48 \choose 12}/{52 \choose 13}$. But I have trouble rationalizing it. Why is it not ${13 \choose 1}{4 \choose 1}{48 \choose 12}/{52 \choose 13}$ as in choose which of the $13$ spots the ace goes into and then choosing which of the $4$ aces and then choosing the rest of the twelve hands? I know it's wrong, but why is it wrong to think like this? Sorry I am really bad at combinatorics. Thanks.",,"['probability', 'combinatorics']"
12,"Conditional expectation of $E(\max(X,a)\mid\min(X,a))$ when $X$ is exponentially distributed",Conditional expectation of  when  is exponentially distributed,"E(\max(X,a)\mid\min(X,a)) X","I am trying to compute the conditional expectation $$E\left[\max{(X,a)} \mid \min{(X,a)}\right]$$ where $X\sim \exp(a)$ and $a$ is a constant. I set $U=\min{(X,a)},W=\max{(X,a)}$, and computed the joint distribution as  $$F_{UW}(u,w)=\begin{cases}P(X\le u,a\le w)+P(X\le w,a\le u)-P(X\le u,a\le u)& u<w\\P(X\le w,a\le w) &w<u\end{cases}$$ Then I don't know how to proceed. Can I differentiate $F_{UW}$ to find the joint density? Also, is there any easy way to compute without finding the joint density? These is a similar question here , but it involves two continuous r.v.","I am trying to compute the conditional expectation $$E\left[\max{(X,a)} \mid \min{(X,a)}\right]$$ where $X\sim \exp(a)$ and $a$ is a constant. I set $U=\min{(X,a)},W=\max{(X,a)}$, and computed the joint distribution as  $$F_{UW}(u,w)=\begin{cases}P(X\le u,a\le w)+P(X\le w,a\le u)-P(X\le u,a\le u)& u<w\\P(X\le w,a\le w) &w<u\end{cases}$$ Then I don't know how to proceed. Can I differentiate $F_{UW}$ to find the joint density? Also, is there any easy way to compute without finding the joint density? These is a similar question here , but it involves two continuous r.v.",,"['probability', 'probability-theory', 'probability-distributions']"
13,Conditional expectation $E(XY\mid Z)$,Conditional expectation,E(XY\mid Z),"I'm trying to solve the following problem: let $X$ and $Y$ be 2 independent standard normal random variables and let be $Z=X+Y$. Calculate $E(XY\mid Z)$. I tried many approaches, but without getting the result. Any suggestion? We know previously that $Z=X+Y$ and $W=X-Y$ are independent and that $E(X\mid Z)=\frac{1}{2}Z$.","I'm trying to solve the following problem: let $X$ and $Y$ be 2 independent standard normal random variables and let be $Z=X+Y$. Calculate $E(XY\mid Z)$. I tried many approaches, but without getting the result. Any suggestion? We know previously that $Z=X+Y$ and $W=X-Y$ are independent and that $E(X\mid Z)=\frac{1}{2}Z$.",,"['probability', 'conditional-expectation']"
14,Probability of an even number of sixes,Probability of an even number of sixes,,"We throw a fair die $n$ times, show that the probability that there are an even number of sixes is $\frac{1}{2}[1+(\frac{2}{3})^n]$. For the purpose of this question, 0 is even. I tried doing this problem with induction, but I have problem with induction so I was wondering if my solution was correct: The base case: For $n=0$, our formula gives us $\frac{1}{2}[1+(\frac{2}{3})^0] =1$. This is true, because if we throw the die zero times, we always get zero sixes. Suppose it's true for $n=k$. Then the odds of an even number of sixes is $\frac{1}{2}[1+(\frac{2}{3})^n]$, and thus the odds of an odd number of sixes is $1 - \frac{1}{2}[1+(\frac{2}{3})^n]$. For $n=k+1$, there are two ways the number of sixes are even: a. The number of sixes for $n=k$ was even, and we do not throw a six for $n=k+1$: $ \frac{5}{6} \cdot  \frac{1}{2}[1+(\frac{2}{3})^n]$ b. The number of sixes for $n=k$ was odd, and we throw a six for $n=k+1$: $\frac{1}{6}(1 - \frac{1}{2}[1+(\frac{2}{3})^n])$ So the probability $p$ for an even number of sixes at $n=k+1$ is $ \frac{5}{6} \cdot  \frac{1}{2}[1+(\frac{2}{3})^n] + \frac{1}{6}(1 - \frac{1}{2}[1+(\frac{2}{3})^n])$ I have two questions How do I get from $ \frac{5}{6} \cdot  \frac{1}{2}[1+(\frac{2}{3})^n] + \frac{1}{6}(1 - \frac{1}{2}[1+(\frac{2}{3})^n])$ to $\frac{1}{2}[1+(\frac{2}{3})^n]$? I seem to have done something wrong, I can't get the algebra correct, I get $p = \frac{1}{3}[1+(\frac{2}{3})^n] + \dfrac{1}{6}$ Other than that, is my use of induction correct? Is it rigorous enough to prove the formula?","We throw a fair die $n$ times, show that the probability that there are an even number of sixes is $\frac{1}{2}[1+(\frac{2}{3})^n]$. For the purpose of this question, 0 is even. I tried doing this problem with induction, but I have problem with induction so I was wondering if my solution was correct: The base case: For $n=0$, our formula gives us $\frac{1}{2}[1+(\frac{2}{3})^0] =1$. This is true, because if we throw the die zero times, we always get zero sixes. Suppose it's true for $n=k$. Then the odds of an even number of sixes is $\frac{1}{2}[1+(\frac{2}{3})^n]$, and thus the odds of an odd number of sixes is $1 - \frac{1}{2}[1+(\frac{2}{3})^n]$. For $n=k+1$, there are two ways the number of sixes are even: a. The number of sixes for $n=k$ was even, and we do not throw a six for $n=k+1$: $ \frac{5}{6} \cdot  \frac{1}{2}[1+(\frac{2}{3})^n]$ b. The number of sixes for $n=k$ was odd, and we throw a six for $n=k+1$: $\frac{1}{6}(1 - \frac{1}{2}[1+(\frac{2}{3})^n])$ So the probability $p$ for an even number of sixes at $n=k+1$ is $ \frac{5}{6} \cdot  \frac{1}{2}[1+(\frac{2}{3})^n] + \frac{1}{6}(1 - \frac{1}{2}[1+(\frac{2}{3})^n])$ I have two questions How do I get from $ \frac{5}{6} \cdot  \frac{1}{2}[1+(\frac{2}{3})^n] + \frac{1}{6}(1 - \frac{1}{2}[1+(\frac{2}{3})^n])$ to $\frac{1}{2}[1+(\frac{2}{3})^n]$? I seem to have done something wrong, I can't get the algebra correct, I get $p = \frac{1}{3}[1+(\frac{2}{3})^n] + \dfrac{1}{6}$ Other than that, is my use of induction correct? Is it rigorous enough to prove the formula?",,"['probability', 'induction']"
15,Can someone explain what a portfolio is in financial math?,Can someone explain what a portfolio is in financial math?,,"I took mathematical probability last semester and now I am taking financial mathematics, but only probability was a pre requisite for financial math (no finance classes were required). These types of questions re confusing me because I don't quite understand financial terminology and I guess my professor thinks that we had taken finance classes in the past. Can someone explain what a portfolio is and what $V(O)$, $V(T)$, and $K_v$ is referring to in this question? Let $A(0)=90$, $A(T)=100$, $S(0)=25$ dollars and let $$S(T) = \begin{cases} 30,  & \text{with probability } p \\ 20, & \text{with probability } 1-p \end{cases}$$ where $0 < p < 1$. For a portfolio with $x=10$ shares and $y=15$ bonds, calculate $V(0)$, $V(T)$, and $K_V$. I know what a random variable is and how to solve for expectation because I learned that in probability, but I just don't know what these finance terms are refering to?","I took mathematical probability last semester and now I am taking financial mathematics, but only probability was a pre requisite for financial math (no finance classes were required). These types of questions re confusing me because I don't quite understand financial terminology and I guess my professor thinks that we had taken finance classes in the past. Can someone explain what a portfolio is and what $V(O)$, $V(T)$, and $K_v$ is referring to in this question? Let $A(0)=90$, $A(T)=100$, $S(0)=25$ dollars and let $$S(T) = \begin{cases} 30,  & \text{with probability } p \\ 20, & \text{with probability } 1-p \end{cases}$$ where $0 < p < 1$. For a portfolio with $x=10$ shares and $y=15$ bonds, calculate $V(0)$, $V(T)$, and $K_V$. I know what a random variable is and how to solve for expectation because I learned that in probability, but I just don't know what these finance terms are refering to?",,"['probability', 'random-variables', 'finance']"
16,Matching problem expectation and variance,Matching problem expectation and variance,,"The matching problem : Suppose $n$ gentlemen go out for dinner and leave their hats in the cloakroom.  After the dinner (and several glasses of wine) they pick their hats completely randomly.  Denote by $X$ the number of gentlemen who take their own hats.  Find $E[X]$ and $Var[X]$. I have seen many answers to this: $E[X] = \sum_i^nE(I_i)= \sum_i^n 1/n = 1$, where $I_i$ is the indicator for each person which equals $1$ if the person takes his hat own hat and $0$ otherwise. I don't understand how the probability of $I_i$ can be $1/n$ for all of $I_i$.  Consider the third gentleman to take a hat; wouldn't the probability he take his hat be $1/(n-3)$ rather than $1/n$?","The matching problem : Suppose $n$ gentlemen go out for dinner and leave their hats in the cloakroom.  After the dinner (and several glasses of wine) they pick their hats completely randomly.  Denote by $X$ the number of gentlemen who take their own hats.  Find $E[X]$ and $Var[X]$. I have seen many answers to this: $E[X] = \sum_i^nE(I_i)= \sum_i^n 1/n = 1$, where $I_i$ is the indicator for each person which equals $1$ if the person takes his hat own hat and $0$ otherwise. I don't understand how the probability of $I_i$ can be $1/n$ for all of $I_i$.  Consider the third gentleman to take a hat; wouldn't the probability he take his hat be $1/(n-3)$ rather than $1/n$?",,"['probability', 'random-variables', 'expectation']"
17,Good introductory book coupling methods,Good introductory book coupling methods,,"I am very interested in coupling methods, can you recommend me a good introductory books  on this subject? Thanks","I am very interested in coupling methods, can you recommend me a good introductory books  on this subject? Thanks",,"['probability', 'reference-request', 'book-recommendation', 'markov-process', 'coupling']"
18,Probability of $A$ given $\neg B \:?$,Probability of  given,A \neg B \:?,"If we have the probabilities of $P(A)$, $P(B)$ and $P(A\mid B)$, how can we calculate the probability of $P(A\mid\neg B)$ ? Does $A$ depends on $\neg B$ if it Actually depends on $B$ ?","If we have the probabilities of $P(A)$, $P(B)$ and $P(A\mid B)$, how can we calculate the probability of $P(A\mid\neg B)$ ? Does $A$ depends on $\neg B$ if it Actually depends on $B$ ?",,"['probability', 'random-variables', 'independence']"
19,Question on the distribution of eigenvalues in a square matrix with random entries.,Question on the distribution of eigenvalues in a square matrix with random entries.,,"Let square matrix $A$ of size $n \times n$, have entries that have been independently sampled from a uniform distribution between $[a_1,a_2]$. The symmetric part of $A$, $A_s$ is defined as $\frac{1}{2}(A+A^T)$. The question I have is what distribution will the eigenvalues of the symmetric part $A_s$ fall under? My Approach: My exploration began by looking at the characteristic polynomial of $A_s$ $$P_A(t) = det(tI - A_s)$$ The roots of the characteristic polynomial will be the eigenvalues of the $A_s$. By Leibniz's formula the determinant will be equal to:  $$det(M) = \sum_{\sigma \in S_n}{sgn(\sigma)\prod_{i=1}^{n}{m_{i,\sigma_i}}}$$ Where the sum is computed over all the permutations of $\{1,2,3,...n\}$, and $sgn$ is the parity of the permutation. My intuition from looking at Leibniz's formula tells me that the eigenvalues should also be distributed uniformly bounded by new constants. But I have not found a way to show this. Any help is much appreciated.","Let square matrix $A$ of size $n \times n$, have entries that have been independently sampled from a uniform distribution between $[a_1,a_2]$. The symmetric part of $A$, $A_s$ is defined as $\frac{1}{2}(A+A^T)$. The question I have is what distribution will the eigenvalues of the symmetric part $A_s$ fall under? My Approach: My exploration began by looking at the characteristic polynomial of $A_s$ $$P_A(t) = det(tI - A_s)$$ The roots of the characteristic polynomial will be the eigenvalues of the $A_s$. By Leibniz's formula the determinant will be equal to:  $$det(M) = \sum_{\sigma \in S_n}{sgn(\sigma)\prod_{i=1}^{n}{m_{i,\sigma_i}}}$$ Where the sum is computed over all the permutations of $\{1,2,3,...n\}$, and $sgn$ is the parity of the permutation. My intuition from looking at Leibniz's formula tells me that the eigenvalues should also be distributed uniformly bounded by new constants. But I have not found a way to show this. Any help is much appreciated.",,"['linear-algebra', 'probability', 'matrices']"
20,Kullback-Leibler divergence and mixture distributions,Kullback-Leibler divergence and mixture distributions,,"Let's say I have three probability densities, $h, g$, and $f$, where f is a weighted mixture of h and g, i.e., $$ f(x) = w\,h(x) + (1-w)\,g(x) $$ For simplicity, let's assume all densities share the same support. Now, it seems reasonable to expect that if, say, $h$ is the ""true"" density, then the Kullback-Leibler divergence (KL) between $f$ and $h$ should be smaller than KL between $g$ and $h$, i.e., $$ KL(f,h) \leq KL(g,h) $$ as $|f(x) - h(x)| \leq |g(x) - h(x)|$ everywhere. However, I have no idea how to prove this, and would be very happy about any suggestions (or suggestions why my intuition might be wrong). Thanks in advance!","Let's say I have three probability densities, $h, g$, and $f$, where f is a weighted mixture of h and g, i.e., $$ f(x) = w\,h(x) + (1-w)\,g(x) $$ For simplicity, let's assume all densities share the same support. Now, it seems reasonable to expect that if, say, $h$ is the ""true"" density, then the Kullback-Leibler divergence (KL) between $f$ and $h$ should be smaller than KL between $g$ and $h$, i.e., $$ KL(f,h) \leq KL(g,h) $$ as $|f(x) - h(x)| \leq |g(x) - h(x)|$ everywhere. However, I have no idea how to prove this, and would be very happy about any suggestions (or suggestions why my intuition might be wrong). Thanks in advance!",,"['probability', 'statistics', 'information-theory']"
21,Probability for a sum of independent gamma random variables,Probability for a sum of independent gamma random variables,,"Suppose we are told that the weight of each gum ball (in centigrams) is given by the gamma distribution function, with $α=25$ and $β=2$.   Find the probability that 100 gum balls will go over the limit of a standard package of $52g$. I use central limit theorem to normalize to random variable Z, and I get the probability is around $0.42$, while my solution says $0.0228$.","Suppose we are told that the weight of each gum ball (in centigrams) is given by the gamma distribution function, with $α=25$ and $β=2$.   Find the probability that 100 gum balls will go over the limit of a standard package of $52g$. I use central limit theorem to normalize to random variable Z, and I get the probability is around $0.42$, while my solution says $0.0228$.",,['probability']
22,Three people each flip two fair coins.Find the probability that exactly two of the people flipped one head and one tail.,Three people each flip two fair coins.Find the probability that exactly two of the people flipped one head and one tail.,,"Three people each flip two fair coins.Find the probability that exactly two of the people flipped one head and one tail. Out of three persons,two persons can be chosen in $\binom{3}{2}$ ways.Each person flips two fair coins.So each persons gets $HH,HT,TH,TT$.Probability of a person getting one head and one tail is $\frac{1}{2}$. So the probability that exactly two of the people flipped one head and one tail is $\binom{3}{2}\times\frac{1}{2}\times\frac{1}{2}=\frac{3}{4}$ But my answer is wrong.What is wrong in my approach.Please help me.","Three people each flip two fair coins.Find the probability that exactly two of the people flipped one head and one tail. Out of three persons,two persons can be chosen in $\binom{3}{2}$ ways.Each person flips two fair coins.So each persons gets $HH,HT,TH,TT$.Probability of a person getting one head and one tail is $\frac{1}{2}$. So the probability that exactly two of the people flipped one head and one tail is $\binom{3}{2}\times\frac{1}{2}\times\frac{1}{2}=\frac{3}{4}$ But my answer is wrong.What is wrong in my approach.Please help me.",,"['probability', 'combinatorics']"
23,Limit as n to infinity of sum to n -- changing upper bound to infinity?,Limit as n to infinity of sum to n -- changing upper bound to infinity?,,"I am just wondering if, in general, $$\lim_{n\to\infty} \sum_{i=1}^n x_i = \sum_{i=1}^\infty x_i$$ or perhaps it is specific to probability, where I am currently seeing it, such as $$\lim_{n\to\infty} \sum_{i=1}^n P(B_i) = \sum_{i=1}^\infty P(B_i)$$ with $B_i$ all being disjoint sets, if that matters. Is this a definition? If it is, can someone provide me a credible link that confirms it? I believe you, but my google searching is not yielding any links that say it is a definition. If it is not a definition how could I prove it? It seems to me the standard $\epsilon$-$\delta$ definition of limit wouldn't be very helpful here, as we are not talking about the limit at a point but instead the limit is changing the number of terms summed... thats why I am leaning towards this being a definition. Thanks","I am just wondering if, in general, $$\lim_{n\to\infty} \sum_{i=1}^n x_i = \sum_{i=1}^\infty x_i$$ or perhaps it is specific to probability, where I am currently seeing it, such as $$\lim_{n\to\infty} \sum_{i=1}^n P(B_i) = \sum_{i=1}^\infty P(B_i)$$ with $B_i$ all being disjoint sets, if that matters. Is this a definition? If it is, can someone provide me a credible link that confirms it? I believe you, but my google searching is not yielding any links that say it is a definition. If it is not a definition how could I prove it? It seems to me the standard $\epsilon$-$\delta$ definition of limit wouldn't be very helpful here, as we are not talking about the limit at a point but instead the limit is changing the number of terms summed... thats why I am leaning towards this being a definition. Thanks",,"['probability', 'limits', 'summation', 'arithmetic']"
24,Eddington's controversy simplified,Eddington's controversy simplified,,"I have been given the following probability problem: A, B and C are three people, who each independently speak the truth one of three times. A denies that B declares that C is lying. What is the probability that C is telling the truth? This problem is similar to Eddington's controversy If A, B, C, D each speaks the truth 1 in 3 times (independently), and A affirms that B denies that C delcares that D is a liar, what’s the probability that D was speaking the truth? I believe that the answer to the Eddington's problem was $\frac{25}{71}$ as given by Eddington himself. However, the other solution (based on different initial assumptions) is $\frac{13}{41}$ . My question is, how are the above solutions worked out? If I understand the logic behind Eddington's problem, I hope I can solve my probability problem.","I have been given the following probability problem: A, B and C are three people, who each independently speak the truth one of three times. A denies that B declares that C is lying. What is the probability that C is telling the truth? This problem is similar to Eddington's controversy If A, B, C, D each speaks the truth 1 in 3 times (independently), and A affirms that B denies that C delcares that D is a liar, what’s the probability that D was speaking the truth? I believe that the answer to the Eddington's problem was as given by Eddington himself. However, the other solution (based on different initial assumptions) is . My question is, how are the above solutions worked out? If I understand the logic behind Eddington's problem, I hope I can solve my probability problem.",\frac{25}{71} \frac{13}{41},['probability']
25,"Probability of exactly two pairs share a birthday, and each pair shares different birthday","Probability of exactly two pairs share a birthday, and each pair shares different birthday",,"This isn't for homework, just a thought. Let's say there are $n$ people where $n \leq 365$ (I'm not entirely sure how to approach the problem if $n > 365$ and inquire about that down below). What is the probability that there are exactly two pairs with the same birthday, and each of the pairs have a different birthday (e.g. Alice and Bob share a birthday on June 8th, Charlotte and Dylan share a birthday on December 1st.), assuming that birthdays are evenly distributed and we pick a completely random sample of $n$ people. My attempt to solve is the following: The sample space is represented by the $365^n$ different combinations of birthdays for the $n$ people. The number of ways that exactly two pairs share a birthday, and the birthday each pair shares is different, is given by $n \choose 2$$(365)$$n - 2 \choose 2$$(364)(\frac{363!}{(363-(n-4))!})$ The explanation is that we first pick two individuals to have the same birthday, then another two individuals to have a different same birthday from the remaining 364 days, and then finally have rest of the $n-4$ individuals all have different birthdays. The solution is thus given by the numerator divided by the sample space (having trouble using latex format with the chooses, I apologize). A couple of questions: Is the above solution correct for $n < 365$? If I try to think about if $n > 365$ the combinatorics I use in the last part $\frac{363!}{(363-(n-4))!}$ doesn't make sense anymore, so I was thinking about how I could use a different approach. Someone hinted that I could try to calculate the conditional probability that there is exactly one pair that shares a birthday given that I remove a pair that shares a birthday. I'm envisioning the distribution as a bell curve of some sort, but am getting overwhelmed in the details of how to account for all the cases. I would appreciate any hints or pointers!","This isn't for homework, just a thought. Let's say there are $n$ people where $n \leq 365$ (I'm not entirely sure how to approach the problem if $n > 365$ and inquire about that down below). What is the probability that there are exactly two pairs with the same birthday, and each of the pairs have a different birthday (e.g. Alice and Bob share a birthday on June 8th, Charlotte and Dylan share a birthday on December 1st.), assuming that birthdays are evenly distributed and we pick a completely random sample of $n$ people. My attempt to solve is the following: The sample space is represented by the $365^n$ different combinations of birthdays for the $n$ people. The number of ways that exactly two pairs share a birthday, and the birthday each pair shares is different, is given by $n \choose 2$$(365)$$n - 2 \choose 2$$(364)(\frac{363!}{(363-(n-4))!})$ The explanation is that we first pick two individuals to have the same birthday, then another two individuals to have a different same birthday from the remaining 364 days, and then finally have rest of the $n-4$ individuals all have different birthdays. The solution is thus given by the numerator divided by the sample space (having trouble using latex format with the chooses, I apologize). A couple of questions: Is the above solution correct for $n < 365$? If I try to think about if $n > 365$ the combinatorics I use in the last part $\frac{363!}{(363-(n-4))!}$ doesn't make sense anymore, so I was thinking about how I could use a different approach. Someone hinted that I could try to calculate the conditional probability that there is exactly one pair that shares a birthday given that I remove a pair that shares a birthday. I'm envisioning the distribution as a bell curve of some sort, but am getting overwhelmed in the details of how to account for all the cases. I would appreciate any hints or pointers!",,['probability']
26,Transformation of variables for a non-monotonic function,Transformation of variables for a non-monotonic function,,"Question: Let $U \sim \mathrm{Unif}(−α, α)$ follow the uniform distribution on the interval $(−α, α)$ for some parameter $α > 0$ and consider the transformed random variable $X = \sin(U)$. Calculate the pdf of $X$ when $\alpha = 2\pi$ Could anyone help me with this question? I don't think you can use the transformation of variables formula as $\sin(U)$ isn't monotonic on the interval $(-2\pi,2\pi)$. I've tried doing this: $F_x(x) = P(X\le x) = P(\sin U \le x) = P(U \le \arcsin(x)) = F_U(\arcsin(x))$. Not too sure where to go from here. Any help would be appreciated.","Question: Let $U \sim \mathrm{Unif}(−α, α)$ follow the uniform distribution on the interval $(−α, α)$ for some parameter $α > 0$ and consider the transformed random variable $X = \sin(U)$. Calculate the pdf of $X$ when $\alpha = 2\pi$ Could anyone help me with this question? I don't think you can use the transformation of variables formula as $\sin(U)$ isn't monotonic on the interval $(-2\pi,2\pi)$. I've tried doing this: $F_x(x) = P(X\le x) = P(\sin U \le x) = P(U \le \arcsin(x)) = F_U(\arcsin(x))$. Not too sure where to go from here. Any help would be appreciated.",,"['probability', 'statistics', 'transformation', 'uniform-distribution', 'density-function']"
27,"Drawing 2 marbles from a box with 3 red, 3 purple, 5 green, and 7 blue marbles.","Drawing 2 marbles from a box with 3 red, 3 purple, 5 green, and 7 blue marbles.",,"A box contains 3 red, 3 purple, 5 green, and 7 blue marbles. 2 marbles are selected from the box without replacement. What is the probability that you choose both marbles to be red or both marbles to be purple. So far, I have figured out (I think): $$\text{ Probability of both red  }= \frac{3}{\binom{18}{2}} = \frac{3}{(\frac{18!}{2!16!})} = \frac{3}{153}$$ Is this correct?","A box contains 3 red, 3 purple, 5 green, and 7 blue marbles. 2 marbles are selected from the box without replacement. What is the probability that you choose both marbles to be red or both marbles to be purple. So far, I have figured out (I think): $$\text{ Probability of both red  }= \frac{3}{\binom{18}{2}} = \frac{3}{(\frac{18!}{2!16!})} = \frac{3}{153}$$ Is this correct?",,"['probability', 'discrete-mathematics']"
28,Proving a bound with binomial coefficients,Proving a bound with binomial coefficients,,I'm trying to prove the inequality below: $$ \frac{\sum^{n/2 + \sqrt{n}}_{j=0} {n \choose j}}{2^n} \geq 0.95 $$ I have no idea where to start. I have tried to fill in the formula for small values of n and I see that it holds but I'm unable to proof this. Can anyone give a hint on how to prove this? Any help would be greatly appreciated.,I'm trying to prove the inequality below: $$ \frac{\sum^{n/2 + \sqrt{n}}_{j=0} {n \choose j}}{2^n} \geq 0.95 $$ I have no idea where to start. I have tried to fill in the formula for small values of n and I see that it holds but I'm unable to proof this. Can anyone give a hint on how to prove this? Any help would be greatly appreciated.,,"['probability', 'inequality', 'binomial-coefficients']"
29,What is the probability that nobody is born in the same month?,What is the probability that nobody is born in the same month?,,"You have 12 people in a room, what is the probability that nobody is born in the same month? So far i have: $\frac{12!}{12^{12}}$ but i am not sure if this is right. If anyone could confirm this is the way to go or tell me where i am wrong it would help me alot. Thank you.","You have 12 people in a room, what is the probability that nobody is born in the same month? So far i have: $\frac{12!}{12^{12}}$ but i am not sure if this is right. If anyone could confirm this is the way to go or tell me where i am wrong it would help me alot. Thank you.",,['probability']
30,Find expectation of Z (normal),Find expectation of Z (normal),,"Assume the following PDF . $$f(z) = \frac{1}{\sqrt{2π}}e^{-(z^2 / 2)}$$ Find E(z). For now, I got E(z) = $\int_{-\infty}^{\infty} f_z(z) dz $ And for any odd function F, (i.e. F(−x) = −F(x)∀x ∈ R), $\int_{-\infty}^{\infty} f_z(z) dz= 0$ So, the function zf(z) = $$ z*e^{-(z^2 / 2)} \frac{1}{\sqrt{2π}}$$ is an odd function. Hence E(Z) = 0. Is it correct? Or is there another way to solve this problem?","Assume the following PDF . $$f(z) = \frac{1}{\sqrt{2π}}e^{-(z^2 / 2)}$$ Find E(z). For now, I got E(z) = $\int_{-\infty}^{\infty} f_z(z) dz $ And for any odd function F, (i.e. F(−x) = −F(x)∀x ∈ R), $\int_{-\infty}^{\infty} f_z(z) dz= 0$ So, the function zf(z) = $$ z*e^{-(z^2 / 2)} \frac{1}{\sqrt{2π}}$$ is an odd function. Hence E(Z) = 0. Is it correct? Or is there another way to solve this problem?",,"['probability', 'normal-distribution', 'expectation']"
31,What probability would you assign to India's win?,What probability would you assign to India's win?,,"Karan tells truth with probability $\frac 13$ and lies with probability $\frac 23$. Independently, Arjun tells truth with probability $\frac 34$ and lies with probability $\frac 14$. Both watch a cricket match. Arjun tells you that India won, Karan tells you that India lost. What probability will you assign to India's win? $(a) \frac  12$ $(b)\frac 23$ $(c)\frac  34$ $(d)\frac 56$ $(e)\frac 67$ According to me the answer should be $\frac 12$ i.e option $(a)$ Arjun told: India won, Karan told: India lost, Probability of India won = Probability that Arjun told truth$(=\frac 34)$ & Karan lied$(= \frac 23)$ So probability that India won = $\frac 34\times\frac 23 =\frac 12$. Is it correct?","Karan tells truth with probability $\frac 13$ and lies with probability $\frac 23$. Independently, Arjun tells truth with probability $\frac 34$ and lies with probability $\frac 14$. Both watch a cricket match. Arjun tells you that India won, Karan tells you that India lost. What probability will you assign to India's win? $(a) \frac  12$ $(b)\frac 23$ $(c)\frac  34$ $(d)\frac 56$ $(e)\frac 67$ According to me the answer should be $\frac 12$ i.e option $(a)$ Arjun told: India won, Karan told: India lost, Probability of India won = Probability that Arjun told truth$(=\frac 34)$ & Karan lied$(= \frac 23)$ So probability that India won = $\frac 34\times\frac 23 =\frac 12$. Is it correct?",,['probability']
32,distribution of a random variable that depends on another random variable,distribution of a random variable that depends on another random variable,,"Let X be a Poisson random variable, $X \thicksim Po(\lambda Y) $ where $Y \thicksim Exp(\alpha)$. Now I would like to compute the distribution of X. If I conditionate on $Y=c$, I find $P(X=0|Y=c)=e^{\lambda c}$. But, in general, how can I compute $P(X=0)?$ I think that I have to take the mean, and so $P(X=0)=E(e^{\lambda y})=\int_{0}^{\infty}e^{\lambda z}\alpha e^{- \alpha z}dz$. But I don't understand why, how can I show the previous equality and how I have to look at this problem.(the variable that I'm studying is a function of random variable or what else..)","Let X be a Poisson random variable, $X \thicksim Po(\lambda Y) $ where $Y \thicksim Exp(\alpha)$. Now I would like to compute the distribution of X. If I conditionate on $Y=c$, I find $P(X=0|Y=c)=e^{\lambda c}$. But, in general, how can I compute $P(X=0)?$ I think that I have to take the mean, and so $P(X=0)=E(e^{\lambda y})=\int_{0}^{\infty}e^{\lambda z}\alpha e^{- \alpha z}dz$. But I don't understand why, how can I show the previous equality and how I have to look at this problem.(the variable that I'm studying is a function of random variable or what else..)",,"['probability', 'probability-theory', 'probability-distributions']"
33,Intuitive reason why the variance of a hypergeometric variable is smaller than the variance of the corresponding Binomial variable,Intuitive reason why the variance of a hypergeometric variable is smaller than the variance of the corresponding Binomial variable,,"I am looking for the most cleanest and most intuitive possible description of why the variance of the number of successes when sampling without replacement is smaller than the variance of the number of successes when sampling with replacement.  I desire a verbal explanation, perhaps combined with an illuminating example. Notes:  I can derive the formulas for both variances and see that one is obtained from the other by a correction factor.  I only want a clear description of the ""intuition"" behind the fact that this happens.","I am looking for the most cleanest and most intuitive possible description of why the variance of the number of successes when sampling without replacement is smaller than the variance of the number of successes when sampling with replacement.  I desire a verbal explanation, perhaps combined with an illuminating example. Notes:  I can derive the formulas for both variances and see that one is obtained from the other by a correction factor.  I only want a clear description of the ""intuition"" behind the fact that this happens.",,"['probability', 'probability-distributions', 'random-variables']"
34,I have a bag containing N coins. What is the probability that I have a round dollar amount?,I have a bag containing N coins. What is the probability that I have a round dollar amount?,,"In my country we have \$0.10, \$0.20, \$0.50, \$1, and \$2 coins.  If I were to pour a bag of coins out on the table what would be the probability that I could buy a heap of \$1 snacks without needing any change? Does this change if the bag doesn't contain any whole dollar value coins? I'm fairly sure the that  $P=0.1$ for very large values of $N$ (as there is 10 possible cent values). I'd like to be able to prove this and be able to see how the probability changes with $N$, but I cant figure out a rule for the entire series & larger values of $N$. I've written a little Python simulation to test $N$ values $0$ through $50$ and I'll edit with the results of that when it finishes. EDIT: Results of my script seem to confirm my thought: http://pastebin.com/cD8PeuwT","In my country we have \$0.10, \$0.20, \$0.50, \$1, and \$2 coins.  If I were to pour a bag of coins out on the table what would be the probability that I could buy a heap of \$1 snacks without needing any change? Does this change if the bag doesn't contain any whole dollar value coins? I'm fairly sure the that  $P=0.1$ for very large values of $N$ (as there is 10 possible cent values). I'd like to be able to prove this and be able to see how the probability changes with $N$, but I cant figure out a rule for the entire series & larger values of $N$. I've written a little Python simulation to test $N$ values $0$ through $50$ and I'll edit with the results of that when it finishes. EDIT: Results of my script seem to confirm my thought: http://pastebin.com/cD8PeuwT",,['probability']
35,Estimating the expectation of a derivative,Estimating the expectation of a derivative,,"Assume $Y$ is a continuously differential function of $X$. Given i.i.d. data $(x_i,y_i)_{i=1}^n$, I would like to estimate $E\left[\left.\frac{\partial Y}{\partial X}\right|_{X=X_0}\right]$. What got me thinking about this problem was estimation of the coefficients in a linear regression using $E\left[\frac{\partial Y}{\partial X}\right]$ (I know it is not the best way to estimate the coefficients, and may even be a bad way to do so). From this question Derivative of a random variable w.r.t. a deterministic variable , I know that $\frac{\partial Y}{\partial X}$ makes sense but I'm trying to understand how to estimate $\frac{\partial Y}{\partial X}$ when there is randomness (without randomness estimation can be done by finite differences, for example). I don't have any good ideas how to estimate $E\left[\left.\frac{\partial Y}{\partial X}\right|_{X=X_0}\right]$ but if I was forced to give a way, I would give weights to points around $X_0$ based on how close they are to $X_0$ and then sample two points at a time based on the weights and first difference the two points and do this many times and take the sample average. References / summary of techniques / specifics are greatly appreciated.","Assume $Y$ is a continuously differential function of $X$. Given i.i.d. data $(x_i,y_i)_{i=1}^n$, I would like to estimate $E\left[\left.\frac{\partial Y}{\partial X}\right|_{X=X_0}\right]$. What got me thinking about this problem was estimation of the coefficients in a linear regression using $E\left[\frac{\partial Y}{\partial X}\right]$ (I know it is not the best way to estimate the coefficients, and may even be a bad way to do so). From this question Derivative of a random variable w.r.t. a deterministic variable , I know that $\frac{\partial Y}{\partial X}$ makes sense but I'm trying to understand how to estimate $\frac{\partial Y}{\partial X}$ when there is randomness (without randomness estimation can be done by finite differences, for example). I don't have any good ideas how to estimate $E\left[\left.\frac{\partial Y}{\partial X}\right|_{X=X_0}\right]$ but if I was forced to give a way, I would give weights to points around $X_0$ based on how close they are to $X_0$ and then sample two points at a time based on the weights and first difference the two points and do this many times and take the sample average. References / summary of techniques / specifics are greatly appreciated.",,"['probability', 'expectation']"
36,Poisson Process Derivation.,Poisson Process Derivation.,,"I was looking at a derivation for the poisson process , which tells the number of events occurring in time $t$ , I came across the following differential equation : $\frac{d}{dt}(P_n(t))$ = $\lambda[P_{n-1}(t) - P_n(t)]$ , but i have no idea how to tackle this differential equation , Here , $P_n(t)$ = Probability that $n$ events occur in time interval $t$. Probability that $0$ events occur in time interval $t$ is given as : $P_0(t)$ = $e^{-\lambda t}$ , Also , how can we take $P_n(t+dt)$ = $P_n(t)$ + $dt*\frac{d}{dt}(P_n(t))$ , where , $P_n(t+dt)$ is the probability that $n$ events occur in the time interval $t+dt$. Kindly help me with this...","I was looking at a derivation for the poisson process , which tells the number of events occurring in time $t$ , I came across the following differential equation : $\frac{d}{dt}(P_n(t))$ = $\lambda[P_{n-1}(t) - P_n(t)]$ , but i have no idea how to tackle this differential equation , Here , $P_n(t)$ = Probability that $n$ events occur in time interval $t$. Probability that $0$ events occur in time interval $t$ is given as : $P_0(t)$ = $e^{-\lambda t}$ , Also , how can we take $P_n(t+dt)$ = $P_n(t)$ + $dt*\frac{d}{dt}(P_n(t))$ , where , $P_n(t+dt)$ is the probability that $n$ events occur in the time interval $t+dt$. Kindly help me with this...",,"['probability', 'ordinary-differential-equations']"
37,How to take into account uncertainty on number of events,How to take into account uncertainty on number of events,,"Suppose I generate a set of events $X_{i}$ for $i = 1,2 \dots N$ and suppose every event is either a success or a failure, ie. $X_{i} = 0, 1$. If $N$ is fixed, the MLE for the probability of success is just $$\hat{p} = \frac{1}{N}\sum_{i = 1}^{N} X_{i}$$ and the variance of the MLE can be estimated as $$V(\hat{p}) = \frac{\hat{p}(1 - \hat{p})}N.$$ But now suppose that $$N \sim \text{Poisson}(\lambda_N),$$ where $\lambda_{N}$ is fairly large, so if we need to, this could be approximated as $$N \sim \text{Normal}\left(\mu = \lambda_{N}, \sigma^2 = \lambda_{N}\right).$$ The MLE is still just $$\hat{p} = \frac{1}{N}\sum_{i = 1}^{N} X_{i}$$ but the variance is increased. What I want to know is how to calculate the new variance of $\hat{p}$ by taking into account the uncertainty on $N$. I tried some error propagation on $N$ but I can't quite reproduce numerical results.","Suppose I generate a set of events $X_{i}$ for $i = 1,2 \dots N$ and suppose every event is either a success or a failure, ie. $X_{i} = 0, 1$. If $N$ is fixed, the MLE for the probability of success is just $$\hat{p} = \frac{1}{N}\sum_{i = 1}^{N} X_{i}$$ and the variance of the MLE can be estimated as $$V(\hat{p}) = \frac{\hat{p}(1 - \hat{p})}N.$$ But now suppose that $$N \sim \text{Poisson}(\lambda_N),$$ where $\lambda_{N}$ is fairly large, so if we need to, this could be approximated as $$N \sim \text{Normal}\left(\mu = \lambda_{N}, \sigma^2 = \lambda_{N}\right).$$ The MLE is still just $$\hat{p} = \frac{1}{N}\sum_{i = 1}^{N} X_{i}$$ but the variance is increased. What I want to know is how to calculate the new variance of $\hat{p}$ by taking into account the uncertainty on $N$. I tried some error propagation on $N$ but I can't quite reproduce numerical results.",,"['probability', 'statistics', 'stochastic-processes', 'poisson-distribution', 'parameter-estimation']"
38,Monopoly Game Statistics,Monopoly Game Statistics,,"I was playing a game of monopoly the other day, and in the course of strategizing I came up with the idea that how 'safe' you were in the game was a matter of what your expected income/outcome was as you went around the board. I figured it would be a fun project to make a helper program that would compute these values based on a given board configuration, but I found that the statistics got too complicated for me. At first I was going to just sum up the amount of potential costs you could have on each tile (excluding Chance and Community Chest cards for simplicity), and dividing by 40, the number of tiles on the board, to get the expected value. But I realized that's not actually the expected value because you're not going to land on every tile, and you definitely won't land on 40 tiles in the course of traversing the board. At this point, I figure, there are several assumptions I could make - average die roll is 7, 40 tiles divided by seven steps is ~5.7 turns, so I could divide the total costs by that for an expected value, but that seems like an overly broad assumption in this case - there could be too much variance in the number of turns to get an accurate projection, I think. I was wondering if anybody more skilled with statistics could give me a hand with this - what is the expected value of your costs in traversing the monopoly board? I intended on ignoring chance and community chest and being sent to jail, as those seemed to overcomplicate the model, but if somebody can incorporate those effects I'd be interested in seeing them.","I was playing a game of monopoly the other day, and in the course of strategizing I came up with the idea that how 'safe' you were in the game was a matter of what your expected income/outcome was as you went around the board. I figured it would be a fun project to make a helper program that would compute these values based on a given board configuration, but I found that the statistics got too complicated for me. At first I was going to just sum up the amount of potential costs you could have on each tile (excluding Chance and Community Chest cards for simplicity), and dividing by 40, the number of tiles on the board, to get the expected value. But I realized that's not actually the expected value because you're not going to land on every tile, and you definitely won't land on 40 tiles in the course of traversing the board. At this point, I figure, there are several assumptions I could make - average die roll is 7, 40 tiles divided by seven steps is ~5.7 turns, so I could divide the total costs by that for an expected value, but that seems like an overly broad assumption in this case - there could be too much variance in the number of turns to get an accurate projection, I think. I was wondering if anybody more skilled with statistics could give me a hand with this - what is the expected value of your costs in traversing the monopoly board? I intended on ignoring chance and community chest and being sent to jail, as those seemed to overcomplicate the model, but if somebody can incorporate those effects I'd be interested in seeing them.",,"['probability', 'statistics']"
39,birthday problem - which solution for expected value of collisions is correct?,birthday problem - which solution for expected value of collisions is correct?,,"I am trying to understand the difference of the two solutions for the expected value of collisions for the birthday problem: https://math.stackexchange.com/a/35798/254705 derives the following solution: ... so the expected number of people who share birthdays with somebody is $n\left(1-(1-1/N)^{n-1}\right)$. whereas https://math.stackexchange.com/a/952272/254705 gives This leads to an expectation value $\lambda$ (date collisions in terms of the lambda distribution) of $\lambda = \frac{n(n-1)}{2m}$ For $2^{32}$ ""days"" and $10^6$ people, results in $E_1 = 232.8033$ and results in $E_2 =  116.4152$ It looks like that $\frac{E_1}{E_2} \approx 2$. As $E_2$ gives the number of collision pairs instead of number of people involved in collisions, this seems reasonable to me. Which of the solutions is correct? Is $E_2$ just an approximation?","I am trying to understand the difference of the two solutions for the expected value of collisions for the birthday problem: https://math.stackexchange.com/a/35798/254705 derives the following solution: ... so the expected number of people who share birthdays with somebody is $n\left(1-(1-1/N)^{n-1}\right)$. whereas https://math.stackexchange.com/a/952272/254705 gives This leads to an expectation value $\lambda$ (date collisions in terms of the lambda distribution) of $\lambda = \frac{n(n-1)}{2m}$ For $2^{32}$ ""days"" and $10^6$ people, results in $E_1 = 232.8033$ and results in $E_2 =  116.4152$ It looks like that $\frac{E_1}{E_2} \approx 2$. As $E_2$ gives the number of collision pairs instead of number of people involved in collisions, this seems reasonable to me. Which of the solutions is correct? Is $E_2$ just an approximation?",,"['probability', 'birthday']"
40,What tactics could help with this probability questions,What tactics could help with this probability questions,,"I'm not too sure if this question is solvable (I sort of just thought of it yesterday) but when I brute force numerical answers on my computer they seem to show a pattern, so I believe it to be solvable. The question: I have $N$ people in a stadium, and there are $5$ different coloured shirts. Each person has an equal chance of wearing any of the coloured shirts. (i.e. it's equally likely that you'll find a guy with a black shirt, than a blue or pink or grey or brown shirt). The love god suddenly starts playing music across the stadium, and every single person suddenly has an unresistable desire to pair up with a person who is wearing a same coloured shirt. Find the probability that nobody is left alone. (equivalent to asking find the probability that the number of people wearing each colour is an even number). Trivial Observations: If $N$ is odd, then the chance is $0$, only if $N$ is even is the chance finite. In fact (for the case where there are $5$ different coloured shirts), if $N$ is odd, the colours can end with only $3$ combinations (all odd, $3$ odd $2$ even, $4$ odd $1$ even) and for $N$ is even - (all even, $4$ odd $1$ even, $2$ odd $3$ even). A (seemingly crucial) observation: It seems that if I increase $N$ to an arbitrarily large amount, that the probability that all the colours are even at the end should asymptote for some value, because the bulk majority of people just pair off. I started my solution by attempting to prove this point. To do this, I assumed that at the beginning all $100$ people were shirtless, and we would add the shirts on to the people one by one. We will keep a 'lonely counter' that keeps count of all lonely people, and the moment someone gets paired they immediately are forgotten from memory for all we care. For the first person, the color shirt he chooses is arbitrary, because he will definitely be lonely, so our lonely counter is at $1$. The next person has a $0.2$ chance of picking the same shirt as the first person (in this case the lonely counter drops to $0$), and a $0.8$ chance of picking a different colour (in this case the lonely counter goes up to $2$). The maximum lonely counter value is $5$, and for the case where we want $0$ lonely people, by the time we are done assigning shirt values to everybody the lonely counter must again be at $0$. To test my asymptotic theory, I pretty much put this 'lonely counter' into excel to see what happens At $N = 0$, the lonely counter is $0$ with a $100\%$ probability (no people around). At $N = 1$, the lonely counter is $1$ with a $100\%$ probability (1 person by himself definitely lonely). At $N = 2$, the lonely counter is $0$ with $0.2$ chance, and $2$ with $0.8$ chance (as explained above). With math and excel magic I ran the data along, and wondrously, the chance the lonely counter was $0$ asymptoted toward a value of $6.25\%$. Then I tried for different numbers of shirts, and found a trend, so unless I messed up my math then I believe $$ P = \dfrac{1}{2^{p-1}} $$ For large $N$, and where $p$ is the number of shirts. I tried to use my lonely counter to actually prove the result though, and I'm sort of stuck now, and not really sure where to go from here. Any help is appreciated.","I'm not too sure if this question is solvable (I sort of just thought of it yesterday) but when I brute force numerical answers on my computer they seem to show a pattern, so I believe it to be solvable. The question: I have $N$ people in a stadium, and there are $5$ different coloured shirts. Each person has an equal chance of wearing any of the coloured shirts. (i.e. it's equally likely that you'll find a guy with a black shirt, than a blue or pink or grey or brown shirt). The love god suddenly starts playing music across the stadium, and every single person suddenly has an unresistable desire to pair up with a person who is wearing a same coloured shirt. Find the probability that nobody is left alone. (equivalent to asking find the probability that the number of people wearing each colour is an even number). Trivial Observations: If $N$ is odd, then the chance is $0$, only if $N$ is even is the chance finite. In fact (for the case where there are $5$ different coloured shirts), if $N$ is odd, the colours can end with only $3$ combinations (all odd, $3$ odd $2$ even, $4$ odd $1$ even) and for $N$ is even - (all even, $4$ odd $1$ even, $2$ odd $3$ even). A (seemingly crucial) observation: It seems that if I increase $N$ to an arbitrarily large amount, that the probability that all the colours are even at the end should asymptote for some value, because the bulk majority of people just pair off. I started my solution by attempting to prove this point. To do this, I assumed that at the beginning all $100$ people were shirtless, and we would add the shirts on to the people one by one. We will keep a 'lonely counter' that keeps count of all lonely people, and the moment someone gets paired they immediately are forgotten from memory for all we care. For the first person, the color shirt he chooses is arbitrary, because he will definitely be lonely, so our lonely counter is at $1$. The next person has a $0.2$ chance of picking the same shirt as the first person (in this case the lonely counter drops to $0$), and a $0.8$ chance of picking a different colour (in this case the lonely counter goes up to $2$). The maximum lonely counter value is $5$, and for the case where we want $0$ lonely people, by the time we are done assigning shirt values to everybody the lonely counter must again be at $0$. To test my asymptotic theory, I pretty much put this 'lonely counter' into excel to see what happens At $N = 0$, the lonely counter is $0$ with a $100\%$ probability (no people around). At $N = 1$, the lonely counter is $1$ with a $100\%$ probability (1 person by himself definitely lonely). At $N = 2$, the lonely counter is $0$ with $0.2$ chance, and $2$ with $0.8$ chance (as explained above). With math and excel magic I ran the data along, and wondrously, the chance the lonely counter was $0$ asymptoted toward a value of $6.25\%$. Then I tried for different numbers of shirts, and found a trend, so unless I messed up my math then I believe $$ P = \dfrac{1}{2^{p-1}} $$ For large $N$, and where $p$ is the number of shirts. I tried to use my lonely counter to actually prove the result though, and I'm sort of stuck now, and not really sure where to go from here. Any help is appreciated.",,"['probability', 'combinatorics']"
41,Conditional Probability for Exponential Random Variables,Conditional Probability for Exponential Random Variables,,"I'm working through a practice problem for an exam and I would like to verify that I've done it correctly. Additionally I'd like some insight on the intuition behind the numbers I'm getting. Problem For $X$ and $Y$ independent $Exp(1)$ r.v.'s compute $P(X<3|X+Y)$. Attempt Since the sum of exponentials is a scaled gamma, $S=X+Y$~$Ga(1,2)$, where the rate is 1 and the shape is 2. When $X+Y\leq 3$, the probability is 1 that $\{X<3\}$. I checked this also by solving: $$P(X<3|X+Y\leq 3)=\frac{P(X<3,Y<3-X)}{P(S\leq 3)}=\frac{\int_0^3\int_0^{3-x} e^{-x}e^{-y}dy dx}{\int_0^3 se^{-s}ds}=1$$ Now when $X+Y>3$, I compute a similar quantity, namely, $$P(X<3|X+Y> 3)=\frac{P(X<3,Y>3-X)}{P(S> 3)}=\frac{3}{4}$$ Interpretation Assuming that the above quantities are correct, could I interpret the quantity $P(X<3|X+Y>3)$ as follows: ""Given that the sum is greater than 3, the chances that the one of the variables is less than 3 is distributed uniformly (due to memoryless property of exponential r.v.'s). That is, if the sum is >3, and if we fix e.g. Y=3, then on average the sum is $Y + E(X)=4$, and we get that X<3, 3/4ths of the time."" The above interpretation is loosely based on my finding that for $k\in\mathbb{N}$ $$P(X<k|X+Y>k)=\frac{k}{k+1}=\frac{k}{k+E(X)}$$ Thanks for any help.","I'm working through a practice problem for an exam and I would like to verify that I've done it correctly. Additionally I'd like some insight on the intuition behind the numbers I'm getting. Problem For $X$ and $Y$ independent $Exp(1)$ r.v.'s compute $P(X<3|X+Y)$. Attempt Since the sum of exponentials is a scaled gamma, $S=X+Y$~$Ga(1,2)$, where the rate is 1 and the shape is 2. When $X+Y\leq 3$, the probability is 1 that $\{X<3\}$. I checked this also by solving: $$P(X<3|X+Y\leq 3)=\frac{P(X<3,Y<3-X)}{P(S\leq 3)}=\frac{\int_0^3\int_0^{3-x} e^{-x}e^{-y}dy dx}{\int_0^3 se^{-s}ds}=1$$ Now when $X+Y>3$, I compute a similar quantity, namely, $$P(X<3|X+Y> 3)=\frac{P(X<3,Y>3-X)}{P(S> 3)}=\frac{3}{4}$$ Interpretation Assuming that the above quantities are correct, could I interpret the quantity $P(X<3|X+Y>3)$ as follows: ""Given that the sum is greater than 3, the chances that the one of the variables is less than 3 is distributed uniformly (due to memoryless property of exponential r.v.'s). That is, if the sum is >3, and if we fix e.g. Y=3, then on average the sum is $Y + E(X)=4$, and we get that X<3, 3/4ths of the time."" The above interpretation is loosely based on my finding that for $k\in\mathbb{N}$ $$P(X<k|X+Y>k)=\frac{k}{k+1}=\frac{k}{k+E(X)}$$ Thanks for any help.",,['probability']
42,"Estimating the ""step size"" of a grid","Estimating the ""step size"" of a grid",,"Suppose one is given a set of $M$ points distributed on a ""grid"", i.e: $$x_i = x_0 + \alpha n_i + \epsilon_i, \quad n_i\in\mathbb{Z}$$ This might like something like this: $\quad\ \quad\quad\quad\quad\quad\quad$ That is, each of the points lies on a grid position with grid size $\alpha$, up to some amount of Gaussian noise $\epsilon_i \sim N(0,\sigma)$. I have tried writing out the maximum likelihood estimator, but since the $n_i$ are not known a priori, one gets an unsolvable equation for $\alpha$: $$\alpha = \frac{\sum (x_i - x_0)n_i}{\sum n_i^2}\ =\ ?$$ How would one estimate the grid size $\alpha$? Intuitively, one can easily ""see"" the solution, but it's not clear how one could get the MLE. In my mind, the problem stems from the fact that $n_i$ are integers is not being used, though it's not clear how one would enforce this constraint.","Suppose one is given a set of $M$ points distributed on a ""grid"", i.e: $$x_i = x_0 + \alpha n_i + \epsilon_i, \quad n_i\in\mathbb{Z}$$ This might like something like this: $\quad\ \quad\quad\quad\quad\quad\quad$ That is, each of the points lies on a grid position with grid size $\alpha$, up to some amount of Gaussian noise $\epsilon_i \sim N(0,\sigma)$. I have tried writing out the maximum likelihood estimator, but since the $n_i$ are not known a priori, one gets an unsolvable equation for $\alpha$: $$\alpha = \frac{\sum (x_i - x_0)n_i}{\sum n_i^2}\ =\ ?$$ How would one estimate the grid size $\alpha$? Intuitively, one can easily ""see"" the solution, but it's not clear how one could get the MLE. In my mind, the problem stems from the fact that $n_i$ are integers is not being used, though it's not clear how one would enforce this constraint.",,"['probability', 'optimization', 'parameter-estimation']"
43,Binomial within a multinomial distribution,Binomial within a multinomial distribution,,"Let $\textbf{X} = (X_1, . . . ,X_k)$ denote the random vector of counts, and let $\textbf{x} = (x_1, . . . , x_k)$ denote a possible value for that random vector. Finally, let $f (x | n, \textbf{p})$ denote the joint p.f. of $X$. With $\textbf{p} = (p_1, \dots , p_k)$. There $f$ denotes the multinomial distribution. We have to prove that $Y = X_1 + X_2 + \dots + X_l$ where $l < k$. So we have to prove that $Y$ is distributed as a binomial distribution with parameters $n$ and $\sum_{i=1}^{l}p_i$. Here is my approach and I am stuck at a point. Let $X_i = X_{i_1} + X_{i_2} + \dots + X_{i_n}$ Where $X_{i_1}$ is $1$ with probability $p_i$ or $0$ otherwise.  $X_{i_1}$ denotes whether we get object $i$ in first place, similarly for others. Now  $$Y = X_{1_1} + X_{1_2} + \dots + X_{1_n} \\         + X_{2_1} + X_{2_2} + \dots + X_{2_n} \\ \vdots \\         + X_{l_1} + X_{l_2} + \dots + X_{l_n}$$ Now grouping in this way $$Y = X_{1_1} + X_{2_1} + \dots + X_{l_1} \\         + X_{1_2} + X_{2_2} + \dots + X_{l_2} \\ \vdots \\         + X_{1_n} + X_{2_n} + \dots + X_{l_n}$$ Now let us discuss for $X_{1_1} + X_{2_1} + \dots + X_{l_1}$, this random variable can take a value $1$ or $0$. It is $1$ when any one of it happens ie first slot is a object from $1$ to $l$ which happens with a proability of $\sum_{i=1}^{l}p_i$. Similarly for the other rows. Now each row is a Bernoulli with probability $\sum_{i=1}^{l}p_i$ and there are $n$ rows. But are these Bernoulli variables independent. Because if they were independent I could conclude that this is a Binomial with the required parameters.","Let $\textbf{X} = (X_1, . . . ,X_k)$ denote the random vector of counts, and let $\textbf{x} = (x_1, . . . , x_k)$ denote a possible value for that random vector. Finally, let $f (x | n, \textbf{p})$ denote the joint p.f. of $X$. With $\textbf{p} = (p_1, \dots , p_k)$. There $f$ denotes the multinomial distribution. We have to prove that $Y = X_1 + X_2 + \dots + X_l$ where $l < k$. So we have to prove that $Y$ is distributed as a binomial distribution with parameters $n$ and $\sum_{i=1}^{l}p_i$. Here is my approach and I am stuck at a point. Let $X_i = X_{i_1} + X_{i_2} + \dots + X_{i_n}$ Where $X_{i_1}$ is $1$ with probability $p_i$ or $0$ otherwise.  $X_{i_1}$ denotes whether we get object $i$ in first place, similarly for others. Now  $$Y = X_{1_1} + X_{1_2} + \dots + X_{1_n} \\         + X_{2_1} + X_{2_2} + \dots + X_{2_n} \\ \vdots \\         + X_{l_1} + X_{l_2} + \dots + X_{l_n}$$ Now grouping in this way $$Y = X_{1_1} + X_{2_1} + \dots + X_{l_1} \\         + X_{1_2} + X_{2_2} + \dots + X_{l_2} \\ \vdots \\         + X_{1_n} + X_{2_n} + \dots + X_{l_n}$$ Now let us discuss for $X_{1_1} + X_{2_1} + \dots + X_{l_1}$, this random variable can take a value $1$ or $0$. It is $1$ when any one of it happens ie first slot is a object from $1$ to $l$ which happens with a proability of $\sum_{i=1}^{l}p_i$. Similarly for the other rows. Now each row is a Bernoulli with probability $\sum_{i=1}^{l}p_i$ and there are $n$ rows. But are these Bernoulli variables independent. Because if they were independent I could conclude that this is a Binomial with the required parameters.",,"['probability', 'binomial-distribution']"
44,Symmetry in Probability Around a Particular Phenomenon in Time?,Symmetry in Probability Around a Particular Phenomenon in Time?,,"This has been hurting my brain substantially, recently. I'm not sure if I'm failing to make connections or if I see connections but am weary of their relevance. In my text the author claims that events occurring in the future are just as relevant as events before the said event. He writes that ""the results of later draws have precisely the same relevance as do the results of earlier ones! Even though performing the later draw does not physically affect the number Mk of red balls, information about the result of a later draw has the same effect on our state of knowledge about what could have been taken on the kth draw, as does information about an earlier one."" _Probability Theory: The Logic of Science, E.T. Jaynes Surely this doesn't refer to future events? I can see how knowing that I'll get a red ball in 4 draws would affect my knowledge of the next 3 draws, but where does something like this become prevalent in everyday use? Is it just a mathematical proof or does it actually hold some value in actual application? Also, correct me if I'm completely missing the point as I've allowed myself to get really confused and it may not even be that complicated. EDIT: The proof I followed resulted in: P(Rj|Rk) = P(Rk|Rj) so it makes mathematical sense but I'm still confused on the intuitive aspect.","This has been hurting my brain substantially, recently. I'm not sure if I'm failing to make connections or if I see connections but am weary of their relevance. In my text the author claims that events occurring in the future are just as relevant as events before the said event. He writes that ""the results of later draws have precisely the same relevance as do the results of earlier ones! Even though performing the later draw does not physically affect the number Mk of red balls, information about the result of a later draw has the same effect on our state of knowledge about what could have been taken on the kth draw, as does information about an earlier one."" _Probability Theory: The Logic of Science, E.T. Jaynes Surely this doesn't refer to future events? I can see how knowing that I'll get a red ball in 4 draws would affect my knowledge of the next 3 draws, but where does something like this become prevalent in everyday use? Is it just a mathematical proof or does it actually hold some value in actual application? Also, correct me if I'm completely missing the point as I've allowed myself to get really confused and it may not even be that complicated. EDIT: The proof I followed resulted in: P(Rj|Rk) = P(Rk|Rj) so it makes mathematical sense but I'm still confused on the intuitive aspect.",,"['probability', 'statistics']"
45,"Conditional probability, Baye's rule, prisoner Ural / Siberia + coat exercise","Conditional probability, Baye's rule, prisoner Ural / Siberia + coat exercise",,"I am currently statistics and probability course. One of the questions in the textbook is following: A prisoner will be sent to either Urals or Siberia , but he does not   know where. He knows, that the probability is 0.8 that he will be sent   to Siberia . He also knows the probabilities of prisoners wearing a coat - 0.5 in Siberia and 0.7 in Urals . When he arrives to the exile, the first person he sees is not wearing   a coat. What is the probability he is in Siberia ? Given previous information, he sees another one, not wearing a coat . What is probability now, that he is in Siberia ? Would it change the probability if he saw both previous people at once? I believe the answer for the 1. is following: $$\mathcal P(S|\bar C)={\mathcal P(S)\times\mathcal P(\bar C|S) \over \mathcal P(\bar C)}={0.8\times0.5\over 1-(0.8\times0.5+0.2\times0.7)}=\frac{20}{23}\dot=\,0.8696$$ However, I have no idea how to move further on 2. or 3. Could you please help me? Thank You! EDIT The professor quickly responded with the solution for 2. : $$\frac{0.8696\times0.5}{0.8596\times0.5+0.1304\times0.3}=0.9174$$ From this, I've found out that the probabilities can be ""chained"", and decoded the underlining formula as: $$\mathcal P(S|\bar{C_2})=\frac{\mathcal P(S|\bar C)\times\mathcal P(\bar C|S)}{\mathcal P(S|\bar C)\times\mathcal P(\bar C|S)+\mathcal P(\bar S|\bar C)\times\mathcal P(\bar C|\bar S)}$$ However, since 0.5 is the probability for $\mathcal P(\bar C|S)$ and also for $\mathcal P(C|S)$, I need a clarification, if my decoded formula is right. Thank You.","I am currently statistics and probability course. One of the questions in the textbook is following: A prisoner will be sent to either Urals or Siberia , but he does not   know where. He knows, that the probability is 0.8 that he will be sent   to Siberia . He also knows the probabilities of prisoners wearing a coat - 0.5 in Siberia and 0.7 in Urals . When he arrives to the exile, the first person he sees is not wearing   a coat. What is the probability he is in Siberia ? Given previous information, he sees another one, not wearing a coat . What is probability now, that he is in Siberia ? Would it change the probability if he saw both previous people at once? I believe the answer for the 1. is following: $$\mathcal P(S|\bar C)={\mathcal P(S)\times\mathcal P(\bar C|S) \over \mathcal P(\bar C)}={0.8\times0.5\over 1-(0.8\times0.5+0.2\times0.7)}=\frac{20}{23}\dot=\,0.8696$$ However, I have no idea how to move further on 2. or 3. Could you please help me? Thank You! EDIT The professor quickly responded with the solution for 2. : $$\frac{0.8696\times0.5}{0.8596\times0.5+0.1304\times0.3}=0.9174$$ From this, I've found out that the probabilities can be ""chained"", and decoded the underlining formula as: $$\mathcal P(S|\bar{C_2})=\frac{\mathcal P(S|\bar C)\times\mathcal P(\bar C|S)}{\mathcal P(S|\bar C)\times\mathcal P(\bar C|S)+\mathcal P(\bar S|\bar C)\times\mathcal P(\bar C|\bar S)}$$ However, since 0.5 is the probability for $\mathcal P(\bar C|S)$ and also for $\mathcal P(C|S)$, I need a clarification, if my decoded formula is right. Thank You.",,"['probability', 'bayes-theorem']"
46,Deriving the value of $\pi$ from a dart board,Deriving the value of  from a dart board,\pi,"I saw this on a website and it was pretty interesting: The circle inscribed in the square has a radius of $1$ and the square has a side length of $2$. This means that the area of the circle is: $$\pi \times r^{2} = \pi \times (1^2) = \pi$$ Moreover, the area of the square is: $$(2^2) = 4$$ Then, we can randomly select points within the square and get a good approximation of pi by doing this thousands to millions of times, maybe by a computer sequence. Once we've repeated this process enough, we can plug our values into this equation: $$ \frac{\pi}{4} = \frac{\text{Number of points within the circle}}{\text{Total number of points}}$$ Is this a viable approach to approximate the value of $\pi$?","I saw this on a website and it was pretty interesting: The circle inscribed in the square has a radius of $1$ and the square has a side length of $2$. This means that the area of the circle is: $$\pi \times r^{2} = \pi \times (1^2) = \pi$$ Moreover, the area of the square is: $$(2^2) = 4$$ Then, we can randomly select points within the square and get a good approximation of pi by doing this thousands to millions of times, maybe by a computer sequence. Once we've repeated this process enough, we can plug our values into this equation: $$ \frac{\pi}{4} = \frac{\text{Number of points within the circle}}{\text{Total number of points}}$$ Is this a viable approach to approximate the value of $\pi$?",,"['probability', 'geometry', 'pi']"
47,Expected value of random permutation,Expected value of random permutation,,"Let n ≥ 1 be an integer and consider a uniformly random permutation $a_1$, $a_2$, . . . ,$a_n$ of the set {1, 2, . . . , n}. Define the random variable X to be the number of indices i for which 1 ≤ i < n and $a_i$ < $a_{i+1}$. Determine the expected value E(X) of X. (Hint: Use indicator random variables.) This question seems to be over my head. Any help to lead in right direction is appreciated. Thank you.","Let n ≥ 1 be an integer and consider a uniformly random permutation $a_1$, $a_2$, . . . ,$a_n$ of the set {1, 2, . . . , n}. Define the random variable X to be the number of indices i for which 1 ≤ i < n and $a_i$ < $a_{i+1}$. Determine the expected value E(X) of X. (Hint: Use indicator random variables.) This question seems to be over my head. Any help to lead in right direction is appreciated. Thank you.",,"['probability', 'permutations', 'random-variables']"
48,"Why does it hold $\operatorname{E}[Y\mid\mathcal{F}]=\operatorname{E}[Y\mid Y]=Y$, if $Y$ is $\mathcal{F}$-measurable?","Why does it hold , if  is -measurable?",\operatorname{E}[Y\mid\mathcal{F}]=\operatorname{E}[Y\mid Y]=Y Y \mathcal{F},"Let $(\Omega,\mathcal{A},\operatorname{P})$ be a probability space $\mathcal{F}\subseteq\mathcal{A}$ be a $\sigma$-algebra on $\Omega$ $Y\in\mathcal{L}^1(\Omega,\mathcal{A},\operatorname{P})$ be measurable wrt $\mathcal{F}$ Then, $$\operatorname{E}[Y\mid\mathcal{F}]=\operatorname{E}[Y\mid Y]=Y$$ From the definition of conditional expectation ( see below ) it's easy to see that we've got $$\operatorname{E}[Z]=\operatorname{E}[Z'],$$ where $Z:=\operatorname{E}[Y\mid\mathcal{F}]$ $Z':=\operatorname{E}[Y\mid\sigma(Y)]=\operatorname{E}[Y\mid Y]$ However, I don't see how we can conclude $Z\equiv Z'$ (almost surely) and $\operatorname{E}[Z']=Y$. Please note: A random variable $Z$ is called conditional expectation of $X$ given $\mathcal{F}$ $:\Leftrightarrow$ $Z$ is $\mathcal{F}$-measurable $\operatorname{E}[1_AX]=\operatorname{E}[1_AZ]$ for all $A\in\mathcal{F}$ We write $\operatorname{E}[X\mid\mathcal{F}]=:Z$. The notation $\operatorname{E}[X\mid X']$, with $X'$ being another random variable, is a shorthand for $\operatorname{E}[X\mid\sigma(X')]$","Let $(\Omega,\mathcal{A},\operatorname{P})$ be a probability space $\mathcal{F}\subseteq\mathcal{A}$ be a $\sigma$-algebra on $\Omega$ $Y\in\mathcal{L}^1(\Omega,\mathcal{A},\operatorname{P})$ be measurable wrt $\mathcal{F}$ Then, $$\operatorname{E}[Y\mid\mathcal{F}]=\operatorname{E}[Y\mid Y]=Y$$ From the definition of conditional expectation ( see below ) it's easy to see that we've got $$\operatorname{E}[Z]=\operatorname{E}[Z'],$$ where $Z:=\operatorname{E}[Y\mid\mathcal{F}]$ $Z':=\operatorname{E}[Y\mid\sigma(Y)]=\operatorname{E}[Y\mid Y]$ However, I don't see how we can conclude $Z\equiv Z'$ (almost surely) and $\operatorname{E}[Z']=Y$. Please note: A random variable $Z$ is called conditional expectation of $X$ given $\mathcal{F}$ $:\Leftrightarrow$ $Z$ is $\mathcal{F}$-measurable $\operatorname{E}[1_AX]=\operatorname{E}[1_AZ]$ for all $A\in\mathcal{F}$ We write $\operatorname{E}[X\mid\mathcal{F}]=:Z$. The notation $\operatorname{E}[X\mid X']$, with $X'$ being another random variable, is a shorthand for $\operatorname{E}[X\mid\sigma(X')]$",,"['real-analysis', 'probability', 'measure-theory', 'probability-theory']"
49,"If $X_n = Y_n + Z_n$ in distribution, and $X_n$ and $Y_n$ converge in distribution, does $Z_n$?","If  in distribution, and  and  converge in distribution, does ?",X_n = Y_n + Z_n X_n Y_n Z_n,"The random variables take values in $\mathbb{R}^d$. I have tried to prove this using characteristic functions. Let $\hat{\mu}_{X_n},\hat{\mu}_{Y_n},\hat{\mu}_{Z_n}$ be the characteristic functions of the corresponding random variables. Let $X$ (resp. $Y$) be the distributional limit of $X_n$ (resp. $Y_n$), with characteristic function $\hat{\mu}_{X}$ (resp. $\hat{\mu}_{Y}$). It is easy to show using the uniform convergence on compact sets of the $\hat{\mu}_{X_n}$ and $\hat{\mu}_{Y_n}$ that $\lim_{n \rightarrow \infty} \hat{\mu}_{Z_n}$ exists on some small ball $B_{\epsilon} := \{z \in \mathbb{R}^d : |z| \leq \epsilon\}$, and that the limiting function is continuous at $0$. This is `nearly' enough to conclude, but the problem is, there is no way of checking that $\lim_{n \rightarrow \infty} \hat{\mu}_{Z_n}$  exists on the set $A:=\{z \in \mathbb{R}^d : \hat{\mu}_{Y}(z)=0\}$. This is why I get stuck. Many thanks for your help. EDIT: (Proposed solution) What is said above is enough (c.f. Chung, page 170-171) to conclude that any subsequence of ${\mu}_{Z_n}$ has a further  subsequence converging to a probability measure. It is enough to show that the characteristic functions of these potentially different limits are the same. Suppose $f$ and $g$ are the characteristic functions of limits of subsequences of subsequences of ${\mu}_{Z_n}$. Then they are both continuous (by Arzela-Ascoli and contents of Chung Theorem 6.3.1). Moreover by the considerations above, $f$ and $g$ agree on the set $A^c:= \mathbb{R}^d \setminus A$ where in fact the limit of $\hat{\mu}_{Z_n}$ exists. It is therefore enough to show that any point in $A$ can be written as the limit of some points in $A^c$. But if this were not the case, $\hat{\mu}_Y$ would vanish on some small ball $D:= B(z_o; \epsilon)$ centered on $z_0 \in\mathbb{R}^d$ with radius $\epsilon$. Integrating shows therefore that $$\int_{\mathbb{R}^d} \int_D 1 - \cos \langle z, x \rangle dz \mu_Y(dx) = 0 $$ and this is impossible unless $Y=0$ almost surely (I think) in which case the claim is trivial.","The random variables take values in $\mathbb{R}^d$. I have tried to prove this using characteristic functions. Let $\hat{\mu}_{X_n},\hat{\mu}_{Y_n},\hat{\mu}_{Z_n}$ be the characteristic functions of the corresponding random variables. Let $X$ (resp. $Y$) be the distributional limit of $X_n$ (resp. $Y_n$), with characteristic function $\hat{\mu}_{X}$ (resp. $\hat{\mu}_{Y}$). It is easy to show using the uniform convergence on compact sets of the $\hat{\mu}_{X_n}$ and $\hat{\mu}_{Y_n}$ that $\lim_{n \rightarrow \infty} \hat{\mu}_{Z_n}$ exists on some small ball $B_{\epsilon} := \{z \in \mathbb{R}^d : |z| \leq \epsilon\}$, and that the limiting function is continuous at $0$. This is `nearly' enough to conclude, but the problem is, there is no way of checking that $\lim_{n \rightarrow \infty} \hat{\mu}_{Z_n}$  exists on the set $A:=\{z \in \mathbb{R}^d : \hat{\mu}_{Y}(z)=0\}$. This is why I get stuck. Many thanks for your help. EDIT: (Proposed solution) What is said above is enough (c.f. Chung, page 170-171) to conclude that any subsequence of ${\mu}_{Z_n}$ has a further  subsequence converging to a probability measure. It is enough to show that the characteristic functions of these potentially different limits are the same. Suppose $f$ and $g$ are the characteristic functions of limits of subsequences of subsequences of ${\mu}_{Z_n}$. Then they are both continuous (by Arzela-Ascoli and contents of Chung Theorem 6.3.1). Moreover by the considerations above, $f$ and $g$ agree on the set $A^c:= \mathbb{R}^d \setminus A$ where in fact the limit of $\hat{\mu}_{Z_n}$ exists. It is therefore enough to show that any point in $A$ can be written as the limit of some points in $A^c$. But if this were not the case, $\hat{\mu}_Y$ would vanish on some small ball $D:= B(z_o; \epsilon)$ centered on $z_0 \in\mathbb{R}^d$ with radius $\epsilon$. Integrating shows therefore that $$\int_{\mathbb{R}^d} \int_D 1 - \cos \langle z, x \rangle dz \mu_Y(dx) = 0 $$ and this is impossible unless $Y=0$ almost surely (I think) in which case the claim is trivial.",,"['probability', 'probability-theory', 'probability-distributions', 'convergence-divergence', 'characteristic-functions']"
50,Linearity of convergence in probability,Linearity of convergence in probability,,"I am trying to prove the following statement. Let $X_n \rightarrow X$ and $Y_n \rightarrow Y$, both in probability. Then $aX_n + bY_n \rightarrow aX + bY$ in probability for  $a,b \in \mathbb{R}$ s.t. $a,b \neq 0$. The statement I need to prove is $$\forall{\varepsilon} >0 \qquad \lim_{n\rightarrow\infty} P\{\lvert aX_n + bY_n - aX - bY \rvert > \varepsilon\} = 0$$ Fix $\varepsilon > 0$. Note that $$\lvert aX_n + bY_n - aX - bY \rvert \leq \lvert a\rvert\lvert X_n - X\rvert + \lvert b\rvert\lvert Y_n - Y\rvert$$ Therefore $$P\{\lvert aX_n + bY_n - aX - bY \rvert > \varepsilon\} \leq P\{\lvert a\rvert\lvert X_n - X\rvert + \lvert b\rvert\lvert Y_n - Y\rvert > \varepsilon\}$$ Here comes the part which I feel uncomfortable about. $$P\{\lvert a\rvert\lvert X_n - X\rvert + \lvert b\rvert\lvert Y_n - Y\rvert > \varepsilon\} = P\{\lvert a\rvert\lvert X_n - X\rvert \vee \lvert b\rvert\lvert Y_n - Y\rvert > \frac{\varepsilon}{2}\}$$ Now I let $n$ go to infinity and claim that the RHS goes to $0$. I base this claim on the intuition that $\lvert X_n - X\rvert$ and $\lvert Y_n - Y\rvert$ converge in probability to $0$. Therefore their ""worst case"" combination must do the same. Could someone help me fix this proof or post a better one? Thanks a lot.","I am trying to prove the following statement. Let $X_n \rightarrow X$ and $Y_n \rightarrow Y$, both in probability. Then $aX_n + bY_n \rightarrow aX + bY$ in probability for  $a,b \in \mathbb{R}$ s.t. $a,b \neq 0$. The statement I need to prove is $$\forall{\varepsilon} >0 \qquad \lim_{n\rightarrow\infty} P\{\lvert aX_n + bY_n - aX - bY \rvert > \varepsilon\} = 0$$ Fix $\varepsilon > 0$. Note that $$\lvert aX_n + bY_n - aX - bY \rvert \leq \lvert a\rvert\lvert X_n - X\rvert + \lvert b\rvert\lvert Y_n - Y\rvert$$ Therefore $$P\{\lvert aX_n + bY_n - aX - bY \rvert > \varepsilon\} \leq P\{\lvert a\rvert\lvert X_n - X\rvert + \lvert b\rvert\lvert Y_n - Y\rvert > \varepsilon\}$$ Here comes the part which I feel uncomfortable about. $$P\{\lvert a\rvert\lvert X_n - X\rvert + \lvert b\rvert\lvert Y_n - Y\rvert > \varepsilon\} = P\{\lvert a\rvert\lvert X_n - X\rvert \vee \lvert b\rvert\lvert Y_n - Y\rvert > \frac{\varepsilon}{2}\}$$ Now I let $n$ go to infinity and claim that the RHS goes to $0$. I base this claim on the intuition that $\lvert X_n - X\rvert$ and $\lvert Y_n - Y\rvert$ converge in probability to $0$. Therefore their ""worst case"" combination must do the same. Could someone help me fix this proof or post a better one? Thanks a lot.",,"['probability', 'proof-verification', 'convergence-divergence']"
51,(conditional probability) Compute the probability that the first 2 balls selected are black and the third selected ball is white.,(conditional probability) Compute the probability that the first 2 balls selected are black and the third selected ball is white.,,"An urn initially contains 6 white and 8 black balls. Each time a ball is selected, its color is noted. If the selected ball is white, then it is replaced in the urn along with 3 other black balls. If the selected ball is instead black, then it is replaced along with 2 other white balls. Compute the probability that the first 2 balls selected are black and the third selected ball is white. My answer: $P(B_1B_2W_3)=\frac{{8 \choose 1} {6 \choose 0}}{{14 \choose 1}}\frac{{8 \choose 1} {8 \choose 0}}{{16 \choose 1}}\frac{{8 \choose 0} {10 \choose 1}}{{18 \choose 1}}$ which I think equals 10/63 Is my understanding of this problem correct?","An urn initially contains 6 white and 8 black balls. Each time a ball is selected, its color is noted. If the selected ball is white, then it is replaced in the urn along with 3 other black balls. If the selected ball is instead black, then it is replaced along with 2 other white balls. Compute the probability that the first 2 balls selected are black and the third selected ball is white. My answer: $P(B_1B_2W_3)=\frac{{8 \choose 1} {6 \choose 0}}{{14 \choose 1}}\frac{{8 \choose 1} {8 \choose 0}}{{16 \choose 1}}\frac{{8 \choose 0} {10 \choose 1}}{{18 \choose 1}}$ which I think equals 10/63 Is my understanding of this problem correct?",,['probability']
52,Total Variation Distance,Total Variation Distance,,"Grimmett and Stirzaker in Probability and Random Processes , 3rd ed. have on pg. 44: Let $X$ and $Y$ be integer-valued random variables, and let $$d_{TV}(X,Y) = \sum_{k}{\vert P(X=k) - P(Y=k)\vert }.$$ They ask the reader to prove that $d_{TV}(X,Y) = 0$ iff $P(X=Y) = 1$. I have no problem with $P(X=Y) = 1 \implies d_{TV}(X,Y) = 0$ but the other direction, $d_{TV}(X,Y) = 0 \implies P(X=Y) = 1$, doesn't look valid to me. Simple counter-example: One toss of a fair coin. Let $X$ be $1$ for $H$ and $0$ for $T$. Let $Y$ be $0$ for $H$ and $1$ for $T$. Then $d_{TV}(X,Y)=0$ but $P(X=Y)=0$ by my calculation. It seems to me that $d_{TV}(X,Y)$ is more a measure of the ""distance"" between the distribution functions of $X$ and $Y$ rather than between $X$ and $Y$ themselves. In the example, $X$ and $Y$ have the same distribution function. I might well be missing something here and the book is correct, but is $d_{TV}(X,Y) = 0 \implies P(X=Y) = 1$ true? If so, could you provide a proof to confirm it? Thanks.","Grimmett and Stirzaker in Probability and Random Processes , 3rd ed. have on pg. 44: Let $X$ and $Y$ be integer-valued random variables, and let $$d_{TV}(X,Y) = \sum_{k}{\vert P(X=k) - P(Y=k)\vert }.$$ They ask the reader to prove that $d_{TV}(X,Y) = 0$ iff $P(X=Y) = 1$. I have no problem with $P(X=Y) = 1 \implies d_{TV}(X,Y) = 0$ but the other direction, $d_{TV}(X,Y) = 0 \implies P(X=Y) = 1$, doesn't look valid to me. Simple counter-example: One toss of a fair coin. Let $X$ be $1$ for $H$ and $0$ for $T$. Let $Y$ be $0$ for $H$ and $1$ for $T$. Then $d_{TV}(X,Y)=0$ but $P(X=Y)=0$ by my calculation. It seems to me that $d_{TV}(X,Y)$ is more a measure of the ""distance"" between the distribution functions of $X$ and $Y$ rather than between $X$ and $Y$ themselves. In the example, $X$ and $Y$ have the same distribution function. I might well be missing something here and the book is correct, but is $d_{TV}(X,Y) = 0 \implies P(X=Y) = 1$ true? If so, could you provide a proof to confirm it? Thanks.",,"['probability', 'probability-theory']"
53,Tightness of probability measures,Tightness of probability measures,,Prove: If there is a $\phi(X)\geq0$ such that $\phi(x)\rightarrow \infty$ for $|x|\rightarrow \infty$ and $\sup_n\int\phi(x)dF_n(x)<\infty$ Then $F_n$ is tight. The definition of tightness of probability measures: $F_n$ is called tight. If for every $\epsilon>0$ there is a compact set $K_{\epsilon}$ such that $\mu(K_{\epsilon})>1-\epsilon$ Can someone give me a tip?,Prove: If there is a $\phi(X)\geq0$ such that $\phi(x)\rightarrow \infty$ for $|x|\rightarrow \infty$ and $\sup_n\int\phi(x)dF_n(x)<\infty$ Then $F_n$ is tight. The definition of tightness of probability measures: $F_n$ is called tight. If for every $\epsilon>0$ there is a compact set $K_{\epsilon}$ such that $\mu(K_{\epsilon})>1-\epsilon$ Can someone give me a tip?,,"['probability', 'probability-theory', 'probability-distributions']"
54,Mathematical justification for incorporating a conditional event in expectation?,Mathematical justification for incorporating a conditional event in expectation?,,"Let $X_1,X_2,\dots$ be independent and identically distributed random variables. Furthermore, consider the sum $$ Y = X_1 + X_2 + \dots + X_N $$ where the number of terms $N$ is itself a random variable, independent of the $X_i$, all defined on the sampe probability space. Given this preamble, the text I am reading claims the following \begin{align} E[Y|N=n] &= E[X_1+X_2+\dots+X_N|N=n] \\ &=E[X_1+X_2+\dots+X_n|N=n] \\ &=E[X_1+X_2+\dots+X_n] \end{align} While I understand the second and third equalities from an intuitive perspective (we know $N=n$, so this information can be incorporated into the number of terms in the sum), how can this be derived mathematically, or in a more pedantic/rigorous fashion using the laws of probability? Do we need to consider the joint distribution of the $X_i$ and $N$? Any ideas would be appreciated.","Let $X_1,X_2,\dots$ be independent and identically distributed random variables. Furthermore, consider the sum $$ Y = X_1 + X_2 + \dots + X_N $$ where the number of terms $N$ is itself a random variable, independent of the $X_i$, all defined on the sampe probability space. Given this preamble, the text I am reading claims the following \begin{align} E[Y|N=n] &= E[X_1+X_2+\dots+X_N|N=n] \\ &=E[X_1+X_2+\dots+X_n|N=n] \\ &=E[X_1+X_2+\dots+X_n] \end{align} While I understand the second and third equalities from an intuitive perspective (we know $N=n$, so this information can be incorporated into the number of terms in the sum), how can this be derived mathematically, or in a more pedantic/rigorous fashion using the laws of probability? Do we need to consider the joint distribution of the $X_i$ and $N$? Any ideas would be appreciated.",,"['probability', 'random-variables', 'conditional-expectation']"
55,Expected count of correct assignments,Expected count of correct assignments,,"There are $40$ letters and $40$ envelopes with addresses. The letters are put in envelopes at random. What is the expected number of letters in their corresponding (correct) envelopes ? One envelope can hold only one letter. I start with $E(X_i)=1\cdot\dfrac{1}{40}+0\cdot\dfrac{39}{40}=\dfrac{1}{40}$. $X_i$ being the $i^{th}$ letter placed correctly or not ($1$, if correctly placed and $0$, if not). I need to calculate the expected count of letters assigned correctly. Then add up all $\implies$ $E(X_1+X_2+\ldots+X_{40})=\underbrace{\dfrac{1}{40}+\dfrac{1}{40}+\ldots+\dfrac{1}{40}}_{40\text{ times}}=1$ Now my doubt is that if I put $39$ letters correctly, the $40^{th}$ one will be automatically assigned correctly . So should I add only $39$ times ? Any other mistakes I may be doing here ? Please advise.","There are $40$ letters and $40$ envelopes with addresses. The letters are put in envelopes at random. What is the expected number of letters in their corresponding (correct) envelopes ? One envelope can hold only one letter. I start with $E(X_i)=1\cdot\dfrac{1}{40}+0\cdot\dfrac{39}{40}=\dfrac{1}{40}$. $X_i$ being the $i^{th}$ letter placed correctly or not ($1$, if correctly placed and $0$, if not). I need to calculate the expected count of letters assigned correctly. Then add up all $\implies$ $E(X_1+X_2+\ldots+X_{40})=\underbrace{\dfrac{1}{40}+\dfrac{1}{40}+\ldots+\dfrac{1}{40}}_{40\text{ times}}=1$ Now my doubt is that if I put $39$ letters correctly, the $40^{th}$ one will be automatically assigned correctly . So should I add only $39$ times ? Any other mistakes I may be doing here ? Please advise.",,"['probability', 'expectation']"
56,Lower bound on probability of sum of random variables,Lower bound on probability of sum of random variables,,"Suppose that the random variables $X_i, i = 1,2,\ldots,n$ are i.i.d.  Suppose $0 \leq X_i \leq 4n^2$ with probability 1 for all $i$.  Suppose that $\mathbb{E}(X_i) \geq n$ for all $i$.  Show that $$\mathbb{P}(X_1 + X_2 + \cdots + X_n \geq n^2/2) \geq \frac{1}{20}.$$ Hint:  Is there a lower bound inequality that you might try here?  What do you need to compute?  How can you use the hypotheses? I tried something that seemed like it was working at first, but didn't get me anywhere.  Here's what I did, considering only the case where $n$ is even: Define $S := X_1 + X_2 + \cdots + X_n$.  Then $\mathbb{E}(S) \geq n^2$.  We have \begin{align*} n^2 \leq \mathbb{E}(S) &\leq  \mathbb{P}(0 \leq S) + \mathbb{P}(1 \leq S) + \cdots + \mathbb{P}(4n^3 - 1 \leq S)\\ &= \left(\mathbb{P}(0 \leq S) + \cdots + \mathbb{P}(n^2/2 - 1 \leq  S) \right) \\ &\qquad {}+ \left(\mathbb{P}(n^2/2 \leq S) + \cdots + \mathbb{P}(4n^3 - 1 \leq S)  \right) \\ &= n^2 + (4n^3 - n^2/2)\mathbb{P}(n^2/2 \leq S)  \end{align*} This yields $$\frac{1}{8n-1} \leq \mathbb{P}(n^2/2 \leq S)$$ Which is a pretty nice result, but isn't what the problem asks for.  Any help would be greatly appreciated.","Suppose that the random variables $X_i, i = 1,2,\ldots,n$ are i.i.d.  Suppose $0 \leq X_i \leq 4n^2$ with probability 1 for all $i$.  Suppose that $\mathbb{E}(X_i) \geq n$ for all $i$.  Show that $$\mathbb{P}(X_1 + X_2 + \cdots + X_n \geq n^2/2) \geq \frac{1}{20}.$$ Hint:  Is there a lower bound inequality that you might try here?  What do you need to compute?  How can you use the hypotheses? I tried something that seemed like it was working at first, but didn't get me anywhere.  Here's what I did, considering only the case where $n$ is even: Define $S := X_1 + X_2 + \cdots + X_n$.  Then $\mathbb{E}(S) \geq n^2$.  We have \begin{align*} n^2 \leq \mathbb{E}(S) &\leq  \mathbb{P}(0 \leq S) + \mathbb{P}(1 \leq S) + \cdots + \mathbb{P}(4n^3 - 1 \leq S)\\ &= \left(\mathbb{P}(0 \leq S) + \cdots + \mathbb{P}(n^2/2 - 1 \leq  S) \right) \\ &\qquad {}+ \left(\mathbb{P}(n^2/2 \leq S) + \cdots + \mathbb{P}(4n^3 - 1 \leq S)  \right) \\ &= n^2 + (4n^3 - n^2/2)\mathbb{P}(n^2/2 \leq S)  \end{align*} This yields $$\frac{1}{8n-1} \leq \mathbb{P}(n^2/2 \leq S)$$ Which is a pretty nice result, but isn't what the problem asks for.  Any help would be greatly appreciated.",,['probability']
57,Rigorous proof of the recursion method to compute expectations in probability.,Rigorous proof of the recursion method to compute expectations in probability.,,"When solving expectation problems in probability, people sometime use recursive argument, but I have never seen a proof that this argument always works. For example, what is the expected number of rolls of a fair six sided die until you roll ""1""? The recursive method says, 1) You have a $1/6$ probability of rolling ""1"" on the first roll and a $5/6$ chance of rolling the other five numbers. 2) If you roll any of the other five numbers you have to start over again, but now you start at roll 1 to try and get your ""1"". If E is the expected number of rolls to get ""1"", the recursive method says, $E = (1/6)*(1 roll) + (5/6)*[(E + 1) rolls]$ So, $E = (1/6) + (5/6)(E + 1)$ and solving for $E$ we get $E  = 6$. There are also recursion methods for things like ""What is the expected number of flips of 2 sided coin to get two consecutive heads"", and other such problems involving questions like ""how many rolls/flips/etc. to get somethings"". My question is: Is there a rigorous mathematical proof that such recursion methods always work? By rigorous I mean please start with the definition of expectation as the integral of the random var. over its sample space. From this definition, can you prove the recursion method? Even if you prove it for a specific example that would be OK too. The issue I am having is that the recursion method seems ""intuitive"" (it could be rigorous, but no book has proved it that I've read!) and I do not see where the definition of expectation (as an integral) is used in the method.  The recursion method seems to be ""trick"" books discuss, but never relate to the definition of expectation as the integral of the function.","When solving expectation problems in probability, people sometime use recursive argument, but I have never seen a proof that this argument always works. For example, what is the expected number of rolls of a fair six sided die until you roll ""1""? The recursive method says, 1) You have a $1/6$ probability of rolling ""1"" on the first roll and a $5/6$ chance of rolling the other five numbers. 2) If you roll any of the other five numbers you have to start over again, but now you start at roll 1 to try and get your ""1"". If E is the expected number of rolls to get ""1"", the recursive method says, $E = (1/6)*(1 roll) + (5/6)*[(E + 1) rolls]$ So, $E = (1/6) + (5/6)(E + 1)$ and solving for $E$ we get $E  = 6$. There are also recursion methods for things like ""What is the expected number of flips of 2 sided coin to get two consecutive heads"", and other such problems involving questions like ""how many rolls/flips/etc. to get somethings"". My question is: Is there a rigorous mathematical proof that such recursion methods always work? By rigorous I mean please start with the definition of expectation as the integral of the random var. over its sample space. From this definition, can you prove the recursion method? Even if you prove it for a specific example that would be OK too. The issue I am having is that the recursion method seems ""intuitive"" (it could be rigorous, but no book has proved it that I've read!) and I do not see where the definition of expectation (as an integral) is used in the method.  The recursion method seems to be ""trick"" books discuss, but never relate to the definition of expectation as the integral of the function.",,"['probability', 'probability-theory']"
58,Stopped-sum of Exponential random variables,Stopped-sum of Exponential random variables,,"Let $\xi_1, \xi_2, \ldots \xi_n, \ldots$ - independent random variables having exponential distribution $p_{\xi_i} (x) = \lambda e^{- \lambda x}, \; x \ge 0$ and $p_{\xi_i} (x) = 0, \; x < 0$. Let $\nu = \min \{n \ge 1 : \xi_n > 1\}$. Need to find the distribution function of a random variable $g = \xi_1 + \xi_2 + \ldots \xi_{\nu}$ that is, find the probability $\mathbb{P}(g < x) = \mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_{\nu} < x)$. I made the following calculations: $\mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_{\nu} < x) = \sum_{k = 1}^{\infty} \mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_k < x, \nu = k) = \sum_{k = 1}^{\infty} \mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_k < x, \xi_1 \le 1, \ldots \xi_{k-1} \le 1, \xi_k > 1)$. The probability of the sum can be represented as integral: $\mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_k < x, \xi_1 \le 1, \ldots \xi_{k-1} \le 1, \xi_k > 1) = \int\limits_D \lambda^k e^{- \lambda u_1} e^{- \lambda u_2} \ldots e^{- \lambda u_k} {d}u_1 \ldots {d}u_k$, where $D = \{ u_1 + \ldots u_k < x, u_1 \le 1, \ldots u_{k-1} \le 1, u_k > 1\}$. I'm afraid that this integral cannot be calculated. Is it somehow easier to find the distribution function $\mathbb{P} (g < x)$?","Let $\xi_1, \xi_2, \ldots \xi_n, \ldots$ - independent random variables having exponential distribution $p_{\xi_i} (x) = \lambda e^{- \lambda x}, \; x \ge 0$ and $p_{\xi_i} (x) = 0, \; x < 0$. Let $\nu = \min \{n \ge 1 : \xi_n > 1\}$. Need to find the distribution function of a random variable $g = \xi_1 + \xi_2 + \ldots \xi_{\nu}$ that is, find the probability $\mathbb{P}(g < x) = \mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_{\nu} < x)$. I made the following calculations: $\mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_{\nu} < x) = \sum_{k = 1}^{\infty} \mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_k < x, \nu = k) = \sum_{k = 1}^{\infty} \mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_k < x, \xi_1 \le 1, \ldots \xi_{k-1} \le 1, \xi_k > 1)$. The probability of the sum can be represented as integral: $\mathbb{P} (\xi_1 + \xi_2 + \ldots \xi_k < x, \xi_1 \le 1, \ldots \xi_{k-1} \le 1, \xi_k > 1) = \int\limits_D \lambda^k e^{- \lambda u_1} e^{- \lambda u_2} \ldots e^{- \lambda u_k} {d}u_1 \ldots {d}u_k$, where $D = \{ u_1 + \ldots u_k < x, u_1 \le 1, \ldots u_{k-1} \le 1, u_k > 1\}$. I'm afraid that this integral cannot be calculated. Is it somehow easier to find the distribution function $\mathbb{P} (g < x)$?",,"['probability', 'probability-theory', 'probability-distributions']"
59,Algorithm for unbiased random derangement,Algorithm for unbiased random derangement,,"I am looking for an algorithm that generates a derangement with uniform probability across all possible derangements. This is similar to Generating a random derangement , but with the requirement that the randomness is unbiased, i.e. every derrangment has equal opportunity of being selected. I have tried the algorithm described here and here , but they offer no such claim, and do not seem to be able to generate every derangement. For example, it does not generate (2,1,4,5,3).","I am looking for an algorithm that generates a derangement with uniform probability across all possible derangements. This is similar to Generating a random derangement , but with the requirement that the randomness is unbiased, i.e. every derrangment has equal opportunity of being selected. I have tried the algorithm described here and here , but they offer no such claim, and do not seem to be able to generate every derangement. For example, it does not generate (2,1,4,5,3).",,"['probability', 'permutations', 'algorithms', 'derangements']"
60,Two series of independent Bernoulli trials. Find distributions of being simultaneously successful and of first success being simultaneous.,Two series of independent Bernoulli trials. Find distributions of being simultaneously successful and of first success being simultaneous.,,"Nick and Penny are independently performing independent Bernoulli trials. For concreteness, assume that Nick is flipping a nickel with probability p1 of Heads and Penny is flipping a penny with probability p2 of Heads. Let $X_1$ , $X_2$, . . . be Nick’s results and $Y_1$ , $Y_2$, . . . be Penny’s results, with $X_i \sim \operatorname{Bern}(p_1)$ and $Y_j \sim \operatorname{Bern}(p_2)$. (a) Find the distribution and expected value of the first time at which they are simultaneously successful, i.e., the smallest n such that $X_n$ = $Y_n$ = 1.   Hint: Define a new sequence of Bernoulli trials and use the story of the Geometric. (b) Find the expected time until at least one has a success (including the success).   Hint: Define a new sequence of Bernoulli trials and use the story of the Geometric. (c) For $p_1$ = $p_2$ , find the probability that their first successes are simultaneous, and use this to find the probability that Nick’s first success precedes Penny’s. Here is my solution. I'd like to know if I did this right. a) Let $Z$ be the number of trials until (and including) the first time the are simultaneously successful. Then $Z \sim \operatorname{FS}(p_1p_2)$, where $\operatorname{FS}$ denotes the First Success distribution (equivalently, $Z-1 \sim \operatorname{Geom}(p_1p_2)$). Then $E(Z) = \frac{1}{p_1p_2}$. b) Analogous to a), the results shoult be $\frac{1}{p_1+p_2 - p_1p_2}$ c) Let $p=p_1=p_2$, $S$ be the event that their first success occurs simulateously, and $S_i$ the event that their first success occurs simultaneously at the $i^{th}$ trial. Then \begin{align} P(S) = P(\cup_{i=1}^{\infty} S_i) &= \sum_{i=1}^\infty \left((1-p)^2 \right)^{k-1} p^2 \\ &=\frac{p^2}{(1-p)^2} \frac{(1-p)^2}{1-(1-p)^2} \\ &= \frac{p^2}{1-(1-p)^2} \\ &= \frac{p}{2-p} \end{align} The probability that Nick's success precedes Penny's should be -by symmetry- one half of the probability that their first successes do NOT occur simultaneously, and thus $\frac{1}{2-p}$. EDIT I think the answer to c) should be $\frac{1-p}{2-p}$","Nick and Penny are independently performing independent Bernoulli trials. For concreteness, assume that Nick is flipping a nickel with probability p1 of Heads and Penny is flipping a penny with probability p2 of Heads. Let $X_1$ , $X_2$, . . . be Nick’s results and $Y_1$ , $Y_2$, . . . be Penny’s results, with $X_i \sim \operatorname{Bern}(p_1)$ and $Y_j \sim \operatorname{Bern}(p_2)$. (a) Find the distribution and expected value of the first time at which they are simultaneously successful, i.e., the smallest n such that $X_n$ = $Y_n$ = 1.   Hint: Define a new sequence of Bernoulli trials and use the story of the Geometric. (b) Find the expected time until at least one has a success (including the success).   Hint: Define a new sequence of Bernoulli trials and use the story of the Geometric. (c) For $p_1$ = $p_2$ , find the probability that their first successes are simultaneous, and use this to find the probability that Nick’s first success precedes Penny’s. Here is my solution. I'd like to know if I did this right. a) Let $Z$ be the number of trials until (and including) the first time the are simultaneously successful. Then $Z \sim \operatorname{FS}(p_1p_2)$, where $\operatorname{FS}$ denotes the First Success distribution (equivalently, $Z-1 \sim \operatorname{Geom}(p_1p_2)$). Then $E(Z) = \frac{1}{p_1p_2}$. b) Analogous to a), the results shoult be $\frac{1}{p_1+p_2 - p_1p_2}$ c) Let $p=p_1=p_2$, $S$ be the event that their first success occurs simulateously, and $S_i$ the event that their first success occurs simultaneously at the $i^{th}$ trial. Then \begin{align} P(S) = P(\cup_{i=1}^{\infty} S_i) &= \sum_{i=1}^\infty \left((1-p)^2 \right)^{k-1} p^2 \\ &=\frac{p^2}{(1-p)^2} \frac{(1-p)^2}{1-(1-p)^2} \\ &= \frac{p^2}{1-(1-p)^2} \\ &= \frac{p}{2-p} \end{align} The probability that Nick's success precedes Penny's should be -by symmetry- one half of the probability that their first successes do NOT occur simultaneously, and thus $\frac{1}{2-p}$. EDIT I think the answer to c) should be $\frac{1-p}{2-p}$",,"['probability', 'probability-distributions']"
61,Finding the PDF from the CDF where the CDF is not differentiable at some point,Finding the PDF from the CDF where the CDF is not differentiable at some point,,"I got the following problem: Let $X$ be a continuous random variable with $CDF$ denoted $F_X$ defined as follows: $F_X(x)= \begin{cases} 1-x^{-4/3}, & x\in[1,\infty) \\ 0, & x\in (-\infty,1) \end{cases}$ Find the PDF of $X$. My try: Since the PDF (denoted $f_X$) is the derivative of the CDF I get that $\forall x\in(1,\infty), f_X(x)=\frac{4}{3}x^{-7/3}$ and that $\forall x\in(-\infty,1), f_X(x)=0$. Now I don't know what to do. The function $F_X$ is not differentiable at $x=1$ since the derivative from the right and from the left got different values and since the domain of the PDF must be $\mathbb{R}$ . Is defining $f_X$ to be zero (or any other non-negative value) when $x=1$ is the solution? Thanks for any help.","I got the following problem: Let $X$ be a continuous random variable with $CDF$ denoted $F_X$ defined as follows: $F_X(x)= \begin{cases} 1-x^{-4/3}, & x\in[1,\infty) \\ 0, & x\in (-\infty,1) \end{cases}$ Find the PDF of $X$. My try: Since the PDF (denoted $f_X$) is the derivative of the CDF I get that $\forall x\in(1,\infty), f_X(x)=\frac{4}{3}x^{-7/3}$ and that $\forall x\in(-\infty,1), f_X(x)=0$. Now I don't know what to do. The function $F_X$ is not differentiable at $x=1$ since the derivative from the right and from the left got different values and since the domain of the PDF must be $\mathbb{R}$ . Is defining $f_X$ to be zero (or any other non-negative value) when $x=1$ is the solution? Thanks for any help.",,"['calculus', 'probability', 'derivatives', 'random-variables']"
62,Almost surely convergence of the sequence,Almost surely convergence of the sequence,,"Let ${X_n}$ be a sequence of independent and identically distributed, square integrable random variables.   Write $ u = E(X_n)$. Study the almost sure convergence, as $n \rightarrow \infty$, $$S_n = (X_1X_2 + X_2X_3 + ... + X_{n-1}X_{n})/n$$ Since $X_iX_{i+1}$ are not independent, it seems we cannot directly use law of large number for that, so anyone can give me some idea?","Let ${X_n}$ be a sequence of independent and identically distributed, square integrable random variables.   Write $ u = E(X_n)$. Study the almost sure convergence, as $n \rightarrow \infty$, $$S_n = (X_1X_2 + X_2X_3 + ... + X_{n-1}X_{n})/n$$ Since $X_iX_{i+1}$ are not independent, it seems we cannot directly use law of large number for that, so anyone can give me some idea?",,"['probability', 'law-of-large-numbers', 'central-limit-theorem']"
63,Probability of having always flipped more $H$ than $T$ in an infinite coin flip sequence,Probability of having always flipped more  than  in an infinite coin flip sequence,H T,"A biased coin has probability $p \in [0,1]$ of landing heads ($H$) and hence probability $1-p$ of landing tails ($T$). We will flip this coin infinitely many times, obtaining a sequence $(x_i)_{i=1}^\infty$ of flips, where $x_i \in \{H, T\}$ for $i \in \mathbb{N}$. What is the probability that for all $N \in \mathbb{N}$, $(x_i)_{i=1}^N$ contains strictly more $H$s than $T$s? I've tried using the Ballot Theorem and taking limits, but nothing has seemed to work so far.","A biased coin has probability $p \in [0,1]$ of landing heads ($H$) and hence probability $1-p$ of landing tails ($T$). We will flip this coin infinitely many times, obtaining a sequence $(x_i)_{i=1}^\infty$ of flips, where $x_i \in \{H, T\}$ for $i \in \mathbb{N}$. What is the probability that for all $N \in \mathbb{N}$, $(x_i)_{i=1}^N$ contains strictly more $H$s than $T$s? I've tried using the Ballot Theorem and taking limits, but nothing has seemed to work so far.",,"['probability', 'combinatorics']"
64,Probability that someone will pick a red ball first?,Probability that someone will pick a red ball first?,,A father and son take turns picking red and green balls from a bag.  There are 2 red balls and 3 green balls. The first person to pick a red ball wins. There is no replacement. What is the probability that the father wins if he goes first? I drew a binary tree to solve this. The father can only win the first round and the third round. P(father wins first round) = $\frac25$ P(father wins third round) = $\frac35 * \frac24 * \frac23 = \frac15$ P(father wins first round) + P(father wins third round) = $\frac25+\frac15 =\frac35$ Is this correct?,A father and son take turns picking red and green balls from a bag.  There are 2 red balls and 3 green balls. The first person to pick a red ball wins. There is no replacement. What is the probability that the father wins if he goes first? I drew a binary tree to solve this. The father can only win the first round and the third round. P(father wins first round) = $\frac25$ P(father wins third round) = $\frac35 * \frac24 * \frac23 = \frac15$ P(father wins first round) + P(father wins third round) = $\frac25+\frac15 =\frac35$ Is this correct?,,['probability']
65,"Given a probability distribution, how many times do I have to repeat an experiment so see a certain outcome","Given a probability distribution, how many times do I have to repeat an experiment so see a certain outcome",,"My question concerns random number generation under certain constraints. I assume that the random number generator is good enough to generate uniformly distributed numbers. This means that each number has the probability 1/N to occur. How many times should I repeat the experiment (generating a random number) such that it's is very likely that a see a certain number. I think there was a theorem that could give me a value, given a certain bound on how certain I want to be that the event happened (i.e. if I want to be 50% certain that it appears I run it x times, if I want to be 99% certain I run it y times, with x < y ).","My question concerns random number generation under certain constraints. I assume that the random number generator is good enough to generate uniformly distributed numbers. This means that each number has the probability 1/N to occur. How many times should I repeat the experiment (generating a random number) such that it's is very likely that a see a certain number. I think there was a theorem that could give me a value, given a certain bound on how certain I want to be that the event happened (i.e. if I want to be 50% certain that it appears I run it x times, if I want to be 99% certain I run it y times, with x < y ).",,"['probability', 'probability-distributions']"
66,How to analyse a random walk with random transition probabilities,How to analyse a random walk with random transition probabilities,,"Consider a $1$-dimensional random walk with discrete time steps. We start at the origin and at each integer position there is possibly different probability of moving right one step, or left one step. For each position $i$ a single coin toss is made to fix the transition probabilities at that position. With probability $1/2$ there  is a probability of moving right of $2/3$ and probability of moving left of $1/3$. With probability $1/2$ there is a probability of moving left of $2/3$ and probability of moving right of $1/3$. For a given position $i$ this coin toss is only ever done once so the transition probabilities for that position are then fixed forever. If you start at the origin, how far away do you expect to be after $n$ steps?  I would be happy with a large $n$ approximation if that is easier.","Consider a $1$-dimensional random walk with discrete time steps. We start at the origin and at each integer position there is possibly different probability of moving right one step, or left one step. For each position $i$ a single coin toss is made to fix the transition probabilities at that position. With probability $1/2$ there  is a probability of moving right of $2/3$ and probability of moving left of $1/3$. With probability $1/2$ there is a probability of moving left of $2/3$ and probability of moving right of $1/3$. For a given position $i$ this coin toss is only ever done once so the transition probabilities for that position are then fixed forever. If you start at the origin, how far away do you expect to be after $n$ steps?  I would be happy with a large $n$ approximation if that is easier.",,['probability']
67,Calculating Catalan numbers using Chebyshev's inequality,Calculating Catalan numbers using Chebyshev's inequality,,"By using Chebyshev's inequality $P(|X - E[X]| \geq \varepsilon) \leq \operatorname{Var}(X)/ \varepsilon^2$ I want to calculate the following estimation for the Catalan numbers $C_n = \frac{1}{n+1} \binom{2n}{n}$ : $$C_n \geq \frac{4^{n-1}}{(n+1)(\sqrt{n} + \frac{1}{2})} \forall n \in \mathbb N.$$ Hint is to use a random variable $X$ which is binomial distributed, in a way that there's $\frac{1}{2}$ on the right side of Chebyshev's inequality for $\varepsilon = \sqrt{n}$, and that $\binom{2n}{n}$ is the largest binomial coefficient among $\binom{2n}{k}, k \in \{0, \ldots, 2n \}$.  I got that for $X \sim \mathrm{Bin}(2n,\frac{1}{2})$. Can anybody show me how to move on?","By using Chebyshev's inequality $P(|X - E[X]| \geq \varepsilon) \leq \operatorname{Var}(X)/ \varepsilon^2$ I want to calculate the following estimation for the Catalan numbers $C_n = \frac{1}{n+1} \binom{2n}{n}$ : $$C_n \geq \frac{4^{n-1}}{(n+1)(\sqrt{n} + \frac{1}{2})} \forall n \in \mathbb N.$$ Hint is to use a random variable $X$ which is binomial distributed, in a way that there's $\frac{1}{2}$ on the right side of Chebyshev's inequality for $\varepsilon = \sqrt{n}$, and that $\binom{2n}{n}$ is the largest binomial coefficient among $\binom{2n}{k}, k \in \{0, \ldots, 2n \}$.  I got that for $X \sim \mathrm{Bin}(2n,\frac{1}{2})$. Can anybody show me how to move on?",,"['probability', 'catalan-numbers']"
68,"show that Cov(X+ Y, X-Y)= Var(X) - Var(Y)","show that Cov(X+ Y, X-Y)= Var(X) - Var(Y)",,"I have up until Cov(X+Y,X-Y) = E[((X-E(X))+(Y-E(Y)))((X-E(X))-(Y+E(Y)))] and now I am stuck and do not know how this turns into Var(X)-Var(Y)","I have up until Cov(X+Y,X-Y) = E[((X-E(X))+(Y-E(Y)))((X-E(X))-(Y+E(Y)))] and now I am stuck and do not know how this turns into Var(X)-Var(Y)",,['probability']
69,What is the probability that you wil win this coin flip game?,What is the probability that you wil win this coin flip game?,,"101 people flip a fair coin. Everyone who tosses heads is on one team and everyone who tosses tails is on another other team. The team with more people on it wins. What are the odds that, given you are one of the 101 players, you will win? (101 players and coins eliminates ties but I am also interested the case where there are 100 players where you can win/lose/tie).","101 people flip a fair coin. Everyone who tosses heads is on one team and everyone who tosses tails is on another other team. The team with more people on it wins. What are the odds that, given you are one of the 101 players, you will win? (101 players and coins eliminates ties but I am also interested the case where there are 100 players where you can win/lose/tie).",,['probability']
70,Why Poisson distribution is used for the Chocolate-Chip cookie problem?,Why Poisson distribution is used for the Chocolate-Chip cookie problem?,,I've noticed that it's very popular to formulate problems related to the probability of finding at least $k$ out of $m$ chocolate chips in one of $n$ cookies using Poisson Distribution. I wanted to know exactly why Poisson Distribution is suitable for this problem?,I've noticed that it's very popular to formulate problems related to the probability of finding at least $k$ out of $m$ chocolate chips in one of $n$ cookies using Poisson Distribution. I wanted to know exactly why Poisson Distribution is suitable for this problem?,,"['probability', 'poisson-distribution']"
71,First-order stochastic dominance and truncation,First-order stochastic dominance and truncation,,"Suppose we have two distributions $F$ and $G$ over $\left[0,1\right]$. Suppose $F(x) \leq G(x)$ for all $x$, i.e. $F$ first-order stochastically dominates $G$. Is it true that $F(x|x\leq k) \leq G(x|x\leq k)$ for all $k$ and for all $x \in \left[0,k\right]$? Put in another way, does first-order stochastic dominance survive half-truncations? Thanks.","Suppose we have two distributions $F$ and $G$ over $\left[0,1\right]$. Suppose $F(x) \leq G(x)$ for all $x$, i.e. $F$ first-order stochastically dominates $G$. Is it true that $F(x|x\leq k) \leq G(x|x\leq k)$ for all $k$ and for all $x \in \left[0,k\right]$? Put in another way, does first-order stochastic dominance survive half-truncations? Thanks.",,"['probability', 'statistics', 'probability-distributions', 'stochastic-analysis']"
72,Bayes' Net Conditional Probability,Bayes' Net Conditional Probability,,"I have a Bayes' Net with 4 boolean nodes connected in a diamond shape.  I want to find the probability of one of the middle nodes being true given that the ones above and below are both true.  So given the diagram below, I want to find P(B|A and D). A  / \  B   C  \ /   D I'm a bit lost because I'm not sure how to relate the conditional probabilities coming from both higher up and further down the net.  Any tips on how to approach this would be welcome!","I have a Bayes' Net with 4 boolean nodes connected in a diamond shape.  I want to find the probability of one of the middle nodes being true given that the ones above and below are both true.  So given the diagram below, I want to find P(B|A and D). A  / \  B   C  \ /   D I'm a bit lost because I'm not sure how to relate the conditional probabilities coming from both higher up and further down the net.  Any tips on how to approach this would be welcome!",,"['probability', 'conditional-probability', 'bayesian']"
73,Why does my money converge to zero?,Why does my money converge to zero?,,"I invest $\$1000$ in a stock. Every year, the stock price will either increase by $90\%$ or decrease by $50\%$. The expected value of the change in the price is: $0.5\cdot90\% + 0.5\cdot(-50\%)= 20\% $ I ran a simulation in excel and I got that the stock price converges to zero. Can someone explain why, or how could I calculate it?","I invest $\$1000$ in a stock. Every year, the stock price will either increase by $90\%$ or decrease by $50\%$. The expected value of the change in the price is: $0.5\cdot90\% + 0.5\cdot(-50\%)= 20\% $ I ran a simulation in excel and I got that the stock price converges to zero. Can someone explain why, or how could I calculate it?",,"['probability', 'convergence-divergence']"
74,Probabilistic proof of green-eyed dragons logic puzzle,Probabilistic proof of green-eyed dragons logic puzzle,,"I came across the ""green-eyed dragons"" puzzle (alternatively known as the ""blue eyed villagers"" puzzle). The typical proof uses a straightforward inductive strategy. I came up with a probabalistic proof, and I wondered if there are holes in it. The puzzle in its (possibly original) form can be found here: https://www.physics.harvard.edu/uploads/files/undergrad/probweek/prob2.pdf and the inductive proof here: https://www.physics.harvard.edu/uploads/files/undergrad/probweek/sol2.pdf . Theorem : All 100 dragons transform at midnight on the first night. Proof : It suffices to prove that each dragon independently concludes $$\Pr[\textrm{exactly 100 dragons have green eyes}] = 1$$ Upon departing, we tell the dragons collectively that at least one of them has green eyes. Specifically, we impart the knowledge that $$\Pr[\textrm{at least 1 dragon has green eyes}] = 1$$ Define $L_i$ to be the event that at least $i$ dragons have green eyes, and $E_i$ to be the event that exactly $i$ dragons have green eyes. Then the above probability can be restated as: \begin{align*} \Pr[L_1] = {100 \choose 1} \Pr[E_1] + {100 \choose 2} \Pr[E_2] + \dots + {100 \choose 100} \Pr[E_{100}] \end{align*} Because each dragon observes the eye color of every other dragon except himself, each dragon concludes independently that: \begin{align*}  \Pr[E_0] = \Pr[E_1] = \Pr[E_2] = \dots = \Pr[E_{98}] = 0 \end{align*} Therefore, each dragon concludes \begin{align*} \Pr[L_1] = {100 \choose 99} \Pr[E_{99}] + \Pr[E_{100}] = 1 \end{align*} Note that \begin{align*} \Pr[E_{99}] &= 1-\left(\Pr[E_0] + {100 \choose 1}\Pr[E_1] + \dots + {100 \choose 98}\Pr[E_{98}] + \Pr[E_{100}]\right) \\ &= 1- \Pr[E_{100}] \end{align*} Therefore,  \begin{align*} {100 \choose 99} \Pr[E_{99}] + \Pr[E_{100}] &= 1 \\ 100(1-\Pr[E_{100}]) + \Pr[E_{100}] &= 1 \\ 100 - 99\Pr[E_{100}] &= 1 \\ \Pr[E_{100}] &= 1 \end{align*} Thus, each dragon individually concludes that with probability 1, all 100 dragons have green eyes (including himself). This reasoning happens simultaneously across all dragons, and thus they all transform together on the first midnight, QED.","I came across the ""green-eyed dragons"" puzzle (alternatively known as the ""blue eyed villagers"" puzzle). The typical proof uses a straightforward inductive strategy. I came up with a probabalistic proof, and I wondered if there are holes in it. The puzzle in its (possibly original) form can be found here: https://www.physics.harvard.edu/uploads/files/undergrad/probweek/prob2.pdf and the inductive proof here: https://www.physics.harvard.edu/uploads/files/undergrad/probweek/sol2.pdf . Theorem : All 100 dragons transform at midnight on the first night. Proof : It suffices to prove that each dragon independently concludes $$\Pr[\textrm{exactly 100 dragons have green eyes}] = 1$$ Upon departing, we tell the dragons collectively that at least one of them has green eyes. Specifically, we impart the knowledge that $$\Pr[\textrm{at least 1 dragon has green eyes}] = 1$$ Define $L_i$ to be the event that at least $i$ dragons have green eyes, and $E_i$ to be the event that exactly $i$ dragons have green eyes. Then the above probability can be restated as: \begin{align*} \Pr[L_1] = {100 \choose 1} \Pr[E_1] + {100 \choose 2} \Pr[E_2] + \dots + {100 \choose 100} \Pr[E_{100}] \end{align*} Because each dragon observes the eye color of every other dragon except himself, each dragon concludes independently that: \begin{align*}  \Pr[E_0] = \Pr[E_1] = \Pr[E_2] = \dots = \Pr[E_{98}] = 0 \end{align*} Therefore, each dragon concludes \begin{align*} \Pr[L_1] = {100 \choose 99} \Pr[E_{99}] + \Pr[E_{100}] = 1 \end{align*} Note that \begin{align*} \Pr[E_{99}] &= 1-\left(\Pr[E_0] + {100 \choose 1}\Pr[E_1] + \dots + {100 \choose 98}\Pr[E_{98}] + \Pr[E_{100}]\right) \\ &= 1- \Pr[E_{100}] \end{align*} Therefore,  \begin{align*} {100 \choose 99} \Pr[E_{99}] + \Pr[E_{100}] &= 1 \\ 100(1-\Pr[E_{100}]) + \Pr[E_{100}] &= 1 \\ 100 - 99\Pr[E_{100}] &= 1 \\ \Pr[E_{100}] &= 1 \end{align*} Thus, each dragon individually concludes that with probability 1, all 100 dragons have green eyes (including himself). This reasoning happens simultaneously across all dragons, and thus they all transform together on the first midnight, QED.",,"['probability', 'solution-verification', 'recreational-mathematics', 'puzzle']"
75,Weak version Fatou lemma,Weak version Fatou lemma,,"I want to show the weak version Fatou Lemma; i.e., Let $f \ge 0$ be continuous function. If $X_n \rightarrow X$ in distribution, then  $$ \liminf_{n\rightarrow \infty} E f(X_n) \ge Ef(X) $$ Here is my thought: I know that if $X_n \rightarrow X$ in distribution, then there exists another random variables $Y_n$ and $Y$ such that the distribution $F_{X_n} = F_{Y_n}$ and $F_X = F_Y$ and $Y_n \rightarrow Y$ almost surely. (1) and since the original Fatou Lemma says that:  If $Y_n \rightarrow Y$ almost surely, and if $f \ge 0$ then we have $$ \liminf_{n\rightarrow \infty} E f(Y_n) \ge Ef(Y) $$ So I combine (1) and original Fatou Lemma, then get  $$ \liminf_{n\rightarrow \infty} E f(Y_n) \ge Ef(Y) $$ But I stuck on how to take advantage of using that fact that $X_n$ and $Y_n$ are the same distribution to infer that   $$ \liminf_{n\rightarrow \infty} E f(X_n) \ge Ef(X) $$ I think the question in my mind is that if $X_n$ and $Y_n$ has the same distribution, then what can I say about its expectation? e.g., Is this legal to saying that $EX_n = EY_n ?$ Thank you.","I want to show the weak version Fatou Lemma; i.e., Let $f \ge 0$ be continuous function. If $X_n \rightarrow X$ in distribution, then  $$ \liminf_{n\rightarrow \infty} E f(X_n) \ge Ef(X) $$ Here is my thought: I know that if $X_n \rightarrow X$ in distribution, then there exists another random variables $Y_n$ and $Y$ such that the distribution $F_{X_n} = F_{Y_n}$ and $F_X = F_Y$ and $Y_n \rightarrow Y$ almost surely. (1) and since the original Fatou Lemma says that:  If $Y_n \rightarrow Y$ almost surely, and if $f \ge 0$ then we have $$ \liminf_{n\rightarrow \infty} E f(Y_n) \ge Ef(Y) $$ So I combine (1) and original Fatou Lemma, then get  $$ \liminf_{n\rightarrow \infty} E f(Y_n) \ge Ef(Y) $$ But I stuck on how to take advantage of using that fact that $X_n$ and $Y_n$ are the same distribution to infer that   $$ \liminf_{n\rightarrow \infty} E f(X_n) \ge Ef(X) $$ I think the question in my mind is that if $X_n$ and $Y_n$ has the same distribution, then what can I say about its expectation? e.g., Is this legal to saying that $EX_n = EY_n ?$ Thank you.",,"['probability', 'probability-theory']"
76,Coin pair betting paradox (NOT!),Coin pair betting paradox (NOT!),,"If we throw two fair coins then there are 4 equally probable possibilities: HH, TT, HT, TH. Suppose we can't see the result, but we can check one of those two coins. (doesn't matter which one) Suppose the checked one is H. Then we know that both of them cannot be TT. So there are now only 3 possibilities: HH, HT, TH. ******And here is my mistake****** Therefore, the probability that the other coin in the pair is T (when we know that one of them is H) is 2/3. Actually the probability is 1/2, because by checking one coin at random we remove only half of the cases in which they are different, so we are left with equal probabilities that both are same, and that they are different. So there is no paradox. Similarly, if we get T when we check one of those two coins, then the possibilities are: TT, HT, TH. So, in this case the probability that the other coin in the pair is H is 2/3. Let say that we have N such random pairs, and for each pair we check one coin and than place a bet on the state of the other. We would naturally always choose the opposite value for the other coin because, as demonstrated above, the probability that the other one will be opposite of the one we checked is always 2/3. However, if those N pairs are truly random, then for large N there will be about N/2 pairs with the coins of same value (TT or HH), and about N/2 pairs with the coins of opposite values (TH or HT). And since we are effectively always betting that the coins have the opposite values, then this implies that we would win about half of the time. How can that be? We are constantly betting on the results which have 2/3 probability, but we win only half of the times. What is wrong with my reasoning?","If we throw two fair coins then there are 4 equally probable possibilities: HH, TT, HT, TH. Suppose we can't see the result, but we can check one of those two coins. (doesn't matter which one) Suppose the checked one is H. Then we know that both of them cannot be TT. So there are now only 3 possibilities: HH, HT, TH. ******And here is my mistake****** Therefore, the probability that the other coin in the pair is T (when we know that one of them is H) is 2/3. Actually the probability is 1/2, because by checking one coin at random we remove only half of the cases in which they are different, so we are left with equal probabilities that both are same, and that they are different. So there is no paradox. Similarly, if we get T when we check one of those two coins, then the possibilities are: TT, HT, TH. So, in this case the probability that the other coin in the pair is H is 2/3. Let say that we have N such random pairs, and for each pair we check one coin and than place a bet on the state of the other. We would naturally always choose the opposite value for the other coin because, as demonstrated above, the probability that the other one will be opposite of the one we checked is always 2/3. However, if those N pairs are truly random, then for large N there will be about N/2 pairs with the coins of same value (TT or HH), and about N/2 pairs with the coins of opposite values (TH or HT). And since we are effectively always betting that the coins have the opposite values, then this implies that we would win about half of the time. How can that be? We are constantly betting on the results which have 2/3 probability, but we win only half of the times. What is wrong with my reasoning?",,['probability']
77,Deriving exponential distribution from geometric,Deriving exponential distribution from geometric,,"Let $\lambda$ be the expected number of events in a unit time interval $[s,s+1]$ (events are independent of each other and of the time interval), and $T$ a continuous random variable that represents the time between two events. If we divide the time interval $[0,1]$ into $n$ intervals of length $\displaystyle \frac{1}{n}$, and set the probability of an event occurring in any interval to be  $\displaystyle \frac{\lambda}{n}$, then $T$ can be approximated by a discrete geometric random variable $X$ which represents the number of time intervals of length $\displaystyle \frac{1}{n}$ between two events. Let $t\in \mathbb{R}$, then $F_T(t)$ can be approximated by $F_X(nt)$ $$ P(T<t) \approx P(X < tn) $$ Where $P(X<nt)$ is the sum of geometric distributions \begin{align} P(X<nt) &= \sum_{k=1}^{\lfloor{t} n\rfloor} P(X=k)  \\ &= \sum_{k=1}^{\lfloor{t} n\rfloor} \left(1 - \frac{\lambda}{n}\right)^{k-1}\left( \frac{\lambda}{n} \right)  \\ &= \frac{\lambda}{n} \sum_{i=0}^{\lfloor{t} n\rfloor -1} \left(1 - \frac{\lambda}{n}\right)^i \\ &= \frac{\lambda}{n} \left( \frac{1 - (1 - \frac{\lambda}{n})^{\lfloor{t}n\rfloor }}{\lambda /n} \right) \underset{n \to \infty}{\longrightarrow} 1 - e^{-\lambda t }  \end{align} But how to justify $$ \lim_{n \to \infty} \left( 1 - \frac{\lambda}{n} \right)^{\lfloor{t}n\rfloor } = e^{-\lambda t} $$ How can I get rid of the floor function, in a formal way?","Let $\lambda$ be the expected number of events in a unit time interval $[s,s+1]$ (events are independent of each other and of the time interval), and $T$ a continuous random variable that represents the time between two events. If we divide the time interval $[0,1]$ into $n$ intervals of length $\displaystyle \frac{1}{n}$, and set the probability of an event occurring in any interval to be  $\displaystyle \frac{\lambda}{n}$, then $T$ can be approximated by a discrete geometric random variable $X$ which represents the number of time intervals of length $\displaystyle \frac{1}{n}$ between two events. Let $t\in \mathbb{R}$, then $F_T(t)$ can be approximated by $F_X(nt)$ $$ P(T<t) \approx P(X < tn) $$ Where $P(X<nt)$ is the sum of geometric distributions \begin{align} P(X<nt) &= \sum_{k=1}^{\lfloor{t} n\rfloor} P(X=k)  \\ &= \sum_{k=1}^{\lfloor{t} n\rfloor} \left(1 - \frac{\lambda}{n}\right)^{k-1}\left( \frac{\lambda}{n} \right)  \\ &= \frac{\lambda}{n} \sum_{i=0}^{\lfloor{t} n\rfloor -1} \left(1 - \frac{\lambda}{n}\right)^i \\ &= \frac{\lambda}{n} \left( \frac{1 - (1 - \frac{\lambda}{n})^{\lfloor{t}n\rfloor }}{\lambda /n} \right) \underset{n \to \infty}{\longrightarrow} 1 - e^{-\lambda t }  \end{align} But how to justify $$ \lim_{n \to \infty} \left( 1 - \frac{\lambda}{n} \right)^{\lfloor{t}n\rfloor } = e^{-\lambda t} $$ How can I get rid of the floor function, in a formal way?",,"['probability', 'probability-distributions', 'random-variables']"
78,Proving that three events are mutually independent,Proving that three events are mutually independent,,"Suppose that: the events $A$ and $B\cap C$ are independent. the events $B$ and $A\cap C$ are independent. the events $C$ and $A\cap B$ are independent. the events $A$ and $B\cup C$ are independent. $P(A),P(B),P(C)$ are nonzero. Prove that $A,B,C$ are mutually independent. I've noticed that $P(A\cap B \cap C)=P(A)P(B\cap C)=P(B)P(A\cap C)=P(C)P(A\cap B)$ . What then? I'm new to probability, and I may be missing some standard trick...","Suppose that: the events and are independent. the events and are independent. the events and are independent. the events and are independent. are nonzero. Prove that are mutually independent. I've noticed that . What then? I'm new to probability, and I may be missing some standard trick...","A B\cap C B A\cap C C A\cap B A B\cup C P(A),P(B),P(C) A,B,C P(A\cap B \cap C)=P(A)P(B\cap C)=P(B)P(A\cap C)=P(C)P(A\cap B)","['probability', 'probability-theory']"
79,Filtration from a Brownian Motion,Filtration from a Brownian Motion,,"The textbook I am reading defines the filtration induced from a Brownian Motion as follows. Let $\{B(t): t \geq 0\}$ be a Brownian Motion defined on some probability space, then we can define a filtration $(\mathcal F^0(t): t\geq0)$ by letting $$ \mathcal F^0(t) := \sigma(B(s): 0\leq s\leq t)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  (*) $$ be the $\sigma$-algebra generated by the random variables $B(s)$ for $0 \leq s\leq t$. My question is whether I can understand the above definition $(*)$ as follows. \begin{equation} \mathcal F^0(t) := \sigma(B(s): 0\leq s\leq t) = \sigma\left(\cup_{0\leq s\leq t} \sigma(B(s))\right). \end{equation} Thank you!","The textbook I am reading defines the filtration induced from a Brownian Motion as follows. Let $\{B(t): t \geq 0\}$ be a Brownian Motion defined on some probability space, then we can define a filtration $(\mathcal F^0(t): t\geq0)$ by letting $$ \mathcal F^0(t) := \sigma(B(s): 0\leq s\leq t)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  (*) $$ be the $\sigma$-algebra generated by the random variables $B(s)$ for $0 \leq s\leq t$. My question is whether I can understand the above definition $(*)$ as follows. \begin{equation} \mathcal F^0(t) := \sigma(B(s): 0\leq s\leq t) = \sigma\left(\cup_{0\leq s\leq t} \sigma(B(s))\right). \end{equation} Thank you!",,"['probability', 'measure-theory', 'probability-theory', 'self-learning', 'brownian-motion']"
80,P(X > a) > P(Y>a) -- does it imply P(X>Y) > 1/2?,P(X > a) > P(Y>a) -- does it imply P(X>Y) > 1/2?,,Given some real number $a$ can anyone prove that if $$ P(X > a) > P(Y > a) $$ is true then $$ P(X > Y) > \frac12 $$ is also true.,Given some real number $a$ can anyone prove that if $$ P(X > a) > P(Y > a) $$ is true then $$ P(X > Y) > \frac12 $$ is also true.,,['probability']
81,Help with conditional expectation,Help with conditional expectation,,"I need help finding a conditional expectation: Let $X$ be a $(0,1)$ uniform random variable i.e. $\mathbb{P}(X \in A)=\lambda((0,1)\cap A)$ where $\lambda$ is the Lebuesgue measure.  We define the random variables $$X_n = \frac{\left\lfloor10^nX \right\rfloor}{10^n}$$ and we need to find $$\mathbb{E}(h(X_{n+1})|X_n) \text{ and }\mathbb{E}(h(X)|X_n)$$ where $h\colon [0,1]\to \mathbb{R}$ is some bounded measurable function. I noticed that $X_n$ has only $n$ decimals of $X$ hence $\sigma(X_n) \subseteq \sigma(X_{n+1})$ and that $X_n \to X$ a.s, but I don't know if this is of any help. Any hint, reference or solution will be appreciated :)!","I need help finding a conditional expectation: Let $X$ be a $(0,1)$ uniform random variable i.e. $\mathbb{P}(X \in A)=\lambda((0,1)\cap A)$ where $\lambda$ is the Lebuesgue measure.  We define the random variables $$X_n = \frac{\left\lfloor10^nX \right\rfloor}{10^n}$$ and we need to find $$\mathbb{E}(h(X_{n+1})|X_n) \text{ and }\mathbb{E}(h(X)|X_n)$$ where $h\colon [0,1]\to \mathbb{R}$ is some bounded measurable function. I noticed that $X_n$ has only $n$ decimals of $X$ hence $\sigma(X_n) \subseteq \sigma(X_{n+1})$ and that $X_n \to X$ a.s, but I don't know if this is of any help. Any hint, reference or solution will be appreciated :)!",,"['probability', 'measure-theory', 'conditional-probability', 'uniform-distribution']"
82,Simple counting problem,Simple counting problem,,"Suppose that you have a box with $n$ balls, from the $n$ balls $k$ are white and $n-k$ are black. Now, sequentially you draw (without replacement) the $n$ balls in groups of $m$ (a natural number that divides $n$). My question is, what is the probability that in every one of the $n/m$ draws there is at least one white ball? A first naive idea that I explored is to think that we have $m$ urns and place one white ball in each urn, then count all the possible ways of drawing $n-m$ balls out of which $k-m$ are white and multiply this number by the positions in which we can place the white ball that is already in the urn within the sequence: $$ \frac{m^{n/m}{n-m\choose k-m}}{n \choose k} $$ However the above formula is obviously overcounting some sequences.","Suppose that you have a box with $n$ balls, from the $n$ balls $k$ are white and $n-k$ are black. Now, sequentially you draw (without replacement) the $n$ balls in groups of $m$ (a natural number that divides $n$). My question is, what is the probability that in every one of the $n/m$ draws there is at least one white ball? A first naive idea that I explored is to think that we have $m$ urns and place one white ball in each urn, then count all the possible ways of drawing $n-m$ balls out of which $k-m$ are white and multiply this number by the positions in which we can place the white ball that is already in the urn within the sequence: $$ \frac{m^{n/m}{n-m\choose k-m}}{n \choose k} $$ However the above formula is obviously overcounting some sequences.",,"['probability', 'combinatorics']"
83,weak convergence of probability measures and unbounded functions with bounded expectation,weak convergence of probability measures and unbounded functions with bounded expectation,,"Assume that $\mu^n$ are probability measures on $R$ that convergence weakly(-*) to $\mu$, i.e for all $f \in C_b (R)$ (bounded and continuous), we have that $\int f(x) \mu^n(dx) \rightarrow \int f(x) \mu(dx)$. Assume that $g \in C(R)$ is an unbounded function (for example $g(x)=x$) but assume that the integral of $\mu^n$ wrt to $|g|$ is uniformly bounded, i.e. $\sup_n  \int |g(x)| \mu^n(dx) \leq C$ Let us call $g_k(x)$ the function such that $g_k(x)=g(x)$ for $x \in [-k,k]$ and $g_k(x) = g(k)$ for $x>k$ and similar for $x<-k$. Hence $g_k$ is bounded and continuous, hence $\int g_k(x) \mu^n(dx) \rightarrow \int g_k(x) \mu(dx)$ for each $k$. Further we have by dominant converging theorem that for each $n$ we have $\int g_k(x) \mu^n(dx) \rightarrow \int g(x) \mu^n(dx)$ Question Does this also imply that $\int g(x) \mu^n(dx) \rightarrow \int g(x) \mu(dx)$ ? Alternative question If thats wrong for general $g$ is it true for the example $g(x)=x$?","Assume that $\mu^n$ are probability measures on $R$ that convergence weakly(-*) to $\mu$, i.e for all $f \in C_b (R)$ (bounded and continuous), we have that $\int f(x) \mu^n(dx) \rightarrow \int f(x) \mu(dx)$. Assume that $g \in C(R)$ is an unbounded function (for example $g(x)=x$) but assume that the integral of $\mu^n$ wrt to $|g|$ is uniformly bounded, i.e. $\sup_n  \int |g(x)| \mu^n(dx) \leq C$ Let us call $g_k(x)$ the function such that $g_k(x)=g(x)$ for $x \in [-k,k]$ and $g_k(x) = g(k)$ for $x>k$ and similar for $x<-k$. Hence $g_k$ is bounded and continuous, hence $\int g_k(x) \mu^n(dx) \rightarrow \int g_k(x) \mu(dx)$ for each $k$. Further we have by dominant converging theorem that for each $n$ we have $\int g_k(x) \mu^n(dx) \rightarrow \int g(x) \mu^n(dx)$ Question Does this also imply that $\int g(x) \mu^n(dx) \rightarrow \int g(x) \mu(dx)$ ? Alternative question If thats wrong for general $g$ is it true for the example $g(x)=x$?",,"['probability', 'functional-analysis', 'convergence-divergence', 'weak-convergence']"
84,What is the expected number of times to see k consecutive heads in n coin tosses?,What is the expected number of times to see k consecutive heads in n coin tosses?,,"For example, if k = 2, and you have the sequence HHH, then you've seen k consecutive heads twice.","For example, if k = 2, and you have the sequence HHH, then you've seen k consecutive heads twice.",,['probability']
85,Betting: Gambler's Fallacy vs. Law of Large Numbers,Betting: Gambler's Fallacy vs. Law of Large Numbers,,"I know this has been asked before, but I think not in this exact way, so here goes: Suppose you're going to bet on the flip of a coin. Your bet is always ""HEADS"", but the amount of your bet may vary, from 1 dollar to 100 dollars. You have deep pockets, so you can bet on thousands of flips. The first 99 flips were heads. I know that the probability of the coin coming up heads is 0.5, but the probability of the flipper flipping 100 in a row is 1/2^100. Assuming you can make dozens, or hundreds of bets, shouldn't you be betting more on heads at this point? Considering that head/tails average will approach 0.5 for large n, wouldn't it be reasonable to start betting 2 dollars instead of 1 dollar on heads? You're not assuming heads is ""due"", but at some point, with a fair coin, the probability of H/T can be expected to average out. To make this more obvious, suppose the first 99,999 flips have been tails, and the coin is fair. The probability of 100,000 tails is the same as 99,999 tails + 1 heads: 1/2^100000, but if the law of large numbers is correct there must be a time at which it's smarter to bet 2 dollars on heads than 1 dollar on heads. If the wager should be different, is there a way to tell how much larger or smaller the wager should be? I know that the law of large numbers speaks more to the dilution of a run in the overall account, but it would seem that when you're generating a large data set, that you should start regressing to the mean at some point. I've read a little about Bayesian analysis, and I naively assumed that the conditional probability of heads after a run of 99,999 tails should be higher than 0.5. I'm sure I'm wrong, but I need it explained, I guess.","I know this has been asked before, but I think not in this exact way, so here goes: Suppose you're going to bet on the flip of a coin. Your bet is always ""HEADS"", but the amount of your bet may vary, from 1 dollar to 100 dollars. You have deep pockets, so you can bet on thousands of flips. The first 99 flips were heads. I know that the probability of the coin coming up heads is 0.5, but the probability of the flipper flipping 100 in a row is 1/2^100. Assuming you can make dozens, or hundreds of bets, shouldn't you be betting more on heads at this point? Considering that head/tails average will approach 0.5 for large n, wouldn't it be reasonable to start betting 2 dollars instead of 1 dollar on heads? You're not assuming heads is ""due"", but at some point, with a fair coin, the probability of H/T can be expected to average out. To make this more obvious, suppose the first 99,999 flips have been tails, and the coin is fair. The probability of 100,000 tails is the same as 99,999 tails + 1 heads: 1/2^100000, but if the law of large numbers is correct there must be a time at which it's smarter to bet 2 dollars on heads than 1 dollar on heads. If the wager should be different, is there a way to tell how much larger or smaller the wager should be? I know that the law of large numbers speaks more to the dilution of a run in the overall account, but it would seem that when you're generating a large data set, that you should start regressing to the mean at some point. I've read a little about Bayesian analysis, and I naively assumed that the conditional probability of heads after a run of 99,999 tails should be higher than 0.5. I'm sure I'm wrong, but I need it explained, I guess.",,"['probability', 'bayesian', 'law-of-large-numbers']"
86,"Probability of drawing all ""socks"" of a given color from a drawer, given certain number of tries","Probability of drawing all ""socks"" of a given color from a drawer, given certain number of tries",,"Let's talk ""socks."" Say I have 7800 socks in a drawer (it's a big drawer), 800 of which are red and 7000 of which are black. If I randomly pull 1300 socks from the drawer, what is the probability that I will draw EVERY ONE of the 800 red socks? I realize there are a number of similar threads, and apologize if this is repetitive -- I have searched and failed to find a situation sufficiently similar to allow me to work through this on my own. Many thanks for any assistance!","Let's talk ""socks."" Say I have 7800 socks in a drawer (it's a big drawer), 800 of which are red and 7000 of which are black. If I randomly pull 1300 socks from the drawer, what is the probability that I will draw EVERY ONE of the 800 red socks? I realize there are a number of similar threads, and apologize if this is repetitive -- I have searched and failed to find a situation sufficiently similar to allow me to work through this on my own. Many thanks for any assistance!",,"['probability', 'combinatorics']"
87,Probability Of a 4 sided die,Probability Of a 4 sided die,,"A fair $4$-sided die is rolled twice and we assume that all sixteen possible outcomes are equally likely. Let $X$ and $Y$ be the result of the $1^{\large\text{st}}$ and the $2^{\large\text{nd}}$ roll, respectively. We wish to determine the conditional probability $P(A|B)$ where $A = \max(X,Y)=m$ and $B= \min(X,Y)=2,\quad m\in\{1,2,3,4\}$. Can somebody first explain me this question and then explain its answer. I'm having trouble in approaching it.","A fair $4$-sided die is rolled twice and we assume that all sixteen possible outcomes are equally likely. Let $X$ and $Y$ be the result of the $1^{\large\text{st}}$ and the $2^{\large\text{nd}}$ roll, respectively. We wish to determine the conditional probability $P(A|B)$ where $A = \max(X,Y)=m$ and $B= \min(X,Y)=2,\quad m\in\{1,2,3,4\}$. Can somebody first explain me this question and then explain its answer. I'm having trouble in approaching it.",,['probability']
88,This is question 3.3 from Alan Karr's Probability,This is question 3.3 from Alan Karr's Probability,,"What is the minimum number of points a sample space must contain in order that there exist $n$ independent events none of which has probability zero or one? I'm thinking the answer is $2^n$, but this is just from checking by hand for the values $n=2$ and $n=3$.  I thought maybe a proof by induction would be appropriate, but didn't make it terribly far with it. I'm merely studying probability because I want to be better at it, and this seems to be a pretty classic problem. So it seemed like a good problem to understand.","What is the minimum number of points a sample space must contain in order that there exist $n$ independent events none of which has probability zero or one? I'm thinking the answer is $2^n$, but this is just from checking by hand for the values $n=2$ and $n=3$.  I thought maybe a proof by induction would be appropriate, but didn't make it terribly far with it. I'm merely studying probability because I want to be better at it, and this seems to be a pretty classic problem. So it seemed like a good problem to understand.",,['probability']
89,How does one 'correct' a table that doesn't add up to $100\%$?,How does one 'correct' a table that doesn't add up to ?,100\%,"I have a table consisting of a number of whole percentages $x_i$ between $0\%$ and $100\%$. However, they don't add up to $100\%$ (rather they add up to $101\%$). But they 'should'. Assuming that any given percentage $x_i\%$ is rounded from some precise (unrounded) $y_i\%$ which is really uniformly distributed according to $y_i\sim \text{UNIF}(\max{(x_i-0.5\%,0\%)},\min(x_i+0.5\%,100\%))$, what is the best way to go about computing some estimates for unrounded $y_i$s, i.e. $\text{E}(y_i)$? I prefer expectation (over MLE). NB: The table does contain some $x_i=0\%$ entries. NB 2: The $\text{E}(y_i)$s that I am looking for are reals, not integers. NB 3: Simply scaling doesn't work. For example take $10\%$, $80\%$ and $11\%$. Total $101\%$. Just scaling those down would obviously yield $100\%$. But $80\%\cdot \frac{100\%}{101\%}=79.2079\ldots\%$ will now round to $79\%$ instead of $80\%$. So, this cannot be right. NB 4: Distributing the error equally over all entries has a drawback too. If the error would be $−1\%$, some such $\text{E}(y_i)$s (e.g. those belonging to $x_i=0$) could become less than zero . That indicates that that procedure cannot be right either.","I have a table consisting of a number of whole percentages $x_i$ between $0\%$ and $100\%$. However, they don't add up to $100\%$ (rather they add up to $101\%$). But they 'should'. Assuming that any given percentage $x_i\%$ is rounded from some precise (unrounded) $y_i\%$ which is really uniformly distributed according to $y_i\sim \text{UNIF}(\max{(x_i-0.5\%,0\%)},\min(x_i+0.5\%,100\%))$, what is the best way to go about computing some estimates for unrounded $y_i$s, i.e. $\text{E}(y_i)$? I prefer expectation (over MLE). NB: The table does contain some $x_i=0\%$ entries. NB 2: The $\text{E}(y_i)$s that I am looking for are reals, not integers. NB 3: Simply scaling doesn't work. For example take $10\%$, $80\%$ and $11\%$. Total $101\%$. Just scaling those down would obviously yield $100\%$. But $80\%\cdot \frac{100\%}{101\%}=79.2079\ldots\%$ will now round to $79\%$ instead of $80\%$. So, this cannot be right. NB 4: Distributing the error equally over all entries has a drawback too. If the error would be $−1\%$, some such $\text{E}(y_i)$s (e.g. those belonging to $x_i=0$) could become less than zero . That indicates that that procedure cannot be right either.",,"['probability', 'statistics', 'probability-distributions']"
90,In probability notation: what does a tilde over a letter mean?,In probability notation: what does a tilde over a letter mean?,,I am reading this paper. In section 1.1 he says: What do the tildes above the letters mean? How can I translate these two sentences into ordinary English?,I am reading this paper. In section 1.1 he says: What do the tildes above the letters mean? How can I translate these two sentences into ordinary English?,,"['probability', 'notation']"
91,Fraction Problem. 3rd grader question got parents thinking,Fraction Problem. 3rd grader question got parents thinking,,"So our nine year old son comes home from 3rd grade and tells us an amazing thing happened in school today. He was playing a math game with his friend and they got the same score two times in a row! Here was the game: Deck of 32 cards, each card is blank on front side and has a fraction $\frac{1}{N}$ on the backside, i.e. $\{1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}..., \frac{1}{32}\}$ . No fraction is repeated. Two players, cards are shuffled, deck is divided into half for each player. It's like War .  In every round each player plays his top card (random).  Whichever player has a bigger fraction takes both cards and sets them aside. After 16 rounds players count the cards they won. Whoever has more cards wins the game. Our nine year old thought it was amazing that he and his partner both had 16 cards at the end of the game. The question is, using nothing fancier than algebra, what are the odds that both players end up with the same number of cards after one game (16 hands). The more interesting question is how to explain the answer to a 3rd grader!","So our nine year old son comes home from 3rd grade and tells us an amazing thing happened in school today. He was playing a math game with his friend and they got the same score two times in a row! Here was the game: Deck of 32 cards, each card is blank on front side and has a fraction on the backside, i.e. . No fraction is repeated. Two players, cards are shuffled, deck is divided into half for each player. It's like War .  In every round each player plays his top card (random).  Whichever player has a bigger fraction takes both cards and sets them aside. After 16 rounds players count the cards they won. Whoever has more cards wins the game. Our nine year old thought it was amazing that he and his partner both had 16 cards at the end of the game. The question is, using nothing fancier than algebra, what are the odds that both players end up with the same number of cards after one game (16 hands). The more interesting question is how to explain the answer to a 3rd grader!","\frac{1}{N} \{1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}..., \frac{1}{32}\}","['probability', 'combinatorics', 'normal-distribution']"
92,Take $-\log$ of a $\beta$ distributed R.V.,Take  of a  distributed R.V.,-\log \beta,"$X_1,\dots,X_n \sim \beta(a,1)$ , where $Y = -\log(X)$ Use the transformation formula to calculate the pdf of $Y$ . What named distribution does it have? I am confused what method to use here. A beta does not converge to a normal, so I cannot use the delta method?",", where Use the transformation formula to calculate the pdf of . What named distribution does it have? I am confused what method to use here. A beta does not converge to a normal, so I cannot use the delta method?","X_1,\dots,X_n \sim \beta(a,1) Y = -\log(X) Y","['probability', 'statistics', 'transformation']"
93,Function of a uniformly distributed continuous random variable,Function of a uniformly distributed continuous random variable,,"Basically, I'd like to add $n$ random vectors in a 2 dimensional space of unit length and of angle $\theta$ relative to a global axis. The probability density function of the angle $\theta$ is a uniform distribution over the interval $[0..2\pi)$. I've come to the equation to find the following vector sum for $n$ vectors: $$ d=\sqrt{(\sum_{i=1}^{n}{\sin(\theta_i)})^2+(\sum_{i=1}^{n}\cos(\theta_i))^2} $$ Where might I go from here to find the probability distribution of $d$? I'm mostly curious about probability distribution of $d$ in the case where $n \rightarrow \infty$. Thanks!","Basically, I'd like to add $n$ random vectors in a 2 dimensional space of unit length and of angle $\theta$ relative to a global axis. The probability density function of the angle $\theta$ is a uniform distribution over the interval $[0..2\pi)$. I've come to the equation to find the following vector sum for $n$ vectors: $$ d=\sqrt{(\sum_{i=1}^{n}{\sin(\theta_i)})^2+(\sum_{i=1}^{n}\cos(\theta_i))^2} $$ Where might I go from here to find the probability distribution of $d$? I'm mostly curious about probability distribution of $d$ in the case where $n \rightarrow \infty$. Thanks!",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'random-walk']"
94,Sum of a random number of independent random variables,Sum of a random number of independent random variables,,"Consider the sum $Y = X_1 + \cdots + X_N$ where $N$ is a random variable that takes nonnegative integer values, and $X_1, X_2, \cdots$, are identically distributed random variables. Assume that $N, X_1, X_2, \cdots$ are independent. Find the moment generating function for $Y$, $M_Y(s) = \displaystyle \mathbb{E}[e^{sY}]$. Working: Using the law of total expectation we have: $\displaystyle \mathbb{E}[e^{sY}] = \mathbb{E}[\mathbb{E}[e^{sY}|N]]$ $\mathbb{E}[e^{sY}|N=n] = \mathbb{E}[e^{sX_1} \cdots e^{sX_N}|N=n] = \mathbb{E}[e^{sX_1} \cdots e^{sX_n}] = \mathbb{E}[e^{sX_1}]\cdots \mathbb{E}[e^{sX_n}] = [M_X(s)]^n$ where $M_X(s)$ denotes the common moment generating function of each of the $X_i$'s. Thus, $M_Y(s) = \mathbb{E}[\mathbb{E}[e^{sY}|N]] = \mathbb{E}[[M_X(s)]^N]$. Query: My book says to actually compute $M_Y(s) = \mathbb{E}[[M_X(s)]^N]$, one can just simply start with the transform $M_N(s) = \mathbb{E}[e^{sN}]$ and then replace each instance of $e^s$ with $M_X(s)$. They give the following example (amongst others): What I don't understand is that how can we simply just replace $e^s$ with $M_X(s)$? Because in general, if we know the expression for, say, $\mathbb{E}[e^{sQ}]$ (for some generic random variable $Q$), then to find $\mathbb{E}[g(s)^Q]$ (for some generic function $g(s)$), we CANNOT just simply replace every instance of $e^s$ (in the expression for $\mathbb{E}[e^{sQ}]$) with $g(s)$. How come my book says we can?","Consider the sum $Y = X_1 + \cdots + X_N$ where $N$ is a random variable that takes nonnegative integer values, and $X_1, X_2, \cdots$, are identically distributed random variables. Assume that $N, X_1, X_2, \cdots$ are independent. Find the moment generating function for $Y$, $M_Y(s) = \displaystyle \mathbb{E}[e^{sY}]$. Working: Using the law of total expectation we have: $\displaystyle \mathbb{E}[e^{sY}] = \mathbb{E}[\mathbb{E}[e^{sY}|N]]$ $\mathbb{E}[e^{sY}|N=n] = \mathbb{E}[e^{sX_1} \cdots e^{sX_N}|N=n] = \mathbb{E}[e^{sX_1} \cdots e^{sX_n}] = \mathbb{E}[e^{sX_1}]\cdots \mathbb{E}[e^{sX_n}] = [M_X(s)]^n$ where $M_X(s)$ denotes the common moment generating function of each of the $X_i$'s. Thus, $M_Y(s) = \mathbb{E}[\mathbb{E}[e^{sY}|N]] = \mathbb{E}[[M_X(s)]^N]$. Query: My book says to actually compute $M_Y(s) = \mathbb{E}[[M_X(s)]^N]$, one can just simply start with the transform $M_N(s) = \mathbb{E}[e^{sN}]$ and then replace each instance of $e^s$ with $M_X(s)$. They give the following example (amongst others): What I don't understand is that how can we simply just replace $e^s$ with $M_X(s)$? Because in general, if we know the expression for, say, $\mathbb{E}[e^{sQ}]$ (for some generic random variable $Q$), then to find $\mathbb{E}[g(s)^Q]$ (for some generic function $g(s)$), we CANNOT just simply replace every instance of $e^s$ (in the expression for $\mathbb{E}[e^{sQ}]$) with $g(s)$. How come my book says we can?",,"['probability', 'moment-generating-functions']"
95,probability of the sum of i.i.d. RV with uniform distribution being $>x$,probability of the sum of i.i.d. RV with uniform distribution being,>x,"I am solving a question for applied stochastic processes homework and I am stuck on this part: Let $X_1,X_2,\cdots, X_n$ be independent identically distributed random variables with uniform distribution on $[0,1]$. Let $0<x<1$.  I need to find $$\mathbb{P}(X_1+\cdots+X_n<x \mid X_1+\cdots +X_{n-1}<x).$$ I think that the answer should be $\mathbb{P}(X_1+\cdots+X_n<x \mid X_1+\cdots +X_{n-1}<x)=\frac{x}{n}$,  for reasons of symmetry , since we have $n$ RV then each of them in average should be less then $\frac{x}{n}$  so that the total sum is less then $x$. Is my guess correct? And how can I state it in more mathematical basis?","I am solving a question for applied stochastic processes homework and I am stuck on this part: Let $X_1,X_2,\cdots, X_n$ be independent identically distributed random variables with uniform distribution on $[0,1]$. Let $0<x<1$.  I need to find $$\mathbb{P}(X_1+\cdots+X_n<x \mid X_1+\cdots +X_{n-1}<x).$$ I think that the answer should be $\mathbb{P}(X_1+\cdots+X_n<x \mid X_1+\cdots +X_{n-1}<x)=\frac{x}{n}$,  for reasons of symmetry , since we have $n$ RV then each of them in average should be less then $\frac{x}{n}$  so that the total sum is less then $x$. Is my guess correct? And how can I state it in more mathematical basis?",,"['probability', 'random-variables', 'conditional-probability']"
96,Prove that $h< \frac{(k+l)^{k+l}}{(k^{k}l^{l})}$.,Prove that .,h< \frac{(k+l)^{k+l}}{(k^{k}l^{l})},"Let $\left \{ \left ( A_{i},B_{i} \right ),1\leq i\leq h \right \}$ be a family of pairs of subsets of the set of integers such that $\left | A_{i} \right |=k$ for all $ i$ and $\left | B_{i} \right |=l$ for all $i$, $A_{i}\cap B_{i}=\emptyset$ and $(A_{i}\cap B_{j})\cup (A_{j}\cap B_{i})\neq \emptyset$ for all $i\neq j$ . Prove that $h< \frac{(k+l)^{k+l}}{(k^{k}l^{l})}$. this is problem 7 of chapter one from alon and spencer The Probabilistic Method. this is very near to the concepts of $(k,l)-system$ which is discussed there. I want to call an event which its probability will be $\frac{(k^{k}l^{l})}{(k+l)^{k+l}}$.this events must be disjoint.then I want to say that the number of these events are $h$.then from the rule of probability we have $h\frac{(k^{k}l^{l})}{(k+l)^{k+l}}<1$ and it is done.it was the basic method. now I don't know what is that  specific event that make every thing done.I have thought about taking red and blue balls from a box because of similarity to $\frac{k}{k+l}$ and $\frac{l}{k+l}$ which they happen $k$ and $l$ times with putting the ball in the box after taking it,but it seems not to work,so please help me,thank you very much.","Let $\left \{ \left ( A_{i},B_{i} \right ),1\leq i\leq h \right \}$ be a family of pairs of subsets of the set of integers such that $\left | A_{i} \right |=k$ for all $ i$ and $\left | B_{i} \right |=l$ for all $i$, $A_{i}\cap B_{i}=\emptyset$ and $(A_{i}\cap B_{j})\cup (A_{j}\cap B_{i})\neq \emptyset$ for all $i\neq j$ . Prove that $h< \frac{(k+l)^{k+l}}{(k^{k}l^{l})}$. this is problem 7 of chapter one from alon and spencer The Probabilistic Method. this is very near to the concepts of $(k,l)-system$ which is discussed there. I want to call an event which its probability will be $\frac{(k^{k}l^{l})}{(k+l)^{k+l}}$.this events must be disjoint.then I want to say that the number of these events are $h$.then from the rule of probability we have $h\frac{(k^{k}l^{l})}{(k+l)^{k+l}}<1$ and it is done.it was the basic method. now I don't know what is that  specific event that make every thing done.I have thought about taking red and blue balls from a box because of similarity to $\frac{k}{k+l}$ and $\frac{l}{k+l}$ which they happen $k$ and $l$ times with putting the ball in the box after taking it,but it seems not to work,so please help me,thank you very much.",,"['probability', 'combinatorics', 'discrete-mathematics', 'probabilistic-method']"
97,What keeps measure-preserving transformations from concentrating in a particular portion of a probability space?,What keeps measure-preserving transformations from concentrating in a particular portion of a probability space?,,"I'm trying to show that for an event A with positive probability there is some n bounded by 1/P(A) such that $P(A \cap$ T$^{-n}A) > 0$, where T is a probability-preserving transformation. I'm getting stuck because I'm not seeing what's keeping all the $T^{-k}A$ from clustering around a particular portion of the sample space. Is there anything we can say about $T^{-j}A \cap T^{-k}A$? I get where n comes from: since $0 < P(A) < 1$, there's some $n$ such that $P(A) < 1/n$. This flows nicely with the relations $1 \ge nP(A) = \sum_{k=1}^n P(A) = \sum_{k=1}^n P(T^{-k}A) \ge P(\bigcup_{k=1}^n T^{-k} A)$. My idea is to assume for each $k \le n, P(A \cap T^{-k} A) = 0$ and derive some contradiction, but if $P(T^{-j}A \cap T^{-k}A)$ is big enough I can't be sure that the orbits cover a sufficient portion of the sample space.","I'm trying to show that for an event A with positive probability there is some n bounded by 1/P(A) such that $P(A \cap$ T$^{-n}A) > 0$, where T is a probability-preserving transformation. I'm getting stuck because I'm not seeing what's keeping all the $T^{-k}A$ from clustering around a particular portion of the sample space. Is there anything we can say about $T^{-j}A \cap T^{-k}A$? I get where n comes from: since $0 < P(A) < 1$, there's some $n$ such that $P(A) < 1/n$. This flows nicely with the relations $1 \ge nP(A) = \sum_{k=1}^n P(A) = \sum_{k=1}^n P(T^{-k}A) \ge P(\bigcup_{k=1}^n T^{-k} A)$. My idea is to assume for each $k \le n, P(A \cap T^{-k} A) = 0$ and derive some contradiction, but if $P(T^{-j}A \cap T^{-k}A)$ is big enough I can't be sure that the orbits cover a sufficient portion of the sample space.",,"['probability', 'measure-theory', 'ergodic-theory']"
98,Show that $\frac{1}{n}X_n\to 0$ a.s.,Show that  a.s.,\frac{1}{n}X_n\to 0,"Show that for any sequence $(X_n)_{n\in\mathbb{N}}\in (L_{\mathbb{P}}^2)^{\mathbb{N}}$ of identically distributed random variables it is $\frac{1}{n}X_n\to 0\text{ a.s.}$. The professor suggested to use Borel-Cantelli . I define $$ E:=\left\{\omega\in\Omega: \lim_{n\to\infty}\frac{1}{n}X_n(\omega)\neq 0\right\} $$ and have to show that $\mathbb{P}(E)=0$. In order to use Borel-Cantelli, my idea is to re-write $E$ for any $\varepsilon > 0$ as $$ E=\left\{\omega\in\Omega: \frac{1}{n}\lvert X_n(\omega)\rvert > \varepsilon~\text{ for }\infty-\text{ many } n\right\}=\limsup_n A_n. $$ with $$ A_n:=\left\{\frac{1}{n}\lvert X_n\rvert > \varepsilon\right\}. $$ I want to show that $\sum_{n\geq 1}\mathbb{P}(A_n)<\infty$. Then it would follow that $\mathbb{P}(\limsup_n A_n)=\mathbb{P}(E)=0$. But I do not know if this is the right strategy and if yes, how to show that $\sum_{n\geq 1}\mathbb{P}(A_n)<\infty$, especially how to use that $X_n\in L_{\mathbb{P}}^2$ and that the $X_n$ are identically distributed.","Show that for any sequence $(X_n)_{n\in\mathbb{N}}\in (L_{\mathbb{P}}^2)^{\mathbb{N}}$ of identically distributed random variables it is $\frac{1}{n}X_n\to 0\text{ a.s.}$. The professor suggested to use Borel-Cantelli . I define $$ E:=\left\{\omega\in\Omega: \lim_{n\to\infty}\frac{1}{n}X_n(\omega)\neq 0\right\} $$ and have to show that $\mathbb{P}(E)=0$. In order to use Borel-Cantelli, my idea is to re-write $E$ for any $\varepsilon > 0$ as $$ E=\left\{\omega\in\Omega: \frac{1}{n}\lvert X_n(\omega)\rvert > \varepsilon~\text{ for }\infty-\text{ many } n\right\}=\limsup_n A_n. $$ with $$ A_n:=\left\{\frac{1}{n}\lvert X_n\rvert > \varepsilon\right\}. $$ I want to show that $\sum_{n\geq 1}\mathbb{P}(A_n)<\infty$. Then it would follow that $\mathbb{P}(\limsup_n A_n)=\mathbb{P}(E)=0$. But I do not know if this is the right strategy and if yes, how to show that $\sum_{n\geq 1}\mathbb{P}(A_n)<\infty$, especially how to use that $X_n\in L_{\mathbb{P}}^2$ and that the $X_n$ are identically distributed.",,"['probability', 'measure-theory', 'probability-theory', 'proof-verification']"
99,What is the probability of rolling $n$ dice until each side appears at least once?,What is the probability of rolling  dice until each side appears at least once?,n,"We roll a die until each side appears at least once, then we stop. What is the probability of rolling exactly $n$ dice? I guess the answer is  $$6-6\left(\dfrac{5}{6}\right)^n\;,$$ but this may be wrong. In trying to solve this problem, I read this paper , but I couldn't solve the problem.","We roll a die until each side appears at least once, then we stop. What is the probability of rolling exactly $n$ dice? I guess the answer is  $$6-6\left(\dfrac{5}{6}\right)^n\;,$$ but this may be wrong. In trying to solve this problem, I read this paper , but I couldn't solve the problem.",,['probability']
