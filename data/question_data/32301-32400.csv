,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Why this random variable is uniformly distributed?,Why this random variable is uniformly distributed?,,"Here is an exercise. Suppose that people arrive at a bus stop in accordance with a Poisson   process with rate $\lambda$. The bus departs at time $t$. Let $X$   denote the total amount of waiting time of all those who get on the   bus at time $t$. Let $N(t)$ denote the number of arrivals by time $t$. Now we want to calculate $E[X\;|\;N(t)]$. The solution says that the waiting time of each person, $T$, is uniformly distribute in $(0,t)$. So $E[X\;|\;N(t)=n]=n\int_0^t(t-s)\frac{1}{t}ds$. My question is, why $T$ is uniformly distribute? If people arrivals obeying Poisson process, shouldn't $T$ obeying exponential distribute with parameter $\lambda$?","Here is an exercise. Suppose that people arrive at a bus stop in accordance with a Poisson   process with rate $\lambda$. The bus departs at time $t$. Let $X$   denote the total amount of waiting time of all those who get on the   bus at time $t$. Let $N(t)$ denote the number of arrivals by time $t$. Now we want to calculate $E[X\;|\;N(t)]$. The solution says that the waiting time of each person, $T$, is uniformly distribute in $(0,t)$. So $E[X\;|\;N(t)=n]=n\int_0^t(t-s)\frac{1}{t}ds$. My question is, why $T$ is uniformly distribute? If people arrivals obeying Poisson process, shouldn't $T$ obeying exponential distribute with parameter $\lambda$?",,"['probability', 'probability-theory']"
1,Expected number of trials to see x unique values out of N total values,Expected number of trials to see x unique values out of N total values,,"I'm new to these forums so please forgive me if my question is poorly worded/phrased. Suppose I have a list of N unique integers that I'm drawing from, one at a time, with replacement. Let x be the number of non-repeated integers I've drawn thus far (or, put another way, the number of trials thus far whose outcome was distinct from every trial before it). Finally, let n be the amount of non-repeated integers I'm seeking, n being (obviously) between [0, N ]. How many trials will it take, on average, before x=n ? For example, take a deck of cards. If I'm drawing with replacement how many trials will it take until I've seen 26 different cards.","I'm new to these forums so please forgive me if my question is poorly worded/phrased. Suppose I have a list of N unique integers that I'm drawing from, one at a time, with replacement. Let x be the number of non-repeated integers I've drawn thus far (or, put another way, the number of trials thus far whose outcome was distinct from every trial before it). Finally, let n be the amount of non-repeated integers I'm seeking, n being (obviously) between [0, N ]. How many trials will it take, on average, before x=n ? For example, take a deck of cards. If I'm drawing with replacement how many trials will it take until I've seen 26 different cards.",,['probability']
2,Derangements with repetitive numbers,Derangements with repetitive numbers,,I have a very simple problem. Lets assume that I have a well shuffled deck of 52 cards. I start drawing the top card always and when the card matches its rank I lose. J=11 Q=12 K=13. If there were only 13 cards I could easily use the $\ \frac{!n}{n!}$ for derangements in order to solve this. The problem is that there are 52 cards so when I pass 13 I start from 1 again so I don't know what is the probability to win. Example of the game 1st card: 4 - Continue 2nd Card: A - continue 3rd Card: K - Continue 4th Card: K - Continue 5th Card: 6 - Continue 6th Card: 9 - Continue 7th Card: 10 - Continue 8th Card: A - Continue 9th Card: J - Continue 10th Card: 3 - Continue 11th Card: 2 - Continue 12th Card: 8 - Continue 13th Card: A - Continue 1st card: 5 - Continue 2nd Card 2 LOSE So actually I have to count from 1 to 13 4 times and if I draw all 52 cards then I win. What's the probability?,I have a very simple problem. Lets assume that I have a well shuffled deck of 52 cards. I start drawing the top card always and when the card matches its rank I lose. J=11 Q=12 K=13. If there were only 13 cards I could easily use the for derangements in order to solve this. The problem is that there are 52 cards so when I pass 13 I start from 1 again so I don't know what is the probability to win. Example of the game 1st card: 4 - Continue 2nd Card: A - continue 3rd Card: K - Continue 4th Card: K - Continue 5th Card: 6 - Continue 6th Card: 9 - Continue 7th Card: 10 - Continue 8th Card: A - Continue 9th Card: J - Continue 10th Card: 3 - Continue 11th Card: 2 - Continue 12th Card: 8 - Continue 13th Card: A - Continue 1st card: 5 - Continue 2nd Card 2 LOSE So actually I have to count from 1 to 13 4 times and if I draw all 52 cards then I win. What's the probability?,\ \frac{!n}{n!},"['probability', 'card-games', 'derangements']"
3,Arcsine law for Brownian motion,Arcsine law for Brownian motion,,"Here is the question: $(B_t,t\ge 0)$ is a standard brwonian motion, starting at $0$.   $S_t=\sup_{0\le s\le t} B_s$. $T=\inf\{t\ge 0: B_t=S_1\}$.   Show that $T$ follows the arcsinus law with density   $g(t)=\frac{1}{\pi\sqrt{t(1-t)}}1_{]0,1[}(t)$. I used Markov property to get the following equality: $P(T<t)=P(\sup_{t<s<1}B_s<S_t)=E(P(\sup_{0<s<1-t}(B_{t+s}-B_t)<S_t-B_t|F_t))=P(\hat{S}_{1-t}<S_t-B_t).$ where $\hat{S}_{1-t}$ is defined for the brownian motion $\hat{B}_s=B_{t+s}-B_t$, which is independant of $F_t$. However the reflexion principle tells us that $S_t-B_t$ has the same law as $S_t$, so we can also write that $P(T<t)=P(\hat{S}_{1-t}<S_t)$. To this point, we can calculate $P(T<t)$ because we know the joint density of $(\hat{S}_{1-t},S_t)$, but this calculation leads to a complicated form of integral and I can not get the density $g$ at the end. Do you know how to get the arcsinus law? Thank you.","Here is the question: $(B_t,t\ge 0)$ is a standard brwonian motion, starting at $0$.   $S_t=\sup_{0\le s\le t} B_s$. $T=\inf\{t\ge 0: B_t=S_1\}$.   Show that $T$ follows the arcsinus law with density   $g(t)=\frac{1}{\pi\sqrt{t(1-t)}}1_{]0,1[}(t)$. I used Markov property to get the following equality: $P(T<t)=P(\sup_{t<s<1}B_s<S_t)=E(P(\sup_{0<s<1-t}(B_{t+s}-B_t)<S_t-B_t|F_t))=P(\hat{S}_{1-t}<S_t-B_t).$ where $\hat{S}_{1-t}$ is defined for the brownian motion $\hat{B}_s=B_{t+s}-B_t$, which is independant of $F_t$. However the reflexion principle tells us that $S_t-B_t$ has the same law as $S_t$, so we can also write that $P(T<t)=P(\hat{S}_{1-t}<S_t)$. To this point, we can calculate $P(T<t)$ because we know the joint density of $(\hat{S}_{1-t},S_t)$, but this calculation leads to a complicated form of integral and I can not get the density $g$ at the end. Do you know how to get the arcsinus law? Thank you.",,"['probability', 'brownian-motion']"
4,Conditional probability given independent random variables,Conditional probability given independent random variables,,"I have a fundamental question regarding conditional probability. Lets say I have $n$ independent random variables $X_1, X_2, \ldots, X_n$. Another random variable, $W$ is conditioned on the conjunction of these random variables: $P(W | X_1, X_2, X_3, \ldots, X_n)$. Given that $X_1, \ldots, X_n$ are independent, is it possible to write $$P(W | X_1, X_2, X_3, \ldots, X_n) =  P(W | X_1) \cdot P(W | X_2) \cdot \cdots \cdot P(W | X_n).$$ Or is the only way to rewrite is the Bayes theorem?","I have a fundamental question regarding conditional probability. Lets say I have $n$ independent random variables $X_1, X_2, \ldots, X_n$. Another random variable, $W$ is conditioned on the conjunction of these random variables: $P(W | X_1, X_2, X_3, \ldots, X_n)$. Given that $X_1, \ldots, X_n$ are independent, is it possible to write $$P(W | X_1, X_2, X_3, \ldots, X_n) =  P(W | X_1) \cdot P(W | X_2) \cdot \cdots \cdot P(W | X_n).$$ Or is the only way to rewrite is the Bayes theorem?",,"['probability', 'random-variables', 'conditional-probability']"
5,Finding probability using moment-generating functions,Finding probability using moment-generating functions,,"I'm working through Schaum's Outline of Probability, Random Variables, and Random Processes , and am stuck on a question about moment-generating functions.  If anyone has the 2nd edition, it is question 4.60, part (b). The question gives the following initial information: $$E[X^k] = 0.8$$ for k = 1, 2, ... The moment-generating function for this is the following: $$0.2 + 0.8\sum_{k=0}^\infty\frac{t^k}{k!} = 0.2 + 0.8e^t$$ The question is asking to find $P(X=0)$ and $P(X=1)$.  The answers are given, $P(X=0)=0.2$ and $P(X=1)=0.8$, but I'm not seeing how the book arrived at these answers. Using the definition of moment-generating functions, I see that the following equation is utilized: $$\sum_{i}e^tx_i*p_X(x_i) = 0.2 + 0.8\sum_{k=0}^\infty\frac{t^k}{k!} = 0.2 + 0.8e^t $$ But I'm not seeing how the $p_X(x_i)$ is extracted from that equation. Any help is greatly appreciated.  Thanks.","I'm working through Schaum's Outline of Probability, Random Variables, and Random Processes , and am stuck on a question about moment-generating functions.  If anyone has the 2nd edition, it is question 4.60, part (b). The question gives the following initial information: $$E[X^k] = 0.8$$ for k = 1, 2, ... The moment-generating function for this is the following: $$0.2 + 0.8\sum_{k=0}^\infty\frac{t^k}{k!} = 0.2 + 0.8e^t$$ The question is asking to find $P(X=0)$ and $P(X=1)$.  The answers are given, $P(X=0)=0.2$ and $P(X=1)=0.8$, but I'm not seeing how the book arrived at these answers. Using the definition of moment-generating functions, I see that the following equation is utilized: $$\sum_{i}e^tx_i*p_X(x_i) = 0.2 + 0.8\sum_{k=0}^\infty\frac{t^k}{k!} = 0.2 + 0.8e^t $$ But I'm not seeing how the $p_X(x_i)$ is extracted from that equation. Any help is greatly appreciated.  Thanks.",,['probability']
6,Statistics: Bertrand's Box Paradox [duplicate],Statistics: Bertrand's Box Paradox [duplicate],,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Probability problem This is the Bertrand's Box Paradox I read about on Wikipedia: Assume there is three boxes: a box containing two gold coins, a box with two silver coins and a box with one of each. After choosing a box at random and withdrawing one coin at random, if that happens to be a gold coin, the probability is actually 66% instead of 50%. And the problem is equivalent to asking the question ""What is the probability that I will pick a box with two coins of the same color?"". No matter how hard I try, I just couldn't comprehend this.. How is the possibility of picking a gold coin the same as the probability of picking a box with two coins of the same color? Does this imply there is a 66% chance of picking a gold coin and a 66% chance of picking a sliver coin? If so, can we just say there is 50% chance of picking either one of them since both stand a 66% chance....?! and suddenly everything makes no sense.. [UPDATES] It is actually the probability of the remaining coin to be gold is 66% but not the probability of obtaining the gold coin is 66%.. I've misread it.... And everything makes sense now :D !","This question already has answers here : Closed 11 years ago . Possible Duplicate: Probability problem This is the Bertrand's Box Paradox I read about on Wikipedia: Assume there is three boxes: a box containing two gold coins, a box with two silver coins and a box with one of each. After choosing a box at random and withdrawing one coin at random, if that happens to be a gold coin, the probability is actually 66% instead of 50%. And the problem is equivalent to asking the question ""What is the probability that I will pick a box with two coins of the same color?"". No matter how hard I try, I just couldn't comprehend this.. How is the possibility of picking a gold coin the same as the probability of picking a box with two coins of the same color? Does this imply there is a 66% chance of picking a gold coin and a 66% chance of picking a sliver coin? If so, can we just say there is 50% chance of picking either one of them since both stand a 66% chance....?! and suddenly everything makes no sense.. [UPDATES] It is actually the probability of the remaining coin to be gold is 66% but not the probability of obtaining the gold coin is 66%.. I've misread it.... And everything makes sense now :D !",,['probability']
7,"In probability, how can a sigma-algebra represent the total information?","In probability, how can a sigma-algebra represent the total information?",,"Why does a sigma-algebra represent the information available at a given time? I understand the idea of filtration and stopping-time, given that each sigma-algebra represent the info we have at a specific time, but why is that? For instance in a game of dice rolls (or anyone you want), what would be total universe and the available information in forms of sigma-algebra, at the n-th turn? thanks","Why does a sigma-algebra represent the information available at a given time? I understand the idea of filtration and stopping-time, given that each sigma-algebra represent the info we have at a specific time, but why is that? For instance in a game of dice rolls (or anyone you want), what would be total universe and the available information in forms of sigma-algebra, at the n-th turn? thanks",,['probability']
8,Coin Toss Probability Question (Feller),Coin Toss Probability Question (Feller),,"I'm working out of Feller's ""Introduction to Probability and its Application (Vol I.)"" textbook and I'm stuck on a coin toss problem. I'll list the full problem and show where I'm having trouble. A coin is tossed until for the first time the same result appears twice in succession. To every possible outcome requiring n tosses attribute probability 1/$2^{n-1}$. Describe the sample space. Find the probability of the following events: a.) the experiment ends before the sixth toss, b.) an even number of tosses is required. Alright so I'm not having any trouble describing the sample space and completing part a. This first part was solved by creating a possibility tree and adding up the probabilities (answer: 15/16). However, I'm stuck on part b and I don't understand how the 1/$2^{n-1}$ given in the problem is to be interpreted because if you toss the coin twice it makes it seem like HH, and TT each have a probability of 1/2 which is not the case. The sample space of two tosses would be {HH, HT, TH, TT} and each would have a probability of 1/4 and following this logic I arrived at 15/16 so I believe this is the correct thinking which makes the problem even more confusing. The answer to part b is 2/3 so I'm not sure if that will help. Thanks for any help.","I'm working out of Feller's ""Introduction to Probability and its Application (Vol I.)"" textbook and I'm stuck on a coin toss problem. I'll list the full problem and show where I'm having trouble. A coin is tossed until for the first time the same result appears twice in succession. To every possible outcome requiring n tosses attribute probability 1/$2^{n-1}$. Describe the sample space. Find the probability of the following events: a.) the experiment ends before the sixth toss, b.) an even number of tosses is required. Alright so I'm not having any trouble describing the sample space and completing part a. This first part was solved by creating a possibility tree and adding up the probabilities (answer: 15/16). However, I'm stuck on part b and I don't understand how the 1/$2^{n-1}$ given in the problem is to be interpreted because if you toss the coin twice it makes it seem like HH, and TT each have a probability of 1/2 which is not the case. The sample space of two tosses would be {HH, HT, TH, TT} and each would have a probability of 1/4 and following this logic I arrived at 15/16 so I believe this is the correct thinking which makes the problem even more confusing. The answer to part b is 2/3 so I'm not sure if that will help. Thanks for any help.",,"['probability', 'probability-theory']"
9,Expected Value of the Difference between 2 Dice,Expected Value of the Difference between 2 Dice,,"What is the expected value of the absolute difference between 2 N   faced dice? What about the difference between 2 dice one with N faces   and one with M faces? While finding the expected value of 2 random variable sums or differences are simple enough, how do you deal with absolute value of differences? Thanks","What is the expected value of the absolute difference between 2 N   faced dice? What about the difference between 2 dice one with N faces   and one with M faces? While finding the expected value of 2 random variable sums or differences are simple enough, how do you deal with absolute value of differences? Thanks",,"['probability', 'puzzle', 'recreational-mathematics', 'dice']"
10,Combinatorics : Which side is heavier?,Combinatorics : Which side is heavier?,,"n coins are given, among which exactly 3 are bad and heavier than the good ones. A balance is used to identify the bad coins. Assume k coins are picked in both sides of the balance at a time. What is the probability of left side being heavier right side being heavier both sides being equal in weight Thanks.","n coins are given, among which exactly 3 are bad and heavier than the good ones. A balance is used to identify the bad coins. Assume k coins are picked in both sides of the balance at a time. What is the probability of left side being heavier right side being heavier both sides being equal in weight Thanks.",,"['probability', 'combinatorics']"
11,On the Total Number of Tries Required to have $n$ Successes,On the Total Number of Tries Required to have  Successes,n,"The Problem A bag contains $b$ black balls and $w$ white balls. Balls are drawn at random from the bag until the last white ball is drawn. What is the expected number of balls drawn? My Partial Solution Suppose the balls are lined up in a line and drawn from left to right. The number of balls to the left of the rightmost white ball (say $N$) ranges from $w-1$ to $w+b-1$, the number of balls to right is given by $w+b-N-1$. So, we can calculate the probability of each value of $N$ using the hypergeometric distribution, and we have $\text{Expected number}=\displaystyle \sum_{k=w-1}^{b+w-1}\frac{\binom{k}{w-1}\binom{w+b-k-1}{0}}{\binom{w+b-1}{w-1}}\cdot\left(k+1\right)$ which requires computation of $$\displaystyle \sum_{k=w-1}^{b+w-1}\binom{k}{w-1} \cdot \left(k+1\right)$$ which I am unable to do. Is my method even correct, and is there any easy way to do the problem or compute the sum?","The Problem A bag contains $b$ black balls and $w$ white balls. Balls are drawn at random from the bag until the last white ball is drawn. What is the expected number of balls drawn? My Partial Solution Suppose the balls are lined up in a line and drawn from left to right. The number of balls to the left of the rightmost white ball (say $N$) ranges from $w-1$ to $w+b-1$, the number of balls to right is given by $w+b-N-1$. So, we can calculate the probability of each value of $N$ using the hypergeometric distribution, and we have $\text{Expected number}=\displaystyle \sum_{k=w-1}^{b+w-1}\frac{\binom{k}{w-1}\binom{w+b-k-1}{0}}{\binom{w+b-1}{w-1}}\cdot\left(k+1\right)$ which requires computation of $$\displaystyle \sum_{k=w-1}^{b+w-1}\binom{k}{w-1} \cdot \left(k+1\right)$$ which I am unable to do. Is my method even correct, and is there any easy way to do the problem or compute the sum?",,['probability']
12,"Relationship between two random, normally distributed variables","Relationship between two random, normally distributed variables",,"I have two normally distributed random variables, X and Y. X has mean 66 and standard deviation 6. Y has mean 77 and standard deviation 7. The correlation between the random variables is given as 0.8. The task is to find the probability $$P(X > 0.7Y)$$ This is my attempt: Create the random variable $$D = 0.7Y - X$$ and calculate $$P(D < 0)$$ The variable D should also be normally distributed with these properties: $$\mu_D = 0.7 \times 77 - 66 = -12.1$$ $$\sigma^2_D = 0.7^2 \times 49 + 36 + 2 \times 0.7 \times -1 \times 0.8 \times 7 \times 6 = 12.97$$ Then, $$P(D < 0) = F_Z\left(\frac{0 + 12.11}{\sqrt{12.97}}\right) \approx F_Z(3.36)$$ But, this is not the answer I'm supposed to get (which is instead $$F_Z(1.17)$$ according to the textbook). Where am I going wrong?","I have two normally distributed random variables, X and Y. X has mean 66 and standard deviation 6. Y has mean 77 and standard deviation 7. The correlation between the random variables is given as 0.8. The task is to find the probability $$P(X > 0.7Y)$$ This is my attempt: Create the random variable $$D = 0.7Y - X$$ and calculate $$P(D < 0)$$ The variable D should also be normally distributed with these properties: $$\mu_D = 0.7 \times 77 - 66 = -12.1$$ $$\sigma^2_D = 0.7^2 \times 49 + 36 + 2 \times 0.7 \times -1 \times 0.8 \times 7 \times 6 = 12.97$$ Then, $$P(D < 0) = F_Z\left(\frac{0 + 12.11}{\sqrt{12.97}}\right) \approx F_Z(3.36)$$ But, this is not the answer I'm supposed to get (which is instead $$F_Z(1.17)$$ according to the textbook). Where am I going wrong?",,"['probability', 'probability-distributions']"
13,Joint distribution of non homogeneous Poisson event times?,Joint distribution of non homogeneous Poisson event times?,,"I am trying to calculate the density of $(T_1,T_2)$ where $T_1$ is the time of the first event and $T_2$ is the time of the second event. I have been looking at the Wiki article on Poisson process and while it has been helpful, I haven't been able to figure out how to apply it to the non homogeneous case.","I am trying to calculate the density of $(T_1,T_2)$ where $T_1$ is the time of the first event and $T_2$ is the time of the second event. I have been looking at the Wiki article on Poisson process and while it has been helpful, I haven't been able to figure out how to apply it to the non homogeneous case.",,"['probability', 'probability-theory', 'stochastic-processes', 'probability-distributions']"
14,Absolute continuity of a distribution function,Absolute continuity of a distribution function,,"This appeared on an exam I took. $Z \sim \text{Uniform}[0, 2\pi]$, and $X  = \cos Z$ and $Y = \sin Z$. Let $F_{XY}$ denote the joint distribution function of $X$ and $Y$. Calculate $\mathbb{P}\left[X+ Y \leq 1\right]$. So this was easy - $$\begin{align}  \mathbb{P}\left[X+Y \leq 1\right] &= \mathbb{P}\left[\sin Z+ \cos Z \leq 1\right] \\ &=\mathbb{P}\left[\sqrt{2}\sin\left(Z+\frac{\pi}{4}\right)\leq 1\right] \\ &= \mathbb{P}\left[Z \leq \arcsin\frac{1}{\sqrt{2}} - \frac{\pi}{4} \right] \\ &= \dfrac{\arcsin\frac{1}{\sqrt{2}} - \frac{\pi}{4}}{2\pi} \end{align} $$ But then, the question asked if $F_{XY}$ was absolutely continuous. I don't think so, but how would I prove it? I thought about proceeding like this $$  \begin{align} F_{XY}(x, y) &= \mathbb{P}\left[X \leq x, Y \leq y\right],\; x, y \in [0, 1] \\ &= \mathbb{P}\left[Z \leq \min(\arccos x, \arcsin y)\right] \end{align} $$ This is definitely continuous, but is it absolutely continuous? Thanks!","This appeared on an exam I took. $Z \sim \text{Uniform}[0, 2\pi]$, and $X  = \cos Z$ and $Y = \sin Z$. Let $F_{XY}$ denote the joint distribution function of $X$ and $Y$. Calculate $\mathbb{P}\left[X+ Y \leq 1\right]$. So this was easy - $$\begin{align}  \mathbb{P}\left[X+Y \leq 1\right] &= \mathbb{P}\left[\sin Z+ \cos Z \leq 1\right] \\ &=\mathbb{P}\left[\sqrt{2}\sin\left(Z+\frac{\pi}{4}\right)\leq 1\right] \\ &= \mathbb{P}\left[Z \leq \arcsin\frac{1}{\sqrt{2}} - \frac{\pi}{4} \right] \\ &= \dfrac{\arcsin\frac{1}{\sqrt{2}} - \frac{\pi}{4}}{2\pi} \end{align} $$ But then, the question asked if $F_{XY}$ was absolutely continuous. I don't think so, but how would I prove it? I thought about proceeding like this $$  \begin{align} F_{XY}(x, y) &= \mathbb{P}\left[X \leq x, Y \leq y\right],\; x, y \in [0, 1] \\ &= \mathbb{P}\left[Z \leq \min(\arccos x, \arcsin y)\right] \end{align} $$ This is definitely continuous, but is it absolutely continuous? Thanks!",,"['probability', 'measure-theory', 'probability-theory', 'probability-distributions']"
15,"Given a random graph $G_{n,p}$, how to get the expectation of number of components with $k$ vertices and $k$ edges?","Given a random graph , how to get the expectation of number of components with  vertices and  edges?","G_{n,p} k k","A random graph $G_{n,p}$ is a graph with $n$ vertices, but every edge exists independently  with probability $p$. If we know $$ np = c, 0 < c < 1 $$ how to get the expectation of number of components with $k$ vertices and $k$ edges when $n$ goes to infinity, where $k$ is constant less than $n$. (In Erdos' classical paper "" On the evolution of random graph "", he actually gave a result of the problem, but without details of proof.  So I have trouble understanding how he reached the conclusion.)","A random graph $G_{n,p}$ is a graph with $n$ vertices, but every edge exists independently  with probability $p$. If we know $$ np = c, 0 < c < 1 $$ how to get the expectation of number of components with $k$ vertices and $k$ edges when $n$ goes to infinity, where $k$ is constant less than $n$. (In Erdos' classical paper "" On the evolution of random graph "", he actually gave a result of the problem, but without details of proof.  So I have trouble understanding how he reached the conclusion.)",,"['probability', 'graph-theory']"
16,Baseball betting and probablity,Baseball betting and probablity,,"Here is a question that came up during class discussions on Friday: Your favorite baseball team is playing against your uncle's favorite team in the  World Series. At the beginning of each game, you and your uncle bet on the game's outcome. Your uncle, being wealthy and carefree, always lets you choose the amount of the bet. If you bet b dollars and your team wins the game, your uncle gives you an IOU for b dollars. But if they lose the game, you give him an IOU for b dollars. When the series is over, all outstanding IOUs are settled in cash. You would like to walk away with 100 in cash if your team wins the series, and lose 100 if your team loses the series. How much should you bet on the opening game? (For non-baseball fans, the first team to win a total of four games  wins the series). I am thinking to apply probability. For example, knowing 100 is the result, moving backward but not exactly sure how to proceed.","Here is a question that came up during class discussions on Friday: Your favorite baseball team is playing against your uncle's favorite team in the  World Series. At the beginning of each game, you and your uncle bet on the game's outcome. Your uncle, being wealthy and carefree, always lets you choose the amount of the bet. If you bet b dollars and your team wins the game, your uncle gives you an IOU for b dollars. But if they lose the game, you give him an IOU for b dollars. When the series is over, all outstanding IOUs are settled in cash. You would like to walk away with 100 in cash if your team wins the series, and lose 100 if your team loses the series. How much should you bet on the opening game? (For non-baseball fans, the first team to win a total of four games  wins the series). I am thinking to apply probability. For example, knowing 100 is the result, moving backward but not exactly sure how to proceed.",,"['probability', 'finance']"
17,Stirling's Approximation and Binomial Random Variable,Stirling's Approximation and Binomial Random Variable,,"I am trying to follow equation (1.13) in MacKay's Information Theory textbook (http://www.inference.phy.cam.ac.uk/itprnn/book.pdf). It is: $$ \ln \binom{N}{r} = \ln \frac{N!}{(N-r)! r!} \approx (N-r) \ln \frac{N}{N-r} + r \ln \frac{N}{r} $$ I am using the approximation in equation (1.12): $$ \ln x! \approx x \ln x - x + \frac12 \ln 2 \pi x$$ Thus, if I expand the expression in the middle of equation (1.13), I should get 9 terms: $$ \ln \frac{N!}{(N-r)! r!} = \ln N! - \ln (N-r)! - \ln r! $$  $$ \approx N \ln N - N + \frac12 \ln 2 \pi N - (N-r) \ln (N-r) + (N-r) - \frac12 \ln 2\pi (N-r) - r \ln r + r - \frac12 \ln 2 \pi r$$ Now, I am stuck. If I remove the $\ln$ terms (seems to be valid for large factorials, http://mathworld.wolfram.com/BinomialDistribution.html equation (37)), I am still stuck. The exact problem seems to be manipulating $N \ln N, - (N-r) \ln (N-r), - r \ln r$ into the form MacKay has in equation (1.13). Thanks.","I am trying to follow equation (1.13) in MacKay's Information Theory textbook (http://www.inference.phy.cam.ac.uk/itprnn/book.pdf). It is: $$ \ln \binom{N}{r} = \ln \frac{N!}{(N-r)! r!} \approx (N-r) \ln \frac{N}{N-r} + r \ln \frac{N}{r} $$ I am using the approximation in equation (1.12): $$ \ln x! \approx x \ln x - x + \frac12 \ln 2 \pi x$$ Thus, if I expand the expression in the middle of equation (1.13), I should get 9 terms: $$ \ln \frac{N!}{(N-r)! r!} = \ln N! - \ln (N-r)! - \ln r! $$  $$ \approx N \ln N - N + \frac12 \ln 2 \pi N - (N-r) \ln (N-r) + (N-r) - \frac12 \ln 2\pi (N-r) - r \ln r + r - \frac12 \ln 2 \pi r$$ Now, I am stuck. If I remove the $\ln$ terms (seems to be valid for large factorials, http://mathworld.wolfram.com/BinomialDistribution.html equation (37)), I am still stuck. The exact problem seems to be manipulating $N \ln N, - (N-r) \ln (N-r), - r \ln r$ into the form MacKay has in equation (1.13). Thanks.",,"['probability', 'approximation']"
18,Isolated vertex probabilities for different random graphs,Isolated vertex probabilities for different random graphs,,"I'm trying to teach myself a little more on threshold probabilities for random graphs, and I'm looking at the probability that graphs have an isolated vertex, when we add on a few restrictions (when by a 'random graph' I mean we take the set of vertices and add each possible (non-directed) edge between vertices with probability p). For example, in the standard ('unrestricted') graph on n vertices, we have something like p = log(n)/n as a probability above which we expect to get no isolated vertices a.e., and below which a.e. we get an isolated vertex. This case is well documented - however, I can find little to nothing in books or online in the case of specific types of random graph which are, for example, k-connected/k-edge-connected bipartite/tripartite etc. The case I'm most interested in (at the moment) is bipartite graphs, and I expect that's the next easiest case to understand too, but I can't find documentation anywhere. Is there a simple way to extend the result from normal graphs to bipartite graphs, assuming both vertex sets have the same size? I suppose my concern is that you're obviously looking at a different set of feasible graphs to the general case on 2n vertices, both fewer graphs with an isolated vertex and fewer graphs in total, so it isn't clear to me that we can immediately say the 'proportion' of graphs which have an isolated vertex will necessarily behave the same for large n. As I mentioned above, I'd be happy to read up on anything anyone could suggest in more restricted cases, I just haven't been able to find it myself, so recommendations will be much appreciated. Thanks very much!","I'm trying to teach myself a little more on threshold probabilities for random graphs, and I'm looking at the probability that graphs have an isolated vertex, when we add on a few restrictions (when by a 'random graph' I mean we take the set of vertices and add each possible (non-directed) edge between vertices with probability p). For example, in the standard ('unrestricted') graph on n vertices, we have something like p = log(n)/n as a probability above which we expect to get no isolated vertices a.e., and below which a.e. we get an isolated vertex. This case is well documented - however, I can find little to nothing in books or online in the case of specific types of random graph which are, for example, k-connected/k-edge-connected bipartite/tripartite etc. The case I'm most interested in (at the moment) is bipartite graphs, and I expect that's the next easiest case to understand too, but I can't find documentation anywhere. Is there a simple way to extend the result from normal graphs to bipartite graphs, assuming both vertex sets have the same size? I suppose my concern is that you're obviously looking at a different set of feasible graphs to the general case on 2n vertices, both fewer graphs with an isolated vertex and fewer graphs in total, so it isn't clear to me that we can immediately say the 'proportion' of graphs which have an isolated vertex will necessarily behave the same for large n. As I mentioned above, I'd be happy to read up on anything anyone could suggest in more restricted cases, I just haven't been able to find it myself, so recommendations will be much appreciated. Thanks very much!",,"['probability', 'reference-request', 'graph-theory']"
19,Collisions in a sample of uniform distribution,Collisions in a sample of uniform distribution,,Asked at a Microsoft interview: Assume you have a uniform distribution (can be discrete or continuous) of size X and you randomly select a sample of size Y. 1) What is the probability in terms of X and Y of a collision? 2) What is the expected number of collisions in terms of X and Y?,Asked at a Microsoft interview: Assume you have a uniform distribution (can be discrete or continuous) of size X and you randomly select a sample of size Y. 1) What is the probability in terms of X and Y of a collision? 2) What is the expected number of collisions in terms of X and Y?,,['probability']
20,Sample sizes for an infinite population,Sample sizes for an infinite population,,"I've poked about in some other questions , and I'm no sure how to deal with my problem and my knowledge of statistics has atrophied. Particularly that I'm trying to choose a sample size for a population that I don't know the size of (potentially infinite, but it could be 10,000's or 100,000's or more). How do I choose a sample size that will give me a meaningful answer. Is it reasonable just to plug in a very large number, and see what comes out - does it approach a limit? My real world problem is this: I have two computer systems (Able and Baker). My user community believes Able is faster than Baker. I can run a simple test on both, and see how long it takes to run one each. However, there are inconsistencies in performance (probably do to the network, which will have spikes in activity and I unfortunately can't removed from the test). Baker will be running for years into the future, so I have no idea how many transactions will run in it over its lifetime. Assuming the performance issues caused by the network are random, how many tests do I have to run each on Able and Baker to to be 90% confident that Able is faster than Baker? Perhaps I'm asking the wrong question? Should I just be finding the average of a 100 tests on Able and 100 tests on Baker and compare? Can I make than number 100 smaller (to say like 20)","I've poked about in some other questions , and I'm no sure how to deal with my problem and my knowledge of statistics has atrophied. Particularly that I'm trying to choose a sample size for a population that I don't know the size of (potentially infinite, but it could be 10,000's or 100,000's or more). How do I choose a sample size that will give me a meaningful answer. Is it reasonable just to plug in a very large number, and see what comes out - does it approach a limit? My real world problem is this: I have two computer systems (Able and Baker). My user community believes Able is faster than Baker. I can run a simple test on both, and see how long it takes to run one each. However, there are inconsistencies in performance (probably do to the network, which will have spikes in activity and I unfortunately can't removed from the test). Baker will be running for years into the future, so I have no idea how many transactions will run in it over its lifetime. Assuming the performance issues caused by the network are random, how many tests do I have to run each on Able and Baker to to be 90% confident that Able is faster than Baker? Perhaps I'm asking the wrong question? Should I just be finding the average of a 100 tests on Able and 100 tests on Baker and compare? Can I make than number 100 smaller (to say like 20)",,"['probability', 'statistics']"
21,Understanding the Pareto distribution as applied to wealth,Understanding the Pareto distribution as applied to wealth,,"The Pareto distribution is used to say, given a particular person X, what is the pdf of his wealth. I would like to explore the reciprocal question: Given the total amount of wealth in a population, what portion does a random person have.  I conjecture that this is simply a constant times the Pareto distribution. More interestingly: What is the shape of the distribution curve, if the richest person would be at the 0 point on the x axis, the next richest person to the right, and so on - we would see a monotonically decreasing curve.  But what is its shape? What is its derivative? It's quite likely that I'm not phrasing that question properly.  Let me ask a more basic question: What is the appropriate terminilogy to explore the question? Give a probability distribution applied many times over, what is the shape of the resultant allocation curve?","The Pareto distribution is used to say, given a particular person X, what is the pdf of his wealth. I would like to explore the reciprocal question: Given the total amount of wealth in a population, what portion does a random person have.  I conjecture that this is simply a constant times the Pareto distribution. More interestingly: What is the shape of the distribution curve, if the richest person would be at the 0 point on the x axis, the next richest person to the right, and so on - we would see a monotonically decreasing curve.  But what is its shape? What is its derivative? It's quite likely that I'm not phrasing that question properly.  Let me ask a more basic question: What is the appropriate terminilogy to explore the question? Give a probability distribution applied many times over, what is the shape of the resultant allocation curve?",,"['probability', 'statistics']"
22,Proof that $\frac{S_n}{n}$ converges almost surely to $\mu$,Proof that  converges almost surely to,\frac{S_n}{n} \mu,"I'm trying to show that given $(X_i)$ i.i.d., $E[X_i^2] < \infty$, $\mu := E[X_i]$ then $P\Big [  \lim_{n \rightarrow \infty} \frac{S_n}{n} = \mu \Big ] = 1$ where $ S_n := \sum_{k=1}^n X_k$. So far, I have rewritten  $P\Big [  \lim_{n \rightarrow \infty} \frac{S_n}{n} = \mu \Big ]$ as $$ \lim_{k \rightarrow \infty} P \Big [ \cap_{n \geq k} \{ \omega \Big | |\frac{S_n}{n} - \mu| < \varepsilon \}  \Big ]$$ But I'm not sure how to proceed from here. I have $$ \sum_{n} P\Big [ |X_n - X|  > \varepsilon \Big] < \infty  \Rightarrow P\Big [ \lim_n X_n = X \Big ] = 1$$ which I think I should apply but I don't see how. Can anyone help me with this? Also, I don't see where $E[X_i^2] < \infty$ comes in. Many thanks for your help!","I'm trying to show that given $(X_i)$ i.i.d., $E[X_i^2] < \infty$, $\mu := E[X_i]$ then $P\Big [  \lim_{n \rightarrow \infty} \frac{S_n}{n} = \mu \Big ] = 1$ where $ S_n := \sum_{k=1}^n X_k$. So far, I have rewritten  $P\Big [  \lim_{n \rightarrow \infty} \frac{S_n}{n} = \mu \Big ]$ as $$ \lim_{k \rightarrow \infty} P \Big [ \cap_{n \geq k} \{ \omega \Big | |\frac{S_n}{n} - \mu| < \varepsilon \}  \Big ]$$ But I'm not sure how to proceed from here. I have $$ \sum_{n} P\Big [ |X_n - X|  > \varepsilon \Big] < \infty  \Rightarrow P\Big [ \lim_n X_n = X \Big ] = 1$$ which I think I should apply but I don't see how. Can anyone help me with this? Also, I don't see where $E[X_i^2] < \infty$ comes in. Many thanks for your help!",,['probability']
23,Particle moving at constant speed with Poisson setbacks,Particle moving at constant speed with Poisson setbacks,,"Consider a particle starting at the the origin and moving along the positive real line at a constant speed of 1.  Suppose there is a counter which clicks at random time intervals following the exponential distribution with parameter $\lambda$ and whenever the counter clicks, the position $x > 0$ of the particle at that time instantaneously changes to the position $x/2$.  We wish to calculate the expected average speed of the particle. I don't really have any idea of how to go about solving this.  Here are a couple of related problems which seem even more difficult to me: Modify the puzzle so that when the counter clicks, the particle moves from $x$ to a point chosen uniformly at random from $[0,x]$. The particle starts moving as above but whenever the counter clicks, its speed increases by 1 (the initial speed was 1).  What is the expected time when the particle hits the position 1?  What is the expected speed when the particle hits the position 1? This is not a homework problem.  Any solutions, hints, thoughts will be appreciated. Thanks,","Consider a particle starting at the the origin and moving along the positive real line at a constant speed of 1.  Suppose there is a counter which clicks at random time intervals following the exponential distribution with parameter $\lambda$ and whenever the counter clicks, the position $x > 0$ of the particle at that time instantaneously changes to the position $x/2$.  We wish to calculate the expected average speed of the particle. I don't really have any idea of how to go about solving this.  Here are a couple of related problems which seem even more difficult to me: Modify the puzzle so that when the counter clicks, the particle moves from $x$ to a point chosen uniformly at random from $[0,x]$. The particle starts moving as above but whenever the counter clicks, its speed increases by 1 (the initial speed was 1).  What is the expected time when the particle hits the position 1?  What is the expected speed when the particle hits the position 1? This is not a homework problem.  Any solutions, hints, thoughts will be appreciated. Thanks,",,"['puzzle', 'probability']"
24,Optimally combining samples to estimate averages,Optimally combining samples to estimate averages,,"Suppose I have two tables, each of unknown size, and I'd like to estimate the average of their true sizes. I hire 2 contractors: one guarantees good precision (i.e., her measurement normally-distributed about the true value, with a standard deviation of 5mm), while the other is a dimwit (i.e., his measurement is also unbiased, but with a standard deviation of 100mm). What's the optimal way to combine the two measurements to form a final estimate of their true average size? The formal way to ask this question is, ""Given a sample from a normally-distributed random variable with known variance, and another sample from a second normally-distributed random variable with known (but potentially different) variance, what is the best guess as to the expected value of the average of the two random variables?"" Is the answer ""Just average them.""? Ideally, I want to prove the answer, whatever it is. EDIT: I'm not sure if it was clear, but one contractor measures table 1, while the other contractor measures table 2.","Suppose I have two tables, each of unknown size, and I'd like to estimate the average of their true sizes. I hire 2 contractors: one guarantees good precision (i.e., her measurement normally-distributed about the true value, with a standard deviation of 5mm), while the other is a dimwit (i.e., his measurement is also unbiased, but with a standard deviation of 100mm). What's the optimal way to combine the two measurements to form a final estimate of their true average size? The formal way to ask this question is, ""Given a sample from a normally-distributed random variable with known variance, and another sample from a second normally-distributed random variable with known (but potentially different) variance, what is the best guess as to the expected value of the average of the two random variables?"" Is the answer ""Just average them.""? Ideally, I want to prove the answer, whatever it is. EDIT: I'm not sure if it was clear, but one contractor measures table 1, while the other contractor measures table 2.",,"['probability', 'probability-theory', 'statistics', 'optimization']"
25,The probability theory around a candy bag,The probability theory around a candy bag,,"Consider a candy bag that contains $N=100$ candies. There are only two types of candy in the bag. Say the caramel candy and the chocolate candy. Nothing more is known about the contents of the bag. Now, you are going to draw (randomly) one candy at a time from the bag until the first caramel appear. Suppose that the first caramel appeared at $k=7$ th drawing. At this moment, what can we say about  the number of caramel candies in the bag?","Consider a candy bag that contains candies. There are only two types of candy in the bag. Say the caramel candy and the chocolate candy. Nothing more is known about the contents of the bag. Now, you are going to draw (randomly) one candy at a time from the bag until the first caramel appear. Suppose that the first caramel appeared at th drawing. At this moment, what can we say about  the number of caramel candies in the bag?",N=100 k=7,['probability']
26,"How to find the probability that the object reaches $(2, 2)$ in six or fewer steps",How to find the probability that the object reaches  in six or fewer steps,"(2, 2)","Starting at $(0, 0)$ an object moves in coordinate plane by a sequence of steps, each of length one. each step is left, right up or down, all four equally likely. Find the probability that the object reaches $(2, 2)$ in six or fewer steps. My Approach- One can reach $(2,2)$ starting from the origin either by $4$ steps or $6$ steps $2$ sub cases in $6$ step path; $3$ steps right, $1$ left, $2$ up, and $0$ down Or $2$ steps right, $0$ left, $3$ up, $1$ down So the required probability should be $$\frac{\frac{4!}{2!2!}}{4^4} + \frac{\frac{6!}{3!2!1!} \cdot 2}{4^6}$$ Did multiply $2$ in the second term of the expression because of $2$ cases. But the answer doesn’t match. Please help!","Starting at an object moves in coordinate plane by a sequence of steps, each of length one. each step is left, right up or down, all four equally likely. Find the probability that the object reaches in six or fewer steps. My Approach- One can reach starting from the origin either by steps or steps sub cases in step path; steps right, left, up, and down Or steps right, left, up, down So the required probability should be Did multiply in the second term of the expression because of cases. But the answer doesn’t match. Please help!","(0, 0) (2, 2) (2,2) 4 6 2 6 3 1 2 0 2 0 3 1 \frac{\frac{4!}{2!2!}}{4^4} + \frac{\frac{6!}{3!2!1!} \cdot 2}{4^6} 2 2","['probability', 'combinatorics', 'contest-math']"
27,Convergent sequences under different probability measures,Convergent sequences under different probability measures,,"What is the „intuitive” reason behind the following statements... Let $\left(X_{n}\right)_{n}$ be a sequence of random variables. Let us assume $\mathbf{Q}\ll\mathbf{P}$ , i.e. the $\mathbf{Q}$ probability measure is absolutely continuous with respect to the $\mathbf{P}$ probability measure. If $\left(X_{n}\right)_{n}$ is almost surely convergent under $\mathbf{P}$ , then ${(X_n)}_n$ is almost surely convergent under $\mathbf{Q}$ as well. If $\left(X_{n}\right)_{n}$ is convergent in the stochastic convergence under $\mathbf{P}$ , then ${(X_n)}_n$ is also convergent in the stochastic convergence under $\mathbf{Q}$ as well. I think the first statement makes sense to me: If I randomly choose an $\omega$ according to $\mathbf{P}$ , then it is 100% sure (i.e. it has $1$ probability), that ${(X_n)}_n$ will be convergent. Since the $\mathbf{Q}$ -zero probabilities are the same as the $\mathbf{P}$ -zero probabilities, then the $\mathbf{Q}$ -one probabilities are the same as the $\mathbf{P}$ -one probabilities. Therefore, if I randomly choose an $\omega$ according to $\mathbf{Q}$ , then ${(X_n)}_n$ will also be convergent under $\mathbf{Q}$ almost surely. However, it is not as obvious to me in case of stochastic convegence as in the case of almost sure convergence. Can you give me some „intuitive” explanation why it is indeed true? Also, is the $X$ limit the same under different measures? (I think it is, but I need confirmation...)","What is the „intuitive” reason behind the following statements... Let be a sequence of random variables. Let us assume , i.e. the probability measure is absolutely continuous with respect to the probability measure. If is almost surely convergent under , then is almost surely convergent under as well. If is convergent in the stochastic convergence under , then is also convergent in the stochastic convergence under as well. I think the first statement makes sense to me: If I randomly choose an according to , then it is 100% sure (i.e. it has probability), that will be convergent. Since the -zero probabilities are the same as the -zero probabilities, then the -one probabilities are the same as the -one probabilities. Therefore, if I randomly choose an according to , then will also be convergent under almost surely. However, it is not as obvious to me in case of stochastic convegence as in the case of almost sure convergence. Can you give me some „intuitive” explanation why it is indeed true? Also, is the limit the same under different measures? (I think it is, but I need confirmation...)",\left(X_{n}\right)_{n} \mathbf{Q}\ll\mathbf{P} \mathbf{Q} \mathbf{P} \left(X_{n}\right)_{n} \mathbf{P} {(X_n)}_n \mathbf{Q} \left(X_{n}\right)_{n} \mathbf{P} {(X_n)}_n \mathbf{Q} \omega \mathbf{P} 1 {(X_n)}_n \mathbf{Q} \mathbf{P} \mathbf{Q} \mathbf{P} \omega \mathbf{Q} {(X_n)}_n \mathbf{Q} X,"['probability', 'measure-theory', 'stochastic-calculus', 'almost-everywhere', 'radon-nikodym']"
28,"If $X_n=Y_n$ in distribution and $X_n \to 0$ almost surely, then does $Y_n \to 0$ almost surely ? (For particular $X_n$ and $Y_n$)","If  in distribution and  almost surely, then does  almost surely ? (For particular  and )",X_n=Y_n X_n \to 0 Y_n \to 0 X_n Y_n,"Of course in general the answer to my question is NO, however I am interested in two sequences of random variables that have very specific structure. Let $a_n,b_n$ be deterministic (real-valued) sequences and let $\xi_n$ be an i.i.d sequence of random variables. Then let $$ X_n=a_n+b_n\xi_n, \quad Y_n=a_n+b_n\xi,$$ where $\xi=\xi_n$ in distribution. If we suppose $X_n \to 0$ almost surely, can we conclude that $Y_n \to 0$ almost surely? An idea of a possible method of proof (or a counter example) would be much appreciated. Note we also assume that the sequence $b_n$ is non-degenerate i.e not the zero sequence (otherwise the question would not be very interesting).","Of course in general the answer to my question is NO, however I am interested in two sequences of random variables that have very specific structure. Let be deterministic (real-valued) sequences and let be an i.i.d sequence of random variables. Then let where in distribution. If we suppose almost surely, can we conclude that almost surely? An idea of a possible method of proof (or a counter example) would be much appreciated. Note we also assume that the sequence is non-degenerate i.e not the zero sequence (otherwise the question would not be very interesting).","a_n,b_n \xi_n  X_n=a_n+b_n\xi_n, \quad Y_n=a_n+b_n\xi, \xi=\xi_n X_n \to 0 Y_n \to 0 b_n","['probability', 'sequences-and-series', 'probability-theory', 'limits']"
29,Probability of Non-Matching Colors in Stacked Book Piles.,Probability of Non-Matching Colors in Stacked Book Piles.,,"Three orange books, three blue books, and three green books are randomly stacked to form three piles of three books each. What is the probability that no book will be the same color as the book directly above it? Using a decision tree in excel I found that the probability is 1/5. The R code below gives the same result. library(MASS) library(RcppAlgos) library(magrittr)  permuteGeneral(c(""A"", ""B"", ""C""), freqs = c(3, 3, 3), FUN = \(x) {   if (x[1] != x[2] && x[2] != x[3] && x[4] != x[5] && x[5] != x[6] &&     x[7] != x[8] && x[8] != x[9]) {     TRUE   } else {     FALSE   } })  %>% unlist() %>% {fractions(sum(.)/length(.))} But surely there must be a more elegant solution. Can anyone help?","Three orange books, three blue books, and three green books are randomly stacked to form three piles of three books each. What is the probability that no book will be the same color as the book directly above it? Using a decision tree in excel I found that the probability is 1/5. The R code below gives the same result. library(MASS) library(RcppAlgos) library(magrittr)  permuteGeneral(c(""A"", ""B"", ""C""), freqs = c(3, 3, 3), FUN = \(x) {   if (x[1] != x[2] && x[2] != x[3] && x[4] != x[5] && x[5] != x[6] &&     x[7] != x[8] && x[8] != x[9]) {     TRUE   } else {     FALSE   } })  %>% unlist() %>% {fractions(sum(.)/length(.))} But surely there must be a more elegant solution. Can anyone help?",,"['probability', 'combinatorics']"
30,Understanding the Likelihood Principle - What is the Big Deal here?,Understanding the Likelihood Principle - What is the Big Deal here?,,"I am reading about the Likelihood Principle ( https://en.wikipedia.org/wiki/Likelihood_principle ). In short, I think the Likelihood Principle discusses the phenomena that if two experiments have the same underlying likelihood function, then even if these experiments result in different observed data - the parameter estimates will be the same in both experiments ... regardless of the fact that both experiments produced different data. That is, if two likelihoods are identical and only differ by some constant: optimizing these two likelihoods will give you the same parameter estimates. I am trying to understand why the Likelihood Principle is important. Part 1: Here is an example from the Wikipedia Page: Suppose we have two experiments involving independent Bernoulli trials with a probability of success on each trial given by $\theta$ . In both experiments, we are interested in estimating $\theta$ based on the data we observe. In the first experiment, $X$ is the number of successes in twelve trials. In the second experiment, $Y$ is the number of trials needed to get three successes (Negative Binomial Distribution https://en.wikipedia.org/wiki/Negative_binomial_distribution ) The likelihood functions for these two experiments are given by: For $X = 3$ , the likelihood function is: $$\mathcal{L}(\theta \mid X=3) = \binom{12}{3} \theta^3 (1-\theta)^9 = 220\theta^3(1-\theta)^9$$ For $Y = 12$ , the likelihood function is: $$\mathcal{L}(\theta \mid Y=12) = \binom{11}{2} \theta^3 (1-\theta)^9 = 55 \theta^3 (1-\theta)^9$$ We can see that one of these likelihoods is 4 times the other likelihood. This means that both likelihoods are essentially identical and only differ by a constant term. Part 2: I tried to continue these examples by myself: For $X = 3$ , the likelihood function is: $\mathcal{L}(\theta \mid X=3) = 220 \theta^3 (1-\theta)^9$ For $Y = 12$ , the likelihood function is: $\mathcal{L}(\theta \mid Y=12) = 55 \theta^3 (1-\theta)^9$ To find the MLE, take the derivative of the likelihood function with respect to $\theta$ , set it equal to zero, and solve for $\theta$ . For both likelihood functions, the derivative is (not that the constant terms in both likelihoods 220 and 55 would cancel out when you would try to solve for $\theta$ ): $$\frac{d}{d\theta} \mathcal{L}(\theta) = 3\theta^2(1-\theta)^9 - 9\theta^3(1-\theta)^8$$ Setting this equal to zero gives: $$3\theta^2(1-\theta)^9 - 9\theta^3(1-\theta)^8 = 0$$ We can factor out $\theta^2(1-\theta)^8$ from both terms: $$\theta^2(1-\theta)^8 (3(1-\theta) - 9\theta) = 0$$ Setting each factor equal to zero gives the possible solutions for $\theta$ : $\theta^2 = 0 \Rightarrow \theta = 0$ $(1-\theta)^8 = 0 \Rightarrow \theta = 1$ $3(1-\theta) - 9\theta = 0 \Rightarrow \theta = \frac{1}{4}$ The possible solutions for $\theta$ are 0, 1, and 1/4. However, $\theta=0$ and $\theta=1$ are likely not valid solutions  because they imply that the event (observing a head) is either impossible or certain to happen. Therefore, the only likely valid solution is $\theta=1/4$ . Thus, we can see that both likelihoods produce the same estimate for $\theta$ , thus demonstrating the Likelihood Principle. My Question: But why is the Likelihood Principle important? The above exercise just showed me that the same likelihood function produces the same parameter estimates in different situations - Is this problematic? Is this useful? What is the big deal here? What is the big deal about the Likelihood Principle? I have a feeling that the Likelihood Principle is trying to highlight some flaw about Likelihood theory - perhaps something about the uniqueness of parameter estimates from Maximum Likelihood Estimation ... or that the design of experiments is more important than the data collected from the experiments. But I am not sure. Can someone please help me understand why the Likelihood Principle is important? Thanks!","I am reading about the Likelihood Principle ( https://en.wikipedia.org/wiki/Likelihood_principle ). In short, I think the Likelihood Principle discusses the phenomena that if two experiments have the same underlying likelihood function, then even if these experiments result in different observed data - the parameter estimates will be the same in both experiments ... regardless of the fact that both experiments produced different data. That is, if two likelihoods are identical and only differ by some constant: optimizing these two likelihoods will give you the same parameter estimates. I am trying to understand why the Likelihood Principle is important. Part 1: Here is an example from the Wikipedia Page: Suppose we have two experiments involving independent Bernoulli trials with a probability of success on each trial given by . In both experiments, we are interested in estimating based on the data we observe. In the first experiment, is the number of successes in twelve trials. In the second experiment, is the number of trials needed to get three successes (Negative Binomial Distribution https://en.wikipedia.org/wiki/Negative_binomial_distribution ) The likelihood functions for these two experiments are given by: For , the likelihood function is: For , the likelihood function is: We can see that one of these likelihoods is 4 times the other likelihood. This means that both likelihoods are essentially identical and only differ by a constant term. Part 2: I tried to continue these examples by myself: For , the likelihood function is: For , the likelihood function is: To find the MLE, take the derivative of the likelihood function with respect to , set it equal to zero, and solve for . For both likelihood functions, the derivative is (not that the constant terms in both likelihoods 220 and 55 would cancel out when you would try to solve for ): Setting this equal to zero gives: We can factor out from both terms: Setting each factor equal to zero gives the possible solutions for : The possible solutions for are 0, 1, and 1/4. However, and are likely not valid solutions  because they imply that the event (observing a head) is either impossible or certain to happen. Therefore, the only likely valid solution is . Thus, we can see that both likelihoods produce the same estimate for , thus demonstrating the Likelihood Principle. My Question: But why is the Likelihood Principle important? The above exercise just showed me that the same likelihood function produces the same parameter estimates in different situations - Is this problematic? Is this useful? What is the big deal here? What is the big deal about the Likelihood Principle? I have a feeling that the Likelihood Principle is trying to highlight some flaw about Likelihood theory - perhaps something about the uniqueness of parameter estimates from Maximum Likelihood Estimation ... or that the design of experiments is more important than the data collected from the experiments. But I am not sure. Can someone please help me understand why the Likelihood Principle is important? Thanks!",\theta \theta X Y X = 3 \mathcal{L}(\theta \mid X=3) = \binom{12}{3} \theta^3 (1-\theta)^9 = 220\theta^3(1-\theta)^9 Y = 12 \mathcal{L}(\theta \mid Y=12) = \binom{11}{2} \theta^3 (1-\theta)^9 = 55 \theta^3 (1-\theta)^9 X = 3 \mathcal{L}(\theta \mid X=3) = 220 \theta^3 (1-\theta)^9 Y = 12 \mathcal{L}(\theta \mid Y=12) = 55 \theta^3 (1-\theta)^9 \theta \theta \theta \frac{d}{d\theta} \mathcal{L}(\theta) = 3\theta^2(1-\theta)^9 - 9\theta^3(1-\theta)^8 3\theta^2(1-\theta)^9 - 9\theta^3(1-\theta)^8 = 0 \theta^2(1-\theta)^8 \theta^2(1-\theta)^8 (3(1-\theta) - 9\theta) = 0 \theta \theta^2 = 0 \Rightarrow \theta = 0 (1-\theta)^8 = 0 \Rightarrow \theta = 1 3(1-\theta) - 9\theta = 0 \Rightarrow \theta = \frac{1}{4} \theta \theta=0 \theta=1 \theta=1/4 \theta,['probability']
31,Game on guessing which is larger between two random number from 0 to 1,Game on guessing which is larger between two random number from 0 to 1,,"Alice and Bob are playing a game. Each time, two numbers are generated uniformly in the interval $[0,1] $ , Alice can see the two numbers and choose one to tell Bob. And Bob needs to determine whether it's the larger one. Bob wins if he is correct, otherwise, Alice wins. Alice and Bob's strategies can be represented as functions. $ F : [0,1]^2 \rightarrow [0,1]$ for Alice, and $f:[0,1] \rightarrow [0,1]$ for Bob. It means that when Alice is told two numbers $p$ and $q$ , she has probability of $F(p,q)$ to tell Bob number $p$ . When Bob is told number $p$ , he has probability of $f(p)$ to guess $p$ is bigger. Then for given $(p,q)$ , the probability for Bob to win is $$\Phi (p,q) = \left\{ \begin{array}{ll}     F(p,q)f(p)+(1-F(p,q))(1-f(q))  &\text{if } p > q \\     F(p,q)(1-f(p))+(1-F(p,q))f(q) & \text{if } p < q \\ \end{array} \right.$$ And $$E = \int \int_{[0,1]^2} \Phi (p,q) dp dq$$ is the expection for Bob to win. It's not hard to know that if Bob takes $$f= \left\{  \begin{array}{ll}     1  &\text{if } p > \frac 1 2 \\     0 & \text{if } p < \frac 1 2 \\ \end{array} \right.$$ There will always be $E \ge \frac 1 2$ , i.e. $f$ guarantees Bob's not losing (in long term). I want to know whether the game is fair(Alice also has a not -losing strategy), namely, there exists an $F$ , s.t. for any $f$ , $E \le \frac 1 2$ . If not, I also want to know whether the following is true. For any $f$ , there exists an $F$ , s.t. $E \le \frac 1 2$ . (Alice still has a chance not to lose).","Alice and Bob are playing a game. Each time, two numbers are generated uniformly in the interval , Alice can see the two numbers and choose one to tell Bob. And Bob needs to determine whether it's the larger one. Bob wins if he is correct, otherwise, Alice wins. Alice and Bob's strategies can be represented as functions. for Alice, and for Bob. It means that when Alice is told two numbers and , she has probability of to tell Bob number . When Bob is told number , he has probability of to guess is bigger. Then for given , the probability for Bob to win is And is the expection for Bob to win. It's not hard to know that if Bob takes There will always be , i.e. guarantees Bob's not losing (in long term). I want to know whether the game is fair(Alice also has a not -losing strategy), namely, there exists an , s.t. for any , . If not, I also want to know whether the following is true. For any , there exists an , s.t. . (Alice still has a chance not to lose).","[0,1]   F : [0,1]^2 \rightarrow [0,1] f:[0,1] \rightarrow [0,1] p q F(p,q) p p f(p) p (p,q) \Phi (p,q) = \left\{
\begin{array}{ll}
    F(p,q)f(p)+(1-F(p,q))(1-f(q))  &\text{if } p > q \\
    F(p,q)(1-f(p))+(1-F(p,q))f(q) & \text{if } p < q \\
\end{array}
\right. E = \int \int_{[0,1]^2} \Phi (p,q) dp dq f= \left\{ 
\begin{array}{ll}
    1  &\text{if } p > \frac 1 2 \\
    0 & \text{if } p < \frac 1 2 \\
\end{array}
\right. E \ge \frac 1 2 f F f E \le \frac 1 2 f F E \le \frac 1 2","['probability', 'game-theory']"
32,Exchangeability of an interacting particle SDE system,Exchangeability of an interacting particle SDE system,,"Let $(W^1,\ldots,W^N)$ be $N$ independent Brownian motions, $\sigma > 0$ and $k$ a Lipschitz function. Consider the following system of SDE's \begin{equation} \mathrm{d}X_t^{i} = -\frac{1}{N} \sum\limits_{j=1}^N k(X_t^{i}-X_t^{j}) \mathrm{d}t + \sigma \mathrm{d}W_t^{i}, \quad \quad i=1,\ldots, N, \end{equation} which is subject to i.i.d. initial conditions. The system is well-defined and has a strong solution by the classic theory. Now, in every paper on interacting particle systems the author's claim that this system is exchangable. This seems reasonable. Unfortunately, I have never seen a complete proof of this statement and I am struggling with the proof myself. If you have an references or could provide a proof of the exchangability I would appreciate it! I think you need to use the pathwise uniqueness + Yamada-Watanabe Theorem, which provides a $\mathbb{R}^N$ -valued function of the form $h(X_0,W_{.})$ ,( $X_0,W$ are the vectors of the whole system).","Let be independent Brownian motions, and a Lipschitz function. Consider the following system of SDE's which is subject to i.i.d. initial conditions. The system is well-defined and has a strong solution by the classic theory. Now, in every paper on interacting particle systems the author's claim that this system is exchangable. This seems reasonable. Unfortunately, I have never seen a complete proof of this statement and I am struggling with the proof myself. If you have an references or could provide a proof of the exchangability I would appreciate it! I think you need to use the pathwise uniqueness + Yamada-Watanabe Theorem, which provides a -valued function of the form ,( are the vectors of the whole system).","(W^1,\ldots,W^N) N \sigma > 0 k \begin{equation}
\mathrm{d}X_t^{i} = -\frac{1}{N} \sum\limits_{j=1}^N k(X_t^{i}-X_t^{j}) \mathrm{d}t + \sigma \mathrm{d}W_t^{i}, \quad \quad i=1,\ldots, N,
\end{equation} \mathbb{R}^N h(X_0,W_{.}) X_0,W","['probability', 'probability-theory', 'systems-of-equations', 'stochastic-differential-equations']"
33,Finite stopping time,Finite stopping time,,"Let $(X_k)_{k \in \mathbb{N}}$ be iid uniformly distributed on $(-1,1)$ , $Y_0:=0$ and $$ Y_n := \sum_{k=0}^n \sin(\pi X_k). $$ We deine another random variable by $Z_K := \inf \lbrace n \in \mathbb{N}: \lvert Y_k \rvert \geq K \rbrace$ . Here, $K>1$ . I am interested in whether $Z_k$ is finite a.s.. I think that it is, since the series $\sum_{k=0}^n \sin(\pi X_k)$ diverges if $X_k \not \rightarrow 0$ . But since the $X_k$ are iid uniformly distributed, this does not hold true. But this is not very rigorous. Ist this outline even correct and ist there an elegant proof for this? Thank you!","Let be iid uniformly distributed on , and We deine another random variable by . Here, . I am interested in whether is finite a.s.. I think that it is, since the series diverges if . But since the are iid uniformly distributed, this does not hold true. But this is not very rigorous. Ist this outline even correct and ist there an elegant proof for this? Thank you!","(X_k)_{k \in \mathbb{N}} (-1,1) Y_0:=0 
Y_n := \sum_{k=0}^n \sin(\pi X_k).
 Z_K := \inf \lbrace n \in \mathbb{N}: \lvert Y_k \rvert \geq K \rbrace K>1 Z_k \sum_{k=0}^n \sin(\pi X_k) X_k \not \rightarrow 0 X_k","['probability', 'probability-theory', 'stochastic-processes', 'martingales']"
34,Probability convergence of a martingale defined as iid random variable product,Probability convergence of a martingale defined as iid random variable product,,Let $(\beta_n)_{n \geq 1}$ be positive independent and identically distributed random variables with $\mathbb{E}[\beta_1] = 1$ and $\mathbb{P}[\beta_1 < 1 ] > 0$ . Define the martingale $M_n = \beta_1 \cdot \beta_2 \cdots \beta_n$ . I have to prove that $M_n \to 0$ almost surely (a.s.). Below what I've tried so far. First attempt. Given that $(M_n)$ is bounded in $L^1$ the pointwise limit exist a.s.. In order to compute the limit let's study the convergence in probability: by the Paul Levy theorem it suffices to study the characteristic function pointwise convergence: $$ \varphi_{M_n}(t) = \mathbb{E}\left[ \exp(itM_n) \right] = \mathbb{E}\left[ \exp\left( it \prod_{i=1}^n \beta_i \right) \right] $$ but I don't know how to go ahead. Second attempt. Let's try to use the Borel Cantelli lemma. It suffices to show that $$ \forall \epsilon > 0 \quad \mathbb{P}[M_n < \epsilon \text{ eventually}] = 1. $$ So $$ \mathbb{P}[M_n < \epsilon \text{ eventually}] = 1 - \mathbb{P}[M_n > \epsilon \text{ infinitely often}]. $$ Let's study $$ \sum_{n \geq 0} \mathbb{P}[M_n > \epsilon] $$ but I can't show that the serie converges. Any hints would be appreciated. In particular I cannot figure out how to use the hypothesis $\mathbb{P}[\beta_1 < 1 ] > 0$ .,Let be positive independent and identically distributed random variables with and . Define the martingale . I have to prove that almost surely (a.s.). Below what I've tried so far. First attempt. Given that is bounded in the pointwise limit exist a.s.. In order to compute the limit let's study the convergence in probability: by the Paul Levy theorem it suffices to study the characteristic function pointwise convergence: but I don't know how to go ahead. Second attempt. Let's try to use the Borel Cantelli lemma. It suffices to show that So Let's study but I can't show that the serie converges. Any hints would be appreciated. In particular I cannot figure out how to use the hypothesis .,"(\beta_n)_{n \geq 1} \mathbb{E}[\beta_1] = 1 \mathbb{P}[\beta_1 < 1 ] > 0 M_n = \beta_1 \cdot \beta_2 \cdots \beta_n M_n \to 0 (M_n) L^1 
\varphi_{M_n}(t) = \mathbb{E}\left[ \exp(itM_n) \right] = \mathbb{E}\left[ \exp\left( it \prod_{i=1}^n \beta_i \right) \right]
 
\forall \epsilon > 0 \quad \mathbb{P}[M_n < \epsilon \text{ eventually}] = 1.
 
\mathbb{P}[M_n < \epsilon \text{ eventually}] = 1 - \mathbb{P}[M_n > \epsilon \text{ infinitely often}].
 
\sum_{n \geq 0} \mathbb{P}[M_n > \epsilon]
 \mathbb{P}[\beta_1 < 1 ] > 0","['probability', 'martingales', 'pointwise-convergence']"
35,A question in Stochastic Convergence,A question in Stochastic Convergence,,"I was reading a proof in a paper and got stuck at the following. Have been trying by best to figure this out for a long time but had no luck. It says: When we have \begin{equation}\tag{1} \frac{1}{{\alpha}^{i-2}}Z_{i-1}\overset{d}\rightarrow\sum_{j=1}^{\infty}\alpha^{1-j}u_j\qquad \text{as}\quad i\rightarrow\infty \end{equation} where $|\alpha|>1$ , $Z_i$ is a sequence of integrable random variables, and $u_j$ is i.i.d. with mean 0 and variance 1, it implies that \begin{equation}\tag{2} \frac{Z_{i-1}^2}{2+Z_{i-1}^2}\overset{p}\rightarrow 1 \qquad \text{as}\quad i\rightarrow\infty \end{equation} from which it follows that \begin{equation}\tag{3} \frac{1}{n}\sum_{i=1}^{n}\frac{Z_{i-1}^2}{2+Z_{i-1}^2}\overset{p}\rightarrow 1 \qquad \text{as}\quad n\rightarrow\infty. \end{equation} $\quad$ If anyone has any clue about this please could you share it with me? Thanks in advance.","I was reading a proof in a paper and got stuck at the following. Have been trying by best to figure this out for a long time but had no luck. It says: When we have where , is a sequence of integrable random variables, and is i.i.d. with mean 0 and variance 1, it implies that from which it follows that If anyone has any clue about this please could you share it with me? Thanks in advance.","\begin{equation}\tag{1}
\frac{1}{{\alpha}^{i-2}}Z_{i-1}\overset{d}\rightarrow\sum_{j=1}^{\infty}\alpha^{1-j}u_j\qquad \text{as}\quad i\rightarrow\infty
\end{equation} |\alpha|>1 Z_i u_j \begin{equation}\tag{2}
\frac{Z_{i-1}^2}{2+Z_{i-1}^2}\overset{p}\rightarrow 1 \qquad \text{as}\quad i\rightarrow\infty
\end{equation} \begin{equation}\tag{3}
\frac{1}{n}\sum_{i=1}^{n}\frac{Z_{i-1}^2}{2+Z_{i-1}^2}\overset{p}\rightarrow 1 \qquad \text{as}\quad n\rightarrow\infty.
\end{equation} \quad",['probability']
36,"Optimal positions to place 3 coins in a line such that when you keep rolling the die and increment your position, you reach a coin.","Optimal positions to place 3 coins in a line such that when you keep rolling the die and increment your position, you reach a coin.",,"You have 3 coins and a die. There is a line with positions from 1 to 1000. you need to place the coins in any of these positions in the line. from position 0,  you keep rolling the die and you jump that many steps in the line. if you reach any position with a coin in it, you win. If you cross 1000 without reaching any positions with a coin, you lose. What are the optimal positions to place the coins in the line to maximize your chance of winning the game?","You have 3 coins and a die. There is a line with positions from 1 to 1000. you need to place the coins in any of these positions in the line. from position 0,  you keep rolling the die and you jump that many steps in the line. if you reach any position with a coin in it, you win. If you cross 1000 without reaching any positions with a coin, you lose. What are the optimal positions to place the coins in the line to maximize your chance of winning the game?",,"['probability', 'combinatorics', 'optimization', 'game-theory']"
37,How to justify conclusion that a coin cannot be fair?,How to justify conclusion that a coin cannot be fair?,,"Suppose one flips a coin $N$ times, and every single time it comes out heads (H).  For some sufficiently large $N = N_0$ (10?, 20?, 100?), even someone who knows nothing of probability theory would reach the conclusion that the coin is not fair 1 . For the sake of this question, let's say that $N_0 = 20$ . Suppose that one wanted to use probability theory to justify the conclusion that the coin is not fair.  How would one do it? The argument I am familiar with goes something like this: the probability of getting $N_0 = 20$ heads out of $N_0 = 20$ flips of a fair coin is $(\frac{1}{2})^{N_0} = (\frac{1}{2})^{20} = 9.5\times 10^{-7}$ .  In other words, this result is too improbable, and therefore, we conclude that the coin must not be fair. One problem with this argument, at least the way I worded it, is that it would apply to any sequence of 20 coin flips.  For example, if the sequence of result had been the very respectable-looking HHTTHTTTHTHHTTTHTHTT instead, one could argue exactly as before: the probability of getting this sequence out of $N_0 = 20$ flips of a fair coin is $(\frac{1}{2})^{N_0} = (\frac{1}{2})^{20} = 9.5\times 10^{-7}$ ; this result is too improbable, and therefore, we conclude that the coin must not be fair. Clearly, my reasoning, or at least its wording, can't be right, since it leads to the absurd conclusion that no coin can be fair. What is the correct way to use probability theory to justify the conclusion that a coin that produces heads in every one of $N_0$ flips (for some sufficiently large $N_0$ ) must not be fair? 1 Here and elsewhere in this post, strictly speaking, instead of ""the coin is not fair"", I should have written something like ""it is very unlikely that the coin is fair,"" but I ultimately decided that this additional precision may end up derailing the discussion.  If you feel that the wording I rejected is actually essential to reason properly through the situation, please feel free use it.","Suppose one flips a coin times, and every single time it comes out heads (H).  For some sufficiently large (10?, 20?, 100?), even someone who knows nothing of probability theory would reach the conclusion that the coin is not fair 1 . For the sake of this question, let's say that . Suppose that one wanted to use probability theory to justify the conclusion that the coin is not fair.  How would one do it? The argument I am familiar with goes something like this: the probability of getting heads out of flips of a fair coin is .  In other words, this result is too improbable, and therefore, we conclude that the coin must not be fair. One problem with this argument, at least the way I worded it, is that it would apply to any sequence of 20 coin flips.  For example, if the sequence of result had been the very respectable-looking HHTTHTTTHTHHTTTHTHTT instead, one could argue exactly as before: the probability of getting this sequence out of flips of a fair coin is ; this result is too improbable, and therefore, we conclude that the coin must not be fair. Clearly, my reasoning, or at least its wording, can't be right, since it leads to the absurd conclusion that no coin can be fair. What is the correct way to use probability theory to justify the conclusion that a coin that produces heads in every one of flips (for some sufficiently large ) must not be fair? 1 Here and elsewhere in this post, strictly speaking, instead of ""the coin is not fair"", I should have written something like ""it is very unlikely that the coin is fair,"" but I ultimately decided that this additional precision may end up derailing the discussion.  If you feel that the wording I rejected is actually essential to reason properly through the situation, please feel free use it.",N N = N_0 N_0 = 20 N_0 = 20 N_0 = 20 (\frac{1}{2})^{N_0} = (\frac{1}{2})^{20} = 9.5\times 10^{-7} N_0 = 20 (\frac{1}{2})^{N_0} = (\frac{1}{2})^{20} = 9.5\times 10^{-7} N_0 N_0,"['probability', 'probability-theory']"
38,Understanding a basic ergodic theory physical analogy,Understanding a basic ergodic theory physical analogy,,"The following excerpt is from the Wikipedia article on ergodic theory : Ergodic theory is often concerned with ergodic transformations. The intuition behind such transformations, which act on a given set, is that they do a thorough job ""stirring"" the elements of that set. E.g. if the set is a quantity of hot oatmeal in a bowl, and if a spoonful of syrup is dropped into the bowl, then iterations of the inverse of an ergodic transformation of the oatmeal will not allow the syrup to remain in a local subregion of the oatmeal, but will distribute the syrup evenly throughout. At the same time, these iterations will not compress or dilate any portion of the oatmeal: they preserve the measure that is density. The formal definition is as follows: Let $ T: X \rightarrow X$ be a measure-preserving transformation on a measure space $(X, \Sigma, \mu)$ , with $\mu(X)=1$ . Then $T$ is ergodic if for every $E $ in $\Sigma$ with $\mu(T^{-1}(E) \Delta E)=0$ , either $\mu(E)=0$ or $\mu(E)=1$ , How could I formalize pouring the syrup into my oatmeal? Would I describe the oatmeal by a density function in $\mathbb{R}^n$ ? Say $\mu$ is Lebesgue measure on $\mathbb{R}^n$ , then I have some density describing the location of the oatmeal, say $\rho d\mu$ . Would the transformation be ergodic w.r.t. $$m(A) =\int_A fd\mu$$ or with resepct to $\mu$ ? When I describe the combination of the syrup and the oatmeal, would this create a new density at time $t$ ? This is confusing as I would assume the oatmeal and syrup have their own densities so I am unsure which measure the transformation is ergodic with respect to.","The following excerpt is from the Wikipedia article on ergodic theory : Ergodic theory is often concerned with ergodic transformations. The intuition behind such transformations, which act on a given set, is that they do a thorough job ""stirring"" the elements of that set. E.g. if the set is a quantity of hot oatmeal in a bowl, and if a spoonful of syrup is dropped into the bowl, then iterations of the inverse of an ergodic transformation of the oatmeal will not allow the syrup to remain in a local subregion of the oatmeal, but will distribute the syrup evenly throughout. At the same time, these iterations will not compress or dilate any portion of the oatmeal: they preserve the measure that is density. The formal definition is as follows: Let be a measure-preserving transformation on a measure space , with . Then is ergodic if for every in with , either or , How could I formalize pouring the syrup into my oatmeal? Would I describe the oatmeal by a density function in ? Say is Lebesgue measure on , then I have some density describing the location of the oatmeal, say . Would the transformation be ergodic w.r.t. or with resepct to ? When I describe the combination of the syrup and the oatmeal, would this create a new density at time ? This is confusing as I would assume the oatmeal and syrup have their own densities so I am unsure which measure the transformation is ergodic with respect to."," T: X \rightarrow X (X, \Sigma, \mu) \mu(X)=1 T E  \Sigma \mu(T^{-1}(E) \Delta E)=0 \mu(E)=0 \mu(E)=1 \mathbb{R}^n \mu \mathbb{R}^n \rho d\mu m(A) =\int_A fd\mu \mu t","['real-analysis', 'probability', 'analysis', 'measure-theory', 'ergodic-theory']"
39,Inutitive explanation for why my crude approximation of a probability approaches exactly half of the exact value,Inutitive explanation for why my crude approximation of a probability approaches exactly half of the exact value,,"First, an introductory question: There are $3n$ couples. The $6n$ people are each randomly allocated to one of three rooms, so that each room has $2n$ people. What is the probability that every couple is separated? I made a crude approximation for large $n$ : $\left(\frac{2}{3}\right)^{3n}$ , because (assuming for the sake of simplicity that each couple consists of a husband and a wife) for each husband, there is an approximately $\frac{2}{3}$ chance that his wife is in a different room. My question is: It turns out that my approximation approaches exactly half of the exact value, as $n\to\infty$ . Is there an intuitive explanation for this? In case you're interested, the exact value is $\dfrac{\binom{3n}{2n}\binom{2n}{n}2^{3n}}{\binom{6n}{2n}\binom{4n}{2n}}$ . Explanation: The denominator is the total number of ways to divide the $6n$ people into three rooms. First, among the $6n$ people, we choose $2n$ people to go to the first room, so $\binom{6n}{2n}$ . Then among the remaining $4n$ people we choose $2n$ people to go to the second room, so $\binom{4n}{2n}$ . Then the remaining $2n$ people go to the third room. The numerator is the total number of ways in which each couple is separated. First, among the $3n$ couples, we choose $2n$ couples to each be represented in the first room (one person from each couple), so $\binom{3n}{2n}$ . Then we allocate the $n$ remaining couples into the second and third rooms (each room getting one member of each of these couples), so the second room must now get an additional $n$ people, and these are chosen among the $2n$ people whose spouse went to the first room, so $\binom{2n}{n}$ . Then the remaining $n$ people go to the third room. Then each couple has two ways of being separated among two rooms, so $2^{3n}$ . It can be shown algebraically or by Wolfram that my approximation, $\left(\frac{2}{3}\right)^{3n}$ , approaches exactly half of the exact value, as $n\to\infty$ . I'm looking for an intuitive explanation. (The introductory question was inspired by this question .)","First, an introductory question: There are couples. The people are each randomly allocated to one of three rooms, so that each room has people. What is the probability that every couple is separated? I made a crude approximation for large : , because (assuming for the sake of simplicity that each couple consists of a husband and a wife) for each husband, there is an approximately chance that his wife is in a different room. My question is: It turns out that my approximation approaches exactly half of the exact value, as . Is there an intuitive explanation for this? In case you're interested, the exact value is . Explanation: The denominator is the total number of ways to divide the people into three rooms. First, among the people, we choose people to go to the first room, so . Then among the remaining people we choose people to go to the second room, so . Then the remaining people go to the third room. The numerator is the total number of ways in which each couple is separated. First, among the couples, we choose couples to each be represented in the first room (one person from each couple), so . Then we allocate the remaining couples into the second and third rooms (each room getting one member of each of these couples), so the second room must now get an additional people, and these are chosen among the people whose spouse went to the first room, so . Then the remaining people go to the third room. Then each couple has two ways of being separated among two rooms, so . It can be shown algebraically or by Wolfram that my approximation, , approaches exactly half of the exact value, as . I'm looking for an intuitive explanation. (The introductory question was inspired by this question .)",3n 6n 2n n \left(\frac{2}{3}\right)^{3n} \frac{2}{3} n\to\infty \dfrac{\binom{3n}{2n}\binom{2n}{n}2^{3n}}{\binom{6n}{2n}\binom{4n}{2n}} 6n 6n 2n \binom{6n}{2n} 4n 2n \binom{4n}{2n} 2n 3n 2n \binom{3n}{2n} n n 2n \binom{2n}{n} n 2^{3n} \left(\frac{2}{3}\right)^{3n} n\to\infty,"['probability', 'combinatorics', 'approximation', 'intuition']"
40,Expected number of fixed points of a random permutation,Expected number of fixed points of a random permutation,,"I am working on this problem and do not know how to proceed. Let $X_n$ be the number of fixed points of a given permuation of $\{1,2\dots ,n\}$ . Show that for $k\in \{1,2\dots,n\}$ , $E[X_n(X_n -1) \dots (X_n- k +1)] = 1$ . It is clear to me to show in the case of $k = n$ , but otherwise unclear. Any pointers on how to proceed?","I am working on this problem and do not know how to proceed. Let be the number of fixed points of a given permuation of . Show that for , . It is clear to me to show in the case of , but otherwise unclear. Any pointers on how to proceed?","X_n \{1,2\dots ,n\} k\in \{1,2\dots,n\} E[X_n(X_n -1) \dots (X_n- k +1)] = 1 k = n","['probability', 'probability-theory', 'probability-distributions']"
41,Proof: product of σ-algebras in separable metric spaces,Proof: product of σ-algebras in separable metric spaces,,"Let $(X_1, d_1)$ ,..., $(X_n, d_n)$ be separable metric spaces, and define $X = X_1 \times ... \times X_n$ to be the produce space with the metric $$d((x_1,...,x_n),(y_1,...,y_n)) = \sqrt{d_1^2 (x_1,y_1)+...+ d_n^2 (x_n, y_n)}$$ Prove that $\mathcal{B}(X) = \mathcal{B}(X_1) \times...\times\mathcal{B}(X_n)$ Some toolsets I have are: Definition: The $\sigma$ -algebra $\mathcal{F}_1 \times ... \times \mathcal{F}_n$ is defined as the minimal $\sigma$ -algebra which contains all the sets of the form $A_1 \times ... \times  A_n$ , where $A_i \in \mathcal{F}_i , 1 \leq i \leq n$ . If $X$ is separable, then any open set can be represented as a countable union of open balls. Thus, for a separable space $X$ , we could define the Borel $\sigma$ -algebra  of $X$ as $\sigma (\mathcal{A})$ , with $\mathcal{A}$ being the family of all open balls.","Let ,..., be separable metric spaces, and define to be the produce space with the metric Prove that Some toolsets I have are: Definition: The -algebra is defined as the minimal -algebra which contains all the sets of the form , where . If is separable, then any open set can be represented as a countable union of open balls. Thus, for a separable space , we could define the Borel -algebra  of as , with being the family of all open balls.","(X_1, d_1) (X_n, d_n) X = X_1 \times ... \times X_n d((x_1,...,x_n),(y_1,...,y_n)) = \sqrt{d_1^2 (x_1,y_1)+...+ d_n^2 (x_n, y_n)} \mathcal{B}(X) = \mathcal{B}(X_1) \times...\times\mathcal{B}(X_n) \sigma \mathcal{F}_1 \times ... \times \mathcal{F}_n \sigma A_1 \times ... \times  A_n A_i \in \mathcal{F}_i , 1 \leq i \leq n X X \sigma X \sigma (\mathcal{A}) \mathcal{A}","['probability', 'probability-theory']"
42,"If 8 people consisting of 4 couples are randomly arranged in a row, find the probability that no person is next to their partner.","If 8 people consisting of 4 couples are randomly arranged in a row, find the probability that no person is next to their partner.",,"I understand how to arrive at the correct answer using the inclusion-exclusion principle. The purpose of this post is so I can understand why the reasoning I first used is incorrect. My reasoning: there are T = 8! total ways to arrange the 8 people. Define $A_i$ to be the number of ways to arrange 8 people in a line such that exactly i of the 4 couples are seated next to each other. Since T = $\sum_{i=0}^4 A_i$ , I attempted to find $A_0$ by computing $A_1$ through $A_4$ and subtracting from T. $A_4$ : Arrange 4 couples in 4! ways, and for each couple, 2 arrangements. So $2^4$ * 4! = 384. $A_3$ : Pick 3 of the 4 couples to be seated together, each of these couples can be arranged in 2 ways, and there are 5 entities (3 couples and 2 individuals) so 5! ways to arrange the 5 entities, thus ${4 \choose 3}$ * $2^3$ * 5!. However, this has counted the ways counted in $A_4$ . So $A_3$ = ${4 \choose 3}$ * $2^3$ * 5! - $A_4$ = 3840 - 384 = 3456. $A_2$ :  Pick 2 of the 4 couples to be seated together, each of these couples can be arranged in 2 ways, and there are 6 entities (2 couples and 4 individuals) so 6! ways to arrange the 6 entities, thus ${4 \choose 2}$ * $2^2$ * 6!. But this has counted the ways counted in $A_3$ and $A_4$ , so $A_2$ = ${4 \choose 2}$ * $2^2$ * 6! - $A_3$ - $A_4$ = 17280 - 3456 - 384 = 13440. $A_1$ :  Pick 1 of the 4 couples to be seated together, the couple can be arranged in 2 ways, and there are 7 entities (1 couple and 6 individuals) so 7! ways to arrange the 7 entities, thus ${4 \choose 1}$ * $2$ * $7!$ . But this has counted the ways counted in $A_2$ and $A_3$ and $A_4$ , so $A_1$ = ${4 \choose 1}$ * $2$ * $7!$ - $A_2$ - $A_3$ - $A_4$ = 40320 - 13440 - 3456 - 384 = 23040. Now, $\sum_{i=1}^4 A_i$ = 40320 = T, implies $A_0$ = 0 which is obviously not true. Where have I gone wrong?","I understand how to arrive at the correct answer using the inclusion-exclusion principle. The purpose of this post is so I can understand why the reasoning I first used is incorrect. My reasoning: there are T = 8! total ways to arrange the 8 people. Define to be the number of ways to arrange 8 people in a line such that exactly i of the 4 couples are seated next to each other. Since T = , I attempted to find by computing through and subtracting from T. : Arrange 4 couples in 4! ways, and for each couple, 2 arrangements. So * 4! = 384. : Pick 3 of the 4 couples to be seated together, each of these couples can be arranged in 2 ways, and there are 5 entities (3 couples and 2 individuals) so 5! ways to arrange the 5 entities, thus * * 5!. However, this has counted the ways counted in . So = * * 5! - = 3840 - 384 = 3456. :  Pick 2 of the 4 couples to be seated together, each of these couples can be arranged in 2 ways, and there are 6 entities (2 couples and 4 individuals) so 6! ways to arrange the 6 entities, thus * * 6!. But this has counted the ways counted in and , so = * * 6! - - = 17280 - 3456 - 384 = 13440. :  Pick 1 of the 4 couples to be seated together, the couple can be arranged in 2 ways, and there are 7 entities (1 couple and 6 individuals) so 7! ways to arrange the 7 entities, thus * * . But this has counted the ways counted in and and , so = * * - - - = 40320 - 13440 - 3456 - 384 = 23040. Now, = 40320 = T, implies = 0 which is obviously not true. Where have I gone wrong?",A_i \sum_{i=0}^4 A_i A_0 A_1 A_4 A_4 2^4 A_3 {4 \choose 3} 2^3 A_4 A_3 {4 \choose 3} 2^3 A_4 A_2 {4 \choose 2} 2^2 A_3 A_4 A_2 {4 \choose 2} 2^2 A_3 A_4 A_1 {4 \choose 1} 2 7! A_2 A_3 A_4 A_1 {4 \choose 1} 2 7! A_2 A_3 A_4 \sum_{i=1}^4 A_i A_0,"['probability', 'combinatorics', 'statistics', 'solution-verification']"
43,What is the average of rolling two dice and only taking the value of the lower dice roll?,What is the average of rolling two dice and only taking the value of the lower dice roll?,,"My question is related to this question , with the exception that I'm looking for the average when taking only the lower of two dice rolls. My question is: What is the average of rolling two dice and only taking the value of the lower dice roll? This formula is used for the ""take higher roll"" case: $$ E[X] = \sum_{x=1}^6\frac{2(x-1)+1}{36}x = \frac{1}{36}\sum_{x=1}^6(2x^2 - x) = \frac{161}{36} \approx 4.47 $$ ...and includes the term "" $2(x−1)+1$ "". Could someone please explain how that term would have to be changed so that it applies for ""take lower roll""? From the original example, I'm somewhat confused where "" $x-1$ "" comes from, although it is mentioned in the comments. PS: I would have written this question as a comment to the original question, but I lack the points to be allowed to write comments.","My question is related to this question , with the exception that I'm looking for the average when taking only the lower of two dice rolls. My question is: What is the average of rolling two dice and only taking the value of the lower dice roll? This formula is used for the ""take higher roll"" case: ...and includes the term "" "". Could someone please explain how that term would have to be changed so that it applies for ""take lower roll""? From the original example, I'm somewhat confused where "" "" comes from, although it is mentioned in the comments. PS: I would have written this question as a comment to the original question, but I lack the points to be allowed to write comments.","
E[X] = \sum_{x=1}^6\frac{2(x-1)+1}{36}x = \frac{1}{36}\sum_{x=1}^6(2x^2 - x) = \frac{161}{36} \approx 4.47
 2(x−1)+1 x-1","['probability', 'dice']"
44,Expected value and variance of number of coin flips until two consecutive tails are flipped,Expected value and variance of number of coin flips until two consecutive tails are flipped,,"I'm working with a problem from an old exam where one had to calculate the expected value and variance of the number of throws, let's call it $N$ , before we get two tails in a row. We also assume the coin to be fair, meaning the probability of getting head and tails is just as equal. For our sake, let's also form the events $T$ for flipping a tail, and $H$ for flipping a head. In order to calculate the expected value, we need to find the pmf of our stochastic variable $N$ . This can easily be done by first examining some base cases of $p(k):=P(N=k)$ . Furthermore, we have that $V_N \in \{2,3,\dots\}$ . For $N = 2$ , $P(N=2) = P(T \cap T) = 1/4$ trivially. For $N = 3$ , $P(N=3) = P(H \cap T \cap T) = 1/8$ also trivially. From this we notice a pattern, before every ending $TT$ we have to place out a $H$ , meaning this position is always determined. For instance $N = 4$ , we have that the last three letters are $HTT$ , and for the first position, we have 2 choices, meaning $P(N=4) = 2 / 2^4 = 1/8$ So what about the case when $N = k$ ? We already know that the last three letters are determined. Meaning we have a total of $2^{k-3}$ choices left to do. But from this, we have to subtract the number of $TT$ - ""strings"" that may arise in the rest of our $k-3$ positions. However, from here, I struggle to find the number of combinations for which we don't get a $TT$ somewhere along the $k-3$ positions. I know that as soon as we get $T$ , we must choose $H$ , but as soon as we get $H$ , we have $2$ choices to make. Maybe this is a better way of tackling the problem instead of the method I used above. Still, I don't really see how to cover all the cases, and I'd be glad if anyone could share these details. Also, I'd be thankful if you didn't share a whole solution to the expected value and variance, since I'll try to solve it on my own. Thanks.","I'm working with a problem from an old exam where one had to calculate the expected value and variance of the number of throws, let's call it , before we get two tails in a row. We also assume the coin to be fair, meaning the probability of getting head and tails is just as equal. For our sake, let's also form the events for flipping a tail, and for flipping a head. In order to calculate the expected value, we need to find the pmf of our stochastic variable . This can easily be done by first examining some base cases of . Furthermore, we have that . For , trivially. For , also trivially. From this we notice a pattern, before every ending we have to place out a , meaning this position is always determined. For instance , we have that the last three letters are , and for the first position, we have 2 choices, meaning So what about the case when ? We already know that the last three letters are determined. Meaning we have a total of choices left to do. But from this, we have to subtract the number of - ""strings"" that may arise in the rest of our positions. However, from here, I struggle to find the number of combinations for which we don't get a somewhere along the positions. I know that as soon as we get , we must choose , but as soon as we get , we have choices to make. Maybe this is a better way of tackling the problem instead of the method I used above. Still, I don't really see how to cover all the cases, and I'd be glad if anyone could share these details. Also, I'd be thankful if you didn't share a whole solution to the expected value and variance, since I'll try to solve it on my own. Thanks.","N T H N p(k):=P(N=k) V_N \in \{2,3,\dots\} N = 2 P(N=2) = P(T \cap T) = 1/4 N = 3 P(N=3) = P(H \cap T \cap T) = 1/8 TT H N = 4 HTT P(N=4) = 2 / 2^4 = 1/8 N = k 2^{k-3} TT k-3 TT k-3 T H H 2","['probability', 'expected-value', 'variance']"
45,Probability of failure of first unit provided that at least one of the two units has failed,Probability of failure of first unit provided that at least one of the two units has failed,,"The following question was asked in JEE Main 2021: An electric instrument consists of two units. Each unit must function independently for the instrument to operate. The probability that the first unit functions is $0.9$ and that of the second unit is $0.8$ . The instrument is switched on and it fails to operate. If the probability that only the first unit failed and second unit is functioning is $p$ , then $98p$ is equal to: My attempt: Let us call the event of the first unit not functioning $A$ and the second unit not functioning $B$ . Let the event of failure of the instrument be $F$ . Then $P(F) = 1 - 0.8 \times 0.9 = 0.28$ . From Bayes' Theorem: $$P(A|F) = \frac{P(F|A) P(A)}{P(F)} = \frac{1 \times 0.1}{0.28}$$ $$P(B|F) = \frac{P(F|B) P(B)}{P(F)} = \frac{1 \times 0.2}{0.28}$$ Hence, $$p = P(A|F) \times (1 - P(B|F)) = \frac{10}{98}$$ And the answer should be $98p = 10$ . However, the given answer is: $28$ Where did I go wrong? The solution given by many websites online is: $$p = \frac{P(A) \times (1 - P(B))}{P(F)} = \frac{28}{98}$$ Although this arrives at the correct answer, this method is not really convincing, and my method seems to be the right method to me. However, I can't arrive at what exactly is wrong in this solution (or mine).","The following question was asked in JEE Main 2021: An electric instrument consists of two units. Each unit must function independently for the instrument to operate. The probability that the first unit functions is and that of the second unit is . The instrument is switched on and it fails to operate. If the probability that only the first unit failed and second unit is functioning is , then is equal to: My attempt: Let us call the event of the first unit not functioning and the second unit not functioning . Let the event of failure of the instrument be . Then . From Bayes' Theorem: Hence, And the answer should be . However, the given answer is: Where did I go wrong? The solution given by many websites online is: Although this arrives at the correct answer, this method is not really convincing, and my method seems to be the right method to me. However, I can't arrive at what exactly is wrong in this solution (or mine).",0.9 0.8 p 98p A B F P(F) = 1 - 0.8 \times 0.9 = 0.28 P(A|F) = \frac{P(F|A) P(A)}{P(F)} = \frac{1 \times 0.1}{0.28} P(B|F) = \frac{P(F|B) P(B)}{P(F)} = \frac{1 \times 0.2}{0.28} p = P(A|F) \times (1 - P(B|F)) = \frac{10}{98} 98p = 10 28 p = \frac{P(A) \times (1 - P(B))}{P(F)} = \frac{28}{98},"['probability', 'conditional-probability', 'bayes-theorem']"
46,"Let two subsets $P,Q$ be selected from the set $A=\{1,2,3,4,5\}$. Find the probability... [duplicate]",Let two subsets  be selected from the set . Find the probability... [duplicate],"P,Q A=\{1,2,3,4,5\}","This question already has an answer here : counting order pairs (A,B) (1 answer) Closed 2 years ago . Let two subsets $P,Q$ be selected from the set $A=\{1,2,3,4,5\}$ . Find the probability that A) $P\cap Q=\phi$ B) $P\cup Q=A$ C) $P\cap Q$ contains exactly one element My Attempt: For part A), each element has $3$ options. It can either go to $P$ or to $Q$ or to neither. So, total cases $=3^5$ Cases involving $P\cap Q$ can be: $^5C_0(^5C_0+...^5C_5)+^5C_1(^4C_0+...^4C_4)+^5C_2(^3C_0+...^3C_3)+^5C_3(^2C_0+...^2C_2)+^5C_4(^1C_0+^1C_1)+^5C_5(^5C_0)=2^5+5(2^4)+10(2^3)+10(2^2)+5(2)+1$ Is this correct? Is there an easier way to solve it? For part $B),$ each element has just two options. So, total cases $=2^5$ So, favorable cases $=^5C_0(^5C_5)+^5C_1(^4C_4+^5C_5)+^5C_2(^3C_3+^4C_4+^5C_5)+...+^5C_5(^5C_0+^5C_1+...+^5C_5)$ Or, maybe $^5C_0(^5C_5)+^5C_1(^5C_4+^5C_5)+^5C_2(^5C_3+^5C_4+^5C_5)+...+^5C_5(^5C_0+^5C_1+...+^5C_5)$ Not sure which one to go with. For part $C)$ , maybe we can take $^5C_1$ . This element would be in the intersection and for the remaining $4$ elements, we can approach like in part $A)$ ?","This question already has an answer here : counting order pairs (A,B) (1 answer) Closed 2 years ago . Let two subsets be selected from the set . Find the probability that A) B) C) contains exactly one element My Attempt: For part A), each element has options. It can either go to or to or to neither. So, total cases Cases involving can be: Is this correct? Is there an easier way to solve it? For part each element has just two options. So, total cases So, favorable cases Or, maybe Not sure which one to go with. For part , maybe we can take . This element would be in the intersection and for the remaining elements, we can approach like in part ?","P,Q A=\{1,2,3,4,5\} P\cap Q=\phi P\cup Q=A P\cap Q 3 P Q =3^5 P\cap Q ^5C_0(^5C_0+...^5C_5)+^5C_1(^4C_0+...^4C_4)+^5C_2(^3C_0+...^3C_3)+^5C_3(^2C_0+...^2C_2)+^5C_4(^1C_0+^1C_1)+^5C_5(^5C_0)=2^5+5(2^4)+10(2^3)+10(2^2)+5(2)+1 B), =2^5 =^5C_0(^5C_5)+^5C_1(^4C_4+^5C_5)+^5C_2(^3C_3+^4C_4+^5C_5)+...+^5C_5(^5C_0+^5C_1+...+^5C_5) ^5C_0(^5C_5)+^5C_1(^5C_4+^5C_5)+^5C_2(^5C_3+^5C_4+^5C_5)+...+^5C_5(^5C_0+^5C_1+...+^5C_5) C) ^5C_1 4 A)","['probability', 'combinatorics', 'combinations']"
47,How to calculate odds in finance,How to calculate odds in finance,,"I'm studying both Financial Math and Statistics , and it came to my mind how could one interrelate them. So I thought in an example and started to scribble: Given two business operation, the first one with 80% of sucess and 5% interest rate per month ; the second one with 95% of sucess and 1,5% interest rate per month . Considering that if the operation fails, no money is lost , which one is more likely profitable at medium term (10 months)? The first one: $$M = x\cdot(1+0,05)^{10}$$ $$M = 1,63x$$ $$Odds = (\frac{80}{100})^{10} = 10,47\%$$ The second one: $$M = x\cdot(1+0,015)^{10}$$ $$M = 1,16x$$ $$Odds = (\frac{95}{100})^{10} = 59,87\%$$ In the first operation , the most probable case is 10,47% of earning 63% income ; while in the second operation , the most probable case is 59,87% of earning 16% income . But it seems that analysis is not fair, as both have different chances, so I thought that in order to make it pair, I should calculate the odds of the first operation (as it haves more income) to have same income as the second one. $$(1+0,05)^x = 1,16$$ $$log\;1,05^x = log\;1,16$$ $$x = \frac{log\;1,16}{log\;1,05}$$ $$x = 3,042 \approx 3$$ It has to be a success 3 times to produce the same result, and the odds are: $$Odds = (\frac{80}{100})^{3} = 51,2\%$$ My questions are: 1 - Is this analysis logical and coherent? 2 - Is it right to assume that the second case is statistically a better choice? 3 - How can this extend into a case that considers money lost at failure?","I'm studying both Financial Math and Statistics , and it came to my mind how could one interrelate them. So I thought in an example and started to scribble: Given two business operation, the first one with 80% of sucess and 5% interest rate per month ; the second one with 95% of sucess and 1,5% interest rate per month . Considering that if the operation fails, no money is lost , which one is more likely profitable at medium term (10 months)? The first one: The second one: In the first operation , the most probable case is 10,47% of earning 63% income ; while in the second operation , the most probable case is 59,87% of earning 16% income . But it seems that analysis is not fair, as both have different chances, so I thought that in order to make it pair, I should calculate the odds of the first operation (as it haves more income) to have same income as the second one. It has to be a success 3 times to produce the same result, and the odds are: My questions are: 1 - Is this analysis logical and coherent? 2 - Is it right to assume that the second case is statistically a better choice? 3 - How can this extend into a case that considers money lost at failure?","M = x\cdot(1+0,05)^{10} M = 1,63x Odds = (\frac{80}{100})^{10} = 10,47\% M = x\cdot(1+0,015)^{10} M = 1,16x Odds = (\frac{95}{100})^{10} = 59,87\% (1+0,05)^x = 1,16 log\;1,05^x = log\;1,16 x = \frac{log\;1,16}{log\;1,05} x = 3,042 \approx 3 Odds = (\frac{80}{100})^{3} = 51,2\%","['probability', 'statistics', 'finance']"
48,Probability for any ball to be picked X times.,Probability for any ball to be picked X times.,,"My team member and I came across a problem in a non-Math-related research area. I am paraphrasing the problem here in order to seek your help: There are 10000 different numbered balls in a bowl. Each time, 10 balls are picked at random from the bowl and put back into the bowl. This process is repeated 5 times. What is the probability that at least one numbered ball is picked at least 3 times? Our first idea is to use cumulative Binomial probability to find the probability that a particular ball is picked more than 2 times. But this only gives the probability from the ""perspective of a single ball"". How can we expand this to seek the answer we need? We highly appreciate any help regarding this.","My team member and I came across a problem in a non-Math-related research area. I am paraphrasing the problem here in order to seek your help: There are 10000 different numbered balls in a bowl. Each time, 10 balls are picked at random from the bowl and put back into the bowl. This process is repeated 5 times. What is the probability that at least one numbered ball is picked at least 3 times? Our first idea is to use cumulative Binomial probability to find the probability that a particular ball is picked more than 2 times. But this only gives the probability from the ""perspective of a single ball"". How can we expand this to seek the answer we need? We highly appreciate any help regarding this.",,"['probability', 'permutations', 'combinations']"
49,"Bounding variance with mean for a $[0,1]$ random variable",Bounding variance with mean for a  random variable,"[0,1]","There is this inequality that I found in an article, which looks like folklore as for how its presented, or something that should be easily seen by the reader. I havent been able to wrap my head around it though. The inequality is the following $$\operatorname{Var}_{\mu} (f) \leq \frac{1}{2} \mu ( | f - \mu (f) |) $$ $\mu$ being a probability measure, so $\mu(f) $ standing for $f$ 's expected value with respect to $\mu$ , and $f$ being a random variable taking values in $[0,1] $ . Does anyone know how to see this? I remember having figured it out some time ago but now I dont see it no more..  Ive got the feeling that it should be something actually measure theoretic and not something following just from an inequality that holds for the function being integrated. Thanks in advance for any answer!","There is this inequality that I found in an article, which looks like folklore as for how its presented, or something that should be easily seen by the reader. I havent been able to wrap my head around it though. The inequality is the following being a probability measure, so standing for 's expected value with respect to , and being a random variable taking values in . Does anyone know how to see this? I remember having figured it out some time ago but now I dont see it no more..  Ive got the feeling that it should be something actually measure theoretic and not something following just from an inequality that holds for the function being integrated. Thanks in advance for any answer!","\operatorname{Var}_{\mu} (f) \leq \frac{1}{2} \mu ( | f - \mu (f) |)  \mu \mu(f)  f \mu f [0,1] ","['probability', 'probability-theory', 'expected-value', 'variance', 'upper-lower-bounds']"
50,Generalization of weak law of large numbers,Generalization of weak law of large numbers,,"In Exercise 5.2.12 of Chung Kai-lai's A Course in Probability Theory, there is a question: Let $\{X_n\}$ be pairwise independent with a common distribution function $F$ (namely, identically distributed) such that (i) $\displaystyle \int_{|x|\leq n}x \, dF(x)=o(1)$ , (ii) $\displaystyle n \int_{|x|>n} \, dF(x)=o(1)$ . Then $\displaystyle\frac{\sum_{j=1}^{n}X_{j}}{n}\rightarrow 0 $ in probability. From condition (i) we can get $\operatorname E(X_j)=0$ . My idea is to get a bound of $\operatorname E(X_j^2)$ but failed, and another thought is to try to construct an equivalent sequence of random variables to $\{X_n\}$ by truncating $X_n$ at $n$ as the author did in this section but also failed. The problem is that I don't know how to apply condition (ii) and find no way to understand it. Can someone give me some hint on the interpretation of (ii) or some method to get the result? Thanks in advance!","In Exercise 5.2.12 of Chung Kai-lai's A Course in Probability Theory, there is a question: Let be pairwise independent with a common distribution function (namely, identically distributed) such that (i) , (ii) . Then in probability. From condition (i) we can get . My idea is to get a bound of but failed, and another thought is to try to construct an equivalent sequence of random variables to by truncating at as the author did in this section but also failed. The problem is that I don't know how to apply condition (ii) and find no way to understand it. Can someone give me some hint on the interpretation of (ii) or some method to get the result? Thanks in advance!","\{X_n\} F \displaystyle \int_{|x|\leq n}x \, dF(x)=o(1) \displaystyle n \int_{|x|>n} \, dF(x)=o(1) \displaystyle\frac{\sum_{j=1}^{n}X_{j}}{n}\rightarrow 0  \operatorname E(X_j)=0 \operatorname E(X_j^2) \{X_n\} X_n n","['probability', 'statistics', 'law-of-large-numbers']"
51,"Why does continuity imply $P(X_i = X_j) = 0$, without integrals","Why does continuity imply , without integrals",P(X_i = X_j) = 0,"In the book A probability path , at chapter 4 integrals were not yet defined. At 4.3.1, it says Let $\{X_n, n\geq 1\}$ be iid (real random variables) with common distribution function $F(x)$ . The continuity of $F$ implies $$P[X_i = X_j] = 0$$ I'm guessing they mean for some $i\neq j$ . Intuitively sounds like that set is going to be a curve and therefore of null measure in $\mathbb{R}^2$ . Is there a simple way to prove this without using integrals?","In the book A probability path , at chapter 4 integrals were not yet defined. At 4.3.1, it says Let be iid (real random variables) with common distribution function . The continuity of implies I'm guessing they mean for some . Intuitively sounds like that set is going to be a curve and therefore of null measure in . Is there a simple way to prove this without using integrals?","\{X_n, n\geq 1\} F(x) F P[X_i = X_j] = 0 i\neq j \mathbb{R}^2","['probability', 'random-variables']"
52,Combinatorial identity on decreasing dice throws,Combinatorial identity on decreasing dice throws,,"Suppose I repeatedly throw fair $n$ -sided dice until I throw a $1$ , at which point I stop. I want to know the probability $p(n)$ that my sequence of throws will be decreasing, such as $5-4-2-1$ or just $1$ immediately, but not $2-3-1$ which would count as a failure. The answer clearly depends on whether I am considering strictly decreasing sequences in which case $4-2-2-1$ would count as a failure, or weakly decreasing sequences in which case it would be a success. Allowing weakly decreasing sequences would increase the probability and would mean there is no bound on the potential length of successful sequences. For strictly decreasing sequences I have $$p_s(n)=\sum\limits_{k=1}^n {n-1 \choose k-1}\frac{1}{n^k} = \frac{(n+1)^{n-1}}{n^n}$$ For weakly decreasing sequences and $n>1$ I have $$p_w(n)=\sum\limits_{k=1}^\infty {n+k-3 \choose k-1}\frac{1}{n^k} = \frac{n^{n-2}}{(n-1)^{n-1}}$$ For example with $n=6$ , I get $p_s(6)=\frac{7^5}{6^6}\approx 0.36023$ and $p_w(6)=\frac{6^4}{5^5}\approx 0.41472$ . In general $$p_s(n)=p_w(n+1).$$ Is there a combinatorial argument that leads to this equality between the finite sum and the infinite sum?","Suppose I repeatedly throw fair -sided dice until I throw a , at which point I stop. I want to know the probability that my sequence of throws will be decreasing, such as or just immediately, but not which would count as a failure. The answer clearly depends on whether I am considering strictly decreasing sequences in which case would count as a failure, or weakly decreasing sequences in which case it would be a success. Allowing weakly decreasing sequences would increase the probability and would mean there is no bound on the potential length of successful sequences. For strictly decreasing sequences I have For weakly decreasing sequences and I have For example with , I get and . In general Is there a combinatorial argument that leads to this equality between the finite sum and the infinite sum?",n 1 p(n) 5-4-2-1 1 2-3-1 4-2-2-1 p_s(n)=\sum\limits_{k=1}^n {n-1 \choose k-1}\frac{1}{n^k} = \frac{(n+1)^{n-1}}{n^n} n>1 p_w(n)=\sum\limits_{k=1}^\infty {n+k-3 \choose k-1}\frac{1}{n^k} = \frac{n^{n-2}}{(n-1)^{n-1}} n=6 p_s(6)=\frac{7^5}{6^6}\approx 0.36023 p_w(6)=\frac{6^4}{5^5}\approx 0.41472 p_s(n)=p_w(n+1).,"['probability', 'combinatorics', 'dice', 'combinatorial-proofs']"
53,Intuition behind the coupon collector problem. Is there inclusion-exclusion principle in play?,Intuition behind the coupon collector problem. Is there inclusion-exclusion principle in play?,,"As well-known the expected number of coupons $N$ required to collect the complete set of $n$ coupons in the general case of non-uniform probability distribution can be computed as: $$ \mathbb E (N)=\sum_i\frac1{p_i}-\sum_{(i,j)}\frac1{p_i+p_j}+\sum_{(i,j,k)}\frac1{p_i+p_j+p_k}-\cdots-\frac{(-1)^n}{\underbrace{p_1+p_2+\cdots+p_n}_{=1}},\tag1 $$ where $p_i$ is the probability to obtain $i$ -th coupon. My question is: can this pattern be explained on the basis of the inclusion-exclusion principle? It really strikes that the first term $\frac1{p_i}$ is nothing else as the expected number of coupons till obtaining the $i$ -th coupon, next term $\frac1{p_i+p_j}$ is the expected number of coupons till obtaining the $i$ -th or the $j$ -th coupon and so on. I am looking for intuitively understandable explanation which would be consistent with the above interpretation of the separate terms. I would appreciate any hint.","As well-known the expected number of coupons required to collect the complete set of coupons in the general case of non-uniform probability distribution can be computed as: where is the probability to obtain -th coupon. My question is: can this pattern be explained on the basis of the inclusion-exclusion principle? It really strikes that the first term is nothing else as the expected number of coupons till obtaining the -th coupon, next term is the expected number of coupons till obtaining the -th or the -th coupon and so on. I am looking for intuitively understandable explanation which would be consistent with the above interpretation of the separate terms. I would appreciate any hint.","N n 
\mathbb E (N)=\sum_i\frac1{p_i}-\sum_{(i,j)}\frac1{p_i+p_j}+\sum_{(i,j,k)}\frac1{p_i+p_j+p_k}-\cdots-\frac{(-1)^n}{\underbrace{p_1+p_2+\cdots+p_n}_{=1}},\tag1
 p_i i \frac1{p_i} i \frac1{p_i+p_j} i j","['probability', 'combinatorics', 'expected-value', 'inclusion-exclusion', 'coupon-collector']"
54,Conditional Probability Multivariate Question,Conditional Probability Multivariate Question,,"Two life insurance policies, each with a death benefit of 10,000 and a one-time premium of 500, are sold to a couple, one for each person. The policies will expire at the end of the 10th year. The probability that only the wife will survive at least 10 years is 0.025, the probability that only the husband will survive at least 10 years is 0.01, and the probability that both of them will survive at least 10 years is 0.96. what is the expected excess of premiums over claims, given that the husband survives at least 10 years? I understood that it was a conditional probability problem but I tried to solve it a different way and I'm not sure where my thinking is wrong. Here's what I tried: X: wife survives 10 years, Y: husband survives 10 years Since we are assuming the husband survives the 10 years, I disregarded the probability that only the wife survives the 10 years. -(Premium for both policies) + (Death Benefit For One) * (Probability Only Husband Survives) + (No Death Benefit) * (Probability Husband and Wife Both Survive) $$-1000 + 10000\times P(X' \cap Y) +0\times P(X \cap Y)$$ I have the solution so I know how to ""correctly"" solve it, I'm just confused about why this method I tried won't work. Thanks in advance!","Two life insurance policies, each with a death benefit of 10,000 and a one-time premium of 500, are sold to a couple, one for each person. The policies will expire at the end of the 10th year. The probability that only the wife will survive at least 10 years is 0.025, the probability that only the husband will survive at least 10 years is 0.01, and the probability that both of them will survive at least 10 years is 0.96. what is the expected excess of premiums over claims, given that the husband survives at least 10 years? I understood that it was a conditional probability problem but I tried to solve it a different way and I'm not sure where my thinking is wrong. Here's what I tried: X: wife survives 10 years, Y: husband survives 10 years Since we are assuming the husband survives the 10 years, I disregarded the probability that only the wife survives the 10 years. -(Premium for both policies) + (Death Benefit For One) * (Probability Only Husband Survives) + (No Death Benefit) * (Probability Husband and Wife Both Survive) I have the solution so I know how to ""correctly"" solve it, I'm just confused about why this method I tried won't work. Thanks in advance!",-1000 + 10000\times P(X' \cap Y) +0\times P(X \cap Y),"['probability', 'conditional-probability', 'actuarial-science']"
55,Monty Hall Problem with Multiple Players?,Monty Hall Problem with Multiple Players?,,"I understand the common Monty Hall Problem and why switching provides a 2/3 chance of winning, but I'm having trouble wrapping my head around how the probabilities work when multiple players are involved, as their probabilities seem to be contradictory. Let's say we have two players and four doors. Each door has a 1/4 probability of hiding a prize. Let's say contestant 1 chooses door A and contestant 2 chooses door B. Door D is then revealed to be empty, leaving A, B, and C. From contestant 1's perspective the odds are 1/4 for door A, 3/8 for door B, and 3/8 for door C. But from contestant 2's perspective the odds are 3/8 for door A, 1/4 for door B, and 3/8 for door C. What are the actual odds for each door hiding the prize, does it change depending on if they know each other's choices, and does it differ from the normal example of the problem? If so why, and if not, why not?","I understand the common Monty Hall Problem and why switching provides a 2/3 chance of winning, but I'm having trouble wrapping my head around how the probabilities work when multiple players are involved, as their probabilities seem to be contradictory. Let's say we have two players and four doors. Each door has a 1/4 probability of hiding a prize. Let's say contestant 1 chooses door A and contestant 2 chooses door B. Door D is then revealed to be empty, leaving A, B, and C. From contestant 1's perspective the odds are 1/4 for door A, 3/8 for door B, and 3/8 for door C. But from contestant 2's perspective the odds are 3/8 for door A, 1/4 for door B, and 3/8 for door C. What are the actual odds for each door hiding the prize, does it change depending on if they know each other's choices, and does it differ from the normal example of the problem? If so why, and if not, why not?",,"['probability', 'monty-hall']"
56,Expected value of sum of two dependent Binomial variables,Expected value of sum of two dependent Binomial variables,,"Question: Assume we toss a coin in two trials. In the first trial we toss it n times. In the second trial we toss it as many as the number of tails observed in the first trial. Calculate the expectation of total number of tails in both trails: Solution : This is what I have tried but can't find any closed form for the answer when n is not given. I am not sure if I have taken the right approach: $T_1$ = Number  of  tails in the 1st trial $T_2$ =  Number of tails in the 2nd trial T1 ~ Binomial(n,p) T2 ~ Binomial(T1,p) $E(T1 + T2) =  E(T1) + E(T2) = \\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n p+\sum_{i=0}^{n} E\left(T_{2} \mid T_{1}=i\right) P\left(T_{1}=i\right) =\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n p+\sum_{i=0}^{n} i p \times\left(\begin{array}{l}n \\ i\end{array}\right) p^{i}(1-p)^{n-i}$ I couldn't find any closed form for the answer. Any advice on how to approach this?","Question: Assume we toss a coin in two trials. In the first trial we toss it n times. In the second trial we toss it as many as the number of tails observed in the first trial. Calculate the expectation of total number of tails in both trails: Solution : This is what I have tried but can't find any closed form for the answer when n is not given. I am not sure if I have taken the right approach: = Number  of  tails in the 1st trial =  Number of tails in the 2nd trial T1 ~ Binomial(n,p) T2 ~ Binomial(T1,p) I couldn't find any closed form for the answer. Any advice on how to approach this?","T_1 T_2 E(T1 + T2) = 
E(T1) + E(T2) = \\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n p+\sum_{i=0}^{n} E\left(T_{2} \mid T_{1}=i\right) P\left(T_{1}=i\right) =\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n p+\sum_{i=0}^{n} i p \times\left(\begin{array}{l}n \\ i\end{array}\right) p^{i}(1-p)^{n-i}","['probability', 'expected-value', 'conditional-expectation', 'binomial-distribution']"
57,Probability of forming triangle from breaking a stick,Probability of forming triangle from breaking a stick,,"Given a stick and break it randomly at two places, what is the probability that you can form a triangle from the pieces? Here is my attempt and the answer does not match, so I am confused what went wrong with this argument. I first denote the two randomly chosen positions by $X$ and $Y$ , and let $A=\max(X,Y)$ , $B=\min(X,Y)$ . We are interested in the probability of the event $\{A>\frac{1}{2}, B>A-\frac{1}{2}\}$ . Thus, we want the joint distribution of $A$ and $B$ . To compute that, I computed $$F_{A,B}(w,z)=\mathbb{P}(A\leq w, B\leq z)=\mathbb{P}(A\leq w)-\mathbb{P}(A\leq w, B>z)=\mathbb{P}(X\leq w,Y\leq w)-\mathbb{P}(X\leq w, Y\leq w, X>z, Y>z)$$ Therefore, we have if $z\leq w$ $$F_{A,B}(w,z)=w^2-(w-z)^2$$ otherwise $$F_{A,B}(w,z)=w^2$$ Then the joint density of $A$ and $B$ is $$f_{A,B}(w,z)=\frac{\partial^2 F}{\partial w\partial z}(w,z)=2$$ if $z\leq w$ and $0$ otherwise. Finally $$\mathbb{P}(A>\frac{1}{2},B>A-\frac{1}{2})=\int_{\frac{1}{2}}^1\int_{w-\frac{1}{2}}^w2dzdw=\frac{1}{2}$$ The answer is $\frac{1}{4}$ instead, but I can't figure out what went wrong with this argument.","Given a stick and break it randomly at two places, what is the probability that you can form a triangle from the pieces? Here is my attempt and the answer does not match, so I am confused what went wrong with this argument. I first denote the two randomly chosen positions by and , and let , . We are interested in the probability of the event . Thus, we want the joint distribution of and . To compute that, I computed Therefore, we have if otherwise Then the joint density of and is if and otherwise. Finally The answer is instead, but I can't figure out what went wrong with this argument.","X Y A=\max(X,Y) B=\min(X,Y) \{A>\frac{1}{2}, B>A-\frac{1}{2}\} A B F_{A,B}(w,z)=\mathbb{P}(A\leq w, B\leq z)=\mathbb{P}(A\leq w)-\mathbb{P}(A\leq w, B>z)=\mathbb{P}(X\leq w,Y\leq w)-\mathbb{P}(X\leq w, Y\leq w, X>z, Y>z) z\leq w F_{A,B}(w,z)=w^2-(w-z)^2 F_{A,B}(w,z)=w^2 A B f_{A,B}(w,z)=\frac{\partial^2 F}{\partial w\partial z}(w,z)=2 z\leq w 0 \mathbb{P}(A>\frac{1}{2},B>A-\frac{1}{2})=\int_{\frac{1}{2}}^1\int_{w-\frac{1}{2}}^w2dzdw=\frac{1}{2} \frac{1}{4}",['probability']
58,What is the optimal strategy of guessing a number where closest without going over wins?,What is the optimal strategy of guessing a number where closest without going over wins?,,"When a group of people need to decide a winner or leader between them, one approach would be that a random hidden integer is chosen with uniform distribution on $\{0, 1, ..., n\}$ and all $p$ participants publicly choose a number. Then, the number is revealed and the participant who was the closest wins. A variant of this happens when we introduce what is informally known as the 'price is right' rule, where you only win when you aren't going over (so the one who is the closest from the bottom wins). Now I am having trouble formalizing the optimal strategy for games like this in my head, and even more so for how the rules would change when the 'price is right' variant is introduced.","When a group of people need to decide a winner or leader between them, one approach would be that a random hidden integer is chosen with uniform distribution on and all participants publicly choose a number. Then, the number is revealed and the participant who was the closest wins. A variant of this happens when we introduce what is informally known as the 'price is right' rule, where you only win when you aren't going over (so the one who is the closest from the bottom wins). Now I am having trouble formalizing the optimal strategy for games like this in my head, and even more so for how the rules would change when the 'price is right' variant is introduced.","\{0, 1, ..., n\} p","['probability', 'game-theory', 'random']"
59,Is there an optimal strategy for this game of card?,Is there an optimal strategy for this game of card?,,"This game is based on the concept of minimizing resource wastage. The Game Cards which do not have numbers are not used e.g. ace, king, queen, joker. For the remaining cards, regardless of the color and shape, the value of a card is equal to the number on it. The cards are shuffled and distributed between the two players. They get equal number of cards. In each round, both player pick a card a place it upside down on the table without showing the opponent to complete their moves. After this they show their cards to each other. The player with the bigger number on the card win the round. The points won by the round winner for this round is equal to the number on card played by the losing players card in this round. E.g if $A$ plays $6$ and $B$ plays $1$ in this round then $A$ wins the round and gets $1$ point. If the number on both cards are equal than the round is a draw and the game continues until someone wins the round or all the cards are used. The round winner get the points equal to the number on the last card played by the round loser. After a round is completed, the played cards are discarded and the game continues with the unused cards remaining with each player until all the cards are used At the end, the player with the greater sum of points win the game. Minimizing wastage : Clearly we want to win a round by using the smallest card. E.g. if $B$ plays $1$ then $A$ will win the round and get $1$ point if he/she puts any card from $2$ to $10$ . But playing a $10$ to win $1$ point is a waste as $10$ can be played to win against bigger numbers later in the match. However before showing, neither player knows what card was played by the opponent. One may argue that if a player uses up the big cards in the beginning to make small win, it may leave him/her weaker in the later rounds. But using bigger cards in the beginning, leaves the player with smaller cards which leaves the opponent less scope to win more points. Question : Is there a mathematically optimal strategy that maximizes the chances of winning? Note : One of the reason why poker is considered a sport as opposed to gambling is because is proven to be a game of strategy and chance and not chance alone.","This game is based on the concept of minimizing resource wastage. The Game Cards which do not have numbers are not used e.g. ace, king, queen, joker. For the remaining cards, regardless of the color and shape, the value of a card is equal to the number on it. The cards are shuffled and distributed between the two players. They get equal number of cards. In each round, both player pick a card a place it upside down on the table without showing the opponent to complete their moves. After this they show their cards to each other. The player with the bigger number on the card win the round. The points won by the round winner for this round is equal to the number on card played by the losing players card in this round. E.g if plays and plays in this round then wins the round and gets point. If the number on both cards are equal than the round is a draw and the game continues until someone wins the round or all the cards are used. The round winner get the points equal to the number on the last card played by the round loser. After a round is completed, the played cards are discarded and the game continues with the unused cards remaining with each player until all the cards are used At the end, the player with the greater sum of points win the game. Minimizing wastage : Clearly we want to win a round by using the smallest card. E.g. if plays then will win the round and get point if he/she puts any card from to . But playing a to win point is a waste as can be played to win against bigger numbers later in the match. However before showing, neither player knows what card was played by the opponent. One may argue that if a player uses up the big cards in the beginning to make small win, it may leave him/her weaker in the later rounds. But using bigger cards in the beginning, leaves the player with smaller cards which leaves the opponent less scope to win more points. Question : Is there a mathematically optimal strategy that maximizes the chances of winning? Note : One of the reason why poker is considered a sport as opposed to gambling is because is proven to be a game of strategy and chance and not chance alone.",A 6 B 1 A 1 B 1 A 1 2 10 10 1 10,"['probability', 'optimization', 'recreational-mathematics', 'game-theory', 'card-games']"
60,"Expected number of people having X tickets, given Y tickets distributed among Z people","Expected number of people having X tickets, given Y tickets distributed among Z people",,"I have had this problem when trying to describe this probability, and I do not know what it's called or how to solve it. Example: 100 (Y) tickets are randomly distributed to 100 (Z) people, each is independent, people can get multiple tickets. The expected number of tickets for any one person is 1, of course, but it will not be distributed that way. It is more likely that some people will get 0 tickets, some will get 2, 3, 4, and so on. So what is the expected number of people who have exactly a particular number (X) of tickets? I know that number will likely be a decimal. On the same subject, it would be nice to know if the same technique can be used to calculate a range of tickets i.e. ""expected number of people who have 3 or more tickets"".","I have had this problem when trying to describe this probability, and I do not know what it's called or how to solve it. Example: 100 (Y) tickets are randomly distributed to 100 (Z) people, each is independent, people can get multiple tickets. The expected number of tickets for any one person is 1, of course, but it will not be distributed that way. It is more likely that some people will get 0 tickets, some will get 2, 3, 4, and so on. So what is the expected number of people who have exactly a particular number (X) of tickets? I know that number will likely be a decimal. On the same subject, it would be nice to know if the same technique can be used to calculate a range of tickets i.e. ""expected number of people who have 3 or more tickets"".",,"['probability', 'probability-distributions']"
61,Expected number of ﬂips needed that at least two heads and one tail have been ﬂipped,Expected number of ﬂips needed that at least two heads and one tail have been ﬂipped,,"The original question is shown below (References from the book of Introduction to Probability Models Tenth Edition): A coin, having probability $p$ of landing heads, is continually ﬂipped until at least one head and one tail have been ﬂipped. (a) Find the expected number of ﬂips needed. (d) Repeat part (a) in the case where ﬂipping is continued until a total of at least two heads and one tail have been ﬂipped. I solve the question (a), but I am not sure my answer for question (d). My answer is shown: Let $N$ is the number of flips at least two head and one tail. $$ \begin{align*} E[N] &= E[E[N|Y]]\\ &= E[N|HH]P(H)P(H) + E[N|HT]P(H)P(T) + E[N|TH]P(T)P(H) \end{align*} $$ $E[N|HH]$ means the first two are heads until a tail appeared; $E[N|HT]$ means the first two are head and tail until a head appeared; $E[N|TH]$ means the first two are head and tail a head appeared; Let $E[T] = 1/q = 1/1-p$ , $E[H] = 1/p$ Then, $E[N] = (2+1/q)pp + (2+1/p)p(1-p) + (2+1/p)p(1-p)$ ←Ans. I am not sure whether I am right? Thanks a lot.","The original question is shown below (References from the book of Introduction to Probability Models Tenth Edition): A coin, having probability of landing heads, is continually ﬂipped until at least one head and one tail have been ﬂipped. (a) Find the expected number of ﬂips needed. (d) Repeat part (a) in the case where ﬂipping is continued until a total of at least two heads and one tail have been ﬂipped. I solve the question (a), but I am not sure my answer for question (d). My answer is shown: Let is the number of flips at least two head and one tail. means the first two are heads until a tail appeared; means the first two are head and tail until a head appeared; means the first two are head and tail a head appeared; Let , Then, ←Ans. I am not sure whether I am right? Thanks a lot.","p N 
\begin{align*}
E[N] &= E[E[N|Y]]\\ &= E[N|HH]P(H)P(H) + E[N|HT]P(H)P(T) + E[N|TH]P(T)P(H)
\end{align*}
 E[N|HH] E[N|HT] E[N|TH] E[T] = 1/q = 1/1-p E[H] = 1/p E[N] = (2+1/q)pp + (2+1/p)p(1-p) + (2+1/p)p(1-p)","['probability', 'expected-value']"
62,Kolmogorov’s Three-Series Theorem,Kolmogorov’s Three-Series Theorem,,"Consider the sequence r.v. $X_i's, i \geq 2$ , $$P(X_i = i^2) = P(X_i = -i^2) = 1/i^2 \ \text{and} \ P(X_i = (-1)^i) = 1- 2/i^2.$$ Consider $S_n = \sum_{i=2}^{n}X_i$ . What is the almost sure limit of $S_n/n$ as $n \rightarrow \infty$ ? I have tried to truncate $X_i$ as defining $Y_i = X_i \boldsymbol{1}_{[|X_i| \leq 1]}$ . However, not sure how to find the limit and prove $S_n/n$ converges almost surely.","Consider the sequence r.v. , Consider . What is the almost sure limit of as ? I have tried to truncate as defining . However, not sure how to find the limit and prove converges almost surely.","X_i's, i \geq 2 P(X_i = i^2) = P(X_i = -i^2) = 1/i^2 \ \text{and} \ P(X_i = (-1)^i) = 1- 2/i^2. S_n = \sum_{i=2}^{n}X_i S_n/n n \rightarrow \infty X_i Y_i = X_i \boldsymbol{1}_{[|X_i| \leq 1]} S_n/n","['real-analysis', 'probability', 'probability-theory', 'measure-theory', 'borel-cantelli-lemmas']"
63,What is the probability of randomly generating a tautology?,What is the probability of randomly generating a tautology?,,"Suppose we randomly generate a classical Hilbert propositional calculus formula $F$ with $n$ variables, using the following method: $F = x_i$ for each of $i \leq n$ with probability $\frac{1}{n+2}$ . $F = \neg F_1$ , where $F_1$ is generated independently using the same method. $F = F_1 \to F_2$ , where $F_1$ and $F_2$ are generated independently using the same method. It follows from the extinction criterion for the Galton-Watson branching processes , that the process of generation will terminate with probability $1$ and thus our random formula is well defined. My question is: What is the probability that $F$ is a tautology? It is clearly less, than $\frac{2}{n+2}$ . However, it is clearly greater, than $\frac{n}{(n + 2)^3}$ which is the probability of generating a formula of the form $x_i \to x_i$ .","Suppose we randomly generate a classical Hilbert propositional calculus formula with variables, using the following method: for each of with probability . , where is generated independently using the same method. , where and are generated independently using the same method. It follows from the extinction criterion for the Galton-Watson branching processes , that the process of generation will terminate with probability and thus our random formula is well defined. My question is: What is the probability that is a tautology? It is clearly less, than . However, it is clearly greater, than which is the probability of generating a formula of the form .",F n F = x_i i \leq n \frac{1}{n+2} F = \neg F_1 F_1 F = F_1 \to F_2 F_1 F_2 1 F \frac{2}{n+2} \frac{n}{(n + 2)^3} x_i \to x_i,"['probability', 'logic', 'stochastic-processes', 'propositional-calculus', 'hilbert-calculus']"
64,"Gaussian binomial coefficients, lattice paths, and vector spaces","Gaussian binomial coefficients, lattice paths, and vector spaces",,"The Gaussian binomial coefficient ${n+k \choose k}_q$ gives a probability generating function for the number of lattice paths from $(0,0)$ to $(n,k)$ enclosing an area $a$ in the upper-right quadrant i.e. this count is given by the coefficient of $q^a$ in the corresponding series expansion of ${n+k \choose k}_q$ . For example, the number of lattice paths in the $10 \times 10$ box between the bottom left and top right corners is ${20 \choose 10}$ , and those which enclose an area of 8 is the coefficient of $q^8$ in the corresponding series $${20 \choose 10}_q = 1 + q + 2 q^2 + 3 q^3 + 5 q^4 + \dots +2 q^{98} + q^{99} + q^{100}$$ which happens to be 22. The Gaussian coefficient ${n+k \choose k}_q$ also counts the number of $k$ -dimensional vector subspaces of an $n+k$ -dimensional vector space over $F_q$ . What is the relation here? Is the vector space interpretation also somehow a generalisation of the notion of partitioning something under a set of constraints (here, into $k$ parts no larger than $n$ )? What, for example, does the lattice path generating function 'mean' when we set $q \neq 1$ ?","The Gaussian binomial coefficient gives a probability generating function for the number of lattice paths from to enclosing an area in the upper-right quadrant i.e. this count is given by the coefficient of in the corresponding series expansion of . For example, the number of lattice paths in the box between the bottom left and top right corners is , and those which enclose an area of 8 is the coefficient of in the corresponding series which happens to be 22. The Gaussian coefficient also counts the number of -dimensional vector subspaces of an -dimensional vector space over . What is the relation here? Is the vector space interpretation also somehow a generalisation of the notion of partitioning something under a set of constraints (here, into parts no larger than )? What, for example, does the lattice path generating function 'mean' when we set ?","{n+k \choose k}_q (0,0) (n,k) a q^a {n+k \choose k}_q 10 \times 10 {20 \choose 10} q^8 {20 \choose 10}_q = 1 + q + 2 q^2 + 3 q^3 + 5 q^4 + \dots +2 q^{98} + q^{99} + q^{100} {n+k \choose k}_q k n+k F_q k n q \neq 1","['probability', 'combinatorics', 'finite-fields', 'q-analogs']"
65,Probability each table leg was in each spot.,Probability each table leg was in each spot.,,"I have a fold up table at home with six legs and three areas. Each area takes 2 legs to keep the table up, but when stored three legs are positioned on the left and three on the right. Everytime I setup the table I randomly take the three legs on the left, put two on the left side and one in the middle. Then I take the three legs from the right and put two on the right and also one in the middle. When folding it up I randomly pick one leg in the middle to go left and one to go right. So basically a leg that started on the left when folded, could end up in the middle when setup and end on the right when folded again. I've setup this table maybe a hundred times and everytime I wonder ""Has each leg been in every spot (six spots when setup) at least once?"" I guess there is a 1/3 change that a leg ends up in the middle and then a 1/2 change it ends up on the other side, which by my uneducated mind results in a 16.6% probability it changes sides, but I have no idea how to go from there. If you perfectly rotate the legs around, you could get them in each spot in 6 times. But I don't know that is even relevant at all. So, what is the probability each leg has been in every spot?","I have a fold up table at home with six legs and three areas. Each area takes 2 legs to keep the table up, but when stored three legs are positioned on the left and three on the right. Everytime I setup the table I randomly take the three legs on the left, put two on the left side and one in the middle. Then I take the three legs from the right and put two on the right and also one in the middle. When folding it up I randomly pick one leg in the middle to go left and one to go right. So basically a leg that started on the left when folded, could end up in the middle when setup and end on the right when folded again. I've setup this table maybe a hundred times and everytime I wonder ""Has each leg been in every spot (six spots when setup) at least once?"" I guess there is a 1/3 change that a leg ends up in the middle and then a 1/2 change it ends up on the other side, which by my uneducated mind results in a 16.6% probability it changes sides, but I have no idea how to go from there. If you perfectly rotate the legs around, you could get them in each spot in 6 times. But I don't know that is even relevant at all. So, what is the probability each leg has been in every spot?",,['probability']
66,Analysis of longest run of heads when flipping a fair coin.,Analysis of longest run of heads when flipping a fair coin.,,"Consider a sequence of $n$ unbiased coin flips. Consider the length of the longest contiguous sequence of heads. (a) Show that you are unlikely to see a sequence of length $c + \log_2(n)$ for $c > 1$ (give a decreasing bound as a function of c). (b) Show that with high probability you will see a sequence of length $\log_2 n − O(\log_2 \log_2 n)$ . For (a) I want to use Markov's inequality to get a bound. For that, I need to find $\mathbb{E}[X]$ where $X$ is the longest run of heads after $n$ flips. I'm not sure how to get $\mathbb{E}[X]$ .","Consider a sequence of unbiased coin flips. Consider the length of the longest contiguous sequence of heads. (a) Show that you are unlikely to see a sequence of length for (give a decreasing bound as a function of c). (b) Show that with high probability you will see a sequence of length . For (a) I want to use Markov's inequality to get a bound. For that, I need to find where is the longest run of heads after flips. I'm not sure how to get .",n c + \log_2(n) c > 1 \log_2 n − O(\log_2 \log_2 n) \mathbb{E}[X] X n \mathbb{E}[X],"['probability', 'probability-theory', 'asymptotics', 'probability-limit-theorems']"
67,What is the probability that you get an increasing sequence of rolls if you roll it three times?,What is the probability that you get an increasing sequence of rolls if you roll it three times?,,"So, I know the answer to this question is: $$\frac{{6 \choose 3}}{6^{3}} = \frac{20}{216} = \frac{5}{54}$$ But I have no intuition. Why is the numerator ${6 \choose 3}$ ? Why is the numbers of ways to pick 3 from 6 equal to getting rolls in increasing order? This doesn't make sense to me that it would be that way if theres a condition that it needs to be increasing. Any help to understand this is appreciated!","So, I know the answer to this question is: But I have no intuition. Why is the numerator ? Why is the numbers of ways to pick 3 from 6 equal to getting rolls in increasing order? This doesn't make sense to me that it would be that way if theres a condition that it needs to be increasing. Any help to understand this is appreciated!",\frac{{6 \choose 3}}{6^{3}} = \frac{20}{216} = \frac{5}{54} {6 \choose 3},['probability']
68,"If $\lim A_n$ exists, then $P(\lim A_n) = \lim P(A_n)$","If  exists, then",\lim A_n P(\lim A_n) = \lim P(A_n),"Given a sequence $\{A_n\}$ of events with $\lim A_n = A$ , I would like to show that $P(\lim A_n) = \lim P(A_n)$ . $\lim A_n = A$ implies that $\limsup A_n = A$ . Thus $\bigcap \bigcup_{k=n}^{\infty}A_k=A$ Let $B_n=\bigcup_{k=n}^{\infty}A_k$ for every $n$ . Then $B_n$ is non increasing. We have: $P(\lim A_n) = P(A) = P(\bigcap \bigcup_{k=n}^{\infty}A_k)=P(\bigcap B_n) = \lim P(B_n)$ since $B_n$ non-increasing. Thus $P(\lim A_n) = \lim P(\bigcup_{k=n}^{\infty}A_k))$ . How do I go from here to $\lim P(A_n)$ ? Any hep would be greatly appreciated.","Given a sequence of events with , I would like to show that . implies that . Thus Let for every . Then is non increasing. We have: since non-increasing. Thus . How do I go from here to ? Any hep would be greatly appreciated.",\{A_n\} \lim A_n = A P(\lim A_n) = \lim P(A_n) \lim A_n = A \limsup A_n = A \bigcap \bigcup_{k=n}^{\infty}A_k=A B_n=\bigcup_{k=n}^{\infty}A_k n B_n P(\lim A_n) = P(A) = P(\bigcap \bigcup_{k=n}^{\infty}A_k)=P(\bigcap B_n) = \lim P(B_n) B_n P(\lim A_n) = \lim P(\bigcup_{k=n}^{\infty}A_k)) \lim P(A_n),"['probability', 'limits', 'probability-theory', 'limsup-and-liminf']"
69,Again boxes with marbles and strategy,Again boxes with marbles and strategy,,"Let’s consider 3 identical jewelry boxes, one with 2 green marbles, one with 2 blue marbles and last one with one green and one blue.   Before opening any box we set a target, either to pick two marbles of the same color or different. We then randomly choose a box and then a marble (without seeing its color before choosing it). We then see the color of the marble and put it back to its box. We repeat the process by picking a box (same with the previous or different) and a marble from it (again randomly). Find the probability that we succeed (i.e. if we had chosen to go for “two of the same color”, we indeed got two marbles of the same color, or, if we chose to go for two marbles of different colors, we got two different. We assume that our moves are of absolute logic. Let's assume that we choose to find two marbles of the same color.  We pick one box (probability $\frac{1}{3}$ ), say we get a green marble (is the (conditional) probability $\frac{1}{2}$ ??), then we must select either the same box again (hoping we will get a marble of the same color - blue probability $\frac{1}{2}$ ) or another box, probability $\frac{1}{2}$ for the box and probability 0 if we pick the box with the two blue marbles, 1/2 if we pick the box with 1+1 and 1 if we pick the box with the 2 green (assuming the one we chose the first time was the 1+1). By intuition only, I think that I must set the target to pick 2 marbles of the same color, as the chances for this are 2/3 overall. I don't know how to continue :(","Let’s consider 3 identical jewelry boxes, one with 2 green marbles, one with 2 blue marbles and last one with one green and one blue.   Before opening any box we set a target, either to pick two marbles of the same color or different. We then randomly choose a box and then a marble (without seeing its color before choosing it). We then see the color of the marble and put it back to its box. We repeat the process by picking a box (same with the previous or different) and a marble from it (again randomly). Find the probability that we succeed (i.e. if we had chosen to go for “two of the same color”, we indeed got two marbles of the same color, or, if we chose to go for two marbles of different colors, we got two different. We assume that our moves are of absolute logic. Let's assume that we choose to find two marbles of the same color.  We pick one box (probability ), say we get a green marble (is the (conditional) probability ??), then we must select either the same box again (hoping we will get a marble of the same color - blue probability ) or another box, probability for the box and probability 0 if we pick the box with the two blue marbles, 1/2 if we pick the box with 1+1 and 1 if we pick the box with the 2 green (assuming the one we chose the first time was the 1+1). By intuition only, I think that I must set the target to pick 2 marbles of the same color, as the chances for this are 2/3 overall. I don't know how to continue :(",\frac{1}{3} \frac{1}{2} \frac{1}{2} \frac{1}{2},"['probability', 'combinatorics']"
70,Calculation of probability. Why is my solution wrong?,Calculation of probability. Why is my solution wrong?,,"The problem (taken from Harvard Stat 110) is as follows: For a group of 7 people, find the probability that all 4 seasons   (winter, spring, summer, fall) occur at least once each among their   birthdays, assuming that all seasons are equally likely. The authors propose a solution using Inclusion-Exlusion method, which is clear for me, so I decided to try a different method, using naive definition of probability. Here's my solution: 1. Denominator, as there are $4^7$ ways to assign seasons to these people, will look as follows: $|\Omega|=4^7$ 2. To compute the numerator, we have to pick 4 people, and assign seasons to them ( $\binom{7}{4}\times4!$ ways). Then we assign seasons to the rest ( $4^3$ ways). So, numerator: $\binom{7}{4}\times4!\times4^3$ . This solution looks reasonable for me, however it's incorrect. Please, explain, why I'm wrong?","The problem (taken from Harvard Stat 110) is as follows: For a group of 7 people, find the probability that all 4 seasons   (winter, spring, summer, fall) occur at least once each among their   birthdays, assuming that all seasons are equally likely. The authors propose a solution using Inclusion-Exlusion method, which is clear for me, so I decided to try a different method, using naive definition of probability. Here's my solution: 1. Denominator, as there are ways to assign seasons to these people, will look as follows: 2. To compute the numerator, we have to pick 4 people, and assign seasons to them ( ways). Then we assign seasons to the rest ( ways). So, numerator: . This solution looks reasonable for me, however it's incorrect. Please, explain, why I'm wrong?",4^7 |\Omega|=4^7 \binom{7}{4}\times4! 4^3 \binom{7}{4}\times4!\times4^3,"['probability', 'probability-theory']"
71,"Two people drawing cards, probability of both having pairs","Two people drawing cards, probability of both having pairs",,"I have been working working on the following probability problem: Alice has a set of 52 perfectly shuffled cards, hands the first 2 cards to Bob, Alice takes the next 2 cards. Let: B:= Bob has a pair A:= Alice has a pair Calculate: $\text{Pr}[A]$ , $\text{Pr}[B]$ , $\text{Pr}[A\cap B]$ $\text{Pr}[B]$ was straight forward, $\frac{3}{51}$ . $\text{Pr}[A]$ took some thinking, but as far as I understand, the point is that handing cards to Bob and not looking at them is equal to not drawing them in the first place. Hence, $\text{Pr}[A]=\frac{3}{51}$ I am now stuck with $\text{Pr}[A\cap B]$ . The way I approached it was to use conditional probability: $\text{Pr}[A\mid B]\cdot \text{Pr}[B]$ , splitting $\text{Pr}[A\mid B]$ Alice draws the same pair as Bob Alice draws a different pair For (1), I calculated: $\frac{2}{52} \cdot \frac{1}{52}$ , because Bob has already drawn the first 2 cards, so Alice has to get exactly the remaining 2 For(2), I calculated: $12 \cdot \frac{4}{52} \cdot \frac{3}{51}$ because there are 12 other possible pairs to make s.t. it is different from Bob's pair. Hence, I am left with: $$\text{Pr}[A\mid B]\cdot \text{Pr}[B]=\left(\frac{2}{52} \cdot \frac{1}{52} + 12 \cdot \frac{4}{52} \cdot \frac{3}{51}\right) \cdot \frac{3}{51}.$$ Unfortunately, this does not agree with the solution of $\frac{73}{20825}$ . I simply cannot find the mistake, help is greatly appreciated! Thanks!","I have been working working on the following probability problem: Alice has a set of 52 perfectly shuffled cards, hands the first 2 cards to Bob, Alice takes the next 2 cards. Let: B:= Bob has a pair A:= Alice has a pair Calculate: , , was straight forward, . took some thinking, but as far as I understand, the point is that handing cards to Bob and not looking at them is equal to not drawing them in the first place. Hence, I am now stuck with . The way I approached it was to use conditional probability: , splitting Alice draws the same pair as Bob Alice draws a different pair For (1), I calculated: , because Bob has already drawn the first 2 cards, so Alice has to get exactly the remaining 2 For(2), I calculated: because there are 12 other possible pairs to make s.t. it is different from Bob's pair. Hence, I am left with: Unfortunately, this does not agree with the solution of . I simply cannot find the mistake, help is greatly appreciated! Thanks!",\text{Pr}[A] \text{Pr}[B] \text{Pr}[A\cap B] \text{Pr}[B] \frac{3}{51} \text{Pr}[A] \text{Pr}[A]=\frac{3}{51} \text{Pr}[A\cap B] \text{Pr}[A\mid B]\cdot \text{Pr}[B] \text{Pr}[A\mid B] \frac{2}{52} \cdot \frac{1}{52} 12 \cdot \frac{4}{52} \cdot \frac{3}{51} \text{Pr}[A\mid B]\cdot \text{Pr}[B]=\left(\frac{2}{52} \cdot \frac{1}{52} + 12 \cdot \frac{4}{52} \cdot \frac{3}{51}\right) \cdot \frac{3}{51}. \frac{73}{20825},"['probability', 'combinatorics', 'binomial-coefficients']"
72,Paradox with probability becoming $1$ from $\frac{1}{2}$,Paradox with probability becoming  from,1 \frac{1}{2},"There are two players $A$ and $B$ that play the following game. Each of them is given a random positive integer number by a fair judge, and the player with the biggest number wins. The judge tells player $A$ his number then waits some time(let's say 1 minute) and then tells player $B$ his number. Obviously the probabilities of winning are $50-50$ (equal). But after the judge tells player $A$ his number (let's name it $x$ ), one could assume (no matter what value the $x$ has) that the probability of $B$ winning is $1$ , since there are infinite integers greater than $x$ but only $x-1$ positive integers smaller than $x$ (and the probability of draw is $0$ ). I know that the game must be fair, but why does the information we take from hearing player's $A$ number condemn player $A$ to lose? Why do we(me at least) think for 1 minute that player $B$ will surely win? It seems like a paradox to me and I would like an explanation/solution for it. I thought of this while reading about another paradox ( Necktie paradox ) but I can't give myself an explanation for it. What is the flaw in the ""logic"" I used?","There are two players and that play the following game. Each of them is given a random positive integer number by a fair judge, and the player with the biggest number wins. The judge tells player his number then waits some time(let's say 1 minute) and then tells player his number. Obviously the probabilities of winning are (equal). But after the judge tells player his number (let's name it ), one could assume (no matter what value the has) that the probability of winning is , since there are infinite integers greater than but only positive integers smaller than (and the probability of draw is ). I know that the game must be fair, but why does the information we take from hearing player's number condemn player to lose? Why do we(me at least) think for 1 minute that player will surely win? It seems like a paradox to me and I would like an explanation/solution for it. I thought of this while reading about another paradox ( Necktie paradox ) but I can't give myself an explanation for it. What is the flaw in the ""logic"" I used?",A B A B 50-50 A x x B 1 x x-1 x 0 A A B,"['probability', 'paradoxes']"
73,What is the distribution of time to absorption for an absorbing Markov chain?,What is the distribution of time to absorption for an absorbing Markov chain?,,"I am interested in finding the distribution of time to absorption for a given absorbing Markov chain transition matrix. I've looked at first passage time (where $f_{ij}^{(n)}$ is the probability that the first passage from $i$ to $j$ occurs in exactly $n$ steps). In my particular case I have a single absorbing state, which I'll call $j$ . I think I can find the probability mass function since $P(x=0)=0\cdot f_{ij}^{(0)}, P(x=1)=1 \cdot f_{ij}^{(1)}, \ldots $ , but I'm not sure where to go from here.","I am interested in finding the distribution of time to absorption for a given absorbing Markov chain transition matrix. I've looked at first passage time (where is the probability that the first passage from to occurs in exactly steps). In my particular case I have a single absorbing state, which I'll call . I think I can find the probability mass function since , but I'm not sure where to go from here.","f_{ij}^{(n)} i j n j P(x=0)=0\cdot f_{ij}^{(0)}, P(x=1)=1 \cdot f_{ij}^{(1)}, \ldots ","['probability', 'markov-chains', 'markov-process']"
74,Compute the probability that the outcome of a die's fifth throw is one of the previous 4,Compute the probability that the outcome of a die's fifth throw is one of the previous 4,,"A die is randomly rolled five times, the probability that outcome of the fifth throw is one of the outcomes of the first 4 throws is? Attempt: For first 4, there are following possibilities:  (after that we will multilply the possibilities for the fifth one) All different 2 same 2 different 3 same 1 different All same $1.$ All different: Number of ways: $(6*5*4*3)\times\dbinom 41 = 1440$ $2$ . $2$ same, $2$ different: Number of ways: $\dfrac{4!}{2!}\dbinom 63 \times \dbinom 31 = 720$ $3$ . $3$ same, $1$ different: Number of ways: $\dfrac{4!}{3!}\dbinom 62 \times \dbinom 21 = 120$ $4$ . All same: Number of ways: $\dbinom 61 \times \dbinom 11 = 6$ Thus, $p(E) = \dfrac{@1+@2+@3+@4}{6^5} = \dfrac{381}{6^4}$ But answer given is: $\dfrac{671}{6^4}$ What's my mistake? Edit: Forgot to use: (as pointed out by @anryvian in comments) $5.$ 2 same, 2 same: Number of ways: $\dfrac{4!}{2!2!} \times \dbinom 6 2 \times 2 = 180$ Which gives the answer as: $\dfrac{411}{6^4}$ (still incorrect :( )","A die is randomly rolled five times, the probability that outcome of the fifth throw is one of the outcomes of the first 4 throws is? Attempt: For first 4, there are following possibilities:  (after that we will multilply the possibilities for the fifth one) All different 2 same 2 different 3 same 1 different All same All different: Number of ways: . same, different: Number of ways: . same, different: Number of ways: . All same: Number of ways: Thus, But answer given is: What's my mistake? Edit: Forgot to use: (as pointed out by @anryvian in comments) 2 same, 2 same: Number of ways: Which gives the answer as: (still incorrect :( )",1. (6*5*4*3)\times\dbinom 41 = 1440 2 2 2 \dfrac{4!}{2!}\dbinom 63 \times \dbinom 31 = 720 3 3 1 \dfrac{4!}{3!}\dbinom 62 \times \dbinom 21 = 120 4 \dbinom 61 \times \dbinom 11 = 6 p(E) = \dfrac{@1+@2+@3+@4}{6^5} = \dfrac{381}{6^4} \dfrac{671}{6^4} 5. \dfrac{4!}{2!2!} \times \dbinom 6 2 \times 2 = 180 \dfrac{411}{6^4},['probability']
75,What is the probability of getting equal numbers of heads and tails?,What is the probability of getting equal numbers of heads and tails?,,"I'm doing my hw, there is a question that I am not sure if I'm correct. Here is the question A fair coin is thrown repeatedly. What is the probability that on the $n$ th throw, the numbers of heads and tails to date are equal? My answer is as follows: $ \mathrm{The\ required\ situation\ holds\ only\ when} \ n\ \mathrm{is\  even.}\\ \mathrm{Let}\ n=2k,\ \mathrm{then\ the\ required\ probability} = {2k \choose k} \left( \frac{1}{2} \right)^{k} \left( \frac{1}{2} \right)^{k} = {2k \choose k} \left( \frac{1}{2} \right)^{2k}  \\  \mathrm{And\  I \ searched\ this\ question\ online\ and\ found\ that\ someone\ said\ that\ the \ probability\ is} \left( \frac{n}{2} \right)\left( \frac{1}{2} \right)^{n}  $ Here is the link: https://www.algebra.com/algebra/homework/Probability-and-statistics/Probability-and-statistics.faq.question.779221.html I also tried to expand ${2k \choose k}$ but failed to get the expression $\left( \frac{n}{2} \right)$ May I know whether I am correct or where did I do it wrongly, thanks.","I'm doing my hw, there is a question that I am not sure if I'm correct. Here is the question A fair coin is thrown repeatedly. What is the probability that on the th throw, the numbers of heads and tails to date are equal? My answer is as follows: Here is the link: https://www.algebra.com/algebra/homework/Probability-and-statistics/Probability-and-statistics.faq.question.779221.html I also tried to expand but failed to get the expression May I know whether I am correct or where did I do it wrongly, thanks.","n  \mathrm{The\ required\ situation\ holds\ only\ when} \ n\ \mathrm{is\  even.}\\
\mathrm{Let}\ n=2k,\ \mathrm{then\ the\ required\ probability} = {2k \choose k} \left( \frac{1}{2} \right)^{k} \left( \frac{1}{2} \right)^{k} = {2k \choose k} \left( \frac{1}{2} \right)^{2k} 
\\ 
\mathrm{And\  I \ searched\ this\ question\ online\ and\ found\ that\ someone\ said\ that\ the \ probability\ is} \left( \frac{n}{2} \right)\left( \frac{1}{2} \right)^{n}   {2k \choose k} \left( \frac{n}{2} \right)","['probability', 'statistics', 'probability-distributions', 'binomial-distribution']"
76,Probability for rolling $n$ dice to add up to at least (a specific sum),Probability for rolling  dice to add up to at least (a specific sum),n,"To clear up potential misunderstandings and make it easier to understand, I'll use this notation: Instead of writing ""Rolling $n$ $m$ -sided dice"", I'll shorten it to ""Rolling ndm "". ( n is the amount of dice and m is the amount of sides on the dice) (This is the notation used in D&D if you know what that is) Im asking how to calculate the probability of getting at least a sum of s when rolling ndm. Finding the amount of possible outcomes is fairly easy, its just $m^n$ . So f.ex for 3d6, the amount of possible outcomes would be $6^3 = 216$ . I've looked at similar asked questions before and found a very useful, related formula for finding the amount of ways to get the sum s when rolling ndm: Let $k = \lfloor \frac {s-n}m \rfloor$ $$\sum_\limits{i=0}^{k} (-1)^i{n\choose i}{s-1 - im\choose n-1}$$ However, this only gives us the probability of getting exactly s, not at least s.","To clear up potential misunderstandings and make it easier to understand, I'll use this notation: Instead of writing ""Rolling -sided dice"", I'll shorten it to ""Rolling ndm "". ( n is the amount of dice and m is the amount of sides on the dice) (This is the notation used in D&D if you know what that is) Im asking how to calculate the probability of getting at least a sum of s when rolling ndm. Finding the amount of possible outcomes is fairly easy, its just . So f.ex for 3d6, the amount of possible outcomes would be . I've looked at similar asked questions before and found a very useful, related formula for finding the amount of ways to get the sum s when rolling ndm: Let However, this only gives us the probability of getting exactly s, not at least s.",n m m^n 6^3 = 216 k = \lfloor \frac {s-n}m \rfloor \sum_\limits{i=0}^{k} (-1)^i{n\choose i}{s-1 - im\choose n-1},['probability']
77,"Birthday problem, want about using unordered counting?","Birthday problem, want about using unordered counting?",,"Given there are 365 days in a year and $n$ people, the probability that at least two people have the same birthday is given by $$\frac{365^n - 365 \cdot 364 \cdots (365-n+1)}{365^n}.$$ In this calculation, we treat the $n$ birthdays we selected as a sequence where their order matters. If we think the $n$ dates that randomly selected as a set where the order does not matter, I believe we would have the probability $$\frac{{365+n-1 \choose n} - {365\choose n}}{{365+n-1 \choose n}}.$$ For the total number of outcomes, we model by throwing $n$ balls uniformly randomly into $365$ boxes. Essentially, there are $n$ balls and $365-1$ walls (between the boxes). For example $$ \circ |\;\;\; |\;\;\;|\circ \circ |\;\;\;|\circ |\cdots |$$ would mean one person was born on day $1$ , two people were born on day $4$ , one person was born on day $6$ , and so on. This is how I came up with the ${365+n-1\choose n}$ . For the case that everyone has a distinct birthday, it would be ${365 \choose n}$ . What is wrong with this approach?","Given there are 365 days in a year and people, the probability that at least two people have the same birthday is given by In this calculation, we treat the birthdays we selected as a sequence where their order matters. If we think the dates that randomly selected as a set where the order does not matter, I believe we would have the probability For the total number of outcomes, we model by throwing balls uniformly randomly into boxes. Essentially, there are balls and walls (between the boxes). For example would mean one person was born on day , two people were born on day , one person was born on day , and so on. This is how I came up with the . For the case that everyone has a distinct birthday, it would be . What is wrong with this approach?",n \frac{365^n - 365 \cdot 364 \cdots (365-n+1)}{365^n}. n n \frac{{365+n-1 \choose n} - {365\choose n}}{{365+n-1 \choose n}}. n 365 n 365-1  \circ |\;\;\; |\;\;\;|\circ \circ |\;\;\;|\circ |\cdots | 1 4 6 {365+n-1\choose n} {365 \choose n},"['probability', 'combinatorics']"
78,"What is an intuitive explanation for how the t-distribution, normal distribution, F-distribution and Chi-square distribution relate to each other?","What is an intuitive explanation for how the t-distribution, normal distribution, F-distribution and Chi-square distribution relate to each other?",,"What is an intuitive explanation for how the t-distribution, normal distribution, F-distribution, and Chi-square distribution relate to each other? Could anyone explain this clearly with a sensible example? I am a biologist and 've been trying to understand this nearly 10 years now. Every time use the statistical tests without a proper understanding of the base. Textbooks do not refer to this question either, moreover, we are not math or stat specialized in the university.","What is an intuitive explanation for how the t-distribution, normal distribution, F-distribution, and Chi-square distribution relate to each other? Could anyone explain this clearly with a sensible example? I am a biologist and 've been trying to understand this nearly 10 years now. Every time use the statistical tests without a proper understanding of the base. Textbooks do not refer to this question either, moreover, we are not math or stat specialized in the university.",,"['probability', 'normal-distribution', 'chi-squared']"
79,Solving a Markov Chain,Solving a Markov Chain,,"Let the distribution on variables $(X_t)$ for $t \in N$ satisfy a Markov chain. Each variable can take the values $\{1, 2\}$ . We are given the pmfs $$p(X_1=i) = 0.5$$ for $i=1,2$ and $$p(X_{t+1} = j\mid X_t = i) = p_{i,j}$$ where $p_{i,j}$ is the $(i, j)$ -th element of the matrix $$P=\begin{pmatrix} 0.3 & 0.7\\ 0.6 & 0.4 \end{pmatrix}$$ Find: $P(X_3 = 2)$ and $p(X_2 = 1\mid X_3 = 2)$ . I'm stuck with how to start this problem. So any hints would be appreciated.",Let the distribution on variables for satisfy a Markov chain. Each variable can take the values . We are given the pmfs for and where is the -th element of the matrix Find: and . I'm stuck with how to start this problem. So any hints would be appreciated.,"(X_t) t \in N \{1, 2\} p(X_1=i) = 0.5 i=1,2 p(X_{t+1} = j\mid X_t = i) = p_{i,j} p_{i,j} (i, j) P=\begin{pmatrix}
0.3 & 0.7\\
0.6 & 0.4
\end{pmatrix} P(X_3 = 2) p(X_2 = 1\mid X_3 = 2)","['probability', 'probability-theory', 'markov-chains']"
80,"Randomly permute $\{1,\cdots,100\}$. What is the probability that none of the $S_k$'s defined by $\sigma(1)+\cdots+\sigma(k)$ is divisible by $3$?",Randomly permute . What is the probability that none of the 's defined by  is divisible by ?,"\{1,\cdots,100\} S_k \sigma(1)+\cdots+\sigma(k) 3","After randomly permuting the numbers from $1$ to $100$ , what is the   probability that none of the $S_k$ 's defined by $S_k =\sigma(1)+\cdots+\sigma(k)$ is divisible by $3$ ? I think I have a solution. Here is my proposed solution: Consider all the numbers from $1$ to $100$ modulo $3$ . We have $33$ zeroes, $34$ ones and $33$ twos. Now let's see which permutations are eligible: First of all, it does not matter where those numbers divisible by $3$ are placed after permutation because they are zero modulo $3$ . I claim there exists only one possible pattern: $$1 \hspace{5px} \underbrace{1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} \cdots \hspace{5px} 1 \hspace{5px}2}_{\text{33 times}}$$ where the remaining zeroes can be put anywhere. Why is this the only pattern? Well, notice that after we have chosen $\sigma(1)$ , no two consecutive sigmas can be $1$ modulo $3$ . Because if $S_k\equiv x \pmod{3}$ , then $S_{k+1} \equiv x+1 \pmod{3}$ and $S_{k+2} \equiv x+2 \pmod{3}$ . One of these three must be divisible by $3$ . Hence, no consecutive $1$ 's can be in the list after the first entry. The same argument applies to any two consecutive sigmas that are equal to $2$ modulo $3$ . So, after we have chosen $\sigma(1)$ , the rest of the list should be filled with alternating $1$ 's and $2$ 's with $0$ 's placed arbitrarily. So, we get two options: $$\text{Pattern I: } \hspace{5px} 1 \hspace{5px}1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} \cdots$$ $$\text{Pattern II: } \hspace{5px} 2 \hspace{5px}2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} \cdots$$ The second pattern is impossible. Because the numbers of $1$ 's and $2$ 's are limited and we cannot fit $34$ ones and $33$ twos in the second pattern. Hence, we only need to count the number of ways we can place zeroes in the only remaining pattern (pattern I) to find out the probability. The final answer therefore is equal to: $$\frac{{67+33-1}\choose{33}}{{100 \choose 33} \times {67 \choose 34}}=\frac{{99}\choose{33}}{{100 \choose 33} \times {67 \choose 34}} \approx 4.7\times 10^{-20}$$ So, the answer is extremely small and the probability is almost $0$ .","After randomly permuting the numbers from to , what is the   probability that none of the 's defined by is divisible by ? I think I have a solution. Here is my proposed solution: Consider all the numbers from to modulo . We have zeroes, ones and twos. Now let's see which permutations are eligible: First of all, it does not matter where those numbers divisible by are placed after permutation because they are zero modulo . I claim there exists only one possible pattern: where the remaining zeroes can be put anywhere. Why is this the only pattern? Well, notice that after we have chosen , no two consecutive sigmas can be modulo . Because if , then and . One of these three must be divisible by . Hence, no consecutive 's can be in the list after the first entry. The same argument applies to any two consecutive sigmas that are equal to modulo . So, after we have chosen , the rest of the list should be filled with alternating 's and 's with 's placed arbitrarily. So, we get two options: The second pattern is impossible. Because the numbers of 's and 's are limited and we cannot fit ones and twos in the second pattern. Hence, we only need to count the number of ways we can place zeroes in the only remaining pattern (pattern I) to find out the probability. The final answer therefore is equal to: So, the answer is extremely small and the probability is almost .",1 100 S_k S_k =\sigma(1)+\cdots+\sigma(k) 3 1 100 3 33 34 33 3 3 1 \hspace{5px} \underbrace{1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} \cdots \hspace{5px} 1 \hspace{5px}2}_{\text{33 times}} \sigma(1) 1 3 S_k\equiv x \pmod{3} S_{k+1} \equiv x+1 \pmod{3} S_{k+2} \equiv x+2 \pmod{3} 3 1 2 3 \sigma(1) 1 2 0 \text{Pattern I: } \hspace{5px} 1 \hspace{5px}1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} \cdots \text{Pattern II: } \hspace{5px} 2 \hspace{5px}2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} 1\hspace{5px} 2\hspace{5px} \cdots 1 2 34 33 \frac{{67+33-1}\choose{33}}{{100 \choose 33} \times {67 \choose 34}}=\frac{{99}\choose{33}}{{100 \choose 33} \times {67 \choose 34}} \approx 4.7\times 10^{-20} 0,"['probability', 'proof-verification', 'stochastic-processes', 'permutations', 'contest-math']"
81,Proof that CDF is continuous for continuous random variables.,Proof that CDF is continuous for continuous random variables.,,"I have to show that, For any continuous random variable $X$ , the cumulative distribution function(CDF) $F : \mathbb{R} \to [0,1]$ is continuous. My attempt Assume $F$ has a discontinuous point $x \in \mathbb{R}$ . Since CDF should be non-decreasing, i.e. monotone increasing, so it follows that $f(x-) < f(x+)$ . Since CDF is right-continuous, $f(x)=f(x+)$ , thus $X$ has point mass of size $f(x+) - f(x-)$ at the point $x$ . This contradicts the fact that $P(X=x) = 0$ for any $x \in \mathbb{R}$ , because $X$ : continuous random variable. Is my proof OK?","I have to show that, For any continuous random variable , the cumulative distribution function(CDF) is continuous. My attempt Assume has a discontinuous point . Since CDF should be non-decreasing, i.e. monotone increasing, so it follows that . Since CDF is right-continuous, , thus has point mass of size at the point . This contradicts the fact that for any , because : continuous random variable. Is my proof OK?","X F : \mathbb{R} \to [0,1] F x \in \mathbb{R} f(x-) < f(x+) f(x)=f(x+) X f(x+) - f(x-) x P(X=x) = 0 x \in \mathbb{R} X","['probability', 'probability-theory']"
82,"Finding the probability that someone has the disease, given they test positive on two tests","Finding the probability that someone has the disease, given they test positive on two tests",,"This question is from the textbook ""Introduction to Probability - Blitzstein & Hwang."" I was studying for a class when I came across an example problem that I solved, but got a slightly different result than the textbook. Here's the problem in question, paraphrased: ""Fred tests for a disease which afflicts 1% of the population. The test's accuracy is deemed 95%. He tests positive for the first test, but decides to get tested for a second time. Unfortunately, Fred also tests positive for the second test as well. Find the probability that Fred has the disease, given the evidence."" $\ $ My approach is as follows: Let $D$ be the event that Fred has the disease, $T_1$ be the event that the first test result is positive, and $T_2$ be the event that the second test is also positive. We want to find $P(D\ |\ T_1,\ T_2)$ . We are also able to condition on $T_1$ (i.e. the event that the first test result is positive). This would give us: $$P(D\ |\ T_1,\ T_2) = \frac{P(T_2\ |\ D,\ T_1)P(D\ |\ T_1)}{P(T_2\ |\ T_1)}$$ From my calculations: $$P(T_2\ |\ D,\ T_1)\ =\ P(T_2\ |\ D)\ =\ 0.95$$ $$P(D\ |\ T_1)\ \approx\ 0.16$$ $$P(T_2\ |\ T_1)\ =\ \frac{P(T_1 ,\ T_2)}{P(T_1)}\ =\ \frac{P(T_1,\ T_2,\ D)\ +\ P(T_1,\ T_2,\ D^c)}{P(T_1,\ D)\ +\ P(T_1,\ D^c)}\ =\ \frac{0.0115}{0.059}\ \approx\ 0.19$$ $\ $ $$P(D\ |\ T_1,\ T_2)\ =\ \frac{0.95\ \times\ 0.16}{0.19}\ =\ 0.8$$ Therefore, I concluded that there is an 80% chance that Fred has the disease, given that both the first and second test results are positive. $\ $ The problem is that the textbook has taken a different approach of using the odds form of Bayes' rule , which resulted in a conclusion slightly different from mine (0.78), and I'm having trouble understanding how that conclusion came to be. $\ $ Textbook approach is as follows: $$\frac{P(D\ |\ T_1,\ T_2)}{P(D^c\ |\ T_1,\ T_2)}\ =\ \frac{P(D)}{P(D^c)}\ \times\ \frac{P(T_1,\ T_2\ |\ D)}{P(T_1,\ T_2\ |\ D^c)}$$ $$=\ \frac{1}{99}\ \times\ \frac{0.95^2}{0.05^2}\ =\ \frac{361}{99}\ \approx\ 3.646$$ which ""corresponds to a probability of 0.78."" $\ $ Here are the specific questions I have: Is my approach wrong? A 0.02 difference is a pretty big difference. How did the author derive the equation: $$P(D\ |\ T_1,\ T_2)\ =\ P(D)P(T_1,\ T_2\ |\ D)$$ What does the author mean when he/she says ""3.646 corresponds to a probability of 0.78?"" $\ $ Any feedback is appreciated. Thank you!","This question is from the textbook ""Introduction to Probability - Blitzstein & Hwang."" I was studying for a class when I came across an example problem that I solved, but got a slightly different result than the textbook. Here's the problem in question, paraphrased: ""Fred tests for a disease which afflicts 1% of the population. The test's accuracy is deemed 95%. He tests positive for the first test, but decides to get tested for a second time. Unfortunately, Fred also tests positive for the second test as well. Find the probability that Fred has the disease, given the evidence."" My approach is as follows: Let be the event that Fred has the disease, be the event that the first test result is positive, and be the event that the second test is also positive. We want to find . We are also able to condition on (i.e. the event that the first test result is positive). This would give us: From my calculations: Therefore, I concluded that there is an 80% chance that Fred has the disease, given that both the first and second test results are positive. The problem is that the textbook has taken a different approach of using the odds form of Bayes' rule , which resulted in a conclusion slightly different from mine (0.78), and I'm having trouble understanding how that conclusion came to be. Textbook approach is as follows: which ""corresponds to a probability of 0.78."" Here are the specific questions I have: Is my approach wrong? A 0.02 difference is a pretty big difference. How did the author derive the equation: What does the author mean when he/she says ""3.646 corresponds to a probability of 0.78?"" Any feedback is appreciated. Thank you!","\  D T_1 T_2 P(D\ |\ T_1,\ T_2) T_1 P(D\ |\ T_1,\ T_2) = \frac{P(T_2\ |\ D,\ T_1)P(D\ |\ T_1)}{P(T_2\ |\ T_1)} P(T_2\ |\ D,\ T_1)\ =\ P(T_2\ |\ D)\ =\ 0.95 P(D\ |\ T_1)\ \approx\ 0.16 P(T_2\ |\ T_1)\ =\ \frac{P(T_1 ,\ T_2)}{P(T_1)}\ =\ \frac{P(T_1,\ T_2,\ D)\ +\ P(T_1,\ T_2,\ D^c)}{P(T_1,\ D)\ +\ P(T_1,\ D^c)}\ =\ \frac{0.0115}{0.059}\ \approx\ 0.19 \  P(D\ |\ T_1,\ T_2)\ =\ \frac{0.95\ \times\ 0.16}{0.19}\ =\ 0.8 \  \  \frac{P(D\ |\ T_1,\ T_2)}{P(D^c\ |\ T_1,\ T_2)}\ =\ \frac{P(D)}{P(D^c)}\ \times\ \frac{P(T_1,\ T_2\ |\ D)}{P(T_1,\ T_2\ |\ D^c)} =\ \frac{1}{99}\ \times\ \frac{0.95^2}{0.05^2}\ =\ \frac{361}{99}\ \approx\ 3.646 \  P(D\ |\ T_1,\ T_2)\ =\ P(D)P(T_1,\ T_2\ |\ D) \ ","['probability', 'conditional-probability', 'bayes-theorem']"
83,Combinatorics - arrangements around circular table,Combinatorics - arrangements around circular table,,""" $4$ boys and $3$ girls sit round a table. What is the probability that exactly $2$ girls will sit next to each other?"" I said the following: there are ${7\choose3} = 35$ ways to pick places for the girls, and in $5$ of those ways, the girls will be completely apart (i.e. no two girls sit together), giving a probability of $\frac{5}{35} = \frac{1}{7}$ . Thus the probability that at least two girls sit together is $1-\frac{1}{7} = \frac{6}{7}$ . The probability that all three girls sit together is $\frac{7}{35} = \frac{1}{5}$ , since there are $7$ ways to pick the three places such that all three girls sit together. Hence, the probability that exactly two girls sit together is $\frac{6}{7} - \frac{1}{5} = \frac{23}{35}$ . However, I'm told that the correct answer should be $\frac{3}{5}$ , so my question is: what is wrong with my working above?",""" boys and girls sit round a table. What is the probability that exactly girls will sit next to each other?"" I said the following: there are ways to pick places for the girls, and in of those ways, the girls will be completely apart (i.e. no two girls sit together), giving a probability of . Thus the probability that at least two girls sit together is . The probability that all three girls sit together is , since there are ways to pick the three places such that all three girls sit together. Hence, the probability that exactly two girls sit together is . However, I'm told that the correct answer should be , so my question is: what is wrong with my working above?",4 3 2 {7\choose3} = 35 5 \frac{5}{35} = \frac{1}{7} 1-\frac{1}{7} = \frac{6}{7} \frac{7}{35} = \frac{1}{5} 7 \frac{6}{7} - \frac{1}{5} = \frac{23}{35} \frac{3}{5},"['probability', 'combinatorics']"
84,Showing $2\int_{-\infty}^{\infty} x f(x) F(x) \ dx = \frac{1}{\sqrt{\pi}}$ for standard normal pdf and cfd,Showing  for standard normal pdf and cfd,2\int_{-\infty}^{\infty} x f(x) F(x) \ dx = \frac{1}{\sqrt{\pi}},"i am trying to prove the identity in the title. I strongly think I need to use the error function $$\text{erf}(x) = \frac{2}{\sqrt{\pi}} \int_0^x \exp\{-t^2\}\ dt$$ in some way. Best I have so far is replacing $F(x) = \frac{1+\text{erf}\left(\frac{x}{\sqrt{2}}\right)}{2}$ to end up with  $$2\int_{-\infty}^{\infty} x \, f(x) \, F(x) \ dx = \int_{-\infty}^{\infty} \text{erf}\left(\frac{x}{\sqrt{2}}\right) \, x\, \frac{1}{\sqrt{2\pi}} \exp\left\{-\frac{1}{2}x^2\right\}\ dx.$$ My attempts on partial integration have failed, any other ideas or does anyone succeed? I have a document stating that the equality holds without any further remarks or calculations and I have confirmed it via integration by quadrature and am looking for an analytic proof. Very thankful for any help.","i am trying to prove the identity in the title. I strongly think I need to use the error function $$\text{erf}(x) = \frac{2}{\sqrt{\pi}} \int_0^x \exp\{-t^2\}\ dt$$ in some way. Best I have so far is replacing $F(x) = \frac{1+\text{erf}\left(\frac{x}{\sqrt{2}}\right)}{2}$ to end up with  $$2\int_{-\infty}^{\infty} x \, f(x) \, F(x) \ dx = \int_{-\infty}^{\infty} \text{erf}\left(\frac{x}{\sqrt{2}}\right) \, x\, \frac{1}{\sqrt{2\pi}} \exp\left\{-\frac{1}{2}x^2\right\}\ dx.$$ My attempts on partial integration have failed, any other ideas or does anyone succeed? I have a document stating that the equality holds without any further remarks or calculations and I have confirmed it via integration by quadrature and am looking for an analytic proof. Very thankful for any help.",,"['probability', 'integration']"
85,The Abel-and-Cain Urn Problem,The Abel-and-Cain Urn Problem,,"An urn contains three distinguishable kinds of balls, say $A,B,C$. Abel bets to get, in $t$ trials with replacement, at least one ball of kind $A$ and at least one ball of kind $B$. Cain bets to get, in $t$ trials with replacement, exactly $t$ balls of kind $C$. We want Abel and Cain to have the same chance to win. My solution is : No matter the number of balls of each kind in the urn, if Abel and Cain have the same chance to win at the end of the game, then it must be $t=2$. My reasoning is : Abel can win at any trial between $2$ and $t$, whereas Cain can possibly win only at the end of the game. Since we asked that at the end of the game Abel and Cain must have the same chance to win, then the last trial must represent the only possible success also for Abel , and this implies $t=2$. Is this reasoning correct? A further question, which might be a bit naive (or even silly), so please apologize me in that case: How do we take into account (e.g. in terms of conditional probability) the fact that Cain already knows that Abel cannot win at the first trial and that Abel already knows that Cain cannot win at any trial a part the last one? EDIT : I attach this scheme to explain the reasoning (see also the comments for further details). Here we interpret each trial as a shot. And the probability to get a success for Abel in each trial $k$ as a target of a certain area (green targets, top scheme). The area of the $Ab_k$ targets increases as $k$ increases, and the area of the target in correspondence of $t$ is $Ab_t=p$. For Cain, there is only one target (blue target, bottom scheme), the last one, since he cannot win in the middle of the game. The area of his last target is $Ca_t=q$. The request is that $p=q$, in correspondence of the last trial. Now, Abel can hit a target (and therefore win the game) at any trial (a part the first one). So if the last one has the same area for Abel and Cain, there must be only one target, otherwise Abel has more chance to win.","An urn contains three distinguishable kinds of balls, say $A,B,C$. Abel bets to get, in $t$ trials with replacement, at least one ball of kind $A$ and at least one ball of kind $B$. Cain bets to get, in $t$ trials with replacement, exactly $t$ balls of kind $C$. We want Abel and Cain to have the same chance to win. My solution is : No matter the number of balls of each kind in the urn, if Abel and Cain have the same chance to win at the end of the game, then it must be $t=2$. My reasoning is : Abel can win at any trial between $2$ and $t$, whereas Cain can possibly win only at the end of the game. Since we asked that at the end of the game Abel and Cain must have the same chance to win, then the last trial must represent the only possible success also for Abel , and this implies $t=2$. Is this reasoning correct? A further question, which might be a bit naive (or even silly), so please apologize me in that case: How do we take into account (e.g. in terms of conditional probability) the fact that Cain already knows that Abel cannot win at the first trial and that Abel already knows that Cain cannot win at any trial a part the last one? EDIT : I attach this scheme to explain the reasoning (see also the comments for further details). Here we interpret each trial as a shot. And the probability to get a success for Abel in each trial $k$ as a target of a certain area (green targets, top scheme). The area of the $Ab_k$ targets increases as $k$ increases, and the area of the target in correspondence of $t$ is $Ab_t=p$. For Cain, there is only one target (blue target, bottom scheme), the last one, since he cannot win in the middle of the game. The area of his last target is $Ca_t=q$. The request is that $p=q$, in correspondence of the last trial. Now, Abel can hit a target (and therefore win the game) at any trial (a part the first one). So if the last one has the same area for Abel and Cain, there must be only one target, otherwise Abel has more chance to win.",,"['probability', 'combinatorics']"
86,"Prove that $n^{-1} \max\left(X_1,\cdots,X_n\right) \to 0$ in probability",Prove that  in probability,"n^{-1} \max\left(X_1,\cdots,X_n\right) \to 0","Let $X_1,\cdots,X_n$ be sequence of positive, iid random variables such that $\mathbb{E} X_1 <\infty$. How can I show that $$\frac{1}{n}\max\left(X_1,X_2,\cdots,X_n\right)\to 0 \text{ in probability}$$ I can prove it assuming $\mathbb{E}X_1^2 < \infty$, but I don't know how to prove it with the given assumption. Note : While almost surely convergence implies convergence in probability, I am looking for a solution that does not take that route, and does not use Borel-Cantelli lemma.","Let $X_1,\cdots,X_n$ be sequence of positive, iid random variables such that $\mathbb{E} X_1 <\infty$. How can I show that $$\frac{1}{n}\max\left(X_1,X_2,\cdots,X_n\right)\to 0 \text{ in probability}$$ I can prove it assuming $\mathbb{E}X_1^2 < \infty$, but I don't know how to prove it with the given assumption. Note : While almost surely convergence implies convergence in probability, I am looking for a solution that does not take that route, and does not use Borel-Cantelli lemma.",,"['probability', 'probability-theory']"
87,Degrees of Freedom in a Wishart distribution,Degrees of Freedom in a Wishart distribution,,"What does the degrees of freedom parameter $n$ mean intuitively in a Wishart distribution $\mathcal{W}_p(\mathbf{V},n)$? Does it have any relation to the covariance of different dimensions of the resulting covariance matrix? Why is $n==p$ called a non-informative prior?","What does the degrees of freedom parameter $n$ mean intuitively in a Wishart distribution $\mathcal{W}_p(\mathbf{V},n)$? Does it have any relation to the covariance of different dimensions of the resulting covariance matrix? Why is $n==p$ called a non-informative prior?",,"['probability', 'probability-theory', 'probability-distributions']"
88,The math of waiting to be sitted,The math of waiting to be sitted,,"You arrive to your favorite restaurant\bar only to realize that there is no empty table :( Assuming there are $n$ number of tables, on average a group at a table spends $\bar t$ time and finally that you are far way from the opening or closing time of the establishment 1 , how long would you have to wait? I have given this much thought and ended up convincing myself that if the arrivals do not follow any distribution (are random), the average time one would have to wait is simply ${\bar t}/n$. Example: $15$ tables and $90$ min of dining on average $\Rightarrow 6$ min of waiting Question: Is it really so or is my intuition mistaken? Is there more math to this problem? 1 No bias on arrivals or departures of groups.","You arrive to your favorite restaurant\bar only to realize that there is no empty table :( Assuming there are $n$ number of tables, on average a group at a table spends $\bar t$ time and finally that you are far way from the opening or closing time of the establishment 1 , how long would you have to wait? I have given this much thought and ended up convincing myself that if the arrivals do not follow any distribution (are random), the average time one would have to wait is simply ${\bar t}/n$. Example: $15$ tables and $90$ min of dining on average $\Rightarrow 6$ min of waiting Question: Is it really so or is my intuition mistaken? Is there more math to this problem? 1 No bias on arrivals or departures of groups.",,"['probability', 'statistics', 'expectation']"
89,What's the Probability of a drunk man open a door with $n$ possible keys?,What's the Probability of a drunk man open a door with  possible keys?,n,"I have this following problem in my problem set and I would like to check if my work is in the right directio. A drunk man with $n$ keys wants to open his door and tries the keys at random. Exactly one key will open the door. Find the mean number of trials if a) unsuccessful keys are not eliminated from further selections; b) unsuccsesful keys are eliminated It seems clear to me that in the first case we have a Geometric distribution with parameter $1/n$ , so the expected number of trials is just $n$ . For the second case, my reasoning follows. Let $X$ denote the number of trials until he opens the door. $P(X = 1) = 1/n$ $P(X = 2) =(n-1)/n \cdot 1/n-1 = 1/n$ $P(X = 3) = (n-1)/n \cdot (n-2)/(n-1) \cdot 1/(n-2) = 1/n$ , and so on. I'm inclined to say that, in the second case, the probabilities over the possible $n$ values of $X$ are uniformly distributed. If this is case, then the average number of trails should be $(n+1)/2$ . Does it seem correct? If not, how to do it? Thanks in advance!!","I have this following problem in my problem set and I would like to check if my work is in the right directio. A drunk man with keys wants to open his door and tries the keys at random. Exactly one key will open the door. Find the mean number of trials if a) unsuccessful keys are not eliminated from further selections; b) unsuccsesful keys are eliminated It seems clear to me that in the first case we have a Geometric distribution with parameter , so the expected number of trials is just . For the second case, my reasoning follows. Let denote the number of trials until he opens the door. , and so on. I'm inclined to say that, in the second case, the probabilities over the possible values of are uniformly distributed. If this is case, then the average number of trails should be . Does it seem correct? If not, how to do it? Thanks in advance!!",n 1/n n X P(X = 1) = 1/n P(X = 2) =(n-1)/n \cdot 1/n-1 = 1/n P(X = 3) = (n-1)/n \cdot (n-2)/(n-1) \cdot 1/(n-2) = 1/n n X (n+1)/2,"['probability', 'proof-verification', 'probability-distributions']"
90,Are all Monte Carlo algorithms to approximate $\pi$ equivalent?,Are all Monte Carlo algorithms to approximate  equivalent?,\pi,"There are several ways one can approximate $\pi$ using a Monte-Carlo type algorithm. For example, one can draw random points in the unit square, and approximate $\pi$ via the ratio of points that fall in the unit disk. Another way would be to use an algorithm based on Buffon's needle problem: from the proportion of needles that fall across the parallel lines, one can approximate $\pi$. One can presumably devise many other random algorithms to estimate $\pi$. My question is: in terms of speed of convergence, are all these algorithms equivalent? Or are there some that will yield correct decimals of $\pi$ faster? What is the Monte Carlo method to estimate $\pi$ that has the fastest convergence?","There are several ways one can approximate $\pi$ using a Monte-Carlo type algorithm. For example, one can draw random points in the unit square, and approximate $\pi$ via the ratio of points that fall in the unit disk. Another way would be to use an algorithm based on Buffon's needle problem: from the proportion of needles that fall across the parallel lines, one can approximate $\pi$. One can presumably devise many other random algorithms to estimate $\pi$. My question is: in terms of speed of convergence, are all these algorithms equivalent? Or are there some that will yield correct decimals of $\pi$ faster? What is the Monte Carlo method to estimate $\pi$ that has the fastest convergence?",,"['probability', 'algorithms', 'approximation', 'simulation']"
91,Question about the binomial distribution,Question about the binomial distribution,,"$X$ is a random variable with binomial distribution parameters $n$ and $p_1$. $Y$ is a random variable with binomial distribution parameters $n$ and $p_2$. $p_1 < p_2$ How can I show that $P(X \leqslant k) \geqslant P(Y \leqslant k)$? Please just give me a hint. I tried comparing the terms ${n \choose k}p_1^k(1-p_1)^{n-k}$, but this doesn't work (after trying this, it's obvious in hindsight that it doesn't work.","$X$ is a random variable with binomial distribution parameters $n$ and $p_1$. $Y$ is a random variable with binomial distribution parameters $n$ and $p_2$. $p_1 < p_2$ How can I show that $P(X \leqslant k) \geqslant P(Y \leqslant k)$? Please just give me a hint. I tried comparing the terms ${n \choose k}p_1^k(1-p_1)^{n-k}$, but this doesn't work (after trying this, it's obvious in hindsight that it doesn't work.",,"['probability', 'probability-distributions']"
92,To find the probability whether $X$ is rational,To find the probability whether  is rational,X,"Let $X$ be a random variable with the moment generating function $$𝑀_𝑋(𝑡) =\frac{6}{\pi^2}\sum_{n\geq 1}\frac{e^{\frac{t^2}{2n}}}{n^2}$$ Then $𝑃(X\in \mathbb{Q})$ , where  is the set of rational numbers, equals $(A) \space\space 0\space\space\space\space\space\space (B) \space\space \frac{1}{4}\space\space\space\space\space\space  (C)\space\space \frac{1}{2}\space\space\space\space\space\space (D) \space\space \frac{3}{4}\space\space\space\space\space\space $ I was thinking whether I can replace this sum by an integral , because I can't think of a distribution whose mgf looks like this. Please Help!","Let be a random variable with the moment generating function Then , where  is the set of rational numbers, equals I was thinking whether I can replace this sum by an integral , because I can't think of a distribution whose mgf looks like this. Please Help!",X 𝑀_𝑋(𝑡) =\frac{6}{\pi^2}\sum_{n\geq 1}\frac{e^{\frac{t^2}{2n}}}{n^2} 𝑃(X\in \mathbb{Q}) (A) \space\space 0\space\space\space\space\space\space (B) \space\space \frac{1}{4}\space\space\space\space\space\space  (C)\space\space \frac{1}{2}\space\space\space\space\space\space (D) \space\space \frac{3}{4}\space\space\space\space\space\space ,['probability']
93,Is it okay to divide something by a random variable that can take on the value of 0 with probability greater than 0?,Is it okay to divide something by a random variable that can take on the value of 0 with probability greater than 0?,,"Is it okay to divide something by a random variable that can take on the value of 0 with probability greater than 0? For example, we know that, by using Slutsky's Theorem, If $\hat{p^*} = \frac{Y}{n}, Y \sim Bin(n,p)$, then $\frac{\hat{p^*}-p}{\sqrt{\hat{p^*}(1-\hat{p^*})/n}} \rightarrow^d N(0,1) $ (i.e. $\frac{\hat{p^*}-p}{\sqrt{\hat{p^*}(1-\hat{p^*})/n}}$ converges in distribution to $N(0,1)$ ). But here, $\hat{p^*}$ is a random variable that can take on the value of $0$ with probability greater than $0$, which means that the probability that $\sqrt{\hat{p^*}(1-\hat{p^*})/n}$ is equal to $0$ is also greater than $0$. so I am not sure whether it is indeed mathematically okay to write an expression like $\frac{\hat{p^*}-p}{\sqrt{\hat{p^*}(1-\hat{p^*})/n}}$ , because we are not supposed to have $0$ in denominator of a fraction. So to summarize, is it okay to have an expression like $\frac{c}{Y}$, where $c=$ constant, and $Y=$ a random variable that can take on the value of 0 with a probability greater than $0$. I hope my question makes sense. Thank you,","Is it okay to divide something by a random variable that can take on the value of 0 with probability greater than 0? For example, we know that, by using Slutsky's Theorem, If $\hat{p^*} = \frac{Y}{n}, Y \sim Bin(n,p)$, then $\frac{\hat{p^*}-p}{\sqrt{\hat{p^*}(1-\hat{p^*})/n}} \rightarrow^d N(0,1) $ (i.e. $\frac{\hat{p^*}-p}{\sqrt{\hat{p^*}(1-\hat{p^*})/n}}$ converges in distribution to $N(0,1)$ ). But here, $\hat{p^*}$ is a random variable that can take on the value of $0$ with probability greater than $0$, which means that the probability that $\sqrt{\hat{p^*}(1-\hat{p^*})/n}$ is equal to $0$ is also greater than $0$. so I am not sure whether it is indeed mathematically okay to write an expression like $\frac{\hat{p^*}-p}{\sqrt{\hat{p^*}(1-\hat{p^*})/n}}$ , because we are not supposed to have $0$ in denominator of a fraction. So to summarize, is it okay to have an expression like $\frac{c}{Y}$, where $c=$ constant, and $Y=$ a random variable that can take on the value of 0 with a probability greater than $0$. I hope my question makes sense. Thank you,",,"['probability', 'statistics', 'random-variables']"
94,Flip a coin 5 times. What is the probability that heads never occurs twice in a row?,Flip a coin 5 times. What is the probability that heads never occurs twice in a row?,,"Suppose I flip a coin $5$ times in a row. There are $2^5$ possible outcomes, i.e: HHHTH, HTTTT, HTHTH, etc. I want to know the probability that heads never occurs twice in a row. I drew out $32$ events that can occur, and I found out that the answer was $\cfrac{13}{32}$. But I'm not sure how to do this generally, because say if the coin was flipped $20$ times in a row, I wouldn't write out $2^{20}$ possibilities. Thanks","Suppose I flip a coin $5$ times in a row. There are $2^5$ possible outcomes, i.e: HHHTH, HTTTT, HTHTH, etc. I want to know the probability that heads never occurs twice in a row. I drew out $32$ events that can occur, and I found out that the answer was $\cfrac{13}{32}$. But I'm not sure how to do this generally, because say if the coin was flipped $20$ times in a row, I wouldn't write out $2^{20}$ possibilities. Thanks",,"['probability', 'combinatorics']"
95,How to derive the characteristic function $\phi_X(t) = \mathbb{E}\left(e^{it^T X}\right) = e^{it^T \mu} e^{-\frac{1}{2}t^T\Sigma t}$?,How to derive the characteristic function ?,\phi_X(t) = \mathbb{E}\left(e^{it^T X}\right) = e^{it^T \mu} e^{-\frac{1}{2}t^T\Sigma t},"My attempt to calculate the characteristic function $\mathbb{E}\left(e^{it^T X}\right)$ of multivariate normal distributed $X \sim \mathcal{N}_d(\mu,\Sigma)$, finding a lecture note that writes as follows, but I am confused about the $\overset{?}{=}$ step. \begin{align*} \phi_X(t) &= \mathbb{E}\left(e^{it^T X}\right) \\ &= \int_{-\infty}^{\infty} e^{it^T X} f_X(x) dx \\ &= \int_{-\infty}^{\infty} e^{it^T X} \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} e^{-\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu)} dx \\ &= \int_{-\infty}^{\infty} \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} \exp{\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)+it^T x\right)} dx \\ &\overset{?}{=} \exp{\left(it^T \mu - \frac{1}{2} t^T \Sigma t\right)} \\ &= e^{it^T \mu} e^{-\frac{1}{2}t^T\Sigma t} \end{align*} Can you show me more details about that step?","My attempt to calculate the characteristic function $\mathbb{E}\left(e^{it^T X}\right)$ of multivariate normal distributed $X \sim \mathcal{N}_d(\mu,\Sigma)$, finding a lecture note that writes as follows, but I am confused about the $\overset{?}{=}$ step. \begin{align*} \phi_X(t) &= \mathbb{E}\left(e^{it^T X}\right) \\ &= \int_{-\infty}^{\infty} e^{it^T X} f_X(x) dx \\ &= \int_{-\infty}^{\infty} e^{it^T X} \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} e^{-\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu)} dx \\ &= \int_{-\infty}^{\infty} \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} \exp{\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)+it^T x\right)} dx \\ &\overset{?}{=} \exp{\left(it^T \mu - \frac{1}{2} t^T \Sigma t\right)} \\ &= e^{it^T \mu} e^{-\frac{1}{2}t^T\Sigma t} \end{align*} Can you show me more details about that step?",,"['probability', 'statistics', 'normal-distribution', 'characteristic-functions']"
96,Understanding Random Walks and Related Theorems/Definitions,Understanding Random Walks and Related Theorems/Definitions,,"I'm reading Durret's book, chapter 4 on Random Walks.  Rather than spending time dwelling in my sorrow and frustration over how bad I think this book is, I think I'll take to Stack Exchange to help me understand some things. I'm going to ask several questions over three posts so that it's more likely for people to respond. Also, I did not know anything about Random Walks before reading this book.(Maybe that's relevant?) If $(S,F,\mu)$ is a measure sapce, Durret tells us that for this section our probability space is $\Omega = S^{\mathbb{N}}$ $($i.e sequences of elements of $S)$ where $F^{\mathbb{N}}$ is the corresponding $\sigma$ algebra, and $P = \mu \times \mu ...$ is our measure.  Lastly, $X_n(\omega) = \omega$ Given a finite permutation, $\pi$, of $\mathbb{N}$, Durret refers to an event $A \in F^\mathbb{N}$ being permutable for any finite permutation $\pi$ provided $\pi^{-1}(A) = A$.  The collection of such events is called the exchangeable $\sigma$ field. Ok cool. According to Durret, if $S = \mathbb{R}$ and $S_n(\omega) = X_1(\omega) + X_2(\omega) + ... X_n(\omega) = \omega_1 + \omega_2 + ...$ $1:\{\omega: S_n(\omega) \in B \ \ i.o \}$ is permutable;however, it's not a tail event. As expected, Durret does not say what $B$ is. I assume its just some subset of $S$ though. I don't understand why it's not a tail event. Please explain this if you can. $2$: In his proof of the Hewitt-Savage $0-1$ law, Durret says that we can choose $A_n \in \sigma(X_1,...X_n)$ such that $P(A_n \Delta A) \to 0$ I don't understand what the sets $A_n \Delta A$ looks like and why $A_n$ can be chosen so that $P(A_n \Delta A) \to 0$ I'll stop here and ask more questions on another post.","I'm reading Durret's book, chapter 4 on Random Walks.  Rather than spending time dwelling in my sorrow and frustration over how bad I think this book is, I think I'll take to Stack Exchange to help me understand some things. I'm going to ask several questions over three posts so that it's more likely for people to respond. Also, I did not know anything about Random Walks before reading this book.(Maybe that's relevant?) If $(S,F,\mu)$ is a measure sapce, Durret tells us that for this section our probability space is $\Omega = S^{\mathbb{N}}$ $($i.e sequences of elements of $S)$ where $F^{\mathbb{N}}$ is the corresponding $\sigma$ algebra, and $P = \mu \times \mu ...$ is our measure.  Lastly, $X_n(\omega) = \omega$ Given a finite permutation, $\pi$, of $\mathbb{N}$, Durret refers to an event $A \in F^\mathbb{N}$ being permutable for any finite permutation $\pi$ provided $\pi^{-1}(A) = A$.  The collection of such events is called the exchangeable $\sigma$ field. Ok cool. According to Durret, if $S = \mathbb{R}$ and $S_n(\omega) = X_1(\omega) + X_2(\omega) + ... X_n(\omega) = \omega_1 + \omega_2 + ...$ $1:\{\omega: S_n(\omega) \in B \ \ i.o \}$ is permutable;however, it's not a tail event. As expected, Durret does not say what $B$ is. I assume its just some subset of $S$ though. I don't understand why it's not a tail event. Please explain this if you can. $2$: In his proof of the Hewitt-Savage $0-1$ law, Durret says that we can choose $A_n \in \sigma(X_1,...X_n)$ such that $P(A_n \Delta A) \to 0$ I don't understand what the sets $A_n \Delta A$ looks like and why $A_n$ can be chosen so that $P(A_n \Delta A) \to 0$ I'll stop here and ask more questions on another post.",,"['probability', 'probability-theory', 'probability-distributions', 'random-walk']"
97,Calculating probability when range of values is given,Calculating probability when range of values is given,,"Assume the number of pounds of peanuts consumed in a year is equally   likely to assume any value (including fractions) between 20 and 100   pounds. What is the probability that someone consumes less than 40   pounds of peanuts in a year? Which method should I use to solve this problem? If we wish to solve this using normal distribution, mean and standard deviation are unknown. I tried solving this assuming mean = 60 and calculating standard deviation with assumption that 99.7% of the area falls under 3 standard deviations from mean. Binomial distribution does not seem to fit here. Which other distribution does fit here? The answer is 0.25.","Assume the number of pounds of peanuts consumed in a year is equally   likely to assume any value (including fractions) between 20 and 100   pounds. What is the probability that someone consumes less than 40   pounds of peanuts in a year? Which method should I use to solve this problem? If we wish to solve this using normal distribution, mean and standard deviation are unknown. I tried solving this assuming mean = 60 and calculating standard deviation with assumption that 99.7% of the area falls under 3 standard deviations from mean. Binomial distribution does not seem to fit here. Which other distribution does fit here? The answer is 0.25.",,"['probability', 'probability-distributions']"
98,Doob's Maximal Inequality and Doob's L^p Inequality for Sub Martingales,Doob's Maximal Inequality and Doob's L^p Inequality for Sub Martingales,,"Let $X:\Omega\times[0,T]\longrightarrow \mathbb{R}$ be a non-negative submartingale with cadlag sample paths, $p>1$ and $C>0$. Then I understand that Doob's Maximal Inequality is given by: \begin{equation*} \mathbb{P}\left( \sup_{t\in [0,T]} X_t \ge C\right) \le \frac{\mathbb{E}\left[ X_T\right]}{C} \end{equation*} And Doob's $\mathcal{L}^p$ Inequality is given by: \begin{equation*} \left\Vert \sup_{t\in [0,T]} X_t\right\Vert_p \le \frac{p}{p-1}\left\Vert X_T\right\Vert_p \end{equation*} My questions are: 1)What happens when I take $T\rightarrow\infty$ and could you please provide a careful proof of why it is the case (of whatever happens as we take $T\rightarrow\infty$)? I would suspect that the following inequalities hold: \begin{equation*} \mathbb{P}\left( \sup_{t\in \mathbb{R}^+} X_t \ge C\right) \le \frac{\sup_{T\in \mathbb{R}^+}\mathbb{E}\left[ X_T\right]}{C} \end{equation*} And: \begin{equation*} \left\Vert \sup_{t\in \mathbb{R}^+} X_t\right\Vert_p \le \frac{p}{p-1}\sup_{t\in \mathbb{R}^+}\left\Vert X_T\right\Vert_p \end{equation*} Basically because $\mathbb{E}\left[X_T\right] \le \mathbb{E}\left[ X_{T+1}\right]$ $\forall T\in \mathbb{R}^+$ and the sets event/random variables on the LHS of the inequalities are also increasing. (I think I actually kind of proved this to myself...but I am extremely in-confident about my own abilities and hence am asking for a) a sanity check b) it would be nice to see how someone else would prove this as I may learn a new trick/technique/insight from their proof!) 2) Intuitively why is the assumption of cadlag sample paths so crucial? 3) (This really is more of a sanity check) do these inequalities hold (both for $T\in \mathbb{R}$ and as $T\rightarrow\infty$) if we remove the assumption that $X$ is a non-negative martingale and subsequently write the Doobs Maximal Inequality with absolute values? I.e. \begin{equation*} \mathbb{P}\left( \sup_{t\in [0,T]}\left\vert X_t\right\vert \ge C\right) \le \frac{\mathbb{E}\left[\left\vert X_T\right\vert\right]}{C} \end{equation*} (and Doobs $\mathcal{L}^p$-Inequality does not change, because the absolute values are automatically already built in) Thanks in advanced.","Let $X:\Omega\times[0,T]\longrightarrow \mathbb{R}$ be a non-negative submartingale with cadlag sample paths, $p>1$ and $C>0$. Then I understand that Doob's Maximal Inequality is given by: \begin{equation*} \mathbb{P}\left( \sup_{t\in [0,T]} X_t \ge C\right) \le \frac{\mathbb{E}\left[ X_T\right]}{C} \end{equation*} And Doob's $\mathcal{L}^p$ Inequality is given by: \begin{equation*} \left\Vert \sup_{t\in [0,T]} X_t\right\Vert_p \le \frac{p}{p-1}\left\Vert X_T\right\Vert_p \end{equation*} My questions are: 1)What happens when I take $T\rightarrow\infty$ and could you please provide a careful proof of why it is the case (of whatever happens as we take $T\rightarrow\infty$)? I would suspect that the following inequalities hold: \begin{equation*} \mathbb{P}\left( \sup_{t\in \mathbb{R}^+} X_t \ge C\right) \le \frac{\sup_{T\in \mathbb{R}^+}\mathbb{E}\left[ X_T\right]}{C} \end{equation*} And: \begin{equation*} \left\Vert \sup_{t\in \mathbb{R}^+} X_t\right\Vert_p \le \frac{p}{p-1}\sup_{t\in \mathbb{R}^+}\left\Vert X_T\right\Vert_p \end{equation*} Basically because $\mathbb{E}\left[X_T\right] \le \mathbb{E}\left[ X_{T+1}\right]$ $\forall T\in \mathbb{R}^+$ and the sets event/random variables on the LHS of the inequalities are also increasing. (I think I actually kind of proved this to myself...but I am extremely in-confident about my own abilities and hence am asking for a) a sanity check b) it would be nice to see how someone else would prove this as I may learn a new trick/technique/insight from their proof!) 2) Intuitively why is the assumption of cadlag sample paths so crucial? 3) (This really is more of a sanity check) do these inequalities hold (both for $T\in \mathbb{R}$ and as $T\rightarrow\infty$) if we remove the assumption that $X$ is a non-negative martingale and subsequently write the Doobs Maximal Inequality with absolute values? I.e. \begin{equation*} \mathbb{P}\left( \sup_{t\in [0,T]}\left\vert X_t\right\vert \ge C\right) \le \frac{\mathbb{E}\left[\left\vert X_T\right\vert\right]}{C} \end{equation*} (and Doobs $\mathcal{L}^p$-Inequality does not change, because the absolute values are automatically already built in) Thanks in advanced.",,"['probability', 'inequality', 'martingales']"
99,Rao-Blackwell's Theorem for uniform distribution,Rao-Blackwell's Theorem for uniform distribution,,"Let $X_1, \cdots, X_n$ be iid from a uniform distribution    $U[\theta-\frac{1}{2}, \theta+\frac{1}{2}]$ with $\theta \in  \mathbb{R}$ unknown. Take for granted that $T(\mathbf{X}) =  (X_{(1)}, X_{(n)})$ is minimal sufficient statistic for $\theta$ and consider the unbiased estimator $\overline{X}$. Apply Rao-Blackwell's Theorem and find the estimator that improves upon $\overline{X}$ by conditioning on $T$. My attempt: Let $\phi(T) = E(\overline{X}|T)$. By Rao-Blackwell's Theorem, $\phi(T)$ is a uniformly better unbiased estimator of $\theta$ than $\overline{X}$. However, how can I find an expression for this estimator? My initial idea: To compute the expectation, I will need to find the conditional distribution of $\overline{X}$ given $T$ (which ofcourse does not depend on $\theta$ since $T$ is sufficient). I have found the joint distribution of $T= (X_{(1)}, X_{(n)})$ which is given by \begin{align*} f_{X_{(1)}, X_{(n)}}(x_{(1)}, x_{(n)}) = \begin{cases} n(n-1)(x_{(n)} - x_{(1)})^{n-2} & \text{ if } \theta-\frac{1}{2} < x_{(1)} < x_{(n)} < \theta+\frac{1}{2} \\ 0 & \text{ otherwise } \end{cases}. \end{align*} If I can somehow find the joint distribution of $\overline{X}$ and $T$, then I should be able to find the conditional distribution and then compute the conditional expectation. Is this the right approach? If so, how can I find the joint distribution of $\overline{X}$ and $T$?","Let $X_1, \cdots, X_n$ be iid from a uniform distribution    $U[\theta-\frac{1}{2}, \theta+\frac{1}{2}]$ with $\theta \in  \mathbb{R}$ unknown. Take for granted that $T(\mathbf{X}) =  (X_{(1)}, X_{(n)})$ is minimal sufficient statistic for $\theta$ and consider the unbiased estimator $\overline{X}$. Apply Rao-Blackwell's Theorem and find the estimator that improves upon $\overline{X}$ by conditioning on $T$. My attempt: Let $\phi(T) = E(\overline{X}|T)$. By Rao-Blackwell's Theorem, $\phi(T)$ is a uniformly better unbiased estimator of $\theta$ than $\overline{X}$. However, how can I find an expression for this estimator? My initial idea: To compute the expectation, I will need to find the conditional distribution of $\overline{X}$ given $T$ (which ofcourse does not depend on $\theta$ since $T$ is sufficient). I have found the joint distribution of $T= (X_{(1)}, X_{(n)})$ which is given by \begin{align*} f_{X_{(1)}, X_{(n)}}(x_{(1)}, x_{(n)}) = \begin{cases} n(n-1)(x_{(n)} - x_{(1)})^{n-2} & \text{ if } \theta-\frac{1}{2} < x_{(1)} < x_{(n)} < \theta+\frac{1}{2} \\ 0 & \text{ otherwise } \end{cases}. \end{align*} If I can somehow find the joint distribution of $\overline{X}$ and $T$, then I should be able to find the conditional distribution and then compute the conditional expectation. Is this the right approach? If so, how can I find the joint distribution of $\overline{X}$ and $T$?",,"['probability', 'statistics', 'uniform-distribution']"
