,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Ask George Casella Question 8.12 b,Ask George Casella Question 8.12 b,,"This is not a too much difficult question, but I think I have problems on concepts or understandings. The problem is a normal population: with mean $\mu$ and known variance $\sigma^2$ . Take $\alpha$ =.05. Then do the LRT that is: $H_0: \mu=0 $ versus $H_1:\mu \neq0$ . The solution is based on example 8.2.2. I can understand this example. In example 8.2.2., the variance is 1. So according to our problem here, I find the LRT statistic is $$\lambda(\textbf{x})=exp[-n\bar{x}^2/(2\sigma^2)]$$ This is similar to (8.2.2), except in our question we don't fix variance to be 1 and our specific value ( $\mu_0$ ) is zero. Then my idea is $\lambda(\textbf{x})\leq c$ , so we have $|\bar{x}|\geq \sqrt{\frac{-2\sigma^2 logc}{n}}$ Now I got my first problem. The solution said For α = .05 take c = 1.96. But I don't know what value c I should plug in. It reminds me when I do differential equations. We see a lot of constants, and each step we have a new c. For example, I can name c above as c. I can also name $logc$ as c. I think I can even name the whole term above as c, since n is fixed and we know $\sigma^2$ . When the solution said c = 1.96, I don't know what part is 1.96. Then I want to get power function. I know power function is $P(|\bar{x}|\geq \sqrt{\frac{-2\sigma^2 logc}{n}})$ . I know $\bar{x}$ has $norm(\mu, \sigma^2/n)$ . So $$P(|\bar{x}|\geq \sqrt{\frac{-2\sigma^2 logc}{n}}) =2*P(\bar{x} \geq \sqrt{\frac{-2\sigma^2 logc}{n}})=P(Z\geq \sqrt{-2logc}-\frac{\mu \sqrt{n}}{\sigma})$$ I don't know the above is correct and how to do next. The solution is below:","This is not a too much difficult question, but I think I have problems on concepts or understandings. The problem is a normal population: with mean and known variance . Take =.05. Then do the LRT that is: versus . The solution is based on example 8.2.2. I can understand this example. In example 8.2.2., the variance is 1. So according to our problem here, I find the LRT statistic is This is similar to (8.2.2), except in our question we don't fix variance to be 1 and our specific value ( ) is zero. Then my idea is , so we have Now I got my first problem. The solution said For α = .05 take c = 1.96. But I don't know what value c I should plug in. It reminds me when I do differential equations. We see a lot of constants, and each step we have a new c. For example, I can name c above as c. I can also name as c. I think I can even name the whole term above as c, since n is fixed and we know . When the solution said c = 1.96, I don't know what part is 1.96. Then I want to get power function. I know power function is . I know has . So I don't know the above is correct and how to do next. The solution is below:","\mu \sigma^2 \alpha H_0: \mu=0  H_1:\mu \neq0 \lambda(\textbf{x})=exp[-n\bar{x}^2/(2\sigma^2)] \mu_0 \lambda(\textbf{x})\leq c |\bar{x}|\geq \sqrt{\frac{-2\sigma^2 logc}{n}} logc \sigma^2 P(|\bar{x}|\geq \sqrt{\frac{-2\sigma^2 logc}{n}}) \bar{x} norm(\mu, \sigma^2/n) P(|\bar{x}|\geq \sqrt{\frac{-2\sigma^2 logc}{n}}) =2*P(\bar{x} \geq \sqrt{\frac{-2\sigma^2 logc}{n}})=P(Z\geq \sqrt{-2logc}-\frac{\mu \sqrt{n}}{\sigma})","['probability', 'statistics', 'statistical-inference']"
1,"How do you obtain Variance of the ""method of moment estimator"" for the beta distribution using delta method?","How do you obtain Variance of the ""method of moment estimator"" for the beta distribution using delta method?",,"I'm trying to solve a question where I have to find $V(\hat{\alpha})$ using the delta-method where $V$ is notation for variance and $\hat{\alpha}$ is the method of moment estimator for a beta distribution. To be more specific, I write down the question below: Suppose $X_1, ..., X_n$ be a random sample from the following distribution, $$f(x)=\alpha x^{\alpha -1}, 0<x<1\text{ and }\alpha>0.$$ Let $\hat{\alpha}$ be the method of moment estimator. Obtain the $V(\hat{\alpha})$ using the delta-method. I know that this function is just Beta distribution where $X\sim\mathrm{Beta}(\alpha,1)$ . So the method of moment $E(X^k)=\frac{\Gamma(\alpha +1)\Gamma(\alpha +k)}{\Gamma(\alpha)\Gamma(\alpha +k+1)}$ , where $\Gamma(\cdot)$ is a Gamma function. But how do I get the variance of the method of moment using delta method? I am not sure how the usage of the delta method will get me the variance. Thank you.","I'm trying to solve a question where I have to find using the delta-method where is notation for variance and is the method of moment estimator for a beta distribution. To be more specific, I write down the question below: Suppose be a random sample from the following distribution, Let be the method of moment estimator. Obtain the using the delta-method. I know that this function is just Beta distribution where . So the method of moment , where is a Gamma function. But how do I get the variance of the method of moment using delta method? I am not sure how the usage of the delta method will get me the variance. Thank you.","V(\hat{\alpha}) V \hat{\alpha} X_1, ..., X_n f(x)=\alpha x^{\alpha -1}, 0<x<1\text{ and }\alpha>0. \hat{\alpha} V(\hat{\alpha}) X\sim\mathrm{Beta}(\alpha,1) E(X^k)=\frac{\Gamma(\alpha +1)\Gamma(\alpha +k)}{\Gamma(\alpha)\Gamma(\alpha +k+1)} \Gamma(\cdot)","['statistics', 'gamma-function', 'variance', 'delta-method']"
2,"Question on limiting variance in example 10.1.8 (Casella, Statistical Inference, 2nd edition)","Question on limiting variance in example 10.1.8 (Casella, Statistical Inference, 2nd edition)",,"This is from George Casella textbook statistical inference (page 470) Example 10.1.8. Limiting variances. It says for the mean $\bar{X_n}$ of n iid normal observations with $EX=\mu$ and $VarX=\sigma^2$ , if we take $T_n=\bar{X_n}$ , then $lim\sqrt{n}Var\bar{X_n}=\sigma^2$ is the limiting variance of $T_n$ . I feel very confused. I think $\bar{X_n}$ is $n(\mu, \sigma^2/n)$ . Then $lim\sqrt{n}*Var\bar{X_n}=lim\sqrt{n}*\sigma^2/n=\sigma^2lim\frac{\sqrt{n}}{n}=0$ . The limit is 0, not $\sigma^2$ . Please point my mistake.","This is from George Casella textbook statistical inference (page 470) Example 10.1.8. Limiting variances. It says for the mean of n iid normal observations with and , if we take , then is the limiting variance of . I feel very confused. I think is . Then . The limit is 0, not . Please point my mistake.","\bar{X_n} EX=\mu VarX=\sigma^2 T_n=\bar{X_n} lim\sqrt{n}Var\bar{X_n}=\sigma^2 T_n \bar{X_n} n(\mu, \sigma^2/n) lim\sqrt{n}*Var\bar{X_n}=lim\sqrt{n}*\sigma^2/n=\sigma^2lim\frac{\sqrt{n}}{n}=0 \sigma^2","['probability', 'statistics', 'statistical-inference']"
3,How to calculate $p$-value in a clinical trial,How to calculate -value in a clinical trial,p,"I'm trying to verify the $p$ -value mentioned in this article: $8\%$ ( $n=\frac{1}{13}$ ) of mavrilimumab-treated patients progressed to mechanical ventilation by Day $28$ , compared to $35\%$ ( $n=\frac{9}{26}$ ) of control-group patients who progressed to mechanical ventilation or died ( $\textbf{p=0.077}$ ). How can I calculate the $p$ -value for the data above? I used $3$ different calculators and they all gave different results, none of them matches with the article. Calculator 1 : $p=0.12$ Calculator 2: $p =  0.06876$ Calculator 3: $p = 0.154$","I'm trying to verify the -value mentioned in this article: ( ) of mavrilimumab-treated patients progressed to mechanical ventilation by Day , compared to ( ) of control-group patients who progressed to mechanical ventilation or died ( ). How can I calculate the -value for the data above? I used different calculators and they all gave different results, none of them matches with the article. Calculator 1 : Calculator 2: Calculator 3:",p 8\% n=\frac{1}{13} 28 35\% n=\frac{9}{26} \textbf{p=0.077} p 3 p=0.12 p =  0.06876 p = 0.154,"['statistics', 'p-value']"
4,Sufficient condition for convergence in mean,Sufficient condition for convergence in mean,,"I want to prove that if $\xi_n$ is sequence of non-negative random variables, $\xi_n\xrightarrow {a.e.}\xi$ and $\mathbb{E}\xi_n^p \to \mathbb{E}\xi^p $ than $$\mathbb{E}|\xi_n-\xi|^p\to0 \text{ (i.e. }\xi_n\xrightarrow {L^p}\xi)$$ I don't know where to start. I would be very grateful for help!","I want to prove that if is sequence of non-negative random variables, and than I don't know where to start. I would be very grateful for help!",\xi_n \xi_n\xrightarrow {a.e.}\xi \mathbb{E}\xi_n^p \to \mathbb{E}\xi^p  \mathbb{E}|\xi_n-\xi|^p\to0 \text{ (i.e. }\xi_n\xrightarrow {L^p}\xi),"['probability', 'probability-theory', 'statistics', 'random-variables']"
5,What is the covariance of the exponential of two jointly distributed normal random variables?,What is the covariance of the exponential of two jointly distributed normal random variables?,,"Suppose I have the bivariate normal variable $[X \ \ Y]'$ which has mean $[\mu_X \ \ \mu_Y]'$ and covariance matrix $ \left[ \begin{array}{cc} \sigma_X ^2 & \sigma_Y \ \sigma_X \ \\  \sigma_Y \ \sigma_X \ & \sigma_Y^2  \end{array} \right]$ . I am trying to figure out what is $\text{Cov}(e^X, e^Y)$ . I'm aware of Stein's lemma which says $\text{Cov}(g(X), Y) = \text{Cov}(X,Y)E[g'(X)]$ , but I don't know how it's derived, or how to extend it to functions on both $X$ and $Y$ . Presumably this case should be simpler since it's the exponential function. Otherwise I'm unsure what other steps to take. I don't need to prove this, but the answer is necessary for a calculation I am doing.","Suppose I have the bivariate normal variable which has mean and covariance matrix . I am trying to figure out what is . I'm aware of Stein's lemma which says , but I don't know how it's derived, or how to extend it to functions on both and . Presumably this case should be simpler since it's the exponential function. Otherwise I'm unsure what other steps to take. I don't need to prove this, but the answer is necessary for a calculation I am doing.","[X \ \ Y]' [\mu_X \ \ \mu_Y]'  \left[ \begin{array}{cc}
\sigma_X ^2 & \sigma_Y \ \sigma_X \ \\ 
\sigma_Y \ \sigma_X \ & \sigma_Y^2 
\end{array} \right] \text{Cov}(e^X, e^Y) \text{Cov}(g(X), Y) = \text{Cov}(X,Y)E[g'(X)] X Y","['probability', 'statistics', 'normal-distribution', 'covariance']"
6,Regularized Incomplete Beta Function,Regularized Incomplete Beta Function,,"I try to solve this property of Regularized Incomplete Beta Function. How can you solve a statement : $I_x (a,a) = 1 - \frac{1}{2} I_{4x(1-x)}(a,\frac{1}{2})  $ where $1/2 \leq x \leq 1$ . Some definitions : $I_x (a,b) = \frac{B(x;a,b)}{B(a,b)}$ with B(x;a,b) is incomplete Beta function and B(a,b) is Beta function. I tried to use substitution rule with z = 1 - x. But it doesn't go any further. Could someone give me idea more please ?","I try to solve this property of Regularized Incomplete Beta Function. How can you solve a statement : where . Some definitions : with B(x;a,b) is incomplete Beta function and B(a,b) is Beta function. I tried to use substitution rule with z = 1 - x. But it doesn't go any further. Could someone give me idea more please ?","I_x (a,a) = 1 - \frac{1}{2} I_{4x(1-x)}(a,\frac{1}{2})   1/2 \leq x \leq 1 I_x (a,b) = \frac{B(x;a,b)}{B(a,b)}","['statistics', 'beta-function']"
7,Multiplying a Probability distribution function by a constant,Multiplying a Probability distribution function by a constant,,"This is a pretty basic question, I understand, but in my head there is something that doesn't make sense. Let's say I have a uniform probability density function X that goes from [0,6]. The pdf would thus be 1/(6-0), which is just 1/6. Now, let's say I multiply this pdf X by 2, to get Y= 2X. Would the pdf then be 2*(1/6)? If so, wouldn't this break the condition that the integral of a pdf has to be equal to 1? What would I do? And for whatever answer I get, would that work for all pdf's (binomial, Poisson, uniform, normal, etc).","This is a pretty basic question, I understand, but in my head there is something that doesn't make sense. Let's say I have a uniform probability density function X that goes from [0,6]. The pdf would thus be 1/(6-0), which is just 1/6. Now, let's say I multiply this pdf X by 2, to get Y= 2X. Would the pdf then be 2*(1/6)? If so, wouldn't this break the condition that the integral of a pdf has to be equal to 1? What would I do? And for whatever answer I get, would that work for all pdf's (binomial, Poisson, uniform, normal, etc).",,"['probability', 'statistics', 'density-function']"
8,"(X,X) independent and moments","(X,X) independent and moments",,"I have a question regarding a random variable X being independent of itself. I have to proof, knowing that X has no moment, that the following real number exists: $$ t_{0} = \inf_{} \{t\in \mathbb{R} | F_X(t) = 1 \}$$ Please, if my question is ambiguous or unclear, do not hesitate to edit it ! Thank you so much !","I have a question regarding a random variable X being independent of itself. I have to proof, knowing that X has no moment, that the following real number exists: Please, if my question is ambiguous or unclear, do not hesitate to edit it ! Thank you so much !", t_{0} = \inf_{} \{t\in \mathbb{R} | F_X(t) = 1 \},"['probability', 'statistics', 'random-variables']"
9,"Is $\inf \{P(|X| > \varepsilon) : E[X] = 0, \operatorname{Var}(X) = 1\} = 0$ for all $\varepsilon > 0$?",Is  for all ?,"\inf \{P(|X| > \varepsilon) : E[X] = 0, \operatorname{Var}(X) = 1\} = 0 \varepsilon > 0","If $\varepsilon > 0$ , is it true that the infimum of $\{P(|X| > \varepsilon) : E[X] = 0, \operatorname{Var} (X) = 1\}$ is zero? That is, for every $a > 0$ , can we always find a random variable $X$ with zero mean and unit variance that satisfies $P(|X| > \varepsilon) < a$ ? My first attempt to prove this statement was by using the Chebyshev's inequality: if $E[X] = 0$ and $\operatorname{Var} (X) = 1$ , then $E[X^2] = \operatorname{Var} (X) + E[X]^2 = 1$ , so we have $$P(|X| > \varepsilon) \leq \frac{1}{\varepsilon^2}.$$ However, this inequality seems to be unhelpful, especially if $\varepsilon \leq 1$ . Moreover, the right hand side does not even depend on $X$ or any other variable, so I cannot make the upper bound of $P(|X| > \varepsilon)$ to approach zero in this inequality. Next, I tried to construct a sequence $\{X_n\}_{n\in\mathbb{N}}$ of random variables based on the uniform and U quadratic distributions. The idea is to reduce the support of $X_n$ to be less than $[-\varepsilon, \varepsilon]$ as $n \to \infty$ , so that $P(|X_n| > \varepsilon) = 0$ eventually. More precisely, each $X_n$ has a probability density function defined by $$f_{X_n} = \frac{2n+1}{2a_n^{2n+1}}x^{2n} \quad (x \in [-a_n,a_n]),$$ where $a_n = \sqrt{1+\frac{2}{2n+1}}$ , and zero otherwise (this formulation ensures that $E[X_n] = 0$ and $\operatorname{Var}(X_n) = 1$ for all $n$ ). Unfortunately, $a_n$ converges to $1$ in this case, and $P(|X_n| > \varepsilon) \neq 0$ for $\varepsilon < 1$ . After these attempts, I began to doubt the validity of this proposition. After all, wouldn't a random variable with variance of $1$ surely ""spread over"" to the value of $1$ if it is centered at $0$ ? This is only my intuition and I have yet to prove this. But if that's the case, then $P(|X| > \varepsilon)$ surely can't approach $0$ for $0 < \varepsilon < 1$ . Any help on proving or disproving the statement in my question is appreciated.","If , is it true that the infimum of is zero? That is, for every , can we always find a random variable with zero mean and unit variance that satisfies ? My first attempt to prove this statement was by using the Chebyshev's inequality: if and , then , so we have However, this inequality seems to be unhelpful, especially if . Moreover, the right hand side does not even depend on or any other variable, so I cannot make the upper bound of to approach zero in this inequality. Next, I tried to construct a sequence of random variables based on the uniform and U quadratic distributions. The idea is to reduce the support of to be less than as , so that eventually. More precisely, each has a probability density function defined by where , and zero otherwise (this formulation ensures that and for all ). Unfortunately, converges to in this case, and for . After these attempts, I began to doubt the validity of this proposition. After all, wouldn't a random variable with variance of surely ""spread over"" to the value of if it is centered at ? This is only my intuition and I have yet to prove this. But if that's the case, then surely can't approach for . Any help on proving or disproving the statement in my question is appreciated.","\varepsilon > 0 \{P(|X| > \varepsilon) : E[X] = 0, \operatorname{Var} (X) = 1\} a > 0 X P(|X| > \varepsilon) < a E[X] = 0 \operatorname{Var} (X) = 1 E[X^2] = \operatorname{Var} (X) + E[X]^2 = 1 P(|X| > \varepsilon) \leq \frac{1}{\varepsilon^2}. \varepsilon \leq 1 X P(|X| > \varepsilon) \{X_n\}_{n\in\mathbb{N}} X_n [-\varepsilon, \varepsilon] n \to \infty P(|X_n| > \varepsilon) = 0 X_n f_{X_n} = \frac{2n+1}{2a_n^{2n+1}}x^{2n} \quad (x \in [-a_n,a_n]), a_n = \sqrt{1+\frac{2}{2n+1}} E[X_n] = 0 \operatorname{Var}(X_n) = 1 n a_n 1 P(|X_n| > \varepsilon) \neq 0 \varepsilon < 1 1 1 0 P(|X| > \varepsilon) 0 0 < \varepsilon < 1","['probability', 'statistics', 'probability-distributions', 'random-variables']"
10,On the notation of the likelihood function,On the notation of the likelihood function,,"Let $X$ be a random variable realized as the event $(X=x)$ . The corresponding likelihood function is given by $$\mathcal{L}_x:\Theta\rightarrow[0,1]$$ $$\theta\mapsto P(X=x|\theta)$$ for a space $\Theta$ of parameter configurations $\theta$ . In the literature, $\mathcal{L}_x(\theta)$ is sometimes written as $\mathcal{L}(\theta|X=x)$ . I assume this is done to emphasize that the event $(X=x)$ is 'given'. However, this notation leads to confusion, since it suggests that $\mathcal{L}_x$ is a probability density ('conditioning' on the event $X=x$ ), which appears to not be true in general (cf. second answer in this thread on math.overflow ). So my questions are: Is $\mathcal{L}(\theta|X=x)$ just 'overloading' the notation $f(\cdot|\cdot)$ , or is there some hidden meaning/analogy to conditional probability $P(\cdot|\cdot)$ which I am missing? Are there other areas in mathematics where $f(\cdot|\cdot)$ is used? Could you provide an example? Currently, I think $\mathcal{L}(\theta|X=x)$ is a bad notational choice because it caused confusion for me when trying to understand the likelihood function. Especially since at any point $\theta$ , one has $\mathcal{L}(\theta|X=x)=P(X=x|\theta)$","Let be a random variable realized as the event . The corresponding likelihood function is given by for a space of parameter configurations . In the literature, is sometimes written as . I assume this is done to emphasize that the event is 'given'. However, this notation leads to confusion, since it suggests that is a probability density ('conditioning' on the event ), which appears to not be true in general (cf. second answer in this thread on math.overflow ). So my questions are: Is just 'overloading' the notation , or is there some hidden meaning/analogy to conditional probability which I am missing? Are there other areas in mathematics where is used? Could you provide an example? Currently, I think is a bad notational choice because it caused confusion for me when trying to understand the likelihood function. Especially since at any point , one has","X (X=x) \mathcal{L}_x:\Theta\rightarrow[0,1] \theta\mapsto P(X=x|\theta) \Theta \theta \mathcal{L}_x(\theta) \mathcal{L}(\theta|X=x) (X=x) \mathcal{L}_x X=x \mathcal{L}(\theta|X=x) f(\cdot|\cdot) P(\cdot|\cdot) f(\cdot|\cdot) \mathcal{L}(\theta|X=x) \theta \mathcal{L}(\theta|X=x)=P(X=x|\theta)","['statistics', 'notation', 'conditional-probability', 'log-likelihood']"
11,P-values and statistical significance,P-values and statistical significance,,"The mean for the result of a regional test is $525$ points with a deviation of $80$ . A $90$ students class did the test and got a mean score of $535$ . Is the mean score of the class different from the regional mean score for a statistical significance of $0.05$ ? I'm trying to understand the role of statistical significance and just can't wrap my head around how could these means not be different, would love to get some help understanding this problem.","The mean for the result of a regional test is points with a deviation of . A students class did the test and got a mean score of . Is the mean score of the class different from the regional mean score for a statistical significance of ? I'm trying to understand the role of statistical significance and just can't wrap my head around how could these means not be different, would love to get some help understanding this problem.",525 80 90 535 0.05,['statistics']
12,finding the mean in normal distribution,finding the mean in normal distribution,,"I am struggling on this question where I need to find the mean given the standard deviation. The question is the following: A certain brand of flood lamps has a length of life that is normally distributed,  with a standard deviation of 392 hours. If 8 % of the lamps last more than 5600 hours, what is the mean length of life? This is what I've tried so far let $X$ = length of light $X\sim\mathcal{N}(\text{mean = unknown }(u), SD = 392)$ $P(X > 5600) = 0.8$ $1 - P(X < 5600) = 0.8$ (stuck after this part) $1 - P(5600-u/392 < 5600) = 0.8$ ( incorrect) I am having troubles working backwards to the find the mean. Could someone point me in the right direction.","I am struggling on this question where I need to find the mean given the standard deviation. The question is the following: A certain brand of flood lamps has a length of life that is normally distributed,  with a standard deviation of 392 hours. If 8 % of the lamps last more than 5600 hours, what is the mean length of life? This is what I've tried so far let = length of light (stuck after this part) ( incorrect) I am having troubles working backwards to the find the mean. Could someone point me in the right direction.","X X\sim\mathcal{N}(\text{mean = unknown }(u), SD = 392) P(X > 5600) = 0.8 1 - P(X < 5600) = 0.8 1 - P(5600-u/392 < 5600) = 0.8","['statistics', 'normal-distribution']"
13,Intuition behind the exponential loss function,Intuition behind the exponential loss function,,"I'm reading about AdaBoost from the book The Elements of Statistical Learning . The book mentions that, to train the model, the exponential loss function is used: $$L(y, f (x)) = e^{−y f (x)},$$ where $y$ is the expected output and $f(x)$ is the model output given the feature $x$ . The problem I have understanding this loss function is that ""same errors"" give different loss. For example, $y=1$ and $f(x)=0.8$ then $L(y, f (x)) = e^{−0.8}$ $y=0$ and $f(x)=.2$ then $L(y, f (x)) = e^{0.2} \neq e^{−0.8}$ In both cases, $y-f(x)= 0.2$ , but the loss functions give different values. Could anyone tell me what I'm missing here? Thank you!","I'm reading about AdaBoost from the book The Elements of Statistical Learning . The book mentions that, to train the model, the exponential loss function is used: where is the expected output and is the model output given the feature . The problem I have understanding this loss function is that ""same errors"" give different loss. For example, and then and then In both cases, , but the loss functions give different values. Could anyone tell me what I'm missing here? Thank you!","L(y, f (x)) = e^{−y f (x)}, y f(x) x y=1 f(x)=0.8 L(y, f (x)) = e^{−0.8} y=0 f(x)=.2 L(y, f (x)) = e^{0.2} \neq e^{−0.8} y-f(x)= 0.2","['statistics', 'intuition', 'machine-learning']"
14,Understanding the derivation of the PDF of a two-point mixed distribution from its CDF,Understanding the derivation of the PDF of a two-point mixed distribution from its CDF,,"A random variable $X$ has the cumulative distribution function $$\begin{cases} 0 & x<1 \\ \dfrac{x^2-2x+2}{2} & 1 \le x<2 \\ 1 & x\ge 2 \end{cases}$$ Calculate $E[X]$ . The answer uses the following pdf to get $E[X]$ : $$\begin{cases} \dfrac{1}{2} & x=1 \\ x-1 & 1 < x<2 \\ 0 & \text{otherwise} \end{cases}$$ The book I am reading doesn't have much (any!) information on two-point mixed distributions and I want to make sure that I understand how this PDF was derived from the CDF. My understanding so far is that firstly, we need to figure out from the CDF that $X$ follows a mixed distribution. Note that $F(1) = 1/2 \ne 0$ , which indicates that there is a jump in the CDF of $X$ at $x=1$ . Since $X$ is continuous from $1<x<2$ , $X$ must follow a two-point mixed distribution. Now, the magnitude of the jump in the graph is $\frac{1}{2}-0 = \frac{1}{2}$ which gives $f(x) = \frac{1}{2}$ if $x=1$ . The rest of the pdf can be obtained using routine computations. Finally, we need to compute the probabilistic ""weights"" to get to the CDF. Clearly, the ""weight"" for the discrete part is $\frac{1}{2}$ , so the ""weight"" for the continuous part must be $1-\frac{1}{2} = \frac{1}{2}$ , and we have $$E[X] = \int_1^2 (x-1) \cdot x dx + \text{Weight for the discrete part} \cdot 1 = \int_1^2 x(x-1) dx + P[X=1] \cdot 1$$ $$= \int_1^2 x(x-1) dx + \frac{1}{2}$$ which gives the correct answer. However, I am more interested in learning whether my process for obtaining the answer (which was based mostly on deduction and intuition) is correct. Can someone please critique my post? Thanks!","A random variable has the cumulative distribution function Calculate . The answer uses the following pdf to get : The book I am reading doesn't have much (any!) information on two-point mixed distributions and I want to make sure that I understand how this PDF was derived from the CDF. My understanding so far is that firstly, we need to figure out from the CDF that follows a mixed distribution. Note that , which indicates that there is a jump in the CDF of at . Since is continuous from , must follow a two-point mixed distribution. Now, the magnitude of the jump in the graph is which gives if . The rest of the pdf can be obtained using routine computations. Finally, we need to compute the probabilistic ""weights"" to get to the CDF. Clearly, the ""weight"" for the discrete part is , so the ""weight"" for the continuous part must be , and we have which gives the correct answer. However, I am more interested in learning whether my process for obtaining the answer (which was based mostly on deduction and intuition) is correct. Can someone please critique my post? Thanks!","X \begin{cases}
0 & x<1 \\
\dfrac{x^2-2x+2}{2} & 1 \le x<2 \\
1 & x\ge 2
\end{cases} E[X] E[X] \begin{cases}
\dfrac{1}{2} & x=1 \\
x-1 & 1 < x<2 \\
0 & \text{otherwise}
\end{cases} X F(1) = 1/2 \ne 0 X x=1 X 1<x<2 X \frac{1}{2}-0 = \frac{1}{2} f(x) = \frac{1}{2} x=1 \frac{1}{2} 1-\frac{1}{2} = \frac{1}{2} E[X] = \int_1^2 (x-1) \cdot x dx + \text{Weight for the discrete part} \cdot 1 = \int_1^2 x(x-1) dx + P[X=1] \cdot 1 = \int_1^2 x(x-1) dx + \frac{1}{2}","['probability', 'statistics', 'probability-distributions', 'solution-verification']"
15,Likelihood of Uniform Distribution Indicator Function,Likelihood of Uniform Distribution Indicator Function,,"It is well known that the likelihood function for the uniform distribution on $[0,\theta]$ is given by $$\frac{1}{\theta^n} \mathbf{1}_{\max(x_1,\ldots,x_n)\leq \theta}$$ Where the reason for this indicator is that the likelihood will be equal to $0$ if one of our observations $x_i$ exceeds $\theta$ . But why do we not impose a similar condition on an observation being less than $0$ ? That is, also including $\mathbf{1}_{\min{(x_1,\ldots,x_n)\geq0}}$ ? Sorry if I've misunderstood anything, please feel free to correct me!","It is well known that the likelihood function for the uniform distribution on is given by Where the reason for this indicator is that the likelihood will be equal to if one of our observations exceeds . But why do we not impose a similar condition on an observation being less than ? That is, also including ? Sorry if I've misunderstood anything, please feel free to correct me!","[0,\theta] \frac{1}{\theta^n} \mathbf{1}_{\max(x_1,\ldots,x_n)\leq \theta} 0 x_i \theta 0 \mathbf{1}_{\min{(x_1,\ldots,x_n)\geq0}}","['probability', 'statistics', 'uniform-distribution', 'maximum-likelihood']"
16,A limit $\lim_{x \to 0} \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2} = \frac12$ and continuity of Kolmogorov distribution.,A limit  and continuity of Kolmogorov distribution.,\lim_{x \to 0} \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2} = \frac12,"Problem: prove that $$\sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2} \to \frac12, x\to 0,$$ not using theta-function. Motivation: Kolmogorov–Smirnov statistic is well known. It's limit distribution has a continious distribution function $F(x)$ such that $F(x) = 0$ for $x \le 0$ and $$F(x) = 1 - 2 \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2}  = \frac{\sqrt{2\pi}}{x} \sum_{k=1}^{\infty} e^{-\frac{(2k-1)^2 \pi^2}{8x^2}}$$ otherwise. The equivalence of two expressions $F_1(x) = 1 - 2 \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2}$ and $F_2(x) = \frac{\sqrt{2\pi}}{x} \sum_{k=1}^{\infty} e^{-\frac{(2k-1)^2 \pi^2}{8x^2}}$ follows easily from transformation formula for theta-functions. Using $F_2(x)$ it's easy to prove that $F(x)$ is continuous for all $x$ . Using $F_1(x)$ it's easy to prove that $F(x)$ is continuous for all $x \ne 0$ . My question was the next one: is there any simple way to prove that $F(x) $ is continuous at $x=0$ , using the definition with $F_1(x)$ ? As $F_1(x)$ is even then the statement "" $F_1(x) \to 0, x \to 0+$ "" is equivalent to the statement "" $F_1(x) \to 0, x \to 0$ "". So, my question is: is there any simple way (without theta-functions) to prove that $$\sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2} \to \frac12, x\to 0?$$ What do I know? I know that the statement $\sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2} \to \frac12, x\to 0$ follows from properties of theta-functions, but the question is about simple methods. I thought about the next idea: if $x=0$ , then we have divergent series $S = 1 - 1 + 1 - 1 + 1 - \ldots = 1 - S$ . It's a wrong way, but in some sense it's natural to write $S= 1 -S$ and hence $S = \frac{1}2$ . Unfortunatelly, $S$ doesn't exist.","Problem: prove that not using theta-function. Motivation: Kolmogorov–Smirnov statistic is well known. It's limit distribution has a continious distribution function such that for and otherwise. The equivalence of two expressions and follows easily from transformation formula for theta-functions. Using it's easy to prove that is continuous for all . Using it's easy to prove that is continuous for all . My question was the next one: is there any simple way to prove that is continuous at , using the definition with ? As is even then the statement "" "" is equivalent to the statement "" "". So, my question is: is there any simple way (without theta-functions) to prove that What do I know? I know that the statement follows from properties of theta-functions, but the question is about simple methods. I thought about the next idea: if , then we have divergent series . It's a wrong way, but in some sense it's natural to write and hence . Unfortunatelly, doesn't exist.","\sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2} \to \frac12, x\to 0, F(x) F(x) = 0 x \le 0 F(x) = 1 - 2 \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2}  = \frac{\sqrt{2\pi}}{x} \sum_{k=1}^{\infty} e^{-\frac{(2k-1)^2 \pi^2}{8x^2}} F_1(x) = 1 - 2 \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2} F_2(x) = \frac{\sqrt{2\pi}}{x} \sum_{k=1}^{\infty} e^{-\frac{(2k-1)^2 \pi^2}{8x^2}} F_2(x) F(x) x F_1(x) F(x) x \ne 0 F(x)  x=0 F_1(x) F_1(x) F_1(x) \to 0, x \to 0+ F_1(x) \to 0, x \to 0 \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2} \to \frac12, x\to 0? \sum_{k=1}^{\infty} (-1)^{k-1} e^{-2k^2 x^2} \to \frac12, x\to 0 x=0 S = 1 - 1 + 1 - 1 + 1 - \ldots = 1 - S S= 1 -S S = \frac{1}2 S","['real-analysis', 'calculus', 'statistics']"
17,"Statistics, Hypothesis and P-value - Check my answers","Statistics, Hypothesis and P-value - Check my answers",,"I am trying to solve a question but stuck with the steps. I can not find any similar questions. With help of some online resources to calculate some parts of the question but I can see that is not enough. I know my approach has lack of information but, this is the only thing I have reached, I was covid ill at the class hours and can not follow the class examples, I thought someone can help me to solve and learn the subject. With help of the answers from here I try to give an answer. Still need some improvements but tried to do my best. I still do not have answer for question D and confused about CL(the part C) and Significance level(part B) My answers: $N\ =\ 9\ \ \ \ \ \ \ \ Sum\ of\ x\ =\ 3970\ \ \ \ \ \ \ \ Mean,\ µ = 441.1111  \      Variance,σ^2  = 161.1111$ $ \sigma\ =\ \sqrt{161.1111}  = 12.6929$ $t\ =\ \frac{m\ -\ \mu}{s\ /\ \sqrt n}$ $t\ =\ \frac{500\ -\ 441.1111}{12.6929\ /\ \sqrt9} = 13.918545$ We subtract 1 to get degrees free 9 - 1 = 8 Degrees of freedom = n – 1 = 8 $Probability: P( T ≤ 13.918545) = 0.00000069 $ So, this is the p-Value $We\ will\ reject\ H_0\ at \ \alpha = 1% $ and also any > 1% $$ (i) 0.10\ The\ information\ from\ the\ first\ question\, the\ critical\ t-value\ for\ α = 0.10\ and\ df = 8,\ t_c=\ 1.86  \\ CI\ =\ (\bar{X}\ -\ \frac{t_c\ \times\ s}{\sqrt n},\ \bar{\ X}\ +\ \frac{t_c\ \times\ s}{\sqrt n})  \\CI\ =\ (441.1111\ -\ \frac{1.86\ \times\ 12.6929}{\sqrt9},\ \ 441.1111+\frac{1.86\ \times\ 12.6929}{\sqrt9}) = (441.1111 – 7.868, 441.1111 + 7.868) = (433.243, 448.979)  $$ $For\ the\ other\ t_c\ values:$ (ii) 0.05 $t_c=\ 2.306$ CL = (431.354, 450.868) (iii) 0.01 $t_c=\ > 3.355$ = (426.915, 455.308) Based on the answers in part 2 for (i) = 0.90, (ii) = 0.95, (iii) = 0.99, none of the confidence intervals contain 500. The Question: The worker says that the mean purchasing cost is 500 USD. We decide to test this. For a random sample of 9 purchases drawn from a normally distributed population with unknown variance, the costs are: 430, 450, 450, 440, 460, 420, 430, 450, 440. A) Conduct a hypothesis test of whether the population mean purchasing equals 500 USD. Include all assumptions, the hypotheses, test statistic, and P-value and interpret the result in context. B) For which significance levels can you reject $H_0?$ (i) 0.10, (ii) 0.05, or (iii) 0.01. C) Based on the answers in part B), for which confidence levels would the confidence interval contain 500? (i) 0.90, (ii) 0.95, or (iii) 0.99. D) Use part B) and part C) to illustrate the correspondence between results of significance tests and results of confidence intervals.","I am trying to solve a question but stuck with the steps. I can not find any similar questions. With help of some online resources to calculate some parts of the question but I can see that is not enough. I know my approach has lack of information but, this is the only thing I have reached, I was covid ill at the class hours and can not follow the class examples, I thought someone can help me to solve and learn the subject. With help of the answers from here I try to give an answer. Still need some improvements but tried to do my best. I still do not have answer for question D and confused about CL(the part C) and Significance level(part B) My answers: We subtract 1 to get degrees free 9 - 1 = 8 Degrees of freedom = n – 1 = 8 So, this is the p-Value and also any > 1% (ii) 0.05 CL = (431.354, 450.868) (iii) 0.01 = (426.915, 455.308) Based on the answers in part 2 for (i) = 0.90, (ii) = 0.95, (iii) = 0.99, none of the confidence intervals contain 500. The Question: The worker says that the mean purchasing cost is 500 USD. We decide to test this. For a random sample of 9 purchases drawn from a normally distributed population with unknown variance, the costs are: 430, 450, 450, 440, 460, 420, 430, 450, 440. A) Conduct a hypothesis test of whether the population mean purchasing equals 500 USD. Include all assumptions, the hypotheses, test statistic, and P-value and interpret the result in context. B) For which significance levels can you reject (i) 0.10, (ii) 0.05, or (iii) 0.01. C) Based on the answers in part B), for which confidence levels would the confidence interval contain 500? (i) 0.90, (ii) 0.95, or (iii) 0.99. D) Use part B) and part C) to illustrate the correspondence between results of significance tests and results of confidence intervals.","N\ =\ 9\ \ \ \ \ \ \ \ Sum\ of\ x\ =\ 3970\ \ \ \ \ \ \ \ Mean,\ µ = 441.1111  \      Variance,σ^2  = 161.1111  \sigma\ =\ \sqrt{161.1111}  = 12.6929 t\ =\ \frac{m\ -\ \mu}{s\ /\ \sqrt n} t\ =\ \frac{500\ -\ 441.1111}{12.6929\ /\ \sqrt9} = 13.918545 Probability: P( T ≤ 13.918545) = 0.00000069  We\ will\ reject\ H_0\ at \ \alpha = 1%   (i) 0.10\
The\ information\ from\ the\ first\ question\, the\ critical\ t-value\ for\ α = 0.10\ and\ df = 8,\ t_c=\ 1.86
 \\ CI\ =\ (\bar{X}\ -\ \frac{t_c\ \times\ s}{\sqrt n},\ \bar{\ X}\ +\ \frac{t_c\ \times\ s}{\sqrt n})
 \\CI\ =\ (441.1111\ -\ \frac{1.86\ \times\ 12.6929}{\sqrt9},\ \ 441.1111+\frac{1.86\ \times\ 12.6929}{\sqrt9})
= (441.1111 – 7.868, 441.1111 + 7.868)
= (433.243, 448.979)
  For\ the\ other\ t_c\ values: t_c=\ 2.306 t_c=\
> 3.355 H_0?","['statistics', 'hypothesis-testing', 'p-value']"
18,"A problem about convergence in distribution to $N(0,1)$.",A problem about convergence in distribution to .,"N(0,1)","Let $(Y_{n})_{n\geq 1}$ be a sequence of  independents random variables such that $$\mathbb{P}[Y_{n}=1]=\mathbb{P}[Y_{n}=-1]=\frac{1}{2n}, \quad \mathbb{P}[Y_{n}=0]=1-\frac{1}{n}, \quad n \geq 1$$ Let $S_{n}=\sum_{i=1}^{n}Y_{i}$ and prove that $$\frac{S_{n}}{n}\overset{a.s}{\to}0 \quad \text{and} \quad \frac{S_{n}}{\sqrt{\log(n)}}\overset{D}{\to}N(0,1)$$ My approach: For the first part, it's to say prove that $\frac{S_{n}}{n} \overset{a.s}{\to} 0$ I think that since that for $n\geq 1$ , we know that \begin{eqnarray*} Y_{n}=1 \implies \mathbb{P}[Y_{n}=1]=\frac{1}{2n}\\ Y_{n}=-1 \implies \mathbb{P}[Y_{n}=-1]=\frac{1}{2n}\\ Y_{n}=0 \implies \mathbb{P}[Y_{n}=0]=1-\frac{1}{n}\\ \end{eqnarray*} other values is not possible. So, the support for $Y_{n}$ is $S_{Y_{n}}={-1,0,1}$ . So, by definition we have $$\mathbb{E}Y_{n}=\sum_{y_{n}\in S_{Y_{n}}}y_{n}\mathbb{P}[Y_{n}=y]=\sum_{y_{n}\in \{-1,0,1\}}y_{n}\mathbb{P}[Y_{n}=y]=0$$ similarly, we have $$\mathbb{V}Y_{n}=\mathbb{E}Y_{n}^{2}-(\mathbb{E}Y_{n})^{2}=\frac{1}{n}$$ and since that $\displaystyle \sum_{n=1}^{\infty}\frac{\mathbb{V}Y_{n}}{n^{2}}<\infty$ , so by SLLN-Kolmogorov with have $$\frac{S_{n}-\mathbb{E}S_{n}}{n}=\frac{S_{n}}{n} \overset{a.s}{\to} 0$$ For the second part, to prove that $\frac{S_{n}}{\sqrt{\log(n)}}\overset{D}{\to} N(0,1)$ but don't have the hypothesis identical distribution, so I can't use the central limit theorem. How can I solve this part? Note: I know that if $Y_{1},Y_{2},\ldots$ are independent random variables and let $\displaystyle S_{n}=\sum_{i=1}^{n}Y_{n}$ . For each $i$ let $\mu_{i}=\mathbb{E}Y_{i}$ and $\sigma^{2}_{i}=\mathbb{V}Y_{i}$ and let $m_{n}=\sum_{i=1}^{\infty}\mu_{i}$ and $s_{n}^{2}=\sum_{i=1}^{n}\sigma_{i}^{2}$ mean and variance respectively. Suppose that a) $s_{n}^{2}\to \infty \quad \text{as} \quad n \to \infty$ and b) there exists a constant $M$ sucha that $\mathbb{P}[|X_{i}|\leq M]=1, \forall i$ . So we have $$\frac{S_{n}-m_{n}}{s_{n}}\overset{D}{\to}N(0,1)$$","Let be a sequence of  independents random variables such that Let and prove that My approach: For the first part, it's to say prove that I think that since that for , we know that other values is not possible. So, the support for is . So, by definition we have similarly, we have and since that , so by SLLN-Kolmogorov with have For the second part, to prove that but don't have the hypothesis identical distribution, so I can't use the central limit theorem. How can I solve this part? Note: I know that if are independent random variables and let . For each let and and let and mean and variance respectively. Suppose that a) and b) there exists a constant sucha that . So we have","(Y_{n})_{n\geq 1} \mathbb{P}[Y_{n}=1]=\mathbb{P}[Y_{n}=-1]=\frac{1}{2n}, \quad \mathbb{P}[Y_{n}=0]=1-\frac{1}{n}, \quad n \geq 1 S_{n}=\sum_{i=1}^{n}Y_{i} \frac{S_{n}}{n}\overset{a.s}{\to}0 \quad \text{and} \quad \frac{S_{n}}{\sqrt{\log(n)}}\overset{D}{\to}N(0,1) \frac{S_{n}}{n} \overset{a.s}{\to} 0 n\geq 1 \begin{eqnarray*}
Y_{n}=1 \implies \mathbb{P}[Y_{n}=1]=\frac{1}{2n}\\
Y_{n}=-1 \implies \mathbb{P}[Y_{n}=-1]=\frac{1}{2n}\\
Y_{n}=0 \implies \mathbb{P}[Y_{n}=0]=1-\frac{1}{n}\\
\end{eqnarray*} Y_{n} S_{Y_{n}}={-1,0,1} \mathbb{E}Y_{n}=\sum_{y_{n}\in S_{Y_{n}}}y_{n}\mathbb{P}[Y_{n}=y]=\sum_{y_{n}\in \{-1,0,1\}}y_{n}\mathbb{P}[Y_{n}=y]=0 \mathbb{V}Y_{n}=\mathbb{E}Y_{n}^{2}-(\mathbb{E}Y_{n})^{2}=\frac{1}{n} \displaystyle \sum_{n=1}^{\infty}\frac{\mathbb{V}Y_{n}}{n^{2}}<\infty \frac{S_{n}-\mathbb{E}S_{n}}{n}=\frac{S_{n}}{n} \overset{a.s}{\to} 0 \frac{S_{n}}{\sqrt{\log(n)}}\overset{D}{\to} N(0,1) Y_{1},Y_{2},\ldots \displaystyle S_{n}=\sum_{i=1}^{n}Y_{n} i \mu_{i}=\mathbb{E}Y_{i} \sigma^{2}_{i}=\mathbb{V}Y_{i} m_{n}=\sum_{i=1}^{\infty}\mu_{i} s_{n}^{2}=\sum_{i=1}^{n}\sigma_{i}^{2} s_{n}^{2}\to \infty \quad \text{as} \quad n \to \infty M \mathbb{P}[|X_{i}|\leq M]=1, \forall i \frac{S_{n}-m_{n}}{s_{n}}\overset{D}{\to}N(0,1)","['probability-theory', 'statistics']"
19,Maximum of N iid random random variables with Gumbel distribution,Maximum of N iid random random variables with Gumbel distribution,,"I know that the maximum of iid random variables has Gumbel distribution. For example, this is true when iid random variables have Exponential distribution. Does this hold when iid random variables have Gumbel distribution themselves? Let's say there are $N$ iid random variables with distribution $X_n\sim Gumbel(\mu, \beta),~n=1,...,N$ . What is the distribution of $\text{max}_n~X_n$ ? If it is also a Gumbel distribution, say $Gumbel(\mu_{\text{max}}, \beta_{\text{max}})$ , how are parameters $\mu_{\text{max}}$ and $\beta_{\text{max}}$ related to $\mu$ and $\beta$ ? I tried to find an answer in multiple textbooks, but could not find anything.","I know that the maximum of iid random variables has Gumbel distribution. For example, this is true when iid random variables have Exponential distribution. Does this hold when iid random variables have Gumbel distribution themselves? Let's say there are iid random variables with distribution . What is the distribution of ? If it is also a Gumbel distribution, say , how are parameters and related to and ? I tried to find an answer in multiple textbooks, but could not find anything.","N X_n\sim Gumbel(\mu, \beta),~n=1,...,N \text{max}_n~X_n Gumbel(\mu_{\text{max}}, \beta_{\text{max}}) \mu_{\text{max}} \beta_{\text{max}} \mu \beta","['probability', 'statistics', 'probability-distributions', 'random-variables']"
20,asymptotic normality of z-estimator,asymptotic normality of z-estimator,,"I'm working on Problem 5.4.1 in Bickel and Docksum's Mathematical Statistics Let $X_1, \dots, X_n$ be i.i.d. random variables distributed according to $P\in\mathcal{P}$ . Suppose $\psi:\mathbb{R}\to\mathbb{R}$ : (i) is monotone nondecreasing (ii) $\psi(-\infty)<0<\psi(\infty)$ (iii) $|\psi|(x)\le M<\infty$ for all $x$ And suppose for all $P\in\mathcal{P}$ , $\theta(P)$ is the unique solution of $\mathbb{E}_P\psi(X_1-\theta) = 0$ . Let $\hat{\theta}_n = \theta(\hat{P})$ , where $\hat{P}$ is the empirical distribution of $X_1,\dots,X_n$ . Now set $\lambda(\theta) = \mathbb{E}_P\psi(X_1-\theta)$ and $\tau^2(\theta) = \text{var}\psi(X_1-\theta)$ . Assume $\lambda'(\theta)<0$ exists and that $$\frac{1}{\sqrt{n}\tau(\theta)}\sum_{i=1}^n\left[\psi(X_i-\theta_n)-\lambda(\theta_n)\right] \xrightarrow{\mathcal{L}} N(0,1)$$ for every sequence $\{\theta_n\}$ with $\theta_n = \theta = t/\sqrt{n}$ for $t\in\mathbb{R}$ .\ $\textbf{The problem is to show that}$ $$\sqrt{n}(\hat{\theta}_n-\theta) \xrightarrow{\mathcal{L}} N(0,\frac{\tau^2(\theta)}{[\lambda'(\theta)]^2})$$ Hint: $P(\sqrt{n}(\hat{\theta}_n-\theta)<t) = P(\hat{\theta}_n<\theta_n) = P(-\sum_{i=1}^n\psi(X_i-\theta_n)<0)$ . $\textbf{My question}$ is that I don't understand the last equality in the hint, and also how this could lead to the conclusion. Any help will be appreciated! (I manage to prove the consistency of this z-estimator $\hat{\theta}_n$ , but not sure whether this could help this problem or not)","I'm working on Problem 5.4.1 in Bickel and Docksum's Mathematical Statistics Let be i.i.d. random variables distributed according to . Suppose : (i) is monotone nondecreasing (ii) (iii) for all And suppose for all , is the unique solution of . Let , where is the empirical distribution of . Now set and . Assume exists and that for every sequence with for .\ Hint: . is that I don't understand the last equality in the hint, and also how this could lead to the conclusion. Any help will be appreciated! (I manage to prove the consistency of this z-estimator , but not sure whether this could help this problem or not)","X_1, \dots, X_n P\in\mathcal{P} \psi:\mathbb{R}\to\mathbb{R} \psi(-\infty)<0<\psi(\infty) |\psi|(x)\le M<\infty x P\in\mathcal{P} \theta(P) \mathbb{E}_P\psi(X_1-\theta) = 0 \hat{\theta}_n = \theta(\hat{P}) \hat{P} X_1,\dots,X_n \lambda(\theta) = \mathbb{E}_P\psi(X_1-\theta) \tau^2(\theta) = \text{var}\psi(X_1-\theta) \lambda'(\theta)<0 \frac{1}{\sqrt{n}\tau(\theta)}\sum_{i=1}^n\left[\psi(X_i-\theta_n)-\lambda(\theta_n)\right] \xrightarrow{\mathcal{L}} N(0,1) \{\theta_n\} \theta_n = \theta = t/\sqrt{n} t\in\mathbb{R} \textbf{The problem is to show that} \sqrt{n}(\hat{\theta}_n-\theta) \xrightarrow{\mathcal{L}} N(0,\frac{\tau^2(\theta)}{[\lambda'(\theta)]^2}) P(\sqrt{n}(\hat{\theta}_n-\theta)<t) = P(\hat{\theta}_n<\theta_n) = P(-\sum_{i=1}^n\psi(X_i-\theta_n)<0) \textbf{My question} \hat{\theta}_n","['statistics', 'asymptotics', 'central-limit-theorem']"
21,prove MLE don't exist,prove MLE don't exist,,"so the pdf is $$f(x)=\frac{1}{2}\frac{1}{\sqrt{2\pi}}\exp^{-\frac{x^2}{2}}+\frac{1}{2}\frac{1}{\sqrt{2\pi}\sigma}\exp^{-\frac{(x-\mu)^2}{2\sigma^2}} $$ $\mu$ and $\sigma$ are unknown,prove that they don't have MLE it is a gaussian mixture model I guess? And I know there are no analytic solve for the derivative of log likehood function. But the text seems to mean that there are no numerical solve either. And I really don't know any methodology for prove MLE don't exist","so the pdf is and are unknown,prove that they don't have MLE it is a gaussian mixture model I guess? And I know there are no analytic solve for the derivative of log likehood function. But the text seems to mean that there are no numerical solve either. And I really don't know any methodology for prove MLE don't exist","f(x)=\frac{1}{2}\frac{1}{\sqrt{2\pi}}\exp^{-\frac{x^2}{2}}+\frac{1}{2}\frac{1}{\sqrt{2\pi}\sigma}\exp^{-\frac{(x-\mu)^2}{2\sigma^2}}
 \mu \sigma","['statistics', 'maximum-likelihood']"
22,How to simplify out of the gamma function $\Gamma(z)$?,How to simplify out of the gamma function ?,\Gamma(z),"$$\mathrm{d}t(x_i; \nu) = \frac{\Gamma \bigg(\frac{\nu+1}{2}\bigg) }{\Gamma (\frac{\nu}{2}) \sqrt{\pi\nu}} \Bigg( 1+\frac{x_i^2}{\nu} \Bigg)^{-\frac{\nu+1}{2} } \enspace, i=1,2$$ How to derive a closed-form solution of the above by simplifying out of the gamma function? Is the gamma function that is being used above (for $z>0$ ) the same as $$\Gamma(z)=\int_0^\infty x^{z-1}e^{-x}\mathrm{d}x ?$$",How to derive a closed-form solution of the above by simplifying out of the gamma function? Is the gamma function that is being used above (for ) the same as,"\mathrm{d}t(x_i; \nu) = \frac{\Gamma \bigg(\frac{\nu+1}{2}\bigg) }{\Gamma (\frac{\nu}{2}) \sqrt{\pi\nu}} \Bigg( 1+\frac{x_i^2}{\nu} \Bigg)^{-\frac{\nu+1}{2} } \enspace, i=1,2 z>0 \Gamma(z)=\int_0^\infty x^{z-1}e^{-x}\mathrm{d}x ?","['integration', 'statistics', 'probability-distributions', 'gamma-function', 'copula']"
23,Can the expected value of a random variable be viewed as a particular linear transformation?,Can the expected value of a random variable be viewed as a particular linear transformation?,,"I teach a low-level probability and statistics class, and today, part of our discussion was of a couple of well-known properties that the expectation obeys. Namely, for random variables $X$ and $Y$ and a constant $a$ , $E(aX) = aE(X)$ and $E(X + Y) = E(X) + E(Y)$ . A student who is also enrolled in a Linear Algebra course then recognized these properties as the same properties one asks for to get a linear transformation. Thus, I'd like to know if one can view the expected value as a linear transformation from a vector space of random variables to $\mathbb{R}$ . Is this an already-studied notion that's out there ? Perhaps one can link me to a source that might contain a discussion on this, as well. Thank you !","I teach a low-level probability and statistics class, and today, part of our discussion was of a couple of well-known properties that the expectation obeys. Namely, for random variables and and a constant , and . A student who is also enrolled in a Linear Algebra course then recognized these properties as the same properties one asks for to get a linear transformation. Thus, I'd like to know if one can view the expected value as a linear transformation from a vector space of random variables to . Is this an already-studied notion that's out there ? Perhaps one can link me to a source that might contain a discussion on this, as well. Thank you !",X Y a E(aX) = aE(X) E(X + Y) = E(X) + E(Y) \mathbb{R},"['probability-theory', 'statistics', 'linear-transformations', 'expected-value']"
24,Expected size of a sample,Expected size of a sample,,"A warehouse contains seven printing machines, three of which are defective. A company worker has a task to send two of the defective machines for a repair. In order to identify such a pair, he selects a printing machine at random and inspects whether it is a defective or a non-defective one. Then he selects another printing machine at random for the inspection and he repeats the process until he identifies the second defective printing machine. What is the expected number of printing machines he has to inspect? I would really appreciate a hint on how to proceed with this problem. So far I have created a tree diagram, which made me believe the answer is 4. But I think there has to be another way to solve this.","A warehouse contains seven printing machines, three of which are defective. A company worker has a task to send two of the defective machines for a repair. In order to identify such a pair, he selects a printing machine at random and inspects whether it is a defective or a non-defective one. Then he selects another printing machine at random for the inspection and he repeats the process until he identifies the second defective printing machine. What is the expected number of printing machines he has to inspect? I would really appreciate a hint on how to proceed with this problem. So far I have created a tree diagram, which made me believe the answer is 4. But I think there has to be another way to solve this.",,"['probability', 'statistics', 'expected-value']"
25,"Distribution of $ \tan \theta$ when $\theta$ is uniform on $[0,2\pi)$",Distribution of  when  is uniform on," \tan \theta \theta [0,2\pi)","Suppose you have $X$ and $Y$ , which are two random variables whose joint distribution is the standard Gaussian distribution. Let random variables $R \geq 0 $ and $\theta \in [0, 2 \pi)$ satisfy: $X=R\cos\theta$ and $Y=R\sin\theta$ . Let $Z=\frac{Y}{X}$ . Thus, to find the density of $Z$ , I did: $Z= \tan \theta$ . And so, $$F_Z(z)=P(Z\leq z) = P(\tan \theta \leq z) = P( \theta \leq \arctan z)$$ Since $ \theta\sim \text{Uniform} [0, 2\pi)$ due to the fact that $X$ and $Y$ are standard Gaussian and deducing the distribution of $\theta$ from the joint distribution of $ R$ and $ \theta $ , we get that this is equal to: $ \int_{0}^{\arctan z} \frac{1}{2𝜋} dt$ , which then works out to be equal to $\frac{\arctan(z)}{2𝜋} $ . After differentiating this to obtain the density function of $Z$ , I get: $$ f_Z(z)= \frac{1}{2\pi(1+{z^2})}$$ I am not sure about what the limits of $Z$ or $\theta$ should now be. Any feedback will be appreciated.","Suppose you have and , which are two random variables whose joint distribution is the standard Gaussian distribution. Let random variables and satisfy: and . Let . Thus, to find the density of , I did: . And so, Since due to the fact that and are standard Gaussian and deducing the distribution of from the joint distribution of and , we get that this is equal to: , which then works out to be equal to . After differentiating this to obtain the density function of , I get: I am not sure about what the limits of or should now be. Any feedback will be appreciated.","X Y R \geq 0  \theta \in [0, 2 \pi) X=R\cos\theta Y=R\sin\theta Z=\frac{Y}{X} Z Z= \tan \theta F_Z(z)=P(Z\leq z) = P(\tan \theta \leq z) = P( \theta \leq \arctan z)  \theta\sim \text{Uniform} [0, 2\pi) X Y \theta  R  \theta   \int_{0}^{\arctan z} \frac{1}{2𝜋} dt \frac{\arctan(z)}{2𝜋}  Z  f_Z(z)= \frac{1}{2\pi(1+{z^2})} Z \theta","['probability', 'statistics']"
26,Variants of Bernoulli factory problems,Variants of Bernoulli factory problems,,"I am interested in the following two questions related to the famous Bernoulli factory problems. Bernoulli factory for certain functions: suppose we are given a coin with arbitrary (unknown) head probability $p$ , I am wondering if there is an easy-to-implement algorithm for generating a $\min\{p, 0.5\}$ coin for any $p\in [0,1]$ . Function $f(p) = \min\{p, 0.5\} \geq \min\{p, 1-p\}$ so the famous paper by Keane and O’Brien guarantees such an algorithm exists. Meanwhile, the function looks slightly simpler than the function discussed in Nacu and Peres , so I am wondering if there is any existing simple algorithm for simulating this. Similarly, can we simulate $f(p) = \min\{p,a\}$ for fixed $a\in (0,1)$ efficiently? High dimensional Bernoulli factory: How to simulate a coin with head probability $f(p_1, p_2)$ (for example $f(p_1, p_2) = \min\{p_1, p_2, 0.5\}$ ), or more generally, simulating a coin with head probability $f(p_1, \cdots, p_n)$ . The setting here is that we are able so simulate a $p_i$ coin, but without further knowledge on the value of $p_i$ , which is consistent with the traditional Bernoulli factory's setting.  When $f$ is a single variable function then the problem is reduced to the Bernoulli factory problem. Any reference/idea will be much appreciated for the multivariate case, thanks!","I am interested in the following two questions related to the famous Bernoulli factory problems. Bernoulli factory for certain functions: suppose we are given a coin with arbitrary (unknown) head probability , I am wondering if there is an easy-to-implement algorithm for generating a coin for any . Function so the famous paper by Keane and O’Brien guarantees such an algorithm exists. Meanwhile, the function looks slightly simpler than the function discussed in Nacu and Peres , so I am wondering if there is any existing simple algorithm for simulating this. Similarly, can we simulate for fixed efficiently? High dimensional Bernoulli factory: How to simulate a coin with head probability (for example ), or more generally, simulating a coin with head probability . The setting here is that we are able so simulate a coin, but without further knowledge on the value of , which is consistent with the traditional Bernoulli factory's setting.  When is a single variable function then the problem is reduced to the Bernoulli factory problem. Any reference/idea will be much appreciated for the multivariate case, thanks!","p \min\{p, 0.5\} p\in [0,1] f(p) = \min\{p, 0.5\} \geq \min\{p, 1-p\} f(p) = \min\{p,a\} a\in (0,1) f(p_1, p_2) f(p_1, p_2) = \min\{p_1, p_2, 0.5\} f(p_1, \cdots, p_n) p_i p_i f","['probability', 'statistics', 'sampling', 'sampling-theory']"
27,Finding 4 Different Sufficient Statistics,Finding 4 Different Sufficient Statistics,,"If $X_1, ..., X_n$ is a random sample taken from a geometric population of the form $$ P(X = x;p) = p(1-p)^x, $$ for $x = 0, 1, 2, ...,$ and $0 < p < 1$ , find four different sufficient statistics for $p$ . Attempt : I have found the joint pmf of the random sample to be $$ P(\mathbf{X} = \mathbf{x}; p) = p^n(1-p)^{\sum x_i}, ~~ x_i = 0, 1, 2, ..., ~~\text{and}~~ 0 < p < 1.  $$ The only sufficient statistic I can think of is $T(\mathbf{X}) = \sum X_i$ , the sample total. Writing the joint pmf in exponential form, I have found $$ P(\mathbf{X} = \mathbf{x}; p) = \operatorname{exp}\Bigl[n\text{ln}(p) + \sum x_i \text{ln}(1-p)\Bigr] $$ I don't see how it helps, though.","If is a random sample taken from a geometric population of the form for and , find four different sufficient statistics for . Attempt : I have found the joint pmf of the random sample to be The only sufficient statistic I can think of is , the sample total. Writing the joint pmf in exponential form, I have found I don't see how it helps, though.","X_1, ..., X_n 
P(X = x;p) = p(1-p)^x,
 x = 0, 1, 2, ..., 0 < p < 1 p 
P(\mathbf{X} = \mathbf{x}; p) = p^n(1-p)^{\sum x_i}, ~~ x_i = 0, 1, 2, ..., ~~\text{and}~~ 0 < p < 1. 
 T(\mathbf{X}) = \sum X_i 
P(\mathbf{X} = \mathbf{x}; p) = \operatorname{exp}\Bigl[n\text{ln}(p) + \sum x_i \text{ln}(1-p)\Bigr]
","['statistics', 'statistical-inference']"
28,How to determine a sufficient statistic for a Poisson sample and show that it has a monotone likelihood ratio.,How to determine a sufficient statistic for a Poisson sample and show that it has a monotone likelihood ratio.,,"The following question is a last year's Statistics exam question I tried to solve (without any luck). Any help would be grateful. Thanks in advance. An Atomic Energy Agency is worried that a particular nuclear plant has leaked radio-active material. They do $5$ independent Geiger counter measurements in the direct neighbourhood of the reactor. They find the following measurements (per unit time): observation i: 1 2 3 4 5 count $x_i$ : 1 2 6 2 7 (I did not know how to implement this into a tabular) The natural background radiation has an average of $λ = 2$ (per unit time). The agency would only be worried if the radiation rate would be in the order of $λ = 5$ . They therefore decide to test: $H_0 : λ ≤ 2$ versus : $H_1 : λ > 2$ They want to device the optimal test to see if there there is any reason for alarm. Assuming that the data are realizations of a sample from a Poisson distribution: $X_1, ..., X_5 ∼ POI(λ)$ with density: $f(x) = e^{-λ}\frac{λ^{x}}{x!}$ I have two questions I need some help with: Determine a sufficient statistic for the Possion sample and show that it has a monotone likelihood ratio. Derive the uniform most powerful test of level $α = 0.0487$ for the test problem. Because we have a Poisson distribution, I know that we can use: $\sum_{i = 1}^{5}X_i \sim Poi(5λ)$ For the first question, my attempt: $p(x_1,...,x_5|λ) = \prod_{i = 1}^{5} e^{-5λ}\frac{λ^{x_1 + x_2 + x_3 + x_4 + x_5}}{x_1!x_2!x_3!x_4!x_5!} = h(x_1 +...+ x_5|λ) * g(x_1,x_2,x_3,x_4,x_5) $ $h(x_1 +...+ x_5|λ) = e^{-5λ}λ^{x_1 + x_2 + x_3 + x_4 + x_5} $ $g(x_1,x_2,x_3,x_4,x_5) = \frac{1}{x_1!x_2!x_3!x_4!x_5!}$ It follows by the factorization theorem that $T(X_1, X_2, X_3,X_4,X_5) = X_1+X_2+X_3+X_4+X_5$ is sufficient statistic. Not sure how to construct a proof to show it has a monotone likelihood ratio.","The following question is a last year's Statistics exam question I tried to solve (without any luck). Any help would be grateful. Thanks in advance. An Atomic Energy Agency is worried that a particular nuclear plant has leaked radio-active material. They do independent Geiger counter measurements in the direct neighbourhood of the reactor. They find the following measurements (per unit time): observation i: 1 2 3 4 5 count : 1 2 6 2 7 (I did not know how to implement this into a tabular) The natural background radiation has an average of (per unit time). The agency would only be worried if the radiation rate would be in the order of . They therefore decide to test: versus : They want to device the optimal test to see if there there is any reason for alarm. Assuming that the data are realizations of a sample from a Poisson distribution: with density: I have two questions I need some help with: Determine a sufficient statistic for the Possion sample and show that it has a monotone likelihood ratio. Derive the uniform most powerful test of level for the test problem. Because we have a Poisson distribution, I know that we can use: For the first question, my attempt: It follows by the factorization theorem that is sufficient statistic. Not sure how to construct a proof to show it has a monotone likelihood ratio.","5 x_i λ = 2 λ = 5 H_0 : λ ≤ 2 H_1 : λ > 2 X_1, ..., X_5 ∼ POI(λ) f(x) = e^{-λ}\frac{λ^{x}}{x!} α = 0.0487 \sum_{i = 1}^{5}X_i \sim Poi(5λ) p(x_1,...,x_5|λ) = \prod_{i = 1}^{5} e^{-5λ}\frac{λ^{x_1 + x_2 + x_3 + x_4 + x_5}}{x_1!x_2!x_3!x_4!x_5!} = h(x_1 +...+ x_5|λ) * g(x_1,x_2,x_3,x_4,x_5)  h(x_1 +...+ x_5|λ) = e^{-5λ}λ^{x_1 + x_2 + x_3 + x_4 + x_5}  g(x_1,x_2,x_3,x_4,x_5) = \frac{1}{x_1!x_2!x_3!x_4!x_5!} T(X_1, X_2, X_3,X_4,X_5) = X_1+X_2+X_3+X_4+X_5","['statistics', 'probability-distributions', 'hypothesis-testing']"
29,Applying CLT to random variable made up of two sequences of iid random variables,Applying CLT to random variable made up of two sequences of iid random variables,,"2nd year stats hw Q: Suppose you have a sequence $X_1, X_2, ...$ of iid random variables with mean $E(X_1)=\mu_X$ and variance $Var(X_1)=\sigma^2_X$ and another sequence $Y_1, Y_2, ...$ of iid random variables with mean $E(Y_1)=\mu_Y$ and variance $Var(Y_1)=\sigma^2_Y$ . For each $n=1,2,...$ let $A_n$ be the random variable $$\frac{\sqrt n}{\sqrt {\sigma^2_X+\sigma^2_Y}}[\bar X_n - \bar Y_n - (\mu_X - \mu_Y)]$$ where $\bar X_n = \sum_{i=1}^n \frac{X_i}{n}$ and $\bar Y_n = \sum_{i=1}^n \frac{Y_i}{n}$ . Show that, in distribution, $A_n$ converges to $N(0,1)$ as $n \to \infty$ . I know that this will require use of the central limit theorem and when I asked my lecturer for help he just reminded me that the $X$ variables are independent to the $Y$ variables, but I don't know how to apply this. Please help - even if its just pointing me in the right direction!","2nd year stats hw Q: Suppose you have a sequence of iid random variables with mean and variance and another sequence of iid random variables with mean and variance . For each let be the random variable where and . Show that, in distribution, converges to as . I know that this will require use of the central limit theorem and when I asked my lecturer for help he just reminded me that the variables are independent to the variables, but I don't know how to apply this. Please help - even if its just pointing me in the right direction!","X_1, X_2, ... E(X_1)=\mu_X Var(X_1)=\sigma^2_X Y_1, Y_2, ... E(Y_1)=\mu_Y Var(Y_1)=\sigma^2_Y n=1,2,... A_n \frac{\sqrt n}{\sqrt {\sigma^2_X+\sigma^2_Y}}[\bar X_n - \bar Y_n - (\mu_X - \mu_Y)] \bar X_n = \sum_{i=1}^n \frac{X_i}{n} \bar Y_n = \sum_{i=1}^n \frac{Y_i}{n} A_n N(0,1) n \to \infty X Y","['probability-theory', 'statistics', 'weak-convergence', 'central-limit-theorem']"
30,Explanation for Weight multiplied in Posterior Probability Sum,Explanation for Weight multiplied in Posterior Probability Sum,,"Let, $P(\theta|x)$ is the posterior probability. It describes $\textbf{how certain or confident we are that hypothesis $\theta$ is true, given that}$ we have observed data $x$ . Calculating posterior probabilities is the main goal of Bayesian statistics! $P(\theta)$ is the prior probability, which describes $\textbf{how sure we were that}$ $\theta$ was true, before we observed the data $x$ . $P(x|\theta)$ is the likelihood. $\textbf{If you were to assume that $\theta$ is true, this is the probability}$ that you would have observed data $x$ . $P(x)$ is the marginal likelihood. This is the probability that you would have observed data $x$ , whether $\theta$ is true or not. So, $P (\theta|x) = \frac{P (\theta) P(x|\theta)}{P (x)}$ The following part is an excerpt from the same text - In the Bayesian framework, our predictions are always in the form of probabilities or (later) probability distributions. They are usually calculated in three stages. First, you pretend you actually know the true value of the parameters, and calculate the probability based on that assumption. Then, you do this for all possible values of the parameter $\theta$ (alternatively, you can calculate the probability as a function of $\theta$ ). Finally, you combine all of these probabilities in a particular way to get one final probability which tells you how confident you are of your prediction. Suppose we knew the true value of $\theta$ was $0.3$ . Then, we would know the probability of catching the right bus tomorrow is $0.3$ . If we knew the true value of $\theta$ was $0.4$ , we would say the probability of catching the right bus tomorrow is 0.4. The problem is, we don’t know what the true value is. We only have the posterior distribution. Luckily, the sum rule of probability (combined with the product rule) can help us out. We are interested in whether I will get the good bus tomorrow. There are $11$ different ways that can happen. Either $\theta=0$ and I get the good bus, or $\theta=0.1$ and I get the good bus, or $\theta=0.2$ and I get the good bus, and so on. These 11 ways are all mutually exclusive. That is, only one of them can be true (since $\theta$ is actually just a single number). Mathematically, we can obtain the posterior probability of catching the good bus tomorrow using the sum rule: $$P(\text{good bus tomorrow}|x) = \sum_{\theta} p(\theta|x) \times P(\text{good bus tomorrow}|\theta, x) $$ $$=  \sum_{\theta} p(\theta|x) \times \theta$$ This says that the total probability for a good bus tomorrow (given the data, i.e. using the posterior distribution and not the prior distribution) is given by going through each possible $\theta$ value, working out the probability assuming the $\theta$ value you are considering is true, multiplying by the probability (given the data) this $\theta$ value is actually true, and summing. In this particular problem, because $P\text{(good bus  tomorrow}|\theta, x) = θ$ , it just so happens that the probability for tomorrow is the expectation value of $\theta$ using the posterior distribution. To three decimal places, the result for the probability tomorrow is $0.429$ . Interestingly, this is not equal to $2/5 = 0.4$ . The problem on page $26, 7$ of the text of Introduction to Bayesian Statistics by Brendon J. Brewer is written as following  - QUESTION Now to calculate posterior probability (of catching the good bus tomorrow) $P(\text{good bus tomorrow}|x)$ why do the author multiplied $p(\theta|x)$ by $P(\text{good bus tomorrow}|\theta, x) $ in the $\sum_{\theta}$ ? To me, $P(\text{good bus tomorrow}|x) = \sum_{\theta} p(\theta|x) $ is correct, so what am I missing? In this comment I have been told, $p(\theta|x)$ itself is a weight, which confused me more, so please explain, thanks.","Let, is the posterior probability. It describes we have observed data . Calculating posterior probabilities is the main goal of Bayesian statistics! is the prior probability, which describes was true, before we observed the data . is the likelihood. that you would have observed data . is the marginal likelihood. This is the probability that you would have observed data , whether is true or not. So, The following part is an excerpt from the same text - In the Bayesian framework, our predictions are always in the form of probabilities or (later) probability distributions. They are usually calculated in three stages. First, you pretend you actually know the true value of the parameters, and calculate the probability based on that assumption. Then, you do this for all possible values of the parameter (alternatively, you can calculate the probability as a function of ). Finally, you combine all of these probabilities in a particular way to get one final probability which tells you how confident you are of your prediction. Suppose we knew the true value of was . Then, we would know the probability of catching the right bus tomorrow is . If we knew the true value of was , we would say the probability of catching the right bus tomorrow is 0.4. The problem is, we don’t know what the true value is. We only have the posterior distribution. Luckily, the sum rule of probability (combined with the product rule) can help us out. We are interested in whether I will get the good bus tomorrow. There are different ways that can happen. Either and I get the good bus, or and I get the good bus, or and I get the good bus, and so on. These 11 ways are all mutually exclusive. That is, only one of them can be true (since is actually just a single number). Mathematically, we can obtain the posterior probability of catching the good bus tomorrow using the sum rule: This says that the total probability for a good bus tomorrow (given the data, i.e. using the posterior distribution and not the prior distribution) is given by going through each possible value, working out the probability assuming the value you are considering is true, multiplying by the probability (given the data) this value is actually true, and summing. In this particular problem, because , it just so happens that the probability for tomorrow is the expectation value of using the posterior distribution. To three decimal places, the result for the probability tomorrow is . Interestingly, this is not equal to . The problem on page of the text of Introduction to Bayesian Statistics by Brendon J. Brewer is written as following  - QUESTION Now to calculate posterior probability (of catching the good bus tomorrow) why do the author multiplied by in the ? To me, is correct, so what am I missing? In this comment I have been told, itself is a weight, which confused me more, so please explain, thanks.","P(\theta|x) \textbf{how certain or confident we
are that hypothesis \theta is true, given that} x P(\theta) \textbf{how sure we were that} \theta x P(x|\theta) \textbf{If you were to assume that \theta is true, this is the
probability} x P(x) x \theta P (\theta|x) = \frac{P (\theta) P(x|\theta)}{P (x)} \theta \theta \theta 0.3 0.3 \theta 0.4 11 \theta=0 \theta=0.1 \theta=0.2 \theta P(\text{good bus tomorrow}|x) = \sum_{\theta} p(\theta|x) \times P(\text{good bus tomorrow}|\theta, x)  =  \sum_{\theta} p(\theta|x) \times \theta \theta \theta \theta P\text{(good bus  tomorrow}|\theta, x) = θ \theta 0.429 2/5 = 0.4 26, 7 P(\text{good bus tomorrow}|x) p(\theta|x) P(\text{good bus tomorrow}|\theta, x)  \sum_{\theta} P(\text{good bus tomorrow}|x) = \sum_{\theta} p(\theta|x)  p(\theta|x)","['statistics', 'bayesian', 'bayes-theorem']"
31,What is the probability that $P(Y>X)$ when $Y$ and $X$ are independent?,What is the probability that  when  and  are independent?,P(Y>X) Y X,"Let $Y\sim N(8.30;0.02^2)$ and $X\sim N(6.60;0.01^2)$ . What is the probability that $P(Y>X)$ when $Y$ and $X$ are independent? My solution so far: Since $Y$ and $X$ are independent, $$Y+X\sim N(\mu_Y+\mu_X,\sigma^2_Y+\sigma^2_X).$$ Now $$Y-X\sim N(1.7;0.02236^2).$$ The probability can be written $$P(Y>X)=P(Y-X>0)=1-P(Y-X\le0)$$ and since the probability has to be greater or equal to zero, $$1-P(Y-X=0).$$ I don't know if I have done correctly so far and I don't know how to go on from here.","Let and . What is the probability that when and are independent? My solution so far: Since and are independent, Now The probability can be written and since the probability has to be greater or equal to zero, I don't know if I have done correctly so far and I don't know how to go on from here.","Y\sim N(8.30;0.02^2) X\sim N(6.60;0.01^2) P(Y>X) Y X Y X Y+X\sim N(\mu_Y+\mu_X,\sigma^2_Y+\sigma^2_X). Y-X\sim N(1.7;0.02236^2). P(Y>X)=P(Y-X>0)=1-P(Y-X\le0) 1-P(Y-X=0).","['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
32,Word Problem about Statistics,Word Problem about Statistics,,The median of 5 numbers is 15. The mode is 12. The mean is 15. What are the 5 numbers? I've done some algebra and now I know that the last 2 digit numbers must add up to 36. How can I determine those two digits without having to use trial and error which would consume a lot of time?,The median of 5 numbers is 15. The mode is 12. The mean is 15. What are the 5 numbers? I've done some algebra and now I know that the last 2 digit numbers must add up to 36. How can I determine those two digits without having to use trial and error which would consume a lot of time?,,"['statistics', 'word-problem']"
33,Finding probability of Sample standard deviation given population is normally distributed,Finding probability of Sample standard deviation given population is normally distributed,,"For a random sample of size $n,$ if the values are taken from the $N(a, b)$ population, what is the probability that $S$ (where $S^2$ is sample variance) will exceed a particular value? I had 2 approaches in mind here. Please let me know which one is correct Since $(n-1) S^2/\sigma^2$ is chi square distributed, can I say the square root of term on LHS is normally distributed? Use $x-\mu/(S/\sqrt{n})$ which is t distributed to find the answer","For a random sample of size if the values are taken from the population, what is the probability that (where is sample variance) will exceed a particular value? I had 2 approaches in mind here. Please let me know which one is correct Since is chi square distributed, can I say the square root of term on LHS is normally distributed? Use which is t distributed to find the answer","n, N(a, b) S S^2 (n-1) S^2/\sigma^2 x-\mu/(S/\sqrt{n})","['probability', 'statistics']"
34,Can $\sqrt{n}$ be dropped from the asymptotic normality of an MLE?,Can  be dropped from the asymptotic normality of an MLE?,\sqrt{n},"Referencing the site below: http://gregorygundersen.com/blog/2019/11/28/asymptotic-normality-mle/ We have the asymptotic normality property of maximum likelihood estimators: Theorem: Assuming sufficient regularity, we have: $$\sqrt{n}(\hat{\theta} - \theta_0) \xrightarrow{\mathcal{D}} \mathcal{N}(0,\mathcal{I}(\theta_0)^{-1})$$ On the next line, the site claims that this property implies: Corollary: $$\hat{\theta} \xrightarrow{\mathcal{D}} \mathcal{N}(\theta_0,\mathcal{I}(\theta_0)^{-1})$$ I have two questions: Why is the $\sqrt{n}$ factor allowed to be dropped? What is the formal reason for this? I just want to make sure, is it correct that the corollary is equivalent to $(\hat{\theta}-\theta_0) \xrightarrow{\mathcal{D}} \mathcal{N}(0,\mathcal{I}(\theta_0)^{-1})$ ?","Referencing the site below: http://gregorygundersen.com/blog/2019/11/28/asymptotic-normality-mle/ We have the asymptotic normality property of maximum likelihood estimators: Theorem: Assuming sufficient regularity, we have: On the next line, the site claims that this property implies: Corollary: I have two questions: Why is the factor allowed to be dropped? What is the formal reason for this? I just want to make sure, is it correct that the corollary is equivalent to ?","\sqrt{n}(\hat{\theta} - \theta_0) \xrightarrow{\mathcal{D}} \mathcal{N}(0,\mathcal{I}(\theta_0)^{-1}) \hat{\theta} \xrightarrow{\mathcal{D}} \mathcal{N}(\theta_0,\mathcal{I}(\theta_0)^{-1}) \sqrt{n} (\hat{\theta}-\theta_0) \xrightarrow{\mathcal{D}} \mathcal{N}(0,\mathcal{I}(\theta_0)^{-1})","['probability', 'probability-theory', 'statistics', 'maximum-likelihood', 'probability-limit-theorems']"
35,Statistical Inversion Problem $F = Ku + \mathcal{E}$ derive conditional probability density $p(f | u)$,Statistical Inversion Problem  derive conditional probability density,F = Ku + \mathcal{E} p(f | u),"Consider the following Inversion Problem $f = Ku + \varepsilon$ where $f \in \mathbb{R}^{m}$ , $u \in \mathbb{R}^{n}$ , $K \in \mathbb{R}^{m,n}$ and $\varepsilon$ is an additive, Gaussian noise. In the Bayesian approach towards Inverse Problems, where you don't rely on explicit regularizers, you consider this problem as $F = Ku + \mathcal{E}$ where $F$ and $\mathcal{E}$ are random variables, $\mathcal{E} \sim \mathcal{N}(0, \Sigma_{\varepsilon})$ . Apparently one can then determine the conditional probability density of $F$ given $u$ as $$ p(f | u) \propto \operatorname{exp}(-\frac{1}{2}\|f - Ku\|^2_{{\Sigma_{\varepsilon}}^{-1}}) $$ where $\|y\|^2_{A} := y^{T}Ay$ . How is this derived?","Consider the following Inversion Problem where , , and is an additive, Gaussian noise. In the Bayesian approach towards Inverse Problems, where you don't rely on explicit regularizers, you consider this problem as where and are random variables, . Apparently one can then determine the conditional probability density of given as where . How is this derived?","f = Ku + \varepsilon f \in \mathbb{R}^{m} u \in \mathbb{R}^{n} K \in \mathbb{R}^{m,n} \varepsilon F = Ku + \mathcal{E} F \mathcal{E} \mathcal{E} \sim \mathcal{N}(0, \Sigma_{\varepsilon}) F u 
p(f | u) \propto \operatorname{exp}(-\frac{1}{2}\|f - Ku\|^2_{{\Sigma_{\varepsilon}}^{-1}})
 \|y\|^2_{A} := y^{T}Ay","['statistics', 'conditional-probability', 'bayesian', 'inverse-problems']"
36,Difference between stationary and homogeneous point process,Difference between stationary and homogeneous point process,,"I do not understand the difference between a stationary and a homogeneous point process. The definitions I found are as follows: A process is stationary if the entire configuration of the process is invariant under translation. A process is homogeneous if the mean number of points in each set A is given by $\alpha \cdot \parallel A \parallel$ , where $\alpha \geq 0$ is a constant. These definitions appear the same to me. Could anyone give me an example of a process that is stationary but not homogeneous or the other way around? Thank you!!","I do not understand the difference between a stationary and a homogeneous point process. The definitions I found are as follows: A process is stationary if the entire configuration of the process is invariant under translation. A process is homogeneous if the mean number of points in each set A is given by , where is a constant. These definitions appear the same to me. Could anyone give me an example of a process that is stationary but not homogeneous or the other way around? Thank you!!",\alpha \cdot \parallel A \parallel \alpha \geq 0,"['statistics', 'stationary-processes', 'point-processes']"
37,What parameter is the Wilcoxon 2-sample statistic estimating?,What parameter is the Wilcoxon 2-sample statistic estimating?,,"I'm reading about the Wilcoxon 2-sample statistic. They say that this is an estimator for the following parameter: $$\theta(F,G) = \int F \, dG = P(X \leq Y)$$ where $F$ and $G$ are continuous distribution functions for the random variables $X$ and $Y$ . How does $\theta$ give us $P(X \leq Y)$ ? Asked another way: why does $\int F \, dG $ imply $P(X \leq Y)$ ? [For context this is the first example of 5.1.3 in Serfling (1980)]",I'm reading about the Wilcoxon 2-sample statistic. They say that this is an estimator for the following parameter: where and are continuous distribution functions for the random variables and . How does give us ? Asked another way: why does imply ? [For context this is the first example of 5.1.3 in Serfling (1980)],"\theta(F,G) = \int F \, dG = P(X \leq Y) F G X Y \theta P(X \leq Y) \int F \, dG  P(X \leq Y)","['probability', 'probability-theory', 'statistics']"
38,Use CLT to find approximation,Use CLT to find approximation,,"We are given $X_1,\dots,X_n$ i.i.d. Poisson( $\lambda$ ) r.v.s. and assume $\lambda = 1$ . We need to use CLT to find an approximation for: $$P(X_1+X_2+\dots+X_{100} \leq 90)$$ What I have done: Let $Y = X_1+X_2 +\dots+ X_{100} $ Therefore $Y\sim$ Poisson(100) (assuming $\lambda=1$ ) Also, if $\lambda$ is sufficiently large, $Y \sim N(100, 100)$ Therefore: $ P(X_1+X_2+\dots+X_{100} \leq 90) = P\left(Z \leq \frac{90-100}{10}\right) = P(Z \leq -1) = P(Z \geq 1) = \Phi(1)$ I need to know if this is okay?","We are given i.i.d. Poisson( ) r.v.s. and assume . We need to use CLT to find an approximation for: What I have done: Let Therefore Poisson(100) (assuming ) Also, if is sufficiently large, Therefore: I need to know if this is okay?","X_1,\dots,X_n \lambda \lambda = 1 P(X_1+X_2+\dots+X_{100} \leq 90) Y = X_1+X_2 +\dots+ X_{100}  Y\sim \lambda=1 \lambda Y \sim N(100, 100)  P(X_1+X_2+\dots+X_{100} \leq 90) = P\left(Z \leq \frac{90-100}{10}\right) = P(Z \leq -1) = P(Z \geq 1) = \Phi(1)","['probability', 'statistics', 'central-limit-theorem']"
39,"LR Test in Beta($\theta$, 1) with $H_0 = {\theta_0}$","LR Test in Beta(, 1) with",\theta H_0 = {\theta_0},"I'm trying to obtain $\alpha$ -level LR Test where $(X_1, ... X_n)$ are from Beta( $\theta$ , 1) with $H_0 = {\theta_0}$ and $H_0 \neq \theta_0$ . I'm looking for $$ \lambda(X) = \frac{\sup_{\theta \in \Theta_0}l(\theta)}{\sup_{\theta \in \Theta}l(\theta)} $$ Suppose $T := \sum^n_{i=1}\ln{X_i}$ and we know that MLE of Beta $(\theta, 1)$ equals $$ \hat{\theta}=\frac{-n}{T} $$ Our $\lambda(X)$ is then: $$ \lambda(X) = \frac{\theta_{0}^{n} (X_1 \cdot ... \cdot X_n)^{\theta_0 - 1}}{(\frac{-n}{T})^n(X_1 \cdot ... \cdot X_n)^{\frac{-n}{T} - 1}} = \left(\frac{- \theta_0 T}{n}\right)^n(X_1 \cdot ... \cdot X_n)^{\theta_0 + \frac{n}{T}} $$ We want to find $\lambda(X) < c$ but we may as well look for $\ln\lambda(X) < \ln c = \hat c $ . Taking the logarithm: $$ \ln\lambda(X) = n \ln{\frac{- \theta_0 T}{n}}+\left({\theta_0 + \frac{n}{T}}\right)T =n \ln{\frac{- \theta_0 T}{n}} + \theta_0T + n $$ This has to be lesser than some $\hat c$ $$ n \ln{\frac{- \theta_0 T}{n}} + \theta_0T + n < \hat c $$ We define $f(x) = n \ln{\frac{- \theta_0 x}{n}} + \theta_0x + n$ and see how it behaves: $$ f'(x) = \frac{n}{\frac{\theta_0x}{n}} + \theta_0 \\ f'(x) = \frac{n^2}{\theta_0x} + \theta_0 $$ $f'(x) > 0$ iff: $$ \frac{n^2}{\theta_0x} + \theta_0 > 0 \\ \frac{n^2}{\theta_0x} > - \theta_0 \\ \theta_0x < -\frac{n^2}{\theta_0} \\ x < -\left(\frac{n}{\theta_0}\right)^2 $$ This makes x negative, but it does not raise my concern because $x=\sum \ln X_i$ where $X_i \in (0,1)$ so $\ln X_i < 0$ it can be indeed negative. I'd then get the LR test looking like: $$ \varphi(X) = \begin{cases} 1 & T < d_1 \text{ or } T > d_2  \\ \gamma_1 & T = d_1 \\ \gamma_2 & T = d_2 \\ 0 & T \in (d_1, d_2) \end{cases} $$ where $d_1 < -\frac{n^2}{\theta_0^2} < d_2$ for $d_1, d_2$ calculated to meet $\alpha$ . Is my solution correct so far? I have noticed the question has been answered here , but I could not fully get the grasp of it and wanted to go step by step.","I'm trying to obtain -level LR Test where are from Beta( , 1) with and . I'm looking for Suppose and we know that MLE of Beta equals Our is then: We want to find but we may as well look for . Taking the logarithm: This has to be lesser than some We define and see how it behaves: iff: This makes x negative, but it does not raise my concern because where so it can be indeed negative. I'd then get the LR test looking like: where for calculated to meet . Is my solution correct so far? I have noticed the question has been answered here , but I could not fully get the grasp of it and wanted to go step by step.","\alpha (X_1, ... X_n) \theta H_0 = {\theta_0} H_0 \neq \theta_0 
\lambda(X) = \frac{\sup_{\theta \in \Theta_0}l(\theta)}{\sup_{\theta \in \Theta}l(\theta)}
 T := \sum^n_{i=1}\ln{X_i} (\theta, 1) 
\hat{\theta}=\frac{-n}{T}
 \lambda(X) 
\lambda(X) = \frac{\theta_{0}^{n} (X_1 \cdot ... \cdot X_n)^{\theta_0 - 1}}{(\frac{-n}{T})^n(X_1 \cdot ... \cdot X_n)^{\frac{-n}{T} - 1}} = \left(\frac{- \theta_0 T}{n}\right)^n(X_1 \cdot ... \cdot X_n)^{\theta_0 + \frac{n}{T}}
 \lambda(X) < c \ln\lambda(X) < \ln c = \hat c  
\ln\lambda(X) = n \ln{\frac{- \theta_0 T}{n}}+\left({\theta_0 + \frac{n}{T}}\right)T =n \ln{\frac{- \theta_0 T}{n}} + \theta_0T + n
 \hat c 
n \ln{\frac{- \theta_0 T}{n}} + \theta_0T + n < \hat c  f(x) = n \ln{\frac{- \theta_0 x}{n}} + \theta_0x + n 
f'(x) = \frac{n}{\frac{\theta_0x}{n}} + \theta_0 \\
f'(x) = \frac{n^2}{\theta_0x} + \theta_0
 f'(x) > 0 
\frac{n^2}{\theta_0x} + \theta_0 > 0 \\
\frac{n^2}{\theta_0x} > - \theta_0 \\
\theta_0x < -\frac{n^2}{\theta_0} \\
x < -\left(\frac{n}{\theta_0}\right)^2
 x=\sum \ln X_i X_i \in (0,1) \ln X_i < 0 
\varphi(X) = \begin{cases}
1 & T < d_1 \text{ or } T > d_2  \\
\gamma_1 & T = d_1 \\
\gamma_2 & T = d_2 \\
0 & T \in (d_1, d_2)
\end{cases}
 d_1 < -\frac{n^2}{\theta_0^2} < d_2 d_1, d_2 \alpha","['probability', 'statistics', 'hypothesis-testing', 'maximum-likelihood', 'log-likelihood']"
40,Poisson distribution - find value for λ given a known probability,Poisson distribution - find value for λ given a known probability,,"I am trying to solve the following: The number of particles decaying per second in a radioactive material with a high half-life (e.g. of several millennia) is (in very good approximation) Poisson-distributed. a) On average, 20.00 particles per second decay from a radioactive sample. What is the probability that 20 particles decay in one second? b) An average of 20.00 particles per second decay from a radioactive sample. What is the probability that at least 10 particles decay in one second? c) From a radioactive sample, it is known that with a probability of 1%, at most 3 particles per second decay. How many particles in this period decay on average in one second? Give your result to three decimal places. My Solution: a) $$p(x=20)=\frac{20^{20}}{20!}e^{-20} = 0.089$$ b) $$p(x \geq 10)= 1- p(x \leq 9) \\            = 1- (\sum\limits_{x=0}^{9} \frac{20^{x}}{x!}e^{-20}) \\            = 1- 0.005   \\            = 0.995 $$ c) $$p(x \leq 3)=  \sum\limits_{x=0}^{3} \frac{\lambda ^{x}}{x!}e^{-\lambda} =0.01 \\           0.01 = (\frac{\lambda^0}{0!} +\frac{\lambda^1}{1!}+ \frac{\lambda^2}{2!} +\frac{\lambda^3}{3!}) e^{-\lambda}   \\            = (1 +\lambda+ \frac{\lambda^2}{2} +\frac{\lambda^3}{6}) e^{-\lambda}   \\ = \frac{(\lambda^3 +3\lambda^2 + 6\lambda+ 6)} {6e^{\lambda}}   \\ $$ Using an online calculator, I found out that $\lambda \approx 10.0451$ , but I'm not entirely sure whether that's the right answer. My question is: If my calculations are correct so far: How to calculate $\lambda$ ?","I am trying to solve the following: The number of particles decaying per second in a radioactive material with a high half-life (e.g. of several millennia) is (in very good approximation) Poisson-distributed. a) On average, 20.00 particles per second decay from a radioactive sample. What is the probability that 20 particles decay in one second? b) An average of 20.00 particles per second decay from a radioactive sample. What is the probability that at least 10 particles decay in one second? c) From a radioactive sample, it is known that with a probability of 1%, at most 3 particles per second decay. How many particles in this period decay on average in one second? Give your result to three decimal places. My Solution: a) b) c) Using an online calculator, I found out that , but I'm not entirely sure whether that's the right answer. My question is: If my calculations are correct so far: How to calculate ?","p(x=20)=\frac{20^{20}}{20!}e^{-20} = 0.089 p(x \geq 10)= 1- p(x \leq 9) \\
           = 1- (\sum\limits_{x=0}^{9} \frac{20^{x}}{x!}e^{-20}) \\
           = 1- 0.005   \\
           = 0.995
 p(x \leq 3)=  \sum\limits_{x=0}^{3} \frac{\lambda ^{x}}{x!}e^{-\lambda} =0.01 \\
          0.01 = (\frac{\lambda^0}{0!} +\frac{\lambda^1}{1!}+ \frac{\lambda^2}{2!} +\frac{\lambda^3}{3!}) e^{-\lambda}   \\
           = (1 +\lambda+ \frac{\lambda^2}{2} +\frac{\lambda^3}{6}) e^{-\lambda}   \\
= \frac{(\lambda^3 +3\lambda^2 + 6\lambda+ 6)} {6e^{\lambda}}   \\
 \lambda \approx 10.0451 \lambda","['probability', 'statistics', 'probability-distributions', 'poisson-distribution']"
41,"Given $U_1, U_2, \ldots, U_n$ i.i.d $\sim \text{Unif}(-1, 1)$, what's the probability that $U_1^2 + U_2^2 + \ldots + U_n^2 \le 1$?","Given  i.i.d , what's the probability that ?","U_1, U_2, \ldots, U_n \sim \text{Unif}(-1, 1) U_1^2 + U_2^2 + \ldots + U_n^2 \le 1","Given $U_1, U_2, \ldots, U_n$ i.i.d $\sim \text{Unif}(-1, 1)$ , what's the probability that $U_1^2 + U_2^2 + \ldots + U_n^2 \le 1$ ? I tried to reduce it to $U_1^2 + U_2^2 \le 1$ and interpret the result geometrically but I'm not able to reason about it properly. $U_1^2 + U_2^2 \le 1$ represents the circle with radius $1$ centred in $0$ , but how can you interpret $|U_1| + |U_2|$ ? If $-1 \le U_1 \le 1$ and $-1 \le U_2 \le 1$ then $0 \le |U_1| + |U_2| \le 2$ . If my reasoning is correct: $$P(U_1^2 + U_2^2 \le 1) = \frac{\textrm{Area of circle}}{\textrm{Area of } |U_1| + |U_2|} = \frac{\pi}{\textrm{Area of } |U_1| + |U_2|}$$ After that the same principle can be applied in a higher dimension, in 3 dimensions could be the volume of sphere divided the volume of the shape defined by $|U_1| + |U_2| + |U_3|$ , etc. I'd appreciate some guidance on this.","Given i.i.d , what's the probability that ? I tried to reduce it to and interpret the result geometrically but I'm not able to reason about it properly. represents the circle with radius centred in , but how can you interpret ? If and then . If my reasoning is correct: After that the same principle can be applied in a higher dimension, in 3 dimensions could be the volume of sphere divided the volume of the shape defined by , etc. I'd appreciate some guidance on this.","U_1, U_2, \ldots, U_n \sim \text{Unif}(-1, 1) U_1^2 + U_2^2 + \ldots + U_n^2 \le 1 U_1^2 + U_2^2 \le 1 U_1^2 + U_2^2 \le 1 1 0 |U_1| + |U_2| -1 \le U_1 \le 1 -1 \le U_2 \le 1 0 \le |U_1| + |U_2| \le 2 P(U_1^2 + U_2^2 \le 1) = \frac{\textrm{Area of circle}}{\textrm{Area of } |U_1| + |U_2|} = \frac{\pi}{\textrm{Area of } |U_1| + |U_2|} |U_1| + |U_2| + |U_3|","['probability', 'statistics', 'probability-distributions', 'random-variables', 'uniform-distribution']"
42,"Exact determination of the probability distribution of a nonlinear function of two normally distributed variables, or of its standard deviation.","Exact determination of the probability distribution of a nonlinear function of two normally distributed variables, or of its standard deviation.",,"As a part of a problem in the design of an electronics apparatus, I am trying to analyze the probability distribution of the following quantity $$ \bar{g}_m=\frac{g_1g_2}{g_1+g_2}\label{1}\tag{1} $$ from the point of view of its probabilistic behavior: parameters $g_1$ and $g_2$ (which are part of the small signal model of a semiconductor device) have normally distributed values (around their ""nominal"" one), and their correlation is $0$ . I do not know the exact value of the standard deviation $\sigma_i$ , $i=1,2$ of their value but I know their so called ""matching"" i.e. I know the value $$ \frac{\Delta g_i}{g_i}=k\sigma_i>0\qquad i=1,2\label{2}\tag{2} $$ where $k$ is an integer $\ge 6$ (these devices are produced in millions of units, so the devices which do not satisfy \eqref{2} and must be rejected during the test phase should be less than one part per million) and can be assumed constant for both $g_1$ and $g_2$ : for the sake of precision, I can say that $\frac{\Delta g_1}{g_1}\simeq\frac{\Delta g_2}{g_2}\simeq 10\%$ , even if this is not very useful from the point of view of the problem I am posing. So my question is Is it possible to determine explicitly the probability distribution of $\bar{g}_m$ , or at least a precise estimate for the matching $\frac{\Delta g_m}{g_m}$ from values of the matching of $g_1$ and $g_2$ expressed by \eqref{2}? As it can bee seen, the question is equivalent to ask if it is possible to determine explicitly (or at least sharply estimate) the standard deviation $\sigma_m$ of $\bar{g}_m$ from the knowledge of $\sigma_1$ and $\sigma_2$ . Notes What I know : V. K. Rohatgi has developed a way of determine the probability distribution of the product of two random variables by using the Mellin transform of their distributions. However, \eqref{1} is not a simple product of random variables, but is a nonlinear algebraic function of two random variables , therefore a knowledge deeper than mine of the applicable probabilistic techniques may be required (read as: I am not an expert in applied probability). What I customarily do in common designs and why I cannot proceed in the same way for this one . The basis of the two methods I use (and, in my opinion, many other engineers customarily do) is the standard technique inherited from the theory of error propagation $$ \mathrm{d}\bar{g}_m =\frac{\partial\bar{g}_m}{\partial g_1}\mathrm{d}g_1+\frac{\partial\bar{g}_m}{\partial g_2}\mathrm{d}g_2\implies \begin{align} \Delta\bar{g}_m &\simeq\frac{\partial\bar{g}_m}{\partial g_1}\Delta g_1+\frac{\partial\bar{g}_m}{\partial g_2}\Delta g_2\\ \frac{\Delta\bar{g}_m}{\bar{g}_m }&\simeq\frac{{g}_1}{\bar{g}_m }\frac{\partial\bar{g}_m}{\partial g_1}\frac{\Delta g_1}{g_1 }+\frac{{g}_2}{\bar{g}_m }\frac{\partial\bar{g}_m}{\partial g_2}\frac{\Delta g_2}{g_2}\\ &=\alpha_1\frac{\Delta g_1}{g_1}+\alpha_2 \frac{\Delta g_2}{g_2} \end{align}\label{3}\tag{3} $$ Assuming \eqref{3}, the I use one of the following two estimates: The ""standard"" error propagation theoretical estimate $$ \left\vert\frac{\Delta\bar{g}_m}{\bar{g}_m }\right\vert\le|\alpha_1|\frac{\Delta g_1}{g_1}+|\alpha_2| \frac{\Delta g_2}{g_2}\label{I}\tag{I} $$ A more refined estimates, that is an equality for the sum of normally distributed variables $$ \left\vert\frac{\Delta\bar{g}_m}{\bar{g}_m}\right\vert\le\sqrt{\left(\alpha_1\frac{\Delta g_1}{g_1}\right)^{\!2}+\left(\alpha_2 \frac{\Delta g_2}{g_2}\right)^{\!2}}\label{II}\tag{II} $$ I use almost always \eqref{I}. However, despite being optimal (from the value-to-cost ratio point of view) for medium/small production batches (from 100 to few thousands units per month), this estimates is too pessimistic and it would rise excessively the costs for large production batches, if I use it to chose the matching of $g_1$ and $g_2$ in order to get the desired matching on $\bar{g}_m$ . On the other hand, \eqref{II} is a little bit more optimistic, but how much is it more optimistic ? A note after the comment of Nap D. Lover . The parameters $g_1$ and $g_2$ are explicitly independent: de facto , they are associated to two different devices, even technologically very different.","As a part of a problem in the design of an electronics apparatus, I am trying to analyze the probability distribution of the following quantity from the point of view of its probabilistic behavior: parameters and (which are part of the small signal model of a semiconductor device) have normally distributed values (around their ""nominal"" one), and their correlation is . I do not know the exact value of the standard deviation , of their value but I know their so called ""matching"" i.e. I know the value where is an integer (these devices are produced in millions of units, so the devices which do not satisfy \eqref{2} and must be rejected during the test phase should be less than one part per million) and can be assumed constant for both and : for the sake of precision, I can say that , even if this is not very useful from the point of view of the problem I am posing. So my question is Is it possible to determine explicitly the probability distribution of , or at least a precise estimate for the matching from values of the matching of and expressed by \eqref{2}? As it can bee seen, the question is equivalent to ask if it is possible to determine explicitly (or at least sharply estimate) the standard deviation of from the knowledge of and . Notes What I know : V. K. Rohatgi has developed a way of determine the probability distribution of the product of two random variables by using the Mellin transform of their distributions. However, \eqref{1} is not a simple product of random variables, but is a nonlinear algebraic function of two random variables , therefore a knowledge deeper than mine of the applicable probabilistic techniques may be required (read as: I am not an expert in applied probability). What I customarily do in common designs and why I cannot proceed in the same way for this one . The basis of the two methods I use (and, in my opinion, many other engineers customarily do) is the standard technique inherited from the theory of error propagation Assuming \eqref{3}, the I use one of the following two estimates: The ""standard"" error propagation theoretical estimate A more refined estimates, that is an equality for the sum of normally distributed variables I use almost always \eqref{I}. However, despite being optimal (from the value-to-cost ratio point of view) for medium/small production batches (from 100 to few thousands units per month), this estimates is too pessimistic and it would rise excessively the costs for large production batches, if I use it to chose the matching of and in order to get the desired matching on . On the other hand, \eqref{II} is a little bit more optimistic, but how much is it more optimistic ? A note after the comment of Nap D. Lover . The parameters and are explicitly independent: de facto , they are associated to two different devices, even technologically very different.","
\bar{g}_m=\frac{g_1g_2}{g_1+g_2}\label{1}\tag{1}
 g_1 g_2 0 \sigma_i i=1,2 
\frac{\Delta g_i}{g_i}=k\sigma_i>0\qquad i=1,2\label{2}\tag{2}
 k \ge 6 g_1 g_2 \frac{\Delta g_1}{g_1}\simeq\frac{\Delta g_2}{g_2}\simeq 10\% \bar{g}_m \frac{\Delta g_m}{g_m} g_1 g_2 \sigma_m \bar{g}_m \sigma_1 \sigma_2 
\mathrm{d}\bar{g}_m =\frac{\partial\bar{g}_m}{\partial g_1}\mathrm{d}g_1+\frac{\partial\bar{g}_m}{\partial g_2}\mathrm{d}g_2\implies
\begin{align}
\Delta\bar{g}_m &\simeq\frac{\partial\bar{g}_m}{\partial g_1}\Delta g_1+\frac{\partial\bar{g}_m}{\partial g_2}\Delta g_2\\
\frac{\Delta\bar{g}_m}{\bar{g}_m }&\simeq\frac{{g}_1}{\bar{g}_m }\frac{\partial\bar{g}_m}{\partial g_1}\frac{\Delta g_1}{g_1 }+\frac{{g}_2}{\bar{g}_m }\frac{\partial\bar{g}_m}{\partial g_2}\frac{\Delta g_2}{g_2}\\
&=\alpha_1\frac{\Delta g_1}{g_1}+\alpha_2 \frac{\Delta g_2}{g_2}
\end{align}\label{3}\tag{3}
 
\left\vert\frac{\Delta\bar{g}_m}{\bar{g}_m }\right\vert\le|\alpha_1|\frac{\Delta g_1}{g_1}+|\alpha_2| \frac{\Delta g_2}{g_2}\label{I}\tag{I}
 
\left\vert\frac{\Delta\bar{g}_m}{\bar{g}_m}\right\vert\le\sqrt{\left(\alpha_1\frac{\Delta g_1}{g_1}\right)^{\!2}+\left(\alpha_2 \frac{\Delta g_2}{g_2}\right)^{\!2}}\label{II}\tag{II}
 g_1 g_2 \bar{g}_m g_1 g_2","['probability-theory', 'statistics', 'probability-distributions']"
43,How do you create a custom probability density function from a discrete distribution?,How do you create a custom probability density function from a discrete distribution?,,"I have some data that follows some unknown probability function. I would like to roughly extract that probability function. My approach is to plot the data in a histogram and smooth it out using LOWESS . I implemented this following this post. I then use interpolation to create my cumulative distribution function (or at least I think so). But here I am stuck. I know I have to normalize the distribution somehow, but simply dividing by the number of data points does not seem to do the trick (read: something is completely wrong). How do I do this? Is there a better approach? I would like to implement all of this in Python. Here is my code so far: import numpy as np from scipy import interpolate, integrate from scipy.stats import rv_continuous import statsmodels.api as sm import matplotlib.pyplot as plt   class CustomDistribution(rv_continuous):     def __init__(self, custom_cdf):         super().__init__()         self.custom_cdf = custom_cdf      def _pdf(self, x, *args):         return self.custom_cdf(x)      # def _ppf(self, q, **kwargs):     #     return   # create some normally distributed values and make a histogram a = np.random.normal(size=10000) counts, bins = np.histogram(a, bins=100, density=True) bin_widths = np.diff(bins) bin_centers = bins[:-1] + bin_widths  # roughly try to fit some distribution lowess = sm.nonparametric.lowess(counts, bin_centers, frac=0.1) fit = interpolate.interp1d(     lowess[:, 0], lowess[:, 1], kind='cubic', fill_value=0,     bounds_error=False )  # integral = integrate.quad(fit, -np.inf, np.inf)[0] # print(integral) distr = CustomDistribution(fit) # print(distr.rvs(size=1))  plt.hist(a, 100, density=True, label='original data') plt.plot(bin_centers, fit(bin_centers), label='fit') plt.hist(distr.rvs(size=100), 100, density=True, label='data from fit') plt.legend() plt.show() In order to be able to draw random variates from this distribution later on, I also need to implement the inverse cdf / _ppf() , according to the rv_continuous documentation . EDIT So I have been able to draw some random variates from the fit, but it takes incredibly long. The main reason seems to be that in order to draw the variates, I need to have a properly implemented inverse cdf / _ppf() . From the documentation of rv_continuous : The default method _rvs relies on the inverse of the cdf, _ppf, applied to a uniform random variate. In order to generate random variates efficiently, either the default _ppf needs to be overwritten (e.g. if the inverse cdf can expressed in an explicit form) or a sampling method needs to be implemented in a custom _rvs method. Because I don't have that, the cdf is created by integrating over the pdf, but for some reason, the integral does not seem to converge: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.   If increasing the limit yields no improvement it is advised to analyze    the integrand in order to determine the difficulties.  If the position of a    local difficulty can be determined (singularity, discontinuity) one will    probably gain from splitting up the interval and calling the integrator    on the subranges.  Perhaps a special-purpose integrator should be used. So I guess I need a good way to create my own implementation of at least the cdf, but better yet of the inverse cdf.","I have some data that follows some unknown probability function. I would like to roughly extract that probability function. My approach is to plot the data in a histogram and smooth it out using LOWESS . I implemented this following this post. I then use interpolation to create my cumulative distribution function (or at least I think so). But here I am stuck. I know I have to normalize the distribution somehow, but simply dividing by the number of data points does not seem to do the trick (read: something is completely wrong). How do I do this? Is there a better approach? I would like to implement all of this in Python. Here is my code so far: import numpy as np from scipy import interpolate, integrate from scipy.stats import rv_continuous import statsmodels.api as sm import matplotlib.pyplot as plt   class CustomDistribution(rv_continuous):     def __init__(self, custom_cdf):         super().__init__()         self.custom_cdf = custom_cdf      def _pdf(self, x, *args):         return self.custom_cdf(x)      # def _ppf(self, q, **kwargs):     #     return   # create some normally distributed values and make a histogram a = np.random.normal(size=10000) counts, bins = np.histogram(a, bins=100, density=True) bin_widths = np.diff(bins) bin_centers = bins[:-1] + bin_widths  # roughly try to fit some distribution lowess = sm.nonparametric.lowess(counts, bin_centers, frac=0.1) fit = interpolate.interp1d(     lowess[:, 0], lowess[:, 1], kind='cubic', fill_value=0,     bounds_error=False )  # integral = integrate.quad(fit, -np.inf, np.inf)[0] # print(integral) distr = CustomDistribution(fit) # print(distr.rvs(size=1))  plt.hist(a, 100, density=True, label='original data') plt.plot(bin_centers, fit(bin_centers), label='fit') plt.hist(distr.rvs(size=100), 100, density=True, label='data from fit') plt.legend() plt.show() In order to be able to draw random variates from this distribution later on, I also need to implement the inverse cdf / _ppf() , according to the rv_continuous documentation . EDIT So I have been able to draw some random variates from the fit, but it takes incredibly long. The main reason seems to be that in order to draw the variates, I need to have a properly implemented inverse cdf / _ppf() . From the documentation of rv_continuous : The default method _rvs relies on the inverse of the cdf, _ppf, applied to a uniform random variate. In order to generate random variates efficiently, either the default _ppf needs to be overwritten (e.g. if the inverse cdf can expressed in an explicit form) or a sampling method needs to be implemented in a custom _rvs method. Because I don't have that, the cdf is created by integrating over the pdf, but for some reason, the integral does not seem to converge: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.   If increasing the limit yields no improvement it is advised to analyze    the integrand in order to determine the difficulties.  If the position of a    local difficulty can be determined (singularity, discontinuity) one will    probably gain from splitting up the interval and calling the integrator    on the subranges.  Perhaps a special-purpose integrator should be used. So I guess I need a good way to create my own implementation of at least the cdf, but better yet of the inverse cdf.",,"['statistics', 'probability-distributions', 'python']"
44,Standardisation of multivariate normal distribution,Standardisation of multivariate normal distribution,,"Knowing that random vector $$ \Sigma^{-\frac{1}{2}}(\textbf{Y}-\mu) \sim N(0, I) $$ what is the distribution of random variable $$ (\textbf{Y}-\mu)^T\Sigma^{-1}(\textbf{Y}-\mu) $$ where random vector $\textbf{Y}$ has a normal distribution with positive semidefinite covariance matrix $\Sigma$ and expected value vector $\mu$ ? My attempt was to $$ (\textbf{Y}-\mu)^T\Sigma^{-1}(\textbf{Y}-\mu) = (\Sigma^{-\frac{1}{2}}(\textbf{Y}-\mu))^T(\Sigma^{-\frac{1}{2}}(\textbf{Y}-\mu)) = \text{?} $$ I know that both brackets are $N(0, I)$ but I don't know how to proceed.",Knowing that random vector what is the distribution of random variable where random vector has a normal distribution with positive semidefinite covariance matrix and expected value vector ? My attempt was to I know that both brackets are but I don't know how to proceed.,"
\Sigma^{-\frac{1}{2}}(\textbf{Y}-\mu) \sim N(0, I)
 
(\textbf{Y}-\mu)^T\Sigma^{-1}(\textbf{Y}-\mu)
 \textbf{Y} \Sigma \mu 
(\textbf{Y}-\mu)^T\Sigma^{-1}(\textbf{Y}-\mu) = (\Sigma^{-\frac{1}{2}}(\textbf{Y}-\mu))^T(\Sigma^{-\frac{1}{2}}(\textbf{Y}-\mu)) = \text{?}
 N(0, I)","['probability', 'statistics', 'probability-distributions']"
45,Gaussian approximation to arbitrary distribution in Kullback–Leibler divergence,Gaussian approximation to arbitrary distribution in Kullback–Leibler divergence,,"The Kullback–Leibler divergence of two densities $p_1,p_2$ over $\mathbb R^d$ is $\def\KL{\mathrm{KL}}$ $$  D_\KL(p_1,p_2)=\int_{\mathbb R^d} p_1(x) \log\frac{p_1 (x)} { p_2(x)}\,\mathrm d x.$$ I know from Gibbs' inequality that $D_{\KL}$ is non-negative. Now I want to prove the following: let $p_2$ be a fixed density, and $p_1$ the density of some Gaussian distribution, then $D_{\KL}(p_1,p_2)$ is minimized exactly when $p_1$ takes the expectation of $p_2$ as its expectation, and the covariance matrix of $p_2$ its covariance matrix. I guess this might require a very technical proof.","The Kullback–Leibler divergence of two densities over is I know from Gibbs' inequality that is non-negative. Now I want to prove the following: let be a fixed density, and the density of some Gaussian distribution, then is minimized exactly when takes the expectation of as its expectation, and the covariance matrix of its covariance matrix. I guess this might require a very technical proof.","p_1,p_2 \mathbb R^d \def\KL{\mathrm{KL}}   D_\KL(p_1,p_2)=\int_{\mathbb R^d} p_1(x) \log\frac{p_1 (x)} { p_2(x)}\,\mathrm d x. D_{\KL} p_2 p_1 D_{\KL}(p_1,p_2) p_1 p_2 p_2","['probability', 'statistics', 'normal-distribution', 'information-theory', 'entropy']"
46,Difference of Chi-squared Variables,Difference of Chi-squared Variables,,"Is this procedure correct? Considering that $X$ is a chi-square random variable with $r$ degrees of freedom? $$E(e^{-tX}) =E \left(\frac{1}{e^{tX}}\right)=\frac{1}{E(e^{tX})} =\frac{1}{(1-2t)^{-r/2}} $$ The following demonstration, despite reaching a true conclusion, is not entirely correct: Let $X_1$ and $X_2$ be a chi-squared random variable with $r_1$ and $r_2$ degrees of freedom respectively, the $Y=X_1-X_2$ is also a chi-squared random variable with $(r_1-r_2)$ degrees of freedom provided that $r_1>r_2$ : $$M_Y(t)=\large{E(e^{tY})=E(e^{t(X_1-X_2)})=\frac{E(e^{tX_1})}{E(e^{-tX_2})}}$$ $$=\large{(1-2t)^{-\frac{r_1}{2}}(1-2t)^{\frac{r_2}{2}}=(1-2t)^{-\frac{(r_1-r_2)}{2}}}$$ therefore, $Y$ is chi-squared with $r_1-r_2$ degrees of freedom.","Is this procedure correct? Considering that is a chi-square random variable with degrees of freedom? The following demonstration, despite reaching a true conclusion, is not entirely correct: Let and be a chi-squared random variable with and degrees of freedom respectively, the is also a chi-squared random variable with degrees of freedom provided that : therefore, is chi-squared with degrees of freedom.",X r E(e^{-tX}) =E \left(\frac{1}{e^{tX}}\right)=\frac{1}{E(e^{tX})} =\frac{1}{(1-2t)^{-r/2}}  X_1 X_2 r_1 r_2 Y=X_1-X_2 (r_1-r_2) r_1>r_2 M_Y(t)=\large{E(e^{tY})=E(e^{t(X_1-X_2)})=\frac{E(e^{tX_1})}{E(e^{-tX_2})}} =\large{(1-2t)^{-\frac{r_1}{2}}(1-2t)^{\frac{r_2}{2}}=(1-2t)^{-\frac{(r_1-r_2)}{2}}} Y r_1-r_2,"['probability', 'statistics', 'probability-distributions']"
47,Problem Interpreting histogram,Problem Interpreting histogram,,"I am reading Understandable statistics . In the second chapter, example 2, the author shows the following histogram: The author then proceed to interpret the histogram as follows: About 40% of the wait times fall between 7 and 9 minutes   while about 80% are between 4 and 9 minutes. Less than 1%   are 3 minutes or less or greater than 12 . I think that the statement: Less than 1%   are 3 minutes or less or greater than 12 is false. It should be: Less than 10%   are 3 minutes or less or greater than 12 Is the author correct or am I missing something?","I am reading Understandable statistics . In the second chapter, example 2, the author shows the following histogram: The author then proceed to interpret the histogram as follows: About 40% of the wait times fall between 7 and 9 minutes   while about 80% are between 4 and 9 minutes. Less than 1%   are 3 minutes or less or greater than 12 . I think that the statement: Less than 1%   are 3 minutes or less or greater than 12 is false. It should be: Less than 10%   are 3 minutes or less or greater than 12 Is the author correct or am I missing something?",,"['statistics', 'descriptive-statistics']"
48,Accuracy of estimation of the variance,Accuracy of estimation of the variance,,"Consider $N$ i.i.d. samples $x_1, \dots, x_N$ from an unknown discrete distribution on $\{0,\dots, n\}$ . We know that $$\frac{1}{N-1} \sum_{i = 1}^N (x_i - m)^2$$ where $m$ is the sample mean, is an unbiased estimator for the variance. But what confidence intervals can we give for this estimate?","Consider i.i.d. samples from an unknown discrete distribution on . We know that where is the sample mean, is an unbiased estimator for the variance. But what confidence intervals can we give for this estimate?","N x_1, \dots, x_N \{0,\dots, n\} \frac{1}{N-1} \sum_{i = 1}^N (x_i - m)^2 m",['statistics']
49,Posterior distribution of uniform likelihood and Pareto prior,Posterior distribution of uniform likelihood and Pareto prior,,"Let the sampling distribution be $$\mathbf{Y}|\Theta\sim U(0,\theta)$$ and $$f(\mathbf{y}|\theta)=\prod^n_{i=1}\frac{1}{\theta}\times \mathbb{1\{0<y_i\le\theta\}}=\frac{1}{\theta^n}\times \mathbb{1}\{0<y_i\}\times \mathbb{1}\{c'\le\theta\},$$ where $c'=\text{max}\{y_1,...,y_i\}.$ Let the prior distribution be Pareto distributed. That is $$p(\theta)=\frac{Kb^K}{\theta^{K+1}}\mathbb\times{1\{b\le\theta\}}\propto \frac{1}{\theta^{K+1}}\mathbb\times{1\{b\le\theta\}}.$$ I'm trying to get the posterior distribution. That is, $$p(\theta|\mathbf{y})=\frac{1}{\theta^n}\frac{1}{\theta^{K+1}}\times \mathbb{1}\{0<y_i\}\times \mathbb{1}\{\text{max}\{b,c'\}\le\theta\} \\ =\theta^{-(n+K+1)}\times \mathbb{1}\{0<y_i\}\times \mathbb{1}\{\text{max}\{b,c'\}\le\theta\}.$$ However, the correct answer is $$p(\theta|\mathbf{y})=\theta^{-(n+K)}\times \mathbb{1}\{b\le\theta\}\times \mathbb{1}\{\text{max}\{b,c'\}\le\theta\}$$ but I don't know how to get there.","Let the sampling distribution be and where Let the prior distribution be Pareto distributed. That is I'm trying to get the posterior distribution. That is, However, the correct answer is but I don't know how to get there.","\mathbf{Y}|\Theta\sim U(0,\theta) f(\mathbf{y}|\theta)=\prod^n_{i=1}\frac{1}{\theta}\times \mathbb{1\{0<y_i\le\theta\}}=\frac{1}{\theta^n}\times \mathbb{1}\{0<y_i\}\times \mathbb{1}\{c'\le\theta\}, c'=\text{max}\{y_1,...,y_i\}. p(\theta)=\frac{Kb^K}{\theta^{K+1}}\mathbb\times{1\{b\le\theta\}}\propto \frac{1}{\theta^{K+1}}\mathbb\times{1\{b\le\theta\}}. p(\theta|\mathbf{y})=\frac{1}{\theta^n}\frac{1}{\theta^{K+1}}\times \mathbb{1}\{0<y_i\}\times \mathbb{1}\{\text{max}\{b,c'\}\le\theta\} \\
=\theta^{-(n+K+1)}\times \mathbb{1}\{0<y_i\}\times \mathbb{1}\{\text{max}\{b,c'\}\le\theta\}. p(\theta|\mathbf{y})=\theta^{-(n+K)}\times \mathbb{1}\{b\le\theta\}\times \mathbb{1}\{\text{max}\{b,c'\}\le\theta\}","['statistics', 'probability-distributions', 'statistical-inference', 'bayesian']"
50,Is the following parametrizations identifiable?,Is the following parametrizations identifiable?,,"$X$ and $Y$ are independent $N(\mu_1, \sigma^2)$ and $N(\mu_2, \sigma^2)$ , $\theta = (\mu_1, \mu_2)$ and we observe $Y − X$ . From what I understand, a model $P_\theta$ is identifiable if $\theta_1=\theta_2$ implies that $P_{\theta_1}=P_{\theta_2}$ and $\theta_1\not=\theta_2$ implies that $P_{\theta_1}\not=P_{\theta_2}$ . How can I choose ${\theta}$ to prove or disprove this? $$Y-X \sim N(\mu_2-\mu_1, 2\sigma^2)$$ If I try both $\mu_2,\mu_1$ with a shift - I think I will get the same answer? Does that mean it's Identifiable?","and are independent and , and we observe . From what I understand, a model is identifiable if implies that and implies that . How can I choose to prove or disprove this? If I try both with a shift - I think I will get the same answer? Does that mean it's Identifiable?","X Y N(\mu_1, \sigma^2) N(\mu_2, \sigma^2) \theta = (\mu_1, \mu_2) Y − X P_\theta \theta_1=\theta_2 P_{\theta_1}=P_{\theta_2} \theta_1\not=\theta_2 P_{\theta_1}\not=P_{\theta_2} {\theta} Y-X \sim N(\mu_2-\mu_1, 2\sigma^2) \mu_2,\mu_1","['statistics', 'statistical-inference']"
51,Functional equation from integral identity,Functional equation from integral identity,,"I have the following equality about some function $F$ , where $n$ is any positive integer: $$ \int_0^\infty [1 - F(x)]^n \mathrm{d}x = \frac{1}{n} \int_0^\infty [1 - F(x)] \mathrm{d}x $$ In this context, $F$ is defined for $x \geq 0$ and is the cdf of a random variable; that is, $0 \leq F(x) \leq 1$ and $a < b \implies F(a) < F(b)$ . I think that the only $F$ that satisfies the above equality is the cdf of the exponential distribution, $F(x) = 1 - e^{-\lambda x}$ where $\lambda > 0$ . I'm having a hard time showing this, though. Does anyone have any pointers? EDIT: as pointed out by a comment, this is equivalent to showing that if $\int_0^\infty G(x)^n \mathrm{d}x = \frac{1}{n} \int_0^\infty G(x) \mathrm{d}x$ then $G(x)$ must be of the form $e^{-\lambda x}$ .","I have the following equality about some function , where is any positive integer: In this context, is defined for and is the cdf of a random variable; that is, and . I think that the only that satisfies the above equality is the cdf of the exponential distribution, where . I'm having a hard time showing this, though. Does anyone have any pointers? EDIT: as pointed out by a comment, this is equivalent to showing that if then must be of the form .","F n 
\int_0^\infty [1 - F(x)]^n \mathrm{d}x = \frac{1}{n} \int_0^\infty [1 - F(x)] \mathrm{d}x
 F x \geq 0 0 \leq F(x) \leq 1 a < b \implies F(a) < F(b) F F(x) = 1 - e^{-\lambda x} \lambda > 0 \int_0^\infty G(x)^n \mathrm{d}x = \frac{1}{n} \int_0^\infty G(x) \mathrm{d}x G(x) e^{-\lambda x}","['integration', 'statistics', 'probability-distributions', 'density-function']"
52,"Counterintuitive result, Expected Value of Uniform Random Variable raised to increasing powers.","Counterintuitive result, Expected Value of Uniform Random Variable raised to increasing powers.",,"Out of curiosity, I've been playing with some simulations to simulate compounded interest rates from markets (such as stocks and cryptocurrencies). Let $r \sim \mathcal{U}(0.90,1.05)$ , be the return (as a percentage) of a single transaction. Let's say a stock was bought and sold, $r$ is the gain or loss for that particular transaction. I assumed a pessimistic distribution, $10\%$ loss and $5\%$ gain are the boundaries of the uniform distribution. The expected value for a single transaction is $\mathbb{E}[r]=0.975$ . I was curious to see the expected rate of return over multiple transactions, let's say $k$ transactions. This means I have to calculate $\mathbb{E}[r^k]$ . I do not know how to calculate $\mathbb{E}[r^k]$ manually and would appeciate if someone could teach me how. All I know is that it is not equal to $\mathbb{E}[r]^k$ . I used software to calculate $\mathbb{E}[r^k]$ for $k\in \{1,\dots,50\}$ , and I was surprised by the result. I plotted the result below. My intuition says that since $\mathbb{E}[r]=0.975$ then it is a losing game, and eventually would ruin the player, and indeed the plot shows increasing loss initially. However, I am baffled to see how it eventually became a positive rate of return. I cannot explain this neither intuitively nor do I have enough mathematical background in this area to reason about it. I appreciate your valuable insight!","Out of curiosity, I've been playing with some simulations to simulate compounded interest rates from markets (such as stocks and cryptocurrencies). Let , be the return (as a percentage) of a single transaction. Let's say a stock was bought and sold, is the gain or loss for that particular transaction. I assumed a pessimistic distribution, loss and gain are the boundaries of the uniform distribution. The expected value for a single transaction is . I was curious to see the expected rate of return over multiple transactions, let's say transactions. This means I have to calculate . I do not know how to calculate manually and would appeciate if someone could teach me how. All I know is that it is not equal to . I used software to calculate for , and I was surprised by the result. I plotted the result below. My intuition says that since then it is a losing game, and eventually would ruin the player, and indeed the plot shows increasing loss initially. However, I am baffled to see how it eventually became a positive rate of return. I cannot explain this neither intuitively nor do I have enough mathematical background in this area to reason about it. I appreciate your valuable insight!","r \sim \mathcal{U}(0.90,1.05) r 10\% 5\% \mathbb{E}[r]=0.975 k \mathbb{E}[r^k] \mathbb{E}[r^k] \mathbb{E}[r]^k \mathbb{E}[r^k] k\in \{1,\dots,50\} \mathbb{E}[r]=0.975","['probability', 'statistics']"
53,There are 3 red balls and 2 white balls in a box. [closed],There are 3 red balls and 2 white balls in a box. [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Now consider an experiment in which a ball is taken out from the box each time, then put back after its color observed, and one ball is put into again whose color is the same as the taking out one. if we repeat the experiment 4 times in succession, try to find the probability that we obtain a white ball in the 1st, 2nd times, and obtain a red ball in the 3rd, 4th times.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Now consider an experiment in which a ball is taken out from the box each time, then put back after its color observed, and one ball is put into again whose color is the same as the taking out one. if we repeat the experiment 4 times in succession, try to find the probability that we obtain a white ball in the 1st, 2nd times, and obtain a red ball in the 3rd, 4th times.",,"['probability', 'statistics']"
54,Why do two different approaches using matrix algebra yield different results?,Why do two different approaches using matrix algebra yield different results?,,"I am solving a problem involving linear regression and I am finding that two different approaches to the matrix algebra is yielding different results. In the second approach, I am merely simplifying the second component of the expression first. As you can see, the results are vastly different. Intuitively, I think the first approach is correct but I can't figure out what is wrong with the second approach to yield such a different answer. Here, we assume $M_{x} = I -X(X'X)^{-1}X'$ and $X'X$ is non-singular. I am hoping that your answer will help me better understand matrix algebra! Approach 1: $$ X'(M_{x})^{-1}X - X'(M_{x})^{-1}X(X'X)^{-1}(X'X) \\ X'(M_{x})^{-1}[I -X(X'X)^{-1}X']X \\ X'(M_{x})^{-1}M_{x}X \\ X'X $$ Approach 2: $$ X'(M_{x})^{-1}X - X'(M_{x})^{-1}X(X'X)^{-1}(X'X) \\ X'(M_{x})^{-1}X - X'(M_{x})^{-1}X \\ 0 $$","I am solving a problem involving linear regression and I am finding that two different approaches to the matrix algebra is yielding different results. In the second approach, I am merely simplifying the second component of the expression first. As you can see, the results are vastly different. Intuitively, I think the first approach is correct but I can't figure out what is wrong with the second approach to yield such a different answer. Here, we assume and is non-singular. I am hoping that your answer will help me better understand matrix algebra! Approach 1: Approach 2:","M_{x} = I -X(X'X)^{-1}X' X'X 
X'(M_{x})^{-1}X - X'(M_{x})^{-1}X(X'X)^{-1}(X'X) \\
X'(M_{x})^{-1}[I -X(X'X)^{-1}X']X \\
X'(M_{x})^{-1}M_{x}X \\
X'X
 
X'(M_{x})^{-1}X - X'(M_{x})^{-1}X(X'X)^{-1}(X'X) \\
X'(M_{x})^{-1}X - X'(M_{x})^{-1}X \\
0
","['linear-algebra', 'statistics', 'regression']"
55,Integrability requirement to prove $f = 0$ a.e.,Integrability requirement to prove  a.e.,f = 0,"I want to show that for measurable $f$ , $\int\limits_{-\infty}^x f(t) dt = 0$ for all $x \in \mathbb{R}$ implies that $f = 0$ a.e. From a previous question , I can see that $\int\limits_{B} f^+(t) dt = \int\limits_{B} f^-(t) dt$ for all Borel sets $B$ . However, my concern is that unless we assume that $f$ is in $\mathcal{L}^1$ , we cannot conclude $f = 0$ a.e. since $\int_B f^+(t)$ might be $\infty$ . Is $f \in \mathcal{L}^1$ a necessary assumption?","I want to show that for measurable , for all implies that a.e. From a previous question , I can see that for all Borel sets . However, my concern is that unless we assume that is in , we cannot conclude a.e. since might be . Is a necessary assumption?",f \int\limits_{-\infty}^x f(t) dt = 0 x \in \mathbb{R} f = 0 \int\limits_{B} f^+(t) dt = \int\limits_{B} f^-(t) dt B f \mathcal{L}^1 f = 0 \int_B f^+(t) \infty f \in \mathcal{L}^1,"['probability-theory', 'statistics', 'measure-theory']"
56,Questions on probability distributions,Questions on probability distributions,,"(1) Let $X_1,X_2$ be two independent gamma-distributed random variables: $X_1 \sim \Gamma(r,1), X_2 \sim \Gamma(s,1)$ . Are $Z_1:=\frac{X_1}{X_1+X_2}$ and $Z_2:= X_1+X_2$ independent? if yes, I have to find their density. I have already found that $X_1=Y_1Y_2$ and $X_2=Y_1(1-Y_2)$ . But I am not done. What is the domain of $Y_1$ and $Y_2$ ? Since $X_1,X_2>0$ I have that $Y_1>0$ and $0<Y_2<1$ . (2) If $X_1 \sim B (a,b), X_2 \sim B(a+b,c),$ prove $X_1 X_2 \sim B(a,b+c)$ (3) If $X \sim N(0,\sigma^2),$ calculate $E(X^n).$ What I know is that $$E(x^n) = \int_{-\infty}^{\infty}x^n\frac{1}{\sqrt{2\pi t}}e^{-x^2/2t}\;dx$$ I've tried solving numerous times it by parts and then taking limits but I keep getting $0$ and not $3t^2$ !  Can somebody give me a better direction?","(1) Let be two independent gamma-distributed random variables: . Are and independent? if yes, I have to find their density. I have already found that and . But I am not done. What is the domain of and ? Since I have that and . (2) If prove (3) If calculate What I know is that I've tried solving numerous times it by parts and then taking limits but I keep getting and not !  Can somebody give me a better direction?","X_1,X_2 X_1 \sim \Gamma(r,1), X_2 \sim \Gamma(s,1) Z_1:=\frac{X_1}{X_1+X_2} Z_2:= X_1+X_2 X_1=Y_1Y_2 X_2=Y_1(1-Y_2) Y_1 Y_2 X_1,X_2>0 Y_1>0 0<Y_2<1 X_1 \sim B (a,b), X_2 \sim B(a+b,c), X_1 X_2 \sim B(a,b+c) X \sim N(0,\sigma^2), E(X^n). E(x^n) = \int_{-\infty}^{\infty}x^n\frac{1}{\sqrt{2\pi t}}e^{-x^2/2t}\;dx 0 3t^2","['statistics', 'probability-distributions']"
57,"Calculate $E(XY)$ if $\mathrm{Cov}(X, Y) = 0$",Calculate  if,"E(XY) \mathrm{Cov}(X, Y) = 0","$E(X) = 3, E(Y) = 4$ and $E(X^2) = 10, E(Y^2) = 25$ How can I calculate $E(XY)$ If I know that $\mathrm{Cov}(XY) = 0$ I know that If $X$ and $Y$ are independent then $\mathrm{Cov}(X, Y) = 0.$ But zero covariance does not always imply independence",and How can I calculate If I know that I know that If and are independent then But zero covariance does not always imply independence,"E(X) = 3, E(Y) = 4 E(X^2) = 10, E(Y^2) = 25 E(XY) \mathrm{Cov}(XY) = 0 X Y \mathrm{Cov}(X, Y) = 0.","['probability', 'statistics', 'covariance']"
58,Probability of wearing a coat & having it snow.,Probability of wearing a coat & having it snow.,,"I haven't been able to solve this, could you please help? Steve has lived in Boston for a long time. From experience, he knows that each day has a 5% chance to be snowy. Steve looks ahead to the next 10 days. Steve decides that, without checking the weather, he will wear his heavy coat to work 3 of those days. What is the probability Steve will wear his coat on at least one snowy day? Thank you","I haven't been able to solve this, could you please help? Steve has lived in Boston for a long time. From experience, he knows that each day has a 5% chance to be snowy. Steve looks ahead to the next 10 days. Steve decides that, without checking the weather, he will wear his heavy coat to work 3 of those days. What is the probability Steve will wear his coat on at least one snowy day? Thank you",,"['probability', 'statistics', 'discrete-mathematics']"
59,"What is the probability of winning a best of 5 game, if I already won the first game?","What is the probability of winning a best of 5 game, if I already won the first game?",,"For example, if I am playing a game with a friend and we both are equally likely to win each game, then what is the probability of me winning the best of 5 match, given that I already won the 1st game ? I did some work on this question, but I don't think this method seems so sound. $P$ (I win in 3 games) = $(\frac{1}{2})^2$ $P$ (I win in 4 games) = $(\frac{1}{2})^3 \cdot \frac{2!}{1! \cdot 1!}$ $P$ (I win in 5 games) = $(\frac{1}{2})^4 \cdot \frac{3!}{1! \cdot 2!}$ $P$ (me winning) = sum of the above probabilities = 0.6875","For example, if I am playing a game with a friend and we both are equally likely to win each game, then what is the probability of me winning the best of 5 match, given that I already won the 1st game ? I did some work on this question, but I don't think this method seems so sound. (I win in 3 games) = (I win in 4 games) = (I win in 5 games) = (me winning) = sum of the above probabilities = 0.6875",P (\frac{1}{2})^2 P (\frac{1}{2})^3 \cdot \frac{2!}{1! \cdot 1!} P (\frac{1}{2})^4 \cdot \frac{3!}{1! \cdot 2!} P,"['probability', 'statistics']"
60,Does a player having one hand increase the likelihood of other players also having that hand?,Does a player having one hand increase the likelihood of other players also having that hand?,,"Say a deck of cards is dealt out equally to four players (each player receives 13 cards). A friend of mine said he believed that if one player is dealt four-of-a-kind (for instance), then the likelihood of another player having four-of-a-kind is increased - compared to if no other players had received a four-of-a-kind. Statistics isn't my strong point but this sort of makes sense given the pigeonhole principle - if one player gets AAAAKKKKQQQQJ , then I would think other players would have a higher likelihood of having four-of-a-kinds in their hand compared to if the one player was dealt AQKJ1098765432 . I wrote a Python program that performs a Monte Carlo evaluation to validate this theory, which found: The odds of exactly one player having a four-of-a-kind are ~12%. The odds of exactly two players having a four-of-a-kind are ~0.77%. The odds of exactly three players having a four-of-a-kind are ~0.03%. The odds of all four players having a four-of-a-kind are ~0.001%. But counter-intuitively, four-of-a-kind frequencies appear to decrease as more players are dealt those hands: The odds of two or more players having a four-of-a-kind when at least one player has four-of-a-kind are ~6.24%. The odds of three or more players having a four-of-a-kind when at least two players have four-of-a-kind are ~3.9%. The odds of all four players having a four-of-a-kind when at least three players have four-of-a-kind are ~1.39%. The result is non-intuitive and I'm all sorts of confused - not sure if my friend's hypothesis was incorrect, or if I'm asking my program the wrong questions.","Say a deck of cards is dealt out equally to four players (each player receives 13 cards). A friend of mine said he believed that if one player is dealt four-of-a-kind (for instance), then the likelihood of another player having four-of-a-kind is increased - compared to if no other players had received a four-of-a-kind. Statistics isn't my strong point but this sort of makes sense given the pigeonhole principle - if one player gets AAAAKKKKQQQQJ , then I would think other players would have a higher likelihood of having four-of-a-kinds in their hand compared to if the one player was dealt AQKJ1098765432 . I wrote a Python program that performs a Monte Carlo evaluation to validate this theory, which found: The odds of exactly one player having a four-of-a-kind are ~12%. The odds of exactly two players having a four-of-a-kind are ~0.77%. The odds of exactly three players having a four-of-a-kind are ~0.03%. The odds of all four players having a four-of-a-kind are ~0.001%. But counter-intuitively, four-of-a-kind frequencies appear to decrease as more players are dealt those hands: The odds of two or more players having a four-of-a-kind when at least one player has four-of-a-kind are ~6.24%. The odds of three or more players having a four-of-a-kind when at least two players have four-of-a-kind are ~3.9%. The odds of all four players having a four-of-a-kind when at least three players have four-of-a-kind are ~1.39%. The result is non-intuitive and I'm all sorts of confused - not sure if my friend's hypothesis was incorrect, or if I'm asking my program the wrong questions.",,"['statistics', 'python', 'poker']"
61,"If $T_1,T_2$ are two unbiased estimators, prove that $\rho(T_1,T_2) \geq \frac{2-\alpha}{\alpha}$.","If  are two unbiased estimators, prove that .","T_1,T_2 \rho(T_1,T_2) \geq \frac{2-\alpha}{\alpha}","Consider the following statement: Let $T_1,T_2$ be two unbiased estimators with common variance $\alpha \sigma^2$ , where $\sigma^2$ is the variance of the UMVUE. Show that that $\rho(T_1,T_2) \geq \frac{2-\alpha}{\alpha}$ , where $\rho$ is the correlation function. Now, clearly $\alpha >1,$ since $\operatorname{Var} (T_1) = \alpha \sigma^2$ must be larger than the UMVUE's variance, $\sigma^2.$ Now, I'm kind of lost on how to show that the statement is true. We can write \begin{align*} \rho(T_1,T_2) &= \frac{\operatorname{Cov}(T_1,T_2)}{\sqrt{\operatorname{Var(T_1)}} \sqrt{\operatorname{Var(T_2)}}}\\[0.3em] &= \frac{\operatorname{Cov}(T_1,T_2)}{\alpha \sigma^2}\\ \end{align*} Here we could write $\operatorname{Cov}(T_1,T_2) =\mathbb{E}(T_1 T_2) - \mathbb{E}(T_1) \mathbb{E}(T_2) $ where we know that $\mathbb{E}(T_1) =\mathbb{E}(T_2)= \theta$ , if $T_1$ and $T_2$ are estimators for the parameter $\theta$ (since they are unbiased estimators). However I don't see how that helps. I've tried to reduce algebraically to something simpler, but don't really get anywhere. If anyone could provide some guidance one how to proceed I would appreciate it very much.","Consider the following statement: Let be two unbiased estimators with common variance , where is the variance of the UMVUE. Show that that , where is the correlation function. Now, clearly since must be larger than the UMVUE's variance, Now, I'm kind of lost on how to show that the statement is true. We can write Here we could write where we know that , if and are estimators for the parameter (since they are unbiased estimators). However I don't see how that helps. I've tried to reduce algebraically to something simpler, but don't really get anywhere. If anyone could provide some guidance one how to proceed I would appreciate it very much.","T_1,T_2 \alpha \sigma^2 \sigma^2 \rho(T_1,T_2) \geq \frac{2-\alpha}{\alpha} \rho \alpha >1, \operatorname{Var} (T_1) = \alpha \sigma^2 \sigma^2. \begin{align*}
\rho(T_1,T_2) &= \frac{\operatorname{Cov}(T_1,T_2)}{\sqrt{\operatorname{Var(T_1)}} \sqrt{\operatorname{Var(T_2)}}}\\[0.3em]
&= \frac{\operatorname{Cov}(T_1,T_2)}{\alpha \sigma^2}\\
\end{align*} \operatorname{Cov}(T_1,T_2) =\mathbb{E}(T_1 T_2) - \mathbb{E}(T_1) \mathbb{E}(T_2)  \mathbb{E}(T_1) =\mathbb{E}(T_2)= \theta T_1 T_2 \theta",['statistics']
62,How to derive the sample size $n$ to achieve $P(\text{type 2 error}) = \beta$ for a two-tailed test?,How to derive the sample size  to achieve  for a two-tailed test?,n P(\text{type 2 error}) = \beta,"Consider testing $H_0 : \mu = \mu_0$ vs $H_a : \mu \neq \mu_0$ at level $\alpha$ . We then wish to control for the type II error, that is have $P(\text{type II error} \ | \ \mu = \mu_1) = \beta$ for a predetermined $\beta$ Assume $\bar{X}$ is approximately normal with mean $\mu$ and standard deviation $\sigma / \sqrt{n}$ . Base a hypothesis test on the standardized variable $Z = \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}$ , where $\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i$ Then the power function is $\gamma(\mu) = P(\text{reject} \ H_0 \ | \ \mu)  = P(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \geq -z_{\alpha/2} \ \text{or} \ \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \leq z_{\alpha/2} \ | \ \mu)$ $= P(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \geq -z_{\alpha/2} \ | \ \mu) + P(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \leq z_{\alpha/2} \ | \ \mu) = 1-\Phi(z_{\alpha/2} + \frac{\mu_0-\mu}{\sigma/\sqrt{n}}) + \Phi(-z_{\alpha/2} + \frac{\mu_0-\mu}{\sigma/\sqrt{n}})$ where we have solved the inequalities for $\bar{X}$ and restandardized with $\mu_1$ . Then, for $\mu_1 \neq \mu_0$ , $P(\text{type II error} \ | \ \mu=\mu_1) = P(\text{don't reject} \ H_0 \ | \ \mu=\mu_1)$ $=1 - P(\text{reject} \ H_0 \ | \ \mu=\mu_1) = 1 - (1-\Phi(z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}}) + \Phi(-z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}}))$ $= \Phi(z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}}) + \Phi(-z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}})$ $ = \beta$ How to solve this for $n$ ? The answer is supposed to be $n = \bigg(\frac{\sigma (z_{\alpha/2} + z_{\beta})}{\mu_0 - \mu_1}\bigg)^2$ (see Devore & Berk, Modern Mathematical Statistics with Applications, 2012: page 441) Sidenote: The way I solved it in the one-tailed case was simply by doing $\Phi(z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}}) = \beta$ $\Phi^{-1}\Phi(z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}}) = \Phi^{-1}\beta = -z_\beta$ , etc","Consider testing vs at level . We then wish to control for the type II error, that is have for a predetermined Assume is approximately normal with mean and standard deviation . Base a hypothesis test on the standardized variable , where Then the power function is where we have solved the inequalities for and restandardized with . Then, for , How to solve this for ? The answer is supposed to be (see Devore & Berk, Modern Mathematical Statistics with Applications, 2012: page 441) Sidenote: The way I solved it in the one-tailed case was simply by doing , etc","H_0 : \mu = \mu_0 H_a : \mu \neq \mu_0 \alpha P(\text{type II error} \ | \ \mu = \mu_1) = \beta \beta \bar{X} \mu \sigma / \sqrt{n} Z = \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \bar{X} = \frac{1}{n} \sum_{i=1}^n X_i \gamma(\mu) = P(\text{reject} \ H_0 \ | \ \mu) 
= P(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \geq -z_{\alpha/2} \ \text{or} \ \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \leq z_{\alpha/2} \ | \ \mu) = P(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \geq -z_{\alpha/2} \ | \ \mu) + P(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \leq z_{\alpha/2} \ | \ \mu) = 1-\Phi(z_{\alpha/2} + \frac{\mu_0-\mu}{\sigma/\sqrt{n}}) + \Phi(-z_{\alpha/2} + \frac{\mu_0-\mu}{\sigma/\sqrt{n}}) \bar{X} \mu_1 \mu_1 \neq \mu_0 P(\text{type II error} \ | \ \mu=\mu_1) = P(\text{don't reject} \ H_0 \ | \ \mu=\mu_1) =1 - P(\text{reject} \ H_0 \ | \ \mu=\mu_1) = 1 - (1-\Phi(z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}}) + \Phi(-z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}})) = \Phi(z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}}) + \Phi(-z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}})  = \beta n n = \bigg(\frac{\sigma (z_{\alpha/2} + z_{\beta})}{\mu_0 - \mu_1}\bigg)^2 \Phi(z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}}) = \beta \Phi^{-1}\Phi(z_{\alpha/2} + \frac{\mu_0-\mu_1}{\sigma/\sqrt{n}}) = \Phi^{-1}\beta = -z_\beta","['statistics', 'hypothesis-testing']"
63,CLT for maximum of random walk,CLT for maximum of random walk,,"Consider a symmetric random walk. Let $M_n = \max\{0,S_1,\cdots,S_n\}$ . I want to find $$\lim_{n\to\infty} Pr( M_n / \sqrt{n} \leq x) $$ I know how to calculate $Pr(M_n = m)$ and how it is connected to the $Pr(S_n = k)$ and I want to use it in my proof, but do not really now how. My best bet is using Central Limit theorem. Would appreciate if someone can help me with tying these two things together.","Consider a symmetric random walk. Let . I want to find I know how to calculate and how it is connected to the and I want to use it in my proof, but do not really now how. My best bet is using Central Limit theorem. Would appreciate if someone can help me with tying these two things together.","M_n = \max\{0,S_1,\cdots,S_n\} \lim_{n\to\infty} Pr( M_n / \sqrt{n} \leq x)  Pr(M_n = m) Pr(S_n = k)","['probability-theory', 'statistics', 'random-walk']"
64,Formula for calculating the odds per user of winning in a raffle each player can win once,Formula for calculating the odds per user of winning in a raffle each player can win once,,"Am trying to write a program which gives each user in a raffle contest their odds so far at winning. The rules of the game are simple: A predefined number of tickets are sold for example 1000 each user can at most buy 50 tickets and a user can only win once in the game after that all his tickets become invalid or pulled out and a new draw begins giving the other users a better chance of winning. The game will have 10 winners only. With the data collected from the software I would then know how many tickets were sold, the users that bought them and the amount of tickets that each user has. Now I just need a formula or pseudocode that would give each user their statistic probability of winning based on the data acquired, so that it be can used before and after each draw in the game to show each user their odds so far. I have looked at similar questions asked here, but no one seems to want to address the part that if a person wins the rest of their tickets become invalid. Am not good with probability or understand those fancy notations , so I don't understand is such a thing possible to calculate per user. Thanks for the help Update Testing my understanding of joriki second method: lets say 10 tickets were sold to 4 users each bought A: 1, B: 2, C: 4, D: 3  and there will be 3 prizes given to users. I calculated the total probability of being drawn for each user to be A = $\frac{1}{10} + \frac{2}{10}*\frac{1}{8}*\frac{1}{6} + \frac{4}{10}*\frac{1}{6}*\frac{1}{2} + \frac{3}{10}*\frac{1}{7}*\frac{1}{4}$ = 0.1482 B = $\frac{1}{10}*\frac{2}{9}*\frac{2}{8} + \frac{2}{10} + \frac{4}{10}*\frac{2}{6}*\frac{2}{2} + \frac{3}{10}*\frac{1}{7}*\frac{1}{4}$ = 0.3817 C= $\frac{1}{10}*\frac{4}{9}*\frac{4}{8} + \frac{2}{10}*\frac{4}{8}*\frac{4}{6} + \frac{4}{10} + \frac{3}{10}*\frac{4}{7}*\frac{4}{4}$ = 0.6603 D= $\frac{1}{10}*\frac{3}{9}*\frac{3}{8} + \frac{2}{10}*\frac{3}{8}*\frac{3}{6} + \frac{4}{10}*\frac{3}{6}*\frac{3}{2} + \frac{3}{10}$ = 0.6500 Their total sum is 1.8403 and not 3 ? also is this considered the total probability of being drawn for the 3 draws or just for the first round of the game with the tickets becoming invalid","Am trying to write a program which gives each user in a raffle contest their odds so far at winning. The rules of the game are simple: A predefined number of tickets are sold for example 1000 each user can at most buy 50 tickets and a user can only win once in the game after that all his tickets become invalid or pulled out and a new draw begins giving the other users a better chance of winning. The game will have 10 winners only. With the data collected from the software I would then know how many tickets were sold, the users that bought them and the amount of tickets that each user has. Now I just need a formula or pseudocode that would give each user their statistic probability of winning based on the data acquired, so that it be can used before and after each draw in the game to show each user their odds so far. I have looked at similar questions asked here, but no one seems to want to address the part that if a person wins the rest of their tickets become invalid. Am not good with probability or understand those fancy notations , so I don't understand is such a thing possible to calculate per user. Thanks for the help Update Testing my understanding of joriki second method: lets say 10 tickets were sold to 4 users each bought A: 1, B: 2, C: 4, D: 3  and there will be 3 prizes given to users. I calculated the total probability of being drawn for each user to be A = = 0.1482 B = = 0.3817 C= = 0.6603 D= = 0.6500 Their total sum is 1.8403 and not 3 ? also is this considered the total probability of being drawn for the 3 draws or just for the first round of the game with the tickets becoming invalid",\frac{1}{10} + \frac{2}{10}*\frac{1}{8}*\frac{1}{6} + \frac{4}{10}*\frac{1}{6}*\frac{1}{2} + \frac{3}{10}*\frac{1}{7}*\frac{1}{4} \frac{1}{10}*\frac{2}{9}*\frac{2}{8} + \frac{2}{10} + \frac{4}{10}*\frac{2}{6}*\frac{2}{2} + \frac{3}{10}*\frac{1}{7}*\frac{1}{4} \frac{1}{10}*\frac{4}{9}*\frac{4}{8} + \frac{2}{10}*\frac{4}{8}*\frac{4}{6} + \frac{4}{10} + \frac{3}{10}*\frac{4}{7}*\frac{4}{4} \frac{1}{10}*\frac{3}{9}*\frac{3}{8} + \frac{2}{10}*\frac{3}{8}*\frac{3}{6} + \frac{4}{10}*\frac{3}{6}*\frac{3}{2} + \frac{3}{10},"['probability', 'statistics']"
65,75th percentile of $e^x$,75th percentile of,e^x,"Let $f(x) = e^x$ on the interval $[0,2]$ and $0$ everywhere else. Calculate the 75th percentile of $f(x)$ . Attempt So normally I would take the integral from $\int_{- \infty }^{x} f(x)dx$ , equal it to $0.75$ and solve for $x$ . But $f(x)$ only exists between $0$ and $2$ , so I take the integral from $0$ to $x$ and equal it to $0.75$ . Solve for $x$ gives $$e^x - e^0 = 0.75$$ or $$x = \ln(1.75) = 0.560 ~ .$$ However my book says it's $4.48$ , I did some calculations and found that's equal to $e^{1.75}$ . So am I wrong? How could the percentile lie outside the interval?","Let on the interval and everywhere else. Calculate the 75th percentile of . Attempt So normally I would take the integral from , equal it to and solve for . But only exists between and , so I take the integral from to and equal it to . Solve for gives or However my book says it's , I did some calculations and found that's equal to . So am I wrong? How could the percentile lie outside the interval?","f(x) = e^x [0,2] 0 f(x) \int_{- \infty }^{x} f(x)dx 0.75 x f(x) 0 2 0 x 0.75 x e^x - e^0 = 0.75 x = \ln(1.75) = 0.560 ~ . 4.48 e^{1.75}",['statistics']
66,A family of probability measures is dominated by a $\sigma$-finite measure then it is dominated by a probability measure.,A family of probability measures is dominated by a -finite measure then it is dominated by a probability measure.,\sigma,"I am reading Jun Shao's Mathematical Statistics and I got stuck on the proof of this lemma: I understood the proof but to extend it from finite measure $\nu$ to a $\sigma$ -finite measure $\nu$ is not trivial for me. I have try to decompose $\nu$ as a countable sum of finite measures $\nu_i$ . But then, the family $\mathcal{P}$ is not dominated by $\nu_i$ . If someone could give me a correct idea, I would be very appreciated. Note: A measure $\mu$ is dominated by $\nu$ if $\mu$ is absolutely continuous with respect to $\nu$ . In other words, $\nu(E)=0$ implies $\mu(E)=0$ .","I am reading Jun Shao's Mathematical Statistics and I got stuck on the proof of this lemma: I understood the proof but to extend it from finite measure to a -finite measure is not trivial for me. I have try to decompose as a countable sum of finite measures . But then, the family is not dominated by . If someone could give me a correct idea, I would be very appreciated. Note: A measure is dominated by if is absolutely continuous with respect to . In other words, implies .",\nu \sigma \nu \nu \nu_i \mathcal{P} \nu_i \mu \nu \mu \nu \nu(E)=0 \mu(E)=0,"['statistics', 'measure-theory', 'proof-explanation']"
67,Covariance between sum of iid random variables and sum of indicator functions,Covariance between sum of iid random variables and sum of indicator functions,,"The question is- Let $X_1,X_2,..,X_n$ be iid random variables from a continuous distribution whose density is symmetric about $0$ . Suppose $\mathbb{E}(|X_1|)=2$ and define $Y=\sum_{i=1}^{n}X_i$ and $Z=\sum_{i=1}^{n}I(X_i>0)$ . Then calculate covariance between $Y$ and $Z$ . My attempt: $E(X_i)=0$ for all $i=1(1)n$ because $X$ is symmetric about $0$ and $E(|X|) $ exists. Now, $Cov (Y,Z)=E(YZ)-E(Y)E(Z)$ $=E(YZ)-0$ $=E[(\sum_{i=1}^{n}X_i)(\sum_{i=1}^{n}I(X_i>0)]$ $=(\sum_{i=1}^{n}E[(X_i.I(X_i>0))]$ $+\sum\sum_{i \neq j}E(X_i)E(I(X_j>0)$ as $X_i,X_j$ are independent. $=\sum_{i=1}^{n}E[(X_i.I(X_i>0)] +0 $ as $E(X_i)=0$ $ =\sum_{i=1}^{n}\{E[X_i.I(X_i>0)|I(X_i>0)=1]×1/2] + E[X_i.I(X_i>0)|I(X_i>0)=0]×1/2]\}$ $=\sum_{i=1}^{n}E[X_i.I(X_i>0)|I(X_i>0)=1]×1/2] +0$ $=\sum_{i=1}^{n}E[X_i|X_i>0]×1/2]$ $=2n×(1/2)$ $=n$ Is my reasoning correct ? Thanks in advance!","The question is- Let be iid random variables from a continuous distribution whose density is symmetric about . Suppose and define and . Then calculate covariance between and . My attempt: for all because is symmetric about and exists. Now, as are independent. as Is my reasoning correct ? Thanks in advance!","X_1,X_2,..,X_n 0 \mathbb{E}(|X_1|)=2 Y=\sum_{i=1}^{n}X_i Z=\sum_{i=1}^{n}I(X_i>0) Y Z E(X_i)=0 i=1(1)n X 0 E(|X|)  Cov (Y,Z)=E(YZ)-E(Y)E(Z) =E(YZ)-0 =E[(\sum_{i=1}^{n}X_i)(\sum_{i=1}^{n}I(X_i>0)] =(\sum_{i=1}^{n}E[(X_i.I(X_i>0))] +\sum\sum_{i \neq j}E(X_i)E(I(X_j>0) X_i,X_j =\sum_{i=1}^{n}E[(X_i.I(X_i>0)] +0  E(X_i)=0  =\sum_{i=1}^{n}\{E[X_i.I(X_i>0)|I(X_i>0)=1]×1/2] + E[X_i.I(X_i>0)|I(X_i>0)=0]×1/2]\} =\sum_{i=1}^{n}E[X_i.I(X_i>0)|I(X_i>0)=1]×1/2] +0 =\sum_{i=1}^{n}E[X_i|X_i>0]×1/2] =2n×(1/2) =n","['probability', 'statistics', 'expected-value', 'covariance']"
68,The MLE of distribution with pdf $f(x;\theta)=\frac{1}{2} e^{-|x-\theta|}$ [duplicate],The MLE of distribution with pdf  [duplicate],f(x;\theta)=\frac{1}{2} e^{-|x-\theta|},"This question already has answers here : Finding the maximum likelihood estimator (3 answers) Closed 4 years ago . I am given that the order statistics $X_{(1)}, ..., X_{(n)}$ are iid from a distribution with pdf $$f_X(x;\theta) = \frac{1}{2}e^{-|x-\theta|}, x\in \Bbb R, \theta\in \Bbb R$$ I approached with a likelihood function $$L(\theta) = 2^{-n}\exp\left[-\sum_{i=1}^n |X_i-\theta|\right]$$ and the log likelihood $$l(\theta) = -n \ln2-\sum_{i=1}^n |X_i-\theta|$$ I am not comfortable taking the derivative from here since the range of $X_i$ and $\theta$ does not let me guarantee that it will be $1$ or $-1$ and it also bothers me that the pdf is not the distribution of the order statistics that I am given. My ultimate goals is to do a likelihood ratio test where $$H_0: \theta = \theta_0 \quad vs \quad H_1: \theta \ne \theta_0$$ so that is why I am trying to find the MLE. My notes suggest that the median is the MLE but I have no idea why that would be true. I appreciate your input.",This question already has answers here : Finding the maximum likelihood estimator (3 answers) Closed 4 years ago . I am given that the order statistics are iid from a distribution with pdf I approached with a likelihood function and the log likelihood I am not comfortable taking the derivative from here since the range of and does not let me guarantee that it will be or and it also bothers me that the pdf is not the distribution of the order statistics that I am given. My ultimate goals is to do a likelihood ratio test where so that is why I am trying to find the MLE. My notes suggest that the median is the MLE but I have no idea why that would be true. I appreciate your input.,"X_{(1)}, ..., X_{(n)} f_X(x;\theta) = \frac{1}{2}e^{-|x-\theta|}, x\in \Bbb R, \theta\in \Bbb R L(\theta) = 2^{-n}\exp\left[-\sum_{i=1}^n |X_i-\theta|\right] l(\theta) = -n \ln2-\sum_{i=1}^n |X_i-\theta| X_i \theta 1 -1 H_0: \theta = \theta_0 \quad vs \quad H_1: \theta \ne \theta_0","['statistics', 'hypothesis-testing', 'maximum-likelihood']"
69,Computing Chi-Square p-value with large degree of freedom (df).,Computing Chi-Square p-value with large degree of freedom (df).,,"I'm using a Chi-square test on a large set of data points, so my degrees of freedom is rather large. So far, none of the online tables I've been able to find have options for $4095$ degrees of freedom. Is a chi-square test still applicable with this large of a dataset? Is there some way to find the p-value for $d.f. = 4065$ ?","I'm using a Chi-square test on a large set of data points, so my degrees of freedom is rather large. So far, none of the online tables I've been able to find have options for degrees of freedom. Is a chi-square test still applicable with this large of a dataset? Is there some way to find the p-value for ?",4095 d.f. = 4065,"['probability', 'statistics', 'chi-squared']"
70,Polynomial expansion (plus/minus trick in statistics),Polynomial expansion (plus/minus trick in statistics),,"Suppose the random variables $X_1, ..., X_n$ are independent and identically distributed. Let $\mu_x$ denote the expected value of $X$ , and let $\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$ . I often see the following plus/minus trick used in statistics, i.e. \begin{align*} \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2 &= \frac{1}{n}\sum_{i=1}^n(X_i - \mu_X + \mu_X - \bar{X})^2 \\ &= \frac{1}{n}\sum_{i=1}^n(X_i - \mu_x)^2 - (\bar{X} - \mu_x)^2\end{align*} Can someone formulate this into an identity for me? That is, something like $(a - b)^2 = (a - c + c - b)^2 = (a - c)^2 + (c - b)^2 + \text{some cross term}?$ What exactly is that cross term? On a similar token, I've also seen \begin{align*} \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y}) &= \frac{1}{n}\sum_{i=1}^n(X_i - \mu_X )(Y_i - \mu_Y) - (\bar{X} - \mu_x)(\bar{Y} - \mu_Y) \end{align*} What polynomial expansion identity is at play here?","Suppose the random variables are independent and identically distributed. Let denote the expected value of , and let . I often see the following plus/minus trick used in statistics, i.e. Can someone formulate this into an identity for me? That is, something like What exactly is that cross term? On a similar token, I've also seen What polynomial expansion identity is at play here?","X_1, ..., X_n \mu_x X \bar{X} = \frac{1}{n}\sum_{i=1}^n X_i \begin{align*} \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2 &= \frac{1}{n}\sum_{i=1}^n(X_i - \mu_X + \mu_X - \bar{X})^2 \\
&= \frac{1}{n}\sum_{i=1}^n(X_i - \mu_x)^2 - (\bar{X} - \mu_x)^2\end{align*} (a - b)^2 = (a - c + c - b)^2 = (a - c)^2 + (c - b)^2 + \text{some cross term}? \begin{align*} \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y}) &= \frac{1}{n}\sum_{i=1}^n(X_i - \mu_X )(Y_i - \mu_Y) - (\bar{X} - \mu_x)(\bar{Y} - \mu_Y) \end{align*}","['algebra-precalculus', 'statistics']"
71,Notation of inverse functions vs powers of minus one in probit function definition,Notation of inverse functions vs powers of minus one in probit function definition,,"The question arose after reading this Wikipedia article . $\Phi^{-1}(p)$ stands for probit, because it's inverse function of cumulative distribution function, which is traditionally $\Phi^{}(z)$ If I understood it right, it's not the power of minus one, but an inverse function. Thus, if you have a value of $z$ , you can obtain the probability with $\Phi(z)$ , but if you have the probability first, then you can obtain the $z$ with $\Phi^{-1}(p)$ . It has nothing with power function, just a weird notation (for me). Then I read this: $\operatorname{probit}(p)=\sqrt2\operatorname{erf}^{-1}(2p-1)$ And now I don't know, if this $\operatorname{erf}^{-1}(2p-1)$ notation is $1/\operatorname{erf}(2p-1)$ , or there is an inverse $\operatorname{erf}$ function. I haven't seen inverse $\operatorname{erf}$ function before, and there's no much sense in defining $\operatorname{probit}$ in terms of it. But my computations show that $1/\operatorname{erf}(2p-1)$ do not produce right values. Questions are: Is there's a general way to distinguish ""inverse function"" from ""power of minus one"" notation? What is the right definition of probit?","The question arose after reading this Wikipedia article . stands for probit, because it's inverse function of cumulative distribution function, which is traditionally If I understood it right, it's not the power of minus one, but an inverse function. Thus, if you have a value of , you can obtain the probability with , but if you have the probability first, then you can obtain the with . It has nothing with power function, just a weird notation (for me). Then I read this: And now I don't know, if this notation is , or there is an inverse function. I haven't seen inverse function before, and there's no much sense in defining in terms of it. But my computations show that do not produce right values. Questions are: Is there's a general way to distinguish ""inverse function"" from ""power of minus one"" notation? What is the right definition of probit?",\Phi^{-1}(p) \Phi^{}(z) z \Phi(z) z \Phi^{-1}(p) \operatorname{probit}(p)=\sqrt2\operatorname{erf}^{-1}(2p-1) \operatorname{erf}^{-1}(2p-1) 1/\operatorname{erf}(2p-1) \operatorname{erf} \operatorname{erf} \operatorname{probit} 1/\operatorname{erf}(2p-1),"['probability-theory', 'statistics', 'notation']"
72,Why are there two formulas for variance of random variables?,Why are there two formulas for variance of random variables?,,"I'm using an introductory statistics textbook and it mentioned this: Definition: If $X$ is a random variable with mean $E(X)  = \mu$ , then the variance  of $X$ is defined by $Var(X) = E((X−\mu)^2)$ . I thought the formula for the variance of X was: $$Var(X) = \sum_{i=1}^n p_i \cdot (x_i - μ)^2$$ How come it's different?","I'm using an introductory statistics textbook and it mentioned this: Definition: If is a random variable with mean , then the variance  of is defined by . I thought the formula for the variance of X was: How come it's different?",X E(X)  = \mu X Var(X) = E((X−\mu)^2) Var(X) = \sum_{i=1}^n p_i \cdot (x_i - μ)^2,"['probability-theory', 'statistics', 'random-variables', 'intuition', 'variance']"
73,Put trivariate PDF in terms of bivariate PDFs,Put trivariate PDF in terms of bivariate PDFs,,"Let there be the random variables $X$ , $Y$ , and $Z$ . Let all the bivariate PDFs $f_{X, Y}$ , $f_{X, Z}$ , and $f_{Y, Z}$ be known. Can we write the unknown trivariate PDF $f_{X, Y, Z}$ in terms of the known bivariate PDFs?","Let there be the random variables , , and . Let all the bivariate PDFs , , and be known. Can we write the unknown trivariate PDF in terms of the known bivariate PDFs?","X Y Z f_{X, Y} f_{X, Z} f_{Y, Z} f_{X, Y, Z}","['probability', 'statistics', 'probability-distributions']"
74,1st Yr Statistics Question: Create an approximate $\alpha$ level test of $H_0 : p_1 = p_2$,1st Yr Statistics Question: Create an approximate  level test of,\alpha H_0 : p_1 = p_2,"Let $X_1$ and $X_2$ be binomial random variables with respective parameters $n_1, p_1$ and $n_2, p_2$ . Show that when $n_1$ and $n_2$ are large, an approximate level $\alpha$ test of $H_0 : p_1 = p_2$ versus $H_1 : p_1 \neq p_2$ is as follows, reject $H_0$ if $$ \frac{|X_1/n_1-X_2/n_2|}{\sqrt{\frac{X_1+X_2}{n_1+n_2} \left( 1 - \frac{X_1+X_2}{n_1+n_2}\right) \left(\frac{1}{n_1}+\frac{1}{n_2}\right)}} > z_{\alpha/2} $$ Hint below in screenshot. My attempt Given $H_0$ is true I can say that $p = p_1 = p_2$ and since $n_1$ and $n_2$ are large, I can use the normal approximation to the binomial to say that $$ V = \frac{X_1 - n_1 p}{\sqrt{n_1 p q}} = \frac{ \frac{X_1}{n_1} - p}{\sqrt{\frac{p q}{n_1}}} \, \dot\sim \, N(0,1)$$ $$ W = \frac{X_2 - n_2 p}{\sqrt{n_2 p q}} = \frac{ \frac{X_2}{n_2} - p}{\sqrt{\frac{p q}{n_2}}} \, \dot\sim \, N(0,1)$$ Then we have $\frac{V-W}{\sqrt{2}} \dot\sim N(0,1)$ and we can build a two sided hypothesis using the fact that $$P \left( -z_{\alpha/2} \le \frac{V-W}{\sqrt{2}} \le z_{\alpha/2} \right) = 1-\alpha  $$ The book answer seems superior because you don't need to know $p_1$ or $p_2$ . However I'm having difficulty getting rid of those two values. Thanks for your help and patience! Book problem with hint","Let and be binomial random variables with respective parameters and . Show that when and are large, an approximate level test of versus is as follows, reject if Hint below in screenshot. My attempt Given is true I can say that and since and are large, I can use the normal approximation to the binomial to say that Then we have and we can build a two sided hypothesis using the fact that The book answer seems superior because you don't need to know or . However I'm having difficulty getting rid of those two values. Thanks for your help and patience! Book problem with hint","X_1 X_2 n_1, p_1 n_2, p_2 n_1 n_2 \alpha H_0 : p_1 = p_2 H_1 : p_1 \neq p_2 H_0  \frac{|X_1/n_1-X_2/n_2|}{\sqrt{\frac{X_1+X_2}{n_1+n_2} \left( 1 - \frac{X_1+X_2}{n_1+n_2}\right) \left(\frac{1}{n_1}+\frac{1}{n_2}\right)}} > z_{\alpha/2}  H_0 p = p_1 = p_2 n_1 n_2  V = \frac{X_1 - n_1 p}{\sqrt{n_1 p q}} = \frac{ \frac{X_1}{n_1} - p}{\sqrt{\frac{p q}{n_1}}} \, \dot\sim \, N(0,1)  W = \frac{X_2 - n_2 p}{\sqrt{n_2 p q}} = \frac{ \frac{X_2}{n_2} - p}{\sqrt{\frac{p q}{n_2}}} \, \dot\sim \, N(0,1) \frac{V-W}{\sqrt{2}} \dot\sim N(0,1) P \left( -z_{\alpha/2} \le \frac{V-W}{\sqrt{2}} \le z_{\alpha/2} \right) = 1-\alpha   p_1 p_2","['probability', 'statistics', 'binomial-distribution', 'hypothesis-testing']"
75,Why can the Kullback-Leibler information function be negative?,Why can the Kullback-Leibler information function be negative?,,"Let $\{ f(x, \theta) ; \theta \in \Theta  \}$ be a set of parametric density functions, $\Theta \subset \mathbb{R}$ . Let $N_\phi$ be a neighborhood of a point $\phi$ in $\Theta$ . The Kullback-Leibler information function for discriminating between $f(X; \theta)$ and $f(X; \phi'), \phi' \in N_{\phi}$ is $$I(\theta, N_{\phi}) = E_{\theta}\left[ \inf_{\phi' \in N_{\phi}} \log \frac{f(X;\theta)}{f(X; \phi')} \right]$$ I am told this quantity can even be negative (unlike the Kullback-Liebler divergence), what would be an example of this fact occuring?","Let be a set of parametric density functions, . Let be a neighborhood of a point in . The Kullback-Leibler information function for discriminating between and is I am told this quantity can even be negative (unlike the Kullback-Liebler divergence), what would be an example of this fact occuring?","\{ f(x, \theta) ; \theta \in \Theta  \} \Theta \subset \mathbb{R} N_\phi \phi \Theta f(X; \theta) f(X; \phi'), \phi' \in N_{\phi} I(\theta, N_{\phi}) = E_{\theta}\left[ \inf_{\phi' \in N_{\phi}} \log \frac{f(X;\theta)}{f(X; \phi')} \right]","['real-analysis', 'probability', 'statistics', 'optimization']"
76,Finding $L_n$ so that $\lim_{n \rightarrow \infty} P(L_n<\rho<1)=\alpha$,Finding  so that,L_n \lim_{n \rightarrow \infty} P(L_n<\rho<1)=\alpha,"Let $(X_1,Y_1),(X_2,Y_2),..,(X_n,Y_n)$ be iid pairs of random variables with $E(X_1)=E(Y_1)$ , $\text{Var}(X_1)=\text{Var}(Y_1)=1$ ,and $\text{cov}(X_1,Y_1)=\rho \in(-1,1)$ . Given $\alpha>0$ , obtain a statistic $L_n$ which is a function of $(X_1,Y_1),(X_2,Y_2),..,(X_n,Y_n)$ such that $\lim_{n \rightarrow \infty} P(L_n<\rho<1)=\alpha$ . Since the sample distribution of the correlation coefficient is quite hard  to work with I am really not being able to crack this one. Can anyone help?","Let be iid pairs of random variables with , ,and . Given , obtain a statistic which is a function of such that . Since the sample distribution of the correlation coefficient is quite hard  to work with I am really not being able to crack this one. Can anyone help?","(X_1,Y_1),(X_2,Y_2),..,(X_n,Y_n) E(X_1)=E(Y_1) \text{Var}(X_1)=\text{Var}(Y_1)=1 \text{cov}(X_1,Y_1)=\rho \in(-1,1) \alpha>0 L_n (X_1,Y_1),(X_2,Y_2),..,(X_n,Y_n) \lim_{n \rightarrow \infty} P(L_n<\rho<1)=\alpha","['probability-theory', 'statistics']"
77,"Moment estimator $\hat{\theta}$ of $\mathrm{Beta}(\theta,1)$ and bias of $\hat{\theta}$",Moment estimator  of  and bias of,"\hat{\theta} \mathrm{Beta}(\theta,1) \hat{\theta}","I'm trying to find the moment estimator for the density function $$f(y)=\theta y^{\theta-1}$$ and check whether this is biased. I know this is a $Beta(\theta,1)$ distribution and it looks like I only need to find the first moment in order to find the estimator. For $Y\sim \mathrm{Beta}(\theta,1)\implies\bar{Y}=\frac{\theta}{\theta+1}$ $$\theta\bar{Y}+\bar{Y}=\theta \implies \hat{\theta}=\frac{\bar{Y}}{1-\bar{Y}}$$ I'm pretty sure I've got that correct but I have no idea how to check whether this is biased or not. Finding the convolution isn't panning out too well and I can't seem to figure out a way to manipulate the expression in $\bar{Y}$ to give me anything to work with. Any pointers towards answering this would be greatly appreciated.",I'm trying to find the moment estimator for the density function and check whether this is biased. I know this is a distribution and it looks like I only need to find the first moment in order to find the estimator. For I'm pretty sure I've got that correct but I have no idea how to check whether this is biased or not. Finding the convolution isn't panning out too well and I can't seem to figure out a way to manipulate the expression in to give me anything to work with. Any pointers towards answering this would be greatly appreciated.,"f(y)=\theta y^{\theta-1} Beta(\theta,1) Y\sim \mathrm{Beta}(\theta,1)\implies\bar{Y}=\frac{\theta}{\theta+1} \theta\bar{Y}+\bar{Y}=\theta \implies \hat{\theta}=\frac{\bar{Y}}{1-\bar{Y}} \bar{Y}","['statistics', 'estimation', 'expected-value', 'parameter-estimation']"
78,Inequality regarding sample mean,Inequality regarding sample mean,,"I was looking at the book ""Asymptotic Theory of statistics and probability, DasGupta A., 2008"" and in one point of a proof they use an inequality which I have not been able to understand. Given that $X_i, i \in \{1,...,n\}$ are independent and identically distributed random variables, with mean $\mu$ , and with sample mean $\overline{X}_n $ , they state that $$ \sum_{i=1}^n |X_i - \overline{X}_n|^3 \leq 2³\left( \sum_{i=1}^n |X_i - \mu|^3  + n|\mu - \overline{X}_n|^3 \right)$$ I don't know how the 2³ term appears. I've tried adding and substracting $\mu$ but I have not been able to proof the inequality. It would be perfect if you could lend me a hand. Thanks","I was looking at the book ""Asymptotic Theory of statistics and probability, DasGupta A., 2008"" and in one point of a proof they use an inequality which I have not been able to understand. Given that are independent and identically distributed random variables, with mean , and with sample mean , they state that I don't know how the 2³ term appears. I've tried adding and substracting but I have not been able to proof the inequality. It would be perfect if you could lend me a hand. Thanks","X_i, i \in \{1,...,n\} \mu \overline{X}_n   \sum_{i=1}^n |X_i - \overline{X}_n|^3 \leq 2³\left( \sum_{i=1}^n |X_i - \mu|^3  + n|\mu - \overline{X}_n|^3 \right) \mu","['statistics', 'inequality', 'random-variables', 'means', 'bootstrap-sampling']"
79,How many possibilities can a 10x5 grid with somewhat even distribution produce?,How many possibilities can a 10x5 grid with somewhat even distribution produce?,,"Imagine a 10 x 5 grid where each square can be either 1 or 0. However, each row (10 squares) must contain five 1's and five 0's. Therefore, each grid (of 50 squares) has twenty five 1's and twenty five 0's but their distribution is somewhat controlled in that each row must contain five of each. How many possible combinations of grids can this produce?","Imagine a 10 x 5 grid where each square can be either 1 or 0. However, each row (10 squares) must contain five 1's and five 0's. Therefore, each grid (of 50 squares) has twenty five 1's and twenty five 0's but their distribution is somewhat controlled in that each row must contain five of each. How many possible combinations of grids can this produce?",,['statistics']
80,Proof $X_n\xrightarrow{D}X$ and $Y_n \xrightarrow{P}0$ then $X_n + Y_n \xrightarrow{D}X$,Proof  and  then,X_n\xrightarrow{D}X Y_n \xrightarrow{P}0 X_n + Y_n \xrightarrow{D}X,"I am having trouble proving this theorem. I know that I am given $$\lim_{n \rightarrow \infty }Pr[X_n<x] = Pr[X<x]$$ and $$\lim_{n \rightarrow \infty }Pr[|Y_n| > \epsilon] = 0, \quad\forall\epsilon>0$$ where I have to show that $$\lim_{n \rightarrow \infty }Pr[X_n+Y_n<t]=Pr[X<t] \qquad(1)$$ Editted: I know that I have to use the squeeze theorem, but I am not too strong in limit problems... I cannot use Slutsky's Theorem because I am actually trying to prove it.","I am having trouble proving this theorem. I know that I am given and where I have to show that Editted: I know that I have to use the squeeze theorem, but I am not too strong in limit problems... I cannot use Slutsky's Theorem because I am actually trying to prove it.","\lim_{n \rightarrow \infty }Pr[X_n<x] = Pr[X<x] \lim_{n \rightarrow \infty }Pr[|Y_n| > \epsilon] = 0, \quad\forall\epsilon>0 \lim_{n \rightarrow \infty }Pr[X_n+Y_n<t]=Pr[X<t] \qquad(1)",['statistics']
81,$\Bbb E(X\mid X^2)=X$,,\Bbb E(X\mid X^2)=X,Assume $X$ is exponential distribution. Is the following proof correct? $$\Bbb E(X\mid X^2)=X$$ This holds because $X$ is measurable in $\sigma\langle  X^2\rangle$$\left(X = \sqrt{X^2}\text{ because } X\ge 0\right)$ .,Assume is exponential distribution. Is the following proof correct? This holds because is measurable in .,X \Bbb E(X\mid X^2)=X X \sigma\langle  X^2\rangle\left(X = \sqrt{X^2}\text{ because } X\ge 0\right),"['probability', 'statistics', 'conditional-expectation', 'expected-value']"
82,"Convergence of power matrix $ (I-\nu P)^m \to (I-P), \ for \ m \to \infty, $ with $0 < \nu < 1$",Convergence of power matrix  with," (I-\nu P)^m \to (I-P), \ for \ m \to \infty,  0 < \nu < 1","Suppose $P$ is a $n \times n$ projection matrix with two eigenvalues equal to one. Is it true that and how can I show that $$ (I-\nu P)^m \to (I-P), \quad for \ m \to \infty, $$ with $0 < \nu < 1$ . My attempt: Let $P=ODO^T$ be an eigendecomposition with $OO^T=I$ and $D=diag(d_1, \dots, d_n)$ where $d_1=d_2=1$ and $d_k=0 \ (k=3, \dots, n)$ . Then $$ (I-\nu P)^m = O(I-\nu D)^mO^T=Odiag((1-\nu d_k)^m)O^T $$ For $k=1, 2$ , $(1-\nu d_k)^m \to 0$ and for $k=3, \dots, n$ , $(1-\nu d_k)^m = 1$ .  Since those are the eigenvalues of the orthogonal complement $I-P$ , the claim follows. Is my reasoning correct?","Suppose is a projection matrix with two eigenvalues equal to one. Is it true that and how can I show that with . My attempt: Let be an eigendecomposition with and where and . Then For , and for , .  Since those are the eigenvalues of the orthogonal complement , the claim follows. Is my reasoning correct?","P n \times n 
(I-\nu P)^m \to (I-P), \quad for \ m \to \infty,
 0 < \nu < 1 P=ODO^T OO^T=I D=diag(d_1, \dots, d_n) d_1=d_2=1 d_k=0 \ (k=3, \dots, n) 
(I-\nu P)^m = O(I-\nu D)^mO^T=Odiag((1-\nu d_k)^m)O^T
 k=1, 2 (1-\nu d_k)^m \to 0 k=3, \dots, n (1-\nu d_k)^m = 1 I-P","['linear-algebra', 'statistics', 'projective-space']"
83,What are the parameters of the sub-exponential distribution that is sub-Gaussian squared?,What are the parameters of the sub-exponential distribution that is sub-Gaussian squared?,,"I understand that the square of a sub-Gaussian is sub-exponential ( https://arxiv.org/pdf/1011.3027.pdf , Lemma 5.14) but it's not clear to me as to what the parameters of the sub-exponential are, given that the sub-Gaussian has parameter $\sigma$ . I know that a Gaussian with parameter $\sigma$ when squared yields a sub-exponential with parameters $(2\sigma^2,4\sigma^2)$ , would the same apply to a sub-Gaussian too?","I understand that the square of a sub-Gaussian is sub-exponential ( https://arxiv.org/pdf/1011.3027.pdf , Lemma 5.14) but it's not clear to me as to what the parameters of the sub-exponential are, given that the sub-Gaussian has parameter . I know that a Gaussian with parameter when squared yields a sub-exponential with parameters , would the same apply to a sub-Gaussian too?","\sigma \sigma (2\sigma^2,4\sigma^2)","['probability', 'statistics', 'probability-distributions']"
84,Poisson Distribution standard deviation,Poisson Distribution standard deviation,,"in a normal distribution, one standard deviation above and below the mean encompasses 68% of data. Can this also apply to Poisson distribution? in not, how can you tell how much of data falls between standard deviations for Poisson distribution? a reference to the answer would be great too. Thanks","in a normal distribution, one standard deviation above and below the mean encompasses 68% of data. Can this also apply to Poisson distribution? in not, how can you tell how much of data falls between standard deviations for Poisson distribution? a reference to the answer would be great too. Thanks",,"['statistics', 'probability-distributions']"
85,discrete version of normal distribution?,discrete version of normal distribution?,,"Just what the title says. I want to model probability of number of sales on a given day. I can't use poisson/binomial, because there are indications that the standard deviation of the sales might differ between two products with the same average number of sales. Is there a discrete version of normal distribution, or something like poisson distribution in which you can independently set the variance?","Just what the title says. I want to model probability of number of sales on a given day. I can't use poisson/binomial, because there are indications that the standard deviation of the sales might differ between two products with the same average number of sales. Is there a discrete version of normal distribution, or something like poisson distribution in which you can independently set the variance?",,"['statistics', 'probability-distributions']"
86,Show that $\max_{1\leq i\leq n}|X_i-\bar{X}| < \frac{(n-1)S}{\sqrt{n}}$,Show that,\max_{1\leq i\leq n}|X_i-\bar{X}| < \frac{(n-1)S}{\sqrt{n}},"Let $X_1, X_2,...,X_n$ be sample from some population. Show that $$\max_{1\leq i\leq n}|X_i-\bar{X}| < \dfrac{(n-1)S}{\sqrt{n}}$$ Simplifying the inequality, I found, to prove: $$n\max_{1\leq i\leq n}(X_i-\bar{X})^2 < (n-1)\sum_{i=1}^n (X_i-\bar{X})^2$$ or more generally, we need to prove, $n\cdot\max_{1\leq i\leq n}Y_i^2 < (n-1) \sum_{i=1}^n Y_i^2$ I am stuck here. Any help appreciated.","Let be sample from some population. Show that Simplifying the inequality, I found, to prove: or more generally, we need to prove, I am stuck here. Any help appreciated.","X_1, X_2,...,X_n \max_{1\leq i\leq n}|X_i-\bar{X}| < \dfrac{(n-1)S}{\sqrt{n}} n\max_{1\leq i\leq n}(X_i-\bar{X})^2 < (n-1)\sum_{i=1}^n (X_i-\bar{X})^2 n\cdot\max_{1\leq i\leq n}Y_i^2 < (n-1) \sum_{i=1}^n Y_i^2","['statistics', 'inequality']"
87,Question about the sum of xi minus x bar square?,Question about the sum of xi minus x bar square?,,Im looking through my notes in class and see that it is written that $$S = \sqrt{\frac{1}{n-1}\sum(X_i - \bar{X})^2} $$ which is then equal to $$S = \sqrt{\frac{1}{n-1}\left(\sum X_i ^2 - n*\bar{X}^2\right)} $$ how is this possible?  I tried expanding but don't see how it works,Im looking through my notes in class and see that it is written that which is then equal to how is this possible?  I tried expanding but don't see how it works,S = \sqrt{\frac{1}{n-1}\sum(X_i - \bar{X})^2}  S = \sqrt{\frac{1}{n-1}\left(\sum X_i ^2 - n*\bar{X}^2\right)} ,"['calculus', 'statistics']"
88,"Use the Central Limit Theorem to deduce that if $λ$ is large, then $X$ approximately has a normal distribution.","Use the Central Limit Theorem to deduce that if  is large, then  approximately has a normal distribution.",λ X,"The time instants of incoming requests at a data server can be modelled with a Poisson process. Let $X$ be the number of requests in one hour and let $λ$ be the intensity (requests per hour) of the Poisson process. - Use the Central Limit Theorem to deduce that if $λ$ is large, then $X$ approximately has a normal distribution. Also specify its parameters. Can I assume that, if $X\sim\operatorname{Poisson}(\lambda)$ then: $$ \frac{X-\lambda}{\sqrt\lambda} \overset{\text{distribution}}\longrightarrow N(0,1) \text{ as } \lambda\to\infty \\  $$ It is a correct way to prove it? The parameters for the normal distribution are $\mu=0$ and $\sigma^2=1$ right?","The time instants of incoming requests at a data server can be modelled with a Poisson process. Let be the number of requests in one hour and let be the intensity (requests per hour) of the Poisson process. - Use the Central Limit Theorem to deduce that if is large, then approximately has a normal distribution. Also specify its parameters. Can I assume that, if then: It is a correct way to prove it? The parameters for the normal distribution are and right?","X λ λ X X\sim\operatorname{Poisson}(\lambda) 
\frac{X-\lambda}{\sqrt\lambda} \overset{\text{distribution}}\longrightarrow N(0,1) \text{ as } \lambda\to\infty \\   \mu=0 \sigma^2=1",['statistics']
89,Calculating UMVUE for Poisson distribution,Calculating UMVUE for Poisson distribution,,I've started to learn methods of finding UMVUE distribution. I found some nice examples on this site . I got stuck while evaluating UMVUE for Poisson distribution for a parametric function $g(\theta)$ . How did the author get $$\sum_{t=o}^\infty \frac{h(t) n^t}{t!} \theta^t = e^{n \theta}g(\theta)?$$ I thought $$\mathbb{E}(h(x)) = g(\theta)$$ should be considered.,I've started to learn methods of finding UMVUE distribution. I found some nice examples on this site . I got stuck while evaluating UMVUE for Poisson distribution for a parametric function . How did the author get I thought should be considered.,g(\theta) \sum_{t=o}^\infty \frac{h(t) n^t}{t!} \theta^t = e^{n \theta}g(\theta)? \mathbb{E}(h(x)) = g(\theta),"['statistics', 'parameter-estimation']"
90,Does a zero conditional expectation imply pairwise covariance is 0?,Does a zero conditional expectation imply pairwise covariance is 0?,,"Suppose in econometrics, $$ y = \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2} + ... + \beta_{k}x_{k} + u$$ In Gujarati's book, it says that the following equation (1) $$ E[u | x_{1}, x_{2},..., x_{k}] = E[u] = 0 \tag{1}$$ given that $$ x_{1}, x_{2},..., x_{k}$$ are independent from each other implies (with bilinearity property of covariance) $$ Cov(u, x_{1} + x_{2} + ... +x_{k}) = cov(u, x_{1}) = cov(u, x_{2}) = ... = cov(u,x_{k}) = 0$$ How can we derive this result? Book's content: Thank you very much.","Suppose in econometrics, In Gujarati's book, it says that the following equation (1) given that are independent from each other implies (with bilinearity property of covariance) How can we derive this result? Book's content: Thank you very much."," y = \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2} + ... + \beta_{k}x_{k} + u  E[u | x_{1}, x_{2},..., x_{k}] = E[u] = 0 \tag{1}  x_{1}, x_{2},..., x_{k}  Cov(u, x_{1} + x_{2} + ... +x_{k}) = cov(u, x_{1}) = cov(u, x_{2}) = ... = cov(u,x_{k}) = 0","['statistics', 'statistical-inference', 'conditional-expectation', 'conditional-probability', 'covariance']"
91,Line Of Best Fit With Perpendicular Error,Line Of Best Fit With Perpendicular Error,,"The standard statistical formula for the least squares error gives us a line that minimises the sum of the vertical distances of the sample points to the line. Suppose that I wanted to find the equation of a line that minimises the sum of the perpendicular distance of the points to the line, is there a way of analytically solving this problem?","The standard statistical formula for the least squares error gives us a line that minimises the sum of the vertical distances of the sample points to the line. Suppose that I wanted to find the equation of a line that minimises the sum of the perpendicular distance of the points to the line, is there a way of analytically solving this problem?",,"['geometry', 'statistics', 'regression']"
92,Probability that a loss occurs to a randomly chosen customer of an insurance company - is my solution correct?,Probability that a loss occurs to a randomly chosen customer of an insurance company - is my solution correct?,,"An insurance company divides its customers into different risk groups. Suppose that 60% of the customers are in group A (low risk), 30% are in group B (medium risk) and 10% are in group C (high risk). The probabilities of loss occurence for customers in the different groups are as follows: Group A: 0.1 Group B: 0.25 Group C: 0.74 Calculate the probability that a loss occurs to a randomly chosen customer of the insurance company. So first, lets start by noting what we already have (L - occurrence of loss): P(A) = 0.6 given P(B) = 0.3 given P(C) = 0.1 given P(L|A) = 0.1 given => P(L $^c$ |A) = 1- 0.1 = 0.9 P(L|B) = 0.25 given => P(L $^c$ |B) = 1 - 0.25 = 0.75 P(L|C) = 0.74 given => P(L $^c$ |C) = 1 - 0.74 = 0.26 I'm not sure exactly whether the rule of total probability should be applied here to find the P(L) and if the rule of total probability is needed here, I'm rather confused as to how to calculate it with 3 different events? (A,B & C). Hence, what I tried is: P(L) = 1 - P(L $^c$ ) - event that no loss occurs for anyone P(L $^c$ ) = P(L $^c$ |A)*P(A)*P(L $^c$ |B)*P(B)*P(L $^c$ |C)*P(C) = 0.9*0.6*0.75*0.3*0.26*0.1 = 0.003159 the chance that no loss occurs to anyone From here it follows that: P(L) = 1 - 0.003159 = 0.996841 chance that loss occurs to a randomly chcosen customer of the company So am I completely wrong or did I correctly solve this? I don't have a solution with which to compare it, hence, I'm asking you, so thank you in advance for your time! Any insights are much appreciated!","An insurance company divides its customers into different risk groups. Suppose that 60% of the customers are in group A (low risk), 30% are in group B (medium risk) and 10% are in group C (high risk). The probabilities of loss occurence for customers in the different groups are as follows: Group A: 0.1 Group B: 0.25 Group C: 0.74 Calculate the probability that a loss occurs to a randomly chosen customer of the insurance company. So first, lets start by noting what we already have (L - occurrence of loss): P(A) = 0.6 given P(B) = 0.3 given P(C) = 0.1 given P(L|A) = 0.1 given => P(L |A) = 1- 0.1 = 0.9 P(L|B) = 0.25 given => P(L |B) = 1 - 0.25 = 0.75 P(L|C) = 0.74 given => P(L |C) = 1 - 0.74 = 0.26 I'm not sure exactly whether the rule of total probability should be applied here to find the P(L) and if the rule of total probability is needed here, I'm rather confused as to how to calculate it with 3 different events? (A,B & C). Hence, what I tried is: P(L) = 1 - P(L ) - event that no loss occurs for anyone P(L ) = P(L |A)*P(A)*P(L |B)*P(B)*P(L |C)*P(C) = 0.9*0.6*0.75*0.3*0.26*0.1 = 0.003159 the chance that no loss occurs to anyone From here it follows that: P(L) = 1 - 0.003159 = 0.996841 chance that loss occurs to a randomly chcosen customer of the company So am I completely wrong or did I correctly solve this? I don't have a solution with which to compare it, hence, I'm asking you, so thank you in advance for your time! Any insights are much appreciated!",^c ^c ^c ^c ^c ^c ^c ^c,"['probability', 'statistics']"
93,"How to solve E($2X $| Y)? Where $f(x,y) = 4e^{-2y}$",How to solve E(| Y)? Where,"2X  f(x,y) = 4e^{-2y}","Help, please! How to solve: $E(2X| Y) = ?$ $$f(x,y) = 4e^{-2y}\;,0 < x<y \mbox{ and }\; y>0.$$ After integrating $f(x,y)$ over domain of $y$ we get marginal density of $X$ : $$f_X(x) = 2e^{-2x} \;,\;x>0$$ Similarly, marginal density of $Y$ $$f_Y(y) = 4ye^{-2y}\;,y>0$$ Then I found out the distribution of $2X$ using Jacobian Theorem as $$f_U(u) = e^{-u}\;,u>0$$ How to calculate $E(2X| Y)$ ?","Help, please! How to solve: After integrating over domain of we get marginal density of : Similarly, marginal density of Then I found out the distribution of using Jacobian Theorem as How to calculate ?","E(2X| Y) = ? f(x,y) = 4e^{-2y}\;,0 < x<y \mbox{ and }\; y>0. f(x,y) y X f_X(x) = 2e^{-2x} \;,\;x>0 Y f_Y(y) = 4ye^{-2y}\;,y>0 2X f_U(u) = e^{-u}\;,u>0 E(2X| Y)","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'conditional-expectation']"
94,let's play a (continuous) probability game!,let's play a (continuous) probability game!,,"Here's the description of the game. We have a target number $x$ in mind and start by picking a number $c_1$ uniformly at random from $(0, 1)$ . Then $c_2$ is picked uniformly at random from $(0, c_1)$ , and in general, $c_i$ is picked uniformly at random from $(0, c_{i -1})$ . The game stops when we pick a $c_i$ such that $c_i < x$ . What is the expected number of times we'll have to pick a number $c_i$ ? Alternatively, what is the expected length of the sequence of $c_i$ 's? I am guessing that the solution will be in terms of our target $x$ . How would one go about approaching this problem? I thought about conditioning in terms of $c_1$ , but I couldn't work it out. Edit: we have $x \in (0, 1)$ . Edit 2: I am not hell-bent on using a conditional expectation approach. But if there exists some ridiculously simple solution, I am guessing it would involve it.","Here's the description of the game. We have a target number in mind and start by picking a number uniformly at random from . Then is picked uniformly at random from , and in general, is picked uniformly at random from . The game stops when we pick a such that . What is the expected number of times we'll have to pick a number ? Alternatively, what is the expected length of the sequence of 's? I am guessing that the solution will be in terms of our target . How would one go about approaching this problem? I thought about conditioning in terms of , but I couldn't work it out. Edit: we have . Edit 2: I am not hell-bent on using a conditional expectation approach. But if there exists some ridiculously simple solution, I am guessing it would involve it.","x c_1 (0, 1) c_2 (0, c_1) c_i (0, c_{i -1}) c_i c_i < x c_i c_i x c_1 x \in (0, 1)","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'conditional-probability']"
95,Bias Variance Decomposition for KL Divergence,Bias Variance Decomposition for KL Divergence,,"While studying a slide deck, I encountered the following exercise: We are to give a bias variance decomposition when the prediction is given as a probability distribution over $C$ classes. Let $P = [P_1, . . . , P_C ]$ be the ground truth class distribution associated to a particular input pattern. Assume the random estimator of class probabilities $$\bar{{P}} = [\bar{{P}}_1, . . . , \bar{{P}}_C ] $$ for the same input pattern. The error function is given by the KL-divergence between the ground truth and the estimated probability distribution: $$\text{Error} = E[D_{KL}(P||\bar{{P}})]$$ First, we would like to determine the mean of the class distribution estimator $\bar{{P}}$ . We define the mean as the distribution that minimizes its expected KL divergence from the class distribution estimator, that is, the distribution $R$ that optimizes $$\begin{matrix}\min\\R \end{matrix} \space E[ D_{KL}(R||\bar{{P}})]$$ I have found a way to proof that this is: $$ R = [R_1, . . . , R_C ] $$ $$ \text{where} \space\space R_i = \frac{{\exp\space E[\log \bar{P_i} ]}}{{\sum_j\exp\space E[\log \bar{P_j}]}}  \space \space \space ∀ \space 1 ≤ i ≤ C.$$ We are now asked to proof that: $$ Error(\hat{P}) = Bias(\hat{P}) + Var(\hat{P}) $$ where $$Error(\hat{P}) = E[D_{KL}(P || \hat{P})$$ $$Bias(\hat{P}) = D_{KL}(P || R)$$ $$Var(\hat{P}) = E[D_{KL}(R || \hat{P})$$ I started by writing out the KL Divergence: $$Bias(\hat{P}) + Var(\hat{P}) = \sum_{i=1}^{C} \left (P_i \log \left (\frac{P_i}{R_i} \right ) \right) + E \left [ \sum_{i=1}^{c} \left (R_i \log \left (\frac{R_i}{\hat{P}_i} \right ) \right ) \right ]$$ But I don't know how to continue from here on.","While studying a slide deck, I encountered the following exercise: We are to give a bias variance decomposition when the prediction is given as a probability distribution over classes. Let be the ground truth class distribution associated to a particular input pattern. Assume the random estimator of class probabilities for the same input pattern. The error function is given by the KL-divergence between the ground truth and the estimated probability distribution: First, we would like to determine the mean of the class distribution estimator . We define the mean as the distribution that minimizes its expected KL divergence from the class distribution estimator, that is, the distribution that optimizes I have found a way to proof that this is: We are now asked to proof that: where I started by writing out the KL Divergence: But I don't know how to continue from here on.","C P = [P_1, . . . , P_C ] \bar{{P}} = [\bar{{P}}_1, . . . , \bar{{P}}_C ]  \text{Error} = E[D_{KL}(P||\bar{{P}})] \bar{{P}} R \begin{matrix}\min\\R \end{matrix} \space E[ D_{KL}(R||\bar{{P}})]  R = [R_1, . . . , R_C ]   \text{where} \space\space R_i = \frac{{\exp\space E[\log \bar{P_i} ]}}{{\sum_j\exp\space E[\log \bar{P_j}]}}  \space \space \space ∀ \space 1 ≤ i ≤ C.  Error(\hat{P}) = Bias(\hat{P}) + Var(\hat{P})  Error(\hat{P}) = E[D_{KL}(P || \hat{P}) Bias(\hat{P}) = D_{KL}(P || R) Var(\hat{P}) = E[D_{KL}(R || \hat{P}) Bias(\hat{P}) + Var(\hat{P}) = \sum_{i=1}^{C} \left (P_i \log \left (\frac{P_i}{R_i} \right ) \right) + E \left [ \sum_{i=1}^{c} \left (R_i \log \left (\frac{R_i}{\hat{P}_i} \right ) \right ) \right ]","['statistics', 'variance']"
96,Finding the probability of two random variables being equal to 1,Finding the probability of two random variables being equal to 1,,"Question: A die is thrown $n+2$ times. After each throw a ' $+$ ' is recorded for $4$ , $5$ , or $6$ and ' $-$ ' for $1$ , $2$ , or $3$ , the signs forming an ordered sequence. To each, except the first and the last sign, is attached a characteristic random variable which takes the value $1$ if both the neighboring signs differ from the one between them and $0$ otherwise. If $X_1, X_2, \ldots , X_n$ are the characteristic random variables, find the mean and variance of $X = \sum_{i=1}^n X_i$ Problematic part: $$ V(X) = V(X_1+X_2+\cdots+X_n) = \sum_{i=1}^n V(X_i) +2\sum_{i=1}^n\sum_{j=1, j>i}^n Cov(X_i,X_j) $$ Calculating the variance of $X$ requires calculating the covariance of two arbitrarily chosen random variables $X_i$ and $X_j$ . The formula then used is $Cov(X_i,X_j) = E(X_iX_j) - E(X_i)E(X_j)$ Which brings us to the essence of my problem -- How to find $E(X_iX_j)$ ? It is certain that $X_iX_j$ can take only two values, namely, $0$ and $1$ . Therefore $E(X_iX_j) = 1.P(X_iX_j=1) + 0.P(X_iX_j=0)= P(X_iX_j=1)$ But at this point I'm not sure how to compute the probability. The book I'm using says the probability is $1/8$ , but I can't seem to wrap my head around the reasoning. An intuitive explanation would be highly appreciated!","Question: A die is thrown times. After each throw a ' ' is recorded for , , or and ' ' for , , or , the signs forming an ordered sequence. To each, except the first and the last sign, is attached a characteristic random variable which takes the value if both the neighboring signs differ from the one between them and otherwise. If are the characteristic random variables, find the mean and variance of Problematic part: Calculating the variance of requires calculating the covariance of two arbitrarily chosen random variables and . The formula then used is Which brings us to the essence of my problem -- How to find ? It is certain that can take only two values, namely, and . Therefore But at this point I'm not sure how to compute the probability. The book I'm using says the probability is , but I can't seem to wrap my head around the reasoning. An intuitive explanation would be highly appreciated!","n+2 + 4 5 6 - 1 2 3 1 0 X_1, X_2, \ldots , X_n X = \sum_{i=1}^n X_i  V(X) = V(X_1+X_2+\cdots+X_n) = \sum_{i=1}^n V(X_i) +2\sum_{i=1}^n\sum_{j=1, j>i}^n Cov(X_i,X_j)  X X_i X_j Cov(X_i,X_j) = E(X_iX_j) - E(X_i)E(X_j) E(X_iX_j) X_iX_j 0 1 E(X_iX_j) = 1.P(X_iX_j=1) + 0.P(X_iX_j=0)= P(X_iX_j=1) 1/8","['probability', 'statistics', 'random-variables', 'covariance', 'expected-value']"
97,mean vs median geometric interpretation?,mean vs median geometric interpretation?,,"I'm looking at this picture on wikipedia, comparing the median and mean of an arbitrary distribution. But what does it mean exactly? From the figure, it looks like the mean is the center of mass of the distribution (in the sense that you could balance the distribution on that point). However, since the median has $50\%$ to its left and right, it seems a more reasonable candidate for the center of mass. Which one is it? And what is the geometric interpretation of the other metric?","I'm looking at this picture on wikipedia, comparing the median and mean of an arbitrary distribution. But what does it mean exactly? From the figure, it looks like the mean is the center of mass of the distribution (in the sense that you could balance the distribution on that point). However, since the median has to its left and right, it seems a more reasonable candidate for the center of mass. Which one is it? And what is the geometric interpretation of the other metric?",50\%,"['statistics', 'means', 'median']"
98,Why are independence and mean-zero necessary for the symmetrization lemma to hold?,Why are independence and mean-zero necessary for the symmetrization lemma to hold?,,"I'm going through the proof of the symmetrization lemma (Vershynin), which says $$ \frac{1}{2} E \left\| \sum_i \epsilon_i X_i \right\| \leq E \left\| \sum_i X_i \right\| \leq 2 E \left\| \sum_i \epsilon_i X_i \right\| $$ where $X_1,\ldots,X_N$ are independent mean-zero random vectors in a normed space. The $\epsilon_i$ 's are i.i.d taking on $1$ or $-1$ with equal probability. However, I don't see why independence or the mean-zero assumption is required anywhere for this to hold because the steps in the proof below don't seem to use either assumption. ==================== Anyone know why this is? References: Vershynin, Roman , High-dimensional probability. An introduction with applications in data science (to appear), ZBL06872475 .","I'm going through the proof of the symmetrization lemma (Vershynin), which says where are independent mean-zero random vectors in a normed space. The 's are i.i.d taking on or with equal probability. However, I don't see why independence or the mean-zero assumption is required anywhere for this to hold because the steps in the proof below don't seem to use either assumption. ==================== Anyone know why this is? References: Vershynin, Roman , High-dimensional probability. An introduction with applications in data science (to appear), ZBL06872475 ."," \frac{1}{2} E \left\| \sum_i \epsilon_i X_i \right\| \leq E \left\| \sum_i X_i \right\| \leq 2 E \left\| \sum_i \epsilon_i X_i \right\|  X_1,\ldots,X_N \epsilon_i 1 -1","['statistics', 'random-matrices', 'empirical-processes']"
99,"Why does bootstrapping approach the distribution of estimator, not mean of the estimator with normal distribution?","Why does bootstrapping approach the distribution of estimator, not mean of the estimator with normal distribution?",,"The wiki page ( https://en.wikipedia.org/wiki/Bootstrapping_(statistics) ) sated that bootstrapping allow one to compute and estimate the approximate distribution of the estimator. But why does bootstrapping approach the distribution of estimator, not mean of the estimator with normal distribution? Suppose one resample the data of size $N$ for $100000$ times and compute the estimator every time, why does the distribution of the computed estimator not approach normal distribution?","The wiki page ( https://en.wikipedia.org/wiki/Bootstrapping_(statistics) ) sated that bootstrapping allow one to compute and estimate the approximate distribution of the estimator. But why does bootstrapping approach the distribution of estimator, not mean of the estimator with normal distribution? Suppose one resample the data of size for times and compute the estimator every time, why does the distribution of the computed estimator not approach normal distribution?",N 100000,"['statistics', 'bootstrap-sampling']"
