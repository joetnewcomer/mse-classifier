,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Uniform limit of injective analytic functions is injective,Uniform limit of injective analytic functions is injective,,"I'm stuck on the following problem: Let $f_n$ be a sequence of injective analytic functions on the unit disc $D$ such that $f_n$ converges uniformly to $f$ on compact subsets of $D$.  Show that $f$ is either injective or constant. Already $f$ is analytic as an almost uniform limit.  If $f'$ is identically zero, then $f$ is constant.  Otherwise $f'$ has isolated zeroes.  If $c$ is such an isolated zero, then $f_n'$ converges uniformly to $f'$ on a small disc near $c$.  By Hurwitz's theorem, for almost all $n$ the functions $f_n'$ should also have a zero in that small disc. But an analytic function is locally injective at a point if and only if its derivative at the point is nonzero.  And injective implies locally injective.  So the $f_n'$ shouldn't have any zeros in $D$. So, we can at least conclude that $f'$ is never zero on $D$.  This shows that $f$ is locally injective.  Is there an easy way to conclude injectivity from local injectivity here?","I'm stuck on the following problem: Let $f_n$ be a sequence of injective analytic functions on the unit disc $D$ such that $f_n$ converges uniformly to $f$ on compact subsets of $D$.  Show that $f$ is either injective or constant. Already $f$ is analytic as an almost uniform limit.  If $f'$ is identically zero, then $f$ is constant.  Otherwise $f'$ has isolated zeroes.  If $c$ is such an isolated zero, then $f_n'$ converges uniformly to $f'$ on a small disc near $c$.  By Hurwitz's theorem, for almost all $n$ the functions $f_n'$ should also have a zero in that small disc. But an analytic function is locally injective at a point if and only if its derivative at the point is nonzero.  And injective implies locally injective.  So the $f_n'$ shouldn't have any zeros in $D$. So, we can at least conclude that $f'$ is never zero on $D$.  This shows that $f$ is locally injective.  Is there an easy way to conclude injectivity from local injectivity here?",,['complex-analysis']
1,contour integral with singularity on the contour,contour integral with singularity on the contour,,"I want to compute the following integral  $$\oint_{|z|=1}\frac{\exp \left (\frac{1}{z} \right)}{z^2-1}\,dz$$ The integrand has essential singularity at the origin, and $2$-poles at $\pm 1$,which lie on the curve $|z|=1$ so I can't apply residue formula. How can I proceed?","I want to compute the following integral  $$\oint_{|z|=1}\frac{\exp \left (\frac{1}{z} \right)}{z^2-1}\,dz$$ The integrand has essential singularity at the origin, and $2$-poles at $\pm 1$,which lie on the curve $|z|=1$ so I can't apply residue formula. How can I proceed?",,"['complex-analysis', 'contour-integration', 'cauchy-principal-value']"
2,Elliptic functions as inverses of Elliptic integrals,Elliptic functions as inverses of Elliptic integrals,,"Let us begin with some (standard, I think) definitions. Def: An elliptic function is a doubly periodic meromorphic function on $\mathbb{C}$. Def: An elliptic integral is an integral of the form $$f(x) = \int_{a}^x R\left(t,\sqrt{P(t)}\right)\ dt,$$ where $R$ is a rational fucntion of its arguments and where $P(t)$ is a third or fourth degree polynomial with simple roots. I have often heard the claim that an elliptic function is (or can be) defined as the inverse of an elliptic integral. However, I have never seen a proof of this statement. As someone who is largely unfamiliar with the subject, most of the references I could dig up seem to refer to the special case of the Jacobi elliptic functions, which appear as inverse functions of the elliptic integrals of the first kind. Maybe the claim I'm referring to is simply talking about the special case of Jacobi elliptic functions, but I believe the statement holds in generality (I could be wrong). So, can anyone provide a proof or reference (or counter-example) to something akin to the following? Claim: The elliptic functions are precisely the inverses of the elliptic integrals, as I've defined them above. That is, every elliptic function arises as the inverse of some elliptic integral, and conversely every elliptic integral arises as the inverse of some elliptic function.","Let us begin with some (standard, I think) definitions. Def: An elliptic function is a doubly periodic meromorphic function on $\mathbb{C}$. Def: An elliptic integral is an integral of the form $$f(x) = \int_{a}^x R\left(t,\sqrt{P(t)}\right)\ dt,$$ where $R$ is a rational fucntion of its arguments and where $P(t)$ is a third or fourth degree polynomial with simple roots. I have often heard the claim that an elliptic function is (or can be) defined as the inverse of an elliptic integral. However, I have never seen a proof of this statement. As someone who is largely unfamiliar with the subject, most of the references I could dig up seem to refer to the special case of the Jacobi elliptic functions, which appear as inverse functions of the elliptic integrals of the first kind. Maybe the claim I'm referring to is simply talking about the special case of Jacobi elliptic functions, but I believe the statement holds in generality (I could be wrong). So, can anyone provide a proof or reference (or counter-example) to something akin to the following? Claim: The elliptic functions are precisely the inverses of the elliptic integrals, as I've defined them above. That is, every elliptic function arises as the inverse of some elliptic integral, and conversely every elliptic integral arises as the inverse of some elliptic function.",,"['complex-analysis', 'special-functions', 'elliptic-functions']"
3,"Is an entire function ""determined by"" its maximum modulus on each circle centered at the origin?","Is an entire function ""determined by"" its maximum modulus on each circle centered at the origin?",,"Let $f$ be an entire function, and $$M_f(r)=\max_{|z|\leq r}|f(z)|$$ denotes its maximum modulus on the circle centered at the origin with radius $r>0$ . It's clear that for any entire functions $f(z)$ and $g(z)=e^{i\varphi}f(e^{i\theta}z)$ , $M_f\equiv M_g$ , where $\varphi$ and $\theta$ are real constants. For $f(z)$ and $h(z)=\overline{f(\overline z)}$ , we also have $M_f\equiv M_h$ . My question is, for any entire functions $f(z), g(z)$ that satisfying $M_f\equiv M_g$ , could we always transform $f$ into $g$ by the rotation and reflection(or some composition of both) as above? If not, is there any other universal transforms that keeps $M_f$ ?","Let be an entire function, and denotes its maximum modulus on the circle centered at the origin with radius . It's clear that for any entire functions and , , where and are real constants. For and , we also have . My question is, for any entire functions that satisfying , could we always transform into by the rotation and reflection(or some composition of both) as above? If not, is there any other universal transforms that keeps ?","f M_f(r)=\max_{|z|\leq r}|f(z)| r>0 f(z) g(z)=e^{i\varphi}f(e^{i\theta}z) M_f\equiv M_g \varphi \theta f(z) h(z)=\overline{f(\overline z)} M_f\equiv M_h f(z), g(z) M_f\equiv M_g f g M_f","['complex-analysis', 'transformation', 'entire-functions']"
4,Are all complex functions onto?,Are all complex functions onto?,,"I am not sure whether this question even makes sense. But I was just wondering whether all inverse operations of functions defined in complex numbers will stay inside complex numbers. (i.e. we don't have to extend the complex number system): $x^2$ is a well-defined function of real numbers alone and yet there is no real number such that $x^2 = -1$ , i.e. there is no inverse, for $-1$ (and so we need complex numbers). Is there a theorem that says that this kind of thing cannot happen with complex numbers? Maybe all continuous complex functions are onto? Or, maybe all taylor series with complex coefficients are onto?","I am not sure whether this question even makes sense. But I was just wondering whether all inverse operations of functions defined in complex numbers will stay inside complex numbers. (i.e. we don't have to extend the complex number system): is a well-defined function of real numbers alone and yet there is no real number such that , i.e. there is no inverse, for (and so we need complex numbers). Is there a theorem that says that this kind of thing cannot happen with complex numbers? Maybe all continuous complex functions are onto? Or, maybe all taylor series with complex coefficients are onto?",x^2 x^2 = -1 -1,"['complex-analysis', 'complex-numbers']"
5,Gaussian integral with a shift in the complex plane,Gaussian integral with a shift in the complex plane,,"$$ \int_{-\infty}^\infty e^{-(x+ia)^2} \text{d}x $$  where $a\in \mathbb{R}$. I don't know where to start but have reasons to believe the answer is $\sqrt{\pi}$. Namely $\int_{-\infty}^\infty e^{-x^2} \text{d}x$. Problem is I feel insecure performing changes of variables when suddenly the variables range in $\mathbb{C}$. I don't even know if this can be done properly, least of all how.","$$ \int_{-\infty}^\infty e^{-(x+ia)^2} \text{d}x $$  where $a\in \mathbb{R}$. I don't know where to start but have reasons to believe the answer is $\sqrt{\pi}$. Namely $\int_{-\infty}^\infty e^{-x^2} \text{d}x$. Problem is I feel insecure performing changes of variables when suddenly the variables range in $\mathbb{C}$. I don't even know if this can be done properly, least of all how.",,"['complex-analysis', 'complex-integration']"
6,Rigorous derivation/explanation of delta function representation?,Rigorous derivation/explanation of delta function representation?,,"I am interested in a derivation of the following representation for the Dirac delta function: $$\delta(x-a)=\frac{1}{2\pi}\int_{-\infty}^{\infty}e^{i p (x-a)}dp$$ It is clear to me how the property $\delta(x-a)=\infty$ for $x=a$ arizes. What I am most interested in, is how $\delta(x-a)=0$ for $x\neq a$ comes about when evaluating the integral? Also, please explain the normalization factor.","I am interested in a derivation of the following representation for the Dirac delta function: $$\delta(x-a)=\frac{1}{2\pi}\int_{-\infty}^{\infty}e^{i p (x-a)}dp$$ It is clear to me how the property $\delta(x-a)=\infty$ for $x=a$ arizes. What I am most interested in, is how $\delta(x-a)=0$ for $x\neq a$ comes about when evaluating the integral? Also, please explain the normalization factor.",,"['complex-analysis', 'fourier-analysis', 'distribution-theory']"
7,Zeta function zeros and analytic continuation,Zeta function zeros and analytic continuation,,"I'm learning about the zeta function and already discovered the intuitive proof of the Euler product and the Basel problem proof. I want to learn how to calculate the first zero of the Riemann Zeta function, but I know first that I will have to learn about analytic continuation  and other things. The problem is that I can't find intuitive proofs and other things explained from its intuitive point of view. I only find books that accept formulas, but I can't really learn about them. I want to know how to transform the normal Zeta function to the complex plane, and if possible, the simplest example of this technique for a simple function, so I know how it works and what really means extending a function to the complex plane.","I'm learning about the zeta function and already discovered the intuitive proof of the Euler product and the Basel problem proof. I want to learn how to calculate the first zero of the Riemann Zeta function, but I know first that I will have to learn about analytic continuation  and other things. The problem is that I can't find intuitive proofs and other things explained from its intuitive point of view. I only find books that accept formulas, but I can't really learn about them. I want to know how to transform the normal Zeta function to the complex plane, and if possible, the simplest example of this technique for a simple function, so I know how it works and what really means extending a function to the complex plane.",,"['complex-analysis', 'riemann-zeta']"
8,Prove that the zeros of an analytic function are finite and isolated,Prove that the zeros of an analytic function are finite and isolated,,"Let us assume that the zeros of $f = \{Z_1,\ldots,Z_n,a\}$ are infinite and converge towards $a$. The book which I am reading says that any neighborhood of $a$ will contain infinite zeros. Since $f$ is continuous, $f$ must be identically zero in this neighborhood. .....(A) Then as the neighborhood grows, it will be identically $0$ in that neighborhood too until it engulfs the whole of this region. Hence, the function becomes identically zero in the whole region. I don't quite understand (A). I am confused over (A) with this analogy. Consider $f(z) = z-1$. This has a zero at $z=1$. Since $f$ is continuous in the $z$ plane, this means that as per (A) points in the neighborhood of $z =1$ should also have mapped value $= 0$. I am confused; where could I be making a mistake? Thanks","Let us assume that the zeros of $f = \{Z_1,\ldots,Z_n,a\}$ are infinite and converge towards $a$. The book which I am reading says that any neighborhood of $a$ will contain infinite zeros. Since $f$ is continuous, $f$ must be identically zero in this neighborhood. .....(A) Then as the neighborhood grows, it will be identically $0$ in that neighborhood too until it engulfs the whole of this region. Hence, the function becomes identically zero in the whole region. I don't quite understand (A). I am confused over (A) with this analogy. Consider $f(z) = z-1$. This has a zero at $z=1$. Since $f$ is continuous in the $z$ plane, this means that as per (A) points in the neighborhood of $z =1$ should also have mapped value $= 0$. I am confused; where could I be making a mistake? Thanks",,"['complex-analysis', 'complex-numbers']"
9,If $f$ is entire and $\lim_\limits{z\to\infty} \frac{f(z)}{z} = 0$ show that $f$ is constant,If  is entire and  show that  is constant,f \lim_\limits{z\to\infty} \frac{f(z)}{z} = 0 f,"I'm learning Complex Analysis and need to verify my work to this problem since my textbook does not provide any solution: If $f$ is entire and $\lim_\limits{z\to\infty} \dfrac{f(z)}{z} = 0$ show that $f$ is constant. My work and thoughts: From the $\varepsilon$ — $\delta$ definition of the limit we have that  $$\forall{\varepsilon} > 0, \exists{n_0} \in \mathbb{N} : \forall{\left|z\right|} \geq n: \left| \frac{f(z)}{z} \right| < \varepsilon \iff \frac{\left| f(z) \right|}{\left| z \right|} < \varepsilon\iff \left| f(z) \right| < \varepsilon \left| z \right|.$$ Now let $C_R = \{z \in \mathbb{C} : \left| z \right| = R \}$. For every $\left| z \right| < R$, by Cauchy's integral formula for derivatives we have that $$ \left| f'(z) \right| = \frac{1}{2 \pi } \left| \int_{|\zeta|=R} \frac{f(\zeta)}{(\zeta - z)^2} \, d\zeta \right|= \frac{1}{2 \pi } \left| \int_{0}^{2\pi} \frac{f(\zeta)}{(\zeta - z)^2} \, \zeta'(t) dt \right| \le$$ $$\le \frac{1}{2\pi} \frac{\varepsilon \left| z \right|}{(R - \left| z \right|)^2} 2\pi R = \frac{\varepsilon \left| z \right|}{(R - \left| z \right|)^2} R.$$ Thus, letting $R \rightarrow \infty$ yields the desired result, that is  $$\left| f'(z) \right| \leq \lim_{R \to \infty} \frac{\varepsilon \left| z \right|}{(R - \left| z \right|)^2} R = 0 \implies f(z) = c \;\; \text{with} \; c \in \mathbb{C}.$$ Is my work correct? Are there parts of the proof that need improvements? I'm also looking for other (possibly quicker) solutions using the  ""big guns"" theorems. The only one I'm familiar with is Picard's little theorem but it doesn't apply here.","I'm learning Complex Analysis and need to verify my work to this problem since my textbook does not provide any solution: If $f$ is entire and $\lim_\limits{z\to\infty} \dfrac{f(z)}{z} = 0$ show that $f$ is constant. My work and thoughts: From the $\varepsilon$ — $\delta$ definition of the limit we have that  $$\forall{\varepsilon} > 0, \exists{n_0} \in \mathbb{N} : \forall{\left|z\right|} \geq n: \left| \frac{f(z)}{z} \right| < \varepsilon \iff \frac{\left| f(z) \right|}{\left| z \right|} < \varepsilon\iff \left| f(z) \right| < \varepsilon \left| z \right|.$$ Now let $C_R = \{z \in \mathbb{C} : \left| z \right| = R \}$. For every $\left| z \right| < R$, by Cauchy's integral formula for derivatives we have that $$ \left| f'(z) \right| = \frac{1}{2 \pi } \left| \int_{|\zeta|=R} \frac{f(\zeta)}{(\zeta - z)^2} \, d\zeta \right|= \frac{1}{2 \pi } \left| \int_{0}^{2\pi} \frac{f(\zeta)}{(\zeta - z)^2} \, \zeta'(t) dt \right| \le$$ $$\le \frac{1}{2\pi} \frac{\varepsilon \left| z \right|}{(R - \left| z \right|)^2} 2\pi R = \frac{\varepsilon \left| z \right|}{(R - \left| z \right|)^2} R.$$ Thus, letting $R \rightarrow \infty$ yields the desired result, that is  $$\left| f'(z) \right| \leq \lim_{R \to \infty} \frac{\varepsilon \left| z \right|}{(R - \left| z \right|)^2} R = 0 \implies f(z) = c \;\; \text{with} \; c \in \mathbb{C}.$$ Is my work correct? Are there parts of the proof that need improvements? I'm also looking for other (possibly quicker) solutions using the  ""big guns"" theorems. The only one I'm familiar with is Picard's little theorem but it doesn't apply here.",,"['complex-analysis', 'proof-verification', 'complex-integration', 'cauchy-integral-formula']"
10,"On every simply connected domain, there exists a holomorphic function with no analytic continuation.","On every simply connected domain, there exists a holomorphic function with no analytic continuation.",,"I am working on a question that requires me to prove that on every simply connected open subset of $\mathbb{C}$, there exists a holomorphic function that cannot be extended to a holomorphic function on a larger connected open set. I know an example of such a holomorphic function on the open unit disc: $$f:z\mapsto\sum_{n=1}^\infty z^{n!}.$$ I tried to combine this with the Riemann mapping theorem. Let $\Omega$ be a simply connected open subset of $\mathbb{C}$ and one may assume that $\Omega$ is not the entire complex plane. By the Riemann mapping theorem, there exists a conformal equivalence $$\phi:\Omega\rightarrow D$$where $D$ is the open unit disc. Then my guess is that $f\circ\phi$ has no analytic continuation, but then I had to link the boundaries of $\Omega$ and of $D$ and I don't know what is going on between $\partial\Omega$ and $\partial D$. Could anyone offer any idea? Many thanks!","I am working on a question that requires me to prove that on every simply connected open subset of $\mathbb{C}$, there exists a holomorphic function that cannot be extended to a holomorphic function on a larger connected open set. I know an example of such a holomorphic function on the open unit disc: $$f:z\mapsto\sum_{n=1}^\infty z^{n!}.$$ I tried to combine this with the Riemann mapping theorem. Let $\Omega$ be a simply connected open subset of $\mathbb{C}$ and one may assume that $\Omega$ is not the entire complex plane. By the Riemann mapping theorem, there exists a conformal equivalence $$\phi:\Omega\rightarrow D$$where $D$ is the open unit disc. Then my guess is that $f\circ\phi$ has no analytic continuation, but then I had to link the boundaries of $\Omega$ and of $D$ and I don't know what is going on between $\partial\Omega$ and $\partial D$. Could anyone offer any idea? Many thanks!",,"['complex-analysis', 'analytic-continuation']"
11,Behavior of the roots of an infinite series.,Behavior of the roots of an infinite series.,,"I have the polynomial $P_n(z)=1-\sum_{k=1}^{n}z^k$ . We know that this polynomial has exactly $n$ roots in $\mathbb{C}$ . Let $\rho$ be the number of roots of $P_n$ , thence if $n\to\infty$ then $\rho$ must tend to $\infty$ too. Though, if we interpret the sum as a geometric series, we get that $$P_n(z)=1-\sum_{k=1}^{n}z^k=\frac{z^{n+1}-2z+1}{1-z}$$ And if we make $n\to\infty$ it only converges for $|z|<1$ , becoming $P_\infty(z)=-\frac{2z-1}{1-z}$ , that has only one real root for $z=\frac{1}{2}$ . So, where did the other roots go? I plotted $P_n$ variating $n$ and noted that the roots tend to accumulate on the unit disk. ( Interactive Mapping ). So, can we say that all the roots will accumulate on the unit disk as $n\to\infty$ for $z\neq1$ ? How can we prove this? Thanks! Here I have some screenshots of the mapping. Respectively, $n=5$ , $n=10$ , $n=100$ . You can see that the roots tend to accumulate towards the unit circle. | | Thanks.","I have the polynomial . We know that this polynomial has exactly roots in . Let be the number of roots of , thence if then must tend to too. Though, if we interpret the sum as a geometric series, we get that And if we make it only converges for , becoming , that has only one real root for . So, where did the other roots go? I plotted variating and noted that the roots tend to accumulate on the unit disk. ( Interactive Mapping ). So, can we say that all the roots will accumulate on the unit disk as for ? How can we prove this? Thanks! Here I have some screenshots of the mapping. Respectively, , , . You can see that the roots tend to accumulate towards the unit circle. | | Thanks.",P_n(z)=1-\sum_{k=1}^{n}z^k n \mathbb{C} \rho P_n n\to\infty \rho \infty P_n(z)=1-\sum_{k=1}^{n}z^k=\frac{z^{n+1}-2z+1}{1-z} n\to\infty |z|<1 P_\infty(z)=-\frac{2z-1}{1-z} z=\frac{1}{2} P_n n n\to\infty z\neq1 n=5 n=10 n=100,"['complex-analysis', 'polynomials', 'complex-numbers', 'power-series']"
12,Striking applications of Morera's theorem,Striking applications of Morera's theorem,,"Morera's theorem is an underappreciated theorem in complex analysis. I have been struck by the simplicity of its proof and some clever applications of it and I had been interested in finding out more of such. Please contribute examples. One example is the Weierstrass theorem that if a sequence of holomorphic functions converge absolutely and uniformly on every compact subset in a domain, then the limit is also holomorphic. And there are numerous applications of this latter fact. So, please come ahead and contribute clever and slick applications of Morera's theorem that will impress people!","Morera's theorem is an underappreciated theorem in complex analysis. I have been struck by the simplicity of its proof and some clever applications of it and I had been interested in finding out more of such. Please contribute examples. One example is the Weierstrass theorem that if a sequence of holomorphic functions converge absolutely and uniformly on every compact subset in a domain, then the limit is also holomorphic. And there are numerous applications of this latter fact. So, please come ahead and contribute clever and slick applications of Morera's theorem that will impress people!",,[]
13,"Working with $z$, $\overline{z}$ instead of $\operatorname{Re}(z)$, $\operatorname{Im}(z)$","Working with ,  instead of ,",z \overline{z} \operatorname{Re}(z) \operatorname{Im}(z),"The problem is the following: Determine conditions for $a,b,c\in\mathbb{C}$ such that $az+b\overline{z}+c=0$ has unique solution in $\mathbb{C}$. Teacher answer: If $az+b\overline{z}+c=0$, then $\overline{b}z+\overline{a}\overline{z}+\overline{c}=0$. So $\left(\begin{array}\\ a & b \\ \overline{b}&\overline{a} \end{array}\right)\left(\begin{array}\\ z \\ \overline{z} \end{array}\right)=\left(\begin{array}\\ -c \\ -\overline{c} \end{array}\right)$. Like in linear algebra, we have only one solution iff $|a|^2-|b|^2\neq 0$. My answer is too long (equaling real and imaginary parts and taking a 2x2 system of linear equations), and teacher answer didn't convince me because teacher is solving a system where one component $z$ depends of another component which is $\overline{z}$ (if we obtain $z$ we automatically obtain $\overline{z}$ and viceversa). Edit: Being more precise I have two conceptual questions, about validity and why the teacher's procedure works: 1) Why is solved for the pair $(z, \overline{z})$? if we obtain $z$, we also obtain its conjugate automatically. That has not sense. 2) Why do you need the conjugate of the first equation (is the same equation)? 3) Why condition $|a|^2-|b|^2\neq 0$ is necessary for unicity of solutions in the pair $z,\overline{z}$? I only know that there is unique solution for $(z,w)$ but we could have unique solution for $(z,\overline{z})$ and multiple solutions for $(z,w)$.","The problem is the following: Determine conditions for $a,b,c\in\mathbb{C}$ such that $az+b\overline{z}+c=0$ has unique solution in $\mathbb{C}$. Teacher answer: If $az+b\overline{z}+c=0$, then $\overline{b}z+\overline{a}\overline{z}+\overline{c}=0$. So $\left(\begin{array}\\ a & b \\ \overline{b}&\overline{a} \end{array}\right)\left(\begin{array}\\ z \\ \overline{z} \end{array}\right)=\left(\begin{array}\\ -c \\ -\overline{c} \end{array}\right)$. Like in linear algebra, we have only one solution iff $|a|^2-|b|^2\neq 0$. My answer is too long (equaling real and imaginary parts and taking a 2x2 system of linear equations), and teacher answer didn't convince me because teacher is solving a system where one component $z$ depends of another component which is $\overline{z}$ (if we obtain $z$ we automatically obtain $\overline{z}$ and viceversa). Edit: Being more precise I have two conceptual questions, about validity and why the teacher's procedure works: 1) Why is solved for the pair $(z, \overline{z})$? if we obtain $z$, we also obtain its conjugate automatically. That has not sense. 2) Why do you need the conjugate of the first equation (is the same equation)? 3) Why condition $|a|^2-|b|^2\neq 0$ is necessary for unicity of solutions in the pair $z,\overline{z}$? I only know that there is unique solution for $(z,w)$ but we could have unique solution for $(z,\overline{z})$ and multiple solutions for $(z,w)$.",,['complex-analysis']
14,Video Lessons in Complex Analysis,Video Lessons in Complex Analysis,,Does anybody have some link for good video lessons of a complete course in Complex Analysis? Grateful.,Does anybody have some link for good video lessons of a complete course in Complex Analysis? Grateful.,,"['complex-analysis', 'reference-request', 'education', 'online-resources']"
15,Analytic continuation of a real function,Analytic continuation of a real function,,"I know that for $U \subset _{open} \mathbb{C}$, if a function $f$ is analytic on $U$ and if $f$ can be extended to the whole complex plane, this extension is unique. Now i am wondering if this is true for real functions. I mean, if $f: \mathbb{R} \to \mathbb{R}$, when is it true that there is an analytic $g$ whose restriction to $\mathbb{R}$ coincides with $f$ and also when is $g$ unique. Surely $f$ needs to be differentiable but this might not be sufficient for existance of such $g$. edit: I mean, is it easy to see that there is and extension of sine cosine and exponential real functions? Thanks a lot.","I know that for $U \subset _{open} \mathbb{C}$, if a function $f$ is analytic on $U$ and if $f$ can be extended to the whole complex plane, this extension is unique. Now i am wondering if this is true for real functions. I mean, if $f: \mathbb{R} \to \mathbb{R}$, when is it true that there is an analytic $g$ whose restriction to $\mathbb{R}$ coincides with $f$ and also when is $g$ unique. Surely $f$ needs to be differentiable but this might not be sufficient for existance of such $g$. edit: I mean, is it easy to see that there is and extension of sine cosine and exponential real functions? Thanks a lot.",,"['complex-analysis', 'analyticity']"
16,"Can $ \int_0^{\pi/2} \ln ( \sin(x)) \; dx$ be evaluated with ""complex method""?","Can  be evaluated with ""complex method""?", \int_0^{\pi/2} \ln ( \sin(x)) \; dx,Can the following integral be evaluated using complex method by substituting $\sin(x) = {e^{ix}-e^{-ix} \over 2i}$? $$ I=\int_0^{\pi/2} \ln ( \sin(x)) \; dx = - {\pi \ln(2) \over 2}$$,Can the following integral be evaluated using complex method by substituting $\sin(x) = {e^{ix}-e^{-ix} \over 2i}$? $$ I=\int_0^{\pi/2} \ln ( \sin(x)) \; dx = - {\pi \ln(2) \over 2}$$,,"['complex-analysis', 'definite-integrals']"
17,How would one evaluate $\int\frac{x\sin(x)}{x^2+1}$ over the real line?,How would one evaluate  over the real line?,\int\frac{x\sin(x)}{x^2+1},"Another exam problem I'm looking at is to evaluate the following integral. $$ \int_{-\infty}^{\infty} \frac{x\hspace{-0.04 in}\cdot\hspace{-0.04 in}\sin(x)}{x^{\hspace{.02 in}2}+1} dx $$ This is a complex analysis exam, so the solution probably involves contours. $\:$ Since the integrand is an even function, one could potentially simplify by changing one endpoint to $0$. However, I have no idea how to make a contour work since the absolute value of the integrand grows exponentially away from the real axis. What does one need to do to evaluate that integral?","Another exam problem I'm looking at is to evaluate the following integral. $$ \int_{-\infty}^{\infty} \frac{x\hspace{-0.04 in}\cdot\hspace{-0.04 in}\sin(x)}{x^{\hspace{.02 in}2}+1} dx $$ This is a complex analysis exam, so the solution probably involves contours. $\:$ Since the integrand is an even function, one could potentially simplify by changing one endpoint to $0$. However, I have no idea how to make a contour work since the absolute value of the integrand grows exponentially away from the real axis. What does one need to do to evaluate that integral?",,['complex-analysis']
18,"If $f:U\to V$ is holomorphic and $f'(z)\neq 0$ for all $z\in U$, then$f$ is locally bijective.","If  is holomorphic and  for all , then is locally bijective.",f:U\to V f'(z)\neq 0 z\in U f,"I am trying to solve the following problem: Let $f:U\to V$ be a holomorphic function such that $f'(z)\neq 0$ for all $z\in U$. Show that for all $z_0\in U$, there exists a disc $D_\varepsilon(z_0)\subseteq U$ such that $f:D_\varepsilon(z_0)\to f(D_\varepsilon(z_0))$ is bijective. Atempt: I am trying to use Rouche's Theorem, but I am stuck on a particular step. Let $z_0\in U$. Since $f'(z_0)\neq 0$, there is a disc $D_r(z_0)\subseteq U$ such that $$f(z)=f(z_0)+(z-z_0)h(z),\quad\forall z\in D_r(z_0)$$ where $h$ is holomorphic on $D_r(z_0)$ and $h(z)\neq 0$ for all $z\in D_r(z_0)$. Let $0<\varepsilon<r$ to be defined later and fix $w\in D_\varepsilon(z_0)$. To show that $f$ is injective in $D_\varepsilon(z_0)$ is to show that the function $f(z)-f(w)$ has exactly one zero in $D_\varepsilon(z_0)$. But $$F(z):=(z-z_0)h(z)$$ has exactly one zero in $D_\varepsilon(z_0)$, so we might want to apply Rouche's Theorem with $F$ and $$G(z):=f(z)-f(w)-(z-z_0)h(z)=f(z_0)-f(w)=-(w-z_0)h(w)$$ to conclude that $F$ and $F+G$ have the same number of zeros and hence $f$ is injective. But that means that we need to find $0<\varepsilon<r$ such that $|G(z)|<|F(z)|$ on $\partial D_\varepsilon(z_0)$. That is, $$|w-z_0||h(w)|<|z-z_0||h(z)|$$ for all $w\in D_\varepsilon(z_0)$ and $z\in\partial D_\varepsilon(z_0)$. Can we find such $\varepsilon>0$? It seems intuitive since if we expand $h$ in a power series at $z_0$, $h(z)=\sum_{n=0}^\infty a_n(z-z_0)^n$, then $$|w-z_0||h(w)| = |w-z_0|\sum_{n=0}^\infty a_n|w-z_0|^n < |z-z_0|\sum_{n=0}^\infty a_n|z-z_0|^n.$$ for $w\in D_\varepsilon(z_0)$ and $z\in\partial D_\varepsilon(z_0)$. But this is of course not a proof.","I am trying to solve the following problem: Let $f:U\to V$ be a holomorphic function such that $f'(z)\neq 0$ for all $z\in U$. Show that for all $z_0\in U$, there exists a disc $D_\varepsilon(z_0)\subseteq U$ such that $f:D_\varepsilon(z_0)\to f(D_\varepsilon(z_0))$ is bijective. Atempt: I am trying to use Rouche's Theorem, but I am stuck on a particular step. Let $z_0\in U$. Since $f'(z_0)\neq 0$, there is a disc $D_r(z_0)\subseteq U$ such that $$f(z)=f(z_0)+(z-z_0)h(z),\quad\forall z\in D_r(z_0)$$ where $h$ is holomorphic on $D_r(z_0)$ and $h(z)\neq 0$ for all $z\in D_r(z_0)$. Let $0<\varepsilon<r$ to be defined later and fix $w\in D_\varepsilon(z_0)$. To show that $f$ is injective in $D_\varepsilon(z_0)$ is to show that the function $f(z)-f(w)$ has exactly one zero in $D_\varepsilon(z_0)$. But $$F(z):=(z-z_0)h(z)$$ has exactly one zero in $D_\varepsilon(z_0)$, so we might want to apply Rouche's Theorem with $F$ and $$G(z):=f(z)-f(w)-(z-z_0)h(z)=f(z_0)-f(w)=-(w-z_0)h(w)$$ to conclude that $F$ and $F+G$ have the same number of zeros and hence $f$ is injective. But that means that we need to find $0<\varepsilon<r$ such that $|G(z)|<|F(z)|$ on $\partial D_\varepsilon(z_0)$. That is, $$|w-z_0||h(w)|<|z-z_0||h(z)|$$ for all $w\in D_\varepsilon(z_0)$ and $z\in\partial D_\varepsilon(z_0)$. Can we find such $\varepsilon>0$? It seems intuitive since if we expand $h$ in a power series at $z_0$, $h(z)=\sum_{n=0}^\infty a_n(z-z_0)^n$, then $$|w-z_0||h(w)| = |w-z_0|\sum_{n=0}^\infty a_n|w-z_0|^n < |z-z_0|\sum_{n=0}^\infty a_n|z-z_0|^n.$$ for $w\in D_\varepsilon(z_0)$ and $z\in\partial D_\varepsilon(z_0)$. But this is of course not a proof.",,['complex-analysis']
19,Real points of a complex curve,Real points of a complex curve,,"Since the ""real points"" of a complex curve can mean a couple of different things, bear with me while I'm annoyingly formal here. Consider first a cubic curve $y^2 = x^3 + a x + b$.  Write $$S := \{ [x:y:z] \in \mathbb{C}P^2 \; | \; y^2 z = x^3 + a x z^2 + b z^3 \}$$ and $$C := \{ [x:y:z] \; | \; x, y, z \in \mathbb{R} \text{ and } [x:y:z] \in S \}.$$ For generic values of $a$ and $b$, we can regard $S$ and a real 2-manifold and $C$ as a one-dimensional submanifold of $C$.  Thus in particular $C$ determines an element of $H_1(S, \mathbb{Z})$.  Which element, and is there a nice way to see this? Follow-up question: What's the situation for an arbitrary smooth projective curve? Second follow-up question: What's the situation for an arbitrary complex projective hypersurface?  For an arbitrary complex projective variety? (Feel free to assume all these varieties are defined over $\mathbb{R}$ if it helps.)","Since the ""real points"" of a complex curve can mean a couple of different things, bear with me while I'm annoyingly formal here. Consider first a cubic curve $y^2 = x^3 + a x + b$.  Write $$S := \{ [x:y:z] \in \mathbb{C}P^2 \; | \; y^2 z = x^3 + a x z^2 + b z^3 \}$$ and $$C := \{ [x:y:z] \; | \; x, y, z \in \mathbb{R} \text{ and } [x:y:z] \in S \}.$$ For generic values of $a$ and $b$, we can regard $S$ and a real 2-manifold and $C$ as a one-dimensional submanifold of $C$.  Thus in particular $C$ determines an element of $H_1(S, \mathbb{Z})$.  Which element, and is there a nice way to see this? Follow-up question: What's the situation for an arbitrary smooth projective curve? Second follow-up question: What's the situation for an arbitrary complex projective hypersurface?  For an arbitrary complex projective variety? (Feel free to assume all these varieties are defined over $\mathbb{R}$ if it helps.)",,"['complex-analysis', 'algebraic-geometry']"
20,Torus and Elliptic curves,Torus and Elliptic curves,,"In a conference on elliptic curves (an introduction to the subject), the speaker said that an elliptic curve (I.e. an equation of the form $y^2=x^3+ax+b $ where the RHS has distinct roots) is, in the complex space, a torus/Riemann surface of genus 1. What is meant by that? Are we talking about a 2-dimensional manifold the 4D space?","In a conference on elliptic curves (an introduction to the subject), the speaker said that an elliptic curve (I.e. an equation of the form $y^2=x^3+ax+b $ where the RHS has distinct roots) is, in the complex space, a torus/Riemann surface of genus 1. What is meant by that? Are we talking about a 2-dimensional manifold the 4D space?",,"['complex-analysis', 'elliptic-curves', 'elliptic-functions']"
21,Does a power series vanish on the circle of convergence imply that the power series equals to zero?,Does a power series vanish on the circle of convergence imply that the power series equals to zero?,,"Let $f(z)=\sum_{n=0}^{\infty} a_n z^n$ be a power series, $a_n, z\in \mathbb{C}$. Suppose the radius of convergence of $f$ is $1$, and $f$ is convergent at every point of the unit circle. Question :If $f(z)=0$ for every $|z|=1$, then can we draw the conclusion that $a_n=0$ for all nonnegative integer $n$? I think the answer is yes , but I failed to prove it. My approach is concerning about the function $F_\lambda(z):=f(\lambda z)$ for $0\leq\lambda\leq 1$, $|z|=1$. Abel's theorem shows that $F_\lambda$ converge to $F_1$ pointwisely as $\lambda\rightarrow 1$ on the unit circle. If I have the property that $f$ is bounded in the unit disk, then I can apply Lebesgue's dominated convergence theorem to prove $a_0=0$, and by induction I can prove $a_n=0$ for all $n$. However, I cannot prove $f(z) $ is bounded in the unit disk. Any answers or comments are welcome. I'll really appreciate your help.","Let $f(z)=\sum_{n=0}^{\infty} a_n z^n$ be a power series, $a_n, z\in \mathbb{C}$. Suppose the radius of convergence of $f$ is $1$, and $f$ is convergent at every point of the unit circle. Question :If $f(z)=0$ for every $|z|=1$, then can we draw the conclusion that $a_n=0$ for all nonnegative integer $n$? I think the answer is yes , but I failed to prove it. My approach is concerning about the function $F_\lambda(z):=f(\lambda z)$ for $0\leq\lambda\leq 1$, $|z|=1$. Abel's theorem shows that $F_\lambda$ converge to $F_1$ pointwisely as $\lambda\rightarrow 1$ on the unit circle. If I have the property that $f$ is bounded in the unit disk, then I can apply Lebesgue's dominated convergence theorem to prove $a_0=0$, and by induction I can prove $a_n=0$ for all $n$. However, I cannot prove $f(z) $ is bounded in the unit disk. Any answers or comments are welcome. I'll really appreciate your help.",,"['complex-analysis', 'power-series']"
22,Complex towers: $i^{i^{i^{...}}}$,Complex towers:,i^{i^{i^{...}}},"If $w = z^{z^{z^{...}}}$ converges, we can determine its value by solving $w = z^{w}$, which leads to $w = -W(-\log z))/\log z$.  To be specific here, let's use $u^v = \exp(v \log u)$ for complex $u$ and $v$. Two questions: How do we determine analytically if the tower converges?  (I have seen the interval of convergence for real towers.) Both the logarithm and Lambert W functions are multivalued.  How do we know which branch to use? In particular $i^{i^{i^{...}}}$ numerically seems to converge to one value of $i2W(-i\pi/2)/\pi$.  How do we establish this convergence analytically? (Yes, I have searched the 'net, including the tetration forum.  I haven't been able to locate the answer to this readily.)","If $w = z^{z^{z^{...}}}$ converges, we can determine its value by solving $w = z^{w}$, which leads to $w = -W(-\log z))/\log z$.  To be specific here, let's use $u^v = \exp(v \log u)$ for complex $u$ and $v$. Two questions: How do we determine analytically if the tower converges?  (I have seen the interval of convergence for real towers.) Both the logarithm and Lambert W functions are multivalued.  How do we know which branch to use? In particular $i^{i^{i^{...}}}$ numerically seems to converge to one value of $i2W(-i\pi/2)/\pi$.  How do we establish this convergence analytically? (Yes, I have searched the 'net, including the tetration forum.  I haven't been able to locate the answer to this readily.)",,"['complex-analysis', 'complex-numbers', 'tetration', 'multivalued-functions']"
23,What can be gleaned from looking at a domain-colored graph of a complex function?,What can be gleaned from looking at a domain-colored graph of a complex function?,,"Functions from $\mathbb{C} \rightarrow \mathbb{C}$ are hard to visualize because of their 4-dimensional nature. One nice way of looking at them is by what's called domain coloring . An example from the wiki article is shown below. When we look at the graph of a real function ($\mathbb{R} \rightarrow \mathbb{R}$), we can get a feel for some of the function's properties: where its zeros are, if it's continuous, if it's differentiable, etc. My question is what kinds of properties of complex functions can we ""see"" by looking at a domain coloring? In the example below, we can obviously see where the zeros are and where it blows up. I'm wondering, can we tell if a function is analytic? A rational function? Can we estimate an integral like we could by looking at a real graph? $f(z) = \frac{(z^2 − 1)(z − 2 − i)^2}{(z^2 + 2 + 2i)}$","Functions from $\mathbb{C} \rightarrow \mathbb{C}$ are hard to visualize because of their 4-dimensional nature. One nice way of looking at them is by what's called domain coloring . An example from the wiki article is shown below. When we look at the graph of a real function ($\mathbb{R} \rightarrow \mathbb{R}$), we can get a feel for some of the function's properties: where its zeros are, if it's continuous, if it's differentiable, etc. My question is what kinds of properties of complex functions can we ""see"" by looking at a domain coloring? In the example below, we can obviously see where the zeros are and where it blows up. I'm wondering, can we tell if a function is analytic? A rational function? Can we estimate an integral like we could by looking at a real graph? $f(z) = \frac{(z^2 − 1)(z − 2 − i)^2}{(z^2 + 2 + 2i)}$",,"['complex-analysis', 'intuition', 'visualization']"
24,The idea behind the proof of Riemann mapping theorem,The idea behind the proof of Riemann mapping theorem,,"The proof of Riemann mapping theorem (if $U\subsetneq\mathbb C$ is simply connected then it's conformally equivalent to the unit disk $D$) goes roughly as follows: Consider the family $F$ of all injective functions $U\rightarrow D$ taking a given point $a$ to $0$. Show that $F$ is nonempty. The map $f\mapsto |f'(a)|$ is continuous and $F$ is uniformly bounded, so by Montel's theorem there is an $f_0\in F$ maximizing $|f_0'(a)|$. Show that $f_0$ is onto $D$. The two tricky bits of the proof are the second and fourth bullets. Here are the ideas behind the proofs of the two: We may WLOG assume $0\not\in U$. Then there is a branch $g$ of a square root defined on $U$. Then $g$ is injective, $-g(U)$ is open and disjoint from $g(U)$ so $g(U)$ is disjoint from some closed disk. The complement of that disk can be then mapped into $D$, and composing with suitable Mobius transformation maps $a$ to $0$. Suppose $b\in D\setminus f_0(U)$. Then the map $$\psi(z)=\sqrt{\frac{f_0(z)-b}{1-\overline{b}f_0(z)}}$$ (the inside function doesn't vanish, so we can find a branch of its square root on $U$) takes $U$ into the unit disk and hence $$h(z)=\frac{\psi(z)-\psi(a)}{1-\overline{\psi(a)}\psi(z)}$$ is in $F$. We then find $$|h'(a)|=\frac{1+|b|}{2\sqrt{|b|}}|f_0'(a)|>|f_0'(a)|$$ contradicting the choice of $f_0$. I can see the reason behind proving the former the way we do - we want to map $U$ into a set the complement of which has nonempty interior. The square root suits this perfectly since $g(U)$ and $-g(U)$ are always disjoint for a branch of square root (we could similarly take a branch of logarithm, then $g(U)$ and $g(U)+2\pi i$ are disjoint). However, the last part of the proof feels to me like a magic trick. I thought about it several times, but I couldn't figure out anything to explain this course of action in the proof. Clearly we would like to increase a derivative somehow, but confirming this with the function constructed above requires a computational effort, not something visible at a glance. I was wondering, how to ""justify"" construction of this function in the last part of the proof (possibly by some geometric argument)? Alternatively, is it possible to argue towards existence of a function with a larger derivative, without necessarily constructing it?","The proof of Riemann mapping theorem (if $U\subsetneq\mathbb C$ is simply connected then it's conformally equivalent to the unit disk $D$) goes roughly as follows: Consider the family $F$ of all injective functions $U\rightarrow D$ taking a given point $a$ to $0$. Show that $F$ is nonempty. The map $f\mapsto |f'(a)|$ is continuous and $F$ is uniformly bounded, so by Montel's theorem there is an $f_0\in F$ maximizing $|f_0'(a)|$. Show that $f_0$ is onto $D$. The two tricky bits of the proof are the second and fourth bullets. Here are the ideas behind the proofs of the two: We may WLOG assume $0\not\in U$. Then there is a branch $g$ of a square root defined on $U$. Then $g$ is injective, $-g(U)$ is open and disjoint from $g(U)$ so $g(U)$ is disjoint from some closed disk. The complement of that disk can be then mapped into $D$, and composing with suitable Mobius transformation maps $a$ to $0$. Suppose $b\in D\setminus f_0(U)$. Then the map $$\psi(z)=\sqrt{\frac{f_0(z)-b}{1-\overline{b}f_0(z)}}$$ (the inside function doesn't vanish, so we can find a branch of its square root on $U$) takes $U$ into the unit disk and hence $$h(z)=\frac{\psi(z)-\psi(a)}{1-\overline{\psi(a)}\psi(z)}$$ is in $F$. We then find $$|h'(a)|=\frac{1+|b|}{2\sqrt{|b|}}|f_0'(a)|>|f_0'(a)|$$ contradicting the choice of $f_0$. I can see the reason behind proving the former the way we do - we want to map $U$ into a set the complement of which has nonempty interior. The square root suits this perfectly since $g(U)$ and $-g(U)$ are always disjoint for a branch of square root (we could similarly take a branch of logarithm, then $g(U)$ and $g(U)+2\pi i$ are disjoint). However, the last part of the proof feels to me like a magic trick. I thought about it several times, but I couldn't figure out anything to explain this course of action in the proof. Clearly we would like to increase a derivative somehow, but confirming this with the function constructed above requires a computational effort, not something visible at a glance. I was wondering, how to ""justify"" construction of this function in the last part of the proof (possibly by some geometric argument)? Alternatively, is it possible to argue towards existence of a function with a larger derivative, without necessarily constructing it?",,"['complex-analysis', 'complex-numbers', 'intuition']"
25,How did Hecke come up with Hecke-operators?,How did Hecke come up with Hecke-operators?,,"I'm currently studying Hecke-operators and I'm curious how Hecke came up with them. The original definition he gave in his paper is $$\left( f \mid T_n\right) (z) = n^{k - 1} \sum_{ad = n, \, b \mod d, \, d > 0} d^{-k } f\left( \frac{az + b}{d}\right)$$ for a modular form $f$ of weight $k$. This is an averaging over the set of representatives of the action of $\mathrm{SL}_2(\mathbf{Z})$ on $M_n := \left\{ A \in \mathbf{Z}^{2 \times 2} : \det (A) = n \right\}$ (acting by left-multiplication), i.e. $$f \mid T_n = n^{\frac{k}{2} - 1} \sum_{\alpha \in \mathrm{SL}_2(\mathbf{Z}) \text{ \ } M_n} f \mid_k \alpha$$ where $\mid_k$ is the slash-operator. But why would someone consider such an 'averaging'? Is there anything one can hope for by averaging over $\mathrm{SL}_2(\mathbf{Z}) \text{ \ } M_n$? More generally, why did Hecke consider operators of such kind?","I'm currently studying Hecke-operators and I'm curious how Hecke came up with them. The original definition he gave in his paper is $$\left( f \mid T_n\right) (z) = n^{k - 1} \sum_{ad = n, \, b \mod d, \, d > 0} d^{-k } f\left( \frac{az + b}{d}\right)$$ for a modular form $f$ of weight $k$. This is an averaging over the set of representatives of the action of $\mathrm{SL}_2(\mathbf{Z})$ on $M_n := \left\{ A \in \mathbf{Z}^{2 \times 2} : \det (A) = n \right\}$ (acting by left-multiplication), i.e. $$f \mid T_n = n^{\frac{k}{2} - 1} \sum_{\alpha \in \mathrm{SL}_2(\mathbf{Z}) \text{ \ } M_n} f \mid_k \alpha$$ where $\mid_k$ is the slash-operator. But why would someone consider such an 'averaging'? Is there anything one can hope for by averaging over $\mathrm{SL}_2(\mathbf{Z}) \text{ \ } M_n$? More generally, why did Hecke consider operators of such kind?",,"['complex-analysis', 'number-theory', 'reference-request', 'math-history', 'modular-forms']"
26,how to understand $\log\zeta(s)$ (Riemann zeta function)?,how to understand  (Riemann zeta function)?,\log\zeta(s),"I know that if a function $f$ is analytic and has no zeros in a simple connected region, then we can define $\log{f}$ making it analytic in that region. Let's assume $Re(s)>1$. Is $\zeta(s)$ defined in a simple connected region? If not, how shall I understand $\log\zeta(s)$? Also, is it true that $\log\zeta(s) = -\sum_p \log(1-p^{-s})$? I have no idea about this because I don't think we always have $\log{z_1z_2}=\log{z_1}+\log{z_2}$.","I know that if a function $f$ is analytic and has no zeros in a simple connected region, then we can define $\log{f}$ making it analytic in that region. Let's assume $Re(s)>1$. Is $\zeta(s)$ defined in a simple connected region? If not, how shall I understand $\log\zeta(s)$? Also, is it true that $\log\zeta(s) = -\sum_p \log(1-p^{-s})$? I have no idea about this because I don't think we always have $\log{z_1z_2}=\log{z_1}+\log{z_2}$.",,"['complex-analysis', 'analytic-number-theory', 'riemann-zeta']"
27,A cute approximation for $\cot(2\pi x)$(!?),A cute approximation for (!?),\cot(2\pi x),"Numerical calculations and some theory leads to the suggestion that $$\cot(2\pi x) \rightarrow\frac{1}{2\pi}\sum_r \frac{1}{x-r}$$ where $r$ ranges over all the roots of $B_{2n+1}$ (Bernoulli polynomial) as $n\rightarrow \infty$ and $n \in \mathbb{N}$. Does this converge to $\cot(2\pi x)$? If so, how fast? Do you have pointers to books, articles? Here is one article that is relevant for a start: Uniform Convergence Behavior of the Bernoulli Polynomials The theory behind it is really just Corollary 2.1, page 3 from that article and that for $P(x)$ and $Q(x) = (x-\alpha_1)(x-\alpha_2) \cdots (x-\alpha_n)$ polynomials $\textrm{deg }P < \textrm{deg }Q$, $\alpha_i$ distinct, then $$\frac{P(x)}{Q(x)} = \sum_{i=1}^n \frac{P(\alpha_i)}{Q'(\alpha_i)}\frac{1}{(x-\alpha_i)}$$ partial fractions Wikipedia (also $B_n'(x)=nB_{n-1}(x))$","Numerical calculations and some theory leads to the suggestion that $$\cot(2\pi x) \rightarrow\frac{1}{2\pi}\sum_r \frac{1}{x-r}$$ where $r$ ranges over all the roots of $B_{2n+1}$ (Bernoulli polynomial) as $n\rightarrow \infty$ and $n \in \mathbb{N}$. Does this converge to $\cot(2\pi x)$? If so, how fast? Do you have pointers to books, articles? Here is one article that is relevant for a start: Uniform Convergence Behavior of the Bernoulli Polynomials The theory behind it is really just Corollary 2.1, page 3 from that article and that for $P(x)$ and $Q(x) = (x-\alpha_1)(x-\alpha_2) \cdots (x-\alpha_n)$ polynomials $\textrm{deg }P < \textrm{deg }Q$, $\alpha_i$ distinct, then $$\frac{P(x)}{Q(x)} = \sum_{i=1}^n \frac{P(\alpha_i)}{Q'(\alpha_i)}\frac{1}{(x-\alpha_i)}$$ partial fractions Wikipedia (also $B_n'(x)=nB_{n-1}(x))$",,['complex-analysis']
28,Multivalued Functions for Dummies,Multivalued Functions for Dummies,,"I have been studying complex analysis for a while, but I still cannot ""get"" how multivalued functions work. Despite having it explained to me many times, my brain cannot process it. For example, I do not know / understand what $f(z) = \sqrt{z^2}$, $g(z) = (\sqrt{z})^2$ are. I don't know how to decide which branch to use when I see expressions like $f(z) = \sqrt{z(z-1)(z-\lambda)}$ I don't understand how integrals involving roots work, especially when it seems like the integral is being taken along the branch cuts. I feel like many books I have seen treats these as being obvious. Is there a reference that really drills on this topic? Kind of like 'multivalued functions for dummies'? EDIT: $g(z) = \sqrt{z}^2 = z$ (with a removable singularity at $z=0$.) $f(z) = \sqrt{z^2}$ is a multivalued function. EDIT2: $f(z) = \sqrt{z(z-1)(z-\lambda)} = \exp(\frac12 \log(g(z)))$ where $g(z) = z(z-1)(z-\lambda).$ Let $z_0$ some point that is not $0, 1, \lambda$. Then, it is possible to define $L$ in a small disk around $z_0$, with $$L(z) = \ln|z| + i \theta,$$ If $z_0$ is not a negative real number, $\theta$ can be $[-\pi,\pi]$. If $z_0$ is a negative real number, then $\theta$ can be $[0,2\pi]$. Then for $z\ne 0,1,\lambda$, we can define $$\log z = \int_{z_0}^z \dfrac{g'(z)}{g(z)} dz + L(z_0),$$ which is multivalued. Then, $$\sqrt{g(z)} =\exp(\dfrac{1}{2} \left(\int_{z_0}^z \dfrac{g'(z)}{g(z)} dz + L(z_0)\right))$$ By the argument principle, this is a single valued function on $D$ as long as $D$ does not allow the path from $z_0$ to $z$ to loop around an odd number of zeros of $g$. This can be prevented by pairing up the zeros with a branch cut. For an odd number of zeroes, the left over one can be connected to the point at infinity. So any combination of branch cuts that connects two of the zeros, and the third zero to the point at infinity will make $\sqrt{g(z)}$ single valued. Similarly, $\sqrt[n]{g(z)}$ would require the branch cuts to group $n$-zeroes at a time, to prevent any loops around $k$-zeroes for $k<n$. If there is any shortage, $\infty$  fire one branch cut off to infinity.","I have been studying complex analysis for a while, but I still cannot ""get"" how multivalued functions work. Despite having it explained to me many times, my brain cannot process it. For example, I do not know / understand what $f(z) = \sqrt{z^2}$, $g(z) = (\sqrt{z})^2$ are. I don't know how to decide which branch to use when I see expressions like $f(z) = \sqrt{z(z-1)(z-\lambda)}$ I don't understand how integrals involving roots work, especially when it seems like the integral is being taken along the branch cuts. I feel like many books I have seen treats these as being obvious. Is there a reference that really drills on this topic? Kind of like 'multivalued functions for dummies'? EDIT: $g(z) = \sqrt{z}^2 = z$ (with a removable singularity at $z=0$.) $f(z) = \sqrt{z^2}$ is a multivalued function. EDIT2: $f(z) = \sqrt{z(z-1)(z-\lambda)} = \exp(\frac12 \log(g(z)))$ where $g(z) = z(z-1)(z-\lambda).$ Let $z_0$ some point that is not $0, 1, \lambda$. Then, it is possible to define $L$ in a small disk around $z_0$, with $$L(z) = \ln|z| + i \theta,$$ If $z_0$ is not a negative real number, $\theta$ can be $[-\pi,\pi]$. If $z_0$ is a negative real number, then $\theta$ can be $[0,2\pi]$. Then for $z\ne 0,1,\lambda$, we can define $$\log z = \int_{z_0}^z \dfrac{g'(z)}{g(z)} dz + L(z_0),$$ which is multivalued. Then, $$\sqrt{g(z)} =\exp(\dfrac{1}{2} \left(\int_{z_0}^z \dfrac{g'(z)}{g(z)} dz + L(z_0)\right))$$ By the argument principle, this is a single valued function on $D$ as long as $D$ does not allow the path from $z_0$ to $z$ to loop around an odd number of zeros of $g$. This can be prevented by pairing up the zeros with a branch cut. For an odd number of zeroes, the left over one can be connected to the point at infinity. So any combination of branch cuts that connects two of the zeros, and the third zero to the point at infinity will make $\sqrt{g(z)}$ single valued. Similarly, $\sqrt[n]{g(z)}$ would require the branch cuts to group $n$-zeroes at a time, to prevent any loops around $k$-zeroes for $k<n$. If there is any shortage, $\infty$  fire one branch cut off to infinity.",,"['complex-analysis', 'reference-request', 'multivalued-functions']"
29,How and why did Weierstrass $\wp$ get its special symbol?,How and why did Weierstrass  get its special symbol?,\wp,"I kind of always hated drawing the Weierstrass $\wp$ symbol by hand, and it struck me as odd how and why it achieved its special status in the first place. After all, there are tons of other important functions throughout different areas of math, but very few (if any) get special symbols; even in complex analysis, other functions, e.g., Riemann $\zeta$, are more famous than $\wp$. (I'm not very deep into complex analysis so I can't claim that $\wp$ is necessarily less important than $\zeta$.) Could anyone please provide a bit of historical notes on Weierstrass $\wp$? A quick Google search yields a Google Books result , but the account is woefully short and doesn't seem to explain anything.","I kind of always hated drawing the Weierstrass $\wp$ symbol by hand, and it struck me as odd how and why it achieved its special status in the first place. After all, there are tons of other important functions throughout different areas of math, but very few (if any) get special symbols; even in complex analysis, other functions, e.g., Riemann $\zeta$, are more famous than $\wp$. (I'm not very deep into complex analysis so I can't claim that $\wp$ is necessarily less important than $\zeta$.) Could anyone please provide a bit of historical notes on Weierstrass $\wp$? A quick Google search yields a Google Books result , but the account is woefully short and doesn't seem to explain anything.",,"['complex-analysis', 'notation', 'math-history']"
30,Finding general harmonic polynomial of form $ax^3+bx^2y+cxy^2+dy^3$.,Finding general harmonic polynomial of form .,ax^3+bx^2y+cxy^2+dy^3,"I'm trying to find the most general harmonic polynomial of form $ax^3+bx^2y+cxy^2+dy^3$. I write this polynomial as $u(x,y)$. I calculate $$ \frac{\partial^2 u}{\partial x^2}=6ax+2by,\qquad \frac{\partial^2 u}{\partial y^2}=2cx+6dy $$ and conclude $3a+c=0=b+3d$. Does this just mean the most general harmonic polynomial has form $ax^3-3dx^2y-3axy^2+dy^3$ with the above condition on the coefficients? ""Most general"" is what my book states, and I'm not quite sure what it means. Also, I want to find the conjugate harmonic function, say $v$. I set $\frac{\partial v}{\partial y}=\frac{\partial u}{\partial x}$ and $\frac{\partial v}{\partial x}=-\frac{\partial u}{\partial y}$ and find $$ v=dx^3+3ax^2y+bxy^2-ay^3+K $$ for some constant $K$. By integrating $\frac{\partial v}{\partial x}$, finding $v$ as some polynomial in $x$ and $y$ plus some function in $y$, and then differentiating with respect to $y$ to determine that function in $y$ up to a constant. Is this the right approach? Finally, the question asks for the corresponding analytic function. Is that just $u(x,y)+iv(x,y)$? Or something else? Thanks for taking the time to read this.","I'm trying to find the most general harmonic polynomial of form $ax^3+bx^2y+cxy^2+dy^3$. I write this polynomial as $u(x,y)$. I calculate $$ \frac{\partial^2 u}{\partial x^2}=6ax+2by,\qquad \frac{\partial^2 u}{\partial y^2}=2cx+6dy $$ and conclude $3a+c=0=b+3d$. Does this just mean the most general harmonic polynomial has form $ax^3-3dx^2y-3axy^2+dy^3$ with the above condition on the coefficients? ""Most general"" is what my book states, and I'm not quite sure what it means. Also, I want to find the conjugate harmonic function, say $v$. I set $\frac{\partial v}{\partial y}=\frac{\partial u}{\partial x}$ and $\frac{\partial v}{\partial x}=-\frac{\partial u}{\partial y}$ and find $$ v=dx^3+3ax^2y+bxy^2-ay^3+K $$ for some constant $K$. By integrating $\frac{\partial v}{\partial x}$, finding $v$ as some polynomial in $x$ and $y$ plus some function in $y$, and then differentiating with respect to $y$ to determine that function in $y$ up to a constant. Is this the right approach? Finally, the question asks for the corresponding analytic function. Is that just $u(x,y)+iv(x,y)$? Or something else? Thanks for taking the time to read this.",,"['complex-analysis', 'functions']"
31,Why is there no continuous log function on $\mathbb{C}\setminus\{0\}$?,Why is there no continuous log function on ?,\mathbb{C}\setminus\{0\},"Over the years, I've often heard that there is no logarithm function which is continuous on $\mathbb{C}\setminus\{0\}$. The usual explanation is usually some handwavey argument about following such a function around the unit circle, and getting a contradiction at $e^{2\pi i}$ or something. I've been a little unsatisfied with these. What is a more formal, rigorous proof that there is no continuous log function on $\mathbb{C}\setminus\{0\}$ that is understandable to a nonexpert? Thanks.","Over the years, I've often heard that there is no logarithm function which is continuous on $\mathbb{C}\setminus\{0\}$. The usual explanation is usually some handwavey argument about following such a function around the unit circle, and getting a contradiction at $e^{2\pi i}$ or something. I've been a little unsatisfied with these. What is a more formal, rigorous proof that there is no continuous log function on $\mathbb{C}\setminus\{0\}$ that is understandable to a nonexpert? Thanks.",,"['complex-analysis', 'functions']"
32,Complex analysis book for Algebraic Geometers,Complex analysis book for Algebraic Geometers,,I know that there exist many questions on this site on complex analysis books but my question is more specific than that. I am looking for recommendations for a concise complex analysis book but with a view towards algebraic geometry/ complex manifolds . I have studied smooth manifold theory before and it would be interesting to see it combined with complex analysis in the complex setting (all manifolds that I'd studied before were real manifolds). Any recommendations for such a book?,I know that there exist many questions on this site on complex analysis books but my question is more specific than that. I am looking for recommendations for a concise complex analysis book but with a view towards algebraic geometry/ complex manifolds . I have studied smooth manifold theory before and it would be interesting to see it combined with complex analysis in the complex setting (all manifolds that I'd studied before were real manifolds). Any recommendations for such a book?,,['complex-analysis']
33,entire bijection of $\mathbb{C}$ with 2 fixed points,entire bijection of  with 2 fixed points,\mathbb{C},"Besides the identity map, is there an entire function $f$ that is a bijection from $\mathbb{C}$ to $\mathbb{C}$ and has 2 fixed points? Thank you for the help.","Besides the identity map, is there an entire function $f$ that is a bijection from $\mathbb{C}$ to $\mathbb{C}$ and has 2 fixed points? Thank you for the help.",,['complex-analysis']
34,Is the complex function $f(z) = Re(z)$ differentiable?,Is the complex function  differentiable?,f(z) = Re(z),"I am preparing to take my first course in complex variables. I am reading some lecture notes online.  They claim that the function $f(z) = Re(z)$ is continuous but NOT differentiable.  I know the definitions of a limit, of continuity, and of a derivative.  I understand why this function is continuous.  I am trying to show that it is NOT differentiable.","I am preparing to take my first course in complex variables. I am reading some lecture notes online.  They claim that the function $f(z) = Re(z)$ is continuous but NOT differentiable.  I know the definitions of a limit, of continuity, and of a derivative.  I understand why this function is continuous.  I am trying to show that it is NOT differentiable.",,['complex-analysis']
35,Every harmonic function is the real part of a holomorphic function,Every harmonic function is the real part of a holomorphic function,,Is there a way to show that every harmonic function is the real part of a holomorphic function without using integration equations if later theorems are allowed also?,Is there a way to show that every harmonic function is the real part of a holomorphic function without using integration equations if later theorems are allowed also?,,"['analysis', 'complex-analysis']"
36,Does there exists an entire function $f: \mathbb C \to \mathbb C$ which is bounded on real line and imaginary line?,Does there exists an entire function  which is bounded on real line and imaginary line?,f: \mathbb C \to \mathbb C,"Does there exists a nonconstant entire function $f: \mathbb C \to \mathbb C$  which is bounded on real line and imaginary line? Clearly,$ f(z)=sin(z)$ is an example of an entire function which is bounded on real line and $ f(z)= e^z$ is example of a function which is bounded on imaginary line.But I'm unable to find a function which is bounded on both the lines.Any ideas?","Does there exists a nonconstant entire function $f: \mathbb C \to \mathbb C$  which is bounded on real line and imaginary line? Clearly,$ f(z)=sin(z)$ is an example of an entire function which is bounded on real line and $ f(z)= e^z$ is example of a function which is bounded on imaginary line.But I'm unable to find a function which is bounded on both the lines.Any ideas?",,['complex-analysis']
37,$\int_0^\infty\frac{\log x dx}{x^2-1}$ with a hint.,with a hint.,\int_0^\infty\frac{\log x dx}{x^2-1},"I have to calculate $$\int_0^\infty\frac{\log x dx}{x^2-1},$$ and the hint is to integrate $\frac{\log z}{z^2-1}$ over the boundary of the domain $$\{z\,:\,r<|z|<R,\,\Re (z)>0,\,\Im (z)>0\}.$$ I don't understand. The boundary of this domain has a pole of the integrand in it, doesn't it? Doesn't it make this method useless?","I have to calculate $$\int_0^\infty\frac{\log x dx}{x^2-1},$$ and the hint is to integrate $\frac{\log z}{z^2-1}$ over the boundary of the domain $$\{z\,:\,r<|z|<R,\,\Re (z)>0,\,\Im (z)>0\}.$$ I don't understand. The boundary of this domain has a pole of the integrand in it, doesn't it? Doesn't it make this method useless?",,"['complex-analysis', 'improper-integrals', 'contour-integration']"
38,Conformal map from a lune to the unit disc in $\mathbb{C}$,Conformal map from a lune to the unit disc in,\mathbb{C},"On my complex analysis prelim this morning I was asked to give a conformal map from the region $L=\{z\in\mathbb{C}:|z-i|<\sqrt{2},|z+i|<\sqrt{2}\}$, a lune with vertices at $-1$ and $1$ to the unit disc $\mathbb{D}=\{z:|z|<1\}$.  I tried to send $L$ to the upper half plane by the Möbius transform sending $(-1,0,1)$ to $(0,i,\infty)$.  Then I composed with the Cayley transformation to get to the unit disc. My question is: does my first map do what I want it to(presuming I calculated it correctly)? To be brief, does the Möbius transform which takes $(-1,0,1)$ to $(0,i,\infty)$ send $L$ to the upper half plane?","On my complex analysis prelim this morning I was asked to give a conformal map from the region $L=\{z\in\mathbb{C}:|z-i|<\sqrt{2},|z+i|<\sqrt{2}\}$, a lune with vertices at $-1$ and $1$ to the unit disc $\mathbb{D}=\{z:|z|<1\}$.  I tried to send $L$ to the upper half plane by the Möbius transform sending $(-1,0,1)$ to $(0,i,\infty)$.  Then I composed with the Cayley transformation to get to the unit disc. My question is: does my first map do what I want it to(presuming I calculated it correctly)? To be brief, does the Möbius transform which takes $(-1,0,1)$ to $(0,i,\infty)$ send $L$ to the upper half plane?",,"['complex-analysis', 'conformal-geometry']"
39,The Riemann Sphere Interpretation,The Riemann Sphere Interpretation,,"Is the Riemann sphere anything more than a simple visual tool to help students understand the complex planes, or the behavior of complex valued functions at infinity, limit points etc? Or is there a practical use in calculations of complex valued functions using the topology or geometry of the the sphere itself?","Is the Riemann sphere anything more than a simple visual tool to help students understand the complex planes, or the behavior of complex valued functions at infinity, limit points etc? Or is there a practical use in calculations of complex valued functions using the topology or geometry of the the sphere itself?",,"['complex-analysis', 'riemannian-geometry', 'riemann-sphere']"
40,Is $\frac{1}{\exp(z)} - \frac{1}{\exp(\exp(z))} + \frac{1}{\exp(\exp(\exp(z)))} -\ldots$ entire?,Is  entire?,\frac{1}{\exp(z)} - \frac{1}{\exp(\exp(z))} + \frac{1}{\exp(\exp(\exp(z)))} -\ldots,"Let $z$ be a complex number. Is the alternating infinite series $$ f(z) = \frac{1}{\exp(z)} - \frac{1}{\exp(\exp(z))} + \frac{1}{\exp(\exp(\exp(z)))} -\dotsb $$ an entire function ? Does it even converge everywhere ? Additional questions (added dec 16) Consider the similar case for $z$ being real or having a small imaginary part: $$ g(z) = \frac{1}{z} +  \frac{1}{\exp(z)} + \frac{1}{\exp(\exp(z))} + \frac{1}{\exp(\exp(\exp(z)))} + \dotsb$$ As such $g(z)$ converges for real $z$ but diverges for nonreals. So we try Some sort of continuation: $$ g(z) = 1/z + 1/\exp + \dotsb$$ $$g(\exp) = 1/\exp + \dotsb $$ Thus $ g(z) - g(\exp(z) ) = 1/z $ $$ \exp(z) = g^{[-1]} ( g(z) - 1/z ) $$ Call that solution $g_1(z)$. Assume differentiability and take the derivative at both sides. (Notice we can repeat to get infinite many equations!) $$ \exp(z) = \frac{d}{dz} g^{[-1]} ( g(z) - 1/z) $$  [ ofcourse we can simplify the RHS by applying the chain rule and the rule for the derivative of the functional inverse - name ? - ] And in General the equations $$ exp(z) = \frac{d^m}{dz^m} g^{[-1]} ( g(z) - 1/z ) $$ Point is: are these equations getting analytic solutions or not? Also we could combine the equations to get new ones. Like this for example : $$ g^{[-1]} ( g(z) - 1/z ) = \frac{d}{dz} g^{[-1]} ( g(z) - 1/z ) $$ And we could continue by taking any positive integer number of $a$ th derivative on the LHS and any positive integer number of $b$ th derivative on the RHS ! So are all these equations nowhere analytic ??  Or Some ? Or all of them ? And when they are analytic is it possible to do analytic continuation ? Are there natural boundaries ?? Many questions. In fact ; not even sure how to solve these equations , neither with expressions nor numerical. - in terms of complex Numbers ofcourse otherwise i simply use the Sum from the beginning -. < ps i considered using the functional inverse of $ g $ with notation $G$ so the simplifications of the derivatives take a different form , yet this makes no essential difference i guess >","Let $z$ be a complex number. Is the alternating infinite series $$ f(z) = \frac{1}{\exp(z)} - \frac{1}{\exp(\exp(z))} + \frac{1}{\exp(\exp(\exp(z)))} -\dotsb $$ an entire function ? Does it even converge everywhere ? Additional questions (added dec 16) Consider the similar case for $z$ being real or having a small imaginary part: $$ g(z) = \frac{1}{z} +  \frac{1}{\exp(z)} + \frac{1}{\exp(\exp(z))} + \frac{1}{\exp(\exp(\exp(z)))} + \dotsb$$ As such $g(z)$ converges for real $z$ but diverges for nonreals. So we try Some sort of continuation: $$ g(z) = 1/z + 1/\exp + \dotsb$$ $$g(\exp) = 1/\exp + \dotsb $$ Thus $ g(z) - g(\exp(z) ) = 1/z $ $$ \exp(z) = g^{[-1]} ( g(z) - 1/z ) $$ Call that solution $g_1(z)$. Assume differentiability and take the derivative at both sides. (Notice we can repeat to get infinite many equations!) $$ \exp(z) = \frac{d}{dz} g^{[-1]} ( g(z) - 1/z) $$  [ ofcourse we can simplify the RHS by applying the chain rule and the rule for the derivative of the functional inverse - name ? - ] And in General the equations $$ exp(z) = \frac{d^m}{dz^m} g^{[-1]} ( g(z) - 1/z ) $$ Point is: are these equations getting analytic solutions or not? Also we could combine the equations to get new ones. Like this for example : $$ g^{[-1]} ( g(z) - 1/z ) = \frac{d}{dz} g^{[-1]} ( g(z) - 1/z ) $$ And we could continue by taking any positive integer number of $a$ th derivative on the LHS and any positive integer number of $b$ th derivative on the RHS ! So are all these equations nowhere analytic ??  Or Some ? Or all of them ? And when they are analytic is it possible to do analytic continuation ? Are there natural boundaries ?? Many questions. In fact ; not even sure how to solve these equations , neither with expressions nor numerical. - in terms of complex Numbers ofcourse otherwise i simply use the Sum from the beginning -. < ps i considered using the functional inverse of $ g $ with notation $G$ so the simplifications of the derivatives take a different form , yet this makes no essential difference i guess >",,"['complex-analysis', 'convergence-divergence', 'complex-dynamics']"
41,Logarithm of absolute value of a holomorphic function harmonic?,Logarithm of absolute value of a holomorphic function harmonic?,,"Let $f:U\rightarrow\mathbb{C}$ be holomorphic on some open domain $U\subset\hat{\mathbb{C}}=\mathbb{C}\cup\{\infty\}$ and $f(z)\not=0$ for $z\in U$. Is it true that $z\mapsto \log(|f(z)|)$ is harmonic on $U$ ? I guess the answer is yes and if that is true, how can I see that without a long and nasty calculation?","Let $f:U\rightarrow\mathbb{C}$ be holomorphic on some open domain $U\subset\hat{\mathbb{C}}=\mathbb{C}\cup\{\infty\}$ and $f(z)\not=0$ for $z\in U$. Is it true that $z\mapsto \log(|f(z)|)$ is harmonic on $U$ ? I guess the answer is yes and if that is true, how can I see that without a long and nasty calculation?",,['complex-analysis']
42,About the limit of the coefficient ratio for a power series over complex numbers,About the limit of the coefficient ratio for a power series over complex numbers,,"This is my first question in mathSE, hope that it is suitable here! I'm currently self-studying complex analysis using the book by Stein & Shakarchi, and this is one of the exercises (p.67, Q14) that I have no idea where to start. Suppose $f$ is holomorphic in an open set $\Omega$ that contains the closed unit disc, except for a pole at $z_0$ on the unit circle. Show that if $f$ has the power series expansion $\sum_{n=0}^\infty a_n z^n$ in the open unit disc, then $\displaystyle \lim_{n \to \infty} \frac{a_n}{a_{n+1}} = z_0$. If the limit is taking on $|\frac{a_n}{a_{n+1}}|$ and assume the limit exists, by the radius of convergence we know that the answer is $1$. But what can we say about the limit of the coefficient ratio, which is a pure complex number? I've tried to expand the limit directly by definition, with no luck. And I couldn't see how we can apply any of the standard theorems in complex analysis. I hope to get some initial directions about how we can start thinking on the problem, rather than a full answer. Thank you for the help!","This is my first question in mathSE, hope that it is suitable here! I'm currently self-studying complex analysis using the book by Stein & Shakarchi, and this is one of the exercises (p.67, Q14) that I have no idea where to start. Suppose $f$ is holomorphic in an open set $\Omega$ that contains the closed unit disc, except for a pole at $z_0$ on the unit circle. Show that if $f$ has the power series expansion $\sum_{n=0}^\infty a_n z^n$ in the open unit disc, then $\displaystyle \lim_{n \to \infty} \frac{a_n}{a_{n+1}} = z_0$. If the limit is taking on $|\frac{a_n}{a_{n+1}}|$ and assume the limit exists, by the radius of convergence we know that the answer is $1$. But what can we say about the limit of the coefficient ratio, which is a pure complex number? I've tried to expand the limit directly by definition, with no luck. And I couldn't see how we can apply any of the standard theorems in complex analysis. I hope to get some initial directions about how we can start thinking on the problem, rather than a full answer. Thank you for the help!",,"['complex-analysis', 'power-series']"
43,Complex vs. Real Differentiable,Complex vs. Real Differentiable,,"I can follow and understand the algebra in the proof that a $\mathbb{R}$ differentiable function is $\mathbb{C}$ differentaible if and only if the partial$\left(\frac{\partial f}{\partial x}\right)$ -$\frac{1}{i}$ $\left(\frac{\partial f}{\partial y}\right)$  $ = 0$. But I can't picture this.  Treating points in the complex plane like vectors in $\mathbb{R^2}$, if a function is differentiable in $\mathbb{R^2}$, why, geometrically, is it not always holomorphic?","I can follow and understand the algebra in the proof that a $\mathbb{R}$ differentiable function is $\mathbb{C}$ differentaible if and only if the partial$\left(\frac{\partial f}{\partial x}\right)$ -$\frac{1}{i}$ $\left(\frac{\partial f}{\partial y}\right)$  $ = 0$. But I can't picture this.  Treating points in the complex plane like vectors in $\mathbb{R^2}$, if a function is differentiable in $\mathbb{R^2}$, why, geometrically, is it not always holomorphic?",,['complex-analysis']
44,Help to understand the generalization of the Argument Principle,Help to understand the generalization of the Argument Principle,,I'm reading Conway's complex analysis book and I'm trying to prove this theorem left to the reader on page 124: I tried to use integration by parts without success. I need some hint how prove this theorem.,I'm reading Conway's complex analysis book and I'm trying to prove this theorem left to the reader on page 124: I tried to use integration by parts without success. I need some hint how prove this theorem.,,['complex-analysis']
45,Can a meromorphic function be written as ratio of holomorphic function?,Can a meromorphic function be written as ratio of holomorphic function?,,"Well, I want to know whether a meromorphic function can be written as ratio of two holomorphic function on $\mathbb{C}$ or on a Riemann surface . Thank you for help.","Well, I want to know whether a meromorphic function can be written as ratio of two holomorphic function on $\mathbb{C}$ or on a Riemann surface . Thank you for help.",,"['complex-analysis', 'riemann-surfaces']"
46,Entire functions such that $f(z^{2})=f(z)^{2}$,Entire functions such that,f(z^{2})=f(z)^{2},"I'm having trouble solving this one. Could you help me? Characterize the entire functions such that $f(z^{2})=f(z)^{2}$ for all $z\in \mathbb{C}$.  Hint: Divide in the cases $f(0)=1$ and $f(0)=0$. For the first case prove ( I've alredy done this ) and use that $f(z^{2^{n}})= f(z)^{2^{n}}$ for all $n$ natural to see that $f$ is constant. For the second case, if $f$ is not identically zero, then $f$ has a zero in $z=0$ of order $m\geq 1$.","I'm having trouble solving this one. Could you help me? Characterize the entire functions such that $f(z^{2})=f(z)^{2}$ for all $z\in \mathbb{C}$.  Hint: Divide in the cases $f(0)=1$ and $f(0)=0$. For the first case prove ( I've alredy done this ) and use that $f(z^{2^{n}})= f(z)^{2^{n}}$ for all $n$ natural to see that $f$ is constant. For the second case, if $f$ is not identically zero, then $f$ has a zero in $z=0$ of order $m\geq 1$.",,"['complex-analysis', 'functional-equations']"
47,Detecting a negative coefficient in a power series,Detecting a negative coefficient in a power series,,"Suppose that I have an analytic function $f(z)=\sum_{n=0}^\infty a_n z^n$ which converges on some disk around the origin. For a particular function I encountered, I wished to prove that every coefficient, $a_n$, is non-negative. I am wondering what complex analytic methods exist to detect negative coefficients if all my coefficients are real.  What nice ways are there to check if all of the coefficients of my power series are the same sign? In more generality, are there methods which detect whether eventually all of the coefficients are of the same sign?  (That is, whether or not there exists $N$ such that for all $n,m>N$, $a_n$ and $a_m$ will be the same sign) I am really interested in any, and many, thoughts on this problem.  What strategies could possibly work? Thanks!","Suppose that I have an analytic function $f(z)=\sum_{n=0}^\infty a_n z^n$ which converges on some disk around the origin. For a particular function I encountered, I wished to prove that every coefficient, $a_n$, is non-negative. I am wondering what complex analytic methods exist to detect negative coefficients if all my coefficients are real.  What nice ways are there to check if all of the coefficients of my power series are the same sign? In more generality, are there methods which detect whether eventually all of the coefficients are of the same sign?  (That is, whether or not there exists $N$ such that for all $n,m>N$, $a_n$ and $a_m$ will be the same sign) I am really interested in any, and many, thoughts on this problem.  What strategies could possibly work? Thanks!",,"['complex-analysis', 'big-list', 'power-series']"
48,Counterexamples in complex analysis,Counterexamples in complex analysis,,"In contrast to other topics in analysis such as functional analysis with its vast amount of counterexamples to intuitively correct looking statements (see here for an example), everything in complex analysis seems to be very well-behaved (for example holomorphic functions are always analytic). But is this maxim always right? Do you know any holomorphic functions which behave in a way one wouldn't expect at first sight? EDIT: As you can see in the answers, I came up with something myself. But I would be glad if you knew more examples where strange stuff happens.","In contrast to other topics in analysis such as functional analysis with its vast amount of counterexamples to intuitively correct looking statements (see here for an example), everything in complex analysis seems to be very well-behaved (for example holomorphic functions are always analytic). But is this maxim always right? Do you know any holomorphic functions which behave in a way one wouldn't expect at first sight? EDIT: As you can see in the answers, I came up with something myself. But I would be glad if you knew more examples where strange stuff happens.",,"['complex-analysis', 'big-list', 'examples-counterexamples']"
49,Derivative and partial derivative of complex functions,Derivative and partial derivative of complex functions,,"I know the formal definition of a derivative of a complex valued function, and how to compute it (same as how I would for real-valued functions), but after doing some problems, I feel as if I could just take the partial derivative w.r.t $x$ of the function to compute the derivative (so it doesn't depend on $y$ ?) as opposed to taking derivative w.r.t $z$ first then substitute. That might be a bit obscure, so I'll put in a couple of examples Examples All of the examples are analytic (satisfy the Riemann conditions) with $z = x+iy$ and $f(z) = u(x,y)+iv(x,y)$ . $f(z) = z = x+iy =u(x,y) + iv(x,y)$ . The derivative is $f'(z) = 1$ . Another way would be just to take partials of $f(z)$ w.r.t $x$ to get the result. $f(z) = z^2 = (x+iy)^2 = x^2 - y^2 + 2ixy$ $f'(z) = 2z = 2x + 2iy$ Another way is to just directly take partial derivative of $f$ w.r.t $x$ since $\frac{\partial u}{\partial x} = 2x$ and $\frac{\partial v}{\partial x} = 2y$ . $f(z) = z^3 = (x+iy)^3 = x^3 - 3xy^2 + i(3x^2 y - y^3)$ . $ f'(z) = 3z^2 = 3x^2 -3y^2 + 6ixy$ . This can also be found similarly in other examples since $\frac{\partial u}{\partial x} = 3x^2 - 3 y^2$ and $\frac{\partial v}{\partial x} = 6xy$ . So it seems that I could just take the partial derivatives with respect to $x$ of the resultant complex number, and ignore the $y$ to find the derivatives. How come this is true?","I know the formal definition of a derivative of a complex valued function, and how to compute it (same as how I would for real-valued functions), but after doing some problems, I feel as if I could just take the partial derivative w.r.t of the function to compute the derivative (so it doesn't depend on ?) as opposed to taking derivative w.r.t first then substitute. That might be a bit obscure, so I'll put in a couple of examples Examples All of the examples are analytic (satisfy the Riemann conditions) with and . . The derivative is . Another way would be just to take partials of w.r.t to get the result. Another way is to just directly take partial derivative of w.r.t since and . . . This can also be found similarly in other examples since and . So it seems that I could just take the partial derivatives with respect to of the resultant complex number, and ignore the to find the derivatives. How come this is true?","x y z z = x+iy f(z) = u(x,y)+iv(x,y) f(z) = z = x+iy =u(x,y) + iv(x,y) f'(z) = 1 f(z) x f(z) = z^2 = (x+iy)^2 = x^2 - y^2 + 2ixy f'(z) = 2z = 2x + 2iy f x \frac{\partial u}{\partial x} = 2x \frac{\partial v}{\partial x} = 2y f(z) = z^3 = (x+iy)^3 = x^3 - 3xy^2 + i(3x^2 y - y^3)  f'(z) = 3z^2 = 3x^2 -3y^2 + 6ixy \frac{\partial u}{\partial x} = 3x^2 - 3 y^2 \frac{\partial v}{\partial x} = 6xy x y",['complex-analysis']
50,Arnold's proof of Abel's theorem,Arnold's proof of Abel's theorem,,"I'm seeking help understanding this video . The author considers the equation $ax^5+bx^4+cx^3+dx^2+ex+f = 0$ and shows both the coefficients $a, b$... and solutions $x_1, x_2$... in the complex plane. The author claims that if the coefficients are varied, moving them along short loops so they return to their original values and the solutions don't return to their original values, but instead exchange places, an expression for the solution cannot be found. What is the significance of the solutions not returning to themselves?","I'm seeking help understanding this video . The author considers the equation $ax^5+bx^4+cx^3+dx^2+ex+f = 0$ and shows both the coefficients $a, b$... and solutions $x_1, x_2$... in the complex plane. The author claims that if the coefficients are varied, moving them along short loops so they return to their original values and the solutions don't return to their original values, but instead exchange places, an expression for the solution cannot be found. What is the significance of the solutions not returning to themselves?",,"['complex-analysis', 'abelian-groups', 'proof-explanation']"
51,Binomial expansion for $(x+a)^n$ for non-integer n,Binomial expansion for  for non-integer n,(x+a)^n,"I finally figured out that you could differentiate $x^n$ and get $nx^{n-1}$ using the derivative quotient, but that required doing binomial expansion for non-integer values. The most I can find with binomial expansion is the first, second, last, and second to last terms. So how do I find something like $(x+a)^{\pi}$?  When differentiating in calculus, I didn't need to find terms after the second because I knew they would all cancel out, but how do you find these terms? Do they work for negative exponents as well? And does this work for complex exponents? Which came first, Euler's method for complex exponents or binomial expansion for complex exponents?","I finally figured out that you could differentiate $x^n$ and get $nx^{n-1}$ using the derivative quotient, but that required doing binomial expansion for non-integer values. The most I can find with binomial expansion is the first, second, last, and second to last terms. So how do I find something like $(x+a)^{\pi}$?  When differentiating in calculus, I didn't need to find terms after the second because I knew they would all cancel out, but how do you find these terms? Do they work for negative exponents as well? And does this work for complex exponents? Which came first, Euler's method for complex exponents or binomial expansion for complex exponents?",,"['complex-analysis', 'algebra-precalculus', 'binomial-theorem']"
52,"Apollonius circle, its radius and center","Apollonius circle, its radius and center",,"I've got the following set: $\{|z-a|=k|z-b|\}$ , where z is a complex number, a an b are fixed, and $k>0$ , $k \ne 1$ . I need to prove that this is a circle (called Apollonius circle). I also have to prove that this circle's radius is equal to $k|a-b||1-k^2|^{-1}$ and it's centre is $(a-k^2b)(1-k^2)^{-1}$ . I don't know what to do. I've tried to work with the analytic circle equation ( $|z-c|^2=r^2$ ), substituting given radius and center, but it didn't work. I also tried to square both sides of the first given equation ( $|z-a|=k|z-b|$ ), which usually works with complex number, but also didn't get any result... Can somebody show me how to solve this problem? I will be very grateful.","I've got the following set: , where z is a complex number, a an b are fixed, and , . I need to prove that this is a circle (called Apollonius circle). I also have to prove that this circle's radius is equal to and it's centre is . I don't know what to do. I've tried to work with the analytic circle equation ( ), substituting given radius and center, but it didn't work. I also tried to square both sides of the first given equation ( ), which usually works with complex number, but also didn't get any result... Can somebody show me how to solve this problem? I will be very grateful.",\{|z-a|=k|z-b|\} k>0 k \ne 1 k|a-b||1-k^2|^{-1} (a-k^2b)(1-k^2)^{-1} |z-c|^2=r^2 |z-a|=k|z-b|,"['complex-analysis', 'complex-numbers']"
53,The action of SU(2) on the Riemann sphere,The action of SU(2) on the Riemann sphere,,"One way to get the famous double cover $\text{SU}(2) \to \text{SO}(3)$ is to note that $\text{SU}(2)$ is isomorphic to the group of unit quaternions and to let unit quaternions $q$ act on the subspace $V$ of $\mathbb{H}$ spanned by $i, j, k$ via conjugation $t \mapsto qtq^{-1}$; this preserves the norm.  (Alternately, this is the adjoint action on the Lie algebra, which preserves the Killing form.) Another way to do this is to let $\text{SU}(2)$ act on $\mathbb{P}^1(\mathbb{C})$, which is diffeomorphic to the sphere.  This gives an action of $\text{SU}(2)$ by conformal automorphisms.  However, I don't know how to prove that $\text{SU}(2)$ actually acts by rotations (at least, not without some explicit and unenlightening calculations). To be more precise, if we fix an inner product on $\mathbb{C}^2$, then the space of lines in $\mathbb{C}^2$ can be given the Fubini-Study metric , which $\text{SU}(2)$ preserves.  But how can I prove that the Fubini-Study metric agrees with the natural metric on the sphere (up to a constant)?","One way to get the famous double cover $\text{SU}(2) \to \text{SO}(3)$ is to note that $\text{SU}(2)$ is isomorphic to the group of unit quaternions and to let unit quaternions $q$ act on the subspace $V$ of $\mathbb{H}$ spanned by $i, j, k$ via conjugation $t \mapsto qtq^{-1}$; this preserves the norm.  (Alternately, this is the adjoint action on the Lie algebra, which preserves the Killing form.) Another way to do this is to let $\text{SU}(2)$ act on $\mathbb{P}^1(\mathbb{C})$, which is diffeomorphic to the sphere.  This gives an action of $\text{SU}(2)$ by conformal automorphisms.  However, I don't know how to prove that $\text{SU}(2)$ actually acts by rotations (at least, not without some explicit and unenlightening calculations). To be more precise, if we fix an inner product on $\mathbb{C}^2$, then the space of lines in $\mathbb{C}^2$ can be given the Fubini-Study metric , which $\text{SU}(2)$ preserves.  But how can I prove that the Fubini-Study metric agrees with the natural metric on the sphere (up to a constant)?",,"['complex-analysis', 'lie-groups']"
54,Space of Germs of Holomorphic Function,Space of Germs of Holomorphic Function,,"A bit of a general question, but here goes. Morally, what is the space of germs of a holomorphic function? I know that a germ is simply an equivalence class of function elements, where we regard two function elements as equivalent at a point if they agree on some open neighbourhood of that point. Moreover I know the definition that the space of germs is simply the union of these equivalence classes for all functions $f$ and points $x$. This is all a bit abstract at the moment though. I can't see how germs are useful, or how I might calculate them for a concrete function. Has anyone got any nice examples of calculations of the space of germs? And could someone explain the overarching idea behind them in Riemann Surfaces? Many thanks.","A bit of a general question, but here goes. Morally, what is the space of germs of a holomorphic function? I know that a germ is simply an equivalence class of function elements, where we regard two function elements as equivalent at a point if they agree on some open neighbourhood of that point. Moreover I know the definition that the space of germs is simply the union of these equivalence classes for all functions $f$ and points $x$. This is all a bit abstract at the moment though. I can't see how germs are useful, or how I might calculate them for a concrete function. Has anyone got any nice examples of calculations of the space of germs? And could someone explain the overarching idea behind them in Riemann Surfaces? Many thanks.",,"['complex-analysis', 'riemann-surfaces']"
55,Why doesn't $\frac 1 z$ have an antiderivative in $\mathbb{C}\setminus\{0\}$?,Why doesn't  have an antiderivative in ?,\frac 1 z \mathbb{C}\setminus\{0\},"Why doesn't $\frac 1 z$ have an antiderivative in $\mathbb{C}\setminus\{0\}$? I understand that the antiderivative could've been $\operatorname{Log}(z)$, but it always has atleast one branch cut. But what if we modify the domain of the $\operatorname{Log}$ function to $-\pi < \theta \leqslant \pi $? Doesn't this make the anti-derivative of $\frac 1 z$ definable? Although this antiderivative will be discontinuous, but still valid. So, why is this not the case? Edit: Can we answer this question without invoking the Fundamental Theorem of Contour Integration?","Why doesn't $\frac 1 z$ have an antiderivative in $\mathbb{C}\setminus\{0\}$? I understand that the antiderivative could've been $\operatorname{Log}(z)$, but it always has atleast one branch cut. But what if we modify the domain of the $\operatorname{Log}$ function to $-\pi < \theta \leqslant \pi $? Doesn't this make the anti-derivative of $\frac 1 z$ definable? Although this antiderivative will be discontinuous, but still valid. So, why is this not the case? Edit: Can we answer this question without invoking the Fundamental Theorem of Contour Integration?",,['complex-analysis']
56,Solving an integral coming from Perron's formula,Solving an integral coming from Perron's formula,,"In analytic number theory, Perron's formula says that  $$ \sum_{1 \leq k < n} a_k + \frac{1}{2}a_n = \int_{c - i\infty}^{c+i\infty} f(s)\frac{n^s}{s}ds,  $$ where $f(s) = \sum_{k \geq 1} a_k/k^s$ and $c$ is greater than the abscissa of convergence  of $f(s)$.  My question is whether Perron's formula can be used as the first step in a derivation of the formula for  a sum of powers of the first $n$ integers. Specifically, for any positive integer $m$, Perron's formula  for $f(s) = \zeta(s-m) = \sum_{k \geq 1} k^m/k^s$ says  $$\sum_{k=1}^n k^m = \frac{1}{2}n^m+\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\zeta(s-m)\frac{n^s}{s}ds$$  for any $c>m+1$.  The integrand $\zeta(s-m)n^s/s$ has poles at $s = 0$ and $s = m+1$. If we formally shift the line of integration to the left across the pole at $s = m+1$, then a formal use of the residue theorem gives us  $$ \sum_{k=1}^n k^m = \frac{1}{m+1}n^{m+1} + \frac{1}{2}n^m+\frac{1}{2\pi i}\int_{b-i\infty}^{b+i\infty}\zeta(s-m)\frac{n^s}{s}ds $$  for $b < m+1$.  When $m-1/2 < b < m+1$, I can justify this shift (i.e., if I truncate the integral on the top and bottom and make a rectangle  with sides along $x = c$ and $x = b$, the integrals along the top and bottom go to 0 as the height of the rectangle goes to $\pm \infty$). The two powers of $n$ on the right side are exactly the first two dominant terms in the standard formula for power sums  in terms of Bernoulli numbers:  $$\sum_{k=1}^n k^m =  \sum_{j=0}^{m} \dbinom{m}{j}\frac{B_{m-j}}{j+1}n^{j+1} =  \frac{1}{m+1}n^{m+1}+\frac{1}{2}n^m + \sum_{j=0}^{m-2} \dbinom{m}{j}\frac{B_{m-j}}{j+1}n^{j+1}.  $$ What I'd like to know is if anyone sees a way to extract all lower order terms in this standard formula from the integral  along the line ${\rm Re}(s) = b$ when $m-1/2 < b  < m+1$. That is, could one show $$ \frac{1}{2\pi i}\int_{b-i\infty}^{b+i\infty}\zeta(s-m)\frac{n^s}{s}ds = \sum_{j=0}^{m-2} \dbinom{m}{j}\frac{B_{m-j}}{j+1}n^{j+1} $$ by some method that is independent of knowledge of the power sum formula?  For concreteness, the first four cases of the standard power sum formula are  \begin{eqnarray*} \sum_{k=1}^n k &=& \frac{1}{2}n^2+\frac{1}{2}n, \\ \sum_{k=1}^n k^2 &=& \frac{1}{3}n^3+\frac{1}{2}n^2 + \frac{1}{6}n, \\ \sum_{k=1}^n k^3 &=& \frac{1}{4}n^4+\frac{1}{2}n^3 + \frac{1}{4}n^2, \\  \sum_{k=1}^n k^4 &=& \frac{1}{5}n^5+\frac{1}{2}n^4 + \frac{1}{3}n^3-\frac{1}{30}n. \end{eqnarray*} So when $m=1$ the integral is 0, when $m=2$ the integral is $\frac{1}{6}n$, when  $m = 3$ the integral is $\frac{1}{4}n^2$, and when $m = 4$ the integral is $\frac{1}{3}n^3 - \frac{1}{30}{n}$. Is there a way to evaluate the integral directly to recover these computations (thereby leading to an alternate proof of the  power sum formula)?  Or is there at least a way to see that the integral is $O(n^{m-1})$ as $n \rightarrow \infty$? The obvious thing to try is to push the contour further to the left, past more poles.  Even if that could be justified (is it valid?), the only pole remaining in $\zeta(s-m)n^s/s$ is at $s = 0$, where the residue is $\zeta(-m) = -B_{m+1}/(m+1)$, which doesn't involve $n$ and is not even a term in the power sum formula.  Without poles to work with, I don't see a way to extract any lower order terms from the integral.","In analytic number theory, Perron's formula says that  $$ \sum_{1 \leq k < n} a_k + \frac{1}{2}a_n = \int_{c - i\infty}^{c+i\infty} f(s)\frac{n^s}{s}ds,  $$ where $f(s) = \sum_{k \geq 1} a_k/k^s$ and $c$ is greater than the abscissa of convergence  of $f(s)$.  My question is whether Perron's formula can be used as the first step in a derivation of the formula for  a sum of powers of the first $n$ integers. Specifically, for any positive integer $m$, Perron's formula  for $f(s) = \zeta(s-m) = \sum_{k \geq 1} k^m/k^s$ says  $$\sum_{k=1}^n k^m = \frac{1}{2}n^m+\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\zeta(s-m)\frac{n^s}{s}ds$$  for any $c>m+1$.  The integrand $\zeta(s-m)n^s/s$ has poles at $s = 0$ and $s = m+1$. If we formally shift the line of integration to the left across the pole at $s = m+1$, then a formal use of the residue theorem gives us  $$ \sum_{k=1}^n k^m = \frac{1}{m+1}n^{m+1} + \frac{1}{2}n^m+\frac{1}{2\pi i}\int_{b-i\infty}^{b+i\infty}\zeta(s-m)\frac{n^s}{s}ds $$  for $b < m+1$.  When $m-1/2 < b < m+1$, I can justify this shift (i.e., if I truncate the integral on the top and bottom and make a rectangle  with sides along $x = c$ and $x = b$, the integrals along the top and bottom go to 0 as the height of the rectangle goes to $\pm \infty$). The two powers of $n$ on the right side are exactly the first two dominant terms in the standard formula for power sums  in terms of Bernoulli numbers:  $$\sum_{k=1}^n k^m =  \sum_{j=0}^{m} \dbinom{m}{j}\frac{B_{m-j}}{j+1}n^{j+1} =  \frac{1}{m+1}n^{m+1}+\frac{1}{2}n^m + \sum_{j=0}^{m-2} \dbinom{m}{j}\frac{B_{m-j}}{j+1}n^{j+1}.  $$ What I'd like to know is if anyone sees a way to extract all lower order terms in this standard formula from the integral  along the line ${\rm Re}(s) = b$ when $m-1/2 < b  < m+1$. That is, could one show $$ \frac{1}{2\pi i}\int_{b-i\infty}^{b+i\infty}\zeta(s-m)\frac{n^s}{s}ds = \sum_{j=0}^{m-2} \dbinom{m}{j}\frac{B_{m-j}}{j+1}n^{j+1} $$ by some method that is independent of knowledge of the power sum formula?  For concreteness, the first four cases of the standard power sum formula are  \begin{eqnarray*} \sum_{k=1}^n k &=& \frac{1}{2}n^2+\frac{1}{2}n, \\ \sum_{k=1}^n k^2 &=& \frac{1}{3}n^3+\frac{1}{2}n^2 + \frac{1}{6}n, \\ \sum_{k=1}^n k^3 &=& \frac{1}{4}n^4+\frac{1}{2}n^3 + \frac{1}{4}n^2, \\  \sum_{k=1}^n k^4 &=& \frac{1}{5}n^5+\frac{1}{2}n^4 + \frac{1}{3}n^3-\frac{1}{30}n. \end{eqnarray*} So when $m=1$ the integral is 0, when $m=2$ the integral is $\frac{1}{6}n$, when  $m = 3$ the integral is $\frac{1}{4}n^2$, and when $m = 4$ the integral is $\frac{1}{3}n^3 - \frac{1}{30}{n}$. Is there a way to evaluate the integral directly to recover these computations (thereby leading to an alternate proof of the  power sum formula)?  Or is there at least a way to see that the integral is $O(n^{m-1})$ as $n \rightarrow \infty$? The obvious thing to try is to push the contour further to the left, past more poles.  Even if that could be justified (is it valid?), the only pole remaining in $\zeta(s-m)n^s/s$ is at $s = 0$, where the residue is $\zeta(-m) = -B_{m+1}/(m+1)$, which doesn't involve $n$ and is not even a term in the power sum formula.  Without poles to work with, I don't see a way to extract any lower order terms from the integral.",,"['complex-analysis', 'number-theory', 'analytic-number-theory']"
57,Entire function $f(z)$ grows like $\exp(x^\pi)$ as $x\to+\infty$,Entire function  grows like  as,f(z) \exp(x^\pi) x\to+\infty,"Does there exists an entire function $f(z)$ such that $\lim_{x\to+\infty}f(x)/\exp(x^\pi)=1$ (along the real axis)? I have successfully constructed $f(z)$ when $\pi$ is replaced by a rational number $\frac pq$ . For $\lim_{x\to+\infty}f(x)/\exp(x^{p/q})=1$ , take $$f(z)=\exp(z^{p/q})+\exp(z^{p/q}e^{2/q\pi i})+\exp(z^{p/q}e^{4/q\pi i})+\cdots+\exp(z^{p/q}e^{2(q-1)/q\pi i})$$ It is easy to verify $\lim_{x\to+\infty}f(x)/\exp(x^{p/q})=1$ . Proof of $f(z)$ is entire It is easy to see $f(z^q)$ is entire.   Denote $$g(z)=\exp(z^p)+\exp(z^pe^{2/q\pi i})+\exp(z^pe^{4/q\pi i})+\cdots+\exp(z^pe^{2(q-1)/q\pi i}),$$ $g$ has property $g(z)=g(ze^{2/q\pi i})$ and $f(z)=g(z^{1/q})$ . Let $g(x)=a_0+a_1x+\cdots$ , substituting $g(z)=g(ze^{2/q\pi i})$ repeatedly and solving the simultaneous equation gives $g(x)=a_0+a_qx^q+a_{2q}x^{2q}+\cdots$ . Hence the entirety of $f$ . But for $\pi$ ? I can't take the limit with respect to $p/q$ . I have no idea how to proceed.","Does there exists an entire function such that (along the real axis)? I have successfully constructed when is replaced by a rational number . For , take It is easy to verify . Proof of is entire It is easy to see is entire.   Denote has property and . Let , substituting repeatedly and solving the simultaneous equation gives . Hence the entirety of . But for ? I can't take the limit with respect to . I have no idea how to proceed.","f(z) \lim_{x\to+\infty}f(x)/\exp(x^\pi)=1 f(z) \pi \frac pq \lim_{x\to+\infty}f(x)/\exp(x^{p/q})=1 f(z)=\exp(z^{p/q})+\exp(z^{p/q}e^{2/q\pi i})+\exp(z^{p/q}e^{4/q\pi i})+\cdots+\exp(z^{p/q}e^{2(q-1)/q\pi i}) \lim_{x\to+\infty}f(x)/\exp(x^{p/q})=1 f(z) f(z^q) g(z)=\exp(z^p)+\exp(z^pe^{2/q\pi i})+\exp(z^pe^{4/q\pi i})+\cdots+\exp(z^pe^{2(q-1)/q\pi i}), g g(z)=g(ze^{2/q\pi i}) f(z)=g(z^{1/q}) g(x)=a_0+a_1x+\cdots g(z)=g(ze^{2/q\pi i}) g(x)=a_0+a_qx^q+a_{2q}x^{2q}+\cdots f \pi p/q","['complex-analysis', 'limits', 'entire-functions']"
58,Creating surjective holomorphic map from unit disc to $\mathbb{C}$?,Creating surjective holomorphic map from unit disc to ?,\mathbb{C},"I'm trying to formulate a surjective holomorphic map from the unit disc ($\mathbb{D}$) to $\mathbb{C}$. I know that there exists $f: \mathbb{D} \rightarrow \mathbb{H}$, which is a biholomorphism from the unit disc to the upper half plane. I know that I can define $g(z) = z -i$ to shift the upper half plane down by 1 unit, then I can define $h(z) = z^2$ to square the result. Then, $h \circ g \circ f$ is a holomorphic function $\mathbb{U} \rightarrow \mathbb{C}$. My question is: how does $h(z)$, (i.e. squaring the result of the shifted upper half plane), extend the image to the entire lower half plane? Maybe I'm missing something obvious, but I'm not seeing how $\mathbb{C}$ is hit in its entirety.","I'm trying to formulate a surjective holomorphic map from the unit disc ($\mathbb{D}$) to $\mathbb{C}$. I know that there exists $f: \mathbb{D} \rightarrow \mathbb{H}$, which is a biholomorphism from the unit disc to the upper half plane. I know that I can define $g(z) = z -i$ to shift the upper half plane down by 1 unit, then I can define $h(z) = z^2$ to square the result. Then, $h \circ g \circ f$ is a holomorphic function $\mathbb{U} \rightarrow \mathbb{C}$. My question is: how does $h(z)$, (i.e. squaring the result of the shifted upper half plane), extend the image to the entire lower half plane? Maybe I'm missing something obvious, but I'm not seeing how $\mathbb{C}$ is hit in its entirety.",,['complex-analysis']
59,Prove the open mapping theorem by using maximum modulus principle,Prove the open mapping theorem by using maximum modulus principle,,"The open mapping theorem says a non constant analytic function maps open sets to open sets. The maximum modulus principle says if $f$ a non constant analytic function on an open connected set $D\subset\mathbb{C}$, then $|f|$ does not attain a local maximum on $D$. It it known that one application of the open mapping theorem is to prove the maximum modulus principle. But what about the other way around? Can we use the maximum modulus principle(possibly plus some other results) to prove the open mapping theorem? The reason I am interested in this question is because after I see the proof in wiki-pedia , personally I found the idea in this proof somewhat ""hidden"", it is not that intuitive (at least to me).","The open mapping theorem says a non constant analytic function maps open sets to open sets. The maximum modulus principle says if $f$ a non constant analytic function on an open connected set $D\subset\mathbb{C}$, then $|f|$ does not attain a local maximum on $D$. It it known that one application of the open mapping theorem is to prove the maximum modulus principle. But what about the other way around? Can we use the maximum modulus principle(possibly plus some other results) to prove the open mapping theorem? The reason I am interested in this question is because after I see the proof in wiki-pedia , personally I found the idea in this proof somewhat ""hidden"", it is not that intuitive (at least to me).",,['complex-analysis']
60,Analytic functions defined by integrals,Analytic functions defined by integrals,,"Suppose I define a function using an integral: $$f(z)=\int_{\mathbb R} g(z,x)\ dx,$$ where $g$ is some function, $z$ is a complex variable, and $x$ is a real variable. Suppose the integral exists for $z\in U$, where $U$ is some open region. What are sufficient conditions on $g$ so that $f$ is analytic here, and why do they suffice? I looked in Ahlfors but couldn't find anything relevant.","Suppose I define a function using an integral: $$f(z)=\int_{\mathbb R} g(z,x)\ dx,$$ where $g$ is some function, $z$ is a complex variable, and $x$ is a real variable. Suppose the integral exists for $z\in U$, where $U$ is some open region. What are sufficient conditions on $g$ so that $f$ is analytic here, and why do they suffice? I looked in Ahlfors but couldn't find anything relevant.",,['complex-analysis']
61,"General method to ""naturally interpolate"" to a complex map?","General method to ""naturally interpolate"" to a complex map?",,"Given a region of the complex plane and a map $z \to f(z)$, is there a general way to ""naturally interpolate"" the point $z$ to $f(z)$ in such a way that the movement follows a ""natural"" smooth path that doesn't generate unnecessary ""kinks"" and overlaps? Background: I make educational animations . A couple of projects I've been playing around with involve complex numbers. I'm trying to figure out a general method to animate complex maps that look good and natural in terms of smooth deformations of the complex plane. Forgive me, but I have no way to confidently and formally state this question at this point. But I can illustrate it. Here's a great video illustrating Möbius transformations. You can see that for the inversion, the points on the plane follow a quite natural path from start to finish. This follows naturally from the rotation of the sphere used in the projection, in this particular case. But here's what a naive linear interpolation ($z \to (1-t) z + t f(z)$, with $0 \leq t \leq 1$) of the same transformation $z \to \frac{1}{z}$ looks like: As you can see, this method creates a lot of ""kinks"" and weird bends along the way. (Also, ignore the straight lines). I'm trying to avoid this, as it makes the animation more confusing than it should be. Some other examples. Here's the same method for $z \to z^2$: And $z \to e^z$ (using $[-1,1] \times [-\pi,\pi]$): In all these cases, I can imagine different and more natural ways to deform along the way, but I haven't come up with a general way to tackle this problem yet. I'm hoping there's something in complex analysis that can be helpful here, but I haven't found anything yet. Any ideas? EDIT : Here's $z \to e^z$ using Rahul's method with some translation: This is pretty much a perfect example of the sort of ""natural"" transformation I'm looking for. Each new step seems like an obvious deformation of the previous step following the same overall ""style"". It creates a nice sense of deliberation, which makes the movement intuitive, comprehensible and predictable.","Given a region of the complex plane and a map $z \to f(z)$, is there a general way to ""naturally interpolate"" the point $z$ to $f(z)$ in such a way that the movement follows a ""natural"" smooth path that doesn't generate unnecessary ""kinks"" and overlaps? Background: I make educational animations . A couple of projects I've been playing around with involve complex numbers. I'm trying to figure out a general method to animate complex maps that look good and natural in terms of smooth deformations of the complex plane. Forgive me, but I have no way to confidently and formally state this question at this point. But I can illustrate it. Here's a great video illustrating Möbius transformations. You can see that for the inversion, the points on the plane follow a quite natural path from start to finish. This follows naturally from the rotation of the sphere used in the projection, in this particular case. But here's what a naive linear interpolation ($z \to (1-t) z + t f(z)$, with $0 \leq t \leq 1$) of the same transformation $z \to \frac{1}{z}$ looks like: As you can see, this method creates a lot of ""kinks"" and weird bends along the way. (Also, ignore the straight lines). I'm trying to avoid this, as it makes the animation more confusing than it should be. Some other examples. Here's the same method for $z \to z^2$: And $z \to e^z$ (using $[-1,1] \times [-\pi,\pi]$): In all these cases, I can imagine different and more natural ways to deform along the way, but I haven't come up with a general way to tackle this problem yet. I'm hoping there's something in complex analysis that can be helpful here, but I haven't found anything yet. Any ideas? EDIT : Here's $z \to e^z$ using Rahul's method with some translation: This is pretty much a perfect example of the sort of ""natural"" transformation I'm looking for. Each new step seems like an obvious deformation of the previous step following the same overall ""style"". It creates a nice sense of deliberation, which makes the movement intuitive, comprehensible and predictable.",,"['complex-analysis', 'geometry', 'interpolation']"
62,Detailed proof that no essential singularity at infinity implies polynomial,Detailed proof that no essential singularity at infinity implies polynomial,,"Suppose $f(z)$ is holomorphic in the whole plane, and that $f(z)$ does not have an essential singularity at $\infty$. Prove that $f(z)$ is a polynomial. I've tried following the hint given in this question . Since $f(z)$ has a nonessential singularity at $\infty$, so $g(z)=f(1/z)$ has a nonessential singularity at $0$. There are two cases: 1) $g(z)$ has a removable singularity at $0$. This means $\lim_{z\rightarrow 0}zg(z)=0$. 2) $g(z)$ has a pole at $0$. This means $g(z)=h(z)/z^k$ for some analytic function $h(z)$ such that $h(0)\neq 0$. How can I finish each of these cases?","Suppose $f(z)$ is holomorphic in the whole plane, and that $f(z)$ does not have an essential singularity at $\infty$. Prove that $f(z)$ is a polynomial. I've tried following the hint given in this question . Since $f(z)$ has a nonessential singularity at $\infty$, so $g(z)=f(1/z)$ has a nonessential singularity at $0$. There are two cases: 1) $g(z)$ has a removable singularity at $0$. This means $\lim_{z\rightarrow 0}zg(z)=0$. 2) $g(z)$ has a pole at $0$. This means $g(z)=h(z)/z^k$ for some analytic function $h(z)$ such that $h(0)\neq 0$. How can I finish each of these cases?",,['complex-analysis']
63,A bounded holomorphic function,A bounded holomorphic function,,"If $\Omega$ is a region which is dense in $\mathbb{C}$, $f\in H(\Omega)$ and is continuous on $\mathbb{C}$, moreover $f$ is bounded on $\mathbb{C}$, can we claim that $f$ is a constant?","If $\Omega$ is a region which is dense in $\mathbb{C}$, $f\in H(\Omega)$ and is continuous on $\mathbb{C}$, moreover $f$ is bounded on $\mathbb{C}$, can we claim that $f$ is a constant?",,['complex-analysis']
64,Analytic functions with nonessential singularity at infinity must be a polynomial,Analytic functions with nonessential singularity at infinity must be a polynomial,,"This is an exercise from Alhfors Complex Analysis book- to show that an analytic function with a nonessential singularity at infinity must be a polynomial. It seems like it should probably be pretty straight forward, but I must be missing something. If it has a removable singularity at infinity then it extends to an analytic function on the Riemann sphere, and so must be constant by Liouville's theorem. What if there is a pole at infinity though? This was homework some time ago, and  I never finished it :/ but have been thinking about it again recently. Thanks :)","This is an exercise from Alhfors Complex Analysis book- to show that an analytic function with a nonessential singularity at infinity must be a polynomial. It seems like it should probably be pretty straight forward, but I must be missing something. If it has a removable singularity at infinity then it extends to an analytic function on the Riemann sphere, and so must be constant by Liouville's theorem. What if there is a pole at infinity though? This was homework some time ago, and  I never finished it :/ but have been thinking about it again recently. Thanks :)",,['complex-analysis']
65,"Prove/Disprove $|1 + z_1| + |1 + z_2| + |1 + r z_1 z_2| \ge 1 + \min(r, 1/r)$",Prove/Disprove,"|1 + z_1| + |1 + z_2| + |1 + r z_1 z_2| \ge 1 + \min(r, 1/r)","Let $r$ be a positive real number. Let $z_1, z_2 \in \mathbb{C}$ . Prove or disprove that $$|1 + z_1| + |1 + z_2| + |1 + r z_1 z_2| \ge 1 + \min(r, 1/r).$$ I came up with this problem after I saw this question ( $r = 1$ ): Prove $\left|1+z_1\right| +\left|1+z_2 \right| + \left|1+z_1z_2\right|\geq 2$ I used Mathematica to do some numerical experiment which supports the claim. Also, if $0 < r < 1$ , $\mathrm{LHS} = \mathrm{RHS}$ occurs when $z_1 = -1, z_2 = -1$ ; if $r \ge 1$ , $\mathrm{LHS} = \mathrm{RHS}$ occurs when $z_1 = -1, z_2 = 1/r$ .","Let be a positive real number. Let . Prove or disprove that I came up with this problem after I saw this question ( ): Prove $\left|1+z_1\right| +\left|1+z_2 \right| + \left|1+z_1z_2\right|\geq 2$ I used Mathematica to do some numerical experiment which supports the claim. Also, if , occurs when ; if , occurs when .","r z_1, z_2 \in \mathbb{C} |1 + z_1| + |1 + z_2| + |1 + r z_1 z_2| \ge 1 + \min(r, 1/r). r = 1 0 < r < 1 \mathrm{LHS} = \mathrm{RHS} z_1 = -1, z_2 = -1 r \ge 1 \mathrm{LHS} = \mathrm{RHS} z_1 = -1, z_2 = 1/r","['complex-analysis', 'inequality', 'complex-numbers']"
66,Contour Integration and Branch Cuts: $\oint_{|\omega|=x}d\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4}$,Contour Integration and Branch Cuts:,\oint_{|\omega|=x}d\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4},"I have a embarrassingly simple question. For some reason I haven't really studied complex before and I'm suffering under this now. I need to evaluate contour integrals of multi-valued functions and I'm confused about a few details (the standard examples in the textbooks avoid the difficulties I encounter with my integrals). Let me take some examples from the paper arXiv:1008.5194 (see pages 53-54). There they want to evaluate the integral $$\oint_{|\omega|=x}d\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4}$$ where $x\in]0,1[$ and they get $$(-1+e^{-i\frac{3\pi}2})\int_0^xd\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4}.$$ (Which is essentially the integral representation of hypergeometric functions). Since the integrand is multi-valued and has branch points at $\omega = 0, x, 1$ we should probably make a branch cut on the positive real axis. If I naively deform the contour into a line from $x$ to $0$ above the real axis and a line from $0$ to $x$ below the real axis, I seem to get the right result. But that can't be correct; due to the branch cut the circle is not closed and we need to cross the cut several times to get back to the original Riemann sheet and close the contour. But when I do this, taking into account the phases accumulated while going around the Riemann surface, I don't get the correct result. How is this done right? Another example is  $$\oint_{|\omega|=1}d\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4} = (1-e^{-i\frac{3\pi}2})\int_1^{\infty}d\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4}.$$ Here I don't get the result, even with the ""naive way"" and I don't understand why the integration should be over the interval $]1,\infty[$. UPDATE: Sasha gave a very good answer and his solution seems to be correct, it agrees with numerical calculation. But it's different from what the paper finds and I think the paper is correct, so is there another non-equivalent way of interpreting the contour? Or might there be a problem in this (and lots of other) papers...?","I have a embarrassingly simple question. For some reason I haven't really studied complex before and I'm suffering under this now. I need to evaluate contour integrals of multi-valued functions and I'm confused about a few details (the standard examples in the textbooks avoid the difficulties I encounter with my integrals). Let me take some examples from the paper arXiv:1008.5194 (see pages 53-54). There they want to evaluate the integral $$\oint_{|\omega|=x}d\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4}$$ where $x\in]0,1[$ and they get $$(-1+e^{-i\frac{3\pi}2})\int_0^xd\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4}.$$ (Which is essentially the integral representation of hypergeometric functions). Since the integrand is multi-valued and has branch points at $\omega = 0, x, 1$ we should probably make a branch cut on the positive real axis. If I naively deform the contour into a line from $x$ to $0$ above the real axis and a line from $0$ to $x$ below the real axis, I seem to get the right result. But that can't be correct; due to the branch cut the circle is not closed and we need to cross the cut several times to get back to the original Riemann sheet and close the contour. But when I do this, taking into account the phases accumulated while going around the Riemann surface, I don't get the correct result. How is this done right? Another example is  $$\oint_{|\omega|=1}d\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4} = (1-e^{-i\frac{3\pi}2})\int_1^{\infty}d\omega\:(1-\omega)^{-3/4}(x-\omega)^{-3/4}\omega^{-3/4}.$$ Here I don't get the result, even with the ""naive way"" and I don't understand why the integration should be over the interval $]1,\infty[$. UPDATE: Sasha gave a very good answer and his solution seems to be correct, it agrees with numerical calculation. But it's different from what the paper finds and I think the paper is correct, so is there another non-equivalent way of interpreting the contour? Or might there be a problem in this (and lots of other) papers...?",,"['complex-analysis', 'contour-integration', 'branch-cuts']"
67,Why does the Mandelbrot fractal appear when plotting $\underbrace{x\cos(x\cos( \cdots x\cos}_9(x))))$?,Why does the Mandelbrot fractal appear when plotting ?,\underbrace{x\cos(x\cos( \cdots x\cos}_9(x)))),"while plotting the function $x\cos(x\cos(x\cos(x\cos(x\cos(x\cos(x\cos(x\cos(x\cos(x)))))))))$ using matplotlib in python I found the mandelbrot fractal. What is the reason that the mandelbrot fractal appears in the process and what literature should I read to learn more about this. Maybe the mandelbrot fractal appears in more places where you iterate a function over and over again. here is the code import numpy as np import matplotlib.pyplot as plt import matplotlib.colors as mcolors import cmath  # Defining the function to map a complex function def map_complex_function(complex_func, real_range, imag_range, color_scheme=(""magnitude"", ""argument"", ""(10x)/(10x+1)"")):     # Creating the domain     real_values, imag_values = np.meshgrid(np.linspace(real_range[0], real_range[1], 1000),                                            np.linspace(imag_range[0], imag_range[1], 1000))     z_values = real_values + 1j * imag_values      # Applying the complex function to the domain     w_values = complex_func(z_values)      # Extracting the magnitude and argument     magnitude = np.abs(w_values)     argument = np.angle(w_values) / (2 * np.pi) % 1      # Determining brightness based on the provided color scheme     if color_scheme[2] == ""(10x)/(10x+1)"":         brightness = (10 * magnitude) / (10 * magnitude + 1)     else:         brightness = magnitude / np.max(magnitude)      # Creating HSV values     saturation = np.ones_like(argument)     hsv_values = np.stack([argument, saturation, brightness], axis=-1)      # Converting HSV to RGB     rgb_values = mcolors.hsv_to_rgb(hsv_values)      # Plotting the image     plt.imshow(rgb_values, origin='lower', extent=[real_range[0], real_range[1], imag_range[0], imag_range[1]])     plt.xlabel('Real part')     plt.ylabel('Imaginary part')     plt.title(f'Complex map for {complex_func.__name__}')     plt.colorbar(label='Magnitude (custom scale)')     plt.show()  def f(z):     return z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z)))))))))      # Creating the plots real_range = (0, 6) imag_range = (-4, 4) map_complex_function(f, real_range, imag_range, color_scheme=(""magnitude"", ""argument"", ""(10x)/(10x+1)"")) ```","while plotting the function using matplotlib in python I found the mandelbrot fractal. What is the reason that the mandelbrot fractal appears in the process and what literature should I read to learn more about this. Maybe the mandelbrot fractal appears in more places where you iterate a function over and over again. here is the code import numpy as np import matplotlib.pyplot as plt import matplotlib.colors as mcolors import cmath  # Defining the function to map a complex function def map_complex_function(complex_func, real_range, imag_range, color_scheme=(""magnitude"", ""argument"", ""(10x)/(10x+1)"")):     # Creating the domain     real_values, imag_values = np.meshgrid(np.linspace(real_range[0], real_range[1], 1000),                                            np.linspace(imag_range[0], imag_range[1], 1000))     z_values = real_values + 1j * imag_values      # Applying the complex function to the domain     w_values = complex_func(z_values)      # Extracting the magnitude and argument     magnitude = np.abs(w_values)     argument = np.angle(w_values) / (2 * np.pi) % 1      # Determining brightness based on the provided color scheme     if color_scheme[2] == ""(10x)/(10x+1)"":         brightness = (10 * magnitude) / (10 * magnitude + 1)     else:         brightness = magnitude / np.max(magnitude)      # Creating HSV values     saturation = np.ones_like(argument)     hsv_values = np.stack([argument, saturation, brightness], axis=-1)      # Converting HSV to RGB     rgb_values = mcolors.hsv_to_rgb(hsv_values)      # Plotting the image     plt.imshow(rgb_values, origin='lower', extent=[real_range[0], real_range[1], imag_range[0], imag_range[1]])     plt.xlabel('Real part')     plt.ylabel('Imaginary part')     plt.title(f'Complex map for {complex_func.__name__}')     plt.colorbar(label='Magnitude (custom scale)')     plt.show()  def f(z):     return z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z*np.cos(z)))))))))      # Creating the plots real_range = (0, 6) imag_range = (-4, 4) map_complex_function(f, real_range, imag_range, color_scheme=(""magnitude"", ""argument"", ""(10x)/(10x+1)""))",x\cos(x\cos(x\cos(x\cos(x\cos(x\cos(x\cos(x\cos(x\cos(x))))))))) ```,"['complex-analysis', 'fractals', 'chaos-theory']"
68,How exactly does $\frac{\partial f}{\partial \bar{z}}$ work?,How exactly does  work?,\frac{\partial f}{\partial \bar{z}},"I'm currently learning about complex analysis, and I keep coming across expressions involving $\frac{\partial f}{\partial \bar{z}}$. But I don't understand what this means. For example people might write $$\frac{\partial }{\partial \bar{z}}z\bar{z}=z$$ But how does that make any sense? Why can we regard $z$ and $\bar{z}$ as independent variable while they clearly aren't? In some material I've also read that  $\frac{\partial f}{\partial \bar{z}}=0$ can be interpreted as meaning that $f$ is 'independent' of $\bar{z}$. But $f$ depends on $z$, and $z$ can be thought of as 'depending' on $\bar{z}$, so clearly $f$ depends as much on $\bar{z}$ as it does on $z$. This  $\frac{\partial f}{\partial \bar{z}}=0$ condition, whatever it even means, seems to also be equivalent to $f$ being analytic, which then leads to people saying things like 'If $f$ can be expressed without involving $\bar{z}$ then it is analytic'. But this again seems very strange to me. For example $$f(z)=\bar{z}=z-2\Im(z)$$ Can certainly 'be expressed' without explicitly involving $\bar{z}$, but is not analytic, so this also doesn't make any sense to me. Basically I'm asking for clarification on why in complex analysis people seem to be doing these dodgy things, and what they mean by them.","I'm currently learning about complex analysis, and I keep coming across expressions involving $\frac{\partial f}{\partial \bar{z}}$. But I don't understand what this means. For example people might write $$\frac{\partial }{\partial \bar{z}}z\bar{z}=z$$ But how does that make any sense? Why can we regard $z$ and $\bar{z}$ as independent variable while they clearly aren't? In some material I've also read that  $\frac{\partial f}{\partial \bar{z}}=0$ can be interpreted as meaning that $f$ is 'independent' of $\bar{z}$. But $f$ depends on $z$, and $z$ can be thought of as 'depending' on $\bar{z}$, so clearly $f$ depends as much on $\bar{z}$ as it does on $z$. This  $\frac{\partial f}{\partial \bar{z}}=0$ condition, whatever it even means, seems to also be equivalent to $f$ being analytic, which then leads to people saying things like 'If $f$ can be expressed without involving $\bar{z}$ then it is analytic'. But this again seems very strange to me. For example $$f(z)=\bar{z}=z-2\Im(z)$$ Can certainly 'be expressed' without explicitly involving $\bar{z}$, but is not analytic, so this also doesn't make any sense to me. Basically I'm asking for clarification on why in complex analysis people seem to be doing these dodgy things, and what they mean by them.",,['complex-analysis']
69,entire function with only finitely many zeros,entire function with only finitely many zeros,,"I saw the following exercise: If $f:\mathbb{C}\rightarrow\mathbb{C}$ is an entire, non-constant function with only finitely many zeros, then either $|f(z)|\rightarrow \infty$ for $|z|\rightarrow\infty$ or there is a sequence of points $z_n$ such that $|z_n|\rightarrow\infty$ and $f(z_n)\rightarrow 0$. I thought a bit about this exercise and of course $f$ has to be unbounded because of Liouville's Theorem. But if I assume, that there is a unbounded sequence $z_n$ for which $f(z_n)\rightarrow \infty$ does not hold, how can I conclude, that there has to be a sequence such that $f(z_n)$ goes to zero? Thanks for hints!","I saw the following exercise: If $f:\mathbb{C}\rightarrow\mathbb{C}$ is an entire, non-constant function with only finitely many zeros, then either $|f(z)|\rightarrow \infty$ for $|z|\rightarrow\infty$ or there is a sequence of points $z_n$ such that $|z_n|\rightarrow\infty$ and $f(z_n)\rightarrow 0$. I thought a bit about this exercise and of course $f$ has to be unbounded because of Liouville's Theorem. But if I assume, that there is a unbounded sequence $z_n$ for which $f(z_n)\rightarrow \infty$ does not hold, how can I conclude, that there has to be a sequence such that $f(z_n)$ goes to zero? Thanks for hints!",,['complex-analysis']
70,Coefficients of binomial continued fractions,Coefficients of binomial continued fractions,,"For a natural number $n$ , let $$ \begin{equation} \beta_n(z)=\frac{(1+z)^n+(1-z)^n}{(1+z)^n-(1-z)^n}. \end{equation} $$ Then the coefficients of the numerator and denominator of $\beta_n$ are binomial. For example: $$\begin{equation} \beta_4(z)=\frac{z^4+6z^2+1}{4z^3+4z}=\frac{1}{4} z+\cfrac{1}{\frac{4}{5}z+\cfrac{1}{\frac{25}{16}z+\cfrac{1}{\frac{16}{5} z}}}. \end{equation} $$ Is there a simple formula for the coefficients of the continued fraction for any $n$ ? NOTES: the fact that all the coefficients are positive numbers follows from complex analysis, since $\Re\beta_n(z)>0$ for $\Re z >0$ computer calculation shows that the factorizations of the coefficients consist of small primes, less than $2(n+1)$ the motivation for the problem is the rational approximation of the square root function, since $(z\beta_n)(z^2)\approx z$ for $\Re z >0$ a relevant discussion: Binary eigenvalues matrices and continued fractions","For a natural number , let Then the coefficients of the numerator and denominator of are binomial. For example: Is there a simple formula for the coefficients of the continued fraction for any ? NOTES: the fact that all the coefficients are positive numbers follows from complex analysis, since for computer calculation shows that the factorizations of the coefficients consist of small primes, less than the motivation for the problem is the rational approximation of the square root function, since for a relevant discussion: Binary eigenvalues matrices and continued fractions","n 
\begin{equation}
\beta_n(z)=\frac{(1+z)^n+(1-z)^n}{(1+z)^n-(1-z)^n}.
\end{equation}
 \beta_n \begin{equation}
\beta_4(z)=\frac{z^4+6z^2+1}{4z^3+4z}=\frac{1}{4} z+\cfrac{1}{\frac{4}{5}z+\cfrac{1}{\frac{25}{16}z+\cfrac{1}{\frac{16}{5} z}}}.
\end{equation}
 n \Re\beta_n(z)>0 \Re z >0 2(n+1) (z\beta_n)(z^2)\approx z \Re z >0","['complex-analysis', 'binomial-coefficients', 'radicals', 'continued-fractions']"
71,Area integral over complex plane of non-holomorphic gaussian $e^{-z\bar{z}}$,Area integral over complex plane of non-holomorphic gaussian,e^{-z\bar{z}},"Let $A$ be the two-dimensional area integral, over the complex plane, of a gaussian function: $$A = \int_\text{plane} \frac{\mathrm{d}\bar{z} \wedge \mathrm{d}z}{2i} \ \exp[-z\bar{z}].$$ Of course one could evaluate this integral by converting to Cartesian (or alternatively to polar) coordinates, where the answer is evident, $$A = \int_\text{plane}  \mathrm{d}x \wedge \mathrm{d}y \ \exp[-(x^2+y^2)] = \pi.$$ But, is there a way to do the complex area integration directly in the complex coordinates $z,\bar{z}$ ? In particular, let us define the (non-holomorphic) function $f$ , $$f=-\frac{1}{z}\exp[-z\bar{z}], \\ \frac{\partial f}{\partial \bar{z}} = \exp[-z\bar{z}].$$ Then I wonder whether one can proceed with the following manipulations: first ""integrate"" over $\bar{z}$ , $$A = \int_\text{plane} \frac{\mathrm{d}\bar{z} \wedge \mathrm{d}z}{2i} \ \exp[-z\bar{z}] =  \oint_\text{contour}  \frac{\mathrm{d}z}{2i}\ f(\bar{z},z) .$$ and then evaluate the positive definite Gaussian part at the $z=0$ pole, to use the Residue theorem, $$ =  \oint_\text{contour} \frac{\mathrm{d}z}{2i} \ \frac{1}{z} = \pi ,$$ which produces the correct value of the integral.  Is there a sense in which these manipulations are correct? Can one perform the complex plane area integral by first integrating over $\bar{z}$ , and then over $z$ ?","Let be the two-dimensional area integral, over the complex plane, of a gaussian function: Of course one could evaluate this integral by converting to Cartesian (or alternatively to polar) coordinates, where the answer is evident, But, is there a way to do the complex area integration directly in the complex coordinates ? In particular, let us define the (non-holomorphic) function , Then I wonder whether one can proceed with the following manipulations: first ""integrate"" over , and then evaluate the positive definite Gaussian part at the pole, to use the Residue theorem, which produces the correct value of the integral.  Is there a sense in which these manipulations are correct? Can one perform the complex plane area integral by first integrating over , and then over ?","A A = \int_\text{plane} \frac{\mathrm{d}\bar{z} \wedge \mathrm{d}z}{2i} \ \exp[-z\bar{z}]. A = \int_\text{plane}  \mathrm{d}x \wedge \mathrm{d}y \ \exp[-(x^2+y^2)] = \pi. z,\bar{z} f f=-\frac{1}{z}\exp[-z\bar{z}], \\ \frac{\partial f}{\partial \bar{z}} = \exp[-z\bar{z}]. \bar{z} A = \int_\text{plane} \frac{\mathrm{d}\bar{z} \wedge \mathrm{d}z}{2i} \ \exp[-z\bar{z}]
=  \oint_\text{contour}  \frac{\mathrm{d}z}{2i}\ f(\bar{z},z) . z=0 
=  \oint_\text{contour} \frac{\mathrm{d}z}{2i} \ \frac{1}{z} = \pi , \bar{z} z","['complex-analysis', 'contour-integration', 'residue-calculus', 'complex-integration']"
72,Reasons for defining sheaves of holomorphic and meromorphic functions on complex manifolds,Reasons for defining sheaves of holomorphic and meromorphic functions on complex manifolds,,"I am hoping this question is sensible and non-trivial. I am learning algebraic geometry at the moment, and have taken a strong liking to it. Unfortunately my complex analysis is weaker and I only know it at an undergraduate level. I am trying to transfer some of what I know in algebraic geometry to the language of complex analysis, particularly complex manifolds. My main question is, what are the benefits and drawbacks of defining the sheaf on a complex manifold (for the time being say a Riemann surface, or even just the Riemann sphere) in terms of holomorphic functions as opposed to meromorphic functions? From what I have gathered, meromorphic functions align better with the theory of discrete valuation rings on algebraic curves, since this provides a framework for studying poles. However it seems that holomorphic functions are taken to be the standard structure sheaf. What difference does this make, and why do you choose one over the other in certain situations? Does it make any difference to the sheaf cohomology? Does it make a difference if the surface is compact or not? Again, forgive me if this question is either trivial or not particularly meaningful, but I feel like it would massively boost the speed I can learn complex geometry if I can frame it in the language of ringed spaces and algebraic geometry. Any help is appreciated, or even some introductory notes that you think would help someone coming from my perspective. Thanks","I am hoping this question is sensible and non-trivial. I am learning algebraic geometry at the moment, and have taken a strong liking to it. Unfortunately my complex analysis is weaker and I only know it at an undergraduate level. I am trying to transfer some of what I know in algebraic geometry to the language of complex analysis, particularly complex manifolds. My main question is, what are the benefits and drawbacks of defining the sheaf on a complex manifold (for the time being say a Riemann surface, or even just the Riemann sphere) in terms of holomorphic functions as opposed to meromorphic functions? From what I have gathered, meromorphic functions align better with the theory of discrete valuation rings on algebraic curves, since this provides a framework for studying poles. However it seems that holomorphic functions are taken to be the standard structure sheaf. What difference does this make, and why do you choose one over the other in certain situations? Does it make any difference to the sheaf cohomology? Does it make a difference if the surface is compact or not? Again, forgive me if this question is either trivial or not particularly meaningful, but I feel like it would massively boost the speed I can learn complex geometry if I can frame it in the language of ringed spaces and algebraic geometry. Any help is appreciated, or even some introductory notes that you think would help someone coming from my perspective. Thanks",,"['complex-analysis', 'algebraic-geometry', 'algebraic-curves', 'complex-geometry', 'riemann-surfaces']"
73,Solving $f(z) = f( z-z^2)$ for $f : \mathbb{C} \to \mathbb{C}$ analytic,Solving  for  analytic,f(z) = f( z-z^2) f : \mathbb{C} \to \mathbb{C},"This is a question that I came across in a math competition and I solved it the following way. But unfortunately, I received 0 out of 20. Are there any errors in my reasoning? $f: \mathbb{C}\to \mathbb{C}$ and $f$ is analytic everywhere in the complex plane. $\forall z \in C$ we have $f(z)= f\left(z-z^2\right)$ . Prove that $f(z)$ has to be a constant in the entire plane. My approach: Since $f$ is analytic everywhere, therefore its Taylor series expansion about $z=0$ has to be convergent $\forall z\in C$ . Therefore we have: $$ \begin{split} f(z)     &= f(0) + f'(0) z + \frac{f''(0)}{2} z^2 + \ldots \\ f(z-z^2) &= f(0) + f'(0)(z-z^2) + \frac{f''(0)}{2} (z-z^2)^2 + \ldots \end{split} $$ So the two series are equal for all complex inputs, therefore the coefficients of the same powers of $z$ have to be equal. So I went on calculating the coefficient of $z^2$ in the second series and concluded that $\frac{f''(0)}{2} = - f'(0) + \frac{f''(0)}{2}$ . So $f'(0)=0$ . I decided to prove by induction that $\forall n \in N, f^n(0)=0$ and therefore, the proof will be complete. Suppose that $f'(0) = f''(0) = ... = f^n(0)=0$ . If we can prove that $f^{n+1}(0)=0$ , the induction will be complete. By the hypothesis of the induction we have: $$ f(z) = f(0) + \frac{f^{n+1}(0)}{(n+1)!}z^{n+1}      + \frac{f^{n+2}(0)}{(n+2)!}z^{n+2} + \ldots  $$ and therefore, $$ f(z-z^2) = f(0) + \frac{f^{n+1}(0)}{(n+1)!}(z-z^2)^{n+1}          + \frac{f^{n+2}(0)}{(n+2)!}(z-z^2)^{n+2} + \ldots $$ By using the Newton's binomial formula I calculated the coefficients of $ z^{n+1}$ and $z^{n+2}$ and concluded that $ \frac{f^{n+2}(0)}{(n+2)!} = \frac{f^{n+2}(0)}{(n+2)!}- (n+1)\frac{f^{n+1}(0)}{(n+1)!}$ and finally $f^{n+1}(0) = 0$ Therefore, $f(z) = f(0)  \  \forall z \in C$ .","This is a question that I came across in a math competition and I solved it the following way. But unfortunately, I received 0 out of 20. Are there any errors in my reasoning? and is analytic everywhere in the complex plane. we have . Prove that has to be a constant in the entire plane. My approach: Since is analytic everywhere, therefore its Taylor series expansion about has to be convergent . Therefore we have: So the two series are equal for all complex inputs, therefore the coefficients of the same powers of have to be equal. So I went on calculating the coefficient of in the second series and concluded that . So . I decided to prove by induction that and therefore, the proof will be complete. Suppose that . If we can prove that , the induction will be complete. By the hypothesis of the induction we have: and therefore, By using the Newton's binomial formula I calculated the coefficients of and and concluded that and finally Therefore, .","f: \mathbb{C}\to \mathbb{C} f \forall z \in C f(z)= f\left(z-z^2\right) f(z) f z=0 \forall z\in C 
\begin{split}
f(z)     &= f(0) + f'(0) z + \frac{f''(0)}{2} z^2 + \ldots \\
f(z-z^2) &= f(0) + f'(0)(z-z^2) + \frac{f''(0)}{2} (z-z^2)^2 + \ldots
\end{split}
 z z^2 \frac{f''(0)}{2} = - f'(0) + \frac{f''(0)}{2} f'(0)=0 \forall n \in N, f^n(0)=0 f'(0) = f''(0) = ... = f^n(0)=0 f^{n+1}(0)=0 
f(z) = f(0) + \frac{f^{n+1}(0)}{(n+1)!}z^{n+1}
     + \frac{f^{n+2}(0)}{(n+2)!}z^{n+2} + \ldots 
 
f(z-z^2) = f(0) + \frac{f^{n+1}(0)}{(n+1)!}(z-z^2)^{n+1}
         + \frac{f^{n+2}(0)}{(n+2)!}(z-z^2)^{n+2} + \ldots
  z^{n+1} z^{n+2}  \frac{f^{n+2}(0)}{(n+2)!} = \frac{f^{n+2}(0)}{(n+2)!}- (n+1)\frac{f^{n+1}(0)}{(n+1)!} f^{n+1}(0) = 0 f(z) = f(0)  \  \forall z \in C","['complex-analysis', 'solution-verification', 'induction', 'taylor-expansion', 'functional-equations']"
74,Is analytic capacity continuous from below?,Is analytic capacity continuous from below?,,"EDIT: I also asked this question on mathoverflow , since it might be too specialized for math.stackexchange.com. I've been wondering about the following, I don't know if anyone knows the answer : For a compact set $K$ in the complex plane, define the analytic capacity of $K$ by $$\gamma(K) := \sup |f'(\infty)|$$ where the supremum is taken over all functions $f$ holomorphic and bounded by $1$ in the complement of $K$ : $f \in H^{\infty}(\mathbb{C}_{\infty} \setminus K)$, $\|f\|_{\infty} \leq 1$. Here $$f'(\infty) = \lim_{z \rightarrow \infty} z(f(z)-f(\infty)).$$ A theorem due to Ahlfors states that for each compact $K$, there always exists a unique function $F$, called the Ahlfors function of $K$, such that $F \in H^{\infty}(\mathbb{C}_{\infty} \setminus K)$, $\|F\|_{\infty} \leq 1$, and $F'(\infty)=\gamma(K)$. It's not hard to show that $\gamma$ is continuous from above : if $(K_n)$ is a decreasing sequence of compact sets, then $$\gamma(\cap_n K_n) = \lim_{n\rightarrow \infty} \gamma(K_n).$$ This essentially follows from Montel's theorem and the fact that $\gamma(E) \subseteq \gamma(F)$ whenever $E \subseteq F$. My question is the following : Is analytic capacity continuous from below ? More precisely, if $(K_n)$ is a sequence of compact sets such that $$K_1 \subseteq K_2 \subseteq K_3 \subseteq \dots$$ and such that $K:=\cup_n K_n$ is compact, then is it true that $\gamma(K) = \lim_{n \rightarrow \infty} \gamma(K_n)?$ I could not find anything in the litterature. Thank you, Malik","EDIT: I also asked this question on mathoverflow , since it might be too specialized for math.stackexchange.com. I've been wondering about the following, I don't know if anyone knows the answer : For a compact set $K$ in the complex plane, define the analytic capacity of $K$ by $$\gamma(K) := \sup |f'(\infty)|$$ where the supremum is taken over all functions $f$ holomorphic and bounded by $1$ in the complement of $K$ : $f \in H^{\infty}(\mathbb{C}_{\infty} \setminus K)$, $\|f\|_{\infty} \leq 1$. Here $$f'(\infty) = \lim_{z \rightarrow \infty} z(f(z)-f(\infty)).$$ A theorem due to Ahlfors states that for each compact $K$, there always exists a unique function $F$, called the Ahlfors function of $K$, such that $F \in H^{\infty}(\mathbb{C}_{\infty} \setminus K)$, $\|F\|_{\infty} \leq 1$, and $F'(\infty)=\gamma(K)$. It's not hard to show that $\gamma$ is continuous from above : if $(K_n)$ is a decreasing sequence of compact sets, then $$\gamma(\cap_n K_n) = \lim_{n\rightarrow \infty} \gamma(K_n).$$ This essentially follows from Montel's theorem and the fact that $\gamma(E) \subseteq \gamma(F)$ whenever $E \subseteq F$. My question is the following : Is analytic capacity continuous from below ? More precisely, if $(K_n)$ is a sequence of compact sets such that $$K_1 \subseteq K_2 \subseteq K_3 \subseteq \dots$$ and such that $K:=\cup_n K_n$ is compact, then is it true that $\gamma(K) = \lim_{n \rightarrow \infty} \gamma(K_n)?$ I could not find anything in the litterature. Thank you, Malik",,['complex-analysis']
75,"What is a good, hi-tech textbook on complex analysis?","What is a good, hi-tech textbook on complex analysis?",,"I am looking for an introductory textbook for Complex Analysis that is hi-tech . All the books I have looked at suffer from the same problem; they're only assuming that the reader is familiar with is basic real analysis, and thus, are by design, low-tech. I'm looking for a textbook that: Doesn't shy away from treating the Riemann sphere as a manifold, and clearly distinguishes it from $\mathbb{C}$, so it's easy to keep track of where my functions live. Gives the statement of Cauchy's theorem in a modern, algebraic topological language of (co)homology Actually compares the theorems, where applicable, to the $2$-dimensional real case with more than passing remarks Doesn't give whacky definitions of topological properties (eg. simple connectedness) This isn't a complete list, but this should give you a good idea about what I mean by hi-tech. Additional extras: Has a sane statement of Liouville's theorem. Why say that ""bounded entire functions are constant"" when you could be saying ""the image of a function $\mathbb{C} \to \mathbb{C}$ is dense or a single point""? Covers basic multivariable complex analysis Treats the logarithm, etc. as functions from a Riemann surface, rather than the clumsy ""multifunction"" treatment Treats power series formally and then passes to convergent ones I basically want someone like John M. Lee to write a complex analysis book. (His book on Smooth Manifolds is about as good as textbooks get, in my opinion.) The closest I have found was Cartan's text, but I'm hoping that someone on this site might know something even better. Many thanks!","I am looking for an introductory textbook for Complex Analysis that is hi-tech . All the books I have looked at suffer from the same problem; they're only assuming that the reader is familiar with is basic real analysis, and thus, are by design, low-tech. I'm looking for a textbook that: Doesn't shy away from treating the Riemann sphere as a manifold, and clearly distinguishes it from $\mathbb{C}$, so it's easy to keep track of where my functions live. Gives the statement of Cauchy's theorem in a modern, algebraic topological language of (co)homology Actually compares the theorems, where applicable, to the $2$-dimensional real case with more than passing remarks Doesn't give whacky definitions of topological properties (eg. simple connectedness) This isn't a complete list, but this should give you a good idea about what I mean by hi-tech. Additional extras: Has a sane statement of Liouville's theorem. Why say that ""bounded entire functions are constant"" when you could be saying ""the image of a function $\mathbb{C} \to \mathbb{C}$ is dense or a single point""? Covers basic multivariable complex analysis Treats the logarithm, etc. as functions from a Riemann surface, rather than the clumsy ""multifunction"" treatment Treats power series formally and then passes to convergent ones I basically want someone like John M. Lee to write a complex analysis book. (His book on Smooth Manifolds is about as good as textbooks get, in my opinion.) The closest I have found was Cartan's text, but I'm hoping that someone on this site might know something even better. Many thanks!",,"['complex-analysis', 'reference-request']"
76,If $\Re(f)$ is bounded then f is constant.,If  is bounded then f is constant.,\Re(f),"I have to solve following problem If $\Re (f)$ is bounded above or below for a function $f$ holomorphic on $\mathbb{C}$ then $f$ is constant. My attempt: If there is $M$ such that $\Re(f) \le M$, then $\|e^{f}\|=e^{\Re(f)}\le e^{M}$. From Liouville's theorem the entire function $e^f$ is constant, that is $0=(e^f)'=f' e^f$. This means $f' =0$, so $f$ is constant. If $\Re(f)$ is bounded below, we consider $e^{-f}$ and proceed the same way. Am I correct? Is there a solution using maximum modulus principle?","I have to solve following problem If $\Re (f)$ is bounded above or below for a function $f$ holomorphic on $\mathbb{C}$ then $f$ is constant. My attempt: If there is $M$ such that $\Re(f) \le M$, then $\|e^{f}\|=e^{\Re(f)}\le e^{M}$. From Liouville's theorem the entire function $e^f$ is constant, that is $0=(e^f)'=f' e^f$. This means $f' =0$, so $f$ is constant. If $\Re(f)$ is bounded below, we consider $e^{-f}$ and proceed the same way. Am I correct? Is there a solution using maximum modulus principle?",,['complex-analysis']
77,Proving that a family of functions converges to the Dirac delta.,Proving that a family of functions converges to the Dirac delta.,,"For each $\epsilon > 0$, define $f_\epsilon:\mathbb R\to \mathbb R$ as follows: \begin{align}   f_\epsilon(k) = \frac{1}{\pi}\frac{\epsilon}{\epsilon^2+k^2}. \end{align} How does one rigorously show (in the sense of distributions) that $f_\epsilon(k) \to \delta(k)$ as $\epsilon\to 0$? I think I have the essential structure of an argument using contour integration, but it's missing some details that I don't have the expertise to fill in. For each $a>0$, let $C_a$ be the CCW contour consisting of a straight segment between $-a$ and $a$ on the real axis, and a semicircular segment in the upper half plane of radius $a$.  Then morally speaking, I'd hope the following steps are correct: \begin{align}   \lim_{\epsilon\to 0}\int_{-\infty}^\infty f_\epsilon(k)\varphi(k)\, dk &= \lim_{\epsilon\to 0} \lim_{a\to\infty}\int_{C_a} \frac{1}{\pi}\frac{\epsilon}{(z-i\epsilon)(z+i\epsilon)}\varphi(z) \, dz \\ &= \lim_{\epsilon\to 0} (2\pi i) \frac{1}{\pi}\frac{\epsilon}{(i\epsilon + i\epsilon)}\varphi(i\epsilon) \\ &= \varphi(0) \end{align} However, I'm most concerned about the details of extending the test function $\varphi$ to a sufficiently nice function on $\mathbb C$ in order to perform the contour integration.   In the book I'm studying, a test function is defined as a function in $C^\infty(\mathbb R)$ such that it and all its derivatives are $O(|x|^{-N})$ for all $N$ as $|x|\to\infty$. Does any test function have a nice continuation to $\mathbb C$ that makes the above steps valid?  Perhaps there is a way of doing this without contour integration so that one doesn't have to worry about continuation? Edit. I was made aware by Mister Benjamin Dover below that there is in fact a quite general way to argue convergence to $\delta$ without complex analysis.  I'm most interested at this point in determining if there is some way to make my manipulation above rigorous -- those sorts of arguments abound in the physics literature.","For each $\epsilon > 0$, define $f_\epsilon:\mathbb R\to \mathbb R$ as follows: \begin{align}   f_\epsilon(k) = \frac{1}{\pi}\frac{\epsilon}{\epsilon^2+k^2}. \end{align} How does one rigorously show (in the sense of distributions) that $f_\epsilon(k) \to \delta(k)$ as $\epsilon\to 0$? I think I have the essential structure of an argument using contour integration, but it's missing some details that I don't have the expertise to fill in. For each $a>0$, let $C_a$ be the CCW contour consisting of a straight segment between $-a$ and $a$ on the real axis, and a semicircular segment in the upper half plane of radius $a$.  Then morally speaking, I'd hope the following steps are correct: \begin{align}   \lim_{\epsilon\to 0}\int_{-\infty}^\infty f_\epsilon(k)\varphi(k)\, dk &= \lim_{\epsilon\to 0} \lim_{a\to\infty}\int_{C_a} \frac{1}{\pi}\frac{\epsilon}{(z-i\epsilon)(z+i\epsilon)}\varphi(z) \, dz \\ &= \lim_{\epsilon\to 0} (2\pi i) \frac{1}{\pi}\frac{\epsilon}{(i\epsilon + i\epsilon)}\varphi(i\epsilon) \\ &= \varphi(0) \end{align} However, I'm most concerned about the details of extending the test function $\varphi$ to a sufficiently nice function on $\mathbb C$ in order to perform the contour integration.   In the book I'm studying, a test function is defined as a function in $C^\infty(\mathbb R)$ such that it and all its derivatives are $O(|x|^{-N})$ for all $N$ as $|x|\to\infty$. Does any test function have a nice continuation to $\mathbb C$ that makes the above steps valid?  Perhaps there is a way of doing this without contour integration so that one doesn't have to worry about continuation? Edit. I was made aware by Mister Benjamin Dover below that there is in fact a quite general way to argue convergence to $\delta$ without complex analysis.  I'm most interested at this point in determining if there is some way to make my manipulation above rigorous -- those sorts of arguments abound in the physics literature.",,"['complex-analysis', 'distribution-theory']"
78,Conformal cobblestones,Conformal cobblestones,,"Open-ended question: It strikes me that the cobblestone pattern known as Bogen, which can be seen in many European cities, is a fairly accurate representation of the conformal mapping defined by the complex function $f(z) = \ln(z)$: Conformal mappings make a good basis for such patterns because of their angle-preserving property, which means that a square grid is mapped onto a curvilinear orthogonal grid which can be easily constructed from an arrangement of square cobblestones (setts). The curves in the Bogen pattern are catenaries of equal strength . They are described by $\xi = c - \ln{\cos{\eta}}$ and $\xi = c - \ln{\sin{\eta}}$, where $f(z) = \xi + i\eta$ and $c$ is a real constant. Other conformal mapping functions commonly seen in cobblestones are $f(z) = z$ (rectilinear) and $f(z) = e^z$ (circular). But which other functions would be suitable, and which have actually been used? [Edit: function definitions inverted to conform to usual convention.]","Open-ended question: It strikes me that the cobblestone pattern known as Bogen, which can be seen in many European cities, is a fairly accurate representation of the conformal mapping defined by the complex function $f(z) = \ln(z)$: Conformal mappings make a good basis for such patterns because of their angle-preserving property, which means that a square grid is mapped onto a curvilinear orthogonal grid which can be easily constructed from an arrangement of square cobblestones (setts). The curves in the Bogen pattern are catenaries of equal strength . They are described by $\xi = c - \ln{\cos{\eta}}$ and $\xi = c - \ln{\sin{\eta}}$, where $f(z) = \xi + i\eta$ and $c$ is a real constant. Other conformal mapping functions commonly seen in cobblestones are $f(z) = z$ (rectilinear) and $f(z) = e^z$ (circular). But which other functions would be suitable, and which have actually been used? [Edit: function definitions inverted to conform to usual convention.]",,"['complex-analysis', 'conformal-geometry']"
79,Eigenvalue problem for $−\psi''(x) − (ix)^ N \psi(x) = E\psi(x)$ in complex plane,Eigenvalue problem for  in complex plane,−\psi''(x) − (ix)^ N \psi(x) = E\psi(x),"To find the eigenvalue $E$ in the complex plane of $x$ for one dimensional Schrodinger equation $$ −\psi''(x) − (ix)^ N \psi(x) = E\psi(x). $$ where $N$ can be any real number, the boundary condition  $\psi(x) \to 0$ as $|x| → ∞$ causes a great difficulty for numerical method, because there are infinite number of contour paths which go from zero to complex infinity. Bender et al on their paper only considered the contour paths (e.g. the black path on the following figure) which are entirely confined in two Stokes wedges symmetric with respect to the imaginary axis. Based on my understanding on what they say, each asymptotic series expansion for $ψ(x)$ is only valid within certain sector or wedge, therefore for any path which is outside of these two wedges, the corresponding asymptotic series is no longer asymptotic to the value of the function $ψ(x)$ . However, there exists a new, unique and valid asymptotic series for $ψ(x)$ outside the wedge. Yet, this new asymptotic series, say $f(x)$, does not satisfy the boundary condition  $f(x) \to 0$ as $|x| \to \infty$ . My question : I don't really understand why the contour path has to be entirely inside the Stokes sector. How about the red and yellow path shown on the figure above? They are partly inside the Stokes wedges. The red path starts from the complex infinity which lies inside the right Stokes wedge and then approaches the origin zero from the left Stokes wedge, so that only the middle part of the red path lies outside the two Stokes sectors. The yellow path starts from the complex infinity which lies inside the right Stokes wedge and then approaches the origin zero inside the right Stokes wedge again. Why do these red and yellow paths have to be excluded please? If we integrate along anyone of these two paths, does it yield finite eigenvalue and exponentially decayed eigenfunction or not? Why?","To find the eigenvalue $E$ in the complex plane of $x$ for one dimensional Schrodinger equation $$ −\psi''(x) − (ix)^ N \psi(x) = E\psi(x). $$ where $N$ can be any real number, the boundary condition  $\psi(x) \to 0$ as $|x| → ∞$ causes a great difficulty for numerical method, because there are infinite number of contour paths which go from zero to complex infinity. Bender et al on their paper only considered the contour paths (e.g. the black path on the following figure) which are entirely confined in two Stokes wedges symmetric with respect to the imaginary axis. Based on my understanding on what they say, each asymptotic series expansion for $ψ(x)$ is only valid within certain sector or wedge, therefore for any path which is outside of these two wedges, the corresponding asymptotic series is no longer asymptotic to the value of the function $ψ(x)$ . However, there exists a new, unique and valid asymptotic series for $ψ(x)$ outside the wedge. Yet, this new asymptotic series, say $f(x)$, does not satisfy the boundary condition  $f(x) \to 0$ as $|x| \to \infty$ . My question : I don't really understand why the contour path has to be entirely inside the Stokes sector. How about the red and yellow path shown on the figure above? They are partly inside the Stokes wedges. The red path starts from the complex infinity which lies inside the right Stokes wedge and then approaches the origin zero from the left Stokes wedge, so that only the middle part of the red path lies outside the two Stokes sectors. The yellow path starts from the complex infinity which lies inside the right Stokes wedge and then approaches the origin zero inside the right Stokes wedge again. Why do these red and yellow paths have to be excluded please? If we integrate along anyone of these two paths, does it yield finite eigenvalue and exponentially decayed eigenfunction or not? Why?",,"['complex-analysis', 'ordinary-differential-equations', 'eigenvalues-eigenvectors', 'asymptotics']"
80,Why is $2\pi i \neq 0?$ [duplicate],Why is  [duplicate],2\pi i \neq 0?,"This question already has answers here : What is wrong with this fake proof $e^i = 1$? (2 answers) Closed 11 years ago . We know that $e^{\pi i} = -1$ because of de Moivre's formula. ($e^{\pi i} = \cos \pi + i\sin \pi = -1).$ Suppose we square both sides and get $e^{2\pi i} = 1$(which you also get from de Moivre's formula), then shouldn't $2\pi i=0$? What am I missing here?","This question already has answers here : What is wrong with this fake proof $e^i = 1$? (2 answers) Closed 11 years ago . We know that $e^{\pi i} = -1$ because of de Moivre's formula. ($e^{\pi i} = \cos \pi + i\sin \pi = -1).$ Suppose we square both sides and get $e^{2\pi i} = 1$(which you also get from de Moivre's formula), then shouldn't $2\pi i=0$? What am I missing here?",,"['complex-analysis', 'exponential-function', 'fake-proofs']"
81,Proof of Cauchy Riemann Equations in Polar Coordinates,Proof of Cauchy Riemann Equations in Polar Coordinates,,"How would one go about showing the polar version of the Cauchy Riemann Equations are sufficient to get differentiability of a complex valued function which has continuous partial derivatives? I haven't found any proof of this online. One of my ideas was writing out $r$ and $\theta$ in terms of $x$ and $y$, then taking the partial derivatives with respect to $x$ and $y$ and showing the Cauchy Riemann equations in the Cartesian coordinate system are satisfied. A problem with this approach is that derivatives get messy. What are some other ways to do it?","How would one go about showing the polar version of the Cauchy Riemann Equations are sufficient to get differentiability of a complex valued function which has continuous partial derivatives? I haven't found any proof of this online. One of my ideas was writing out $r$ and $\theta$ in terms of $x$ and $y$, then taking the partial derivatives with respect to $x$ and $y$ and showing the Cauchy Riemann equations in the Cartesian coordinate system are satisfied. A problem with this approach is that derivatives get messy. What are some other ways to do it?",,['complex-analysis']
82,An entire function is identically zero?,An entire function is identically zero?,,"I'm preparing for a PhD prelim in Complex Analysis, and I encountered this question from an old PhD prelim: Suppose $f(z)$ is an entire function such that $|f(z)| \leq \log(1+|z|) \forall z$. Show that $f \equiv 0$. Well, for $z=0$, $|f(0)| \leq 0$. On the other hand, for $z \neq 0$, $\log(1+|z|) > 0$, a positive constant. I'm guessing this would mean that $f$ turns out to be a bounded entire function, so then by Liouville's theorem, $f$ is constant, but this doesn't necessarily mean that $f \equiv 0$, does it? Am I wrong somewhere? Some guidance would be much appreciated!","I'm preparing for a PhD prelim in Complex Analysis, and I encountered this question from an old PhD prelim: Suppose $f(z)$ is an entire function such that $|f(z)| \leq \log(1+|z|) \forall z$. Show that $f \equiv 0$. Well, for $z=0$, $|f(0)| \leq 0$. On the other hand, for $z \neq 0$, $\log(1+|z|) > 0$, a positive constant. I'm guessing this would mean that $f$ turns out to be a bounded entire function, so then by Liouville's theorem, $f$ is constant, but this doesn't necessarily mean that $f \equiv 0$, does it? Am I wrong somewhere? Some guidance would be much appreciated!",,['complex-analysis']
83,"Is the complex exponential function injective, surjective and/or bijective - and why?","Is the complex exponential function injective, surjective and/or bijective - and why?",,"I was just reading about the e -function in the complex plane and was trying to understand the differences between the real and the complex case. Part of the problem is that the mapping of a 2-D plane to another 2-D plane is hard to visualize. My question What are the properties of the complex exponential function in terms of being injective, surjective and/or bijective - and how is this different from the real case? How can you proof these attributes in the real and in the complex case?","I was just reading about the e -function in the complex plane and was trying to understand the differences between the real and the complex case. Part of the problem is that the mapping of a 2-D plane to another 2-D plane is hard to visualize. My question What are the properties of the complex exponential function in terms of being injective, surjective and/or bijective - and how is this different from the real case? How can you proof these attributes in the real and in the complex case?",,['complex-analysis']
84,"Let $z_1$, $z_2$ and $z_3$ be complex vertices of an equilateral triangle. Show $z_1^2 + z_2^2 + z_3^2 = z_1 z_2 + z_2 z_3 + z_3 z_1$.","Let ,  and  be complex vertices of an equilateral triangle. Show .",z_1 z_2 z_3 z_1^2 + z_2^2 + z_3^2 = z_1 z_2 + z_2 z_3 + z_3 z_1,"Prompt: Let $z_1$, $z_2$ and $z_3$ represent vertices of an equilateral triangle in the complex plane. Show $z_1^2 + z_2^2 + z_3^2 = z_1 z_2 + z_2 z_3 + z_3 z_1$. Question: I hope the following question isn't too soft. I know a solution to the above question by taking the sides of the triangle and equating them by rotations in the complex plane of $e^{i\pi/3}$. What, if anything, is the significance of the result other than showing some clever algebraic manipulation? Does it tell us something unique about equilateral triangles defined by vertices in the complex plane? Is there any intuition to be gained here?","Prompt: Let $z_1$, $z_2$ and $z_3$ represent vertices of an equilateral triangle in the complex plane. Show $z_1^2 + z_2^2 + z_3^2 = z_1 z_2 + z_2 z_3 + z_3 z_1$. Question: I hope the following question isn't too soft. I know a solution to the above question by taking the sides of the triangle and equating them by rotations in the complex plane of $e^{i\pi/3}$. What, if anything, is the significance of the result other than showing some clever algebraic manipulation? Does it tell us something unique about equilateral triangles defined by vertices in the complex plane? Is there any intuition to be gained here?",,"['complex-analysis', 'intuition']"
85,$f$ has an essential singularity in $z_0$. What about $1/f$?,has an essential singularity in . What about ?,f z_0 1/f,"Let $\Omega$ be a non-empty, open subset of $\mathbb C$. Consider an holomorphic function $f:\Omega \setminus \{z_0\} \to \mathbb C$ and suppose we know $z_0$ is an essential singularity of $f$. I am wondering what we can say about the function $\tilde{f}:=\frac{1}{f}$ and its singularity in $z_0$. Do you know any theorem that answers to this question? Actually, I can't prove anything, since I do not know the answer: I've studied some examples. For instance, if you take $f(z)=e^{\frac{1}{z}}$ then $\tilde{f}$ will still have an essential singularity, hasn't it? On the other side, if we take $f(z)=\sin(\frac{1}{z})$ then I think that $z_0=0$ becomes a limit point of poles for $\tilde{f}$ (so we can't classify it, because it isn't an isolated singularity). Wha do you think? Do you know any useful theorem concerning this? Thank you in advance.","Let $\Omega$ be a non-empty, open subset of $\mathbb C$. Consider an holomorphic function $f:\Omega \setminus \{z_0\} \to \mathbb C$ and suppose we know $z_0$ is an essential singularity of $f$. I am wondering what we can say about the function $\tilde{f}:=\frac{1}{f}$ and its singularity in $z_0$. Do you know any theorem that answers to this question? Actually, I can't prove anything, since I do not know the answer: I've studied some examples. For instance, if you take $f(z)=e^{\frac{1}{z}}$ then $\tilde{f}$ will still have an essential singularity, hasn't it? On the other side, if we take $f(z)=\sin(\frac{1}{z})$ then I think that $z_0=0$ becomes a limit point of poles for $\tilde{f}$ (so we can't classify it, because it isn't an isolated singularity). Wha do you think? Do you know any useful theorem concerning this? Thank you in advance.",,['complex-analysis']
86,Limit point of poles is essential singularity? Am I speaking nonsense?,Limit point of poles is essential singularity? Am I speaking nonsense?,,"The following is exercise 15 in section V.1 of Conway's Functions of One Complex Variable (""Classification of Singularities""). I'm currently studying for a complex analysis qualifying exam and this has appeared in the past. Let $f$ be analytic in $G=\{z:0<|z-a|&ltr\}$ except that there is a sequence of poles $\{a_n\}$ in $G$ with $a_n\rightarrow a$. Show that for any $w$ in $\mathbb{C}$ there is a sequence $\{z_n\}$ in $G$ with $a=\lim z_n$ and $w=\lim f(z)$. The conclusion makes me want to apply the Casorati-Weirstrass theorem. However, the singularity at $a$ is not isolated. As far as I know, an essential singularity is a particular type of isolated singularity. Am I wrong about this? Any help would be greatly appreciated.","The following is exercise 15 in section V.1 of Conway's Functions of One Complex Variable (""Classification of Singularities""). I'm currently studying for a complex analysis qualifying exam and this has appeared in the past. Let $f$ be analytic in $G=\{z:0<|z-a|&ltr\}$ except that there is a sequence of poles $\{a_n\}$ in $G$ with $a_n\rightarrow a$. Show that for any $w$ in $\mathbb{C}$ there is a sequence $\{z_n\}$ in $G$ with $a=\lim z_n$ and $w=\lim f(z)$. The conclusion makes me want to apply the Casorati-Weirstrass theorem. However, the singularity at $a$ is not isolated. As far as I know, an essential singularity is a particular type of isolated singularity. Am I wrong about this? Any help would be greatly appreciated.",,['complex-analysis']
87,Complex Conjugate of Complex function,Complex Conjugate of Complex function,,"I am currently reading Hamming's Numerical Methods for Scientists and Engineers . On pg. 79 he discusses the topic of finding the zeros of a complex analytic function. He then proceeds to discuss different types of complex conjugation for a function $w(z)$. Here are examples of the three types for $w(z)=\sin z = \frac{e^{iz} - e^{-iz}}{2i}$ $\overline{w}(z)$ : replace $i$ with $-i$ in $w$, e.g. $\overline{w}(z)= \frac{e^{-iz} - e^{iz}}{-2i} = \sin z$. $w(\overline{z})$ : conjugate the argument, $w(\overline{z}) = \frac{e^{i\overline{z}} - e^{-i\overline{z}}}{2i}$ $\overline{w(z)}$ : Hamming describes this as conjugating the values which I take to mean the conjugate of the image of $w(z)$ in the codomain. Although, I am not clear on this. These three definitions have left me a bit confused. 2 and 3 seem relatively straight forward. But 1 leaves me a bit baffled in that it doesn't appear to be an actual complex conjugate of anything. It appears that the first version can only be applied to functions of $z$, because if I rewrite $w(z)=\sin z$ as $w(x + iy) = \sin(x+iy) = \sin x \cosh y + i \cos x \sinh y$ then $\overline{w}(x + iy) = \sin x \cosh y - i \cos x \sinh y \neq w(x+iy) = \sin(x + iy)$ gives what I would expect to be the value of case 3 and a different answer then in the $z$-form where $w(z)=\overline{w}(z) = \sin z$. Also, he later appears to state that $\overline{w(z)} = \overline{w}(\overline{z})$ although it is not clear whether that is true for all analytic functions or just those that have the property of $w(z) = \overline{w}(z)$ like $\sin z$. My question is several-fold. Is the definition of conjugation given in 1 standard? What is its meaning? Also, is my interpretation of 3 correct and is $\overline{w(z)} = \overline{w}(\overline{z})$ the proper definition of 3. Addendum: The motivation behind understanding definition 1 is that Hamming uses it in the proof that analytic complex functions have zeros that are conjugate pairs if the function is real over the real domain. He states without proof that if $w(z)$ is real for real $z$ then $w(z)=\overline{w}(z)$. He then provides the following proof for the above. $w(a+bi)=0=\overline{w(a+bi)}=\overline{w}(a-bi)=w(a-bi)$","I am currently reading Hamming's Numerical Methods for Scientists and Engineers . On pg. 79 he discusses the topic of finding the zeros of a complex analytic function. He then proceeds to discuss different types of complex conjugation for a function $w(z)$. Here are examples of the three types for $w(z)=\sin z = \frac{e^{iz} - e^{-iz}}{2i}$ $\overline{w}(z)$ : replace $i$ with $-i$ in $w$, e.g. $\overline{w}(z)= \frac{e^{-iz} - e^{iz}}{-2i} = \sin z$. $w(\overline{z})$ : conjugate the argument, $w(\overline{z}) = \frac{e^{i\overline{z}} - e^{-i\overline{z}}}{2i}$ $\overline{w(z)}$ : Hamming describes this as conjugating the values which I take to mean the conjugate of the image of $w(z)$ in the codomain. Although, I am not clear on this. These three definitions have left me a bit confused. 2 and 3 seem relatively straight forward. But 1 leaves me a bit baffled in that it doesn't appear to be an actual complex conjugate of anything. It appears that the first version can only be applied to functions of $z$, because if I rewrite $w(z)=\sin z$ as $w(x + iy) = \sin(x+iy) = \sin x \cosh y + i \cos x \sinh y$ then $\overline{w}(x + iy) = \sin x \cosh y - i \cos x \sinh y \neq w(x+iy) = \sin(x + iy)$ gives what I would expect to be the value of case 3 and a different answer then in the $z$-form where $w(z)=\overline{w}(z) = \sin z$. Also, he later appears to state that $\overline{w(z)} = \overline{w}(\overline{z})$ although it is not clear whether that is true for all analytic functions or just those that have the property of $w(z) = \overline{w}(z)$ like $\sin z$. My question is several-fold. Is the definition of conjugation given in 1 standard? What is its meaning? Also, is my interpretation of 3 correct and is $\overline{w(z)} = \overline{w}(\overline{z})$ the proper definition of 3. Addendum: The motivation behind understanding definition 1 is that Hamming uses it in the proof that analytic complex functions have zeros that are conjugate pairs if the function is real over the real domain. He states without proof that if $w(z)$ is real for real $z$ then $w(z)=\overline{w}(z)$. He then provides the following proof for the above. $w(a+bi)=0=\overline{w(a+bi)}=\overline{w}(a-bi)=w(a-bi)$",,"['complex-analysis', 'complex-numbers']"
88,What is the difference between the three types of logarithms? [closed],What is the difference between the three types of logarithms? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question In complex analysis I came across three types of logarithms  namely $\ln$, $\log$ and $\text{Log}$. What is the difference between the three?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question In complex analysis I came across three types of logarithms  namely $\ln$, $\log$ and $\text{Log}$. What is the difference between the three?",,"['complex-analysis', 'notation', 'logarithms']"
89,Entire function with vanishing derivatives?,Entire function with vanishing derivatives?,,"Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be an entire function. And assume that at each point, one of it's derivatives vanishes. What can you say about $f$? A hint suggests that $f$ must be a polynomial.","Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be an entire function. And assume that at each point, one of it's derivatives vanishes. What can you say about $f$? A hint suggests that $f$ must be a polynomial.",,['complex-analysis']
90,Calculating a real integral using complex integration,Calculating a real integral using complex integration,,$$\int^\infty_0 \frac{dx}{x^6 + 1}$$ Does someone know how to calculate this integral using complex integrals? I don't know how to deal with the $x^6$ in the denominator.,$$\int^\infty_0 \frac{dx}{x^6 + 1}$$ Does someone know how to calculate this integral using complex integrals? I don't know how to deal with the $x^6$ in the denominator.,,['complex-analysis']
91,Intuition about the values of Cauchy integrals on the unit circle,Intuition about the values of Cauchy integrals on the unit circle,,"Considering the Cauchy integral $$\oint \frac{f(x)}{(x-z)} dx $$ over the unit circle. The integral equals zero if $z$ is outside the circle, yet it has a value if $z$ is inside the circle. Why is this the case if one just looks at it computationally (without using the Fundamental Theorem of Calculus, etc.). I.e., what can be said along the lines of: when $z$ in in the interior, this and this happens to give a value; whereas when it's exterior, that and that happens to result in $0$. Thanks!","Considering the Cauchy integral $$\oint \frac{f(x)}{(x-z)} dx $$ over the unit circle. The integral equals zero if $z$ is outside the circle, yet it has a value if $z$ is inside the circle. Why is this the case if one just looks at it computationally (without using the Fundamental Theorem of Calculus, etc.). I.e., what can be said along the lines of: when $z$ in in the interior, this and this happens to give a value; whereas when it's exterior, that and that happens to result in $0$. Thanks!",,[]
92,Intuition Behind Maximum Principle (Complex Analysis),Intuition Behind Maximum Principle (Complex Analysis),,"Let $D$ be an open set in the complex plane and $f(z)$ be a non-constant holomorphic function on D. Then $|f(z)|$ has no local maximum on D. I can follow the proof fine - usually if I don't understand a theorem intuitively beforehand, the proof will offer the insight necessary. Here, however, I can't see the reason for the Maximum Principle to hold - or perhaps I was just too shallow in my grasp of the proof.  Does anybody have any shillings of wisdom that they would be willing to offer? Cheers.","Let $D$ be an open set in the complex plane and $f(z)$ be a non-constant holomorphic function on D. Then $|f(z)|$ has no local maximum on D. I can follow the proof fine - usually if I don't understand a theorem intuitively beforehand, the proof will offer the insight necessary. Here, however, I can't see the reason for the Maximum Principle to hold - or perhaps I was just too shallow in my grasp of the proof.  Does anybody have any shillings of wisdom that they would be willing to offer? Cheers.",,"['complex-analysis', 'analysis', 'maximum-principle']"
93,$e^{1/z}$ and Laurent expansion,and Laurent expansion,e^{1/z},"$e^\frac1z$ is not holomorphic at $z=0$, but it is known that it can be expanded as $$e^\frac1z=1+\frac1z+\frac1{2!z^2}+\frac1{3!z^3}+\cdots$$ The coefficients of this Laurent expansion are computed the same way as Taylor's. The question is how is that possible? If function is not holomoprhic at $z=0$, then it's not true that it is holomophic at $|z|<R$ and Taylor's coefficients can not be used.  Please someone explain.","$e^\frac1z$ is not holomorphic at $z=0$, but it is known that it can be expanded as $$e^\frac1z=1+\frac1z+\frac1{2!z^2}+\frac1{3!z^3}+\cdots$$ The coefficients of this Laurent expansion are computed the same way as Taylor's. The question is how is that possible? If function is not holomoprhic at $z=0$, then it's not true that it is holomophic at $|z|<R$ and Taylor's coefficients can not be used.  Please someone explain.",,"['complex-analysis', 'laurent-series']"
94,False proof that every continuous function is holomorphic,False proof that every continuous function is holomorphic,,"Let $\Omega$ be an open subset of $\mathbb{C}$ and $f:\Omega\to\mathbb{C}$ be a continuous function. Consider the following function: $$F(z)=\int_{[z_0,z]}f(w)\:\mathrm{d}w,$$ where $z_0$ is a fixed complex number. Firstly I will prove that $F$ is holomorphic. $$\lim_{h\to 0} \frac{F(z+h)-F(z)}{h} = \lim_{h\to 0} \frac{1}{h}\left(\int_{[z_0,z+h]} f(w)\:\mathrm{d}w - \int_{[z_0,z]} f(w)\:\mathrm{d}w\right)= \lim_{h\to 0} \frac{1}{h}\int_{[z,z+h]} f(w)\:\mathrm{d}w= \lim_{h\to 0} \int_0^1 f(z+th)\:\mathrm{d}t= \int_0^1 \lim_{h\to 0}f(z+th)\:\mathrm{d}t= f(z)$$ We can pass the limit under the integral sign by the following reason: $[0,1]$ is compact and $f$ is continuous. Hence there exists a real number $M>0$ such that $|f(z+th)|\leq M$ for all $t\in[0,1]$. This means that we can use the continuity under the (Lebesgue's) integral sign theorem. Since $F$ is holomorphic and holomorphic functions have derivatives of all orders, $F'=f$ also has derivatives of all orders. In particular, $f$ is holomorphic. Ok, this is clearly an absurd. However I don't know where is my error.","Let $\Omega$ be an open subset of $\mathbb{C}$ and $f:\Omega\to\mathbb{C}$ be a continuous function. Consider the following function: $$F(z)=\int_{[z_0,z]}f(w)\:\mathrm{d}w,$$ where $z_0$ is a fixed complex number. Firstly I will prove that $F$ is holomorphic. $$\lim_{h\to 0} \frac{F(z+h)-F(z)}{h} = \lim_{h\to 0} \frac{1}{h}\left(\int_{[z_0,z+h]} f(w)\:\mathrm{d}w - \int_{[z_0,z]} f(w)\:\mathrm{d}w\right)= \lim_{h\to 0} \frac{1}{h}\int_{[z,z+h]} f(w)\:\mathrm{d}w= \lim_{h\to 0} \int_0^1 f(z+th)\:\mathrm{d}t= \int_0^1 \lim_{h\to 0}f(z+th)\:\mathrm{d}t= f(z)$$ We can pass the limit under the integral sign by the following reason: $[0,1]$ is compact and $f$ is continuous. Hence there exists a real number $M>0$ such that $|f(z+th)|\leq M$ for all $t\in[0,1]$. This means that we can use the continuity under the (Lebesgue's) integral sign theorem. Since $F$ is holomorphic and holomorphic functions have derivatives of all orders, $F'=f$ also has derivatives of all orders. In particular, $f$ is holomorphic. Ok, this is clearly an absurd. However I don't know where is my error.",,['complex-analysis']
95,How do I find the series expansion of the meromorphic function $\frac{1}{e^z+1}$?,How do I find the series expansion of the meromorphic function ?,\frac{1}{e^z+1},"in a theoretical physics book, the author makes the following claim: $$\frac{1}{e^z + 1} = \frac{1}{2} + \sum_{n=-\infty}^\infty \frac{1}{(2n+1) i\pi - z}$$ and justifies this as These series can be derived from a theorem which states that any meromorphic function may be expanded as a summation over its poles and residues at those poles What's the name of that theorem? It's not really a Laurent series, since the Laurent series is for an expansion around one particular point only. I can see that the poles occur whenever $z = (2n+1)i\pi$ for $n \in \mathbb{N}$, but then where does that constant $1/2$ come from? EDIT: Well, it appears that the general claim isn't valid, so now I'd be interested in a justification for the expansion in my particular example...","in a theoretical physics book, the author makes the following claim: $$\frac{1}{e^z + 1} = \frac{1}{2} + \sum_{n=-\infty}^\infty \frac{1}{(2n+1) i\pi - z}$$ and justifies this as These series can be derived from a theorem which states that any meromorphic function may be expanded as a summation over its poles and residues at those poles What's the name of that theorem? It's not really a Laurent series, since the Laurent series is for an expansion around one particular point only. I can see that the poles occur whenever $z = (2n+1)i\pi$ for $n \in \mathbb{N}$, but then where does that constant $1/2$ come from? EDIT: Well, it appears that the general claim isn't valid, so now I'd be interested in a justification for the expansion in my particular example...",,['complex-analysis']
96,Interesting but elementary properties of the Mandelbrot Set,Interesting but elementary properties of the Mandelbrot Set,,"I suppose everyone is familiar with the Mandelbrot set. I'm teaching a course right now in which I am trying to convey the beauty of some mathematical ideas to first year students. They basically know calculus but not much beyond. The Mandelbrot set is certainly fascinating in that you can zoom in and get an incredible amount of detail, all out of an analysis of the simple recursion $z\mapsto z^2+c$. So my plan is to show them a movie of a deep fractal zoom, and go over the definition of the Mandelbrot set. But I'd like to also show them something mathematically rigorous, and the main interesting properties I know about the Mandelbrot set are well beyond the scope of the course. I could mention connectedness, which is of course a seminal result, but that's probably not that interesting to someone at their level. So my question is whether anyone has any ideas about an interesting property of the Mandelbrot set that I could discuss at the calculus level, hopefully including an actual calculation or simple proof.","I suppose everyone is familiar with the Mandelbrot set. I'm teaching a course right now in which I am trying to convey the beauty of some mathematical ideas to first year students. They basically know calculus but not much beyond. The Mandelbrot set is certainly fascinating in that you can zoom in and get an incredible amount of detail, all out of an analysis of the simple recursion $z\mapsto z^2+c$. So my plan is to show them a movie of a deep fractal zoom, and go over the definition of the Mandelbrot set. But I'd like to also show them something mathematically rigorous, and the main interesting properties I know about the Mandelbrot set are well beyond the scope of the course. I could mention connectedness, which is of course a seminal result, but that's probably not that interesting to someone at their level. So my question is whether anyone has any ideas about an interesting property of the Mandelbrot set that I could discuss at the calculus level, hopefully including an actual calculation or simple proof.",,"['complex-analysis', 'dynamical-systems', 'education', 'fractals']"
97,Equilateral Triangle from three complex points,Equilateral Triangle from three complex points,,"I need some help proving this, I've seen it proven in the other direction (prove the formula if it is an equilateral) but cant figure out how to prove it this way around. Given three complex numbers $z_1, z_2, z_3$ prove that the points $z_1, z_2, z_3$ are vertices of an equilateral triangle in $\Bbb C$, if $$z_1^2 + z_2^2 + z_3^2 = z_1z_2 + z_1z_3 + z_2z_3$$","I need some help proving this, I've seen it proven in the other direction (prove the formula if it is an equilateral) but cant figure out how to prove it this way around. Given three complex numbers $z_1, z_2, z_3$ prove that the points $z_1, z_2, z_3$ are vertices of an equilateral triangle in $\Bbb C$, if $$z_1^2 + z_2^2 + z_3^2 = z_1z_2 + z_1z_3 + z_2z_3$$",,['complex-analysis']
98,"How to Prove that if $f(z)$ is entire, and $f(z+i) = f(z), f(z+1) = f(z)$, then $f(z)$ is constant?","How to Prove that if  is entire, and , then  is constant?","f(z) f(z+i) = f(z), f(z+1) = f(z) f(z)","So the problem states that if $f(z)$ is entire, and satisfies the relation $f(z+i) = f(z)$ and $f(z+1) = f(z)$ , show that $f(z)$ is constant. So I was thinking that since any point in $\mathbb{C}$ can be written as $\alpha * 1 + \beta * i $ we can say that $f(z + z_0) = f(z) $ in which case it is constant, but I'm having trouble breaking down the steps and using the fact that $f$ is entire, which makes me feel like I'm missing something. What should I review to figure this out?","So the problem states that if is entire, and satisfies the relation and , show that is constant. So I was thinking that since any point in can be written as we can say that in which case it is constant, but I'm having trouble breaking down the steps and using the fact that is entire, which makes me feel like I'm missing something. What should I review to figure this out?",f(z) f(z+i) = f(z) f(z+1) = f(z) f(z) \mathbb{C} \alpha * 1 + \beta * i  f(z + z_0) = f(z)  f,"['complex-analysis', 'entire-functions']"
99,Why can the meromorphic function only have finitely many poles in the complex plane?,Why can the meromorphic function only have finitely many poles in the complex plane?,,There is a proof in Complex Analysis by Stein-Shakarchi that I do not understand. I have highlighted it in red. Why can they say that $f$ only has a finite number of points? What makes them able to exclude the countable number in the definition of a meromorphic function?,There is a proof in Complex Analysis by Stein-Shakarchi that I do not understand. I have highlighted it in red. Why can they say that $f$ only has a finite number of points? What makes them able to exclude the countable number in the definition of a meromorphic function?,,"['complex-analysis', 'proof-explanation']"
