,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"If two modules are each isomorphic to direct summands of the other, must they be isomorphic?","If two modules are each isomorphic to direct summands of the other, must they be isomorphic?",,"Let $R$ be a ring. $M,N$ are left $R$-modules such that $M$ is isomorphic to a direct summand of $N$ and $N$ is isomorphic to a direct summand of $M$. Could we get that $M \cong N$?  (This holds if $M,N$ are finitely generated.  I think it also holds if $M,N$ are semisimple.  But I don't have a proof for the general case.)","Let $R$ be a ring. $M,N$ are left $R$-modules such that $M$ is isomorphic to a direct summand of $N$ and $N$ is isomorphic to a direct summand of $M$. Could we get that $M \cong N$?  (This holds if $M,N$ are finitely generated.  I think it also holds if $M,N$ are semisimple.  But I don't have a proof for the general case.)",,"['abstract-algebra', 'modules']"
1,Difference between 'free algebra' and 'absolutely free algebra',Difference between 'free algebra' and 'absolutely free algebra',,What is the difference between a free algebra and an absolutely free algebra? Wikipedia and Encyclopaedia of Maths are not very clear on the subject...,What is the difference between a free algebra and an absolutely free algebra? Wikipedia and Encyclopaedia of Maths are not very clear on the subject...,,['abstract-algebra']
2,Prove that $\mathbb{Q}$ is not projective using the Hom functor,Prove that  is not projective using the Hom functor,\mathbb{Q},"I am aware of more direct proofs of this on this website but I am looking for a proof along the following lines: Find an epimorphism $f:A \to B$ such that $Hom(\mathbb{Q},A) \to Hom(\mathbb{Q},B)$ is not an epimorphism. Therefore the above Hom functor is not exact and $\mathbb{Q}$ is not projective. I am thinking that I should use the fact that $Hom(\mathbb{Q},\mathbb{Z})=0$.","I am aware of more direct proofs of this on this website but I am looking for a proof along the following lines: Find an epimorphism $f:A \to B$ such that $Hom(\mathbb{Q},A) \to Hom(\mathbb{Q},B)$ is not an epimorphism. Therefore the above Hom functor is not exact and $\mathbb{Q}$ is not projective. I am thinking that I should use the fact that $Hom(\mathbb{Q},\mathbb{Z})=0$.",,"['abstract-algebra', 'modules', 'homological-algebra', 'projective-module']"
3,A module that has a basis shorter than its rank?,A module that has a basis shorter than its rank?,,"Rank has been defined to me as the maximum number of elements of M which are linearly independent, allowing the rank to be $0$ if the module is of torsion, or $\infty$ if there is no maximum. Now, the course is based pretty much on the book Abstract Algebra by Dummit and Foote, and there the rank is defined to be as the length of a basis of $M$ (assume $M$ has a finite basis and that $R$ is commutative with $1$ here to have a well defined rank). We now are seeing the following theorem: Let $R$ be a PID and $M$ a free module of rank $n$ . Then any submodule $N$ of $M$ satisfies: (1) $N$ is free of rank less than $n$ . (2) There is a basis $y_1,...,y_n$ of $M$ such that $r_1y_1,...,r_ty_t$ is a basis for $N$ , for some $t \le n$ . I think that, according to my definition, the length of the basis' of M doesn't have to be n. It certainly can't be more than n, cause then the elements would be l.d., but it could be less than n. In consequence, the assertion (2) makes no sense a priori. My question is whether the fact that $R$ is a PID and $M$ is a free module over $R$ implies that both definitions of rank coincide (i.e., that the maximum number of l.i. elements is also the length of a basis's of $M$ ), or whether this was just a mistake due to my professor giving a different definition of rank.","Rank has been defined to me as the maximum number of elements of M which are linearly independent, allowing the rank to be if the module is of torsion, or if there is no maximum. Now, the course is based pretty much on the book Abstract Algebra by Dummit and Foote, and there the rank is defined to be as the length of a basis of (assume has a finite basis and that is commutative with here to have a well defined rank). We now are seeing the following theorem: Let be a PID and a free module of rank . Then any submodule of satisfies: (1) is free of rank less than . (2) There is a basis of such that is a basis for , for some . I think that, according to my definition, the length of the basis' of M doesn't have to be n. It certainly can't be more than n, cause then the elements would be l.d., but it could be less than n. In consequence, the assertion (2) makes no sense a priori. My question is whether the fact that is a PID and is a free module over implies that both definitions of rank coincide (i.e., that the maximum number of l.i. elements is also the length of a basis's of ), or whether this was just a mistake due to my professor giving a different definition of rank.","0 \infty M M R 1 R M n N M N n y_1,...,y_n M r_1y_1,...,r_ty_t N t \le n R M R M","['abstract-algebra', 'modules']"
4,What are some local properties? [closed],What are some local properties? [closed],,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question What I mean by the question is for example the following statement: Let $R$ be a ring and suppose that for each prime ideal $\mathfrak{p}$ the local ring $R_{\mathfrak{p}}$ has no nilpotent elements. Then $R$ itself also has no nilpotent elements. So we call having nilpotent elements a local property. What are other local properties or what are non-local properties? For example being an integral domain is not a local property.,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question What I mean by the question is for example the following statement: Let $R$ be a ring and suppose that for each prime ideal $\mathfrak{p}$ the local ring $R_{\mathfrak{p}}$ has no nilpotent elements. Then $R$ itself also has no nilpotent elements. So we call having nilpotent elements a local property. What are other local properties or what are non-local properties? For example being an integral domain is not a local property.,,"['abstract-algebra', 'algebraic-geometry', 'ring-theory', 'commutative-algebra', 'localization']"
5,How many roots does $f=x^4+x^2+2$ have in $\mathbb Q[x]/(f)$?,How many roots does  have in ?,f=x^4+x^2+2 \mathbb Q[x]/(f),"Given an irreducible $f\in \mathbb Q[x]$, how to determine the number of roots of $f=0$ in $\mathbb Q[x]/(f)$? For some simple examples, I know how to do. If $f(x)=x^2+x-1$, the we use $x\in\mathbb Q[x]/(f)$ to represent $(-1+\sqrt 5)/2$, and $-x-1$ will be another root. If $f=x^3-2$, $x\in\mathbb Q[x]/(f)$ will represent $2^{1/3}$, and it is the only root of $f=0$ in $\mathbb Q[x]/(f)$, since the other roots are complex. But for more complicated $f$, e.g. $f=x^4+x^2+2$, I have no idea how to find the number of roots in the extended field. Thank you.","Given an irreducible $f\in \mathbb Q[x]$, how to determine the number of roots of $f=0$ in $\mathbb Q[x]/(f)$? For some simple examples, I know how to do. If $f(x)=x^2+x-1$, the we use $x\in\mathbb Q[x]/(f)$ to represent $(-1+\sqrt 5)/2$, and $-x-1$ will be another root. If $f=x^3-2$, $x\in\mathbb Q[x]/(f)$ will represent $2^{1/3}$, and it is the only root of $f=0$ in $\mathbb Q[x]/(f)$, since the other roots are complex. But for more complicated $f$, e.g. $f=x^4+x^2+2$, I have no idea how to find the number of roots in the extended field. Thank you.",,"['abstract-algebra', 'field-theory', 'extension-field']"
6,To show that R is a division ring given some property on ring R.,To show that R is a division ring given some property on ring R.,,"Let $R$ be a non-zero ring such that the equation $ax=b$ has a solution in $R$ for all $a, b\in R$ with $a\neq 0$. Show that $R$ must have unity and it is a division ring. Now to show this we need to show that every non zero element is invertible. If we take '$a$' as non zero element with $ax=b$ then how can I use the given fact to show the ring is a division ring. Please help.","Let $R$ be a non-zero ring such that the equation $ax=b$ has a solution in $R$ for all $a, b\in R$ with $a\neq 0$. Show that $R$ must have unity and it is a division ring. Now to show this we need to show that every non zero element is invertible. If we take '$a$' as non zero element with $ax=b$ then how can I use the given fact to show the ring is a division ring. Please help.",,"['abstract-algebra', 'ring-theory']"
7,Uniqueness of the remainder and quotient in an Euclidean domain,Uniqueness of the remainder and quotient in an Euclidean domain,,"Let $R$ be a Euclidean ring with Euclidean norm $N$. Let $a,b\in R\setminus\{0\}$ and let $q,r\in R$  such that $a=bq+r$ with $r=0$ or $N(r)<N(b)$. Prove that $r$ and $q$ are unique if and only if $N(a+b)\le\max\{N(a),N(b)\}$. I do not see how to relate both. If I suppose the second: let $q'$ and $r'$ be  such that  $a=bq'+r'$ with $r'=0$ or $N(r')<N(b)$ It is sufficient to prove that $r'=r$, because in this case $a=bq'+r'=bq+r$ implies $bq'=bq$ and then $q'=q$. How $bq'+r'=bq+r$ then  $r'-r=b(q-q')$. By the properties of Euclidian norm: $$ N(r')-N(r)\le N(r)<N(b) \quad\text{and}\quad N(r-r')=N(b(q-q'))\ge N(b) $$ I got other inequalities but I do not think they are any good. For the converse I have no idea.","Let $R$ be a Euclidean ring with Euclidean norm $N$. Let $a,b\in R\setminus\{0\}$ and let $q,r\in R$  such that $a=bq+r$ with $r=0$ or $N(r)<N(b)$. Prove that $r$ and $q$ are unique if and only if $N(a+b)\le\max\{N(a),N(b)\}$. I do not see how to relate both. If I suppose the second: let $q'$ and $r'$ be  such that  $a=bq'+r'$ with $r'=0$ or $N(r')<N(b)$ It is sufficient to prove that $r'=r$, because in this case $a=bq'+r'=bq+r$ implies $bq'=bq$ and then $q'=q$. How $bq'+r'=bq+r$ then  $r'-r=b(q-q')$. By the properties of Euclidian norm: $$ N(r')-N(r)\le N(r)<N(b) \quad\text{and}\quad N(r-r')=N(b(q-q'))\ge N(b) $$ I got other inequalities but I do not think they are any good. For the converse I have no idea.",,"['abstract-algebra', 'ring-theory', 'euclidean-domain']"
8,Formal Construction of Polynomial Ring in Several Variables,Formal Construction of Polynomial Ring in Several Variables,,"The formal construction of the polynomial ring in one variable is briefly the following: We take a ring $(R,+,\cdot)$ with $1_R$. We define $R^{ \mathbb{N}}$ be the set of all the sequences $(a_0,a_1,a_2,a_3,...)$, $a_i \in R^{ \mathbb{N}},\forall i\in \mathbb{N}$ and we define the following operations:  $$+:  R^{ \mathbb{N}} \times  R^{ \mathbb{N}} \longrightarrow  R^{ \mathbb{N}},\  ((a_0,a_1,a_2,...),(b_0,b_1,b_2,...))\mapsto (a_0,a_1,a_2,...)+(b_0,b_1,b_2,...):= (a_0+b_0,a_1+b_1,a_2+b_2,...)$$ and $$\cdot:  R^{ \mathbb{N}} \times  R^{ \mathbb{N}} \longrightarrow  R^{ \mathbb{N}},\ ((a_0,a_1,a_2,...),(b_0,b_1,b_2,...))\mapsto (a_0,a_1,a_2,...) \cdot (b_0,b_1,b_2,...):=(c_0,c_1,c_2,...)$$ with $c_n=a_0b_n+a_1b_{n-1}+...+a_{n-1}b_1+a_nb_0,\forall n\in \mathbb{N}=\{0,1,...\}$. Furthermore we define the equality $(a_0,a_1,a_2,...)=(b_0,b_1,b_2,...) \iff a_i=b_i, \forall i\in \mathbb{N}$. With these two binary operations we have that $(R^{ \mathbb{N}},+\cdot )$ is a ring with $1_{R^{ \mathbb{N}}}=(1_R,0_R,0_R,...)$. Now, polynomial is every element of the last ring of the form $(a_0,a_1,a_2,...,a_n,0_R,0_R,...)$. If $R[X]$ is the set of all the polynomials then $R[X]$ is a subring of $R^{ \mathbb{N}}$ and the mapping $f:R\longrightarrow R[X]$, $a\mapsto (a,0_R,0_R,...) $ is a monomorphism. So, we can say that $R$ is a subring of $R[X]$, and after this we have all the usual theorems. My question is: How we can do exactly the same construction in the polynomial ring in several variables with the same procedure? PS 1: I apologize for my English. If you don't understand something ask me please. PS 2: I know that a similar question already exists, but I think I have a different procedure. Thank you in advance.","The formal construction of the polynomial ring in one variable is briefly the following: We take a ring $(R,+,\cdot)$ with $1_R$. We define $R^{ \mathbb{N}}$ be the set of all the sequences $(a_0,a_1,a_2,a_3,...)$, $a_i \in R^{ \mathbb{N}},\forall i\in \mathbb{N}$ and we define the following operations:  $$+:  R^{ \mathbb{N}} \times  R^{ \mathbb{N}} \longrightarrow  R^{ \mathbb{N}},\  ((a_0,a_1,a_2,...),(b_0,b_1,b_2,...))\mapsto (a_0,a_1,a_2,...)+(b_0,b_1,b_2,...):= (a_0+b_0,a_1+b_1,a_2+b_2,...)$$ and $$\cdot:  R^{ \mathbb{N}} \times  R^{ \mathbb{N}} \longrightarrow  R^{ \mathbb{N}},\ ((a_0,a_1,a_2,...),(b_0,b_1,b_2,...))\mapsto (a_0,a_1,a_2,...) \cdot (b_0,b_1,b_2,...):=(c_0,c_1,c_2,...)$$ with $c_n=a_0b_n+a_1b_{n-1}+...+a_{n-1}b_1+a_nb_0,\forall n\in \mathbb{N}=\{0,1,...\}$. Furthermore we define the equality $(a_0,a_1,a_2,...)=(b_0,b_1,b_2,...) \iff a_i=b_i, \forall i\in \mathbb{N}$. With these two binary operations we have that $(R^{ \mathbb{N}},+\cdot )$ is a ring with $1_{R^{ \mathbb{N}}}=(1_R,0_R,0_R,...)$. Now, polynomial is every element of the last ring of the form $(a_0,a_1,a_2,...,a_n,0_R,0_R,...)$. If $R[X]$ is the set of all the polynomials then $R[X]$ is a subring of $R^{ \mathbb{N}}$ and the mapping $f:R\longrightarrow R[X]$, $a\mapsto (a,0_R,0_R,...) $ is a monomorphism. So, we can say that $R$ is a subring of $R[X]$, and after this we have all the usual theorems. My question is: How we can do exactly the same construction in the polynomial ring in several variables with the same procedure? PS 1: I apologize for my English. If you don't understand something ask me please. PS 2: I know that a similar question already exists, but I think I have a different procedure. Thank you in advance.",,"['abstract-algebra', 'polynomials', 'ring-theory']"
9,Sylow $p$-subgroups of $GL_n(\mathbb{F}_p)$,Sylow -subgroups of,p GL_n(\mathbb{F}_p),"How to find the number $n_p$ of Sylow $p$-subgroups of $GL_n(\mathbb{F}_p)$? For example, in $GL_3(\mathbb{F}_p)$, $|GL_3(\mathbb{F}_p)|=(p^3-1)(p^3-p)(p^3-p^2) = p^3(p-1)^3(p+1)(p^2+p+1)$, we have the Heisenberg group $$ \begin{pmatrix} 1&x&y\\ 0&1&z\\ 0&0&1 \end{pmatrix} $$ as a Sylow $p$-subgroup. And its normalizer is at least the upper triangular matrices, which has order $p^3(p-1)^3$. So we now know $n_p\mid(p+1)(p^2+p+1)$. How to proceed from here to determine $n_p$?","How to find the number $n_p$ of Sylow $p$-subgroups of $GL_n(\mathbb{F}_p)$? For example, in $GL_3(\mathbb{F}_p)$, $|GL_3(\mathbb{F}_p)|=(p^3-1)(p^3-p)(p^3-p^2) = p^3(p-1)^3(p+1)(p^2+p+1)$, we have the Heisenberg group $$ \begin{pmatrix} 1&x&y\\ 0&1&z\\ 0&0&1 \end{pmatrix} $$ as a Sylow $p$-subgroup. And its normalizer is at least the upper triangular matrices, which has order $p^3(p-1)^3$. So we now know $n_p\mid(p+1)(p^2+p+1)$. How to proceed from here to determine $n_p$?",,"['abstract-algebra', 'group-theory']"
10,Is it true that an isomorphism maps elements of the same order to each other?,Is it true that an isomorphism maps elements of the same order to each other?,,"I know that for two groups to be isomorphic each group must contain elements of the same order.  So then are elements of the same order mapped to each other?  If so, why?","I know that for two groups to be isomorphic each group must contain elements of the same order.  So then are elements of the same order mapped to each other?  If so, why?",,"['abstract-algebra', 'group-theory', 'group-isomorphism']"
11,Definition of exterior algebra,Definition of exterior algebra,,"I'm studying tensor algebra and exterior algebra and having problems with the definition of $\bigwedge(\mathbb{V})$. Let $\mathbb{V}$ be any vectorial space over a field $K$. Define $T^k\mathbb{V}:=\underbrace{\mathbb{V}\otimes \mathbb{V}\otimes\cdots\otimes\mathbb{V}}_{k-times}$, where $T^0\mathbb{V}=K$. Define the tensorial algebra $T(\mathbb{V}):=\bigoplus_{k=0}^{\infty}T^k(\mathbb{V})=K\oplus\mathbb{V}\oplus(\mathbb{V}\otimes\mathbb{V})\oplus\cdots$. Multiplication on $T(\mathbb{V})$ is determinated by the canonical isomorphism $T^k(\mathbb{V})\oplus T^j(\mathbb{V})\rightarrow T^{k+j}(\mathbb{V})$, so $T(\mathbb{V})$ is naturally a graded algebra. Define exterior algebra (and here is my doubt) $\bigwedge(\mathbb{V})$ over a $K$-vector space $\mathbb{V}$ as the quotient algebra  of the tensorial algebra $T(\mathbb{V})$ by the two sided ideal $I$ spanned by the elements of the form $x\otimes x$ with $x\in\mathbb{V}$, $\bigwedge(\mathbb{V}):=\dfrac{T(\mathbb{V})}{I}$ My question is, first of all how are specifically the elements of $I$? It is a subspace of $T(\mathbb{V})$.","I'm studying tensor algebra and exterior algebra and having problems with the definition of $\bigwedge(\mathbb{V})$. Let $\mathbb{V}$ be any vectorial space over a field $K$. Define $T^k\mathbb{V}:=\underbrace{\mathbb{V}\otimes \mathbb{V}\otimes\cdots\otimes\mathbb{V}}_{k-times}$, where $T^0\mathbb{V}=K$. Define the tensorial algebra $T(\mathbb{V}):=\bigoplus_{k=0}^{\infty}T^k(\mathbb{V})=K\oplus\mathbb{V}\oplus(\mathbb{V}\otimes\mathbb{V})\oplus\cdots$. Multiplication on $T(\mathbb{V})$ is determinated by the canonical isomorphism $T^k(\mathbb{V})\oplus T^j(\mathbb{V})\rightarrow T^{k+j}(\mathbb{V})$, so $T(\mathbb{V})$ is naturally a graded algebra. Define exterior algebra (and here is my doubt) $\bigwedge(\mathbb{V})$ over a $K$-vector space $\mathbb{V}$ as the quotient algebra  of the tensorial algebra $T(\mathbb{V})$ by the two sided ideal $I$ spanned by the elements of the form $x\otimes x$ with $x\in\mathbb{V}$, $\bigwedge(\mathbb{V}):=\dfrac{T(\mathbb{V})}{I}$ My question is, first of all how are specifically the elements of $I$? It is a subspace of $T(\mathbb{V})$.",,"['abstract-algebra', 'tensor-products', 'exterior-algebra']"
12,"Polynomial irreducibility test over finite field $\Bbb F_3$, $x^5-x-1\bmod 3$","Polynomial irreducibility test over finite field ,",\Bbb F_3 x^5-x-1\bmod 3,"I am reading a text, where it says that $X^5-X-1$ is irreducible modulo 3. I am not sure how I can know that. Could someone help? By the way, is there some practical trick to judge whether a polynomial irreducible over a finite field in general? Because when I calculate the galois group I find this information is very important, so I am very curious. Thanks!","I am reading a text, where it says that $X^5-X-1$ is irreducible modulo 3. I am not sure how I can know that. Could someone help? By the way, is there some practical trick to judge whether a polynomial irreducible over a finite field in general? Because when I calculate the galois group I find this information is very important, so I am very curious. Thanks!",,"['abstract-algebra', 'ring-theory', 'field-theory', 'irreducible-polynomials', 'primality-test']"
13,Is the set of hyperreal numbers a quotient ring?,Is the set of hyperreal numbers a quotient ring?,,"It is easy to see that the set of real sequences $\mathbb{R}^{\mathbb{N}}$ is a ring. It suffices to define, for all $r,s\in\mathbb{R}^{\mathbb{N}}$, the operations $r\oplus s =(r_n+s_n)_{n\in\mathbb{N}}$ and $r\odot s=(r_n\cdot s_n)_{n\in\mathbb{N}}$. Let $\mathcal{U}$ be a nonprincipal ultrafilter on $\mathbb{N}$. For all $r\in\mathbb{R}^{\mathbb{N}}$, we define the set $r^{(0)}=\{n\in\mathbb{N} \mid r_n=0\}$. My question: Is the set of the $\textit{almost null sequences}$ $$ \mathbb{I} = \{r\in\mathbb{R}^{\mathbb{N}}\mid r^{(0)}\!\in\mathcal{U}\} $$ a two-sided ideal of $\mathbb{R}^{\mathbb{N}}$?  I think yes, because if $s\in\mathbb{I}$ and $r\in\mathbb{R}^{\mathbb{N}}$, then $(s\odot r)^{(0)}\in\mathcal{U}$ (i.e. the product of any sequence and an almost null sequence is almost null). If yes, is the set of the hyperreal numbers the quotient ring $\mathbb{R}^{\mathbb{N}}\diagup \mathbb{I}$? In this case two sequences should belong to the same class if their difference is almost null (namely, they match on an index set which belongs to the ultrafilter $\mathcal{U}$)","It is easy to see that the set of real sequences $\mathbb{R}^{\mathbb{N}}$ is a ring. It suffices to define, for all $r,s\in\mathbb{R}^{\mathbb{N}}$, the operations $r\oplus s =(r_n+s_n)_{n\in\mathbb{N}}$ and $r\odot s=(r_n\cdot s_n)_{n\in\mathbb{N}}$. Let $\mathcal{U}$ be a nonprincipal ultrafilter on $\mathbb{N}$. For all $r\in\mathbb{R}^{\mathbb{N}}$, we define the set $r^{(0)}=\{n\in\mathbb{N} \mid r_n=0\}$. My question: Is the set of the $\textit{almost null sequences}$ $$ \mathbb{I} = \{r\in\mathbb{R}^{\mathbb{N}}\mid r^{(0)}\!\in\mathcal{U}\} $$ a two-sided ideal of $\mathbb{R}^{\mathbb{N}}$?  I think yes, because if $s\in\mathbb{I}$ and $r\in\mathbb{R}^{\mathbb{N}}$, then $(s\odot r)^{(0)}\in\mathcal{U}$ (i.e. the product of any sequence and an almost null sequence is almost null). If yes, is the set of the hyperreal numbers the quotient ring $\mathbb{R}^{\mathbb{N}}\diagup \mathbb{I}$? In this case two sequences should belong to the same class if their difference is almost null (namely, they match on an index set which belongs to the ultrafilter $\mathcal{U}$)",,"['abstract-algebra', 'elementary-set-theory', 'nonstandard-analysis']"
14,The group algebra $KG$,The group algebra,KG,"If $G$ is a cyclic group of order $m$. Then $KG\cong K[t]/(t^m-1)$. Where $K$ is a field. I define \begin{align*} \varphi:K[t]&\longrightarrow KG\\ \sum_ia_it^i&\longmapsto\sum_ia_ig^i \end{align*}  where $\left\langle g\right\rangle=G$ and $a_i\in K$ and $\varphi$ is surjective and homomorphism. Let $I=\left\langle t^m-1\right\rangle$. So I want to prove that $ker\varphi\subseteq I$. Thus Let $p(t)\in ker\varphi$, where $p(t)=\sum_ia_it^i$, and $e$ the identity of $G$. Then \begin{align*} \varphi(p(t))&=\varphi\left(\sum_ia_it^i\right)\\ &=0\\ &=\sum_ib_ig^i-\sum_ib_ig^i\\ &=\sum_ib_ieg^i-\sum_ib_ig^i\\ &=\sum_ib_ig^mg^i-\sum_ib_ig^i\\ &=\sum_ib_ig^{m+i}-\sum_ib_ig^i\\ &=\varphi\left(\sum_ib_it^{m+i}\right)-\varphi\left(\sum_ib_it^i\right)\\ &=\varphi\left(\sum_ib_it^{m+i}-\sum_ib_it^i\right)\\ &=\varphi\left(\sum_ib_it^{i}(t^m-1)\right)\\ &=\varphi\left(q(t)(t^m-1)\right) \end{align*}  Where $q(t)=\sum_ib_it^i$ and $b_i\in K$. How I can guarantee that $p(t)=q(t)(t^m-1)$?","If $G$ is a cyclic group of order $m$. Then $KG\cong K[t]/(t^m-1)$. Where $K$ is a field. I define \begin{align*} \varphi:K[t]&\longrightarrow KG\\ \sum_ia_it^i&\longmapsto\sum_ia_ig^i \end{align*}  where $\left\langle g\right\rangle=G$ and $a_i\in K$ and $\varphi$ is surjective and homomorphism. Let $I=\left\langle t^m-1\right\rangle$. So I want to prove that $ker\varphi\subseteq I$. Thus Let $p(t)\in ker\varphi$, where $p(t)=\sum_ia_it^i$, and $e$ the identity of $G$. Then \begin{align*} \varphi(p(t))&=\varphi\left(\sum_ia_it^i\right)\\ &=0\\ &=\sum_ib_ig^i-\sum_ib_ig^i\\ &=\sum_ib_ieg^i-\sum_ib_ig^i\\ &=\sum_ib_ig^mg^i-\sum_ib_ig^i\\ &=\sum_ib_ig^{m+i}-\sum_ib_ig^i\\ &=\varphi\left(\sum_ib_it^{m+i}\right)-\varphi\left(\sum_ib_it^i\right)\\ &=\varphi\left(\sum_ib_it^{m+i}-\sum_ib_it^i\right)\\ &=\varphi\left(\sum_ib_it^{i}(t^m-1)\right)\\ &=\varphi\left(q(t)(t^m-1)\right) \end{align*}  Where $q(t)=\sum_ib_it^i$ and $b_i\in K$. How I can guarantee that $p(t)=q(t)(t^m-1)$?",,"['abstract-algebra', 'group-theory']"
15,Is there a binary operation satisfying these conditions?,Is there a binary operation satisfying these conditions?,,"Last night I started to read some book that has to do with applications of groups in physics and the question came in my mind about the existence of some structure, which I define in this way: Suppose that we have set $S$ which has at least countably infinite number of elements which is equipped with the binary operation $*$ and that we have: 1) $\forall x,y \in S$ we have $x*y \in S$ 2) There exist one and only one $e \in S$ such that we have $x*e=e*x=x$, for every $x \in S$. 3) For every $x \in S$ there exist $l \in S$ and $r \in S$ such that we have $l*x=e$ and $x*r=e$ and $l \neq r$. So this structure is similar to the group in that that it satisfies closure axiom and it has unique identity element but it is different from group in that that every element has left and right inverse which do not coincide and we do not assume associativity. Since I know that there are a lot of structures in mathematics if this structure exists it is probably not something new, but I do not know. And now the question: Does structure defined in this way exist?","Last night I started to read some book that has to do with applications of groups in physics and the question came in my mind about the existence of some structure, which I define in this way: Suppose that we have set $S$ which has at least countably infinite number of elements which is equipped with the binary operation $*$ and that we have: 1) $\forall x,y \in S$ we have $x*y \in S$ 2) There exist one and only one $e \in S$ such that we have $x*e=e*x=x$, for every $x \in S$. 3) For every $x \in S$ there exist $l \in S$ and $r \in S$ such that we have $l*x=e$ and $x*r=e$ and $l \neq r$. So this structure is similar to the group in that that it satisfies closure axiom and it has unique identity element but it is different from group in that that every element has left and right inverse which do not coincide and we do not assume associativity. Since I know that there are a lot of structures in mathematics if this structure exists it is probably not something new, but I do not know. And now the question: Does structure defined in this way exist?",,['abstract-algebra']
16,Is a matrix over a PID similar to its transpose?,Is a matrix over a PID similar to its transpose?,,"We say that two matrices $A,\,B\in M_n(R)$ are similar if there is some invertible matrix $P$ such that $P^{-1}AP=B$ . Now, if $R$ was a field (or certainly an algebraically closed field) then it is straightforward to show $A$ and $A^T$ are similar. Simply use the Jordan form. I am wondering if this result also holds true over more general rings, say a PID. As a starting position I was thinking of looking over $\mathbb{Z}$ and perhaps using the Smith Normal Form in some way.","We say that two matrices are similar if there is some invertible matrix such that . Now, if was a field (or certainly an algebraically closed field) then it is straightforward to show and are similar. Simply use the Jordan form. I am wondering if this result also holds true over more general rings, say a PID. As a starting position I was thinking of looking over and perhaps using the Smith Normal Form in some way.","A,\,B\in M_n(R) P P^{-1}AP=B R A A^T \mathbb{Z}","['abstract-algebra', 'matrices', 'jordan-normal-form', 'principal-ideal-domains', 'transpose']"
17,A Noetherian integral domain is a UFD iff $(f):(g)$ is principal,A Noetherian integral domain is a UFD iff  is principal,(f):(g),"Let $R$ be a Noetherian integral domain. For $f, g \in R$, define $(f):(g)=\{h \in R \mid hg \in (f) \}$. Sow that $R$ is a UFD if and only if $(f):(g)$ is principal for all $f,g \in R$. It is easy to show that $(f):(g)$ is an ideal. For the forward direction, I suspect that I need to use the fact that $R$ is Noetherian to show that $(f):(g)$ is principal. For the reverse direction, I know that if every $(f):(g)$ is principal then the ring $R$ is a PID. But I don't know how to proceed. Any ideas?","Let $R$ be a Noetherian integral domain. For $f, g \in R$, define $(f):(g)=\{h \in R \mid hg \in (f) \}$. Sow that $R$ is a UFD if and only if $(f):(g)$ is principal for all $f,g \in R$. It is easy to show that $(f):(g)$ is an ideal. For the forward direction, I suspect that I need to use the fact that $R$ is Noetherian to show that $(f):(g)$ is principal. For the reverse direction, I know that if every $(f):(g)$ is principal then the ring $R$ is a PID. But I don't know how to proceed. Any ideas?",,"['abstract-algebra', 'ring-theory', 'noetherian', 'unique-factorization-domains']"
18,Semisimplicity of the induced representation of an irreducible representation,Semisimplicity of the induced representation of an irreducible representation,,"Let $G$ be an arbitrary group, $H$ be a subgroup of finite index $n$ and $k$ be an algebraically closed field of characteristic prime to $n$. Suppose that we have an irreducible representation $$\rho: H\to \mathrm{GL}(V)$$ where $V$ is a finite-dimensional $k$-vector space. Is the induced representation $\mathrm{Ind}_H^G(\rho)$ semisimple? This will certainly be true if $H$ is finite of order prime to the characteristic, or if we are in characteristic $0$ and $G$ is compact. Can we get away with less in this case? If $\mathrm{Ind}_H^G(\rho)$ is not semisimple, does the situation change if we assume that $\rho$ is actually the restriction of some irreducible representation $\sigma: G\to\mathrm{GL}(V)$? Edit: Alternatively, would the situation change if we knew that $H$ was normal in $G$?","Let $G$ be an arbitrary group, $H$ be a subgroup of finite index $n$ and $k$ be an algebraically closed field of characteristic prime to $n$. Suppose that we have an irreducible representation $$\rho: H\to \mathrm{GL}(V)$$ where $V$ is a finite-dimensional $k$-vector space. Is the induced representation $\mathrm{Ind}_H^G(\rho)$ semisimple? This will certainly be true if $H$ is finite of order prime to the characteristic, or if we are in characteristic $0$ and $G$ is compact. Can we get away with less in this case? If $\mathrm{Ind}_H^G(\rho)$ is not semisimple, does the situation change if we assume that $\rho$ is actually the restriction of some irreducible representation $\sigma: G\to\mathrm{GL}(V)$? Edit: Alternatively, would the situation change if we knew that $H$ was normal in $G$?",,"['abstract-algebra', 'group-theory', 'representation-theory']"
19,Idempotent ideals in certain commutative rings,Idempotent ideals in certain commutative rings,,"Let $R$ be a commutative ring with zero Jacobson radical such that each maximal ideal of $R$ is idempotent. Does it guarantee that each ideal is idempotent? I know only that if each maximal ideal is generated by an idempotent element then $R$ turns out to be semisimple Artinian. I think this fact is associated with my question, at least if one could show that any maximal ideal is generated by an idempotent element. Thanks for any suggestion!","Let $R$ be a commutative ring with zero Jacobson radical such that each maximal ideal of $R$ is idempotent. Does it guarantee that each ideal is idempotent? I know only that if each maximal ideal is generated by an idempotent element then $R$ turns out to be semisimple Artinian. I think this fact is associated with my question, at least if one could show that any maximal ideal is generated by an idempotent element. Thanks for any suggestion!",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'idempotents']"
20,Lifting an equation from the localization by clearing denominators (Atiyah-Macdonald 5.12),Lifting an equation from the localization by clearing denominators (Atiyah-Macdonald 5.12),,"In proposition 5.12, Atiyah & Macdonald prove that localization commutes with taking the integral closure. That is, they prove the following: Let $A \leq B $ be commutative rings, Let $C$ be the integral closure of $A$ in $B$, and let $S$ be a submonoid of $A$. Then $S^{-1}(C)$ is the integral closure of $S^{-1}A$ in $S^{-1}B$. In the proof, they show that every element $\frac bs \in S^{-1}B$ is integral over $S^{-1}A$, by multiplying the equation $$(\frac bs)^n+\frac {a_1} {s_1}(\frac bs)^{n-1}+...+\frac {a_n}{s_n}=0$$ by $(s \cdot \prod s_i)^n$, and claiming that this gives an integral equation in $A$ for $bs_1...s_n$. How do we justify going from an equation in the localization to an equation in the original ring, given that $A$ is not necessarily a domain? After all, the equation in the localization means a ""pretty complicated"" thing: that the numerator resulting from the common denominator of the expression is annihilated by some element of $S$. Do I have to write explicitly the numerator to make this implication? how is it formally justified?","In proposition 5.12, Atiyah & Macdonald prove that localization commutes with taking the integral closure. That is, they prove the following: Let $A \leq B $ be commutative rings, Let $C$ be the integral closure of $A$ in $B$, and let $S$ be a submonoid of $A$. Then $S^{-1}(C)$ is the integral closure of $S^{-1}A$ in $S^{-1}B$. In the proof, they show that every element $\frac bs \in S^{-1}B$ is integral over $S^{-1}A$, by multiplying the equation $$(\frac bs)^n+\frac {a_1} {s_1}(\frac bs)^{n-1}+...+\frac {a_n}{s_n}=0$$ by $(s \cdot \prod s_i)^n$, and claiming that this gives an integral equation in $A$ for $bs_1...s_n$. How do we justify going from an equation in the localization to an equation in the original ring, given that $A$ is not necessarily a domain? After all, the equation in the localization means a ""pretty complicated"" thing: that the numerator resulting from the common denominator of the expression is annihilated by some element of $S$. Do I have to write explicitly the numerator to make this implication? how is it formally justified?",,"['abstract-algebra', 'commutative-algebra', 'localization']"
21,How is class equation of a group of given order determined?,How is class equation of a group of given order determined?,,"How is class equation of a group of given order determined? Suppose we have a group of order $8$ say $D_8=\{r^4=s^2=1;rs=sr^{-1}\}$. How can I find the class equation of this group ? Should I take each and every element and find the conjugacy class of that element.I know that class equation of a group is given by $|G|=|Z(G)|+\sum_{i=1}^n |cl(a_i)| $ where $a_i's$ are distinct class representatives. Is there any elegant approach available that would even work for higher order groups such as $D_{10},S_4$ etc.","How is class equation of a group of given order determined? Suppose we have a group of order $8$ say $D_8=\{r^4=s^2=1;rs=sr^{-1}\}$. How can I find the class equation of this group ? Should I take each and every element and find the conjugacy class of that element.I know that class equation of a group is given by $|G|=|Z(G)|+\sum_{i=1}^n |cl(a_i)| $ where $a_i's$ are distinct class representatives. Is there any elegant approach available that would even work for higher order groups such as $D_{10},S_4$ etc.",,"['abstract-algebra', 'group-theory']"
22,Is there an obvious reason why the number of binary Lyndon words is equal to the number of irreducible polynomials over GF(2)?,Is there an obvious reason why the number of binary Lyndon words is equal to the number of irreducible polynomials over GF(2)?,,"The title of Sloane's A001037 is: Number of degree-$n$ irreducible polynomials over $GF(2)$; number of $n$-bead necklaces with beads of 2 colors when turning over is not allowed and with primitive period $n$; number of binary Lyndon words of length $n$. The first few terms of the sequence are (for $n=1,2,...$ ) $2,1,2,3,6,9,...$ The formula for the sequence is $\frac{1}{n}\sum_{d|n}\mu(\frac{n}{d})\cdot 2^d$. I am familiar with the derivation given by Wilf in Generatingfunctiontology on page 62.  This derivation explains why the formula enumerates binary Lyndon words and equivalently the ""$n$ bead necklaces"" statement in the title. I know the 2 irreducible polynomials of degree 1 are $x$ and $x+1$. The degree 2 polynomial is $x^2+x+1$. The degree 3 polynomials are $x^3+x^2+1$ and $x^3+x+1$. The degree 4 polynomials are $x^4+x+1$, $x^4+x^3+x^2+x+1$ and $x^4+x^3+1$. The binary Lyndon words are: $a(1)=2=\#\{""0"",""1""\}$, $a(2)=1=\#\{""01""\}$, $a(3)=2=\#\{""001"",""011""\}$, $a(4)=3=\#\{""0001"",""0011"",""0111""\}$ I would like to know if there is an easy correspondence between these objects or if there is some explanation as to why the formula counts the irreducible polynomial over $GF(2)$.","The title of Sloane's A001037 is: Number of degree-$n$ irreducible polynomials over $GF(2)$; number of $n$-bead necklaces with beads of 2 colors when turning over is not allowed and with primitive period $n$; number of binary Lyndon words of length $n$. The first few terms of the sequence are (for $n=1,2,...$ ) $2,1,2,3,6,9,...$ The formula for the sequence is $\frac{1}{n}\sum_{d|n}\mu(\frac{n}{d})\cdot 2^d$. I am familiar with the derivation given by Wilf in Generatingfunctiontology on page 62.  This derivation explains why the formula enumerates binary Lyndon words and equivalently the ""$n$ bead necklaces"" statement in the title. I know the 2 irreducible polynomials of degree 1 are $x$ and $x+1$. The degree 2 polynomial is $x^2+x+1$. The degree 3 polynomials are $x^3+x^2+1$ and $x^3+x+1$. The degree 4 polynomials are $x^4+x+1$, $x^4+x^3+x^2+x+1$ and $x^4+x^3+1$. The binary Lyndon words are: $a(1)=2=\#\{""0"",""1""\}$, $a(2)=1=\#\{""01""\}$, $a(3)=2=\#\{""001"",""011""\}$, $a(4)=3=\#\{""0001"",""0011"",""0111""\}$ I would like to know if there is an easy correspondence between these objects or if there is some explanation as to why the formula counts the irreducible polynomial over $GF(2)$.",,"['abstract-algebra', 'combinatorics', 'number-theory', 'galois-theory', 'finite-fields']"
23,A structural view to the power set axiom: Is this axiom really justifiable?,A structural view to the power set axiom: Is this axiom really justifiable?,,"The power set axiom in set theory states that the collection of the subsets of a set is a set itself. I wonder if this is a ""natural"" axiom in the sense that if we consider sets as the simplest structures in mathematics and replace the word ""set"" in power set axiom with ""structure"" of arbitrary type, we get the following: The collection of sub-structures of a given $\mathcal{L}$ - structure $\mathcal{M}$ form an $\mathcal{L}$ - structure. ($\mathcal{L}$ is a first order language. However it is not essential to restrict ourselves to the first order framework). Then we can ask the following question: Question. In what realms of mathematics do the substructures of a fixed structure form a structure of the same type? For example is there any ""natural"" (whatever it means) group structure on the collection of all subgroups of a given group $G$? Or does sub-spaces of a given vector space $V$ form a vector space? What about finding a field structure on the sub-fields of a field? Existence of such phenomenon in other parts of mathematics might be considered as a kind of justification for validity of the power set axiom in its structural form.","The power set axiom in set theory states that the collection of the subsets of a set is a set itself. I wonder if this is a ""natural"" axiom in the sense that if we consider sets as the simplest structures in mathematics and replace the word ""set"" in power set axiom with ""structure"" of arbitrary type, we get the following: The collection of sub-structures of a given $\mathcal{L}$ - structure $\mathcal{M}$ form an $\mathcal{L}$ - structure. ($\mathcal{L}$ is a first order language. However it is not essential to restrict ourselves to the first order framework). Then we can ask the following question: Question. In what realms of mathematics do the substructures of a fixed structure form a structure of the same type? For example is there any ""natural"" (whatever it means) group structure on the collection of all subgroups of a given group $G$? Or does sub-spaces of a given vector space $V$ form a vector space? What about finding a field structure on the sub-fields of a field? Existence of such phenomenon in other parts of mathematics might be considered as a kind of justification for validity of the power set axiom in its structural form.",,"['abstract-algebra', 'logic']"
24,"$\mathbb C[X_1, \ldots, X_n]$ is a free module over $\mathbb C[X_1, \ldots, X_n]^G$",is a free module over,"\mathbb C[X_1, \ldots, X_n] \mathbb C[X_1, \ldots, X_n]^G","Let $G$ be finite subgroup of $GL_n( \mathbb C )$. Let $\mathbb C[X_1, \ldots, X_n]^G$ be the set of all   G-invariant polynomials of $\mathbb C[X_1, \ldots, X_n]$. Is there any rule by which we can find out when $\mathbb C[X_1, \ldots, X_n]$ is a free module over $\mathbb C[X_1, \ldots, X_n]^G$?","Let $G$ be finite subgroup of $GL_n( \mathbb C )$. Let $\mathbb C[X_1, \ldots, X_n]^G$ be the set of all   G-invariant polynomials of $\mathbb C[X_1, \ldots, X_n]$. Is there any rule by which we can find out when $\mathbb C[X_1, \ldots, X_n]$ is a free module over $\mathbb C[X_1, \ldots, X_n]^G$?",,"['abstract-algebra', 'algebraic-geometry', 'polynomials', 'commutative-algebra', 'invariant-theory']"
25,Quadratic extensions of p-adic rationals,Quadratic extensions of p-adic rationals,,"In Alain Robert's A Course in p-adic Analysis , the author uses Hensel's Lemma to analyze quadratic extensions of $\mathbb{Q}_p$. He wants to calculate the index of $(\mathbb{Q}^*_p)^2$ in $\mathbb{Q}^*_p$, as multiplicative groups; and to do that, he computes (page 50, $p$ is assumed odd): $\mathbb{Q}^*_p/(\mathbb{Q}^*_p)^2 \cong (p^\mathbb{Z}/p^{2\mathbb{Z}}) \times (\mathbb{Z}^*_p/(\mathbb{Z}^*_p)^2) \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$ I could use help understanding this argument - it doesn't seem to refer to anything earlier in the book, and I'm not even sure what $p^\mathbb{Z}$ and $p^{2\mathbb{Z}}$ are here. The only part of this I seem to understand is why $\mathbb{Z}^*_p/(\mathbb{Z}^*_p)^2 \cong \mathbb{Z}/2\mathbb{Z}$. Please tell me in case this is wrong: this is the part that uses Hensel's Lemma. By the lemma, a p-adic integer is a square $\iff$ its $0$-th digit is a square in $\mathbb{F}^*_p$; but squares form a subgroup of index $2$ in the cyclic group $\mathbb{F}^*_p$ because they're precisely the even powers of (any) generator.","In Alain Robert's A Course in p-adic Analysis , the author uses Hensel's Lemma to analyze quadratic extensions of $\mathbb{Q}_p$. He wants to calculate the index of $(\mathbb{Q}^*_p)^2$ in $\mathbb{Q}^*_p$, as multiplicative groups; and to do that, he computes (page 50, $p$ is assumed odd): $\mathbb{Q}^*_p/(\mathbb{Q}^*_p)^2 \cong (p^\mathbb{Z}/p^{2\mathbb{Z}}) \times (\mathbb{Z}^*_p/(\mathbb{Z}^*_p)^2) \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$ I could use help understanding this argument - it doesn't seem to refer to anything earlier in the book, and I'm not even sure what $p^\mathbb{Z}$ and $p^{2\mathbb{Z}}$ are here. The only part of this I seem to understand is why $\mathbb{Z}^*_p/(\mathbb{Z}^*_p)^2 \cong \mathbb{Z}/2\mathbb{Z}$. Please tell me in case this is wrong: this is the part that uses Hensel's Lemma. By the lemma, a p-adic integer is a square $\iff$ its $0$-th digit is a square in $\mathbb{F}^*_p$; but squares form a subgroup of index $2$ in the cyclic group $\mathbb{F}^*_p$ because they're precisely the even powers of (any) generator.",,"['abstract-algebra', 'p-adic-number-theory']"
26,Group $G$ is nilpotent if and only if $G^n = 1$ for some $n \geq 0$,Group  is nilpotent if and only if  for some,G G^n = 1 n \geq 0,"This is from the book Abstract Algebra , $3$ rd edition, by Dummit & Foote; theorem $8$ on page $194$ . Definition ( upper central series ): For any group $G$ define the following subgroups inductively: $$Z_0(G) = 1, \qquad Z_1(G) = Z(G)$$ and $Z_{i+1}(G)$ is the subgroup of $G$ containing $Z_i(G)$ such that $$Z_{i+1}(G)/Z_i(G) = Z(G/Z_i(G)).$$ The chain of subgroups $$Z_0(G) \leq Z_1(G) \leq Z_2(G) \leq \cdots$$ is called the upper central series of $G$ . Definition ( nilpotent ): A group $G$ is called nilpotent if $Z_c(G) = G$ for some $c \in \Bbb Z$ . The smallest such $c$ is called the nilpotence class of $G$ . Definition ( $G^n$ and lower central series ): For any (finite or infinite) group $G$ define the following subgroups inductively: $$G^0 = G, \qquad G^1 = [G, G], \qquad \text{ and } G^{i+1} = [G, G^i].$$ The chain of groups $$G^0 \geq G^1 \geq G^2 \geq \cdots$$ is called the lower central series of $G$ . The next theorem shows the relation between the upper and lower central series of a group. Theorem $8$ : A group $G$ is nilpotent if and only if $G^n = 1$ for some $n \geq 0$ . More precisely, $G$ is nilpotent of class $c$ if and only if $c$ is the smallest non-negative integer such that $G^c = 1$ . If $G$ is nilpotent of class $c$ then $$Z_i(G) \leq G^{c - i - 1} \leq Z_{i+1}(G) \qquad \text{ for all } i \in \{0, 1, \ldots , c - 1\}.$$ Proof: This is proved by a straightforward induction on the length of either the upper or lower central series. $\square$ I don't see the straightforward proof here, and would like the complete details. Is there another book or reference that includes the complete proof in detail?","This is from the book Abstract Algebra , rd edition, by Dummit & Foote; theorem on page . Definition ( upper central series ): For any group define the following subgroups inductively: and is the subgroup of containing such that The chain of subgroups is called the upper central series of . Definition ( nilpotent ): A group is called nilpotent if for some . The smallest such is called the nilpotence class of . Definition ( and lower central series ): For any (finite or infinite) group define the following subgroups inductively: The chain of groups is called the lower central series of . The next theorem shows the relation between the upper and lower central series of a group. Theorem : A group is nilpotent if and only if for some . More precisely, is nilpotent of class if and only if is the smallest non-negative integer such that . If is nilpotent of class then Proof: This is proved by a straightforward induction on the length of either the upper or lower central series. I don't see the straightforward proof here, and would like the complete details. Is there another book or reference that includes the complete proof in detail?","3 8 194 G Z_0(G) = 1, \qquad Z_1(G) = Z(G) Z_{i+1}(G) G Z_i(G) Z_{i+1}(G)/Z_i(G) = Z(G/Z_i(G)). Z_0(G) \leq Z_1(G) \leq Z_2(G) \leq \cdots G G Z_c(G) = G c \in \Bbb Z c G G^n G G^0 = G, \qquad G^1 = [G, G], \qquad \text{ and } G^{i+1} = [G, G^i]. G^0 \geq G^1 \geq G^2 \geq \cdots G 8 G G^n = 1 n \geq 0 G c c G^c = 1 G c Z_i(G) \leq G^{c - i - 1} \leq Z_{i+1}(G) \qquad \text{ for all } i \in \{0, 1, \ldots , c - 1\}. \square","['abstract-algebra', 'group-theory', 'reference-request']"
27,Projective resolutions of modules in a short exact sequence (Dummit & Foote Proposition 17.1.7),Projective resolutions of modules in a short exact sequence (Dummit & Foote Proposition 17.1.7),,"This proposition is as follows: Let $$ 0\rightarrow L\rightarrow M\rightarrow N\rightarrow 0 $$ be a short exact sequence of R-modules. Let the following be projective resolutions of L and N respectively: $$ \cdots\rightarrow P_{1}\rightarrow P_{0}\rightarrow L\rightarrow 0 $$ $$ \cdots\rightarrow \bar{P}_{1}\rightarrow \bar{P}_{0}\rightarrow N\rightarrow 0 $$ The proposition claims that there is a projective resolution for M: $$ \cdots\rightarrow P_{1}\oplus\bar{P}_{1}\rightarrow P_{0}\oplus\bar{P}_{0}\rightarrow M\rightarrow 0 $$ that commutes with all the above exact sequences, as well as the obvious ones given by $$ 0\rightarrow P_n\rightarrow P_n\oplus\bar{P}_{n}\rightarrow\bar{P}_{n}\rightarrow 0 $$ The book constructs the maps in the projective resolution for M as follows:  For the first map, first lift the map $\bar{P}_{0}\rightarrow N$ to $\Phi:\bar{P}_{0}\rightarrow M$ (this is possible because $M\rightarrow N\rightarrow 0$ is surjective and $\bar{P}_{0}$ is projective). Then, compose $P_{0}\rightarrow L$ and $L\rightarrow M$ to get a map $\psi:P_{0}\rightarrow M$, and define $\phi:P_{0}\oplus \bar{P}_{0}\rightarrow M$ as follows: $$ \phi(a,b)=\psi(a)+\Phi(b) $$ It is not hard to see that this makes the diagram commute. However, my problem is that I cannot see how the sequence given by the maps is exact at $P_{0}\oplus \bar{P}_{0}$. I want to prove that if $\phi(a,b)\in ker(\phi)$, then $\phi(a,b)\in im(\alpha)$ where $\alpha:P_{1}\oplus \bar{P}_{1}\rightarrow P_{0}\oplus \bar{P}_{0}$. That means I need $\psi(a)$ to be zero so that $a$ is in the image of $P_{1}\rightarrow P_{0}$. However, there does not seem to be any reason for this to be true. In particular, I have the following seeming counterexample. Suppose the initial exact sequence was  $$ 0\rightarrow n\mathbb{Z}\rightarrow \mathbb{Z} \rightarrow \mathbb{Z}/n\mathbb{Z}\rightarrow 0 $$ and the projective resolutions are: $$ \cdots\rightarrow 0\rightarrow\mathbb{Z}\xrightarrow{n}n\mathbb{Z}\rightarrow 0 $$ $$ \cdots\rightarrow\mathbb{Z}\xrightarrow{\alpha}\mathbb{Z}\oplus\mathbb{Z}\xrightarrow{\phi}\mathbb{Z}\rightarrow 0 $$ $$ \cdots\rightarrow\mathbb{Z}\xrightarrow{n}\mathbb{Z}\xrightarrow{n\mathbb{Z}}\mathbb{Z}/n\mathbb{Z}\rightarrow 0 $$ Then we have  $$ \phi(a,b)=an+b $$ $$ \alpha(c)=(0,nc) $$ by commutativity of the whole diagram (which unfortunately I do not know how to draw). However, $(-1,n)\in ker(\phi)$ but $(-1,n)\not\in im(\alpha)$. This seems to contradict exactness. It would be great if someone could point out the flaws in my argument. Thanks very much in advance!","This proposition is as follows: Let $$ 0\rightarrow L\rightarrow M\rightarrow N\rightarrow 0 $$ be a short exact sequence of R-modules. Let the following be projective resolutions of L and N respectively: $$ \cdots\rightarrow P_{1}\rightarrow P_{0}\rightarrow L\rightarrow 0 $$ $$ \cdots\rightarrow \bar{P}_{1}\rightarrow \bar{P}_{0}\rightarrow N\rightarrow 0 $$ The proposition claims that there is a projective resolution for M: $$ \cdots\rightarrow P_{1}\oplus\bar{P}_{1}\rightarrow P_{0}\oplus\bar{P}_{0}\rightarrow M\rightarrow 0 $$ that commutes with all the above exact sequences, as well as the obvious ones given by $$ 0\rightarrow P_n\rightarrow P_n\oplus\bar{P}_{n}\rightarrow\bar{P}_{n}\rightarrow 0 $$ The book constructs the maps in the projective resolution for M as follows:  For the first map, first lift the map $\bar{P}_{0}\rightarrow N$ to $\Phi:\bar{P}_{0}\rightarrow M$ (this is possible because $M\rightarrow N\rightarrow 0$ is surjective and $\bar{P}_{0}$ is projective). Then, compose $P_{0}\rightarrow L$ and $L\rightarrow M$ to get a map $\psi:P_{0}\rightarrow M$, and define $\phi:P_{0}\oplus \bar{P}_{0}\rightarrow M$ as follows: $$ \phi(a,b)=\psi(a)+\Phi(b) $$ It is not hard to see that this makes the diagram commute. However, my problem is that I cannot see how the sequence given by the maps is exact at $P_{0}\oplus \bar{P}_{0}$. I want to prove that if $\phi(a,b)\in ker(\phi)$, then $\phi(a,b)\in im(\alpha)$ where $\alpha:P_{1}\oplus \bar{P}_{1}\rightarrow P_{0}\oplus \bar{P}_{0}$. That means I need $\psi(a)$ to be zero so that $a$ is in the image of $P_{1}\rightarrow P_{0}$. However, there does not seem to be any reason for this to be true. In particular, I have the following seeming counterexample. Suppose the initial exact sequence was  $$ 0\rightarrow n\mathbb{Z}\rightarrow \mathbb{Z} \rightarrow \mathbb{Z}/n\mathbb{Z}\rightarrow 0 $$ and the projective resolutions are: $$ \cdots\rightarrow 0\rightarrow\mathbb{Z}\xrightarrow{n}n\mathbb{Z}\rightarrow 0 $$ $$ \cdots\rightarrow\mathbb{Z}\xrightarrow{\alpha}\mathbb{Z}\oplus\mathbb{Z}\xrightarrow{\phi}\mathbb{Z}\rightarrow 0 $$ $$ \cdots\rightarrow\mathbb{Z}\xrightarrow{n}\mathbb{Z}\xrightarrow{n\mathbb{Z}}\mathbb{Z}/n\mathbb{Z}\rightarrow 0 $$ Then we have  $$ \phi(a,b)=an+b $$ $$ \alpha(c)=(0,nc) $$ by commutativity of the whole diagram (which unfortunately I do not know how to draw). However, $(-1,n)\in ker(\phi)$ but $(-1,n)\not\in im(\alpha)$. This seems to contradict exactness. It would be great if someone could point out the flaws in my argument. Thanks very much in advance!",,"['abstract-algebra', 'homological-algebra', 'projective-module']"
28,"Knapp (Basic Algebra) Prop 8.52, error?","Knapp (Basic Algebra) Prop 8.52, error?",,"The above proposition says: Let $R$ be a Noetherian ring and let $I$ and $P$ be ideals of $R$ where $P$ is a prime ideal. If $IP=I$, then $I=0$. I feel that this is false. After passing to localization at $P$ and using Nakayama, we can easily get $S^{-1}I=0$ ($S=R-P$), from which we can conclude that $sI=0$ for some $s\in S$. How can we conclude that $I=0$? Alternatively, we can use Corollary 2.5 of Atiyah and Macdonald to directly conclude that $xI=0$, where $x=1+p$ with $p\in P$. The proof given there says since $I$ is a subset of $S^{-1}I$, $I=0$. This is false unless $R$ is a domain, isn't it?","The above proposition says: Let $R$ be a Noetherian ring and let $I$ and $P$ be ideals of $R$ where $P$ is a prime ideal. If $IP=I$, then $I=0$. I feel that this is false. After passing to localization at $P$ and using Nakayama, we can easily get $S^{-1}I=0$ ($S=R-P$), from which we can conclude that $sI=0$ for some $s\in S$. How can we conclude that $I=0$? Alternatively, we can use Corollary 2.5 of Atiyah and Macdonald to directly conclude that $xI=0$, where $x=1+p$ with $p\in P$. The proof given there says since $I$ is a subset of $S^{-1}I$, $I=0$. This is false unless $R$ is a domain, isn't it?",,"['abstract-algebra', 'commutative-algebra']"
29,What are the roots of the polynomial $x^{3}+3x-2\pi$ $?$,What are the roots of the polynomial,x^{3}+3x-2\pi ?,"By  using  Descartes's   sign   rule ,  I  can  tell  this  polynomial $$x^{3}+3x-2\pi$$  has  one  real  root. But  I  want  to  know  what  that  root  is  and  what  the factorization  of  it  is. For  the  complex  roots  I  can  find  them  from  the  quadratic  factor  of  this. Any  help  on  how  to start   thinking  of  the    factorization  of  the  polynomial  are  welcome. Thanks.","By  using  Descartes's   sign   rule ,  I  can  tell  this  polynomial $$x^{3}+3x-2\pi$$  has  one  real  root. But  I  want  to  know  what  that  root  is  and  what  the factorization  of  it  is. For  the  complex  roots  I  can  find  them  from  the  quadratic  factor  of  this. Any  help  on  how  to start   thinking  of  the    factorization  of  the  polynomial  are  welcome. Thanks.",,"['abstract-algebra', 'polynomials', 'roots', 'factoring']"
30,A normal extension over $\mathbb{Q}$,A normal extension over,\mathbb{Q},"Let $f(x)$ be an irreducible polynomial of degree $5$ in $\mathbb{Q}[x]$. Suppose $a$ and $b$ are distinct roots of $f$ and that $\mathbb{Q}(a)=\mathbb{Q}(b)$. Show that $\mathbb{Q}(a)$ is a normal extension of $\mathbb{Q}$. Now both $\mathbb{Q}(a)$ and $\mathbb{Q}(b)$ have degree $5$ and $f$ has at least one real root and I also think that the given roots can not be conjugate of each other, otherwise $f$ wouldn't be an irreducible polynomial of degree $5$. But I couldn't get the statement. Any help would be great.","Let $f(x)$ be an irreducible polynomial of degree $5$ in $\mathbb{Q}[x]$. Suppose $a$ and $b$ are distinct roots of $f$ and that $\mathbb{Q}(a)=\mathbb{Q}(b)$. Show that $\mathbb{Q}(a)$ is a normal extension of $\mathbb{Q}$. Now both $\mathbb{Q}(a)$ and $\mathbb{Q}(b)$ have degree $5$ and $f$ has at least one real root and I also think that the given roots can not be conjugate of each other, otherwise $f$ wouldn't be an irreducible polynomial of degree $5$. But I couldn't get the statement. Any help would be great.",,"['abstract-algebra', 'galois-theory']"
31,A group is abelian if and only if the center of the group is all the group,A group is abelian if and only if the center of the group is all the group,,"Isn't it the same to say that a group is abelian, and that the center of the group is all the group? I have an exercise to prove that this is true, and it's exactly one stroke for each direction of the proof, correct me if I wrong: First direction: The group $G$ is abelian, therefore for each $a,b\in G$: $$ab\:=\:ba$$ Therefore, in other words: $$a\in G\::\:Z(G)=\{ab\:=\:ba\::\:b\in G\}$$ and by definition of center (which here I symbolized as $Z(x)$), the center here is every element of $G$, therefore it is whole $G$ itself. Second direction:  That is true: $$a\in G\::\:Z\left(G\right)=\left\{ab\:=\:ba\::\:b\in G\right\}$$ and in other words, for each for each $a,b\in G$: $$ab\:=\:ba.$$ What should I add in this proof, does it seems that i missed something? I mean it seemed pretty trivial, both directions.","Isn't it the same to say that a group is abelian, and that the center of the group is all the group? I have an exercise to prove that this is true, and it's exactly one stroke for each direction of the proof, correct me if I wrong: First direction: The group $G$ is abelian, therefore for each $a,b\in G$: $$ab\:=\:ba$$ Therefore, in other words: $$a\in G\::\:Z(G)=\{ab\:=\:ba\::\:b\in G\}$$ and by definition of center (which here I symbolized as $Z(x)$), the center here is every element of $G$, therefore it is whole $G$ itself. Second direction:  That is true: $$a\in G\::\:Z\left(G\right)=\left\{ab\:=\:ba\::\:b\in G\right\}$$ and in other words, for each for each $a,b\in G$: $$ab\:=\:ba.$$ What should I add in this proof, does it seems that i missed something? I mean it seemed pretty trivial, both directions.",,"['abstract-algebra', 'group-theory', 'proof-verification', 'abelian-groups']"
32,Proof: $\mathbb{Z}[\zeta_6]$ is a PID.,Proof:  is a PID.,\mathbb{Z}[\zeta_6],"I am reading through A First Course in Modular Forms . In Proposition 2.2.3 they claim that $\mathbb{Z}[\zeta_6]$ is known to be a principal ideal domain. Does anyone have a reference for the proof of this fact? If the proof is simple enough, perhaps you could sketch it below.","I am reading through A First Course in Modular Forms . In Proposition 2.2.3 they claim that $\mathbb{Z}[\zeta_6]$ is known to be a principal ideal domain. Does anyone have a reference for the proof of this fact? If the proof is simple enough, perhaps you could sketch it below.",,['abstract-algebra']
33,Visual approach to abstract algebra,Visual approach to abstract algebra,,"I'm currently finding abstract algebra to be very fascinating. However, one of the things that pulls me back is that I sometimes find it hard to understand something visually. For example, one could visualise the First Isomorphism Theorem as being a circle with a smaller circle inside (kernel) mapping to another large circle  with a dot (zero element), and the ""annulus"" left when you ignore the kernel is equivalent to the other circle, except for the dot. I have a very amazing book Visual Complex Analysis, and was wondering if there's a similar one for abstract algebra.","I'm currently finding abstract algebra to be very fascinating. However, one of the things that pulls me back is that I sometimes find it hard to understand something visually. For example, one could visualise the First Isomorphism Theorem as being a circle with a smaller circle inside (kernel) mapping to another large circle  with a dot (zero element), and the ""annulus"" left when you ignore the kernel is equivalent to the other circle, except for the dot. I have a very amazing book Visual Complex Analysis, and was wondering if there's a similar one for abstract algebra.",,"['abstract-algebra', 'reference-request', 'book-recommendation', 'visualization']"
34,Non-abelian Group with infinite exponent in which every proper subgroup has finite exponent,Non-abelian Group with infinite exponent in which every proper subgroup has finite exponent,,can you find a Non-abelian Group with infinite exponent in which every proper subgroup has finite exponent?,can you find a Non-abelian Group with infinite exponent in which every proper subgroup has finite exponent?,,"['abstract-algebra', 'group-theory', 'infinite-groups']"
35,"Can a field extension still have ""non-separability"" above its maximal purely inseparable subextension?","Can a field extension still have ""non-separability"" above its maximal purely inseparable subextension?",,"Question 1 Let $E/F$ be an algebraic field extension. Let $K$ be the set of all elements of $E$ that are purely inseparable over $F$ . Then, $E/K/F$ is a tower of fields, and $K/F$ is purely inseparable. In this case, is $E/K$ always separable? If not, what is a counterexample? Moreover, let $K^s$ and $F^s$ be the separable closures in $E$ . Then, $E/K^s$ is purely inseparable. How different are $K^s$ and $F^s$ as fields? That is, how much nicer is the extension $K^s/K$ compared to $F^s/F$ ? Question 2 Let $E/F$ be a normal field extension. Let $E^G$ denote the fixed field of $\operatorname{Aut}(E/F)$ . Then, $E/E^G$ is separable and $E^G/F$ is purely inseperable. Is $E^G$ the unique such subextension? That is, is there a subextension $K$ of $F$ such that $E/K$ is separable and $K/F$ is purely inseparable, but $K\neq E^G$ ?","Question 1 Let be an algebraic field extension. Let be the set of all elements of that are purely inseparable over . Then, is a tower of fields, and is purely inseparable. In this case, is always separable? If not, what is a counterexample? Moreover, let and be the separable closures in . Then, is purely inseparable. How different are and as fields? That is, how much nicer is the extension compared to ? Question 2 Let be a normal field extension. Let denote the fixed field of . Then, is separable and is purely inseperable. Is the unique such subextension? That is, is there a subextension of such that is separable and is purely inseparable, but ?",E/F K E F E/K/F K/F E/K K^s F^s E E/K^s K^s F^s K^s/K F^s/F E/F E^G \operatorname{Aut}(E/F) E/E^G E^G/F E^G K F E/K K/F K\neq E^G,"['abstract-algebra', 'field-theory', 'examples-counterexamples', 'extension-field', 'separable-extension']"
36,Isomorphism type of the Galois group,Isomorphism type of the Galois group,,"Let $f=(x^2-2)(x^3-3)\in\mathbb Q[x]$ . Let $K$ be the splitting field of $f$ over $\mathbb{Q}$ . a) Determine the degree of extension of $K$ over $\mathbb{Q}$ . b) Determine the isomorphism type of the Galois group of $K$ over $\mathbb{Q}$ . I have part (a), where I have shown that $K=\mathbb{Q}(2^{(1/2)}, 3^{(1/3)}, 3^{(1/2)}i)$ and hence the degree of extension is $12$ . I am not sure how to figure out part (b).","Let . Let be the splitting field of over . a) Determine the degree of extension of over . b) Determine the isomorphism type of the Galois group of over . I have part (a), where I have shown that and hence the degree of extension is . I am not sure how to figure out part (b).","f=(x^2-2)(x^3-3)\in\mathbb Q[x] K f \mathbb{Q} K \mathbb{Q} K \mathbb{Q} K=\mathbb{Q}(2^{(1/2)}, 3^{(1/3)}, 3^{(1/2)}i) 12","['abstract-algebra', 'galois-theory']"
37,Finite conjugate subgroup,Finite conjugate subgroup,,"In a paper titled ""Trivial units in Group Rings"" by Farkas, what does it mean by Finite conjugate subgroup. Here is the related image attached- What is finite conjugate subgroup of a group? It is not clear to me what is author referring here.","In a paper titled ""Trivial units in Group Rings"" by Farkas, what does it mean by Finite conjugate subgroup. Here is the related image attached- What is finite conjugate subgroup of a group? It is not clear to me what is author referring here.",,"['abstract-algebra', 'group-theory', 'group-rings']"
38,The minimal group with Fitting length three,The minimal group with Fitting length three,,Let $G$ be a group with Fitting lengt $3$ i.e $$e< F_1< F_2 < F_3=G$$ and $F(G)=F_1$ and $\bar {F_2}=F(G/F_1)$. If every proper subgroup of $G$ and every non-trivial quatient of $G$ has fitting lengt at most $2$ then can we say that $F_i/F_{i-1}$ is abelian ? Or What can we say in that case ?,Let $G$ be a group with Fitting lengt $3$ i.e $$e< F_1< F_2 < F_3=G$$ and $F(G)=F_1$ and $\bar {F_2}=F(G/F_1)$. If every proper subgroup of $G$ and every non-trivial quatient of $G$ has fitting lengt at most $2$ then can we say that $F_i/F_{i-1}$ is abelian ? Or What can we say in that case ?,,"['abstract-algebra', 'group-theory', 'finite-groups']"
39,Prove multiplication in fields is commutative,Prove multiplication in fields is commutative,,This is Problem $16$ from Halmos' Linear Algebra Problem Book. The problem asks whether or not multiplication must be commutative in a field. The solution uses the distributive properties $a(b+c)=ab+ac$ and $(a+b)c=ac+bc$ with $(0+1)x$ and $x(0+1)$ to show that both $0x=x0=0$. From here it states that this implies that multiplication is both commutative and associative. I can't seem to grasp the underlying logic of this. How does this imply that $xy=yx$ for every $x$ and $y$ in the field? Thanks for any help! -Tusike,This is Problem $16$ from Halmos' Linear Algebra Problem Book. The problem asks whether or not multiplication must be commutative in a field. The solution uses the distributive properties $a(b+c)=ab+ac$ and $(a+b)c=ac+bc$ with $(0+1)x$ and $x(0+1)$ to show that both $0x=x0=0$. From here it states that this implies that multiplication is both commutative and associative. I can't seem to grasp the underlying logic of this. How does this imply that $xy=yx$ for every $x$ and $y$ in the field? Thanks for any help! -Tusike,,"['abstract-algebra', 'field-theory']"
40,Infinite Units for $\mathbb{Z}[\sqrt{7}]$,Infinite Units for,\mathbb{Z}[\sqrt{7}],"Suppose that $\alpha \in \mathbb{Z}[\sqrt{7}]$ where $\alpha$ is of the form $a + b\sqrt{7}$ where $a, b \in \mathbb{Z}$. Because $\alpha$ is a unit if and only if $N(\alpha)=\pm 1$ we must show: $N(\alpha) = a^2 - 7b^2 = \pm 1$ has infinitely many solutions for $\alpha$. Not quite sure how show this. I am trying to find an $\alpha$ that satisfies the equation and then use the fact that $\mu^n$ is a unit if $\mu$ is a unit.","Suppose that $\alpha \in \mathbb{Z}[\sqrt{7}]$ where $\alpha$ is of the form $a + b\sqrt{7}$ where $a, b \in \mathbb{Z}$. Because $\alpha$ is a unit if and only if $N(\alpha)=\pm 1$ we must show: $N(\alpha) = a^2 - 7b^2 = \pm 1$ has infinitely many solutions for $\alpha$. Not quite sure how show this. I am trying to find an $\alpha$ that satisfies the equation and then use the fact that $\mu^n$ is a unit if $\mu$ is a unit.",,"['abstract-algebra', 'algebraic-number-theory']"
41,A group $G$ with $|G|=p^3q$ and with no normal Sylow subgroups is $G \cong \mathbb S_4$,A group  with  and with no normal Sylow subgroups is,G |G|=p^3q G \cong \mathbb S_4,"Problem Show that if $|G|=p^3q$ and $G$ has no normal Sylow subgroups, then $G \cong \mathbb S_4$ The attempt at a solution By the Sylow theorems we have: -$n_p  \equiv 1 (p), \space n_p|q$ -$n_q \equiv 1 (q), \space n_q|p^3$ Since $G$ has no normal subgroups, one can deduce from one of the Sylow theorems that $n_p,n_q \neq 1$, so the possibilities are $n_p=q, n_q \in \{p,p^2,p^3\}$ Since $|\mathbb S_4|=2^33$ and $\mathbb S_4$ has four $3-$Sylow subgroups, I should prove that $n_q=p^2$ and, specifically, that $p=2^3,q=3$. After that, I must somehow conclude $G \cong \mathbb S_4$ I would appreciate if someone could explain me how to show these things. Answers, hints, suggestions are welcome. Thanks in advance.","Problem Show that if $|G|=p^3q$ and $G$ has no normal Sylow subgroups, then $G \cong \mathbb S_4$ The attempt at a solution By the Sylow theorems we have: -$n_p  \equiv 1 (p), \space n_p|q$ -$n_q \equiv 1 (q), \space n_q|p^3$ Since $G$ has no normal subgroups, one can deduce from one of the Sylow theorems that $n_p,n_q \neq 1$, so the possibilities are $n_p=q, n_q \in \{p,p^2,p^3\}$ Since $|\mathbb S_4|=2^33$ and $\mathbb S_4$ has four $3-$Sylow subgroups, I should prove that $n_q=p^2$ and, specifically, that $p=2^3,q=3$. After that, I must somehow conclude $G \cong \mathbb S_4$ I would appreciate if someone could explain me how to show these things. Answers, hints, suggestions are welcome. Thanks in advance.",,"['abstract-algebra', 'group-theory', 'sylow-theory']"
42,Closure of a Fundamental Weyl Chamber,Closure of a Fundamental Weyl Chamber,,"Can someone explain what a ""closure"" of a Fundamental Weyl Chamber means? I assume it is related to an algebraic closure, but I don't see how. In addition, how does the Weyl group act on it and why does it act that way? Thank you for the help","Can someone explain what a ""closure"" of a Fundamental Weyl Chamber means? I assume it is related to an algebraic closure, but I don't see how. In addition, how does the Weyl group act on it and why does it act that way? Thank you for the help",,"['abstract-algebra', 'lie-algebras', 'root-systems']"
43,Proving that the intersection of a Sylow p-group with a normal subgroup is also a Sylow p-group,Proving that the intersection of a Sylow p-group with a normal subgroup is also a Sylow p-group,,"An exercise from Dummit and Foote pg. $101$ ex. $9$ asks to show the following: Let $G$ be a group of order $p^{a}n$ where $p$ does not divide $n$ and   let $N\unlhd G$ so that $|N|=p^{b}m$ where $p$ does not divide $m$ and $P\leq G$ is of order $p^a$ is a Sylow p-group. Prove that $|P\cap N|=p^{b}$. I have seen other posts, but I found only hints or solutions that uses Sylow theorms (which have yet to be proven in the text). I tried to use the second isomorphism theorem and I drew the subgroups lattice, I have also used the fact that $|N\cap P|=p^{r}$ for some $r$ (using Lagrange) but since I don't know what is $|PN|$ I didn't manage to find $r$. Can someone please guide me further ?","An exercise from Dummit and Foote pg. $101$ ex. $9$ asks to show the following: Let $G$ be a group of order $p^{a}n$ where $p$ does not divide $n$ and   let $N\unlhd G$ so that $|N|=p^{b}m$ where $p$ does not divide $m$ and $P\leq G$ is of order $p^a$ is a Sylow p-group. Prove that $|P\cap N|=p^{b}$. I have seen other posts, but I found only hints or solutions that uses Sylow theorms (which have yet to be proven in the text). I tried to use the second isomorphism theorem and I drew the subgroups lattice, I have also used the fact that $|N\cap P|=p^{r}$ for some $r$ (using Lagrange) but since I don't know what is $|PN|$ I didn't manage to find $r$. Can someone please guide me further ?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory', 'normal-subgroups']"
44,Additive non-abelian group?,Additive non-abelian group?,,"Sometimes I see in books the term ""additive Abelian groups"". In my opinion, when we use addition to represent the group operation, we already have in mind that the operation is commutative. So additive group means Abelian group. Am I wrong? Are there ""additive non-abelian groups""? I quote this from a book: ""...it is shown that any additive group $M$ admits a scalar multiplication by integers, and if $M$ is Abelian, the properties are satisfied to make $M$ a $Z$ -module ..."" Why the author needs to say ""if $M$ is Abelian"", given that it is said to be additive? If the addition is not assumed to be Abelian, then it is a general binary operation, so the author was saying "" ... it is shown that any group $M$ admits a scalar multiplication by integers and if $M$ is Abelian, the preperties are satisfied to make $M$ a $Z$ -module ..."" Right?","Sometimes I see in books the term ""additive Abelian groups"". In my opinion, when we use addition to represent the group operation, we already have in mind that the operation is commutative. So additive group means Abelian group. Am I wrong? Are there ""additive non-abelian groups""? I quote this from a book: ""...it is shown that any additive group admits a scalar multiplication by integers, and if is Abelian, the properties are satisfied to make a -module ..."" Why the author needs to say ""if is Abelian"", given that it is said to be additive? If the addition is not assumed to be Abelian, then it is a general binary operation, so the author was saying "" ... it is shown that any group admits a scalar multiplication by integers and if is Abelian, the preperties are satisfied to make a -module ..."" Right?",M M M Z M M M M Z,"['abstract-algebra', 'group-theory', 'terminology', 'abelian-groups']"
45,Existence of an element in a group of certain order if an element of other order exists,Existence of an element in a group of certain order if an element of other order exists,,Show that if a group $G$ of order $1089=3^2\cdot 11^2$ contains an element of order $9$ then it also contains an element of order $33$. I tried to see what would Sylow theorems tell for this problem but i could not conclude anything about the order$(33)$ of an element in the group. How to approach this problem? Any hint would be appreciated. Thank you.,Show that if a group $G$ of order $1089=3^2\cdot 11^2$ contains an element of order $9$ then it also contains an element of order $33$. I tried to see what would Sylow theorems tell for this problem but i could not conclude anything about the order$(33)$ of an element in the group. How to approach this problem? Any hint would be appreciated. Thank you.,,"['abstract-algebra', 'group-theory']"
46,Conditions for a quotient module to be Noetherian,Conditions for a quotient module to be Noetherian,,"I'm solving this problem from ""Introduction to Commutative Algebra"" of Atiyah and Macdonald. Here is the problem: Let $M$ be an $A$-module and let $N_1, N_2$ be submodules of $M$. If $M/N_1, M/N_2$ are Noetherian, so is $M/(N_1 \cap N_2)$. I found a solution which states that we have the exact sequence $$0 \rightarrow M/N_1 \rightarrow M/(N_1 \cap N_2) \rightarrow M/N_2 \rightarrow 0$$ so $M/(N_1 \cap N_2)$ is Noetherian if and only if $M/N_1$ and $M/N_2$ are Noetherian. I can't prove that this sequence is exact but can't find any counter-example for it. Can anyone help me? Thanks so much.","I'm solving this problem from ""Introduction to Commutative Algebra"" of Atiyah and Macdonald. Here is the problem: Let $M$ be an $A$-module and let $N_1, N_2$ be submodules of $M$. If $M/N_1, M/N_2$ are Noetherian, so is $M/(N_1 \cap N_2)$. I found a solution which states that we have the exact sequence $$0 \rightarrow M/N_1 \rightarrow M/(N_1 \cap N_2) \rightarrow M/N_2 \rightarrow 0$$ so $M/(N_1 \cap N_2)$ is Noetherian if and only if $M/N_1$ and $M/N_2$ are Noetherian. I can't prove that this sequence is exact but can't find any counter-example for it. Can anyone help me? Thanks so much.",,"['abstract-algebra', 'commutative-algebra', 'modules', 'noetherian']"
47,Fixed Field of Automorphisms of $k(x)$,Fixed Field of Automorphisms of,k(x),"Fixed field of automorphisms of $k(x)$, with $k$ a field, induced by $I(x)=x$, $\varphi_1(x) = \frac{1}{1-x}$, $\varphi_2 (x)=\frac{x-1}{x}$? Since $I(x)=x$, $\varphi_1(x)=\frac{1}{1-x}$, $\varphi_2 (x)=\frac{x-1}{x}$ form a group of order 3 the group is cyclic, so it is generated by $\varphi_1$ then I have to find the fixed field of $\varphi_1$. If $a(x)=\frac{f(x)}{g(x)} \in k(x)$ with $(f,g)=1$ and $\varphi_1$ fix to $a(x)$ then $a(x)=a(\frac{1}{1-x}) \Rightarrow  \frac{f(x)}{g(x)} = \frac{f(\frac{1}{1-x})}{g(\frac{1}{1-x})} \Rightarrow f(x) \mid f(\frac{1}{1-x)})$ and by th same reason $ f(\frac{1}{1-x}) \mid f(x)$ so  $f(\frac{1}{1-x})=f(x)$ so $\varphi_1$ fix to $a(x)$, $f(x)$ then $\varphi_1$ fix to $g(x)$. So $\varphi_1$ fix to $\frac{f(x)}{g(x)}$. Someone can tell me if it is correct.","Fixed field of automorphisms of $k(x)$, with $k$ a field, induced by $I(x)=x$, $\varphi_1(x) = \frac{1}{1-x}$, $\varphi_2 (x)=\frac{x-1}{x}$? Since $I(x)=x$, $\varphi_1(x)=\frac{1}{1-x}$, $\varphi_2 (x)=\frac{x-1}{x}$ form a group of order 3 the group is cyclic, so it is generated by $\varphi_1$ then I have to find the fixed field of $\varphi_1$. If $a(x)=\frac{f(x)}{g(x)} \in k(x)$ with $(f,g)=1$ and $\varphi_1$ fix to $a(x)$ then $a(x)=a(\frac{1}{1-x}) \Rightarrow  \frac{f(x)}{g(x)} = \frac{f(\frac{1}{1-x})}{g(\frac{1}{1-x})} \Rightarrow f(x) \mid f(\frac{1}{1-x)})$ and by th same reason $ f(\frac{1}{1-x}) \mid f(x)$ so  $f(\frac{1}{1-x})=f(x)$ so $\varphi_1$ fix to $a(x)$, $f(x)$ then $\varphi_1$ fix to $g(x)$. So $\varphi_1$ fix to $\frac{f(x)}{g(x)}$. Someone can tell me if it is correct.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
48,How many nonabelian groups of order 2009? (Check work),How many nonabelian groups of order 2009? (Check work),,"I just need someone to check this argument. Let $G$ be a nonabelian group of order $2009$.  The prime factorization of $2009$ is $7^2 \cdot 41$.  Let $n$ be the number of Sylow 7-subgroups. Then $n \equiv 1$ mod $7$ and $n$ divides $41$.  Since $41$ is prime, we must have $n =1$ or $n=41$, but $41 \equiv 6$ mod $7$.  Thus $n=1$ and we have a unique Sylow 7-subgroup $H$. Since $H$ is the unique Sylow 7-subgroup, we have that $H$ is a normal subgroup of $G$.  Taking the quotient we have that $|G/H|=41$, so $G/H$ is cyclic of order 41. Since $G/H$ is cyclic, $G$ is abelian.  Thus there is no nonabelian group of order $2009$.","I just need someone to check this argument. Let $G$ be a nonabelian group of order $2009$.  The prime factorization of $2009$ is $7^2 \cdot 41$.  Let $n$ be the number of Sylow 7-subgroups. Then $n \equiv 1$ mod $7$ and $n$ divides $41$.  Since $41$ is prime, we must have $n =1$ or $n=41$, but $41 \equiv 6$ mod $7$.  Thus $n=1$ and we have a unique Sylow 7-subgroup $H$. Since $H$ is the unique Sylow 7-subgroup, we have that $H$ is a normal subgroup of $G$.  Taking the quotient we have that $|G/H|=41$, so $G/H$ is cyclic of order 41. Since $G/H$ is cyclic, $G$ is abelian.  Thus there is no nonabelian group of order $2009$.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory', 'groups-enumeration']"
49,Uniqueness of tensor product,Uniqueness of tensor product,,"The uniqueness property of tensor product $M ⊗ N$ of two $A-$modules $M$ and $N$ specifies the following: for sake of simplicity we will write $M⊗N$ as $T$. A tensor product of $M$ and $N$ is pair $(T,g)$ where $T$ is an $A-$module and $g:M × N → T$ is a bilinear map such that any bilinear map $f:M × N → P$ factors through an $A-$module homomorphism $h$ such that $f = h \circ g$. uniqueness says that if you have another pair $( T',g' )$  then $∃  \  j: T \to T' $ an isomorphism s.t $g' = j \circ g$. While proving this,  we use the factoring property of tensor product for both $(T,g)$ and $(T' , g')$ to get maps $j$ and $j'$ s.t   $g' = j \circ g$ and $g = j' \circ g'$. Now to show $j$ is an $A-$module isomorphism,  since $g' = j \circ g ⇒ g' = j \circ (j' \circ g') ⇒ g' = (j \circ j') \circ g'$ ,hence  $j \circ j' =Id_{T'}$ and similarly,  $j' \circ j = Id_{T}$, hence $j$ is an isomorphism. my problem is with this statement  $g' =  j \circ (j' \circ g') ⇒ g' = (j \circ j') \circ g'$ how can we change the order of brackets when $g'$ is a bilinear map , $j  ∈ End_A(T,T')$ , $j' ∈ End_A(T' , T)$ and we do not know if associativity is valid for whatever algebraic object(if any) these together live in.","The uniqueness property of tensor product $M ⊗ N$ of two $A-$modules $M$ and $N$ specifies the following: for sake of simplicity we will write $M⊗N$ as $T$. A tensor product of $M$ and $N$ is pair $(T,g)$ where $T$ is an $A-$module and $g:M × N → T$ is a bilinear map such that any bilinear map $f:M × N → P$ factors through an $A-$module homomorphism $h$ such that $f = h \circ g$. uniqueness says that if you have another pair $( T',g' )$  then $∃  \  j: T \to T' $ an isomorphism s.t $g' = j \circ g$. While proving this,  we use the factoring property of tensor product for both $(T,g)$ and $(T' , g')$ to get maps $j$ and $j'$ s.t   $g' = j \circ g$ and $g = j' \circ g'$. Now to show $j$ is an $A-$module isomorphism,  since $g' = j \circ g ⇒ g' = j \circ (j' \circ g') ⇒ g' = (j \circ j') \circ g'$ ,hence  $j \circ j' =Id_{T'}$ and similarly,  $j' \circ j = Id_{T}$, hence $j$ is an isomorphism. my problem is with this statement  $g' =  j \circ (j' \circ g') ⇒ g' = (j \circ j') \circ g'$ how can we change the order of brackets when $g'$ is a bilinear map , $j  ∈ End_A(T,T')$ , $j' ∈ End_A(T' , T)$ and we do not know if associativity is valid for whatever algebraic object(if any) these together live in.",,"['abstract-algebra', 'commutative-algebra']"
50,Rank of $(G/H)/(G/H)_t$ where $G$ is finitely generated abelian and $H$ is a subgroup.,Rank of  where  is finitely generated abelian and  is a subgroup.,(G/H)/(G/H)_t G H,"Let $G$ be a finitely generated abelian group and $H$ be a subgroup. Let subscript $t$ denote the torsion subgroup. If $G/G_t$ is free of rank $n$ and $H/H_t$ is free of rank $m$, it is easy to embed $H/H_t\hookrightarrow G/G_t$ and deduce that $m\le n$. Now the question is that I want to show that $(G/H)/(G/H)_t$ is free of rank $n-m$. This is harder than it looks and I have not succeeded in finding a proof after many hours. [EDIT] I'm looking for a group theory proof.","Let $G$ be a finitely generated abelian group and $H$ be a subgroup. Let subscript $t$ denote the torsion subgroup. If $G/G_t$ is free of rank $n$ and $H/H_t$ is free of rank $m$, it is easy to embed $H/H_t\hookrightarrow G/G_t$ and deduce that $m\le n$. Now the question is that I want to show that $(G/H)/(G/H)_t$ is free of rank $n-m$. This is harder than it looks and I have not succeeded in finding a proof after many hours. [EDIT] I'm looking for a group theory proof.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
51,How to prove that $[G:xHx^{-1}] = [G:H]$ given $H \le G$?,How to prove that  given ?,[G:xHx^{-1}] = [G:H] H \le G,"The problem is as follows: Let $G$ be a group and $H$ a subgroup of $G$ (i.e., $H \le G$); let $x$ be any element of $G$ (i.e., $x \in G$). To prove that $[G:xHx^{-1}] = [G:H]$. I am able to justify that the $xHx^{-1}$ is indeed a subgroup of $G$ (i.e., $xHx^{-1} \le G$) and that $|xHx^{-1}| = |H|$. To prove that $[G:xHx^{-1}] = [G:H]$, it is necessary to provide a bijective function $F$ between the set of (different, left) cosets of $H$ (denoted $S = \{ aH : a \in G \}$) and that of $xHx^{-1}$ (denoted $T = \{ a (xHx^{-1}) : a \in G\} $). I have tried the function $F(aH) = a(xHx^{-1})$, but failed to show it is bijective. Could someone offer a hint of the feasible function?","The problem is as follows: Let $G$ be a group and $H$ a subgroup of $G$ (i.e., $H \le G$); let $x$ be any element of $G$ (i.e., $x \in G$). To prove that $[G:xHx^{-1}] = [G:H]$. I am able to justify that the $xHx^{-1}$ is indeed a subgroup of $G$ (i.e., $xHx^{-1} \le G$) and that $|xHx^{-1}| = |H|$. To prove that $[G:xHx^{-1}] = [G:H]$, it is necessary to provide a bijective function $F$ between the set of (different, left) cosets of $H$ (denoted $S = \{ aH : a \in G \}$) and that of $xHx^{-1}$ (denoted $T = \{ a (xHx^{-1}) : a \in G\} $). I have tried the function $F(aH) = a(xHx^{-1})$, but failed to show it is bijective. Could someone offer a hint of the feasible function?",,"['abstract-algebra', 'group-theory']"
52,Exact sequence induces exact sequences for free parts and torsion parts?,Exact sequence induces exact sequences for free parts and torsion parts?,,Let $A$ be a PID and consider the exact sequence of finitely generately modules over$A$: $$0\longrightarrow M' \overset{f}{\longrightarrow}M\overset{g}{\longrightarrow}M''\longrightarrow 0 \tag{1}.$$ Denote the free part and torsion part by $F(M)$ etc. and $T(M)$ etc. respectively. Does the above exact sequence induces ones on the free parts and torsion parts?,Let $A$ be a PID and consider the exact sequence of finitely generately modules over$A$: $$0\longrightarrow M' \overset{f}{\longrightarrow}M\overset{g}{\longrightarrow}M''\longrightarrow 0 \tag{1}.$$ Denote the free part and torsion part by $F(M)$ etc. and $T(M)$ etc. respectively. Does the above exact sequence induces ones on the free parts and torsion parts?,,"['abstract-algebra', 'commutative-algebra', 'homological-algebra', 'exact-sequence']"
53,Find minimal polynomial of this element?,Find minimal polynomial of this element?,,"Let $f(x)=x^3+x+1$. $\alpha_1, \alpha_2, \alpha_3 - $ roots of $f$. The task is to determine the minimal polynomial of $\frac{\alpha_1}{\alpha_2}$ over $\Bbb Q $ and $\Bbb Q(\alpha_1)$. My thoughts (not sure if everything is correct) There is only one real root of $f$, since $f'=3x^2+1>0$. So $x^3+x+1=(x-b)(x-w)(x-\overline{w})$ for some $w \in \Bbb{C} \setminus \Bbb{R}$ and $b \in \Bbb{R}$. If we open brackets then we get $$ \begin{cases}b=-w-\overline{w}\\ b(w+\overline{w})+w\overline{w}=1\\aw\overline{w}=-1\end{cases}$$ This set of equations might somehow lead to the fact that $\Bbb Q (\frac{\alpha_1}{\alpha_2}) = \Bbb Q(\alpha_1, \alpha_2, \alpha_3)$ and $[\Bbb Q (\frac{\alpha_1}{\alpha_2}):\Bbb Q] = 6$ (which should be if we take a look at first equation), regardless what roots we call $\alpha_1, \alpha_2, \alpha_3$. So we get that the minimal polynomial of $\frac{\alpha_1}{\alpha_2}$ has degree 6. And since $[\Bbb{Q}(\alpha_1):\Bbb{Q}]=3$, then the minimal polynomial over $\Bbb{Q}(\alpha_1)$ must have degree 2. But how can I figure out what are they? Thanks in advance!","Let $f(x)=x^3+x+1$. $\alpha_1, \alpha_2, \alpha_3 - $ roots of $f$. The task is to determine the minimal polynomial of $\frac{\alpha_1}{\alpha_2}$ over $\Bbb Q $ and $\Bbb Q(\alpha_1)$. My thoughts (not sure if everything is correct) There is only one real root of $f$, since $f'=3x^2+1>0$. So $x^3+x+1=(x-b)(x-w)(x-\overline{w})$ for some $w \in \Bbb{C} \setminus \Bbb{R}$ and $b \in \Bbb{R}$. If we open brackets then we get $$ \begin{cases}b=-w-\overline{w}\\ b(w+\overline{w})+w\overline{w}=1\\aw\overline{w}=-1\end{cases}$$ This set of equations might somehow lead to the fact that $\Bbb Q (\frac{\alpha_1}{\alpha_2}) = \Bbb Q(\alpha_1, \alpha_2, \alpha_3)$ and $[\Bbb Q (\frac{\alpha_1}{\alpha_2}):\Bbb Q] = 6$ (which should be if we take a look at first equation), regardless what roots we call $\alpha_1, \alpha_2, \alpha_3$. So we get that the minimal polynomial of $\frac{\alpha_1}{\alpha_2}$ has degree 6. And since $[\Bbb{Q}(\alpha_1):\Bbb{Q}]=3$, then the minimal polynomial over $\Bbb{Q}(\alpha_1)$ must have degree 2. But how can I figure out what are they? Thanks in advance!",,"['abstract-algebra', 'field-theory']"
54,A problem about localization of $\mathbb{Z}/6\mathbb{Z}$ at prime ideal $2\mathbb{Z}/6\mathbb{Z}$,A problem about localization of  at prime ideal,\mathbb{Z}/6\mathbb{Z} 2\mathbb{Z}/6\mathbb{Z},"We know that Given a prime ideal $P$ of a commutative ring, there is a one-to-one correspondence between $\lbrace\text{prime ideals }Q\subset P\rbrace$ and $\lbrace\text{prime ideals of } S^{-1}R \rbrace$ by $I \longrightarrow S^{-1}I$, where $S^{-1}R$  is the localization at $P$ and $S^{-1}I=\lbrace \frac{a}{s}|a\in I, s\in R-P \rbrace$; If $I$ is principal, say $I=(a)$ , then $S^{-1}I=(\frac{a}{1})$. For $R=\mathbb{Z}/6\mathbb{Z}$ and $S=R-2\mathbb{Z}/6\mathbb{Z}=\lbrace 1, 3 ,5 \rbrace$, $S^{-1}R=\lbrace \frac{0}{1},\frac{1}{1} \rbrace$, which is a finite field of order 2. But combining these two facts above $(0)\longrightarrow (\frac{0}{1})$ and $(2)=2\mathbb{Z}/6\mathbb{Z} \longrightarrow (\frac{2}{1})=(\frac{0}{1})$ since $\frac{2}{1}=\frac{0}{1}$ and get a contradiction! Could someone point out anything wrong?","We know that Given a prime ideal $P$ of a commutative ring, there is a one-to-one correspondence between $\lbrace\text{prime ideals }Q\subset P\rbrace$ and $\lbrace\text{prime ideals of } S^{-1}R \rbrace$ by $I \longrightarrow S^{-1}I$, where $S^{-1}R$  is the localization at $P$ and $S^{-1}I=\lbrace \frac{a}{s}|a\in I, s\in R-P \rbrace$; If $I$ is principal, say $I=(a)$ , then $S^{-1}I=(\frac{a}{1})$. For $R=\mathbb{Z}/6\mathbb{Z}$ and $S=R-2\mathbb{Z}/6\mathbb{Z}=\lbrace 1, 3 ,5 \rbrace$, $S^{-1}R=\lbrace \frac{0}{1},\frac{1}{1} \rbrace$, which is a finite field of order 2. But combining these two facts above $(0)\longrightarrow (\frac{0}{1})$ and $(2)=2\mathbb{Z}/6\mathbb{Z} \longrightarrow (\frac{2}{1})=(\frac{0}{1})$ since $\frac{2}{1}=\frac{0}{1}$ and get a contradiction! Could someone point out anything wrong?",,"['abstract-algebra', 'commutative-algebra', 'ideals']"
55,Do silly-rings exist?,Do silly-rings exist?,,"A ring can be defined as a near-ring satisfying two-sided distributivity, whose underlying additive group is Abelian. Negating this second stipulation, we obtain the following definition. A silly-ring is a near-ring satisfying two-sided distributivity, whose underlying additive group is non -Abelian. Do silly-rings exist?","A ring can be defined as a near-ring satisfying two-sided distributivity, whose underlying additive group is Abelian. Negating this second stipulation, we obtain the following definition. A silly-ring is a near-ring satisfying two-sided distributivity, whose underlying additive group is non -Abelian. Do silly-rings exist?",,"['abstract-algebra', 'ring-theory', 'examples-counterexamples']"
56,Finite extensions of fields that are algebraically closed,Finite extensions of fields that are algebraically closed,,"Consider a finite field extension $K/k$ with $K$ algebraically closed.  The immediate example that comes to mind is $\mathbb{C}/\mathbb{R}$, of degree $2$.  Are there any other examples?  Can we construct them of any desired degree $n$? Motivation: I've recently been studying the Weil restriction of an affine scheme, which requires a finite extension of fields, and because algebraic geometry is cleaner over an algebraically closed field, I'd like one of my fields to be algebraically closed.  Since there are no non-trivial finite extensions of an algebraically closed field, I'm left to find a field that has a finite extension that is algebraically closed.","Consider a finite field extension $K/k$ with $K$ algebraically closed.  The immediate example that comes to mind is $\mathbb{C}/\mathbb{R}$, of degree $2$.  Are there any other examples?  Can we construct them of any desired degree $n$? Motivation: I've recently been studying the Weil restriction of an affine scheme, which requires a finite extension of fields, and because algebraic geometry is cleaner over an algebraically closed field, I'd like one of my fields to be algebraically closed.  Since there are no non-trivial finite extensions of an algebraically closed field, I'm left to find a field that has a finite extension that is algebraically closed.",,"['abstract-algebra', 'field-theory', 'extension-field']"
57,Why is Weil restriction right adjoint to base change?,Why is Weil restriction right adjoint to base change?,,"Let $k'/k$ be a finite field extension, and let $X'$ be an affine group scheme over $k'$.  We can define the Weil restriction of $X'$ to be the affine group scheme $\mathrm{Res}_{k'/k}(X')$ over $k$ whose $A$-valued points are given by: $$\mathrm{Res}_{k'/k}(X')(A)=X'(A\otimes_kk')$$ where $A$ is any commutative $k$-algebra.  Here we view affine group schemes as representable functors from commutative algebras to groups. I'd like to see why Weil restriction is right adjoint to base change, that is, why we have a natural correspondence: $$\mathrm{Hom}_{\text{aff. gp. sch./k}}(X,\mathrm{Res}_{k'/k}(X'))\cong\mathrm{Hom}_{\text{aff. gp. sch./k'}}(X\times_kk',X')$$ My idea: in my experience, adjoint functors usually arise from some universal property, which would mean I would need some sort of natural map between $\mathrm{Res}_{k'/k}(X')$ and $X'$, but these objects aren't even in the same category, so this suggestion could be nonsense.  I don't have very good intuition here.  Any help is appreciated.","Let $k'/k$ be a finite field extension, and let $X'$ be an affine group scheme over $k'$.  We can define the Weil restriction of $X'$ to be the affine group scheme $\mathrm{Res}_{k'/k}(X')$ over $k$ whose $A$-valued points are given by: $$\mathrm{Res}_{k'/k}(X')(A)=X'(A\otimes_kk')$$ where $A$ is any commutative $k$-algebra.  Here we view affine group schemes as representable functors from commutative algebras to groups. I'd like to see why Weil restriction is right adjoint to base change, that is, why we have a natural correspondence: $$\mathrm{Hom}_{\text{aff. gp. sch./k}}(X,\mathrm{Res}_{k'/k}(X'))\cong\mathrm{Hom}_{\text{aff. gp. sch./k'}}(X\times_kk',X')$$ My idea: in my experience, adjoint functors usually arise from some universal property, which would mean I would need some sort of natural map between $\mathrm{Res}_{k'/k}(X')$ and $X'$, but these objects aren't even in the same category, so this suggestion could be nonsense.  I don't have very good intuition here.  Any help is appreciated.",,"['abstract-algebra', 'algebraic-geometry', 'schemes', 'affine-schemes', 'group-schemes']"
58,Field and Algebra,Field and Algebra,,"What is the difference between ""algebra"" and ""field""? In term of definition in Abstract algebra. (In probability theory, sigma-algebra is a synonym of sigma-field, does this imply  algebra is the same as field?)","What is the difference between ""algebra"" and ""field""? In term of definition in Abstract algebra. (In probability theory, sigma-algebra is a synonym of sigma-field, does this imply  algebra is the same as field?)",,"['abstract-algebra', 'measure-theory', 'probability-theory']"
59,Does a homomorphic image of even permutations consist of even permutations?,Does a homomorphic image of even permutations consist of even permutations?,,"If $f:S_n \to S_n$ is a homomorphism, prove $f(A_n) \subseteq A_n$. If every image of a transposition is even, then there is nothing to prove, but it is not sure.. How can I prove the problem?","If $f:S_n \to S_n$ is a homomorphism, prove $f(A_n) \subseteq A_n$. If every image of a transposition is even, then there is nothing to prove, but it is not sure.. How can I prove the problem?",,"['abstract-algebra', 'group-theory', 'permutations']"
60,Can logic be significantly geometrised?,Can logic be significantly geometrised?,,"I've already asked this question on philosophy.stackexchange, I'm hoping for a different answer here: Descarte has been lauded for putting together geometry and algebra, and his achievement allowed the invention of calculus by Leibniz & Newton and allowed its efficacious and explosive development by subsequent mathematicians & physicists in contrast to the rudimentary and primitive steps taken by Archimedes in integration and the Keralan school in power series. Now various propositional Logic can be algebraised: classical propositional logic -> boolean algebras intuitionistic propositional logic -> heyting algebra modal logic -> modal algebra The question: is there a significant geometric form of these logics? Significant, simply in not being just a translation into geometric form, as in Venn Diagrams for boolean algebras (first being represented as some system of sets), but that allows for something deeper to be said about logic itself? There is of course the Stone representation for a Boolean Algebra, but what does this significantly say about logic?","I've already asked this question on philosophy.stackexchange, I'm hoping for a different answer here: Descarte has been lauded for putting together geometry and algebra, and his achievement allowed the invention of calculus by Leibniz & Newton and allowed its efficacious and explosive development by subsequent mathematicians & physicists in contrast to the rudimentary and primitive steps taken by Archimedes in integration and the Keralan school in power series. Now various propositional Logic can be algebraised: classical propositional logic -> boolean algebras intuitionistic propositional logic -> heyting algebra modal logic -> modal algebra The question: is there a significant geometric form of these logics? Significant, simply in not being just a translation into geometric form, as in Venn Diagrams for boolean algebras (first being represented as some system of sets), but that allows for something deeper to be said about logic itself? There is of course the Stone representation for a Boolean Algebra, but what does this significantly say about logic?",,"['abstract-algebra', 'logic', 'category-theory']"
61,How the ring of algebraic numbers looks like?,How the ring of algebraic numbers looks like?,,"Suppose I have an algebraic number field $K = \mathbb Q(\alpha)$ for some $\alpha \in O_K$, ring of algebraic integers. Is there a criterion that tells us when $O_K =\mathbb Z[\alpha]$ by any chance? For example, if $\alpha^3 - \alpha - 1 = 0$, then $O_K =\mathbb Z[\alpha]$. I was wondering if there is an easy way to see this. Thanks!","Suppose I have an algebraic number field $K = \mathbb Q(\alpha)$ for some $\alpha \in O_K$, ring of algebraic integers. Is there a criterion that tells us when $O_K =\mathbb Z[\alpha]$ by any chance? For example, if $\alpha^3 - \alpha - 1 = 0$, then $O_K =\mathbb Z[\alpha]$. I was wondering if there is an easy way to see this. Thanks!",,"['abstract-algebra', 'algebraic-number-theory']"
62,"Learn about valuations, valuation rings, value group","Learn about valuations, valuation rings, value group",,"I am reading a paper for a summer research project ( Example of an interpolation domain ). I am unfamiliar with some of the terms used here and I have tried searching on google for definitions but I am a little confused. I am not sure if the definitions I am finding pertain to what I am looking at. The passage that I am at states: ... we take $v(r)$ to be the smallest exponent on a nonzero term of $r$. Denote the valuation ring of $v$ by $V$; so that, to be in $V$, a series must have no (nonzero) terms with negative exponents. Because $V$ has value group $G$, its maximal ideal is idempotent, and hence ... (The quote comes from the bottom of the first paragraph in Example 1 on page 2.) We are doing long division of polynomials and writing them as a kind of Laurent series and each non-zero element of the fraction field has a unique kind of ""Laurent expansion."" I have worked a little bit with valuations before but in what seemed to be kind of informal as the definition that I worked with then I have not seen repeated in my searches recently. Specifically, I worked with the $p$-adic valuation on $\mathbb{Z}$ defined by $v_p(x)=p^{-n}$ where $x=p^nb$, $p\nmid b$ for $x\neq 0$ and $v_p(x)=0$ if $x=0$. I just want to learn more about valuations, valuation rings, value groups, and an ideal being idempotent. From what I gather, you define a valuation on a field and then this gives rise to a valuation ring. The definitions of valuation that I have looked at involve $\infty$ which confuses me a little bit as it looks like each non-zero element gets mapped to a rational number in this case, as the exponents are rational. Looking at when I worked with the $p$-adic valuation on $\mathbb{Z}$, we never mapped $0 \mapsto \infty$. Maybe there is material that is available online I can look at to work through elementary results with valuations and valuation rings. Any advice on places I can go to find more information about these things? Thanks very much.","I am reading a paper for a summer research project ( Example of an interpolation domain ). I am unfamiliar with some of the terms used here and I have tried searching on google for definitions but I am a little confused. I am not sure if the definitions I am finding pertain to what I am looking at. The passage that I am at states: ... we take $v(r)$ to be the smallest exponent on a nonzero term of $r$. Denote the valuation ring of $v$ by $V$; so that, to be in $V$, a series must have no (nonzero) terms with negative exponents. Because $V$ has value group $G$, its maximal ideal is idempotent, and hence ... (The quote comes from the bottom of the first paragraph in Example 1 on page 2.) We are doing long division of polynomials and writing them as a kind of Laurent series and each non-zero element of the fraction field has a unique kind of ""Laurent expansion."" I have worked a little bit with valuations before but in what seemed to be kind of informal as the definition that I worked with then I have not seen repeated in my searches recently. Specifically, I worked with the $p$-adic valuation on $\mathbb{Z}$ defined by $v_p(x)=p^{-n}$ where $x=p^nb$, $p\nmid b$ for $x\neq 0$ and $v_p(x)=0$ if $x=0$. I just want to learn more about valuations, valuation rings, value groups, and an ideal being idempotent. From what I gather, you define a valuation on a field and then this gives rise to a valuation ring. The definitions of valuation that I have looked at involve $\infty$ which confuses me a little bit as it looks like each non-zero element gets mapped to a rational number in this case, as the exponents are rational. Looking at when I worked with the $p$-adic valuation on $\mathbb{Z}$, we never mapped $0 \mapsto \infty$. Maybe there is material that is available online I can look at to work through elementary results with valuations and valuation rings. Any advice on places I can go to find more information about these things? Thanks very much.",,['abstract-algebra']
63,Showing that $a^{\phi(n)}\equiv 1\pmod n$ when $a$ and $n$ are relatively prime,Showing that  when  and  are relatively prime,a^{\phi(n)}\equiv 1\pmod n a n,"I am trying to show that if $a$ is any integer relatively prime to $n$, then $a^{\phi(n)}\equiv 1\pmod n$, where $\phi(n)$ is Euler's totient function whose value is equal to the number of numbers less than $n$ that are relatively prime to $n$. This seems number-theoretic, but given the context, is meant to be solved with group theory.  I know that the order of $U(n)$ (the group of all numbers less than and relatively prime to $n$ under multiplication) is $\phi(n)$.  Therefore, for any $g \in U(n)$ we know that $g^{\phi(n)}=1$.  I have been trying to use this fact in my proof.  Clearly $a$ need not be in $U(n)$, but I thought perhaps if it is congruent to a member of $U(n)$ I can get the desired result.  For this reason, I applied the division algorithm to write $a=nm+r$ where $m$ is some integer and $1 \le r \le n-1$, and tried to show that $r$ is relatively prime to $n$, so that $a \equiv r \mod n$.  I do not know that this is the best approach, but no others have borne fruit either. I'd really appreciate a HINT, as always, on how to prove this.  Thanks.","I am trying to show that if $a$ is any integer relatively prime to $n$, then $a^{\phi(n)}\equiv 1\pmod n$, where $\phi(n)$ is Euler's totient function whose value is equal to the number of numbers less than $n$ that are relatively prime to $n$. This seems number-theoretic, but given the context, is meant to be solved with group theory.  I know that the order of $U(n)$ (the group of all numbers less than and relatively prime to $n$ under multiplication) is $\phi(n)$.  Therefore, for any $g \in U(n)$ we know that $g^{\phi(n)}=1$.  I have been trying to use this fact in my proof.  Clearly $a$ need not be in $U(n)$, but I thought perhaps if it is congruent to a member of $U(n)$ I can get the desired result.  For this reason, I applied the division algorithm to write $a=nm+r$ where $m$ is some integer and $1 \le r \le n-1$, and tried to show that $r$ is relatively prime to $n$, so that $a \equiv r \mod n$.  I do not know that this is the best approach, but no others have borne fruit either. I'd really appreciate a HINT, as always, on how to prove this.  Thanks.",,"['abstract-algebra', 'group-theory']"
64,Ring without zero divisors that has positive characteristic must have prime characteristic,Ring without zero divisors that has positive characteristic must have prime characteristic,,"Let $R$ be an integral domain and suppose $R$ has characteristic $n > 0$.   Prove that $n$ must be prime. I just proved this exercise, but I think it needs extra conditions. We can prove the statement if $R$ is ring without zero divisors. It's not needed $R$ to be commutative or to have an identity. Here is the proof. Let $n$ is characteristic which is not prime. So $n = mk$ and neither $m$ nor $k$ are characteristic so exists $a,b\in R$ for $ma\ne0$ and $kb\ne 0$. So we have $0 = n(ab) = mk(ab)=(ma)(kb)$ which contradicts that $R$ hasn't zero divisors. What is wrong with this proof? Definition 2.16 If $R$ is an arbitrary ring and there exists a positive   integer $n$ such that $nr = 0$ for every $r \in R$ (i.e. $r$ added to itself $n$   times is the zero element) then the least such positive integer $n$ is   called the characteristic of $R$, and $R$ is said to have positive   characteristic. If no such positive integer $n$ exists, $R$ is said to   have characteristic $0$.","Let $R$ be an integral domain and suppose $R$ has characteristic $n > 0$.   Prove that $n$ must be prime. I just proved this exercise, but I think it needs extra conditions. We can prove the statement if $R$ is ring without zero divisors. It's not needed $R$ to be commutative or to have an identity. Here is the proof. Let $n$ is characteristic which is not prime. So $n = mk$ and neither $m$ nor $k$ are characteristic so exists $a,b\in R$ for $ma\ne0$ and $kb\ne 0$. So we have $0 = n(ab) = mk(ab)=(ma)(kb)$ which contradicts that $R$ hasn't zero divisors. What is wrong with this proof? Definition 2.16 If $R$ is an arbitrary ring and there exists a positive   integer $n$ such that $nr = 0$ for every $r \in R$ (i.e. $r$ added to itself $n$   times is the zero element) then the least such positive integer $n$ is   called the characteristic of $R$, and $R$ is said to have positive   characteristic. If no such positive integer $n$ exists, $R$ is said to   have characteristic $0$.",,"['abstract-algebra', 'ring-theory']"
65,Any commutative associative operation can be extended to a function on nonempty finite sets,Any commutative associative operation can be extended to a function on nonempty finite sets,,"This is a fact we use very frequently in general mathematics when we write such notations as $1+2+3+4$ : since we know that $+$ is commutative and associative, we can just ""drop the parentheses"" and not worry about order of operations. Of course I believe this, but how does one prove this in full generality? Even stating it is giving me trouble. Here's my attempt: Assume an operation $\oplus:S\times S\to S$ is provided satisfying $x\oplus y=y\oplus x$ and $x\oplus(y\oplus z)=(x\oplus y)\oplus z$ for all $x,y,z\in S$ . Claim: Given any finite set $\emptyset\subset A\subseteq S$ , there exists a unique $z\in S$ such that for any function $f:{\cal P}(A)\to{\cal P}(A)$ which satisfies $\emptyset \subset f(B)\subset B$ for all $B\subseteq A$ with $|B|\ge 2$ and any function $g:{\cal P}(A)\to S$ which satisfies $g(\{x\})=x$ for all $x\in S$ and $g(B)=g(f(B))\oplus g(B-f(B))$ for all $|B|\ge 2$ , $g(A)=z$ . The operation $\oplus$ does not necessarily have an identity element, so we do not attempt to define an empty sum. Intuitively, this element $z$ represents the finite sum of the elements in $A$ , so if $A=\{1,2,3\}$ and $f(\{1,2,3\})=\{1\}$ and $f(\{2,3\})=\{3\}$ , then $$z=g(\{1,2,3\})=g(\{1\})\oplus g(\{2,3\})=g(\{1\})\oplus (g(\{3\})\oplus g(\{2\}))=1\oplus(3\oplus 2).$$ There has got to be a better way to say that, but this is the only way I can think of to capture all the possibilities of parenthesization, and still be amenable to a formal proof. And now that I've stated it, how should I prove it? I suppose I should induct on something, but I've no idea what. Edit: The goal here is to be able to define an operation $F$ such that $F(\{x_1,\dots,x_n\})=x_1\oplus\cdots\oplus x_n$ and be assured that the operation is well defined and satisfies $F(A\cup B)=F(A)\oplus F(B)$ , when $A$ and $B$ are disjoint finite nonempty subsets of $S$ .","This is a fact we use very frequently in general mathematics when we write such notations as : since we know that is commutative and associative, we can just ""drop the parentheses"" and not worry about order of operations. Of course I believe this, but how does one prove this in full generality? Even stating it is giving me trouble. Here's my attempt: Assume an operation is provided satisfying and for all . Claim: Given any finite set , there exists a unique such that for any function which satisfies for all with and any function which satisfies for all and for all , . The operation does not necessarily have an identity element, so we do not attempt to define an empty sum. Intuitively, this element represents the finite sum of the elements in , so if and and , then There has got to be a better way to say that, but this is the only way I can think of to capture all the possibilities of parenthesization, and still be amenable to a formal proof. And now that I've stated it, how should I prove it? I suppose I should induct on something, but I've no idea what. Edit: The goal here is to be able to define an operation such that and be assured that the operation is well defined and satisfies , when and are disjoint finite nonempty subsets of .","1+2+3+4 + \oplus:S\times S\to S x\oplus y=y\oplus x x\oplus(y\oplus z)=(x\oplus y)\oplus z x,y,z\in S \emptyset\subset A\subseteq S z\in S f:{\cal P}(A)\to{\cal P}(A) \emptyset \subset f(B)\subset B B\subseteq A |B|\ge 2 g:{\cal P}(A)\to S g(\{x\})=x x\in S g(B)=g(f(B))\oplus g(B-f(B)) |B|\ge 2 g(A)=z \oplus z A A=\{1,2,3\} f(\{1,2,3\})=\{1\} f(\{2,3\})=\{3\} z=g(\{1,2,3\})=g(\{1\})\oplus g(\{2,3\})=g(\{1\})\oplus (g(\{3\})\oplus g(\{2\}))=1\oplus(3\oplus 2). F F(\{x_1,\dots,x_n\})=x_1\oplus\cdots\oplus x_n F(A\cup B)=F(A)\oplus F(B) A B S","['abstract-algebra', 'notation', 'proof-writing', 'universal-algebra']"
66,Structure theorem of finite rings,Structure theorem of finite rings,,"Like structure theorem for finite abelian groups or modules over PID, is there any structure theorem for finite rings? Thanks.","Like structure theorem for finite abelian groups or modules over PID, is there any structure theorem for finite rings? Thanks.",,"['abstract-algebra', 'ring-theory', 'finite-rings']"
67,How is $x^2 + x + 1$ reducible in $\mathbb{Z}_3[x]$?,How is  reducible in ?,x^2 + x + 1 \mathbb{Z}_3[x],"I am going through my number theory notes and have got on to the bit about the ring $\mathbb{Z}_p[x]$ , where $p$ is prime, and unique factorisation domains. The example I am looking at is to do with irreducible and reducible polynomials. It says e.g in $\mathbb{Z}_3[x]$ , $x^2 + x + 1 = (x + 2)(x+2) = (x-1)(x-1)$ because $x^2 + x + 1 = x^2 - 2x + 1$ . So $x^2 + x + 1$ is reducible in $\mathbb{Z}_3[x]$ . But $x^2 + x + 1$ is irreducible in $\mathbb{Z}_2[x]$ or $\mathbb{Z}_2[x]$ (for example). I don't get how my lecturer has done this. How can she write $x^2 + x + 1 = (x + 2)(x + 2)$ when $(x + 2) (x+2) = x^2 + 4x + 4$ and how can she say that $x^2 + x + 1 = x^2 - 2x + 1$ ? Also, why does this only work in $\mathbb{Z}_3[x]$ and not say $\mathbb{Z}_2[x]$ or $\mathbb{Z}_5[x]$ ? EDIT: In case it helps, my definition of $\mathbb{Z}_p[x]$ is given by: The proof of the Primitive Element Theorem uses the fact that if $p \in \mathbb{Z}_+$ is prime, then the ring $\mathbb{Z}_p[x] = \{a_0 + a_1x + \cdots + a_nx^n: n \in \mathbb{Z}, a_i \in \mathbb{Z}_p, 0 \leq i \leq n\}$ is a unique factorisation domain (UFD). This means that $\mathbb{Z}_p[x]$ : is a commutative ring with identity has no zero divisors has unique factorisations into irreducibles - which are also primes sinc this is a UFD. The ""units"" in $\mathbb{Z}_p[x]$ are the constant polynomials $a_0 \in \mathbb{Z}_p^*$ .","I am going through my number theory notes and have got on to the bit about the ring , where is prime, and unique factorisation domains. The example I am looking at is to do with irreducible and reducible polynomials. It says e.g in , because . So is reducible in . But is irreducible in or (for example). I don't get how my lecturer has done this. How can she write when and how can she say that ? Also, why does this only work in and not say or ? EDIT: In case it helps, my definition of is given by: The proof of the Primitive Element Theorem uses the fact that if is prime, then the ring is a unique factorisation domain (UFD). This means that : is a commutative ring with identity has no zero divisors has unique factorisations into irreducibles - which are also primes sinc this is a UFD. The ""units"" in are the constant polynomials .","\mathbb{Z}_p[x] p \mathbb{Z}_3[x] x^2 + x + 1 = (x + 2)(x+2) = (x-1)(x-1) x^2 + x + 1 = x^2 - 2x + 1 x^2 + x + 1 \mathbb{Z}_3[x] x^2 + x + 1 \mathbb{Z}_2[x] \mathbb{Z}_2[x] x^2 + x + 1 = (x + 2)(x + 2) (x + 2) (x+2) = x^2 + 4x + 4 x^2 + x + 1 = x^2 - 2x + 1 \mathbb{Z}_3[x] \mathbb{Z}_2[x] \mathbb{Z}_5[x] \mathbb{Z}_p[x] p \in \mathbb{Z}_+ \mathbb{Z}_p[x] = \{a_0 + a_1x + \cdots + a_nx^n: n \in \mathbb{Z}, a_i \in \mathbb{Z}_p, 0 \leq i \leq n\} \mathbb{Z}_p[x] \mathbb{Z}_p[x] a_0 \in \mathbb{Z}_p^*","['abstract-algebra', 'elementary-number-theory', 'polynomials', 'irreducible-polynomials']"
68,"Is there a rigorous theory of context, whereby sets can gain additional structure within a context?","Is there a rigorous theory of context, whereby sets can gain additional structure within a context?",,"Consider sets $G$ and $H$ and a function $f : G \rightarrow  H$. So far, it doesn't really make sense to ask whether $G$ and $H$ are groups (technically, the answer is ""no, they're not groups""), and it certainly doesn't make any sense to ask whether $f$ is a group homomorphism. However, viewing $G$ and $H$ as sets equipped with a binary operation , it suddenly makes sense to ask whether $G$ and $H$ are groups. Suppose they are. Then, it also makes sense to ask whether or not $f$ is a group homomorphism. So $G$ and $H$ are just sets, but in context they can be viewed as groups, or topological spaces, or whatever. So what I'm looking for is a rigorous way of endowing sets with additional structure within specific contexts. So for example, in the ""empty-context,"" set $G$ is just a set, with no additional structure. But within a context, $G$ might be equipped with a binary operation, or some open sets, or whatever. As a more complete example, I'd like to make precise the meaning of theorems like the following. Theorem . Let $G$ and $H$ denote sets and $f : G \rightarrow H$ denote a function. Let $\Gamma$ denote a context wherein $G$ and $H$ are groups and $f$ is a group homomorphism. Then the following are equivalent. $f$ is an injection In the context $\Gamma$, it holds that the kernel of $f$ is a singleton set. Note that condition 1 is context-independent, because whether or not $f$ is an injection or not does not depend on the additional structure that $\Gamma$ endows upon $G$ and $H$. On the other hand, condition 2 is context-dependent, because the meaning of ""the kernel of $f$"" depends on the additional structure that $\Gamma$ endows upon $H$. So in conclusion, I'm looking for a rigorous approach to this idea that sets can gain structure within contexts. I want something that is near computer-readable, and not ""hand-waivy."" Remark. Groups are just an example; I am not specifically interested in groups. Edit. What follows is the thinking that lead me to the idea of context. Usually, we can make assumptions by opening a new ""environment"" in our proof. For instance, if $p$ is already a natural number, we can open a new environment in which we assume that $p$ is prime. If we prove the statement $p>10$ within the new environment, then we get to write the statement ""If $p$ is prime, then $p>10$"" in the original environment. Now importantly, when we open a new environment in this way, we are not usually allowed to ""remove"" assumptions. For instance, if $p$ is already natural, we can write ""Assume $p$ is prime,"" but we cannot write, ""Assume $p$ is no longer natural."" That is, we cannot undo an assumption by making a new assumption. In a sense, this is exactly what I'm looking for. I'd like to be able to say, ""Assume $G$ is no longer just a set; assume it is now a set together   with a binary operation satisfying the group axioms."" Of course, no assumption could possibly achieve this. An assumption cannot undo a previous assumption. So we get clever; we invent the notion of a context. Our sentence becomes: Let $\Gamma$ denote a context in which $G$ is no longer just a set; rather, it is now a set together with a binary operation satisfying the group axioms. Now we've made a bit of progress, because we're no longer trying to use assumptions to undo other assumptions. But this begs the question: what does the above sentence even mean? And what is the right definition of the word ""context""?","Consider sets $G$ and $H$ and a function $f : G \rightarrow  H$. So far, it doesn't really make sense to ask whether $G$ and $H$ are groups (technically, the answer is ""no, they're not groups""), and it certainly doesn't make any sense to ask whether $f$ is a group homomorphism. However, viewing $G$ and $H$ as sets equipped with a binary operation , it suddenly makes sense to ask whether $G$ and $H$ are groups. Suppose they are. Then, it also makes sense to ask whether or not $f$ is a group homomorphism. So $G$ and $H$ are just sets, but in context they can be viewed as groups, or topological spaces, or whatever. So what I'm looking for is a rigorous way of endowing sets with additional structure within specific contexts. So for example, in the ""empty-context,"" set $G$ is just a set, with no additional structure. But within a context, $G$ might be equipped with a binary operation, or some open sets, or whatever. As a more complete example, I'd like to make precise the meaning of theorems like the following. Theorem . Let $G$ and $H$ denote sets and $f : G \rightarrow H$ denote a function. Let $\Gamma$ denote a context wherein $G$ and $H$ are groups and $f$ is a group homomorphism. Then the following are equivalent. $f$ is an injection In the context $\Gamma$, it holds that the kernel of $f$ is a singleton set. Note that condition 1 is context-independent, because whether or not $f$ is an injection or not does not depend on the additional structure that $\Gamma$ endows upon $G$ and $H$. On the other hand, condition 2 is context-dependent, because the meaning of ""the kernel of $f$"" depends on the additional structure that $\Gamma$ endows upon $H$. So in conclusion, I'm looking for a rigorous approach to this idea that sets can gain structure within contexts. I want something that is near computer-readable, and not ""hand-waivy."" Remark. Groups are just an example; I am not specifically interested in groups. Edit. What follows is the thinking that lead me to the idea of context. Usually, we can make assumptions by opening a new ""environment"" in our proof. For instance, if $p$ is already a natural number, we can open a new environment in which we assume that $p$ is prime. If we prove the statement $p>10$ within the new environment, then we get to write the statement ""If $p$ is prime, then $p>10$"" in the original environment. Now importantly, when we open a new environment in this way, we are not usually allowed to ""remove"" assumptions. For instance, if $p$ is already natural, we can write ""Assume $p$ is prime,"" but we cannot write, ""Assume $p$ is no longer natural."" That is, we cannot undo an assumption by making a new assumption. In a sense, this is exactly what I'm looking for. I'd like to be able to say, ""Assume $G$ is no longer just a set; assume it is now a set together   with a binary operation satisfying the group axioms."" Of course, no assumption could possibly achieve this. An assumption cannot undo a previous assumption. So we get clever; we invent the notion of a context. Our sentence becomes: Let $\Gamma$ denote a context in which $G$ is no longer just a set; rather, it is now a set together with a binary operation satisfying the group axioms. Now we've made a bit of progress, because we're no longer trying to use assumptions to undo other assumptions. But this begs the question: what does the above sentence even mean? And what is the right definition of the word ""context""?",,"['abstract-algebra', 'reference-request', 'soft-question', 'notation']"
69,"If $x\otimes y=0$, then $x\otimes y=0$ in the tensor product of finitely generated submodules","If , then  in the tensor product of finitely generated submodules",x\otimes y=0 x\otimes y=0,"Let $A$ be a commutative ring, let $E,F$ be $A$-modules. Let $x\in E$ and $y\in F$. If $x\otimes y=0$ in $E\otimes F$, then there exist finitely generated submodules $M\subset E$ containing $x$ and $N\subset F$ containing $y$ such that $x\otimes y=0$ in $M\otimes N$. Now, I already know the proof of this statement, see also here . $E$ and $F$ are the direct limits of their finitely generated submodules, so $E\otimes F$ is the direct limit of the modules of the form $M\otimes N$ with $M\subset E$ an $N\subset F$ finitely generated submodules. Suppose we didn't know about direct limits. What would be the easiest proof of this statement? In other words: is the concept of direct limit essential here or a sledgehammer to crack a nut?","Let $A$ be a commutative ring, let $E,F$ be $A$-modules. Let $x\in E$ and $y\in F$. If $x\otimes y=0$ in $E\otimes F$, then there exist finitely generated submodules $M\subset E$ containing $x$ and $N\subset F$ containing $y$ such that $x\otimes y=0$ in $M\otimes N$. Now, I already know the proof of this statement, see also here . $E$ and $F$ are the direct limits of their finitely generated submodules, so $E\otimes F$ is the direct limit of the modules of the form $M\otimes N$ with $M\subset E$ an $N\subset F$ finitely generated submodules. Suppose we didn't know about direct limits. What would be the easiest proof of this statement? In other words: is the concept of direct limit essential here or a sledgehammer to crack a nut?",,"['abstract-algebra', 'modules', 'tensor-products']"
70,Equivalent definitions for projective modules,Equivalent definitions for projective modules,,"Fact : Let $R$ be a ring with identity. Let $J$ be an $R$-module. Then, $J$ is injective iff for every left ideal $L$ of $R$ every $R$-module homomorphism $L\rightarrow J$ can be extended to an $R$-module homomorphism $R\rightarrow J$. This fact provides an equivalent definition of the categorical definition of injective modules. The equivalent definition given by the fact is easier to check. Question : Let $R$ be a ring with identity. Is there a similar fact for projective $R$-modules ? Is there an equivalent definition  for projective $R$-modules such that it is much easier to check ?","Fact : Let $R$ be a ring with identity. Let $J$ be an $R$-module. Then, $J$ is injective iff for every left ideal $L$ of $R$ every $R$-module homomorphism $L\rightarrow J$ can be extended to an $R$-module homomorphism $R\rightarrow J$. This fact provides an equivalent definition of the categorical definition of injective modules. The equivalent definition given by the fact is easier to check. Question : Let $R$ be a ring with identity. Is there a similar fact for projective $R$-modules ? Is there an equivalent definition  for projective $R$-modules such that it is much easier to check ?",,"['abstract-algebra', 'ring-theory', 'modules']"
71,Multiple roots of polynomials over a finite field,Multiple roots of polynomials over a finite field,,"Show that $x^4+x+1$ over $\mathbb{Z}_2$ does not have any multiple zeros in any field extension of $\mathbb{Z}_2$. Show that $x^{21} + 2x^8 +1$ does not have multiple zeros in any extension of $\mathbb{Z}_3$. Show that $x^{21} + 2x^9 +1$  has multiple zeros in some extension of $\mathbb{Z}_3$. These are three similar problems on field extensions. Can anybody help me please - how can I solve this type of problem? I am learning about field extensions on my own, so my ideas are not very clear. Please help.","Show that $x^4+x+1$ over $\mathbb{Z}_2$ does not have any multiple zeros in any field extension of $\mathbb{Z}_2$. Show that $x^{21} + 2x^8 +1$ does not have multiple zeros in any extension of $\mathbb{Z}_3$. Show that $x^{21} + 2x^9 +1$  has multiple zeros in some extension of $\mathbb{Z}_3$. These are three similar problems on field extensions. Can anybody help me please - how can I solve this type of problem? I am learning about field extensions on my own, so my ideas are not very clear. Please help.",,"['abstract-algebra', 'polynomials', 'field-theory']"
72,Homework problems for Isaacs' Algebra: A Graduate Course?,Homework problems for Isaacs' Algebra: A Graduate Course?,,"I am about to embark on a journey through Isaacs' Algebra: A Graduate Course.  He provides in the preface a very nice, detailed outline of what he covers while teaching his first-year graduate algebra course.  I would like to follow this outline, and it would be wonderful to actually 'take the course' as much as possible.  So my question is: Where, if anywhere, on the internet could I could access the homework problems assigned for Isaacs' first-year graduate algebra course? I see that he is now retired from University of Wisconsin, Madison, and it appears that his webpage has been taken down from the school site.  A Google search did not yield anything either.  I'm hoping someone may have the homework problems from the course, or know where to find them. I would also like to ask... Would it be reasonable to e-mail Professor Isaacs to ask for the set of homework problems he used? Isaacs' book seems popular and I see that there are several questions on this site on problems from his book, so I think this could very well be of interest to multiple people who use this site. I suppose I would also settle for a different set of problems that closely follows the outline of Isaacs' course, but understandably I'd love to have the problems he used personally.","I am about to embark on a journey through Isaacs' Algebra: A Graduate Course.  He provides in the preface a very nice, detailed outline of what he covers while teaching his first-year graduate algebra course.  I would like to follow this outline, and it would be wonderful to actually 'take the course' as much as possible.  So my question is: Where, if anywhere, on the internet could I could access the homework problems assigned for Isaacs' first-year graduate algebra course? I see that he is now retired from University of Wisconsin, Madison, and it appears that his webpage has been taken down from the school site.  A Google search did not yield anything either.  I'm hoping someone may have the homework problems from the course, or know where to find them. I would also like to ask... Would it be reasonable to e-mail Professor Isaacs to ask for the set of homework problems he used? Isaacs' book seems popular and I see that there are several questions on this site on problems from his book, so I think this could very well be of interest to multiple people who use this site. I suppose I would also settle for a different set of problems that closely follows the outline of Isaacs' course, but understandably I'd love to have the problems he used personally.",,"['abstract-algebra', 'reference-request']"
73,Can a sum of idempotents vanish?,Can a sum of idempotents vanish?,,"Let $A$ be a finite dimensional $\mathbb C$-algebra. Let $e_1,\ldots,e_r\in A$ be nonzero idempotents (with $r>0$), i.e. $e_i^2=e_i$. My question is: Can it happen that $e_1+\cdots+e_r=0$? I can't think of a single example. Note: I do not require the $e_i$ to be central, primitive, or orthogonal.","Let $A$ be a finite dimensional $\mathbb C$-algebra. Let $e_1,\ldots,e_r\in A$ be nonzero idempotents (with $r>0$), i.e. $e_i^2=e_i$. My question is: Can it happen that $e_1+\cdots+e_r=0$? I can't think of a single example. Note: I do not require the $e_i$ to be central, primitive, or orthogonal.",,"['abstract-algebra', 'idempotents']"
74,Order of an element in the factor group divides order or element,Order of an element in the factor group divides order or element,,"Let $N$ be a normal subgroup of a finite group $G$, and $a \in G$ is an element of order $o(a)$. Prove that the order $m$ of $aN$ in $G/N$ is a divisor of $o(a)$. Here what I did: $(aN)^{o(a)}=a^{o(a)}N=eN=N$ but is the least power such that $(aN)^m=N$. I then assumed that $m$ will have to divide $o(a)$ which is apparently wrong. Here's what I did to prove the assumption. $(aN)^{o(a)}=(aN)^{mq+r} 0\le r<m\implies ((aN)^m)^{-q}(aN)^{o(a)}=(aN)^r \implies N=(aN)^r$ but $r<m$ then $r=0$ hence $mq=o(a)$. Is this right? I know another proof exists but I'm trying to do this in my own way .","Let $N$ be a normal subgroup of a finite group $G$, and $a \in G$ is an element of order $o(a)$. Prove that the order $m$ of $aN$ in $G/N$ is a divisor of $o(a)$. Here what I did: $(aN)^{o(a)}=a^{o(a)}N=eN=N$ but is the least power such that $(aN)^m=N$. I then assumed that $m$ will have to divide $o(a)$ which is apparently wrong. Here's what I did to prove the assumption. $(aN)^{o(a)}=(aN)^{mq+r} 0\le r<m\implies ((aN)^m)^{-q}(aN)^{o(a)}=(aN)^r \implies N=(aN)^r$ but $r<m$ then $r=0$ hence $mq=o(a)$. Is this right? I know another proof exists but I'm trying to do this in my own way .",,"['abstract-algebra', 'group-theory', 'finite-groups']"
75,Subgroup of a soluble group is soluble,Subgroup of a soluble group is soluble,,"I'm trying to show that if $G$ is a soluble group with $H$ some subgroup then $H$ is also soluble. My argument is as follows: As $G$ is soluble then we have the subnormal series: $\{e\}\triangleleft G_1 \triangleleft..... \triangleleft G_n=G$. If we now intersect $H$ with this series we get: $$\{e\}\triangleleft G_1\cap H \triangleleft G_2\cap H..... \triangleleft  G_i\cap H\triangleleft H\cap G_i=H$$ So we now need to show the normality and that each factor is abelian. To see the normality we need to prove that given $A,B,H$ subgroups of $G$ such that $A\triangleleft B$ we have $A\cap H \triangleleft B\cap H$. So take $g\in A\cap H$ and $h\in B\cap H$ and consider $hgh^{-1}$. Now as $h\in B$ and $g\in A$ we have $hgh^{-1}\in A$ also as $h\in H$ and $g\in H$ then $hgh^{-1}\in H$ and so we have that $hgh^{-1}\in A\cap H$ and this is normal. Now we need to show that each factor is abelian. So we need to show that given $A,B,H$ subgroups of $G$ such that $A\triangleleft B$ we have: If $B/A$ is abelian then $(B\cap H) / (A \cap H)$ is abelian. To see this we need to show that $(B\cap H) / (A \cap H)$ is a subgroup of $B/A$. So I am claiming that: $$(B\cap H) / (A \cap H)\cong A(B\cap H)/A$$ Which is a subgroup of $B/ A$ Now we have the following, that $A\triangleleft B$ and $B\cap H < A$. So we apply the second isomorphism theorem to get: $$A(B\cap H)/A\cong (B\cap H)/ (A\cap H \cap B)=A(B\cap H)/A\cong (B\cap H)/ (A\cap H )$$ as $A\cap B=A$ Is this correct, I am a bit worried about the last part. Thanks very much any help","I'm trying to show that if $G$ is a soluble group with $H$ some subgroup then $H$ is also soluble. My argument is as follows: As $G$ is soluble then we have the subnormal series: $\{e\}\triangleleft G_1 \triangleleft..... \triangleleft G_n=G$. If we now intersect $H$ with this series we get: $$\{e\}\triangleleft G_1\cap H \triangleleft G_2\cap H..... \triangleleft  G_i\cap H\triangleleft H\cap G_i=H$$ So we now need to show the normality and that each factor is abelian. To see the normality we need to prove that given $A,B,H$ subgroups of $G$ such that $A\triangleleft B$ we have $A\cap H \triangleleft B\cap H$. So take $g\in A\cap H$ and $h\in B\cap H$ and consider $hgh^{-1}$. Now as $h\in B$ and $g\in A$ we have $hgh^{-1}\in A$ also as $h\in H$ and $g\in H$ then $hgh^{-1}\in H$ and so we have that $hgh^{-1}\in A\cap H$ and this is normal. Now we need to show that each factor is abelian. So we need to show that given $A,B,H$ subgroups of $G$ such that $A\triangleleft B$ we have: If $B/A$ is abelian then $(B\cap H) / (A \cap H)$ is abelian. To see this we need to show that $(B\cap H) / (A \cap H)$ is a subgroup of $B/A$. So I am claiming that: $$(B\cap H) / (A \cap H)\cong A(B\cap H)/A$$ Which is a subgroup of $B/ A$ Now we have the following, that $A\triangleleft B$ and $B\cap H < A$. So we apply the second isomorphism theorem to get: $$A(B\cap H)/A\cong (B\cap H)/ (A\cap H \cap B)=A(B\cap H)/A\cong (B\cap H)/ (A\cap H )$$ as $A\cap B=A$ Is this correct, I am a bit worried about the last part. Thanks very much any help",,"['abstract-algebra', 'group-theory', 'finite-groups']"
76,Factoring in $Z_3[x]$,Factoring in,Z_3[x],"I need to factor $x^6+x^4+x^2+1$ into irreducible parts in $Z_3[x]$. Obviously this polynomial reduces to $(x^4+1)(x^2+1)$ which is irreducible in $Z[x]$, but I'm not sure how to confirm that it's irreducible in $Z_3[x]$. I've tried trial and error, and haven't found anything but would love some suggestions if anyone has ideas. Just a heads up, I'm working ahead of my class since I have to work later this week and won't have time to wait for the lecture notes before finishing the assignment. Apologies if I've missed something obvious.","I need to factor $x^6+x^4+x^2+1$ into irreducible parts in $Z_3[x]$. Obviously this polynomial reduces to $(x^4+1)(x^2+1)$ which is irreducible in $Z[x]$, but I'm not sure how to confirm that it's irreducible in $Z_3[x]$. I've tried trial and error, and haven't found anything but would love some suggestions if anyone has ideas. Just a heads up, I'm working ahead of my class since I have to work later this week and won't have time to wait for the lecture notes before finishing the assignment. Apologies if I've missed something obvious.",,"['abstract-algebra', 'polynomials', 'ring-theory', 'factoring']"
77,Isomorphic representations on exterior powers,Isomorphic representations on exterior powers,,"Exercise from F+H, Exercise 1.3: Let $\rho : G \rightarrow GL(V)$ be any representation of the finite group $G$ on a $n$-dimensional vector space $V$ and suppose that for any $g \in G$ the determinant of $\rho(g)$ is 1. Show that $\bigwedge^k V$ and $\bigwedge^{n-k} V^*$ are isomorphic as representations of G For the life of me I can't figure out. I know that $\bigwedge^k V$ and $\bigwedge^{n-k} V^*$ are isomorphic as spaces, but why are they isomorphic as representations, I have no idea. I suspect it has something to do with the determinant being 1, but...","Exercise from F+H, Exercise 1.3: Let $\rho : G \rightarrow GL(V)$ be any representation of the finite group $G$ on a $n$-dimensional vector space $V$ and suppose that for any $g \in G$ the determinant of $\rho(g)$ is 1. Show that $\bigwedge^k V$ and $\bigwedge^{n-k} V^*$ are isomorphic as representations of G For the life of me I can't figure out. I know that $\bigwedge^k V$ and $\bigwedge^{n-k} V^*$ are isomorphic as spaces, but why are they isomorphic as representations, I have no idea. I suspect it has something to do with the determinant being 1, but...",,"['abstract-algebra', 'group-theory', 'representation-theory']"
78,The relation between logic and algebra.,The relation between logic and algebra.,,What's the relation between logic and algebra? Can one be thought of as a special case of the other?,What's the relation between logic and algebra? Can one be thought of as a special case of the other?,,"['abstract-algebra', 'logic']"
79,Zero-divisors and units in $\mathbb Z_4[x]$,Zero-divisors and units in,\mathbb Z_4[x],"Consider the ring $\mathbb Z_4[x]$. Clearly the elements of the form $2f(x)$ are zero divisors. 1 . Is it true that they are all the zero divisors? I mean is it true that if $p(x)$ is a zero divisor then it is of the form   $$ 2f(x) $$   for some $f(x) \in \mathbb Z_4[x]$? In other words, is the set of zero-divisors  exactly the ideal $(2)$? I believe it is true, but I do not know how to prove it. Secondly, the elements $1+g(x)$, with $g(x)$ zero divisors, are clearly units: $(1+g(x))^2=1$. 2 . Is it true that they are all the units? I mean is it true that if $p(x)\in \mathbb Z_4[x]$ is a unit then it is of the form   $$ 1+g(x) $$   for some zero divisor $g(x)$?","Consider the ring $\mathbb Z_4[x]$. Clearly the elements of the form $2f(x)$ are zero divisors. 1 . Is it true that they are all the zero divisors? I mean is it true that if $p(x)$ is a zero divisor then it is of the form   $$ 2f(x) $$   for some $f(x) \in \mathbb Z_4[x]$? In other words, is the set of zero-divisors  exactly the ideal $(2)$? I believe it is true, but I do not know how to prove it. Secondly, the elements $1+g(x)$, with $g(x)$ zero divisors, are clearly units: $(1+g(x))^2=1$. 2 . Is it true that they are all the units? I mean is it true that if $p(x)\in \mathbb Z_4[x]$ is a unit then it is of the form   $$ 1+g(x) $$   for some zero divisor $g(x)$?",,"['abstract-algebra', 'polynomials']"
80,What do you call a group that doesn't have a unique identity?,What do you call a group that doesn't have a unique identity?,,"I have a set $M$ and an associative binary relation $+ : M \times M \to M$. There exists an inversion operator $-$ , such that if $ m \in M$, then $m+(-m) \in Z$ where $Z$ is the set of all zeros ($Z \subset M$). Additionally, if $z \in Z$ and $m \in M$, then $m+z=m$ If $|Z| = 1,$ then this would form a group, right?  But since $|Z|>1$, what would I call it?  Is there any theory about categories like this? Also, what if there was no identity at all?  That is, $m_1 + m_2 + (-m_2) = m_1$, but $m_2 + (-m_2)$ is undefined.  In this case, associativity would not hold.","I have a set $M$ and an associative binary relation $+ : M \times M \to M$. There exists an inversion operator $-$ , such that if $ m \in M$, then $m+(-m) \in Z$ where $Z$ is the set of all zeros ($Z \subset M$). Additionally, if $z \in Z$ and $m \in M$, then $m+z=m$ If $|Z| = 1,$ then this would form a group, right?  But since $|Z|>1$, what would I call it?  Is there any theory about categories like this? Also, what if there was no identity at all?  That is, $m_1 + m_2 + (-m_2) = m_1$, but $m_2 + (-m_2)$ is undefined.  In this case, associativity would not hold.",,"['abstract-algebra', 'group-theory']"
81,Proof of Hilbert's Nullstellensatz,Proof of Hilbert's Nullstellensatz,,"I'm working through my notes and I'm stuck in the middle of the proof of Hilbert's Nullstellensatz. (Hilbert's Nullstellensatz) Let $k$ be an algebraically closed field. Let $J$ be an ideal in $k[x_1, \dots , x_n]$. Let $V(J)$ denote the set of $x$ in $k$ such that all $f$ in $J$ vanish on them. Let $U \subset k^n$ and let $I(U)$ denote the set of $f$ in $k[x_1, \dots , x_n]$ that vanish on $U$. Then  $$ r(J) = I(V(J))$$ where $r$ denotes the radical of $J$. Let me go through the proof as far as I understand it: $\subset$: Easy. Let $p \in r(J)$. Then $p^k \in J$ which means $p(x)^k = 0$ for all $x$ in $V(J)$. Hence $p(x) = 0$  for $x$ in $V(J)$ hence $p \in I(V(J))$. $\supset$: Assume $f \notin r(J)$. Then for all $k>0$, $f^k \notin J$. We know that there exists a prime ideal $p$ such that $J \subset p$ and $f^k \notin p$ for all $k>0$. To see this we use the same argument used in the proof of proposition 1.8. on page 5 in Atiyah-MacDonald: Let $\Sigma$ be the set of all ideals that do not contain any power of $f$. We order $\Sigma$ by inclusion and use Zorn's lemma to get a maximal element $p$. We claim $p$ is prime. Assume neither $x \notin p$ nor $y \notin p$ (then we want to show $xy \notin p$). Then $p + (x), p + (y)$ are ideals properly containing $p$ hence neither of them is in $\Sigma$ hence $f^n \in p + (x)$ and $f^m \in p + (y)$. Now $f^{n+m} \in (p + (x)) (p + (y)) = p^2 + (x)\cdot p + (y)\cdot p + (xy) \subset p + (xy)$ so $p + (xy) \notin \Sigma$. Hence $p$ is properly contained in $p + (xy)$ hence $xy$ cannot lie in $p$. So we have $p$ is a prime ideal containing $J$. Now consider the map $$ k[x_1, \dots, x_n] \xrightarrow{\pi_1} k[x_1, \dots, x_n]/p \xrightarrow{i} (k[x_1, \dots, x_n]/p) [\overline{f}^{-1}] =: B([\overline{f}^{-1}]) \xrightarrow{\pi_2}  B[\overline{f}^{-1}] /m$$ where $\overline{f}$ denotes $\pi_1 (f)$ and $m$ is some maximal ideal in $B[\overline{f}^{-1}]$. We may assume $f \neq 0$ so that $\overline{f} \neq \overline{0}$. $\overline{f}^{-1}$ is an element of the field of fractions of $B$ so we may adjoin it to $B$ to get a new ring. Since we only adjoined one element and otherwise only took quotients, the thing coming out on the RHS is a finitely generated $k$-algebra (because $ k[x_1, \dots, x_n]$ is). Now by theorem 5.24 in Atiyah-MacDonald we know that $k \cong B[\overline{f}^{-1}] /m$. The proof now finishes as follows: ""Let $t_1, \dots, t_n$ denote the images of $x_1 , \dots, x_n$ under this composite ring homomorphism. (*)By construction, $g \in J \implies g \in p \implies g(t_1, \dots, t_n) = 0 \implies (t_1 , \dots, t_n ) \in V(J)$. (**)On the other hand, $f(t_1 , \dots, t_n )$ is precisely the image of $f$ in $B[\overline{f}^{-1}] /m$, which is a unit. $\implies f(t_1 , \dots, t_n ) \neq 0 \implies f \notin I(V(J))$."" Question 1: What is the line (*) showing? I think we want to show $f \notin I(V(J))$, where does this come in here? Question 2: Why is $f(t_1 , \dots, t_n )$ a unit? Thank you for your help.","I'm working through my notes and I'm stuck in the middle of the proof of Hilbert's Nullstellensatz. (Hilbert's Nullstellensatz) Let $k$ be an algebraically closed field. Let $J$ be an ideal in $k[x_1, \dots , x_n]$. Let $V(J)$ denote the set of $x$ in $k$ such that all $f$ in $J$ vanish on them. Let $U \subset k^n$ and let $I(U)$ denote the set of $f$ in $k[x_1, \dots , x_n]$ that vanish on $U$. Then  $$ r(J) = I(V(J))$$ where $r$ denotes the radical of $J$. Let me go through the proof as far as I understand it: $\subset$: Easy. Let $p \in r(J)$. Then $p^k \in J$ which means $p(x)^k = 0$ for all $x$ in $V(J)$. Hence $p(x) = 0$  for $x$ in $V(J)$ hence $p \in I(V(J))$. $\supset$: Assume $f \notin r(J)$. Then for all $k>0$, $f^k \notin J$. We know that there exists a prime ideal $p$ such that $J \subset p$ and $f^k \notin p$ for all $k>0$. To see this we use the same argument used in the proof of proposition 1.8. on page 5 in Atiyah-MacDonald: Let $\Sigma$ be the set of all ideals that do not contain any power of $f$. We order $\Sigma$ by inclusion and use Zorn's lemma to get a maximal element $p$. We claim $p$ is prime. Assume neither $x \notin p$ nor $y \notin p$ (then we want to show $xy \notin p$). Then $p + (x), p + (y)$ are ideals properly containing $p$ hence neither of them is in $\Sigma$ hence $f^n \in p + (x)$ and $f^m \in p + (y)$. Now $f^{n+m} \in (p + (x)) (p + (y)) = p^2 + (x)\cdot p + (y)\cdot p + (xy) \subset p + (xy)$ so $p + (xy) \notin \Sigma$. Hence $p$ is properly contained in $p + (xy)$ hence $xy$ cannot lie in $p$. So we have $p$ is a prime ideal containing $J$. Now consider the map $$ k[x_1, \dots, x_n] \xrightarrow{\pi_1} k[x_1, \dots, x_n]/p \xrightarrow{i} (k[x_1, \dots, x_n]/p) [\overline{f}^{-1}] =: B([\overline{f}^{-1}]) \xrightarrow{\pi_2}  B[\overline{f}^{-1}] /m$$ where $\overline{f}$ denotes $\pi_1 (f)$ and $m$ is some maximal ideal in $B[\overline{f}^{-1}]$. We may assume $f \neq 0$ so that $\overline{f} \neq \overline{0}$. $\overline{f}^{-1}$ is an element of the field of fractions of $B$ so we may adjoin it to $B$ to get a new ring. Since we only adjoined one element and otherwise only took quotients, the thing coming out on the RHS is a finitely generated $k$-algebra (because $ k[x_1, \dots, x_n]$ is). Now by theorem 5.24 in Atiyah-MacDonald we know that $k \cong B[\overline{f}^{-1}] /m$. The proof now finishes as follows: ""Let $t_1, \dots, t_n$ denote the images of $x_1 , \dots, x_n$ under this composite ring homomorphism. (*)By construction, $g \in J \implies g \in p \implies g(t_1, \dots, t_n) = 0 \implies (t_1 , \dots, t_n ) \in V(J)$. (**)On the other hand, $f(t_1 , \dots, t_n )$ is precisely the image of $f$ in $B[\overline{f}^{-1}] /m$, which is a unit. $\implies f(t_1 , \dots, t_n ) \neq 0 \implies f \notin I(V(J))$."" Question 1: What is the line (*) showing? I think we want to show $f \notin I(V(J))$, where does this come in here? Question 2: Why is $f(t_1 , \dots, t_n )$ a unit? Thank you for your help.",,"['abstract-algebra', 'commutative-algebra']"
82,"If two polynomials are equal as functions, are they necessarily equal as polynomials?","If two polynomials are equal as functions, are they necessarily equal as polynomials?",,"Say you have a finite field $F$ of order $p^k$. Suppose that $f,g\in F[X_1,\dots,X_m]$, such that the degree of each $X_i$ is strictly less than $p^k$ in both $f$ and $g$. I'm putting this condition to avoid things like $f=X_1X_2X_3^{p^k}$ and $g=X_1X_2X_3$ which technically define the same polynomial function over $F$ since $X_i^{p^k}-X_i$ is in the kernel of the evaluation homomorphism, but are not equal in the polynomial ring. Under this condition, if $f$ and $g$ define the same polynomial function over $F$, are they equal as polynomials? By equality of polynomial functions, I mean they are equal as sets of ordered pairs. I feel like restricting the degree of each indeterminate should force this to be so, but how can it actually be proven?","Say you have a finite field $F$ of order $p^k$. Suppose that $f,g\in F[X_1,\dots,X_m]$, such that the degree of each $X_i$ is strictly less than $p^k$ in both $f$ and $g$. I'm putting this condition to avoid things like $f=X_1X_2X_3^{p^k}$ and $g=X_1X_2X_3$ which technically define the same polynomial function over $F$ since $X_i^{p^k}-X_i$ is in the kernel of the evaluation homomorphism, but are not equal in the polynomial ring. Under this condition, if $f$ and $g$ define the same polynomial function over $F$, are they equal as polynomials? By equality of polynomial functions, I mean they are equal as sets of ordered pairs. I feel like restricting the degree of each indeterminate should force this to be so, but how can it actually be proven?",,"['abstract-algebra', 'polynomials', 'finite-fields']"
83,"Characterizing all ring homomorphisms $C[0,1]\to\mathbb{R}$.",Characterizing all ring homomorphisms .,"C[0,1]\to\mathbb{R}","This is something I've been trying to work out this evening. Let $R$ be the ring of continuous real-valued functions on $[0,1]$ with pointwise addition and multiplication. For $t\in [0,1]$, the map $\phi_t\colon f\to f(t)$ is a ring homomorphism of $R$ to $\mathbb{R}$. I'm trying to show that every ring homomorphism of $R\to\mathbb{R}$ has this form. Suppose otherwise, that there is some $\phi\neq\phi_t$, and thus there is some $f_t\in R$ such that $\phi(f_t)\neq \phi_t(f_t)=f_t(t)$. Define $g_t=f_t-\phi(f_t)1\in R$. Here $\phi(f_t)1$ is the constant function sending $[0,1]$ to $\phi(f_t)$. Then $g_t(t)\neq 0$. My first small question is why does $\phi(g_t)=0$? It seems only that $\phi(g_t)=\phi(f_t)-\phi(\phi(f_t)1)$. I would like to conclude that there are only finitely many $t_i$ such that $g(x)=\sum g_{t_i}^2(x)\neq 0$ for all $x$. Then $g^{-1}=1/g(x)\in R$, but $\phi(g)=0$, contradicting the fact that homomorphisms map units to units. How can we be sure there are only finitely many $g_{t_i}$ such that the sum of their squares is never $0$? Thanks.","This is something I've been trying to work out this evening. Let $R$ be the ring of continuous real-valued functions on $[0,1]$ with pointwise addition and multiplication. For $t\in [0,1]$, the map $\phi_t\colon f\to f(t)$ is a ring homomorphism of $R$ to $\mathbb{R}$. I'm trying to show that every ring homomorphism of $R\to\mathbb{R}$ has this form. Suppose otherwise, that there is some $\phi\neq\phi_t$, and thus there is some $f_t\in R$ such that $\phi(f_t)\neq \phi_t(f_t)=f_t(t)$. Define $g_t=f_t-\phi(f_t)1\in R$. Here $\phi(f_t)1$ is the constant function sending $[0,1]$ to $\phi(f_t)$. Then $g_t(t)\neq 0$. My first small question is why does $\phi(g_t)=0$? It seems only that $\phi(g_t)=\phi(f_t)-\phi(\phi(f_t)1)$. I would like to conclude that there are only finitely many $t_i$ such that $g(x)=\sum g_{t_i}^2(x)\neq 0$ for all $x$. Then $g^{-1}=1/g(x)\in R$, but $\phi(g)=0$, contradicting the fact that homomorphisms map units to units. How can we be sure there are only finitely many $g_{t_i}$ such that the sum of their squares is never $0$? Thanks.",,"['abstract-algebra', 'ring-theory']"
84,$M_3$ is a simple lattice,is a simple lattice,M_3,"I'd like to prove (exercise 9.5 in Roman's Lattices and Ordered Sets , p. 203 ) that the lattice $M_3$ is simple , meaning that the only congruences on $M_3$ are the trivial ones (the 'equality' congruence, i.e. $\{(x,x); x\!\in\!M_3\}$, and the 'everything' congruence, i.e. $\{(x,y); x,y\!\in\!M_3\}$). Attempt of proof: By the symmetry of $M_3$, it suffices to prove that for any congruence $\theta$ on $M_3$: (i) if $0 \theta a$, then $\theta\!=\!M_3\!\times\!M_3$; (ii) if $a \theta b$, then $\theta\!=\!M_3\!\times\!M_3$. (i): If $0 \theta a$, then by the definition of a congruence, $(0\!\vee\!b)\theta(a\!\vee\!b)$, i.e. $b\theta1$. Then $(c\!\wedge\!b)\theta(c\!\wedge\!1)$, i.e. $0\theta c$. Then $(a\!\vee\!0)\theta(a\!\vee\!c)$, i.e. $a\theta 1$. Then $(b\!\wedge\!a)\theta(b\!\wedge\!1)$, i.e. $0\theta b$. Then $(c\!\vee\!0)\theta(c\!\vee\!b)$, i.e. $c\theta 1$. Thus $\theta\!=\!M_3\!\times\!M_3$. (ii): If $a \theta b$, then ???","I'd like to prove (exercise 9.5 in Roman's Lattices and Ordered Sets , p. 203 ) that the lattice $M_3$ is simple , meaning that the only congruences on $M_3$ are the trivial ones (the 'equality' congruence, i.e. $\{(x,x); x\!\in\!M_3\}$, and the 'everything' congruence, i.e. $\{(x,y); x,y\!\in\!M_3\}$). Attempt of proof: By the symmetry of $M_3$, it suffices to prove that for any congruence $\theta$ on $M_3$: (i) if $0 \theta a$, then $\theta\!=\!M_3\!\times\!M_3$; (ii) if $a \theta b$, then $\theta\!=\!M_3\!\times\!M_3$. (i): If $0 \theta a$, then by the definition of a congruence, $(0\!\vee\!b)\theta(a\!\vee\!b)$, i.e. $b\theta1$. Then $(c\!\wedge\!b)\theta(c\!\wedge\!1)$, i.e. $0\theta c$. Then $(a\!\vee\!0)\theta(a\!\vee\!c)$, i.e. $a\theta 1$. Then $(b\!\wedge\!a)\theta(b\!\wedge\!1)$, i.e. $0\theta b$. Then $(c\!\vee\!0)\theta(c\!\vee\!b)$, i.e. $c\theta 1$. Thus $\theta\!=\!M_3\!\times\!M_3$. (ii): If $a \theta b$, then ???",,"['abstract-algebra', 'order-theory', 'lattice-orders', 'universal-algebra', 'congruence-relations']"
85,How much algebra is there in Noncommutative Geometry?,How much algebra is there in Noncommutative Geometry?,,"My Professor of Homological Algebra got me into some Hochschild (co)homology and then suggested to continue with formally smooth algebras, noncommutative differential forms and so forth. Now, my personal interest has always been algebra, especially noncommutative (ring and module theory, category theory, some homological algebra). Moreover, my studies have been concerned almost exclusively with such subjects. Hence, I am very bad at calculus, differential geometry etc. I do have the basics, though. I know it's recommendable to have a decent knowledge in most of the subjects, but I got far enough in algebra not needing very much knowledge of calculus, say. What I want to ask you is the following: Assuming that I got on the way to noncommutative geometry (so it seems to me...), how much algebra is there in? As I said, I really want a career in noncommutative algebra and it would be pretty unpleasant to get involved intensively in a subject which is not my cup of tea. So far, so good, I am enjoying the subject and it interests me in a personal way (not just for school), but I am only at the beginning, I have met only the most basics. I read that Connes somehow started the subject of NG wanting to extend differential geometry for arbitrary (noncommutative) rings, but would you say the current research work in NG, cyclic homology and the like is algebra at its finest or does it have deep and links with something else (what?)? OR am I getting this wrong and there are some other paths ahead, starting from noncommutative differential forms, formally smooth algebras, Hochschild (co)homology and the like? Thank you.","My Professor of Homological Algebra got me into some Hochschild (co)homology and then suggested to continue with formally smooth algebras, noncommutative differential forms and so forth. Now, my personal interest has always been algebra, especially noncommutative (ring and module theory, category theory, some homological algebra). Moreover, my studies have been concerned almost exclusively with such subjects. Hence, I am very bad at calculus, differential geometry etc. I do have the basics, though. I know it's recommendable to have a decent knowledge in most of the subjects, but I got far enough in algebra not needing very much knowledge of calculus, say. What I want to ask you is the following: Assuming that I got on the way to noncommutative geometry (so it seems to me...), how much algebra is there in? As I said, I really want a career in noncommutative algebra and it would be pretty unpleasant to get involved intensively in a subject which is not my cup of tea. So far, so good, I am enjoying the subject and it interests me in a personal way (not just for school), but I am only at the beginning, I have met only the most basics. I read that Connes somehow started the subject of NG wanting to extend differential geometry for arbitrary (noncommutative) rings, but would you say the current research work in NG, cyclic homology and the like is algebra at its finest or does it have deep and links with something else (what?)? OR am I getting this wrong and there are some other paths ahead, starting from noncommutative differential forms, formally smooth algebras, Hochschild (co)homology and the like? Thank you.",,"['abstract-algebra', 'soft-question', 'noncommutative-geometry']"
86,List all subgroups of the symmetry group of $n$-gon,List all subgroups of the symmetry group of -gon,n,"List all subgroups of the symmetry group of the regular $n$-gon. If $n$ is prime, there are only $n+1$ subgroups: subgroup of all rotations and $n$ subgroups with $2$ elements (one reflection and rotation by zero degrees). But if $n$ is composite, there are additional subgroups in the group of rotations, namely rotations by angle $\frac{\pi}{k},\ k|n$. Also there are subgroups containing rotations and reflections, number of which I can't found. I know that $s_\alpha s_\beta=r_{2(\alpha-\beta)}$, where $s_\alpha$ is a reflection by the line inlcined at an angle $\alpha$ to the horizontal axis. So if a subgroup contains $r_\alpha$ and $s_\beta$, it contains their product $s_{\beta - \frac{\alpha}{2}}$. What is the best way to count all subgroups for each $n$? Update: I have found an group-theoretic answer at http://ysharifi.wordpress.com/2011/02/17/subgroups-of-dihedral-groups-1/ Later I will post the answer below.","List all subgroups of the symmetry group of the regular $n$-gon. If $n$ is prime, there are only $n+1$ subgroups: subgroup of all rotations and $n$ subgroups with $2$ elements (one reflection and rotation by zero degrees). But if $n$ is composite, there are additional subgroups in the group of rotations, namely rotations by angle $\frac{\pi}{k},\ k|n$. Also there are subgroups containing rotations and reflections, number of which I can't found. I know that $s_\alpha s_\beta=r_{2(\alpha-\beta)}$, where $s_\alpha$ is a reflection by the line inlcined at an angle $\alpha$ to the horizontal axis. So if a subgroup contains $r_\alpha$ and $s_\beta$, it contains their product $s_{\beta - \frac{\alpha}{2}}$. What is the best way to count all subgroups for each $n$? Update: I have found an group-theoretic answer at http://ysharifi.wordpress.com/2011/02/17/subgroups-of-dihedral-groups-1/ Later I will post the answer below.",,"['abstract-algebra', 'group-theory']"
87,Find all ideals of $\mathbb Q$ [duplicate],Find all ideals of  [duplicate],\mathbb Q,"This question already has answers here : A commutative ring is a field iff the only ideals are $(0)$ and $(1)$ (5 answers) Closed 1 year ago . Let $\mathbb Q$ be the set of all rational numbers. I would like to know what the ideal for $\mathbb Q$ as ring is. I think the ideal of $\mathbb Q$ is $\mathbb Q$, Am I right?","This question already has answers here : A commutative ring is a field iff the only ideals are $(0)$ and $(1)$ (5 answers) Closed 1 year ago . Let $\mathbb Q$ be the set of all rational numbers. I would like to know what the ideal for $\mathbb Q$ as ring is. I think the ideal of $\mathbb Q$ is $\mathbb Q$, Am I right?",,['abstract-algebra']
88,Does the ring of integers have the following property?,Does the ring of integers have the following property?,,"As a follow-up to this question , I'd like to ask: What are examples of rings $R$ with the property that for all finite sets of ideals $I_1,\ldots,I_n$ in $R$ the sequence $$ \bigoplus_{1\leq j < k\leq n}^n I_j\cap I_k\quad\xrightarrow{f}\quad\bigoplus_{l=1}^n I_l\quad\xrightarrow{g}\quad\sum_{k=1}^n I_k $$ is exact in the middle ? Here $g$ is given by addition, and $f$ maps $x\in I_j\cap I_k$ to $x\in I_j$ and to $-x\in I_k$ (and to zero in all other components). A complete description of this class of rings would be even better, of course. Obvious examples seem to be rings with at most two proper ideals. Those I would consider pathological in this context. I'd be happy to restrict to complex algebras if that is useful. Also, is there a name for rings with this property? Edit: In order to make the question more answerable, let's just consider the case $R=\mathbb Z$. Can we find ideals in $\mathbb Z$ such that the above sequence is not exact, or can we prove that this is impossible?","As a follow-up to this question , I'd like to ask: What are examples of rings $R$ with the property that for all finite sets of ideals $I_1,\ldots,I_n$ in $R$ the sequence $$ \bigoplus_{1\leq j < k\leq n}^n I_j\cap I_k\quad\xrightarrow{f}\quad\bigoplus_{l=1}^n I_l\quad\xrightarrow{g}\quad\sum_{k=1}^n I_k $$ is exact in the middle ? Here $g$ is given by addition, and $f$ maps $x\in I_j\cap I_k$ to $x\in I_j$ and to $-x\in I_k$ (and to zero in all other components). A complete description of this class of rings would be even better, of course. Obvious examples seem to be rings with at most two proper ideals. Those I would consider pathological in this context. I'd be happy to restrict to complex algebras if that is useful. Also, is there a name for rings with this property? Edit: In order to make the question more answerable, let's just consider the case $R=\mathbb Z$. Can we find ideals in $\mathbb Z$ such that the above sequence is not exact, or can we prove that this is impossible?",,"['abstract-algebra', 'number-theory', 'homological-algebra']"
89,Algebra without Zorn's lemma,Algebra without Zorn's lemma,,"One can't get too far in abstract algebra before encountering Zorn's Lemma.  For example, it is used in the proof that every nonzero ring has a maximal ideal.  However, it seems that if we restrict our focus to Noetherian rings, we can often avoid Zorn's lemma.  How far could a development of the theory for just Noetherian rings go?  When do non-Noetherian rings come up in an essential way for which there is no Noetherian analog?  For example, Artin's proof that every field has an algebraic closure uses Zorn's lemma.  Is there a proof of this theorem (or some Zorn-less version of this theorem) that avoids it?","One can't get too far in abstract algebra before encountering Zorn's Lemma.  For example, it is used in the proof that every nonzero ring has a maximal ideal.  However, it seems that if we restrict our focus to Noetherian rings, we can often avoid Zorn's lemma.  How far could a development of the theory for just Noetherian rings go?  When do non-Noetherian rings come up in an essential way for which there is no Noetherian analog?  For example, Artin's proof that every field has an algebraic closure uses Zorn's lemma.  Is there a proof of this theorem (or some Zorn-less version of this theorem) that avoids it?",,"['abstract-algebra', 'axiom-of-choice']"
90,Does a finite-dimensional algebra have the same length as a regular module when considered as a left module and as a right module?,Does a finite-dimensional algebra have the same length as a regular module when considered as a left module and as a right module?,,"Let $A$ be a finite-dimensional algebra over a field $k$ . Naturally, $A$ can be considered as a left $A-module$ and as a right $A-module$ . So the question arises: Does a finite-dimensional algebra $A$ have the same length as a regular module when considered as a left module and as a right module? In other words, do we always have $$l(_{A}A)  =  l(A_{A})\ \ ,$$ where $l(_{A}A)$ and $l(A_{A})$ denote the length of $A$ as a left module and as a right module, respectively?","Let be a finite-dimensional algebra over a field . Naturally, can be considered as a left and as a right . So the question arises: Does a finite-dimensional algebra have the same length as a regular module when considered as a left module and as a right module? In other words, do we always have where and denote the length of as a left module and as a right module, respectively?","A k A A-module A-module A l(_{A}A)  =  l(A_{A})\ \ , l(_{A}A) l(A_{A}) A","['abstract-algebra', 'modules']"
91,"Notation $S\twoheadrightarrow \,\,\,\stackrel{S}{}\!\!\unicode{x2215}_{\!\unicode{x202f}\sim} \hookrightarrow T$ in Group Theory",Notation  in Group Theory,"S\twoheadrightarrow \,\,\,\stackrel{S}{}\!\!\unicode{x2215}_{\!\unicode{x202f}\sim} \hookrightarrow T","I am learning group theory now. My professor wrote down some notation that I was not able to understand. Can you tell me the meanings? $$S\twoheadrightarrow  \,\,\,\stackrel{S}{}\!\!\unicode{x2215}_{\!\unicode{x202f}\sim} \hookrightarrow T$$ $$a\mapsto [a]\mapsto f(a)$$",I am learning group theory now. My professor wrote down some notation that I was not able to understand. Can you tell me the meanings?,"S\twoheadrightarrow 
\,\,\,\stackrel{S}{}\!\!\unicode{x2215}_{\!\unicode{x202f}\sim}
\hookrightarrow T a\mapsto [a]\mapsto f(a)","['abstract-algebra', 'group-theory', 'notation']"
92,Product ideals are the kernel of what ring homomorphism?,Product ideals are the kernel of what ring homomorphism?,,"As I learned here , since the very beginning of humanity/Kummer's development of ideals, the idea that they are ""numbers"" that we can ""modulo by""/do ""modular arithmetic by"" has been central to the concept. An example that was given in the linked post is that the ideal $(2,1+\sqrt{-5})$ in $\mathbb Z[\sqrt{-5}]$ can be thought of as (the kernel of) the ring homomorphism $$f:\mathbb Z[\sqrt{-5}] \to \mathbb Z/2\mathbb Z, f(a+b\sqrt{-5}) := a+b+2{\mathbb Z}.$$ It took until the work of Dedekind (and even then, the later revisions) that the notion of ideals as sets of elements of a ring took center stage, especially in the seemingly-naive but miraculously-suitable definition of multiplying 2 ideals. (Indeed, somehow all the stars align and we get unique factorization of ideals in terms of the aforementioned definition of product ideal in, for instance, all number rings. Although using Kummer's ring isomorphism conception of ideals we can talk about ideals dividing/divisible by other ideals, we seem to be missing the notion of multiplicity of ""how many times"" an ideal divides another --- perhaps this is some intuition for the alternative definition of Dedekind domain: Noetherian domain s.t. all localizations at prime ideals are DVRs, where discrete valuations are exactly the framework for talking about multiplicities [and Noetherianity is there to guarantee finiteness of the prime factorization process]). Question: I'm wondering if there's any way to interpret the multiplication of ideals ""in Kummer's original conception of the ideal"", or more concretely, is there somehow a way to construct, using ring homomrphisms that define $I_1,I_2$ , a ring homomorphism whose kernel is $I_1\cdot I_2$ ? I'm aware that the Chinese remainder theorem does this if $I_1,I_2$ are relatively prime, but it doesn't seem to apply in general.","As I learned here , since the very beginning of humanity/Kummer's development of ideals, the idea that they are ""numbers"" that we can ""modulo by""/do ""modular arithmetic by"" has been central to the concept. An example that was given in the linked post is that the ideal in can be thought of as (the kernel of) the ring homomorphism It took until the work of Dedekind (and even then, the later revisions) that the notion of ideals as sets of elements of a ring took center stage, especially in the seemingly-naive but miraculously-suitable definition of multiplying 2 ideals. (Indeed, somehow all the stars align and we get unique factorization of ideals in terms of the aforementioned definition of product ideal in, for instance, all number rings. Although using Kummer's ring isomorphism conception of ideals we can talk about ideals dividing/divisible by other ideals, we seem to be missing the notion of multiplicity of ""how many times"" an ideal divides another --- perhaps this is some intuition for the alternative definition of Dedekind domain: Noetherian domain s.t. all localizations at prime ideals are DVRs, where discrete valuations are exactly the framework for talking about multiplicities [and Noetherianity is there to guarantee finiteness of the prime factorization process]). Question: I'm wondering if there's any way to interpret the multiplication of ideals ""in Kummer's original conception of the ideal"", or more concretely, is there somehow a way to construct, using ring homomrphisms that define , a ring homomorphism whose kernel is ? I'm aware that the Chinese remainder theorem does this if are relatively prime, but it doesn't seem to apply in general.","(2,1+\sqrt{-5}) \mathbb Z[\sqrt{-5}] f:\mathbb Z[\sqrt{-5}] \to \mathbb Z/2\mathbb Z, f(a+b\sqrt{-5}) := a+b+2{\mathbb Z}. I_1,I_2 I_1\cdot I_2 I_1,I_2","['abstract-algebra', 'ring-theory', 'commutative-algebra', 'algebraic-number-theory', 'ideals']"
93,Universality of Hecke algebra of a finite group,Universality of Hecke algebra of a finite group,,"I am solving an assignment problem on the Hecke algebra of a finite group, and looking for an idea that might help find a right direction. Given a pair of finite groups $G\geq K$ , the Hecke algebra $\mathcal{H}_{G,K}$ can be defined as $$ \mathcal{H}_{G,K} = \mathbb{C}[K\backslash G/K], $$ equipped with the convolution product s.t. $\delta_{KgK} \cdot \delta_{KhK} = \sum_{k\in K}\delta_{K(gkh)K}.$ Given a representation $\pi:G\to \mathrm{GL}(V)$ , it is straightforward that $\mathcal{H}_{G,K}$ acts on the space $V^K$ of $K-$ invariants $$ V^K = \{v\in V : \pi(k) v = v, \; \forall k\in K\}. $$ The question is to figure out in what sense $\mathcal{H}_{G,K}$ acts ""in a universal way"" to $V^K$ , given the hint that one may invoke Frobenius reciprocity. However, I have no idea to proceed on. Am I supposed to formulate the answer in terms of the usual categorical notion of universal property? What aspects of $\mathcal{H}_{G,K}$ should I ponder on? Any kind of instruction will be greatly appreciated.","I am solving an assignment problem on the Hecke algebra of a finite group, and looking for an idea that might help find a right direction. Given a pair of finite groups , the Hecke algebra can be defined as equipped with the convolution product s.t. Given a representation , it is straightforward that acts on the space of invariants The question is to figure out in what sense acts ""in a universal way"" to , given the hint that one may invoke Frobenius reciprocity. However, I have no idea to proceed on. Am I supposed to formulate the answer in terms of the usual categorical notion of universal property? What aspects of should I ponder on? Any kind of instruction will be greatly appreciated.","G\geq K \mathcal{H}_{G,K}  \mathcal{H}_{G,K} = \mathbb{C}[K\backslash G/K],  \delta_{KgK} \cdot \delta_{KhK} = \sum_{k\in K}\delta_{K(gkh)K}. \pi:G\to \mathrm{GL}(V) \mathcal{H}_{G,K} V^K K-  V^K = \{v\in V : \pi(k) v = v, \; \forall k\in K\}.  \mathcal{H}_{G,K} V^K \mathcal{H}_{G,K}","['abstract-algebra', 'group-theory', 'representation-theory', 'hecke-algebras']"
94,"Find the possible values for $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}]$ and provide an example of $(\alpha,\beta)$ for each possible value",Find the possible values for  and provide an example of  for each possible value,"[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] (\alpha,\beta)","Let $\alpha, \beta \in \mathbb{C}$ s.t. $[\mathbb{Q}(\alpha):\mathbb{Q}] = [\mathbb{Q}(\beta):\mathbb{Q}] = 4$ Find the possible values for $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}]$ and provide an example for each possible value. We know that $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] \leq [\mathbb{Q}(\alpha):\mathbb{Q}] [\mathbb{Q}(\beta):\mathbb{Q}] = 4 \cdot 4 = 16$ On the other hand, $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)][\mathbb{Q}(\alpha):\mathbb{Q}] = k \cdot 4 = 4k$ We got that $4|[\mathbb{Q}(\alpha,\beta):\mathbb{Q}]$ and $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] \leq 16$ , implying the possible values are in the set $\{4,8,12,16\}$ These are the examples I have $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 4$ Take $\alpha = \beta = \sqrt[4]{2}$ Here we have that $m_\alpha(\mathbb{Q}) = x^4 - 2$ , then $[\mathbb{Q}(\alpha):\mathbb{Q}] = 4$ . Since $\beta  = \sqrt[4]{2} \in \mathbb{Q}(\sqrt[4]{2}) = \mathbb{Q}(\alpha)$ , we have $m_\beta(\mathbb{Q}(\alpha)) = x - \sqrt[4]{2}$ , then $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] = 1$ Therefore, $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] [\mathbb{Q}(\alpha):\mathbb{Q}] = 1 \cdot 4 = 4$ $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 8$ Take $\alpha = \sqrt[4]{2}, \beta = \sqrt[4]{2} i$ Here we have that $m_\alpha(\mathbb{Q}) = x^4 - 2$ , then $[\mathbb{Q}(\alpha):\mathbb{Q}] = 4$ . Let $x=\sqrt[4]{2} i$ . Squaring, $x^2 = - (\sqrt[4]{2})^2$ , then $x^2 + (\sqrt[4]{2})^2 = 0$ . Since $(\sqrt[4]{2})^2 \in \mathbb{Q}(\sqrt[4]{2}) = \mathbb{Q}(\alpha)$ , we have $m_\beta(\mathbb{Q}(\alpha)) = x^2 + (\sqrt[4]{2})^2$ , then $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] = 2$ . Therefore, $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] [\mathbb{Q}(\alpha):\mathbb{Q}] = 2 \cdot 4 = 8$ $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 16$ Take $\alpha = \sqrt[4]{2}, \beta = \sqrt[4]{3}$ Here we have that $m_\alpha(\mathbb{Q}) = x^4 - 2$ , then $[\mathbb{Q}(\alpha):\mathbb{Q}] = 4$ . Since $\beta = \sqrt[4]{3} \notin \mathbb{Q}(\sqrt[4]{2}) = \mathbb{Q}(\alpha)$ , we have that $deg(m_\beta(\mathbb{Q}(\alpha))) > 1$ . Clearly $\beta = \sqrt[4]{3}$ solves $x^4 - 3 = 0$ . We now look for possible quadratic or cubic factors on $\mathbb{Q}(\sqrt[4]{2})[x]$ . $x^4 - 3 = (x^2 - \sqrt{3})(x^2 + \sqrt{3})$ . But $\sqrt{3} \notin \mathbb{Q}(\sqrt[4]{2})$ . $x^4 - 3 = (x-\sqrt[4]{3})(x^3+\sqrt[4]{3}x^2+(\sqrt[4]{3})^2x+(\sqrt[4]{3})^3)$ . But $\sqrt[4]{3} \notin \mathbb{Q}(\sqrt[4]{2})$ . This implies $m_\beta(\mathbb{Q}(\alpha)) = x^4 - 3$ , then $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] = 4$ . Therefore, $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] [\mathbb{Q}(\alpha):\mathbb{Q}] = 4 \cdot 4 = 16$ I got this problem a while ago in an Abstract Algebra II midterm, on which the professor later decided that the $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 12$ example wasn't required to earn full credit, given its extreme difficulty level. I would like to know an example for $[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 12$ , for the sake of curiosity.","Let s.t. Find the possible values for and provide an example for each possible value. We know that On the other hand, We got that and , implying the possible values are in the set These are the examples I have Take Here we have that , then . Since , we have , then Therefore, Take Here we have that , then . Let . Squaring, , then . Since , we have , then . Therefore, Take Here we have that , then . Since , we have that . Clearly solves . We now look for possible quadratic or cubic factors on . . But . . But . This implies , then . Therefore, I got this problem a while ago in an Abstract Algebra II midterm, on which the professor later decided that the example wasn't required to earn full credit, given its extreme difficulty level. I would like to know an example for , for the sake of curiosity.","\alpha, \beta \in \mathbb{C} [\mathbb{Q}(\alpha):\mathbb{Q}] = [\mathbb{Q}(\beta):\mathbb{Q}] = 4 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] \leq [\mathbb{Q}(\alpha):\mathbb{Q}] [\mathbb{Q}(\beta):\mathbb{Q}] = 4 \cdot 4 = 16 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)][\mathbb{Q}(\alpha):\mathbb{Q}] = k \cdot 4 = 4k 4|[\mathbb{Q}(\alpha,\beta):\mathbb{Q}] [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] \leq 16 \{4,8,12,16\} [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 4 \alpha = \beta = \sqrt[4]{2} m_\alpha(\mathbb{Q}) = x^4 - 2 [\mathbb{Q}(\alpha):\mathbb{Q}] = 4 \beta  = \sqrt[4]{2} \in \mathbb{Q}(\sqrt[4]{2}) = \mathbb{Q}(\alpha) m_\beta(\mathbb{Q}(\alpha)) = x - \sqrt[4]{2} [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] = 1 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] [\mathbb{Q}(\alpha):\mathbb{Q}] = 1 \cdot 4 = 4 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 8 \alpha = \sqrt[4]{2}, \beta = \sqrt[4]{2} i m_\alpha(\mathbb{Q}) = x^4 - 2 [\mathbb{Q}(\alpha):\mathbb{Q}] = 4 x=\sqrt[4]{2} i x^2 = - (\sqrt[4]{2})^2 x^2 + (\sqrt[4]{2})^2 = 0 (\sqrt[4]{2})^2 \in \mathbb{Q}(\sqrt[4]{2}) = \mathbb{Q}(\alpha) m_\beta(\mathbb{Q}(\alpha)) = x^2 + (\sqrt[4]{2})^2 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] = 2 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] [\mathbb{Q}(\alpha):\mathbb{Q}] = 2 \cdot 4 = 8 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 16 \alpha = \sqrt[4]{2}, \beta = \sqrt[4]{3} m_\alpha(\mathbb{Q}) = x^4 - 2 [\mathbb{Q}(\alpha):\mathbb{Q}] = 4 \beta = \sqrt[4]{3} \notin \mathbb{Q}(\sqrt[4]{2}) = \mathbb{Q}(\alpha) deg(m_\beta(\mathbb{Q}(\alpha))) > 1 \beta = \sqrt[4]{3} x^4 - 3 = 0 \mathbb{Q}(\sqrt[4]{2})[x] x^4 - 3 = (x^2 - \sqrt{3})(x^2 + \sqrt{3}) \sqrt{3} \notin \mathbb{Q}(\sqrt[4]{2}) x^4 - 3 = (x-\sqrt[4]{3})(x^3+\sqrt[4]{3}x^2+(\sqrt[4]{3})^2x+(\sqrt[4]{3})^3) \sqrt[4]{3} \notin \mathbb{Q}(\sqrt[4]{2}) m_\beta(\mathbb{Q}(\alpha)) = x^4 - 3 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] = 4 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = [\mathbb{Q}(\alpha,\beta):\mathbb{Q}(\alpha)] [\mathbb{Q}(\alpha):\mathbb{Q}] = 4 \cdot 4 = 16 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 12 [\mathbb{Q}(\alpha,\beta):\mathbb{Q}] = 12","['abstract-algebra', 'polynomials', 'field-theory', 'extension-field', 'minimal-polynomials']"
95,Existence of the complement of product of two normal subgroups having complement,Existence of the complement of product of two normal subgroups having complement,,"Let $G$ be a group. If $H\le G$ , $G=HK$ and $H\cap K=1$ , then $K$ is called a complement of $H$ in $G$ . In general complements do not exist. For example, the center of a quaternion group $Q$ does not have a complement since there is only one involution in $Q$ ; also, nontrivial proper subgroups of cyclic groups of prime power order do not have complements. There are some nice theorems ensuring the existence of complement under some conditions, like the one of Schur-Zassenhaus and the one of Gaschütz. When two normal subgroups both have their complements, it can be seen that $N_1N_2$ does not necessarily has complement. But it seems that the complement exists provided that some additional information is given, for example one the two normal subgroups is contained in a complement of another subgroup. So the following question arises: Let $N_1$ and $N_2$ be normal subgroups of $G$ . If $N_i$ has a complement $L_i$ ( $i=1,2$ ) such that $N_2\le L_1$ , then also $N_1N_2$ has a complement. Is the statement true? Any help is appreciated.","Let be a group. If , and , then is called a complement of in . In general complements do not exist. For example, the center of a quaternion group does not have a complement since there is only one involution in ; also, nontrivial proper subgroups of cyclic groups of prime power order do not have complements. There are some nice theorems ensuring the existence of complement under some conditions, like the one of Schur-Zassenhaus and the one of Gaschütz. When two normal subgroups both have their complements, it can be seen that does not necessarily has complement. But it seems that the complement exists provided that some additional information is given, for example one the two normal subgroups is contained in a complement of another subgroup. So the following question arises: Let and be normal subgroups of . If has a complement ( ) such that , then also has a complement. Is the statement true? Any help is appreciated.","G H\le G G=HK H\cap K=1 K H G Q Q N_1N_2 N_1 N_2 G N_i L_i i=1,2 N_2\le L_1 N_1N_2","['abstract-algebra', 'group-theory', 'finite-groups']"
96,Algebra structure of $\mathbb{R}[Q_8]$ where $Q_8$ is the quaternion group of order $8$.,Algebra structure of  where  is the quaternion group of order .,\mathbb{R}[Q_8] Q_8 8,"Let $Q_8$ be the quaternion group of order $8$ . I would like to determine the algebra structure for $\mathbb{R}[Q_8]$ . I think $\mathbb{R}[Q_8] \cong \mathbb{R}^4 \oplus \mathbb{H}$ . Maybe a simpler question to all of this is: why is $\mathbb{R}[Q_8] \not\cong \mathbb{R}^4 \oplus M_2(\mathbb{R})$ ? My work so far: By Maschke's Theorem, $\mathbb{R}[Q_8]$ is semisimple. By Artin-Wedderburn Theorem, since $\mathbb{R}[Q_8]$ is a finite-dimensional semisimple $\mathbb{R}$ -algebra, it follows that $$\mathbb{R}[Q_8] \cong M_{n_1}(D_1) \oplus \dots \oplus M_{n_k}(D_k)$$ where each $n_i$ is a positive integer and $D_i$ is a division ring over $\mathbb{R}$ . By Frobenius theorem (of real division algebras), it follows that each $D_i$ is isomorphic to either $\mathbb{R}$ (1-dimensional), $\mathbb{C}$ (2-dimensional), or the quaternions $\mathbb{H}$ (4-dimensional). Thus, we begin a combinatorial argument: $$\mathbb{R}[Q_8] \cong \mathbb{R}^a \oplus M_2(\mathbb{R})^b \oplus \mathbb{C}^c \oplus M_2(\mathbb{C})^d \oplus \mathbb{H}^e$$ (Note that $\mathbb{R}[Q_8]$ is an $8$ -dimensional group algebra which is why $M_n(\mathbb{R})$ terms don't exist for $n>2$ and similar reasoning for $M_n(\mathbb{C})$ and $M_n(\mathbb{H})$ .) My argument will rely on the following facts: (i) $Q_8$ has five conjugacy classes so $k=5=a+b+c+d+e$ . (ii) $\operatorname{dim}(\mathbb{R}[Q_8]) = 8 = a + 4b + 2c + 8d + 4e$ (iii) $\mathbb{R}[Q_8]$ is non-commutative because $Q_8$ is non-abelian so we must have at least one of $b$ , $d$ , or $e$ to be nonzero. [Claim 1: d = 0] First of all, to satisfy (ii), $d$ must be either $0$ or $1$ . If $d=1$ , then we immediately get $a=b=c=e=0$ which contradicts (i) so $d=0$ . [Claim 2: c = 0] Similarly, if $c>1$ then we cannot simultaneously satisfy (i) and (ii) so $c$ is either $0$ or $1$ . To satisfy both conditions with $c=1$ , we are forced to have $a=4$ and $b=d=e=0$ which contradicts (iii). Thus, $c=0$ . [Claim 3: a = 4] Condition (ii) is now simplified to $8=a+4b+4e$ . This equation can only be satisfied when $a\in \{ 0 ,4,8 \}$ . However, $a=8$ contradicts (iii) and $a=0$ contradicts (i) so we must have that $a=4$ . At this point, I now have that $\mathbb{R}[Q_8] \cong \mathbb{R}^4 \oplus M_2(\mathbb{R})$ OR $\mathbb{R}[Q_8] \cong \mathbb{R}^4 \oplus \mathbb{H}$ . Both possibilities satisfy (i)-(iii). Intuition tells me that I should get a copy of $\mathbb{H}$ and Wikipedia suggests this too. However, their reasoning seems to rely on more advanced machinery on irreducible characters/representations that I do not have. I thought about possibly arguing by nilpotent elements or the center of the algebra but I don't know how to rigorously argue that it should be isomorphic to the latter. Ideally, I am hoping there would be a fundamental property about these group algebras that I am overlooking to provide a simple argument rather than going into heavier machinary.","Let be the quaternion group of order . I would like to determine the algebra structure for . I think . Maybe a simpler question to all of this is: why is ? My work so far: By Maschke's Theorem, is semisimple. By Artin-Wedderburn Theorem, since is a finite-dimensional semisimple -algebra, it follows that where each is a positive integer and is a division ring over . By Frobenius theorem (of real division algebras), it follows that each is isomorphic to either (1-dimensional), (2-dimensional), or the quaternions (4-dimensional). Thus, we begin a combinatorial argument: (Note that is an -dimensional group algebra which is why terms don't exist for and similar reasoning for and .) My argument will rely on the following facts: (i) has five conjugacy classes so . (ii) (iii) is non-commutative because is non-abelian so we must have at least one of , , or to be nonzero. [Claim 1: d = 0] First of all, to satisfy (ii), must be either or . If , then we immediately get which contradicts (i) so . [Claim 2: c = 0] Similarly, if then we cannot simultaneously satisfy (i) and (ii) so is either or . To satisfy both conditions with , we are forced to have and which contradicts (iii). Thus, . [Claim 3: a = 4] Condition (ii) is now simplified to . This equation can only be satisfied when . However, contradicts (iii) and contradicts (i) so we must have that . At this point, I now have that OR . Both possibilities satisfy (i)-(iii). Intuition tells me that I should get a copy of and Wikipedia suggests this too. However, their reasoning seems to rely on more advanced machinery on irreducible characters/representations that I do not have. I thought about possibly arguing by nilpotent elements or the center of the algebra but I don't know how to rigorously argue that it should be isomorphic to the latter. Ideally, I am hoping there would be a fundamental property about these group algebras that I am overlooking to provide a simple argument rather than going into heavier machinary.","Q_8 8 \mathbb{R}[Q_8] \mathbb{R}[Q_8] \cong \mathbb{R}^4 \oplus \mathbb{H} \mathbb{R}[Q_8] \not\cong \mathbb{R}^4 \oplus M_2(\mathbb{R}) \mathbb{R}[Q_8] \mathbb{R}[Q_8] \mathbb{R} \mathbb{R}[Q_8] \cong M_{n_1}(D_1) \oplus \dots \oplus M_{n_k}(D_k) n_i D_i \mathbb{R} D_i \mathbb{R} \mathbb{C} \mathbb{H} \mathbb{R}[Q_8] \cong \mathbb{R}^a \oplus M_2(\mathbb{R})^b \oplus \mathbb{C}^c \oplus M_2(\mathbb{C})^d \oplus \mathbb{H}^e \mathbb{R}[Q_8] 8 M_n(\mathbb{R}) n>2 M_n(\mathbb{C}) M_n(\mathbb{H}) Q_8 k=5=a+b+c+d+e \operatorname{dim}(\mathbb{R}[Q_8]) = 8 = a + 4b + 2c + 8d + 4e \mathbb{R}[Q_8] Q_8 b d e d 0 1 d=1 a=b=c=e=0 d=0 c>1 c 0 1 c=1 a=4 b=d=e=0 c=0 8=a+4b+4e a\in \{ 0 ,4,8 \} a=8 a=0 a=4 \mathbb{R}[Q_8] \cong \mathbb{R}^4 \oplus M_2(\mathbb{R}) \mathbb{R}[Q_8] \cong \mathbb{R}^4 \oplus \mathbb{H} \mathbb{H}","['abstract-algebra', 'quaternions']"
97,Let $\alpha$ belong to $S_n$. Prove that $|\alpha|$ divides $n!$,Let  belong to . Prove that  divides,\alpha S_n |\alpha| n!,"From Gallian's ""Contemporary Abstract Algebra"", Part 2 Chapter 5 It looks like using Lagrange's theorem would work, since $|S_n| = n!$ and $\langle\alpha\rangle$ is a subgroup of $S_n$ . However, that hasn't been covered in the book at this point, so I'm assuming a different solution is expected $\alpha$ can be broken up into disjoint cycles $\alpha_1\dots\alpha_m$ such that $|\alpha_1| + \dots +|\alpha_m| = n$ , and then $|\alpha| = \operatorname{lcm}(|\alpha_1|, \dots, |\alpha_n|)$ . Don't know how to continue though","From Gallian's ""Contemporary Abstract Algebra"", Part 2 Chapter 5 It looks like using Lagrange's theorem would work, since and is a subgroup of . However, that hasn't been covered in the book at this point, so I'm assuming a different solution is expected can be broken up into disjoint cycles such that , and then . Don't know how to continue though","|S_n| = n! \langle\alpha\rangle S_n \alpha \alpha_1\dots\alpha_m |\alpha_1| + \dots +|\alpha_m| = n |\alpha| = \operatorname{lcm}(|\alpha_1|, \dots, |\alpha_n|)","['abstract-algebra', 'group-theory', 'permutation-cycles']"
98,Group of units of $\mathbb{Z}_3[[x]]$,Group of units of,\mathbb{Z}_3[[x]],"I am trying to calculate the group of units of the power series ring $\mathbb{Z}_3[[x]]$ . I know that all the unit elements are of the form $u+\sum_1^{\infty} a_nx^n$ where $u$ is a unit in $\mathbb{Z}_3$ , where $\mathbb{Z}_3$ are the $3$ -adic integers. However I am not sure about the group structure. For example, we have many subgroups $U_i$ which are the set of elements of the form $u+\sum_i^{\infty} a_nx^n$ i.e the power series where the first power of $x$ is $x^i$ . These groups form a filtration on the group of units. Is there a way to relate these groups to the group of units of $\mathbb{Z}_3[[x]]$ similar to the result for the ring $\mathbb{F}_3[[x]]$ ? For the result for $\mathbb{F}_3[[x]]$ look at Thm 4.4 here . Thanks in advance.","I am trying to calculate the group of units of the power series ring . I know that all the unit elements are of the form where is a unit in , where are the -adic integers. However I am not sure about the group structure. For example, we have many subgroups which are the set of elements of the form i.e the power series where the first power of is . These groups form a filtration on the group of units. Is there a way to relate these groups to the group of units of similar to the result for the ring ? For the result for look at Thm 4.4 here . Thanks in advance.",\mathbb{Z}_3[[x]] u+\sum_1^{\infty} a_nx^n u \mathbb{Z}_3 \mathbb{Z}_3 3 U_i u+\sum_i^{\infty} a_nx^n x x^i \mathbb{Z}_3[[x]] \mathbb{F}_3[[x]] \mathbb{F}_3[[x]],"['abstract-algebra', 'group-theory', 'p-adic-number-theory', 'formal-power-series']"
99,Is a subgroup determined by where the generators are in its cosets?,Is a subgroup determined by where the generators are in its cosets?,,"Let $G$ be a finitely generated infinite group and $H$ be a subgroup of finite index. In particular say $G=\langle x_1,x_2,...,x_n\rangle$ and $G:H=\{R_1,...,R_m\}$ . Does the distribution of the $x_i$ among the $R_j$ determine $H$ (up to reordering cosets)? For example if $G=\langle x_1,x_2,x_3\rangle$ and $H$ is such that $x_1, x_2\in R^H_1$ and $x_3\in R^H_2$ , then if $K\le G$ with $x_1,x_2\in R_1^K, x_3\in R_2^K$ , we must have $H=K$ ? Hopefully the intention is clear, but let me know in the comments if otherwise","Let be a finitely generated infinite group and be a subgroup of finite index. In particular say and . Does the distribution of the among the determine (up to reordering cosets)? For example if and is such that and , then if with , we must have ? Hopefully the intention is clear, but let me know in the comments if otherwise","G H G=\langle x_1,x_2,...,x_n\rangle G:H=\{R_1,...,R_m\} x_i R_j H G=\langle x_1,x_2,x_3\rangle H x_1, x_2\in R^H_1 x_3\in R^H_2 K\le G x_1,x_2\in R_1^K, x_3\in R_2^K H=K","['abstract-algebra', 'group-theory', 'finitely-generated', 'infinite-groups']"
