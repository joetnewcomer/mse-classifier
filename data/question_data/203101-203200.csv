,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Prove that $\kappa(s) = \lim\limits_{h \to 0} \left|\frac{\theta (s,h)}{h}\right|$",Prove that,"\kappa(s) = \lim\limits_{h \to 0} \left|\frac{\theta (s,h)}{h}\right|","$\newcommand{\Reals}{\mathbf{R}}$Let $\gamma:I\subset \Reals \to \Reals^{n}$ the arc length parameterization of a curve $C\subset \Reals^{n}$. If $\theta(s, h)$ is the angle between $T(s)$ and $T(s + h)$, show that $$ \kappa(s) = \lim_{h \to 0} \left|\frac{\theta (s, h)}{h}\right|. $$ Indeed, I can see that geometrically this is what happens, but how can I prove it? I have tried using that $$ \cos\theta = \langle T(s), T(s + h)\rangle, $$ but I can't get to anything, any help will be appreciated, thanks.","$\newcommand{\Reals}{\mathbf{R}}$Let $\gamma:I\subset \Reals \to \Reals^{n}$ the arc length parameterization of a curve $C\subset \Reals^{n}$. If $\theta(s, h)$ is the angle between $T(s)$ and $T(s + h)$, show that $$ \kappa(s) = \lim_{h \to 0} \left|\frac{\theta (s, h)}{h}\right|. $$ Indeed, I can see that geometrically this is what happens, but how can I prove it? I have tried using that $$ \cos\theta = \langle T(s), T(s + h)\rangle, $$ but I can't get to anything, any help will be appreciated, thanks.",,"['differential-geometry', 'curves', 'frenet-frame']"
1,What does the compatibility condition in the definition of meromorphic differentials mean?,What does the compatibility condition in the definition of meromorphic differentials mean?,,"Let $S$ be a Riemann surface, with an atlas $(U_i, \varphi_i)_{i \in I}$. For any $P \in S$, denote $$\frac{dz_i}{dz_j}(P):= (\varphi_i \circ \varphi_j^{-1})^\prime (\varphi_j(P)).$$ We then define a meromorphic differential $\omega$ as a collection of meromorphic functions $\{f_i : U_i \rightarrow \mathbb{C}\}$ satisfying the compatibility condition $$f_j = f_i \frac{dz_i}{dz_j}$$ in the intersection $U_i \cap U_j$. What is the meaning of this compatibility condition? What property is preserved under change of coordinates, and why give it the name differential? Also, is this a differential form?","Let $S$ be a Riemann surface, with an atlas $(U_i, \varphi_i)_{i \in I}$. For any $P \in S$, denote $$\frac{dz_i}{dz_j}(P):= (\varphi_i \circ \varphi_j^{-1})^\prime (\varphi_j(P)).$$ We then define a meromorphic differential $\omega$ as a collection of meromorphic functions $\{f_i : U_i \rightarrow \mathbb{C}\}$ satisfying the compatibility condition $$f_j = f_i \frac{dz_i}{dz_j}$$ in the intersection $U_i \cap U_j$. What is the meaning of this compatibility condition? What property is preserved under change of coordinates, and why give it the name differential? Also, is this a differential form?",,['differential-geometry']
2,Convexity and mean curvature,Convexity and mean curvature,,"Let $N$ be a Riemannian 3-Manifold with and $M \subset N$ an embedded, oriented codimension $0$ submanifold-with-boundary, bounded by a non-empty smooth subsurface $S := \partial M$. Now, with $M$ and therefore $S$ being oriented, the latter has a tubular neighborhood $T \cong S\times(-1,1)$ via some diffeomorphism $\phi$, such that under the same $\phi$, $T \cap M \cong S\times(-1,0]$.  We call this the inward normal section of $T$ and, for $s \in S$, its intersection with the fiber $F_s \subset T$ the inward normal at $s$. Further, we say that $M$ has almost convex boundary if for any $s \in S$ there exists an $\epsilon > 0$ such that for all $0 < \delta < \epsilon$, the cut-off ball $B(\delta,s) \cap M$ is a convex subset of $N$ (any two points in this set can be connected by a minimal geodesic which lies completely inside the set).  In contrast, $M$ is said to have sufficiently convex boundary if $S$ has nonnegative mean curvature with respect to the inward normal section. Now I want to prove that \begin{equation} \mbox{M has almost convex boundary} \implies\mbox{M has sufficiently convex boundary}. \end{equation} As it is natural (for me at least) with these kinds of problems, I first tried to solve this problem in eucledian space $\mathbb R^3$ and then look at what needs to be changed and generalized for arbitrary 3-manifolds. Here is what I came up with so far: If $M \subset \mathbb R^3$ and $s \in S$, there is a small neighborhood $U \ni s$ and a smooth function $f: U \to \mathbb R$ that describes $U$ in terms of its level sets, i.e we have $U \cap M = f^{-1}[0,\infty)$ and $U \cap S = f^{-1}(0)$. This implies that the inward unit normal field of $S$ restricted to $U$ can be expressed by \begin{equation} \frac{\nabla f}{|\nabla f|}, \end{equation} with the corresponding mean curvature just being the negative divergence of the above vectorfield. Now assuming $M$ has almost convex boundary and $U$ has been chosen sufficiently small, the unique line segment $(1-t)x + ty, t \in [0,1]$ connecting any two given points $x,y \in S \cap U$ lies completley in $M \cap U$, which is equivalent to $g_y(t) := f((1-t)x + ty) \geq 0$. Since $g_y(0) = f(x) = 0$, we must have $0 \leq g'_y(0) = \nabla f|_x * (y-x)$ by the chain rule. This nicely illustrates an intuitive property for manifolds with almost convex boundary: The angle between the inward normal at $x$ and any vector emanating from $x$, pointing in the direction of $y$, should be at most $90$ degrees for any $y$ on $S$ sufficiently close to $x$. Moreover, it seems to me that this ""angle condition"" should also suffice to prove the nonnegativity of mean curvature. Does anyone have an idea how to proceed from here?","Let $N$ be a Riemannian 3-Manifold with and $M \subset N$ an embedded, oriented codimension $0$ submanifold-with-boundary, bounded by a non-empty smooth subsurface $S := \partial M$. Now, with $M$ and therefore $S$ being oriented, the latter has a tubular neighborhood $T \cong S\times(-1,1)$ via some diffeomorphism $\phi$, such that under the same $\phi$, $T \cap M \cong S\times(-1,0]$.  We call this the inward normal section of $T$ and, for $s \in S$, its intersection with the fiber $F_s \subset T$ the inward normal at $s$. Further, we say that $M$ has almost convex boundary if for any $s \in S$ there exists an $\epsilon > 0$ such that for all $0 < \delta < \epsilon$, the cut-off ball $B(\delta,s) \cap M$ is a convex subset of $N$ (any two points in this set can be connected by a minimal geodesic which lies completely inside the set).  In contrast, $M$ is said to have sufficiently convex boundary if $S$ has nonnegative mean curvature with respect to the inward normal section. Now I want to prove that \begin{equation} \mbox{M has almost convex boundary} \implies\mbox{M has sufficiently convex boundary}. \end{equation} As it is natural (for me at least) with these kinds of problems, I first tried to solve this problem in eucledian space $\mathbb R^3$ and then look at what needs to be changed and generalized for arbitrary 3-manifolds. Here is what I came up with so far: If $M \subset \mathbb R^3$ and $s \in S$, there is a small neighborhood $U \ni s$ and a smooth function $f: U \to \mathbb R$ that describes $U$ in terms of its level sets, i.e we have $U \cap M = f^{-1}[0,\infty)$ and $U \cap S = f^{-1}(0)$. This implies that the inward unit normal field of $S$ restricted to $U$ can be expressed by \begin{equation} \frac{\nabla f}{|\nabla f|}, \end{equation} with the corresponding mean curvature just being the negative divergence of the above vectorfield. Now assuming $M$ has almost convex boundary and $U$ has been chosen sufficiently small, the unique line segment $(1-t)x + ty, t \in [0,1]$ connecting any two given points $x,y \in S \cap U$ lies completley in $M \cap U$, which is equivalent to $g_y(t) := f((1-t)x + ty) \geq 0$. Since $g_y(0) = f(x) = 0$, we must have $0 \leq g'_y(0) = \nabla f|_x * (y-x)$ by the chain rule. This nicely illustrates an intuitive property for manifolds with almost convex boundary: The angle between the inward normal at $x$ and any vector emanating from $x$, pointing in the direction of $y$, should be at most $90$ degrees for any $y$ on $S$ sufficiently close to $x$. Moreover, it seems to me that this ""angle condition"" should also suffice to prove the nonnegativity of mean curvature. Does anyone have an idea how to proceed from here?",,"['differential-geometry', 'riemannian-geometry']"
3,Interpreting partial derivatives $\frac{\partial f}{\partial u}$ in differential geometry,Interpreting partial derivatives  in differential geometry,\frac{\partial f}{\partial u},"I'm reading Do Carmo's ""Riemannian Geometry""  and at some point he introduces the following notation: Let $A \subset \mathbb{R}^2$ be an open region bounded by a piecewise differentiable curve and $f: A \to M$ be a differentiable mapping into a manifold $M$. Now define: $$\frac{\partial f}{\partial u} (u,v) := T_{(u,v)}f \cdot \frac{\partial}{\partial u}$$ And similarily for $\frac{\partial f}{\partial v}$. Next in the book there's a remark saying both of these can be viewed as vector fields along $f$. What does that mean? Does it mean that $(p \mapsto T_{f^{-1}(p)}f \cdot \frac{\partial}{\partial u})$ is a smooth vector field defined on $f(A)$? What if $f^{-1}$ isn't differentiable? Straight after he introduces the notation $\frac{D}{\partial u}$ for the covariant derivative along the curve $(u \mapsto f(u,v_0))$. Is it correct to translate that to $\nabla_{\frac{\partial f}{\partial u}}$ ? What's really bothering me is that I'm finding the partial derivative notation very confusing. After a couple of pages the following expression appears: $$\frac{\partial}{\partial u}<\frac{\partial f}{\partial v},\frac{\partial f}{\partial u}> = <\frac{D}{\partial u} \frac{\partial f}{\partial v},\frac{\partial f}{\partial u}> + <\frac{\partial f}{\partial v},\frac{D}{\partial u} \frac{\partial f}{\partial u}>$$ Which to me looks extremely confusingly simplistic. As i see it, $\frac{\partial}{\partial u}$ at the start of the line must really stand for $\frac{\partial f}{\partial u}$ and plugging it in it does make much more sense to me (and looks like the usual inner product rule for covariant derivatives). Now, for the general question: How should I think of an object like $\frac{\partial f}{\partial u}$ in the context of differential geometry? Should I always think of it $Tf \cdot \frac{\partial }{\partial u} : A \to TM$ ? If $f$ is a diffeomorphism i can interpert it as a pushforward of the section $\frac{\partial }{\partial u} |_{(u,v)}$ by $f$ i.e. $$\frac{\partial f}{\partial u} := f_* (\frac{\partial}{\partial u}) = Tf \circ \frac{\partial}{\partial u} \circ f^{-1} : f(A) \to TM$$ Is this the right interpretation? I'm really lost here, thanks for the help.","I'm reading Do Carmo's ""Riemannian Geometry""  and at some point he introduces the following notation: Let $A \subset \mathbb{R}^2$ be an open region bounded by a piecewise differentiable curve and $f: A \to M$ be a differentiable mapping into a manifold $M$. Now define: $$\frac{\partial f}{\partial u} (u,v) := T_{(u,v)}f \cdot \frac{\partial}{\partial u}$$ And similarily for $\frac{\partial f}{\partial v}$. Next in the book there's a remark saying both of these can be viewed as vector fields along $f$. What does that mean? Does it mean that $(p \mapsto T_{f^{-1}(p)}f \cdot \frac{\partial}{\partial u})$ is a smooth vector field defined on $f(A)$? What if $f^{-1}$ isn't differentiable? Straight after he introduces the notation $\frac{D}{\partial u}$ for the covariant derivative along the curve $(u \mapsto f(u,v_0))$. Is it correct to translate that to $\nabla_{\frac{\partial f}{\partial u}}$ ? What's really bothering me is that I'm finding the partial derivative notation very confusing. After a couple of pages the following expression appears: $$\frac{\partial}{\partial u}<\frac{\partial f}{\partial v},\frac{\partial f}{\partial u}> = <\frac{D}{\partial u} \frac{\partial f}{\partial v},\frac{\partial f}{\partial u}> + <\frac{\partial f}{\partial v},\frac{D}{\partial u} \frac{\partial f}{\partial u}>$$ Which to me looks extremely confusingly simplistic. As i see it, $\frac{\partial}{\partial u}$ at the start of the line must really stand for $\frac{\partial f}{\partial u}$ and plugging it in it does make much more sense to me (and looks like the usual inner product rule for covariant derivatives). Now, for the general question: How should I think of an object like $\frac{\partial f}{\partial u}$ in the context of differential geometry? Should I always think of it $Tf \cdot \frac{\partial }{\partial u} : A \to TM$ ? If $f$ is a diffeomorphism i can interpert it as a pushforward of the section $\frac{\partial }{\partial u} |_{(u,v)}$ by $f$ i.e. $$\frac{\partial f}{\partial u} := f_* (\frac{\partial}{\partial u}) = Tf \circ \frac{\partial}{\partial u} \circ f^{-1} : f(A) \to TM$$ Is this the right interpretation? I'm really lost here, thanks for the help.",,"['differential-geometry', 'riemannian-geometry', 'vector-analysis']"
4,The arc length in Riemannian geometry is well defined (independent from the choice of the coordinates),The arc length in Riemannian geometry is well defined (independent from the choice of the coordinates),,"Let be $(M,g)$ a connected Riemannian manifold and $p,q \in M$. If $ \phi : [a,b] \rightarrow M$ is $C^\infty$ we define the arc-length of the curve $\phi$ as the quantity: $$J(\phi )= \int_a^b f(\phi (t),\dot{\phi(t)})\; dt$$ where $$ f(\phi(t),\dot{\phi(t)})^2= \sum_{\alpha, \beta} g_{\alpha,\beta}(\phi(t)) \:\dot{\phi}(t)^\alpha\: \dot{\phi}(t)^\beta$$ and $\phi^1(t),\dots, \phi^n(t)$ are the local coordinates of $\phi(t)$. I want to prove that $f(\phi(t),\dot{\phi(t)})$is independent from the choice of the coordinates in a neighborhood of $\phi(t)$. In my text book it is said that this is an obvious fact. Why? I try to do that substituting in the summation the relation between  $g_{j,\, \alpha, \beta} $ and  $g_{k,\, \alpha, \beta}$ and the relations between $\frac{\partial}{\partial x_j}$ and $\frac{\partial}{\partial X_k}$ involving the Jacobian matrix (the rules of changing of coordinates for tensors in components) but I didn't succeed in  proving the above claim . Is there a more direct way to check this? Thanks!","Let be $(M,g)$ a connected Riemannian manifold and $p,q \in M$. If $ \phi : [a,b] \rightarrow M$ is $C^\infty$ we define the arc-length of the curve $\phi$ as the quantity: $$J(\phi )= \int_a^b f(\phi (t),\dot{\phi(t)})\; dt$$ where $$ f(\phi(t),\dot{\phi(t)})^2= \sum_{\alpha, \beta} g_{\alpha,\beta}(\phi(t)) \:\dot{\phi}(t)^\alpha\: \dot{\phi}(t)^\beta$$ and $\phi^1(t),\dots, \phi^n(t)$ are the local coordinates of $\phi(t)$. I want to prove that $f(\phi(t),\dot{\phi(t)})$is independent from the choice of the coordinates in a neighborhood of $\phi(t)$. In my text book it is said that this is an obvious fact. Why? I try to do that substituting in the summation the relation between  $g_{j,\, \alpha, \beta} $ and  $g_{k,\, \alpha, \beta}$ and the relations between $\frac{\partial}{\partial x_j}$ and $\frac{\partial}{\partial X_k}$ involving the Jacobian matrix (the rules of changing of coordinates for tensors in components) but I didn't succeed in  proving the above claim . Is there a more direct way to check this? Thanks!",,"['differential-geometry', 'riemannian-geometry']"
5,Specifying an arbitrary point on a manifold,Specifying an arbitrary point on a manifold,,"It is known that any arbitrary point x on the sphere $\mathbb{S}^2$ can be parametrised by the spherical coordinates $$\bf{x}=r(\theta,\phi)=(\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta),\quad 0\le\theta\le\pi,0\le\phi\le 2\pi.$$ Here the arbitrary point x appears to be a vector function on $\mathbb{R}^3$.See for instance Steward calculus (parametrisation of the unit sphere) Now I know that the sphere is embedded in $\mathbb{R}^3$, I start asking and want to know a very elementary general fact... Can any arbitrary point on a general manifold be viewed as a vector function on the corresponding Euclidean space? (Given the manifold can be embedded into that Euclidean space)","It is known that any arbitrary point x on the sphere $\mathbb{S}^2$ can be parametrised by the spherical coordinates $$\bf{x}=r(\theta,\phi)=(\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta),\quad 0\le\theta\le\pi,0\le\phi\le 2\pi.$$ Here the arbitrary point x appears to be a vector function on $\mathbb{R}^3$.See for instance Steward calculus (parametrisation of the unit sphere) Now I know that the sphere is embedded in $\mathbb{R}^3$, I start asking and want to know a very elementary general fact... Can any arbitrary point on a general manifold be viewed as a vector function on the corresponding Euclidean space? (Given the manifold can be embedded into that Euclidean space)",,"['differential-geometry', 'manifolds', 'geometric-topology']"
6,"Differential geometry: $|\alpha(t)|=c\ne 0 \iff \langle \alpha(t),\alpha'(t)\rangle = 0,\forall t\in I$",Differential geometry:,"|\alpha(t)|=c\ne 0 \iff \langle \alpha(t),\alpha'(t)\rangle = 0,\forall t\in I","Let $\alpha: I\to \Bbb R^3$ be a regular para curve. I want to prove that: $|\alpha(t)|=c\ne 0 \iff \langle \alpha(t),\alpha'(t)\rangle = 0,\forall t\in I$ Now $|\alpha(t)|=c\ne 0$ means that this traces some subset or an entire path on the surface of a sphere radius $c$, in some direction. I can see that then the tangent to any point on the sphere is definitely an orthogonal plane(it's flat on the surface). What I can't do is prove either direction mathematically. $(\implies)$ $|\alpha(t)|=c\ne0$ gives us $x(t)^2+y(t)^2+z(t)^2=c^2$ which is our surface transversal as we know. No idea how to get the orthogonality. Actually the fact that $xx'+yy'+zz'=0$ looks like it implies that whatever was nonzero in $\alpha$ is zero in $\alpha'$, so then $\alpha'=0$ But the definition of orthogonality comes from nonzero vectors, so I don't know.","Let $\alpha: I\to \Bbb R^3$ be a regular para curve. I want to prove that: $|\alpha(t)|=c\ne 0 \iff \langle \alpha(t),\alpha'(t)\rangle = 0,\forall t\in I$ Now $|\alpha(t)|=c\ne 0$ means that this traces some subset or an entire path on the surface of a sphere radius $c$, in some direction. I can see that then the tangent to any point on the sphere is definitely an orthogonal plane(it's flat on the surface). What I can't do is prove either direction mathematically. $(\implies)$ $|\alpha(t)|=c\ne0$ gives us $x(t)^2+y(t)^2+z(t)^2=c^2$ which is our surface transversal as we know. No idea how to get the orthogonality. Actually the fact that $xx'+yy'+zz'=0$ looks like it implies that whatever was nonzero in $\alpha$ is zero in $\alpha'$, so then $\alpha'=0$ But the definition of orthogonality comes from nonzero vectors, so I don't know.",,['differential-geometry']
7,Existence of real structure on CY m-fold,Existence of real structure on CY m-fold,,"Suppose $M$ is Calabi-Yau $m$-fold with complex structure $J$, Kahler form $\omega$, metric $g$ and holomorphic $m$-form $\Omega$. What are the conditions on $M$ for the existence of a map $\sigma: M \to M$ such that $\sigma^2 = id$, $\sigma^* (J)=-J$, $\sigma^* (\omega)=-\omega$, $\sigma^*(g)=g$, $\sigma^* (\Omega) = \bar \Omega$ ? in particular, suppose we see $M$ as a point in moduli space, then what are the restrictions on the moduli space so that the above involution exists?","Suppose $M$ is Calabi-Yau $m$-fold with complex structure $J$, Kahler form $\omega$, metric $g$ and holomorphic $m$-form $\Omega$. What are the conditions on $M$ for the existence of a map $\sigma: M \to M$ such that $\sigma^2 = id$, $\sigma^* (J)=-J$, $\sigma^* (\omega)=-\omega$, $\sigma^*(g)=g$, $\sigma^* (\Omega) = \bar \Omega$ ? in particular, suppose we see $M$ as a point in moduli space, then what are the restrictions on the moduli space so that the above involution exists?",,"['algebraic-geometry', 'differential-geometry', 'complex-geometry']"
8,"If $\nabla_1$ and $\nabla_2$ are Levi-Civita connections for a metric on the smooth sphere, then their curvature tensor would recover the radius...?","If  and  are Levi-Civita connections for a metric on the smooth sphere, then their curvature tensor would recover the radius...?",\nabla_1 \nabla_2,"I am a little confused by an idea suggested to me: putting a connection on a sphere doesn't specify a metric geometry - it remembers notions like straightness of paths, but not length of paths. Let me ask a specific question. Let $\nabla$ be a connection on the smooth sphere $S^2$ (a topological manifold with a smooth atlas). Provided the connection $\nabla$ spherically symmetric (I capriciously define this to mean that it pulls back to itself for all elements in some conjugacy class of $SO(n)$ in the full diffeomorphism group of the zero set $x^2 + y^2 + z^2 = 1$ in $R^3$), torsion-free, and has constant scalar curvature $1/2(1/r^2)$, can I conclude that the connection is the Levi-Civita connection of the round sphere of radius $r$ with the usual spherical metric? Thanks - I am just trying to understand better exactly what information is contained in the connection / covariant derivative.","I am a little confused by an idea suggested to me: putting a connection on a sphere doesn't specify a metric geometry - it remembers notions like straightness of paths, but not length of paths. Let me ask a specific question. Let $\nabla$ be a connection on the smooth sphere $S^2$ (a topological manifold with a smooth atlas). Provided the connection $\nabla$ spherically symmetric (I capriciously define this to mean that it pulls back to itself for all elements in some conjugacy class of $SO(n)$ in the full diffeomorphism group of the zero set $x^2 + y^2 + z^2 = 1$ in $R^3$), torsion-free, and has constant scalar curvature $1/2(1/r^2)$, can I conclude that the connection is the Levi-Civita connection of the round sphere of radius $r$ with the usual spherical metric? Thanks - I am just trying to understand better exactly what information is contained in the connection / covariant derivative.",,"['differential-geometry', 'riemannian-geometry', 'connections']"
9,Is Heisenberg group Euclidean?,Is Heisenberg group Euclidean?,,"I'm reading an article speaking about Heisenberg group $\mathbb H^n$ and some of its properties.  Now, I have some questions to ask, hoping to be clear enought. Reading the introduction I've understood that we can identify $\mathbb H^n$ with $\mathbb R^{2n+1}$ so we can denote points of Heisenberg group as $P=(x_1,\dots, x_n, y_1,\dots,y_n,t)$. On $\mathbb H^n$ we have an operation $\cdot: \mathbb H^n\times \mathbb H^n\to \mathbb H^n$ defined as $$P\cdot P'= (x_1+x'_1,\dots,y_n+y_n',t+t'+\frac{1}{2}\sum_{j=1}^n x_iy'_i-x'_iy_i),$$ which is not commutative. We can define dilatations $\delta_\lambda:\mathbb H^n\to\mathbb H^n$, $$\delta_{\lambda}(P)=(\lambda x_1,\dots,\lambda y_n,\lambda^2 t).$$ Now, we can equipe $\mathbb H^n$ with a norm $||\cdot||$ defined as $$||P||=max\{|(x_1,\dots,x_n,y_1\dots,y_n)|,|t|^{\frac{1}{2}}\},$$ turning $\mathbb H^n$ in a metric space with distance $d,\, d(P,Q)=||P^{-1}\cdot Q||.$ This said, I'm going to add some my considerations and I would like to know if they are a correct way of thinking or not. Since I can identify $\mathbb H^n$ with $\mathbb R^{2n+1}$, I can think about $(\mathbb H^n,d)$ as $(\mathbb R^{2n+1},d)$. Then, since all norms on $\mathbb R^{2n+1}$ are equivalent, so are the distance $d$ and the Euclidean distance $D$, hence $(\mathbb H^n,d)$ and $(\mathbb R^{2n+1},D)$ are topologically equivalent. So, if I think about $\mathbb H^n$ as a smooth manifold, it coincides with $\mathbb R^{2n+1}$, in the sense that I have a unique chart ($\mathbb H^n$ itself) and the homeomorphism is given by the identity. On the other hand, in the introduction there's also written that $\mathbb H^n$ is not Euclidean and this seems to contrast what I've said so far. Could someone help me to understand?","I'm reading an article speaking about Heisenberg group $\mathbb H^n$ and some of its properties.  Now, I have some questions to ask, hoping to be clear enought. Reading the introduction I've understood that we can identify $\mathbb H^n$ with $\mathbb R^{2n+1}$ so we can denote points of Heisenberg group as $P=(x_1,\dots, x_n, y_1,\dots,y_n,t)$. On $\mathbb H^n$ we have an operation $\cdot: \mathbb H^n\times \mathbb H^n\to \mathbb H^n$ defined as $$P\cdot P'= (x_1+x'_1,\dots,y_n+y_n',t+t'+\frac{1}{2}\sum_{j=1}^n x_iy'_i-x'_iy_i),$$ which is not commutative. We can define dilatations $\delta_\lambda:\mathbb H^n\to\mathbb H^n$, $$\delta_{\lambda}(P)=(\lambda x_1,\dots,\lambda y_n,\lambda^2 t).$$ Now, we can equipe $\mathbb H^n$ with a norm $||\cdot||$ defined as $$||P||=max\{|(x_1,\dots,x_n,y_1\dots,y_n)|,|t|^{\frac{1}{2}}\},$$ turning $\mathbb H^n$ in a metric space with distance $d,\, d(P,Q)=||P^{-1}\cdot Q||.$ This said, I'm going to add some my considerations and I would like to know if they are a correct way of thinking or not. Since I can identify $\mathbb H^n$ with $\mathbb R^{2n+1}$, I can think about $(\mathbb H^n,d)$ as $(\mathbb R^{2n+1},d)$. Then, since all norms on $\mathbb R^{2n+1}$ are equivalent, so are the distance $d$ and the Euclidean distance $D$, hence $(\mathbb H^n,d)$ and $(\mathbb R^{2n+1},D)$ are topologically equivalent. So, if I think about $\mathbb H^n$ as a smooth manifold, it coincides with $\mathbb R^{2n+1}$, in the sense that I have a unique chart ($\mathbb H^n$ itself) and the homeomorphism is given by the identity. On the other hand, in the introduction there's also written that $\mathbb H^n$ is not Euclidean and this seems to contrast what I've said so far. Could someone help me to understand?",,"['general-topology', 'differential-geometry', 'differential-topology', 'lie-groups']"
10,Accounting for signs in divergence thm. on Lorentzian manifold,Accounting for signs in divergence thm. on Lorentzian manifold,,"I am trying to learn about integration in Lorentzian manifolds (I will use signature -+++) and have some problems. Oft quoted (in books for GR) form of divergence theorem is: $\int _U div( X )vol_M=\int _{\partial U}(N,X)vol_{\partial U}$ With remark that orientation on (nonnull) boundary should be chosen such that normal vector is pointing inside if it is timelike and outwards if it is spacelike. I don't understand that. This is how I tried to do it (and got wrong results when confronted with made up example): choose $\omega = i_X vol _M$ and apply Stokes. We have: $\int _U d\omega=\int _U di_XvolM=\int_Udiv(X)vol_M$ $\int _{\partial U} \omega =\int _{\partial U}(N,N)(N,X)i_Nvol_M=\int _{\partial U}(N,N)(N,X)vol_{\partial U}$ So I would think I can use equality of two integrals above no matter what orientation of boundary, as long as I make sure that basis $(N,Y_1,Y_2,Y_3)$ is positively oriented, where $Y_i$ make up the basis that I use on boundary. What am I doing wrong?","I am trying to learn about integration in Lorentzian manifolds (I will use signature -+++) and have some problems. Oft quoted (in books for GR) form of divergence theorem is: $\int _U div( X )vol_M=\int _{\partial U}(N,X)vol_{\partial U}$ With remark that orientation on (nonnull) boundary should be chosen such that normal vector is pointing inside if it is timelike and outwards if it is spacelike. I don't understand that. This is how I tried to do it (and got wrong results when confronted with made up example): choose $\omega = i_X vol _M$ and apply Stokes. We have: $\int _U d\omega=\int _U di_XvolM=\int_Udiv(X)vol_M$ $\int _{\partial U} \omega =\int _{\partial U}(N,N)(N,X)i_Nvol_M=\int _{\partial U}(N,N)(N,X)vol_{\partial U}$ So I would think I can use equality of two integrals above no matter what orientation of boundary, as long as I make sure that basis $(N,Y_1,Y_2,Y_3)$ is positively oriented, where $Y_i$ make up the basis that I use on boundary. What am I doing wrong?",,"['differential-geometry', 'general-relativity', 'semi-riemannian-geometry']"
11,Stokes' theorem and symplectic geometry,Stokes' theorem and symplectic geometry,,"Let $V = \mathbb{R}^2,$ as a vector space then the Poincaré invariant is an integral $\int_{\gamma} \theta$ where $\theta = p dx $ is the symplectic 1-form and $\gamma$ a closed curve. Now, it is interesting that in the 2d-case, that by Stokes' theorem $\gamma$ natually defines an area $A$ with $\partial A = \gamma$ and $\int_{\gamma} \theta = \int_{A} d \theta = \int_{A} dp \wedge dx.$ So what this invariant actually defines is the phase space volume. The situation gets more difficult when we are dealing with higher-dimensional spaces Let $V = \mathbb{R}^{2n}$ with $n>1$, then we can still define $\int_{\gamma} \sum_{i} p_i dx_i.$ Now, I started wondering: Can we still identify this with some area or interpret what this quantity actually tells us? A natural thing to do would be to assume $\int_{\gamma} \sum_{i} p_i dx_i = \int_{A} \sum_{i} dp_i \wedge dx_i.$ This basically means that we are summing up the area of the projection down to each $x_i,p_i$ plane, but now I don't know whether $\gamma$ naturally defines such an $A$ so that we can apply Stokes' theorem? But even if you cannot make any sense out of my last equation, it would be interesting for me to know whether we can interpret what $\int_{\gamma} \sum_i p_i dx_i $ actually tells us? If anything is unclear, please let me know.","Let $V = \mathbb{R}^2,$ as a vector space then the Poincaré invariant is an integral $\int_{\gamma} \theta$ where $\theta = p dx $ is the symplectic 1-form and $\gamma$ a closed curve. Now, it is interesting that in the 2d-case, that by Stokes' theorem $\gamma$ natually defines an area $A$ with $\partial A = \gamma$ and $\int_{\gamma} \theta = \int_{A} d \theta = \int_{A} dp \wedge dx.$ So what this invariant actually defines is the phase space volume. The situation gets more difficult when we are dealing with higher-dimensional spaces Let $V = \mathbb{R}^{2n}$ with $n>1$, then we can still define $\int_{\gamma} \sum_{i} p_i dx_i.$ Now, I started wondering: Can we still identify this with some area or interpret what this quantity actually tells us? A natural thing to do would be to assume $\int_{\gamma} \sum_{i} p_i dx_i = \int_{A} \sum_{i} dp_i \wedge dx_i.$ This basically means that we are summing up the area of the projection down to each $x_i,p_i$ plane, but now I don't know whether $\gamma$ naturally defines such an $A$ so that we can apply Stokes' theorem? But even if you cannot make any sense out of my last equation, it would be interesting for me to know whether we can interpret what $\int_{\gamma} \sum_i p_i dx_i $ actually tells us? If anything is unclear, please let me know.",,"['real-analysis', 'integration', 'differential-geometry', 'differential-forms', 'symplectic-geometry']"
12,Area form and surface area,Area form and surface area,,"I know how one can define the surface area via the charts of a surface in $\mathbb{R}^3.$ click here for instance Now, I read that the canonical surface area form for such a surface with surface normal $n$ is given by $\omega( \xi,\eta ) = \det(n,\xi,\eta).$ My question is now: How can I see that both definitions coincide? So why does the integral over $\int_{A} \omega$ the surface area now? The thing is that I am completely new to differential forms and maybe it is more or less the definition, but my problem is that I don't know how it follows now. If anything is unclear, please let me know.","I know how one can define the surface area via the charts of a surface in click here for instance Now, I read that the canonical surface area form for such a surface with surface normal is given by My question is now: How can I see that both definitions coincide? So why does the integral over the surface area now? The thing is that I am completely new to differential forms and maybe it is more or less the definition, but my problem is that I don't know how it follows now. If anything is unclear, please let me know.","\mathbb{R}^3. n \omega( \xi,\eta ) = \det(n,\xi,\eta). \int_{A} \omega","['real-analysis', 'integration', 'differential-geometry', 'manifolds', 'area']"
13,Exterior derivarive dependent only on point,Exterior derivarive dependent only on point,,"For any one-form (a linear form on the tangent space of each point) we have its exterior derivative $d\omega$ which is a two-form defined by $d\omega(X,Y)=D_X(\omega(Y))-D_Y(\omega(X))-\omega([X,Y])$ I'm trying to show that the value of $dw(X,Y)$ at a point $p$ is depndent only on the values of the vetcor fields $X,Y$ at that point. I've just started diving into this subject, and I really don't have a good direction. I tried to think of all the tools I have so I thought of decomposing $X,Y$ to some orthonoraml base, or maybe even decompose $\omega$ by $\sum_i\omega(X_i)\omega^i$ where $\omega^i$ is the linear form associated with $X_i$ i.e for any $i,j$: $\omega^i(X_j)=\delta_{ij}$ I will be very glad for some help! In addition, any general insight on this new definition of exterior derivative can be helpful. For now it seems quite peculiar. Thanks!","For any one-form (a linear form on the tangent space of each point) we have its exterior derivative $d\omega$ which is a two-form defined by $d\omega(X,Y)=D_X(\omega(Y))-D_Y(\omega(X))-\omega([X,Y])$ I'm trying to show that the value of $dw(X,Y)$ at a point $p$ is depndent only on the values of the vetcor fields $X,Y$ at that point. I've just started diving into this subject, and I really don't have a good direction. I tried to think of all the tools I have so I thought of decomposing $X,Y$ to some orthonoraml base, or maybe even decompose $\omega$ by $\sum_i\omega(X_i)\omega^i$ where $\omega^i$ is the linear form associated with $X_i$ i.e for any $i,j$: $\omega^i(X_j)=\delta_{ij}$ I will be very glad for some help! In addition, any general insight on this new definition of exterior derivative can be helpful. For now it seems quite peculiar. Thanks!",,"['differential-geometry', 'differential-forms']"
14,Left and right action?!,Left and right action?!,,"The adjoint of the adjoint representation $Ad^* : G \times \mathfrak{g}^* \rightarrow \mathfrak{g}^*, (g,x) \mapsto Ad^*_{g}(x)$ is a group action on the dual space of the Lie algebra. Now, we said that due to $Ad_{g_1g_2}(x)=Ad_{g_1}Ad_{g_2}(x)$ we see by conjugating this equation that the above written group action is actually a right-action. The thing is that our teacher told us now that $Ad^*:G \times \mathfrak{g}^* \rightarrow \mathfrak{g}^*,(g,x) \mapsto Ad^*_{g^{-1}}(x)$ is a left-action. Unfortunately, I don't see why this is the case. Could anybody here try to explain why we have now a left-action?","The adjoint of the adjoint representation $Ad^* : G \times \mathfrak{g}^* \rightarrow \mathfrak{g}^*, (g,x) \mapsto Ad^*_{g}(x)$ is a group action on the dual space of the Lie algebra. Now, we said that due to $Ad_{g_1g_2}(x)=Ad_{g_1}Ad_{g_2}(x)$ we see by conjugating this equation that the above written group action is actually a right-action. The thing is that our teacher told us now that $Ad^*:G \times \mathfrak{g}^* \rightarrow \mathfrak{g}^*,(g,x) \mapsto Ad^*_{g^{-1}}(x)$ is a left-action. Unfortunately, I don't see why this is the case. Could anybody here try to explain why we have now a left-action?",,"['group-theory', 'differential-geometry', 'algebraic-topology', 'lie-groups', 'lie-algebras']"
15,Question about Lie bracket and cross product,Question about Lie bracket and cross product,,"Let $\chi(\mathbb{R^3})$ denote the vector space of all smooth vector fields on $\mathbb{R^3}$, and let $A$ be the subspace of $\chi(\mathbb{R^3})$ spanned by $\{X,Y,Z \}$ where \begin{align*} X &= y {\partial \over \partial z}-z {\partial \over \partial y},\\ Y &= z {\partial \over \partial x}-x {\partial \over \partial z},\\ Z &= x {\partial \over \partial y}-y {\partial \over \partial x}. \end{align*} The question first ask me to compute the Lie brackets $[X,Y]$,$[Y,Z]$ and $[Z,X]$. Which I did and they are, \begin{align*} [X,Y] &= y {\partial \over \partial x}-x {\partial \over \partial y},\\ [Y,Z] &= z {\partial \over \partial y}-y {\partial \over \partial z},\\ [Z,X] &= x {\partial \over \partial z}-z {\partial \over \partial x}. \end{align*} Then how can I deduce that there is an isomorphism from $\mathbb{R^3}$ to $A$ so that the cross product in $\mathbb{R^3}$ corresponds to the Lie bracket of vector fields.","Let $\chi(\mathbb{R^3})$ denote the vector space of all smooth vector fields on $\mathbb{R^3}$, and let $A$ be the subspace of $\chi(\mathbb{R^3})$ spanned by $\{X,Y,Z \}$ where \begin{align*} X &= y {\partial \over \partial z}-z {\partial \over \partial y},\\ Y &= z {\partial \over \partial x}-x {\partial \over \partial z},\\ Z &= x {\partial \over \partial y}-y {\partial \over \partial x}. \end{align*} The question first ask me to compute the Lie brackets $[X,Y]$,$[Y,Z]$ and $[Z,X]$. Which I did and they are, \begin{align*} [X,Y] &= y {\partial \over \partial x}-x {\partial \over \partial y},\\ [Y,Z] &= z {\partial \over \partial y}-y {\partial \over \partial z},\\ [Z,X] &= x {\partial \over \partial z}-z {\partial \over \partial x}. \end{align*} Then how can I deduce that there is an isomorphism from $\mathbb{R^3}$ to $A$ so that the cross product in $\mathbb{R^3}$ corresponds to the Lie bracket of vector fields.",,"['differential-geometry', 'cross-product']"
16,Hodge star of second-rank antisymmetric tensor,Hodge star of second-rank antisymmetric tensor,,"Say we have a tensor $F$ which just for familiarity's sake, we take to be a second rank antisymmetric tensor. I understand that given the Hodge star operator defined as  $$^*F_{\alpha\beta}=\tfrac{1}{2}\varepsilon_{\alpha\beta\mu\nu}F^{\mu\nu},$$ applying it twice gives $^{**}F=-F.$ I'm not yet familiar enough with this notation to see intuitively why this should be true. Is there a quick way to understand and see how we can get this result? At a guess, I feel like this should perform a kind of ""swapping"" action thanks to the Levi-Civita tensor, because $^*F_{\alpha\beta}$ can only be nonzero when $\mu$ and $\nu$ do not repeat either $\alpha$ or $\beta,$ so we should have something like $^*F_{\alpha\beta}=F^{\mu\nu}.$ Then if $\varepsilon^{\alpha\beta\mu\nu}=-\varepsilon_{\alpha\beta\mu\nu},$ we might get $$^{**}F^{\alpha\beta}=\tfrac{1}{2}\varepsilon^{\alpha\beta\mu\nu}F^{\mu\nu}=-\tfrac{1}{2}\varepsilon_{\alpha\beta\mu\nu}F^{\mu\nu}=-F^{\mu\nu}.$$ Is it fine to then relabel $F^{\mu\nu}$ as $F^{\alpha\beta}$ and then conclude the result? I have a feeling this is a question with a very obvious answer, but I have not yet adjusted to this machinery. Thanks for any help.","Say we have a tensor $F$ which just for familiarity's sake, we take to be a second rank antisymmetric tensor. I understand that given the Hodge star operator defined as  $$^*F_{\alpha\beta}=\tfrac{1}{2}\varepsilon_{\alpha\beta\mu\nu}F^{\mu\nu},$$ applying it twice gives $^{**}F=-F.$ I'm not yet familiar enough with this notation to see intuitively why this should be true. Is there a quick way to understand and see how we can get this result? At a guess, I feel like this should perform a kind of ""swapping"" action thanks to the Levi-Civita tensor, because $^*F_{\alpha\beta}$ can only be nonzero when $\mu$ and $\nu$ do not repeat either $\alpha$ or $\beta,$ so we should have something like $^*F_{\alpha\beta}=F^{\mu\nu}.$ Then if $\varepsilon^{\alpha\beta\mu\nu}=-\varepsilon_{\alpha\beta\mu\nu},$ we might get $$^{**}F^{\alpha\beta}=\tfrac{1}{2}\varepsilon^{\alpha\beta\mu\nu}F^{\mu\nu}=-\tfrac{1}{2}\varepsilon_{\alpha\beta\mu\nu}F^{\mu\nu}=-F^{\mu\nu}.$$ Is it fine to then relabel $F^{\mu\nu}$ as $F^{\alpha\beta}$ and then conclude the result? I have a feeling this is a question with a very obvious answer, but I have not yet adjusted to this machinery. Thanks for any help.",,"['differential-geometry', 'tensors']"
17,Is every open cover of a smooth manifold finer than a cover built from the union of disjoint open sets?,Is every open cover of a smooth manifold finer than a cover built from the union of disjoint open sets?,,"Let $M$ be a finite dimensional smooth manifold and $M=\bigcup_{i\in I}U_i$ an open cover of $M$. Does there exist a finite open cover $M=\bigcup_{k=0}^l V_k$, such that each $V_k$ is the disjoint union of open subsets $V_k=\bigcup_{j\in J}V_{k,j}$ and each $V_{k,j}$ lies in one $U_i$? I tried to attack this problem with the help of a triangulation, such that all simplices lie in one $U_i$, but was not succesful.","Let $M$ be a finite dimensional smooth manifold and $M=\bigcup_{i\in I}U_i$ an open cover of $M$. Does there exist a finite open cover $M=\bigcup_{k=0}^l V_k$, such that each $V_k$ is the disjoint union of open subsets $V_k=\bigcup_{j\in J}V_{k,j}$ and each $V_{k,j}$ lies in one $U_i$? I tried to attack this problem with the help of a triangulation, such that all simplices lie in one $U_i$, but was not succesful.",,"['general-topology', 'differential-geometry', 'geometric-topology']"
18,"Find an atlas for $M=\{(x,y,z)\in\mathbb{R}^3:x^2+y^2=1+z^2\}$",Find an atlas for,"M=\{(x,y,z)\in\mathbb{R}^3:x^2+y^2=1+z^2\}","Find an atlas for $M=\{(x,y,z)\in\mathbb{R}^3:x^2+y^2=1+z^2\}$ It is easy for me to check that $M$ is a submanifold of $\mathbb{R}^3$ of dimension $2$ using the following theorem: Let $F:U \rightarrow \mathbb{R}^m$ be a $C^\infty$ function on an open set $U \subseteq \mathbb{R}^{n+m}$ and let $c \in \mathbb{R}^m$. Assume that for each $a \in F^{-1}(c)$, the derivative $DF_a:\mathbb{R}^{n+m} \rightarrow \mathbb{R}^m$ is surjective. Then, $F^{-1}(c)$ has the structure of an $n$-dimensional manifold which is Hausdorff and has a countable basis of open sets. I know also that the proof of this Theorem is to find an atlas, but in practise I have problems with construction that atlas. Let $F:\mathbb{R}^3 \rightarrow \mathbb{R}$ s.t. $F(x,y,z)=x^2+y^2-z^2-1$. We have $DF_a=[2a_1 \quad 2a_2 \quad 2a_3]$, where $a=(a_1,a_2,a_3)$. Since $(0,0,0) \not \in M$, $DF_a$ has rank $1$, ie, $DF_a$ is surjective. Then $M=F^{-1}(0)$ is a submanifold of $\mathbb{R}^3$ os dimension $3-1=2$. Now comes the part I don't understand. We construct $G:U \rightarrow \mathbb{R}^3$ s.t. $G(x,y,z)=(x^2+y^2-z^2-1,y,z)$. Then, $$DG_a=\begin{bmatrix}        2a_1 & 2a_2 & -2a_3 \\[0.3em]        0 & 1 & 0 \\[0.3em]        0 & 0 & 1      \end{bmatrix}.$$ So the atlas is $\{(U_i,\varphi_i)\}_{1 \leq i \leq 3}$ where $U_i=\{(x,y,z) \in \mathbb{R}^3:x_i \neq 0\}$. But what is explicitly $\varphi_i:U_i \rightarrow \varphi(U_i)$? Some help here would be appreciated.","Find an atlas for $M=\{(x,y,z)\in\mathbb{R}^3:x^2+y^2=1+z^2\}$ It is easy for me to check that $M$ is a submanifold of $\mathbb{R}^3$ of dimension $2$ using the following theorem: Let $F:U \rightarrow \mathbb{R}^m$ be a $C^\infty$ function on an open set $U \subseteq \mathbb{R}^{n+m}$ and let $c \in \mathbb{R}^m$. Assume that for each $a \in F^{-1}(c)$, the derivative $DF_a:\mathbb{R}^{n+m} \rightarrow \mathbb{R}^m$ is surjective. Then, $F^{-1}(c)$ has the structure of an $n$-dimensional manifold which is Hausdorff and has a countable basis of open sets. I know also that the proof of this Theorem is to find an atlas, but in practise I have problems with construction that atlas. Let $F:\mathbb{R}^3 \rightarrow \mathbb{R}$ s.t. $F(x,y,z)=x^2+y^2-z^2-1$. We have $DF_a=[2a_1 \quad 2a_2 \quad 2a_3]$, where $a=(a_1,a_2,a_3)$. Since $(0,0,0) \not \in M$, $DF_a$ has rank $1$, ie, $DF_a$ is surjective. Then $M=F^{-1}(0)$ is a submanifold of $\mathbb{R}^3$ os dimension $3-1=2$. Now comes the part I don't understand. We construct $G:U \rightarrow \mathbb{R}^3$ s.t. $G(x,y,z)=(x^2+y^2-z^2-1,y,z)$. Then, $$DG_a=\begin{bmatrix}        2a_1 & 2a_2 & -2a_3 \\[0.3em]        0 & 1 & 0 \\[0.3em]        0 & 0 & 1      \end{bmatrix}.$$ So the atlas is $\{(U_i,\varphi_i)\}_{1 \leq i \leq 3}$ where $U_i=\{(x,y,z) \in \mathbb{R}^3:x_i \neq 0\}$. But what is explicitly $\varphi_i:U_i \rightarrow \varphi(U_i)$? Some help here would be appreciated.",,"['differential-geometry', 'manifolds']"
19,"Understanding proof that $[X_e,Y_e]\in T_e G$ generates the right-invariant vector field $[X,Y]$ on $G$",Understanding proof that  generates the right-invariant vector field  on,"[X_e,Y_e]\in T_e G [X,Y] G","Let $X_e,Y_e \in T_eG$ be vectors and $G = GL(n).$ Then the right translation is given by $Y_g = Y_e g$ and $X_g = X_e g.$ Now, I have a proof showing that $[X_e,Y_e] \in T_eG$ is the element generating the right- invariant vector field $[X,Y]$ on $G.$ Now, the proof starts with $$([X,Y]_g)_{i,j}) = \sum_{k,l=1}^{N} \left((Y_g)_{k,l} \frac{\partial (X_g)_{i,j}}{\partial g_{k,l}}- (X_g)_{k,l}  \frac{\partial (Y_g)_{i,j}}{\partial g_{k,l}} \right),$$ but I don't understand where the derivatives come from in this expression. Can anybody explain this equality to me?","Let $X_e,Y_e \in T_eG$ be vectors and $G = GL(n).$ Then the right translation is given by $Y_g = Y_e g$ and $X_g = X_e g.$ Now, I have a proof showing that $[X_e,Y_e] \in T_eG$ is the element generating the right- invariant vector field $[X,Y]$ on $G.$ Now, the proof starts with $$([X,Y]_g)_{i,j}) = \sum_{k,l=1}^{N} \left((Y_g)_{k,l} \frac{\partial (X_g)_{i,j}}{\partial g_{k,l}}- (X_g)_{k,l}  \frac{\partial (Y_g)_{i,j}}{\partial g_{k,l}} \right),$$ but I don't understand where the derivatives come from in this expression. Can anybody explain this equality to me?",,"['general-topology', 'differential-geometry', 'differential-topology', 'lie-groups', 'lie-algebras']"
20,How to show the following vector bundles are equivalent?,How to show the following vector bundles are equivalent?,,"Given a smooth sub-manifold $X$ of $\mathbb{R^n}$ and define the diagonal in $X \times X$ to be $$\triangle = \{(x,x) \mid x \in X \} \subset \mathbb{R^n}\times \mathbb{R^n}$$ and normal bundle to $\triangle$ is defined to be $$N(\triangle)=\{(y,w) \mid y\in \triangle, w\in T_y(X\times X) \text{ such that } w \cdot v =0 \text{ for all } v \in T_y(\triangle)\}$$ with projection $\pi : N(\triangle) \to \triangle$ given by $(y,w)\mapsto y$ Then we want to show that $N(\triangle)$ is equivalent to the tangent bundle $TX$. I know (by definition of equivalent) that two vector bundles said to be equivalent if there are diffeomorphisms $$f:TX \to N(\triangle) \text{ and }\tilde{f}:X \to \triangle$$ such that $f$ takes each fibre $TX_x$ to $N(\triangle)_{\tilde{f}(x)}$ by a vector space isomorphism. What do I really need to do? Should I try to write down $f$ and $\tilde{f}$ and show that $f$ is an isomorphism on fibres? Any help would be thankful.","Given a smooth sub-manifold $X$ of $\mathbb{R^n}$ and define the diagonal in $X \times X$ to be $$\triangle = \{(x,x) \mid x \in X \} \subset \mathbb{R^n}\times \mathbb{R^n}$$ and normal bundle to $\triangle$ is defined to be $$N(\triangle)=\{(y,w) \mid y\in \triangle, w\in T_y(X\times X) \text{ such that } w \cdot v =0 \text{ for all } v \in T_y(\triangle)\}$$ with projection $\pi : N(\triangle) \to \triangle$ given by $(y,w)\mapsto y$ Then we want to show that $N(\triangle)$ is equivalent to the tangent bundle $TX$. I know (by definition of equivalent) that two vector bundles said to be equivalent if there are diffeomorphisms $$f:TX \to N(\triangle) \text{ and }\tilde{f}:X \to \triangle$$ such that $f$ takes each fibre $TX_x$ to $N(\triangle)_{\tilde{f}(x)}$ by a vector space isomorphism. What do I really need to do? Should I try to write down $f$ and $\tilde{f}$ and show that $f$ is an isomorphism on fibres? Any help would be thankful.",,['differential-geometry']
21,"Explaining problem in Gadea's ""Analysis and Algebra on Differentiable Manifolds""","Explaining problem in Gadea's ""Analysis and Algebra on Differentiable Manifolds""",,"I have a lot of trouble trying to explain to myself what the author did in problem 1.102 (the answer is in the link): Let $TM$ be the tangent bundle over a differentiable manifold $M$. Let $\varphi: \mathbb R\times TM \to TM$ defined by $\varphi(t, X)=e^tX$. (i) Prove that $\varphi$ is a $1$-parameter group of transformations of $TM$. (ii) Calculate the vector field $Y$ on $TM$ associated to $\varphi$. (iii) Prove that $Y$ is invariant under $\varphi$. I'm interested in the first point since maybe the rest continues from in. The definition of $1$-parameter group (or flow) is given for maps that go from $M\times \mathbb R$ to $M$, where $M$ is a smooth manifold. Althought we know that the tangent bundle $TM$ gives a manifold structure to tangent vectors, applying straight the definition of flow doesn't seem like the way  the author took. $(1)$ I don't uderstand why does he prove that $\varphi_t \circ \varphi_s=\varphi_{t+s}$, I saw that he used that too in the problem before. $(2)$ Later when he is defining the chart in $TM$, I don't quite get the definition of $\Psi$. I thought the charts in $TM$ where given like this: if you take a chart of $M$, say $(U,\phi)$ then it induces the chart of the tangent bundle  like $(\pi^{-1}(U),\tilde \phi)$, with $\tilde\phi(X_p)=(\phi(p),\omega)$ and $\omega\in T_pM$. I don't know if my diagram is correct, but that's what I understand, and I don't see how did he got the so called $\Psi$ and $\tau$.","I have a lot of trouble trying to explain to myself what the author did in problem 1.102 (the answer is in the link): Let $TM$ be the tangent bundle over a differentiable manifold $M$. Let $\varphi: \mathbb R\times TM \to TM$ defined by $\varphi(t, X)=e^tX$. (i) Prove that $\varphi$ is a $1$-parameter group of transformations of $TM$. (ii) Calculate the vector field $Y$ on $TM$ associated to $\varphi$. (iii) Prove that $Y$ is invariant under $\varphi$. I'm interested in the first point since maybe the rest continues from in. The definition of $1$-parameter group (or flow) is given for maps that go from $M\times \mathbb R$ to $M$, where $M$ is a smooth manifold. Althought we know that the tangent bundle $TM$ gives a manifold structure to tangent vectors, applying straight the definition of flow doesn't seem like the way  the author took. $(1)$ I don't uderstand why does he prove that $\varphi_t \circ \varphi_s=\varphi_{t+s}$, I saw that he used that too in the problem before. $(2)$ Later when he is defining the chart in $TM$, I don't quite get the definition of $\Psi$. I thought the charts in $TM$ where given like this: if you take a chart of $M$, say $(U,\phi)$ then it induces the chart of the tangent bundle  like $(\pi^{-1}(U),\tilde \phi)$, with $\tilde\phi(X_p)=(\phi(p),\omega)$ and $\omega\in T_pM$. I don't know if my diagram is correct, but that's what I understand, and I don't see how did he got the so called $\Psi$ and $\tau$.",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
22,Unknown functions yield a given determinant,Unknown functions yield a given determinant,,"I am trying to develop a nomogram which simultaneously shows the exact Fisher equation $(1+u) = (1+v)(1+w)$ and its linear approximation $u \approx v + w$. This amounts to finding twelve smooth curves such that the following equations hold: $$\det \begin{bmatrix}f_1(u) & f_2(u) & f_3(u) \\ g_1(v)& g_2(v) & g_3(v) \\ h_1(w) & h_2(w) & h_3(w)\end{bmatrix} = (1+v)(1+w) - (1+u)$$ $$\det \begin{bmatrix}f_4(u) & f_5(u) & f_6(u) \\ g_1(v)& g_2(v) & g_3(v) \\ h_1(w) & h_2(w) & h_3(w)\end{bmatrix} = v + w - u$$ My question is how to begin thinking about this problem --- how can you decide whether such curves exist, and how might you look for them?","I am trying to develop a nomogram which simultaneously shows the exact Fisher equation $(1+u) = (1+v)(1+w)$ and its linear approximation $u \approx v + w$. This amounts to finding twelve smooth curves such that the following equations hold: $$\det \begin{bmatrix}f_1(u) & f_2(u) & f_3(u) \\ g_1(v)& g_2(v) & g_3(v) \\ h_1(w) & h_2(w) & h_3(w)\end{bmatrix} = (1+v)(1+w) - (1+u)$$ $$\det \begin{bmatrix}f_4(u) & f_5(u) & f_6(u) \\ g_1(v)& g_2(v) & g_3(v) \\ h_1(w) & h_2(w) & h_3(w)\end{bmatrix} = v + w - u$$ My question is how to begin thinking about this problem --- how can you decide whether such curves exist, and how might you look for them?",,"['linear-algebra', 'differential-geometry', 'determinant', 'economics', 'nomography']"
23,Vector space operations on fibres of associated bundles.,Vector space operations on fibres of associated bundles.,,"Let $\pi:P\rightarrow M$ be a principal bundle with structure group $G$. Let $\mathfrak{g}$ be the Lie algebra of $G$ and $\text{ad}:G\rightarrow GL(\mathfrak{g})$ be the adjoint representation. Let $\text{ad}P:=P\times_{\text{ad}} \mathfrak{g}$ be the adjoint bundle. I am seeking a bit of clarification on the sections of $\text{ad}P$. Let $\sigma\in \Gamma(\text{ad}P)$. Since $\sigma$ is a map $M\rightarrow \text{ad}P$, it follows that $\sigma(m)\in \text{ad}P$ and so $\sigma(m)=[(p,v)]$ for some $p\in P$ and $v\in \mathfrak{g}$. (Here $[,]$ denotes the equivalence class defined by the right action of $G$). However, since $\sigma$ is a section of the vector bundle $\pi_{\mathfrak{g}}:\text{ad}P\rightarrow M$, it follows that $\sigma(m)\in \pi_{\mathfrak{g}}^{-1}(m)$. The space $\pi_{\mathfrak{g}}^{-1}(m)$ has the structure of a vector space. Thus, $[(p,v)]$ is an element of a vector space. Question 1: is it true to say that \begin{align*} \pi_{\mathfrak{g}}^{-1}(m)=\{[(p,v)]:\pi(p)=m,v\in \mathfrak{g}\} \end{align*} Question 2: how are the vector space operations defined? Here is what I think is a natural way but I have no idea if I'm correct. If $p,q\in\pi^{-1}(m)$, and $v,w\in \mathfrak{g}$, then how do we define $[(p,v)]+[(q,w)]$ ? Is it by noting that since $p$ and $g$ lie in the same fibre over $m$, then $q=pg$ for some $g\in G$, and thus \begin{align*} [(q,w)]=[(pg,w)]=[(p,\text{ad}_g w)g]=[(p,\text{ad}_g w)]. \end{align*} And so, \begin{align*} [(p,v)]+[(q,w)]=[(p,v+\text{ad}_g w)] \end{align*} for $g\in G$ such that $q=pg$?","Let $\pi:P\rightarrow M$ be a principal bundle with structure group $G$. Let $\mathfrak{g}$ be the Lie algebra of $G$ and $\text{ad}:G\rightarrow GL(\mathfrak{g})$ be the adjoint representation. Let $\text{ad}P:=P\times_{\text{ad}} \mathfrak{g}$ be the adjoint bundle. I am seeking a bit of clarification on the sections of $\text{ad}P$. Let $\sigma\in \Gamma(\text{ad}P)$. Since $\sigma$ is a map $M\rightarrow \text{ad}P$, it follows that $\sigma(m)\in \text{ad}P$ and so $\sigma(m)=[(p,v)]$ for some $p\in P$ and $v\in \mathfrak{g}$. (Here $[,]$ denotes the equivalence class defined by the right action of $G$). However, since $\sigma$ is a section of the vector bundle $\pi_{\mathfrak{g}}:\text{ad}P\rightarrow M$, it follows that $\sigma(m)\in \pi_{\mathfrak{g}}^{-1}(m)$. The space $\pi_{\mathfrak{g}}^{-1}(m)$ has the structure of a vector space. Thus, $[(p,v)]$ is an element of a vector space. Question 1: is it true to say that \begin{align*} \pi_{\mathfrak{g}}^{-1}(m)=\{[(p,v)]:\pi(p)=m,v\in \mathfrak{g}\} \end{align*} Question 2: how are the vector space operations defined? Here is what I think is a natural way but I have no idea if I'm correct. If $p,q\in\pi^{-1}(m)$, and $v,w\in \mathfrak{g}$, then how do we define $[(p,v)]+[(q,w)]$ ? Is it by noting that since $p$ and $g$ lie in the same fibre over $m$, then $q=pg$ for some $g\in G$, and thus \begin{align*} [(q,w)]=[(pg,w)]=[(p,\text{ad}_g w)g]=[(p,\text{ad}_g w)]. \end{align*} And so, \begin{align*} [(p,v)]+[(q,w)]=[(p,v+\text{ad}_g w)] \end{align*} for $g\in G$ such that $q=pg$?",,"['differential-geometry', 'manifolds', 'lie-groups', 'vector-bundles']"
24,Show this is not a manifold with boundary,Show this is not a manifold with boundary,,"Consider a curve $\alpha: \mathbb R \to \mathbb R^2$ defined by $t \mapsto (e^t \cos(t), e^t \sin(t))$. Show the closure of $\alpha(\mathbb R )$ is not a manifold with boundary. Denote $\alpha(\mathbb R )$ by M. The closure of M is the spiral plus the limit point, the origin. I want to show there is no boundary coordinate chart for the origin. Intuitively,for every open neighbourhood $B$ of $(0,0)$, for every given direction $(a,b)$, there is a point $(x,y)$ in $\overline M  \cap B$ s.t. $(x,y)= \lambda (a,b)$. Then $\overline M  \cap B$ is not the graph of a smooth function $g$ because if $g'(0)=b/a$, then there are points in $\overline M  \cap B$ that are not in that direction. But how can I write this rigourously?","Consider a curve $\alpha: \mathbb R \to \mathbb R^2$ defined by $t \mapsto (e^t \cos(t), e^t \sin(t))$. Show the closure of $\alpha(\mathbb R )$ is not a manifold with boundary. Denote $\alpha(\mathbb R )$ by M. The closure of M is the spiral plus the limit point, the origin. I want to show there is no boundary coordinate chart for the origin. Intuitively,for every open neighbourhood $B$ of $(0,0)$, for every given direction $(a,b)$, there is a point $(x,y)$ in $\overline M  \cap B$ s.t. $(x,y)= \lambda (a,b)$. Then $\overline M  \cap B$ is not the graph of a smooth function $g$ because if $g'(0)=b/a$, then there are points in $\overline M  \cap B$ that are not in that direction. But how can I write this rigourously?",,"['differential-geometry', 'manifolds']"
25,Constant torsion-expression of unit speed curves,Constant torsion-expression of unit speed curves,,I am currently studying for an exam in differential geometry. There's a problem which I am not able to solve and do not even know where to start (although I think it has to do with the Frenet equations) :Let $\alpha(s)$ be a curve parametrised by arc length of non zero constant torsion $\frac{1}{a}$. Show that there exists a (vector valued) function $f$ satisfying : $\alpha(s) = a \int (f(s) \times f'(s)) ds$ $\vert f(s) \vert =1$ and $(f(s) \times f'(s)) \cdot f''(s) \not =0$ Any help/hints?,I am currently studying for an exam in differential geometry. There's a problem which I am not able to solve and do not even know where to start (although I think it has to do with the Frenet equations) :Let $\alpha(s)$ be a curve parametrised by arc length of non zero constant torsion $\frac{1}{a}$. Show that there exists a (vector valued) function $f$ satisfying : $\alpha(s) = a \int (f(s) \times f'(s)) ds$ $\vert f(s) \vert =1$ and $(f(s) \times f'(s)) \cdot f''(s) \not =0$ Any help/hints?,,['differential-geometry']
26,Showing $T$ equivalent to linear map,Showing  equivalent to linear map,T,"Let $T$ be a $(1,1)$ tensor over a vector space $V$.  Let $\left\{e_a\right\}$ be a basis for $V$ and $\left\{f^a\right \}$ be its dual basis.  Show that $T$ is equivalent to a linear map $V^* \rightarrow V^*$.  Similarly, show that $T$ is also equivalent to a linear map $V \rightarrow V$. Attempt: $T$ being a $(1,1)$ tensor means that it is a linear map $V^* \times V \rightarrow \mathbb{R}$ or explicitly, I think I can write $T : (\lambda, X) \mapsto \lambda_a X^aT^i_{\,\,j} \in \mathbb{R}$ where $T^i_{\,\,j}, \lambda_a$ and $X^a$ are coefficients of the tensor, co-vector and vector respectively in basis $\left\{f^a, e_a\right\}$ . Now the book goes onto write the following: Given a $(1, 1)$ tensor $T$ and $\lambda \in V^*$, we can form the $(0, 1)$ tensor $T(\lambda, \cdot)$, i.e. $T(\lambda, \cdot) \in V^*$.  Thus $T$ defines a linear map $V^* \rightarrow V^*$, $λ \mapsto T(\lambda, \cdot).$  I don't really understand this paragraph. How can such a tensor be formed? It looks like some sort of contraction, however contraction of a $(1,1)$ tensor would only produce $(0,0)$ tensor as far as I understand. (Contraction of $T^i_{\,\,j} \rightarrow T^i_{\,\,i}$). Similarly, why is $T(\lambda, \cdot)$ even a $(0,1)$ tensor? As far as I understand, the notation $(0,1)$ means the map feeds on zero covector arguments and one vector argument which is not what $T(\lambda, \cdot)$ suggests given that $\lambda \in V^*$. Many thanks!","Let $T$ be a $(1,1)$ tensor over a vector space $V$.  Let $\left\{e_a\right\}$ be a basis for $V$ and $\left\{f^a\right \}$ be its dual basis.  Show that $T$ is equivalent to a linear map $V^* \rightarrow V^*$.  Similarly, show that $T$ is also equivalent to a linear map $V \rightarrow V$. Attempt: $T$ being a $(1,1)$ tensor means that it is a linear map $V^* \times V \rightarrow \mathbb{R}$ or explicitly, I think I can write $T : (\lambda, X) \mapsto \lambda_a X^aT^i_{\,\,j} \in \mathbb{R}$ where $T^i_{\,\,j}, \lambda_a$ and $X^a$ are coefficients of the tensor, co-vector and vector respectively in basis $\left\{f^a, e_a\right\}$ . Now the book goes onto write the following: Given a $(1, 1)$ tensor $T$ and $\lambda \in V^*$, we can form the $(0, 1)$ tensor $T(\lambda, \cdot)$, i.e. $T(\lambda, \cdot) \in V^*$.  Thus $T$ defines a linear map $V^* \rightarrow V^*$, $λ \mapsto T(\lambda, \cdot).$  I don't really understand this paragraph. How can such a tensor be formed? It looks like some sort of contraction, however contraction of a $(1,1)$ tensor would only produce $(0,0)$ tensor as far as I understand. (Contraction of $T^i_{\,\,j} \rightarrow T^i_{\,\,i}$). Similarly, why is $T(\lambda, \cdot)$ even a $(0,1)$ tensor? As far as I understand, the notation $(0,1)$ means the map feeds on zero covector arguments and one vector argument which is not what $T(\lambda, \cdot)$ suggests given that $\lambda \in V^*$. Many thanks!",,"['linear-algebra', 'differential-geometry', 'vector-spaces', 'vectors', 'tensors']"
27,Do local flows of left-invariant vector fields satisfy $\Phi_X^t\circ L_x=L_x\circ \Phi_X^t$?,Do local flows of left-invariant vector fields satisfy ?,\Phi_X^t\circ L_x=L_x\circ \Phi_X^t,Given $G$ a lie group and $X$ a left-invariant vector field. Let $\Phi_X^t$ be the local flow of $X$ . Why can we conclude that $\Phi_X^t \circ L_x=L_x \circ \Phi_X^t$ ? Thanks!,Given a lie group and a left-invariant vector field. Let be the local flow of . Why can we conclude that ? Thanks!,G X \Phi_X^t X \Phi_X^t \circ L_x=L_x \circ \Phi_X^t,"['differential-geometry', 'lie-groups', 'smooth-manifolds', 'vector-fields']"
28,Understanding an exercise about gradients and vector fields,Understanding an exercise about gradients and vector fields,,"In John M. Lee's Introduction to Smooth Manifolds, exercise 11.17 goes as follows: Let $f(x,y)=x^2$ on $\mathbb R^2$, and let $X$ be the vector field $$X=\operatorname{grad} f=2x\frac\partial{\partial x}.$$ Compute the coordinate expression for $X$ in polar coordinates (on some open subset on which they are defined) and show that it is not equal to $$\frac{\partial f}{\partial r}\frac{\partial }{\partial r}+\frac{\partial f}{\partial \theta}\frac{\partial}{\partial\theta}.\tag{*}$$ I am not sure, what I am supposed to do here, but this is what I thought: Considering the change of coordinates $(x,y)=(r\cos\theta,r\sin\theta)$ we can compute the change of bases of tangent spaces: $$ \begin{align} \frac{\partial}{\partial r} &=\cos\theta\frac{\partial}{\partial x}+\sin\theta\frac{\partial}{\partial y}\\ \frac{\partial}{\partial\theta} &=-r\sin\theta\frac{\partial}{\partial x}+r\cos\theta\frac{\partial}{\partial y} \end{align} $$ and then since $f(r,\theta)=r^2\cos^2\theta$ we have $$ \begin{align} \frac{\partial f}{\partial r}&=2r\cos^2\theta\\ \frac{\partial f}{\partial\theta}&=-2r^2\cos\theta\sin\theta \end{align} $$ we see that the coefficient of $\dfrac{\partial}{\partial y}$ in $(*)$ becomes $$ 2r\cos^2\theta\sin\theta-2r^3\cos^2\theta\sin\theta\neq 0 $$ but to equal $X$, this coefficient should have been identical zero. I chose to use $(x,y)=(r\cos\theta,r\sin\theta)$ instead of $(r,\theta)=(\sqrt{x^2+y^2},\tan^{-1}(y/x))$ which is limited to $x>0$ and more heavy to work with. But I would like to know, if what I write here even makes sense, or if I am way off.","In John M. Lee's Introduction to Smooth Manifolds, exercise 11.17 goes as follows: Let $f(x,y)=x^2$ on $\mathbb R^2$, and let $X$ be the vector field $$X=\operatorname{grad} f=2x\frac\partial{\partial x}.$$ Compute the coordinate expression for $X$ in polar coordinates (on some open subset on which they are defined) and show that it is not equal to $$\frac{\partial f}{\partial r}\frac{\partial }{\partial r}+\frac{\partial f}{\partial \theta}\frac{\partial}{\partial\theta}.\tag{*}$$ I am not sure, what I am supposed to do here, but this is what I thought: Considering the change of coordinates $(x,y)=(r\cos\theta,r\sin\theta)$ we can compute the change of bases of tangent spaces: $$ \begin{align} \frac{\partial}{\partial r} &=\cos\theta\frac{\partial}{\partial x}+\sin\theta\frac{\partial}{\partial y}\\ \frac{\partial}{\partial\theta} &=-r\sin\theta\frac{\partial}{\partial x}+r\cos\theta\frac{\partial}{\partial y} \end{align} $$ and then since $f(r,\theta)=r^2\cos^2\theta$ we have $$ \begin{align} \frac{\partial f}{\partial r}&=2r\cos^2\theta\\ \frac{\partial f}{\partial\theta}&=-2r^2\cos\theta\sin\theta \end{align} $$ we see that the coefficient of $\dfrac{\partial}{\partial y}$ in $(*)$ becomes $$ 2r\cos^2\theta\sin\theta-2r^3\cos^2\theta\sin\theta\neq 0 $$ but to equal $X$, this coefficient should have been identical zero. I chose to use $(x,y)=(r\cos\theta,r\sin\theta)$ instead of $(r,\theta)=(\sqrt{x^2+y^2},\tan^{-1}(y/x))$ which is limited to $x>0$ and more heavy to work with. But I would like to know, if what I write here even makes sense, or if I am way off.",,"['differential-geometry', 'vector-fields']"
29,Is it possible to construct a non-closed plane curve from a closed space curve via the curvature of the latter one,Is it possible to construct a non-closed plane curve from a closed space curve via the curvature of the latter one,,"I'm really stuck on this problem. Let $\alpha:[a,b]\subset \mathbb{R}\to \mathbb{R}^3$ be a smooth arc-length parametrized curve and let $\kappa:[a,b]\to \mathbb{R}$ be its curvature. I know from the ""Fundamental theorem of the local theory of curves"" that, roughly speaking, associated to each smooth non-zero curvature function and smooth torsion function there is a unique regular parametrized curve, up to rigid motions. In particular, defining a smooth non-zero curvature function, there is a unique plane curve associated. Let $\beta:[a,b]\to\mathbb{R}^2$ be the plane curve endowed with the curvature $\kappa$ and suppose that $\alpha(I)$ is a closed curve. Is it possible that $\beta(I)$ be a non-closed curve? I tried to read a paper called ""A differential-geometric criterion for a space curve to be closed"", the author is Hwang Cheng-Chung. But I don't know how to apply it to my problem.","I'm really stuck on this problem. Let $\alpha:[a,b]\subset \mathbb{R}\to \mathbb{R}^3$ be a smooth arc-length parametrized curve and let $\kappa:[a,b]\to \mathbb{R}$ be its curvature. I know from the ""Fundamental theorem of the local theory of curves"" that, roughly speaking, associated to each smooth non-zero curvature function and smooth torsion function there is a unique regular parametrized curve, up to rigid motions. In particular, defining a smooth non-zero curvature function, there is a unique plane curve associated. Let $\beta:[a,b]\to\mathbb{R}^2$ be the plane curve endowed with the curvature $\kappa$ and suppose that $\alpha(I)$ is a closed curve. Is it possible that $\beta(I)$ be a non-closed curve? I tried to read a paper called ""A differential-geometric criterion for a space curve to be closed"", the author is Hwang Cheng-Chung. But I don't know how to apply it to my problem.",,['differential-geometry']
30,Normal of a coons patch at a given point,Normal of a coons patch at a given point,,"Disclamer: Rendering the Coons patch is part of 3D Graphics homework, but finding the normals at a given point isn't. Just curious. Here's what I got so far: It's a Coons patch defined by four Hermite curves. I render the Coons patch by making a mesh of triangles from points calculated on the Coons patch. The surface could look much smoother than it actually is if I could figure out how to get the normal of the patch at any given point, instead of using the normals of the flat triangles. Now I know that if I have two tangents of the surface at a given point, their cross product will give me what I look for. I also know that, for an Hermite curve in 2D space, finding the tangent means getting the derivative, which is easy if you see Hermite curve as a product of matrixes and the vector (1, t, t^2, t^3); just use this vector instead (0, 1, 2t 3t^2). The normal is just the perpendicular of the tangent then: But how do I translate that knowledge into finding the two tangents necessary for finding the normal of the Coons patch at a given point? My shaky programmer maths fail me. EDIT: Here's how I build my Coons patch. Taken at Wikipedia . The 4 curves are Hermites. Given four space curves c 0 (s), c 1 (s), d 0 (t), d 1 (t) which meet at four corners c 0 (0) = d 0 (0), c 0 (1) = d 1 (0), c 1 (0) = d 0 (1), c 1 (1) = d 1 (1); linear interpolation can be used to interpolate between c 0 and c 1 , that is $L_c(s,t)=(1-t) c_0(s)+ t c_1(s) $ and between d 0 , d 1 $L_d(s,t)=(1-s) d_0(t)+ s d_1(t) $ producing two ruled surfaces defined on the unit square. The bilinear interpolation on the four corner points is another surface $ B(s,t) = c_0(0) (1-s)(1-t) + c_0(1) s(1-t) +  c_1(0) (1-s)t + c_1(1) s t. $ A bilinearly blended Coons patch is the surface $L_c(s,t)+L_d(s,t)-B(s,t). $","Disclamer: Rendering the Coons patch is part of 3D Graphics homework, but finding the normals at a given point isn't. Just curious. Here's what I got so far: It's a Coons patch defined by four Hermite curves. I render the Coons patch by making a mesh of triangles from points calculated on the Coons patch. The surface could look much smoother than it actually is if I could figure out how to get the normal of the patch at any given point, instead of using the normals of the flat triangles. Now I know that if I have two tangents of the surface at a given point, their cross product will give me what I look for. I also know that, for an Hermite curve in 2D space, finding the tangent means getting the derivative, which is easy if you see Hermite curve as a product of matrixes and the vector (1, t, t^2, t^3); just use this vector instead (0, 1, 2t 3t^2). The normal is just the perpendicular of the tangent then: But how do I translate that knowledge into finding the two tangents necessary for finding the normal of the Coons patch at a given point? My shaky programmer maths fail me. EDIT: Here's how I build my Coons patch. Taken at Wikipedia . The 4 curves are Hermites. Given four space curves c 0 (s), c 1 (s), d 0 (t), d 1 (t) which meet at four corners c 0 (0) = d 0 (0), c 0 (1) = d 1 (0), c 1 (0) = d 0 (1), c 1 (1) = d 1 (1); linear interpolation can be used to interpolate between c 0 and c 1 , that is $L_c(s,t)=(1-t) c_0(s)+ t c_1(s) $ and between d 0 , d 1 $L_d(s,t)=(1-s) d_0(t)+ s d_1(t) $ producing two ruled surfaces defined on the unit square. The bilinear interpolation on the four corner points is another surface $ B(s,t) = c_0(0) (1-s)(1-t) + c_0(1) s(1-t) +  c_1(0) (1-s)t + c_1(1) s t. $ A bilinearly blended Coons patch is the surface $L_c(s,t)+L_d(s,t)-B(s,t). $",,"['differential-geometry', '3d', 'surfaces']"
31,Why don't we write $\nabla_{X}(fY) = f\nabla_{X}Y$ instead of $\nabla_{X}(fY) = f\nabla_{X}Y+ X(f)Y$ for affine connections?,Why don't we write  instead of  for affine connections?,\nabla_{X}(fY) = f\nabla_{X}Y \nabla_{X}(fY) = f\nabla_{X}Y+ X(f)Y,"According to do Carmo, in Riemannian Geometry pages 49-50, he says let $\mathcal{X}(M)$ denote the set of all vector fields of class $C^{\infty}$ on $M$. Let $\mathcal{D}(M)$ denote the ring of all real-valued functions of class $C^{\infty}$ defined on $M$. An affine connection $\nabla$ on differential manifold $M$ is a mapping $\nabla : \mathcal{X}(M) \times \mathcal{X}(M) \rightarrow \mathcal{X}(M)$ which is denoted by $(X,Y) \xrightarrow{\nabla} \nabla_{X}Y$ and which satisfies the following properties: $\nabla_{fX+gY}Z = f\nabla_{X} Z+ g\nabla_{Y}Z$ $\nabla_{X}(Y+Z) = \nabla_{X}Y + \nabla_{X}Z$ $\nabla_{X}(fY) = f\nabla_{X}Y+ X(f)Y$ in which $X,Y,Z \in \mathcal{X}(M)$ and $f,g \in \mathcal{D}(M)$. The first property simply is linear in the first argument $X$ right? In that case, $X$ happened to be defined as $fX + gY$ So why is the second argument different? By argument, I mean if I write the covariant derivative like $\nabla (X,Y)$, I can clearly see the linearity stated in property 1. Then property 2 looks like property 1 in this regard in that it satisfies the addition property. But the multiplication part is different. Instead of yielding just $\nabla_{X}(fY) = f\nabla_{X}Y$ it yields $\nabla_{X}(fY) = f\nabla_{X}Y+ X(f)Y$. My Question: Why don't we write  $\nabla_{X}(fY) = f\nabla_{X}Y$? Why do we specify the product rule? Why is this important for affine connections? Remark: Consider the first property. We have $\nabla_{fX}Z=f\nabla_X Z$. That doesn't involve the product rule, does it? So why do we need it when we are applying it $\nabla_{X}(fZ)$?","According to do Carmo, in Riemannian Geometry pages 49-50, he says let $\mathcal{X}(M)$ denote the set of all vector fields of class $C^{\infty}$ on $M$. Let $\mathcal{D}(M)$ denote the ring of all real-valued functions of class $C^{\infty}$ defined on $M$. An affine connection $\nabla$ on differential manifold $M$ is a mapping $\nabla : \mathcal{X}(M) \times \mathcal{X}(M) \rightarrow \mathcal{X}(M)$ which is denoted by $(X,Y) \xrightarrow{\nabla} \nabla_{X}Y$ and which satisfies the following properties: $\nabla_{fX+gY}Z = f\nabla_{X} Z+ g\nabla_{Y}Z$ $\nabla_{X}(Y+Z) = \nabla_{X}Y + \nabla_{X}Z$ $\nabla_{X}(fY) = f\nabla_{X}Y+ X(f)Y$ in which $X,Y,Z \in \mathcal{X}(M)$ and $f,g \in \mathcal{D}(M)$. The first property simply is linear in the first argument $X$ right? In that case, $X$ happened to be defined as $fX + gY$ So why is the second argument different? By argument, I mean if I write the covariant derivative like $\nabla (X,Y)$, I can clearly see the linearity stated in property 1. Then property 2 looks like property 1 in this regard in that it satisfies the addition property. But the multiplication part is different. Instead of yielding just $\nabla_{X}(fY) = f\nabla_{X}Y$ it yields $\nabla_{X}(fY) = f\nabla_{X}Y+ X(f)Y$. My Question: Why don't we write  $\nabla_{X}(fY) = f\nabla_{X}Y$? Why do we specify the product rule? Why is this important for affine connections? Remark: Consider the first property. We have $\nabla_{fX}Z=f\nabla_X Z$. That doesn't involve the product rule, does it? So why do we need it when we are applying it $\nabla_{X}(fZ)$?",,"['differential-geometry', 'riemannian-geometry']"
32,Canonical isomorphism from $I_p/I_p^2$ to cotangent space,Canonical isomorphism from  to cotangent space,I_p/I_p^2,"Sorry if the title is confusing, I don't know if the terminology is standard. For my homework this week I have to prove the following: Let $M$ be a smooth manifold and let $p \in M$. Let $I_p$ denote the set of smooth functions $f:M \to \mathbb{R}$ such that $f(p)=0$. Let $I_p^2$ denote the set of sums $\sum_{i=1}^k f_ig_i$ where $k$ is a nonnegative integer and $f_i,g_i \in I_p$. Show that the quotient vector space $I_p/I_p^2$ is canonically isomorphic to the cotangent space $T_p^*M$. I found the map $f \mapsto \phi_f$, where $\phi_f(v)=vf$ for $v \in T_pM$, and I've proved every part except injectivity. I've tried finding a basis for $I_p/I_p^2$ to show that it has the same dimension as $T_pM$, and I've tried showing that if $f=g \bmod I_p^2$ then there exist derivations taking $f$ and $g$ to different numbers, and I've tried showing that for any smooth function vanishing at $p$ and not in $I_p^2$ there is a derivation taking it to a nonzero number. I tried working in coordinates but that didn't seem to help. Does anyone have any hints? Thanks!","Sorry if the title is confusing, I don't know if the terminology is standard. For my homework this week I have to prove the following: Let $M$ be a smooth manifold and let $p \in M$. Let $I_p$ denote the set of smooth functions $f:M \to \mathbb{R}$ such that $f(p)=0$. Let $I_p^2$ denote the set of sums $\sum_{i=1}^k f_ig_i$ where $k$ is a nonnegative integer and $f_i,g_i \in I_p$. Show that the quotient vector space $I_p/I_p^2$ is canonically isomorphic to the cotangent space $T_p^*M$. I found the map $f \mapsto \phi_f$, where $\phi_f(v)=vf$ for $v \in T_pM$, and I've proved every part except injectivity. I've tried finding a basis for $I_p/I_p^2$ to show that it has the same dimension as $T_pM$, and I've tried showing that if $f=g \bmod I_p^2$ then there exist derivations taking $f$ and $g$ to different numbers, and I've tried showing that for any smooth function vanishing at $p$ and not in $I_p^2$ there is a derivation taking it to a nonzero number. I tried working in coordinates but that didn't seem to help. Does anyone have any hints? Thanks!",,"['differential-geometry', 'smooth-manifolds']"
33,Proving that on a Lie group $G$ the space of left-invariant vector fields is isomorphic to $T_e G$,Proving that on a Lie group  the space of left-invariant vector fields is isomorphic to,G T_e G,"Let $G$ be a Lie Group. Given a vector $v\in T_e G$, we define the left-invariant vector field $L^v$ on $G$ by $$L^v(g)=L^v|_g=(dL_g)_e v.$$ I want to show that $v\mapsto L^v$ is a linear isomorphism between $T_e G$ and $\mathfrak{X}^L(G)$ (The set of all left invariant vector fields on $G$). I am comfortable showing the map is linear and 1-1. To show surjectivity, let $X\in \mathfrak{X}^L(G)$ be arbitrary. We want to show there exists $v\in T_e G$ such that $L^v|_g = X|_g$ for all $g\in G$. Define the vector $v$ as $v:=(dL_{g^{-1}})_g X|_g$. Then, $\begin{align*} L^v|_g&=(dL_g)_e\left[(dL_{g^{-1}})_g X|_g\right]\\ \\ &=(dL_g)_e[X|_e]\\ \\ &=X|_g, \end{align*}$ where the last two lines are because $X$ is a left-invariant vector field. Is this argument sufficient?","Let $G$ be a Lie Group. Given a vector $v\in T_e G$, we define the left-invariant vector field $L^v$ on $G$ by $$L^v(g)=L^v|_g=(dL_g)_e v.$$ I want to show that $v\mapsto L^v$ is a linear isomorphism between $T_e G$ and $\mathfrak{X}^L(G)$ (The set of all left invariant vector fields on $G$). I am comfortable showing the map is linear and 1-1. To show surjectivity, let $X\in \mathfrak{X}^L(G)$ be arbitrary. We want to show there exists $v\in T_e G$ such that $L^v|_g = X|_g$ for all $g\in G$. Define the vector $v$ as $v:=(dL_{g^{-1}})_g X|_g$. Then, $\begin{align*} L^v|_g&=(dL_g)_e\left[(dL_{g^{-1}})_g X|_g\right]\\ \\ &=(dL_g)_e[X|_e]\\ \\ &=X|_g, \end{align*}$ where the last two lines are because $X$ is a left-invariant vector field. Is this argument sufficient?",,"['differential-geometry', 'lie-groups', 'smooth-manifolds', 'vector-fields']"
34,Flat vector bundles and constant transition functions,Flat vector bundles and constant transition functions,,"Let $E\to M$  be a vector bundle endowed with a flat connection. Then, does $E$ admit a bundle atlas with constant transition functions? For a vector bundle with constant transition functions, are the possible structure groups in correspondence with representations of the fundamental group of the base? Thanks.","Let $E\to M$  be a vector bundle endowed with a flat connection. Then, does $E$ admit a bundle atlas with constant transition functions? For a vector bundle with constant transition functions, are the possible structure groups in correspondence with representations of the fundamental group of the base? Thanks.",,"['algebraic-topology', 'differential-geometry']"
35,Centroid of manifold,Centroid of manifold,,"The centroid of a compact manifold is defined by the following equation: $c(Y_a)$ is the centroid of the parametrized manifold $Y_a$ is the point in $\Bbb R^n$ whose $i^{th}$ coordinate is given by the equation $$c_i(Y_a)=\frac{1}{v(Y_a)}\int_{Y_a}\pi_i$$ where $\pi_i:\Bbb R^n\to\Bbb R$ is the $i^{th}$ projection function. Show that if $M$ is symmetric with respect to the subspace $x_i=0,$ then $c_i(M)=0.$ I do not know to proceed from the given even. Can someone please help me with this? I am new to this manifold stuff Thanks in advance!","The centroid of a compact manifold is defined by the following equation: $c(Y_a)$ is the centroid of the parametrized manifold $Y_a$ is the point in $\Bbb R^n$ whose $i^{th}$ coordinate is given by the equation $$c_i(Y_a)=\frac{1}{v(Y_a)}\int_{Y_a}\pi_i$$ where $\pi_i:\Bbb R^n\to\Bbb R$ is the $i^{th}$ projection function. Show that if $M$ is symmetric with respect to the subspace $x_i=0,$ then $c_i(M)=0.$ I do not know to proceed from the given even. Can someone please help me with this? I am new to this manifold stuff Thanks in advance!",,"['real-analysis', 'differential-geometry', 'manifolds', 'smooth-manifolds']"
36,Question on tangent spaces,Question on tangent spaces,,"In this question, if I also had that $f$ were a diffeomorphism and $f^k = I$ for some positive integer $k$ would it make a difference to the answer being in the negative? Here, by $f^k$ I mean $f$ composed with itself $k$ time. Thanks!","In this question, if I also had that $f$ were a diffeomorphism and $f^k = I$ for some positive integer $k$ would it make a difference to the answer being in the negative? Here, by $f^k$ I mean $f$ composed with itself $k$ time. Thanks!",,"['differential-geometry', 'differential-topology', 'smooth-manifolds']"
37,Mapping degree of a diffeomorphism,Mapping degree of a diffeomorphism,,"This might be a bit silly question but I haven't find direct reference. Let $\Omega$ be open, bounded and connected in $\mathbb{R}^n$. Assume that $f:\overline{\Omega}\rightarrow \mathbb{R}^n$ is a diffeomorphism. Since $f:\overline{\Omega}\rightarrow f(\overline{\Omega})$ is a bijection, every $y=f(x)$ has only one solution in $\Omega$, i.e. $ \{ f^{-1}(y_1)\}=\{x_1\}$. Due to inverse function theorem $\det f'(x_1) \ne 0$, for all $x_1 \in \Omega$. Set $y\notin \partial \Omega$ and calculate the degree $$\deg( f,\Omega,y) = \sum_{x\in ^{-1}(y)} sign \det f'(x)= sign \det f'(x_1) =±1. $$ Can we find the mapping degree of a diffeomorphism in this simply way?","This might be a bit silly question but I haven't find direct reference. Let $\Omega$ be open, bounded and connected in $\mathbb{R}^n$. Assume that $f:\overline{\Omega}\rightarrow \mathbb{R}^n$ is a diffeomorphism. Since $f:\overline{\Omega}\rightarrow f(\overline{\Omega})$ is a bijection, every $y=f(x)$ has only one solution in $\Omega$, i.e. $ \{ f^{-1}(y_1)\}=\{x_1\}$. Due to inverse function theorem $\det f'(x_1) \ne 0$, for all $x_1 \in \Omega$. Set $y\notin \partial \Omega$ and calculate the degree $$\deg( f,\Omega,y) = \sum_{x\in ^{-1}(y)} sign \det f'(x)= sign \det f'(x_1) =±1. $$ Can we find the mapping degree of a diffeomorphism in this simply way?",,"['differential-geometry', 'differential-topology']"
38,Stereographic projection of a sphere,Stereographic projection of a sphere,,"What should have been a simple exercise in geometry has morphed into a multi-day affair with me figuratively tearing my hair out. I have no clue what's wrong. This image accompanies the problem: The problem is ""simply"" to show that $$r=\frac{\rho}{1+\frac{\rho^2}{4L^2}}$$ I can do the calculus and differential geometry that follows, but I cannot figure this out. I've even resorted to getting out a ruler and measuring the relevant quantities to check the answer. Taking this head-on has done nothing, so I tried to reverse engineer the solution. Calling the large hypotenuse $x$, we have $$\rho^2+4L^2=x^2$$  Inserting this in the answer, we have $$r=\frac{4L^2\rho}{x^2}$$ I think this is about all that I've been able to to productively. A huge thank you to anyone who helps in any capacity.","What should have been a simple exercise in geometry has morphed into a multi-day affair with me figuratively tearing my hair out. I have no clue what's wrong. This image accompanies the problem: The problem is ""simply"" to show that $$r=\frac{\rho}{1+\frac{\rho^2}{4L^2}}$$ I can do the calculus and differential geometry that follows, but I cannot figure this out. I've even resorted to getting out a ruler and measuring the relevant quantities to check the answer. Taking this head-on has done nothing, so I tried to reverse engineer the solution. Calling the large hypotenuse $x$, we have $$\rho^2+4L^2=x^2$$  Inserting this in the answer, we have $$r=\frac{4L^2\rho}{x^2}$$ I think this is about all that I've been able to to productively. A huge thank you to anyone who helps in any capacity.",,"['geometry', 'differential-geometry', 'projective-geometry', 'spherical-geometry']"
39,Find a parametrization of the intersection curve between two surfaces in $\mathbb{R^3}$ $x^2+y^2+z^2=1$ and $x^2+y^2=x$.,Find a parametrization of the intersection curve between two surfaces in   and .,\mathbb{R^3} x^2+y^2+z^2=1 x^2+y^2=x,"Find a parametrization of the intersection curve between two surfaces in $\mathbb{R}^3$ $$x^2+y^2+z^2=1$$ and $$x^2+y^2=x.$$ I know that $x^2+y^2+z^2=1$ is a sphere and that $x^2+y^2=x$ is a circular cylinder. Any help is greatly appreciated, thank you.","Find a parametrization of the intersection curve between two surfaces in $\mathbb{R}^3$ $$x^2+y^2+z^2=1$$ and $$x^2+y^2=x.$$ I know that $x^2+y^2+z^2=1$ is a sphere and that $x^2+y^2=x$ is a circular cylinder. Any help is greatly appreciated, thank you.",,['differential-geometry']
40,Is the Riemannian distance function Lipschitz on a hypersurface?,Is the Riemannian distance function Lipschitz on a hypersurface?,,"Let $M$ be a compact hypersurface in $\mathbb{R}^{n+1}$ of dimenion $n$. Is it true that there exists a constant $C$ such that  $$d(x,y) \leq C|x-y|$$ for all $x, y \in M$? Here $d$ is the Riemannian distance function and $|\cdot|$ is the usual norm on $\mathbb{R}^{n+1}$. I think it is trivially true that $|x-y| \leq d(x,y)$ since the straight line minimises the distance between two points. But the reverse, I don't know.","Let $M$ be a compact hypersurface in $\mathbb{R}^{n+1}$ of dimenion $n$. Is it true that there exists a constant $C$ such that  $$d(x,y) \leq C|x-y|$$ for all $x, y \in M$? Here $d$ is the Riemannian distance function and $|\cdot|$ is the usual norm on $\mathbb{R}^{n+1}$. I think it is trivially true that $|x-y| \leq d(x,y)$ since the straight line minimises the distance between two points. But the reverse, I don't know.",,"['functional-analysis', 'differential-geometry', 'manifolds']"
41,The injectivity of torus in the category of abelian Lie groups,The injectivity of torus in the category of abelian Lie groups,,HI: I have the following question: Definition: A Lie group $T$ is called a torus if $T\cong \prod_{1\leq i\leq k} \mathbb{R}/\mathbb{Z}$ for some $k\in \mathbb{N}$. ${\bf Question}$: Is it true that a torus is an injective object in the category of abelian Lie groups?  Thanks very much!,HI: I have the following question: Definition: A Lie group $T$ is called a torus if $T\cong \prod_{1\leq i\leq k} \mathbb{R}/\mathbb{Z}$ for some $k\in \mathbb{N}$. ${\bf Question}$: Is it true that a torus is an injective object in the category of abelian Lie groups?  Thanks very much!,,"['geometry', 'differential-geometry', 'category-theory', 'lie-groups', 'lie-algebras']"
42,Weaker definitions of Lie subgroups,Weaker definitions of Lie subgroups,,"A Lie group $H$ is called a Lie subgroup of a Lie Group $G$ if there is a map $i:H\to G$ which is (a) an injective immersion and (b) a group homomorphism. My questios are: What happens if we replace (a) ""injective immersion"" by (a') ""injective and differentiable""? What happens if we go further and replace (a) ""injective immersion"" by (a'') ""injective""? Can anybody give examples where (a'') and (b) hold but not (a') and (b)? Or (a') and (b) but not (a) and (b)?","A Lie group $H$ is called a Lie subgroup of a Lie Group $G$ if there is a map $i:H\to G$ which is (a) an injective immersion and (b) a group homomorphism. My questios are: What happens if we replace (a) ""injective immersion"" by (a') ""injective and differentiable""? What happens if we go further and replace (a) ""injective immersion"" by (a'') ""injective""? Can anybody give examples where (a'') and (b) hold but not (a') and (b)? Or (a') and (b) but not (a) and (b)?",,"['differential-geometry', 'lie-groups', 'examples-counterexamples']"
43,Exterior product of a differential form and its derivative,Exterior product of a differential form and its derivative,,Let $\omega$ be a k-form on a smooth manifold $M$ such that there exists $f\in C^{\infty}(M)$ with $f(x)\ne 0$ for all $x\in M$ and $d(f \cdot \omega)=0$. I need to show that $\omega \wedge d\omega =0$. I have only been able to show that $\omega \wedge d\omega =\frac{1}{f} \omega \wedge \omega \wedge df$ but I don't know how to conclude.,Let $\omega$ be a k-form on a smooth manifold $M$ such that there exists $f\in C^{\infty}(M)$ with $f(x)\ne 0$ for all $x\in M$ and $d(f \cdot \omega)=0$. I need to show that $\omega \wedge d\omega =0$. I have only been able to show that $\omega \wedge d\omega =\frac{1}{f} \omega \wedge \omega \wedge df$ but I don't know how to conclude.,,['differential-geometry']
44,Symmetry of Killing Vectors in Covariant Derivative,Symmetry of Killing Vectors in Covariant Derivative,,"Several times, I've seen statements along the lines of ""$\nabla_X Y=\nabla_Y X$ because $X$ is a Killing vector field."" One example I found on Stack Exchange is here . I have yet to understand why such arguments work, and I particularly don't understand what role the Killing structure plays in the relationship. Could someone please explain this symmetry?","Several times, I've seen statements along the lines of ""$\nabla_X Y=\nabla_Y X$ because $X$ is a Killing vector field."" One example I found on Stack Exchange is here . I have yet to understand why such arguments work, and I particularly don't understand what role the Killing structure plays in the relationship. Could someone please explain this symmetry?",,"['differential-geometry', 'riemannian-geometry', 'vector-fields']"
45,Integration by parts (Differential Geometry),Integration by parts (Differential Geometry),,"I am studying the proof of a theorem and I am stuck. It says that by integration by parts we get that: For $g(t)$ a variation of Riemannian metrics wih $g'(0)=h,$ $$\int_{M} (-\Delta (tr h) + \delta^2 h)\;dV_g=0$$ where $\Delta$ is the rough Laplacian, and $\delta^2 h=\nabla^i \nabla^j h_{ij}$ is the double-divergence operator. I don't understand how integration by parts imply that this integral is equal to zero. Any help is appreciated!","I am studying the proof of a theorem and I am stuck. It says that by integration by parts we get that: For $g(t)$ a variation of Riemannian metrics wih $g'(0)=h,$ $$\int_{M} (-\Delta (tr h) + \delta^2 h)\;dV_g=0$$ where $\Delta$ is the rough Laplacian, and $\delta^2 h=\nabla^i \nabla^j h_{ij}$ is the double-divergence operator. I don't understand how integration by parts imply that this integral is equal to zero. Any help is appreciated!",,"['geometry', 'differential-geometry', 'riemannian-geometry']"
46,Evaluating the Lie derivative of the metric,Evaluating the Lie derivative of the metric,,"From the Wikipedia definition of the Lie derivative of a tensor along a vector field, we have, $$\mathcal{L}_X g_{\mu\nu} = X^\lambda \nabla_\lambda g_{\mu\nu} + (\nabla_\mu X^\lambda)g_{\lambda \nu} + (\nabla_\nu X^\lambda)g_{\mu\lambda}$$ Since the covariant derivative of the metric vanishes, $$\mathcal{L}_X g_{\mu\nu} = (\nabla_\mu X^\lambda)g_{\lambda \nu} + (\nabla_\nu X^\lambda)g_{\mu\lambda}$$ But we know this must be the Killing equation, i.e. $\nabla_\mu X_\nu + \nabla_\nu X_\mu$. But it is my understanding that the covariant derivative is only acting on $X$, and not on $g$ as well, so I don't see why this is justified: $$(\nabla_\mu X^\lambda)g_{\lambda \nu} = \nabla_\mu(X^\lambda g_{\lambda \nu}) = \nabla_\mu X_ v$$ Am I misinterpreting the definition of the Lie derivative, or is something else going on?","From the Wikipedia definition of the Lie derivative of a tensor along a vector field, we have, $$\mathcal{L}_X g_{\mu\nu} = X^\lambda \nabla_\lambda g_{\mu\nu} + (\nabla_\mu X^\lambda)g_{\lambda \nu} + (\nabla_\nu X^\lambda)g_{\mu\lambda}$$ Since the covariant derivative of the metric vanishes, $$\mathcal{L}_X g_{\mu\nu} = (\nabla_\mu X^\lambda)g_{\lambda \nu} + (\nabla_\nu X^\lambda)g_{\mu\lambda}$$ But we know this must be the Killing equation, i.e. $\nabla_\mu X_\nu + \nabla_\nu X_\mu$. But it is my understanding that the covariant derivative is only acting on $X$, and not on $g$ as well, so I don't see why this is justified: $$(\nabla_\mu X^\lambda)g_{\lambda \nu} = \nabla_\mu(X^\lambda g_{\lambda \nu}) = \nabla_\mu X_ v$$ Am I misinterpreting the definition of the Lie derivative, or is something else going on?",,"['differential-geometry', 'tensors']"
47,Poincare Hopf Theorem,Poincare Hopf Theorem,,"I'm trying to apply the Poincare-Hopf theorem for a vector field over a closed disk. The vector fields sometimes have zeros on the boundary (if number of zeros is infinite, then it's zero over the whole boundary). Furthermore, the fields are undefined at the center, so I guess it's a vector field over a closed disk with a hole. In all other ways the vector field satisfies the conditions for the Poincare-Hopf theorem. In a different scenario, the vector field is defined over the whole 2D plane except the origin but is not differentiable at the boundary of the unit disk. The field tends to zero at infinity. How do I apply the Poincare-Hopf Theorem (or an extension of it) in these two scenarios? What if I take away the condition that the vector field is perpendicular to the boundary for scenario 1?","I'm trying to apply the Poincare-Hopf theorem for a vector field over a closed disk. The vector fields sometimes have zeros on the boundary (if number of zeros is infinite, then it's zero over the whole boundary). Furthermore, the fields are undefined at the center, so I guess it's a vector field over a closed disk with a hole. In all other ways the vector field satisfies the conditions for the Poincare-Hopf theorem. In a different scenario, the vector field is defined over the whole 2D plane except the origin but is not differentiable at the boundary of the unit disk. The field tends to zero at infinity. How do I apply the Poincare-Hopf Theorem (or an extension of it) in these two scenarios? What if I take away the condition that the vector field is perpendicular to the boundary for scenario 1?",,"['differential-geometry', 'differential-topology']"
48,Tangent space to lie group at identity.,Tangent space to lie group at identity.,,"I'm supposed to show that  for a Lie group G, $T_{(e,e)}G\times G \simeq T_eG\oplus T_eG$ and that $T_{(e,e)}m$ is given by $(X,Y)\mapsto X+Y$. I'm having trouble proving this. I'm not exactly clear what this means or how one would go about proving this.","I'm supposed to show that  for a Lie group G, $T_{(e,e)}G\times G \simeq T_eG\oplus T_eG$ and that $T_{(e,e)}m$ is given by $(X,Y)\mapsto X+Y$. I'm having trouble proving this. I'm not exactly clear what this means or how one would go about proving this.",,"['differential-geometry', 'lie-groups']"
49,which surfaces have (for a large area) a constant negative curvature?,which surfaces have (for a large area) a constant negative curvature?,,"There is no surface in $ R^3 $ that can represent the complete hyperbolic plane (Hilberts theorem) so we always have to do with a surface that is not completely equivalent, has a cusp somewhere, but in most publications on hyperbolic geometry, it is almost given that the tracioid (tractrix rotated about its asymptope) is a surface that has a constant negative curvature, and in many publications ""tracioid"" and ""pseudosphere"" are used interchangable. But I am wondering are there other surfaces that have a constant negative curvature? I did some searching and did find: In Klein's ""Vorlesungen uber Nicht-Euclidische Geometrie"" (1928) $4, page 286, figure 218 - 220, Klein gives three surfaces for hyperbolic surfaces: one that looks like an hill one that looks like an single sheet hyperboloid and then the well known tracioid Unfortunedly Klein doesn't give the equations of these surfaces. In Sommerville ""The elements of non euclidean geometry"" it says (Dover edition page 167) Furtunedly we do not require to take the imaginary circle a the type of surfaces of constant negative curvature. There are different forms of such surfaces, even of revolution, but the simplest is the surface called pseudosphere, which is formed by revolving a tractrix about its asymptope. Again a hint that other surfaces exist but no equations In https://math.stackexchange.com/a/666101/88985 there is a link to http://www.dm.unibo.it/~arcozzi/beltrami_sent1.pdf and this publication says at page 6 Gauss published his Theorema egregium in 1827 and it was already clear that, if figures could be moved isometrically, cuvature had to be constant. Minding observed that the converse was true in the 30's, and he found various surfaces of constant negative curvature in Euclidean space, the tractroid among them. sadly there is no reference to the publication of Minding. So i am stuck: What are those other surfaces of a constant negative curvature? and what are their equations?","There is no surface in $ R^3 $ that can represent the complete hyperbolic plane (Hilberts theorem) so we always have to do with a surface that is not completely equivalent, has a cusp somewhere, but in most publications on hyperbolic geometry, it is almost given that the tracioid (tractrix rotated about its asymptope) is a surface that has a constant negative curvature, and in many publications ""tracioid"" and ""pseudosphere"" are used interchangable. But I am wondering are there other surfaces that have a constant negative curvature? I did some searching and did find: In Klein's ""Vorlesungen uber Nicht-Euclidische Geometrie"" (1928) $4, page 286, figure 218 - 220, Klein gives three surfaces for hyperbolic surfaces: one that looks like an hill one that looks like an single sheet hyperboloid and then the well known tracioid Unfortunedly Klein doesn't give the equations of these surfaces. In Sommerville ""The elements of non euclidean geometry"" it says (Dover edition page 167) Furtunedly we do not require to take the imaginary circle a the type of surfaces of constant negative curvature. There are different forms of such surfaces, even of revolution, but the simplest is the surface called pseudosphere, which is formed by revolving a tractrix about its asymptope. Again a hint that other surfaces exist but no equations In https://math.stackexchange.com/a/666101/88985 there is a link to http://www.dm.unibo.it/~arcozzi/beltrami_sent1.pdf and this publication says at page 6 Gauss published his Theorema egregium in 1827 and it was already clear that, if figures could be moved isometrically, cuvature had to be constant. Minding observed that the converse was true in the 30's, and he found various surfaces of constant negative curvature in Euclidean space, the tractroid among them. sadly there is no reference to the publication of Minding. So i am stuck: What are those other surfaces of a constant negative curvature? and what are their equations?",,"['differential-geometry', 'hyperbolic-geometry']"
50,Definition of a coordinate vector bundle,Definition of a coordinate vector bundle,,"Consider the following definition of a coordinate vector bundle. Let $M$ be a smooth manifold of dimension $m$, and $\{(f, U_f)\}$ an   atlas of compatible charts for $M$. A smooth coordinate vector bundle   of rank $n$ over $M$ relative to this atlas consists of a smooth   manifold $B$, and a smooth surjective mapping $\pi \colon B\to M$, and   diffeomorphisms $\phi_f\colon U_f\times \mathbb{R}^n\to \pi^{-1}(U_f)$   such that $\pi\phi_f(p, v)=p$ for all $(p, v)\in U_f\times \mathbb{R}^n$. the smooth maps $\phi_{f, p}\colon \mathbb{R}^n\to \pi^{-1}(U_f)$ defined for $p\in U_f$ by $\phi_{f, p}(v)=\phi_f(p, v)$ are such that   $\phi^{-1}_{f', p}\circ \phi_{f, p}\colon \mathbb{R}^n\to \mathbb{R}^n$ is in $\operatorname{GL}(n, \mathbb{R})$ for each $f$   and $f'$ and all $p\in U_f\cap U_{f'}$. the map $g_{f'f}\colon U_f\cap U_{f'}\to \operatorname{GL}(n, \mathbb{R})$ defined by $\phi^{-1}_{f', p}\circ \phi_{f, p}$ is   smooth. Although it is built into the usual definition of vector bundles that each fiber $\pi^{-1}(p)$ is a vector space and the coordinate maps $\phi_{f, p}$ are linear, this definition doesn't make these two properties explicit. My question is whether these two properties can be extracted from the above definition readily. (I can assume that they still have to hold in this case, because the transition maps satisfy the Cech cocycle relations.)","Consider the following definition of a coordinate vector bundle. Let $M$ be a smooth manifold of dimension $m$, and $\{(f, U_f)\}$ an   atlas of compatible charts for $M$. A smooth coordinate vector bundle   of rank $n$ over $M$ relative to this atlas consists of a smooth   manifold $B$, and a smooth surjective mapping $\pi \colon B\to M$, and   diffeomorphisms $\phi_f\colon U_f\times \mathbb{R}^n\to \pi^{-1}(U_f)$   such that $\pi\phi_f(p, v)=p$ for all $(p, v)\in U_f\times \mathbb{R}^n$. the smooth maps $\phi_{f, p}\colon \mathbb{R}^n\to \pi^{-1}(U_f)$ defined for $p\in U_f$ by $\phi_{f, p}(v)=\phi_f(p, v)$ are such that   $\phi^{-1}_{f', p}\circ \phi_{f, p}\colon \mathbb{R}^n\to \mathbb{R}^n$ is in $\operatorname{GL}(n, \mathbb{R})$ for each $f$   and $f'$ and all $p\in U_f\cap U_{f'}$. the map $g_{f'f}\colon U_f\cap U_{f'}\to \operatorname{GL}(n, \mathbb{R})$ defined by $\phi^{-1}_{f', p}\circ \phi_{f, p}$ is   smooth. Although it is built into the usual definition of vector bundles that each fiber $\pi^{-1}(p)$ is a vector space and the coordinate maps $\phi_{f, p}$ are linear, this definition doesn't make these two properties explicit. My question is whether these two properties can be extracted from the above definition readily. (I can assume that they still have to hold in this case, because the transition maps satisfy the Cech cocycle relations.)",,"['differential-geometry', 'manifolds', 'vector-bundles']"
51,Smooth map on differential manifolds,Smooth map on differential manifolds,,"given two differential manifolds $M_1$ and $M_2$. I have to show that the projection $\pi: M_1 \times M_2 \to M_1$ is smooth. By definition, I then need to show that for a point $(a,b)\in M_1\times M_2$ with charts $(\psi,\phi): U\times \tilde U\ni (a,b) \to V\times \tilde V$ and open sets $U\subset M_1, \tilde U \subset M_2, V\subset \mathbb{R}^n, \tilde{V}\subset \mathbb{R}^k$, we have that  \begin{align} \phi^\prime \circ \pi \circ (\phi^{-1},\psi^{-1}) \end{align} is smooth. I know that $\phi^\prime, \phi\text{ and }\psi$ are smooth but I only know that $\pi$ is linear. Is it sufficent to conclude that this map is smooth?","given two differential manifolds $M_1$ and $M_2$. I have to show that the projection $\pi: M_1 \times M_2 \to M_1$ is smooth. By definition, I then need to show that for a point $(a,b)\in M_1\times M_2$ with charts $(\psi,\phi): U\times \tilde U\ni (a,b) \to V\times \tilde V$ and open sets $U\subset M_1, \tilde U \subset M_2, V\subset \mathbb{R}^n, \tilde{V}\subset \mathbb{R}^k$, we have that  \begin{align} \phi^\prime \circ \pi \circ (\phi^{-1},\psi^{-1}) \end{align} is smooth. I know that $\phi^\prime, \phi\text{ and }\psi$ are smooth but I only know that $\pi$ is linear. Is it sufficent to conclude that this map is smooth?",,"['differential-geometry', 'smooth-manifolds']"
52,Compute the derivative of Plucker Embedding,Compute the derivative of Plucker Embedding,,"Let V be an n-dimensional vector space over $\mathbb{R}$, and $$\Psi: G(k,V)\rightarrow \mathbb{P}(\Lambda^k V)$$ be the Plucker embedding, where $$L=span \{u_1, ..., u_k\} \mapsto \Psi(L)=[u_1 \wedge u_2 \wedge ... \wedge u_k].$$ (a) How can I show that this map is smooth? (b) How can I compute its derivative? ($\Psi_*:Hom(L,L^\perp)\rightarrow Hom(det(L), det(L)) $) Any help is appreciated!","Let V be an n-dimensional vector space over $\mathbb{R}$, and $$\Psi: G(k,V)\rightarrow \mathbb{P}(\Lambda^k V)$$ be the Plucker embedding, where $$L=span \{u_1, ..., u_k\} \mapsto \Psi(L)=[u_1 \wedge u_2 \wedge ... \wedge u_k].$$ (a) How can I show that this map is smooth? (b) How can I compute its derivative? ($\Psi_*:Hom(L,L^\perp)\rightarrow Hom(det(L), det(L)) $) Any help is appreciated!",,"['geometry', 'differential-geometry']"
53,Constructing lagrangian submanifold of a symplectic manifold,Constructing lagrangian submanifold of a symplectic manifold,,"Let $(M,\omega)$ be a symplectic manifold. To keep it simple, let us take $M = \mathbb{R}^{2n}$ with linear coordinates $(x^1,\ldots,x^n,y^1,\ldots,y^n)$ and the standard symplectic form $\omega = \sum_{i=1}^n dx^i \wedge dy^i$. A submanifold $\Lambda$ of $M$ is said to be Lagrangian if, for each $p \in \Lambda$, $T_p\Lambda$ is a lagrangian subspace of $T_pM$, that is, $\omega_p \vert_{T_p\Lambda} \equiv 0$ and $\dim T_p\Lambda = \frac{1}{2}\dim T_pM$. Equivalently, if $\iota : \Lambda \hookrightarrow M$ is the inclusion map, then $\Lambda$ is Lagrangian if and only if $\iota^*\omega = 0$ and $\dim \Lambda = \frac{1}{2} \dim M$. This seems like a reasonably easy definition, but in practice, how does one really construct a lagrangian submanifold of $(M,\omega)$? For instance, given a smooth function $f : U \subset \mathbb{R}^2 \to \mathbb{R}^4$, can one explicitely construct a Lagrangian immersion out of $f$? I read a little bit about generating functions of Lagrangian submanifolds, but am unsure if this relates here. Thank you for your help.","Let $(M,\omega)$ be a symplectic manifold. To keep it simple, let us take $M = \mathbb{R}^{2n}$ with linear coordinates $(x^1,\ldots,x^n,y^1,\ldots,y^n)$ and the standard symplectic form $\omega = \sum_{i=1}^n dx^i \wedge dy^i$. A submanifold $\Lambda$ of $M$ is said to be Lagrangian if, for each $p \in \Lambda$, $T_p\Lambda$ is a lagrangian subspace of $T_pM$, that is, $\omega_p \vert_{T_p\Lambda} \equiv 0$ and $\dim T_p\Lambda = \frac{1}{2}\dim T_pM$. Equivalently, if $\iota : \Lambda \hookrightarrow M$ is the inclusion map, then $\Lambda$ is Lagrangian if and only if $\iota^*\omega = 0$ and $\dim \Lambda = \frac{1}{2} \dim M$. This seems like a reasonably easy definition, but in practice, how does one really construct a lagrangian submanifold of $(M,\omega)$? For instance, given a smooth function $f : U \subset \mathbb{R}^2 \to \mathbb{R}^4$, can one explicitely construct a Lagrangian immersion out of $f$? I read a little bit about generating functions of Lagrangian submanifolds, but am unsure if this relates here. Thank you for your help.",,"['differential-geometry', 'symplectic-geometry', 'smooth-manifolds']"
54,"How do we check conformal equivalence of parametrized surfaces, e.g. parallel surfaces?","How do we check conformal equivalence of parametrized surfaces, e.g. parallel surfaces?",,"Suppose we have two parametrized surfaces in $\mathbb{R}^3$: $$ X,Y:\mathbb{R}^2 \rightarrow \mathbb{R}^3 $$ The induced metric on either surface is the pullback of the Euclidean metric $\bar g$ due to the inclusion map: $$ g_X = X^\ast \bar g, \quad g_Y = Y^\ast \bar g $$ To check if $X$ and $Y$ are conformally equivalent, can we directly compare $g_X$ and $g_Y$, since they both are defined on $T\mathbb{R}^2$, or do we need to find out the a diffeomorphism $\varphi$ (if it exists) from $X$ to $Y$ and then compare $\varphi^\ast g_Y$ and $g_X$? Addendum: Thanks to This is much healthier for the clarifying comment. I have slightly edited my question above due to this. The specific case I am interested in is of parallel surfaces : $$ Y(u,v) = X(u,v) + aN(u,v) $$ Let us assume that $X$ is convex, e.g. an ellipsoid, and $N$ is the ""outward"" normal, i.e. the surface curves away from $N$. Is it possible to determine for this case if the surfaces are conformal or not? One can show that  $$ g_Y = Q^T g_X Q $$ where $Q$ is the change-of-basis matrix from $\{X_u,X_v\}\ (\equiv X_\ast)$ to $\{Y_u,Y_v\}\ (\equiv Y_\ast)$. Does this help in any way in deciding conformality?","Suppose we have two parametrized surfaces in $\mathbb{R}^3$: $$ X,Y:\mathbb{R}^2 \rightarrow \mathbb{R}^3 $$ The induced metric on either surface is the pullback of the Euclidean metric $\bar g$ due to the inclusion map: $$ g_X = X^\ast \bar g, \quad g_Y = Y^\ast \bar g $$ To check if $X$ and $Y$ are conformally equivalent, can we directly compare $g_X$ and $g_Y$, since they both are defined on $T\mathbb{R}^2$, or do we need to find out the a diffeomorphism $\varphi$ (if it exists) from $X$ to $Y$ and then compare $\varphi^\ast g_Y$ and $g_X$? Addendum: Thanks to This is much healthier for the clarifying comment. I have slightly edited my question above due to this. The specific case I am interested in is of parallel surfaces : $$ Y(u,v) = X(u,v) + aN(u,v) $$ Let us assume that $X$ is convex, e.g. an ellipsoid, and $N$ is the ""outward"" normal, i.e. the surface curves away from $N$. Is it possible to determine for this case if the surfaces are conformal or not? One can show that  $$ g_Y = Q^T g_X Q $$ where $Q$ is the change-of-basis matrix from $\{X_u,X_v\}\ (\equiv X_\ast)$ to $\{Y_u,Y_v\}\ (\equiv Y_\ast)$. Does this help in any way in deciding conformality?",,"['differential-geometry', 'riemannian-geometry', 'surfaces', 'conformal-geometry', 'smooth-manifolds']"
55,Finding the surface element of $S^{3}$,Finding the surface element of,S^{3},"How does one show that the surface element of $S^{3} = \{x=(x_{1}, \dots, x_{4}) \in \mathbb{R}^{4} \mid |x|^2=1\}$ is given by the following $3$-form: $$\omega=x_{1}dx_{2}\wedge dx_{3}\wedge dx_{4}-x_{2}dx_{1}\wedge dx_{3}\wedge dx_{4}+x_{3}dx_{1}\wedge dx_{2}\wedge dx_{4}-x_{4}dx_{1}\wedge dx_{2}\wedge dx_{3}?$$ Is there a standard way of calculating this? How to begin with it? Thanks in advance.","How does one show that the surface element of $S^{3} = \{x=(x_{1}, \dots, x_{4}) \in \mathbb{R}^{4} \mid |x|^2=1\}$ is given by the following $3$-form: $$\omega=x_{1}dx_{2}\wedge dx_{3}\wedge dx_{4}-x_{2}dx_{1}\wedge dx_{3}\wedge dx_{4}+x_{3}dx_{1}\wedge dx_{2}\wedge dx_{4}-x_{4}dx_{1}\wedge dx_{2}\wedge dx_{3}?$$ Is there a standard way of calculating this? How to begin with it? Thanks in advance.",,"['differential-geometry', 'differential-forms']"
56,Computing the geodesic curvature of the upper parallel of the torus,Computing the geodesic curvature of the upper parallel of the torus,,"How would this be done? In a previous exercise we were asked to determine whether the minimum, maximum and upper parallels of the torus were geodesics, asymptotic curves, or lines of curvature. The hint at the back says use the fact that the absolute value of the geodesic curvature is the absolute value of the projection onto the tangent plane of the usual curvature. But I don't really know what this means. I'm new to geodesics and I'm trying to get a better visual feel for them. I know it can be done by brute force (parametrizing the torus and setting u=pi/2 etc..) but I feel theres a much nicer way. Any help is appreciated.","How would this be done? In a previous exercise we were asked to determine whether the minimum, maximum and upper parallels of the torus were geodesics, asymptotic curves, or lines of curvature. The hint at the back says use the fact that the absolute value of the geodesic curvature is the absolute value of the projection onto the tangent plane of the usual curvature. But I don't really know what this means. I'm new to geodesics and I'm trying to get a better visual feel for them. I know it can be done by brute force (parametrizing the torus and setting u=pi/2 etc..) but I feel theres a much nicer way. Any help is appreciated.",,"['differential-geometry', 'geodesic']"
57,Computing the Gaussian curvature of this surface $z=e^{(-1/2)(x^2+y^2)}$.,Computing the Gaussian curvature of this surface .,z=e^{(-1/2)(x^2+y^2)},"Compute the Gaussian curvature of $z=e^{(-1/2)(x^2+y^2)}$. Sketch this surface and show where $K=0 $, $K>0$, and $K<0$. So would the easiest way to do this question be to construct a parametrization $$\mathbf{x}(u,v)=(u, v, e^{-\frac{1}{2}(u^2+v^2)} )?$$ If so, I calculated the Normal to be $$\left( \frac{u}{u^2+v^2+e^{u^2+v^2}},  \frac{v}{u^2+v^2+e^{u^2+v^2}},  1 \right).$$ Is that correct? Thanks","Compute the Gaussian curvature of $z=e^{(-1/2)(x^2+y^2)}$. Sketch this surface and show where $K=0 $, $K>0$, and $K<0$. So would the easiest way to do this question be to construct a parametrization $$\mathbf{x}(u,v)=(u, v, e^{-\frac{1}{2}(u^2+v^2)} )?$$ If so, I calculated the Normal to be $$\left( \frac{u}{u^2+v^2+e^{u^2+v^2}},  \frac{v}{u^2+v^2+e^{u^2+v^2}},  1 \right).$$ Is that correct? Thanks",,"['differential-geometry', 'curvature']"
58,Finding relationship between Laplace-Beltrami operators of two spheres,Finding relationship between Laplace-Beltrami operators of two spheres,,"Let $S$ and $T$ be spheres with radius $R_S$ and $R_T$ respectively. Define the diffeomorphism $\Phi:S \to T$ by $\Phi(s) = \frac{R_T}{R_S}s$. Given a function $u:T \to \mathbb{R}$, we can define $\tilde u:S \to \mathbb{R}$ by $$\tilde u(s) = u(\Phi(s)) = u\left(\frac{R_T}{R_S}s\right).$$ I am trying to write the Laplace-Beltrami operator $\Delta_T$ of $u$ in terms of $\Delta_S$ and $\tilde u$. I start with the formula $$\Delta_{S(R)} f(x) = R^2\Delta f\left(R\frac{x}{|x|}\right)\tag{1}$$ which holds for any sphere $S(R)$ of radius $R$. Using this I see that $$\Delta_S \tilde u(s) = R_S^2\Delta \tilde u\left(R_S\frac{s}{|s|}\right) = R_S^2\Delta u\left(R_T\frac{s}{|s|}\right)$$ with the last equality by definition of $\tilde u$. I want to say this is equal to $$\frac{R_S^2}{R_T^2}\Delta_T u(s)$$ by the formula (1). But then since $s \in S$ it doesn't make sense to write the above expression since we are taking the Laplace-Beltrami over $T$. And I'm not sure that I can use (1) because in (1) $x \in S(R)$, and here $s \in S$ and not $s \in T$. How do I do this calculation correctly??","Let $S$ and $T$ be spheres with radius $R_S$ and $R_T$ respectively. Define the diffeomorphism $\Phi:S \to T$ by $\Phi(s) = \frac{R_T}{R_S}s$. Given a function $u:T \to \mathbb{R}$, we can define $\tilde u:S \to \mathbb{R}$ by $$\tilde u(s) = u(\Phi(s)) = u\left(\frac{R_T}{R_S}s\right).$$ I am trying to write the Laplace-Beltrami operator $\Delta_T$ of $u$ in terms of $\Delta_S$ and $\tilde u$. I start with the formula $$\Delta_{S(R)} f(x) = R^2\Delta f\left(R\frac{x}{|x|}\right)\tag{1}$$ which holds for any sphere $S(R)$ of radius $R$. Using this I see that $$\Delta_S \tilde u(s) = R_S^2\Delta \tilde u\left(R_S\frac{s}{|s|}\right) = R_S^2\Delta u\left(R_T\frac{s}{|s|}\right)$$ with the last equality by definition of $\tilde u$. I want to say this is equal to $$\frac{R_S^2}{R_T^2}\Delta_T u(s)$$ by the formula (1). But then since $s \in S$ it doesn't make sense to write the above expression since we are taking the Laplace-Beltrami over $T$. And I'm not sure that I can use (1) because in (1) $x \in S(R)$, and here $s \in S$ and not $s \in T$. How do I do this calculation correctly??",,"['differential-geometry', 'manifolds']"
59,"Understanding the notation $\nabla_n K_{bd}$ for covariant derivatives, with $n$ a vector","Understanding the notation  for covariant derivatives, with  a vector",\nabla_n K_{bd} n,"I am having troubling interpreting a particular expression in differential geometry. It arose in computing the Lie derivative along a unit normal, $n$, of the extrinsic curvature of a sub-manifold embedded in spacetime. Specifically, $$\mathcal{L}_n K_{bd} = \underbrace{\nabla_n K_{bd}}+(\nabla_b n^c)K_{cd} + (\nabla_d n^c)K_{bc} = \underbrace{\nabla_n K_{bd}} + 2K_{bc}K^c_d$$ I do not know how to make sense of what looks like a covariant derivative $\nabla_n$. Normally, the subscript is an index, but in this case $n$ is a vector. So I can only assume that $\nabla_n$ is compact notation for something else. Source : The notation was encountered at roughly 25:00 minutes on the Perimeter Institute lecture available at: http://pirsa.org/displayFlash.php?id=12020017 .","I am having troubling interpreting a particular expression in differential geometry. It arose in computing the Lie derivative along a unit normal, $n$, of the extrinsic curvature of a sub-manifold embedded in spacetime. Specifically, $$\mathcal{L}_n K_{bd} = \underbrace{\nabla_n K_{bd}}+(\nabla_b n^c)K_{cd} + (\nabla_d n^c)K_{bc} = \underbrace{\nabla_n K_{bd}} + 2K_{bc}K^c_d$$ I do not know how to make sense of what looks like a covariant derivative $\nabla_n$. Normally, the subscript is an index, but in this case $n$ is a vector. So I can only assume that $\nabla_n$ is compact notation for something else. Source : The notation was encountered at roughly 25:00 minutes on the Perimeter Institute lecture available at: http://pirsa.org/displayFlash.php?id=12020017 .",,"['differential-geometry', 'notation', 'lie-derivative']"
60,Contraction between basis vectors and basis one-forms,Contraction between basis vectors and basis one-forms,,"Discretion: The title may be misleading, because I am not certain whether the one-forms are actually basis one-forms. I always thought by definition, $dx^i (e_j) =\delta^i_j $. But, I am confused because of what it says on one of the book I am reading, ""Mathematical Methods of Classical Mechanics"", by Arnold. In page 178 - 179, he says if we define the metric $g = diag(E_1,E_2,E_3)$, then $dx^i (e_i) = 1/\sqrt E_i$. I cannot wrap my head around this. Is $dx^i$ the dual basis one-form, or is it something else? Thank you so much for your help.","Discretion: The title may be misleading, because I am not certain whether the one-forms are actually basis one-forms. I always thought by definition, $dx^i (e_j) =\delta^i_j $. But, I am confused because of what it says on one of the book I am reading, ""Mathematical Methods of Classical Mechanics"", by Arnold. In page 178 - 179, he says if we define the metric $g = diag(E_1,E_2,E_3)$, then $dx^i (e_i) = 1/\sqrt E_i$. I cannot wrap my head around this. Is $dx^i$ the dual basis one-form, or is it something else? Thank you so much for your help.",,['differential-geometry']
61,Integrability of almost complex structure,Integrability of almost complex structure,,"If we want to check an integrability of an almost complex structure in $R^{4}$ is it enough to take vectors $X=X^{1}\frac{\partial}{\partial x^{1}}$ and $Y=Y^{1}\frac{\partial}{\partial x^{1}}$ and then calculate Nijenhuis tensor $N(X,Y)$, or we must calculate $N$ on vectors $X=X^{1}\frac{\partial}{\partial x^{1}}+X^{2}\frac{\partial}{\partial x^{2}}+X^{3}\frac{\partial}{\partial y^{1}}+X^{4}\frac{\partial}{\partial y^{2}}$ and $Y=Y^{1}\frac{\partial}{\partial x^{1}}+Y^{2}\frac{\partial}{\partial x^{2}}+Y^{3}\frac{\partial}{\partial y^{1}}+Y^{4}\frac{\partial}{\partial y^{2}}$? Thank you!","If we want to check an integrability of an almost complex structure in $R^{4}$ is it enough to take vectors $X=X^{1}\frac{\partial}{\partial x^{1}}$ and $Y=Y^{1}\frac{\partial}{\partial x^{1}}$ and then calculate Nijenhuis tensor $N(X,Y)$, or we must calculate $N$ on vectors $X=X^{1}\frac{\partial}{\partial x^{1}}+X^{2}\frac{\partial}{\partial x^{2}}+X^{3}\frac{\partial}{\partial y^{1}}+X^{4}\frac{\partial}{\partial y^{2}}$ and $Y=Y^{1}\frac{\partial}{\partial x^{1}}+Y^{2}\frac{\partial}{\partial x^{2}}+Y^{3}\frac{\partial}{\partial y^{1}}+Y^{4}\frac{\partial}{\partial y^{2}}$? Thank you!",,"['differential-geometry', 'almost-complex']"
62,Is there an efficient way to find the principal curvatures?,Is there an efficient way to find the principal curvatures?,,"Let $S$ be the surface $z=1+x^2+y^2.$ This is a regular surface with coordinate function  $\textbf{x}(u,v)=(u,v,1+u^2+v^2).$ The Gauss map $N:S \to S^2$  ($S^2$ is a sphere) is given by $(N \circ\textbf{x})(u,v)= \dfrac{(-2u,-2v,1)}{R}$ and $[-dN]_{B,B}=  \dfrac{2}{R^3}\begin{pmatrix} 4v^2+1 & -4uv \\ -4uv & 4u^2+1 \end{pmatrix},$ where  $R=\sqrt{1+4u^2+4v^2}$ and $B=\{\textbf{x}_u, \textbf{x}_v\}.$ Suppose $u,v \neq 0$. To find the principal curvatures, we need to solve for this characteristic equation: $\text{det}([-dN]_{B,B} -k\textbf{I}_2)= 0 \Leftrightarrow \left(\dfrac{8v^2}{R^3}+\dfrac{2}{R^3}-k\right)\left(\dfrac{8u^2}{R^3}+\dfrac{2}{R^3}-k\right)-\dfrac{64u^2v^2}{R^6}=0.$ Clearly, one of the values of $k$ is $\dfrac{2}{R^3}.$ How do I find the other value of $k$ without using the quadratic formula ( which is too complicated) ? Thank you.","Let $S$ be the surface $z=1+x^2+y^2.$ This is a regular surface with coordinate function  $\textbf{x}(u,v)=(u,v,1+u^2+v^2).$ The Gauss map $N:S \to S^2$  ($S^2$ is a sphere) is given by $(N \circ\textbf{x})(u,v)= \dfrac{(-2u,-2v,1)}{R}$ and $[-dN]_{B,B}=  \dfrac{2}{R^3}\begin{pmatrix} 4v^2+1 & -4uv \\ -4uv & 4u^2+1 \end{pmatrix},$ where  $R=\sqrt{1+4u^2+4v^2}$ and $B=\{\textbf{x}_u, \textbf{x}_v\}.$ Suppose $u,v \neq 0$. To find the principal curvatures, we need to solve for this characteristic equation: $\text{det}([-dN]_{B,B} -k\textbf{I}_2)= 0 \Leftrightarrow \left(\dfrac{8v^2}{R^3}+\dfrac{2}{R^3}-k\right)\left(\dfrac{8u^2}{R^3}+\dfrac{2}{R^3}-k\right)-\dfrac{64u^2v^2}{R^6}=0.$ Clearly, one of the values of $k$ is $\dfrac{2}{R^3}.$ How do I find the other value of $k$ without using the quadratic formula ( which is too complicated) ? Thank you.",,"['algebra-precalculus', 'differential-geometry']"
63,"Notation and hierarchy of cartesian spaces, euclidean spaces, riemannian spaces and manifolds","Notation and hierarchy of cartesian spaces, euclidean spaces, riemannian spaces and manifolds",,"I am confused by some definitions. Forgive the looseness of my language. A Cartesian space is basically a space of points that can be represented by n-tuples ( and other things, but I won't go into specifics). Open sets are denoted by $|x^i_{0}-x^i|<{\epsilon}$. It is denoted by $R^n$ (according to Dubrovin's book). Euclidean spaces are Cartesian spaces where there exists co-ordinate systems in which the metric can be represented by the Kronecker delta. Its open sets can be represented as open balls with the usual definition of 'balls'. Riemannian spaces are Cartesian spaces which have a positive definite quadratic form on its tangent vectors. Euclidean spaces are special cases of Riemannian spaces. So I imagine that open sets are determined by the riemannian metric? or are they determined by euclidean balls? Now manifolds are spaces, whose subsets can be identified with Euclidean spaces. But such charts can be equipped with additional Riemannian metric. So I am confused. Does that mean that the charts on manifolds have 2 'metrics', a fundamental one determined via the identification with a region of euclidean space and second additional riemannian metric? Also open sets on a manifold may be defined by identifying them with the open sets in Euclidean space. So then how does the additional riemannian metric help determine open sets on the manifold? I am totally confused about the hierarchy of these spaces, if Cartesian is on the top and Riemannian is below and Euclidean even lower than that, than why are manifolds defined first by identification with Euclidean spaces and then given additional structure of a Riemannian metric? Isn't this the inversion of the given hierarchy? When answering please don't be ambiguous with the words and notations, for it will only compound my confusion.","I am confused by some definitions. Forgive the looseness of my language. A Cartesian space is basically a space of points that can be represented by n-tuples ( and other things, but I won't go into specifics). Open sets are denoted by $|x^i_{0}-x^i|<{\epsilon}$. It is denoted by $R^n$ (according to Dubrovin's book). Euclidean spaces are Cartesian spaces where there exists co-ordinate systems in which the metric can be represented by the Kronecker delta. Its open sets can be represented as open balls with the usual definition of 'balls'. Riemannian spaces are Cartesian spaces which have a positive definite quadratic form on its tangent vectors. Euclidean spaces are special cases of Riemannian spaces. So I imagine that open sets are determined by the riemannian metric? or are they determined by euclidean balls? Now manifolds are spaces, whose subsets can be identified with Euclidean spaces. But such charts can be equipped with additional Riemannian metric. So I am confused. Does that mean that the charts on manifolds have 2 'metrics', a fundamental one determined via the identification with a region of euclidean space and second additional riemannian metric? Also open sets on a manifold may be defined by identifying them with the open sets in Euclidean space. So then how does the additional riemannian metric help determine open sets on the manifold? I am totally confused about the hierarchy of these spaces, if Cartesian is on the top and Riemannian is below and Euclidean even lower than that, than why are manifolds defined first by identification with Euclidean spaces and then given additional structure of a Riemannian metric? Isn't this the inversion of the given hierarchy? When answering please don't be ambiguous with the words and notations, for it will only compound my confusion.",,"['differential-geometry', 'manifolds', 'differential-topology', 'euclidean-geometry', 'riemannian-geometry']"
64,Two curvature formulas when equal arc-length,Two curvature formulas when equal arc-length,,"all. So with a parametric curve $\vec{r}=\langle x(t),y(t)\rangle$, curvature is given by  $$\kappa=\frac{|x'y''-x''y'|}{(x'^2+y'^2)^{3/2}}.$$ When we have constant arc-length, an alternate expression is $$\kappa=|\vec{r}''(t)|=\sqrt{x''^2+y''^2}.$$ So I see why these are both valid expressions (I can derive them both), but when we have constant arc-length, I don't see why, when we have constant arc-length $$|x'y''-x''y'|=x''^2+y''^2$$ is true.  Care to enlighten me?","all. So with a parametric curve $\vec{r}=\langle x(t),y(t)\rangle$, curvature is given by  $$\kappa=\frac{|x'y''-x''y'|}{(x'^2+y'^2)^{3/2}}.$$ When we have constant arc-length, an alternate expression is $$\kappa=|\vec{r}''(t)|=\sqrt{x''^2+y''^2}.$$ So I see why these are both valid expressions (I can derive them both), but when we have constant arc-length, I don't see why, when we have constant arc-length $$|x'y''-x''y'|=x''^2+y''^2$$ is true.  Care to enlighten me?",,"['calculus', 'geometry', 'differential-geometry', 'parametric', 'curvature']"
65,Find the maximum angle possible,Find the maximum angle possible,,"$P$ is a point on the $Y-axis$ . Find the maximum possible value of $\angle APB$ where $A=(1,0)$ and $B=(3,0)$. Here is how I solved the problem. Suppose $P=(0,k)$ .  Then using the cosine formula we get  $\cos\angle APB$ as a $f(k)$ . Then differentiating the function for finding maxima and minima, I got the answer. But this is a very lengthy process because $f(k)$ is a little complicated and then differentiating it makes it a lot more worse. Can anyone tell me a simpler way to solve the problem?","$P$ is a point on the $Y-axis$ . Find the maximum possible value of $\angle APB$ where $A=(1,0)$ and $B=(3,0)$. Here is how I solved the problem. Suppose $P=(0,k)$ .  Then using the cosine formula we get  $\cos\angle APB$ as a $f(k)$ . Then differentiating the function for finding maxima and minima, I got the answer. But this is a very lengthy process because $f(k)$ is a little complicated and then differentiating it makes it a lot more worse. Can anyone tell me a simpler way to solve the problem?",,"['calculus', 'geometry', 'differential-geometry', 'trigonometry', 'triangles']"
66,Constant Speed of Geodesics,Constant Speed of Geodesics,,"Let V be the set of smooth functions $ f : [0,1] \rightarrow \Bbb R $ such that $ \int_0^1 f(t) dt = k $. If $ F : V \rightarrow \Bbb R $ is given by $ F(f) = \int_0^1 f(t)^2 dt $, then show that the only critical point of F is the constant function $ f(t) = k$. Deduce that geodesics have constant speed. This looks like it should be pretty straight forward, but I can't manage it. I someone able to give me a (fairly sizeable!) hint, but not just a full solution. (If I still can't get it after a hint, then I may ask for a full solution!) (I can show that $ f(t) = k $ is a critical point, but not that it is the only critical point.) Thanks in advance! :)","Let V be the set of smooth functions $ f : [0,1] \rightarrow \Bbb R $ such that $ \int_0^1 f(t) dt = k $. If $ F : V \rightarrow \Bbb R $ is given by $ F(f) = \int_0^1 f(t)^2 dt $, then show that the only critical point of F is the constant function $ f(t) = k$. Deduce that geodesics have constant speed. This looks like it should be pretty straight forward, but I can't manage it. I someone able to give me a (fairly sizeable!) hint, but not just a full solution. (If I still can't get it after a hint, then I may ask for a full solution!) (I can show that $ f(t) = k $ is a critical point, but not that it is the only critical point.) Thanks in advance! :)",,"['differential-geometry', 'calculus-of-variations', 'geodesic']"
67,Curvature of saddle by definition,Curvature of saddle by definition,,"I'm trying to compute the principle curvatures of the saddle $M$ defined by $z= y^2 -x^2$ at the point $p = (0,0,0)$, but I know my computations are wrong.  Maybe you can help to see where I went wrong. I have computed the tangent plane as $z = 0$.  So first take a vector $(0,1,0)= e_1$, corresponding to the $x=0$ part (so that $z = y^2$).  Now, define a map $\gamma(s) = (0,s,s^2)$.  Then, $\gamma : (-\epsilon,\epsilon) \rightarrow M$ and this satisfies $\gamma(0) = (0,0,0) = p$ and also $\gamma'(0) = (0,1,0) = e_1$. Now, the first curvature should be the eigenvalue of the Weingarten map $L$.  That is by definition $$L(e_1) = -\frac{d}{ds}n(\gamma(s))|_{s=0}$$  But $$n(\gamma(s)) = \frac{\gamma(s)}{|\gamma(s)|} = \frac{(0,s,s^2)}{\sqrt{s^2+s^4}}$$ When I take the derivative and evaluate at $s= 0$, I get $(0,0,1)$, which is not a multiple of $e_1$. I know by a different method that I should get $L(e_1) = 2e_1$.  Can you see where I went wrong?  Thanks.","I'm trying to compute the principle curvatures of the saddle $M$ defined by $z= y^2 -x^2$ at the point $p = (0,0,0)$, but I know my computations are wrong.  Maybe you can help to see where I went wrong. I have computed the tangent plane as $z = 0$.  So first take a vector $(0,1,0)= e_1$, corresponding to the $x=0$ part (so that $z = y^2$).  Now, define a map $\gamma(s) = (0,s,s^2)$.  Then, $\gamma : (-\epsilon,\epsilon) \rightarrow M$ and this satisfies $\gamma(0) = (0,0,0) = p$ and also $\gamma'(0) = (0,1,0) = e_1$. Now, the first curvature should be the eigenvalue of the Weingarten map $L$.  That is by definition $$L(e_1) = -\frac{d}{ds}n(\gamma(s))|_{s=0}$$  But $$n(\gamma(s)) = \frac{\gamma(s)}{|\gamma(s)|} = \frac{(0,s,s^2)}{\sqrt{s^2+s^4}}$$ When I take the derivative and evaluate at $s= 0$, I get $(0,0,1)$, which is not a multiple of $e_1$. I know by a different method that I should get $L(e_1) = 2e_1$.  Can you see where I went wrong?  Thanks.",,"['differential-geometry', 'curvature']"
68,Hilbert-Schmidt norm/smooth manifolds,Hilbert-Schmidt norm/smooth manifolds,,"Given two riemannian manifolds $M$ and $N$ and a smooth map $f$ : $M$ $\rightarrow$ $N$, we define the energy density of $f$ as the smooth function $e(f)$ : $M$ $\rightarrow$ $\mathbb{R}$ given by $e(f)$ = $\frac{1}{2}$$|df|^2$, where $|df|^2$ is the Hilbert-Schmidt norm of the differential $df$ of $f$. I've got a couple of questions about the definition above: I believe that the differential in this definition is the global one, I mean, the differential  $df$ defined on the tangent bundle of $M$ to the t.b. of $N$ ($df$ : $TM$ $\rightarrow$ $TN$), am I right? Beside that, I'd like to know what is the H-S norm of the differential $df$. The notes that I'm reading say that, if $(e_1,...,e_n)$ is a local orthonormal frame on an open set $U$ $\subset$ $M$, then $e(f)$ = $\frac{1}{2}$$\langle(f_{*})e_i,(f_{*})e_i\rangle$. I didn't understand how the global differential acts on frames, since the domain of $df$ is $TM$ (so it would have to be something like $df$$(p,v)$). Thanks for your time.","Given two riemannian manifolds $M$ and $N$ and a smooth map $f$ : $M$ $\rightarrow$ $N$, we define the energy density of $f$ as the smooth function $e(f)$ : $M$ $\rightarrow$ $\mathbb{R}$ given by $e(f)$ = $\frac{1}{2}$$|df|^2$, where $|df|^2$ is the Hilbert-Schmidt norm of the differential $df$ of $f$. I've got a couple of questions about the definition above: I believe that the differential in this definition is the global one, I mean, the differential  $df$ defined on the tangent bundle of $M$ to the t.b. of $N$ ($df$ : $TM$ $\rightarrow$ $TN$), am I right? Beside that, I'd like to know what is the H-S norm of the differential $df$. The notes that I'm reading say that, if $(e_1,...,e_n)$ is a local orthonormal frame on an open set $U$ $\subset$ $M$, then $e(f)$ = $\frac{1}{2}$$\langle(f_{*})e_i,(f_{*})e_i\rangle$. I didn't understand how the global differential acts on frames, since the domain of $df$ is $TM$ (so it would have to be something like $df$$(p,v)$). Thanks for your time.",,"['differential-geometry', 'riemannian-geometry', 'normed-spaces', 'smooth-manifolds']"
69,Cohomology group of a torus with g holes,Cohomology group of a torus with g holes,,"I have to compute the cohomology groups of a torus with g holes (the Riemann surface of genus g). first I have computed the cohomology of a Torus with 3 holes in the following way: I pick a covering $\{U,V \}$ so that $U,V$ look like a pants, cutting suitably the torus, and then by Mayer-Vietoris I computed the cohomology group. But how I can generalize it to a torus with g holes? The exercice continues asking: Compute  the cohomology groups of a torus with g holes minus n point? Compute  the cohomology groups of a torus with g holes minus n small open disc pairwise disjoint. How could I proceed with this two point?","I have to compute the cohomology groups of a torus with g holes (the Riemann surface of genus g). first I have computed the cohomology of a Torus with 3 holes in the following way: I pick a covering $\{U,V \}$ so that $U,V$ look like a pants, cutting suitably the torus, and then by Mayer-Vietoris I computed the cohomology group. But how I can generalize it to a torus with g holes? The exercice continues asking: Compute  the cohomology groups of a torus with g holes minus n point? Compute  the cohomology groups of a torus with g holes minus n small open disc pairwise disjoint. How could I proceed with this two point?",,"['differential-geometry', 'algebraic-topology']"
70,Parameterization of the Schwarz P surface,Parameterization of the Schwarz P surface,,Is there a closed form parameterization of the Schwarz P minimal surface ?,Is there a closed form parameterization of the Schwarz P minimal surface ?,,"['differential-geometry', 'closed-form', 'parametrization', 'minimal-surfaces']"
71,Equation of a plane from cross product,Equation of a plane from cross product,,"I'm working from Do Carmo, and I ran into another snag. More specifically, 1.4.5: Given points $p_1, p_2, p_3 \in \mathbb{R}^3$ , show that the following expression gives the equation for the plane containing these points: $((p-p_1) \wedge (p-p_2)) \bullet (p-p_3) = 0$ for an arbitrary point on the plane $p=(x,y,z)$ My issue is that Do Carmo doesn't mention any equation for planes, so I'm not sure what he wants here.  Furthermore, I think I may be missing some nuance of it as direct computation was very messy and unfruitful. One may simplify the expression to $(p \wedge p_2 + p_1 \wedge p) \bullet p_3 + (p_1 \wedge p_2) \bullet (p-p_3)$ but the usefulness of this is questionable at best. Note that $u \wedge v$ here is equivalent to the cross product. Any help or clarification is appreciated.","I'm working from Do Carmo, and I ran into another snag. More specifically, 1.4.5: Given points , show that the following expression gives the equation for the plane containing these points: for an arbitrary point on the plane My issue is that Do Carmo doesn't mention any equation for planes, so I'm not sure what he wants here.  Furthermore, I think I may be missing some nuance of it as direct computation was very messy and unfruitful. One may simplify the expression to but the usefulness of this is questionable at best. Note that here is equivalent to the cross product. Any help or clarification is appreciated.","p_1, p_2, p_3 \in \mathbb{R}^3 ((p-p_1) \wedge (p-p_2)) \bullet (p-p_3) = 0 p=(x,y,z) (p \wedge p_2 + p_1 \wedge p) \bullet p_3 + (p_1 \wedge p_2) \bullet (p-p_3) u \wedge v",['differential-geometry']
72,"What is the value of the 2-form $X(u(Y))-Y(u(X))-u([X,Y])$, is it $2du(X,Y)$?","What is the value of the 2-form , is it ?","X(u(Y))-Y(u(X))-u([X,Y]) 2du(X,Y)","Let $X,Y$ be two vector fields on a Riemannian manifold $(M,g,\nabla)$ where $\nabla $ is the symmetric metric connection on $M$ and let $u$ be a 1-form. I want to find the value or a simple form or interpretation of the following \begin{equation} (1)\hspace{.51cm} X(u(Y))-Y(u(X))-u([X,Y])\\ (2)\hspace{.51cm} X(u(Y))-u(\nabla_XY)-u(X)u(Y) \end{equation} John show that the first expression is a 2-form, I have been trying to prove that it is $2du$ as he claimed. We can take $X=\Sigma X^i \frac{\partial}{\partial x_i}$ , $Y=\Sigma Y^i \frac{\partial}{\partial x_i}$ and $u(\frac{\partial}{\partial x_i})=u_i$ Thanks in advance","Let $X,Y$ be two vector fields on a Riemannian manifold $(M,g,\nabla)$ where $\nabla $ is the symmetric metric connection on $M$ and let $u$ be a 1-form. I want to find the value or a simple form or interpretation of the following \begin{equation} (1)\hspace{.51cm} X(u(Y))-Y(u(X))-u([X,Y])\\ (2)\hspace{.51cm} X(u(Y))-u(\nabla_XY)-u(X)u(Y) \end{equation} John show that the first expression is a 2-form, I have been trying to prove that it is $2du$ as he claimed. We can take $X=\Sigma X^i \frac{\partial}{\partial x_i}$ , $Y=\Sigma Y^i \frac{\partial}{\partial x_i}$ and $u(\frac{\partial}{\partial x_i})=u_i$ Thanks in advance",,"['differential-geometry', 'riemannian-geometry', 'differential-forms', 'tensors']"
73,Flat Points in Irreducible Algebraic Varieties,Flat Points in Irreducible Algebraic Varieties,,"I am trying to understand the paper ""Algebraic Methods in Discrete Analogs of the Kakeya Problem"" by L. Guth and N. H. Katz.  This paper contains the following lemma: Let $S$ be the set of points in $\mathbb{R}^3$ on which the polynomial $p$ vanishes, and let $a$ be a regular point of $S$.  Suppose that $S$ contains 3 distinct lines all of which intersect at $a$.  Then $a$ is a flat point. I'm having a hard time picturing the situation in this lemma.  Can someone give me examples (other than a plane) of irreducible algebraic varieties that contain three distinct lines that meet at a point?","I am trying to understand the paper ""Algebraic Methods in Discrete Analogs of the Kakeya Problem"" by L. Guth and N. H. Katz.  This paper contains the following lemma: Let $S$ be the set of points in $\mathbb{R}^3$ on which the polynomial $p$ vanishes, and let $a$ be a regular point of $S$.  Suppose that $S$ contains 3 distinct lines all of which intersect at $a$.  Then $a$ is a flat point. I'm having a hard time picturing the situation in this lemma.  Can someone give me examples (other than a plane) of irreducible algebraic varieties that contain three distinct lines that meet at a point?",,"['algebraic-geometry', 'differential-geometry', 'kakeya-sets']"
74,D'Alembertian $\Box$,D'Alembertian,\Box,This question has to do with the D'Alembertian operator on a general manifold with a metric $g_{\mu\nu}$. I understand that the definition of the D'Alembertian is  $$\Box \phi\equiv g_{\mu\nu}\partial^\mu\partial^\nu \phi$$ So why is it also given in the form $$\Box \phi=\frac{1}{\sqrt{-g}}\partial_\mu(\sqrt{-g}g^{\mu\nu}\partial_\nu \phi)$$where $g=$det$(g_{\mu\nu})$? I don't understand how the $\sqrt{-g}$ factors come about in the second equation. Could someone kindly point it out? Many thanks.,This question has to do with the D'Alembertian operator on a general manifold with a metric $g_{\mu\nu}$. I understand that the definition of the D'Alembertian is  $$\Box \phi\equiv g_{\mu\nu}\partial^\mu\partial^\nu \phi$$ So why is it also given in the form $$\Box \phi=\frac{1}{\sqrt{-g}}\partial_\mu(\sqrt{-g}g^{\mu\nu}\partial_\nu \phi)$$where $g=$det$(g_{\mu\nu})$? I don't understand how the $\sqrt{-g}$ factors come about in the second equation. Could someone kindly point it out? Many thanks.,,"['differential-geometry', 'metric-spaces', 'manifolds']"
75,Metric on tangent vectors to tangent space,Metric on tangent vectors to tangent space,,"Let $M$ be a Riemannian manifold and $p$ be a point of $M$. Let $v$, $v'$ be  tangent vectors to $M$ at $p$. Of course we have $\langle v,v'\rangle_p$ defined. Let $u$, $w$ be tangent vectors to $T_p(M)$ at $v$. How is $\langle u,w\rangle_v$ defined? How is it related to the metric of $M$?","Let $M$ be a Riemannian manifold and $p$ be a point of $M$. Let $v$, $v'$ be  tangent vectors to $M$ at $p$. Of course we have $\langle v,v'\rangle_p$ defined. Let $u$, $w$ be tangent vectors to $T_p(M)$ at $v$. How is $\langle u,w\rangle_v$ defined? How is it related to the metric of $M$?",,['differential-geometry']
76,Should diffeomorphisms preserving arc length be affine?,Should diffeomorphisms preserving arc length be affine?,,"Problem Suppose $\varphi\colon V=\mathbb R^n\to V$ be a differmorphism and $d\varphi$ is its tangent mapping. $\langle\circ,\circ\rangle$ is a nondegenerate (symmetric or symplectic ) bilinear form on $V$. If $d\varphi$ preserves the scalar product everywhere, i.e. $\langle u,v\rangle=\langle d\varphi_x(u),d\varphi_x(v)\rangle$ for all $x\in V$ and $u,v\in V$ (identify $T_xV$ with $V$), should $\varphi$ be affine? Thoughts Suppose $\langle\circ,\circ\rangle$ is an inner-product, the result seems true, for it's not hard to show that $\varphi$ preserves arc length by curvilinear integral, then if $l_{pq}$ is the segment connecting $p$ and $q$ of the minimal distance, then $\varphi(l_{pq})$ connects $\varphi(p)$ and $\varphi(q)$ of the minimal distance, hence $l_{\varphi(p)\varphi(q)}$. Backgrounds The problem arises from the twin paradox in special relativity. The frame of reference of the traveling twin isn't inertial therefore isn't equivalent to the inertial frame of reference on earth, thus the time dilation argument is nonsense. Mathematically, if the coordinate system of the spacetime in which the frame of reference isn't inertial, we cannot determine the proper time of a world line naïvely from integrating $c^{-1}ds=\sqrt{dt^2-c^{-2}(x^2+y^2+z^2)}$ in the new coordinate system, i.e, the arc length of the world line isn't preserved under the coordinate transformation. Any idea? Thanks! Edit The symplectic case is already disproved by Seub.","Problem Suppose $\varphi\colon V=\mathbb R^n\to V$ be a differmorphism and $d\varphi$ is its tangent mapping. $\langle\circ,\circ\rangle$ is a nondegenerate (symmetric or symplectic ) bilinear form on $V$. If $d\varphi$ preserves the scalar product everywhere, i.e. $\langle u,v\rangle=\langle d\varphi_x(u),d\varphi_x(v)\rangle$ for all $x\in V$ and $u,v\in V$ (identify $T_xV$ with $V$), should $\varphi$ be affine? Thoughts Suppose $\langle\circ,\circ\rangle$ is an inner-product, the result seems true, for it's not hard to show that $\varphi$ preserves arc length by curvilinear integral, then if $l_{pq}$ is the segment connecting $p$ and $q$ of the minimal distance, then $\varphi(l_{pq})$ connects $\varphi(p)$ and $\varphi(q)$ of the minimal distance, hence $l_{\varphi(p)\varphi(q)}$. Backgrounds The problem arises from the twin paradox in special relativity. The frame of reference of the traveling twin isn't inertial therefore isn't equivalent to the inertial frame of reference on earth, thus the time dilation argument is nonsense. Mathematically, if the coordinate system of the spacetime in which the frame of reference isn't inertial, we cannot determine the proper time of a world line naïvely from integrating $c^{-1}ds=\sqrt{dt^2-c^{-2}(x^2+y^2+z^2)}$ in the new coordinate system, i.e, the arc length of the world line isn't preserved under the coordinate transformation. Any idea? Thanks! Edit The symplectic case is already disproved by Seub.",,"['differential-geometry', 'physics', 'quadratic-forms', 'symplectic-geometry']"
77,Action of a Lie group on the tangent bundle..,Action of a Lie group on the tangent bundle..,,Let $P\longrightarrow M$ be a $G$-principal bundles. How do I define an action of $G$ over $TP$? Furthermore how can I identify the space of sections $\Gamma(TP/G)$ with $\mathfrak{X}(M)^G$ where $\mathfrak{X}(M)^G$ denotes the set of all $G$-invariant vector fields? Thanks,Let $P\longrightarrow M$ be a $G$-principal bundles. How do I define an action of $G$ over $TP$? Furthermore how can I identify the space of sections $\Gamma(TP/G)$ with $\mathfrak{X}(M)^G$ where $\mathfrak{X}(M)^G$ denotes the set of all $G$-invariant vector fields? Thanks,,"['differential-geometry', 'vector-bundles', 'principal-bundles']"
78,Compact hypersurface of $\mathbb{R}^{n+1}$ with positive curvature is diffeomorphic to $S^n$.,Compact hypersurface of  with positive curvature is diffeomorphic to .,\mathbb{R}^{n+1} S^n,"I have a compact hypersurface $M$ of $\mathbb{R}^{n+1}$ with positive curvature. I need to show that it is diffeomorphic to $S^n$. The hint is to consider the shape operator $A_{\nu_p} x$, where $\nu$ is a smooth unit normal vector field regarded as a map $\nu: M \rightarrow S^n$, and then show that it is a covering map. Unfortunately, I don't think the hint really made the approach any clearer. Can anyone help to shed some light on this exercise for me?","I have a compact hypersurface $M$ of $\mathbb{R}^{n+1}$ with positive curvature. I need to show that it is diffeomorphic to $S^n$. The hint is to consider the shape operator $A_{\nu_p} x$, where $\nu$ is a smooth unit normal vector field regarded as a map $\nu: M \rightarrow S^n$, and then show that it is a covering map. Unfortunately, I don't think the hint really made the approach any clearer. Can anyone help to shed some light on this exercise for me?",,"['differential-geometry', 'riemannian-geometry']"
79,Ideas for a Project on Differential Geometry,Ideas for a Project on Differential Geometry,,"Currently trying to find a topic for a roughly fifteen page paper on Differential Geometry with presentation, with the rough target being a second year graduate student audience. I was looking in particular for some interesting problem that can be efficiently solved using differential-geometric techniques, or at least something suitably categorical. Any ideas? I was considering discussing categorical generalizations of Lie algebras.","Currently trying to find a topic for a roughly fifteen page paper on Differential Geometry with presentation, with the rough target being a second year graduate student audience. I was looking in particular for some interesting problem that can be efficiently solved using differential-geometric techniques, or at least something suitably categorical. Any ideas? I was considering discussing categorical generalizations of Lie algebras.",,"['reference-request', 'differential-geometry', 'soft-question']"
80,Show that F(t) is an immersion,Show that F(t) is an immersion,,"I've got here an exercise that says: ""Show that the map $F:\mathbb{R}\rightarrow \mathbb{R^2}$ defined by $F(t)=(\cos t, \sin t)$ is an immersion"". $F$ is an immersion if $dF_x:T_x\mathbb{R}\rightarrow T_{F(x)}\mathbb{R^2}$ is injective. Now $dF_x$ is $(-\sin x, \cos x)^t$ (am I wrong?) and it isn't injective, so it isn't an immersion. Is it correct?","I've got here an exercise that says: ""Show that the map $F:\mathbb{R}\rightarrow \mathbb{R^2}$ defined by $F(t)=(\cos t, \sin t)$ is an immersion"". $F$ is an immersion if $dF_x:T_x\mathbb{R}\rightarrow T_{F(x)}\mathbb{R^2}$ is injective. Now $dF_x$ is $(-\sin x, \cos x)^t$ (am I wrong?) and it isn't injective, so it isn't an immersion. Is it correct?",,['differential-geometry']
81,"Distinction between a vector and a tensor of type (1,0)","Distinction between a vector and a tensor of type (1,0)",,"Let's say I have a differentiable manifold $\mathscr{M}$. A vector $v$ on this manifold is a map from $\mathscr{F}$ to $\mathbb{R}$, where $\mathscr{F}$ is the set of all smooth functions from $\mathscr{M}$ to $\mathbb{R}$. A tensor of type (1,0) is a map from $V^{\ast}$ to $\mathbb{R}$, which we identify as a vector (because $V^{\ast\ast}$ is isomorphic to $V$). So how do we make this association, between a map that takes an element from $V^{\ast}$ and gives a number, to a map that takes an element from $\mathscr{F}$ and gives a number? Does that mean $V^{\ast}$ and $\mathscr{F}$ are isomorphic?","Let's say I have a differentiable manifold $\mathscr{M}$. A vector $v$ on this manifold is a map from $\mathscr{F}$ to $\mathbb{R}$, where $\mathscr{F}$ is the set of all smooth functions from $\mathscr{M}$ to $\mathbb{R}$. A tensor of type (1,0) is a map from $V^{\ast}$ to $\mathbb{R}$, which we identify as a vector (because $V^{\ast\ast}$ is isomorphic to $V$). So how do we make this association, between a map that takes an element from $V^{\ast}$ and gives a number, to a map that takes an element from $\mathscr{F}$ and gives a number? Does that mean $V^{\ast}$ and $\mathscr{F}$ are isomorphic?",,"['linear-algebra', 'differential-geometry', 'manifolds']"
82,Euler Lagrange equation for harmonic maps,Euler Lagrange equation for harmonic maps,,"In the paper ""The existence of minimal immersions of 2-spheres"" by Sacks and Uhlenbeck the authors claim that the Euler Lagrange equation for the modified functional $E_\alpha(s) = \int_M (1 + |ds(x)|^2)^\alpha d\mu$, $\alpha>1$, is $$ \Delta s + (\alpha - 1)\frac{(d^2s,ds)ds}{1+|ds|^2} + A(s)(ds,ds) = 0 $$ namely Equation (2). As far as I understand, this is a compact form. But how should I interpret it? Can anyone help me unravel the equation in order to write it neatly in components? @John: what I mean is the following: if we were given the classical Euler-Lagrange equation for harmonic maps, i.e. $$ \Delta s + A(s)(ds,ds) = 0, $$ this could be re-written as, putting $\phi = i \circ s$, $$ \Delta \phi^a(x) + g^{ij}(x) A^a_{s(x)} ( \frac{\partial \phi}{\partial x^i}; \frac{\partial \phi}{\partial x^j} ) =0, $$ where $i$ is the immersion in $R^k$ of the target manifold, $a=1,2,...,k$ and $x^i$ are local coordinates on the first manifold. Now I would like to do something similar to the equation above, but the middle term in the left hand side is troublesome.","In the paper ""The existence of minimal immersions of 2-spheres"" by Sacks and Uhlenbeck the authors claim that the Euler Lagrange equation for the modified functional $E_\alpha(s) = \int_M (1 + |ds(x)|^2)^\alpha d\mu$, $\alpha>1$, is $$ \Delta s + (\alpha - 1)\frac{(d^2s,ds)ds}{1+|ds|^2} + A(s)(ds,ds) = 0 $$ namely Equation (2). As far as I understand, this is a compact form. But how should I interpret it? Can anyone help me unravel the equation in order to write it neatly in components? @John: what I mean is the following: if we were given the classical Euler-Lagrange equation for harmonic maps, i.e. $$ \Delta s + A(s)(ds,ds) = 0, $$ this could be re-written as, putting $\phi = i \circ s$, $$ \Delta \phi^a(x) + g^{ij}(x) A^a_{s(x)} ( \frac{\partial \phi}{\partial x^i}; \frac{\partial \phi}{\partial x^j} ) =0, $$ where $i$ is the immersion in $R^k$ of the target manifold, $a=1,2,...,k$ and $x^i$ are local coordinates on the first manifold. Now I would like to do something similar to the equation above, but the middle term in the left hand side is troublesome.",,"['differential-geometry', 'riemannian-geometry', 'calculus-of-variations']"
83,Showing the parametrically representation of hyperbolic paraboloid. And how to find the curves $u$ and $v$ be constant.,Showing the parametrically representation of hyperbolic paraboloid. And how to find the curves  and  be constant.,u v,"Show that the hyperbolic paraboloid can be represented parametrically as $$r(u,v)=\langle a(u+v), b(u-v), uv\rangle$$ Find the curves $u$ is constant and $v$ is constant. I guess I need to use the hyperbolic paraboloid equation. But I cannot solve this. Please help me doing it. Thank you very much","Show that the hyperbolic paraboloid can be represented parametrically as $$r(u,v)=\langle a(u+v), b(u-v), uv\rangle$$ Find the curves $u$ is constant and $v$ is constant. I guess I need to use the hyperbolic paraboloid equation. But I cannot solve this. Please help me doing it. Thank you very much",,"['geometry', 'differential-geometry', 'self-learning']"
84,Covariant derivative with contravariant components derivation,Covariant derivative with contravariant components derivation,,"I'm doing Leonard Susskind's course on General Relativity ( http://deimos3.apple.com/WebObjects/Core.woa/Feed/itunes.stanford.edu-dz.19344853322.019344853324 ), and I'm stuck on a particular derivation (in Lecture 4, about 12 minutes in). He left as an exercise to calculate: $D_m V^n$. He gave us the answer already as: $D_m V^n=\partial_m V^n+\Gamma _{\text{mr}}^nV^r $ I can do most of the derivation as follows: $D_m V^n=D_m\left(g^{\text{np}} V_p\right)$ $D_m V^n=\left(D_m g^{\text{np}}\right)V_p - g^{\text{np}}\left(D_m V_p\right) $     Product rule $D_m V^n=g^{\text{np}}\left(D_m V_p\right)$                            $D_m g^{\text{np}}=0$ in Gaussian-normal coordinates $D_m V^n=g^{\text{np}}\left(\partial_m V_p-V_r \Gamma _{\text{mp}}^r\right)$            apply covariant derivative $D_m V^n=\partial_m g^{\text{np}}V_p -g^{\text{np}} V_r \Gamma _{\text{mp}}^r$           multiply through $D_m V^n=\partial_m V^n-g^{\text{np}} \Gamma _{\text{mp}}^rV_r$ This last step is where I am stuck. How to get from $$-g^{\text{np}} \Gamma _{\text{mp}}^rV_r$$ to   $$\Gamma _{\text{mr}}^nV^r $$ I have some idea that the minus sign will be taken care of by $g^{\text{np}}=-g_{\text{np}}$, and there must be some swap of summation indices, but I can't seem to see it.","I'm doing Leonard Susskind's course on General Relativity ( http://deimos3.apple.com/WebObjects/Core.woa/Feed/itunes.stanford.edu-dz.19344853322.019344853324 ), and I'm stuck on a particular derivation (in Lecture 4, about 12 minutes in). He left as an exercise to calculate: $D_m V^n$. He gave us the answer already as: $D_m V^n=\partial_m V^n+\Gamma _{\text{mr}}^nV^r $ I can do most of the derivation as follows: $D_m V^n=D_m\left(g^{\text{np}} V_p\right)$ $D_m V^n=\left(D_m g^{\text{np}}\right)V_p - g^{\text{np}}\left(D_m V_p\right) $     Product rule $D_m V^n=g^{\text{np}}\left(D_m V_p\right)$                            $D_m g^{\text{np}}=0$ in Gaussian-normal coordinates $D_m V^n=g^{\text{np}}\left(\partial_m V_p-V_r \Gamma _{\text{mp}}^r\right)$            apply covariant derivative $D_m V^n=\partial_m g^{\text{np}}V_p -g^{\text{np}} V_r \Gamma _{\text{mp}}^r$           multiply through $D_m V^n=\partial_m V^n-g^{\text{np}} \Gamma _{\text{mp}}^rV_r$ This last step is where I am stuck. How to get from $$-g^{\text{np}} \Gamma _{\text{mp}}^rV_r$$ to   $$\Gamma _{\text{mr}}^nV^r $$ I have some idea that the minus sign will be taken care of by $g^{\text{np}}=-g_{\text{np}}$, and there must be some swap of summation indices, but I can't seem to see it.",,['differential-geometry']
85,What separates rotations from other co-ordinate transformations?,What separates rotations from other co-ordinate transformations?,,"I am confused about some seemingly elementary ideas. From what I have understood, a rotation is just a specific class of co-ordinate transformations. If this is true, what exactly separates a rotation from the other transformations? I will give an example below. Let us take an $n$-dimensional manifold (we have provided with a metric), to label points on the manifold we use have co-ordinates  $$x^1,...,x^n$$ Let us transform the co-ordinates into new co-ordinates $$x'^k=x'^k(x^1,...,x^n) $$ where $k$ goes from $1$ to $n$. These functions are single valued, continuous and have continuous derivatives. The elements of the metric (for the original co-ordinate system) are $f_{ij}(x_1,...,x_n)$. The elements of the new metric $f'_{ij}$ are related to the old as $$f_{ij} = f'_{kl}{a^{k}_{i}}{a^{l}_{j}}$$ where $a^{r}_{s}$ is an element of the Jacobian. Now, what exactly are the restrictions that must be imposed on the elements ${a^{r}_{s}}$ to constitute a 'rotation'? I might have omitted some details, so you are welcome to make reasonable assumptions.","I am confused about some seemingly elementary ideas. From what I have understood, a rotation is just a specific class of co-ordinate transformations. If this is true, what exactly separates a rotation from the other transformations? I will give an example below. Let us take an $n$-dimensional manifold (we have provided with a metric), to label points on the manifold we use have co-ordinates  $$x^1,...,x^n$$ Let us transform the co-ordinates into new co-ordinates $$x'^k=x'^k(x^1,...,x^n) $$ where $k$ goes from $1$ to $n$. These functions are single valued, continuous and have continuous derivatives. The elements of the metric (for the original co-ordinate system) are $f_{ij}(x_1,...,x_n)$. The elements of the new metric $f'_{ij}$ are related to the old as $$f_{ij} = f'_{kl}{a^{k}_{i}}{a^{l}_{j}}$$ where $a^{r}_{s}$ is an element of the Jacobian. Now, what exactly are the restrictions that must be imposed on the elements ${a^{r}_{s}}$ to constitute a 'rotation'? I might have omitted some details, so you are welcome to make reasonable assumptions.",,"['differential-geometry', 'soft-question', 'coordinate-systems', 'rotations']"
86,Fundamental group of a component of $GL_n({\bf R})$,Fundamental group of a component of,GL_n({\bf R}),"Let $G$ be a component of $GL_n({\bf R})$ such that element has a positive determenant. (1) Since it contains $SO(n)$, $\pi_1(SO(n))$ ? What is a fundamental group of $G$ ? (2) It has a curvature bound ? That is to say, we can have bound $-1$ below or $-\infty$ ?","Let $G$ be a component of $GL_n({\bf R})$ such that element has a positive determenant. (1) Since it contains $SO(n)$, $\pi_1(SO(n))$ ? What is a fundamental group of $G$ ? (2) It has a curvature bound ? That is to say, we can have bound $-1$ below or $-\infty$ ?",,"['differential-geometry', 'lie-groups', 'riemannian-geometry', 'curvature', 'fundamental-groups']"
87,The non-vanishing 1-form on $\mathbb R^2$,The non-vanishing 1-form on,\mathbb R^2,"If $\omega$ is a non-vanishing 1-form on $\mathbb R^2$, then for any a point $p\in \mathbb R^2$, can we find an open neighborhood $U$ of $p$ and two functions $f,g$ on $U$ such that $\omega=fdg$ on $U$?","If $\omega$ is a non-vanishing 1-form on $\mathbb R^2$, then for any a point $p\in \mathbb R^2$, can we find an open neighborhood $U$ of $p$ and two functions $f,g$ on $U$ such that $\omega=fdg$ on $U$?",,['differential-geometry']
88,Calculation mistake in variation of length functional?,Calculation mistake in variation of length functional?,,"This should be pretty simple to check if you know the basics of variational calculus. I feel like I am making an obvious mistake somewhere like not using chain rule somewhere. Let $g : \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$ be a smooth metric on some domain in $\mathbb{R}^n$, and let $\gamma : [0,1] \rightarrow \mathbb{R}^n$ be a smooth path in this domain. I'm trying to show that minimising the length functional $$A(\gamma) = \int_0^1 \sqrt{g(\dot{\gamma},\dot{\gamma})} dt$$ is equivalent to minimising the action functional $$E(\gamma) = \frac{1}{2} \int_0^1 g(\dot{\gamma},\dot{\gamma}) dt.$$ I can do this in coordinates no problem, but this calculation is a bit messy. In general, the Lagrangian $L$ is not linear, but in this case $g$ is bilinear. Let $v \in C^1$, $v(0) = v(1) = 0$. Question: is this use of the metric $g$ correct, and can we conclude the result via this calculation, or am I forgetting to use the chain rule somewhere? \begin{align*} A(\gamma+tv) &= \frac{d}{dt}\bigg|_{t=0} \int_0^1 \sqrt{g(\dot{\gamma}+t\dot{v},\dot{\gamma}+t\dot{v})} dt \\ &= \frac{d}{dt}\bigg|_{t=0} \int_0^1 \sqrt{g(\dot{\gamma},\dot{\gamma}) + 2t g(\dot{v},\dot{\gamma}) + t^2 g(\dot{v},\dot{v})} dt \\ &= \int_0^1 \frac{1}{\sqrt{g(\dot{\gamma},\dot{\gamma})}}g(\dot{v},\dot{\gamma})dt \end{align*} By comparison, the first variation of the action functional is $$\frac{d}{dt}\bigg|_{t=0} E(\gamma+tv) = \int_0^1 g(\dot{\gamma},\dot{v})dt.$$ So if $\gamma$ has constant speed, i.e. if $g(\dot{\gamma},\dot{\gamma})$, then it seems that minimizing these functionals is identical. But this seems too easy (no derivatives of $g$ coming out)! Also, I can't get the Euler-Lagrange equations for geodesics to come out of this computation (integration by parts, right? -- so that's where the derivatives of $g$ would come out?). A simple ""incorrect"" will be appreciated, and an explanation why even more so. Thanks!","This should be pretty simple to check if you know the basics of variational calculus. I feel like I am making an obvious mistake somewhere like not using chain rule somewhere. Let $g : \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$ be a smooth metric on some domain in $\mathbb{R}^n$, and let $\gamma : [0,1] \rightarrow \mathbb{R}^n$ be a smooth path in this domain. I'm trying to show that minimising the length functional $$A(\gamma) = \int_0^1 \sqrt{g(\dot{\gamma},\dot{\gamma})} dt$$ is equivalent to minimising the action functional $$E(\gamma) = \frac{1}{2} \int_0^1 g(\dot{\gamma},\dot{\gamma}) dt.$$ I can do this in coordinates no problem, but this calculation is a bit messy. In general, the Lagrangian $L$ is not linear, but in this case $g$ is bilinear. Let $v \in C^1$, $v(0) = v(1) = 0$. Question: is this use of the metric $g$ correct, and can we conclude the result via this calculation, or am I forgetting to use the chain rule somewhere? \begin{align*} A(\gamma+tv) &= \frac{d}{dt}\bigg|_{t=0} \int_0^1 \sqrt{g(\dot{\gamma}+t\dot{v},\dot{\gamma}+t\dot{v})} dt \\ &= \frac{d}{dt}\bigg|_{t=0} \int_0^1 \sqrt{g(\dot{\gamma},\dot{\gamma}) + 2t g(\dot{v},\dot{\gamma}) + t^2 g(\dot{v},\dot{v})} dt \\ &= \int_0^1 \frac{1}{\sqrt{g(\dot{\gamma},\dot{\gamma})}}g(\dot{v},\dot{\gamma})dt \end{align*} By comparison, the first variation of the action functional is $$\frac{d}{dt}\bigg|_{t=0} E(\gamma+tv) = \int_0^1 g(\dot{\gamma},\dot{v})dt.$$ So if $\gamma$ has constant speed, i.e. if $g(\dot{\gamma},\dot{\gamma})$, then it seems that minimizing these functionals is identical. But this seems too easy (no derivatives of $g$ coming out)! Also, I can't get the Euler-Lagrange equations for geodesics to come out of this computation (integration by parts, right? -- so that's where the derivatives of $g$ would come out?). A simple ""incorrect"" will be appreciated, and an explanation why even more so. Thanks!",,"['differential-geometry', 'calculus-of-variations', 'geodesic']"
89,Arc length parameterization lying on a sphere,Arc length parameterization lying on a sphere,,"Show that if $\alpha$ is an arc length parameterization of a curve $C$   which lies on a sphere of radius $R$ about the origin then $$R^2 =  (\frac{1}{\kappa(s)})^2+((\frac{1}{\kappa(s)})'\frac{1}{\tau(s)})^2.$$ I know I can write the unit tangent $T$, normal $N$, and the binormal $B$ as a linear combination $\alpha(s) = a(s)T(s)+b(s)N(s)+c(s)B(s)$ and try to determine what $a, b, c $ are, but how can I continue solving this?","Show that if $\alpha$ is an arc length parameterization of a curve $C$   which lies on a sphere of radius $R$ about the origin then $$R^2 =  (\frac{1}{\kappa(s)})^2+((\frac{1}{\kappa(s)})'\frac{1}{\tau(s)})^2.$$ I know I can write the unit tangent $T$, normal $N$, and the binormal $B$ as a linear combination $\alpha(s) = a(s)T(s)+b(s)N(s)+c(s)B(s)$ and try to determine what $a, b, c $ are, but how can I continue solving this?",,['differential-geometry']
90,What does it mean for a surface to evolve with divergence-free velocity?,What does it mean for a surface to evolve with divergence-free velocity?,,"Suppose we have an evolving hypersurface which evolves with a velocity field $V$, such that $\nabla_S \cdot V = 0$ where $\nabla_S$ is the surface or tangential gradient. What does this mean? What does it mean physically for example?","Suppose we have an evolving hypersurface which evolves with a velocity field $V$, such that $\nabla_S \cdot V = 0$ where $\nabla_S$ is the surface or tangential gradient. What does this mean? What does it mean physically for example?",,"['functional-analysis', 'differential-geometry', 'surfaces']"
91,Calculate the curvature of a parametrized curve,Calculate the curvature of a parametrized curve,,"I have started to study differential geometry and have some questions about an exercise which is probably not very difficult. Exercise: Let $\gamma: I \rightarrow\mathbb{R}^{2}$ be a regular curve, parametrized by arclength, with Frenet frame $\{ T(s), N(s) \}$. For $\lambda \in \mathbb{R}$ we define the parallel curve $\gamma_{\lambda}: I \rightarrow \mathbb{R}^{2}$ by $\gamma_{\lambda}(t) = \gamma(t) + \lambda N(t)$. Calculate the curvature $\kappa_{\lambda}$ of those curves $\gamma_{\lambda}$ which are regular. Attempt to solution: First, we need to now when $\gamma_{\lambda}$ is regular, i.e., when $\dot{\gamma}_{\lambda} \neq 0$. $\dot{\gamma}_{\lambda}  = \dot{\gamma}(t) + \lambda \dot{N}(t)$, so if $\dot{\gamma}(t) \neq -\lambda\dot{N}(t)$, then $\gamma_{\lambda}$ is regular. Secondly, we need to calculate the curvature, and we have that $\kappa(t) = \langle\dot{T}(s), N(s)\rangle$, if $\{ T(s), N(s) \}$ is the Frenet frame for a curve $\gamma(s)$, if $\gamma$ is parametrized by arclength. However, our curve $\gamma_{\lambda}$ is not parametrized by arclength so I don't think we can use the scalar product directly to calculate the curvature. So I am not sure how to continue. I guess we shall do something like $\langle \dot{T}_{\lambda}, N_{\lambda}\rangle$. Any help would be appreciated!","I have started to study differential geometry and have some questions about an exercise which is probably not very difficult. Exercise: Let $\gamma: I \rightarrow\mathbb{R}^{2}$ be a regular curve, parametrized by arclength, with Frenet frame $\{ T(s), N(s) \}$. For $\lambda \in \mathbb{R}$ we define the parallel curve $\gamma_{\lambda}: I \rightarrow \mathbb{R}^{2}$ by $\gamma_{\lambda}(t) = \gamma(t) + \lambda N(t)$. Calculate the curvature $\kappa_{\lambda}$ of those curves $\gamma_{\lambda}$ which are regular. Attempt to solution: First, we need to now when $\gamma_{\lambda}$ is regular, i.e., when $\dot{\gamma}_{\lambda} \neq 0$. $\dot{\gamma}_{\lambda}  = \dot{\gamma}(t) + \lambda \dot{N}(t)$, so if $\dot{\gamma}(t) \neq -\lambda\dot{N}(t)$, then $\gamma_{\lambda}$ is regular. Secondly, we need to calculate the curvature, and we have that $\kappa(t) = \langle\dot{T}(s), N(s)\rangle$, if $\{ T(s), N(s) \}$ is the Frenet frame for a curve $\gamma(s)$, if $\gamma$ is parametrized by arclength. However, our curve $\gamma_{\lambda}$ is not parametrized by arclength so I don't think we can use the scalar product directly to calculate the curvature. So I am not sure how to continue. I guess we shall do something like $\langle \dot{T}_{\lambda}, N_{\lambda}\rangle$. Any help would be appreciated!",,['differential-geometry']
92,Finding all alternating bilinear $T$ that preserve a certain group of isometries of $\mathbb{R}^{n+1}$,Finding all alternating bilinear  that preserve a certain group of isometries of,T \mathbb{R}^{n+1},"Let $$G=\left\{\begin{pmatrix} H & 0 \\ 0 & 1\end{pmatrix} \ | \ H\in O(n), HJ=JH \right\}\subset \mathrm{Lin}(\mathbb{R}^{n+1},\mathbb{R}^{n+1}) $$ where: $n=2m$, $J$ is the standard complex structure on $\mathbb{R}^{2m}$ $\left(\text{that is}, J=\begin{pmatrix} 0 & 1 \\ -1 & 0\end{pmatrix}\right)$ and $O(n)$ is the orthogonal group. I need help with this: Find all antisymmetric bilinear $\mathbb{R}^{n+1}$-valued functions T on $\mathbb{R}^{n+1}\times \mathbb{R}^{n+1}$ such that $$g\circ T(u,v)=T(g(u),g(v))$$ for all $g\in G$, $u,v\in\mathbb{R}^{n+1}$. I tried a coordinate approach but it got too messy and I arrived at expressions that say nothing to me. I suspect that (for instance, if $m=1$ ($n=3$)), $T$ acts as a wedge product on pairs of vectors of the $xy$-plane, but that's all I've been able to tell. I'll appreciate any help.","Let $$G=\left\{\begin{pmatrix} H & 0 \\ 0 & 1\end{pmatrix} \ | \ H\in O(n), HJ=JH \right\}\subset \mathrm{Lin}(\mathbb{R}^{n+1},\mathbb{R}^{n+1}) $$ where: $n=2m$, $J$ is the standard complex structure on $\mathbb{R}^{2m}$ $\left(\text{that is}, J=\begin{pmatrix} 0 & 1 \\ -1 & 0\end{pmatrix}\right)$ and $O(n)$ is the orthogonal group. I need help with this: Find all antisymmetric bilinear $\mathbb{R}^{n+1}$-valued functions T on $\mathbb{R}^{n+1}\times \mathbb{R}^{n+1}$ such that $$g\circ T(u,v)=T(g(u),g(v))$$ for all $g\in G$, $u,v\in\mathbb{R}^{n+1}$. I tried a coordinate approach but it got too messy and I arrived at expressions that say nothing to me. I suspect that (for instance, if $m=1$ ($n=3$)), $T$ acts as a wedge product on pairs of vectors of the $xy$-plane, but that's all I've been able to tell. I'll appreciate any help.",,"['linear-algebra', 'differential-geometry', 'multilinear-algebra']"
93,On tangent spaces of Stiefel Manifolds,On tangent spaces of Stiefel Manifolds,,"I was trying to read Edelman et al.'s 1998 paper ""The Geometry of Algorithms with Orthogonality Constraints"" and since I don't have any differential geometry or much linear algebra background I am stuck at a few places. This is regarding section 2.2.1, i.e tangent and normal spaces of the Stiefel manifold. Here is the excerpt: Let $Z$ be any $n$ -by- $p$ matrix. Let $\newcommand{\sym}{\operatorname{sym}}\sym(A)$ denote $(A + A^T)/2$ and $\newcommand{\skew}{\operatorname{skew}}\skew(A)$ denote $(A - A^T)/2$ , then at $Y$ , $\pi_N(Z) = Y \sym(Y^TZ)$ defines a projection of Z onto the normal space. Similarly at $Y$ , $\pi_T(Z) = Y \skew(Y^TZ) + (I - YY^T)Z$ I tried deriving $\pi_N(Z)$ as $\newcommand{\tr}{\operatorname{tr}}\pi_N(Z) = \tr(N^TZ)$ ; $N = YS$ where $S$ is any $p$ -by- $p$ symmetric matrix but couldn't arrive at the result. But using that result I could easily derive $\pi_T(Z)$ because $Z = \pi_T(Z) + \pi_N(Z)$ Next, they go on to say that tangent directions $\Delta$ at $Y$ then have the general form: $\Delta = YA + Y_{\perp}B$ where $A$ is $p$ -by- $p$ skew symmetric, $B$ is any $(n-p)$ -by- $p$ matrix and $Y_{\perp}$ is any $n$ -by- $(n-p)$ matrix such that $YY^T + Y_{\perp}{Y_{\perp}}^T = 1$ I couldn't derive the general form of the tangents either. Can someone please help me out on this? Thanks","I was trying to read Edelman et al.'s 1998 paper ""The Geometry of Algorithms with Orthogonality Constraints"" and since I don't have any differential geometry or much linear algebra background I am stuck at a few places. This is regarding section 2.2.1, i.e tangent and normal spaces of the Stiefel manifold. Here is the excerpt: Let be any -by- matrix. Let denote and denote , then at , defines a projection of Z onto the normal space. Similarly at , I tried deriving as ; where is any -by- symmetric matrix but couldn't arrive at the result. But using that result I could easily derive because Next, they go on to say that tangent directions at then have the general form: where is -by- skew symmetric, is any -by- matrix and is any -by- matrix such that I couldn't derive the general form of the tangents either. Can someone please help me out on this? Thanks",Z n p \newcommand{\sym}{\operatorname{sym}}\sym(A) (A + A^T)/2 \newcommand{\skew}{\operatorname{skew}}\skew(A) (A - A^T)/2 Y \pi_N(Z) = Y \sym(Y^TZ) Y \pi_T(Z) = Y \skew(Y^TZ) + (I - YY^T)Z \pi_N(Z) \newcommand{\tr}{\operatorname{tr}}\pi_N(Z) = \tr(N^TZ) N = YS S p p \pi_T(Z) Z = \pi_T(Z) + \pi_N(Z) \Delta Y \Delta = YA + Y_{\perp}B A p p B (n-p) p Y_{\perp} n (n-p) YY^T + Y_{\perp}{Y_{\perp}}^T = 1,"['differential-geometry', 'vector-spaces', 'manifolds']"
94,Vector field from Lamination.,Vector field from Lamination.,,Let $S$ be a smooth closed (i.e. compact without boundary) surface. A geodesic lamination on $S$ is a nonempty closed subset of $S$ which is a disjoint union of geodesics. Suppose $\alpha$ is a geodesic lamination on $S$ such that for every $p\in S$ there is a geodesic of $\alpha$ containing $p$. Can we construct a smooth vector field in $S$ using $\alpha$? I was trying to use the tangents of the geodesics but I am not sure how to give the orientation on them. P.S.: If necessary assume that $S$ is a hyperbolic surface. Thanks in advance.,Let $S$ be a smooth closed (i.e. compact without boundary) surface. A geodesic lamination on $S$ is a nonempty closed subset of $S$ which is a disjoint union of geodesics. Suppose $\alpha$ is a geodesic lamination on $S$ such that for every $p\in S$ there is a geodesic of $\alpha$ containing $p$. Can we construct a smooth vector field in $S$ using $\alpha$? I was trying to use the tangents of the geodesics but I am not sure how to give the orientation on them. P.S.: If necessary assume that $S$ is a hyperbolic surface. Thanks in advance.,,"['differential-geometry', 'manifolds', 'differential-topology']"
95,Geometric Sig.$\frac{d}{dt}(|\lVert \boldsymbol{r}(t)\rVert )=\frac{\boldsymbol{r}(t).\frac{d}{dt}(\boldsymbol{r}(t))}{\lVert\boldsymbol{r}(t)\rVert}$,Geometric Sig.,\frac{d}{dt}(|\lVert \boldsymbol{r}(t)\rVert )=\frac{\boldsymbol{r}(t).\frac{d}{dt}(\boldsymbol{r}(t))}{\lVert\boldsymbol{r}(t)\rVert},"Suppose $\boldsymbol{r}\not=0$, what's the geometric derivation/significance of the above, the question is a show that, I could (probably) just use definitions. Instead I thought about when it'd be zero, if the derivative of the magnitude of a vector is 0, it's never changing length, it could be doing nothing (so r`(t)=0) or it could be moving in a circle/sphere/whatever is above that around the origin, thus never changing length. If the vector starts at the origin and is moving away from the origin then in the same direction as it's position (vector) .... I can see there's something nice here, not quite sure what. Anyway I'm faffing with poorly drawn diagrams is there a nice way of doing this, I'd like to show this geometrically, I've ""done"" the case when change in length is zero. Perhaps I am wrong and there isn't something nice here, but the circle/spherical thing is just a special case, then I shall defer to from definitions. If there is something nice, what is it? Thanks I've not used Latex much in the text because I'd rather use pictures and a thought process, if you want me to Latex what 'lil math there is, add a comment. using $r=\boldsymbol{r}(t)$ and $|r| = \lVert\boldsymbol{r}(t)\rVert$ and r` as the derivative of r $$\frac{d}{dt}(|r|) = \frac{r.r'}{|r|}$$ implies (iff? why not, why implies? Not entirely confident here) $$|r|\frac{d}{dt}(|r|)=r.r'=|r||r'|cos(\theta)$$ where theta is the angle between r and r` Now  $$\frac{d}{dt}(|r|)=|r'|cos(\theta)$$ ""The rate of change of length from the origin to a point on the curve is the amount of it's magnitude of it's rate of change in the direction from the origin to that point"" Shall I pose this as my own answer?","Suppose $\boldsymbol{r}\not=0$, what's the geometric derivation/significance of the above, the question is a show that, I could (probably) just use definitions. Instead I thought about when it'd be zero, if the derivative of the magnitude of a vector is 0, it's never changing length, it could be doing nothing (so r`(t)=0) or it could be moving in a circle/sphere/whatever is above that around the origin, thus never changing length. If the vector starts at the origin and is moving away from the origin then in the same direction as it's position (vector) .... I can see there's something nice here, not quite sure what. Anyway I'm faffing with poorly drawn diagrams is there a nice way of doing this, I'd like to show this geometrically, I've ""done"" the case when change in length is zero. Perhaps I am wrong and there isn't something nice here, but the circle/spherical thing is just a special case, then I shall defer to from definitions. If there is something nice, what is it? Thanks I've not used Latex much in the text because I'd rather use pictures and a thought process, if you want me to Latex what 'lil math there is, add a comment. using $r=\boldsymbol{r}(t)$ and $|r| = \lVert\boldsymbol{r}(t)\rVert$ and r` as the derivative of r $$\frac{d}{dt}(|r|) = \frac{r.r'}{|r|}$$ implies (iff? why not, why implies? Not entirely confident here) $$|r|\frac{d}{dt}(|r|)=r.r'=|r||r'|cos(\theta)$$ where theta is the angle between r and r` Now  $$\frac{d}{dt}(|r|)=|r'|cos(\theta)$$ ""The rate of change of length from the origin to a point on the curve is the amount of it's magnitude of it's rate of change in the direction from the origin to that point"" Shall I pose this as my own answer?",,['differential-geometry']
96,Hopf fibration with 7-dim. spheres as fibers.,Hopf fibration with 7-dim. spheres as fibers.,,I've read that one can generalize the Hopf fibration to get a fibration with 7-dimensional sphere fibers $\mathbb{S}^7 \rightarrow \mathbb{S}^{15} \rightarrow \mathbb{S}^8$. What is the explicit formula for this?,I've read that one can generalize the Hopf fibration to get a fibration with 7-dimensional sphere fibers $\mathbb{S}^7 \rightarrow \mathbb{S}^{15} \rightarrow \mathbb{S}^8$. What is the explicit formula for this?,,['differential-geometry']
97,"Prove $G = \left\{ \mathrm{diag} (e^{ti}, e^{\lambda ti}) \mid t \in \mathbb{R} \right\}$ is not a manifold.",Prove  is not a manifold.,"G = \left\{ \mathrm{diag} (e^{ti}, e^{\lambda ti}) \mid t \in \mathbb{R} \right\}","Let $\lambda$ be an irrational number. Let $G \subset G_2(\mathbb{C})$ be defined as $G = \left\{ \mathrm{diag} (e^{ti}, e^{\lambda ti}) \mid t \in \mathbb{R} \right\}$. Prove that $G$ is not a manifold. The definition I am using for a manifold of dimension $n$ is a set $X \subset \mathbb R^m$ such that, for all $x \in X$, there exists a neighborhood $V$ of $x$ in $X$ that is homeomorphic to an open set $U \subset \mathbb R^n$, where the homeomorphism $f\colon U \to V$ is smooth and has a smooth inverse (the latter meaning that $f^{-1}$ extends to a smooth map on an open subset of $\mathbb R^m$ containing $V$). Thanks!","Let $\lambda$ be an irrational number. Let $G \subset G_2(\mathbb{C})$ be defined as $G = \left\{ \mathrm{diag} (e^{ti}, e^{\lambda ti}) \mid t \in \mathbb{R} \right\}$. Prove that $G$ is not a manifold. The definition I am using for a manifold of dimension $n$ is a set $X \subset \mathbb R^m$ such that, for all $x \in X$, there exists a neighborhood $V$ of $x$ in $X$ that is homeomorphic to an open set $U \subset \mathbb R^n$, where the homeomorphism $f\colon U \to V$ is smooth and has a smooth inverse (the latter meaning that $f^{-1}$ extends to a smooth map on an open subset of $\mathbb R^m$ containing $V$). Thanks!",,"['differential-geometry', 'differential-topology', 'lie-groups']"
98,De Rham cohomology notation,De Rham cohomology notation,,"According to http://en.wikipedia.org/wiki/De_Rham_cohomology , one defines the $k$-th de Rham cohomology group   $H^{k}_{\mathrm{dR}}(M)$ to be the set of equivalence classes, that   is, the set of closed forms in $\Omega^k(M)$ modulo the exact forms. On the other hand, the de Rham cohomology groups of a $n$-dimensional sphere $H_{dR}^q(S^n)$ is $\mathbb{R}$ if $q=0,n$ and 0 otherwise. I am not sure to understand the link between $\mathbb{R}$ and the equivalence groups. Does that mean that to generate the de Rham cohomology groups of $S^n$, one can take any constant function $\omega$ (case $q=0$) or non-zero $n$-differential form $\omega$ (case $q=n$), and that each equivalence class can be generated from the product of $\omega$ by a particular member of $\mathbb{R}$ ?","According to http://en.wikipedia.org/wiki/De_Rham_cohomology , one defines the $k$-th de Rham cohomology group   $H^{k}_{\mathrm{dR}}(M)$ to be the set of equivalence classes, that   is, the set of closed forms in $\Omega^k(M)$ modulo the exact forms. On the other hand, the de Rham cohomology groups of a $n$-dimensional sphere $H_{dR}^q(S^n)$ is $\mathbb{R}$ if $q=0,n$ and 0 otherwise. I am not sure to understand the link between $\mathbb{R}$ and the equivalence groups. Does that mean that to generate the de Rham cohomology groups of $S^n$, one can take any constant function $\omega$ (case $q=0$) or non-zero $n$-differential form $\omega$ (case $q=n$), and that each equivalence class can be generated from the product of $\omega$ by a particular member of $\mathbb{R}$ ?",,"['differential-geometry', 'homology-cohomology', 'differential-forms']"
99,Researching for differential invariants,Researching for differential invariants,,"I have just graduated and I have to start thinking about topics for my PhD thesis and areas I am going to specialize in. The thing is that one thing that looks fun to me is classifying smooth manifolds up to diffeomorphism, searching for ""differential invariants"", which is the way I call invariants that allow to distinguish homeomorphic but not diffeomorphic manifolds. If this has already a standard name, please tell me what is it. Is this area interesting for doing research? I've read Milnor's paper on the existance of exotic 7-spheres (which I don't fully understand yet), and it seems like he hasn't any good tool for solving his problem, so he has to biuld his own invariant. Also, all of the homology theories I know so far are invariant under homotopy equivalence, so despite they are sophisticated, they are useless for this purpose, right? These are the reasons why I think this might be interesting. If so, what should I learn from now on in order to get to the ""differential invariants"" already known? Thank you.","I have just graduated and I have to start thinking about topics for my PhD thesis and areas I am going to specialize in. The thing is that one thing that looks fun to me is classifying smooth manifolds up to diffeomorphism, searching for ""differential invariants"", which is the way I call invariants that allow to distinguish homeomorphic but not diffeomorphic manifolds. If this has already a standard name, please tell me what is it. Is this area interesting for doing research? I've read Milnor's paper on the existance of exotic 7-spheres (which I don't fully understand yet), and it seems like he hasn't any good tool for solving his problem, so he has to biuld his own invariant. Also, all of the homology theories I know so far are invariant under homotopy equivalence, so despite they are sophisticated, they are useless for this purpose, right? These are the reasons why I think this might be interesting. If so, what should I learn from now on in order to get to the ""differential invariants"" already known? Thank you.",,"['differential-geometry', 'differential-topology']"
