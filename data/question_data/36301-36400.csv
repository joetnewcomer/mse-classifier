,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Fisher information for a single sampling of an exponential distribution,Fisher information for a single sampling of an exponential distribution,,"I am viewing an example of finding the Fisher information for a single sampling from an exponential distribution where: $$P(x|\theta) = \frac{1}{\theta}e^{-\frac{x}{\theta}}$$ The score $S$ is $S(x|\theta) = \frac{\partial}{\partial\theta}logP(x|\theta) = -\frac{1}{\theta} + \frac{x}{\theta^2}$. Fisher information is the expectency of $S^2$ which is: $$E_x[S^2] = E_x\left[\frac{1}{\theta^2} - 2\frac{x}{\theta^3} + \frac{x^2}{\theta^4}\right]$$ I know this might sound strange, but I don't know how to calculate this expectation. Something is mixed for me here. I know that $$E[P(x)]=\int xp(x)dx$$ But I can't connect the two pieces of information. In the book, they got: $$E_x[S^2] = E_x\left[\frac{1}{\theta^2} - 2\frac{x}{\theta^3} + \frac{x}{\theta^4}] = \frac{1}{\theta^2} - 2\frac{\theta}{\theta^3} + \frac{2\theta^2}{\theta^4}\right] = \frac{1}{\theta^2}$$ But I can't see how they got that. Any information will be useful. Thanks.","I am viewing an example of finding the Fisher information for a single sampling from an exponential distribution where: $$P(x|\theta) = \frac{1}{\theta}e^{-\frac{x}{\theta}}$$ The score $S$ is $S(x|\theta) = \frac{\partial}{\partial\theta}logP(x|\theta) = -\frac{1}{\theta} + \frac{x}{\theta^2}$. Fisher information is the expectency of $S^2$ which is: $$E_x[S^2] = E_x\left[\frac{1}{\theta^2} - 2\frac{x}{\theta^3} + \frac{x^2}{\theta^4}\right]$$ I know this might sound strange, but I don't know how to calculate this expectation. Something is mixed for me here. I know that $$E[P(x)]=\int xp(x)dx$$ But I can't connect the two pieces of information. In the book, they got: $$E_x[S^2] = E_x\left[\frac{1}{\theta^2} - 2\frac{x}{\theta^3} + \frac{x}{\theta^4}] = \frac{1}{\theta^2} - 2\frac{\theta}{\theta^3} + \frac{2\theta^2}{\theta^4}\right] = \frac{1}{\theta^2}$$ But I can't see how they got that. Any information will be useful. Thanks.",,"['probability', 'probability-theory', 'statistics']"
1,Probability of a result when spinning a disk,Probability of a result when spinning a disk,,"A circular disk is divided into $5$ equal segments. On spinning the disk a pointer always points to one segment. The segments contain pictures of $2$ bananas, $2$ lemons and one kiwi fruit. The disk is spun $4$ times. The probability of not getting a kiwi is $\frac45 \times \frac45 \times \frac45 \times \frac45  = 0.410$. The probability of getting one kiwi is $(\frac15 \times \frac45 \times \frac45 \times \frac45)  + (\frac15 \times \frac45 \times \frac45 \times \frac45) + (\frac15 \times \frac45 \times \frac45 \times \frac45) + (\frac15 \times \frac45 \times \frac45 \times \frac45) = 0.410$ What is wrong here? the probability of no kiwi or one kiwi cannot be the same?","A circular disk is divided into $5$ equal segments. On spinning the disk a pointer always points to one segment. The segments contain pictures of $2$ bananas, $2$ lemons and one kiwi fruit. The disk is spun $4$ times. The probability of not getting a kiwi is $\frac45 \times \frac45 \times \frac45 \times \frac45  = 0.410$. The probability of getting one kiwi is $(\frac15 \times \frac45 \times \frac45 \times \frac45)  + (\frac15 \times \frac45 \times \frac45 \times \frac45) + (\frac15 \times \frac45 \times \frac45 \times \frac45) + (\frac15 \times \frac45 \times \frac45 \times \frac45) = 0.410$ What is wrong here? the probability of no kiwi or one kiwi cannot be the same?",,['probability']
2,Proof of Paley-Zygmund inequality (lower bound for upper tail of square-integrable random variables),Proof of Paley-Zygmund inequality (lower bound for upper tail of square-integrable random variables),,"Given a square integrable r.v. $X$ satisfying $P(|X| > 0) > 0$, the goal is to show that  $$ P(|X| \ge \lambda E[|X|]) \ge \frac{(1-\lambda)^2 E^2[|X|]}{E[X^2]} $$ My attempt so far: Let $A = \{|X| \ge \lambda E[|X|]\}$, and $1_A$ the indicator for $A$.  Applying Holder's inequality to $\int |X| \chi_A dP$ gives us  $$ \left (\int |X|\cdot 1_A dP\right )^2 \le \int |X|^2 dP \int 1_A^2 dP = E[X^2]P(A)$$ so that $$ P(A) \ge \frac{E^2[|X|\cdot 1_A]}{E[X^2]} $$ Then it would suffice to show that $E[|X|\cdot 1_A] \ge (1-\lambda)E[|X|]$, but I am not sure how to do this or if this is on track in general. Thanks! Edit: As a hint to others who come upon this: We can always decompose$E[X] = E[1_A X] + E[1_{A^\complement}X]$. You can bound one of these terms by $\lambda E[X]$, and applying Cauchy-Schwarz (= Holders for p = q = 2) gives you the desired result, which is known as the Paley-Zygmund inequality.","Given a square integrable r.v. $X$ satisfying $P(|X| > 0) > 0$, the goal is to show that  $$ P(|X| \ge \lambda E[|X|]) \ge \frac{(1-\lambda)^2 E^2[|X|]}{E[X^2]} $$ My attempt so far: Let $A = \{|X| \ge \lambda E[|X|]\}$, and $1_A$ the indicator for $A$.  Applying Holder's inequality to $\int |X| \chi_A dP$ gives us  $$ \left (\int |X|\cdot 1_A dP\right )^2 \le \int |X|^2 dP \int 1_A^2 dP = E[X^2]P(A)$$ so that $$ P(A) \ge \frac{E^2[|X|\cdot 1_A]}{E[X^2]} $$ Then it would suffice to show that $E[|X|\cdot 1_A] \ge (1-\lambda)E[|X|]$, but I am not sure how to do this or if this is on track in general. Thanks! Edit: As a hint to others who come upon this: We can always decompose$E[X] = E[1_A X] + E[1_{A^\complement}X]$. You can bound one of these terms by $\lambda E[X]$, and applying Cauchy-Schwarz (= Holders for p = q = 2) gives you the desired result, which is known as the Paley-Zygmund inequality.",,"['probability', 'probability-theory', 'measure-theory']"
3,Equal probabilities in each count in stars and bars,Equal probabilities in each count in stars and bars,,"Stars and bars is a common technique used in combinatorics. It asserts that the number of ways to put $n$ indistinguishable balls into $k$ distinguishable bins is given by: $$ n + k - 1 \choose k - 1 $$ I've seen this count used frequently to calculate probabilities but after some thought, I am slightly skeptical as to whether or not each of the counts given by the stars and bars has a equal probability of occurring. Lets consider the case with 3 balls and 2 bins. I will represent different arrangements of balls with $(n_1, n_2)$ being the case where there are $n_1$ balls in bin 1 and $n_2$ balls in bin 2. Naturally, we have $0 \leq n_1, n_2 \leq 3$ and $n_1 + n_2 = 3$. We can compute the probability of $P(0,3)$, $P(1,2)$, $P(2,1)$, and $P(3,0)$ as follows. Label each of the balls so that there are $2^3 = 8$ different equally likely arrangements. Of these arrangements, there is only $1$ way to put $0$ balls in bin 1. There are $3$ ways to $1$ ball into bin 2, and the other two cases are symmetrical.  Hence: $$P(0,3) = 1/8 \qquad P(1,2) = 3/8$$ This shows that the different items counted in stars and bars do not occur with equal probability. If someone would be so kinda, could you confirm this work? I believe that I have seen the usage of stars and bars to count the number of possibilities for use in the denominator of probability problems. Am I right in thinking that such a practices is incorrect?","Stars and bars is a common technique used in combinatorics. It asserts that the number of ways to put $n$ indistinguishable balls into $k$ distinguishable bins is given by: $$ n + k - 1 \choose k - 1 $$ I've seen this count used frequently to calculate probabilities but after some thought, I am slightly skeptical as to whether or not each of the counts given by the stars and bars has a equal probability of occurring. Lets consider the case with 3 balls and 2 bins. I will represent different arrangements of balls with $(n_1, n_2)$ being the case where there are $n_1$ balls in bin 1 and $n_2$ balls in bin 2. Naturally, we have $0 \leq n_1, n_2 \leq 3$ and $n_1 + n_2 = 3$. We can compute the probability of $P(0,3)$, $P(1,2)$, $P(2,1)$, and $P(3,0)$ as follows. Label each of the balls so that there are $2^3 = 8$ different equally likely arrangements. Of these arrangements, there is only $1$ way to put $0$ balls in bin 1. There are $3$ ways to $1$ ball into bin 2, and the other two cases are symmetrical.  Hence: $$P(0,3) = 1/8 \qquad P(1,2) = 3/8$$ This shows that the different items counted in stars and bars do not occur with equal probability. If someone would be so kinda, could you confirm this work? I believe that I have seen the usage of stars and bars to count the number of possibilities for use in the denominator of probability problems. Am I right in thinking that such a practices is incorrect?",,"['probability', 'combinatorics']"
4,Most likely number of matching cards when two people select different numbers of cards from their own packs,Most likely number of matching cards when two people select different numbers of cards from their own packs,,"Two people R and T each have a standard deck of playing cards and each randomly chooses  as many cards as they like  from their packs. We know that each pack has N=52  different cards and that (say) R chose 10 cards and T 30 but we do not know what specific cards they chose. How do we now calculate the probability (p(M))  of  8 of the cards chosen by R and T being the same (e.g. both chose 6 of clubs, etc.)? or of 5 cards being the same? What we really want to know is the most likely number of chance matches in this scenario.  What is M with the greatest p(M)? Btw we are not interested in the order of picking cards here: R and T need not draw the same card at the same time in order of picking as each other for it to be a match. Hence I take it that this is a problem of combinations and since there is no replacement, hypergeometric? Indeed some of the required probabilities seem to be obtainable with the well known formula below, calculating combinations C where one can select different values of M to get p(M) for each value. This works  where R=T, i.e. both people pick the same number of cards, like in lottery analogies where the lottery chooses 6 numbers and people also pick 6 numbers (usually called K in these formulae): (KCM x ((N-K)C(K-M))) / NCK But what I need is a formula that also works where K is not the same for the two people. If you like, in the lottery version, it is where the player would be able to choose more numbers than the lottery's six. Looking at formulae I have found involving extra bonus balls or people buying more than one ticket, they don't seem to quite fit my case. Picking 12 numbers and looking for matches with the 6 winning numbers is not the same as buying two lottery tickets of 6, each of which has to be separately judged for matches with the winning numbers in order to win? I have worked out answers on a very small scale, imagining packs of cards with only  4 cards in them, by constructing tables of all the possible combinations that could occur and counting matches. In the real situation I am interested in packs of 'cards' which could each have 1000 cards in them, however, so I  need a formula. E.g. for N=4, I get by hand that p(M=2) =.75  if R=T=3, and the same from the formula above. Where N=4, R=3, T=2 by hand I get p(M=2) = .5 but I can't find a formula to do this. but I am sure it is out there.","Two people R and T each have a standard deck of playing cards and each randomly chooses  as many cards as they like  from their packs. We know that each pack has N=52  different cards and that (say) R chose 10 cards and T 30 but we do not know what specific cards they chose. How do we now calculate the probability (p(M))  of  8 of the cards chosen by R and T being the same (e.g. both chose 6 of clubs, etc.)? or of 5 cards being the same? What we really want to know is the most likely number of chance matches in this scenario.  What is M with the greatest p(M)? Btw we are not interested in the order of picking cards here: R and T need not draw the same card at the same time in order of picking as each other for it to be a match. Hence I take it that this is a problem of combinations and since there is no replacement, hypergeometric? Indeed some of the required probabilities seem to be obtainable with the well known formula below, calculating combinations C where one can select different values of M to get p(M) for each value. This works  where R=T, i.e. both people pick the same number of cards, like in lottery analogies where the lottery chooses 6 numbers and people also pick 6 numbers (usually called K in these formulae): (KCM x ((N-K)C(K-M))) / NCK But what I need is a formula that also works where K is not the same for the two people. If you like, in the lottery version, it is where the player would be able to choose more numbers than the lottery's six. Looking at formulae I have found involving extra bonus balls or people buying more than one ticket, they don't seem to quite fit my case. Picking 12 numbers and looking for matches with the 6 winning numbers is not the same as buying two lottery tickets of 6, each of which has to be separately judged for matches with the winning numbers in order to win? I have worked out answers on a very small scale, imagining packs of cards with only  4 cards in them, by constructing tables of all the possible combinations that could occur and counting matches. In the real situation I am interested in packs of 'cards' which could each have 1000 cards in them, however, so I  need a formula. E.g. for N=4, I get by hand that p(M=2) =.75  if R=T=3, and the same from the formula above. Where N=4, R=3, T=2 by hand I get p(M=2) = .5 but I can't find a formula to do this. but I am sure it is out there.",,"['probability', 'combinations']"
5,Upper bound on expectation of n non independent random variables,Upper bound on expectation of n non independent random variables,,"Given $X_i$ are (not necessarily independent) and $\max_{j \leq n} (E|X_j|^p)^{1/p} = \sigma_p < \infty$, $p>1$ Prove that : $E\ \max_{j \leq n} |X_j| \leq n^{1/p} \sigma_p$ Approach: $$ E\ \max|X_i| \leq E\ \max|X_i|^P \leq \sum_{j \leq n} E|X_j|^p \leq n\ \max E|X_j|^p = n\sigma_p^p $$","Given $X_i$ are (not necessarily independent) and $\max_{j \leq n} (E|X_j|^p)^{1/p} = \sigma_p < \infty$, $p>1$ Prove that : $E\ \max_{j \leq n} |X_j| \leq n^{1/p} \sigma_p$ Approach: $$ E\ \max|X_i| \leq E\ \max|X_i|^P \leq \sum_{j \leq n} E|X_j|^p \leq n\ \max E|X_j|^p = n\sigma_p^p $$",,"['probability', 'probability-theory', 'inequality', 'expectation', 'order-statistics']"
6,Puzzle on rolling dice game,Puzzle on rolling dice game,,"A gambler goes to bet. The dealer has 3 dice, which are fair, meaning that the chance that each face shows up is exactly 1/6. The dealer says: ""You can choose your bet on a number, any number from 1 to 6. Then I'll roll the 3 dice. If none show the number you bet, you'll lose \$1. If one shows the number you bet, you'll win \$1. If two or three dice show the number you bet, you'll win \$3 or \$5, respectively."" Is it a fair game? PROPOSED APPROACH: Let A be event when all three dice show the given number, B be the event that only two dice show the same given number, C be the event that only one dice shows the given number, D be the event otherwise. Now P(A) = $1/216$ P(B) = ${3 \choose 2} * [1*1*5/216] = 15/216$ P(C) = ${3 \choose 1} * [1*5*5/216] = 75/216$ From the law of complementary event the P(D) = 1 - P(A) - P(B) - P(C) = $1 - 1/216 - 15/216 - 75/216 = 125/216$ Now expected value for winning is $\$1*P(C) + \$3*P(B) + \$5*P(A) = 125/216$ expected value for losing is $\$1*P(D) = 125/216$ Given the two values are equal, it is a fair game. I am thinking if there is a quicker or smarter way to do it.","A gambler goes to bet. The dealer has 3 dice, which are fair, meaning that the chance that each face shows up is exactly 1/6. The dealer says: ""You can choose your bet on a number, any number from 1 to 6. Then I'll roll the 3 dice. If none show the number you bet, you'll lose \$1. If one shows the number you bet, you'll win \$1. If two or three dice show the number you bet, you'll win \$3 or \$5, respectively."" Is it a fair game? PROPOSED APPROACH: Let A be event when all three dice show the given number, B be the event that only two dice show the same given number, C be the event that only one dice shows the given number, D be the event otherwise. Now P(A) = $1/216$ P(B) = ${3 \choose 2} * [1*1*5/216] = 15/216$ P(C) = ${3 \choose 1} * [1*5*5/216] = 75/216$ From the law of complementary event the P(D) = 1 - P(A) - P(B) - P(C) = $1 - 1/216 - 15/216 - 75/216 = 125/216$ Now expected value for winning is $\$1*P(C) + \$3*P(B) + \$5*P(A) = 125/216$ expected value for losing is $\$1*P(D) = 125/216$ Given the two values are equal, it is a fair game. I am thinking if there is a quicker or smarter way to do it.",,"['probability', 'dice', 'gambling']"
7,"what does it mean ""converge in probability to a random variable""?","what does it mean ""converge in probability to a random variable""?",,"In statistics, a sequence of random variables $X_n$ is said to converge to a random $X$ in probability if $P(|X_n - X| > \epsilon ) \to 0 $. Also,  $X_n$ is said to converge to a constant c if $P(|X_n - c| > \epsilon ) \to 0 $. I can understand the argument with the constant $c$ which means that $X_n$ gets more and more concentrated on $c$, as $n \to \infty$. However, I don't quite understand the ""converge to a r.v."" argument. It seems to me that $X$ has to be degenerated for this to hold true. But the textbook I had in my hand does not elaborate on this, so I am confused. Can you explain it ? or by showing some simple examples?","In statistics, a sequence of random variables $X_n$ is said to converge to a random $X$ in probability if $P(|X_n - X| > \epsilon ) \to 0 $. Also,  $X_n$ is said to converge to a constant c if $P(|X_n - c| > \epsilon ) \to 0 $. I can understand the argument with the constant $c$ which means that $X_n$ gets more and more concentrated on $c$, as $n \to \infty$. However, I don't quite understand the ""converge to a r.v."" argument. It seems to me that $X$ has to be degenerated for this to hold true. But the textbook I had in my hand does not elaborate on this, so I am confused. Can you explain it ? or by showing some simple examples?",,"['probability', 'statistics', 'convergence-divergence', 'law-of-large-numbers']"
8,Construct a sequence of i.i.d random variables with a given a distribution function,Construct a sequence of i.i.d random variables with a given a distribution function,,"I am being asked to solve the following problem: Assume you have a sequence of i.i.d. (independent identically distributed) random variables, $X_1, X_2, \dots,$ on a probability space $(\Omega,\mathcal{F},P)$ with $P(X_n=1)=P(X_n=-1)=1/2$. Given a distribution function, $F$, use the $X_n$'s to construct a sequence of i.i.d. random variables, $Y_1, Y_2, \dots,$ with distribution function $F$. [Hint: First show that $U=\sum_{n=1}^{\infty} 2^{-n}X_n$ is a Uniform$([0,1])$ random variable, then use $U$ to find one random variable with distribution function F.] If it helps this was the part (b) of the problem. Prior to this, in part (a) we were asked to solve: Let $U$ be a Uniform($[0,1]$) random variable (i.e., the distribution of $U$ is the Lebesgue measure on $[0,1]$). Define $X_n=\lfloor 2^n U \rfloor, \ n= 1,2,\dots,$ to be the $n^{\text{th}}$ digit in the binary expansion of $U$ ($\lfloor x \rfloor$ is the greatest integer less than or equal to $x$). Show that $X_1, X_2, \dots $ are i.i.d. random variables.  Note i.i.d. stands for independent identically distributed. So in any help you provide feel free to use this result, without proof. I am really lost, I don't know how to proceed. I would appreciate any help. Thanks!","I am being asked to solve the following problem: Assume you have a sequence of i.i.d. (independent identically distributed) random variables, $X_1, X_2, \dots,$ on a probability space $(\Omega,\mathcal{F},P)$ with $P(X_n=1)=P(X_n=-1)=1/2$. Given a distribution function, $F$, use the $X_n$'s to construct a sequence of i.i.d. random variables, $Y_1, Y_2, \dots,$ with distribution function $F$. [Hint: First show that $U=\sum_{n=1}^{\infty} 2^{-n}X_n$ is a Uniform$([0,1])$ random variable, then use $U$ to find one random variable with distribution function F.] If it helps this was the part (b) of the problem. Prior to this, in part (a) we were asked to solve: Let $U$ be a Uniform($[0,1]$) random variable (i.e., the distribution of $U$ is the Lebesgue measure on $[0,1]$). Define $X_n=\lfloor 2^n U \rfloor, \ n= 1,2,\dots,$ to be the $n^{\text{th}}$ digit in the binary expansion of $U$ ($\lfloor x \rfloor$ is the greatest integer less than or equal to $x$). Show that $X_1, X_2, \dots $ are i.i.d. random variables.  Note i.i.d. stands for independent identically distributed. So in any help you provide feel free to use this result, without proof. I am really lost, I don't know how to proceed. I would appreciate any help. Thanks!",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
9,Variance of a Certain Random Matrix,Variance of a Certain Random Matrix,,"Let $A$ be a random $n \times n$ matrix, whose entries $X_{ij}$ are independent and $P(X_{ij}=1)=P(X_{ij}=-1)=1/2$. Compute $\text{Var}(\text{det}(A))$. I'm not really sure how to even proceed here. I think the question may imply that each $X_{ij}$ is either $1$ or $-1$ almost surely. So perhaps that helps things out. I would really appreciate any help with this question.","Let $A$ be a random $n \times n$ matrix, whose entries $X_{ij}$ are independent and $P(X_{ij}=1)=P(X_{ij}=-1)=1/2$. Compute $\text{Var}(\text{det}(A))$. I'm not really sure how to even proceed here. I think the question may imply that each $X_{ij}$ is either $1$ or $-1$ almost surely. So perhaps that helps things out. I would really appreciate any help with this question.",,"['probability', 'probability-theory']"
10,Uniform Probability Measure on $\mathbb{N}$?,Uniform Probability Measure on ?,\mathbb{N},"Hello this problem I am working on has four parts, and I have figured out the first three, but I am stuck on the fourth. For some clarification, the title of the problem I am working on is, Uniform Probability Measure on $\mathbb{N}$? That is why I titled my question so. In searching for a solution to this problem, I found out that such a thing does not exist so I am not asserting that I may have found one or anything like that. For each $A\subset \mathbb{N}$ define $$\rho_n(A)= \frac{1}{n}|A\cap[1,n]|,$$ and say that A has density $\rho(A)=\lim\limits_{n\rightarrow \infty}\rho_n(A)$ if that limit exists. Let $D=\{ A\subset\mathbb{N}:\rho(A) \text{exists}\}.$ 1) Show that $D$ is closed under complements. 2) Show that $D$ is closed under finite disjoint unions. 3) Show that $D$ is not closed under countable disjoint unions. 4) Show that $D$ is not closed under finite non-disjoint unions. For 1) I found that for any $A\in D,$ $\lim\limits_{n\rightarrow\infty} \rho_n(A^c)=1-\lim\limits_{n\rightarrow\infty} \rho_n(A)$ using the $\varepsilon$ definition of limit of a sequence. For 2) I get the answer to be the sum of the limits, again using the $\varepsilon$ definition and this time the triangle inequality. For 3) I defined a countable disjoint sequence so that the $\rho_n \text{'s}$ of their union oscillates between $3/4$ and $1/2$. I want to do something similar as 3) for 4), but I am a little stuck as to how to find a finite number of sets that will give me a nice oscillation like that (I would prefer to find 2 such sets). I do know that the only way to get the sequence to diverge is to make it oscillate in some way. Otherwise, we would get convergence because the sequence is bounded. Any help would be greatly appreciated.","Hello this problem I am working on has four parts, and I have figured out the first three, but I am stuck on the fourth. For some clarification, the title of the problem I am working on is, Uniform Probability Measure on $\mathbb{N}$? That is why I titled my question so. In searching for a solution to this problem, I found out that such a thing does not exist so I am not asserting that I may have found one or anything like that. For each $A\subset \mathbb{N}$ define $$\rho_n(A)= \frac{1}{n}|A\cap[1,n]|,$$ and say that A has density $\rho(A)=\lim\limits_{n\rightarrow \infty}\rho_n(A)$ if that limit exists. Let $D=\{ A\subset\mathbb{N}:\rho(A) \text{exists}\}.$ 1) Show that $D$ is closed under complements. 2) Show that $D$ is closed under finite disjoint unions. 3) Show that $D$ is not closed under countable disjoint unions. 4) Show that $D$ is not closed under finite non-disjoint unions. For 1) I found that for any $A\in D,$ $\lim\limits_{n\rightarrow\infty} \rho_n(A^c)=1-\lim\limits_{n\rightarrow\infty} \rho_n(A)$ using the $\varepsilon$ definition of limit of a sequence. For 2) I get the answer to be the sum of the limits, again using the $\varepsilon$ definition and this time the triangle inequality. For 3) I defined a countable disjoint sequence so that the $\rho_n \text{'s}$ of their union oscillates between $3/4$ and $1/2$. I want to do something similar as 3) for 4), but I am a little stuck as to how to find a finite number of sets that will give me a nice oscillation like that (I would prefer to find 2 such sets). I do know that the only way to get the sequence to diverge is to make it oscillate in some way. Otherwise, we would get convergence because the sequence is bounded. Any help would be greatly appreciated.",,"['real-analysis', 'probability', 'measure-theory']"
11,Irreducible Markov chain and invariant measure,Irreducible Markov chain and invariant measure,,"We consider a Markov chain $\left(X,P\right)$   on a finite state space $X$.  We denote $P:=\left(p_{x,y}\right)_{x,y\in X}$   and for $n\in\mathbb{N}$   $P^{n}:=\left(p_{x,y}^{(n)}\right)_{x,y\in X}$. Assume that $\left(X,P\right)$   is irreducible. Let $\pi$   be the unique $P$-invariant measure on $X$. Prove that there exists $\rho\in]0,1[$  and $c>0$   such that $$\forall x,y\in X,\forall n\in\mathbb{N},\left|P^{n}(x,y)-\pi(y)\right|\leq c\rho^{n}$$ Thank you in advance.","We consider a Markov chain $\left(X,P\right)$   on a finite state space $X$.  We denote $P:=\left(p_{x,y}\right)_{x,y\in X}$   and for $n\in\mathbb{N}$   $P^{n}:=\left(p_{x,y}^{(n)}\right)_{x,y\in X}$. Assume that $\left(X,P\right)$   is irreducible. Let $\pi$   be the unique $P$-invariant measure on $X$. Prove that there exists $\rho\in]0,1[$  and $c>0$   such that $$\forall x,y\in X,\forall n\in\mathbb{N},\left|P^{n}(x,y)-\pi(y)\right|\leq c\rho^{n}$$ Thank you in advance.",,"['probability', 'probability-theory', 'markov-chains', 'markov-process']"
12,Let $X$ be a random variable with values in $\mathbb Z_{\geq0}$. Show that $E[X]=\sum_{k=0}^\infty P[X>k]$ [duplicate],Let  be a random variable with values in . Show that  [duplicate],X \mathbb Z_{\geq0} E[X]=\sum_{k=0}^\infty P[X>k],"This question already has answers here : Showing that ${\rm E}[X]=\sum_{k=0}^\infty P(X>k)$ for a discrete random variable (4 answers) Closed 8 years ago . Let $X$ be a random variable with values in $\mathbb Z_{\geq0}$. Show that $E[X]=\sum_{k=0}^\infty P[X>k]$. The question is taken from Introduction to Probability Models, 10th Ed. (Ross, pg. 91). Attempt. Let $X=\sum_{k=1}^\infty X_k$, with \begin{equation}X_k=\begin{cases}1 & \text{when }X\leq k \\ 0 & \text{when }X>k\end{cases}\end{equation} Since $E[X_k]=P[X\leq k]$, $$E[X]=\sum_{k=1}^\infty E[X_k]=\sum_{k=1}^\infty P[X\leq k]=\sum_{k=1}^\infty \left(1-P[X>k]\right)$$ And at this point I'm at a loss as to how I should obtain the result. Attempt 2. Following drhab's help, I reformulated the definition of $X$ in terms of $X_k$. Using the same $X_k$ (for brevity of this post), let $X=\sum_{k=0}^\infty(1-X_k)$. Then $$E[X]=\sum_{k=0}^\infty E[1-X_k]=\sum_{k=0}^\infty(E[1]-E[X_k])=\sum_{k=0}^\infty(1-P[X\leq k])=\sum_{k=0}^\infty P[X>k]$$ I believe this is correct now.","This question already has answers here : Showing that ${\rm E}[X]=\sum_{k=0}^\infty P(X>k)$ for a discrete random variable (4 answers) Closed 8 years ago . Let $X$ be a random variable with values in $\mathbb Z_{\geq0}$. Show that $E[X]=\sum_{k=0}^\infty P[X>k]$. The question is taken from Introduction to Probability Models, 10th Ed. (Ross, pg. 91). Attempt. Let $X=\sum_{k=1}^\infty X_k$, with \begin{equation}X_k=\begin{cases}1 & \text{when }X\leq k \\ 0 & \text{when }X>k\end{cases}\end{equation} Since $E[X_k]=P[X\leq k]$, $$E[X]=\sum_{k=1}^\infty E[X_k]=\sum_{k=1}^\infty P[X\leq k]=\sum_{k=1}^\infty \left(1-P[X>k]\right)$$ And at this point I'm at a loss as to how I should obtain the result. Attempt 2. Following drhab's help, I reformulated the definition of $X$ in terms of $X_k$. Using the same $X_k$ (for brevity of this post), let $X=\sum_{k=0}^\infty(1-X_k)$. Then $$E[X]=\sum_{k=0}^\infty E[1-X_k]=\sum_{k=0}^\infty(E[1]-E[X_k])=\sum_{k=0}^\infty(1-P[X\leq k])=\sum_{k=0}^\infty P[X>k]$$ I believe this is correct now.",,"['probability', 'random-variables']"
13,What is the probability that a customer will not use a credit card? Pays in cash or with a credit card?,What is the probability that a customer will not use a credit card? Pays in cash or with a credit card?,,"So I'm doing some basic probability problems for homework, and we just recently went over the Inclusion-Exclusion prinicple, which I'm assuming this problem deals with, which is as follows. Shoppers can pay for their purchases with cash, a credit card, or a   debit card. Suppose that the proprietor of a shop determines that 63%   of her customers use a credit card, 23% pay with cash, and the rest   use a debit card. What is the probability that a person will not use a credit card? What is the probability that a person pays in cash or with a credit card? Now, it's my understanding that these percentages they give us don't overlap (i.e. a person won't pay part of their bill with cash, and the rest on a card, etc. etc.) So it seems relatively straightforward in the sense that only 14% of people pay with a debit card. So for the first part of the problem, wouldn't the answer simply be to add 14% and 23%? And the second would simply be the addition of 63% and 23%? I have a feeling I'm misunderstanding something, as I'm not getting the problem right.","So I'm doing some basic probability problems for homework, and we just recently went over the Inclusion-Exclusion prinicple, which I'm assuming this problem deals with, which is as follows. Shoppers can pay for their purchases with cash, a credit card, or a   debit card. Suppose that the proprietor of a shop determines that 63%   of her customers use a credit card, 23% pay with cash, and the rest   use a debit card. What is the probability that a person will not use a credit card? What is the probability that a person pays in cash or with a credit card? Now, it's my understanding that these percentages they give us don't overlap (i.e. a person won't pay part of their bill with cash, and the rest on a card, etc. etc.) So it seems relatively straightforward in the sense that only 14% of people pay with a debit card. So for the first part of the problem, wouldn't the answer simply be to add 14% and 23%? And the second would simply be the addition of 63% and 23%? I have a feeling I'm misunderstanding something, as I'm not getting the problem right.",,['probability']
14,Existence of moments and slowly varying function at infinity,Existence of moments and slowly varying function at infinity,,"I have a somewhat advanced question involving the role of slowly varying functions and their relation to moments. I want to use them to derive certain results for domains of attraction. My problem is the following. Let $L(x) = E[Y^2; |Y|\le x] $ and assume that L(x) is slowly varying to $\infty. $ This means that for any $t >  0,  $ we have $$ \lim_{x\to \infty} \frac{L(tx)}{L(x)} = 1. $$ Fix $p\in [0, 2). $ I can prove (it is some work, but not a major task) that $$ \lim_{x\to\infty} \frac{x^{2-p}E[|Y|^p; |Y|>x]}{L(x)} = 0 \hskip 10pt (*) $$ I would like to prove that $E[|Y|^p] < \infty $ for $p \in [0, 2). $ I am aware that there are certain theorems (Karamata type theorems) that use arguments related to the survival function $G(x) = Pr[Y> x] = 1-F(x) $ varying slowly to infinity to derive the existence of certain moments. But, I wonder if what I know, i.e., (*), is enough. My line of attack is the traditional one, i.e., $$E[|Y|^p] = E[|Y|^p; |Y|\le x] + E[|Y|^p; |Y|>x] $$ Now the first term on the right-hand side is clearly bounded and I was hoping to use what I learned above to prove that also the second term on the right-hand side is bounded, but I seem to run in some problems. For instance, I could use (*), and write $$ E[|Y|^p; |Y|>x] = x^{2-p}E[|Y|^p; |Y|>x]/L(x) \cdot \frac{L(x)}{x^{2-p}}. $$ The first term on the right goes to 0 as $x \to \infty, $ however, I have an $\frac{\infty}{\infty} $ issue on the second term. Am I approaching the issue in the wrong way or am I missing something else? As usual thank you to whoever could chip in some words of wisdom. Maurice","I have a somewhat advanced question involving the role of slowly varying functions and their relation to moments. I want to use them to derive certain results for domains of attraction. My problem is the following. Let $L(x) = E[Y^2; |Y|\le x] $ and assume that L(x) is slowly varying to $\infty. $ This means that for any $t >  0,  $ we have $$ \lim_{x\to \infty} \frac{L(tx)}{L(x)} = 1. $$ Fix $p\in [0, 2). $ I can prove (it is some work, but not a major task) that $$ \lim_{x\to\infty} \frac{x^{2-p}E[|Y|^p; |Y|>x]}{L(x)} = 0 \hskip 10pt (*) $$ I would like to prove that $E[|Y|^p] < \infty $ for $p \in [0, 2). $ I am aware that there are certain theorems (Karamata type theorems) that use arguments related to the survival function $G(x) = Pr[Y> x] = 1-F(x) $ varying slowly to infinity to derive the existence of certain moments. But, I wonder if what I know, i.e., (*), is enough. My line of attack is the traditional one, i.e., $$E[|Y|^p] = E[|Y|^p; |Y|\le x] + E[|Y|^p; |Y|>x] $$ Now the first term on the right-hand side is clearly bounded and I was hoping to use what I learned above to prove that also the second term on the right-hand side is bounded, but I seem to run in some problems. For instance, I could use (*), and write $$ E[|Y|^p; |Y|>x] = x^{2-p}E[|Y|^p; |Y|>x]/L(x) \cdot \frac{L(x)}{x^{2-p}}. $$ The first term on the right goes to 0 as $x \to \infty, $ however, I have an $\frac{\infty}{\infty} $ issue on the second term. Am I approaching the issue in the wrong way or am I missing something else? As usual thank you to whoever could chip in some words of wisdom. Maurice",,"['probability', 'probability-theory']"
15,Maximize the Cyclic sum,Maximize the Cyclic sum,,"Let $x_1,x_2,\dots ,x_6$ be nonnegative real numbers such that $x_1+x_2+x_3+x_4+x_5+x_6=1$, and $x_1x_3x_5+x_2x_4x_6 \geq \frac{1}{540}$. Let $p$ and $q$ be positive relatively prime integers such that $\frac{p}{q}$ is the maximum possible value of $x_1x_2x_3+x_2x_3x_4 + x_3x_4x_5 + x_4x_5x_6 + x_5x_6x_1 + x_6x_1x_2$. Find $p+q$. Hints only! This was a very difficult problem actually. A possibility is: $x_k = \frac{1}{6}$ so that: $\sum_{cyc} x_1x_3x_5 = 1/108 > \frac{1}{504}$, which is a possiblity (true). I took: $540 = 5(3^3)(2^2)$ Obviously, $x_k < 1$ so, the bigger each number, the bigger the total max value. I would think $1/6$ is the best, to get: $6\cdot \frac{1}{216} = \frac{1}{36}$ But this seems way too easy! Hints only!","Let $x_1,x_2,\dots ,x_6$ be nonnegative real numbers such that $x_1+x_2+x_3+x_4+x_5+x_6=1$, and $x_1x_3x_5+x_2x_4x_6 \geq \frac{1}{540}$. Let $p$ and $q$ be positive relatively prime integers such that $\frac{p}{q}$ is the maximum possible value of $x_1x_2x_3+x_2x_3x_4 + x_3x_4x_5 + x_4x_5x_6 + x_5x_6x_1 + x_6x_1x_2$. Find $p+q$. Hints only! This was a very difficult problem actually. A possibility is: $x_k = \frac{1}{6}$ so that: $\sum_{cyc} x_1x_3x_5 = 1/108 > \frac{1}{504}$, which is a possiblity (true). I took: $540 = 5(3^3)(2^2)$ Obviously, $x_k < 1$ so, the bigger each number, the bigger the total max value. I would think $1/6$ is the best, to get: $6\cdot \frac{1}{216} = \frac{1}{36}$ But this seems way too easy! Hints only!",,"['probability', 'combinatorics', 'algebra-precalculus', 'elementary-number-theory', 'contest-math']"
16,Packing of discrete random variables with finite second moment,Packing of discrete random variables with finite second moment,,"I am considering a discrete random variable $X \in\mathbb{R}$ with $N$ points (where each point has non-zero probability) and $E[X^2]=1$ and $E[X]=0$. Let $d_l$ be the the smallest distance between $x_l \in X$ and its closest neighbor in the support of $X$ that is \begin{align} d_{l}=\min_{x_l, x_k: l \neq k} |x_l-x_k| \end{align} Also, define \begin{align} d_{\max}&=\max_{l} d_l \\ d_{\min}&=\min_{l} d_l \\ \end{align} I know that amongst random variables with finite second moment uniformly spaced and uniformly described random variable gives the best packing that  \begin{align} d_{\min} \le d_{\min \text{Unif}}=\sqrt{\frac{12}{N^2-1}} \end{align} Here some question that I was thinking about: Can we have also a lower bound on $d_{\min}$ in terms of $N$ other than $d_{\min} \ge 0$. I am thinking no. We can always find an $X$ with a smaller and small minimum distance. Can we find upper and lower bounds  $d_{\max}$? I am thinking that  \begin{align*} d_{\max}  \le N d_{\min} \le  \sqrt{\frac{12 N^2}{N^2-1}} \end{align*} Can we find lower and upper bounds on $\frac{d_{\min}}{d_{\max}}$? If we know $d_{\min}$ can we say something about the second smallest distance or $d_{\max}$? Finally,  where I can find any reference on this subject? And what branch of math studies some thing like this? Also, it seems to me that we do not have to talk about random variables here and just talk about packing deterministic points. Please let me know how I can improve the question.  Thank you for any help in advance.","I am considering a discrete random variable $X \in\mathbb{R}$ with $N$ points (where each point has non-zero probability) and $E[X^2]=1$ and $E[X]=0$. Let $d_l$ be the the smallest distance between $x_l \in X$ and its closest neighbor in the support of $X$ that is \begin{align} d_{l}=\min_{x_l, x_k: l \neq k} |x_l-x_k| \end{align} Also, define \begin{align} d_{\max}&=\max_{l} d_l \\ d_{\min}&=\min_{l} d_l \\ \end{align} I know that amongst random variables with finite second moment uniformly spaced and uniformly described random variable gives the best packing that  \begin{align} d_{\min} \le d_{\min \text{Unif}}=\sqrt{\frac{12}{N^2-1}} \end{align} Here some question that I was thinking about: Can we have also a lower bound on $d_{\min}$ in terms of $N$ other than $d_{\min} \ge 0$. I am thinking no. We can always find an $X$ with a smaller and small minimum distance. Can we find upper and lower bounds  $d_{\max}$? I am thinking that  \begin{align*} d_{\max}  \le N d_{\min} \le  \sqrt{\frac{12 N^2}{N^2-1}} \end{align*} Can we find lower and upper bounds on $\frac{d_{\min}}{d_{\max}}$? If we know $d_{\min}$ can we say something about the second smallest distance or $d_{\max}$? Finally,  where I can find any reference on this subject? And what branch of math studies some thing like this? Also, it seems to me that we do not have to talk about random variables here and just talk about packing deterministic points. Please let me know how I can improve the question.  Thank you for any help in advance.",,"['probability', 'probability-theory', 'random-variables', 'packing-problem']"
17,"Prove that $\mathrm E\left({\max}\left\{X^2 , Y^2\right\} \right) \leq 1 + \sqrt{1 - \rho^2}$ where $\rho$ is their correlation.",Prove that  where  is their correlation.,"\mathrm E\left({\max}\left\{X^2 , Y^2\right\} \right) \leq 1 + \sqrt{1 - \rho^2} \rho","I have 2 random variables $X,Y$ with mean 0 and variance 1, their correlation is $\rho$. I need to prove this inequality $$\mathrm E\left({\max}\left\{X^2 , Y^2\right\} \right) \leq 1 + \sqrt{1 - \rho^2}$$ I need some pointers as to how to solve this problem. Thanks!","I have 2 random variables $X,Y$ with mean 0 and variance 1, their correlation is $\rho$. I need to prove this inequality $$\mathrm E\left({\max}\left\{X^2 , Y^2\right\} \right) \leq 1 + \sqrt{1 - \rho^2}$$ I need some pointers as to how to solve this problem. Thanks!",,['probability']
18,Continuous and measurable in each variable $\implies$ product measurable?,Continuous and measurable in each variable  product measurable?,\implies,"Consider a metric space $A$ with a metric $d$, and consider the measurable space $(A,\mathcal{B}(A))$ with the Borel $\sigma$-algebra generated by $d$-open sets. Let $(\Omega,\mathcal{F})$ be a measurable space. Consider the product $\sigma$-algebra $\mathcal{B}(A)\otimes\mathcal{F}:=\sigma(\{B\times F\mid B\in\mathcal{B}(A),\,F\in\mathcal{F}\})$ Suppose a function $f:A\times\Omega\to \mathbb{R}$ satisfies $f(\cdot,\omega):A\ni a\mapsto f(a,\omega)$ is a continuous function for each $\omega\in\Omega$. $f(a,\cdot):\Omega\ni \omega\mapsto f(a,\omega)$ is a $\mathcal{B}({A})$ measurable. Question: Can we say that $f$ is $\mathcal{B}(A)\otimes\mathcal{F}$-measurable? My guess is we can. I am aware that there are similar questions where $A:=\mathbb{R}$, e.g., A function which is continuous in one variable and measurable in other is jointly measurable A question on measurability in product spaces A question regarding separable continuity and measurability and I think what I should do is to something in line with constructing a sequence $f_n$, step function in $a\in A$, and whose pre-image is a rectangle, then use the continuity in $a$. But I am not really sure how to write down explicitly.","Consider a metric space $A$ with a metric $d$, and consider the measurable space $(A,\mathcal{B}(A))$ with the Borel $\sigma$-algebra generated by $d$-open sets. Let $(\Omega,\mathcal{F})$ be a measurable space. Consider the product $\sigma$-algebra $\mathcal{B}(A)\otimes\mathcal{F}:=\sigma(\{B\times F\mid B\in\mathcal{B}(A),\,F\in\mathcal{F}\})$ Suppose a function $f:A\times\Omega\to \mathbb{R}$ satisfies $f(\cdot,\omega):A\ni a\mapsto f(a,\omega)$ is a continuous function for each $\omega\in\Omega$. $f(a,\cdot):\Omega\ni \omega\mapsto f(a,\omega)$ is a $\mathcal{B}({A})$ measurable. Question: Can we say that $f$ is $\mathcal{B}(A)\otimes\mathcal{F}$-measurable? My guess is we can. I am aware that there are similar questions where $A:=\mathbb{R}$, e.g., A function which is continuous in one variable and measurable in other is jointly measurable A question on measurability in product spaces A question regarding separable continuity and measurability and I think what I should do is to something in line with constructing a sequence $f_n$, step function in $a\in A$, and whose pre-image is a rectangle, then use the continuity in $a$. But I am not really sure how to write down explicitly.",,"['real-analysis', 'probability', 'analysis', 'measure-theory']"
19,Is there anything special about a transforming a random variable according to its density/mass function?,Is there anything special about a transforming a random variable according to its density/mass function?,,"Lets say that $X\sim p$, where $p:x\mapsto p(x)$ is either a pmf or a pdf. Does the following random variable possess any unique properties: $$Y:=p(X)$$ It seems like $E[Y]=\int f^2(x)dx$ is similar to the Entropy of $Y$, which is: $$ H(Y):=E[-\log(Y)]$$ It seems like we can always make this transformation due to the way random variables are defined. Has someone studied or run across literature that discusses the properties of random variables transformed by their own distribution functions? One interpretation I can see is that $E[Y]$ gives the degree of ""concentration"" of the random variable $X$. How about the variance?: $$\int (p(x)-\mu_Y)^2p(x) dx$$ This seems to measure the degree of uniformity of the function (e.g., it will be 0 for a uniform RV) I did a couple numerical studies of some common distributions. See below:","Lets say that $X\sim p$, where $p:x\mapsto p(x)$ is either a pmf or a pdf. Does the following random variable possess any unique properties: $$Y:=p(X)$$ It seems like $E[Y]=\int f^2(x)dx$ is similar to the Entropy of $Y$, which is: $$ H(Y):=E[-\log(Y)]$$ It seems like we can always make this transformation due to the way random variables are defined. Has someone studied or run across literature that discusses the properties of random variables transformed by their own distribution functions? One interpretation I can see is that $E[Y]$ gives the degree of ""concentration"" of the random variable $X$. How about the variance?: $$\int (p(x)-\mu_Y)^2p(x) dx$$ This seems to measure the degree of uniformity of the function (e.g., it will be 0 for a uniform RV) I did a couple numerical studies of some common distributions. See below:",,"['probability', 'probability-theory']"
20,Expectation of an increasing transformation of a random variable,Expectation of an increasing transformation of a random variable,,"Suppose $X$ is real-valued random variable and $\phi$ an increasing function. An upper set is either an open or a closed right half line. Below, all expectations are assumed to exist and $I$ denotes the indicator function. Shaked and Shanthikumar (2007) claims the following: it is possible, for each $m$, to define a sequence of upper sets $U_i$'s, a sequence of $a_i$'s, and a $b$ (all of which may depend on $m$), such that as $m\to\infty$,   $$ E\left[\sum_{i=1}^m a_i I_{U_i}(X)\right]-b\to E[\phi(X)] $$ I vaguely guess that the Monotone Convergence Theorem is somehow involved but I can't conjure up a construction that does the job. Can you please help me?","Suppose $X$ is real-valued random variable and $\phi$ an increasing function. An upper set is either an open or a closed right half line. Below, all expectations are assumed to exist and $I$ denotes the indicator function. Shaked and Shanthikumar (2007) claims the following: it is possible, for each $m$, to define a sequence of upper sets $U_i$'s, a sequence of $a_i$'s, and a $b$ (all of which may depend on $m$), such that as $m\to\infty$,   $$ E\left[\sum_{i=1}^m a_i I_{U_i}(X)\right]-b\to E[\phi(X)] $$ I vaguely guess that the Monotone Convergence Theorem is somehow involved but I can't conjure up a construction that does the job. Can you please help me?",,"['probability', 'limits', 'probability-theory', 'expectation']"
21,Transition probability between urn,Transition probability between urn,,"$N$ black balls and $N$ white balls are placed in two urns so that   each urn contains $N$ balls. At each step one ball is selected at   random from each urn and the two balls interchange. The state of the   system is the number of white balls in the first urn. What I think Let $X$ the number of white balls in the urn $(1)$ then we want $$P_{jk}=P(X_{n+1}=k|X_n=j)$$ then we have three possibilities for $k$ $$(i)\;k=j+1$$ $$(ii)\;k=j$$ $$(iii)\;k=j-1$$ First we know if $(1)$ have $j$ white balls then $(2)$ have $N-j$ white balls. Let $A$ the event take a white ball in $(1)$ and $A'$ the event take black ball in $(1)$ then $$P(A)=\frac{j}{N}\space ,\space P(A')=\frac{N-j}{N}$$ analogous let $B$ the event take white ball in $(2)$ and $B'$ the event take a black ball in $(2)$ so $$P(B)=\frac{N-j}{N}\space,\space P(B')=\frac{j}{N}$$ Then we have for $i)$ $$P(X_{n+1}=k|X_n=j)=P(A')*P(B)=\left(\frac{N-j}{N}\right)^2$$ $ii)$ $$P(X_{n+1}=k|X_n=j)=P(A)P(B)+P(A')P(B')=\left(\frac{j}{N}\right)\left(\frac{N-j}{N}\right)+\left(\frac{N-j}{N}\right)\left(\frac{j}{N}\right)=2\left(\frac{j}{N}\right)\left(\frac{N-j}{N}\right)$$ $iii)$ $$P(X_{n+1}=k|X_n=j)=P(A)P(B')=\frac{j}{N}\frac{j}{N}=\left(\frac{j}{N}\right)^2$$ Is that right? There is an easier way to do?","$N$ black balls and $N$ white balls are placed in two urns so that   each urn contains $N$ balls. At each step one ball is selected at   random from each urn and the two balls interchange. The state of the   system is the number of white balls in the first urn. What I think Let $X$ the number of white balls in the urn $(1)$ then we want $$P_{jk}=P(X_{n+1}=k|X_n=j)$$ then we have three possibilities for $k$ $$(i)\;k=j+1$$ $$(ii)\;k=j$$ $$(iii)\;k=j-1$$ First we know if $(1)$ have $j$ white balls then $(2)$ have $N-j$ white balls. Let $A$ the event take a white ball in $(1)$ and $A'$ the event take black ball in $(1)$ then $$P(A)=\frac{j}{N}\space ,\space P(A')=\frac{N-j}{N}$$ analogous let $B$ the event take white ball in $(2)$ and $B'$ the event take a black ball in $(2)$ so $$P(B)=\frac{N-j}{N}\space,\space P(B')=\frac{j}{N}$$ Then we have for $i)$ $$P(X_{n+1}=k|X_n=j)=P(A')*P(B)=\left(\frac{N-j}{N}\right)^2$$ $ii)$ $$P(X_{n+1}=k|X_n=j)=P(A)P(B)+P(A')P(B')=\left(\frac{j}{N}\right)\left(\frac{N-j}{N}\right)+\left(\frac{N-j}{N}\right)\left(\frac{j}{N}\right)=2\left(\frac{j}{N}\right)\left(\frac{N-j}{N}\right)$$ $iii)$ $$P(X_{n+1}=k|X_n=j)=P(A)P(B')=\frac{j}{N}\frac{j}{N}=\left(\frac{j}{N}\right)^2$$ Is that right? There is an easier way to do?",,"['probability', 'stochastic-processes', 'solution-verification']"
22,"Stochastic process $\exp(W_t - t/2)$ approaches zero for large $t$, but it is a martingale?","Stochastic process  approaches zero for large , but it is a martingale?",\exp(W_t - t/2) t,"The stochastic process $$  S_t = \exp\left( W_t - \frac{1}{2} t \right) $$ is a martingale (for example this could be seen by noting that it solves the SDE $dS_t = S_t dB_t$, which has no drift). But this does not make intuitively sense for me, if $t$ is large, then $W_t - \frac{1}{2} t$ looks like the straight line $-\frac{1}{2}t$ with little perturbations, so this expression is very likely a large negative number, and therefore the exponential of this should be near zero. If it would be a martingale, then it expectation for each point in future should be the starting value, which in this case is $S_0 = \exp(0) = 1$ almost surely, and not $0$. I also made some pictures of this process, using $R$ and the following code N=1000 d=rnorm(N) W=cumsum(d) c=W-0.5*(1:N) par(mfrow=c(2,2)) plot(W,type=""l"") plot(c,type=""l"") plot(exp(W),type=""l"") plot(exp(c),type=""1"") Which gives the output (the process $S_t$ is the one on the bottom on the right, and above is the process $W_t - t/2$, which resembles the straight line for large $t$): So I do not understand, if it should be a martingale then it should not approach zero for large $t$, instead it should stay around its starting value (for most samples of course, but this process will approach zero for most samples, so this is not just a random deviation)?","The stochastic process $$  S_t = \exp\left( W_t - \frac{1}{2} t \right) $$ is a martingale (for example this could be seen by noting that it solves the SDE $dS_t = S_t dB_t$, which has no drift). But this does not make intuitively sense for me, if $t$ is large, then $W_t - \frac{1}{2} t$ looks like the straight line $-\frac{1}{2}t$ with little perturbations, so this expression is very likely a large negative number, and therefore the exponential of this should be near zero. If it would be a martingale, then it expectation for each point in future should be the starting value, which in this case is $S_0 = \exp(0) = 1$ almost surely, and not $0$. I also made some pictures of this process, using $R$ and the following code N=1000 d=rnorm(N) W=cumsum(d) c=W-0.5*(1:N) par(mfrow=c(2,2)) plot(W,type=""l"") plot(c,type=""l"") plot(exp(W),type=""l"") plot(exp(c),type=""1"") Which gives the output (the process $S_t$ is the one on the bottom on the right, and above is the process $W_t - t/2$, which resembles the straight line for large $t$): So I do not understand, if it should be a martingale then it should not approach zero for large $t$, instead it should stay around its starting value (for most samples of course, but this process will approach zero for most samples, so this is not just a random deviation)?",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'martingales']"
23,Probability a blackjack dealer will bust if you know their score and know the exact deck?,Probability a blackjack dealer will bust if you know their score and know the exact deck?,,"If you know the exact cards left in a deck, and the score of the dealer, how can you calculate the exact probability that they will bust? The dealer behaves as follows: If the dealer's score is less than 16, the dealer will ""hit"" and take another card. If the dealer has over 17 (even a ""soft"" score of 17 or greater with an ace and another 6 points from the other cards) the dealer will stay. And just for clarification, in the game of blackjack an Ace can count either as 11 points or 1 point, so if the score with 11 points is still under 21, it is called a ""soft"" hand, meaning if the next card would put you over 21, the ace can be counted as 1 point instead. I am able to calculate the probability of busting on the first hit as follows: $$ P(\text{busts on hit } | \text{ current score, deck}) = {(\text{# cards in deck where card + score} \gt 21) \over \text{total cards in deck}} $$ The issue I am running into is the recursive part, where the dealer must continue to hit if their score is less than 16. For instance, if the dealer has a score of 13 to start, they could hit and receive an ace, a 2 or a 3 and they would have to hit again. So the total probability of busting on the first or second hit would be something like: $$ P(\text{busts on first or second hit } | \text { current score, deck}) \\= P(\text{busting on first hit}) + P(\text{less than 16 on first hit and busting on second}) \\ = {(\text{# cards in deck where card + score} \gt 21) \over \text{total cards in deck}} \\ + \sum\limits_x P(\text{getting score of x on hit}) \times P(\text{busting on next hit with score of x}) $$ The problem seems to get even hairier when you consider that the dealer might receive several cards and still have less than 16, albeit with a low probability for most deck compositions. Is there an elegant (or at least less awful) way to express/calculate this recursive term in this problem?","If you know the exact cards left in a deck, and the score of the dealer, how can you calculate the exact probability that they will bust? The dealer behaves as follows: If the dealer's score is less than 16, the dealer will ""hit"" and take another card. If the dealer has over 17 (even a ""soft"" score of 17 or greater with an ace and another 6 points from the other cards) the dealer will stay. And just for clarification, in the game of blackjack an Ace can count either as 11 points or 1 point, so if the score with 11 points is still under 21, it is called a ""soft"" hand, meaning if the next card would put you over 21, the ace can be counted as 1 point instead. I am able to calculate the probability of busting on the first hit as follows: $$ P(\text{busts on hit } | \text{ current score, deck}) = {(\text{# cards in deck where card + score} \gt 21) \over \text{total cards in deck}} $$ The issue I am running into is the recursive part, where the dealer must continue to hit if their score is less than 16. For instance, if the dealer has a score of 13 to start, they could hit and receive an ace, a 2 or a 3 and they would have to hit again. So the total probability of busting on the first or second hit would be something like: $$ P(\text{busts on first or second hit } | \text { current score, deck}) \\= P(\text{busting on first hit}) + P(\text{less than 16 on first hit and busting on second}) \\ = {(\text{# cards in deck where card + score} \gt 21) \over \text{total cards in deck}} \\ + \sum\limits_x P(\text{getting score of x on hit}) \times P(\text{busting on next hit with score of x}) $$ The problem seems to get even hairier when you consider that the dealer might receive several cards and still have less than 16, albeit with a low probability for most deck compositions. Is there an elegant (or at least less awful) way to express/calculate this recursive term in this problem?",,"['probability', 'combinatorics', 'card-games']"
24,What's the best approach for a red light so you'll pass at maximum speed when it turns green?,What's the best approach for a red light so you'll pass at maximum speed when it turns green?,,"So me and a couple of friends were driving back home when we started wondering about this (admittedly silly) question. Say you are driving your car on a straight lane and see a red light up ahead. What is the best course of action to do, so that when it turns green you'll pass it at maximum speed possible? For sake of simplicity, we're putting aside more complicated situations like if the road is curved or uphill or there are other cars or whatever. All you have is a pretty decent assumption of the length between you and the traffic light, and knowing that the red light will change between, say, the next 1 and 45 seconds. To clarify, we obviously understand there's no fullproof solution that will always work, because we don't know the exact timing until the light turns green. Instead we're looking for a constant mathematical method that will work most of the time (i.e., where the percentage of success is the highest possible), and that will also not break any laws (we can't apply a method where we speed up and hope it changes, we have to account for the possibility of having to stop if it doesn't on time). Also, assume we're only interested in saving time (ignore gas usage and other issues). Thank you all","So me and a couple of friends were driving back home when we started wondering about this (admittedly silly) question. Say you are driving your car on a straight lane and see a red light up ahead. What is the best course of action to do, so that when it turns green you'll pass it at maximum speed possible? For sake of simplicity, we're putting aside more complicated situations like if the road is curved or uphill or there are other cars or whatever. All you have is a pretty decent assumption of the length between you and the traffic light, and knowing that the red light will change between, say, the next 1 and 45 seconds. To clarify, we obviously understand there's no fullproof solution that will always work, because we don't know the exact timing until the light turns green. Instead we're looking for a constant mathematical method that will work most of the time (i.e., where the percentage of success is the highest possible), and that will also not break any laws (we can't apply a method where we speed up and hope it changes, we have to account for the possibility of having to stop if it doesn't on time). Also, assume we're only interested in saving time (ignore gas usage and other issues). Thank you all",,"['probability', 'optimization']"
25,Uniform distribution on a sphere,Uniform distribution on a sphere,,Consider the unit ball $S_n$ (centered at the origin) in $\mathbb{R}^n$ for $n \ge 1$ and a stochastic process $(X_t)_{t\ge 0}$ taking values in $\mathbb{R}^n$. Let $T = \inf\{t > 0 \colon X_t \in \partial S_n\}$ i.e. the first hitting time of the boundary of the unit circle. I know that the distribution of $X_T$ is uniform on $\partial S_n$ but I am unsure how to write this. Is it acceptable to write $$\mathbb{P}(X_T \in d\textbf{x}) = d\textbf{x}$$ for $\textbf{x} \in \partial S_n$?,Consider the unit ball $S_n$ (centered at the origin) in $\mathbb{R}^n$ for $n \ge 1$ and a stochastic process $(X_t)_{t\ge 0}$ taking values in $\mathbb{R}^n$. Let $T = \inf\{t > 0 \colon X_t \in \partial S_n\}$ i.e. the first hitting time of the boundary of the unit circle. I know that the distribution of $X_T$ is uniform on $\partial S_n$ but I am unsure how to write this. Is it acceptable to write $$\mathbb{P}(X_T \in d\textbf{x}) = d\textbf{x}$$ for $\textbf{x} \in \partial S_n$?,,"['probability', 'geometry', 'probability-theory', 'probability-distributions']"
26,How to use Laplace method to get the asymptotic expansion of multiple integral,How to use Laplace method to get the asymptotic expansion of multiple integral,,"I meet difficulty when I try to get the asymptotic behaviour of multiple integral as x tends to plus infinity. And $-1<$p$<1$ $$\int_x^{+\infty}\int_x^{+\infty}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (u^2+2puv+v^2)}}dudv$$First, I can transform the variable to move x into integrant.$$\int_0^{+\infty}\int_0^{+\infty}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (u^2+2puv+v^2+(2+2p)x^2+(2+2p)(u+v)x)}}dudv$$ Then,apply transform: $$ \   \left\{     \begin{aligned}       &a=u+v\\       &b=v     \end{aligned}   \right. $$ I get $$\int_0^{+\infty}\int_0^{a}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (a^2+(2p-2)ab+(2-2p)b^2)+(2+2p)ax}+(2+2p)x^2}dbda$$ To apply Laplace method, I have to  view the first part of the integrant as a function g(a), and show that g is not too bad. But it seems that I cannot prove that. Or maybe I have made things worse. We can try another transform: $$ \   \left\{     \begin{aligned}       &a=u+pv\\       &b=v     \end{aligned}   \right. $$ Then get $$\int_x^{+\infty}\int_{pb+x}^{+\infty}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (a^2+(1-p^2)b^2)}}dadb$$ The asymototic behavior of the error function may be inappropriate here, since pb+x may fail to tend to infinity. But when $p\ge0$, we have $pb+x\ge x$, thus the integral can be controled by $$\int_x^{+\infty}\int_{x}^{+\infty}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (a^2+(1-p^2)b^2)}}dadb$$, then we can apply the asymptotic expension of error function. When $p<0$, it is a problem. However, the spirit of Laplace method is to calculate the integral near the extremum point of the integrant. So I think the first way to deal with the problem is clear. Any suggestion would be appreciated.","I meet difficulty when I try to get the asymptotic behaviour of multiple integral as x tends to plus infinity. And $-1<$p$<1$ $$\int_x^{+\infty}\int_x^{+\infty}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (u^2+2puv+v^2)}}dudv$$First, I can transform the variable to move x into integrant.$$\int_0^{+\infty}\int_0^{+\infty}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (u^2+2puv+v^2+(2+2p)x^2+(2+2p)(u+v)x)}}dudv$$ Then,apply transform: $$ \   \left\{     \begin{aligned}       &a=u+v\\       &b=v     \end{aligned}   \right. $$ I get $$\int_0^{+\infty}\int_0^{a}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (a^2+(2p-2)ab+(2-2p)b^2)+(2+2p)ax}+(2+2p)x^2}dbda$$ To apply Laplace method, I have to  view the first part of the integrant as a function g(a), and show that g is not too bad. But it seems that I cannot prove that. Or maybe I have made things worse. We can try another transform: $$ \   \left\{     \begin{aligned}       &a=u+pv\\       &b=v     \end{aligned}   \right. $$ Then get $$\int_x^{+\infty}\int_{pb+x}^{+\infty}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (a^2+(1-p^2)b^2)}}dadb$$ The asymototic behavior of the error function may be inappropriate here, since pb+x may fail to tend to infinity. But when $p\ge0$, we have $pb+x\ge x$, thus the integral can be controled by $$\int_x^{+\infty}\int_{x}^{+\infty}e^{-{\frac{1}{2\sigma^2(1-p^2)}\ \ (a^2+(1-p^2)b^2)}}dadb$$, then we can apply the asymptotic expension of error function. When $p<0$, it is a problem. However, the spirit of Laplace method is to calculate the integral near the extremum point of the integrant. So I think the first way to deal with the problem is clear. Any suggestion would be appreciated.",,"['probability', 'integration', 'asymptotics', 'statistical-inference']"
27,"If I assign a random number $r_x \in (0,1)$ to every $x \in (0,1)$ what are the odds that one of them will be a specific number?",If I assign a random number  to every  what are the odds that one of them will be a specific number?,"r_x \in (0,1) x \in (0,1)","I'll start by motivating by question with a simpler scenario to ensure I've at least understood that scenario properly. Scenario 1 : Imagine an infinite sequence of numbers where $i$ is the $i^{th}$ element of that sequence. If I assign a random number $r_i \in (0,1)$ to each $i$, and then ask ""What are the odds that for at least one $i$ we have $r_i = a$ ?"" where $a$ is some specific pre-chosen number in $(0,1)$ (say $0.5$), I believe I am correct in assuming that such an $i$ will almost never exist because $\aleph_0 = |\mathbb{N}| < |(0,1)| = \mathfrak{c}$. Is this reasoning accurate ? Scenario 2 : So now I would like to consider another infinite set of random numbers, but this time I'd like to replace my discrete infinite sequence with a sort of continuous equivalent, which I suppose is somewhat similar to a random function. Namely, for every real number in $x \in (0,1)$ I associate a random number $r_x \in (0,1)$. Now I again ask the question ""What are the odds that for some $x$ we have $r_x = a$ ?"". Here I'm really not sure what to think. It's certainly possible that the very scenario I'm describing cannot be rigorously defined and no such set of $r_x$ can exist, in which case I'd appreciate an explanation as to why this is so and what the closest possible scenario is. Conversely, feel free to more rigorously define my problem. Michael provided a solution to a seemingly related problem that's somewhere in between scenario 1 and 2 and so I'll post it here to see if anyone can extend this type of thinking to the reals : 1) Choose some natural number $n$ 2) List the naturals from $1$ to $n$ (let's call this set $\mathbb{N}_n$) 3) For each number in $\mathbb{N}_n$ randomly assign another number in $\mathbb{N}_n$ We can then see that the probability that some randomly chosen number $a \in \mathbb{N}$ never appears is $(1-1/n)^n$, which approaches $1/e$ as $n\to\infty$.  The chance that it does appear therefore approaches $1-1/e=0.632$. Is there any way to extend this to all reals between $0$ and $1$ ? After a little digging, I've come to think that perhaps there can't be an answer to my question, or if there is I'm probably in way over my head trying to find one. Let's define the problem a little more rigorously first : 1) Consider the family of sets $S_x$ where $S_x = (0,1) \forall x \in (0,1)$ (yes these are all the same set, why I'm considering this family will become apparent in step 2). 2) Using the axiom of choice, construct a set $R$ which contains one randomly chosen element from each $S_x$. This set $R$ is non-measurable. 3) Pick some number $a \in (0,1)$, and ask what are the odds that $a \in R$ is true ? And now I'm simply not sure what to make of the fact that $R$ is non-measurable. Does it make my question unanswerable ? Or does it actually provide a great test case for understanding non-measurable sets ?","I'll start by motivating by question with a simpler scenario to ensure I've at least understood that scenario properly. Scenario 1 : Imagine an infinite sequence of numbers where $i$ is the $i^{th}$ element of that sequence. If I assign a random number $r_i \in (0,1)$ to each $i$, and then ask ""What are the odds that for at least one $i$ we have $r_i = a$ ?"" where $a$ is some specific pre-chosen number in $(0,1)$ (say $0.5$), I believe I am correct in assuming that such an $i$ will almost never exist because $\aleph_0 = |\mathbb{N}| < |(0,1)| = \mathfrak{c}$. Is this reasoning accurate ? Scenario 2 : So now I would like to consider another infinite set of random numbers, but this time I'd like to replace my discrete infinite sequence with a sort of continuous equivalent, which I suppose is somewhat similar to a random function. Namely, for every real number in $x \in (0,1)$ I associate a random number $r_x \in (0,1)$. Now I again ask the question ""What are the odds that for some $x$ we have $r_x = a$ ?"". Here I'm really not sure what to think. It's certainly possible that the very scenario I'm describing cannot be rigorously defined and no such set of $r_x$ can exist, in which case I'd appreciate an explanation as to why this is so and what the closest possible scenario is. Conversely, feel free to more rigorously define my problem. Michael provided a solution to a seemingly related problem that's somewhere in between scenario 1 and 2 and so I'll post it here to see if anyone can extend this type of thinking to the reals : 1) Choose some natural number $n$ 2) List the naturals from $1$ to $n$ (let's call this set $\mathbb{N}_n$) 3) For each number in $\mathbb{N}_n$ randomly assign another number in $\mathbb{N}_n$ We can then see that the probability that some randomly chosen number $a \in \mathbb{N}$ never appears is $(1-1/n)^n$, which approaches $1/e$ as $n\to\infty$.  The chance that it does appear therefore approaches $1-1/e=0.632$. Is there any way to extend this to all reals between $0$ and $1$ ? After a little digging, I've come to think that perhaps there can't be an answer to my question, or if there is I'm probably in way over my head trying to find one. Let's define the problem a little more rigorously first : 1) Consider the family of sets $S_x$ where $S_x = (0,1) \forall x \in (0,1)$ (yes these are all the same set, why I'm considering this family will become apparent in step 2). 2) Using the axiom of choice, construct a set $R$ which contains one randomly chosen element from each $S_x$. This set $R$ is non-measurable. 3) Pick some number $a \in (0,1)$, and ask what are the odds that $a \in R$ is true ? And now I'm simply not sure what to make of the fact that $R$ is non-measurable. Does it make my question unanswerable ? Or does it actually provide a great test case for understanding non-measurable sets ?",,"['probability', 'axiom-of-choice', 'random-functions']"
28,Sampling distribution of sample trimmed (truncated) mean,Sampling distribution of sample trimmed (truncated) mean,,"It is elementary probability theory that the sample mean of an i.i.d. sample follows normal distribution, if the background distribution is normal. But what about the trimmed mean? Is there any result on its distribution for an i.i.d. sample of size $n$ ? (For normal or general population distribution.) My only idea is to use the results for the distribution of order statistics (summing them, taking their non-independence into account), but it seems exceedingly complicated, perhaps there is an easier way... EDIT (2021-08-12): See the answer here .","It is elementary probability theory that the sample mean of an i.i.d. sample follows normal distribution, if the background distribution is normal. But what about the trimmed mean? Is there any result on its distribution for an i.i.d. sample of size ? (For normal or general population distribution.) My only idea is to use the results for the distribution of order statistics (summing them, taking their non-independence into account), but it seems exceedingly complicated, perhaps there is an easier way... EDIT (2021-08-12): See the answer here .",n,"['probability', 'statistics', 'probability-distributions', 'statistical-inference', 'order-statistics']"
29,Random Variables and Moment Generating functions,Random Variables and Moment Generating functions,,"Let $(X_i)_{i\Bbb{N^+}}$ be a sequence of i.i.d random variables and for $n  \Bbb{N^+}$ set $S_n := \sum _{i=1}^{n} X_i$ and $Y_n := max(X_1, . . . , X_n)$. Assume that the moment generating function exists and has continuous derivatives. (the constant h is the radius of the interval containing zero for which the moment generating function exists). 1. Show that $x\Bbb{R}$ and $t>0, \,I_{\{x\le c\}}\le e^{t(cx)} $ and hence $P(X_i \le c)\le e^{tc} m_{X_i}(t)$ for $0 < t < h$. I understand why the indicator function statement is true but don't know how to show the second bit. I would guess that you take probabilities of both sides and hence if $x\le c$ (from the indicator function statement) $P(X_i \le c)\le P(e^{t(cx)}), $ pulling out terms independent of x, we have $ = e^{tc}P(e^{-tx})=e^{tc}m_{X_i}(-t). $ I feel what I have done lacks mathematical accuracy. 2. Show that $x\Bbb{R}$ and $t>0,\,I_{\{x> c\}} \le e^{t(x-c)} $ and hence $P(S_n >a)\le e^{at} [m_{X}(t)]^n$ for $0 < t < h$. Once again, I understand why the indicator function statement is true but don't know how to show the second bit. If I follow the logic from part 1, replacing the $c$ with an $a$ and then taking probabilities of both sides we have $P(S_n>a)\le P(e^{t(x-a)})=e^{-at}P(e^{tx})=e^{-at}[m_{X}(t)]^n.$ because it's a sum from $1$ to $n$. 3. Use the facts that $m_X(0) = 1$ and $m_X(0) = E(X)$ to show that if $E(X) < 0$, then there exist $0<c<1$ with $P(S_n >a)\le c^n$, using the mean value theorem. I have no idea for this one. 4.If one scales the random variable $Y_n$ using appropriate sequences of real numbers, $(a_n)_{n\Bbb{N^+}}$ and $(b_n)_{n\Bbb{N^+}}$, then $\frac{Y_na_n}{b_n}$ converges to a non-trivial random variable with a non-trivial distribution. Let $(X_i)_{i\Bbb{N^+}}$ be a sequence of i.i.d. $exp()$ random variables, show that for $n\Bbb{N^+}$, if we set $a_n =\lambda log(n)$ and $b_n =$ then $$\lim_{n\to \infty} P(b_n^{1}(Y_na_n)\le x)=e^{e^{x}}$$ I don't have much of a clue for this one as well.","Let $(X_i)_{i\Bbb{N^+}}$ be a sequence of i.i.d random variables and for $n  \Bbb{N^+}$ set $S_n := \sum _{i=1}^{n} X_i$ and $Y_n := max(X_1, . . . , X_n)$. Assume that the moment generating function exists and has continuous derivatives. (the constant h is the radius of the interval containing zero for which the moment generating function exists). 1. Show that $x\Bbb{R}$ and $t>0, \,I_{\{x\le c\}}\le e^{t(cx)} $ and hence $P(X_i \le c)\le e^{tc} m_{X_i}(t)$ for $0 < t < h$. I understand why the indicator function statement is true but don't know how to show the second bit. I would guess that you take probabilities of both sides and hence if $x\le c$ (from the indicator function statement) $P(X_i \le c)\le P(e^{t(cx)}), $ pulling out terms independent of x, we have $ = e^{tc}P(e^{-tx})=e^{tc}m_{X_i}(-t). $ I feel what I have done lacks mathematical accuracy. 2. Show that $x\Bbb{R}$ and $t>0,\,I_{\{x> c\}} \le e^{t(x-c)} $ and hence $P(S_n >a)\le e^{at} [m_{X}(t)]^n$ for $0 < t < h$. Once again, I understand why the indicator function statement is true but don't know how to show the second bit. If I follow the logic from part 1, replacing the $c$ with an $a$ and then taking probabilities of both sides we have $P(S_n>a)\le P(e^{t(x-a)})=e^{-at}P(e^{tx})=e^{-at}[m_{X}(t)]^n.$ because it's a sum from $1$ to $n$. 3. Use the facts that $m_X(0) = 1$ and $m_X(0) = E(X)$ to show that if $E(X) < 0$, then there exist $0<c<1$ with $P(S_n >a)\le c^n$, using the mean value theorem. I have no idea for this one. 4.If one scales the random variable $Y_n$ using appropriate sequences of real numbers, $(a_n)_{n\Bbb{N^+}}$ and $(b_n)_{n\Bbb{N^+}}$, then $\frac{Y_na_n}{b_n}$ converges to a non-trivial random variable with a non-trivial distribution. Let $(X_i)_{i\Bbb{N^+}}$ be a sequence of i.i.d. $exp()$ random variables, show that for $n\Bbb{N^+}$, if we set $a_n =\lambda log(n)$ and $b_n =$ then $$\lim_{n\to \infty} P(b_n^{1}(Y_na_n)\le x)=e^{e^{x}}$$ I don't have much of a clue for this one as well.",,"['probability', 'probability-theory']"
30,How to prove the sign test,How to prove the sign test,,"Please correct me if I'm wrong, but a version of the sign test assumes under $H_0$ that there is some distribution $F$ where $X_i \sim F, Y_i \sim F$ and $X_i, Y_i$ are iid. Then it states that $T = \#\{x_i > y_i\}$ follows a binomial distribution $B(m, 0.5)$ where $m = \#\{x_i \ne y_i\}$. The fact that $T$ follows a binomial distribution is intuitive (I can see that $\Pr(X_i < Y_i) = \Pr(Y_i < X_i)$ by symmetry), but how do you justify this formally?","Please correct me if I'm wrong, but a version of the sign test assumes under $H_0$ that there is some distribution $F$ where $X_i \sim F, Y_i \sim F$ and $X_i, Y_i$ are iid. Then it states that $T = \#\{x_i > y_i\}$ follows a binomial distribution $B(m, 0.5)$ where $m = \#\{x_i \ne y_i\}$. The fact that $T$ follows a binomial distribution is intuitive (I can see that $\Pr(X_i < Y_i) = \Pr(Y_i < X_i)$ by symmetry), but how do you justify this formally?",,"['probability', 'statistics', 'hypothesis-testing']"
31,A convolution involving binomials,A convolution involving binomials,,"Given $$f(i)\gt0,\:g(i)>0,\:i =0,1,2,3,...\:$$and$$\sum_{i=0}^{\infty}f(i) = 1,\sum_{i=0}^{\infty}g(i) = 1$$Prove that, if$$\frac{g(l-k)f(k)}{\sum_{i=0}^{l}f(i)g(l-i)}=\binom{l}{k}p^k(1-p)^{l-k}\: when\:0\le k\le l,\:where\: 0\lt p\lt1$$then$$f(i) = e^{-ru}\frac{(ru)^i}{i!},\: g(i) = e^{-u}\frac{(u)^i}{i!},\:i =0,1,2,3,...\:where\:u\gt 0$$ Progress: Let $F(s)$ and $G(s)$ be the generating functions of $f(i)$ and $g(i)$ then the problem becomes $$\frac{F^{(k)}(0)G^{(l-k)}(0)}{\frac{1}{l!}\sum_{i=0}^{l}\binom{l}{i}F^{(i)}(0)G^{(l-i)}(0)} = p^{k}(1-p)^{(l-k)}$$ So I eliminated one binomial but introduced another!","Given $$f(i)\gt0,\:g(i)>0,\:i =0,1,2,3,...\:$$and$$\sum_{i=0}^{\infty}f(i) = 1,\sum_{i=0}^{\infty}g(i) = 1$$Prove that, if$$\frac{g(l-k)f(k)}{\sum_{i=0}^{l}f(i)g(l-i)}=\binom{l}{k}p^k(1-p)^{l-k}\: when\:0\le k\le l,\:where\: 0\lt p\lt1$$then$$f(i) = e^{-ru}\frac{(ru)^i}{i!},\: g(i) = e^{-u}\frac{(u)^i}{i!},\:i =0,1,2,3,...\:where\:u\gt 0$$ Progress: Let $F(s)$ and $G(s)$ be the generating functions of $f(i)$ and $g(i)$ then the problem becomes $$\frac{F^{(k)}(0)G^{(l-k)}(0)}{\frac{1}{l!}\sum_{i=0}^{l}\binom{l}{i}F^{(i)}(0)G^{(l-i)}(0)} = p^{k}(1-p)^{(l-k)}$$ So I eliminated one binomial but introduced another!",,"['probability', 'summation', 'binomial-coefficients', 'generating-functions', 'convolution']"
32,Stochastic continuity,Stochastic continuity,,"Let $(X_t)_{t \in \mathbb{R}}$ be a square-integrable real-valued process with a continuous mean value function $\mu:\mathbb{R}\rightarrow\mathbb{R}$ and a continuous covariance function $\Sigma:~\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$. I want to show, that this process is stochastic continuous  ($\lim_{s \rightarrow t} \mathbb{P}(|X_t - X_s| > \epsilon)=0~ \forall t \in \mathbb{R})$. My first idea was using the markov inequality, then I would get $\mathbb{P}(|X_t-X_s|>\epsilon) \leq \dfrac{\mathbb{E}(|X_t-X_s|^2)}{\epsilon^2} = \dfrac{\mathbb{E}(X_t^2-2X_tX_s+X_s^2)}{\epsilon^2} = \dfrac{\mathbb{E}(X_t^2)-2\mathbb{E}(X_tX_s)+\mathbb{E}(X_s^2)}{\epsilon^2}$. Is this a helpful beginning of the proof or is there a better way? And how can I proceed? Thanks in advance.","Let $(X_t)_{t \in \mathbb{R}}$ be a square-integrable real-valued process with a continuous mean value function $\mu:\mathbb{R}\rightarrow\mathbb{R}$ and a continuous covariance function $\Sigma:~\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$. I want to show, that this process is stochastic continuous  ($\lim_{s \rightarrow t} \mathbb{P}(|X_t - X_s| > \epsilon)=0~ \forall t \in \mathbb{R})$. My first idea was using the markov inequality, then I would get $\mathbb{P}(|X_t-X_s|>\epsilon) \leq \dfrac{\mathbb{E}(|X_t-X_s|^2)}{\epsilon^2} = \dfrac{\mathbb{E}(X_t^2-2X_tX_s+X_s^2)}{\epsilon^2} = \dfrac{\mathbb{E}(X_t^2)-2\mathbb{E}(X_tX_s)+\mathbb{E}(X_s^2)}{\epsilon^2}$. Is this a helpful beginning of the proof or is there a better way? And how can I proceed? Thanks in advance.",,"['real-analysis', 'probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus']"
33,Difference between conditional expectation and conditional probabilty,Difference between conditional expectation and conditional probabilty,,"These are known definitions : We have a probability space $(\Omega, A, P)$ Conditional probability is defined through $P(A|B) = \frac{P(A \cap B)}{P(B)}, P(B) > 0$. This is a real nunmber . Then also where is conditional expectation $E[X|A_0]$ with $A_0$ being some subalgebra. This is a random variable. In the special case when $A_0$ is generated by a random variable $Y$ we also write $E[X|\sigma(Y)] = E[X|Y]$ and using the factorization theorem you can also write $E[X|Y]$ as a RV of $Y$ which you then denote as $E[X|Y=y]$. For $X$ being in indicator function we sometimes also write $E[1_A | Y=y] =: P(A | Y = y)$ which confuses me very much, because this now is the evaluation of an only a.s. defined RV I am particular confused with the proof I state in this Question . Since the probability of $\{X_1 = i_1, ... X_{n-1} = i_{n-1}\}$ is 0 because the $X_i$ are real valued, the proof can't be talking about conditional probabilities. Thus I think the proof uses the sloppy notation for conditional expectation $E[1_B(X_n) | X_1 = i_1, ... X_{n-1} = i_{n-1}] =: P(X_n \in B | X_1 = i_1, ... X_{n-1} = i_{n-1})$. Now in this concept, I dont understand why the single steps in the proof are true. They are all obvious true for $P(|)$ being conditional probability, but in my eye not trivial for $P(|)$ being conditional expectations","These are known definitions : We have a probability space $(\Omega, A, P)$ Conditional probability is defined through $P(A|B) = \frac{P(A \cap B)}{P(B)}, P(B) > 0$. This is a real nunmber . Then also where is conditional expectation $E[X|A_0]$ with $A_0$ being some subalgebra. This is a random variable. In the special case when $A_0$ is generated by a random variable $Y$ we also write $E[X|\sigma(Y)] = E[X|Y]$ and using the factorization theorem you can also write $E[X|Y]$ as a RV of $Y$ which you then denote as $E[X|Y=y]$. For $X$ being in indicator function we sometimes also write $E[1_A | Y=y] =: P(A | Y = y)$ which confuses me very much, because this now is the evaluation of an only a.s. defined RV I am particular confused with the proof I state in this Question . Since the probability of $\{X_1 = i_1, ... X_{n-1} = i_{n-1}\}$ is 0 because the $X_i$ are real valued, the proof can't be talking about conditional probabilities. Thus I think the proof uses the sloppy notation for conditional expectation $E[1_B(X_n) | X_1 = i_1, ... X_{n-1} = i_{n-1}] =: P(X_n \in B | X_1 = i_1, ... X_{n-1} = i_{n-1})$. Now in this concept, I dont understand why the single steps in the proof are true. They are all obvious true for $P(|)$ being conditional probability, but in my eye not trivial for $P(|)$ being conditional expectations",,"['probability', 'probability-theory', 'markov-chains', 'conditional-expectation']"
34,Sequence of independent events in a discrete probability space,Sequence of independent events in a discrete probability space,,"Let $(\Omega, \mathcal{A}, \Bbb{P})$ be a discrete probability space. Let $A_1, A_2,...\in \mathcal{A}$ be a sequence of independent events with $p_n = \Bbb{P}(A_n)$. Then $$\sum_{n\in \Bbb{N}} \min(p_n, 1-p_n)< \infty$$ My attempt: Suppose toward contradiction that the sum diverges. Then in particular $\sum_n p_n = \infty$. Applying Borel-Cantelli gives us $\Bbb{P}\left( \bigcap_{n\in \Bbb{N}} \bigcup_{k\geq n} A_n \right) =1$. Discreteness then implies that $\Omega = \bigcap_{n\in \Bbb{N}} \bigcup_{k\geq n} A_n$, so each $\omega \in \Omega$ is contained in infinitely many $A_n$'s. On the other hand, since the sum diverges, we have that $0=\prod_{n\in \Bbb{N}} 1 - \min(p_n, 1-p_n) = \prod_{n\in \Bbb{N}} \max(1-p_n, p_n) \geq \prod_n p_n = \Bbb{P}(\bigcap_n A_n) \geq 0$, and thus $\emptyset = \bigcap_n A_n$. That's not really a contradiction yet, but I feel like I'm almost there. What can I do?","Let $(\Omega, \mathcal{A}, \Bbb{P})$ be a discrete probability space. Let $A_1, A_2,...\in \mathcal{A}$ be a sequence of independent events with $p_n = \Bbb{P}(A_n)$. Then $$\sum_{n\in \Bbb{N}} \min(p_n, 1-p_n)< \infty$$ My attempt: Suppose toward contradiction that the sum diverges. Then in particular $\sum_n p_n = \infty$. Applying Borel-Cantelli gives us $\Bbb{P}\left( \bigcap_{n\in \Bbb{N}} \bigcup_{k\geq n} A_n \right) =1$. Discreteness then implies that $\Omega = \bigcap_{n\in \Bbb{N}} \bigcup_{k\geq n} A_n$, so each $\omega \in \Omega$ is contained in infinitely many $A_n$'s. On the other hand, since the sum diverges, we have that $0=\prod_{n\in \Bbb{N}} 1 - \min(p_n, 1-p_n) = \prod_{n\in \Bbb{N}} \max(1-p_n, p_n) \geq \prod_n p_n = \Bbb{P}(\bigcap_n A_n) \geq 0$, and thus $\emptyset = \bigcap_n A_n$. That's not really a contradiction yet, but I feel like I'm almost there. What can I do?",,"['probability', 'statistics', 'probability-theory']"
35,Deriving master equation for discrete process,Deriving master equation for discrete process,,"Consider a group of $N$ professors, $Y$ of whom are wearing white socks and $X = N  Y$ others who are wearing black socks. On each time step, one professor is chosen at random and he has to put a new pair of socks on, irrespectively of the color of the socks he is currently wearing. The probability of the professor choosing a white pair of socks is $p$ and the probability of him choosing a black pair of socks is $1  p$, independently of the pair of socks he was previously wearing. a) How can I derive a master equation for the model of how the probability $\pi(i,t)$ that $i$ professors are wearing white socks at time $t$ changes throught time, that is, how $\pi(i,t+1)$ varies with $\pi(i,t)$, $\pi(i-1,t)$ and $\pi(i+1,t)$? b) How can I solve the master equation to show that, for $t \rightarrow \infty$, $$ \pi(i) = \left( \begin{array}{c} N\\ i\end{array} \right) p^i (1-p)^{N-i} \;?$$ MY ATTEMPT a) $$\begin{align} \pi(i,t+1) = & \pi(i-1,t) P(X\rightarrow Y) + \pi(i+1,t) P(Y\rightarrow X) + \\ & \pi(i,t) P(Y\rightarrow Y) + \pi(i,t) P(X\rightarrow X)\\ = & \pi(i-1,t) p \frac{N-(i-1)}{N} + \pi(i+1,t) (1-p) \frac{i+1}{N} + \\ & \pi(i,t) p \frac{i}{N} + \pi(i,t) (1-p) \frac{N-i}{N} \end{align}$$ Do you think this is correct? b) I've tried to assume $\pi(i)$ is as told, and then substitute it on the RHS of the master equation I derived, but I cannot reach an equality. Thanks in advance for all the help you can provide.","Consider a group of $N$ professors, $Y$ of whom are wearing white socks and $X = N  Y$ others who are wearing black socks. On each time step, one professor is chosen at random and he has to put a new pair of socks on, irrespectively of the color of the socks he is currently wearing. The probability of the professor choosing a white pair of socks is $p$ and the probability of him choosing a black pair of socks is $1  p$, independently of the pair of socks he was previously wearing. a) How can I derive a master equation for the model of how the probability $\pi(i,t)$ that $i$ professors are wearing white socks at time $t$ changes throught time, that is, how $\pi(i,t+1)$ varies with $\pi(i,t)$, $\pi(i-1,t)$ and $\pi(i+1,t)$? b) How can I solve the master equation to show that, for $t \rightarrow \infty$, $$ \pi(i) = \left( \begin{array}{c} N\\ i\end{array} \right) p^i (1-p)^{N-i} \;?$$ MY ATTEMPT a) $$\begin{align} \pi(i,t+1) = & \pi(i-1,t) P(X\rightarrow Y) + \pi(i+1,t) P(Y\rightarrow X) + \\ & \pi(i,t) P(Y\rightarrow Y) + \pi(i,t) P(X\rightarrow X)\\ = & \pi(i-1,t) p \frac{N-(i-1)}{N} + \pi(i+1,t) (1-p) \frac{i+1}{N} + \\ & \pi(i,t) p \frac{i}{N} + \pi(i,t) (1-p) \frac{N-i}{N} \end{align}$$ Do you think this is correct? b) I've tried to assume $\pi(i)$ is as told, and then substitute it on the RHS of the master equation I derived, but I cannot reach an equality. Thanks in advance for all the help you can provide.",,"['probability', 'probability-distributions', 'stochastic-processes']"
36,Distribution of Brownian Motion help,Distribution of Brownian Motion help,,"If $X = \frac{B_1 - B_3 + B_2}{\sqrt{2}}$ Where $B_t$ is brownian motion at time $t$ . And I want to find the the distribution of $X$ , how would I do so? $E[X] = 0$ is fairly straight forward. For variance, however, I run into difficulty in treating: \begin{equation*} Var(B_1 - B_3 + B_2) = Var( (B_1-B_3) + B_2)) = Var(B_1 - B_3) + Var(B_2) + 2Cov(B_1-B_3,B_2) \end{equation*} But $Var(B_1 - B_3)$ isn't defined... is it? Is there something I am missing, another method to calculate the variance of $X$ ? Edit: \begin{equation*}Var(X) = \frac{1}{2} [ Var(B_1 - B_3 + B_2)] = 0.5 [ Var( (B_1-B_3) + B_2))] = 0.5[Var(B_1 - B_3) + Var(B_2) + 2Cov(B_1-B_3,B_2)]  =  0.5 [ Var(B_1) + Var(B_3) + Var(B_2) + 2Cov(B_1-B_3,B_2) -2Cov(B_1,B_3)]= 2 ? \end{equation*}","If Where is brownian motion at time . And I want to find the the distribution of , how would I do so? is fairly straight forward. For variance, however, I run into difficulty in treating: But isn't defined... is it? Is there something I am missing, another method to calculate the variance of ? Edit:","X = \frac{B_1 - B_3 + B_2}{\sqrt{2}} B_t t X E[X] = 0 \begin{equation*}
Var(B_1 - B_3 + B_2) = Var( (B_1-B_3) + B_2)) = Var(B_1 - B_3) + Var(B_2) + 2Cov(B_1-B_3,B_2)
\end{equation*} Var(B_1 - B_3) X \begin{equation*}Var(X) = \frac{1}{2} [ Var(B_1 - B_3 + B_2)] = 0.5 [ Var( (B_1-B_3) + B_2))] = 0.5[Var(B_1 - B_3) + Var(B_2) + 2Cov(B_1-B_3,B_2)]
 =  0.5 [ Var(B_1) + Var(B_3) + Var(B_2) + 2Cov(B_1-B_3,B_2) -2Cov(B_1,B_3)]= 2 ?
\end{equation*}","['probability', 'stochastic-processes', 'brownian-motion', 'covariance']"
37,Is the following statement true on $L^0$ spaces?,Is the following statement true on  spaces?,L^0,"Let $(\Omega,\mathcal{F},P)$ be a probability space. Let $X,Y\in L^0(\Omega;\mathbb{R})$ two random variables taking values in $\mathbb{R}$. Is it true that: $$\int_{A} f(X(\omega)) P(d\omega) = \int_{A} f(Y(\omega)) dP(\omega)$$ for all $A\in \mathcal{F}$ and all Lipschitz continuous functions $f:\mathbb{R}\rightarrow \mathbb{R}$ then $$X=Y, \quad P-a.s.?$$ In other notation this is like saying: $$E[f(X)] = E[f(Y)] \quad \forall f\in Lip(\mathbb{R}) \Rightarrow X=Y,\quad P-a.s.$$ Could we also relax it to all $f$ continuous and bounded (not necessarily Lipschitz)? Thank you for the help :)","Let $(\Omega,\mathcal{F},P)$ be a probability space. Let $X,Y\in L^0(\Omega;\mathbb{R})$ two random variables taking values in $\mathbb{R}$. Is it true that: $$\int_{A} f(X(\omega)) P(d\omega) = \int_{A} f(Y(\omega)) dP(\omega)$$ for all $A\in \mathcal{F}$ and all Lipschitz continuous functions $f:\mathbb{R}\rightarrow \mathbb{R}$ then $$X=Y, \quad P-a.s.?$$ In other notation this is like saying: $$E[f(X)] = E[f(Y)] \quad \forall f\in Lip(\mathbb{R}) \Rightarrow X=Y,\quad P-a.s.$$ Could we also relax it to all $f$ continuous and bounded (not necessarily Lipschitz)? Thank you for the help :)",,"['real-analysis', 'probability', 'functional-analysis', 'measure-theory']"
38,Chess Probability 8 rooks,Chess Probability 8 rooks,,"You have 8 rooks. What is the probability of placing all 8 rooks on an 8 by 8 chess board with out one being able to hit each other? But there's a catch of course..one of the spaces is unavailable to be used. That being said, there could potentially be 2 rooks in a certain row or column. The unavailable space is 7 columns over and 7 rows down. Without the catch it would be $\frac{8!}{64\choose 8}$ I came up with.. $\frac{8\cdot{7\choose 2}6\cdot6\cdot5\cdot4\cdot3\cdot2}{63 \choose 8}$  but I don't think I'm correct.  Any advice/ideas?","You have 8 rooks. What is the probability of placing all 8 rooks on an 8 by 8 chess board with out one being able to hit each other? But there's a catch of course..one of the spaces is unavailable to be used. That being said, there could potentially be 2 rooks in a certain row or column. The unavailable space is 7 columns over and 7 rows down. Without the catch it would be $\frac{8!}{64\choose 8}$ I came up with.. $\frac{8\cdot{7\choose 2}6\cdot6\cdot5\cdot4\cdot3\cdot2}{63 \choose 8}$  but I don't think I'm correct.  Any advice/ideas?",,['probability']
39,how to determine transient and recurrent state from transition matrix,how to determine transient and recurrent state from transition matrix,,I wonder how can I determine the transient and recurrent state from transition matrix ? I mean if I have 10 states It would be very hard to draw diagram for them so how to analyse the matrix?      For example consider : $$ \begin{bmatrix} 0.1 & 0.2 & 0.7 & 0 \\ 0.7 & 0 & 0.2 & 0.1 \\ 0.6 & 0.4 & 0 & 0\\ 0 & 0.5 & 0.5 & 0 \end{bmatrix} $$ Can anyone tell me how to approach this problem I only want to know how to look at transition matrix and identify transient and recurrent states? Thanks.,I wonder how can I determine the transient and recurrent state from transition matrix ? I mean if I have 10 states It would be very hard to draw diagram for them so how to analyse the matrix?      For example consider : $$ \begin{bmatrix} 0.1 & 0.2 & 0.7 & 0 \\ 0.7 & 0 & 0.2 & 0.1 \\ 0.6 & 0.4 & 0 & 0\\ 0 & 0.5 & 0.5 & 0 \end{bmatrix} $$ Can anyone tell me how to approach this problem I only want to know how to look at transition matrix and identify transient and recurrent states? Thanks.,,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'markov-chains']"
40,Using CLT to calculate probability question,Using CLT to calculate probability question,,"Suppose $53$ percent of the population prefer red socks to green. If $100$ random people are asked, what is the probability that most (at least $50$) will say prefer GREEN: So I set \begin{align*} N & = 49.5\\   n & = 100\\   p & = 0.47 \end{align*} Then.. \begin{align*}    P(N \geq 49.5) & = P\left(\frac{N - np}{\sqrt{npq}}\right)\\                & \geq \frac{49.5 - 47}{\sqrt{100*.47*.53}}\\                   & = \varphi(0.50)\\                   & = 0.3085   \end{align*} Except, that's not the right answer. What did I do wrong in my calculations?","Suppose $53$ percent of the population prefer red socks to green. If $100$ random people are asked, what is the probability that most (at least $50$) will say prefer GREEN: So I set \begin{align*} N & = 49.5\\   n & = 100\\   p & = 0.47 \end{align*} Then.. \begin{align*}    P(N \geq 49.5) & = P\left(\frac{N - np}{\sqrt{npq}}\right)\\                & \geq \frac{49.5 - 47}{\sqrt{100*.47*.53}}\\                   & = \varphi(0.50)\\                   & = 0.3085   \end{align*} Except, that's not the right answer. What did I do wrong in my calculations?",,['probability']
41,Determining te probability that a message can not be corrected,Determining te probability that a message can not be corrected,,A bit error occurs with probability $10^{-7}$  . A message consists of 8000 bits. Upto three bit errors can be corrected at the receiver with FEC (Forward Error Correction) code in the message. Determine the probability that a message can not be corrected at the receiver. I thougt that a message contain three or less error with probability $$\begin{align} p & = \binom{8000}{3}\left(\frac{1}{10^7}\right)^3\left(1-\frac{1}{10^7}\right)^{7997} + \binom{8000}{2}\left(\frac{1}{10^7}\right)^2\left(1-\frac{1}{10^7}\right)^{7998} + \binom{8000}{1}\left(\frac{1}{10^7}\right)\left(1-\frac{1}{10^7}\right)^{7999} + \left(1-\frac{1}{10^7}\right)^{8000} \end{align}$$ so probability that a message can not be corrected is  $$ 1-p $$ Is this answer right?,A bit error occurs with probability $10^{-7}$  . A message consists of 8000 bits. Upto three bit errors can be corrected at the receiver with FEC (Forward Error Correction) code in the message. Determine the probability that a message can not be corrected at the receiver. I thougt that a message contain three or less error with probability $$\begin{align} p & = \binom{8000}{3}\left(\frac{1}{10^7}\right)^3\left(1-\frac{1}{10^7}\right)^{7997} + \binom{8000}{2}\left(\frac{1}{10^7}\right)^2\left(1-\frac{1}{10^7}\right)^{7998} + \binom{8000}{1}\left(\frac{1}{10^7}\right)\left(1-\frac{1}{10^7}\right)^{7999} + \left(1-\frac{1}{10^7}\right)^{8000} \end{align}$$ so probability that a message can not be corrected is  $$ 1-p $$ Is this answer right?,,"['probability', 'combinatorics', 'solution-verification']"
42,"Compute the covariance of $\xi$ and $\min \{\xi,2\}$, where $\xi$ is exponentially distributed","Compute the covariance of  and , where  is exponentially distributed","\xi \min \{\xi,2\} \xi","Let $\xi$ be a random variable exponentially distributed and let $\xi_1=\min \{\xi,2\}$. Calculate $Cov(\xi,\xi_1)$. I know the problem is easy but I just need somebody to check my work. Here's my solution. $$ E(\xi\cdot\xi_1)=\int_0^\infty x\cdot\min(x,2)\cdot\lambda\exp(-\lambda x) \,dx= \int_0^2x^2\lambda e^{-\lambda x} \,dx+2\int_2^\infty x\lambda e^{-\lambda x} \,dx=\int_0^{2\lambda} \lambda^{-2} t^2e^{-t}\,dt +\frac{2}{\lambda}\int_{2\lambda}^{\infty}te^{-t}\,dt=\frac{-e^{-t}(t^2+2t+2)}{\lambda^2}|_{t=0}^{2\lambda}+\frac{-2(1+t)e^{-t}}{\lambda}|_{t=2\lambda}^{\infty}=\frac{2}{\lambda^2}(1-e^{-2\lambda}(\lambda+1)). $$ Next $$ E(\xi_1)=\int_0^{\infty}\min(x,2)\lambda e^{-\lambda x}\,dx=\int_0^2 x\lambda e^{-\lambda x}\,dx+2\int_2^\infty\lambda e^{-\lambda x}\,dx=\lambda^{-1} \int_0^{2 \lambda}te^{-t}\,dt+\int_{2\lambda}^{\infty}2e^{-t}\,dt=\frac{-e^{-t}(1+t)}{\lambda}|_{t=0}^{2\lambda}-2e^{-t}|_{t=2\lambda}^{\infty}=\frac{1-e^{-2\lambda}(1+2\lambda)}{\lambda}+2e^{-2\lambda}=\frac{1-e^{-2\lambda}}{\lambda}. $$ Hence $$ Cov(\xi,\xi_1)=E(\xi\cdot\xi_1)-E\xi\cdot E\xi_1=\frac{2}{\lambda^2}(1-e^{-2\lambda}(\lambda+1))-\frac{1-e^{-2\lambda}}{\lambda^2}=\frac{1-e^{-2\lambda}-2\lambda e^{-2\lambda}}{\lambda^2} $$ Could you please check whether it is correct?","Let $\xi$ be a random variable exponentially distributed and let $\xi_1=\min \{\xi,2\}$. Calculate $Cov(\xi,\xi_1)$. I know the problem is easy but I just need somebody to check my work. Here's my solution. $$ E(\xi\cdot\xi_1)=\int_0^\infty x\cdot\min(x,2)\cdot\lambda\exp(-\lambda x) \,dx= \int_0^2x^2\lambda e^{-\lambda x} \,dx+2\int_2^\infty x\lambda e^{-\lambda x} \,dx=\int_0^{2\lambda} \lambda^{-2} t^2e^{-t}\,dt +\frac{2}{\lambda}\int_{2\lambda}^{\infty}te^{-t}\,dt=\frac{-e^{-t}(t^2+2t+2)}{\lambda^2}|_{t=0}^{2\lambda}+\frac{-2(1+t)e^{-t}}{\lambda}|_{t=2\lambda}^{\infty}=\frac{2}{\lambda^2}(1-e^{-2\lambda}(\lambda+1)). $$ Next $$ E(\xi_1)=\int_0^{\infty}\min(x,2)\lambda e^{-\lambda x}\,dx=\int_0^2 x\lambda e^{-\lambda x}\,dx+2\int_2^\infty\lambda e^{-\lambda x}\,dx=\lambda^{-1} \int_0^{2 \lambda}te^{-t}\,dt+\int_{2\lambda}^{\infty}2e^{-t}\,dt=\frac{-e^{-t}(1+t)}{\lambda}|_{t=0}^{2\lambda}-2e^{-t}|_{t=2\lambda}^{\infty}=\frac{1-e^{-2\lambda}(1+2\lambda)}{\lambda}+2e^{-2\lambda}=\frac{1-e^{-2\lambda}}{\lambda}. $$ Hence $$ Cov(\xi,\xi_1)=E(\xi\cdot\xi_1)-E\xi\cdot E\xi_1=\frac{2}{\lambda^2}(1-e^{-2\lambda}(\lambda+1))-\frac{1-e^{-2\lambda}}{\lambda^2}=\frac{1-e^{-2\lambda}-2\lambda e^{-2\lambda}}{\lambda^2} $$ Could you please check whether it is correct?",,"['probability', 'probability-distributions']"
43,Combinatorics and Probability- where am I wrong?,Combinatorics and Probability- where am I wrong?,,"Let there be a cube with $n$ sides denoted $1,...,n$ each. The cube is tossed $n+1$ times. For $1\le k\le n$, what is the probability that exactly $k$ first tosses give different number (i.e, the $(k+1)$-st toss give a number that was already gotten.) I really need to know why I got a slightly different answer from the official one. My attempt: Let us build a uniform sample space. $\Omega=\{a_i=(i_1,...,i_k)|1\le i_j\le n\}$. $|\Omega|=(n+1)^n$, $\forall \omega\in \Omega, P(\omega)={1\over |\Omega|}$. We seek for the event $A=\{(i_1,...,i_k,i_{k+1},...,i_{n+1})|i_t\ne i_s, \forall 1\le t\ne s\le k, k\in \{i_1,...,i_k\}\}$. This is the problematic part: $|A|={n\choose k}\cdot k!\cdot k \cdot n^{n-k-1} $. (Then I and the answer use the formula for probability of an even it a uniform sample space.) The point is, the answer says: $|A|={n\choose k}\cdot k!\cdot k \cdot n^{n-k} $. I don't understand why; First I pick $k$ numbers, count all their permutations, then pick one of them for the $(k+1)$-th toss, and then I have $n-k-1$ tosses left, each of which has $n$ possibilities. I would appreciate your help.","Let there be a cube with $n$ sides denoted $1,...,n$ each. The cube is tossed $n+1$ times. For $1\le k\le n$, what is the probability that exactly $k$ first tosses give different number (i.e, the $(k+1)$-st toss give a number that was already gotten.) I really need to know why I got a slightly different answer from the official one. My attempt: Let us build a uniform sample space. $\Omega=\{a_i=(i_1,...,i_k)|1\le i_j\le n\}$. $|\Omega|=(n+1)^n$, $\forall \omega\in \Omega, P(\omega)={1\over |\Omega|}$. We seek for the event $A=\{(i_1,...,i_k,i_{k+1},...,i_{n+1})|i_t\ne i_s, \forall 1\le t\ne s\le k, k\in \{i_1,...,i_k\}\}$. This is the problematic part: $|A|={n\choose k}\cdot k!\cdot k \cdot n^{n-k-1} $. (Then I and the answer use the formula for probability of an even it a uniform sample space.) The point is, the answer says: $|A|={n\choose k}\cdot k!\cdot k \cdot n^{n-k} $. I don't understand why; First I pick $k$ numbers, count all their permutations, then pick one of them for the $(k+1)$-th toss, and then I have $n-k-1$ tosses left, each of which has $n$ possibilities. I would appreciate your help.",,"['probability', 'combinatorics']"
44,Calculate probability of nodes in a graph,Calculate probability of nodes in a graph,,I have the following graph: A and F post the same joke on Facebook. Now there is a probability of 0.6 that node b will post the joke too. and so on... So the weights on the edges say how likely it is that this node will post the joke if the previous node posted it. Now I wonder how many of the nodes will have posted this joke in average after 4 Timesteps. Can anyone help me with this? I am very new to probability-theory. Thank you very much!,I have the following graph: A and F post the same joke on Facebook. Now there is a probability of 0.6 that node b will post the joke too. and so on... So the weights on the edges say how likely it is that this node will post the joke if the previous node posted it. Now I wonder how many of the nodes will have posted this joke in average after 4 Timesteps. Can anyone help me with this? I am very new to probability-theory. Thank you very much!,,"['probability', 'probability-theory', 'graph-theory']"
45,Expected length of minimum chord,Expected length of minimum chord,,"You are given a circle of radius $1$. Suppose you pick $n$ independent points randomly on the circle and join neighboring points with lines to create chords. What is the expected length of the shortest chord? I thought about doing this using angles from the center, i.e. minimize $E[\min 2\sin(\theta_i / 2)]$ where $\theta_i$ are random on $[0, 2\pi]$ and sum of $\theta_i = 2\pi$. But not really sure where to go about it from here.","You are given a circle of radius $1$. Suppose you pick $n$ independent points randomly on the circle and join neighboring points with lines to create chords. What is the expected length of the shortest chord? I thought about doing this using angles from the center, i.e. minimize $E[\min 2\sin(\theta_i / 2)]$ where $\theta_i$ are random on $[0, 2\pi]$ and sum of $\theta_i = 2\pi$. But not really sure where to go about it from here.",,"['probability', 'geometry', 'expectation', 'geometric-probability']"
46,Random signs - a remark of david williams:probability with martingales,Random signs - a remark of david williams:probability with martingales,,"This can be found in David Williams p.113-114. Suppose that $(a_n)$ is a sequence of real numbers and that $(\epsilon_n)$ is a sequence of IID random variables with $P(\epsilon_n=\pm1)=\frac{1}{2}$. The result of 12.2 shows that $(1) \sum \epsilon_na_n \text{ converges a.s. if and only if} \sum a_n^2<\infty $ and $(2)\sum\epsilon_na_n \text{ oscillates infinitely if and only if} \sum a_n^2=\infty $ It's very clear to me why the first equivalence is true. Just the usage of 12.2 in David Williams which states that: (12.2) $\sum X_k \text{ converges a.s. if and only if} \sum Var(X_k)<\infty$ for a sequence of independent zero mean random variables $(X_k)$. I want to understand now why the second equivalence is true. For $""\Rightarrow""$: If $\liminf_{n\rightarrow \infty}\sum \epsilon_na_n\neq \limsup_{n\rightarrow \infty}\sum \epsilon_na_n$ then $\sum \epsilon_na_n$ does not converge and theorem 12.2 yields that $\sum Var(\epsilon_na_n)=\sum a_n^2=\infty$ as desired. But now I don't how to show the other direction. Can someone help?","This can be found in David Williams p.113-114. Suppose that $(a_n)$ is a sequence of real numbers and that $(\epsilon_n)$ is a sequence of IID random variables with $P(\epsilon_n=\pm1)=\frac{1}{2}$. The result of 12.2 shows that $(1) \sum \epsilon_na_n \text{ converges a.s. if and only if} \sum a_n^2<\infty $ and $(2)\sum\epsilon_na_n \text{ oscillates infinitely if and only if} \sum a_n^2=\infty $ It's very clear to me why the first equivalence is true. Just the usage of 12.2 in David Williams which states that: (12.2) $\sum X_k \text{ converges a.s. if and only if} \sum Var(X_k)<\infty$ for a sequence of independent zero mean random variables $(X_k)$. I want to understand now why the second equivalence is true. For $""\Rightarrow""$: If $\liminf_{n\rightarrow \infty}\sum \epsilon_na_n\neq \limsup_{n\rightarrow \infty}\sum \epsilon_na_n$ then $\sum \epsilon_na_n$ does not converge and theorem 12.2 yields that $\sum Var(\epsilon_na_n)=\sum a_n^2=\infty$ as desired. But now I don't how to show the other direction. Can someone help?",,"['probability', 'probability-theory', 'expectation', 'almost-everywhere']"
47,Cambridge Mathematical Tripos Question - 1871,Cambridge Mathematical Tripos Question - 1871,,"This is a question from the Cambridge Mathematical Tripos in 1871, Scanned copy added at the end of the post. A ship $A$ sees another ship    $B$ whose course is not known. Given that they have the same speed, prove that chance of them coming within a distance $d$ of each other is always $\frac{2sin^{-1}(\frac{d}{a})}{\pi}$ no matter the course of $A$, provided that it's inclination to $AB$ is not greater than $cos^{-1}(\frac{d}{a})$where $AB=a$ This is a summary of my method so far: First I constructed a vector triangle $ABC$ where $C$ was the intersection of the courses of $A$ and $B$. In this triangle I denoted the angle between $A$ and $AB$ as $\theta$ and $B$ and $AB$ as $\phi$. I then used trigonometry to get an expression for $d$ which I subsequently differentiated with respect to time and set as a minimum so I could get $t=\frac{b+c}{2v}$ where $v$ is the velocity of the ships. Using this I got $d=acos(\frac{\theta + \phi}{2})$ which implies $\phi=2cos^{-1}(\frac{d}{a})-\theta$ Could someone help me proceed and  post a solution themselves if they have a better method? It would also be helpful if you could point out if this is possible to complete having only high school maths knowledge.","This is a question from the Cambridge Mathematical Tripos in 1871, Scanned copy added at the end of the post. A ship $A$ sees another ship    $B$ whose course is not known. Given that they have the same speed, prove that chance of them coming within a distance $d$ of each other is always $\frac{2sin^{-1}(\frac{d}{a})}{\pi}$ no matter the course of $A$, provided that it's inclination to $AB$ is not greater than $cos^{-1}(\frac{d}{a})$where $AB=a$ This is a summary of my method so far: First I constructed a vector triangle $ABC$ where $C$ was the intersection of the courses of $A$ and $B$. In this triangle I denoted the angle between $A$ and $AB$ as $\theta$ and $B$ and $AB$ as $\phi$. I then used trigonometry to get an expression for $d$ which I subsequently differentiated with respect to time and set as a minimum so I could get $t=\frac{b+c}{2v}$ where $v$ is the velocity of the ships. Using this I got $d=acos(\frac{\theta + \phi}{2})$ which implies $\phi=2cos^{-1}(\frac{d}{a})-\theta$ Could someone help me proceed and  post a solution themselves if they have a better method? It would also be helpful if you could point out if this is possible to complete having only high school maths knowledge.",,"['probability', 'classical-mechanics']"
48,disintegration of infinite convex combination of measures,disintegration of infinite convex combination of measures,,"One expects that the disintegration (under a map $X \to Y$) of a convex combination of probability measures on X is the convex combination of disintegration of the measures. My question is if this can be stated rigorously and proved. I suspect that its proof is trivial once the correct statement is formulated, but I am stuck at how to state it precisely. Background ($M(X)$ denotes the set of probability measures on $X$) Given a Borel map $\pi: X \to Y$ between standard Borel spaces, any probability measure $\mu \in M(X)$ can be decomposed into two parts: its pushforward image $\pi \mu \in M(Y)$ and its disintegration $y \in Y \mapsto \mu_y \in M(X)$. The disintegration $y \mapsto \mu_y$ is unique in the $\pi\mu$-a.e. sense. Now suppose $\mu \in M(X)$ is given as some infinite convex combination of other measures on X. In other words, suppose $\mu = \int_A \mu^\alpha\ d\rho(\alpha)$ where $A$ is another standard Borel space and $\alpha \in A \mapsto \mu^\alpha \in M(X)$ is a Borel map and $\rho \in M(A)$. One can check that the pushforward image $\pi\mu$ is the $\rho$ convex combination of $\pi(\mu^\alpha)$. In other words, $$\pi\mu = \int_A \pi(\mu^\alpha) \ d\rho(\alpha)$$ And one then intuitively expects the following proposition: The disintegration $y \mapsto \mu_y$ is the $\rho$ convex combination   of the disintegration $y \mapsto (\mu^\alpha)_y$, in other words,   $$\mu_y = \int_A (\mu^\alpha)_y \ d\rho(\alpha)$$ But the integrand on the right side does not seem measurable and even if it is measurable, perturbing each $y \mapsto (\mu^\alpha)_y$ on a $\pi(\mu^\alpha)$-null set can perturb $y \mapsto \int_A (\mu^\alpha)_y \ d\rho(\alpha)$ on the whole Y (this issue can be demonstrated with a simple example with finite $A$), so the proposition as stated is false. How should I modify the proposition to make it true? Example demonstrating the issue Let $\mu = \frac12 \mu^1 + \frac12 \mu^2$ where $\mu^1, \mu^2 \in M([0,1]\times[0,1])$ are the uniform distributions on $[0,1]\times [0,\frac12]$, $[0,1]\times [\frac12, 1]$ respectively. Then $\mu$ is the uniform distribution on the unit square $[0,1]\times [0,1]$. Denote by $\lambda$ the uniform distribution on $[0,1]$, i.e., the Lebesgue measure restricted to $[0,1]$. Denote by $\delta_y$ the Dirac measure on $y \in [0,1]$. The map $y \mapsto \mu^1_y$ defined by $$\mu^1_y =  \begin{cases}   \lambda \times \delta_y & \text{if } y \in [0,\frac12] \\   \delta_0 \times \delta_0 & \text{otherwise} \end{cases} $$ is a disintegration of $\mu^1$ w.r.t. the 2nd projection map $\pi: [0,1]\times [0,1] \to [0,1]$ defined by $\pi(x,y) = y$. Similarly, the map $y \mapsto \mu^2_y$ defined by $$\mu^2_y =  \begin{cases}   \lambda \times \delta_y & \text{if } y \in [\frac12,1] \\   \delta_0 \times \delta_0 & \text{otherwise } \end{cases} $$ is a disintegration of $\mu^2$ w.r.t. the same $\pi$. On the other hand, the map $y \mapsto \frac12 \mu^1_y + \frac12 \mu^2_y$ is not a disintegration of $\mu$ w.r.t. $\pi$.","One expects that the disintegration (under a map $X \to Y$) of a convex combination of probability measures on X is the convex combination of disintegration of the measures. My question is if this can be stated rigorously and proved. I suspect that its proof is trivial once the correct statement is formulated, but I am stuck at how to state it precisely. Background ($M(X)$ denotes the set of probability measures on $X$) Given a Borel map $\pi: X \to Y$ between standard Borel spaces, any probability measure $\mu \in M(X)$ can be decomposed into two parts: its pushforward image $\pi \mu \in M(Y)$ and its disintegration $y \in Y \mapsto \mu_y \in M(X)$. The disintegration $y \mapsto \mu_y$ is unique in the $\pi\mu$-a.e. sense. Now suppose $\mu \in M(X)$ is given as some infinite convex combination of other measures on X. In other words, suppose $\mu = \int_A \mu^\alpha\ d\rho(\alpha)$ where $A$ is another standard Borel space and $\alpha \in A \mapsto \mu^\alpha \in M(X)$ is a Borel map and $\rho \in M(A)$. One can check that the pushforward image $\pi\mu$ is the $\rho$ convex combination of $\pi(\mu^\alpha)$. In other words, $$\pi\mu = \int_A \pi(\mu^\alpha) \ d\rho(\alpha)$$ And one then intuitively expects the following proposition: The disintegration $y \mapsto \mu_y$ is the $\rho$ convex combination   of the disintegration $y \mapsto (\mu^\alpha)_y$, in other words,   $$\mu_y = \int_A (\mu^\alpha)_y \ d\rho(\alpha)$$ But the integrand on the right side does not seem measurable and even if it is measurable, perturbing each $y \mapsto (\mu^\alpha)_y$ on a $\pi(\mu^\alpha)$-null set can perturb $y \mapsto \int_A (\mu^\alpha)_y \ d\rho(\alpha)$ on the whole Y (this issue can be demonstrated with a simple example with finite $A$), so the proposition as stated is false. How should I modify the proposition to make it true? Example demonstrating the issue Let $\mu = \frac12 \mu^1 + \frac12 \mu^2$ where $\mu^1, \mu^2 \in M([0,1]\times[0,1])$ are the uniform distributions on $[0,1]\times [0,\frac12]$, $[0,1]\times [\frac12, 1]$ respectively. Then $\mu$ is the uniform distribution on the unit square $[0,1]\times [0,1]$. Denote by $\lambda$ the uniform distribution on $[0,1]$, i.e., the Lebesgue measure restricted to $[0,1]$. Denote by $\delta_y$ the Dirac measure on $y \in [0,1]$. The map $y \mapsto \mu^1_y$ defined by $$\mu^1_y =  \begin{cases}   \lambda \times \delta_y & \text{if } y \in [0,\frac12] \\   \delta_0 \times \delta_0 & \text{otherwise} \end{cases} $$ is a disintegration of $\mu^1$ w.r.t. the 2nd projection map $\pi: [0,1]\times [0,1] \to [0,1]$ defined by $\pi(x,y) = y$. Similarly, the map $y \mapsto \mu^2_y$ defined by $$\mu^2_y =  \begin{cases}   \lambda \times \delta_y & \text{if } y \in [\frac12,1] \\   \delta_0 \times \delta_0 & \text{otherwise } \end{cases} $$ is a disintegration of $\mu^2$ w.r.t. the same $\pi$. On the other hand, the map $y \mapsto \frac12 \mu^1_y + \frac12 \mu^2_y$ is not a disintegration of $\mu$ w.r.t. $\pi$.",,"['probability', 'measure-theory']"
49,Is a symmetrical fair odd-faced die posssible?,Is a symmetrical fair odd-faced die posssible?,,"I can't come up with a scenario for a 5-faced die, but maybe 9 or 27 is possible?","I can't come up with a scenario for a 5-faced die, but maybe 9 or 27 is possible?",,"['probability', 'geometry']"
50,What is the probability distribution for this question? [duplicate],What is the probability distribution for this question? [duplicate],,"This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 8 years ago . I tried to find the probability distribution for this problem and then calculate the expectation of $n$. I suppose the total states of our problem would be $52^n$ and our desired states would be $52$ combination of n with permutation $52!$ for distinct cards and our probability function will be $p(n)=\frac{n!}{(n-52)!(52^n)}$ with $n = 52,53, ....$ But the summation over $p(n)$ is not $1$. I don't know what is wrong with this solution. Can anybody help? Thank you so much","This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 8 years ago . I tried to find the probability distribution for this problem and then calculate the expectation of $n$. I suppose the total states of our problem would be $52^n$ and our desired states would be $52$ combination of n with permutation $52!$ for distinct cards and our probability function will be $p(n)=\frac{n!}{(n-52)!(52^n)}$ with $n = 52,53, ....$ But the summation over $p(n)$ is not $1$. I don't know what is wrong with this solution. Can anybody help? Thank you so much",,"['probability', 'statistics', 'coupon-collector']"
51,Strong law of large numbers for square-integrable and uncorrelated random variables with bounded variance,Strong law of large numbers for square-integrable and uncorrelated random variables with bounded variance,,"Let $(\Omega,\mathcal{A},P)$ be a probability space and  $(X_n)_{n\in\mathbb{N}}$ be a sequence of square-integrable and uncorrelated (maybe we actually need independence) random variables $\Omega\to [0,\infty]$ with $V:=\sup_{n\in\mathbb{N}}\operatorname{Var}X_n<\infty$. Moreover, let $$X^{(n)}:=\sum_{i=1}^nX_i\;\;\;\text{and}\;\;\;\overline{X}^{(n)}:=\frac{1}{n}X^{(n)}$$ I want to show, that it holds: $$\limsup_{i\to\infty}\left|\overline{X}^{(i)}-E\left[\overline{X}^{(i)}\right]\right|=0\;\;\;\text{almost surely}\tag{1}$$ Proof : Let $\varepsilon>0$ and $$k_n:=\lfloor(1+\varepsilon)^n\rfloor\ge\frac{1}{2}(1+\varepsilon)^n\tag{2}$$ Chebyshev's inequality yields \begin{equation} \begin{split} \sum_{n\in\mathbb{N}}\Pr\left[\left|\overline{X}^{(k_n)}-E\left[\overline{X}^{(k_n)}\right]\right|\ge\frac{1}{(1+\varepsilon)^{n/4}}\right]&\le&\sum_{n\in\mathbb{N}}(1+\varepsilon)^{n/2}\operatorname{Var}\overline{X}^{(k_n)}\\ &\stackrel{(*)}{\le}&\sum_{n\in\mathbb{N}}(1+\varepsilon)^{n/2}\frac{V}{k_n}\\&\stackrel{\text{(2)}}{\le}&2V\sum_{n\in\mathbb{N}}\frac{1}{(1+\varepsilon)^{n/2}}&<\infty \end{split} \end{equation} where $(*)$ holds by uncorrelatedness and the formula of Bienaym . Thus, the lemma of Borel-Cantelli yields $$\Pr\left[\limsup_{n\to\infty}\left\{\left|\overline{X}^{(k_n)}-E\left[\overline{X}^{(k_n)}\right]\right|\ge\frac{1}{(1+\varepsilon)^{n/4}}\right\}\right]=0,$$ i.e. there is a $n\in\mathbb{N}$, such that for all $m\ge n$ $$\left|\overline{X}^{(k_n)}-E\left[\overline{X}^{(k_n)}\right]\right|<\frac{1}{(1+\varepsilon)^{n/4}}\;\;\;\text{almost surely}$$ So, we've got $$\limsup_{n\to\infty}\left|\overline{X}^{(k_n)}-E\left[\overline{X}^{(k_n)}\right]\right|=0\;\;\;\text{alsmost surely}\tag{3}$$ Now, observe that $$k_{n+1}\le(1+2\varepsilon)k_n$$ which implies that  \begin{equation} \begin{split} \frac{1}{1+2\varepsilon}\overline{X}^{(k_n)}&\le& \frac{k_n}{k_{n+1}}\overline{X}^{(k_n)}\\ &=&\frac{1}{k_{n+1}}X^{(k_n)}\\&\le& \overline{X}^{(i)}\\&\le&\frac{1}{k_n}X^{(k_{n+1})}\\&\le &(1+2\varepsilon)\overline{X}^{(k_{n+1})} \end{split}\tag{4} \end{equation} for all $i\in [k_n,k_{n+1}]\cap\mathbb{N}$. How can we conclude, that $$L:=\limsup_{i\to\infty}\left|\overline{X}^{(i)}-E\left[\overline{X}^{(i)}\right]\right|=0\tag{5}$$ almost surely? My first idea was to use $(4)$ to see that $$L\le\limsup_{n\to\infty}\left|(1+2\varepsilon)\overline{X}^{(k_{n+1})}-E\left[\frac{1}{1+2\varepsilon}\overline{X}^{(k_n)}\right]\right|\tag{6}$$However, I am not able to take advantage of $(3)$ in $(6)$.","Let $(\Omega,\mathcal{A},P)$ be a probability space and  $(X_n)_{n\in\mathbb{N}}$ be a sequence of square-integrable and uncorrelated (maybe we actually need independence) random variables $\Omega\to [0,\infty]$ with $V:=\sup_{n\in\mathbb{N}}\operatorname{Var}X_n<\infty$. Moreover, let $$X^{(n)}:=\sum_{i=1}^nX_i\;\;\;\text{and}\;\;\;\overline{X}^{(n)}:=\frac{1}{n}X^{(n)}$$ I want to show, that it holds: $$\limsup_{i\to\infty}\left|\overline{X}^{(i)}-E\left[\overline{X}^{(i)}\right]\right|=0\;\;\;\text{almost surely}\tag{1}$$ Proof : Let $\varepsilon>0$ and $$k_n:=\lfloor(1+\varepsilon)^n\rfloor\ge\frac{1}{2}(1+\varepsilon)^n\tag{2}$$ Chebyshev's inequality yields \begin{equation} \begin{split} \sum_{n\in\mathbb{N}}\Pr\left[\left|\overline{X}^{(k_n)}-E\left[\overline{X}^{(k_n)}\right]\right|\ge\frac{1}{(1+\varepsilon)^{n/4}}\right]&\le&\sum_{n\in\mathbb{N}}(1+\varepsilon)^{n/2}\operatorname{Var}\overline{X}^{(k_n)}\\ &\stackrel{(*)}{\le}&\sum_{n\in\mathbb{N}}(1+\varepsilon)^{n/2}\frac{V}{k_n}\\&\stackrel{\text{(2)}}{\le}&2V\sum_{n\in\mathbb{N}}\frac{1}{(1+\varepsilon)^{n/2}}&<\infty \end{split} \end{equation} where $(*)$ holds by uncorrelatedness and the formula of Bienaym . Thus, the lemma of Borel-Cantelli yields $$\Pr\left[\limsup_{n\to\infty}\left\{\left|\overline{X}^{(k_n)}-E\left[\overline{X}^{(k_n)}\right]\right|\ge\frac{1}{(1+\varepsilon)^{n/4}}\right\}\right]=0,$$ i.e. there is a $n\in\mathbb{N}$, such that for all $m\ge n$ $$\left|\overline{X}^{(k_n)}-E\left[\overline{X}^{(k_n)}\right]\right|<\frac{1}{(1+\varepsilon)^{n/4}}\;\;\;\text{almost surely}$$ So, we've got $$\limsup_{n\to\infty}\left|\overline{X}^{(k_n)}-E\left[\overline{X}^{(k_n)}\right]\right|=0\;\;\;\text{alsmost surely}\tag{3}$$ Now, observe that $$k_{n+1}\le(1+2\varepsilon)k_n$$ which implies that  \begin{equation} \begin{split} \frac{1}{1+2\varepsilon}\overline{X}^{(k_n)}&\le& \frac{k_n}{k_{n+1}}\overline{X}^{(k_n)}\\ &=&\frac{1}{k_{n+1}}X^{(k_n)}\\&\le& \overline{X}^{(i)}\\&\le&\frac{1}{k_n}X^{(k_{n+1})}\\&\le &(1+2\varepsilon)\overline{X}^{(k_{n+1})} \end{split}\tag{4} \end{equation} for all $i\in [k_n,k_{n+1}]\cap\mathbb{N}$. How can we conclude, that $$L:=\limsup_{i\to\infty}\left|\overline{X}^{(i)}-E\left[\overline{X}^{(i)}\right]\right|=0\tag{5}$$ almost surely? My first idea was to use $(4)$ to see that $$L\le\limsup_{n\to\infty}\left|(1+2\varepsilon)\overline{X}^{(k_{n+1})}-E\left[\frac{1}{1+2\varepsilon}\overline{X}^{(k_n)}\right]\right|\tag{6}$$However, I am not able to take advantage of $(3)$ in $(6)$.",,"['real-analysis', 'probability', 'measure-theory', 'probability-theory']"
52,How to write $1-x-x^3+x^4+x^5+x^6-x^7 \cdots$ as a power series representation,How to write  as a power series representation,1-x-x^3+x^4+x^5+x^6-x^7 \cdots,"How can I write $1-x-x^3+x^4+x^5+x^6-x^7 ....$ as a power series representation (i.e., a neat fraction such as $\frac{1}{1-x}$. This stems from $\binom{\text{number of partitions of }n}{\text{into an even number of parts}}-\binom{\text{number of partitions of }n}{\text{into an odd number of parts}}$. I've been pondering this for a while, yet can't seem to think of any ways to solve this. Any hints? EDIT: The polynominal with a few extra terms i: $1-x-x^3+x^4+x^5+x^6-x^7+2x^8-2x^9+2x^{10}-2x^{11}+3x^{12}-3x^{13}+3x^{14} ...$","How can I write $1-x-x^3+x^4+x^5+x^6-x^7 ....$ as a power series representation (i.e., a neat fraction such as $\frac{1}{1-x}$. This stems from $\binom{\text{number of partitions of }n}{\text{into an even number of parts}}-\binom{\text{number of partitions of }n}{\text{into an odd number of parts}}$. I've been pondering this for a while, yet can't seem to think of any ways to solve this. Any hints? EDIT: The polynominal with a few extra terms i: $1-x-x^3+x^4+x^5+x^6-x^7+2x^8-2x^9+2x^{10}-2x^{11}+3x^{12}-3x^{13}+3x^{14} ...$",,"['probability', 'power-series', 'generating-functions']"
53,Distributing candies,Distributing candies,,"Suppose ther are B boys and G girls in a classroom.Teacher wants to distribute candies among B boys and G girls such that: 1.Each student gets atleast one candy and atmost N candies. 2.sum of candies given to all boys equals sum of candies given to all girls. find the number of different ways to do it. Note :Two ways are considered different if there exists a student that received different number of candies in these two candies' distributions. Example:  if B=1 G=2 N=3 there are 3 ways, they are: (2, 1, 1), (3, 1, 2), (3, 2, 1). if B=2 G=2 N=2 there are 6 ways, they are: (1, 1, 1, 1), (1, 2, 1, 2), (1, 2, 2, 1), (2, 1, 1, 2), (2, 1, 2, 1), (2, 2, 2, 2). How to approach this problem?","Suppose ther are B boys and G girls in a classroom.Teacher wants to distribute candies among B boys and G girls such that: 1.Each student gets atleast one candy and atmost N candies. 2.sum of candies given to all boys equals sum of candies given to all girls. find the number of different ways to do it. Note :Two ways are considered different if there exists a student that received different number of candies in these two candies' distributions. Example:  if B=1 G=2 N=3 there are 3 ways, they are: (2, 1, 1), (3, 1, 2), (3, 2, 1). if B=2 G=2 N=2 there are 6 ways, they are: (1, 1, 1, 1), (1, 2, 1, 2), (1, 2, 2, 1), (2, 1, 1, 2), (2, 1, 2, 1), (2, 2, 2, 2). How to approach this problem?",,"['probability', 'combinatorics', 'permutations']"
54,Convergence of third moment in central limit theorem,Convergence of third moment in central limit theorem,,"Previously, I asked a question here about the rate of convergence of expectations of absolute values to the expected value of a Gaussian. If $Z_1,Z_2,Z_3,\ldots$ are i.i.d. with $P(Z_i=-1) = P(Z_i=+1) = \frac 12,$ then we have by the Central Limit Theorem that   $\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\stackrel{d}{\to} \mathcal{N}(0,1),$   so that for any continuous bounded function $f,$ we have   $\mathbb{E}f\left(\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\right)\to\mathbb{E}f(W)$ where $W\sim\mathcal{N}(0,1).$   Now, $|\cdot|$ is not a bounded function, so it is not necessarily   true that $$\mathbb{E}\left|\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\right|\to\mathbb{E}|W|.$$ But uniform integrability guarantees the convergence $\mathbb{E}\left|\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\right|\to\mathbb{E}|W|.$ How fast does it converge? My question today is: Do we have uniform integrability in this specific example for all moments? In other words, for what $p$ is the following true? $$\mathbb{E}\left|\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\right|^p\to\mathbb{E}|W|^p.$$ I know the answer is YES for $p=1,2$ but suspect it is NO for $p=3,4,\ldots.$","Previously, I asked a question here about the rate of convergence of expectations of absolute values to the expected value of a Gaussian. If $Z_1,Z_2,Z_3,\ldots$ are i.i.d. with $P(Z_i=-1) = P(Z_i=+1) = \frac 12,$ then we have by the Central Limit Theorem that   $\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\stackrel{d}{\to} \mathcal{N}(0,1),$   so that for any continuous bounded function $f,$ we have   $\mathbb{E}f\left(\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\right)\to\mathbb{E}f(W)$ where $W\sim\mathcal{N}(0,1).$   Now, $|\cdot|$ is not a bounded function, so it is not necessarily   true that $$\mathbb{E}\left|\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\right|\to\mathbb{E}|W|.$$ But uniform integrability guarantees the convergence $\mathbb{E}\left|\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\right|\to\mathbb{E}|W|.$ How fast does it converge? My question today is: Do we have uniform integrability in this specific example for all moments? In other words, for what $p$ is the following true? $$\mathbb{E}\left|\frac{\sum_{i=1}^n Z_i}{\sqrt{n}}\right|^p\to\mathbb{E}|W|^p.$$ I know the answer is YES for $p=1,2$ but suspect it is NO for $p=3,4,\ldots.$",,"['probability', 'convergence-divergence', 'probability-limit-theorems']"
55,Average time to fill boxes with balls,Average time to fill boxes with balls,,"Let's have n users with each having a ball and m boxes . The users put their ball in a random box. It takes exactly 10 seconds for all balls to be put in a random box (independently to the number of users). When the 10 seconds are passed, we remove the boxes with at least one ball and start the process again (each user get a new ball) until there is no boxes left. We know that each iteration takes exactly 10 seconds, hence: average_execution_time = average_iteration_count * 10 How can we calculate the average iteration count? Here I describe an analog problem but it will help modelling a distributed computing problem.","Let's have n users with each having a ball and m boxes . The users put their ball in a random box. It takes exactly 10 seconds for all balls to be put in a random box (independently to the number of users). When the 10 seconds are passed, we remove the boxes with at least one ball and start the process again (each user get a new ball) until there is no boxes left. We know that each iteration takes exactly 10 seconds, hence: average_execution_time = average_iteration_count * 10 How can we calculate the average iteration count? Here I describe an analog problem but it will help modelling a distributed computing problem.",,"['probability', 'combinatorics']"
56,Shannon Entropy Continuity Constraint,Shannon Entropy Continuity Constraint,,"I have the following problem: I want to find the probability density $p$ which maximizes the Shannon entropy  \begin{equation} S := - \int_{x_b}^{x_c} dx ~ p(x) \log (p(x)) \end{equation} under the following constraints: normalization $p(x_b) = v$ for some fixed value $v$ $p$ is continuous. Usually, such problems can be solved using a Lagrange multiplier.  My problem is: how can I impose the continuity condition in terms of Lagrange multipliers?","I have the following problem: I want to find the probability density $p$ which maximizes the Shannon entropy  \begin{equation} S := - \int_{x_b}^{x_c} dx ~ p(x) \log (p(x)) \end{equation} under the following constraints: normalization $p(x_b) = v$ for some fixed value $v$ $p$ is continuous. Usually, such problems can be solved using a Lagrange multiplier.  My problem is: how can I impose the continuity condition in terms of Lagrange multipliers?",,"['probability', 'optimization', 'continuity', 'entropy']"
57,delta-method-ish question,delta-method-ish question,,"This is a problem from Resnick's heavy tail analysis book: Let $\{X_n\}$ be a sequence of random variables such that $EX_n=m$ and Var$(X_n)=\sigma_n^2>0$ for all $n$, where $\sigma_n^2\rightarrow 0$ as $n\rightarrow\infty$ Define $$Z_n=\sigma_{n}^{-1} (X_n-m)$$ and let $f$ be a function with non-zero derivative $f'(m)$ at $m$. Show that (1) $X_n-m\Rightarrow0$ (2)   If $$Y_n=\frac{f(X_n)-f(m)}{\sigma_n^{-1}f'(m)}$$show that $Y_n-Z_n\Rightarrow 0$ (3)Show that if $Z_n$ converges in probability or in distribution, then so does $Y_n$. (4)If $S_n$ is binomially distributed with parameters $n$ and $p$ and $f'(p)\ne0$, use the preceding results to determine the asymptotic distribution of $f(S_n/n)$ Attempted solution (1)It suffices to show that $X_m-m\rightarrow 0$ in probability which can follows easily by Chebyshev's inequality. (2) I am not sure how to do this one. Since we are only given that the function is differentiable at $m$, it seems that Taylor theorem is the way to go. So rewriting this question using Taylor expansion in the first degree, we have $$f(X_n)=f(m)+f'(m)(X_n-m)+h(X_n)(X_n-m)$$ and rearrange the term and dividing by $\sigma_n$ we get $$\frac{f(X_n)-f(m)}{\sigma_n f'(m)}-\frac{X_n-m}{\sigma_nf'(m)}=\frac{h(X_n)(X_n-m)}{\sigma_n f'(m)}$$ I got stuck here since I don't know what to do with RHS.. I didn't figure out (3) and (4) since i believe they rely on the result of (2)..Can someone explain what this problem is trying to say? I think it looks like Delta method in statistics..","This is a problem from Resnick's heavy tail analysis book: Let $\{X_n\}$ be a sequence of random variables such that $EX_n=m$ and Var$(X_n)=\sigma_n^2>0$ for all $n$, where $\sigma_n^2\rightarrow 0$ as $n\rightarrow\infty$ Define $$Z_n=\sigma_{n}^{-1} (X_n-m)$$ and let $f$ be a function with non-zero derivative $f'(m)$ at $m$. Show that (1) $X_n-m\Rightarrow0$ (2)   If $$Y_n=\frac{f(X_n)-f(m)}{\sigma_n^{-1}f'(m)}$$show that $Y_n-Z_n\Rightarrow 0$ (3)Show that if $Z_n$ converges in probability or in distribution, then so does $Y_n$. (4)If $S_n$ is binomially distributed with parameters $n$ and $p$ and $f'(p)\ne0$, use the preceding results to determine the asymptotic distribution of $f(S_n/n)$ Attempted solution (1)It suffices to show that $X_m-m\rightarrow 0$ in probability which can follows easily by Chebyshev's inequality. (2) I am not sure how to do this one. Since we are only given that the function is differentiable at $m$, it seems that Taylor theorem is the way to go. So rewriting this question using Taylor expansion in the first degree, we have $$f(X_n)=f(m)+f'(m)(X_n-m)+h(X_n)(X_n-m)$$ and rearrange the term and dividing by $\sigma_n$ we get $$\frac{f(X_n)-f(m)}{\sigma_n f'(m)}-\frac{X_n-m}{\sigma_nf'(m)}=\frac{h(X_n)(X_n-m)}{\sigma_n f'(m)}$$ I got stuck here since I don't know what to do with RHS.. I didn't figure out (3) and (4) since i believe they rely on the result of (2)..Can someone explain what this problem is trying to say? I think it looks like Delta method in statistics..",,"['real-analysis', 'probability', 'statistics', 'probability-theory']"
58,Exercise from Norris' book on Markov chains,Exercise from Norris' book on Markov chains,,"Let $(X_n)$ be a Markov chain on $\mathbb{N}$ with transition probabilities satisfying: $$p_{0,1}=1,\quad p_{i,i-1}+p_{i,i+1}=1,\quad p_{i,i+1}=\left(\frac{i+1}{i}\right)^{\alpha}p_{i,i-1}$$ The exercise asks to find $\mathbb{P}(X_n\to \infty\;\text{as}\;n\to\infty)$ The problem is that I am having real trouble getting started off, because I cannot express the event $X_n\to\infty$ in a more suitable form. Any help on this would be greatly appreciated. My first thought was: $$\mathbb{P}(X_n\to\infty)=\prod_k\mathbb{P}(X_n\geq k\;\text{eventually})=\prod_k \mathbb{P}(X_n \neq 0,\cdots X_n\neq k-1\;\text{eventually})$$ But I am having trouble with translating ""eventually"".","Let $(X_n)$ be a Markov chain on $\mathbb{N}$ with transition probabilities satisfying: $$p_{0,1}=1,\quad p_{i,i-1}+p_{i,i+1}=1,\quad p_{i,i+1}=\left(\frac{i+1}{i}\right)^{\alpha}p_{i,i-1}$$ The exercise asks to find $\mathbb{P}(X_n\to \infty\;\text{as}\;n\to\infty)$ The problem is that I am having real trouble getting started off, because I cannot express the event $X_n\to\infty$ in a more suitable form. Any help on this would be greatly appreciated. My first thought was: $$\mathbb{P}(X_n\to\infty)=\prod_k\mathbb{P}(X_n\geq k\;\text{eventually})=\prod_k \mathbb{P}(X_n \neq 0,\cdots X_n\neq k-1\;\text{eventually})$$ But I am having trouble with translating ""eventually"".",,"['probability', 'markov-chains', 'probability-limit-theorems']"
59,Probability density function with the help of the Laplace (Fourier) transform,Probability density function with the help of the Laplace (Fourier) transform,,"I am reading a paper that derives a closed form expression of the following probability using properties from Fourier transform, $$ \mathbb{P} \biggl( F \geq T \ (I+W) \biggl)$$ Assumptions: 1- Assume that the $F$ has a finite first moment and admits a square integrable density $f(y)$. 2- $I$ and $W$ are independent and either one admits a density which is square integrable. 3- $I+W$ admits a density $g(t)$. 4- $T$ is a constant The proof is presented next, Proof $$\begin{align} \mathbb{P} \biggl( F \geq T(I+W) \biggl)&= \int_{0}^{\infty} f(y) \  \mathbb{P} \biggl(I+W<y/T \biggl)\\ &= \int_{0}^{+\infty} f(y) \ \int_{-\infty}^{+\infty} g(t) \ 1(0<t<y/T) dt \\ &\stackrel{?}{=} \int_{0}^{+\infty} f(y)\int_{-\infty}^{+\infty} \mathcal{L}_{I}(-2 i \pi s)\mathcal{L}_{W}(-2i\pi s)\times \frac{e^{2i\pi ys/T }-1}{2i\pi s} ds dy\\ &\stackrel{?}{=} \int_{0}^{+\infty} f(y)\int_{-\infty}^{+\infty} \mathcal{L}_{I}(-2 i \pi s T)\mathcal{L}_{W}(-2i\pi sT)\times \frac{e^{2i\pi ys }-1}{2i\pi s} ds dy\\ &\stackrel{?}{=}\int_{-\infty}^{+\infty} \mathcal{L}_{I}(2 i \pi s T)\mathcal{L}_{W}(2i\pi sT)\times \frac{\mathcal{L_F}(-2i\pi s )-1}{2i\pi s} ds  \end{align}$$ where the notation $\mathcal{L}_{I}(.),\mathcal{L}_{W}(.), \mathcal{L}_{F}(.)$ represent the Laplace transform of $I,W$ and $F$. Questions My questions are regarding the last three steps marked with (?). I understand that there is a convolution step for the probability density function $I+W$ which becomes in the frequency domain multiplication between two transforms, however I don't understand how the authors arrive to the argument of the Laplace that is $-2 i \pi s$. The authors claim that this can be done using Plancherel-Parseval theroem. I have added the theorem below $$\int_{\mathbb{R}} f(t)\ g(t) \ dt = \int_{\mathbb{R}}\hat{f}(s)\ \overline{\hat{g}(s)} \ ds $$ where for all functions $f,g$ from $\mathbb{R}$ to $\mathbb{R}$, the Fourier of Transform at $s\in \mathbb{R}$ when it exists is given by  $$\hat{f}(s)= \int_{\mathbb{R}}e^{-2i\pi t s} f(t) \ dt $$ $$\hat{g}(s)= \int_{\mathbb{R}}e^{-2i\pi t s} g(t) \ dt $$ and $ \ \overline{\hat{g}(s)}$ denotes the complex conjugate of $\hat{g}(s)$. Many thanks","I am reading a paper that derives a closed form expression of the following probability using properties from Fourier transform, $$ \mathbb{P} \biggl( F \geq T \ (I+W) \biggl)$$ Assumptions: 1- Assume that the $F$ has a finite first moment and admits a square integrable density $f(y)$. 2- $I$ and $W$ are independent and either one admits a density which is square integrable. 3- $I+W$ admits a density $g(t)$. 4- $T$ is a constant The proof is presented next, Proof $$\begin{align} \mathbb{P} \biggl( F \geq T(I+W) \biggl)&= \int_{0}^{\infty} f(y) \  \mathbb{P} \biggl(I+W<y/T \biggl)\\ &= \int_{0}^{+\infty} f(y) \ \int_{-\infty}^{+\infty} g(t) \ 1(0<t<y/T) dt \\ &\stackrel{?}{=} \int_{0}^{+\infty} f(y)\int_{-\infty}^{+\infty} \mathcal{L}_{I}(-2 i \pi s)\mathcal{L}_{W}(-2i\pi s)\times \frac{e^{2i\pi ys/T }-1}{2i\pi s} ds dy\\ &\stackrel{?}{=} \int_{0}^{+\infty} f(y)\int_{-\infty}^{+\infty} \mathcal{L}_{I}(-2 i \pi s T)\mathcal{L}_{W}(-2i\pi sT)\times \frac{e^{2i\pi ys }-1}{2i\pi s} ds dy\\ &\stackrel{?}{=}\int_{-\infty}^{+\infty} \mathcal{L}_{I}(2 i \pi s T)\mathcal{L}_{W}(2i\pi sT)\times \frac{\mathcal{L_F}(-2i\pi s )-1}{2i\pi s} ds  \end{align}$$ where the notation $\mathcal{L}_{I}(.),\mathcal{L}_{W}(.), \mathcal{L}_{F}(.)$ represent the Laplace transform of $I,W$ and $F$. Questions My questions are regarding the last three steps marked with (?). I understand that there is a convolution step for the probability density function $I+W$ which becomes in the frequency domain multiplication between two transforms, however I don't understand how the authors arrive to the argument of the Laplace that is $-2 i \pi s$. The authors claim that this can be done using Plancherel-Parseval theroem. I have added the theorem below $$\int_{\mathbb{R}} f(t)\ g(t) \ dt = \int_{\mathbb{R}}\hat{f}(s)\ \overline{\hat{g}(s)} \ ds $$ where for all functions $f,g$ from $\mathbb{R}$ to $\mathbb{R}$, the Fourier of Transform at $s\in \mathbb{R}$ when it exists is given by  $$\hat{f}(s)= \int_{\mathbb{R}}e^{-2i\pi t s} f(t) \ dt $$ $$\hat{g}(s)= \int_{\mathbb{R}}e^{-2i\pi t s} g(t) \ dt $$ and $ \ \overline{\hat{g}(s)}$ denotes the complex conjugate of $\hat{g}(s)$. Many thanks",,"['probability', 'probability-theory', 'probability-distributions', 'conditional-probability', 'laplace-transform']"
60,Asymptotically uncorrelated sequence converges in distribution to normal distribution?,Asymptotically uncorrelated sequence converges in distribution to normal distribution?,,"If we know that the two random sequences $\{X_n\}$ and $\{Y_n\}$ $$ X_n \stackrel{d}{\longrightarrow} N(0,\sigma_1^2)\\ Y_n \stackrel{d}{\longrightarrow} N(0,\sigma_2^2) $$ and $\mathrm{cov}(X_n,Y_n) \to 0$, can we conclude that the joint random vectors $$ \pmatrix{X_n \\ Y_n} \stackrel{d}{\longrightarrow} N(0,\mathrm{diag}\{\sigma_1^2, \sigma_2^2\}) $$ Is there any counterexample or proof? I have considered using the characteristic function with expansion but did not work it out.... Many thanks to any help!","If we know that the two random sequences $\{X_n\}$ and $\{Y_n\}$ $$ X_n \stackrel{d}{\longrightarrow} N(0,\sigma_1^2)\\ Y_n \stackrel{d}{\longrightarrow} N(0,\sigma_2^2) $$ and $\mathrm{cov}(X_n,Y_n) \to 0$, can we conclude that the joint random vectors $$ \pmatrix{X_n \\ Y_n} \stackrel{d}{\longrightarrow} N(0,\mathrm{diag}\{\sigma_1^2, \sigma_2^2\}) $$ Is there any counterexample or proof? I have considered using the characteristic function with expansion but did not work it out.... Many thanks to any help!",,"['probability', 'statistics', 'convergence-divergence', 'normal-distribution', 'bivariate-distributions']"
61,Optimal Strategy Game of Communicating without Overlap,Optimal Strategy Game of Communicating without Overlap,,"Today, I had a conversation which proceeded very poorly; indeed, I had this conversation with $n$ people, including myself, and everyone had something to say. Problem was that, for an unreasonably long time, it was always two or more people trying to speak at once - and everything was indecipherable. Then, people backed off and there were periods when no one was talking - only to trigger a few people to try to jump into the conversation, and overlap again! Eventually , by pure chance, one person got to talking alone (and never had to talk again), and, slowly but surely, everyone got their turn to speak. Now, being the mathematician that I am, I figured, hey, I can solve this problem. I want to give all $n$ people a sheet of paper describing the rules of conversation - a simple solution would be to assign each a time to speak, but that's not fair to the people who have to wait. So, I want to give all $n$ people the same set of rules to follow. I assume I recognize that, this means, at the first opportunity to speak, everyone will speak with equal probability, and it seems likely that there will be overlap - but then the strategies can differentiate based on the results of that first opportunity (though these people are poor listeners; from each opportunity, they only know whether they tried to speak, and whether there were multiple people, a single person, or no one speaking). To be very formal, define the problem as follows: A conversation is a series of discrete opportunities to talk, at which each player may choose either to attempt to talk, or to be silent. Anyone who successfully talks without interruption will not attempt to speak again. The conversation ends when everyone has spoken. The history of a conversation, will be a finite sequence of the three possible outcomes of an opportunity (no one talks, one person talks, many people talk) - it does not distinguish between $2$ and $3$ people talking. A strategy is a map taking the history of a conversation, and determining whether a given player will talk.  A mixed strategy is a probability distribution over of the set of possibly strategies, and represents, essentially, a non-deterministic strategy. And my question is thus: For what mixed strategy is the expected length of the conversation (measured in opportunities missed) minimized when $n$ people play the strategy against itself? What I know so far are the following strategies: $n=1$: The person should talk at the first opportunity. The conversation will have length $1$ and will be very lonely. $n=2$: The people should maximize the probability that exactly one of them talks at each turn - and, if they both choose to talk or both not to, they gain no useful information about the other, and hence should continue with the same strategy. Thus, the best strategy is to talk with probability $\frac{1}2$ until one of them is successful, after which the other one speaks, yielding an expected length of $3$. $n=3$: This one is trickier and I don't have a proof. I'm fairly certain that the following strategy is locally optimal, and I suspect that it is the best, but I'm not sure. We use three states for which a person can be in - everyone starts in state A: (State A) Speak with probability $p$ at the next opportunity. If no one speaks, remain in state A. If one person speaks, transition to the two person game. If many people, including yourself, speak, go to state B. If many people, not including yourself speak (implying the two others spoke), go to state C. (State B) Don't speak at the next opportunity, then transition to state A if no one speaks. If one person speaks, transition to the two state game. (No more than one person will ever speak in this state) (State C) Speak at the next opportunity; you are guaranteed to be successful. The idea here is that we either escape the dilemma when one person speaks out of the three, or when two people do (and then the other person talks while the two who overlapped are in state B, silent). Using that the expected length of a conversation for two people is $3$, we can find the expected length $\ell$ of this conversation as $$\ell = p^3\cdot(2+\ell)+3p^2(1-p)\cdot (2+3)+3p(1-p)^2\cdot (1+3)+(1-p)^3\cdot(1+\ell)$$ which yields the minimum, according to Mathematica $$p=\frac{1}{4} \left(2-\sqrt{6}+\sqrt{4 \sqrt{6}-6}\right)\approx .37$$ $$\ell=\frac{1}{6} \left(21+\sqrt{9+24 \sqrt{6}}\right)\approx 4.87.$$ Given that the problem of characterizing the optimal strategy for arbitrary $n$ may be extremely difficult, I would not expect answers to find one (but, if you find one, or have something you suspect to be optimal, I'd love to see it)- indeed, even the case of $n=4$ is interesting to me, since I have no handle on what the strategy might be. (The account given in this post is purely fictional; any resemblance to real conversations is purely coincidental)","Today, I had a conversation which proceeded very poorly; indeed, I had this conversation with $n$ people, including myself, and everyone had something to say. Problem was that, for an unreasonably long time, it was always two or more people trying to speak at once - and everything was indecipherable. Then, people backed off and there were periods when no one was talking - only to trigger a few people to try to jump into the conversation, and overlap again! Eventually , by pure chance, one person got to talking alone (and never had to talk again), and, slowly but surely, everyone got their turn to speak. Now, being the mathematician that I am, I figured, hey, I can solve this problem. I want to give all $n$ people a sheet of paper describing the rules of conversation - a simple solution would be to assign each a time to speak, but that's not fair to the people who have to wait. So, I want to give all $n$ people the same set of rules to follow. I assume I recognize that, this means, at the first opportunity to speak, everyone will speak with equal probability, and it seems likely that there will be overlap - but then the strategies can differentiate based on the results of that first opportunity (though these people are poor listeners; from each opportunity, they only know whether they tried to speak, and whether there were multiple people, a single person, or no one speaking). To be very formal, define the problem as follows: A conversation is a series of discrete opportunities to talk, at which each player may choose either to attempt to talk, or to be silent. Anyone who successfully talks without interruption will not attempt to speak again. The conversation ends when everyone has spoken. The history of a conversation, will be a finite sequence of the three possible outcomes of an opportunity (no one talks, one person talks, many people talk) - it does not distinguish between $2$ and $3$ people talking. A strategy is a map taking the history of a conversation, and determining whether a given player will talk.  A mixed strategy is a probability distribution over of the set of possibly strategies, and represents, essentially, a non-deterministic strategy. And my question is thus: For what mixed strategy is the expected length of the conversation (measured in opportunities missed) minimized when $n$ people play the strategy against itself? What I know so far are the following strategies: $n=1$: The person should talk at the first opportunity. The conversation will have length $1$ and will be very lonely. $n=2$: The people should maximize the probability that exactly one of them talks at each turn - and, if they both choose to talk or both not to, they gain no useful information about the other, and hence should continue with the same strategy. Thus, the best strategy is to talk with probability $\frac{1}2$ until one of them is successful, after which the other one speaks, yielding an expected length of $3$. $n=3$: This one is trickier and I don't have a proof. I'm fairly certain that the following strategy is locally optimal, and I suspect that it is the best, but I'm not sure. We use three states for which a person can be in - everyone starts in state A: (State A) Speak with probability $p$ at the next opportunity. If no one speaks, remain in state A. If one person speaks, transition to the two person game. If many people, including yourself, speak, go to state B. If many people, not including yourself speak (implying the two others spoke), go to state C. (State B) Don't speak at the next opportunity, then transition to state A if no one speaks. If one person speaks, transition to the two state game. (No more than one person will ever speak in this state) (State C) Speak at the next opportunity; you are guaranteed to be successful. The idea here is that we either escape the dilemma when one person speaks out of the three, or when two people do (and then the other person talks while the two who overlapped are in state B, silent). Using that the expected length of a conversation for two people is $3$, we can find the expected length $\ell$ of this conversation as $$\ell = p^3\cdot(2+\ell)+3p^2(1-p)\cdot (2+3)+3p(1-p)^2\cdot (1+3)+(1-p)^3\cdot(1+\ell)$$ which yields the minimum, according to Mathematica $$p=\frac{1}{4} \left(2-\sqrt{6}+\sqrt{4 \sqrt{6}-6}\right)\approx .37$$ $$\ell=\frac{1}{6} \left(21+\sqrt{9+24 \sqrt{6}}\right)\approx 4.87.$$ Given that the problem of characterizing the optimal strategy for arbitrary $n$ may be extremely difficult, I would not expect answers to find one (but, if you find one, or have something you suspect to be optimal, I'd love to see it)- indeed, even the case of $n=4$ is interesting to me, since I have no handle on what the strategy might be. (The account given in this post is purely fictional; any resemblance to real conversations is purely coincidental)",,"['probability', 'game-theory']"
62,Normal distribution - how to solve P(-b<X<b)=0.95,Normal distribution - how to solve P(-b<X<b)=0.95,,"$X\sim N(2,3^2)$ How do you find $b$ where $P(-b<X<b)=0.95$ other than trial and error? You can't directly transform to $z$ because if you find an appropriate $z$, transforming back will give you the difference between $b$ and $z$, not $\pm z$. I know it's a simple question but I'm stuck in a rut.","$X\sim N(2,3^2)$ How do you find $b$ where $P(-b<X<b)=0.95$ other than trial and error? You can't directly transform to $z$ because if you find an appropriate $z$, transforming back will give you the difference between $b$ and $z$, not $\pm z$. I know it's a simple question but I'm stuck in a rut.",,"['probability', 'probability-distributions', 'normal-distribution', 'problem-solving']"
63,Probability that an event will occur X times in a row at any point in Y trials?,Probability that an event will occur X times in a row at any point in Y trials?,,"Event AA has a $60\text{%}$ failure rate.  Given $256$ trials, what is the probability that at some point event AA will fail $9$ times in a row? Is there a formula that is fairly plug-and-play? I realize that the probability for AA to fail $9$ trials in a row is equal to $(6/10)^9$, but accounting for the $256$ trials throws me off. I have a basic understanding of statistics and probability, so I would appreciate the clarification of variables in an equation.","Event AA has a $60\text{%}$ failure rate.  Given $256$ trials, what is the probability that at some point event AA will fail $9$ times in a row? Is there a formula that is fairly plug-and-play? I realize that the probability for AA to fail $9$ trials in a row is equal to $(6/10)^9$, but accounting for the $256$ trials throws me off. I have a basic understanding of statistics and probability, so I would appreciate the clarification of variables in an equation.",,"['probability', 'statistics']"
64,Almost equal probable sums with loaded dice,Almost equal probable sums with loaded dice,,"It's known that it's impossible to assign probabilities to a pair of loaded dice so that the sums $2,...,12$ are equally probable. How would one set the probabilities $\{p_i: 1\le i\le 6\}$ and $\{q_i: 1\le i\le 6\}$ for the two dice so that $\sum_{i=1}^{11}\|s_i-1/11\|_2$ is minimal? ( for $1\le i\le 11$, $s_i$ is the probability that the sum is $i+1$).","It's known that it's impossible to assign probabilities to a pair of loaded dice so that the sums $2,...,12$ are equally probable. How would one set the probabilities $\{p_i: 1\le i\le 6\}$ and $\{q_i: 1\le i\le 6\}$ for the two dice so that $\sum_{i=1}^{11}\|s_i-1/11\|_2$ is minimal? ( for $1\le i\le 11$, $s_i$ is the probability that the sum is $i+1$).",,['probability']
65,Secretary Problem with rank based selection and cardinal payoff,Secretary Problem with rank based selection and cardinal payoff,,"Background: The cardinal payoff variant of the Secretary problem aims to maximize the expected value of the selected applicant, assuming values of applicants are random variables X drawn i.i.d. from a uniform distribution on [0, 1]. Refer the paper for details: New Secretary Problem While determining the expected value/payoff of the selected applicant after applying some cutoff c, the expected value is expressed in the form of a recurrence (pg3 of the aforementioned paper) : Question : In this recurrence formula, the first term denotes the case if (t)th applicant is the best so far and the second term =(Probability that (t)th applicant is not the best so far)* V(t+1) = (1/t) *  V(t+1) = (1/t)* {1/(t+1)}* E(t+1) +  (1/t)* {1- 1/(t+1)}* V(t+2) where the first term denotes the case of (t+1)th applicant being the best so far. How would the probability of this ((t+1)th applicant being the best so far) be (1/t)* {1/(t+1)} ? Shouldn't it be = (1/t)* (1/t) = (Probability that (t)th applicant is not the best among the first t applicants)* (Probability that (t+1)th applicant is the best so far, given (t)th applicant was not the best among first t applicants) ?","Background: The cardinal payoff variant of the Secretary problem aims to maximize the expected value of the selected applicant, assuming values of applicants are random variables X drawn i.i.d. from a uniform distribution on [0, 1]. Refer the paper for details: New Secretary Problem While determining the expected value/payoff of the selected applicant after applying some cutoff c, the expected value is expressed in the form of a recurrence (pg3 of the aforementioned paper) : Question : In this recurrence formula, the first term denotes the case if (t)th applicant is the best so far and the second term =(Probability that (t)th applicant is not the best so far)* V(t+1) = (1/t) *  V(t+1) = (1/t)* {1/(t+1)}* E(t+1) +  (1/t)* {1- 1/(t+1)}* V(t+2) where the first term denotes the case of (t+1)th applicant being the best so far. How would the probability of this ((t+1)th applicant being the best so far) be (1/t)* {1/(t+1)} ? Shouldn't it be = (1/t)* (1/t) = (Probability that (t)th applicant is not the best among the first t applicants)* (Probability that (t+1)th applicant is the best so far, given (t)th applicant was not the best among first t applicants) ?",,"['probability', 'decision-theory']"
66,"The math behind generating Dungeons & Dragons ability scores: roll 4d6, toss lowest","The math behind generating Dungeons & Dragons ability scores: roll 4d6, toss lowest",,"D&D 5th ed. gives the following instructions for determining your ability scores. Roll four 6-sided dice and record the total of the highest three dice If I repeat the roll-toss-and-total 6 times (generating a set of 6 totals), what is the probability that my resulting set will contain 4 or more totals  10 and 3 or more totals  12 and 2 or more totals  15? Note that this problem contains and statements. I already figured out the probabilities the totals of these rolls. (3: 1/1296;  4: 1/324;  5: 5/648;  6: 7/432;  7: 19/648;  8: 31/648;  9: 91/1296;  10: 61/648;  11: 37/324;  12: 167/1296;  13: 43/324;  14: 10/81;  15: 131/1296;  16: 47/648;  17: 1/24;  18: 7/432) I cant remember how to use these probabilities to ask more than basic questions. :-/","D&D 5th ed. gives the following instructions for determining your ability scores. Roll four 6-sided dice and record the total of the highest three dice If I repeat the roll-toss-and-total 6 times (generating a set of 6 totals), what is the probability that my resulting set will contain 4 or more totals  10 and 3 or more totals  12 and 2 or more totals  15? Note that this problem contains and statements. I already figured out the probabilities the totals of these rolls. (3: 1/1296;  4: 1/324;  5: 5/648;  6: 7/432;  7: 19/648;  8: 31/648;  9: 91/1296;  10: 61/648;  11: 37/324;  12: 167/1296;  13: 43/324;  14: 10/81;  15: 131/1296;  16: 47/648;  17: 1/24;  18: 7/432) I cant remember how to use these probabilities to ask more than basic questions. :-/",,"['probability', 'dice']"
67,Expected frequency of most frequent die roll,Expected frequency of most frequent die roll,,"Suppose we have an fair $m$-sided die, and we roll it $n$ times. What is the expected frequency $E(n, m)$ of the most frequently rolled face? If we fix $n$ we can calculate $E(n,m)$ like so. Let $\Pi(n)$ be the set of partitions of $n$, where each partition is a weakly descending sequence of nonnegative integers, like $(5,2,2,1,1,0...)$. For each partition $\pi$, we calculate the probability that the frequency distribution equals $\pi$, then we multiply that by $\pi_1$ to get the contribution to $E$. Summing over $\Pi(n)$ gives us $E$. I have computed the following (using Mathematica): $\begin{align*} E(1,m) &= 1\\ E(2,m) &= (m+1)/m\\ E(3,m) &= (m^2+3m-1)/m^2\\ E(4,m) &= (m^3+6m^2-7m+4)/m^3\\ E(5,m) &= (m^4+10m^3-25m^2+40m-21)/m^4\\ E(6,m) &= (m^5+15m^4-65m^3+195m^2-266m+126)/m^5\\ E(7,m) &= (m^6+21m^5-140m^4+665m^3-1631m^2+1911m-820)/m^6\\ E(8,m) &= (m^7+28m^6-266m^5+1820m^4-6881m^3+14140m^2-14554m+5720)/m^7 \end{align*}$","Suppose we have an fair $m$-sided die, and we roll it $n$ times. What is the expected frequency $E(n, m)$ of the most frequently rolled face? If we fix $n$ we can calculate $E(n,m)$ like so. Let $\Pi(n)$ be the set of partitions of $n$, where each partition is a weakly descending sequence of nonnegative integers, like $(5,2,2,1,1,0...)$. For each partition $\pi$, we calculate the probability that the frequency distribution equals $\pi$, then we multiply that by $\pi_1$ to get the contribution to $E$. Summing over $\Pi(n)$ gives us $E$. I have computed the following (using Mathematica): $\begin{align*} E(1,m) &= 1\\ E(2,m) &= (m+1)/m\\ E(3,m) &= (m^2+3m-1)/m^2\\ E(4,m) &= (m^3+6m^2-7m+4)/m^3\\ E(5,m) &= (m^4+10m^3-25m^2+40m-21)/m^4\\ E(6,m) &= (m^5+15m^4-65m^3+195m^2-266m+126)/m^5\\ E(7,m) &= (m^6+21m^5-140m^4+665m^3-1631m^2+1911m-820)/m^6\\ E(8,m) &= (m^7+28m^6-266m^5+1820m^4-6881m^3+14140m^2-14554m+5720)/m^7 \end{align*}$",,"['probability', 'combinatorics', 'expectation', 'integer-partitions']"
68,Understanding probabilities in a puzzle solution,Understanding probabilities in a puzzle solution,,"I'm having a problem understanding a solution based on probabilities in the following puzzle: Puzzle: There is a ""triangular"" duel between the three shooters. Everyone shoots one by one, can shoot once and any person he wants. Smith always hits the target (100%) and shoots last. Brown hits the target 80% of the time and shoots second. Jones is the worst, hitting the target only 50% of the time and he shoots first. Who should Jones shoot in order to increase his chance of surviving? Answer: Jones should shoot in the air. The worst shooter has the best chance of surviving in the triangular duel, which is Jones. After him goes Smith who never misses the target. Since Smith and Brown will be shooting each other when their turn comes, Jones must shoot no one until one of his enemies dies. After that he shoots at his enemy, again having an advantage. First, it's easier to calculate the probability of surviving for Smith. In the duel with Brown he shoots first with a probability of 1/2. In this case he kills Brown. Brown also shoots first with a probability of 1/2. Smith survives with a probability of 1/5. Thus, Smith will live over Brown with a probability of 1/2 + 1/2 * 1/5 = 3/5 . With a probability of 1/2, Smith survives the duel with Jones. All in all: the probability to survive for Smith is 3/5 * 1/2 = 3/10. The probability for Brown to survive the duel with Smith is 2/5 . Then Jones shoots Brown. In the first round, Brown has a probability of 1/2 * 4/5 = 4/10 to win. In the second round, he has a probability of 1/2 * 1/5 * 1/2 * 4/5 = 4/100 . Thus, Brown has a chance to survive Jones: 4/10 + 4/100 + 4/1000 + 4/10000 = 0.4444(4) = 4/9 . The probability of Brown to survive both of his opponents is equal to 2/5 (over Smith) * 4/9 (over Jones) = 8/45. The probability of Jones to survive = 1 - 3/10 - 8/45 = 47/90. In bold are the calculations I'm confused about and don't know how to arrive at. Can someone please explain it? Thank you.","I'm having a problem understanding a solution based on probabilities in the following puzzle: Puzzle: There is a ""triangular"" duel between the three shooters. Everyone shoots one by one, can shoot once and any person he wants. Smith always hits the target (100%) and shoots last. Brown hits the target 80% of the time and shoots second. Jones is the worst, hitting the target only 50% of the time and he shoots first. Who should Jones shoot in order to increase his chance of surviving? Answer: Jones should shoot in the air. The worst shooter has the best chance of surviving in the triangular duel, which is Jones. After him goes Smith who never misses the target. Since Smith and Brown will be shooting each other when their turn comes, Jones must shoot no one until one of his enemies dies. After that he shoots at his enemy, again having an advantage. First, it's easier to calculate the probability of surviving for Smith. In the duel with Brown he shoots first with a probability of 1/2. In this case he kills Brown. Brown also shoots first with a probability of 1/2. Smith survives with a probability of 1/5. Thus, Smith will live over Brown with a probability of 1/2 + 1/2 * 1/5 = 3/5 . With a probability of 1/2, Smith survives the duel with Jones. All in all: the probability to survive for Smith is 3/5 * 1/2 = 3/10. The probability for Brown to survive the duel with Smith is 2/5 . Then Jones shoots Brown. In the first round, Brown has a probability of 1/2 * 4/5 = 4/10 to win. In the second round, he has a probability of 1/2 * 1/5 * 1/2 * 4/5 = 4/100 . Thus, Brown has a chance to survive Jones: 4/10 + 4/100 + 4/1000 + 4/10000 = 0.4444(4) = 4/9 . The probability of Brown to survive both of his opponents is equal to 2/5 (over Smith) * 4/9 (over Jones) = 8/45. The probability of Jones to survive = 1 - 3/10 - 8/45 = 47/90. In bold are the calculations I'm confused about and don't know how to arrive at. Can someone please explain it? Thank you.",,"['probability', 'puzzle']"
69,Is it absolutely certain that repeated random selection of integers from 0 to 100 will eventually select every integer?,Is it absolutely certain that repeated random selection of integers from 0 to 100 will eventually select every integer?,,"I would like to know if one can be absolutely certain, after a number of trials, to circle every integer from 1 to 100 using the following method: Let's say you write down integers 0 to 100 from left to right. Then take one 6-sided die and roll it. The result gives the number of integers from 0 to move to the right along the number line you wrote down. Circle that number. Do it again, moving along the number line and circling numbers. So if on the first roll the die resulted in a 3, you move 3 spaces from zero to the number 3. If the second roll results in a 5, you move 5 spaces from the number 3, to the number 8. Then circle number 8. So now you have 3 and 8 circled. Do this all the way up through the numbers until the last die roll results in a number that would put you past 100. Call this set of results ""layer 1"". Now repeat this again on the exact same set of numbers, with some already circled. This will be called ""layer 2"". Then do ""layer 3"" and so on until all numbers from 1 to 100 are circled (if possible). What I am puzzled by is that common sense tells me that eventually all numbers from 1 to 100 will be circled. This appears to me to be absolutely certain. But the results depend on die rolls, which are based on probability, which says there's a small chance that 1 billion ""layers"" can still leave one number uncircled. I would guess that a resolution to this would be that there's a limit to how many layers of this there could be before all numbers are circled. Or is there always going to be some probability that billions of layers of this can be done with still one or more numbers uncircled? I'm interested in seeing the mathematics behind this problem.","I would like to know if one can be absolutely certain, after a number of trials, to circle every integer from 1 to 100 using the following method: Let's say you write down integers 0 to 100 from left to right. Then take one 6-sided die and roll it. The result gives the number of integers from 0 to move to the right along the number line you wrote down. Circle that number. Do it again, moving along the number line and circling numbers. So if on the first roll the die resulted in a 3, you move 3 spaces from zero to the number 3. If the second roll results in a 5, you move 5 spaces from the number 3, to the number 8. Then circle number 8. So now you have 3 and 8 circled. Do this all the way up through the numbers until the last die roll results in a number that would put you past 100. Call this set of results ""layer 1"". Now repeat this again on the exact same set of numbers, with some already circled. This will be called ""layer 2"". Then do ""layer 3"" and so on until all numbers from 1 to 100 are circled (if possible). What I am puzzled by is that common sense tells me that eventually all numbers from 1 to 100 will be circled. This appears to me to be absolutely certain. But the results depend on die rolls, which are based on probability, which says there's a small chance that 1 billion ""layers"" can still leave one number uncircled. I would guess that a resolution to this would be that there's a limit to how many layers of this there could be before all numbers are circled. Or is there always going to be some probability that billions of layers of this can be done with still one or more numbers uncircled? I'm interested in seeing the mathematics behind this problem.",,"['probability', 'dice']"
70,"The probability of winning in a shootout, using a geometric random variable","The probability of winning in a shootout, using a geometric random variable",,"Sir Lancelot and Sir Galahad are doing a shoot out, in which they try to shoot each other while shooting in the same time at each other. The probability of Sir Lancelot to hit Sir Galahad is 0.5 and the probability of Sir Galahad to hit Sir Lancelot is 0.25. All the shots are independent. A. What is the probability that the shoot out will end in the n's round ? B. If it is known that after k rounds the shoot out did not end, what is the chance that is will end within two rounds ? C. What is the chance of Sir Lancelot to win ? D. What is the chance of Sir Galahad to win ? I solved A and B correctly. The answer for A is $[(3/8)^n-1]\cdot 5/8$ and for B is $(3/8)\cdot (5/8)$. In B I used the memory loss characteristic of the Geometric random variable. I find it hard to solve C and D. Will appreciate your help. Thank you very much in advance.","Sir Lancelot and Sir Galahad are doing a shoot out, in which they try to shoot each other while shooting in the same time at each other. The probability of Sir Lancelot to hit Sir Galahad is 0.5 and the probability of Sir Galahad to hit Sir Lancelot is 0.25. All the shots are independent. A. What is the probability that the shoot out will end in the n's round ? B. If it is known that after k rounds the shoot out did not end, what is the chance that is will end within two rounds ? C. What is the chance of Sir Lancelot to win ? D. What is the chance of Sir Galahad to win ? I solved A and B correctly. The answer for A is $[(3/8)^n-1]\cdot 5/8$ and for B is $(3/8)\cdot (5/8)$. In B I used the memory loss characteristic of the Geometric random variable. I find it hard to solve C and D. Will appreciate your help. Thank you very much in advance.",,['probability']
71,"hat matching problem (Ross, p.41)","hat matching problem (Ross, p.41)",,"I'm studying Ross's probability book, and kind of got stuck on the matching problem. Suppose that each of $N$ men at a party throws his hat into the center of the room. The hats are first mixed up, and then each man randomly selects a hat. What is the probability that none of the men select their own hat? Solution(partial): $P(\text{none of the men select their own hat})= 1- P( \text{at least one of the men select their own hat})$ Let: $E_i =$ the event that the ith man selects his own hat, $i=1, 2, \ldots, N$ $ E_{i_1}E_{i_2}\dots E_{i_n}$ = the event that each of the $n$ men, $i_1,i_2,\ldots, i_n$, selects his own hat the remaining $N-n$ men: the first can select any of $N-n$ hats, the second can then select any of $N-n-1$, and so on. Therefore, there are $(N-n)!$ combinations of the event $ E_{i_1}E_{i_2}\dots E_{i_n}$ My question is: It looks like the solution doesn't care whether there's a match among the remaining $N-n$ men. but, shouldn't we care? if there's one matched among the remaining $N-n$ men, it would be no longer be the event $ E_{i_1}E_{i_2}\dots E_{i_n}$ ? Any hint would be very appreciate, thank you!","I'm studying Ross's probability book, and kind of got stuck on the matching problem. Suppose that each of $N$ men at a party throws his hat into the center of the room. The hats are first mixed up, and then each man randomly selects a hat. What is the probability that none of the men select their own hat? Solution(partial): $P(\text{none of the men select their own hat})= 1- P( \text{at least one of the men select their own hat})$ Let: $E_i =$ the event that the ith man selects his own hat, $i=1, 2, \ldots, N$ $ E_{i_1}E_{i_2}\dots E_{i_n}$ = the event that each of the $n$ men, $i_1,i_2,\ldots, i_n$, selects his own hat the remaining $N-n$ men: the first can select any of $N-n$ hats, the second can then select any of $N-n-1$, and so on. Therefore, there are $(N-n)!$ combinations of the event $ E_{i_1}E_{i_2}\dots E_{i_n}$ My question is: It looks like the solution doesn't care whether there's a match among the remaining $N-n$ men. but, shouldn't we care? if there's one matched among the remaining $N-n$ men, it would be no longer be the event $ E_{i_1}E_{i_2}\dots E_{i_n}$ ? Any hint would be very appreciate, thank you!",,"['probability', 'combinatorics', 'inclusion-exclusion']"
72,law of iterated logarithm,law of iterated logarithm,,"Wikipedia claims see this link that the law of the iterated logarithm marks exactly the point, where convergence in probability and convergence almost sure become different. It is apparent from the law of the iterated logarithm that there is no convergence almost sure, but-according to wikipedia- $$\frac{S_n}{\sqrt{n \log(\log(n))}} \rightarrow 0$$ in probability. I don't know where this comes from. The laws of large numbers are to weak to show this. Therefore, I would appreciate it if anybody could explain, why this is true?","Wikipedia claims see this link that the law of the iterated logarithm marks exactly the point, where convergence in probability and convergence almost sure become different. It is apparent from the law of the iterated logarithm that there is no convergence almost sure, but-according to wikipedia- in probability. I don't know where this comes from. The laws of large numbers are to weak to show this. Therefore, I would appreciate it if anybody could explain, why this is true?",\frac{S_n}{\sqrt{n \log(\log(n))}} \rightarrow 0,"['real-analysis', 'probability']"
73,"$n$ players roll a die. For every pair rolling the same number, the group scores that number. Find the variance of the total score.","players roll a die. For every pair rolling the same number, the group scores that number. Find the variance of the total score.",n,"This is problem 3.3.3.(b) in Probability and Random Processes by Grimmett and Stirzaker. Here's my attempted solution: We introduce the random variables $\{X_{ij}\}$, denoting the scores of each pair (player $i$ and player $j$), and the total score $Y = \sum_{i<j}X_{ij}$. We calculate the expected value of $Y$:  $$  \mathbb{E}(Y) = \sum_{i<j}\mathbb{E}(X_{ij}) = {n\choose{2}}\mathbb{E}(X_{12}) =   \frac{7}{12}{n\choose{2}}. $$ Now, let's determine the variance of $Y$: $$ \mathrm{var}(Y) = \mathbb{E}(Y^2) - \mathbb{E}(Y)^2  = \mathbb{E} \left\{ \left( \sum_{i<j}X_{ij} \right)^2 \right\} - \mathbb{E}(Y)^2 = \mathbb{E} \left( \sum_{i<j,\space k<l}X_{ij}X_{kl} \right) - \mathbb{E}(Y)^2 . $$ Further, we look closer at the sum  $\sum_{i<j,\space k<l}X_{ij}X_{kl}$. Here $X_{ij}$ and $X_{kl}$ are independent whenever $i\neq k$, $i\neq l$, $j\neq k$ and $j\neq l$. When both $i = k$ and $j = l$ we get the random variables $\{X_{ij}^2\}_{i<j}$, each having expected value  $$ \mathbb{E}(X_{ij}^2) = \mathbb{E}(X_{12}^2) = \sum_{m=1}^6\frac{m^2}{36}=\frac{91}{36}. $$  When only three of the four inequalities above hold we get a random variable on one of the following forms: $X_{ij}X_{jl}$, $X_{ij}X_{il}$, $X_{ij}X_{ki}$ or $X_{ij}X_{kj}$. These have expected value  $$ \mathbb{E}(X_{ij}X_{il}) = \mathbb{E}(X_{12}X_{13})  = \sum_{m=1}^6\frac{m^2}{216}=\frac{91}{216}. $$ We note that each triple $\{a,b,c\}$, such that $1\leq a < b < c \leq n$, is associated to the following six terms $X_{ab}X_{ac}$, $X_{ac}X_{ab}$, $X_{ab}X_{bc}$, $X_{bc}X_{ab}$, $X_{ac}X_{bc}$, $X_{bc}X_{ac}$, all with the above expected value. Clearly there are ${n\choose{3}}$ such triples. This gives us the following: $$ \mathrm{var}(Y) =  \mathbb{E} \left( \sum_{i<j,\space k<l}X_{ij}X_{kl} \right) - \mathbb{E}(Y)^2 $$ $$ = {n\choose{2}}\mathbb{E}(X_{12}^2) +  6{n\choose{3}}\mathbb{E}(X_{12}X_{13})+ \left\{{n\choose{2}}^2 - {n\choose{2}} - 6{n\choose{3}} \right\}\mathbb{E}(X_{12})^2 - \left\{{n\choose{2}}\mathbb{E}(X_{12})\right\}^2  $$ $$ = \frac{35}{16}{n\choose{2}} + \frac{35}{72}{n\choose{3}} $$ The book of solutions gives the answer $\frac{35}{16}{n\choose{2}} + \frac{35}{432}{n\choose{3}}$ though, which is what I would get if each triple $\{a,b,c\}$ only was associated with one term $X_{ab}X_{bc}$. So I guess I'm asking why(/if) that is the case!","This is problem 3.3.3.(b) in Probability and Random Processes by Grimmett and Stirzaker. Here's my attempted solution: We introduce the random variables $\{X_{ij}\}$, denoting the scores of each pair (player $i$ and player $j$), and the total score $Y = \sum_{i<j}X_{ij}$. We calculate the expected value of $Y$:  $$  \mathbb{E}(Y) = \sum_{i<j}\mathbb{E}(X_{ij}) = {n\choose{2}}\mathbb{E}(X_{12}) =   \frac{7}{12}{n\choose{2}}. $$ Now, let's determine the variance of $Y$: $$ \mathrm{var}(Y) = \mathbb{E}(Y^2) - \mathbb{E}(Y)^2  = \mathbb{E} \left\{ \left( \sum_{i<j}X_{ij} \right)^2 \right\} - \mathbb{E}(Y)^2 = \mathbb{E} \left( \sum_{i<j,\space k<l}X_{ij}X_{kl} \right) - \mathbb{E}(Y)^2 . $$ Further, we look closer at the sum  $\sum_{i<j,\space k<l}X_{ij}X_{kl}$. Here $X_{ij}$ and $X_{kl}$ are independent whenever $i\neq k$, $i\neq l$, $j\neq k$ and $j\neq l$. When both $i = k$ and $j = l$ we get the random variables $\{X_{ij}^2\}_{i<j}$, each having expected value  $$ \mathbb{E}(X_{ij}^2) = \mathbb{E}(X_{12}^2) = \sum_{m=1}^6\frac{m^2}{36}=\frac{91}{36}. $$  When only three of the four inequalities above hold we get a random variable on one of the following forms: $X_{ij}X_{jl}$, $X_{ij}X_{il}$, $X_{ij}X_{ki}$ or $X_{ij}X_{kj}$. These have expected value  $$ \mathbb{E}(X_{ij}X_{il}) = \mathbb{E}(X_{12}X_{13})  = \sum_{m=1}^6\frac{m^2}{216}=\frac{91}{216}. $$ We note that each triple $\{a,b,c\}$, such that $1\leq a < b < c \leq n$, is associated to the following six terms $X_{ab}X_{ac}$, $X_{ac}X_{ab}$, $X_{ab}X_{bc}$, $X_{bc}X_{ab}$, $X_{ac}X_{bc}$, $X_{bc}X_{ac}$, all with the above expected value. Clearly there are ${n\choose{3}}$ such triples. This gives us the following: $$ \mathrm{var}(Y) =  \mathbb{E} \left( \sum_{i<j,\space k<l}X_{ij}X_{kl} \right) - \mathbb{E}(Y)^2 $$ $$ = {n\choose{2}}\mathbb{E}(X_{12}^2) +  6{n\choose{3}}\mathbb{E}(X_{12}X_{13})+ \left\{{n\choose{2}}^2 - {n\choose{2}} - 6{n\choose{3}} \right\}\mathbb{E}(X_{12})^2 - \left\{{n\choose{2}}\mathbb{E}(X_{12})\right\}^2  $$ $$ = \frac{35}{16}{n\choose{2}} + \frac{35}{72}{n\choose{3}} $$ The book of solutions gives the answer $\frac{35}{16}{n\choose{2}} + \frac{35}{432}{n\choose{3}}$ though, which is what I would get if each triple $\{a,b,c\}$ only was associated with one term $X_{ab}X_{bc}$. So I guess I'm asking why(/if) that is the case!",,"['probability', 'expectation']"
74,Homework problem - Ways to test if a density function is cumulative density function,Homework problem - Ways to test if a density function is cumulative density function,,"I have a problem that states: Let $F : \mathbb R \to R$ be defined by $$F(x) =\begin{cases}e^{\frac{-1}{x}} &\text{if } x > 0\\          0&\text{if } x \leq 0\end{cases}$$ Is $F$ a cumulative distribution function? If yes, what is the associated probability density function? Obviously just by how the function is denoted with $F(x)$ my answer would be yes, and then I would just take the derivative of the function to get the pdf.  I know for the cumulative $P(X \leq x)$.  Is there a way to show this function is cdf with the information given mathematically?  I'm thinking that this problem can't be that easy just by looking at the size of the letter $f$.","I have a problem that states: Let $F : \mathbb R \to R$ be defined by $$F(x) =\begin{cases}e^{\frac{-1}{x}} &\text{if } x > 0\\          0&\text{if } x \leq 0\end{cases}$$ Is $F$ a cumulative distribution function? If yes, what is the associated probability density function? Obviously just by how the function is denoted with $F(x)$ my answer would be yes, and then I would just take the derivative of the function to get the pdf.  I know for the cumulative $P(X \leq x)$.  Is there a way to show this function is cdf with the information given mathematically?  I'm thinking that this problem can't be that easy just by looking at the size of the letter $f$.",,"['probability', 'probability-theory', 'probability-distributions']"
75,Why does this determinant have a continuous density at zero?,Why does this determinant have a continuous density at zero?,,"This question is a simplification of my previous question . I think this is easy, but I don't have a strong enough background in probability. Let $A$ be a random $n\times n$ real matrix that satisfies the following rules: All entries $A_{ij}$ are standard Gaussians, with mean $0$ and variance $1$. Furthermore, they are jointly normally distributed. The matrix is symmetric, that is $A_{ij} = A_{ji}$. Any two entries on the diagonal, $A_{ii}$ and $A_{jj}$ (where $i \ne j$), are correlated, and their covariance is positive and constant (that is, the same for any pair $i, j$). Any two entries in the matrix that weren't covered by the previous two rules are uncorrelated. Since they are jointly normal, the above rules describe the distribution of $A$ completely (am I correct?). My question concerns the distribution of the determinant, $\det A$: I need to prove it has a bounded density near $0$. That is, for all small enough $\epsilon>0$, $$\mathbb{P}\left\{|\det A| \le \epsilon\right\} \le M\epsilon$$ for some constant $M$. (For example, if $n=2$ and $A = \left(\begin{smallmatrix}X&X\\X&X\end{smallmatrix}\right)$ where $X$ is a standard Gaussian then this would be false. But this example violates the 4th rule.) Any help will be appreciated!","This question is a simplification of my previous question . I think this is easy, but I don't have a strong enough background in probability. Let $A$ be a random $n\times n$ real matrix that satisfies the following rules: All entries $A_{ij}$ are standard Gaussians, with mean $0$ and variance $1$. Furthermore, they are jointly normally distributed. The matrix is symmetric, that is $A_{ij} = A_{ji}$. Any two entries on the diagonal, $A_{ii}$ and $A_{jj}$ (where $i \ne j$), are correlated, and their covariance is positive and constant (that is, the same for any pair $i, j$). Any two entries in the matrix that weren't covered by the previous two rules are uncorrelated. Since they are jointly normal, the above rules describe the distribution of $A$ completely (am I correct?). My question concerns the distribution of the determinant, $\det A$: I need to prove it has a bounded density near $0$. That is, for all small enough $\epsilon>0$, $$\mathbb{P}\left\{|\det A| \le \epsilon\right\} \le M\epsilon$$ for some constant $M$. (For example, if $n=2$ and $A = \left(\begin{smallmatrix}X&X\\X&X\end{smallmatrix}\right)$ where $X$ is a standard Gaussian then this would be false. But this example violates the 4th rule.) Any help will be appreciated!",,"['probability', 'normal-distribution', 'random-matrices']"
76,"What is the probability that $k$ events have occurred at time $t$, i.e., $\Pr[N(t)=k]$?","What is the probability that  events have occurred at time , i.e., ?",k t \Pr[N(t)=k],"Assume that the starting time $T_0=0$. There are $n$ events that occur sequentially at time $T_1$, $T_2$, , $T_n$, ($T_k\geqslant T_{k-1}$). Suppose the time intervals $\Delta{T_k}\,(\Delta{T_k} = T_k-T_{k-1})$ are independent exponential random variables with different rate parameters $\lambda_k$, respectively. $(1\leqslant k\leqslant n)$ What is the probability that $k$ events have occurred at time $t$, i.e., $\Pr[N(t)=k]$? I can calculate the distribution of $T_k$ which is the sum of k independent exponential random variables. But I find it is difficult to formulate $\Pr[N(t)=k]$. Is $N(t)$ a non-homogeneous Poisson process? Besides, I was told this probability has no closed form expression. If that is the case, maybe there is an approximation method? I feel like this problem has been solved, but Im having trouble finding sources. Any references to papers/books would be helpful and greatly appreciated.","Assume that the starting time $T_0=0$. There are $n$ events that occur sequentially at time $T_1$, $T_2$, , $T_n$, ($T_k\geqslant T_{k-1}$). Suppose the time intervals $\Delta{T_k}\,(\Delta{T_k} = T_k-T_{k-1})$ are independent exponential random variables with different rate parameters $\lambda_k$, respectively. $(1\leqslant k\leqslant n)$ What is the probability that $k$ events have occurred at time $t$, i.e., $\Pr[N(t)=k]$? I can calculate the distribution of $T_k$ which is the sum of k independent exponential random variables. But I find it is difficult to formulate $\Pr[N(t)=k]$. Is $N(t)$ a non-homogeneous Poisson process? Besides, I was told this probability has no closed form expression. If that is the case, maybe there is an approximation method? I feel like this problem has been solved, but Im having trouble finding sources. Any references to papers/books would be helpful and greatly appreciated.",,"['probability', 'probability-distributions', 'stochastic-processes']"
77,Find a chance that intersection of power set entries is an empty set,Find a chance that intersection of power set entries is an empty set,,"We are given set $A = \{1,2, ...n\}$. $k$ entries picked from the power set of $A$. Task is to find probability that  $A_1 \cap A_2 \space \cap \space... \cap \space A_k = \emptyset$. I came up with solution, but result looks overcomplicated and probably with better knowledge of combinatorics one could do better and find actual answer. Solution We are given: $card(A)=n$ and $X_i \in 2^A$. We will denote $card(X_i) = m_i$ Also, I derived following formulas: Chance of appearing of specific element $a$ in the subset $X_i$: $\frac{C_{n-1}^{m_i-1}}{C_{n}^{m_i}} = \frac {m_i} n$. Analogously, chance of appearing two specific elements in the subset $X_i$: $\frac{C_{n-2}^{m_i-2}}{C_{n}^{m_i}} = \frac {(m_i-1)m_i} {(n-1)n}$. Final idea is: probability of intersection $X_1,X_2...X_k$ being an empty set is: 1 - P(intesection has card 1) - P(intesection has card 2) ... - P(intesection has card n). I was able to write it as: $$1 - \sum_{i=1}^n\prod_{j=1}^k\prod_{l=1}^i \frac{m_j - l +1}{n - l +1}$$ Could it be considered as valid solution? Also I would appreciate hints about mistakes in it. Thank you.","We are given set $A = \{1,2, ...n\}$. $k$ entries picked from the power set of $A$. Task is to find probability that  $A_1 \cap A_2 \space \cap \space... \cap \space A_k = \emptyset$. I came up with solution, but result looks overcomplicated and probably with better knowledge of combinatorics one could do better and find actual answer. Solution We are given: $card(A)=n$ and $X_i \in 2^A$. We will denote $card(X_i) = m_i$ Also, I derived following formulas: Chance of appearing of specific element $a$ in the subset $X_i$: $\frac{C_{n-1}^{m_i-1}}{C_{n}^{m_i}} = \frac {m_i} n$. Analogously, chance of appearing two specific elements in the subset $X_i$: $\frac{C_{n-2}^{m_i-2}}{C_{n}^{m_i}} = \frac {(m_i-1)m_i} {(n-1)n}$. Final idea is: probability of intersection $X_1,X_2...X_k$ being an empty set is: 1 - P(intesection has card 1) - P(intesection has card 2) ... - P(intesection has card n). I was able to write it as: $$1 - \sum_{i=1}^n\prod_{j=1}^k\prod_{l=1}^i \frac{m_j - l +1}{n - l +1}$$ Could it be considered as valid solution? Also I would appreciate hints about mistakes in it. Thank you.",,"['probability', 'combinatorics', 'proof-verification', 'solution-verification']"
78,Find the expected value from a point to three edges of a right triangle.,Find the expected value from a point to three edges of a right triangle.,,"Given a right triangle with a, b, c are the lengths of three edges. Here $a^2=b^2+c^2$. A point is randomly chosen inside the right triangle. Find the expected value of the sum of the distances from the point to three edges.","Given a right triangle with a, b, c are the lengths of three edges. Here $a^2=b^2+c^2$. A point is randomly chosen inside the right triangle. Find the expected value of the sum of the distances from the point to three edges.",,['probability']
79,Find the probability of n different people having the same birthday month,Find the probability of n different people having the same birthday month,,Find the probability of n different people having the same birthday month. Is the following the right way to do: Choose any one of the n people. Then the rest must have the same birthday month as the chosen one. So the probability is: $n (\frac{1}{12^{n-1}})$.,Find the probability of n different people having the same birthday month. Is the following the right way to do: Choose any one of the n people. Then the rest must have the same birthday month as the chosen one. So the probability is: $n (\frac{1}{12^{n-1}})$.,,['probability']
80,Weak Law of Large Numbers,Weak Law of Large Numbers,,"The Weak Law of Large Numbers is often stated with the iid assumption for the underlying RV's. However, I have seen the independence assumption being diluted to the ""uncorrelatedness"" assumption (e.g., Durrett, Sect. 1.5, 3rd ed). I also vaguely remember (from Billingsley's text?)  that the RV's do not even have to be identically distributed. I will appreciate, if someone could shade light on the most general (the least restrictive) form of the WLLN--including the relaxation of the two above-mentioned requirements. Thank you.","The Weak Law of Large Numbers is often stated with the iid assumption for the underlying RV's. However, I have seen the independence assumption being diluted to the ""uncorrelatedness"" assumption (e.g., Durrett, Sect. 1.5, 3rd ed). I also vaguely remember (from Billingsley's text?)  that the RV's do not even have to be identically distributed. I will appreciate, if someone could shade light on the most general (the least restrictive) form of the WLLN--including the relaxation of the two above-mentioned requirements. Thank you.",,"['probability', 'measure-theory', 'probability-limit-theorems', 'law-of-large-numbers']"
81,Gumbel distribution,Gumbel distribution,,"Let $(X_i)_{i \geq 1}$ be a sequence of i.i.d. normal $\mathcal{N}(0,1)$ random variables. Let $M_n = \max_{i=1,\ldots,n} X_i$. Show that  $$P[\sqrt{2 \log n} M_n - 2 \log n \leq u ] \rightarrow e^{-e^{-u}} \text{ as } n \rightarrow \infty$$ I thought maybe to use the following property: $$P[\sqrt{2 \log n} M_n - 2 \log n \leq u ] = P(M_n \leq \frac{u+2 \log n}{\sqrt{2 \log n}})= F^n(\frac{u+2 \log n}{\sqrt{2 \log n}})$$ but dont know how to proceed..","Let $(X_i)_{i \geq 1}$ be a sequence of i.i.d. normal $\mathcal{N}(0,1)$ random variables. Let $M_n = \max_{i=1,\ldots,n} X_i$. Show that  $$P[\sqrt{2 \log n} M_n - 2 \log n \leq u ] \rightarrow e^{-e^{-u}} \text{ as } n \rightarrow \infty$$ I thought maybe to use the following property: $$P[\sqrt{2 \log n} M_n - 2 \log n \leq u ] = P(M_n \leq \frac{u+2 \log n}{\sqrt{2 \log n}})= F^n(\frac{u+2 \log n}{\sqrt{2 \log n}})$$ but dont know how to proceed..",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
82,Random embedding of $K_4$ in the unit square,Random embedding of  in the unit square,K_4,"Suppose I embed $K_4$ (the complete graph on 4 vertices) randomly in the unit square (using the uniform distribution for the positioning of the vertices). $K_4$ is planar , but not any embedding of it is a plane graph . What is the probability that the embedding will be a plane graph? [ Edit: when I say embedding , I mean an embedding of the vertices as points and embedding of the edges as straight line segments connecting their vertices; I am not sure this was clear] Is the result different when we take the unit circle instead, or if we embed it in $\mathbb{R}^2$ using Gaussian distribution? Update An equivalent question would be that: given a random triangle, what is the probability that a random selected point will lie in it. For the uniform distribution on the unit square, that had been asked already here and answered here . I have not verified the solution presented there, but if it is correct, the probability of the random embedding of $K_4$ in the unit square is $\frac{11}{144}$. This does not solve the unit circle case or the Gaussian case, however, and I am not convinced this should be similar at all.","Suppose I embed $K_4$ (the complete graph on 4 vertices) randomly in the unit square (using the uniform distribution for the positioning of the vertices). $K_4$ is planar , but not any embedding of it is a plane graph . What is the probability that the embedding will be a plane graph? [ Edit: when I say embedding , I mean an embedding of the vertices as points and embedding of the edges as straight line segments connecting their vertices; I am not sure this was clear] Is the result different when we take the unit circle instead, or if we embed it in $\mathbb{R}^2$ using Gaussian distribution? Update An equivalent question would be that: given a random triangle, what is the probability that a random selected point will lie in it. For the uniform distribution on the unit square, that had been asked already here and answered here . I have not verified the solution presented there, but if it is correct, the probability of the random embedding of $K_4$ in the unit square is $\frac{11}{144}$. This does not solve the unit circle case or the Gaussian case, however, and I am not convinced this should be similar at all.",,"['probability', 'geometry', 'graph-theory', 'geometric-probability']"
83,Poisson Distribution when only given using mean,Poisson Distribution when only given using mean,,"I'm doing the following homework problem and am unsure of whether or not my answers are correct. This is my first time working with Poisson distribution and I want to make sure I am doing it correctly. Suppose that the number of drivers who travel between a particular origin and destination during a designated time period has a Poisson distribution with mean $u = 20$. What is the probability that the number of drivers will a. Be at most 10? b. Exceed 20? c. Be between 10 and 20, inclusive? Be strictly between 10 and 20? d. Be within 2 standard deviations of the mean value? I'm pretty much just trying to follow the formula that I was given for Poisson distribution and have the following answers: a. $P(x\le 10) = \sum{0\to10}\frac {e^{20} \times 20^x}{x!} $ b. $P(x>20) = \frac {e^{20} \times 20^(20)}{20!} $ c. $P(10 \le x \le 20) = \sum_{10\to20}\frac {e^{20} \times 20^x}{x!} $ $P(10 < x <20) = \sum_{10\to20}\frac {e^{20} \times 20^x}{x!} $ d. not sure still","I'm doing the following homework problem and am unsure of whether or not my answers are correct. This is my first time working with Poisson distribution and I want to make sure I am doing it correctly. Suppose that the number of drivers who travel between a particular origin and destination during a designated time period has a Poisson distribution with mean $u = 20$. What is the probability that the number of drivers will a. Be at most 10? b. Exceed 20? c. Be between 10 and 20, inclusive? Be strictly between 10 and 20? d. Be within 2 standard deviations of the mean value? I'm pretty much just trying to follow the formula that I was given for Poisson distribution and have the following answers: a. $P(x\le 10) = \sum{0\to10}\frac {e^{20} \times 20^x}{x!} $ b. $P(x>20) = \frac {e^{20} \times 20^(20)}{20!} $ c. $P(10 \le x \le 20) = \sum_{10\to20}\frac {e^{20} \times 20^x}{x!} $ $P(10 < x <20) = \sum_{10\to20}\frac {e^{20} \times 20^x}{x!} $ d. not sure still",,"['probability', 'probability-distributions']"
84,Monte Carlo estimator of the number of 1's in a very long binary sequence,Monte Carlo estimator of the number of 1's in a very long binary sequence,,"Preface The question below is related to a problem I am working on, which requires counting the number of times a logic-valued function evaluates ""TRUE"" given an input value. The size of my input set is HUGE and evaluating the function is rather costly. However, I can think of this statistically by viewing the set of values generated by applying the function to each input value as a population . I would like to study this population statistically by evaluating a ( relatively ) small subset of the input values and using that information to infer a plausible range for the total number of times it would have evaluated true had I actually evaluated each input. Therefore, I chose to conceptualize this as inferring the total number of 1's in a very long binary string via Monte Carlo. This conceptualization contains all the salient features of my problem. Problem Statement Given a long (but finite) binary string, $S$ with $n_S\gg 2^{20}$  I would like to use a Monte Carlo sampling approach to estimate the number of 1's in S. Probabilistically, if I let each digit in S have an equal chance of being selected by the Monte Carlo sampler, then the digits in S can be thought of as a outcomes of a random variable. Therefor, the goal is to estimate $\mu = E[x\in S]$ via Monte Carlo. Since we know the size of S, our estimate of the number of 1's in S will be $\mu n_S$. However, there is no explicit formula for calculating $\mu$ apart from brute force enumeration. For very large sets, enumeration is not possible and the basic/naive Monte Carlo approach is very inefficient. I was thinking that some form of adaptive stratification would be helpful, with adaptation based on the sample average of each strata. Any suggestions or references to relevant literature would be helpful.","Preface The question below is related to a problem I am working on, which requires counting the number of times a logic-valued function evaluates ""TRUE"" given an input value. The size of my input set is HUGE and evaluating the function is rather costly. However, I can think of this statistically by viewing the set of values generated by applying the function to each input value as a population . I would like to study this population statistically by evaluating a ( relatively ) small subset of the input values and using that information to infer a plausible range for the total number of times it would have evaluated true had I actually evaluated each input. Therefore, I chose to conceptualize this as inferring the total number of 1's in a very long binary string via Monte Carlo. This conceptualization contains all the salient features of my problem. Problem Statement Given a long (but finite) binary string, $S$ with $n_S\gg 2^{20}$  I would like to use a Monte Carlo sampling approach to estimate the number of 1's in S. Probabilistically, if I let each digit in S have an equal chance of being selected by the Monte Carlo sampler, then the digits in S can be thought of as a outcomes of a random variable. Therefor, the goal is to estimate $\mu = E[x\in S]$ via Monte Carlo. Since we know the size of S, our estimate of the number of 1's in S will be $\mu n_S$. However, there is no explicit formula for calculating $\mu$ apart from brute force enumeration. For very large sets, enumeration is not possible and the basic/naive Monte Carlo approach is very inefficient. I was thinking that some form of adaptive stratification would be helpful, with adaptation based on the sample average of each strata. Any suggestions or references to relevant literature would be helpful.",,"['probability', 'statistics']"
85,Maximum-Value Secretary Problem,Maximum-Value Secretary Problem,,"Background: The classic secretary problem has the simple solution of rejecting the first 1/e applicants and then selecting anyone who was better than the best in the rejected set.  However, in the real world secretaries are not of value 0 if they are not the best, and so choosing the 2nd best is normally far better than choosing the worst.  Also, if you stick to the classical approach, there's a 1/e chance that you will receive a random secretary from the set that excludes the best secretary. Real-World Example: Say that you've interviewed 98 out of 100 secretaries and have not found any better than secretary #32.  You then interview the 99th secretary and find that she is second only to #32. Analysis: Under the classical problem, you'd reject #99 as they have a value of 0 (not the best).  Thus, you'd take a random secretary in favor of the 98th or 99th best, depending on whether the last secretary is the best or not. However, the classical solution would not be the best decision in nearly all real-world cases, as you are taking a random applicant instead of one better than at least 97/99 others. Question: What is the proper stopping strategy to maximize the expected-value of the secretary you hire? You have n secretaries. Each secretary has a linear value assigned after each interview (a secretary ranked 4 is assumed to be twice as valuable as one ranked 2). The value-distribution of secretaries is unknown. You must accept or reject each secretary immediately following their interview with no recalls. You must maximize the expected value of the secretary you hire.","Background: The classic secretary problem has the simple solution of rejecting the first 1/e applicants and then selecting anyone who was better than the best in the rejected set.  However, in the real world secretaries are not of value 0 if they are not the best, and so choosing the 2nd best is normally far better than choosing the worst.  Also, if you stick to the classical approach, there's a 1/e chance that you will receive a random secretary from the set that excludes the best secretary. Real-World Example: Say that you've interviewed 98 out of 100 secretaries and have not found any better than secretary #32.  You then interview the 99th secretary and find that she is second only to #32. Analysis: Under the classical problem, you'd reject #99 as they have a value of 0 (not the best).  Thus, you'd take a random secretary in favor of the 98th or 99th best, depending on whether the last secretary is the best or not. However, the classical solution would not be the best decision in nearly all real-world cases, as you are taking a random applicant instead of one better than at least 97/99 others. Question: What is the proper stopping strategy to maximize the expected-value of the secretary you hire? You have n secretaries. Each secretary has a linear value assigned after each interview (a secretary ranked 4 is assumed to be twice as valuable as one ranked 2). The value-distribution of secretaries is unknown. You must accept or reject each secretary immediately following their interview with no recalls. You must maximize the expected value of the secretary you hire.",,"['probability', 'decision-theory']"
86,Buffon's experiment with squares,Buffon's experiment with squares,,"Say, we'd like to make the Buffon's experiment but with squares instead of needles. Notation: $d$ is the distance between lines $b$ is the square side length $y$ is the distance from the center of the square to the nearest line $\alpha$ is the acute angle between one of the diagonals and the vertical line My attempt to illustrate it: Now we note that $y$ is uniformly distributed in $[0,\frac{d}{2}]$  and $\alpha$ in $[0,\frac{\pi}{4}]$. Furthermore, the square crosses the closest line if $$y\leq \frac{\sqrt{2}}{2}b \cos\ \alpha$$ Now if $E$ is the the event when the square crosses a line then: $$P(E)=\frac{\int_0^{\pi/4} \frac{\sqrt{2}}{2}b \cos\alpha \ \text{d}\alpha}{\frac{d}{2}\frac{\pi}{4}}=\frac{4b}{\pi d}$$ Therefore $$\pi= \frac{4b}{P(E)d}$$ Does this make sense? Unfortunately, my textbook gives a different answer: $$\pi= \frac{4b(\sqrt{2}-1)}{P(E)d}$$ Any clarifications or alternative solutions are highly appreciated.","Say, we'd like to make the Buffon's experiment but with squares instead of needles. Notation: $d$ is the distance between lines $b$ is the square side length $y$ is the distance from the center of the square to the nearest line $\alpha$ is the acute angle between one of the diagonals and the vertical line My attempt to illustrate it: Now we note that $y$ is uniformly distributed in $[0,\frac{d}{2}]$  and $\alpha$ in $[0,\frac{\pi}{4}]$. Furthermore, the square crosses the closest line if $$y\leq \frac{\sqrt{2}}{2}b \cos\ \alpha$$ Now if $E$ is the the event when the square crosses a line then: $$P(E)=\frac{\int_0^{\pi/4} \frac{\sqrt{2}}{2}b \cos\alpha \ \text{d}\alpha}{\frac{d}{2}\frac{\pi}{4}}=\frac{4b}{\pi d}$$ Therefore $$\pi= \frac{4b}{P(E)d}$$ Does this make sense? Unfortunately, my textbook gives a different answer: $$\pi= \frac{4b(\sqrt{2}-1)}{P(E)d}$$ Any clarifications or alternative solutions are highly appreciated.",,"['probability', 'geometry', 'trigonometry', 'monte-carlo', 'geometric-probability']"
87,BINGO Probability: Controlling average game duration,BINGO Probability: Controlling average game duration,,"I wandered over here from StackOverflow and my understanding of advanced mathematics is limited, so bear with me... A standard, BINGO game card has 24 numbers arranged in a 5x5 format. The center of the card has a free space. The numbers range from 1 to 75. Each column has 1/5 of the numbers (1-15, 16-30, etc). Every round results in a single number being called. To win, a player must have 5 numbers in a row, column, or diagonal for a total of 12 possible ways to win. My understanding is that a single player will on average call bingo in 41.36 rounds. See Wizard of Odds. As the number of players increase, does the average rounds to win decrease? Would proportionally increasing the number range (e.g. 1-85 instead of 1-75) cancel the effect of the increased number of players? If so, how is it related? GOAL: Given a fixed set of players P and a desired number of rounds R, how large should the set of numbers N be? Example: For 100 players, how large should the set of numbers be for the game to last, on average, 50 rounds?","I wandered over here from StackOverflow and my understanding of advanced mathematics is limited, so bear with me... A standard, BINGO game card has 24 numbers arranged in a 5x5 format. The center of the card has a free space. The numbers range from 1 to 75. Each column has 1/5 of the numbers (1-15, 16-30, etc). Every round results in a single number being called. To win, a player must have 5 numbers in a row, column, or diagonal for a total of 12 possible ways to win. My understanding is that a single player will on average call bingo in 41.36 rounds. See Wizard of Odds. As the number of players increase, does the average rounds to win decrease? Would proportionally increasing the number range (e.g. 1-85 instead of 1-75) cancel the effect of the increased number of players? If so, how is it related? GOAL: Given a fixed set of players P and a desired number of rounds R, how large should the set of numbers N be? Example: For 100 players, how large should the set of numbers be for the game to last, on average, 50 rounds?",,"['probability', 'recreational-mathematics']"
88,Why can we apply the central limit theorem in this case?,Why can we apply the central limit theorem in this case?,,"The problem at hand is to show that for $X_j$ iid holds $$\lim_{n \to \infty}\frac{P(\bar{X}_n \leq x)}{\frac{1}{ \sqrt{2\pi(\sigma^2/n)}} \int_{-\infty}^x \exp\Big(\frac{-(t-\mu)^2}{2(\sigma^2/n)}\Big)\ \text{d}t}=1$$ Apparently, one needs to notice that $$\{\bar{X}_n \leq x\}=\bigg\{\sqrt{n}\frac{\bar{X}_n - \mu}{\sigma} \leq \color{red}{\sqrt{n}}\frac{x - \mu}{\sigma} \bigg\}$$ and then apply the CLT. Yet I don't understand why can we apply it if the RHS of the inequality depends on $n$. So applying the CLT, we'd get $$ \lim_{n \to \infty} P\bigg\{\sqrt{n}\frac{\bar{X}_n - \mu}{\sigma} \leq \sqrt{n}\frac{x - \mu}{\sigma} \bigg\} =\frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\sqrt{n}\frac{x - \mu}{\sigma}} e^{-t^2/2} \ \text{d}t $$ Which doesn't quite make sense.","The problem at hand is to show that for $X_j$ iid holds $$\lim_{n \to \infty}\frac{P(\bar{X}_n \leq x)}{\frac{1}{ \sqrt{2\pi(\sigma^2/n)}} \int_{-\infty}^x \exp\Big(\frac{-(t-\mu)^2}{2(\sigma^2/n)}\Big)\ \text{d}t}=1$$ Apparently, one needs to notice that $$\{\bar{X}_n \leq x\}=\bigg\{\sqrt{n}\frac{\bar{X}_n - \mu}{\sigma} \leq \color{red}{\sqrt{n}}\frac{x - \mu}{\sigma} \bigg\}$$ and then apply the CLT. Yet I don't understand why can we apply it if the RHS of the inequality depends on $n$. So applying the CLT, we'd get $$ \lim_{n \to \infty} P\bigg\{\sqrt{n}\frac{\bar{X}_n - \mu}{\sigma} \leq \sqrt{n}\frac{x - \mu}{\sigma} \bigg\} =\frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\sqrt{n}\frac{x - \mu}{\sigma}} e^{-t^2/2} \ \text{d}t $$ Which doesn't quite make sense.",,"['probability', 'central-limit-theorem']"
89,Probability - sum of two dependent binomial variable,Probability - sum of two dependent binomial variable,,"If $X \sim B(n, p)$ and $Y \sim B(m, p)$ are dependent binomial variables with the same probability $p$, and same number of elements $N$, does that make $X + Y$ a binomial variable as well? If so with what parameters?","If $X \sim B(n, p)$ and $Y \sim B(m, p)$ are dependent binomial variables with the same probability $p$, and same number of elements $N$, does that make $X + Y$ a binomial variable as well? If so with what parameters?",,['probability']
90,Gradient-descent and Hidden Markov Models,Gradient-descent and Hidden Markov Models,,"I would like to use gradient-descent to fit the parameters of a simple 2-state HMM. This paper Levinson, S. E., Rabiner, L. R. and Sondhi, M. M. (1983), An Introduction to the Application of the Theory of Probabilistic Functions of a Markov Process to Automatic Speech Recognition . Bell System Technical Journal, 62: 10351074. doi: 10.1002/j.1538-7305.1983.tb03114.x shows derivations of the partial derivatives required for gradient descent, but I am having trouble following the steps. Namely, the paper starts by stating that: $$P(\mathbf{O}|\mathbf{M})=\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_{t}(i)a_{ij}b_{j}(O_{t+1})\beta_{t+1}(j)$$ for any $t$ such that $1 \leq t \leq T-1$, where $\mathbf{O} = O_1...O_T$ are the observations and $\mathbf{M}$ represents the transition and emission matrices. $\alpha$ is the forward probability and $\beta$ is the backwards probability. $a_{ij}$ is the probability of transition from state $i$ to state $j$ and $b_j(O_{t+1})$ is the probability of observing $O_{t+1}$ given state $j$. Finally, $N$ is the number of states. To run gradient descent, one needs to calculate the partial derivatives with respect to model parameters. The paper derives: $$\frac{\partial{P}}{\partial{a_{ij}}}=\sum_{t=1}^{T-1}\alpha_t(i)b_j(O_{t+1})\beta_{t+1}(j)$$ But the exact steps for reaching this formula are not shown. Can anyone elaborate on how this result was obtained? Thank you,","I would like to use gradient-descent to fit the parameters of a simple 2-state HMM. This paper Levinson, S. E., Rabiner, L. R. and Sondhi, M. M. (1983), An Introduction to the Application of the Theory of Probabilistic Functions of a Markov Process to Automatic Speech Recognition . Bell System Technical Journal, 62: 10351074. doi: 10.1002/j.1538-7305.1983.tb03114.x shows derivations of the partial derivatives required for gradient descent, but I am having trouble following the steps. Namely, the paper starts by stating that: $$P(\mathbf{O}|\mathbf{M})=\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_{t}(i)a_{ij}b_{j}(O_{t+1})\beta_{t+1}(j)$$ for any $t$ such that $1 \leq t \leq T-1$, where $\mathbf{O} = O_1...O_T$ are the observations and $\mathbf{M}$ represents the transition and emission matrices. $\alpha$ is the forward probability and $\beta$ is the backwards probability. $a_{ij}$ is the probability of transition from state $i$ to state $j$ and $b_j(O_{t+1})$ is the probability of observing $O_{t+1}$ given state $j$. Finally, $N$ is the number of states. To run gradient descent, one needs to calculate the partial derivatives with respect to model parameters. The paper derives: $$\frac{\partial{P}}{\partial{a_{ij}}}=\sum_{t=1}^{T-1}\alpha_t(i)b_j(O_{t+1})\beta_{t+1}(j)$$ But the exact steps for reaching this formula are not shown. Can anyone elaborate on how this result was obtained? Thank you,",,"['probability', 'optimization', 'markov-chains', 'bayesian-network']"
91,problem requires condition probability,problem requires condition probability,,"Q. A robot fires 3 shots at a moving target. For the first shot, the probability of hitting the moving target is 1/3. For subsequent shots beyond the first shot, the probability of hitting the moving target is 1/2 if the previous shot is a hit (for example, the probability of hitting the moving target on the 3rd shot is 1/2 if the 2nd shot is a hit) and the probability of hitting the moving target is 1/4 if the previous shot is a miss. What is the mean and variance of the number of hits? I understand that we can draw a probability tree diagram and find out the possibility of each case, but what i don't understand is how to calculate mean for the number of hits. some kind of hint would be really helpful","Q. A robot fires 3 shots at a moving target. For the first shot, the probability of hitting the moving target is 1/3. For subsequent shots beyond the first shot, the probability of hitting the moving target is 1/2 if the previous shot is a hit (for example, the probability of hitting the moving target on the 3rd shot is 1/2 if the 2nd shot is a hit) and the probability of hitting the moving target is 1/4 if the previous shot is a miss. What is the mean and variance of the number of hits? I understand that we can draw a probability tree diagram and find out the possibility of each case, but what i don't understand is how to calculate mean for the number of hits. some kind of hint would be really helpful",,['probability']
92,Can you prove this recursive multiple $n$-sided dice throwing statement?,Can you prove this recursive multiple -sided dice throwing statement?,n,"Let $W_{s,r,n}$ be the total number of ways that the sum $s$ can be displayed after throwing $r$ number of $n$-sided dice. Define $$W_{s,0,n} = \begin{cases} 1,  & \text{if s = 0} \\ 0, & \text{if s $\neq$ 0} \\ \end{cases} $$ for all $s \in \mathbb Z$ and $n \in \mathbb N^*$. Can you prove that $$W_{s,r,n} =W_{s-1,r,n} + W_{s-1,r-1,n} - W_{s-(1+n),r-1,n}$$ for all $s \in \mathbb Z$, $r \in \mathbb N^*$, and $n \in \mathbb N^*$?","Let $W_{s,r,n}$ be the total number of ways that the sum $s$ can be displayed after throwing $r$ number of $n$-sided dice. Define $$W_{s,0,n} = \begin{cases} 1,  & \text{if s = 0} \\ 0, & \text{if s $\neq$ 0} \\ \end{cases} $$ for all $s \in \mathbb Z$ and $n \in \mathbb N^*$. Can you prove that $$W_{s,r,n} =W_{s-1,r,n} + W_{s-1,r-1,n} - W_{s-(1+n),r-1,n}$$ for all $s \in \mathbb Z$, $r \in \mathbb N^*$, and $n \in \mathbb N^*$?",,"['probability', 'number-theory', 'recursion']"
93,Joint PDF of random variables,Joint PDF of random variables,,"I am given two independent random variables $X$ and $Y$ with density functions $$ f_X(u) = 2u \cdot \chi_{(0,1)}(u),\qquad f_Y(v) = 2v\cdot \chi_{(0,1)}(v), $$ where $\chi_A(t)= 0$ if $t\not\in A$ and $\chi_A(t) = 1$ if $t\in A$. I would like to determine directly from the joint PDF $f_{X,Y}$ the PDF of the random variable $Z:=X+Y$, and also to determine the joint PDF of the vector $(Z,W)$ where $W:=\min\{X,Y\}$. The first part isn't hard since I introduce a random variable $U:=Y$ in order to obtain the inverse of the measurable transformation, that is: $$ \{z = x+y; u = y \leadsto \{x = z-u; y = u $$ so since the Jacobian of the inverse is $1$ I would get $$ f_Z(z) = \int_{-\infty}^\infty f_{Z,U}(z,u) du = \int_{-\infty}^\infty f_X(z-u) f_Y(u) du. $$ where the integrand is 0 unless $0 \leq z-u< 1 \implies z-1 < u\leq z$ and $0< u < 1$. This gives me $$ f_{Z}(z) = \left\{ \begin{array}{lll} \int_0^z 4(z-u)u du &= \frac{2}{3} z^3 & \text{if } 0 < z < 1,\\ \int_{z-1}^1 4 (z-u)u du &= -\frac{2}{3} (z^3 -6z + 4) & \text{if } 1 \leq z < 2\\ 0 & & \text{otherwise.}\end{array} \right. $$ I've checked that $\int_{-\infty}^\infty f_Z(z) dz = 1$. (Is this correct?, is there a shorter approach?). However, for the second part I'm having doubts because of the definition $\min\{X,Y\}$. A first attempt I've considered is using $$ F_{W}(w) = \mathrm P(W\leq w) = \mathrm P(\min\{X,Y\} \leq w\} = 1- \mathrm P(\min\{X,Y\} > w) = 1-\mathrm P(X > w, Y > w)  $$ $$ = 1- \mathrm P(X > w) \mathrm P(Y > w) = 1-(1- F_X(w)) (1-F_Y(w))=\cdots $$ since $\min$ is not differentiable. I would appreciate some help, only hints if you prefer. Thanks in advance.","I am given two independent random variables $X$ and $Y$ with density functions $$ f_X(u) = 2u \cdot \chi_{(0,1)}(u),\qquad f_Y(v) = 2v\cdot \chi_{(0,1)}(v), $$ where $\chi_A(t)= 0$ if $t\not\in A$ and $\chi_A(t) = 1$ if $t\in A$. I would like to determine directly from the joint PDF $f_{X,Y}$ the PDF of the random variable $Z:=X+Y$, and also to determine the joint PDF of the vector $(Z,W)$ where $W:=\min\{X,Y\}$. The first part isn't hard since I introduce a random variable $U:=Y$ in order to obtain the inverse of the measurable transformation, that is: $$ \{z = x+y; u = y \leadsto \{x = z-u; y = u $$ so since the Jacobian of the inverse is $1$ I would get $$ f_Z(z) = \int_{-\infty}^\infty f_{Z,U}(z,u) du = \int_{-\infty}^\infty f_X(z-u) f_Y(u) du. $$ where the integrand is 0 unless $0 \leq z-u< 1 \implies z-1 < u\leq z$ and $0< u < 1$. This gives me $$ f_{Z}(z) = \left\{ \begin{array}{lll} \int_0^z 4(z-u)u du &= \frac{2}{3} z^3 & \text{if } 0 < z < 1,\\ \int_{z-1}^1 4 (z-u)u du &= -\frac{2}{3} (z^3 -6z + 4) & \text{if } 1 \leq z < 2\\ 0 & & \text{otherwise.}\end{array} \right. $$ I've checked that $\int_{-\infty}^\infty f_Z(z) dz = 1$. (Is this correct?, is there a shorter approach?). However, for the second part I'm having doubts because of the definition $\min\{X,Y\}$. A first attempt I've considered is using $$ F_{W}(w) = \mathrm P(W\leq w) = \mathrm P(\min\{X,Y\} \leq w\} = 1- \mathrm P(\min\{X,Y\} > w) = 1-\mathrm P(X > w, Y > w)  $$ $$ = 1- \mathrm P(X > w) \mathrm P(Y > w) = 1-(1- F_X(w)) (1-F_Y(w))=\cdots $$ since $\min$ is not differentiable. I would appreciate some help, only hints if you prefer. Thanks in advance.",,"['probability', 'proof-verification']"
94,Uniform convergence in integrated survival function implies uniform convergence of distribution functions?,Uniform convergence in integrated survival function implies uniform convergence of distribution functions?,,"For a probability distribution function $F$ supported on a bounded interval $[a,b]$, the integrated survival function (ISF) is defined as $$\Psi_F(t)=\mathbb E_F\max\{X-t,0\}=\int_t^b(1-F(x))d x.$$ Clearly, if two distributions have the same ISF then they are equal. The question is whether uniform convergence in ISF implies uniform convergence in distribution function, or at least just point-wise. Consider distribution functions $F,F_1,F_2,\dots$ all supported on a bounded interval $[a,b]$. Suppose $\sup_t\left|\Psi_{F_n}(t)-\Psi_F(t)\right|\to0$. Is it true that $\sup_t\left|{F_n}(t)-F(t)\right|\to0$, or at least that $\forall t\ \left|{F_n}(t)-F(t)\right|\to0$? Does it help to assume that $\forall n,t\ \Psi_{F_n}(t)\geq\Psi_F(t)$?","For a probability distribution function $F$ supported on a bounded interval $[a,b]$, the integrated survival function (ISF) is defined as $$\Psi_F(t)=\mathbb E_F\max\{X-t,0\}=\int_t^b(1-F(x))d x.$$ Clearly, if two distributions have the same ISF then they are equal. The question is whether uniform convergence in ISF implies uniform convergence in distribution function, or at least just point-wise. Consider distribution functions $F,F_1,F_2,\dots$ all supported on a bounded interval $[a,b]$. Suppose $\sup_t\left|\Psi_{F_n}(t)-\Psi_F(t)\right|\to0$. Is it true that $\sup_t\left|{F_n}(t)-F(t)\right|\to0$, or at least that $\forall t\ \left|{F_n}(t)-F(t)\right|\to0$? Does it help to assume that $\forall n,t\ \Psi_{F_n}(t)\geq\Psi_F(t)$?",,"['probability', 'probability-theory', 'probability-distributions', 'convergence-divergence', 'uniform-convergence']"
95,Find the probability the same color was used twice in a chess game given the player did not lose,Find the probability the same color was used twice in a chess game given the player did not lose,,"Here's the question and its solution: I don't see how the solution to the problem is to compute: $[1-P(W|L)]^2+[1-P(B|L)]^2$ i.e. I don't think the expression above reflects what the question is asking and I actually computed this: $ \begin{align} P((W^1 \cap W^2) \cup (B^1 \cap B^2) \left| L_c^1 \cap L_c^2 \right.) &= \frac{P([(W^1 \cap W^2) \cup (B^1 \cap B^2)] \cap (L_c^1 \cap L_c^2))}{P(L_c^1 \cap L_c^2)} \\ &=\frac{P((W^1 \cap L_c^1) \cap (W^2 \cap L_c^2)) + P((B^1 \cap L_c^1) \cap (B^2 \cap L_c^2))}{P(L_c^1 \cap L_c^2)}\\ &=\frac{\left[P \left(L_c^1 \left| W^1\right.\right)P(W^1) \right]\left[ P \left(L_c^2 \left| W^2 \right. \right)P(W^2)\right] + \left[P \left(L_c^1 \left| B^1\right.\right)P(B^1) \right]\left[ P \left(L_c^2 \left| B^2 \right. \right)P(B^2)\right]}{P(L_c^1 \cap L_c^2)}\\ &=\frac{[(1-0.2)(0.5)][(1-0.2)(0.5)]+[(1-0.3)(0.5)][(1-0.3)(0.5)]}{(0.75)(0.75)}\\ &= \frac{0.4^2+0.35^2}{0.75^2} \\ &= \frac{113}{225} \end{align}$ Why is my attempted solution incorrect? EDIT: Where the superscripts denote the number of the game (1st game, 2nd game) and $L_c$ denote the event that the chess player does not lose i.e. win or draw.","Here's the question and its solution: I don't see how the solution to the problem is to compute: $[1-P(W|L)]^2+[1-P(B|L)]^2$ i.e. I don't think the expression above reflects what the question is asking and I actually computed this: $ \begin{align} P((W^1 \cap W^2) \cup (B^1 \cap B^2) \left| L_c^1 \cap L_c^2 \right.) &= \frac{P([(W^1 \cap W^2) \cup (B^1 \cap B^2)] \cap (L_c^1 \cap L_c^2))}{P(L_c^1 \cap L_c^2)} \\ &=\frac{P((W^1 \cap L_c^1) \cap (W^2 \cap L_c^2)) + P((B^1 \cap L_c^1) \cap (B^2 \cap L_c^2))}{P(L_c^1 \cap L_c^2)}\\ &=\frac{\left[P \left(L_c^1 \left| W^1\right.\right)P(W^1) \right]\left[ P \left(L_c^2 \left| W^2 \right. \right)P(W^2)\right] + \left[P \left(L_c^1 \left| B^1\right.\right)P(B^1) \right]\left[ P \left(L_c^2 \left| B^2 \right. \right)P(B^2)\right]}{P(L_c^1 \cap L_c^2)}\\ &=\frac{[(1-0.2)(0.5)][(1-0.2)(0.5)]+[(1-0.3)(0.5)][(1-0.3)(0.5)]}{(0.75)(0.75)}\\ &= \frac{0.4^2+0.35^2}{0.75^2} \\ &= \frac{113}{225} \end{align}$ Why is my attempted solution incorrect? EDIT: Where the superscripts denote the number of the game (1st game, 2nd game) and $L_c$ denote the event that the chess player does not lose i.e. win or draw.",,['probability']
96,To prove the independency of two random variables,To prove the independency of two random variables,,"Suppose two random variables $X_1$ and $X_2$ are of identical independent distribution, with the same PDF $f(x) = e^{-x},  \space x>0$. Now, we have $$Y_1=\min(X_1, X_2)$$ $$Y_2=\max(X_1, X_2)$$  $$Y_3=Y_2 - Y_1$$ The problem is to determine if $Y_1$ and $Y_3$ are independent, and prove why. Unfortunately, I have no idea how to prove it. I only have the notion of $f(X_1X_2)=f(X_1)f(X_2)$ for $X_1$ and $X_2$ independent. Please help me.","Suppose two random variables $X_1$ and $X_2$ are of identical independent distribution, with the same PDF $f(x) = e^{-x},  \space x>0$. Now, we have $$Y_1=\min(X_1, X_2)$$ $$Y_2=\max(X_1, X_2)$$  $$Y_3=Y_2 - Y_1$$ The problem is to determine if $Y_1$ and $Y_3$ are independent, and prove why. Unfortunately, I have no idea how to prove it. I only have the notion of $f(X_1X_2)=f(X_1)f(X_2)$ for $X_1$ and $X_2$ independent. Please help me.",,['probability']
97,Random sample from discrete distribution. Find an unbiased estimator.,Random sample from discrete distribution. Find an unbiased estimator.,,"$X$ is a discrete random variable with parameter $a > 0$ whose pmf is defined as: $$ f_X(x) = \begin{cases}0.2, &x = a\\0.3, &x = 6a\\0.5, &x = 10a\end{cases} $$ Say we have a random sample of length $n$ of $n$ independent, identically distributed random variables with the distribution of $X$. I need to find an unbiased estimator ($\operatorname{E}[\,\hat{\theta}\,] = \theta$) for $a$. We know that $\operatorname{E}[X] = 7a$, and we could say $\operatorname{E}[\frac{1}{7}\cdot\overline{X}] = a$. So, is $\frac{1}{7}\cdot\overline{X}$ an unbiased estimator for $a$?","$X$ is a discrete random variable with parameter $a > 0$ whose pmf is defined as: $$ f_X(x) = \begin{cases}0.2, &x = a\\0.3, &x = 6a\\0.5, &x = 10a\end{cases} $$ Say we have a random sample of length $n$ of $n$ independent, identically distributed random variables with the distribution of $X$. I need to find an unbiased estimator ($\operatorname{E}[\,\hat{\theta}\,] = \theta$) for $a$. We know that $\operatorname{E}[X] = 7a$, and we could say $\operatorname{E}[\frac{1}{7}\cdot\overline{X}] = a$. So, is $\frac{1}{7}\cdot\overline{X}$ an unbiased estimator for $a$?",,"['probability', 'probability-theory', 'probability-distributions']"
98,Unbiased Estimator Question and Understanding,Unbiased Estimator Question and Understanding,,"I'm having some difficulty with unbiased estimators, and wondered if anyone could help me. I believe I understand the general concepts OK, however when I come to look at some sample questions to test my understanding, I feel a little lost! I must stress that this is not homework, or any other assessed work - purely for my own understanding, as statistic isn't an area I have studied in great detail to he truthful. For instance, one question I would like to get my head around is: $X \sim B(n,p)$ and $P=bX$. Assuming $n$ is known, determine $b$ such that $P$ is an unbiased estimator of $p$ and find its standard error. To start with, I have found the following: $E(P)=E(bX)=bE(X)=bnp$ - therefore, am I right in thinking that for P to be an inbiased estimator, we must have b equal to $1/n$? For the second part, I believe that I require the variance, as follows: $V(P)=V(bX)=b^2V(X)=b^2 np(1-p)$, and so where $b=1/n$ we have: $V(P)=\frac{p(1-p)}{n}$ and so the standard error will be: Standard Error $=\sqrt{\frac{p(1-p)}{n}}$. Does this solution look correct - I feel that it is, however would like to check my understanding. Thanks in advance for any help! Best, Chris","I'm having some difficulty with unbiased estimators, and wondered if anyone could help me. I believe I understand the general concepts OK, however when I come to look at some sample questions to test my understanding, I feel a little lost! I must stress that this is not homework, or any other assessed work - purely for my own understanding, as statistic isn't an area I have studied in great detail to he truthful. For instance, one question I would like to get my head around is: $X \sim B(n,p)$ and $P=bX$. Assuming $n$ is known, determine $b$ such that $P$ is an unbiased estimator of $p$ and find its standard error. To start with, I have found the following: $E(P)=E(bX)=bE(X)=bnp$ - therefore, am I right in thinking that for P to be an inbiased estimator, we must have b equal to $1/n$? For the second part, I believe that I require the variance, as follows: $V(P)=V(bX)=b^2V(X)=b^2 np(1-p)$, and so where $b=1/n$ we have: $V(P)=\frac{p(1-p)}{n}$ and so the standard error will be: Standard Error $=\sqrt{\frac{p(1-p)}{n}}$. Does this solution look correct - I feel that it is, however would like to check my understanding. Thanks in advance for any help! Best, Chris",,"['probability', 'statistics', 'estimation']"
99,"Recurrence Relation, Discrete Math problem(Homework)","Recurrence Relation, Discrete Math problem(Homework)",,"There is a disk, separated into n sections, as indicated in the graph. For each section, you can paint it with one color out of four: Red, Yellow, Blue, Green. The rule is adjacent sections can't have the same color. Find the Recurrence Relation of $S_n$ (possible ways to paint the disk for $n$ sections). Here is what I am thinking so far: Case $1$ : $S_1=4$  since for the whole disk, we can pick $4$ possible colors to paint it. Case $2$ : $S_2=4 \times 3=12$  There are $4$ colors to choose for the first section, $3$ remaining for the second. Case $3$ : $S_2=4 \times 3 \times 2=24$ (Since for the first section, we can pick $4$ colors, the second has $3$ possible choices. The third only have $2$ since it can't be the same with both the first one and the second one. Case $4$ : For $4$ sections, similarly, the first section have $4$ choices. The second section have $3$ choices. The third section have $3$ choices. For the last section, there is uncertainty. If the first and third section have the same color. Then it has $3$ choices. Else, it just have $2$ choice. So I don't know how many possible choices would be there. For now, my strategy is to find cases from $1$ to $5$ or $6$. Then I will figure out the recurrence relation numerically... But I know it's not the right way to go. This should not be a hard problem and I'd appreciate your help!","There is a disk, separated into n sections, as indicated in the graph. For each section, you can paint it with one color out of four: Red, Yellow, Blue, Green. The rule is adjacent sections can't have the same color. Find the Recurrence Relation of $S_n$ (possible ways to paint the disk for $n$ sections). Here is what I am thinking so far: Case $1$ : $S_1=4$  since for the whole disk, we can pick $4$ possible colors to paint it. Case $2$ : $S_2=4 \times 3=12$  There are $4$ colors to choose for the first section, $3$ remaining for the second. Case $3$ : $S_2=4 \times 3 \times 2=24$ (Since for the first section, we can pick $4$ colors, the second has $3$ possible choices. The third only have $2$ since it can't be the same with both the first one and the second one. Case $4$ : For $4$ sections, similarly, the first section have $4$ choices. The second section have $3$ choices. The third section have $3$ choices. For the last section, there is uncertainty. If the first and third section have the same color. Then it has $3$ choices. Else, it just have $2$ choice. So I don't know how many possible choices would be there. For now, my strategy is to find cases from $1$ to $5$ or $6$. Then I will figure out the recurrence relation numerically... But I know it's not the right way to go. This should not be a hard problem and I'd appreciate your help!",,['probability']
