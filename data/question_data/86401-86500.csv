,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Existence of Classical Solution to $\square u + u = 0$ in unbounded domains,Existence of Classical Solution to  in unbounded domains,\square u + u = 0,"Let $\Omega \subseteq \mathbb{R}^n$ be a domain, not necessarily bounded. Let's also assume for simplicity that $\Omega$ has smooth boundary. Fix two functions $$ \alpha, \beta : \bar{\Omega} \to \mathbb{R}, $$ each assumed to be smooth in $\Omega$ , continuous up to the boundary, with $\alpha \equiv \beta \equiv 0$ on $\partial \Omega$ .  In the case that $\Omega$ is unbounded, we will assume in addition that $$ \alpha,\beta \to 0 \quad \text{as } {|x|} \to \infty. $$ Can we ensure the existence of a smooth solution $u$ to the Cauchy problem \begin{align} \square u + u \equiv 0 \quad \text{in }\Omega \times \mathbb{R},\\ u(x,0) \equiv \alpha(x) \quad \text{in } \Omega,\\ u_t(x,0) \equiv \beta(x) \quad \text{in } \Omega. \end{align} Naturally, I wanted to obtain a weak solution to this problem and to then invoke regularity results to lift it to a classical solution. However, $\alpha$ and $\beta$ need not belong to $L^p(\Omega)$ for any $1 < p < \infty$ . Consequently, I cannot see how to formulate this problem in a ""weak sense"". Is this approach correct? Or am I missing something entirely?","Let be a domain, not necessarily bounded. Let's also assume for simplicity that has smooth boundary. Fix two functions each assumed to be smooth in , continuous up to the boundary, with on .  In the case that is unbounded, we will assume in addition that Can we ensure the existence of a smooth solution to the Cauchy problem Naturally, I wanted to obtain a weak solution to this problem and to then invoke regularity results to lift it to a classical solution. However, and need not belong to for any . Consequently, I cannot see how to formulate this problem in a ""weak sense"". Is this approach correct? Or am I missing something entirely?","\Omega \subseteq \mathbb{R}^n \Omega 
\alpha, \beta : \bar{\Omega} \to \mathbb{R},
 \Omega \alpha \equiv \beta \equiv 0 \partial \Omega \Omega 
\alpha,\beta \to 0 \quad \text{as } {|x|} \to \infty.
 u \begin{align}
\square u + u \equiv 0 \quad \text{in }\Omega \times \mathbb{R},\\
u(x,0) \equiv \alpha(x) \quad \text{in } \Omega,\\
u_t(x,0) \equiv \beta(x) \quad \text{in } \Omega.
\end{align} \alpha \beta L^p(\Omega) 1 < p < \infty",['real-analysis']
1,Is a weak derivate of $f$ always a classical derivative of some $g$?,Is a weak derivate of  always a classical derivative of some ?,f g,"Let $\Omega \subseteq \mathbb{R}^n$ be open, $p \in [1,\infty]$ , $\alpha$ be a multi-index with $n$ entries. If $v,w\in L^p(\Omega)$ we call $w$ the weak- $\alpha$ -derivative of $v$ if $$ \forall \varphi \in C_0^\infty (\Omega): \quad \int_\Omega w(x)\varphi(x) dx = (-1)^{|\alpha|} \int_\Omega v(x) \partial^\alpha\varphi(x) dx $$ Now in many cases we have that, if $w$ is the classical derivative $\partial^\alpha v$ almost everywhere, then it also is the weak- $\alpha$ -derivative of $v$ . My question is now: does the converse hold? I.e. if $w$ is the weak- $\alpha$ -derivative of $v$ ,  can we choose other representatives $v',w'$ which are equivalent to $v,w$ resp. and a Lebesgue-measure-zero set $Z\subseteq \Omega$ such that $w'|_{\Omega\backslash Z}$ is the classical derivative $\partial^\alpha (v'|_{\Omega \backslash Z})$ ?","Let be open, , be a multi-index with entries. If we call the weak- -derivative of if Now in many cases we have that, if is the classical derivative almost everywhere, then it also is the weak- -derivative of . My question is now: does the converse hold? I.e. if is the weak- -derivative of ,  can we choose other representatives which are equivalent to resp. and a Lebesgue-measure-zero set such that is the classical derivative ?","\Omega \subseteq \mathbb{R}^n p \in [1,\infty] \alpha n v,w\in L^p(\Omega) w \alpha v 
\forall \varphi \in C_0^\infty (\Omega): \quad \int_\Omega w(x)\varphi(x) dx = (-1)^{|\alpha|} \int_\Omega v(x) \partial^\alpha\varphi(x) dx
 w \partial^\alpha v \alpha v w \alpha v v',w' v,w Z\subseteq \Omega w'|_{\Omega\backslash Z} \partial^\alpha (v'|_{\Omega \backslash Z})","['functional-analysis', 'sobolev-spaces', 'weak-derivatives']"
2,Is the $p$-norm ever a norm for $0<p<1$?,Is the -norm ever a norm for ?,p 0<p<1,"I wonder: Is there a measure space $(X,\Sigma,\mu)$ such that $L^p(\mu)$ form a normed space w.r.t the $p$ -norm, for some $0<p<1$ ?(assuming that $X$ contains more than point). I know that in general the "" $p$ -norm"" is not really a norm for $0<p<1$ .  (it violates the triangle inequality). I am asking if there are (non-trivial) special cases where it does form a norm.","I wonder: Is there a measure space such that form a normed space w.r.t the -norm, for some ?(assuming that contains more than point). I know that in general the "" -norm"" is not really a norm for .  (it violates the triangle inequality). I am asking if there are (non-trivial) special cases where it does form a norm.","(X,\Sigma,\mu) L^p(\mu) p 0<p<1 X p 0<p<1","['functional-analysis', 'normed-spaces', 'lp-spaces']"
3,Uniform boundedness theorem.,Uniform boundedness theorem.,,"Let $V$ be subspace of $\ell^2$ which contains all 1 summable sequences. For each natural number $n$ , define $T_n: V \to \mathbb R$ by $T_n(x)=\sum_{i=1}^n x_i$ . Then $T_n$ is not uniformly bounded on unit ball $\|x\|_2\leq1$ . My intuition says it has something to do with closed and bounded in infinite dimensional banach space need not be compact. But I don't know how to get a firm answer. Could you please tell me the reason? Thank you very much for your time.","Let be subspace of which contains all 1 summable sequences. For each natural number , define by . Then is not uniformly bounded on unit ball . My intuition says it has something to do with closed and bounded in infinite dimensional banach space need not be compact. But I don't know how to get a firm answer. Could you please tell me the reason? Thank you very much for your time.",V \ell^2 n T_n: V \to \mathbb R T_n(x)=\sum_{i=1}^n x_i T_n \|x\|_2\leq1,"['functional-analysis', 'hilbert-spaces', 'banach-spaces']"
4,equations of unbounded operator,equations of unbounded operator,,"$T$ is densely defined closed operator on $\mathcal{H}$ which is a Hilbert space. Prove that $\forall a,b\in H$ ,the equations \begin{equation} \label{eq:1} \left\{ \begin{aligned}          -Tx+y &= a \\                   x+T^{\star}y&=b                           \end{aligned} \right.                           \end{equation} have unique solution $x\in D(T),y\in D(T^\star)$ . $T^\star$ is the adjoint operator of $T$ . $D(T)$ is the space where $T$ is defined. I have proved the uniqueness. And if $a\in D(T^\star),b\in D(T)$ , I can just solve it just by taking $T$ on the second equation and plus the first one. But for $\forall a,b\in H$ , I have some troubles.  Any idea will help, thank you.","is densely defined closed operator on which is a Hilbert space. Prove that ,the equations have unique solution . is the adjoint operator of . is the space where is defined. I have proved the uniqueness. And if , I can just solve it just by taking on the second equation and plus the first one. But for , I have some troubles.  Any idea will help, thank you.","T \mathcal{H} \forall a,b\in H \begin{equation} \label{eq:1}
\left\{ \begin{aligned}
         -Tx+y &= a \\
                  x+T^{\star}y&=b
                          \end{aligned} \right.
                          \end{equation} x\in D(T),y\in D(T^\star) T^\star T D(T) T a\in D(T^\star),b\in D(T) T \forall a,b\in H","['functional-analysis', 'unbounded-operators']"
5,Dual of the product is isometric to the product of the dual,Dual of the product is isometric to the product of the dual,,"Let $X,Y$ be Banach spaces. Let $Z = X\times Y$ equipped with the $p$ -norm, where $||(x,y)||_Z = (||x||_X^p + ||y||_Y^p)^{1/p}$ . Suppose $X^* \times Y^*$ is equipped with the $q$ -norm where $1/p+1/q = 1.$ Then there exists $\phi:X^* \times Y^* \longrightarrow Z^*$ , an isometric isomorphism. For $f \in X^*, g \in Y^*$ , the obvious map I can think of is $\phi(f,g)(x,y) = f(x) + g(y)$ . With holder's inequality I managed to show that $||\phi(f,g)||\leq ||(f,g)||$ . But I'm not sure how to show the other direction.","Let be Banach spaces. Let equipped with the -norm, where . Suppose is equipped with the -norm where Then there exists , an isometric isomorphism. For , the obvious map I can think of is . With holder's inequality I managed to show that . But I'm not sure how to show the other direction.","X,Y Z = X\times Y p ||(x,y)||_Z = (||x||_X^p + ||y||_Y^p)^{1/p} X^* \times Y^* q 1/p+1/q = 1. \phi:X^* \times Y^* \longrightarrow Z^* f \in X^*, g \in Y^* \phi(f,g)(x,y) = f(x) + g(y) ||\phi(f,g)||\leq ||(f,g)||","['functional-analysis', 'banach-spaces', 'lp-spaces', 'dual-spaces']"
6,Divergence of power series in commutative Banach algebras,Divergence of power series in commutative Banach algebras,,"Let $(A,||\cdot||)$ be a commutative Banach algebra over $\mathbb{C}$. Consider a formal power series $f(z):=\sum_{n=0}a_n z^n\in A[[z]]$ and let  $$ r:=\frac{1}{\limsup\limits_{n\to\infty}||a_n||^{1/n}} $$ For $b\in A$ denote by $\rho(b)$ its spectral radius. Is it generally true that $f(b)$ is divergent (in the $||\cdot||$-topology) for any $b\in A$ with $\rho(b)>r$? I believe one can easily show in certain cases that $f(b)$ is divergent if $$ \rho(b)> \frac{1}{\limsup\limits_{n\to\infty}\rho(a_n)^{1/n}}=:R, $$ but $R$ can be much bigger than $r$.","Let $(A,||\cdot||)$ be a commutative Banach algebra over $\mathbb{C}$. Consider a formal power series $f(z):=\sum_{n=0}a_n z^n\in A[[z]]$ and let  $$ r:=\frac{1}{\limsup\limits_{n\to\infty}||a_n||^{1/n}} $$ For $b\in A$ denote by $\rho(b)$ its spectral radius. Is it generally true that $f(b)$ is divergent (in the $||\cdot||$-topology) for any $b\in A$ with $\rho(b)>r$? I believe one can easily show in certain cases that $f(b)$ is divergent if $$ \rho(b)> \frac{1}{\limsup\limits_{n\to\infty}\rho(a_n)^{1/n}}=:R, $$ but $R$ can be much bigger than $r$.",,"['functional-analysis', 'power-series', 'banach-algebras']"
7,A generalization of conditional expectation,A generalization of conditional expectation,,"Consider the following generalization of conditional expectation: Start with measurable spaces $A,B$ equipped with measures $\mu_A, \mu_B$ respectively and a measurable map $T : A \to B$ s.t. $\mu_A \circ T^{-1} \leq C \mu_B$ for some $C > 0$ (i.e. this inequality holds event-wise). Then $T$ induces (in a functorial, contravariant way) a linear map $$\mathcal L_2(T) : \mathcal L_2(B,\mu_B) \to \mathcal L_2(A,\mu_A), g\mapsto g\circ T.$$ Indeed $$\|g\circ T\|_2 = \int g(Tx)^2\,d\mu_A(x) \leq \int g(y)^2 \,dC\mu_B(y) = C\|g\|_2,$$ which shows that $\mathcal L_2(T)$ is well-defined and bounded with operator norm $\leq C$ (in fact, it is an isometry if $\mu_A \circ T^{-1} = \mu_B$). Then $\mathcal L_2(T)$ has an adjoint operator $\mathbb E^T$. If we consider a probability space $(\Omega, \mathcal F, \mathbb P)$ and sub-$\sigma$-algebra $\mathcal G$ of $\mathcal F$. and set $A = (\Omega,\mathcal F)$, $B = (\Omega, \mathcal G)$, $\mu_A = \mathbb P$, $\mu_B = \mathbb P_{|\mathcal G}$ and $T(t) = t$, the defining property of adjoints implies $$\mathbb E(\mathbb E^T X \cdot \mathbb 1_B) = \mathbb E(X\cdot \mathbb 1_B)$$ for all $B\in \mathcal G$. So $\mathbb E^T$ is the conditional expectation of $X$ w.r.t. $\mathcal G$. Are there any important examples of $\mathbb E^T$ besides conditional expectation?","Consider the following generalization of conditional expectation: Start with measurable spaces $A,B$ equipped with measures $\mu_A, \mu_B$ respectively and a measurable map $T : A \to B$ s.t. $\mu_A \circ T^{-1} \leq C \mu_B$ for some $C > 0$ (i.e. this inequality holds event-wise). Then $T$ induces (in a functorial, contravariant way) a linear map $$\mathcal L_2(T) : \mathcal L_2(B,\mu_B) \to \mathcal L_2(A,\mu_A), g\mapsto g\circ T.$$ Indeed $$\|g\circ T\|_2 = \int g(Tx)^2\,d\mu_A(x) \leq \int g(y)^2 \,dC\mu_B(y) = C\|g\|_2,$$ which shows that $\mathcal L_2(T)$ is well-defined and bounded with operator norm $\leq C$ (in fact, it is an isometry if $\mu_A \circ T^{-1} = \mu_B$). Then $\mathcal L_2(T)$ has an adjoint operator $\mathbb E^T$. If we consider a probability space $(\Omega, \mathcal F, \mathbb P)$ and sub-$\sigma$-algebra $\mathcal G$ of $\mathcal F$. and set $A = (\Omega,\mathcal F)$, $B = (\Omega, \mathcal G)$, $\mu_A = \mathbb P$, $\mu_B = \mathbb P_{|\mathcal G}$ and $T(t) = t$, the defining property of adjoints implies $$\mathbb E(\mathbb E^T X \cdot \mathbb 1_B) = \mathbb E(X\cdot \mathbb 1_B)$$ for all $B\in \mathcal G$. So $\mathbb E^T$ is the conditional expectation of $X$ w.r.t. $\mathcal G$. Are there any important examples of $\mathbb E^T$ besides conditional expectation?",,"['functional-analysis', 'probability-theory', 'reference-request']"
8,Uniqueness in Bernstein's theorem of calculus of variations,Uniqueness in Bernstein's theorem of calculus of variations,,"I'm working through Gelfand and Fomin's book on calculus of variations. One of the book's exercises is to prove the uniqueness portion of a result called ""Bernstein's theorem"" on solutions to equations of the form $y'' = F(x, y, y')$. The book states the theorem thus: If the functions $F$, $F_y$, and $F_{y'}$ are continuous at every finite point $(x, y)$ for every finite $y$, and if a constant $k > 0$ and functions $$\alpha = \alpha(x, y) \geq 0, \qquad \beta = \beta(x, y) \geq 0$$ (which are bounded in every finite region of the plane) can be found such that $$F_y(x, y, y') > k, \quad |F(x, y, y')| < \alpha y'^2 + \beta,$$ then one and only one integral curve satisfying $y'' = F(x, y, y')$ passes through any two points $(a, A)$ and $(b, B)$ with different abscissas ($a \neq b$). (Subscripts on $F$ mean partial derivatives.) The hint for the exercise is: Let $\Delta(x) = \varphi_2(x) - \varphi_1(x)$, where $\varphi_1(x)$ and $\varphi_2(x)$ are two solutions of $y'' = F(x, y, y')$, write an expression for $\Delta''$ and use the condition $F_y(x, y, y') > k$. Following the hint, I got the expression $$\Delta''(x) = F(x, \varphi_2(x), \varphi'_2(x)) - F(x, \varphi_1(x), \varphi_1'(x)).$$ I thought that I could use the condition on $F_y$ to get some sort of lower bound on the magnitude of the RHS of this equation, and then try to turn that into some sort of proof that $\Delta(a)$ and $\Delta(b)$ cannot both be zero. But because $\varphi_1'(x) \neq \varphi_2'(x)$, I don't know what I can conclude about $ F(x, \varphi_2(x), \varphi'_2(x)) - F(x, \varphi_1(x), \varphi_1'(x))$ unless I also know something about $F_{y'}$ as well as $F_y$, and the theorem imposes only a very weak hypothesis, continuity, on $F_{y'}$.","I'm working through Gelfand and Fomin's book on calculus of variations. One of the book's exercises is to prove the uniqueness portion of a result called ""Bernstein's theorem"" on solutions to equations of the form $y'' = F(x, y, y')$. The book states the theorem thus: If the functions $F$, $F_y$, and $F_{y'}$ are continuous at every finite point $(x, y)$ for every finite $y$, and if a constant $k > 0$ and functions $$\alpha = \alpha(x, y) \geq 0, \qquad \beta = \beta(x, y) \geq 0$$ (which are bounded in every finite region of the plane) can be found such that $$F_y(x, y, y') > k, \quad |F(x, y, y')| < \alpha y'^2 + \beta,$$ then one and only one integral curve satisfying $y'' = F(x, y, y')$ passes through any two points $(a, A)$ and $(b, B)$ with different abscissas ($a \neq b$). (Subscripts on $F$ mean partial derivatives.) The hint for the exercise is: Let $\Delta(x) = \varphi_2(x) - \varphi_1(x)$, where $\varphi_1(x)$ and $\varphi_2(x)$ are two solutions of $y'' = F(x, y, y')$, write an expression for $\Delta''$ and use the condition $F_y(x, y, y') > k$. Following the hint, I got the expression $$\Delta''(x) = F(x, \varphi_2(x), \varphi'_2(x)) - F(x, \varphi_1(x), \varphi_1'(x)).$$ I thought that I could use the condition on $F_y$ to get some sort of lower bound on the magnitude of the RHS of this equation, and then try to turn that into some sort of proof that $\Delta(a)$ and $\Delta(b)$ cannot both be zero. But because $\varphi_1'(x) \neq \varphi_2'(x)$, I don't know what I can conclude about $ F(x, \varphi_2(x), \varphi'_2(x)) - F(x, \varphi_1(x), \varphi_1'(x))$ unless I also know something about $F_{y'}$ as well as $F_y$, and the theorem imposes only a very weak hypothesis, continuity, on $F_{y'}$.",,"['functional-analysis', 'calculus-of-variations']"
9,Proof of a Separating Hyperplane Theorem,Proof of a Separating Hyperplane Theorem,,"SEP: Let Y be a convex, located and inhabited set in $ \mathbb{R}^n$ such that $0 \notin Y$. Fix $y^1,\dots,y^l$ in Y. Then there exists and $ \xi \in Y$ such that \begin{align*} (\langle \xi, y^1 \rangle , \dots, \langle \xi , y^l \rangle ) >0, \end{align*} meaning all entries of the vector are nonnegative and at least one is greater $0$. LLPO: $\forall x , y \in \mathbb{R} : x \ge 0 \vee x \le 0$. I am trying to prove constructively that LLPO implies SEP. I tried to do this by induction: The case $n=1$ is trivial. For the general case I tried to split $Y$ into two sets. $Y_1 = \{ y \in Y : y_n = 0\}$ and $Y_2 = \{ y \in Y : y_1 = \dots = y_{n-1} = 0\}$. The problem however is now, that in order to apply the Induction Hypothesis, I need that $Y_1$ is convex and $ 0 \notin Y_1$. But this does not necessarily hold. Is there a more sophisticated way to solve this?","SEP: Let Y be a convex, located and inhabited set in $ \mathbb{R}^n$ such that $0 \notin Y$. Fix $y^1,\dots,y^l$ in Y. Then there exists and $ \xi \in Y$ such that \begin{align*} (\langle \xi, y^1 \rangle , \dots, \langle \xi , y^l \rangle ) >0, \end{align*} meaning all entries of the vector are nonnegative and at least one is greater $0$. LLPO: $\forall x , y \in \mathbb{R} : x \ge 0 \vee x \le 0$. I am trying to prove constructively that LLPO implies SEP. I tried to do this by induction: The case $n=1$ is trivial. For the general case I tried to split $Y$ into two sets. $Y_1 = \{ y \in Y : y_n = 0\}$ and $Y_2 = \{ y \in Y : y_1 = \dots = y_{n-1} = 0\}$. The problem however is now, that in order to apply the Induction Hypothesis, I need that $Y_1$ is convex and $ 0 \notin Y_1$. But this does not necessarily hold. Is there a more sophisticated way to solve this?",,['functional-analysis']
10,Average of irrational flow on the torus,Average of irrational flow on the torus,,"Let $$F(x,y) = \frac{1}{\sqrt{2-\sin(2\pi x) - \sin(2\pi y)}}$$ defined on $\mathbb{T}^2$. Here $\mathbb{T}^2 = \mathbb{R}^2/ \mathbb{Z}^2$ is the 2-torus. How can I show that $$ \lim_{T\longrightarrow \infty} \frac{1}{T}\int_0^T F(x,\sqrt{2}x)\;dx = \iint_{[0,1]^2} F(x,y)\;dxdy?$$ What can we say about the rate of convergence? Say $\frac{1}{T^\alpha}$ for some $\alpha \in (0,1)$?","Let $$F(x,y) = \frac{1}{\sqrt{2-\sin(2\pi x) - \sin(2\pi y)}}$$ defined on $\mathbb{T}^2$. Here $\mathbb{T}^2 = \mathbb{R}^2/ \mathbb{Z}^2$ is the 2-torus. How can I show that $$ \lim_{T\longrightarrow \infty} \frac{1}{T}\int_0^T F(x,\sqrt{2}x)\;dx = \iint_{[0,1]^2} F(x,y)\;dxdy?$$ What can we say about the rate of convergence? Say $\frac{1}{T^\alpha}$ for some $\alpha \in (0,1)$?",,"['functional-analysis', 'fourier-analysis', 'harmonic-analysis', 'irrational-numbers', 'ergodic-theory']"
11,The intuition behind the definition of a monotone operator,The intuition behind the definition of a monotone operator,,"I started reading about monotone operators in Zeidlers'  book on Nonlinear functional analysis: The operator $A:X \to X^*$ is monotone on the reflexive Banach space $X$ if:   $\langle Ax - Ay, x-y\rangle \geq 0$ for all $u,v \in X$. This definition (if I get it right) is supposed to be a generalization of a monotone function $f: \mathbb{R} \to \mathbb{R}$. He proceeds with an example: Set $X=\mathbb{R}$ and $F(u)=Au$. Then $X^*= \mathbb{R} $ and:   $\langle Ax - Ay, x-y\rangle =\big(F(u) -F(v) \big)(u-v)$. But I'm thinking if $F$ is strictly decreasing and we have $v<u, u,v\in \mathbb{R}$ then $u-v >0$ while $F(u) -F(v)<0$, so $\big(F(u) -F(v) \big)(u-v)<0$. What am I missing here? If this were a generalization of a monotone function of $\mathbb{R}$ it should be positive for all $u,v \in \mathbb{R}$ I think? If someone could help me and explain where the definition comes from I'd also be very grateful.","I started reading about monotone operators in Zeidlers'  book on Nonlinear functional analysis: The operator $A:X \to X^*$ is monotone on the reflexive Banach space $X$ if:   $\langle Ax - Ay, x-y\rangle \geq 0$ for all $u,v \in X$. This definition (if I get it right) is supposed to be a generalization of a monotone function $f: \mathbb{R} \to \mathbb{R}$. He proceeds with an example: Set $X=\mathbb{R}$ and $F(u)=Au$. Then $X^*= \mathbb{R} $ and:   $\langle Ax - Ay, x-y\rangle =\big(F(u) -F(v) \big)(u-v)$. But I'm thinking if $F$ is strictly decreasing and we have $v<u, u,v\in \mathbb{R}$ then $u-v >0$ while $F(u) -F(v)<0$, so $\big(F(u) -F(v) \big)(u-v)<0$. What am I missing here? If this were a generalization of a monotone function of $\mathbb{R}$ it should be positive for all $u,v \in \mathbb{R}$ I think? If someone could help me and explain where the definition comes from I'd also be very grateful.",,"['real-analysis', 'functional-analysis', 'operator-theory', 'intuition', 'monotone-functions']"
12,Nyquist theorems for sampling in regularly spaced Taylor bases?,Nyquist theorems for sampling in regularly spaced Taylor bases?,,"The Nyquist / Shannon sampling theorem is like super famous in signal processing. It says that when doing regularly spaced point-wise sampling we need to sample a sinusoidal signal at least two times each period to avoid frequency aliasing . But what happens if we don't just sample the function value in instants in time, but say a local Taylor approximation? $$f_k(x) = \sum_{l=0}^Nc_{kl}(x-k\Delta_x)^l$$ For $N=0$ this becomes the usual sampling $f_k(x) = c_{k0}$, we only measure the function values but none of the derivatives. Below is an illustration of Nyquist phenomenon on a typical chirp signal. We see the catastrophy that occurs when the local frequency increases above the sampling rate prescribed by Nyquist. But what would happen if we could measure also the slope at the green points or even the second derivatives et.c.? Could we push the bound upwards?","The Nyquist / Shannon sampling theorem is like super famous in signal processing. It says that when doing regularly spaced point-wise sampling we need to sample a sinusoidal signal at least two times each period to avoid frequency aliasing . But what happens if we don't just sample the function value in instants in time, but say a local Taylor approximation? $$f_k(x) = \sum_{l=0}^Nc_{kl}(x-k\Delta_x)^l$$ For $N=0$ this becomes the usual sampling $f_k(x) = c_{k0}$, we only measure the function values but none of the derivatives. Below is an illustration of Nyquist phenomenon on a typical chirp signal. We see the catastrophy that occurs when the local frequency increases above the sampling rate prescribed by Nyquist. But what would happen if we could measure also the slope at the green points or even the second derivatives et.c.? Could we push the bound upwards?",,"['functional-analysis', 'soft-question', 'fourier-analysis', 'signal-processing', 'sampling']"
13,Spectral families of commuting operators,Spectral families of commuting operators,,"Consider two self-adjoint bounded operators $A$ and $B$ on a separable Hilbert space. According to the spectral theorem we can write $$ A=\int_{-\infty}^{\infty} x d E^{A}_x, \quad B=\int_{-\infty}^{\infty} y d E^{A}_y $$ where $E^{A}_x$ and $E^{B}_y$ are the spectral families of projectors of $A$ and $B$ respectively. Is there a simple way to prove that if $[A,B]=AB-BA=0$, then $[E^{A}_x,E^{B}_y]=0$ for all $x,y$?","Consider two self-adjoint bounded operators $A$ and $B$ on a separable Hilbert space. According to the spectral theorem we can write $$ A=\int_{-\infty}^{\infty} x d E^{A}_x, \quad B=\int_{-\infty}^{\infty} y d E^{A}_y $$ where $E^{A}_x$ and $E^{B}_y$ are the spectral families of projectors of $A$ and $B$ respectively. Is there a simple way to prove that if $[A,B]=AB-BA=0$, then $[E^{A}_x,E^{B}_y]=0$ for all $x,y$?",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
14,Fractional Sobolev spaces are Banach spaces,Fractional Sobolev spaces are Banach spaces,,"Let $1\leq p\leq +\infty$, $0<s<1$ and $\Omega\subseteq \mathbb{R}^n$ an open set. The fractional Sobolev space $W^{s,p}(\Omega)$ is defined to be $$ W^{s,p}(\Omega) = \left\{ u\in L^p(\Omega) : \frac{|u(x)-u(y)|}{|x-y|^{\frac{n}{p} + s}} \in L^p(\Omega\times\Omega) \right\} $$ equipped with the norm $$ \|u\|_{W^{s,p}(\Omega)} = \left( \int_\Omega |u|^p \; dx + \int_\Omega\int_\Omega \frac{|u(x)-u(y)|^p}{|x-y|^{n+ sp}} \; dx dy \right)^{1/p}. $$ It is a well known result that this is a Banach space, but every reference I read says that this is true, without giving a proof. Adam's Sobolev Spaces uses techniques from interpolation theory to prove this result, but I'm no familiar with the theory, so I'm asking for an ""elementary proof"", that is, as usual, proving that every Cauchy sequence has a limit in the space. Here is my ""attempt"": Let $(u_n)$ be a Cauchy sequence in $W^{1,p}(\Omega)$, then $(u_n)$ is a Cauchy sequence in $L^p(\Omega)$, so there exists $u\in L^p(\Omega)$ such that $u_n\to u$ in $L^p(\Omega)$. I would like to prove that $u\in W^{s,p}(\Omega)$ and that $u_n\to u$ in $W^{s,p}(\Omega)$. But I don't know how to proceed here. Thanks for the help!","Let $1\leq p\leq +\infty$, $0<s<1$ and $\Omega\subseteq \mathbb{R}^n$ an open set. The fractional Sobolev space $W^{s,p}(\Omega)$ is defined to be $$ W^{s,p}(\Omega) = \left\{ u\in L^p(\Omega) : \frac{|u(x)-u(y)|}{|x-y|^{\frac{n}{p} + s}} \in L^p(\Omega\times\Omega) \right\} $$ equipped with the norm $$ \|u\|_{W^{s,p}(\Omega)} = \left( \int_\Omega |u|^p \; dx + \int_\Omega\int_\Omega \frac{|u(x)-u(y)|^p}{|x-y|^{n+ sp}} \; dx dy \right)^{1/p}. $$ It is a well known result that this is a Banach space, but every reference I read says that this is true, without giving a proof. Adam's Sobolev Spaces uses techniques from interpolation theory to prove this result, but I'm no familiar with the theory, so I'm asking for an ""elementary proof"", that is, as usual, proving that every Cauchy sequence has a limit in the space. Here is my ""attempt"": Let $(u_n)$ be a Cauchy sequence in $W^{1,p}(\Omega)$, then $(u_n)$ is a Cauchy sequence in $L^p(\Omega)$, so there exists $u\in L^p(\Omega)$ such that $u_n\to u$ in $L^p(\Omega)$. I would like to prove that $u\in W^{s,p}(\Omega)$ and that $u_n\to u$ in $W^{s,p}(\Omega)$. But I don't know how to proceed here. Thanks for the help!",,"['functional-analysis', 'banach-spaces', 'sobolev-spaces']"
15,Theorem still true if $X$ is not complete,Theorem still true if  is not complete,X,"Consider the following theorem: Let $S$ be a non-empty set and let $\{0\} \neq X$ be a vector space of bounded functions on $S$, with the condition that $S$ is a Banach space when $X$ is supplied with the supremum-norm. Suppose $f : S → \mathbb{F}$ is a function such that $fg \in X$ for all $g \in X$. Then the multiplication operator $M_f : X → X$, defined by $M_f (g) = fg$ $(g ∈ X)$, is bounded. I want to know, Is $f$ necessarily bounded? Is this theorem still true if $X$ is not complete. Any insights are much appreciated.","Consider the following theorem: Let $S$ be a non-empty set and let $\{0\} \neq X$ be a vector space of bounded functions on $S$, with the condition that $S$ is a Banach space when $X$ is supplied with the supremum-norm. Suppose $f : S → \mathbb{F}$ is a function such that $fg \in X$ for all $g \in X$. Then the multiplication operator $M_f : X → X$, defined by $M_f (g) = fg$ $(g ∈ X)$, is bounded. I want to know, Is $f$ necessarily bounded? Is this theorem still true if $X$ is not complete. Any insights are much appreciated.",,"['real-analysis', 'functional-analysis']"
16,"$(e_{n})$ orthonormal basis, $(f_{n})$ orthonormal sequence such that $\sum\left\|e_{n}-f_{n}\right\|^{2}<\infty$ Then $(f_{n})$ is orthonormal basis.","orthonormal basis,  orthonormal sequence such that  Then  is orthonormal basis.",(e_{n}) (f_{n}) \sum\left\|e_{n}-f_{n}\right\|^{2}<\infty (f_{n}),"Let $H$ be a hilbert space, $(e_{n})$ a orthonormal basis of $H$, and, $(f_{n})$  a orthonormal sequence on $H$ such that $$\sum_{n=1}^{\infty}\left\|e_{n}-f_{n}\right\|^{2}<\infty. \tag{I}$$ Show that $(f_{n})$ is also a orthonormal basis. Remark: My idea was the following: First I show the following fact: Fact 1: Let $H$ be a Hilbert space, $(x_{n})_{n=1}^{\infty}$ a orthonormal basis of $H$, and let $(y_{n})_{n=1}^{\infty}$ be a sequence in $H$ such that    $$\sum_{n=1}^{\infty}\left\|x_{n}-y_{n}\right\|^{2}<1. \tag{II}$$   Then, if $z\bot y_{n}$ for all $n\in\mathbb{N}$, then $z=0$. Let $f\bot f_{n}$ for all $n\leq 1$, then by (I) there exists $m$ such that $$\sum_{n=m+1}^{\infty}\left\|e_{n}-f_{n}\right\|^{2}<1. \tag{III}$$ Therefore, by Fact 1 we have that $\left\{e_{1},\ldots,e_{m},f_{m+1},f_{m+2},\ldots\right\}$ is total in $H$. I need to show that $\left\{f,f_{1},\ldots,f_{m}\right\}$ is linearly dependent.","Let $H$ be a hilbert space, $(e_{n})$ a orthonormal basis of $H$, and, $(f_{n})$  a orthonormal sequence on $H$ such that $$\sum_{n=1}^{\infty}\left\|e_{n}-f_{n}\right\|^{2}<\infty. \tag{I}$$ Show that $(f_{n})$ is also a orthonormal basis. Remark: My idea was the following: First I show the following fact: Fact 1: Let $H$ be a Hilbert space, $(x_{n})_{n=1}^{\infty}$ a orthonormal basis of $H$, and let $(y_{n})_{n=1}^{\infty}$ be a sequence in $H$ such that    $$\sum_{n=1}^{\infty}\left\|x_{n}-y_{n}\right\|^{2}<1. \tag{II}$$   Then, if $z\bot y_{n}$ for all $n\in\mathbb{N}$, then $z=0$. Let $f\bot f_{n}$ for all $n\leq 1$, then by (I) there exists $m$ such that $$\sum_{n=m+1}^{\infty}\left\|e_{n}-f_{n}\right\|^{2}<1. \tag{III}$$ Therefore, by Fact 1 we have that $\left\{e_{1},\ldots,e_{m},f_{m+1},f_{m+2},\ldots\right\}$ is total in $H$. I need to show that $\left\{f,f_{1},\ldots,f_{m}\right\}$ is linearly dependent.",,"['functional-analysis', 'hilbert-spaces', 'orthonormal']"
17,Version of Hahn-Banach Theorem,Version of Hahn-Banach Theorem,,"Problem: Let $X$ be a vector space over $\mathbb{R}$ and $Y \subset X$ a linear subspace. Let $p: X \to \mathbb{R}$ be a sublinear functional and $f: Y \to \mathbb{R}$ linear with $f \leq p$ on $Y$ (by Hahn-Banach this can be extended of course) Consider now $G \subset \mathcal{L}(X)$ a subset of bounded linear operators $T: X \to X$ with the properties that  id $_X \in G$ and for all $A,B \in G, AB \in G$ and moreover $AB=BA$ . Assume that for all $A \in G$ we have $p(Ax) \leq p(x)$ for all $x \in X, Ay \in Y$ and $f(Ay)=f(y)$ for all $y \in Y$ Claim: There exists $F: X \to \mathbb{R}$ linear with $F_{ \mid Y} =f, F \leq p$ on $X$ and $F(Ax)=F(x)$ for all $x \in X$ and $A \in G$ My approach: I am given the hint to consider $q(x):= \inf_{A_1, \dots , A_n} \frac{1}{n}p(A_1x + \dots + A_n x)$ where the infimum is taken over finitely many $A_i \in G$ , then show that $q$ is sublinear and $f(y) \leq q(y)$ for all $y \in Y$ in order to apply Hahn-Banach. Showing that $q$ is sublinear follows from the fact that all the $A_i$ are linear and $p$ is sublinear by definition. Further for $y \in Y$ and $A_1, \dots , A_n \in G$ we have \begin{align} f(A_1y + \dots + A_ny) &= f(A_1y) + \dots + f(A_ny) =n f(y)  \end{align} But also $f(A_1y + \dots + A_ny) \leq p(A_1y + \dots + A_ny)$ , thus we have $f(y) \leq \frac{1}{n}p(A_1y + \dots + A_ny)$ taking the infimum we get that $f(y) \leq q(y)$ on $Y$ . By Hahn-Banach there exists $F: X \to \mathbb{R}$ linear with $F_{ \mid Y} = f$ and $F(x) \leq q(x)$ for all $x \in X$ . However since $p(A_1x + \dots + A_nx) \leq p(A_1x)+ \dots + p(A_nx) \leq n p(x)$ it also follows that $q \leq p$ on $X$ which takes care of the first claim. I need to show that $F(Ax)=F(x)$ for all $x \in X$ and $A \in G$ holds. It would be good if I could show that $F(Ax) \leq F(x)$ , then the other inequality would follow by linearty of $F$ . \begin{align}F(Ax) \leq q(Ax)&= \inf_{A_1, \dots , A_n} \frac{1}{n} p(A_1Ax + \dots + A_nAx) \\ &= \inf_{A_1, \dots , A_n} \frac{1}{n} p(AA_1x + \dots + AA_nx) \end{align} Here I get stuck. My Question(s) would be if my approach above is correct so far and how I would go on about concluding that $F(Ax)=F(x)$ on $X$ .","Problem: Let be a vector space over and a linear subspace. Let be a sublinear functional and linear with on (by Hahn-Banach this can be extended of course) Consider now a subset of bounded linear operators with the properties that  id and for all and moreover . Assume that for all we have for all and for all Claim: There exists linear with on and for all and My approach: I am given the hint to consider where the infimum is taken over finitely many , then show that is sublinear and for all in order to apply Hahn-Banach. Showing that is sublinear follows from the fact that all the are linear and is sublinear by definition. Further for and we have But also , thus we have taking the infimum we get that on . By Hahn-Banach there exists linear with and for all . However since it also follows that on which takes care of the first claim. I need to show that for all and holds. It would be good if I could show that , then the other inequality would follow by linearty of . Here I get stuck. My Question(s) would be if my approach above is correct so far and how I would go on about concluding that on .","X \mathbb{R} Y \subset X p: X \to \mathbb{R} f: Y \to \mathbb{R} f \leq p Y G \subset \mathcal{L}(X) T: X \to X _X \in G A,B \in G, AB \in G AB=BA A \in G p(Ax) \leq p(x) x \in X, Ay \in Y f(Ay)=f(y) y \in Y F: X \to \mathbb{R} F_{ \mid Y} =f, F \leq p X F(Ax)=F(x) x \in X A \in G q(x):= \inf_{A_1, \dots , A_n} \frac{1}{n}p(A_1x + \dots + A_n x) A_i \in G q f(y) \leq q(y) y \in Y q A_i p y \in Y A_1, \dots , A_n \in G \begin{align} f(A_1y + \dots + A_ny) &= f(A_1y) + \dots + f(A_ny) =n f(y)  \end{align} f(A_1y + \dots + A_ny) \leq p(A_1y + \dots + A_ny) f(y) \leq \frac{1}{n}p(A_1y + \dots + A_ny) f(y) \leq q(y) Y F: X \to \mathbb{R} F_{ \mid Y} = f F(x) \leq q(x) x \in X p(A_1x + \dots + A_nx) \leq p(A_1x)+ \dots + p(A_nx) \leq n p(x) q \leq p X F(Ax)=F(x) x \in X A \in G F(Ax) \leq F(x) F \begin{align}F(Ax) \leq q(Ax)&= \inf_{A_1, \dots , A_n} \frac{1}{n} p(A_1Ax + \dots + A_nAx) \\ &= \inf_{A_1, \dots , A_n} \frac{1}{n} p(AA_1x + \dots + AA_nx) \end{align} F(Ax)=F(x) X",['functional-analysis']
18,Construction of exponential for an unbounded operator.,Construction of exponential for an unbounded operator.,,"I'm puzzling out the way one can determine $exp(iA)$ operator for an unbounded $A$. More precisely I would like to know, how could I deal with the momentum operator $p_x = -i\hbar\partial_x$. I'm trying to follow the instruction which I learned from Frederic Schullers lectures ( https://www.youtube.com/watch?v=GbqA9Xn_iM0 lecture 10 and 11) The instruction is as following: 1) Construct the positive real-valued measure $\mu_{\psi}$ using Stieltjes inversion formula : $\mu_{\psi}((-\infty,\ \lambda]) = \lim_{\delta\to 0^{+}}\lim_{\epsilon\to 0^{+}}\frac{1}{\pi} \int\limits_{-\infty}^{\lambda+\delta}dt \ Im<\psi, R_p(t + i\epsilon)\psi> $, where $R_p(z)$ is a resolvent operator. 2)Construct complex-valued measure $\mu_{\psi, \phi}$ by polarization formula: $\mu_{\psi, \phi}(\Omega) = \frac{1}{4} [\mu_{\psi+\phi}(\Omega) - \mu_{\psi-\phi}(\Omega)+i\mu_{\psi-i\phi}(\Omega)-i\mu_{\psi+i\phi}(\Omega)], \Omega$ is a Borel set in $\mathbb{R}$ 3) Construct projection-valued measure $P$ as following: $<\psi, P(\Omega)\phi> := \int \chi_\Omega d\mu_{\psi, \phi}$ 4) Calculate the integral: $exp(i\hbar\partial_x) := \int_{\mathbb{R}} e^{i\lambda}\ P(d\lambda)$ My achievments are really poor. Actually, I've just calculated the resolvent for the momentum operator: $R_p(z) = \frac{i}{\hbar} \int\limits_{0}^{\infty}dt\ e^{izt\hbar^{-1}}u(t)$, where $u(t)\psi(x) = \psi(x-t)$. But I got in trouble even at the first step while calculating Stieltjes integral. I've achieved such thing to calculate: $\frac{i}{h}\int\limits_{0}^{\infty}da\ e^{iza\hbar^{-1}}\ \int_{\mathbb{R}} dx\ \psi^{*}(x)u(a)\psi(x)$ and I don't know how to deal with it. Maybe someone tried this way and can give me some advices? However, I bet it is not the shortest way to rigorously construct exponential of unbounded operator. Are they any other ideas to define exp?  If they are, what is the main purpose of the spectral theorem and all of equastions I mentioned before. It seems to be not constructive in this case.","I'm puzzling out the way one can determine $exp(iA)$ operator for an unbounded $A$. More precisely I would like to know, how could I deal with the momentum operator $p_x = -i\hbar\partial_x$. I'm trying to follow the instruction which I learned from Frederic Schullers lectures ( https://www.youtube.com/watch?v=GbqA9Xn_iM0 lecture 10 and 11) The instruction is as following: 1) Construct the positive real-valued measure $\mu_{\psi}$ using Stieltjes inversion formula : $\mu_{\psi}((-\infty,\ \lambda]) = \lim_{\delta\to 0^{+}}\lim_{\epsilon\to 0^{+}}\frac{1}{\pi} \int\limits_{-\infty}^{\lambda+\delta}dt \ Im<\psi, R_p(t + i\epsilon)\psi> $, where $R_p(z)$ is a resolvent operator. 2)Construct complex-valued measure $\mu_{\psi, \phi}$ by polarization formula: $\mu_{\psi, \phi}(\Omega) = \frac{1}{4} [\mu_{\psi+\phi}(\Omega) - \mu_{\psi-\phi}(\Omega)+i\mu_{\psi-i\phi}(\Omega)-i\mu_{\psi+i\phi}(\Omega)], \Omega$ is a Borel set in $\mathbb{R}$ 3) Construct projection-valued measure $P$ as following: $<\psi, P(\Omega)\phi> := \int \chi_\Omega d\mu_{\psi, \phi}$ 4) Calculate the integral: $exp(i\hbar\partial_x) := \int_{\mathbb{R}} e^{i\lambda}\ P(d\lambda)$ My achievments are really poor. Actually, I've just calculated the resolvent for the momentum operator: $R_p(z) = \frac{i}{\hbar} \int\limits_{0}^{\infty}dt\ e^{izt\hbar^{-1}}u(t)$, where $u(t)\psi(x) = \psi(x-t)$. But I got in trouble even at the first step while calculating Stieltjes integral. I've achieved such thing to calculate: $\frac{i}{h}\int\limits_{0}^{\infty}da\ e^{iza\hbar^{-1}}\ \int_{\mathbb{R}} dx\ \psi^{*}(x)u(a)\psi(x)$ and I don't know how to deal with it. Maybe someone tried this way and can give me some advices? However, I bet it is not the shortest way to rigorously construct exponential of unbounded operator. Are they any other ideas to define exp?  If they are, what is the main purpose of the spectral theorem and all of equastions I mentioned before. It seems to be not constructive in this case.",,"['functional-analysis', 'measure-theory', 'quantum-mechanics', 'unbounded-operators']"
19,Prove that a complete metric space contains a non-empty open set,Prove that a complete metric space contains a non-empty open set,,"In the proof of Baire's Category Theorem in the book by Kreyszig, it is mentioned that a complete metric space will contain a non-empty open set. I like to know the proof of this.","In the proof of Baire's Category Theorem in the book by Kreyszig, it is mentioned that a complete metric space will contain a non-empty open set. I like to know the proof of this.",,"['functional-analysis', 'metric-spaces', 'complete-spaces']"
20,Proving an operator from $\ell^\infty \to \ell^\infty$ is invertible,Proving an operator from  is invertible,\ell^\infty \to \ell^\infty,"(Just to fix some notation, $\ell^\infty = \ell^\infty(\mathbb{N\cup \{0\}},\mathbb{C})$ in what follows) Let $S:\ell^\infty\to\ell^\infty$ be the left shift operator and let $A:\ell^\infty\to\ell^\infty$ be the the multiplication by the element $a\in \ell^\infty$.  In other words we have that $S(x)_n = x_{n+1}$ and $A(x)_n=a_n x_n$. Suppose that $a\in \ell^\infty$ satisfies $$(1)\quad \quad |\Pi_{k=0}^{n-1}a_{j+k}|\leq c\alpha^n \ \ \forall j\geq 0$$  where $c>0, \alpha \in (0,1)$. My problem is the following: Prove that $I-AS$ is invertible ($I$ is the identity operator). Unfortunately $\|AS\|_{\mathcal{\ell^\infty}}= \|a\|_{\ell^\infty}$ that can be greater than $1$ so we cannot exploit the Neumann series to define the inverse. I managed to prove, though, that $I-AS$ is injective, indeed if $y = AS y$ then we would have (by $(1)$) that  $$y_n = a_n y_{n+1} = a_n a_{n+1}\dots a_{n+N} y_{n+N+1}\leq ||y|||_{\infty}\Pi_{k=0}^{N}a_{n+k}|\leq ||y|||_{\infty} c\alpha^{N+1} $$ for any $N>0$ thus taking the limit $y_n = 0 $ for any $n$. Now this would be sufficient to conclude if for example we manage to prove that $AS$ is a compact operator. But this is not the case since the image of the unit ball through $S$ is the ball itself and $A$ is not compact (for example consider a sequence $a$ such that $a_{2n} = 0$ $a_{2n+1}=1$ so that condition $(1)$ is satisfied). The only way I see to solve this problem is therefore to prove that $I-AS$ is surjective or maybe that is Fredholm of index $0$. And here I got stuck since I tried to write the inverse  obtaining $$ (I-AS)^{-1}(y)_n = y_n + \sum_{k\geq 0} a_{n+k} y_{n+k+1}$$  but I don't see a way to exploit relation $(1)$ to prove the series is convergent.","(Just to fix some notation, $\ell^\infty = \ell^\infty(\mathbb{N\cup \{0\}},\mathbb{C})$ in what follows) Let $S:\ell^\infty\to\ell^\infty$ be the left shift operator and let $A:\ell^\infty\to\ell^\infty$ be the the multiplication by the element $a\in \ell^\infty$.  In other words we have that $S(x)_n = x_{n+1}$ and $A(x)_n=a_n x_n$. Suppose that $a\in \ell^\infty$ satisfies $$(1)\quad \quad |\Pi_{k=0}^{n-1}a_{j+k}|\leq c\alpha^n \ \ \forall j\geq 0$$  where $c>0, \alpha \in (0,1)$. My problem is the following: Prove that $I-AS$ is invertible ($I$ is the identity operator). Unfortunately $\|AS\|_{\mathcal{\ell^\infty}}= \|a\|_{\ell^\infty}$ that can be greater than $1$ so we cannot exploit the Neumann series to define the inverse. I managed to prove, though, that $I-AS$ is injective, indeed if $y = AS y$ then we would have (by $(1)$) that  $$y_n = a_n y_{n+1} = a_n a_{n+1}\dots a_{n+N} y_{n+N+1}\leq ||y|||_{\infty}\Pi_{k=0}^{N}a_{n+k}|\leq ||y|||_{\infty} c\alpha^{N+1} $$ for any $N>0$ thus taking the limit $y_n = 0 $ for any $n$. Now this would be sufficient to conclude if for example we manage to prove that $AS$ is a compact operator. But this is not the case since the image of the unit ball through $S$ is the ball itself and $A$ is not compact (for example consider a sequence $a$ such that $a_{2n} = 0$ $a_{2n+1}=1$ so that condition $(1)$ is satisfied). The only way I see to solve this problem is therefore to prove that $I-AS$ is surjective or maybe that is Fredholm of index $0$. And here I got stuck since I tried to write the inverse  obtaining $$ (I-AS)^{-1}(y)_n = y_n + \sum_{k\geq 0} a_{n+k} y_{n+k+1}$$  but I don't see a way to exploit relation $(1)$ to prove the series is convergent.",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'lp-spaces']"
21,Existence of bounded sequences for image of bounded linear operators,Existence of bounded sequences for image of bounded linear operators,,Let $X$ and $Y$ be Banach spaces and $A:X\to Y$ be a bounded linear operator. Assume that $y\in \overline {A(X)}$. Can we always choose a bounded sequence $(x_n)\subset X$ such that $\displaystyle \lim_{n\to \infty} Ax_n=y$?,Let $X$ and $Y$ be Banach spaces and $A:X\to Y$ be a bounded linear operator. Assume that $y\in \overline {A(X)}$. Can we always choose a bounded sequence $(x_n)\subset X$ such that $\displaystyle \lim_{n\to \infty} Ax_n=y$?,,"['functional-analysis', 'banach-spaces']"
22,Show an operator on $L^2$ is compact,Show an operator on  is compact,L^2,"Let $X$ be the complex Lebesgue space $L^2(0,1)$. Let $T:X\to X$ be $(Tf)(x)=x\int_0^1 \int_0^r f(s)\ ds\ dr-\int_0^x\int_0^r f(s)\ ds\ dr$ Prove that $T$ is compact. Given a bounded sequence $\{f_n\}$ in $X$, we want to show $\{Tf_n\}$ has a convergent subsequence. I have shown that $|Tf(x)|\leq 2\lVert f \rVert$. Hence $\lVert Tf_n \rVert \leq 2 \lVert f_n \rVert$. Since $\{f_n\}$ is bounded, then $\{Tf_n\}$ is bounded. Hence there is a weakly convergent subsequence $\{Tf_{n_k}\}$. Then I don't know how to go from weakly convergent to strong convergent.","Let $X$ be the complex Lebesgue space $L^2(0,1)$. Let $T:X\to X$ be $(Tf)(x)=x\int_0^1 \int_0^r f(s)\ ds\ dr-\int_0^x\int_0^r f(s)\ ds\ dr$ Prove that $T$ is compact. Given a bounded sequence $\{f_n\}$ in $X$, we want to show $\{Tf_n\}$ has a convergent subsequence. I have shown that $|Tf(x)|\leq 2\lVert f \rVert$. Hence $\lVert Tf_n \rVert \leq 2 \lVert f_n \rVert$. Since $\{f_n\}$ is bounded, then $\{Tf_n\}$ is bounded. Hence there is a weakly convergent subsequence $\{Tf_{n_k}\}$. Then I don't know how to go from weakly convergent to strong convergent.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
23,Density of Fredholm operators,Density of Fredholm operators,,Let $X$ be a Banach space. It is well known that an operator $T\in B(X)$ is Fredholm if and only if $\pi(T)$ is invertible in the Calkin algebra $B(X)/K(X)$. Now suppose that the invertible elements in $B(X)/K(X)$ are dense. Can we conclude that Fredholm operators are dense in $B(X)$? Note that there exist spaces for which every operator $T\in B(X)$ is Fredholm with index 0.,Let $X$ be a Banach space. It is well known that an operator $T\in B(X)$ is Fredholm if and only if $\pi(T)$ is invertible in the Calkin algebra $B(X)/K(X)$. Now suppose that the invertible elements in $B(X)/K(X)$ are dense. Can we conclude that Fredholm operators are dense in $B(X)$? Note that there exist spaces for which every operator $T\in B(X)$ is Fredholm with index 0.,,"['functional-analysis', 'operator-theory', 'banach-spaces', 'banach-algebras']"
24,Prove that there is a unique function of class $C^1$ such that for all $x \in \mathbb{R}$: $x^2f(x)^3 + 3x^3f (x)^2 + (5x^4 + 1) f (x) = \cos (f (x))$,Prove that there is a unique function of class  such that for all :,C^1 x \in \mathbb{R} x^2f(x)^3 + 3x^3f (x)^2 + (5x^4 + 1) f (x) = \cos (f (x)),"Prove that there is a unique function $f: \mathbb{R} \to \mathbb{R}$ of class $C^1$ such that for all $x \in \mathbb{R}$: $$x^2f(x)^3  + 3x^3f (x)^2 + (5x^4 + 1) f (x) = \cos (f (x))$$ My work: Let $y=f(x)$ and by using implicit theorem is idea to solve this: $$F(x,y)=x^2y^3  + 3x^3y^2 + (5x^4 + 1)y - \cos (y)=0=F(x,f(x))$$ (F is class $C^1$) To show this we must show that: $\frac{\partial F}{\partial y}$ is regular matrix for all x. $$\frac{\partial F}{\partial y}(x,y)=3y^2x^2+6yx^3+5x^4+1-\sin(y)$$ $$\frac{\partial F}{\partial y}(x,y)=3y^2x^2+6yx^3+5x^4+1-\sin(y)=0$$  But for $(x,y)=(0,\pi/2)$ $F$ is 0 - which isn't good :/ What I did wrong?","Prove that there is a unique function $f: \mathbb{R} \to \mathbb{R}$ of class $C^1$ such that for all $x \in \mathbb{R}$: $$x^2f(x)^3  + 3x^3f (x)^2 + (5x^4 + 1) f (x) = \cos (f (x))$$ My work: Let $y=f(x)$ and by using implicit theorem is idea to solve this: $$F(x,y)=x^2y^3  + 3x^3y^2 + (5x^4 + 1)y - \cos (y)=0=F(x,f(x))$$ (F is class $C^1$) To show this we must show that: $\frac{\partial F}{\partial y}$ is regular matrix for all x. $$\frac{\partial F}{\partial y}(x,y)=3y^2x^2+6yx^3+5x^4+1-\sin(y)$$ $$\frac{\partial F}{\partial y}(x,y)=3y^2x^2+6yx^3+5x^4+1-\sin(y)=0$$  But for $(x,y)=(0,\pi/2)$ $F$ is 0 - which isn't good :/ What I did wrong?",,"['functional-analysis', 'multivariable-calculus', 'derivatives', 'proof-verification', 'partial-derivative']"
25,Reproducing kernel Hilbert space of set functions,Reproducing kernel Hilbert space of set functions,,"Let $\Omega$ be a finite set. Can we construct a reproducing kernel Hilbert space (RKHS) of real-valued functions $2^\Omega \to \mathbb{R}$? If so, how can we construct one and how is the kernel defined? Thank you!","Let $\Omega$ be a finite set. Can we construct a reproducing kernel Hilbert space (RKHS) of real-valued functions $2^\Omega \to \mathbb{R}$? If so, how can we construct one and how is the kernel defined? Thank you!",,"['functional-analysis', 'hilbert-spaces', 'machine-learning', 'reproducing-kernel-hilbert-spaces']"
26,Hahn-Banach Theorem and Elliptic PDEs,Hahn-Banach Theorem and Elliptic PDEs,,"Suppose $A$ is positive-definite and bounded.  For a fixed $u\in W^{1,2}(U)$, define $$ \ell_u(v)=\int_{U}A\nabla u\nabla v $$ for $v\in W^{1,2}(U)$.  Also suppose $\ell_u$ is bounded on some linear subspace $X$ of $W^{1,2}(U)$ (e.g., maybe $W^{1,2}_0(U)$).  Is there any conclusion I can draw regarding $\|u\|_{W^{1,2}(U)}$? By Hahn-Banach, I can extend $\ell_u$ uniquely to a bounded linear functional $\tilde{\ell}_u$ on $W^{1,2}(U)$ with $\|\ell_u\|=\|\tilde{\ell}_u\|$, but I don't think I'm guaranteed anymore information about $\tilde{\ell}_u$.  I can say $|\tilde{\ell}_u(u)|\leq \|\ell\|\|u\|_{W^{1,2}(U)}$, but is there anymore?","Suppose $A$ is positive-definite and bounded.  For a fixed $u\in W^{1,2}(U)$, define $$ \ell_u(v)=\int_{U}A\nabla u\nabla v $$ for $v\in W^{1,2}(U)$.  Also suppose $\ell_u$ is bounded on some linear subspace $X$ of $W^{1,2}(U)$ (e.g., maybe $W^{1,2}_0(U)$).  Is there any conclusion I can draw regarding $\|u\|_{W^{1,2}(U)}$? By Hahn-Banach, I can extend $\ell_u$ uniquely to a bounded linear functional $\tilde{\ell}_u$ on $W^{1,2}(U)$ with $\|\ell_u\|=\|\tilde{\ell}_u\|$, but I don't think I'm guaranteed anymore information about $\tilde{\ell}_u$.  I can say $|\tilde{\ell}_u(u)|\leq \|\ell\|\|u\|_{W^{1,2}(U)}$, but is there anymore?",,"['functional-analysis', 'partial-differential-equations']"
27,Closed Range Convolution Operator,Closed Range Convolution Operator,,Does there exists a nontrivial $f \in L^1(\mathbb{R})\cap L^\infty(\mathbb{R})$ such that $f\ast L^\infty(\mathbb{R})$ is a closed subspace of $L^\infty(\mathbb{R})$? I couldn't find any good reference on closed range convolution operators.,Does there exists a nontrivial $f \in L^1(\mathbb{R})\cap L^\infty(\mathbb{R})$ such that $f\ast L^\infty(\mathbb{R})$ is a closed subspace of $L^\infty(\mathbb{R})$? I couldn't find any good reference on closed range convolution operators.,,"['functional-analysis', 'operator-theory', 'convolution', 'open-map']"
28,Use the Cauchy-Schwarz inequality to prove $||x||_1 \leq \sqrt{n}||x||_2$,Use the Cauchy-Schwarz inequality to prove,||x||_1 \leq \sqrt{n}||x||_2,"If $x,y \in \mathbb{R}^n$, then the Cauchy-Schwarz Inequality tell us that $$|x^Ty| \leq ||x||_2||y||_2,$$ where \begin{align*} \|x\|_2 &= \sqrt{\sum_{i=1}^nx_i^2},\\  \|x\|_1 &= \sum_{i=1}^n|x_i|. \end{align*} To show that  $$||x||_1 \leq \sqrt{n}||x||_2,$$ we let $x = (|x_1|, |x_2|, \cdots, |x_n|)$ and $y = (1,1, \cdots, 1)$.  Then $$|x^Ty| \leq ||x||_2||x||_2 \Rightarrow |\sum_{i=1}^n|x_i|| \leq \sqrt{\sum_{i=1}^n|x_i|^2}\sqrt{\sum_{i=1}^n1},$$ but for each $i = 1,2, \ldots,n$, we have \begin{align*} |x_i| &>0,\\  |x_i|^2 &= x_i^2, \end{align*} hence it follows that  $$|\sum_{i=1}^n|x_i|| = \sum_{i=1}^n|x_i| \text{ and } \sqrt{\sum_{i=1}^n|x_i|^2} = \sqrt{\sum_{i=1}^nx_i^2}.$$ Therefore, $$|\sum_{i=1}^n|x_i|| \leq \sqrt{\sum_{i=1}^n|x_i|^2}\sqrt{\sum_{i=1}^n1} \Rightarrow ||x||_1 \leq \sqrt{n}||x||_2,$$ as required. Is this approach correct?","If $x,y \in \mathbb{R}^n$, then the Cauchy-Schwarz Inequality tell us that $$|x^Ty| \leq ||x||_2||y||_2,$$ where \begin{align*} \|x\|_2 &= \sqrt{\sum_{i=1}^nx_i^2},\\  \|x\|_1 &= \sum_{i=1}^n|x_i|. \end{align*} To show that  $$||x||_1 \leq \sqrt{n}||x||_2,$$ we let $x = (|x_1|, |x_2|, \cdots, |x_n|)$ and $y = (1,1, \cdots, 1)$.  Then $$|x^Ty| \leq ||x||_2||x||_2 \Rightarrow |\sum_{i=1}^n|x_i|| \leq \sqrt{\sum_{i=1}^n|x_i|^2}\sqrt{\sum_{i=1}^n1},$$ but for each $i = 1,2, \ldots,n$, we have \begin{align*} |x_i| &>0,\\  |x_i|^2 &= x_i^2, \end{align*} hence it follows that  $$|\sum_{i=1}^n|x_i|| = \sum_{i=1}^n|x_i| \text{ and } \sqrt{\sum_{i=1}^n|x_i|^2} = \sqrt{\sum_{i=1}^nx_i^2}.$$ Therefore, $$|\sum_{i=1}^n|x_i|| \leq \sqrt{\sum_{i=1}^n|x_i|^2}\sqrt{\sum_{i=1}^n1} \Rightarrow ||x||_1 \leq \sqrt{n}||x||_2,$$ as required. Is this approach correct?",,"['functional-analysis', 'inequality', 'proof-verification', 'normed-spaces']"
29,Reference text for Hilbert space theory.,Reference text for Hilbert space theory.,,"I am searching for a reference that contains a detailed discussion of most of the topics in Hilbert space theory. I am both interested in the geometry of Hilbert spaces and operators on Hilbert spaces. I am familiar with several excellent texts on Banach space theory; for example, Megginson's An Introduction to Banach Space Theory and Albiac & Fanton's Topics in Banach Space Theory . However, I am not aware of similar types of books for the theory of Hilbert spaces. The book that comes most closely to what I have in mind is probably Halmos' A Hilbert Space Problem Book . However, as the title of this book indicates, this book is meant as a problem book and not really a reference text. I am familiar with general topology, abstract measure theory, and functional analysis; so it is no problem if the book has these topics as a prerequisite (as Halmos' book has). All suggestions and comments are welcome.","I am searching for a reference that contains a detailed discussion of most of the topics in Hilbert space theory. I am both interested in the geometry of Hilbert spaces and operators on Hilbert spaces. I am familiar with several excellent texts on Banach space theory; for example, Megginson's An Introduction to Banach Space Theory and Albiac & Fanton's Topics in Banach Space Theory . However, I am not aware of similar types of books for the theory of Hilbert spaces. The book that comes most closely to what I have in mind is probably Halmos' A Hilbert Space Problem Book . However, as the title of this book indicates, this book is meant as a problem book and not really a reference text. I am familiar with general topology, abstract measure theory, and functional analysis; so it is no problem if the book has these topics as a prerequisite (as Halmos' book has). All suggestions and comments are welcome.",,"['functional-analysis', 'reference-request']"
30,How to prove a fomula is real or not?,How to prove a fomula is real or not?,,"The formula is: $$f(u):=\sqrt{1+i}\arctan\left(\dfrac{\sqrt{2}}{\sqrt{(-1+i)u}}\right)+\sqrt{1-i}\arctan\left(\frac{(-1)^{3/4}\sqrt{(-1-i)u}}{u}\right)\tag{1}$$ I obtained it from the following definite integral: $$f(u):=\int_u^{\infty } \frac{\sqrt{x}}{x^2-2 x+2} \, dx\quad {\text{ where }} u>0\tag{2}$$ Numercial estimation indicates that, when $u>0$, $f(u)\in \mathbb{R}$ because the imaginary part of the results are close to numerical epsilon. How to prove or disprove it? If the conclusion is true, is it possible to eliminate the imaginary unit $i$ from the fomula of $f(u)$ in $(1)$ and obtain a relatively simpler form of it which does not contain or implies any imaginary number? update $$f^*(u):=\frac{1}{2}\sqrt{\frac{1}{2}+\frac{1}{\sqrt{2}}} \left(\left(\sqrt{2}-1\right) \left(\ln \left(u-\sqrt{2 \left(1+\sqrt{2}\right)} \sqrt{u}+\sqrt{2}\right)-\ln \left(u+\sqrt{2 \left(1+\sqrt{2}\right)} \sqrt{u}+\sqrt{2}\right)\right)-2 \arctan\left(-\sqrt{2 \left(1+\sqrt{2}\right)} \sqrt{u}+\sqrt{2}+1\right)+2 \arctan\left(\sqrt{2 \left(1+\sqrt{2}\right)} \sqrt{u}+\sqrt{2}+1\right)-2 \pi \right)$$","The formula is: $$f(u):=\sqrt{1+i}\arctan\left(\dfrac{\sqrt{2}}{\sqrt{(-1+i)u}}\right)+\sqrt{1-i}\arctan\left(\frac{(-1)^{3/4}\sqrt{(-1-i)u}}{u}\right)\tag{1}$$ I obtained it from the following definite integral: $$f(u):=\int_u^{\infty } \frac{\sqrt{x}}{x^2-2 x+2} \, dx\quad {\text{ where }} u>0\tag{2}$$ Numercial estimation indicates that, when $u>0$, $f(u)\in \mathbb{R}$ because the imaginary part of the results are close to numerical epsilon. How to prove or disprove it? If the conclusion is true, is it possible to eliminate the imaginary unit $i$ from the fomula of $f(u)$ in $(1)$ and obtain a relatively simpler form of it which does not contain or implies any imaginary number? update $$f^*(u):=\frac{1}{2}\sqrt{\frac{1}{2}+\frac{1}{\sqrt{2}}} \left(\left(\sqrt{2}-1\right) \left(\ln \left(u-\sqrt{2 \left(1+\sqrt{2}\right)} \sqrt{u}+\sqrt{2}\right)-\ln \left(u+\sqrt{2 \left(1+\sqrt{2}\right)} \sqrt{u}+\sqrt{2}\right)\right)-2 \arctan\left(-\sqrt{2 \left(1+\sqrt{2}\right)} \sqrt{u}+\sqrt{2}+1\right)+2 \arctan\left(\sqrt{2 \left(1+\sqrt{2}\right)} \sqrt{u}+\sqrt{2}+1\right)-2 \pi \right)$$",,"['calculus', 'functional-analysis', 'trigonometry', 'complex-numbers', 'numerical-methods']"
31,Why do we need the extra condition of being 'Fredholm of index zero' when showing that an operator has a bounded inverse?,Why do we need the extra condition of being 'Fredholm of index zero' when showing that an operator has a bounded inverse?,,"In finite dimensional linear algebra if we have $A x = 0$, and $\ker(A) = 0$, then $A$ is invertible. But it seems having a trivial kernel is not a sufficient condition for invertibility when dealing with infinite dimensional operators. Consider the following theorem: Theorem Let $S_D: L^2(\partial D) \to W_1^2(\partial D)$ be the single layer potential for the Laplacian in $\mathbb{R}^3$ where $D$ is a bounded Lipschitz domain in $\mathbb{R}^3$. Let $\phi \in L^2(\partial D)$ satisfy  $$S_D[\phi] = 0 \quad \text{on} \quad \partial D.$$ It can be shown then that $\phi = 0$. Now we want to prove that $S_D$ has a bounded inverse. Proof As $W_1^2(\partial D) \hookrightarrow{} L^2(\partial D)$ is compact, and $S_D$ maps $L^2(\partial D)$ into $W_1^2(\partial D)$ boundedly, we have that $S_D$ is Fredholm with index zero. And as we have that $\ker(S_D) = \{0\}$, this means that $S_D$ has a bounded inverse. Question Unlike in a finite dimensional matrix problem, in this case having a trivial kernel $\ker(S_D) = \{0\}$ was not enough to show that $S_D$ is invertible. We also needed to show that $S_D$ is Fredholm with index zero . Why is this? I am not very experienced with Fredholm theory. I know that being Fredholm of index zero means that an operator has finite dimensional kernel finite dimensional cokernel closed range $\dim(\ker) - \dim(\text{coker}) = 0$ (for the index zero property) So why do we need these extra properties when dealing with the invertibility of an infinite dimensional operator as opposed to a finite dimensional matrix?","In finite dimensional linear algebra if we have $A x = 0$, and $\ker(A) = 0$, then $A$ is invertible. But it seems having a trivial kernel is not a sufficient condition for invertibility when dealing with infinite dimensional operators. Consider the following theorem: Theorem Let $S_D: L^2(\partial D) \to W_1^2(\partial D)$ be the single layer potential for the Laplacian in $\mathbb{R}^3$ where $D$ is a bounded Lipschitz domain in $\mathbb{R}^3$. Let $\phi \in L^2(\partial D)$ satisfy  $$S_D[\phi] = 0 \quad \text{on} \quad \partial D.$$ It can be shown then that $\phi = 0$. Now we want to prove that $S_D$ has a bounded inverse. Proof As $W_1^2(\partial D) \hookrightarrow{} L^2(\partial D)$ is compact, and $S_D$ maps $L^2(\partial D)$ into $W_1^2(\partial D)$ boundedly, we have that $S_D$ is Fredholm with index zero. And as we have that $\ker(S_D) = \{0\}$, this means that $S_D$ has a bounded inverse. Question Unlike in a finite dimensional matrix problem, in this case having a trivial kernel $\ker(S_D) = \{0\}$ was not enough to show that $S_D$ is invertible. We also needed to show that $S_D$ is Fredholm with index zero . Why is this? I am not very experienced with Fredholm theory. I know that being Fredholm of index zero means that an operator has finite dimensional kernel finite dimensional cokernel closed range $\dim(\ker) - \dim(\text{coker}) = 0$ (for the index zero property) So why do we need these extra properties when dealing with the invertibility of an infinite dimensional operator as opposed to a finite dimensional matrix?",,"['functional-analysis', 'operator-theory', 'sobolev-spaces']"
32,Show that linear functional $L(f) = \int_0^1 f(x) dx$ is continuous,Show that linear functional  is continuous,L(f) = \int_0^1 f(x) dx,"Let $(C[0,1], d_1)$ be a metric space of all continuous functions $f:[0,1] \to \mathbb{R}$, $d_1$ is the $L_1$ metric $$d_1(f,g) = \int\limits_0^1 |f(x) - g(x)| dx$$ Show that linear functional $L(f) = \int\limits_0^1 f(x) dx$ is   continuous I'm not sure what would be the easiest way to prove this claim, I feel like I am on the right track Proof Attempt: Recall $L$ is continuous if for all convergent sequence $(f_n), f_n    \to f$ as $n \to \infty \implies L(f_n) \to L(f)$ as $n \to \infty$ Let $(f_n)$ be a convergent sequence in $(C[0,1], d_1)$, we wish to show that $L(f_n) \to L(f)$ as $n \to \infty$ $f_n \to f$ if $\forall \epsilon >0, \exists N \in \mathbb{N}$, such that $\forall x \in [0,1], \forall n \geq N, d_1(f_n(x), f(x)) <    \epsilon$ By definition, $d_1(f_n(x), f(x)) < \epsilon \implies \int\limits_0^1    |f_n(x) - f(x)| dx < \epsilon$ If $L(f_n) \to L(f)$ as $n \to \infty$ then $|L(f_n) - L(f)| = |\int\limits_0^1 f_n(x) - f(x) dx| < \epsilon$ But $|\int\limits_0^1 f_n(x) - f(x) dx|  \leq \int\limits_0^1 |f_n(x) - f(x)| dx $ by triangle inequality, and $\int\limits_0^1 |f_n(x) - f(x)| dx  < \epsilon$ Therefore,  $L(f_n) \to L(f)$ as $n \to \infty$ Does this look correct?","Let $(C[0,1], d_1)$ be a metric space of all continuous functions $f:[0,1] \to \mathbb{R}$, $d_1$ is the $L_1$ metric $$d_1(f,g) = \int\limits_0^1 |f(x) - g(x)| dx$$ Show that linear functional $L(f) = \int\limits_0^1 f(x) dx$ is   continuous I'm not sure what would be the easiest way to prove this claim, I feel like I am on the right track Proof Attempt: Recall $L$ is continuous if for all convergent sequence $(f_n), f_n    \to f$ as $n \to \infty \implies L(f_n) \to L(f)$ as $n \to \infty$ Let $(f_n)$ be a convergent sequence in $(C[0,1], d_1)$, we wish to show that $L(f_n) \to L(f)$ as $n \to \infty$ $f_n \to f$ if $\forall \epsilon >0, \exists N \in \mathbb{N}$, such that $\forall x \in [0,1], \forall n \geq N, d_1(f_n(x), f(x)) <    \epsilon$ By definition, $d_1(f_n(x), f(x)) < \epsilon \implies \int\limits_0^1    |f_n(x) - f(x)| dx < \epsilon$ If $L(f_n) \to L(f)$ as $n \to \infty$ then $|L(f_n) - L(f)| = |\int\limits_0^1 f_n(x) - f(x) dx| < \epsilon$ But $|\int\limits_0^1 f_n(x) - f(x) dx|  \leq \int\limits_0^1 |f_n(x) - f(x)| dx $ by triangle inequality, and $\int\limits_0^1 |f_n(x) - f(x)| dx  < \epsilon$ Therefore,  $L(f_n) \to L(f)$ as $n \to \infty$ Does this look correct?",,"['real-analysis', 'functional-analysis', 'proof-verification', 'convergence-divergence', 'metric-spaces']"
33,Is it true that $\|Du\|_{L^{2p}} \le C\|u\|_{L^\infty}^{1\over2} \|D^2u\|_{L^p}^{1\over 2}$?,Is it true that ?,\|Du\|_{L^{2p}} \le C\|u\|_{L^\infty}^{1\over2} \|D^2u\|_{L^p}^{1\over 2},Is it true that$$\|Du\|_{L^{2p}} \le C\|u\|_{L^\infty}^{1\over2} \|D^2u\|_{L^p}^{1\over 2}$$for $1 \le p < \infty$ and all $u \in C_c^\infty(U)$?,Is it true that$$\|Du\|_{L^{2p}} \le C\|u\|_{L^\infty}^{1\over2} \|D^2u\|_{L^p}^{1\over 2}$$for $1 \le p < \infty$ and all $u \in C_c^\infty(U)$?,,"['real-analysis', 'functional-analysis']"
34,"Two questions about a function in $W^{1, p}(0, 1)$.",Two questions about a function in .,"W^{1, p}(0, 1)","Let $f \in W^{1, p}(0, 1)$ with $1 < p < \infty$. If $f(0) = 0$, then does it necessarily follow that$${{f(x)}\over x} \in L^p(0, 1)$$and$$\left\|{{f(x)}\over x}\right\|_{L^p(0, 1)} \le {p\over{p - 1}}\|f'\|_{L^p(0, 1)}?$$ Conversely, assume that $f \in W^{1, p}(0, 1)$ with $1 \le p < \infty$ and that$${{f(x)}\over x} \in L^p(0, 1).$$Does it necessarily follow that $f(0) = 0$?","Let $f \in W^{1, p}(0, 1)$ with $1 < p < \infty$. If $f(0) = 0$, then does it necessarily follow that$${{f(x)}\over x} \in L^p(0, 1)$$and$$\left\|{{f(x)}\over x}\right\|_{L^p(0, 1)} \le {p\over{p - 1}}\|f'\|_{L^p(0, 1)}?$$ Conversely, assume that $f \in W^{1, p}(0, 1)$ with $1 \le p < \infty$ and that$${{f(x)}\over x} \in L^p(0, 1).$$Does it necessarily follow that $f(0) = 0$?",,"['real-analysis', 'analysis']"
35,Check the proof of $||x||^2$ is not a norm,Check the proof of  is not a norm,||x||^2,"Show if $f$ is a norm: For $\mathbb{R}^n$, Define $f: \mathbb{R}^n \rightarrow \mathbb{R} $ by $ f(x) = \|x\|^2$ =$\sum_{n} x_n^2 $ I tried to solve if $f$ satisfies the three properties of a norm: 1) zero vector 2)positive homogeneity 3)Triangle Inequality. It satisfies the 1st property obviously. For the 2nd property, I got $f(ax)= ||ax||^2=ax \cdot ax=a^2||x||^2 \neq |a|||x||^2$, so $f$ does not satisfy the 2nd property. For the 3rd property, I got $f(x+y)=||x+y||^2=(x+y)\cdot (x+y)=||x||^2+2x\cdot y+||y||^2$. In order to satisfy the triangle inequality, it has to be that $||x||^2+2x\cdot y+||y||^2 \le ||x||^2+||y||^2$, i.e, $x \cdot y \le 0$, but there's no guarantee that $x \cdot y \le 0$, therefore the triangule inequality is not satisfied. Since $f$ does not satisfy the second and third property, it is not a norm in $\Bbb R^n$. Is the above proof correct? If it's not right, could someone provide a proof of this problem? Thanks.","Show if $f$ is a norm: For $\mathbb{R}^n$, Define $f: \mathbb{R}^n \rightarrow \mathbb{R} $ by $ f(x) = \|x\|^2$ =$\sum_{n} x_n^2 $ I tried to solve if $f$ satisfies the three properties of a norm: 1) zero vector 2)positive homogeneity 3)Triangle Inequality. It satisfies the 1st property obviously. For the 2nd property, I got $f(ax)= ||ax||^2=ax \cdot ax=a^2||x||^2 \neq |a|||x||^2$, so $f$ does not satisfy the 2nd property. For the 3rd property, I got $f(x+y)=||x+y||^2=(x+y)\cdot (x+y)=||x||^2+2x\cdot y+||y||^2$. In order to satisfy the triangle inequality, it has to be that $||x||^2+2x\cdot y+||y||^2 \le ||x||^2+||y||^2$, i.e, $x \cdot y \le 0$, but there's no guarantee that $x \cdot y \le 0$, therefore the triangule inequality is not satisfied. Since $f$ does not satisfy the second and third property, it is not a norm in $\Bbb R^n$. Is the above proof correct? If it's not right, could someone provide a proof of this problem? Thanks.",,"['real-analysis', 'functional-analysis']"
36,Almost orthogonal collection of $L^{2}$ functions,Almost orthogonal collection of  functions,L^{2},"Suppose I had an infinite sequence of smooth compactly supported functions $\{f_{n}\}_{n \geq 1}$ such that for each $n$, $f_{n}$ is mutually orthogonal to all but a fixed absolute constant $C$ of the other $f_{m}$. That is, $\int_{\mathbb{R}}f_{m}f_{n}\, dx = 0$ for all but $C$ of the other functions in $\{f_{n}\}_{n \geq 1}$ (where $C$ is independent of $n$). Is it true that $$\left\|\sum_{n \geq 1}f_{n}\right\|_{L^{2}(\mathbb{R}^n)} \leq C'\left(\sum_{n \geq 1}\|f_{n}\|_{L^{2}(\mathbb{R}^n)}^{2}\right)^{1/2}$$ for some absolute constant $C'$?","Suppose I had an infinite sequence of smooth compactly supported functions $\{f_{n}\}_{n \geq 1}$ such that for each $n$, $f_{n}$ is mutually orthogonal to all but a fixed absolute constant $C$ of the other $f_{m}$. That is, $\int_{\mathbb{R}}f_{m}f_{n}\, dx = 0$ for all but $C$ of the other functions in $\{f_{n}\}_{n \geq 1}$ (where $C$ is independent of $n$). Is it true that $$\left\|\sum_{n \geq 1}f_{n}\right\|_{L^{2}(\mathbb{R}^n)} \leq C'\left(\sum_{n \geq 1}\|f_{n}\|_{L^{2}(\mathbb{R}^n)}^{2}\right)^{1/2}$$ for some absolute constant $C'$?",,"['real-analysis', 'analysis', 'functional-analysis', 'hilbert-spaces', 'orthogonality']"
37,When is the completion of a space of functions a space of functions?,When is the completion of a space of functions a space of functions?,,"If $V$ is a $\mathbb C$-vector space of functions $f: X \to \mathbb C$ on some common domain $X$ and $\tau$ is a Hausdorff, locally convex topology on $V$, when may the completion of $(V,\tau)$ also be realized as a space of functions on $X$? Are there any general conditions that can be imposed on $V$ and $\tau$ that will ensure this? Since completions are, of course, determined only up to isomorphism, the question is perhaps in too imprecise a form to provide a meaningful answer, but it's motivated by the difference between basic examples from functional analysis. Compare, for instance, the difference between (1) the space of polynomials on $[0,1]$ having completion $C[0,1]$ (a space of functions on $[0,1]$) under the uniform norm and (2) the vector space of integrable simple functions on $[0,1]$ having $L^p[0,1]$ as its completion with respect to $\|\cdot\|_p$. More dramatic examples than (2) appear to be common. One from Sobolev theory I stumbled on recently can be found in Theorem 3.1 and the subsequent Remark in this article . Thank you for any help or references you can provide.","If $V$ is a $\mathbb C$-vector space of functions $f: X \to \mathbb C$ on some common domain $X$ and $\tau$ is a Hausdorff, locally convex topology on $V$, when may the completion of $(V,\tau)$ also be realized as a space of functions on $X$? Are there any general conditions that can be imposed on $V$ and $\tau$ that will ensure this? Since completions are, of course, determined only up to isomorphism, the question is perhaps in too imprecise a form to provide a meaningful answer, but it's motivated by the difference between basic examples from functional analysis. Compare, for instance, the difference between (1) the space of polynomials on $[0,1]$ having completion $C[0,1]$ (a space of functions on $[0,1]$) under the uniform norm and (2) the vector space of integrable simple functions on $[0,1]$ having $L^p[0,1]$ as its completion with respect to $\|\cdot\|_p$. More dramatic examples than (2) appear to be common. One from Sobolev theory I stumbled on recently can be found in Theorem 3.1 and the subsequent Remark in this article . Thank you for any help or references you can provide.",,"['functional-analysis', 'vector-spaces', 'normed-spaces']"
38,Connection of Fourier's work with Fredholm's,Connection of Fourier's work with Fredholm's,,"Im trying to formulate for myself in what sense Fredholms work on the Dirichlet problem is connected to Fouriers work on the heat equation. Fourier idea seems to have fundamental problems with convergence, while Fredholm concerns himself with existence of solutions via the integral equation $I \lambda - K$. There doesn't seem to be any series or convergence in the work of Fredholm, also anyone writing about the work of Fredholms have an abstract kernel $K$ and do not say anything about how this looked in his specific problems which makes it even harder to see the connection. Is there simple explanation why these problems seem so far apart? Own idea ; Fourier suggest solution in term of series. No one knows what this expression represent. Fredholm doesn't investigate the solution itself but rather tries showing that some solution exists. If it doesn't then fourier expression might not even be well defined. It turns out that this has solutions, and then people carry on investigating the convergence. Am I on the right track?","Im trying to formulate for myself in what sense Fredholms work on the Dirichlet problem is connected to Fouriers work on the heat equation. Fourier idea seems to have fundamental problems with convergence, while Fredholm concerns himself with existence of solutions via the integral equation $I \lambda - K$. There doesn't seem to be any series or convergence in the work of Fredholm, also anyone writing about the work of Fredholms have an abstract kernel $K$ and do not say anything about how this looked in his specific problems which makes it even harder to see the connection. Is there simple explanation why these problems seem so far apart? Own idea ; Fourier suggest solution in term of series. No one knows what this expression represent. Fredholm doesn't investigate the solution itself but rather tries showing that some solution exists. If it doesn't then fourier expression might not even be well defined. It turns out that this has solutions, and then people carry on investigating the convergence. Am I on the right track?",,"['functional-analysis', 'partial-differential-equations', 'fourier-analysis', 'operator-theory', 'math-history']"
39,"Trace-class, Hilbert Schmidt operators, $L^p(H)$: duality theorems","Trace-class, Hilbert Schmidt operators, : duality theorems",L^p(H),"Let $H$ be a Hilbert space, separable if necessary, and let $tr$ be the usual trace on $L^1(H)$. It is classical theory that $K(H)^*=L^1(H)$, and $L^1(H)^*=B(H)$, via the canonical application $\langle T,S\rangle=tr(TS)$ for suitable $T$ and $S$. It is often mentioned that these duality results are analogous to the well-known $c_0^*=\ell_1$ and $\ell_1^*=\ell_\infty$. I think I more or less understand how this analogy works: The operator norm in $B(H)$ is the uniform norm when we restrict the maps to the unit ball, so $B(H)$ consists of the maps with finite ""uniform norm"", $K(H)$ consists of the elements which can be approximated by finite rank ones, and these are clear analogues of $\ell_\infty$ and $c_0$, respectively. I see more or less the analogy between $L^1(H)$ and $\ell_1$: identify the $i$-th element of a fixed basis for $H$ with the $i$-coordinate function in $\ell^1$, but I don't really see, precisely, how $\langle T\xi_i,\xi_i\rangle$ relates with $x_i$, for $T\in L^1(H)$ and $x=(x_i)\in\ell_1$. My question is what is the precise relation between these two duality results. More precisely, Question 1 : Can we obtain the duality results $c_0^*=\ell_1$ and $\ell_1^*=\ell_\infty$ from $K(H)^*=L^1(H)$ and $L^1(H)^*=B(H)$? What if we consider a measure/probability space $(X,\mu)$ instead of $\mathbb{N}$ with counting measure (although $c_0$ has no analogue in this case). More generaly, we might define $L^p(H)$ to consist of those $T\in B(H)$ for which the ""norm"" $\Vert T\Vert_p=(\Vert |T|^p\Vert_1)^{1/p}$ is finite. I'm not sure if this is indeed a complete norm, but if we assume so, it is natural to ask: Question 2 : Let $p$ and $q$ be (finite) Hölder conjugates. Are $L^p(H)$ and $L^q(H)$ duals of each other (with the usual application $\langle T,S\rangle=tr(TS)$), and does this indeed generalize the duality of $\ell^p$ and $\ell^q$? Moreover, is the map $p\mapsto\Vert T\Vert_p$ continuous in some sense and does $\Vert T\Vert_p$ converges to $\Vert T\Vert$ as $p\to \infty$ for $T\in \cap_p L^p(H)$? I'm interested in these questions to understand better how tracial von Neumann algebras/$II_1$ factors are related to probability spaces, and the importance of the Hilbert-Schmidt norm on such algebras.","Let $H$ be a Hilbert space, separable if necessary, and let $tr$ be the usual trace on $L^1(H)$. It is classical theory that $K(H)^*=L^1(H)$, and $L^1(H)^*=B(H)$, via the canonical application $\langle T,S\rangle=tr(TS)$ for suitable $T$ and $S$. It is often mentioned that these duality results are analogous to the well-known $c_0^*=\ell_1$ and $\ell_1^*=\ell_\infty$. I think I more or less understand how this analogy works: The operator norm in $B(H)$ is the uniform norm when we restrict the maps to the unit ball, so $B(H)$ consists of the maps with finite ""uniform norm"", $K(H)$ consists of the elements which can be approximated by finite rank ones, and these are clear analogues of $\ell_\infty$ and $c_0$, respectively. I see more or less the analogy between $L^1(H)$ and $\ell_1$: identify the $i$-th element of a fixed basis for $H$ with the $i$-coordinate function in $\ell^1$, but I don't really see, precisely, how $\langle T\xi_i,\xi_i\rangle$ relates with $x_i$, for $T\in L^1(H)$ and $x=(x_i)\in\ell_1$. My question is what is the precise relation between these two duality results. More precisely, Question 1 : Can we obtain the duality results $c_0^*=\ell_1$ and $\ell_1^*=\ell_\infty$ from $K(H)^*=L^1(H)$ and $L^1(H)^*=B(H)$? What if we consider a measure/probability space $(X,\mu)$ instead of $\mathbb{N}$ with counting measure (although $c_0$ has no analogue in this case). More generaly, we might define $L^p(H)$ to consist of those $T\in B(H)$ for which the ""norm"" $\Vert T\Vert_p=(\Vert |T|^p\Vert_1)^{1/p}$ is finite. I'm not sure if this is indeed a complete norm, but if we assume so, it is natural to ask: Question 2 : Let $p$ and $q$ be (finite) Hölder conjugates. Are $L^p(H)$ and $L^q(H)$ duals of each other (with the usual application $\langle T,S\rangle=tr(TS)$), and does this indeed generalize the duality of $\ell^p$ and $\ell^q$? Moreover, is the map $p\mapsto\Vert T\Vert_p$ continuous in some sense and does $\Vert T\Vert_p$ converges to $\Vert T\Vert$ as $p\to \infty$ for $T\in \cap_p L^p(H)$? I'm interested in these questions to understand better how tracial von Neumann algebras/$II_1$ factors are related to probability spaces, and the importance of the Hilbert-Schmidt norm on such algebras.",,['functional-analysis']
40,Boundary conditions for Green's function?,Boundary conditions for Green's function?,,"I have been told that when using green's function we need boundary conditions of that are homogenous and of the form:  $$\alpha y(a)+\beta y'(a)+\gamma y(b)+\epsilon y'(b)=0$$ But I cannot see the reason for the need of boundary conditions like this, why won't any boundary conditions work?","I have been told that when using green's function we need boundary conditions of that are homogenous and of the form:  $$\alpha y(a)+\beta y'(a)+\gamma y(b)+\epsilon y'(b)=0$$ But I cannot see the reason for the need of boundary conditions like this, why won't any boundary conditions work?",,"['functional-analysis', 'greens-function']"
41,"Every complete orthonormal set in a Hilbert space $H$ is an orthonormal basis, if and only if $H$ is finite dimensional.","Every complete orthonormal set in a Hilbert space  is an orthonormal basis, if and only if  is finite dimensional.",H H,"Show that any orthonormal set in a Hilbert space $H$ is linearly independent, and use this to show that $H$ is finite dimensional if and only if every complete orthonormal set is an orthonormal basis. Attempt: Trying to show that every orthonormal set is linearly independent is easy if the set is countable, but if it weren't, I'm uncomfortable about considering uncountable sums ($\sum_{\alpha \in I} c_{\alpha}e_{\alpha} = 0$). Anyway around this? Once I show linear independence, how do prove the claim using it?","Show that any orthonormal set in a Hilbert space $H$ is linearly independent, and use this to show that $H$ is finite dimensional if and only if every complete orthonormal set is an orthonormal basis. Attempt: Trying to show that every orthonormal set is linearly independent is easy if the set is countable, but if it weren't, I'm uncomfortable about considering uncountable sums ($\sum_{\alpha \in I} c_{\alpha}e_{\alpha} = 0$). Anyway around this? Once I show linear independence, how do prove the claim using it?",,"['functional-analysis', 'hilbert-spaces', 'orthonormal']"
42,(Exponential) Growth of Operator Norm of Uncentered Maximal Function,(Exponential) Growth of Operator Norm of Uncentered Maximal Function,,"Define the uncentered Hardy-Littlewood maximal operator $M$ by $$Mf(x):=\sup_{x\in B}\dfrac{1}{\left|B\right|}\int_{B}\left|f\right|,$$ where we the supremum is taken over all (open) balls $B$ containing the point $x\in\mathbb{R}^{n}$. Let $f_{0}$ denote the characteristic function of the unit ball. I am trying to show that for $1<p<\infty$, $$\lim_{n\rightarrow\infty}\dfrac{\left\|Mf_{0}\right\|_{L^{p}}}{\left\|f_{0}\right\|_{L^{p}}}=\infty > \tag{1}$$ by following the suggestion in Exercise 2.1.8 of L. Grafakos, Classical Fourier Analysis (Third Edition). Actually, I would like to show that the growth of the $L^{p}\rightarrow L^{p}$ is exponential in the dimension $n$, but I'll settle for the above. Let $B_{0}$ denote the unit ball, and for $\left|x\right|>1$, let $B_{x}$ be the ball with center $c$ and radius $r$ given by $$c=\dfrac{(\left|x\right|-\left|x\right|^{-1})}{2}\dfrac{x}{\left|x\right|},\quad r=\dfrac{(\left|x\right|+\left|x\right|^{-1})}{2}$$ Observe that $x\in B_{x}$, so  $$Mf(x)\geq\dfrac{1}{\left|B_{x}\right|}\int_{B_{x}}\left|f_{0}\right|=\dfrac{2^{n}}{(\left|x\right|+\left|x\right|^{-1})^{n}\left|B_{0}\right|}\left|B_{x}\cap B_{0}\right|$$ Since \begin{align*} \dfrac{1}{4}\left(\left|x\right|-\left|x\right|^{-1}\right)^{2}+1&=\dfrac{\left|x\right|^{2}}{4}+\dfrac{\left|x\right|^{-2}}{4}+\dfrac{1}{2}=\left(\dfrac{\left|x\right|+\left|x\right|^{-1}}{2}\right)^{2}, \end{align*} we see that $B_{x}\cap B_{0}$ contains $B_{x}\cap B_{0}$ contains a ""half-ball"" of $B_{1}(0)$and a hyperspherical cap of height $\left|x\right|^{-1}$ and radius $(\left|x\right|+\left|x\right|^{-1})/2$, which we denote by $C_{x}$. In particular, $$\left|B_{x}\cap B_{0}\right|\geq\dfrac{1}{2}\left|B_{0}\right|+\left|C_{x}\right|$$ My initial thought was to simplify things and ignore the term $\left|C_{x}\right|$ to get the lower bound $$Mf(x)\geq\dfrac{2^{n-1}}{(\left|x\right|+\left|x\right|^{-1})^{n}},\quad\forall \left|x\right|>1$$ Thus, \begin{align*} \dfrac{\left\|Mf\right\|_{L^{p}}}{\left\|f_{0}\right\|_{L^{p}}}&\geq\dfrac{2^{n-1}}{(n^{-1}\omega_{n-1})^{1/p}}\left(\int_{\left|x\right|>1}\dfrac{1}{(\left|x\right|+\left|x\right|^{-1})^{np}}dx\right)^{1/p}\\ &=\dfrac{2^{n-1}}{(n^{-1}\omega_{n-1})^{1/p}}\left(\int_{1}^{\infty}\dfrac{r^{n-1}}{(r+r^{-1})^{np}}dr\int_{S^{n-1}}d\theta dr\right)^{1/p}\\ &=2^{n-1}n^{1/p}\left(\int_{1}^{\infty}\dfrac{r^{n-1}}{(r+r^{-1})^{np}}dr\right)^{1/p} \end{align*} I'm having trouble giving a useful asymptotic for the integral factor above. Perhaps, I errored in ignoring $\left|C_{x}\right|$. I would greatly appreciate any suggestions in how to proceed. Edit 1: Plugging in some special values of $p$ into Wolfram Alpha, it looks like hypergeometric functions might be relevant here.","Define the uncentered Hardy-Littlewood maximal operator $M$ by $$Mf(x):=\sup_{x\in B}\dfrac{1}{\left|B\right|}\int_{B}\left|f\right|,$$ where we the supremum is taken over all (open) balls $B$ containing the point $x\in\mathbb{R}^{n}$. Let $f_{0}$ denote the characteristic function of the unit ball. I am trying to show that for $1<p<\infty$, $$\lim_{n\rightarrow\infty}\dfrac{\left\|Mf_{0}\right\|_{L^{p}}}{\left\|f_{0}\right\|_{L^{p}}}=\infty > \tag{1}$$ by following the suggestion in Exercise 2.1.8 of L. Grafakos, Classical Fourier Analysis (Third Edition). Actually, I would like to show that the growth of the $L^{p}\rightarrow L^{p}$ is exponential in the dimension $n$, but I'll settle for the above. Let $B_{0}$ denote the unit ball, and for $\left|x\right|>1$, let $B_{x}$ be the ball with center $c$ and radius $r$ given by $$c=\dfrac{(\left|x\right|-\left|x\right|^{-1})}{2}\dfrac{x}{\left|x\right|},\quad r=\dfrac{(\left|x\right|+\left|x\right|^{-1})}{2}$$ Observe that $x\in B_{x}$, so  $$Mf(x)\geq\dfrac{1}{\left|B_{x}\right|}\int_{B_{x}}\left|f_{0}\right|=\dfrac{2^{n}}{(\left|x\right|+\left|x\right|^{-1})^{n}\left|B_{0}\right|}\left|B_{x}\cap B_{0}\right|$$ Since \begin{align*} \dfrac{1}{4}\left(\left|x\right|-\left|x\right|^{-1}\right)^{2}+1&=\dfrac{\left|x\right|^{2}}{4}+\dfrac{\left|x\right|^{-2}}{4}+\dfrac{1}{2}=\left(\dfrac{\left|x\right|+\left|x\right|^{-1}}{2}\right)^{2}, \end{align*} we see that $B_{x}\cap B_{0}$ contains $B_{x}\cap B_{0}$ contains a ""half-ball"" of $B_{1}(0)$and a hyperspherical cap of height $\left|x\right|^{-1}$ and radius $(\left|x\right|+\left|x\right|^{-1})/2$, which we denote by $C_{x}$. In particular, $$\left|B_{x}\cap B_{0}\right|\geq\dfrac{1}{2}\left|B_{0}\right|+\left|C_{x}\right|$$ My initial thought was to simplify things and ignore the term $\left|C_{x}\right|$ to get the lower bound $$Mf(x)\geq\dfrac{2^{n-1}}{(\left|x\right|+\left|x\right|^{-1})^{n}},\quad\forall \left|x\right|>1$$ Thus, \begin{align*} \dfrac{\left\|Mf\right\|_{L^{p}}}{\left\|f_{0}\right\|_{L^{p}}}&\geq\dfrac{2^{n-1}}{(n^{-1}\omega_{n-1})^{1/p}}\left(\int_{\left|x\right|>1}\dfrac{1}{(\left|x\right|+\left|x\right|^{-1})^{np}}dx\right)^{1/p}\\ &=\dfrac{2^{n-1}}{(n^{-1}\omega_{n-1})^{1/p}}\left(\int_{1}^{\infty}\dfrac{r^{n-1}}{(r+r^{-1})^{np}}dr\int_{S^{n-1}}d\theta dr\right)^{1/p}\\ &=2^{n-1}n^{1/p}\left(\int_{1}^{\infty}\dfrac{r^{n-1}}{(r+r^{-1})^{np}}dr\right)^{1/p} \end{align*} I'm having trouble giving a useful asymptotic for the integral factor above. Perhaps, I errored in ignoring $\left|C_{x}\right|$. I would greatly appreciate any suggestions in how to proceed. Edit 1: Plugging in some special values of $p$ into Wolfram Alpha, it looks like hypergeometric functions might be relevant here.",,"['functional-analysis', 'measure-theory', 'asymptotics', 'harmonic-analysis', 'hypergeometric-function']"
43,Characterization of normal operators on Hilbert space as function of a self-adjoint operator,Characterization of normal operators on Hilbert space as function of a self-adjoint operator,,"My question : Suppose T is a normal operator on a Hilbert space H. Show that there exists a self-adjoint operator S on H such that T=f(S), where f is continuous function from spectrum of S into S. My approach to the problem was to find out an operator S and show that the $C^*$ algebra generated by $I$ and $S$ includes T. Then, continuous functional calculus would prove the result. So my first guess was to choose $S=(T+T^*)/2$. However, I have been unable to show that T is the limit of some polynomial in S. Is my intuition about the problem correct? In that case, please provide some suggestions regarding how to show that T is in the unital sub-algebra generated by S?","My question : Suppose T is a normal operator on a Hilbert space H. Show that there exists a self-adjoint operator S on H such that T=f(S), where f is continuous function from spectrum of S into S. My approach to the problem was to find out an operator S and show that the $C^*$ algebra generated by $I$ and $S$ includes T. Then, continuous functional calculus would prove the result. So my first guess was to choose $S=(T+T^*)/2$. However, I have been unable to show that T is the limit of some polynomial in S. Is my intuition about the problem correct? In that case, please provide some suggestions regarding how to show that T is in the unital sub-algebra generated by S?",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
44,Proof that every finite-dimensional normed space is reflexive,Proof that every finite-dimensional normed space is reflexive,,"Let $X$ be a finite-dimensional normed vector space. Let $X^*$ denote the space of linear dual space of $X$ , i.e. $X^*=L(X,\mathbb{C})$ and let $X^{**}$ be the dual space of $X^*$ . For each $x\in X$ , define $\hat{x}:X^*\to \mathbb{C}$ by $\hat{x}(f)=f(x)$ . Let $\hat{X}=\{\hat{x}:x\in X\}$ .  Verify that $X^{**}$ and $\hat{X}$ have the same dimension and therefore are the same. It is a reformulation from a passage in Folland (p. 159). I know how to find the dimension of $X^{**}$ (In general if $\dim X=n$ and $\dim Y=m$ , $\dim(L(X,Y))=nm$ ). But how can I know $\hat{X}$ has the same dimension?","Let be a finite-dimensional normed vector space. Let denote the space of linear dual space of , i.e. and let be the dual space of . For each , define by . Let .  Verify that and have the same dimension and therefore are the same. It is a reformulation from a passage in Folland (p. 159). I know how to find the dimension of (In general if and , ). But how can I know has the same dimension?","X X^* X X^*=L(X,\mathbb{C}) X^{**} X^* x\in X \hat{x}:X^*\to \mathbb{C} \hat{x}(f)=f(x) \hat{X}=\{\hat{x}:x\in X\} X^{**} \hat{X} X^{**} \dim X=n \dim Y=m \dim(L(X,Y))=nm \hat{X}","['real-analysis', 'functional-analysis', 'reflexive-space']"
45,“Smallness” of the set of Archimedean copulas in the set of all exchangeable copulas,“Smallness” of the set of Archimedean copulas in the set of all exchangeable copulas,,"This is a little bit of a vague question I guess. Let us for simplicity consider bivariate copulas. We can think aboutset $\mathcal{C}$ of all exchangeable copulas: that is, these are copulas $C: [0,1]^2\rightarrow [0,1]$ that satisfy the following condition:  $$C(u,v)=C(v,u).$$ We can also consider a subset $\mathcal{C}_0 \subset \mathcal{C}$ of Archimedean copulas $-$ these are copulas represented in the following form:  $$C(u,v)=\phi^{[-1]}(\phi(u)+\phi(v)), \text{ where } $$ the generator $\phi:[0,1] \rightarrow [0,\infty)$ is a continuous, strictly decreasing and convex function such that $\phi(1)=0$. The pseudo-inverse $\phi^{[-1]}$ is defined as  $$\phi^{[-1]}(t)= \left\{ \begin{array}{l} \phi^{-1}(t), \quad \text{if } 0\leq t \leq \phi(0),\\ 0, \quad \text{if } \phi(0)<t. \end{array} \right. $$ My question is how “small” $\mathcal{C}_0$ is in larger $\mathcal{C}$. I am not sure what meaning and what notion of smallness would be appropriate here.","This is a little bit of a vague question I guess. Let us for simplicity consider bivariate copulas. We can think aboutset $\mathcal{C}$ of all exchangeable copulas: that is, these are copulas $C: [0,1]^2\rightarrow [0,1]$ that satisfy the following condition:  $$C(u,v)=C(v,u).$$ We can also consider a subset $\mathcal{C}_0 \subset \mathcal{C}$ of Archimedean copulas $-$ these are copulas represented in the following form:  $$C(u,v)=\phi^{[-1]}(\phi(u)+\phi(v)), \text{ where } $$ the generator $\phi:[0,1] \rightarrow [0,\infty)$ is a continuous, strictly decreasing and convex function such that $\phi(1)=0$. The pseudo-inverse $\phi^{[-1]}$ is defined as  $$\phi^{[-1]}(t)= \left\{ \begin{array}{l} \phi^{-1}(t), \quad \text{if } 0\leq t \leq \phi(0),\\ 0, \quad \text{if } \phi(0)<t. \end{array} \right. $$ My question is how “small” $\mathcal{C}_0$ is in larger $\mathcal{C}$. I am not sure what meaning and what notion of smallness would be appropriate here.",,"['real-analysis', 'functional-analysis', 'probability-theory', 'probability-distributions']"
46,Hilbert vs. De Morgan,Hilbert vs. De Morgan,,"Problem Given a Hilbert space $\mathcal{H}$. Then it holds:   $$\overline{\left\langle\bigcap_{\lambda\in\Lambda}A_\lambda^\perp\right\rangle}=\left(\bigcup_{\lambda\in\Lambda}A_\lambda\right)^\perp\quad\overline{\left\langle\bigcup_{\lambda\in\Lambda}A_\lambda^\perp\right\rangle}=\left(\bigcap_{\lambda\in\Lambda}A_\lambda\right)^\perp$$   How can I prove this? Span, closure, orthogonal complement: $\langle A\rangle$, $\overline{A}$, $A^\perp$ Application This applies in: Beppo-Levi","Problem Given a Hilbert space $\mathcal{H}$. Then it holds:   $$\overline{\left\langle\bigcap_{\lambda\in\Lambda}A_\lambda^\perp\right\rangle}=\left(\bigcup_{\lambda\in\Lambda}A_\lambda\right)^\perp\quad\overline{\left\langle\bigcup_{\lambda\in\Lambda}A_\lambda^\perp\right\rangle}=\left(\bigcap_{\lambda\in\Lambda}A_\lambda\right)^\perp$$   How can I prove this? Span, closure, orthogonal complement: $\langle A\rangle$, $\overline{A}$, $A^\perp$ Application This applies in: Beppo-Levi",,"['functional-analysis', 'hilbert-spaces']"
47,Reference request: The compactness and compact embedding in Besov Space?,Reference request: The compactness and compact embedding in Besov Space?,,"This post has been on MathOverflow for couple of days but receive no response. So I put it here hoping for more attentions. Thank you guys! Let $\Omega\subset \mathbb R^N$ be open bounded with smooth boundary. Let $0<s<1$, $1\leq p<\infty$, and $1\leq \theta\leq\infty$. We denote by $B^{s;p,\theta}(\Omega)$ the Besov space.  For definition of Besov space we refer to Leoni's book , Chapter 14, section 14.1. (Also this book by Adam, page 230, section 7.32.) Theorem 14.29 in Leoni's book states the continuous imbedding theorem for Besov space. (For simplification, let's assume $p=1$.) We have $B^{s;1,\theta}(\Omega)$ continuous imbedded in $L^{\frac{N}{N-s}}(\Omega)$ for $1\leq \theta\leq \frac{N}{N-s}$. We now take $r<\frac{N}{N-s}$. My question is: do we have $B^{s;1,\theta}(\Omega)$ is COMPACT imbedded in $L^{r}$? I think the answer is yes because according to this post , exercise 15, that sequences bounded in a high regularity space, and constrained to lie   in a compact domain, will tend to have convergent subsequences in low   regularity spaces. So I would think my conjecture is true. However, I did a deep search over the internet but has no lucky to find such result. If there is no such result, please let me know (and maybe a counterexample?). If there is, please direct me to a reference. Thank you!","This post has been on MathOverflow for couple of days but receive no response. So I put it here hoping for more attentions. Thank you guys! Let $\Omega\subset \mathbb R^N$ be open bounded with smooth boundary. Let $0<s<1$, $1\leq p<\infty$, and $1\leq \theta\leq\infty$. We denote by $B^{s;p,\theta}(\Omega)$ the Besov space.  For definition of Besov space we refer to Leoni's book , Chapter 14, section 14.1. (Also this book by Adam, page 230, section 7.32.) Theorem 14.29 in Leoni's book states the continuous imbedding theorem for Besov space. (For simplification, let's assume $p=1$.) We have $B^{s;1,\theta}(\Omega)$ continuous imbedded in $L^{\frac{N}{N-s}}(\Omega)$ for $1\leq \theta\leq \frac{N}{N-s}$. We now take $r<\frac{N}{N-s}$. My question is: do we have $B^{s;1,\theta}(\Omega)$ is COMPACT imbedded in $L^{r}$? I think the answer is yes because according to this post , exercise 15, that sequences bounded in a high regularity space, and constrained to lie   in a compact domain, will tend to have convergent subsequences in low   regularity spaces. So I would think my conjecture is true. However, I did a deep search over the internet but has no lucky to find such result. If there is no such result, please let me know (and maybe a counterexample?). If there is, please direct me to a reference. Thank you!",,"['real-analysis', 'functional-analysis', 'reference-request', 'partial-differential-equations', 'sobolev-spaces']"
48,Definitions of order-dense Riesz spaces,Definitions of order-dense Riesz spaces,,"I would like to get an intuitive idea as to why the definitions of order-dense and locally order-dense Riesz subspaces were chosen in the following way: A Riesz subspace $F$ of $E$ is order-dense if for every $x \in E^{+},$ $$x =\sup \{y:~0 \leq y \leq x, ~ y \in F \}.$$ $F$ is locally order-dense if it is order-dense in its solid hull i.e., if $$0 \leq x \leq x_{0} \in F \implies x = \sup\{ y:~ y\in F, 0 \leq y \leq x \}.$$ Thanks for any assistance.","I would like to get an intuitive idea as to why the definitions of order-dense and locally order-dense Riesz subspaces were chosen in the following way: A Riesz subspace $F$ of $E$ is order-dense if for every $x \in E^{+},$ $$x =\sup \{y:~0 \leq y \leq x, ~ y \in F \}.$$ $F$ is locally order-dense if it is order-dense in its solid hull i.e., if $$0 \leq x \leq x_{0} \in F \implies x = \sup\{ y:~ y\in F, 0 \leq y \leq x \}.$$ Thanks for any assistance.",,"['analysis', 'functional-analysis', 'measure-theory', 'definition', 'vector-lattices']"
49,Dimension of a certain $L^p$ quotient space.,Dimension of a certain  quotient space.,L^p,"Define $L^p_0 := \{ f \in L^p : \int f = 0 \}$. I am trying to calculate the dimension of the cokernel of the inclusion operator $i:L^p_0 \to L^p$. That is, I am trying to calculate $$\dim ( L^p / L^p_0 )$$ If $p=2$, I would have a Hilbert space and I would say that  $$ L^2_0 = \{ f \in L^2 : \langle f,c\rangle =0\}, $$  that is, $L^2_0$ is the orthogonal complement of the subspace of constant functions. As this subspace has dimension 1, I guess there is some simple argument to conclude that the cokernel of its orthogonal space is also 1 (Is this because of the projection theorem? How can I do this rigorously?) For the general case, I don't know how to proceed to do the same thing rigorously for a Banach space. I think this is pretty straightforward but I've forgotten most of functional analysis stuff and I'd like to re-learn these things. Thanks in advance. Bonus question: Is it true that the dual space $(L^p_0)^* = L^{p'} / \mathbb{R}$ ? Is the inclusion $i:L^p_0 \to L^p$ the adjoint operator of the projection $pr: L^{p'} \to L^{p'} / \mathbb{R}$ ?","Define $L^p_0 := \{ f \in L^p : \int f = 0 \}$. I am trying to calculate the dimension of the cokernel of the inclusion operator $i:L^p_0 \to L^p$. That is, I am trying to calculate $$\dim ( L^p / L^p_0 )$$ If $p=2$, I would have a Hilbert space and I would say that  $$ L^2_0 = \{ f \in L^2 : \langle f,c\rangle =0\}, $$  that is, $L^2_0$ is the orthogonal complement of the subspace of constant functions. As this subspace has dimension 1, I guess there is some simple argument to conclude that the cokernel of its orthogonal space is also 1 (Is this because of the projection theorem? How can I do this rigorously?) For the general case, I don't know how to proceed to do the same thing rigorously for a Banach space. I think this is pretty straightforward but I've forgotten most of functional analysis stuff and I'd like to re-learn these things. Thanks in advance. Bonus question: Is it true that the dual space $(L^p_0)^* = L^{p'} / \mathbb{R}$ ? Is the inclusion $i:L^p_0 \to L^p$ the adjoint operator of the projection $pr: L^{p'} \to L^{p'} / \mathbb{R}$ ?",,"['analysis', 'functional-analysis', 'lp-spaces', 'dimension-theory-analysis', 'quotient-spaces']"
50,When is a local contraction mapping globally contraction.,When is a local contraction mapping globally contraction.,,"Let $A$ be a complete metric space and $T:A\rightarrow A$ is an continuous operator.  There exists some $\Delta$ such that for $\forall x,y\in A$  and $d(x,y)<\Delta$, there's some $\epsilon <1$ s.t. $d(Tx,Ty)\le \epsilon d(x,y)$. This is what I mean by the ""local contraction"" property and I'm wondering when is $T$ is a global contraction. My conjecture is that when $T$ is an ""uniformly local contraction"", i.e. the $\Delta$ and $\epsilon$ are identical for all $x,y$. Then for arbitrarily chosen $x$ and $y$ we can always find some points between them in $A$, and the distance between each of those points are less than $\Delta$, then applying the triangle inequality gives the global contraction result. I'm not sure whether this is an established result or whether there are some traps to be aware of. Thank you! Specifically, I'm interested in the fixed point property about contraction mappings. I've read the paper Remarks on metric transforms and fixed-point theorems that gives the result if any two points in $A$ can be joined by a rectifiable curve, then a local contraction acts like a global contraction in deriving fixed points. However the space $A$ I'm working on is a functional space and I'm fuzzy about the ""rectifiable curve"" concept and it seems I only need a weaker result than this.","Let $A$ be a complete metric space and $T:A\rightarrow A$ is an continuous operator.  There exists some $\Delta$ such that for $\forall x,y\in A$  and $d(x,y)<\Delta$, there's some $\epsilon <1$ s.t. $d(Tx,Ty)\le \epsilon d(x,y)$. This is what I mean by the ""local contraction"" property and I'm wondering when is $T$ is a global contraction. My conjecture is that when $T$ is an ""uniformly local contraction"", i.e. the $\Delta$ and $\epsilon$ are identical for all $x,y$. Then for arbitrarily chosen $x$ and $y$ we can always find some points between them in $A$, and the distance between each of those points are less than $\Delta$, then applying the triangle inequality gives the global contraction result. I'm not sure whether this is an established result or whether there are some traps to be aware of. Thank you! Specifically, I'm interested in the fixed point property about contraction mappings. I've read the paper Remarks on metric transforms and fixed-point theorems that gives the result if any two points in $A$ can be joined by a rectifiable curve, then a local contraction acts like a global contraction in deriving fixed points. However the space $A$ I'm working on is a functional space and I'm fuzzy about the ""rectifiable curve"" concept and it seems I only need a weaker result than this.",,"['real-analysis', 'functional-analysis']"
51,About closed graph theorem,About closed graph theorem,,"I want to show that in the closed graph theorem, the completeness of $Y$ is essential. (a.e I want to find two norm space $X,Y$ which $Y$ isn't complete and linear function $T:X\to Y$ such that $T$ is closed but isn't bounded.) I know that when $X$ isn't complete, there exist such $T$. See here . I tried to find a counter example in $C^1[0,1]$ but I couldn't find closed linear function here. Please give me a hint to solve this question.","I want to show that in the closed graph theorem, the completeness of $Y$ is essential. (a.e I want to find two norm space $X,Y$ which $Y$ isn't complete and linear function $T:X\to Y$ such that $T$ is closed but isn't bounded.) I know that when $X$ isn't complete, there exist such $T$. See here . I tried to find a counter example in $C^1[0,1]$ but I couldn't find closed linear function here. Please give me a hint to solve this question.",,"['functional-analysis', 'banach-spaces', 'closed-graph']"
52,A uniform bound by an integrable function for a Fourier series' partial sums.,A uniform bound by an integrable function for a Fourier series' partial sums.,,"Consider   \begin{equation}     \sum\limits_{n=1}^\infty\frac{\cos(nx)}{n}=-\log|2\sin x/2|~~~ \big(x\in(0,2\pi)\big),   \end{equation} and its $2\pi$-periodic extension $f$ (for a proof of the above identity see this MSE post .) Notice that $f\in L^1(0,\pi)$, since $f(x)\sim\log(x)~(x\rightarrow0)$. This Fourier series is not absolutely or uniformly convergent. My problem is to show that every one of the partial sums   \begin{equation}     s_N(x)=\sum\limits_{n=1}^N\frac{\cos(nx)}{n}   \end{equation} is bounded in absolute value by the same function $h\in L^1(0,\pi)$. I.e., $|s_N(x)|\leq h(x)$ for every $N\in\mathbb{N}$ and $x\in(0,\pi)$. The various things I have tried so far mostly involve writing the partial sums using the Dirichlet kernel \begin{equation}     D_N(x)=\frac{\sin(N+1/2)x}{2\sin x/2}=\frac{1}{2}+\sum_{n=1}^N\cos(nx).   \end{equation} Then, using that $f$ is even and $2\pi$-periodic,   \begin{align}     \pi s_N(x) &=\int_{-\pi}^\pi f(t)D_N(t-x)\text dt \\                &=\int_0^\pi\big(f(y+x)+f(y-x)\big)D_N(y)\text dy \\                &=\int_0^\pi \underbrace{\log\left|\frac{\sin(y-x)/2}{\sin(y+x)/2}\right|}_{\displaystyle{:=g(x,y)}}                   D_N(y)\text dy.   \end{align} We may differentiate $g$ to find   \begin{equation}     \partial_yg(x,y)=\frac{\sin x}{\cos x-\cos y}.   \end{equation} Hence, integrating by parts,   \begin{align}     \pi s_N(x)=\left[g(x,y)\int_x^yD_N\right]_{y=0}^{y=\pi} -\int_0^\pi\frac{\sin x\int_x^yD_N}{\cos x-\cos y}\text dy.   \end{align} The boundary terms vanish since $g(x,y)$ vanishes when $y=0,\pi$, so if we write $\int_x^yD_N=K_N(x,y)$ then   \begin{equation}     \pi s_N(x)=-\int_0^\pi K_N(x,y)\partial_yg(x,y)\text dy.   \end{equation} Observe that $\partial_yg(x,y)$ is singular as $y\rightarrow x$, and indeed, by Taylor-expanding $\cos y$ around $x$, behaves like   \begin{equation}     \frac{1}{y-x}\big(1+O(y-x)\big).   \end{equation} Clearly, then, one needs to prove that $K_N(x,y)$ will ""kill"" $(y-x)^{-1}$ in some uniform fashion as $y\rightarrow x$ (and $N\rightarrow\infty$!). Unfortunately using the $\sin$-representation of $D_N$ to Taylor-expand $K_N$ around $y=x$ gives   \begin{equation}     K_N(x,y)=D_N(x)\int_x^y\big(1+N\cdot O(t-x)\big)\text dt=              D_N(x)(y-x)\big(1+N\cdot O(y-x)\big),   \end{equation} where I have left out the factor $N$ from the $O$-term to illustrate the non-uniformity of the convergence. There are a couple of other failed attempts I made in a similar vein (for example using the $\cos$-representation of $D_N$), but for fear of making this post too long, I will leave them out. Any ideas on how to proceed would be greatly appreciated, though I would prefer them left as ideas, and not fully fleshed-out answers. Thanks in advance!","Consider   \begin{equation}     \sum\limits_{n=1}^\infty\frac{\cos(nx)}{n}=-\log|2\sin x/2|~~~ \big(x\in(0,2\pi)\big),   \end{equation} and its $2\pi$-periodic extension $f$ (for a proof of the above identity see this MSE post .) Notice that $f\in L^1(0,\pi)$, since $f(x)\sim\log(x)~(x\rightarrow0)$. This Fourier series is not absolutely or uniformly convergent. My problem is to show that every one of the partial sums   \begin{equation}     s_N(x)=\sum\limits_{n=1}^N\frac{\cos(nx)}{n}   \end{equation} is bounded in absolute value by the same function $h\in L^1(0,\pi)$. I.e., $|s_N(x)|\leq h(x)$ for every $N\in\mathbb{N}$ and $x\in(0,\pi)$. The various things I have tried so far mostly involve writing the partial sums using the Dirichlet kernel \begin{equation}     D_N(x)=\frac{\sin(N+1/2)x}{2\sin x/2}=\frac{1}{2}+\sum_{n=1}^N\cos(nx).   \end{equation} Then, using that $f$ is even and $2\pi$-periodic,   \begin{align}     \pi s_N(x) &=\int_{-\pi}^\pi f(t)D_N(t-x)\text dt \\                &=\int_0^\pi\big(f(y+x)+f(y-x)\big)D_N(y)\text dy \\                &=\int_0^\pi \underbrace{\log\left|\frac{\sin(y-x)/2}{\sin(y+x)/2}\right|}_{\displaystyle{:=g(x,y)}}                   D_N(y)\text dy.   \end{align} We may differentiate $g$ to find   \begin{equation}     \partial_yg(x,y)=\frac{\sin x}{\cos x-\cos y}.   \end{equation} Hence, integrating by parts,   \begin{align}     \pi s_N(x)=\left[g(x,y)\int_x^yD_N\right]_{y=0}^{y=\pi} -\int_0^\pi\frac{\sin x\int_x^yD_N}{\cos x-\cos y}\text dy.   \end{align} The boundary terms vanish since $g(x,y)$ vanishes when $y=0,\pi$, so if we write $\int_x^yD_N=K_N(x,y)$ then   \begin{equation}     \pi s_N(x)=-\int_0^\pi K_N(x,y)\partial_yg(x,y)\text dy.   \end{equation} Observe that $\partial_yg(x,y)$ is singular as $y\rightarrow x$, and indeed, by Taylor-expanding $\cos y$ around $x$, behaves like   \begin{equation}     \frac{1}{y-x}\big(1+O(y-x)\big).   \end{equation} Clearly, then, one needs to prove that $K_N(x,y)$ will ""kill"" $(y-x)^{-1}$ in some uniform fashion as $y\rightarrow x$ (and $N\rightarrow\infty$!). Unfortunately using the $\sin$-representation of $D_N$ to Taylor-expand $K_N$ around $y=x$ gives   \begin{equation}     K_N(x,y)=D_N(x)\int_x^y\big(1+N\cdot O(t-x)\big)\text dt=              D_N(x)(y-x)\big(1+N\cdot O(y-x)\big),   \end{equation} where I have left out the factor $N$ from the $O$-term to illustrate the non-uniformity of the convergence. There are a couple of other failed attempts I made in a similar vein (for example using the $\cos$-representation of $D_N$), but for fear of making this post too long, I will leave them out. Any ideas on how to proceed would be greatly appreciated, though I would prefer them left as ideas, and not fully fleshed-out answers. Thanks in advance!",,"['real-analysis', 'functional-analysis', 'fourier-analysis', 'fourier-series']"
53,"Seminorms in distribution theory are norms, right?","Seminorms in distribution theory are norms, right?",,"In distribution theory the seminorms that you use there $p_m( \phi) := \max_{|\alpha| \le  m}  \sup_{x \in \Omega} |(\partial^{\alpha}(\phi) (x)|, \phi \in C_c^{\infty}(\Omega)$. Those guys are norms and not just seminorms, right?- I am just wondering because I have a book that keeps on calling them seminorms, so I just wanted to be sure that I am not making a stupid error over and over again","In distribution theory the seminorms that you use there $p_m( \phi) := \max_{|\alpha| \le  m}  \sup_{x \in \Omega} |(\partial^{\alpha}(\phi) (x)|, \phi \in C_c^{\infty}(\Omega)$. Those guys are norms and not just seminorms, right?- I am just wondering because I have a book that keeps on calling them seminorms, so I just wanted to be sure that I am not making a stupid error over and over again",,"['real-analysis', 'analysis', 'functional-analysis', 'normal-distribution', 'distribution-theory']"
54,Existence of regular Borel measure,Existence of regular Borel measure,,"Let $X$ be a $\sigma$-compact and locally compact space, and let $\Lambda:C(X)\rightarrow \mathbb{C}$ be a linear functional such that $\Lambda(f)\ge0$ if $f\ge0$. How to show that exist exactly one regular Borel measure $\mu$ with compact support such that $\Lambda(f)=\int_{X}fd\mu$ for every $f\in C(X)$ ?","Let $X$ be a $\sigma$-compact and locally compact space, and let $\Lambda:C(X)\rightarrow \mathbb{C}$ be a linear functional such that $\Lambda(f)\ge0$ if $f\ge0$. How to show that exist exactly one regular Borel measure $\mu$ with compact support such that $\Lambda(f)=\int_{X}fd\mu$ for every $f\in C(X)$ ?",,"['functional-analysis', 'measure-theory']"
55,A question concerning the Schwartz space,A question concerning the Schwartz space,,"Denote the Schwartz space by $\mathcal S(\mathbb{R})$. I want to show that $\forall n,k \in \mathbb{N} \cup \{0\}$, $\|\cdot\|^{(n,k)} : \mathcal S(\mathbb{R}) \rightarrow [0, \infty)$ defined by  $$\|f\|^{(n,k)} = \sup_{x \in \mathbb{R}} |x^n f^{(k)}(x)|$$ is a norm on $\mathcal S(\mathbb{R})$ and therefore is a countably normed space. I have never worked with this space before so I am a little unsure. The help would be appreciated!","Denote the Schwartz space by $\mathcal S(\mathbb{R})$. I want to show that $\forall n,k \in \mathbb{N} \cup \{0\}$, $\|\cdot\|^{(n,k)} : \mathcal S(\mathbb{R}) \rightarrow [0, \infty)$ defined by  $$\|f\|^{(n,k)} = \sup_{x \in \mathbb{R}} |x^n f^{(k)}(x)|$$ is a norm on $\mathcal S(\mathbb{R})$ and therefore is a countably normed space. I have never worked with this space before so I am a little unsure. The help would be appreciated!",,"['functional-analysis', 'normed-spaces', 'schwartz-space']"
56,Banach spaces with a bounded linear functional constant on some normalized Hamel basis,Banach spaces with a bounded linear functional constant on some normalized Hamel basis,,"Let $V$ be a normed vector space over $\mathbb R$. For a normalized Hamel basis $\mathcal B$ of $V$, consider the linear functional $f_{\mathcal B}:V\to\mathbb R$ taking constant value $1$ on $\mathcal B$; explicitly, $f_{\mathcal B}\bigl(\sum_{v\in\mathcal B}c_vv\bigr)=\sum_{v\in\mathcal B}c_v\,.$ Is there some characterization of the spaces $V$ such that $f_{\mathcal B}$ is bounded for some $\mathcal B$? what if $V$ is also assumed to be a Banach space?.","Let $V$ be a normed vector space over $\mathbb R$. For a normalized Hamel basis $\mathcal B$ of $V$, consider the linear functional $f_{\mathcal B}:V\to\mathbb R$ taking constant value $1$ on $\mathcal B$; explicitly, $f_{\mathcal B}\bigl(\sum_{v\in\mathcal B}c_vv\bigr)=\sum_{v\in\mathcal B}c_v\,.$ Is there some characterization of the spaces $V$ such that $f_{\mathcal B}$ is bounded for some $\mathcal B$? what if $V$ is also assumed to be a Banach space?.",,"['functional-analysis', 'banach-spaces']"
57,"$\left\{\,f\in L^1[0,1]\,\big\vert\,\int_0^1\lvert f\rvert^2>1\right\}$ is open",is open,"\left\{\,f\in L^1[0,1]\,\big\vert\,\int_0^1\lvert f\rvert^2>1\right\}","Problem (Here $\lVert f\rVert$ means the $L^1$-norm $\int_0^1\lvert f\rvert$) Suppose $f\in L^1[0,1]$ such that $\int_0^1\lvert f\rvert^2>1$. I need to work out an explicit $\epsilon>0$ such that such that $\int_0^1\lvert g\rvert^2>1$ for each $g\in L^1[0,1]$ whenever $\lVert g-f\rVert\le\epsilon$. Comment One can find $\epsilon$ non-constructively as follows: for otherwise we can choose $\{g_n\}\subseteq L^1[0,1]$ such that $\lVert g_n-f\rVert\to0$ and $\int_0^1\lvert g_n\rvert^2\le1$, then $\lvert g_n\rvert^2\to\lvert f\rvert^2$ in measure, and by Fatou's lemma , $\int_0^1\lvert f\rvert^2\ge1$, contradiction! However, I want to explicate an $\epsilon>0$, i.e. the perturbation radius, for each $f$. To start with, let's consider $f=c>1$ and fix $\epsilon>0$. We try to minimize $\int_0^1\lvert g\rvert^2$ under the assumption that $\lVert g-f\rVert=\eta\le\epsilon$. Let $h=f-g$, and it's natural to assume that $h>0$, since $\lvert g\rvert\ge\big\lvert\lvert f\rvert-\lvert h\rvert\big\rvert$. Then $$I=\int_0^1\lvert g\rvert^2=c^2-2c\eta+\int_0^1\lvert h\rvert^2\ge c^2-2c\eta+\left(\int_0^1\lvert h\rvert\right)^2=(c-\eta)^2$$ If $\epsilon$ is sufficiently small, then $I_\mathrm{min}=(c-\epsilon)^2$ when taking $h=\epsilon$. If $f$ is arbitrary, maybe we can approximate $f$ by simple functions then obtain some good estimations. I have no clear idea on how to proceed next, and I hope we can obtain a good, if not best, $\epsilon$ for each $f$. Any idea? Thanks! Caveat One should note that the result is not that trivial, by seeing that on contrary, $\left\{\,f\in L^1[0,1]\,\big\vert\,\int_0^1\lvert f\rvert^2<1\,\right\}$ is however nowhere dense, and therefore $L^2[0,1]$ is meager in $L^1[0,1]$. It seems astonishing, but it should be clear after you recall the following facts: $h_\epsilon(x)=\epsilon/\sqrt x$ is small in $L^1$-norm but not square-integrable; The collection of continuous functions $C^0[0,1]$ with $L^1$-norm can be embedded densely in $L^1[0,1]$; For each $f\in C^0[0,1]$, we have $\int_0^1\lvert f+h_\epsilon\rvert^2=+\infty$.","Problem (Here $\lVert f\rVert$ means the $L^1$-norm $\int_0^1\lvert f\rvert$) Suppose $f\in L^1[0,1]$ such that $\int_0^1\lvert f\rvert^2>1$. I need to work out an explicit $\epsilon>0$ such that such that $\int_0^1\lvert g\rvert^2>1$ for each $g\in L^1[0,1]$ whenever $\lVert g-f\rVert\le\epsilon$. Comment One can find $\epsilon$ non-constructively as follows: for otherwise we can choose $\{g_n\}\subseteq L^1[0,1]$ such that $\lVert g_n-f\rVert\to0$ and $\int_0^1\lvert g_n\rvert^2\le1$, then $\lvert g_n\rvert^2\to\lvert f\rvert^2$ in measure, and by Fatou's lemma , $\int_0^1\lvert f\rvert^2\ge1$, contradiction! However, I want to explicate an $\epsilon>0$, i.e. the perturbation radius, for each $f$. To start with, let's consider $f=c>1$ and fix $\epsilon>0$. We try to minimize $\int_0^1\lvert g\rvert^2$ under the assumption that $\lVert g-f\rVert=\eta\le\epsilon$. Let $h=f-g$, and it's natural to assume that $h>0$, since $\lvert g\rvert\ge\big\lvert\lvert f\rvert-\lvert h\rvert\big\rvert$. Then $$I=\int_0^1\lvert g\rvert^2=c^2-2c\eta+\int_0^1\lvert h\rvert^2\ge c^2-2c\eta+\left(\int_0^1\lvert h\rvert\right)^2=(c-\eta)^2$$ If $\epsilon$ is sufficiently small, then $I_\mathrm{min}=(c-\epsilon)^2$ when taking $h=\epsilon$. If $f$ is arbitrary, maybe we can approximate $f$ by simple functions then obtain some good estimations. I have no clear idea on how to proceed next, and I hope we can obtain a good, if not best, $\epsilon$ for each $f$. Any idea? Thanks! Caveat One should note that the result is not that trivial, by seeing that on contrary, $\left\{\,f\in L^1[0,1]\,\big\vert\,\int_0^1\lvert f\rvert^2<1\,\right\}$ is however nowhere dense, and therefore $L^2[0,1]$ is meager in $L^1[0,1]$. It seems astonishing, but it should be clear after you recall the following facts: $h_\epsilon(x)=\epsilon/\sqrt x$ is small in $L^1$-norm but not square-integrable; The collection of continuous functions $C^0[0,1]$ with $L^1$-norm can be embedded densely in $L^1[0,1]$; For each $f\in C^0[0,1]$, we have $\int_0^1\lvert f+h_\epsilon\rvert^2=+\infty$.",,"['real-analysis', 'functional-analysis', 'inequality']"
58,"Is there a cyclic vector for $-\frac{d^{2}}{dx^{2}}$ on $L^{2}[0,2\pi]$ with periodic conditions?",Is there a cyclic vector for  on  with periodic conditions?,"-\frac{d^{2}}{dx^{2}} L^{2}[0,2\pi]","Let $\mathcal{H}=L^{2}[0,2\pi]$, and let $L=-\frac{d^{2}}{dx^{2}}$ on the domain $\mathcal{D}(L)$ consisting of twice absolutely continuous functions $f$ on $[0,2\pi]$ with $f''\in\mathcal{H}$ and $f(0)=f(2\pi)$, $f'(0)=f'(2\pi)$. Then $L$ is selfadjoint on this domain. Is there a cyclic vector $\phi \in \mathcal{H}$ for the $C^{\star}$ algebra generated by the resolvents $(L-\lambda I)^{-1}$?","Let $\mathcal{H}=L^{2}[0,2\pi]$, and let $L=-\frac{d^{2}}{dx^{2}}$ on the domain $\mathcal{D}(L)$ consisting of twice absolutely continuous functions $f$ on $[0,2\pi]$ with $f''\in\mathcal{H}$ and $f(0)=f(2\pi)$, $f'(0)=f'(2\pi)$. Then $L$ is selfadjoint on this domain. Is there a cyclic vector $\phi \in \mathcal{H}$ for the $C^{\star}$ algebra generated by the resolvents $(L-\lambda I)^{-1}$?",,"['functional-analysis', 'fourier-analysis', 'operator-theory', 'operator-algebras', 'spectral-theory']"
59,Perturbation theory PDEs,Perturbation theory PDEs,,"I have the solution of a PDE of the form: $$ \Delta \Psi(r,\theta, \phi) = k \Psi(r,\theta,\phi)$$ on a set $\mathbb{R}^3 \backslash B(0,R)$. Hence, the actual solution is known there! Regarding this, you might have a look at: Related thread Notice, that my solution is bounded and vanishes at infinity! Now I want to consider an additional small perturbation $$ \Delta \Psi(r,\theta, \phi) = k \Psi(r,\theta,\phi) + \epsilon \Psi(r,\theta,\phi)^2.$$ Of course, I suspect that you cannot analytically solve this PDE anymore, but is it possible to come up with some kind of perturbation theory(if it is difficult to answer this question with mathematical rigour, you are invited to argue with handwaving).","I have the solution of a PDE of the form: $$ \Delta \Psi(r,\theta, \phi) = k \Psi(r,\theta,\phi)$$ on a set $\mathbb{R}^3 \backslash B(0,R)$. Hence, the actual solution is known there! Regarding this, you might have a look at: Related thread Notice, that my solution is bounded and vanishes at infinity! Now I want to consider an additional small perturbation $$ \Delta \Psi(r,\theta, \phi) = k \Psi(r,\theta,\phi) + \epsilon \Psi(r,\theta,\phi)^2.$$ Of course, I suspect that you cannot analytically solve this PDE anymore, but is it possible to come up with some kind of perturbation theory(if it is difficult to answer this question with mathematical rigour, you are invited to argue with handwaving).",,"['calculus', 'real-analysis']"
60,Trying to show that $z \mapsto f_z : \mathbb{C} \to L^1(\mathbb{R})$ is complex differentiable where $f_z(x) = e^{-(x+z)^2}$,Trying to show that  is complex differentiable where,z \mapsto f_z : \mathbb{C} \to L^1(\mathbb{R}) f_z(x) = e^{-(x+z)^2},"Let $g$ be the entire function $g(z) = e^{-z^2}$. Note $g$ is integrable along every horizontal line. For each complex number $z \in \mathbb{C}$, define $f_z : \mathbb{R} \to \mathbb{C}$ by $f_z(x) = g(z+x)$.  I am trying to show that the map $z \mapsto f_z : \mathbb{C} \to L^1(\mathbb{R})$ is complex differentiable in the sense that, for all $z \in \mathbb{C}$, $$\frac{f_{z +h} - f_z}{h} \to (f_z)'$$ in $L^1$ as the complex variable $h \to 0$. In other words, I want to show that, for all $z \in \mathbb{C}$, $$ \int_{-\infty}^\infty \left| \frac{g(z+h+x) -g(z+x)}{h} - g'(z+x) \right| \ dx \to 0$$ as $h \to 0$. There is no harm in assuming $z$ is pure imaginary above since the integral is translation invariant in the real direction. So far I have had the idea to write $$g(z+h+x) -g(z+x) = \int_0^1 g'(z+th +x) \ d(th) = h \int_0^1 g'(z+th+x) \ dt$$ and $$ g'(x+x) = \int_0^1 g'(z+x) \ dt$$ so that $$\frac{g(z+h+x) -g(z+x)}{h} - g'(z+x) = \int_0^1 \left( g'(z+th + x) - g'(z+x) \right) \ dt,$$ which is bounded in magnitude by the largest variation in $g'$ over the line from $z+x$ to $z+h+x$. This, would seem to mean, perhaps, that there is an estimate of $$\int_{-\infty}^\infty \left| \frac{g(z+h+x) -g(z+x)}{h} - g'(z+x) \right| $$ related to an area integral of $|g''|$ over on the strip bounded between the lines $\{z+x:x + \mathbb{R}\}$ and $\{z+x+h:x \in \mathbb{R}\}$? Anyhow, I'm beginning to get muddled. Help would be appreciated.","Let $g$ be the entire function $g(z) = e^{-z^2}$. Note $g$ is integrable along every horizontal line. For each complex number $z \in \mathbb{C}$, define $f_z : \mathbb{R} \to \mathbb{C}$ by $f_z(x) = g(z+x)$.  I am trying to show that the map $z \mapsto f_z : \mathbb{C} \to L^1(\mathbb{R})$ is complex differentiable in the sense that, for all $z \in \mathbb{C}$, $$\frac{f_{z +h} - f_z}{h} \to (f_z)'$$ in $L^1$ as the complex variable $h \to 0$. In other words, I want to show that, for all $z \in \mathbb{C}$, $$ \int_{-\infty}^\infty \left| \frac{g(z+h+x) -g(z+x)}{h} - g'(z+x) \right| \ dx \to 0$$ as $h \to 0$. There is no harm in assuming $z$ is pure imaginary above since the integral is translation invariant in the real direction. So far I have had the idea to write $$g(z+h+x) -g(z+x) = \int_0^1 g'(z+th +x) \ d(th) = h \int_0^1 g'(z+th+x) \ dt$$ and $$ g'(x+x) = \int_0^1 g'(z+x) \ dt$$ so that $$\frac{g(z+h+x) -g(z+x)}{h} - g'(z+x) = \int_0^1 \left( g'(z+th + x) - g'(z+x) \right) \ dt,$$ which is bounded in magnitude by the largest variation in $g'$ over the line from $z+x$ to $z+h+x$. This, would seem to mean, perhaps, that there is an estimate of $$\int_{-\infty}^\infty \left| \frac{g(z+h+x) -g(z+x)}{h} - g'(z+x) \right| $$ related to an area integral of $|g''|$ over on the strip bounded between the lines $\{z+x:x + \mathbb{R}\}$ and $\{z+x+h:x \in \mathbb{R}\}$? Anyhow, I'm beginning to get muddled. Help would be appreciated.",,"['complex-analysis', 'functional-analysis']"
61,Fundamental theorem of calculus of Banach-space valued functions,Fundamental theorem of calculus of Banach-space valued functions,,"Let $f:[a,b]\rightarrow E$ be a  continuous function from the interval $[a,b]$ to a Banach space $E$. Let $F(x)=\int_a^xf(t)\text{ }dt$ where the integral is the Bochner integral. I have to prove that $F'(x)=f(x)$. The first thing I tried to do was try to calculate $F(x+h)-F(h)=\int_x^{x+h}f(t)\text{ }dt$. If $F'(x)=f(x)$ then this integral must equal $hf(x)+o(|h|)$, but the only thing I can say about this integral is $||\int_x^{x+h}f(t)\text{ }dt||_E\leq h||f||_{\infty}$. I am kind of stuck. I need a hint. Thanks.","Let $f:[a,b]\rightarrow E$ be a  continuous function from the interval $[a,b]$ to a Banach space $E$. Let $F(x)=\int_a^xf(t)\text{ }dt$ where the integral is the Bochner integral. I have to prove that $F'(x)=f(x)$. The first thing I tried to do was try to calculate $F(x+h)-F(h)=\int_x^{x+h}f(t)\text{ }dt$. If $F'(x)=f(x)$ then this integral must equal $hf(x)+o(|h|)$, but the only thing I can say about this integral is $||\int_x^{x+h}f(t)\text{ }dt||_E\leq h||f||_{\infty}$. I am kind of stuck. I need a hint. Thanks.",,"['calculus', 'functional-analysis', 'banach-spaces']"
62,estimate the max of a function using p-norm of the function and its derivative,estimate the max of a function using p-norm of the function and its derivative,,"Prove the following interesting, elementary but tricky problem : Let f be a smooth function defined on the interval $[a,b]$ and $p\in[1,\infty]$. Then there exists a constant $C_p$ such that for any $\mu\gt0$,$\max|f|\le C_p(|f(a)|+\mu^{1/p-1}||f'||_p+\mu^{1/p}||f||_p)$. There is a hint for this exercise: using fundamental theorem of calculus and Holder inequality. I started this problem by writing f(t) as f(a)+$\int_a^tf'(x)dx$. Then I can use Holder to get the $p$-norm of the derivative $f'$. However, I don't know how to relate this expression with the $p$-norm of f and $\mu$.","Prove the following interesting, elementary but tricky problem : Let f be a smooth function defined on the interval $[a,b]$ and $p\in[1,\infty]$. Then there exists a constant $C_p$ such that for any $\mu\gt0$,$\max|f|\le C_p(|f(a)|+\mu^{1/p-1}||f'||_p+\mu^{1/p}||f||_p)$. There is a hint for this exercise: using fundamental theorem of calculus and Holder inequality. I started this problem by writing f(t) as f(a)+$\int_a^tf'(x)dx$. Then I can use Holder to get the $p$-norm of the derivative $f'$. However, I don't know how to relate this expression with the $p$-norm of f and $\mu$.",,"['real-analysis', 'functional-analysis', 'lebesgue-measure']"
63,Is this set convex?,Is this set convex?,,"I have been trying to show that the following set is convex, with no luck. I am not even entirely convinced that it is in fact convex. A small hint would be greatly appreciated. For $M>0:$ $$ \{g\in C([a,b])|\,\exists x\in [a,b]:\forall y\in [a,b]:\left|g(x)-g(y) \right|\leq M|x-y|\} $$ To clarify: $x$ depends on $g$","I have been trying to show that the following set is convex, with no luck. I am not even entirely convinced that it is in fact convex. A small hint would be greatly appreciated. For $M>0:$ $$ \{g\in C([a,b])|\,\exists x\in [a,b]:\forall y\in [a,b]:\left|g(x)-g(y) \right|\leq M|x-y|\} $$ To clarify: $x$ depends on $g$",,"['functional-analysis', 'convex-analysis']"
64,"$ (\mathbb{R}^3, \|.\|_1) $ and $ (\mathbb{R}^3, \|.\|_\infty) $ cannot be isometric [duplicate]",and  cannot be isometric [duplicate]," (\mathbb{R}^3, \|.\|_1)   (\mathbb{R}^3, \|.\|_\infty) ","This question already has answers here : How to show that $\mathbb R^n$ with the $1$-norm is not isometric to $\mathbb R^n$ with the infinity norm for $n>2$? (2 answers) Closed 10 years ago . Can anyone prove that the spaces $ (\mathbb{R}^3, \|.\|_1) $ and $ (\mathbb{R}^3, \|.\|_\infty) $ cannot be isometric? Thanks.","This question already has answers here : How to show that $\mathbb R^n$ with the $1$-norm is not isometric to $\mathbb R^n$ with the infinity norm for $n>2$? (2 answers) Closed 10 years ago . Can anyone prove that the spaces $ (\mathbb{R}^3, \|.\|_1) $ and $ (\mathbb{R}^3, \|.\|_\infty) $ cannot be isometric? Thanks.",,['functional-analysis']
65,Stone's theorem for 1-parameter groups of unitary multipliers?,Stone's theorem for 1-parameter groups of unitary multipliers?,,"Let $A$ be a nonunital C*-algebra and let $M(A)$ denote its multiplier algebra. Let $(u_t)_{t \in \mathbb{R}}$ be a strictly continuous 1-parameter group of unitary multipliers. That is, $u_t x \to x$ as $t \to 0$ for all $x \in A$. I am wondering whether there exists an unbounded operator $H : A \to A$ such that $u_t  = e^{itH}$ in some sense? I would want some condititions on $H$: $H$ should be densely-defined and closed. That is, the domain of $H$ should be a dense subspace $A_0$ of $A$ and, whenever $x_n \in A_0$ are such that $x_n \to x \in A$ and $H x_n \to y \in A$ we should have $x \in A_0$ and $H x = y$. We should have $H$ symmetric with respect to the $A$-valued inner-product $\langle \cdot, \cdot \rangle : A \times A \to A$ given by $\langle x,y \rangle = x^* y$. That is, whenever $x,y \in A_0$, it should hold that $\langle Ax,y \rangle = \langle x,Ay \rangle$. A good ""core"" for $H$ should be something like the set of smooth elements $x \in A$, that is elements for which $t \mapsto u_t x$ is a $C^\infty$ path $\mathbb{R} \to A$. There, we can define $H$ by $$ H(x) = \frac{1}{i} \frac{d}{dt} \big|_{t = 0} u_t x .$$ Notice that, for $x$ and $y$ smooth in the above sense, we have $$ \langle u_t x,y \rangle = (u_tx)^* y = x^* u_{-t} y = \langle x, u_{-t} y \rangle. $$ Differentiating both sides and evalutating at $t = 0$ we get gives the desired self-adjointness condition. So one, wants to do things like: Prove that smooth elements are a dense subalgebra Prove that the operator defined as above on smooth elements is closable, probably by using the symmetry condition Find a sense in which $e^{itH} = u_t$, probably strong convergence of the series $\sum_{n=0}^\infty \frac{(itH)^n}{n!}$ on the $\bigcap_{n=1}^\infty \operatorname{dom}(H^n)$ or something. Hopefully someone can spell out what sorts of results are true in this context? Or point me towards references? Thanks.","Let $A$ be a nonunital C*-algebra and let $M(A)$ denote its multiplier algebra. Let $(u_t)_{t \in \mathbb{R}}$ be a strictly continuous 1-parameter group of unitary multipliers. That is, $u_t x \to x$ as $t \to 0$ for all $x \in A$. I am wondering whether there exists an unbounded operator $H : A \to A$ such that $u_t  = e^{itH}$ in some sense? I would want some condititions on $H$: $H$ should be densely-defined and closed. That is, the domain of $H$ should be a dense subspace $A_0$ of $A$ and, whenever $x_n \in A_0$ are such that $x_n \to x \in A$ and $H x_n \to y \in A$ we should have $x \in A_0$ and $H x = y$. We should have $H$ symmetric with respect to the $A$-valued inner-product $\langle \cdot, \cdot \rangle : A \times A \to A$ given by $\langle x,y \rangle = x^* y$. That is, whenever $x,y \in A_0$, it should hold that $\langle Ax,y \rangle = \langle x,Ay \rangle$. A good ""core"" for $H$ should be something like the set of smooth elements $x \in A$, that is elements for which $t \mapsto u_t x$ is a $C^\infty$ path $\mathbb{R} \to A$. There, we can define $H$ by $$ H(x) = \frac{1}{i} \frac{d}{dt} \big|_{t = 0} u_t x .$$ Notice that, for $x$ and $y$ smooth in the above sense, we have $$ \langle u_t x,y \rangle = (u_tx)^* y = x^* u_{-t} y = \langle x, u_{-t} y \rangle. $$ Differentiating both sides and evalutating at $t = 0$ we get gives the desired self-adjointness condition. So one, wants to do things like: Prove that smooth elements are a dense subalgebra Prove that the operator defined as above on smooth elements is closable, probably by using the symmetry condition Find a sense in which $e^{itH} = u_t$, probably strong convergence of the series $\sum_{n=0}^\infty \frac{(itH)^n}{n!}$ on the $\bigcap_{n=1}^\infty \operatorname{dom}(H^n)$ or something. Hopefully someone can spell out what sorts of results are true in this context? Or point me towards references? Thanks.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'operator-algebras', 'c-star-algebras']"
66,Non strictly singular operators,Non strictly singular operators,,"Let $X$ be a separable Banach space and let $T:X\to X$ be a bounded operator that is not strictly singular. Can we always find an infinite dimensional, closed, and complemented subspace $Y$ of $X$ such that $T:Y\to T(Y)$ is an isomorphism? I cannot show this is true, and I cannot think of a counterexample. The only idea of counterexample I had was looking at HI spaces, where every operator is of the form $\lambda I+S$, where $S$ is strictly singular. However, as far as I know, such operators (when $\lambda\neq 0$) are isomorphisms on a closed, finite-codimensional subspace, thus complemented.","Let $X$ be a separable Banach space and let $T:X\to X$ be a bounded operator that is not strictly singular. Can we always find an infinite dimensional, closed, and complemented subspace $Y$ of $X$ such that $T:Y\to T(Y)$ is an isomorphism? I cannot show this is true, and I cannot think of a counterexample. The only idea of counterexample I had was looking at HI spaces, where every operator is of the form $\lambda I+S$, where $S$ is strictly singular. However, as far as I know, such operators (when $\lambda\neq 0$) are isomorphisms on a closed, finite-codimensional subspace, thus complemented.",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
67,Strict Inequality in Rudin's Proof of the Riesz Representation Theorem,Strict Inequality in Rudin's Proof of the Riesz Representation Theorem,,"In Rudin's proof of the Riesz Representation Theorem (step ten), he proves that $$\Lambda h_i \leq \mu(V_i) < \mu(E_i) + \epsilon/n , \quad \mu(K) \leq \sum\limits_{1 \leq i \leq n} \Lambda h_i.$$ Writing $A = \sum\limits_{1 \leq i \leq n} \Lambda h_i$, he then asserts that $$\sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)\Lambda h_i - |a| A  \leq \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)(\mu(E_i) + \epsilon/n) - |a|\mu(K).$$ My question is, how does he avoid strict inequality? As $\Lambda h_i  < \mu(E_i) + \epsilon/n$, it seems to follow that $$ \begin{align*} \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)\Lambda h_i - |a| A  &< \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)(\mu(E_i) + \epsilon/n) - |a|A\\ &\leq \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)(\mu(E_i) + \epsilon/n) - |a|\mu(K) \end{align*} $$ and therefore that $$\sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)\Lambda h_i - |a| A  < \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)(\mu(E_i) + \epsilon/n) - |a|A.$$","In Rudin's proof of the Riesz Representation Theorem (step ten), he proves that $$\Lambda h_i \leq \mu(V_i) < \mu(E_i) + \epsilon/n , \quad \mu(K) \leq \sum\limits_{1 \leq i \leq n} \Lambda h_i.$$ Writing $A = \sum\limits_{1 \leq i \leq n} \Lambda h_i$, he then asserts that $$\sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)\Lambda h_i - |a| A  \leq \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)(\mu(E_i) + \epsilon/n) - |a|\mu(K).$$ My question is, how does he avoid strict inequality? As $\Lambda h_i  < \mu(E_i) + \epsilon/n$, it seems to follow that $$ \begin{align*} \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)\Lambda h_i - |a| A  &< \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)(\mu(E_i) + \epsilon/n) - |a|A\\ &\leq \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)(\mu(E_i) + \epsilon/n) - |a|\mu(K) \end{align*} $$ and therefore that $$\sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)\Lambda h_i - |a| A  < \sum\limits_{1 \leq i \leq n} (|a|+y_i+\epsilon)(\mu(E_i) + \epsilon/n) - |a|A.$$",,"['functional-analysis', 'measure-theory', 'riesz-representation-theorem']"
68,Equivalent continuation of a metric,Equivalent continuation of a metric,,"Hello fellow mathematicians, I am confronted with the following, supposedly not too difficult, problem: Let $(E,f_1)$ be a normed space and $F \subset E$ a linear subspace. Let $f_2$ be a norm on E which is equivalent with the norm $f_1$ on $F$. Prove that there is a norm $g$ on $E$ which is equivalent to $f_1$ on $E$ and whose restriction on $F$ is $f_2$. I tried with all the lemmata and corollaries connected with Hahn-Banach theorem, but, even though I still feel the proof should be easy, I have found no way to tackle the problem. I would be very thankful for pointers!","Hello fellow mathematicians, I am confronted with the following, supposedly not too difficult, problem: Let $(E,f_1)$ be a normed space and $F \subset E$ a linear subspace. Let $f_2$ be a norm on E which is equivalent with the norm $f_1$ on $F$. Prove that there is a norm $g$ on $E$ which is equivalent to $f_1$ on $E$ and whose restriction on $F$ is $f_2$. I tried with all the lemmata and corollaries connected with Hahn-Banach theorem, but, even though I still feel the proof should be easy, I have found no way to tackle the problem. I would be very thankful for pointers!",,"['functional-analysis', 'normed-spaces']"
69,Concerning unbounded linear operators on a Hilbert space,Concerning unbounded linear operators on a Hilbert space,,"Let $H$ be some Hilbert space and let $B:H\rightarrow H$ be a bounded linear operator and $T:D(T)\rightarrow H$ an unbounded linear operator. Furthermore we assume that $T$ is closed ,i.e. it's graph in $H\times H$ is closed and we also have that that the domains $D(T)$ and $D(BT)$ of operator $T$ and $BT$ are both dense sets in $H$. The closure of a closable linear operator $S:D(S)\rightarrow H$ is written as $\overline{S}$. The adjoint of a densely defined linear operator $S:D(S)\rightarrow H$ is written as $S^*$. Operator $A^*$ is always closed for any densely defined operator $A$. With the given assumptions and notations I would like to show the following equation holds $ (TB)^*=\overline{B^* T^*}$. This also means that the domains must coincide. So far I am only able to show that $TB$ is closed and that $(TB)^*$ is an extension of $\overline{B^* T^*}$. But I still need to show that $\overline{B^* T^*}$ is an extension of $(TB)^*$. The most difficult and crucial part seems to me to show that the following inclusion holds $D((TB)^*)\subset D(\overline{B^*T^*})$. But so far I got nothing. Kindly apreciated, Aris","Let $H$ be some Hilbert space and let $B:H\rightarrow H$ be a bounded linear operator and $T:D(T)\rightarrow H$ an unbounded linear operator. Furthermore we assume that $T$ is closed ,i.e. it's graph in $H\times H$ is closed and we also have that that the domains $D(T)$ and $D(BT)$ of operator $T$ and $BT$ are both dense sets in $H$. The closure of a closable linear operator $S:D(S)\rightarrow H$ is written as $\overline{S}$. The adjoint of a densely defined linear operator $S:D(S)\rightarrow H$ is written as $S^*$. Operator $A^*$ is always closed for any densely defined operator $A$. With the given assumptions and notations I would like to show the following equation holds $ (TB)^*=\overline{B^* T^*}$. This also means that the domains must coincide. So far I am only able to show that $TB$ is closed and that $(TB)^*$ is an extension of $\overline{B^* T^*}$. But I still need to show that $\overline{B^* T^*}$ is an extension of $(TB)^*$. The most difficult and crucial part seems to me to show that the following inclusion holds $D((TB)^*)\subset D(\overline{B^*T^*})$. But so far I got nothing. Kindly apreciated, Aris",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'unbounded-operators']"
70,Proving an alternative norm on Sobolev space is equivalent to usual norm,Proving an alternative norm on Sobolev space is equivalent to usual norm,,"I have this exercice and my problel is only in item 4, and i will desespere. Let $f \in L^2(\mathbb{R}^n).$ 1-  Why the equation $\Delta u - u = \dfrac{\partial f}{\partial x_i}$ admits a unique solution $u \in H^1(\mathbb{R}^n)$? 2- Prove that there exist a constant $C \geq 0$ that $||u||_{H^1} \leq C ||f||_{L^2}$. 3- Prove that there exist a constant $M \geq 0$ that for all $u \in H^2(\mathbb{R}^n)$ we have $||u||_{H^2} \leq M (||u||_{L^2})$. 4- We assume that $$\sum_{i,j=1}^n \displaystyle\int_{\mathbb{R}^n} \dfrac{\partial^2 u}{\partial x_i^2} \overline{\dfrac{\partial^2 v}{\partial x_j^2}} \,\mathrm dx + \lambda \displaystyle\int_{\mathbb{R}^n} u \overline{v} \,\mathrm dx$$ represente an scalar product to $H^2(\mathbb{R}^n)$ for all $\lambda > 0.$ Prove that this scalar product is equivalent to the classical scalar product to $H^2(\mathbb{R}^n)$ We denote the norm defined by this scalar product $\|\cdot\|_*$. I wan't to prove the existance of two constantes positives $c_1$ and $c_2$ such that $$c_1 \|u\|_{H^2} \leq \|u\|_* \leq c_2 \|u\|_{H^2}.$$ But i can't prove this two inequality. Okay, so my work for item 4 is: to prove the second inequality: we have from item 3) that: $||u||_{H^2} \leq M (||u||_{L^2} + ||\Delta u||_{L^2})$ and we know that $\Delta u = \sum_{i=1}^n \dfrac{\partial^2 u}{\partial x_i^2}$ so $$\sum_{i,j=1}^n \displaystyle\int \dfrac{\partial^2 u}{\partial x_i} \overline{\dfrac{\partial^2 v}{\partial x_j}} dx = \displaystyle\int |\Delta u|^2 dx = ||\Delta u||^2_{L^2}$$ but my problem is to use item 3 to deduce the second inequality. To prove the first inequality, we have $$||u||^2_{H^2} =||\Delta u||^2_{L^2} + ||\nabla u||^2_{L^2} + ||u||^2_{L^2}$$ and we have by Holder and Young inequalities, \begin{align*} \sum_{i,j=1}^n \displaystyle\int \dfrac{\partial^2 u}{\partial x_i^2} \overline{\dfrac{\partial^2 u}{\partial x_j^2}} dx & \leq \sum_{i,j=1}^n ||\dfrac{\partial^2 u}{\partial x_i^2}||^2_{L^2} . ||\dfrac{\partial^2 \overline{u}}{\partial x_j^2}||^2_{L^2}\\ & \leq \dfrac{1}{2} \sum_{i,j=1}^n (||\dfrac{\partial^2 u}{\partial x_i^2}||^2_{L^2} + ||\dfrac{\partial^2 \overline{u}}{\partial x_j^2}||^2)\\ & \leq \sum_{i,j=1}^n (||\dfrac{\partial^2 u}{\partial x_i^2}||^2_{L^2} + ||\dfrac{\partial^2 \overline{u}}{\partial x_j^2}||^2) \end{align*} and and I'm stuck for the rest i have difficulties just for the last step, help me please to finish this exercice Thank's for help.","I have this exercice and my problel is only in item 4, and i will desespere. Let $f \in L^2(\mathbb{R}^n).$ 1-  Why the equation $\Delta u - u = \dfrac{\partial f}{\partial x_i}$ admits a unique solution $u \in H^1(\mathbb{R}^n)$? 2- Prove that there exist a constant $C \geq 0$ that $||u||_{H^1} \leq C ||f||_{L^2}$. 3- Prove that there exist a constant $M \geq 0$ that for all $u \in H^2(\mathbb{R}^n)$ we have $||u||_{H^2} \leq M (||u||_{L^2})$. 4- We assume that $$\sum_{i,j=1}^n \displaystyle\int_{\mathbb{R}^n} \dfrac{\partial^2 u}{\partial x_i^2} \overline{\dfrac{\partial^2 v}{\partial x_j^2}} \,\mathrm dx + \lambda \displaystyle\int_{\mathbb{R}^n} u \overline{v} \,\mathrm dx$$ represente an scalar product to $H^2(\mathbb{R}^n)$ for all $\lambda > 0.$ Prove that this scalar product is equivalent to the classical scalar product to $H^2(\mathbb{R}^n)$ We denote the norm defined by this scalar product $\|\cdot\|_*$. I wan't to prove the existance of two constantes positives $c_1$ and $c_2$ such that $$c_1 \|u\|_{H^2} \leq \|u\|_* \leq c_2 \|u\|_{H^2}.$$ But i can't prove this two inequality. Okay, so my work for item 4 is: to prove the second inequality: we have from item 3) that: $||u||_{H^2} \leq M (||u||_{L^2} + ||\Delta u||_{L^2})$ and we know that $\Delta u = \sum_{i=1}^n \dfrac{\partial^2 u}{\partial x_i^2}$ so $$\sum_{i,j=1}^n \displaystyle\int \dfrac{\partial^2 u}{\partial x_i} \overline{\dfrac{\partial^2 v}{\partial x_j}} dx = \displaystyle\int |\Delta u|^2 dx = ||\Delta u||^2_{L^2}$$ but my problem is to use item 3 to deduce the second inequality. To prove the first inequality, we have $$||u||^2_{H^2} =||\Delta u||^2_{L^2} + ||\nabla u||^2_{L^2} + ||u||^2_{L^2}$$ and we have by Holder and Young inequalities, \begin{align*} \sum_{i,j=1}^n \displaystyle\int \dfrac{\partial^2 u}{\partial x_i^2} \overline{\dfrac{\partial^2 u}{\partial x_j^2}} dx & \leq \sum_{i,j=1}^n ||\dfrac{\partial^2 u}{\partial x_i^2}||^2_{L^2} . ||\dfrac{\partial^2 \overline{u}}{\partial x_j^2}||^2_{L^2}\\ & \leq \dfrac{1}{2} \sum_{i,j=1}^n (||\dfrac{\partial^2 u}{\partial x_i^2}||^2_{L^2} + ||\dfrac{\partial^2 \overline{u}}{\partial x_j^2}||^2)\\ & \leq \sum_{i,j=1}^n (||\dfrac{\partial^2 u}{\partial x_i^2}||^2_{L^2} + ||\dfrac{\partial^2 \overline{u}}{\partial x_j^2}||^2) \end{align*} and and I'm stuck for the rest i have difficulties just for the last step, help me please to finish this exercice Thank's for help.",,"['functional-analysis', 'normed-spaces', 'sobolev-spaces']"
71,Is $\{g(n)\}_{n\in\mathbb{Z}}\in\ell_2$ if $g$ is a Sobolev function on the real line?,Is  if  is a Sobolev function on the real line?,\{g(n)\}_{n\in\mathbb{Z}}\in\ell_2 g,"If we are given a function $g\in W_2^k(\mathbb{R})$ (even consider $k=1$ for simplicity), then is it true or not that $\{g(n)\}_{n\in\mathbb{Z}}\in\ell_2$?  That is, do we have $$\underset{n\in\mathbb{Z}}\sum|g(n)|^2<\infty$$ ? At first I thought that this must be false, but after trying for a while to construct a counterexample, I found it a little more difficult than I thought.  The conclusion is certainly not true for functions only in $L_2(\mathbb{R})=W_2^0(\mathbb{R})$, because consider the function $g$ so that $g^2$ forms triangles or tent functions at each integer of height 1 and width $2^{-n}$.  The area is square summable, but the above sum is infinite.  However when we have to have control over even the first derivative it becomes a little harder, because such a tent function no longer works. My idea was to try to set $g(n)=n^{-1/2}$ for an infinite subset of the natural numbers (consider $g(x)=0$ for $x\leq 0$), and try to ensure that the functions derivative was small enough to be square summable, but this didn't seem to work. Any suggestions or comments would be helpful.  I am sure somebody knows this even though I have never seen it before.","If we are given a function $g\in W_2^k(\mathbb{R})$ (even consider $k=1$ for simplicity), then is it true or not that $\{g(n)\}_{n\in\mathbb{Z}}\in\ell_2$?  That is, do we have $$\underset{n\in\mathbb{Z}}\sum|g(n)|^2<\infty$$ ? At first I thought that this must be false, but after trying for a while to construct a counterexample, I found it a little more difficult than I thought.  The conclusion is certainly not true for functions only in $L_2(\mathbb{R})=W_2^0(\mathbb{R})$, because consider the function $g$ so that $g^2$ forms triangles or tent functions at each integer of height 1 and width $2^{-n}$.  The area is square summable, but the above sum is infinite.  However when we have to have control over even the first derivative it becomes a little harder, because such a tent function no longer works. My idea was to try to set $g(n)=n^{-1/2}$ for an infinite subset of the natural numbers (consider $g(x)=0$ for $x\leq 0$), and try to ensure that the functions derivative was small enough to be square summable, but this didn't seem to work. Any suggestions or comments would be helpful.  I am sure somebody knows this even though I have never seen it before.",,"['real-analysis', 'functional-analysis', 'fourier-analysis', 'sobolev-spaces']"
72,Continuity of Lebesgue integral with continuously-varying measures?,Continuity of Lebesgue integral with continuously-varying measures?,,"Consider the locally bounded mapping $m: X \times \mathcal{B}(X) \rightarrow [0,1]$, with $X \subseteq \mathbb{R}^n$ and $\mathcal{B}(X)$ denoting the Borel sets, such that for all $x \in X$, $\ m(x,\cdot)$ is a probability measure on $X$, so that $\forall x \in X$ $\ m(x,X)=1$; for all $\tilde{X} \subseteq X$, the mapping $m(\cdot,\tilde{X})$ is continuous. Given a continuous function $\ f: X \rightarrow [0,1]$, I am wondering on the following integral to be a continuous function as well. $$ x \mapsto F(x) := \int_X f(y) m(dy,x) $$ Comment. This is a variation of that question , where for ""constant"" probability measure $m$, the Dominated Converge Theorem is sufficient to show continuity of the integral. Now I think it is interesting to ask if this holds whenever the probability measure $m$ changes continuously. I believe continuity does not hold, but I was not able to find a counterexample. Edit. $f$ takes values on $[0,1]$.","Consider the locally bounded mapping $m: X \times \mathcal{B}(X) \rightarrow [0,1]$, with $X \subseteq \mathbb{R}^n$ and $\mathcal{B}(X)$ denoting the Borel sets, such that for all $x \in X$, $\ m(x,\cdot)$ is a probability measure on $X$, so that $\forall x \in X$ $\ m(x,X)=1$; for all $\tilde{X} \subseteq X$, the mapping $m(\cdot,\tilde{X})$ is continuous. Given a continuous function $\ f: X \rightarrow [0,1]$, I am wondering on the following integral to be a continuous function as well. $$ x \mapsto F(x) := \int_X f(y) m(dy,x) $$ Comment. This is a variation of that question , where for ""constant"" probability measure $m$, the Dominated Converge Theorem is sufficient to show continuity of the integral. Now I think it is interesting to ask if this holds whenever the probability measure $m$ changes continuously. I believe continuity does not hold, but I was not able to find a counterexample. Edit. $f$ takes values on $[0,1]$.",,"['functional-analysis', 'measure-theory', 'probability-theory']"
73,irreducible representation of a group,irreducible representation of a group,,Reduced group $C^\ast$-algebra of group $G$ is defined to be $G^*_{r}(G)=\overline{\lambda(L^1(G))}$ where $\lambda$ is left regular representation. My question is how to get a irreducible representation of $G$ from a irreducible representation of reduced group $C^*$-algebra $G^*_{r}(G)$? (In my question $G$ is a locally compact group),Reduced group $C^\ast$-algebra of group $G$ is defined to be $G^*_{r}(G)=\overline{\lambda(L^1(G))}$ where $\lambda$ is left regular representation. My question is how to get a irreducible representation of $G$ from a irreducible representation of reduced group $C^*$-algebra $G^*_{r}(G)$? (In my question $G$ is a locally compact group),,"['group-theory', 'functional-analysis', 'representation-theory']"
74,Spectral radius in Banach Algebra,Spectral radius in Banach Algebra,,"Let $A$ be a unital Banach algebra and $a\in A$ and $\lambda \in \rho(a)$. I want to prove that $$r(R(a,\lambda))=\frac{1}{d(\lambda,\sigma(a))}.$$ where $R(a,\lambda)=(\lambda 1-a)^{-1}$ and $r(.)$ is the spectral radius. I'm giving this hint: prove the result if $A$ is commutative then do it for the general case. I'm trying to do this but the only thing that I can prove is $\|R(a,\lambda)\|\ge\frac{1}{d(\lambda,\sigma(a))}$, but since $r(.)\le \|.\|$ things don't add up. and when dealing with the general case a'm not sure how to go from the commutative case to the general case I have a feeling that this has to do with $r(.)$ being upper semi continuous. Please help. Thank you.","Let $A$ be a unital Banach algebra and $a\in A$ and $\lambda \in \rho(a)$. I want to prove that $$r(R(a,\lambda))=\frac{1}{d(\lambda,\sigma(a))}.$$ where $R(a,\lambda)=(\lambda 1-a)^{-1}$ and $r(.)$ is the spectral radius. I'm giving this hint: prove the result if $A$ is commutative then do it for the general case. I'm trying to do this but the only thing that I can prove is $\|R(a,\lambda)\|\ge\frac{1}{d(\lambda,\sigma(a))}$, but since $r(.)\le \|.\|$ things don't add up. and when dealing with the general case a'm not sure how to go from the commutative case to the general case I have a feeling that this has to do with $r(.)$ being upper semi continuous. Please help. Thank you.",,"['functional-analysis', 'banach-algebras']"
75,"Elaborating Mercer's theorem (RKHS) on Cameron-Martin space $k(x,y)=\min(x,y)$",Elaborating Mercer's theorem (RKHS) on Cameron-Martin space,"k(x,y)=\min(x,y)","I'm trying to employ Mercer's theorem on the kernel $k(x,y)=\min(x,y)$. It is known (and easy to verify) that this is a nonnegative-definite kernel over $[0,T]$ for any $T>0$. Fix $T>0$. Let's calculate the eigenfunctions of the transformation $\mathcal T_kf=\intop_{0}^T k(x,y)f(y)dy$: $$ \lambda\psi(x)=\intop_{0}^T \min(x,y)\psi(y)dy=$$ $$ \intop_{0}^x \min(x,y)\psi(y)dy - \intop_{T}^x \min(x,y)\psi(y)dy=$$ $$ \intop_{0}^x y\psi(y)dy - x\intop_{T}^x \psi(y)dy\implies$$ $$ \lambda\psi'(x)= x\psi(x)-x\psi(x)-\intop_{T}^x \psi(y)dy\implies$$ $$ -\lambda\psi''(x)= \psi(x)\implies$$ $$\psi(x)=C_1\sin\frac x {\sqrt\lambda} + C_2\cos\frac x {\sqrt\lambda}$$ it seems like we're allowed to pick $C_1=1$ and $C_2=0$. So we pick $\psi_n(x)=\sin nx $ and $\lambda_n = n^{-2}$. Then Mercer's theorem actually says that we should get: $$ \min(x,y)=\sum_{n=1}^\infty n^{-2}\sin nx\sin ny$$ this all seem very nice, but when evaluating this numerically, it doesn't work. I tried also to normalize $\psi$ by dividing by its norm which is $\sqrt {\frac 1 {4n}  (2nT-\sin2nT)}$, and it didn't help. So what's wrong here? EDIT: I also tried to substitute the original solution with $C_1,C_2$ in the original eigenvalue problem equation, and then to calculate $C_1,C_2$. It didn't work. It's a bit tedious, I did it with wxMaxima so I won't bring it here.","I'm trying to employ Mercer's theorem on the kernel $k(x,y)=\min(x,y)$. It is known (and easy to verify) that this is a nonnegative-definite kernel over $[0,T]$ for any $T>0$. Fix $T>0$. Let's calculate the eigenfunctions of the transformation $\mathcal T_kf=\intop_{0}^T k(x,y)f(y)dy$: $$ \lambda\psi(x)=\intop_{0}^T \min(x,y)\psi(y)dy=$$ $$ \intop_{0}^x \min(x,y)\psi(y)dy - \intop_{T}^x \min(x,y)\psi(y)dy=$$ $$ \intop_{0}^x y\psi(y)dy - x\intop_{T}^x \psi(y)dy\implies$$ $$ \lambda\psi'(x)= x\psi(x)-x\psi(x)-\intop_{T}^x \psi(y)dy\implies$$ $$ -\lambda\psi''(x)= \psi(x)\implies$$ $$\psi(x)=C_1\sin\frac x {\sqrt\lambda} + C_2\cos\frac x {\sqrt\lambda}$$ it seems like we're allowed to pick $C_1=1$ and $C_2=0$. So we pick $\psi_n(x)=\sin nx $ and $\lambda_n = n^{-2}$. Then Mercer's theorem actually says that we should get: $$ \min(x,y)=\sum_{n=1}^\infty n^{-2}\sin nx\sin ny$$ this all seem very nice, but when evaluating this numerically, it doesn't work. I tried also to normalize $\psi$ by dividing by its norm which is $\sqrt {\frac 1 {4n}  (2nT-\sin2nT)}$, and it didn't help. So what's wrong here? EDIT: I also tried to substitute the original solution with $C_1,C_2$ in the original eigenvalue problem equation, and then to calculate $C_1,C_2$. It didn't work. It's a bit tedious, I did it with wxMaxima so I won't bring it here.",,"['functional-analysis', 'ordinary-differential-equations']"
76,Bounded and compact sets in a subspace of $\mathbb R^{\mathbb N}$,Bounded and compact sets in a subspace of,\mathbb R^{\mathbb N},"Let    $$ X= \{u=(u_1, u_2, \ldots): u_n \ne 0 \text{ only for a finite number of terms}\}\subseteq\mathbb R^\mathbb N, $$   with the topology inherited from $\mathbb R^\mathbb N$ (the "" pointwise convergence topology"").   Find the bounded sets and prove they're compact. I show you what I've done. First of all, I think - but I'm not sure on how to prove it - the topology of $X$ is equivalent to the one generated by the (countable) family of seminorms  $$ p_n(u)=\vert u_n\vert, \qquad n \in \mathbb N. $$ This allows me also to write an ""explicit"" form of an invariant metric $d$, e.g.  $$ d(x,y) = \sum_{n \in \mathbb N} 2^{-n}\frac{p_n(x-y)}{1+p_n(x-y)} $$ Do you agree? Have you got any idea about how I can prove that the two topologies are the same? Is it true? Anyway, let us come back to bounded sets. If my idea is correct, bounded sets of $X$ are exactly the ones for which every $p_n$ is bounded (as real valued functions). Is there a more explicit description? And what about compactness? I suppose I have to use some theorem about compactness (Tychonov?) but I can't see how. Thanks in advance.","Let    $$ X= \{u=(u_1, u_2, \ldots): u_n \ne 0 \text{ only for a finite number of terms}\}\subseteq\mathbb R^\mathbb N, $$   with the topology inherited from $\mathbb R^\mathbb N$ (the "" pointwise convergence topology"").   Find the bounded sets and prove they're compact. I show you what I've done. First of all, I think - but I'm not sure on how to prove it - the topology of $X$ is equivalent to the one generated by the (countable) family of seminorms  $$ p_n(u)=\vert u_n\vert, \qquad n \in \mathbb N. $$ This allows me also to write an ""explicit"" form of an invariant metric $d$, e.g.  $$ d(x,y) = \sum_{n \in \mathbb N} 2^{-n}\frac{p_n(x-y)}{1+p_n(x-y)} $$ Do you agree? Have you got any idea about how I can prove that the two topologies are the same? Is it true? Anyway, let us come back to bounded sets. If my idea is correct, bounded sets of $X$ are exactly the ones for which every $p_n$ is bounded (as real valued functions). Is there a more explicit description? And what about compactness? I suppose I have to use some theorem about compactness (Tychonov?) but I can't see how. Thanks in advance.",,"['functional-analysis', 'compactness', 'topological-vector-spaces']"
77,Must-read papers in Operator Theory,Must-read papers in Operator Theory,,"I have basically finished my grad school applications and have some time at hand. I want to start reading some classic papers in Operator Theory so as to breathe more culture here. I have read some when doing specific problems but have never systematically study the literature. I wonder whether someone can give some suggestions on where to start since this area has been so highly-developed. Maybe to focus the attention let's, say, try to make a list of the top 20 must-read papers in Operator Theory. I believe this must be a very very difficult job, but maybe some more criteria would make it a little bit easier. I can only read English and Chinese and it's a pity since I know many of the founding fathers use other languages. I prefer papers that give some kind of big pictures, since I can always pick up papers related to specific problems when I need them (but this is not a strict restriction). I would like to focus on the theory itself, not too much on application to physics. I have already done a rather thorough study of literature related to the invariant subspace problem, so I guess we can omit this important area. Thanks very much!","I have basically finished my grad school applications and have some time at hand. I want to start reading some classic papers in Operator Theory so as to breathe more culture here. I have read some when doing specific problems but have never systematically study the literature. I wonder whether someone can give some suggestions on where to start since this area has been so highly-developed. Maybe to focus the attention let's, say, try to make a list of the top 20 must-read papers in Operator Theory. I believe this must be a very very difficult job, but maybe some more criteria would make it a little bit easier. I can only read English and Chinese and it's a pity since I know many of the founding fathers use other languages. I prefer papers that give some kind of big pictures, since I can always pick up papers related to specific problems when I need them (but this is not a strict restriction). I would like to focus on the theory itself, not too much on application to physics. I have already done a rather thorough study of literature related to the invariant subspace problem, so I guess we can omit this important area. Thanks very much!",,"['functional-analysis', 'banach-spaces', 'hilbert-spaces', 'operator-theory', 'operator-algebras']"
78,solution of Lagrange differential equation are square integrable,solution of Lagrange differential equation are square integrable,,"I was recently posing myself this question. Given the Lagrange DE $$[(1-x^2)u']'+\lambda u=0,$$ where $\lambda$ is a real parameter and $x\in[-1,1]$, it is well known that, if $\lambda=n(n+1)$ for some integer $n$, then we get the Legendre polynomials as solutions of the DE. However, if we consider a general parameter $\lambda$ and we consider the solution $u=u_\lambda$ which solves the DE with that particular parameter, then it is true that $u\in L^2([-1,1])$? Moreover, do we still have some boundary conditions like $$\lim_{x\to\pm 1}(1-x^2)u(x)=0?$$ Thanks for your attention.  Best regards, -Guido-","I was recently posing myself this question. Given the Lagrange DE $$[(1-x^2)u']'+\lambda u=0,$$ where $\lambda$ is a real parameter and $x\in[-1,1]$, it is well known that, if $\lambda=n(n+1)$ for some integer $n$, then we get the Legendre polynomials as solutions of the DE. However, if we consider a general parameter $\lambda$ and we consider the solution $u=u_\lambda$ which solves the DE with that particular parameter, then it is true that $u\in L^2([-1,1])$? Moreover, do we still have some boundary conditions like $$\lim_{x\to\pm 1}(1-x^2)u(x)=0?$$ Thanks for your attention.  Best regards, -Guido-",,"['real-analysis', 'complex-analysis', 'functional-analysis', 'ordinary-differential-equations', 'special-functions']"
79,Are smooth functions with compact support weakly-* dense in $L^\infty$?,Are smooth functions with compact support weakly-* dense in ?,L^\infty,"My question is this : given $f \in L^\infty(\mathbb{R}^2)$, can we find a sequence $\phi_n$ of smooth, compactly supported functions (test functions) such that for any $g \in L^1(\mathbb{R}^2)$, $$\int g \phi_n \rightarrow_n \int g f$$ i.e. $\phi_n$ converges weakly to $f$ in the weak * topology of $L^\infty$ ? I know that a strong convergence is true for $L^p$, $p < \infty$ and wrong for $p=\infty$. However, it seems that if you only ask weak convergence it should be true even in $L^\infty$... I have not been able to find a reference for this, either in Rudin's Functional Analysis or Brezis's book. Is this true ? If so, can anyone provide me with a reference ? Thanks in advance.","My question is this : given $f \in L^\infty(\mathbb{R}^2)$, can we find a sequence $\phi_n$ of smooth, compactly supported functions (test functions) such that for any $g \in L^1(\mathbb{R}^2)$, $$\int g \phi_n \rightarrow_n \int g f$$ i.e. $\phi_n$ converges weakly to $f$ in the weak * topology of $L^\infty$ ? I know that a strong convergence is true for $L^p$, $p < \infty$ and wrong for $p=\infty$. However, it seems that if you only ask weak convergence it should be true even in $L^\infty$... I have not been able to find a reference for this, either in Rudin's Functional Analysis or Brezis's book. Is this true ? If so, can anyone provide me with a reference ? Thanks in advance.",,"['functional-analysis', 'reference-request', 'distribution-theory', 'topological-vector-spaces']"
80,Time dependent or Bochner space references?,Time dependent or Bochner space references?,,"Does anyone have any recommendations where I can learn about time dependent or Bochner spaces? I mean spaces like $L^p(0,T; H^{-1}(\Omega))$. I think one needs some knowledge of distributions, so any material that covers the relevant distribution theory would be especially appreciated. I want to get good at using these spaces and understanding the embeddings of these spaces into other Bochner spaces. Edit: please no Evans!","Does anyone have any recommendations where I can learn about time dependent or Bochner spaces? I mean spaces like $L^p(0,T; H^{-1}(\Omega))$. I think one needs some knowledge of distributions, so any material that covers the relevant distribution theory would be especially appreciated. I want to get good at using these spaces and understanding the embeddings of these spaces into other Bochner spaces. Edit: please no Evans!",,"['functional-analysis', 'reference-request', 'sobolev-spaces']"
81,Problem from Brezis's book (mollifiers),Problem from Brezis's book (mollifiers),,Any ideas on how to get started with this? Let $\rho \in L^1(\mathbb{R}^N)$ with $\int \rho=1$. Set $\rho_n(x)=n^N \rho(nx)$. Let $f \in L^p(\mathbb{R}^N)$. Show that $\rho_n \star f \to f$ in $L^p(\mathbb{R}^N)$. The proof of Theorem 4.22 would almost go through for this case. The problem is that I don't know anything about the support of the $\rho_n$'s.This seems to be crucial for the proof of Proposition 4.21 which is used to prove the theorem.,Any ideas on how to get started with this? Let $\rho \in L^1(\mathbb{R}^N)$ with $\int \rho=1$. Set $\rho_n(x)=n^N \rho(nx)$. Let $f \in L^p(\mathbb{R}^N)$. Show that $\rho_n \star f \to f$ in $L^p(\mathbb{R}^N)$. The proof of Theorem 4.22 would almost go through for this case. The problem is that I don't know anything about the support of the $\rho_n$'s.This seems to be crucial for the proof of Proposition 4.21 which is used to prove the theorem.,,"['functional-analysis', 'measure-theory']"
82,A Hölder-like inequality,A Hölder-like inequality,,"Consider a probability measure $\mu$ on a set $X$. Let $p,q \in (1, \infty)$, $f \in L^{pq} \cap L^1$ (so also $f\in L^p \cap L^q$) by non-negative. Can we say anything about the relationship between $$\int f^{qp} d\mu + \left(\int f d\mu\right)^{qp}$$ and $$\left(\int f^p d\mu \right)^q + \left(\int f^q d\mu \right)^p ?$$ In other words, is there an inequality saying that one of these two quantities is greater than or equal to the other under certain circumstances? It seems as if there should be a way to deduce something like this from Hölders/Jensens inequalities, but I have been unable to do so.","Consider a probability measure $\mu$ on a set $X$. Let $p,q \in (1, \infty)$, $f \in L^{pq} \cap L^1$ (so also $f\in L^p \cap L^q$) by non-negative. Can we say anything about the relationship between $$\int f^{qp} d\mu + \left(\int f d\mu\right)^{qp}$$ and $$\left(\int f^p d\mu \right)^q + \left(\int f^q d\mu \right)^p ?$$ In other words, is there an inequality saying that one of these two quantities is greater than or equal to the other under certain circumstances? It seems as if there should be a way to deduce something like this from Hölders/Jensens inequalities, but I have been unable to do so.",,"['functional-analysis', 'inequality']"
83,A measurable function,A measurable function,,Suppose $f\geq 0$ be a measurable function such that $$\int_Bf\leq \frac{m(B)}{1+m(B)}$$ for any ball. Then show that  $$\int_{\mathbb{R}^n}f(kx)g(x)\to 0$$ as $k\to \infty$ for any $g$ integrable in $\mathbb{R}^n$.,Suppose $f\geq 0$ be a measurable function such that $$\int_Bf\leq \frac{m(B)}{1+m(B)}$$ for any ball. Then show that  $$\int_{\mathbb{R}^n}f(kx)g(x)\to 0$$ as $k\to \infty$ for any $g$ integrable in $\mathbb{R}^n$.,,"['measure-theory', 'functional-analysis']"
84,Relation between two orthogonal projections in a Hilbert space,Relation between two orthogonal projections in a Hilbert space,,"Let $\mathcal{H}$ be a Hilbert space and let $P$ and $Q$ be two orthogonal projections to closed subspaces $M$ and $N$ respectively. Prove that: If $PQ$ is an orthogonal projection then it's range is $M\cap N$ $PQ$ is orthogonal iff $PQ = QP$ I got stuck with the first clause, any hint would be most welcomed.","Let $\mathcal{H}$ be a Hilbert space and let $P$ and $Q$ be two orthogonal projections to closed subspaces $M$ and $N$ respectively. Prove that: If $PQ$ is an orthogonal projection then it's range is $M\cap N$ $PQ$ is orthogonal iff $PQ = QP$ I got stuck with the first clause, any hint would be most welcomed.",,"['functional-analysis', 'hilbert-spaces']"
85,Heisenberg Uncertainty Principle,Heisenberg Uncertainty Principle,,"The uncertainty principle (UP) comes up in engineering and physics, but it is a mathematical idea. An old text describes it as ""reciprocal spreading."" If $f$ is a well-behaved function, the UP might be expressed as $W(f)W(\hat{f}) \geq k$, where $k$ is some constant. If $g$ is a Gaussian, we get equality, i.e., $W(g)W(\hat{g}) = k$. My question is this. At least in Fourier analysis, the Gaussian is sort of a minimum in the above sense. Are there any real-world problems for which this is a solution? Even in EE I don't think ""optimality"" of the Gaussian with respect to the UP is ever used. Thanks for any thoughts.","The uncertainty principle (UP) comes up in engineering and physics, but it is a mathematical idea. An old text describes it as ""reciprocal spreading."" If $f$ is a well-behaved function, the UP might be expressed as $W(f)W(\hat{f}) \geq k$, where $k$ is some constant. If $g$ is a Gaussian, we get equality, i.e., $W(g)W(\hat{g}) = k$. My question is this. At least in Fourier analysis, the Gaussian is sort of a minimum in the above sense. Are there any real-world problems for which this is a solution? Even in EE I don't think ""optimality"" of the Gaussian with respect to the UP is ever used. Thanks for any thoughts.",,"['functional-analysis', 'fourier-analysis']"
86,Comparison between Rademacher average and random average,Comparison between Rademacher average and random average,,"Let $X$ be a Banach space. We let $j=e^{2i\pi/3}$. Let $(\epsilon_i)$ be a sequence of independent Rademacher variables on a fixed probability space $\Omega$. Let $(\varphi_i)$ be a sequence of independent complex random variables such that $P(\varphi_i=1)=\frac{1}{3}$, $P(\varphi_i=j)=\frac{1}{3}$ and $P(\varphi_i=j^2)=\frac{1}{3}$ for any $i$. Do there exist sufficient conditions on $X$ such that there exist constants $m,M>0$ such that $$ m\Big\vert\Big\vert\sum_i \epsilon_i\otimes x_i \Big\vert\Big\vert_{L^p(\Omega,X)}\leq \Big\vert\Big\vert\sum_i \varphi_i \otimes x_i \Big\vert\Big\vert_{L^p(\Omega,X)}\leq M\Big\vert\Big\vert\sum_i \epsilon_i\otimes x_i \Big\vert\Big\vert_{L^p(\Omega,X)} $$ for any $x_1,\ldots,x_n\in X$? Remark: I know that if $X$ has finite cotype, the Rademacher averages and the gaussian averages are equivalent.","Let $X$ be a Banach space. We let $j=e^{2i\pi/3}$. Let $(\epsilon_i)$ be a sequence of independent Rademacher variables on a fixed probability space $\Omega$. Let $(\varphi_i)$ be a sequence of independent complex random variables such that $P(\varphi_i=1)=\frac{1}{3}$, $P(\varphi_i=j)=\frac{1}{3}$ and $P(\varphi_i=j^2)=\frac{1}{3}$ for any $i$. Do there exist sufficient conditions on $X$ such that there exist constants $m,M>0$ such that $$ m\Big\vert\Big\vert\sum_i \epsilon_i\otimes x_i \Big\vert\Big\vert_{L^p(\Omega,X)}\leq \Big\vert\Big\vert\sum_i \varphi_i \otimes x_i \Big\vert\Big\vert_{L^p(\Omega,X)}\leq M\Big\vert\Big\vert\sum_i \epsilon_i\otimes x_i \Big\vert\Big\vert_{L^p(\Omega,X)} $$ for any $x_1,\ldots,x_n\in X$? Remark: I know that if $X$ has finite cotype, the Rademacher averages and the gaussian averages are equivalent.",,"['reference-request', 'probability-theory', 'functional-analysis', 'banach-spaces']"
87,How to define the derivative of Radon measures,How to define the derivative of Radon measures,,"Let $M$ be the positive borel measures on a hausdorff topological space $X$, which are finite on compacts sets $--$ i.e. the real cone of radon measures. I am given a definition of a derivative of two radon measures, say $\mu, \eta \in M$, as follows. Let $D^+_\mu \eta (x) := \left\{ \begin{array}{1 1} \limsup \limits_{r \rightarrow 0} \frac{ \eta(\overline{B_r(0)}) }{ \mu(\overline{B_r(0)}) } & \mu(\overline{B_r(0)}) > 0 \forall r > 0\\ \infty & \mu(\overline{B_r(0)}) = 0 \forall r > 0 \end{array} \right. $ and $D^-_\mu \eta (x) := \left\{ \begin{array}{1 1} \liminf \limits_{r \rightarrow 0} \frac{ \eta(\overline{B_r(0)}) }{ \mu(\overline{B_r(0)}) } & \mu(\overline{B_r(0)}) > 0 \forall r > 0\\ \infty & \mu(\overline{B_r(0)}) = 0 \forall r > 0 \end{array} \right. $ and we write in case of equality $D_\mu \eta (x) := D^+_\mu \eta (x) = D^-_\mu \eta (x)$ I could accept this ad-hoc definition ""as is"". Nevertheless, I know there is a canonical topology on the linear space of bounded radon measures, so is probably on the cone of positive (not necessarily bounded) radon measures (Furthermore, I guess the thoughs pass over the linear space of signed Radon measures) Hence, I would like to obtain a good intuition how the definition of derivative of above relates to the canonical definition (if applicable) of derivative on infinite-dimensional vector spaces. (I suppose there is such a connection). Can give a explanation or tell me a good tight resource to look this up? Thank you.","Let $M$ be the positive borel measures on a hausdorff topological space $X$, which are finite on compacts sets $--$ i.e. the real cone of radon measures. I am given a definition of a derivative of two radon measures, say $\mu, \eta \in M$, as follows. Let $D^+_\mu \eta (x) := \left\{ \begin{array}{1 1} \limsup \limits_{r \rightarrow 0} \frac{ \eta(\overline{B_r(0)}) }{ \mu(\overline{B_r(0)}) } & \mu(\overline{B_r(0)}) > 0 \forall r > 0\\ \infty & \mu(\overline{B_r(0)}) = 0 \forall r > 0 \end{array} \right. $ and $D^-_\mu \eta (x) := \left\{ \begin{array}{1 1} \liminf \limits_{r \rightarrow 0} \frac{ \eta(\overline{B_r(0)}) }{ \mu(\overline{B_r(0)}) } & \mu(\overline{B_r(0)}) > 0 \forall r > 0\\ \infty & \mu(\overline{B_r(0)}) = 0 \forall r > 0 \end{array} \right. $ and we write in case of equality $D_\mu \eta (x) := D^+_\mu \eta (x) = D^-_\mu \eta (x)$ I could accept this ad-hoc definition ""as is"". Nevertheless, I know there is a canonical topology on the linear space of bounded radon measures, so is probably on the cone of positive (not necessarily bounded) radon measures (Furthermore, I guess the thoughs pass over the linear space of signed Radon measures) Hence, I would like to obtain a good intuition how the definition of derivative of above relates to the canonical definition (if applicable) of derivative on infinite-dimensional vector spaces. (I suppose there is such a connection). Can give a explanation or tell me a good tight resource to look this up? Thank you.",,"['analysis', 'measure-theory', 'functional-analysis', 'topological-vector-spaces']"
88,Existence of a postive measurable set such that $T^{-k}(E)\cap E=\emptyset$ for a particular $k\ge 1.$,Existence of a postive measurable set such that  for a particular,T^{-k}(E)\cap E=\emptyset k\ge 1.,"Let $(X,\mathcal B,\mu)$ be a atomless probability measure space and $T:X\to X$ be a non-singular transformation such that $\mu\left(\{x\in X: T^n(x)=x\}\right)=0$ for every $n\ge 1.$ Let $A\in \mathcal B$ such that $\mu(A)>0$ and $k\ge 1$ a positive integer. I want to show that there exists a set $E\in \mathcal B$ such that $\mu(E)>0$ with $E\subseteq A$ and $T^{-k}(E)\cap E=\emptyset.$ Let $E=A\setminus T^{-k}(A)$ and $y\in T^{-k}(E)\cap E$ . Then $y\in E\implies y\notin T^{-k}(A)$ . Also $y\in T^{-k}E\implies T^k(y)\in E\implies T^ky\in A\implies y\in T^{-k}A.$ So, $T^{-k}(E)\cap E =\emptyset$ . But I am unable to construct the set $E$ out of the aforesaid hypothesis such that $\mu(E)>0$ . Please help me to solve this. Thank you for your time and help.","Let be a atomless probability measure space and be a non-singular transformation such that for every Let such that and a positive integer. I want to show that there exists a set such that with and Let and . Then . Also So, . But I am unable to construct the set out of the aforesaid hypothesis such that . Please help me to solve this. Thank you for your time and help.","(X,\mathcal B,\mu) T:X\to X \mu\left(\{x\in X: T^n(x)=x\}\right)=0 n\ge 1. A\in \mathcal B \mu(A)>0 k\ge 1 E\in \mathcal B \mu(E)>0 E\subseteq A T^{-k}(E)\cap E=\emptyset. E=A\setminus T^{-k}(A) y\in T^{-k}(E)\cap E y\in E\implies y\notin T^{-k}(A) y\in T^{-k}E\implies T^k(y)\in E\implies T^ky\in A\implies y\in T^{-k}A. T^{-k}(E)\cap E =\emptyset E \mu(E)>0","['functional-analysis', 'measure-theory', 'transformation', 'ergodic-theory']"
89,Does $X \times \mathbb{R} \simeq X$ hold for infinite dimension inner product space $X$?,Does  hold for infinite dimension inner product space ?,X \times \mathbb{R} \simeq X X,"The $X$ is infinite dimension real inner product space, not restricting it as a Hilbert space. This question has troubled my friend and me a lot of days. It is obviously true when $X$ is infinite dimension Hilbert space. However, I can't answer this in arbitrary space. I have thought to find all of the style of infinite dimension space. I thought any space may like $l^2(\alpha) \times \mathbb{R}^{⊕\beta}$ , but it's wrong, such as $l^2(\mathbb{N})^{⊕ω}$ . Any useful answer will be appreciated. Add: where isomorphic maintain inner product. It isn't only as a algebraic isomorphic. $X \times \mathbb{R}$ is a inner product space, which inner product is $(x,r) \cdot (y,s) = x \cdot y + rs$ .","The is infinite dimension real inner product space, not restricting it as a Hilbert space. This question has troubled my friend and me a lot of days. It is obviously true when is infinite dimension Hilbert space. However, I can't answer this in arbitrary space. I have thought to find all of the style of infinite dimension space. I thought any space may like , but it's wrong, such as . Any useful answer will be appreciated. Add: where isomorphic maintain inner product. It isn't only as a algebraic isomorphic. is a inner product space, which inner product is .","X X l^2(\alpha) \times \mathbb{R}^{⊕\beta} l^2(\mathbb{N})^{⊕ω} X \times \mathbb{R} (x,r) \cdot (y,s) = x \cdot y + rs","['functional-analysis', 'analysis', 'inner-products', 'dimension-theory-analysis']"
90,Basic properties of Green function and resolvent,Basic properties of Green function and resolvent,,"I am trying to understand better the properties of the resolvent and Green function of a bounded self-adjoint operator $H$ at $z=E+i\eta$ when $\eta \to 0^+$ . The resolvent is the operator $R(H;z)=(H-zI)^{-1}$ , which is defined when $z$ is is not in the spectrum. If I am not mistaken, the Green function is defined as $G:\mathcal{H}\times \mathcal{H\times \mathbb{C}}$ by $G(\psi,\phi; z):= \langle  R(H,z)\phi,\psi \rangle$ , and is defined when $z$ is not in the spectrum. My question is what happens when $E$ is in the spectrum of $H$ to $\Vert R(H;E+i\eta)\Vert$ or $G(\psi, \phi;E+i\eta)$ when $\eta\to 0^+?$ It seems that when $E$ is an approximate eigenvalue, that $\Vert R(H;E+i\eta)\Vert\to \infty$ by Weyl's criterion for the spectrum. On the other hand, I don't see what should happen to the Green function when $\eta \to  0^+$ . Should it tend to $\infty$ ? And is there an importance to when the Green function vanishes? I am motivated by the case where $H= \Delta+D$ on $\ell^2(\mathbb{Z})$ , with $\Delta$ being the discrete Laplacian and $D$ being a diagonal operator with finitely many diagonal values.   I am trying to consider the Green function using the Random walk expansion for the Green function given in chapter 6 of Random operators by Aizenman and Warzel for such operators.","I am trying to understand better the properties of the resolvent and Green function of a bounded self-adjoint operator at when . The resolvent is the operator , which is defined when is is not in the spectrum. If I am not mistaken, the Green function is defined as by , and is defined when is not in the spectrum. My question is what happens when is in the spectrum of to or when It seems that when is an approximate eigenvalue, that by Weyl's criterion for the spectrum. On the other hand, I don't see what should happen to the Green function when . Should it tend to ? And is there an importance to when the Green function vanishes? I am motivated by the case where on , with being the discrete Laplacian and being a diagonal operator with finitely many diagonal values.   I am trying to consider the Green function using the Random walk expansion for the Green function given in chapter 6 of Random operators by Aizenman and Warzel for such operators.","H z=E+i\eta \eta \to 0^+ R(H;z)=(H-zI)^{-1} z G:\mathcal{H}\times \mathcal{H\times \mathbb{C}} G(\psi,\phi; z):= \langle  R(H,z)\phi,\psi \rangle z E H \Vert R(H;E+i\eta)\Vert G(\psi, \phi;E+i\eta) \eta\to 0^+? E \Vert R(H;E+i\eta)\Vert\to \infty \eta \to  0^+ \infty H= \Delta+D \ell^2(\mathbb{Z}) \Delta D","['functional-analysis', 'spectral-theory', 'greens-function']"
91,"""almost everywhere defined"" ordinary differential equations","""almost everywhere defined"" ordinary differential equations",,"Let $u(t)$ be a measurable function on time interval $[0,T]$ , consider the ""almost everywhere defined"" ordinary differential equation: $$\left\{\begin{matrix} \frac{dx(t)}{dt}=b(t,x(t),u(t)) \;\;\;a.e.t\in[0,T]\\ x(0)=x_0\end{matrix}\right.$$ where $b(t,x,u)$ is a measurable function satisfying: (1) $|b(t,0,u)|<L$ holds for some $L$ and every $(t,u)\in[0,T]\times R$ . (2) $b(t,x,u)$ is Lipschitz continuous in variables $x$ and $u$ . Some literature that I am working with claim that the solution to the above ODE exists and is unique. I have a few questions though: (1) Does the solution to the above ODE equivalent to ""weak solution""? That is $$\int_0^T x(t)\phi'(t)dt=-\int_0^T b(t,x(t),u(t))\phi(t)dt$$ holds for every $\phi\in C_0^\infty([0,T])$ ? (2) Does the above ODE equivalent to the integral equation $$x(t)=x(0)+\int_0^tb(s,x(s),u(s))d s$$ (3) Classical theory of ODEs require a continuous $f(t,x)$ to ensure the existence and uniqueness to $dx(t)=f(t,x)dt$ with initial value. Here we don't have any continuity assumed on the time variable, why are the existence and uniqueness still valid? Please help by leading me to related literatures, thanks.","Let be a measurable function on time interval , consider the ""almost everywhere defined"" ordinary differential equation: where is a measurable function satisfying: (1) holds for some and every . (2) is Lipschitz continuous in variables and . Some literature that I am working with claim that the solution to the above ODE exists and is unique. I have a few questions though: (1) Does the solution to the above ODE equivalent to ""weak solution""? That is holds for every ? (2) Does the above ODE equivalent to the integral equation (3) Classical theory of ODEs require a continuous to ensure the existence and uniqueness to with initial value. Here we don't have any continuity assumed on the time variable, why are the existence and uniqueness still valid? Please help by leading me to related literatures, thanks.","u(t) [0,T] \left\{\begin{matrix} \frac{dx(t)}{dt}=b(t,x(t),u(t)) \;\;\;a.e.t\in[0,T]\\
x(0)=x_0\end{matrix}\right. b(t,x,u) |b(t,0,u)|<L L (t,u)\in[0,T]\times R b(t,x,u) x u \int_0^T x(t)\phi'(t)dt=-\int_0^T b(t,x(t),u(t))\phi(t)dt \phi\in C_0^\infty([0,T]) x(t)=x(0)+\int_0^tb(s,x(s),u(s))d s f(t,x) dx(t)=f(t,x)dt","['real-analysis', 'functional-analysis', 'ordinary-differential-equations', 'partial-differential-equations', 'measurable-functions']"
92,A problem about how dominated convergence is used while reading a paper about find the saddle point of the functional.,A problem about how dominated convergence is used while reading a paper about find the saddle point of the functional.,,"I'm reading Existence of solutions to a higher dimensional mean-field equation on manifolds and get stuck on Lemma6. They want to find the saddle point of $$ I_\lambda(u)=\frac{1}{2} \int_M|\Delta_g^{m/2} u|^2 d \mu_g-\frac{\lambda}{2 m} \log \left(\int_M e^{2 m u} d \mu_g\right) $$ on $$ E:=\left\{u \in H^m(M): \int_M u d \mu_g=0\right\}. $$ And equip $E$ with the norm $\|u\|:=\left(\int_M\left|\Delta_g^{\frac{m}{2}} u\right|^2 d \mu_g\right)^{\frac{1}{2}}$ . They have proved that there exists a bounded sequence $\left(u_n\right)$ in $E$ such that $I_\mu^{\prime}\left(u_n\right) \rightarrow 0$ and $I_\mu\left(u_n\right) \rightarrow c_\mu$ . Then they assume that $u_n$ converges weakly in $E$ and almost everywhere to a function $u$ , and proved that $e^{2 m u_n}$ and $e^{2 m u}$ are uniformly bounded in $L^4$ . My question arises in the next step, they wrote that : by dominated convergence one has for $N>0$ $$\tag{1} \min \left\{e^{2 m u_n}, N\right\} \rightarrow \min \left\{e^{2 m u}, N\right\} \quad \text { in } L^2\left(M, d \mu_g\right) $$ as $n \rightarrow \infty$ and that $$ \sup _{n \in \mathbb{N}}\left\|\min \left\{e^{2 m u_n}, N\right\}-e^{2 m u_n}\right\|_{L^2}^2 \leq \frac{1}{N^2} \sup _{n \in \mathbb{N}}\left\|e^{2 m u_n}\right\|_{L^4}^4 \rightarrow 0 \quad \text { as } N \rightarrow \infty, $$ we infer that $e^{2 m u_n} \rightarrow e^{2 m u}$ in $L^2$ . I wonder why they need to choose a $N$ and wrote (1) ? Actually I don't even know how the dominated convergence is used here.","I'm reading Existence of solutions to a higher dimensional mean-field equation on manifolds and get stuck on Lemma6. They want to find the saddle point of on And equip with the norm . They have proved that there exists a bounded sequence in such that and . Then they assume that converges weakly in and almost everywhere to a function , and proved that and are uniformly bounded in . My question arises in the next step, they wrote that : by dominated convergence one has for as and that we infer that in . I wonder why they need to choose a and wrote (1) ? Actually I don't even know how the dominated convergence is used here.","
I_\lambda(u)=\frac{1}{2} \int_M|\Delta_g^{m/2} u|^2 d \mu_g-\frac{\lambda}{2 m} \log \left(\int_M e^{2 m u} d \mu_g\right)
 
E:=\left\{u \in H^m(M): \int_M u d \mu_g=0\right\}.
 E \|u\|:=\left(\int_M\left|\Delta_g^{\frac{m}{2}} u\right|^2 d \mu_g\right)^{\frac{1}{2}} \left(u_n\right) E I_\mu^{\prime}\left(u_n\right) \rightarrow 0 I_\mu\left(u_n\right) \rightarrow c_\mu u_n E u e^{2 m u_n} e^{2 m u} L^4 N>0 \tag{1}
\min \left\{e^{2 m u_n}, N\right\} \rightarrow \min \left\{e^{2 m u}, N\right\} \quad \text { in } L^2\left(M, d \mu_g\right)
 n \rightarrow \infty 
\sup _{n \in \mathbb{N}}\left\|\min \left\{e^{2 m u_n}, N\right\}-e^{2 m u_n}\right\|_{L^2}^2 \leq \frac{1}{N^2} \sup _{n \in \mathbb{N}}\left\|e^{2 m u_n}\right\|_{L^4}^4 \rightarrow 0 \quad \text { as } N \rightarrow \infty,
 e^{2 m u_n} \rightarrow e^{2 m u} L^2 N","['real-analysis', 'functional-analysis', 'calculus-of-variations']"
93,Finding the limit of an integral using the Stone-Weierstrass theorem,Finding the limit of an integral using the Stone-Weierstrass theorem,,"I found the following problem while preparing for some math olympiad in my country. Let $c\in (1, +\infty)$ and $f \colon [0, c] \to \mathbb{R}$ be a continuous and monotonically increasing function with $f(0)=0$ and $f(1)=1$ . Calculate the following limit $$\lim_{t \to 0^+} \frac{1}{t}\int_0^1 f(x)(f(x+t)-f(x))dx$$ (the integral is assumed to be a Riemann integral, it is supposed to be solved without Lebesgue integrals) My approach to solving the problem: The problem is trivial if we assume that $f$ is differentiable. If we do, then by the mean value theorem, there exists, for each $x \in [0, 1]$ a $c_t \in [x, x+t]$ , such that $f(x+t)-f(x)=f'(c_t)*t$ . Since $f$ is continuous and $f'$ is bounded, so is $f(x)*f'(c_t)$ , for all $t$ near $0$ . So our limit becomes $\lim_{t \to 0^+} \int_0^1 f(x)*f(c_t)dx$ . By Arzela's theorem for uniformly bounded integrals, we can interchange the limit and the integral and we get $\int_0^1 f(x)*f'(x)dx=0.5*(f(1)^2-f(0)^2)$ . Since every continuous function can be uniformly approximated by polynomials(Stone-Weierstrass theorem), then the set of differentiable functions with bounded derivative are dense in the set of continuous functions with the $||\cdot||_{\infty}$ norm, so for any continuous function $f_0$ , we can find differentiable functions arbitrarily ""close"" to it. These observations lead to considering the following function. Let $C$ be the Banach space of continuous functions with the $||\cdot||_{\infty}$ norm. Let $T \colon C \times (0, +\infty) \to \mathbb{R}, T(f)(t) = \frac{1}{t} \int_0^1 f(x)(f(x+t)-f(x))dx$ . Consider now, $u \in C$ and $v \in C$ fixed and $t$ an arbitrary positive real number. Then $$ |T(u)(t)-T(v)(t)| \leq \frac{1}{t} \int_0^1 | u(x)u(x+t)-u(x)v(x+t)+u(x)v(x+t)-v(x)v(x+t)+v(x)^2-u(x)^2 |dx \leq \frac{1}{t}\left(\int_0^1|u(x)||u(x+t)-v(x+t)|dx+\int_0^1|u(x)-v(x)||v(x+t)|dx + \int_0^1|u(x)-v(x)||u(x)+v(x)|dx\right) \\ \leq \frac{1}{t} \left(\|u\|_{\infty}\|u-v\|_{\infty}+\|u-v\|_{\infty}\|v\|_{\infty} + \|u-v\|_{\infty}\|u+v\|_{\infty}\right) \leq \frac{1}{t} \left( \|u-v\|_{\infty} \left( \|u\|_{\infty}+\|v\|_{\infty} + \|u+v\|_{\infty} \right) \right) \leq \frac{1}{t} \left( 2\|u-v\|_{\infty} \left( \|u-v\|_{\infty}+2\|v\|_{\infty}\right) \right) $$ Therefore $T$ is continuous in $f$ uniformly in $t$ . Because of $T(f)(t)$ converges uniformly to some function $g(t)$ . Therefore, $$ \lim_{t \to 0} \lim_{f \to f_0} T(f)(t) =\lim_{f \to f_0} \lim_{t \to 0} T(f)(t)  $$ To justify the interchange of limits, let's denote $g(t)\colon=\lim_{f \ to f_0} T(f)(t)$ , $h(f)= \lim_{t \to 0} T(f)(t)$ and $l=\lim_{f \to f_0} \lim_{t \to 0} T(f)(t)$ . Now let $a$ be a function such that $\|a-f_0\|<\delta$ . We can see that $$ |g(t)-l| \leq |g(t)-T(a)(t)+T(a)(t)-h(a)+h(a)-l| \leq |g(t)-T(a)(t)| + |T(a)(t)-h(a)| + |h(a)-l| $$ And each term can be made arbitrarily small. Since the differentiable functions are dense in $C$ , we can assume WLOG that $f$ is differentiable in the limits above. The question in the problem is equivalent to $\lim_{t \to 0} \lim_{f \to f_0} T(f)(t)$ . And by interchanging limits, the result is trivial. Is my proof correct? To me it seems like it is, but I never used the monotonicity of $f$ ?","I found the following problem while preparing for some math olympiad in my country. Let and be a continuous and monotonically increasing function with and . Calculate the following limit (the integral is assumed to be a Riemann integral, it is supposed to be solved without Lebesgue integrals) My approach to solving the problem: The problem is trivial if we assume that is differentiable. If we do, then by the mean value theorem, there exists, for each a , such that . Since is continuous and is bounded, so is , for all near . So our limit becomes . By Arzela's theorem for uniformly bounded integrals, we can interchange the limit and the integral and we get . Since every continuous function can be uniformly approximated by polynomials(Stone-Weierstrass theorem), then the set of differentiable functions with bounded derivative are dense in the set of continuous functions with the norm, so for any continuous function , we can find differentiable functions arbitrarily ""close"" to it. These observations lead to considering the following function. Let be the Banach space of continuous functions with the norm. Let . Consider now, and fixed and an arbitrary positive real number. Then Therefore is continuous in uniformly in . Because of converges uniformly to some function . Therefore, To justify the interchange of limits, let's denote , and . Now let be a function such that . We can see that And each term can be made arbitrarily small. Since the differentiable functions are dense in , we can assume WLOG that is differentiable in the limits above. The question in the problem is equivalent to . And by interchanging limits, the result is trivial. Is my proof correct? To me it seems like it is, but I never used the monotonicity of ?","c\in (1, +\infty) f \colon [0, c] \to \mathbb{R} f(0)=0 f(1)=1 \lim_{t \to 0^+} \frac{1}{t}\int_0^1 f(x)(f(x+t)-f(x))dx f x \in [0, 1] c_t \in [x, x+t] f(x+t)-f(x)=f'(c_t)*t f f' f(x)*f'(c_t) t 0 \lim_{t \to 0^+} \int_0^1 f(x)*f(c_t)dx \int_0^1 f(x)*f'(x)dx=0.5*(f(1)^2-f(0)^2) ||\cdot||_{\infty} f_0 C ||\cdot||_{\infty} T \colon C \times (0, +\infty) \to \mathbb{R}, T(f)(t) = \frac{1}{t} \int_0^1 f(x)(f(x+t)-f(x))dx u \in C v \in C t 
|T(u)(t)-T(v)(t)| \leq \frac{1}{t} \int_0^1 | u(x)u(x+t)-u(x)v(x+t)+u(x)v(x+t)-v(x)v(x+t)+v(x)^2-u(x)^2 |dx \leq \frac{1}{t}\left(\int_0^1|u(x)||u(x+t)-v(x+t)|dx+\int_0^1|u(x)-v(x)||v(x+t)|dx + \int_0^1|u(x)-v(x)||u(x)+v(x)|dx\right) \\ \leq \frac{1}{t} \left(\|u\|_{\infty}\|u-v\|_{\infty}+\|u-v\|_{\infty}\|v\|_{\infty} + \|u-v\|_{\infty}\|u+v\|_{\infty}\right) \leq \frac{1}{t} \left( \|u-v\|_{\infty} \left( \|u\|_{\infty}+\|v\|_{\infty} + \|u+v\|_{\infty} \right) \right) \leq \frac{1}{t} \left( 2\|u-v\|_{\infty} \left( \|u-v\|_{\infty}+2\|v\|_{\infty}\right) \right)
 T f t T(f)(t) g(t) 
\lim_{t \to 0} \lim_{f \to f_0} T(f)(t) =\lim_{f \to f_0} \lim_{t \to 0} T(f)(t) 
 g(t)\colon=\lim_{f \ to f_0} T(f)(t) h(f)= \lim_{t \to 0} T(f)(t) l=\lim_{f \to f_0} \lim_{t \to 0} T(f)(t) a \|a-f_0\|<\delta 
|g(t)-l| \leq |g(t)-T(a)(t)+T(a)(t)-h(a)+h(a)-l| \leq |g(t)-T(a)(t)| + |T(a)(t)-h(a)| + |h(a)-l|
 C f \lim_{t \to 0} \lim_{f \to f_0} T(f)(t) f","['functional-analysis', 'limits', 'analysis', 'continuity', 'uniform-continuity']"
94,Inequality appearing at theorem 1.3.5 in Hormander's book,Inequality appearing at theorem 1.3.5 in Hormander's book,,"Theorem 1.3.5 p19 in ""the analysis of linear partial differential operators I"" by Hormander states that for any positive sequence $a_{0}\geq a_{1}\geq \cdots $ such that $a=\sum_{k=0}^{+\infty }a_{k}<+\infty $ , if $% u_{k}=H_{a_{0}}\ast \cdots \ast H_{a_{k}}$ (where $H_{c}(x)=c^{-1}$ when $% 0\leq x\leq c$ and $H_{c}(x)=0$ otherwise), then $u_{k}\in $ $% C_{0}^{k-1}\left(\mathbb{R} \right) $ has support in $\left[ 0,a\right] $ and converges as $k\rightarrow +\infty $ to a function $u\in C_{0}^{\infty }\left(  \mathbb{R}\right) $ with support in $\left[ 0,a\right] $ such that $\int udx=1$ and $% \left\vert u^{(k)}(x)\right\vert \leq 2^{-1}\int \left\vert u^{(k+1)}(x)\right\vert dx\leq 2^{k}(a_{0}...a_{k})^{-1},k=0,1,\ldots $ In the proof of the theorem, the author shows clearly that $\left\vert u^{(k)}(x)\right\vert \leq 2^{k}(a_{0}...a_{k})^{-1}$ and $2^{-1}\int \left\vert u^{(k+1)}(x)\right\vert dx\leq 2^{k}(a_{0}...a_{k})^{-1}$ , but, if I am not wrong, he doesn't give any hint for the inequality $\left\vert u^{(k)}(x)\right\vert \leq 2^{-1}\int \left\vert u^{(k+1)}(x)\right\vert dx$ . I have tried to state it myself but all I have found is the inequality : $ \int \left\vert u^{\left( k\right)}\left(x\right)-u^{\left( k\right)}\left(x-a_{k}\right)\right\vert dx  \leq 2^{-1}\int \left\vert u^{(k+1)}(x)\right\vert dx$ and nothing further. Please help me clarify this point, as I am totally stuck. Thanks in advance.","Theorem 1.3.5 p19 in ""the analysis of linear partial differential operators I"" by Hormander states that for any positive sequence such that , if (where when and otherwise), then has support in and converges as to a function with support in such that and In the proof of the theorem, the author shows clearly that and , but, if I am not wrong, he doesn't give any hint for the inequality . I have tried to state it myself but all I have found is the inequality : and nothing further. Please help me clarify this point, as I am totally stuck. Thanks in advance.","a_{0}\geq a_{1}\geq
\cdots  a=\sum_{k=0}^{+\infty }a_{k}<+\infty  %
u_{k}=H_{a_{0}}\ast \cdots \ast H_{a_{k}} H_{c}(x)=c^{-1} %
0\leq x\leq c H_{c}(x)=0 u_{k}\in  %
C_{0}^{k-1}\left(\mathbb{R}
\right)  \left[ 0,a\right]  k\rightarrow
+\infty  u\in C_{0}^{\infty }\left( 
\mathbb{R}\right)  \left[ 0,a\right]  \int udx=1 %
\left\vert u^{(k)}(x)\right\vert \leq 2^{-1}\int \left\vert
u^{(k+1)}(x)\right\vert dx\leq 2^{k}(a_{0}...a_{k})^{-1},k=0,1,\ldots  \left\vert
u^{(k)}(x)\right\vert \leq 2^{k}(a_{0}...a_{k})^{-1} 2^{-1}\int
\left\vert u^{(k+1)}(x)\right\vert dx\leq 2^{k}(a_{0}...a_{k})^{-1} \left\vert
u^{(k)}(x)\right\vert \leq 2^{-1}\int \left\vert u^{(k+1)}(x)\right\vert dx  \int \left\vert u^{\left( k\right)}\left(x\right)-u^{\left( k\right)}\left(x-a_{k}\right)\right\vert dx  \leq 2^{-1}\int \left\vert u^{(k+1)}(x)\right\vert dx","['functional-analysis', 'inequality', 'proof-explanation', 'convolution']"
95,Existence of a weak-star limit of a family of operators in $B(\mathcal{H})$,Existence of a weak-star limit of a family of operators in,B(\mathcal{H}),"Thank you in advance for reading this question, and your thoughts. I am working with a family of operators $(A_{s,\alpha})_{s\geq 0,\alpha>0}$ in the space $B(\mathcal{H})$ (the space of bounded linear operators on a complex separable Hilbert space $\mathcal{H}$ ) depending on two parameters $s\geq 0$ and $\alpha>0$ . This family is such that for fixed $\alpha>0$ , the mapping $[0,\infty)\ni s\mapsto A_{s,\alpha}\in B(\mathcal{H})$ is a strongly continuous semigroup , and $$(\star)\quad \forall\, s>0,\,\forall\, \alpha>0:\quad \big|\big|A_{s,\alpha}\big|\big|_{B(\mathcal{H}}\leq 1\,, $$ i.e. the family of operators $(A_{s,\alpha})_{s\geq 0,\alpha>0}$ lives in the norm-closed unit ball of $B(\mathcal{H})$ . Next, the pre-dual of $B(\mathcal{H})$ (up to isometric isomorphism)  is $B_1(\mathcal{H})$ , the trace-class operators on $\mathcal{H}$ . This defines a weak-star topology on $B(\mathcal{H})$ , and by the  Banach-Alaoglu theorem, the norm-closed unit ball of $B(\mathcal{H})$ is weak-star compact. Question 1: I think that since $\mathcal{H}$ is separable, it follows that $B_1(\mathcal{H})$ is separable, and hence the norm-closed unit ball of $B(\mathcal{H})$ is weak-star sequentially compact? Next, assuming an affirmative answer to Question 1 , let us fix an arbitrary sequence $\alpha_n\to 0^+$ .  Then for any fixed $s\geq 0$ , $(\star)$ above implies   the sequence of operators $(A_{s,\alpha_n})_{n\in \mathbb{N}}$ has a weak-star convergent subsequence $(A_{s,\alpha_{n_k}})_{k\in \mathbb{N}}$ . Unfortunately , however, this subsequence may depend on the particular $s\geq 0$ . Question 2: Is it possible to show that there exists a subsequence $(\alpha_{n_j})_{j\in \mathbb{N}}$ of the above $\alpha_n\to 0^+$ so that for all $s\geq 0$ the sequence of operators $(A_{s,\alpha_{n_j}})_{j\in \mathbb{N}}$ converges in the weak-star topology in $B(\mathcal{H})$ ? If not, are there some ""natural"" assumptions one can make on the $\alpha$ -dependence of the operators such that this works?","Thank you in advance for reading this question, and your thoughts. I am working with a family of operators in the space (the space of bounded linear operators on a complex separable Hilbert space ) depending on two parameters and . This family is such that for fixed , the mapping is a strongly continuous semigroup , and i.e. the family of operators lives in the norm-closed unit ball of . Next, the pre-dual of (up to isometric isomorphism)  is , the trace-class operators on . This defines a weak-star topology on , and by the  Banach-Alaoglu theorem, the norm-closed unit ball of is weak-star compact. Question 1: I think that since is separable, it follows that is separable, and hence the norm-closed unit ball of is weak-star sequentially compact? Next, assuming an affirmative answer to Question 1 , let us fix an arbitrary sequence .  Then for any fixed , above implies   the sequence of operators has a weak-star convergent subsequence . Unfortunately , however, this subsequence may depend on the particular . Question 2: Is it possible to show that there exists a subsequence of the above so that for all the sequence of operators converges in the weak-star topology in ? If not, are there some ""natural"" assumptions one can make on the -dependence of the operators such that this works?","(A_{s,\alpha})_{s\geq 0,\alpha>0} B(\mathcal{H}) \mathcal{H} s\geq 0 \alpha>0 \alpha>0 [0,\infty)\ni s\mapsto A_{s,\alpha}\in B(\mathcal{H}) (\star)\quad \forall\, s>0,\,\forall\, \alpha>0:\quad \big|\big|A_{s,\alpha}\big|\big|_{B(\mathcal{H}}\leq 1\,,  (A_{s,\alpha})_{s\geq 0,\alpha>0} B(\mathcal{H}) B(\mathcal{H}) B_1(\mathcal{H}) \mathcal{H} B(\mathcal{H}) B(\mathcal{H}) \mathcal{H} B_1(\mathcal{H}) B(\mathcal{H}) \alpha_n\to 0^+ s\geq 0 (\star) (A_{s,\alpha_n})_{n\in \mathbb{N}} (A_{s,\alpha_{n_k}})_{k\in \mathbb{N}} s\geq 0 (\alpha_{n_j})_{j\in \mathbb{N}} \alpha_n\to 0^+ s\geq 0 (A_{s,\alpha_{n_j}})_{j\in \mathbb{N}} B(\mathcal{H}) \alpha","['functional-analysis', 'operator-theory', 'operator-algebras', 'semigroup-of-operators', 'weak-topology']"
96,Projections in atomless von Neumann algebras,Projections in atomless von Neumann algebras,,"Let $\varepsilon>0$ . If we consider a sequence $\{f_n\}$ in $L_\infty(0,1)$ , then there exists a very small subset $A$ of $(0,1)$ with $m(A)<\varepsilon$ such that $$\|f_n \chi_A\|_\infty =\|f_n \|_\infty $$ for all $n$ . My question is, do we have an analogue of this result in the von Neuamnn algebra setting? Precisely, let $M$ be an atomless von Neumann algebra and let $\{x_n\}$ be a sequence in $M$ . Can we find a projection $p$ in $M$ which is very small (say, for a semifinite faithful normal weight, $\omega(p)<\varepsilon$ ) such that $$\|x_n p\|_\infty =\|x_n \|_\infty $$ for all $n$ . For the case of a semifinite von Neumann algebra, it is true because we may take $p_n$ to be very small such that $\|x_n p_n\|_\infty =\|x_n\|_\infty$ and let $p:=\vee p_n$ . Since $\tau(p)\le \sum_{n\ge 1}\tau(p_n)$ ， we may choose suitable $p_n$ such that $\tau(p)<\varepsilon$ . Moreover, $$\|x_n p\|_\infty =\|x_n \|_\infty $$ for all $n$ . However, for the type III case, it seems to be rather difficult.","Let . If we consider a sequence in , then there exists a very small subset of with such that for all . My question is, do we have an analogue of this result in the von Neuamnn algebra setting? Precisely, let be an atomless von Neumann algebra and let be a sequence in . Can we find a projection in which is very small (say, for a semifinite faithful normal weight, ) such that for all . For the case of a semifinite von Neumann algebra, it is true because we may take to be very small such that and let . Since ， we may choose suitable such that . Moreover, for all . However, for the type III case, it seems to be rather difficult.","\varepsilon>0 \{f_n\} L_\infty(0,1) A (0,1) m(A)<\varepsilon \|f_n \chi_A\|_\infty =\|f_n \|_\infty  n M \{x_n\} M p M \omega(p)<\varepsilon \|x_n p\|_\infty =\|x_n \|_\infty  n p_n \|x_n p_n\|_\infty =\|x_n\|_\infty p:=\vee p_n \tau(p)\le \sum_{n\ge 1}\tau(p_n) p_n \tau(p)<\varepsilon \|x_n p\|_\infty =\|x_n \|_\infty  n","['functional-analysis', 'operator-algebras', 'von-neumann-algebras']"
97,Commutation of operators,Commutation of operators,,"Let $(\mathcal{H},\langle\cdot,\cdot\rangle)$ be a complex Hilbert space. Furthermore, let $E:\mathcal{D}(E)\to\mathcal{H}$ be a self-adjoint unbounded operator and $A:\mathcal{D}(A)\to\mathcal{H}$ (not necessarily self-adjoint) another unbounded densely-defined operator such that $$EA=AE$$ on the common domain $\mathcal{D}(AE)\cap\mathcal{D}(EA)$ . Lets now take a bounded continuous function $f\in C(\sigma(E),\mathbb{C})$ and define the bounded operator $f(E)\in\mathcal{B}(\mathcal{H})$ by means of the spectral calculus. Under which additional assumptions is it true that $f(E)A=Af(E)$ on $\mathcal{D}(A)\cap\mathcal{D}(Af(E))$ ? I was looking in the internet and there seems to be some theorems about the commutation of operators and the spectral theorem, but I was not able to find a version in which both operators are unbounded.","Let be a complex Hilbert space. Furthermore, let be a self-adjoint unbounded operator and (not necessarily self-adjoint) another unbounded densely-defined operator such that on the common domain . Lets now take a bounded continuous function and define the bounded operator by means of the spectral calculus. Under which additional assumptions is it true that on ? I was looking in the internet and there seems to be some theorems about the commutation of operators and the spectral theorem, but I was not able to find a version in which both operators are unbounded.","(\mathcal{H},\langle\cdot,\cdot\rangle) E:\mathcal{D}(E)\to\mathcal{H} A:\mathcal{D}(A)\to\mathcal{H} EA=AE \mathcal{D}(AE)\cap\mathcal{D}(EA) f\in C(\sigma(E),\mathbb{C}) f(E)\in\mathcal{B}(\mathcal{H}) f(E)A=Af(E) \mathcal{D}(A)\cap\mathcal{D}(Af(E))","['functional-analysis', 'reference-request', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
98,Do mollifiers exist in dimensions higher than 1?,Do mollifiers exist in dimensions higher than 1?,,"A mollifier is defined as a function $\varphi: \mathbb{R}^n \rightarrow \mathbb{R}$ such that $$\int_{\mathbb{R}^n} \varphi(x) dx = 1$$ $\varphi$ has compact support $$\lim_{\epsilon \rightarrow 0} \varphi_\epsilon = \lim_{\epsilon \rightarrow 0} \frac{1}{\epsilon^{n}} \varphi\big(\frac{x}{\epsilon}\big) = \delta_0$$ Thus we may mollify any function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ by computing the convolution $f * \varphi_\epsilon$ . I would like to do the same for a function $g: \mathbb{R}^n \rightarrow \mathbb{R}^m$ where $m > 1$ . To do this would require the mollifiers $\varphi$ to be extended to higher dimensions, that is $\varphi: \mathbb{R}^n \rightarrow \mathbb{R}^m$ for $m > 1$ . Does such an object exist? If not, what about the three criteria above fails in higher dimensions? I could not find it in any textbooks.","A mollifier is defined as a function such that has compact support Thus we may mollify any function by computing the convolution . I would like to do the same for a function where . To do this would require the mollifiers to be extended to higher dimensions, that is for . Does such an object exist? If not, what about the three criteria above fails in higher dimensions? I could not find it in any textbooks.",\varphi: \mathbb{R}^n \rightarrow \mathbb{R} \int_{\mathbb{R}^n} \varphi(x) dx = 1 \varphi \lim_{\epsilon \rightarrow 0} \varphi_\epsilon = \lim_{\epsilon \rightarrow 0} \frac{1}{\epsilon^{n}} \varphi\big(\frac{x}{\epsilon}\big) = \delta_0 f: \mathbb{R}^n \rightarrow \mathbb{R} f * \varphi_\epsilon g: \mathbb{R}^n \rightarrow \mathbb{R}^m m > 1 \varphi \varphi: \mathbb{R}^n \rightarrow \mathbb{R}^m m > 1,"['functional-analysis', 'analysis', 'fourier-analysis', 'convolution']"
99,"Prove that if $f\in C([a,b])$ satisfies $\int_a^bx^kf(x)dx=0 \ \forall k\geq0$ then $f=0$",Prove that if  satisfies  then,"f\in C([a,b]) \int_a^bx^kf(x)dx=0 \ \forall k\geq0 f=0","Prove that if $f\in C([a,b])$ satisfies $\int_a^bx^kf(x)dx=0 \ \forall k\geq0$ then $f=0$ . I saw this problem online and as I'm currently studying functional analysis I'm interested in a solution using this field. I proceed as follows: Let $L:C([a,b])\rightarrow\mathbb{R}$ given by $L(x)=\int_a^bf(t)x(t)dt$ . From linearity of the integral que see that $L$ is linear. Furthermore, $$|L(x)|=\bigg\vert\int_a^bf(t)x(t)dt\bigg\vert\leq\int_a^b|f(t)x(t)|dt\leq C||x||_{\infty}, \ \ C=\int_a^b|f(t)|dt$$ So $L$ is continuous ( $L\in (C([a,b]))^*$ ). By Weiertrass approximation theorem, the span of $\{x^k\}_{k\geq0}$ is dense in $C([a,b])$ , and by hypothesis $L$ is identically $0$ on this set, so $L=0$ (as $\mathbb{R}$ is Hausdorff and $L$ and the zero functional are equal on a dense set). Now use that to conclude that $$ L(f)=\int_a^bf(t)^2dt=0 $$ and so $f=0$ . Is my solution correct?","Prove that if satisfies then . I saw this problem online and as I'm currently studying functional analysis I'm interested in a solution using this field. I proceed as follows: Let given by . From linearity of the integral que see that is linear. Furthermore, So is continuous ( ). By Weiertrass approximation theorem, the span of is dense in , and by hypothesis is identically on this set, so (as is Hausdorff and and the zero functional are equal on a dense set). Now use that to conclude that and so . Is my solution correct?","f\in C([a,b]) \int_a^bx^kf(x)dx=0 \ \forall k\geq0 f=0 L:C([a,b])\rightarrow\mathbb{R} L(x)=\int_a^bf(t)x(t)dt L |L(x)|=\bigg\vert\int_a^bf(t)x(t)dt\bigg\vert\leq\int_a^b|f(t)x(t)|dt\leq C||x||_{\infty}, \ \ C=\int_a^b|f(t)|dt L L\in (C([a,b]))^* \{x^k\}_{k\geq0} C([a,b]) L 0 L=0 \mathbb{R} L 
L(f)=\int_a^bf(t)^2dt=0
 f=0","['real-analysis', 'functional-analysis', 'solution-verification', 'continuity']"
