,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Dixmier-Douady class: computations,Dixmier-Douady class: computations,,"As far as I know, Dixmier-Douady classes represent obstrucions to spin$^c$ structures. Questions: Could somebody prove or give a reference: manifolds of dimension lower than $5$ always have a vanishing Dixmier-Douady class. I want to compute Dixmier-Douady classes for $n$-manifolds, $n\geq 5$. Rather, I want to be sure that I understand at a computational level, what DD classes are. Could somebody provide an operational definition of Dixmier-Douady classes that would work for this task? I have no idea how to begin with. E.g. I only know the example in T. Friedrich's book. He considers the homogeneous space $X^5=SU(3)/SO(3)$, shows via homotopy theory that the frame bundle $Q\to X^5$ has vanishing fundamental group and therefore admits no spin$^c$ structure. Indirectly, he is showing that the Dixmier-Douady class of $X^5$ is not trivial. But, can one do the same for arbitrary manifods? could somebody give a simple example how to procede?","As far as I know, Dixmier-Douady classes represent obstrucions to spin$^c$ structures. Questions: Could somebody prove or give a reference: manifolds of dimension lower than $5$ always have a vanishing Dixmier-Douady class. I want to compute Dixmier-Douady classes for $n$-manifolds, $n\geq 5$. Rather, I want to be sure that I understand at a computational level, what DD classes are. Could somebody provide an operational definition of Dixmier-Douady classes that would work for this task? I have no idea how to begin with. E.g. I only know the example in T. Friedrich's book. He considers the homogeneous space $X^5=SU(3)/SO(3)$, shows via homotopy theory that the frame bundle $Q\to X^5$ has vanishing fundamental group and therefore admits no spin$^c$ structure. Indirectly, he is showing that the Dixmier-Douady class of $X^5$ is not trivial. But, can one do the same for arbitrary manifods? could somebody give a simple example how to procede?",,"['algebraic-topology', 'differential-geometry', 'homotopy-theory', 'noncommutative-geometry']"
1,Is a basis for the Lie algebra of a Lie group also a set of infinitesimal generators for the Lie group?,Is a basis for the Lie algebra of a Lie group also a set of infinitesimal generators for the Lie group?,,"Let $G$ be a (EDIT: connected) Lie group of dimension $n$, and let $\mathfrak{g}$ be the associated Lie algebra. If $x_1,\ldots,x_n$ is a basis for $\mathfrak{g},$ is it necessarily true that the 1-parameter subgroups $e^{tx_1},\ldots,e^{tx_n}$ generate $G$? Note: It is sufficient to show that the subgroup generated by the 1-parameter subgroups is closed, since it follows that it is a Lie subgroup of dimension $n$. In particular, it must contain a neighborhood of the identity, which generates $G$. Also, note that it is not always true that the subgroup generated by 1-parameter subgroups is a Lie subgroup; consider the 1-parameter subgroup of the 2-torus that is a line with irrational slope.","Let $G$ be a (EDIT: connected) Lie group of dimension $n$, and let $\mathfrak{g}$ be the associated Lie algebra. If $x_1,\ldots,x_n$ is a basis for $\mathfrak{g},$ is it necessarily true that the 1-parameter subgroups $e^{tx_1},\ldots,e^{tx_n}$ generate $G$? Note: It is sufficient to show that the subgroup generated by the 1-parameter subgroups is closed, since it follows that it is a Lie subgroup of dimension $n$. In particular, it must contain a neighborhood of the identity, which generates $G$. Also, note that it is not always true that the subgroup generated by 1-parameter subgroups is a Lie subgroup; consider the 1-parameter subgroup of the 2-torus that is a line with irrational slope.",,"['differential-geometry', 'lie-algebras', 'lie-groups']"
2,De Rham cohomology for non-compact manifolds,De Rham cohomology for non-compact manifolds,,"Let $M$ be a non-compact differential manifold. It is true that in general $H^q_c(M) \neq H^q(M)$, where $H^q_c$ is the de Rham's cohomolgy with compact support group and $H^q$ is the usual de Rham's cohomology group. We have just begun the subject, so I don't have much confidence with it. I wanted to ask: is it true that for any non-compact $M$ there exists a $q$ for which $H^q_c (M) \neq H^q(M)$? Or are there any examples of non-compact manifolds for which the two cohomologies are the same for all $q$? EDIT: ok, from the comments I gathered that if such an example exists it must be non-orientable (a reference to a proof would be nice, even though I think the resul is quite non-elementary). The question still remains open though (that's my main reason to editing: I think this question didn't get enough attention).","Let $M$ be a non-compact differential manifold. It is true that in general $H^q_c(M) \neq H^q(M)$, where $H^q_c$ is the de Rham's cohomolgy with compact support group and $H^q$ is the usual de Rham's cohomology group. We have just begun the subject, so I don't have much confidence with it. I wanted to ask: is it true that for any non-compact $M$ there exists a $q$ for which $H^q_c (M) \neq H^q(M)$? Or are there any examples of non-compact manifolds for which the two cohomologies are the same for all $q$? EDIT: ok, from the comments I gathered that if such an example exists it must be non-orientable (a reference to a proof would be nice, even though I think the resul is quite non-elementary). The question still remains open though (that's my main reason to editing: I think this question didn't get enough attention).",,"['differential-geometry', 'homology-cohomology']"
3,Unit-speed reparametrizations,Unit-speed reparametrizations,,"I have to prove that for a regular parametrized curve there is essentially (up to sign and a constant) a unique reparametrization which makes it a unit-speed curve. Let $x$ be a curve,  $s(t) = \int_{t_0}^{t} \left \| \frac{\mathrm{d} x}{\mathrm{d} t} \right \| d\tau$ is an arc length parameter. We have the unit-speed reparametrization $y(s) = x(t(s))$, in fact $$1=\left \| \dot{y}(s) \right \| = \left \| \frac{\mathrm{d} x}{\mathrm{d} t} \right \| \, \frac{\mathrm{d} t}{\mathrm{d} s}.$$ Suppose that u is a parameter that makes $y(u) = x(t(u))$ a unit-speed parametrization. Then $$1=\left \| \dot{y}(u) \right \| = \left \| \frac{\mathrm{d} x}{\mathrm{d} t} \right \| \, \frac{\mathrm{d} t}{\mathrm{d} u}$$ and so $$\frac{\mathrm{d} u}{\mathrm{d} t} = \pm \frac{\mathrm{d} s}{\mathrm{d} t} $$ that finally yelds $u=\pm s + \mathrm{const}$. I have no idea if this can be proved as I did, can you spot any errors? Thanks","I have to prove that for a regular parametrized curve there is essentially (up to sign and a constant) a unique reparametrization which makes it a unit-speed curve. Let $x$ be a curve,  $s(t) = \int_{t_0}^{t} \left \| \frac{\mathrm{d} x}{\mathrm{d} t} \right \| d\tau$ is an arc length parameter. We have the unit-speed reparametrization $y(s) = x(t(s))$, in fact $$1=\left \| \dot{y}(s) \right \| = \left \| \frac{\mathrm{d} x}{\mathrm{d} t} \right \| \, \frac{\mathrm{d} t}{\mathrm{d} s}.$$ Suppose that u is a parameter that makes $y(u) = x(t(u))$ a unit-speed parametrization. Then $$1=\left \| \dot{y}(u) \right \| = \left \| \frac{\mathrm{d} x}{\mathrm{d} t} \right \| \, \frac{\mathrm{d} t}{\mathrm{d} u}$$ and so $$\frac{\mathrm{d} u}{\mathrm{d} t} = \pm \frac{\mathrm{d} s}{\mathrm{d} t} $$ that finally yelds $u=\pm s + \mathrm{const}$. I have no idea if this can be proved as I did, can you spot any errors? Thanks",,[]
4,Global conformally flat coordinates in 2d spacetimes,Global conformally flat coordinates in 2d spacetimes,,"Let $(M,g)$ be a 2 dimensional pseudo-Riemannian manifold that is topologically a disc. Is it possible to construct a global coordinate system in which the metric is conformally flat? I.e. coordinates $(t,x)$ which cover the whole manifold such that the line element takes the form $ds^2=\Omega^2(t,x)(-dt^2 + dx^2)$ for some conformal factor $\Omega$.","Let $(M,g)$ be a 2 dimensional pseudo-Riemannian manifold that is topologically a disc. Is it possible to construct a global coordinate system in which the metric is conformally flat? I.e. coordinates $(t,x)$ which cover the whole manifold such that the line element takes the form $ds^2=\Omega^2(t,x)(-dt^2 + dx^2)$ for some conformal factor $\Omega$.",,['differential-geometry']
5,What is the proper way to address this result?,What is the proper way to address this result?,,"Reading a paper I came through an argument proving the following: Let be given a smooth action of $\mathbb{R}^n$ on a manifold $M$, such   that it is infinitesimally free and its orbits are pairwise diffeomorphic.   If the orbits of this action are the fibers of a surjective submersion   $\pi:M\to P$ then $\pi$ is a locally trivial fiber bundle whose standard   fiber is $\mathbb{T}^k\times\mathbb{R}^{n-k}$. Is this just an easy exercise? or is a special case of some other result? and in such a case is there a useful reference? I am asking this question in order to have a proper way to refer to this result.","Reading a paper I came through an argument proving the following: Let be given a smooth action of $\mathbb{R}^n$ on a manifold $M$, such   that it is infinitesimally free and its orbits are pairwise diffeomorphic.   If the orbits of this action are the fibers of a surjective submersion   $\pi:M\to P$ then $\pi$ is a locally trivial fiber bundle whose standard   fiber is $\mathbb{T}^k\times\mathbb{R}^{n-k}$. Is this just an easy exercise? or is a special case of some other result? and in such a case is there a useful reference? I am asking this question in order to have a proper way to refer to this result.",,"['differential-geometry', 'lie-groups', 'fiber-bundles']"
6,An Hamiltonian diffeomorphism is also a Poisson diffeomorphism,An Hamiltonian diffeomorphism is also a Poisson diffeomorphism,,"Let $(M,\{-,-\})$ be a Poisson manifold. An Hamiltonian isotopy is a smooth family of diffeomorphisms $\{\varphi^t:M\to M\}_{t\in [0,1]}$ such that $\varphi^0=\text{id}_M$ there exists a smooth family of functions $\{h_t:M\to \mathbb{R}\}_{t\in [0,1]}$ such that $$\frac{d\varphi^t(x)}{dt}=X_{h_t}|_{\varphi^t(x)}$$ where $X_{h_t}$ is the Hamilton vector field induced by $h_t$ (i.e. $X_{h_t}(g):=\{h_t,g\}$ for any $g\in C^\infty(M)$ ). A diffeomorphism $\varphi:M\to M$ is a Hamiltonian diffeomorphism iff there exists an Hamiltonian isotopy $\{\varphi^t\}$ such that $\varphi^1=\varphi$ . I want to prove that an Hamiltonian diffeomorphism is also a Poisson diffeomorphism i.e. $$\{f\circ \varphi,g\circ \varphi\}=\{f,g\}\circ \varphi$$ for any $f,g\in C^\infty(M)$ . My attempt Let's prove that $$\{f\circ \varphi^t,g\circ \varphi^t\}-\{f,g\}\circ \varphi^t=0$$ for any $t$ . This trivially holds for $t=0$ , so I just need to prove that the derivative of the expression above (with respect to $t$ ) is $0$ : $$\frac{d}{dt}|_{t=t_0}\{f\circ \varphi^t,g\circ \varphi^t\}-\{f,g\}\circ \varphi^t=$$ $$=\left\{f_\ast\left(\frac{d}{dt}|_{t=t_0}\varphi^t\right),g\circ \varphi^{t_0}\right\}+\left\{f\circ \varphi^{t_0},g_\ast\left(\frac{d}{dt}|_{t=t_0}\varphi^t\right)\right\}-\{f,g\}_\ast \left(\frac{d}{dt}|_{t=t_0}\varphi^t\right)=$$ $$=\left\{f_\ast\left(X_{h_{t_0}}|_{\varphi^{t_0}(\cdot)}\right),g\circ \varphi^{t_0}\right\}+\left\{f\circ \varphi^{t_0},g_\ast\left(X_{h_{t_0}}|_{\varphi^{t_0}(\cdot)}\right)\right\}-\{f,g\}_\ast \left(X_{h_{t_0}}|_{\varphi^{t_0}(\cdot)}\right)=$$ $$=\{\{h_{t_0},f\}\circ \varphi^{t_0},g\circ \varphi^{t_0}\}+\{f\circ \varphi^{t_0},\{h_{t_0},g\}\circ \varphi^{t_0}\}-\{h_{t_0},\{f,g\}\}\circ \varphi^{t_0}$$ And now I feel stuck.","Let be a Poisson manifold. An Hamiltonian isotopy is a smooth family of diffeomorphisms such that there exists a smooth family of functions such that where is the Hamilton vector field induced by (i.e. for any ). A diffeomorphism is a Hamiltonian diffeomorphism iff there exists an Hamiltonian isotopy such that . I want to prove that an Hamiltonian diffeomorphism is also a Poisson diffeomorphism i.e. for any . My attempt Let's prove that for any . This trivially holds for , so I just need to prove that the derivative of the expression above (with respect to ) is : And now I feel stuck.","(M,\{-,-\}) \{\varphi^t:M\to M\}_{t\in [0,1]} \varphi^0=\text{id}_M \{h_t:M\to \mathbb{R}\}_{t\in [0,1]} \frac{d\varphi^t(x)}{dt}=X_{h_t}|_{\varphi^t(x)} X_{h_t} h_t X_{h_t}(g):=\{h_t,g\} g\in C^\infty(M) \varphi:M\to M \{\varphi^t\} \varphi^1=\varphi \{f\circ \varphi,g\circ \varphi\}=\{f,g\}\circ \varphi f,g\in C^\infty(M) \{f\circ \varphi^t,g\circ \varphi^t\}-\{f,g\}\circ \varphi^t=0 t t=0 t 0 \frac{d}{dt}|_{t=t_0}\{f\circ \varphi^t,g\circ \varphi^t\}-\{f,g\}\circ \varphi^t= =\left\{f_\ast\left(\frac{d}{dt}|_{t=t_0}\varphi^t\right),g\circ \varphi^{t_0}\right\}+\left\{f\circ \varphi^{t_0},g_\ast\left(\frac{d}{dt}|_{t=t_0}\varphi^t\right)\right\}-\{f,g\}_\ast \left(\frac{d}{dt}|_{t=t_0}\varphi^t\right)= =\left\{f_\ast\left(X_{h_{t_0}}|_{\varphi^{t_0}(\cdot)}\right),g\circ \varphi^{t_0}\right\}+\left\{f\circ \varphi^{t_0},g_\ast\left(X_{h_{t_0}}|_{\varphi^{t_0}(\cdot)}\right)\right\}-\{f,g\}_\ast \left(X_{h_{t_0}}|_{\varphi^{t_0}(\cdot)}\right)= =\{\{h_{t_0},f\}\circ \varphi^{t_0},g\circ \varphi^{t_0}\}+\{f\circ \varphi^{t_0},\{h_{t_0},g\}\circ \varphi^{t_0}\}-\{h_{t_0},\{f,g\}\}\circ \varphi^{t_0}","['differential-geometry', 'vector-fields', 'symplectic-geometry', 'poisson-geometry']"
7,"""The curvature of $\nabla=\mathrm d+\omega$ equals $\mathrm{d}\omega+\omega\wedge\omega$""","""The curvature of  equals """,\nabla=\mathrm d+\omega \mathrm{d}\omega+\omega\wedge\omega,"The following definition and lemma are from page $23$ of Heat Kernels and Dirac Operators . Definition : Let $E$ be a vector bundle with base space $M$ . The curvature $F$ of a covariant derivative $\nabla$ is defined by $$F(X,Y)=[\nabla_X,\nabla_Y]-\nabla_{[X,Y]}$$ for all vector fields $X$ and $Y$ on $M$ . Lemma : If $E$ is a trivial bundle and $\nabla = \mathrm d + \omega$ , then $F$ is given by the formula $$F=\mathrm{d}\omega+\omega\wedge\omega.$$ My problem is that I don't even know how $\mathrm d\omega$ and $\omega\wedge\omega$ are defined in this context. Since $$(\mathrm d\alpha)(X,Y)=\mathrm{d}_X\iota_Y\alpha-\mathrm{d}_Y\iota_X\alpha-\iota_{[X,Y]}\alpha$$ and $$(\alpha\wedge\alpha)(X,Y)=[\iota_X\alpha,\iota_Y\alpha]$$ for a $1$ -form $\alpha$ (see e.g. equation $(1.3)$ and definition $1.6$ in the book), my guess would be that $$(\mathrm d\omega)(X,Y)=\mathrm d_X\iota_Y\omega-\mathrm d_Y\iota_X\omega-\iota_{[X,Y]}\omega$$ and $$(\omega\wedge\omega)(X,Y)=[\iota_X\omega,\iota_Y\omega].$$ Actually this seems to yield the correct result. $^1$ Nevertheless I would like to get a confirmation, preferably an answer drawing from credible and/or official sources. $^1$ To simplify the notation, set $\omega_X:=\iota_X\omega$ . \begin{align} &F(X,Y)\Phi=\nabla_X\nabla_Y\Phi-\nabla_Y\nabla_X\Phi-\nabla_{[X,Y]}\Phi&\\ &=\underbrace{(\mathrm{d}_X\mathrm{d}_Y-\mathrm{d}_Y\mathrm{d}_X)\Phi}_{=\mathrm{d}_{[X,Y]}\Phi}+\underbrace{\mathrm{d}_X(\omega_Y\Phi)-\omega_Y\mathrm{d}_X\Phi}_{=(\mathrm d_X\omega_Y)\Phi}+\underbrace{\omega_X\mathrm{d}_Y\Phi-\mathrm{d}_Y(\omega_X\Phi)}_{=-(\mathrm d_Y\omega_X)\Phi}&\\ &\phantom{={}}-\mathrm{d}_{[X,Y]}\Phi+[\omega_X,\omega_Y]\Phi-\omega_{[X,Y]}\Phi&\\ &=\underbrace{(\mathrm d_X\omega_Y-\mathrm d_Y\omega_X-\omega_{[X,Y]})}_{=(\mathrm{d}\omega)(X,Y)}\Phi+\underbrace{(\omega_X\omega_Y-\omega_Y\omega_X)}_{=(\omega\wedge\omega)(X,Y)}\Phi&\\ &=(\mathrm{d}\omega+\omega\wedge\omega)(X,Y)\Phi& \end{align}","The following definition and lemma are from page of Heat Kernels and Dirac Operators . Definition : Let be a vector bundle with base space . The curvature of a covariant derivative is defined by for all vector fields and on . Lemma : If is a trivial bundle and , then is given by the formula My problem is that I don't even know how and are defined in this context. Since and for a -form (see e.g. equation and definition in the book), my guess would be that and Actually this seems to yield the correct result. Nevertheless I would like to get a confirmation, preferably an answer drawing from credible and/or official sources. To simplify the notation, set .","23 E M F \nabla F(X,Y)=[\nabla_X,\nabla_Y]-\nabla_{[X,Y]} X Y M E \nabla = \mathrm d + \omega F F=\mathrm{d}\omega+\omega\wedge\omega. \mathrm d\omega \omega\wedge\omega (\mathrm d\alpha)(X,Y)=\mathrm{d}_X\iota_Y\alpha-\mathrm{d}_Y\iota_X\alpha-\iota_{[X,Y]}\alpha (\alpha\wedge\alpha)(X,Y)=[\iota_X\alpha,\iota_Y\alpha] 1 \alpha (1.3) 1.6 (\mathrm d\omega)(X,Y)=\mathrm d_X\iota_Y\omega-\mathrm d_Y\iota_X\omega-\iota_{[X,Y]}\omega (\omega\wedge\omega)(X,Y)=[\iota_X\omega,\iota_Y\omega]. ^1 ^1 \omega_X:=\iota_X\omega \begin{align}
&F(X,Y)\Phi=\nabla_X\nabla_Y\Phi-\nabla_Y\nabla_X\Phi-\nabla_{[X,Y]}\Phi&\\
&=\underbrace{(\mathrm{d}_X\mathrm{d}_Y-\mathrm{d}_Y\mathrm{d}_X)\Phi}_{=\mathrm{d}_{[X,Y]}\Phi}+\underbrace{\mathrm{d}_X(\omega_Y\Phi)-\omega_Y\mathrm{d}_X\Phi}_{=(\mathrm d_X\omega_Y)\Phi}+\underbrace{\omega_X\mathrm{d}_Y\Phi-\mathrm{d}_Y(\omega_X\Phi)}_{=-(\mathrm d_Y\omega_X)\Phi}&\\
&\phantom{={}}-\mathrm{d}_{[X,Y]}\Phi+[\omega_X,\omega_Y]\Phi-\omega_{[X,Y]}\Phi&\\
&=\underbrace{(\mathrm d_X\omega_Y-\mathrm d_Y\omega_X-\omega_{[X,Y]})}_{=(\mathrm{d}\omega)(X,Y)}\Phi+\underbrace{(\omega_X\omega_Y-\omega_Y\omega_X)}_{=(\omega\wedge\omega)(X,Y)}\Phi&\\
&=(\mathrm{d}\omega+\omega\wedge\omega)(X,Y)\Phi&
\end{align}","['differential-geometry', 'vector-bundles', 'connections']"
8,Geometric interpretation of the isomorphism $\mathcal{N}_{Y/X} \cong \mathcal{O}_X(Y) \vert_Y$,Geometric interpretation of the isomorphism,\mathcal{N}_{Y/X} \cong \mathcal{O}_X(Y) \vert_Y,"Let $X$ be a smooth variety / manifold over $\mathbb{C}$ of dimension $n$ and suppose that $Y \subset X$ is a smooth $n-1$ -dimensional subvariety. The normal bundle $\mathcal{N}_{Y/X}$ comes from exact sequence $$  0 \to \mathcal{T}_Y \to  \mathcal{T}_X \vert_{Y} \to  \mathcal{N}_{Y/X} \to 0 $$ and it is known that as sheaf $\mathcal{N}_{Y/X}$ is isomorphic to the restriction of the invertible sheaf $\mathcal{O}_X(Y)$ to $Y$ . That's more or less a consequence of identification of the conormal bundle $\mathcal{N}_{Y/X}^*$ with the locally free sheaf $\mathcal{I}_{Y/X}/\mathcal{I}_{Y/X}^2 = \mathcal{I}_{Y/X} \otimes \mathcal{O}_Y$ where $\mathcal{I}_{Y/X}$ is the ideal sheaf of $Y$ . For a proof, see e.g. 1.4.2 in the book 3264 and All That by Eisenbud & Harris. Even though the proof is formally clear I'm missing the clear geometric picture of the isomorphism $\mathcal{N}_{Y/X} \cong \mathcal{O}_X(Y) \vert_Y$ and how to think about it as map of vecor bundles. Does this isomorphism have a concrete geometric interpreteation or does it exist only on abstract level? Is it possible to write down an explicit isomorphism $\mathcal{N}_{Y/X} \to \mathcal{O}_X(Y) \vert_Y$ in terms of classical bundle map if we use the correspondence priciple and treat locally free sheaves as vector bundles? The latter means that we can associate to the free sheaf $\mathcal{O}_X^n $ the trivial bundle $X \times \mathbb{C}^n$ and to the local sections $\mathcal{O}_X^n(U) $ to sections $U \to X \times \mathbb{C}^n$ which correspond to polynomial maps $U \to  \mathbb{C}^n$ . Here a guess: we can find a global section $s: X \to \mathcal{O}_X(Y)$ such that at every local trivialisation $U \subset X$ with $\mathcal{O}_X(Y) \vert _U= U \times \mathbb{C}$ the restricted section $s \vert_U $ equals $u \mapsto (u, \tilde{s}(u))$ with $\tilde{s}(u)=0$ iff $u \in U \cap Y$ . The tangent bundle $\mathcal{T}_X $ restricted to $U$ can be identified with $ U \times (\bigoplus_{i=1}^n \mathbb{C} \cdot \frac{\partial}{\partial t_i})$ . Then it looks reasonable to try to define it locally at $U \cap Y$ as the map $$\mathcal{T}_X \vert _{U \cap Y} \to (U \cap Y) \times \mathbb{C}, \ \ \frac{\partial}{\partial t_i} \mapsto ds(\frac{\partial}{\partial t_i})$$ where $ds$ is differential of $s: U \to \mathbb{C}$ and $\frac{\partial}{\partial t_i} \in \mathcal{T}_X \vert _{U \cap Y} = (U \cap Y) \times (\bigoplus_{i=1}^n \mathbb{C} \cdot \frac{\partial}{\partial t_i})$ . By the choice of $s$ the kernel of this map is exactly $ \mathcal{T}_Y \vert _U= \mathcal{T}_{Y \cap U}$ . Does this local map glue to global map $\mathcal{T}_X \vert _{Y} \to \mathcal{O}_X(Y) \vert _Y$ ? Also, is this the most natural way to ""capture the geometric picture"" behind the isomorphism $\mathcal{N}_{Y/X} \cong \mathcal{O}_X(Y) \vert_Y$ or is there a more ""natural"" way to think about it?","Let be a smooth variety / manifold over of dimension and suppose that is a smooth -dimensional subvariety. The normal bundle comes from exact sequence and it is known that as sheaf is isomorphic to the restriction of the invertible sheaf to . That's more or less a consequence of identification of the conormal bundle with the locally free sheaf where is the ideal sheaf of . For a proof, see e.g. 1.4.2 in the book 3264 and All That by Eisenbud & Harris. Even though the proof is formally clear I'm missing the clear geometric picture of the isomorphism and how to think about it as map of vecor bundles. Does this isomorphism have a concrete geometric interpreteation or does it exist only on abstract level? Is it possible to write down an explicit isomorphism in terms of classical bundle map if we use the correspondence priciple and treat locally free sheaves as vector bundles? The latter means that we can associate to the free sheaf the trivial bundle and to the local sections to sections which correspond to polynomial maps . Here a guess: we can find a global section such that at every local trivialisation with the restricted section equals with iff . The tangent bundle restricted to can be identified with . Then it looks reasonable to try to define it locally at as the map where is differential of and . By the choice of the kernel of this map is exactly . Does this local map glue to global map ? Also, is this the most natural way to ""capture the geometric picture"" behind the isomorphism or is there a more ""natural"" way to think about it?","X \mathbb{C} n Y \subset X n-1 \mathcal{N}_{Y/X}   0 \to \mathcal{T}_Y \to  \mathcal{T}_X \vert_{Y} \to  \mathcal{N}_{Y/X} \to 0  \mathcal{N}_{Y/X} \mathcal{O}_X(Y) Y \mathcal{N}_{Y/X}^* \mathcal{I}_{Y/X}/\mathcal{I}_{Y/X}^2 = \mathcal{I}_{Y/X} \otimes \mathcal{O}_Y \mathcal{I}_{Y/X} Y \mathcal{N}_{Y/X} \cong \mathcal{O}_X(Y) \vert_Y \mathcal{N}_{Y/X} \to \mathcal{O}_X(Y) \vert_Y \mathcal{O}_X^n  X \times \mathbb{C}^n \mathcal{O}_X^n(U)  U \to X \times \mathbb{C}^n U \to  \mathbb{C}^n s: X \to \mathcal{O}_X(Y) U \subset X \mathcal{O}_X(Y) \vert _U= U \times \mathbb{C} s \vert_U  u \mapsto (u, \tilde{s}(u)) \tilde{s}(u)=0 u \in U \cap Y \mathcal{T}_X  U  U \times (\bigoplus_{i=1}^n \mathbb{C} \cdot \frac{\partial}{\partial t_i}) U \cap Y \mathcal{T}_X \vert _{U \cap Y} \to (U \cap Y) \times \mathbb{C}, \ \
\frac{\partial}{\partial t_i} \mapsto ds(\frac{\partial}{\partial t_i}) ds s: U \to \mathbb{C} \frac{\partial}{\partial t_i} \in \mathcal{T}_X \vert _{U \cap Y} = (U \cap Y) \times (\bigoplus_{i=1}^n \mathbb{C} \cdot \frac{\partial}{\partial t_i}) s  \mathcal{T}_Y \vert _U= \mathcal{T}_{Y \cap U} \mathcal{T}_X \vert _{Y} \to \mathcal{O}_X(Y) \vert _Y \mathcal{N}_{Y/X} \cong \mathcal{O}_X(Y) \vert_Y","['differential-geometry', 'algebraic-geometry', 'vector-bundles', 'line-bundles']"
9,Trivial tangent bundle not diffeomorphic to 2n-dimensional open set,Trivial tangent bundle not diffeomorphic to 2n-dimensional open set,,"I was trying to find an explicit example of a trivial tangent bundle, i.e. $TM = M\times \mathbb{R}^n$ , with $M$ a smooth manifold without boundary of dimension $n\in\mathbb{N}$ , which is not diffeomorphic to any open subset $U\subseteq\mathbb{R}^{2n}$ . It seems, but maybe I'm wrong, that all the easy classical example of trivial tangent bundle are actually diffeomorphic to some open $2n$ -dimensional set. For instance, take the circle $S^1$ , its tangent bundle is a cylinder $S^1\times\mathbb{R}$ . We can parametrize it as $$ \\\{ (x,y,z)\in\mathbb{R}^3 , x^2+y^2=1 \}, $$ and by dilating/schrinking it a bit and projecting it on the $z=0$ plane we obtain that it is diffeomorphic to an open annulus: take $$ C = \{ (x,y,z), \; x^2+y^2 = \frac{2}{\pi}\arctan z + 2 \} $$ The projection of $C$ on the plane $z=0$ is one-to-one and its image is the open annulus $A=\{ 1 < x^2+y^2 < 3 \}$ . The 2D-torus doesn't work either, because it's diffeomorphic to $S^1\times S^1$ and adapting the previous argument one obtain again that the tangent bundle is diffeomorphic to an open set of $\mathbb{R}^4$ . I have also considered some examples of Lie groups, for instance $SL(2,\mathbb{R})$ , but also this fails since it can be seen as $S^1\times\mathbb{R}^2$ and again one can apply the same argument. Does anyone know a nice example? EDIT: I'd rather appreciate a solution that takes into account the case of $M$ a non-compact manifold (even though I don't know if it changes anything).","I was trying to find an explicit example of a trivial tangent bundle, i.e. , with a smooth manifold without boundary of dimension , which is not diffeomorphic to any open subset . It seems, but maybe I'm wrong, that all the easy classical example of trivial tangent bundle are actually diffeomorphic to some open -dimensional set. For instance, take the circle , its tangent bundle is a cylinder . We can parametrize it as and by dilating/schrinking it a bit and projecting it on the plane we obtain that it is diffeomorphic to an open annulus: take The projection of on the plane is one-to-one and its image is the open annulus . The 2D-torus doesn't work either, because it's diffeomorphic to and adapting the previous argument one obtain again that the tangent bundle is diffeomorphic to an open set of . I have also considered some examples of Lie groups, for instance , but also this fails since it can be seen as and again one can apply the same argument. Does anyone know a nice example? EDIT: I'd rather appreciate a solution that takes into account the case of a non-compact manifold (even though I don't know if it changes anything).","TM = M\times \mathbb{R}^n M n\in\mathbb{N} U\subseteq\mathbb{R}^{2n} 2n S^1 S^1\times\mathbb{R} 
\\\{
(x,y,z)\in\mathbb{R}^3
,
x^2+y^2=1
\},
 z=0 
C
=
\{
(x,y,z),
\;
x^2+y^2
=
\frac{2}{\pi}\arctan z + 2
\}
 C z=0 A=\{ 1 < x^2+y^2 < 3 \} S^1\times S^1 \mathbb{R}^4 SL(2,\mathbb{R}) S^1\times\mathbb{R}^2 M","['differential-geometry', 'lie-groups', 'smooth-manifolds', 'diffeomorphism', 'tangent-bundle']"
10,Curvature on an Associated Vector Bundle,Curvature on an Associated Vector Bundle,,"I am in the midst of trying to solve problem 13 from chapter 5 of Hamilton's Mathematical Gauge theory text, and have come across some terms I am not sure what to do with. I will elaborate below. Let $P\rightarrow M$ be a principal $G$ bundle, and $E=P\times_\rho V\rightarrow M$ an associated vector bundle. Fix a connection $A$ on a $P$ , the induces the following covariant derivative on $E$ , letting $\Phi$ be a local section of $E$ : $$\nabla^A_X\Phi=[s,d\phi(X_x)+\rho_*(A_s(X_x))\phi]$$ where $s$ is a local section of $P$ , $\phi$ is a map $U\subset M\rightarrow V$ , $X\in \mathfrak{X}(M)$ , and where $A_s=s^*A$ , can be thought of as a Lie algebra valued one form on the base $M$ . In a principal bundle we define curvature as: $$F=dA+\frac{1}{2}[A,A]$$ The curvature of a covariant derivative in an arbitrary vector bundle is: $$F^\nabla(X,Y)\Phi=\nabla_X\nabla_Y\Phi-\nabla_Y\nabla_X\Phi-\nabla_{[X,Y]}\Phi$$ I am trying to show that in an associated vector bundle: $$F^\nabla(X,Y)\Phi=[s,\rho_*(F_s(X,Y))\phi]$$ where $F_s=s^*F$ . So I calculated the following: $$\nabla^A_X\nabla^A_Y\Phi=[s,d\left(\rho_*(A_s(X_x)\right)(Y_x)\phi+\rho_*(A_s(X_x))d\phi(Y_x)+\rho_*(A_s(X_x))d\phi(Y_x)+\rho_*(A_s(X_x)A_s(Y_x))]$$ $$\nabla^A_X\nabla^A_Y\Phi=[s,d\left(\rho_*(A_s(Y_x)\right)(X_x)\phi+\rho_*(A_s(Y_x))d\phi(X_x)+\rho_*(A_s(Y_x))d\phi(X_x)+\rho_*(A_s(Y_x)A_s(X_x))]$$ $$\nabla^A_{[X,Y]}\Phi=[s,d\phi([X,Y]_x)+\rho_*(A_s([X,Y]_x)\phi]$$ Putting it all together I obtain that: $$F^\nabla(X,Y)\Phi=[s,d\left(\rho_*(A_s(Y_x)\right)(X_x)\phi-d\left(\rho_*(A_s(X_x)\right)(Y_x)\phi+\rho_*(A_s(X_x)A_s(Y_x)-A_s(Y_x)A_s(X_x))\phi-d\phi([X,Y]_x)-\rho_*(A_s([X,Y]_x)\phi]$$ I feel like I see all the pieces, but am unsure of how to move them around. Like the third term I'm pretty sure simplifies to $\frac{1}{2}[A_s,A_s](X_x,Y_x)$ , but I don't know what to do with the exterior derivative of $\rho_*$ , or what to do with the Lie bracket terms, especially since it seems like I have all the pieces without those terms, so I feel like they should cancel out some how but that doesn't make a ton of sense to me. Any help would be greatly appreciated. Edit: I suspect I'm messing up something up with the exterior derivative, perhaps $d(d\phi(X_x)(Y_x)$ isn't zero? Because you technically contract then apply the exterior derivative again? I am unsure...","I am in the midst of trying to solve problem 13 from chapter 5 of Hamilton's Mathematical Gauge theory text, and have come across some terms I am not sure what to do with. I will elaborate below. Let be a principal bundle, and an associated vector bundle. Fix a connection on a , the induces the following covariant derivative on , letting be a local section of : where is a local section of , is a map , , and where , can be thought of as a Lie algebra valued one form on the base . In a principal bundle we define curvature as: The curvature of a covariant derivative in an arbitrary vector bundle is: I am trying to show that in an associated vector bundle: where . So I calculated the following: Putting it all together I obtain that: I feel like I see all the pieces, but am unsure of how to move them around. Like the third term I'm pretty sure simplifies to , but I don't know what to do with the exterior derivative of , or what to do with the Lie bracket terms, especially since it seems like I have all the pieces without those terms, so I feel like they should cancel out some how but that doesn't make a ton of sense to me. Any help would be greatly appreciated. Edit: I suspect I'm messing up something up with the exterior derivative, perhaps isn't zero? Because you technically contract then apply the exterior derivative again? I am unsure...","P\rightarrow M G E=P\times_\rho V\rightarrow M A P E \Phi E \nabla^A_X\Phi=[s,d\phi(X_x)+\rho_*(A_s(X_x))\phi] s P \phi U\subset M\rightarrow V X\in \mathfrak{X}(M) A_s=s^*A M F=dA+\frac{1}{2}[A,A] F^\nabla(X,Y)\Phi=\nabla_X\nabla_Y\Phi-\nabla_Y\nabla_X\Phi-\nabla_{[X,Y]}\Phi F^\nabla(X,Y)\Phi=[s,\rho_*(F_s(X,Y))\phi] F_s=s^*F \nabla^A_X\nabla^A_Y\Phi=[s,d\left(\rho_*(A_s(X_x)\right)(Y_x)\phi+\rho_*(A_s(X_x))d\phi(Y_x)+\rho_*(A_s(X_x))d\phi(Y_x)+\rho_*(A_s(X_x)A_s(Y_x))] \nabla^A_X\nabla^A_Y\Phi=[s,d\left(\rho_*(A_s(Y_x)\right)(X_x)\phi+\rho_*(A_s(Y_x))d\phi(X_x)+\rho_*(A_s(Y_x))d\phi(X_x)+\rho_*(A_s(Y_x)A_s(X_x))] \nabla^A_{[X,Y]}\Phi=[s,d\phi([X,Y]_x)+\rho_*(A_s([X,Y]_x)\phi] F^\nabla(X,Y)\Phi=[s,d\left(\rho_*(A_s(Y_x)\right)(X_x)\phi-d\left(\rho_*(A_s(X_x)\right)(Y_x)\phi+\rho_*(A_s(X_x)A_s(Y_x)-A_s(Y_x)A_s(X_x))\phi-d\phi([X,Y]_x)-\rho_*(A_s([X,Y]_x)\phi] \frac{1}{2}[A_s,A_s](X_x,Y_x) \rho_* d(d\phi(X_x)(Y_x)","['differential-geometry', 'differential-topology', 'curvature', 'principal-bundles', 'gauge-theory']"
11,"Is there a ""universal connection"" on the universal $G$-bundle?","Is there a ""universal connection"" on the universal -bundle?",G,"Let $G$ a Lie group, $X$ a smooth manifold. Let $EG \rightarrow BG$ be the (topological) universal $G$ -bundle. We know for every (topological) principal $G$ -bundle $P \rightarrow X$ there is a (continuous) classifying map $f_P : X \rightarrow BG$ such that $P \approx f_P^*EG$ . I was wondering if there exists a (perhaps infinite-dimensional) smooth structure on $EG \rightarrow BG$ , and a principal $G$ -connection $\omega$ on $EG$ , such that every smooth principal $G$ -bundle on $X$ equipped with connection is a pullback of $EG \rightarrow BG$ equipped with $\omega$ , along some smooth map $X\rightarrow BG$ ?","Let a Lie group, a smooth manifold. Let be the (topological) universal -bundle. We know for every (topological) principal -bundle there is a (continuous) classifying map such that . I was wondering if there exists a (perhaps infinite-dimensional) smooth structure on , and a principal -connection on , such that every smooth principal -bundle on equipped with connection is a pullback of equipped with , along some smooth map ?",G X EG \rightarrow BG G G P \rightarrow X f_P : X \rightarrow BG P \approx f_P^*EG EG \rightarrow BG G \omega EG G X EG \rightarrow BG \omega X\rightarrow BG,"['differential-geometry', 'algebraic-topology', 'connections', 'principal-bundles', 'classifying-spaces']"
12,Good applied differential geometry books,Good applied differential geometry books,,"I'm searching a book which goes about how Differential Geometry can be applied to solve Real world problems. I tried William L Burke's book, but I found it to be all over the place. The information, at least in the first chapter, seemed to have no continuity. A book that I liked is Tristan Needham's Visual Differential Geometry, and while it only goes indirectly over the matter, I liked Penrose's Road to reality as well.","I'm searching a book which goes about how Differential Geometry can be applied to solve Real world problems. I tried William L Burke's book, but I found it to be all over the place. The information, at least in the first chapter, seemed to have no continuity. A book that I liked is Tristan Needham's Visual Differential Geometry, and while it only goes indirectly over the matter, I liked Penrose's Road to reality as well.",,"['differential-geometry', 'reference-request']"
13,Change of two normal coordinates based on two nearby points?,Change of two normal coordinates based on two nearby points?,,"Let $M$ be a manifold and $L(M)$ be the tangent frame bundle on $M$ . Let $\Gamma$ be a linear connection on $L(M)$ which induces a covariant derivative $\nabla$ on $TM$ . Let $p, q$ be two distinguished and sufficiently close points on $M$ , connected by a smooth curve $\gamma = \{\gamma_t\}_{t\in[0,\epsilon]}$ so that $\gamma(0)=p$ , $\gamma(\epsilon)=q$ . Suppose that there is an open set $U\subset M$ , such that $U$ contains $\gamma$ and is a normal neighborhood of both $p$ and $q$ . Fix a linear frame $u_p \in L_p(M): \mathbf R^d\to T_pM$ . Let $u_q = \Gamma(\gamma)_0^\epsilon (u_p) \in L_q(M)$ be the parallel displacement of $u_p$ along $\gamma$ , that is, $u_q$ can be joined to $u_p$ by a horizontal curve on $L(M)$ along $\gamma$ . Then we have two normal coordinate systems on $U$ : $$x=u_p^{-1}\circ \exp_p^{-1}: U \to \mathbf R^d,$$ $$y=u_q^{-1}\circ \exp_q^{-1}: U \to \mathbf R^d,$$ so that $(U,(x^i))$ and $(U,(y^j))$ are coordinate charts based on $p$ and $q$ respectively. Now my question is: how to do change of coordinates between these two normal coordinate charts? More precisely, let $m \in U$ , then what is the relation between $x(m)$ and $y(m)$ ? If necessary, you can endow more structures to $M$ . Say, $M$ is equipped with a Riemannian metric $g$ and $\nabla$ is the Levi-Civita connection , the frame bundle $L(M)$ is replaced by the orthonormal frame bundle $O(M)$ ... Some thinking: Clearly, $x(p) = y(q) = 0$ . If $\gamma$ is a geodesic , then it is easy to check $x(q) = -y(p)$ . Denote $\rho = x(q) \in\mathbf R^d$ . Then I believe that $x(m) = y(m) + \rho$ for all $m \in U$ . If $\gamma$ is not a geodesic , then I think that a curvature term should appear, since we may use the holonomy . But I do not know how to prove my conjectures... EDIT: I think there maybe no exact expressions for $x(m)$ and $y(m)$ , but there should be an asymptotic expression with infinitesimals $o(\epsilon)$ or $o(d(x,y))$ ...","Let be a manifold and be the tangent frame bundle on . Let be a linear connection on which induces a covariant derivative on . Let be two distinguished and sufficiently close points on , connected by a smooth curve so that , . Suppose that there is an open set , such that contains and is a normal neighborhood of both and . Fix a linear frame . Let be the parallel displacement of along , that is, can be joined to by a horizontal curve on along . Then we have two normal coordinate systems on : so that and are coordinate charts based on and respectively. Now my question is: how to do change of coordinates between these two normal coordinate charts? More precisely, let , then what is the relation between and ? If necessary, you can endow more structures to . Say, is equipped with a Riemannian metric and is the Levi-Civita connection , the frame bundle is replaced by the orthonormal frame bundle ... Some thinking: Clearly, . If is a geodesic , then it is easy to check . Denote . Then I believe that for all . If is not a geodesic , then I think that a curvature term should appear, since we may use the holonomy . But I do not know how to prove my conjectures... EDIT: I think there maybe no exact expressions for and , but there should be an asymptotic expression with infinitesimals or ...","M L(M) M \Gamma L(M) \nabla TM p, q M \gamma = \{\gamma_t\}_{t\in[0,\epsilon]} \gamma(0)=p \gamma(\epsilon)=q U\subset M U \gamma p q u_p \in L_p(M): \mathbf R^d\to T_pM u_q = \Gamma(\gamma)_0^\epsilon (u_p) \in L_q(M) u_p \gamma u_q u_p L(M) \gamma U x=u_p^{-1}\circ \exp_p^{-1}: U \to \mathbf R^d, y=u_q^{-1}\circ \exp_q^{-1}: U \to \mathbf R^d, (U,(x^i)) (U,(y^j)) p q m \in U x(m) y(m) M M g \nabla L(M) O(M) x(p) = y(q) = 0 \gamma x(q) = -y(p) \rho = x(q) \in\mathbf R^d x(m) = y(m) + \rho m \in U \gamma x(m) y(m) o(\epsilon) o(d(x,y))","['differential-geometry', 'riemannian-geometry', 'connections', 'principal-bundles', 'tangent-bundle']"
14,The metric $g=dx^2+\cosh^2(x)dy^2$ is complete,The metric  is complete,g=dx^2+\cosh^2(x)dy^2,"I want prove that the metric $g=dx^2+\cosh^2(x)dy^2$ is complete with constant curvature $-1$ on $\mathbb{R}^2$ , for that I considered the following function (suggested in an article) $f:(\mathbb{R}^2,g)\to (\mathbb{R}^2,g_{-1})$ , where $g_1=dx^2+e^{2x}dy^2$ , defined by $$f(x,y)=(-y+\ln(\cosh x),e^y\tanh x).$$ I gotten to show that this is a diffeomorphism with inverse $$f^{-1}(x,y)=\Big(\sinh^{-1}(ye^x),\ln(\sqrt{e^{-2x}+y^2})\Big),$$ I need to know explicitly how the mentioned function $f$ preserves the metric. This is the Danilo Blanusa's article: Über die Einbettung hyperbolischer Räume in euklidische Räume I'm trying to read in detail this article about the immersion of $\mathbb{H}^2$ in $\mathbb{R}^6$ in which I found this metric, I have not been able to find the other article where it mentions the function mentioned.","I want prove that the metric is complete with constant curvature on , for that I considered the following function (suggested in an article) , where , defined by I gotten to show that this is a diffeomorphism with inverse I need to know explicitly how the mentioned function preserves the metric. This is the Danilo Blanusa's article: Über die Einbettung hyperbolischer Räume in euklidische Räume I'm trying to read in detail this article about the immersion of in in which I found this metric, I have not been able to find the other article where it mentions the function mentioned.","g=dx^2+\cosh^2(x)dy^2 -1 \mathbb{R}^2 f:(\mathbb{R}^2,g)\to (\mathbb{R}^2,g_{-1}) g_1=dx^2+e^{2x}dy^2 f(x,y)=(-y+\ln(\cosh x),e^y\tanh x). f^{-1}(x,y)=\Big(\sinh^{-1}(ye^x),\ln(\sqrt{e^{-2x}+y^2})\Big), f \mathbb{H}^2 \mathbb{R}^6","['differential-geometry', 'riemannian-geometry', 'riemann-surfaces', 'hyperbolic-geometry']"
15,Change in function's chord length depends on $|s-t|$,Change in function's chord length depends on,|s-t|,"I am stuck on this question and any help would go a long way. Show that if $\alpha : [a, b] \rightarrow \mathbb{R}$ is a regular smooth curve and $||α(s) − α(t)||$ depends only on $|s − t|$ , then $\alpha$ must be a subset of a circle or a line. I have shown that the speed of such a curve is constant, but I don't know where further to go. Also, the answer given here did not seem to help. Any help will be extremely appreciated. Thank you! EDIT As per the comment, I will elaborate on my answer and what I understood from the answer attached. I have understood that the speed of such a curve must be constant. With the speed being constant, and knowing the relation $\langle \alpha'(t)-\alpha'(s),\alpha(t)-\alpha(s)\rangle=0,$ which one can derive as the solution given does, we get that the angles formed by $\alpha'(t)$ and $\alpha'(s)$ with $\alpha(t)-\alpha(s)$ are equal. Now, the solution says that the directions of $\alpha'(t),\alpha'(s)$ are different... Why? Suppose this was true; then the solution says that one can see that the curve alpha must satisfy the equation $$r\frac{d\theta}{dr}=\tan \theta.$$ Why does this follow? Help with these doubts will be much appreciated. A different approach altogether also is be fantastic. Thank you.","I am stuck on this question and any help would go a long way. Show that if is a regular smooth curve and depends only on , then must be a subset of a circle or a line. I have shown that the speed of such a curve is constant, but I don't know where further to go. Also, the answer given here did not seem to help. Any help will be extremely appreciated. Thank you! EDIT As per the comment, I will elaborate on my answer and what I understood from the answer attached. I have understood that the speed of such a curve must be constant. With the speed being constant, and knowing the relation which one can derive as the solution given does, we get that the angles formed by and with are equal. Now, the solution says that the directions of are different... Why? Suppose this was true; then the solution says that one can see that the curve alpha must satisfy the equation Why does this follow? Help with these doubts will be much appreciated. A different approach altogether also is be fantastic. Thank you.","\alpha : [a, b] \rightarrow \mathbb{R} ||α(s) − α(t)|| |s − t| \alpha \langle \alpha'(t)-\alpha'(s),\alpha(t)-\alpha(s)\rangle=0, \alpha'(t) \alpha'(s) \alpha(t)-\alpha(s) \alpha'(t),\alpha'(s) r\frac{d\theta}{dr}=\tan \theta.",['differential-geometry']
16,Ricci flow as heat flow on Riemannian manifold,Ricci flow as heat flow on Riemannian manifold,,"I read that Ricci flow is ""a nonlinear heat flow for the Riemannian metric"". Can someone explain what this means? Nonlinear heat flow has a wikipedia page but I don't understand how this differs from the traditional heat flow on Euclidean space. My guess is to replace the Laplacian with its version on a Riemannian manifold. This might also be related, but I recently learned that heat flow is locally a mean curvature flow. I'm not sure what the relationship between MCF and Ricci flow is, but this seems like a piece of the puzzle.","I read that Ricci flow is ""a nonlinear heat flow for the Riemannian metric"". Can someone explain what this means? Nonlinear heat flow has a wikipedia page but I don't understand how this differs from the traditional heat flow on Euclidean space. My guess is to replace the Laplacian with its version on a Riemannian manifold. This might also be related, but I recently learned that heat flow is locally a mean curvature flow. I'm not sure what the relationship between MCF and Ricci flow is, but this seems like a piece of the puzzle.",,"['differential-geometry', 'riemannian-geometry', 'heat-equation', 'ricci-flow']"
17,Differential inequality regarding volume comparison,Differential inequality regarding volume comparison,,"Let $(M,g)$ be a complete $n$ -dimensional Riemannian manifold and let $p \in M$ . Consider $(t,\Theta)$ , the geodesic spherical coordinates around $p$ , where $t \in (0,\text{conj}_p(\Theta))$ and $\Theta$ is a unit vector in $T_pM$ . Let $A_p(t,\Theta)$ be the density of the volume measure in these coordinates, i.e. \begin{equation*}      d\operatorname{Vol} = A_p(t,\Theta) dt  d\Theta \end{equation*} A well-known theorem of Gromov states that if $\operatorname{Ric}(M) \geqslant (n-1)\kappa$ ,  then the map \begin{equation}     t \mapsto \frac{{A}_p(t,\Theta)}{sn^{n-1}_{\kappa}(t)} \end{equation} is non-increasing in $t$ . As usual, $sn_{\kappa}$ is given by \begin{align*}  sn_{\kappa}(t) = \begin{cases}  \frac{\sin{\sqrt{k}t}}{\sqrt{k}} & k > 0\\ t & k = 0\\ \frac{\sinh{\sqrt{-k}t}}{\sqrt{-k}} & k < 0 \end{cases} \end{align*} Now I would like to prove a similar result when the sectional curvature of $M$ is bounded from above. That is, if $ \text{sec}(M) \leqslant \kappa$ , then \begin{equation*}      \frac{d^2}{dt^2}\left(\frac{A_p(t,\Theta)}{sn^{n-2}_{\kappa}(t)}\right) + \kappa \left(\frac{A_p(t,\Theta)}{sn^{n-2}_{\kappa}(t)}\right) \geqslant 0 \end{equation*} I'm trying to mimic the argument given by Gromov, letting $\varphi(t) = A_p(t,\Theta)^{\frac{1}{n-2}}$ and calculate that $(\log \varphi(t))' = \frac{1}{n-2}\text{tr}(\text{II}(t))$ , where $\text{II}(t)$ is the second fundamental form of $\partial B(p,t)$ . But since we are not proving a statement about monotonicity, I don't know how I can get rid of the power $(n-2)$ . Differentiating such expression directly seems intimidating and tedious, and I believe there's a shortcut to the problem since it is very similar to the estimate of the norm of Jacobi fields. Any insight of the problem will be appreciated.","Let be a complete -dimensional Riemannian manifold and let . Consider , the geodesic spherical coordinates around , where and is a unit vector in . Let be the density of the volume measure in these coordinates, i.e. A well-known theorem of Gromov states that if ,  then the map is non-increasing in . As usual, is given by Now I would like to prove a similar result when the sectional curvature of is bounded from above. That is, if , then I'm trying to mimic the argument given by Gromov, letting and calculate that , where is the second fundamental form of . But since we are not proving a statement about monotonicity, I don't know how I can get rid of the power . Differentiating such expression directly seems intimidating and tedious, and I believe there's a shortcut to the problem since it is very similar to the estimate of the norm of Jacobi fields. Any insight of the problem will be appreciated.","(M,g) n p \in M (t,\Theta) p t \in (0,\text{conj}_p(\Theta)) \Theta T_pM A_p(t,\Theta) \begin{equation*}
     d\operatorname{Vol} = A_p(t,\Theta) dt  d\Theta
\end{equation*} \operatorname{Ric}(M) \geqslant (n-1)\kappa \begin{equation}
    t \mapsto \frac{{A}_p(t,\Theta)}{sn^{n-1}_{\kappa}(t)}
\end{equation} t sn_{\kappa} \begin{align*}
 sn_{\kappa}(t) = \begin{cases} 
\frac{\sin{\sqrt{k}t}}{\sqrt{k}} & k > 0\\
t & k = 0\\
\frac{\sinh{\sqrt{-k}t}}{\sqrt{-k}} & k < 0
\end{cases}
\end{align*} M  \text{sec}(M) \leqslant \kappa \begin{equation*}
     \frac{d^2}{dt^2}\left(\frac{A_p(t,\Theta)}{sn^{n-2}_{\kappa}(t)}\right) + \kappa \left(\frac{A_p(t,\Theta)}{sn^{n-2}_{\kappa}(t)}\right) \geqslant 0
\end{equation*} \varphi(t) = A_p(t,\Theta)^{\frac{1}{n-2}} (\log \varphi(t))' = \frac{1}{n-2}\text{tr}(\text{II}(t)) \text{II}(t) \partial B(p,t) (n-2)","['differential-geometry', 'riemannian-geometry']"
18,Derivative of Gauss map is the second fundamental form,Derivative of Gauss map is the second fundamental form,,"I have been messing around with Grassmannians lately. Let $M^k\subseteq \Bbb R^n$ be an embedded submanifold equipped with the induced Riemannian metric, and consider the Gauss map $G\colon M \to {\rm Gr}_k(\Bbb R^n)$ given by $G(p) = T_pM$ , taking values in the Grassmannian of $k$ -planes of $\Bbb R^n$ . Then the derivative is a map ${\rm d}G_p\colon T_pM \to {\rm Hom}(T_pM, T_pM^\perp)$ , which by currying may be seen as a bilinear map ${\rm d}G_p\colon T_pM \times T_pM \to T_pM^\perp$ . The only reasonable guess is that ${\rm d}G_p$ is the second fundamental form ${\rm II}_p$ , but I'm not sure how to even start this. Can someone show me the calculation or give a reference? Thanks. Note: I can see that $${\rm d}G_p(v,w) = \frac{\partial \alpha}{\partial s}(0,0)$$ where $\alpha \colon (-\epsilon,\epsilon)^2 \to M$ is given by $\alpha(t,s) = \exp_{\gamma(t)}(sw(t))$ , where $t \mapsto \gamma(t)$ is any curve in $M$ with $\gamma(0) = p$ and $\gamma'(0) = v$ , while $t \mapsto w(t)$ is a curve of vectors such that $w(0) = w$ and $w(t) \in T_{\gamma(t)}M$ for all $t$ . But it is not clear to me how to make $\nabla$ and ${\rm D}$ appear here. Nevermind, it is trivial. We may assume that $t \mapsto w(t)$ is a parallel field along $\gamma$ , so $$w'(t) = \frac{{\rm D}w}{{\rm d}t}(t) + {\rm II}_{\gamma(t)}(\gamma'(t),w(t))\implies w'(0) = {\rm II}_p(v,w)$$ as wanted. I'll leave this open in case someone realizes I'm royally screwing the pooch here...","I have been messing around with Grassmannians lately. Let be an embedded submanifold equipped with the induced Riemannian metric, and consider the Gauss map given by , taking values in the Grassmannian of -planes of . Then the derivative is a map , which by currying may be seen as a bilinear map . The only reasonable guess is that is the second fundamental form , but I'm not sure how to even start this. Can someone show me the calculation or give a reference? Thanks. Note: I can see that where is given by , where is any curve in with and , while is a curve of vectors such that and for all . But it is not clear to me how to make and appear here. Nevermind, it is trivial. We may assume that is a parallel field along , so as wanted. I'll leave this open in case someone realizes I'm royally screwing the pooch here...","M^k\subseteq \Bbb R^n G\colon M \to {\rm Gr}_k(\Bbb R^n) G(p) = T_pM k \Bbb R^n {\rm d}G_p\colon T_pM \to {\rm Hom}(T_pM, T_pM^\perp) {\rm d}G_p\colon T_pM \times T_pM \to T_pM^\perp {\rm d}G_p {\rm II}_p {\rm d}G_p(v,w) = \frac{\partial \alpha}{\partial s}(0,0) \alpha \colon (-\epsilon,\epsilon)^2 \to M \alpha(t,s) = \exp_{\gamma(t)}(sw(t)) t \mapsto \gamma(t) M \gamma(0) = p \gamma'(0) = v t \mapsto w(t) w(0) = w w(t) \in T_{\gamma(t)}M t \nabla {\rm D} t \mapsto w(t) \gamma w'(t) = \frac{{\rm D}w}{{\rm d}t}(t) + {\rm II}_{\gamma(t)}(\gamma'(t),w(t))\implies w'(0) = {\rm II}_p(v,w)","['differential-geometry', 'riemannian-geometry', 'grassmannian']"
19,Is There a Basis for a Smooth Vector Fields on the 2-Sphere?,Is There a Basis for a Smooth Vector Fields on the 2-Sphere?,,"I've been watching Frederic Schuller's course on ""The Mathematics and Physics of Gravity and Light"" and at a moment during Lecture 6 he claims there is no basis for $\Gamma(TS^2)$ (the space of smooth sections $\sigma \colon S^2 \to TS^2$ ) when considered as a $C^\infty(S^2)$ -module and gives an example through the claim that since every vector field must vanish somewhere, you can't get a basis. During his example, he uses a vector field which vanishes at points $(\pm 1, 0, 0)$ and $(0, 0, \pm 1)$ and says that since on, say, $(0, 0, \pm 1)$ you have only one nonvanishing vector field, and thus a linear combination can't point towards a different direction. My first question is: adding a new vector field which vanishes at $(0, \pm 1, 0)$ wouldn't solve the problem? At every point you have at least two non-parallel vectors, so it seems to me it would work, at least in principle. Furthermore, every vector space admits a basis, so $\Gamma(TM)$ (for some smooth manifold $M$ ) when considered as a real vector space has a basis. Since every real number can be regarded as a constant (and hence smooth) function, wouldn't it allow us to obtain a basis for $\Gamma(TM)$ when considered as a $C^\infty(M)$ -module? I believe it is worth mentioning I do not have much background in Differential Geometry nor Module Theory.","I've been watching Frederic Schuller's course on ""The Mathematics and Physics of Gravity and Light"" and at a moment during Lecture 6 he claims there is no basis for (the space of smooth sections ) when considered as a -module and gives an example through the claim that since every vector field must vanish somewhere, you can't get a basis. During his example, he uses a vector field which vanishes at points and and says that since on, say, you have only one nonvanishing vector field, and thus a linear combination can't point towards a different direction. My first question is: adding a new vector field which vanishes at wouldn't solve the problem? At every point you have at least two non-parallel vectors, so it seems to me it would work, at least in principle. Furthermore, every vector space admits a basis, so (for some smooth manifold ) when considered as a real vector space has a basis. Since every real number can be regarded as a constant (and hence smooth) function, wouldn't it allow us to obtain a basis for when considered as a -module? I believe it is worth mentioning I do not have much background in Differential Geometry nor Module Theory.","\Gamma(TS^2) \sigma \colon S^2 \to TS^2 C^\infty(S^2) (\pm 1, 0, 0) (0, 0, \pm 1) (0, 0, \pm 1) (0, \pm 1, 0) \Gamma(TM) M \Gamma(TM) C^\infty(M)","['differential-geometry', 'modules', 'vector-fields']"
20,Explicit description of tangent spaces of $O(n)$,Explicit description of tangent spaces of,O(n),"I would like someone to verify the calcuations that I'm making about the tangent spaces of $O(n)$ , and help answer some general questions that I have from this special case. I don't know much about Lie theory at all, so I'm flying by the seat of my pants here :) So, we have the space $O(n) \equiv \{ X | X^TX = I \}$ . It's not hard to show that the tangent space should satisfy the constraint: tangent space at $P \in O(n) \equiv T_P O(n) \equiv \{ Z | Z^T P + P^T Z = 0\}$ . Now, by performing the usual Lie algebra trick of ""calculate tangent space at identity"", we see that: $$ T_I O(n) = \{ Z | Z^T + Z = 0 \} $$ Next, to calculate the tangent space at some arbitrary point $P \in O(n)$ , we consider the map: $$ f: O(n) \rightarrow O(n) \qquad f(X) = PX $$ Note that $f(I) = P$ , and hence the differential of this map, $df$ will have the type $df: T_I O(n) \rightarrow T_P O(n)$ . Now, all that's left to do is to calculate the differential. To perform this, we take a curve: $$ c: (-\epsilon, \epsilon) \rightarrow O(n) \qquad c(t) = e^{Kt} \qquad K^T = -K $$ This has image in $O(n)$ , since $$ c(t)^T c(t) = e^{K^T t}e^{Kt} = e^{t(K^T + K)} = e^{t\cdot 0} = I $$ Hence, this is a valid curve. Now, we compute $df$ : $$ df \equiv \frac{d}{dt} (f \circ c)(t) \vert_{t = 0} = \frac{d}{dt} P  e^{Kt} \vert_{t=0} = PKe^{K0} = PK $$ Hence, the tangent space at the point $P$ is $T_PO(n) \equiv \{ PK | K^T + K = 0 \}$ I am uncomfortable with many things that ""automatically work"" in this proof: Is this proof correct? If not, where is it wrong? Why is the choice of the integral curve $c(t) = e^{Kt}$ the ""correct"" choice? How do I prove that the mapping of tangent spaces is indeed a bijection, and not some artefact of the curve parametrization I chose? What is the ""general form"" of this proof, for an arbitrary matrix Lie group $M$ ? Can I state that the tangent space at a point $P$ will be of the form $T_P M \equiv \{ PZ \mid Z \in T_I M \}$ ? If not, why is this not correct? Is there a slick proof of this fact?","I would like someone to verify the calcuations that I'm making about the tangent spaces of , and help answer some general questions that I have from this special case. I don't know much about Lie theory at all, so I'm flying by the seat of my pants here :) So, we have the space . It's not hard to show that the tangent space should satisfy the constraint: tangent space at . Now, by performing the usual Lie algebra trick of ""calculate tangent space at identity"", we see that: Next, to calculate the tangent space at some arbitrary point , we consider the map: Note that , and hence the differential of this map, will have the type . Now, all that's left to do is to calculate the differential. To perform this, we take a curve: This has image in , since Hence, this is a valid curve. Now, we compute : Hence, the tangent space at the point is I am uncomfortable with many things that ""automatically work"" in this proof: Is this proof correct? If not, where is it wrong? Why is the choice of the integral curve the ""correct"" choice? How do I prove that the mapping of tangent spaces is indeed a bijection, and not some artefact of the curve parametrization I chose? What is the ""general form"" of this proof, for an arbitrary matrix Lie group ? Can I state that the tangent space at a point will be of the form ? If not, why is this not correct? Is there a slick proof of this fact?","O(n) O(n) \equiv \{ X | X^TX = I \} P \in O(n) \equiv T_P O(n) \equiv \{ Z | Z^T P + P^T Z = 0\} 
T_I O(n) = \{ Z | Z^T + Z = 0 \}
 P \in O(n) 
f: O(n) \rightarrow O(n) \qquad f(X) = PX
 f(I) = P df df: T_I O(n) \rightarrow T_P O(n) 
c: (-\epsilon, \epsilon) \rightarrow O(n) \qquad
c(t) = e^{Kt} \qquad
K^T = -K
 O(n) 
c(t)^T c(t) = e^{K^T t}e^{Kt} = e^{t(K^T + K)} = e^{t\cdot 0} = I
 df 
df \equiv \frac{d}{dt} (f \circ c)(t) \vert_{t = 0} = \frac{d}{dt} P  e^{Kt} \vert_{t=0} = PKe^{K0} = PK
 P T_PO(n) \equiv \{ PK | K^T + K = 0 \} c(t) = e^{Kt} M P T_P M \equiv \{ PZ \mid Z \in T_I M \}","['differential-geometry', 'manifolds', 'lie-groups', 'lie-algebras', 'smooth-manifolds']"
21,Approximate embeddings of the hyperbolic plane in $\Bbb R^3$,Approximate embeddings of the hyperbolic plane in,\Bbb R^3,"It is known that there is no isometric embedding of the hyperbolic plane into $\Bbb R^3$ that is $C^2$ or higher. (The Nash-Kuiper theorem guarantees the existence of an exact $C^1$ embedding.) How does this situation change if we look at approximate embeddings, in which the embedded geodesic distance is always within some arbitrarily small $\epsilon$ of the true hyperbolic distance? Are $C^\infty$ approximate embeddings guaranteed to exist for any arbitrarily small $\epsilon$ ? If not, what is the smallest such $\epsilon$ , and how does this change if we look at $C^2$ instead? Formally, let's assume there is some map, call it $f$ , which maps from $\Bbb H^2$ to $\Bbb R^3$ , and that this mapping is suitably smooth (at least $C^2$ , preferably $C^\infty$ ). Let's say that $d(a,b)$ is the distance between any two points in the hyperbolic plane, and $d_f(a,b)$ is the geodesic distance on the embedded surface in $\Bbb R^3$ . Then an "" $\epsilon$ -approximate embedding"" is one in which $|d_f(a,b) - d(a,b)| < \epsilon$ , for all $a, b$ . Then the question is, what is the largest $n$ such that a $C^n$ approximate embedding of $\Bbb H^2 \to \Bbb R^3$ exists for all arbitrarily small $\epsilon$ ? And if such embeddings don't exist, are there any lower bounds on how small $\epsilon$ can be?","It is known that there is no isometric embedding of the hyperbolic plane into that is or higher. (The Nash-Kuiper theorem guarantees the existence of an exact embedding.) How does this situation change if we look at approximate embeddings, in which the embedded geodesic distance is always within some arbitrarily small of the true hyperbolic distance? Are approximate embeddings guaranteed to exist for any arbitrarily small ? If not, what is the smallest such , and how does this change if we look at instead? Formally, let's assume there is some map, call it , which maps from to , and that this mapping is suitably smooth (at least , preferably ). Let's say that is the distance between any two points in the hyperbolic plane, and is the geodesic distance on the embedded surface in . Then an "" -approximate embedding"" is one in which , for all . Then the question is, what is the largest such that a approximate embedding of exists for all arbitrarily small ? And if such embeddings don't exist, are there any lower bounds on how small can be?","\Bbb R^3 C^2 C^1 \epsilon C^\infty \epsilon \epsilon C^2 f \Bbb H^2 \Bbb R^3 C^2 C^\infty d(a,b) d_f(a,b) \Bbb R^3 \epsilon |d_f(a,b) - d(a,b)| < \epsilon a, b n C^n \Bbb H^2 \to \Bbb R^3 \epsilon \epsilon","['differential-geometry', 'approximation', 'hyperbolic-geometry', 'isometry']"
22,$F:M\to N$ is surjective if $\int_M F^* \eta \ne 0$ for some $\eta \in \Omega^n(N)$,is surjective if  for some,F:M\to N \int_M F^* \eta \ne 0 \eta \in \Omega^n(N),"Let $M$ and $N$ be compact orientable and connected smooth $n$ -manifolds and $F:M \to N$ a smooth map. Suppose $$\int_M F^* \eta \ne 0$$ for some $\eta \in \Omega^n(N)$ . Then $F$ is surjective. Give an example that shows the converse is not true. A non-surjective map has degree $0$ so the first part is clear. I could not think of an example for the converse, however. I want to find two compact oriented connected manifolds such that $F$ is surjective but $\int_M F^* \eta = 0$ for all $\eta \in \Omega^n(N)$ .","Let and be compact orientable and connected smooth -manifolds and a smooth map. Suppose for some . Then is surjective. Give an example that shows the converse is not true. A non-surjective map has degree so the first part is clear. I could not think of an example for the converse, however. I want to find two compact oriented connected manifolds such that is surjective but for all .",M N n F:M \to N \int_M F^* \eta \ne 0 \eta \in \Omega^n(N) F 0 F \int_M F^* \eta = 0 \eta \in \Omega^n(N),"['differential-geometry', 'smooth-manifolds', 'de-rham-cohomology']"
23,Equivalence between commuting (complete) vector fields and commuting flows,Equivalence between commuting (complete) vector fields and commuting flows,,"I am proving that for complete vector fields $X,Y$ on a manifold $M$ , $[X,Y]=0\iff\Phi_X^t\circ\Phi_Y^s=\Phi_Y^s\circ\Phi_X^t$ . I have proven the "" $\Leftarrow""$ implication, but for the $""\Rightarrow""$ , I need the following to hold. Namely $$ (\Phi_X^t)^*Y=Y $$ Could anyone help me with this please? I was thinking that \begin{align*} \frac{d}{dt}\bigg|_{t=t_0}(\Phi_X^t)^* Y &=\frac{d}{ds}\bigg|_{s=0} (\Phi_X^{t_0+s})^*Y\\ &=\frac{d}{ds}\bigg|_{s=0} (\Phi_X^{t_0}\circ\Phi_X^s)^*Y\\ &=(\Phi_X^{t_0})^*\frac{d}{ds}\bigg|_{s=0} (\Phi_X^s)^*Y\\ &=(\Phi_X^{t_0})^*\mathcal{L}_X(Y)=0. \end{align*} So for all $t_0\in\mathbb{R}$ , $$\frac{d}{dt}\bigg|_{t=t_0}(\Phi_X^t)^*Y=0\implies(\Phi_X^{t_0})^*Y=(\Phi_X^0)^*Y=Y.$$ Could anyone help to improve this reasoning, or is it fine like this? Thanks :)","I am proving that for complete vector fields on a manifold , . I have proven the "" implication, but for the , I need the following to hold. Namely Could anyone help me with this please? I was thinking that So for all , Could anyone help to improve this reasoning, or is it fine like this? Thanks :)","X,Y M [X,Y]=0\iff\Phi_X^t\circ\Phi_Y^s=\Phi_Y^s\circ\Phi_X^t \Leftarrow"" ""\Rightarrow"" 
(\Phi_X^t)^*Y=Y
 \begin{align*}
\frac{d}{dt}\bigg|_{t=t_0}(\Phi_X^t)^* Y &=\frac{d}{ds}\bigg|_{s=0}
(\Phi_X^{t_0+s})^*Y\\
&=\frac{d}{ds}\bigg|_{s=0}
(\Phi_X^{t_0}\circ\Phi_X^s)^*Y\\
&=(\Phi_X^{t_0})^*\frac{d}{ds}\bigg|_{s=0}
(\Phi_X^s)^*Y\\
&=(\Phi_X^{t_0})^*\mathcal{L}_X(Y)=0.
\end{align*} t_0\in\mathbb{R} \frac{d}{dt}\bigg|_{t=t_0}(\Phi_X^t)^*Y=0\implies(\Phi_X^{t_0})^*Y=(\Phi_X^0)^*Y=Y.",['differential-geometry']
24,A representation of $S^3$,A representation of,S^3,"I am intending to learn low dimensional topology from Saveliev's Book ""Lectures on the Topology of 3-manifolds"" by myself. At the very beginning, he gives a Heegaard splitting of $S^3$ stating that ""the sphere $S^3$ is represented as the result of revolving the 2-sphere $S^2=R^2\cup\{\infty\}$ about the circle $l\cup\{\infty\}$ where $l$ is a straight line in $R^2$."" I do not understand why the revolution of $S^2$ about $S^1$ results in $S^3$. Is it a fact that can be generalized to higher dimensions, i.e. does the revolution of $S^{n+1}$ about $S^{n}$ result in $S^{n+2}$?. Thanks for any help and suggestions.","I am intending to learn low dimensional topology from Saveliev's Book ""Lectures on the Topology of 3-manifolds"" by myself. At the very beginning, he gives a Heegaard splitting of $S^3$ stating that ""the sphere $S^3$ is represented as the result of revolving the 2-sphere $S^2=R^2\cup\{\infty\}$ about the circle $l\cup\{\infty\}$ where $l$ is a straight line in $R^2$."" I do not understand why the revolution of $S^2$ about $S^1$ results in $S^3$. Is it a fact that can be generalized to higher dimensions, i.e. does the revolution of $S^{n+1}$ about $S^{n}$ result in $S^{n+2}$?. Thanks for any help and suggestions.",,"['differential-geometry', 'manifolds', 'spheres', 'low-dimensional-topology']"
25,Existence of a coordinate system,Existence of a coordinate system,,"How can we formally show that a coordinate system $(x,y)$ exists or does not exist? For instance for some given coordinate system $(r,\phi,\theta)$ defined on the manifold $M =(1,\infty)\times\mathbb{S}^2$, does there exist a coordinate system $(s,\phi,\theta)$ for some tensor:  $$h=ds⊗ds+g(s)^2(d\phi⊗d\phi+\cos^2\phi \space d\theta⊗d\theta)$$ where $g(s)$ is a positive smooth function. NOTE: There is some $2$-tensor given on $M$ by: $$f=\frac{r}{r^3+r-2}dr \otimes dr +r^2d\phi \otimes d\phi + r^2\cos^2\phi \space d\theta\otimes d\theta$$ This is a problem I am stuck with for days already, just do not know the formal way of proving such coordinate systems exist, given some manifold $M.$ I would appreciate the help.","How can we formally show that a coordinate system $(x,y)$ exists or does not exist? For instance for some given coordinate system $(r,\phi,\theta)$ defined on the manifold $M =(1,\infty)\times\mathbb{S}^2$, does there exist a coordinate system $(s,\phi,\theta)$ for some tensor:  $$h=ds⊗ds+g(s)^2(d\phi⊗d\phi+\cos^2\phi \space d\theta⊗d\theta)$$ where $g(s)$ is a positive smooth function. NOTE: There is some $2$-tensor given on $M$ by: $$f=\frac{r}{r^3+r-2}dr \otimes dr +r^2d\phi \otimes d\phi + r^2\cos^2\phi \space d\theta\otimes d\theta$$ This is a problem I am stuck with for days already, just do not know the formal way of proving such coordinate systems exist, given some manifold $M.$ I would appreciate the help.",,['differential-geometry']
26,Arnolds geometric formulation of the implicit function theorem,Arnolds geometric formulation of the implicit function theorem,,"I have trouble understanding why Arnold's geometric formulation of the implicit function theorem is equivalent to the usual one . In his book ""Ordinary Differential Equations"", Vladimir Arnold gives the following variant of the implicit function theorem (p. 92 of the third edition): Implicit function theorem: In some neighborhood of a nondegenerate point any two smooth mappings (of spaces of fixed dimension $m$ and $n$) are equivalent. He calls a smooth mapping $f:\mathbb{R}^m\to\mathbb{R}^n$ nondegenerate in the origin if its derivative has maximal rank there (i.e. the rank equals the minimum of $m$ and $n$). He supposes that $f(0)=0$ and calls two such mappings $f$ and $g$ equivalent in the origin if there exist diffeomorphisms $h:\mathbb{R}^m\to\mathbb{R}^m$ and $k:\mathbb{R}^n\to\mathbb{R}^n$ in the domain and target space that leave the origin fixed and such that $f\circ h = k\circ g$. Local equivalence is thus given if the two functions can be written by the same formulas if suitable local coordinates systems are used in the domain an target space. Arnold writes The reader accustomed to more complicated statements of the implicit function theorem will easily verify that these more complicated statements are equivalent to the simple geometric statement above. In spite of being advertized as an easy exercise, I have not succeeded in proving either that the usual formulation implies Arnold's formulation nor the other way around.","I have trouble understanding why Arnold's geometric formulation of the implicit function theorem is equivalent to the usual one . In his book ""Ordinary Differential Equations"", Vladimir Arnold gives the following variant of the implicit function theorem (p. 92 of the third edition): Implicit function theorem: In some neighborhood of a nondegenerate point any two smooth mappings (of spaces of fixed dimension $m$ and $n$) are equivalent. He calls a smooth mapping $f:\mathbb{R}^m\to\mathbb{R}^n$ nondegenerate in the origin if its derivative has maximal rank there (i.e. the rank equals the minimum of $m$ and $n$). He supposes that $f(0)=0$ and calls two such mappings $f$ and $g$ equivalent in the origin if there exist diffeomorphisms $h:\mathbb{R}^m\to\mathbb{R}^m$ and $k:\mathbb{R}^n\to\mathbb{R}^n$ in the domain and target space that leave the origin fixed and such that $f\circ h = k\circ g$. Local equivalence is thus given if the two functions can be written by the same formulas if suitable local coordinates systems are used in the domain an target space. Arnold writes The reader accustomed to more complicated statements of the implicit function theorem will easily verify that these more complicated statements are equivalent to the simple geometric statement above. In spite of being advertized as an easy exercise, I have not succeeded in proving either that the usual formulation implies Arnold's formulation nor the other way around.",,"['differential-geometry', 'implicit-function-theorem']"
27,Find conditions for a surface of rotation to be regular,Find conditions for a surface of rotation to be regular,,"I am reading Geomtric Structures in Dimension two by Bjørn Jahren, and have some questions about exercise 5.1.4, which says the following: Let $\alpha(u)=(f(u),g(u)),u\in[a,b]$ be an embedded curve in the $xz$-plane such that $f (u) > 0$ for all $u$. Find a parametrization of the surface of rotation obtained by rotating $\alpha$ around the $z$–axis and find conditions for this to be a regular surface. Discuss what happens if we remove the condition $f (u) > 0$. A regular surface is defined by the following: Definition 5.1.3. Let $S$ be a subset of $\mathbb{R}^3$ which is also a smooth surface, and let $\iota: S \to\mathbb{R}^3$ be the inclusion map. $S$ is called a regular surface if for every local parametrization $x$ of $S$ the Jacobian of the composition $\iota\circ x$ has rank 2 at every point. A parametrization of this surface is given by $(u,t)\mapsto(f(u)\cos(t),f(u)\sin(t),g(u))$. By the definition of regular surfaces, we need the Jacobian of this parametrizationto be of rank 2. The Jacobian has the columns $(f'(u)\cos(t),f'(u)\sin(t),g'(u))$ and $(-f(u)\sin(t),f(u)\cos(t),0)$. If $g'(u)\neq0$ they are linearly independent if and only if $f(u)\neq 0$, since $\sin$ and $\cos$ are not 0 in the same point. If $g'(u)=0$ linear independence is equivalent to the matrix $\begin{bmatrix} f'(u)\cos(t) & -f(u)\sin(t)\\ f'(u)\sin(t) & f(u)\cos(t) \end{bmatrix}$ having nonzero determinant, i.e. that $f(u)f'(u)\neq 0$. To conclude, the Jacobian has rank 2 if and only if $g'(u)\neq0\land f(u)\neq0$ or $f(u)\neq0\land f'(u)\neq 0$. Under the condition $f(u)>0$, that is if and only if $\alpha'(u)\neq 0$. Where do I go from here? I have found conditions given one specific parametrization, but I need to show it for all possible parametrizations. How do I generalize the result? (( EDIT : Maybe this suffices, since I can create an atlas with just this parametrization, by varying the domain?)) What about the points $a$ and $b$ are mapped to? Can I find a parametrization from an open subset of $\mathbb{R}^2$ around these? And what happens if we remove the condition $f(u)>0$, how should I attack that? Here is a handwritten (i.e. not so readable) and brief solution which may be of some use: (Available here .)","I am reading Geomtric Structures in Dimension two by Bjørn Jahren, and have some questions about exercise 5.1.4, which says the following: Let $\alpha(u)=(f(u),g(u)),u\in[a,b]$ be an embedded curve in the $xz$-plane such that $f (u) > 0$ for all $u$. Find a parametrization of the surface of rotation obtained by rotating $\alpha$ around the $z$–axis and find conditions for this to be a regular surface. Discuss what happens if we remove the condition $f (u) > 0$. A regular surface is defined by the following: Definition 5.1.3. Let $S$ be a subset of $\mathbb{R}^3$ which is also a smooth surface, and let $\iota: S \to\mathbb{R}^3$ be the inclusion map. $S$ is called a regular surface if for every local parametrization $x$ of $S$ the Jacobian of the composition $\iota\circ x$ has rank 2 at every point. A parametrization of this surface is given by $(u,t)\mapsto(f(u)\cos(t),f(u)\sin(t),g(u))$. By the definition of regular surfaces, we need the Jacobian of this parametrizationto be of rank 2. The Jacobian has the columns $(f'(u)\cos(t),f'(u)\sin(t),g'(u))$ and $(-f(u)\sin(t),f(u)\cos(t),0)$. If $g'(u)\neq0$ they are linearly independent if and only if $f(u)\neq 0$, since $\sin$ and $\cos$ are not 0 in the same point. If $g'(u)=0$ linear independence is equivalent to the matrix $\begin{bmatrix} f'(u)\cos(t) & -f(u)\sin(t)\\ f'(u)\sin(t) & f(u)\cos(t) \end{bmatrix}$ having nonzero determinant, i.e. that $f(u)f'(u)\neq 0$. To conclude, the Jacobian has rank 2 if and only if $g'(u)\neq0\land f(u)\neq0$ or $f(u)\neq0\land f'(u)\neq 0$. Under the condition $f(u)>0$, that is if and only if $\alpha'(u)\neq 0$. Where do I go from here? I have found conditions given one specific parametrization, but I need to show it for all possible parametrizations. How do I generalize the result? (( EDIT : Maybe this suffices, since I can create an atlas with just this parametrization, by varying the domain?)) What about the points $a$ and $b$ are mapped to? Can I find a parametrization from an open subset of $\mathbb{R}^2$ around these? And what happens if we remove the condition $f(u)>0$, how should I attack that? Here is a handwritten (i.e. not so readable) and brief solution which may be of some use: (Available here .)",,"['differential-geometry', 'surfaces']"
28,Does minimal submanifolds minimize area locally?,Does minimal submanifolds minimize area locally?,,"Consider $(\tilde{M},g)$ a riemannian manifold and $M \subset \tilde{M}$ riemannian submanifold. Is it true that if $M$ is a minimal submanifold of $\tilde{M}$ then for every $p \in M$ there exists a neighborhood $W$ of $p$ in $\tilde{M}$ such that $V=W\cap M$ has least area among every $\Omega \subset W$ with $\partial \Omega = \partial V$? I've been thinking about it, I think it is true but I don't know how to prove. If it's true, how should I go about proving it?","Consider $(\tilde{M},g)$ a riemannian manifold and $M \subset \tilde{M}$ riemannian submanifold. Is it true that if $M$ is a minimal submanifold of $\tilde{M}$ then for every $p \in M$ there exists a neighborhood $W$ of $p$ in $\tilde{M}$ such that $V=W\cap M$ has least area among every $\Omega \subset W$ with $\partial \Omega = \partial V$? I've been thinking about it, I think it is true but I don't know how to prove. If it's true, how should I go about proving it?",,"['differential-geometry', 'riemannian-geometry', 'minimal-surfaces', 'calibrated-geometry']"
29,diameter of Riemannian manifolds,diameter of Riemannian manifolds,,"Let $M$ be a compact Riemannian manifold of dimension $n$. If $M\subset N$ is an embedding in another Riemannian manifold, we can define the diameter $d(M,N$) of $M$ in $N$ as the longest distance in $N$ of two points in $M$. For example if $S^2$ is a sphere of radius $R$ in ${\mathbb{R}}^3$, we have $$d(S^2,S^2)=\pi R , \qquad d(S^2,{\mathbb{R}}^3)=2R.$$ If $d>0$ is an integer we can then define $$e(M,d)=\inf\big(d(M,N);\quad M\subset N \quad \text{and} \quad \dim(N)=\dim(M)+d\big)$$ If there a way (a formula) to compute $e(M,d)$ ? Is it true that $$\lim_{d\to\infty}e(M,d) \ = \ 0 \ ?$$","Let $M$ be a compact Riemannian manifold of dimension $n$. If $M\subset N$ is an embedding in another Riemannian manifold, we can define the diameter $d(M,N$) of $M$ in $N$ as the longest distance in $N$ of two points in $M$. For example if $S^2$ is a sphere of radius $R$ in ${\mathbb{R}}^3$, we have $$d(S^2,S^2)=\pi R , \qquad d(S^2,{\mathbb{R}}^3)=2R.$$ If $d>0$ is an integer we can then define $$e(M,d)=\inf\big(d(M,N);\quad M\subset N \quad \text{and} \quad \dim(N)=\dim(M)+d\big)$$ If there a way (a formula) to compute $e(M,d)$ ? Is it true that $$\lim_{d\to\infty}e(M,d) \ = \ 0 \ ?$$",,"['differential-geometry', 'riemannian-geometry']"
30,Vector subbundle and frame field relation,Vector subbundle and frame field relation,,"Question: Let $E \to M $ be a vector bundle of rank $k$ . Suppose that for each $p \in M $ we are given a subspace $E'_p$ of $E_p$ and consider the set $\displaystyle E' = \bigcup_{p \in M} E'_p $ . Show that $E'$ is the total space of a rank $l$ subbundle if and only if for each $p\in M$ there is an open set $U$ of $p$ on which smooth sections $\sigma_1, \ldots, \sigma_l$ are defined such that for each $q \in M$ the set $\{\sigma_1(q), \ldots, \sigma_l(q)\}$ is a basis of the subspace $E'_q$ . Attempt of proof: ( $\implies$ ) Suppose $E'$ is the total space of a rank $l$ subbundle then for every $p \in M$ there exists a VB-chart such that $$\phi (\pi^{-1}(U) \,\,\cap\,\,E' ) = U \times V' \subseteq U \times V$$ This rises a chart of the triple $(E', \pi|_{E'}, M, V')$ if we define the $\phi'$ as $\phi|_{\pi^{-1}_{E'}(U)}$ (the restriction of $\phi$ to $\pi^{-1}_{E'}(U)$ ), where $\pi^{-1}(U) \cap  E' = \pi^{-1}|_{E'}(U)$ and such that the following diagram commutes $$\require {AMScd} \begin{CD}\pi^{-1}(U) \cap E' = \pi^{-1}|_{E'}(U) @>\phi'>> U \times V' \subseteq U \times V\\@V \pi|_{E'} VV @VVpr_1V\\U @>>id >U\end{CD}$$ Let $\{e_1, \ldots, e_l\}$ be a basis of $V'$ . Since $\phi$ is a diffeomorphism we maydefine the sections of $E'$ as $$\sigma_j (q) = \phi^{-1} (q, e_j) \, \, , j = 1, \ldots, l , \forall q \in U $$ Now the inclusion $\iota_j : U \to U \times V' $ , $\iota_j (x) = (x, e_j)$ is a section of $U \times V'$ since $pr_1 \circ \iota_j = id_U$ and as $\phi' $ is a bundle isomorphism then $\sigma_j$ are sections of $E'$ . Since the vectors $(q, e_j)$ form a basis of $\{q\}\times V'$ and $\phi'$ is an isomorphism then $\{\sigma_1(q), \ldots, \sigma_l(q)\}$ is a basis of $E'_q$ , ( notice that $\sigma_j(q) \in E'_q, \forall j$ ) for each $q$ as wanted. ( $\Longleftarrow$ ) Suppose there exists an open neighborhood $U$ of $p$ (taken arbitrarily) such that for each $q \in U$ the set $\{\sigma_1(q), \ldots, \sigma_l(q)\}$ is a basis of the subspace $E'_q$ . Define $\phi' : U \times V' \to E' \cap \pi^{-1}(U)$ by $\phi' (q, c_1, \ldots, c_l) = \displaystyle \sum_{j=1}^l c^j\sigma_j(q)$ . As $\sigma_j$ are smooth then $\phi$ is smooth. We have that $\pi(\phi'(q,c)) = q = pr_1 (q,c)$ and the restriction of $\phi'$ to $\{q\} \times V'$ is linear. Since $\sigma_1(q), \ldots, \sigma_l(q)$ are  linearly independent the homomorphism $\phi'$ is injective and thus an isomorphism on each fiber. We conclude that $\phi$ is a bundle isomorphism and $$\phi'^{-1}(E' \cap \pi^{-1}(U)) = U \times V'$$ and therefore $E'$ is a total space of a rank $l$ subbundle. I would like to check if this is correct. Do I have to show that $E'$ is a submanifold of $E$ ?","Question: Let be a vector bundle of rank . Suppose that for each we are given a subspace of and consider the set . Show that is the total space of a rank subbundle if and only if for each there is an open set of on which smooth sections are defined such that for each the set is a basis of the subspace . Attempt of proof: ( ) Suppose is the total space of a rank subbundle then for every there exists a VB-chart such that This rises a chart of the triple if we define the as (the restriction of to ), where and such that the following diagram commutes Let be a basis of . Since is a diffeomorphism we maydefine the sections of as Now the inclusion , is a section of since and as is a bundle isomorphism then are sections of . Since the vectors form a basis of and is an isomorphism then is a basis of , ( notice that ) for each as wanted. ( ) Suppose there exists an open neighborhood of (taken arbitrarily) such that for each the set is a basis of the subspace . Define by . As are smooth then is smooth. We have that and the restriction of to is linear. Since are  linearly independent the homomorphism is injective and thus an isomorphism on each fiber. We conclude that is a bundle isomorphism and and therefore is a total space of a rank subbundle. I would like to check if this is correct. Do I have to show that is a submanifold of ?","E \to M  k p \in M  E'_p E_p \displaystyle E' = \bigcup_{p \in M} E'_p  E' l p\in M U p \sigma_1, \ldots, \sigma_l q \in M \{\sigma_1(q), \ldots, \sigma_l(q)\} E'_q \implies E' l p \in M \phi (\pi^{-1}(U) \,\,\cap\,\,E' ) = U \times V' \subseteq U \times V (E', \pi|_{E'}, M, V') \phi' \phi|_{\pi^{-1}_{E'}(U)} \phi \pi^{-1}_{E'}(U) \pi^{-1}(U) \cap  E' = \pi^{-1}|_{E'}(U) \require {AMScd} \begin{CD}\pi^{-1}(U) \cap E' = \pi^{-1}|_{E'}(U) @>\phi'>> U \times V' \subseteq U \times V\\@V \pi|_{E'} VV @VVpr_1V\\U @>>id >U\end{CD} \{e_1, \ldots, e_l\} V' \phi E' \sigma_j (q) = \phi^{-1} (q, e_j) \, \, , j = 1, \ldots, l , \forall q \in U  \iota_j : U \to U \times V'  \iota_j (x) = (x, e_j) U \times V' pr_1 \circ \iota_j = id_U \phi'  \sigma_j E' (q, e_j) \{q\}\times V' \phi' \{\sigma_1(q), \ldots, \sigma_l(q)\} E'_q \sigma_j(q) \in E'_q, \forall j q \Longleftarrow U p q \in U \{\sigma_1(q), \ldots, \sigma_l(q)\} E'_q \phi' : U \times V' \to E' \cap \pi^{-1}(U) \phi' (q, c_1, \ldots, c_l) = \displaystyle \sum_{j=1}^l c^j\sigma_j(q) \sigma_j \phi \pi(\phi'(q,c)) = q = pr_1 (q,c) \phi' \{q\} \times V' \sigma_1(q), \ldots, \sigma_l(q) \phi' \phi \phi'^{-1}(E' \cap \pi^{-1}(U)) = U \times V' E' l E' E","['differential-geometry', 'proof-verification', 'vector-bundles']"
31,Geodesic curvature of a curve in the hyperbolic plane,Geodesic curvature of a curve in the hyperbolic plane,,Consider the curve $\gamma$ given by $y=b$ in the upper half-plane equipped with the hyperbolic metric $$\dfrac{dx^2+dy^2}{y^2}$$   Calculate the geodesic curvature of $\gamma$. The problem I'm having is that every way I know of calculating the geodesic curvature of a curve in a surface involves knowledge of a normal vector and I'm not sure how one would go about defining the tangential derivative for such abstract smooth surfaces. Any clarification would be appreciated.,Consider the curve $\gamma$ given by $y=b$ in the upper half-plane equipped with the hyperbolic metric $$\dfrac{dx^2+dy^2}{y^2}$$   Calculate the geodesic curvature of $\gamma$. The problem I'm having is that every way I know of calculating the geodesic curvature of a curve in a surface involves knowledge of a normal vector and I'm not sure how one would go about defining the tangential derivative for such abstract smooth surfaces. Any clarification would be appreciated.,,"['differential-geometry', 'smooth-manifolds', 'hyperbolic-geometry']"
32,Question about the definition of the dual map of the differential,Question about the definition of the dual map of the differential,,"Background Let $M,N$ be smooth manifolds, $\psi: M \rightarrow N$ a $C^{\infty}$ and $M_m, N_{\psi(m)}$ the tangent spaces at $m \in M$ and $\psi(m) \in N$. The differential of $\psi$ at $m$ is the linear map $$d\psi: M_m\rightarrow N_{\psi(m)}$$ defined by setting $$d\psi(v)(g)=v(g\circ\psi),$$ where $v \in M_m$ is a tangent vector and $g$ is $c^{\infty}$ in a neighborhood of $\psi(m)$. The dual map $$\delta\psi:N^*_{\psi(m)} \rightarrow M^*_m$$ is defined by requiring that $$\delta \psi(\omega)(v)=\omega(d\psi(v))$$ whenever $\omega \in N^*_{\psi(m)}$ and $v\in M_m$ Question I am having some trouble understanding the following: In the special case of a $C^{\infty}$ function $f:M\rightarrow \mathbb{R},$ if $v\in M_m$ and $f(m)=r_0,$ then $$df(v)=v(f)\frac{d}{dr}\bigg |_{r_0}.$$ In this case, we usually take $df$ to mean the element of $M^*_m$ defined by $$df(v)=v(f).$$ That is, we identify $df$ with $\delta f(\omega)$, where $\omega$ is the basis of the $1$ dimensional space $\mathbb{R}^*_{r_0}$ dual to $(d/dr)|_{r_0}$ My Interpretation Since $df(v)$ is a tangent vector at $f(m)=r_0$ and since $\frac{d}{dr}\bigg|_{r_0}$ is a basis for the tangent space at $r_0$, we should have $$df(v)=a\frac{d}{dr}\bigg|_{r_0}.$$ Now, evaluating both sides at $r$ we obtain $$df(v)(r)=a.$$ Now $df(v)(r)=v(r \circ f)=v(f)$ so we have the desired result. Next, I am not sure what the text means when it states that $df(v)=v(f)$. We just showed that $df(v)=v(f)\frac{d}{dr}\bigg |_{r_0}$. In fact, I do not understand how $df$ is being associated with $\delta f(\omega)$ (or why this association even matters). Is the text just trying to say that since $df(v)$ maps into the reals, it is a linear functional on $M_m$? Reference The text I am referring to is Foundations of Differentiable Manifolds and Lie Groups by Frank W. Warner","Background Let $M,N$ be smooth manifolds, $\psi: M \rightarrow N$ a $C^{\infty}$ and $M_m, N_{\psi(m)}$ the tangent spaces at $m \in M$ and $\psi(m) \in N$. The differential of $\psi$ at $m$ is the linear map $$d\psi: M_m\rightarrow N_{\psi(m)}$$ defined by setting $$d\psi(v)(g)=v(g\circ\psi),$$ where $v \in M_m$ is a tangent vector and $g$ is $c^{\infty}$ in a neighborhood of $\psi(m)$. The dual map $$\delta\psi:N^*_{\psi(m)} \rightarrow M^*_m$$ is defined by requiring that $$\delta \psi(\omega)(v)=\omega(d\psi(v))$$ whenever $\omega \in N^*_{\psi(m)}$ and $v\in M_m$ Question I am having some trouble understanding the following: In the special case of a $C^{\infty}$ function $f:M\rightarrow \mathbb{R},$ if $v\in M_m$ and $f(m)=r_0,$ then $$df(v)=v(f)\frac{d}{dr}\bigg |_{r_0}.$$ In this case, we usually take $df$ to mean the element of $M^*_m$ defined by $$df(v)=v(f).$$ That is, we identify $df$ with $\delta f(\omega)$, where $\omega$ is the basis of the $1$ dimensional space $\mathbb{R}^*_{r_0}$ dual to $(d/dr)|_{r_0}$ My Interpretation Since $df(v)$ is a tangent vector at $f(m)=r_0$ and since $\frac{d}{dr}\bigg|_{r_0}$ is a basis for the tangent space at $r_0$, we should have $$df(v)=a\frac{d}{dr}\bigg|_{r_0}.$$ Now, evaluating both sides at $r$ we obtain $$df(v)(r)=a.$$ Now $df(v)(r)=v(r \circ f)=v(f)$ so we have the desired result. Next, I am not sure what the text means when it states that $df(v)=v(f)$. We just showed that $df(v)=v(f)\frac{d}{dr}\bigg |_{r_0}$. In fact, I do not understand how $df$ is being associated with $\delta f(\omega)$ (or why this association even matters). Is the text just trying to say that since $df(v)$ maps into the reals, it is a linear functional on $M_m$? Reference The text I am referring to is Foundations of Differentiable Manifolds and Lie Groups by Frank W. Warner",,['differential-geometry']
33,Prop 12.8 in Bott & Tu,Prop 12.8 in Bott & Tu,,"This proposition in Bott & Tu have been haunting me for a year or so since I always have to come back to this book for references. More precisely, the second equality in Proposition 12.8 in page 135 of Differential Forms in Algebraic Topology has a weird assertion. Let $E \twoheadrightarrow X$ be a vector bundle over a manifold $X$ , $S_0$ the image of the zero section, $S$ the image of a section transversal to $S_0$ , $Z = S \cap S_0$ , $x \in Z$ (by identifying $S_0$ and $X$ ) and $S_x = (N_{Z/S})_x$ . Let $\Phi$ be the Thom class of $N_{Z/X}$ . The authors claim that $$\int_{S_x} \Phi = \int_{E_x} \Phi$$ , because $S_x$ and $E_x$ are homotopic modulo the region in $E$ where $\Phi$ is zero. In this context, this justification makes no sense. The unique possible theorem that they're alluding to is contained in the answer of invariance of integrals for homotopy equivalent spaces . However this still makes no sense in the equality above even by fixing a homotopy equivalence $f: S_x \rightarrow E_x$ since $f^* \Phi \neq \Phi$ might happens. I would like a clarification of the equality mentioned above. Thanks in advance.","This proposition in Bott & Tu have been haunting me for a year or so since I always have to come back to this book for references. More precisely, the second equality in Proposition 12.8 in page 135 of Differential Forms in Algebraic Topology has a weird assertion. Let be a vector bundle over a manifold , the image of the zero section, the image of a section transversal to , , (by identifying and ) and . Let be the Thom class of . The authors claim that , because and are homotopic modulo the region in where is zero. In this context, this justification makes no sense. The unique possible theorem that they're alluding to is contained in the answer of invariance of integrals for homotopy equivalent spaces . However this still makes no sense in the equality above even by fixing a homotopy equivalence since might happens. I would like a clarification of the equality mentioned above. Thanks in advance.",E \twoheadrightarrow X X S_0 S S_0 Z = S \cap S_0 x \in Z S_0 X S_x = (N_{Z/S})_x \Phi N_{Z/X} \int_{S_x} \Phi = \int_{E_x} \Phi S_x E_x E \Phi f: S_x \rightarrow E_x f^* \Phi \neq \Phi,"['differential-geometry', 'algebraic-topology', 'characteristic-classes']"
34,Relationship between Curvature and Torsion on a Sphere [Homework],Relationship between Curvature and Torsion on a Sphere [Homework],,"The problem asks: Let $\kappa(s)$ and $\tau(s)$ be the curvature and torsion of a curve parameterized by its arclength $s$ . If $$(\frac{1}{\kappa})^2 + [\frac{1}{\tau}\frac{d}{ds}(\frac{1}{\kappa})]^2 = constant$$ , then either this curve lies on a sphere or the its curvature $\kappa$ is constant. (Thinking in $\mathbb{R}^3$ , assuming all ""good conditions"", like smooth curve, $\kappa \neq0$ etc.) Since the equation looks like a inner product. I tried to construct a curve with $\frac{1}{\kappa}$ and $\frac{1}{\tau}\frac{d}{ds}(\frac{1}{\kappa})$ as its components. But it turns out that the resulting curve's curvature is not the given $\kappa$ . I also tried differentiating the equations w.r.t $s$ , but did not find any clues. Any ideas? Update: although this question was marked duplicate, that post did not solve the problem completely. Here I posted my solution. Updated 2: the following text is also posted to that post ( math.SE ). But be noticed that the two posts' problem differs subtlety, and my problem requires an extra step to prove. Thanks to @Ted Shifrin and another post at math.SE , I solved this problem. The key is to construct a vector $\alpha$ as in the link above : We assume that $R$ is in a sphere. Then think of the vector $\alpha$ as exactly the vector that points from the centre of sphere to the curve $R$ . So $\alpha$ is different from the original curve $R$ by just by a translation, hence they have the same tangent, curvature and torsion. We can always express $\alpha$ as a linear combination (as suggested by Shifrin) of: $$\alpha(s) = \lambda(s)T(s) + \mu(s)N(s)+\nu(s)B(s)$$ for some functions $\lambda$ , $\mu$ , $\nu$ (Note that $\alpha$ itself not necessarily arc length parametrised.) Then since we assume that the $R$ is on the sphere, and that $\alpha$ is from the centre to the sphere, we require that $\alpha$ is tangent to its tangent vector (notice that if $\alpha$ does not point from the centre to the sphere, it will not be tangent to its tangent vector $T$ ), that is, $$<\alpha, T>=0$$ By differentiating above, we will find the expression for $\alpha$ as shown in the post mentioned: $$\alpha=-\frac{1}{\kappa}N-\left(\frac{1}{\kappa}\right)'\frac{1}{\tau}B,$$ We see clearly $\alpha$ is of constant length. If we can prove $r(s)= R(s) - \alpha(s)$ is a fixed point, then our proof is done. To prove $r(s)$ is a fixed point, we prove that $\frac{d}{ds}r(s) =0$ . This could be done by differentiating the original equation w.r.t $s$ (do a straight forward calculation and then  compare the results of the two)","The problem asks: Let and be the curvature and torsion of a curve parameterized by its arclength . If , then either this curve lies on a sphere or the its curvature is constant. (Thinking in , assuming all ""good conditions"", like smooth curve, etc.) Since the equation looks like a inner product. I tried to construct a curve with and as its components. But it turns out that the resulting curve's curvature is not the given . I also tried differentiating the equations w.r.t , but did not find any clues. Any ideas? Update: although this question was marked duplicate, that post did not solve the problem completely. Here I posted my solution. Updated 2: the following text is also posted to that post ( math.SE ). But be noticed that the two posts' problem differs subtlety, and my problem requires an extra step to prove. Thanks to @Ted Shifrin and another post at math.SE , I solved this problem. The key is to construct a vector as in the link above : We assume that is in a sphere. Then think of the vector as exactly the vector that points from the centre of sphere to the curve . So is different from the original curve by just by a translation, hence they have the same tangent, curvature and torsion. We can always express as a linear combination (as suggested by Shifrin) of: for some functions , , (Note that itself not necessarily arc length parametrised.) Then since we assume that the is on the sphere, and that is from the centre to the sphere, we require that is tangent to its tangent vector (notice that if does not point from the centre to the sphere, it will not be tangent to its tangent vector ), that is, By differentiating above, we will find the expression for as shown in the post mentioned: We see clearly is of constant length. If we can prove is a fixed point, then our proof is done. To prove is a fixed point, we prove that . This could be done by differentiating the original equation w.r.t (do a straight forward calculation and then  compare the results of the two)","\kappa(s) \tau(s) s (\frac{1}{\kappa})^2 + [\frac{1}{\tau}\frac{d}{ds}(\frac{1}{\kappa})]^2 = constant \kappa \mathbb{R}^3 \kappa \neq0 \frac{1}{\kappa} \frac{1}{\tau}\frac{d}{ds}(\frac{1}{\kappa}) \kappa s \alpha R \alpha R \alpha R \alpha \alpha(s) = \lambda(s)T(s) + \mu(s)N(s)+\nu(s)B(s) \lambda \mu \nu \alpha R \alpha \alpha \alpha T <\alpha, T>=0 \alpha \alpha=-\frac{1}{\kappa}N-\left(\frac{1}{\kappa}\right)'\frac{1}{\tau}B, \alpha r(s)= R(s) - \alpha(s) r(s) \frac{d}{ds}r(s) =0 s",['differential-geometry']
35,Master's Exploration in General Relativity,Master's Exploration in General Relativity,,"just throwing a query out to the Math community. I'm about to embark on a master's in Gravitation, Cosmology and General Relativity and was looking for possible subjects to start researching. My main interests are in the geometrical side of things (i.e. differential geometry or anything focused on geometry) but am open to interesting, subtle and exciting topics. So far I've been looking at Carter-Penrose hypersurfaces, matching/junction conditions for given metrics; otherwise I'm not having much luck in topics which could be deemed ""original"" or ""new"". If anybody has any advice on research topics or books/papers I could/should be reading, it would be immensely appreciated! Thanks! MKF","just throwing a query out to the Math community. I'm about to embark on a master's in Gravitation, Cosmology and General Relativity and was looking for possible subjects to start researching. My main interests are in the geometrical side of things (i.e. differential geometry or anything focused on geometry) but am open to interesting, subtle and exciting topics. So far I've been looking at Carter-Penrose hypersurfaces, matching/junction conditions for given metrics; otherwise I'm not having much luck in topics which could be deemed ""original"" or ""new"". If anybody has any advice on research topics or books/papers I could/should be reading, it would be immensely appreciated! Thanks! MKF",,"['differential-geometry', 'riemannian-geometry', 'general-relativity', 'semi-riemannian-geometry']"
36,"For any smooth n-manifold $M$, construct a smooth map $f:M\to S^n$ which is not null-homotopic","For any smooth n-manifold , construct a smooth map  which is not null-homotopic",M f:M\to S^n,"PROBLEM: For any smooth n-manifold $M$, construct a smooth map $f:M\to S^n$ which is not null-homotopic ,or even of degree 1 The following is my idea: First, choosing an arbitrary open coordinate ball $B$ on $M$ and then collapsing $M\setminus B$ to a single point gives a continuous map $f:M \to S^n$.Also, we may assume all $M\setminus B$ is mapped to the north pole $\mathbb N$. It is known that any continuous map $f$ between two manifolds $M_1$ and $M_2$ is homotopic to a smooth map $F$. Moreover,  can we require $|F-f|\le \epsilon$ for any  positive   continuous function $\epsilon$ on $M_1$ ? Here the norm $|\cdot|$ can be viewed as a Euclidean norm when we embeds $M_2$ to some $\mathbb R^m$ Personally, I believe it's true. If the statement above is indeed true, then we denote $F$ the smooth map homotopic to $f$ and choose $\epsilon$ small enough. Also, we choose a regular value $\mathbb P$ near the South pole $\mathbb S$ of $S^n$. Then, $\mathbb P$ can only has one preimage and thus the degree of $F$ must be 1 or -1","PROBLEM: For any smooth n-manifold $M$, construct a smooth map $f:M\to S^n$ which is not null-homotopic ,or even of degree 1 The following is my idea: First, choosing an arbitrary open coordinate ball $B$ on $M$ and then collapsing $M\setminus B$ to a single point gives a continuous map $f:M \to S^n$.Also, we may assume all $M\setminus B$ is mapped to the north pole $\mathbb N$. It is known that any continuous map $f$ between two manifolds $M_1$ and $M_2$ is homotopic to a smooth map $F$. Moreover,  can we require $|F-f|\le \epsilon$ for any  positive   continuous function $\epsilon$ on $M_1$ ? Here the norm $|\cdot|$ can be viewed as a Euclidean norm when we embeds $M_2$ to some $\mathbb R^m$ Personally, I believe it's true. If the statement above is indeed true, then we denote $F$ the smooth map homotopic to $f$ and choose $\epsilon$ small enough. Also, we choose a regular value $\mathbb P$ near the South pole $\mathbb S$ of $S^n$. Then, $\mathbb P$ can only has one preimage and thus the degree of $F$ must be 1 or -1",,"['differential-geometry', 'approximation', 'homotopy-theory', 'smooth-manifolds']"
37,Is it true that a map that maps geodesics to geodesics must be an differeomorphism?,Is it true that a map that maps geodesics to geodesics must be an differeomorphism?,,"Let $M,N$ be connected Riemannian manifolds. Let $f:M\rightarrow N$ be a bijective smooth map that maps any unit speed geodesic in $M$ to unit speed geodesic in $N$. Question: Is this suffice to show that $f$ induces a differeomorphism $M\cong N$? Can $f$ even be an (local) isometry? If either is not true, what additional assumption is needed (like $M,N$ are simply-connected)? (originally asked by a classmate and I was stuck)","Let $M,N$ be connected Riemannian manifolds. Let $f:M\rightarrow N$ be a bijective smooth map that maps any unit speed geodesic in $M$ to unit speed geodesic in $N$. Question: Is this suffice to show that $f$ induces a differeomorphism $M\cong N$? Can $f$ even be an (local) isometry? If either is not true, what additional assumption is needed (like $M,N$ are simply-connected)? (originally asked by a classmate and I was stuck)",,['differential-geometry']
38,Left-Invariant Vector Fields: Smoothness,Left-Invariant Vector Fields: Smoothness,,Given a Lie group $G$. For a left-invariant vector field it holds: $$\mathrm{d}l_gV=V\circ l_g:\quad V_g=\mathrm{d}l_gV_e$$ Conversely rough vector fields are smooth: $$V_g:=\mathrm{d}l_gv:\quad V\in\Gamma_G(\mathrm{T}G)$$ How to prove this in a clever way?,Given a Lie group $G$. For a left-invariant vector field it holds: $$\mathrm{d}l_gV=V\circ l_g:\quad V_g=\mathrm{d}l_gV_e$$ Conversely rough vector fields are smooth: $$V_g:=\mathrm{d}l_gv:\quad V\in\Gamma_G(\mathrm{T}G)$$ How to prove this in a clever way?,,['differential-geometry']
39,Bundle metric and connection on trivial vector bundle,Bundle metric and connection on trivial vector bundle,,"I read this: Let $(M,g)$ be a compact Riemannian  manifold and let $W$ be a vector bundle (rank $n$) over $M$ with $h_W$ a bundle metric of $W$ and $D$ a bundle connection of $W$. I choose $W$ to be the trivial vector bundle $M \times \mathbb{R}$. Let $V=T^0_0 M \otimes W = W$ be the vector bundle of $W-$valued (0,0)-tensors on $M$. Endow $V$ with the bundle metric   $$h := (\cdot, \cdot)^0_0 \otimes h_W$$   where $(\cdot, \cdot)^0_0 := g^{\otimes 0}\otimes g^{*\otimes 0}$ is the bundle metric on $T^0_0M$ induced by $g$. Equip $V$ with the metric connection   $$\nabla = \nabla(\nabla_g, D)$$   induced by the Levi-civita connection of $M$ and connection $D$ of $W$. It follows that $\nabla u = Du$ for $u \in \mathcal{T}^0_0(M, W)$. Am I right that in my case $h = h_W$? I am very confused about how the notation should be simplified for my simple trivial bundle case. Now the last sentence seems wrong to me. Don't we need $\nabla u = \nabla_g u$ where $\nabla_g$ is the Levi-Civita connection on $M$, whenever $u \in \mathcal{T}^0_0(M, W)$ (i.e., whenever $u$ is a smooth function on $M$)??? The purpose of all this stuff is to set up Sobolev spaces over vector or tensor bundles. I only need sobolev spaces over $M$, so I thought of taking the trivial vector bundle like I wrote above in order for the theory to simplify, but I have a lot of trouble understanding. My second point for example, I would expect $\nabla$ to be the ordinary gradient for a function on $M$ but it's not. It's a different connection $D$, and I don't know what I should choose $h_W$ and $D$ to be to make it work. Thanks.","I read this: Let $(M,g)$ be a compact Riemannian  manifold and let $W$ be a vector bundle (rank $n$) over $M$ with $h_W$ a bundle metric of $W$ and $D$ a bundle connection of $W$. I choose $W$ to be the trivial vector bundle $M \times \mathbb{R}$. Let $V=T^0_0 M \otimes W = W$ be the vector bundle of $W-$valued (0,0)-tensors on $M$. Endow $V$ with the bundle metric   $$h := (\cdot, \cdot)^0_0 \otimes h_W$$   where $(\cdot, \cdot)^0_0 := g^{\otimes 0}\otimes g^{*\otimes 0}$ is the bundle metric on $T^0_0M$ induced by $g$. Equip $V$ with the metric connection   $$\nabla = \nabla(\nabla_g, D)$$   induced by the Levi-civita connection of $M$ and connection $D$ of $W$. It follows that $\nabla u = Du$ for $u \in \mathcal{T}^0_0(M, W)$. Am I right that in my case $h = h_W$? I am very confused about how the notation should be simplified for my simple trivial bundle case. Now the last sentence seems wrong to me. Don't we need $\nabla u = \nabla_g u$ where $\nabla_g$ is the Levi-Civita connection on $M$, whenever $u \in \mathcal{T}^0_0(M, W)$ (i.e., whenever $u$ is a smooth function on $M$)??? The purpose of all this stuff is to set up Sobolev spaces over vector or tensor bundles. I only need sobolev spaces over $M$, so I thought of taking the trivial vector bundle like I wrote above in order for the theory to simplify, but I have a lot of trouble understanding. My second point for example, I would expect $\nabla$ to be the ordinary gradient for a function on $M$ but it's not. It's a different connection $D$, and I don't know what I should choose $h_W$ and $D$ to be to make it work. Thanks.",,"['differential-geometry', 'manifolds']"
40,Lifting Riemannian metrics on principal bundles,Lifting Riemannian metrics on principal bundles,,"Given a principal bundle $\pi:M\rightarrow M/G$, there are natural maps $$\pi_{\mathcal{F}}:\mathcal{F}(M)^G\rightarrow\mathcal{F}(M/G)$$ $$\pi_{\mathfrak{X}}:\mathfrak{X}(M)^G\rightarrow\mathfrak{X}(M/G)$$ $$\pi_{\mathcal{R}}:\mathcal{R}(M)^G\rightarrow\mathcal{R}(M/G)$$ from $G$-invariant functions ($\mathcal{F}$), vector fields ($\mathfrak{X}$) and Riemannian metrics ($\mathcal{R}$) on $M$ to the corresponding objects on the base space $M/G$. The pull-back map $\pi^*:\mathcal{F}(M/G)\rightarrow\mathcal{F}(M)^G$ and $\pi_{\mathcal{F}}$ are mutual inverses. Also, fixing a section $s:M/G\rightarrow M$ of $\pi$, I know how to construct a section $\pi^*_s:\mathfrak{X}(M/G)\rightarrow\mathfrak{X}(M)^G$ of $\pi_{\mathfrak{X}}$. My question is: How can one construct sections of $\pi_{\mathcal{R}}$? Given a section $s$, any point of $M$ is of the form $\psi_g(s(\pi(x)))$ for some $g\in G$ and $x\in M$ (here $\psi_g$ is the diffeo on $M$ defined by the action of $g$). From $s$ we get a connection on $M$ with horizontal spaces $$H_{\psi_g(s(\pi(x))}=d_{\pi(x)}(\psi_g\circ s)(T_{\pi(x)}(M/G)).$$ This is sufficient to construct the pull-back for vector fields, because a vector field on $M/G$ is lifted to a horizontal vector field on $M$, which is then projected back by $\pi_\mathfrak{X}$ to the original vector field. For Riemannian metrics it seems that something else is necessary because lifting a metric on $M/G$ tells us how the metric on $M$ looks like when restricted to horizontal spaces, but we need more than that: How is the metric defined for non-horizontal vectors?","Given a principal bundle $\pi:M\rightarrow M/G$, there are natural maps $$\pi_{\mathcal{F}}:\mathcal{F}(M)^G\rightarrow\mathcal{F}(M/G)$$ $$\pi_{\mathfrak{X}}:\mathfrak{X}(M)^G\rightarrow\mathfrak{X}(M/G)$$ $$\pi_{\mathcal{R}}:\mathcal{R}(M)^G\rightarrow\mathcal{R}(M/G)$$ from $G$-invariant functions ($\mathcal{F}$), vector fields ($\mathfrak{X}$) and Riemannian metrics ($\mathcal{R}$) on $M$ to the corresponding objects on the base space $M/G$. The pull-back map $\pi^*:\mathcal{F}(M/G)\rightarrow\mathcal{F}(M)^G$ and $\pi_{\mathcal{F}}$ are mutual inverses. Also, fixing a section $s:M/G\rightarrow M$ of $\pi$, I know how to construct a section $\pi^*_s:\mathfrak{X}(M/G)\rightarrow\mathfrak{X}(M)^G$ of $\pi_{\mathfrak{X}}$. My question is: How can one construct sections of $\pi_{\mathcal{R}}$? Given a section $s$, any point of $M$ is of the form $\psi_g(s(\pi(x)))$ for some $g\in G$ and $x\in M$ (here $\psi_g$ is the diffeo on $M$ defined by the action of $g$). From $s$ we get a connection on $M$ with horizontal spaces $$H_{\psi_g(s(\pi(x))}=d_{\pi(x)}(\psi_g\circ s)(T_{\pi(x)}(M/G)).$$ This is sufficient to construct the pull-back for vector fields, because a vector field on $M/G$ is lifted to a horizontal vector field on $M$, which is then projected back by $\pi_\mathfrak{X}$ to the original vector field. For Riemannian metrics it seems that something else is necessary because lifting a metric on $M/G$ tells us how the metric on $M$ looks like when restricted to horizontal spaces, but we need more than that: How is the metric defined for non-horizontal vectors?",,"['differential-geometry', 'lie-groups', 'riemannian-geometry', 'principal-bundles']"
41,What is the metric on a cone?,What is the metric on a cone?,,"I'm trying to learn differential geometry.  I thought a cone would be an easy place to start with calculating a metric, shape operator, what have you. First of all, by the way, when I say ""cone"" I mean the map $f: (x,y) \rightarrow (x,y,\sqrt{x^2+y^2})$  Nothing fancy. So I run through a prescription for getting a metric: $g_{ij} = \partial_i f_k \partial_j f_k$ where repeated indices indicate sum. I get $G=((2x^2+y^2)\,dx^2+2xy\,dx\,dy+(x^2+2y^2)\,dy^2)/(x^2+y^2)$ Can someone just tell me whether this is right or not, and show me how to correct myself if I have gone wrong?  I can't find this formula or, surprising to me, any other formula anywhere.  I thought this would be a widely discussed example.  Maybe I ought to just stop being cheap and buy a book?","I'm trying to learn differential geometry.  I thought a cone would be an easy place to start with calculating a metric, shape operator, what have you. First of all, by the way, when I say ""cone"" I mean the map $f: (x,y) \rightarrow (x,y,\sqrt{x^2+y^2})$  Nothing fancy. So I run through a prescription for getting a metric: $g_{ij} = \partial_i f_k \partial_j f_k$ where repeated indices indicate sum. I get $G=((2x^2+y^2)\,dx^2+2xy\,dx\,dy+(x^2+2y^2)\,dy^2)/(x^2+y^2)$ Can someone just tell me whether this is right or not, and show me how to correct myself if I have gone wrong?  I can't find this formula or, surprising to me, any other formula anywhere.  I thought this would be a widely discussed example.  Maybe I ought to just stop being cheap and buy a book?",,"['differential-geometry', 'metric-spaces']"
42,Space of oriented lines in $\mathbb{R}^{n+1}$ as symplectic quotient.,Space of oriented lines in  as symplectic quotient.,\mathbb{R}^{n+1},"I've been working out a nice example of symplectic reduction, and have come to a solution only after quite a lot of effort. So I was wondering if anyone knew a more straightforward route to the answer. This example is about the space of oriented lines in $\mathbb{R}^{n+1}$. Start by considering the symplectic manifold $(\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}, dp_{i} \wedge dq_{i})$, where $(q_{i},p_{i})$ are the coordinates on $\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$. We let $\mathbb{R}$ act on $\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$ as follows: \begin{equation} t \ast (q,p) = (q+tp, p). \end{equation} This action is evidently symplectic. Then define the following moment map  \begin{equation} \mu : \mathbb{R}^{n+1} \times \mathbb{R}^{n+1} \to \mathbb{R}, \ \ \ \ (q,p) \mapsto \frac{1}{2}(|p|^2 - 1). \end{equation} The symplectic quotient is the space $(\mu^{-1}(0)/\mathbb{R}, \omega_{r})$, where $\omega_{r}$ is the reduced symplectic form, which is the unique symplectic form on the quotient $\mu^{-1}(0)/\mathbb{R}$, satisfying \begin{equation} \pi^{*}(\omega_{r}) = \iota^{*}(dp_{i} \wedge dq_{i}), \end{equation} where $\pi : \mu^{-1}(0) \to \mu^{-1}(0)/\mathbb{R}$ is the orbit projection map, and $\iota : \mu^{-1}(0) \to \mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$ is the inclusion. We have the following interpretation of the resulting space: If we restrict to $|p| = 1$, then $p$ specifies a direction in $\mathbb{R}^{n+1}$. The coordinate $q$ specifies a point in $\mathbb{R}^{n+1}$. Therefore, the pair $(q,p)$ singles out the line passing through $q$ in the direction of $p$. Hence $\mu^{-1}(0)$ consists of all the directed lines in $n+1$ dimensional space. However, there is a degeneracy: pairs $(q,p)$, where the $q$ lie along the same line, all pick out the same oriented line. In fact, our action of $\mathbb{R}$ is a symmetry of this interpretation because all points $t \ast (q,p)$ correspond to the same line; each orbit corresponds to a single line. Therefore $\mu^{-1}(0)/\mathbb{R}$ is the space of oriented lines. Now we want to describe the geometry of this space, and to do so we should pick a representative from each orbit. The natural choice for each line is to pick the closest point to the origin. Given a line specified by $(q,p)$, this point is $(q - (q \cdot p)p, p)$. Note that $(q - (q \cdot p)p) \cdot p = 0$. The two coordinates of this representative are orthogonal. So if we define $N$ to be the following embedded submanifold of $ \mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$: \begin{equation} N = \{ (q,p) \in  \mathbb{R}^{n+1} \times \mathbb{R}^{n+1} \ | \ |p| = 1, \ q \cdot p = 0\}, \end{equation} then we can describe the orbit projection map $\pi$ as the smooth submersion \begin{equation} \pi : \mu^{-1}(0) \to N, \ \ (q,p) \mapsto (q - (q \cdot p)p, p). \end{equation} Now note that the image $N$ is nothing but the tangent bundle of the n-sphere $TS^n$, and that this is isomorphic to the cotangent bundle of the n-sphere $T^{*}S^{n}$. I want to show that in fact, $N$ is symplectomorphic to $T^{*}S^{n}$ with the canonical symplectic structure ( http://en.wikipedia.org/wiki/Cotangent_bundle#Symplectic_form ). This is where I'm a little less sure about how to proceed. My idea is as follows: We can use the standard Euclidean metric $g$ on the ambient space $\mathbb{R}^{n+1}$ to induce a metric on the sphere $S^n$. This induces a vector bundle isomorphism between the tangent and cotangent bundles of $S^n$ which covers the identity on $S^n$ \begin{equation} \hat{g} : TS^n \to T^{*}S^n, \ \ v_{s} \mapsto g_{s}(v_{s}, -). \end{equation}  Note that this means that if $\Pi : TS^n \to S^n$ and $\tilde{\Pi} : T^{*}S^n \to S^n$ are the projection maps, then $\tilde{\Pi} \circ \hat{g} = \Pi$. I want to now pull back the canonical symplectic structure on $T^{*}S^n$ with $\hat{g}$ and compare it to the reduced symplectic form $\omega_{r}$. If they turn out to agree, then this proves that $\hat{g}$ is a symplectomorphism between $\mu^{-1}(0)/\mathbb{R}$ and $T^{*}S^n$. Now note that the canonical symplectic structure is the (negative of the) differential of the tautological one form $\alpha \in \Omega^{1}(T^{*}S^n)$, which is defined as follows: \begin{equation} \xi_{s} \in T^{*}_{s}S^n, \ \ \alpha(\xi_{s}) = d\tilde{\Pi}^{*}_{\xi_{s}}(\xi_{s}) \in T^{*}_{\xi_{s}}(T^{*}S^n). \end{equation} So we pull this back instead, since we can always take the differential later on. Now $\hat{g}^{*}(\alpha) \in \Omega^{1}(TS^n)$ and at a point $v_{s} \in T_{s}S^n$ we have \begin{equation} \hat{g}^{*}(\alpha)_{v_{s}} = \alpha_{\hat{g}(v_{s})} \circ d\hat{g}_{v_{s}} = \hat{g}(v_{s}) \circ d(\tilde{\Pi} \circ \hat{g})_{v_{s}} = \hat{g}(v_{s}) \circ d\Pi_{v_{s}} = v_{s} \cdot (d\Pi_{v_{s}}(-)), \end{equation} where the last term means taking a dot product in euclidean space. Now how does this act on specific vectors: Take coordinates $(u_{i})$ for $S^n$ around a point $s$. This gives local frame $\frac{\partial}{\partial u_{i}}$ for the tangent bundle. And this in turn gives coordinates $(u_{i}, v_{i})$ for the tangent bundle. That is to say $(u_{i}, v_{i}) \mapsto v_{i}\frac{\partial}{\partial u_{i}}|_{u}$. Now take a vector $(t_{i} \frac{\partial}{\partial u_{i}} + l_{i} \frac{\partial}{\partial v_{i}})$ at a point $(u,v)$. Then  \begin{equation} \hat{g}^{*}(\alpha)_{(u,v)}(t_{i} \frac{\partial}{\partial u_{i}} + l_{i} \frac{\partial}{\partial v_{i}}) = v_{u} \cdot d\Pi_{(u,v)}(t_{i} \frac{\partial}{\partial u_{i}} + l_{i} \frac{\partial}{\partial v_{i}}) = v_{u} \cdot t_{u}. \end{equation} In other words, if we note that $T_{(u,v)}(TS^n) \cong T_{u}S^n \times \mathbb{R}^{n}$, then $\hat{g}^{*}(\alpha)_{(u,v)}(t,l) = v \cdot t$. Now we also have the standard 1-form on $\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$ which is given by $q_{i} dp_{i}$. We can pull this back to $TS^n = N$ using the inclusion $i : N \to \mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$. Since $T_{(q,p)}N \cong \mathbb{R}^{n} \times T_{p}S^{n} \subseteq \mathbb{R}^{n+1}_{q} \times \mathbb{R}^{n+1}_{p}$, for $(l,t) \in T_{(q,p)}N$ we have $i^{*}(q \cdot dp)_{(q,p)}(l,t) = q \cdot dp_{(q,p)} (l + t) = q \cdot dp_{(q,p)}(t) = q \cdot t$. Therefore, $\hat{g}^{*}(\alpha) = i^{*}(q \cdot dp)$ since they have the same effect on vectors. Therefore $\pi^{*}(\hat{g}^{*}(\alpha)) = \pi^{*} i^* (q \cdot dp) = (i \circ \pi)^* (q \cdot dp)$. We wish to compare this with $\iota^{*}(q \cdot dp)$. We do this using coordinates on $\mu^{-1}(0) = \mathbb{R}^{n+1} \times S^n$. We choose coordinates $(q,u) \in \mathbb{R}^{n+1} \times \mathbb{B}^n$, with coordinate map $\phi^{\pm} : \mathbb{R}^{n+1} \times \mathbb{B}^n \to \mu^{-1}(0), \ \ (q,u) \mapsto (q,u,\pm\sqrt{1-|u|^2})$. We also write $q = (\overrightarrow{q}, q_{n+1})$, where $\overrightarrow{q}$ denotes the first $n$ coordinates. In these coordinates then we see that \begin{equation} \iota^{*}(q \cdot dp) = \overrightarrow{q} \cdot du \pm q_{n+1}d\sqrt{1-|u|^2} = \overrightarrow{q} \cdot du - (\pm 1)\frac{q_{n+1} u \cdot du}{\sqrt{1-|u|^2}}. \end{equation} And that (after some cancellation of terms) \begin{equation} \pi^{*}(\hat{g}^{*}(\alpha)) = (i \circ \pi)^* (q \cdot dp) = \overrightarrow{q} \cdot du - (\pm 1)\frac{q_{n+1} u \cdot du}{\sqrt{1-|u|^2}}. \end{equation} Therefore we have shown that $\iota^{*}(q \cdot dp) = \pi^{*} (\hat{g}^{*}(\alpha))$. Taking the differential of both sides and multiplying by $-1$ gives \begin{equation} \iota^{*}(dp_{i} \wedge dq_{i}) = \pi^{*} (\hat{g}^{*}(-d\alpha)), \end{equation} where $-d\alpha$ is the canonical symplectic form on $T^{*}S^n$. And so $\omega_{r} = \hat{g}^{*}(-d\alpha)$, showing that $\hat{g} : (N,\omega_{r}) \to (T^{*}S^n, -d\alpha)$ is a symplectomorphism. The way I exhibit the symplectomorphism uses a lot of extra stuff like the tautological 1-form, and the ambient euclidean metric. I'm wondering if there is a more direct way to see the symplectomorphism. Thanks","I've been working out a nice example of symplectic reduction, and have come to a solution only after quite a lot of effort. So I was wondering if anyone knew a more straightforward route to the answer. This example is about the space of oriented lines in $\mathbb{R}^{n+1}$. Start by considering the symplectic manifold $(\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}, dp_{i} \wedge dq_{i})$, where $(q_{i},p_{i})$ are the coordinates on $\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$. We let $\mathbb{R}$ act on $\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$ as follows: \begin{equation} t \ast (q,p) = (q+tp, p). \end{equation} This action is evidently symplectic. Then define the following moment map  \begin{equation} \mu : \mathbb{R}^{n+1} \times \mathbb{R}^{n+1} \to \mathbb{R}, \ \ \ \ (q,p) \mapsto \frac{1}{2}(|p|^2 - 1). \end{equation} The symplectic quotient is the space $(\mu^{-1}(0)/\mathbb{R}, \omega_{r})$, where $\omega_{r}$ is the reduced symplectic form, which is the unique symplectic form on the quotient $\mu^{-1}(0)/\mathbb{R}$, satisfying \begin{equation} \pi^{*}(\omega_{r}) = \iota^{*}(dp_{i} \wedge dq_{i}), \end{equation} where $\pi : \mu^{-1}(0) \to \mu^{-1}(0)/\mathbb{R}$ is the orbit projection map, and $\iota : \mu^{-1}(0) \to \mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$ is the inclusion. We have the following interpretation of the resulting space: If we restrict to $|p| = 1$, then $p$ specifies a direction in $\mathbb{R}^{n+1}$. The coordinate $q$ specifies a point in $\mathbb{R}^{n+1}$. Therefore, the pair $(q,p)$ singles out the line passing through $q$ in the direction of $p$. Hence $\mu^{-1}(0)$ consists of all the directed lines in $n+1$ dimensional space. However, there is a degeneracy: pairs $(q,p)$, where the $q$ lie along the same line, all pick out the same oriented line. In fact, our action of $\mathbb{R}$ is a symmetry of this interpretation because all points $t \ast (q,p)$ correspond to the same line; each orbit corresponds to a single line. Therefore $\mu^{-1}(0)/\mathbb{R}$ is the space of oriented lines. Now we want to describe the geometry of this space, and to do so we should pick a representative from each orbit. The natural choice for each line is to pick the closest point to the origin. Given a line specified by $(q,p)$, this point is $(q - (q \cdot p)p, p)$. Note that $(q - (q \cdot p)p) \cdot p = 0$. The two coordinates of this representative are orthogonal. So if we define $N$ to be the following embedded submanifold of $ \mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$: \begin{equation} N = \{ (q,p) \in  \mathbb{R}^{n+1} \times \mathbb{R}^{n+1} \ | \ |p| = 1, \ q \cdot p = 0\}, \end{equation} then we can describe the orbit projection map $\pi$ as the smooth submersion \begin{equation} \pi : \mu^{-1}(0) \to N, \ \ (q,p) \mapsto (q - (q \cdot p)p, p). \end{equation} Now note that the image $N$ is nothing but the tangent bundle of the n-sphere $TS^n$, and that this is isomorphic to the cotangent bundle of the n-sphere $T^{*}S^{n}$. I want to show that in fact, $N$ is symplectomorphic to $T^{*}S^{n}$ with the canonical symplectic structure ( http://en.wikipedia.org/wiki/Cotangent_bundle#Symplectic_form ). This is where I'm a little less sure about how to proceed. My idea is as follows: We can use the standard Euclidean metric $g$ on the ambient space $\mathbb{R}^{n+1}$ to induce a metric on the sphere $S^n$. This induces a vector bundle isomorphism between the tangent and cotangent bundles of $S^n$ which covers the identity on $S^n$ \begin{equation} \hat{g} : TS^n \to T^{*}S^n, \ \ v_{s} \mapsto g_{s}(v_{s}, -). \end{equation}  Note that this means that if $\Pi : TS^n \to S^n$ and $\tilde{\Pi} : T^{*}S^n \to S^n$ are the projection maps, then $\tilde{\Pi} \circ \hat{g} = \Pi$. I want to now pull back the canonical symplectic structure on $T^{*}S^n$ with $\hat{g}$ and compare it to the reduced symplectic form $\omega_{r}$. If they turn out to agree, then this proves that $\hat{g}$ is a symplectomorphism between $\mu^{-1}(0)/\mathbb{R}$ and $T^{*}S^n$. Now note that the canonical symplectic structure is the (negative of the) differential of the tautological one form $\alpha \in \Omega^{1}(T^{*}S^n)$, which is defined as follows: \begin{equation} \xi_{s} \in T^{*}_{s}S^n, \ \ \alpha(\xi_{s}) = d\tilde{\Pi}^{*}_{\xi_{s}}(\xi_{s}) \in T^{*}_{\xi_{s}}(T^{*}S^n). \end{equation} So we pull this back instead, since we can always take the differential later on. Now $\hat{g}^{*}(\alpha) \in \Omega^{1}(TS^n)$ and at a point $v_{s} \in T_{s}S^n$ we have \begin{equation} \hat{g}^{*}(\alpha)_{v_{s}} = \alpha_{\hat{g}(v_{s})} \circ d\hat{g}_{v_{s}} = \hat{g}(v_{s}) \circ d(\tilde{\Pi} \circ \hat{g})_{v_{s}} = \hat{g}(v_{s}) \circ d\Pi_{v_{s}} = v_{s} \cdot (d\Pi_{v_{s}}(-)), \end{equation} where the last term means taking a dot product in euclidean space. Now how does this act on specific vectors: Take coordinates $(u_{i})$ for $S^n$ around a point $s$. This gives local frame $\frac{\partial}{\partial u_{i}}$ for the tangent bundle. And this in turn gives coordinates $(u_{i}, v_{i})$ for the tangent bundle. That is to say $(u_{i}, v_{i}) \mapsto v_{i}\frac{\partial}{\partial u_{i}}|_{u}$. Now take a vector $(t_{i} \frac{\partial}{\partial u_{i}} + l_{i} \frac{\partial}{\partial v_{i}})$ at a point $(u,v)$. Then  \begin{equation} \hat{g}^{*}(\alpha)_{(u,v)}(t_{i} \frac{\partial}{\partial u_{i}} + l_{i} \frac{\partial}{\partial v_{i}}) = v_{u} \cdot d\Pi_{(u,v)}(t_{i} \frac{\partial}{\partial u_{i}} + l_{i} \frac{\partial}{\partial v_{i}}) = v_{u} \cdot t_{u}. \end{equation} In other words, if we note that $T_{(u,v)}(TS^n) \cong T_{u}S^n \times \mathbb{R}^{n}$, then $\hat{g}^{*}(\alpha)_{(u,v)}(t,l) = v \cdot t$. Now we also have the standard 1-form on $\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$ which is given by $q_{i} dp_{i}$. We can pull this back to $TS^n = N$ using the inclusion $i : N \to \mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$. Since $T_{(q,p)}N \cong \mathbb{R}^{n} \times T_{p}S^{n} \subseteq \mathbb{R}^{n+1}_{q} \times \mathbb{R}^{n+1}_{p}$, for $(l,t) \in T_{(q,p)}N$ we have $i^{*}(q \cdot dp)_{(q,p)}(l,t) = q \cdot dp_{(q,p)} (l + t) = q \cdot dp_{(q,p)}(t) = q \cdot t$. Therefore, $\hat{g}^{*}(\alpha) = i^{*}(q \cdot dp)$ since they have the same effect on vectors. Therefore $\pi^{*}(\hat{g}^{*}(\alpha)) = \pi^{*} i^* (q \cdot dp) = (i \circ \pi)^* (q \cdot dp)$. We wish to compare this with $\iota^{*}(q \cdot dp)$. We do this using coordinates on $\mu^{-1}(0) = \mathbb{R}^{n+1} \times S^n$. We choose coordinates $(q,u) \in \mathbb{R}^{n+1} \times \mathbb{B}^n$, with coordinate map $\phi^{\pm} : \mathbb{R}^{n+1} \times \mathbb{B}^n \to \mu^{-1}(0), \ \ (q,u) \mapsto (q,u,\pm\sqrt{1-|u|^2})$. We also write $q = (\overrightarrow{q}, q_{n+1})$, where $\overrightarrow{q}$ denotes the first $n$ coordinates. In these coordinates then we see that \begin{equation} \iota^{*}(q \cdot dp) = \overrightarrow{q} \cdot du \pm q_{n+1}d\sqrt{1-|u|^2} = \overrightarrow{q} \cdot du - (\pm 1)\frac{q_{n+1} u \cdot du}{\sqrt{1-|u|^2}}. \end{equation} And that (after some cancellation of terms) \begin{equation} \pi^{*}(\hat{g}^{*}(\alpha)) = (i \circ \pi)^* (q \cdot dp) = \overrightarrow{q} \cdot du - (\pm 1)\frac{q_{n+1} u \cdot du}{\sqrt{1-|u|^2}}. \end{equation} Therefore we have shown that $\iota^{*}(q \cdot dp) = \pi^{*} (\hat{g}^{*}(\alpha))$. Taking the differential of both sides and multiplying by $-1$ gives \begin{equation} \iota^{*}(dp_{i} \wedge dq_{i}) = \pi^{*} (\hat{g}^{*}(-d\alpha)), \end{equation} where $-d\alpha$ is the canonical symplectic form on $T^{*}S^n$. And so $\omega_{r} = \hat{g}^{*}(-d\alpha)$, showing that $\hat{g} : (N,\omega_{r}) \to (T^{*}S^n, -d\alpha)$ is a symplectomorphism. The way I exhibit the symplectomorphism uses a lot of extra stuff like the tautological 1-form, and the ambient euclidean metric. I'm wondering if there is a more direct way to see the symplectomorphism. Thanks",,"['differential-geometry', 'riemannian-geometry', 'symplectic-geometry']"
43,Riemannian Metric Notation,Riemannian Metric Notation,,"I am just being introduced to Riemannian metrics, and I am having a bit of confusion on the notation.  When reading, I've encountered some different notation in different sources, so I want to make sure I'm understanding what the different notation means.  I'm sure there are lots of misunderstandings in what follows, so I'd appreciate if someone could correct them. Say for example we have $\mathbb{R}^2$ in canonical coordinates, and we're going to use the usual dot product $\langle x,y \rangle = x_1y_1 + x_2y_2$, where $x=(x_1,x_2)$ and $y=(y_1,y_2)$.  Then the Riemannian metric would be the $2 \times 2$ identity matrix, so that $$\begin{pmatrix} x_1 & x_2 \end{pmatrix} \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \end{pmatrix} = x_1y_1+x_2y_2,$$ so $g_{ij} = \delta_{ij}$.  This notation makes sense to me, but I am confused about the notation $g = dx^2+dy^2$.  Do $dx$ and $dy$ denote linear functionals in the dual space?  And if they do, then is $dx = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$ and $dy = \begin{pmatrix} 0 \\ 1 \end{pmatrix}$?  This doesn't seem right, because the dimensions of the matrices wouldn't come out correctly. Then say we want to convert this to polar coordinates, so $x=r \cos \theta$ and $y=r \sin \theta$.  Then do we have $$g = \begin{pmatrix} 1 & 0 \\ 0 & r^2 \end{pmatrix} = dr^2 + r^2 d \theta^2?$$  Then to get the inner product, we would do $$\begin{pmatrix} r_1 & \theta_1 \end{pmatrix} \begin{pmatrix} 1 & 0 \\ 0 & r^2 \end{pmatrix} \begin{pmatrix} r_2 \\ \theta_2 \end{pmatrix} = r_1r_2 + r^2 \theta_1 \theta_2?$$  If this is correct, then what does the $r^2$ in the metric represent in the calculation?  Is it the $r$ that corresponds to the point at which we're defining the metric?  Like, if we wanted $\langle v,w \rangle$ where $v = (3,\pi/2)$ and $w = (5,\pi/4)$, what does the expression $$\langle v,w \rangle = 3 \cdot 5 + r^2 \cdot \dfrac{\pi}{2} \cdot \dfrac{\pi}{4}$$ mean, intuitively? Thanks in advance for the help. P.S. Other examples, or links to well-explained other examples would be much appreciated.","I am just being introduced to Riemannian metrics, and I am having a bit of confusion on the notation.  When reading, I've encountered some different notation in different sources, so I want to make sure I'm understanding what the different notation means.  I'm sure there are lots of misunderstandings in what follows, so I'd appreciate if someone could correct them. Say for example we have $\mathbb{R}^2$ in canonical coordinates, and we're going to use the usual dot product $\langle x,y \rangle = x_1y_1 + x_2y_2$, where $x=(x_1,x_2)$ and $y=(y_1,y_2)$.  Then the Riemannian metric would be the $2 \times 2$ identity matrix, so that $$\begin{pmatrix} x_1 & x_2 \end{pmatrix} \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \end{pmatrix} = x_1y_1+x_2y_2,$$ so $g_{ij} = \delta_{ij}$.  This notation makes sense to me, but I am confused about the notation $g = dx^2+dy^2$.  Do $dx$ and $dy$ denote linear functionals in the dual space?  And if they do, then is $dx = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$ and $dy = \begin{pmatrix} 0 \\ 1 \end{pmatrix}$?  This doesn't seem right, because the dimensions of the matrices wouldn't come out correctly. Then say we want to convert this to polar coordinates, so $x=r \cos \theta$ and $y=r \sin \theta$.  Then do we have $$g = \begin{pmatrix} 1 & 0 \\ 0 & r^2 \end{pmatrix} = dr^2 + r^2 d \theta^2?$$  Then to get the inner product, we would do $$\begin{pmatrix} r_1 & \theta_1 \end{pmatrix} \begin{pmatrix} 1 & 0 \\ 0 & r^2 \end{pmatrix} \begin{pmatrix} r_2 \\ \theta_2 \end{pmatrix} = r_1r_2 + r^2 \theta_1 \theta_2?$$  If this is correct, then what does the $r^2$ in the metric represent in the calculation?  Is it the $r$ that corresponds to the point at which we're defining the metric?  Like, if we wanted $\langle v,w \rangle$ where $v = (3,\pi/2)$ and $w = (5,\pi/4)$, what does the expression $$\langle v,w \rangle = 3 \cdot 5 + r^2 \cdot \dfrac{\pi}{2} \cdot \dfrac{\pi}{4}$$ mean, intuitively? Thanks in advance for the help. P.S. Other examples, or links to well-explained other examples would be much appreciated.",,"['differential-geometry', 'riemannian-geometry']"
44,What is wrong with this exercise in do Carmo's Differential Geometry?,What is wrong with this exercise in do Carmo's Differential Geometry?,,"This is an exercise in do Carmo's Differential Geometry: Let $\alpha : I \longrightarrow S$ be a curve parametrized by arc length $s$, with nonzero curvature. Consider the parametrized surface \begin{align}\textbf{x}(s,v)=\alpha(s)+vb(s), & s \in I, -\epsilon < v < \epsilon, \epsilon > 0\end{align}   where $b$ is the binormal vector of $\alpha$. Prove that if $\epsilon$ is small, $\textbf{x}(I \times (-\epsilon, \epsilon)) = S$ is a regular surface over which $\alpha(I)$ is a geodesic ( thus, every curve is a geodesic on the surface generated by its binormals ). An errata online says that the first conclusion of this exercise is wrong: p. 262. Exercise 17: The first conclusion is false: It can happen that for all $\epsilon > 0$, the set $\textbf{x}(I \times (-\epsilon,\epsilon))$ fails to be a regular surface. (Consider a curve $\alpha : (0,1) \rightarrow \mathbb{R}^3$ such that $\alpha(s)$ approaches $(0,0,0)$ from the same direction as $s \rightarrow 0^+$ or $s \rightarrow 1^-$, and such that the part of $\alpha$ near $s=0$ is contained in a plane, and the part of $\alpha$ near $s=1$ is contained in a different plane.) I don't quite understand the counterexample in the errata. Can somebody help to explicitly construct the curve $\alpha$?","This is an exercise in do Carmo's Differential Geometry: Let $\alpha : I \longrightarrow S$ be a curve parametrized by arc length $s$, with nonzero curvature. Consider the parametrized surface \begin{align}\textbf{x}(s,v)=\alpha(s)+vb(s), & s \in I, -\epsilon < v < \epsilon, \epsilon > 0\end{align}   where $b$ is the binormal vector of $\alpha$. Prove that if $\epsilon$ is small, $\textbf{x}(I \times (-\epsilon, \epsilon)) = S$ is a regular surface over which $\alpha(I)$ is a geodesic ( thus, every curve is a geodesic on the surface generated by its binormals ). An errata online says that the first conclusion of this exercise is wrong: p. 262. Exercise 17: The first conclusion is false: It can happen that for all $\epsilon > 0$, the set $\textbf{x}(I \times (-\epsilon,\epsilon))$ fails to be a regular surface. (Consider a curve $\alpha : (0,1) \rightarrow \mathbb{R}^3$ such that $\alpha(s)$ approaches $(0,0,0)$ from the same direction as $s \rightarrow 0^+$ or $s \rightarrow 1^-$, and such that the part of $\alpha$ near $s=0$ is contained in a plane, and the part of $\alpha$ near $s=1$ is contained in a different plane.) I don't quite understand the counterexample in the errata. Can somebody help to explicitly construct the curve $\alpha$?",,[]
45,Geodesic on a Riemannian manifold with a random metric tensor,Geodesic on a Riemannian manifold with a random metric tensor,,"Given a metric tensor $g_{\mu\nu}$ on a Riemannian manifold, it's possible to write the geodesic equations using: $$\frac{d^2x^a}{ds^2} + \Gamma^{a}_{bc}\frac{dx^b}{ds}\frac{dx^c}{ds} = 0$$ where: $$\Gamma^a_{bc} = \frac{1}{2} g^{ad} \left( g_{cd,b} + g_{bd,c} - g_{bc,d} \right)$$ are the Christoffel symbols. In the euclidean metrics, the tensor $g_{\mu\nu}$ is given by the identity matrix $I.$ Suppose we have: $$g_{\mu\nu} =  \begin{pmatrix}   1 & \eta_1(t) &  \eta_2(t) \\   0 & 1 &  \eta_3(t) \\     \\   0 & 0 & 1  \end{pmatrix}$$ with: $\eta_k(t)$ random variables normally distribuited with variance: $\sigma_1,\sigma_2,\sigma_3$, and zero means, how can I write down the geodesic equations? Thanks in advance.","Given a metric tensor $g_{\mu\nu}$ on a Riemannian manifold, it's possible to write the geodesic equations using: $$\frac{d^2x^a}{ds^2} + \Gamma^{a}_{bc}\frac{dx^b}{ds}\frac{dx^c}{ds} = 0$$ where: $$\Gamma^a_{bc} = \frac{1}{2} g^{ad} \left( g_{cd,b} + g_{bd,c} - g_{bc,d} \right)$$ are the Christoffel symbols. In the euclidean metrics, the tensor $g_{\mu\nu}$ is given by the identity matrix $I.$ Suppose we have: $$g_{\mu\nu} =  \begin{pmatrix}   1 & \eta_1(t) &  \eta_2(t) \\   0 & 1 &  \eta_3(t) \\     \\   0 & 0 & 1  \end{pmatrix}$$ with: $\eta_k(t)$ random variables normally distribuited with variance: $\sigma_1,\sigma_2,\sigma_3$, and zero means, how can I write down the geodesic equations? Thanks in advance.",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
46,"If $\omega^k$ is exact, is $\omega$ exact?","If  is exact, is  exact?",\omega^k \omega,"Let $\omega$ be a differential form on a manifold and suppose $\omega^k$ is exact (but non-zero). Is $\omega$ necessarily exact? Note, the converse is true. If $\omega$ is exact, then $\omega^k$ is exact. To see this, let $\omega = d\alpha$, then $$\omega^k = (d\alpha)^k = d\alpha\wedge\dots\wedge d\alpha = d(\alpha\wedge d\alpha \wedge\dots\wedge d\alpha).$$ The case I am interested in, $\omega$ is a two-form and the manifold is compact, but I'd be interested to see what can be said in general.","Let $\omega$ be a differential form on a manifold and suppose $\omega^k$ is exact (but non-zero). Is $\omega$ necessarily exact? Note, the converse is true. If $\omega$ is exact, then $\omega^k$ is exact. To see this, let $\omega = d\alpha$, then $$\omega^k = (d\alpha)^k = d\alpha\wedge\dots\wedge d\alpha = d(\alpha\wedge d\alpha \wedge\dots\wedge d\alpha).$$ The case I am interested in, $\omega$ is a two-form and the manifold is compact, but I'd be interested to see what can be said in general.",,['differential-geometry']
47,Are geodesic flows on surfaces with negative curvature Anosov?,Are geodesic flows on surfaces with negative curvature Anosov?,,"I'm just going through the original book by Anosov, where he tries to proof this result. I don't quite understand it. So let $\phi_t:TM\rightarrow TM$ be a geodesic flow on a compact surface $M$ of negative curvature. Let $\theta=(x,v)\in TM$, then there exists an isomorphism $T_\theta TM\cong T_pM\oplus T_pM$ So how can we find stable and unstable directions and show that vectors in this direction contract or expand exponentially, as it is required by an Anosov flow? First of all, I understand that the direction of the flow itself is invariant and the phase velocity stays constant there. Then I have also understood that a vector $\xi=(\xi_h,\xi_ v)\in T_pM\oplus T_pM$, that is transversal to the flow direction will have a length that is convex for all $t$, i.e.  \begin{equation} \frac{d^2}{dt^2}\Big|\;\xi\;\Big|^2>0 \end{equation} But how do we conclude the existence of contracting and expanding directions from this? What is your approach? Sometimes I have seen people using Jacobi fields. But I don't know how to do that? Thanks in advance btw. do you know how to show that the geodesic flow on $M$, as above, has no conjugate points?","I'm just going through the original book by Anosov, where he tries to proof this result. I don't quite understand it. So let $\phi_t:TM\rightarrow TM$ be a geodesic flow on a compact surface $M$ of negative curvature. Let $\theta=(x,v)\in TM$, then there exists an isomorphism $T_\theta TM\cong T_pM\oplus T_pM$ So how can we find stable and unstable directions and show that vectors in this direction contract or expand exponentially, as it is required by an Anosov flow? First of all, I understand that the direction of the flow itself is invariant and the phase velocity stays constant there. Then I have also understood that a vector $\xi=(\xi_h,\xi_ v)\in T_pM\oplus T_pM$, that is transversal to the flow direction will have a length that is convex for all $t$, i.e.  \begin{equation} \frac{d^2}{dt^2}\Big|\;\xi\;\Big|^2>0 \end{equation} But how do we conclude the existence of contracting and expanding directions from this? What is your approach? Sometimes I have seen people using Jacobi fields. But I don't know how to do that? Thanks in advance btw. do you know how to show that the geodesic flow on $M$, as above, has no conjugate points?",,"['differential-geometry', 'dynamical-systems', 'ergodic-theory']"
48,"Equivalence of two definitions of Lie bracket of vector fields $[X,Y]$ in terms of derivatives and differential of flows",Equivalence of two definitions of Lie bracket of vector fields  in terms of derivatives and differential of flows,"[X,Y]","Lie bracket of vector fields is defined in two ways: Let $\Phi^X_t$ be the flow associated with the vector field $X$, and let $d$ denote the   tangent map derivative operator. Then   the Lie bracket of $X$ and $Y$ at the point $x \in M$ can   be defined as $[X, Y]_x := \lim_{t \to 0}\frac{(\mathrm{d}\Phi^X_{-t}) Y_{\Phi^X_t(x)} - Y_x}t = \left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} (\mathrm{d}\Phi^X_{-t}) Y_{\Phi^X_t(x)}$ or equivalently $[X, Y]_x := \left.\frac12\frac{\mathrm{d}^2}{\mathrm{dt}^2}\right|_{t=0}  (\Phi^Y_{-t} \circ \Phi^X_{-t} \circ \Phi^Y_{t} \circ \Phi^X_{t})(x) = \left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} (\Phi^Y_{-\sqrt{t}} \circ \Phi^X_{-\sqrt{t}} \circ \Phi^Y_{\sqrt{t}} \circ \Phi^X_{\sqrt{t}})(x)$ How does one show by math that these two definitions are equivalent? And for the second definition, how does one show that $\left.\frac12\frac{\mathrm{d}^2}{\mathrm{dt}^2}\right|_{t=0}  (\Phi^Y_{-t} \circ \Phi^X_{-t} \circ \Phi^Y_{t} \circ \Phi^X_{t})(x) = \left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} (\Phi^Y_{-\sqrt{t}} \circ \Phi^X_{-\sqrt{t}} \circ \Phi^Y_{\sqrt{t}} \circ \Phi^X_{\sqrt{t}})(x)$?","Lie bracket of vector fields is defined in two ways: Let $\Phi^X_t$ be the flow associated with the vector field $X$, and let $d$ denote the   tangent map derivative operator. Then   the Lie bracket of $X$ and $Y$ at the point $x \in M$ can   be defined as $[X, Y]_x := \lim_{t \to 0}\frac{(\mathrm{d}\Phi^X_{-t}) Y_{\Phi^X_t(x)} - Y_x}t = \left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} (\mathrm{d}\Phi^X_{-t}) Y_{\Phi^X_t(x)}$ or equivalently $[X, Y]_x := \left.\frac12\frac{\mathrm{d}^2}{\mathrm{dt}^2}\right|_{t=0}  (\Phi^Y_{-t} \circ \Phi^X_{-t} \circ \Phi^Y_{t} \circ \Phi^X_{t})(x) = \left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} (\Phi^Y_{-\sqrt{t}} \circ \Phi^X_{-\sqrt{t}} \circ \Phi^Y_{\sqrt{t}} \circ \Phi^X_{\sqrt{t}})(x)$ How does one show by math that these two definitions are equivalent? And for the second definition, how does one show that $\left.\frac12\frac{\mathrm{d}^2}{\mathrm{dt}^2}\right|_{t=0}  (\Phi^Y_{-t} \circ \Phi^X_{-t} \circ \Phi^Y_{t} \circ \Phi^X_{t})(x) = \left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} (\Phi^Y_{-\sqrt{t}} \circ \Phi^X_{-\sqrt{t}} \circ \Phi^Y_{\sqrt{t}} \circ \Phi^X_{\sqrt{t}})(x)$?",,"['differential-geometry', 'lie-algebras', 'vector-fields']"
49,What to give as final lecture in a differential geometry class?,What to give as final lecture in a differential geometry class?,,"During the fall semester, I had to give an exercise class to second year math students, as support for a theoretical class loosely based on the book `Differential geometry of curves and surfaces' by Do Carmo. Now and then I succeeded in squeezing in some fun topics not covered in the theory class, like the four-vertex theorem, minimal surfaces, de Rham cohomology of $\mathbb{R^{3}}$, ... Next week I have to give the last class, and I want to finish with some very nice theorem or set of ideas. Does anyone have any experience with this? Maybe someone was once in a class that tried to do something similar? There are a couple of criteria: It should take about an hour to explain It should only need the embedded definition of a variety, not the intrinsic one It is around the level of Do Carmo The prerequisites are the first and second fundamental form, normal and Gauss curvatures, the theorema egregium and basic ideas on geodesics and geodesic curvature. One of the physicists in the class asked me to say something about general relativity and differential geometry, but having looked through a number of references, this seems rather hard.","During the fall semester, I had to give an exercise class to second year math students, as support for a theoretical class loosely based on the book `Differential geometry of curves and surfaces' by Do Carmo. Now and then I succeeded in squeezing in some fun topics not covered in the theory class, like the four-vertex theorem, minimal surfaces, de Rham cohomology of $\mathbb{R^{3}}$, ... Next week I have to give the last class, and I want to finish with some very nice theorem or set of ideas. Does anyone have any experience with this? Maybe someone was once in a class that tried to do something similar? There are a couple of criteria: It should take about an hour to explain It should only need the embedded definition of a variety, not the intrinsic one It is around the level of Do Carmo The prerequisites are the first and second fundamental form, normal and Gauss curvatures, the theorema egregium and basic ideas on geodesics and geodesic curvature. One of the physicists in the class asked me to say something about general relativity and differential geometry, but having looked through a number of references, this seems rather hard.",,"['differential-geometry', 'education']"
50,Differential of Det Map,Differential of Det Map,,"I want to prove differential of det map at some matrix $A$ is given by $f(A)\operatorname{tr}(X)$ let $f:GL_n(\mathbb{R})\rightarrow\mathbb{R}$ is det map i.e $f(A)=\det A$, claim: $f_{*}(AX)=(f(A))\operatorname{tr}(X)$ proof of claim: Let a curve $c(t)=Ae^{tX}$ such that $c(0)=A,c'(0)=AX$. using this curve we calculate differential $f_{A{*}}(AX)=\frac{d}{dt}|_{t=0}f(c(t))=c'(t)|_{t=0}f(c(t))|_{t=0}=AXf(A)=AX(\det A)$, where am I getting wrong? Thank you.","I want to prove differential of det map at some matrix $A$ is given by $f(A)\operatorname{tr}(X)$ let $f:GL_n(\mathbb{R})\rightarrow\mathbb{R}$ is det map i.e $f(A)=\det A$, claim: $f_{*}(AX)=(f(A))\operatorname{tr}(X)$ proof of claim: Let a curve $c(t)=Ae^{tX}$ such that $c(0)=A,c'(0)=AX$. using this curve we calculate differential $f_{A{*}}(AX)=\frac{d}{dt}|_{t=0}f(c(t))=c'(t)|_{t=0}f(c(t))|_{t=0}=AXf(A)=AX(\det A)$, where am I getting wrong? Thank you.",,"['differential-geometry', 'lie-groups']"
51,Proof of Bochner formula/ Weitzenböck formula in a non-normal frame,Proof of Bochner formula/ Weitzenböck formula in a non-normal frame,,"The proof of the classical  Weitzenböck  formula $$ \Delta (|f|^2)=|{\rm Hess}f|^2+\langle\nabla f, \nabla (\Delta f) +{\rm Ric} (\nabla f, \nabla f) \rangle $$ uses the local orthonormal frame field $X_i$ around any fixed point $p\in M$ satisfy  $$ \langle X_i, X_j \rangle =\delta_{ij}, \ \ \nabla_{X_i}X_j(p)=0 $$ to simplify the calculation. My question is: What if I start with arbitary orthonormal fram say $\{e_1, \cdots, e_n\}$. My calculation shows that for any fixed $\alpha=1,\cdots,n$, the following holds: $$ \begin{align} {\rm Hess}(|\nabla f|^2)(e_{\alpha}, e_{\alpha})= &2|\nabla f|^2 {\rm sec}(\nabla f, e_{\alpha}) + 2\nabla f \langle \nabla_{e_{\alpha}}\nabla f, e_{\alpha}\rangle +2 \langle \nabla _{e_{\alpha}}\nabla f, \nabla_{e_{\alpha}}\nabla f\rangle \\ &- 4\langle \nabla_{e_{\alpha}}\nabla f, \nabla_{\nabla f}e_{\alpha}\rangle \end{align} $$ Where the ${\rm sec}$ denotes the sectional curvature spaned by $\nabla f$ and $e_{\alpha}$, . The only difference between the standard calculation using normal fram and mine is the term $$- 4\langle \nabla_{e_{\alpha}}\nabla f, \nabla_{\nabla f}e_{\alpha}\rangle $$ So it means after summing up over $1, \cdots , n$, we must get $0$. i.e. $$ \sum_{\alpha} - 4\langle \nabla_{e_{\alpha}}\nabla f, \nabla_{\nabla f}e_{\alpha}\rangle=0 $$ But this seems not obvious to me. Did I miss something? The classical calculation can be found here: The Comparison Geometry of Ricci Curvature, by Shunhui Zhu, 221-262 http://library.msri.org/books/Book30/contents.html","The proof of the classical  Weitzenböck  formula $$ \Delta (|f|^2)=|{\rm Hess}f|^2+\langle\nabla f, \nabla (\Delta f) +{\rm Ric} (\nabla f, \nabla f) \rangle $$ uses the local orthonormal frame field $X_i$ around any fixed point $p\in M$ satisfy  $$ \langle X_i, X_j \rangle =\delta_{ij}, \ \ \nabla_{X_i}X_j(p)=0 $$ to simplify the calculation. My question is: What if I start with arbitary orthonormal fram say $\{e_1, \cdots, e_n\}$. My calculation shows that for any fixed $\alpha=1,\cdots,n$, the following holds: $$ \begin{align} {\rm Hess}(|\nabla f|^2)(e_{\alpha}, e_{\alpha})= &2|\nabla f|^2 {\rm sec}(\nabla f, e_{\alpha}) + 2\nabla f \langle \nabla_{e_{\alpha}}\nabla f, e_{\alpha}\rangle +2 \langle \nabla _{e_{\alpha}}\nabla f, \nabla_{e_{\alpha}}\nabla f\rangle \\ &- 4\langle \nabla_{e_{\alpha}}\nabla f, \nabla_{\nabla f}e_{\alpha}\rangle \end{align} $$ Where the ${\rm sec}$ denotes the sectional curvature spaned by $\nabla f$ and $e_{\alpha}$, . The only difference between the standard calculation using normal fram and mine is the term $$- 4\langle \nabla_{e_{\alpha}}\nabla f, \nabla_{\nabla f}e_{\alpha}\rangle $$ So it means after summing up over $1, \cdots , n$, we must get $0$. i.e. $$ \sum_{\alpha} - 4\langle \nabla_{e_{\alpha}}\nabla f, \nabla_{\nabla f}e_{\alpha}\rangle=0 $$ But this seems not obvious to me. Did I miss something? The classical calculation can be found here: The Comparison Geometry of Ricci Curvature, by Shunhui Zhu, 221-262 http://library.msri.org/books/Book30/contents.html",,"['differential-geometry', 'riemannian-geometry']"
52,What is the precise relationship between connections in differential geometry and Kähler differentials?,What is the precise relationship between connections in differential geometry and Kähler differentials?,,"I've been reading some differential geometry at my leisure, and I couldn't help but getting a very familiar feeling when I've read the definition of a connection: A derivation of $M$ (or in some notations, the derivation of the identity map $M\rightarrow M$) is defined as: a function, $D$, that takes tensor fields to tensor fields of the same type, such that $D(C \otimes A)=D(C) \otimes A + C\otimes D(A)$ for any two tensor fields $C$ and $D$, and such that $D(aA+bB)=aD(A)+bD(B)$ for any two tensor fields $A$ and $B$ and (real) scalars $a$ and $b$. A connection is defined as a function $\nabla$ that takes a vector field $X$ to a derivation $\nabla _X$, such that $\nabla$ satisfies: If $f$ is a function on $M$ then $\nabla_X(f)=Xf$, and $\nabla$ is linear (for the module of vector fields over the ring of $C^{\infty}$-functions), and such that $\nabla_X$ commutes with contraction. This was the first time I saw the definition of a connection formulated in this way, and it is very reminiscent of themes in Kähler differentials. I wonder if there is a rigorous relationship between the two notions.","I've been reading some differential geometry at my leisure, and I couldn't help but getting a very familiar feeling when I've read the definition of a connection: A derivation of $M$ (or in some notations, the derivation of the identity map $M\rightarrow M$) is defined as: a function, $D$, that takes tensor fields to tensor fields of the same type, such that $D(C \otimes A)=D(C) \otimes A + C\otimes D(A)$ for any two tensor fields $C$ and $D$, and such that $D(aA+bB)=aD(A)+bD(B)$ for any two tensor fields $A$ and $B$ and (real) scalars $a$ and $b$. A connection is defined as a function $\nabla$ that takes a vector field $X$ to a derivation $\nabla _X$, such that $\nabla$ satisfies: If $f$ is a function on $M$ then $\nabla_X(f)=Xf$, and $\nabla$ is linear (for the module of vector fields over the ring of $C^{\infty}$-functions), and such that $\nabla_X$ commutes with contraction. This was the first time I saw the definition of a connection formulated in this way, and it is very reminiscent of themes in Kähler differentials. I wonder if there is a rigorous relationship between the two notions.",,"['algebraic-geometry', 'differential-geometry']"
53,Help Antie evaluate Gauss curvature of a smooth surface using ruler and a protractor,Help Antie evaluate Gauss curvature of a smooth surface using ruler and a protractor,,"Antie, a smart ant living on a smooth surface $S$ of $\mathbb{R}^3$ , would like to evaluate the Gauss curvature $K$ at a certain point $P\in S$ . Antie is aware of Gauss Theorema Egregium, according to which Gauss curvature may be evaluated using the first fundamental form of the surface. So, Antie grabs a ruler and a  protractor, determines a neighbourhood  around $P$ and is ready to start calculating, since it has heard that the first fundamental form is related to lengths and angles around $P$ (words like tangent space do not really make sense to Antie). Αntie knows that if he knew some quantities, called $E$ , $F$ , $G$ , then it would be able to evaluate $K$ . But of course Antie is not aware of the way the surface is embedded in space $\mathbb{R}^3$ and its local parametrization $\sigma(u,v)=( \sigma_1(u,v),   \sigma_2(u,v),\sigma_3(u,v))$ around $P$ (in order to evaluate $E=\sigma_u\cdot \sigma_u$ etc around $P$ ). How would we help Antie calculate all the quantities needed for Gauss curvature $K$ at $P$ ?","Antie, a smart ant living on a smooth surface of , would like to evaluate the Gauss curvature at a certain point . Antie is aware of Gauss Theorema Egregium, according to which Gauss curvature may be evaluated using the first fundamental form of the surface. So, Antie grabs a ruler and a  protractor, determines a neighbourhood  around and is ready to start calculating, since it has heard that the first fundamental form is related to lengths and angles around (words like tangent space do not really make sense to Antie). Αntie knows that if he knew some quantities, called , , , then it would be able to evaluate . But of course Antie is not aware of the way the surface is embedded in space and its local parametrization around (in order to evaluate etc around ). How would we help Antie calculate all the quantities needed for Gauss curvature at ?","S \mathbb{R}^3 K P\in S P P E F G K \mathbb{R}^3 \sigma(u,v)=( \sigma_1(u,v),   \sigma_2(u,v),\sigma_3(u,v)) P E=\sigma_u\cdot \sigma_u P K P","['differential-geometry', 'surfaces', 'curvature']"
54,Is the $n/2$-th heat kernel coefficient topological?,Is the -th heat kernel coefficient topological?,n/2,"Let $M$ be an $n$ -dimensional manifold, with $n$ even and consider the heat kernel of the Laplacian on $M$ : $$K_M(t) := \mathrm{Tr}\Big(\mathrm{e}^{-t \Delta_M}\Big) \equiv \sum_{\lambda\in\mathrm{spec}(\Delta_M)} \mathrm{e}^{-t \lambda}.$$ The heat kernel admits an asympotic small- $t$ expansion as $$K_M(t) = \frac{1}{(4\pi t)^{n/2}}\sum_{k=0}^\infty b_k(M) t^k,$$ where $b_k(M)$ are known as the heat kernel coefficients and are given by integrals of local geometric data of $M$ . I am particularly interested in what I'll call middle-dimensional heat kernel coefficient , namely $$ b_{n/2}(M) = b_{\mathrm{dim}M/2}(M).$$ This coefficient is interesting because it is closely related to the value of the Minakshisundaram-Pleijel zeta function (i.e. the spectral zeta function for the Laplacian) at zero. Is an explicit formula for the calculation of $b_{n/2}(M)$ known? In particular, is it a topological invariant? It seems to me that it wants to be related to the number of connected components of $M$ or to some sum of Betti numbers of $M$ , but I haven't managed to show it. (If anyone feels brave, I'd be curious about how it generalizes to $p$ -forms; namely what's the middle-dimensional heat kernel coefficient associated with the Laplacian, $\Delta_p = \mathrm{d}\delta + \delta \mathrm{d}$ , acting on $p$ -forms on $M$ )","Let be an -dimensional manifold, with even and consider the heat kernel of the Laplacian on : The heat kernel admits an asympotic small- expansion as where are known as the heat kernel coefficients and are given by integrals of local geometric data of . I am particularly interested in what I'll call middle-dimensional heat kernel coefficient , namely This coefficient is interesting because it is closely related to the value of the Minakshisundaram-Pleijel zeta function (i.e. the spectral zeta function for the Laplacian) at zero. Is an explicit formula for the calculation of known? In particular, is it a topological invariant? It seems to me that it wants to be related to the number of connected components of or to some sum of Betti numbers of , but I haven't managed to show it. (If anyone feels brave, I'd be curious about how it generalizes to -forms; namely what's the middle-dimensional heat kernel coefficient associated with the Laplacian, , acting on -forms on )","M n n M K_M(t) := \mathrm{Tr}\Big(\mathrm{e}^{-t \Delta_M}\Big) \equiv \sum_{\lambda\in\mathrm{spec}(\Delta_M)} \mathrm{e}^{-t \lambda}. t K_M(t) = \frac{1}{(4\pi t)^{n/2}}\sum_{k=0}^\infty b_k(M) t^k, b_k(M) M  b_{n/2}(M) = b_{\mathrm{dim}M/2}(M). b_{n/2}(M) M M p \Delta_p = \mathrm{d}\delta + \delta \mathrm{d} p M","['differential-geometry', 'partial-differential-equations', 'spectral-theory', 'harmonic-analysis', 'laplacian']"
55,How is $F(FM)$ related to 2-Jet bundle $F^{2} M$?,How is  related to 2-Jet bundle ?,F(FM) F^{2} M,"I get that the bundle of invertible 2-jets $F^{2}M$ over a manifold $M$ holds second order derivative information about smooth functions in $M$ . The Wikipedia article speaks of a close relation between the double tangent bundle $TTM$ and $F^{2}M$ . I'm looking at a principal frame  bundle, over another principal frame bundle over a Riemannian manifold (denoted $F(FM)$ ). Given a manifold $M$ , We examine it's (tangent) frame bundle $FM$ . This is known to be in bijection with the bundle of invertible 1-jets $F^{1}(M)$ on $M$ . Considering the total space $FM$ , let us now examine it's frame bundle $F(FM)$ . Similarly, we have a bijection between $F^{1}\left(FM\right)$ and $F(FM)$ . But(as I understand it) this is just the 1-jet prolongation of $FM$ , namely $J^{1}FM$ . In principal bundle structure on jet prolongation of frame bundles page 1288, it's stated that $J^{1}FM$ is diffeomorphic to $\tilde{F}^{2}\left(M\right)$ ,the bundle of semi-holonomic 2-jets over $M$ . Further there is a bundle reduction to the holonomic 2-jet bundle such that: $$F^{2}(M)\rightarrow J^{1}FM$$ So I would expect that the frame bundle of the frame bundle $F(FM)$ of $M$ is diffeomorphic to the semi-holonomic bundle of 2-jets over $M$ , $\tilde{F}^{2}(M)$ . is this right or am I misunderstanding something? I would be satisfied if anyone can explain the relationship between the two bundles in the title. Example: Without getting into individual frames and coordinate patches, suppose I have some n-dimensional Riemannian manifold $M$ . $M$ will accordingly have a principle $GL(n)$ frame bundle $FM$ over $M$ that locally looks like $FM\approx\mathbb{\mathbb{R}}^{n}\times gl(n)$ . $FM$ is then a Riemannian manifold of dimension $n+n^{2}$ . Now if we take it's frame bundle we have a principle $GL(n+n^{2})$ frame bundle $FFM$ over $FM$ . Without getting into the Homotopy principle too much, we can say this $GL(n+n^{2})$ bundle is the bundle of aholonomic frames over $FM$ . We could also say it's a $GL(n+n^{2})\rtimes GL(n)$ bundle over $M$ . Does this coincide with the (aholonomic) second order frame bundle $F^{2}$ of $M$ ? Some of our frame components here are first and second order derivatives of our original frame components on $M$ (this is because connections on $M$ correspond to frames on $gl(n)$ )  When we start enforcing those relations, we move to semi holonomic (by enforcing the first order derivative conditions) and finally holonomic (by enforcing second order derivative conditions) frames. As We do this we will  have a reduction of the $GL(n+n^{2})$ to some subgroup. This is right along the lines of what is done in this paper but there they're using Jet bundles and calling them higher order frame bundles $F^{2}M$ . How are they related to what I'm looking at? I apologize for any sloppiness, I'm new and trying to learn this, it is admittedly out if my main area of study.","I get that the bundle of invertible 2-jets over a manifold holds second order derivative information about smooth functions in . The Wikipedia article speaks of a close relation between the double tangent bundle and . I'm looking at a principal frame  bundle, over another principal frame bundle over a Riemannian manifold (denoted ). Given a manifold , We examine it's (tangent) frame bundle . This is known to be in bijection with the bundle of invertible 1-jets on . Considering the total space , let us now examine it's frame bundle . Similarly, we have a bijection between and . But(as I understand it) this is just the 1-jet prolongation of , namely . In principal bundle structure on jet prolongation of frame bundles page 1288, it's stated that is diffeomorphic to ,the bundle of semi-holonomic 2-jets over . Further there is a bundle reduction to the holonomic 2-jet bundle such that: So I would expect that the frame bundle of the frame bundle of is diffeomorphic to the semi-holonomic bundle of 2-jets over , . is this right or am I misunderstanding something? I would be satisfied if anyone can explain the relationship between the two bundles in the title. Example: Without getting into individual frames and coordinate patches, suppose I have some n-dimensional Riemannian manifold . will accordingly have a principle frame bundle over that locally looks like . is then a Riemannian manifold of dimension . Now if we take it's frame bundle we have a principle frame bundle over . Without getting into the Homotopy principle too much, we can say this bundle is the bundle of aholonomic frames over . We could also say it's a bundle over . Does this coincide with the (aholonomic) second order frame bundle of ? Some of our frame components here are first and second order derivatives of our original frame components on (this is because connections on correspond to frames on )  When we start enforcing those relations, we move to semi holonomic (by enforcing the first order derivative conditions) and finally holonomic (by enforcing second order derivative conditions) frames. As We do this we will  have a reduction of the to some subgroup. This is right along the lines of what is done in this paper but there they're using Jet bundles and calling them higher order frame bundles . How are they related to what I'm looking at? I apologize for any sloppiness, I'm new and trying to learn this, it is admittedly out if my main area of study.",F^{2}M M M TTM F^{2}M F(FM) M FM F^{1}(M) M FM F(FM) F^{1}\left(FM\right) F(FM) FM J^{1}FM J^{1}FM \tilde{F}^{2}\left(M\right) M F^{2}(M)\rightarrow J^{1}FM F(FM) M M \tilde{F}^{2}(M) M M GL(n) FM M FM\approx\mathbb{\mathbb{R}}^{n}\times gl(n) FM n+n^{2} GL(n+n^{2}) FFM FM GL(n+n^{2}) FM GL(n+n^{2})\rtimes GL(n) M F^{2} M M M gl(n) GL(n+n^{2}) F^{2}M,"['differential-geometry', 'riemannian-geometry', 'vector-bundles']"
56,Why does gimbal lock occur “in two circles”?,Why does gimbal lock occur “in two circles”?,,"Let $S^1=ℝ/2\pi ℤ$ . Consider the Euler angle parametrization $$ T^3 \to SO(3),\\\ (ξ, υ, ζ)\mapsto R^Z_{ζ}R^Y_{υ}R^X_{ξ}, $$ where $T^3\cong S^1\times S^1\times S^1$ is the 3-torus and $$ R^X_ξ=\begin{pmatrix}1&0&0\\\ 0& \cos ξ&-\sin ξ\\\ 0& \sinξ &\cos ξ\end{pmatrix} $$ represents the rotation around the $x$ -axis etc. This map has singular values whenever $υ=\pm \pi/2$ , a phenomenon which is known as gimbal lock . It is well known that we cannot circumvent the existence of singular values with such a three-angle parametrization: If a continuous map $T^3\to SO(3) $ would have only regular values, it would have to be a covering map, because it's proper. But the only cover of $SO(3)\cong \mathbb RP^3$ is $S^3$ , contradiction. However, couldn't it be possible that there exists a different map $T^3\to SO(3)$ which posesses „less“ singular values? Calculating the image of the singular values $S^1\times \{\pm \pi/2\}\times S^1$ , we get (unless I miscalculated) $$ \begin{pmatrix}0 & \sin(ξ-ζ) & \cos(ξ-ζ) \\\ 0 & \cos(ξ-ζ) & -\sin(ξ-ζ) \\\ -1 & 0 & 0\end{pmatrix},\qquad \begin{pmatrix}0 & -\sin(ξ+ζ) & -\cos(ξ+ζ) \\\ 0 & \cos(ξ+ζ) & -\sin(ξ+ζ) \\\ 1 & 0 & 0\end{pmatrix}, $$ where $ξ, ζ$ range over $S^1$ . This is homeomorphic to $S^1\sqcup S^1$ . Question Is there a continuous surjection $T^3 \to SO(3)$ whose (image of the) set of singular values is „topologically simpler“ than $S^1\sqcup S^1$ , e.g. by being of the form $S^1\times D$ or $D$ where $D$ is discrete? If not, is there a theorem putting qualitative restrictions on what this subspace of $SO(3)$ can look like?","Let . Consider the Euler angle parametrization where is the 3-torus and represents the rotation around the -axis etc. This map has singular values whenever , a phenomenon which is known as gimbal lock . It is well known that we cannot circumvent the existence of singular values with such a three-angle parametrization: If a continuous map would have only regular values, it would have to be a covering map, because it's proper. But the only cover of is , contradiction. However, couldn't it be possible that there exists a different map which posesses „less“ singular values? Calculating the image of the singular values , we get (unless I miscalculated) where range over . This is homeomorphic to . Question Is there a continuous surjection whose (image of the) set of singular values is „topologically simpler“ than , e.g. by being of the form or where is discrete? If not, is there a theorem putting qualitative restrictions on what this subspace of can look like?","S^1=ℝ/2\pi ℤ 
T^3 \to SO(3),\\\ (ξ, υ, ζ)\mapsto R^Z_{ζ}R^Y_{υ}R^X_{ξ},
 T^3\cong S^1\times S^1\times S^1 
R^X_ξ=\begin{pmatrix}1&0&0\\\ 0& \cos ξ&-\sin ξ\\\ 0& \sinξ &\cos ξ\end{pmatrix}
 x υ=\pm \pi/2 T^3\to SO(3)  SO(3)\cong \mathbb RP^3 S^3 T^3\to SO(3) S^1\times \{\pm \pi/2\}\times S^1 
\begin{pmatrix}0 & \sin(ξ-ζ) & \cos(ξ-ζ) \\\ 0 & \cos(ξ-ζ) & -\sin(ξ-ζ) \\\ -1 & 0 & 0\end{pmatrix},\qquad
\begin{pmatrix}0 & -\sin(ξ+ζ) & -\cos(ξ+ζ) \\\ 0 & \cos(ξ+ζ) & -\sin(ξ+ζ) \\\ 1 & 0 & 0\end{pmatrix},
 ξ, ζ S^1 S^1\sqcup S^1 T^3 \to SO(3) S^1\sqcup S^1 S^1\times D D D SO(3)","['differential-geometry', 'differential-topology', 'orthogonal-matrices']"
57,"Can we get a soldering ""form"" whose pull-backs encode arbitrary tensor components?","Can we get a soldering ""form"" whose pull-backs encode arbitrary tensor components?",,"Context/notation: If $M^n$ is a smooth manifold, and $\pi\colon {\rm Fr}(TM) \to M$ denotes its frame bundle (it is a principal ${\rm GL}_n(\Bbb R)$ -bundle whose elements are pairs $(x,\mathfrak{v})$ with $x \in M$ and $\mathfrak{v}$ an ordered basis for $T_xM$ ), we have the soldering form $\theta \in \Omega^1({\rm Fr}(TM); \Bbb R^n)$ , defined by $$\theta_{(x,\mathfrak{v})}(X) = [{{\rm d}\pi}_{(x,\mathfrak{v})}(X)]_{\mathfrak{v}},\qquad \mbox{for} \quad X \in T_{(x,\mathfrak{v})}{\rm Fr}(TM),$$ where $[\cdot]_{\mathfrak{v}} \colon T_xM \to \Bbb R^n$ takes a tangent vector to its column vector in $\Bbb R^n$ of components relative to $\mathfrak{v}$ . If $U \subseteq M$ is open and $\mathfrak{e}$ is a local frame on $U$ (that is, a local section of ${\rm Fr}(TM)$ ), the pull-back $\mathfrak{e}^*\theta \in \Omega^1(U; \Bbb R^n)$ satisfies $$(\mathfrak{e}^*\theta)_x(v) = [v]_{\mathfrak{e}_x}$$ for all $x \in U$ and $v \in T_xM$ . It also has nice properties like $R_A^*\theta = A^{-1}\circ \theta$ for all $A \in {\rm GL}_n(\Bbb R)$ , where $R_A\colon {\rm Fr}(TM) \to {\rm Fr}(TM)$ is the map ""change of basis via $A$ "" (it's a consequence of the general formula $[v]_{\mathfrak{v}A} = A^{-1}[v]_{\mathfrak{v}}$ ). This construction does not work replacing $TM \to M$ with an arbitrary vector bundle $E \to M$ because the derivative of the bundle projection takes values in tangent spaces to $M$ , and not on the fibers of $E$ . Question. Now consider the tensor bundle $TM^{\otimes r} \otimes T^*M^{\otimes s}$ . Since a basis for a vector space gives rise to a basis of any associated tensor space, doing this pointwise we get (with suggestive notation) a map $${\rm Fr}(TM) \ni (x,\mathfrak{v}) \mapsto (x, \mathfrak{v}^{\otimes r}\otimes (\mathfrak{v}^*)^{\otimes s}) \in {\rm Fr}(TM^{\otimes r}\otimes T^*M^{\otimes s}).$$ I was wondering if whether we get some object $\Theta$ (which apparently will not be a $1$ -form) such that for each local frame $\mathfrak{e}$ on some open set $U \subseteq M$ , $\mathfrak{e}^*\Theta$ (whatever this is) will satisfy $$(\mathfrak{e}^*\Theta)_x(T) = [T]_{\mathfrak{e}_x^{\otimes r}\otimes (\mathfrak{e}_x^*)^{\otimes s}}, \quad\mbox{for}\quad T \in T_xM^{\otimes r}\otimes T_x^*M^{\otimes s}$$ Understanding the case $(r,s) = (0,1)$ would already provide some insight. For the same reason why the original construction doesn't work for arbitrary $E\to M$ , the derivative of the projection ${\rm Fr}(T^*M) \to M$ will take values in tangent spaces to $M$ instead of cotangent spaces (this construction should be natural and not require identifications between $TM$ and $T^*M$ , and even by taking a Riemannian metric on $M$ , it's not clear how this sorry attempt would carry to general $(r,s)$ ). I'm not sure what to try and can only guess that general bundle morphisms should enter the picture somehow. I know that this is a bit vague but hopefully I managed to convey what I want here. Certainly someone has thought about this already, so maybe there's just some terminology I'm not aware of. Any comments are welcome. Thank you!","Context/notation: If is a smooth manifold, and denotes its frame bundle (it is a principal -bundle whose elements are pairs with and an ordered basis for ), we have the soldering form , defined by where takes a tangent vector to its column vector in of components relative to . If is open and is a local frame on (that is, a local section of ), the pull-back satisfies for all and . It also has nice properties like for all , where is the map ""change of basis via "" (it's a consequence of the general formula ). This construction does not work replacing with an arbitrary vector bundle because the derivative of the bundle projection takes values in tangent spaces to , and not on the fibers of . Question. Now consider the tensor bundle . Since a basis for a vector space gives rise to a basis of any associated tensor space, doing this pointwise we get (with suggestive notation) a map I was wondering if whether we get some object (which apparently will not be a -form) such that for each local frame on some open set , (whatever this is) will satisfy Understanding the case would already provide some insight. For the same reason why the original construction doesn't work for arbitrary , the derivative of the projection will take values in tangent spaces to instead of cotangent spaces (this construction should be natural and not require identifications between and , and even by taking a Riemannian metric on , it's not clear how this sorry attempt would carry to general ). I'm not sure what to try and can only guess that general bundle morphisms should enter the picture somehow. I know that this is a bit vague but hopefully I managed to convey what I want here. Certainly someone has thought about this already, so maybe there's just some terminology I'm not aware of. Any comments are welcome. Thank you!","M^n \pi\colon {\rm Fr}(TM) \to M {\rm GL}_n(\Bbb R) (x,\mathfrak{v}) x \in M \mathfrak{v} T_xM \theta \in \Omega^1({\rm Fr}(TM); \Bbb R^n) \theta_{(x,\mathfrak{v})}(X) = [{{\rm d}\pi}_{(x,\mathfrak{v})}(X)]_{\mathfrak{v}},\qquad \mbox{for}
\quad X \in T_{(x,\mathfrak{v})}{\rm Fr}(TM), [\cdot]_{\mathfrak{v}} \colon T_xM \to \Bbb R^n \Bbb R^n \mathfrak{v} U \subseteq M \mathfrak{e} U {\rm Fr}(TM) \mathfrak{e}^*\theta \in \Omega^1(U; \Bbb R^n) (\mathfrak{e}^*\theta)_x(v) = [v]_{\mathfrak{e}_x} x \in U v \in T_xM R_A^*\theta = A^{-1}\circ \theta A \in {\rm GL}_n(\Bbb R) R_A\colon {\rm Fr}(TM) \to {\rm Fr}(TM) A [v]_{\mathfrak{v}A} = A^{-1}[v]_{\mathfrak{v}} TM \to M E \to M M E TM^{\otimes r} \otimes T^*M^{\otimes s} {\rm Fr}(TM) \ni (x,\mathfrak{v}) \mapsto (x, \mathfrak{v}^{\otimes r}\otimes (\mathfrak{v}^*)^{\otimes s}) \in {\rm Fr}(TM^{\otimes r}\otimes T^*M^{\otimes s}). \Theta 1 \mathfrak{e} U \subseteq M \mathfrak{e}^*\Theta (\mathfrak{e}^*\Theta)_x(T) = [T]_{\mathfrak{e}_x^{\otimes r}\otimes (\mathfrak{e}_x^*)^{\otimes s}}, \quad\mbox{for}\quad T \in T_xM^{\otimes r}\otimes T_x^*M^{\otimes s} (r,s) = (0,1) E\to M {\rm Fr}(T^*M) \to M M TM T^*M M (r,s)","['differential-geometry', 'tensors', 'differential-forms', 'vector-bundles', 'principal-bundles']"
58,Induced Second Fundamental Form for a Graph,Induced Second Fundamental Form for a Graph,,"If one has a Riemannian $3$ -manifold $(M,g)$ and a warped product space $(M \times\mathbb{R}, g + \phi^2 dt^2)$ , the induced metric of a hypersurface $\Sigma$ given by a graph $t = f(x)$ is $g + \phi^2 df^2$ , but in that case how does one define the induced second fundamental form of $\Sigma$ ?","If one has a Riemannian -manifold and a warped product space , the induced metric of a hypersurface given by a graph is , but in that case how does one define the induced second fundamental form of ?","3 (M,g) (M \times\mathbb{R}, g + \phi^2 dt^2) \Sigma t = f(x) g + \phi^2 df^2 \Sigma","['differential-geometry', 'riemannian-geometry']"
59,About Getzler's rescaling operator,About Getzler's rescaling operator,,"I am trying to read the heat kernel proof of the Atiyah-Singer index theorem by the method of Getzler's rescaling method. Here, we define an operator $$(\delta_{\lambda}\phi)(t,x)=\sum_{j=0}^n \lambda^{-j}\phi(\lambda^2t,\lambda x)$$ $\phi$ is defined on $\mathbb R^{+}\times U$ with values in $Cl(T_qM)\otimes End(W)$ where $W$ is the twisted bundle for Clifford module bundle $E=S\otimes W$ . We can imagine $\phi(t,x)$ as terms like asymptotic expansion of heat kernels $k(t,x)$ and identify it with CLifford algebra basis. And we define the Getzler's operator as $\delta_{\lambda} A \delta_{\lambda}^{-1}$ for some operators (For the square of the Dirac operator $D^2$ , this is actually the rescaled Dirac laplacian $D_{\lambda}^2$ , which has the rescaled heat kernel, this transforms the asymptotic expansion with $t\to0^{+}$ to rescaled $\lambda\to 0^{+}$ ) My question is how does the inverse $\delta_{\lambda}^{-1} $ work ? How to calculate it on operators like $A=\partial_t$ , the example shows that this is equal to $\delta_{\lambda} \partial_{t} \delta_{\lambda}^{-1}=\lambda^{-2}\partial_{t}$","I am trying to read the heat kernel proof of the Atiyah-Singer index theorem by the method of Getzler's rescaling method. Here, we define an operator is defined on with values in where is the twisted bundle for Clifford module bundle . We can imagine as terms like asymptotic expansion of heat kernels and identify it with CLifford algebra basis. And we define the Getzler's operator as for some operators (For the square of the Dirac operator , this is actually the rescaled Dirac laplacian , which has the rescaled heat kernel, this transforms the asymptotic expansion with to rescaled ) My question is how does the inverse work ? How to calculate it on operators like , the example shows that this is equal to","(\delta_{\lambda}\phi)(t,x)=\sum_{j=0}^n \lambda^{-j}\phi(\lambda^2t,\lambda x) \phi \mathbb R^{+}\times U Cl(T_qM)\otimes End(W) W E=S\otimes W \phi(t,x) k(t,x) \delta_{\lambda} A \delta_{\lambda}^{-1} D^2 D_{\lambda}^2 t\to0^{+} \lambda\to 0^{+} \delta_{\lambda}^{-1}  A=\partial_t \delta_{\lambda} \partial_{t} \delta_{\lambda}^{-1}=\lambda^{-2}\partial_{t}","['differential-geometry', 'riemannian-geometry', 'mathematical-physics']"
60,"If $\gamma$ is a curve connecting $x$ and $y$, can we show $\int_0^1\left\|\gamma'(t)\right\|\:{\rm d}t\ge\left\|x-y\right\|$?","If  is a curve connecting  and , can we show ?",\gamma x y \int_0^1\left\|\gamma'(t)\right\|\:{\rm d}t\ge\left\|x-y\right\|,"Let $E$ be a $\mathbb R$ -Banach space, $x,y\in E$ and $\gamma\in C^1([0,1],E)$ . Can we show that $$\int_0^1\left\|\gamma'(t)\right\|_E\:{\rm d}t\ge\left\|x-y\right\|_E?\tag1$$ Clearly, by the mean value inequality, there is a $t_0\in(0,1)$ with $\left\|\gamma'(t_0)\right\|_E\ge\left\|x-y\right\|_E$ , but that doesn't seem to be helpful. Intuitively, interpreting the left-hand side of $(1)$ at the length of the curve $\gamma$ , it is clear that there is no shorter curve then a straight line ...","Let be a -Banach space, and . Can we show that Clearly, by the mean value inequality, there is a with , but that doesn't seem to be helpful. Intuitively, interpreting the left-hand side of at the length of the curve , it is clear that there is no shorter curve then a straight line ...","E \mathbb R x,y\in E \gamma\in C^1([0,1],E) \int_0^1\left\|\gamma'(t)\right\|_E\:{\rm d}t\ge\left\|x-y\right\|_E?\tag1 t_0\in(0,1) \left\|\gamma'(t_0)\right\|_E\ge\left\|x-y\right\|_E (1) \gamma","['differential-geometry', 'banach-spaces', 'curves']"
61,$G$-bundles over $S^2$,-bundles over,G S^2,"In light of the fact that the only homogeneous (under a finite--dimensional Lie group action) $S^2$ -bundle over $S^2$ is the trivial one. I would like to know if this fact is more general. i.e., is any homogeneous fiber bundle over $S^2$ and with a fiber that is  connected and simply-connected is trivial? I did a google search and I found the following in Encyclopedic dictionary of math. p. 572 , the following: ""The set of the equivalence classes of principal $G$ -bundles or $G$ -bundles with fiber $F$ over the base $S^n$ is one-to-one correspondence with the set $\pi_{n-1}(G)/\pi_0(G)$ of equivalence classes under the operation  of $G$ on $\pi_{n-1}(G)$ ..."" So for example in the (principal) Hopf-fibration $$SO(2)\hookrightarrow SO(3) \to SO(3)/SO(2)=S^2$$ we have $\pi_1(SO(2))=\mathbb Z$ , so there are infinitely many different $S^1$ -bundles over $S^2$ . However, I didn't find an ""actual""  reference for the result claimed in the shaded box in the case of $G$ -homogeneous bundles? But in case it is true, shouldn't be a condition on the effectivity of the group action as we can take our group to be simply connected (by going up to the universal covering)? I have a hunch about the following situation: Let $J/H\hookrightarrow G/H\to G/J$ be a fiber bundle consisting of a connected (finite--dimensional) Lie group $G$ and closed connected subgroups $H\subset J$ with base $$G/J\;\cong\; \mathrm{SU}(2)/S^1\;\cong \;S^2$$ and a compact fiber $$J/H\;\cong\;\mathrm{SU}(n)/T$$ where $T$ is a maximal torus in $\mathrm{SU}(n)$ . In this case, the following can be shown: (1) the total space $G/H$ can be given a structure of a (generalized) flag variety. Thus, $G/H\cong \mathrm{SU}(m)/T_m$ . (2) the $\mathrm{SU}(2)$ acting in the base is a normal subgroup of $G$ . Since maximal tori are conjugate  to each other, then I can pick any maximal torus $T_m$ such that $$G/H \;\cong\; \mathrm{SU}(m)/ T_m\; \cong \; \Big(\mathrm{SU}(n)\times \mathrm{SU}(2)\Big)\Big/\Big(T\times S^1\Big)\; \cong \; \mathrm{SU}(n)/T \;\times \mathrm{SU}(2)/S^1$$ But even if my hunch is right, a general fact would be more interesting! My question : Let $G$ be a connected and simply-connected finite dimensional Lie group and $H\subset J$ be closed subgroups of $G$ such that $J$ is connected  and $J/H$ is simply-connected. Is the following fibration trivial? $$J/H\hookrightarrow G/H\to G/J\cong S^2$$","In light of the fact that the only homogeneous (under a finite--dimensional Lie group action) -bundle over is the trivial one. I would like to know if this fact is more general. i.e., is any homogeneous fiber bundle over and with a fiber that is  connected and simply-connected is trivial? I did a google search and I found the following in Encyclopedic dictionary of math. p. 572 , the following: ""The set of the equivalence classes of principal -bundles or -bundles with fiber over the base is one-to-one correspondence with the set of equivalence classes under the operation  of on ..."" So for example in the (principal) Hopf-fibration we have , so there are infinitely many different -bundles over . However, I didn't find an ""actual""  reference for the result claimed in the shaded box in the case of -homogeneous bundles? But in case it is true, shouldn't be a condition on the effectivity of the group action as we can take our group to be simply connected (by going up to the universal covering)? I have a hunch about the following situation: Let be a fiber bundle consisting of a connected (finite--dimensional) Lie group and closed connected subgroups with base and a compact fiber where is a maximal torus in . In this case, the following can be shown: (1) the total space can be given a structure of a (generalized) flag variety. Thus, . (2) the acting in the base is a normal subgroup of . Since maximal tori are conjugate  to each other, then I can pick any maximal torus such that But even if my hunch is right, a general fact would be more interesting! My question : Let be a connected and simply-connected finite dimensional Lie group and be closed subgroups of such that is connected  and is simply-connected. Is the following fibration trivial?",S^2 S^2 S^2 G G F S^n \pi_{n-1}(G)/\pi_0(G) G \pi_{n-1}(G) SO(2)\hookrightarrow SO(3) \to SO(3)/SO(2)=S^2 \pi_1(SO(2))=\mathbb Z S^1 S^2 G J/H\hookrightarrow G/H\to G/J G H\subset J G/J\;\cong\; \mathrm{SU}(2)/S^1\;\cong \;S^2 J/H\;\cong\;\mathrm{SU}(n)/T T \mathrm{SU}(n) G/H G/H\cong \mathrm{SU}(m)/T_m \mathrm{SU}(2) G T_m G/H \;\cong\; \mathrm{SU}(m)/ T_m\; \cong \; \Big(\mathrm{SU}(n)\times \mathrm{SU}(2)\Big)\Big/\Big(T\times S^1\Big)\; \cong \; \mathrm{SU}(n)/T \;\times \mathrm{SU}(2)/S^1 G H\subset J G J J/H J/H\hookrightarrow G/H\to G/J\cong S^2,"['differential-geometry', 'algebraic-topology']"
62,"On the proof that ""Poincare dual=Thom Class""","On the proof that ""Poincare dual=Thom Class""",,"Suppose that $S$ is an oriented smooth $s$ -manifold, and $\pi :E\to S$ is an oriented real vector bundle over $S$ . The Thom isomorphism asserts that the integration along the fiber defines isomorphisms $$H_{cv}^*(E)\cong H^{*-n}_{dR}(S).$$ The Thom class $\Phi_E$ is defined to be the element $\Phi_E\in H^n_{cv}(E)$ which corresponds to $1\in H_{dR}^0(S)$ in the above isomorphism. In several sources I have read, such as Bott-Tu (around p.65) and this pdf , it is stated that the Poincare dual of $S$ in $E$ is equal to $\Phi_E$ , that is, if we equip $E$ an orientation by the canonical isomorphism $T_xE_x\oplus T_xS\cong T_x E$ , then we have $$\int_E \omega\wedge \Phi_E=\int _S\omega$$ for all $\omega\in H^s_{c}(E)$ . However, I have some trouble understanding the proof of this claim, and I need someone's help. The proof goes as follows: if $i:S\to E$ denotes the zero section, then $i\circ\pi$ is homotopy equivalent to the identity on $E$ , so $\omega -\pi^*i^*\omega =d\tau$ for some $\tau\in\Omega^{s-1}(E)$ . Thus we have $$ \int_E\omega\wedge \Phi_E=\int_E\pi^*i^*\omega\wedge\Phi_E+\int_E d\tau\wedge \Phi_E. $$ The first term on the RHS of the above equation can be computed, using the projection formula, and it equals $\int_S\omega$ . The problem is the second term, which involves the integral of $d\tau\wedge \Phi_E=d(\tau\wedge \Phi_E)$ . If we can show that this integral vanishes, then we are done. But we cannot blindly apply the Stokes's theorem, for $\tau\wedge \Phi_E$ may not have compact support. In Bott-Tu, it is simply stated that this integral equals zero by the Stokes's theorem. But for the reasons stated above, I think we need to ensure compactness of the support of $\tau\wedge \Phi _E$ In the pdf I cited above, it is stated that $i\circ\pi$ is properly homotopic to the identity map of E via the homotopy $H:E\times [0,1]\to E, \,(v,t)\mapsto (1-t)v$ , and hence $i$ and $\pi$ induce isomorphism in the compact cohomology and thus we can actually assume $\tau $ to have compact support. However, if I understand it correctly, $H$ is not proper because, for example, if $x\in S$ is any point in $S$ and $0_x$ denotes the zero vector  in $E_x$ , then $H^{-1}(0_x)\cap(E\times\{1\})=E_x\times\{1\}$ is not compact, unless $E$ has rank $0$ . Actually, since $\Phi_E\in\Omega_{cv}^n(E)$ , it is enough to ensure the compactness of $\pi(\operatorname{supp}\tau)$ . But I have trouble proving even this. I must be missing something. Can anyone help me? Thanks in advance.","Suppose that is an oriented smooth -manifold, and is an oriented real vector bundle over . The Thom isomorphism asserts that the integration along the fiber defines isomorphisms The Thom class is defined to be the element which corresponds to in the above isomorphism. In several sources I have read, such as Bott-Tu (around p.65) and this pdf , it is stated that the Poincare dual of in is equal to , that is, if we equip an orientation by the canonical isomorphism , then we have for all . However, I have some trouble understanding the proof of this claim, and I need someone's help. The proof goes as follows: if denotes the zero section, then is homotopy equivalent to the identity on , so for some . Thus we have The first term on the RHS of the above equation can be computed, using the projection formula, and it equals . The problem is the second term, which involves the integral of . If we can show that this integral vanishes, then we are done. But we cannot blindly apply the Stokes's theorem, for may not have compact support. In Bott-Tu, it is simply stated that this integral equals zero by the Stokes's theorem. But for the reasons stated above, I think we need to ensure compactness of the support of In the pdf I cited above, it is stated that is properly homotopic to the identity map of E via the homotopy , and hence and induce isomorphism in the compact cohomology and thus we can actually assume to have compact support. However, if I understand it correctly, is not proper because, for example, if is any point in and denotes the zero vector  in , then is not compact, unless has rank . Actually, since , it is enough to ensure the compactness of . But I have trouble proving even this. I must be missing something. Can anyone help me? Thanks in advance.","S s \pi :E\to S S H_{cv}^*(E)\cong H^{*-n}_{dR}(S). \Phi_E \Phi_E\in H^n_{cv}(E) 1\in H_{dR}^0(S) S E \Phi_E E T_xE_x\oplus T_xS\cong T_x E \int_E \omega\wedge \Phi_E=\int _S\omega \omega\in H^s_{c}(E) i:S\to E i\circ\pi E \omega -\pi^*i^*\omega =d\tau \tau\in\Omega^{s-1}(E) 
\int_E\omega\wedge \Phi_E=\int_E\pi^*i^*\omega\wedge\Phi_E+\int_E d\tau\wedge \Phi_E.
 \int_S\omega d\tau\wedge \Phi_E=d(\tau\wedge \Phi_E) \tau\wedge \Phi_E \tau\wedge \Phi _E i\circ\pi H:E\times [0,1]\to E, \,(v,t)\mapsto (1-t)v i \pi \tau  H x\in S S 0_x E_x H^{-1}(0_x)\cap(E\times\{1\})=E_x\times\{1\} E 0 \Phi_E\in\Omega_{cv}^n(E) \pi(\operatorname{supp}\tau)","['differential-geometry', 'algebraic-topology', 'differential-topology', 'poincare-duality']"
63,Solutions for PDE $(1+u_x^2)v_{yy} -2u_xu_yv_{xy} + (1+u_y^2)v_{yy}$,Solutions for PDE,(1+u_x^2)v_{yy} -2u_xu_yv_{xy} + (1+u_y^2)v_{yy},"I am reading a proof on Bernstein's Theorem on Minimal Surfaces. On this proof it is claimed that if $u: \mathbb{R^2} \rightarrow \mathbb{R}$ sastisfies the minimal surface equation, ie: $$ (1+u_x^2)u_{yy} -2u_xu_yu_{xy} + (1+u_y^2)u_{xx} = 0 $$ Then both the functions $\psi_1 = \arctan(u_x)$ and $\psi_2 = \arctan(u_y)$ are solutions of the equation $$(1+u_x^2)v_{yy} -2u_xu_yv_{xy} + (1+u_y^2)v_{xx} = 0$$ Since the above equation is in someway ""symmetric"" (changing $x$ 's into $y$ 's and vice versa does not alter the equation) then I believe it is easily seen that if $\psi_1$ satisfies the equation then $\psi_2$ must also do so. What I've done so far: We have the following identities: $$ (\psi_1)_{xx} = \frac{u_{xxx}(1+u_x^2) - 2u_xu_{xx}^2}{(1+u_x^2)^2} $$ $$ (\psi_1)_{xy} = \frac{u_{xxy}(1+u_x^2) - 2u_xu_{xy}u_{xx}}{(1+u_x^2)^2} $$ $$ (\psi_1)_{yy} = \frac{u_{xyy}(1+u_x^2) - 2u_xu_{xy}^2}{(1+u_x^2)^2} $$ Which when we substitute correspondingly on the $v$ 's in the equation and after using the hypothesis of the minimal surface equation we are left with $$ \frac{u_{xxx}(1+u_y^2) - 2u_xu_yu_{xxy}+u_{xyy}(1+u_x^2)+2u_{x}(u_{xx}u_{yy}-u_{xy}^2)}{(1+u_x^2)} $$ Which I cannot then, prove is equal to $0$ .","I am reading a proof on Bernstein's Theorem on Minimal Surfaces. On this proof it is claimed that if sastisfies the minimal surface equation, ie: Then both the functions and are solutions of the equation Since the above equation is in someway ""symmetric"" (changing 's into 's and vice versa does not alter the equation) then I believe it is easily seen that if satisfies the equation then must also do so. What I've done so far: We have the following identities: Which when we substitute correspondingly on the 's in the equation and after using the hypothesis of the minimal surface equation we are left with Which I cannot then, prove is equal to .","u: \mathbb{R^2} \rightarrow \mathbb{R} 
(1+u_x^2)u_{yy} -2u_xu_yu_{xy} + (1+u_y^2)u_{xx} = 0
 \psi_1 = \arctan(u_x) \psi_2 = \arctan(u_y) (1+u_x^2)v_{yy} -2u_xu_yv_{xy} + (1+u_y^2)v_{xx} = 0 x y \psi_1 \psi_2 
(\psi_1)_{xx} = \frac{u_{xxx}(1+u_x^2) - 2u_xu_{xx}^2}{(1+u_x^2)^2}
 
(\psi_1)_{xy} = \frac{u_{xxy}(1+u_x^2) - 2u_xu_{xy}u_{xx}}{(1+u_x^2)^2}
 
(\psi_1)_{yy} = \frac{u_{xyy}(1+u_x^2) - 2u_xu_{xy}^2}{(1+u_x^2)^2}
 v 
\frac{u_{xxx}(1+u_y^2) - 2u_xu_yu_{xxy}+u_{xyy}(1+u_x^2)+2u_{x}(u_{xx}u_{yy}-u_{xy}^2)}{(1+u_x^2)}
 0","['differential-geometry', 'partial-differential-equations']"
64,Sections on Möbius bundle correspond to $f:\mathbb{R}\rightarrow \mathbb{R}$ such that $f(x+n)=(-1)^nf(x)$,Sections on Möbius bundle correspond to  such that,f:\mathbb{R}\rightarrow \mathbb{R} f(x+n)=(-1)^nf(x),"I want to show that sections of the Möbius bundle correspond to functions $f:\mathbb{R}\rightarrow \mathbb{R}$ such that $f(x+n)=(-1)^nf(x)$ .  Given a section of the Möbius bundle I want to define such an $f$ , this will give a map from sections of the Möbius bundle into the set of desired functions. We view $S^1$ as $\mathbb{R}/\mathbb{Z}$ where $\mathbb{Z}$ acts on $\mathbb{R}$ by $n\cdot x=x+n$ . We get the Mobius bundle over $S^1$ by considering the $\mathbb{Z}$ action on $\mathbb{R}^2$ that is $n\cdot(x,y)=(x+n,(-1)^n y)$ . Denote the Möbius bundle by $L$ . The projection $\pi:L\rightarrow S^1$ is then $\pi(x,y)=(x)$ . Recall that a section of a line bundle over $S^1$ is a map $s:S^1\rightarrow L$ such that $\pi \circ s= id_{S^1}$ . Intuitively this makes sense but I am not sure how to rigoursly identify these things. Given a section $s:S^1\rightarrow L$ , we want to define an $f:\mathbb{R}\rightarrow \mathbb{R}$ such that $f(x+n)=(-1)^nf(x)$ . The $(-1)^n$ term appears when we act on $(x,y)\in L$ by $n$ . So if for a section $s(x)=(s_1(x),s_2(x))$ I think we will need to define $f$ in terms of $s_2$ . But this only gives $(s_1(x),s_2(x))=n\cdot(s_1(x),s_2(x))=(s_1(x)+n,(-1)^ns_2(x))$ . Do we do something like $f(x)=\pi_2(n\cdot s(\overline{x}))$ ? where $\overline{x}$ is the $x$ minus the nearest integer to $x$ and $n$ is the nearest integer to $x$ ? This feels wrong, it seems like there should be a neater way to do this since $x+n$ and $(-1)^n$ both appear in the action of $\mathbb{Z}$ /","I want to show that sections of the Möbius bundle correspond to functions such that .  Given a section of the Möbius bundle I want to define such an , this will give a map from sections of the Möbius bundle into the set of desired functions. We view as where acts on by . We get the Mobius bundle over by considering the action on that is . Denote the Möbius bundle by . The projection is then . Recall that a section of a line bundle over is a map such that . Intuitively this makes sense but I am not sure how to rigoursly identify these things. Given a section , we want to define an such that . The term appears when we act on by . So if for a section I think we will need to define in terms of . But this only gives . Do we do something like ? where is the minus the nearest integer to and is the nearest integer to ? This feels wrong, it seems like there should be a neater way to do this since and both appear in the action of /","f:\mathbb{R}\rightarrow \mathbb{R} f(x+n)=(-1)^nf(x) f S^1 \mathbb{R}/\mathbb{Z} \mathbb{Z} \mathbb{R} n\cdot x=x+n S^1 \mathbb{Z} \mathbb{R}^2 n\cdot(x,y)=(x+n,(-1)^n y) L \pi:L\rightarrow S^1 \pi(x,y)=(x) S^1 s:S^1\rightarrow L \pi \circ s= id_{S^1} s:S^1\rightarrow L f:\mathbb{R}\rightarrow \mathbb{R} f(x+n)=(-1)^nf(x) (-1)^n (x,y)\in L n s(x)=(s_1(x),s_2(x)) f s_2 (s_1(x),s_2(x))=n\cdot(s_1(x),s_2(x))=(s_1(x)+n,(-1)^ns_2(x)) f(x)=\pi_2(n\cdot s(\overline{x})) \overline{x} x x n x x+n (-1)^n \mathbb{Z}","['differential-geometry', 'vector-bundles']"
65,Covariant derivative on the base space,Covariant derivative on the base space,,"The basic definition of a covariant derivative for a Lie algebra valued n-form $\alpha \in \Omega^n(P)\otimes T_eG$ with $P$ a principle bundle with base space a manifold $M$ , and $T_eG$ the Lie algebra of the fiber $G$ is $$ D\alpha(x_1, ..., x_{n + 1}) = d\alpha(x_1^H, ..., x_{n + 1}^H) $$ Where $x = (x_1, ..., x_{n+1}) \in T_qP$ and $x^H \in H_qP$ , being this the horizontal tangent space at $q \in P$ such that $T_qP = V_qP\oplus H_qP$ and $V_qP \subset T_qG$ the vertical tangent space. Also, $d$ is the exterior derivative map $d: \Omega^n \rightarrow \Omega^{n + 1}$ In Nakahara's ""Geometry, Topology and Physics"" the equation (10.47) stands that for any Lie algebra valued n-form defined on $M$ , $\eta$ , you can write $$ D\eta = d\eta + [A, \eta] = d\eta + A\wedge\eta - \eta\wedge A \tag1$$ Where $A = S_i^*\omega$ with $S_i: U_i\subset M \rightarrow P$ and $\omega$ is the connection 1-form. I tried to prove it aplying $S_i^*$ to $D\alpha$ since $S_i^*\alpha$ is a Lie algebra valued n-form defined on $M$ , after defining $D$ in a more suitable way: $$ D\alpha = d\alpha + \sum_{i = 1}^n(-1)^{i + 1}\omega(x_i)\wedge \alpha(x_1, ..., \hat{x}_i, ..., x_n) \tag2$$ Where the hat over $x_i$ means that that vector doesn't appear on $\alpha$ I think this is the right way to define $D$ due to the answer in Covariant derivative: QFT vs. Math But if you apply $S_i^*$ to Eq. (2) and call $\eta = S_i^*\alpha$ you get $$ D\eta = d\eta + \sum_{i = 1}^n(-1)^{i + 1}(S_i^*\omega(x_i))\wedge (S_i^*\alpha(x_1, ..., \hat{x}_i, ..., x_n)) = \\ d\eta + \sum_{i = 1}^n(-1)^{i + 1}A(x_i)\wedge \eta(x_1, ..., \hat{x}_i, ..., x_n) $$ Therefore, Eq. (2) is equal to Eq. (1) only in the case $\eta \in \Omega^1(M)\otimes T_eG$ , i.e. just for $n = 1$ . Nevertheless, Nakahara ensures that is true for any n. Is Eq. (2) wrong or maybe my interpretation of commutator in Eq. (1)? How can you write in terms of a connection 1-form the covariant derivative for any Lie algebra valued n-form such that when defining on $M$ (i.e., after using $S_i^*$ ) leads you to Eq. (1)?","The basic definition of a covariant derivative for a Lie algebra valued n-form with a principle bundle with base space a manifold , and the Lie algebra of the fiber is Where and , being this the horizontal tangent space at such that and the vertical tangent space. Also, is the exterior derivative map In Nakahara's ""Geometry, Topology and Physics"" the equation (10.47) stands that for any Lie algebra valued n-form defined on , , you can write Where with and is the connection 1-form. I tried to prove it aplying to since is a Lie algebra valued n-form defined on , after defining in a more suitable way: Where the hat over means that that vector doesn't appear on I think this is the right way to define due to the answer in Covariant derivative: QFT vs. Math But if you apply to Eq. (2) and call you get Therefore, Eq. (2) is equal to Eq. (1) only in the case , i.e. just for . Nevertheless, Nakahara ensures that is true for any n. Is Eq. (2) wrong or maybe my interpretation of commutator in Eq. (1)? How can you write in terms of a connection 1-form the covariant derivative for any Lie algebra valued n-form such that when defining on (i.e., after using ) leads you to Eq. (1)?","\alpha \in \Omega^n(P)\otimes T_eG P M T_eG G 
D\alpha(x_1, ..., x_{n + 1}) = d\alpha(x_1^H, ..., x_{n + 1}^H)
 x = (x_1, ..., x_{n+1}) \in T_qP x^H \in H_qP q \in P T_qP = V_qP\oplus H_qP V_qP \subset T_qG d d: \Omega^n \rightarrow \Omega^{n + 1} M \eta 
D\eta = d\eta + [A, \eta] = d\eta + A\wedge\eta - \eta\wedge A
\tag1 A = S_i^*\omega S_i: U_i\subset M \rightarrow P \omega S_i^* D\alpha S_i^*\alpha M D 
D\alpha = d\alpha + \sum_{i = 1}^n(-1)^{i + 1}\omega(x_i)\wedge \alpha(x_1, ..., \hat{x}_i, ..., x_n)
\tag2 x_i \alpha D S_i^* \eta = S_i^*\alpha 
D\eta = d\eta + \sum_{i = 1}^n(-1)^{i + 1}(S_i^*\omega(x_i))\wedge (S_i^*\alpha(x_1, ..., \hat{x}_i, ..., x_n)) = \\ d\eta + \sum_{i = 1}^n(-1)^{i + 1}A(x_i)\wedge \eta(x_1, ..., \hat{x}_i, ..., x_n)
 \eta \in \Omega^1(M)\otimes T_eG n = 1 M S_i^*","['differential-geometry', 'lie-groups', 'lie-algebras', 'fiber-bundles', 'principal-bundles']"
66,Lemma 4.1. Do Carmo's Riemannian Geometry,Lemma 4.1. Do Carmo's Riemannian Geometry,,"A question about the lemma in the title: Lemma 4.1. For any $p \in M$ there exists a number $c > 0$ such that any geodesic in $M$ that is tangent at $q \in M$ to the geodesic sphere $S_r(p)$ of radius $r < c$ stays out of the geodesic ball $B_r(p)$ for some neighborhood of $q$ . I'll write down the proof and write the question after Proof. Let $W$ be a totally normal neighborhood of $p$ . Using the lemma of homogeneity, we can suppose, by conveniently restricting the the interval of definition, that all of the geodesics of $W$ have velocity one. We can, therefore, restrict ourselves to the unit tangent bundle $T_1 W$ given by $$ T_1 W = \left\{(q,v) : q \in W, v \in T_q M, |v| = 1 \right\} $$ Let $\gamma : I \times T_1 W \to M$ , $I = (-\epsilon,\epsilon)$ , be the differentiable mapping such that $t \to \gamma(t,q,v)$ is the geodesic that at the instant $t=0$ passes through $q$ with velocity $v, |v| = 1$ . Define $u(t,q,v) = \exp_p^{-1}(\gamma(t,q,v))$ and $$ F:I\times T_qW \to \mathbb{R}, \;\;\;\; F(t,q,v) = |u(t,q,v)|^2. $$ $F$ measures the square of the ""distance"" from $p$ to a point that is moving along the geodesic $\gamma$ . It is clear that $u$ and $F$ are differentiable, and that $$ \begin{array}{l} \frac{\partial F}{\partial t} = 2 \left\langle \frac{\partial u}{\partial t}, u\right\rangle \\ \frac{\partial^2 F}{\partial t^2} = 2 \left\langle \frac{\partial^2 u}{\partial t^2}, u\right\rangle + 2 \left| \frac{\partial u}{\partial t} \right|^2 \end{array} $$ Now let $r > 0$ be chosen so that $$ \exp_p B_r(0) = B_r(p) \subset W $$ If a geodesic $\gamma$ is tangent to the geodesic sphere $S_r(p)$ at the point $q = \gamma(0,q,v)$ , then, from the Gauss lemma $$ \left\langle \frac{\partial u}{\partial t}(0,q,v), u(0,q,v) \right\rangle = 0 $$ Question : How is the Gauss lemma exactly applied here?","A question about the lemma in the title: Lemma 4.1. For any there exists a number such that any geodesic in that is tangent at to the geodesic sphere of radius stays out of the geodesic ball for some neighborhood of . I'll write down the proof and write the question after Proof. Let be a totally normal neighborhood of . Using the lemma of homogeneity, we can suppose, by conveniently restricting the the interval of definition, that all of the geodesics of have velocity one. We can, therefore, restrict ourselves to the unit tangent bundle given by Let , , be the differentiable mapping such that is the geodesic that at the instant passes through with velocity . Define and measures the square of the ""distance"" from to a point that is moving along the geodesic . It is clear that and are differentiable, and that Now let be chosen so that If a geodesic is tangent to the geodesic sphere at the point , then, from the Gauss lemma Question : How is the Gauss lemma exactly applied here?","p \in M c > 0 M q \in M S_r(p) r < c B_r(p) q W p W T_1 W 
T_1 W = \left\{(q,v) : q \in W, v \in T_q M, |v| = 1 \right\}
 \gamma : I \times T_1 W \to M I = (-\epsilon,\epsilon) t \to \gamma(t,q,v) t=0 q v, |v| = 1 u(t,q,v) = \exp_p^{-1}(\gamma(t,q,v)) 
F:I\times T_qW \to \mathbb{R}, \;\;\;\; F(t,q,v) = |u(t,q,v)|^2.
 F p \gamma u F 
\begin{array}{l}
\frac{\partial F}{\partial t} = 2 \left\langle \frac{\partial u}{\partial t}, u\right\rangle \\
\frac{\partial^2 F}{\partial t^2} = 2 \left\langle \frac{\partial^2 u}{\partial t^2}, u\right\rangle + 2 \left| \frac{\partial u}{\partial t} \right|^2
\end{array}
 r > 0 
\exp_p B_r(0) = B_r(p) \subset W
 \gamma S_r(p) q = \gamma(0,q,v) 
\left\langle \frac{\partial u}{\partial t}(0,q,v), u(0,q,v) \right\rangle = 0
","['differential-geometry', 'proof-explanation', 'manifolds', 'riemannian-geometry']"
67,Proof of equivalence between variational principle and Euler-Lagrange equations on a manifold,Proof of equivalence between variational principle and Euler-Lagrange equations on a manifold,,"Let M be some manifold, and TM the tangent bundle. Let $\gamma : [a,b] \to M$ be a smooth curve on M defined on an interval on $\mathbb{R}$ . Let $J$ be another interval in $\mathbb{R}$ containing 0. A 'deformation of $\gamma(t)$ with fixed endpoints' is a curve $\overline{\gamma}:[a,b]\times J \to M : (t,\epsilon) \mapsto \overline{\gamma}_{\epsilon}(t)$ such that $\overline{\gamma}_{0}(t)=\gamma(t), \forall t \in [a,b]$ $\overline{\gamma}_{\epsilon}(a) = \gamma(a)$ and $\overline{\gamma}_{\epsilon}(b) = \gamma(b)$ for all $\epsilon \in J$ Let L be a lagrangian, i.e. a smooth map $L : TM \to \mathbb{R} : (p,\dot{p}) \mapsto L(p,\dot{p})$ . For $M = \mathbb{R}^n$ it is simple to prove that $\gamma$ fulfills the variational principle $$\left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_a^b L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt = 0$$ for every deformation of $\gamma$ , if and only if $\gamma$ satisfies the Euler-Lagrange equations $$\frac{d}{dt}\frac{\partial L}{\partial \dot{p}}(\gamma(t),\dot{\gamma}(t)) - \frac{\partial L}{\partial {p}}(\gamma(t),\dot{\gamma}(t)).$$ My question In many references (any book on geometric mechanics), it is stated that this equivalence hold on any manifold - not just the euclidean case. And in several places (for examples Marsden and Ratiu's book on geometric mechanics) I have seen it stated that this can be prooved in coordinates. However, this is only done for the case where $\gamma$ is contained in a single chart. I am trying to prove, or looking for a reference that proves, the general case. Preferably in coordinates, or in a relatively 'simple' intrinsic way. Can anyone help with this? My attempt Say we want to prove the following direction; let $\gamma : [a,b]\to M$ fulfill the Euler-Lagrange equation. I.e. it fulfills the equation in every chart. We want to show that the variation of the integral is 0. Choose a cover of M , and let $\gamma$ be covered by 3 charts, as in the figure below (copied from the book 'Geometric mechanics and symmetry' by Holm et al). Then its deformations (for small enough $\epsilon$ ) is also covered by these charts. Depiction of a curve and deformations covered by 3 charts Choose one such deformation. Then we can split it into three subcurves defined on the intervals $[a,t_1],[t_1,t_2],[t_2,b]$ , respectively, such that each is contained in a single chart. Likewise, we can split up the integral into three integrals \begin{align} \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_a^b L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt =& \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_a^{t_{1}} L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt \\ &+ \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_{t_{1}}^{t_{2}} L(\overline{\gamma}_{\epsilon}\nonumber(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt \\ &+ \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_{t_{2}}^b L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt. \end{align} In each integral, we can use the coordinates of the suitable chart. However, for each such curve/deformation in $\mathbb{R}^n$ , the endpoints will not be fixed, except at a and b . From the proof of the equivalence on $M = \mathbb{R}^n$ , one can deduce that if an arbitrary deformation $\overline{g} : [T_1,T_2]\times J \to \mathbb{R}^n$ (not necessarily with fixed endpoints) fulfills the E-L equations, then \begin{align*} \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_{T_1}^{T_2} L(\overline{g}_{\epsilon}(t),\dot{\overline{g}}_{\epsilon}(t)) dt = \left[ \frac{\partial L}{\partial \dot{p}}(g(t),\dot{{g}}(t)) \cdot \left.\frac{d}{d\epsilon}\right|_{\epsilon=0} \overline{g}_{\epsilon}(t)\right]_{T_1}^{T_2}  \end{align*} This can be used on the previous equation to get \begin{align} \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_a^b L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt =& \left[ \frac{\partial L'}{\partial \dot{p}}(\gamma(t)',\dot{{\gamma}}'(t)) \cdot \left.\frac{d}{d\epsilon}\right|_{\epsilon=0} \overline{\gamma}'_{\epsilon}(t)\right]_{a}^{t_1}  \\ &+ \left[ \frac{\partial L''}{\partial \dot{p}}(\gamma(t)'',\dot{{\gamma}}(t)'') \cdot \left.\frac{d}{d\epsilon}\right|_{\epsilon=0} \overline{\gamma}_{\epsilon}''(t)\right]_{t_1}^{t_2} \\ &+ \left[ \frac{\partial L'''}{\partial \dot{p}}(\gamma(t)''',\dot{{\gamma}}(t)''') \cdot \left.\frac{d}{d\epsilon}\right|_{\epsilon=0} \overline{\gamma}_{\epsilon}'''(t)\right]_{t_2}^{b}  \end{align} where the clumsy '-notation denotes that in each term of the sum we use a different coordinate representation of L , $\gamma$ and $\overline{\gamma}$ , since they belong to different charts. In the case where $M = \mathbb{R}^n$ we can use a single chart, so the sum telescopes. But on a general manifold, the sum does not necessarily telescope due to the different coordinate maps. Is there a way to fix this?","Let M be some manifold, and TM the tangent bundle. Let be a smooth curve on M defined on an interval on . Let be another interval in containing 0. A 'deformation of with fixed endpoints' is a curve such that and for all Let L be a lagrangian, i.e. a smooth map . For it is simple to prove that fulfills the variational principle for every deformation of , if and only if satisfies the Euler-Lagrange equations My question In many references (any book on geometric mechanics), it is stated that this equivalence hold on any manifold - not just the euclidean case. And in several places (for examples Marsden and Ratiu's book on geometric mechanics) I have seen it stated that this can be prooved in coordinates. However, this is only done for the case where is contained in a single chart. I am trying to prove, or looking for a reference that proves, the general case. Preferably in coordinates, or in a relatively 'simple' intrinsic way. Can anyone help with this? My attempt Say we want to prove the following direction; let fulfill the Euler-Lagrange equation. I.e. it fulfills the equation in every chart. We want to show that the variation of the integral is 0. Choose a cover of M , and let be covered by 3 charts, as in the figure below (copied from the book 'Geometric mechanics and symmetry' by Holm et al). Then its deformations (for small enough ) is also covered by these charts. Depiction of a curve and deformations covered by 3 charts Choose one such deformation. Then we can split it into three subcurves defined on the intervals , respectively, such that each is contained in a single chart. Likewise, we can split up the integral into three integrals In each integral, we can use the coordinates of the suitable chart. However, for each such curve/deformation in , the endpoints will not be fixed, except at a and b . From the proof of the equivalence on , one can deduce that if an arbitrary deformation (not necessarily with fixed endpoints) fulfills the E-L equations, then This can be used on the previous equation to get where the clumsy '-notation denotes that in each term of the sum we use a different coordinate representation of L , and , since they belong to different charts. In the case where we can use a single chart, so the sum telescopes. But on a general manifold, the sum does not necessarily telescope due to the different coordinate maps. Is there a way to fix this?","\gamma : [a,b] \to M \mathbb{R} J \mathbb{R} \gamma(t) \overline{\gamma}:[a,b]\times J \to M : (t,\epsilon) \mapsto \overline{\gamma}_{\epsilon}(t) \overline{\gamma}_{0}(t)=\gamma(t), \forall t \in [a,b] \overline{\gamma}_{\epsilon}(a) = \gamma(a) \overline{\gamma}_{\epsilon}(b) = \gamma(b) \epsilon \in J L : TM \to \mathbb{R} : (p,\dot{p}) \mapsto L(p,\dot{p}) M = \mathbb{R}^n \gamma \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_a^b L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt = 0 \gamma \gamma \frac{d}{dt}\frac{\partial L}{\partial \dot{p}}(\gamma(t),\dot{\gamma}(t)) - \frac{\partial L}{\partial {p}}(\gamma(t),\dot{\gamma}(t)). \gamma \gamma : [a,b]\to M \gamma \epsilon [a,t_1],[t_1,t_2],[t_2,b] \begin{align}
\left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_a^b L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt =& \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_a^{t_{1}} L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt \\
&+ \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_{t_{1}}^{t_{2}} L(\overline{\gamma}_{\epsilon}\nonumber(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt \\
&+ \left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_{t_{2}}^b L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt.
\end{align} \mathbb{R}^n M = \mathbb{R}^n \overline{g} : [T_1,T_2]\times J \to \mathbb{R}^n \begin{align*}
\left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_{T_1}^{T_2} L(\overline{g}_{\epsilon}(t),\dot{\overline{g}}_{\epsilon}(t)) dt = \left[ \frac{\partial L}{\partial \dot{p}}(g(t),\dot{{g}}(t)) \cdot \left.\frac{d}{d\epsilon}\right|_{\epsilon=0} \overline{g}_{\epsilon}(t)\right]_{T_1}^{T_2} 
\end{align*} \begin{align}
\left. \frac{d}{d\epsilon} \right |_{\epsilon=0} \int_a^b L(\overline{\gamma}_{\epsilon}(t),\dot{\overline{\gamma}}_{\epsilon}(t)) dt =& \left[ \frac{\partial L'}{\partial \dot{p}}(\gamma(t)',\dot{{\gamma}}'(t)) \cdot \left.\frac{d}{d\epsilon}\right|_{\epsilon=0} \overline{\gamma}'_{\epsilon}(t)\right]_{a}^{t_1}  \\
&+ \left[ \frac{\partial L''}{\partial \dot{p}}(\gamma(t)'',\dot{{\gamma}}(t)'') \cdot \left.\frac{d}{d\epsilon}\right|_{\epsilon=0} \overline{\gamma}_{\epsilon}''(t)\right]_{t_1}^{t_2} \\
&+ \left[ \frac{\partial L'''}{\partial \dot{p}}(\gamma(t)''',\dot{{\gamma}}(t)''') \cdot \left.\frac{d}{d\epsilon}\right|_{\epsilon=0} \overline{\gamma}_{\epsilon}'''(t)\right]_{t_2}^{b} 
\end{align} \gamma \overline{\gamma} M = \mathbb{R}^n","['differential-geometry', 'calculus-of-variations', 'classical-mechanics']"
68,Showing that the conformal Laplacian is a conformally covariant operator,Showing that the conformal Laplacian is a conformally covariant operator,,"Consider a Riemannian manifold of dimension $n\geq3$ . Consider the conformal Laplacian \begin{equation*} P_g=\Delta_g+\frac{n-2}{4(n-1)}R_g, \end{equation*} where $R_g$ is the scalar curvature associated to the metric $g$ . I would like to show that $P_g$ is a conformally covariant operator in the sense that under the conformal change $\tilde{g}=e^{2f}g$ , the following transformation law is satisfied: \begin{align*} P_{\tilde{g}}&=e^{-(\frac{n}{2}+1)f}P_g \,e^{(\frac{n}{2}-1)f}\\ &= e^{-(\frac{n}{2}+1)f}\Delta_g \,e^{(\frac{n}{2}-1)f}+\frac{n-2}{4(n-1)}R_g\,e^{-2f} \tag{1} \end{align*} I know that under such a conformal change, the Laplace-Beltrami operator transforms like \begin{equation*} \Delta_{\tilde{g}}=e^{-2f}\Delta_g-(n-2)e^{-2f}g^{ij}\frac{\partial f}{\partial x_j}\frac{\partial}{\partial x_i}. \end{equation*} For the scalar curvature, one can make the substitution $e^{2f}=\varphi^{4/(n-2)}$ (where $\varphi$ is positive) to get \begin{equation*} R_{\tilde{g}}=\varphi^{-(n+2)/(n-2)}\bigg(4\frac{n-1}{n-2}\Delta_g \varphi + R_g\varphi\bigg) \end{equation*} which is really just \begin{equation*} R_{\tilde{g}}=4\frac{n-1}{n-2}e^{-(\frac{n}{2}+1)f}\Delta_g \, e^{(\frac{n}{2}-1)f}+R_g e^{-2f}. \end{equation*} So, I get \begin{equation*} \tag{2} P_{\tilde{g}}= e^{-2f}\Delta_g-(n-2)e^{-2f}g^{ij}\frac{\partial f}{\partial x_j}\frac{\partial}{\partial x_i} + e^{-(\frac{n}{2}+1)f}\Delta_g \, e^{(\frac{n}{2}-1)f}+\frac{n-2}{4(n-1)}R_g\, e^{-2f}. \end{equation*} The problem is that I do not see how (1) is the same as (2). Have I made a mistake somewhere? Or do the first two terms in (2) somehow cancel each other out? Any help would be greatly appreciated!","Consider a Riemannian manifold of dimension . Consider the conformal Laplacian where is the scalar curvature associated to the metric . I would like to show that is a conformally covariant operator in the sense that under the conformal change , the following transformation law is satisfied: I know that under such a conformal change, the Laplace-Beltrami operator transforms like For the scalar curvature, one can make the substitution (where is positive) to get which is really just So, I get The problem is that I do not see how (1) is the same as (2). Have I made a mistake somewhere? Or do the first two terms in (2) somehow cancel each other out? Any help would be greatly appreciated!","n\geq3 \begin{equation*}
P_g=\Delta_g+\frac{n-2}{4(n-1)}R_g,
\end{equation*} R_g g P_g \tilde{g}=e^{2f}g \begin{align*}
P_{\tilde{g}}&=e^{-(\frac{n}{2}+1)f}P_g \,e^{(\frac{n}{2}-1)f}\\
&= e^{-(\frac{n}{2}+1)f}\Delta_g \,e^{(\frac{n}{2}-1)f}+\frac{n-2}{4(n-1)}R_g\,e^{-2f} \tag{1}
\end{align*} \begin{equation*}
\Delta_{\tilde{g}}=e^{-2f}\Delta_g-(n-2)e^{-2f}g^{ij}\frac{\partial f}{\partial x_j}\frac{\partial}{\partial x_i}.
\end{equation*} e^{2f}=\varphi^{4/(n-2)} \varphi \begin{equation*}
R_{\tilde{g}}=\varphi^{-(n+2)/(n-2)}\bigg(4\frac{n-1}{n-2}\Delta_g \varphi + R_g\varphi\bigg)
\end{equation*} \begin{equation*}
R_{\tilde{g}}=4\frac{n-1}{n-2}e^{-(\frac{n}{2}+1)f}\Delta_g \, e^{(\frac{n}{2}-1)f}+R_g e^{-2f}.
\end{equation*} \begin{equation*}
\tag{2}
P_{\tilde{g}}= e^{-2f}\Delta_g-(n-2)e^{-2f}g^{ij}\frac{\partial f}{\partial x_j}\frac{\partial}{\partial x_i} + e^{-(\frac{n}{2}+1)f}\Delta_g \, e^{(\frac{n}{2}-1)f}+\frac{n-2}{4(n-1)}R_g\, e^{-2f}.
\end{equation*}","['differential-geometry', 'riemannian-geometry', 'conformal-geometry']"
69,Understanding projection of vector field in homgeneous spaces,Understanding projection of vector field in homgeneous spaces,,"I'm studying homogeneous spaces from the book of A.Arvanitoyeorgos, ""An introduction to Lie groups and the geometry of homogeneous spaces"". Consider $G/H$ be a homogeneous space, and let $\pi:G\rightarrow G/H$ be the canonical projection. We can consider the differential $d\pi_e:T_eG\rightarrow T_o(G/H)$ (and remember that $\mathfrak{g}\cong T_eG)$ . Now we can compute what is the projection of a $X\in\mathfrak{g}$ . The author says that, for any $g\in G$ $$X^{\star}_{gH}=\frac{d}{dt}(\exp{tX})gH\Bigr\rvert_{t=0}$$ where $\exp{tX}$ is the corresponing 1-parameter subgroup. Now my doubt is: The author notice that $[X^{\star},Y^{\star}]=-[X,Y]^{\star}$ ; Unfortunately I tried lots of computation for proving this identity but this result keeps arising as a magic trick; moreover my gut feeling is that this identity is not true, since if we reduce to the case $gH=o$ we should en up with an identity without the minus sign. And this is a problem, because this identity is strongly used to obtain the Riemannian connection for a reductive homogeneous space. So i'd like to understand whhy this result should be true, and in the other case why the computation of the Riemannian connection are correct (or, if they're not, what is the known formula). Thanks in advance to anyone who will help me trying to understand this a little bit.","I'm studying homogeneous spaces from the book of A.Arvanitoyeorgos, ""An introduction to Lie groups and the geometry of homogeneous spaces"". Consider be a homogeneous space, and let be the canonical projection. We can consider the differential (and remember that . Now we can compute what is the projection of a . The author says that, for any where is the corresponing 1-parameter subgroup. Now my doubt is: The author notice that ; Unfortunately I tried lots of computation for proving this identity but this result keeps arising as a magic trick; moreover my gut feeling is that this identity is not true, since if we reduce to the case we should en up with an identity without the minus sign. And this is a problem, because this identity is strongly used to obtain the Riemannian connection for a reductive homogeneous space. So i'd like to understand whhy this result should be true, and in the other case why the computation of the Riemannian connection are correct (or, if they're not, what is the known formula). Thanks in advance to anyone who will help me trying to understand this a little bit.","G/H \pi:G\rightarrow G/H d\pi_e:T_eG\rightarrow T_o(G/H) \mathfrak{g}\cong T_eG) X\in\mathfrak{g} g\in G X^{\star}_{gH}=\frac{d}{dt}(\exp{tX})gH\Bigr\rvert_{t=0} \exp{tX} [X^{\star},Y^{\star}]=-[X,Y]^{\star} gH=o","['differential-geometry', 'lie-groups', 'homogeneous-spaces']"
70,Irrep. of SU(2) and Laplace Eigenspaces,Irrep. of SU(2) and Laplace Eigenspaces,,"In order to calculate the Dirac spectrum on Berger's sphere $(S^3,g_t)$, I came across irreps of SU(2) (see Hitchin p. 30). Apperently, Hitchin restricts the Dirac operator to the eigenspaces of the Laplacian relative to the standard metric because they commute. That's clear. Now he says, that they are given by irreps of SU(2), ie. homogeneous polynomials in two complex variables. And that's the part I do not understand. The eigenspaces of the corresponding Laplacian on $S^3$ are given by harmonic homogeneous polynomials all with respect to the Euclidean $\mathbb{R}^4$, aren't they? So why does he talk about just homogeneous polynomials without the harmonic restriction? I already consulted Bröcker and Hall and cannot find anything helpful. Obviously, I don't understand the connection between Laplace eigenspaces and irreps and definitely miss something. Maybe it's a silly question. But unfortunately, I don't get the point. So I would appreciate some help. Thank you! :) EDIT: I worked up a little and come to the conclusion that the Peter-Weyl theorem is the key point here. It seems that the functions given by the matrix coefficents \begin{align} g \mapsto f_{v,w}(g) = \left< \pi_k(g)v,w\right> \end{align} on the irreps $\pi_k$ of SU(2), namely homogeneous polynomials in two complex variables of degree $k$, must give the spherical harmonics I'm seeking for. Can anybody confirm this?","In order to calculate the Dirac spectrum on Berger's sphere $(S^3,g_t)$, I came across irreps of SU(2) (see Hitchin p. 30). Apperently, Hitchin restricts the Dirac operator to the eigenspaces of the Laplacian relative to the standard metric because they commute. That's clear. Now he says, that they are given by irreps of SU(2), ie. homogeneous polynomials in two complex variables. And that's the part I do not understand. The eigenspaces of the corresponding Laplacian on $S^3$ are given by harmonic homogeneous polynomials all with respect to the Euclidean $\mathbb{R}^4$, aren't they? So why does he talk about just homogeneous polynomials without the harmonic restriction? I already consulted Bröcker and Hall and cannot find anything helpful. Obviously, I don't understand the connection between Laplace eigenspaces and irreps and definitely miss something. Maybe it's a silly question. But unfortunately, I don't get the point. So I would appreciate some help. Thank you! :) EDIT: I worked up a little and come to the conclusion that the Peter-Weyl theorem is the key point here. It seems that the functions given by the matrix coefficents \begin{align} g \mapsto f_{v,w}(g) = \left< \pi_k(g)v,w\right> \end{align} on the irreps $\pi_k$ of SU(2), namely homogeneous polynomials in two complex variables of degree $k$, must give the spherical harmonics I'm seeking for. Can anybody confirm this?",,"['differential-geometry', 'representation-theory', 'lie-groups', 'harmonic-analysis', 'spherical-harmonics']"
71,Proof of theorem egregium with moving frames,Proof of theorem egregium with moving frames,,"I'm learning the moving frame approach (with differential form) in surface theory from different books and papers (Cartan, O'Neill, Shifrin, Flanders and others). Briefly: you define an adapted moving frame on the surface $(P, e_1, e_2, e_3)$, then you define the dual forms $\omega_i = dP\cdot e_i$ and the connection forms $\omega_{ij} = de_i \cdot e_j$. From Cartan's structure equations you find Gauss and Codazzi equations and other things. Next you prove the fundamental formula $d\omega_{12} = -Kd\sigma$ (where $K = detS$ is the gaussian curvature). Here in some texts follows two steps before arrive at theorem egregium: 1) You prove that if you consider another frame $(P, \bar e_1, \bar e_2, \bar e_3$) than $d\omega_{12} = d \bar \omega_{12}$ 2) You prove that $\omega_{12}$ is the only 1-form which satisfy the two equations $d\omega_1 = -\omega_2 \wedge \omega_{12}$ and $d\omega_2 = \omega_1 \wedge \omega_{12}$ and so it is intrinsic Are these steps necessary? I mean 1) It is not obvious that $d\omega_{12}$ does not depend on the frame since neither $K$ nor $d\sigma$ depend on the frame? 2) It is not obvious that $\omega_{12}$ is intrinsic since it's defined as $de_1\cdot e_2$? Thanks in advance.","I'm learning the moving frame approach (with differential form) in surface theory from different books and papers (Cartan, O'Neill, Shifrin, Flanders and others). Briefly: you define an adapted moving frame on the surface $(P, e_1, e_2, e_3)$, then you define the dual forms $\omega_i = dP\cdot e_i$ and the connection forms $\omega_{ij} = de_i \cdot e_j$. From Cartan's structure equations you find Gauss and Codazzi equations and other things. Next you prove the fundamental formula $d\omega_{12} = -Kd\sigma$ (where $K = detS$ is the gaussian curvature). Here in some texts follows two steps before arrive at theorem egregium: 1) You prove that if you consider another frame $(P, \bar e_1, \bar e_2, \bar e_3$) than $d\omega_{12} = d \bar \omega_{12}$ 2) You prove that $\omega_{12}$ is the only 1-form which satisfy the two equations $d\omega_1 = -\omega_2 \wedge \omega_{12}$ and $d\omega_2 = \omega_1 \wedge \omega_{12}$ and so it is intrinsic Are these steps necessary? I mean 1) It is not obvious that $d\omega_{12}$ does not depend on the frame since neither $K$ nor $d\sigma$ depend on the frame? 2) It is not obvious that $\omega_{12}$ is intrinsic since it's defined as $de_1\cdot e_2$? Thanks in advance.",,"['differential-geometry', 'differential-forms']"
72,the de Rham poincare duals of the unit circle in the punctured plane.,the de Rham poincare duals of the unit circle in the punctured plane.,,"I'm reading from Bott-Tu's Differential forms in algebraic topology , and came across the following exercise: (p52 Exercise 5.16(b)) Let $S$ be the unit circle in the plane, and $M := \mathbb{R}^2-\{0\}$. Show that the closed Poincare dual of the unit circle $i : S\hookrightarrow M$ in $H^1(M)$ is 0, but the compact Poincare dual is the nontrivial generator $\rho(r)dr$ in $H^1_c(M)$, where $\rho(r)$ is a bump function with total integral 1 (By a bump function we mean a smooth function whose support is contained in some disc and whose graph looks like a ""bump""). (My question is near the bottom) To compute the closed dual, we must check that there is a closed form $\eta = \eta_r dr + \eta_\theta d\theta$ on $M$ such that for every closed compactly supported form $\omega = \omega_rdr + \omega_\theta d\theta$ on $M$, we have $$\int_S i^*\omega = \int_M\omega\wedge\eta$$ However, since $\omega$ is compactly supported and closed, realizing $S$ as the boundary of the punctured unit disk, Stoke's theorem tells us that $\int_S i^*\omega = 0$, so we may pick $\eta = 0$. To compute the compact dual, we must now find a closed compactly supported form $\eta' = \eta_r' dr + \eta_\theta' d\theta$ on $M$ such that for every closed (not necessarily compactly supported) form $\omega = \omega_rdr + \omega_\theta d\theta$, we have again: $$\int_S i^*\omega = \int_M\omega\wedge\eta$$ If we assume $\eta' = \rho(r)dr$ as in the exercise, we wish to check: $$\int_S i^*\omega = \int_0^{2\pi}\omega_\theta(1,\theta)d\theta = \int_\epsilon^{\epsilon'}\rho(r)\left(\int_0^{2\pi}\omega_\theta(r,\theta)d\theta \right)dr$$ where the support of $\rho(r)$ is contained in the annuli of radii $\epsilon,\epsilon'$. Again, applying Stoke's theorem to the closed annulus with radii $R_1,R_2$, we find that the integral $\int_{0}^{2\pi}\omega_\theta(r,\theta)d\theta$ is independent of the choice of $r$. Thus, $\rho(r)dr$ has total integral 1, the equality is checked as desired. My question is: Suppose we didn't know to guess $\eta' = \rho(r)dr$. How would we have deduced it? Ie, let us just assume that $\eta' = \eta'_rdr + \eta'_\theta d\theta$, with support on the annulus of radii $\epsilon,\epsilon'$. Thus we want to find $\eta'_r,\eta'_\theta$ such that: $$\int_0^{2\pi}\omega_\theta(1,\theta)d\theta =  \int_0^{2\pi}\int_\epsilon^{\epsilon'}\omega_r\eta'_\theta drd\theta - \int_0^{2\pi}\int_\epsilon^{\epsilon'}\omega_\theta\eta'_r drd\theta$$ The fact that $\omega,\eta$ are closed is the same as saying that $\frac{\partial\omega_r}{\partial\theta} = \frac{\partial\omega_\theta}{\partial r}$ and $\frac{\partial\eta'_r}{\partial\theta} = \frac{\partial\eta'_\theta}{\partial r}$. How can we deduce that we may pick $\eta'$ to be of the form $\eta' = \rho(r)dr$?","I'm reading from Bott-Tu's Differential forms in algebraic topology , and came across the following exercise: (p52 Exercise 5.16(b)) Let $S$ be the unit circle in the plane, and $M := \mathbb{R}^2-\{0\}$. Show that the closed Poincare dual of the unit circle $i : S\hookrightarrow M$ in $H^1(M)$ is 0, but the compact Poincare dual is the nontrivial generator $\rho(r)dr$ in $H^1_c(M)$, where $\rho(r)$ is a bump function with total integral 1 (By a bump function we mean a smooth function whose support is contained in some disc and whose graph looks like a ""bump""). (My question is near the bottom) To compute the closed dual, we must check that there is a closed form $\eta = \eta_r dr + \eta_\theta d\theta$ on $M$ such that for every closed compactly supported form $\omega = \omega_rdr + \omega_\theta d\theta$ on $M$, we have $$\int_S i^*\omega = \int_M\omega\wedge\eta$$ However, since $\omega$ is compactly supported and closed, realizing $S$ as the boundary of the punctured unit disk, Stoke's theorem tells us that $\int_S i^*\omega = 0$, so we may pick $\eta = 0$. To compute the compact dual, we must now find a closed compactly supported form $\eta' = \eta_r' dr + \eta_\theta' d\theta$ on $M$ such that for every closed (not necessarily compactly supported) form $\omega = \omega_rdr + \omega_\theta d\theta$, we have again: $$\int_S i^*\omega = \int_M\omega\wedge\eta$$ If we assume $\eta' = \rho(r)dr$ as in the exercise, we wish to check: $$\int_S i^*\omega = \int_0^{2\pi}\omega_\theta(1,\theta)d\theta = \int_\epsilon^{\epsilon'}\rho(r)\left(\int_0^{2\pi}\omega_\theta(r,\theta)d\theta \right)dr$$ where the support of $\rho(r)$ is contained in the annuli of radii $\epsilon,\epsilon'$. Again, applying Stoke's theorem to the closed annulus with radii $R_1,R_2$, we find that the integral $\int_{0}^{2\pi}\omega_\theta(r,\theta)d\theta$ is independent of the choice of $r$. Thus, $\rho(r)dr$ has total integral 1, the equality is checked as desired. My question is: Suppose we didn't know to guess $\eta' = \rho(r)dr$. How would we have deduced it? Ie, let us just assume that $\eta' = \eta'_rdr + \eta'_\theta d\theta$, with support on the annulus of radii $\epsilon,\epsilon'$. Thus we want to find $\eta'_r,\eta'_\theta$ such that: $$\int_0^{2\pi}\omega_\theta(1,\theta)d\theta =  \int_0^{2\pi}\int_\epsilon^{\epsilon'}\omega_r\eta'_\theta drd\theta - \int_0^{2\pi}\int_\epsilon^{\epsilon'}\omega_\theta\eta'_r drd\theta$$ The fact that $\omega,\eta$ are closed is the same as saying that $\frac{\partial\omega_r}{\partial\theta} = \frac{\partial\omega_\theta}{\partial r}$ and $\frac{\partial\eta'_r}{\partial\theta} = \frac{\partial\eta'_\theta}{\partial r}$. How can we deduce that we may pick $\eta'$ to be of the form $\eta' = \rho(r)dr$?",,[]
73,Diffeomorphism between a submanifold of $\mathbb{R}^4$ and $\mathbb{S}^2$,Diffeomorphism between a submanifold of  and,\mathbb{R}^4 \mathbb{S}^2,"Problem 5-1 from John Lee's Introduction to Smooth Manifolds ask us to show that the submanifold $\Phi^{-1}(0,1) \subset \mathbb{R}^4$ is diffeomorphic to $\mathbb{S}^2$, where $\Phi: \mathbb{R}^4 \to \mathbb{R}^2$ is given by $\Phi(x,y,s,t) = (x^2 + y, x^2 + y^2 + s^2 + t^2 + y)$. For me, it seems natural to try to show the map $F: \Phi^{-1}(0,1) \to \mathbb{S}^2$ given by $F(x,y,s,t) = (y,s,t)$ is a diffeomorphism. However the condition $x^2 + y = 0$ implies that if $(x,y,s,t) \in \Phi^{-1}(0,1)$, then $y \leq 0$ and so the map $F$ cannot be surjective. Any idea is welcome!","Problem 5-1 from John Lee's Introduction to Smooth Manifolds ask us to show that the submanifold $\Phi^{-1}(0,1) \subset \mathbb{R}^4$ is diffeomorphic to $\mathbb{S}^2$, where $\Phi: \mathbb{R}^4 \to \mathbb{R}^2$ is given by $\Phi(x,y,s,t) = (x^2 + y, x^2 + y^2 + s^2 + t^2 + y)$. For me, it seems natural to try to show the map $F: \Phi^{-1}(0,1) \to \mathbb{S}^2$ given by $F(x,y,s,t) = (y,s,t)$ is a diffeomorphism. However the condition $x^2 + y = 0$ implies that if $(x,y,s,t) \in \Phi^{-1}(0,1)$, then $y \leq 0$ and so the map $F$ cannot be surjective. Any idea is welcome!",,"['differential-geometry', 'manifolds']"
74,Do there exist energy-minimizing immersions?,Do there exist energy-minimizing immersions?,,"Let $M,N$ be $d$ -dimensional connected oriented Riemannian manifolds, possibly with boundary, $M$ compact. Let $E_d:C^{\infty}(M,N) \to \mathbb{R}$ be the $d$ -energy, i.e. $$ E_d(f)=\int_M |df|^d \text{Vol}_M.$$ Set $E_{M,N}=\inf \{ E_d(f) \, | \,\, f \in C^{\infty}(M,N) \text{ is an immersion} \}$ , and suppose that $E_{M,N} >0$ . Does $E_{M,N}$ always obtained? i.e. does there exist an immersion with minimal energy? (I am assuming there exist at least one immersion from $M$ to $N$ .  ) I am specifically considering the $d$ -energy between $d$ -manifolds, and not the $2$ -energy; for the $2$ -energy the answer can be negative; it is known that $$\inf_{f \in \text{Diff}(\mathbb{S}^n) }  E_2(f) =0$$ when $n >2$ , but there is no immersion with zero $2$ -energy. However, the identity map $\text{Id}_{M^d}$ has minimal $d$ -energy among all diffeomorphisms. (So, in particular, for any simply-connected and closed $M$ , we have $E_{M,M}=E_d(\text{Id}_{M})$ as any immersion is a diffeomorphism).","Let be -dimensional connected oriented Riemannian manifolds, possibly with boundary, compact. Let be the -energy, i.e. Set , and suppose that . Does always obtained? i.e. does there exist an immersion with minimal energy? (I am assuming there exist at least one immersion from to .  ) I am specifically considering the -energy between -manifolds, and not the -energy; for the -energy the answer can be negative; it is known that when , but there is no immersion with zero -energy. However, the identity map has minimal -energy among all diffeomorphisms. (So, in particular, for any simply-connected and closed , we have as any immersion is a diffeomorphism).","M,N d M E_d:C^{\infty}(M,N) \to \mathbb{R} d  E_d(f)=\int_M |df|^d \text{Vol}_M. E_{M,N}=\inf \{ E_d(f) \, | \,\, f \in C^{\infty}(M,N) \text{ is an immersion} \} E_{M,N} >0 E_{M,N} M N d d 2 2 \inf_{f \in \text{Diff}(\mathbb{S}^n) }  E_2(f) =0 n >2 2 \text{Id}_{M^d} d M E_{M,M}=E_d(\text{Id}_{M})","['differential-geometry', 'riemannian-geometry', 'calculus-of-variations', 'harmonic-functions', 'variational-analysis']"
75,Geodesically convex neighborhoods,Geodesically convex neighborhoods,,"Let $(M,g)$ be a Riemannian manifold. As part of an exercise, I have proved the following two facts: For every $m\in M$ there exists $\varepsilon >0$  and an open neighborhood $U$ of $m$ such that: for every $x$ and $y$ in $U$  there is $v\in T_x M$ with $||v||<\varepsilon$ and such that $\textrm{exp }(x,v)=y.$ I have proved this by using the inverse function theorem. If $\gamma$ is a non-radial geodesic contained in some geodesic ball $\textrm{exp}_m (B(\varepsilon))$ then $r\circ \gamma$ attains its maximum  values at the endpoints (cannot have strict maximums). To prove this I have used the geodesic equation locally. Now I have to show as a consequence of the previous facts that every point has a geodesically convex neighborhood, i.e. that for every pair of points there is a lengh minimizing geodesic joining them, and such that it is contained in the neighborhood for every time. It seems it should be easy to solve regarding the previous facts, but I am not able to prove it...","Let $(M,g)$ be a Riemannian manifold. As part of an exercise, I have proved the following two facts: For every $m\in M$ there exists $\varepsilon >0$  and an open neighborhood $U$ of $m$ such that: for every $x$ and $y$ in $U$  there is $v\in T_x M$ with $||v||<\varepsilon$ and such that $\textrm{exp }(x,v)=y.$ I have proved this by using the inverse function theorem. If $\gamma$ is a non-radial geodesic contained in some geodesic ball $\textrm{exp}_m (B(\varepsilon))$ then $r\circ \gamma$ attains its maximum  values at the endpoints (cannot have strict maximums). To prove this I have used the geodesic equation locally. Now I have to show as a consequence of the previous facts that every point has a geodesically convex neighborhood, i.e. that for every pair of points there is a lengh minimizing geodesic joining them, and such that it is contained in the neighborhood for every time. It seems it should be easy to solve regarding the previous facts, but I am not able to prove it...",,"['differential-geometry', 'riemannian-geometry']"
76,What is a mathematical definition of the Maxwellian spacetime?,What is a mathematical definition of the Maxwellian spacetime?,,"While this problem originated in physics, the question is purely mathematical. Because Maxwell's equations were not invariant under the Galilean transformation, Maxwell proposed his version of spacetime. It is as a 4D collection of points, such that: Between any two points $p(t, x, y, z)$ and $q(t', x', y', z')$ there is a definite temporal interval $T(p, q) = t' − t$. Between any two simultaneous points $p(t, x, y, z)$ and $q(t, x', y', z')$ there is a definite Euclidean distance $$R(p,q) = \sqrt{(x' − x)^2 + (y' − y)^2 + (z' − z)^2}$$ Any worldline $\gamma$ through the point $p$ has a definite twist $\Omega(γ, p)$. As a result of the third condition, linear acceleration is not absolute like in the Galilean spacetime. There is not enough structure in the Maxwellian spacetime to distinguish straight worldlines from curved worldlines. However, rotation is still absolute, because the third condition allows telling when a worldline is ""twisted"". For a worldline $\gamma$ and a point $p$ on $\gamma$, the absolute rotation of $\gamma$ w.r.t. $p$ is given by $\Omega(γ, p)$. (Image and partial content credit: Jonathan Bain, NY University .) Properties of the Maxwellian spacetime: No inertial frames (as opposed to many inertial frames in the Galilean spacetime). Velocity is relative. Acceleration is relative (as opposed to absolute in the Galilean spacetime). Rotation is absolute. Simultaneity is absolute. The mathematical definition of the Galilean spacetime is a tuple $(\mathbb{R}^4,t_{ab},h^{ab},\nabla)$ where $t_{ab}$ (temporal metric) and $h^{ab}$ (spatial metric) are tensor fields and $\nabla$ is the coordinate derivative operator specifying the geodesic trajectories ( Spacetime Structure ). A single metric does not work, because the speed of light is infinite, so time and space should be treated separately with the temporal metric: $$t_{ab}=(\text{d}_a t)(\text{d}_b t)$$ and the spatial metric: $$h^{ab}=\left(\dfrac{\partial}{\partial x}\right)^a\left(\dfrac{\partial}{\partial x}\right)^b+ \left(\dfrac{\partial}{\partial y}\right)^a\left(\dfrac{\partial}{\partial y}\right)^b+ \left(\dfrac{\partial}{\partial z}\right)^a\left(\dfrac{\partial}{\partial z}\right)^b$$ Finally, $\nabla$ on $\mathbb{R}^4$ is a unique flat derivative operator that for each coordinate $x^i$ satisfies: $$\nabla_a\left(\dfrac{\partial}{\partial x^i}\right)^b=\mathbf{0}$$ In turn, the Newtonian spacetime is the same tuple with an additional structure $(\mathbb{R}^4,t_{ab},h^{ab},\nabla,\lambda^a)$ where $\lambda^a$ is a field that adds the preferred frame of rest: $$\lambda^a=\left(\dfrac{\partial}{\partial t}\right)^a$$ What is a rigorous mathematical definition of the Maxwellian spacetime? Intuitively, it may be the same Galilean tuple, but with some additional structure (or a reduced structure) similar to how the Newtonian spacetime is created by adding $\lambda$ to the Galilean tuple. Thanks for your help!","While this problem originated in physics, the question is purely mathematical. Because Maxwell's equations were not invariant under the Galilean transformation, Maxwell proposed his version of spacetime. It is as a 4D collection of points, such that: Between any two points $p(t, x, y, z)$ and $q(t', x', y', z')$ there is a definite temporal interval $T(p, q) = t' − t$. Between any two simultaneous points $p(t, x, y, z)$ and $q(t, x', y', z')$ there is a definite Euclidean distance $$R(p,q) = \sqrt{(x' − x)^2 + (y' − y)^2 + (z' − z)^2}$$ Any worldline $\gamma$ through the point $p$ has a definite twist $\Omega(γ, p)$. As a result of the third condition, linear acceleration is not absolute like in the Galilean spacetime. There is not enough structure in the Maxwellian spacetime to distinguish straight worldlines from curved worldlines. However, rotation is still absolute, because the third condition allows telling when a worldline is ""twisted"". For a worldline $\gamma$ and a point $p$ on $\gamma$, the absolute rotation of $\gamma$ w.r.t. $p$ is given by $\Omega(γ, p)$. (Image and partial content credit: Jonathan Bain, NY University .) Properties of the Maxwellian spacetime: No inertial frames (as opposed to many inertial frames in the Galilean spacetime). Velocity is relative. Acceleration is relative (as opposed to absolute in the Galilean spacetime). Rotation is absolute. Simultaneity is absolute. The mathematical definition of the Galilean spacetime is a tuple $(\mathbb{R}^4,t_{ab},h^{ab},\nabla)$ where $t_{ab}$ (temporal metric) and $h^{ab}$ (spatial metric) are tensor fields and $\nabla$ is the coordinate derivative operator specifying the geodesic trajectories ( Spacetime Structure ). A single metric does not work, because the speed of light is infinite, so time and space should be treated separately with the temporal metric: $$t_{ab}=(\text{d}_a t)(\text{d}_b t)$$ and the spatial metric: $$h^{ab}=\left(\dfrac{\partial}{\partial x}\right)^a\left(\dfrac{\partial}{\partial x}\right)^b+ \left(\dfrac{\partial}{\partial y}\right)^a\left(\dfrac{\partial}{\partial y}\right)^b+ \left(\dfrac{\partial}{\partial z}\right)^a\left(\dfrac{\partial}{\partial z}\right)^b$$ Finally, $\nabla$ on $\mathbb{R}^4$ is a unique flat derivative operator that for each coordinate $x^i$ satisfies: $$\nabla_a\left(\dfrac{\partial}{\partial x^i}\right)^b=\mathbf{0}$$ In turn, the Newtonian spacetime is the same tuple with an additional structure $(\mathbb{R}^4,t_{ab},h^{ab},\nabla,\lambda^a)$ where $\lambda^a$ is a field that adds the preferred frame of rest: $$\lambda^a=\left(\dfrac{\partial}{\partial t}\right)^a$$ What is a rigorous mathematical definition of the Maxwellian spacetime? Intuitively, it may be the same Galilean tuple, but with some additional structure (or a reduced structure) similar to how the Newtonian spacetime is created by adding $\lambda$ to the Galilean tuple. Thanks for your help!",,"['differential-geometry', 'metric-spaces', 'coordinate-systems']"
77,Defining integration on analytic subvarieties,Defining integration on analytic subvarieties,,"Let $X$ be a compact complex manifold, and let $V$ be an analytic subvariety. In books like Griffiths-Harris: Principles of algebraic geometry , they authors freely integrate differential forms on $V$, without caring about whether it is well-defined. For example, in page 140, it says ""Recall also that for any analytic subvariety $V$ of dimension $k$, we have defined the fundamental class $(V)\in H_{2k}(X,\mathbb{R})$ to be given by the linear functional $\varphi\mapsto\int_{V}\varphi$ on $H_{DR}^{2k}(X)$..."" 1) It's not clear to me how the integration is defined; as far as I know, integration can be defined on manifolds or chains, but I'm not sure how to define it on a closed subset, since pullback on a closed subset doesn't make sense (I guess, right?). Does one do it by covering the closed subset by charts, and then taking partition of unity subordinate to an open cover containing the charts? Or is there some other way of defining it? Can one define it in general for any closed bounded subset, or are analytic subvarieties special? 2) Also, at least for $\mathbb {R}^n$ by a theorem due to Lebesgue, a bounded continuous function on a bounded subset $A$ is integrable as long as boundary of $A$ has measure zero; but I'm not sure whether the same is true for an analytic subvariety. (Sorry for this vague question; here I'm just trying to find a connection between the theory on $\mathbb{R}^n$ and manifolds in general). Any help would be appreciated.","Let $X$ be a compact complex manifold, and let $V$ be an analytic subvariety. In books like Griffiths-Harris: Principles of algebraic geometry , they authors freely integrate differential forms on $V$, without caring about whether it is well-defined. For example, in page 140, it says ""Recall also that for any analytic subvariety $V$ of dimension $k$, we have defined the fundamental class $(V)\in H_{2k}(X,\mathbb{R})$ to be given by the linear functional $\varphi\mapsto\int_{V}\varphi$ on $H_{DR}^{2k}(X)$..."" 1) It's not clear to me how the integration is defined; as far as I know, integration can be defined on manifolds or chains, but I'm not sure how to define it on a closed subset, since pullback on a closed subset doesn't make sense (I guess, right?). Does one do it by covering the closed subset by charts, and then taking partition of unity subordinate to an open cover containing the charts? Or is there some other way of defining it? Can one define it in general for any closed bounded subset, or are analytic subvarieties special? 2) Also, at least for $\mathbb {R}^n$ by a theorem due to Lebesgue, a bounded continuous function on a bounded subset $A$ is integrable as long as boundary of $A$ has measure zero; but I'm not sure whether the same is true for an analytic subvariety. (Sorry for this vague question; here I'm just trying to find a connection between the theory on $\mathbb{R}^n$ and manifolds in general). Any help would be appreciated.",,"['differential-geometry', 'complex-geometry']"
78,Covariant derivatives for bundle maps,Covariant derivatives for bundle maps,,"Suppose that $M$ is a smooth manifold and $\nabla$ is an affine connection on it (in my case it is the Levi-Civita connection of a Riemannian metric, but probably this is not relevant). If $E$ and $F$ are linear bundles over $M$, I call a bundle map a smooth map $E \to F$ that covers the identity map on $M$. Also, $M$ can be seen as a trivial bundle over itself. A vector field $X$ can be interpreted as a bundle map $M \to T^1M$. Then $\nabla X$ is a bundle map $M \to T^1_1M$, and the same construction can be repeated for tensors of any order. What I would like to do is to use $\nabla$ to differentiate bundle maps between tensor spaces, i.e., maps of the type $G \colon T^k_hM \to T^p_qM$. Is there some reference that lays the theoretical foundations for this operation and the basic properties? In particular, I would like to have a chain-rule-like formula: if $X \colon M \to T^1M$ and $G \colon T^1M \to T^1M$, what is $\nabla(G \circ X)$ in terms of $\nabla X$ and the derivatives of $G$?","Suppose that $M$ is a smooth manifold and $\nabla$ is an affine connection on it (in my case it is the Levi-Civita connection of a Riemannian metric, but probably this is not relevant). If $E$ and $F$ are linear bundles over $M$, I call a bundle map a smooth map $E \to F$ that covers the identity map on $M$. Also, $M$ can be seen as a trivial bundle over itself. A vector field $X$ can be interpreted as a bundle map $M \to T^1M$. Then $\nabla X$ is a bundle map $M \to T^1_1M$, and the same construction can be repeated for tensors of any order. What I would like to do is to use $\nabla$ to differentiate bundle maps between tensor spaces, i.e., maps of the type $G \colon T^k_hM \to T^p_qM$. Is there some reference that lays the theoretical foundations for this operation and the basic properties? In particular, I would like to have a chain-rule-like formula: if $X \colon M \to T^1M$ and $G \colon T^1M \to T^1M$, what is $\nabla(G \circ X)$ in terms of $\nabla X$ and the derivatives of $G$?",,"['differential-geometry', 'reference-request']"
79,"Prove that if all geodesics of a surface $S$ are planar curves, then $S$ is contained in a plane or a sphere","Prove that if all geodesics of a surface  are planar curves, then  is contained in a plane or a sphere",S S,"I know that if $\alpha$ is geodesic and its curvature is never zero, and it's plane, then it's a line of curvature (i.e. the tangent is a principal direction). I can prove this using Frenet. I want to show first that all points are umbilical, because then I know how to prove that the curvature is constant, so the surface must be in a plane, a pshere, or the pseudosphere (but it can't be the pseudosphere because of reasons). Given a point in the surface, and a direction, there exists one and only one geodesic in that direction. If the curvature is never zero, the direction is principal. If I can do this with all points and all directions, all points are umbilical. But...it can happen that the curvature of the geodesic is zero and I don't know what to do in that case. Can you help me?","I know that if $\alpha$ is geodesic and its curvature is never zero, and it's plane, then it's a line of curvature (i.e. the tangent is a principal direction). I can prove this using Frenet. I want to show first that all points are umbilical, because then I know how to prove that the curvature is constant, so the surface must be in a plane, a pshere, or the pseudosphere (but it can't be the pseudosphere because of reasons). Given a point in the surface, and a direction, there exists one and only one geodesic in that direction. If the curvature is never zero, the direction is principal. If I can do this with all points and all directions, all points are umbilical. But...it can happen that the curvature of the geodesic is zero and I don't know what to do in that case. Can you help me?",,"['differential-geometry', 'geodesic']"
80,References for differential cohomology and secondary characteristic classes,References for differential cohomology and secondary characteristic classes,,"I am interested in differential cohomology & secondary characteristic classes and am currently studying the notes by Ulrich Bunke. While these are nice notes, I sometimes find it hard to fill in the gaps in the proofs. Could someone please suggest a reference that I could use to supplement the article ? Are there any other good references on this subject for a beginner ? As regards my background, I have studied homology and cohomology theory, basic homotopy theory & topology of fibre bundles (from Husemoller's book) and differential geometry (connections, curvature, deRham cohomology, chern classes). Thanks a lot !","I am interested in differential cohomology & secondary characteristic classes and am currently studying the notes by Ulrich Bunke. While these are nice notes, I sometimes find it hard to fill in the gaps in the proofs. Could someone please suggest a reference that I could use to supplement the article ? Are there any other good references on this subject for a beginner ? As regards my background, I have studied homology and cohomology theory, basic homotopy theory & topology of fibre bundles (from Husemoller's book) and differential geometry (connections, curvature, deRham cohomology, chern classes). Thanks a lot !",,"['differential-geometry', 'reference-request', 'algebraic-topology']"
81,"Is $T(M)$ necessarily equivalent to the normal bundle of $M$ in $\textbf{R}^{2n}$, if $M$ is totally real?","Is  necessarily equivalent to the normal bundle of  in , if  is totally real?",T(M) M \textbf{R}^{2n} M,"Consider real submanifolds, $M^n \subset \textbf{C}^n$. ($\textbf{C}^n \equiv (\textbf{R}^{2n}, J)$, where $J(x, y) = (-y, x)$). $M^n$ is totally real if $J(T_pM) \cap T_pM = 0$, for all $p \in M$. Is $T(M)$ necessarily equivalent to the normal bundle of $M$ in $\textbf{R}^{2n}$, if $M$ is totally real?","Consider real submanifolds, $M^n \subset \textbf{C}^n$. ($\textbf{C}^n \equiv (\textbf{R}^{2n}, J)$, where $J(x, y) = (-y, x)$). $M^n$ is totally real if $J(T_pM) \cap T_pM = 0$, for all $p \in M$. Is $T(M)$ necessarily equivalent to the normal bundle of $M$ in $\textbf{R}^{2n}$, if $M$ is totally real?",,"['differential-geometry', 'manifolds']"
82,Literature Request: Stochastic Differential Geometry,Literature Request: Stochastic Differential Geometry,,"I've in my studies taken (introductory, at the masters level) courses on both stochastic calculus, differential geometry (both elementary at the level of Pressley's book, and more advanced at the level of John Lee's ""Introduction to Smooth Manifolds"") and Riemannian geometry, all of which I have found very interesting. However, I have also heard of there being an intersection of these subjects in what is apparently called stochastic differential geometry. Needless to say, that sounds incredibly fun, and I would like to try and study it in my free time. The point of this post is, I would like some help in where to start. A quick Google-search brings up some articles, a couple sets of lecture notes, and some Springer books. I've had a quick look at those (previews in the case of books), but I'd like to have some established opinions to help me choose. Does anyone have any recommendations for someone learning the subject for the first time? For the sake of comparison, in Algebra people often point to Dummit & Foote, Fraleigh, Lang, or maybe some other book when one asks for references. Topologists point to Munkres or Hatcher, differential geometers to Lee, Spivak or do Carmo, and in (real) analysis we have Baby-Rudin. I want to know if there are similar ""universally acclaimed"" references in stochastic differential geometry that I should look out for. (I have seen the following post already, but I feel that I ask for a more general reference: what are prerequisite to study Stochastic differential geometry? )","I've in my studies taken (introductory, at the masters level) courses on both stochastic calculus, differential geometry (both elementary at the level of Pressley's book, and more advanced at the level of John Lee's ""Introduction to Smooth Manifolds"") and Riemannian geometry, all of which I have found very interesting. However, I have also heard of there being an intersection of these subjects in what is apparently called stochastic differential geometry. Needless to say, that sounds incredibly fun, and I would like to try and study it in my free time. The point of this post is, I would like some help in where to start. A quick Google-search brings up some articles, a couple sets of lecture notes, and some Springer books. I've had a quick look at those (previews in the case of books), but I'd like to have some established opinions to help me choose. Does anyone have any recommendations for someone learning the subject for the first time? For the sake of comparison, in Algebra people often point to Dummit & Foote, Fraleigh, Lang, or maybe some other book when one asks for references. Topologists point to Munkres or Hatcher, differential geometers to Lee, Spivak or do Carmo, and in (real) analysis we have Baby-Rudin. I want to know if there are similar ""universally acclaimed"" references in stochastic differential geometry that I should look out for. (I have seen the following post already, but I feel that I ask for a more general reference: what are prerequisite to study Stochastic differential geometry? )",,"['differential-geometry', 'reference-request', 'manifolds', 'riemannian-geometry', 'stochastic-calculus']"
83,Parametrizations and coordinates in differential geometry - what's the difference?,Parametrizations and coordinates in differential geometry - what's the difference?,,"From what I've read one can introduce the notion of a tangent vector to a point on a manifold in terms of an equivalence class of curves passing through that point (the equivalence relation being that they have the same tangent at that point). Now my confusion arises from the fact that in the texts that I've read, the author introduces a curve $\gamma :(a,b)\subset\mathbb{R}\rightarrow M$ that is parametrized in terms of some real parameter $t\in (a,b)$, with $a<0<b$ and $\gamma (0)=p\in M$. From this a tangent vector at a point $p\in M$ can be defined in a coordinate independent manner, in terms of the directional derivative of function $f:M\rightarrow\mathbb{R}$, as $$\frac{df}{dt}\bigg\vert_{p}$$  I know that if one introduces a coordinate chart $(U,\phi)$ (where $p\in U$) then the curve can be represented in terms of the local coordinates, $$(\phi\circ\gamma)(t)=\gamma (x^{1}(t),\ldots ,x^{n}(t))$$ So what distinguishes a parameter $t$ (parametrizing the curve $\gamma$) from a coordinate? Is it that the parameter is defined in terms of an intrinsic property of the curve (such as arc-length) and thus is independent of any coordinate system, or am I completely misunderstanding things?","From what I've read one can introduce the notion of a tangent vector to a point on a manifold in terms of an equivalence class of curves passing through that point (the equivalence relation being that they have the same tangent at that point). Now my confusion arises from the fact that in the texts that I've read, the author introduces a curve $\gamma :(a,b)\subset\mathbb{R}\rightarrow M$ that is parametrized in terms of some real parameter $t\in (a,b)$, with $a<0<b$ and $\gamma (0)=p\in M$. From this a tangent vector at a point $p\in M$ can be defined in a coordinate independent manner, in terms of the directional derivative of function $f:M\rightarrow\mathbb{R}$, as $$\frac{df}{dt}\bigg\vert_{p}$$  I know that if one introduces a coordinate chart $(U,\phi)$ (where $p\in U$) then the curve can be represented in terms of the local coordinates, $$(\phi\circ\gamma)(t)=\gamma (x^{1}(t),\ldots ,x^{n}(t))$$ So what distinguishes a parameter $t$ (parametrizing the curve $\gamma$) from a coordinate? Is it that the parameter is defined in terms of an intrinsic property of the curve (such as arc-length) and thus is independent of any coordinate system, or am I completely misunderstanding things?",,"['differential-geometry', 'coordinate-systems', 'smooth-manifolds']"
84,Linear algebra revisited: What do we do when we set a coordinate system?,Linear algebra revisited: What do we do when we set a coordinate system?,,"I was learning about covariant and contravariant vectors due to special relativity, and it occured to me that we don't live in $\mathbb{R}^4$. I'll explain myself better. Consider the space of polynomials of degree $\leq n$. This is a vector space, and choosing ${1,x,x^2,...,x^n}$ as a basis makes perfect sense: those objects exist regardless of their coordinates. However, when we set up a coordinate system in classical mechanics (for example) we have a preesisting space (the ""physical world""), in which we choose a point (which is going to be the $0$ of our identification with $\mathbb{R}^3$) and then a basis with which we are able to give coordinates to that point. So far so good, except that I have no idea what the ""physical world"" is without resorting to an $\mathbb{R}^3$ description in the first place. Now, I thought of thinking about the ""physical world"" in a manifold sense: you have a topological space $(M, \tau)$ and you construct an atlas with one chart. In that sense, we can talk about coordinates and when we choose a reference point we are equipping the topological space of a manifold structure to talk unambiguously of points. My question is: what's that topological space? What is the space I am equipping with a manifold structure?","I was learning about covariant and contravariant vectors due to special relativity, and it occured to me that we don't live in $\mathbb{R}^4$. I'll explain myself better. Consider the space of polynomials of degree $\leq n$. This is a vector space, and choosing ${1,x,x^2,...,x^n}$ as a basis makes perfect sense: those objects exist regardless of their coordinates. However, when we set up a coordinate system in classical mechanics (for example) we have a preesisting space (the ""physical world""), in which we choose a point (which is going to be the $0$ of our identification with $\mathbb{R}^3$) and then a basis with which we are able to give coordinates to that point. So far so good, except that I have no idea what the ""physical world"" is without resorting to an $\mathbb{R}^3$ description in the first place. Now, I thought of thinking about the ""physical world"" in a manifold sense: you have a topological space $(M, \tau)$ and you construct an atlas with one chart. In that sense, we can talk about coordinates and when we choose a reference point we are equipping the topological space of a manifold structure to talk unambiguously of points. My question is: what's that topological space? What is the space I am equipping with a manifold structure?",,"['differential-geometry', 'manifolds']"
85,characterization of non compact surfaces in $\mathbb{R^3}$,characterization of non compact surfaces in,\mathbb{R^3},"Is there a way to characterize non compact surfaces with constant mean and gaussian curvature. I know that if $K=0=H$ then the surface is a plane. How can I know about the others? Just to add, for compact surfaces with constant positive curvature I know Liebmann's theorem as well. But i want to do it for non compact surfaces. Any help???? Assuming $K$ and $H$ constant. If $k_1$ and $k_2$ are principal curvature then $k_1=H+\sqrt{H^2-K}$ and $k_2=H-\sqrt{H^2-K}$, for compact surfaces I only have $k_1=k_2$ and $k_1>k_2$ is not possible. What can i say about them in this case?","Is there a way to characterize non compact surfaces with constant mean and gaussian curvature. I know that if $K=0=H$ then the surface is a plane. How can I know about the others? Just to add, for compact surfaces with constant positive curvature I know Liebmann's theorem as well. But i want to do it for non compact surfaces. Any help???? Assuming $K$ and $H$ constant. If $k_1$ and $k_2$ are principal curvature then $k_1=H+\sqrt{H^2-K}$ and $k_2=H-\sqrt{H^2-K}$, for compact surfaces I only have $k_1=k_2$ and $k_1>k_2$ is not possible. What can i say about them in this case?",,['differential-geometry']
86,Making a gradient-like vector field a gradient vector field via choosing a Riemannian metric.,Making a gradient-like vector field a gradient vector field via choosing a Riemannian metric.,,Let $\xi$ be a vector field on manifold $M^n$ which is a gradient-like vector field for a some Morse function $f$. Prove that there exists a Riemannian metric on $M$ such that $\xi$ is a gradient vector field for $M$.,Let $\xi$ be a vector field on manifold $M^n$ which is a gradient-like vector field for a some Morse function $f$. Prove that there exists a Riemannian metric on $M$ such that $\xi$ is a gradient vector field for $M$.,,"['differential-geometry', 'differential-topology', 'morse-theory']"
87,Orientability of Stiefel manifold $V_2(\mathbb R^4)$,Orientability of Stiefel manifold,V_2(\mathbb R^4),"What is an easy proof of orientability of Stiefel manifold $V_2(\mathbb{R}^4)$ (pairs of orthonormal vectors from $\mathbb{R}^4$ - subset of $\mathbb{R}^8$)? All  proofs I found deal with Lie groups and other complicated for me stuff. I suppose that there is an easy proof because task was given to me by my teacher in university, and our differential geometry course doesn't include Lie groups.","What is an easy proof of orientability of Stiefel manifold $V_2(\mathbb{R}^4)$ (pairs of orthonormal vectors from $\mathbb{R}^4$ - subset of $\mathbb{R}^8$)? All  proofs I found deal with Lie groups and other complicated for me stuff. I suppose that there is an easy proof because task was given to me by my teacher in university, and our differential geometry course doesn't include Lie groups.",,"['differential-geometry', 'manifolds', 'stiefel-manifolds']"
88,Slice of a coordinate system in a manifold,Slice of a coordinate system in a manifold,,"In the book - Foundations of differentiable manifolds and Lie groups by Frank Warner, the definition of a slice is as under. Suppose that $(U,\phi)$ is a coordinate system on $M$ (dimension $d$) with coordinate functions $x_1,...,x_d$, and that $c$ is an integer such that $0\leq c\leq d$. Let $a=(a_1,...,a_d)\in\phi(U)$, and let $S=\{q\in U\ :\ x_i(q)=a_i,i=c+1,...d\}$. Then the subspace $S$ of $M$ together with the coordinate system $\{x_j|_S:j=1,...,c\}$ forms a manifold which is a submanifold of $M$ called a slice of the coordinate system $(U,\phi)$. Now, it seems to me that, even though in the definition we are fixing the last few coordinates, we could do the same to any random coordinates (not necessarily the last few) and still we would get a slice (if we can call that one). Warner next proves a proposition that : Let $\psi:M^c\longrightarrow N^d$ be an immersion and let $m\in M$. Then there exists a cubic centered coordinate system $(V,\phi)$ about $\psi(m)$ and a neighbourhood $U$ of $m$ such that $\psi|_U$ is 1:1 and $\psi(U)$ is a slice of $(V,\phi)$. He follows this by a remark in which I have a doubt. The remark is as follows I don't understand this example. Isn't $\psi(M)\cap V$ a union of two slices, the x-axis portion and the y-axis portion? Any help will be appreciated! Thanks in advance.","In the book - Foundations of differentiable manifolds and Lie groups by Frank Warner, the definition of a slice is as under. Suppose that $(U,\phi)$ is a coordinate system on $M$ (dimension $d$) with coordinate functions $x_1,...,x_d$, and that $c$ is an integer such that $0\leq c\leq d$. Let $a=(a_1,...,a_d)\in\phi(U)$, and let $S=\{q\in U\ :\ x_i(q)=a_i,i=c+1,...d\}$. Then the subspace $S$ of $M$ together with the coordinate system $\{x_j|_S:j=1,...,c\}$ forms a manifold which is a submanifold of $M$ called a slice of the coordinate system $(U,\phi)$. Now, it seems to me that, even though in the definition we are fixing the last few coordinates, we could do the same to any random coordinates (not necessarily the last few) and still we would get a slice (if we can call that one). Warner next proves a proposition that : Let $\psi:M^c\longrightarrow N^d$ be an immersion and let $m\in M$. Then there exists a cubic centered coordinate system $(V,\phi)$ about $\psi(m)$ and a neighbourhood $U$ of $m$ such that $\psi|_U$ is 1:1 and $\psi(U)$ is a slice of $(V,\phi)$. He follows this by a remark in which I have a doubt. The remark is as follows I don't understand this example. Isn't $\psi(M)\cap V$ a union of two slices, the x-axis portion and the y-axis portion? Any help will be appreciated! Thanks in advance.",,"['differential-geometry', 'manifolds']"
89,Show isometry of flow on a compact Riemannian manifold where the vector field is Killing,Show isometry of flow on a compact Riemannian manifold where the vector field is Killing,,"Let $(M,g)$ be a Riemannian manifold, $\nabla$ the Levi-Civita connection of $g$. A vector filed $V$ on $M$ is called a Killing field if for every $p\in M$ and every $X,Y\in T_p M$, $$ g(\nabla_X V, Y)+g(X,\nabla_Y V)=0 $$ Show that if $(M,g)$ is a compact Riemannian manifold, and $V$ is a Killing field, then the flow $\Psi_t$ of $V$ is an isometry for each $t$. Now to get us started, First we shall show that the rate of change of the metric $g_{\Psi_t(x)}(D_x\Psi_t X, D_x\Psi_t Y)$ with $t$ is zero at $t=0$ for any $X$ and $Y$ in $T_p M$.  Then use the local group property of the flow. Any help is appreciated. First we claim that $$ \nabla_{Xg} (X_i,X_j)=X(g(X_i,X_j))-([X,X_i],X_j)-([X,X_j],X_i)=X(g(X_i,X_j)),\dagger $$ Step 1 Define a connection for differentiating convector fields (1-forms). The derivative $\nabla_Y\omega$ should satisfy $$ Y(\omega(X))=(\nabla_Y\omega)(X)+\omega(\nabla_Y X). $$ Hence,  $$ (\nabla_Y\omega)(X) := Y(\omega(X))-\omega(\nabla_Y X).\qquad (1) $$ Apply (1), we have     \begin{align*} 		(\nabla_X g)(X_i, X_j)&=[Y,g](X_i,X_j)\\ 	&=Y(g(X_i,X_j))-g(\nabla_Y(X_i,X_j))\\ 		&=Y(g(X_i,X_j))-g(\nabla_Y X_i,X_j)-g(X_i,\nabla_Y X_j) 	\end{align*}","Let $(M,g)$ be a Riemannian manifold, $\nabla$ the Levi-Civita connection of $g$. A vector filed $V$ on $M$ is called a Killing field if for every $p\in M$ and every $X,Y\in T_p M$, $$ g(\nabla_X V, Y)+g(X,\nabla_Y V)=0 $$ Show that if $(M,g)$ is a compact Riemannian manifold, and $V$ is a Killing field, then the flow $\Psi_t$ of $V$ is an isometry for each $t$. Now to get us started, First we shall show that the rate of change of the metric $g_{\Psi_t(x)}(D_x\Psi_t X, D_x\Psi_t Y)$ with $t$ is zero at $t=0$ for any $X$ and $Y$ in $T_p M$.  Then use the local group property of the flow. Any help is appreciated. First we claim that $$ \nabla_{Xg} (X_i,X_j)=X(g(X_i,X_j))-([X,X_i],X_j)-([X,X_j],X_i)=X(g(X_i,X_j)),\dagger $$ Step 1 Define a connection for differentiating convector fields (1-forms). The derivative $\nabla_Y\omega$ should satisfy $$ Y(\omega(X))=(\nabla_Y\omega)(X)+\omega(\nabla_Y X). $$ Hence,  $$ (\nabla_Y\omega)(X) := Y(\omega(X))-\omega(\nabla_Y X).\qquad (1) $$ Apply (1), we have     \begin{align*} 		(\nabla_X g)(X_i, X_j)&=[Y,g](X_i,X_j)\\ 	&=Y(g(X_i,X_j))-g(\nabla_Y(X_i,X_j))\\ 		&=Y(g(X_i,X_j))-g(\nabla_Y X_i,X_j)-g(X_i,\nabla_Y X_j) 	\end{align*}",,"['differential-geometry', 'riemannian-geometry', 'semi-riemannian-geometry']"
90,Bishop - Gromov Comparison Theorem proof and references.,Bishop - Gromov Comparison Theorem proof and references.,,"I'm having trouble understanding a proof of the Bishop's volume comparison theorem and any help would be really appreciated. It's a simple part of the proof but I'm not quite getting what they want to say. The proof is the one in Gallot, Hulin and Lafontaine's Riemannian Geometry book. So it starts something like this: We take a geodesic $c(t)=\text{exp}_m(tu)$ with inicial point $m \in M$. Also take an o.n.b., $\, \{u,e_2,\cdots , e_n\}$, of  $\,T_mM$ (the tangent space of M at m), and parallel vector fields , $(E_i)_{2\leq i\leq n}$, along $c(t)$ such that $E_i(0)=e_i$. Now, given the correct restrictions so $T_{ru}\,\text{exp}_m$ (the differential of $\text{exp}_m$ at $ru\in T_mM$) is a isomorphism we can find Jacobi fields staisfying: $$Y_i^r(0)=0,\; Y_i^r(r)=E_i(r)$$ The specific form of these Jacobi fields is:  $$Y_i^r(t)=T_{tu}\text{exp}_m(tv) $$ Here we are making the identification $T_{ru}T_mM \approx T_mM$, and  $v \in T_mM$ is the unique vector such that $T_{ru}\text{exp}_m(rv)=E_i(r)$. So nothing worng with the setting until now, but then the proof reads: $``$Now, $$J(u,t)=C_r t^{1-n}\text{det}(Y_2^r(t),\dots,Y_n^r(t)) $$ $$\text{where } C_r^{-1}=\text{det}((Y_2'^{r}(0),\dots,Y_n'^{r}(0)) )""$$ Here $J(u,t)= t^{1-n}\text{ det}(g(\tilde Y_i(t),\tilde Y_j(t)))^{1/2}$ with $\tilde Y_i(t)$ being the Jacobi Field that satisfies $\tilde Y_i(0)=0$ and $\tilde Y_i'(0)=e_i$ for $2\leq i \leq n$. I totally don't get this statement, why are these equalities valid? I don't even understand what do they mean by $\text{det}(Y_2^r(t),\dots,Y_n^r(t)) $ since thay are already using another notation for the determinant of the metric. If anyone can help me clarify this it would be extremelly nice. Lastly, I would like to know if anybody can recomend another nice reference for a proof of this theorem or the Gromov Volume comparison theorem. Thanks!","I'm having trouble understanding a proof of the Bishop's volume comparison theorem and any help would be really appreciated. It's a simple part of the proof but I'm not quite getting what they want to say. The proof is the one in Gallot, Hulin and Lafontaine's Riemannian Geometry book. So it starts something like this: We take a geodesic $c(t)=\text{exp}_m(tu)$ with inicial point $m \in M$. Also take an o.n.b., $\, \{u,e_2,\cdots , e_n\}$, of  $\,T_mM$ (the tangent space of M at m), and parallel vector fields , $(E_i)_{2\leq i\leq n}$, along $c(t)$ such that $E_i(0)=e_i$. Now, given the correct restrictions so $T_{ru}\,\text{exp}_m$ (the differential of $\text{exp}_m$ at $ru\in T_mM$) is a isomorphism we can find Jacobi fields staisfying: $$Y_i^r(0)=0,\; Y_i^r(r)=E_i(r)$$ The specific form of these Jacobi fields is:  $$Y_i^r(t)=T_{tu}\text{exp}_m(tv) $$ Here we are making the identification $T_{ru}T_mM \approx T_mM$, and  $v \in T_mM$ is the unique vector such that $T_{ru}\text{exp}_m(rv)=E_i(r)$. So nothing worng with the setting until now, but then the proof reads: $``$Now, $$J(u,t)=C_r t^{1-n}\text{det}(Y_2^r(t),\dots,Y_n^r(t)) $$ $$\text{where } C_r^{-1}=\text{det}((Y_2'^{r}(0),\dots,Y_n'^{r}(0)) )""$$ Here $J(u,t)= t^{1-n}\text{ det}(g(\tilde Y_i(t),\tilde Y_j(t)))^{1/2}$ with $\tilde Y_i(t)$ being the Jacobi Field that satisfies $\tilde Y_i(0)=0$ and $\tilde Y_i'(0)=e_i$ for $2\leq i \leq n$. I totally don't get this statement, why are these equalities valid? I don't even understand what do they mean by $\text{det}(Y_2^r(t),\dots,Y_n^r(t)) $ since thay are already using another notation for the determinant of the metric. If anyone can help me clarify this it would be extremelly nice. Lastly, I would like to know if anybody can recomend another nice reference for a proof of this theorem or the Gromov Volume comparison theorem. Thanks!",,"['differential-geometry', 'riemannian-geometry']"
91,Mixed Partials from Peter Petersen's book,Mixed Partials from Peter Petersen's book,,"I am trying to understand how mixed partials are defined for a function $\gamma : \mathbb R^m \rightarrow M$ , where $M$ is an $n$ dimensional manifold, from Peter Petersen's ""Riemannian Geometry"" (Page 112). Please refer to the book. Let $\gamma\colon \mathbb{R}^m \to M$ .  We wish to define the second partials so that they lie in $TM$ as opposed to $TTM$ . Lemma 6 (Uniqueness of mixed partials): There is at most one way of defining mixed partials so that (1) $\frac{\partial^2 \gamma}{\partial t^i \partial t^j} = \frac{\partial^2 \gamma}{\partial t^j \partial t^i}$ and (2) $\frac{\partial}{\partial t^k}g(\frac{\partial\gamma}{{\partial t^i}}, \frac{\partial \gamma}{\partial t^j}) = g(\frac{\partial^2\gamma}{\partial t^k \partial t^i}, \frac{\partial \gamma}{\partial t^j}) + g(\frac{\partial \gamma}{\partial t^j}, \frac{\partial^2\gamma}{\partial t^k \partial t^j})$ both hold. My question is about lemma 6 (Page 112). I understand how he proves the Koszul type formula and makes an extension of $\gamma$ to $\overline{\gamma}$ , but why is that $\frac{\partial^2 \gamma}{\partial t^i \partial t^j} = \frac{\partial^2 \overline{\gamma}}{\partial t^i \partial t^j}$ ? More specifically, what does the last line of the proof mean and how does he conclude the proof with this last statement (please refer to the link provided by Anthony below) Thanks!","I am trying to understand how mixed partials are defined for a function , where is an dimensional manifold, from Peter Petersen's ""Riemannian Geometry"" (Page 112). Please refer to the book. Let .  We wish to define the second partials so that they lie in as opposed to . Lemma 6 (Uniqueness of mixed partials): There is at most one way of defining mixed partials so that (1) and (2) both hold. My question is about lemma 6 (Page 112). I understand how he proves the Koszul type formula and makes an extension of to , but why is that ? More specifically, what does the last line of the proof mean and how does he conclude the proof with this last statement (please refer to the link provided by Anthony below) Thanks!","\gamma : \mathbb R^m \rightarrow M M n \gamma\colon \mathbb{R}^m \to M TM TTM \frac{\partial^2 \gamma}{\partial t^i \partial t^j} = \frac{\partial^2 \gamma}{\partial t^j \partial t^i} \frac{\partial}{\partial t^k}g(\frac{\partial\gamma}{{\partial t^i}}, \frac{\partial \gamma}{\partial t^j}) = g(\frac{\partial^2\gamma}{\partial t^k \partial t^i}, \frac{\partial \gamma}{\partial t^j}) + g(\frac{\partial \gamma}{\partial t^j}, \frac{\partial^2\gamma}{\partial t^k \partial t^j}) \gamma \overline{\gamma} \frac{\partial^2 \gamma}{\partial t^i \partial t^j} = \frac{\partial^2 \overline{\gamma}}{\partial t^i \partial t^j}",['differential-geometry']
92,Is Poincare-Hopf index theorem connected with Leftschetz fixed point theorem?,Is Poincare-Hopf index theorem connected with Leftschetz fixed point theorem?,,"Lefschetz Fixed Point Theorem: For a compact triangulable space $X$, and a continuous map $f:X\rightarrow X$, we have   $$\sum_i(-1)^i\mathrm{Tr}(f_*|H_k(X,\mathbb{Q})=\sum_{x\in\mathrm{Fix}(f)}\mathrm{index} _x f$$ Poincare-Hopf Index Theorem: For a compact orientable differentiable manifold $M$, and a vector field $v$ on $M$ with isolated singularities, we have $$\sum_i(-1)^i\dim H_k(X,\mathbb{Q})=\sum_{x\in\mathrm{Sing}(v)}\mathrm{index}_xv$$ Observing the formal similarity between these formulae and the compatibility of the conditions, I came up the idea that they are connected. For one possible connection, I imagined that we can construct a map $f_v:M\rightarrow M$, by letting the points flow along $v$ (in a sufficiently short time?). Then this map is very similar (homotopic?) to $\mathrm{id}_M$, so trace is dimension. And by construction the two index should agree. So we can view the latter as a corollary. But I was not able to realize this. Can anyone tell me how to do it? Or it can be found in some texts?","Lefschetz Fixed Point Theorem: For a compact triangulable space $X$, and a continuous map $f:X\rightarrow X$, we have   $$\sum_i(-1)^i\mathrm{Tr}(f_*|H_k(X,\mathbb{Q})=\sum_{x\in\mathrm{Fix}(f)}\mathrm{index} _x f$$ Poincare-Hopf Index Theorem: For a compact orientable differentiable manifold $M$, and a vector field $v$ on $M$ with isolated singularities, we have $$\sum_i(-1)^i\dim H_k(X,\mathbb{Q})=\sum_{x\in\mathrm{Sing}(v)}\mathrm{index}_xv$$ Observing the formal similarity between these formulae and the compatibility of the conditions, I came up the idea that they are connected. For one possible connection, I imagined that we can construct a map $f_v:M\rightarrow M$, by letting the points flow along $v$ (in a sufficiently short time?). Then this map is very similar (homotopic?) to $\mathrm{id}_M$, so trace is dimension. And by construction the two index should agree. So we can view the latter as a corollary. But I was not able to realize this. Can anyone tell me how to do it? Or it can be found in some texts?",,"['differential-geometry', 'fixed-point-theorems']"
93,Simple exercise in cohomology,Simple exercise in cohomology,,"I know this is a simple exercise but I am stuck unfortunately. Question: Use de Rham cohomology to prove that the sphere $S^2$ is not diffeomorphic to the torus $T$. You may assume that $H^1(\mathbb{R}^2) = \{0\}$. Answer: For the sphere $S^2$, one can show that $H^1(S^2) \cong \{0\}$, for the torus one can show that $H^1(T) \cong  \mathbb{R}^2$. Now I don't know how to proceed, what I vaguely understand is that different cohomology implies the manifolds cannot be diffeomorphic. How can I make this precise ? In particular, I must be missing something because I don't know how to make use of the given fact $H^1(\mathbb{R^2}) \cong \{0\}$. Many thanks for your help!","I know this is a simple exercise but I am stuck unfortunately. Question: Use de Rham cohomology to prove that the sphere $S^2$ is not diffeomorphic to the torus $T$. You may assume that $H^1(\mathbb{R}^2) = \{0\}$. Answer: For the sphere $S^2$, one can show that $H^1(S^2) \cong \{0\}$, for the torus one can show that $H^1(T) \cong  \mathbb{R}^2$. Now I don't know how to proceed, what I vaguely understand is that different cohomology implies the manifolds cannot be diffeomorphic. How can I make this precise ? In particular, I must be missing something because I don't know how to make use of the given fact $H^1(\mathbb{R^2}) \cong \{0\}$. Many thanks for your help!",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'homology-cohomology']"
94,Can I solve the Frenet-Serret formulas with the only assumption that the cirvature-torsion of the curve are constant?,Can I solve the Frenet-Serret formulas with the only assumption that the cirvature-torsion of the curve are constant?,,"I am trying to find the general  equation for space curves which have constant curvatures throughout their length. In general I am interested for curves of more than 3 dimensions. Assuming that all curvatures are constant for the entire length of the space curve, can I use the frenet serret formulae to derive the most general representation of such a curve?","I am trying to find the general  equation for space curves which have constant curvatures throughout their length. In general I am interested for curves of more than 3 dimensions. Assuming that all curvatures are constant for the entire length of the space curve, can I use the frenet serret formulae to derive the most general representation of such a curve?",,['differential-geometry']
95,Isometries from Diffeomorphisms,Isometries from Diffeomorphisms,,"Given a compact, connected Lie group G of diffeomorphisms on a manifold M, how to construct a Riemannian metric on M such that elements of G are isometries of M?","Given a compact, connected Lie group G of diffeomorphisms on a manifold M, how to construct a Riemannian metric on M such that elements of G are isometries of M?",,"['differential-geometry', 'manifolds', 'lie-groups', 'riemannian-geometry']"
96,an injective immersion between two compact manifold of same dimension,an injective immersion between two compact manifold of same dimension,,"$f:M\rightarrow N$ be a injective immersion, where $M$ and $N$ are same dimensional manifold with out boundary, we need to show $f$ is a covering map. what I tried is, $df_x:T_x(M)\rightarrow T_{f(x)}(N)$ is injective and as $M$ and $N$ has the same dimension the map is isomorphism of vector spaces.Hence $f$ is surjective submersion also. So every point of $M$ is a regular value for $f$, now as $M$ is compact $f^{-1}(y)$ is finite, ingeneral I guess $f$ will become a proper map right? Now take any neighborhood $U$,of $y$, can I just say that $f^{-1}(U)$ is disjoint union of neighborhoods around the points $x_1,\dots,x_k$ where $f^{-1}(y)=\{x_1,\dots,x_k\}$? and $f$ maps homeomorphically those neighborhoods onot $U$? Thank you for help and correction of my answer in advance.","$f:M\rightarrow N$ be a injective immersion, where $M$ and $N$ are same dimensional manifold with out boundary, we need to show $f$ is a covering map. what I tried is, $df_x:T_x(M)\rightarrow T_{f(x)}(N)$ is injective and as $M$ and $N$ has the same dimension the map is isomorphism of vector spaces.Hence $f$ is surjective submersion also. So every point of $M$ is a regular value for $f$, now as $M$ is compact $f^{-1}(y)$ is finite, ingeneral I guess $f$ will become a proper map right? Now take any neighborhood $U$,of $y$, can I just say that $f^{-1}(U)$ is disjoint union of neighborhoods around the points $x_1,\dots,x_k$ where $f^{-1}(y)=\{x_1,\dots,x_k\}$? and $f$ maps homeomorphically those neighborhoods onot $U$? Thank you for help and correction of my answer in advance.",,"['differential-geometry', 'manifolds']"
97,Is there a fundamental misunderstanding here or have I made an algebraic slip?,Is there a fundamental misunderstanding here or have I made an algebraic slip?,,"Is there a fundamental misunderstanding here or have I made an algebraic slip? I have a Riemannian metric of the form $ds^2={du^2+dv^2\over 1-u^2-v^2}$ on an open disc and I want to prove that radial curve $(r(t), 0)$ is a geodesic. I wrote the metric in polar form -- $ds^2={dr^2+r^2d\theta^2\over 1-r^2}$, so the coefficients of the first fundamental form are $E={1\over 1-r^2}, F=0, G={r^2\over 1-r^2}$. So the geodesic equations become ${d\over dt} (E\dot{r})={1\over 2}{\partial \over \partial r} (E\dot{r}^2)$ and (another equation which works). I can always reparametrise $r(t)$ so that it has unit speed. And I get $2r\over (1-r^2)^2$= $r\over (1-r^2)^2$, which is clearly wrong! Why is there an extra factor of 2? Thank you. ADDED: Perhaps it would be helpful for me to point out that generally, for a Riemannian metric of the form $Edu^2+2Fdudv+Gdv^2$ and geodesic $g(t)=(a(t),b(t))$, the Euler Lagrange equations are ${d\over dt} (E\dot{a}+F\dot{b})={1\over 2} (E_u\dot{a}^2+2F_u\dot{a}\dot{b}+G_u\dot{b}^2)$ and ${d\over dt} (F\dot{a}+G\dot{b})={1\over 2} (E_v\dot{a}^2+2F_v\dot{a}\dot{b}+G_v\dot{b}^2)$ where $\dot{a}={d\over dt}a,\,\,\,E_u={\partial\over\partial u}E$ and so on. EUREKA! Ooh, I think I know what the bug is, The geodesic has constant speed, but the inner product here is not simply the Euclidean one which is what I assumed when I set $\dot{r}=1$! I think it works fine now. :) -- I write it here because I can't post it as an answer...","Is there a fundamental misunderstanding here or have I made an algebraic slip? I have a Riemannian metric of the form $ds^2={du^2+dv^2\over 1-u^2-v^2}$ on an open disc and I want to prove that radial curve $(r(t), 0)$ is a geodesic. I wrote the metric in polar form -- $ds^2={dr^2+r^2d\theta^2\over 1-r^2}$, so the coefficients of the first fundamental form are $E={1\over 1-r^2}, F=0, G={r^2\over 1-r^2}$. So the geodesic equations become ${d\over dt} (E\dot{r})={1\over 2}{\partial \over \partial r} (E\dot{r}^2)$ and (another equation which works). I can always reparametrise $r(t)$ so that it has unit speed. And I get $2r\over (1-r^2)^2$= $r\over (1-r^2)^2$, which is clearly wrong! Why is there an extra factor of 2? Thank you. ADDED: Perhaps it would be helpful for me to point out that generally, for a Riemannian metric of the form $Edu^2+2Fdudv+Gdv^2$ and geodesic $g(t)=(a(t),b(t))$, the Euler Lagrange equations are ${d\over dt} (E\dot{a}+F\dot{b})={1\over 2} (E_u\dot{a}^2+2F_u\dot{a}\dot{b}+G_u\dot{b}^2)$ and ${d\over dt} (F\dot{a}+G\dot{b})={1\over 2} (E_v\dot{a}^2+2F_v\dot{a}\dot{b}+G_v\dot{b}^2)$ where $\dot{a}={d\over dt}a,\,\,\,E_u={\partial\over\partial u}E$ and so on. EUREKA! Ooh, I think I know what the bug is, The geodesic has constant speed, but the inner product here is not simply the Euclidean one which is what I assumed when I set $\dot{r}=1$! I think it works fine now. :) -- I write it here because I can't post it as an answer...",,"['differential-geometry', 'calculus-of-variations']"
98,warping functions obey diff eq. does that imply $g_t$ obeys same diff eq?,warping functions obey diff eq. does that imply  obeys same diff eq?,g_t,"Consider $(M,g_{t})$ equipped with  a $1$ -parameter family of warped metrics for real parameter $t>0$ $$g_{t} = \frac{1}{\phi_t(u)^{2}}\ du^{2} + \phi_t(u)\ dv^{2}$$ and suppose that the warping function obeys the linear equation $$ t \frac{\partial^2}{\partial t^2}\phi_t(u)=-u \frac{\partial}{\partial u}\phi_t(u) $$ for warping function $$ \phi_t(u)=\exp\big(t/\log u \big) $$ Does this imply that $g_t$ satisfies the same linear PDE as well? I suspect $g_t$ obeys the same PDE but am not sure what to do with the $v$ variable in the metric and where the $v$ variable comes into the PDE. I believe $t$ should act as a time parameter and $u,v$ acting as space variables.",Consider equipped with  a -parameter family of warped metrics for real parameter and suppose that the warping function obeys the linear equation for warping function Does this imply that satisfies the same linear PDE as well? I suspect obeys the same PDE but am not sure what to do with the variable in the metric and where the variable comes into the PDE. I believe should act as a time parameter and acting as space variables.,"(M,g_{t}) 1 t>0 g_{t} = \frac{1}{\phi_t(u)^{2}}\ du^{2} + \phi_t(u)\ dv^{2}  t \frac{\partial^2}{\partial t^2}\phi_t(u)=-u \frac{\partial}{\partial u}\phi_t(u)   \phi_t(u)=\exp\big(t/\log u \big)  g_t g_t v v t u,v","['differential-geometry', 'partial-differential-equations', 'soft-question', 'riemannian-geometry', 'linear-pde']"
99,Which differential equations are invariant under change of camera projection?,Which differential equations are invariant under change of camera projection?,,"For background, I am working in the plane $\mathbb{R}^2$ . I know that the derivatives $\frac{\partial}{\partial x}$ and $\frac{\partial}{\partial y}$ are invariant under translation. I know that the Laplacian $\frac{\partial^2}{\partial x^2} + \frac{\partial ^2}{\partial y^2}$ is invariant under rotations. And now I want to consider homographies, which are invertible transformations $\tau:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ of the form $$\tau(x,y) = \left\langle \frac{ax + by +c}{gx + hy + i},\;\frac{dx + ey +f}{gx + hy + i}\right\rangle.$$ I have constructed one differential operator that I believe is invariant under all homographies: $$\mathscr{L}(F) =  F_{xx} F_y^2 - 2 F_{xy} F_x F_y + F_{yy} F_x^2$$ But I'm sufficiently unfamiliar with this area of mathematics that I don't know if there is a systematic way to find others, or all such operators. I also don't know if the answer to my question is a well-known result. I'm looking for insights such as: A characterization of these operators, their closure properties, a second example of a differential operator that's invariant under homography, suggestions for how to efficiently establish invariance, hints about how to generate such operators, and/or keywords for what to look at next. Most of what I've been able to find involves Lie groups on manifolds, which is outside my area of expertise and feels potentially heavy-handed and abstract for a situation in $\mathbb{R}^2$ . Edit: Incidentally, I found this theorem , which states: A differential operator $L=\sum_{\lvert \alpha\rvert\le m} a_\alpha(x)\partial^\alpha$ is invariant under all translations and rotations iff $L$ can be written as a polynomial $\mathsf{poly}(-\Delta)$ in the Laplacian $-\Delta$ . Because invariance under homography implies invariance under translation and rotation, I initially asssumed the theorem would apply here. After some initial confusion, I concluded that the operator in the theorem is assumed to be linear in a way that mine isn't, because mine depends on $F_y^2$ and so on. But I still hope the theorem represents a step in the right direction.","For background, I am working in the plane . I know that the derivatives and are invariant under translation. I know that the Laplacian is invariant under rotations. And now I want to consider homographies, which are invertible transformations of the form I have constructed one differential operator that I believe is invariant under all homographies: But I'm sufficiently unfamiliar with this area of mathematics that I don't know if there is a systematic way to find others, or all such operators. I also don't know if the answer to my question is a well-known result. I'm looking for insights such as: A characterization of these operators, their closure properties, a second example of a differential operator that's invariant under homography, suggestions for how to efficiently establish invariance, hints about how to generate such operators, and/or keywords for what to look at next. Most of what I've been able to find involves Lie groups on manifolds, which is outside my area of expertise and feels potentially heavy-handed and abstract for a situation in . Edit: Incidentally, I found this theorem , which states: A differential operator is invariant under all translations and rotations iff can be written as a polynomial in the Laplacian . Because invariance under homography implies invariance under translation and rotation, I initially asssumed the theorem would apply here. After some initial confusion, I concluded that the operator in the theorem is assumed to be linear in a way that mine isn't, because mine depends on and so on. But I still hope the theorem represents a step in the right direction.","\mathbb{R}^2 \frac{\partial}{\partial x} \frac{\partial}{\partial y} \frac{\partial^2}{\partial x^2} + \frac{\partial ^2}{\partial y^2} \tau:\mathbb{R}^2 \rightarrow \mathbb{R}^2 \tau(x,y) = \left\langle \frac{ax + by +c}{gx + hy + i},\;\frac{dx + ey +f}{gx + hy + i}\right\rangle. \mathscr{L}(F) =  F_{xx} F_y^2 - 2 F_{xy} F_x F_y + F_{yy} F_x^2 \mathbb{R}^2 L=\sum_{\lvert \alpha\rvert\le m} a_\alpha(x)\partial^\alpha L \mathsf{poly}(-\Delta) -\Delta F_y^2","['differential-geometry', 'group-actions', 'projective-geometry', 'differential-operators']"
