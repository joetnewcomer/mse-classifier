,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,cosine integral,cosine integral,,"Show that  $$\int_0^x \frac{1-\cos(t)}{t}=\gamma+\ln(x)-\operatorname{Ci}(x)$$ where $$\operatorname{Ci}(x)=-\int_x^\infty \frac{\cos(t)}{t} \, dt$$ and gamma is an euler-mascheroni constant. I did as follows: $$\int_0^x \frac{1-\cos(t)}{t} \, dt=\int_0^x \frac{1}{t} \,dt-\int_0^x \frac{\cos(t)}{t}\,dt$$ $$=\int_0^x \frac{1}{t}\,dt-\int_0^\infty \frac{\cos(t)}{t}\,dt+\int_x^\infty \frac{\cos(t)}{t} \, dt=\int_0^x \frac{1}{t}-\int_0^\infty \frac{\cos(t)}{t}-\operatorname{Ci}(x)$$ I am stuck with the last two integrals. How do I proceed?  A shorthand notation tells me that I get $\ln(x)-\ln(0)-\Gamma(0)$ which is wrong since $\ln(0)$ and $\Gamma(0)$ are undefined unless  $$\ln(0)+\Gamma(0)=-\gamma$$","Show that  $$\int_0^x \frac{1-\cos(t)}{t}=\gamma+\ln(x)-\operatorname{Ci}(x)$$ where $$\operatorname{Ci}(x)=-\int_x^\infty \frac{\cos(t)}{t} \, dt$$ and gamma is an euler-mascheroni constant. I did as follows: $$\int_0^x \frac{1-\cos(t)}{t} \, dt=\int_0^x \frac{1}{t} \,dt-\int_0^x \frac{\cos(t)}{t}\,dt$$ $$=\int_0^x \frac{1}{t}\,dt-\int_0^\infty \frac{\cos(t)}{t}\,dt+\int_x^\infty \frac{\cos(t)}{t} \, dt=\int_0^x \frac{1}{t}-\int_0^\infty \frac{\cos(t)}{t}-\operatorname{Ci}(x)$$ I am stuck with the last two integrals. How do I proceed?  A shorthand notation tells me that I get $\ln(x)-\ln(0)-\Gamma(0)$ which is wrong since $\ln(0)$ and $\Gamma(0)$ are undefined unless  $$\ln(0)+\Gamma(0)=-\gamma$$",,"['integration', 'definite-integrals', 'improper-integrals']"
1,Error accumulation in an approximating numerical algorithm for $y_n =\int_{0}^{1} \frac{x^n}{x+10} dx $,Error accumulation in an approximating numerical algorithm for,y_n =\int_{0}^{1} \frac{x^n}{x+10} dx ,"Consider the problem of calculating the integral $$y_n =\int_{0}^{1} \dfrac{x^n}{x+10} \mathrm{d}x $$ for a positive integer $n$. Observe that $$y_n + 10y_{n-1} = \int_{0}^{1} \dfrac{x^n +10x^{n-1}}{x+10} \mathrm{d}x  = \int_{0}^{1} x^{n-1}\mathrm{d}x = \dfrac{1}{n}$$ and that using this relationship in a forward recursion leads to a numerically unstable procedure. $(a)$ Derive a formula for approximately computing these integrals based on evaluating $y_{n-1}$ given $y_n$. $(b)$ Show that for any given value $\epsilon > 0$ and positive integer $n_0$, there exists an integer $n_1 \geq n_0$ such that taking $y_{n_1} = 0$ as a starting value will produce integral evaluations $y_n$ with an absolute error smaller than $\epsilon$ for all  $0 < n \leqslant n_0$. $(c)$ Explain why your algorithm is stable. Here is what I have so far, for part(a) $$y_{n-1} = \dfrac{1}{10} \left(\dfrac{1}{n} - y_n\right)$$ and for part $(c)$ The algorithm is stable because the magnitude of roundoff errors gets divided by 10 each time the recursion is applied. I really don't know how to start on the proof for part $(b)$, any hints and help would be appreciated.","Consider the problem of calculating the integral $$y_n =\int_{0}^{1} \dfrac{x^n}{x+10} \mathrm{d}x $$ for a positive integer $n$. Observe that $$y_n + 10y_{n-1} = \int_{0}^{1} \dfrac{x^n +10x^{n-1}}{x+10} \mathrm{d}x  = \int_{0}^{1} x^{n-1}\mathrm{d}x = \dfrac{1}{n}$$ and that using this relationship in a forward recursion leads to a numerically unstable procedure. $(a)$ Derive a formula for approximately computing these integrals based on evaluating $y_{n-1}$ given $y_n$. $(b)$ Show that for any given value $\epsilon > 0$ and positive integer $n_0$, there exists an integer $n_1 \geq n_0$ such that taking $y_{n_1} = 0$ as a starting value will produce integral evaluations $y_n$ with an absolute error smaller than $\epsilon$ for all  $0 < n \leqslant n_0$. $(c)$ Explain why your algorithm is stable. Here is what I have so far, for part(a) $$y_{n-1} = \dfrac{1}{10} \left(\dfrac{1}{n} - y_n\right)$$ and for part $(c)$ The algorithm is stable because the magnitude of roundoff errors gets divided by 10 each time the recursion is applied. I really don't know how to start on the proof for part $(b)$, any hints and help would be appreciated.",,"['integration', 'recursive-algorithms']"
2,Evaluating $\int\limits_{-\infty}^\infty {\exp(iax)\over1+ix}dx$,Evaluating,\int\limits_{-\infty}^\infty {\exp(iax)\over1+ix}dx,"How does one evaluate the integral $\int\limits_{-\infty}^\infty {\exp(iax)\over1+ix}dx$? I tried Wolfram Alpha, but it just says ""computation timed out""... I tried the indefinite integral and got an answer involving some weird function $E_1$. Is it possible to bypass the weird function? I presume the limits of my integral would eliminate that, but how?","How does one evaluate the integral $\int\limits_{-\infty}^\infty {\exp(iax)\over1+ix}dx$? I tried Wolfram Alpha, but it just says ""computation timed out""... I tried the indefinite integral and got an answer involving some weird function $E_1$. Is it possible to bypass the weird function? I presume the limits of my integral would eliminate that, but how?",,['integration']
3,Finite part of $-1/x^2$,Finite part of,-1/x^2,"I'm learning the basic of Distributional Theory. I ended up solving the following exercise: 'Find the distributional derivative of $P.V.1/x$ '. After few computation, I arrived at the following: $$\left\langle\left(P.V.\frac{1}{x}\right)', \phi\right\rangle = \lim_{\epsilon \rightarrow 0^{+}}\bigg(\frac{2\phi(0)}{\epsilon} + \int_{|x| \geq \epsilon} \phi(x) \bigg(-\frac{1}{x^2}\bigg)dx\bigg).$$ I've discovered that $P.V.\dfrac{1}{x}$ has a short form, without the limit: $$\left\langle P.V.\dfrac{1}{x}, \phi\right\rangle = \int_{-1}^{1} \frac{\phi(x) -\phi(0)}{x}dx + \int_{|x| > 1}\frac{\phi(x)}{x}dx.$$ Could I find a similar form for partie finie? Thanks for your help.","I'm learning the basic of Distributional Theory. I ended up solving the following exercise: 'Find the distributional derivative of '. After few computation, I arrived at the following: I've discovered that has a short form, without the limit: Could I find a similar form for partie finie? Thanks for your help.","P.V.1/x \left\langle\left(P.V.\frac{1}{x}\right)', \phi\right\rangle = \lim_{\epsilon \rightarrow 0^{+}}\bigg(\frac{2\phi(0)}{\epsilon} + \int_{|x| \geq \epsilon} \phi(x) \bigg(-\frac{1}{x^2}\bigg)dx\bigg). P.V.\dfrac{1}{x} \left\langle P.V.\dfrac{1}{x}, \phi\right\rangle = \int_{-1}^{1} \frac{\phi(x) -\phi(0)}{x}dx + \int_{|x| > 1}\frac{\phi(x)}{x}dx.","['integration', 'limits', 'derivatives', 'distribution-theory', 'cauchy-principal-value']"
4,What do these double integrals represent?,What do these double integrals represent?,,"Question I have three double integrals: (A) $$\int_{0}^{1}\int_{x^2}^1 dydx$$ (B) $$\int_{0}^{1}\int_{x}^{2x} x^2 dydx$$ (C) $$\int_{0}^{1}\int_{-y}^{y} dxdy$$ These need to be matched to the appropriate statements: (a) The area of the triangle in the $xy$ -plane corresponds to (b) The area of a region in the $xy$ -plane bounded on a side by a parabola corresponds to (c) The volume under the surface $z=x^2$ above a triangle in the $xy$ plane corresponds to (d) The volume under the plane $z=1$ above a triangle in the $xy$ plane corresponds to My Attempt So far I have that (a) C (b) A (c) B (d) C However I am confused if there can be multiple answers. For example, is it possible that (a) is B and C, since both regions of integration are triangles in the $xy$ plane? These are my sketches of the regions of integration:","Question I have three double integrals: (A) (B) (C) These need to be matched to the appropriate statements: (a) The area of the triangle in the -plane corresponds to (b) The area of a region in the -plane bounded on a side by a parabola corresponds to (c) The volume under the surface above a triangle in the plane corresponds to (d) The volume under the plane above a triangle in the plane corresponds to My Attempt So far I have that (a) C (b) A (c) B (d) C However I am confused if there can be multiple answers. For example, is it possible that (a) is B and C, since both regions of integration are triangles in the plane? These are my sketches of the regions of integration:",\int_{0}^{1}\int_{x^2}^1 dydx \int_{0}^{1}\int_{x}^{2x} x^2 dydx \int_{0}^{1}\int_{-y}^{y} dxdy xy xy z=x^2 xy z=1 xy xy,"['integration', 'multivariable-calculus', 'definite-integrals', 'area', 'volume']"
5,Approximating a line integral over a rectifiable path by a line integral over a polygonal path in an infinite dimensional space,Approximating a line integral over a rectifiable path by a line integral over a polygonal path in an infinite dimensional space,,"Let $E$ be a complex Banach algebra and $U\subseteq E$ an open subset. Suppose we are given a continuous map $f:U\to E$ and a rectifiable path $\gamma:[a,b]\to U$ . For each tagged partition $\{a=t_0<t_1<\dots<t_n=b\}$ with tags $\tau_k\in [t_{k-1},t_k]$ , we consider the Riemann sum $$ \sum_{k=1}^n f(\gamma(\tau_k))\mkern2mu[\gamma(t_k)-\gamma(t_{k-1})]. $$ Analagously to the case $E=\mathbb{C}$ , we may define the line integral of $f$ along $\gamma$ by the limit of the net of Riemann sums as the mesh of the partitions tends to $0$ . (This limit exists, since $f$ is continuous and $\gamma$ is rectifiable.) I want to prove the following lemma from Conway's book on Complex Analysis (cf. page 65) in this more general setting. 1.19 Lemma. For every $\epsilon>0$ there exists a polygonal path $\Gamma$ in $U$ such that $\Gamma(a)=\gamma(a)$ , $\Gamma(b)=\gamma(b)$ and $$\Bigl\lvert\int_{\gamma} f-\int_{\Gamma}f\mkern2mu\Bigr\rvert<\epsilon.$$ By this old paper on Cauchy's theorem in Banach spaces, the above lemma is easily seen to be true (cf. page 77). On the other hand, an essential part of Conway's proof uses the fact that $\mathbb{C}$ is locally compact and hence $f$ uniformly continuous in a neighbourhood of $\gamma([a,b])$ , which is not the case anymore if $E$ is infinite dimensional. Do I miss something?","Let be a complex Banach algebra and an open subset. Suppose we are given a continuous map and a rectifiable path . For each tagged partition with tags , we consider the Riemann sum Analagously to the case , we may define the line integral of along by the limit of the net of Riemann sums as the mesh of the partitions tends to . (This limit exists, since is continuous and is rectifiable.) I want to prove the following lemma from Conway's book on Complex Analysis (cf. page 65) in this more general setting. 1.19 Lemma. For every there exists a polygonal path in such that , and By this old paper on Cauchy's theorem in Banach spaces, the above lemma is easily seen to be true (cf. page 77). On the other hand, an essential part of Conway's proof uses the fact that is locally compact and hence uniformly continuous in a neighbourhood of , which is not the case anymore if is infinite dimensional. Do I miss something?","E U\subseteq E f:U\to E \gamma:[a,b]\to U \{a=t_0<t_1<\dots<t_n=b\} \tau_k\in [t_{k-1},t_k] 
\sum_{k=1}^n f(\gamma(\tau_k))\mkern2mu[\gamma(t_k)-\gamma(t_{k-1})].
 E=\mathbb{C} f \gamma 0 f \gamma \epsilon>0 \Gamma U \Gamma(a)=\gamma(a) \Gamma(b)=\gamma(b) \Bigl\lvert\int_{\gamma} f-\int_{\Gamma}f\mkern2mu\Bigr\rvert<\epsilon. \mathbb{C} f \gamma([a,b]) E","['integration', 'complex-analysis', 'functional-analysis', 'banach-spaces']"
6,"How do I solve this integral $\displaystyle\int_{0}^{+\infty} \frac{x^{2} \sin x}{x^{4}+a^{4}} \,dx$?",How do I solve this integral ?,"\displaystyle\int_{0}^{+\infty} \frac{x^{2} \sin x}{x^{4}+a^{4}} \,dx","To solve it, you need to factor the lower part and get squares instead of power $4$ . The problem is that the solution will be with imaginary numbers, since the denominator cannot be decomposed into factors other than through the roots of negative numbers. This results in the following: \begin{align} \int\frac{x^2 \sin(x)}{x^4 + a^4}\,dx = {} & \frac1{4a} (-1)^{1/4} (-i \sin(a(-1)^{1/4}) \operatorname{Ci}(x - a (-1)^{1/4}) \\[4pt] & {} - \sin(a (-1)^{3/4}) \operatorname{Ci}(x - a (-1)^{3/4}) \\[4pt] & {} - \sin(a (-1)^{3/4}) \operatorname{Ci}(x + a (-1)^{3/4}) \\[4pt] & {} - i \sin(a (-1)^{1/4}) \operatorname{Ci}(x + a (-1)^{1/4}) \\[4pt] & {} + i \cos(a (-1)^{1/4}) \operatorname{Si}(a (-1)^{1/4} - x) \\[4pt] & {} + \cos(a (-1)^{3/4}) \operatorname{Si}(a (-1)^{3/4} - x) \\[4pt] & {} + i \cos(a (-1)^{1/4}) \operatorname{Si}(x + a (-1)^{1/4}) \\[4pt] & {} + \cos(a (-1)^{3/4}) \operatorname{Si}(x + a (-1)^{3/4})) + \text{constant} \end{align} $\mathrm{Ci}$ is the cosine integral, $\mathrm{Si}$ is the sine integral, $\mathrm{G}$ is the Meyer G-function.","To solve it, you need to factor the lower part and get squares instead of power . The problem is that the solution will be with imaginary numbers, since the denominator cannot be decomposed into factors other than through the roots of negative numbers. This results in the following: is the cosine integral, is the sine integral, is the Meyer G-function.","4 \begin{align}
\int\frac{x^2 \sin(x)}{x^4 + a^4}\,dx = {} & \frac1{4a} (-1)^{1/4} (-i \sin(a(-1)^{1/4}) \operatorname{Ci}(x - a (-1)^{1/4}) \\[4pt]
& {} - \sin(a (-1)^{3/4}) \operatorname{Ci}(x - a (-1)^{3/4}) \\[4pt]
& {} - \sin(a (-1)^{3/4}) \operatorname{Ci}(x + a (-1)^{3/4}) \\[4pt]
& {} - i \sin(a (-1)^{1/4}) \operatorname{Ci}(x + a (-1)^{1/4}) \\[4pt]
& {} + i \cos(a (-1)^{1/4}) \operatorname{Si}(a (-1)^{1/4} - x) \\[4pt]
& {} + \cos(a (-1)^{3/4}) \operatorname{Si}(a (-1)^{3/4} - x) \\[4pt]
& {} + i \cos(a (-1)^{1/4}) \operatorname{Si}(x + a (-1)^{1/4}) \\[4pt]
& {} + \cos(a (-1)^{3/4}) \operatorname{Si}(x + a (-1)^{3/4})) + \text{constant}
\end{align} \mathrm{Ci} \mathrm{Si} \mathrm{G}","['integration', 'complex-analysis', 'improper-integrals', 'complex-integration']"
7,Show that $H(x):=\frac{1}{|x|^{n-2}}u(\frac{x}{|x|^2})$ is harmonic if $u$ is harmonic [duplicate],Show that  is harmonic if  is harmonic [duplicate],H(x):=\frac{1}{|x|^{n-2}}u(\frac{x}{|x|^2}) u,"This question already has answers here : Show that the Kelvin-transform is harmonic (1 answer) $u$ is harmonic, prove that $v(x)=\frac{1}{|x|^{n-2}}\cdot u\left(\frac{x}{|x|^2}\right)$ is harmonic. [closed] (1 answer) Closed last year . (This is the $n$ -dimensional analogue of the 3D case: Show that $H(x) := |x|^{-1} u(x/|x|^2) $ is harmonic if $u$ is harmonic ) Suppose that $u$ is a harmonic function on $\mathbb{R}^n$ . Prove that the function $\displaystyle H(x):=\frac{1}{|x|^{n-2}}u\left(\frac{x}{|x|^2}\right)$ is harmonic on $\mathbb{R}^n\backslash\{0\}$ . I tried to compute $\Delta H$ directly by following the brute force method in the linked question, but it gets tedious very soon. Therefore, I am wondering if there is a more elegant way? I am thinking to use the converse of mean value property. So far I have worked out (probably) that Under the mapping $f: x\mapsto \frac{x}{|x|^2}$ , a circle with radius $r$ centered at $x_0$ would be mapped to a circle with radius $R=\frac{2r}{|x_0|^2-r^2}$ centered at $y_0=\frac{x_0}{|x_0|^2-r^2}$ . $f = f^{-1}$ Its Jacobian is $|Jf|=|x|^{2n}$ . I am stuck after doing change of variables in the integral $\displaystyle\frac{1}{|B_R(y_0)|}\int_{B_R(y_0)} H(y)dy$ , since the terms do not magically cancel out as wished, and expressing $|B_R(y_0)|$ in terms of the corresponding $|B_r(x_0)|$ also yields a mess. I really appreciate any help. Other methods (or more efficient brute force) are also greatly welcomed.","This question already has answers here : Show that the Kelvin-transform is harmonic (1 answer) $u$ is harmonic, prove that $v(x)=\frac{1}{|x|^{n-2}}\cdot u\left(\frac{x}{|x|^2}\right)$ is harmonic. [closed] (1 answer) Closed last year . (This is the -dimensional analogue of the 3D case: Show that $H(x) := |x|^{-1} u(x/|x|^2) $ is harmonic if $u$ is harmonic ) Suppose that is a harmonic function on . Prove that the function is harmonic on . I tried to compute directly by following the brute force method in the linked question, but it gets tedious very soon. Therefore, I am wondering if there is a more elegant way? I am thinking to use the converse of mean value property. So far I have worked out (probably) that Under the mapping , a circle with radius centered at would be mapped to a circle with radius centered at . Its Jacobian is . I am stuck after doing change of variables in the integral , since the terms do not magically cancel out as wished, and expressing in terms of the corresponding also yields a mess. I really appreciate any help. Other methods (or more efficient brute force) are also greatly welcomed.",n u \mathbb{R}^n \displaystyle H(x):=\frac{1}{|x|^{n-2}}u\left(\frac{x}{|x|^2}\right) \mathbb{R}^n\backslash\{0\} \Delta H f: x\mapsto \frac{x}{|x|^2} r x_0 R=\frac{2r}{|x_0|^2-r^2} y_0=\frac{x_0}{|x_0|^2-r^2} f = f^{-1} |Jf|=|x|^{2n} \displaystyle\frac{1}{|B_R(y_0)|}\int_{B_R(y_0)} H(y)dy |B_R(y_0)| |B_r(x_0)|,"['integration', 'multivariable-calculus', 'partial-differential-equations', 'harmonic-functions', 'laplacian']"
8,Evaluating $ \int_{-\infty}^{t} e^{-(\tau+a)^2} \mathrm{erf}(\tau) \mathrm{d}\tau$,Evaluating, \int_{-\infty}^{t} e^{-(\tau+a)^2} \mathrm{erf}(\tau) \mathrm{d}\tau,"I need to evaluate this integral: $$ I(t,a) = \int_{-\infty}^{t} e^{-(\tau+a)^2} \mathrm{erf}(\tau) \ \mathrm{d}\tau $$ where the $\mathrm{erf}(\tau)$ is the error function. I can prove that this integral converges. By employing the python library import numpy as np from scipy.special import erf import matplotlib.pyplot as plt dtau = 0.01;p=[] trange = np.arange(-20,20,0.1) for t in trange:     tau = np.arange(-20,t,dtau)     I = np.exp(-(tau+a)**2)* erf(tau)     p.append(np.trapz(I,tau)) p=np.array(p) plt.plot(trange,p);plt.show(); I got three graphs for different $a$ therefor one can speculate the behavior of the integral for $|a|\ll1$ is as a Bi-gaussian function and for $|a|\gg1$ is as an $\mathrm{erf}(t)$ function. therefore the answer is something like this $$ I(t,a) \sim \alpha(a) \ \mathrm{erf}(t+a) + \beta(a) \ e^{-(t\pm a)^2} $$ I would highly appreciate it if someone could help me to solve it. Edit: if $t \rightarrow \infty$ , the $I(\infty, a)$ is given by $$ I(t \rightarrow \infty,a) = \sqrt{\pi} \ \mathrm{erf} \Big(\dfrac{a}{\sqrt{2}} \Big) $$ this might be helpful.","I need to evaluate this integral: where the is the error function. I can prove that this integral converges. By employing the python library import numpy as np from scipy.special import erf import matplotlib.pyplot as plt dtau = 0.01;p=[] trange = np.arange(-20,20,0.1) for t in trange:     tau = np.arange(-20,t,dtau)     I = np.exp(-(tau+a)**2)* erf(tau)     p.append(np.trapz(I,tau)) p=np.array(p) plt.plot(trange,p);plt.show(); I got three graphs for different therefor one can speculate the behavior of the integral for is as a Bi-gaussian function and for is as an function. therefore the answer is something like this I would highly appreciate it if someone could help me to solve it. Edit: if , the is given by this might be helpful.","
I(t,a) = \int_{-\infty}^{t} e^{-(\tau+a)^2} \mathrm{erf}(\tau) \ \mathrm{d}\tau
 \mathrm{erf}(\tau) a |a|\ll1 |a|\gg1 \mathrm{erf}(t) 
I(t,a) \sim \alpha(a) \ \mathrm{erf}(t+a) + \beta(a) \ e^{-(t\pm a)^2}
 t \rightarrow \infty I(\infty, a) 
I(t \rightarrow \infty,a) = \sqrt{\pi} \ \mathrm{erf} \Big(\dfrac{a}{\sqrt{2}} \Big)
","['integration', 'gaussian-integral', 'error-function', 'gaussian']"
9,Measure of complexity of a function,Measure of complexity of a function,,"Generally, when we try to write a function to fit to a group of points (curve fitting), it is important to find a balance between the accuracy and complexity of the function. The following picture shows different examples of this. If the function is excessively simple at the cost of accuracy, it will underfit (such as with the line). On the other hand, if the function is excessively complex, it will overfit (such as with the curve on the right). I am looking for a formal and widely accepted definition for the complexity of the function. One definition I was thinking about was how much the slope varies. Letting the average slope of the function in an interval be $\bar{m}$ , then I can write the complexity as $$\int_a^b (f'(x)-\bar{m})^2 dx$$ where $f(x)$ is the function, $a$ is the lower endpoint, and $b$ is the upper endpoint. Expanding the square, I get $$\int_a^b (f'(x)^2 - 2\bar{m}f'(x) + \bar{m}^2)dx = \int_a^bf'(x)^2dx - 2\bar{m}\int_a^bf'(x)dx + \bar{m}^2\int_a^bdx$$ Using the Fundamental Theorem of Calculus on the second integral, I get $$\int_a^bf'(x)^2dx - 2\bar{m}(f(b)-f(a)) + \bar{m}^2(b-a)$$ Because $\bar{m}$ is $$\frac{f(b)-f(a)}{b-a}$$ I can simplify the above equation to get $$\int_a^bf'(x)^2dx - \frac{\left(f(b)-f(a)\right)^2}{b-a}$$ The higher this value is, the more ""complex"" and varying the function is. If this value is $0$ , then $f(x)$ is a line from $a$ to $b$ . Are there other measures of the complexity of a function? If so, what are the corresponding equations for them? Edit: I am not looking for a complexity function dependent on the points. For example, $f(x) = x$ should have the same complexity no matter what points are on the graph. Edit 2: A problem with the above definition of complexity is that $c^x$ would have a very high complexity (when I believe it should have a lower value). Specifically, from $a$ to $b$ , the complexity is $$ \ln(c) \frac{c^{2b}-c^{2a}}{2} - \frac{(c^b-c^a)^2}{b-a}$$ which increases exponentially with respect to $b$ .","Generally, when we try to write a function to fit to a group of points (curve fitting), it is important to find a balance between the accuracy and complexity of the function. The following picture shows different examples of this. If the function is excessively simple at the cost of accuracy, it will underfit (such as with the line). On the other hand, if the function is excessively complex, it will overfit (such as with the curve on the right). I am looking for a formal and widely accepted definition for the complexity of the function. One definition I was thinking about was how much the slope varies. Letting the average slope of the function in an interval be , then I can write the complexity as where is the function, is the lower endpoint, and is the upper endpoint. Expanding the square, I get Using the Fundamental Theorem of Calculus on the second integral, I get Because is I can simplify the above equation to get The higher this value is, the more ""complex"" and varying the function is. If this value is , then is a line from to . Are there other measures of the complexity of a function? If so, what are the corresponding equations for them? Edit: I am not looking for a complexity function dependent on the points. For example, should have the same complexity no matter what points are on the graph. Edit 2: A problem with the above definition of complexity is that would have a very high complexity (when I believe it should have a lower value). Specifically, from to , the complexity is which increases exponentially with respect to .",\bar{m} \int_a^b (f'(x)-\bar{m})^2 dx f(x) a b \int_a^b (f'(x)^2 - 2\bar{m}f'(x) + \bar{m}^2)dx = \int_a^bf'(x)^2dx - 2\bar{m}\int_a^bf'(x)dx + \bar{m}^2\int_a^bdx \int_a^bf'(x)^2dx - 2\bar{m}(f(b)-f(a)) + \bar{m}^2(b-a) \bar{m} \frac{f(b)-f(a)}{b-a} \int_a^bf'(x)^2dx - \frac{\left(f(b)-f(a)\right)^2}{b-a} 0 f(x) a b f(x) = x c^x a b  \ln(c) \frac{c^{2b}-c^{2a}}{2} - \frac{(c^b-c^a)^2}{b-a} b,"['integration', 'approximation-theory']"
10,"Definite integral over a semicircular area $\int_0^{2a}\int_0^{\sqrt{2ax-x^2}}\frac{\phi'(y)(x^2+y^2)x}{\sqrt{4a^2x^2-(x^2+y^2)^2}}dy\,dx$. [duplicate]",Definite integral over a semicircular area . [duplicate],"\int_0^{2a}\int_0^{\sqrt{2ax-x^2}}\frac{\phi'(y)(x^2+y^2)x}{\sqrt{4a^2x^2-(x^2+y^2)^2}}dy\,dx","This question already has an answer here : Evaluate the integral $\int_0^{2a}\int_0^\sqrt{2ax-x^2}\frac{\phi'(y)(x^2+y^2)x dxdy}{\sqrt{4a^2x^2-(x^2+y^2)^2}}$ (1 answer) Closed 3 years ago . change the order of integration in $$\int_0^{2a}\int_0^{\sqrt{2ax-x^2}}\frac{\phi'(y)(x^2+y^2)x}{\sqrt{4a^2x^2-(x^2+y^2)^2}}dy\,dx$$ I was able to change the order of integration here to  $$\int_0^a\int_{a-\sqrt{a^2-y^2}}^{a+\sqrt{a^2-y^2}}\frac{\phi'(y)(x^2+y^2)x}{\sqrt{4a^2x^2-(x^2+y^2)^2}}dx\,dy$$ Now i am stuck with the integration here w.r.t $x$. I tried substituting $(x^2+y^2)^2$ with $t$ but then replacing value of $4a^2x^2$ becomes a problem. I was thinking of substituting both $x$ and $y$ as $k\cos\theta$ and $k\sin\theta$ but then $y$ won't be constant w.r.t $x$, so that too I believe is out of the question!","This question already has an answer here : Evaluate the integral $\int_0^{2a}\int_0^\sqrt{2ax-x^2}\frac{\phi'(y)(x^2+y^2)x dxdy}{\sqrt{4a^2x^2-(x^2+y^2)^2}}$ (1 answer) Closed 3 years ago . change the order of integration in $$\int_0^{2a}\int_0^{\sqrt{2ax-x^2}}\frac{\phi'(y)(x^2+y^2)x}{\sqrt{4a^2x^2-(x^2+y^2)^2}}dy\,dx$$ I was able to change the order of integration here to  $$\int_0^a\int_{a-\sqrt{a^2-y^2}}^{a+\sqrt{a^2-y^2}}\frac{\phi'(y)(x^2+y^2)x}{\sqrt{4a^2x^2-(x^2+y^2)^2}}dx\,dy$$ Now i am stuck with the integration here w.r.t $x$. I tried substituting $(x^2+y^2)^2$ with $t$ but then replacing value of $4a^2x^2$ becomes a problem. I was thinking of substituting both $x$ and $y$ as $k\cos\theta$ and $k\sin\theta$ but then $y$ won't be constant w.r.t $x$, so that too I believe is out of the question!",,"['integration', 'definite-integrals', 'area']"
11,Gaussian integral variant $\int_{-\infty}^\infty \frac{e^{-x^2}}{1+a e^{-x}} dx$,Gaussian integral variant,\int_{-\infty}^\infty \frac{e^{-x^2}}{1+a e^{-x}} dx,"I have been trying to compute this integral $$\int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+a e^{-x}} dx$$ quickly and to a high-degree of accuracy. I have some partial results, for example for $n \in \mathbb N$ $$ \frac{1}{\sqrt\pi} \int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+e^{-(x+n/2)}}dx = \frac{1}{2}\sum_{i=0}^{2n}(-1)^{i} e^{-i(2n-i)/4},$$ and for $a \in (0,1)$ we have $$ \frac{1}{\sqrt\pi} \int_{0}^\infty \frac{e^{-x^2}}{1+ae^{-x}}dx = \frac{1}{2}\sum_{n=0}^\infty (-1)^n a^n e^{n^2/4} \mathrm{erfc}(n/2)$$ where $\mathrm{erfc}$ is the error function complement fuction $$ \mathrm{erfc}(x) = 1-\mathrm{erf}(x),$$ which we obtain by using the substitution $$ \frac{1}{1+ae^{-x}} = \sum_{n=0}^\infty (-1)^n a^n e^{-nx}.$$ This $\mathrm{erfc}$ series does not converge very quickly unless $a$ is very small, and wolframalpha can compute the integral very accurately between say $-100$ and $100$ for various values of $a$, so I must be missing a trick. Edit I found an infinite series for the whole integral, but it converges slowly $$\frac{1}{\sqrt\pi}\int_{-\infty}^\infty \frac{e^{-x^2}}{1+e^{-(x+a)}}dx = \frac{e^{-a^2}}{2}\left[\sum_{n=0}^\infty (-1)^n \mathrm{erfcx}(-a+n/2) + \sum_{n=1}^\infty (-1)^{n+1} \mathrm{erfcx}(a+n/2)\right],$$ where $\mathrm{erfcx}$ is the scaled complement error function $$ \mathrm{erfcx}(x) = e^{x^2} \mathrm{erfcx}(x) = e^{x^2}(1-\mathrm{erf}(x)).$$","I have been trying to compute this integral $$\int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+a e^{-x}} dx$$ quickly and to a high-degree of accuracy. I have some partial results, for example for $n \in \mathbb N$ $$ \frac{1}{\sqrt\pi} \int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+e^{-(x+n/2)}}dx = \frac{1}{2}\sum_{i=0}^{2n}(-1)^{i} e^{-i(2n-i)/4},$$ and for $a \in (0,1)$ we have $$ \frac{1}{\sqrt\pi} \int_{0}^\infty \frac{e^{-x^2}}{1+ae^{-x}}dx = \frac{1}{2}\sum_{n=0}^\infty (-1)^n a^n e^{n^2/4} \mathrm{erfc}(n/2)$$ where $\mathrm{erfc}$ is the error function complement fuction $$ \mathrm{erfc}(x) = 1-\mathrm{erf}(x),$$ which we obtain by using the substitution $$ \frac{1}{1+ae^{-x}} = \sum_{n=0}^\infty (-1)^n a^n e^{-nx}.$$ This $\mathrm{erfc}$ series does not converge very quickly unless $a$ is very small, and wolframalpha can compute the integral very accurately between say $-100$ and $100$ for various values of $a$, so I must be missing a trick. Edit I found an infinite series for the whole integral, but it converges slowly $$\frac{1}{\sqrt\pi}\int_{-\infty}^\infty \frac{e^{-x^2}}{1+e^{-(x+a)}}dx = \frac{e^{-a^2}}{2}\left[\sum_{n=0}^\infty (-1)^n \mathrm{erfcx}(-a+n/2) + \sum_{n=1}^\infty (-1)^{n+1} \mathrm{erfcx}(a+n/2)\right],$$ where $\mathrm{erfcx}$ is the scaled complement error function $$ \mathrm{erfcx}(x) = e^{x^2} \mathrm{erfcx}(x) = e^{x^2}(1-\mathrm{erf}(x)).$$",,"['integration', 'exponential-function']"
12,"Show that $\sup\left\{\frac{1}{\varepsilon}\int_{\{|f|<\varepsilon\}}|f'(x)|dx:\varepsilon\in(0,1]\right\}$ is finite",Show that  is finite,"\sup\left\{\frac{1}{\varepsilon}\int_{\{|f|<\varepsilon\}}|f'(x)|dx:\varepsilon\in(0,1]\right\}","Let $[a,b]$ be a closed and bounded interval and let $f:[a,b]\to\mathbb{R}$ be a continuously differentiable function $f\in C^1([a,b])$. I am trying to bound from above the following expression $$\frac{1}{\varepsilon}\int_{\{|f|<\varepsilon\}}|f'(x)|dx$$ uniformly as $\varepsilon\downarrow 0$. I would like to prove $$\sup\left\{\frac{1}{\varepsilon}\int_{\{|f|<\varepsilon\}}|f'(x)|dx:\varepsilon\in(0,1]\right\}$$ is finite but I have no idea of how to do it. Any suggestions? Olivier made me realise I should probably explain how this came up, so I will explain the original question. Consider the step function approximation of Dirac's delta $\delta^\varepsilon(t)=\frac{1}{2\varepsilon}\textbf{1}_{\{|t|<\varepsilon\}}$. I would like to justify for $f\in C^1(\mathbb{R})$ the equation $$\lim_{\varepsilon\downarrow 0}\int_0^T\delta^\varepsilon(f(t))|f'(t)|dt=\int_0^T\lim_{\varepsilon\downarrow0}\delta^\varepsilon(f(t))|f'(t)|dt$$ Any hints on this would be equally helpful.","Let $[a,b]$ be a closed and bounded interval and let $f:[a,b]\to\mathbb{R}$ be a continuously differentiable function $f\in C^1([a,b])$. I am trying to bound from above the following expression $$\frac{1}{\varepsilon}\int_{\{|f|<\varepsilon\}}|f'(x)|dx$$ uniformly as $\varepsilon\downarrow 0$. I would like to prove $$\sup\left\{\frac{1}{\varepsilon}\int_{\{|f|<\varepsilon\}}|f'(x)|dx:\varepsilon\in(0,1]\right\}$$ is finite but I have no idea of how to do it. Any suggestions? Olivier made me realise I should probably explain how this came up, so I will explain the original question. Consider the step function approximation of Dirac's delta $\delta^\varepsilon(t)=\frac{1}{2\varepsilon}\textbf{1}_{\{|t|<\varepsilon\}}$. I would like to justify for $f\in C^1(\mathbb{R})$ the equation $$\lim_{\varepsilon\downarrow 0}\int_0^T\delta^\varepsilon(f(t))|f'(t)|dt=\int_0^T\lim_{\varepsilon\downarrow0}\delta^\varepsilon(f(t))|f'(t)|dt$$ Any hints on this would be equally helpful.",,"['integration', 'measure-theory', 'lebesgue-integral']"
13,Evaluating the integral $\int_{-\ln 2}^{\ln 2} e^{-x}(\sin x+x)^{1/3}dx$,Evaluating the integral,\int_{-\ln 2}^{\ln 2} e^{-x}(\sin x+x)^{1/3}dx,"As the title states, I'm having quite a lot of trouble with the integral: $$\int_{-\ln 2}^{\ln 2}  \frac{(\sin x+x)^{1/3}}{e^x}dx$$ The problem is that my standard (admittedly sparse) repertoire of tricks seems to have no effect at all. I can't think of any clever substitution that would work, and it looks like a nasty integral all-round. I was hoping to apply some symmetry arguments (especially considering the limits of integration), but the exponential function is neither even nor odd, so I don't see how this would work. I'm afraid I have absolutely no idea how to approach this.","As the title states, I'm having quite a lot of trouble with the integral: $$\int_{-\ln 2}^{\ln 2}  \frac{(\sin x+x)^{1/3}}{e^x}dx$$ The problem is that my standard (admittedly sparse) repertoire of tricks seems to have no effect at all. I can't think of any clever substitution that would work, and it looks like a nasty integral all-round. I was hoping to apply some symmetry arguments (especially considering the limits of integration), but the exponential function is neither even nor odd, so I don't see how this would work. I'm afraid I have absolutely no idea how to approach this.",,"['integration', 'definite-integrals']"
14,Showing limit of improper integral using Riemann sum,Showing limit of improper integral using Riemann sum,,"I can show that if $f$ is continuous for $x\ge0$ with $\lim\limits_{x \to \infty} f(x) = A$, then   \begin{equation}     \lim_{x \to \infty} \frac{1}{x} \int_0^x \! f(t) \, \mathrm{d}t = A   \end{equation} using the definition of limits, etc. (a homework question). However, just for my understanding I'm trying to wrap my head around showing the same thing using a Riemann sum. If I divide the interval of the integral in $n$ parts, each part will be $\frac{x}{n}$ wide. In each such subinterval, I pick the right endpoint: $c_i = \frac{x}{n} \cdot i$ for $i = 1,2,3,\dots,n$. \begin{align}   \lim_{x \to \infty} \frac{1}{x} \int_0^x \! f(t) \, \mathrm{d}t & = A \\   \lim_{x \to \infty} \frac{1}{x} \sum_{i=1}^n f(c_i) \frac{x}{n} &= A \\   \lim_{x \to \infty} \frac{1}{x} \sum_{i=1}^n \frac{f(c_i)}{n} x &= A \end{align} The $x$ does not depend on $i$ so I can move that out of the summation. \begin{align}   \lim_{x \to \infty} \frac{1}{x} x \sum_{i=1}^n \frac{f(c_i)}{n} &= A \\   \lim_{x \to \infty} 1 \sum_{i=1}^n \frac{f(c_i)}{n} &= A \end{align} I can see that each $i$ provides an $n$:th contribution to the sum and there's $n$ parts altogether. I can make calculations and see that the sum does converge using various functions for $f$ but I can't quite see why the sum of $f(c_i) = f(\frac{x}{n} \cdot i)$ behaves the way it does when $x\to\infty$ and $n\to\infty$. I hope that was clear enough (first question here! :)","I can show that if $f$ is continuous for $x\ge0$ with $\lim\limits_{x \to \infty} f(x) = A$, then   \begin{equation}     \lim_{x \to \infty} \frac{1}{x} \int_0^x \! f(t) \, \mathrm{d}t = A   \end{equation} using the definition of limits, etc. (a homework question). However, just for my understanding I'm trying to wrap my head around showing the same thing using a Riemann sum. If I divide the interval of the integral in $n$ parts, each part will be $\frac{x}{n}$ wide. In each such subinterval, I pick the right endpoint: $c_i = \frac{x}{n} \cdot i$ for $i = 1,2,3,\dots,n$. \begin{align}   \lim_{x \to \infty} \frac{1}{x} \int_0^x \! f(t) \, \mathrm{d}t & = A \\   \lim_{x \to \infty} \frac{1}{x} \sum_{i=1}^n f(c_i) \frac{x}{n} &= A \\   \lim_{x \to \infty} \frac{1}{x} \sum_{i=1}^n \frac{f(c_i)}{n} x &= A \end{align} The $x$ does not depend on $i$ so I can move that out of the summation. \begin{align}   \lim_{x \to \infty} \frac{1}{x} x \sum_{i=1}^n \frac{f(c_i)}{n} &= A \\   \lim_{x \to \infty} 1 \sum_{i=1}^n \frac{f(c_i)}{n} &= A \end{align} I can see that each $i$ provides an $n$:th contribution to the sum and there's $n$ parts altogether. I can make calculations and see that the sum does converge using various functions for $f$ but I can't quite see why the sum of $f(c_i) = f(\frac{x}{n} \cdot i)$ behaves the way it does when $x\to\infty$ and $n\to\infty$. I hope that was clear enough (first question here! :)",,"['integration', 'limits', 'riemann-sum']"
15,Any advice on simplifying this nasty integral,Any advice on simplifying this nasty integral,,"Can anyone think of any smart way of approximating this nasty integral $$F = \int_{-c}^c f_X(x) \, dx $$ where $c$ is a non-negative constant (for example $\frac{1}{64}$) and where the integrand is given by $$f_X(x)= \int_{\max\{-1,-1-x\}}^{\min\{1,1-x\}} \left( \frac{1}{\pi^2\sqrt{1-(x+y)^2}} \frac{1}{\sqrt{1-y^2}}\right) \, dy$$ I would really like to avoid numerical integration. Can anyone think of any simplifications that can reduce the complexity of my problem. Please read comments below on why I have such a problem in the first place... Thanks","Can anyone think of any smart way of approximating this nasty integral $$F = \int_{-c}^c f_X(x) \, dx $$ where $c$ is a non-negative constant (for example $\frac{1}{64}$) and where the integrand is given by $$f_X(x)= \int_{\max\{-1,-1-x\}}^{\min\{1,1-x\}} \left( \frac{1}{\pi^2\sqrt{1-(x+y)^2}} \frac{1}{\sqrt{1-y^2}}\right) \, dy$$ I would really like to avoid numerical integration. Can anyone think of any simplifications that can reduce the complexity of my problem. Please read comments below on why I have such a problem in the first place... Thanks",,['integration']
16,Bochner Integral: Axioms,Bochner Integral: Axioms,,"Disclaimer It is meant to record. See: Answer own Question It is written as question. Have fun! :) Reference It is taken from the original paper: S. Bochner, Integration It is related to: Bochner Integral: Integrability Definition Given a measure space $\Omega$ and a Banach space $E$. Consider Bochner measurable functions $S_n\to F$. Suppose Bochner integrability as $\int\|F\|\mathrm{d}\mu<\infty$. Denote the abstract Bochner integral by $\int F\mathrm{d}\mu$. Define the Bochner integral axiomatically by: $$\text{(L)}\quad\int(F+G)\mathrm{d}\mu=\int F\mathrm{d}\mu+\int F\mathrm{d}\mu,\,\int\lambda F\mathrm{d}\mu=\lambda\int F\mathrm{d}\mu$$ $$\text{(N)}:\quad\left\|\int F\mathrm{d}\mu\right\|\leq\int\|F\|\mathrm{d}\mu$$ $$\text{(DC)}:\quad\|F_n\|\leq h:\quad F_n\to F\implies\int F\mathrm{d}\mu\to\int F\mathrm{d}\mu\quad\left(\int h\mathrm{d}\mu<\infty\right)$$ And especially for finite measures: $$\text{(C)}:\quad\int C\mathrm{d}\mu=C\mu(\Omega)$$ Construction This forces the integral for simple functions to become: $$S=\sum_{k=1}^KS_k\chi(A_k):\quad\int S\mathrm{d}\mu=\sum_{k=1}^KS_k\mu(A_k)$$ Now, for Bochner measurable functions Bochner integrability should determine the integral, too: $$S_n\to F\implies\int S_n\mathrm{d}\mu\to\int F\mathrm{d}\mu$$ But how to apply dominated convergence therefore: $$\|F-S_n\|\to0\implies\|S_n\|\leq\|F\|$$ (I got it now; in any way, you are warmly encouraged to do give an answer, too!!) Discardure Introduce the restricted integral through $\int_A F\mathrm{d}\mu:=\int\chi_AF\mathrm{d}\mu$. There is another axiom which seems not independent of the others: $$\text{(S)}:\quad\int_A F\mathrm{d}\mu=\sum_{k\in\mathbb{N}}\int_{A_k}F\mathrm{d}\mu\quad\left(A=\bigsqcup_{k\in\mathbb{N}}A_k\right)$$ (Is it really independent?)","Disclaimer It is meant to record. See: Answer own Question It is written as question. Have fun! :) Reference It is taken from the original paper: S. Bochner, Integration It is related to: Bochner Integral: Integrability Definition Given a measure space $\Omega$ and a Banach space $E$. Consider Bochner measurable functions $S_n\to F$. Suppose Bochner integrability as $\int\|F\|\mathrm{d}\mu<\infty$. Denote the abstract Bochner integral by $\int F\mathrm{d}\mu$. Define the Bochner integral axiomatically by: $$\text{(L)}\quad\int(F+G)\mathrm{d}\mu=\int F\mathrm{d}\mu+\int F\mathrm{d}\mu,\,\int\lambda F\mathrm{d}\mu=\lambda\int F\mathrm{d}\mu$$ $$\text{(N)}:\quad\left\|\int F\mathrm{d}\mu\right\|\leq\int\|F\|\mathrm{d}\mu$$ $$\text{(DC)}:\quad\|F_n\|\leq h:\quad F_n\to F\implies\int F\mathrm{d}\mu\to\int F\mathrm{d}\mu\quad\left(\int h\mathrm{d}\mu<\infty\right)$$ And especially for finite measures: $$\text{(C)}:\quad\int C\mathrm{d}\mu=C\mu(\Omega)$$ Construction This forces the integral for simple functions to become: $$S=\sum_{k=1}^KS_k\chi(A_k):\quad\int S\mathrm{d}\mu=\sum_{k=1}^KS_k\mu(A_k)$$ Now, for Bochner measurable functions Bochner integrability should determine the integral, too: $$S_n\to F\implies\int S_n\mathrm{d}\mu\to\int F\mathrm{d}\mu$$ But how to apply dominated convergence therefore: $$\|F-S_n\|\to0\implies\|S_n\|\leq\|F\|$$ (I got it now; in any way, you are warmly encouraged to do give an answer, too!!) Discardure Introduce the restricted integral through $\int_A F\mathrm{d}\mu:=\int\chi_AF\mathrm{d}\mu$. There is another axiom which seems not independent of the others: $$\text{(S)}:\quad\int_A F\mathrm{d}\mu=\sum_{k\in\mathbb{N}}\int_{A_k}F\mathrm{d}\mu\quad\left(A=\bigsqcup_{k\in\mathbb{N}}A_k\right)$$ (Is it really independent?)",,"['integration', 'functional-analysis', 'banach-spaces']"
17,Area of Intersection of Circle and Square,Area of Intersection of Circle and Square,,"Given a point $(x,y)\in [0,1]^2$ and $r > 0$, I would like to derive a general formula for the area of the intersection of the circle of radius $r$ centered at $(x,y)$ and the unit square. What is the best approach for this? I have thought of a divide-and-conquer approach using cases, but there are quite a few, so I'm wondering if this could be done more elegantly. Perhaps a double integral could help?","Given a point $(x,y)\in [0,1]^2$ and $r > 0$, I would like to derive a general formula for the area of the intersection of the circle of radius $r$ centered at $(x,y)$ and the unit square. What is the best approach for this? I have thought of a divide-and-conquer approach using cases, but there are quite a few, so I'm wondering if this could be done more elegantly. Perhaps a double integral could help?",,"['integration', 'geometry', 'multivariable-calculus', 'euclidean-geometry', 'area']"
18,Trying to recall an integration trick,Trying to recall an integration trick,,"In my notes, I have the following problem. Find the volume of (a) $x^2+y^2 \le 1$, $x^2+z^2\le 1$ in $\mathbb R^3$ (b) $x^2+y^2 \le 1$, $x^2+z^2\le 1$, $y^2+z^2\le 1$ in $\mathbb R^3$ (c) $x^2+y^2+z^2+w^2 \le 1$ in $\mathbb R^4$ Observe that these form interesting geometric shapes. The first is the intersection of two orthogonal cylinders, the second in the intersection of three orthogonal cylinders, and the third is the $4$-ball. One can of course bash these with messy calculus. However, I copied this problem down when it was presented to me because each part had a clever solution that was not very computational. In particular, I vaguely remember doing the last one by taking the four iterated integrals in pairs. I do not remember how this helps. I think it was something to do with recognizing each as the area of a circle. Question: How does one cleverly and with minimal computation find the above volumes?","In my notes, I have the following problem. Find the volume of (a) $x^2+y^2 \le 1$, $x^2+z^2\le 1$ in $\mathbb R^3$ (b) $x^2+y^2 \le 1$, $x^2+z^2\le 1$, $y^2+z^2\le 1$ in $\mathbb R^3$ (c) $x^2+y^2+z^2+w^2 \le 1$ in $\mathbb R^4$ Observe that these form interesting geometric shapes. The first is the intersection of two orthogonal cylinders, the second in the intersection of three orthogonal cylinders, and the third is the $4$-ball. One can of course bash these with messy calculus. However, I copied this problem down when it was presented to me because each part had a clever solution that was not very computational. In particular, I vaguely remember doing the last one by taking the four iterated integrals in pairs. I do not remember how this helps. I think it was something to do with recognizing each as the area of a circle. Question: How does one cleverly and with minimal computation find the above volumes?",,"['integration', 'contest-math']"
19,"Using the definition of the integral, find $\int_0^a x^2 dx$","Using the definition of the integral, find",\int_0^a x^2 dx,"The definition of the integral I was given (which after searching around seems like the common definition) is the value of the inf{upper sums across all dissections} (integral exists when this coincides with the sup{lower sums across all dissections}). Now, when I searched online of how to do the integral in question, all solutions said: partition $[0,a]$ into strips of equal width $(1/N)$ and then let $N$ tend to infinity to get a limit $L$ etc. But surely this doesn't cover all the possible dissections and also can't be a refinement of some dissections (e.g. if a is rational and I have a dissection with an irrational point $x$ in it then any dissection given in the above way can never have $x$ as a point in it). So why should $L$ be the value of the integral? Yet, I don't know how else to approach this. Help greatly appreciated!","The definition of the integral I was given (which after searching around seems like the common definition) is the value of the inf{upper sums across all dissections} (integral exists when this coincides with the sup{lower sums across all dissections}). Now, when I searched online of how to do the integral in question, all solutions said: partition $[0,a]$ into strips of equal width $(1/N)$ and then let $N$ tend to infinity to get a limit $L$ etc. But surely this doesn't cover all the possible dissections and also can't be a refinement of some dissections (e.g. if a is rational and I have a dissection with an irrational point $x$ in it then any dissection given in the above way can never have $x$ as a point in it). So why should $L$ be the value of the integral? Yet, I don't know how else to approach this. Help greatly appreciated!",,[]
20,Rewriting an integral,Rewriting an integral,,"This is concerning Poisson's equation with oblique boundary condition (Gilbarg Trudinger p121) We let $\Gamma(|x-y|)$ denote the fundamental solution to Laplace's equation.  Also, let $x-y^{*} = (x_1-y_1, \cdots ,x_{n-1}-y_{n-1},x_n+y_n)$.  Finally, let  $\zeta = \frac{(x-y^{*})}{|x-y^{*}|}$ I don't understand the computations to get from this $$ \Theta = -2b_n\int_0^{\infty}{e^{as}D_n\Gamma(x-y^{*}+\textbf{b}s)ds}$$ where $a\leq 0$ to this $$ \Theta = -|x-y^{*}|^{2-n}\left( (\frac{2 b_n}{n\omega_n})\int_0^{\infty}e^{a|x-y^{*}|s}\frac{\zeta_n+b_ns}{(1+2({\textbf{$\zeta$}\cdot\textbf{b})s+s^2)^{\frac{n}{2}}}}ds\right)$$ where $\omega_n$ is the volume of the n-ball.  I guess I'm getting stuck in one regard because we only define the fundamental solution for $|x-y|$, and I've never seen something where you are adding a vector inside.  Also, how do we get the additional term in the exponent?  If someone could point me in the right direction, I would appreciate it.  Thanks.","This is concerning Poisson's equation with oblique boundary condition (Gilbarg Trudinger p121) We let $\Gamma(|x-y|)$ denote the fundamental solution to Laplace's equation.  Also, let $x-y^{*} = (x_1-y_1, \cdots ,x_{n-1}-y_{n-1},x_n+y_n)$.  Finally, let  $\zeta = \frac{(x-y^{*})}{|x-y^{*}|}$ I don't understand the computations to get from this $$ \Theta = -2b_n\int_0^{\infty}{e^{as}D_n\Gamma(x-y^{*}+\textbf{b}s)ds}$$ where $a\leq 0$ to this $$ \Theta = -|x-y^{*}|^{2-n}\left( (\frac{2 b_n}{n\omega_n})\int_0^{\infty}e^{a|x-y^{*}|s}\frac{\zeta_n+b_ns}{(1+2({\textbf{$\zeta$}\cdot\textbf{b})s+s^2)^{\frac{n}{2}}}}ds\right)$$ where $\omega_n$ is the volume of the n-ball.  I guess I'm getting stuck in one regard because we only define the fundamental solution for $|x-y|$, and I've never seen something where you are adding a vector inside.  Also, how do we get the additional term in the exponent?  If someone could point me in the right direction, I would appreciate it.  Thanks.",,"['integration', 'partial-differential-equations']"
21,"Evaluate $\int\limits_{\mathbb{R}^2} \frac{e^{i \langle \xi, x \rangle} d\xi}{ \langle\xi,\theta\rangle}$",Evaluate,"\int\limits_{\mathbb{R}^2} \frac{e^{i \langle \xi, x \rangle} d\xi}{ \langle\xi,\theta\rangle}","The task is to evalute  $$ \int\limits_{\mathbb{R}^2} \frac{e^{i \langle \xi, x \rangle} d\xi}{ \langle\xi,\theta\rangle}, \;\;\; \theta \in \mathbb{C}^2 \setminus ( \mathbb{S}^1 \cup \left\{ 0 \right\} ), \;\;\; \theta_1^2 + \theta_2^2 = 1,\;\;\;  x\in \mathbb{R}^2 $$ Obviously it is the Fourrier transform of $f(\xi) = \langle \xi,\theta \rangle ^ {-1}$. I tried to make the change $y_{1} = \langle\xi,\Re \theta\rangle, \;\; y_2 = \langle \xi, \Im \theta \rangle$, but i faced with difficult calculations. Update: let  $$  f(x) = \frac{1}{2\pi i}\int\limits_{\mathbb{R}^2} \frac{e^{i \langle \xi, x \rangle} d\xi}{ \langle\xi,\theta\rangle} $$ Then, using inverse Fourrier transform we get $$  i\langle\theta,\xi\rangle \hat{f}(\xi) = \frac{1}{\sqrt{2\pi}} $$ Taking Fourier transform now we recieve $$  \langle \theta, \nabla f(x) \rangle = \delta(x) $$ In other words, f(x) is a Green function for operator $L = \langle \theta, \nabla \rangle$.","The task is to evalute  $$ \int\limits_{\mathbb{R}^2} \frac{e^{i \langle \xi, x \rangle} d\xi}{ \langle\xi,\theta\rangle}, \;\;\; \theta \in \mathbb{C}^2 \setminus ( \mathbb{S}^1 \cup \left\{ 0 \right\} ), \;\;\; \theta_1^2 + \theta_2^2 = 1,\;\;\;  x\in \mathbb{R}^2 $$ Obviously it is the Fourrier transform of $f(\xi) = \langle \xi,\theta \rangle ^ {-1}$. I tried to make the change $y_{1} = \langle\xi,\Re \theta\rangle, \;\; y_2 = \langle \xi, \Im \theta \rangle$, but i faced with difficult calculations. Update: let  $$  f(x) = \frac{1}{2\pi i}\int\limits_{\mathbb{R}^2} \frac{e^{i \langle \xi, x \rangle} d\xi}{ \langle\xi,\theta\rangle} $$ Then, using inverse Fourrier transform we get $$  i\langle\theta,\xi\rangle \hat{f}(\xi) = \frac{1}{\sqrt{2\pi}} $$ Taking Fourier transform now we recieve $$  \langle \theta, \nabla f(x) \rangle = \delta(x) $$ In other words, f(x) is a Green function for operator $L = \langle \theta, \nabla \rangle$.",,"['fourier-analysis', 'integration', 'integral-transforms']"
22,"Evaluating $\int_{-\infty}^\infty \coth x \exp(-a \cosh x + b \sinh x) \, dx$ and $\int_0^b K_0(\sqrt{a^2 - b'^2}) \, db'$",Evaluating  and,"\int_{-\infty}^\infty \coth x \exp(-a \cosh x + b \sinh x) \, dx \int_0^b K_0(\sqrt{a^2 - b'^2}) \, db'","I am trying to evaluate the integral $$I = \int_{-\infty}^{\infty} \underbrace{\coth x}_{f(x)} \exp(-a \cosh x + b \sinh x) \, dx \, ,$$ where $a \in \mathbb{R}^+$ , $b \in \mathbb{R}$ , and $|b/a| < 1$ . Related integrals, where one replaces $f(x) = \coth x$ by $\cosh^n x \sinh^m x$ for $n, m \in \mathbb{N}$ , are relatively straightforward to solve by repeatedly differentiating under the integral, i.e. $$\int_{-\infty}^{\infty} \cosh^n x \sinh^m x \exp(-a \cosh x + b \sinh x) \, dx = (-\partial_a)^n \partial_b^m \int_{-\infty}^{\infty} \exp(-a \cosh x + b \sinh x) \, dx \, .$$ This integral can be evaluated to get a modified Bessel function of the second kind $$\int_{-\infty}^{\infty} \exp(-a \cosh x + b \sinh x) \, dx = 2 K_0(\sqrt{a^2 - b^2}) \, ,$$ whereupon one may straightforwardly apply the derivatives to generate the even $(\cosh^n x)$ and odd $(\sinh^m x)$ moments of the distribution. However, this same approach does not work for the negative integer moments, since one must integrate for negative powers, with the integral in question being rather non-trivial to evaluate. For example, in the case that $f(x) = 1/\sinh x$ , one finds $$I'(b) = \int_{-\infty}^{\infty} \exp(-a \cosh x + b \sinh x) \, dx \, .$$ Then, using the fact that the integrand of $I(0)$ is odd, such that $I(0) = 0$ , one must find $$I = \int_0^b \int_{-\infty}^{\infty} \exp(-a \cosh x + b' \sinh x) \, dx \, db' = \int_0^b 2 K_0(\sqrt{a^2 - b'^2}) \, db' \, ,$$ and I do not know how to proceed. Similar difficulties are encountered for $f(x) = 1/\cosh x$ . If one wants to evaluate the original integral by this method, with $f(x) = \coth x$ (or also for $f(x) = \tanh x$ ), then one must evaluate the above cases. I would greatly appreciate any suggestions on how to evaluate the above integrals (for $f(x) = 1/\sinh x$ and $f(x) = 1/\cosh x$ ), or any suggestions of alternative approaches that would avoid these difficulties.","I am trying to evaluate the integral where , , and . Related integrals, where one replaces by for , are relatively straightforward to solve by repeatedly differentiating under the integral, i.e. This integral can be evaluated to get a modified Bessel function of the second kind whereupon one may straightforwardly apply the derivatives to generate the even and odd moments of the distribution. However, this same approach does not work for the negative integer moments, since one must integrate for negative powers, with the integral in question being rather non-trivial to evaluate. For example, in the case that , one finds Then, using the fact that the integrand of is odd, such that , one must find and I do not know how to proceed. Similar difficulties are encountered for . If one wants to evaluate the original integral by this method, with (or also for ), then one must evaluate the above cases. I would greatly appreciate any suggestions on how to evaluate the above integrals (for and ), or any suggestions of alternative approaches that would avoid these difficulties.","I = \int_{-\infty}^{\infty} \underbrace{\coth x}_{f(x)} \exp(-a \cosh x + b \sinh x) \, dx \, , a \in \mathbb{R}^+ b \in \mathbb{R} |b/a| < 1 f(x) = \coth x \cosh^n x \sinh^m x n, m \in \mathbb{N} \int_{-\infty}^{\infty} \cosh^n x \sinh^m x \exp(-a \cosh x + b \sinh x) \, dx = (-\partial_a)^n \partial_b^m \int_{-\infty}^{\infty} \exp(-a \cosh x + b \sinh x) \, dx \, . \int_{-\infty}^{\infty} \exp(-a \cosh x + b \sinh x) \, dx = 2 K_0(\sqrt{a^2 - b^2}) \, , (\cosh^n x) (\sinh^m x) f(x) = 1/\sinh x I'(b) = \int_{-\infty}^{\infty} \exp(-a \cosh x + b \sinh x) \, dx \, . I(0) I(0) = 0 I = \int_0^b \int_{-\infty}^{\infty} \exp(-a \cosh x + b' \sinh x) \, dx \, db' = \int_0^b 2 K_0(\sqrt{a^2 - b'^2}) \, db' \, , f(x) = 1/\cosh x f(x) = \coth x f(x) = \tanh x f(x) = 1/\sinh x f(x) = 1/\cosh x","['integration', 'definite-integrals', 'special-functions', 'bessel-functions', 'hyperbolic-functions']"
23,Evaluating $\int_{0}^{\infty} \frac{\mathrm{d}x}{x(I_n(x)^2 + K_n(x)^2)}$ and similar integrals.,Evaluating  and similar integrals.,\int_{0}^{\infty} \frac{\mathrm{d}x}{x(I_n(x)^2 + K_n(x)^2)},"This question is inspired by this evaluation of an integral by Michael Penn. Suppose we have a differential equation $y''+p(x) y' +q(x)y =0$ with linearly independent solutions $y_1(x)$ and $y_2(x)$ over some interval $I$ . Given that $p,q$ are continuous then $$ \mathrm{d}\left(\frac{y_2}{y_1} \right) = \frac{y_1 y_2' -y_1' y_2}{y_1^2} \mathrm{d}x= \frac{W(y_1, y_2)(x)}{y_1^2} \mathrm{d}x= W(y_1, y_2)(x_0) e^{-\int_{x_0}^{x}p(t)\, \mathrm{d}t}\frac{\mathrm{d}x}{y_1^2}, \quad x_0 \in I $$ where Abel's formula was used in the last step. So if we now suppose that we have an integral like $\int_{a}^{b} \frac{\mathrm{d}x}{y_1^2(x)+y_2^2(x)}$ then we can do the following $$ \int_{a}^{b} \frac{\mathrm{d}x}{y_1^2(x)+y_2^2(x)} = \int_{a}^{b} \frac{1}{1+ \left( \frac{y_2}{y_1}\right)^2}\frac{\mathrm{d}x}{y_1^2 } \overset{u = y_2/y_1}{=}\frac{1}{W(y_1,y_2)(x_0)}\int_{\alpha}^{\beta}\frac{\mathrm{d}u}{\left(1+u^2\right)e^{-\int_{x_0}^{\left( \frac{y_2}{y_1}\right)^{-1}(u)}p(t)\, \mathrm{d}t}}  $$ which is ugly in general, except for when $p =0$ , and then the integral reduces to $$ \int_{a}^{b} \frac{\mathrm{d}x}{y_1^2(x)+y_2^2(x)} = \frac{\arctan\left(\frac{y_2(b)}{y_1(b)}\right)- \arctan\left(\frac{y_2(a)}{y_1(a)}\right)}{W(y_1,y_2)(x_0)} $$ One application of the above is for the integral $$ \int_{0}^{\infty} \frac{\mathrm{d}x}{x(I_n(x)^2 + K_{n}(x)^2)} $$ where $I,K$ are the modified Bessel functions. If we know that $x^2y'' -\left(x^2 + n^2 - \frac{1}{4}\right)y=0$ has solutions $\sqrt{x}I_n(x)$ and $\sqrt{x}K_{n}(x)$ then we can readily evaluate the integral as $$ \frac{\pi}{x\left(I_nK_{n-1} + I_nK_{n+1}+K_nI_{n-1} + K_nI_{n+1}\right)\Big\vert_{x_0}} = \frac{\pi}{2} $$ Does this technique have a name? And do you know some other examples of integrals that could be evaluated by a similar method? Thank you!","This question is inspired by this evaluation of an integral by Michael Penn. Suppose we have a differential equation with linearly independent solutions and over some interval . Given that are continuous then where Abel's formula was used in the last step. So if we now suppose that we have an integral like then we can do the following which is ugly in general, except for when , and then the integral reduces to One application of the above is for the integral where are the modified Bessel functions. If we know that has solutions and then we can readily evaluate the integral as Does this technique have a name? And do you know some other examples of integrals that could be evaluated by a similar method? Thank you!","y''+p(x) y' +q(x)y =0 y_1(x) y_2(x) I p,q 
\mathrm{d}\left(\frac{y_2}{y_1} \right) = \frac{y_1 y_2' -y_1' y_2}{y_1^2} \mathrm{d}x= \frac{W(y_1, y_2)(x)}{y_1^2} \mathrm{d}x= W(y_1, y_2)(x_0) e^{-\int_{x_0}^{x}p(t)\, \mathrm{d}t}\frac{\mathrm{d}x}{y_1^2}, \quad x_0 \in I
 \int_{a}^{b} \frac{\mathrm{d}x}{y_1^2(x)+y_2^2(x)} 
\int_{a}^{b} \frac{\mathrm{d}x}{y_1^2(x)+y_2^2(x)} = \int_{a}^{b} \frac{1}{1+ \left( \frac{y_2}{y_1}\right)^2}\frac{\mathrm{d}x}{y_1^2 } \overset{u = y_2/y_1}{=}\frac{1}{W(y_1,y_2)(x_0)}\int_{\alpha}^{\beta}\frac{\mathrm{d}u}{\left(1+u^2\right)e^{-\int_{x_0}^{\left( \frac{y_2}{y_1}\right)^{-1}(u)}p(t)\, \mathrm{d}t}} 
 p =0 
\int_{a}^{b} \frac{\mathrm{d}x}{y_1^2(x)+y_2^2(x)} = \frac{\arctan\left(\frac{y_2(b)}{y_1(b)}\right)- \arctan\left(\frac{y_2(a)}{y_1(a)}\right)}{W(y_1,y_2)(x_0)}
 
\int_{0}^{\infty} \frac{\mathrm{d}x}{x(I_n(x)^2 + K_{n}(x)^2)}
 I,K x^2y'' -\left(x^2 + n^2 - \frac{1}{4}\right)y=0 \sqrt{x}I_n(x) \sqrt{x}K_{n}(x) 
\frac{\pi}{x\left(I_nK_{n-1} + I_nK_{n+1}+K_nI_{n-1} + K_nI_{n+1}\right)\Big\vert_{x_0}} = \frac{\pi}{2}
","['integration', 'ordinary-differential-equations', 'definite-integrals', 'special-functions', 'homogeneous-equation']"
24,Path Signatures and Picard iterations,Path Signatures and Picard iterations,,"Recently, I've started studying path signatures and, currently, I'm reading a standard reference, namely ""A Primer on the Signature Method in Machine Learning"" by Ilya Chevyrev and Andrey Kormilitzin. Now, at some point the authors try to show how path signatures naturally emerge in the theory of Controlled Differential Equations, and they do so via Picard iterations. So far, so good. The things that are bothering me are the following: The authors claim that a map $V: \mathbb{R}^e \to L(\mathbb{R}^d,\mathbb{R}^e)$ can be equivalently seen as a map $V: \mathbb{R}^d \to L(\mathbb{R}^e,\mathbb{R}^e)$ . This I am more or less willing to accept. Indeed, if we consider $x \in \mathbb{R}^d$ and $y \in \mathbb{R}^e$ , we observe that $$ y \in \mathbb{R}^e \mapsto V(y) \in \mathbb{R}^{e \times d} \implies V(y)x \in \mathbb{R}^e, $$ yields a map in $\mathcal{L}(\mathbb{R}^e, \mathbb{R}^e)$ by taking $y$ to $V(y)x$ for all $y\in \mathbb{R}^e$ . If we now consider this map to be parameterized by $x$ , we end up with a map $\mathbb{R}^d \to \mathcal{L}(\mathbb{R}^e, \mathbb{R}^e)$ associated to $V$ . This association can be made one-to-one, thus we may equivalently treat $V$ as a linear map $\mathbb{R}^d \to \mathcal{L}(\mathbb{R}^e, \mathbb{R}^e)$ . I think this is what the authors had in mind, but I'd appreciate more insight. Now, my main problem is the claim made in the beginning of page 10. They say: Here $X$ is a path $[a,b] \to \mathbb{R}^d$ and $Y$ is another path $[a,b] \to \mathbb{R}^e$ . How do signatures actually pop out of this iterated integral? Is it just by the linearity of $V$ and the integral? I want to see something of the form $$\int_{a<t_k<b} \int_{a<t_{k-1} < t_k} ... \int_{a < t_1 <t_2} dX_{t_1}^{i_1} ... dX_{t_{k-1}}^{i_{k-1}} dX_{t_k}^{i_k}$$ Could you help me figure out how to formally derive the iterated integral above from the quantity (1.34)?","Recently, I've started studying path signatures and, currently, I'm reading a standard reference, namely ""A Primer on the Signature Method in Machine Learning"" by Ilya Chevyrev and Andrey Kormilitzin. Now, at some point the authors try to show how path signatures naturally emerge in the theory of Controlled Differential Equations, and they do so via Picard iterations. So far, so good. The things that are bothering me are the following: The authors claim that a map can be equivalently seen as a map . This I am more or less willing to accept. Indeed, if we consider and , we observe that yields a map in by taking to for all . If we now consider this map to be parameterized by , we end up with a map associated to . This association can be made one-to-one, thus we may equivalently treat as a linear map . I think this is what the authors had in mind, but I'd appreciate more insight. Now, my main problem is the claim made in the beginning of page 10. They say: Here is a path and is another path . How do signatures actually pop out of this iterated integral? Is it just by the linearity of and the integral? I want to see something of the form Could you help me figure out how to formally derive the iterated integral above from the quantity (1.34)?","V: \mathbb{R}^e \to L(\mathbb{R}^d,\mathbb{R}^e) V: \mathbb{R}^d \to L(\mathbb{R}^e,\mathbb{R}^e) x \in \mathbb{R}^d y \in \mathbb{R}^e  y \in \mathbb{R}^e \mapsto V(y) \in \mathbb{R}^{e \times d} \implies V(y)x \in \mathbb{R}^e,  \mathcal{L}(\mathbb{R}^e, \mathbb{R}^e) y V(y)x y\in \mathbb{R}^e x \mathbb{R}^d \to \mathcal{L}(\mathbb{R}^e, \mathbb{R}^e) V V \mathbb{R}^d \to \mathcal{L}(\mathbb{R}^e, \mathbb{R}^e) X [a,b] \to \mathbb{R}^d Y [a,b] \to \mathbb{R}^e V \int_{a<t_k<b} \int_{a<t_{k-1} < t_k} ... \int_{a < t_1 <t_2} dX_{t_1}^{i_1} ... dX_{t_{k-1}}^{i_{k-1}} dX_{t_k}^{i_k}","['integration', 'ordinary-differential-equations', 'reference-request', 'notation', 'stieltjes-integral']"
25,A non-Riemann integrable function that is Lebesgue integrable,A non-Riemann integrable function that is Lebesgue integrable,,"I'm seeking a function that is non-Riemann integrable yet Lebesgue integrable. Everyone seems to illustrate this phenomenon with the indicator function applied to rational numbers. Is there another such function... perhaps one that would be of greater interest and background to students... one that can be (approximately) plotted? We need an uncountable number of singularities.  A function such as $f(x) = \frac{1}{\sin 1/x}$ on $[0,1]$ (plotted) has an infinite number of discontinuities, but these can be counted.","I'm seeking a function that is non-Riemann integrable yet Lebesgue integrable. Everyone seems to illustrate this phenomenon with the indicator function applied to rational numbers. Is there another such function... perhaps one that would be of greater interest and background to students... one that can be (approximately) plotted? We need an uncountable number of singularities.  A function such as on (plotted) has an infinite number of discontinuities, but these can be counted.","f(x) = \frac{1}{\sin 1/x} [0,1]","['integration', 'lebesgue-integral', 'examples-counterexamples', 'riemann-integration']"
26,Integral representation for series of any order,Integral representation for series of any order,,"Hello infinity series enjoyers. If my calulations are correct, I think I made some integral representation of any divergent and convergent seris of any order s. All calulations and the question are down below. $\displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!  f (k)  =\overbrace { \sum_{k_{s-1}=x} ^{\infty} ... \sum_{k_1=k_2}^{\infty} \sum_{k_0=k_1}^{\infty}}^{s}f (k_0) =\sum_{k=x}^{\infty}f (k)\frac {( k-x+s-1)!}{\Gamma (s)(k-x)!}$ We can prove that ( Infinite series as integral representation ) $\displaystyle   \sum\limits^1_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!    f (k) =  \lim\limits_{h \rightarrow 0} \sum_{n=0}^{\infty}\frac {\frac{d^{n}}{dx^n}F^s (x) \frac{d^{n}}{dh^n}  \left( \frac{-h}{e^h-1}   \right)    }{n!}   =-\frac {i \pi}{2}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  \csc^2 (\pi t) \int f(x+t)dt dt $ Now we have to just substitute first equation to secound $\displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!    f (k) =-\frac {i \pi  }{2}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  csc^2 (\pi t) \int   f (t+x)\frac {( t+s-1)!}{\Gamma (s)(t)!}   dt dt =\frac {i \pi (-1)^{s}}{2\Gamma (s)}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  F^{s}(x+t)\Psi_s (t)dt$ Where $F^s$ is s ordered antideritative of f and $\Psi_s(t)$ is defined down below. $\displaystyle \Psi_s(t)= \sum_{n=0} ^{\infty} \left [ \frac {d^{n}}{dt^{n}}csc^2 (\pi t) \right] \left [   \frac {d^{s-1-n}}{dt^{s-1-n}} \frac {(t+s-1)!}{ t!}   {s\choose n+1}  \right]$ But we can write $F^{s}(x+t)$ as Taylor series and compere it to generalised Euler-Maclouren Summation to determinate $(-1)^{s}$ for non itintegers $\displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!  f (k)  =  \sum_{n=0}^{\infty}\frac {   F^{s-n}(x)}{n!}  (-1)^s\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}(-t)^n   \frac {i \pi }{2\Gamma (s)}\Psi_s (t)dt = \lim\limits_{h \rightarrow 0}      \sum_{n=0}^{\infty} \frac {F^{s-n} (x) \frac{d^{n}}{dh^n}  \left(   \frac{-h}{e^h-1}   \right)^s    }{n!}   $ And that imply $\displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!  f (k) =\frac {i \pi e^{i \pi s}}{2\Gamma (s)}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  F^{s}(x+t)\Psi_s (t)dt $ Is there any simple equation for $\Psi_s (t) $ ? Maybe I overcomplicated some transformations.","Hello infinity series enjoyers. If my calulations are correct, I think I made some integral representation of any divergent and convergent seris of any order s. All calulations and the question are down below. We can prove that ( Infinite series as integral representation ) Now we have to just substitute first equation to secound Where is s ordered antideritative of f and is defined down below. But we can write as Taylor series and compere it to generalised Euler-Maclouren Summation to determinate for non itintegers And that imply Is there any simple equation for ? Maybe I overcomplicated some transformations.","\displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!  f (k)  =\overbrace {
\sum_{k_{s-1}=x} ^{\infty} ... \sum_{k_1=k_2}^{\infty} \sum_{k_0=k_1}^{\infty}}^{s}f (k_0)
=\sum_{k=x}^{\infty}f (k)\frac {( k-x+s-1)!}{\Gamma (s)(k-x)!} \displaystyle   \sum\limits^1_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!    f (k) = 
\lim\limits_{h \rightarrow 0} \sum_{n=0}^{\infty}\frac {\frac{d^{n}}{dx^n}F^s (x) \frac{d^{n}}{dh^n}  \left( \frac{-h}{e^h-1}   \right)    }{n!}   =-\frac {i \pi}{2}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  \csc^2 (\pi t) \int f(x+t)dt dt  \displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!    f (k) =-\frac {i \pi  }{2}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  csc^2 (\pi t) \int
  f (t+x)\frac {( t+s-1)!}{\Gamma (s)(t)!}   dt dt
=\frac {i \pi (-1)^{s}}{2\Gamma (s)}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  F^{s}(x+t)\Psi_s (t)dt F^s \Psi_s(t) \displaystyle \Psi_s(t)= \sum_{n=0} ^{\infty} \left [ \frac {d^{n}}{dt^{n}}csc^2 (\pi t) \right] \left [   \frac {d^{s-1-n}}{dt^{s-1-n}} \frac {(t+s-1)!}{ t!}   {s\choose n+1}  \right] F^{s}(x+t) (-1)^{s} \displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!  f (k)  =  \sum_{n=0}^{\infty}\frac {   F^{s-n}(x)}{n!}  (-1)^s\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}(-t)^n   \frac {i \pi }{2\Gamma (s)}\Psi_s (t)dt = \lim\limits_{h \rightarrow 0}      \sum_{n=0}^{\infty} \frac {F^{s-n} (x) \frac{d^{n}}{dh^n}  \left(   \frac{-h}{e^h-1}   \right)^s    }{n!}    \displaystyle   \sum\limits^s_{k=x}     \;\!\!\;\!  \!\!\!\!\!\!\!\!\! \lower -0.2pt {\infty}  \quad \!\!\!  f (k) =\frac {i \pi e^{i \pi s}}{2\Gamma (s)}\int_{-\frac {1}{2}-i\infty}^{-\frac {1}{2}+i\infty}  F^{s}(x+t)\Psi_s (t)dt  \Psi_s (t) ","['integration', 'sequences-and-series', 'transformation', 'divergent-series', 'analytic-continuation']"
27,"Evaluate $\int_{0}^{\infty }\!{\frac {\ln \left( x \right) \arctan \left( x \right) }{{{\rm e}^{\pi\,x}}-1}}\,{\rm d}x$",Evaluate,"\int_{0}^{\infty }\!{\frac {\ln \left( x \right) \arctan \left( x \right) }{{{\rm e}^{\pi\,x}}-1}}\,{\rm d}x","I have the idea of this integral when I see $$\int_{0}^{\infty }\!{\frac {\arctan \left( x \right) }{{{\rm e}^{\pi\,x}}-1}}\,{\rm d}x$$ and so I know that the closed form is $${\frac{1}{2}}-{\frac {\ln  \left( 2 \right) }{2}}.$$ But really, I don't know any paper where I can evaluate for example $$\int_{0}^{\infty }\!{\frac {\ln  \left( x \right) \arctan \left( x  \right) }{{{\rm e}^{\pi\,x}}-1}}\,{\rm d}x.$$ In the same time, I see that Wolfram can't give a closed form. Does someone has an idea please? Thanks","I have the idea of this integral when I see and so I know that the closed form is But really, I don't know any paper where I can evaluate for example In the same time, I see that Wolfram can't give a closed form. Does someone has an idea please? Thanks","\int_{0}^{\infty }\!{\frac {\arctan \left( x \right) }{{{\rm e}^{\pi\,x}}-1}}\,{\rm d}x {\frac{1}{2}}-{\frac {\ln  \left( 2 \right) }{2}}. \int_{0}^{\infty }\!{\frac {\ln  \left( x \right) \arctan \left( x  \right) }{{{\rm e}^{\pi\,x}}-1}}\,{\rm d}x.","['integration', 'definite-integrals', 'closed-form']"
28,Convergence of double integral involving logarithms and binomials? Can anyone present a simpler proof?,Convergence of double integral involving logarithms and binomials? Can anyone present a simpler proof?,,"I am working through a paper I posted to arXiv and am looking to condense my results as well as seek alternative proofs for some of my intermediate results. In particular, I am looking for a shorter proof that gets me to the result of Theorem 1 below. This Theorem was used to justify convergence of a more complicated double integral in my paper. Is Lemma 1 needed at all? Is there a much simpler line of reasoning to get to Theorem 1 ? Lemma 1. For any $n\in\Bbb N_0$ , $$ I_n=\int_0^1\int_0^1(-1)^n\log^n(1-(1-x)(1-y))\,(1-(1-x)(1-y))^{s-2}\,\mathrm dx\mathrm dy, $$ converges if $s>0$ . Proof. We will first evaluate $I_0$ . Perform the change of variables $(t,v)=((1-x)(1-y),x)$ and integrate over $v$ yielding $$ I_n=\int_0^1(-1)^n\log^n(1-t)(-\log t) (1-t)^{s-2}\,\mathrm dt. $$ Substituting $n=0$ , we again change variables via $x=1-t$ and then integrate by parts with $u=-\log(1-x)$ and $\mathrm dv=x^{s-2}\,\mathrm dx$ to find $$ I_0=\frac{1}{s-1}\int_0^1\frac{1-x^{s-1}}{1-x}\,\mathrm dx+\log(1-x)\frac{1-x^{s-1}}{s-1}\bigg|_{x=0}^1. $$ If $s>0$ the limit term vanishes and upon inspection of the integral representation for the harmonic numbers $$ I_0=\frac{H_{s-1}}{s-1}. $$ Now consider the general case $I_n$ . Without loss of generality assume $n\geq 1$ and perform integration by parts with $u=(-1)^n\log^n(1-t)$ and $\mathrm dv=-\log t(1-t)^{s-2}\,\mathrm dt$ . Expanding the logarithm in $\mathrm dv$ as a power series in $(1-t)$ and integrating termwise we find $$ v=-\sum_{k=0}^\infty\frac{(1-t)^{s+k}}{(s+k)(1+k)}. $$ In this form, it becomes clear that the limit term $uv|_{t=0}^1$ vanishes if $n\geq 1$ so that $I_n=\int_0^1(-v)\,\mathrm du$ . Furthermore, we observe for $s>0$ : $$ -v=\frac{1}{s}(1-t)^{s-1}\sum_{k=0}^\infty\frac{s(1-t)^{k+1}}{(s+k)(1+k)}\leq \frac{1}{s}(-\log t)(1-t)^{s-1}. $$ Hence, $$ I_n\leq\frac{n}{s}\int_0^1(-1)^{n-1}\log^{n-1}(1-t)(-\log t)(1-t)^{s-2}\,\mathrm du=\frac{n}{s}I_{n-1}. $$ Solving the recurrence relation and calling on the result for $I_0$ we find for $s>0$ : $$ I_n\leq\frac{n!}{s^n}\frac{H_{s-1}}{s-1}<\infty, $$ Theorem 1. Let $z\in\Bbb R^+$ , $m,n\in\Bbb N_0$ , $a,b\in(-\infty,2]$ , $$ f(x,y,z) =1-\frac{(1-x)(1-y)}{(1-(1-z)x)(1-(1-z) y)}, $$ $$ F(x,y,z,l,s)=(-1)^l(\log\circ f)^l(x,y,z)f^{s-2}(x,y,z), $$ and $$ I=\int_0^1\int_0^1F(x,y,z,n,a)F(x,y,1,m,b)\,\mathrm dx\mathrm dy. $$ Then $I$ converges whenever $a+b>2$ . Proof. For convenience we will introduce the auxiliary function $$ J(x,y,z)=\frac{z^2}{(z+(1-z)x)^2(z+(1-z)y)^2} $$ as well as the following properties: $$ \begin{array}{*2{>{\displaystyle}l}} (\mathrm{FII}) &\text{$f(\cdot,z)$ is increasing on $z\in\Bbb R^+$ from $f(\cdot,0)=0$ to $f(\cdot,\infty)=1$}.\\[1ex] (\mathrm{J}) &\text{For all $z\in\Bbb R^+$ and $(x,y)\in[0,1]^2$: $0\leq J(x,y,z)\leq z^{2\operatorname{sign}(z-1)}$}. \end{array} $$ Since $n\in\Bbb N_0$ and $a\leq 2$ we are able to deduce from property $(\mathrm{FII})$ that $F(x,y,z,n,a)$ is nonnegative and a decreasing function of $z$ for all $z\in\Bbb R^+$ . Denoting $z^\ast=\min\{1,z\}$ , it follows for all $z\in\Bbb R^+$ $$ I\leq\int_0^1\int_0^1F(x,y,z^\ast,m+n,a+b-2)\,\mathrm dx\mathrm dy. $$ Performing the change of variables $(1-u,1-v)=((1-x)/(1-(1-z^\ast)x),(1-y),(1-(1-z^\ast)y))$ and then using property $(\mathrm J)$ subsequently gives $$ I\leq\max\{1,z^{-2}\}\int_0^1\int_0^1F(u,v,1,m+n,a+b-2)\,\mathrm du\mathrm dv, $$ which according to the Lemma 1 converges if $a+b>2$ . The proof is now complete.","I am working through a paper I posted to arXiv and am looking to condense my results as well as seek alternative proofs for some of my intermediate results. In particular, I am looking for a shorter proof that gets me to the result of Theorem 1 below. This Theorem was used to justify convergence of a more complicated double integral in my paper. Is Lemma 1 needed at all? Is there a much simpler line of reasoning to get to Theorem 1 ? Lemma 1. For any , converges if . Proof. We will first evaluate . Perform the change of variables and integrate over yielding Substituting , we again change variables via and then integrate by parts with and to find If the limit term vanishes and upon inspection of the integral representation for the harmonic numbers Now consider the general case . Without loss of generality assume and perform integration by parts with and . Expanding the logarithm in as a power series in and integrating termwise we find In this form, it becomes clear that the limit term vanishes if so that . Furthermore, we observe for : Hence, Solving the recurrence relation and calling on the result for we find for : Theorem 1. Let , , , and Then converges whenever . Proof. For convenience we will introduce the auxiliary function as well as the following properties: Since and we are able to deduce from property that is nonnegative and a decreasing function of for all . Denoting , it follows for all Performing the change of variables and then using property subsequently gives which according to the Lemma 1 converges if . The proof is now complete.","n\in\Bbb N_0 
I_n=\int_0^1\int_0^1(-1)^n\log^n(1-(1-x)(1-y))\,(1-(1-x)(1-y))^{s-2}\,\mathrm dx\mathrm dy,
 s>0 I_0 (t,v)=((1-x)(1-y),x) v 
I_n=\int_0^1(-1)^n\log^n(1-t)(-\log t) (1-t)^{s-2}\,\mathrm dt.
 n=0 x=1-t u=-\log(1-x) \mathrm dv=x^{s-2}\,\mathrm dx 
I_0=\frac{1}{s-1}\int_0^1\frac{1-x^{s-1}}{1-x}\,\mathrm dx+\log(1-x)\frac{1-x^{s-1}}{s-1}\bigg|_{x=0}^1.
 s>0 
I_0=\frac{H_{s-1}}{s-1}.
 I_n n\geq 1 u=(-1)^n\log^n(1-t) \mathrm dv=-\log t(1-t)^{s-2}\,\mathrm dt \mathrm dv (1-t) 
v=-\sum_{k=0}^\infty\frac{(1-t)^{s+k}}{(s+k)(1+k)}.
 uv|_{t=0}^1 n\geq 1 I_n=\int_0^1(-v)\,\mathrm du s>0 
-v=\frac{1}{s}(1-t)^{s-1}\sum_{k=0}^\infty\frac{s(1-t)^{k+1}}{(s+k)(1+k)}\leq \frac{1}{s}(-\log t)(1-t)^{s-1}.
 
I_n\leq\frac{n}{s}\int_0^1(-1)^{n-1}\log^{n-1}(1-t)(-\log t)(1-t)^{s-2}\,\mathrm du=\frac{n}{s}I_{n-1}.
 I_0 s>0 
I_n\leq\frac{n!}{s^n}\frac{H_{s-1}}{s-1}<\infty,
 z\in\Bbb R^+ m,n\in\Bbb N_0 a,b\in(-\infty,2] 
f(x,y,z) =1-\frac{(1-x)(1-y)}{(1-(1-z)x)(1-(1-z) y)},
 
F(x,y,z,l,s)=(-1)^l(\log\circ f)^l(x,y,z)f^{s-2}(x,y,z),
 
I=\int_0^1\int_0^1F(x,y,z,n,a)F(x,y,1,m,b)\,\mathrm dx\mathrm dy.
 I a+b>2 
J(x,y,z)=\frac{z^2}{(z+(1-z)x)^2(z+(1-z)y)^2}
 
\begin{array}{*2{>{\displaystyle}l}}
(\mathrm{FII}) &\text{f(\cdot,z) is increasing on z\in\Bbb R^+ from f(\cdot,0)=0 to f(\cdot,\infty)=1}.\\[1ex]
(\mathrm{J}) &\text{For all z\in\Bbb R^+ and (x,y)\in[0,1]^2: 0\leq J(x,y,z)\leq z^{2\operatorname{sign}(z-1)}}.
\end{array}
 n\in\Bbb N_0 a\leq 2 (\mathrm{FII}) F(x,y,z,n,a) z z\in\Bbb R^+ z^\ast=\min\{1,z\} z\in\Bbb R^+ 
I\leq\int_0^1\int_0^1F(x,y,z^\ast,m+n,a+b-2)\,\mathrm dx\mathrm dy.
 (1-u,1-v)=((1-x)/(1-(1-z^\ast)x),(1-y),(1-(1-z^\ast)y)) (\mathrm J) 
I\leq\max\{1,z^{-2}\}\int_0^1\int_0^1F(u,v,1,m+n,a+b-2)\,\mathrm du\mathrm dv,
 a+b>2","['integration', 'definite-integrals', 'solution-verification', 'alternative-proof', 'harmonic-numbers']"
29,"Evaluate $\int_0^t e^{-\lambda s} \,\text{erf}(\ln(t-s))\,\text{d}s$?",Evaluate ?,"\int_0^t e^{-\lambda s} \,\text{erf}(\ln(t-s))\,\text{d}s","I'm trying to efficiently graph the function $I(t)$ for $t>0$ where $$I(t) :=\int_0^t e^{-\lambda s} \,\text{erf}(\ln(t-s))\,\text{d}s,\qquad \lambda>0$$ but its evaluation is beyond my powers of integration. I can use a numerical integration package to plot it, but it is pretty slow. Happy to compute a decent approximation if it's available. Mathematica was not able to provide an answer, and I've tried some integral substitutions like $u=\ln(t-s)$ , as well as looked through the fantastic table of erf integrals , but no solution seems to be clear. My current strategy is to approximate the exponential by a quartic polynomial $$\exp(-\lambda x)\approx \sum_{k=0}^4 c_k (\lambda x)^k$$ in some region $x\in[0,R]$ , and set to zero when $x>R$ . Then I can compute $\int s^k \text{erf}(\ln(t-s))\,\text{d}s$ , but there are a painful number of terms when using a quartic - are there any better suggestions? Perhaps some other approximation of the $\exp$ , or nice series expansion of the function? Thanks! Edit : Just to be clear, imagine I am given ten thousand different values of $\lambda$ , and I want to graph $I(t)$ for each of them in the region $t\in [0,100]$ . How can I do this efficiently?","I'm trying to efficiently graph the function for where but its evaluation is beyond my powers of integration. I can use a numerical integration package to plot it, but it is pretty slow. Happy to compute a decent approximation if it's available. Mathematica was not able to provide an answer, and I've tried some integral substitutions like , as well as looked through the fantastic table of erf integrals , but no solution seems to be clear. My current strategy is to approximate the exponential by a quartic polynomial in some region , and set to zero when . Then I can compute , but there are a painful number of terms when using a quartic - are there any better suggestions? Perhaps some other approximation of the , or nice series expansion of the function? Thanks! Edit : Just to be clear, imagine I am given ten thousand different values of , and I want to graph for each of them in the region . How can I do this efficiently?","I(t) t>0 I(t) :=\int_0^t e^{-\lambda s} \,\text{erf}(\ln(t-s))\,\text{d}s,\qquad \lambda>0 u=\ln(t-s) \exp(-\lambda x)\approx \sum_{k=0}^4 c_k (\lambda x)^k x\in[0,R] x>R \int s^k \text{erf}(\ln(t-s))\,\text{d}s \exp \lambda I(t) t\in [0,100]","['integration', 'definite-integrals', 'special-functions', 'convolution', 'error-function']"
30,Evaluating an adelic integral,Evaluating an adelic integral,,"I am reading Arthur's notes on the trace formula, and I would like to understand why sometimes the integral appearing there diverge. The example he gives is the following: $G=GL(2)$ , $P_0$ the standard parabolic of upper triangular matrices, and $\gamma$ the matrix $\pmatrix{1&1\\1&1}$ . He then considers the integral $$\int_{G_\gamma(\mathbb A) \backslash P_0(\mathbb A)} \int_{P_0(\mathbb A) \backslash G(\mathbb A)} f(k^{-1}p^{-1}\gamma p k) dp dk$$ Here $dp = |a|^{-1} da db du$ is a left Haar measure if $p = \pmatrix{a & u \\ & b}$ (I also do not understand how the left Haar measure takes this form). Now he claims that this integral reduces to a constant times $$\prod_{p} (1-p^{-1})^{-1} \int_{P_0(\mathbb A) \backslash G(\mathbb A)} \int_{\mathbb A} f(k^{-1}\pmatrix{1& u \\ & 1} k) du dk$$ I do not understands these computations. I tried to write explicitly the variable in $f$ , making the $u$ disappear (yet it is still in Arthur's expression). Also, I tried to cut the adelic integral in product of local integrals to see the factor $(1-p^{-1})^{-1}$ (I think it should come from $|a|^{-1}$ ), but I only end up with $$\int_{G_\gamma(\mathbb A) \backslash P_0(\mathbb A)} \int_{P_0(\mathbb A) \backslash G(\mathbb A)} f(k^{-1}\pmatrix{1 & a/b \\ & 1} k) |a|^{-1} da db du dk$$ I would like to understand how to obtain his statement, e.g. if there are standard tricks to compute such integrals.","I am reading Arthur's notes on the trace formula, and I would like to understand why sometimes the integral appearing there diverge. The example he gives is the following: , the standard parabolic of upper triangular matrices, and the matrix . He then considers the integral Here is a left Haar measure if (I also do not understand how the left Haar measure takes this form). Now he claims that this integral reduces to a constant times I do not understands these computations. I tried to write explicitly the variable in , making the disappear (yet it is still in Arthur's expression). Also, I tried to cut the adelic integral in product of local integrals to see the factor (I think it should come from ), but I only end up with I would like to understand how to obtain his statement, e.g. if there are standard tricks to compute such integrals.",G=GL(2) P_0 \gamma \pmatrix{1&1\\1&1} \int_{G_\gamma(\mathbb A) \backslash P_0(\mathbb A)} \int_{P_0(\mathbb A) \backslash G(\mathbb A)} f(k^{-1}p^{-1}\gamma p k) dp dk dp = |a|^{-1} da db du p = \pmatrix{a & u \\ & b} \prod_{p} (1-p^{-1})^{-1} \int_{P_0(\mathbb A) \backslash G(\mathbb A)} \int_{\mathbb A} f(k^{-1}\pmatrix{1& u \\ & 1} k) du dk f u (1-p^{-1})^{-1} |a|^{-1} \int_{G_\gamma(\mathbb A) \backslash P_0(\mathbb A)} \int_{P_0(\mathbb A) \backslash G(\mathbb A)} f(k^{-1}\pmatrix{1 & a/b \\ & 1} k) |a|^{-1} da db du dk,"['integration', 'number-theory', 'adeles']"
31,Is this intuition for integrating differential forms correct?,Is this intuition for integrating differential forms correct?,,"I'm learning about differential forms and have seen that the wedge product of $k$ 1-forms $\omega_{1},\cdots,\omega_{k}$ acting on $k$ vectors $\mathbf{v}_{1},\ldots,\mathbf{v}_{k}$ is given by $$\left(\omega_{1}\wedge\cdots\wedge\omega_{k}\right)\left(\mathbf{v}_{1},\ldots,\mathbf{v}_{k}\right)=\left|\begin{array}{ccc} \omega_{1}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{1}\left(\mathbf{v}_{k}\right)\\ \vdots &  & \vdots\\ \omega_{k}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{k}\left(\mathbf{v}_{k}\right) \end{array}\right|.$$ This provides me with a nice mental picture that the value of the $k$ -form $\omega=\omega_{1}\wedge\cdots\wedge\omega_{k}$ acting on the $k$ vectors $\mathbf{v}_{1},\ldots,\mathbf{v}_{k}$ is given by the signed volume of the $k$ -dimensional parallelotope spanned by the column vectors of the matrix $$\left[\begin{array}{ccc} \omega_{1}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{1}\left(\mathbf{v}_{k}\right)\\ \vdots &  & \vdots\\ \omega_{k}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{k}\left(\mathbf{v}_{k}\right) \end{array}\right].$$ My question is, can that nice mental picture be extended to integrating differential forms? In other words, can I regard the integral of $$\intop_{M}\omega=\intop_{D}\omega\left(\frac{\partial\Phi}{\partial u^{1}},\ldots,\frac{\partial\Phi}{\partial u^{k}}\right)du^{1}\wedge\cdots\wedge du^{n}$$ as in some way the signed volume of the sum of all the little $k$ -dimensional parallelotopes spanned by the column vectors of $$\left[\begin{array}{ccc} \omega_{1}\left(\frac{\partial\Phi}{\partial u^{1}}\right) & \cdots & \omega_{1}\left(\frac{\partial\Phi}{\partial u^{k}}\right)\\ \vdots &  & \vdots\\ \omega_{k}\left(\frac{\partial\Phi}{\partial u^{1}}\right) & \cdots & \omega_{k}\left(\frac{\partial\Phi}{\partial u^{k}}\right) \end{array}\right].$$ Or have I got this wrong? Late in the day edit If my intuition is correct, could anyone provide a deeper explanation as to what it means for the integral to equal the sum of all the little $k$ -dimensional parallelotopes? I'm having trouble visualising what that actually means.","I'm learning about differential forms and have seen that the wedge product of 1-forms acting on vectors is given by This provides me with a nice mental picture that the value of the -form acting on the vectors is given by the signed volume of the -dimensional parallelotope spanned by the column vectors of the matrix My question is, can that nice mental picture be extended to integrating differential forms? In other words, can I regard the integral of as in some way the signed volume of the sum of all the little -dimensional parallelotopes spanned by the column vectors of Or have I got this wrong? Late in the day edit If my intuition is correct, could anyone provide a deeper explanation as to what it means for the integral to equal the sum of all the little -dimensional parallelotopes? I'm having trouble visualising what that actually means.","k \omega_{1},\cdots,\omega_{k} k \mathbf{v}_{1},\ldots,\mathbf{v}_{k} \left(\omega_{1}\wedge\cdots\wedge\omega_{k}\right)\left(\mathbf{v}_{1},\ldots,\mathbf{v}_{k}\right)=\left|\begin{array}{ccc}
\omega_{1}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{1}\left(\mathbf{v}_{k}\right)\\
\vdots &  & \vdots\\
\omega_{k}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{k}\left(\mathbf{v}_{k}\right)
\end{array}\right|. k \omega=\omega_{1}\wedge\cdots\wedge\omega_{k} k \mathbf{v}_{1},\ldots,\mathbf{v}_{k} k \left[\begin{array}{ccc}
\omega_{1}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{1}\left(\mathbf{v}_{k}\right)\\
\vdots &  & \vdots\\
\omega_{k}\left(\mathbf{v}_{1}\right) & \cdots & \omega_{k}\left(\mathbf{v}_{k}\right)
\end{array}\right]. \intop_{M}\omega=\intop_{D}\omega\left(\frac{\partial\Phi}{\partial u^{1}},\ldots,\frac{\partial\Phi}{\partial u^{k}}\right)du^{1}\wedge\cdots\wedge du^{n} k \left[\begin{array}{ccc}
\omega_{1}\left(\frac{\partial\Phi}{\partial u^{1}}\right) & \cdots & \omega_{1}\left(\frac{\partial\Phi}{\partial u^{k}}\right)\\
\vdots &  & \vdots\\
\omega_{k}\left(\frac{\partial\Phi}{\partial u^{1}}\right) & \cdots & \omega_{k}\left(\frac{\partial\Phi}{\partial u^{k}}\right)
\end{array}\right]. k","['integration', 'intuition', 'differential-forms']"
32,The difference between $d\mu(\omega)$ and $\mu(d\omega)$,The difference between  and,d\mu(\omega) \mu(d\omega),"Let $(\Omega,\mathcal{A},\mu)$ be measure space and $f:\Omega\to \mathbb{R}$ be a integrable function. What is the difference between the following two formulas : $$ (1) \int_{\Omega} f(\omega)d\mu(\omega)  \qquad  (2) \int_{\Omega} f(\omega)\mu(d\omega)  $$ are the two formulas identical?",Let be measure space and be a integrable function. What is the difference between the following two formulas : are the two formulas identical?,"(\Omega,\mathcal{A},\mu) f:\Omega\to \mathbb{R} 
(1) \int_{\Omega} f(\omega)d\mu(\omega) 
\qquad 
(2) \int_{\Omega} f(\omega)\mu(d\omega) 
","['integration', 'measure-theory']"
33,When is a surface integral equal to double integral over projection? A verification of Stokes' Theorem. Intuition and relation to Green's Theorem.,When is a surface integral equal to double integral over projection? A verification of Stokes' Theorem. Intuition and relation to Green's Theorem.,,"I'm helping a calculus student. It's been awhile since I've done some vector calculus. I know Stokes' Theorem in terms of differential forms and manifolds with boundary, but I've forgotten much of Stokes' Theorem in the undergraduate setting. The problem is (paraphrased) Consider the vector field $F(x,y,z) = [2z-y, x+z, 3x-2y]^T$ . Let $\Sigma$ be the surface of the paraboloid defined by $z \ge 0$ and $z = 9-x^2-y^2$ . Let $\Sigma$ 's unique outward-pointing normal vector be $n$ . Verify Stokes' Theorem $$\int_C F^T dr = \int \int_{\Sigma} (\nabla \times F)^Tn dS \tag{A}$$ Some notes : I think we have $F: \mathbb R^3 \to \mathbb R^3$ (or $F: \mathbb R^3 \to \mathbb R^6$ if you think of tangent bundle), but no range is given. The domain isn't given either. It could be $\mathbb R^3 \setminus 0$ for all we know, but I think, in undergraduate, a map with 3 variables usually has domain $\mathbb R^3$ unless the problem says otherwise. I think paraboloids are surfaces, so I guess 'the surface of the paraboloid' is in a similar meaning as 'game of tennis' rather than 'colour of the phone'. Or 'the surface of the paraboloid defined ... $-y^2$ ' means 'the section of the surface, which is the paraboloid $z=9-x^2-y^2$ , defined by intersecting the paraboloid with $z \ge 0$ ' No $C$ is mentioned. I guess this is up to the students to determine. Questions Question : Is this a correct computation for the line integral? For C: The boundary of $\Sigma$ is $B = \{x^2+y^2=9\} \times \{0\}$ . Therefore, we choose $C$ to be the projection of $B$ onto $z=0$ , which is the circle $C = \{x^2+y^2=9\}$ . Equivalently, I think, we choose $C$ to be the boundary of the projection of $S$ onto $z=0$ , where the projection is, I think, the disc $D = \{x^2+y^2 \le 9 \}$ . I guess $B$ is the manifold boundary of $\Sigma$ . I mostly just pretend that I remember what is meant by 'boundary' in undergraduate. For F: For $z=0$ , $F=F(x,y,z)$ becomes the projection of $F=F(x,y,0) = [-y,x,3x-2y]^T$ onto $z=0$ which is $F=[-y,x]^T$ (I think this new $F$ is the pullback $\iota^{*}F$ for $\iota: C \to S$ ) For the bounds: I think $0$ to $2 \pi$ , where we parametrise $C$ as the image of the curve $r: [0, 2 \pi] \to \mathbb R^2$ , $r(t)=[x(t),y(t)]^T=[3\cos(t),3\sin(t)]^T$ Hence, the line integral is $$\int_C F^T dr = \int_0^{2 \pi} [-y(t),x(t)] [dx(t), dy(t)]^T$$ with $x(t) = 3 \cos(t)$ , $y(t)= 3 \sin(t)$ , $dx(t) = -3 \sin(t) dt$ , $dy(t) = 3 \cos(t)$ , $dr(t) = [dx(t),dy(t)]^T$ . Therefore, the line integral is $18 \pi$ , as computed here . Question : Is this another correct computation for the line integral? I use Green's theorem $$\int_C F^T dr = \int \int_{R} (\nabla \times F)^T[0,0,1]^T dA$$ The $F$ in the line integral is $F=[-y,x]^T$ . The $F$ on the double integral, I think, can be either $[-y,x,0]^T$ or $[-y,x,3x-2y]^T$ because, regardless, $(\nabla \times F)^T[0,0,1]^T = 2$ . The $C$ is the still the circle. I choose $R=D$ from Question (1). Hence, the line integral is equal to the double integral $$\int_C F^T dr = \int \int_{D} 2 dx dy = 2 \int \int_{D} dx dy = 2 \ \text{Area}(D)$$ Therefore, the line integral is again $18 \pi$ . Question : Which of the two computations for the surface integral are correct? For both computations: For curl: $curl F = \nabla \times F = [-3,-1,2]^T$ , as computed here . For n ( First method ): Form the explicit surface $\{z=f\}$ , where $f$ is $f: \mathbb R^2 \to \mathbb R$ , $f(x,y) = x^2+y^2-9$ . Let $\nabla f = [f_x, f_y]^T$ . Then $n$ is normalised version of either $[-f_x, -f_y, 1]^T = [-2x,-2y,1]^T$ or $[f_x, f_y, -1]^T = [2x,2y,-1]^T$ . I guess $[-f_x, -f_y, 1]^T$ is outward-pointing. For n ( Second method ): Alternatively, form the implicit surface $\{h=0\}$ , where $h$ is $h: \mathbb R^3 \to \mathbb R$ , $h(x,y,z) = x^2+y^2-9-z$ . Then $n$ is normalised version of either $\nabla h = [h_x, h_y, h_z]^T = [2x,2y,-1]^T$ or $-\nabla h$ . I guess $-\nabla h$ is outward-pointing. The first computation : For the bounds and for $dS$ : I'm actually not really sure of this. Off the top of my head , I think I kind of just project $\Sigma$ onto $z=0$ to get $D$ from Question (1). ( See Question (4). ) Therefore, I think $dS = |\nabla h| dA = |\nabla h| dx dy$ , where we use the notation ' $dS$ ' (of course in differential geometry, $dS$ and $dA$ are no longer just notation) for $\Sigma$ and ' $dA$ ' for $D$ , though I think we should have instead 'dA = du dv' instead of 'dA = dx dy' ( see the 'However, upon...' later a few bullet points down ). Hence, the surface integral does not need any of the $\nabla h$ , $\nabla f$ above and just uses $n = [0,0,1]^T$ : $$\int \int_{\Sigma} (\nabla \times F)^Tn dS = \int \int_{D} (\nabla \times F)^T[0,0,1]^T dA = \int \int_{D} (\nabla \times F)^T [0,0,1]^T dx dy$$ $$= \int \int_{D} [-3,-1,2]^T [0,0,1]^T dx dy = \int \int_{D} 2 dx dy = \int_{0}^{2 \pi} \int_{0}^{3} 2 dx dy$$ Therefore, the surface integral is $18 \pi$ , with precisely the same computation as in Question (2). The second computation : However, upon closer inspection of my undergraduate calculus textbook ( no longer off the top of my head ), what is supposed to be done, I think, is something like: $$\int \int_{\Sigma} (\nabla \times F)^Tn dS = \int \int_{P} (\nabla \times F)^Tn |\nabla h| dA$$ where $P$ is our 'parameter domain', so our $dA$ becomes not $dx dy$ but actually $du dv$ (which makes more sense actually). Our surface is given explicitly as $\Sigma = \{z=f(x,y)=9-x^2-y^2 | z \ge 0\}$ , but we don't really have an explicit parameter domain $P=\{(u,v)\}$ here to have $\Sigma$ as the image of some $r(u,v)$ , $r: P \to \mathbb R^3$ . The book says we can $x,y$ as our parameters $u,v$ , when our surface is given explicitly, so, for some parameter domain $P$ , we have $\Sigma = \{z=f(x,y)=9-x^2-y^2 | (x,y) \in P\}$ . Converting ' $z \ge 0$ ' into ' $(x,y) \in P$ ' seems to be done in taking $P=D$ , i.e. we take our parameter domain $P$ to be the projection $D$ of the surface $\Sigma$ , i.e. the surface $\Sigma$ is parametrised by its projection $D$ . Edited to add : Oh, I guess this is the 3D version of the same idea for curves: This part of a parabola $L = \{y=x^2 | y \in [0,1] \}$ is explicit and so although one might parametrise $L$ as $L = \{(x,y)=(t,t^2) | t \in [-1,1]\}$ with a new variable $t$ , one can also do $L = \{(x,y)=(x,x^2) | x \in [-1,1] =: P_L\}$ , and indeed $P_L := [-1,1]$ is both the parameter domain of the map $r: [-1,1] \to \mathbb R^2$ , $r(t) = (t,t^2)$ with image $L$ and the projection of $L$ into a dimension one lower than the dimension of $L$ . Therefore, it appears that the intuition of the idea of flattening, a.k.a. projecting, $\Sigma$ onto $z=0$ to get $D$ is justified by the fact that the flattening, a.k.a. projection, $D$ can be used to parametrise $\Sigma$ . Anyway, the surface integral should instead be computed as follows $$\int \int_{\Sigma} (\nabla \times F)^Tn dS = \int \int_{D} (\nabla \times F)^Tn |\nabla h| dA = \int \int_{D} (\nabla \times F)^T \frac{-\nabla h}{|\nabla h|} |\nabla h| dx dy$$ $$= \int \int_{D} [-3,-1,2]^T [-2x,-2y,1]^T dx dy = \int \int_{D} 6x +2y + 2 dx dy = \int_{0}^{2 \pi} \int_{0}^{3} [6x(r,\theta) +2y(r,\theta) + 2] (r dr d\theta)$$ Therefore, the surface integral is $18 \pi$ , as computed here . Question : It appears in this case we can convert a surface integral into a double integral $$\int \int_{D} (\nabla \times F)^T[0,0,1]^T dA = \int \int_{\Sigma} [-3,-1,2]^T  dS \tag{B}$$ where $D$ is the projection of $\Sigma$ onto $z=0$ (or $D$ is the region in $z=0$ that is diffeomorphic to the boundary of $\Sigma$ or something). What's going on? It appears we have the fact that for an explicit surface $\Sigma$ , we can take $P=D$ to parametrise $\Sigma$ . This fact suggests, if not outright implies, that we can compute a surface integral over $\Sigma$ as the double integral over $\Sigma$ 's projection $(P=)D$ . I know Stokes' theorem is a generalisation of not only the fundamental theorem of calculus and the fundamental theorem of line integrals but also Green's theorem and that the theme of all of these is that, whenever applicable, the integral of something depends only on the values of the 'antidervative' ( $f(x)$ for $f'(x)$ , $f(x)$ for $\nabla f(x)$ , $F(x)$ for $curl F(x)$ , etc) values at the boundary points. However, it seems that whenever Stokes' theorem is applicable for a surface integral over $\Sigma$ , we can convert the integral into a double integral over $D$ , a flattening of the $\Sigma$ , bypassing any need to obtain the 'boundary' $B$ of $\Sigma$ or 'boundary $C$ of $\Sigma$ 's projection $D$ . It actually seems more practical to compute the double integral over $D$ than the line integral over $B$ or $C$ . ( See Question (5). ) I think Stokes' theorem is actually more of something with an equation looks like $(B)$ and then $(A)$ is a corollary of $(B)$ . (You might end up proving $(A)$ and $(B)$ are equivalent forms of Stokes' theorem.) Something that would have an equation like $(B)$ might be: Under the same assumptions of Stokes' theorem in $(A)$ , you can evaluate the surface integral over $\Sigma$ into the double integral over the projection $D$ of $\Sigma$ . The fact that Green's Theorem is used in proving the Stokes' Theorem in (A) suggests there's indeed a form of Stokes' Theorem like in $(B)$ that is simply converting a surface integral into a double integral. Of course, this form $(B)$ would not be in line with the theme mentioned in the preceding paragraph. I think $$\int_C F^T dr = \int_B F^T dr = \int \int_D (curl F)^T [0,0,1]^T dA = \int \int_{\Sigma} (curl F)^T n dS$$ or something. Here, $\Sigma$ and $D$ have respective boundaries $B$ and $C$ . The projections of $\Sigma$ and $B$ are respectively $D$ and $C$ . Question : ( A follow-up to Question (4) ) If I'm right about the existence of some kind of form $(B)$ for Stokes' theorem or right about something in my bullet points in Question (4), then while I see the theoretical point of Stokes' Theorem in form $(A)$ , I don't see the practical point. What is the practical point ? I don't think form $(A)$ is practical for computing line integrals over a boundary curve $B$ of a surface $\Sigma$ because we could instead compute line integral over projection $C$ of the boundary curve $B$ of the surface $\Sigma$ , a.k.a. the boundary curve $C$ of the projection $D$ of the surface $\Sigma$ , which we would do using Green's theorem. I don't think form $(A)$ is practical for computing surface integrals over a surface $\Sigma$ because if I convert the surface integral, under form $(A)$ into a to line integral over the boundary curve $B$ , why wouldn't I then just use Green's Theorem to further convert the line integral over $B$ (into a line integral over $C$ ) into a double integral over $D$ ? Edited to add : EuYu might not have explicitly said this in the comments, but maybe my mistake here is assuming is assuming Green's Theorem is applicable. In general, $B$ and $C$ are not curves in $\mathbb R^2$ or even curves that lie on a single plane. Also, in general, $B \ne C$ , which was kinda unlike the case above, where $B = \{x^2+y^2 = 9\} \times \{0\} = \{x^2+y^2=9\} = C$ and furthermore even if $B \ne C$ but $C$ is the projection of $B$ , I don't believe the line integral is the same. A simple example (for non-closed curves and 1-dimension lower): $C=[0,1]$ , the closed (in the sense of containing $\{0,1\}$ rather than in the sense of having the same start and end points) unit interval in $\mathbb R^1$ and $B = ([0,\frac12] \times \{0\}) \cup ([\frac12,1] \times \{1\})$ as a union of intervals from different $\mathbb R^1$ 's (Actually $B$ isn't smooth or even continuous, but $B$ is at least piecewise continuous). We have $C$ as the projection of $B$ onto $\mathbb R^1$ (assuming we treat $[0,1]$ as identical to $[0,1] \times \{0\}$ ), but the line integral of the scalar constant function $f:D \to \mathbb R$ , $f(D)=\{2\}$ , where $D$ is either $B$ or $C$ is surely different over $B$ (I think it's 1.5) from the one over $C$ (I think it's 2).","I'm helping a calculus student. It's been awhile since I've done some vector calculus. I know Stokes' Theorem in terms of differential forms and manifolds with boundary, but I've forgotten much of Stokes' Theorem in the undergraduate setting. The problem is (paraphrased) Consider the vector field . Let be the surface of the paraboloid defined by and . Let 's unique outward-pointing normal vector be . Verify Stokes' Theorem Some notes : I think we have (or if you think of tangent bundle), but no range is given. The domain isn't given either. It could be for all we know, but I think, in undergraduate, a map with 3 variables usually has domain unless the problem says otherwise. I think paraboloids are surfaces, so I guess 'the surface of the paraboloid' is in a similar meaning as 'game of tennis' rather than 'colour of the phone'. Or 'the surface of the paraboloid defined ... ' means 'the section of the surface, which is the paraboloid , defined by intersecting the paraboloid with ' No is mentioned. I guess this is up to the students to determine. Questions Question : Is this a correct computation for the line integral? For C: The boundary of is . Therefore, we choose to be the projection of onto , which is the circle . Equivalently, I think, we choose to be the boundary of the projection of onto , where the projection is, I think, the disc . I guess is the manifold boundary of . I mostly just pretend that I remember what is meant by 'boundary' in undergraduate. For F: For , becomes the projection of onto which is (I think this new is the pullback for ) For the bounds: I think to , where we parametrise as the image of the curve , Hence, the line integral is with , , , , . Therefore, the line integral is , as computed here . Question : Is this another correct computation for the line integral? I use Green's theorem The in the line integral is . The on the double integral, I think, can be either or because, regardless, . The is the still the circle. I choose from Question (1). Hence, the line integral is equal to the double integral Therefore, the line integral is again . Question : Which of the two computations for the surface integral are correct? For both computations: For curl: , as computed here . For n ( First method ): Form the explicit surface , where is , . Let . Then is normalised version of either or . I guess is outward-pointing. For n ( Second method ): Alternatively, form the implicit surface , where is , . Then is normalised version of either or . I guess is outward-pointing. The first computation : For the bounds and for : I'm actually not really sure of this. Off the top of my head , I think I kind of just project onto to get from Question (1). ( See Question (4). ) Therefore, I think , where we use the notation ' ' (of course in differential geometry, and are no longer just notation) for and ' ' for , though I think we should have instead 'dA = du dv' instead of 'dA = dx dy' ( see the 'However, upon...' later a few bullet points down ). Hence, the surface integral does not need any of the , above and just uses : Therefore, the surface integral is , with precisely the same computation as in Question (2). The second computation : However, upon closer inspection of my undergraduate calculus textbook ( no longer off the top of my head ), what is supposed to be done, I think, is something like: where is our 'parameter domain', so our becomes not but actually (which makes more sense actually). Our surface is given explicitly as , but we don't really have an explicit parameter domain here to have as the image of some , . The book says we can as our parameters , when our surface is given explicitly, so, for some parameter domain , we have . Converting ' ' into ' ' seems to be done in taking , i.e. we take our parameter domain to be the projection of the surface , i.e. the surface is parametrised by its projection . Edited to add : Oh, I guess this is the 3D version of the same idea for curves: This part of a parabola is explicit and so although one might parametrise as with a new variable , one can also do , and indeed is both the parameter domain of the map , with image and the projection of into a dimension one lower than the dimension of . Therefore, it appears that the intuition of the idea of flattening, a.k.a. projecting, onto to get is justified by the fact that the flattening, a.k.a. projection, can be used to parametrise . Anyway, the surface integral should instead be computed as follows Therefore, the surface integral is , as computed here . Question : It appears in this case we can convert a surface integral into a double integral where is the projection of onto (or is the region in that is diffeomorphic to the boundary of or something). What's going on? It appears we have the fact that for an explicit surface , we can take to parametrise . This fact suggests, if not outright implies, that we can compute a surface integral over as the double integral over 's projection . I know Stokes' theorem is a generalisation of not only the fundamental theorem of calculus and the fundamental theorem of line integrals but also Green's theorem and that the theme of all of these is that, whenever applicable, the integral of something depends only on the values of the 'antidervative' ( for , for , for , etc) values at the boundary points. However, it seems that whenever Stokes' theorem is applicable for a surface integral over , we can convert the integral into a double integral over , a flattening of the , bypassing any need to obtain the 'boundary' of or 'boundary of 's projection . It actually seems more practical to compute the double integral over than the line integral over or . ( See Question (5). ) I think Stokes' theorem is actually more of something with an equation looks like and then is a corollary of . (You might end up proving and are equivalent forms of Stokes' theorem.) Something that would have an equation like might be: Under the same assumptions of Stokes' theorem in , you can evaluate the surface integral over into the double integral over the projection of . The fact that Green's Theorem is used in proving the Stokes' Theorem in (A) suggests there's indeed a form of Stokes' Theorem like in that is simply converting a surface integral into a double integral. Of course, this form would not be in line with the theme mentioned in the preceding paragraph. I think or something. Here, and have respective boundaries and . The projections of and are respectively and . Question : ( A follow-up to Question (4) ) If I'm right about the existence of some kind of form for Stokes' theorem or right about something in my bullet points in Question (4), then while I see the theoretical point of Stokes' Theorem in form , I don't see the practical point. What is the practical point ? I don't think form is practical for computing line integrals over a boundary curve of a surface because we could instead compute line integral over projection of the boundary curve of the surface , a.k.a. the boundary curve of the projection of the surface , which we would do using Green's theorem. I don't think form is practical for computing surface integrals over a surface because if I convert the surface integral, under form into a to line integral over the boundary curve , why wouldn't I then just use Green's Theorem to further convert the line integral over (into a line integral over ) into a double integral over ? Edited to add : EuYu might not have explicitly said this in the comments, but maybe my mistake here is assuming is assuming Green's Theorem is applicable. In general, and are not curves in or even curves that lie on a single plane. Also, in general, , which was kinda unlike the case above, where and furthermore even if but is the projection of , I don't believe the line integral is the same. A simple example (for non-closed curves and 1-dimension lower): , the closed (in the sense of containing rather than in the sense of having the same start and end points) unit interval in and as a union of intervals from different 's (Actually isn't smooth or even continuous, but is at least piecewise continuous). We have as the projection of onto (assuming we treat as identical to ), but the line integral of the scalar constant function , , where is either or is surely different over (I think it's 1.5) from the one over (I think it's 2).","F(x,y,z) = [2z-y, x+z, 3x-2y]^T \Sigma z \ge 0 z = 9-x^2-y^2 \Sigma n \int_C F^T dr = \int \int_{\Sigma} (\nabla \times F)^Tn dS \tag{A} F: \mathbb R^3 \to \mathbb R^3 F: \mathbb R^3 \to \mathbb R^6 \mathbb R^3 \setminus 0 \mathbb R^3 -y^2 z=9-x^2-y^2 z \ge 0 C \Sigma B = \{x^2+y^2=9\} \times \{0\} C B z=0 C = \{x^2+y^2=9\} C S z=0 D = \{x^2+y^2 \le 9 \} B \Sigma z=0 F=F(x,y,z) F=F(x,y,0) = [-y,x,3x-2y]^T z=0 F=[-y,x]^T F \iota^{*}F \iota: C \to S 0 2 \pi C r: [0, 2 \pi] \to \mathbb R^2 r(t)=[x(t),y(t)]^T=[3\cos(t),3\sin(t)]^T \int_C F^T dr = \int_0^{2 \pi} [-y(t),x(t)] [dx(t), dy(t)]^T x(t) = 3 \cos(t) y(t)= 3 \sin(t) dx(t) = -3 \sin(t) dt dy(t) = 3 \cos(t) dr(t) = [dx(t),dy(t)]^T 18 \pi \int_C F^T dr = \int \int_{R} (\nabla \times F)^T[0,0,1]^T dA F F=[-y,x]^T F [-y,x,0]^T [-y,x,3x-2y]^T (\nabla \times F)^T[0,0,1]^T = 2 C R=D \int_C F^T dr = \int \int_{D} 2 dx dy = 2 \int \int_{D} dx dy = 2 \ \text{Area}(D) 18 \pi curl F = \nabla \times F = [-3,-1,2]^T \{z=f\} f f: \mathbb R^2 \to \mathbb R f(x,y) = x^2+y^2-9 \nabla f = [f_x, f_y]^T n [-f_x, -f_y, 1]^T = [-2x,-2y,1]^T [f_x, f_y, -1]^T = [2x,2y,-1]^T [-f_x, -f_y, 1]^T \{h=0\} h h: \mathbb R^3 \to \mathbb R h(x,y,z) = x^2+y^2-9-z n \nabla h = [h_x, h_y, h_z]^T = [2x,2y,-1]^T -\nabla h -\nabla h dS \Sigma z=0 D dS = |\nabla h| dA = |\nabla h| dx dy dS dS dA \Sigma dA D \nabla h \nabla f n = [0,0,1]^T \int \int_{\Sigma} (\nabla \times F)^Tn dS = \int \int_{D} (\nabla \times F)^T[0,0,1]^T dA = \int \int_{D} (\nabla \times F)^T [0,0,1]^T dx dy = \int \int_{D} [-3,-1,2]^T [0,0,1]^T dx dy = \int \int_{D} 2 dx dy = \int_{0}^{2 \pi} \int_{0}^{3} 2 dx dy 18 \pi \int \int_{\Sigma} (\nabla \times F)^Tn dS = \int \int_{P} (\nabla \times F)^Tn |\nabla h| dA P dA dx dy du dv \Sigma = \{z=f(x,y)=9-x^2-y^2 | z \ge 0\} P=\{(u,v)\} \Sigma r(u,v) r: P \to \mathbb R^3 x,y u,v P \Sigma = \{z=f(x,y)=9-x^2-y^2 | (x,y) \in P\} z \ge 0 (x,y) \in P P=D P D \Sigma \Sigma D L = \{y=x^2 | y \in [0,1] \} L L = \{(x,y)=(t,t^2) | t \in [-1,1]\} t L = \{(x,y)=(x,x^2) | x \in [-1,1] =: P_L\} P_L := [-1,1] r: [-1,1] \to \mathbb R^2 r(t) = (t,t^2) L L L \Sigma z=0 D D \Sigma \int \int_{\Sigma} (\nabla \times F)^Tn dS = \int \int_{D} (\nabla \times F)^Tn |\nabla h| dA = \int \int_{D} (\nabla \times F)^T \frac{-\nabla h}{|\nabla h|} |\nabla h| dx dy = \int \int_{D} [-3,-1,2]^T [-2x,-2y,1]^T dx dy = \int \int_{D} 6x +2y + 2 dx dy = \int_{0}^{2 \pi} \int_{0}^{3} [6x(r,\theta) +2y(r,\theta) + 2] (r dr d\theta) 18 \pi \int \int_{D} (\nabla \times F)^T[0,0,1]^T dA = \int \int_{\Sigma} [-3,-1,2]^T  dS \tag{B} D \Sigma z=0 D z=0 \Sigma \Sigma P=D \Sigma \Sigma \Sigma (P=)D f(x) f'(x) f(x) \nabla f(x) F(x) curl F(x) \Sigma D \Sigma B \Sigma C \Sigma D D B C (B) (A) (B) (A) (B) (B) (A) \Sigma D \Sigma (B) (B) \int_C F^T dr = \int_B F^T dr = \int \int_D (curl F)^T [0,0,1]^T dA = \int \int_{\Sigma} (curl F)^T n dS \Sigma D B C \Sigma B D C (B) (A) (A) B \Sigma C B \Sigma C D \Sigma (A) \Sigma (A) B B C D B C \mathbb R^2 B \ne C B = \{x^2+y^2 = 9\} \times \{0\} = \{x^2+y^2=9\} = C B \ne C C B C=[0,1] \{0,1\} \mathbb R^1 B = ([0,\frac12] \times \{0\}) \cup ([\frac12,1] \times \{1\}) \mathbb R^1 B B C B \mathbb R^1 [0,1] [0,1] \times \{0\} f:D \to \mathbb R f(D)=\{2\} D B C B C","['integration', 'multivariable-calculus']"
34,Is Sophomore's Dream Transcendental?,Is Sophomore's Dream Transcendental?,,"Sophomore's dream is the pair of identities $$ \int_0^1 x^{-x}\,dx=\sum_{n=1}^\infty n^{-n}\\[20pt] \int_0^1x^x\,dx=\sum_{n=1}^\infty (-1)^{n+1}n^{-n} $$ Are these numbers transcendental?",Sophomore's dream is the pair of identities Are these numbers transcendental?,"
\int_0^1 x^{-x}\,dx=\sum_{n=1}^\infty n^{-n}\\[20pt]
\int_0^1x^x\,dx=\sum_{n=1}^\infty (-1)^{n+1}n^{-n}
","['integration', 'definite-integrals', 'transcendental-numbers']"
35,Finding a particular solution to a linear PDE,Finding a particular solution to a linear PDE,,"I want to solve the PDE $$\frac{\partial u}{\partial t}+x_1(x_2-x_3) \frac{\partial u}{\partial x_1}+x_2(x_3-x_1) \frac{\partial u}{\partial x_2}+x_3(x_1-x_2) \frac{\partial u}{\partial x_3}=\sum_{i=1}^3 \alpha_i \frac{\partial f}{\partial x_i}, \tag{1} $$ where $\alpha_1,\alpha_2,\alpha_3$ are constants and $f$ is the function $$f(\mathbf{x},t)= \frac{\alpha _1 \left(\wp '\left(t;g_2,g_3\right)+x_2x_3 \left(x_2-x_3\right)\right)}{2 \left(\wp \left(t;g_2,g_3\right)-\frac{1}{12} \left(x_1+x_2+x_3\right){}^2+x_2 x_3\right)}+\frac{\alpha_2 \left(\wp '\left(t;g_2,g_3\right)+x_1 x_3 \left(x_3-x_1\right)\right)}{2 \left(\wp \left(t;g_2,g_3\right)-\frac{1}{12} \left(x_1+x_2+x_3\right){}^2+x_1 x_3\right)}+\frac{\alpha _3 \left(\wp '\left(t;g_2,g_3\right)+x_1x_2 \left(x_1-x_2\right) \right)}{2 \left(\wp \left(t;g_2,g_3\right)-\frac{1}{12} \left(x_1+x_2+x_3\right){}^2+x_1 x_2\right)}+\left(\alpha _1+\alpha _2+\alpha _3\right) \left(\zeta \left(t;g_2,g_3\right)+\frac{1}{12} t \left(x_1+x_2+x_3\right){}^2\right). $$ Here $\wp$ and $\zeta$ are the Weierstraß p- and zeta- functions respectively, with the elliptic invariants $$    \begin{align}         g_2 &= \frac{(x_1+x_2+x_3)^4}{12}-2 x_1 x_2 x_3 (x_1+x_2+x_3), \\         g_3 &= -(x_1 x_2 x_3)^2+\frac{x_1 x_2 x_3 (x_1+x_2+x_3)^3}{6}-\frac{(x_1+x_2+x_3)^6}{216}.     \end{align} $$ From this point onward the invariants $g_2,g_3$ will not be shown explicitly. My attempt: First, I managed to solve the associated homogeneous PDE $$ \frac{\partial u_h}{\partial t}+x_1(x_2-x_3) \frac{\partial u_h}{\partial x_1}+x_2(x_3-x_1) \frac{\partial u_h}{\partial x_2}+x_3(x_1-x_2) \frac{\partial u_h}{\partial x_3}=0, $$ via the method of characteristics. The solution is given by $$ u_h =\Phi \left( X_1(\mathbf{x},t), X_2(\mathbf{x},t) ,X_3(\mathbf{x},t) \right) $$ where $\Phi$ is an arbitrary function, and $$X_1=\frac{12 x_1 x_2 x_3}{\left(x_1+x_2+x_3\right)^2-12 \left(\frac{\left(\wp'(t)-x_{2}x_{3} \left(x_{3}-x_{2}\right) \right)^2}{4 \left(\wp (t)+ x_{2}x_{3} -\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)^2}-\wp (t)+ x_{2} x_{3}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)}, \\ X_2 = \frac{12 x_1 x_2 x_3}{\left(x_1+x_2+x_3\right)^2-12 \left(\frac{\left(\wp'(t)-x_{1} x_{3} \left(x_{1}-x_{3}\right) \right)^2}{4 \left(\wp (t)+x_{1} x_{3}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)^2}-\wp (t)+x_{1} x_{3}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)}, \\ X_3 = \frac{12 x_1 x_2 x_3}{\left(x_1+x_2+x_3\right)^2-12 \left(\frac{\left(\wp'(t)-x_{1} x_{2} \left(x_{2}-x_{1}\right) \right)^2}{4 \left(\wp (t)+ x_{1} x_{2}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)^2}-\wp (t)+ x_{1} x_{2}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)}. $$ The final ingredient is a particular solution. Denoting the RHS in Equation (1) above by $R(\mathbf{x},t)$ , Duhamel's principle (or the method of characteristics again) suggests that a particular solution is given by $$u_p=\int_0^t R \left( \mathbf{X}(\mathbf{x},t-u),u \right) \mathrm{d} u .$$ I tried computing this with Mathematica and it didn't go well. This is probably because Mathematica seems to be unaware of the elliptic identity $\wp'^2=4 \wp^3-g_2 \wp -g_3$ . I would appreciate help with the evaluation of the integral above, or any other method of obtaining a particular solution of Equation (1). Thank you!","I want to solve the PDE where are constants and is the function Here and are the Weierstraß p- and zeta- functions respectively, with the elliptic invariants From this point onward the invariants will not be shown explicitly. My attempt: First, I managed to solve the associated homogeneous PDE via the method of characteristics. The solution is given by where is an arbitrary function, and The final ingredient is a particular solution. Denoting the RHS in Equation (1) above by , Duhamel's principle (or the method of characteristics again) suggests that a particular solution is given by I tried computing this with Mathematica and it didn't go well. This is probably because Mathematica seems to be unaware of the elliptic identity . I would appreciate help with the evaluation of the integral above, or any other method of obtaining a particular solution of Equation (1). Thank you!","\frac{\partial u}{\partial t}+x_1(x_2-x_3) \frac{\partial u}{\partial x_1}+x_2(x_3-x_1) \frac{\partial u}{\partial x_2}+x_3(x_1-x_2) \frac{\partial u}{\partial x_3}=\sum_{i=1}^3 \alpha_i \frac{\partial f}{\partial x_i}, \tag{1}  \alpha_1,\alpha_2,\alpha_3 f f(\mathbf{x},t)= \frac{\alpha _1 \left(\wp '\left(t;g_2,g_3\right)+x_2x_3 \left(x_2-x_3\right)\right)}{2 \left(\wp \left(t;g_2,g_3\right)-\frac{1}{12} \left(x_1+x_2+x_3\right){}^2+x_2 x_3\right)}+\frac{\alpha_2 \left(\wp '\left(t;g_2,g_3\right)+x_1 x_3 \left(x_3-x_1\right)\right)}{2 \left(\wp \left(t;g_2,g_3\right)-\frac{1}{12} \left(x_1+x_2+x_3\right){}^2+x_1 x_3\right)}+\frac{\alpha _3 \left(\wp '\left(t;g_2,g_3\right)+x_1x_2 \left(x_1-x_2\right) \right)}{2 \left(\wp \left(t;g_2,g_3\right)-\frac{1}{12} \left(x_1+x_2+x_3\right){}^2+x_1 x_2\right)}+\left(\alpha _1+\alpha _2+\alpha _3\right) \left(\zeta \left(t;g_2,g_3\right)+\frac{1}{12} t \left(x_1+x_2+x_3\right){}^2\right).  \wp \zeta     \begin{align}
        g_2 &= \frac{(x_1+x_2+x_3)^4}{12}-2 x_1 x_2 x_3 (x_1+x_2+x_3), \\
        g_3 &= -(x_1 x_2 x_3)^2+\frac{x_1 x_2 x_3 (x_1+x_2+x_3)^3}{6}-\frac{(x_1+x_2+x_3)^6}{216}.
    \end{align}  g_2,g_3  \frac{\partial u_h}{\partial t}+x_1(x_2-x_3) \frac{\partial u_h}{\partial x_1}+x_2(x_3-x_1) \frac{\partial u_h}{\partial x_2}+x_3(x_1-x_2) \frac{\partial u_h}{\partial x_3}=0,   u_h =\Phi \left( X_1(\mathbf{x},t), X_2(\mathbf{x},t) ,X_3(\mathbf{x},t) \right)  \Phi X_1=\frac{12 x_1 x_2 x_3}{\left(x_1+x_2+x_3\right)^2-12 \left(\frac{\left(\wp'(t)-x_{2}x_{3} \left(x_{3}-x_{2}\right) \right)^2}{4 \left(\wp (t)+ x_{2}x_{3} -\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)^2}-\wp (t)+ x_{2} x_{3}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)}, \\
X_2 = \frac{12 x_1 x_2 x_3}{\left(x_1+x_2+x_3\right)^2-12 \left(\frac{\left(\wp'(t)-x_{1} x_{3} \left(x_{1}-x_{3}\right) \right)^2}{4 \left(\wp (t)+x_{1} x_{3}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)^2}-\wp (t)+x_{1} x_{3}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)}, \\
X_3 = \frac{12 x_1 x_2 x_3}{\left(x_1+x_2+x_3\right)^2-12 \left(\frac{\left(\wp'(t)-x_{1} x_{2} \left(x_{2}-x_{1}\right) \right)^2}{4 \left(\wp (t)+ x_{1} x_{2}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)^2}-\wp (t)+ x_{1} x_{2}-\frac{1}{12} \left(x_1+x_2+x_3\right)^2\right)}.  R(\mathbf{x},t) u_p=\int_0^t R \left( \mathbf{X}(\mathbf{x},t-u),u \right) \mathrm{d} u . \wp'^2=4 \wp^3-g_2 \wp -g_3","['integration', 'ordinary-differential-equations', 'partial-differential-equations', 'closed-form', 'elliptic-functions']"
36,Evaluate $\int_0^1 \log^n(x^a)\log^m(1-x^{\color{red}{\alpha}})x^b(1-x^{\color{red}{\beta}})^t\mathrm dx$ with $\alpha\ne\beta$,Evaluate  with,\int_0^1 \log^n(x^a)\log^m(1-x^{\color{red}{\alpha}})x^b(1-x^{\color{red}{\beta}})^t\mathrm dx \alpha\ne\beta,"While dealing with algebraic integrals composited of logarithms and polynomials, I learned about using the derivatives of the Beta Function in order to evaluate them. Applying this knowledge I was able to show that $$\int_0^1 \log^n(x^a)\log^m(1-x^b)x^c(1-x^b)^t\mathrm dx~=~\frac{a^n}{b^{n+1}}\left.\frac{\partial^{n+m}}{\partial x^n\partial y^m}B(x,y)\right|^{x=\frac{c+1}{b}}_{y=t+1}\tag1$$ Which is not difficult at all since it is just the application of the substitution $u=x^b$ . The explicit evaluation gets more and more complicated while $n$ and $m$ are increasing. Furthermore I can only apply this formula for the case $n,m\in\mathbb{N}$ . Anyway now I thought about the following integral $$\int_0^1 \log^n(x^a)\log^m(1-x^{\color{red}{\alpha}})x^b(1-x^{\color{red}{\beta}})^t~dx\tag2$$ With $\alpha\ne\beta$ . For this case the simple substitution $u=x^{\alpha}$ or $u=x^{\beta}$ , respectively, does not work out since it produces a term of the type $(1-x^{\alpha/\beta})$ which does not fit within the integral representation of the Beta Function and its derivatives. Therefore, I think it is maybe not the right approach at all but I could not figure out a different way to get started with $(2)$ . IBP or a different subsititution seem pointless to me as well as a series expansion of the logarithm because of the powers $m$ and $n$ respectively. How can one tackle $(2)$ ? I would be interested in a general formula similar to $(1)$ if possible. I would be glad about an attempt concerning small values of $n$ and $m$ . My priority lies within the evaluation of the composition of $\log(1-x^{\alpha})$ and $(1-x^{\beta})^t$ therefore the powers of the logarithm are of minor matter. Thanks in advance!","While dealing with algebraic integrals composited of logarithms and polynomials, I learned about using the derivatives of the Beta Function in order to evaluate them. Applying this knowledge I was able to show that Which is not difficult at all since it is just the application of the substitution . The explicit evaluation gets more and more complicated while and are increasing. Furthermore I can only apply this formula for the case . Anyway now I thought about the following integral With . For this case the simple substitution or , respectively, does not work out since it produces a term of the type which does not fit within the integral representation of the Beta Function and its derivatives. Therefore, I think it is maybe not the right approach at all but I could not figure out a different way to get started with . IBP or a different subsititution seem pointless to me as well as a series expansion of the logarithm because of the powers and respectively. How can one tackle ? I would be interested in a general formula similar to if possible. I would be glad about an attempt concerning small values of and . My priority lies within the evaluation of the composition of and therefore the powers of the logarithm are of minor matter. Thanks in advance!","\int_0^1 \log^n(x^a)\log^m(1-x^b)x^c(1-x^b)^t\mathrm dx~=~\frac{a^n}{b^{n+1}}\left.\frac{\partial^{n+m}}{\partial x^n\partial y^m}B(x,y)\right|^{x=\frac{c+1}{b}}_{y=t+1}\tag1 u=x^b n m n,m\in\mathbb{N} \int_0^1 \log^n(x^a)\log^m(1-x^{\color{red}{\alpha}})x^b(1-x^{\color{red}{\beta}})^t~dx\tag2 \alpha\ne\beta u=x^{\alpha} u=x^{\beta} (1-x^{\alpha/\beta}) (2) m n (2) (1) n m \log(1-x^{\alpha}) (1-x^{\beta})^t","['integration', 'definite-integrals', 'logarithms', 'closed-form', 'beta-function']"
37,High dimensional integral of exponentials,High dimensional integral of exponentials,,"I am attempting to marginalize a probability density function. But I got stuck on the following integral $$ \int_{-\infty}^\infty\cdots\int_{-\infty}^\infty \frac{\exp(\pmb x^T A\pmb z)} {|\exp(A\pmb z )|_1^{n+|\pmb{x}|_1}} \mathrm dz_1\cdots\mathrm dz_m $$ where $\pmb x, \pmb z \in\mathbb R^n$ , $x_i\ge 0$ with large $n,m \in\mathbb N$ . $|\cdot|_1$ is the sum of the components e.g. $|\pmb x|_1 = \sum_{i=1}^nx_i$ . $A\in\mathbb R^{n\times n}$ is orthogonal and the first $m$ coloums are also orthogonal to $(1,\dots,1)$ . I already stripped away some constants. My goal is a fast evaluation of the integral on the remaining dimensions $z_{m+1},\dots,z_n$ . Can anybody solve this? If there is no explicit form of the integral, a good approximation would also be very helpful!","I am attempting to marginalize a probability density function. But I got stuck on the following integral where , with large . is the sum of the components e.g. . is orthogonal and the first coloums are also orthogonal to . I already stripped away some constants. My goal is a fast evaluation of the integral on the remaining dimensions . Can anybody solve this? If there is no explicit form of the integral, a good approximation would also be very helpful!","
\int_{-\infty}^\infty\cdots\int_{-\infty}^\infty
\frac{\exp(\pmb x^T A\pmb z)}
{|\exp(A\pmb z )|_1^{n+|\pmb{x}|_1}}
\mathrm dz_1\cdots\mathrm dz_m
 \pmb x, \pmb z \in\mathbb R^n x_i\ge 0 n,m \in\mathbb N |\cdot|_1 |\pmb x|_1 = \sum_{i=1}^nx_i A\in\mathbb R^{n\times n} m (1,\dots,1) z_{m+1},\dots,z_n","['integration', 'definite-integrals', 'exponential-function', 'approximation']"
38,Deconvolution question,Deconvolution question,,"Suppose $a,b,x:\mathbb{R}\mapsto\mathbb{R}$ are three functions of which $a$ and $b$ are known and $x$ is unknown. Suppose they are related by the integral equation. $$\int_{-\infty}^\infty a(t-s)\,x(s)\,ds = b(t)~,\forall\ t\in\mathbb{R}~.$$ Assume $a(t)$ is a symmetric function ($a(t) = a(-t)$) so that it has a Fourier transform $A(\omega)$ that is real. Assume also that $A(\omega)$ is positive everywhere. If the Fourier transform of $b(t)$ is $B(\omega),$ then we can solve for the Fourier transform of $x(t)$, as $$A(\omega)X(\omega) = B(\omega)~,$$ from which we can write out $x(t)$ explicitly by using the inverse Fourier transform. Is there such an explicit solution for $x$ when $a:[-1,1]\mapsto\mathbb{R}$ is a symmetric function, $b,x:[0,1]\mapsto\mathbb{R}$ and are related by $$\int_{0}^1 a(t-s)\,x(s)\,ds = b(t)~,\forall\ t\in [0,1]~.$$ You can impose any regularity condition on $a(t)$ if that helps in obtaining a solution.","Suppose $a,b,x:\mathbb{R}\mapsto\mathbb{R}$ are three functions of which $a$ and $b$ are known and $x$ is unknown. Suppose they are related by the integral equation. $$\int_{-\infty}^\infty a(t-s)\,x(s)\,ds = b(t)~,\forall\ t\in\mathbb{R}~.$$ Assume $a(t)$ is a symmetric function ($a(t) = a(-t)$) so that it has a Fourier transform $A(\omega)$ that is real. Assume also that $A(\omega)$ is positive everywhere. If the Fourier transform of $b(t)$ is $B(\omega),$ then we can solve for the Fourier transform of $x(t)$, as $$A(\omega)X(\omega) = B(\omega)~,$$ from which we can write out $x(t)$ explicitly by using the inverse Fourier transform. Is there such an explicit solution for $x$ when $a:[-1,1]\mapsto\mathbb{R}$ is a symmetric function, $b,x:[0,1]\mapsto\mathbb{R}$ and are related by $$\int_{0}^1 a(t-s)\,x(s)\,ds = b(t)~,\forall\ t\in [0,1]~.$$ You can impose any regularity condition on $a(t)$ if that helps in obtaining a solution.",,"['integration', 'fourier-analysis']"
39,Integral $\int_0^{\infty} \frac{e^{-x^2}}{a+b\cos{x}}dx$,Integral,\int_0^{\infty} \frac{e^{-x^2}}{a+b\cos{x}}dx,"Hello there I am trying to solve for $a > b$:  $$I=\int_0^{\infty} \frac{e^{-x^2}}{a+b\cos{x}}dx$$  My thought was to expand into fourier series $$g(t)=\frac{1}{a+b\cos t}$$ Since g(t) has the period $T=2\pi\, $ we can rewrite $$g(t)=\frac{a_0}{2}+\sum_{n=1}^{\infty}(a_n\cos{nt}+b_n\sin{nt})$$ $$a_0=\frac{1}{\pi}\int_0^{2\pi}\frac{1}{a+b\cos t}dt$$ $$a_n=\frac{1}{\pi}\int_0^{2\pi}\frac{\cos(nt)}{a+b\cos t}dt$$$$b_n=\frac{1}{\pi}\int_0^{2\pi}\frac{\sin(nt)}{a+b\cos t}dt$$ $$X=a_n+ib_n=\frac{1}{\pi}\int_0^{2\pi}\frac{e^{int} }{a+b\cos t}dt$$ we let $$e^{it}=z \rightarrow dt=\frac{dz}{iz}\, ; |z|=1$$ And we can write due to Euler's formula $\cos t=\frac{z^2+1}{2z}$  $$X=\frac{2}{i\pi}\oint_{|z|=1} \frac{z^n}{bz^2+2az+b}dz$$ Inside the circle $|z|=1\,$ the integrand function has only the pole $z_1=\frac{\sqrt{a^2-b^2}-a}{b}\,$ Thus our residue is $$\text{Res}(f,z_1)=\lim_{z\to z_1} \frac{z^n}{2bz+2a}=\frac{1}{2}\frac{1}{\sqrt{a^2-b^2}}\left(\frac{\sqrt{a^2-b^2}-a}{b}\right)^n$$ $$X=\frac{2}{\sqrt{a^2-b^2}}\left(\frac{\sqrt{a^2-b^2}-a}{b}\right)^n$$ Thus $a_n=X \, , \, b_n=0$ and finally $$g(t)=\frac{1}{\sqrt{a^2-b^2}}+\frac{2}{\sqrt{a^2-b^2}}\sum_{n=1}^{\infty}\left(\frac{\sqrt{a^2-b^2}-a}{b}\right)^n\cos{nt}$$ Plugging those into the original integral and making use of the gaussian integral for example see here: $\int_{-\infty}^{+\infty} e^{-x^2} dx$ with complex analysis also $$\int_{0}^{\infty} e^{-x^2}\cos(nx)dx=\Re\frac{1}{2}\int_{-\infty}^{\infty} e^{-x^2+nix}dx= \Re\frac{1}{2}\int_{-\infty}^{\infty} e^{-(x-\frac{ni}{2})^2-\frac{n^2}{4}}dx=\frac{\sqrt{\pi}}{2}e^{\frac{-n^2}{4}}$$ and denoting $w=\frac{\sqrt{a^2-b^2}-a}{b}$ will yield to: $$I=\frac{\sqrt{\pi}}{\sqrt{a^2-b^2}}\left(\frac{1}{2}+\sum_{n=1}^{\infty}w^ne^{-\frac{n^2}{4}}\right)$$ Now I never encountered the latter sum, is there already a known closed form or can you help me find one? Also have I done any mistakes?","Hello there I am trying to solve for $a > b$:  $$I=\int_0^{\infty} \frac{e^{-x^2}}{a+b\cos{x}}dx$$  My thought was to expand into fourier series $$g(t)=\frac{1}{a+b\cos t}$$ Since g(t) has the period $T=2\pi\, $ we can rewrite $$g(t)=\frac{a_0}{2}+\sum_{n=1}^{\infty}(a_n\cos{nt}+b_n\sin{nt})$$ $$a_0=\frac{1}{\pi}\int_0^{2\pi}\frac{1}{a+b\cos t}dt$$ $$a_n=\frac{1}{\pi}\int_0^{2\pi}\frac{\cos(nt)}{a+b\cos t}dt$$$$b_n=\frac{1}{\pi}\int_0^{2\pi}\frac{\sin(nt)}{a+b\cos t}dt$$ $$X=a_n+ib_n=\frac{1}{\pi}\int_0^{2\pi}\frac{e^{int} }{a+b\cos t}dt$$ we let $$e^{it}=z \rightarrow dt=\frac{dz}{iz}\, ; |z|=1$$ And we can write due to Euler's formula $\cos t=\frac{z^2+1}{2z}$  $$X=\frac{2}{i\pi}\oint_{|z|=1} \frac{z^n}{bz^2+2az+b}dz$$ Inside the circle $|z|=1\,$ the integrand function has only the pole $z_1=\frac{\sqrt{a^2-b^2}-a}{b}\,$ Thus our residue is $$\text{Res}(f,z_1)=\lim_{z\to z_1} \frac{z^n}{2bz+2a}=\frac{1}{2}\frac{1}{\sqrt{a^2-b^2}}\left(\frac{\sqrt{a^2-b^2}-a}{b}\right)^n$$ $$X=\frac{2}{\sqrt{a^2-b^2}}\left(\frac{\sqrt{a^2-b^2}-a}{b}\right)^n$$ Thus $a_n=X \, , \, b_n=0$ and finally $$g(t)=\frac{1}{\sqrt{a^2-b^2}}+\frac{2}{\sqrt{a^2-b^2}}\sum_{n=1}^{\infty}\left(\frac{\sqrt{a^2-b^2}-a}{b}\right)^n\cos{nt}$$ Plugging those into the original integral and making use of the gaussian integral for example see here: $\int_{-\infty}^{+\infty} e^{-x^2} dx$ with complex analysis also $$\int_{0}^{\infty} e^{-x^2}\cos(nx)dx=\Re\frac{1}{2}\int_{-\infty}^{\infty} e^{-x^2+nix}dx= \Re\frac{1}{2}\int_{-\infty}^{\infty} e^{-(x-\frac{ni}{2})^2-\frac{n^2}{4}}dx=\frac{\sqrt{\pi}}{2}e^{\frac{-n^2}{4}}$$ and denoting $w=\frac{\sqrt{a^2-b^2}-a}{b}$ will yield to: $$I=\frac{\sqrt{\pi}}{\sqrt{a^2-b^2}}\left(\frac{1}{2}+\sum_{n=1}^{\infty}w^ne^{-\frac{n^2}{4}}\right)$$ Now I never encountered the latter sum, is there already a known closed form or can you help me find one? Also have I done any mistakes?",,"['integration', 'closed-form']"
40,Subtlety about an integral and its primitive,Subtlety about an integral and its primitive,,"I stumbled over a paper mentioning another paper, which gives an example of a subtle situation in integral theory (the example should be given in Jeffrey, D.J. ; Rich, A.D.: The Evaluation of Trigonome- tric Integrals Avoiding Spurious Discontinuities. In: ACM   Transactions on Mathematical Software 20 (1994), Nr. 1, S. 124–135) where I don't have any access to.). The integral is given as: $$ I:=\int \frac{3}{5-4\,\cos(x)} \mathrm{d} x $$ Simple symbolical calculation (and ignoring the poles in $\mathbb{R}$) yields: $$ I = 2 \, \arctan\left( 3 \, \tan\left(\frac{x}{2} \right) \right) + C.$$ Ploting this with maple gives: The subtlety of this example is that the $\tan\left(\frac{x}{2} \right)$ substitution creates singularities, though the integrant itself is perfectly continuous. Therefore, we'd expect at least a continuous function as an antiderivative in theory. As I am aware that I need to introduce local constants for getting all possible antiderivates locally as with the integral of $\frac{1}{x}$  in $\mathbb{R}_{-}$ and $\mathbb{R}_{+}$, I am convinced that I can get a continuous function. My question now is: Assume that I have chosen all the contants properly, so that I ""glue"" the parts together in a continuous or even continuously differentialbe way. Is there any way to write down the formula for the antiderivate avoiding infinite many cases? EDIT: As the answer is already given as a comment, I might ask if there is a generic way how to avoid these troubles where choosing different local constants can be omitted? It seems as if one needs to choose different brances of the tangent at different places. Can this be done symbolically and automatically without worrying at all?","I stumbled over a paper mentioning another paper, which gives an example of a subtle situation in integral theory (the example should be given in Jeffrey, D.J. ; Rich, A.D.: The Evaluation of Trigonome- tric Integrals Avoiding Spurious Discontinuities. In: ACM   Transactions on Mathematical Software 20 (1994), Nr. 1, S. 124–135) where I don't have any access to.). The integral is given as: $$ I:=\int \frac{3}{5-4\,\cos(x)} \mathrm{d} x $$ Simple symbolical calculation (and ignoring the poles in $\mathbb{R}$) yields: $$ I = 2 \, \arctan\left( 3 \, \tan\left(\frac{x}{2} \right) \right) + C.$$ Ploting this with maple gives: The subtlety of this example is that the $\tan\left(\frac{x}{2} \right)$ substitution creates singularities, though the integrant itself is perfectly continuous. Therefore, we'd expect at least a continuous function as an antiderivative in theory. As I am aware that I need to introduce local constants for getting all possible antiderivates locally as with the integral of $\frac{1}{x}$  in $\mathbb{R}_{-}$ and $\mathbb{R}_{+}$, I am convinced that I can get a continuous function. My question now is: Assume that I have chosen all the contants properly, so that I ""glue"" the parts together in a continuous or even continuously differentialbe way. Is there any way to write down the formula for the antiderivate avoiding infinite many cases? EDIT: As the answer is already given as a comment, I might ask if there is a generic way how to avoid these troubles where choosing different local constants can be omitted? It seems as if one needs to choose different brances of the tangent at different places. Can this be done symbolically and automatically without worrying at all?",,"['integration', 'continuity', 'trigonometric-integrals']"
41,Proving that $\int_0^{\infty} \frac{(3-\sqrt{8}\cos(\log(2)t))Z(t)^2}{t^2+\frac{1}{4}}~dt=\pi \log(2)$ where $Z(t)$ is the Riemann-Siegel Z-function.,Proving that  where  is the Riemann-Siegel Z-function.,\int_0^{\infty} \frac{(3-\sqrt{8}\cos(\log(2)t))Z(t)^2}{t^2+\frac{1}{4}}~dt=\pi \log(2) Z(t),"While looking at articles relevant to the Riemann Hypothesis, I've seen that the Riemann-Siegel Z-function $Z(t)$ is frequently used to study the Riemann zeta function along the critical line. Therefore, I decided to go on the Wolfram Functions site, and look up some interesting properties of that function. One of them I especially found interesting was this one ( Formula 10.04.21.0001.01 ): $$\int_0^{\infty} \frac{(3-\sqrt{8}\cos(\log(2)t))Z(t)^2}{t^2+\frac{1}{4}}~dt=\pi \log(2) \tag{1}$$ However, the site does not provide a proof of this result. Therefore, this leads me to my current question: Question: How can we prove $(1)$ ? In case one does not know the definition of $Z(t)$ , it can be defined as: $$Z(t)=e^{i\theta(t)}\zeta\left(\frac{1}{2}+it\right),$$ where $\theta(\cdot )$ and $\zeta(\cdot )$ are the Riemann-Siegel Theta and Riemann Zeta functions respectively. One definition of $\theta(t)$ is: $$\theta(t) = \arg \left(\Gamma\left(\frac{2it+1}{4}\right)\right)- \frac{\log \pi}{2} t,$$ where $\Gamma(\cdot )$ is the Gamma function . My first thought was to use the fact that the integrand is even, then consider a contour $C$ going along the real line from $-a$ to $a$ then going counter-clockwise along a semicircle centered at $0$ going from $a$ to $-a$ . $$\int_0^{\infty} \frac{(3-\sqrt{8}\cos(\log(2)t))Z(t)^2}{t^2+\frac{1}{4}}~dt=\frac{1}{2}\cdot PV\int_{-\infty}^{\infty} \frac{(3-\sqrt{8}\cos(\log(2)t))Z(t)^2}{t^2+\frac{1}{4}}~dt \tag{2}$$ Hence, we must consider: $$\lim_{a \to \infty}\int_{C} f(z)~dz=\lim_{a\to \infty}\left(\int_{-a}^a f(z)~dz+\int_{\text{arc}} f(z)~dz\right),$$ where $f(z)=\dfrac{(3-\sqrt{8}\cos(\log(2)z))Z(z)^2}{z^2+\frac{1}{4}}$ . I found two poles at $z=\pm \frac{i}{2}$ , but only $z=\frac{i}{2}$ is bounded by $C$ . The residue at that point can be evaluated easily since we know it is a simple pole: $$\operatorname*{Res}_{z=\frac{i}{2}} \dfrac{(3-\sqrt{8}\cos(\log(2)z))Z(z)^2}{z^2+\frac{1}{4}}=\lim_{z\to \frac{i}{2}} \frac{(3-\sqrt{8}\cos(\log(2)z))Z(z)^2}{z+\frac{i}{2}}=-\frac{1}{2}i\log(2)$$ I evaluated the above limit, then confirmed it using Wolfram|Alpha . Multiplying by $2\pi i$ gives $\pi \log(2)$ . However, notice that my answer seems to be off by a factor of $\frac{1}{2}$ due to equation $(2)$ . Hence, I suspect that either $\lim\limits_{a \to \infty} \int_{\text{arc}}f(z)~dz\neq 0$ is the issue here, or that I missed one of the conditions necessary to apply the residue theorem. Note: An answer to my question may consist of both real and complex methods.","While looking at articles relevant to the Riemann Hypothesis, I've seen that the Riemann-Siegel Z-function is frequently used to study the Riemann zeta function along the critical line. Therefore, I decided to go on the Wolfram Functions site, and look up some interesting properties of that function. One of them I especially found interesting was this one ( Formula 10.04.21.0001.01 ): However, the site does not provide a proof of this result. Therefore, this leads me to my current question: Question: How can we prove ? In case one does not know the definition of , it can be defined as: where and are the Riemann-Siegel Theta and Riemann Zeta functions respectively. One definition of is: where is the Gamma function . My first thought was to use the fact that the integrand is even, then consider a contour going along the real line from to then going counter-clockwise along a semicircle centered at going from to . Hence, we must consider: where . I found two poles at , but only is bounded by . The residue at that point can be evaluated easily since we know it is a simple pole: I evaluated the above limit, then confirmed it using Wolfram|Alpha . Multiplying by gives . However, notice that my answer seems to be off by a factor of due to equation . Hence, I suspect that either is the issue here, or that I missed one of the conditions necessary to apply the residue theorem. Note: An answer to my question may consist of both real and complex methods.","Z(t) \int_0^{\infty} \frac{(3-\sqrt{8}\cos(\log(2)t))Z(t)^2}{t^2+\frac{1}{4}}~dt=\pi \log(2) \tag{1} (1) Z(t) Z(t)=e^{i\theta(t)}\zeta\left(\frac{1}{2}+it\right), \theta(\cdot ) \zeta(\cdot ) \theta(t) \theta(t) = \arg \left(\Gamma\left(\frac{2it+1}{4}\right)\right)- \frac{\log \pi}{2} t, \Gamma(\cdot ) C -a a 0 a -a \int_0^{\infty} \frac{(3-\sqrt{8}\cos(\log(2)t))Z(t)^2}{t^2+\frac{1}{4}}~dt=\frac{1}{2}\cdot PV\int_{-\infty}^{\infty} \frac{(3-\sqrt{8}\cos(\log(2)t))Z(t)^2}{t^2+\frac{1}{4}}~dt \tag{2} \lim_{a \to \infty}\int_{C} f(z)~dz=\lim_{a\to \infty}\left(\int_{-a}^a f(z)~dz+\int_{\text{arc}} f(z)~dz\right), f(z)=\dfrac{(3-\sqrt{8}\cos(\log(2)z))Z(z)^2}{z^2+\frac{1}{4}} z=\pm \frac{i}{2} z=\frac{i}{2} C \operatorname*{Res}_{z=\frac{i}{2}} \dfrac{(3-\sqrt{8}\cos(\log(2)z))Z(z)^2}{z^2+\frac{1}{4}}=\lim_{z\to \frac{i}{2}} \frac{(3-\sqrt{8}\cos(\log(2)z))Z(z)^2}{z+\frac{i}{2}}=-\frac{1}{2}i\log(2) 2\pi i \pi \log(2) \frac{1}{2} (2) \lim\limits_{a \to \infty} \int_{\text{arc}}f(z)~dz\neq 0","['integration', 'definite-integrals', 'improper-integrals', 'contour-integration', 'zeta-functions']"
42,Integrating a sum of delta functions?,Integrating a sum of delta functions?,,"I know that the ""hand-wavy"" definition of the $\delta (x)$ function is $$   \delta(x) =       \begin{cases}        \infty &\quad\ x=0 \\        0 &\quad\text{otherwise}      \end{cases} $$ and the more rigorous definition is that it's the limit of a sequence of functions $f_n$ for which $f_n(x) \rightarrow 0$ for all $x \neq 0$, and $f_n \rightarrow \infty$ for $x=0$, and (edited to add) $\int f_n = 1$ for all $n$. From this perspective, I see why the integral should be one, because the integral of all of the $f_n$ is equal to $1$. Now, suppose I want to construct a function $f(x,y)$ in the plane for which $$   \nabla ^2f(x,y) =       \begin{cases}        a &\quad\ (x,y) \in D \\        0 &\quad\text{otherwise}      \end{cases} $$ where $D$ is some simply connected region. I can definitely solve $\nabla ^2f(x,y) = \delta(\|(x,y) - (x_0,y_0)\|)$ for any point $(x_0,y_0)$. This is just done by using the fundamental solution $$f(x,y) = \frac{-1}{2\pi} \ln\left( \|(x,y)-(x_0,y_0)\|\right)$$ My question is whether I can do the following: Because I want the Laplacian of $f$ to be as described above, can I write $$ f(x,y) = a \int_D \frac{-1}{2\pi} \ln\left( \|(x,y)-(x_0,y_0)\|\right) \,dA \quad ?$$ where $dA$ refers to integration with respect to $(x_0,y_0)$ over the area of $D$. My confusion is coming from the fact that: The Laplacian of $f$ will be the Laplacian of a sum of (infinitely) many $\delta$ functions, so intuition tells me it should be infinite; on the other hand, integrating a $\delta$ function gives $1$, so the factor of $a$ in front of the integral should give the desired result, no?","I know that the ""hand-wavy"" definition of the $\delta (x)$ function is $$   \delta(x) =       \begin{cases}        \infty &\quad\ x=0 \\        0 &\quad\text{otherwise}      \end{cases} $$ and the more rigorous definition is that it's the limit of a sequence of functions $f_n$ for which $f_n(x) \rightarrow 0$ for all $x \neq 0$, and $f_n \rightarrow \infty$ for $x=0$, and (edited to add) $\int f_n = 1$ for all $n$. From this perspective, I see why the integral should be one, because the integral of all of the $f_n$ is equal to $1$. Now, suppose I want to construct a function $f(x,y)$ in the plane for which $$   \nabla ^2f(x,y) =       \begin{cases}        a &\quad\ (x,y) \in D \\        0 &\quad\text{otherwise}      \end{cases} $$ where $D$ is some simply connected region. I can definitely solve $\nabla ^2f(x,y) = \delta(\|(x,y) - (x_0,y_0)\|)$ for any point $(x_0,y_0)$. This is just done by using the fundamental solution $$f(x,y) = \frac{-1}{2\pi} \ln\left( \|(x,y)-(x_0,y_0)\|\right)$$ My question is whether I can do the following: Because I want the Laplacian of $f$ to be as described above, can I write $$ f(x,y) = a \int_D \frac{-1}{2\pi} \ln\left( \|(x,y)-(x_0,y_0)\|\right) \,dA \quad ?$$ where $dA$ refers to integration with respect to $(x_0,y_0)$ over the area of $D$. My confusion is coming from the fact that: The Laplacian of $f$ will be the Laplacian of a sum of (infinitely) many $\delta$ functions, so intuition tells me it should be infinite; on the other hand, integrating a $\delta$ function gives $1$, so the factor of $a$ in front of the integral should give the desired result, no?",,"['integration', 'partial-differential-equations', 'boundary-value-problem', 'laplacian', 'greens-function']"
43,"Reference request for Grothendieck's work on ""Integration with values in a topological group""","Reference request for Grothendieck's work on ""Integration with values in a topological group""",,"Recently I was reading the available part of the second part of W. Scharlau's book on Alexandre Grothendieck (see here ). There I found, An anecdote survives about Grothendieck's arrival in Nancy: the story of his rude reception at the hands of Dieudonné when, on their very first contact, he showed him a dense handwritten manuscript on ""generalized integrals"". He had already mentioned this work in writing to Dieudonné, and had received a warm and friendly response in which Dieudonné praised his ""ardor for mathematics"". But Dieudonné's initial receptiveness did not outlast a first look at the actual text. Those who recall this incident (or rather, who recall Dieudonné's telling them about it) claim that Dieudonné gave Grothendieck a   rather sharp dressing down, finding that the work displayed a reprehensible tendency to gratuitous generality. Later it is also mentioned that (as Schwartz recounts in his autobiography), He first gave Dieudonné an article of fifty or so pages, on ""Integration with values in a topological group"". It was correct, but absolutely uninteresting. Dieudonné, with the (always temporary) aggressiveness he was capable of, gave him a memorable scolding, claiming that one shouldn't work that way, generalizing just for the pleasure of generalizing. The problem one considered had to be difficult, and applicable to the rest of mathematics   (or other sciences); his results would never be useful to anyone for anything. Questions. Does anyone know how Grothendieck treated the problem of integration with values in a topological group which he submitted to Dieudonné (I can't seem to find anything on internet)? Why was Grothendieck's work on ""Integration with values in a topological group"" has been referred to as ""would never be useful to anyone for anything"" by Dieudonné? Has there been any future research on this topic? Where can I find (if possible at all) Grothendieck's original paper in the internet?","Recently I was reading the available part of the second part of W. Scharlau's book on Alexandre Grothendieck (see here ). There I found, An anecdote survives about Grothendieck's arrival in Nancy: the story of his rude reception at the hands of Dieudonné when, on their very first contact, he showed him a dense handwritten manuscript on ""generalized integrals"". He had already mentioned this work in writing to Dieudonné, and had received a warm and friendly response in which Dieudonné praised his ""ardor for mathematics"". But Dieudonné's initial receptiveness did not outlast a first look at the actual text. Those who recall this incident (or rather, who recall Dieudonné's telling them about it) claim that Dieudonné gave Grothendieck a   rather sharp dressing down, finding that the work displayed a reprehensible tendency to gratuitous generality. Later it is also mentioned that (as Schwartz recounts in his autobiography), He first gave Dieudonné an article of fifty or so pages, on ""Integration with values in a topological group"". It was correct, but absolutely uninteresting. Dieudonné, with the (always temporary) aggressiveness he was capable of, gave him a memorable scolding, claiming that one shouldn't work that way, generalizing just for the pleasure of generalizing. The problem one considered had to be difficult, and applicable to the rest of mathematics   (or other sciences); his results would never be useful to anyone for anything. Questions. Does anyone know how Grothendieck treated the problem of integration with values in a topological group which he submitted to Dieudonné (I can't seem to find anything on internet)? Why was Grothendieck's work on ""Integration with values in a topological group"" has been referred to as ""would never be useful to anyone for anything"" by Dieudonné? Has there been any future research on this topic? Where can I find (if possible at all) Grothendieck's original paper in the internet?",,"['integration', 'reference-request']"
44,Solving two electron integral,Solving two electron integral,,"During one of my practical courses we had to do the Hartree-Fock-method ""by hand"". Part of that was to calculate the occurring two electron integrals. With $$\chi_i(r) = 2 \cdot \alpha_i^{3/2} e^{-\alpha_i r} Y_0^0$$ we were given the following equation: $$\iint \frac{\chi_m(r_1)~\chi_n(r_1)~\chi_t(r_2)~\chi_u(r_2)}{|r_1-r_2|}~\mathrm d r_2 \mathrm d r_1$$ $$= 16\pi^2\int_0^{\infty}\int_0^{r_1} \chi_m(r_1)~\chi_n(r_1)~\chi_t(r_2)~\chi_u(r_2)~r_1~r_2^2~\mathrm d r_2 \mathrm d r_1$$ $$+ 16\pi^2\int_0^{\infty}\int_{r_1}^{\infty} \chi_m(r_1)~\chi_n(r_1)~\chi_t(r_2)~\chi_u(r_2)~r_1^2~r_2~\mathrm d r_2 \mathrm d r_1$$ What are the steps to come up with this? (At least I know where the $16\pi^2$ come from $\ldots$)","During one of my practical courses we had to do the Hartree-Fock-method ""by hand"". Part of that was to calculate the occurring two electron integrals. With $$\chi_i(r) = 2 \cdot \alpha_i^{3/2} e^{-\alpha_i r} Y_0^0$$ we were given the following equation: $$\iint \frac{\chi_m(r_1)~\chi_n(r_1)~\chi_t(r_2)~\chi_u(r_2)}{|r_1-r_2|}~\mathrm d r_2 \mathrm d r_1$$ $$= 16\pi^2\int_0^{\infty}\int_0^{r_1} \chi_m(r_1)~\chi_n(r_1)~\chi_t(r_2)~\chi_u(r_2)~r_1~r_2^2~\mathrm d r_2 \mathrm d r_1$$ $$+ 16\pi^2\int_0^{\infty}\int_{r_1}^{\infty} \chi_m(r_1)~\chi_n(r_1)~\chi_t(r_2)~\chi_u(r_2)~r_1^2~r_2~\mathrm d r_2 \mathrm d r_1$$ What are the steps to come up with this? (At least I know where the $16\pi^2$ come from $\ldots$)",,"['integration', 'chemistry']"
45,"Prove: $\frac{p}{2\pi}\int_{-\infty}^{+\infty}\frac{\sin xt}{t\cdot \sin\frac12pt}\sin([\frac xp]+\frac12) pt \, \mathrm dt=\cdots$",Prove:,"\frac{p}{2\pi}\int_{-\infty}^{+\infty}\frac{\sin xt}{t\cdot \sin\frac12pt}\sin([\frac xp]+\frac12) pt \, \mathrm dt=\cdots","Suppose $p>0$, define that $$ g(x)=\begin{cases} p\left\lfloor\frac xp\right\rfloor+\frac p2,x\geqslant0\\\\-g(-x), x<0\end{cases}$$ Prove  for all $x$, $$ \frac{p}{2\pi}\int_{-\infty}^{+\infty}\sum_{n=-\lfloor x/p\rfloor}^{\lfloor x/p\rfloor}\frac{\sin ((n+\frac12)pt)}{\sin (\frac12pt)}\cdot\frac{\sin (xt)}{t} \, \mathrm dt=\frac12[g(x^+)+g(x^-)].$$ First, $$\sum_{n=-\lfloor x/p\rfloor}^{\lfloor x/p\rfloor}\frac{\sin ((n+\frac12)pt)}{\sin (\frac12pt)}\cdot\frac{\sin (xt)}{t}=\frac{\sin (xt)}{t\cdot  \sin(\frac12pt)} \sin\left(\left\lfloor \frac xp\right\rfloor+\frac12\right) pt ,$$ I just simplify it, then get $$\frac{p}{2\pi}\int_{-\infty}^{+\infty}\frac{\sin (xt)}{t\cdot \sin(\frac12pt)} \sin\left(\left(\left\lfloor \frac xp\right\rfloor+\frac12\right) pt\right) \, \mathrm dt=\frac12[g(x^+)+g(x^-)].$$ However, I don't know how to continue it. I guess that it may be related to $fourier.$ Can someone help me out? Sincerely thanks.","Suppose $p>0$, define that $$ g(x)=\begin{cases} p\left\lfloor\frac xp\right\rfloor+\frac p2,x\geqslant0\\\\-g(-x), x<0\end{cases}$$ Prove  for all $x$, $$ \frac{p}{2\pi}\int_{-\infty}^{+\infty}\sum_{n=-\lfloor x/p\rfloor}^{\lfloor x/p\rfloor}\frac{\sin ((n+\frac12)pt)}{\sin (\frac12pt)}\cdot\frac{\sin (xt)}{t} \, \mathrm dt=\frac12[g(x^+)+g(x^-)].$$ First, $$\sum_{n=-\lfloor x/p\rfloor}^{\lfloor x/p\rfloor}\frac{\sin ((n+\frac12)pt)}{\sin (\frac12pt)}\cdot\frac{\sin (xt)}{t}=\frac{\sin (xt)}{t\cdot  \sin(\frac12pt)} \sin\left(\left\lfloor \frac xp\right\rfloor+\frac12\right) pt ,$$ I just simplify it, then get $$\frac{p}{2\pi}\int_{-\infty}^{+\infty}\frac{\sin (xt)}{t\cdot \sin(\frac12pt)} \sin\left(\left(\left\lfloor \frac xp\right\rfloor+\frac12\right) pt\right) \, \mathrm dt=\frac12[g(x^+)+g(x^-)].$$ However, I don't know how to continue it. I guess that it may be related to $fourier.$ Can someone help me out? Sincerely thanks.",,"['integration', 'analysis', 'limits']"
46,Calculation of $\int_{0}^1 \frac{\sin(\ln^4(1-x))}{x}~dx$,Calculation of,\int_{0}^1 \frac{\sin(\ln^4(1-x))}{x}~dx,"$$I=\int_0^1 \frac{\sin(\ln^4 (1-x))}{x}dx$$ What is the closed-form evaluation of this integral? I honestly do not have a single clue how to solve this. (There is no application, but it is out of curiosity.)","$$I=\int_0^1 \frac{\sin(\ln^4 (1-x))}{x}dx$$ What is the closed-form evaluation of this integral? I honestly do not have a single clue how to solve this. (There is no application, but it is out of curiosity.)",,['integration']
47,Why do the Borwein integrals stop being $\frac{\pi}{2}$?,Why do the Borwein integrals stop being ?,\frac{\pi}{2},"I just received the book ""single digits - In praise of Small Numbers"" by Marc Chamberland. In this book, he gives an interesting integral $$\displaystyle \int_0^\infty \dfrac{\sin x}{x} = \dfrac{\pi}{2}$$ $$\displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3} = \dfrac{\pi}{2}$$ $$\displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5} = \dfrac{\pi}{2}$$ $$\displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} = \dfrac{\pi}{2}$$ $$\displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} \dfrac{\sin(x/9)}{x/9}= \dfrac{\pi}{2}$$ $$\displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} \dfrac{\sin(x/9)}{x/9}\dfrac{\sin(x/11)}{x/11}= \dfrac{\pi}{2}$$ $$\displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} \dfrac{\sin(x/9)}{x/9}\dfrac{\sin(x/11)}{x/11}\dfrac{\sin(x/13)}{x/13} = \dfrac{\pi}{2}$$ At this point, it is tempting to speculate that this pattern goes on forever, but we run into problems and this is another example of jumping to conclusions too soon. $$\displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} \dfrac{\sin(x/9)}{x/9}\dfrac{\sin(x/11)}{x/11}\dfrac{\sin(x/13)}{x/13}\dfrac{\sin(x/15)}{x/15} = \dfrac{467807924713440738696537864469 \pi }{935615849440640907310521750000}$$ I calculated the next several and they are nice approximations to the results above, but not that result $$\dfrac{17708695183056190642497315530628422295569865119 \pi }{35417390788301195294898352987527510935040000000}$$ $$\dfrac{8096799621940897567828686854312535486311061114550605367511653 \pi }{16193600755941299921751838065715269433640150152124763150000000}$$ $$\dfrac{2051563935160591194337436768610392837217226815379395891838337765936509 \pi }{4103129007448718822870650414175026723860506854636748901313920000000000}$$ $$\dfrac{37193167701690492344448194533283488902041049236760438302965167901187323851384840067287863 \pi }{74386376780038719358535506076609218130495936637120586884474907521986965251324791250000000}$$ He states ""The explanation for this change is a bit technical, but the critical reason is that $\dfrac{1}{3} + \dfrac{1}{5} + \ldots + \dfrac{1}{13} \lt 1$ , whereas, adding the next term $\frac{1}{15}$ pushes the sum over $1$ , making a difference in the value of the integral."" He does not mention the researcher, but I'd like to know what is a ""bit technical"" explanation or if there is a more analytical or mathematical rationale or a reference to the research?","I just received the book ""single digits - In praise of Small Numbers"" by Marc Chamberland. In this book, he gives an interesting integral At this point, it is tempting to speculate that this pattern goes on forever, but we run into problems and this is another example of jumping to conclusions too soon. I calculated the next several and they are nice approximations to the results above, but not that result He states ""The explanation for this change is a bit technical, but the critical reason is that , whereas, adding the next term pushes the sum over , making a difference in the value of the integral."" He does not mention the researcher, but I'd like to know what is a ""bit technical"" explanation or if there is a more analytical or mathematical rationale or a reference to the research?",\displaystyle \int_0^\infty \dfrac{\sin x}{x} = \dfrac{\pi}{2} \displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3} = \dfrac{\pi}{2} \displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5} = \dfrac{\pi}{2} \displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} = \dfrac{\pi}{2} \displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} \dfrac{\sin(x/9)}{x/9}= \dfrac{\pi}{2} \displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} \dfrac{\sin(x/9)}{x/9}\dfrac{\sin(x/11)}{x/11}= \dfrac{\pi}{2} \displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} \dfrac{\sin(x/9)}{x/9}\dfrac{\sin(x/11)}{x/11}\dfrac{\sin(x/13)}{x/13} = \dfrac{\pi}{2} \displaystyle \int_0^\infty \dfrac{\sin(x)}{x}\dfrac{\sin(x/3)}{x/3}\dfrac{\sin(x/5)}{x/5}\dfrac{\sin(x/7)}{x/7} \dfrac{\sin(x/9)}{x/9}\dfrac{\sin(x/11)}{x/11}\dfrac{\sin(x/13)}{x/13}\dfrac{\sin(x/15)}{x/15} = \dfrac{467807924713440738696537864469 \pi }{935615849440640907310521750000} \dfrac{17708695183056190642497315530628422295569865119 \pi }{35417390788301195294898352987527510935040000000} \dfrac{8096799621940897567828686854312535486311061114550605367511653 \pi }{16193600755941299921751838065715269433640150152124763150000000} \dfrac{2051563935160591194337436768610392837217226815379395891838337765936509 \pi }{4103129007448718822870650414175026723860506854636748901313920000000000} \dfrac{37193167701690492344448194533283488902041049236760438302965167901187323851384840067287863 \pi }{74386376780038719358535506076609218130495936637120586884474907521986965251324791250000000} \dfrac{1}{3} + \dfrac{1}{5} + \ldots + \dfrac{1}{13} \lt 1 \frac{1}{15} 1,"['reference-request', 'definite-integrals', 'divergent-series']"
48,Different representations of Appell hypergeometric series,Different representations of Appell hypergeometric series,,"The (first) Appell series: $$F(a; b_1, b_2; c \mid z_1, z_2) = \sum_{n=0}^{\infty} \frac{(a)_n}{(c)_n} \sum_{n_1+n_2=n} (b_1)_{n_1} (b_2)_{n_2} \, \frac{z^{n_1}}{n_1!} \frac{z^{n_2}}{n_2!}$$ can be written in integral from in two ways: $$F(a; b_1, b_2; c \mid z_1, z_2) = \frac{\Gamma(c)}{\Gamma(a) \Gamma(c-a)} \int_0^1 d t \, \frac{t^{a-1} (1-t)^{c-a-1}}{(1-z_1 t)^{b_1} (1-z_2 t)^{b_2}}$$ (due to Erdelyi) and: $$F(a; b_1, b_2; c \mid z_1, z_2) = \frac{\Gamma(c)}{\Gamma(b_1) \Gamma(b_2) \Gamma(c-b_1-b_1)} \iint_{\triangle} d u_1 \, d u_2 \, \frac{u_1{}^{b_1-1} u_2{}^{b_2-1} (1-u_1-u_2)^{c-b_1-b_2-1}}{(1-z_1 u_1 - z_2 u_2)^{a}}$$ where $\triangle = \{0 \leq u_1, u_2 \leq 1 : 0 \leq u_1 + u_2 \leq 1\}$ (due to Bailey). My question is what manipulations are necessary in order to express one of the integrals into the other one?","The (first) Appell series: $$F(a; b_1, b_2; c \mid z_1, z_2) = \sum_{n=0}^{\infty} \frac{(a)_n}{(c)_n} \sum_{n_1+n_2=n} (b_1)_{n_1} (b_2)_{n_2} \, \frac{z^{n_1}}{n_1!} \frac{z^{n_2}}{n_2!}$$ can be written in integral from in two ways: $$F(a; b_1, b_2; c \mid z_1, z_2) = \frac{\Gamma(c)}{\Gamma(a) \Gamma(c-a)} \int_0^1 d t \, \frac{t^{a-1} (1-t)^{c-a-1}}{(1-z_1 t)^{b_1} (1-z_2 t)^{b_2}}$$ (due to Erdelyi) and: $$F(a; b_1, b_2; c \mid z_1, z_2) = \frac{\Gamma(c)}{\Gamma(b_1) \Gamma(b_2) \Gamma(c-b_1-b_1)} \iint_{\triangle} d u_1 \, d u_2 \, \frac{u_1{}^{b_1-1} u_2{}^{b_2-1} (1-u_1-u_2)^{c-b_1-b_2-1}}{(1-z_1 u_1 - z_2 u_2)^{a}}$$ where $\triangle = \{0 \leq u_1, u_2 \leq 1 : 0 \leq u_1 + u_2 \leq 1\}$ (due to Bailey). My question is what manipulations are necessary in order to express one of the integrals into the other one?",,"['integration', 'hypergeometric-function']"
49,How to solve this definite Integral containing $E_{1}${.}!,How to solve this definite Integral containing {.}!,E_{1},"The integral is: $$\int_{N}^{\infty}\frac{E_{1}(cz+d)}{az+b}e^{-pz}dz$$ where, $E_{1}${.} is the exponential integral, and $$a>0,\ b>0,\ c>0,\ d>0,\ p>0,\ N>0.$$ This is similar to another question of mine which I don't have any Idea to solve it. Any hint or coment  would be appreciated. It must be noted that I already have solved the integral using approximation of exponential integral. I am seeking an exact solution possible. Regards.","The integral is: $$\int_{N}^{\infty}\frac{E_{1}(cz+d)}{az+b}e^{-pz}dz$$ where, $E_{1}${.} is the exponential integral, and $$a>0,\ b>0,\ c>0,\ d>0,\ p>0,\ N>0.$$ This is similar to another question of mine which I don't have any Idea to solve it. Any hint or coment  would be appreciated. It must be noted that I already have solved the integral using approximation of exponential integral. I am seeking an exact solution possible. Regards.",,"['integration', 'definite-integrals', 'special-functions']"
50,"integrate $\int \frac{1}{e^{x}+e^{ax}+e^{a^{2}x}} \, dx$",integrate,"\int \frac{1}{e^{x}+e^{ax}+e^{a^{2}x}} \, dx","I've been trying to integrate  $$ \int \frac{1}{e^{x}+e^{\omega x}+e^{\omega^{2}x}} \, dx  $$ where $\omega=e^{2i\pi/3}$ but to no avail. I've tried substituting in $u=e^{(1+\omega)x}$ but ended up with an integral which looked like: $$ \int \frac{1}{u^{\frac{2+\omega}{1+\omega}}+u^{\frac{1+2\omega}{1+\omega}}+1}\,du $$ multipled by some constant including $\omega$. Does this integral have a closed form in terms of the hypergeometric function or otherwise? EDIT Let the integral be denoted by I then $$ I=-\omega\int\frac{1}{u^{1-\omega}+u^{1-\omega^2}+1}\,dx=-\omega\int\frac{1}{u^{1-\omega}(1+u^{1+\omega})+1}\,dx $$ using the notation from earlier.","I've been trying to integrate  $$ \int \frac{1}{e^{x}+e^{\omega x}+e^{\omega^{2}x}} \, dx  $$ where $\omega=e^{2i\pi/3}$ but to no avail. I've tried substituting in $u=e^{(1+\omega)x}$ but ended up with an integral which looked like: $$ \int \frac{1}{u^{\frac{2+\omega}{1+\omega}}+u^{\frac{1+2\omega}{1+\omega}}+1}\,du $$ multipled by some constant including $\omega$. Does this integral have a closed form in terms of the hypergeometric function or otherwise? EDIT Let the integral be denoted by I then $$ I=-\omega\int\frac{1}{u^{1-\omega}+u^{1-\omega^2}+1}\,dx=-\omega\int\frac{1}{u^{1-\omega}(1+u^{1+\omega})+1}\,dx $$ using the notation from earlier.",,"['integration', 'special-functions']"
51,Integration Around Part of a Branch Cut,Integration Around Part of a Branch Cut,,"I am studying the integral, given by a Laplace transform, $$\int_0^\infty\!e^{-\alpha x}\sinh^{-2/3}x\left(1+\frac 12\sinh^2x\right)^{-1/6}\left(1-\beta\sinh^{4/3}x\right)^{1/2}\,\mathrm dx$$ From what I can tell there are three singularities:  one at $x = 0$ (from the second term in the integrand) and two at $x = \pm\sin^{-1}\sqrt 2$ (from the third term).  The only multi-valued term should be the third term since $$\left(1+\frac 12 \sinh^2x\right)^{-1/6} = \left(x-\sin^{-1}\sqrt 2\right)^{-1/6}\left(x+\sin^{-1}\sqrt 2\right)^{-1/6}$$ and the hyperbolic functions are single-valued.  This means I can set up my branch cut along the real axis in the range $x\in\left(-\sin^{-1}\sqrt 2,\sin^{-1}\sqrt 2\right)$, but this makes the choice of contour really confusing.  This integral is not symmetric under the transformation $x\to -x$ or anything else as far as I can see. Here's my question: What is a good choice for a contour for this integral?  Would it even include any of the three poles if it does not go around the branch cut? FIRST EDIT: From what I understand, when hyperbolic functions are involved it is good to use a rectangular contour and exploit symmetries.  Here it would be $\sinh x = \sinh(x+2\pi i)$ and a good contour would be from $i\epsilon$ to $2\pi i$ to $R+2\pi i$ to $R+i\epsilon$ and back along the real axis, taking the limits as $\epsilon\to 0$ and $R\to\infty$. Some new questions with respect to this revelation:  do I pick up a quarter of the residue at the origin?  And am I correct that the branch point at $\sin^{-1}\sqrt 2$ does not contribute any residue?  How is the limit $\epsilon\to 0$ different along the branch cut vs past it? SECOND EDIT: After further study (and the limited help of Mathematica) it turns out this integral is filled with branch points.  See the picture below. Notice how I've connected pairs to form short, finite-length branch cuts which can be integrated around.  This now means there are no removable singularities where the residues may be picked up.  Instead, the path I've previously described needs to be extremely deformed in order to close the contour.  The main concept which confuses me now is how you would integrate over half a dumbbell/dogbone contour (see the branch cut along the portion of the real axis) when the contour continues further past it.","I am studying the integral, given by a Laplace transform, $$\int_0^\infty\!e^{-\alpha x}\sinh^{-2/3}x\left(1+\frac 12\sinh^2x\right)^{-1/6}\left(1-\beta\sinh^{4/3}x\right)^{1/2}\,\mathrm dx$$ From what I can tell there are three singularities:  one at $x = 0$ (from the second term in the integrand) and two at $x = \pm\sin^{-1}\sqrt 2$ (from the third term).  The only multi-valued term should be the third term since $$\left(1+\frac 12 \sinh^2x\right)^{-1/6} = \left(x-\sin^{-1}\sqrt 2\right)^{-1/6}\left(x+\sin^{-1}\sqrt 2\right)^{-1/6}$$ and the hyperbolic functions are single-valued.  This means I can set up my branch cut along the real axis in the range $x\in\left(-\sin^{-1}\sqrt 2,\sin^{-1}\sqrt 2\right)$, but this makes the choice of contour really confusing.  This integral is not symmetric under the transformation $x\to -x$ or anything else as far as I can see. Here's my question: What is a good choice for a contour for this integral?  Would it even include any of the three poles if it does not go around the branch cut? FIRST EDIT: From what I understand, when hyperbolic functions are involved it is good to use a rectangular contour and exploit symmetries.  Here it would be $\sinh x = \sinh(x+2\pi i)$ and a good contour would be from $i\epsilon$ to $2\pi i$ to $R+2\pi i$ to $R+i\epsilon$ and back along the real axis, taking the limits as $\epsilon\to 0$ and $R\to\infty$. Some new questions with respect to this revelation:  do I pick up a quarter of the residue at the origin?  And am I correct that the branch point at $\sin^{-1}\sqrt 2$ does not contribute any residue?  How is the limit $\epsilon\to 0$ different along the branch cut vs past it? SECOND EDIT: After further study (and the limited help of Mathematica) it turns out this integral is filled with branch points.  See the picture below. Notice how I've connected pairs to form short, finite-length branch cuts which can be integrated around.  This now means there are no removable singularities where the residues may be picked up.  Instead, the path I've previously described needs to be extremely deformed in order to close the contour.  The main concept which confuses me now is how you would integrate over half a dumbbell/dogbone contour (see the branch cut along the portion of the real axis) when the contour continues further past it.",,"['integration', 'laplace-transform', 'contour-integration', 'branch-cuts', 'branch-points']"
52,Can quaternions be useful for integrals?,Can quaternions be useful for integrals?,,Lets assume we want to find a closed form for $\int_0^1 f(x) dx$ where $f(x)$ is a real-analytic function. There are many techniques to find that. Some include contour integration on the complex plane. But I wonder : Can quaternions be useful for integrals ?,Lets assume we want to find a closed form for $\int_0^1 f(x) dx$ where $f(x)$ is a real-analytic function. There are many techniques to find that. Some include contour integration on the complex plane. But I wonder : Can quaternions be useful for integrals ?,,"['integration', 'quaternions']"
53,How to compute or simplify this integration?,How to compute or simplify this integration?,,"Any hints on solving an integration of the following form, $$\int_{x}^{+\infty}\left(1-\frac{1}{1+sy^{-1}}\right) \left(\text{exp}(-\sqrt{y})+ y^{-\frac{1}{2}}(1-\text{exp}(-\sqrt[4]y)\right)dy $$ This arises pretty much in Poisson point processes after using the probability generating function property. I know the above looks pretty much hopeless, I tried using Mathematica and Wolfram Alpha, both don't really help much. I also have $x>0$ and $s>0$ real numbers if that helps. I tried the following Wolfram|Alpha input and it gives a result in terms of $i$ imaginary, I don't understand why. Also is there any valid approximation for which I can say that this integral can be approximately upper and lower bound by? Thanks in advance for any help.","Any hints on solving an integration of the following form, $$\int_{x}^{+\infty}\left(1-\frac{1}{1+sy^{-1}}\right) \left(\text{exp}(-\sqrt{y})+ y^{-\frac{1}{2}}(1-\text{exp}(-\sqrt[4]y)\right)dy $$ This arises pretty much in Poisson point processes after using the probability generating function property. I know the above looks pretty much hopeless, I tried using Mathematica and Wolfram Alpha, both don't really help much. I also have $x>0$ and $s>0$ real numbers if that helps. I tried the following Wolfram|Alpha input and it gives a result in terms of $i$ imaginary, I don't understand why. Also is there any valid approximation for which I can say that this integral can be approximately upper and lower bound by? Thanks in advance for any help.",,"['integration', 'probability-theory', 'probability-distributions', 'definite-integrals', 'improper-integrals']"
54,Is there any geometric explanation of relationship between Integral and derivative?,Is there any geometric explanation of relationship between Integral and derivative?,,"It is said integral is anti-derivative, derivative is tangent of graph function in each point on the function and integral is the area of the region in the $xy$ -plane bounded by the graph. I can not understand the relationship between these, can anyone help me? I want understand the relationship between area and slope of tangent line.","It is said integral is anti-derivative, derivative is tangent of graph function in each point on the function and integral is the area of the region in the -plane bounded by the graph. I can not understand the relationship between these, can anyone help me? I want understand the relationship between area and slope of tangent line.",xy,"['integration', 'derivatives']"
55,Rising Sun Inequality (Dunford-Schwartz maximal inequality),Rising Sun Inequality (Dunford-Schwartz maximal inequality),,"Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be an absolutely integrable function, and let $f^*:\mathbb{R} \rightarrow \mathbb{R}$ be the one-sided signed Hardy-Littlewood maximal function $$f^*(x)  := \sup_{h>o} \frac{1}{h}\int_{[x,x+h]} f(t) dt.$$ Establish the rising sun inequality $$\lambda \mu (\{f^* > \lambda\})\leq \int_{\{f^*>\lambda\}} f(t)dt,$$ furthermore, the above is in fact equal when $\lambda > 0$. I have been stuck on this for the past couple of days. I am still trying to show the case when $\lambda = 0$. Here is the hint from the problem: when $f$ is compactly supported on the compact interval $[a,b]$, then $F(x) = \int_a^x f(t)dt-(x-a)\lambda$ is continuous on the compact interval; apply the Rising Sun lemma to $F(x)$. Side note: for $\lambda >0$ $$\mu (\{x\in \mathbb{R} : \sup_{h>o} \frac{1}{h}\int_{[x,x+h]} |f(t)| dt > \lambda\})\leq \frac{1}{\lambda}\int_\mathbb{R}|f(t)|dt$$ is called One-sided Hardy-Littlewood maximal inequality. This can be proven with the hint from above instead of the standard method using Vitali cover lemma.","Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be an absolutely integrable function, and let $f^*:\mathbb{R} \rightarrow \mathbb{R}$ be the one-sided signed Hardy-Littlewood maximal function $$f^*(x)  := \sup_{h>o} \frac{1}{h}\int_{[x,x+h]} f(t) dt.$$ Establish the rising sun inequality $$\lambda \mu (\{f^* > \lambda\})\leq \int_{\{f^*>\lambda\}} f(t)dt,$$ furthermore, the above is in fact equal when $\lambda > 0$. I have been stuck on this for the past couple of days. I am still trying to show the case when $\lambda = 0$. Here is the hint from the problem: when $f$ is compactly supported on the compact interval $[a,b]$, then $F(x) = \int_a^x f(t)dt-(x-a)\lambda$ is continuous on the compact interval; apply the Rising Sun lemma to $F(x)$. Side note: for $\lambda >0$ $$\mu (\{x\in \mathbb{R} : \sup_{h>o} \frac{1}{h}\int_{[x,x+h]} |f(t)| dt > \lambda\})\leq \frac{1}{\lambda}\int_\mathbb{R}|f(t)|dt$$ is called One-sided Hardy-Littlewood maximal inequality. This can be proven with the hint from above instead of the standard method using Vitali cover lemma.",,"['functional-analysis', 'inequality', 'ergodic-theory', 'integration']"
56,Is this Neumann series solution unique?,Is this Neumann series solution unique?,,"I have a Fredholm integral equation of the second kind given as $$f(x)=g(x)+\lambda\int_{-\infty}^\infty K(x,y)f(y)dy, $$ where $\lambda\in(0,1)$, the kernel $K(x,y)=\phi(x-y)$ is a Gaussian function, and $g(x)$ is a known continuous function. I am interested in solutions $f$ that satisfy this. I could find a solution by the Neumann series approach (see, for example, Section 5.3 here: http://www.hep.caltech.edu/~fcp/math/integralEquations/integralEquations.pdf ). My question is now: How do I know whether that solution is unique? Could there be other functions that solve this (discontinuous functions $f$ are allowed)? What I could find is, e.g., that the Neumann series converges to the unique solution if $|\lambda|M(b-a)<1$, where $M$ is an upper bound for $K$ and $a,b$ are the integral bounds. However, since in my case $b-a=\infty$ this is obviously not satisfied. But perhaps weaker conditions exist, especially given I already know that the Neumann series converges to a solution? Is the solution then unique? Edit: Another condition I found is: The Neumann series converges to the unique solution if $|\lambda|\|K\|_2<1$, where the norm is defined as $$\|K\|_2=\left(\int_{-\infty}^\infty \int_{-\infty}^\infty |K(x,y)|^2 dxdy\right)^{1/2}.$$ However, I don't think I can evaluate that double integral for a Gaussian function $K(x,y)=\phi(x-x)$, can I?","I have a Fredholm integral equation of the second kind given as $$f(x)=g(x)+\lambda\int_{-\infty}^\infty K(x,y)f(y)dy, $$ where $\lambda\in(0,1)$, the kernel $K(x,y)=\phi(x-y)$ is a Gaussian function, and $g(x)$ is a known continuous function. I am interested in solutions $f$ that satisfy this. I could find a solution by the Neumann series approach (see, for example, Section 5.3 here: http://www.hep.caltech.edu/~fcp/math/integralEquations/integralEquations.pdf ). My question is now: How do I know whether that solution is unique? Could there be other functions that solve this (discontinuous functions $f$ are allowed)? What I could find is, e.g., that the Neumann series converges to the unique solution if $|\lambda|M(b-a)<1$, where $M$ is an upper bound for $K$ and $a,b$ are the integral bounds. However, since in my case $b-a=\infty$ this is obviously not satisfied. But perhaps weaker conditions exist, especially given I already know that the Neumann series converges to a solution? Is the solution then unique? Edit: Another condition I found is: The Neumann series converges to the unique solution if $|\lambda|\|K\|_2<1$, where the norm is defined as $$\|K\|_2=\left(\int_{-\infty}^\infty \int_{-\infty}^\infty |K(x,y)|^2 dxdy\right)^{1/2}.$$ However, I don't think I can evaluate that double integral for a Gaussian function $K(x,y)=\phi(x-x)$, can I?",,"['integration', 'sequences-and-series', 'functional-analysis', 'integral-equations']"
57,A question on integration,A question on integration,,"I want to compute the following integral: $$\raise 1ex{\Large\int} \frac{\sqrt{\ln(x+\sqrt{1+x^2}})}{1+x^2}\,dx$$","I want to compute the following integral: $$\raise 1ex{\Large\int} \frac{\sqrt{\ln(x+\sqrt{1+x^2}})}{1+x^2}\,dx$$",,"['integration', 'indefinite-integrals']"
58,Integral of a gaussian function of trigonometric functions,Integral of a gaussian function of trigonometric functions,,"I need help with the analytical solution of this integral: $$\int_{0}^{2\pi}\frac{1}{\sqrt{a^2-b^2\cos^{2}2\phi}}\exp{\left(-\frac{(x-c\cos\phi)^2}{a+b\cos2\phi}-\frac{(y-d\sin\phi)^2}{a-b\cos2\phi}\right)}\mathrm d\phi$$ where $a^2-b^2=1$ and $c, d$ are constants. I know the solution for $a=1$, $b=0$, using the generating function of the modified Bessel functions of first kind, but I think it can't be used in this case. ¿Can it be solved using the stationary phase method? Any help would be welcomed.","I need help with the analytical solution of this integral: $$\int_{0}^{2\pi}\frac{1}{\sqrt{a^2-b^2\cos^{2}2\phi}}\exp{\left(-\frac{(x-c\cos\phi)^2}{a+b\cos2\phi}-\frac{(y-d\sin\phi)^2}{a-b\cos2\phi}\right)}\mathrm d\phi$$ where $a^2-b^2=1$ and $c, d$ are constants. I know the solution for $a=1$, $b=0$, using the generating function of the modified Bessel functions of first kind, but I think it can't be used in this case. ¿Can it be solved using the stationary phase method? Any help would be welcomed.",,"['analysis', 'integration', 'trigonometry', 'physics']"
59,formula that can be used to integrate powers of log-sin,formula that can be used to integrate powers of log-sin,,"I found a formula which, upon differentiating, can be used to evaluate various powers of log-sine or log-cos integrals. $\displaystyle I(a,p)=\int_{0}^{\frac{\pi}{2}}x\cos^{p-1}(x)\sin(ax)dx$ $=\displaystyle\frac{\pi}{2^{p+1}}\Gamma(p)\left(\frac{\psi(\frac{p+a+1}{2})-\psi(\frac{p-a+1}{2})}{\Gamma(\frac{p+a+1}{2})\Gamma(\frac{p-a+1}{2})}\right); \;\ p>0, \;\ |a|<|p+1|$ For example, this can be differentiated w.r.t $a$, set $a=0$, then differentiate w.r.t $p$, then the result $\displaystyle\int_{0}^{\frac{\pi}{2}}x^{2}\ln^{2}(2\cos(x))dx=\frac{11{\pi}^{5}}{1440}$ is obtained. My question is, how can the above formula be derived.  I realize it looks nasty, but may  not be as bad as it appears.  It would seem the trig version of the Beta function could be  applied, but that $ax$ in the $\sin$ throws me off. The digammas in the solution make it seem  as if some differentiating of the Gamma function has been done.  Does anyone have any  ideas how to evaluate the above integral to that result?  I know some here, like Sasha  and Robjohn, are very adept at using the digamma, so I thought perhaps this problem would  be of interest. I ran a few examples, and it does work.  The differentiation is a little  tedious, though, depending on the power one wants to integrate. I had a thought.  For what it's worth.  Maybe the identity: $\displaystyle\frac{1}{\pi}\int_{0}^{\pi}\left(2\cos(t/2)\right)^{x}\cos(ty)dt=\frac{\Gamma(x+1)}{\Gamma(\frac{x}{2}+y+1)\Gamma(\frac{x}{2}-y+1)}$ could be applied with $x=p-1$ and $y=a/2$.  It looks like it may be promising. :)","I found a formula which, upon differentiating, can be used to evaluate various powers of log-sine or log-cos integrals. $\displaystyle I(a,p)=\int_{0}^{\frac{\pi}{2}}x\cos^{p-1}(x)\sin(ax)dx$ $=\displaystyle\frac{\pi}{2^{p+1}}\Gamma(p)\left(\frac{\psi(\frac{p+a+1}{2})-\psi(\frac{p-a+1}{2})}{\Gamma(\frac{p+a+1}{2})\Gamma(\frac{p-a+1}{2})}\right); \;\ p>0, \;\ |a|<|p+1|$ For example, this can be differentiated w.r.t $a$, set $a=0$, then differentiate w.r.t $p$, then the result $\displaystyle\int_{0}^{\frac{\pi}{2}}x^{2}\ln^{2}(2\cos(x))dx=\frac{11{\pi}^{5}}{1440}$ is obtained. My question is, how can the above formula be derived.  I realize it looks nasty, but may  not be as bad as it appears.  It would seem the trig version of the Beta function could be  applied, but that $ax$ in the $\sin$ throws me off. The digammas in the solution make it seem  as if some differentiating of the Gamma function has been done.  Does anyone have any  ideas how to evaluate the above integral to that result?  I know some here, like Sasha  and Robjohn, are very adept at using the digamma, so I thought perhaps this problem would  be of interest. I ran a few examples, and it does work.  The differentiation is a little  tedious, though, depending on the power one wants to integrate. I had a thought.  For what it's worth.  Maybe the identity: $\displaystyle\frac{1}{\pi}\int_{0}^{\pi}\left(2\cos(t/2)\right)^{x}\cos(ty)dt=\frac{\Gamma(x+1)}{\Gamma(\frac{x}{2}+y+1)\Gamma(\frac{x}{2}-y+1)}$ could be applied with $x=p-1$ and $y=a/2$.  It looks like it may be promising. :)",,['integration']
60,Uniqueness of the Solution to Fredholm's Integral Equations of the First Kind [closed],Uniqueness of the Solution to Fredholm's Integral Equations of the First Kind [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question Any one who knows the conditions for Uniqueness of the Solution to Fredholm's Integral Equations of the First Kind? Thanks.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question Any one who knows the conditions for Uniqueness of the Solution to Fredholm's Integral Equations of the First Kind? Thanks.",,"['integration', 'integral-equations']"
61,To determine if$f^{-1}(x)$ is periodic function or not? $f(x)=\int_1^{x} \frac{1}{\sqrt[m]{P(t)}}\;dt$,To determine if is periodic function or not?,f^{-1}(x) f(x)=\int_1^{x} \frac{1}{\sqrt[m]{P(t)}}\;dt,"$$f(x)=\int_1^{x}  \frac{1}{\sqrt[m]{P(t)}}\;dt$$ $P(x)$ is polynomial with degree $n$. $m$ is an positive integer and $m>1$ What is the algoritm to determine $f^{-1}(x)$ is periodic function via using  $P(x)$ and $m$ without evaluting the integral ? Is there also a way to find period without evaluting the integral? Example 1: $P(x)=x^2$ , $m=2$ $$f_1(x)=\int_1^{x}  \frac{1}{t}\;dt=\ln x$$ $$f_1^{-1}(x)=e^x$$ $$f_1^{-1}(x+2k\pi i)=e^{x+2k\pi i}=e^x=f_1^{-1}(x)$$   $k$ is an integer $$f_1^{-1}(x+2k\pi i)=f_1^{-1}(x)$$ $f_1^{-1}(x)$ is a periodic function Example 2: $P(x)=1-x^2$ , $m=2$ $$f_2(x)=\int_1^{x}  \frac{1}{\sqrt{1-t^2}}\;dt=\arcsin x-\frac{\pi}{2}$$ $$f_2^{-1}(x)=\sin {(x+\frac{\pi}{2})}$$ $$f_2^{-1}(x+2k\pi )=\sin{(x+\frac{\pi}{2}+2k\pi )}=\sin{(x +\frac{\pi}{2})}=f_2^{-1}(x)$$   $k$ is an integer $$f_2^{-1}(x+2k\pi )=f_2^{-1}(x)$$ $f_2^{-1}(x)$ is a periodic function Example 3: $P(x)=(1+x^2)^2=1+2x^2+x^4$ , $m=2$ $$f_3(x)=\int_1^{x}  \frac{1}{1+t^2}\;dt=\arctan x -\frac{\pi}{4}$$ $$f_3^{-1}(x)=\tan (x+\frac{\pi}{4})$$ $$f_3^{-1}(x+k\pi )=\tan{(x+\frac{\pi}{4}+k\pi )}=\tan{(x+\frac{\pi}{4} )}=f_3^{-1}(x)$$   $k$ is an integer $$f_3^{-1}(x+k\pi )=f_3^{-1}(x)$$ $f_3^{-1}(x)$ is a periodic function Example 4: $P(x)=x^4$ , $m=2$ $$f_4(x)=\int_1^{x}  \frac{1}{t^2}\;dt=\frac{x-1}{x}$$ $$f_4^{-1}(x)=\frac{1}{1-x}$$ $f_4^{-1}(x)$ is not periodic function Thanks a lot for answers","$$f(x)=\int_1^{x}  \frac{1}{\sqrt[m]{P(t)}}\;dt$$ $P(x)$ is polynomial with degree $n$. $m$ is an positive integer and $m>1$ What is the algoritm to determine $f^{-1}(x)$ is periodic function via using  $P(x)$ and $m$ without evaluting the integral ? Is there also a way to find period without evaluting the integral? Example 1: $P(x)=x^2$ , $m=2$ $$f_1(x)=\int_1^{x}  \frac{1}{t}\;dt=\ln x$$ $$f_1^{-1}(x)=e^x$$ $$f_1^{-1}(x+2k\pi i)=e^{x+2k\pi i}=e^x=f_1^{-1}(x)$$   $k$ is an integer $$f_1^{-1}(x+2k\pi i)=f_1^{-1}(x)$$ $f_1^{-1}(x)$ is a periodic function Example 2: $P(x)=1-x^2$ , $m=2$ $$f_2(x)=\int_1^{x}  \frac{1}{\sqrt{1-t^2}}\;dt=\arcsin x-\frac{\pi}{2}$$ $$f_2^{-1}(x)=\sin {(x+\frac{\pi}{2})}$$ $$f_2^{-1}(x+2k\pi )=\sin{(x+\frac{\pi}{2}+2k\pi )}=\sin{(x +\frac{\pi}{2})}=f_2^{-1}(x)$$   $k$ is an integer $$f_2^{-1}(x+2k\pi )=f_2^{-1}(x)$$ $f_2^{-1}(x)$ is a periodic function Example 3: $P(x)=(1+x^2)^2=1+2x^2+x^4$ , $m=2$ $$f_3(x)=\int_1^{x}  \frac{1}{1+t^2}\;dt=\arctan x -\frac{\pi}{4}$$ $$f_3^{-1}(x)=\tan (x+\frac{\pi}{4})$$ $$f_3^{-1}(x+k\pi )=\tan{(x+\frac{\pi}{4}+k\pi )}=\tan{(x+\frac{\pi}{4} )}=f_3^{-1}(x)$$   $k$ is an integer $$f_3^{-1}(x+k\pi )=f_3^{-1}(x)$$ $f_3^{-1}(x)$ is a periodic function Example 4: $P(x)=x^4$ , $m=2$ $$f_4(x)=\int_1^{x}  \frac{1}{t^2}\;dt=\frac{x-1}{x}$$ $$f_4^{-1}(x)=\frac{1}{1-x}$$ $f_4^{-1}(x)$ is not periodic function Thanks a lot for answers",,"['integration', 'functions']"
62,Simpler way to compute a definite integral without resorting to partial fractions?,Simpler way to compute a definite integral without resorting to partial fractions?,,"I found the method of partial fractions very laborious to solve this definite integral : $$\int_0^\infty \frac{\sqrt[3]{x}}{1 + x^2}\,dx$$ Is there a simpler way to do this ?","I found the method of partial fractions very laborious to solve this definite integral : $$\int_0^\infty \frac{\sqrt[3]{x}}{1 + x^2}\,dx$$ Is there a simpler way to do this ?",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
63,Generalization of an Integral Trick?,Generalization of an Integral Trick?,,"There is an interesting trick that can be used to evaluate integrals in the form $$I=\int_{-a}^a \frac{E(x)}{b^x+1}dx$$ where $E$ is an even function. Notice that, by substituting $x\to -x$, $$I=\int_{-a}^a \frac{E(-x)}{b^{-x}+1}dx=\int_{-a}^a \frac{b^xE(x)}{b^{x}+1}dx$$ and so $$I+I=\int_{-a}^a \frac{E(x)+b^xE(x)}{b^x+1}dx=\int_{-a}^a E(x)dx$$ and so $$I=\frac{1}{2}\int_{-a}^a E(x)dx=\int_{0}^a E(x)dx$$ For example, this trick can be used to evaluate the intimidating integral $$\int_{-1}^1 \frac{x^{100}}{e^x+1}dx=\frac{1}{101}$$ QUESTION: Is there some way to generalize this trick to integrals of the form $$I=\int_{-a}^a \frac{E(x)}{(b^x+1)^2}dx$$ or will this type of integral just have to be done the hard way?","There is an interesting trick that can be used to evaluate integrals in the form $$I=\int_{-a}^a \frac{E(x)}{b^x+1}dx$$ where $E$ is an even function. Notice that, by substituting $x\to -x$, $$I=\int_{-a}^a \frac{E(-x)}{b^{-x}+1}dx=\int_{-a}^a \frac{b^xE(x)}{b^{x}+1}dx$$ and so $$I+I=\int_{-a}^a \frac{E(x)+b^xE(x)}{b^x+1}dx=\int_{-a}^a E(x)dx$$ and so $$I=\frac{1}{2}\int_{-a}^a E(x)dx=\int_{0}^a E(x)dx$$ For example, this trick can be used to evaluate the intimidating integral $$\int_{-1}^1 \frac{x^{100}}{e^x+1}dx=\frac{1}{101}$$ QUESTION: Is there some way to generalize this trick to integrals of the form $$I=\int_{-a}^a \frac{E(x)}{(b^x+1)^2}dx$$ or will this type of integral just have to be done the hard way?",,"['integration', 'definite-integrals', 'even-and-odd-functions']"
64,How to solve $\int\sqrt{1+x\sqrt{x^2+2}}dx$,How to solve,\int\sqrt{1+x\sqrt{x^2+2}}dx,"I need to solve $$\int\sqrt{1+x\sqrt{x^2+2}}dx$$ I've chosen the substitution variables $$u=\sqrt{x^2+2}$$ $$du=\frac{x}{\sqrt{x^2+2}}$$ However, I am completly stuck at $$\int\sqrt{1+xu} dx$$ Which let me believe I've chosen wrong substitution variables. I've then tried letting $u=x^2+2$ or simply $u=x$, but it does not help me at all solving it. Would someone please give me an hint on this ? Thanks.","I need to solve $$\int\sqrt{1+x\sqrt{x^2+2}}dx$$ I've chosen the substitution variables $$u=\sqrt{x^2+2}$$ $$du=\frac{x}{\sqrt{x^2+2}}$$ However, I am completly stuck at $$\int\sqrt{1+xu} dx$$ Which let me believe I've chosen wrong substitution variables. I've then tried letting $u=x^2+2$ or simply $u=x$, but it does not help me at all solving it. Would someone please give me an hint on this ? Thanks.",,"['integration', 'improper-integrals']"
65,Evaluate $\int {2x\over x^2-1}dx$,Evaluate,\int {2x\over x^2-1}dx,"My friend evaluated this before he went to bed: $$\int {2x\over x^2-1}dx$$ The answer was $\log(x^2-1)$. I just can't figure out how that works. I know that $\int \frac1x dx = \log|x|$, so what just happened to $2x$?","My friend evaluated this before he went to bed: $$\int {2x\over x^2-1}dx$$ The answer was $\log(x^2-1)$. I just can't figure out how that works. I know that $\int \frac1x dx = \log|x|$, so what just happened to $2x$?",,['integration']
66,Integrate without expansion?,Integrate without expansion?,,"I want to evaluate $$ \int_0^1 ( 1 - x^2)^{10} dx $$ One way I can do this is by expanding out $(1 - x^2)^{10}$ term by term, but is there a better way to do this?","I want to evaluate One way I can do this is by expanding out term by term, but is there a better way to do this?", \int_0^1 ( 1 - x^2)^{10} dx  (1 - x^2)^{10},[]
67,How do you solve the following separable differential equation: y'y = y + 1?,How do you solve the following separable differential equation: y'y = y + 1?,,I just started learning about differential equations and encountered following equation: $$ y'y = y +1 $$ Wolfram alpha provided the following explanation: here But I'm not sure how the integration is performed. What rules are used? How does $\int{\frac{y'y}{y+1}dx}$ become $-\log(y + 1) + y$?,I just started learning about differential equations and encountered following equation: $$ y'y = y +1 $$ Wolfram alpha provided the following explanation: here But I'm not sure how the integration is performed. What rules are used? How does $\int{\frac{y'y}{y+1}dx}$ become $-\log(y + 1) + y$?,,"['integration', 'ordinary-differential-equations']"
68,I'm trying to find out if this limit exists,I'm trying to find out if this limit exists,,"I'm trying to calculate the following limit but I can't wrap my head,  around it. Can you guys give me some hints: $$\lim_{x\to0^+}\frac{{\int_0^{x^2}\sin{\sqrt{t}}}~ dt}{x^3}$$","I'm trying to calculate the following limit but I can't wrap my head,  around it. Can you guys give me some hints: $$\lim_{x\to0^+}\frac{{\int_0^{x^2}\sin{\sqrt{t}}}~ dt}{x^3}$$",,"['integration', 'limits']"
69,How find this limit $I=\lim_{n\to\infty}n^a\left(\int_{0}^{\pi/2}\sin{(nx)}\cos^n{x}dx\right)=b$,How find this limit,I=\lim_{n\to\infty}n^a\left(\int_{0}^{\pi/2}\sin{(nx)}\cos^n{x}dx\right)=b,"If the constant $a,b\neq 0$ such  $$ I=\lim_{n \to \infty}\left[% n^{a}\int_{0}^{\pi/2}\sin\left(nx\right)\cos^{n}\left(x\right)\,{\rm d}x \right] = b $$ find $a,b$ My idea: since $$\sin{(nx)}=\dfrac{e^{inx}-e^{-inx}}{2i}$$ $$\cos{x}=\dfrac{1}{2}(e^{ix}+e^{-ix})$$ so $$(e^{ix}+e^{-ix})^n=\sum_{k=0}^{n}\binom{n}{k}e^{i(n-k)x}e^{-ikx}$$ so $$\sin{(nx)}\cos^n{x}=\dfrac{1}{2i}\cdot\dfrac{1}{2^n}(e^{inx}-e^{-inx})(e^{ix}+e^{-ix})^n=\dfrac{1}{2^{n+1}\cdot i}\sum_{k=0}^{n}\left(\binom{n}{k}(e^{i(2n-2k)x}-e^{-2ikx}\right)$$ then I can't.Thank you","If the constant $a,b\neq 0$ such  $$ I=\lim_{n \to \infty}\left[% n^{a}\int_{0}^{\pi/2}\sin\left(nx\right)\cos^{n}\left(x\right)\,{\rm d}x \right] = b $$ find $a,b$ My idea: since $$\sin{(nx)}=\dfrac{e^{inx}-e^{-inx}}{2i}$$ $$\cos{x}=\dfrac{1}{2}(e^{ix}+e^{-ix})$$ so $$(e^{ix}+e^{-ix})^n=\sum_{k=0}^{n}\binom{n}{k}e^{i(n-k)x}e^{-ikx}$$ so $$\sin{(nx)}\cos^n{x}=\dfrac{1}{2i}\cdot\dfrac{1}{2^n}(e^{inx}-e^{-inx})(e^{ix}+e^{-ix})^n=\dfrac{1}{2^{n+1}\cdot i}\sum_{k=0}^{n}\left(\binom{n}{k}(e^{i(2n-2k)x}-e^{-2ikx}\right)$$ then I can't.Thank you",,"['integration', 'limits']"
70,How do I start this integral problem: $\int_0^1 \frac{\ln^3 u}{1-u} du = -\frac{\pi^4}{15} $? [closed],How do I start this integral problem: ? [closed],\int_0^1 \frac{\ln^3 u}{1-u} du = -\frac{\pi^4}{15} ,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How do I prove this? $$\int_0^1 \frac{\ln^3 u}{1-u} du = -\frac{\pi^4}{15} $$ I'm guessing using Riemann zeta function? But then how do I start?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How do I prove this? $$\int_0^1 \frac{\ln^3 u}{1-u} du = -\frac{\pi^4}{15} $$ I'm guessing using Riemann zeta function? But then how do I start?",,"['integration', 'definite-integrals', 'riemann-integration', 'pi']"
71,Compute $\int^{\pi/2}_0 \frac{dx}{(a^2\cos^2 x + b^2 \sin ^2 x)^2}$,Compute,\int^{\pi/2}_0 \frac{dx}{(a^2\cos^2 x + b^2 \sin ^2 x)^2},"I have tried solving this for about an hour and will probably resort to head banging in some time: $$\int ^{\frac{\pi}{2}}_{0} \dfrac{dx}{(a^2\cos^2 x + b^2 \sin ^2 x)^2}$$ I first divided by $\cos^4 x$ and then subsequently put $\tan x = t$, to get: $$\int ^{\infty}_{0} \dfrac{1+t^2}{(a^2 + b^2 t^2)^2}dt$$ This has become unmanageable. Neither splitting the numerator, nor Partial fraction (taking t^2 = z and applying partial fraction) seems to work.","I have tried solving this for about an hour and will probably resort to head banging in some time: $$\int ^{\frac{\pi}{2}}_{0} \dfrac{dx}{(a^2\cos^2 x + b^2 \sin ^2 x)^2}$$ I first divided by $\cos^4 x$ and then subsequently put $\tan x = t$, to get: $$\int ^{\infty}_{0} \dfrac{1+t^2}{(a^2 + b^2 t^2)^2}dt$$ This has become unmanageable. Neither splitting the numerator, nor Partial fraction (taking t^2 = z and applying partial fraction) seems to work.",,"['integration', 'definite-integrals']"
72,How to know when to complete the square,How to know when to complete the square,,Question is: $$\int \frac{dx}{ x^2+8x+20}$$ Why can I not just solve for $A/(x+2) +B/(x+10)$ and integrate it this way? The answer on symbolab shows I need to complete the square of the denominator first but I don't know hen to do that or when to factor it out. Any help would be great!,Question is: $$\int \frac{dx}{ x^2+8x+20}$$ Why can I not just solve for $A/(x+2) +B/(x+10)$ and integrate it this way? The answer on symbolab shows I need to complete the square of the denominator first but I don't know hen to do that or when to factor it out. Any help would be great!,,['integration']
73,"When taking the integral of $\sec(x)$, how do you come up with the crucial step?","When taking the integral of , how do you come up with the crucial step?",\sec(x),"You have to multiply with $\frac{\sec(x) + \tan(x)}{\sec(x) + \tan(x)}$ ( http://math2.org/math/integrals/more/sec.htm ), but how do you come up with this idea? Is there a specific reason for that step, or is it just mathematical intuition?","You have to multiply with $\frac{\sec(x) + \tan(x)}{\sec(x) + \tan(x)}$ ( http://math2.org/math/integrals/more/sec.htm ), but how do you come up with this idea? Is there a specific reason for that step, or is it just mathematical intuition?",,"['integration', 'secant']"
74,"Prove or refute: If $f$ is Riemann integrable on $[0,1]$, then so is $\sin(f)$","Prove or refute: If  is Riemann integrable on , then so is","f [0,1] \sin(f)","I'd love your help with the following question: I need to prove or refute the claim that for a Riemann integrable function $f$ in $[0,1]$ also $\sin(f)$ is integrable on $[0,1]$. My translation for this claim: If $\int_{0}^{1} f(x) dx < \infty$, so does $\int_{0}^{1} \sin(f(x))dx < \infty$, Am I right? I tried to think of an elementary function that will fit the conditions, one that will blow up in $0$ or $1$ or both, but I didn't find any. Can I just use the fact that $\int_{0}^{1} \sin(f(x))dx \leq \int_{0}^{1} 1dx < \infty$ and that's it or Am I missing something? Thanks!","I'd love your help with the following question: I need to prove or refute the claim that for a Riemann integrable function $f$ in $[0,1]$ also $\sin(f)$ is integrable on $[0,1]$. My translation for this claim: If $\int_{0}^{1} f(x) dx < \infty$, so does $\int_{0}^{1} \sin(f(x))dx < \infty$, Am I right? I tried to think of an elementary function that will fit the conditions, one that will blow up in $0$ or $1$ or both, but I didn't find any. Can I just use the fact that $\int_{0}^{1} \sin(f(x))dx \leq \int_{0}^{1} 1dx < \infty$ and that's it or Am I missing something? Thanks!",,"['integration', 'riemann-sum']"
75,Calculate $\int_0^\infty\frac{\sin(x)\log(x)}{x}\mathrm dx$.,Calculate .,\int_0^\infty\frac{\sin(x)\log(x)}{x}\mathrm dx,"Calculate $\displaystyle\int_0^\infty\dfrac{\sin(x)\log(x)}{x}\mathrm dx$. I tried to expand $\sin(x)$ at zero, or use SI(SinIntegral) function, but it did not work. Besides, I searched the question on math.stackexchange , nothing found. Mathematica tells me the answer is $-\dfrac{\gamma\pi}{2}$, I have no idea how to get it. Thanks for your help!","Calculate $\displaystyle\int_0^\infty\dfrac{\sin(x)\log(x)}{x}\mathrm dx$. I tried to expand $\sin(x)$ at zero, or use SI(SinIntegral) function, but it did not work. Besides, I searched the question on math.stackexchange , nothing found. Mathematica tells me the answer is $-\dfrac{\gamma\pi}{2}$, I have no idea how to get it. Thanks for your help!",,['integration']
76,How can I calculate $\int\frac{x-2}{-x^2+2x-5}dx$?,How can I calculate ?,\int\frac{x-2}{-x^2+2x-5}dx,"I'm completely stuck on solving this indefinite integral: $$\int\frac{x-2}{-x^2+2x-5}dx$$ By completing the square in the denominator and separating the original into two integrals, I get: $$-\int\frac{x}{x^2-2x+5}dx -\int\frac{2}{(x-1)^2 + 4}dx$$ The second one is trivial, but the first one has me stuck. Whatever substitution I apply or form I put it in, I just can't figure it out. They're meant to be solved without partial integration, by the way.","I'm completely stuck on solving this indefinite integral: By completing the square in the denominator and separating the original into two integrals, I get: The second one is trivial, but the first one has me stuck. Whatever substitution I apply or form I put it in, I just can't figure it out. They're meant to be solved without partial integration, by the way.",\int\frac{x-2}{-x^2+2x-5}dx -\int\frac{x}{x^2-2x+5}dx -\int\frac{2}{(x-1)^2 + 4}dx,"['integration', 'indefinite-integrals', 'partial-fractions']"
77,How to show that $\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}=\frac{\pi^2}{6}$,How to show that,\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}=\frac{\pi^2}{6},"Wolfram Alpha shows that $$\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}=\zeta(2)=\frac{\pi^2}{6}$$ I want to prove this. Attempt: I tried to treat this as a telescoping series: $$\begin{align} \sum_{n=1}^{\infty}\frac{H_n}{n^2+n}&=\sum_{n=1}^{\infty}H_n\left(\frac{1}{n}-\frac{1}{n+1}\right)\\ &=H_{1}\left(1-\frac{1}{2}\right)+H_{2}\left(\frac{1}{2}-\frac{1}{3}\right)+H_{3}\left(\frac{1}{3}-\frac{1}{4}\right)\\ &=1-\frac{1}{2}+\frac{1}{2}-\frac{1}{3}+\frac{1}{4}-\frac{1}{6}+\frac{1}{3}-\frac{1}{4}+\frac{1}{6}-\frac{1}{8}+\frac{1}{9}-\frac{1}{12} \end{align}$$ I think this method is not quite useful, so I tried  another one: $$H_n=\int_{0}^{1}\frac{1-t^n}{1-t}dt$$ Then, $$\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}=\sum_{n=1}^{\infty}\frac{1}{n^2+n}\int_{0}^{1}\frac{1-t^n}{1-t}dt$$ At this point, I do not know how to proceed.","Wolfram Alpha shows that I want to prove this. Attempt: I tried to treat this as a telescoping series: I think this method is not quite useful, so I tried  another one: Then, At this point, I do not know how to proceed.","\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}=\zeta(2)=\frac{\pi^2}{6} \begin{align}
\sum_{n=1}^{\infty}\frac{H_n}{n^2+n}&=\sum_{n=1}^{\infty}H_n\left(\frac{1}{n}-\frac{1}{n+1}\right)\\
&=H_{1}\left(1-\frac{1}{2}\right)+H_{2}\left(\frac{1}{2}-\frac{1}{3}\right)+H_{3}\left(\frac{1}{3}-\frac{1}{4}\right)\\
&=1-\frac{1}{2}+\frac{1}{2}-\frac{1}{3}+\frac{1}{4}-\frac{1}{6}+\frac{1}{3}-\frac{1}{4}+\frac{1}{6}-\frac{1}{8}+\frac{1}{9}-\frac{1}{12}
\end{align} H_n=\int_{0}^{1}\frac{1-t^n}{1-t}dt \sum_{n=1}^{\infty}\frac{H_n}{n^2+n}=\sum_{n=1}^{\infty}\frac{1}{n^2+n}\int_{0}^{1}\frac{1-t^n}{1-t}dt","['integration', 'sequences-and-series', 'closed-form', 'harmonic-numbers']"
78,Find the mass of the unit sphere,Find the mass of the unit sphere,,"I would like to find the mass of the unit sphere such that the density at any point is proportional to the distance from the surface of the sphere. I think spherical coordinates would probably be best to accomplish this. I know that $$ mass = \iiint_D\rho(x,y,z) dV $$ but I do not understand how to translate ""proportional to the distance from the surface of the sphere"" symbolically. I know that the bounds of the integral will be easy to write in spherical coordinates. I need help to understand how to find the density function. I am looking for help to set up the integrand. I can solve the integral myself. Any help would be greatly appreciated.","I would like to find the mass of the unit sphere such that the density at any point is proportional to the distance from the surface of the sphere. I think spherical coordinates would probably be best to accomplish this. I know that $$ mass = \iiint_D\rho(x,y,z) dV $$ but I do not understand how to translate ""proportional to the distance from the surface of the sphere"" symbolically. I know that the bounds of the integral will be easy to write in spherical coordinates. I need help to understand how to find the density function. I am looking for help to set up the integrand. I can solve the integral myself. Any help would be greatly appreciated.",,"['integration', 'multivariable-calculus', 'spherical-coordinates']"
79,Find $\int_0^\infty \frac{\ln ^2z} {1+z^2}{d}z$ [closed],Find  [closed],\int_0^\infty \frac{\ln ^2z} {1+z^2}{d}z,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question How to find the value of the integral $$\int_{0}^{\infty} \frac{\ln^2z}{1+z^2}{d}z$$ without using contour integration - using usual special functions, e.g. zeta/gamma/beta/etc. Thank you.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question How to find the value of the integral without using contour integration - using usual special functions, e.g. zeta/gamma/beta/etc. Thank you.",\int_{0}^{\infty} \frac{\ln^2z}{1+z^2}{d}z,"['integration', 'definite-integrals', 'special-functions', 'riemann-zeta']"
80,compute one improper integral involving arctangent,compute one improper integral involving arctangent,,"Compute $$\int_{0}^{\infty} \frac{\arctan(ax)}{x(1+x^{2})}dx$$ The answer is: $\frac{\pi}{2}\ln(1+a)$ when $a \geq 0$ $-\frac{\pi}{2}\ln(1-a)$ when $a < 0$ Here is my problem, and I can't even dive into a appropriate first step. The most difficult part is the $\arctan$ which I have no idea to eliminate. Thank you for help.","Compute $$\int_{0}^{\infty} \frac{\arctan(ax)}{x(1+x^{2})}dx$$ The answer is: $\frac{\pi}{2}\ln(1+a)$ when $a \geq 0$ $-\frac{\pi}{2}\ln(1-a)$ when $a < 0$ Here is my problem, and I can't even dive into a appropriate first step. The most difficult part is the $\arctan$ which I have no idea to eliminate. Thank you for help.",,"['integration', 'definite-integrals']"
81,Estimate $\int_0^{\infty} 1/\sqrt{1+x^4} \mathrm{d}x$,Estimate,\int_0^{\infty} 1/\sqrt{1+x^4} \mathrm{d}x,I need an analytical estimation of the following integral: $$\int\limits_0^\infty \frac{{\mathrm{d} x}}{\sqrt{1 + x^4}}$$ It has a root in the denomenator -- so I can't make use of complex residues technique. Edit : Since CAS can do it symbolically -- there's certainly a solution. However I did this analytically a couple of years ago and obtained $$    \frac{\pi}{2^{3/4}}$$ estimation. I remember it was easy and fast estimation. I'm trying to recover it.,I need an analytical estimation of the following integral: $$\int\limits_0^\infty \frac{{\mathrm{d} x}}{\sqrt{1 + x^4}}$$ It has a root in the denomenator -- so I can't make use of complex residues technique. Edit : Since CAS can do it symbolically -- there's certainly a solution. However I did this analytically a couple of years ago and obtained $$    \frac{\pi}{2^{3/4}}$$ estimation. I remember it was easy and fast estimation. I'm trying to recover it.,,"['integration', 'definite-integrals', 'improper-integrals']"
82,show that $\int_{-\infty}^{+\infty} \frac{dx}{(x^2+1)^{n+1}}=\frac {(2n)!\pi}{2^{2n}(n!)^2}$,show that,\int_{-\infty}^{+\infty} \frac{dx}{(x^2+1)^{n+1}}=\frac {(2n)!\pi}{2^{2n}(n!)^2},"show that: $$\int_{-\infty}^{+\infty} \frac{dx}{(x^2+1)^{n+1}}=\frac {(2n)!\pi}{2^{2n}(n!)^2}$$ where $n=0,1,2,3,\ldots$. is there any help? thanks for all","show that: $$\int_{-\infty}^{+\infty} \frac{dx}{(x^2+1)^{n+1}}=\frac {(2n)!\pi}{2^{2n}(n!)^2}$$ where $n=0,1,2,3,\ldots$. is there any help? thanks for all",,"['integration', 'contour-integration']"
83,"What is the integral of $\int e^x\,\sin x\,\,dx$?",What is the integral of ?,"\int e^x\,\sin x\,\,dx","I'm trying to solve the integral of $\left(\int e^x\,\sin x\,\,dx\right)$ (My solution): $\int e^x\sin\left(x\right)\,\,dx=$ $\int \sin\left(x\right) \,e^x\,\,dx=$ $\left(\sin(x)\,\int e^x\right)-\left(\int\sin^{'}(x)\,\left(\int e^x\right)\right)$ $\left(\sin(x)\,e^x\right)-\left(\int\cos(x)\,e^x\right)$ $\left(\sin(x)\,e^x\right)-\left(\cos(x)\,e^x-\left(\int-\sin\left(x\right)\,e^x\right)\right)$ $\left(\sin(x)\,e^x\right)-\left(\cos(x)\,e^x-\left(-\sin\left(x\right)\,e^x-\int-\cos\left(x\right)\,e^x\right)\right)$ I don't know how to complete because the solution gonna be very complicated.","I'm trying to solve the integral of $\left(\int e^x\,\sin x\,\,dx\right)$ (My solution): $\int e^x\sin\left(x\right)\,\,dx=$ $\int \sin\left(x\right) \,e^x\,\,dx=$ $\left(\sin(x)\,\int e^x\right)-\left(\int\sin^{'}(x)\,\left(\int e^x\right)\right)$ $\left(\sin(x)\,e^x\right)-\left(\int\cos(x)\,e^x\right)$ $\left(\sin(x)\,e^x\right)-\left(\cos(x)\,e^x-\left(\int-\sin\left(x\right)\,e^x\right)\right)$ $\left(\sin(x)\,e^x\right)-\left(\cos(x)\,e^x-\left(-\sin\left(x\right)\,e^x-\int-\cos\left(x\right)\,e^x\right)\right)$ I don't know how to complete because the solution gonna be very complicated.",,['integration']
84,Evaluate $ \int^{ \pi/2}_{- \pi/2} \frac {1}{ 1+e^{\sin x} }dx $,Evaluate, \int^{ \pi/2}_{- \pi/2} \frac {1}{ 1+e^{\sin x} }dx ,"Evaluate $ \int^{\pi/2}_{-\pi/2} \frac {1}{ 1+e^{\sin x} }dx $ Solution : I think odd, even functions are of no use here. Also we get nothing by taking $e^{\sin x} $ common in denominator. Also rationalizing  the denominator is of no use. Really I have no idea how to solve this question. Please help.","Evaluate Solution : I think odd, even functions are of no use here. Also we get nothing by taking common in denominator. Also rationalizing  the denominator is of no use. Really I have no idea how to solve this question. Please help.", \int^{\pi/2}_{-\pi/2} \frac {1}{ 1+e^{\sin x} }dx  e^{\sin x} ,"['integration', 'definite-integrals']"
85,Integral $\int_0^2 \frac{\arctan x}{x^2+2x+2}dx$,Integral,\int_0^2 \frac{\arctan x}{x^2+2x+2}dx,I am tring to evaluate $$I=\int_0^2 \frac{\arctan x}{x^2+2x+2}dx$$ The first thing I did was to notice that $$\frac{1}{x^2+2x+2}=\frac{1}{(x+1)^2+1}=\frac{d}{dx}\arctan(x+1)$$ So I integrated by parts in order to get $$I=\arctan 2\arctan 3-\int_0^2\frac{\arctan(x+1)}{1+x^2}dx$$ I let $x=u+1$ but when I do that I get $$I=\arctan 2\arctan 3+\int_{-1}^1\frac{\arctan(u)}{1+(1+u)^2}du    =\arctan 2\arctan 3$$ Now this is not close to the approximation given by wolfram. What have I done wrong and how to solve this?,I am tring to evaluate The first thing I did was to notice that So I integrated by parts in order to get I let but when I do that I get Now this is not close to the approximation given by wolfram. What have I done wrong and how to solve this?,"I=\int_0^2 \frac{\arctan x}{x^2+2x+2}dx \frac{1}{x^2+2x+2}=\frac{1}{(x+1)^2+1}=\frac{d}{dx}\arctan(x+1) I=\arctan 2\arctan 3-\int_0^2\frac{\arctan(x+1)}{1+x^2}dx x=u+1 I=\arctan 2\arctan 3+\int_{-1}^1\frac{\arctan(u)}{1+(1+u)^2}du
   =\arctan 2\arctan 3",['integration']
86,"$\int^\infty_0\frac{x^2e^{-x/y}}y\,dx$",,"\int^\infty_0\frac{x^2e^{-x/y}}y\,dx","I've come across a rather difficult expression to integrate. $$\int^\infty_0\frac{x^2e^{-x/y}}y\,dx$$ Is there an easy way to solve this? I've solved it manually which involved multiple u-subs and integration by parts, and took up a decent amount of my time. This comes from a probability textbook so I doubt they want me to spend so much time solving an integral. The final answer should be $2y^2$.","I've come across a rather difficult expression to integrate. $$\int^\infty_0\frac{x^2e^{-x/y}}y\,dx$$ Is there an easy way to solve this? I've solved it manually which involved multiple u-subs and integration by parts, and took up a decent amount of my time. This comes from a probability textbook so I doubt they want me to spend so much time solving an integral. The final answer should be $2y^2$.",,"['integration', 'definite-integrals']"
87,A generalization for Serret's integral $\int_0^a \frac{\ln(1+ax)}{1+x^2}dx$,A generalization for Serret's integral,\int_0^a \frac{\ln(1+ax)}{1+x^2}dx,"The integral specified in the title appears in Gradshteyn & Ryzhik 4.291.18 , also followed by its sister integral: $$\int_0^a \frac{\ln(1+ax)}{1+x^2}dx=\int_0^a \frac{a\arctan x}{1+ax}dx=\frac12 \arctan a\ln(1+a^2) \tag 1$$ Some application of the above gives us some nice results, such as: $$\int_0^1\frac{\arctan x}x\ln\left(\frac{(1+x^2)^3}{(1+x)^2}\right)dx=0$$ Above follows by converting $\int_0^1 \frac{\arctan x\ln(1+x^2)}{x}dx$ to a double integral using $(1)$ and then swapping the order of the integrals. Or another one: $$\int_0^1 \frac{\arctan x\ln(1+x^2)}{x(1+x)}dx=\frac{\pi^3}{96}-\frac{\pi}{8}\ln^2 2$$ But the question here would be how to prove the result given in $(1)$ ? I tried to differentiate under the integral sign with respect to $a$ , but something nasty appeared. Are there any other ideas?","The integral specified in the title appears in Gradshteyn & Ryzhik 4.291.18 , also followed by its sister integral: Some application of the above gives us some nice results, such as: Above follows by converting to a double integral using and then swapping the order of the integrals. Or another one: But the question here would be how to prove the result given in ? I tried to differentiate under the integral sign with respect to , but something nasty appeared. Are there any other ideas?",\int_0^a \frac{\ln(1+ax)}{1+x^2}dx=\int_0^a \frac{a\arctan x}{1+ax}dx=\frac12 \arctan a\ln(1+a^2) \tag 1 \int_0^1\frac{\arctan x}x\ln\left(\frac{(1+x^2)^3}{(1+x)^2}\right)dx=0 \int_0^1 \frac{\arctan x\ln(1+x^2)}{x}dx (1) \int_0^1 \frac{\arctan x\ln(1+x^2)}{x(1+x)}dx=\frac{\pi^3}{96}-\frac{\pi}{8}\ln^2 2 (1) a,"['integration', 'definite-integrals']"
88,"Prove that $2\int_0^\infty \frac{e^x-x-1}{x(e^{2x}-1)} \, \mathrm{d}x =\ln(\pi)-\gamma $",Prove that,"2\int_0^\infty \frac{e^x-x-1}{x(e^{2x}-1)} \, \mathrm{d}x =\ln(\pi)-\gamma ","Let $\gamma$ be the Euler-Mascheroni constant . I'm trying to prove that $$2\int_0^\infty \frac{e^x-x-1}{x(e^{2x}-1)} \, \mathrm{d}x =\ln(\pi)-\gamma $$ I tried introducing a parameter to the exponent in the numerator and then differentiating under the integral sign. But doing so seems to result in an integral that doesn't converge.","Let $\gamma$ be the Euler-Mascheroni constant . I'm trying to prove that $$2\int_0^\infty \frac{e^x-x-1}{x(e^{2x}-1)} \, \mathrm{d}x =\ln(\pi)-\gamma $$ I tried introducing a parameter to the exponent in the numerator and then differentiating under the integral sign. But doing so seems to result in an integral that doesn't converge.",,"['integration', 'definite-integrals']"
89,Compute definite integral,Compute definite integral,,Question : Compute  $$\int_0^1 \frac{\sqrt{x-x^2}}{x+2}dx.$$ Attempt : I've tried various substitutions with no success. Looked for a possible contour integration by converting this into a rational function of $\sin\theta$ and $\cos \theta$.,Question : Compute  $$\int_0^1 \frac{\sqrt{x-x^2}}{x+2}dx.$$ Attempt : I've tried various substitutions with no success. Looked for a possible contour integration by converting this into a rational function of $\sin\theta$ and $\cos \theta$.,,"['integration', 'complex-analysis', 'definite-integrals', 'contour-integration']"
90,Integral of $\sin(\sqrt{x})$,Integral of,\sin(\sqrt{x}),I need help finding the integral of $\sin(\sqrt{x})dx$. I have the answer here but would like to know how to get there.,I need help finding the integral of $\sin(\sqrt{x})dx$. I have the answer here but would like to know how to get there.,,"['trigonometry', 'integration']"
91,Approximation of log(n!),Approximation of log(n!),,"I just finished calculus 1 (derivative and integral) then I take another course on calculus 2. In the video the professor talks about the the series $$\frac{n!}{(\frac{n}{e})^n}$$ He shows the approximation of the numerator ($n!$) and the denominator ($(\frac{n}{e})^n$) he approximates $\log(n!)$ using $$\sum_{k=1}^n\log(k) \approx \int_1^n\log(x) \text{d}x$$ I'm very curious because I think the $\log(n!)$ is a step function. I tried it with graphing calculator here but it shows continuous function. Is the calculator wrong? Because $n!$ has whole number as a domain so $\log(n!)$ should also be a step function? My second question is can we apply integral to a step function? What is the result different from continuous function, and how can we distinguish. For example when we have $f(x) = x^2$ and we want to do integral with the step domain (whole number) or all the domain? Here is the video (you can go and view it at 2:30) I'm a beginner in this field please explain a step by step and beginner friendly to me.","I just finished calculus 1 (derivative and integral) then I take another course on calculus 2. In the video the professor talks about the the series $$\frac{n!}{(\frac{n}{e})^n}$$ He shows the approximation of the numerator ($n!$) and the denominator ($(\frac{n}{e})^n$) he approximates $\log(n!)$ using $$\sum_{k=1}^n\log(k) \approx \int_1^n\log(x) \text{d}x$$ I'm very curious because I think the $\log(n!)$ is a step function. I tried it with graphing calculator here but it shows continuous function. Is the calculator wrong? Because $n!$ has whole number as a domain so $\log(n!)$ should also be a step function? My second question is can we apply integral to a step function? What is the result different from continuous function, and how can we distinguish. For example when we have $f(x) = x^2$ and we want to do integral with the step domain (whole number) or all the domain? Here is the video (you can go and view it at 2:30) I'm a beginner in this field please explain a step by step and beginner friendly to me.",,"['integration', 'sequences-and-series', 'factorial']"
92,How $dxdy$ becomes $rdrd\theta$ during integration by substitution with polar coordinates,How  becomes  during integration by substitution with polar coordinates,dxdy rdrd\theta,Does anyone know how $dxdy$ becomes $rdrd\theta$ in the example below? I always end up with cosines and sines in the expression no matter how I go about it and I'm not sure  how they are disappearing from the expression.,Does anyone know how becomes in the example below? I always end up with cosines and sines in the expression no matter how I go about it and I'm not sure  how they are disappearing from the expression.,dxdy rdrd\theta,"['integration', 'derivatives', 'substitution', 'multiple-integral']"
93,"Quotient of two integrals $\frac{\int_0^\pi x^3\ln(\sin x)\,dx}{\int_0^\pi x^2\ln(\sqrt{2}(\sin x))\,dx}$",Quotient of two integrals,"\frac{\int_0^\pi x^3\ln(\sin x)\,dx}{\int_0^\pi x^2\ln(\sqrt{2}(\sin x))\,dx}","Calculate $$\frac{\int_0^\pi x^3\ln(\sin x)\,dx}{\int_0^\pi x^2\ln(\sqrt{2}(\sin x))\,dx}$$ In this problem, I'm unable to understand how to start. I tried applying integration by parts but I couldn't solve it. I also tried the various properties of definite integration but they were of no use. Maybe applying integration by parts (or DI method) successively may work but it leads to a form of $\frac{\infty}{\infty}$ .","Calculate In this problem, I'm unable to understand how to start. I tried applying integration by parts but I couldn't solve it. I also tried the various properties of definite integration but they were of no use. Maybe applying integration by parts (or DI method) successively may work but it leads to a form of .","\frac{\int_0^\pi x^3\ln(\sin x)\,dx}{\int_0^\pi x^2\ln(\sqrt{2}(\sin x))\,dx} \frac{\infty}{\infty}","['integration', 'definite-integrals']"
94,How to estimate $\int^{1}_{-1} \left(\frac{\sin{x}}{x}\right)^{300} dx$ to 1 significant figure?,How to estimate  to 1 significant figure?,\int^{1}_{-1} \left(\frac{\sin{x}}{x}\right)^{300} dx,I would like to estimate $\int^{1}_{-1} \left(\frac{\sin{x}}{x}\right)^{300} dx$ to $1$ significant figure. (This question is taken from a quant exam). My (vague) idea is to use Taylor series expansion and to estimate the remainder term. But then I run into problems immediately as I don't see a straightforward way to compute the first few terms of Taylor series for $\left(\frac{\sin{x}}{x}\right)^{300}$... Any ideas?,I would like to estimate $\int^{1}_{-1} \left(\frac{\sin{x}}{x}\right)^{300} dx$ to $1$ significant figure. (This question is taken from a quant exam). My (vague) idea is to use Taylor series expansion and to estimate the remainder term. But then I run into problems immediately as I don't see a straightforward way to compute the first few terms of Taylor series for $\left(\frac{\sin{x}}{x}\right)^{300}$... Any ideas?,,"['integration', 'definite-integrals', 'numerical-methods', 'taylor-expansion', 'approximation']"
95,"Evaluate $\int_0^\pi\frac{\ln\left(1+\cos\theta\right)}{\cos\theta}\,d\theta$",Evaluate,"\int_0^\pi\frac{\ln\left(1+\cos\theta\right)}{\cos\theta}\,d\theta","The problem is to evaluate: $$\int_{0}^{\pi}{\left(\frac{\ln{\left(1+\cos{\theta}\right)}}{\cos{\theta}}\,d\theta\right)}$$ An estimate for the integral is $4.9348022$. There is a similarity between this integral and the dilogarithm function, which is defined by: $$\operatorname{Li}_2(z):=-\int_{0}^{z}{\left(\frac{\ln{\left(1-t\right)}}{t}\,dt\right)}$$ but I am not sure how to use this effectively. In addition, there are two singularities in the interval of integration: one singularity when $\theta\to\pi$ and the integrand increases without bound, and one removable 'hole' at $\theta=\pi/2$, where the limit of the value of the integrand is $1$. Integration by parts does not seem to simplify the integral. I also tried some substitutions, such as $x=\cos{\theta}$: $$\int_{-1}^{1}{\left(\frac{\ln{\left(1+x\right)}}{x\sqrt{1-x^2}}\,dx\right)}$$ which brings it closer to the dilogarithm form. The Weierstrass substitution $x=\tan{\left(\theta/2\right)}$ gives: $$\int_{0}^{\infty}{\left(\frac{2}{1-x^2}\cdot\ln{\left(\frac{2}{1+x^2}\right)}\,dx\right)}$$ Any ideas? Thanks!","The problem is to evaluate: $$\int_{0}^{\pi}{\left(\frac{\ln{\left(1+\cos{\theta}\right)}}{\cos{\theta}}\,d\theta\right)}$$ An estimate for the integral is $4.9348022$. There is a similarity between this integral and the dilogarithm function, which is defined by: $$\operatorname{Li}_2(z):=-\int_{0}^{z}{\left(\frac{\ln{\left(1-t\right)}}{t}\,dt\right)}$$ but I am not sure how to use this effectively. In addition, there are two singularities in the interval of integration: one singularity when $\theta\to\pi$ and the integrand increases without bound, and one removable 'hole' at $\theta=\pi/2$, where the limit of the value of the integrand is $1$. Integration by parts does not seem to simplify the integral. I also tried some substitutions, such as $x=\cos{\theta}$: $$\int_{-1}^{1}{\left(\frac{\ln{\left(1+x\right)}}{x\sqrt{1-x^2}}\,dx\right)}$$ which brings it closer to the dilogarithm form. The Weierstrass substitution $x=\tan{\left(\theta/2\right)}$ gives: $$\int_{0}^{\infty}{\left(\frac{2}{1-x^2}\cdot\ln{\left(\frac{2}{1+x^2}\right)}\,dx\right)}$$ Any ideas? Thanks!",,"['integration', 'definite-integrals']"
96,$\int_{0}^{\infty}{\left(x^3\cdot(e^x-1)^{-1} \right)}dx$,,\int_{0}^{\infty}{\left(x^3\cdot(e^x-1)^{-1} \right)}dx,"In a certain list of exercises, contained the question $$\int_{0}^{\infty}{\left(x^3\cdot(e^x-1)^{-1} \right)}dx$$ How do you solve?","In a certain list of exercises, contained the question $$\int_{0}^{\infty}{\left(x^3\cdot(e^x-1)^{-1} \right)}dx$$ How do you solve?",,"['integration', 'improper-integrals']"
97,show that $\int_{0}^{\pi/2}\ln(\tan x)dx=0$,show that,\int_{0}^{\pi/2}\ln(\tan x)dx=0,show that $$\int_{0}^{\pi/2}\ln(\tan x)dx=0$$ using two ways The first with real analysis and the second with contour integration,show that $$\int_{0}^{\pi/2}\ln(\tan x)dx=0$$ using two ways The first with real analysis and the second with contour integration,,"['integration', 'contour-integration']"
98,Integration exercise: $ \int \frac{e^{5x}}{ (e^{2x} - e^x - 20) }dx$,Integration exercise:, \int \frac{e^{5x}}{ (e^{2x} - e^x - 20) }dx,"I have trouble integrating: $$ \int \frac{e^{5x}}{e^{2x} - e^x - 20} dx$$ With $t=e^x$, I've rewritten it as: $$\int \frac{t^5}{t^2 - t - 20} \frac{1}{t} dt$$ Then I tried integration by parts , but I am not any closer to the solution.","I have trouble integrating: $$ \int \frac{e^{5x}}{e^{2x} - e^x - 20} dx$$ With $t=e^x$, I've rewritten it as: $$\int \frac{t^5}{t^2 - t - 20} \frac{1}{t} dt$$ Then I tried integration by parts , but I am not any closer to the solution.",,['integration']
99,Riemann sum of $\sin(x)$,Riemann sum of,\sin(x),"I would like to calculate the Riemann sum of $\sin(x)$. Fun starts here: $$R = \frac{\pi}{n} \sum_{j=1}^n \sin\left(\frac{\pi}{n}\cdot j\right)$$ What would be the simplest way to calculate the sum of $\sin\left(\frac{\pi}{n}\cdot j\right)$, so that one could proceed to evaluating the limit and thus getting the value of the Riemann sum, in other words - the integral? There maybe a way using $\mathbb{C}$?","I would like to calculate the Riemann sum of $\sin(x)$. Fun starts here: $$R = \frac{\pi}{n} \sum_{j=1}^n \sin\left(\frac{\pi}{n}\cdot j\right)$$ What would be the simplest way to calculate the sum of $\sin\left(\frac{\pi}{n}\cdot j\right)$, so that one could proceed to evaluating the limit and thus getting the value of the Riemann sum, in other words - the integral? There maybe a way using $\mathbb{C}$?",,['sequences-and-series']
