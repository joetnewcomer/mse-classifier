,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"For submersion and submetry,why can we lift a geodesic ""horizontally"" to a geodesic?","For submersion and submetry,why can we lift a geodesic ""horizontally"" to a geodesic?",,"A map $\sigma:X\to Y$ between locally compact complete inner metric spaces is called a submetry if $\sigma(B_r(p))=B_r(\sigma(p))$ for all $r>0$ and $p\in X$. Why is that a geodesic in $Y$ can be lifted ""horizontally"" to a geodesic in $X$. And the case for submersion? The problem lies when we lift a point we don't know where we lift in the fiber.","A map $\sigma:X\to Y$ between locally compact complete inner metric spaces is called a submetry if $\sigma(B_r(p))=B_r(\sigma(p))$ for all $r>0$ and $p\in X$. Why is that a geodesic in $Y$ can be lifted ""horizontally"" to a geodesic in $X$. And the case for submersion? The problem lies when we lift a point we don't know where we lift in the fiber.",,"['geometry', 'differential-geometry', 'geodesic']"
1,How Does A Precessing Sphere Precess?,How Does A Precessing Sphere Precess?,,"In particular, consider a perfectly spherical object or radius $r$, with a certain axis $L$ , and this axis titled relative to a vertical axis by some amount $\theta$. Say that it's ""wobbling"" in a stable, circular manner -- the axis $L$ is revolving around the vertical axis, but comes back to where it started after a revolution. In other words, the sphere looks like this one . My question is, how can I describe the motion of any point on that sphere (assuming it's a perfect sphere)? First, notice that if you look at the bottom-most point of Africa, it rotates in an ellipse counterclockwise. But, the North & South Poles as viewed from the top are rotating clockwise! But if you look at areas around the equator (the green areas of Africa), they seem to have an 8-shaped motion with the smaller circle being formed a the bottom. How can this be? I'm totally mystified. How can different points of the sphere rotate in different directions (and opposite directions, too) in that way? I also imagine that some points from behind the Earth in that video will be rotating clockwise at the same time as Africa is rotating counterclockwise. But then again, it seems like the motions change from upper to lower hemispheres, and the directions seem to be the same in the same hemisphere if you view it overhead. Is there a way for me to know how a certain point is moving? Or is this animation misleading me? This seems to me like a purely mathematical problem if we assume the ideal case.","In particular, consider a perfectly spherical object or radius $r$, with a certain axis $L$ , and this axis titled relative to a vertical axis by some amount $\theta$. Say that it's ""wobbling"" in a stable, circular manner -- the axis $L$ is revolving around the vertical axis, but comes back to where it started after a revolution. In other words, the sphere looks like this one . My question is, how can I describe the motion of any point on that sphere (assuming it's a perfect sphere)? First, notice that if you look at the bottom-most point of Africa, it rotates in an ellipse counterclockwise. But, the North & South Poles as viewed from the top are rotating clockwise! But if you look at areas around the equator (the green areas of Africa), they seem to have an 8-shaped motion with the smaller circle being formed a the bottom. How can this be? I'm totally mystified. How can different points of the sphere rotate in different directions (and opposite directions, too) in that way? I also imagine that some points from behind the Earth in that video will be rotating clockwise at the same time as Africa is rotating counterclockwise. But then again, it seems like the motions change from upper to lower hemispheres, and the directions seem to be the same in the same hemisphere if you view it overhead. Is there a way for me to know how a certain point is moving? Or is this animation misleading me? This seems to me like a purely mathematical problem if we assume the ideal case.",,"['calculus', 'geometry', 'differential-geometry', 'topological-vector-spaces']"
2,Please the Inequality in the proof of The Isoperimetric Inequality,Please the Inequality in the proof of The Isoperimetric Inequality,,"From A proof of the Isoperimetric Inequality , can you please explain the starred inequality $$A + \pi r^2 = \int_{\gamma} x\,dy + \int_C -y\,dx = \int^l_0 x(s)y_s(s)\,ds - \int^l_0 \overline{y}(s)x_s(s)\,ds = $$ $$ = \int^l_0 ( x(s)y_s(s) - \overline{y}(s)x_s(s)) \,ds \le \int^l_0 \sqrt{ (x(s)y_s(s) - \overline{y}(s)x_s(s))^2} \,ds \stackrel{*}{\le}$$ $$ \stackrel{*}{\le} \int^l_0 \sqrt{ (x^2(s) + \overline{y}^2(s))} \,ds = lr$$ Where the starred inequality follows from the fact that: $$(x y_s - \overline{y} x_s)^2 = [(x, - \overline{y}) \cdot (y_s, x_s)]^2 \le (x^2 + \overline{y}^2) \cdot (y^2_s + x^2_s) = x^2 + \overline{y}^2 $$ This is my question: How do you justify this inequality? $$(x y_s - \overline{y} x_s)^2 \le (x^2 + \overline{y}^2) \cdot (y^2_s + x^2_s)$$ If you expand the left and right hand side you get $$ x^2 y_s^2 -2xx_s \overline{y}y_s + \overline{y}^2 x_s^2 \le x^2y_s^2 +x^2 x_s^2 + \overline{y}^2 y_s^2 +\overline{y}^2 x_s^2 $$ So why is  $$ -2xx_s \overline{y}y_s \le x^2 x_s^2 + \overline{y}^2 y_s^2 $$ Thanks in advance!","From A proof of the Isoperimetric Inequality , can you please explain the starred inequality $$A + \pi r^2 = \int_{\gamma} x\,dy + \int_C -y\,dx = \int^l_0 x(s)y_s(s)\,ds - \int^l_0 \overline{y}(s)x_s(s)\,ds = $$ $$ = \int^l_0 ( x(s)y_s(s) - \overline{y}(s)x_s(s)) \,ds \le \int^l_0 \sqrt{ (x(s)y_s(s) - \overline{y}(s)x_s(s))^2} \,ds \stackrel{*}{\le}$$ $$ \stackrel{*}{\le} \int^l_0 \sqrt{ (x^2(s) + \overline{y}^2(s))} \,ds = lr$$ Where the starred inequality follows from the fact that: $$(x y_s - \overline{y} x_s)^2 = [(x, - \overline{y}) \cdot (y_s, x_s)]^2 \le (x^2 + \overline{y}^2) \cdot (y^2_s + x^2_s) = x^2 + \overline{y}^2 $$ This is my question: How do you justify this inequality? $$(x y_s - \overline{y} x_s)^2 \le (x^2 + \overline{y}^2) \cdot (y^2_s + x^2_s)$$ If you expand the left and right hand side you get $$ x^2 y_s^2 -2xx_s \overline{y}y_s + \overline{y}^2 x_s^2 \le x^2y_s^2 +x^2 x_s^2 + \overline{y}^2 y_s^2 +\overline{y}^2 x_s^2 $$ So why is  $$ -2xx_s \overline{y}y_s \le x^2 x_s^2 + \overline{y}^2 y_s^2 $$ Thanks in advance!",,"['differential-geometry', 'inequality']"
3,Smooth retraction onto a differentiable manifold,Smooth retraction onto a differentiable manifold,,"Let $M\subset\mathbb{R}^n$ be a smooth k-dimensional differentiable manifold (by which I mean that it is locally diffeomorphic to an open set in $\mathbb{R}^k$). Let us suppose $M$ compact for simplicity. How can one prove that there exists an open set $U\supset M$ and a smooth retraction of $U$ onto $M$? I heard that it has to do with the smooth dependence on initial conditions of the solution of an ODE.. Can somebody shed light on this? (Remark: clearly $U$ can't be arbitrary, since for example $\mathbb{R}^2$ does not retract onto $S^1$)","Let $M\subset\mathbb{R}^n$ be a smooth k-dimensional differentiable manifold (by which I mean that it is locally diffeomorphic to an open set in $\mathbb{R}^k$). Let us suppose $M$ compact for simplicity. How can one prove that there exists an open set $U\supset M$ and a smooth retraction of $U$ onto $M$? I heard that it has to do with the smooth dependence on initial conditions of the solution of an ODE.. Can somebody shed light on this? (Remark: clearly $U$ can't be arbitrary, since for example $\mathbb{R}^2$ does not retract onto $S^1$)",,"['differential-geometry', 'manifolds']"
4,"Showing that $E=X/{\sim}$ (where $X=[0,1]\times\mathbb{R}^n$) is a smooth vector bundle over $S^1$",Showing that  (where ) is a smooth vector bundle over,"E=X/{\sim} X=[0,1]\times\mathbb{R}^n S^1","I want to show that $E=X/{\sim}$ (where $X=[0,1]\times\mathbb{R}^n$) is the total space of a smooth vector bundle over $S^1$. Here $\sim$ is defined as follows: fix a linear isomorphism $L$ of $\mathbb{R}^n$ and set $(0,v)\sim(1,Lv)$ for all $v\in\mathbb{R}^n$. Here's what I've thought so far and my idea for solving this. There is a smooth map $\pi:E\longrightarrow S^1$ that maps points $[(t,v)]$, $0<t<1$, to points $s(t)\in S^1$, $s(t)\neq \mathbf{1}$, where $\mathbf{1}\in S^1$ is the point where the gluing of $[0,1]$ took place ($s(t)$ is $p(t)$ where $p:[0,1]\longrightarrow S^1$ is just the defining quotient map of $S^1$), and $\pi$ maps $[(0,v)]=[(1,v)]$ to $\mathbf{1}\in S^1$. One local trivialization is the easier one, which is where there is no gluing so basically it is the passage to the quotient of the identity map of $(0,1)\times \mathbb{R}^n$. I'm stuck with the other trivialization. My idea is to construct a map $[0,\epsilon)\cup (1-\epsilon,1]$ into itself such that $(t,v)$ is sent to $(t,L_t v)$ where $L_t$ is a family of isomorphisms that ""approaches $L$"" smoothly as $t\to 0$. Is this a good idea? If so, could you show me how to fill in the details?","I want to show that $E=X/{\sim}$ (where $X=[0,1]\times\mathbb{R}^n$) is the total space of a smooth vector bundle over $S^1$. Here $\sim$ is defined as follows: fix a linear isomorphism $L$ of $\mathbb{R}^n$ and set $(0,v)\sim(1,Lv)$ for all $v\in\mathbb{R}^n$. Here's what I've thought so far and my idea for solving this. There is a smooth map $\pi:E\longrightarrow S^1$ that maps points $[(t,v)]$, $0<t<1$, to points $s(t)\in S^1$, $s(t)\neq \mathbf{1}$, where $\mathbf{1}\in S^1$ is the point where the gluing of $[0,1]$ took place ($s(t)$ is $p(t)$ where $p:[0,1]\longrightarrow S^1$ is just the defining quotient map of $S^1$), and $\pi$ maps $[(0,v)]=[(1,v)]$ to $\mathbf{1}\in S^1$. One local trivialization is the easier one, which is where there is no gluing so basically it is the passage to the quotient of the identity map of $(0,1)\times \mathbb{R}^n$. I'm stuck with the other trivialization. My idea is to construct a map $[0,\epsilon)\cup (1-\epsilon,1]$ into itself such that $(t,v)$ is sent to $(t,L_t v)$ where $L_t$ is a family of isomorphisms that ""approaches $L$"" smoothly as $t\to 0$. Is this a good idea? If so, could you show me how to fill in the details?",,"['differential-geometry', 'differential-topology', 'vector-bundles']"
5,Curvature tensor of 2-sphere using exterior differential forms (tetrads),Curvature tensor of 2-sphere using exterior differential forms (tetrads),,"$ds^2= r^2 (d\theta^2 + \sin^2{\theta}d\phi^2)$ The following is the tetrad basis $e^{\theta}=r d{\theta}  \,\,\,\,\,\,\,\,\,\,    e^{\phi}=r \sin{\theta} d{\phi}$ Hence, $de^{\theta}=0 \,\,\,\,\,\, de^{\phi}=r\cos{\theta} d{\theta} \wedge d\phi = \frac{\cot{\theta}}{r} e^{\theta}\wedge e^{\phi}$ Setting the torsion tensor to zero gives: $de^a + \omega^a _b \wedge e^b =0$. This equation for $a=\theta$ gives $\omega^{\theta}_{\phi}=0$. (I have used $\omega^{\theta}_{\theta}=\omega^{\phi}_{\phi}=0$) The equation for $\phi$:  $\omega^{\phi}_{\theta} \wedge e^{\theta}=\frac{\cot{\theta}}{r} e^{\phi} \wedge e^{\theta} \implies \omega^{\phi}_{\theta}=\frac{\cot{\theta}}{r}=\cos{\theta} d{\phi}$ $d\omega^{\phi}_{\theta}=-\sin{\theta} d\theta \wedge d\phi$ Hence $R^i_j = d\omega^i_j+ \omega^i_b \wedge \omega^b_j$ gives $R^{\phi}_{\theta}=-\sin{\theta} d\theta \wedge d\phi$ and $R^{\theta}_{\phi}=0$ Writing in terms of components gives $R^{\phi}_{\theta \theta \phi}=-\sin{\theta}$, and $R^{\theta}_{\phi \phi \theta}=0$ However this is wrong. I have done the same problem using Christoffel connections, and the answer which I know to be correct is $R^{\phi}_{\theta \theta \phi}=-1$, and $R^{\theta}_{\phi \phi \theta}=\sin^2{\theta}$ Please could anyone tell mw what I am doing wrong? Any help will be appreciated?","$ds^2= r^2 (d\theta^2 + \sin^2{\theta}d\phi^2)$ The following is the tetrad basis $e^{\theta}=r d{\theta}  \,\,\,\,\,\,\,\,\,\,    e^{\phi}=r \sin{\theta} d{\phi}$ Hence, $de^{\theta}=0 \,\,\,\,\,\, de^{\phi}=r\cos{\theta} d{\theta} \wedge d\phi = \frac{\cot{\theta}}{r} e^{\theta}\wedge e^{\phi}$ Setting the torsion tensor to zero gives: $de^a + \omega^a _b \wedge e^b =0$. This equation for $a=\theta$ gives $\omega^{\theta}_{\phi}=0$. (I have used $\omega^{\theta}_{\theta}=\omega^{\phi}_{\phi}=0$) The equation for $\phi$:  $\omega^{\phi}_{\theta} \wedge e^{\theta}=\frac{\cot{\theta}}{r} e^{\phi} \wedge e^{\theta} \implies \omega^{\phi}_{\theta}=\frac{\cot{\theta}}{r}=\cos{\theta} d{\phi}$ $d\omega^{\phi}_{\theta}=-\sin{\theta} d\theta \wedge d\phi$ Hence $R^i_j = d\omega^i_j+ \omega^i_b \wedge \omega^b_j$ gives $R^{\phi}_{\theta}=-\sin{\theta} d\theta \wedge d\phi$ and $R^{\theta}_{\phi}=0$ Writing in terms of components gives $R^{\phi}_{\theta \theta \phi}=-\sin{\theta}$, and $R^{\theta}_{\phi \phi \theta}=0$ However this is wrong. I have done the same problem using Christoffel connections, and the answer which I know to be correct is $R^{\phi}_{\theta \theta \phi}=-1$, and $R^{\theta}_{\phi \phi \theta}=\sin^2{\theta}$ Please could anyone tell mw what I am doing wrong? Any help will be appreciated?",,['differential-geometry']
6,Why is the integral $C^\infty$,Why is the integral,C^\infty,"I am reading Differentiable manifolds from Warner. In order to prove that the dimension of the tangent space is the same as the dimension of the manifold, they use the following calculus lemma - If $g$ is of class $C^k$ ($k \geq 2$) on a convex open subset $U$ about $p$ in $\mathbb{R}^d$, then for each $q \in U$, $g(q)\ =\ g(p) + \sum_{i=1}^d \frac{\partial g}{\partial r_i}|_p (r_i(q)-r_i(p))+\sum_{i,j}(r_i(q)-r_i(p))(r_j(q)-r_j(p))\int_0^1(1-t)\frac{\partial^2g}{\partial r_i\partial r_j}|_{(p+t(q-p))} dt.$ This is the Taylor expansion. It further says, if $g\in C^\infty$, then the integral as a function of $q$ is of class $C^\infty$. How is this? Do we have to use fundamental theorem of calculus or something like that?","I am reading Differentiable manifolds from Warner. In order to prove that the dimension of the tangent space is the same as the dimension of the manifold, they use the following calculus lemma - If $g$ is of class $C^k$ ($k \geq 2$) on a convex open subset $U$ about $p$ in $\mathbb{R}^d$, then for each $q \in U$, $g(q)\ =\ g(p) + \sum_{i=1}^d \frac{\partial g}{\partial r_i}|_p (r_i(q)-r_i(p))+\sum_{i,j}(r_i(q)-r_i(p))(r_j(q)-r_j(p))\int_0^1(1-t)\frac{\partial^2g}{\partial r_i\partial r_j}|_{(p+t(q-p))} dt.$ This is the Taylor expansion. It further says, if $g\in C^\infty$, then the integral as a function of $q$ is of class $C^\infty$. How is this? Do we have to use fundamental theorem of calculus or something like that?",,['differential-geometry']
7,Geodesic and Euler - Lagrange equation,Geodesic and Euler - Lagrange equation,,"If we have a metric $g_{\mu \nu}$, defined in a Riemannian manifold we can write the equation of the geodesic: $$\frac{d^2x^\mu}{dt^2}+\Gamma^\mu_{\alpha\beta}\frac{dx^\alpha}{dt}\frac{dx^\beta}{dt}$$ in which $\Gamma^\mu_{\alpha\beta}$ are the Christoffel symbols. The geodesic in that metric can be obtained also using the Euler - Lagrange equations: $$\frac{d}{dt}\frac{\partial L}{\partial \dot q_k}-\frac{\partial L}{\partial q_k}=0$$ Where the $q_k$ are the generalized coordinates. How can I find the Lagrangian $L$ in order to find the same geodesic obtained using the affine connection symbols?","If we have a metric $g_{\mu \nu}$, defined in a Riemannian manifold we can write the equation of the geodesic: $$\frac{d^2x^\mu}{dt^2}+\Gamma^\mu_{\alpha\beta}\frac{dx^\alpha}{dt}\frac{dx^\beta}{dt}$$ in which $\Gamma^\mu_{\alpha\beta}$ are the Christoffel symbols. The geodesic in that metric can be obtained also using the Euler - Lagrange equations: $$\frac{d}{dt}\frac{\partial L}{\partial \dot q_k}-\frac{\partial L}{\partial q_k}=0$$ Where the $q_k$ are the generalized coordinates. How can I find the Lagrangian $L$ in order to find the same geodesic obtained using the affine connection symbols?",,"['differential-geometry', 'calculus-of-variations']"
8,Question about diffeomorphism,Question about diffeomorphism,,"Here is an assignment problem: $f:\mathbb{S}^2 \longrightarrow \mathbb{S}^2$ is smooth and surjective. Prove $\exists$ open subset $ U $ of $\mathbb{S}^2$, such that $f|_U$ is a diffeomorphism. I've tried to relate it to covering maps but failed. Can someone help me with this problem? Thanks for help.","Here is an assignment problem: $f:\mathbb{S}^2 \longrightarrow \mathbb{S}^2$ is smooth and surjective. Prove $\exists$ open subset $ U $ of $\mathbb{S}^2$, such that $f|_U$ is a diffeomorphism. I've tried to relate it to covering maps but failed. Can someone help me with this problem? Thanks for help.",,"['differential-geometry', 'manifolds']"
9,"Lie subalgebra, Lie subgroup and membership","Lie subalgebra, Lie subgroup and membership",,"Let $G$ be a Lie group with Lie algebra $\mathfrak{g}$ and let $H$ be a connected Lie subgroup with Lie algebra $\mathfrak{h}$. We have that $X \in \mathfrak{h} $ iff $exp(tX) \in H \ \ \  \forall  t \in \mathbb{R} $ . I have seen a proof of this but I don't understand why we need that $\forall t \in \mathbb{R}$.  An answer to this question shows that it is equivalent to ask $\forall t \in \mathbb{R}$ or just in $\forall t \in \, ]-t_0,t_0[$ for some $t_0$. Therefore I'm not worried about ""for all $t$"" versus ""for $t$ small enough"", but about ""for just one $t$"" versus ""for more than one $t$"" (of course $t\neq 0$). I'd like to see an example in which you have some vector $X \in \mathfrak{g}$ such that $exp(X) \in H$ but $X \not \in \mathfrak{h}$. Is this possible?","Let $G$ be a Lie group with Lie algebra $\mathfrak{g}$ and let $H$ be a connected Lie subgroup with Lie algebra $\mathfrak{h}$. We have that $X \in \mathfrak{h} $ iff $exp(tX) \in H \ \ \  \forall  t \in \mathbb{R} $ . I have seen a proof of this but I don't understand why we need that $\forall t \in \mathbb{R}$.  An answer to this question shows that it is equivalent to ask $\forall t \in \mathbb{R}$ or just in $\forall t \in \, ]-t_0,t_0[$ for some $t_0$. Therefore I'm not worried about ""for all $t$"" versus ""for $t$ small enough"", but about ""for just one $t$"" versus ""for more than one $t$"" (of course $t\neq 0$). I'd like to see an example in which you have some vector $X \in \mathfrak{g}$ such that $exp(X) \in H$ but $X \not \in \mathfrak{h}$. Is this possible?",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
10,Boundary orientation for a cylinder,Boundary orientation for a cylinder,,Please help me.I am think that I can use stokes theorem but ı could not apply.This question is very benefical for me to learn the subject please help me :(,Please help me.I am think that I can use stokes theorem but ı could not apply.This question is very benefical for me to learn the subject please help me :(,,"['real-analysis', 'general-topology', 'geometry', 'differential-geometry', 'manifolds']"
11,Why is the differential of a map between manifolds a map between the tangent spaces?,Why is the differential of a map between manifolds a map between the tangent spaces?,,"In the books that I have seen, given a smooth map $\phi: M \rightarrow N$ where $N$ and $M$ are manifolds, the differential at a point $x$ is defined as $d \phi_x: T_x M \rightarrow T_x N$ . Why is it the case that the differential is defined as a map of the tangent spaces? Is it possible to show that this is true taking, for example, the definition of the tangent space of $M$ at $x$ to be $(dF_x)^{-1}(0)$ if $M=F^{-1}(0)$ ? For example, the problem I am working on treats $SO(n, \mathbb{R})$ as a manifold of $M(n, \mathbb{R})$ . Given $w_1, \ldots w_n \in SO(n, \mathbb{R})$ I define the function \begin{align} \varphi: SO(n, \mathbb{R}) &\rightarrow SO(n, \mathbb{R})\\ g & \mapsto gw_1g^{-1}w_1^{-1} \ldots g w_n g^{-1}w_n^{-1} \end{align} I need to show that $d \varphi_I$ (where $I$ is the identity matrix) is a map from $SO(n, \mathbb{R})$ to itself where $SO(n, \mathbb{R})$ is the set of anti-symmetric matrices and is the tangent space of $SO(n, \mathbb{R})$ at $I$ . Thanks in advance.","In the books that I have seen, given a smooth map where and are manifolds, the differential at a point is defined as . Why is it the case that the differential is defined as a map of the tangent spaces? Is it possible to show that this is true taking, for example, the definition of the tangent space of at to be if ? For example, the problem I am working on treats as a manifold of . Given I define the function I need to show that (where is the identity matrix) is a map from to itself where is the set of anti-symmetric matrices and is the tangent space of at . Thanks in advance.","\phi: M \rightarrow N N M x d \phi_x: T_x M \rightarrow T_x N M x (dF_x)^{-1}(0) M=F^{-1}(0) SO(n, \mathbb{R}) M(n, \mathbb{R}) w_1, \ldots w_n \in SO(n, \mathbb{R}) \begin{align}
\varphi: SO(n, \mathbb{R}) &\rightarrow SO(n, \mathbb{R})\\
g & \mapsto gw_1g^{-1}w_1^{-1} \ldots g w_n g^{-1}w_n^{-1}
\end{align} d \varphi_I I SO(n, \mathbb{R}) SO(n, \mathbb{R}) SO(n, \mathbb{R}) I","['differential-geometry', 'manifolds']"
12,When is a topological space a manifold?,When is a topological space a manifold?,,"I'm looking for someone to point me in the direction of papers or books which discuss when a topological space (perhaps with the conditions locally compact, Hausdorff) is a topological manifold, differentiable manifold, etc. This is to say, what work work has been done on necessary conditions for these classifications, knowing very little about the original space?","I'm looking for someone to point me in the direction of papers or books which discuss when a topological space (perhaps with the conditions locally compact, Hausdorff) is a topological manifold, differentiable manifold, etc. This is to say, what work work has been done on necessary conditions for these classifications, knowing very little about the original space?",,"['differential-geometry', 'manifolds', 'differential-topology']"
13,"""WLOG"" when studying Schwarzschild geodesics","""WLOG"" when studying Schwarzschild geodesics",,"Why, when studying geodesics in the Schwarzschild metric, one can WLOG set $$\theta=\frac{\pi}{2}$$? I assume it is so because when digging around the internet, most references seem to consider this particular case... and some actually said ""wlog"". But why? I don't think the motion is necessarily confined to a plane? Correct me if I'm wrong, but isn't the Euler-Lagrange equations for the coordinate $\theta$ $$\ddot\theta +\frac{2\dot r}{r}\dot\theta-\dot\phi\sin\theta\cos\theta=0$$? I don't see why the motion can be ""wlog"" in $\theta=\frac{\pi}{2}$. Thanks.","Why, when studying geodesics in the Schwarzschild metric, one can WLOG set $$\theta=\frac{\pi}{2}$$? I assume it is so because when digging around the internet, most references seem to consider this particular case... and some actually said ""wlog"". But why? I don't think the motion is necessarily confined to a plane? Correct me if I'm wrong, but isn't the Euler-Lagrange equations for the coordinate $\theta$ $$\ddot\theta +\frac{2\dot r}{r}\dot\theta-\dot\phi\sin\theta\cos\theta=0$$? I don't see why the motion can be ""wlog"" in $\theta=\frac{\pi}{2}$. Thanks.",,"['differential-geometry', 'general-relativity']"
14,Trouble with geometrical application of Lagrange multiplier,Trouble with geometrical application of Lagrange multiplier,,"Let $A\in\mathbb R^{n\times n}$ be positive-definite and $\langle Ax,x\rangle=1$ be the equation of an ellipsoid $M\subset\mathbb R^n$. Use Lagrange multipliers to prove that the greatest distance of a point in $M$ to the origin is the smallest eigenvalue of $A$ raised to $-1/2$. $A$ is too general, so I tried using that there is an invertible matrix $P$ such that $D\triangleq PAP^{-1}$ is diagonal to solve the problem with $D$ and then go back to the original problem. For simplicity, I'm maximizing the squared distance, so, with $\tilde x$ being the critical distance, the system of equations is $$\left\{\begin{align} \nabla\|x\|^2&=\lambda\nabla\langle Dx,x\rangle\Leftarrow x=\tilde x\\ \langle D\tilde x,\tilde x\rangle&=1 \end{align}\right.\quad.$$ This is equivalent to  $$\left\{\begin{align} \nabla\left(\sum_{i=1}^n x_i^2\right)&=\lambda\nabla\left(\sum_{i=1}^n\mu_i x_i^2\right)\Leftarrow x=\tilde x\\ \sum_{i=1}^n\mu_i\tilde x_i^2&=1 \end{align}\right.\quad,$$ where $\mu_1,\ldots,\mu_n$ are the diagonal entries of $D$, which are the eigenvalues of $A$. The first equation gives $$2\tilde x_i=2\lambda\mu_i\tilde x_i : i=1,\ldots,n\quad.$$ If every $\tilde x_i$ is zero, the restriction is impossible, because every $\mu_i$ is positive, thus I get the very questionable conclusion that every $\mu_i$ equals $1/\lambda$. What is going on?","Let $A\in\mathbb R^{n\times n}$ be positive-definite and $\langle Ax,x\rangle=1$ be the equation of an ellipsoid $M\subset\mathbb R^n$. Use Lagrange multipliers to prove that the greatest distance of a point in $M$ to the origin is the smallest eigenvalue of $A$ raised to $-1/2$. $A$ is too general, so I tried using that there is an invertible matrix $P$ such that $D\triangleq PAP^{-1}$ is diagonal to solve the problem with $D$ and then go back to the original problem. For simplicity, I'm maximizing the squared distance, so, with $\tilde x$ being the critical distance, the system of equations is $$\left\{\begin{align} \nabla\|x\|^2&=\lambda\nabla\langle Dx,x\rangle\Leftarrow x=\tilde x\\ \langle D\tilde x,\tilde x\rangle&=1 \end{align}\right.\quad.$$ This is equivalent to  $$\left\{\begin{align} \nabla\left(\sum_{i=1}^n x_i^2\right)&=\lambda\nabla\left(\sum_{i=1}^n\mu_i x_i^2\right)\Leftarrow x=\tilde x\\ \sum_{i=1}^n\mu_i\tilde x_i^2&=1 \end{align}\right.\quad,$$ where $\mu_1,\ldots,\mu_n$ are the diagonal entries of $D$, which are the eigenvalues of $A$. The first equation gives $$2\tilde x_i=2\lambda\mu_i\tilde x_i : i=1,\ldots,n\quad.$$ If every $\tilde x_i$ is zero, the restriction is impossible, because every $\mu_i$ is positive, thus I get the very questionable conclusion that every $\mu_i$ equals $1/\lambda$. What is going on?",,"['differential-geometry', 'eigenvalues-eigenvectors', 'lagrange-multiplier']"
15,Finding the degree of a map,Finding the degree of a map,,"I am having trouble computing the degree of a certain map using the fact that $f: N \rightarrow M$ where $M$ and $N$ are both $n$-dimensional manifolds induces a homomorphism between the nth cohomology groups.  Also if there is a more algebraic topology approach as opposed to differential manifolds approach I would be interested in that as well. The map is. Consider the map $f : R^2 \rightarrow R^2$, $f(x, y) = (x^2 - y^2, 2xy).$ Find deg$(f)�.$ Thank you in advance.","I am having trouble computing the degree of a certain map using the fact that $f: N \rightarrow M$ where $M$ and $N$ are both $n$-dimensional manifolds induces a homomorphism between the nth cohomology groups.  Also if there is a more algebraic topology approach as opposed to differential manifolds approach I would be interested in that as well. The map is. Consider the map $f : R^2 \rightarrow R^2$, $f(x, y) = (x^2 - y^2, 2xy).$ Find deg$(f)�.$ Thank you in advance.",,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
16,Regarding the definition of covariant derivative and its use on basis vector fields,Regarding the definition of covariant derivative and its use on basis vector fields,,"we find that for general vector fields ${\mathbf v}= v^ie_i$ and ${\mathbf u}= u^je_j$ we get :$\nabla_{\mathbf v} {\mathbf u} = \nabla_{v^i {\mathbf e}_i} u^j {\mathbf e}_j = v^i \nabla_{{\mathbf e}_i}  u^j{\mathbf e}_j = v^i u^j \nabla_{{\mathbf e}_i} {\mathbf e}_j + v^i {\mathbf e}_j \nabla_{{\mathbf e}_i} u^j = v^i u^j \Gamma^k {}_{i j}{\mathbf e}_k+v^i{\partial u^j\over\partial x^i} {\mathbf e}_j $ so   $ \nabla_{\mathbf v} {\mathbf u} = \left(v^i u^j \Gamma^k {}_{i j}+v^i{\partial u^k\over\partial x^i}\right){\mathbf e}_k$ First of all, in $v^i u^j \nabla_{{\mathbf e}_i} {\mathbf e}_j + v^i {\mathbf e}_j \nabla_{{\mathbf e}_i} u^j = v^i u^j \Gamma^k {}_{i j}{\mathbf e}_k+v^i{\partial u^j\over\partial x^i} {\mathbf e}_j $, ${\mathbf e}_j \nabla_{{\mathbf e}_i} u^j$ seems to equal to ${\partial u^j\over\partial x^i} {\mathbf e}_j $, and that seems to mean that $\mathbf{e}_j$ commutes with covariant derivative part (or here it equals to partial derivative part.). But this seems to be clearly wrong... Secondly, for $ \nabla_{\mathbf v} {\mathbf u} = \left(v^i u^j \Gamma^k {}_{i j}+v^i{\partial u^k\over\partial x^i}\right){\mathbf e}_k$ part, it seems that $\mathbf{e}_j$ part was switched with $\mathbf{e}_k$, but is this allowed? why is it?","we find that for general vector fields ${\mathbf v}= v^ie_i$ and ${\mathbf u}= u^je_j$ we get :$\nabla_{\mathbf v} {\mathbf u} = \nabla_{v^i {\mathbf e}_i} u^j {\mathbf e}_j = v^i \nabla_{{\mathbf e}_i}  u^j{\mathbf e}_j = v^i u^j \nabla_{{\mathbf e}_i} {\mathbf e}_j + v^i {\mathbf e}_j \nabla_{{\mathbf e}_i} u^j = v^i u^j \Gamma^k {}_{i j}{\mathbf e}_k+v^i{\partial u^j\over\partial x^i} {\mathbf e}_j $ so   $ \nabla_{\mathbf v} {\mathbf u} = \left(v^i u^j \Gamma^k {}_{i j}+v^i{\partial u^k\over\partial x^i}\right){\mathbf e}_k$ First of all, in $v^i u^j \nabla_{{\mathbf e}_i} {\mathbf e}_j + v^i {\mathbf e}_j \nabla_{{\mathbf e}_i} u^j = v^i u^j \Gamma^k {}_{i j}{\mathbf e}_k+v^i{\partial u^j\over\partial x^i} {\mathbf e}_j $, ${\mathbf e}_j \nabla_{{\mathbf e}_i} u^j$ seems to equal to ${\partial u^j\over\partial x^i} {\mathbf e}_j $, and that seems to mean that $\mathbf{e}_j$ commutes with covariant derivative part (or here it equals to partial derivative part.). But this seems to be clearly wrong... Secondly, for $ \nabla_{\mathbf v} {\mathbf u} = \left(v^i u^j \Gamma^k {}_{i j}+v^i{\partial u^k\over\partial x^i}\right){\mathbf e}_k$ part, it seems that $\mathbf{e}_j$ part was switched with $\mathbf{e}_k$, but is this allowed? why is it?",,"['differential-geometry', 'tensors']"
17,Extensions of Carathéodory's theorem,Extensions of Carathéodory's theorem,,"We know about the Carathéodory's theorem which is on the convex bodies of $\mathbb{R}^d$. My question is, how far we can extend it? Is it true for say, any convex object of Banach space, or for convex objects of any real manifold? I believe the answers are negative. However I want to know whether there is a similar result like Carathéodory (i.e. an upper bound with respect to dimension of the space/manifold). Advanced thanks for any help/suggestion/reference which can be (relatively) easily understood. Feel free to ask (and also edit) if you want more clarification.","We know about the Carathéodory's theorem which is on the convex bodies of $\mathbb{R}^d$. My question is, how far we can extend it? Is it true for say, any convex object of Banach space, or for convex objects of any real manifold? I believe the answers are negative. However I want to know whether there is a similar result like Carathéodory (i.e. an upper bound with respect to dimension of the space/manifold). Advanced thanks for any help/suggestion/reference which can be (relatively) easily understood. Feel free to ask (and also edit) if you want more clarification.",,"['differential-geometry', 'banach-spaces', 'convex-analysis']"
18,Bullseye-shaped interference pattern in seminar-room chair,Bullseye-shaped interference pattern in seminar-room chair,,"During a break n a seminar today, I noticed that the chairs in front of me all had slightly transparent black mesh fabric. The backs of the chairs were in the shape of a hyperbolic paraboloid. The fabric covering it had two layers a couple of centimeters apart (it was just a fabric sheath over a frame), and the mesh was a hexagonal tiling with hole size approximately equal to thread size, both small. I noticed that the interference between the two meshes made a bullseye pattern. The circles in the bullseye moved inwards or outwards as I moved my head, but the center of the bullseye seemed to be constantly at the critical point of the hyperbolic paraboloid (although I couldn't move my head much from side to side). Why did this shape appear?","During a break n a seminar today, I noticed that the chairs in front of me all had slightly transparent black mesh fabric. The backs of the chairs were in the shape of a hyperbolic paraboloid. The fabric covering it had two layers a couple of centimeters apart (it was just a fabric sheath over a frame), and the mesh was a hexagonal tiling with hole size approximately equal to thread size, both small. I noticed that the interference between the two meshes made a bullseye pattern. The circles in the bullseye moved inwards or outwards as I moved my head, but the center of the bullseye seemed to be constantly at the critical point of the hyperbolic paraboloid (although I couldn't move my head much from side to side). Why did this shape appear?",,"['geometry', 'differential-geometry', 'physics']"
19,How can I show that the Mercator projection is in the sphere,How can I show that the Mercator projection is in the sphere,,"Define a function $f: \Bbb R×(0,2 \pi) \to \Bbb R^3$ (Mercator projection) by: $$f(u,\theta) = {1 \over {\cosh\,\, u} }\begin{pmatrix}\cos\,\, \theta\\\sin\,\, \theta\\\sinh\,\, u\end{pmatrix} $$ How can I show that $f(u,\theta)$ is in the sphere $S$ (given by the equation $x^2+y^2+z^2=1$)?","Define a function $f: \Bbb R×(0,2 \pi) \to \Bbb R^3$ (Mercator projection) by: $$f(u,\theta) = {1 \over {\cosh\,\, u} }\begin{pmatrix}\cos\,\, \theta\\\sin\,\, \theta\\\sinh\,\, u\end{pmatrix} $$ How can I show that $f(u,\theta)$ is in the sphere $S$ (given by the equation $x^2+y^2+z^2=1$)?",,['differential-geometry']
20,Doubt about the Domain of the chart on a Manifold,Doubt about the Domain of the chart on a Manifold,,"I have a doubt about the domain of the chart on a manifold. Suppose $M$ is a smooth manifold and that $(U, \varphi)$ is a chart on $M$, then $\varphi : U \to \mathbb{R}^n$ has $U$ as it's domain. That's fine to me. My doubt has to do with the comparison of this to the case of regular surfaces in $\mathbb{R}^3$. In that case, the surface $S$ is a subset of $\mathbb{R}^3$ and so, if $(V, \psi)$ is a chart on $S$, then I know that $\psi$ takes points in $\mathbb{R}^3$ and takes to $\mathbb{R}^2$. In other, words, I know that I can write: $$(u,v)=\psi(x_1,x_2,x_3)$$ And so, I know many things, for instance, I know that to build the chart I'll need to find one expression of $x_1, x_2,x_3$ which gives $(u,v)$ respecting the properties required. On general Manifolds, however, I feel a little confused. I mean, the manifold isn't inside another higher dimensional ambient space, so, if $(U, \varphi)$ is a chart, I would have: $$(x^1, \dots, x^n) = \varphi(\text{what goes here ?})$$ And the $\text{what goes here ?}$ is because if I plug there some $m$-tuple of numbers, I'm supposing that $M$ is a subset of $\mathbb{R}^m$ and that supposition shouldn't be necessary. I've read for instance, that to find charts for the $n$-sphere, we can consider it as a subset of $\mathbb{R}^{n+1}$, but that isn't really necessary. My point is, I know that elements of the codomain of a map of a chart will be $n$-tuples of numbers, that's fine, I know how to work with such objects. But how will be the elements of the domain, if we do not express the manifold as a subset of a higher dimensional ambient space? I think I've made clear my point. If I've failed to explain my doubt, please ask and I'll try to explain better. Thanks very much in advance! EDIT: The definition of Manifold I'm working with is the definition as presented by Manfredo Do Carmo: A smooth manifold of dimension $n$ is a set $M$ with a family of bijective maps $\varphi_\alpha : U_\alpha \to M$ from open sets $U_\alpha\subset \mathbb{R}^n$ to $M$ such that: $\bigcup_\alpha\varphi_\alpha(U_\alpha)=M$ For each pair $\alpha, \beta$ with $\varphi_\alpha(U_\alpha)\cap\varphi_\beta(U_\beta)=W\neq\emptyset$ we have $\varphi_\alpha^{-1}(W)$, $\varphi_\beta^{-1}(W)$ open in $\mathbb{R}^n$ and $\varphi_\beta^{-1}\circ\varphi_\alpha$, $\varphi_\alpha^{-1}\circ\varphi_\beta$ are differentiable. The family $\left\{U_\alpha, \varphi_\alpha\right\}$ is maximum with respect to conditions 1 and 2. The only point is that on my text above, I've decided to change the direction of the maps, but the definition is yet that one.","I have a doubt about the domain of the chart on a manifold. Suppose $M$ is a smooth manifold and that $(U, \varphi)$ is a chart on $M$, then $\varphi : U \to \mathbb{R}^n$ has $U$ as it's domain. That's fine to me. My doubt has to do with the comparison of this to the case of regular surfaces in $\mathbb{R}^3$. In that case, the surface $S$ is a subset of $\mathbb{R}^3$ and so, if $(V, \psi)$ is a chart on $S$, then I know that $\psi$ takes points in $\mathbb{R}^3$ and takes to $\mathbb{R}^2$. In other, words, I know that I can write: $$(u,v)=\psi(x_1,x_2,x_3)$$ And so, I know many things, for instance, I know that to build the chart I'll need to find one expression of $x_1, x_2,x_3$ which gives $(u,v)$ respecting the properties required. On general Manifolds, however, I feel a little confused. I mean, the manifold isn't inside another higher dimensional ambient space, so, if $(U, \varphi)$ is a chart, I would have: $$(x^1, \dots, x^n) = \varphi(\text{what goes here ?})$$ And the $\text{what goes here ?}$ is because if I plug there some $m$-tuple of numbers, I'm supposing that $M$ is a subset of $\mathbb{R}^m$ and that supposition shouldn't be necessary. I've read for instance, that to find charts for the $n$-sphere, we can consider it as a subset of $\mathbb{R}^{n+1}$, but that isn't really necessary. My point is, I know that elements of the codomain of a map of a chart will be $n$-tuples of numbers, that's fine, I know how to work with such objects. But how will be the elements of the domain, if we do not express the manifold as a subset of a higher dimensional ambient space? I think I've made clear my point. If I've failed to explain my doubt, please ask and I'll try to explain better. Thanks very much in advance! EDIT: The definition of Manifold I'm working with is the definition as presented by Manfredo Do Carmo: A smooth manifold of dimension $n$ is a set $M$ with a family of bijective maps $\varphi_\alpha : U_\alpha \to M$ from open sets $U_\alpha\subset \mathbb{R}^n$ to $M$ such that: $\bigcup_\alpha\varphi_\alpha(U_\alpha)=M$ For each pair $\alpha, \beta$ with $\varphi_\alpha(U_\alpha)\cap\varphi_\beta(U_\beta)=W\neq\emptyset$ we have $\varphi_\alpha^{-1}(W)$, $\varphi_\beta^{-1}(W)$ open in $\mathbb{R}^n$ and $\varphi_\beta^{-1}\circ\varphi_\alpha$, $\varphi_\alpha^{-1}\circ\varphi_\beta$ are differentiable. The family $\left\{U_\alpha, \varphi_\alpha\right\}$ is maximum with respect to conditions 1 and 2. The only point is that on my text above, I've decided to change the direction of the maps, but the definition is yet that one.",,"['differential-geometry', 'manifolds']"
21,What is a tangential gradient?,What is a tangential gradient?,,"If $\mathbb{R}_{+}^{n}$ is the half space $\{x\in\mathbb{R}^n\vert\ x_n>0\}$ and $u$ is a twice differentiable function in $\mathbb{R}^{n}$. If we write:  \begin{equation} Du(x)=\left(\frac{\partial u(x)}{\partial x_1},\dots,\frac{\partial u(x)}{\partial x_n}\right)^T\quad\text{for}  \ x\in\partial\mathbb{R}_{+}^{n}, \end{equation} then what does it mean to say that $\left(\frac{\partial u(x)}{\partial x_1},\dots,\frac{\partial u(x)}{\partial x_{n-1}}\right)^T$ is the tangential gradient?","If $\mathbb{R}_{+}^{n}$ is the half space $\{x\in\mathbb{R}^n\vert\ x_n>0\}$ and $u$ is a twice differentiable function in $\mathbb{R}^{n}$. If we write:  \begin{equation} Du(x)=\left(\frac{\partial u(x)}{\partial x_1},\dots,\frac{\partial u(x)}{\partial x_n}\right)^T\quad\text{for}  \ x\in\partial\mathbb{R}_{+}^{n}, \end{equation} then what does it mean to say that $\left(\frac{\partial u(x)}{\partial x_1},\dots,\frac{\partial u(x)}{\partial x_{n-1}}\right)^T$ is the tangential gradient?",,"['differential-geometry', 'partial-differential-equations', 'definition']"
22,Show that we can define a connection on any manifold using partitions of unity,Show that we can define a connection on any manifold using partitions of unity,,"Suppose that $(U,\varphi)$ is a chart on manifold $M$, and $X,V$ are vector fields on manifold $M$, then we can write: $$X=\sum_{i=1}^{i=n}X^{i}\frac{\partial}{\partial x^{i}}$$ on $U$, and define a connection on $U$ by: $$D_{V}X=\sum_{i=1}^{i=n}(VX^{i})\frac{\partial}{\partial x^{i}}\cdots\tag{1}$$ Let $\{U_{j}\}_{j=1}^{\infty}$ be a locally finite covering of $M$, where each $U_{j}$ is coordinate neighborhood on $M$. Let $D^{j}$ be the connection on $U_{j}$ defined by (1) respectively . and let $\{f_{j}\}$ be the partitions of unity on $M$ that are subordinate to $\{U_{j}\}$. Show that: $\sum_{j=1}^{\infty}f_{j}D^{j}$ is a connection on $M$. Another question: suppose  $X,V$ are two vcetor fields on manifold $M$, with the connection $\sum_{j=1}^{\infty}$ $f_{j}D^{j}$ defined above, how do we know that the new vector field $(\sum_{j=1}^{\infty}f_{j}D^{j})_{V}X$ is well defined on some intersections of the coordinate neighborhood, say $U_{j_{1}}$ and $U_{j_{2}}$ .","Suppose that $(U,\varphi)$ is a chart on manifold $M$, and $X,V$ are vector fields on manifold $M$, then we can write: $$X=\sum_{i=1}^{i=n}X^{i}\frac{\partial}{\partial x^{i}}$$ on $U$, and define a connection on $U$ by: $$D_{V}X=\sum_{i=1}^{i=n}(VX^{i})\frac{\partial}{\partial x^{i}}\cdots\tag{1}$$ Let $\{U_{j}\}_{j=1}^{\infty}$ be a locally finite covering of $M$, where each $U_{j}$ is coordinate neighborhood on $M$. Let $D^{j}$ be the connection on $U_{j}$ defined by (1) respectively . and let $\{f_{j}\}$ be the partitions of unity on $M$ that are subordinate to $\{U_{j}\}$. Show that: $\sum_{j=1}^{\infty}f_{j}D^{j}$ is a connection on $M$. Another question: suppose  $X,V$ are two vcetor fields on manifold $M$, with the connection $\sum_{j=1}^{\infty}$ $f_{j}D^{j}$ defined above, how do we know that the new vector field $(\sum_{j=1}^{\infty}f_{j}D^{j})_{V}X$ is well defined on some intersections of the coordinate neighborhood, say $U_{j_{1}}$ and $U_{j_{2}}$ .",,"['differential-geometry', 'differential-topology']"
23,Why Can't we define the differentiation of vector fields in the same way as in $\mathbb{R^{n}}$,Why Can't we define the differentiation of vector fields in the same way as in,\mathbb{R^{n}},"In $\mathbb{R^{n}}$, if $X$ is a vector field on $\mathbb{R^{n}}$, and $X=$$\sum_{i=1}^{i=n}$ $X^{i}$ $\frac{\partial}{\partial x^{i}}$, $X^{i}$ $\in$$C^{\infty}(p)$. Then 1. The differentiation of vector fields $X$ along a given vector $v$ $\in$ $T_{p}(\mathbb{R^{n}})$,denoted by $D_{v}X$ ,can be defined as : $D_{v}X$ = $\sum_{i=1}^{i=n}$ $(D_{v}X^{i})$ $\frac{\partial}{\partial x^{i}}$ , where $D_{v}X^{i}$ is just the directional derivative in the common sense. 2.Given two vector fields on $\mathbb{R^{n}}$ , X and V , we can define a new vector field $D_{V}X$ on $\mathbb{R^{n}}$ as: $(D_{V}X)(p)$ = $D_{V(p)}X$ , where $D_{V(p)}X$ is defeined as above. So my question is that :can we do the same thing to abstract manifolds ,namely,given two vector fields  X and V on manifold  M ,we get a new vector field $D_{V}X$ in the way listed above. PS:I have been told that the answer is no ,because the new vector field $D_{V}X$ can not be defined globaly .But I don't know the reason. Thanks very much in advance.","In $\mathbb{R^{n}}$, if $X$ is a vector field on $\mathbb{R^{n}}$, and $X=$$\sum_{i=1}^{i=n}$ $X^{i}$ $\frac{\partial}{\partial x^{i}}$, $X^{i}$ $\in$$C^{\infty}(p)$. Then 1. The differentiation of vector fields $X$ along a given vector $v$ $\in$ $T_{p}(\mathbb{R^{n}})$,denoted by $D_{v}X$ ,can be defined as : $D_{v}X$ = $\sum_{i=1}^{i=n}$ $(D_{v}X^{i})$ $\frac{\partial}{\partial x^{i}}$ , where $D_{v}X^{i}$ is just the directional derivative in the common sense. 2.Given two vector fields on $\mathbb{R^{n}}$ , X and V , we can define a new vector field $D_{V}X$ on $\mathbb{R^{n}}$ as: $(D_{V}X)(p)$ = $D_{V(p)}X$ , where $D_{V(p)}X$ is defeined as above. So my question is that :can we do the same thing to abstract manifolds ,namely,given two vector fields  X and V on manifold  M ,we get a new vector field $D_{V}X$ in the way listed above. PS:I have been told that the answer is no ,because the new vector field $D_{V}X$ can not be defined globaly .But I don't know the reason. Thanks very much in advance.",,"['differential-geometry', 'manifolds', 'definition']"
24,Induced sequence of global sections,Induced sequence of global sections,,I'm reading Differential Analysis on Complex Manifolds by Raymond O. Wells. It states the following in the beginning of section 3 of chapter 2 on page 51: Consider a short exact sequence of sheaves: $$0 \to \mathcal{A} \to \mathcal{B} \to \mathcal{C} \to 0$$ Then it is easy to verify that the induced sequence $$0 \to \mathcal{A}(X) \to \mathcal{B}(X) \to \mathcal{C}(X) \to 0$$ is exact at $\mathcal{A}(X)$ and $\mathcal{B}(X)$ but not necessarily at $\mathcal{C}(X)$. After that they give an example of failing exactness at $\mathcal{C}(X)$. My problem is that Ii dont see why the induced sequence has to be exact at $\mathcal{A}(X)$ and $\mathcal{B}(X)$. I tried to find an answer in other books. In the book Sheaf Theory by Bredon they make the same statement in proposition 2.2 but they also state it is easy to verify. I tried to come up with an argument of my own and got something like this (the argument is wrong i think): If we have the zero element  $0 \in \mathcal{B}(X)$ this should induce a section $\tilde{0} $ of the stalks of $\mathcal{B}$ and should take the value of the zero element in every stalk. Then since the sequence of sheaves is exact (and thus exact in stalk level) we get that around every $x \in X$ there should be an open $V$ such that $\tilde{0}|_{V}$ is the image of the zero section in $\mathcal{A}(V)$ and since $\mathcal{A}$ is a sheaf we can patch these together to get a global zero section. Also while i get the example that shows inexactness at $\mathcal{C}(X)$ i dont get why this should generally be the case. Any help would be much appreciated,I'm reading Differential Analysis on Complex Manifolds by Raymond O. Wells. It states the following in the beginning of section 3 of chapter 2 on page 51: Consider a short exact sequence of sheaves: $$0 \to \mathcal{A} \to \mathcal{B} \to \mathcal{C} \to 0$$ Then it is easy to verify that the induced sequence $$0 \to \mathcal{A}(X) \to \mathcal{B}(X) \to \mathcal{C}(X) \to 0$$ is exact at $\mathcal{A}(X)$ and $\mathcal{B}(X)$ but not necessarily at $\mathcal{C}(X)$. After that they give an example of failing exactness at $\mathcal{C}(X)$. My problem is that Ii dont see why the induced sequence has to be exact at $\mathcal{A}(X)$ and $\mathcal{B}(X)$. I tried to find an answer in other books. In the book Sheaf Theory by Bredon they make the same statement in proposition 2.2 but they also state it is easy to verify. I tried to come up with an argument of my own and got something like this (the argument is wrong i think): If we have the zero element  $0 \in \mathcal{B}(X)$ this should induce a section $\tilde{0} $ of the stalks of $\mathcal{B}$ and should take the value of the zero element in every stalk. Then since the sequence of sheaves is exact (and thus exact in stalk level) we get that around every $x \in X$ there should be an open $V$ such that $\tilde{0}|_{V}$ is the image of the zero section in $\mathcal{A}(V)$ and since $\mathcal{A}$ is a sheaf we can patch these together to get a global zero section. Also while i get the example that shows inexactness at $\mathcal{C}(X)$ i dont get why this should generally be the case. Any help would be much appreciated,,"['differential-geometry', 'sheaf-theory', 'homology-cohomology']"
25,"Find point $X$ such that line through plane $E$ and sphere $S$ meet at $(0,0,1)$ (stereographic projection)",Find point  such that line through plane  and sphere  meet at  (stereographic projection),"X E S (0,0,1)","Find the point $X$ such that the line going through the plane $E$ and sphere $S$ meet at the point $(0,0,1)$ (stereographic projection). Let $S$ denote the unit sphere $$S = \{(x,y,z) \in \mathbb{R}^3 \mid x^2 + y^2 + z^2 = 1\}$$ and $E$ denote the plane in $\mathbb{R}^3$ given by $z = 0$ $$E = \{(x,y,z) \in \mathbb{R}^3 \mid z = 0\}.$$ If $(u,v,0)$ is a point of $E$ then the line joining  $(u,v,0)$ to $(0,0,1)$ meets $S$  in a point other than  $(0,0,1)$. Denote this point by $X(u,v)$. 1) Compute the formula for $X$. [HINT: Any point on the line joining $(u,v,0)$ and $(0,0,1)$ is of the form $\lambda \cdot (u,v,0) + (1 - \lambda) \cdot (0,0,1)$ for some $\lambda \in \mathbb{R}$. We need to determine such $\lambda_0 \in \mathbb{R}$ that $X(u,v) = \lambda_0 \cdot (u,v,0) + (1 - \lambda_0) \cdot (0,0,1)$ lies on $S$.] For this bit, I said using the fact that $$\pmatrix{x\\y\\x} = \lambda_0 \cdot \pmatrix{u \\ v \\ 0} + (1 - \lambda_0)\cdot \pmatrix{0 \\ 0 \\ 1},$$ we get $$x = \lambda_0 \cdot u$$ $$y = \lambda_0 \cdot v$$ $$z = 1 - \lambda_ 0.$$ Putting it in $x^2 + y^2 + z^2 = 1$ and solving gives us $\lambda_0 = 0, \frac{2}{1 + u^2 + v^2}$. When $\lambda_0 = 0$, we get the point $(0,0,1)$, and according to the question the point that meets $S$ but isn't $(0,0,1)$ and so we pick $\lambda_0 = \frac{2}{1 + u^2 + v^2}$. So we end up getting $$X(u,v) = \left( \frac{2u}{1 + u^2 + v^2}, \frac{2v}{1 + u^2 + v^2}, 1 - \frac{2}{1 + u^2 + v^2}\right).$$ 2) Show that the map $X: \mathbb{r}^2 \rightarrow \mathbb{R}^3$ determines a refular surface patch. [HINT: Prove that $X_u \circ X_v = 0$, then show that $a \circ b = $ implies that the vectors $a$ and $b$ are linearly independent] Here $a \circ b$ is the dot product between $a$ and $b$ and $X_u$ is the partial derivative of $X$ with respect to $u$. So the first thing to do was the partial derivatives and I got them to be $$X_u = \left(\frac{2}{1 + u^2 + v^2} - \frac{4u^2}{(1 + u^2 + v^2)^2}, -\frac{4uv}{(1 + u^2 + v^2)^2}, \frac{4u}{(1 + u^2 + v^2)^2} \right)$$ $$X_v = \left( -\frac{4uv}{(1 + u^2 + v^2)^2}, \frac{2}{(1 + u^2 + v^2)} - \frac{4v^2}{(1 + u^2 + v^2)^2}, \frac{4v}{(1 + u^2 + v^2)^2} \right)$$ but when I then do the dot product, I don't get them to be $0$. I get it to be $$\left(\frac{2}{1 + u^2 + v^2} - \frac{4u^2}{(1 + u^2 + v^2)^2} \right) \cdot \left( -\frac{4uv}{(1 + u^2 + v^2)^2} \right) + \left(-\frac{4uv}{(1 + u^2 + v^2)^2} \right) \cdot \left(\frac{2}{(1 + u^2 + v^2)} - \frac{4v^2}{(1 + u^2 + v^2)^2} \right) + \left(\frac{4u}{(1 + u^2 + v^2)^2} \right) \cdot \left(\frac{4v}{(1 + u^2 + v^2)^2} \right),$$ which gives me $$\frac{16u^3v}{(1 + u^2 + v^2)^4} - \frac{8uv}{(1 + u^2 + v^2)^3} + \frac{16v^3u}{(1 + u^2 + v^2)^4} - \frac{8uv}{(1 + u^2 + v^2)^3} + \frac{16uv}{(1 + u^2 + v^2)^4}$$ $$ = \frac{16u^3v}{(1 + u^2 + v^2)^4}+ \frac{16v^3u}{(1 + u^2 + v^2)^4} - \frac{16uv}{(1 + u^2 + v^2)^3} + \frac{16uv}{(1 + u^2 + v^2)^4} \neq 0$$ Where am I making my mistake? 3) How much of the sphere is covered by the parametrization $X$? I also haven't got a clue how to do this bit. Maybe once I sort the first two parts out, I might get an idea. EDIT: Also, I'm thinking that my $X$ is wrong as when I do $x^2 + y^2 + z^2$, I don't get it to equal $1$. I'm not sure if it should or not. If it did, then it would lie on the surface of the sphere and not inside it. The question doesn't necasarrily say that it needs to lie on the surface, but I thought if I used the constraint $x^2 + y^2 + z^2 = 1$ then I've moved to the point on the line that does lie on the surface and so I should get $x^2 + y^2 + z^2 = 1$ for my $x,y,z$ coordinates for $X$, right?","Find the point $X$ such that the line going through the plane $E$ and sphere $S$ meet at the point $(0,0,1)$ (stereographic projection). Let $S$ denote the unit sphere $$S = \{(x,y,z) \in \mathbb{R}^3 \mid x^2 + y^2 + z^2 = 1\}$$ and $E$ denote the plane in $\mathbb{R}^3$ given by $z = 0$ $$E = \{(x,y,z) \in \mathbb{R}^3 \mid z = 0\}.$$ If $(u,v,0)$ is a point of $E$ then the line joining  $(u,v,0)$ to $(0,0,1)$ meets $S$  in a point other than  $(0,0,1)$. Denote this point by $X(u,v)$. 1) Compute the formula for $X$. [HINT: Any point on the line joining $(u,v,0)$ and $(0,0,1)$ is of the form $\lambda \cdot (u,v,0) + (1 - \lambda) \cdot (0,0,1)$ for some $\lambda \in \mathbb{R}$. We need to determine such $\lambda_0 \in \mathbb{R}$ that $X(u,v) = \lambda_0 \cdot (u,v,0) + (1 - \lambda_0) \cdot (0,0,1)$ lies on $S$.] For this bit, I said using the fact that $$\pmatrix{x\\y\\x} = \lambda_0 \cdot \pmatrix{u \\ v \\ 0} + (1 - \lambda_0)\cdot \pmatrix{0 \\ 0 \\ 1},$$ we get $$x = \lambda_0 \cdot u$$ $$y = \lambda_0 \cdot v$$ $$z = 1 - \lambda_ 0.$$ Putting it in $x^2 + y^2 + z^2 = 1$ and solving gives us $\lambda_0 = 0, \frac{2}{1 + u^2 + v^2}$. When $\lambda_0 = 0$, we get the point $(0,0,1)$, and according to the question the point that meets $S$ but isn't $(0,0,1)$ and so we pick $\lambda_0 = \frac{2}{1 + u^2 + v^2}$. So we end up getting $$X(u,v) = \left( \frac{2u}{1 + u^2 + v^2}, \frac{2v}{1 + u^2 + v^2}, 1 - \frac{2}{1 + u^2 + v^2}\right).$$ 2) Show that the map $X: \mathbb{r}^2 \rightarrow \mathbb{R}^3$ determines a refular surface patch. [HINT: Prove that $X_u \circ X_v = 0$, then show that $a \circ b = $ implies that the vectors $a$ and $b$ are linearly independent] Here $a \circ b$ is the dot product between $a$ and $b$ and $X_u$ is the partial derivative of $X$ with respect to $u$. So the first thing to do was the partial derivatives and I got them to be $$X_u = \left(\frac{2}{1 + u^2 + v^2} - \frac{4u^2}{(1 + u^2 + v^2)^2}, -\frac{4uv}{(1 + u^2 + v^2)^2}, \frac{4u}{(1 + u^2 + v^2)^2} \right)$$ $$X_v = \left( -\frac{4uv}{(1 + u^2 + v^2)^2}, \frac{2}{(1 + u^2 + v^2)} - \frac{4v^2}{(1 + u^2 + v^2)^2}, \frac{4v}{(1 + u^2 + v^2)^2} \right)$$ but when I then do the dot product, I don't get them to be $0$. I get it to be $$\left(\frac{2}{1 + u^2 + v^2} - \frac{4u^2}{(1 + u^2 + v^2)^2} \right) \cdot \left( -\frac{4uv}{(1 + u^2 + v^2)^2} \right) + \left(-\frac{4uv}{(1 + u^2 + v^2)^2} \right) \cdot \left(\frac{2}{(1 + u^2 + v^2)} - \frac{4v^2}{(1 + u^2 + v^2)^2} \right) + \left(\frac{4u}{(1 + u^2 + v^2)^2} \right) \cdot \left(\frac{4v}{(1 + u^2 + v^2)^2} \right),$$ which gives me $$\frac{16u^3v}{(1 + u^2 + v^2)^4} - \frac{8uv}{(1 + u^2 + v^2)^3} + \frac{16v^3u}{(1 + u^2 + v^2)^4} - \frac{8uv}{(1 + u^2 + v^2)^3} + \frac{16uv}{(1 + u^2 + v^2)^4}$$ $$ = \frac{16u^3v}{(1 + u^2 + v^2)^4}+ \frac{16v^3u}{(1 + u^2 + v^2)^4} - \frac{16uv}{(1 + u^2 + v^2)^3} + \frac{16uv}{(1 + u^2 + v^2)^4} \neq 0$$ Where am I making my mistake? 3) How much of the sphere is covered by the parametrization $X$? I also haven't got a clue how to do this bit. Maybe once I sort the first two parts out, I might get an idea. EDIT: Also, I'm thinking that my $X$ is wrong as when I do $x^2 + y^2 + z^2$, I don't get it to equal $1$. I'm not sure if it should or not. If it did, then it would lie on the surface of the sphere and not inside it. The question doesn't necasarrily say that it needs to lie on the surface, but I thought if I used the constraint $x^2 + y^2 + z^2 = 1$ then I've moved to the point on the line that does lie on the surface and so I should get $x^2 + y^2 + z^2 = 1$ for my $x,y,z$ coordinates for $X$, right?",,"['linear-algebra', 'differential-geometry']"
26,Is it possible that a 2-sphere has a Weitzenböck connection?,Is it possible that a 2-sphere has a Weitzenböck connection?,,"I mean, is it possible to have a connection on the 2-sphere with vanishing curvature but not vanishing torsion? In a more general sense, it is know that every Riemannian manifold has a Levi-Civita connection,is this true for the Weitzenböck connection?","I mean, is it possible to have a connection on the 2-sphere with vanishing curvature but not vanishing torsion? In a more general sense, it is know that every Riemannian manifold has a Levi-Civita connection,is this true for the Weitzenböck connection?",,['differential-geometry']
27,Generalization of Grassmann manifold to include translations?,Generalization of Grassmann manifold to include translations?,,"I came across a certain generalization of Grassmann manifolds and was wondering what work if any has been done on it.  If you take the space of $n\times p$ real matrices, $n>p$, and define an equivalence relationship $A\sim B \Leftrightarrow \exists M\in GL(p)\mid AM=B$ where $GL(p)$ is the space of invertible $p\times p$ real matrices, then the quotient space defined by this relation is the space of all $p$-dimensional subspaces of $\mathbb{R}^n$, called the Grassmann manifold $Gr(n,p)$. If you generalize this equivalence relation to also include the addition of a constant to each column: $A\sim B \Leftrightarrow \exists M\in GL(p), x \in \mathbb{R}^p\mid (A1_n)\left(\begin{array}{c}M\\x^T\end{array}\right)=B$ what is the manifold given by the corresponding quotient space?  Does it have a name?  Are there analytic solutions for the geodesics on this manifold, like there are for Grassmann manifolds? This came up while trying to figure out how to maximize Gaussian mutual information under certain constraints.  If you have two data matrices $X\in\mathbb{R}^{n\times T}$ and $Y\in\mathbb{R}^{m\times T}$, then the empirical Gaussian mutual information between them can be computed as $\hat{I}[X;Y] = \frac{1}{2}\mathrm{log}|M_nXX^TM_n^T| - \frac{1}{2}\mathrm{log}|M_nXX^TM_n^T-M_nXY^TM_m^T(M_mYY^TM_m^T)^{-1}M_mYX^TM_n^T|$ where $M_n:=I_n-1_{n\times n}/n$ is the matrix that subtracts the mean from each row of a matrix. This function is invariant under left multiplication of $X$ or $Y$ by an arbitrary matrix in $GL(n)$ or $GL(m)$ respectively, but also under addition of an arbitrary vector in $\mathbb{R}^{n}$ or $\mathbb{R}^{m}$ to each column.  I'd like to do optimization of this function directly in the quotient space defined by this equivalence relationship, instead of on $\mathbb{R}^{n\times T} \times \mathbb{R}^{m\times T}$, which is precisely the Cartesian product of the manifold I defined above. Edit: I realized my previous comment about this manifold being larger than $Gr(n,p)$ is wrong.  The equivalence relation is more general than the equivalence relation for $Gr(n,p)$, so the manifold is smaller.  It also occurs to me that the construction I described can be given as $GL(n)/(GL(n-p)\times Aff(p)) = GL(n)/(GL(n-p)\times (\mathbb{R}^p \rtimes GL(p)))$ where $Aff(p)$ is the $p$ dimensional affine space.  I believe this is equivalent to $O(n)/(O(n-p)\times(\mathbb{R}^p \rtimes O(p))$ where $O(n)$ is the group of $n$ dimensional orthogonal matrices, since $Gr(n,p)$ can be constructed as $O(n)/(O(n-p)\times O(p))$.","I came across a certain generalization of Grassmann manifolds and was wondering what work if any has been done on it.  If you take the space of $n\times p$ real matrices, $n>p$, and define an equivalence relationship $A\sim B \Leftrightarrow \exists M\in GL(p)\mid AM=B$ where $GL(p)$ is the space of invertible $p\times p$ real matrices, then the quotient space defined by this relation is the space of all $p$-dimensional subspaces of $\mathbb{R}^n$, called the Grassmann manifold $Gr(n,p)$. If you generalize this equivalence relation to also include the addition of a constant to each column: $A\sim B \Leftrightarrow \exists M\in GL(p), x \in \mathbb{R}^p\mid (A1_n)\left(\begin{array}{c}M\\x^T\end{array}\right)=B$ what is the manifold given by the corresponding quotient space?  Does it have a name?  Are there analytic solutions for the geodesics on this manifold, like there are for Grassmann manifolds? This came up while trying to figure out how to maximize Gaussian mutual information under certain constraints.  If you have two data matrices $X\in\mathbb{R}^{n\times T}$ and $Y\in\mathbb{R}^{m\times T}$, then the empirical Gaussian mutual information between them can be computed as $\hat{I}[X;Y] = \frac{1}{2}\mathrm{log}|M_nXX^TM_n^T| - \frac{1}{2}\mathrm{log}|M_nXX^TM_n^T-M_nXY^TM_m^T(M_mYY^TM_m^T)^{-1}M_mYX^TM_n^T|$ where $M_n:=I_n-1_{n\times n}/n$ is the matrix that subtracts the mean from each row of a matrix. This function is invariant under left multiplication of $X$ or $Y$ by an arbitrary matrix in $GL(n)$ or $GL(m)$ respectively, but also under addition of an arbitrary vector in $\mathbb{R}^{n}$ or $\mathbb{R}^{m}$ to each column.  I'd like to do optimization of this function directly in the quotient space defined by this equivalence relationship, instead of on $\mathbb{R}^{n\times T} \times \mathbb{R}^{m\times T}$, which is precisely the Cartesian product of the manifold I defined above. Edit: I realized my previous comment about this manifold being larger than $Gr(n,p)$ is wrong.  The equivalence relation is more general than the equivalence relation for $Gr(n,p)$, so the manifold is smaller.  It also occurs to me that the construction I described can be given as $GL(n)/(GL(n-p)\times Aff(p)) = GL(n)/(GL(n-p)\times (\mathbb{R}^p \rtimes GL(p)))$ where $Aff(p)$ is the $p$ dimensional affine space.  I believe this is equivalent to $O(n)/(O(n-p)\times(\mathbb{R}^p \rtimes O(p))$ where $O(n)$ is the group of $n$ dimensional orthogonal matrices, since $Gr(n,p)$ can be constructed as $O(n)/(O(n-p)\times O(p))$.",,"['linear-algebra', 'differential-geometry', 'manifolds']"
28,Vector field decomposition into gradient and hamiltonian vector field,Vector field decomposition into gradient and hamiltonian vector field,,"I have just read (without further explanation) that any vector field $(v_x(x,y),v_y(x,y))$ from $\mathbb{R}^2$ to $\mathbb{R}^2$, which has a continuous derivative, can be uniquely written as the sum of a gradient and a hamiltonian vector field, i.e. $$ v_x(x,y) = \partial_xP(x,y) + \partial_y S(x,y) $$ $$ v_y(x,y) = \partial_yP(x,y) -\partial_x S(x,y)$$for $P$,$S$ : $\mathbb{R}^2 \to \mathbb{R}$. If this is true, how can I show it? It seems non-obvious to me. Thanks!","I have just read (without further explanation) that any vector field $(v_x(x,y),v_y(x,y))$ from $\mathbb{R}^2$ to $\mathbb{R}^2$, which has a continuous derivative, can be uniquely written as the sum of a gradient and a hamiltonian vector field, i.e. $$ v_x(x,y) = \partial_xP(x,y) + \partial_y S(x,y) $$ $$ v_y(x,y) = \partial_yP(x,y) -\partial_x S(x,y)$$for $P$,$S$ : $\mathbb{R}^2 \to \mathbb{R}$. If this is true, how can I show it? It seems non-obvious to me. Thanks!",,['differential-geometry']
29,Length of a curve on a manifold using diffeomorphisms,Length of a curve on a manifold using diffeomorphisms,,"Lets say I have two (compact) manifolds $U$,$V$ and a diffeomorphism $\psi:U\rightarrow V $. The shortest way between two points $a$ , $b \in V$ is given by a parametrisation $\gamma :W \rightarrow V $ which I found using Euler-Langrange-Equation. Now I want to have a parametrisation $\eta: W \rightarrow U$ with the same property, that means $\psi(\eta(t))=\gamma(t)$. Moreover, I need more theory according to lengths on manifolds, I minimized the length using $L=\int \left \|\gamma '(t))  \right \|dt$ but I don't know if this is an elegent way of doing it. The problem which I want to solve is: what is the Length of to points $a,b\in U$ regarding to $V$, without transforming to $V$, finding a parametrisation and integrating over it.","Lets say I have two (compact) manifolds $U$,$V$ and a diffeomorphism $\psi:U\rightarrow V $. The shortest way between two points $a$ , $b \in V$ is given by a parametrisation $\gamma :W \rightarrow V $ which I found using Euler-Langrange-Equation. Now I want to have a parametrisation $\eta: W \rightarrow U$ with the same property, that means $\psi(\eta(t))=\gamma(t)$. Moreover, I need more theory according to lengths on manifolds, I minimized the length using $L=\int \left \|\gamma '(t))  \right \|dt$ but I don't know if this is an elegent way of doing it. The problem which I want to solve is: what is the Length of to points $a,b\in U$ regarding to $V$, without transforming to $V$, finding a parametrisation and integrating over it.",,"['differential-geometry', 'manifolds']"
30,What are all isometry classes of the 2-sphere?,What are all isometry classes of the 2-sphere?,,"In topology, one learns how to classify the compact surfaces up to homeomorphism.  And in fact, since ""homeomorphic"" and ""diffeomorphic"" coincide in dimension 2, we can classify the compact (smooth) surfaces up to diffeomorphism. This makes me wonder about classifying compact Riemannian 2-manifolds up to isometry.  In particular: Is there a classification of all Riemannian 2-manifolds that are diffeomorphic to the 2-sphere? I imagine this to be a very difficult question.  As such, I have two follow-up questions: If this is a tractable question, how much progress has been made in this direction?  What is known and what isn't? If the question is considered too difficult to have a real answer (is this the case?), then I imagine there to be simpler, related questions.  What are some examples of these?","In topology, one learns how to classify the compact surfaces up to homeomorphism.  And in fact, since ""homeomorphic"" and ""diffeomorphic"" coincide in dimension 2, we can classify the compact (smooth) surfaces up to diffeomorphism. This makes me wonder about classifying compact Riemannian 2-manifolds up to isometry.  In particular: Is there a classification of all Riemannian 2-manifolds that are diffeomorphic to the 2-sphere? I imagine this to be a very difficult question.  As such, I have two follow-up questions: If this is a tractable question, how much progress has been made in this direction?  What is known and what isn't? If the question is considered too difficult to have a real answer (is this the case?), then I imagine there to be simpler, related questions.  What are some examples of these?",,"['reference-request', 'differential-geometry', 'soft-question', 'riemannian-geometry']"
31,Critical paths for length cannot have kinks.,Critical paths for length cannot have kinks.,,"This problem is in Spivak's Differential Geometry (Ch.9 #37), and he gives a sketch of a proof which I have been unable to finish. So let's compute $\frac{dL(\overline{\alpha}(u))}{du}\mid_{u=0}$  where $L(\overline{\alpha}(u))=L_{0}^{t_{1}}(\gamma)+\int_{t_{1}}^{t_{0}+u}F(\,,\,)dt+\int_{t_{0}+u}^{1}F(\,,\,)dt$ , and of course $F(\alpha(u,t),\frac{\partial\alpha}{\partial t}(u,t))=\sqrt{\underset{i,j}{\sum}g_{ij}(\alpha)\frac{\partial\alpha^{i}}{\partial t}\frac{\partial\alpha^{j}}{\partial t}}$  (all the ""$(u,t)$"" omitted). Well, $\frac{dL(\overline{\alpha}(u))}{du}=\frac{d}{du}\int_{t_{1}}^{t_{0}+u}F(\,,\,)dt+\frac{d}{du}\int_{t_{0}+u}^{1}F(\,,\,)dt$ . Now I apply the Leibniz integral rule, and the terms become $F(\alpha(u,t_{0}+u),\frac{\partial\alpha}{\partial t}(u,t_{0}+u))+\int_{t_{1}}^{t_{0}+u}\frac{\partial}{\partial u}F(\alpha(u,t),\frac{\partial\alpha}{\partial t}(u,t))dt$ and $\int_{t_{0}+u}^{1}\frac{\partial}{\partial u}F(\alpha(u,t),\frac{\partial\alpha}{\partial t}(u,t))dt-F(\alpha(u,t_{0}+u),\frac{\partial\alpha}{\partial t}(u,t_{0}+u))$ , respectively. Evaluating their sum at $u=0$ , we just get $\int_{t_{1}}^{1}\frac{\partial}{\partial u}F(\alpha(0,t),\frac{\partial\alpha}{\partial t}(0,t))dt$ . Note that $\alpha$  is not exactly a variation on $\gamma$  since $\alpha(0,t)$  has a piece of $\gamma$  replaced by a geodesic (*). But anyway, $\alpha$ is  a variation on the piecewise smooth curve $\alpha(0,t)$ , and the integral obtained yields the First Variation Formula for Length of $\alpha(0,t)\mid_{[t_{1},1]} .$ . For the moment ignore *, and assume this is the thing we want to show $\neq0$ . The integral term in the First Variation Formula will disappear, leaving $\left\langle \frac{\partial\alpha}{\partial u}(0,t_{0}),\frac{\partial\alpha}{\partial t}(0,t_{0}^{+})-\frac{\partial\alpha}{\partial t}(0,t_{0}^{-})\right\rangle$  . This is sort of like $\left\langle \frac{\partial\alpha}{\partial u}(0,t_{0}),\Delta_{t_{0}}\frac{d\gamma}{dt}\right\rangle$  , where we know $\Delta_{t_{0}}\frac{d\gamma}{dt}\neq0$ . Assuming everything was correct so far, I have two questions: 1) Why (where) do we need $t_{1}$  to be sufficiently close to $t_{0}$, as hinted by Spivak ? 2) How can I conclude that the inner product term is not 0?","This problem is in Spivak's Differential Geometry (Ch.9 #37), and he gives a sketch of a proof which I have been unable to finish. So let's compute $\frac{dL(\overline{\alpha}(u))}{du}\mid_{u=0}$  where $L(\overline{\alpha}(u))=L_{0}^{t_{1}}(\gamma)+\int_{t_{1}}^{t_{0}+u}F(\,,\,)dt+\int_{t_{0}+u}^{1}F(\,,\,)dt$ , and of course $F(\alpha(u,t),\frac{\partial\alpha}{\partial t}(u,t))=\sqrt{\underset{i,j}{\sum}g_{ij}(\alpha)\frac{\partial\alpha^{i}}{\partial t}\frac{\partial\alpha^{j}}{\partial t}}$  (all the ""$(u,t)$"" omitted). Well, $\frac{dL(\overline{\alpha}(u))}{du}=\frac{d}{du}\int_{t_{1}}^{t_{0}+u}F(\,,\,)dt+\frac{d}{du}\int_{t_{0}+u}^{1}F(\,,\,)dt$ . Now I apply the Leibniz integral rule, and the terms become $F(\alpha(u,t_{0}+u),\frac{\partial\alpha}{\partial t}(u,t_{0}+u))+\int_{t_{1}}^{t_{0}+u}\frac{\partial}{\partial u}F(\alpha(u,t),\frac{\partial\alpha}{\partial t}(u,t))dt$ and $\int_{t_{0}+u}^{1}\frac{\partial}{\partial u}F(\alpha(u,t),\frac{\partial\alpha}{\partial t}(u,t))dt-F(\alpha(u,t_{0}+u),\frac{\partial\alpha}{\partial t}(u,t_{0}+u))$ , respectively. Evaluating their sum at $u=0$ , we just get $\int_{t_{1}}^{1}\frac{\partial}{\partial u}F(\alpha(0,t),\frac{\partial\alpha}{\partial t}(0,t))dt$ . Note that $\alpha$  is not exactly a variation on $\gamma$  since $\alpha(0,t)$  has a piece of $\gamma$  replaced by a geodesic (*). But anyway, $\alpha$ is  a variation on the piecewise smooth curve $\alpha(0,t)$ , and the integral obtained yields the First Variation Formula for Length of $\alpha(0,t)\mid_{[t_{1},1]} .$ . For the moment ignore *, and assume this is the thing we want to show $\neq0$ . The integral term in the First Variation Formula will disappear, leaving $\left\langle \frac{\partial\alpha}{\partial u}(0,t_{0}),\frac{\partial\alpha}{\partial t}(0,t_{0}^{+})-\frac{\partial\alpha}{\partial t}(0,t_{0}^{-})\right\rangle$  . This is sort of like $\left\langle \frac{\partial\alpha}{\partial u}(0,t_{0}),\Delta_{t_{0}}\frac{d\gamma}{dt}\right\rangle$  , where we know $\Delta_{t_{0}}\frac{d\gamma}{dt}\neq0$ . Assuming everything was correct so far, I have two questions: 1) Why (where) do we need $t_{1}$  to be sufficiently close to $t_{0}$, as hinted by Spivak ? 2) How can I conclude that the inner product term is not 0?",,"['differential-geometry', 'riemannian-geometry']"
32,On a theorem on Lie derivatives,On a theorem on Lie derivatives,,"I am a little confused proving this theorem (for $p$-forms on $M^n$, $M^n$ is a smooth manifold): $L_X\cdot i_Y-i_Y\cdot L_X=i_{[X,Y]}$ where $X,Y$ are smooth vector fields. Now it is clear that both sides are anti-derivations, since $L_X$ is a derivation, $i_Y$ and $i_{[X,Y]}$ are anti-derivations. Now this reduces the problem to proving that the theorem is true for $f\in C^\infty$ and $df$ for such $f$. It seems to me the the L.H.S is zero for both $f$ and $df$. For $f$: L.H.S $=0$ is trivial since $i_Y$ for any zero-form is $0$ for $df$ $$i_Y \, df=df(Y) \implies L_X(i_Y \, df)=L_X(df(Y))$$ And $$L_X(df)=dL_X(f) \implies i_Y(L_X(df))=L_X(df)(Y)$$ Hence L.H.S. $=0$ Have I made an error here ? Thanks for any help or pointers.","I am a little confused proving this theorem (for $p$-forms on $M^n$, $M^n$ is a smooth manifold): $L_X\cdot i_Y-i_Y\cdot L_X=i_{[X,Y]}$ where $X,Y$ are smooth vector fields. Now it is clear that both sides are anti-derivations, since $L_X$ is a derivation, $i_Y$ and $i_{[X,Y]}$ are anti-derivations. Now this reduces the problem to proving that the theorem is true for $f\in C^\infty$ and $df$ for such $f$. It seems to me the the L.H.S is zero for both $f$ and $df$. For $f$: L.H.S $=0$ is trivial since $i_Y$ for any zero-form is $0$ for $df$ $$i_Y \, df=df(Y) \implies L_X(i_Y \, df)=L_X(df(Y))$$ And $$L_X(df)=dL_X(f) \implies i_Y(L_X(df))=L_X(df)(Y)$$ Hence L.H.S. $=0$ Have I made an error here ? Thanks for any help or pointers.",,"['differential-geometry', 'lie-groups']"
33,How to compute the index of a given vector field on a triangular mesh,How to compute the index of a given vector field on a triangular mesh,,"Suppose that I have a triangular mesh (discrete surface composed of triangles). Now, I have been given a vector field (one vector with each triangle, tangential, unit length, so can be represented by only one angle). I would like to compute the index of this vector field on every vertex. One of the definition of the index can be the number of full rotations experienced by a vector transported along a loop of triangles around the vertex. I have some confusions because if only the vector of one triangle (among all triangles around the vertex) is changed, it seems that the index will not change. But the index will be definitely determined by the vectors of all triangles. What am I missing here?","Suppose that I have a triangular mesh (discrete surface composed of triangles). Now, I have been given a vector field (one vector with each triangle, tangential, unit length, so can be represented by only one angle). I would like to compute the index of this vector field on every vertex. One of the definition of the index can be the number of full rotations experienced by a vector transported along a loop of triangles around the vertex. I have some confusions because if only the vector of one triangle (among all triangles around the vertex) is changed, it seems that the index will not change. But the index will be definitely determined by the vectors of all triangles. What am I missing here?",,['differential-geometry']
34,Geodesic First Variation,Geodesic First Variation,,"I'm trying to prove that if the first variation of length vanishes then the curve $\gamma$ must be an affinely parameterised geodesic. In the following $T=\dot{\gamma}$. So I've attacked the contrapositive, assuming that $\gamma$ is not an affinely parameterised geodesic. I've got the stage where $$L'(s)\leq \int_{t_1}^{t_2} -g(T,T)^{-1/2}||\nabla_TT-(\nabla_T.T)/||T||^2||^2 dt$$ with $\nabla_TT\neq 0$ in the region of integration. I'd like to conclude that this is strictly negative, which is immediate if $\nabla_TT\not\propto T$. I can't seem to show this though. Does anyone have any ideas how to proceed? If you want to see the early part of the argument look at p32 here . Cheers!","I'm trying to prove that if the first variation of length vanishes then the curve $\gamma$ must be an affinely parameterised geodesic. In the following $T=\dot{\gamma}$. So I've attacked the contrapositive, assuming that $\gamma$ is not an affinely parameterised geodesic. I've got the stage where $$L'(s)\leq \int_{t_1}^{t_2} -g(T,T)^{-1/2}||\nabla_TT-(\nabla_T.T)/||T||^2||^2 dt$$ with $\nabla_TT\neq 0$ in the region of integration. I'd like to conclude that this is strictly negative, which is immediate if $\nabla_TT\not\propto T$. I can't seem to show this though. Does anyone have any ideas how to proceed? If you want to see the early part of the argument look at p32 here . Cheers!",,"['differential-geometry', 'calculus-of-variations', 'mathematical-physics', 'geodesic']"
35,Spivak problem on orientations. (A comprehensive introduction to differential geometry),Spivak problem on orientations. (A comprehensive introduction to differential geometry),,"I have a problems doing exercise 16 of chapter 3 (p.98 in my edition) of Spivak's book. The problem is very simple. Let $M$ be a manifold with boundary, and choose a point $p\in\delta(M)$. Now consider an element $v\in T_p M$ which is not spanned by the vectors on $T_p\delta(M)$, that is, it's last coordinate is non-zero (after good identifications). We say that $v$ is inward pointing if there is a chart $\phi: U\rightarrow \mathbb{H}^n$ ($p\in U$) such that $d_p\phi(v)=(v_1,\dots,v_n)$ where $v_n>0$. It is asked to show that this is independent on the choice of coordinates (on the chart). I think that Spivak's idea is to realize first that the subespace of vectors in $T_p\delta M$ is independent on the chart, which can be seen noticing that  if $i:\delta (M)\rightarrow M$ then $d_pi(v_1,\dots,v_{n-1})=(v_1,\dots,v_{n-1},0)\in T_p \mathbb{H}^n$","I have a problems doing exercise 16 of chapter 3 (p.98 in my edition) of Spivak's book. The problem is very simple. Let $M$ be a manifold with boundary, and choose a point $p\in\delta(M)$. Now consider an element $v\in T_p M$ which is not spanned by the vectors on $T_p\delta(M)$, that is, it's last coordinate is non-zero (after good identifications). We say that $v$ is inward pointing if there is a chart $\phi: U\rightarrow \mathbb{H}^n$ ($p\in U$) such that $d_p\phi(v)=(v_1,\dots,v_n)$ where $v_n>0$. It is asked to show that this is independent on the choice of coordinates (on the chart). I think that Spivak's idea is to realize first that the subespace of vectors in $T_p\delta M$ is independent on the chart, which can be seen noticing that  if $i:\delta (M)\rightarrow M$ then $d_pi(v_1,\dots,v_{n-1})=(v_1,\dots,v_{n-1},0)\in T_p \mathbb{H}^n$",,['differential-geometry']
36,Transversality is generic,Transversality is generic,,"Let $M$ and $N$ be submanifolds of $\mathbb R^n$. I am trying to prove that for almost every $x\in \mathbb R^n$, $M+x$ and $N$ intersect transversely. Intuitively, transversality is a ""generic"" condition, so if we slightly change $x$, we can make the intersection transverse. However, I do not know how to make this intuition precise. Can anyone explain?","Let $M$ and $N$ be submanifolds of $\mathbb R^n$. I am trying to prove that for almost every $x\in \mathbb R^n$, $M+x$ and $N$ intersect transversely. Intuitively, transversality is a ""generic"" condition, so if we slightly change $x$, we can make the intersection transverse. However, I do not know how to make this intuition precise. Can anyone explain?",,"['differential-geometry', 'differential-topology', 'transversality']"
37,I don't understand holonomy well,I don't understand holonomy well,,"I'm just trying to understand how a vector can rotate around a smooth loop $\gamma$ on some manifold $M$. By Picard's theorem, the differential equation $\nabla_{\frac{\partial}{\partial t}} W =0$ with initial condition $W_{\gamma(t_0)} = v$ for this given connection just have one solution and ,since W is a vector field, $W_{\gamma(t_f)} = v$. I think it's very idiot, but I'm not getting it.  Thanks in advance.","I'm just trying to understand how a vector can rotate around a smooth loop $\gamma$ on some manifold $M$. By Picard's theorem, the differential equation $\nabla_{\frac{\partial}{\partial t}} W =0$ with initial condition $W_{\gamma(t_0)} = v$ for this given connection just have one solution and ,since W is a vector field, $W_{\gamma(t_f)} = v$. I think it's very idiot, but I'm not getting it.  Thanks in advance.",,['differential-geometry']
38,Computing gradient in cylindrical polar coordinates using metric?,Computing gradient in cylindrical polar coordinates using metric?,,"I am trying to understand coordinate transformations properly (having studied some general relativity in the past). Let us consider the transformation from cartesian to cylindrical coordinates, $x=\rho\cos\varphi$, $y=\rho\sin\varphi$, $z=z$. I know that the line element (invariant at coord transformations) is simply defined as  $$ ds^{2}=g_{ij}dx^{i}dx^{j}=\tilde{g}_{ij}d\tilde{x}^{i}d\tilde{x}^{j} $$ where the non-tilde quantities belong to one coordinates (cartesian in my example) and the tilde ones to another (cylindrical in my example). The cartesian coordinates are simply $$ ds^{2}=dx^{2}+dy^{2}+dz^{2} $$ where the metric is $g_{ij}=diag(1,1,1)$ and the inverse metric is $g^{ij}=g_{ij}$. Simply using total differentials I can compute that $dx^{2}=\left[d(\rho\cos\varphi)\right]^{2}$ and do the derivatives etc. This way, I obtain $$ ds^{2}=d\rho^{2}+\rho^{2}d\varphi^{2}+dz^{2} $$ which means $\tilde{g}_{ij}=diag(1,\rho^{2},1)$ and $\tilde{g}^{ij}=diag(1,\frac{1}{\rho^{2}},1)$. So far, so good. Now I was wondering how I can use the metric in order to obtain expressions for simple things, for instance the gradient of a scalar field $\phi$. In my thinking, it should simply be $$ \nabla\phi=\left(\partial^{i}\phi\right)\mathbf{e}_{\left(i\right)}=\tilde{g}^{ij}\left(\partial_{i}\phi\right)\mathbf{e}_{\left(j\right)}=\tilde{g}^{\rho\rho}\left(\partial_{\rho}\phi\right)\mathbf{e}_{\rho}+\tilde{g}^{\varphi\varphi}\left(\partial_{\varphi}\phi\right)\mathbf{e}_{\varphi}+\tilde{g}^{zz}\left(\partial_{z}\phi\right)\mathbf{e}_{z}. $$ where $\mathbf{e}_{\left(i\right)}$ represents the $i$-th unit vector, e.g. $\mathbf{e}_{\left(2\right)}=\mathbf{e}_{\varphi}$. The result should then be  $$ \nabla\phi=\frac{\partial\phi}{\partial\rho}\mathbf{e}_{\rho}+\frac{1}{\rho^{2}}\frac{\partial\phi}{\partial\varphi}\mathbf{e}_{\varphi}+\frac{\partial\phi}{\partial z}\mathbf{e}_{z} $$ which is wrong. Computing other expressions, like the Laplacian, gets things considerably more wrong. My thinking about using the metric in this way must be flawed. Can you help me out and rectify this?","I am trying to understand coordinate transformations properly (having studied some general relativity in the past). Let us consider the transformation from cartesian to cylindrical coordinates, $x=\rho\cos\varphi$, $y=\rho\sin\varphi$, $z=z$. I know that the line element (invariant at coord transformations) is simply defined as  $$ ds^{2}=g_{ij}dx^{i}dx^{j}=\tilde{g}_{ij}d\tilde{x}^{i}d\tilde{x}^{j} $$ where the non-tilde quantities belong to one coordinates (cartesian in my example) and the tilde ones to another (cylindrical in my example). The cartesian coordinates are simply $$ ds^{2}=dx^{2}+dy^{2}+dz^{2} $$ where the metric is $g_{ij}=diag(1,1,1)$ and the inverse metric is $g^{ij}=g_{ij}$. Simply using total differentials I can compute that $dx^{2}=\left[d(\rho\cos\varphi)\right]^{2}$ and do the derivatives etc. This way, I obtain $$ ds^{2}=d\rho^{2}+\rho^{2}d\varphi^{2}+dz^{2} $$ which means $\tilde{g}_{ij}=diag(1,\rho^{2},1)$ and $\tilde{g}^{ij}=diag(1,\frac{1}{\rho^{2}},1)$. So far, so good. Now I was wondering how I can use the metric in order to obtain expressions for simple things, for instance the gradient of a scalar field $\phi$. In my thinking, it should simply be $$ \nabla\phi=\left(\partial^{i}\phi\right)\mathbf{e}_{\left(i\right)}=\tilde{g}^{ij}\left(\partial_{i}\phi\right)\mathbf{e}_{\left(j\right)}=\tilde{g}^{\rho\rho}\left(\partial_{\rho}\phi\right)\mathbf{e}_{\rho}+\tilde{g}^{\varphi\varphi}\left(\partial_{\varphi}\phi\right)\mathbf{e}_{\varphi}+\tilde{g}^{zz}\left(\partial_{z}\phi\right)\mathbf{e}_{z}. $$ where $\mathbf{e}_{\left(i\right)}$ represents the $i$-th unit vector, e.g. $\mathbf{e}_{\left(2\right)}=\mathbf{e}_{\varphi}$. The result should then be  $$ \nabla\phi=\frac{\partial\phi}{\partial\rho}\mathbf{e}_{\rho}+\frac{1}{\rho^{2}}\frac{\partial\phi}{\partial\varphi}\mathbf{e}_{\varphi}+\frac{\partial\phi}{\partial z}\mathbf{e}_{z} $$ which is wrong. Computing other expressions, like the Laplacian, gets things considerably more wrong. My thinking about using the metric in this way must be flawed. Can you help me out and rectify this?",,"['differential-geometry', 'coordinate-systems', 'polar-coordinates']"
39,Levi-Civita connection,Levi-Civita connection,,"Well if $\Sigma$ is a submanifold of $R^{n+p}$ and $\{e_i,e_\alpha\}$ is orthonormal frame over $\Sigma$ where the $e_i$'s are tangent and the $e_\alpha$'s are normal to $\Sigma$. Can anyone prove (with an adequate frame) that  $\nabla_{e_i}^{\perp} e_\alpha=0$? Obs: The result is pretty easy when we have only one normal direction, but in this case there are more.","Well if $\Sigma$ is a submanifold of $R^{n+p}$ and $\{e_i,e_\alpha\}$ is orthonormal frame over $\Sigma$ where the $e_i$'s are tangent and the $e_\alpha$'s are normal to $\Sigma$. Can anyone prove (with an adequate frame) that  $\nabla_{e_i}^{\perp} e_\alpha=0$? Obs: The result is pretty easy when we have only one normal direction, but in this case there are more.",,"['differential-geometry', 'manifolds', 'riemannian-geometry']"
40,Vanishing section of a sheaf,Vanishing section of a sheaf,,"This is my first post on math.stackexchange.com - please excuse me if I have overseen some relevant part of the FAQ or this question among those already answered or if I do misbehave in any other way, it maybe takes a bit of use to understand how to find out whether one can ask a question or not. I am supposed to teach myself the content ""Sheaves, Cohomology and the de Rham Theorem"" using Warner's Foundations of Differentiable Manifolds and Lie Groups. I have an issue with a very early supposedly easy problem and this suggest that I do not get any grip on the objects I am dealing with. Could somebody maybe give me a hint or a point of view which stays in Warner's framework (no ringed spaces a.s.o.)? Before I delve into the questions, I fix a bit of vocabulary (as this might vary from author to author): $M$ is a manifold $K$ is a principal ideal domain A sheaf $\mathcal{S}$ of $K$-modules over $M$ is a tuple $(\mathcal{S},\pi)$ where $\mathcal{S}$ is a topological space and $\pi:\mathcal{S}\to M$ is a local homeomorphism such that for all $m\in M$ the preimage $\pi^{-1}(m)$ is a $K$-module and the composition laws (on the modules in) $\mathcal{S}$ are continuous. Now for the question: Let $(\mathcal{S},\pi)$ be a sheaf of $K$-modules over a manifold $M$. Let $U\subset M$ open and $f:U\to\mathcal{S}$ be a section of $\mathcal{S}$ over $U$, i.e. $f$ is continuous and $\pi\circ f=\operatorname{id}_{U}$. Assume $m\in U$ such that $f(m)=0$ in $\pi^{-1}(m)$. Then there exists a neighbourhood $m\in V\subset U$ such that $f$ vanishes on all of $V$, i.e. $f(v)=0\in\pi^{-1}(v)$. I assume that this must be true as of the following: ""[...] if sections $f$ and $g$ agree at $m\in M$, then they must agree on a neighbourhood of $m$"". As I had no idea how to answer this question, I decided to first work on the first problem in the exercise section, i.e. that the null-section $g:M\to\mathcal{S}$ defined by $g(m)=0\in\pi^{-1}(m)$ is continuous. I haven't even managed to prove this. That's why I am asking for help. I have tried to prove it pretty directly, i.e. I chose a neighbourhood $g(m)=0\in W\subseteq\mathcal{S}$ such that $\pi\big|_{W}$ is a homeomorphism and then started looking for a neigbourhood $m\in U\subseteq M$ which satisfies $g(U)\subseteq W$. I used some neighbourhood $m\in V\subseteq\pi(W)$ and $\pi\circ g\big|_{V}=\operatorname{id}_{V}$ to deduce that $g(V)\subseteq \pi^{-1}(\pi(W))$. The latter simply is: $$ \pi^{-1}(\pi(W))=\bigcup_{w\in W}(\{0\}\cup\pi^{-1}(\pi(w))\setminus\{0\}) $$ which is what I did stare at but this did not help. I feel that I really do not get a grip on these objects, so that is why I am turning to you. Maybe somebody could give me a hint on what to do More usefully maybe somebody could give me a hint on how to interprete these things in the context of Warner's definition.","This is my first post on math.stackexchange.com - please excuse me if I have overseen some relevant part of the FAQ or this question among those already answered or if I do misbehave in any other way, it maybe takes a bit of use to understand how to find out whether one can ask a question or not. I am supposed to teach myself the content ""Sheaves, Cohomology and the de Rham Theorem"" using Warner's Foundations of Differentiable Manifolds and Lie Groups. I have an issue with a very early supposedly easy problem and this suggest that I do not get any grip on the objects I am dealing with. Could somebody maybe give me a hint or a point of view which stays in Warner's framework (no ringed spaces a.s.o.)? Before I delve into the questions, I fix a bit of vocabulary (as this might vary from author to author): $M$ is a manifold $K$ is a principal ideal domain A sheaf $\mathcal{S}$ of $K$-modules over $M$ is a tuple $(\mathcal{S},\pi)$ where $\mathcal{S}$ is a topological space and $\pi:\mathcal{S}\to M$ is a local homeomorphism such that for all $m\in M$ the preimage $\pi^{-1}(m)$ is a $K$-module and the composition laws (on the modules in) $\mathcal{S}$ are continuous. Now for the question: Let $(\mathcal{S},\pi)$ be a sheaf of $K$-modules over a manifold $M$. Let $U\subset M$ open and $f:U\to\mathcal{S}$ be a section of $\mathcal{S}$ over $U$, i.e. $f$ is continuous and $\pi\circ f=\operatorname{id}_{U}$. Assume $m\in U$ such that $f(m)=0$ in $\pi^{-1}(m)$. Then there exists a neighbourhood $m\in V\subset U$ such that $f$ vanishes on all of $V$, i.e. $f(v)=0\in\pi^{-1}(v)$. I assume that this must be true as of the following: ""[...] if sections $f$ and $g$ agree at $m\in M$, then they must agree on a neighbourhood of $m$"". As I had no idea how to answer this question, I decided to first work on the first problem in the exercise section, i.e. that the null-section $g:M\to\mathcal{S}$ defined by $g(m)=0\in\pi^{-1}(m)$ is continuous. I haven't even managed to prove this. That's why I am asking for help. I have tried to prove it pretty directly, i.e. I chose a neighbourhood $g(m)=0\in W\subseteq\mathcal{S}$ such that $\pi\big|_{W}$ is a homeomorphism and then started looking for a neigbourhood $m\in U\subseteq M$ which satisfies $g(U)\subseteq W$. I used some neighbourhood $m\in V\subseteq\pi(W)$ and $\pi\circ g\big|_{V}=\operatorname{id}_{V}$ to deduce that $g(V)\subseteq \pi^{-1}(\pi(W))$. The latter simply is: $$ \pi^{-1}(\pi(W))=\bigcup_{w\in W}(\{0\}\cup\pi^{-1}(\pi(w))\setminus\{0\}) $$ which is what I did stare at but this did not help. I feel that I really do not get a grip on these objects, so that is why I am turning to you. Maybe somebody could give me a hint on what to do More usefully maybe somebody could give me a hint on how to interprete these things in the context of Warner's definition.",,"['differential-geometry', 'sheaf-theory']"
41,Transition functions on a quotient manifold,Transition functions on a quotient manifold,,"Here's an exercise given during a course in Differential Geometry that I'm taking. Let $M$ denote a smooth manifold and let $G$ be a finite group of diffeomorphisms acting on it without fixed points (that is, $g(p)=p$ for some $p\in M$ forces $g$ to be the identity). We then have on the quotient space $M/G$ a differentiable structure. An atlas for it is obtained via the following observation: if $[p]$ is a point in $M/G$ then there exist a representative $p\in M$ and a chart $(U, \phi)$ in $p$ such that the projection $\pi\colon M\to M/G$ is injective on $U$. It then makes sense to define a chart $$(\overline{U}, \phi_{\overline{U}})=\left(\pi(U), \phi\circ\left(\pi|_{U}\right)^{-1}\right).$$ The family of all such charts is an atlas for $M/G$. Exercise Show that the transition functions $\phi_{\overline{V}}\circ\phi_{\overline{U}}^{-1}$ can be identified   with elements of $G$. I find this question to be somewhat vague. Identified in which sense? The set of those transition functions might well be infinite, while $G$ is not. Also, I cannot see any relationship between the two. Can somebody provide me with some hint? Thank you.","Here's an exercise given during a course in Differential Geometry that I'm taking. Let $M$ denote a smooth manifold and let $G$ be a finite group of diffeomorphisms acting on it without fixed points (that is, $g(p)=p$ for some $p\in M$ forces $g$ to be the identity). We then have on the quotient space $M/G$ a differentiable structure. An atlas for it is obtained via the following observation: if $[p]$ is a point in $M/G$ then there exist a representative $p\in M$ and a chart $(U, \phi)$ in $p$ such that the projection $\pi\colon M\to M/G$ is injective on $U$. It then makes sense to define a chart $$(\overline{U}, \phi_{\overline{U}})=\left(\pi(U), \phi\circ\left(\pi|_{U}\right)^{-1}\right).$$ The family of all such charts is an atlas for $M/G$. Exercise Show that the transition functions $\phi_{\overline{V}}\circ\phi_{\overline{U}}^{-1}$ can be identified   with elements of $G$. I find this question to be somewhat vague. Identified in which sense? The set of those transition functions might well be infinite, while $G$ is not. Also, I cannot see any relationship between the two. Can somebody provide me with some hint? Thank you.",,['differential-geometry']
42,Is there any loss in generality when I assume that a regular curve is arc-lenght parameterized?,Is there any loss in generality when I assume that a regular curve is arc-lenght parameterized?,,"My doubt is simple as that. When I have a smooth, regular curve (that is, its curvature is never zero), can I just assume that it is parameterized by arc-lenght, without any loss of generality? If not, is there any counter example?","My doubt is simple as that. When I have a smooth, regular curve (that is, its curvature is never zero), can I just assume that it is parameterized by arc-lenght, without any loss of generality? If not, is there any counter example?",,['differential-geometry']
43,A Question of Curvature:,A Question of Curvature:,,"When is a sphere the best approximation to a surface at  a point? To be more specific: Let $S$ be a smooth surface in $R^3$. $P$ a point on $S$. $N$ normal to $S$ at $P$. $\Pi$ a plane through $N$. $C$ the intersection of $\Pi$ with $S$. $R$ the radius of curvature of $C$ at $P$. Under what conditions would $R$ not depend on $\Pi$? That is, all the normal planes that intersect the surface at $P$ leave a trace with the same curvature?","When is a sphere the best approximation to a surface at  a point? To be more specific: Let $S$ be a smooth surface in $R^3$. $P$ a point on $S$. $N$ normal to $S$ at $P$. $\Pi$ a plane through $N$. $C$ the intersection of $\Pi$ with $S$. $R$ the radius of curvature of $C$ at $P$. Under what conditions would $R$ not depend on $\Pi$? That is, all the normal planes that intersect the surface at $P$ leave a trace with the same curvature?",,"['differential-geometry', 'curvature']"
44,Integration of a differential form,Integration of a differential form,,"Let $\omega$ be a $2$-form on $\mathbb{R}^3-\{(1,0,0),(-1,0,0)\}$, $$\omega=((x-1)^2+y^2+z^2)^{-3/2}((x-1)dy\wedge dz+ydz\wedge dx+zdx \wedge dy)+   ((x+1)^2+y^2+z^2)^{-3/2}((x+1)dy\wedge dz+ydz\wedge dx+zdx \wedge dy)$$  and $S=\{(x,y,z)\in \mathbb{R^3}: x^2+y^2+z^2=5 \}$. In this condition, we calculate $\int_{S}\omega$, where the orientation of $S$ is the natural orientation induced by $D=\{(x,y,z)\in \mathbb{R^3}: x^2+y^2+z^2 \leq 5 \}$. I can't calculate this, so if you  solve this, please teach me the answer for this.","Let $\omega$ be a $2$-form on $\mathbb{R}^3-\{(1,0,0),(-1,0,0)\}$, $$\omega=((x-1)^2+y^2+z^2)^{-3/2}((x-1)dy\wedge dz+ydz\wedge dx+zdx \wedge dy)+   ((x+1)^2+y^2+z^2)^{-3/2}((x+1)dy\wedge dz+ydz\wedge dx+zdx \wedge dy)$$  and $S=\{(x,y,z)\in \mathbb{R^3}: x^2+y^2+z^2=5 \}$. In this condition, we calculate $\int_{S}\omega$, where the orientation of $S$ is the natural orientation induced by $D=\{(x,y,z)\in \mathbb{R^3}: x^2+y^2+z^2 \leq 5 \}$. I can't calculate this, so if you  solve this, please teach me the answer for this.",,"['differential-geometry', 'manifolds']"
45,Show that curve lies on a sphere,Show that curve lies on a sphere,,Let $\alpha$ be a curve (in $\mathbb{R^{3}}$) with natural (arc length) parametrization which all osculating planes have exactly one point in common. Show that $\alpha$ is a spherical curve (lies on a sphere).,Let $\alpha$ be a curve (in $\mathbb{R^{3}}$) with natural (arc length) parametrization which all osculating planes have exactly one point in common. Show that $\alpha$ is a spherical curve (lies on a sphere).,,['differential-geometry']
46,Projective Space orientation,Projective Space orientation,,"I'm trying to prove that the projective plane $\mathbb{P}^n$ is orientable is and only if $n$ is odd. To do that that, I have a hint,to prove that the antipodal map is orientation preserving if only if $n$ is odd, I've done that, but it don't know how to conclude the result.","I'm trying to prove that the projective plane $\mathbb{P}^n$ is orientable is and only if $n$ is odd. To do that that, I have a hint,to prove that the antipodal map is orientation preserving if only if $n$ is odd, I've done that, but it don't know how to conclude the result.",,['differential-geometry']
47,Coordinate change for metrics,Coordinate change for metrics,,"I am rather confused by the idea of ""geodesic polar coordinates"", so I hope someone would kindly explain it to me. As far as my understanding goes, given a Riemannian metric $ds^2=E\,dx^2+2F\,dx\,dy+G\,dy^2$ we somehow have to find other variables $u,v$ so that $ds^2=du^2+G(u,v)\,dv^2$. How can I convert $ds^2={dr^2+r^2\,d\theta^2\over f(r)^2}$ where $f(r)$ is some function of $r$ into that form? Is there an ""algorithm"" to achieve this change of form? Is there some significant benefit in doing so? Thank you.","I am rather confused by the idea of ""geodesic polar coordinates"", so I hope someone would kindly explain it to me. As far as my understanding goes, given a Riemannian metric $ds^2=E\,dx^2+2F\,dx\,dy+G\,dy^2$ we somehow have to find other variables $u,v$ so that $ds^2=du^2+G(u,v)\,dv^2$. How can I convert $ds^2={dr^2+r^2\,d\theta^2\over f(r)^2}$ where $f(r)$ is some function of $r$ into that form? Is there an ""algorithm"" to achieve this change of form? Is there some significant benefit in doing so? Thank you.",,"['differential-geometry', 'metric-spaces']"
48,Could someone please explain what this question is asking?,Could someone please explain what this question is asking?,,"I have some trouble understanding the following question: Suppose we have 1st fundamental form $E \, dx^2+2F \, dx \, dy+G \, dy^2$ and we are given that for any $u,v$, the curve given by $x=u, y=v$ are geodesics. Show that ${\partial \over \partial y}\left({F\over \sqrt{G}}\right)={\partial \sqrt{G}\over \partial x}$. I don't understand what ""$x=u, y=v$ are geodesics"" mean. So the path is a constant point?? That doesn't make sense! Can anybody understand what it is saying?","I have some trouble understanding the following question: Suppose we have 1st fundamental form $E \, dx^2+2F \, dx \, dy+G \, dy^2$ and we are given that for any $u,v$, the curve given by $x=u, y=v$ are geodesics. Show that ${\partial \over \partial y}\left({F\over \sqrt{G}}\right)={\partial \sqrt{G}\over \partial x}$. I don't understand what ""$x=u, y=v$ are geodesics"" mean. So the path is a constant point?? That doesn't make sense! Can anybody understand what it is saying?",,"['differential-geometry', 'calculus-of-variations']"
49,The square root of positive definite matrix,The square root of positive definite matrix,,"Let $M$ be the manifold of real positive definite $n \times n$ matrices, define a mapping $i:A \to \sqrt A$ (where $A\in M$ and $\sqrt A$ means the unique positive definite square root of $A$). Please show that $i$ is smooth.","Let $M$ be the manifold of real positive definite $n \times n$ matrices, define a mapping $i:A \to \sqrt A$ (where $A\in M$ and $\sqrt A$ means the unique positive definite square root of $A$). Please show that $i$ is smooth.",,"['matrices', 'differential-geometry']"
50,Flows of two vector fields,Flows of two vector fields,,"Suppose $M$ is a manifold and $f:M \rightarrow \bf{R}$ is a $\mathcal{C}^{\infty}$ function. Let $X$ and $Y$ denote vector fields on $M$, and let $\varphi_Y^t$ denote the flow of $Y$. Fix a point $p \in M$, and consider the real valued function  $$u(t):=df_{\varphi_Y^t (p)}(X(\varphi_Y^t (p))).$$  When is $u$ identically zero? Is it always zero if the Lie bracket $\mathcal{L}_X Y$ is zero, or does the condition depend on the function $f$?","Suppose $M$ is a manifold and $f:M \rightarrow \bf{R}$ is a $\mathcal{C}^{\infty}$ function. Let $X$ and $Y$ denote vector fields on $M$, and let $\varphi_Y^t$ denote the flow of $Y$. Fix a point $p \in M$, and consider the real valued function  $$u(t):=df_{\varphi_Y^t (p)}(X(\varphi_Y^t (p))).$$  When is $u$ identically zero? Is it always zero if the Lie bracket $\mathcal{L}_X Y$ is zero, or does the condition depend on the function $f$?",,['differential-geometry']
51,Intuitive interpretation of these differential forms,Intuitive interpretation of these differential forms,,"Let $\pi: S^2-\{N\}\to \mathbb R^2$ be the stereographic projection map. Let $\sigma:\mathbb R^2\to S^2-\{N\}$ be its inverse. Let $p\in S^2-\{N\}$ and $x_1,x_2\in$ the tangent space of $S^2$ Would someone be nice enough to explain to me then what the following mean intuitively? And hopefully also a way to visualize them/gain some sort of physical intuition on them? 1) $(d\sigma)_{\pi(p)}$ 2) $d\pi_p$ 3) Why $x_1\cdot x_2=(d\pi_p(x_1),d\pi_p(x_2))_{\pi(p)}$ 4) $d\pi_p\circ (d\sigma)_{\pi(p)}=$ identity I have read the differential forms article on Wikipedia in hope to learn more, but I still don't quite get the idea. I know for example that (1) is the differential of $\sigma$ at the point $\pi(p)$ but I don't understand what that means. I hope that someone could give me a geometric picture of some kind. And if there should be such a saint out there, I would like to thank you very much (in advance).","Let $\pi: S^2-\{N\}\to \mathbb R^2$ be the stereographic projection map. Let $\sigma:\mathbb R^2\to S^2-\{N\}$ be its inverse. Let $p\in S^2-\{N\}$ and $x_1,x_2\in$ the tangent space of $S^2$ Would someone be nice enough to explain to me then what the following mean intuitively? And hopefully also a way to visualize them/gain some sort of physical intuition on them? 1) $(d\sigma)_{\pi(p)}$ 2) $d\pi_p$ 3) Why $x_1\cdot x_2=(d\pi_p(x_1),d\pi_p(x_2))_{\pi(p)}$ 4) $d\pi_p\circ (d\sigma)_{\pi(p)}=$ identity I have read the differential forms article on Wikipedia in hope to learn more, but I still don't quite get the idea. I know for example that (1) is the differential of $\sigma$ at the point $\pi(p)$ but I don't understand what that means. I hope that someone could give me a geometric picture of some kind. And if there should be such a saint out there, I would like to thank you very much (in advance).",,"['geometry', 'differential-geometry', 'intuition', 'differential-forms']"
52,Derivative of an integral of differential form,Derivative of an integral of differential form,,"I have some smooth function $g(x) \colon \mathbb{R}^{n}_{+} \to \mathbb{R}_+$ such that $G_{t} = \{ x \in \mathbb{R}^n_+ \mid g(x) \leqslant t \}$ is compact. I consider a function $$   f(t) = \int\limits_{G_t}a(x)dx_1 \wedge  ... \wedge dx_n $$ I want to find its derivative. In this article http://amath.colorado.edu/pub/wavelets/papers/BEYLKI-1984.pdf author uses the represenation of the form $dx_1 \wedge ... \wedge dx_n = dg(x) \wedge \Omega$ to reduce an integral of the form $dx$ to an iterated integral. Is it possible to do something similar here? I think the answer is $$   f'(t) = \int\limits_{ \{ x\mid g(x)=t \}} a(x) \Omega $$","I have some smooth function $g(x) \colon \mathbb{R}^{n}_{+} \to \mathbb{R}_+$ such that $G_{t} = \{ x \in \mathbb{R}^n_+ \mid g(x) \leqslant t \}$ is compact. I consider a function $$   f(t) = \int\limits_{G_t}a(x)dx_1 \wedge  ... \wedge dx_n $$ I want to find its derivative. In this article http://amath.colorado.edu/pub/wavelets/papers/BEYLKI-1984.pdf author uses the represenation of the form $dx_1 \wedge ... \wedge dx_n = dg(x) \wedge \Omega$ to reduce an integral of the form $dx$ to an iterated integral. Is it possible to do something similar here? I think the answer is $$   f'(t) = \int\limits_{ \{ x\mid g(x)=t \}} a(x) \Omega $$",,"['integration', 'differential-geometry', 'differential-forms']"
53,How many terms in a series expansion,How many terms in a series expansion,,"General: If $f \in C^1$ is a periodic function defined over some multi-dimensional space, then it should be possible to express $f$ as a FINITE fourier series. is this true of any periodic basis? is there a way to determine the number of terms in this finite series? Specific: I have a function that is smooth and continuous and is defined on the unit hypersphere.  I want to know: is it possible to represent this function as a FINITE series in the hyperspherical harmonic basis? how many terms will it take?","General: If $f \in C^1$ is a periodic function defined over some multi-dimensional space, then it should be possible to express $f$ as a FINITE fourier series. is this true of any periodic basis? is there a way to determine the number of terms in this finite series? Specific: I have a function that is smooth and continuous and is defined on the unit hypersphere.  I want to know: is it possible to represent this function as a FINITE series in the hyperspherical harmonic basis? how many terms will it take?",,"['group-theory', 'differential-geometry', 'fourier-analysis', 'fourier-series']"
54,Ways to define a curve,Ways to define a curve,,"I'm trying to give shapes in my physics engine roundness/ curvature. I am aware of various methods for mathematically defining curvature such as bezier-curves, ellipses, etc; but I'm not sure which methods are most appropriate for use in a physics engine. I must consider the speed, flexibility, and difficulty of constructing/joining the curves when choosing my approach. The ideal is a system where a user could easily construct and collide a large amount of curved, aesthetic polygon bodies together, yet I could still maintain a satisfactory framerate. However it's inevitable that ease-of-use and other attributes will suffer. NOTE: my physics engine is continuous, which means I must pre-calculate the times at which polygons will collide. Keep in mind that the curve's route my not be linear. For each suggestion please give the positives/negatives! What techniques are there for mathematically defining a 2D curve? Advantages/Disadvantages (speed, flexibility, ease of construction/use)? Is the technique feasible for an engine where predictability of collisions is crucial?","I'm trying to give shapes in my physics engine roundness/ curvature. I am aware of various methods for mathematically defining curvature such as bezier-curves, ellipses, etc; but I'm not sure which methods are most appropriate for use in a physics engine. I must consider the speed, flexibility, and difficulty of constructing/joining the curves when choosing my approach. The ideal is a system where a user could easily construct and collide a large amount of curved, aesthetic polygon bodies together, yet I could still maintain a satisfactory framerate. However it's inevitable that ease-of-use and other attributes will suffer. NOTE: my physics engine is continuous, which means I must pre-calculate the times at which polygons will collide. Keep in mind that the curve's route my not be linear. For each suggestion please give the positives/negatives! What techniques are there for mathematically defining a 2D curve? Advantages/Disadvantages (speed, flexibility, ease of construction/use)? Is the technique feasible for an engine where predictability of collisions is crucial?",,"['geometry', 'differential-geometry', 'plane-curves', 'collision-detection']"
55,Show $V - E + F = 2 - 2g$,Show,V - E + F = 2 - 2g,"I'd like to show that the Euler characteristic ($V - E + F$) of a compact oriented surface without boundary, $S$ $g$ , is of the form $2 - 2g$ where $S$ $g$ is a sphere with $g$ handles. A sphere with handles is obtained by cutting $2g$ disks out of the sphere and gluing in $g$ cylinders along the boundary circles. Hence, $S$ $0$ is the sphere and the torus is $S$ $1$ . I'm pretty new to topology. But I think induction would make for an easy, understandable proof where the base case is the sphere. Any help or solutions are appreciated!","I'd like to show that the Euler characteristic ($V - E + F$) of a compact oriented surface without boundary, $S$ $g$ , is of the form $2 - 2g$ where $S$ $g$ is a sphere with $g$ handles. A sphere with handles is obtained by cutting $2g$ disks out of the sphere and gluing in $g$ cylinders along the boundary circles. Hence, $S$ $0$ is the sphere and the torus is $S$ $1$ . I'm pretty new to topology. But I think induction would make for an easy, understandable proof where the base case is the sphere. Any help or solutions are appreciated!",,"['algebraic-topology', 'differential-geometry']"
56,Associated bundle,Associated bundle,,"Given a principal $G$-Bundle $P\rightarrow X$ and if we let $G$ act on itself by multiplication (denote this action by $\rho$) we obtain an associated bundle $P\times_{\rho} G=(P\times G)/\sim$ where $(p,f)\sim(gp, gf)$ with fibers homeomorphic to $G$. It is easy to check that this bundle is G-principal; the G-action is given by $g[p,f]=[p,fg]$. If we change the action of $G$ on itself to conjugation (denote this action by $\phi$) we can construct an associated bundle $P \times_{\phi} G$ in the same way. However, I want to show that this is not a principal bundle by showing that the fibers are not only homeomorphic to $G$ but they are groups isomorphic to $G$. (This would imply that the bundle has a section and if it were principal it would be trivial and there are examples of non trivial associated conjugation bundles). How can I show that each fiber of $P \times_{\phi} G$ is a fiber bundle of groups? I would probably have to use the fact that conjugation by a fixed element is a group isomorphism, since in the case of multiplication, which is not a group isomorphism, the obtained bundle is principal.","Given a principal $G$-Bundle $P\rightarrow X$ and if we let $G$ act on itself by multiplication (denote this action by $\rho$) we obtain an associated bundle $P\times_{\rho} G=(P\times G)/\sim$ where $(p,f)\sim(gp, gf)$ with fibers homeomorphic to $G$. It is easy to check that this bundle is G-principal; the G-action is given by $g[p,f]=[p,fg]$. If we change the action of $G$ on itself to conjugation (denote this action by $\phi$) we can construct an associated bundle $P \times_{\phi} G$ in the same way. However, I want to show that this is not a principal bundle by showing that the fibers are not only homeomorphic to $G$ but they are groups isomorphic to $G$. (This would imply that the bundle has a section and if it were principal it would be trivial and there are examples of non trivial associated conjugation bundles). How can I show that each fiber of $P \times_{\phi} G$ is a fiber bundle of groups? I would probably have to use the fact that conjugation by a fixed element is a group isomorphism, since in the case of multiplication, which is not a group isomorphism, the obtained bundle is principal.",,"['algebraic-topology', 'differential-geometry', 'fiber-bundles']"
57,"References for the basic theory of surfaces of revolution, cylinders and cones","References for the basic theory of surfaces of revolution, cylinders and cones",,"I'm looking for references to books were the following types of problems about finding the equation defining a surface of revolution, a cylinder or a cone are treated. These are problems that are usually presented every semester in the University of Costa Rica's multivariable calculus course for engineers. When I was in Costa Rica I asked the younger professors about references and nobody seemed to know, I have not seen such problems in calculus textbooks, and everybody seemed to have some old notes they had borrowed from somebody else when they faced the same situation of having to teach multivariable calculus and had to present these topics in class. The types of problems I'm talking about are of the following sort. Find the equation of the cylinder whose directrix is the curve $$\begin{eqnarray} x^2 + y^2 + 2z^2 &= 8\\ x - y + 2z &= 0 \end{eqnarray} $$ and whose generatrices are parallel to the line $(x, y, z) = (-3, 1, 5) + t(2, 1, -4), \quad t \in \mathbb{R}$. Calculate the equation of the surface of revolution that results from rotating the line  $$\begin{eqnarray} x + y + z &= 0\\ y - z &= 0 \end{eqnarray} $$ around the axis that is the intersection of the planes $x + y = 1$ and $z = 0$. I actually know how to solve such problems by forming a system of equations and eliminating variables until one ends up with an equation involving only $x, y, z$ say, but I would like to have some references where the general theory of surfaces of revolution, cones and cylinders is treated. Thank you very much for any help.","I'm looking for references to books were the following types of problems about finding the equation defining a surface of revolution, a cylinder or a cone are treated. These are problems that are usually presented every semester in the University of Costa Rica's multivariable calculus course for engineers. When I was in Costa Rica I asked the younger professors about references and nobody seemed to know, I have not seen such problems in calculus textbooks, and everybody seemed to have some old notes they had borrowed from somebody else when they faced the same situation of having to teach multivariable calculus and had to present these topics in class. The types of problems I'm talking about are of the following sort. Find the equation of the cylinder whose directrix is the curve $$\begin{eqnarray} x^2 + y^2 + 2z^2 &= 8\\ x - y + 2z &= 0 \end{eqnarray} $$ and whose generatrices are parallel to the line $(x, y, z) = (-3, 1, 5) + t(2, 1, -4), \quad t \in \mathbb{R}$. Calculate the equation of the surface of revolution that results from rotating the line  $$\begin{eqnarray} x + y + z &= 0\\ y - z &= 0 \end{eqnarray} $$ around the axis that is the intersection of the planes $x + y = 1$ and $z = 0$. I actually know how to solve such problems by forming a system of equations and eliminating variables until one ends up with an equation involving only $x, y, z$ say, but I would like to have some references where the general theory of surfaces of revolution, cones and cylinders is treated. Thank you very much for any help.",,"['calculus', 'reference-request', 'differential-geometry', 'analytic-geometry']"
58,Unit Normal Field on a 2D manifold embedded in R^3,Unit Normal Field on a 2D manifold embedded in R^3,,"Let us assume that we are given a closed, orientable 2D manifold embedded in $R^3$, and lets call it $M$. I think it is clear that in a coordinate neighborhood $(U, \phi)$ it is possible to at each point define a unit normal vector $N_p$ by looking at the tangent space $T_pM$ as a subspace of $T_pR^3$ and considering the 1D vector space $T_pM^\perp$. However, there are always two choices of $N_p$. Intuitively, an orientation should should define $N_p$ uniquely, but I am not sure how to use that $M$ is oriented to do this. If we have an orientation 2-form $\Omega$ on $M$, how can we use this to figure out which of the two possible $N_p$'s is correct? Furthermore, since we have $N_p$ defined at each point in $U$, we have a vector field on $U$. I was not sure how to show that this is a smooth vector field, but I believe that once you've done this, you can somehow use a partition of unity to extend $N$ to the entire manifold. But, I think that there is some subtlety even to this. I mean, for a non-orientable manifold such as a Möbius strip, it seems to me that you can define locally a smooth unit-normal vector field, but when you try to extend it to the whole manifold it is no longer a continuous vector field, so somehow the orientation must play a role in the extension, and I am not sure how.","Let us assume that we are given a closed, orientable 2D manifold embedded in $R^3$, and lets call it $M$. I think it is clear that in a coordinate neighborhood $(U, \phi)$ it is possible to at each point define a unit normal vector $N_p$ by looking at the tangent space $T_pM$ as a subspace of $T_pR^3$ and considering the 1D vector space $T_pM^\perp$. However, there are always two choices of $N_p$. Intuitively, an orientation should should define $N_p$ uniquely, but I am not sure how to use that $M$ is oriented to do this. If we have an orientation 2-form $\Omega$ on $M$, how can we use this to figure out which of the two possible $N_p$'s is correct? Furthermore, since we have $N_p$ defined at each point in $U$, we have a vector field on $U$. I was not sure how to show that this is a smooth vector field, but I believe that once you've done this, you can somehow use a partition of unity to extend $N$ to the entire manifold. But, I think that there is some subtlety even to this. I mean, for a non-orientable manifold such as a Möbius strip, it seems to me that you can define locally a smooth unit-normal vector field, but when you try to extend it to the whole manifold it is no longer a continuous vector field, so somehow the orientation must play a role in the extension, and I am not sure how.",,"['calculus', 'general-topology', 'differential-geometry']"
59,Closed geodesics of a non positively curved manifold are minimizing,Closed geodesics of a non positively curved manifold are minimizing,,"As the title says, closed geodesics of a complete non positive sectional curvature manifold should be minimal in their free homotopy class. This should be well known but I don't know a reference. I can imagine at least two proofs: using flat strip theorem or using Morse theory. Neither are very simple, so a reference would be preferred.","As the title says, closed geodesics of a complete non positive sectional curvature manifold should be minimal in their free homotopy class. This should be well known but I don't know a reference. I can imagine at least two proofs: using flat strip theorem or using Morse theory. Neither are very simple, so a reference would be preferred.",,"['differential-geometry', 'riemannian-geometry', 'curvature', 'geodesic']"
60,Stable bundles over $\Bbb P^1$.,Stable bundles over .,\Bbb P^1,"Is there a direct way to see that the only stable vector bundles over $\Bbb P^1$ are line bundles? I think that this can be shown using the Birkhoff–Grothendieck theorem, but it seems like an overkill here. If $E$ is a rank $r$ vector bundle over $\Bbb P^1$ and $F \subset E$ any subbundle, then the stability condition gives $$ \mu(F) < \mu(E) \iff \frac{\int_{\Bbb P^1} c_1(F)}{\text{rank}(F)} < \frac{\int_{\Bbb P^1} c_1(E)}{\text{rank}(E)} \iff  \text{rank}(E)\int_{\Bbb P^1} c_1(F) < \text{rank}(F)\int_{\Bbb P^1} c_1(E). $$ However, I can't find a direct way to argue from here that $\text{rank}(E) =r= 1$ . What additional information do I need?","Is there a direct way to see that the only stable vector bundles over are line bundles? I think that this can be shown using the Birkhoff–Grothendieck theorem, but it seems like an overkill here. If is a rank vector bundle over and any subbundle, then the stability condition gives However, I can't find a direct way to argue from here that . What additional information do I need?","\Bbb P^1 E r \Bbb P^1 F \subset E 
\mu(F) < \mu(E) \iff \frac{\int_{\Bbb P^1} c_1(F)}{\text{rank}(F)} < \frac{\int_{\Bbb P^1} c_1(E)}{\text{rank}(E)} \iff  \text{rank}(E)\int_{\Bbb P^1} c_1(F) < \text{rank}(F)\int_{\Bbb P^1} c_1(E).
 \text{rank}(E) =r= 1","['differential-geometry', 'complex-geometry', 'vector-bundles']"
61,Definition of smooth map between smooth manifolds,Definition of smooth map between smooth manifolds,,"Let $(M,\mathcal{A})$ an m-dimensional smooth manifold and $(N, \mathcal{B})$ a n-dimensional smooth manifold, with $\mathcal{A}:=\{\phi_i:U_i\to V_i \ | \ i \in I\}$ an atlas for $M$ (that is: $U_i \subseteq M$ and $V_i \subseteq \mathbb{R}^m$ are open sets, $\phi$ is an omeomorphism and the maps $\phi_\alpha\phi_\beta^{-1}$ are $C^{\infty}$ )  and $\mathcal{B}:=\{\psi_i:W_j\to Z_j \ | \ j \in J\}$ an atlas for $N$ . A function $f:(M,\mathcal{A}) \to (N,\mathcal{B})$ is smooth if $\forall p \in M, \ \exists U_i \in \mathcal{A} \  \exists W_j \in \mathcal{B}$ such that $p\in U_i, \ f(p) \in W_j$ and $f(U_i) \subseteq W_j$ The composition $\psi_j \circ f \circ \phi_i^{-1}$ is $C^{\infty}$ The problem is that a manifold is usually defined as $(M, [\mathcal{A}])$ where $[\mathcal{A}]$ is the equivalence class of all smooth atlas equivalent to $\mathcal{A}$ (two atlas $\mathcal{A}$ and $\mathcal{A'}$ are equivalent if $\mathcal{A} \cup \mathcal{A'}$ is an atlas). Is the definition of smooth function independent of the choice of equivalent atlas? Let $\mathcal{A'}$ equivalent to $\mathcal{A}$ and $\mathcal{B'}$ equivalent to $\mathcal{B}$ , I can't find $U'_i \in \mathcal{A'}$ and $W'_j \in \mathcal{B'}$ such that $p\in U'_i, \ f(p) \in W'_j$ and $f(U'_i) \subseteq W'_j$ . Can you give me suggestions of what should i choose as $U'_i$ and $W'_j$ ?","Let an m-dimensional smooth manifold and a n-dimensional smooth manifold, with an atlas for (that is: and are open sets, is an omeomorphism and the maps are )  and an atlas for . A function is smooth if such that and The composition is The problem is that a manifold is usually defined as where is the equivalence class of all smooth atlas equivalent to (two atlas and are equivalent if is an atlas). Is the definition of smooth function independent of the choice of equivalent atlas? Let equivalent to and equivalent to , I can't find and such that and . Can you give me suggestions of what should i choose as and ?","(M,\mathcal{A}) (N, \mathcal{B}) \mathcal{A}:=\{\phi_i:U_i\to V_i \ | \ i \in I\} M U_i \subseteq M V_i \subseteq \mathbb{R}^m \phi \phi_\alpha\phi_\beta^{-1} C^{\infty} \mathcal{B}:=\{\psi_i:W_j\to Z_j \ | \ j \in J\} N f:(M,\mathcal{A}) \to (N,\mathcal{B}) \forall p \in M, \ \exists U_i \in \mathcal{A} \  \exists W_j \in \mathcal{B} p\in U_i, \ f(p) \in W_j f(U_i) \subseteq W_j \psi_j \circ f \circ \phi_i^{-1} C^{\infty} (M, [\mathcal{A}]) [\mathcal{A}] \mathcal{A} \mathcal{A} \mathcal{A'} \mathcal{A} \cup \mathcal{A'} \mathcal{A'} \mathcal{A} \mathcal{B'} \mathcal{B} U'_i \in \mathcal{A'} W'_j \in \mathcal{B'} p\in U'_i, \ f(p) \in W'_j f(U'_i) \subseteq W'_j U'_i W'_j","['differential-geometry', 'smooth-manifolds']"
62,The length of a curve determined by a curve in the tangent space starting from the origin.,The length of a curve determined by a curve in the tangent space starting from the origin.,,"Let $M$ be a Riemannian manifold, $p$ is a point of $M$ . Suppose $exp_p$ is defined on an open neighborhood $U$ of the origin, and let $v$ be a vector in $U$ . By definition, the length of the curve $exp_p(tv), t\in[0,1]$ is just $|v|$ . However, if I choose an arbitrary curve $\alpha(t)$ in $U$ joining the origin and $v$ , what can I say about the length of $exp_p(\alpha(t))$ . Is it necessary that the length of $exp_p(\alpha(t))$ is always larger than $|v|$ ?","Let be a Riemannian manifold, is a point of . Suppose is defined on an open neighborhood of the origin, and let be a vector in . By definition, the length of the curve is just . However, if I choose an arbitrary curve in joining the origin and , what can I say about the length of . Is it necessary that the length of is always larger than ?","M p M exp_p U v U exp_p(tv), t\in[0,1] |v| \alpha(t) U v exp_p(\alpha(t)) exp_p(\alpha(t)) |v|","['geometry', 'differential-geometry', 'riemannian-geometry']"
63,Differential vs derivative in Differential Geometry,Differential vs derivative in Differential Geometry,,"In differential geometry one shows that, associated to a smooth map between manifolds $f:M\to N$ there is a linear map $d_pf: T_pM \to T_{f(p)}N$ for each $p\in M$ which is called the differential of $f$ at $p$ . My question is: why is it called “differential” and not derivative? I understand the expression in local coordinates is in fact a Jacobian matrix. In my mind “differential” stands for the “change in $f$ ” and derivative means the rate of change of $f$ compared to the rate of change of the variable. What is the reason for this name?","In differential geometry one shows that, associated to a smooth map between manifolds there is a linear map for each which is called the differential of at . My question is: why is it called “differential” and not derivative? I understand the expression in local coordinates is in fact a Jacobian matrix. In my mind “differential” stands for the “change in ” and derivative means the rate of change of compared to the rate of change of the variable. What is the reason for this name?",f:M\to N d_pf: T_pM \to T_{f(p)}N p\in M f p f f,['differential-geometry']
64,Prove that if a smooth manifold $M$ is contractible then every vector bundle over $M$ is trivial,Prove that if a smooth manifold  is contractible then every vector bundle over  is trivial,M M,"I've seen that this can be proved by using that if two functions are homotopic then the pullbacks of such functions are isomorphic, but the only ""easy"" proof of this I found is in Hatcher's vector bundles book and I don't find this proof very clear. This was left to me as a homework exercise and all we've seen of vector bundles are the basic definitions, constrictions by cocycles and that every vector bundle has a riemmanian metric so I don't know how to proceed with only this, any help would be appreciated","I've seen that this can be proved by using that if two functions are homotopic then the pullbacks of such functions are isomorphic, but the only ""easy"" proof of this I found is in Hatcher's vector bundles book and I don't find this proof very clear. This was left to me as a homework exercise and all we've seen of vector bundles are the basic definitions, constrictions by cocycles and that every vector bundle has a riemmanian metric so I don't know how to proceed with only this, any help would be appreciated",,"['differential-geometry', 'riemannian-geometry', 'differential-topology', 'homotopy-theory', 'vector-bundles']"
65,Steenrod squares and higher cup products for differential forms?,Steenrod squares and higher cup products for differential forms?,,"I am physicist, so I am sorry if I am not too rigorous in the following. I have two (closely related I guess) questions: Let me consider a triangulated manifold $M$ and its simplicial cohomology. Here the Steenrod square is an operation $Sq^q: H^p (M,Z_2) \to H^{p+q}(M,Z_2)$ . My manifold is smooth and I have also a differential structure on it: is there an analogous operation also on the de Rham cohomology? (eventually by considering forms in $H_{dR}^p (M)$ mod 2 for example) Now, perhaps more important for me, the Steenrod squares can be written on a element $\alpha_p \in H^p(M,Z_2)$ by introducing the so called higher cup products, so that $Sq^q \alpha_p = \alpha_p \cup_{p-q} \alpha_p$ (where $\cup_0 = \cup$ is the standard cup product and $\cup_p$ actually makes sense for $\alpha_p \in H^p(M,G)$ for some Abelian group $G$ ). Is there a generalization of these products also for differential forms? In my understanding these higher cup products basically come from the fact that the standard cup product is not graded commutative at the level of cochains (and its failure to be commutative is measured by $\cup_1$ ). For the differential forms the wedge product ('which is the cup product for forms') has no this kind of problem, so I cannot see how similar products could arise for the forms. Let me end with an intuitive physical picture that I have in mind (just to explain my questions). I start with a manifold $M$ with a triangulation. This is a discretization of my physical space, where I work with cochains on simplexes. In my view this is an approximation: I then take the continuum limit to $M$ and I represent the cochains as forms. As long as I am concerned just with the ordinary cup product I somewhat know how to handle it (physically). But higher cup products? I really do not know how to make sense of expressions like $\alpha \cup_1 \alpha$ for example (they somewhat resemble 'discretization errors' in this intuitive picture). I have tried to look (and I am looking) in the mathematical literature but I have not found anything for now, especially for the part regarding the higher cup products (at least anything for what I could understand).","I am physicist, so I am sorry if I am not too rigorous in the following. I have two (closely related I guess) questions: Let me consider a triangulated manifold and its simplicial cohomology. Here the Steenrod square is an operation . My manifold is smooth and I have also a differential structure on it: is there an analogous operation also on the de Rham cohomology? (eventually by considering forms in mod 2 for example) Now, perhaps more important for me, the Steenrod squares can be written on a element by introducing the so called higher cup products, so that (where is the standard cup product and actually makes sense for for some Abelian group ). Is there a generalization of these products also for differential forms? In my understanding these higher cup products basically come from the fact that the standard cup product is not graded commutative at the level of cochains (and its failure to be commutative is measured by ). For the differential forms the wedge product ('which is the cup product for forms') has no this kind of problem, so I cannot see how similar products could arise for the forms. Let me end with an intuitive physical picture that I have in mind (just to explain my questions). I start with a manifold with a triangulation. This is a discretization of my physical space, where I work with cochains on simplexes. In my view this is an approximation: I then take the continuum limit to and I represent the cochains as forms. As long as I am concerned just with the ordinary cup product I somewhat know how to handle it (physically). But higher cup products? I really do not know how to make sense of expressions like for example (they somewhat resemble 'discretization errors' in this intuitive picture). I have tried to look (and I am looking) in the mathematical literature but I have not found anything for now, especially for the part regarding the higher cup products (at least anything for what I could understand).","M Sq^q: H^p (M,Z_2) \to H^{p+q}(M,Z_2) H_{dR}^p (M) \alpha_p \in H^p(M,Z_2) Sq^q \alpha_p = \alpha_p \cup_{p-q} \alpha_p \cup_0 = \cup \cup_p \alpha_p \in H^p(M,G) G \cup_1 M M \alpha \cup_1 \alpha","['differential-geometry', 'algebraic-topology', 'homology-cohomology', 'simplicial-complex', 'de-rham-cohomology']"
66,Computing the the exterior derivative of the connection matrix on a hermitian vector bundle,Computing the the exterior derivative of the connection matrix on a hermitian vector bundle,,"If $D$ is the Chern connection on a holomorphic hermitian vector bundle $(E,h)$ and $e$ is a holomorphic frame, then $$\vartheta=\partial h \cdot h^{-1}$$ where $h_{ij}=h(e_i,e_j)$ . Here $\vartheta$ is the connection matrix and $\partial h$ means the del-derivative of the matrix $h$ . I was going through the following calculation $$ \begin{align*} d\vartheta &= (\partial+\bar{\partial})\vartheta =\bar{\partial}\vartheta+\partial(\partial h\cdot h^{-1})= \bar{\partial}\vartheta-\partial h \wedge \partial h^{-1}\\ &= \bar{\partial}\vartheta + \partial h\wedge h^{-1}\partial hh^{-1} = \bar{\partial}\vartheta + \partial hh^{-1}\wedge\partial hh^{-1}. \end{align*} $$ I don't see where the last three equalities come from, firstly why do we have $$ \bar{\partial}\vartheta+\partial(\partial h\cdot h^{-1})= \bar{\partial}\vartheta-\partial h \wedge \partial h^{-1}, $$ is this an application of the Leibniz rule? Secondly why does this equal $$ \bar{\partial}\vartheta-\partial h \wedge \partial h^{-1}=\bar{\partial}\vartheta + \partial h\wedge h^{-1}\partial hh^{-1} $$ and $$ \bar{\partial}\vartheta + \partial h\wedge h^{-1}\partial hh^{-1} =\bar{\partial}\vartheta + \partial hh^{-1}\wedge\partial hh^{-1}? $$","If is the Chern connection on a holomorphic hermitian vector bundle and is a holomorphic frame, then where . Here is the connection matrix and means the del-derivative of the matrix . I was going through the following calculation I don't see where the last three equalities come from, firstly why do we have is this an application of the Leibniz rule? Secondly why does this equal and","D (E,h) e \vartheta=\partial h \cdot h^{-1} h_{ij}=h(e_i,e_j) \vartheta \partial h h 
\begin{align*}
d\vartheta &= (\partial+\bar{\partial})\vartheta =\bar{\partial}\vartheta+\partial(\partial h\cdot h^{-1})= \bar{\partial}\vartheta-\partial h \wedge \partial h^{-1}\\
&= \bar{\partial}\vartheta + \partial h\wedge h^{-1}\partial hh^{-1} = \bar{\partial}\vartheta + \partial hh^{-1}\wedge\partial hh^{-1}.
\end{align*}
 
\bar{\partial}\vartheta+\partial(\partial h\cdot h^{-1})= \bar{\partial}\vartheta-\partial h \wedge \partial h^{-1},
 
\bar{\partial}\vartheta-\partial h \wedge \partial h^{-1}=\bar{\partial}\vartheta + \partial h\wedge h^{-1}\partial hh^{-1}
 
\bar{\partial}\vartheta + \partial h\wedge h^{-1}\partial hh^{-1} =\bar{\partial}\vartheta + \partial hh^{-1}\wedge\partial hh^{-1}?
","['differential-geometry', 'complex-geometry']"
67,Winding numbers in QCD and winding numbers in complex analysis. Is there a relation through a differential geometric generalization?,Winding numbers in QCD and winding numbers in complex analysis. Is there a relation through a differential geometric generalization?,,"I have a background in theoretical physics and the first time I came across winding numbers was in the context of the vacuum of QCD. By the way physicists treat this topic, I thought it had little to do with Winding numbers in complex analysis.  Now I, came across some results of complex Brownian motion applied to proofs of Picard's theorems in complex analysis, related to winding and tangling of curves, and also to similarstochastic techniques applied to path integral formulation of quantum mechanics and related QFT topics. Thus, I am asking myself if winding numbers in QCD are related to closed loops on a certain bundle related to the SU(3) group. The paths could be the brownian motion that provides an equivalent measure to the vacuum state.  I am very familiar with stochastic calculus applied to QFT, differential geometry and functional analysis,  what I am lacking to answer the question in the title is the interpretation of the QCD winding numbers in this sense. I have also been thinking about Berry phases  for U(1) groups, and in that case the Berry phase gained through closed loops in the base of a fibre bundle. Is this related to an analogous question to the one of the winding numbers of QCD for this (way simpler) abelian group? Thanks.","I have a background in theoretical physics and the first time I came across winding numbers was in the context of the vacuum of QCD. By the way physicists treat this topic, I thought it had little to do with Winding numbers in complex analysis.  Now I, came across some results of complex Brownian motion applied to proofs of Picard's theorems in complex analysis, related to winding and tangling of curves, and also to similarstochastic techniques applied to path integral formulation of quantum mechanics and related QFT topics. Thus, I am asking myself if winding numbers in QCD are related to closed loops on a certain bundle related to the SU(3) group. The paths could be the brownian motion that provides an equivalent measure to the vacuum state.  I am very familiar with stochastic calculus applied to QFT, differential geometry and functional analysis,  what I am lacking to answer the question in the title is the interpretation of the QCD winding numbers in this sense. I have also been thinking about Berry phases  for U(1) groups, and in that case the Berry phase gained through closed loops in the base of a fibre bundle. Is this related to an analogous question to the one of the winding numbers of QCD for this (way simpler) abelian group? Thanks.",,"['differential-geometry', 'stochastic-calculus', 'winding-number']"
68,Metric circle on a sphere,Metric circle on a sphere,,"Consider $\mathbb S_R^2 \subseteq \mathbb R^3$ be a sphere of radius $R$ . Let $N$ denote the north pole and $0 < r < R \pi$ . Define the metric circle with center N to be all points, $x \in \mathbb S_R^2$ that $$d_{\mathbb S_R^2}(x,N) = r$$ Here $d_{\mathbb S_R^2}$ is the induced metric on the sphere. Parameterize $\mathbb S_R^2$ with the usual spherical coordinates: $$\Gamma:[0,2\pi) \times [0,\pi]\to\mathbb{R}^3 \quad \quad  (\phi, \theta)\mapsto (R\sin\theta\cos\phi,R\sin\theta\sin\phi, R\cos\theta),$$ My hunch is that the metric circle with center N is spherical circle: $$\Gamma ( [0,2\pi) \times \{ r / R \} ) \subseteq \mathbb S_R^2$$ However, I cannot justify this claim using only elementary arguments using only elementary techniques. Edit: Bump!","Consider be a sphere of radius . Let denote the north pole and . Define the metric circle with center N to be all points, that Here is the induced metric on the sphere. Parameterize with the usual spherical coordinates: My hunch is that the metric circle with center N is spherical circle: However, I cannot justify this claim using only elementary arguments using only elementary techniques. Edit: Bump!","\mathbb S_R^2 \subseteq \mathbb R^3 R N 0 < r < R \pi x \in \mathbb S_R^2 d_{\mathbb S_R^2}(x,N) = r d_{\mathbb S_R^2} \mathbb S_R^2 \Gamma:[0,2\pi) \times [0,\pi]\to\mathbb{R}^3 \quad \quad  (\phi, \theta)\mapsto (R\sin\theta\cos\phi,R\sin\theta\sin\phi, R\cos\theta), \Gamma ( [0,2\pi) \times \{ r / R \} ) \subseteq \mathbb S_R^2","['differential-geometry', 'spheres']"
69,Curve cover direction,Curve cover direction,,"I have interesting problem: Let's imagine a wire bent into a curve. We have a set of non-stretchable plastic covers of various diameters. The larger the diameter of the cover, the deeper it can be placed on the wire. The cover has some direction. With the casing diameter approaching zero, the direction is that of the derivative at the ends of the curve. If the cover is wide enough so that the entire curve fits in it, there is only one cover instead of two (starting and ending) and its direction can be calculated using the ""rotating calipers"" algorithm (in practice, a poly-line can be used instead of a smooth curve). How to calculate the direction depending on the curve (implemented as a polyline) and the width of the cover? Problem goal: image reconstruction where we have many polylines and gaps between parts of polylines, we need to find the most appropriate line B for line A and connect them by filling the gap - if tail cover of A intersect with head cover of B, optionally, we also limit the cover lengths. Hint: maybe easier parameter will be not width but rather depth; if depth small - direction will equals to direction first/last segment; up to the length of this segment; next, when will covered two segments, direction will between direction first and second segment, weighted with (first segment length, length of part of second segment); next will weighted direction between (first segment, second segment, part of third segment) etc. Using rotating calipers on k first/last of n vertex ?","I have interesting problem: Let's imagine a wire bent into a curve. We have a set of non-stretchable plastic covers of various diameters. The larger the diameter of the cover, the deeper it can be placed on the wire. The cover has some direction. With the casing diameter approaching zero, the direction is that of the derivative at the ends of the curve. If the cover is wide enough so that the entire curve fits in it, there is only one cover instead of two (starting and ending) and its direction can be calculated using the ""rotating calipers"" algorithm (in practice, a poly-line can be used instead of a smooth curve). How to calculate the direction depending on the curve (implemented as a polyline) and the width of the cover? Problem goal: image reconstruction where we have many polylines and gaps between parts of polylines, we need to find the most appropriate line B for line A and connect them by filling the gap - if tail cover of A intersect with head cover of B, optionally, we also limit the cover lengths. Hint: maybe easier parameter will be not width but rather depth; if depth small - direction will equals to direction first/last segment; up to the length of this segment; next, when will covered two segments, direction will between direction first and second segment, weighted with (first segment length, length of part of second segment); next will weighted direction between (first segment, second segment, part of third segment) etc. Using rotating calipers on k first/last of n vertex ?",,"['geometry', 'differential-geometry']"
70,Proof check that a given metric on $\mathbb{S}^1\times\mathbb{R}$ is not time-orientable,Proof check that a given metric on  is not time-orientable,\mathbb{S}^1\times\mathbb{R},"I want to prove that there exist a non time-orientable Lorentzian metric on the manifold $M=\mathbb{S}^1\times\mathbb{R}.$ I have an idea on how to do this but since it's the first time I approach this kind of exercises I would like to have a check of my reasoning... Let $\theta$ be the coordinate on $\mathbb{S}^1$ and $t$ be the coordinate on $\mathbb{R}:$ my intuition suggests to consider the metric given by the matrix $$\begin{pmatrix}\cos\theta & \sin\theta\\ \sin\theta & -\cos\theta\end{pmatrix}$$ on the tangent space $T_{(\theta,t)}M$ for each $\theta$ and $t:$ this metric is Lorentzian, since for each choice of the coordinates this matrix has signature $(1,-1).$ I know that a metric is time-orientable if and only if there exists a vector field $X$ on $M$ such that $X_p$ is timelike for each $p\in M:$ to conclude I then have to prove that such a $X$ cannot exist. Working in coordinates such an $X=(X_1,X_2)$ should verify the relation $$(X_1,X_2)\begin{pmatrix}\cos\theta & \sin\theta\\ \sin\theta & -\cos\theta\end{pmatrix}\begin{pmatrix}X_1\\X_2\end{pmatrix}<0$$ for each $\theta$ and $t$ (the metric is $t-$ indipendent but $X_1,X_2$ are functions of $\theta$ and $t$ ): a simple computation then gives $$(X_1^2-X_2^2)\cos\theta+2X_1X_2\sin\theta<0$$ The function on the LHS is continuous: since for $\theta=0$ and $\theta=\pi$ we respectively get $$X_1^2-X_2^2$$ $$X_2^2-X_1^2$$ we find that this value cannot alway be negative, hence a timelike vector field $X$ cannot exists. Is this reasoning correct or are there some mistakes? In this case how can I correct them?","I want to prove that there exist a non time-orientable Lorentzian metric on the manifold I have an idea on how to do this but since it's the first time I approach this kind of exercises I would like to have a check of my reasoning... Let be the coordinate on and be the coordinate on my intuition suggests to consider the metric given by the matrix on the tangent space for each and this metric is Lorentzian, since for each choice of the coordinates this matrix has signature I know that a metric is time-orientable if and only if there exists a vector field on such that is timelike for each to conclude I then have to prove that such a cannot exist. Working in coordinates such an should verify the relation for each and (the metric is indipendent but are functions of and ): a simple computation then gives The function on the LHS is continuous: since for and we respectively get we find that this value cannot alway be negative, hence a timelike vector field cannot exists. Is this reasoning correct or are there some mistakes? In this case how can I correct them?","M=\mathbb{S}^1\times\mathbb{R}. \theta \mathbb{S}^1 t \mathbb{R}: \begin{pmatrix}\cos\theta & \sin\theta\\ \sin\theta & -\cos\theta\end{pmatrix} T_{(\theta,t)}M \theta t: (1,-1). X M X_p p\in M: X X=(X_1,X_2) (X_1,X_2)\begin{pmatrix}\cos\theta & \sin\theta\\ \sin\theta & -\cos\theta\end{pmatrix}\begin{pmatrix}X_1\\X_2\end{pmatrix}<0 \theta t t- X_1,X_2 \theta t (X_1^2-X_2^2)\cos\theta+2X_1X_2\sin\theta<0 \theta=0 \theta=\pi X_1^2-X_2^2 X_2^2-X_1^2 X","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'semi-riemannian-geometry']"
71,Why are the coefficients of a smooth differential form smooth?,Why are the coefficients of a smooth differential form smooth?,,"Suppose $U$ is an open subset of $\mathbb R^n$ , and $\omega:U\to\operatorname{Alt}^k(\mathbb R^n)$ is a smooth differential $k$ -form. By $\operatorname{Alt}^k(\mathbb R^n)$ I mean the set of alternating $k$ -linear forms, and by ""smooth"" I mean that $\omega$ is infinitely differentiable (since $\operatorname{Alt}^k(\mathbb R^n)$ is a real normed space, we can make sense of $D\omega$ and $D^2\omega$ , etc., where $D$ denotes the Fréchet derivative). We can write $\omega$ in coordinates as $\sum_{I}\alpha_Idx^I$ , where each $\alpha_I:U\to\mathbb R$ is a function. However, how do we conclude that each $\alpha_I$ is smooth from the fact that $\omega$ is smooth?","Suppose is an open subset of , and is a smooth differential -form. By I mean the set of alternating -linear forms, and by ""smooth"" I mean that is infinitely differentiable (since is a real normed space, we can make sense of and , etc., where denotes the Fréchet derivative). We can write in coordinates as , where each is a function. However, how do we conclude that each is smooth from the fact that is smooth?",U \mathbb R^n \omega:U\to\operatorname{Alt}^k(\mathbb R^n) k \operatorname{Alt}^k(\mathbb R^n) k \omega \operatorname{Alt}^k(\mathbb R^n) D\omega D^2\omega D \omega \sum_{I}\alpha_Idx^I \alpha_I:U\to\mathbb R \alpha_I \omega,['differential-geometry']
72,Induced connection 1-form on orthogonal frame bundle by the Levi-Civita connection on tangent bundle,Induced connection 1-form on orthogonal frame bundle by the Levi-Civita connection on tangent bundle,,"I recently posted a similar question but I have deleted that one and replaced it with this one, which is hopefully more focused. On page 317 of this paper by Pu-Young Kim and Joon-Sik Park they say It is well known that, in orthonormal frame bundle $O(M)$ of a Riemannian manifold $(M,g)$ , the connection form defined by the Levi-Civita connection becomes a connection of principal fibre bundle $O(M)$ . I could not find a reference for this well known result so I am trying to figure it out on my own. Suppose $M$ has dimension $n$ . The Levi-Civita connection is a connection on $TM$ , and $TM$ can be viewed as an associated vector bundle whose fiber is isomorphic to $\mathbb{R}^n$ with structure group $O(n, \mathbb{R})$ . I am also familiar with Ehresmann connections on principal bundles, and in this case the principal bundle of interest is the $O(M)$ frame bundle. I am having trouble connecting the Levi-Civita connection to the associated vector bundle and then connecting that to a connection on the $O(M)$ bundle. So far what I've thought of is that we know every vector bundle has a metric connection, so if we can somehow introduce a torsion-free condition to the associated vector bundle then we will have a Levi-Civita connection which we can hopefully show is unique. But what does this have to do with the Levi-Civita connection on $TM$ ? And how does all of this induce a Ehresmann connection on the frame bundle $O(M)$ ?","I recently posted a similar question but I have deleted that one and replaced it with this one, which is hopefully more focused. On page 317 of this paper by Pu-Young Kim and Joon-Sik Park they say It is well known that, in orthonormal frame bundle of a Riemannian manifold , the connection form defined by the Levi-Civita connection becomes a connection of principal fibre bundle . I could not find a reference for this well known result so I am trying to figure it out on my own. Suppose has dimension . The Levi-Civita connection is a connection on , and can be viewed as an associated vector bundle whose fiber is isomorphic to with structure group . I am also familiar with Ehresmann connections on principal bundles, and in this case the principal bundle of interest is the frame bundle. I am having trouble connecting the Levi-Civita connection to the associated vector bundle and then connecting that to a connection on the bundle. So far what I've thought of is that we know every vector bundle has a metric connection, so if we can somehow introduce a torsion-free condition to the associated vector bundle then we will have a Levi-Civita connection which we can hopefully show is unique. But what does this have to do with the Levi-Civita connection on ? And how does all of this induce a Ehresmann connection on the frame bundle ?","O(M) (M,g) O(M) M n TM TM \mathbb{R}^n O(n, \mathbb{R}) O(M) O(M) TM O(M)","['differential-geometry', 'vector-bundles', 'connections', 'principal-bundles']"
73,How to understand all characteristic classes as generators of classifying space cohomologies,How to understand all characteristic classes as generators of classifying space cohomologies,,"Context: I'm somewhere in the middle of my study of differential geometry and starting to learn about characteristic classes. I like to have a general intuitive understanding of a concept before diving into details, and I've been struggling to assemble that understanding for characteristic classes. Getting an answer to the following couple of questions would be a huge help. To set the stage, let's restrict to the smooth category and define characteristic classes as natural transformations between the (contravariant) functor $A$ from the category of smooth manifolds $\mathrm{Man}^\infty$ to $\mathrm{Set}$ which maps a manifold $M$ to its associated set of isomorphism classes of vector bundles with base $M$ (and mapping morphisms to pullbacks), and a cohomology functor $B$ from $\mathrm{Man}^\infty$ to $\mathrm{Set}$ which maps a manifold to its set of cohomology groups. We can develop an alternative characterization as follows. Exploiting a bijection between isomorphisms classes of real $n$ -vector bundles and isomorphism classes of $GL_n(\mathbb{R})$ -principal bundles, one can construct the classifying space $BO(n)$ and show that all real bundles over $M$ are pullbacks of the universal bundle $\gamma_n$ over this space. This is useful because it means that $BO(n)$ represents the functor $A$ , so by the Yoneda lemma, we can think about characteristic classes for $n$ -vector bundles as choices of elements in the cohomology of $BO(n)$ . A similar result holds for complex vector bundles if we replace $BO(n)$ with $BU(n)$ . These ideas are all nicely summarized, for example, in this REU paper . This can in turn be made more tangible by computing some cohomology rings for these classifying spaces. For example, $H^*(BO(n), \mathbb{Z}_2) \cong \mathbb{Z}_2[x_1, \dots, x_n]$ $H^*(BU(n), \mathbb{Z}) \cong \mathbb{Z}[y_1, \dots, y_n]$ and you can pick out canonical manifestations of these isomorphisms. Putting together all of the pieces, characteristic classes for real vector bundles with coefficients in $\mathbb{Z}_2$ are generated by the $x_i$ (the Stiefel-Whitney classes), while for complex vector bundles with coefficients in $\mathbb{Z}$ they are generated by the $y_i$ (the Chern classes). Now, there are only so many characteristic classes discussed in the literature: Stiefel-Whitney, Chern, Thom, Euler, Pontryagin, Todd. My questions are as follows: Is there a concise way to see how Thom, Euler, Pontryagin, and Todd classes fit in this framework of looking at the generators of $H^*(BG,R)$ for $G = O(n), U(n)$ and some choice of ring $R$ ? How come the list of characteristic classes stops there, given the number of rings one can consider? That is, why does it suffice to look at some subset of all of the possible rings, and why do we choose the ones we do?","Context: I'm somewhere in the middle of my study of differential geometry and starting to learn about characteristic classes. I like to have a general intuitive understanding of a concept before diving into details, and I've been struggling to assemble that understanding for characteristic classes. Getting an answer to the following couple of questions would be a huge help. To set the stage, let's restrict to the smooth category and define characteristic classes as natural transformations between the (contravariant) functor from the category of smooth manifolds to which maps a manifold to its associated set of isomorphism classes of vector bundles with base (and mapping morphisms to pullbacks), and a cohomology functor from to which maps a manifold to its set of cohomology groups. We can develop an alternative characterization as follows. Exploiting a bijection between isomorphisms classes of real -vector bundles and isomorphism classes of -principal bundles, one can construct the classifying space and show that all real bundles over are pullbacks of the universal bundle over this space. This is useful because it means that represents the functor , so by the Yoneda lemma, we can think about characteristic classes for -vector bundles as choices of elements in the cohomology of . A similar result holds for complex vector bundles if we replace with . These ideas are all nicely summarized, for example, in this REU paper . This can in turn be made more tangible by computing some cohomology rings for these classifying spaces. For example, and you can pick out canonical manifestations of these isomorphisms. Putting together all of the pieces, characteristic classes for real vector bundles with coefficients in are generated by the (the Stiefel-Whitney classes), while for complex vector bundles with coefficients in they are generated by the (the Chern classes). Now, there are only so many characteristic classes discussed in the literature: Stiefel-Whitney, Chern, Thom, Euler, Pontryagin, Todd. My questions are as follows: Is there a concise way to see how Thom, Euler, Pontryagin, and Todd classes fit in this framework of looking at the generators of for and some choice of ring ? How come the list of characteristic classes stops there, given the number of rings one can consider? That is, why does it suffice to look at some subset of all of the possible rings, and why do we choose the ones we do?","A \mathrm{Man}^\infty \mathrm{Set} M M B \mathrm{Man}^\infty \mathrm{Set} n GL_n(\mathbb{R}) BO(n) M \gamma_n BO(n) A n BO(n) BO(n) BU(n) H^*(BO(n), \mathbb{Z}_2) \cong \mathbb{Z}_2[x_1, \dots, x_n] H^*(BU(n), \mathbb{Z}) \cong \mathbb{Z}[y_1, \dots, y_n] \mathbb{Z}_2 x_i \mathbb{Z} y_i H^*(BG,R) G = O(n), U(n) R","['differential-geometry', 'homology-cohomology', 'complex-geometry', 'characteristic-classes', 'classifying-spaces']"
74,Ricci Flow: The existence of potential of Curvature,Ricci Flow: The existence of potential of Curvature,,"For a compact Riemannian Manifold $(M,g)$ without boundary. $R$ as the scalar curvature. And $d\mu$ is the Riemannian volume form. So we can define the average of the scalar curvature $r:=  \frac{\int_{M} R d\mu}{\int_{M}  d\mu}$ When consider the equation $$\Delta f = R-r$$ I was told that $f$ must exist due to the fact that $$\int_M R-r d\mu =0  \quad (1)$$ But I cant prove this as true. I current idea is try to use the Elliptic PDE theory, but of what from the theory? I think Fredholm Theory is a choice but I don't know how to connect the fact (1) to there. Any help will be appreciated .","For a compact Riemannian Manifold without boundary. as the scalar curvature. And is the Riemannian volume form. So we can define the average of the scalar curvature When consider the equation I was told that must exist due to the fact that But I cant prove this as true. I current idea is try to use the Elliptic PDE theory, but of what from the theory? I think Fredholm Theory is a choice but I don't know how to connect the fact (1) to there. Any help will be appreciated .","(M,g) R d\mu r:=  \frac{\int_{M} R d\mu}{\int_{M}  d\mu} \Delta f = R-r f \int_M R-r d\mu =0  \quad (1)","['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'ricci-flow', 'elliptic-operators']"
75,Alternate definition of riemannian manifold,Alternate definition of riemannian manifold,,"By the Nash embedding theorem, it seems the definition of riemannian smooth manifold is equivalent to the zero locus of some functions $f_1,\dots,f_r : \mathbb{R}^n\to\mathbb{R} $ which are $C^\infty$ and which differentials are zero at no point. This alternate definition is simpler, because it does not introduce partial charts, the metric tensor is just the restriction of the euclidean inner product and the Levi-Civita connection is just the orthogonal projection of the usual derivative of vector fields. And as a bonus, the zero locus approach is closer to the definition of affine schemes in algebraic geometry. Pseudo-riemannian manifolds can also be defined this way, under the additional assumption of stable causality. So what is the advantage of the standard definition of riemannian manifold through charts and custom metric tensors? Is it just that the dimension increase of the Nash embedding $n(n+1)(3n+11)/2$ makes computations intractable? The story of an internal observer's viewpoint is not very convincing, because the only riemannian manifolds with rigid body motions (as would be a true internal observer) are the ones with constant curvature, so a tiny part of riemannian manifolds.","By the Nash embedding theorem, it seems the definition of riemannian smooth manifold is equivalent to the zero locus of some functions which are and which differentials are zero at no point. This alternate definition is simpler, because it does not introduce partial charts, the metric tensor is just the restriction of the euclidean inner product and the Levi-Civita connection is just the orthogonal projection of the usual derivative of vector fields. And as a bonus, the zero locus approach is closer to the definition of affine schemes in algebraic geometry. Pseudo-riemannian manifolds can also be defined this way, under the additional assumption of stable causality. So what is the advantage of the standard definition of riemannian manifold through charts and custom metric tensors? Is it just that the dimension increase of the Nash embedding makes computations intractable? The story of an internal observer's viewpoint is not very convincing, because the only riemannian manifolds with rigid body motions (as would be a true internal observer) are the ones with constant curvature, so a tiny part of riemannian manifolds.","f_1,\dots,f_r : \mathbb{R}^n\to\mathbb{R}  C^\infty n(n+1)(3n+11)/2",['differential-geometry']
76,"Confused about ""k-form""","Confused about ""k-form""",,"Lee's Riemannian Manifolds: An Introduction to Curvature states the following on page 14: We let $\Lambda ^k (V)$ denote the space of covariant alternating $k$ -tensors on $V$ , also called $k$ - covectors or (exterior) $k$ - forms . This confused me because, for me, a $k$ -form is an alternating covariant tensor field of degree $k$ , not just a tensor. Later, Lee defines the following: the bundle of $k$ - forms is $\Lambda^k M := \coprod_{p\in M}\Lambda^k(T_p M).$ a differential $k$ - form is a smooth section of $\Lambda^k M$ . According to this, am I correct in assuming the following? A $k$ -form without ""differential"" is just an alternating multilinear map from a vector space to the space of scalars. A differential $k$ -form is what I have been thinking a $k$ -form is, that is, an alternating covariant tensor field of degree $k$ . Some people omit ""differential"" for some reason when they actually mean differential $k$ -form. If I am correct, is it a common naming method?","Lee's Riemannian Manifolds: An Introduction to Curvature states the following on page 14: We let denote the space of covariant alternating -tensors on , also called - covectors or (exterior) - forms . This confused me because, for me, a -form is an alternating covariant tensor field of degree , not just a tensor. Later, Lee defines the following: the bundle of - forms is a differential - form is a smooth section of . According to this, am I correct in assuming the following? A -form without ""differential"" is just an alternating multilinear map from a vector space to the space of scalars. A differential -form is what I have been thinking a -form is, that is, an alternating covariant tensor field of degree . Some people omit ""differential"" for some reason when they actually mean differential -form. If I am correct, is it a common naming method?",\Lambda ^k (V) k V k k k k k \Lambda^k M := \coprod_{p\in M}\Lambda^k(T_p M). k \Lambda^k M k k k k k,"['differential-geometry', 'differential-forms']"
77,"Redundancy with basis vectors for $T_pM^\mathbb C \cong T_pM^{1,0} \oplus T_pM^{0,1}$",Redundancy with basis vectors for,"T_pM^\mathbb C \cong T_pM^{1,0} \oplus T_pM^{0,1}","I've found out that the primary motivation for complexifying the tangent bundle is to enable its decomposition into the eigenspaces $\pm i$ of $J$ . This decomposition facilitates the splitting of the bundle into holomorphic and antiholomorphic components. For the complexified tangent space $T_pM^\mathbb C$ , we have a complex basis given by $\{\partial/\partial x_1,\dots, \partial/\partial x_n, \partial/\partial y_1,\dots, \partial/\partial y_n\}$ . Given that $T_pM^\mathbb C \cong T_pM^{1,0} \oplus T_pM^{0,1}$ , the isomorphisms can be represented as: \begin{align*}     T_pM &\to T_pM^{1,0}, \ v \mapsto \frac{1}{2}(v-iJv) \\     T_pM &\to T_pM^{0,1}, \ v \mapsto \frac{1}{2}(v+iJv). \end{align*} Next I wanted to show that under these isomorphisms we can map the basis $$\{\partial/\partial x_1,\dots, \partial/\partial x_n, \partial/\partial x_y,\dots, \partial/\partial y_n\}$$ to the basis $$\{\partial/\partial z_1,\dots, \partial/\partial z_n, \partial/\partial \bar{z}_1,\dots, \partial/\partial \bar{z}_n\}$$ but I get some redundancy. For the first map $T_pM \to T_pM^{1,0}, \ v \mapsto \frac{1}{2}(v-iJv)$ we have \begin{align*}     \frac{\partial}{\partial x_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial x_j} - iJ\left(\frac{\partial}{\partial x_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial x_j} - i\frac{\partial}{\partial y_j}\right) = \frac{\partial}{\partial z_j} \\     \frac{\partial}{\partial y_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial y_j} - iJ\left(\frac{\partial}{\partial y_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial y_j} + i\frac{\partial}{\partial x_j}\right) \end{align*} and here $\frac{\partial}{\partial y_j}$ doesn't map to either $\frac{\partial}{\partial z_j}$ or $\frac{\partial}{\partial \bar{z}_j}$ . Similarly for the map $T_pM \to T_pM^{0,1}, \ v \mapsto \frac{1}{2}(v+iJv)$ we have \begin{align*}     \frac{\partial}{\partial x_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial x_j} + iJ\left(\frac{\partial}{\partial x_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial x_j} + i\frac{\partial}{\partial y_j}\right) = \frac{\partial}{\partial \bar{z}_j} \\     \frac{\partial}{\partial y_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial y_j} + iJ\left(\frac{\partial}{\partial y_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial y_j} - i\frac{\partial}{\partial x_j}\right) \end{align*} but again $\frac{\partial}{\partial y_j}$ doesn't map to a corresponding basis element. Could anyone help me out why? Edit : Does the following work out properly with the differences regarding complex and real bases? Since $T_pM^\mathbb C \cong T_pM^{1,0} \oplus T_pM^{0,1}$ we can use the isomorphisms \begin{align*}     T_pM &\to T_pM^{1,0}, \ v \mapsto \frac{1}{2}(v-iJv) \\     T_pM &\to T_pM^{0,1}, \ v \mapsto \frac{1}{2}(v+iJv) \end{align*} to send the real basis $\left\{ \frac{\partial}{\partial x_1}, \dots, \frac{\partial}{\partial x_n}, \frac{\partial}{\partial y_1}, \dots, \frac{\partial}{\partial y_n} \right\}$ of $T_pM$ to \begin{align*}     \frac{\partial}{\partial x_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial x_j} - iJ\left(\frac{\partial}{\partial x_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial x_j} - i\frac{\partial}{\partial y_j}\right) = \frac{\partial}{\partial z_j} \\     \frac{\partial}{\partial y_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial y_j} - iJ\left(\frac{\partial}{\partial y_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial y_j} + i\frac{\partial}{\partial x_j}\right) = i\frac{\partial}{\partial z_j} \end{align*} giving $T_pM^{1,0}$ a real basis $\left\{ \frac{\partial}{\partial z_1}, \dots, \frac{\partial}{\partial z_n}, i\frac{\partial}{\partial z_1}, \dots, i\frac{\partial}{\partial z_n} \right\}$ and a complex basis $\left\{ \frac{\partial}{\partial z_1}, \dots, \frac{\partial}{\partial z_n}\right\}$ . In a similar manner we send the real basis of $T_pM$ to $T_pM^{0,1}$ by \begin{align*}     \frac{\partial}{\partial x_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial x_j} + iJ\left(\frac{\partial}{\partial x_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial x_j} + i\frac{\partial}{\partial y_j}\right) = \frac{\partial}{\partial \bar{z}_j} \\     \frac{\partial}{\partial y_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial y_j} + iJ\left(\frac{\partial}{\partial y_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial y_j} - i\frac{\partial}{\partial x_j}\right) = -i\frac{\partial}{\partial \bar{z}_j} \end{align*} which gives $T_pM^{0,1}$ a real basis $\left\{ \frac{\partial}{\partial z_1}, \dots, \frac{\partial}{\partial z_n}, -i\frac{\partial}{\partial \bar{z}_1}, \dots, -i\frac{\partial}{\partial \bar{z}_n} \right\}$ and a complex basis $\left\{ \frac{\partial}{\partial \bar{z}_1}, \dots, \frac{\partial}{\partial \bar{z}_n}\right\}$ .","I've found out that the primary motivation for complexifying the tangent bundle is to enable its decomposition into the eigenspaces of . This decomposition facilitates the splitting of the bundle into holomorphic and antiholomorphic components. For the complexified tangent space , we have a complex basis given by . Given that , the isomorphisms can be represented as: Next I wanted to show that under these isomorphisms we can map the basis to the basis but I get some redundancy. For the first map we have and here doesn't map to either or . Similarly for the map we have but again doesn't map to a corresponding basis element. Could anyone help me out why? Edit : Does the following work out properly with the differences regarding complex and real bases? Since we can use the isomorphisms to send the real basis of to giving a real basis and a complex basis . In a similar manner we send the real basis of to by which gives a real basis and a complex basis .","\pm i J T_pM^\mathbb C \{\partial/\partial x_1,\dots, \partial/\partial x_n, \partial/\partial y_1,\dots, \partial/\partial y_n\} T_pM^\mathbb C \cong T_pM^{1,0} \oplus T_pM^{0,1} \begin{align*}
    T_pM &\to T_pM^{1,0}, \ v \mapsto \frac{1}{2}(v-iJv) \\
    T_pM &\to T_pM^{0,1}, \ v \mapsto \frac{1}{2}(v+iJv).
\end{align*} \{\partial/\partial x_1,\dots, \partial/\partial x_n, \partial/\partial x_y,\dots, \partial/\partial y_n\} \{\partial/\partial z_1,\dots, \partial/\partial z_n, \partial/\partial \bar{z}_1,\dots, \partial/\partial \bar{z}_n\} T_pM \to T_pM^{1,0}, \ v \mapsto \frac{1}{2}(v-iJv) \begin{align*}
    \frac{\partial}{\partial x_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial x_j} - iJ\left(\frac{\partial}{\partial x_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial x_j} - i\frac{\partial}{\partial y_j}\right) = \frac{\partial}{\partial z_j} \\
    \frac{\partial}{\partial y_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial y_j} - iJ\left(\frac{\partial}{\partial y_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial y_j} + i\frac{\partial}{\partial x_j}\right)
\end{align*} \frac{\partial}{\partial y_j} \frac{\partial}{\partial z_j} \frac{\partial}{\partial \bar{z}_j} T_pM \to T_pM^{0,1}, \ v \mapsto \frac{1}{2}(v+iJv) \begin{align*}
    \frac{\partial}{\partial x_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial x_j} + iJ\left(\frac{\partial}{\partial x_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial x_j} + i\frac{\partial}{\partial y_j}\right) = \frac{\partial}{\partial \bar{z}_j} \\
    \frac{\partial}{\partial y_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial y_j} + iJ\left(\frac{\partial}{\partial y_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial y_j} - i\frac{\partial}{\partial x_j}\right)
\end{align*} \frac{\partial}{\partial y_j} T_pM^\mathbb C \cong T_pM^{1,0} \oplus T_pM^{0,1} \begin{align*}
    T_pM &\to T_pM^{1,0}, \ v \mapsto \frac{1}{2}(v-iJv) \\
    T_pM &\to T_pM^{0,1}, \ v \mapsto \frac{1}{2}(v+iJv)
\end{align*} \left\{ \frac{\partial}{\partial x_1}, \dots, \frac{\partial}{\partial x_n}, \frac{\partial}{\partial y_1}, \dots, \frac{\partial}{\partial y_n} \right\} T_pM \begin{align*}
    \frac{\partial}{\partial x_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial x_j} - iJ\left(\frac{\partial}{\partial x_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial x_j} - i\frac{\partial}{\partial y_j}\right) = \frac{\partial}{\partial z_j} \\
    \frac{\partial}{\partial y_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial y_j} - iJ\left(\frac{\partial}{\partial y_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial y_j} + i\frac{\partial}{\partial x_j}\right) = i\frac{\partial}{\partial z_j}
\end{align*} T_pM^{1,0} \left\{ \frac{\partial}{\partial z_1}, \dots, \frac{\partial}{\partial z_n}, i\frac{\partial}{\partial z_1}, \dots, i\frac{\partial}{\partial z_n} \right\} \left\{ \frac{\partial}{\partial z_1}, \dots, \frac{\partial}{\partial z_n}\right\} T_pM T_pM^{0,1} \begin{align*}
    \frac{\partial}{\partial x_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial x_j} + iJ\left(\frac{\partial}{\partial x_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial x_j} + i\frac{\partial}{\partial y_j}\right) = \frac{\partial}{\partial \bar{z}_j} \\
    \frac{\partial}{\partial y_j} &\mapsto \frac{1}{2}\left(\frac{\partial}{\partial y_j} + iJ\left(\frac{\partial}{\partial y_j}\right)\right) = \frac{1}{2}\left(\frac{\partial}{\partial y_j} - i\frac{\partial}{\partial x_j}\right) = -i\frac{\partial}{\partial \bar{z}_j}
\end{align*} T_pM^{0,1} \left\{ \frac{\partial}{\partial z_1}, \dots, \frac{\partial}{\partial z_n}, -i\frac{\partial}{\partial \bar{z}_1}, \dots, -i\frac{\partial}{\partial \bar{z}_n} \right\} \left\{ \frac{\partial}{\partial \bar{z}_1}, \dots, \frac{\partial}{\partial \bar{z}_n}\right\}","['differential-geometry', 'complex-manifolds']"
78,Comparison of terms in local formulation of Christoffel-symbols in relation to isometries.,Comparison of terms in local formulation of Christoffel-symbols in relation to isometries.,,"Let $(M,g),(N,h)$ be semi-riemannian manifolds, and $\varphi \in C^{\infty}(M,N)$ an isometry (hence a diffeomorphism). Let $(U,\psi = (x^1,\ldots,x^n))$ be a coordinate chart of a point $p \in U \subset M$ , and $(\varphi(U),\psi \circ \varphi^{-1} = (y^1,\ldots,y^n))$ be a chart of $\varphi(p) \in \varphi(U) \subset N$ . By a (I believe) standard-theorem, we get $$T_p\varphi\Big(\frac{\partial}{\partial x^i}\Big|_p\Big)$$ $$ = \sum_{j = 1}^{n} \frac{\partial ((\psi \circ \varphi^{-1})^j \circ \varphi \circ \psi^{-1})}{\partial x^i}(\psi(p)) \cdot \frac{\partial}{\partial y^j}\Big|_{\varphi(p)}$$ $$ = \sum_{j = 1}^{n} \frac{\partial x^j}{\partial x^i} \frac{\partial}{\partial y^j}\Big|_{\varphi(p)} = \frac{\partial}{\partial y^i}\Big|_{\varphi(p)}.$$ Now, by the definition of isometries, and the calculation above, we get $$g_{ij}(p) := g\Big(\frac{\partial}{\partial x^i}\Big|_p,\frac{\partial}{\partial x^j}\Big|_p\Big) = h\Big(T_p\varphi\Big(\frac{\partial}{\partial x^i}\Big|_p\Big),T_p\varphi\Big(\frac{\partial}{\partial x^j}\Big|_p\Big)\Big) = h\Big(\frac{\partial}{\partial y^i}\Big|_{\varphi(p)},\frac{\partial}{\partial y^j}\Big|_{\varphi(p}\Big) = h_{ij}(\varphi(p)).$$ Now, to my question: Why does this imply $$\frac{\partial}{\partial y^k}\Big|_{\varphi(p)} h_{ij} = \frac{\partial}{\partial x^k}\Big|_p g_{ij}?$$ I feel like I am missing something obvious. The reason we want to show this is to see that $${}^g\Gamma^k_{ij}(p) = {}^h\Gamma^k_{ij}(\varphi(p))$$ for the Christoffel-symbols on $U,\varphi(U)$ respectively.","Let be semi-riemannian manifolds, and an isometry (hence a diffeomorphism). Let be a coordinate chart of a point , and be a chart of . By a (I believe) standard-theorem, we get Now, by the definition of isometries, and the calculation above, we get Now, to my question: Why does this imply I feel like I am missing something obvious. The reason we want to show this is to see that for the Christoffel-symbols on respectively.","(M,g),(N,h) \varphi \in C^{\infty}(M,N) (U,\psi = (x^1,\ldots,x^n)) p \in U \subset M (\varphi(U),\psi \circ \varphi^{-1} = (y^1,\ldots,y^n)) \varphi(p) \in \varphi(U) \subset N T_p\varphi\Big(\frac{\partial}{\partial x^i}\Big|_p\Big)  = \sum_{j = 1}^{n} \frac{\partial ((\psi \circ \varphi^{-1})^j \circ \varphi \circ \psi^{-1})}{\partial x^i}(\psi(p)) \cdot \frac{\partial}{\partial y^j}\Big|_{\varphi(p)}  = \sum_{j = 1}^{n} \frac{\partial x^j}{\partial x^i} \frac{\partial}{\partial y^j}\Big|_{\varphi(p)} = \frac{\partial}{\partial y^i}\Big|_{\varphi(p)}. g_{ij}(p) := g\Big(\frac{\partial}{\partial x^i}\Big|_p,\frac{\partial}{\partial x^j}\Big|_p\Big) = h\Big(T_p\varphi\Big(\frac{\partial}{\partial x^i}\Big|_p\Big),T_p\varphi\Big(\frac{\partial}{\partial x^j}\Big|_p\Big)\Big) = h\Big(\frac{\partial}{\partial y^i}\Big|_{\varphi(p)},\frac{\partial}{\partial y^j}\Big|_{\varphi(p}\Big) = h_{ij}(\varphi(p)). \frac{\partial}{\partial y^k}\Big|_{\varphi(p)} h_{ij} = \frac{\partial}{\partial x^k}\Big|_p g_{ij}? {}^g\Gamma^k_{ij}(p) = {}^h\Gamma^k_{ij}(\varphi(p)) U,\varphi(U)","['differential-geometry', 'isometry', 'semi-riemannian-geometry']"
79,Connection laplacian and abstract index notation,Connection laplacian and abstract index notation,,"Let $(M,g)$ be a (pseudo-)Riemannian manifold. I am having some struggles to relate two different approaches, one based on the abstract index notation, and the other one based on global, coordinate-free, notation. Consider a general covariant $k$ -tensor field $T\in\Gamma^{\infty}(T^{\ast}M^{\otimes k})$ . In coordinates, I can write down the components of $T$ as $T_{\mu_{1}\dots\mu_{k}}$ . Then, the (connection) Laplacian of $T$ is the $k$ -tensor field $\square T\in\Gamma^{\infty}(T^{\ast}M^{\otimes k})$ with components $$(\square T)_{\mu_{1}\dots\mu_{k}}:=g^{\mu\nu}\nabla_{\mu}\nabla_{\nu}T_{\mu_{1}\dots\mu_{k}}$$ I won't write down the explicit expression of the right-hand side, but I think it is clear what it means. For example, if $k=1$ , then $$(\square T)_{\alpha}=g^{\mu\nu}(\partial_{\mu}\nabla_{\nu}T_{\alpha}-\Gamma^{\lambda}_{\mu\nu}\nabla_{\lambda}T_{\alpha}-\Gamma^{\lambda}_{\mu\alpha}\nabla_{\nu}T_{\lambda})$$ and substituting the usual expression $\nabla_{\mu}T_{\alpha}=\partial_{\mu}T_{\alpha}-\Gamma^{\lambda}_{\mu\alpha}T_{\lambda}$ , which gives a lengthy formula for the components of the Laplacian. On the other hand, on wikipedia for example, the connection Laplacian is defined globally as $$\square T:=\mathrm{tr}(\nabla^{2}T)$$ with the double covariant derivative $\nabla_{X,Y}^{2}T:=\nabla_{X}\nabla_{Y}T-\nabla_{\nabla_{X}Y}T$ . I am a bit confused about the term $\nabla_{\nabla_{X}Y}T$ . The first term $\nabla_{X}\nabla_{Y}T$ , using the trace, should give my coordinate expression above, i.e. $g^{\mu\nu}\nabla_{\mu}\nabla_{\nu}T_{\alpha}$ , but what about the second term? Or does it vanish? Maybe my confusion is related to how to relate the expression $\nabla_{\alpha}\nabla_{\beta}T_{\mu_{1}\dots\mu_{k}}$ to the double covariant derivative $\nabla^{2}T$ ...","Let be a (pseudo-)Riemannian manifold. I am having some struggles to relate two different approaches, one based on the abstract index notation, and the other one based on global, coordinate-free, notation. Consider a general covariant -tensor field . In coordinates, I can write down the components of as . Then, the (connection) Laplacian of is the -tensor field with components I won't write down the explicit expression of the right-hand side, but I think it is clear what it means. For example, if , then and substituting the usual expression , which gives a lengthy formula for the components of the Laplacian. On the other hand, on wikipedia for example, the connection Laplacian is defined globally as with the double covariant derivative . I am a bit confused about the term . The first term , using the trace, should give my coordinate expression above, i.e. , but what about the second term? Or does it vanish? Maybe my confusion is related to how to relate the expression to the double covariant derivative ...","(M,g) k T\in\Gamma^{\infty}(T^{\ast}M^{\otimes k}) T T_{\mu_{1}\dots\mu_{k}} T k \square T\in\Gamma^{\infty}(T^{\ast}M^{\otimes k}) (\square T)_{\mu_{1}\dots\mu_{k}}:=g^{\mu\nu}\nabla_{\mu}\nabla_{\nu}T_{\mu_{1}\dots\mu_{k}} k=1 (\square T)_{\alpha}=g^{\mu\nu}(\partial_{\mu}\nabla_{\nu}T_{\alpha}-\Gamma^{\lambda}_{\mu\nu}\nabla_{\lambda}T_{\alpha}-\Gamma^{\lambda}_{\mu\alpha}\nabla_{\nu}T_{\lambda}) \nabla_{\mu}T_{\alpha}=\partial_{\mu}T_{\alpha}-\Gamma^{\lambda}_{\mu\alpha}T_{\lambda} \square T:=\mathrm{tr}(\nabla^{2}T) \nabla_{X,Y}^{2}T:=\nabla_{X}\nabla_{Y}T-\nabla_{\nabla_{X}Y}T \nabla_{\nabla_{X}Y}T \nabla_{X}\nabla_{Y}T g^{\mu\nu}\nabla_{\mu}\nabla_{\nu}T_{\alpha} \nabla_{\alpha}\nabla_{\beta}T_{\mu_{1}\dots\mu_{k}} \nabla^{2}T","['differential-geometry', 'manifolds', 'riemannian-geometry', 'tensors', 'laplacian']"
80,Second De Rham Cohomology of $\mathbb{P}^2_\mathbb{R}$,Second De Rham Cohomology of,\mathbb{P}^2_\mathbb{R},"I'm trying to show that $H^2(\mathbb{P}^2_\mathbb{R})=0$ by pulling back closed 2-forms $\omega$ on $\mathbb{P}^2_\mathbb{R}$ to $S^2$ using the fact that $\pi^*\omega$ is exact (where $\pi:S^2\longrightarrow\mathbb{P}^2_\mathbb{R}$ is the canonical quotient map). If we write $\pi^*\omega=d\eta$ for $\eta\in\Omega^1(S^2)$ , I would like to ""average"" $\eta$ to produce a 1-form $\kappa\in\Omega^1(S^2)$ that descends to a 1-form $\tilde{\kappa}$ on $\mathbb{P}^2_\mathbb{R}$ , akin to my approach in 1 . However, I'm not entirely sure what conditions I need to check to prove that this is the case. In showing the analogous statement for 1-forms, I was able to just define a smooth function $g:S^2\longrightarrow S^2$ by $$g(p)=\frac{1}{2}\left(f(p)+f(-p)\right)=\frac{1}{2}\left(f(p)+(\alpha^*f)(p)\right)$$ if $\pi^*\omega=df$ for $f\in \Omega^0(S^2)$ , and checking that $g(p)=g(-p)$ . Returning to the 2-form case, I first tried to find a 1-form $\kappa$ on $S^2$ such that $\kappa_p(v)=\kappa_{-p}(v)$ , but I'm not even sure this statement makes sense: here, we'd want to regard $v$ as the ""same"" tangent vector in both $T_pS^2$ and $T_{-p}S^2$ . Anyway, I wasn't able to come up with a $\kappa$ that works, assuming this is the ""correct"" thing to check. Are there general conditions would I have to check to ensure this descent works (and similarly, a natural definition for $\kappa$ )? I'm hoping to establish that $H^2(\mathbb{P}^2_\mathbb{R})=0$ using this approach. Thank you for any help. References: 1 : De Rham Cohomology of $\mathbb{P}_\mathbb{R}^2$","I'm trying to show that by pulling back closed 2-forms on to using the fact that is exact (where is the canonical quotient map). If we write for , I would like to ""average"" to produce a 1-form that descends to a 1-form on , akin to my approach in 1 . However, I'm not entirely sure what conditions I need to check to prove that this is the case. In showing the analogous statement for 1-forms, I was able to just define a smooth function by if for , and checking that . Returning to the 2-form case, I first tried to find a 1-form on such that , but I'm not even sure this statement makes sense: here, we'd want to regard as the ""same"" tangent vector in both and . Anyway, I wasn't able to come up with a that works, assuming this is the ""correct"" thing to check. Are there general conditions would I have to check to ensure this descent works (and similarly, a natural definition for )? I'm hoping to establish that using this approach. Thank you for any help. References: 1 : De Rham Cohomology of",H^2(\mathbb{P}^2_\mathbb{R})=0 \omega \mathbb{P}^2_\mathbb{R} S^2 \pi^*\omega \pi:S^2\longrightarrow\mathbb{P}^2_\mathbb{R} \pi^*\omega=d\eta \eta\in\Omega^1(S^2) \eta \kappa\in\Omega^1(S^2) \tilde{\kappa} \mathbb{P}^2_\mathbb{R} g:S^2\longrightarrow S^2 g(p)=\frac{1}{2}\left(f(p)+f(-p)\right)=\frac{1}{2}\left(f(p)+(\alpha^*f)(p)\right) \pi^*\omega=df f\in \Omega^0(S^2) g(p)=g(-p) \kappa S^2 \kappa_p(v)=\kappa_{-p}(v) v T_pS^2 T_{-p}S^2 \kappa \kappa H^2(\mathbb{P}^2_\mathbb{R})=0 \mathbb{P}_\mathbb{R}^2,"['differential-geometry', 'smooth-manifolds', 'de-rham-cohomology']"
81,Kernel and image of vector bundle morphism over smooth submersion. [closed],Kernel and image of vector bundle morphism over smooth submersion. [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 11 months ago . The community reviewed whether to reopen this question 11 months ago and left it closed: Original close reason(s) were not resolved Improve this question Suppose we have vector bundles $\pi_E:E\to M$ and $\pi_{E'}:E'\to M'$ , smooth submersion $G:M\to M'$ and vector bundle morphism $F:E\to E'$ over $G$ . Are then the sets $ker F$ and $im F$ smooth vector subbundles of $E$ and $E'$ . I know that the answer is yes if $G=id_M$ , however I am not sure what the answer is in this case. Can someone give me some literature with the proof please. EDIT: I forgot to say that $F$ has a constant rang.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 11 months ago . The community reviewed whether to reopen this question 11 months ago and left it closed: Original close reason(s) were not resolved Improve this question Suppose we have vector bundles and , smooth submersion and vector bundle morphism over . Are then the sets and smooth vector subbundles of and . I know that the answer is yes if , however I am not sure what the answer is in this case. Can someone give me some literature with the proof please. EDIT: I forgot to say that has a constant rang.",\pi_E:E\to M \pi_{E'}:E'\to M' G:M\to M' F:E\to E' G ker F im F E E' G=id_M F,"['differential-geometry', 'smooth-manifolds', 'vector-bundles']"
82,Modifying critical point of function on manifold ODE theory,Modifying critical point of function on manifold ODE theory,,"Assume $M$ is compact Riemannian manifold and $g(t)$ is a time dependent metric. Assume $\Psi:M\times [0,C)\rightarrow \mathbb{R}$ is smooth and $C<\infty$ . Suppose we have $(\partial_t\Psi -\Delta_{g(t)} \Psi)\geq 0$ . If $\Psi\geq 0$ on $M\times 0$ , then, $\Psi \geq 0$ everywhere. Proof is as follows: It suffices to assume that case $\Psi>0$ . Now, assume for contradiction $\Psi<0$ somewhere. Since $M$ is compact, we can find $(x'',t'')$ such that $\Psi(x'',t'')=0$ and $\Psi(x,t)\geq 0$ for all $x\in M$ and all $t\in [0,t'']$ . Then on this point, $\partial_t \Psi$ $\leq 0$ and $\Delta \Psi \geq 0$ . I am confsed as to why compactness implies the existence of $(x'',t'')$ as above and why that implies $\partial_t \Psi\leq 0$ . Note. For fixed $x$ , there exists $t_x$ such that $\Psi(x,t_x)=0$ . For fixed $t$ there exists unique $x_t$ such that $\Psi(x_t,t)\geq  \Psi(x,t)$ for all $x\in M$ . There are proofs but using maximal time, I don't understand why such time exists by compactness.","Assume is compact Riemannian manifold and is a time dependent metric. Assume is smooth and . Suppose we have . If on , then, everywhere. Proof is as follows: It suffices to assume that case . Now, assume for contradiction somewhere. Since is compact, we can find such that and for all and all . Then on this point, and . I am confsed as to why compactness implies the existence of as above and why that implies . Note. For fixed , there exists such that . For fixed there exists unique such that for all . There are proofs but using maximal time, I don't understand why such time exists by compactness.","M g(t) \Psi:M\times [0,C)\rightarrow \mathbb{R} C<\infty (\partial_t\Psi -\Delta_{g(t)} \Psi)\geq 0 \Psi\geq 0 M\times 0 \Psi \geq 0 \Psi>0 \Psi<0 M (x'',t'') \Psi(x'',t'')=0 \Psi(x,t)\geq 0 x\in M t\in [0,t''] \partial_t \Psi \leq 0 \Delta \Psi \geq 0 (x'',t'') \partial_t \Psi\leq 0 x t_x \Psi(x,t_x)=0 t x_t \Psi(x_t,t)\geq  \Psi(x,t) x\in M","['functional-analysis', 'differential-geometry']"
83,Finding the closest point to a Manifold,Finding the closest point to a Manifold,,"Hello differential geometry community! Suppose that I have a smooth Riemannian manifold $\mathcal{N}$ embedded into a Euclidean space $\mathcal{P}$ . Assume that I have two position vectors $p_1,p_2 \in \mathcal{N}$ ; s.t. $p_1 \neq p_2$ . Now, imagine the straight line segment passing through these two points in $\mathcal{P}$ called, say, $\ell$ . Let $p_k \in \ell$ . Is it possible to find the shortest line segment passing through both $p_k$ and another point in $\mathcal{N}$ ? It could also be an iterative algorithm like in Newton’s method to find the root; not necessarily a closed form mathematical expression. By the way there is not limit on the distance between $p_1$ and $p_2$ w.r.t. Euclidean norm in $\mathcal{P}$ .","Hello differential geometry community! Suppose that I have a smooth Riemannian manifold embedded into a Euclidean space . Assume that I have two position vectors ; s.t. . Now, imagine the straight line segment passing through these two points in called, say, . Let . Is it possible to find the shortest line segment passing through both and another point in ? It could also be an iterative algorithm like in Newton’s method to find the root; not necessarily a closed form mathematical expression. By the way there is not limit on the distance between and w.r.t. Euclidean norm in .","\mathcal{N} \mathcal{P} p_1,p_2 \in \mathcal{N} p_1 \neq p_2 \mathcal{P} \ell p_k \in \ell p_k \mathcal{N} p_1 p_2 \mathcal{P}","['differential-geometry', 'smooth-manifolds']"
84,Question about the scalar second fundamental form being proportional to the hessian of the defining function,Question about the scalar second fundamental form being proportional to the hessian of the defining function,,"I'm working on problem 8.3 of Lee's Riemannian Manifold textbook: let $\Omega \subset R^{n+1}$ be an open set, $F:\Omega\rightarrow R$ a smooth submersion, and $M=F^{-1}(0)$ . Show the scalar second fundamental form of M with respect to the unit normal vector field $N=grad F/\|grad F\|$ is given by $h(V,V)=-\frac{\partial_i\partial_jFV^{i}V^j}{\|gradF\|}$ , where $V=V^i\partial_i$ in the Euclidean coordinates on $R^{n+1}$ . (the original book had an error and the corrected form is given here). I made two attempts. I wonder why they differ from each other AND the true answer: #1 The scalar second fundamental form is the inner product between the second fundamental form and the unit normal. The definition of the second fundamental form: $II(V,V)=\tilde \nabla_VV-\nabla _VV$ , where $\tilde \nabla$ is the connection in the ambient euclidean space and $\nabla$ on the manifold). If I take the inner product with the unit normal on both sides, since $\langle\nabla_VV,N\rangle=0$ , I get the scalar second fundamental form $h(V,V)=\langle II(V,V),N\rangle=\langle\tilde\nabla_VV,N\rangle=\langle V(V^i)\partial_i,(\partial_iF)\partial_i/|gradF| \rangle =V(V^i)(\partial_iF)$ . This is clearly not right so what's wrong?? Is expanding $gradF$ into $\partial_iF\partial_i$ right? Is doing the inner product this way (only taking the coefficients of $\partial_i$ on both terms and multiply them) correct? #2 The other way is to use the Weingarten equation: $h(V,V)=\langle N,II(V,V)\rangle=-\langle\tilde\nabla_VN,N\rangle=-\langle V(N^j)\partial_j,V^j\partial_j\rangle=V^i\partial_i(\partial_jF/|gradF|)V^j$ . Now from here, if I treat $|gradF|$ as constant and take it outside of the $\partial_i$ , then I would recover the solution. But I can't see a reason why that is the case. If I continue the derivation, I get: $(\partial_i\partial_jF / |grad F| + \partial_jF\partial_iF/|gradF|^3)V^iV^j$ . So what's wrong in my derivation?? I would really appreciate any help!! Thanks!!","I'm working on problem 8.3 of Lee's Riemannian Manifold textbook: let be an open set, a smooth submersion, and . Show the scalar second fundamental form of M with respect to the unit normal vector field is given by , where in the Euclidean coordinates on . (the original book had an error and the corrected form is given here). I made two attempts. I wonder why they differ from each other AND the true answer: #1 The scalar second fundamental form is the inner product between the second fundamental form and the unit normal. The definition of the second fundamental form: , where is the connection in the ambient euclidean space and on the manifold). If I take the inner product with the unit normal on both sides, since , I get the scalar second fundamental form . This is clearly not right so what's wrong?? Is expanding into right? Is doing the inner product this way (only taking the coefficients of on both terms and multiply them) correct? #2 The other way is to use the Weingarten equation: . Now from here, if I treat as constant and take it outside of the , then I would recover the solution. But I can't see a reason why that is the case. If I continue the derivation, I get: . So what's wrong in my derivation?? I would really appreciate any help!! Thanks!!","\Omega \subset R^{n+1} F:\Omega\rightarrow R M=F^{-1}(0) N=grad F/\|grad F\| h(V,V)=-\frac{\partial_i\partial_jFV^{i}V^j}{\|gradF\|} V=V^i\partial_i R^{n+1} II(V,V)=\tilde \nabla_VV-\nabla _VV \tilde \nabla \nabla \langle\nabla_VV,N\rangle=0 h(V,V)=\langle II(V,V),N\rangle=\langle\tilde\nabla_VV,N\rangle=\langle V(V^i)\partial_i,(\partial_iF)\partial_i/|gradF| \rangle =V(V^i)(\partial_iF) gradF \partial_iF\partial_i \partial_i h(V,V)=\langle N,II(V,V)\rangle=-\langle\tilde\nabla_VN,N\rangle=-\langle V(N^j)\partial_j,V^j\partial_j\rangle=V^i\partial_i(\partial_jF/|gradF|)V^j |gradF| \partial_i (\partial_i\partial_jF / |grad F| + \partial_jF\partial_iF/|gradF|^3)V^iV^j","['differential-geometry', 'riemannian-geometry']"
85,Generator for $H^1(S^1)$ (Bott & Tu),Generator for  (Bott & Tu),H^1(S^1),"I'm reading Bott and Tu's book on differential forms in algebraic topology and they have the following observation made when computing the de Rham cohomology of $S^1$ . They first conclude that $$H^1(S^1)= \operatorname{coker}(\delta)=\mathbb{R}$$ where $\delta$ is the difference map sending $(\omega,\tau)$ to $(\tau-\omega,\tau-\omega)$ from $H^0(U) \oplus H^0(V)$ to $H^0(U \cap V)$ . It's worth noting that the cover $U \cup V$ is chosen so that the intersection will result in having a small  interval containing the north pole and a small interval containing the south pole. After this they find an explicit generator for $H^1(S^1)$ which is the reason for this post. They state that We now find an explicit representative for the generator of $H^1(S^1)$ . If $\alpha \in \Omega^0(U \cap V)$ is a closed $0$ -form which is not the image under $\delta$ of a closed form in $\Omega^0(U) \oplus \Omega^0(V)$ , then $d^*\alpha$ will represent a generator of $H^1(S^1)$ . As $\alpha$ we may take the function which is $1$ on the upper piece of $U \cap V$ and $0$ on the lower piece Now $\alpha$ is the image of $( - \rho_V \alpha, \rho_U \alpha)$ . Since $-d(\rho_V \alpha)$ and $d\rho_U \alpha$ agree on $U \cap V$ , they represent a global form on $S^1$ ; this form is $d^*\alpha$ . It is a bump $1$ -form with support in $U \cap V$ . Then they have the following illustrations Now I would appreciate if someone could help me understand what these illustrations represent as I do not see how to tie them together with the reasoning they gave.","I'm reading Bott and Tu's book on differential forms in algebraic topology and they have the following observation made when computing the de Rham cohomology of . They first conclude that where is the difference map sending to from to . It's worth noting that the cover is chosen so that the intersection will result in having a small  interval containing the north pole and a small interval containing the south pole. After this they find an explicit generator for which is the reason for this post. They state that We now find an explicit representative for the generator of . If is a closed -form which is not the image under of a closed form in , then will represent a generator of . As we may take the function which is on the upper piece of and on the lower piece Now is the image of . Since and agree on , they represent a global form on ; this form is . It is a bump -form with support in . Then they have the following illustrations Now I would appreciate if someone could help me understand what these illustrations represent as I do not see how to tie them together with the reasoning they gave.","S^1 H^1(S^1)= \operatorname{coker}(\delta)=\mathbb{R} \delta (\omega,\tau) (\tau-\omega,\tau-\omega) H^0(U) \oplus H^0(V) H^0(U \cap V) U \cup V H^1(S^1) H^1(S^1) \alpha \in \Omega^0(U \cap V) 0 \delta \Omega^0(U) \oplus \Omega^0(V) d^*\alpha H^1(S^1) \alpha 1 U \cap V 0 \alpha ( - \rho_V \alpha, \rho_U \alpha) -d(\rho_V \alpha) d\rho_U \alpha U \cap V S^1 d^*\alpha 1 U \cap V","['differential-geometry', 'differential-topology', 'homology-cohomology']"
86,Tangent bundle of a fibered product,Tangent bundle of a fibered product,,"There is an argument that I would like to fully understand, but I can't see it, yet. Here is the situation: Given smooth manifolds $X$ , $Y$ and $Z$ and transverse maps $f:X\rightarrow Z$ , $g\rightarrow Z$ , then the fibered product $M:=X\times_{f=g} Y$ is well defined. In fact, it is given by points $(x,y)\in X\times Y$ such that $f(x) = g(y)$ . In other words, it is the preiamge of the diagonal $\Delta_Z\subset Z\times Z$ of the map $F=(f,g): X\times Y\rightarrow Z\times Z$ . I am looking for an expression for the tangent bundle $TM$ using the language of $K$ -theory (i.e. a virtual bundle). I have read the following argument: The normal bundle of $\Delta_Z$ in $Z\times Z$ is isomorphic to (the pullback of) $TZ$ , so it follows that the tangent bundle of the fibered square is $TM = TX+TY - f^*TZ$ . It must have something to do with the transversallity of $f$ and $g$ but I can't fill in the details. Any help is appreciated:)","There is an argument that I would like to fully understand, but I can't see it, yet. Here is the situation: Given smooth manifolds , and and transverse maps , , then the fibered product is well defined. In fact, it is given by points such that . In other words, it is the preiamge of the diagonal of the map . I am looking for an expression for the tangent bundle using the language of -theory (i.e. a virtual bundle). I have read the following argument: The normal bundle of in is isomorphic to (the pullback of) , so it follows that the tangent bundle of the fibered square is . It must have something to do with the transversallity of and but I can't fill in the details. Any help is appreciated:)","X Y Z f:X\rightarrow Z g\rightarrow Z M:=X\times_{f=g} Y (x,y)\in X\times Y f(x) = g(y) \Delta_Z\subset Z\times Z F=(f,g): X\times Y\rightarrow Z\times Z TM K \Delta_Z Z\times Z TZ TM = TX+TY - f^*TZ f g","['differential-geometry', 'algebraic-topology', 'fiber-bundles', 'tangent-bundle']"
87,Existence of a principal bundle charts compatible with $f$-equivariant reductions,Existence of a principal bundle charts compatible with -equivariant reductions,f,"Let $\pi:P\rightarrow M$ and $\pi':P'\rightarrow M$ be principal $G$ and $H$ bundles respectively, and $f:G\rightarrow H$ be Lie group homomorphism. Let $F$ be a principal bundle homomorphism, that is a smooth map $F:P\rightarrow P'$ such that: $$\pi'\circ F=\pi$$ and : $$F(p\cdot g)=F(p)\cdot f(g)$$ for all $p\in P$ , and $g\in G$ . Suppose that $F$ is surjective, and $f$ is a surjective Lie group homomorphism. Furthermore, assume that $G$ and $H$ are connected for simplicity. Let $(U,\phi)$ , be a principal bundle chart for $P'$ , i.e. the trivialization $$\begin{align} \phi:\pi'^{-1}(U)&\longrightarrow U\times H\\ p&\longmapsto(\pi'(p),h(p)) \end{align}$$ where $h(p)$ is some smooth map $P'_U\rightarrow G$ . Does it follow that there exists a principal bundle chart $(U,\psi)$ for $P$ such that: $$\phi\circ F=(\text{Id}_U\times f)\circ \psi$$ If so, how would one construct $\psi$ ? If not, are there cases where this can happen? i.e. perhaps if $F$ and $f$ are double coverings? And if no such case exists, how can I see that this breaks down? Note that if $f$ is a surjective Lie group homomorphism, then $G/\ker f\cong H$ , because the kernel is a closed Lie subgroup of $G$ , and the action of $\ker f$ on $G$ is free and proper. For context, I asked this question earlier today, and I believe if I can show that such a chart exists then I could easily prove what I seek out to prove. I am starting to suspect that no such chart exists however, I just can't see why. It seems that maybe such a chart would depend on global sections of $f$ , which is a submersion.","Let and be principal and bundles respectively, and be Lie group homomorphism. Let be a principal bundle homomorphism, that is a smooth map such that: and : for all , and . Suppose that is surjective, and is a surjective Lie group homomorphism. Furthermore, assume that and are connected for simplicity. Let , be a principal bundle chart for , i.e. the trivialization where is some smooth map . Does it follow that there exists a principal bundle chart for such that: If so, how would one construct ? If not, are there cases where this can happen? i.e. perhaps if and are double coverings? And if no such case exists, how can I see that this breaks down? Note that if is a surjective Lie group homomorphism, then , because the kernel is a closed Lie subgroup of , and the action of on is free and proper. For context, I asked this question earlier today, and I believe if I can show that such a chart exists then I could easily prove what I seek out to prove. I am starting to suspect that no such chart exists however, I just can't see why. It seems that maybe such a chart would depend on global sections of , which is a submersion.","\pi:P\rightarrow M \pi':P'\rightarrow M G H f:G\rightarrow H F F:P\rightarrow P' \pi'\circ F=\pi F(p\cdot g)=F(p)\cdot f(g) p\in P g\in G F f G H (U,\phi) P' \begin{align}
\phi:\pi'^{-1}(U)&\longrightarrow U\times H\\
p&\longmapsto(\pi'(p),h(p))
\end{align} h(p) P'_U\rightarrow G (U,\psi) P \phi\circ F=(\text{Id}_U\times f)\circ \psi \psi F f f G/\ker f\cong H G \ker f G f","['differential-geometry', 'lie-groups', 'differential-topology', 'principal-bundles', 'equivariant-maps']"
88,Riccati equation from strange Frenet–Serret system,Riccati equation from strange Frenet–Serret system,,"If $\kappa(\mathrm{s})$ and $\tau(\mathrm{s})$ are continuous functions, then we can apply to the system of three simultaneous differential equations of first order in $\alpha, \beta, \gamma$ . $$ \left.\begin{array}{l} \frac{\mathrm{d} \alpha}{\mathrm{ds}}=\kappa \beta \\ \frac{\mathrm{d} \beta}{\mathrm{ds}}=-\kappa \alpha+t \gamma \\ \frac{\mathrm{d} \gamma}{\mathrm{ds}}=-\tau \beta \end{array}\right\} \cdots \cdots(1) $$ The solution of $(1)$ can be reduced to the first order differential equation and equation is so called Riceati equation. From equation (1), we get $$ \begin{gathered} \alpha \frac{\mathrm{d} \alpha}{\mathrm{ds}}+\beta \frac{\mathrm{d} \beta}{\mathrm{ds}}+\gamma \frac{\mathrm{d} \gamma}{\mathrm{ds}}=0 \\ \text { or, } \frac{1}{2} \frac{d}{d s}\left(\alpha^2+\beta^2+\gamma^2\right)=0 \\ \text { or, } \alpha^2+\beta^2+\gamma^2=c \end{gathered} $$ If we find three continuous solutions $\alpha(s), \beta(s)$ and $\gamma(s)$ so that $$ \underbrace{\alpha(s)=1, \quad \beta(s)=0 \text { and } \gamma(s)=0}_{\text{**I didn't understand the physical meaning of letting $\alpha(s)=1$?}} $$ Question 1: I didn't understand the physical meaning of letting $\alpha(s)=1$ and others to zero? it follows that $\mathrm{c}=1$ . Hence $\alpha^2+\beta^2+\gamma^2=1 \cdots \cdots(2)$ Equation (2) can be decomposed as follows : $$ (\alpha+i \beta)(\alpha-i \beta)=(1+\gamma)(1-\gamma) $$ Question 2: Why should I need to assume $c=1$ ? Is it for calculation purposes? Let us now introduce the conjugate imaginary functions w and $-z^{-1}$ , where $$ \left.\begin{array}{c} w=\frac{\alpha+i \beta}{1-\gamma}=\frac{1+\gamma}{\alpha-i \beta} \\ \text { and }-z^{-1}=-\frac{1}{z}=\frac{\alpha-i \beta}{1-\gamma}=\frac{1+\gamma}{\alpha+i \beta} \end{array}\right\} \cdots \cdots (3) $$ Now, we have to express $\alpha, \beta$ , $\gamma$ in terms of $w$ and $z$ From (3). we have $$ \alpha=\frac{1-w z}{w-z}, \quad \beta=i \frac{1+w z}{w-z}, \quad \gamma=\frac{w+z}{w-z} \cdots \cdots(4) $$ Finally, we get, $$ \begin{align} \frac{dw}{ds}&==-\frac{i \tau}{2}-i \kappa w+\frac{i \tau}{2} w^2\\ \frac{dz}{ds}&=-\frac{\mathrm{i} \tau}{2}-\mathrm{i} z \mathrm{i}+\frac{i \tau}{2} z^2 \end{align} $$ This type of equation has the form $$ \frac{\mathrm{d} f}{\mathrm{~d}}=\mathrm{A}(\mathrm{s})+\mathrm{B}(\mathrm{s}) f+\mathrm{C}(\mathrm{s}) f^2 $$ where $A(s)=-\frac{i \tau}{2}, B(s)=-i k$ and $C(s)=\frac{i \tau}{2}$ . This equation is the so-called Riccati equation. It will be a great help if something helps me to figure out Question 1,2 . TIA","If and are continuous functions, then we can apply to the system of three simultaneous differential equations of first order in . The solution of can be reduced to the first order differential equation and equation is so called Riceati equation. From equation (1), we get If we find three continuous solutions and so that Question 1: I didn't understand the physical meaning of letting and others to zero? it follows that . Hence Equation (2) can be decomposed as follows : Question 2: Why should I need to assume ? Is it for calculation purposes? Let us now introduce the conjugate imaginary functions w and , where Now, we have to express , in terms of and From (3). we have Finally, we get, This type of equation has the form where and . This equation is the so-called Riccati equation. It will be a great help if something helps me to figure out Question 1,2 . TIA","\kappa(\mathrm{s}) \tau(\mathrm{s}) \alpha, \beta, \gamma 
\left.\begin{array}{l}
\frac{\mathrm{d} \alpha}{\mathrm{ds}}=\kappa \beta \\
\frac{\mathrm{d} \beta}{\mathrm{ds}}=-\kappa \alpha+t \gamma \\
\frac{\mathrm{d} \gamma}{\mathrm{ds}}=-\tau \beta
\end{array}\right\} \cdots \cdots(1)
 (1) 
\begin{gathered}
\alpha \frac{\mathrm{d} \alpha}{\mathrm{ds}}+\beta \frac{\mathrm{d} \beta}{\mathrm{ds}}+\gamma \frac{\mathrm{d} \gamma}{\mathrm{ds}}=0 \\
\text { or, } \frac{1}{2} \frac{d}{d s}\left(\alpha^2+\beta^2+\gamma^2\right)=0 \\
\text { or, } \alpha^2+\beta^2+\gamma^2=c
\end{gathered}
 \alpha(s), \beta(s) \gamma(s) 
\underbrace{\alpha(s)=1, \quad \beta(s)=0 \text { and } \gamma(s)=0}_{\text{**I didn't understand the physical meaning of letting \alpha(s)=1?}}
 \alpha(s)=1 \mathrm{c}=1 \alpha^2+\beta^2+\gamma^2=1 \cdots \cdots(2) 
(\alpha+i \beta)(\alpha-i \beta)=(1+\gamma)(1-\gamma)
 c=1 -z^{-1} 
\left.\begin{array}{c}
w=\frac{\alpha+i \beta}{1-\gamma}=\frac{1+\gamma}{\alpha-i \beta} \\
\text { and }-z^{-1}=-\frac{1}{z}=\frac{\alpha-i \beta}{1-\gamma}=\frac{1+\gamma}{\alpha+i \beta}
\end{array}\right\} \cdots \cdots (3)
 \alpha, \beta \gamma w z 
\alpha=\frac{1-w z}{w-z}, \quad \beta=i \frac{1+w z}{w-z}, \quad \gamma=\frac{w+z}{w-z} \cdots \cdots(4)
 
\begin{align}
\frac{dw}{ds}&==-\frac{i \tau}{2}-i \kappa w+\frac{i \tau}{2} w^2\\
\frac{dz}{ds}&=-\frac{\mathrm{i} \tau}{2}-\mathrm{i} z \mathrm{i}+\frac{i \tau}{2} z^2
\end{align}
 
\frac{\mathrm{d} f}{\mathrm{~d}}=\mathrm{A}(\mathrm{s})+\mathrm{B}(\mathrm{s}) f+\mathrm{C}(\mathrm{s}) f^2
 A(s)=-\frac{i \tau}{2}, B(s)=-i k C(s)=\frac{i \tau}{2}","['differential-geometry', 'surfaces', 'frenet-frame']"
89,"To prove Stokes's theorem, why does it suffice to prove it for $\mathbb{R}^n$ and for $\mathcal{H}^n$?","To prove Stokes's theorem, why does it suffice to prove it for  and for ?",\mathbb{R}^n \mathcal{H}^n,"In Tu's An Introduction to Manifolds , he states Stokes's theorem as: For any smooth $(n-1)$ -form $\omega$ with compact support on the oriented $n$ -dimensional manifold $M$ , $$\int_M d\omega = \int_{\partial M}\omega.$$ In his proof he chooses an atlas $\{(U_\alpha, \phi_\alpha)\}$ for $M$ in which each $U_\alpha$ is diffeomorphic to either $\mathbb{R}^n$ or $\mathcal{H}^n$ via an orientation-preserving diffeomorphism. He then says Suppose Stokes's theorem holds for $\mathbb{R}^n$ and for $\mathcal{H}^n$ . Then it holds for all the charts $U_\alpha$ in our atlas, which are diffeomorphic to $\mathbb{R}^n$ or $\mathcal{H}^n$ . I am having trouble seeing how Stokes's theorem applying to $\mathbb{R}^n$ and $\mathcal{H}^n$ implies it also holds for all the charts $U_\alpha$ . Is he using the diffeomorphism and a pull back to make some sort of change of variables that preserves the integral?","In Tu's An Introduction to Manifolds , he states Stokes's theorem as: For any smooth -form with compact support on the oriented -dimensional manifold , In his proof he chooses an atlas for in which each is diffeomorphic to either or via an orientation-preserving diffeomorphism. He then says Suppose Stokes's theorem holds for and for . Then it holds for all the charts in our atlas, which are diffeomorphic to or . I am having trouble seeing how Stokes's theorem applying to and implies it also holds for all the charts . Is he using the diffeomorphism and a pull back to make some sort of change of variables that preserves the integral?","(n-1) \omega n M \int_M d\omega = \int_{\partial M}\omega. \{(U_\alpha, \phi_\alpha)\} M U_\alpha \mathbb{R}^n \mathcal{H}^n \mathbb{R}^n \mathcal{H}^n U_\alpha \mathbb{R}^n \mathcal{H}^n \mathbb{R}^n \mathcal{H}^n U_\alpha","['differential-geometry', 'smooth-manifolds', 'differential-forms', 'stokes-theorem']"
90,The definition of smooth sections given in Introduction to smooth manifolds by John M. Lee,The definition of smooth sections given in Introduction to smooth manifolds by John M. Lee,,"In p. 176 of John M. Lee's Introduction to smooth manifolds, 2nd edition, Lee defines vector fields along subsets $A \subseteq M$ of a smooth manifold with boundary $M$ . The part that intrigues me is the fact that he requires a smooth local extension at each point by vector fields , not just any smooth maps. That makes you think there is a separate definition for smooth vector fields along arbitrary subsets. I've been thinking about it and I think the requirement of local extension at each point by vector fields is unnecessary. I'll write briefly about that here in the more general context of vector bundles. I want to know (preferably from @ Jack Lee ) if I'm doing this correctly. This is the definition that Lee suggest of smooth sections along arbitrary subsets. Definition. Let $M$ be a smooth manifold with or without boundary, $\pi: E \to M$ a vector bundle of rank $k$ , $A \subseteq M$ an arbitrary subset and $\sigma: A \to E$ a rough section, i.e. a map (not necessarily continuous) such that $\pi\circ\sigma = Id_A$ . We say $\sigma$ is smooth if $\sigma$ extends to a smooth local section of E in a neighborhood of each point. See Definition of smoothness to have some context about the definition of smoothness along arbitrary subsets. And this is what I'm thinking. Theorem 1. Let $M$ be a smooth manifold with or without boundary, $A \subseteq M$ an arbitrary subset and $k \in \mathbb{N}$ . If $f: A \to \mathbb{R}^k$ is smooth then there exist an open neighborhood $U$ of $A$ and a smooth extension $\overline{f}: U \to \mathbb{R}^k$ of $f$ . Proof. Use partitions of unity. Theorem 2. Let $M$ be a smooth manifold with or without boundary, $\pi: E \to M$ a vector bundle of rank $k$ , $(\sigma_1, \dots, \sigma_k)$ a local frame for $E$ over the open subset $U \subseteq M$ , $A \subseteq U$ an arbitrary subset and $\sigma: A \to E$ a rough section. Write $\sigma = \tau^i\sigma_i$ for some component functions $\tau^i: A \to \mathbb{R}$ . Then $\sigma$ is smooth if and only if all $\tau^i$ are smooth. Furthermore, if $\sigma$ is smooth then there exists a neighborhood $W$ of $A$ and a smooth  extension $\overline{\sigma}: W \to E$ of $\sigma$ which is a section such that $W \subseteq U$ . Proof. The first part is just following the definitions (but being careful of using the right definition of smoothness for arbitrary subsets of smooth manifolds with boundary). For the second part, assume $\tau = (\tau^1, \dots, \tau^k): A \to \mathbb{R}^k$ is smooth. By Theorem 1. , there exists  a neighborhood $W$ of $A$ and a smooth extension $\overline{\tau}: W \to \mathbb{R}^k$ of $\tau$ such that $W \subseteq U$ . Now simply define $\overline{\sigma} = \overline{\tau}^i\sigma_i$ . This is a smooth section and extends $\sigma$ . Theorem 3. Let $M$ be a smooth manifold with or without boundary, $\pi: E \to M$ a vector bundle of rank $k$ , $A \subseteq M$ an arbitrary subset and $\sigma: A \to E$ a rough section. If $\sigma$ is smooth then there exists an open neighborhood $U$ of $A$ and a smooth extension $\overline{\sigma}: U \to E$ of $\sigma$ which is a section. Proof. By Theorem 2. , we can pick for each $p \in A$ , a neighborhood $U_p$ of $p$ and a smooth extension $\overline{\sigma}_p: U_p \to E$ of $\sigma|_{A \cap U_p}$ which is a section. Now pick a smooth partitions of unity $(\psi_p)_{p \in A}$ subordinated to the open cover $(U_p)_{p \in A}$ of $U = \bigcup_{p \in A}U_p$ . Now define \begin{equation*}   \overline{\sigma}(x) = \sum_{p \in A}\psi_p(x)\overline{\sigma}_p(x), \end{equation*} for $x \in U$ . This is a smooth section and extends $\sigma$ .","In p. 176 of John M. Lee's Introduction to smooth manifolds, 2nd edition, Lee defines vector fields along subsets of a smooth manifold with boundary . The part that intrigues me is the fact that he requires a smooth local extension at each point by vector fields , not just any smooth maps. That makes you think there is a separate definition for smooth vector fields along arbitrary subsets. I've been thinking about it and I think the requirement of local extension at each point by vector fields is unnecessary. I'll write briefly about that here in the more general context of vector bundles. I want to know (preferably from @ Jack Lee ) if I'm doing this correctly. This is the definition that Lee suggest of smooth sections along arbitrary subsets. Definition. Let be a smooth manifold with or without boundary, a vector bundle of rank , an arbitrary subset and a rough section, i.e. a map (not necessarily continuous) such that . We say is smooth if extends to a smooth local section of E in a neighborhood of each point. See Definition of smoothness to have some context about the definition of smoothness along arbitrary subsets. And this is what I'm thinking. Theorem 1. Let be a smooth manifold with or without boundary, an arbitrary subset and . If is smooth then there exist an open neighborhood of and a smooth extension of . Proof. Use partitions of unity. Theorem 2. Let be a smooth manifold with or without boundary, a vector bundle of rank , a local frame for over the open subset , an arbitrary subset and a rough section. Write for some component functions . Then is smooth if and only if all are smooth. Furthermore, if is smooth then there exists a neighborhood of and a smooth  extension of which is a section such that . Proof. The first part is just following the definitions (but being careful of using the right definition of smoothness for arbitrary subsets of smooth manifolds with boundary). For the second part, assume is smooth. By Theorem 1. , there exists  a neighborhood of and a smooth extension of such that . Now simply define . This is a smooth section and extends . Theorem 3. Let be a smooth manifold with or without boundary, a vector bundle of rank , an arbitrary subset and a rough section. If is smooth then there exists an open neighborhood of and a smooth extension of which is a section. Proof. By Theorem 2. , we can pick for each , a neighborhood of and a smooth extension of which is a section. Now pick a smooth partitions of unity subordinated to the open cover of . Now define for . This is a smooth section and extends .","A \subseteq M M M \pi: E \to M k A \subseteq M \sigma: A \to E \pi\circ\sigma = Id_A \sigma \sigma M A \subseteq M k \in \mathbb{N} f: A \to \mathbb{R}^k U A \overline{f}: U \to \mathbb{R}^k f M \pi: E \to M k (\sigma_1, \dots, \sigma_k) E U \subseteq M A \subseteq U \sigma: A \to E \sigma = \tau^i\sigma_i \tau^i: A \to \mathbb{R} \sigma \tau^i \sigma W A \overline{\sigma}: W \to E \sigma W \subseteq U \tau = (\tau^1, \dots, \tau^k): A \to \mathbb{R}^k W A \overline{\tau}: W \to \mathbb{R}^k \tau W \subseteq U \overline{\sigma} = \overline{\tau}^i\sigma_i \sigma M \pi: E \to M k A \subseteq M \sigma: A \to E \sigma U A \overline{\sigma}: U \to E \sigma p \in A U_p p \overline{\sigma}_p: U_p \to E \sigma|_{A \cap U_p} (\psi_p)_{p \in A} (U_p)_{p \in A} U = \bigcup_{p \in A}U_p \begin{equation*}
  \overline{\sigma}(x) = \sum_{p \in A}\psi_p(x)\overline{\sigma}_p(x),
\end{equation*} x \in U \sigma","['differential-geometry', 'smooth-manifolds', 'vector-bundles']"
91,Proving that the intersection of two regular surfaces is a regular curve,Proving that the intersection of two regular surfaces is a regular curve,,"I'm having some trouble with the following problem: Let $S_1$ and $S_2$ be two regular surfaces that intersect at a point $p$ , such that $T_pS_1\neq T_pS_2$ . Prove that there is an open neighborhood $U\subseteq\mathbb R^3$ of $p$ such that $S_1 \cap S_2\cap U$ is the trace of a regular curve. My first idea was to use the fact that, because $S_1$ and $S_2$ are regular surfaces, there are open neighborhoods $W,V$ in $\mathbb R^3$ of $p$ and $f:W\to\mathbb R$ , $g:V\to\mathbb R$ differentiable, such that: $$W\cap S_1=f^{-1}(\{0\})$$ $$V\cap S_2=g^{-1}(\{0\})$$ So with this, we can conclude, if we set $U=W\cap V$ , that $S_1\cap S_2\cap U$ is defined by the following system of equations: $$f(x,y,z)=0$$ $$g(x,y,z)=0$$ This is a system with 2 equations and 3 variables, so my intuition tells me that the solution will have 1 free variable, and thus be a curve, but I have no idea how to formalize this. My second idea was the following: If $T_pS_1$ and $T_pS_2$ intersect and are not the same, then $T_pS_1\cap T_pS_2$ is a one-dimensional linear subspace of $\mathbb R^3$ , let it be the space generated by the vector $v$ . Now we know a vector that will be tangent to the curve we want to find. Maybe with this, we can construct the curve? Does any of these ideas work? If that's now the case, how can this be done?","I'm having some trouble with the following problem: Let and be two regular surfaces that intersect at a point , such that . Prove that there is an open neighborhood of such that is the trace of a regular curve. My first idea was to use the fact that, because and are regular surfaces, there are open neighborhoods in of and , differentiable, such that: So with this, we can conclude, if we set , that is defined by the following system of equations: This is a system with 2 equations and 3 variables, so my intuition tells me that the solution will have 1 free variable, and thus be a curve, but I have no idea how to formalize this. My second idea was the following: If and intersect and are not the same, then is a one-dimensional linear subspace of , let it be the space generated by the vector . Now we know a vector that will be tangent to the curve we want to find. Maybe with this, we can construct the curve? Does any of these ideas work? If that's now the case, how can this be done?","S_1 S_2 p T_pS_1\neq T_pS_2 U\subseteq\mathbb R^3 p S_1 \cap S_2\cap U S_1 S_2 W,V \mathbb R^3 p f:W\to\mathbb R g:V\to\mathbb R W\cap S_1=f^{-1}(\{0\}) V\cap S_2=g^{-1}(\{0\}) U=W\cap V S_1\cap S_2\cap U f(x,y,z)=0 g(x,y,z)=0 T_pS_1 T_pS_2 T_pS_1\cap T_pS_2 \mathbb R^3 v","['differential-geometry', 'solution-verification', 'curves', 'surfaces']"
92,Showing a level curve is not $C^1$.,Showing a level curve is not .,C^1,"Define $F(x,y) := x^3 - y^2$ and $C$ is the curve $F(x,y) = 0$ . Now when you graph this, we can see its clearly not $C^1$ , as there is a cusp at the origin (meaning not differentiable at origin). We can define $x$ globally as a function of $y$ , but according to Implicit Function Theorem, $F_x(0,0) = 0$ , so we can't locally define $x$ as a function of $y$ . The question is essentially asking if this is a contradiction of the Implicit Function Theorem and I believe it's not since $x^3 - y^2 = 0$ is not $C^1$ , so the assumptions of IFT are not met. The partials are $(3x^2, -2y)$ which exist and are continuous everywhere, which imply that it is $C^1$ , but this is clearly not the case. How do I go about showing the curve $x^3-y^2=0$ is not $C^1$ ?","Define and is the curve . Now when you graph this, we can see its clearly not , as there is a cusp at the origin (meaning not differentiable at origin). We can define globally as a function of , but according to Implicit Function Theorem, , so we can't locally define as a function of . The question is essentially asking if this is a contradiction of the Implicit Function Theorem and I believe it's not since is not , so the assumptions of IFT are not met. The partials are which exist and are continuous everywhere, which imply that it is , but this is clearly not the case. How do I go about showing the curve is not ?","F(x,y) := x^3 - y^2 C F(x,y) = 0 C^1 x y F_x(0,0) = 0 x y x^3 - y^2 = 0 C^1 (3x^2, -2y) C^1 x^3-y^2=0 C^1","['calculus', 'differential-geometry', 'implicit-function-theorem']"
93,"If $w \ge 0$ and $\mu$ is a finite measure on $X$ with $\mu(w = 0) \ge \mu(X)/2$, is $\mu(w > t) \le 2 \mu(|w - c| > t/2)$?","If  and  is a finite measure on  with , is ?",w \ge 0 \mu X \mu(w = 0) \ge \mu(X)/2 \mu(w > t) \le 2 \mu(|w - c| > t/2),"Suppose we have a finite measure space $(X, \mu)$ and a measurable function $w \ge 0$ on $X$ satisfying $\mu(w = 0) \ge \mu(X)/2$ , is it true that for any real $c$ we have $\mu(w > t) \le 2 \mu(|w - c| > t/2)$ whenever $t > 0$ ? If $c > t/2$ then clearly $\{ w = 0 \} \subset \{c - w > t/2\}$ , but $c - w(x) > t/2 > 0$ implies $|w(x) - c| = c -w(x) > t/2$ , so we have $$ \mu(X)/2 \le \mu(w = 0) \le \mu(|w -c| > t/2).  $$ On the other hand, $\{ w > t\} \subset \{ w \neq 0\}$ so $$\mu(w > t) \le \mu(X) - \mu(w = 0) \le \mu(X)/2 \le \mu(|w - c| > t/2), $$ which proves the claim when $c > t/2$ . When $c \le t/2$ , we have $w > t \ge c + t/2$ so $\{ w > t\} \subset \{w - c > t/2\} \subset \{ |w - c| > t/2\}$ , from which we again see that $\mu(w > t) \le \mu(|w - c| > t/2)$ . However, in Petersen's Riemannian Geometry (in his proof of Theorem 7.1.13), and in Lemma 2.2 of this paper , the inequality given is $$ \mu(w > t) \le 2 \mu(|w -c| > t/2), $$ this extra factor of $2$ leads me to believe that I must have done something wrong, but the argument is so simple I cannot find any problems with it. Am I missing something obvious?","Suppose we have a finite measure space and a measurable function on satisfying , is it true that for any real we have whenever ? If then clearly , but implies , so we have On the other hand, so which proves the claim when . When , we have so , from which we again see that . However, in Petersen's Riemannian Geometry (in his proof of Theorem 7.1.13), and in Lemma 2.2 of this paper , the inequality given is this extra factor of leads me to believe that I must have done something wrong, but the argument is so simple I cannot find any problems with it. Am I missing something obvious?","(X, \mu) w \ge 0 X \mu(w = 0) \ge \mu(X)/2 c \mu(w > t) \le 2 \mu(|w - c| > t/2) t > 0 c > t/2 \{ w = 0 \} \subset \{c - w > t/2\} c - w(x) > t/2 > 0 |w(x) - c| = c -w(x) > t/2 
\mu(X)/2 \le \mu(w = 0) \le \mu(|w -c| > t/2). 
 \{ w > t\} \subset \{ w \neq 0\} \mu(w > t) \le \mu(X) - \mu(w = 0) \le \mu(X)/2 \le \mu(|w - c| > t/2),
 c > t/2 c \le t/2 w > t \ge c + t/2 \{ w > t\} \subset \{w - c > t/2\} \subset \{ |w - c| > t/2\} \mu(w > t) \le \mu(|w - c| > t/2) 
\mu(w > t) \le 2 \mu(|w -c| > t/2),
 2","['differential-geometry', 'riemannian-geometry', 'sobolev-spaces']"
94,"$SL(n,\mathbb{C})\rightarrow GL(2n,\mathbb{R})$ reduction of frame bundle",reduction of frame bundle,"SL(n,\mathbb{C})\rightarrow GL(2n,\mathbb{R})","When we study the frame bundle of a n-dimensional Riemannian manifold $M$ we start with a principal $GL(n,\mathbb{R})$ bundle over $M$ . There are a series of topological obstructions to reducing the structure. If the bundle is orientable we have a reduction $$GL^{+}(n,\mathbb{R})\rightarrow GL(n,\mathbb{R}) $$ If the manifold admits a metric (always since we're talking Riemannian), then we get: $$O(n,\mathbb{R})\rightarrow GL(n,\mathbb{R})$$ We call it a reduction to the orthonormal frame bundle. Suppose we look at instead: $$SL(n,\mathbb{R})\rightarrow GL(n,\mathbb{R})$$ Then we have a volume form on our manifold. I'm familiar with the idea, what I'm wondering about is a reduction of the form: $$SL(n,\mathbb{C})\rightarrow SL(2n,\mathbb{R})$$ for a manifold of even dimension. What does that correspond to? What are the topological obstructions to it's existence? Or we might consider instead: $$GL(n,\mathbb{C})\rightarrow GL(2n,\mathbb{R})$$ is this just the existence of a complex structure, or is there more, what kind of frames does this reduction of the frame bundle correspond to?","When we study the frame bundle of a n-dimensional Riemannian manifold we start with a principal bundle over . There are a series of topological obstructions to reducing the structure. If the bundle is orientable we have a reduction If the manifold admits a metric (always since we're talking Riemannian), then we get: We call it a reduction to the orthonormal frame bundle. Suppose we look at instead: Then we have a volume form on our manifold. I'm familiar with the idea, what I'm wondering about is a reduction of the form: for a manifold of even dimension. What does that correspond to? What are the topological obstructions to it's existence? Or we might consider instead: is this just the existence of a complex structure, or is there more, what kind of frames does this reduction of the frame bundle correspond to?","M GL(n,\mathbb{R}) M GL^{+}(n,\mathbb{R})\rightarrow GL(n,\mathbb{R})  O(n,\mathbb{R})\rightarrow GL(n,\mathbb{R}) SL(n,\mathbb{R})\rightarrow GL(n,\mathbb{R}) SL(n,\mathbb{C})\rightarrow SL(2n,\mathbb{R}) GL(n,\mathbb{C})\rightarrow GL(2n,\mathbb{R})","['differential-geometry', 'algebraic-topology', 'principal-bundles']"
95,"A description of line bundles on projective spaces, $\mathcal{O}_{\mathbb{P}^n}(m)$ defined using a character of $\mathbb{C}^*$.","A description of line bundles on projective spaces,  defined using a character of .",\mathcal{O}_{\mathbb{P}^n}(m) \mathbb{C}^*,"I am trying to define line bundles on $\mathbb{P}^n$ as a triplet $E \xrightarrow{p} \mathbb{P}^n$ . It follows the idea. Let $m \in \mathbb{Z}$ a fixed integer. Take $E$ the quotient of $\mathbb{C}^{n+1} \times \mathbb{C}$ by the action of $\mathbb{C}^\times$ given by $$ t \cdot ((z_0,\dots,z_n),\lambda)=(t(z_0,\dots,z_n),t^m\lambda)$$ and let me denote it by $E=\mathbb{C}^{n+1} \times_{\mathbb{C}^\times} \mathbb{C}$ . We have a natural $p$ which is the projection onto the first factor: $$ E=\mathbb{C}^{n+1} \times_{\mathbb{C}^\times} \mathbb{C} \rightarrow \mathbb{P}^n$$ $$ (z,l) \mapsto [z] $$ I'm wondering if it is $\mathcal{O}(m)$ or $\mathcal{O}(-m)$ . Where $\mathcal{O}(m)$ is defined in terms of sheaves as the sheaf of ""holomorphic maps of degree $m$ "".","I am trying to define line bundles on as a triplet . It follows the idea. Let a fixed integer. Take the quotient of by the action of given by and let me denote it by . We have a natural which is the projection onto the first factor: I'm wondering if it is or . Where is defined in terms of sheaves as the sheaf of ""holomorphic maps of degree "".","\mathbb{P}^n E \xrightarrow{p} \mathbb{P}^n m \in \mathbb{Z} E \mathbb{C}^{n+1} \times \mathbb{C} \mathbb{C}^\times  t \cdot ((z_0,\dots,z_n),\lambda)=(t(z_0,\dots,z_n),t^m\lambda) E=\mathbb{C}^{n+1} \times_{\mathbb{C}^\times} \mathbb{C} p  E=\mathbb{C}^{n+1} \times_{\mathbb{C}^\times} \mathbb{C} \rightarrow \mathbb{P}^n  (z,l) \mapsto [z]  \mathcal{O}(m) \mathcal{O}(-m) \mathcal{O}(m) m","['differential-geometry', 'algebraic-geometry', 'representation-theory', 'vector-bundles', 'line-bundles']"
96,"Injective Lie Group Homomorphism, compact domain","Injective Lie Group Homomorphism, compact domain",,"Problem: Assume $F:G\rightarrow G$ is an injective Lie group homomorphism, where $G$ is finite dimensional. If $G$ is compact, then show that $F$ is surjective. Incomplete attempt: As $F$ is a Lie group homomorphism, it has constant rank. Hence, the differential $F_{*,e}:\mathfrak{g}\rightarrow \mathfrak{g}$ is an isomorphism. Hence by the Inverse function theorem, $F$ is a local diffeomorphism. Since $G$ is compact, $F$ is closed. Since $F$ is a local diffeomorphism, $F$ is open. Moreover, $F:G\rightarrow F(G)$ is a homeomorphism, and so $F(G_0)=G_0$ since $G_0$ is the only open connected subgroup of $G$ . Now why does it follow that $F$ is surjective?","Problem: Assume is an injective Lie group homomorphism, where is finite dimensional. If is compact, then show that is surjective. Incomplete attempt: As is a Lie group homomorphism, it has constant rank. Hence, the differential is an isomorphism. Hence by the Inverse function theorem, is a local diffeomorphism. Since is compact, is closed. Since is a local diffeomorphism, is open. Moreover, is a homeomorphism, and so since is the only open connected subgroup of . Now why does it follow that is surjective?","F:G\rightarrow G G G F F F_{*,e}:\mathfrak{g}\rightarrow \mathfrak{g} F G F F F F:G\rightarrow F(G) F(G_0)=G_0 G_0 G F",['differential-geometry']
97,Finding tangent vectors to unit circle,Finding tangent vectors to unit circle,,"I am working on the following problem from Tu's Introduction to Manifolds . I have been able to do (a), but (b) is causing me some troubles. My approach so far is as follows. Let $C$ be some smooth curve in $\mathbb{R}^2$ with $C(0) = p$ and $C'(0) = \frac{\partial}{\partial \overline{x}}\Big|_p.$ Then $$i_*\Big(\frac{\partial}{\partial \overline{x}}\Big|_p\Big) = \frac{d}{dt}\Big|_0(i \circ C)(t) = \frac{\partial i}{\partial C}\Big|_{C(0)} \frac{\partial C}{\partial t}\Big|_0 = \frac{\partial i}{\partial C}\frac{\partial}{\partial \overline{x}}\Big|_p.$$ I am unable to take this any further and it seems I am on the wrong track. Can anyone provide some hints?","I am working on the following problem from Tu's Introduction to Manifolds . I have been able to do (a), but (b) is causing me some troubles. My approach so far is as follows. Let be some smooth curve in with and Then I am unable to take this any further and it seems I am on the wrong track. Can anyone provide some hints?",C \mathbb{R}^2 C(0) = p C'(0) = \frac{\partial}{\partial \overline{x}}\Big|_p. i_*\Big(\frac{\partial}{\partial \overline{x}}\Big|_p\Big) = \frac{d}{dt}\Big|_0(i \circ C)(t) = \frac{\partial i}{\partial C}\Big|_{C(0)} \frac{\partial C}{\partial t}\Big|_0 = \frac{\partial i}{\partial C}\frac{\partial}{\partial \overline{x}}\Big|_p.,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
98,Why does $g_x$ depends continuously on $x$?,Why does  depends continuously on ?,g_x x,"In Vector Bundles and K-Theory (version 2.2, p.8), Hatcher explains: Lemma 1.1. A continuous map $h:E_1\to E_2$ between vector bundles over the same base space $B$ is an isomorphism if it takes each fiber $p_1^{-1}(b)$ to the corresponding fiber $p_2^{-1}(b)$ by a linear isomorphism. Proof: The hypothesis implies that $h$ is one-to-one and onto. What must be checked is that $h^{-1}$ is continuous. This is a local question, so we may restrict to an open set $U\subset B$ over which $E_1$ and $E_2$ are trivial. Composing with local trivializations reduces to the case that $h$ is a continuous map $U\times\mathbb{R}^n\to U\times\mathbb{R}^n$ of the form $h(x,v)=(x,g_x(v))$ . Here $g_x$ is an element of the group $GL(n,\mathbb{R})$ of invertible linear transformations of $\mathbb{R}^n$ , and $g_x$ depends continuously on $x$ . This means that if $g_x$ is regarded as an $n\times n$ matrix, its $n^2$ entries depends continuously on $x$ . The inverse matrix $g_x^{-1}$ also depends continuously on $x$ since its entries can be expressed algebraically in terms of the entries of $g_x$ , namely $g_x^{-1}$ is $1/(\det g_x)$ times the classical adjoint matrix of $g_x$ . Therefore $h^{-1}(x,v)=(x,g_x^{-1}(v))$ is continuous. $\square$ The part that confuses me is in bold. Why does $g_x$ depends continuously on $x$ ?","In Vector Bundles and K-Theory (version 2.2, p.8), Hatcher explains: Lemma 1.1. A continuous map between vector bundles over the same base space is an isomorphism if it takes each fiber to the corresponding fiber by a linear isomorphism. Proof: The hypothesis implies that is one-to-one and onto. What must be checked is that is continuous. This is a local question, so we may restrict to an open set over which and are trivial. Composing with local trivializations reduces to the case that is a continuous map of the form . Here is an element of the group of invertible linear transformations of , and depends continuously on . This means that if is regarded as an matrix, its entries depends continuously on . The inverse matrix also depends continuously on since its entries can be expressed algebraically in terms of the entries of , namely is times the classical adjoint matrix of . Therefore is continuous. The part that confuses me is in bold. Why does depends continuously on ?","h:E_1\to E_2 B p_1^{-1}(b) p_2^{-1}(b) h h^{-1} U\subset B E_1 E_2 h U\times\mathbb{R}^n\to U\times\mathbb{R}^n h(x,v)=(x,g_x(v)) g_x GL(n,\mathbb{R}) \mathbb{R}^n g_x x g_x n\times n n^2 x g_x^{-1} x g_x g_x^{-1} 1/(\det g_x) g_x h^{-1}(x,v)=(x,g_x^{-1}(v)) \square g_x x","['differential-geometry', 'vector-bundles']"
99,smooth points on variety of linear subspaces intersecting a given subspace,smooth points on variety of linear subspaces intersecting a given subspace,,"$\newcommand{\Ind}{\operatorname{Ind}} \newcommand{\Gr}{\operatorname{Gr}} \newcommand{\Hom}{\operatorname{Hom}} \newcommand{\R}{\mathbb{R}} \newcommand{\GL}{\operatorname{GL}} \newcommand{\codim}{\operatorname{codim}}$ Let $\Gr_k$ be the Grassmannian manifold of $k$ -dimensional subspaces in $\R^n$ . Let $\GL(n)$ act on $\Gr_k$ in the natural way. For an arbitrary such subspace $V \in \Gr_k$ , let $\varphi_V \colon \GL(n) \to \Gr_k$ take $\varphi_V(g) = g V$ . This is a surjective map with surjective differential. Differentiating $\varphi_V$ at the identity element $e \in \GL(n)$ gives a map $d \varphi_V \colon \Hom(\R^n, \R^n) \to T_V \Gr_k$ , and its kernel are the maps $f$ that stabilize $V$ , in the sense that $f(V) \subseteq V$ . Since the map $\eta_V \colon \Hom(\R^n, \R^n) \to \Hom(V, \R^n / V)$ defined by $\eta_V(f) = \pi_V \circ f \circ \iota_V$ has the same kernel, this establishes an isomorphism $T_V \Gr_k \cong \Hom(V, \R^n / V)$ . When $W$ is some subspace, define $\Ind_k(W)$ to be the subset of elements $V \in \Gr_k$ that intersect $W$ in dimension at least one. In the literature, this is a special case of a ""Schubert variety."" I strongly suspect that $\Ind_k(W)$ is an embedded submanifold of $\Gr_k$ in a neighborhood of an element $V$ where $\dim V \cap W = 1$ . Furthermore, I believe its tangent space at such an element is composed, under the isomorphism above, of the maps $f$ for which $f(V \cap W) \subseteq W / V$ . However, I'm having trouble proving this rigorously. One idea is to consider the function $F(g) = g V \wedge W$ , viewing $V$ and $W$ as arbitrarily scaled elements of the exterior algebra $\Lambda(\R^n)$ . The system of $k$ -degree polynomial relations $F(g) = 0$ cuts out the preimage of $\Ind_k(W)$ under $\varphi_V$ . We can also differentiate $F$ at the identity in the following way. Since $V \cap W$ is a one-dimensional subspace, we have a basis $v_1, \ldots, v_k$ for $V$ with $V \cap W = \langle v_1 \rangle$ . For $A \in \Hom(\R^n, \R^n)$ , differentiating gives \begin{align*} d F_e(A) & = \frac d{dt}_{t = 0} e^{t A} V \wedge W = \frac d{dt}_{t = 0} \left (\bigwedge_{i = 1}^k e^{t A} v_i \right) \wedge W \\  & = \sum_{i = 1}^k (-1)^{i + 1} A v_i \wedge \bigwedge_{\substack{j = 1 \\ j \neq i}}^k v_j \wedge W  = A v_1 \wedge v_2 \wedge \ldots \wedge v_k \wedge W, \end{align*} where the last equality follows because $v_1 \wedge W = 0$ . In particular, we conclude that the kernel of $dF$ are the maps $f$ for which $f(V \cap W) \subseteq V + W$ . The image of $\ker dF_e$ under $d \varphi_V$ coincides with the description of $T_V \Ind_k(W)$ that I have conjectured. Unfortunately, I believe that $F$ does not have constant rank near the identity. How can I easily show that $F^{-1}(0)$ is an embedded submanifold near this point, with tangent space given by the kernel of $dF$ ?","Let be the Grassmannian manifold of -dimensional subspaces in . Let act on in the natural way. For an arbitrary such subspace , let take . This is a surjective map with surjective differential. Differentiating at the identity element gives a map , and its kernel are the maps that stabilize , in the sense that . Since the map defined by has the same kernel, this establishes an isomorphism . When is some subspace, define to be the subset of elements that intersect in dimension at least one. In the literature, this is a special case of a ""Schubert variety."" I strongly suspect that is an embedded submanifold of in a neighborhood of an element where . Furthermore, I believe its tangent space at such an element is composed, under the isomorphism above, of the maps for which . However, I'm having trouble proving this rigorously. One idea is to consider the function , viewing and as arbitrarily scaled elements of the exterior algebra . The system of -degree polynomial relations cuts out the preimage of under . We can also differentiate at the identity in the following way. Since is a one-dimensional subspace, we have a basis for with . For , differentiating gives where the last equality follows because . In particular, we conclude that the kernel of are the maps for which . The image of under coincides with the description of that I have conjectured. Unfortunately, I believe that does not have constant rank near the identity. How can I easily show that is an embedded submanifold near this point, with tangent space given by the kernel of ?","\newcommand{\Ind}{\operatorname{Ind}} \newcommand{\Gr}{\operatorname{Gr}} \newcommand{\Hom}{\operatorname{Hom}} \newcommand{\R}{\mathbb{R}} \newcommand{\GL}{\operatorname{GL}} \newcommand{\codim}{\operatorname{codim}} \Gr_k k \R^n \GL(n) \Gr_k V \in \Gr_k \varphi_V \colon \GL(n) \to \Gr_k \varphi_V(g) = g V \varphi_V e \in \GL(n) d \varphi_V \colon \Hom(\R^n, \R^n) \to T_V \Gr_k f V f(V) \subseteq V \eta_V \colon \Hom(\R^n, \R^n) \to \Hom(V, \R^n / V) \eta_V(f) = \pi_V \circ f \circ \iota_V T_V \Gr_k \cong \Hom(V, \R^n / V) W \Ind_k(W) V \in \Gr_k W \Ind_k(W) \Gr_k V \dim V \cap W = 1 f f(V \cap W) \subseteq W / V F(g) = g V \wedge W V W \Lambda(\R^n) k F(g) = 0 \Ind_k(W) \varphi_V F V \cap W v_1, \ldots, v_k V V \cap W = \langle v_1 \rangle A \in \Hom(\R^n, \R^n) \begin{align*}
d F_e(A) & = \frac d{dt}_{t = 0} e^{t A} V \wedge W = \frac d{dt}_{t = 0} \left (\bigwedge_{i = 1}^k e^{t A} v_i \right) \wedge W \\ 
& = \sum_{i = 1}^k (-1)^{i + 1} A v_i \wedge \bigwedge_{\substack{j = 1 \\ j \neq i}}^k v_j \wedge W  = A v_1 \wedge v_2 \wedge \ldots \wedge v_k \wedge W,
\end{align*} v_1 \wedge W = 0 dF f f(V \cap W) \subseteq V + W \ker dF_e d \varphi_V T_V \Ind_k(W) F F^{-1}(0) dF","['differential-geometry', 'grassmannian', 'schubert-calculus']"
