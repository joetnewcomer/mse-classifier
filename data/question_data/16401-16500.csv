,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Find an integral with fractions,Find an integral with fractions,,How to find the integral $$\int_0^\infty \frac{e^{-x^2}}{(x^2+1/2)^2}dx?$$ I find it is difficult to do if I integrate by parts...What's the trick?,How to find the integral $$\int_0^\infty \frac{e^{-x^2}}{(x^2+1/2)^2}dx?$$ I find it is difficult to do if I integrate by parts...What's the trick?,,"['calculus', 'integration', 'definite-integrals']"
1,Solve for constants: Derivatives using first principles,Solve for constants: Derivatives using first principles,,"Question Find the values of the constants $a$ and $b$ such that $$\lim_{x \to 0}\frac{\sqrt[3]{ax + b}-2}{x} = \frac{5}{12}$$ My approach Using the definition of the derivative, $$f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}$$ I view limit as a derivative of a function $f$ at some value, let's call that value $c$, as follows :$$f'(c) = \lim_{x\to 0}\frac{f(c + x) - f(c)}{x} = \frac{\sqrt[3]{ax + b} - 2}{x} = \frac{5}{12}$$ Now I deduce the following: $$f(c + x)  = \sqrt[3]{ax + b}$$ and $$f(c) = 2$$ Use limits as follows: $$\lim_{x\to 0} f(c + x) = f(c) = 2$$ that is, $$\lim_{x\to 0} f(c + x) = \lim_{x\to 0} \sqrt[3]{ax + b} = \sqrt[3]{b} = 2$$ now solve for $b$, $$\sqrt[3]{b} = 2 \Leftrightarrow b = 8$$ Since I know that $$f(c + x) = \sqrt[3]{ax + 8}$$, I can solve for $a$, which is $$a = \frac{[f(c+x)]^3 - 8}{x} = \frac{[f(c+x)]^3 - [f(c)]^3}{x}$$ Let $g(x) = [f(x)]^3$, such that $$g'(x) = 3\cdot [f(x)]^2 \cdot f'(x)$$ so $$g'(c) = 3\cdot [f(c)]^2 \cdot f'(c) = 3 \cdot 4 \cdot \frac{5}{12} = 5$$ Rephrase $g'(c)$ using first principles such that $$g'(c) = \lim_{x \to 0}\frac{g(c + x)- g(c)}{x}= \lim_{x \to 0}\frac{[f(c + x)]^3 - [f(c)]^3}{x} = \lim_{x \to 0} a = 5$$ Since $a$ is a constant, $\lim_{x \to 0} a = a$, that is, $$a = 5$$ My solution: $b = 8, a = 5$. Please have a look at my approach and give me any hints/suggestions regarding the solution and/or steps taken.","Question Find the values of the constants $a$ and $b$ such that $$\lim_{x \to 0}\frac{\sqrt[3]{ax + b}-2}{x} = \frac{5}{12}$$ My approach Using the definition of the derivative, $$f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}$$ I view limit as a derivative of a function $f$ at some value, let's call that value $c$, as follows :$$f'(c) = \lim_{x\to 0}\frac{f(c + x) - f(c)}{x} = \frac{\sqrt[3]{ax + b} - 2}{x} = \frac{5}{12}$$ Now I deduce the following: $$f(c + x)  = \sqrt[3]{ax + b}$$ and $$f(c) = 2$$ Use limits as follows: $$\lim_{x\to 0} f(c + x) = f(c) = 2$$ that is, $$\lim_{x\to 0} f(c + x) = \lim_{x\to 0} \sqrt[3]{ax + b} = \sqrt[3]{b} = 2$$ now solve for $b$, $$\sqrt[3]{b} = 2 \Leftrightarrow b = 8$$ Since I know that $$f(c + x) = \sqrt[3]{ax + 8}$$, I can solve for $a$, which is $$a = \frac{[f(c+x)]^3 - 8}{x} = \frac{[f(c+x)]^3 - [f(c)]^3}{x}$$ Let $g(x) = [f(x)]^3$, such that $$g'(x) = 3\cdot [f(x)]^2 \cdot f'(x)$$ so $$g'(c) = 3\cdot [f(c)]^2 \cdot f'(c) = 3 \cdot 4 \cdot \frac{5}{12} = 5$$ Rephrase $g'(c)$ using first principles such that $$g'(c) = \lim_{x \to 0}\frac{g(c + x)- g(c)}{x}= \lim_{x \to 0}\frac{[f(c + x)]^3 - [f(c)]^3}{x} = \lim_{x \to 0} a = 5$$ Since $a$ is a constant, $\lim_{x \to 0} a = a$, that is, $$a = 5$$ My solution: $b = 8, a = 5$. Please have a look at my approach and give me any hints/suggestions regarding the solution and/or steps taken.",,"['calculus', 'limits', 'derivatives']"
2,Integration $I_n=\int_{0}^{1}\frac{dx}{(x^n+1)(\sqrt[n]{x^n+1})}$,Integration,I_n=\int_{0}^{1}\frac{dx}{(x^n+1)(\sqrt[n]{x^n+1})},$$I_n=\int_{0}^{1}\frac{dx}{(x^n+1)\large\sqrt[n]{\normalsize x^n+1}}$$ Could someone help me through this problem?,$$I_n=\int_{0}^{1}\frac{dx}{(x^n+1)\large\sqrt[n]{\normalsize x^n+1}}$$ Could someone help me through this problem?,,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
3,Does the series $\sum_{n=1}^{\infty}\sin\left(2\pi\sqrt{n^2+\alpha^2\sin n+(-1)^n}\right)$ converge?,Does the series  converge?,\sum_{n=1}^{\infty}\sin\left(2\pi\sqrt{n^2+\alpha^2\sin n+(-1)^n}\right),"Let $\alpha$ be such that $0\leq \alpha \leq 1$. Since $\sin n$ has no limit as $n$ tends to $\infty$, I'm having trouble with finding if the series $$\sum_{n=1}^{\infty}\sin \left(2\pi\sqrt{n^2+\alpha^2\sin n+(-1)^n}\right)$$ is convergent? Thanks.","Let $\alpha$ be such that $0\leq \alpha \leq 1$. Since $\sin n$ has no limit as $n$ tends to $\infty$, I'm having trouble with finding if the series $$\sum_{n=1}^{\infty}\sin \left(2\pi\sqrt{n^2+\alpha^2\sin n+(-1)^n}\right)$$ is convergent? Thanks.",,"['calculus', 'sequences-and-series', 'convergence-divergence', 'conditional-convergence']"
4,Finding a limit to negative infinity with square roots: $\lim\limits_{x\to -\infty}(x+\sqrt{x^2+2x})$,Finding a limit to negative infinity with square roots:,\lim\limits_{x\to -\infty}(x+\sqrt{x^2+2x}),Find the limit of the equation $$\lim_{x\to-\infty} (x+\sqrt{x^2 + 2x})$$ I start by multiplying with the conjugate: $$\lim_{x\to-\infty} \left[(x+\sqrt{x^2 + 2x})\left({x - \sqrt{x^2 + 2x}\over x - \sqrt{x^2+2x}}\right)\right]$$ $$\lim_{x\to-\infty} {x^2 - (x^2 + 2x)\over x - \sqrt{x^2+2x}}$$ $$\lim_{x\to-\infty} {-2x\over x - \sqrt{x^2+2x}}$$ divide by highest power of denominator $$\lim_{x\to-\infty} {(\frac1x)(-2x)\over (\frac1x) x - ({1\over \sqrt{x^2}})\sqrt{x^2+2x}}$$ $$\lim_{x\to-\infty} {-2\over 1 - \sqrt{1+\frac2x}} = {-2 \over 1-\sqrt{1 + 0}} = {-2 \over 0}$$ but I know this is wrong as the answer is $-1$. Where did I mess up? Thanks.,Find the limit of the equation $$\lim_{x\to-\infty} (x+\sqrt{x^2 + 2x})$$ I start by multiplying with the conjugate: $$\lim_{x\to-\infty} \left[(x+\sqrt{x^2 + 2x})\left({x - \sqrt{x^2 + 2x}\over x - \sqrt{x^2+2x}}\right)\right]$$ $$\lim_{x\to-\infty} {x^2 - (x^2 + 2x)\over x - \sqrt{x^2+2x}}$$ $$\lim_{x\to-\infty} {-2x\over x - \sqrt{x^2+2x}}$$ divide by highest power of denominator $$\lim_{x\to-\infty} {(\frac1x)(-2x)\over (\frac1x) x - ({1\over \sqrt{x^2}})\sqrt{x^2+2x}}$$ $$\lim_{x\to-\infty} {-2\over 1 - \sqrt{1+\frac2x}} = {-2 \over 1-\sqrt{1 + 0}} = {-2 \over 0}$$ but I know this is wrong as the answer is $-1$. Where did I mess up? Thanks.,,"['calculus', 'limits']"
5,Show that a specific $w$ cannot be the root of an quadratic with integer coefficients.,Show that a specific  cannot be the root of an quadratic with integer coefficients.,w,"Let $w$ be the only real root of $x^3-x-1=0$. Show that  $w$  cannot satisfy the quadratic $ax^2 + bx + c$ ,where $a,b,c\in \Bbb Z$. I have written  $$w^3=w+1$$ but I can't go any further than this. Thank you.","Let $w$ be the only real root of $x^3-x-1=0$. Show that  $w$  cannot satisfy the quadratic $ax^2 + bx + c$ ,where $a,b,c\in \Bbb Z$. I have written  $$w^3=w+1$$ but I can't go any further than this. Thank you.",,"['calculus', 'number-theory']"
6,optimal way to approximate second derivative,optimal way to approximate second derivative,,"Suppose there is a function $f: \mathbb R\to \mathbb R$ and that we only know $f(0),f(h),f'(h),f(2h)$ for some $h>0$. and we can't know the value of $f$ with $100$% accuracy at any other point. What is the optimal way of approximating $f''(0)$ with the given data? I'd say that $f''(0)=\frac{f'(h)-f'(0)}{h}+O(h)$ and $f'(0)=\frac{f(h)-f(0)}{h}+O(h)$, therefor we get $$f''(0)=\frac{f'(h)-\frac{f(h)-f(0)}{h}}{h}+O(h)$$ But that can't be the optimal way since we know $f(2h)$ and i didn't use it at all. Could someone shed some light?","Suppose there is a function $f: \mathbb R\to \mathbb R$ and that we only know $f(0),f(h),f'(h),f(2h)$ for some $h>0$. and we can't know the value of $f$ with $100$% accuracy at any other point. What is the optimal way of approximating $f''(0)$ with the given data? I'd say that $f''(0)=\frac{f'(h)-f'(0)}{h}+O(h)$ and $f'(0)=\frac{f(h)-f(0)}{h}+O(h)$, therefor we get $$f''(0)=\frac{f'(h)-\frac{f(h)-f(0)}{h}}{h}+O(h)$$ But that can't be the optimal way since we know $f(2h)$ and i didn't use it at all. Could someone shed some light?",,"['calculus', 'derivatives', 'numerical-methods']"
7,Taylor series of an integral function,Taylor series of an integral function,,"Problem $$I(x) = \int_{1}^x \frac{e^t - 1}{t}$$ Find $I'( \sqrt{x} )$. Solution We know that $F'(x) = f(x)$ by the fundamental theorem of calculus so $$I'(x) = \frac{e^t -1}{t}$$ And so $$I'( \sqrt{x}) = \frac{ e^{\sqrt{x}} -1 }{ \sqrt{x}}$$ Problem Find the fourth taylor polynomial of $I(x)$ around $0$ (Guess this makes it a Maclaurin series?) Taylor series: $$ \sum_{n=o}^\infty \frac{ f^{(n)} (a) }{n!} (x-a)^n$$ So as we know the first derivative, we can compute the first Taylor expansion: $$\frac{e^t-1}{t} (x)^n$$ Do I just continue like this? Am I doing this whole problem right? I'm just not feeling sure at all!","Problem $$I(x) = \int_{1}^x \frac{e^t - 1}{t}$$ Find $I'( \sqrt{x} )$. Solution We know that $F'(x) = f(x)$ by the fundamental theorem of calculus so $$I'(x) = \frac{e^t -1}{t}$$ And so $$I'( \sqrt{x}) = \frac{ e^{\sqrt{x}} -1 }{ \sqrt{x}}$$ Problem Find the fourth taylor polynomial of $I(x)$ around $0$ (Guess this makes it a Maclaurin series?) Taylor series: $$ \sum_{n=o}^\infty \frac{ f^{(n)} (a) }{n!} (x-a)^n$$ So as we know the first derivative, we can compute the first Taylor expansion: $$\frac{e^t-1}{t} (x)^n$$ Do I just continue like this? Am I doing this whole problem right? I'm just not feeling sure at all!",,"['calculus', 'integration', 'taylor-expansion']"
8,Radius of convergence and the endpoints of a power series,Radius of convergence and the endpoints of a power series,,"Find the radius of convergence and the convergence at the end points of the series: $$\sum_{n=1}^\infty(2+(-1)^n)^nx^n$$ This is what I did: $a_n=(2+(-1)^n)^n\Rightarrow R=\frac{1}{limsup|a_n|^\frac1n}\\  for\ n=2k \to lim(2+1)=3 \\ for\ n= 2k+1 \to lim(2-1)=1 \\ limsup \ a_n^{\frac1n}=3 \Rightarrow R=\frac13$ So the series converge at $(-\frac13 , \frac13)$ But now I don't really understand what I'm being asked for the end points. Am I supposed to check if the series really converge at the two end points ?","Find the radius of convergence and the convergence at the end points of the series: $$\sum_{n=1}^\infty(2+(-1)^n)^nx^n$$ This is what I did: $a_n=(2+(-1)^n)^n\Rightarrow R=\frac{1}{limsup|a_n|^\frac1n}\\  for\ n=2k \to lim(2+1)=3 \\ for\ n= 2k+1 \to lim(2-1)=1 \\ limsup \ a_n^{\frac1n}=3 \Rightarrow R=\frac13$ So the series converge at $(-\frac13 , \frac13)$ But now I don't really understand what I'm being asked for the end points. Am I supposed to check if the series really converge at the two end points ?",,"['calculus', 'sequences-and-series', 'power-series']"
9,Find $\lim_{n\rightarrow \infty}\left(\sqrt{n^2+n+1}-\big\lfloor \sqrt{n^2+n+1} \big\rfloor \right)$,Find,\lim_{n\rightarrow \infty}\left(\sqrt{n^2+n+1}-\big\lfloor \sqrt{n^2+n+1} \big\rfloor \right),"I need to find the limit $$ \displaystyle \lim_{n\rightarrow \infty}\left(\sqrt{n^2+n+1}-\big\lfloor  \sqrt{n^2+n+1} \big\rfloor \right),$$ where $n\in \mathbb{N}$. My attempt . As $\displaystyle \lim_{n\rightarrow \infty} (n^2+n+1)\approx n^2$, then $\displaystyle \lim_{n\rightarrow \infty}\sqrt{n^2+n+1}\approx \displaystyle \lim_{n\rightarrow \infty}\sqrt{n^2} = n$. So $$\displaystyle \lim_{n\rightarrow \infty}\left(\sqrt{n^2+n+1}-n\right) = \displaystyle \lim_{n\rightarrow \infty}\frac{\left(\sqrt{n^2+n+1}-n\right).\left(\sqrt{n^2+n+1}+n\right)}{\left(\sqrt{n^2+n+1}+n\right)}.$$ So $$\displaystyle \lim_{n\rightarrow \infty}\frac{n\cdot\left(1+\frac{1}{n}\right)}{n \left(\sqrt{1+\frac{1}{n}+\frac{1}{n^2}}+1\right)} = \frac{1}{2}.$$ My Question is , Is my Process is Right OR Not ,OR Is there is any error . If Not Then How can I Solve it Help Required Thanks","I need to find the limit $$ \displaystyle \lim_{n\rightarrow \infty}\left(\sqrt{n^2+n+1}-\big\lfloor  \sqrt{n^2+n+1} \big\rfloor \right),$$ where $n\in \mathbb{N}$. My attempt . As $\displaystyle \lim_{n\rightarrow \infty} (n^2+n+1)\approx n^2$, then $\displaystyle \lim_{n\rightarrow \infty}\sqrt{n^2+n+1}\approx \displaystyle \lim_{n\rightarrow \infty}\sqrt{n^2} = n$. So $$\displaystyle \lim_{n\rightarrow \infty}\left(\sqrt{n^2+n+1}-n\right) = \displaystyle \lim_{n\rightarrow \infty}\frac{\left(\sqrt{n^2+n+1}-n\right).\left(\sqrt{n^2+n+1}+n\right)}{\left(\sqrt{n^2+n+1}+n\right)}.$$ So $$\displaystyle \lim_{n\rightarrow \infty}\frac{n\cdot\left(1+\frac{1}{n}\right)}{n \left(\sqrt{1+\frac{1}{n}+\frac{1}{n^2}}+1\right)} = \frac{1}{2}.$$ My Question is , Is my Process is Right OR Not ,OR Is there is any error . If Not Then How can I Solve it Help Required Thanks",,"['calculus', 'sequences-and-series', 'limits', 'radicals', 'ceiling-and-floor-functions']"
10,"Integrate $\int \frac{\ln(\sin x)}{\sin^2 x}\,\mathrm dx.$",Integrate,"\int \frac{\ln(\sin x)}{\sin^2 x}\,\mathrm dx.","I'm having trouble evaluating the integral $$\int \frac{\ln(\sin x)}{\sin^2 x}\,\mathrm dx.$$ I tried $u$-substitution and integration by parts but they didn't work.","I'm having trouble evaluating the integral $$\int \frac{\ln(\sin x)}{\sin^2 x}\,\mathrm dx.$$ I tried $u$-substitution and integration by parts but they didn't work.",,"['calculus', 'integration']"
11,Calc III: Volume of the Intersection of two spheres,Calc III: Volume of the Intersection of two spheres,,"Question: I am not getting the correct answer. How do I get the solution (and why does my solution not work?) Find volume that lies inside both spheres: \begin{align} A: 4	&= (x+2)^2 + (y-1)^2 + (z+2)^2\\ B: 4	&= x^2 + y^2 + z^2\\ \end{align} My solution gives the answer $V \approx 11$, whereas Chegg.com gives the answer $\frac{11}{24}\tau$, where $\tau = 2\pi$. However, I don't like their method because they pull the equation for the volume of the cap of a sphere out of thin-air with no explanation. I was hoping to find a more intuitive answer. The distance between the spheres is $d = \sqrt{2^2 + 1^2 + 2^2} = 3$, so I can replace these spheres with two similar spheres 3 units apart, lying along the $x$-axis. I project the spheres into the $xy$-plane. The line of intersection is $x = 1.5$. Next, I integrate over $x: [1.5 , 2]$ by volume of rotation using the disc method: $ V = \tau \int f(x) \ dx$. This should give the volume of half of the volume inside both spheres. If I double the integral, I should get the entire volume, so: $$V = 2\tau\int_{1.5}^{2} \sqrt{x^2 - 4}\ dx$$ Let: $x=2\sin\theta$. Then: $dx = 2\cos\theta\ d\theta$. $$V =2\tau\int_{\arcsin(3/4)}^{\tau / 4} \sqrt{(2\sin\theta)^2 -4} \cdot2\cos\theta\ d\theta$$ Integrate by factoring out 4 from squareroot, then use the Double-Angle Formula. $$V=4\tau(\theta + \tfrac{1}{2}\sin2\theta)\Big]_{\arcsin(3/4)}^{\tau/4}\approx 11 \neq \frac{11}{24}\tau$$ What did I do wrong?","Question: I am not getting the correct answer. How do I get the solution (and why does my solution not work?) Find volume that lies inside both spheres: \begin{align} A: 4	&= (x+2)^2 + (y-1)^2 + (z+2)^2\\ B: 4	&= x^2 + y^2 + z^2\\ \end{align} My solution gives the answer $V \approx 11$, whereas Chegg.com gives the answer $\frac{11}{24}\tau$, where $\tau = 2\pi$. However, I don't like their method because they pull the equation for the volume of the cap of a sphere out of thin-air with no explanation. I was hoping to find a more intuitive answer. The distance between the spheres is $d = \sqrt{2^2 + 1^2 + 2^2} = 3$, so I can replace these spheres with two similar spheres 3 units apart, lying along the $x$-axis. I project the spheres into the $xy$-plane. The line of intersection is $x = 1.5$. Next, I integrate over $x: [1.5 , 2]$ by volume of rotation using the disc method: $ V = \tau \int f(x) \ dx$. This should give the volume of half of the volume inside both spheres. If I double the integral, I should get the entire volume, so: $$V = 2\tau\int_{1.5}^{2} \sqrt{x^2 - 4}\ dx$$ Let: $x=2\sin\theta$. Then: $dx = 2\cos\theta\ d\theta$. $$V =2\tau\int_{\arcsin(3/4)}^{\tau / 4} \sqrt{(2\sin\theta)^2 -4} \cdot2\cos\theta\ d\theta$$ Integrate by factoring out 4 from squareroot, then use the Double-Angle Formula. $$V=4\tau(\theta + \tfrac{1}{2}\sin2\theta)\Big]_{\arcsin(3/4)}^{\tau/4}\approx 11 \neq \frac{11}{24}\tau$$ What did I do wrong?",,['calculus']
12,"Vector Calculus Proof: $\oint_K \nabla f\cdot \vec n\,ds$ has two possible values",Vector Calculus Proof:  has two possible values,"\oint_K \nabla f\cdot \vec n\,ds","I'm looking over the last chapter in my University Calculus (2nd edition) text by Hass, Weir, and Thomas.  I came across the following problem (not homework), with which I have had some difficulty. Let $K$ be an arbitrary smooth, simple closed curve in the plane that does not pass through $(0, 0)$.  Use Green's Theorem to show that   $$\oint_K \nabla f\cdot \vec n\,ds$$   has two possible values, depending on whether $(0, 0)$ lies inside $K$ or outside $K$. Problem 15.4.39b, page 869 I don't really want to see the whole answer, but I would like some guidance as to what sort of route I should take. Here's what I've done: Let $K$ be an arbitrary smooth, simple closed curve in the plane that does not pass through $(0, 0)$.  Let $D$ be the region bordered by $K$. Let $f(x, y)$ be a function with continuous $2^\text{nd}$ partial derivatives on $D$. (Question: do I need to specify that $f$ has continuous 2nd partial derivatives?  I think so, to fulfill the qualifications on Green's Theorem...) Then:  $$\begin{align} \oint_K \nabla f\cdot \vec n\,ds &= \iint_D \frac{\partial}{\partial x}\left[\frac{\partial f}{\partial x}\right] + \frac{\partial}{\partial y}\left[\frac{\partial f}{\partial y}\right]\, dA \\ &=  \iint_D \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}\, dA \\ \end{align}$$ At this point, I know that the integrand is the right-hand-side of Laplace's equation, but I don't see how that applies.  I also know that this is the divergence of $\nabla f$, but I don't see how that applies, either. Could I have a push/shove in the right direction? :)","I'm looking over the last chapter in my University Calculus (2nd edition) text by Hass, Weir, and Thomas.  I came across the following problem (not homework), with which I have had some difficulty. Let $K$ be an arbitrary smooth, simple closed curve in the plane that does not pass through $(0, 0)$.  Use Green's Theorem to show that   $$\oint_K \nabla f\cdot \vec n\,ds$$   has two possible values, depending on whether $(0, 0)$ lies inside $K$ or outside $K$. Problem 15.4.39b, page 869 I don't really want to see the whole answer, but I would like some guidance as to what sort of route I should take. Here's what I've done: Let $K$ be an arbitrary smooth, simple closed curve in the plane that does not pass through $(0, 0)$.  Let $D$ be the region bordered by $K$. Let $f(x, y)$ be a function with continuous $2^\text{nd}$ partial derivatives on $D$. (Question: do I need to specify that $f$ has continuous 2nd partial derivatives?  I think so, to fulfill the qualifications on Green's Theorem...) Then:  $$\begin{align} \oint_K \nabla f\cdot \vec n\,ds &= \iint_D \frac{\partial}{\partial x}\left[\frac{\partial f}{\partial x}\right] + \frac{\partial}{\partial y}\left[\frac{\partial f}{\partial y}\right]\, dA \\ &=  \iint_D \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}\, dA \\ \end{align}$$ At this point, I know that the integrand is the right-hand-side of Laplace's equation, but I don't see how that applies.  I also know that this is the divergence of $\nabla f$, but I don't see how that applies, either. Could I have a push/shove in the right direction? :)",,"['calculus', 'integration', 'multivariable-calculus']"
13,Find $f^{(1001)}(0)$,Find,f^{(1001)}(0),"I am to find the value in 0 of 1001th derivative of the function $$f(x) = \frac{1}{2+3x^2}$$ How should I approach this kind of problem? I tried something like : $$\frac{1}{2+3x^2} = \frac{1}{2}\cdot\frac{1}{1-(-\frac{3}{2}x^2)}= \frac{1}{2}\sum_{n=0}^{\infty}\left(\frac{3x^2}{2}\right)^n$$ and compare whats next to $x^{1001}$ in this sum and in MacLaurin series but damn, we've got only even powers of x here. How should I do that?","I am to find the value in 0 of 1001th derivative of the function $$f(x) = \frac{1}{2+3x^2}$$ How should I approach this kind of problem? I tried something like : $$\frac{1}{2+3x^2} = \frac{1}{2}\cdot\frac{1}{1-(-\frac{3}{2}x^2)}= \frac{1}{2}\sum_{n=0}^{\infty}\left(\frac{3x^2}{2}\right)^n$$ and compare whats next to $x^{1001}$ in this sum and in MacLaurin series but damn, we've got only even powers of x here. How should I do that?",,"['calculus', 'derivatives', 'taylor-expansion']"
14,"Evaluate : $\int^{\frac{\pi}{2}}_0 \frac{\cos^2x\,dx}{\cos^2x+4\sin^2x}$",Evaluate :,"\int^{\frac{\pi}{2}}_0 \frac{\cos^2x\,dx}{\cos^2x+4\sin^2x}","Evaluate: $$\int^{\frac{\pi}{2}}_0 \frac{\cos^2x\,dx}{\cos^2x+4\sin^2x}$$ First approach : $$\int^{\frac{\pi}{2}}_0 \frac{\cos^2x\,dx}{\cos^2x+4(1-\cos^2x)}$$ $$=\int^{\frac{\pi}{2}}_0 \frac{\cos^2xdx}{4 - 3\cos^2x}$$ $$=\int^{\frac{\pi}{2}}_0 \frac{1}{3}\{\frac{4-3\cos^2x-4}{4 - 3\cos^2x}\}\,dx$$ $$=\int^{\frac{\pi}{2}}_0 \frac{1}{3}\{ 1- \frac{4}{4 - 3\cos^2x}\}\,dx$$ $$=\int^{\frac{\pi}{2}}_0 \frac{1}{3} 1\,dx- \int^{\frac{\pi}{2}}_0 \frac{1}{3} \frac{4\sec^2x}{4\sec^2x - 3}\,dx$$ $$=\int^{\frac{\pi}{2}}_0 \frac{1}{3} 1\,dx- \int^{\frac{\pi}{2}}_0 \frac{1}{3} \frac{4 \sec^2x}{4(1+\tan^2x) - 3}\,dx$$ Now I can easily put $\tan x = t$ and I get $\sec^2x \,dx =dt$ Second approach : $$\int^{\frac{\pi}{2}}_0 \frac{\cos^2x\,dx}{\cos^2x+4\sin^2x}$$ Dividing numerator and denominator by $\cos^2x$ we get : $$=\int^{\frac{\pi}{2}}_0 \frac{dx}{1 +4\tan^2x}$$ $$=\int^{\frac{\pi}{2}}_0 \frac{dx}{(4)\{\frac{1}{4} +\tan^2x\}}$$ $$=\int^{\frac{\pi}{2}}_0 \frac{dx}{(4)\{\{\frac{1}{2}\}^2 +(\tan x)^2\}}$$ Can we apply this formula of integral here : $$\int \frac{1}{a^2+x^2}dx = \frac{1}{a}\tan^{-1}\frac{x}{a}$$ I tried but its not working here, I think doing some manipulation we can implement this here.. Please suggest thanks...","Evaluate: $$\int^{\frac{\pi}{2}}_0 \frac{\cos^2x\,dx}{\cos^2x+4\sin^2x}$$ First approach : $$\int^{\frac{\pi}{2}}_0 \frac{\cos^2x\,dx}{\cos^2x+4(1-\cos^2x)}$$ $$=\int^{\frac{\pi}{2}}_0 \frac{\cos^2xdx}{4 - 3\cos^2x}$$ $$=\int^{\frac{\pi}{2}}_0 \frac{1}{3}\{\frac{4-3\cos^2x-4}{4 - 3\cos^2x}\}\,dx$$ $$=\int^{\frac{\pi}{2}}_0 \frac{1}{3}\{ 1- \frac{4}{4 - 3\cos^2x}\}\,dx$$ $$=\int^{\frac{\pi}{2}}_0 \frac{1}{3} 1\,dx- \int^{\frac{\pi}{2}}_0 \frac{1}{3} \frac{4\sec^2x}{4\sec^2x - 3}\,dx$$ $$=\int^{\frac{\pi}{2}}_0 \frac{1}{3} 1\,dx- \int^{\frac{\pi}{2}}_0 \frac{1}{3} \frac{4 \sec^2x}{4(1+\tan^2x) - 3}\,dx$$ Now I can easily put $\tan x = t$ and I get $\sec^2x \,dx =dt$ Second approach : $$\int^{\frac{\pi}{2}}_0 \frac{\cos^2x\,dx}{\cos^2x+4\sin^2x}$$ Dividing numerator and denominator by $\cos^2x$ we get : $$=\int^{\frac{\pi}{2}}_0 \frac{dx}{1 +4\tan^2x}$$ $$=\int^{\frac{\pi}{2}}_0 \frac{dx}{(4)\{\frac{1}{4} +\tan^2x\}}$$ $$=\int^{\frac{\pi}{2}}_0 \frac{dx}{(4)\{\{\frac{1}{2}\}^2 +(\tan x)^2\}}$$ Can we apply this formula of integral here : $$\int \frac{1}{a^2+x^2}dx = \frac{1}{a}\tan^{-1}\frac{x}{a}$$ I tried but its not working here, I think doing some manipulation we can implement this here.. Please suggest thanks...",,"['calculus', 'integration']"
15,Cancelling differentials,Cancelling differentials,,"I'll start with an example. In physics, $x(t)$ represents the $x$-position of a particle, and $v(t)$ its ($x$-)velocity. To determine the total displacement of a particle on the interval $[a, b]$, we can use the formula $$\Delta x = \int_a^b{v(t)~dt}$$ To me, this makes sense, because $v = \frac {dx}{dt}\\$, so the above equation is equivalent to: $$\Delta x = \int_a^b{v(t)~dt} = \int_a^b{\frac {dx}{dt}~dt} = \int_a^b{dx} = x(b) - x(a) = \Delta x$$ However, I've been told that you can't just ""cancel"" the $dt$ differential because it's not ""proper."" Another example uses parametric arc length: $$\ell = \int_a^b{\sqrt{\left ( \frac {dx}{dt} \right )^2 + \left ( \frac {dy}{dt} \right )^2} dt}$$ Now take a standard function, $y = f(x)$. We can define $x = t$, and then we have $y(t) = f(t)$, $x(t) = t$, and $\frac{dx}{dt} = 1$. Then, $\frac {dy}{dt} = \frac {{dy}~/~{dx}}{{dx}~/~{dt}} = \frac {{dy}~/~{dx}} 1 = \frac {dy}{dx}$, and our formula simplifies to $$\ell = \int_a^b{\sqrt{1 + \left ( \frac {dy}{dx} \right )^2} dt}$$ This is indeed the correct formula for arc length of a function (also derivable with Pythagorean theorem), but it relies on being able to cancel the $dx$s in $\frac {{dy}~/~{dx}}{{dx}~/~{dt}}$. So, my question is, when, if ever, can you cancel differentials?","I'll start with an example. In physics, $x(t)$ represents the $x$-position of a particle, and $v(t)$ its ($x$-)velocity. To determine the total displacement of a particle on the interval $[a, b]$, we can use the formula $$\Delta x = \int_a^b{v(t)~dt}$$ To me, this makes sense, because $v = \frac {dx}{dt}\\$, so the above equation is equivalent to: $$\Delta x = \int_a^b{v(t)~dt} = \int_a^b{\frac {dx}{dt}~dt} = \int_a^b{dx} = x(b) - x(a) = \Delta x$$ However, I've been told that you can't just ""cancel"" the $dt$ differential because it's not ""proper."" Another example uses parametric arc length: $$\ell = \int_a^b{\sqrt{\left ( \frac {dx}{dt} \right )^2 + \left ( \frac {dy}{dt} \right )^2} dt}$$ Now take a standard function, $y = f(x)$. We can define $x = t$, and then we have $y(t) = f(t)$, $x(t) = t$, and $\frac{dx}{dt} = 1$. Then, $\frac {dy}{dt} = \frac {{dy}~/~{dx}}{{dx}~/~{dt}} = \frac {{dy}~/~{dx}} 1 = \frac {dy}{dx}$, and our formula simplifies to $$\ell = \int_a^b{\sqrt{1 + \left ( \frac {dy}{dx} \right )^2} dt}$$ This is indeed the correct formula for arc length of a function (also derivable with Pythagorean theorem), but it relies on being able to cancel the $dx$s in $\frac {{dy}~/~{dx}}{{dx}~/~{dt}}$. So, my question is, when, if ever, can you cancel differentials?",,"['calculus', 'ordinary-differential-equations']"
16,When the polynomial $mx^3-nx^2+5x-1$ is divided by $x+2$ the remainder is $-39$?,When the polynomial  is divided by  the remainder is ?,mx^3-nx^2+5x-1 x+2 -39,When the polynomial $mx^3-nx^2+5x-1$ is divided by $x+2$ the remainder is $-39$. When the polynomial is divided by $x-1$ the remainder is $3$. Find the values of $m$ and $n$. My attempt?: I feel I did something incorrect $$-8m -n -10 - 1 = -39\\ m - n + 5 - 1 = 3$$ Subtract the first equation from the second one. $$-9m -15 = -42\\ 9m = 27\\ m = 3$$ Plug m into one of the equations $$3 - n + 5 - 1 = 3\\ n = 4$$,When the polynomial $mx^3-nx^2+5x-1$ is divided by $x+2$ the remainder is $-39$. When the polynomial is divided by $x-1$ the remainder is $3$. Find the values of $m$ and $n$. My attempt?: I feel I did something incorrect $$-8m -n -10 - 1 = -39\\ m - n + 5 - 1 = 3$$ Subtract the first equation from the second one. $$-9m -15 = -42\\ 9m = 27\\ m = 3$$ Plug m into one of the equations $$3 - n + 5 - 1 = 3\\ n = 4$$,,['calculus']
17,$\frac{\sqrt{1+\sqrt{x}}+\sqrt{1+\sqrt{1-x}}}{\sqrt{1-\sqrt{x}}+\sqrt{1-\sqrt{1-x}}}$,,\frac{\sqrt{1+\sqrt{x}}+\sqrt{1+\sqrt{1-x}}}{\sqrt{1-\sqrt{x}}+\sqrt{1-\sqrt{1-x}}},"Find the value of $\frac{\sqrt{1+\sqrt{x}}+\sqrt{1+\sqrt{1-x}}}{\sqrt{1-\sqrt{x}}+\sqrt{1-\sqrt{1-x}}}$, if $x\in \left(0,\frac{1}{2}\right)$. I know it is equal to $\sqrt{2}+1$, but I don't know how to prove it?","Find the value of $\frac{\sqrt{1+\sqrt{x}}+\sqrt{1+\sqrt{1-x}}}{\sqrt{1-\sqrt{x}}+\sqrt{1-\sqrt{1-x}}}$, if $x\in \left(0,\frac{1}{2}\right)$. I know it is equal to $\sqrt{2}+1$, but I don't know how to prove it?",,['calculus']
18,Trig substitution integral,Trig substitution integral,,"I am trying to find $$\int{ \frac {5x + 1}{x^2 + 4} dx}$$ The best approach would be to split up the fraction. According to Wolfram Alpha , the answer is $\frac{5}{2}\ln\left(x^2 + 4\right) + \frac{1}{2}\displaystyle\arctan\left(\frac x2\right)$ which seems OK, but when I try the trig substitution: $x = 2\tan\theta$, I get an answer that is slightly different but not equivalent, and I've looked at this over and over and I couldn't quite figure out what I did wrong. $$x = 2\tan\theta$$ $$dx = 2\sec^2\theta d\theta$$ $$\int{ \frac {5x + 1}{x^2 + 4}dx} = \frac{1}{4}\int{\frac{10\tan\theta + 1}{\sec^2\theta} 2\sec^2\theta \,d\theta}$$ $$ = \frac{1}{2}\int{10 \tan\theta + 1}\space d\theta$$ $$ = 5 \ln|\sec\theta| + \frac{\theta}{2} + C$$ We know $\theta = \displaystyle\arctan\left(\frac x2\right)$ and since $\tan\theta = \displaystyle\frac{x}{2}$, we can draw a triangle to see that $\sec\theta = \displaystyle\frac{\sqrt{x^2 + 4}}{2}$. $$5 \ln|\sec\theta| + \frac{\theta}{2} = 5\ln\left({\frac{\sqrt{x^2 + 4}}{2}}\right) + \frac{1}{2}\arctan\left({\frac x2}\right) $$ $$= \frac{5}{2}\ln\left({\frac{x^2 + 4}{4}}\right) + \frac{1}{2}\arctan\left({\frac x2}\right)$$ But $$\frac{5}{2}\ln\left({\frac{x^2 + 4}{4}}\right) + \frac{1}{2}\arctan\left({\frac x2}\right) \neq \frac{5}{2}\ln\left(x^2 + 4\right) + \frac{1}{2}\arctan\left(\frac x2\right)$$ There seems to be a small difference between the answer provided by Alpha and the trig substitution method, but I cannot see where I made the mistake.","I am trying to find $$\int{ \frac {5x + 1}{x^2 + 4} dx}$$ The best approach would be to split up the fraction. According to Wolfram Alpha , the answer is $\frac{5}{2}\ln\left(x^2 + 4\right) + \frac{1}{2}\displaystyle\arctan\left(\frac x2\right)$ which seems OK, but when I try the trig substitution: $x = 2\tan\theta$, I get an answer that is slightly different but not equivalent, and I've looked at this over and over and I couldn't quite figure out what I did wrong. $$x = 2\tan\theta$$ $$dx = 2\sec^2\theta d\theta$$ $$\int{ \frac {5x + 1}{x^2 + 4}dx} = \frac{1}{4}\int{\frac{10\tan\theta + 1}{\sec^2\theta} 2\sec^2\theta \,d\theta}$$ $$ = \frac{1}{2}\int{10 \tan\theta + 1}\space d\theta$$ $$ = 5 \ln|\sec\theta| + \frac{\theta}{2} + C$$ We know $\theta = \displaystyle\arctan\left(\frac x2\right)$ and since $\tan\theta = \displaystyle\frac{x}{2}$, we can draw a triangle to see that $\sec\theta = \displaystyle\frac{\sqrt{x^2 + 4}}{2}$. $$5 \ln|\sec\theta| + \frac{\theta}{2} = 5\ln\left({\frac{\sqrt{x^2 + 4}}{2}}\right) + \frac{1}{2}\arctan\left({\frac x2}\right) $$ $$= \frac{5}{2}\ln\left({\frac{x^2 + 4}{4}}\right) + \frac{1}{2}\arctan\left({\frac x2}\right)$$ But $$\frac{5}{2}\ln\left({\frac{x^2 + 4}{4}}\right) + \frac{1}{2}\arctan\left({\frac x2}\right) \neq \frac{5}{2}\ln\left(x^2 + 4\right) + \frac{1}{2}\arctan\left(\frac x2\right)$$ There seems to be a small difference between the answer provided by Alpha and the trig substitution method, but I cannot see where I made the mistake.",,"['calculus', 'integration']"
19,A sum refers to euler's constant,A sum refers to euler's constant,,Show that : $$\sum\limits_{m=1}^{\infty }{\sum\limits_{n={{2}^{m-1}}}^{{{2}^{m}}-1}{\frac{m}{\left( 2n+1 \right)\left( 2n+2 \right)}}}=1-\gamma $$,Show that : $$\sum\limits_{m=1}^{\infty }{\sum\limits_{n={{2}^{m-1}}}^{{{2}^{m}}-1}{\frac{m}{\left( 2n+1 \right)\left( 2n+2 \right)}}}=1-\gamma $$,,"['calculus', 'sequences-and-series', 'integration', 'summation']"
20,How did Newton (or whoever invented the process) come up with the idea that the anti-derivative can be used to calculate the area under a curve?,How did Newton (or whoever invented the process) come up with the idea that the anti-derivative can be used to calculate the area under a curve?,,"I don't know if it has anything directly to do with the fundamental theorem of calculus, but if it does I can't seem to see the connection. Or maybe I just don't understand the theorem. I can understand how the definition of derivative works... you plug in any $f(x)$ and you get out $f\prime(x)$. $$f\prime(x)=\lim_{h\to \infty}\frac{f(x+h)-f(x)}{h}$$ But I can't understand the connection between the limit process of finding the area under a curve and the definite integral. $$\lim_{n\to \infty}\sum_{i=1}^{n}y_{i}\Delta x\ on\ interval\ [a,b]=\int_{a}^{b}f(x)\ dx$$ Why is it that the anti-derivative of a function can serve as a shortcut to solving this problem?","I don't know if it has anything directly to do with the fundamental theorem of calculus, but if it does I can't seem to see the connection. Or maybe I just don't understand the theorem. I can understand how the definition of derivative works... you plug in any $f(x)$ and you get out $f\prime(x)$. $$f\prime(x)=\lim_{h\to \infty}\frac{f(x+h)-f(x)}{h}$$ But I can't understand the connection between the limit process of finding the area under a curve and the definite integral. $$\lim_{n\to \infty}\sum_{i=1}^{n}y_{i}\Delta x\ on\ interval\ [a,b]=\int_{a}^{b}f(x)\ dx$$ Why is it that the anti-derivative of a function can serve as a shortcut to solving this problem?",,"['calculus', 'definite-integrals']"
21,How do I solve this Maclaurin series problem using geometric series?,How do I solve this Maclaurin series problem using geometric series?,,"So, I am given a function $f(x) = -\dfrac{1}{(2+x)^2}$ and I am asked the following: ""Compute the Maclaurin series of $f(x)$. Does the series converge? Hint: Use a geometric series. "" For the Maclaurin series, I did the following:: $f(x) = \sum\limits_{n=0}^\infty \dfrac{f'^{(n)}(0)}{n!}x^n \\ f^{(n)}(0) = -\frac14, \frac{2*1}8, -\frac{3*2*1}{16}, ... \textrm{ for } n = 0, 1, 2, ... \\  f(x) = \sum\limits_{n=0}^\infty \dfrac{(-1)^{n+1}(n+1)!}{2^{n+2}}\dfrac{x^n}{n!} = \sum\limits_{n=0}^\infty \dfrac{(-1)^{n+1}(n+1)}{4 (2^n)}x^n$ To find the values for which the sequence converges, I did the ratio test: $\lim_{n \to \infty} | \dfrac{(-1)^{n+2}(n+2)x^{n+1}}{4(2^{n+1})}\dfrac{4(2^n)}{(-1)^{n+1}(n+1)x^n} | = \\ |\dfrac{x}{2}| \lim_{n \to \infty} | \dfrac{(n+2)}{(n+1)}| = |\dfrac{x}{2}| < 1 \\  \therefore |x| < 2$ As you can see, however, I did not use geometric series anywhere in that solution. How would I use geometric series to solve this problem?","So, I am given a function $f(x) = -\dfrac{1}{(2+x)^2}$ and I am asked the following: ""Compute the Maclaurin series of $f(x)$. Does the series converge? Hint: Use a geometric series. "" For the Maclaurin series, I did the following:: $f(x) = \sum\limits_{n=0}^\infty \dfrac{f'^{(n)}(0)}{n!}x^n \\ f^{(n)}(0) = -\frac14, \frac{2*1}8, -\frac{3*2*1}{16}, ... \textrm{ for } n = 0, 1, 2, ... \\  f(x) = \sum\limits_{n=0}^\infty \dfrac{(-1)^{n+1}(n+1)!}{2^{n+2}}\dfrac{x^n}{n!} = \sum\limits_{n=0}^\infty \dfrac{(-1)^{n+1}(n+1)}{4 (2^n)}x^n$ To find the values for which the sequence converges, I did the ratio test: $\lim_{n \to \infty} | \dfrac{(-1)^{n+2}(n+2)x^{n+1}}{4(2^{n+1})}\dfrac{4(2^n)}{(-1)^{n+1}(n+1)x^n} | = \\ |\dfrac{x}{2}| \lim_{n \to \infty} | \dfrac{(n+2)}{(n+1)}| = |\dfrac{x}{2}| < 1 \\  \therefore |x| < 2$ As you can see, however, I did not use geometric series anywhere in that solution. How would I use geometric series to solve this problem?",,"['calculus', 'sequences-and-series', 'convergence-divergence']"
22,Rotating parametric curve,Rotating parametric curve,,"Given parametric curve: $x=t\cos(t)$, $y=t^2$, how can i rotate the curve about the origin by an angle $\theta=\pi/3$?","Given parametric curve: $x=t\cos(t)$, $y=t^2$, how can i rotate the curve about the origin by an angle $\theta=\pi/3$?",,['calculus']
23,Intuition behind two functions being equal up to order $n$ at $a$,Intuition behind two functions being equal up to order  at,n a,"Two functions $f$, $g: \mathbb R \to \mathbb R$ are said to be equal up to order $n$ at $a$ if and only if $$\lim_{x \to a} \frac{f(x) - g(x)}{(x - a)^n} = 0.$$ What is the intuition behind this definition? What is the idea behind considering two functions to be ""very equal"" versus ""not so equal""? The current picture in my head is this: two functions are ""somewhat equal"" if their graphs ""look like they overlap."" Given $a \in \mathbb R$, two functions are equal up to a ""high order"" if you have to zoom in ""a lot"" at $a$ in order to tell the two graphs apart; they are equal up to a ""low order"" if you can see two distinct graphs even without zooming in at $a$? I don't really know how I got this picture; I think it's somewhat correct, but I can't see how the picture relates to the limit definition.","Two functions $f$, $g: \mathbb R \to \mathbb R$ are said to be equal up to order $n$ at $a$ if and only if $$\lim_{x \to a} \frac{f(x) - g(x)}{(x - a)^n} = 0.$$ What is the intuition behind this definition? What is the idea behind considering two functions to be ""very equal"" versus ""not so equal""? The current picture in my head is this: two functions are ""somewhat equal"" if their graphs ""look like they overlap."" Given $a \in \mathbb R$, two functions are equal up to a ""high order"" if you have to zoom in ""a lot"" at $a$ in order to tell the two graphs apart; they are equal up to a ""low order"" if you can see two distinct graphs even without zooming in at $a$? I don't really know how I got this picture; I think it's somewhat correct, but I can't see how the picture relates to the limit definition.",,"['calculus', 'integration']"
24,Multiplication of Taylor series - expanding $2x\sin(x)$,Multiplication of Taylor series - expanding,2x\sin(x),"I'm working on a problem for university Calculus 2. We're talking about Taylor series right now and I need to approximate an integral using one of a function that I think it should be easy to produce a series for, but I'm not 100% sure. This is the function: $$f(x) = 2x\sin(x)$$ I know the expansion for $\sin(x)$ , which is in a reference table in the book. To give the first few terms it looks like this: $$x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \;\cdots$$ I'm pretty sure I can just multiply the whole polynomial by $2x$ , giving: $$2x^2 - \frac{2x^4}{3!} + \frac{2x^6}{5!} - \frac{2x^8}{7!} + \;\cdots$$ What's odd is that I can't find any examples quite like this in either of the textbooks or on the internet... which makes me wonder if this isn't actually a valid manipulation. Additionally, I can't seem to get an answer that matches this from Wolfram Alpha. I could work out the Taylor series by hand, but the derivatives of the function start getting a bit ugly (by which I mean long), so I think I'm supposed to manipulate a known series since this should be an easy problem. So, am I doing this right or am I on the wrong track?","I'm working on a problem for university Calculus 2. We're talking about Taylor series right now and I need to approximate an integral using one of a function that I think it should be easy to produce a series for, but I'm not 100% sure. This is the function: I know the expansion for , which is in a reference table in the book. To give the first few terms it looks like this: I'm pretty sure I can just multiply the whole polynomial by , giving: What's odd is that I can't find any examples quite like this in either of the textbooks or on the internet... which makes me wonder if this isn't actually a valid manipulation. Additionally, I can't seem to get an answer that matches this from Wolfram Alpha. I could work out the Taylor series by hand, but the derivatives of the function start getting a bit ugly (by which I mean long), so I think I'm supposed to manipulate a known series since this should be an easy problem. So, am I doing this right or am I on the wrong track?",f(x) = 2x\sin(x) \sin(x) x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \;\cdots 2x 2x^2 - \frac{2x^4}{3!} + \frac{2x^6}{5!} - \frac{2x^8}{7!} + \;\cdots,"['calculus', 'taylor-expansion']"
25,Taylor Expansion of Error Function,Taylor Expansion of Error Function,,"I am working on a question that involves finding the Taylor expansion of the error function. The question is stated as follows The error function is defined by $\mathrm{erf}(x):=\frac {2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^{2}}dt$. Find its Taylor expansion. I know that the Taylor series of the function $f$ at $a$ is given by $$f(x)=\sum_{n=0}^{\infty}\frac {f^{(n)}(a)}{n!}(x-a)^{n}.$$ However, the question doesn't give a point $a$ with which to center the Taylor series. How should I interpret this? May I use a Maclaurin series, with $a=0$? This appears to be what was done on the Wikipedia page here: http://en.wikipedia.org/wiki/Error_function Any explanations and advice would be appreciated.","I am working on a question that involves finding the Taylor expansion of the error function. The question is stated as follows The error function is defined by $\mathrm{erf}(x):=\frac {2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^{2}}dt$. Find its Taylor expansion. I know that the Taylor series of the function $f$ at $a$ is given by $$f(x)=\sum_{n=0}^{\infty}\frac {f^{(n)}(a)}{n!}(x-a)^{n}.$$ However, the question doesn't give a point $a$ with which to center the Taylor series. How should I interpret this? May I use a Maclaurin series, with $a=0$? This appears to be what was done on the Wikipedia page here: http://en.wikipedia.org/wiki/Error_function Any explanations and advice would be appreciated.",,"['calculus', 'special-functions', 'taylor-expansion']"
26,Series sum is approximately $b\log n$ implies the terms are approximately $b/n$?,Series sum is approximately  implies the terms are approximately ?,b\log n b/n,"Let's say I have a sequence $a_n \ge 0$ such that I know: $$b \log n - C \le \sum_{i=1}^n a_i \le b \log n + C$$ for some constants $b$ and $C$ larger than 0. How can I prove that: $$a_n = \frac{b}{n} + o(1)\  ?$$ This intuitively seems correct because we know that for the harmonic series we get $\sum_{i=1}^n \frac{1}{i} = \log n + o(1)$, but I am not completely sure how to show the reverse.","Let's say I have a sequence $a_n \ge 0$ such that I know: $$b \log n - C \le \sum_{i=1}^n a_i \le b \log n + C$$ for some constants $b$ and $C$ larger than 0. How can I prove that: $$a_n = \frac{b}{n} + o(1)\  ?$$ This intuitively seems correct because we know that for the harmonic series we get $\sum_{i=1}^n \frac{1}{i} = \log n + o(1)$, but I am not completely sure how to show the reverse.",,['calculus']
27,basic calculus proof - using theorems to prove stuff,basic calculus proof - using theorems to prove stuff,,"A function $f(x)$ is defined and continuous on the interval $[0,2]$ and $f(0)=f(2)$.  Prove that the numbers $x,y$ on $[0,2]$ exist such that $y-x=1$ and $f(x) = f(y)$. I can already guess this is going to involve the intermediate value theorem.  So far I've defined things as such: I'm looking to satisfy the following conditions for values x, y: $f(x) = f(x+1)$ $f(x) = f(y)$ I've defined another function, $g(x)$ such that $g(x) = f(x+1) - f(x)$ If I can show that there exists an $x$ such that $g(x) = 0$ then I've also proven that $f(x) = f(x+1)$. since I'm given the interval [0,2], I can show that: $g(1) = f(2) - f(1)$, $g(0) = f(1) - f(0)$ I'm told that $f(2) = f(0)$ so I can rearrange things to show that $g(1) = f(0) - f(1) = -g(0)$.  Ok, So i've shown that $g(0) = -g(1)$ How do I tie this up? I'm not able to close this proof. I know I need to incorporate the intermediate value theorem which states that if there's a point c in $(a,b)$ then there must be a value $a<k<b$ such that $f(k) = c $ because there's nothing else. I thought maybe to use Rolle's theorem to state that since $f(0) = f(2)$ I know this function isn't monotonic. And if it's not monotonic it must have a ""turning point"" where $f'(x) = 0$ but it's not working out.  Anyway I need help with this proof in particular and perhaps some advice on solving proofs in general since this type of thing takes me hours. Thanks.","A function $f(x)$ is defined and continuous on the interval $[0,2]$ and $f(0)=f(2)$.  Prove that the numbers $x,y$ on $[0,2]$ exist such that $y-x=1$ and $f(x) = f(y)$. I can already guess this is going to involve the intermediate value theorem.  So far I've defined things as such: I'm looking to satisfy the following conditions for values x, y: $f(x) = f(x+1)$ $f(x) = f(y)$ I've defined another function, $g(x)$ such that $g(x) = f(x+1) - f(x)$ If I can show that there exists an $x$ such that $g(x) = 0$ then I've also proven that $f(x) = f(x+1)$. since I'm given the interval [0,2], I can show that: $g(1) = f(2) - f(1)$, $g(0) = f(1) - f(0)$ I'm told that $f(2) = f(0)$ so I can rearrange things to show that $g(1) = f(0) - f(1) = -g(0)$.  Ok, So i've shown that $g(0) = -g(1)$ How do I tie this up? I'm not able to close this proof. I know I need to incorporate the intermediate value theorem which states that if there's a point c in $(a,b)$ then there must be a value $a<k<b$ such that $f(k) = c $ because there's nothing else. I thought maybe to use Rolle's theorem to state that since $f(0) = f(2)$ I know this function isn't monotonic. And if it's not monotonic it must have a ""turning point"" where $f'(x) = 0$ but it's not working out.  Anyway I need help with this proof in particular and perhaps some advice on solving proofs in general since this type of thing takes me hours. Thanks.",,['calculus']
28,Intuition on Mean Value Theorem,Intuition on Mean Value Theorem,,"The following is my opinion, please correct it if I'm wrong or not good explanation: if we get $a, b$, then there must be a constant changing-rate $m$ of $(a, f(a))$ and $(b, f(b))$, if the function go this straight line, then everything point has derivative equal to m, if $f'(x)$ greater or lower than m, then it must be somewhere to lower or greater than m in order to reach the f(b), between them, it meets the m . If we get this 'feeling', then theorem is just natural and obvious : there must exist at least one x for, $f'(x)=\frac{f(b)-f(a)}{b-a}=m$ I realize if I think like this way to get the mathematical feeling behind definitions or theorems, then most of them are just natural , for example, fundamental theorem of calculus, if a function $f(x)$, we consider function value as changing-rate, $$\lim\limits_{n\rightarrow\infty}\left[\sum_{i=1}^{n}f(x_i)(x_{i}-x_{i-1})\right]$$ is just how much the original function-value changes, i.e. $\Delta F(x)=F(b)-F(a)$ But for some other things which always called rules, it seems cannot be understood directly , like the Chain rule, I could prove it by basic definition of derivative, but just cannot 'feel' it as the same way with Mean-Value theorem.","The following is my opinion, please correct it if I'm wrong or not good explanation: if we get $a, b$, then there must be a constant changing-rate $m$ of $(a, f(a))$ and $(b, f(b))$, if the function go this straight line, then everything point has derivative equal to m, if $f'(x)$ greater or lower than m, then it must be somewhere to lower or greater than m in order to reach the f(b), between them, it meets the m . If we get this 'feeling', then theorem is just natural and obvious : there must exist at least one x for, $f'(x)=\frac{f(b)-f(a)}{b-a}=m$ I realize if I think like this way to get the mathematical feeling behind definitions or theorems, then most of them are just natural , for example, fundamental theorem of calculus, if a function $f(x)$, we consider function value as changing-rate, $$\lim\limits_{n\rightarrow\infty}\left[\sum_{i=1}^{n}f(x_i)(x_{i}-x_{i-1})\right]$$ is just how much the original function-value changes, i.e. $\Delta F(x)=F(b)-F(a)$ But for some other things which always called rules, it seems cannot be understood directly , like the Chain rule, I could prove it by basic definition of derivative, but just cannot 'feel' it as the same way with Mean-Value theorem.",,['calculus']
29,find constants using limits,find constants using limits,,"Suppose that we have function $f(x)$ ,which is defined  as follows: $$f(x):= \begin{cases} a+bx &\text{, if } x>2\\ 3 &\text{, if } x=2\\ b-ax^2 &\text{, if } x<2\end{cases}$$ (here $a,b$ are some constants). We  should find $a,b$ so that limit for $x\to 2$ of $f(x)$ exists and equals $3$. I think that, because limit at point $2$ exist, it means that left and right limits are equal,  so  after we evaluate limits on left and right side,  we  will get  $$a+2b=b-4a\mbox{ or }b=-5a.$$ Also because the limit  is equal to  $3$ at point $2$, it means that left or right limit is also equal to $3$, so $a+2b=3$ put one in another, I have got that $a=-1/3$ and $b=5/3$. Am i correct?","Suppose that we have function $f(x)$ ,which is defined  as follows: $$f(x):= \begin{cases} a+bx &\text{, if } x>2\\ 3 &\text{, if } x=2\\ b-ax^2 &\text{, if } x<2\end{cases}$$ (here $a,b$ are some constants). We  should find $a,b$ so that limit for $x\to 2$ of $f(x)$ exists and equals $3$. I think that, because limit at point $2$ exist, it means that left and right limits are equal,  so  after we evaluate limits on left and right side,  we  will get  $$a+2b=b-4a\mbox{ or }b=-5a.$$ Also because the limit  is equal to  $3$ at point $2$, it means that left or right limit is also equal to $3$, so $a+2b=3$ put one in another, I have got that $a=-1/3$ and $b=5/3$. Am i correct?",,"['calculus', 'limits']"
30,Polar to Parametric Equation?,Polar to Parametric Equation?,,"I'm struggling with this problem, I'm still only on part (a). I tried X=rcos(theta) Y=rsin(theta) but I don't think I'm doing it right. Curve C has polar equation r=sin(${\theta}$)+cos(${\theta}$). (a) Write parametric equations for the curve C. $\left\{\begin{matrix} x= \\ y= \end{matrix}\right.$ (b) Find the slope of the tangent line to C at its point where   ${\theta}$ = $\frac{\pi}{2}$. (c) Calculate the length of the arc for 0 $\leq {\theta} \leq {\pi}$  of that   same curve C with polar equation r=sin(${\theta}$)+cos(${\theta}$).","I'm struggling with this problem, I'm still only on part (a). I tried X=rcos(theta) Y=rsin(theta) but I don't think I'm doing it right. Curve C has polar equation r=sin(${\theta}$)+cos(${\theta}$). (a) Write parametric equations for the curve C. $\left\{\begin{matrix} x= \\ y= \end{matrix}\right.$ (b) Find the slope of the tangent line to C at its point where   ${\theta}$ = $\frac{\pi}{2}$. (c) Calculate the length of the arc for 0 $\leq {\theta} \leq {\pi}$  of that   same curve C with polar equation r=sin(${\theta}$)+cos(${\theta}$).",,"['calculus', 'plane-curves', 'polar-coordinates', 'parametric']"
31,Is $f(x) = \sum_{n=-\infty}^\infty \frac{2^n \log x}{1+(2^n \log x)^2}$ for $x \geq 2$ constant?,Is  for  constant?,f(x) = \sum_{n=-\infty}^\infty \frac{2^n \log x}{1+(2^n \log x)^2} x \geq 2,"I want to find a non-constant, continuous function $f: [2, \infty) \rightarrow \mathbb{R}$ which satisfies $f(x) = f(x^2)$ for all $x \in [2, \infty)$. A friend of mine suggested to try something of the form $$f(x) = \sum_{n=-\infty}^\infty \varphi(2^n \log x)$$ and we tried $\varphi(x) = \frac{x}{1+x^2}$. Now my friend plotted the function for $-1000 \leq n \leq 1000$ which gave the following result: Now we let MATLAB compute $f(x)$ for a few $x \in \mathbb{N}$ and observed that $f(x) \approx 2.2662$. As the plot of the function did not imply that the function was constant but periodic (however with a very small amplitude), we computed a few other values, e.g. $x = \pi$, $x = \pi+1$ and we were surprised to see that again $f(x) \approx 2.2662$. For large values, MATLAB was no more capable of computing the result. So I mainly have have two questions: Is this function constant? How can I see this and prove or disprove it? Is there a more trivial example of such a function which is non-constant? Thanks for any answers in advance.","I want to find a non-constant, continuous function $f: [2, \infty) \rightarrow \mathbb{R}$ which satisfies $f(x) = f(x^2)$ for all $x \in [2, \infty)$. A friend of mine suggested to try something of the form $$f(x) = \sum_{n=-\infty}^\infty \varphi(2^n \log x)$$ and we tried $\varphi(x) = \frac{x}{1+x^2}$. Now my friend plotted the function for $-1000 \leq n \leq 1000$ which gave the following result: Now we let MATLAB compute $f(x)$ for a few $x \in \mathbb{N}$ and observed that $f(x) \approx 2.2662$. As the plot of the function did not imply that the function was constant but periodic (however with a very small amplitude), we computed a few other values, e.g. $x = \pi$, $x = \pi+1$ and we were surprised to see that again $f(x) \approx 2.2662$. For large values, MATLAB was no more capable of computing the result. So I mainly have have two questions: Is this function constant? How can I see this and prove or disprove it? Is there a more trivial example of such a function which is non-constant? Thanks for any answers in advance.",,['calculus']
32,How to determine whether or not this series converges?,How to determine whether or not this series converges?,,$$\displaystyle\sum\limits_{n=1}^\infty \dfrac{n^{-1/2}}{2+\sin^2(n)}$$ I tried the divergence test but it approaches 0. It's not a geometric series. Doubt I could apply the integral test. Not a p-series nor an alternating series. Can't use root test. I suppose I am left with either ratio test or a comparison test but I couldn't figure those out. Advice?,$$\displaystyle\sum\limits_{n=1}^\infty \dfrac{n^{-1/2}}{2+\sin^2(n)}$$ I tried the divergence test but it approaches 0. It's not a geometric series. Doubt I could apply the integral test. Not a p-series nor an alternating series. Can't use root test. I suppose I am left with either ratio test or a comparison test but I couldn't figure those out. Advice?,,"['calculus', 'sequences-and-series', 'convergence-divergence']"
33,"evaluating $ \int_0^{\sqrt3} \arcsin(\frac{2t}{1+t^2}) \,dt$",evaluating," \int_0^{\sqrt3} \arcsin(\frac{2t}{1+t^2}) \,dt","$$\begin{align*}  \int \arcsin\left(\frac{2t}{1+t^2}\right)\,dt&=t\arcsin\left(\frac{2t}{1+t^2}\right)+\int\frac{2t}{1+t^2}\,dt\\ &=t\arcsin\left(\frac{2t}{1+t^2}\right) + \ln(1+t^2)+C  \end{align*}$$ So $$ \int\nolimits_0^{\sqrt3} \arcsin\left(\frac{2t}{1+t^2}\right)=\pi/\sqrt3+2\ln2.$$ However the result seems to be $ \pi/\sqrt3 $ only.  Why is there this $ 2\ln2 $? Detail: $$ \begin{align*} t  \arcsin\left(\frac{2t}{1+t^2}\right)&- \int t \left(\frac{2(1-t^2)}{(1+t^2)^2}\right)\frac{1}{\sqrt{1-\frac{4t^2}{(1+t^2)^2}}}\,dt\\ &= t\arcsin\left(\frac{2t}{1+t^2}\right)- \int \frac{2(1-t^2)t}{(1+t^2)\sqrt{(t^2-1)^2}}\,dt\\ &=t\arcsin\left(\frac{2t}{1+t^2}\right)+\int \frac{2t}{1+t^2}\,dt \end{align*} $$","$$\begin{align*}  \int \arcsin\left(\frac{2t}{1+t^2}\right)\,dt&=t\arcsin\left(\frac{2t}{1+t^2}\right)+\int\frac{2t}{1+t^2}\,dt\\ &=t\arcsin\left(\frac{2t}{1+t^2}\right) + \ln(1+t^2)+C  \end{align*}$$ So $$ \int\nolimits_0^{\sqrt3} \arcsin\left(\frac{2t}{1+t^2}\right)=\pi/\sqrt3+2\ln2.$$ However the result seems to be $ \pi/\sqrt3 $ only.  Why is there this $ 2\ln2 $? Detail: $$ \begin{align*} t  \arcsin\left(\frac{2t}{1+t^2}\right)&- \int t \left(\frac{2(1-t^2)}{(1+t^2)^2}\right)\frac{1}{\sqrt{1-\frac{4t^2}{(1+t^2)^2}}}\,dt\\ &= t\arcsin\left(\frac{2t}{1+t^2}\right)- \int \frac{2(1-t^2)t}{(1+t^2)\sqrt{(t^2-1)^2}}\,dt\\ &=t\arcsin\left(\frac{2t}{1+t^2}\right)+\int \frac{2t}{1+t^2}\,dt \end{align*} $$",,"['calculus', 'integration']"
34,Finding asymptotes to $y = \frac{2x^2 + 3x - 6}{2x + 1}$,Finding asymptotes to,y = \frac{2x^2 + 3x - 6}{2x + 1},"I need to find the asymptotes of  $y = \frac{2x^2 + 3x - 6}{2x + 1}$. The asymptote at $x = -1/2$ is clear. If one long divides they can easily see that there is an asymptote of $y = x + 1$ as $x$ goes to infinity. However, what is wrong with this reasoning? I claim that as $x$ goes to infinity, the $2x^2$ term will dominate, so the graph will be on the order of $y = 2x^2$, which has no asymptote. So $y = x + 1$ is not an asymptote.","I need to find the asymptotes of  $y = \frac{2x^2 + 3x - 6}{2x + 1}$. The asymptote at $x = -1/2$ is clear. If one long divides they can easily see that there is an asymptote of $y = x + 1$ as $x$ goes to infinity. However, what is wrong with this reasoning? I claim that as $x$ goes to infinity, the $2x^2$ term will dominate, so the graph will be on the order of $y = 2x^2$, which has no asymptote. So $y = x + 1$ is not an asymptote.",,['calculus']
35,Coordinate-free differentiation techniques in Riemannian geometry,Coordinate-free differentiation techniques in Riemannian geometry,,"I encountered the following identities while reading this article on global calculus (p. 10): $$ d(\|df\|^2)=2\mathop{\iota_{\mathop{\mathrm{grad}} f}} \mathop{\mathrm{Hess}} f, $$ $$ \mathop{\mathrm{grad}}(\|df\|^2)=2\mathop{\nabla_{\mathop{\mathrm{grad}} f}}\mathop{\mathrm{grad}} f $$ Here $\mathop{\mathrm{Hess}} f = \nabla d f$ is the covariant derivative of the 1-form $df$, and the norm $\|\cdot\|$ is given by Riemannian metric: $\|\upsilon\|^2=g(\upsilon,\upsilon)$. I wonder how does one usually derive these identities (without using coordinates)?","I encountered the following identities while reading this article on global calculus (p. 10): $$ d(\|df\|^2)=2\mathop{\iota_{\mathop{\mathrm{grad}} f}} \mathop{\mathrm{Hess}} f, $$ $$ \mathop{\mathrm{grad}}(\|df\|^2)=2\mathop{\nabla_{\mathop{\mathrm{grad}} f}}\mathop{\mathrm{grad}} f $$ Here $\mathop{\mathrm{Hess}} f = \nabla d f$ is the covariant derivative of the 1-form $df$, and the norm $\|\cdot\|$ is given by Riemannian metric: $\|\upsilon\|^2=g(\upsilon,\upsilon)$. I wonder how does one usually derive these identities (without using coordinates)?",,"['calculus', 'riemannian-geometry']"
36,Draw customized (calculus) graphs like these?,Draw customized (calculus) graphs like these?,,"Can you please suggest some good software to draw customized graphs like these? PS:I am studying calculus (engineering degree) and would like to take notes on my pc, including customized graphs, about all the theorems I am learning (bolzano-weierstrass, Rolle, etc...). Hope you can help. Thanks. NB: I am on windows, but can use linux software as well.","Can you please suggest some good software to draw customized graphs like these? PS:I am studying calculus (engineering degree) and would like to take notes on my pc, including customized graphs, about all the theorems I am learning (bolzano-weierstrass, Rolle, etc...). Hope you can help. Thanks. NB: I am on windows, but can use linux software as well.",,"['calculus', 'math-software', 'graphing-functions']"
37,Infinitely differentiable function with compact support,Infinitely differentiable function with compact support,,"I already know that the function $$ f(x) =  \begin{cases} \exp(- \frac{1}{x^2}), \quad  x > 0 \\ 0 , \quad x \leq 0  \end{cases}  $$ is infinitely differentiable throughout $\mathbb R$. The only real problem, of course, lies in showing that $f^{(k)} (0) = 0$ for any positive integer $k$. What I have not been able to deduce is that $$ \phi(x) =  \begin{cases} \exp(- \frac{1}{1 - x^2}), \quad  |x| < 1 \\ 0 , \quad |x| \geq 1  \end{cases}  $$ is also infinitely differentiable throughout $\mathbb R$, using the previous function. The problem now is finding out what happens at $x = 1,-1$. Does the substitution $\zeta ^2 = 1 - x^2$ work, or is there another way to prove this? Thank you all!","I already know that the function $$ f(x) =  \begin{cases} \exp(- \frac{1}{x^2}), \quad  x > 0 \\ 0 , \quad x \leq 0  \end{cases}  $$ is infinitely differentiable throughout $\mathbb R$. The only real problem, of course, lies in showing that $f^{(k)} (0) = 0$ for any positive integer $k$. What I have not been able to deduce is that $$ \phi(x) =  \begin{cases} \exp(- \frac{1}{1 - x^2}), \quad  |x| < 1 \\ 0 , \quad |x| \geq 1  \end{cases}  $$ is also infinitely differentiable throughout $\mathbb R$, using the previous function. The problem now is finding out what happens at $x = 1,-1$. Does the substitution $\zeta ^2 = 1 - x^2$ work, or is there another way to prove this? Thank you all!",,['calculus']
38,Chain rule for multi-variable functions,Chain rule for multi-variable functions,,"So I have been studying the multi-variable chain rule.  Most importantly, and this is what I must have overlooked, is it's not always clear to me how to see which variables are functions of other variables, so that you know when to use the chain rule.  For example, if you have: $$ x^2+y^2-z^2+2xy=1 $$ $$ x^3+y^3-5y=8 $$ In general, say we want to find $\frac{dz}{dt}$ but $z$ is a function of $x$, then we get: $$ \frac{dz}{dt} = \frac{dz}{dx} \frac{dx}{dt} .$$ And if $z$ is a function of both $y$ and $t$, we get: $$ \frac{dz}{dt} = \frac{dz}{dx} \frac{dx}{dt} + \frac{dz}{dy} \frac{dy}{dt}$$ In this case, we have two equations.  One involving all three variables $x,y,z$ and one involving just $x,y$.  Say we want to find $\frac{dz}{dx}$. What does this mean for this case?  How should we interpret this rule in general?","So I have been studying the multi-variable chain rule.  Most importantly, and this is what I must have overlooked, is it's not always clear to me how to see which variables are functions of other variables, so that you know when to use the chain rule.  For example, if you have: $$ x^2+y^2-z^2+2xy=1 $$ $$ x^3+y^3-5y=8 $$ In general, say we want to find $\frac{dz}{dt}$ but $z$ is a function of $x$, then we get: $$ \frac{dz}{dt} = \frac{dz}{dx} \frac{dx}{dt} .$$ And if $z$ is a function of both $y$ and $t$, we get: $$ \frac{dz}{dt} = \frac{dz}{dx} \frac{dx}{dt} + \frac{dz}{dy} \frac{dy}{dt}$$ In this case, we have two equations.  One involving all three variables $x,y,z$ and one involving just $x,y$.  Say we want to find $\frac{dz}{dx}$. What does this mean for this case?  How should we interpret this rule in general?",,"['calculus', 'multivariable-calculus']"
39,"What's With The Integral $\int\sqrt{\cos(2\theta)}\, \mathrm d\theta$?",What's With The Integral ?,"\int\sqrt{\cos(2\theta)}\, \mathrm d\theta","A student randomly asked me to compute $$\int\sqrt{\cos(2\theta)}\, \mathrm d\theta.$$ I was unable to do so, as were several other instructors.  I typed the integral into Wolfram and it says that it is an elliptic integral of type 2.  I am not familiar with elliptic integrals and I don't have any idea why this student asked me to do this since we are not even doing derivatives yet.  Is this integral important?  Does it have a closed form answer?","A student randomly asked me to compute $$\int\sqrt{\cos(2\theta)}\, \mathrm d\theta.$$ I was unable to do so, as were several other instructors.  I typed the integral into Wolfram and it says that it is an elliptic integral of type 2.  I am not familiar with elliptic integrals and I don't have any idea why this student asked me to do this since we are not even doing derivatives yet.  Is this integral important?  Does it have a closed form answer?",,"['calculus', 'integration']"
40,"Ways to tackle the integral $\int_{0}^{\frac{\pi}{4}}\operatorname{Li}_3(\tan^4 x) \, dx$",Ways to tackle the integral,"\int_{0}^{\frac{\pi}{4}}\operatorname{Li}_3(\tan^4 x) \, dx","$$\boxed{J = \int_0^{\frac{\pi}{4}}\operatorname{Li}_3(\tan^4(x)) \, dx}$$ Since I had no clue about trilogarithms, tried some searching to get enough understanding to solve the above integral, I found this general relation; $$\operatorname{Li}_s(z)=\frac{\Gamma(1-s)}{2\pi^{1-s}}\left(i^{1-s}\zeta\left(1-s,\frac{1}{2}+\frac{\ln(-z)}{2\pi i}\right)+i^{s-1}\zeta\left(1-s,\frac{1}{2}-\frac{\ln(-z)}{2\pi i}\right)\right)$$ Also, some general functional equations from here , specifically, $$\operatorname{Li}_3(z)+\operatorname{Li}_3(-z)=\frac{1}{4}\operatorname{Li}_3(z^2)$$ $$\operatorname{Li}_3(z)-\operatorname{Li}_3(-z^{-1})=\frac{-1}{6}\left(\ln^3 z+\pi^2 \ln z\right)$$ Or rewriting the above as; $$\operatorname{Li}_3(z)-\operatorname{Li}_3(-z^{-1})=\frac{-1}{6}\ln^3 z-\zeta(2)\ln z$$ Understanding any other aspects about trilogarithms (or polylogarithm in general) required knowledge was beyond my scope. So I started solving the integral as follows; Using some prior experience in solving some basic dilogarithmic integrals, I substituted $\tan(x)=t$ ; $$J=\int_0^{1}\frac{\operatorname{Li}_3(t^4)}{1+t^2}\,dt$$ $$J=\int_0^{1}\frac{\operatorname{Li}_3(x^4)}{1+x^2}\,dx$$ Using the first functional equation, $$J=\int_0^{1}\frac{4\operatorname{Li}_3(x^2)}{1+x^2}\,dx+\int_0^{1}\frac{4\operatorname{Li}_3(-x^2)}{1+x^2}\,dx=J_1+J_2$$ Edit 1: $$\operatorname{Li}_n(z)=\frac{(-1)^{n-1}}{(n-1)!}\left[\int_0^1\frac{z\ln^{n-1}x}{-zx+1}\,dx\right]$$ Found the above here in the 5th integral representation. Putting $n=3$ , $$J_1=\int_0^{1}\frac{4\operatorname{Li}_3(x^2)}{1+x^2}\,dx=2\int_0^1\int_0^1\frac{1}{(1+x^2)}\frac{x^2\ln^{2}t}{(1-x^2t)}\,dx\,dt$$ Edit 2: $$J_1=2\int_0^1\int_0^1\frac{x^2\ln^{2}t}{(1-x^2t)(1+x^2)}\,dx\,dt$$ $$J_1=\int_0^1\int_0^1\frac{\ln^{2}t}{(1-x^2t)(1+x^2)}\,dx\,dt-\int_0^1\int_0^1\frac{\ln^{2}t}{(1+t)(1+x^2)}\,dx\,dt$$ Could take this further but it seems like I'm missing some identity or formula to move forward. I am interested in understanding how to solve this integral. Edit 3: The answer is $$\boxed{J=\frac{1}{8}\left(\zeta\left(4,\frac{1}{4}\right)-\zeta\left(4,\frac{3}{4}\right)\right)-\pi \left(\frac{2\pi G}{3}+\frac{27\zeta(3)}{4}\right)}$$ $G$ is Catalan's constant.","Since I had no clue about trilogarithms, tried some searching to get enough understanding to solve the above integral, I found this general relation; Also, some general functional equations from here , specifically, Or rewriting the above as; Understanding any other aspects about trilogarithms (or polylogarithm in general) required knowledge was beyond my scope. So I started solving the integral as follows; Using some prior experience in solving some basic dilogarithmic integrals, I substituted ; Using the first functional equation, Edit 1: Found the above here in the 5th integral representation. Putting , Edit 2: Could take this further but it seems like I'm missing some identity or formula to move forward. I am interested in understanding how to solve this integral. Edit 3: The answer is is Catalan's constant.","\boxed{J = \int_0^{\frac{\pi}{4}}\operatorname{Li}_3(\tan^4(x)) \, dx} \operatorname{Li}_s(z)=\frac{\Gamma(1-s)}{2\pi^{1-s}}\left(i^{1-s}\zeta\left(1-s,\frac{1}{2}+\frac{\ln(-z)}{2\pi i}\right)+i^{s-1}\zeta\left(1-s,\frac{1}{2}-\frac{\ln(-z)}{2\pi i}\right)\right) \operatorname{Li}_3(z)+\operatorname{Li}_3(-z)=\frac{1}{4}\operatorname{Li}_3(z^2) \operatorname{Li}_3(z)-\operatorname{Li}_3(-z^{-1})=\frac{-1}{6}\left(\ln^3 z+\pi^2 \ln z\right) \operatorname{Li}_3(z)-\operatorname{Li}_3(-z^{-1})=\frac{-1}{6}\ln^3 z-\zeta(2)\ln z \tan(x)=t J=\int_0^{1}\frac{\operatorname{Li}_3(t^4)}{1+t^2}\,dt J=\int_0^{1}\frac{\operatorname{Li}_3(x^4)}{1+x^2}\,dx J=\int_0^{1}\frac{4\operatorname{Li}_3(x^2)}{1+x^2}\,dx+\int_0^{1}\frac{4\operatorname{Li}_3(-x^2)}{1+x^2}\,dx=J_1+J_2 \operatorname{Li}_n(z)=\frac{(-1)^{n-1}}{(n-1)!}\left[\int_0^1\frac{z\ln^{n-1}x}{-zx+1}\,dx\right] n=3 J_1=\int_0^{1}\frac{4\operatorname{Li}_3(x^2)}{1+x^2}\,dx=2\int_0^1\int_0^1\frac{1}{(1+x^2)}\frac{x^2\ln^{2}t}{(1-x^2t)}\,dx\,dt J_1=2\int_0^1\int_0^1\frac{x^2\ln^{2}t}{(1-x^2t)(1+x^2)}\,dx\,dt J_1=\int_0^1\int_0^1\frac{\ln^{2}t}{(1-x^2t)(1+x^2)}\,dx\,dt-\int_0^1\int_0^1\frac{\ln^{2}t}{(1+t)(1+x^2)}\,dx\,dt \boxed{J=\frac{1}{8}\left(\zeta\left(4,\frac{1}{4}\right)-\zeta\left(4,\frac{3}{4}\right)\right)-\pi \left(\frac{2\pi G}{3}+\frac{27\zeta(3)}{4}\right)} G","['calculus', 'integration', 'definite-integrals', 'contest-math', 'special-functions']"
41,Generalising $I_n=\int_0^1 \arcsin(\sqrt{1-x^n})\mathrm dx$.,Generalising .,I_n=\int_0^1 \arcsin(\sqrt{1-x^n})\mathrm dx,"Consider the integrals of the form $$I_n=\int_0^1 \arcsin(\sqrt{1-x^n})\mathrm dx$$ With the help of calculators , I noticed: $$I_{3}=\frac{3\Gamma{\left(\frac{11}{6}\right)}}{5\Gamma{\left(\frac{4}{3}\right)}}\sqrt{π}$$ $$I_{5}=\frac{5\Gamma{\left(\frac{17}{10}\right)}}{7\Gamma{\left(\frac{6}{5}\right)}}\sqrt{π}$$ $$I_{7}=\frac{7\Gamma{\left(\frac{23}{14}\right)}}{9\Gamma{\left(\frac{8}{7}\right)}}\sqrt{π}$$ $$I_{13}=\frac{13\Gamma{\left(\frac{41}{26}\right)}}{15\Gamma{\left(\frac{14}{13}\right)}}\sqrt{π}$$ So , based on the pattern, I thought that if $n$ is a positive integer greater than $3$ , then : $$I_{n}=\frac{n\Gamma{\left(\frac{3n+2}{2n}\right)}}{(n+2)\Gamma{\left(\frac{n+1}{n}\right)}}\sqrt{π}$$ Question: How can we prove the above generalisation ? Can we extend it for even larger set of numbers ?","Consider the integrals of the form With the help of calculators , I noticed: So , based on the pattern, I thought that if is a positive integer greater than , then : Question: How can we prove the above generalisation ? Can we extend it for even larger set of numbers ?",I_n=\int_0^1 \arcsin(\sqrt{1-x^n})\mathrm dx I_{3}=\frac{3\Gamma{\left(\frac{11}{6}\right)}}{5\Gamma{\left(\frac{4}{3}\right)}}\sqrt{π} I_{5}=\frac{5\Gamma{\left(\frac{17}{10}\right)}}{7\Gamma{\left(\frac{6}{5}\right)}}\sqrt{π} I_{7}=\frac{7\Gamma{\left(\frac{23}{14}\right)}}{9\Gamma{\left(\frac{8}{7}\right)}}\sqrt{π} I_{13}=\frac{13\Gamma{\left(\frac{41}{26}\right)}}{15\Gamma{\left(\frac{14}{13}\right)}}\sqrt{π} n 3 I_{n}=\frac{n\Gamma{\left(\frac{3n+2}{2n}\right)}}{(n+2)\Gamma{\left(\frac{n+1}{n}\right)}}\sqrt{π},"['calculus', 'integration', 'definite-integrals', 'gamma-function']"
42,"A novice substitution in differentiation, why is it wrong?","A novice substitution in differentiation, why is it wrong?",,"Edit: It is given that $f$ is continuously differentiable. One of my colleague's student wrote this: Let $x=2-h,$ $$\lim_{h\to0}\frac{f(2+3h)-f(2-h)}{h}=4\lim_{h\to0}\frac{f(x+4h)-f(x)}{4h}=4f'(2)$$ We feel repelled to accept the latter equality, but aren't sure why, other than that we've always used the more common method of making up extra terms $-f(2)+f(2)$ in the nominator. I've tried to find an example where the student's treatment of two related variables in a single limit would lead to an error, but nothing can seem to go wrong. What would you say as a teacher of calculus?","Edit: It is given that is continuously differentiable. One of my colleague's student wrote this: Let We feel repelled to accept the latter equality, but aren't sure why, other than that we've always used the more common method of making up extra terms in the nominator. I've tried to find an example where the student's treatment of two related variables in a single limit would lead to an error, but nothing can seem to go wrong. What would you say as a teacher of calculus?","f x=2-h, \lim_{h\to0}\frac{f(2+3h)-f(2-h)}{h}=4\lim_{h\to0}\frac{f(x+4h)-f(x)}{4h}=4f'(2) -f(2)+f(2)","['calculus', 'limits', 'analysis', 'derivatives', 'continuity']"
43,Show that $(1+x)^{1+x} \ge 1 + x + x^2 + \frac{x^3}{2}$ for $x \ge -1$,Show that  for,(1+x)^{1+x} \ge 1 + x + x^2 + \frac{x^3}{2} x \ge -1,"Show that for every $x\ge -1$ we have the inequality $$(1+x)^{1+x} \ge 1 + x + x^2  + \frac{x^3}{2}$$ with equality only if $x = 0$ . Notes: One of Bernoulli's inequalities  : $(1+x)^a \ge 1 + a x$ if $x\ge -1$ and $a\ge 1$ , so $(1+x)^{1+x}\ge 1 + x + x^2$ for $x \ge 0$ . We can further improve it as follows $(1+x)^{1+x} \ge 1 + x + x^2 + \frac{x^3}{2} + \frac{x^4}{3} + \frac{x^5}{12} $ for $x \ge -1$ . One could look at the Taylor expansion of $(1+x)^{1+x}= \exp( (1+x) \log (1+x))$ Any feedback would be appreciated!","Show that for every we have the inequality with equality only if . Notes: One of Bernoulli's inequalities  : if and , so for . We can further improve it as follows for . One could look at the Taylor expansion of Any feedback would be appreciated!",x\ge -1 (1+x)^{1+x} \ge 1 + x + x^2  + \frac{x^3}{2} x = 0 (1+x)^a \ge 1 + a x x\ge -1 a\ge 1 (1+x)^{1+x}\ge 1 + x + x^2 x \ge 0 (1+x)^{1+x} \ge 1 + x + x^2 + \frac{x^3}{2} + \frac{x^4}{3} + \frac{x^5}{12}  x \ge -1 (1+x)^{1+x}= \exp( (1+x) \log (1+x)),"['calculus', 'inequality', 'taylor-expansion', 'exponential-function']"
44,Integral $\int_0^\infty\frac{\cos(\pi x^2)}{\cosh (\pi x)(\cosh (4\pi)-\cos(4\pi x))}dx$,Integral,\int_0^\infty\frac{\cos(\pi x^2)}{\cosh (\pi x)(\cosh (4\pi)-\cos(4\pi x))}dx,"I encountered the integral $$ \int_0^\infty\frac{\cos(\pi x^2)}{\cosh (\pi x)(\cosh (4\pi)-\cos(4\pi x))}dx=\frac{1}{\sinh (4\pi)}\left(\frac{\coth(\pi)}{\sqrt{2}}-\frac{1+\sqrt{2}}{16\,\pi\sqrt{\pi }}\Gamma^2\left(\frac{1}{4}\right)\right) $$ The value is checked in high precision via CAS. Some posts on the site considered integrals of similar forms, e.g. Does $\int_{0}^{\infty}{\sin{(\pi{x^2})}\over \sinh{(\pi{x}})\tanh(x\pi)}\mathrm{d}x$ have a simple closed from? tough integral involving $\sin(x^2)$ and $\sinh^2 (x)$ integral $\int_{0}^{\infty}\frac{\cos(\pi x^{2})}{1+2\cosh(\frac{2\pi}{\sqrt{3}}x)}dx=\frac{\sqrt{2}-\sqrt{6}+2}{8}$ I thought of integrating on contours similar to those above, so I tried functions like $$ \frac{e^{i \pi  z^2}}{\cosh (\pi  z) (1-e^{i\pi z})} $$ and integrated them on rectangular contours. However, all attempts failed. I was more convinced that contour integration cannot directly find the answer because of the $\Gamma^2\left(\dfrac{1}{4}\right)$ term. That made me think that the integral somehow relates to elliptic functions. After all my effort, I could not work out the result on my own. How can we evaluate the integral? Maybe some really clever contour integration, or applying special functions formulas? Any help would be appreciated.","I encountered the integral The value is checked in high precision via CAS. Some posts on the site considered integrals of similar forms, e.g. Does $\int_{0}^{\infty}{\sin{(\pi{x^2})}\over \sinh{(\pi{x}})\tanh(x\pi)}\mathrm{d}x$ have a simple closed from? tough integral involving $\sin(x^2)$ and $\sinh^2 (x)$ integral $\int_{0}^{\infty}\frac{\cos(\pi x^{2})}{1+2\cosh(\frac{2\pi}{\sqrt{3}}x)}dx=\frac{\sqrt{2}-\sqrt{6}+2}{8}$ I thought of integrating on contours similar to those above, so I tried functions like and integrated them on rectangular contours. However, all attempts failed. I was more convinced that contour integration cannot directly find the answer because of the term. That made me think that the integral somehow relates to elliptic functions. After all my effort, I could not work out the result on my own. How can we evaluate the integral? Maybe some really clever contour integration, or applying special functions formulas? Any help would be appreciated.","
\int_0^\infty\frac{\cos(\pi x^2)}{\cosh (\pi x)(\cosh (4\pi)-\cos(4\pi x))}dx=\frac{1}{\sinh (4\pi)}\left(\frac{\coth(\pi)}{\sqrt{2}}-\frac{1+\sqrt{2}}{16\,\pi\sqrt{\pi }}\Gamma^2\left(\frac{1}{4}\right)\right)
 
\frac{e^{i \pi  z^2}}{\cosh (\pi  z) (1-e^{i\pi z})}
 \Gamma^2\left(\dfrac{1}{4}\right)","['calculus', 'integration', 'definite-integrals', 'contour-integration']"
45,Can $\frac{1}{1-x^2}$ be integrated by parts?,Can  be integrated by parts?,\frac{1}{1-x^2},"I was watching a video of a professor who said that $\int \frac{1}{1-x^2} dx$ can be done using the method of integration by parts. Though he skipped the solution and simply gave the answer, I tried solving it myself but I'm having difficulty moving forward. What I did was: Let $u = \frac{1}{1-x^2}, du = \frac{2x}{(1-x^2)^2} dx , dv = dx, v=x$ . Then, $$\int \frac{dx}{1-x^2} = \frac{x}{1-x^2} - \int \frac{2x^2}{(1-x^2)^2} dx$$ However, the new integral seems problematic. I tried doing the method again but the equation just ends up to be $0=0$ . Is integration by parts not a viable way of solving this integral? P.S.: I already know the answer using a different method (partial fraction decomposition). I just want to know how to solve the integral in a different way.","I was watching a video of a professor who said that can be done using the method of integration by parts. Though he skipped the solution and simply gave the answer, I tried solving it myself but I'm having difficulty moving forward. What I did was: Let . Then, However, the new integral seems problematic. I tried doing the method again but the equation just ends up to be . Is integration by parts not a viable way of solving this integral? P.S.: I already know the answer using a different method (partial fraction decomposition). I just want to know how to solve the integral in a different way.","\int \frac{1}{1-x^2} dx u = \frac{1}{1-x^2}, du = \frac{2x}{(1-x^2)^2} dx , dv = dx, v=x \int \frac{dx}{1-x^2} = \frac{x}{1-x^2} - \int \frac{2x^2}{(1-x^2)^2} dx 0=0","['calculus', 'integration', 'indefinite-integrals']"
46,How do I evaluate the following limit?,How do I evaluate the following limit?,,"I understand that I need to somehow use that $PR=AP=AQ$ as the point $A \to P$ . But beyond that, I am unable to use that information to find $OB$ . This problem is from the textbook ""Calculus with analytic geometry"" by G. Simmons. The problem is the $27$ th problem in section $12.2$ where the L'Hospitals rule is introduced.","I understand that I need to somehow use that as the point . But beyond that, I am unable to use that information to find . This problem is from the textbook ""Calculus with analytic geometry"" by G. Simmons. The problem is the th problem in section where the L'Hospitals rule is introduced.",PR=AP=AQ A \to P OB 27 12.2,"['calculus', 'limits', 'analytic-geometry', 'circles']"
47,"The ""average"" in average rate of change comes from sum of instantaneous rate of change divided by number of rates of change?","The ""average"" in average rate of change comes from sum of instantaneous rate of change divided by number of rates of change?",,"To show what I mean here is a graph of $y = x^2$ . The red line represents AROC from $a$ to $b$ . The blue lines represent the IROC at some points $x$ , where $a<x<b$ If I were to calculate the gradients of those blue lines, add them up and divide by the number of lines I used, would I get the average rate of change? If this is true; is this why the ""average"" exists in average rate of change?","To show what I mean here is a graph of . The red line represents AROC from to . The blue lines represent the IROC at some points , where If I were to calculate the gradients of those blue lines, add them up and divide by the number of lines I used, would I get the average rate of change? If this is true; is this why the ""average"" exists in average rate of change?",y = x^2 a b x a<x<b,"['calculus', 'algebra-precalculus', 'functions']"
48,General Rule for Differentiation of Tetrations,General Rule for Differentiation of Tetrations,,"I'll start at the beginning. Initially, this sort of began as just what is $\frac{d}{dx}$ [ $x^x$ ] the answer being $x^x$ +ln(x) $x^x$ . This wasn't difficult to achieve, just some chain rule and product rule. I then took $\frac{d}{dx}$ [ $x^{x^x}$ ], this took some more chain and product rule but one should end up with an answer of ( $x^{x^x}$$x^x$$)\frac{1}{x}$ + $x^{x^x}$$x^x$ ln $(x)$ + $x^{x^x}$$x^x$ ln $^2(x)$ . Evidently, I now could just take the $\frac{d}{dx}$ [ $x^{x^{x^x}}$ ], but I saw the pattern with the other derivatives and thought that there might be a general formula or rule for the derivatives of tetration. After a search online, and on the exchange, it led to no nothing. So I decided to differentiate the 4th tetration of x, which is $x^{x^{x^x}}$ . For future reference the 4 tetration of x, I'll call $x^{x|4}$ . Additionally, I'll call $x^{x^{x^x}}$ * $x^{x^x}$ -> $x^{x|4,3}$ just to make my life easier typing this. The $\frac{d}{dx}$ [ $x^{x|4}$ ], is equal to ( $x^{x|4,3}$ + $x^{x|4,2}$ ln $(x)$ ) $\frac{1}{x}$ + $x^{x|4,2}$ *ln $^2(x)$ + $x^{x|4,2}$ *ln $^3(x)$ From here I noticed a pattern, to where I could accurately predict the $\frac{d}{dx}$ [ $x^{x|n}$ ] (The derivative of the nth tetration of x) The general pattern is: $\frac{d}{dx}$ [ $x^{x|2}$ ] = $x^{x|2}$ + $x^{x|2}$ ln $(x)$ $\frac{d}{dx}$ [ $x^{x|3}$ ] = $\frac{x^{x|3,2}}{x}$ + $x^{x|3,2}$ ln $(x)$ + $x^{x|3,2}$ ln $^2(x)$ $\frac{d}{dx}$ [ $x^{x|4}$ ] = $\frac{x^{x|4,3}}{x}$ + $\frac{x^{x|4,2}ln(x)}{x}$ + $x^{x|4,2}ln^2(x)$ + $x^{x|4,2}$ ln $^3(x)$ Some rules of the pattern are as follows: All terms except for the last two will be over x. The maxima, which is the highest tetration, will always be the number of tetrations in the original tetration that is being differentiated. The minima, the lowest tetration, will be the maxima-1 then count down to 2, where it will remain until the addition ends. The exponent on the logarithm starts at zero and counts up until it reaches the maxima-1. Note: Maxima and minima aren’t accepted terms so use your own as you wish. For example: The first segment of the $\frac{d}{dx}$ [ $x^{x|4}$ ]. $\frac{x^{x|4,3}}{x}$ notice how it is over x, the maxima is 4, the minima is 4-1, and there is no logarithm because ln $^0(x)$ =1. Then one would add, $\frac{x^{x|4,2}ln(x)}{x}$ this segment is also over x and has a maxima of 4 and a minima of one less than the previous. Additionally, this segment has an ln $(x)$ , this is because ln $^1(x)$ = ln $(1)$ , no surprises. This pattern continues bound by these rules, so now the $\frac{d}{dx}$ [ $x^{x|10}$ ]. However, I wasn’t satisfied with this answer; because I wanted a general formula. I had my friend, who’s a lot better at math than me, assist me in finding a general formula. He eventually devised $\frac{d}{dx}[x^{x|n}]$ : $$\sum_{k=0}^{n-2}\frac{x^{x|n,n-k}ln^{k-1}(x)}{x}+x^{x|2}ln^{n-2}+x^{x|2}ln^{n-1}, (n\ge2)$$ We've gone through the mathematical rigor, and so far this formula has seemed to uphold. The main reason I’m writing this is that I have a few questions about this formula and the general idea of there being a general formula. Can this formula be disproved? Is there a nicer-looking formula? Is there a formula with proper notation, not my made-up one? Can a formula be made so that n is a fraction or even a complex number?","I'll start at the beginning. Initially, this sort of began as just what is [ ] the answer being +ln(x) . This wasn't difficult to achieve, just some chain rule and product rule. I then took [ ], this took some more chain and product rule but one should end up with an answer of ( + ln + ln . Evidently, I now could just take the [ ], but I saw the pattern with the other derivatives and thought that there might be a general formula or rule for the derivatives of tetration. After a search online, and on the exchange, it led to no nothing. So I decided to differentiate the 4th tetration of x, which is . For future reference the 4 tetration of x, I'll call . Additionally, I'll call * -> just to make my life easier typing this. The [ ], is equal to ( + ln ) + *ln + *ln From here I noticed a pattern, to where I could accurately predict the [ ] (The derivative of the nth tetration of x) The general pattern is: [ ] = + ln [ ] = + ln + ln [ ] = + + + ln Some rules of the pattern are as follows: All terms except for the last two will be over x. The maxima, which is the highest tetration, will always be the number of tetrations in the original tetration that is being differentiated. The minima, the lowest tetration, will be the maxima-1 then count down to 2, where it will remain until the addition ends. The exponent on the logarithm starts at zero and counts up until it reaches the maxima-1. Note: Maxima and minima aren’t accepted terms so use your own as you wish. For example: The first segment of the [ ]. notice how it is over x, the maxima is 4, the minima is 4-1, and there is no logarithm because ln =1. Then one would add, this segment is also over x and has a maxima of 4 and a minima of one less than the previous. Additionally, this segment has an ln , this is because ln = ln , no surprises. This pattern continues bound by these rules, so now the [ ]. However, I wasn’t satisfied with this answer; because I wanted a general formula. I had my friend, who’s a lot better at math than me, assist me in finding a general formula. He eventually devised : We've gone through the mathematical rigor, and so far this formula has seemed to uphold. The main reason I’m writing this is that I have a few questions about this formula and the general idea of there being a general formula. Can this formula be disproved? Is there a nicer-looking formula? Is there a formula with proper notation, not my made-up one? Can a formula be made so that n is a fraction or even a complex number?","\frac{d}{dx} x^x x^x x^x \frac{d}{dx} x^{x^x} x^{x^x}x^x)\frac{1}{x} x^{x^x}x^x (x) x^{x^x}x^x ^2(x) \frac{d}{dx} x^{x^{x^x}} x^{x^{x^x}} x^{x|4} x^{x^{x^x}} x^{x^x} x^{x|4,3} \frac{d}{dx} x^{x|4} x^{x|4,3} x^{x|4,2} (x) \frac{1}{x} x^{x|4,2} ^2(x) x^{x|4,2} ^3(x) \frac{d}{dx} x^{x|n} \frac{d}{dx} x^{x|2} x^{x|2} x^{x|2} (x) \frac{d}{dx} x^{x|3} \frac{x^{x|3,2}}{x} x^{x|3,2} (x) x^{x|3,2} ^2(x) \frac{d}{dx} x^{x|4} \frac{x^{x|4,3}}{x} \frac{x^{x|4,2}ln(x)}{x} x^{x|4,2}ln^2(x) x^{x|4,2} ^3(x) \frac{d}{dx} x^{x|4} \frac{x^{x|4,3}}{x} ^0(x) \frac{x^{x|4,2}ln(x)}{x} (x) ^1(x) (1) \frac{d}{dx} x^{x|10} \frac{d}{dx}[x^{x|n}] \sum_{k=0}^{n-2}\frac{x^{x|n,n-k}ln^{k-1}(x)}{x}+x^{x|2}ln^{n-2}+x^{x|2}ln^{n-1}, (n\ge2)","['calculus', 'sequences-and-series', 'tetration']"
49,Mean of an Exponential Distribution whose rate parameter is also exponentially distributed,Mean of an Exponential Distribution whose rate parameter is also exponentially distributed,,"Suppose I have a random variable $X$ with an exponential distribution with rate parameter $\lambda$ . Suppose also that I don’t know the value of $\lambda$ but that it will be drawn from another exponential distribution with rate parameter $K$ . I’m trying to figure out what my expected value for $X$ is in terms of $K$ . The integral as I understand it seems to be $\int \frac{Ke^{-Kx}}{x}$ Playing around it seems as though setting $K = 1$ gives $X$ a mean of the Exponential Integral function $\mathrm{Ei}(0)$ (please correct me if this is wrong), but I’m not familiar enough with this function to understand how changing $K$ affects this output In particular, setting $K = 2$ seems to yield $\int \frac{2e^{-2x}}{x} = 4\int \frac{e^{-2x}}{2x} = 4 \mathrm{Ei}(0)$ Which intuitively seems wrong as increasing the rate parameter should decrease the mean. Clearly I’m doing something very stupid here but would appreciate pointers! Thanks","Suppose I have a random variable with an exponential distribution with rate parameter . Suppose also that I don’t know the value of but that it will be drawn from another exponential distribution with rate parameter . I’m trying to figure out what my expected value for is in terms of . The integral as I understand it seems to be Playing around it seems as though setting gives a mean of the Exponential Integral function (please correct me if this is wrong), but I’m not familiar enough with this function to understand how changing affects this output In particular, setting seems to yield Which intuitively seems wrong as increasing the rate parameter should decrease the mean. Clearly I’m doing something very stupid here but would appreciate pointers! Thanks",X \lambda \lambda K X K \int \frac{Ke^{-Kx}}{x} K = 1 X \mathrm{Ei}(0) K K = 2 \int \frac{2e^{-2x}}{x} = 4\int \frac{e^{-2x}}{2x} = 4 \mathrm{Ei}(0),"['calculus', 'random-variables', 'exponential-function', 'expected-value', 'exponential-distribution']"
50,Show that the full Euler-Lagrange equation of the Brachistochrone is $2y(x)y''(x)+y'(x)^2+1=0$,Show that the full Euler-Lagrange equation of the Brachistochrone is,2y(x)y''(x)+y'(x)^2+1=0,"This question I have is related to this previous question I asked regarding the Brachistochrone problem, so here are some background details from the previous link: If a point-like mass is rolling down a hill from a point $A$ to a point $B$ , the time it takes the mass to get from $A$ to $B$ depends on the profile of the hill. The Brachistochrone Curve is the profile that minimizes the time and we can find this profile using a Lagrangian extremization procedure. You can easily convince yourself that one can always find profiles which would make the time taken arbitrarily long, so if one finds a finite curve that extremizes the time taken, that curve should necessarily be a minimum. Before jumping to the core of this problem, let us first look at the ‘cycloid’ curve, which can be thought of as the curve a fixed point on a circle of radius $R$ draws as the circle ‘rolls’ along a straight line (see left of Fig. 4). With $\theta$ as the angle parameterizing the circle’s rotation, the coordinates on the curve are $$x=R(\theta-\sin\theta)\quad\text{and}\quad y=R(1-\cos\theta)$$ The derivatives along that curve are $x'(\theta) = R(1-\cos\theta)$ and $y'(\theta)=R \sin\theta$ and bearing in mind that $\cos\theta=1-y/R$ , ie $x'(\theta)=y$ , we have $$\left(x'(y)\right)^{-1}=y'(x)=\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{y'(\theta)}{x'(\theta)}=\sqrt\frac{2R-y}{y}\tag{1}$$ Start of new question: Instead of parameterizing the trajectory as a function $x(y)$ we could have decided to parameterize the trajectory as a function $y(x)$ . Show that finding the trajectory $y(x)$ that leads to the quickest descent between the origin and the point B can also be formulated as a Lagrangian problem. Determine the relevant action, Lagrangian and coordinates. What are the resulting equations of motions. The author's solution (shown directly below) makes no attempt to derive the equation in the title (which is what I am trying to show): We have $$T=\int dt=\int\sqrt{\frac{\mathrm{d}x^2+\mathrm{d}y^2}{2gy(x)}}=\int_0^{x_B}\sqrt{\frac{y'(x)^2+1}{2gy(x)}}\mathrm{d}x$$ Now we can see the total time $T$ as a functional of the path $y(x)$ chosen to connect both points with fixed boundary conditions, the problem therefore reduces to one of Lagrangian mechanics where $T[y(x)]$ plays the role of the action, $L = \sqrt{\frac{y'(x)^2+1}{2gy(x)}}$ plays the role of the Lagrangian. In this language, the generalized coordinate is $y$ which is a function of $x$ (so $x$ plays the role of the ‘time’ $t$ is the standard Lagrangian formulation. The Euler Lagrange equations are $$\frac{\partial L}{\partial y(x)}-\frac{\mathrm{d}}{\mathrm{d}x}\frac{\partial L}{\partial y'(x)}=0\tag{A}$$ In the previous formulation, the Lagrangian did not depend on the coordinate itself (only on its derivative). This is no longer the case here as we see that this new Lagrangian depends both on $y(x)$ and $y' (x)$ . Note however that the Lagrangian does not depend explicitly on $x$ so the Hamiltonian is conserved in this formulation. Unsurprisingly, the number of conserved quantities s the same in both formulation. The full Euler-Lagrange equation is $$2y(x)y''(x)+y'(x)^2+1=0\tag{B}$$ I am trying to reach eqn $(\mathrm{B})$ . So starting with the leftmost term of $(\mathrm{A})$ : $$\begin{align}\frac{\partial L}{\partial y(x)}&=\frac{\partial}{\partial y(x)}\left({\frac{y'(x)^2+1}{2gy(x)}}\right)^{1/2}\\&=\sqrt{\frac{y'(x)^2+1}{2g}}\frac{\partial}{\partial y(x)}\left(y(x)^{-1/2}\right)\\&=-\frac12y(x)^{-3/2}\sqrt{\frac{y'(x)^2+1}{2g}}\end{align}$$ Now moving on the right hand term of $(\mathrm{A})$ : $$\begin{align}\frac{\partial L}{\partial y'(x)}&=\frac{\partial}{\partial y'(x)}\left({\frac{y'(x)^2+1}{2gy(x)}}\right)^{1/2}\\&=\frac{1}{2}\times 2y'(x)\left(y'(x)^2+1\right)^{-1/2}\times \frac{1}{\sqrt{2gy(x)}}\\&=\frac{y'(x)}{\sqrt{2gy(x)}\sqrt{1+y'(x)^2}}\end{align}$$ and so $$\begin{align}-\frac{\mathrm{d}}{\mathrm{d}x}\frac{\partial L}{\partial y'(x)}&=-\frac{1}{\sqrt{2g}}\frac{\mathrm{d}}{\mathrm{d}x}\left(y'(x)\left(y(x)\left[1+y'(x)^2\right]\right)^{-1/2}\right)\\&=-\frac{1}{\sqrt{2g}}\left(y''(x)\left(y(x)\left[1+y'(x)^2\right]\right)^{-1/2}-\frac12y'(x)^{-3/2}y'(x)\left[1+y'(x)^2\right]^{-1/2}-\frac12\times 2y''(x)y'(x)y(x)^{-1/2}\left[1+y'(x)^2\right]^{-3/2}\right)\\&=-\frac{1}{\sqrt{2g}}\left(y''(x)\left(y(x)\left[1+y'(x)^2\right]\right)^{-1/2}-\frac12y'(x)^{-1/2}\left[1+y'(x)^2\right]^{-1/2}-y''(x)y'(x)y(x)^{-1/2}\left[1+y'(x)^2\right]^{-3/2}\right)\tag{C}\end{align}$$ Now putting it all together eqn $(\mathrm{A})$ implies $$\frac{\partial L}{\partial y(x)}-\frac{\mathrm{d}}{\mathrm{d}x}\frac{\partial L}{\partial y'(x)}=0$$ $$\implies-\frac12y(x)^{-3/2}\sqrt{\frac{y'(x)^2+1}{2g}}+\frac{1}{\sqrt{2g}}\left(y''(x)\left(y(x)\left[1+y'(x)^2\right]\right)^{-1/2}-\frac12y'(x)^{-1/2}\left[1+y'(x)^2\right]^{-1/2}-y''(x)y'(x)y(x)^{-1/2}\left[1+y'(x)^2\right]^{-3/2}\right)=0$$ I know this can be simplified a little, but I'm getting the impression that I have made a mistake or used the wrong approach (by using the triple product rule) to get $(\mathrm{C})$ for the $-\frac{\mathrm{d}}{\mathrm{d}x}\frac{\partial L}{\partial y'(x)}$ part of $(\mathrm{A})$ . Any hints or tips that will lead me closer to $2y(x)y''(x)+y'(x)^2+1=0\tag{B}$ please?","This question I have is related to this previous question I asked regarding the Brachistochrone problem, so here are some background details from the previous link: If a point-like mass is rolling down a hill from a point to a point , the time it takes the mass to get from to depends on the profile of the hill. The Brachistochrone Curve is the profile that minimizes the time and we can find this profile using a Lagrangian extremization procedure. You can easily convince yourself that one can always find profiles which would make the time taken arbitrarily long, so if one finds a finite curve that extremizes the time taken, that curve should necessarily be a minimum. Before jumping to the core of this problem, let us first look at the ‘cycloid’ curve, which can be thought of as the curve a fixed point on a circle of radius draws as the circle ‘rolls’ along a straight line (see left of Fig. 4). With as the angle parameterizing the circle’s rotation, the coordinates on the curve are The derivatives along that curve are and and bearing in mind that , ie , we have Start of new question: Instead of parameterizing the trajectory as a function we could have decided to parameterize the trajectory as a function . Show that finding the trajectory that leads to the quickest descent between the origin and the point B can also be formulated as a Lagrangian problem. Determine the relevant action, Lagrangian and coordinates. What are the resulting equations of motions. The author's solution (shown directly below) makes no attempt to derive the equation in the title (which is what I am trying to show): We have Now we can see the total time as a functional of the path chosen to connect both points with fixed boundary conditions, the problem therefore reduces to one of Lagrangian mechanics where plays the role of the action, plays the role of the Lagrangian. In this language, the generalized coordinate is which is a function of (so plays the role of the ‘time’ is the standard Lagrangian formulation. The Euler Lagrange equations are In the previous formulation, the Lagrangian did not depend on the coordinate itself (only on its derivative). This is no longer the case here as we see that this new Lagrangian depends both on and . Note however that the Lagrangian does not depend explicitly on so the Hamiltonian is conserved in this formulation. Unsurprisingly, the number of conserved quantities s the same in both formulation. The full Euler-Lagrange equation is I am trying to reach eqn . So starting with the leftmost term of : Now moving on the right hand term of : and so Now putting it all together eqn implies I know this can be simplified a little, but I'm getting the impression that I have made a mistake or used the wrong approach (by using the triple product rule) to get for the part of . Any hints or tips that will lead me closer to please?",A B A B R \theta x=R(\theta-\sin\theta)\quad\text{and}\quad y=R(1-\cos\theta) x'(\theta) = R(1-\cos\theta) y'(\theta)=R \sin\theta \cos\theta=1-y/R x'(\theta)=y \left(x'(y)\right)^{-1}=y'(x)=\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{y'(\theta)}{x'(\theta)}=\sqrt\frac{2R-y}{y}\tag{1} x(y) y(x) y(x) T=\int dt=\int\sqrt{\frac{\mathrm{d}x^2+\mathrm{d}y^2}{2gy(x)}}=\int_0^{x_B}\sqrt{\frac{y'(x)^2+1}{2gy(x)}}\mathrm{d}x T y(x) T[y(x)] L = \sqrt{\frac{y'(x)^2+1}{2gy(x)}} y x x t \frac{\partial L}{\partial y(x)}-\frac{\mathrm{d}}{\mathrm{d}x}\frac{\partial L}{\partial y'(x)}=0\tag{A} y(x) y' (x) x 2y(x)y''(x)+y'(x)^2+1=0\tag{B} (\mathrm{B}) (\mathrm{A}) \begin{align}\frac{\partial L}{\partial y(x)}&=\frac{\partial}{\partial y(x)}\left({\frac{y'(x)^2+1}{2gy(x)}}\right)^{1/2}\\&=\sqrt{\frac{y'(x)^2+1}{2g}}\frac{\partial}{\partial y(x)}\left(y(x)^{-1/2}\right)\\&=-\frac12y(x)^{-3/2}\sqrt{\frac{y'(x)^2+1}{2g}}\end{align} (\mathrm{A}) \begin{align}\frac{\partial L}{\partial y'(x)}&=\frac{\partial}{\partial y'(x)}\left({\frac{y'(x)^2+1}{2gy(x)}}\right)^{1/2}\\&=\frac{1}{2}\times 2y'(x)\left(y'(x)^2+1\right)^{-1/2}\times \frac{1}{\sqrt{2gy(x)}}\\&=\frac{y'(x)}{\sqrt{2gy(x)}\sqrt{1+y'(x)^2}}\end{align} \begin{align}-\frac{\mathrm{d}}{\mathrm{d}x}\frac{\partial L}{\partial y'(x)}&=-\frac{1}{\sqrt{2g}}\frac{\mathrm{d}}{\mathrm{d}x}\left(y'(x)\left(y(x)\left[1+y'(x)^2\right]\right)^{-1/2}\right)\\&=-\frac{1}{\sqrt{2g}}\left(y''(x)\left(y(x)\left[1+y'(x)^2\right]\right)^{-1/2}-\frac12y'(x)^{-3/2}y'(x)\left[1+y'(x)^2\right]^{-1/2}-\frac12\times 2y''(x)y'(x)y(x)^{-1/2}\left[1+y'(x)^2\right]^{-3/2}\right)\\&=-\frac{1}{\sqrt{2g}}\left(y''(x)\left(y(x)\left[1+y'(x)^2\right]\right)^{-1/2}-\frac12y'(x)^{-1/2}\left[1+y'(x)^2\right]^{-1/2}-y''(x)y'(x)y(x)^{-1/2}\left[1+y'(x)^2\right]^{-3/2}\right)\tag{C}\end{align} (\mathrm{A}) \frac{\partial L}{\partial y(x)}-\frac{\mathrm{d}}{\mathrm{d}x}\frac{\partial L}{\partial y'(x)}=0 \implies-\frac12y(x)^{-3/2}\sqrt{\frac{y'(x)^2+1}{2g}}+\frac{1}{\sqrt{2g}}\left(y''(x)\left(y(x)\left[1+y'(x)^2\right]\right)^{-1/2}-\frac12y'(x)^{-1/2}\left[1+y'(x)^2\right]^{-1/2}-y''(x)y'(x)y(x)^{-1/2}\left[1+y'(x)^2\right]^{-3/2}\right)=0 (\mathrm{C}) -\frac{\mathrm{d}}{\mathrm{d}x}\frac{\partial L}{\partial y'(x)} (\mathrm{A}) 2y(x)y''(x)+y'(x)^2+1=0\tag{B},"['calculus', 'multivariable-calculus', 'calculus-of-variations', 'euler-lagrange-equation']"
51,Mistake computing $\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(x)}-\frac{a}{e^{2x}} \right)\frac{dx}{x}$,Mistake computing,\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(x)}-\frac{a}{e^{2x}} \right)\frac{dx}{x},"I am looking to evaluate the integral $$\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(x)}-\frac{a}{e^{2x}} \right)\frac{dx}{x}=\ln\left(\frac{\pi}{\Gamma^2\left(\frac{1+a}{2b}\right)\cos\left(\frac{a\pi}{2}\right)}\right)$$ To this end I considered $$I(w)=\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(bx)}-\frac{ad}{e^{cx}} \right)\frac{e^{-wx}}{x}\,dx \tag{1}$$ Note that as $w \to \infty$ the integrand vanishes. And as $w =0$ we recover the desired integral. Differentiating $(1)$ w.r. to $w$ we obtain $$ \begin{aligned} I^\prime(w)&=-\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(bx)}-\frac{ad}{e^{cx}} \right)e^{-wx}\,dx\\ &=ad\int_0^\infty e^{-(c+w)x}\,dx- \int_0^\infty \frac{\sinh(ax)}{\sinh(bx)}e^{-wx}\,dx\\ &=\frac{ad}{c+w}-\int_0^\infty \frac{e^{ax}-e^{-ax}}{e^{bx}-e^{-bx}}e^{-wx}\,dx\\ &=\frac{ad}{c+w}-\int_0^\infty \frac{e^{-(w-a)x}-e^{-(w+a)x}}{e^{bx}-e^{-bx}}\,dx\\ &=\frac{ad}{c+w}-\int_0^\infty \frac{e^{-bx}}{e^{-bx}}\cdot\frac{e^{-(w-a)x}-e^{-(w+a)x}}{e^{bx}-e^{-bx}}\,dx\\ &=\frac{ad}{c+w}-\int_0^\infty \frac{e^{-(w-a+b)x}-e^{-(w+a+b)x}}{1-e^{-2bx}}\,dx\\ &=\frac{ad}{c+w}-\frac{1}{2b}\int_0^\infty \frac{e^{-\frac{(w-a+b)}{2b}x}-e^{-\frac{(w+a+b)}{2b}x}}{1-e^{-x}}\,dx \qquad (2bx \to x)\\ &=\frac{ad}{c+w}-\frac{1}{2b}\int_0^1 \frac{x^{\frac{(w-a+b)}{2b}-1}-x^{\frac{(w+a+b)}{2b}-1}}{1-x}\,dx \qquad (e^{-x} \to x)\\ &=\frac{ad}{c+w}-\frac{1}{2b}\left(\psi\left(\frac{w+a+b}{2b}\right)-\psi\left(\frac{w-a+b}{2b}\right)\right)\\ I(w)&=ad\int\frac{1}{c+w}\,dw-\frac{1}{2b}\left(\int\psi\left(\frac{w+a+b}{2b}\right)\,dw-\int\psi\left(\frac{w-a+b}{2b}\right)\,dw\right)\\ &=ad\ln(c+w)-\left(\ln\left(\Gamma\left(\frac{w+a+b}{2b}\right)\right)\,-\ln\left(\Gamma\left(\frac{w-a+b}{2b}\right)\right)\right)\\ &=ad\ln(c+w)+\ln\left(\frac{\Gamma\left(\frac{w-a+b}{2b}\right)}{\Gamma\left(\frac{w+a+b}{2b}\right)}\right)\\ \end{aligned} $$ Now,our integral is equal to $$I=-\int_0^\infty I^\prime(w)\,dw=I(0)$$ Letting $w=0$ $$\begin{aligned} \int_0^\infty \left(\frac{\sinh(ax)}{\sinh(bx)}-\frac{ad}{e^{cx}} \right)\frac{dx}{x}&=\ln\left(\frac{c^{ad}\Gamma\left(\frac12-\frac{a}{2b}\right)}{\Gamma\left(\frac12+\frac{a}{2b}\right)}\right)\\ &=\ln\left(\frac{c^{ad}\Gamma\left(\frac12-\frac{a}{2b}\right)\Gamma\left(\frac12+\frac{a}{2b}\right)}{\Gamma\left(\frac12+\frac{a}{2b}\right)\Gamma\left(\frac12+\frac{a}{2b}\right)}\right)\\ &=\ln\left(\frac{c^{ad}\pi}{\Gamma^2\left(\frac12+\frac{a}{2b}\right)\cos\left(\frac{a\pi}{2b}\right)}\right) \qquad \blacksquare\\ \end{aligned}$$ setting $b=1$ , $c=2$ and $d=1$ I obtained $$\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(x)}-\frac{a}{e^{2x}} \right)\frac{dx}{x}=\ln\left(\frac{2^{a}\pi}{\Gamma^2\left(\frac{1+a}{2b}\right)\cos\left(\frac{a\pi}{2}\right)}\right)$$ Which has an extra term leading to an incorrect answer. Can someone please point out where I am mistaking?","I am looking to evaluate the integral To this end I considered Note that as the integrand vanishes. And as we recover the desired integral. Differentiating w.r. to we obtain Now,our integral is equal to Letting setting , and I obtained Which has an extra term leading to an incorrect answer. Can someone please point out where I am mistaking?","\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(x)}-\frac{a}{e^{2x}} \right)\frac{dx}{x}=\ln\left(\frac{\pi}{\Gamma^2\left(\frac{1+a}{2b}\right)\cos\left(\frac{a\pi}{2}\right)}\right) I(w)=\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(bx)}-\frac{ad}{e^{cx}} \right)\frac{e^{-wx}}{x}\,dx \tag{1} w \to \infty w =0 (1) w 
\begin{aligned}
I^\prime(w)&=-\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(bx)}-\frac{ad}{e^{cx}} \right)e^{-wx}\,dx\\
&=ad\int_0^\infty e^{-(c+w)x}\,dx- \int_0^\infty \frac{\sinh(ax)}{\sinh(bx)}e^{-wx}\,dx\\
&=\frac{ad}{c+w}-\int_0^\infty \frac{e^{ax}-e^{-ax}}{e^{bx}-e^{-bx}}e^{-wx}\,dx\\
&=\frac{ad}{c+w}-\int_0^\infty \frac{e^{-(w-a)x}-e^{-(w+a)x}}{e^{bx}-e^{-bx}}\,dx\\
&=\frac{ad}{c+w}-\int_0^\infty \frac{e^{-bx}}{e^{-bx}}\cdot\frac{e^{-(w-a)x}-e^{-(w+a)x}}{e^{bx}-e^{-bx}}\,dx\\
&=\frac{ad}{c+w}-\int_0^\infty \frac{e^{-(w-a+b)x}-e^{-(w+a+b)x}}{1-e^{-2bx}}\,dx\\
&=\frac{ad}{c+w}-\frac{1}{2b}\int_0^\infty \frac{e^{-\frac{(w-a+b)}{2b}x}-e^{-\frac{(w+a+b)}{2b}x}}{1-e^{-x}}\,dx \qquad (2bx \to x)\\
&=\frac{ad}{c+w}-\frac{1}{2b}\int_0^1 \frac{x^{\frac{(w-a+b)}{2b}-1}-x^{\frac{(w+a+b)}{2b}-1}}{1-x}\,dx \qquad (e^{-x} \to x)\\
&=\frac{ad}{c+w}-\frac{1}{2b}\left(\psi\left(\frac{w+a+b}{2b}\right)-\psi\left(\frac{w-a+b}{2b}\right)\right)\\
I(w)&=ad\int\frac{1}{c+w}\,dw-\frac{1}{2b}\left(\int\psi\left(\frac{w+a+b}{2b}\right)\,dw-\int\psi\left(\frac{w-a+b}{2b}\right)\,dw\right)\\
&=ad\ln(c+w)-\left(\ln\left(\Gamma\left(\frac{w+a+b}{2b}\right)\right)\,-\ln\left(\Gamma\left(\frac{w-a+b}{2b}\right)\right)\right)\\
&=ad\ln(c+w)+\ln\left(\frac{\Gamma\left(\frac{w-a+b}{2b}\right)}{\Gamma\left(\frac{w+a+b}{2b}\right)}\right)\\
\end{aligned}
 I=-\int_0^\infty I^\prime(w)\,dw=I(0) w=0 \begin{aligned}
\int_0^\infty \left(\frac{\sinh(ax)}{\sinh(bx)}-\frac{ad}{e^{cx}} \right)\frac{dx}{x}&=\ln\left(\frac{c^{ad}\Gamma\left(\frac12-\frac{a}{2b}\right)}{\Gamma\left(\frac12+\frac{a}{2b}\right)}\right)\\
&=\ln\left(\frac{c^{ad}\Gamma\left(\frac12-\frac{a}{2b}\right)\Gamma\left(\frac12+\frac{a}{2b}\right)}{\Gamma\left(\frac12+\frac{a}{2b}\right)\Gamma\left(\frac12+\frac{a}{2b}\right)}\right)\\
&=\ln\left(\frac{c^{ad}\pi}{\Gamma^2\left(\frac12+\frac{a}{2b}\right)\cos\left(\frac{a\pi}{2b}\right)}\right) \qquad \blacksquare\\
\end{aligned} b=1 c=2 d=1 \int_0^\infty \left(\frac{\sinh(ax)}{\sinh(x)}-\frac{a}{e^{2x}} \right)\frac{dx}{x}=\ln\left(\frac{2^{a}\pi}{\Gamma^2\left(\frac{1+a}{2b}\right)\cos\left(\frac{a\pi}{2}\right)}\right)","['calculus', 'integration', 'gamma-function']"
52,Evaluate $\lim_{x\to\infty}\left(\frac{x^2}{2x+1}\right)^{\frac1x}$,Evaluate,\lim_{x\to\infty}\left(\frac{x^2}{2x+1}\right)^{\frac1x},"How do you evaluate the following limit? $$ \lim_{x\to\infty}\left(\frac{x^2}{2x+1}\right)^{\frac1x} $$ I tried to make it approach the shape of the euler limit $$ \lim_{x\to\infty}\left(1+\frac{1}{f(x)}\right)^{f(x)} $$ I added and subtracted 1, so that we get ""1 + a function"", I inverted this function, making 1 / (1 / f (x)). then to the exponent I multiplied and divided by the function, in order to obtain a limit like that of euler, raised to another function but I realized that it was not the solution, because f (x) did not go to infinity when x went to infinity. Then I gave up and asked here.","How do you evaluate the following limit? I tried to make it approach the shape of the euler limit I added and subtracted 1, so that we get ""1 + a function"", I inverted this function, making 1 / (1 / f (x)). then to the exponent I multiplied and divided by the function, in order to obtain a limit like that of euler, raised to another function but I realized that it was not the solution, because f (x) did not go to infinity when x went to infinity. Then I gave up and asked here.","
\lim_{x\to\infty}\left(\frac{x^2}{2x+1}\right)^{\frac1x}
 
\lim_{x\to\infty}\left(1+\frac{1}{f(x)}\right)^{f(x)}
","['calculus', 'limits', 'limits-without-lhopital']"
53,Difference of $f:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ and as $f: \mathbb{C} \rightarrow \mathbb{C}$.,Difference of  and as .,f:\mathbb{R}^2 \rightarrow \mathbb{R}^2 f: \mathbb{C} \rightarrow \mathbb{C},"I want to know the difference of differentation as $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ and $f: \mathbb{C} \rightarrow \mathbb{C}$ . What are their differences, $f$ as two real variables, or $f$ as differentiation as a complex function? This question arose when I took the youtube lectures by ""Richard E. BORCHERDS"" on complex analysis. First treatment of real analysis : In multivariable calculus, when we set $f(x,y)$ its total derivatives is written as \begin{align} df =f_x dx + f_y dy  \end{align} where $f_x, f_y$ are partial derivatives with respect to $x,y$ Formally, we say that a function $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ is differentiable at $a \in \mathbb{R}^2$ if it exists a continuous linear map $\nabla f(a) : \mathbb{R}^2 \rightarrow \mathbb{R}^2$ such that \begin{align} \lim_{h \rightarrow 0} \frac{f(a+h) - f(a) - \nabla f(a) \cdot h}{\|h\|} =0 \end{align} so when we consider multivariable calculus, we have to see whether the multivariable function have a partial derivatives(or directional derivatives) and then see the above limit holds[In the calculus, we learn that a function having a partial derivatives but not differentiable, i.e., $f(x,y) = \frac{xy}{\sqrt{x^2+y^2}}$ at $(x,y) \neq (0,0)$ but $0$ at $(x,y)=(0,0)$ . ] In the complex analysis, we treat $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ or $f: \mathbb{C} \rightarrow \mathbb{C}$ and define complex derivatives analogus to real derivatives and obtain Cauchy Riemann equation. For example $w=u+iv$ , \begin{align}   \begin{pmatrix}     u(x,y) \\     v(x,y)   \end{pmatrix} = \begin{pmatrix}     u(x_0, y_0) \\     v(x_0, y_0)   \end{pmatrix} + \begin{pmatrix}      \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\      \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y}   \end{pmatrix} \begin{pmatrix}     x-x_0 \\     y-y_0   \end{pmatrix} + \epsilon \end{align} and doing $w$ as \begin{align} w=w_0 + A (z-z_0) + \epsilon, \quad A \in \mathbb{C} \end{align} [This is Borcherds treatment of differentiation as a linear approximation. Like real case he treats $w$ as $\mathbb{C}$ and does the linear approximation on $\mathbb{C}$ ] then identifying the component of $A$ he obtain Cauchy Riemann equation. In complex cases, I feel Borcherds treat the differentiation as $x,y$ and $z$ equally, but in general case those two approaches are different am I? For example, when dealing with complex analysis, differentiable at some open region (analytic) implies $C^{\infty}$ but I know in multi-variable calculus this does may not happen. What are their differences, $f$ as two real variables, or $f$ as differentiation as a complex function?","I want to know the difference of differentation as and . What are their differences, as two real variables, or as differentiation as a complex function? This question arose when I took the youtube lectures by ""Richard E. BORCHERDS"" on complex analysis. First treatment of real analysis : In multivariable calculus, when we set its total derivatives is written as where are partial derivatives with respect to Formally, we say that a function is differentiable at if it exists a continuous linear map such that so when we consider multivariable calculus, we have to see whether the multivariable function have a partial derivatives(or directional derivatives) and then see the above limit holds[In the calculus, we learn that a function having a partial derivatives but not differentiable, i.e., at but at . ] In the complex analysis, we treat or and define complex derivatives analogus to real derivatives and obtain Cauchy Riemann equation. For example , and doing as [This is Borcherds treatment of differentiation as a linear approximation. Like real case he treats as and does the linear approximation on ] then identifying the component of he obtain Cauchy Riemann equation. In complex cases, I feel Borcherds treat the differentiation as and equally, but in general case those two approaches are different am I? For example, when dealing with complex analysis, differentiable at some open region (analytic) implies but I know in multi-variable calculus this does may not happen. What are their differences, as two real variables, or as differentiation as a complex function?","f: \mathbb{R}^2 \rightarrow \mathbb{R}^2 f: \mathbb{C} \rightarrow \mathbb{C} f f f(x,y) \begin{align}
df =f_x dx + f_y dy 
\end{align} f_x, f_y x,y f: \mathbb{R}^2 \rightarrow \mathbb{R}^2 a \in \mathbb{R}^2 \nabla f(a) : \mathbb{R}^2 \rightarrow \mathbb{R}^2 \begin{align}
\lim_{h \rightarrow 0} \frac{f(a+h) - f(a) - \nabla f(a) \cdot h}{\|h\|} =0
\end{align} f(x,y) = \frac{xy}{\sqrt{x^2+y^2}} (x,y) \neq (0,0) 0 (x,y)=(0,0) f: \mathbb{R}^2 \rightarrow \mathbb{R}^2 f: \mathbb{C} \rightarrow \mathbb{C} w=u+iv \begin{align}
  \begin{pmatrix}
    u(x,y) \\
    v(x,y)
  \end{pmatrix} = \begin{pmatrix}
    u(x_0, y_0) \\
    v(x_0, y_0)
  \end{pmatrix} + \begin{pmatrix}
     \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\
     \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y}
  \end{pmatrix} \begin{pmatrix}
    x-x_0 \\
    y-y_0
  \end{pmatrix} + \epsilon
\end{align} w \begin{align}
w=w_0 + A (z-z_0) + \epsilon, \quad A \in \mathbb{C}
\end{align} w \mathbb{C} \mathbb{C} A x,y z C^{\infty} f f","['calculus', 'complex-analysis', 'multivariable-calculus', 'derivatives']"
54,Prove that $ t_{n}=1+\frac{\ln (2 n)}{2 n}+o\left(\frac{1}{n}\right) $ as $n$ tends to infinity.,Prove that  as  tends to infinity., t_{n}=1+\frac{\ln (2 n)}{2 n}+o\left(\frac{1}{n}\right)  n,"For all $n \geqslant 1$ , we define $$ f_{n}(t):=t^{2 n}-2 n t+1 $$ (i) Prove that there exists a unique solution of $f_{n}(t)=0$ in $[1,+\infty)$ . This solution will be denoted by $t_{n}$ . (ii) Prove that $\lim _{n \rightarrow+\infty} t_{n}=1$ . (iii) Prove that $$ t_{n}=1+\frac{\ln (2 n)}{2 n}+o\left(\frac{1}{n}\right) $$ as $n$ tends to infinity. For the question (I) Since $\lim_{t\to 1^{+}} f_n(t)=-2n<0$ And $\lim_{t\to +\infty}f_n(t)=+\infty<0$ By intermediate value theorem there exist $t_n \in[1, +\infty)$ which $f_n(t_n)=0$ For other question, I think for a lot but I can’t do it. please kindly give me a hint or something that I can do this. THANK in advance !","For all , we define (i) Prove that there exists a unique solution of in . This solution will be denoted by . (ii) Prove that . (iii) Prove that as tends to infinity. For the question (I) Since And By intermediate value theorem there exist which For other question, I think for a lot but I can’t do it. please kindly give me a hint or something that I can do this. THANK in advance !","n \geqslant 1 
f_{n}(t):=t^{2 n}-2 n t+1
 f_{n}(t)=0 [1,+\infty) t_{n} \lim _{n \rightarrow+\infty} t_{n}=1 
t_{n}=1+\frac{\ln (2 n)}{2 n}+o\left(\frac{1}{n}\right)
 n \lim_{t\to 1^{+}} f_n(t)=-2n<0 \lim_{t\to +\infty}f_n(t)=+\infty<0 t_n \in[1, +\infty) f_n(t_n)=0","['calculus', 'polynomials', 'taylor-expansion']"
55,"Indefinite integration of $\int\frac{1}{\cos(x-1)\cos(x-2)\cos(x-3)}\,\textrm dx$",Indefinite integration of,"\int\frac{1}{\cos(x-1)\cos(x-2)\cos(x-3)}\,\textrm dx","Integrate $$\int\dfrac{1}{\cos(x-1)\cos(x-2)\cos(x-3)}\,\textrm dx$$ My Attempt: Using, $$\tan A-\tan B=\dfrac{\sin(A-B)}{\cos A\cdot \cos B}$$ The given integral can be transformed as $$\int\dfrac{\tan(x-1)}{\cos(x-2)}\,\textrm dx - \int\dfrac{\tan(x-3)}{\cos(x-3)}\,\textrm dx$$ The right most integral can be calculated easily by writing $\tan(x-3)$ as $\frac{\sin(x-3)}{\cos(x-3)}$ and then by a substituiton $\cos(x-3)$ as $t$ . But I have no clue for the left most integral. How to evaluate that?","Integrate My Attempt: Using, The given integral can be transformed as The right most integral can be calculated easily by writing as and then by a substituiton as . But I have no clue for the left most integral. How to evaluate that?","\int\dfrac{1}{\cos(x-1)\cos(x-2)\cos(x-3)}\,\textrm dx \tan A-\tan B=\dfrac{\sin(A-B)}{\cos A\cdot \cos B} \int\dfrac{\tan(x-1)}{\cos(x-2)}\,\textrm dx - \int\dfrac{\tan(x-3)}{\cos(x-3)}\,\textrm dx \tan(x-3) \frac{\sin(x-3)}{\cos(x-3)} \cos(x-3) t","['calculus', 'integration', 'indefinite-integrals', 'trigonometric-integrals']"
56,Expand $\frac{\Gamma\left(\frac{x}{2}\right)}{\Gamma\left(\frac{x-1}{2}\right)}$ at $x=\infty$,Expand  at,\frac{\Gamma\left(\frac{x}{2}\right)}{\Gamma\left(\frac{x-1}{2}\right)} x=\infty,"I used Wolfram Alpha for this problem and it gives me a ""Puiseux expansion"": $$\sqrt{x}-\frac{3 \sqrt{\frac{1}{x}}}{8}-\frac{7}{128}\left(\frac{1}{x}\right)^{3 / 2}-\frac{9\left(\frac{1}{x}\right)^{5 / 2}}{1024}+O\left(\left(\frac{1}{x}\right)^{3}\right)$$ which is exactly what I need. My only question is how one would be able to obtain this expansion manually.","I used Wolfram Alpha for this problem and it gives me a ""Puiseux expansion"": which is exactly what I need. My only question is how one would be able to obtain this expansion manually.",\sqrt{x}-\frac{3 \sqrt{\frac{1}{x}}}{8}-\frac{7}{128}\left(\frac{1}{x}\right)^{3 / 2}-\frac{9\left(\frac{1}{x}\right)^{5 / 2}}{1024}+O\left(\left(\frac{1}{x}\right)^{3}\right),"['calculus', 'sequences-and-series', 'taylor-expansion', 'gamma-function', 'laurent-series']"
57,Compact formula for the $n$th derivative of $f\left(\sqrt{x+1}\right)$?,Compact formula for the th derivative of ?,n f\left(\sqrt{x+1}\right),"I'm interested in a general formula for $$\frac{d^n}{dx^n}\Big[f\left(\sqrt{x+1}\right)\Big].$$ In particular, Fàa di Bruno's formula gives $$\frac{d^n}{dx^n}\Big[f\left(\sqrt{x+1}\right)\Big]=\sum_{k=1}^n f^{(k)}\left(\sqrt{x+1}\right)B_{n,k}\big(g'(x),g''(x),\dots,g^{(n-k+1)}(x)\big),$$ where $g(x)=\sqrt{x+1}$ and $B_{n,k}$ denote Bell polynomials . I suspect we can do better than this, using the identities $$\frac{d^k}{dx^k}\Big[\sqrt{x+1}\Big]=\left(\frac{1}{2}\right)^\underline{k}x^{1/2-k}=-\frac{(2k-3)!!}{(-2)^k}x^{1/2-k}=\frac{\sqrt{\pi}}{2\Gamma(3/2-k)}x^{1/2-k}.$$ In particular, every term in $B_{n,k}$ for fixed $n$ and $k$ will be some numerical factor times $(x+1)^{k/2-n}$ (see notes below), so the result is always of the form $$\frac{d^n}{dx^n}\Big[f\left(\sqrt{x+1}\right)\Big] =\sum_{k=1}^n a_{n,k} \frac{f^{(k)}\left(\sqrt{x+1}\right)}{(x+1)^{n-k/2}}$$ for some constants $a_{n,k}.$ Is there an explicit expression for the $a_{n,k}$ above? For example, it seems likely that there is some expression using Stirling numbers , factorials, binomial coefficients, etc., given the combinatorial nature of the problem. Current progress: Using the first identity above for derivatives of $\sqrt{x+1}$ [where $(\cdot)^\underline{k}$ denotes the $k$ th falling factorial ], we have $$B_{n,k}\big(g'(x),g''(x),\dots,g^{(n-k+1)}(x)\big) =B_{n,k}\left[\left(\frac{1}{2}\right)^\underline{1}x^{1/2-1},\left(\frac{1}{2}\right)^\underline{2}x^{1/2-2},\dots,\left(\frac{1}{2}\right)^\underline{n-k+1}x^{1/2-(n-k+1)}\right].$$ The definition of the Bell polynomials guarantees that the power of $x$ in every term of $B_{n,k}(\cdots)$ comes out to $x^{k/2-n}$ , with pre-factor given by $$a_{n,k}=B_{n,k}\left[\left(\frac{1}{2}\right)^\underline{1},\left(\frac{1}{2}\right)^\underline{2},\dots,\left(\frac{1}{2}\right)^\underline{n-k+1}\right],$$ so the remaining task is to simplify the above expression, if possible.","I'm interested in a general formula for In particular, Fàa di Bruno's formula gives where and denote Bell polynomials . I suspect we can do better than this, using the identities In particular, every term in for fixed and will be some numerical factor times (see notes below), so the result is always of the form for some constants Is there an explicit expression for the above? For example, it seems likely that there is some expression using Stirling numbers , factorials, binomial coefficients, etc., given the combinatorial nature of the problem. Current progress: Using the first identity above for derivatives of [where denotes the th falling factorial ], we have The definition of the Bell polynomials guarantees that the power of in every term of comes out to , with pre-factor given by so the remaining task is to simplify the above expression, if possible.","\frac{d^n}{dx^n}\Big[f\left(\sqrt{x+1}\right)\Big]. \frac{d^n}{dx^n}\Big[f\left(\sqrt{x+1}\right)\Big]=\sum_{k=1}^n f^{(k)}\left(\sqrt{x+1}\right)B_{n,k}\big(g'(x),g''(x),\dots,g^{(n-k+1)}(x)\big), g(x)=\sqrt{x+1} B_{n,k} \frac{d^k}{dx^k}\Big[\sqrt{x+1}\Big]=\left(\frac{1}{2}\right)^\underline{k}x^{1/2-k}=-\frac{(2k-3)!!}{(-2)^k}x^{1/2-k}=\frac{\sqrt{\pi}}{2\Gamma(3/2-k)}x^{1/2-k}. B_{n,k} n k (x+1)^{k/2-n} \frac{d^n}{dx^n}\Big[f\left(\sqrt{x+1}\right)\Big]
=\sum_{k=1}^n a_{n,k} \frac{f^{(k)}\left(\sqrt{x+1}\right)}{(x+1)^{n-k/2}} a_{n,k}. a_{n,k} \sqrt{x+1} (\cdot)^\underline{k} k B_{n,k}\big(g'(x),g''(x),\dots,g^{(n-k+1)}(x)\big)
=B_{n,k}\left[\left(\frac{1}{2}\right)^\underline{1}x^{1/2-1},\left(\frac{1}{2}\right)^\underline{2}x^{1/2-2},\dots,\left(\frac{1}{2}\right)^\underline{n-k+1}x^{1/2-(n-k+1)}\right]. x B_{n,k}(\cdots) x^{k/2-n} a_{n,k}=B_{n,k}\left[\left(\frac{1}{2}\right)^\underline{1},\left(\frac{1}{2}\right)^\underline{2},\dots,\left(\frac{1}{2}\right)^\underline{n-k+1}\right],","['calculus', 'combinatorics', 'derivatives', 'stirling-numbers', 'bell-numbers']"
58,Expected Value Bounded by Median - a Direct Proof?,Expected Value Bounded by Median - a Direct Proof?,,"Let $f:[0,1]\to \mathbb{R}$ be a positive, continuous and strictly increasing function such that $$\int_0^1 f(x)dx=1$$ Let $\xi\in (0,1)$ be such that $$\int_0^{\xi}f(x)dx=\int_{\xi}^1f(x)dx=\frac{1}{2}$$ Prove that $$\int_0^1 xf(x)dx\leq \xi$$ This problem comes from physics and has to do with the center of gravity of a shape. But I'd like to see a direct, computational proof. Here is my attempt. To begin with, note that $$ \begin{aligned} \int_0^1xf(x)dx &=\int_0^1[\xi+(x-\xi)]f(x)dx \\ &=\xi\int_0^1f(x)dx+\int_0^1(x-\xi)f(x)dx \\ &=\xi+\int_{-\xi}^{1-\xi}yf(y+\xi)dy \end{aligned} $$ For the second term, we know that $$\int_{-\xi}^{1-\xi}yf(y+\xi)dy=\int_{-\xi}^0yf(y+\xi)dy+\int_0^{1-\xi}yf(y+\xi)dy:=I_1+I_2$$ In $I_1$ , let $z=-y$ . Since $f$ is strictly increasing, the defining properties of $\xi$ imply that $\xi>\frac{1}{2}$ . So $1-\xi<\xi$ , and hence $$ \begin{aligned} I_1 &=\int_{\xi}^0(-z)(-1)f(-z+\xi)dz \\ &=-\int_0^{\xi}zf(-z+\xi)dz \\ &=-\left[\int_0^{1-\xi}zf(-z+\xi)dz+\int_{1-\xi}^{\xi}zf(-z+\xi)dz\right] \end{aligned} $$ We want to show that $I_1+I_2\leq 0$ . Equivalently, we have to prove that $$\int_0^{1-\xi}z\left[f(z+\xi)-f(-z+\xi)\right]dz\leq \int_{1-\xi}^{\xi}zf(-z+\xi)dz$$ If we perform a change of variables on the RHS by setting $$w=\frac{1-\xi}{2\xi-1}z-\frac{(1-\xi)^2}{2\xi-1}$$ then the RHS becomes $$\int_0^{1-\xi}\left[(2\xi-1)+\left(\frac{2\xi-1}{1-\xi}\right)^2w\right]f\left((2\xi-1)-\frac{2\xi-1}{1-\xi}w\right)dw$$ However, this is getting too complicated and is clearly not the right way to go. Can anyone share some ideas on how to solve to problem? Thank you!","Let be a positive, continuous and strictly increasing function such that Let be such that Prove that This problem comes from physics and has to do with the center of gravity of a shape. But I'd like to see a direct, computational proof. Here is my attempt. To begin with, note that For the second term, we know that In , let . Since is strictly increasing, the defining properties of imply that . So , and hence We want to show that . Equivalently, we have to prove that If we perform a change of variables on the RHS by setting then the RHS becomes However, this is getting too complicated and is clearly not the right way to go. Can anyone share some ideas on how to solve to problem? Thank you!","f:[0,1]\to \mathbb{R} \int_0^1 f(x)dx=1 \xi\in (0,1) \int_0^{\xi}f(x)dx=\int_{\xi}^1f(x)dx=\frac{1}{2} \int_0^1 xf(x)dx\leq \xi 
\begin{aligned}
\int_0^1xf(x)dx
&=\int_0^1[\xi+(x-\xi)]f(x)dx \\
&=\xi\int_0^1f(x)dx+\int_0^1(x-\xi)f(x)dx \\
&=\xi+\int_{-\xi}^{1-\xi}yf(y+\xi)dy
\end{aligned}
 \int_{-\xi}^{1-\xi}yf(y+\xi)dy=\int_{-\xi}^0yf(y+\xi)dy+\int_0^{1-\xi}yf(y+\xi)dy:=I_1+I_2 I_1 z=-y f \xi \xi>\frac{1}{2} 1-\xi<\xi 
\begin{aligned}
I_1
&=\int_{\xi}^0(-z)(-1)f(-z+\xi)dz \\
&=-\int_0^{\xi}zf(-z+\xi)dz \\
&=-\left[\int_0^{1-\xi}zf(-z+\xi)dz+\int_{1-\xi}^{\xi}zf(-z+\xi)dz\right]
\end{aligned}
 I_1+I_2\leq 0 \int_0^{1-\xi}z\left[f(z+\xi)-f(-z+\xi)\right]dz\leq \int_{1-\xi}^{\xi}zf(-z+\xi)dz w=\frac{1-\xi}{2\xi-1}z-\frac{(1-\xi)^2}{2\xi-1} \int_0^{1-\xi}\left[(2\xi-1)+\left(\frac{2\xi-1}{1-\xi}\right)^2w\right]f\left((2\xi-1)-\frac{2\xi-1}{1-\xi}w\right)dw","['calculus', 'integration', 'definite-integrals', 'expected-value']"
59,"How do I understand ""odd parity""","How do I understand ""odd parity""",,"In my Calc 2 course, we're in the u-sub section at the moment. One of my homework problems was $$\int_{-\pi/2}^{\pi/2}{(\cfrac{x^6\sin(3x)}{1+x^{10}})dx}$$ I realized substitution nor integration by parts will work. It turns out the answer is 0 because If $f(x)$ is an odd function and is continuous on the interval [-a, a], then $\int_{-a}^af(x)dx=0$ Can somebody explain the logic behind this; especially why $f$ has to be odd? Is there a simple illustration showing why I should trust the theory?","In my Calc 2 course, we're in the u-sub section at the moment. One of my homework problems was I realized substitution nor integration by parts will work. It turns out the answer is 0 because If is an odd function and is continuous on the interval [-a, a], then Can somebody explain the logic behind this; especially why has to be odd? Is there a simple illustration showing why I should trust the theory?",\int_{-\pi/2}^{\pi/2}{(\cfrac{x^6\sin(3x)}{1+x^{10}})dx} f(x) \int_{-a}^af(x)dx=0 f,"['calculus', 'integration', 'definite-integrals']"
60,Derivative of $\sec^{-1}x$ and integral of $\frac{1}{x\sqrt{x^2-1}}$,Derivative of  and integral of,\sec^{-1}x \frac{1}{x\sqrt{x^2-1}},"My attempt is as follows:- Derivative of $\sec^{-1}x$ Let $\theta=\sec^{-1}x,$ where $\theta\in [0,\pi]-{\dfrac{\pi}{2}}.$ $$\sec\theta=x.$$ Differentiating both sides with respect to $x:$ $$\sec\theta\cdot\tan\theta\cdot\dfrac{\mathrm d\theta}{\mathrm dx}=1\\ \dfrac{\mathrm d\theta}{\mathrm dx}=\dfrac{1}{x\sqrt{x^2-1}}.$$ As $\sec^{-1}x$ is a strictly increasing function, its derivative should be positive, hence we write $x$ as $|x|$ to ensure that $\dfrac{\mathrm d\theta}{\mathrm dx}$ will not be negative if $x$ is negative. But I wonder why I didn't get $\dfrac{\mathrm d\theta}{\mathrm dx}=\dfrac{1}{|x|\sqrt{x^2-1}}$ in the above calculation? Integral of $\dfrac{1}{x\sqrt{x^2-1}}$ Case $1:x>0$ Then the integral is definitely $\sec^{-1}x.$ Case $2: x<0$ Then the integral is $-\sec^{-1}x.$ But many textbooks write that $\displaystyle\int\frac{1}{x\sqrt{x^2-1}}\,\mathrm dx=\sec^{-1}x+C.$ Shouldn't $\displaystyle\int\frac{1}{|x|\sqrt{x^2-1}}\,\mathrm dx=\sec^{-1}x+C\:?$ What am I missing here?","My attempt is as follows:- Derivative of Let where Differentiating both sides with respect to As is a strictly increasing function, its derivative should be positive, hence we write as to ensure that will not be negative if is negative. But I wonder why I didn't get in the above calculation? Integral of Case Then the integral is definitely Case Then the integral is But many textbooks write that Shouldn't What am I missing here?","\sec^{-1}x \theta=\sec^{-1}x, \theta\in [0,\pi]-{\dfrac{\pi}{2}}. \sec\theta=x. x: \sec\theta\cdot\tan\theta\cdot\dfrac{\mathrm d\theta}{\mathrm dx}=1\\
\dfrac{\mathrm d\theta}{\mathrm dx}=\dfrac{1}{x\sqrt{x^2-1}}. \sec^{-1}x x |x| \dfrac{\mathrm d\theta}{\mathrm dx} x \dfrac{\mathrm d\theta}{\mathrm dx}=\dfrac{1}{|x|\sqrt{x^2-1}} \dfrac{1}{x\sqrt{x^2-1}} 1:x>0 \sec^{-1}x. 2: x<0 -\sec^{-1}x. \displaystyle\int\frac{1}{x\sqrt{x^2-1}}\,\mathrm dx=\sec^{-1}x+C. \displaystyle\int\frac{1}{|x|\sqrt{x^2-1}}\,\mathrm dx=\sec^{-1}x+C\:?","['calculus', 'integration', 'derivatives']"
61,"$\frac{d}{dx} \frac{1}{x+\frac{1}{x+\frac{1}{ \ddots}}}$, the derivative of an infinite continued fraction.",", the derivative of an infinite continued fraction.",\frac{d}{dx} \frac{1}{x+\frac{1}{x+\frac{1}{ \ddots}}},"I computed the first few derivatives in the sequence $\frac{1}{x+\frac{1}{x}}, \frac{1}{x+\frac{1}{x+\frac{1}{x}}} \dots$ and eventually lost feeling in my fingers and also realized I was seeing nothing meaningful. Let $$f(x,t) = \overbrace{\cfrac{1}{x+\cfrac{1}{x+\cfrac{1}{\ddots}}}}^{x\text{ appearing }t \text{ times.}}$$ My question: does there exist a closed-form of the derivative of an infinite continued fraction, at least for positive arguments? That is, does $g(x)$ such that: $$g(x)=\lim_{t \to \infty}\frac{d}{dx}f(x,t)$$ Have a closed-form expression?","I computed the first few derivatives in the sequence and eventually lost feeling in my fingers and also realized I was seeing nothing meaningful. Let My question: does there exist a closed-form of the derivative of an infinite continued fraction, at least for positive arguments? That is, does such that: Have a closed-form expression?","\frac{1}{x+\frac{1}{x}}, \frac{1}{x+\frac{1}{x+\frac{1}{x}}} \dots f(x,t) = \overbrace{\cfrac{1}{x+\cfrac{1}{x+\cfrac{1}{\ddots}}}}^{x\text{ appearing }t \text{ times.}} g(x) g(x)=\lim_{t \to \infty}\frac{d}{dx}f(x,t)","['calculus', 'derivatives', 'fractions', 'continued-fractions']"
62,"Why this trick apparently works to make piecewise function differentiable? (also, difference between right derivative and right limit of derivative?)","Why this trick apparently works to make piecewise function differentiable? (also, difference between right derivative and right limit of derivative?)",,"In high school Calculus a few weeks ago we were given the following problem - it has haunted me ever since and I finally decided to ask about it here: $$f(x) = \left\{\begin{array}{ll} 2x^2+x+1\ &\text{if }x\leq 0,\\ ax+b &\text{if }x>0. \end{array}\right.$$ 1. Determine the values of $a$ and $b$ such that $f$ is continuous for all x-values. 2. Determine the values of $a$ and $b$ such that $f$ is differentiable for all x-values. (Hint/reminder: for $f$ to be differentiable, both $f$ and $f'$ must be continuous.) Part 1 was easy and I believe I understand why it works. And clearly $b=1$ because that's the solution to $a(0)+b = 2(0)^2+0+1$ . Part 2 was conceptually much more difficult. The first issue is that the statement in the question that ""for $f$ to be differentiable ... $f'$ must be continuous"" is demonstrably false. Being the math nerd that I am, I remembered quickly that in fact the function $f(x)=x^2\sin(1/x)$ , where $f(0)=0$ , is differentiable at $x=0$ but nevertheless $f'$ is NOT continuous there. The second tricky thing is that even though my teacher's premise was apparently false, the solution they derived from that premise was apparently correct! (or at least I have no reason to believe it was incorrect) Specifically, they set the derivative at $x=0$ of the top expression, $4(0)+1$ , equal to that of the bottom expression, $a$ , and quickly found $a=1$ ( $b$ is, of course, still 1 as well). That's a really nifty trick -- just set the derivatives of the two expressions equal to one another and solve. So at this point I'm super confused. Assuming the method my teacher used did in fact work, why did it work? Furthermore, when researching this topic I came across the idea of right and left-hand derivatives. My understanding is that those two terms are related to, but distinct from, the left and right-hand limits of the derivative function at a  point. In other words, my understanding is that the left derivative at $x=a$ is defined as.... $$f'_{-}(a)=\lim_{h\to 0^-}\frac{f(a+h)-f(a)}{h}$$ ... while the limit of the derivative function as $x$ approaches $a$ from the left is simply... $$\lim_{x\to a^-}f'(x)$$ Am I correct that there's a difference between those two concepts (and, regardless, does it matter to my ultimate inquiry?) I am aware that others have asked somewhat similar questions here in the past (e.g. here and here ). However, the answers I have seen either gloss over things I'm confused about or otherwise have not helped me achieve full understanding. I'll note, lastly, that I've also tried to think about this problem graphically. I suppose that has shown me that the teacher's solution was somewhat sensible (it did give me an intuitive idea that the ""slopes"" need to ""match"" on each side), but it has not completely convinced me in the way a formal justification would. Furthermore, oftentimes it just takes me back in circles to the difference (if any) between a right-hand derivative and the right-hand limit of the derivative function.","In high school Calculus a few weeks ago we were given the following problem - it has haunted me ever since and I finally decided to ask about it here: 1. Determine the values of and such that is continuous for all x-values. 2. Determine the values of and such that is differentiable for all x-values. (Hint/reminder: for to be differentiable, both and must be continuous.) Part 1 was easy and I believe I understand why it works. And clearly because that's the solution to . Part 2 was conceptually much more difficult. The first issue is that the statement in the question that ""for to be differentiable ... must be continuous"" is demonstrably false. Being the math nerd that I am, I remembered quickly that in fact the function , where , is differentiable at but nevertheless is NOT continuous there. The second tricky thing is that even though my teacher's premise was apparently false, the solution they derived from that premise was apparently correct! (or at least I have no reason to believe it was incorrect) Specifically, they set the derivative at of the top expression, , equal to that of the bottom expression, , and quickly found ( is, of course, still 1 as well). That's a really nifty trick -- just set the derivatives of the two expressions equal to one another and solve. So at this point I'm super confused. Assuming the method my teacher used did in fact work, why did it work? Furthermore, when researching this topic I came across the idea of right and left-hand derivatives. My understanding is that those two terms are related to, but distinct from, the left and right-hand limits of the derivative function at a  point. In other words, my understanding is that the left derivative at is defined as.... ... while the limit of the derivative function as approaches from the left is simply... Am I correct that there's a difference between those two concepts (and, regardless, does it matter to my ultimate inquiry?) I am aware that others have asked somewhat similar questions here in the past (e.g. here and here ). However, the answers I have seen either gloss over things I'm confused about or otherwise have not helped me achieve full understanding. I'll note, lastly, that I've also tried to think about this problem graphically. I suppose that has shown me that the teacher's solution was somewhat sensible (it did give me an intuitive idea that the ""slopes"" need to ""match"" on each side), but it has not completely convinced me in the way a formal justification would. Furthermore, oftentimes it just takes me back in circles to the difference (if any) between a right-hand derivative and the right-hand limit of the derivative function.","f(x) = \left\{\begin{array}{ll}
2x^2+x+1\ &\text{if }x\leq 0,\\
ax+b &\text{if }x>0.
\end{array}\right. a b f a b f f f f' b=1 a(0)+b = 2(0)^2+0+1 f f' f(x)=x^2\sin(1/x) f(0)=0 x=0 f' x=0 4(0)+1 a a=1 b x=a f'_{-}(a)=\lim_{h\to 0^-}\frac{f(a+h)-f(a)}{h} x a \lim_{x\to a^-}f'(x)","['calculus', 'derivatives', 'continuity']"
63,What did I get wrong when solving $\int\frac{\sqrt{x^2-1}}{x^4}dx$?,What did I get wrong when solving ?,\int\frac{\sqrt{x^2-1}}{x^4}dx,"I'm not sure that this is the problem, but I think I may not know how to find the $\theta$ value when solving an integral problem with trigonometric substitution. I got $\frac{\sin^3(\sec^{-1}(x))}{3}+C$ for the answer, but the answer should be, $\frac{1}{3}\frac{(x^2-1)^{3/2}}{x^3}+C$ $$\int\frac{\sqrt{x^2-1}}{x^4}dx$$ Let $x=\sec\theta$ Then $dx=\sec\theta\tan\theta d\theta$ $$\int\frac{\sqrt{\sec^2\theta-1}}{\sec^4\theta}\sec\theta\tan\theta d\theta$$ $$=\int\frac{\sec\theta}{\sec^4\theta}\sqrt{\tan^2\theta}\tan\theta d\theta$$ $$=\int\frac{1}{\sec^3\theta} \tan^2\theta d\theta$$ $$=\int\frac{1}{\sec^3\theta}\frac{\sec^2\theta}{\csc^2\theta}d\theta$$ $$=\int\frac{1}{\sec\theta}\frac{1}{\csc^2\theta}d\theta$$ $$=\int \cos\theta\sin^2\theta d \theta$$ Using $u$ -substition, let $u=\sin\theta$ Then $du=\cos\theta d\theta$ and $dx = \frac{1}{\cos\theta}du$ $$\int\cos\theta u^2 \frac{1}{\cos\theta}du$$ $$=\int u^2 du$$ $$=\frac{u^3}{3}+C$$ $$=\frac{\sin^3\theta}{3}+C$$ Since $x=\sec\theta$ , $\sec^{-1}(x)=\theta$ $$=\frac{\sin^3(\sec^{-1}(x))}{3}+C$$ What am I doing wrong?","I'm not sure that this is the problem, but I think I may not know how to find the value when solving an integral problem with trigonometric substitution. I got for the answer, but the answer should be, Let Then Using -substition, let Then and Since , What am I doing wrong?",\theta \frac{\sin^3(\sec^{-1}(x))}{3}+C \frac{1}{3}\frac{(x^2-1)^{3/2}}{x^3}+C \int\frac{\sqrt{x^2-1}}{x^4}dx x=\sec\theta dx=\sec\theta\tan\theta d\theta \int\frac{\sqrt{\sec^2\theta-1}}{\sec^4\theta}\sec\theta\tan\theta d\theta =\int\frac{\sec\theta}{\sec^4\theta}\sqrt{\tan^2\theta}\tan\theta d\theta =\int\frac{1}{\sec^3\theta} \tan^2\theta d\theta =\int\frac{1}{\sec^3\theta}\frac{\sec^2\theta}{\csc^2\theta}d\theta =\int\frac{1}{\sec\theta}\frac{1}{\csc^2\theta}d\theta =\int \cos\theta\sin^2\theta d \theta u u=\sin\theta du=\cos\theta d\theta dx = \frac{1}{\cos\theta}du \int\cos\theta u^2 \frac{1}{\cos\theta}du =\int u^2 du =\frac{u^3}{3}+C =\frac{\sin^3\theta}{3}+C x=\sec\theta \sec^{-1}(x)=\theta =\frac{\sin^3(\sec^{-1}(x))}{3}+C,"['calculus', 'integration', 'trigonometry', 'indefinite-integrals', 'trigonometric-integrals']"
64,Showing $\sqrt[3]{\cos\frac{2\pi}{9}}+\sqrt[3]{\cos\frac{4\pi}{9}}+\sqrt[3]{\cos\frac{8\pi}{9}} = \sqrt[3]{\frac{3\sqrt[3]9-6}{2}} $,Showing,\sqrt[3]{\cos\frac{2\pi}{9}}+\sqrt[3]{\cos\frac{4\pi}{9}}+\sqrt[3]{\cos\frac{8\pi}{9}} = \sqrt[3]{\frac{3\sqrt[3]9-6}{2}} ,"Show that $$\sqrt[3]{\cos\frac{2\pi}{9}}+\sqrt[3]{\cos\frac{4\pi}{9}}+\sqrt[3]{\cos\frac{8\pi}{9}} = \sqrt[3]{\frac{3\sqrt[3]9-6}{2}} $$ I tried to find a polynomial that had its roots, but the degree grows too fast and I'm getting lost.","Show that I tried to find a polynomial that had its roots, but the degree grows too fast and I'm getting lost.",\sqrt[3]{\cos\frac{2\pi}{9}}+\sqrt[3]{\cos\frac{4\pi}{9}}+\sqrt[3]{\cos\frac{8\pi}{9}} = \sqrt[3]{\frac{3\sqrt[3]9-6}{2}} ,"['calculus', 'trigonometry']"
65,"""Calculus 4th Edition"" by Michael Spivak -- Chapter 11 Problem 59","""Calculus 4th Edition"" by Michael Spivak -- Chapter 11 Problem 59",,"In Michael Spivak's ""Calculus"" 4th edition, Chapter 11 Problem 59 reads Suppose that the function $f > 0$ has the property that $$(f')^2=f-{1 \over f^2}.$$ Find a formula for $f''$ in terms of $f$ . (Why is this problem in this chapter?) This seems to be straight-forward: \begin{align} (f')^2 &= f-{1 \over f^2} \\ 2f'f'' &= f'+{2 \over f^3}f' \\ 2f''   &= 1+{2 \over f^3} \\ f''    &= {1 \over 2} + {1 \over f^3} \end{align} My problem is I can't figure out how to answer why this problem is in this chapter. Chapter 11 covers Rolle's Theorem, the Mean Value Theorem, the Cauchy Mean Value Theorem and L'Hopital's Rule. It also covers local extrema and the Second-Derivative Test. We answered a substantially similar question in Chapter 10 after covering the Chain Rule etc. Since I'm not using any new concepts, I'm suspicious I'm doing something wrong. I'd very much appreciate any insight. EDIT: Thank you everyone, you have all been very helpful. I would accept both answers if I could.","In Michael Spivak's ""Calculus"" 4th edition, Chapter 11 Problem 59 reads Suppose that the function has the property that Find a formula for in terms of . (Why is this problem in this chapter?) This seems to be straight-forward: My problem is I can't figure out how to answer why this problem is in this chapter. Chapter 11 covers Rolle's Theorem, the Mean Value Theorem, the Cauchy Mean Value Theorem and L'Hopital's Rule. It also covers local extrema and the Second-Derivative Test. We answered a substantially similar question in Chapter 10 after covering the Chain Rule etc. Since I'm not using any new concepts, I'm suspicious I'm doing something wrong. I'd very much appreciate any insight. EDIT: Thank you everyone, you have all been very helpful. I would accept both answers if I could.","f > 0 (f')^2=f-{1 \over f^2}. f'' f \begin{align}
(f')^2 &= f-{1 \over f^2} \\
2f'f'' &= f'+{2 \over f^3}f' \\
2f''   &= 1+{2 \over f^3} \\
f''    &= {1 \over 2} + {1 \over f^3}
\end{align}",['calculus']
66,"Find a monotone increasing nonnegative function such that $f'(x)^2 \ge \alpha f(x)f''(x),\alpha>1$",Find a monotone increasing nonnegative function such that,"f'(x)^2 \ge \alpha f(x)f''(x),\alpha>1","Can we construct a function that is monotone increasing and nonnegative, such that $f'(x)^2 \ge \alpha f(x)f''(x)$ for each $x\in \mathbb R$ , where $\alpha$ is greater than $1$ . If not, how can we give a proof? Note: we say $f(x)$ is monotone increasing, iff $f(x)<f(y)$ for all $x<y$ . I have tried a lot of examples but havn't found a solution. For example, consider $f(x)=b\exp(ax)$ , then $f'(x)^2=f(x)f''(x)=b^2a^2\exp(ax)$ , so the constraint "" $\alpha$ is greater than 1"" is not true.","Can we construct a function that is monotone increasing and nonnegative, such that for each , where is greater than . If not, how can we give a proof? Note: we say is monotone increasing, iff for all . I have tried a lot of examples but havn't found a solution. For example, consider , then , so the constraint "" is greater than 1"" is not true.",f'(x)^2 \ge \alpha f(x)f''(x) x\in \mathbb R \alpha 1 f(x) f(x)<f(y) x<y f(x)=b\exp(ax) f'(x)^2=f(x)f''(x)=b^2a^2\exp(ax) \alpha,"['calculus', 'functions']"
67,Calculating limit of a sum,Calculating limit of a sum,,"Helllo everyone, I have to calculate a particular limit that contais a sum and I have no idea how to solve such problem. The task is to calculate this limit: $$\lim_{n\to \infty}\left(\frac n6\sum_{i=0}^\infty \left(\frac 56\right)^i\left(1-\left(\frac56\right)^i\right)^{n-1}\right) $$ I will be grateful for any hints or solutions.","Helllo everyone, I have to calculate a particular limit that contais a sum and I have no idea how to solve such problem. The task is to calculate this limit: I will be grateful for any hints or solutions.",\lim_{n\to \infty}\left(\frac n6\sum_{i=0}^\infty \left(\frac 56\right)^i\left(1-\left(\frac56\right)^i\right)^{n-1}\right) ,"['calculus', 'limits']"
68,Proving inequality $\int_a^{\pi/2}\cos^nxdx\le e^{-na^2/2}\int_0^{\pi/2}\cos^nxdx$,Proving inequality,\int_a^{\pi/2}\cos^nxdx\le e^{-na^2/2}\int_0^{\pi/2}\cos^nxdx,"How to prove $$\int_a^{\pi/2}\cos^nxdx\le e^{-na^2/2}\int_0^{\pi/2}\cos^nxdx,$$ where $n\in\mathbb N$ and $a\in[0,\pi/2]$ ? I noticed that if we can prove $$\cos^na\le nae^{-na^2/2}\int_0^{\pi/2}\cos^nxdx,$$ apply $\displaystyle\int_a^{\pi/2}$ to both side, the conclusion will follow. But unfortunately, this inequality above is not true. When $a=0$ , $LHS=1>0=RHS$ . Also, Wallis' formula can help us find $\displaystyle\int_0^{\pi/2}\cos^nxdx$ . I'm not sure if it helps.","How to prove where and ? I noticed that if we can prove apply to both side, the conclusion will follow. But unfortunately, this inequality above is not true. When , . Also, Wallis' formula can help us find . I'm not sure if it helps.","\int_a^{\pi/2}\cos^nxdx\le e^{-na^2/2}\int_0^{\pi/2}\cos^nxdx, n\in\mathbb N a\in[0,\pi/2] \cos^na\le nae^{-na^2/2}\int_0^{\pi/2}\cos^nxdx, \displaystyle\int_a^{\pi/2} a=0 LHS=1>0=RHS \displaystyle\int_0^{\pi/2}\cos^nxdx","['calculus', 'integration', 'inequality', 'definite-integrals']"
69,Delta Epsilon Proof of $\lim_{x\to\infty}\frac{\ln{x}^2}{x}=0$,Delta Epsilon Proof of,\lim_{x\to\infty}\frac{\ln{x}^2}{x}=0,"I am trying to prove that $\lim_{x\to\infty}\frac{\ln{x}^2}{x}=0$ via the delta epsilon definition of a limit but I keep getting hung up. I have started the proof like this: $\forall \epsilon>0, \exists \delta$ so if $\delta>0$ , $|\frac{\ln{x}^2}{x}-0|<\epsilon$ . If we suppose that $|\frac{\ln{x}^2}{x}-0|<\epsilon$ and solve for x we get... When I try solving the inequality for $x$ , it keeps cancelling. What I have tried: $2x^{-1}\ln{x}<\ln{\epsilon}$ Which becomes: $2x^{-1}(x^1)<e^{\ln{\epsilon}}$ But then, $x^{-1}$ and $x^1$ multiply to $x^0$ , which is $1$ and $x$ is removed from the problem. Any pointers as how to proceed? I know that the limit is $0$ , I just can't seem to get past solving for $x$ . Thank you.","I am trying to prove that via the delta epsilon definition of a limit but I keep getting hung up. I have started the proof like this: so if , . If we suppose that and solve for x we get... When I try solving the inequality for , it keeps cancelling. What I have tried: Which becomes: But then, and multiply to , which is and is removed from the problem. Any pointers as how to proceed? I know that the limit is , I just can't seem to get past solving for . Thank you.","\lim_{x\to\infty}\frac{\ln{x}^2}{x}=0 \forall \epsilon>0, \exists \delta \delta>0 |\frac{\ln{x}^2}{x}-0|<\epsilon |\frac{\ln{x}^2}{x}-0|<\epsilon x 2x^{-1}\ln{x}<\ln{\epsilon} 2x^{-1}(x^1)<e^{\ln{\epsilon}} x^{-1} x^1 x^0 1 x 0 x","['calculus', 'proof-verification', 'epsilon-delta']"
70,Calculate$\int\limits_{-2}^{0} \frac{x}{\sqrt{e^x+(x+2)^2}}dx$ [duplicate],Calculate [duplicate],\int\limits_{-2}^{0} \frac{x}{\sqrt{e^x+(x+2)^2}}dx,This question already has an answer here : Calculate $ \int_{-2}^{0} \frac{x}{\sqrt{e^x+(x+2)^2}} dx $ (1 answer) Closed 5 years ago . Calculate $$\int\limits_{-2}^{0} \frac{x}{\sqrt{e^x+(x+2)^2}}dx$$ First I tried the substitution $t=x+2$ and obtained $$\int\limits_{0}^{2} \frac{t-2}{\sqrt{e^{t-2}+t^2}}dt$$ and than I thought to write it as $$\int\limits_{0}^{2} (t-2)\frac{1}{\sqrt{e^{t-2}+t^2}}dt$$ and use the fact that $$2(\sqrt{e^{t-2}+t^2})'=\frac{1}{\sqrt{e^{t-2}+t^2}} \cdot(e^{t-2}+2t)$$ Using integration by parts we get that we have to calculate (excluding some terms we know) $$\int\limits_{0}^{2} \sqrt{e^{t-2}+t^2}\cdot \frac{6e^{t-2}-2te^{t-2}+8}{(e^{t-2}+2t)^2}dt$$ which is uglier then the initial problem. Do you have any idea how to solve the problem?,This question already has an answer here : Calculate $ \int_{-2}^{0} \frac{x}{\sqrt{e^x+(x+2)^2}} dx $ (1 answer) Closed 5 years ago . Calculate $$\int\limits_{-2}^{0} \frac{x}{\sqrt{e^x+(x+2)^2}}dx$$ First I tried the substitution $t=x+2$ and obtained $$\int\limits_{0}^{2} \frac{t-2}{\sqrt{e^{t-2}+t^2}}dt$$ and than I thought to write it as $$\int\limits_{0}^{2} (t-2)\frac{1}{\sqrt{e^{t-2}+t^2}}dt$$ and use the fact that $$2(\sqrt{e^{t-2}+t^2})'=\frac{1}{\sqrt{e^{t-2}+t^2}} \cdot(e^{t-2}+2t)$$ Using integration by parts we get that we have to calculate (excluding some terms we know) $$\int\limits_{0}^{2} \sqrt{e^{t-2}+t^2}\cdot \frac{6e^{t-2}-2te^{t-2}+8}{(e^{t-2}+2t)^2}dt$$ which is uglier then the initial problem. Do you have any idea how to solve the problem?,,"['calculus', 'integration', 'definite-integrals']"
71,"How to prove $\lim_{(x,y) \rightarrow (0,0)} \frac{x^{2}y^{2}}{x^{3}+y^{3}}$ doesn't exist [duplicate]",How to prove  doesn't exist [duplicate],"\lim_{(x,y) \rightarrow (0,0)} \frac{x^{2}y^{2}}{x^{3}+y^{3}}","This question already has answers here : Limit of $\lim_{(x,y)\rightarrow(0,0)}\frac{x^2y^2}{x^3+y^3}$ (3 answers) Closed 5 years ago . I have tried using polar coordinates and several polynomial functions, but they all converge to the value of $0$; checking at Wolfram Alpha, however, it confirms that the limit does not exist. How should I approach these kinds of questions and not get stuck?  $$ \lim_{(x,y) \rightarrow (0,0)} \frac{x^{2}y^{2}}{x^{3}+y^{3}} $$","This question already has answers here : Limit of $\lim_{(x,y)\rightarrow(0,0)}\frac{x^2y^2}{x^3+y^3}$ (3 answers) Closed 5 years ago . I have tried using polar coordinates and several polynomial functions, but they all converge to the value of $0$; checking at Wolfram Alpha, however, it confirms that the limit does not exist. How should I approach these kinds of questions and not get stuck?  $$ \lim_{(x,y) \rightarrow (0,0)} \frac{x^{2}y^{2}}{x^{3}+y^{3}} $$",,"['calculus', 'limits']"
72,Prove that $\log_23>\log_35>\log_47$.,Prove that .,\log_23>\log_35>\log_47,"Using calculus, prove that $\log_23>\log_35>\log_47$ . My try : If $\log_x(2x-1)$ is decreasing function then we can say that $\log_23>\log_35>\log_47$. $f(x)=\log_x(2x-1)$ $f(x)=\dfrac{\ln(2x-1)}{\ln x}$ $f'(x)=\dfrac{2x\ln x-(x-1)\ln(2x-1)}{(\ln x)^2x(2x-1)}$","Using calculus, prove that $\log_23>\log_35>\log_47$ . My try : If $\log_x(2x-1)$ is decreasing function then we can say that $\log_23>\log_35>\log_47$. $f(x)=\log_x(2x-1)$ $f(x)=\dfrac{\ln(2x-1)}{\ln x}$ $f'(x)=\dfrac{2x\ln x-(x-1)\ln(2x-1)}{(\ln x)^2x(2x-1)}$",,"['calculus', 'logarithms']"
73,"What is $x$, if $\cot ^{-1} \left(3x+\frac{2}{x}\right)+\cot ^{-1} \left(6x+\frac{2}{x}\right)+\cot ^{-1} \left(10x+\frac{2}{x}\right)+\cdots = 1$?","What is , if ?",x \cot ^{-1} \left(3x+\frac{2}{x}\right)+\cot ^{-1} \left(6x+\frac{2}{x}\right)+\cot ^{-1} \left(10x+\frac{2}{x}\right)+\cdots = 1,"Let $$S_{n}=\cot ^{-1} \left(3x+\frac{2}{x}\right)+\cot ^{-1} \left(6x+\frac{2}{x}\right)+\cot ^{-1} \left(10x+\frac{2}{x}\right)+\cdots \quad\text{($n$ terms)}$$ where $x>0$ . If $\lim _{n \to \infty} S_{n}=1$ , then  find the value of $x$ . Can the given series be converted to telescopic series? I converted in into $\tan^{-1}$ but in every term $x$ is in numerator? Could someone please given some hint?","Let where . If , then  find the value of . Can the given series be converted to telescopic series? I converted in into but in every term is in numerator? Could someone please given some hint?",S_{n}=\cot ^{-1} \left(3x+\frac{2}{x}\right)+\cot ^{-1} \left(6x+\frac{2}{x}\right)+\cot ^{-1} \left(10x+\frac{2}{x}\right)+\cdots \quad\text{(n terms)} x>0 \lim _{n \to \infty} S_{n}=1 x \tan^{-1} x,"['calculus', 'sequences-and-series', 'trigonometry', 'telescopic-series']"
74,How to calculate the integral $\int\frac{1}{\sqrt{(x^2+8)^3}}dx$?,How to calculate the integral ?,\int\frac{1}{\sqrt{(x^2+8)^3}}dx,I need to solve something like this $$\int\frac{1}{\sqrt{(x^2+8)^3}}dx$$ Wolfram alpha says the solution is $$\frac{x}{8\sqrt{x^2+8}} + c$$ The problem is that the integrand is obtained by the quotient rule: $$\bigg(\frac{g(x)}{h(x)}\bigg)'=\frac{g'(x)h(x)-g(x)h'(x)}{h^2(x)}$$ $$\bigg(\frac{x}{8\sqrt{x^2+8}}\bigg)'=\frac{1}{8}\cdot\frac{\sqrt{x^2+8}-\frac{x^2}{\sqrt{x^2+8}}}{x^2+8}=\frac{1}{8}\cdot\frac{\frac{x^2+8-x^2}{\sqrt{x^2+8}}}{x^2+8}=\frac{1}{8}\cdot\frac{8}{\sqrt{(x^2+8)^3}}=\frac{1}{\sqrt{(x^2+8)^3}}$$ It there a way to extract the solution from these types of integrals which argument is born from the easy quotient rule?,I need to solve something like this $$\int\frac{1}{\sqrt{(x^2+8)^3}}dx$$ Wolfram alpha says the solution is $$\frac{x}{8\sqrt{x^2+8}} + c$$ The problem is that the integrand is obtained by the quotient rule: $$\bigg(\frac{g(x)}{h(x)}\bigg)'=\frac{g'(x)h(x)-g(x)h'(x)}{h^2(x)}$$ $$\bigg(\frac{x}{8\sqrt{x^2+8}}\bigg)'=\frac{1}{8}\cdot\frac{\sqrt{x^2+8}-\frac{x^2}{\sqrt{x^2+8}}}{x^2+8}=\frac{1}{8}\cdot\frac{\frac{x^2+8-x^2}{\sqrt{x^2+8}}}{x^2+8}=\frac{1}{8}\cdot\frac{8}{\sqrt{(x^2+8)^3}}=\frac{1}{\sqrt{(x^2+8)^3}}$$ It there a way to extract the solution from these types of integrals which argument is born from the easy quotient rule?,,"['calculus', 'integration', 'indefinite-integrals', 'substitution']"
75,Evaluation of Integral $\int \frac{x^2+1}{\sqrt{x^3+3}}dx$,Evaluation of Integral,\int \frac{x^2+1}{\sqrt{x^3+3}}dx,Calculate  integral $\int \frac{x^2+1}{\sqrt{x^3+3}}dx$ This was my exam question. I've tried many online math solvers and math programs but none were able to solve. If anybody has an answer would be helpful. Thanks,Calculate  integral $\int \frac{x^2+1}{\sqrt{x^3+3}}dx$ This was my exam question. I've tried many online math solvers and math programs but none were able to solve. If anybody has an answer would be helpful. Thanks,,"['calculus', 'integration', 'indefinite-integrals', 'elliptic-integrals']"
76,Gaps between numbers on the real number line,Gaps between numbers on the real number line,,"I was reading a book called Calculus Basic Concepts for High Schools , and, under the topic limit, it was discussed that one cannot have two limits for a given sequence, provided the sequence has a limit. And the immediate implication of this is that there cannot be a neighboring number because one can always find a number between any selected numbers; however, close they may be. So in an open interval $(a,b)$, one cannot find the largest number. I want someone to elaborate on this piece of text from ""Calculus Basic Concepts for High Schools: L. V. Tarasov"": However, if there were a point   neighboring 1, after the removal of the latter this ""neighbor""   would have become the largest number. I would like   to note here that many ""delicate"" points and many ""secrets""   in the calculus theorems are ultimately associated with the   impossibility of identifying two neighboring points on the   real line, or of specifying the greatest or least number on an   open interval of the real line. What would happen if we can find a neighboring number? How is calculus associated with the impossibility of identifying two neighboring points on the real line?","I was reading a book called Calculus Basic Concepts for High Schools , and, under the topic limit, it was discussed that one cannot have two limits for a given sequence, provided the sequence has a limit. And the immediate implication of this is that there cannot be a neighboring number because one can always find a number between any selected numbers; however, close they may be. So in an open interval $(a,b)$, one cannot find the largest number. I want someone to elaborate on this piece of text from ""Calculus Basic Concepts for High Schools: L. V. Tarasov"": However, if there were a point   neighboring 1, after the removal of the latter this ""neighbor""   would have become the largest number. I would like   to note here that many ""delicate"" points and many ""secrets""   in the calculus theorems are ultimately associated with the   impossibility of identifying two neighboring points on the   real line, or of specifying the greatest or least number on an   open interval of the real line. What would happen if we can find a neighboring number? How is calculus associated with the impossibility of identifying two neighboring points on the real line?",,"['calculus', 'sequences-and-series', 'limits', 'real-numbers']"
77,Why can we replace a variable with a constant in a limit?,Why can we replace a variable with a constant in a limit?,,"We say $\lim_{x \to c} f(x) = L$ that means $f(x)$ may be as close to $L$ as $x$ tends to $c$. "" Tends "" here means $x$ approaches $c$ but never actually becomes $c$. If it so, then why do we such easily replace $x$ with value $c$, whenever it is appropriate. E.g. $\lim_{x \to 5} 4 + x = 4 + 5 = 9$, or $\lim_{h \to 0} f(x+h) = f(x)$. Understand me right. I don't want to discuss cases when we can do the substitution and sometimes not, because we get a division by zero, and we need to do some simplification, etc. I understand all this. I just can't understand if $x$ actually is never $c$, what allows me to write $c$ as a value of $x$? Well, I used to think about it like ""ah, as $x \to 0$, x is very small number, let it be zero"". But it is not statistics, you know, to close eyes and make approximations. I met the notion of ""infinitesimal"" and as I understood it is opposed to ""$\delta-\epsilon$"" approach. I can't fully understand how they are related to each other and to my question. Maybe I lack of historical context. If it so, please clarify this for me. Thanks.","We say $\lim_{x \to c} f(x) = L$ that means $f(x)$ may be as close to $L$ as $x$ tends to $c$. "" Tends "" here means $x$ approaches $c$ but never actually becomes $c$. If it so, then why do we such easily replace $x$ with value $c$, whenever it is appropriate. E.g. $\lim_{x \to 5} 4 + x = 4 + 5 = 9$, or $\lim_{h \to 0} f(x+h) = f(x)$. Understand me right. I don't want to discuss cases when we can do the substitution and sometimes not, because we get a division by zero, and we need to do some simplification, etc. I understand all this. I just can't understand if $x$ actually is never $c$, what allows me to write $c$ as a value of $x$? Well, I used to think about it like ""ah, as $x \to 0$, x is very small number, let it be zero"". But it is not statistics, you know, to close eyes and make approximations. I met the notion of ""infinitesimal"" and as I understood it is opposed to ""$\delta-\epsilon$"" approach. I can't fully understand how they are related to each other and to my question. Maybe I lack of historical context. If it so, please clarify this for me. Thanks.",,"['calculus', 'limits']"
78,"Smooth map on a ""non-open"" subset","Smooth map on a ""non-open"" subset",,"Let $A\subset\mathbb{R}^n$ be a subset (not necessarily open) and $f:A\to\mathbb{R}$ be a map. As far as I have read, there are two definitions of the smoothness of $f$. [Definition 1] The map $f$ is smooth if and only if there exists an open set $U\subset\mathbb{R}^n$ and a smooth map $F:U\to\mathbb{R}$ such that  $A\subset U$ and $f=F$ on $A\cap U$. [Definition 2] The map $f$ is smooth if and only if for every $x\in\mathbb{R}^n$ there exists an open neighborhood $U$ of $x$ and a smooth map $F:U\to\mathbb{R}$ such that $f=F$ on $A\cap U$. Maybe Definition 1 is more usual than Definition 2. Definition 2 is seen in Lee's ""Introduction to smooth manifolds."" Now, I have a question. Are these two definitions equivalent? The implication [Definition 1]$\Rightarrow$[Definition 2] is clear. But the converse does not seem to be obvious. Is there any counterexample?","Let $A\subset\mathbb{R}^n$ be a subset (not necessarily open) and $f:A\to\mathbb{R}$ be a map. As far as I have read, there are two definitions of the smoothness of $f$. [Definition 1] The map $f$ is smooth if and only if there exists an open set $U\subset\mathbb{R}^n$ and a smooth map $F:U\to\mathbb{R}$ such that  $A\subset U$ and $f=F$ on $A\cap U$. [Definition 2] The map $f$ is smooth if and only if for every $x\in\mathbb{R}^n$ there exists an open neighborhood $U$ of $x$ and a smooth map $F:U\to\mathbb{R}$ such that $f=F$ on $A\cap U$. Maybe Definition 1 is more usual than Definition 2. Definition 2 is seen in Lee's ""Introduction to smooth manifolds."" Now, I have a question. Are these two definitions equivalent? The implication [Definition 1]$\Rightarrow$[Definition 2] is clear. But the converse does not seem to be obvious. Is there any counterexample?",,"['calculus', 'differential-geometry', 'smooth-manifolds']"
79,What is the meaning of the area bound by two curves?,What is the meaning of the area bound by two curves?,,"As the title states, I don't fully understand what the meaning of the area between two curves is, in an application sense. For example, if I was provided with the equations of two velocity curves, what does the area between some region from a to b mean? Is it the distance between the two objects in motion? Edit: Thanks to everyone that responded to the post, it was all very useful :D","As the title states, I don't fully understand what the meaning of the area between two curves is, in an application sense. For example, if I was provided with the equations of two velocity curves, what does the area between some region from a to b mean? Is it the distance between the two objects in motion? Edit: Thanks to everyone that responded to the post, it was all very useful :D",,"['calculus', 'integration']"
80,A very different alternative form of the geometric series,A very different alternative form of the geometric series,,While I was playing around with series that came up in a calculus assignment I came across this thing here: $$\lim_{n\to \infty} \sum_{i=1}^n \frac{1}{\sqrt[x]{n^{x-1}i}}$$ And after using wolframalpha to evaluate it at some positive real numbers $x$ it seems that $$\lim_{n\to \infty} \sum_{i=1}^n \frac{1}{\sqrt[x]{n^{x-1}i}} = \frac{x}{x-1}$$ which is the value of the geometric series with parameter $\frac{1}{x}$. Unfortunately I have no clue how to prove this.,While I was playing around with series that came up in a calculus assignment I came across this thing here: $$\lim_{n\to \infty} \sum_{i=1}^n \frac{1}{\sqrt[x]{n^{x-1}i}}$$ And after using wolframalpha to evaluate it at some positive real numbers $x$ it seems that $$\lim_{n\to \infty} \sum_{i=1}^n \frac{1}{\sqrt[x]{n^{x-1}i}} = \frac{x}{x-1}$$ which is the value of the geometric series with parameter $\frac{1}{x}$. Unfortunately I have no clue how to prove this.,,"['calculus', 'sequences-and-series', 'geometric-series']"
81,How to find $\lim_{x \to \infty} \frac{ex^{x+1}-x(x+1)^x}{(x+1)^x}$,How to find,\lim_{x \to \infty} \frac{ex^{x+1}-x(x+1)^x}{(x+1)^x},"I came across this problem a few days ago and I have not been able to solve it. Wolfram Alpha says the answer is 1/2 but the answer I came up with is 0. Can anyone see what is wrong with my work and/or provide the correct way of solving this problem? $$\lim_{x \to \infty} \frac{ex^{x+1}-x(x+1)^x}{(x+1)^x} $$ $$\lim_{x \to \infty} \frac{ex^{x+1}-x[(x)(1+\frac{1}{x})]^x}{[(x)(1+\frac{1}{x})]^x} $$ $$\lim_{x \to \infty} \frac{ex^{x+1}-x^{x+1}(1+\frac{1}{x})^x}{x^x(1+\frac{1}{x})^x} $$ $$\lim_{x \to \infty} \frac{ex^{x+1}-x^{x+1}e}{x^xe} $$ $$\lim_{x \to \infty} \frac{x-x}{1} $$ $$\lim_{x \to \infty} \frac{0}{1} $$ $$0$$ I understand my mistakes may be simple and trivial, but I'm trying to learn. Thank you for your help!","I came across this problem a few days ago and I have not been able to solve it. Wolfram Alpha says the answer is 1/2 but the answer I came up with is 0. Can anyone see what is wrong with my work and/or provide the correct way of solving this problem? $$\lim_{x \to \infty} \frac{ex^{x+1}-x(x+1)^x}{(x+1)^x} $$ $$\lim_{x \to \infty} \frac{ex^{x+1}-x[(x)(1+\frac{1}{x})]^x}{[(x)(1+\frac{1}{x})]^x} $$ $$\lim_{x \to \infty} \frac{ex^{x+1}-x^{x+1}(1+\frac{1}{x})^x}{x^x(1+\frac{1}{x})^x} $$ $$\lim_{x \to \infty} \frac{ex^{x+1}-x^{x+1}e}{x^xe} $$ $$\lim_{x \to \infty} \frac{x-x}{1} $$ $$\lim_{x \to \infty} \frac{0}{1} $$ $$0$$ I understand my mistakes may be simple and trivial, but I'm trying to learn. Thank you for your help!",,"['calculus', 'limits', 'rational-functions']"
82,Is the following correct $dx = \lim_{ \Delta x\to 0} \Delta x\ $?,Is the following correct ?,dx = \lim_{ \Delta x\to 0} \Delta x\ ,I hope your answer for this question will help me understand a lot of things. Thank you guys.,I hope your answer for this question will help me understand a lot of things. Thank you guys.,,"['calculus', 'limits', 'notation']"
83,The limit of a sequence,The limit of a sequence,,"Given $$x_n=\frac{1}{n^2+1}+\frac{1}{n^2+2}+\frac{1}{n^2+3}+\cdots+\frac{1}{n^2+n}$$ Verify if there is or no a limit. Find it if affirmative. Let $a_n=\frac{n}{n^2+1}$ (The biggest portion of the sum $n$ times)  and $b_n=\frac{n}{n^2+n}$ (the smallest portion of the sum $n$ times) then $$b_n\le x_n \le a_n$$ since$$\lim \frac{n}{n^2+1}=\lim \frac{n}{n^2+n}=0,$$ we have that $$\lim x_n=0.$$ Is this wrong? why? If it is, any tips on how to find $\lim x_n$? Grateful for any help. **Edited","Given $$x_n=\frac{1}{n^2+1}+\frac{1}{n^2+2}+\frac{1}{n^2+3}+\cdots+\frac{1}{n^2+n}$$ Verify if there is or no a limit. Find it if affirmative. Let $a_n=\frac{n}{n^2+1}$ (The biggest portion of the sum $n$ times)  and $b_n=\frac{n}{n^2+n}$ (the smallest portion of the sum $n$ times) then $$b_n\le x_n \le a_n$$ since$$\lim \frac{n}{n^2+1}=\lim \frac{n}{n^2+n}=0,$$ we have that $$\lim x_n=0.$$ Is this wrong? why? If it is, any tips on how to find $\lim x_n$? Grateful for any help. **Edited",,"['calculus', 'sequences-and-series', 'limits', 'summation', 'fractions']"
84,Double Integral of Minimum Function,Double Integral of Minimum Function,,"I was trying to solve the following integral: $$ \begin{equation} \int _0^{\alpha }\int _0^{\beta }\min (x,y)dydx \tag{1} \label{eq:1} \end{equation} $$ with $\alpha,\beta > 0$, (generally, $\alpha \ne \beta$). I've found a question from MSE ( how to solve double integral of a min function ) where an user suggested the following equivalence: $$ \begin{equation} \int_0^{\beta } \min (x,y) \, dy =\int_0^x \min (x,y) \, dy+\int_x^{\beta } \min(x,y) \, dy \\ =\int_0^x y \, dy+\int_x^{\beta } x \, dy \tag{2} \label{eq:2} \end{equation} $$ The explanation is in link above and I also found it by myself. The issue is that the $(1)$ and the $(2)$ inserted in $(1)$: $$ \int _0^{\alpha }\int _0^{\beta }\min (x,y)dydx \tag{1} $$ $$ \int _0^{\alpha } \bigg( \int_0^x y \, dy+\int_x^{\beta } x \, dy \bigg) dx \tag{3} $$ are giving me different results. In fact, generally, through different cases of $\alpha$ and $\beta$ I set, it seems that, if $\beta \ge \alpha$, the $(1)$ and $(3)$ are equivalent, else they aren't. What am I missing? Have I to suppose some conditions for the $(2)$ is effective? Is there a problem of integral interchange?","I was trying to solve the following integral: $$ \begin{equation} \int _0^{\alpha }\int _0^{\beta }\min (x,y)dydx \tag{1} \label{eq:1} \end{equation} $$ with $\alpha,\beta > 0$, (generally, $\alpha \ne \beta$). I've found a question from MSE ( how to solve double integral of a min function ) where an user suggested the following equivalence: $$ \begin{equation} \int_0^{\beta } \min (x,y) \, dy =\int_0^x \min (x,y) \, dy+\int_x^{\beta } \min(x,y) \, dy \\ =\int_0^x y \, dy+\int_x^{\beta } x \, dy \tag{2} \label{eq:2} \end{equation} $$ The explanation is in link above and I also found it by myself. The issue is that the $(1)$ and the $(2)$ inserted in $(1)$: $$ \int _0^{\alpha }\int _0^{\beta }\min (x,y)dydx \tag{1} $$ $$ \int _0^{\alpha } \bigg( \int_0^x y \, dy+\int_x^{\beta } x \, dy \bigg) dx \tag{3} $$ are giving me different results. In fact, generally, through different cases of $\alpha$ and $\beta$ I set, it seems that, if $\beta \ge \alpha$, the $(1)$ and $(3)$ are equivalent, else they aren't. What am I missing? Have I to suppose some conditions for the $(2)$ is effective? Is there a problem of integral interchange?",,"['calculus', 'integration', 'definite-integrals']"
85,Can we extend the proof of density of $\sin(n)$ to $\sin(n^2)$?,Can we extend the proof of density of  to ?,\sin(n) \sin(n^2),"We know that $(x_n)_{n\in\mathbb{N}} $ defined as $x_n=\sin(n) $ is dense in the interval $[-1,1]$ , can we extend this to prove also $\sin(n^2) $ is dense in $[-1,1]$ ? First i present my proof of density of $\sin(n)$ to let you understand the key step i have in mind to pass to $\sin(n^2) $ . Since $ \sin(n)=\sin(n+2k\pi) $ where $k\in \mathbb{Z}$ the problem is equivalent to prove $ n+2k\pi $ is dense in $\mathbb{R}$ , or equivalently $ n-2k\pi $ is dense in $[0,2\pi)$ it's enough. For the proof i will need this theorem: Dirichlet's approximation theorem For any real number $\alpha$ and natural number $N$ there exists integers $p,q$ with $ 1\le q \le N $ such that $$ |q\alpha-p|<\frac{1}{N} $$ A consequence of this theorem it's that for every irrational alpha $\alpha$ the inequality $$ \left|{\alpha -\frac{p}{q}} \right|<\frac{1}{q^2} \ \ \  \Longleftrightarrow \ \ \ |q\alpha-p|<\frac{1}{q} \ \ \ \ \ \ \ (*)$$ is satisfied for infinitely many integers $p,q$ . For $(*)$ there exists infinitely many integers $p,q$ such that $|2\pi q-p|<\frac{1}{q}$ this is equivalent to $ \inf_{n,m\in \mathbb{N}}|n-2\pi m|=0$ then $\forall \epsilon >0 $ there exists $m,n$ such that $ |n-2\pi m|<\epsilon $ . Now let $n-2\pi m = \Delta $ and $\alpha \in [0,2\pi) $ a real number. We have two cases: $\Delta>0 $ we have $ 0<\Delta < \epsilon $ and let $ k=\lfloor \frac{\alpha}{\Delta} \rfloor$ then $$ 0< \frac{\alpha}{\Delta} -k <1 \ \ \ \Longrightarrow \ \ \ \ 0<\alpha-k\Delta < \Delta $$ Then we have $$ 0<\alpha-k\Delta=\alpha-(kn-2\pi mk) < \Delta < \epsilon \ \ \ \ \ (1) $$ $\Delta<0 $ we have $ -\epsilon<\Delta < 0 $ and let $ k=\lfloor \frac{\alpha-2\pi}{\Delta} \rfloor$ then $$ 0< \frac{\alpha-2\pi}{\Delta} -k <1 \ \ \ \Longrightarrow \ \ \ \ 0> \alpha-2\pi-k\Delta > \Delta $$ Then $$ 0 >\alpha-2\pi-k\Delta = \alpha-(kn-2\pi (mk-1)) > \Delta >-\epsilon$$ So we have proved that $ \forall \epsilon >0 $ we can find a number $Q$ in the form $ Q=n-2\pi m $ for some $m,n$ integers such that $ |Q-\alpha|< \epsilon $ so the set $ \{ n-2\pi m \} $ is dense in $[0,2\pi) $ and our proof is complete. I tried to extend this proof to $\sin(n^2) $ but i failed, my main idea is : Can we find a ""cubic form"" or something similar to Dirichlet's approximation theorem? If we can find a statement with same hypothesis like, for some $c\in \mathbb{R} $ : $$ \left|{\alpha -\frac{p}{q}} \right|<\frac{1}{cq^3} \ \ \  \Longleftrightarrow \ \ \ |q\alpha-p|<\frac{1}{cq^2} \Longrightarrow |q^2\alpha-(pq)|<\frac{1}{cq}$$ we would be able to prove density of $ \{n^2-2\pi m \}$ in $[0,2\pi) $ . Does something similar do exist? Or we must go to a different approach?","We know that defined as is dense in the interval , can we extend this to prove also is dense in ? First i present my proof of density of to let you understand the key step i have in mind to pass to . Since where the problem is equivalent to prove is dense in , or equivalently is dense in it's enough. For the proof i will need this theorem: Dirichlet's approximation theorem For any real number and natural number there exists integers with such that A consequence of this theorem it's that for every irrational alpha the inequality is satisfied for infinitely many integers . For there exists infinitely many integers such that this is equivalent to then there exists such that . Now let and a real number. We have two cases: we have and let then Then we have we have and let then Then So we have proved that we can find a number in the form for some integers such that so the set is dense in and our proof is complete. I tried to extend this proof to but i failed, my main idea is : Can we find a ""cubic form"" or something similar to Dirichlet's approximation theorem? If we can find a statement with same hypothesis like, for some : we would be able to prove density of in . Does something similar do exist? Or we must go to a different approach?","(x_n)_{n\in\mathbb{N}}  x_n=\sin(n)  [-1,1] \sin(n^2)  [-1,1] \sin(n) \sin(n^2)   \sin(n)=\sin(n+2k\pi)  k\in \mathbb{Z}  n+2k\pi  \mathbb{R}  n-2k\pi  [0,2\pi) \alpha N p,q  1\le q \le N   |q\alpha-p|<\frac{1}{N}  \alpha  \left|{\alpha -\frac{p}{q}} \right|<\frac{1}{q^2} \ \ \  \Longleftrightarrow \ \ \ |q\alpha-p|<\frac{1}{q} \ \ \ \ \ \ \ (*) p,q (*) p,q |2\pi q-p|<\frac{1}{q}  \inf_{n,m\in \mathbb{N}}|n-2\pi m|=0 \forall \epsilon >0  m,n  |n-2\pi m|<\epsilon  n-2\pi m = \Delta  \alpha \in [0,2\pi)  \Delta>0   0<\Delta < \epsilon   k=\lfloor \frac{\alpha}{\Delta} \rfloor  0< \frac{\alpha}{\Delta} -k <1 \ \ \ \Longrightarrow \ \ \ \ 0<\alpha-k\Delta < \Delta   0<\alpha-k\Delta=\alpha-(kn-2\pi mk) < \Delta < \epsilon \ \ \ \ \ (1)  \Delta<0   -\epsilon<\Delta < 0   k=\lfloor \frac{\alpha-2\pi}{\Delta} \rfloor  0< \frac{\alpha-2\pi}{\Delta} -k <1 \ \ \ \Longrightarrow \ \ \ \ 0> \alpha-2\pi-k\Delta > \Delta   0 >\alpha-2\pi-k\Delta = \alpha-(kn-2\pi (mk-1)) > \Delta >-\epsilon  \forall \epsilon >0  Q  Q=n-2\pi m  m,n  |Q-\alpha|< \epsilon   \{ n-2\pi m \}  [0,2\pi)  \sin(n^2)  c\in \mathbb{R}   \left|{\alpha -\frac{p}{q}} \right|<\frac{1}{cq^3} \ \ \  \Longleftrightarrow \ \ \ |q\alpha-p|<\frac{1}{cq^2} \Longrightarrow |q^2\alpha-(pq)|<\frac{1}{cq}  \{n^2-2\pi m \} [0,2\pi) ","['calculus', 'general-topology', 'measure-theory', 'density-function']"
86,The relation between a polynomial's multiplicity and that of its derivative.,The relation between a polynomial's multiplicity and that of its derivative.,,"Say a polynomial $p(x)$ has $n$ real roots with a multiplicity of $k$. It can be shown that $p'(x)$ has a multiplicity of $k-1$. $$ p(x) = (x-a)^k\cdot h(x) $$ $$ p'(x) = k\cdot (x-a)^{k-1}\cdot h(x) + (x-a)^k\cdot h'(x)$$ $$ p'(x) = (x-a)^{k-1}(k\cdot h(x) + (x-a)\cdot h'(x))$$ Is it true in reverse? If I show that the derivative of a function $f(x)$ has a multiplicity of $k-1$, does this mean that $f(x)$ having multiplicity of $k$ is true?","Say a polynomial $p(x)$ has $n$ real roots with a multiplicity of $k$. It can be shown that $p'(x)$ has a multiplicity of $k-1$. $$ p(x) = (x-a)^k\cdot h(x) $$ $$ p'(x) = k\cdot (x-a)^{k-1}\cdot h(x) + (x-a)^k\cdot h'(x)$$ $$ p'(x) = (x-a)^{k-1}(k\cdot h(x) + (x-a)\cdot h'(x))$$ Is it true in reverse? If I show that the derivative of a function $f(x)$ has a multiplicity of $k-1$, does this mean that $f(x)$ having multiplicity of $k$ is true?",,"['calculus', 'algebra-precalculus', 'derivatives']"
87,integrate $\int\frac{x\cdot dx}{(x^3+1)^2}$,integrate,\int\frac{x\cdot dx}{(x^3+1)^2},"What methods are there to integrate: $$\int\frac{x\cdot dx}{(x^3+1)^2}$$ I know about partial fractions:  $$\int\frac{x\cdot dx}{(x^3+1)^2} $$ $$= \int\frac{x\cdot dx}{((x+1)(x^2-x+1))^2} $$ $$= \int \left(\frac{A}{x+1}+\frac{Bx+C}{(x+1)^2} + \frac{Dx+E}{x^2-x+1} + \frac{Fx^3+Gx^2+H+I}{(x^2-x+1)^2}\right)dx$$ and after this solving is easy, i was trying to do the same many times, but i can't find coefficients because mistakes or something other. I want to know about another methods to solve it.","What methods are there to integrate: $$\int\frac{x\cdot dx}{(x^3+1)^2}$$ I know about partial fractions:  $$\int\frac{x\cdot dx}{(x^3+1)^2} $$ $$= \int\frac{x\cdot dx}{((x+1)(x^2-x+1))^2} $$ $$= \int \left(\frac{A}{x+1}+\frac{Bx+C}{(x+1)^2} + \frac{Dx+E}{x^2-x+1} + \frac{Fx^3+Gx^2+H+I}{(x^2-x+1)^2}\right)dx$$ and after this solving is easy, i was trying to do the same many times, but i can't find coefficients because mistakes or something other. I want to know about another methods to solve it.",,"['calculus', 'integration', 'indefinite-integrals']"
88,Fractional part of normally distributed variable,Fractional part of normally distributed variable,,"Let $X$ be a normally distributed variable with mean $0$ and standard deviation $1$. I will consider its fractional part $$\overline{X} = X - \lfloor X \rfloor = X \, \bmod \, 1.$$ I have done some numerical testing and it seems likely that $\overline{X}$ is uniformly distributed on $[0,1].$ To be specific I computed $$\sum_{k=-200}^{200} \Big( \Phi(k+b) - \Phi(k+a) \Big)$$ for a few values of $b \ge a$ in $[0,1]$ and the result is consistently very close to $b-a$. Here is the code in Sage: I first define def Phi(x):     return (1/2 + erf(x / sqrt(2)) / 2).n() then a few examples of these computations: s = 0 for k in range(-200,200):     s = s + Phi(k+3/5) - Phi(k + 2/5) print s.n() 0.199999998998919 and s=0 for k in range(-200,200):     s = s + Phi(k+4/9) - Phi(k + 2/9) print s.n() 0.222222221674844 Question: is $\overline{X}$ in fact uniformly distributed? From the examples I've done I am confident that it is but I am not sure how to prove it.","Let $X$ be a normally distributed variable with mean $0$ and standard deviation $1$. I will consider its fractional part $$\overline{X} = X - \lfloor X \rfloor = X \, \bmod \, 1.$$ I have done some numerical testing and it seems likely that $\overline{X}$ is uniformly distributed on $[0,1].$ To be specific I computed $$\sum_{k=-200}^{200} \Big( \Phi(k+b) - \Phi(k+a) \Big)$$ for a few values of $b \ge a$ in $[0,1]$ and the result is consistently very close to $b-a$. Here is the code in Sage: I first define def Phi(x):     return (1/2 + erf(x / sqrt(2)) / 2).n() then a few examples of these computations: s = 0 for k in range(-200,200):     s = s + Phi(k+3/5) - Phi(k + 2/5) print s.n() 0.199999998998919 and s=0 for k in range(-200,200):     s = s + Phi(k+4/9) - Phi(k + 2/9) print s.n() 0.222222221674844 Question: is $\overline{X}$ in fact uniformly distributed? From the examples I've done I am confident that it is but I am not sure how to prove it.",,"['calculus', 'probability', 'error-function']"
89,Does $\int _0^{\infty }\:\frac{1}{1+x^2\left(\sin x\right)^2}\ \operatorname dx$ converge?,Does  converge?,\int _0^{\infty }\:\frac{1}{1+x^2\left(\sin x\right)^2}\ \operatorname dx,I have been trying to prove the following integral: $$\int _0^{\infty }\:\frac{1}{1+x^2\left(\sin x\right)^2}\ dx$$ diverges (please correct me if I am mistaken). I have tried to use different comparison tests (as this is an integral of a positive function) with no success. Any ideas?,I have been trying to prove the following integral: $$\int _0^{\infty }\:\frac{1}{1+x^2\left(\sin x\right)^2}\ dx$$ diverges (please correct me if I am mistaken). I have tried to use different comparison tests (as this is an integral of a positive function) with no success. Any ideas?,,"['calculus', 'integration', 'convergence-divergence', 'improper-integrals']"
90,Why does Euler's formula have to be $e^{ix} = \cos(x) + i\sin(x)$,Why does Euler's formula have to be,e^{ix} = \cos(x) + i\sin(x),In part one of this youtube video the uploader goes on to explain the calculus proof for Euler's Formula. The Formula $$e^{ix} = \cos(x) + i\sin(x)$$ Differentiate $$ie^{ix} = f'(x) + i g'(x)$$ Multiply original formula by $i$ $$ie^{ix} = if(x) - g(x)$$ Equate the differentiation and the multiplied version $$f'(x) + ig'(x) = if(x) - g(x)$$ Equate real and imaginary (and cancel the i) $$f'(x) = -g(x) \qquad g'(x) = f(x)$$ Then he goes on to explain $f(x) = \cos(x)$ and $g(x) = \sin(x)$. My question is why can't $f(x) = \sin(x)$ and $g(x) = -\cos(x)$? Can further proof be added to this proof to eliminate $f(x) = \sin(x)$ and $g(x) = -\cos(x)$?,In part one of this youtube video the uploader goes on to explain the calculus proof for Euler's Formula. The Formula $$e^{ix} = \cos(x) + i\sin(x)$$ Differentiate $$ie^{ix} = f'(x) + i g'(x)$$ Multiply original formula by $i$ $$ie^{ix} = if(x) - g(x)$$ Equate the differentiation and the multiplied version $$f'(x) + ig'(x) = if(x) - g(x)$$ Equate real and imaginary (and cancel the i) $$f'(x) = -g(x) \qquad g'(x) = f(x)$$ Then he goes on to explain $f(x) = \cos(x)$ and $g(x) = \sin(x)$. My question is why can't $f(x) = \sin(x)$ and $g(x) = -\cos(x)$? Can further proof be added to this proof to eliminate $f(x) = \sin(x)$ and $g(x) = -\cos(x)$?,,"['calculus', 'complex-analysis', 'proof-verification', 'complex-numbers', 'proof-explanation']"
91,To Find $\int_0^{\pi} \frac{\sin(x)}{1+\sin(x)}$ why the substitution of $\sin(x)=t$ Gives wrong answer?,To Find  why the substitution of  Gives wrong answer?,\int_0^{\pi} \frac{\sin(x)}{1+\sin(x)} \sin(x)=t,"To find out this basic integral  $$\int_0^{\pi} \frac{\sin(x)}{1+\sin(x)} \,\mathrm{d}x$$ I though of two methods : Method 1: I started by multiplying and dividing by $1-\sin(x)$  and then manipulating it one easily gets - $$\int_0^{\pi} {(\sec(x)\tan(x) - (\tan(x))^2})\,\mathrm{d}x$$ Which is quite easy to calculate and gives value of $\pi-2$ I do not have any problem with this method , even though it took me some time to solve it. Method 2 :  This was first thing I had thought of : To let $\sin(x)=t$ and then when I tried to change the limits of integral I found that this substitution makes both upper and lower limits as $t=0$ which would give The value of above integral = 0 , according to the property $\int_a^a f(x)\,\mathrm{d}x = 0$. But the previous method gives answer of $\pi-2$ then what is wrong with the method 2 . Is that substitution incorrect ? But how and why ?","To find out this basic integral  $$\int_0^{\pi} \frac{\sin(x)}{1+\sin(x)} \,\mathrm{d}x$$ I though of two methods : Method 1: I started by multiplying and dividing by $1-\sin(x)$  and then manipulating it one easily gets - $$\int_0^{\pi} {(\sec(x)\tan(x) - (\tan(x))^2})\,\mathrm{d}x$$ Which is quite easy to calculate and gives value of $\pi-2$ I do not have any problem with this method , even though it took me some time to solve it. Method 2 :  This was first thing I had thought of : To let $\sin(x)=t$ and then when I tried to change the limits of integral I found that this substitution makes both upper and lower limits as $t=0$ which would give The value of above integral = 0 , according to the property $\int_a^a f(x)\,\mathrm{d}x = 0$. But the previous method gives answer of $\pi-2$ then what is wrong with the method 2 . Is that substitution incorrect ? But how and why ?",,"['calculus', 'definite-integrals']"
92,Evaluating $\int\sqrt{1-\sin x}\ dx$,Evaluating,\int\sqrt{1-\sin x}\ dx,"One of the method to find the integral $$\int\sqrt{1-\sin x}\ dx$$ is by multiplying by $\dfrac{1+\sin x}{1+\sin x}$ inside the root. Then, by using the identity $\sin^2x+\cos^2x=1$ , we get $$\int\dfrac{\sqrt{\cos^2x}}{\sqrt{1+\sin x}}\ dx$$ The next step is we remove the square with the root and using the substitution $u=\sin x$. My question is why ? Why don't we put an absolute value of $\cos x$? So, we have two answers. Is this situation always true in any similar situation in indefinite integrals? Sorry, if my question is trivial. Thanks","One of the method to find the integral $$\int\sqrt{1-\sin x}\ dx$$ is by multiplying by $\dfrac{1+\sin x}{1+\sin x}$ inside the root. Then, by using the identity $\sin^2x+\cos^2x=1$ , we get $$\int\dfrac{\sqrt{\cos^2x}}{\sqrt{1+\sin x}}\ dx$$ The next step is we remove the square with the root and using the substitution $u=\sin x$. My question is why ? Why don't we put an absolute value of $\cos x$? So, we have two answers. Is this situation always true in any similar situation in indefinite integrals? Sorry, if my question is trivial. Thanks",,"['calculus', 'integration']"
93,An Alternate Solution to a Differential Equation,An Alternate Solution to a Differential Equation,,"The main question being asked: is it possible an $f(x)$ which satisfies the below equation where $u=u(x)$ ;if so, how? $$\boxed{ \frac{df(u^2)}{d(u^2)} = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \quad ,u = u(x)\qquad(*)}$$ or similarly after using the transformation in the Remarks section: $$\boxed{\frac{df(u^2)}{du} = 2u\left[\left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2}\right] \quad ,u = u(x) \qquad (**)}$$ Part 1 : This stems from the initial question assigned to me which was: Find an $f(x)$ which satisfies: $$ f'(\sin^2x) = \cos^2x + \tan^2x, \quad 0<x<1$$ ( I have left this part in 'prime' notation because this is how the original question was presented. ) The proper solution involves the following method: $$ f'(\sin^2x) = (1-\sin^2x) + \frac{\sin^2 x}{1-\sin^2 x}$$ Let $u = \sin^2x$ , then: $$ f'(u) = (1 - u) + \frac{u}{1-u}$$ $$ f(u) = \int\,\left[(1 - u) + \frac{u}{1-u} \right] du$$ $$ f(u) = \int\,\left[(1 - u) + \frac{u-1+1}{1-u} \right] du$$ $$  = \int\,\left[-u + \frac{1}{1-u} \right] du$$ $$ \therefore f(x) = -\frac{1}{2}u^2-\ln|1-u|=-\frac{1}{2}x^2-\ln|1-x|$$ Part 2: My question is if this can  be solved with the following alternate method: $$ \frac{d(f(\sin^2x))}{d(\sin^2x)} = \cos^2x + \tan^2x, \quad 0<x<1$$ then, $$\frac{d(f(\sin^2x))}{d(\sin^2x)} = \cos^2x + \frac{\sin^2x}{\cos^2x}$$ Let $u = \sin x$ , $du = \cos x\,dx$ then: $$ \frac{d(f(u^2))}{d(u^2)} = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \qquad$$ Can this equation be solved to find an $f(x)$ which satisfies this relation regardless of what $u(x)$ actually is? See Main Edit 1&2 for clarification on why it is in this form The following steps are INCORRECT, as this is not how the chain rule works. But there is something in my head grinding such that I feel that it can be solved in a way invoking the chain rule but I can't get my thoughts wrapped around it properly. ( I have left this part in 'prime' notation because this displays my erroneous thought process of misunderstanding differentials which probably led me to the wrong answer. ) $$ 2u\, f'(u) = \left(u'\right)^2 +\frac{u^2}{\left(u'\right)^2}$$ Clearly $ f'(u^2) \ne 2u\, f'(u)$ , however continuing with this incorrect thought.. $$ f'(u) = \frac{1}{2} \left[\frac{\left(u'\right)^2}{u}+\frac{u}{u'}\right]$$ $$ f(u) = \int\frac{1}{2} \left[\frac{\left(u'\right)^2}{u}+\frac{u}{u'}\right] $$ Is there anyway I can actually correctly use the chain rule starting from $(*)$ to reach this point and then integrate, or solve it through some method for differential equations? I've never experienced a question with the square of a derivative so I was wondering if someone could give me insight on this. Main Edit 1: As @JJacquelin noted, the notation with 'prime' causes quite problem with what the question being asked is: Using the fact that $u = \sin x\,\, \text{is a function of}\, x$ The line: $$ f'(u^2) = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \qquad$$ can be written as such: $$ \frac{df(u^2)}{d(u^2)} = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \quad ,u = u(x) \qquad(*)$$ And as so, I have replaced all appropriate parts of this post with Leibniz notation to suggest clarity. Now can I find an $f(x)$ which satisfies this equation? I have left my previous work as is, so that I may reference it one day in case I come across a problem of pinpointing what my prime notation means. Please do let me know if there are any further clarifications that need to be made before this can be solved properly. Edit 2: Proof of why [ incorrectly ] believed it is $\frac{d}{dx}$ : Thank you to @JJacquelin once again for helping me clarify the differentials in the question. I have edited the general question with reflection to their analysis, and hope to recieve the answer I was looking for now that the notion of differentials is cleared up. I was incorrect in my reasoning before and it is actually $\frac{df(X)}{dX}$ for any dummy variable $X$ , contrary to what I had thought as you can see below.: If we start from the solution of Part 1: $$f(x) = -\frac{1}{2}x^2-\ln|1-x|$$ $$\frac{df(x)}{dx} = -x+\frac{1}{1-x}$$ $$\frac{df(x)}{dx} = -x+\frac{1-x+x}{1-x}$$ $$\frac{df(x)}{dx} = -x+\frac{1-x}{1-x}+\frac{x}{1-x}$$ $$\frac{df(x)}{dx} = -x + 1 + \frac{x}{1-x}$$ $$\frac{df(x)}{dx} = 1 - x +\frac{x}{1-x}$$ Now $x \mapsto \sin^2x$ : $$\frac{df(\sin^2x)}{dx} = 1 -\sin^2x+\frac{\sin^2x}{1-\sin^2x}$$ $$\frac{df(\sin^2x)}{dx} = \cos^2x + \tan^2x$$ But this turns out to be wrong, when $x\mapsto \sin^2 x$ it becomes : $$\frac{df(\sin^2x)}{d(\sin^2x)} = \cos^2x + \tan^2x$$ $$f'(\sin^2x)=\cos^2x + \tan^2x$$ Which is what we started with. Now I am beginning to doubt my self, because I am not sure if the $dx$ changes to $d(\sin^2x)$ when $x\mapsto\sin^2x$ . I would appreciate it if someone could help me realize which one it is, because then I can't begin to even grasp the main question without formulating the correct statement. Thank you for @JJacquelin clearing this up . Remarks : On another note, I looked back to some of my differential work from university and came across a homework problem we proved which shows that: $$\frac{d^2x}{dy^2}= -\frac{\frac{d^2y}{dx^2}}{\left(\frac{dy}{dx}\right)^3}$$ Which leads me to wonder, can the terms $\left(\frac{du}{dx}\right)^2$ be transformed into some $n$ -th derivative? More generally, are there possible transformations to convert powers of derivatives to $n$ -th derivatives in order to simplify this problem into a differential equation which can be solved using usual methods? Also something @JJacquelin helped me realize about use of the chain rule, which may be of some help to progress: $$\frac{df(u^2)}{d(u^2)}= \frac{df(u^2)}{2udu}$$ which may simplify the original question to: $$\frac{df(u^2)}{du} = 2u\left[\left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2}\right] \quad ,u = u(x) \qquad (**)$$ These two identities might be of some help...possibly.","The main question being asked: is it possible an which satisfies the below equation where ;if so, how? or similarly after using the transformation in the Remarks section: Part 1 : This stems from the initial question assigned to me which was: Find an which satisfies: ( I have left this part in 'prime' notation because this is how the original question was presented. ) The proper solution involves the following method: Let , then: Part 2: My question is if this can  be solved with the following alternate method: then, Let , then: Can this equation be solved to find an which satisfies this relation regardless of what actually is? See Main Edit 1&2 for clarification on why it is in this form The following steps are INCORRECT, as this is not how the chain rule works. But there is something in my head grinding such that I feel that it can be solved in a way invoking the chain rule but I can't get my thoughts wrapped around it properly. ( I have left this part in 'prime' notation because this displays my erroneous thought process of misunderstanding differentials which probably led me to the wrong answer. ) Clearly , however continuing with this incorrect thought.. Is there anyway I can actually correctly use the chain rule starting from to reach this point and then integrate, or solve it through some method for differential equations? I've never experienced a question with the square of a derivative so I was wondering if someone could give me insight on this. Main Edit 1: As @JJacquelin noted, the notation with 'prime' causes quite problem with what the question being asked is: Using the fact that The line: can be written as such: And as so, I have replaced all appropriate parts of this post with Leibniz notation to suggest clarity. Now can I find an which satisfies this equation? I have left my previous work as is, so that I may reference it one day in case I come across a problem of pinpointing what my prime notation means. Please do let me know if there are any further clarifications that need to be made before this can be solved properly. Edit 2: Proof of why [ incorrectly ] believed it is : Thank you to @JJacquelin once again for helping me clarify the differentials in the question. I have edited the general question with reflection to their analysis, and hope to recieve the answer I was looking for now that the notion of differentials is cleared up. I was incorrect in my reasoning before and it is actually for any dummy variable , contrary to what I had thought as you can see below.: If we start from the solution of Part 1: Now : But this turns out to be wrong, when it becomes : Which is what we started with. Now I am beginning to doubt my self, because I am not sure if the changes to when . I would appreciate it if someone could help me realize which one it is, because then I can't begin to even grasp the main question without formulating the correct statement. Thank you for @JJacquelin clearing this up . Remarks : On another note, I looked back to some of my differential work from university and came across a homework problem we proved which shows that: Which leads me to wonder, can the terms be transformed into some -th derivative? More generally, are there possible transformations to convert powers of derivatives to -th derivatives in order to simplify this problem into a differential equation which can be solved using usual methods? Also something @JJacquelin helped me realize about use of the chain rule, which may be of some help to progress: which may simplify the original question to: These two identities might be of some help...possibly.","f(x) u=u(x) \boxed{ \frac{df(u^2)}{d(u^2)} = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \quad ,u = u(x)\qquad(*)} \boxed{\frac{df(u^2)}{du} = 2u\left[\left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2}\right] \quad ,u = u(x) \qquad (**)} f(x)  f'(\sin^2x) = \cos^2x + \tan^2x, \quad 0<x<1  f'(\sin^2x) = (1-\sin^2x) + \frac{\sin^2 x}{1-\sin^2 x} u = \sin^2x  f'(u) = (1 - u) + \frac{u}{1-u}  f(u) = \int\,\left[(1 - u) + \frac{u}{1-u} \right] du  f(u) = \int\,\left[(1 - u) + \frac{u-1+1}{1-u} \right] du   = \int\,\left[-u + \frac{1}{1-u} \right] du  \therefore f(x) = -\frac{1}{2}u^2-\ln|1-u|=-\frac{1}{2}x^2-\ln|1-x|  \frac{d(f(\sin^2x))}{d(\sin^2x)} = \cos^2x + \tan^2x, \quad 0<x<1 \frac{d(f(\sin^2x))}{d(\sin^2x)} = \cos^2x + \frac{\sin^2x}{\cos^2x} u = \sin x du = \cos x\,dx  \frac{d(f(u^2))}{d(u^2)} = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \qquad f(x) u(x)  2u\, f'(u) = \left(u'\right)^2 +\frac{u^2}{\left(u'\right)^2}  f'(u^2) \ne 2u\, f'(u)  f'(u) = \frac{1}{2} \left[\frac{\left(u'\right)^2}{u}+\frac{u}{u'}\right]  f(u) = \int\frac{1}{2} \left[\frac{\left(u'\right)^2}{u}+\frac{u}{u'}\right]  (*) u = \sin x\,\, \text{is a function of}\, x  f'(u^2) = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \qquad  \frac{df(u^2)}{d(u^2)} = \left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2} \quad ,u = u(x) \qquad(*) f(x) \frac{d}{dx} \frac{df(X)}{dX} X f(x) = -\frac{1}{2}x^2-\ln|1-x| \frac{df(x)}{dx} = -x+\frac{1}{1-x} \frac{df(x)}{dx} = -x+\frac{1-x+x}{1-x} \frac{df(x)}{dx} = -x+\frac{1-x}{1-x}+\frac{x}{1-x} \frac{df(x)}{dx} = -x + 1 + \frac{x}{1-x} \frac{df(x)}{dx} = 1 - x +\frac{x}{1-x} x \mapsto \sin^2x \frac{df(\sin^2x)}{dx} = 1 -\sin^2x+\frac{\sin^2x}{1-\sin^2x} \frac{df(\sin^2x)}{dx} = \cos^2x + \tan^2x x\mapsto \sin^2 x \frac{df(\sin^2x)}{d(\sin^2x)} = \cos^2x + \tan^2x f'(\sin^2x)=\cos^2x + \tan^2x dx d(\sin^2x) x\mapsto\sin^2x \frac{d^2x}{dy^2}= -\frac{\frac{d^2y}{dx^2}}{\left(\frac{dy}{dx}\right)^3} \left(\frac{du}{dx}\right)^2 n n \frac{df(u^2)}{d(u^2)}= \frac{df(u^2)}{2udu} \frac{df(u^2)}{du} = 2u\left[\left(\frac{du}{dx}\right)^2 + \frac{u^2}{\left(\frac{du}{dx}\right)^2}\right] \quad ,u = u(x) \qquad (**)","['calculus', 'integration', 'ordinary-differential-equations', 'derivatives']"
94,$\int_{0}^{1}{2n-x-x^3-x^5-\cdots-x^{4n-1}\over 1+x^2}\cdot{\mathrm dx\over \ln{x}}$,,\int_{0}^{1}{2n-x-x^3-x^5-\cdots-x^{4n-1}\over 1+x^2}\cdot{\mathrm dx\over \ln{x}},Consider $$\int_{0}^{1}{2n-x-x^3-x^5-\cdots-x^{4n-1}\over 1+x^2}\cdot{\mathrm dx\over \ln{x}}=I\tag1$$   $n\ge1$ How does one show that $I=2n\ln{\Gamma(3/4)\over \Gamma(5/4)}-\ln{[8^n(2n-1)!!]}?$ An attempt: $J=x+x^3+x^5+x^7+\cdots+$ $J=x(1+x^2+x^4+x^6+\cdots+)$ Geometric series $1+x+x^2+x^3+\cdots x^{n-1}={x(1-x^n)\over 1-x}$ $1+x^2+x^4+x^6+\cdots+x^{2n-2}={x^2(1-x^{2n})\over 1-x^2}$ $I$ becomes $$2n\int_{0}^{1}{1\over 1+x^2}\cdot{\mathrm dx\over \ln{x}}-\int_{0}^{1}{1-x^{2n}\over 1+x^2}\cdot{x^3\over \ln{x}}\mathrm dx=I\tag2$$ $x=\tan{y}$ then $dx=\sec^2{y}dy$ $$\int_{0}^{\pi/4}{1\over \ln{\tan{y}}}\mathrm dy-\int_{0}^{\pi/4}{1-\tan^{2n}{y}\over \ln{\tan{y}}}\cdot\tan^3{y}\mathrm dy\tag3$$ $$\int_{0}^{\pi/4}{1-\tan^3{y}\over \ln{\tan{y}}}\mathrm dy-\int_{0}^{\pi/4}{\tan^{2n}{y}\over \ln{\tan{y}}}\cdot\tan^3{y}\mathrm dy\tag4$$ $1-x^3=(1-x)(1+x+x^2)$ I am not sure what to do next,Consider $$\int_{0}^{1}{2n-x-x^3-x^5-\cdots-x^{4n-1}\over 1+x^2}\cdot{\mathrm dx\over \ln{x}}=I\tag1$$   $n\ge1$ How does one show that $I=2n\ln{\Gamma(3/4)\over \Gamma(5/4)}-\ln{[8^n(2n-1)!!]}?$ An attempt: $J=x+x^3+x^5+x^7+\cdots+$ $J=x(1+x^2+x^4+x^6+\cdots+)$ Geometric series $1+x+x^2+x^3+\cdots x^{n-1}={x(1-x^n)\over 1-x}$ $1+x^2+x^4+x^6+\cdots+x^{2n-2}={x^2(1-x^{2n})\over 1-x^2}$ $I$ becomes $$2n\int_{0}^{1}{1\over 1+x^2}\cdot{\mathrm dx\over \ln{x}}-\int_{0}^{1}{1-x^{2n}\over 1+x^2}\cdot{x^3\over \ln{x}}\mathrm dx=I\tag2$$ $x=\tan{y}$ then $dx=\sec^2{y}dy$ $$\int_{0}^{\pi/4}{1\over \ln{\tan{y}}}\mathrm dy-\int_{0}^{\pi/4}{1-\tan^{2n}{y}\over \ln{\tan{y}}}\cdot\tan^3{y}\mathrm dy\tag3$$ $$\int_{0}^{\pi/4}{1-\tan^3{y}\over \ln{\tan{y}}}\mathrm dy-\int_{0}^{\pi/4}{\tan^{2n}{y}\over \ln{\tan{y}}}\cdot\tan^3{y}\mathrm dy\tag4$$ $1-x^3=(1-x)(1+x+x^2)$ I am not sure what to do next,,"['calculus', 'integration', 'definite-integrals', 'power-series']"
95,Triple Integral $\iiint x^{2n}+y^{2n}+z^{2n}dV$,Triple Integral,\iiint x^{2n}+y^{2n}+z^{2n}dV,"Evaluate: $$\iiint_{x^2+y^2+z^2 \leqslant 1} x^{2n}+y^{2n}+z^{2n} dV $$ I have tried to convert to spherical polars and then compute the integral, but it gets really messy because of the 2n power. Any tips?","Evaluate: $$\iiint_{x^2+y^2+z^2 \leqslant 1} x^{2n}+y^{2n}+z^{2n} dV $$ I have tried to convert to spherical polars and then compute the integral, but it gets really messy because of the 2n power. Any tips?",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals']"
96,"What is $_3F_2\left(1,\frac32,2;\ \frac43,\frac53;\ \frac4{27}\right)$ as an integral?",What is  as an integral?,"_3F_2\left(1,\frac32,2;\ \frac43,\frac53;\ \frac4{27}\right)","This was buried in a rather long question , so I'm asking it separately to give it some air. Define, $$A_3={_3F_2}\left(1,\frac{\color{blue}1}2,\frac22;\ \frac43,\frac53;\ \frac4{27}\right)$$ $$B_3={_3F_2}\left(1,\frac{\color{blue}2}2,\frac32;\ \frac43,\frac53;\ \frac4{27}\right)$$ $$C_3={_3F_2}\left(1,\frac{\color{blue}3}2,\frac42;\ \frac43,\frac53;\ \frac4{27}\right)$$ These generalized hypergeometric functions belong to infinite families that differ in the starting numerator (in blue). Given the three roots $x_n$ of $x^3-x+1=0$. Then, $$\frac12 A_3= \int_1^\infty \frac{-3+2x}{x^3-x+1}dx =-\sum_{n=1}^3 x_n\ln(1-x_n)=0.517977\dots$$ $$\frac13 B_3 = \int_1^\infty\frac1{x(x^3-x+1)}dx=-\sum_{n=1}^3 \frac{\ln(1-x_n)}{-3+2x_n}=0.371216\dots$$ Q: But what is $\displaystyle C_3 = 3\sum_{n=1}^\infty\frac1{\binom{3n}n}$  as a similar integral? $\color{green}{Update:}$ Courtesy of David H's answer, by generalizing we find, $$k\sum_{n=1}^\infty\frac1{\binom{kn}n}=\int_1^\infty\frac1{(x^k-x+1)^2}dx$$ hence, $$C_3 = \int_1^\infty\frac1{(x^3-x+1)^2}dx=\tfrac{12}{23}-\tfrac{6}{23}\sum_{n=1}^3 \frac{3x_n + x_n^2}{-3+2x_n}\,\ln(1-x_n)=1.242966\dots$$ and a closed-form using the roots $x_n$.","This was buried in a rather long question , so I'm asking it separately to give it some air. Define, $$A_3={_3F_2}\left(1,\frac{\color{blue}1}2,\frac22;\ \frac43,\frac53;\ \frac4{27}\right)$$ $$B_3={_3F_2}\left(1,\frac{\color{blue}2}2,\frac32;\ \frac43,\frac53;\ \frac4{27}\right)$$ $$C_3={_3F_2}\left(1,\frac{\color{blue}3}2,\frac42;\ \frac43,\frac53;\ \frac4{27}\right)$$ These generalized hypergeometric functions belong to infinite families that differ in the starting numerator (in blue). Given the three roots $x_n$ of $x^3-x+1=0$. Then, $$\frac12 A_3= \int_1^\infty \frac{-3+2x}{x^3-x+1}dx =-\sum_{n=1}^3 x_n\ln(1-x_n)=0.517977\dots$$ $$\frac13 B_3 = \int_1^\infty\frac1{x(x^3-x+1)}dx=-\sum_{n=1}^3 \frac{\ln(1-x_n)}{-3+2x_n}=0.371216\dots$$ Q: But what is $\displaystyle C_3 = 3\sum_{n=1}^\infty\frac1{\binom{3n}n}$  as a similar integral? $\color{green}{Update:}$ Courtesy of David H's answer, by generalizing we find, $$k\sum_{n=1}^\infty\frac1{\binom{kn}n}=\int_1^\infty\frac1{(x^k-x+1)^2}dx$$ hence, $$C_3 = \int_1^\infty\frac1{(x^3-x+1)^2}dx=\tfrac{12}{23}-\tfrac{6}{23}\sum_{n=1}^3 \frac{3x_n + x_n^2}{-3+2x_n}\,\ln(1-x_n)=1.242966\dots$$ and a closed-form using the roots $x_n$.",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'hypergeometric-function']"
97,Checking if Tedious Limit is $0$.,Checking if Tedious Limit is .,0,"I am trying to rigorously (without a calculator) show $$\lim_{n\to \infty }\sqrt{n}\color{blue}{{{n}\choose {\Big[ np + \sqrt{np(1-p)}\,\Big]}}p^{\Big[np + \sqrt{np(1-p)} \,\Big]}{(1-p)^{\bigg(n-\Big[np + \sqrt{np(1-p)}\,\Big]\bigg)}}}=0$$ where $0<p<1$ and $[\cdot ]$ denotes the nearest integer.  This limit was formed while playing with the $\color{blue}{\text{binomial mass function}}$ and while fiddling with the proof of the DeMoivre/Laplace Central Limit Theorem: https://en.wikipedia.org/wiki/De_Moivre%E2%80%93Laplace_theorem I am not completely convinced that the limit is 0, but after seeing some computations on Mathematica https://mathematica.stackexchange.com/questions/134523/why-wont-limit-evaluate-and-what-can-be-done-about-it?noredirect=1#comment362965_134523 , I see that it tends to $0$ for several rational values of $p$. I want to see whether the limit is $0$ for all $p$ in $(0,1)$. What I've tried: (1) Using ${{a}\choose{b}}\le (\frac{ae}{b})^b$ and dropping $[ \cdot]$ for simplicity (and hopefully at no cost) to get $$\sqrt{n}\Bigg(\frac{ne}{np + \sqrt{np(1-p)}}\Bigg)^{np + \sqrt{np(1-p)}}p^{np + \sqrt{np(1-p)}}(1-p)^{n-np + \sqrt{np(1-p)}} \\\le \sqrt{n}\Bigg(\frac{nep}{np(1-p)+n\sqrt{\frac{p(1-p)}{n}}(1-p) }\Bigg)^{np+ \sqrt{np(1-p)}}(1-p)^n\\\le \sqrt{n}\bigg(\frac{e}{(1-p)}\bigg)^{2np}(1-p)^n$$ but according to Mathematica the latest expression doesn't tend to 0, so I may need a better upper bound.","I am trying to rigorously (without a calculator) show $$\lim_{n\to \infty }\sqrt{n}\color{blue}{{{n}\choose {\Big[ np + \sqrt{np(1-p)}\,\Big]}}p^{\Big[np + \sqrt{np(1-p)} \,\Big]}{(1-p)^{\bigg(n-\Big[np + \sqrt{np(1-p)}\,\Big]\bigg)}}}=0$$ where $0<p<1$ and $[\cdot ]$ denotes the nearest integer.  This limit was formed while playing with the $\color{blue}{\text{binomial mass function}}$ and while fiddling with the proof of the DeMoivre/Laplace Central Limit Theorem: https://en.wikipedia.org/wiki/De_Moivre%E2%80%93Laplace_theorem I am not completely convinced that the limit is 0, but after seeing some computations on Mathematica https://mathematica.stackexchange.com/questions/134523/why-wont-limit-evaluate-and-what-can-be-done-about-it?noredirect=1#comment362965_134523 , I see that it tends to $0$ for several rational values of $p$. I want to see whether the limit is $0$ for all $p$ in $(0,1)$. What I've tried: (1) Using ${{a}\choose{b}}\le (\frac{ae}{b})^b$ and dropping $[ \cdot]$ for simplicity (and hopefully at no cost) to get $$\sqrt{n}\Bigg(\frac{ne}{np + \sqrt{np(1-p)}}\Bigg)^{np + \sqrt{np(1-p)}}p^{np + \sqrt{np(1-p)}}(1-p)^{n-np + \sqrt{np(1-p)}} \\\le \sqrt{n}\Bigg(\frac{nep}{np(1-p)+n\sqrt{\frac{p(1-p)}{n}}(1-p) }\Bigg)^{np+ \sqrt{np(1-p)}}(1-p)^n\\\le \sqrt{n}\bigg(\frac{e}{(1-p)}\bigg)^{2np}(1-p)^n$$ but according to Mathematica the latest expression doesn't tend to 0, so I may need a better upper bound.",,"['calculus', 'limits', 'computational-mathematics']"
98,Prove $f(x)\le0$ if $f(0)=0$ and $\int_0^xf(t)\mathbb dt\ge xf(x)$,Prove  if  and,f(x)\le0 f(0)=0 \int_0^xf(t)\mathbb dt\ge xf(x),$f(x)$ is a differentiable real valued function that satisfies following conditions:   $$f(0)=0$$   $$\int_0^xf(t)\mathbb dt\ge xf(x)\quad$$   Prove that for all $x>0$   $$f(x)\le0$$ I tried but couldn't derive the conclusion from the given conditions. $f(x)$ seems to have to decrease around $x=0$ but not necessarily for all $x$.,$f(x)$ is a differentiable real valued function that satisfies following conditions:   $$f(0)=0$$   $$\int_0^xf(t)\mathbb dt\ge xf(x)\quad$$   Prove that for all $x>0$   $$f(x)\le0$$ I tried but couldn't derive the conclusion from the given conditions. $f(x)$ seems to have to decrease around $x=0$ but not necessarily for all $x$.,,"['calculus', 'integral-inequality']"
99,Is $f(x)$ necessarily a polynomial if $f(f(x))$ is?,Is  necessarily a polynomial if  is?,f(x) f(f(x)),"If $g(x)$ is a polynomial, and $$g(x) = f(f(x))\ \forall x\in \mathbb{R}$$ is $f(x)$ necessarily a polynomial, given that $f$ is infinitely differentiable? Reading this question I noticed that the answer fails if we consider the domain to be the whole real line. I'm wondering whether removing the increasing condition allows for solutions that work across the whole real line, without allowing for ""weird"" functions like $$f(x) = \left|x\right|^{\sqrt{2}}$$ hence the infinitely differentiable condition. The only progress I've mad on this is as follows: Assume $g(x)$ has degree $d$ and leading coefficient $a$. Thus $$\lim_{x\to\infty} \frac{g(x)}{ax^d} = 1$$ $$\lim_{x\to\infty} \frac{f(f(x))}{ax^d} = 1$$ If $$x^{k-\epsilon} << f(x) << x^{k+\epsilon}\ \forall\ \epsilon>0$$ for some $k$ (which I think has to hold), then $$x^{k^2-\epsilon} << f(f(x)) << x^{k^2+\epsilon}$$ and thus $d=k^2$. I don't think this does much though. Does anyone have any ideas?","If $g(x)$ is a polynomial, and $$g(x) = f(f(x))\ \forall x\in \mathbb{R}$$ is $f(x)$ necessarily a polynomial, given that $f$ is infinitely differentiable? Reading this question I noticed that the answer fails if we consider the domain to be the whole real line. I'm wondering whether removing the increasing condition allows for solutions that work across the whole real line, without allowing for ""weird"" functions like $$f(x) = \left|x\right|^{\sqrt{2}}$$ hence the infinitely differentiable condition. The only progress I've mad on this is as follows: Assume $g(x)$ has degree $d$ and leading coefficient $a$. Thus $$\lim_{x\to\infty} \frac{g(x)}{ax^d} = 1$$ $$\lim_{x\to\infty} \frac{f(f(x))}{ax^d} = 1$$ If $$x^{k-\epsilon} << f(x) << x^{k+\epsilon}\ \forall\ \epsilon>0$$ for some $k$ (which I think has to hold), then $$x^{k^2-\epsilon} << f(f(x)) << x^{k^2+\epsilon}$$ and thus $d=k^2$. I don't think this does much though. Does anyone have any ideas?",,"['calculus', 'functions', 'polynomials']"
