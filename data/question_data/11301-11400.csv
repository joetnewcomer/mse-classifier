,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Evaluating $\int_0^{\infty}\frac{e^{-x}}{1+x^2}dx$,Evaluating,\int_0^{\infty}\frac{e^{-x}}{1+x^2}dx,"I'm trying to evaluate $$\int_0^{\infty}\dfrac{e^{-x}}{1+x^2}dx$$ By making the substitution $x=\tan\theta$,  $$\int_0^{\infty}\dfrac{e^{-x}}{1+x^2}dx=\int_0^{\frac \pi 2}\exp(-\tan\theta)d\theta$$ So it converges to something less than $\frac \pi 2$. Is there any way to  find the exact value, using only elementary methods?","I'm trying to evaluate $$\int_0^{\infty}\dfrac{e^{-x}}{1+x^2}dx$$ By making the substitution $x=\tan\theta$,  $$\int_0^{\infty}\dfrac{e^{-x}}{1+x^2}dx=\int_0^{\frac \pi 2}\exp(-\tan\theta)d\theta$$ So it converges to something less than $\frac \pi 2$. Is there any way to  find the exact value, using only elementary methods?",,"['calculus', 'integration', 'improper-integrals']"
1,Relations connecting values of the polylogarithm $\operatorname{Li}_n$ at rational points,Relations connecting values of the polylogarithm  at rational points,\operatorname{Li}_n,"The polylogarithm is defined by the series $$\operatorname{Li}_n(x)=\sum_{k=1}^\infty\frac{x^k}{k^n}.$$ There are relations connecting values of the polylogarithm at certain rational points in the interval $(0,1)$ using combinations of logarithms and values of $\zeta$-function of integer arguments. Here are some examples for small integer orders: $$\pi^2-12\ln^22+12\ln2\cdot\ln3-6\ln^23-12\operatorname{Li}_2\!\left(\tfrac13\right)-6\operatorname{Li}_2\!\left(\tfrac14\right)=0$$ $$2\!\;\pi^2\ln2-4\!\;\pi^2\ln3+8\ln^32-12\ln2\cdot\ln^23+8\ln^33\\+45\,\zeta(3)-24\operatorname{Li}_3\!\left(\tfrac13\right)-24\operatorname{Li}_3\!\left(\tfrac23\right)-6\operatorname{Li}_3\!\left(\tfrac14\right)=0$$ $$8\,\pi^4\ln2-12\,\pi^2\ln^32+18\ln^52-1209\,\zeta(5)\\+1728\operatorname{Li}_5\!\left(\tfrac12\right)-486\operatorname{Li}_5\!\left(\tfrac14\right)-48\operatorname{Li}_5\!\left(\tfrac18\right)+3\operatorname{Li}_5\!\left(\tfrac1{64}\right)=0$$ Are there any known similar relations for $\operatorname{Li}_6$ and higher orders? I know there are some relations (""ladders"") for non-rational algebraic arguments, but now I'm interested in rational arguments only. MathWorld has formula $(19)$ attributed to Bailey et al. that is apparently supposed to hold for any positive integer order, but it does not check numerically for $m>5$. Perhaps, there is a missing term or condition. ( Update: Indeed, the original paper has this identity as formula $(2.16)$ saying it only holds for $1\le m\le5$, and attributes it to Lewin)","The polylogarithm is defined by the series $$\operatorname{Li}_n(x)=\sum_{k=1}^\infty\frac{x^k}{k^n}.$$ There are relations connecting values of the polylogarithm at certain rational points in the interval $(0,1)$ using combinations of logarithms and values of $\zeta$-function of integer arguments. Here are some examples for small integer orders: $$\pi^2-12\ln^22+12\ln2\cdot\ln3-6\ln^23-12\operatorname{Li}_2\!\left(\tfrac13\right)-6\operatorname{Li}_2\!\left(\tfrac14\right)=0$$ $$2\!\;\pi^2\ln2-4\!\;\pi^2\ln3+8\ln^32-12\ln2\cdot\ln^23+8\ln^33\\+45\,\zeta(3)-24\operatorname{Li}_3\!\left(\tfrac13\right)-24\operatorname{Li}_3\!\left(\tfrac23\right)-6\operatorname{Li}_3\!\left(\tfrac14\right)=0$$ $$8\,\pi^4\ln2-12\,\pi^2\ln^32+18\ln^52-1209\,\zeta(5)\\+1728\operatorname{Li}_5\!\left(\tfrac12\right)-486\operatorname{Li}_5\!\left(\tfrac14\right)-48\operatorname{Li}_5\!\left(\tfrac18\right)+3\operatorname{Li}_5\!\left(\tfrac1{64}\right)=0$$ Are there any known similar relations for $\operatorname{Li}_6$ and higher orders? I know there are some relations (""ladders"") for non-rational algebraic arguments, but now I'm interested in rational arguments only. MathWorld has formula $(19)$ attributed to Bailey et al. that is apparently supposed to hold for any positive integer order, but it does not check numerically for $m>5$. Perhaps, there is a missing term or condition. ( Update: Indeed, the original paper has this identity as formula $(2.16)$ saying it only holds for $1\le m\le5$, and attributes it to Lewin)",,"['calculus', 'sequences-and-series', 'logarithms', 'special-functions', 'polylogarithm']"
2,An interesting AM-HM-GM inequality: $\text{AM}+\text{HM}\geq C_n\cdot \text{GM}$,An interesting AM-HM-GM inequality:,\text{AM}+\text{HM}\geq C_n\cdot \text{GM},"It is not difficult to prove that if $x,y\in\mathbb{R}^+$ the inequality $$ \frac{x+y}{2}+\frac{2}{\frac{1}{x}+\frac{1}{y}}\geq \color{purple}{2}\cdot\sqrt{xy} $$ holds, and the constant $\color{purple}{2}$ is optimal. In a recent question I proved, with a quite involved technique, that if $x,y,z\in\mathbb{R}^+$ then $$ \frac{x+y+z}{3}+\frac{3}{\frac{1}{x}+\frac{1}{y}+\frac{1}{z}}\geq \color{purple}{\frac{5}{2\sqrt[3]{2}}}\cdot\sqrt[3]{xyz} $$ holds, and the constant $\color{purple}{\frac{5}{2\sqrt[3]{2}}}$ (that is a bit less than $2$) is optimal. Then I was wondering: Given $x_1,x_2,\ldots,x_n\in\mathbb{R}^+$, what is the optimal constant $C_n$ such that:   $$\text{AM}(x_1,\ldots,x_n)+\text{HM}(x_1,\ldots,x_n)\geq \color{purple}{C_n}\cdot \text{GM}(x_1,\ldots,x_n)$$ I do not think my approach with $3$ variables has a simple generalization (also because in $\mathbb{R}_+^3$ the stationary points are non-trivial), but maybe something is well-known about the improvements of the AM-GM inequality, or there is a cunning approach by some sort of induction on $n$.","It is not difficult to prove that if $x,y\in\mathbb{R}^+$ the inequality $$ \frac{x+y}{2}+\frac{2}{\frac{1}{x}+\frac{1}{y}}\geq \color{purple}{2}\cdot\sqrt{xy} $$ holds, and the constant $\color{purple}{2}$ is optimal. In a recent question I proved, with a quite involved technique, that if $x,y,z\in\mathbb{R}^+$ then $$ \frac{x+y+z}{3}+\frac{3}{\frac{1}{x}+\frac{1}{y}+\frac{1}{z}}\geq \color{purple}{\frac{5}{2\sqrt[3]{2}}}\cdot\sqrt[3]{xyz} $$ holds, and the constant $\color{purple}{\frac{5}{2\sqrt[3]{2}}}$ (that is a bit less than $2$) is optimal. Then I was wondering: Given $x_1,x_2,\ldots,x_n\in\mathbb{R}^+$, what is the optimal constant $C_n$ such that:   $$\text{AM}(x_1,\ldots,x_n)+\text{HM}(x_1,\ldots,x_n)\geq \color{purple}{C_n}\cdot \text{GM}(x_1,\ldots,x_n)$$ I do not think my approach with $3$ variables has a simple generalization (also because in $\mathbb{R}_+^3$ the stationary points are non-trivial), but maybe something is well-known about the improvements of the AM-GM inequality, or there is a cunning approach by some sort of induction on $n$.",,"['calculus', 'inequality']"
3,Three sequences and a limit(own),Three sequences and a limit(own),,"Let us consider three sequences $(a_n)_{n\ge1}$, $(b_n)_{n\ge1}$ and $(c_n)_{n\ge1}$ having the properties: $a_{n},\ b_{n},\ c_{n}\in\left(0,\ \infty\right)$ $a_{n}+b_{n}+c_{n}\ge\frac{a_{n}}{b_{n}}+\frac{b_{n}}{c_{n}}+\frac{c_{n}}{a_{n}}\ \forall n\ge1$ $\lim\limits_{n\to\infty}a_{n}b_{n}c_{n}=1  $ Prove that    $$\lim_{n\to\infty}\frac{a_{n}+b_{n}+c_{n}}{a_{n}b_{n}+b_{n}c_{n}+c_{n}a_{n}}=1  $$","Let us consider three sequences $(a_n)_{n\ge1}$, $(b_n)_{n\ge1}$ and $(c_n)_{n\ge1}$ having the properties: $a_{n},\ b_{n},\ c_{n}\in\left(0,\ \infty\right)$ $a_{n}+b_{n}+c_{n}\ge\frac{a_{n}}{b_{n}}+\frac{b_{n}}{c_{n}}+\frac{c_{n}}{a_{n}}\ \forall n\ge1$ $\lim\limits_{n\to\infty}a_{n}b_{n}c_{n}=1  $ Prove that    $$\lim_{n\to\infty}\frac{a_{n}+b_{n}+c_{n}}{a_{n}b_{n}+b_{n}c_{n}+c_{n}a_{n}}=1  $$",,"['calculus', 'sequences-and-series', 'limits']"
4,What is the relation between dx in elementary calculus and dx in differential geometry?,What is the relation between dx in elementary calculus and dx in differential geometry?,,"I've recently started studying differential geometry and was really hoping that in doing so I'd finally have an answer to something that's been bugging me since I first learnt calculus - what is $dx$?! As far as I understand, in differential geometry $dx^{i}$ is a linear functional that maps vectors in a tangent space $T_{p}M$ at a point $p\in M$ on a manifold $M$ to the set of real numbers $\mathbb{R}$, i.e. $$dx^{i} :T_{p}M\rightarrow\mathbb{R}$$ In this sense the differential form $dx^{i}$ maps a vector $v\in T_{p}M$ to its $i^{th}$ coordinate with respect to the coordinate basis $\frac{\partial}{\partial x^{i}}$, i.e. $dx^{i}(v)=v^{i}$. In elementary calculus I was always told when I asked the question ""what is $dx$?"" , that it is an infinitesimal change in the x-coordinate . This has never rested easy with me as e.g. if we have the formula $$ df=\lim_{\Delta x\rightarrow 0}\Delta f = \lim_{\Delta x\rightarrow 0}f'(x)\Delta x $$ then due to the properties of limits this can be expressed as $$\lim_{\Delta x\rightarrow 0}f'(x)\lim_{\Delta x\rightarrow 0}\Delta x$$ and clearly $\lim_{\Delta x\rightarrow 0}\Delta x =0$ which seems inconsistent. So my main question is: what actually is $dx$ and is there any intuitive (perhaps geometric) explanation as to how it relates to an infinitesimal line element?","I've recently started studying differential geometry and was really hoping that in doing so I'd finally have an answer to something that's been bugging me since I first learnt calculus - what is $dx$?! As far as I understand, in differential geometry $dx^{i}$ is a linear functional that maps vectors in a tangent space $T_{p}M$ at a point $p\in M$ on a manifold $M$ to the set of real numbers $\mathbb{R}$, i.e. $$dx^{i} :T_{p}M\rightarrow\mathbb{R}$$ In this sense the differential form $dx^{i}$ maps a vector $v\in T_{p}M$ to its $i^{th}$ coordinate with respect to the coordinate basis $\frac{\partial}{\partial x^{i}}$, i.e. $dx^{i}(v)=v^{i}$. In elementary calculus I was always told when I asked the question ""what is $dx$?"" , that it is an infinitesimal change in the x-coordinate . This has never rested easy with me as e.g. if we have the formula $$ df=\lim_{\Delta x\rightarrow 0}\Delta f = \lim_{\Delta x\rightarrow 0}f'(x)\Delta x $$ then due to the properties of limits this can be expressed as $$\lim_{\Delta x\rightarrow 0}f'(x)\lim_{\Delta x\rightarrow 0}\Delta x$$ and clearly $\lim_{\Delta x\rightarrow 0}\Delta x =0$ which seems inconsistent. So my main question is: what actually is $dx$ and is there any intuitive (perhaps geometric) explanation as to how it relates to an infinitesimal line element?",,"['calculus', 'differential-geometry', 'differential-forms']"
5,"Find $\int_{-1}^3xf(x)\,dx$ where $f(x)=\min(1,x^2)$",Find  where,"\int_{-1}^3xf(x)\,dx f(x)=\min(1,x^2)","Find: $$\int_{-1}^3xf(x)\,dx,$$ where $f(x)=\min(1,x^2)$. I thought about solving it like this: $$\int_{-1}^1 x^3\,dx + \int_{1}^3x\,dx = \cdots = 4.$$ But the solution is $\frac{26}{3}$ and I don't understand how they got it.","Find: $$\int_{-1}^3xf(x)\,dx,$$ where $f(x)=\min(1,x^2)$. I thought about solving it like this: $$\int_{-1}^1 x^3\,dx + \int_{1}^3x\,dx = \cdots = 4.$$ But the solution is $\frac{26}{3}$ and I don't understand how they got it.",,"['calculus', 'definite-integrals']"
6,Can we prove that the solutions of $\int_0^y \sin(\sin(x)) dx =1$ are irrational?,Can we prove that the solutions of  are irrational?,\int_0^y \sin(\sin(x)) dx =1,Can we prove that the solutions of $$\int_0^y \sin(\sin(x)) dx =1$$ are irrational? Wolfram Alpha gives two approximate sets of solutions as $\{4.58+2\pi k|k\in\mathbb{Z}\}$ and $\{1.69+2\pi k|k\in\mathbb{Z}\}$. Can we prove they are irrational?,Can we prove that the solutions of $$\int_0^y \sin(\sin(x)) dx =1$$ are irrational? Wolfram Alpha gives two approximate sets of solutions as $\{4.58+2\pi k|k\in\mathbb{Z}\}$ and $\{1.69+2\pi k|k\in\mathbb{Z}\}$. Can we prove they are irrational?,,"['calculus', 'integration', 'roots', 'irrational-numbers']"
7,Is this Euler-Mascheroni constant calculation from double integrals a true identity?,Is this Euler-Mascheroni constant calculation from double integrals a true identity?,,"A prime number is a number that is only divisible by itself and one, that is the number of divisors of a prime number is equal to $2$. One way to illustrate this is to plot a matrix such that if the column index (1,2,3,...) divides the row index (1,2,3,...) then a black square is drawn at that column and row index intersection, like this: As a matrix this has the definition in Mathematica: MatrixForm[Table[Table[If[Mod[n, k] == 0, 1, 0 ], {k, 1, 12}], {n, 1, 12}]] which gives the table below: $$\small \left( \begin{array}{cccccccccccc}  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\  1 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\  1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\  1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\  1 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 \end{array} \right)$$ The number of divisors of n, also called tau, is the row sums of this matrix and starts: 1, 2, 2, 3, 2, 4, 2, 4, 3, 4, 2, 6 ... So at a row equal to a prime number there are only two black dots and the row sums in the above matrix are equal to 2. To find the ordinary generating function of the number of divisors of n we consider table $a$ times $b$, or row index times column index: MatrixForm[Table[Table[a*b, {b, 1, 12}], {a, 1, 12}]] $$\small \left( \begin{array}{cccccccccccc}  1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\  2 & 4 & 6 & 8 & 10 & 12 & 14 & 16 & 18 & 20 & 22 & 24 \\  3 & 6 & 9 & 12 & 15 & 18 & 21 & 24 & 27 & 30 & 33 & 36 \\  4 & 8 & 12 & 16 & 20 & 24 & 28 & 32 & 36 & 40 & 44 & 48 \\  5 & 10 & 15 & 20 & 25 & 30 & 35 & 40 & 45 & 50 & 55 & 60 \\  6 & 12 & 18 & 24 & 30 & 36 & 42 & 48 & 54 & 60 & 66 & 72 \\  7 & 14 & 21 & 28 & 35 & 42 & 49 & 56 & 63 & 70 & 77 & 84 \\  8 & 16 & 24 & 32 & 40 & 48 & 56 & 64 & 72 & 80 & 88 & 96 \\  9 & 18 & 27 & 36 & 45 & 54 & 63 & 72 & 81 & 90 & 99 & 108 \\  10 & 20 & 30 & 40 & 50 & 60 & 70 & 80 & 90 & 100 & 110 & 120 \\  11 & 22 & 33 & 44 & 55 & 66 & 77 & 88 & 99 & 110 & 121 & 132 \\  12 & 24 & 36 & 48 & 60 & 72 & 84 & 96 & 108 & 120 & 132 & 144 \end{array} \right)$$ By stretching out this table in the downward direction we get this table: MatrixForm[Table[Table[If[Mod[a, b] == 0, a, 0], {b, 1, 12}], {a, 1, 12}]] $$\small \left( \begin{array}{cccccccccccc}  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  2 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  3 & 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  4 & 4 & 0 & 4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  5 & 0 & 0 & 0 & 5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  6 & 6 & 6 & 0 & 0 & 6 & 0 & 0 & 0 & 0 & 0 & 0 \\  7 & 0 & 0 & 0 & 0 & 0 & 7 & 0 & 0 & 0 & 0 & 0 \\  8 & 8 & 0 & 8 & 0 & 0 & 0 & 8 & 0 & 0 & 0 & 0 \\  9 & 0 & 9 & 0 & 0 & 0 & 0 & 0 & 9 & 0 & 0 & 0 \\  10 & 10 & 0 & 0 & 10 & 0 & 0 & 0 & 0 & 10 & 0 & 0 \\  11 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 11 & 0 \\  12 & 12 & 12 & 12 & 0 & 12 & 0 & 0 & 0 & 0 & 0 & 12 \end{array} \right)$$ This looks very much like the divisorplot at the beginning. To find the generating function for the number of divisors of $n$ we then introduce the variable $x$ like this: Clear[x] MatrixForm[  Table[Table[If[Mod[a, b] == 0, x^a, 0], {b, 1, 12}], {a, 1, 12}]] $$\small \left( \begin{array}{cccccccccccc}  x & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^2 & x^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^3 & 0 & x^3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^4 & x^4 & 0 & x^4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^5 & 0 & 0 & 0 & x^5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^6 & x^6 & x^6 & 0 & 0 & x^6 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^7 & 0 & 0 & 0 & 0 & 0 & x^7 & 0 & 0 & 0 & 0 & 0 \\  x^8 & x^8 & 0 & x^8 & 0 & 0 & 0 & x^8 & 0 & 0 & 0 & 0 \\  x^9 & 0 & x^9 & 0 & 0 & 0 & 0 & 0 & x^9 & 0 & 0 & 0 \\  x^{10} & x^{10} & 0 & 0 & x^{10} & 0 & 0 & 0 & 0 & x^{10} & 0 & 0 \\  x^{11} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & x^{11} & 0 \\  x^{12} & x^{12} & x^{12} & x^{12} & 0 & x^{12} & 0 & 0 & 0 & 0 & 0 & x^{12} \end{array} \right)$$ The generating function for the number of divisors of $n$ is then the infinite double sum which is the sum of the infinite matrix above: $$\sum\limits_{n=1}^{\infty} d(n)x^{n} = \sum\limits_{a=1}^{\infty} \sum\limits_{b=1}^{\infty} x^{a b}$$  $$= 1\, x^{1} + 2\, x^{2} +  2\, x^{3} +  3\, x^{4} +  2\, x^{5} +  4\, x^{6} +  2\, x^{7} +  4\, x^{8} +  3\, x^{9} +  4\, x^{10} + 2\, x^{11} +  6\, x^{12} +  ...$$ where $d(n)$ = the number of divisors of $n$ A sum $\sum$ is a sum of distances - usually under a function, while an integral $\int$ is a sum of areas under a function, and a double integral $\int \int$ is a sum of volumes and so on... Often in mathematics one wants to compare a sum to an integral, or at least so I have heard. In this case we have a double sum: $$\sum\limits_{a=1}^{\infty} \sum\limits_{b=1}^{\infty} x^{a b}$$ Considering the double integral instead we have: $$\int\limits_{a=1}^{\infty} \int\limits_{b=1}^{\infty} x^{a b}$$ As suggested by Chris's wise sister in the chat room about two weeks ago, the similar triple integral evaluates faster at $x=\frac{1}{e}$: According to Mathematica: Integrate[Integrate[1/Exp[1]^(a*b), {a, 1, Infinity}], {b, 1, Infinity}] the double integral then evaluates to: $$\int\limits_{a=1}^{\infty} \int\limits_{b=1}^{\infty} \frac{1}{e^{a b}}=-\text{Ei}(-1)$$ Or as Mathematica calls it, the exponential integral. Reading about the exponential integral in Wikipedia that passing a logarithm as argument to it one gets the logarithmic integral and remembering that the logarithmic integral has to do with the prime number theorem, I did some experimenting in Mathematica with the program: Monitor[MatrixForm[   Table[Table[     Integrate[       Integrate[Exp[a*b], {a, k, Infinity},         GenerateConditions -> False], {b, 0, n},        GenerateConditions -> False] -       Integrate[       Integrate[Exp[a*b], {a, 0, n}, GenerateConditions -> False], {b,         k, Infinity}, GenerateConditions -> False], {n, 1, 4}], {k, 0,      4}]], k] and came to the conclusion that for $n \gt 0$ and $k \geq 0$, this appears to be an identity: $$\gamma = \int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db$$ where $\gamma$ = Euler-Mascheroni constant , approximately equal to 0.57721566490153286060651209... My question is: Why is this identity true? I also noted that: For $k \lt 0$ and $n \lt 0$, it appears to be true that: $$\gamma = \Re(\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db)$$ $$-\pi = \Im(\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db)$$ But this is probably less interesting. As a starting point I believe it has something to do with the fact: -Integrate[Integrate[Exp[a*b], {a, 0, 1}, GenerateConditions -> False], {b, 0,     Infinity}, GenerateConditions -> False] $$\gamma = -\int_0^{\infty } \left(\int_0^1 e^{a b} \, da\right) \, db$$ and that it somehow can be separated out from both of the double integrals: $$\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db$$ $$\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db$$ depending on the values of $n$ and $k$ since: Monitor[MatrixForm[   Table[Table[     Integrate[       Integrate[Exp[a*b], {a, k, Infinity},         GenerateConditions -> False], {b, 0, n},        GenerateConditions -> False] -       0*Integrate[        Integrate[Exp[a*b], {a, 0, n},          GenerateConditions -> False], {b, k, Infinity},         GenerateConditions -> False], {n, 1, 4}], {k, 0, 4}]], k] Monitor[MatrixForm[   Table[Table[     0*Integrate[        Integrate[Exp[a*b], {a, k, Infinity},          GenerateConditions -> False], {b, 0, n},         GenerateConditions -> False] -       Integrate[       Integrate[Exp[a*b], {a, 0, n}, GenerateConditions -> False], {b,         k, Infinity}, GenerateConditions -> False], {n, 1, 4}], {k, 0,      4}]], k] for $n \geq 1$ and $k \geq 0$ we have for the first double integral: $$\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db$$ (for $n=1,2,3,4...$ and $k=0,1,2,3,4...$): $$\small \left( \begin{array}{cccc}  0 & -\log (2) & -\log (3) & -\log (4) \\  \gamma -\text{Ei}(1) & \gamma -\text{Ei}(2) & \gamma -\text{Ei}(3) & \gamma -\text{Ei}(4) \\  -\text{Ei}(2)+\gamma +\log (2) & -\text{Ei}(4)+\gamma +\log (2) & -\text{Ei}(6)+\gamma +\log (2) & -\text{Ei}(8)+\gamma +\log (2) \\  -\text{Ei}(3)+\gamma +\log (3) & -\text{Ei}(6)+\gamma +\log (3) & -\text{Ei}(9)+\gamma +\log (3) & -\text{Ei}(12)+\gamma +\log (3) \\  -\text{Ei}(4)+\gamma +\log (4) & -\text{Ei}(8)+\gamma +\log (4) & -\text{Ei}(12)+\gamma +\log (4) & -\text{Ei}(16)+\gamma +\log (4) \end{array} \right)$$ and for the second double integral: $$-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db)$$ (for $n=1,2,3,4...$ and $k=0,1,2,3,4...$): $$\small \left( \begin{array}{cccc}  \gamma  & \gamma +\log (2) & \gamma +\log (3) & \gamma +\log (4) \\  \text{Ei}(1) & \text{Ei}(2) & \text{Ei}(3) & \text{Ei}(4) \\  \text{Ei}(2)-\log (2) & \text{Ei}(4)-\log (2) & \text{Ei}(6)-\log (2) & \text{Ei}(8)-\log (2) \\  \text{Ei}(3)-\log (3) & \text{Ei}(6)-\log (3) & \text{Ei}(9)-\log (3) & \text{Ei}(12)-\log (3) \\  \text{Ei}(4)-\log (4) & \text{Ei}(8)-\log (4) & \text{Ei}(12)-\log (4) & \text{Ei}(16)-\log (4) \end{array} \right)$$ I was not entirely clear in the use of integration indices $n$ and $k$. Usually $n$ is the row index and $k$ is the column index, while in the matrices above they have been permuted. Edit 10.6.2013: I should have used the 'PrincipalValue' command instead of the 'GenerateConditions' command, like this: t = 1; Table[Integrate[   Integrate[Exp[a*b] + 1/b/t, {a, 0, t}], {b, -Infinity, n},    PrincipalValue -> True], {n, 1, 4}] Table[Integrate[   Integrate[Exp[a*b] + 1/b/t, {a, 0, t}], {b, -Infinity, Log[n]},    PrincipalValue -> True], {n, 1, 4}] $$\text{Ei}(n \cdot t) = \int_{-\infty }^n \left(\int_0^t \left(e^{a b}+\frac{1}{b \cdot t}\right) \, da\right) \, db$$ And the relation from Wikipedia I wanted explore is: $$\text{Ei}(\log (n)) = \text{li}(n)$$ Edit 11.6.2013: This allows us to write: X=5; Monitor[Table[   Integrate[    Integrate[Exp[a*b] + n/b, {a, 0, 1/n}], {b, -Infinity, Log[X]},     PrincipalValue -> True], {n, 1, 6}], n] $$\text{li}(X^{\frac{1}{n}}) = \int_{-\infty }^{\text{Log}[X]} \left(\int_0^{\frac{1}{n}} \left(e^{a b}+\frac{n}{b}\right) \, da\right) \, db$$ Which simplifies to: X = 5; Monitor[Table[   Integrate[E^(b/n)/b, {b, -Infinity, Log[X]},     PrincipalValue -> True], {n, 1, 6}], n] $$\text{li}(X^{\frac{1}{n}}) = \int_{-\infty }^{\text{Log}[X]} \frac{e^{b/n}}{b} \, db$$","A prime number is a number that is only divisible by itself and one, that is the number of divisors of a prime number is equal to $2$. One way to illustrate this is to plot a matrix such that if the column index (1,2,3,...) divides the row index (1,2,3,...) then a black square is drawn at that column and row index intersection, like this: As a matrix this has the definition in Mathematica: MatrixForm[Table[Table[If[Mod[n, k] == 0, 1, 0 ], {k, 1, 12}], {n, 1, 12}]] which gives the table below: $$\small \left( \begin{array}{cccccccccccc}  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\  1 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\  1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\  1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\  1 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 \end{array} \right)$$ The number of divisors of n, also called tau, is the row sums of this matrix and starts: 1, 2, 2, 3, 2, 4, 2, 4, 3, 4, 2, 6 ... So at a row equal to a prime number there are only two black dots and the row sums in the above matrix are equal to 2. To find the ordinary generating function of the number of divisors of n we consider table $a$ times $b$, or row index times column index: MatrixForm[Table[Table[a*b, {b, 1, 12}], {a, 1, 12}]] $$\small \left( \begin{array}{cccccccccccc}  1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\  2 & 4 & 6 & 8 & 10 & 12 & 14 & 16 & 18 & 20 & 22 & 24 \\  3 & 6 & 9 & 12 & 15 & 18 & 21 & 24 & 27 & 30 & 33 & 36 \\  4 & 8 & 12 & 16 & 20 & 24 & 28 & 32 & 36 & 40 & 44 & 48 \\  5 & 10 & 15 & 20 & 25 & 30 & 35 & 40 & 45 & 50 & 55 & 60 \\  6 & 12 & 18 & 24 & 30 & 36 & 42 & 48 & 54 & 60 & 66 & 72 \\  7 & 14 & 21 & 28 & 35 & 42 & 49 & 56 & 63 & 70 & 77 & 84 \\  8 & 16 & 24 & 32 & 40 & 48 & 56 & 64 & 72 & 80 & 88 & 96 \\  9 & 18 & 27 & 36 & 45 & 54 & 63 & 72 & 81 & 90 & 99 & 108 \\  10 & 20 & 30 & 40 & 50 & 60 & 70 & 80 & 90 & 100 & 110 & 120 \\  11 & 22 & 33 & 44 & 55 & 66 & 77 & 88 & 99 & 110 & 121 & 132 \\  12 & 24 & 36 & 48 & 60 & 72 & 84 & 96 & 108 & 120 & 132 & 144 \end{array} \right)$$ By stretching out this table in the downward direction we get this table: MatrixForm[Table[Table[If[Mod[a, b] == 0, a, 0], {b, 1, 12}], {a, 1, 12}]] $$\small \left( \begin{array}{cccccccccccc}  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  2 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  3 & 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  4 & 4 & 0 & 4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  5 & 0 & 0 & 0 & 5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  6 & 6 & 6 & 0 & 0 & 6 & 0 & 0 & 0 & 0 & 0 & 0 \\  7 & 0 & 0 & 0 & 0 & 0 & 7 & 0 & 0 & 0 & 0 & 0 \\  8 & 8 & 0 & 8 & 0 & 0 & 0 & 8 & 0 & 0 & 0 & 0 \\  9 & 0 & 9 & 0 & 0 & 0 & 0 & 0 & 9 & 0 & 0 & 0 \\  10 & 10 & 0 & 0 & 10 & 0 & 0 & 0 & 0 & 10 & 0 & 0 \\  11 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 11 & 0 \\  12 & 12 & 12 & 12 & 0 & 12 & 0 & 0 & 0 & 0 & 0 & 12 \end{array} \right)$$ This looks very much like the divisorplot at the beginning. To find the generating function for the number of divisors of $n$ we then introduce the variable $x$ like this: Clear[x] MatrixForm[  Table[Table[If[Mod[a, b] == 0, x^a, 0], {b, 1, 12}], {a, 1, 12}]] $$\small \left( \begin{array}{cccccccccccc}  x & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^2 & x^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^3 & 0 & x^3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^4 & x^4 & 0 & x^4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^5 & 0 & 0 & 0 & x^5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^6 & x^6 & x^6 & 0 & 0 & x^6 & 0 & 0 & 0 & 0 & 0 & 0 \\  x^7 & 0 & 0 & 0 & 0 & 0 & x^7 & 0 & 0 & 0 & 0 & 0 \\  x^8 & x^8 & 0 & x^8 & 0 & 0 & 0 & x^8 & 0 & 0 & 0 & 0 \\  x^9 & 0 & x^9 & 0 & 0 & 0 & 0 & 0 & x^9 & 0 & 0 & 0 \\  x^{10} & x^{10} & 0 & 0 & x^{10} & 0 & 0 & 0 & 0 & x^{10} & 0 & 0 \\  x^{11} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & x^{11} & 0 \\  x^{12} & x^{12} & x^{12} & x^{12} & 0 & x^{12} & 0 & 0 & 0 & 0 & 0 & x^{12} \end{array} \right)$$ The generating function for the number of divisors of $n$ is then the infinite double sum which is the sum of the infinite matrix above: $$\sum\limits_{n=1}^{\infty} d(n)x^{n} = \sum\limits_{a=1}^{\infty} \sum\limits_{b=1}^{\infty} x^{a b}$$  $$= 1\, x^{1} + 2\, x^{2} +  2\, x^{3} +  3\, x^{4} +  2\, x^{5} +  4\, x^{6} +  2\, x^{7} +  4\, x^{8} +  3\, x^{9} +  4\, x^{10} + 2\, x^{11} +  6\, x^{12} +  ...$$ where $d(n)$ = the number of divisors of $n$ A sum $\sum$ is a sum of distances - usually under a function, while an integral $\int$ is a sum of areas under a function, and a double integral $\int \int$ is a sum of volumes and so on... Often in mathematics one wants to compare a sum to an integral, or at least so I have heard. In this case we have a double sum: $$\sum\limits_{a=1}^{\infty} \sum\limits_{b=1}^{\infty} x^{a b}$$ Considering the double integral instead we have: $$\int\limits_{a=1}^{\infty} \int\limits_{b=1}^{\infty} x^{a b}$$ As suggested by Chris's wise sister in the chat room about two weeks ago, the similar triple integral evaluates faster at $x=\frac{1}{e}$: According to Mathematica: Integrate[Integrate[1/Exp[1]^(a*b), {a, 1, Infinity}], {b, 1, Infinity}] the double integral then evaluates to: $$\int\limits_{a=1}^{\infty} \int\limits_{b=1}^{\infty} \frac{1}{e^{a b}}=-\text{Ei}(-1)$$ Or as Mathematica calls it, the exponential integral. Reading about the exponential integral in Wikipedia that passing a logarithm as argument to it one gets the logarithmic integral and remembering that the logarithmic integral has to do with the prime number theorem, I did some experimenting in Mathematica with the program: Monitor[MatrixForm[   Table[Table[     Integrate[       Integrate[Exp[a*b], {a, k, Infinity},         GenerateConditions -> False], {b, 0, n},        GenerateConditions -> False] -       Integrate[       Integrate[Exp[a*b], {a, 0, n}, GenerateConditions -> False], {b,         k, Infinity}, GenerateConditions -> False], {n, 1, 4}], {k, 0,      4}]], k] and came to the conclusion that for $n \gt 0$ and $k \geq 0$, this appears to be an identity: $$\gamma = \int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db$$ where $\gamma$ = Euler-Mascheroni constant , approximately equal to 0.57721566490153286060651209... My question is: Why is this identity true? I also noted that: For $k \lt 0$ and $n \lt 0$, it appears to be true that: $$\gamma = \Re(\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db)$$ $$-\pi = \Im(\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db)$$ But this is probably less interesting. As a starting point I believe it has something to do with the fact: -Integrate[Integrate[Exp[a*b], {a, 0, 1}, GenerateConditions -> False], {b, 0,     Infinity}, GenerateConditions -> False] $$\gamma = -\int_0^{\infty } \left(\int_0^1 e^{a b} \, da\right) \, db$$ and that it somehow can be separated out from both of the double integrals: $$\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db$$ $$\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db$$ depending on the values of $n$ and $k$ since: Monitor[MatrixForm[   Table[Table[     Integrate[       Integrate[Exp[a*b], {a, k, Infinity},         GenerateConditions -> False], {b, 0, n},        GenerateConditions -> False] -       0*Integrate[        Integrate[Exp[a*b], {a, 0, n},          GenerateConditions -> False], {b, k, Infinity},         GenerateConditions -> False], {n, 1, 4}], {k, 0, 4}]], k] Monitor[MatrixForm[   Table[Table[     0*Integrate[        Integrate[Exp[a*b], {a, k, Infinity},          GenerateConditions -> False], {b, 0, n},         GenerateConditions -> False] -       Integrate[       Integrate[Exp[a*b], {a, 0, n}, GenerateConditions -> False], {b,         k, Infinity}, GenerateConditions -> False], {n, 1, 4}], {k, 0,      4}]], k] for $n \geq 1$ and $k \geq 0$ we have for the first double integral: $$\int_0^n \left(\int_k^{\infty } e^{a b} \, da\right) \, db$$ (for $n=1,2,3,4...$ and $k=0,1,2,3,4...$): $$\small \left( \begin{array}{cccc}  0 & -\log (2) & -\log (3) & -\log (4) \\  \gamma -\text{Ei}(1) & \gamma -\text{Ei}(2) & \gamma -\text{Ei}(3) & \gamma -\text{Ei}(4) \\  -\text{Ei}(2)+\gamma +\log (2) & -\text{Ei}(4)+\gamma +\log (2) & -\text{Ei}(6)+\gamma +\log (2) & -\text{Ei}(8)+\gamma +\log (2) \\  -\text{Ei}(3)+\gamma +\log (3) & -\text{Ei}(6)+\gamma +\log (3) & -\text{Ei}(9)+\gamma +\log (3) & -\text{Ei}(12)+\gamma +\log (3) \\  -\text{Ei}(4)+\gamma +\log (4) & -\text{Ei}(8)+\gamma +\log (4) & -\text{Ei}(12)+\gamma +\log (4) & -\text{Ei}(16)+\gamma +\log (4) \end{array} \right)$$ and for the second double integral: $$-\int_k^{\infty } \left(\int_0^n e^{a b} \, da\right) \, db)$$ (for $n=1,2,3,4...$ and $k=0,1,2,3,4...$): $$\small \left( \begin{array}{cccc}  \gamma  & \gamma +\log (2) & \gamma +\log (3) & \gamma +\log (4) \\  \text{Ei}(1) & \text{Ei}(2) & \text{Ei}(3) & \text{Ei}(4) \\  \text{Ei}(2)-\log (2) & \text{Ei}(4)-\log (2) & \text{Ei}(6)-\log (2) & \text{Ei}(8)-\log (2) \\  \text{Ei}(3)-\log (3) & \text{Ei}(6)-\log (3) & \text{Ei}(9)-\log (3) & \text{Ei}(12)-\log (3) \\  \text{Ei}(4)-\log (4) & \text{Ei}(8)-\log (4) & \text{Ei}(12)-\log (4) & \text{Ei}(16)-\log (4) \end{array} \right)$$ I was not entirely clear in the use of integration indices $n$ and $k$. Usually $n$ is the row index and $k$ is the column index, while in the matrices above they have been permuted. Edit 10.6.2013: I should have used the 'PrincipalValue' command instead of the 'GenerateConditions' command, like this: t = 1; Table[Integrate[   Integrate[Exp[a*b] + 1/b/t, {a, 0, t}], {b, -Infinity, n},    PrincipalValue -> True], {n, 1, 4}] Table[Integrate[   Integrate[Exp[a*b] + 1/b/t, {a, 0, t}], {b, -Infinity, Log[n]},    PrincipalValue -> True], {n, 1, 4}] $$\text{Ei}(n \cdot t) = \int_{-\infty }^n \left(\int_0^t \left(e^{a b}+\frac{1}{b \cdot t}\right) \, da\right) \, db$$ And the relation from Wikipedia I wanted explore is: $$\text{Ei}(\log (n)) = \text{li}(n)$$ Edit 11.6.2013: This allows us to write: X=5; Monitor[Table[   Integrate[    Integrate[Exp[a*b] + n/b, {a, 0, 1/n}], {b, -Infinity, Log[X]},     PrincipalValue -> True], {n, 1, 6}], n] $$\text{li}(X^{\frac{1}{n}}) = \int_{-\infty }^{\text{Log}[X]} \left(\int_0^{\frac{1}{n}} \left(e^{a b}+\frac{n}{b}\right) \, da\right) \, db$$ Which simplifies to: X = 5; Monitor[Table[   Integrate[E^(b/n)/b, {b, -Infinity, Log[X]},     PrincipalValue -> True], {n, 1, 6}], n] $$\text{li}(X^{\frac{1}{n}}) = \int_{-\infty }^{\text{Log}[X]} \frac{e^{b/n}}{b} \, db$$",,"['calculus', 'number-theory', 'multivariable-calculus', 'integration', 'euler-mascheroni-constant']"
8,Deriving a formula for the amount of time you should study for multiple tests,Deriving a formula for the amount of time you should study for multiple tests,,"Just a bit of procrastination here but at the bus stop I was wondering how should I study before multiple tests given the percentage of the grade each one was worth, the days until each test and the amount of hours you want to study that day. Here's my attempt I have come to the conclusion that it would be an inverse relationship between the percentage of time you should allocate (S) and the time until the test (t). Multiplied this by the grade percentage the test was worth (G). $$S\propto \frac{G}{t}$$ Given that you have multiple tests and 8 hours (S=8) a day to study I sum the above relationship to and equate the hours to yield the following: (k= 8/sum) $$8=k \sum^n_{i=1} S_i$$ $$8=k \sum^n_{i=1} \frac{G_i}{t_i}$$ For instance let's say that I have 6 tests: English( $G_1=0.25$ , $t=58$ days) Maths Methods( $G_2=0.5$ , $t=60$ days), Specialist Maths( $G_3=0.5$ , $t=65$ days), Chemistry( $G_4=0.5$ , $t=72$ days), Modern History( $G_5=0.25$ , $t=74$ days), Physics( $G_6=0.5$ , $t=76$ days). Today I have 8 hours to study (more like 7 after I'm done with this), using my formula I can calculate how long I should study for each test today ( $S_i$ ). $$8=k \sum^n_{i=1} \frac{G_i}{t_i}= k\Big(\frac{G_1}{D_1}+\frac{G_2}{D_2}+\frac{G_3}{D_3}+\frac{G_4}{t_4}+\frac{G_5}{t_5}+\frac{G_6}{t_6}\Big)$$ $$=k\Big(\frac{0.25}{58}+\frac{0.5}{60}+\frac{0.5}{65}+\frac{0.5}{72}+\frac{0.25}{74}+\frac{0.5}{76}\Big)$$ $k\approx 214.84$ Therefore, English $S= 0.93$ hours Maths Methods $S= 1.79$ hours Specialist Maths $S= 1.65$ hours Chemistry $S= 1.49$ hours Modern History $S= 0.73$ hours Physics $S= 1.41$ hours Now given that the time approaches the day before the first test (English) I want to just study the content of the first test so I am ready for the test. So let $t_1=1$ $$8=k\Big(\frac{0.25}{1}+\frac{0.5}{3}+\frac{0.5}{8}+\frac{0.5}{15}+\frac{0.25}{17}+\frac{0.5}{19}\Big)$$ $k\approx 14.45 $ Therefore English $S= 3.61$ hours Maths Methods $S= 2.4$ hours Specialist Maths $S=0.90 $ hours Chemistry $S= 0.48$ hours Modern History $S= 0.21$ hours Physics $S= 0.38$ hours This is where my model somewhat fails as I want most of the day to be studying the most urgent subject. If the test dates were more 'spaced out' or English had a 50% of the marks test then I would spend most of the day before the test studying the subject. Can any of you 'test anxious' mathematicians suggest any improvements of this crude model (I am a high school student)? I was thinking about throwing in some differential equations ( $\frac{\partial S}{\partial t_1} )$ but I'm not smart enough for that yet. Thank you Edit: I have more of a think about it and have come up with the following conditions. Ignoring $S\propto \frac G t$ $$1=k \sum^n_{i=1} S_i $$ $$0=\sum^n_{i=1} \frac{dS_i}{dt} $$ $$ S_i(t_i=1)=1 $$ $$ S_i(t_i<1)=0$$ $t$ is the days until the exam. I have come up with the following model for 3 different tests with test dates t=10, t=20, t=30 https://www.desmos.com/calculator/jrrawaofki This application can be extended to all tasks you pursue which have a deadline. This isn't a serious model and there is plenty of space to play with. How could I extend and improve this model using differential equations? This is the second bounty","Just a bit of procrastination here but at the bus stop I was wondering how should I study before multiple tests given the percentage of the grade each one was worth, the days until each test and the amount of hours you want to study that day. Here's my attempt I have come to the conclusion that it would be an inverse relationship between the percentage of time you should allocate (S) and the time until the test (t). Multiplied this by the grade percentage the test was worth (G). Given that you have multiple tests and 8 hours (S=8) a day to study I sum the above relationship to and equate the hours to yield the following: (k= 8/sum) For instance let's say that I have 6 tests: English( , days) Maths Methods( , days), Specialist Maths( , days), Chemistry( , days), Modern History( , days), Physics( , days). Today I have 8 hours to study (more like 7 after I'm done with this), using my formula I can calculate how long I should study for each test today ( ). Therefore, English hours Maths Methods hours Specialist Maths hours Chemistry hours Modern History hours Physics hours Now given that the time approaches the day before the first test (English) I want to just study the content of the first test so I am ready for the test. So let Therefore English hours Maths Methods hours Specialist Maths hours Chemistry hours Modern History hours Physics hours This is where my model somewhat fails as I want most of the day to be studying the most urgent subject. If the test dates were more 'spaced out' or English had a 50% of the marks test then I would spend most of the day before the test studying the subject. Can any of you 'test anxious' mathematicians suggest any improvements of this crude model (I am a high school student)? I was thinking about throwing in some differential equations ( but I'm not smart enough for that yet. Thank you Edit: I have more of a think about it and have come up with the following conditions. Ignoring is the days until the exam. I have come up with the following model for 3 different tests with test dates t=10, t=20, t=30 https://www.desmos.com/calculator/jrrawaofki This application can be extended to all tasks you pursue which have a deadline. This isn't a serious model and there is plenty of space to play with. How could I extend and improve this model using differential equations? This is the second bounty",S\propto \frac{G}{t} 8=k \sum^n_{i=1} S_i 8=k \sum^n_{i=1} \frac{G_i}{t_i} G_1=0.25 t=58 G_2=0.5 t=60 G_3=0.5 t=65 G_4=0.5 t=72 G_5=0.25 t=74 G_6=0.5 t=76 S_i 8=k \sum^n_{i=1} \frac{G_i}{t_i}= k\Big(\frac{G_1}{D_1}+\frac{G_2}{D_2}+\frac{G_3}{D_3}+\frac{G_4}{t_4}+\frac{G_5}{t_5}+\frac{G_6}{t_6}\Big) =k\Big(\frac{0.25}{58}+\frac{0.5}{60}+\frac{0.5}{65}+\frac{0.5}{72}+\frac{0.25}{74}+\frac{0.5}{76}\Big) k\approx 214.84 S= 0.93 S= 1.79 S= 1.65 S= 1.49 S= 0.73 S= 1.41 t_1=1 8=k\Big(\frac{0.25}{1}+\frac{0.5}{3}+\frac{0.5}{8}+\frac{0.5}{15}+\frac{0.25}{17}+\frac{0.5}{19}\Big) k\approx 14.45  S= 3.61 S= 2.4 S=0.90  S= 0.48 S= 0.21 S= 0.38 \frac{\partial S}{\partial t_1} ) S\propto \frac G t 1=k \sum^n_{i=1} S_i  0=\sum^n_{i=1} \frac{dS_i}{dt}   S_i(t_i=1)=1   S_i(t_i<1)=0 t,"['calculus', 'ordinary-differential-equations', 'derivatives', 'partial-differential-equations', 'recreational-mathematics']"
9,Limits - It's always possible to escape an indeterminate form?,Limits - It's always possible to escape an indeterminate form?,,"In general, when we are solving limits and get to an indeterminate form($\frac{0}{0}$, $\frac{\infty}{\infty}$, $0^0$,etc.), we use some technique to get rid of the indeterminate form(factorization, conjugate, variable substition, etc.) and then finish solving the limit. My question is, it's always possible to get rid of indeterminate forms? If it's not, what conclusion should i take about the limit I'm trying to solve?","In general, when we are solving limits and get to an indeterminate form($\frac{0}{0}$, $\frac{\infty}{\infty}$, $0^0$,etc.), we use some technique to get rid of the indeterminate form(factorization, conjugate, variable substition, etc.) and then finish solving the limit. My question is, it's always possible to get rid of indeterminate forms? If it's not, what conclusion should i take about the limit I'm trying to solve?",,"['calculus', 'limits']"
10,"Integration by parts, the cases when it does not matter what $u$ and $dv$ we choose.","Integration by parts, the cases when it does not matter what  and  we choose.",u dv,"I was reviewing Integration By Parts on Brilliant.org where an example they use is $$\int x \ln x \;dx$$   Let $u=\ln x$ and $dv=x\;dx$ such that   $$\begin{align} \int x \ln x\;dx&\;=\;\frac 12x^2\ln x\;-\;\frac 12\int \frac{x^2}x\;dx\\ \\ &\;=\; \frac 12x^2\ln x\;-\;\frac 14x^2\;+\;C  \\ \end{align}$$ Personally, I would have solved it by letting $u=x$ and $dv=\ln x\;dx$ such that $$\begin{align} \int x \ln x\;dx&\;=\;x^2\left(\ln x -1\right)\;-\;\int x \ln x\;dx\;+\;\int x\;dx\\ \\ &\;=\; \frac 12\left[x^2\left(\ln x - 1\right)\;+\;\frac 12x^2\right]\;+\;C\\ \\ &\;=\; \frac 12x^2\ln x\;-\;\frac 14x^2\;+\;C  \\ \end{align}$$ So both choices for $u$ and $dv$ yield a correct result that also is the same both ways up to a constant and I would like to know if that is trivial or what that means. Is there something interesting about integrals such as $\int x\ln x\;dx$ where it does not matter what $u$ and $dv$ we choose to perform Integration By Parts and would there be other examples of this? Edit This edit is to add to the main post the integral $$\int \cos(ax)e^{bx}\;dx$$ from @ Michael Hardy 's comment Letting $u=\cos(ax)$ and $dv=e^{bx}dx$ yields $$\begin{align} \\ \int \cos(ax)e^{bx}\;dx&\;=\;\underbrace{\frac 1b\cos(ax) e^{bx}}_A\;+\;\underbrace{\frac ab}_B \int \sin(ax)e^{bx}\;dx\\ \\ &\;=\;A\;+\;B \left[\frac 1b\sin(ax)e^{bx}\;-\;B\int \cos(ax)e^{bx}\;dx\right]\\ \\ &\;=\;\frac 1{1+B^2}\left(A\;+\;\frac a{b^2}\sin(ax)e^{bx}\right)\;+\;C\\ \\ &\;=\;\frac {e^{bx}}{a^2+b^2}\left(b\cos(ax)+a\sin(ax)\right)\;+\;C\\ \\ \end{align}$$ which is the same result as when letting $u=e^{bx}$ and $dv=\cos(ax)\;dx$ such that $$\begin{align} \\ \int \cos(ax)e^{bx}\;dx&\;=\;\underbrace{\frac 1a\sin(ax) e^{bx}}_A\;-\;\underbrace{\frac ba}_B \int \sin(ax)e^{bx}\;dx\\ \\ &\;=\;A\;-\;B \left[-\frac 1a\cos(ax)e^{bx}\;+\;B\int \cos(ax)e^{bx}\;dx\right]\\ \\ &\;=\;\frac 1{1+B^2}\left(A\;+\;\frac b{a^2}\cos(ax)e^{bx}\right)\;+\;C\\ \\ &\;=\;\frac {e^{bx}}{a^2+b^2}\left(a\sin(ax)\;+\;b\cos(ax)\right)\;+\;C\\ \\ \end{align}$$ Edit (2) This edit is to add the $3$ following integrals: $$\int x \tan^{-1}x\;dx$$   $$\int x \cos^{-1}x\;dx$$   $$\int x \sin^{-1}x\;dx$$ that I got from @ User8128 's answer, after reading "" logarithms and inverse trig functions become algebraic functions when differentiated "". $\int x \tan^{-1}x\;dx$ letting $u=x$ and $dv=\tan^{-1}x\;dx$ $$\begin{align} \int x \tan^{-1}x\;dx&\;=\;\underbrace{x^2\tan^{-1}x-\frac x2\ln|1+x^2|}_\alpha-\int x\tan^{-1}x\;dx+\frac 12\int\ln|1+x^2|\;dx\\ \\ &\;=\;\frac 12\left[\alpha+\frac 12 x \ln|1+x^2|-2x+2\tan^{-1}x\right]+C\\ \\ &\;=\;\frac {x^2}2\tan^{-1}x-x+\tan^{-1}x+C\\ \\ \end{align}$$ $\int x \tan^{-1}x\;dx$ letting $u=\tan^{-1}x$ and $du=x\;dx$ $$\begin{align} \int x \tan^{-1}x\;dx &\;=\;\frac {x^2}2 \tan^{-1}x-\frac 12 \int \frac {x^2}{1+x^2}\;dx\\ \\ &\;=\;\frac {x^2}2 \tan^{-1}x-x+\tan^{-1}x+C\\ \\ \end{align}$$ $\int x \cos^{-1}x\;dx$ letting $u=x$ and $dv=\cos^{-1}x\;dx$ $$\begin{align} \int x \cos^{-1}x\;dx&\;=\;\underbrace{x^2\cos^{-1}-x\sqrt{1-x^2}}_\beta -\int x \cos^{-1}x\;dx+\int \sqrt{1-x^2}\;dx\\ \\ &\;=\;\frac 12 \left[\beta+\frac 12 \left(x\sqrt{1-x^2}+\sin^{-1}x\right)\right]+C\\ \\ &\;=\;\frac {x^2}2 \cos^{-1}x-\frac 14 x\sqrt{1-x^2}+\frac 14 \sin^{-1}x+C\\ \\ \end{align}$$ $\int x \cos^{-1}x\;dx$ letting $u=\cos^{-1}x$ and $dv=x\;dx$ $$\begin{align} \int x\cos^{-1}x\;dx&\;=\;\frac {x^2}2\cos^{-1}x+\frac 12 \int \frac {x^2}{\sqrt{1-x^2}}\;dx\\ \\ &\;=\;\frac {x^2}2 \cos^{-1}x-\frac 14 x\sqrt{1-x^2}+\frac 14 \sin^{-1}x+C\\ \\ \end{align}$$ $\int x \sin^{-1}x\;dx$ letting $u=x$ and $dv=\sin^{-1}x\;dx$ $$\begin{align} \int x \sin^{-1}x\;dx&\;=\;\underbrace{x^2\sin^{-1}+x\sqrt{1-x^2}}_\gamma -\int x \sin^{-1}x\;dx-\int \sqrt{1-x^2}\;dx\\ \\ &\;=\;\frac 12 \left[\gamma-\frac 12 \left(x\sqrt{1-x^2}-\sin^{-1}x\right)\right]+C\\ \\ &\;=\;\frac {x^2}2 \sin^{-1}x+\frac 14 x\sqrt{1-x^2}-\frac 14 \sin^{-1}x+C\\ \\ \end{align}$$ $\int x \sin^{-1}x\;dx$ letting $u=\sin^{-1}x$ and $dv=x\;dx$ $$\begin{align} \int x\sin^{-1}x\;dx&\;=\;\frac {x^2}2\sin^{-1}x-\frac 12 \int \frac {x^2}{\sqrt{1-x^2}}\;dx\\ \\ &\;=\;\frac {x^2}2 \sin^{-1}x+\frac 14 x\sqrt{1-x^2}-\frac 14 \sin^{-1}x+C\\ \\ \end{align}$$ I see that in the case of $\cos^{-1}x$ and $\sin^{-1}x$, one choice of $u$ and $dv$ either turns the inverse trig function into an algebraic function right away (i.e. $d\left(\cos^{-1}x\right)=\frac{-1}{\sqrt{1-x^2}}\;dx$) by differentiation or the other choice of $u$ and $dv$ makes the original function ""re-appear"" along with an algebraic function (i.e. $\int \cos^{-1}x\;dx = x\cos^{-1}x-\sqrt{1-x^2}+C$) by integration. In the case of $\tan^{-1}x$, a $\log$ appears if we integrate the function but then $\log$s turn into algebraic functions upon derivation as well or make the original function ""re-appear"" along with an algebraic function upon integration (i.e $\int \ln x\;dx = x\ln x - x +C$ ) and so we get the same result. I understand that this is not special but I'm still trying to fully wrap my head around the reason why these integrals are such that when we apply Integration By Parts , any choice for $u$ and $dv$ yield correct results that are also identical to each other. Edit (last) I got "" Calculus: An Intuitive and Physical Approach "" by Morris Kline and at the end of chapter $14$ on Further Techniques of Integration in section $6$ on The Use of Tables he says: "" [...] One answer would be to study more techniques or seek to discover a new one. However, the number of techniques and special tricks is quite extensive. It is neither wise nor efficient to spend months or years on what is really an incidental process or means to an end at the expense of the acquisition of more significant knowledge. "" So, I will follow this advice and (for now) be content with the fact that I understand much better how integrals are obtained, avoid wasting time on knowing why some peculiar results of this "" incidental process or means to an end "" do occur and be going on my merry mathematical way.","I was reviewing Integration By Parts on Brilliant.org where an example they use is $$\int x \ln x \;dx$$   Let $u=\ln x$ and $dv=x\;dx$ such that   $$\begin{align} \int x \ln x\;dx&\;=\;\frac 12x^2\ln x\;-\;\frac 12\int \frac{x^2}x\;dx\\ \\ &\;=\; \frac 12x^2\ln x\;-\;\frac 14x^2\;+\;C  \\ \end{align}$$ Personally, I would have solved it by letting $u=x$ and $dv=\ln x\;dx$ such that $$\begin{align} \int x \ln x\;dx&\;=\;x^2\left(\ln x -1\right)\;-\;\int x \ln x\;dx\;+\;\int x\;dx\\ \\ &\;=\; \frac 12\left[x^2\left(\ln x - 1\right)\;+\;\frac 12x^2\right]\;+\;C\\ \\ &\;=\; \frac 12x^2\ln x\;-\;\frac 14x^2\;+\;C  \\ \end{align}$$ So both choices for $u$ and $dv$ yield a correct result that also is the same both ways up to a constant and I would like to know if that is trivial or what that means. Is there something interesting about integrals such as $\int x\ln x\;dx$ where it does not matter what $u$ and $dv$ we choose to perform Integration By Parts and would there be other examples of this? Edit This edit is to add to the main post the integral $$\int \cos(ax)e^{bx}\;dx$$ from @ Michael Hardy 's comment Letting $u=\cos(ax)$ and $dv=e^{bx}dx$ yields $$\begin{align} \\ \int \cos(ax)e^{bx}\;dx&\;=\;\underbrace{\frac 1b\cos(ax) e^{bx}}_A\;+\;\underbrace{\frac ab}_B \int \sin(ax)e^{bx}\;dx\\ \\ &\;=\;A\;+\;B \left[\frac 1b\sin(ax)e^{bx}\;-\;B\int \cos(ax)e^{bx}\;dx\right]\\ \\ &\;=\;\frac 1{1+B^2}\left(A\;+\;\frac a{b^2}\sin(ax)e^{bx}\right)\;+\;C\\ \\ &\;=\;\frac {e^{bx}}{a^2+b^2}\left(b\cos(ax)+a\sin(ax)\right)\;+\;C\\ \\ \end{align}$$ which is the same result as when letting $u=e^{bx}$ and $dv=\cos(ax)\;dx$ such that $$\begin{align} \\ \int \cos(ax)e^{bx}\;dx&\;=\;\underbrace{\frac 1a\sin(ax) e^{bx}}_A\;-\;\underbrace{\frac ba}_B \int \sin(ax)e^{bx}\;dx\\ \\ &\;=\;A\;-\;B \left[-\frac 1a\cos(ax)e^{bx}\;+\;B\int \cos(ax)e^{bx}\;dx\right]\\ \\ &\;=\;\frac 1{1+B^2}\left(A\;+\;\frac b{a^2}\cos(ax)e^{bx}\right)\;+\;C\\ \\ &\;=\;\frac {e^{bx}}{a^2+b^2}\left(a\sin(ax)\;+\;b\cos(ax)\right)\;+\;C\\ \\ \end{align}$$ Edit (2) This edit is to add the $3$ following integrals: $$\int x \tan^{-1}x\;dx$$   $$\int x \cos^{-1}x\;dx$$   $$\int x \sin^{-1}x\;dx$$ that I got from @ User8128 's answer, after reading "" logarithms and inverse trig functions become algebraic functions when differentiated "". $\int x \tan^{-1}x\;dx$ letting $u=x$ and $dv=\tan^{-1}x\;dx$ $$\begin{align} \int x \tan^{-1}x\;dx&\;=\;\underbrace{x^2\tan^{-1}x-\frac x2\ln|1+x^2|}_\alpha-\int x\tan^{-1}x\;dx+\frac 12\int\ln|1+x^2|\;dx\\ \\ &\;=\;\frac 12\left[\alpha+\frac 12 x \ln|1+x^2|-2x+2\tan^{-1}x\right]+C\\ \\ &\;=\;\frac {x^2}2\tan^{-1}x-x+\tan^{-1}x+C\\ \\ \end{align}$$ $\int x \tan^{-1}x\;dx$ letting $u=\tan^{-1}x$ and $du=x\;dx$ $$\begin{align} \int x \tan^{-1}x\;dx &\;=\;\frac {x^2}2 \tan^{-1}x-\frac 12 \int \frac {x^2}{1+x^2}\;dx\\ \\ &\;=\;\frac {x^2}2 \tan^{-1}x-x+\tan^{-1}x+C\\ \\ \end{align}$$ $\int x \cos^{-1}x\;dx$ letting $u=x$ and $dv=\cos^{-1}x\;dx$ $$\begin{align} \int x \cos^{-1}x\;dx&\;=\;\underbrace{x^2\cos^{-1}-x\sqrt{1-x^2}}_\beta -\int x \cos^{-1}x\;dx+\int \sqrt{1-x^2}\;dx\\ \\ &\;=\;\frac 12 \left[\beta+\frac 12 \left(x\sqrt{1-x^2}+\sin^{-1}x\right)\right]+C\\ \\ &\;=\;\frac {x^2}2 \cos^{-1}x-\frac 14 x\sqrt{1-x^2}+\frac 14 \sin^{-1}x+C\\ \\ \end{align}$$ $\int x \cos^{-1}x\;dx$ letting $u=\cos^{-1}x$ and $dv=x\;dx$ $$\begin{align} \int x\cos^{-1}x\;dx&\;=\;\frac {x^2}2\cos^{-1}x+\frac 12 \int \frac {x^2}{\sqrt{1-x^2}}\;dx\\ \\ &\;=\;\frac {x^2}2 \cos^{-1}x-\frac 14 x\sqrt{1-x^2}+\frac 14 \sin^{-1}x+C\\ \\ \end{align}$$ $\int x \sin^{-1}x\;dx$ letting $u=x$ and $dv=\sin^{-1}x\;dx$ $$\begin{align} \int x \sin^{-1}x\;dx&\;=\;\underbrace{x^2\sin^{-1}+x\sqrt{1-x^2}}_\gamma -\int x \sin^{-1}x\;dx-\int \sqrt{1-x^2}\;dx\\ \\ &\;=\;\frac 12 \left[\gamma-\frac 12 \left(x\sqrt{1-x^2}-\sin^{-1}x\right)\right]+C\\ \\ &\;=\;\frac {x^2}2 \sin^{-1}x+\frac 14 x\sqrt{1-x^2}-\frac 14 \sin^{-1}x+C\\ \\ \end{align}$$ $\int x \sin^{-1}x\;dx$ letting $u=\sin^{-1}x$ and $dv=x\;dx$ $$\begin{align} \int x\sin^{-1}x\;dx&\;=\;\frac {x^2}2\sin^{-1}x-\frac 12 \int \frac {x^2}{\sqrt{1-x^2}}\;dx\\ \\ &\;=\;\frac {x^2}2 \sin^{-1}x+\frac 14 x\sqrt{1-x^2}-\frac 14 \sin^{-1}x+C\\ \\ \end{align}$$ I see that in the case of $\cos^{-1}x$ and $\sin^{-1}x$, one choice of $u$ and $dv$ either turns the inverse trig function into an algebraic function right away (i.e. $d\left(\cos^{-1}x\right)=\frac{-1}{\sqrt{1-x^2}}\;dx$) by differentiation or the other choice of $u$ and $dv$ makes the original function ""re-appear"" along with an algebraic function (i.e. $\int \cos^{-1}x\;dx = x\cos^{-1}x-\sqrt{1-x^2}+C$) by integration. In the case of $\tan^{-1}x$, a $\log$ appears if we integrate the function but then $\log$s turn into algebraic functions upon derivation as well or make the original function ""re-appear"" along with an algebraic function upon integration (i.e $\int \ln x\;dx = x\ln x - x +C$ ) and so we get the same result. I understand that this is not special but I'm still trying to fully wrap my head around the reason why these integrals are such that when we apply Integration By Parts , any choice for $u$ and $dv$ yield correct results that are also identical to each other. Edit (last) I got "" Calculus: An Intuitive and Physical Approach "" by Morris Kline and at the end of chapter $14$ on Further Techniques of Integration in section $6$ on The Use of Tables he says: "" [...] One answer would be to study more techniques or seek to discover a new one. However, the number of techniques and special tricks is quite extensive. It is neither wise nor efficient to spend months or years on what is really an incidental process or means to an end at the expense of the acquisition of more significant knowledge. "" So, I will follow this advice and (for now) be content with the fact that I understand much better how integrals are obtained, avoid wasting time on knowing why some peculiar results of this "" incidental process or means to an end "" do occur and be going on my merry mathematical way.",,"['calculus', 'integration']"
11,Calculus of variations with two functions and inequality,Calculus of variations with two functions and inequality,,"I wish to extremise $$ Q = \int_0^h u \, \,dy $$ with the following constraints $$B = \int_0^h u g \, \, dy \\ M = \int_0^h u^2 +\left(\int_0^y g \, \,dy^*\right) \, \, dy$$ where $M,B$ are constant. So my idea is to set this up as a variational problem as such $$\varepsilon \left(Q + \lambda B + \mu M\right) = 0$$ We assume $$u = u_0 + \varepsilon u_1 \\ g = g_0 + \varepsilon g_1 $$ I also wish to constrain that $0 < g \leq g^*$ for some given $g^*$, but I will ignore that for the time being. Taking $O(\varepsilon)$ terms gives $$\varepsilon \left[\int_0^h u_1 + \lambda(u_0g_1+u_1g_0) + \mu 2 u_0u_1 +  \mu\left[y \int_0^h g_1 \right]_0^h - \mu \int_0^h y  g_1  \, \,dy \right] = 0$$ Where I have used integration by parts on the $\int g$ term in $M$. This gives $$ \int_0^h \left[ u_1(1 + \lambda g_0 + 2 \mu u_0) + g_1(\lambda u_0 + \mu(h-y) \right] = 0 $$ Taking the two terms to be independent gives $$u_0 = -\frac{\mu}{\lambda}(h-y) \\ g_0 = -\frac{1}{\lambda} + 2\left(\frac{\mu}{\lambda}\right)^2(h-y)$$ All good so far I think? I expected $u_0,g_0$ to be linear. For ease of notation set $\omega = -\mu / \lambda$ and $-1/\lambda = \beta$. Then we can arrive substituiting $u_0, g_0$ into the definitions of $M,B$ with some algebra, at $$M = \omega^2 h^3 + \frac{\beta h^2}{2} \\ B = \frac{2}{3}\omega^3 h^3 + \frac{\beta \omega h^2}{2}$$ And hence, these two simultaneous equations give $$Q = \frac{(3(M \omega - B)^{2/3}}{2 \omega} $$ So here is where I run out of steam a bit. I guess I want to extremise $Q$ so take $$\frac{\partial Q}{\partial \omega} = 0 \Rightarrow \omega = \frac{3B}{M}$$ However, this $\omega$ implies that $\beta = -2M / h^2 < 0$, which means that the constant term in $g_0$ is negative, which is unphysical in my set up, so we must have $\beta = 0$ at the maximal value. Proceeding with $\beta = 0$ gives us $$\omega = \frac{3B}{2M}$$ which gives me a maximal $$Q = \frac{M}{2^{2/3} 3^{1/3} B^{1/3}}$$. However, I am not sure if this answer/my method is correct, nor how to incorporate the inequality constraint that $g_0$ is smaller than some fixed value. I can get a measurement for maximal $Q$ via a different method, which provides me with the correct powers/dimension, but the prefactors (in particular the $2^{2/3}$) are incorrect. Any pointers on how to answer this type of question? How to incorporate the inequality? Or if indeed my method is correct. EDIT To show why I select $\beta = 0$ as the maximal case. Consider the plot of $Q$ against $\omega$. If we input some reasonable (physically sound) values for $M = 4.5$ and $B = 2$ we have So we can see that $Q$ has a maximal value. However, plotting $\beta$ against $\omega$ for the same values of $M,B$ shows us that $\beta$ gives a negative value at this maximal value, which is unphsyical. So the maximal $Q$ goes with $\beta = 0$.","I wish to extremise $$ Q = \int_0^h u \, \,dy $$ with the following constraints $$B = \int_0^h u g \, \, dy \\ M = \int_0^h u^2 +\left(\int_0^y g \, \,dy^*\right) \, \, dy$$ where $M,B$ are constant. So my idea is to set this up as a variational problem as such $$\varepsilon \left(Q + \lambda B + \mu M\right) = 0$$ We assume $$u = u_0 + \varepsilon u_1 \\ g = g_0 + \varepsilon g_1 $$ I also wish to constrain that $0 < g \leq g^*$ for some given $g^*$, but I will ignore that for the time being. Taking $O(\varepsilon)$ terms gives $$\varepsilon \left[\int_0^h u_1 + \lambda(u_0g_1+u_1g_0) + \mu 2 u_0u_1 +  \mu\left[y \int_0^h g_1 \right]_0^h - \mu \int_0^h y  g_1  \, \,dy \right] = 0$$ Where I have used integration by parts on the $\int g$ term in $M$. This gives $$ \int_0^h \left[ u_1(1 + \lambda g_0 + 2 \mu u_0) + g_1(\lambda u_0 + \mu(h-y) \right] = 0 $$ Taking the two terms to be independent gives $$u_0 = -\frac{\mu}{\lambda}(h-y) \\ g_0 = -\frac{1}{\lambda} + 2\left(\frac{\mu}{\lambda}\right)^2(h-y)$$ All good so far I think? I expected $u_0,g_0$ to be linear. For ease of notation set $\omega = -\mu / \lambda$ and $-1/\lambda = \beta$. Then we can arrive substituiting $u_0, g_0$ into the definitions of $M,B$ with some algebra, at $$M = \omega^2 h^3 + \frac{\beta h^2}{2} \\ B = \frac{2}{3}\omega^3 h^3 + \frac{\beta \omega h^2}{2}$$ And hence, these two simultaneous equations give $$Q = \frac{(3(M \omega - B)^{2/3}}{2 \omega} $$ So here is where I run out of steam a bit. I guess I want to extremise $Q$ so take $$\frac{\partial Q}{\partial \omega} = 0 \Rightarrow \omega = \frac{3B}{M}$$ However, this $\omega$ implies that $\beta = -2M / h^2 < 0$, which means that the constant term in $g_0$ is negative, which is unphysical in my set up, so we must have $\beta = 0$ at the maximal value. Proceeding with $\beta = 0$ gives us $$\omega = \frac{3B}{2M}$$ which gives me a maximal $$Q = \frac{M}{2^{2/3} 3^{1/3} B^{1/3}}$$. However, I am not sure if this answer/my method is correct, nor how to incorporate the inequality constraint that $g_0$ is smaller than some fixed value. I can get a measurement for maximal $Q$ via a different method, which provides me with the correct powers/dimension, but the prefactors (in particular the $2^{2/3}$) are incorrect. Any pointers on how to answer this type of question? How to incorporate the inequality? Or if indeed my method is correct. EDIT To show why I select $\beta = 0$ as the maximal case. Consider the plot of $Q$ against $\omega$. If we input some reasonable (physically sound) values for $M = 4.5$ and $B = 2$ we have So we can see that $Q$ has a maximal value. However, plotting $\beta$ against $\omega$ for the same values of $M,B$ shows us that $\beta$ gives a negative value at this maximal value, which is unphsyical. So the maximal $Q$ goes with $\beta = 0$.",,"['calculus', 'calculus-of-variations']"
12,On the infinite series $\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n}}\right)$,On the infinite series,\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n}}\right),"Let $F_n$ the $n-$ th Fibonacci number, i.e. $F_n=F_{n-1}+F_{n-2}$ with $F_0=0$ and $F_1=1$ . We know that ( here ): $$\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n+1}}\right)=\frac{\pi}{4}$$ but how about the following series: $$\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n}}\right)$$ We can use Catalan's identity with $r=2$ and $m=2n$ , leading us to: $$F_{2n}^2-F_{2n-2}\cdot F_{2n+2}=(-1)^{2n-2}\cdot F_2^2\implies F_{2n}^2=1+F_{2n-2}\cdot F_{2n+2}$$ So: $$\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n}}\right)=\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{\sqrt{1+F_{2n-2}\cdot F_{2n+2}}}\right)$$ How can we go on? Also, I've calculated the result with the following C++ code and it appears to be $\mathcal{S}=1.30850 28221 75405 19611 19578 86489...$ #include<stdlib.h> #include<iostream> #include<math.h> #include<iomanip> int main(){  long double fn2, fn1, fn, sum;  fn2 = 0; fn1 = 1; sum = 0;  for(int i = 0; i < 5000; i++){     fn = fn1 + fn2;     fn2 = fn1;     fn1 = fn;      if(i%2==0){         sum = sum + atan(1/fn);     } }  std::cout << setprecision(50); std::cout << ""Result: "" << sum << std::endl; system(""pause""); } With Inverse Symbolic Calculator (via wayback), no result has been found. Possible linked post here .","Let the th Fibonacci number, i.e. with and . We know that ( here ): but how about the following series: We can use Catalan's identity with and , leading us to: So: How can we go on? Also, I've calculated the result with the following C++ code and it appears to be #include<stdlib.h> #include<iostream> #include<math.h> #include<iomanip> int main(){  long double fn2, fn1, fn, sum;  fn2 = 0; fn1 = 1; sum = 0;  for(int i = 0; i < 5000; i++){     fn = fn1 + fn2;     fn2 = fn1;     fn1 = fn;      if(i%2==0){         sum = sum + atan(1/fn);     } }  std::cout << setprecision(50); std::cout << ""Result: "" << sum << std::endl; system(""pause""); } With Inverse Symbolic Calculator (via wayback), no result has been found. Possible linked post here .",F_n n- F_n=F_{n-1}+F_{n-2} F_0=0 F_1=1 \sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n+1}}\right)=\frac{\pi}{4} \sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n}}\right) r=2 m=2n F_{2n}^2-F_{2n-2}\cdot F_{2n+2}=(-1)^{2n-2}\cdot F_2^2\implies F_{2n}^2=1+F_{2n-2}\cdot F_{2n+2} \sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n}}\right)=\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{\sqrt{1+F_{2n-2}\cdot F_{2n+2}}}\right) \mathcal{S}=1.30850 28221 75405 19611 19578 86489...,"['calculus', 'sequences-and-series', 'fibonacci-numbers']"
13,"I'm a late-bloomer, apparently. Do I have any hope of college? [closed]","I'm a late-bloomer, apparently. Do I have any hope of college? [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 8 years ago . Improve this question I'll keep this short. I'm a 26-year-old high school dropout. College never seemed to be in my cards. (I come from a poor family and higher education was always seen as a pipe dream.) My grades in school were abysmal, but not for lack of intelligence; I was the kid who'd draw patterns on my Scantron answer sheet and then nap until the bell rang. Academics meant nothing, so I dropped out, got my GED (near-perfect score without having studied, btw), and moved on with my life. Anyway, when I was 23, I decided to look into the strange world of mathematics. I bought a used algebra textbook, and, to my surprise, was easy. I worked through the whole thing, cover to cover, in about a month. I became curious at that point, so I continued learning. By the end of the fifth month, I had learned geometry, and in another month or two I had gone through a trig textbook. Long story short, within a year and a half of self-study, I went from knowing rudimentary algebra to passing the CLEP calculus exam. I haven't gone any further than that, but never once did I find myself puzzled by any concept. It all made sense to me. As a 26-year-old with nothing but a GED, is it too late to start college, assuming I find the money for it? Thanks for your time!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 8 years ago . Improve this question I'll keep this short. I'm a 26-year-old high school dropout. College never seemed to be in my cards. (I come from a poor family and higher education was always seen as a pipe dream.) My grades in school were abysmal, but not for lack of intelligence; I was the kid who'd draw patterns on my Scantron answer sheet and then nap until the bell rang. Academics meant nothing, so I dropped out, got my GED (near-perfect score without having studied, btw), and moved on with my life. Anyway, when I was 23, I decided to look into the strange world of mathematics. I bought a used algebra textbook, and, to my surprise, was easy. I worked through the whole thing, cover to cover, in about a month. I became curious at that point, so I continued learning. By the end of the fifth month, I had learned geometry, and in another month or two I had gone through a trig textbook. Long story short, within a year and a half of self-study, I went from knowing rudimentary algebra to passing the CLEP calculus exam. I haven't gone any further than that, but never once did I find myself puzzled by any concept. It all made sense to me. As a 26-year-old with nothing but a GED, is it too late to start college, assuming I find the money for it? Thanks for your time!",,"['calculus', 'career-development']"
14,"Infinitely $more$ algebraic numbers $\gamma$ and $\delta$ for $_2F_1\left(a,b;\tfrac12;\gamma\right)=\delta$?",Infinitely  algebraic numbers  and  for ?,"more \gamma \delta _2F_1\left(a,b;\tfrac12;\gamma\right)=\delta","Given the Elliptic integral singular value $K(k_m)$ , Dedekind eta $\eta(\tau)$ , j-function $j(\tau)$ , and hypergeometric $_2F_1\left(a,b;c;z\right)$ with $\color{brown}{a+b=c=\tfrac12}$ . Conjecture: ""The proposed equalities below hold for real $N>1$ , though for any integer $N>1$ , then the hypergeometric function $_2F_1(z)$ and its argument $z$ are algebraic numbers ."" I. For $a=\tfrac14$ and $\tau=N\sqrt{-\color{blue}4}$ $$\begin{aligned}\,_2F_1\left(\tfrac14,\tfrac14;\tfrac12;\,(1-2w)^2\right) &=\frac{N+1}{2}\frac{(1+\sqrt2)}{4\sqrt2}\frac{_2F_1\left(\tfrac12,\tfrac12;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}4)}\\[2mm] \end{aligned}\tag1$$ $$w=\frac{16}{16+\Big(\tfrac{\eta(\tau/4)}{\eta(\tau)}\Big)^8}$$ Example: If $N=2$ so $\tau=2\sqrt{-4}$ , then, $$_2F_1\left(\tfrac14,\tfrac14;\tfrac12;\,\tfrac{9\,(1-2\sqrt2)^2}{(1+\sqrt2)^4}\right)=\tfrac{3}{4\sqrt2}(1+\sqrt2)$$ II. For $a=\tfrac16$ and $\tau=N\sqrt{-\color{blue}3}$ $$\begin{aligned}\,_2F_1\left(\tfrac16,\tfrac13;\tfrac12;\,(1-2w)^2\right) &=\frac{N+1}{2}\frac{1}{27^{1/4}}\frac{_2F_1\left(\tfrac13,\tfrac23;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}3)}\\[2mm] \end{aligned}\tag2$$ $$w=\frac{27}{27+\Big(\tfrac{\eta(\tau/3)}{\eta(\tau)}\Big)^{12}}$$ Example: If $N=2$ so $\tau=2\sqrt{-3}$ , then, $$_2F_1\left(\tfrac16,\tfrac13;\tfrac12;\,\tfrac{25}{27}\right)=\tfrac{3\sqrt3}{4}$$ III. For $a=\tfrac18$ and $\tau=N\sqrt{-\color{blue}2}$ $$\begin{aligned}\,_2F_1\left(\tfrac18,\tfrac38;\tfrac12;\,(1-2w)^2\right) &=\frac{N+1}{2}\frac{\sqrt{1+\sqrt2}}{128^{1/4}}\frac{_2F_1\left(\tfrac14,\tfrac34;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}2)}\\[2mm] \end{aligned}\tag3$$ $$w=\frac{64}{64+\Big(\tfrac{\eta(\tau/2)}{\eta(\tau)}\Big)^{24}}$$ Example: If $N=3$ so $\tau=3\sqrt{-2}$ , then, $$_2F_1\left(\tfrac18,\tfrac38;\tfrac12;\tfrac{2400}{2401}\right)=\tfrac{2\sqrt7}{3}$$ IV. For $a=\tfrac1{12}$ and $\tau=N\sqrt{-\color{blue}1}$ $$\begin{aligned}\,_2F_1\left(\tfrac1{12},\tfrac5{12};\tfrac12;\,(1-2w)^2\right) &=\frac{N+1}{2}\frac{1}{12^{1/4}}\frac{_2F_1\left(\tfrac16,\tfrac56;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}1)}\\[2mm] \end{aligned}\tag4$$ $$\frac{12^3}{4w(1-w)} =j(\tau)$$ Example: If $N=2$ so $\tau=2\sqrt{-1}$ , then, $$_2F_1\left(\tfrac1{12},\tfrac5{12};\tfrac12;\tfrac{1323}{1331}\right)=\tfrac{3\,\sqrt[4]{11}}{4}$$ This is a highly compactified version of the results by Zucker and Joyce in "" Special values of the hypergeometric series II, III "" but I used a common form for the argument $z = (1-2w)^2$ as well as similar eta quotients to better illustrate their affinity. However, I only derived this empirically. Q: How do we rigorously prove the four conjectures?","Given the Elliptic integral singular value , Dedekind eta , j-function , and hypergeometric with . Conjecture: ""The proposed equalities below hold for real , though for any integer , then the hypergeometric function and its argument are algebraic numbers ."" I. For and Example: If so , then, II. For and Example: If so , then, III. For and Example: If so , then, IV. For and Example: If so , then, This is a highly compactified version of the results by Zucker and Joyce in "" Special values of the hypergeometric series II, III "" but I used a common form for the argument as well as similar eta quotients to better illustrate their affinity. However, I only derived this empirically. Q: How do we rigorously prove the four conjectures?","K(k_m) \eta(\tau) j(\tau) _2F_1\left(a,b;c;z\right) \color{brown}{a+b=c=\tfrac12} N>1 N>1 _2F_1(z) z a=\tfrac14 \tau=N\sqrt{-\color{blue}4} \begin{aligned}\,_2F_1\left(\tfrac14,\tfrac14;\tfrac12;\,(1-2w)^2\right)
&=\frac{N+1}{2}\frac{(1+\sqrt2)}{4\sqrt2}\frac{_2F_1\left(\tfrac12,\tfrac12;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}4)}\\[2mm]
\end{aligned}\tag1 w=\frac{16}{16+\Big(\tfrac{\eta(\tau/4)}{\eta(\tau)}\Big)^8} N=2 \tau=2\sqrt{-4} _2F_1\left(\tfrac14,\tfrac14;\tfrac12;\,\tfrac{9\,(1-2\sqrt2)^2}{(1+\sqrt2)^4}\right)=\tfrac{3}{4\sqrt2}(1+\sqrt2) a=\tfrac16 \tau=N\sqrt{-\color{blue}3} \begin{aligned}\,_2F_1\left(\tfrac16,\tfrac13;\tfrac12;\,(1-2w)^2\right)
&=\frac{N+1}{2}\frac{1}{27^{1/4}}\frac{_2F_1\left(\tfrac13,\tfrac23;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}3)}\\[2mm]
\end{aligned}\tag2 w=\frac{27}{27+\Big(\tfrac{\eta(\tau/3)}{\eta(\tau)}\Big)^{12}} N=2 \tau=2\sqrt{-3} _2F_1\left(\tfrac16,\tfrac13;\tfrac12;\,\tfrac{25}{27}\right)=\tfrac{3\sqrt3}{4} a=\tfrac18 \tau=N\sqrt{-\color{blue}2} \begin{aligned}\,_2F_1\left(\tfrac18,\tfrac38;\tfrac12;\,(1-2w)^2\right)
&=\frac{N+1}{2}\frac{\sqrt{1+\sqrt2}}{128^{1/4}}\frac{_2F_1\left(\tfrac14,\tfrac34;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}2)}\\[2mm]
\end{aligned}\tag3 w=\frac{64}{64+\Big(\tfrac{\eta(\tau/2)}{\eta(\tau)}\Big)^{24}} N=3 \tau=3\sqrt{-2} _2F_1\left(\tfrac18,\tfrac38;\tfrac12;\tfrac{2400}{2401}\right)=\tfrac{2\sqrt7}{3} a=\tfrac1{12} \tau=N\sqrt{-\color{blue}1} \begin{aligned}\,_2F_1\left(\tfrac1{12},\tfrac5{12};\tfrac12;\,(1-2w)^2\right)
&=\frac{N+1}{2}\frac{1}{12^{1/4}}\frac{_2F_1\left(\tfrac16,\tfrac56;1;\,w\right)}{\pi^{-1}\,K(k_\color{blue}1)}\\[2mm]
\end{aligned}\tag4 \frac{12^3}{4w(1-w)} =j(\tau) N=2 \tau=2\sqrt{-1} _2F_1\left(\tfrac1{12},\tfrac5{12};\tfrac12;\tfrac{1323}{1331}\right)=\tfrac{3\,\sqrt[4]{11}}{4} z = (1-2w)^2","['calculus', 'radicals', 'modular-forms', 'hypergeometric-function', 'conjectures']"
15,Juantheron-like integral,Juantheron-like integral,,"While seeing this post , the following integral is just struck me \begin{equation} \int_0^\infty \frac{dx}{(1+x^2)(1+\tan x)}\tag1 \end{equation} I have tried like what user @OlivierOloa did in his answer , but no luck with finding its closed-form. Using substitution $x\mapsto\tan x$ didn't make it any easier either. \begin{equation} \int_0^{\pi/2}\frac{dx}{1+\tan (\tan x)}\tag2 \end{equation} I reached a dead end in the attempt. How does one evaluate the integral $(1)$ or $(2)$?","While seeing this post , the following integral is just struck me \begin{equation} \int_0^\infty \frac{dx}{(1+x^2)(1+\tan x)}\tag1 \end{equation} I have tried like what user @OlivierOloa did in his answer , but no luck with finding its closed-form. Using substitution $x\mapsto\tan x$ didn't make it any easier either. \begin{equation} \int_0^{\pi/2}\frac{dx}{1+\tan (\tan x)}\tag2 \end{equation} I reached a dead end in the attempt. How does one evaluate the integral $(1)$ or $(2)$?",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
16,"Prove that $F_{2n}(x)=0$ has exactly one root in the interval $x\in(0,1),$ and this root $\to 0$ when $n \to \infty.$",Prove that  has exactly one root in the interval  and this root  when,"F_{2n}(x)=0 x\in(0,1), \to 0 n \to \infty.","Define $$f_1(x)=x\\f_2(x)=x^x\\\vdots\\f_{n+1}(x)=x^{f_n(x)}$$ Let $F_n(x)=f_n^{'}(x).$ Hence $$F_1(x)=1\\F_2(x)=x^x(1+\log(x))\\\vdots$$ Prove that $F_{2n}(x)=0$ has exactly one root in the interval $x\in(0,1),$ and this root $\to 0$ when $n \to \infty.$ Here are the images of $f_{2n}(x)$ for $n=1,2,\ldots,10.$","Define $$f_1(x)=x\\f_2(x)=x^x\\\vdots\\f_{n+1}(x)=x^{f_n(x)}$$ Let $F_n(x)=f_n^{'}(x).$ Hence $$F_1(x)=1\\F_2(x)=x^x(1+\log(x))\\\vdots$$ Prove that $F_{2n}(x)=0$ has exactly one root in the interval $x\in(0,1),$ and this root $\to 0$ when $n \to \infty.$ Here are the images of $f_{2n}(x)$ for $n=1,2,\ldots,10.$",,"['calculus', 'limits', 'roots', 'tetration', 'power-towers']"
17,Finding the tenth derivative of $f(x) = e^x\sin x$ at $x=0$ [duplicate],Finding the tenth derivative of  at  [duplicate],f(x) = e^x\sin x x=0,"This question already has answers here : $n$th derivative of $e^x \sin x$ (3 answers) Closed 5 years ago . I came across this Question where I have to find $$f^{(10)}$$ for the following function at $x = 0$ $$f(x) = e^x\sin x$$ I tried differentiating a few times to get a pattern but didnt get one, can someone provide the solution.","This question already has answers here : $n$th derivative of $e^x \sin x$ (3 answers) Closed 5 years ago . I came across this Question where I have to find for the following function at I tried differentiating a few times to get a pattern but didnt get one, can someone provide the solution.",f^{(10)} x = 0 f(x) = e^x\sin x,"['calculus', 'derivatives']"
18,Integration of $\int\frac{1}{x^{4}+1}\mathrm dx$,Integration of,\int\frac{1}{x^{4}+1}\mathrm dx,"I don't know how to integrate $\displaystyle \int\frac{1}{x^{4}+1}\mathrm dx$ . Do I have to use trigonometric substitution? Many duplicate posts link to this one as the target. (Those posts were merged into this one, which is the source of the many answers.)","I don't know how to integrate . Do I have to use trigonometric substitution? Many duplicate posts link to this one as the target. (Those posts were merged into this one, which is the source of the many answers.)",\displaystyle \int\frac{1}{x^{4}+1}\mathrm dx,"['calculus', 'integration', 'indefinite-integrals']"
19,"Determine $\lim_{x \to 0}{\frac{x-\sin{x}}{x^3}}=\frac{1}{6}$, without L'Hospital or Taylor","Determine , without L'Hospital or Taylor",\lim_{x \to 0}{\frac{x-\sin{x}}{x^3}}=\frac{1}{6},How can I prove that $$\lim_{x \to 0}{\frac{x-\sin{x}}{x^3}}=\frac{1}{6}$$ without using L'Hospital or Taylor series? thanks :),How can I prove that $$\lim_{x \to 0}{\frac{x-\sin{x}}{x^3}}=\frac{1}{6}$$ without using L'Hospital or Taylor series? thanks :),,"['calculus', 'limits', 'limits-without-lhopital']"
20,Fallacious proof involving trigonometry,Fallacious proof involving trigonometry,,"Which step in the following incorrect proof is fallacious? Is it something with the use of indefinite integrals or with the domain and range of trignometric functions? I encountered this fallacious proof here . $$ \int\tan(x)\,dx=\int\tan(x)\,dx $$ substitute $\tan(x)$ : $$ \int\tan(x)\,dx=\int\sin(x)\sec(x)\,dx $$ Integrate by parts, assume $$ u=\sec(x),dv=\sin(x)\,dx $$ Therefore, $$ \int\tan(x)\,dx=-\sec(x)\cos(x)+\int\cos(x)\tan(x)\sec(x)\,dx $$ but $\cos(x)\sec(x)=1$ so: $$ \int\tan(x)\,dx=-1+\int\tan(x)\,dx $$ we subtract both sides by $\int\tan(x)\,dx$ : $$ \int\tan(x)\,dx-\int\tan(x)\,dx =-1+\int\tan(x)\,dx-\int\tan(x)\,dx $$ then: $0=-1$ Thanks in advance for any help.","Which step in the following incorrect proof is fallacious? Is it something with the use of indefinite integrals or with the domain and range of trignometric functions? I encountered this fallacious proof here . $$ \int\tan(x)\,dx=\int\tan(x)\,dx $$ substitute $\tan(x)$ : $$ \int\tan(x)\,dx=\int\sin(x)\sec(x)\,dx $$ Integrate by parts, assume $$ u=\sec(x),dv=\sin(x)\,dx $$ Therefore, $$ \int\tan(x)\,dx=-\sec(x)\cos(x)+\int\cos(x)\tan(x)\sec(x)\,dx $$ but $\cos(x)\sec(x)=1$ so: $$ \int\tan(x)\,dx=-1+\int\tan(x)\,dx $$ we subtract both sides by $\int\tan(x)\,dx$ : $$ \int\tan(x)\,dx-\int\tan(x)\,dx =-1+\int\tan(x)\,dx-\int\tan(x)\,dx $$ then: $0=-1$ Thanks in advance for any help.",,"['calculus', 'trigonometry', 'proof-explanation', 'fake-proofs', 'trigonometric-integrals']"
21,Proving $ \lim_{x\to\infty}\frac{\sqrt x\cos(x-x^2)}{x+1} = 0. $,Proving, \lim_{x\to\infty}\frac{\sqrt x\cos(x-x^2)}{x+1} = 0. ,"I have to prove that  $$ \lim_{x\to\infty}\frac{\sqrt x\cos(x-x^2)}{x+1} = 0. $$ I tried squaring both the denominator and numerator to get rid of $\sqrt{x}$ but then $\cos$ becomes $\cos^2$ and I do not know how to solve it/simplify it further. I have also tried to use the squeeze theorem with $a_n = 0$, and $$ b_n =\frac{\sqrt x\cos(x-x^2)}{x+1}, $$ but to no avail. I could not find another function that is greater than $b_n$ that has a limit of $0$.","I have to prove that  $$ \lim_{x\to\infty}\frac{\sqrt x\cos(x-x^2)}{x+1} = 0. $$ I tried squaring both the denominator and numerator to get rid of $\sqrt{x}$ but then $\cos$ becomes $\cos^2$ and I do not know how to solve it/simplify it further. I have also tried to use the squeeze theorem with $a_n = 0$, and $$ b_n =\frac{\sqrt x\cos(x-x^2)}{x+1}, $$ but to no avail. I could not find another function that is greater than $b_n$ that has a limit of $0$.",,"['calculus', 'limits']"
22,Why is this equation of what appears to be a circle not a function? How do show this algebraically.,Why is this equation of what appears to be a circle not a function? How do show this algebraically.,,"I know this is a circle (right?) and so for every x, there are 2 values of y (so y is not a function of x ), but how do I algebraically show this. This is the question: If I square root both sides, I get: $$y = \sqrt{4 - x^2} $$ But that seems to get rid of a y answer. If I reduce it, I get: $$y^2 = (2+x)(2-x)$$ But I still feel like I haven't algebraically shown this NOT to be a function.","I know this is a circle (right?) and so for every x, there are 2 values of y (so y is not a function of x ), but how do I algebraically show this. This is the question: If I square root both sides, I get: $$y = \sqrt{4 - x^2} $$ But that seems to get rid of a y answer. If I reduce it, I get: $$y^2 = (2+x)(2-x)$$ But I still feel like I haven't algebraically shown this NOT to be a function.",,['calculus']
23,What's my confusion with the chain rule? (Differentiating $x^x$),What's my confusion with the chain rule? (Differentiating ),x^x,"When deriving $x^x$, why can't you choose $u$ to be $x$, and find $\dfrac{d(x^u)}{du} \dfrac{du}{dx} = x^x$? Or you could go the other way and find $\dfrac{d(u^x)}{du}\dfrac{du}{dx}$, giving $\ln(x)\cdot{x^x}$? Both methods seem to be equally wrong.","When deriving $x^x$, why can't you choose $u$ to be $x$, and find $\dfrac{d(x^u)}{du} \dfrac{du}{dx} = x^x$? Or you could go the other way and find $\dfrac{d(u^x)}{du}\dfrac{du}{dx}$, giving $\ln(x)\cdot{x^x}$? Both methods seem to be equally wrong.",,"['calculus', 'chain-rule']"
24,Differentiating $y=x^{2}$,Differentiating,y=x^{2},"I am reading in a book about differentiating, but I am confused with one of the steps he takes.  We start with: $$\begin{align} y &= x^{2} \\ y + \mathrm{d}y &= (x + \mathrm{d}x)^2 \\ y + \mathrm{d}y &= x^2 + x\mathrm{d}x + x\mathrm{d}x + (\mathrm{d}x^2) \end{align}$$ Now the author simplifies this to: $$y + dy = x^2 + 2x\mathrm{d}x + (\mathrm{d}x^2)$$ I dislike how the middle term is simplified to $2x\mathrm{d}x$ instead of $2(x\mathrm{d}x)$ , as I feel like it is more intuitive on what is going.  As in, $2$ of the term $x\mathrm{d}x$ , instead of $2x\mathrm{d}x$ .  But I fear writing it as $2(x\mathrm{d}x)$ may result in an incorrect distributive property. Next, he omits the $(\mathrm{d}x^2)$ : $y + \mathrm{d}y = x^2 + 2x \mathrm{d}x$ . Subtract the original $y = x^2.$ : $$\mathrm{d}y = 2x \mathrm{d}x.$$ Now here is where I get confused: $$\frac{\mathrm{d}y}{\mathrm{d}x} = 2x.$$ How can he just divide both sides by $\mathrm{d}x$ !?  If the original term was $2$ of $x\mathrm{d}x$ , wouldn't it have to be written out as $2x * 2\mathrm{d}x$ , and thus divide both sides by $2\mathrm{d}x$ instead? I think the root of my confusion is how to properly simplify: $x\mathrm{d}x + x\mathrm{d}x$ . I trust that he is right, but I am looking for an explanation of why his simplification can work, and why $2(x\mathrm{d}x)$ would be incorrect.","I am reading in a book about differentiating, but I am confused with one of the steps he takes.  We start with: Now the author simplifies this to: I dislike how the middle term is simplified to instead of , as I feel like it is more intuitive on what is going.  As in, of the term , instead of .  But I fear writing it as may result in an incorrect distributive property. Next, he omits the : . Subtract the original : Now here is where I get confused: How can he just divide both sides by !?  If the original term was of , wouldn't it have to be written out as , and thus divide both sides by instead? I think the root of my confusion is how to properly simplify: . I trust that he is right, but I am looking for an explanation of why his simplification can work, and why would be incorrect.","\begin{align}
y &= x^{2} \\
y + \mathrm{d}y &= (x + \mathrm{d}x)^2 \\
y + \mathrm{d}y &= x^2 + x\mathrm{d}x + x\mathrm{d}x + (\mathrm{d}x^2)
\end{align} y + dy = x^2 + 2x\mathrm{d}x + (\mathrm{d}x^2) 2x\mathrm{d}x 2(x\mathrm{d}x) 2 x\mathrm{d}x 2x\mathrm{d}x 2(x\mathrm{d}x) (\mathrm{d}x^2) y + \mathrm{d}y = x^2 + 2x \mathrm{d}x y = x^2. \mathrm{d}y = 2x \mathrm{d}x. \frac{\mathrm{d}y}{\mathrm{d}x} = 2x. \mathrm{d}x 2 x\mathrm{d}x 2x * 2\mathrm{d}x 2\mathrm{d}x x\mathrm{d}x + x\mathrm{d}x 2(x\mathrm{d}x)","['calculus', 'derivatives']"
25,Why does $r = \cos \theta$ produce a circle?,Why does  produce a circle?,r = \cos \theta,"I am trying to do a double integral over the following region in polar coordinates: I know that the limits of integration are: $$\theta = -\frac{\pi}{2} \quad \to \quad \theta = \frac{\pi}{2} \\ r = 0 \quad \to \quad r = \cos \theta$$ However, I don't understand how $r = 0 \quad \to \quad r = \cos \theta$ works. Cosine is a function (not just a relation) meaning that it has only one value of $r$ for every value of $\theta$. However, it seems like the graph $r = \cos \theta$ has two values of $r$ for every value of $\theta$. Why does $r = \cos \theta$ produce a circle?","I am trying to do a double integral over the following region in polar coordinates: I know that the limits of integration are: $$\theta = -\frac{\pi}{2} \quad \to \quad \theta = \frac{\pi}{2} \\ r = 0 \quad \to \quad r = \cos \theta$$ However, I don't understand how $r = 0 \quad \to \quad r = \cos \theta$ works. Cosine is a function (not just a relation) meaning that it has only one value of $r$ for every value of $\theta$. However, it seems like the graph $r = \cos \theta$ has two values of $r$ for every value of $\theta$. Why does $r = \cos \theta$ produce a circle?",,"['calculus', 'integration', 'multivariable-calculus', 'analytic-geometry', 'polar-coordinates']"
26,Prove that $\int_0^\infty\left(\arctan \frac1x\right)^2 \mathrm d x = \pi\ln 2$,Prove that,\int_0^\infty\left(\arctan \frac1x\right)^2 \mathrm d x = \pi\ln 2,"Prove $$\int_0^\infty\left(\arctan \frac1x\right)^2 \mathrm d x = \pi\ln 2$$ Out of boredom, I decided to play with some integrals and Inverse Symbolic Calculator and accidentally found this to my surprise $$\int_0^\infty\Big(\arctan \frac1x\Big)^2 \mathrm d x = \pi\ln 2 \quad (\text{conjectural}) \,\,\, {\tag{1}} $$ Here is Wolfram Alpha computation which shows (1) to be true to 50 digits. Is (1) true and how to prove it? I can calculate $$\int_0^\infty\arctan \frac{1}{x^2}\mathrm d x = \frac{\pi}{\sqrt2}$$ easily by expanding $\arctan$ into Maclaurin series. But how to proceed with $\arctan^2$ ?","Prove Out of boredom, I decided to play with some integrals and Inverse Symbolic Calculator and accidentally found this to my surprise Here is Wolfram Alpha computation which shows (1) to be true to 50 digits. Is (1) true and how to prove it? I can calculate easily by expanding into Maclaurin series. But how to proceed with ?","\int_0^\infty\left(\arctan \frac1x\right)^2 \mathrm d x = \pi\ln 2 \int_0^\infty\Big(\arctan \frac1x\Big)^2 \mathrm d x = \pi\ln 2 \quad (\text{conjectural}) \,\,\, {\tag{1}}  \int_0^\infty\arctan \frac{1}{x^2}\mathrm d x = \frac{\pi}{\sqrt2} \arctan \arctan^2","['calculus', 'integration', 'improper-integrals', 'conjectures', 'experimental-mathematics']"
27,Mathematical function that converges towards $7$?,Mathematical function that converges towards ?,7,"My friends and I are finishing High School in Denmark. We have to do a math poster for some school activity, where the poster needs to have something to do with the number $7$. So my question is: does someone know a cool mathematical function that converges towards $7$?  We covered Calculus III, so we should be able to understand a little math!","My friends and I are finishing High School in Denmark. We have to do a math poster for some school activity, where the poster needs to have something to do with the number $7$. So my question is: does someone know a cool mathematical function that converges towards $7$?  We covered Calculus III, so we should be able to understand a little math!",,['calculus']
28,"In polynomial functions, is the midpoint of two adjacent minimum and maximum always a point of inflection?","In polynomial functions, is the midpoint of two adjacent minimum and maximum always a point of inflection?",,"For any generic polynomial function, it seems that a point of inflection is always half-way between the nearest minimum and maximum (if they exist). Is there a way to prove that midpoints of adjacent minima and maxima are POIs? Or might I be missing a simple counterexample?","For any generic polynomial function, it seems that a point of inflection is always half-way between the nearest minimum and maximum (if they exist). Is there a way to prove that midpoints of adjacent minima and maxima are POIs? Or might I be missing a simple counterexample?",,"['calculus', 'derivatives', 'polynomials']"
29,Proving $x^{4}+x^{3}+x^{2}+x+1$ is always positive for real $x$,Proving  is always positive for real,x^{4}+x^{3}+x^{2}+x+1 x,"So I was bored in class  and decided to graph polynomials in geogebra, I noticed that $x^{4}+x^{3}+x^{2}+x+1$ and $x^{6}+x^{5}+x^{4}+x^{3}+x^{2}+x+1$, are all above the x-axis. Now I am wondering if it is possible to prove that these polynomials (or maybe the first one) are above x-axis without finding the stationary points. (I ask this since I can't solve cubic equations without newtons method). I am also wondering that if every polynomial that has the format above, which starts with an even number power will be above the x-axis.","So I was bored in class  and decided to graph polynomials in geogebra, I noticed that $x^{4}+x^{3}+x^{2}+x+1$ and $x^{6}+x^{5}+x^{4}+x^{3}+x^{2}+x+1$, are all above the x-axis. Now I am wondering if it is possible to prove that these polynomials (or maybe the first one) are above x-axis without finding the stationary points. (I ask this since I can't solve cubic equations without newtons method). I am also wondering that if every polynomial that has the format above, which starts with an even number power will be above the x-axis.",,"['calculus', 'polynomials']"
30,Is there any way to integrate $\frac1{f(x)}$ in terms of the integral of $f(x)$?,Is there any way to integrate  in terms of the integral of ?,\frac1{f(x)} f(x),"Is there any way to find $$\int \frac1{f(x)}\mathrm dx$$ in terms of $\int f(x) \mathrm dx$, $f(x)$ and its derivatives?","Is there any way to find $$\int \frac1{f(x)}\mathrm dx$$ in terms of $\int f(x) \mathrm dx$, $f(x)$ and its derivatives?",,"['calculus', 'integration', 'functions']"
31,Is there a simple geometric proof of why two simple harmonic oscillators draw a circle?,Is there a simple geometric proof of why two simple harmonic oscillators draw a circle?,,"We all know that a circle can be drawn with the trigonometric functions $x=\cos(t),  y=\sin(t)$ . If we define the sine and cosine functions in terms of triangles (like we do in high school), then this is quite obvious. But then later on in our education, we learn that the solution to a simple harmonic oscillator is the sine function. A weight on an undamped spring goes back and forth following a sine wave over time, and that this is the intuition behind a lot of wave motion (like sound waves). However, it's not generally taught why the sine wave solution to simple harmonic motion is the same function as the sine wave as defined by triangles or circles. Or in other words, when you take two harmonic oscillators and plot their outputs as $x=\cos(t),  y=\sin(t)$ , why should they make a perfect circle? More specifically: it's intuitive enough that they must form a shape that makes a full loop of some kind. But why does it happen to be a perfect circle , as opposed to an alternative shape like a larger ""squircle"", or something smaller similar to a rhombus with rounded corners? After doing a bit of research, the best answer I've found is that if you independently derive the Taylor series for each of: $\sin(t)$ as defined by simple harmonic oscillator (as the negative of its second derivative) $\sin(x)$ as defined trigonometrically (as the opposite side of a right triangle over the hypoteneuse) Then you discover they're the same Taylor series and therefore the same function and therefore simple harmonic oscillators can be used to draw a circle. But I'm wondering two things. First, is there some kind of more intuitive, direct, ideally geometric explanation? Resorting to Taylor series certainly works as a formal proof, but it doesn't build any kind of intuitive understanding. And for something so foundational to math and engineering as circles and sine waves, it seems like there should be a more obvious link. And second, if there is no such intuitive explanation and we're forced to resort to the Taylor series equivalence, is there an easy yet rigorous way to derive that that doesn't involve mixing up the two origins/definitions of the sine function to do so? E.g. every example I can find of deriving the Taylor series expansion of a simple harmonic oscillator involves using a trigonometric identity at some point, e.g. to show that the derivative of sine is cosine. But this defeats the whole purpose because it assumes what I'm trying to prove -- that the simple harmonic oscillator sine wave is the same as the trigonometric sine wave in the first place.","We all know that a circle can be drawn with the trigonometric functions . If we define the sine and cosine functions in terms of triangles (like we do in high school), then this is quite obvious. But then later on in our education, we learn that the solution to a simple harmonic oscillator is the sine function. A weight on an undamped spring goes back and forth following a sine wave over time, and that this is the intuition behind a lot of wave motion (like sound waves). However, it's not generally taught why the sine wave solution to simple harmonic motion is the same function as the sine wave as defined by triangles or circles. Or in other words, when you take two harmonic oscillators and plot their outputs as , why should they make a perfect circle? More specifically: it's intuitive enough that they must form a shape that makes a full loop of some kind. But why does it happen to be a perfect circle , as opposed to an alternative shape like a larger ""squircle"", or something smaller similar to a rhombus with rounded corners? After doing a bit of research, the best answer I've found is that if you independently derive the Taylor series for each of: as defined by simple harmonic oscillator (as the negative of its second derivative) as defined trigonometrically (as the opposite side of a right triangle over the hypoteneuse) Then you discover they're the same Taylor series and therefore the same function and therefore simple harmonic oscillators can be used to draw a circle. But I'm wondering two things. First, is there some kind of more intuitive, direct, ideally geometric explanation? Resorting to Taylor series certainly works as a formal proof, but it doesn't build any kind of intuitive understanding. And for something so foundational to math and engineering as circles and sine waves, it seems like there should be a more obvious link. And second, if there is no such intuitive explanation and we're forced to resort to the Taylor series equivalence, is there an easy yet rigorous way to derive that that doesn't involve mixing up the two origins/definitions of the sine function to do so? E.g. every example I can find of deriving the Taylor series expansion of a simple harmonic oscillator involves using a trigonometric identity at some point, e.g. to show that the derivative of sine is cosine. But this defeats the whole purpose because it assumes what I'm trying to prove -- that the simple harmonic oscillator sine wave is the same as the trigonometric sine wave in the first place.","x=\cos(t),  y=\sin(t) x=\cos(t),  y=\sin(t) \sin(t) \sin(x)","['calculus', 'geometry', 'trigonometry', 'taylor-expansion', 'intuition']"
32,Why is there no product/quotient rule for integration?,Why is there no product/quotient rule for integration?,,"So it's known that there's no product rule and quotient rule for integration. But is there a reason why they don't exist, and the rules exist for differentiation?","So it's known that there's no product rule and quotient rule for integration. But is there a reason why they don't exist, and the rules exist for differentiation?",,"['calculus', 'integration', 'derivatives']"
33,Linear Algebra with functions,Linear Algebra with functions,,"Basically my question is - How to check for linear independence between functions ?! Let the group $\mathcal{F}(\mathbb{R},\mathbb{R})$   Be a group of real valued fnctions. i.e $\mathcal{F}(\mathbb{R},\mathbb{R})=\left\{ f:\mathbb{R}\rightarrow\mathbb{R}\right\} $ Let 3 functions $f_{1},f_{2},f_{3}$   be given such that $\forall x\in\mathbb{R}\,\,\,f_{1}=e^{x},\,\,f_{2}=e^{2x},\,\,f_{3}=e^{3x}$ $W=sp(f_{1},f_{2},f_{3})$   what is $dim(W)$  ? How to approach this question ? (from a linear algebra perspective) I know that $\forall x\in\mathbb{R}\,\,\,W=\alpha e^{x}+\beta e^{2x}+\gamma e^{3x}$ And to get the dimension I need to find the base of $W$ so I need to check whether the following holds true : $\forall x\in\mathbb{R}\,\,\alpha e^{x}+\beta e^{2x}+\gamma e^{3x}=0\,\Leftrightarrow\,\alpha,\beta,\gamma=0$ However when $x=0$   I get $\alpha+\beta+\gamma=0$   which leads to infinite amount of solutions. How to approach this question ?","Basically my question is - How to check for linear independence between functions ?! Let the group $\mathcal{F}(\mathbb{R},\mathbb{R})$   Be a group of real valued fnctions. i.e $\mathcal{F}(\mathbb{R},\mathbb{R})=\left\{ f:\mathbb{R}\rightarrow\mathbb{R}\right\} $ Let 3 functions $f_{1},f_{2},f_{3}$   be given such that $\forall x\in\mathbb{R}\,\,\,f_{1}=e^{x},\,\,f_{2}=e^{2x},\,\,f_{3}=e^{3x}$ $W=sp(f_{1},f_{2},f_{3})$   what is $dim(W)$  ? How to approach this question ? (from a linear algebra perspective) I know that $\forall x\in\mathbb{R}\,\,\,W=\alpha e^{x}+\beta e^{2x}+\gamma e^{3x}$ And to get the dimension I need to find the base of $W$ so I need to check whether the following holds true : $\forall x\in\mathbb{R}\,\,\alpha e^{x}+\beta e^{2x}+\gamma e^{3x}=0\,\Leftrightarrow\,\alpha,\beta,\gamma=0$ However when $x=0$   I get $\alpha+\beta+\gamma=0$   which leads to infinite amount of solutions. How to approach this question ?",,"['calculus', 'linear-algebra', 'functional-analysis', 'vector-spaces']"
34,Does the series $\sum n!/n^n$ converge or diverge?,Does the series  converge or diverge?,\sum n!/n^n,"so I used the root test, but i'm not quite sure if i'm allowed to. I think im performing the operations correctly,a and i keep ending up with $(1)^{\infty}$. So really my question is am i performing the operations wrong or do i have to use a different test?","so I used the root test, but i'm not quite sure if i'm allowed to. I think im performing the operations correctly,a and i keep ending up with $(1)^{\infty}$. So really my question is am i performing the operations wrong or do i have to use a different test?",,['calculus']
35,Intuition behind chain rule [duplicate],Intuition behind chain rule [duplicate],,This question already has answers here : Chain Rule Intuition (8 answers) Closed 10 years ago . What is the intuition behind chain rule in mathematics in particular why there is a multiplication in between?,This question already has answers here : Chain Rule Intuition (8 answers) Closed 10 years ago . What is the intuition behind chain rule in mathematics in particular why there is a multiplication in between?,,"['calculus', 'derivatives', 'intuition']"
36,How can we prove $\sum {\frac{1}{n^{1+1/n}}}$ is divergent?,How can we prove  is divergent?,\sum {\frac{1}{n^{1+1/n}}},We know that $\sum \frac{1}{n^p}$ is convergent for $p>1$ . However the series $\sum {\frac{1}{n^{1+1/n}}}$ is apparently divergent since $1+1/n$ tends to 1 as $n$ tends to infinity. But how to prove this? The root test fails expectedly and I haven't been able to find a smaller divergent series for comparison test.,We know that is convergent for . However the series is apparently divergent since tends to 1 as tends to infinity. But how to prove this? The root test fails expectedly and I haven't been able to find a smaller divergent series for comparison test.,\sum \frac{1}{n^p} p>1 \sum {\frac{1}{n^{1+1/n}}} 1+1/n n,"['calculus', 'sequences-and-series', 'divergent-series']"
37,"Evaluate $\int_0^4 \frac{\ln x}{\sqrt{4x-x^2}} \,\mathrm dx$",Evaluate,"\int_0^4 \frac{\ln x}{\sqrt{4x-x^2}} \,\mathrm dx","Evaluate $$\displaystyle\int_0^4 \frac{\ln x}{\sqrt{4x-x^2}} \,\mathrm dx$$ How do I evaluate this integral?  I know that the result is $0$, but I don't know how to obtain this.  Wolfram|Alpha yields a non-elementary antiderivative for the indefinite integral, so I don't think I can directly integrate and then plug in the upper/lower limits.","Evaluate $$\displaystyle\int_0^4 \frac{\ln x}{\sqrt{4x-x^2}} \,\mathrm dx$$ How do I evaluate this integral?  I know that the result is $0$, but I don't know how to obtain this.  Wolfram|Alpha yields a non-elementary antiderivative for the indefinite integral, so I don't think I can directly integrate and then plug in the upper/lower limits.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
38,Prove that $\int_0^1\frac{x\ln (1+x)}{1+x^2}dx=\frac{\pi^2}{96}+\frac{\ln^2 2}{8}$,Prove that,\int_0^1\frac{x\ln (1+x)}{1+x^2}dx=\frac{\pi^2}{96}+\frac{\ln^2 2}{8},"We know that $$\int_0^1\frac{\ln (1+x)}{1+x^2}dx=\frac{\pi}8\ln 2,$$ but how about $$\int_0^1\frac{x\ln (1+x)}{1+x^2}dx?$$Prove that $$\int_0^1\frac{x\ln (1+x)}{1+x^2}dx=\frac{\pi^2}{96}+\frac{\ln^2 2}{8}.$$","We know that $$\int_0^1\frac{\ln (1+x)}{1+x^2}dx=\frac{\pi}8\ln 2,$$ but how about $$\int_0^1\frac{x\ln (1+x)}{1+x^2}dx?$$Prove that $$\int_0^1\frac{x\ln (1+x)}{1+x^2}dx=\frac{\pi^2}{96}+\frac{\ln^2 2}{8}.$$",,"['calculus', 'integration', 'sequences-and-series', 'definite-integrals', 'harmonic-numbers']"
39,Proving that the maximum of two convex functions is also convex,Proving that the maximum of two convex functions is also convex,,"Here's a homework question I'm struggling with: Let $f,g$ two convex functions. Prove that $h(x)=\max\{f(x),g(x)\}$ is also convex I don't know where to begin. The only thing I had in mind was was to try proving that if a function is convex on two sets $A$ and $B$ , it is also convex on their union. That does not seem right though, for example, if I glue together $f(x)=x^2, g(x)=\frac{x^2}{1000}$ where $f$ is defined on $[0,1]$ and $g$ on $(1,2]$ . Anyway, that was the only thing I thought about. Any better ideas? thanks!","Here's a homework question I'm struggling with: Let two convex functions. Prove that is also convex I don't know where to begin. The only thing I had in mind was was to try proving that if a function is convex on two sets and , it is also convex on their union. That does not seem right though, for example, if I glue together where is defined on and on . Anyway, that was the only thing I thought about. Any better ideas? thanks!","f,g h(x)=\max\{f(x),g(x)\} A B f(x)=x^2, g(x)=\frac{x^2}{1000} f [0,1] g (1,2]",['calculus']
40,Summation of a term to infinity,Summation of a term to infinity,,I read through many tutorials but no one mentioned this explicitly. Is the following conversion valid? $$\sum_{k=0}^\infty \frac{k-1}{2^k} = \lim_{n\to \infty} \sum_{k=0}^n \frac{k-1}{2^k}$$ Please excuse if it seems stupid or too simple to ask in the forum.,I read through many tutorials but no one mentioned this explicitly. Is the following conversion valid? $$\sum_{k=0}^\infty \frac{k-1}{2^k} = \lim_{n\to \infty} \sum_{k=0}^n \frac{k-1}{2^k}$$ Please excuse if it seems stupid or too simple to ask in the forum.,,"['calculus', 'sequences-and-series', 'limits', 'summation']"
41,sum of reciprocals of derivative of polynomial at its roots,sum of reciprocals of derivative of polynomial at its roots,,"If $P(x)$ is a polynomial of degree $n > 1$ with only simple roots $a_1,\ldots,a_n$, is it true that $\frac 1{P'(a_1)} + \cdots + \frac 1{P'(a_n)} = 0$, and, if so, what is the proof?  I can see this directly for $n = 2,3,4$ with some brute force for $4$.","If $P(x)$ is a polynomial of degree $n > 1$ with only simple roots $a_1,\ldots,a_n$, is it true that $\frac 1{P'(a_1)} + \cdots + \frac 1{P'(a_n)} = 0$, and, if so, what is the proof?  I can see this directly for $n = 2,3,4$ with some brute force for $4$.",,"['calculus', 'polynomials', 'roots']"
42,"What do the $+,-$ mean in limit notation, like$\lim\limits_{t \to 0^+}$ and $\lim\limits_{t \to 0^-}$?","What do the  mean in limit notation, like and ?","+,- \lim\limits_{t \to 0^+} \lim\limits_{t \to 0^-}",I'm working on Laplace Transforms and have got to a section where they are talking about zero to the power plus or minus and that they are different. I can't remember what this means though. It's generally used in limits. $\lim\limits_{t\to 0^-}$ or $\lim\limits_{t\to 0^+}$ Any help would be much appreciated.,I'm working on Laplace Transforms and have got to a section where they are talking about zero to the power plus or minus and that they are different. I can't remember what this means though. It's generally used in limits. $\lim\limits_{t\to 0^-}$ or $\lim\limits_{t\to 0^+}$ Any help would be much appreciated.,,"['calculus', 'limits', 'notation']"
43,"Approaching to zero, but not equal to zero, then why do the points get overlapped?","Approaching to zero, but not equal to zero, then why do the points get overlapped?",,"It is my question when I was in Senior High School. Up to now, I have no idea about the correct explanation. I just accept it by faith :D Here  is the question: If the symbol $\Delta x \to 0$ does not mean $\Delta x =0$, how can the points $A$ and $B$ get overlapped which in turn, how can the line joining $A$ and $B$ become $C$, the tangent line to the curve $y=f(x)$ at point $A$? Thank you in advance.","It is my question when I was in Senior High School. Up to now, I have no idea about the correct explanation. I just accept it by faith :D Here  is the question: If the symbol $\Delta x \to 0$ does not mean $\Delta x =0$, how can the points $A$ and $B$ get overlapped which in turn, how can the line joining $A$ and $B$ become $C$, the tangent line to the curve $y=f(x)$ at point $A$? Thank you in advance.",,['calculus']
44,"Evaluating $\int_0^{\pi/2}\operatorname{arcsinh}(2\tan x)\,dx$",Evaluating,"\int_0^{\pi/2}\operatorname{arcsinh}(2\tan x)\,dx","How to prove $$\int_0^{\pi/2}\operatorname{arcsinh}(2\tan x) \, dx = \frac43G + \frac13\pi\ln\left(2+\sqrt3\right),$$ where $G$ is Catalan's constant? I have a premonition that this integral is related to $\Im\operatorname{Li}_2\left(2\pm\sqrt3\right)$ . Attempt $$\int_0^{\pi/2}\operatorname{arcsinh}(2\tan x) \, dx \\ =\int_0^\infty\frac{\operatorname{arcsinh}(2x)}{1+x^2} \, dx\\ =2\int_0^\infty\frac{x\cosh x}{4+\sinh^2x} \, dx\\ =2\int_0^\infty\frac{x\cosh x}{3+\cosh^2x} \, dx\\ =2\int_0^\infty\sum_{n=0}^\infty x(-3)^n\cosh^{-2n-1}(x) \, dx$$ I failed to integrate $x\cosh^{-2n-1}(x)$ . Mathematica returns a hypergeometric term while integrating it.",How to prove where is Catalan's constant? I have a premonition that this integral is related to . Attempt I failed to integrate . Mathematica returns a hypergeometric term while integrating it.,"\int_0^{\pi/2}\operatorname{arcsinh}(2\tan x) \, dx = \frac43G + \frac13\pi\ln\left(2+\sqrt3\right), G \Im\operatorname{Li}_2\left(2\pm\sqrt3\right) \int_0^{\pi/2}\operatorname{arcsinh}(2\tan x) \, dx \\ =\int_0^\infty\frac{\operatorname{arcsinh}(2x)}{1+x^2} \, dx\\
=2\int_0^\infty\frac{x\cosh x}{4+\sinh^2x} \, dx\\
=2\int_0^\infty\frac{x\cosh x}{3+\cosh^2x} \, dx\\
=2\int_0^\infty\sum_{n=0}^\infty x(-3)^n\cosh^{-2n-1}(x) \, dx x\cosh^{-2n-1}(x)","['calculus', 'integration', 'improper-integrals', 'trigonometric-integrals']"
45,Finding the angle between two line equations,Finding the angle between two line equations,,"I need to find the angle between two lines in $y = mx + b$ form and they are: \begin{equation*} y = 4x + 2~\text{and}~y = -x + 3 \end{equation*} I have no idea how to solve this and if you could please consider that I'm in Grade 12 Calculus and Vectors. So my knowledge consist of adding vectors, derivatives, etc. Somehow the answer is suppose to be 59 degrees but I don't know how to get that","I need to find the angle between two lines in $y = mx + b$ form and they are: \begin{equation*} y = 4x + 2~\text{and}~y = -x + 3 \end{equation*} I have no idea how to solve this and if you could please consider that I'm in Grade 12 Calculus and Vectors. So my knowledge consist of adding vectors, derivatives, etc. Somehow the answer is suppose to be 59 degrees but I don't know how to get that",,['calculus']
46,Are continuous functions monotonic for very small ranges?,Are continuous functions monotonic for very small ranges?,,"So I am wondering, if we have a continuous function $f : A \to B$, does a range $[x, x + h]$ exist for each $x\in A$ , $h = h(x)>0$ so that $f$ is monotonic in that range?","So I am wondering, if we have a continuous function $f : A \to B$, does a range $[x, x + h]$ exist for each $x\in A$ , $h = h(x)>0$ so that $f$ is monotonic in that range?",,"['calculus', 'examples-counterexamples']"
47,Why does Trapezoidal Rule have potential error greater than Midpoint?,Why does Trapezoidal Rule have potential error greater than Midpoint?,,"I can approximate the area beneath a curve using the Midpoint and Trapezoidal methods, with errors such that: $Error_m \leq \frac{k(b-a)^3}{24n^2}$ and $Error_T \leq \frac{k(b-a)^3}{12n^2}$. Doesn't this suggest that the Midpoint Method is twice as accurate as the Trapezoidal Method?","I can approximate the area beneath a curve using the Midpoint and Trapezoidal methods, with errors such that: $Error_m \leq \frac{k(b-a)^3}{24n^2}$ and $Error_T \leq \frac{k(b-a)^3}{12n^2}$. Doesn't this suggest that the Midpoint Method is twice as accurate as the Trapezoidal Method?",,"['calculus', 'sequences-and-series']"
48,Help solving $\int {\frac{8x^4+15x^3+16x^2+22x+4}{x(x+1)^2(x^2+2)}dx}$,Help solving,\int {\frac{8x^4+15x^3+16x^2+22x+4}{x(x+1)^2(x^2+2)}dx},"$\displaystyle\int {\frac{8x^4+15x^3+16x^2+22x+4}{x(x+1)^2(x^2+2)}\,\mathrm{d}x}$ I used partial fractions, solved $A = 2, C = 3$. $$\frac{A}{x} + \frac{B}{x+1} + \frac{C}{(x+1)^2} +\frac{(Dx+E)}{(x^2+2)}$$ \begin{align*} &8x^4+15x^3+16x^2+22x+4\\ &\quad = A(x+1)^2(x^2+2)+B(x)(x+1)(x^2+2)+C(x)(x^2+2)+(Dx+E)(x)(x+1)^2 \end{align*} Substitute in $x=0$ to get $4=A(1)(2)$, so  $A = 2$ $$6x^4+11x^3+10x^2+14x = B(x)(x+1)(x^2+2)+C(x)(x^2+2)+(Dx+E)(x)(x+1)^2$$ Substitute in $x=-1$ to get $$6-11+10-14 = C(-1)(1+2)$$ so $-9=-3C$, thus $C=3$. Leaving me what I have below: Which brings me to where I am currently stuck. $$6x^4 +8x^3 +10x^2+8x = B(x)(x+1)(x^2+2) + (Dx + E) (x) (x+1)^2$$ Is the next best move to use substitution to solve for $B$?","$\displaystyle\int {\frac{8x^4+15x^3+16x^2+22x+4}{x(x+1)^2(x^2+2)}\,\mathrm{d}x}$ I used partial fractions, solved $A = 2, C = 3$. $$\frac{A}{x} + \frac{B}{x+1} + \frac{C}{(x+1)^2} +\frac{(Dx+E)}{(x^2+2)}$$ \begin{align*} &8x^4+15x^3+16x^2+22x+4\\ &\quad = A(x+1)^2(x^2+2)+B(x)(x+1)(x^2+2)+C(x)(x^2+2)+(Dx+E)(x)(x+1)^2 \end{align*} Substitute in $x=0$ to get $4=A(1)(2)$, so  $A = 2$ $$6x^4+11x^3+10x^2+14x = B(x)(x+1)(x^2+2)+C(x)(x^2+2)+(Dx+E)(x)(x+1)^2$$ Substitute in $x=-1$ to get $$6-11+10-14 = C(-1)(1+2)$$ so $-9=-3C$, thus $C=3$. Leaving me what I have below: Which brings me to where I am currently stuck. $$6x^4 +8x^3 +10x^2+8x = B(x)(x+1)(x^2+2) + (Dx + E) (x) (x+1)^2$$ Is the next best move to use substitution to solve for $B$?",,"['calculus', 'integration']"
49,How to evaluate $\lim_{n \rightarrow \infty}\left(\frac{(2n)!}{n!n^n} \right)^{1/n}$?,How to evaluate ?,\lim_{n \rightarrow \infty}\left(\frac{(2n)!}{n!n^n} \right)^{1/n},Find$$\lim_{n \rightarrow \infty}\left(\frac{(2n)!}{n!n^n} \right)^{1/n}$$ is there some trick in this questions. seems it must simplify to something but I am unable to solve it.,Find$$\lim_{n \rightarrow \infty}\left(\frac{(2n)!}{n!n^n} \right)^{1/n}$$ is there some trick in this questions. seems it must simplify to something but I am unable to solve it.,,"['calculus', 'limits']"
50,What are some methods to show $\log$ is not a rational function?,What are some methods to show  is not a rational function?,\log,"It is easy to show $\log$ isn't a polynomial (no continuous extension to $\mathbb{R}$). More challenging is showing it isn't rational. Suppose it were a rational function. Then write, the fraction in lowest terms $$\log x =\frac{G(x)}{Q(x)} \Longleftrightarrow\frac{G(x)}{\log x} = Q(x)$$ Clearly, as $x \to 0$, $Q(x) \to 0$. However, $Q(x)$ then has $x$ as factor so that $$\frac{G(x)}{x\log x} = Q_2(x)$$ It is well known that $x \log x \to 0$ as $x \to 0$, so for $Q_2(x)$ to have a finite limit as $x \to 0$, which it must since it is a polynomial, $G(x) \to 0$ as $x \to 0$ so that $x$ is a factor of $G(x)$. This contradicts the assumption that $\frac{G}{Q}$ was in lowest terms. If there is something wrong with this, please comment, but my main question is What are some other ways to prove that $\log x$ isn't a rational function?","It is easy to show $\log$ isn't a polynomial (no continuous extension to $\mathbb{R}$). More challenging is showing it isn't rational. Suppose it were a rational function. Then write, the fraction in lowest terms $$\log x =\frac{G(x)}{Q(x)} \Longleftrightarrow\frac{G(x)}{\log x} = Q(x)$$ Clearly, as $x \to 0$, $Q(x) \to 0$. However, $Q(x)$ then has $x$ as factor so that $$\frac{G(x)}{x\log x} = Q_2(x)$$ It is well known that $x \log x \to 0$ as $x \to 0$, so for $Q_2(x)$ to have a finite limit as $x \to 0$, which it must since it is a polynomial, $G(x) \to 0$ as $x \to 0$ so that $x$ is a factor of $G(x)$. This contradicts the assumption that $\frac{G}{Q}$ was in lowest terms. If there is something wrong with this, please comment, but my main question is What are some other ways to prove that $\log x$ isn't a rational function?",,"['calculus', 'logarithms']"
51,How to prove the result of this definite integral?,How to prove the result of this definite integral?,,"During my work I came up with this integral: $$\mathcal{J} = \int_0^{+\infty} \frac{\sqrt{x}\ln(x)}{e^{\sqrt{x}}}\ \text{d}x$$ Mathematica has a very elegant and simple numerical result for this, which is $$\mathcal{J} = 12 - 8\gamma$$ where $\gamma$ is the Euler-Mascheroni constant. I tried to make some substitutions, but I failed. Any hint to proceed?","During my work I came up with this integral: $$\mathcal{J} = \int_0^{+\infty} \frac{\sqrt{x}\ln(x)}{e^{\sqrt{x}}}\ \text{d}x$$ Mathematica has a very elegant and simple numerical result for this, which is $$\mathcal{J} = 12 - 8\gamma$$ where $\gamma$ is the Euler-Mascheroni constant. I tried to make some substitutions, but I failed. Any hint to proceed?",,"['calculus', 'integration', 'definite-integrals']"
52,Does the symbol $\nabla^2$ has the same meaning in Laplace Equation and Hessian Matrix?,Does the symbol  has the same meaning in Laplace Equation and Hessian Matrix?,\nabla^2,"we know that the Laplace Equation can be written in the form: $$\nabla^2 \Phi=0$$ while in this equation,the symbol $\nabla^2 \Phi$ stand for $\sum_{i=1}^n\frac{\partial^2 \Phi}{\partial x_i^2}$ . At the same time, the Hessian Matrix is also denoted as $$H=\nabla^2f$$ My question is what does $\nabla^2$ really mean?","we know that the Laplace Equation can be written in the form: while in this equation,the symbol stand for . At the same time, the Hessian Matrix is also denoted as My question is what does really mean?",\nabla^2 \Phi=0 \nabla^2 \Phi \sum_{i=1}^n\frac{\partial^2 \Phi}{\partial x_i^2} H=\nabla^2f \nabla^2,"['calculus', 'notation', 'laplacian']"
53,What is the Fourier transform of $f(x)=e^{-x^2}$?,What is the Fourier transform of ?,f(x)=e^{-x^2},"I remember there is a special rule for this kind of function, but I can't remember what it was. Does anyone know?","I remember there is a special rule for this kind of function, but I can't remember what it was. Does anyone know?",,"['calculus', 'fourier-analysis', 'normal-distribution', 'fourier-transform']"
54,Simplification of an expression containing $\operatorname{Li}_3(x)$ terms,Simplification of an expression containing  terms,\operatorname{Li}_3(x),"In my computations I ended up with this result: $$\mathcal{K}=78\operatorname{Li}_3\left(\frac13\right)+15\operatorname{Li}_3\left(\frac23\right)-64\operatorname{Li}_3\left(\frac15\right)-102 \operatorname{Li}_3\left(\frac25\right)+126\operatorname{Li}_3\left(\frac35\right)\\+12\operatorname{Li}_3\left(\frac45\right)-89\operatorname{Li}_3\left(\frac16\right)-152\operatorname{Li}_3\left(\frac56\right)+63\operatorname{Li}_3\left(\frac38\right)+76\operatorname{Li}_3\left(\frac58\right).$$ I wonder if it's possible to simplify this expression somehow, e.g. to combine some trilogarithm terms to express them using logarithms, or at least to reduce the number of terms? I tried to apply identities given at MathWorld and Wolfram Functions , but could not make the overall expression simpler. Mathematica could not simplify it either.","In my computations I ended up with this result: $$\mathcal{K}=78\operatorname{Li}_3\left(\frac13\right)+15\operatorname{Li}_3\left(\frac23\right)-64\operatorname{Li}_3\left(\frac15\right)-102 \operatorname{Li}_3\left(\frac25\right)+126\operatorname{Li}_3\left(\frac35\right)\\+12\operatorname{Li}_3\left(\frac45\right)-89\operatorname{Li}_3\left(\frac16\right)-152\operatorname{Li}_3\left(\frac56\right)+63\operatorname{Li}_3\left(\frac38\right)+76\operatorname{Li}_3\left(\frac58\right).$$ I wonder if it's possible to simplify this expression somehow, e.g. to combine some trilogarithm terms to express them using logarithms, or at least to reduce the number of terms? I tried to apply identities given at MathWorld and Wolfram Functions , but could not make the overall expression simpler. Mathematica could not simplify it either.",,"['calculus', 'logarithms', 'special-functions', 'polylogarithm']"
55,Calculate integrals involving gamma function,Calculate integrals involving gamma function,,"What are the usual ways to follow in order to solve the integrals given below?  $$\begin{align*} I&=\int_0^1 \ln\Gamma(x)\,dx\\ J&=\int_0^1 x\ln\Gamma(x)\,dx \end{align*}$$","What are the usual ways to follow in order to solve the integrals given below?  $$\begin{align*} I&=\int_0^1 \ln\Gamma(x)\,dx\\ J&=\int_0^1 x\ln\Gamma(x)\,dx \end{align*}$$",,"['calculus', 'integration', 'special-functions', 'definite-integrals', 'gamma-function']"
56,Why do some integrals and derivatives have absolute values?,Why do some integrals and derivatives have absolute values?,,"I have noticed that some integrals and derivatives have absolute  value. For example: $$\int\frac 1 x \, dx=\ln|x|+c$$ for $x$ is not equal to zero. So, the point is why is there the absolute value of $x$?","I have noticed that some integrals and derivatives have absolute  value. For example: $$\int\frac 1 x \, dx=\ln|x|+c$$ for $x$ is not equal to zero. So, the point is why is there the absolute value of $x$?",,"['calculus', 'integration']"
57,"Evaluating $\int_{0}^{\pi}\ln (1+\cos x)\, dx$ [duplicate]",Evaluating  [duplicate],"\int_{0}^{\pi}\ln (1+\cos x)\, dx",This question already has answers here : How to find $\int_{0}^{\pi/2} \log ({1+\cos x}) dx$ using real-variable methods? (6 answers) Closed 7 years ago . The problem is $$\int_{0}^{\pi}\ln (1+\cos x)\ dx$$ What I tried was using standard limit formulas like changing $x$ to $\pi - x$ and I also tried integration by parts on it to no avail. Please help. Also this is my first question so please tell if I am wrong somewhere.,This question already has answers here : How to find $\int_{0}^{\pi/2} \log ({1+\cos x}) dx$ using real-variable methods? (6 answers) Closed 7 years ago . The problem is $$\int_{0}^{\pi}\ln (1+\cos x)\ dx$$ What I tried was using standard limit formulas like changing $x$ to $\pi - x$ and I also tried integration by parts on it to no avail. Please help. Also this is my first question so please tell if I am wrong somewhere.,,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'logarithms']"
58,Evaluating the integral with trigonometric integrand,Evaluating the integral with trigonometric integrand,,"While solving another problem I have come across this integral which I am unable to evaluate. Can someone please evaluate the following integral? Thank you. $$\int_0^{2\pi}\frac{1}{(2+\cos\theta)^2}\,d\theta.$$","While solving another problem I have come across this integral which I am unable to evaluate. Can someone please evaluate the following integral? Thank you. $$\int_0^{2\pi}\frac{1}{(2+\cos\theta)^2}\,d\theta.$$",,"['calculus', 'integration', 'definite-integrals']"
59,Why $\lim\limits_{n\to \infty}\left(1+\frac{1}{n}\right)^n$ doesn't evaluate to 1?,Why  doesn't evaluate to 1?,\lim\limits_{n\to \infty}\left(1+\frac{1}{n}\right)^n,"I am trying to identify what the flaw is exactly when reasoning about a limit such as the definition of $\mathbf e$: $$ \lim_{n\rightarrow \infty}\left(1+\frac{1}{n}\right)^n={e} $$ Now, I know there are ways of proving this limit, such as by considering the binomial expansion of $(1+\frac{1}{n})^n$ and comparing that to the Maclaurin series of $e$. So to make this clear, I am not looking for a proof of the limit definition of $e$. I tried searching for ""limit laws/rules"" but none of the rules I found described the above case. Hence, I am looking for a specific rule (or perhaps a certain perspective) that will help me realize why the above does not in fact evaluate to 1. My train of thought is as follows: at a first glance, if I wasn't already familiar with what the limit evaluates to, I probably would evaluate the expression inside the brackets first, and then apply the limit to the power. So, $$\displaystyle\lim_{n\to\infty}\frac{1}{n}=0\quad\text{and then}$$  $$\displaystyle\lim_{n\rightarrow \infty}\left(1+0\right)^n=\lim_{n\to\infty}1^n=1$$ Why is my reasoning flawed?","I am trying to identify what the flaw is exactly when reasoning about a limit such as the definition of $\mathbf e$: $$ \lim_{n\rightarrow \infty}\left(1+\frac{1}{n}\right)^n={e} $$ Now, I know there are ways of proving this limit, such as by considering the binomial expansion of $(1+\frac{1}{n})^n$ and comparing that to the Maclaurin series of $e$. So to make this clear, I am not looking for a proof of the limit definition of $e$. I tried searching for ""limit laws/rules"" but none of the rules I found described the above case. Hence, I am looking for a specific rule (or perhaps a certain perspective) that will help me realize why the above does not in fact evaluate to 1. My train of thought is as follows: at a first glance, if I wasn't already familiar with what the limit evaluates to, I probably would evaluate the expression inside the brackets first, and then apply the limit to the power. So, $$\displaystyle\lim_{n\to\infty}\frac{1}{n}=0\quad\text{and then}$$  $$\displaystyle\lim_{n\rightarrow \infty}\left(1+0\right)^n=\lim_{n\to\infty}1^n=1$$ Why is my reasoning flawed?",,"['calculus', 'sequences-and-series', 'limits', 'exponential-function', 'definition']"
60,Integrating $\frac{x^k }{1+\cosh(x)}$,Integrating,\frac{x^k }{1+\cosh(x)},"In the course of solving a certain problem, I've had to evaluate integrals of the form: $$\int_0^\infty \frac{x^k}{1+\cosh(x)} \mathrm{d}x $$ for several values of k. I've noticed that that, for k a positive integer other than 1, the result is seemingly always a dyadic rational multiple of $\zeta(k)$, which is not particularly surprising given some of the identities for $\zeta$ (k=7 is the first noninteger value). However, I've been unable to find a nice way to evaluate this integral. I'm reasonably sure there's a way to change this expression into $\int \frac{x^{k-1}}{e^x+1} \mathrm{d}x$, but all the things I tried didn't work. Integration by parts also got too messy quickly, and Mathematica couldn't solve it (though it could calculate for a particular value of k very easily). So I'm looking for a simple way to evaluate the above integral.","In the course of solving a certain problem, I've had to evaluate integrals of the form: $$\int_0^\infty \frac{x^k}{1+\cosh(x)} \mathrm{d}x $$ for several values of k. I've noticed that that, for k a positive integer other than 1, the result is seemingly always a dyadic rational multiple of $\zeta(k)$, which is not particularly surprising given some of the identities for $\zeta$ (k=7 is the first noninteger value). However, I've been unable to find a nice way to evaluate this integral. I'm reasonably sure there's a way to change this expression into $\int \frac{x^{k-1}}{e^x+1} \mathrm{d}x$, but all the things I tried didn't work. Integration by parts also got too messy quickly, and Mathematica couldn't solve it (though it could calculate for a particular value of k very easily). So I'm looking for a simple way to evaluate the above integral.",,"['calculus', 'integration', 'special-functions', 'riemann-zeta']"
61,trying to solve the nested sum $\sum_{n=1}^{\infty} \frac{1}{1^2+2^2+\dots+n^2} $,trying to solve the nested sum,\sum_{n=1}^{\infty} \frac{1}{1^2+2^2+\dots+n^2} ,"This sum grabbed my curiousity $$ \sum_{n=1}^{\infty}  \frac{1}{1^2+2^2+\dots+n^2} $$ I want to solve it with Calc II methods (that's the math I have). By getting a closed form for the expression in the denominator, it becomes this: $$ 6 \sum_{n=1}^{\infty}  \frac{1}{n(n+1)(2n+1)}  $$ First thing I did was partial fractions $$ 6 \sum_{n=1}^{\infty} \left( \frac{1}{n}  + \frac{1}{n+1}-  \frac{4}{2n+1} \right) $$ You can reindex the first two terms, but I couldn't reindex the $2n+1$ term to telescope with that combined term, my thought is it's not possible because it isn't in the form (n+integer). So I tried expressing it as an integral, viewing each term as multiplied by an $x$ evaluated between 0 and 1. Then deriving with respect to $x$ to produce an integral. $$ 6 \sum_{n=1}^{\infty}   \int_0^1  (x^{n-1} +x^n  - 4x^{2n}) dx $$ Switching the order of integration and summation, and doing some reindexing: $$ 6 \int_0^1  \left(3+ 2\sum_{n=0}^\infty x^n - 4 \sum_{n=0}^\infty (x^2)^n\right)dx $$ I've been doing decimal approximations the whole time, checking that my steps work. They do up to and including that point, the answer is about $1.3$ Next I used the geometric series expansion, and this is where the approximation goes wrong, so I believe this is a problematic step: $$ 6 \int_0^1  \left(3+  \frac{2}{1-x} - \frac{4}{1-x^2} \right)dx $$ This integral is easy to solve using partial fractions on the $x^2$ term. You get an answer of $6(3-2\ln2)$ , which is about $9.6$ The correct answer, based on some website that doesn't show steps, is $6(3-4\ln2)$ , which matches my approximation. I'm really stumped on what I'm doing wrong and how to get that correct answer. I've checked my algebra over and over and learned some latex to write this post. Any help is appreciated!","This sum grabbed my curiousity I want to solve it with Calc II methods (that's the math I have). By getting a closed form for the expression in the denominator, it becomes this: First thing I did was partial fractions You can reindex the first two terms, but I couldn't reindex the term to telescope with that combined term, my thought is it's not possible because it isn't in the form (n+integer). So I tried expressing it as an integral, viewing each term as multiplied by an evaluated between 0 and 1. Then deriving with respect to to produce an integral. Switching the order of integration and summation, and doing some reindexing: I've been doing decimal approximations the whole time, checking that my steps work. They do up to and including that point, the answer is about Next I used the geometric series expansion, and this is where the approximation goes wrong, so I believe this is a problematic step: This integral is easy to solve using partial fractions on the term. You get an answer of , which is about The correct answer, based on some website that doesn't show steps, is , which matches my approximation. I'm really stumped on what I'm doing wrong and how to get that correct answer. I've checked my algebra over and over and learned some latex to write this post. Any help is appreciated!","
\sum_{n=1}^{\infty}  \frac{1}{1^2+2^2+\dots+n^2}
 
6 \sum_{n=1}^{\infty}  \frac{1}{n(n+1)(2n+1)} 
 
6 \sum_{n=1}^{\infty} \left( \frac{1}{n}  + \frac{1}{n+1}-  \frac{4}{2n+1} \right)
 2n+1 x x 
6 \sum_{n=1}^{\infty}   \int_0^1  (x^{n-1} +x^n  - 4x^{2n}) dx
 
6 \int_0^1  \left(3+ 2\sum_{n=0}^\infty x^n - 4 \sum_{n=0}^\infty (x^2)^n\right)dx
 1.3 
6 \int_0^1  \left(3+  \frac{2}{1-x} - \frac{4}{1-x^2} \right)dx
 x^2 6(3-2\ln2) 9.6 6(3-4\ln2)","['calculus', 'polynomials', 'summation']"
62,"Show that $f^{(n)}(0)=0$ for $n=0,1,2, \dots$",Show that  for,"f^{(n)}(0)=0 n=0,1,2, \dots","Let $f: \mathbb{R} \rightarrow \mathbb{R}$ an infinitely many times differentiable function and $f(\frac{1}{n})=0$ for each $n \in \mathbb{N}$. Show that $f^{(n)}(0)=0$ for $n=0,1,2, \dots$ $$$$ Could you give me some hint what I could do?? I got stuck right now..","Let $f: \mathbb{R} \rightarrow \mathbb{R}$ an infinitely many times differentiable function and $f(\frac{1}{n})=0$ for each $n \in \mathbb{N}$. Show that $f^{(n)}(0)=0$ for $n=0,1,2, \dots$ $$$$ Could you give me some hint what I could do?? I got stuck right now..",,['calculus']
63,What is wrong with this fake proof that $\lim\limits_{n\rightarrow \infty}\sqrt[n]{n!} = 1$?,What is wrong with this fake proof that ?,\lim\limits_{n\rightarrow \infty}\sqrt[n]{n!} = 1,$$\lim_{n\rightarrow \infty}\sqrt[n]{n!}=\lim_{n\rightarrow \infty}\sqrt[n]{1}*\sqrt[n]{2}\cdots\cdot\sqrt[n]{n}=1\cdot1\cdot\ldots\cdot1=1$$ I already know that this is incorrect but I am wondering why. It probably has something to do with the fact that multiplication in $n!$ is done infinite number of times.,$$\lim_{n\rightarrow \infty}\sqrt[n]{n!}=\lim_{n\rightarrow \infty}\sqrt[n]{1}*\sqrt[n]{2}\cdots\cdot\sqrt[n]{n}=1\cdot1\cdot\ldots\cdot1=1$$ I already know that this is incorrect but I am wondering why. It probably has something to do with the fact that multiplication in $n!$ is done infinite number of times.,,"['calculus', 'sequences-and-series', 'limits', 'fake-proofs']"
64,Evaluate $\int \sqrt{1+x^{\frac{3}{2}}} \operatorname d x$,Evaluate,\int \sqrt{1+x^{\frac{3}{2}}} \operatorname d x,"I can't figure out how to integrate $$\int \sqrt{1+x^{\frac{3}{2}}} \operatorname d x$$ I've tried substitution by letting $u = x^3$, but it didn't go anywhere. I also tried to integrate using a trigonometric substitution, but that also got me nowhere. Then I tried Wolfram Alpha, and it got me even nowhere-er! If you could give me a hint as to where to go, I'll try to answer this question at a later time. Thanks!","I can't figure out how to integrate $$\int \sqrt{1+x^{\frac{3}{2}}} \operatorname d x$$ I've tried substitution by letting $u = x^3$, but it didn't go anywhere. I also tried to integrate using a trigonometric substitution, but that also got me nowhere. Then I tried Wolfram Alpha, and it got me even nowhere-er! If you could give me a hint as to where to go, I'll try to answer this question at a later time. Thanks!",,"['calculus', 'integration', 'indefinite-integrals']"
65,Evaluate $\int_{-\infty}^\infty \frac{\sin{(x\sin{x})}}{x^2}dx$.,Evaluate .,\int_{-\infty}^\infty \frac{\sin{(x\sin{x})}}{x^2}dx,"Evaluate $$\int_{-\infty}^\infty \frac{\sin{(x\sin{x})}}{x^2}dx.$$ Numerical investigation suggests that it equals $\pi$ . Let $f(\alpha)=\frac{1}{\pi}\int_{-\alpha}^\alpha \frac{\sin{(x\sin{x})}}{x^2}dx$ . Wolfram (free version) gives me the following results: $f(10)=0.992293$ $f(20)=0.996916$ $f(30)=0.998604$ $f(100)=0.999761$ $f(200)=0.999916$ $f(300)=0.999934$ But with even larger values of $\alpha$ , Wolfram behaves erratically: $f(1\times10^5)=2.12907$ $f(2\times10^5)=0.574468$ $f(3\times10^5)=0.351411$ And finally, Wolfram gives: $f(\infty)=0.998775$ But in the comments, @NN2 said that the paid version of Wolfram gives some detailed warnings about the accuracy of this last result. Perhaps someone with more reliable computing power could shed some light on $f(\infty)$ . My attempt I tried to use some of the techniques for proving $\int_0^\infty {\sin{x}\over x}dx=\pi/2$ , to no avail. For example, this one sets up $I(a)=\int_0^\infty e^{-ax}\frac{\sin x}{x}dx$ , then evaluates $I'(a)$ via integration by parts. If we just have $\sin{x}$ this is easy, but the fact that $\int_0^\infty{\sin{(x\sin{x})}\over x^2}dx$ involves a sine within a sine, seems to make everything difficult. Context I've been searching (in vain) for a definite integral with no numbers that equals $\pi/7$ , and I stumbled upon this integral. I was surprised that it seems to admit a closed form, $\pi$ .","Evaluate Numerical investigation suggests that it equals . Let . Wolfram (free version) gives me the following results: But with even larger values of , Wolfram behaves erratically: And finally, Wolfram gives: But in the comments, @NN2 said that the paid version of Wolfram gives some detailed warnings about the accuracy of this last result. Perhaps someone with more reliable computing power could shed some light on . My attempt I tried to use some of the techniques for proving , to no avail. For example, this one sets up , then evaluates via integration by parts. If we just have this is easy, but the fact that involves a sine within a sine, seems to make everything difficult. Context I've been searching (in vain) for a definite integral with no numbers that equals , and I stumbled upon this integral. I was surprised that it seems to admit a closed form, .",\int_{-\infty}^\infty \frac{\sin{(x\sin{x})}}{x^2}dx. \pi f(\alpha)=\frac{1}{\pi}\int_{-\alpha}^\alpha \frac{\sin{(x\sin{x})}}{x^2}dx f(10)=0.992293 f(20)=0.996916 f(30)=0.998604 f(100)=0.999761 f(200)=0.999916 f(300)=0.999934 \alpha f(1\times10^5)=2.12907 f(2\times10^5)=0.574468 f(3\times10^5)=0.351411 f(\infty)=0.998775 f(\infty) \int_0^\infty {\sin{x}\over x}dx=\pi/2 I(a)=\int_0^\infty e^{-ax}\frac{\sin x}{x}dx I'(a) \sin{x} \int_0^\infty{\sin{(x\sin{x})}\over x^2}dx \pi/7 \pi,"['calculus', 'complex-analysis', 'definite-integrals', 'improper-integrals', 'wolfram-alpha']"
66,How to find out the global minimum of the following expression,How to find out the global minimum of the following expression,,What is the global minimum of the expression \begin{align} |x-1| &+ |x-2|+|x-5|+|x-6|+|x-8|+|x-9|+|x- 10| \\&+  |x-11|+|x-12|+|x-17|+|x-24|+|x-31|+ |x-32|? \end{align} I've solved questions of this sort before but there were only 3 terms. I solved those by expanding all the terms in the modulus and drawing a graph. This question came in a paper which requires the student to solve it within 5 minutes. What's a better method?,What is the global minimum of the expression I've solved questions of this sort before but there were only 3 terms. I solved those by expanding all the terms in the modulus and drawing a graph. This question came in a paper which requires the student to solve it within 5 minutes. What's a better method?,"\begin{align} |x-1| &+ |x-2|+|x-5|+|x-6|+|x-8|+|x-9|+|x- 10| \\&+
 |x-11|+|x-12|+|x-17|+|x-24|+|x-31|+ |x-32|? \end{align}",[]
67,How to find $\int_0^1f(x)dx$ if $f(f(x))=1-x$?,How to find  if ?,\int_0^1f(x)dx f(f(x))=1-x,"A friend of mine gave this question to me : Find the value of $\int_0^1f(x)dx$ if $f$ is a real, non-constant, differentiable function satisfying $$f(f(x))=1-x  \space\space\space\space\space\space\forall x\in(0,1)$$ The only thing that came to my mind was to form a differential equation with the given equation and find a solution but that was a dead end. If someone could give me a hint on how to tackle this problem it would be great. EDIT: All this time wonghang and John Ma's answers had me convinced that this problem was not well thought-out. But like Sanket has pointed out, if we disregard the differentiable assumption for a while, does there now exist an $f$ satisfying the given conditions? Can someone find an example? I tried to produce one using some variants of the absolute value function but to no avail.","A friend of mine gave this question to me : Find the value of $\int_0^1f(x)dx$ if $f$ is a real, non-constant, differentiable function satisfying $$f(f(x))=1-x  \space\space\space\space\space\space\forall x\in(0,1)$$ The only thing that came to my mind was to form a differential equation with the given equation and find a solution but that was a dead end. If someone could give me a hint on how to tackle this problem it would be great. EDIT: All this time wonghang and John Ma's answers had me convinced that this problem was not well thought-out. But like Sanket has pointed out, if we disregard the differentiable assumption for a while, does there now exist an $f$ satisfying the given conditions? Can someone find an example? I tried to produce one using some variants of the absolute value function but to no avail.",,"['calculus', 'integration', 'functions', 'definite-integrals']"
68,Integral of $\sqrt{1-x^2}$ using integration by parts,Integral of  using integration by parts,\sqrt{1-x^2},I was asked to solve this indefinite integral using Integration by parts. $$\int \sqrt{1-x^2} dx$$ I know how to solve if use the substitution $x=\sin(t)$ but I'm looking for the Integration by parts way. any help would be very appreciated.,I was asked to solve this indefinite integral using Integration by parts. $$\int \sqrt{1-x^2} dx$$ I know how to solve if use the substitution $x=\sin(t)$ but I'm looking for the Integration by parts way. any help would be very appreciated.,,"['calculus', 'integration', 'indefinite-integrals']"
69,Elegant proof of $\int_{-\infty}^{\infty} \frac{dx}{x^4 + a x^2 + b ^2} =\frac {\pi} {b \sqrt{2b+a}}$?,Elegant proof of ?,\int_{-\infty}^{\infty} \frac{dx}{x^4 + a x^2 + b ^2} =\frac {\pi} {b \sqrt{2b+a}},"Let $a, b > 0$ satisfy $a^2-4b^2 \geq 0$. Then: $$\int_{-\infty}^{\infty} \frac{dx}{x^4 + a x^2 + b ^2} =\frac {\pi} {b \sqrt{2b+a}}$$ One way to calculate this is by computing the residues at the poles in the upper half-plane and integrating around the standard semicircle. However, the sum of the two residues becomes a complicated expression involving nested square roots, which magically simplifies to the concise expression above. Sometimes such 'magical' cancellations indicate that there is a faster, more elegant method to reach the same result. Is there a faster or more insightful way to compute the above integral?","Let $a, b > 0$ satisfy $a^2-4b^2 \geq 0$. Then: $$\int_{-\infty}^{\infty} \frac{dx}{x^4 + a x^2 + b ^2} =\frac {\pi} {b \sqrt{2b+a}}$$ One way to calculate this is by computing the residues at the poles in the upper half-plane and integrating around the standard semicircle. However, the sum of the two residues becomes a complicated expression involving nested square roots, which magically simplifies to the concise expression above. Sometimes such 'magical' cancellations indicate that there is a faster, more elegant method to reach the same result. Is there a faster or more insightful way to compute the above integral?",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
70,Matrix derivative $(Ax-b)^T(Ax-b)$,Matrix derivative,(Ax-b)^T(Ax-b),I am trying to find the minimum of $(Ax-b)^T(Ax-b)$ but I am not sure whether I am taking the derivative of this expression properly. What I did is the following: \begin{align*} \frac{\delta}{\delta x_i}\left(\sum_i \sum_j (A_{ij}x_i-b_i)(A_{ij}x_j-b_j)\right)&= \sum_j A_{ij}(A_{ij}x_j-b_j) + \sum_i A_{ij}(A_{ij}x_j-b_i)  \end{align*} but I'm not quite sure if this is correct and what the derivate would then be. Any help is appreciated.,I am trying to find the minimum of $(Ax-b)^T(Ax-b)$ but I am not sure whether I am taking the derivative of this expression properly. What I did is the following: \begin{align*} \frac{\delta}{\delta x_i}\left(\sum_i \sum_j (A_{ij}x_i-b_i)(A_{ij}x_j-b_j)\right)&= \sum_j A_{ij}(A_{ij}x_j-b_j) + \sum_i A_{ij}(A_{ij}x_j-b_i)  \end{align*} but I'm not quite sure if this is correct and what the derivate would then be. Any help is appreciated.,,"['calculus', 'matrices', 'derivatives', 'matrix-calculus']"
71,differentiate with respect to a function,differentiate with respect to a function,,"Let's say I have this function $f(x)=x$. I want to differentiate with respect to $x^2$. So I want to calculate $\large\frac{df(x)}{dx^2}$. In general, how can I calculate the derivative of a function $f(x)$ with respect to a function $g(x)$, so $\large\frac{df(x)}{dg(x)}$? (I dont know whether this is a good notation)?","Let's say I have this function $f(x)=x$. I want to differentiate with respect to $x^2$. So I want to calculate $\large\frac{df(x)}{dx^2}$. In general, how can I calculate the derivative of a function $f(x)$ with respect to a function $g(x)$, so $\large\frac{df(x)}{dg(x)}$? (I dont know whether this is a good notation)?",,"['calculus', 'derivatives']"
72,"Show that $f(x)=\sqrt 2$ has no solutions $f(x)=\sin x\cos x(2+\sin x)$ and $x\in [0,\frac{\pi}{2}]$.",Show that  has no solutions  and .,"f(x)=\sqrt 2 f(x)=\sin x\cos x(2+\sin x) x\in [0,\frac{\pi}{2}]","Show that $f(x)=\sqrt 2$ has no solutions when $$f(x)=\sin x\cos x(2+\sin x)$$ and $x\in [0,\frac{\pi}{2}]$ . My attempt: Since $f(x)$ is continuous in its domain, it is enough to show that maximum value attained by $f$ in $[0,\frac{\pi}{2}]$ is less than $\sqrt 2$ . Also, since $f(0)=f(\pi/2)=0$ , it must hold true that $f'(c)=0$ for some $c\in[0,\frac{\pi}{2}]$ (Rolle's Theorem). And since $f(\pi/6)>0$ , there has to exist a maxima. But differentiation doesn't help me here, because when I set $f'(x)$ to $0$ , I get (on rearrangement and using basic trigonometry) a cubic in $\sin x$ : $$3t^3+4t^2-2t-2=0$$ where $t=\sin x$ . The above cubic doesn't have any rational roots and I'm stuck. Any help will be great. Thanks! Edit: I created this question by myself to solve in a pen-paper test. So methods that involve usage of calculators are useless. No offence. P.S. Please keep in mind that I'm barely seventeen, so no highly advance math please!","Show that has no solutions when and . My attempt: Since is continuous in its domain, it is enough to show that maximum value attained by in is less than . Also, since , it must hold true that for some (Rolle's Theorem). And since , there has to exist a maxima. But differentiation doesn't help me here, because when I set to , I get (on rearrangement and using basic trigonometry) a cubic in : where . The above cubic doesn't have any rational roots and I'm stuck. Any help will be great. Thanks! Edit: I created this question by myself to solve in a pen-paper test. So methods that involve usage of calculators are useless. No offence. P.S. Please keep in mind that I'm barely seventeen, so no highly advance math please!","f(x)=\sqrt 2 f(x)=\sin x\cos x(2+\sin x) x\in [0,\frac{\pi}{2}] f(x) f [0,\frac{\pi}{2}] \sqrt 2 f(0)=f(\pi/2)=0 f'(c)=0 c\in[0,\frac{\pi}{2}] f(\pi/6)>0 f'(x) 0 \sin x 3t^3+4t^2-2t-2=0 t=\sin x","['calculus', 'derivatives', 'trigonometry']"
73,"Evaluate $\int_0^1\frac{\ln(1-x)}{x}\text{Li}_3\left(\frac{1+x}{2}\right)dx$ , $\int_0^1\frac{\ln^2(1-x)}{x}\text{Li}_2\left(\frac{1+x}{2} \right)dx$","Evaluate  ,",\int_0^1\frac{\ln(1-x)}{x}\text{Li}_3\left(\frac{1+x}{2}\right)dx \int_0^1\frac{\ln^2(1-x)}{x}\text{Li}_2\left(\frac{1+x}{2} \right)dx,"How can we evaluate the following integrals: $$\int_0^1\frac{\ln(1-x)}{x}\text{Li}_3\left(\frac{1 + x}{2} \right)\,dx\\ .\\ \int_0^1\frac{\ln^2(1-x)}{x}\text{Li}_2\left(\frac{1 + x}{2} \right)\,dx$$",How can we evaluate the following integrals:,"\int_0^1\frac{\ln(1-x)}{x}\text{Li}_3\left(\frac{1 + x}{2} \right)\,dx\\
.\\
\int_0^1\frac{\ln^2(1-x)}{x}\text{Li}_2\left(\frac{1 + x}{2} \right)\,dx","['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
74,Limit $\lim_{x \to \infty}{\sin{\sqrt{x+1}}-\sin{\sqrt{x}}}$,Limit,\lim_{x \to \infty}{\sin{\sqrt{x+1}}-\sin{\sqrt{x}}},I want to compute $$\lim_{x \to \infty}{\sin{\sqrt{x+1}}-\sin{\sqrt{x}}}.$$ Is it OK how I want to do? $$\sin{\sqrt{x+1}}-\sin{\sqrt{x}}=2\sin{\frac{\sqrt{x+1}-\sqrt{x}}{2}}\cos{\frac{\sqrt{x+1}+\sqrt{x}}{2}}=2\sin{\frac{1}{2(\sqrt{x+1}+\sqrt{x})}}\cos{\frac{\sqrt{x+1}+\sqrt{x}}{2}}$$ I'm not surem but I want to say that $$|\cos \frac{\sqrt{x+1}-\sqrt{x}}{2}| \leq 1$$ $$\sin{\frac{1}{2(\sqrt{x+1}+\sqrt{x})}} \to 0 \mbox{ when } x \to \infty$$ So the limit is $0$ ? I thinks is not because  if I say that $ \displaystyle|\sin{\frac{1}{2(\sqrt{x+1}+\sqrt{x})}}| \leq 1$ I will obtain that another limit than $0$. Thanks :),I want to compute $$\lim_{x \to \infty}{\sin{\sqrt{x+1}}-\sin{\sqrt{x}}}.$$ Is it OK how I want to do? $$\sin{\sqrt{x+1}}-\sin{\sqrt{x}}=2\sin{\frac{\sqrt{x+1}-\sqrt{x}}{2}}\cos{\frac{\sqrt{x+1}+\sqrt{x}}{2}}=2\sin{\frac{1}{2(\sqrt{x+1}+\sqrt{x})}}\cos{\frac{\sqrt{x+1}+\sqrt{x}}{2}}$$ I'm not surem but I want to say that $$|\cos \frac{\sqrt{x+1}-\sqrt{x}}{2}| \leq 1$$ $$\sin{\frac{1}{2(\sqrt{x+1}+\sqrt{x})}} \to 0 \mbox{ when } x \to \infty$$ So the limit is $0$ ? I thinks is not because  if I say that $ \displaystyle|\sin{\frac{1}{2(\sqrt{x+1}+\sqrt{x})}}| \leq 1$ I will obtain that another limit than $0$. Thanks :),,"['calculus', 'analysis', 'limits', 'trigonometry', 'radicals']"
75,What does $dx$ mean without $dy$?,What does  mean without ?,dx dy,I understand that  $dy/dx$ represents how $y$ changes as $x$ changes. But what does $dx$ mean in isolation? I have been told it means an infinitely small change in $x$ without $dx$ being zero. I would like a more rigorous definition.,I understand that  $dy/dx$ represents how $y$ changes as $x$ changes. But what does $dx$ mean in isolation? I have been told it means an infinitely small change in $x$ without $dx$ being zero. I would like a more rigorous definition.,,"['calculus', 'integration', 'derivatives', 'notation']"
76,Area of circle (double integral and cartesian coordinates)?,Area of circle (double integral and cartesian coordinates)?,,"I know that the area of a circle, $x^2+y^2=a^2$, in cylindrical coordinates is $$ \int\limits_{0}^{2\pi} \int\limits_{0}^{a} r \, dr \, d\theta = \pi a^2 $$ But how can find the same result with a double integral and only cartesian coordinates?","I know that the area of a circle, $x^2+y^2=a^2$, in cylindrical coordinates is $$ \int\limits_{0}^{2\pi} \int\limits_{0}^{a} r \, dr \, d\theta = \pi a^2 $$ But how can find the same result with a double integral and only cartesian coordinates?",,"['calculus', 'integration', 'multivariable-calculus']"
77,How to prove: $\left(\frac{2}{\sqrt{4-3\sqrt[4]{5}+2\sqrt[4]{25}-\sqrt[4]{125}}}-1\right)^{4}=5$?,How to prove: ?,\left(\frac{2}{\sqrt{4-3\sqrt[4]{5}+2\sqrt[4]{25}-\sqrt[4]{125}}}-1\right)^{4}=5,"Question: show that: the beautiful ${\tt sqrt}$-identity: $$ \left({2 \over \sqrt{\vphantom{\Large A}\, 4\ -\ 3\,\sqrt[4]{\,5\,}\ +\ 2\,\sqrt[4]{\,25\,}\ - \,\sqrt[4]{\,125\,}\,}\,}\ -\ 1\right)^{4} =5 $$ Can you someone have methods to prove this by hand? (Maybe this problem have many methods?because this result is integer. It's a surprise to me.) Thank you Because I found this $$4\ -\ 3\sqrt[4]{\,5\,}\ +\ 2\sqrt[4]{\,25\,}\ -\ \sqrt[4]{\,125\,}$$ is not square numbers.","Question: show that: the beautiful ${\tt sqrt}$-identity: $$ \left({2 \over \sqrt{\vphantom{\Large A}\, 4\ -\ 3\,\sqrt[4]{\,5\,}\ +\ 2\,\sqrt[4]{\,25\,}\ - \,\sqrt[4]{\,125\,}\,}\,}\ -\ 1\right)^{4} =5 $$ Can you someone have methods to prove this by hand? (Maybe this problem have many methods?because this result is integer. It's a surprise to me.) Thank you Because I found this $$4\ -\ 3\sqrt[4]{\,5\,}\ +\ 2\sqrt[4]{\,25\,}\ -\ \sqrt[4]{\,125\,}$$ is not square numbers.",,"['calculus', 'arithmetic', 'radicals']"
78,"Integrating $\int_0^\infty \frac{\log x}{(1+x)^3}\,\operatorname d\!x$ using residues",Integrating  using residues,"\int_0^\infty \frac{\log x}{(1+x)^3}\,\operatorname d\!x","I am trying to use residues to compute $$\int_0^\infty\frac{\log x}{(1+x)^3}\,\operatorname d\!x.$$My first attempt involved trying to take a circular contour with the branch cut being the positive real axis, but this ended up cancelling off the term I wanted. I wasn't sure if there was another contour I should use. I also had someone suggest using the substitution $x=e^z$, so the integral becomes $$\int_{-\infty}^\infty\frac{ze^z}{(1+e^z)^3}\,\operatorname d\!z$$so that the poles are the at the odd multiples of $i\pi$. I haven't actually worked this out, but it does not seem like the solution the author was looking for (this question comes from an old preliminary exam). Any suggestions on how to integrate?","I am trying to use residues to compute $$\int_0^\infty\frac{\log x}{(1+x)^3}\,\operatorname d\!x.$$My first attempt involved trying to take a circular contour with the branch cut being the positive real axis, but this ended up cancelling off the term I wanted. I wasn't sure if there was another contour I should use. I also had someone suggest using the substitution $x=e^z$, so the integral becomes $$\int_{-\infty}^\infty\frac{ze^z}{(1+e^z)^3}\,\operatorname d\!z$$so that the poles are the at the odd multiples of $i\pi$. I haven't actually worked this out, but it does not seem like the solution the author was looking for (this question comes from an old preliminary exam). Any suggestions on how to integrate?",,"['calculus', 'complex-analysis', 'integration', 'contour-integration', 'residue-calculus']"
79,Very indeterminate form: $\lim_{x \to \infty} \left(\sqrt{x^2+2x+3} -\sqrt{x^2+3}\right)^x \longrightarrow (\infty-\infty)^{\infty}$,Very indeterminate form:,\lim_{x \to \infty} \left(\sqrt{x^2+2x+3} -\sqrt{x^2+3}\right)^x \longrightarrow (\infty-\infty)^{\infty},"Here is problem: $$\lim_{x \to \infty} \left(\sqrt{x^2+2x+3} -\sqrt{x^2+3}\right)^x$$ The solution I presented in the picture below was made by a Mathematics Teacher I tried to solve this Limit without using derivative (L'hospital) and Big O notation. Although I get the answer, I don't know if the technique I'm using definitely correct. And here is my method: $$\begin{align*}\lim_{x \to \infty} \left(\sqrt{x^2+2x+3} -\sqrt{x^2+3}\right)^x&=\lim_{x \to \infty} \left(\frac {2x}{\sqrt{x^2+2x+3} +\sqrt{x^2+3}}\right)^x\\&=\lim_{x \to \infty}\frac{1}{ \left(\frac {\sqrt{x^2+2x+3} +\sqrt{x^2+3}}{2x}\right)^x}\end{align*}$$ Then, I define a new function here $$y(x)=\sqrt{x^2+2x+3} +\sqrt{x^2+3}-2x-1$$ We have $$\begin{align*} \lim _{x\to\infty} y(x)&=\lim_{x \to \infty}\sqrt{x^2+2x+3} +\sqrt{x^2+3}-2x-1\\ &=\lim_{x \to \infty}(\sqrt{x^2+2x+3}-(x+1))+(\sqrt{x^2+3}-x)\\ &=\lim_{x \to \infty}\frac{2}{\sqrt{x^2+2x+3}+x+1}+ \lim_{x \to \infty}\frac{3}{\sqrt{x^2+3}+x}\\ &=0.  \end{align*}$$ This implies that $$\lim_{x \to \infty}\frac{2x}{y(x)+1}=\infty $$ Therefore, $$\begin{align*} \lim_{x \to \infty}\frac{1}{ \left(\frac {\sqrt{x^2+2x+3} +\sqrt{x^2+3}}{2x}\right)^x}&=\lim_{x \to\infty} \frac{1}{ \left(\frac{y(x)+2x+1}{2x} \right)^x}\\ &=\lim_{x \to\infty} \frac{1}{ \left(1+\frac{y(x)+1}{2x} \right)^x}\\ &=\lim_{x \to \infty}\frac{1}{\left( \left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}}\right)^{\frac{y(x)+1}{2}}}\\ & \end{align*}$$ Here, we define two functions: $$f(x)=\left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}},\quad g(x)=\frac{y(x)+1}{2}. $$ We deduce that, $$ \lim_{x\to\infty} f(x)=e>0,\quad \lim_{x\to\infty} g(x)=\frac 12>0. $$ Thus, the limit $\lim_{x\to\infty} f(x)^{g(x)} $ exists and is finite. Finally we get, $$\begin{align*}  \lim_{x \to \infty}\frac{1}{\left( \left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}}\right)^{\frac{y(x)+1}{2}}} &=\frac{1}{\lim_{x \to \infty}\left( \left( \left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}}\right)^{\frac{y(x)+1}{2}}\right)}\\ &=\frac{1}{\left(\lim_{x\to\infty} \left( 1+\frac{1}{\frac{2x}{y(x)+1}} \right)^{\frac{2x}{y(x)+1}}\right)^{ \lim_{x\to\infty} \frac{y(x)+1}{2}}}\\  &=\frac {1}{e^{\frac12}}=\frac{\sqrt e}{e}.\\&& \end{align*}$$ Is the method I use correct? I have received criticisms against my work. What can I do to make the method I use, rigorous? What are the points I missed in the method? Thank you!","Here is problem: The solution I presented in the picture below was made by a Mathematics Teacher I tried to solve this Limit without using derivative (L'hospital) and Big O notation. Although I get the answer, I don't know if the technique I'm using definitely correct. And here is my method: Then, I define a new function here We have This implies that Therefore, Here, we define two functions: We deduce that, Thus, the limit exists and is finite. Finally we get, Is the method I use correct? I have received criticisms against my work. What can I do to make the method I use, rigorous? What are the points I missed in the method? Thank you!","\lim_{x \to \infty} \left(\sqrt{x^2+2x+3} -\sqrt{x^2+3}\right)^x \begin{align*}\lim_{x \to \infty} \left(\sqrt{x^2+2x+3} -\sqrt{x^2+3}\right)^x&=\lim_{x \to \infty} \left(\frac {2x}{\sqrt{x^2+2x+3} +\sqrt{x^2+3}}\right)^x\\&=\lim_{x \to \infty}\frac{1}{ \left(\frac {\sqrt{x^2+2x+3} +\sqrt{x^2+3}}{2x}\right)^x}\end{align*} y(x)=\sqrt{x^2+2x+3} +\sqrt{x^2+3}-2x-1 \begin{align*}
\lim _{x\to\infty} y(x)&=\lim_{x \to \infty}\sqrt{x^2+2x+3} +\sqrt{x^2+3}-2x-1\\
&=\lim_{x \to \infty}(\sqrt{x^2+2x+3}-(x+1))+(\sqrt{x^2+3}-x)\\
&=\lim_{x \to \infty}\frac{2}{\sqrt{x^2+2x+3}+x+1}+ \lim_{x \to \infty}\frac{3}{\sqrt{x^2+3}+x}\\
&=0. 
\end{align*} \lim_{x \to \infty}\frac{2x}{y(x)+1}=\infty  \begin{align*}
\lim_{x \to \infty}\frac{1}{ \left(\frac {\sqrt{x^2+2x+3} +\sqrt{x^2+3}}{2x}\right)^x}&=\lim_{x \to\infty} \frac{1}{ \left(\frac{y(x)+2x+1}{2x} \right)^x}\\
&=\lim_{x \to\infty} \frac{1}{ \left(1+\frac{y(x)+1}{2x} \right)^x}\\
&=\lim_{x \to \infty}\frac{1}{\left( \left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}}\right)^{\frac{y(x)+1}{2}}}\\
&
\end{align*} f(x)=\left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}},\quad
g(x)=\frac{y(x)+1}{2}.
 
\lim_{x\to\infty} f(x)=e>0,\quad \lim_{x\to\infty} g(x)=\frac 12>0.
 \lim_{x\to\infty} f(x)^{g(x)}  \begin{align*} 
\lim_{x \to \infty}\frac{1}{\left( \left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}}\right)^{\frac{y(x)+1}{2}}}
&=\frac{1}{\lim_{x \to \infty}\left( \left( \left( 1+\frac{1}{\frac{2x}{y(x)+1}}\right)^{\frac{2x}{y(x)+1}}\right)^{\frac{y(x)+1}{2}}\right)}\\
&=\frac{1}{\left(\lim_{x\to\infty} \left( 1+\frac{1}{\frac{2x}{y(x)+1}} \right)^{\frac{2x}{y(x)+1}}\right)^{ \lim_{x\to\infty} \frac{y(x)+1}{2}}}\\ 
&=\frac {1}{e^{\frac12}}=\frac{\sqrt e}{e}.\\&&
\end{align*}","['calculus', 'limits', 'proof-verification', 'alternative-proof', 'limits-without-lhopital']"
80,"Find a continuous function $f:[1,\infty)\to\Bbb R $ such that $f(x) >0 $, $\int_1^\infty f(x)\,dx $ converges and $\int_1^\infty f(x)^2\,dx$ diverges","Find a continuous function  such that ,  converges and  diverges","f:[1,\infty)\to\Bbb R  f(x) >0  \int_1^\infty f(x)\,dx  \int_1^\infty f(x)^2\,dx","I'm trying to find an example of a continuous function $f:[1,\infty) \to \Bbb R $ such that  $$f(x) >0 $$ $$\int_{1}^{\infty} f(x) \ dx \ \text{converges and } \int_{1} ^{\infty} f(x)^2 dx \ \text{diverges}.$$","I'm trying to find an example of a continuous function $f:[1,\infty) \to \Bbb R $ such that  $$f(x) >0 $$ $$\int_{1}^{\infty} f(x) \ dx \ \text{converges and } \int_{1} ^{\infty} f(x)^2 dx \ \text{diverges}.$$",,['calculus']
81,Why doesn't this operation work?,Why doesn't this operation work?,,"In my maths class we are learning about indefinite integrals, this is the problem we were working on: $$ \int \frac{1}{2x+1}dx $$ Using u-substitution we obtain: $$ \frac{1}{2}\ln\left | 2x+1 \right | + C $$ But why does it not work to pull out a $\frac{1}{2}$ so that we don't have to do u-substitution $$ \frac{1}{2}\int \frac{1}{x+\frac{1}{2}}dx $$ This yields a completely different result $$ \frac{1}{2}\ln \left |x+\frac{1}{2}\right | + C_1 \neq \frac{1}{2}\ln\left | 2x+1 \right | + C_2 $$ Pulling out the $\frac{1}{2}$ seems like a completely valid move, so why does it get a completely different result?","In my maths class we are learning about indefinite integrals, this is the problem we were working on: $$ \int \frac{1}{2x+1}dx $$ Using u-substitution we obtain: $$ \frac{1}{2}\ln\left | 2x+1 \right | + C $$ But why does it not work to pull out a $\frac{1}{2}$ so that we don't have to do u-substitution $$ \frac{1}{2}\int \frac{1}{x+\frac{1}{2}}dx $$ This yields a completely different result $$ \frac{1}{2}\ln \left |x+\frac{1}{2}\right | + C_1 \neq \frac{1}{2}\ln\left | 2x+1 \right | + C_2 $$ Pulling out the $\frac{1}{2}$ seems like a completely valid move, so why does it get a completely different result?",,"['calculus', 'integration', 'indefinite-integrals']"
82,"Why is $\frac{\operatorname dy'}{\operatorname dy}$ zero, since $y'$ depends on $y$?","Why is  zero, since  depends on ?",\frac{\operatorname dy'}{\operatorname dy} y' y,"I know that $\frac{dy'(x)}{dy}=0$ (where $y'=\frac{dy(x)}{dx}$). The reason explained is that $y'$  does not depend explicitly on $y$. But intuitively, $y'$ depends on $y$, since if you vary $y$ you will modify $y'$. Why is my reasoning wrong (my reasoning sounds like it's related to functional calculus, instead of standard calculus)? I tried to write  $\frac{dy'(x)}{dy}=\frac{d}{dy}\frac{dy}{dx}=\frac{d}{dx}\frac{dy}{dy}=\frac{d}{dx}1=0$, but this proof doesn't convince me. I think that other way to see this is saying that if a function is of the form $f(y)$, it will not dependend on the variable $y'$.  But the same way you write $f(y)=y^2$, you could write $f(y)=\frac{d}{dx}y$, which clearly depends on $y'$. So I don't know if there are some types of operations which are restricted (for example, taking limits): Note: The problem raises in the context of Classical Mechanics, where: $\frac{\partial L(\dot{x},t)}{\partial x}=0$.","I know that $\frac{dy'(x)}{dy}=0$ (where $y'=\frac{dy(x)}{dx}$). The reason explained is that $y'$  does not depend explicitly on $y$. But intuitively, $y'$ depends on $y$, since if you vary $y$ you will modify $y'$. Why is my reasoning wrong (my reasoning sounds like it's related to functional calculus, instead of standard calculus)? I tried to write  $\frac{dy'(x)}{dy}=\frac{d}{dy}\frac{dy}{dx}=\frac{d}{dx}\frac{dy}{dy}=\frac{d}{dx}1=0$, but this proof doesn't convince me. I think that other way to see this is saying that if a function is of the form $f(y)$, it will not dependend on the variable $y'$.  But the same way you write $f(y)=y^2$, you could write $f(y)=\frac{d}{dx}y$, which clearly depends on $y'$. So I don't know if there are some types of operations which are restricted (for example, taking limits): Note: The problem raises in the context of Classical Mechanics, where: $\frac{\partial L(\dot{x},t)}{\partial x}=0$.",,"['calculus', 'partial-derivative', 'calculus-of-variations', 'classical-mechanics', 'euler-lagrange-equation']"
83,Regularization and $\int_{0}^{\infty}\sin x \;\mathrm{d}x$,Regularization and,\int_{0}^{\infty}\sin x \;\mathrm{d}x,"In my grad quantum/E&M classes I had to do intuition-bending regularization of integrals that didn't seem mathematically justified (but got full credit and were repeated in the solutions) like the following: $$\int_{0}^{\infty}\sin x \;\mathrm{d}x = \lim_{\alpha \to 0^+} \int_{0}^{\infty} e^{-\alpha x} \sin x \;\mathrm{d}x = \lim_{\alpha \to 0^+}\frac{1}{\alpha^2+1} = 1$$ which is unreasonable as $\int_{a}^{b}\sin x \;\mathrm{d}x = \cos(a)-\cos(b)$, or in our case $\lim_{b \to \infty} 1 - \cos(b) = \mathrm{undefined}$ as the limit doesn't converge. Is there any formal mathematics behind this line of thought claiming divergent things converge with regularization?  (E.g., similar to the infinite sums 1+1+1+... = -1/2 or 1+2+3+4+... = -1/12 )?","In my grad quantum/E&M classes I had to do intuition-bending regularization of integrals that didn't seem mathematically justified (but got full credit and were repeated in the solutions) like the following: $$\int_{0}^{\infty}\sin x \;\mathrm{d}x = \lim_{\alpha \to 0^+} \int_{0}^{\infty} e^{-\alpha x} \sin x \;\mathrm{d}x = \lim_{\alpha \to 0^+}\frac{1}{\alpha^2+1} = 1$$ which is unreasonable as $\int_{a}^{b}\sin x \;\mathrm{d}x = \cos(a)-\cos(b)$, or in our case $\lim_{b \to \infty} 1 - \cos(b) = \mathrm{undefined}$ as the limit doesn't converge. Is there any formal mathematics behind this line of thought claiming divergent things converge with regularization?  (E.g., similar to the infinite sums 1+1+1+... = -1/2 or 1+2+3+4+... = -1/12 )?",,"['calculus', 'integration', 'definite-integrals', 'regularization']"
84,Circular uses of LHpitals rule,Circular uses of LHpitals rule,,"If you try to find the $\lim_{x\to \infty}\frac{\sqrt{x^2+1}}{x}$ using LHpitals rule, youll find that it flip-flops back and forth between $\frac{\sqrt{x^2+1}}{x}$ and $\frac{x}{\sqrt{x^2+1}}$. Are there other expressions that do a similar thing when LHpitals rule is applied to them? I already know that this applies to any fraction of the form $\frac{\sqrt{x^{2n}+c}}{x^n}$.","If you try to find the $\lim_{x\to \infty}\frac{\sqrt{x^2+1}}{x}$ using LHpitals rule, youll find that it flip-flops back and forth between $\frac{\sqrt{x^2+1}}{x}$ and $\frac{x}{\sqrt{x^2+1}}$. Are there other expressions that do a similar thing when LHpitals rule is applied to them? I already know that this applies to any fraction of the form $\frac{\sqrt{x^{2n}+c}}{x^n}$.",,"['calculus', 'limits']"
85,Evaluate $\int_{0}^{1} \frac{\ln(1 + x + x^2 + \ldots + x^n)}{x}\mathrm d x$,Evaluate,\int_{0}^{1} \frac{\ln(1 + x + x^2 + \ldots + x^n)}{x}\mathrm d x,"How to evaluate: $$\int_{0}^{1} \frac{\ln(1 + x + x^2 + \ldots + x^n)}{x}\mathrm d x$$ Attempt: $$\int_{0}^{1}\frac{\ln(1 + x + x^2 + \ldots + x^n)}{x} \mathrm dx = \int_{0}^{1}\frac{\ln(1 -x^{n+1}) - \ln(1 - x)}{x}\mathrm d x$$ Any hints would be appreciated. Edit: Testing it with different values of $n$ , it seems like the integral evaluates to be $\frac{n \pi^2}{6(n+1)}$","How to evaluate: Attempt: Any hints would be appreciated. Edit: Testing it with different values of , it seems like the integral evaluates to be","\int_{0}^{1} \frac{\ln(1 + x + x^2 + \ldots + x^n)}{x}\mathrm d x \int_{0}^{1}\frac{\ln(1 + x + x^2 + \ldots + x^n)}{x} \mathrm dx
= \int_{0}^{1}\frac{\ln(1 -x^{n+1}) - \ln(1 - x)}{x}\mathrm d x n \frac{n \pi^2}{6(n+1)}","['calculus', 'integration', 'definite-integrals']"
86,Derivatives by complex number and conjugate,Derivatives by complex number and conjugate,,"Suppose we write a complex number $z=x+iy$. Then we have $\overline{z}=x-iy$, and therefore $x=\dfrac12(z+\overline{z})$, $y=-\dfrac12i(z-\overline{z})$. If the rules of calculus were applicable, we would obtain $$\frac{\partial{f}}{\partial{z}}=\frac12\left(\frac{\partial{f}}{\partial{x}}-i\frac{\partial{f}}{\partial{y}}\right), \frac{\partial{f}}{\partial{\overline{z}}}=\frac12\left(\frac{\partial{f}}{\partial{x}}+i\frac{\partial{f}}{\partial{y}}\right)$$ How does this follow from the rules of calculus?","Suppose we write a complex number $z=x+iy$. Then we have $\overline{z}=x-iy$, and therefore $x=\dfrac12(z+\overline{z})$, $y=-\dfrac12i(z-\overline{z})$. If the rules of calculus were applicable, we would obtain $$\frac{\partial{f}}{\partial{z}}=\frac12\left(\frac{\partial{f}}{\partial{x}}-i\frac{\partial{f}}{\partial{y}}\right), \frac{\partial{f}}{\partial{\overline{z}}}=\frac12\left(\frac{\partial{f}}{\partial{x}}+i\frac{\partial{f}}{\partial{y}}\right)$$ How does this follow from the rules of calculus?",,"['calculus', 'complex-analysis']"
87,"Finding the limits related to $a_1=1$, $a_{k+1}=\sqrt{a_1+a_2+\cdots +a_k}$","Finding the limits related to ,",a_1=1 a_{k+1}=\sqrt{a_1+a_2+\cdots +a_k},"Suppose $a_1=1, a_{k+1}=\sqrt{a_1+a_2+\cdots +a_k}, k \in \mathbb{N}$. Find the limits $$i)\space \lim_{n\to\infty}\displaystyle \frac{\sum_{k=1}^{n} a_{k}}{n\sqrt{n}}$$ $$ii)\space \lim_{n\to\infty}\displaystyle \frac{\sum_{k=1}^{n} a_{k}}{n^2}$$ I'm puzzled with it. What to do?","Suppose $a_1=1, a_{k+1}=\sqrt{a_1+a_2+\cdots +a_k}, k \in \mathbb{N}$. Find the limits $$i)\space \lim_{n\to\infty}\displaystyle \frac{\sum_{k=1}^{n} a_{k}}{n\sqrt{n}}$$ $$ii)\space \lim_{n\to\infty}\displaystyle \frac{\sum_{k=1}^{n} a_{k}}{n^2}$$ I'm puzzled with it. What to do?",,"['calculus', 'sequences-and-series', 'limits', 'recurrence-relations']"
88,Nested Radicals: $\sqrt{a+\sqrt{2a+\sqrt{3a+\ldots}}}$,Nested Radicals:,\sqrt{a+\sqrt{2a+\sqrt{3a+\ldots}}},Let $a>0$ . How we can find the limit of : $$\sqrt{a+\sqrt{2a+\sqrt{3a+\ldots}}}$$ Thanks in advance for your help,Let $a>0$ . How we can find the limit of : $$\sqrt{a+\sqrt{2a+\sqrt{3a+\ldots}}}$$ Thanks in advance for your help,,"['calculus', 'limits']"
89,How far can we go with $\int_{0}^{\infty} \frac{\ln \left(1+x^n\right)}{1+x^{2}} dx \textrm{ where }n\in N ?$,How far can we go with,\int_{0}^{\infty} \frac{\ln \left(1+x^n\right)}{1+x^{2}} dx \textrm{ where }n\in N ?,"Latest Edit Great thanks to @Quanto for giving us the complete solution to ALL even powers using two wonderful factorizations \begin{align} &1+x^{4m}= \prod_{k=1}^m \left(1+2x^2\cos\frac{(2k-1)\pi}{2m}+x^4 \right)\\ & 1+x^{4m+2}= (1+x^2)\prod_{k=1}^m \left(1+2x^2\cos\frac{2k\pi}{2m+1}+x^4\right) \end{align} and made use of the post that $$\int_0^\infty \frac{\ln(1+2x^2\cos \theta +x^4)}{1+x^2}dx =2\pi \ln\left(2\cos\frac{\theta}4\right) $$ to build up two decent formula for ALL even powers as below: $$\begin{align} &\int_0^\infty \frac{\ln(1+x^{4m})}{1+x^2}dx =2\pi \ln \bigg( 2^m \prod_{k=1}^m \cos\frac{(2k-1)\pi}{8m}\bigg)\ \\ &\int_0^\infty \frac{\ln(1+x^{4m+2})}{1+x^2}dx = \pi\ln2 + 2\pi \ln \bigg( 2^m \prod_{k=1}^m \cos\frac{k\pi}{2(2m+1)}\bigg) \end{align}$$ which can be merged into a single formula below: $$ \boxed{\int_0^\infty \frac{\ln(1+x^{2n})}{1+x^2}dx =\frac{1-(-1)^n}{2} \pi \ln 2+2 \pi \ln \left[2^{\left[\frac{n}{2}\right]} \prod_{k=1}^{\left[\frac{n}{2}\right]}\left(\cos \frac{(n-2 k+1) \pi}{4 n}\right)\right]} $$ where $n>1.$ Though the nut for odd powers is much harder, @J.G had cracked the nut partially by giving it a closed form with double sum. $$\boxed{\int_0^\infty\frac{\ln(1+x^n)}{1+x^2}dx=\frac{\pi}{4}\ln2+G+\sum_{k=0}^{(n-3)/2}\left(\pi\ln\left|2\sin\frac{\pi(2k+1)}{2n}\right|+\frac{\pi(n-4k-2)}{2n}\ln\left|\tan\frac{\pi(2k+1)}{2n}\right|+2\sum_{j\ge0}\frac{(-1)^{j+1}\cos\frac{\pi(2j+1)(2k+1)}{n}}{(2j+1)^2}\right)}$$ Would you like to try to simplify the sum over $j,\,k$ ? Backgound Couple months ago, I met the integrals $$ \int_{0}^{\infty} \frac{\ln \left(x\right)}{1+x^{2}} dx \stackrel{x\mapsto\frac{1}{x}}{=} -\int_{0}^{\infty} \frac{\ln \left(x\right)}{1+x^{2}} d x \Rightarrow \int_{0}^{\infty} \frac{\ln \left(x\right)}{1+x^{2}} dx =0 \tag*{} $$ $$\textrm{  and}$$ $$ I(0)=\int_{0}^{\infty} \frac{\ln 2}{1+x^{2}} d x=\frac{\pi}{2} \ln 2 $$ Then I started to investigate, in my post 1 , $$I(1)= \int_{0}^{\infty} \frac{\ln (1+x)}{1+x^{2}}dx=  \frac{\pi}{4} \ln 2+G $$ Next integral $$I(2)=\int_{0}^{\infty} \frac{\ln \left(1+x^2\right)}{1+x^{2}} dx \stackrel{x\mapsto\tan {\theta}}{=} -2 \int_{0}^{\frac{\pi}{2}} \ln (\cos \theta) d \theta=\pi \ln 2 $$ The third one is split into two integrals, first of which refer to my post 2 , $$\begin{aligned} I(3)&=\int_{0}^{\infty} \frac{\ln \left(1+x^{3}\right)}{1+x^{2}} d x\\&= \underbrace{\frac{\ln \left(1-x+x^{2}\right)}{1+x^{2}}}_{\frac{2 \pi}{3} \ln (2+\sqrt{3})-\frac{4}{3} G} d x+\underbrace{\int_{0}^{\infty} \frac{\ln (1+x)}{1+x^{2}}}_{\frac{\pi}{4} \ln 2+G} d x\\ &\boxed{\int_{0}^{\infty} \frac{\ln \left(1+x^{3}\right)}{1+x^{2}} d x =-\frac{G}{3}+\frac{\pi}{4} \ln 2 +\frac{2 \pi}{3}\ln(2+\sqrt{3})}\end{aligned} $$ The fourth one comes immediately after the my post 3 which states that $$J(a)=\int_{0}^{\infty} \frac{\ln \left(1+2 x \sin a+x^{2}\right)}{1+x^{2}} d x =\pi\ln \left|2 \cos \frac{a}{2}\right|+|a| \ln \left|\tan \frac{a}{2}\right|-2 \operatorname{sgn} (a) \int_{0}^{\frac{|a|}{2}} \ln (\tan x) d x$$ $$ \begin{aligned} I(4)&=\int_{0}^{\infty} \frac{\ln \left(1+x^{4}\right)}{1+x^{2}} d x\\&=\int_{0}^{\infty} \frac{\ln \left[\left(x^{2}+\sqrt{2} x+1\right)\left(x^{2}-\sqrt{2} x+1\right)\right]}{1+x^{2}} \\ &=J\left(\frac{\pi}{4}\right)+J\left(-\frac{\pi}{4}\right)\\& =2 \pi \ln \left(2 \cos \frac{\pi}{8}\right)\\& \boxed{\int_{0}^{\infty} \frac{\ln \left(1+x^{4}\right)}{1+x^{2}} d x =\pi \ln (2+\sqrt{2})} \end{aligned} $$ The harder one comes from the post 4 by @Quanto. $$ \begin{aligned}I(5)&=\int_0^1\frac{\ln(1+x^5)}{1+x^2}dx\\ &\boxed{= \frac15G -\frac{19\pi }{20}\ln 2+\frac{3\pi }{5}\ln 5+\frac{4\pi}5 \ln \left(1+\sqrt{1+\frac{2}{\sqrt{5}}}\right)+\frac{8\pi}5\ln \left(1+\sqrt{1-\frac{2}{\sqrt{5}}}\right)}\end{aligned} $$ When the power of $x$ is raised to the power $6$ , I first split the integral into 2. $$\int_0^1\frac{\ln(1+x^6)}{1+x^2}dx=  \underbrace{\int_{0}^{\infty} \frac{\ln \left(x^{2}+1\right)}{1+x^{2}} d x}_{=\pi \ln 2}+  \underbrace{\int_{0}^{\infty} \frac{\ln \left(x^{4}-x^{2}+1\right)}{1+x^{2}} d x }_{K} $$ For integral $K$ , we use the formula founded in my post 3 stating that $$J(a)=\int_{0}^{\infty} \frac{\ln \left(1+2 x \sin a+x^{2}\right)}{1+x^{2}} d x =\pi\ln \left|2 \cos \frac{a}{2}\right|+|a| \ln \left|\tan \frac{a}{2}\right|-2 \operatorname{sgn} (a) \int_{0}^{\frac{|a|}{2}} \ln (\tan x) d x$$ Then $$ \begin{aligned} K &=\int_{0}^{\infty} \frac{\ln \left(x^{4}-x^{2}+1\right)}{1+x^{2}} d x \\ &=\int_{0}^{\infty} \frac{\ln \left(x^{2}+\sqrt{3} x+1\right)}{1+x^{2}} d x+\int_{0}^{\infty} \frac{\ln \left(x^{2}-\sqrt{3} x+1 \right) }{1+x^{2}} dx\\ &=J\left(\frac{\pi}{3}\right)+J\left(-\frac{\pi}{3}\right) \\ &=2 \pi \ln \left(2 \cos \frac{\pi}{6}\right) \\ &=\pi \ln 3 \end{aligned} $$ $$ \boxed{ \int_{0}^{\infty} \frac{\ln \left(1+x^{6}\right)}{1+x^{2}} d x=\pi \ln 2+\pi \ln 3=\pi \ln 6 } $$ From my recent post , $$ \boxed{\int_{0}^{\infty} \frac{\ln \left(x^{4}+b x^{2}+1\right)}{1+x^{2}} d x = 2 \pi \ln \left[2 \cos \left(\frac{1}{4} \cos ^{-1}\left(\frac{b}{2}\right)\right)\right]} $$ $$ \begin{aligned} \int_{0}^{\infty} \frac{\ln \left(x^{8}+1\right)}{1+x^{2}}=& \int_{0}^{\infty} \frac{\ln \left(x^{4}+\sqrt{2} x+1\right)}{1+x^{2}} d x +\int_{0}^{\infty} \frac{\ln \left(x^{4}-\sqrt{2} x+1\right)}{1+x^{2}} d x \\ =& 2 \pi \ln \left[2 \cos \frac{1}{4} \cos ^{-1}\left(\frac{\sqrt{2}}{2}\right)\right] +2 \pi \ln \left[2 \cos \frac{1}{4} \cos ^{-1}\left(-\frac{\sqrt{2}}{2}\right)\right] \\ =& 2 \pi \ln \left(2 \cos \frac{\pi}{16}\right)+2 \pi \ln \left(2 \cos \frac{3 \pi}{16}\right)\\ =& 2 \pi \ln \left(2^2 \cos \frac{\pi}{16} \cos \frac{3 \pi}{16}\right)\\=& 2 \pi \ln (\sqrt{2}+\sqrt{2+\sqrt{2}}) \end{aligned} $$ Through the investigation, I found that it is very interesting to find their exact values as most of them are unexpectedly simple and decent except $I(5)$ . We can foresee the difficulty of the evaluation will be increased. My question is whether we can go further for $n=7$ and $n\geq 9.$ Your help and contributions will be highly appreciated.","Latest Edit Great thanks to @Quanto for giving us the complete solution to ALL even powers using two wonderful factorizations and made use of the post that to build up two decent formula for ALL even powers as below: which can be merged into a single formula below: where Though the nut for odd powers is much harder, @J.G had cracked the nut partially by giving it a closed form with double sum. Would you like to try to simplify the sum over ? Backgound Couple months ago, I met the integrals Then I started to investigate, in my post 1 , Next integral The third one is split into two integrals, first of which refer to my post 2 , The fourth one comes immediately after the my post 3 which states that The harder one comes from the post 4 by @Quanto. When the power of is raised to the power , I first split the integral into 2. For integral , we use the formula founded in my post 3 stating that Then From my recent post , Through the investigation, I found that it is very interesting to find their exact values as most of them are unexpectedly simple and decent except . We can foresee the difficulty of the evaluation will be increased. My question is whether we can go further for and Your help and contributions will be highly appreciated.","\begin{align}
&1+x^{4m}= \prod_{k=1}^m \left(1+2x^2\cos\frac{(2k-1)\pi}{2m}+x^4 \right)\\
& 1+x^{4m+2}= (1+x^2)\prod_{k=1}^m \left(1+2x^2\cos\frac{2k\pi}{2m+1}+x^4\right)
\end{align} \int_0^\infty \frac{\ln(1+2x^2\cos \theta +x^4)}{1+x^2}dx
=2\pi \ln\left(2\cos\frac{\theta}4\right)
 \begin{align}
&\int_0^\infty \frac{\ln(1+x^{4m})}{1+x^2}dx
=2\pi \ln \bigg( 2^m \prod_{k=1}^m \cos\frac{(2k-1)\pi}{8m}\bigg)\
\\
&\int_0^\infty \frac{\ln(1+x^{4m+2})}{1+x^2}dx
= \pi\ln2 + 2\pi \ln \bigg( 2^m \prod_{k=1}^m \cos\frac{k\pi}{2(2m+1)}\bigg)
\end{align} 
\boxed{\int_0^\infty \frac{\ln(1+x^{2n})}{1+x^2}dx =\frac{1-(-1)^n}{2} \pi \ln 2+2 \pi \ln \left[2^{\left[\frac{n}{2}\right]} \prod_{k=1}^{\left[\frac{n}{2}\right]}\left(\cos \frac{(n-2 k+1) \pi}{4 n}\right)\right]}
 n>1. \boxed{\int_0^\infty\frac{\ln(1+x^n)}{1+x^2}dx=\frac{\pi}{4}\ln2+G+\sum_{k=0}^{(n-3)/2}\left(\pi\ln\left|2\sin\frac{\pi(2k+1)}{2n}\right|+\frac{\pi(n-4k-2)}{2n}\ln\left|\tan\frac{\pi(2k+1)}{2n}\right|+2\sum_{j\ge0}\frac{(-1)^{j+1}\cos\frac{\pi(2j+1)(2k+1)}{n}}{(2j+1)^2}\right)} j,\,k 
\int_{0}^{\infty} \frac{\ln \left(x\right)}{1+x^{2}} dx \stackrel{x\mapsto\frac{1}{x}}{=} -\int_{0}^{\infty} \frac{\ln \left(x\right)}{1+x^{2}} d x \Rightarrow \int_{0}^{\infty} \frac{\ln \left(x\right)}{1+x^{2}} dx =0 \tag*{}
 \textrm{  and} 
I(0)=\int_{0}^{\infty} \frac{\ln 2}{1+x^{2}} d x=\frac{\pi}{2} \ln 2
 I(1)= \int_{0}^{\infty} \frac{\ln (1+x)}{1+x^{2}}dx=  \frac{\pi}{4} \ln 2+G  I(2)=\int_{0}^{\infty} \frac{\ln \left(1+x^2\right)}{1+x^{2}} dx \stackrel{x\mapsto\tan {\theta}}{=} -2 \int_{0}^{\frac{\pi}{2}} \ln (\cos \theta) d \theta=\pi \ln 2  \begin{aligned} I(3)&=\int_{0}^{\infty} \frac{\ln \left(1+x^{3}\right)}{1+x^{2}} d x\\&= \underbrace{\frac{\ln \left(1-x+x^{2}\right)}{1+x^{2}}}_{\frac{2 \pi}{3} \ln (2+\sqrt{3})-\frac{4}{3} G} d x+\underbrace{\int_{0}^{\infty} \frac{\ln (1+x)}{1+x^{2}}}_{\frac{\pi}{4} \ln 2+G} d x\\ &\boxed{\int_{0}^{\infty} \frac{\ln \left(1+x^{3}\right)}{1+x^{2}} d x =-\frac{G}{3}+\frac{\pi}{4} \ln 2 +\frac{2 \pi}{3}\ln(2+\sqrt{3})}\end{aligned}
 J(a)=\int_{0}^{\infty} \frac{\ln \left(1+2 x \sin a+x^{2}\right)}{1+x^{2}} d x =\pi\ln \left|2 \cos \frac{a}{2}\right|+|a| \ln \left|\tan \frac{a}{2}\right|-2 \operatorname{sgn} (a) \int_{0}^{\frac{|a|}{2}} \ln (\tan x) d x 
\begin{aligned}
I(4)&=\int_{0}^{\infty} \frac{\ln \left(1+x^{4}\right)}{1+x^{2}} d x\\&=\int_{0}^{\infty} \frac{\ln \left[\left(x^{2}+\sqrt{2} x+1\right)\left(x^{2}-\sqrt{2} x+1\right)\right]}{1+x^{2}} \\
&=J\left(\frac{\pi}{4}\right)+J\left(-\frac{\pi}{4}\right)\\& =2 \pi \ln \left(2 \cos \frac{\pi}{8}\right)\\& \boxed{\int_{0}^{\infty} \frac{\ln \left(1+x^{4}\right)}{1+x^{2}} d x =\pi \ln (2+\sqrt{2})}
\end{aligned}
  \begin{aligned}I(5)&=\int_0^1\frac{\ln(1+x^5)}{1+x^2}dx\\
&\boxed{= \frac15G -\frac{19\pi }{20}\ln 2+\frac{3\pi }{5}\ln 5+\frac{4\pi}5 \ln \left(1+\sqrt{1+\frac{2}{\sqrt{5}}}\right)+\frac{8\pi}5\ln \left(1+\sqrt{1-\frac{2}{\sqrt{5}}}\right)}\end{aligned}
 x 6 \int_0^1\frac{\ln(1+x^6)}{1+x^2}dx=  \underbrace{\int_{0}^{\infty} \frac{\ln \left(x^{2}+1\right)}{1+x^{2}} d x}_{=\pi \ln 2}+  \underbrace{\int_{0}^{\infty} \frac{\ln \left(x^{4}-x^{2}+1\right)}{1+x^{2}} d x
}_{K}  K J(a)=\int_{0}^{\infty} \frac{\ln \left(1+2 x \sin a+x^{2}\right)}{1+x^{2}} d x =\pi\ln \left|2 \cos \frac{a}{2}\right|+|a| \ln \left|\tan \frac{a}{2}\right|-2 \operatorname{sgn} (a) \int_{0}^{\frac{|a|}{2}} \ln (\tan x) d x 
\begin{aligned}
K &=\int_{0}^{\infty} \frac{\ln \left(x^{4}-x^{2}+1\right)}{1+x^{2}} d x \\
&=\int_{0}^{\infty} \frac{\ln \left(x^{2}+\sqrt{3} x+1\right)}{1+x^{2}} d x+\int_{0}^{\infty} \frac{\ln \left(x^{2}-\sqrt{3} x+1 \right) }{1+x^{2}} dx\\
&=J\left(\frac{\pi}{3}\right)+J\left(-\frac{\pi}{3}\right) \\
&=2 \pi \ln \left(2 \cos \frac{\pi}{6}\right) \\
&=\pi \ln 3
\end{aligned}
 
\boxed{ \int_{0}^{\infty} \frac{\ln \left(1+x^{6}\right)}{1+x^{2}} d x=\pi \ln 2+\pi \ln 3=\pi \ln 6 }
 
\boxed{\int_{0}^{\infty} \frac{\ln \left(x^{4}+b x^{2}+1\right)}{1+x^{2}} d x = 2 \pi \ln \left[2 \cos \left(\frac{1}{4} \cos ^{-1}\left(\frac{b}{2}\right)\right)\right]}
 
\begin{aligned}
\int_{0}^{\infty} \frac{\ln \left(x^{8}+1\right)}{1+x^{2}}=& \int_{0}^{\infty} \frac{\ln \left(x^{4}+\sqrt{2} x+1\right)}{1+x^{2}} d x +\int_{0}^{\infty} \frac{\ln \left(x^{4}-\sqrt{2} x+1\right)}{1+x^{2}} d x \\
=& 2 \pi \ln \left[2 \cos \frac{1}{4} \cos ^{-1}\left(\frac{\sqrt{2}}{2}\right)\right] +2 \pi \ln \left[2 \cos \frac{1}{4} \cos ^{-1}\left(-\frac{\sqrt{2}}{2}\right)\right] \\
=& 2 \pi \ln \left(2 \cos \frac{\pi}{16}\right)+2 \pi \ln \left(2 \cos \frac{3 \pi}{16}\right)\\
=& 2 \pi \ln \left(2^2 \cos \frac{\pi}{16} \cos \frac{3 \pi}{16}\right)\\=& 2 \pi \ln (\sqrt{2}+\sqrt{2+\sqrt{2}})
\end{aligned}
 I(5) n=7 n\geq 9.","['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'trigonometric-integrals']"
90,"Conjecture $\int_0^1\frac{\ln\left(\ln^2x+\arccos^2x\right)}{\sqrt{1-x^2}}dx\stackrel?=\pi\,\ln\ln2$",Conjecture,"\int_0^1\frac{\ln\left(\ln^2x+\arccos^2x\right)}{\sqrt{1-x^2}}dx\stackrel?=\pi\,\ln\ln2","$$\int_0^1\frac{\ln\left(\ln^2x+\arccos^2x\right)}{\sqrt{1-x^2}}dx\stackrel?=\pi\,\ln\ln2$$ Is it possible to prove this?","$$\int_0^1\frac{\ln\left(\ln^2x+\arccos^2x\right)}{\sqrt{1-x^2}}dx\stackrel?=\pi\,\ln\ln2$$ Is it possible to prove this?",,"['calculus', 'integration', 'logarithms', 'closed-form', 'conjectures']"
91,Integration and area - why is integrating over a single point zero?,Integration and area - why is integrating over a single point zero?,,"This is a naive question, but I'm only starting to learn calculus so please cut me some slack. So we all know the integral from $a$ to $b$ of a function over an interval measures the area under the curve $(x, f(x))$ from $a, b$. For any point $c$ in this interval $$\int_c^c f(x)dx = 0$$ So, $$\int_a^b f(x)dx = \sum_{c \in [a, b]} \int_c^cf(x)dx = 0$$ But obviously this isn't true.  So it cannot be the case that $\int_c^c f(x)dx = 0$.  What is wrong with my reasoning?","This is a naive question, but I'm only starting to learn calculus so please cut me some slack. So we all know the integral from $a$ to $b$ of a function over an interval measures the area under the curve $(x, f(x))$ from $a, b$. For any point $c$ in this interval $$\int_c^c f(x)dx = 0$$ So, $$\int_a^b f(x)dx = \sum_{c \in [a, b]} \int_c^cf(x)dx = 0$$ But obviously this isn't true.  So it cannot be the case that $\int_c^c f(x)dx = 0$.  What is wrong with my reasoning?",,['calculus']
92,True or False?: There are infinitely many continuous functions $f$ for which $\int_0^1f(x)(1-f(x))dx=\frac{1}{4}$,True or False?: There are infinitely many continuous functions  for which,f \int_0^1f(x)(1-f(x))dx=\frac{1}{4},"I was going through CMI 2019 paper; I stumbled upon the statement: For $f:R\rightarrow R$ , there are infinitely many continuous functions $f$ for which $\int_0^1f(x)(1-f(x))dx=\frac{1}{4}$ . My approach is, we can write $f(x)(1-f(x))=\frac{1}{4}-(f(x)-\frac{1}{2})^2$ . Now, we can write $\int_0^1f(x)(1-f(x))dx=\frac{1}{4}-\int_0^1(f(x)-\frac{1}{2})^2dx$ $\Rightarrow \int_0^1(f(x)-\frac{1}{2})^2dx=0 \Rightarrow f(x)=\frac{1}{2}$ . So, there must be only one function satisfying the condition. However, the official answer says the statement is true. Am I missing something?","I was going through CMI 2019 paper; I stumbled upon the statement: For , there are infinitely many continuous functions for which . My approach is, we can write . Now, we can write . So, there must be only one function satisfying the condition. However, the official answer says the statement is true. Am I missing something?",f:R\rightarrow R f \int_0^1f(x)(1-f(x))dx=\frac{1}{4} f(x)(1-f(x))=\frac{1}{4}-(f(x)-\frac{1}{2})^2 \int_0^1f(x)(1-f(x))dx=\frac{1}{4}-\int_0^1(f(x)-\frac{1}{2})^2dx \Rightarrow \int_0^1(f(x)-\frac{1}{2})^2dx=0 \Rightarrow f(x)=\frac{1}{2},"['calculus', 'integration']"
93,Is the proof of $\lim_{\theta\to 0} \frac{\sin \theta}{\theta}=1$ in some high school textbooks circular?,Is the proof of  in some high school textbooks circular?,\lim_{\theta\to 0} \frac{\sin \theta}{\theta}=1,"I was taught the following proof in high school. By constructing triangles with $0<\theta<\pi/2$ and a circle with radius $r$ and by comparing the areas, we have $$\frac{1}{2}r^2\sin\theta\cos\theta \le \frac{1}{2}r^2\theta\le\frac{1}{2}r^2\tan\theta$$ Hence $$\cos\theta\le\frac{\theta}{\sin\theta}\le\frac{1}{\cos\theta}$$ Then by squeeze theorem, we have the result. My question is, the middle term in the above inequality comes from the fact that the area of the circle is $\pi r^2$, which in my textbooks, is later proved by integration. But the integration requires results in calculus which comes from the fact that $$\lim_{\theta\to 0}\frac{\sin\theta}{\theta}=1$$","I was taught the following proof in high school. By constructing triangles with $0<\theta<\pi/2$ and a circle with radius $r$ and by comparing the areas, we have $$\frac{1}{2}r^2\sin\theta\cos\theta \le \frac{1}{2}r^2\theta\le\frac{1}{2}r^2\tan\theta$$ Hence $$\cos\theta\le\frac{\theta}{\sin\theta}\le\frac{1}{\cos\theta}$$ Then by squeeze theorem, we have the result. My question is, the middle term in the above inequality comes from the fact that the area of the circle is $\pi r^2$, which in my textbooks, is later proved by integration. But the integration requires results in calculus which comes from the fact that $$\lim_{\theta\to 0}\frac{\sin\theta}{\theta}=1$$",,['calculus']
94,Sigmoid function with fixed bounds and variable steepness [partially solved],Sigmoid function with fixed bounds and variable steepness [partially solved],,"(see edits below with attempts made in the meanwhile after posting the question) Problem I need to modify a sigmoid function for an AI application, but cannot figure out the correct math. Given a variable $x \in [0,1]$ , a function $f(x)$ should satisfy the following requirements (pardon the math-noobiness of my expression): a) the values of $f(x)$ should be costrained to $[0,1]$ b) when $x=0$ then $f(x)=0$ , and when $x=1$ then $f(x)=1$ c) $f(x)$ should follow a sigmoid or ""S-curve"" shape within these bounds, with some variable changing the ""steepness"" of the curve. I used a different function earlier, corresponding to (0), illustrated below on the left: (0) $f(x) = x^{(z+0.5)^{-b}}$ , where $b=2$ with $z \in [0,1]$ controlling the curve What is a function that would satisfy these requirements, i.e. do the same thing as equation (0) but with an S-curve $?_{(I\hspace{1mm} hope\hspace{1mm} this\hspace{1mm} makes\hspace{1mm} at\hspace{1mm} least\hspace{1mm} some \hspace{1mm}mathematical\hspace{1mm} sense...)}$ Attempt 1 I tried to accomplish something similar with a logistic function (by varying the $x_0$ value; cf. equation (1) and the right side plot above) (1) $f(x) = \dfrac{1}{1 + e^{-b(x-(1-x_0))}}$ , where $b=10$ , $x_0 \in [0,1]$ ...so that $x_0 = 0.5$ yields some central or average curve (like the linear growth line on the leftmost plot), and values around it rise or lower the steepness. Shortcoming: the ""ends"" of the curve where $x=\{0,1\}$ won't reach the required values of 0 and 1 respectively. I don't want to force it arbitrarily with an if-else , it should come naturally from the properties of an equation (and as such form nice curves). Attempt 2 This sort of does the trick, now the ends smootly reach 0 and 1 for all values of $x_0$ : (2) $f(x) = \Bigg(\bigg( \dfrac{1}{1 + e^{-b(x-(1-x_0))}}\bigg)x\Bigg)^{1-x} $ Only problem, the effect is not ""symmetrical"", when comparing high and low values. Observe the values for $f(x)$ with $x_0 = [0,1]$ ; $b=10$ (left side plot below). The curve steepness varies more among lower $x_0$ values (yellow,red) than amoing higher values (pink); also, changing $x_0$ also has noticably more effect in lower values of $x$ than its higher values. Attempt 3 Ok maybe if-elsing the hell out of those extreme values is not such a bad idea. (3) $f(x) = \Bigg(\bigg( \dfrac{1}{1 + e^{-b(x-(1-x_0))}}\bigg)g(x)\Bigg)^{1-h(x)} $ where $g(x) = \left\{\begin{array}{ll}1 & x>0\\0 & otherwise\end{array}\right.$ and $h(x) = \left\{\begin{array}{ll}1 & x==0\\0 & otherwise\end{array}\right.$ The right side plot above illustrates the result: the ends are still nicely 0 and 1, and now the curves above and below $x_0=0.5$ are symmetrical, but there are noticable ""jumps"" on $x=0.1$ and $x=0.9$ if $x_0$ is in its either extremes. Still not good. So far all my attempts are all so-so, each lacking in some respect. A better solution would thus still be very welcome.","(see edits below with attempts made in the meanwhile after posting the question) Problem I need to modify a sigmoid function for an AI application, but cannot figure out the correct math. Given a variable , a function should satisfy the following requirements (pardon the math-noobiness of my expression): a) the values of should be costrained to b) when then , and when then c) should follow a sigmoid or ""S-curve"" shape within these bounds, with some variable changing the ""steepness"" of the curve. I used a different function earlier, corresponding to (0), illustrated below on the left: (0) , where with controlling the curve What is a function that would satisfy these requirements, i.e. do the same thing as equation (0) but with an S-curve Attempt 1 I tried to accomplish something similar with a logistic function (by varying the value; cf. equation (1) and the right side plot above) (1) , where , ...so that yields some central or average curve (like the linear growth line on the leftmost plot), and values around it rise or lower the steepness. Shortcoming: the ""ends"" of the curve where won't reach the required values of 0 and 1 respectively. I don't want to force it arbitrarily with an if-else , it should come naturally from the properties of an equation (and as such form nice curves). Attempt 2 This sort of does the trick, now the ends smootly reach 0 and 1 for all values of : (2) Only problem, the effect is not ""symmetrical"", when comparing high and low values. Observe the values for with ; (left side plot below). The curve steepness varies more among lower values (yellow,red) than amoing higher values (pink); also, changing also has noticably more effect in lower values of than its higher values. Attempt 3 Ok maybe if-elsing the hell out of those extreme values is not such a bad idea. (3) where and The right side plot above illustrates the result: the ends are still nicely 0 and 1, and now the curves above and below are symmetrical, but there are noticable ""jumps"" on and if is in its either extremes. Still not good. So far all my attempts are all so-so, each lacking in some respect. A better solution would thus still be very welcome.","x \in [0,1] f(x) f(x) [0,1] x=0 f(x)=0 x=1 f(x)=1 f(x) f(x) = x^{(z+0.5)^{-b}} b=2 z \in [0,1] ?_{(I\hspace{1mm} hope\hspace{1mm} this\hspace{1mm} makes\hspace{1mm} at\hspace{1mm} least\hspace{1mm} some \hspace{1mm}mathematical\hspace{1mm} sense...)} x_0 f(x) = \dfrac{1}{1 + e^{-b(x-(1-x_0))}} b=10 x_0 \in [0,1] x_0 = 0.5 x=\{0,1\} x_0 f(x) = \Bigg(\bigg( \dfrac{1}{1 + e^{-b(x-(1-x_0))}}\bigg)x\Bigg)^{1-x}  f(x) x_0 = [0,1] b=10 x_0 x_0 x f(x) = \Bigg(\bigg( \dfrac{1}{1 + e^{-b(x-(1-x_0))}}\bigg)g(x)\Bigg)^{1-h(x)}  g(x) = \left\{\begin{array}{ll}1 & x>0\\0 & otherwise\end{array}\right. h(x) = \left\{\begin{array}{ll}1 & x==0\\0 & otherwise\end{array}\right. x_0=0.5 x=0.1 x=0.9 x_0","['calculus', 'functions', 'curves']"
95,How to prove $\int_{0}^{-1} \frac{\operatorname{Li}_2(x)}{(1-x)^2} dx=\frac{\pi^2}{24}-\frac{\ln^2(2)}{2} $,How to prove,\int_{0}^{-1} \frac{\operatorname{Li}_2(x)}{(1-x)^2} dx=\frac{\pi^2}{24}-\frac{\ln^2(2)}{2} ,"$\def\Li{\operatorname{Li}}$ I wonder how to prove: $$ \int_{0}^{-1} \frac{\Li_2(x)}{(1-x)^2} dx=\frac{\pi^2}{24}-\frac{\ln^2(2)}{2} $$ I'm not used to polylogarithm, so I don't know how to tackle it. So any help is highly appreciated.","$\def\Li{\operatorname{Li}}$ I wonder how to prove: $$ \int_{0}^{-1} \frac{\Li_2(x)}{(1-x)^2} dx=\frac{\pi^2}{24}-\frac{\ln^2(2)}{2} $$ I'm not used to polylogarithm, so I don't know how to tackle it. So any help is highly appreciated.",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'polylogarithm']"
96,$\int_0^{2\pi}e^{\cos x}\cos(\sin x)dx$ [duplicate],[duplicate],\int_0^{2\pi}e^{\cos x}\cos(\sin x)dx,This question already has answers here : integrate $\int_0^{2\pi} e^{\cos \theta} \cos( \sin \theta) d\theta$ [closed] (4 answers) Closed 9 years ago . $$\int_0^{2\pi}e^{\cos x}\cos(\sin x)dx$$ I tried Integration by parts but failed. Wolfram alpha gives answer in decimal points which are same as of $2\pi$. Any hints or suggestions will be helpful.,This question already has answers here : integrate $\int_0^{2\pi} e^{\cos \theta} \cos( \sin \theta) d\theta$ [closed] (4 answers) Closed 9 years ago . $$\int_0^{2\pi}e^{\cos x}\cos(\sin x)dx$$ I tried Integration by parts but failed. Wolfram alpha gives answer in decimal points which are same as of $2\pi$. Any hints or suggestions will be helpful.,,"['calculus', 'integration', 'definite-integrals']"
97,Evaluate $\int \frac{\sec^{2}{x}}{(\sec{x} + \tan{x})^{5/2}} \ \mathrm dx$,Evaluate,\int \frac{\sec^{2}{x}}{(\sec{x} + \tan{x})^{5/2}} \ \mathrm dx,I am unable to solve the following integral: $$\int \frac{\sec^{2}{x}}{(\sec{x} + \tan{x})^{5/2}} \ \mathrm dx.$$ Tried putting $t=\tan{x}$ so that numerator has $\sec^{2}{x}$ but that doesn't help.,I am unable to solve the following integral: $$\int \frac{\sec^{2}{x}}{(\sec{x} + \tan{x})^{5/2}} \ \mathrm dx.$$ Tried putting $t=\tan{x}$ so that numerator has $\sec^{2}{x}$ but that doesn't help.,,"['calculus', 'integration', 'indefinite-integrals']"
98,Aunt and Uncle's fuel oil tank dip stick problem,Aunt and Uncle's fuel oil tank dip stick problem,,"This problem first came to me in high school, and a couple times since, and I even assigned it for extra credit in one of my calculus classes after I became a teacher.  So I know the solution.  What I am looking for is other WAYS to obtain the solution.  I've been told there exists a solution using only arithmetic, but have never figured it out.  Other solutions using ordinary calculus, trigonometry, algebra of conic sections, and so on are also possible. The problem is usually stated in the form of a letter from an Aunt and Uncle: Dear niece/nephew, How are things   going for you and your folks?  We hear   you are doing quite well it school.    Keep it up!  Given this success, we   were hoping you could help us figure   out a little dilemma.  As you know,   our home is heated by fuel oil, and we   have a big tank buried in the side   yard.  The tank is a cylinder, 20 feet   long and 10 feet in diameter, lying on   its side five feet deep, with a narrow   tube coming to a fill cap at ground   level.  Your uncle has a 15 foot   length of old pipe that we'd like to   utilize as a dip stick in order to   know when we are getting close to   needing a fill-up.  We know that 0   feet is empty, 5 feet is half full,   and 10 feet is completely full.    Trouble is, we don't know how to mark   any other points. We are pretty sure   they will not be uniformly spaced.    What we really want is to know, within   the nearest 0.01 foot, where to mark   the dip stick for every multiple of   10% from 0% to 100%.  Can you figure   this out for us?  Of course, we will   want to see details of your solution   and check it ourselves, and it would   especially help if you could draw us a   scale model of the dip stick. Love,   Auntie Flo and Uncle Jim That last sentence shows the teacher influence on the problem. So, my challenge to this community is not to find any old solution, but to find the solution at the lowest possible grade level, so to speak. Thanks. UPDATE:  To those who are focusing in on the .01 feet accuracy, I apologize.  The intent was merely to state, it is acceptable to estimate.  If the exact answer is sqrt(2)*pi/2 or some other silly thing, go ahead and just write 2.22 feet, for example.","This problem first came to me in high school, and a couple times since, and I even assigned it for extra credit in one of my calculus classes after I became a teacher.  So I know the solution.  What I am looking for is other WAYS to obtain the solution.  I've been told there exists a solution using only arithmetic, but have never figured it out.  Other solutions using ordinary calculus, trigonometry, algebra of conic sections, and so on are also possible. The problem is usually stated in the form of a letter from an Aunt and Uncle: Dear niece/nephew, How are things   going for you and your folks?  We hear   you are doing quite well it school.    Keep it up!  Given this success, we   were hoping you could help us figure   out a little dilemma.  As you know,   our home is heated by fuel oil, and we   have a big tank buried in the side   yard.  The tank is a cylinder, 20 feet   long and 10 feet in diameter, lying on   its side five feet deep, with a narrow   tube coming to a fill cap at ground   level.  Your uncle has a 15 foot   length of old pipe that we'd like to   utilize as a dip stick in order to   know when we are getting close to   needing a fill-up.  We know that 0   feet is empty, 5 feet is half full,   and 10 feet is completely full.    Trouble is, we don't know how to mark   any other points. We are pretty sure   they will not be uniformly spaced.    What we really want is to know, within   the nearest 0.01 foot, where to mark   the dip stick for every multiple of   10% from 0% to 100%.  Can you figure   this out for us?  Of course, we will   want to see details of your solution   and check it ourselves, and it would   especially help if you could draw us a   scale model of the dip stick. Love,   Auntie Flo and Uncle Jim That last sentence shows the teacher influence on the problem. So, my challenge to this community is not to find any old solution, but to find the solution at the lowest possible grade level, so to speak. Thanks. UPDATE:  To those who are focusing in on the .01 feet accuracy, I apologize.  The intent was merely to state, it is acceptable to estimate.  If the exact answer is sqrt(2)*pi/2 or some other silly thing, go ahead and just write 2.22 feet, for example.",,"['calculus', 'trigonometry', 'arithmetic', 'conic-sections']"
99,"Evaluating $\int_{0}^{\infty}{\sin(x)\sin(2x)\sin(3x)\ldots \sin(nx)\sin(n^{2}x) \over x^{n + 1}}\,dx $",Evaluating,"\int_{0}^{\infty}{\sin(x)\sin(2x)\sin(3x)\ldots \sin(nx)\sin(n^{2}x) \over x^{n + 1}}\,dx ","How can we calculate $$ \int_{0}^{\infty}{\sin\left(x\right)\sin\left(2x\right)\sin\left(3x\right)\ldots \sin\left(nx\right)\sin\left(n^{2}x\right) \over x^{n + 1}}\,\mathrm{d}x ? $$ I believe that we can use the Dirichlet integral $$ \int_{0}^{\infty}{\sin\left(x\right) \over x}\,\mathrm{d}x = {\pi \over 2} $$ But how do we split the integrand?","How can we calculate $$ \int_{0}^{\infty}{\sin\left(x\right)\sin\left(2x\right)\sin\left(3x\right)\ldots \sin\left(nx\right)\sin\left(n^{2}x\right) \over x^{n + 1}}\,\mathrm{d}x ? $$ I believe that we can use the Dirichlet integral $$ \int_{0}^{\infty}{\sin\left(x\right) \over x}\,\mathrm{d}x = {\pi \over 2} $$ But how do we split the integrand?",,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'improper-integrals']"
