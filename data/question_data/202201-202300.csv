,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Volume preserving mean curvature flow preserving uniformly convex,Volume preserving mean curvature flow preserving uniformly convex,,"Let $(M_t,g_t)$ be a Riemannian manifold evolve by volume preserving mean curvature flow. So , for second fundamental form, we have  $$ \partial_t h_{ij}=\Delta h_{ij}-2H h_{im}h^m_j+hh_{im}h^m_j + |A|^2 h_{ij} $$ $H=g^{ij}h_{ij}$ is mean curvature, $|A|^2=g^{ij}g^{kl}h_{ik}h_{jl}$ is inner product of second fundamental form. If the initial manifold is uniformly convex : the eigenvalues of its second fundamental form are strictly positive everywhere. Then, how to show $M_t$ still be uniformly convex for all $t\ge 0$ where the solution exists ?","Let $(M_t,g_t)$ be a Riemannian manifold evolve by volume preserving mean curvature flow. So , for second fundamental form, we have  $$ \partial_t h_{ij}=\Delta h_{ij}-2H h_{im}h^m_j+hh_{im}h^m_j + |A|^2 h_{ij} $$ $H=g^{ij}h_{ij}$ is mean curvature, $|A|^2=g^{ij}g^{kl}h_{ik}h_{jl}$ is inner product of second fundamental form. If the initial manifold is uniformly convex : the eigenvalues of its second fundamental form are strictly positive everywhere. Then, how to show $M_t$ still be uniformly convex for all $t\ge 0$ where the solution exists ?",,"['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'mean-curvature-flows']"
1,Cartan's proof of the determination of the metric by means of curvature,Cartan's proof of the determination of the metric by means of curvature,,"This is our setup: Let $(M,g)$ and $(\tilde{M},\tilde{g})$ be $n$-dimensional Riemannian manifolds. Pick two points $p\in M$ and $\tilde{p}\in\tilde{M}$, fix some linear isometry $$i:\mathrm{T}_p M\to\mathrm{T}_\tilde{p}\tilde{M},$$   let $V\subseteq M$ be a normal neighborhood of $p$ such that $\exp_\tilde{p}$ is defined on $i\circ\exp_p^{-1}(V)$, and define $$f:V\to\tilde{M},\ \ \ \ q\mapsto\exp_\tilde{p}\circ i\circ\exp_p^{-1}(q).$$ For all $q\in V$, there exists a unique normalized geodesic $\gamma:[0,t]\to M$ in $V$, with $\gamma(0)=p$ and $\gamma(t) = q$. Denote by $P_t$ the parallel transport along $\gamma$ from $\gamma(0)$ to $\gamma(t)$. Define $$\phi_t:\mathrm{T}_q M\to\mathrm{T}_{f(q)}\tilde{M},\ \ \ \ v\mapsto \tilde{P_t}\circ i\circ P_t^{-1}(v)$$ where $\tilde{P_t}$ is the parallel transport along the normalize geodesic $\tilde{\gamma}:[0,t]\to\tilde{M}$ given by $\tilde{\gamma}(0)=\tilde{p}$, $\tilde{\gamma}\,'(0)=i(\gamma'(0))$. Now, suppose we are given a Jacobi field $J$ on $\gamma$ such that $J(0)=0$, and assume (the conditions of the theorem in fact give us this) that $\tilde{J} = \phi_t\circ J$ is a Jacobi field along $\tilde{\gamma} = f\circ\gamma$. Now, in the proof of this theorem (which is found in Do Carmo ), we are told that $\tilde{J}\,'(0) = i(J'(0))$. But why is this so? It seems a bit bizarre for me to even see a derivative inside of another function – the opposite of what happens in the usual chain rule.","This is our setup: Let $(M,g)$ and $(\tilde{M},\tilde{g})$ be $n$-dimensional Riemannian manifolds. Pick two points $p\in M$ and $\tilde{p}\in\tilde{M}$, fix some linear isometry $$i:\mathrm{T}_p M\to\mathrm{T}_\tilde{p}\tilde{M},$$   let $V\subseteq M$ be a normal neighborhood of $p$ such that $\exp_\tilde{p}$ is defined on $i\circ\exp_p^{-1}(V)$, and define $$f:V\to\tilde{M},\ \ \ \ q\mapsto\exp_\tilde{p}\circ i\circ\exp_p^{-1}(q).$$ For all $q\in V$, there exists a unique normalized geodesic $\gamma:[0,t]\to M$ in $V$, with $\gamma(0)=p$ and $\gamma(t) = q$. Denote by $P_t$ the parallel transport along $\gamma$ from $\gamma(0)$ to $\gamma(t)$. Define $$\phi_t:\mathrm{T}_q M\to\mathrm{T}_{f(q)}\tilde{M},\ \ \ \ v\mapsto \tilde{P_t}\circ i\circ P_t^{-1}(v)$$ where $\tilde{P_t}$ is the parallel transport along the normalize geodesic $\tilde{\gamma}:[0,t]\to\tilde{M}$ given by $\tilde{\gamma}(0)=\tilde{p}$, $\tilde{\gamma}\,'(0)=i(\gamma'(0))$. Now, suppose we are given a Jacobi field $J$ on $\gamma$ such that $J(0)=0$, and assume (the conditions of the theorem in fact give us this) that $\tilde{J} = \phi_t\circ J$ is a Jacobi field along $\tilde{\gamma} = f\circ\gamma$. Now, in the proof of this theorem (which is found in Do Carmo ), we are told that $\tilde{J}\,'(0) = i(J'(0))$. But why is this so? It seems a bit bizarre for me to even see a derivative inside of another function – the opposite of what happens in the usual chain rule.",,"['differential-geometry', 'riemannian-geometry', 'curvature']"
2,Pre-image of submanifold under submersion,Pre-image of submanifold under submersion,,"Let $F:M\to N$ be a submersion. I want to show that for any submanifold $S\subset N$, $F^{-1}(S)$ is a submanifold of $M$. We have not yet covered transversality theorems. However, we have regular value theorem that states the preimage of regular value under submersion is a submanifold. Can we somehow use regular value theorem to prove this? Any hints would be appreciated! Thanks.","Let $F:M\to N$ be a submersion. I want to show that for any submanifold $S\subset N$, $F^{-1}(S)$ is a submanifold of $M$. We have not yet covered transversality theorems. However, we have regular value theorem that states the preimage of regular value under submersion is a submanifold. Can we somehow use regular value theorem to prove this? Any hints would be appreciated! Thanks.",,['differential-geometry']
3,N-dimensional generalization of vector curl from elements of Jacobian,N-dimensional generalization of vector curl from elements of Jacobian,,"I want to determine whether a certain n-dimensional, simply-connected vector field is conservative. I can very easily calculate its Jacobian in numerical form. In 3 dimensions, the problem is easy: the Jacobian is a 3x3 matrix, and the curl can be obtained from its elements: [jacobian[2,1] - jacobian[1,2],  jacobian[0,2] - jacobian[2,0],  jacobian[1,0] - jacobian[0,1]] A curl of zero would mean that the vector field is conservative. But what if my Jacobian has 100 elements? The curl is only defined for 3 dimensions, but is there a formula for some high-dimensional generalization?","I want to determine whether a certain n-dimensional, simply-connected vector field is conservative. I can very easily calculate its Jacobian in numerical form. In 3 dimensions, the problem is easy: the Jacobian is a 3x3 matrix, and the curl can be obtained from its elements: [jacobian[2,1] - jacobian[1,2],  jacobian[0,2] - jacobian[2,0],  jacobian[1,0] - jacobian[0,1]] A curl of zero would mean that the vector field is conservative. But what if my Jacobian has 100 elements? The curl is only defined for 3 dimensions, but is there a formula for some high-dimensional generalization?",,"['differential-geometry', 'multilinear-algebra']"
4,Algebraic characterization of the exterior covariant derivative,Algebraic characterization of the exterior covariant derivative,,"The de Rham complex on a smooth manifold $M$ is a complex of sheaves of $\mathbb{R}$-modules, which I will denote by $$\Omega^\bullet \xrightarrow{d} \Omega^{\bullet+1}.$$ A connection (not assumed to be flat!) on a vector bundle $E \to M$ with sheaf of sections $\mathcal{E}$ can be given by a covariant derivative, which is an $\mathbb{R}$-linear sheaf homomorphism: $$\mathcal{E} \xrightarrow{\nabla} \mathcal{E} \otimes_{\mathcal{C}^\infty} \Omega^1 .$$ Is there an algebraic (in terms of category theory, sheaves and/or homological algebra) way to characterize the construction of the exterior covariant derivative  $$\mathcal{E} \otimes_{\mathcal{C}^\infty} \Omega^\bullet \xrightarrow{d^\nabla} \mathcal{E} \otimes_{\mathcal{C}^\infty}\Omega^{\bullet+1}$$ from this data? Naively, we might just stick stick zero sheaves on either side of the covariant derivative to get a complex, and then tensor with the de Rham complex (over the constant sheaf $\mathbb{R}$). But this is obviously wrong because we get a complex, and the connection is not assumed to be flat. Even in the flat case it is easy to see by looking at the individual sheaves that this approach gives the wrong complex.","The de Rham complex on a smooth manifold $M$ is a complex of sheaves of $\mathbb{R}$-modules, which I will denote by $$\Omega^\bullet \xrightarrow{d} \Omega^{\bullet+1}.$$ A connection (not assumed to be flat!) on a vector bundle $E \to M$ with sheaf of sections $\mathcal{E}$ can be given by a covariant derivative, which is an $\mathbb{R}$-linear sheaf homomorphism: $$\mathcal{E} \xrightarrow{\nabla} \mathcal{E} \otimes_{\mathcal{C}^\infty} \Omega^1 .$$ Is there an algebraic (in terms of category theory, sheaves and/or homological algebra) way to characterize the construction of the exterior covariant derivative  $$\mathcal{E} \otimes_{\mathcal{C}^\infty} \Omega^\bullet \xrightarrow{d^\nabla} \mathcal{E} \otimes_{\mathcal{C}^\infty}\Omega^{\bullet+1}$$ from this data? Naively, we might just stick stick zero sheaves on either side of the covariant derivative to get a complex, and then tensor with the de Rham complex (over the constant sheaf $\mathbb{R}$). But this is obviously wrong because we get a complex, and the connection is not assumed to be flat. Even in the flat case it is easy to see by looking at the individual sheaves that this approach gives the wrong complex.",,"['differential-geometry', 'homological-algebra', 'differential-forms', 'sheaf-theory', 'graded-rings']"
5,Subset of symmetric matrices is submanifold,Subset of symmetric matrices is submanifold,,"Let $Sym(3)\cong\mathbb{R}$ denote the set of real symmetric $3\times 3$-matrices. Let $$M:=\{ P\in Sym(3)|\ P^2=P,\ \operatorname{tr}{P}=1 \}.$$ I asked to show that $M$ is a submanifold diffeomorphic to the projective space $\mathbb{R}P^2$. My effort: I'm familiar with two types of definition for a submanifold: Definition of an immersed manifold and A subset $N$ of a manifold $M$ is called a submanifold if for all $p\in N$ there exists a chart $(U,\phi)$ of $M$ with $p\in U$ such that $\phi(N\cap U)=(\mathbb{R}\times 0)\cap \phi(U)$. I want to use the second one. We can choose a global chart given by $(Sym(3),\phi)$, where $$\phi:\begin{pmatrix}a&d&f\\d&b&e\\f&e&c\end{pmatrix}\mapsto(a,b,c,d,e,f).$$ In this case we have: $\phi(Sym(3))=\mathbb{R}^6$ and $N\cap Sym(3)=N$. This idea ends in analyzing the conditions $\operatorname{tr}P=1$ and $P^2=P$. For example we can set $a=1-b-c$. Before I continue: Is there an easier way to solve the problem? Furthermore: I have no idea how to show that $M$ is diffeomorphic to $\mathbb{R}P^2$. Your help is greatly appreciated.","Let $Sym(3)\cong\mathbb{R}$ denote the set of real symmetric $3\times 3$-matrices. Let $$M:=\{ P\in Sym(3)|\ P^2=P,\ \operatorname{tr}{P}=1 \}.$$ I asked to show that $M$ is a submanifold diffeomorphic to the projective space $\mathbb{R}P^2$. My effort: I'm familiar with two types of definition for a submanifold: Definition of an immersed manifold and A subset $N$ of a manifold $M$ is called a submanifold if for all $p\in N$ there exists a chart $(U,\phi)$ of $M$ with $p\in U$ such that $\phi(N\cap U)=(\mathbb{R}\times 0)\cap \phi(U)$. I want to use the second one. We can choose a global chart given by $(Sym(3),\phi)$, where $$\phi:\begin{pmatrix}a&d&f\\d&b&e\\f&e&c\end{pmatrix}\mapsto(a,b,c,d,e,f).$$ In this case we have: $\phi(Sym(3))=\mathbb{R}^6$ and $N\cap Sym(3)=N$. This idea ends in analyzing the conditions $\operatorname{tr}P=1$ and $P^2=P$. For example we can set $a=1-b-c$. Before I continue: Is there an easier way to solve the problem? Furthermore: I have no idea how to show that $M$ is diffeomorphic to $\mathbb{R}P^2$. Your help is greatly appreciated.",,['differential-geometry']
6,Sections of line bundles over $\mathbb{C}P^n$,Sections of line bundles over,\mathbb{C}P^n,"Let $M=\mathbb{CP}^n$ be our manifold, and $U_j$ be the standard coordinate charts, i.e. $$U_j=\{[z_0:z_1:\cdots:z_n] : z_j\neq 0\}$$  with coordinates $w^{(j)}_i=z_i/z_j$ for $i\neq j.$ Consider the section $s$ of $\mathcal{O}(1)$ which is $s=z_0$ in homogeneous coordinates. In local cordinates: over $U_1$ is equal to $w_1$. Now consider the section $s^*$ of $\mathcal{O}(2)$ which is $s=z_0z_1$ in homogeneous coordinates. In local cordinates: over $U_1$ is equal to $w_1$. Is that correct? The two sections $s$ and $s^*$ are equal on $U_1$? Similarly, what is the local expression in $U_1$ for $t=z_0 z_1 z_2 \cdots z_n$ (as a section of $\mathcal{O}(n+1)$) ? I'm a bit confused. I would honestly appreciate any help.","Let $M=\mathbb{CP}^n$ be our manifold, and $U_j$ be the standard coordinate charts, i.e. $$U_j=\{[z_0:z_1:\cdots:z_n] : z_j\neq 0\}$$  with coordinates $w^{(j)}_i=z_i/z_j$ for $i\neq j.$ Consider the section $s$ of $\mathcal{O}(1)$ which is $s=z_0$ in homogeneous coordinates. In local cordinates: over $U_1$ is equal to $w_1$. Now consider the section $s^*$ of $\mathcal{O}(2)$ which is $s=z_0z_1$ in homogeneous coordinates. In local cordinates: over $U_1$ is equal to $w_1$. Is that correct? The two sections $s$ and $s^*$ are equal on $U_1$? Similarly, what is the local expression in $U_1$ for $t=z_0 z_1 z_2 \cdots z_n$ (as a section of $\mathcal{O}(n+1)$) ? I'm a bit confused. I would honestly appreciate any help.",,"['differential-geometry', 'complex-geometry', 'vector-bundles', 'kahler-manifolds']"
7,Calabi-Yau condition in darboux coordinates,Calabi-Yau condition in darboux coordinates,,"Definition: One definition of a Calabi-Yau manifold is that of a Kahler manifold $X$ of dimension $n$, with a non-vanishing holomorphic $(n,0)$-form $\Omega$ satisfying  $$ \omega^n/n! = (-1)^{n(n-1)/2}(i/2)^n \Omega \wedge \bar{\Omega}, $$ where $\omega$ is the symplectic form on $X$. For any symplectic form we can take Darboux coordinates $(x,y)=(x_1,\dots,x_n, y_1,\dots,y_n)$ such that  $$\omega = \sum_i dx_i \wedge dy_i.$$ (Note: In general these coordinates are not holomorphic, i.e. $z= x+iy$ are not complex coordinates.) Question: In these coordinates, does $\Omega$ look like $\Omega = dx_1 +idy_1 \wedge \dots \wedge dx_n +idy_n$? Thoughts : This seems like a lot to expect since the condition only requires the wedge product to be non-trivial as we are in the top degree and the coefficients can be adjusted. So I guess this must be a highly underdetermined equation. On the other hand, I don't see that it is has to be false. The Calab-Yau condition would definitely hold and it seems like it is true when $n=1$. In the $X=\mathbb C^n$ setting it is also true (however, in that case $(x,y)$ do induce complex coordinates). Another reason I'm thinking this might be true up to some function is that a Kahler manifold with SU$(n)$ holonomy admits such an $(n,0)$-form $\Omega$ and it is unique up to change of phase (see Lemma 4.4) . So maybe it is not as underdetermined as it looks?","Definition: One definition of a Calabi-Yau manifold is that of a Kahler manifold $X$ of dimension $n$, with a non-vanishing holomorphic $(n,0)$-form $\Omega$ satisfying  $$ \omega^n/n! = (-1)^{n(n-1)/2}(i/2)^n \Omega \wedge \bar{\Omega}, $$ where $\omega$ is the symplectic form on $X$. For any symplectic form we can take Darboux coordinates $(x,y)=(x_1,\dots,x_n, y_1,\dots,y_n)$ such that  $$\omega = \sum_i dx_i \wedge dy_i.$$ (Note: In general these coordinates are not holomorphic, i.e. $z= x+iy$ are not complex coordinates.) Question: In these coordinates, does $\Omega$ look like $\Omega = dx_1 +idy_1 \wedge \dots \wedge dx_n +idy_n$? Thoughts : This seems like a lot to expect since the condition only requires the wedge product to be non-trivial as we are in the top degree and the coefficients can be adjusted. So I guess this must be a highly underdetermined equation. On the other hand, I don't see that it is has to be false. The Calab-Yau condition would definitely hold and it seems like it is true when $n=1$. In the $X=\mathbb C^n$ setting it is also true (however, in that case $(x,y)$ do induce complex coordinates). Another reason I'm thinking this might be true up to some function is that a Kahler manifold with SU$(n)$ holonomy admits such an $(n,0)$-form $\Omega$ and it is unique up to change of phase (see Lemma 4.4) . So maybe it is not as underdetermined as it looks?",,"['differential-geometry', 'riemannian-geometry', 'complex-geometry', 'symplectic-geometry', 'kahler-manifolds']"
8,Product of immersions is immersion?,Product of immersions is immersion?,,"If $U\subseteq \mathbb{R}^n$ and $V\subseteq \mathbb{R}^m$, let's define immersions $f\colon U\longrightarrow \mathbb{R}^n$ and $g\colon V\longrightarrow \mathbb{R}^m$, if I define $$h\colon U\times V\longrightarrow \mathbb{R}^{m+n}$$ With $h((u,v))=(f(u),g(v))$, then it is an immersion too? Why?","If $U\subseteq \mathbb{R}^n$ and $V\subseteq \mathbb{R}^m$, let's define immersions $f\colon U\longrightarrow \mathbb{R}^n$ and $g\colon V\longrightarrow \mathbb{R}^m$, if I define $$h\colon U\times V\longrightarrow \mathbb{R}^{m+n}$$ With $h((u,v))=(f(u),g(v))$, then it is an immersion too? Why?",,['differential-geometry']
9,definition of gradient vector field.,definition of gradient vector field.,,"I don't understand the definition of gradient vector field. Let $M$ be a manifold, $f:M\rightarrow \mathbb{R}$ be a smooth function and $\varphi_1,\varphi_2:U\rightarrow \mathbb{R}^n$ be coordinate charts of $M$. It's my understanding that grad$f$ on $U$ is the tangent vector firld$:U\rightarrow TU$  $$p \mapsto \frac{\partial f_1}{\partial x^1_1}(\varphi_1(p))\frac{\partial}{\partial x^1_1}+\dots +\frac{\partial f_1}{\partial x^1_n}(\varphi_1(p))\frac{\partial}{\partial x^1_n}$$,  where $f_1=f\circ\varphi_1^{-1}:\varphi_1(U)\rightarrow \mathbb{R}$ and $(x^1_1,...,x^1_n)$ is the coordinate system of $\varphi_1(U)$. If this definition is correct and it doesn't depend on the choice of chart, it must coincide with  $$p \mapsto \frac{\partial f_2}{\partial x^2_1}(\varphi_2(p))\frac{\partial}{\partial x^2_1}+\dots +\frac{\partial f_2}{\partial x^2_n}(\varphi_2(p))\frac{\partial}{\partial x^2_n}$$,  where $f_2=f\circ\varphi_2^{-1}:\varphi_2(U)\rightarrow \mathbb{R}$ and $(x^2_1,...,x^2_n)$ is the coordinate system of $\varphi_2(U)$. However, these two coincides iff  $$ \begin{pmatrix} \frac{\partial f_2}{\partial x^2_1}(\varphi_2(p))\\ \dots\\ \frac{\partial f_2}{\partial x^2_n}(\varphi_2(p)) \end{pmatrix} =D(\varphi_2\circ \varphi_1^{-1}) \begin{pmatrix} \frac{\partial f_1}{\partial x^1_1}(\varphi_1(p))\\ \dots\\ \frac{\partial f_1}{\partial x^1_n}(\varphi_1(p)) \end{pmatrix}= D(\varphi_2\circ \varphi_1^{-1})(D(\varphi_2\circ \varphi_1^{-1}))^T\begin{pmatrix} \frac{\partial f_2}{\partial x^2_1}(\varphi_2(p))\\ \dots\\ \frac{\partial f_2}{\partial x^2_n}(\varphi_2(p)) \end{pmatrix} $$, where $D(\varphi_2\circ \varphi_1^{-1})$ is the Jacobian matrix, and this doesn't necessarily hold. Where is the misunderstanding?","I don't understand the definition of gradient vector field. Let $M$ be a manifold, $f:M\rightarrow \mathbb{R}$ be a smooth function and $\varphi_1,\varphi_2:U\rightarrow \mathbb{R}^n$ be coordinate charts of $M$. It's my understanding that grad$f$ on $U$ is the tangent vector firld$:U\rightarrow TU$  $$p \mapsto \frac{\partial f_1}{\partial x^1_1}(\varphi_1(p))\frac{\partial}{\partial x^1_1}+\dots +\frac{\partial f_1}{\partial x^1_n}(\varphi_1(p))\frac{\partial}{\partial x^1_n}$$,  where $f_1=f\circ\varphi_1^{-1}:\varphi_1(U)\rightarrow \mathbb{R}$ and $(x^1_1,...,x^1_n)$ is the coordinate system of $\varphi_1(U)$. If this definition is correct and it doesn't depend on the choice of chart, it must coincide with  $$p \mapsto \frac{\partial f_2}{\partial x^2_1}(\varphi_2(p))\frac{\partial}{\partial x^2_1}+\dots +\frac{\partial f_2}{\partial x^2_n}(\varphi_2(p))\frac{\partial}{\partial x^2_n}$$,  where $f_2=f\circ\varphi_2^{-1}:\varphi_2(U)\rightarrow \mathbb{R}$ and $(x^2_1,...,x^2_n)$ is the coordinate system of $\varphi_2(U)$. However, these two coincides iff  $$ \begin{pmatrix} \frac{\partial f_2}{\partial x^2_1}(\varphi_2(p))\\ \dots\\ \frac{\partial f_2}{\partial x^2_n}(\varphi_2(p)) \end{pmatrix} =D(\varphi_2\circ \varphi_1^{-1}) \begin{pmatrix} \frac{\partial f_1}{\partial x^1_1}(\varphi_1(p))\\ \dots\\ \frac{\partial f_1}{\partial x^1_n}(\varphi_1(p)) \end{pmatrix}= D(\varphi_2\circ \varphi_1^{-1})(D(\varphi_2\circ \varphi_1^{-1}))^T\begin{pmatrix} \frac{\partial f_2}{\partial x^2_1}(\varphi_2(p))\\ \dots\\ \frac{\partial f_2}{\partial x^2_n}(\varphi_2(p)) \end{pmatrix} $$, where $D(\varphi_2\circ \varphi_1^{-1})$ is the Jacobian matrix, and this doesn't necessarily hold. Where is the misunderstanding?",,['calculus']
10,"Given $f:M\to\mathbb{R}$ non singular, find a vector field $X$ with $X(f)\equiv 1$","Given  non singular, find a vector field  with",f:M\to\mathbb{R} X X(f)\equiv 1,"Let $M^m$ be a smooth manifold and $f:M\to\mathbb{R}$ a smooth, non singular function. Prove that there exists a vector field $X\in\frak{X}$$(M)$ such that $X(f)\equiv 1$. Take a chart $(U, \phi)$ at $p\in M$ with $U$ small enough so that we can assume, with no loss in generality, that $\frac{\partial f}{\partial \phi^{n}}\neq 0$ in $U$ (that's possible since $f$ is non singular). That way, take any $g_1, ...,g_{n-1}\in C^{\infty}(M)$ and define $$g_n:=\left(\frac{\partial f}{\partial \phi^{n}}\right)^{-1}\left(1-\sum_{i=1}^{n-1}g_i\frac{\partial f}{\partial \phi^{i}}\right)$$ which is obviously in $C^{\infty}(M)$. Now, defining $X_{U}:=\sum_{i=1}^n g_i\frac{\partial }{\partial \phi^{i}}$, we have a local smooth vector field with $X_U(f)\equiv 1$ in $U$. I've tried to use a partition of unity to define some $X:=\sum X_{U}$, but I could not guarantee that $X(f)\equiv 1$ and I don't know how to work this out. Any ideas?","Let $M^m$ be a smooth manifold and $f:M\to\mathbb{R}$ a smooth, non singular function. Prove that there exists a vector field $X\in\frak{X}$$(M)$ such that $X(f)\equiv 1$. Take a chart $(U, \phi)$ at $p\in M$ with $U$ small enough so that we can assume, with no loss in generality, that $\frac{\partial f}{\partial \phi^{n}}\neq 0$ in $U$ (that's possible since $f$ is non singular). That way, take any $g_1, ...,g_{n-1}\in C^{\infty}(M)$ and define $$g_n:=\left(\frac{\partial f}{\partial \phi^{n}}\right)^{-1}\left(1-\sum_{i=1}^{n-1}g_i\frac{\partial f}{\partial \phi^{i}}\right)$$ which is obviously in $C^{\infty}(M)$. Now, defining $X_{U}:=\sum_{i=1}^n g_i\frac{\partial }{\partial \phi^{i}}$, we have a local smooth vector field with $X_U(f)\equiv 1$ in $U$. I've tried to use a partition of unity to define some $X:=\sum X_{U}$, but I could not guarantee that $X(f)\equiv 1$ and I don't know how to work this out. Any ideas?",,"['differential-geometry', 'smooth-manifolds']"
11,Strange plus sign in the Lie derivative of a 1-form,Strange plus sign in the Lie derivative of a 1-form,,While the coordinate expression for the Lie derivative of a vector field $Y$ with respect to another vector field $X$ is given by $$ L_X Y = \sum_j \left\{X^j\left( \frac{\partial Y^i}{\partial x^j}\right)         -  Y^j \left(\frac{\partial X^i}{\partial x^j}\right)\right\} $$ there is a plus sign in the coordinate expression for the Lie derivative of a 1-form $\alpha$ with respect to $X$ $$ L_X \alpha = \sum_j \left\{X^j\left( \frac{\partial a^i}{\partial x^j}\right)         +  a^j \left(\frac{\partial X^i}{\partial x^j}\right)\right\}dx_i $$ The $a^i$ and $a^j$ are the coordinates of the 1-form. Where does this plus sign come from?,While the coordinate expression for the Lie derivative of a vector field $Y$ with respect to another vector field $X$ is given by $$ L_X Y = \sum_j \left\{X^j\left( \frac{\partial Y^i}{\partial x^j}\right)         -  Y^j \left(\frac{\partial X^i}{\partial x^j}\right)\right\} $$ there is a plus sign in the coordinate expression for the Lie derivative of a 1-form $\alpha$ with respect to $X$ $$ L_X \alpha = \sum_j \left\{X^j\left( \frac{\partial a^i}{\partial x^j}\right)         +  a^j \left(\frac{\partial X^i}{\partial x^j}\right)\right\}dx_i $$ The $a^i$ and $a^j$ are the coordinates of the 1-form. Where does this plus sign come from?,,"['differential-geometry', 'differential-forms', 'lie-derivative']"
12,Smooth domain and compact sets,Smooth domain and compact sets,,"suppose $M$ is a smooth manifold, $O\subset M$ is an open domain and $K\subset O$ is some compact set. I am wondering if there always exists an open domain $D$ in $M$ with smooth boundary and such that $K\subset D\subset O$? Unfortunately I do not know how to approach this problem. Does anyone have an idea? Best wishes","suppose $M$ is a smooth manifold, $O\subset M$ is an open domain and $K\subset O$ is some compact set. I am wondering if there always exists an open domain $D$ in $M$ with smooth boundary and such that $K\subset D\subset O$? Unfortunately I do not know how to approach this problem. Does anyone have an idea? Best wishes",,"['differential-geometry', 'riemannian-geometry']"
13,The smooth atlas of a manifold,The smooth atlas of a manifold,,"Suppose that $M$ is a smooth manifold with an atlas $A$, and $p$ is a point of $M$. pick a smooth chart $(U,\phi)$ such that $p \in U$, then a trick we often use is that we can always let $\phi(p) = 0$. The reason is that if $\phi(p) \neq 0$, we can simply compose it with a translation map. My question is, if we do compose it with a translation map, how am I able to guarantee that this composition is still in the original atlas $A$? If it is not in $A$, then how am I able to conclude that this change of charts will not have any impact on the structure of $M$?","Suppose that $M$ is a smooth manifold with an atlas $A$, and $p$ is a point of $M$. pick a smooth chart $(U,\phi)$ such that $p \in U$, then a trick we often use is that we can always let $\phi(p) = 0$. The reason is that if $\phi(p) \neq 0$, we can simply compose it with a translation map. My question is, if we do compose it with a translation map, how am I able to guarantee that this composition is still in the original atlas $A$? If it is not in $A$, then how am I able to conclude that this change of charts will not have any impact on the structure of $M$?",,"['differential-geometry', 'differential-topology', 'smooth-manifolds']"
14,Can bundles be trivial if the structure group is not?,Can bundles be trivial if the structure group is not?,,"I am confused about a basic concept and any help to clear up my misunderstanding is appreciated: In https://arxiv.org/abs/hep-th/0611201 , for example, it is stated that a fibre bundle is trivial if and only if all transition functions can be chosen to be identity maps. If this is not the case, the fibres are ‘twisted’  in a way that the bundle  cannot be simply described by a product manifold. This non-trivial aspect is encoded in a non-trivial structure group S of the bundle. As a first example often the struture group of the  Mobius strip versus a cylinder  is discussed. So far so good! My confusion arises when considering a principle bundle $ P= P(M,G) $ over some base manifold $M$ where the fibre $G$ is the structured group $S$ itself, e.g. $G \simeq S $. This is because I can choose $M \simeq \mathbb{R^4}$ which makes the fibre bundle trivial no matter how ""complicated"" one chooses $G$ (because  $\mathbb{R^4}$ can be contracted to a point). This seems like a contradiction to me. Furthermore image I start out with  $ P= P(M,G) $ and systematically ""test out"" different base manifolds $M$ while keeping $G$ fixed. Now as soon as the topology of $M$ changes ( say $M$ cannot be contracted to a point unlike before) one needs to expects the structure group of the bundle to change as well; but it was fixed to be $G$ in the first place? How can this be? One way out I see if one replaces $G \simeq S $ by $G \supseteq S$ requiring that the structured group only needs to be a subset of $G$. So in the trivial case from before $ P = P(\mathbb{R^4},G)$ the structured group would only pick out the trivial sub-group $S=\{e\}$ from G. However even in this case, in my second example of ""testing out"" different base-manifolds for a given $G$, which theorem guarantees me that one always stays within $G \supseteq S$ for an arbitrary choice of $M$? many thanks!","I am confused about a basic concept and any help to clear up my misunderstanding is appreciated: In https://arxiv.org/abs/hep-th/0611201 , for example, it is stated that a fibre bundle is trivial if and only if all transition functions can be chosen to be identity maps. If this is not the case, the fibres are ‘twisted’  in a way that the bundle  cannot be simply described by a product manifold. This non-trivial aspect is encoded in a non-trivial structure group S of the bundle. As a first example often the struture group of the  Mobius strip versus a cylinder  is discussed. So far so good! My confusion arises when considering a principle bundle $ P= P(M,G) $ over some base manifold $M$ where the fibre $G$ is the structured group $S$ itself, e.g. $G \simeq S $. This is because I can choose $M \simeq \mathbb{R^4}$ which makes the fibre bundle trivial no matter how ""complicated"" one chooses $G$ (because  $\mathbb{R^4}$ can be contracted to a point). This seems like a contradiction to me. Furthermore image I start out with  $ P= P(M,G) $ and systematically ""test out"" different base manifolds $M$ while keeping $G$ fixed. Now as soon as the topology of $M$ changes ( say $M$ cannot be contracted to a point unlike before) one needs to expects the structure group of the bundle to change as well; but it was fixed to be $G$ in the first place? How can this be? One way out I see if one replaces $G \simeq S $ by $G \supseteq S$ requiring that the structured group only needs to be a subset of $G$. So in the trivial case from before $ P = P(\mathbb{R^4},G)$ the structured group would only pick out the trivial sub-group $S=\{e\}$ from G. However even in this case, in my second example of ""testing out"" different base-manifolds for a given $G$, which theorem guarantees me that one always stays within $G \supseteq S$ for an arbitrary choice of $M$? many thanks!",,"['differential-geometry', 'principal-bundles']"
15,Is the number of killing vector fields equal to the number of all isometries of a Riemannian manifold?,Is the number of killing vector fields equal to the number of all isometries of a Riemannian manifold?,,"I've been wondering wether there is a bijection between the set of killing vector fields and the group of all isometries of a fixed given manifold. Is it true in general, when does it fail to happen? It's obvious from definition that the number of killing vector fields does not exceed that of all isometries of the manifold (this I can actually see! ;) In those cases of affirmative answer, how's the bijection or, in other words, how's the counting process?","I've been wondering wether there is a bijection between the set of killing vector fields and the group of all isometries of a fixed given manifold. Is it true in general, when does it fail to happen? It's obvious from definition that the number of killing vector fields does not exceed that of all isometries of the manifold (this I can actually see! ;) In those cases of affirmative answer, how's the bijection or, in other words, how's the counting process?",,"['differential-geometry', 'isometry']"
16,Is this intuitive way of thinking about the implicit function theorem correct?,Is this intuitive way of thinking about the implicit function theorem correct?,,"""Intuitive version"": Let $f: \mathbb{R}^n \to \mathbb{R}^m$, $n\ge m$, be a smooth map. If , given $q \in \mathbb{R}^m$, for a fixed point $p \in f^{-1}(q)$ one can define a maximum-dimension vector space using the partial derivatives of $f$ then there exists a diffeomorphism between a neighborhood in $f^{-1}(q)$ of $p$  and $\mathbb{R}^{n-m}$ (i.e. one can ""smoothly deform"" a neighborhood of $f^{-1}(q)$ into $\mathbb{R}^{n-m}$). When I say ""non-degenerate"" I mean of maximum possible dimension, which is the maximum possible number of linearly independent vectors which can be defined by the partial derivatives. One has to specify the point $q$ before specifying the point $p$, because otherwise one would try to construct a diffeomorphism between a neighborhood in $\mathbb{R}^n$ of $p$ and $\mathbb{R}^{n-m}$, which obviously does not make any sense -- we have to specify that the neighborhood is in $f^{-1}(q)$. Questions: 1. Is this way of thinking about the implicit function theorem correct? 2. Why is $f^{-1}(q)$ of dimension $n-m$ when the dimension of the space spanned by the partial derivatives of $f$ at every point $p \in f^{-1}(q)$ is $m$? If $f^{-1}(q)$ has $m$-dimensional tangent spaces then why should it be an $n-m$ dimensional manifold, and not an $m-$dimensional one? 3. If for one of the points in $f^{-1}(q)$ the derivative of $f$ doesn't have full rank (i.e. we can only define a degenerate tangent space), then does that make that point a singular point of $f^{-1}(q)$? 4. If $p_0$ is the point from the third question, then is $f^{-1}(q) \setminus \{p_0 \}$ a smooth manifold? The example I have in mind is the singular point of a curve, e.g. $(0,0)$ of $y^2 - x^3=0$. 5. What prevents the following scenario: for every point $p \in f^{-1}(q)$, $Df(p)$ has rank $m-1$, so $f^{-1}(q)$ is a manifold of dimension $n-m-1$? Does the constant rank theorem allow this possibility, explaining why the constant rank theorem is a generalization?","""Intuitive version"": Let $f: \mathbb{R}^n \to \mathbb{R}^m$, $n\ge m$, be a smooth map. If , given $q \in \mathbb{R}^m$, for a fixed point $p \in f^{-1}(q)$ one can define a maximum-dimension vector space using the partial derivatives of $f$ then there exists a diffeomorphism between a neighborhood in $f^{-1}(q)$ of $p$  and $\mathbb{R}^{n-m}$ (i.e. one can ""smoothly deform"" a neighborhood of $f^{-1}(q)$ into $\mathbb{R}^{n-m}$). When I say ""non-degenerate"" I mean of maximum possible dimension, which is the maximum possible number of linearly independent vectors which can be defined by the partial derivatives. One has to specify the point $q$ before specifying the point $p$, because otherwise one would try to construct a diffeomorphism between a neighborhood in $\mathbb{R}^n$ of $p$ and $\mathbb{R}^{n-m}$, which obviously does not make any sense -- we have to specify that the neighborhood is in $f^{-1}(q)$. Questions: 1. Is this way of thinking about the implicit function theorem correct? 2. Why is $f^{-1}(q)$ of dimension $n-m$ when the dimension of the space spanned by the partial derivatives of $f$ at every point $p \in f^{-1}(q)$ is $m$? If $f^{-1}(q)$ has $m$-dimensional tangent spaces then why should it be an $n-m$ dimensional manifold, and not an $m-$dimensional one? 3. If for one of the points in $f^{-1}(q)$ the derivative of $f$ doesn't have full rank (i.e. we can only define a degenerate tangent space), then does that make that point a singular point of $f^{-1}(q)$? 4. If $p_0$ is the point from the third question, then is $f^{-1}(q) \setminus \{p_0 \}$ a smooth manifold? The example I have in mind is the singular point of a curve, e.g. $(0,0)$ of $y^2 - x^3=0$. 5. What prevents the following scenario: for every point $p \in f^{-1}(q)$, $Df(p)$ has rank $m-1$, so $f^{-1}(q)$ is a manifold of dimension $n-m-1$? Does the constant rank theorem allow this possibility, explaining why the constant rank theorem is a generalization?",,"['real-analysis', 'differential-geometry', 'intuition', 'implicit-differentiation', 'implicit-function-theorem']"
17,composition of stereographic projections is inversion through the ball - a geometric way,composition of stereographic projections is inversion through the ball - a geometric way,,"$S^{n}$ be the unit sphere in $\mathbb{R}^{n+1}$.  Let $\pi_N$ be stereographic projection from the sphere without the north pole on to $\mathbb{R}^{n}$ and let $\pi_S$ be defined similarly using the south pole. On $\pi_N(\pi_S^{-1}(\mathbb{R^n}))=\mathbb{R^n-0}$, one can take $\pi_S \circ \pi_N^{-1}$.  By messy algebra, I showed that this is the inversion through the unit sphere $S^{n-1} \subset \mathbb R^{n}$ sending $x \in \mathbb{R}^{n} \mapsto x/|x|^2$. In full detail, I showed that that under this correspondence $z \mapsto z \cdot 2/(1+|z|^2)+(|z|^2-1)/(|z|^2+1)(0,....,0,1) \mapsto z  \cdot (2/(1+|z|^2))/(2 |z|^2 /(1+|z|^2))=z/|z|^2$ Is there a geometric way of seeing this using just inner products and such. i.e. I don't want to have to use the quadratic forumula like I did (I am trying to do this along the lines of the symmetry lemma given in Axler's Harmonic function theory. You don't have to though.)","$S^{n}$ be the unit sphere in $\mathbb{R}^{n+1}$.  Let $\pi_N$ be stereographic projection from the sphere without the north pole on to $\mathbb{R}^{n}$ and let $\pi_S$ be defined similarly using the south pole. On $\pi_N(\pi_S^{-1}(\mathbb{R^n}))=\mathbb{R^n-0}$, one can take $\pi_S \circ \pi_N^{-1}$.  By messy algebra, I showed that this is the inversion through the unit sphere $S^{n-1} \subset \mathbb R^{n}$ sending $x \in \mathbb{R}^{n} \mapsto x/|x|^2$. In full detail, I showed that that under this correspondence $z \mapsto z \cdot 2/(1+|z|^2)+(|z|^2-1)/(|z|^2+1)(0,....,0,1) \mapsto z  \cdot (2/(1+|z|^2))/(2 |z|^2 /(1+|z|^2))=z/|z|^2$ Is there a geometric way of seeing this using just inner products and such. i.e. I don't want to have to use the quadratic forumula like I did (I am trying to do this along the lines of the symmetry lemma given in Axler's Harmonic function theory. You don't have to though.)",,"['differential-geometry', 'euclidean-geometry', 'harmonic-functions']"
18,Differential on a manifold,Differential on a manifold,,"I got confused with the differential of a map on a manifold. I try to wrap up what I learned and what I am confused about. Let $X$ be a manifold and $c_1,c_2: (-\epsilon, \epsilon) \to X$ two curves satisfying $c_1(0) = x = c_2(0)$ for an $x \in X$. A tangent vector at $x$ is an equivalence class of curves satisfying the relation $c_1 \sim c_2 \Longleftrightarrow D(\varphi \circ c_1)(0) = D(\tilde{\varphi} \circ c_2)(0)$ where $(U, \varphi)$ and $(V,\tilde{\varphi})$ are charts around x and the tangent space of $X$ at $x$ is defined as the set of all these equivalence classes. If I have a map $f: X \to Y$ where $Y$ is another manifold, I can define the tangent map $T_xf: T_xX \to T_yY$ where $[c] \mapsto [f \circ c] \in T_yY$. But how can I define the derivative of $f$ at $x$ in this setup? I don't want to to this with derivations.  Since the local representation of $f$ is $(\psi \circ f \circ \varphi^{-1}). (\varphi(x))$ cant I just differentiate this and obtain $Df$ in this way i.e. $Df(x) = D(\psi \circ f \circ \varphi^{-1})(\varphi(x))$? And is this related to the tangent map? If yes, what happened to $[f \circ c]$? I am sorry for my (maybe confusing) explanation but I can't get my head around this.","I got confused with the differential of a map on a manifold. I try to wrap up what I learned and what I am confused about. Let $X$ be a manifold and $c_1,c_2: (-\epsilon, \epsilon) \to X$ two curves satisfying $c_1(0) = x = c_2(0)$ for an $x \in X$. A tangent vector at $x$ is an equivalence class of curves satisfying the relation $c_1 \sim c_2 \Longleftrightarrow D(\varphi \circ c_1)(0) = D(\tilde{\varphi} \circ c_2)(0)$ where $(U, \varphi)$ and $(V,\tilde{\varphi})$ are charts around x and the tangent space of $X$ at $x$ is defined as the set of all these equivalence classes. If I have a map $f: X \to Y$ where $Y$ is another manifold, I can define the tangent map $T_xf: T_xX \to T_yY$ where $[c] \mapsto [f \circ c] \in T_yY$. But how can I define the derivative of $f$ at $x$ in this setup? I don't want to to this with derivations.  Since the local representation of $f$ is $(\psi \circ f \circ \varphi^{-1}). (\varphi(x))$ cant I just differentiate this and obtain $Df$ in this way i.e. $Df(x) = D(\psi \circ f \circ \varphi^{-1})(\varphi(x))$? And is this related to the tangent map? If yes, what happened to $[f \circ c]$? I am sorry for my (maybe confusing) explanation but I can't get my head around this.",,['differential-geometry']
19,Quick question: Extension of vector bundles on a compact Riemann surface,Quick question: Extension of vector bundles on a compact Riemann surface,,"Given the following short exact sequence of holomorphic vector bundles on a compact Riemann surface: $0\rightarrow M\rightarrow E \rightarrow N\rightarrow 0$ Fix a hermitian metric on $E$ and $n=rank(E)$. Let $\nabla$ be the corresponding unitary connection on the $U(n)-$bundle underlying $E$. Then it splits as $\nabla=\begin{pmatrix}\nabla_M & C \\ B & \nabla_N\end{pmatrix}$ where $\nabla_M=pr_M\nabla$ where $pr_M$ denotes the orthogonal projection with respect to our Hermitian metric. Since $M$ is a holomorphic subbundle of $E$ and $\nabla$ is compatible with $E$ (i.e. $\nabla^{0,1}=\overline{\partial}_E$), $\nabla_M$ is compatible with $M$. Hence $B$ is a ($1,0$)-form. Why must we have $C=-B^\dagger$ (maybe with respect to some orthonormal basis)? Is $\nabla$ being unitary equivalent to the matrix of $\nabla$ above being Hermitian with respect to an orthonormal basis? If this is true, maybe the explanation of $C=-B^\dagger$ has to do with it? Thank you.","Given the following short exact sequence of holomorphic vector bundles on a compact Riemann surface: $0\rightarrow M\rightarrow E \rightarrow N\rightarrow 0$ Fix a hermitian metric on $E$ and $n=rank(E)$. Let $\nabla$ be the corresponding unitary connection on the $U(n)-$bundle underlying $E$. Then it splits as $\nabla=\begin{pmatrix}\nabla_M & C \\ B & \nabla_N\end{pmatrix}$ where $\nabla_M=pr_M\nabla$ where $pr_M$ denotes the orthogonal projection with respect to our Hermitian metric. Since $M$ is a holomorphic subbundle of $E$ and $\nabla$ is compatible with $E$ (i.e. $\nabla^{0,1}=\overline{\partial}_E$), $\nabla_M$ is compatible with $M$. Hence $B$ is a ($1,0$)-form. Why must we have $C=-B^\dagger$ (maybe with respect to some orthonormal basis)? Is $\nabla$ being unitary equivalent to the matrix of $\nabla$ above being Hermitian with respect to an orthonormal basis? If this is true, maybe the explanation of $C=-B^\dagger$ has to do with it? Thank you.",,"['algebraic-geometry', 'differential-geometry', 'connections', 'moduli-space', 'gauge-theory']"
20,Elementary question: local computation of curvature on principal bundle,Elementary question: local computation of curvature on principal bundle,,"Let $G$ be a Lie group and $S=[0,1]^2$. Let $\omega$ be a connection $1$-form on the trivial principal $G-$bundle $P=S\times G$ over $S$. Let $(x_1,x_2)$ be coordinates on the base $S$. We can choose a trivialization of $P$ which is parallel with respect to the $x_1-$direction over the $x_1-$axis (aka $[0,1]\times\{0\}$) and which is parallel in the $x_2-$direction at every point of $S$. Then $\omega=A_1dx_1+A_2dx_2$ where $A_i\in\mathfrak{g}$ satisfy $A_2=0$ everywhere and $A_1|_{[0,1]\times\{0\}}=0$. Denote the horizontal lift of a vector field $\chi$ on the base to $P$ as $\tilde{\chi}$. Let $\sigma$ be the vertical projection on $P$ given by $\omega$. Let $\chi_i=\partial_{x_i}$ then $\tilde{\chi_2}=\partial_{x_2}$ and $\tilde{\chi_1}|_{[0,1]\times\{0\}}=\partial_{x_1}$. How to show that $\sigma([\tilde{\chi_1},\tilde{\chi_2}])=-\partial A_1/\partial x_2$ at $(0,0)\in S$? I mean, it doesn't make sense since $\omega|_{(0,0)}=0$, is it not? Where is my misunderstanding? This is taken from page $73$ of the book ""Gauge Theory and the Topology of Four-Manifolds"" by Friedman and Morgan. Thank you.","Let $G$ be a Lie group and $S=[0,1]^2$. Let $\omega$ be a connection $1$-form on the trivial principal $G-$bundle $P=S\times G$ over $S$. Let $(x_1,x_2)$ be coordinates on the base $S$. We can choose a trivialization of $P$ which is parallel with respect to the $x_1-$direction over the $x_1-$axis (aka $[0,1]\times\{0\}$) and which is parallel in the $x_2-$direction at every point of $S$. Then $\omega=A_1dx_1+A_2dx_2$ where $A_i\in\mathfrak{g}$ satisfy $A_2=0$ everywhere and $A_1|_{[0,1]\times\{0\}}=0$. Denote the horizontal lift of a vector field $\chi$ on the base to $P$ as $\tilde{\chi}$. Let $\sigma$ be the vertical projection on $P$ given by $\omega$. Let $\chi_i=\partial_{x_i}$ then $\tilde{\chi_2}=\partial_{x_2}$ and $\tilde{\chi_1}|_{[0,1]\times\{0\}}=\partial_{x_1}$. How to show that $\sigma([\tilde{\chi_1},\tilde{\chi_2}])=-\partial A_1/\partial x_2$ at $(0,0)\in S$? I mean, it doesn't make sense since $\omega|_{(0,0)}=0$, is it not? Where is my misunderstanding? This is taken from page $73$ of the book ""Gauge Theory and the Topology of Four-Manifolds"" by Friedman and Morgan. Thank you.",,"['algebraic-geometry', 'differential-geometry', 'reference-request', 'gauge-theory']"
21,Metric non symmetric connection in the tangent bundle?,Metric non symmetric connection in the tangent bundle?,,"Let $\Sigma$ be a surface endowed with a Riemannian metric $g.$ According to the fundamental theorem of Riemannian geometry, there exist a unique $\nabla$ symmetric connection ( i.e. torsionless) in the tangent bundle of $\Sigma$ that preserves the metric, that is $$ \nabla g \equiv 0.$$ Are there any examples of non symmetric connections that preserve a metrig $g$ on a surface $\Sigma?$ What if $g$ is flat?","Let $\Sigma$ be a surface endowed with a Riemannian metric $g.$ According to the fundamental theorem of Riemannian geometry, there exist a unique $\nabla$ symmetric connection ( i.e. torsionless) in the tangent bundle of $\Sigma$ that preserves the metric, that is $$ \nabla g \equiv 0.$$ Are there any examples of non symmetric connections that preserve a metrig $g$ on a surface $\Sigma?$ What if $g$ is flat?",,"['differential-geometry', 'riemannian-geometry', 'connections']"
22,Are convex combinations of projection operators still projection operators?,Are convex combinations of projection operators still projection operators?,,"If $P_1, P_2: V \to V$ are linear projection operators on the vector space $V$ with $R := P_1(V) = P_2(V)$, is it true that any convex combination of $P_1$ and $P_2$ is again a projection operator $P_3$ with $P_3(V) = R$? I'm trying to figure out whether or not the convex combination of two Ehresmann connections on a fiber bundle is again an Ehresmann connection, as is seemingly implied by the first paragraph of $\S$2 of this paper .","If $P_1, P_2: V \to V$ are linear projection operators on the vector space $V$ with $R := P_1(V) = P_2(V)$, is it true that any convex combination of $P_1$ and $P_2$ is again a projection operator $P_3$ with $P_3(V) = R$? I'm trying to figure out whether or not the convex combination of two Ehresmann connections on a fiber bundle is again an Ehresmann connection, as is seemingly implied by the first paragraph of $\S$2 of this paper .",,"['linear-algebra', 'differential-geometry', 'differential-topology']"
23,The group $\mathrm{Diff}(F)$ and transition functions of a fibre bundle.,The group  and transition functions of a fibre bundle.,\mathrm{Diff}(F),"Let $M$ and $F$ be differentiable manifolds, and let $F\to E\to M$ be a differentiable fibre bundle over $M$. A trivialising cover $\{(U_i,\phi_i)\,|\,i\in I\}$ of $M$ determines a set $\{t_{ij}:U_{ij}\to\mathrm{Diff}(F)\,|\,i,h\in I\}$ of transition functions satisfying the Čech cocycle conditions. In [Nakahra, Geometry, Topology and Physics, 2003], it is assumed that these transition functions actually take values in some Lie group $G$, and it is simply mentioned that the transition functions are smooth maps. I was pondering: Why are they actually smooth? If one considers the general case that the transition functions take values in $\mathrm{Diff}(F)$, are these functions still smooth? Is this even well-defined, i.e. is $\mathrm{Diff}(F)$ always a manifold? Any help is much appreciated.","Let $M$ and $F$ be differentiable manifolds, and let $F\to E\to M$ be a differentiable fibre bundle over $M$. A trivialising cover $\{(U_i,\phi_i)\,|\,i\in I\}$ of $M$ determines a set $\{t_{ij}:U_{ij}\to\mathrm{Diff}(F)\,|\,i,h\in I\}$ of transition functions satisfying the Čech cocycle conditions. In [Nakahra, Geometry, Topology and Physics, 2003], it is assumed that these transition functions actually take values in some Lie group $G$, and it is simply mentioned that the transition functions are smooth maps. I was pondering: Why are they actually smooth? If one considers the general case that the transition functions take values in $\mathrm{Diff}(F)$, are these functions still smooth? Is this even well-defined, i.e. is $\mathrm{Diff}(F)$ always a manifold? Any help is much appreciated.",,"['differential-geometry', 'differential-topology', 'lie-groups', 'smooth-manifolds']"
24,"Schwarzschild metric, speed of ball as measured by observer who catches the ball, just before ball is caught?","Schwarzschild metric, speed of ball as measured by observer who catches the ball, just before ball is caught?",,"The Schwarzschild metric, describing the exterior gravitational field of a planet of mass $M$ and radius $R$, is given by$$ds^2 = -(1 - 2M/r)\,dt^2 + (1 - 2M/r)^{-1}\,dr^2 + r^2(d\theta^2 + \sin^2\theta \,d\phi^2).$$A tower has its base on the surface of this planet ($r = R$) and its top at radial coordinate $r = R_1$. A ball is held at rest by an observer at the top of the tower. It is then dropped and caught by an observer at the bottom of the tower. What is the speed, $v$, of the ball as measured by the observer who catches the ball, just before the ball is caught? Here, we are not assuming that $R \gg 2M$ or that $R_1 - R \ll R$. Also, I want the physical speed here, $v$, as would be measured, e.g. by a radar gun, not a coordinate speed, such as $dr/dt$.","The Schwarzschild metric, describing the exterior gravitational field of a planet of mass $M$ and radius $R$, is given by$$ds^2 = -(1 - 2M/r)\,dt^2 + (1 - 2M/r)^{-1}\,dr^2 + r^2(d\theta^2 + \sin^2\theta \,d\phi^2).$$A tower has its base on the surface of this planet ($r = R$) and its top at radial coordinate $r = R_1$. A ball is held at rest by an observer at the top of the tower. It is then dropped and caught by an observer at the bottom of the tower. What is the speed, $v$, of the ball as measured by the observer who catches the ball, just before the ball is caught? Here, we are not assuming that $R \gg 2M$ or that $R_1 - R \ll R$. Also, I want the physical speed here, $v$, as would be measured, e.g. by a radar gun, not a coordinate speed, such as $dr/dt$.",,"['differential-geometry', 'physics']"
25,"Bott&Tu Definition: ""Types of Forms:","Bott&Tu Definition: ""Types of Forms:",,"In Bott&Tu's well-known book ""Differential forms in Algebraic topology"", they note  -(p34): every form on $\mathbb{R}^n \times \mathbb{R}$ can be decomposed uniquely as a linear combination of two types of forms: Type 1: $\pi^*(\phi) f(x,t)$ Type 2: $\pi^*(\phi) f(x,t) dt.$ Here $\phi$ is a form on $\mathbb{R}^n.$ Then (on p35) they add : -If $\{U_{\alpha}\}$ is an atlas for $M$ then $\{ U_{\alpha} \times \mathbb{R} \}$ is an atlas for $M \times \mathbb{R}.$ Again every form on $M \times \mathbb{R}$ is a linear combination of forms of type (1) and type (2). My question: I agree with the claim on p34. I also agree that, given a form on $M \times \mathbb{R},$ I can split it canonically as $\text{ker}(i^*) \oplus (1- \text{ker}(i^*))$ (where $i: M\to M \times \mathbb{R}$ is the zero section).  The two summands will then be $\textbf{locally}$ of the form claimed by Bott and Tu. However, I don't understand why this decomposition should hold globally, as Bott&Tu seem to be arguing (they repeat the claim on p61).","In Bott&Tu's well-known book ""Differential forms in Algebraic topology"", they note  -(p34): every form on $\mathbb{R}^n \times \mathbb{R}$ can be decomposed uniquely as a linear combination of two types of forms: Type 1: $\pi^*(\phi) f(x,t)$ Type 2: $\pi^*(\phi) f(x,t) dt.$ Here $\phi$ is a form on $\mathbb{R}^n.$ Then (on p35) they add : -If $\{U_{\alpha}\}$ is an atlas for $M$ then $\{ U_{\alpha} \times \mathbb{R} \}$ is an atlas for $M \times \mathbb{R}.$ Again every form on $M \times \mathbb{R}$ is a linear combination of forms of type (1) and type (2). My question: I agree with the claim on p34. I also agree that, given a form on $M \times \mathbb{R},$ I can split it canonically as $\text{ker}(i^*) \oplus (1- \text{ker}(i^*))$ (where $i: M\to M \times \mathbb{R}$ is the zero section).  The two summands will then be $\textbf{locally}$ of the form claimed by Bott and Tu. However, I don't understand why this decomposition should hold globally, as Bott&Tu seem to be arguing (they repeat the claim on p61).",,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
26,"Showing that, at an elliptic point, a surface lies on one side of the tangent plane.","Showing that, at an elliptic point, a surface lies on one side of the tangent plane.",,"Let $p\in S$ be an elliptic point of a surface $S$. I want to show that there exists a neighbourhhod $V$ of $p$ in $S$ such that all points in $V$ belong to the same side of the tangent plane $T_p(S)$. The book I'm reading (Do Carmo), proceeds as follows: Let $\mathbf{x}$ be a parametrization at $p$, with $\mathbf{x}(0,0)=p$. We consider the distance function: $$d(u,v)=\langle \mathbf{x}(u,v)-p,N(p) \rangle$$ Applying Taylor's Formula we obtain: $$\mathbf{x}(u,v)=\mathbf{x}(0,0)+\mathbf{x}_u u +\mathbf{x}_v v+\frac{1}{2}(\mathbf{x}_{uu}u^2+2\mathbf{x}_{uv} uv + \mathbf{x}_{vv}v^2)+\overline{R}$$ where all derivatives are evaluated at $(0,0)$ and $\displaystyle\lim_{(u,v)\to (0,0)}\frac{\overline{R}(u,v)}{u^2+v^2}=0$. Rearranging the terms: $$d(u,v)=\frac{1}{2}II_p(w)+R(u,v)$$ where $II_p(\cdot)$ is the ssecond fundamental form at $p$, $w=u\mathbf{x}_u+v\mathbf{x}_v$ and $R(u,v)=\langle \overline{R}(u,v),N(p)\rangle$. The author claims that $\lim_{w\to \mathbf{0}}\frac{R}{|w|^2}=0$. My question is Why is this? The norm $|w|$ is given by the first fundamental form $|w|^2=I_p(w)=Eu^2+2Fuv+Gv^2$, with $EG-F^2>0$. Hence: $$\frac{\overline{R}}{|w|^2}=\frac{u^2+v^2}{Eu^2+2Fuv+Gv^2}\frac{\overline{R}}{u^2+v^2}$$ If I could show that the quotient $$\frac{u^2+v^2}{Eu^2+2Fuv+Gv^2}$$ is bounded in a neighbourhood of $(0,0)$, then I would be done, but I don't see why this should be the case. Any ideas? (or alternative proofs of the initial claim?).","Let $p\in S$ be an elliptic point of a surface $S$. I want to show that there exists a neighbourhhod $V$ of $p$ in $S$ such that all points in $V$ belong to the same side of the tangent plane $T_p(S)$. The book I'm reading (Do Carmo), proceeds as follows: Let $\mathbf{x}$ be a parametrization at $p$, with $\mathbf{x}(0,0)=p$. We consider the distance function: $$d(u,v)=\langle \mathbf{x}(u,v)-p,N(p) \rangle$$ Applying Taylor's Formula we obtain: $$\mathbf{x}(u,v)=\mathbf{x}(0,0)+\mathbf{x}_u u +\mathbf{x}_v v+\frac{1}{2}(\mathbf{x}_{uu}u^2+2\mathbf{x}_{uv} uv + \mathbf{x}_{vv}v^2)+\overline{R}$$ where all derivatives are evaluated at $(0,0)$ and $\displaystyle\lim_{(u,v)\to (0,0)}\frac{\overline{R}(u,v)}{u^2+v^2}=0$. Rearranging the terms: $$d(u,v)=\frac{1}{2}II_p(w)+R(u,v)$$ where $II_p(\cdot)$ is the ssecond fundamental form at $p$, $w=u\mathbf{x}_u+v\mathbf{x}_v$ and $R(u,v)=\langle \overline{R}(u,v),N(p)\rangle$. The author claims that $\lim_{w\to \mathbf{0}}\frac{R}{|w|^2}=0$. My question is Why is this? The norm $|w|$ is given by the first fundamental form $|w|^2=I_p(w)=Eu^2+2Fuv+Gv^2$, with $EG-F^2>0$. Hence: $$\frac{\overline{R}}{|w|^2}=\frac{u^2+v^2}{Eu^2+2Fuv+Gv^2}\frac{\overline{R}}{u^2+v^2}$$ If I could show that the quotient $$\frac{u^2+v^2}{Eu^2+2Fuv+Gv^2}$$ is bounded in a neighbourhood of $(0,0)$, then I would be done, but I don't see why this should be the case. Any ideas? (or alternative proofs of the initial claim?).",,"['differential-geometry', 'surfaces']"
27,What does $C^k$ at a single point mean?,What does  at a single point mean?,C^k,"I'm reading textbooks on manifolds. I usually see a saying that ""function $f$ is $C^k$ at a point $p \in M$"". I am confused with this. What does this mean? Furthermore if $f$ is $C^k$ at $p$, is it necessary that $f$ is $C^k$ in some neighborhood of $p$? Thanks for your help in advance.","I'm reading textbooks on manifolds. I usually see a saying that ""function $f$ is $C^k$ at a point $p \in M$"". I am confused with this. What does this mean? Furthermore if $f$ is $C^k$ at $p$, is it necessary that $f$ is $C^k$ in some neighborhood of $p$? Thanks for your help in advance.",,"['real-analysis', 'differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
28,Proof that this is a smooth manifold,Proof that this is a smooth manifold,,"Let $F: \mathbb{R}^2 \rightarrow \mathbb{R}^4$ be defined by $F(u,v) = (u+v, uv, u-v, v^3)$ and let $M = F(\mathbb{R}^2)$. Prove that $M$ is a smooth manifold. The proof that my TA posted online was this: If the differential $DF|_{(u,v)}: T_{(u,v)} \mathbb{R}^2 \rightarrow T_{F(u,v)} \mathbb{R}^4$ is non degenerate then $F$ defines a smooth immersion of $\mathbb{R}^2$ into $\mathbb{R}^4$ and hence $F$ defines local diffeomorphisms for the image $M$. To verify that $F$ is a smooth immersion, note that $\mathrm{rank}(F) = 2 = \dim(\mathbb{R}^2)$. Because $F$ is globally injective, then it is actually a global diffeomorphism onto its image $M$. Hence $M$ is a smooth $2$-manifold. I am struggling to understand this proof. I get why $F$ is a smooth immersion, but I don't get why it defines local diffeomorphisms. It seems as if he is applying the inverse function theorem to $F: \mathbb{R}^2 \rightarrow \mathbb{R}^4$, but he can't do this because the domain and co-domain do not have the same dimension. You could apply the inverse function theorem to $F: \mathbb{R}^2 \rightarrow M$, but this would require you to already know that $M$ is a smooth $2$-manifold, which is what we are trying to prove. What am I missing here? I would ask my TA but classes are done for the semester, so I won't be seeeing him again.","Let $F: \mathbb{R}^2 \rightarrow \mathbb{R}^4$ be defined by $F(u,v) = (u+v, uv, u-v, v^3)$ and let $M = F(\mathbb{R}^2)$. Prove that $M$ is a smooth manifold. The proof that my TA posted online was this: If the differential $DF|_{(u,v)}: T_{(u,v)} \mathbb{R}^2 \rightarrow T_{F(u,v)} \mathbb{R}^4$ is non degenerate then $F$ defines a smooth immersion of $\mathbb{R}^2$ into $\mathbb{R}^4$ and hence $F$ defines local diffeomorphisms for the image $M$. To verify that $F$ is a smooth immersion, note that $\mathrm{rank}(F) = 2 = \dim(\mathbb{R}^2)$. Because $F$ is globally injective, then it is actually a global diffeomorphism onto its image $M$. Hence $M$ is a smooth $2$-manifold. I am struggling to understand this proof. I get why $F$ is a smooth immersion, but I don't get why it defines local diffeomorphisms. It seems as if he is applying the inverse function theorem to $F: \mathbb{R}^2 \rightarrow \mathbb{R}^4$, but he can't do this because the domain and co-domain do not have the same dimension. You could apply the inverse function theorem to $F: \mathbb{R}^2 \rightarrow M$, but this would require you to already know that $M$ is a smooth $2$-manifold, which is what we are trying to prove. What am I missing here? I would ask my TA but classes are done for the semester, so I won't be seeeing him again.",,"['differential-geometry', 'differential-topology', 'smooth-manifolds']"
29,Why image of curvature is a Lie subalgebra?,Why image of curvature is a Lie subalgebra?,,"In the red line of  picture below, why it is Lie algebra ? $M_{\alpha\beta}$ is the Lie bracket ? But $M_{\alpha\beta}$ is symmetric . Picture below is from the 216 page of this paper . $\ \ \ \ $ $\text{T}\scriptstyle{\text{HEOREM}}\ $ $2.2.1\ $ (Hamilton's strong maximum principle). Let $M_{\alpha\beta}$ be a smooth solution of the equation $(2.2.1)$ . Suppose $M_{\alpha\beta}\geq0$ on $\Sigma\times[0,T]$ . Then there exists a positive constant $0<\delta\leq T$ such that on $\Sigma\times(0,\delta)$ , the rank of $M_{\alpha\beta}$ is constant, and the null space of $M_{\alpha\beta}$ is invariant under parallel translation and invariant in time and also lies in the null space of $N_{\alpha\beta}$ .","In the red line of  picture below, why it is Lie algebra ? is the Lie bracket ? But is symmetric . Picture below is from the 216 page of this paper . (Hamilton's strong maximum principle). Let be a smooth solution of the equation . Suppose on . Then there exists a positive constant such that on , the rank of is constant, and the null space of is invariant under parallel translation and invariant in time and also lies in the null space of .","M_{\alpha\beta} M_{\alpha\beta} \ \ \ \  \text{T}\scriptstyle{\text{HEOREM}}\  2.2.1\  M_{\alpha\beta} (2.2.1) M_{\alpha\beta}\geq0 \Sigma\times[0,T] 0<\delta\leq T \Sigma\times(0,\delta) M_{\alpha\beta} M_{\alpha\beta} N_{\alpha\beta}","['differential-geometry', 'riemannian-geometry', 'curvature', 'ricci-flow']"
30,Definition of a regular surface,Definition of a regular surface,,"Here is the definition of a regular surface from Differential Geometry of Curves and Surfaces by Manfredo do Carmo: A subset $S ⊂ \mathbb R^3$ is a regular surface if, for each $p ∈ S$ , there exists a neighborhood $V ⊂ \mathbb R^3$ and a map $f : U → V ∩ S$ of an open set $U ⊂ \mathbb R^2$ onto $V ∩ S ⊂ \mathbb R^3$ such that $f$ is $C^\infty$ . $f$ is a homeomorphism. Since $f$ is continuous, this means that $f$ has an inverse $f^{-1} : V ∩ S → U$ which is continuous; that is, $f^{-1}$ is the restriction of a continuous map $F : W ⊂ \mathbb R^3 → \mathbb R^2$ defined on an open set $W$ containing $V ∩ S$ . For each $q ∈ U$ holds $f'(q) : \mathbb R^2 → \mathbb R^3$ is one-to-one. I don't understand what is meant by that is, $f^{-1}$ is the restriction of a continuous map $F : W ⊂ \mathbb R^3 → \mathbb R^2$ defined on an open set $W$ containing $V ∩ S$ Why does it mention $W ⊂ \mathbb R^3$ and the restriction?","Here is the definition of a regular surface from Differential Geometry of Curves and Surfaces by Manfredo do Carmo: A subset is a regular surface if, for each , there exists a neighborhood and a map of an open set onto such that is . is a homeomorphism. Since is continuous, this means that has an inverse which is continuous; that is, is the restriction of a continuous map defined on an open set containing . For each holds is one-to-one. I don't understand what is meant by that is, is the restriction of a continuous map defined on an open set containing Why does it mention and the restriction?",S ⊂ \mathbb R^3 p ∈ S V ⊂ \mathbb R^3 f : U → V ∩ S U ⊂ \mathbb R^2 V ∩ S ⊂ \mathbb R^3 f C^\infty f f f f^{-1} : V ∩ S → U f^{-1} F : W ⊂ \mathbb R^3 → \mathbb R^2 W V ∩ S q ∈ U f'(q) : \mathbb R^2 → \mathbb R^3 f^{-1} F : W ⊂ \mathbb R^3 → \mathbb R^2 W V ∩ S W ⊂ \mathbb R^3,"['differential-geometry', 'surfaces']"
31,No conjugate points on $S^1\times \Bbb R$,No conjugate points on,S^1\times \Bbb R,Lee claims in his book that $S^1\times \Bbb R$ (considered as a submanifold of $\Bbb R^3$) admits no conjugate points along any geodesic. I am struggling to make that rigorous. Being conjugate along a geodesic $c$ means that there is a nontrivial Jacobi field $J$ which vanishes at the end points. Each such Jacobi field is induced by a variation of $c$ of the form $$c_s(t)=\exp_p(t(c'(0)+sW))$$ for some nonzero $W\in T_pM$. How can I see that such a variation must have $W=0$?,Lee claims in his book that $S^1\times \Bbb R$ (considered as a submanifold of $\Bbb R^3$) admits no conjugate points along any geodesic. I am struggling to make that rigorous. Being conjugate along a geodesic $c$ means that there is a nontrivial Jacobi field $J$ which vanishes at the end points. Each such Jacobi field is induced by a variation of $c$ of the form $$c_s(t)=\exp_p(t(c'(0)+sW))$$ for some nonzero $W\in T_pM$. How can I see that such a variation must have $W=0$?,,"['differential-geometry', 'riemannian-geometry', 'curvature', 'geodesic']"
32,Tangent Space Well Defined?,Tangent Space Well Defined?,,"Question: Let $M$ be a $k$-manifold of class $C^r$ in $\mathbb R^n$. Let  $p\in M$. Show that the tangent space to $M$ at $p$ is well-defined, independent of choice patch. Unsure if I'm understanding what this is asking of me. What does it mean to be well defined and how do I prove it? From Munkres Calculus on Manifolds Thanks in advance!","Question: Let $M$ be a $k$-manifold of class $C^r$ in $\mathbb R^n$. Let  $p\in M$. Show that the tangent space to $M$ at $p$ is well-defined, independent of choice patch. Unsure if I'm understanding what this is asking of me. What does it mean to be well defined and how do I prove it? From Munkres Calculus on Manifolds Thanks in advance!",,"['differential-geometry', 'manifolds']"
33,Harmonic function with injective boundary conditions is an immersion?,Harmonic function with injective boundary conditions is an immersion?,,"This question is in some sense a continuation of this question , though more focused in its scope. Let $(M,g)$ be an $n$-dimensional, connected, compact Riemannian manifold with boundary. Assume we are given an immersion $f:M \to \mathbb{R}^n$. (i.e $df$ is invertible at every point $p \in M$, note that I assume $n$ is the dimension of $M$). Let $\omega:(M,g) \to (\mathbb{R}^n,e)$ be the harmonic function corresponding to the Dirichlet problem imposed by $f$, i.e $\omega|_{\partial M}=f|_{\partial M}$ Is it true that $\omega$ must be an immersion? Does anything change if we assume $f$ is (globally) injective? Note that since $f$ is an immersion, it is locally injective, hence $f|_{\partial M}$ is locally injective. (In particular naive ""counter-examples"" like taking $\,f|_{\partial M}$ to be constant so $\omega$ is constant do not work). In fact we have $\text{rank}(d\omega_p)\ge \text{rank}\big(d(\omega|_{\partial M})_p\big)= \text{rank}\big(d(f|_{\partial M})_p\big)=n-1$ for every $p \in \partial M$","This question is in some sense a continuation of this question , though more focused in its scope. Let $(M,g)$ be an $n$-dimensional, connected, compact Riemannian manifold with boundary. Assume we are given an immersion $f:M \to \mathbb{R}^n$. (i.e $df$ is invertible at every point $p \in M$, note that I assume $n$ is the dimension of $M$). Let $\omega:(M,g) \to (\mathbb{R}^n,e)$ be the harmonic function corresponding to the Dirichlet problem imposed by $f$, i.e $\omega|_{\partial M}=f|_{\partial M}$ Is it true that $\omega$ must be an immersion? Does anything change if we assume $f$ is (globally) injective? Note that since $f$ is an immersion, it is locally injective, hence $f|_{\partial M}$ is locally injective. (In particular naive ""counter-examples"" like taking $\,f|_{\partial M}$ to be constant so $\omega$ is constant do not work). In fact we have $\text{rank}(d\omega_p)\ge \text{rank}\big(d(\omega|_{\partial M})_p\big)= \text{rank}\big(d(f|_{\partial M})_p\big)=n-1$ for every $p \in \partial M$",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'harmonic-functions']"
34,Why is finding a closed form of a geodesic so difficult?,Why is finding a closed form of a geodesic so difficult?,,"What is it about geodesics (does this term apply in $R^n$ or just $R^3$?) that makes finding a closed form of the curve so difficult? My thoughts: The minimal curve may not be unique which complicates solving the differential equation. If the surface is not continuous, smooth or lacking a closed form then finding the geodesic that satisfies the conditions would be difficult but I don't really know why. The way in which the minimal curve passes across the surface may be in such a way that it doesn't fit well into our set of functions.  I don't really know a better way to put this. So what exactly makes this class of questions so difficult to find closed form solutions to? Sorry if this is too general. Thanks","What is it about geodesics (does this term apply in $R^n$ or just $R^3$?) that makes finding a closed form of the curve so difficult? My thoughts: The minimal curve may not be unique which complicates solving the differential equation. If the surface is not continuous, smooth or lacking a closed form then finding the geodesic that satisfies the conditions would be difficult but I don't really know why. The way in which the minimal curve passes across the surface may be in such a way that it doesn't fit well into our set of functions.  I don't really know a better way to put this. So what exactly makes this class of questions so difficult to find closed form solutions to? Sorry if this is too general. Thanks",,"['calculus', 'differential-geometry', 'calculus-of-variations']"
35,Vector Bundles: Continuity of map between total space implies homeomorphism.,Vector Bundles: Continuity of map between total space implies homeomorphism.,,"In Spivak's ""A Comprehensive Introduction to Differential Geometry"" Spivak defines a vector bundle as a tuple: $(E, \pi, B, \bigoplus, \bigodot),$ where $E$ is the total space, $B$ is the base space, $\pi$ is a continuous map from $E$ onto $B$ (thought of as like a projection) and there are vector additions on each fiber, and scalar multiplication on the total space. Lastly, he gives a local trivialization condition. He says that two vector bundles over the same space are equivalent if there is a homeomorphism of the total spaces which takes fibers onto fibers. This is what he says is the definition of equivalence. In an exercise after this, he says that we do not need a homeomorphism - that if the map between total spaces is continuous, then the spaces are in fact homeomorphic. I don't even begin to see what's going on here. For manifolds in general, this is far from true - there is no reason continuity should say anything about the inverse map being continuous, and certainly not bijectivity. The only thing I can think of is that Spivak's question is worded a little poorly, and I should assume the map is continuous, and the fibers are taken isomorphically to fibers.  Even with this new information though, I still feel mostly lost. For example, why can't we send the whole total space to just a single point and fiber? Thanks for any pointers or hints.","In Spivak's ""A Comprehensive Introduction to Differential Geometry"" Spivak defines a vector bundle as a tuple: $(E, \pi, B, \bigoplus, \bigodot),$ where $E$ is the total space, $B$ is the base space, $\pi$ is a continuous map from $E$ onto $B$ (thought of as like a projection) and there are vector additions on each fiber, and scalar multiplication on the total space. Lastly, he gives a local trivialization condition. He says that two vector bundles over the same space are equivalent if there is a homeomorphism of the total spaces which takes fibers onto fibers. This is what he says is the definition of equivalence. In an exercise after this, he says that we do not need a homeomorphism - that if the map between total spaces is continuous, then the spaces are in fact homeomorphic. I don't even begin to see what's going on here. For manifolds in general, this is far from true - there is no reason continuity should say anything about the inverse map being continuous, and certainly not bijectivity. The only thing I can think of is that Spivak's question is worded a little poorly, and I should assume the map is continuous, and the fibers are taken isomorphically to fibers.  Even with this new information though, I still feel mostly lost. For example, why can't we send the whole total space to just a single point and fiber? Thanks for any pointers or hints.",,"['differential-geometry', 'manifolds', 'fiber-bundles']"
36,Spheres as Homogeneous Spaces,Spheres as Homogeneous Spaces,,"Any odd dimensional sphere $S^{2n+1}$ can be expressed as an homogenous space of $SU(n+1)$ by $S^{2n+1} \simeq SU(n+1)/SU(n)$ . Any even dimensional sphere $S^{2n}$ sphere can be expressed as an homogeneous space of $SO(n)$ according to $S^{2n} \simeq SO(n)/SO(n-1)$ . Can we make for a switch here? In explicit, can one realize the odd spheres as $SO(n)$ homogeneous spaces, and can one realize the even spheres as $SU(n)$ homogeneous spaces.","Any odd dimensional sphere can be expressed as an homogenous space of by . Any even dimensional sphere sphere can be expressed as an homogeneous space of according to . Can we make for a switch here? In explicit, can one realize the odd spheres as homogeneous spaces, and can one realize the even spheres as homogeneous spaces.",S^{2n+1} SU(n+1) S^{2n+1} \simeq SU(n+1)/SU(n) S^{2n} SO(n) S^{2n} \simeq SO(n)/SO(n-1) SO(n) SU(n),"['differential-geometry', 'lie-groups', 'lie-algebras', 'homogeneous-spaces']"
37,The quadric contains the whole line,The quadric contains the whole line,,"I am looking at the following exercise: Show that, if a quadric contains three points on a straight line, it contains the whole line. Deduce that, if $L_1$, $L_2$ and $L_3$ are nonintersecting straight lines in $\mathbb{R}^3$, there is a quadric containing all three lines. $$$$ A straight line is of the form $\gamma (t)=a+tb$, right? Do we use the following equation that defines the quadric? $$v^tAv+b^tv+c=0$$ What does it mean that the quadric contains three points on a straight line? $$$$ EDIT: I am looking also at the next exercise: I have the following: Let $L_1, L_2, L_3$ be three  nonintersecting straight lines of the first family. From the previous Exercise we have that there is a quadric that contains all the three lines. We have that each line of the second family , with at most a  finite number of exceptions, intersects each line of the first family. Let $\tilde{L}$ such a line of the second family. So $\tilde{L} $ intersects the lines $L_1, L_2, L_3$. Since the above quadric contains $L_1, L_2, L_3$ we have that the quadric contains three points on $\tilde{L}$. Therefore the quadric contains the whole $\tilde{L}$. So the quadric contains all the lines of the second family, with at most a finite number of exceptions. So a doubly ruled surface is a quadric surface, or part of a quadric surface. Is this correct? Which quadric surfaces are doubly ruled?","I am looking at the following exercise: Show that, if a quadric contains three points on a straight line, it contains the whole line. Deduce that, if $L_1$, $L_2$ and $L_3$ are nonintersecting straight lines in $\mathbb{R}^3$, there is a quadric containing all three lines. $$$$ A straight line is of the form $\gamma (t)=a+tb$, right? Do we use the following equation that defines the quadric? $$v^tAv+b^tv+c=0$$ What does it mean that the quadric contains three points on a straight line? $$$$ EDIT: I am looking also at the next exercise: I have the following: Let $L_1, L_2, L_3$ be three  nonintersecting straight lines of the first family. From the previous Exercise we have that there is a quadric that contains all the three lines. We have that each line of the second family , with at most a  finite number of exceptions, intersects each line of the first family. Let $\tilde{L}$ such a line of the second family. So $\tilde{L} $ intersects the lines $L_1, L_2, L_3$. Since the above quadric contains $L_1, L_2, L_3$ we have that the quadric contains three points on $\tilde{L}$. Therefore the quadric contains the whole $\tilde{L}$. So the quadric contains all the lines of the second family, with at most a finite number of exceptions. So a doubly ruled surface is a quadric surface, or part of a quadric surface. Is this correct? Which quadric surfaces are doubly ruled?",,['differential-geometry']
38,Lift of a curve in a principal bundle?,Lift of a curve in a principal bundle?,,"Let $\pi:P\longrightarrow M$ be a $G$-principal bundle and $I:=[0, 1]$. Given a curve $\alpha:I\longrightarrow M$ and $p_0\in \pi^{-1}(\alpha(0))$ how can I show there is a curve $\beta:I\longrightarrow P$ such that $\pi\circ \beta=\alpha$ and $\beta(0)=p_0$? I thought defining $$\beta(t):=\phi_t^{-1}(\alpha(t), e_G),$$ where $\phi_t:\pi^{-1}(U_t)\longrightarrow U_t\times G$ are local trivializations with $\alpha(t)\in U_t$ for each $t\in I$. This satisfies $\pi\circ \beta=\alpha$ but I don't know how to get the condition $\beta(0)=p_0$. Thanks.","Let $\pi:P\longrightarrow M$ be a $G$-principal bundle and $I:=[0, 1]$. Given a curve $\alpha:I\longrightarrow M$ and $p_0\in \pi^{-1}(\alpha(0))$ how can I show there is a curve $\beta:I\longrightarrow P$ such that $\pi\circ \beta=\alpha$ and $\beta(0)=p_0$? I thought defining $$\beta(t):=\phi_t^{-1}(\alpha(t), e_G),$$ where $\phi_t:\pi^{-1}(U_t)\longrightarrow U_t\times G$ are local trivializations with $\alpha(t)\in U_t$ for each $t\in I$. This satisfies $\pi\circ \beta=\alpha$ but I don't know how to get the condition $\beta(0)=p_0$. Thanks.",,"['differential-geometry', 'principal-bundles']"
39,"Whether $df(X)=\langle\operatorname{grad}f,X\rangle$?",Whether ?,"df(X)=\langle\operatorname{grad}f,X\rangle","$(M,g)$ is Riemann manifold, $X$ is vector field, $f$ is function on $M$. $\langle\cdot,\cdot\rangle$ is inner. Whether $df(X)=\langle\operatorname{grad}f,X\rangle$ ? I only know $df(X)=X(f)$.","$(M,g)$ is Riemann manifold, $X$ is vector field, $f$ is function on $M$. $\langle\cdot,\cdot\rangle$ is inner. Whether $df(X)=\langle\operatorname{grad}f,X\rangle$ ? I only know $df(X)=X(f)$.",,"['differential-geometry', 'riemannian-geometry']"
40,Sections of a sheaf,Sections of a sheaf,,"In algebraic geometry, specifically Hartshorne, for a given sheaf $\mathscr{F}$, we say that the sections of the sheaf over some open set $U$ are merely elements $s \in \mathscr{F} (U)$. However, I believe sections is also used in other mathematical fields such as differential topology. In particular, I recently saw in Liu's book where he has the following definition: Let $\pi: X \to S$ be an $S$-scheme. A section of $X$ is a morphism $\sigma : S \to X$. What is the relation between the two definitions?","In algebraic geometry, specifically Hartshorne, for a given sheaf $\mathscr{F}$, we say that the sections of the sheaf over some open set $U$ are merely elements $s \in \mathscr{F} (U)$. However, I believe sections is also used in other mathematical fields such as differential topology. In particular, I recently saw in Liu's book where he has the following definition: Let $\pi: X \to S$ be an $S$-scheme. A section of $X$ is a morphism $\sigma : S \to X$. What is the relation between the two definitions?",,"['algebraic-geometry', 'differential-geometry', 'differential-topology']"
41,Conservative Covector Fields are Exact,Conservative Covector Fields are Exact,,"$\newcommand{\R}{\mathbf R}$ I am trying to understand the proof of the following: Theorem. Let $M$ be a smooth manifold and $\omega$ be a smooth covector field on $M$. Then $\omega$ is conservative iff it is exact. The fact that exactness implies conservativeness is clear. The other direction is more interesting. I am following the proof given in Lee's Introduction to Smooth Manifolds (Theorem 11.42). Proof. Assume $M$ is connected and $\omega$ is conservative. We need to show that $\omega$ is exact. For two points $p$ and $q$ in $M$, we write $\int_p^q \omega$ to denote the line integral $\int_\gamma \omega$, where $\gamma$ is any piecewise smooth curve starting at $p$ and ending at $q$. This notation is unambiguous because of the conservativeness of $\omega$. It is easy to guess a candidate $f:M\to \R$ such that $df=\omega$. Fix $p_0\in M$ and define $f:M\to \R$ (just a set map as of now, no smoothness claimed yet), as $$f(q)=\int_{p_0}^q\omega$$ for all $q\in M$. Main Question. To show that  $f$ defined above is smooth. For me it is enough to understand why $f$ is smooth at $p_0$. We may further assume, by passing to a smooth chart, that $M=\R^n$ and $p_0=\mathbf 0$. So the main question is revised to: Revised Main Question. Take $M=\R^n$ and $p_0=\mathbf 0$. To show that $f$ defined above is smooth at $p_0$. The rest of the proof now goes like this: Let $\epsilon>0$. Fix $j$, and let $\gamma:[-\epsilon, \epsilon]\to\R^n$ be defined as $\gamma(t)=(0, \ldots, 0, t, 0, \ldots, 0)$, where $t$ is in the $j$-th place. Let $p_1=\gamma(-\epsilon)$, and define $\tilde f:\R^n\to \R$ as $$\tilde f(q)=\int_{p_1}^q\omega$$ It is clear that the difference $f-\tilde f$ is a constant. So it is enough to show that $\tilde f$ is smooth. Now we have: $$\tilde f\circ \gamma(t)=\int_{-\epsilon}^t\omega_j(\gamma(s))ds$$ where $\omega_j$ is given by $\omega=\omega_1dx^1+\cdots +\omega_ndx^n$. By fundamental theorem of calculus this shows that $\tilde f\circ \gamma$ is smooth and we get $\frac{\partial \tilde f}{\partial x_j}(p_0)=\omega_j(p_0)$. What I do not Understand. But I do not see how does this prove that $\tilde f$ is smooth. It only shows that the partial derivative exists. What am I missing?","$\newcommand{\R}{\mathbf R}$ I am trying to understand the proof of the following: Theorem. Let $M$ be a smooth manifold and $\omega$ be a smooth covector field on $M$. Then $\omega$ is conservative iff it is exact. The fact that exactness implies conservativeness is clear. The other direction is more interesting. I am following the proof given in Lee's Introduction to Smooth Manifolds (Theorem 11.42). Proof. Assume $M$ is connected and $\omega$ is conservative. We need to show that $\omega$ is exact. For two points $p$ and $q$ in $M$, we write $\int_p^q \omega$ to denote the line integral $\int_\gamma \omega$, where $\gamma$ is any piecewise smooth curve starting at $p$ and ending at $q$. This notation is unambiguous because of the conservativeness of $\omega$. It is easy to guess a candidate $f:M\to \R$ such that $df=\omega$. Fix $p_0\in M$ and define $f:M\to \R$ (just a set map as of now, no smoothness claimed yet), as $$f(q)=\int_{p_0}^q\omega$$ for all $q\in M$. Main Question. To show that  $f$ defined above is smooth. For me it is enough to understand why $f$ is smooth at $p_0$. We may further assume, by passing to a smooth chart, that $M=\R^n$ and $p_0=\mathbf 0$. So the main question is revised to: Revised Main Question. Take $M=\R^n$ and $p_0=\mathbf 0$. To show that $f$ defined above is smooth at $p_0$. The rest of the proof now goes like this: Let $\epsilon>0$. Fix $j$, and let $\gamma:[-\epsilon, \epsilon]\to\R^n$ be defined as $\gamma(t)=(0, \ldots, 0, t, 0, \ldots, 0)$, where $t$ is in the $j$-th place. Let $p_1=\gamma(-\epsilon)$, and define $\tilde f:\R^n\to \R$ as $$\tilde f(q)=\int_{p_1}^q\omega$$ It is clear that the difference $f-\tilde f$ is a constant. So it is enough to show that $\tilde f$ is smooth. Now we have: $$\tilde f\circ \gamma(t)=\int_{-\epsilon}^t\omega_j(\gamma(s))ds$$ where $\omega_j$ is given by $\omega=\omega_1dx^1+\cdots +\omega_ndx^n$. By fundamental theorem of calculus this shows that $\tilde f\circ \gamma$ is smooth and we get $\frac{\partial \tilde f}{\partial x_j}(p_0)=\omega_j(p_0)$. What I do not Understand. But I do not see how does this prove that $\tilde f$ is smooth. It only shows that the partial derivative exists. What am I missing?",,"['differential-geometry', 'differential-forms', 'smooth-manifolds', 'line-integrals']"
42,"The value of the rational ""Möbius""-like transformations at infinity","The value of the rational ""Möbius""-like transformations at infinity",,"If $\mathbb F$ is some field, the group $PSL(2, \mathbb F)$ consists of the mappings $$  x \mapsto \frac{ax + b}{cx + d} $$ with $a,b,c,d \in \mathbb F$ and $ad - bc = 1$. These mappings are defined over the extended field $\mathbb F_{\infty} := \mathbb F \cup \{\infty\}$ (or the so called projective line). As for example written on wikipedia:Möbius transformation we have $f(\infty) = \infty$ if $c = 0$. But I am asking myself what happens with $f(\infty)$ if $c \ne 0$? There is another way to view these mappings, consider $SL(2, \mathbb K)$, the group of matrices  $$  \begin{pmatrix}     a & b \\ c & d   \end{pmatrix} $$ with $ad - bc = 1$. Then each such matrix could be mapped onto such a mapping as above, and this correspondence is surjective. By computation we find $$  \frac{a\left( \frac{a'x + b'}{c' + d'} \right) + d}{c\left( \frac{a'x + b'}{c' + d'}\right) + d}  = \frac{(aa' + c'b)z + (ab' + bd')}{(ca' + dc')z + (cb' + d'd)} $$ and of course $$  \begin{pmatrix} a & b \\ c & d \end{pmatrix}   \begin{pmatrix} a' & b' \\ c' & d' \end{pmatrix}  = \begin{pmatrix} aa' + bc' & ab' + bd' \\ a'c + dc' & cb' + dd'      \end{pmatrix} $$ so this correspondence is a homomorphism. Such a mapping is the identity if $a = d, c = b = 0$, and the condition $ad = 1$ leaves the possiblities $a = b = \pm 1$, hence the kernel of this correspondence is $$  \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}, \quad  \begin{pmatrix} -1 & 0 \\ 0 & -1 \end{pmatrix}. $$ and this is precisely the center in the group $SL(2, \mathbb F)$. Hence $PSL(2, \mathbb F) \cong SL(2, \mathbb F) / Z(SL(2,\mathbb F))$. Now $SL(2, \mathbb F)$ acts on $\mathbb F^2$ in a natural way by matrix multiplication, hence we have an induced action of $PSL(2,\mathbb F)$ on $\mathbb F^2$. Now each $v = (x, y)^T\in \mathbb F^2$ could be identified with $(x/y, 1)^T$ if $y \ne 1$ and $(1,0)^T$ if $y = 0$, and by this we get an identification of $\mathbb F^2$ with $\mathbb F_{\infty}$ where $(1,0)^T$ corresponds to $\infty$. As $$  \begin{pmatrix}    a & b \\ c & d   \end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} a \\ c \end{pmatrix} $$ I guess we would have $f(\infty) = a/c$ if $c \ne 0$ (which corresponds to the projective point $(a,c)^T \equiv (a/c, 1)^T$). But I am not sure if this is reasonable, so I am asking what is $f(\infty)$ in the general case?","If $\mathbb F$ is some field, the group $PSL(2, \mathbb F)$ consists of the mappings $$  x \mapsto \frac{ax + b}{cx + d} $$ with $a,b,c,d \in \mathbb F$ and $ad - bc = 1$. These mappings are defined over the extended field $\mathbb F_{\infty} := \mathbb F \cup \{\infty\}$ (or the so called projective line). As for example written on wikipedia:Möbius transformation we have $f(\infty) = \infty$ if $c = 0$. But I am asking myself what happens with $f(\infty)$ if $c \ne 0$? There is another way to view these mappings, consider $SL(2, \mathbb K)$, the group of matrices  $$  \begin{pmatrix}     a & b \\ c & d   \end{pmatrix} $$ with $ad - bc = 1$. Then each such matrix could be mapped onto such a mapping as above, and this correspondence is surjective. By computation we find $$  \frac{a\left( \frac{a'x + b'}{c' + d'} \right) + d}{c\left( \frac{a'x + b'}{c' + d'}\right) + d}  = \frac{(aa' + c'b)z + (ab' + bd')}{(ca' + dc')z + (cb' + d'd)} $$ and of course $$  \begin{pmatrix} a & b \\ c & d \end{pmatrix}   \begin{pmatrix} a' & b' \\ c' & d' \end{pmatrix}  = \begin{pmatrix} aa' + bc' & ab' + bd' \\ a'c + dc' & cb' + dd'      \end{pmatrix} $$ so this correspondence is a homomorphism. Such a mapping is the identity if $a = d, c = b = 0$, and the condition $ad = 1$ leaves the possiblities $a = b = \pm 1$, hence the kernel of this correspondence is $$  \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}, \quad  \begin{pmatrix} -1 & 0 \\ 0 & -1 \end{pmatrix}. $$ and this is precisely the center in the group $SL(2, \mathbb F)$. Hence $PSL(2, \mathbb F) \cong SL(2, \mathbb F) / Z(SL(2,\mathbb F))$. Now $SL(2, \mathbb F)$ acts on $\mathbb F^2$ in a natural way by matrix multiplication, hence we have an induced action of $PSL(2,\mathbb F)$ on $\mathbb F^2$. Now each $v = (x, y)^T\in \mathbb F^2$ could be identified with $(x/y, 1)^T$ if $y \ne 1$ and $(1,0)^T$ if $y = 0$, and by this we get an identification of $\mathbb F^2$ with $\mathbb F_{\infty}$ where $(1,0)^T$ corresponds to $\infty$. As $$  \begin{pmatrix}    a & b \\ c & d   \end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} a \\ c \end{pmatrix} $$ I guess we would have $f(\infty) = a/c$ if $c \ne 0$ (which corresponds to the projective point $(a,c)^T \equiv (a/c, 1)^T$). But I am not sure if this is reasonable, so I am asking what is $f(\infty)$ in the general case?",,"['abstract-algebra', 'group-theory', 'differential-geometry', 'mobius-transformation']"
43,Support of Pullback of Differential form,Support of Pullback of Differential form,,"This is a dumb question, but I'm learning about differntial forms, and it seems to me that if $f:N^n\to M^n$ is a diffeomorphism and $\omega$ a smooth $n$ form on $M^n$, then $\omega$ vanishes at $p\in M^n$ $\iff$ the pullback $f^*\omega$ vanishes at $f^{-1}(p)$. This implies that if $\omega$ has compact support in $M^n\iff$  $f^{-1}\omega$ has compact support in $N^n$. Question 1: Is the above correct? Question 2: Does ""$\omega$ vanishes at $p\in M^n$ $\iff$ the pullback $f^*\omega$ vanishes at $f^{-1}(p)$If $f$"" hold if $f$ is just a surjective smooth map, instead of diffeomorphism?","This is a dumb question, but I'm learning about differntial forms, and it seems to me that if $f:N^n\to M^n$ is a diffeomorphism and $\omega$ a smooth $n$ form on $M^n$, then $\omega$ vanishes at $p\in M^n$ $\iff$ the pullback $f^*\omega$ vanishes at $f^{-1}(p)$. This implies that if $\omega$ has compact support in $M^n\iff$  $f^{-1}\omega$ has compact support in $N^n$. Question 1: Is the above correct? Question 2: Does ""$\omega$ vanishes at $p\in M^n$ $\iff$ the pullback $f^*\omega$ vanishes at $f^{-1}(p)$If $f$"" hold if $f$ is just a surjective smooth map, instead of diffeomorphism?",,"['differential-geometry', 'differential-forms']"
44,Covariant derivative of 1-form,Covariant derivative of 1-form,,"I use the 3 of Proposition 1.27 to compute equality above red line.  $\nabla_X(dx^j\otimes\partial_i)= \nabla_X(dx^j)\otimes\partial_i+ dx^j\otimes\nabla_X(\partial_i)$. Then, how to get the red line equality ? And,How use $\nabla_X(tr(dx^j\otimes\partial_i))=0$  to get $\nabla_X(dx^j\otimes\partial_i)=0$ ?","I use the 3 of Proposition 1.27 to compute equality above red line.  $\nabla_X(dx^j\otimes\partial_i)= \nabla_X(dx^j)\otimes\partial_i+ dx^j\otimes\nabla_X(\partial_i)$. Then, how to get the red line equality ? And,How use $\nabla_X(tr(dx^j\otimes\partial_i))=0$  to get $\nabla_X(dx^j\otimes\partial_i)=0$ ?",,"['differential-geometry', 'riemannian-geometry']"
45,Number of Orientations of Disconnected Manifold,Number of Orientations of Disconnected Manifold,,"This seems like a stupid question, but the number of orientations of a smooth manifold with $n$ maximal connected components would be $2^n$, right? Since each connected component $U\subset M$ is open $\Rightarrow$ $U$ is a (connected) manifold and hence has two orientations.","This seems like a stupid question, but the number of orientations of a smooth manifold with $n$ maximal connected components would be $2^n$, right? Since each connected component $U\subset M$ is open $\Rightarrow$ $U$ is a (connected) manifold and hence has two orientations.",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
46,Gradient flow under varying riemannian metric,Gradient flow under varying riemannian metric,,"Suppose I have a smooth flow $\varphi(t)$ on some Riemannian manifold $(M,g)$ and I know that $\dot{\varphi}(t) = \textrm{grad }F$ for some smooth function $F$.  If I smoothly modify the metric $g$, it's obvious that $\varphi$ will not usually still be a gradient flow of $F$, but will it still be the gradient flow of some other function $\hat{F}$?  If so, is there a good way to determine what $\hat{F}$ is? It seems like this should be true as long as $F$ is sufficiently nice.  It's also worth mentioning that, while I'd like to find global results, I really only care if $\varphi$ is a gradient flow in some local chart. At the very least, maybe someone could point me toward a useful book/article, or just some better terminology to google.","Suppose I have a smooth flow $\varphi(t)$ on some Riemannian manifold $(M,g)$ and I know that $\dot{\varphi}(t) = \textrm{grad }F$ for some smooth function $F$.  If I smoothly modify the metric $g$, it's obvious that $\varphi$ will not usually still be a gradient flow of $F$, but will it still be the gradient flow of some other function $\hat{F}$?  If so, is there a good way to determine what $\hat{F}$ is? It seems like this should be true as long as $F$ is sufficiently nice.  It's also worth mentioning that, while I'd like to find global results, I really only care if $\varphi$ is a gradient flow in some local chart. At the very least, maybe someone could point me toward a useful book/article, or just some better terminology to google.",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'gradient-flows']"
47,Isometries preserve inner product in tangent spaces,Isometries preserve inner product in tangent spaces,,"I'm trying to prove that given two surfaces $S_1$ and $S_2$ and an isometric map $f:S_1\to S_2$, the maps $df_p:T_pS_1\to T_pS_2$ preserve inner products for any $p\in S_1$, i.e.,  $$\langle df_p(x),df_p(y)\rangle_{T_pS_2}=\langle x,y\rangle_{T_pS_1}$$ for any two $x,y\in T_pS_1$. I don't know very well where to start from, and there is not too much information of this results in many of the classical books (they seem to assume this result as trivial, but it is not trivial at all for me). By the way, the definition I have of isometric maps is: A diffeomorphism $f:S_1\to S_2$ is said to be isometric if the length of any curve $\gamma$ in $S_1$ is the same length of the curve $f\circ\gamma$","I'm trying to prove that given two surfaces $S_1$ and $S_2$ and an isometric map $f:S_1\to S_2$, the maps $df_p:T_pS_1\to T_pS_2$ preserve inner products for any $p\in S_1$, i.e.,  $$\langle df_p(x),df_p(y)\rangle_{T_pS_2}=\langle x,y\rangle_{T_pS_1}$$ for any two $x,y\in T_pS_1$. I don't know very well where to start from, and there is not too much information of this results in many of the classical books (they seem to assume this result as trivial, but it is not trivial at all for me). By the way, the definition I have of isometric maps is: A diffeomorphism $f:S_1\to S_2$ is said to be isometric if the length of any curve $\gamma$ in $S_1$ is the same length of the curve $f\circ\gamma$",,"['differential-geometry', 'isometry']"
48,"Problems with Leibniz rule in calculating the covariant derivative of a $(1,1)-$ tensor. Where is my mistake?",Problems with Leibniz rule in calculating the covariant derivative of a  tensor. Where is my mistake?,"(1,1)-","Let be $$R=\sum _{\alpha, \beta} R^\alpha_\beta \frac{\partial}{\partial x^\alpha} \otimes dx^\beta. $$ I want to calculate $\nabla_\gamma(R)=\nabla_{\frac{\partial}{\partial x^\gamma}}(R).$ My book gives me this first result: $$\nabla_\gamma(R)=\sum_{\beta}\big(\nabla_\gamma\sum_\alpha\big[R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\big]\big)\otimes dx^\beta+\sum_\alpha \frac{\partial}{\partial x^\alpha}\otimes\big(\nabla_\gamma\sum_\beta\big[R^\alpha_\beta dx^\beta\big]\big).$$ I have tried to obtain this expression using the Leibniz rule for tensors but I have found something different for the second addendum: $$\nabla_\gamma(R)=\sum_\beta\big( \nabla_\gamma\big[\sum_\alpha R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\otimes dx^\beta\big]\big)=\\\sum_\beta\big(\nabla_\gamma\sum_\alpha\big[R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\big]\big)\otimes dx^\beta+\sum_\beta\big(\sum_\alpha R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\big)\otimes \nabla_\gamma dx^\beta=\\\\\sum_\beta\big(\nabla_\gamma\sum_\alpha\big[R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\big]\big)\otimes dx^\beta+\sum_\alpha\big(\frac{\partial}{\partial x^\alpha}\otimes\sum_\beta\big(R^\alpha_\beta\nabla_\gamma dx^\beta \big) \big). $$ Where is my mistake? Why is this last expression  not correct?I have only used the rules of the covariant derivative but my result is different. How can I obtain the first formula? Thanks in advance for the help!","Let be $$R=\sum _{\alpha, \beta} R^\alpha_\beta \frac{\partial}{\partial x^\alpha} \otimes dx^\beta. $$ I want to calculate $\nabla_\gamma(R)=\nabla_{\frac{\partial}{\partial x^\gamma}}(R).$ My book gives me this first result: $$\nabla_\gamma(R)=\sum_{\beta}\big(\nabla_\gamma\sum_\alpha\big[R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\big]\big)\otimes dx^\beta+\sum_\alpha \frac{\partial}{\partial x^\alpha}\otimes\big(\nabla_\gamma\sum_\beta\big[R^\alpha_\beta dx^\beta\big]\big).$$ I have tried to obtain this expression using the Leibniz rule for tensors but I have found something different for the second addendum: $$\nabla_\gamma(R)=\sum_\beta\big( \nabla_\gamma\big[\sum_\alpha R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\otimes dx^\beta\big]\big)=\\\sum_\beta\big(\nabla_\gamma\sum_\alpha\big[R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\big]\big)\otimes dx^\beta+\sum_\beta\big(\sum_\alpha R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\big)\otimes \nabla_\gamma dx^\beta=\\\\\sum_\beta\big(\nabla_\gamma\sum_\alpha\big[R^\alpha_\beta\frac{\partial}{\partial x^\alpha}\big]\big)\otimes dx^\beta+\sum_\alpha\big(\frac{\partial}{\partial x^\alpha}\otimes\sum_\beta\big(R^\alpha_\beta\nabla_\gamma dx^\beta \big) \big). $$ Where is my mistake? Why is this last expression  not correct?I have only used the rules of the covariant derivative but my result is different. How can I obtain the first formula? Thanks in advance for the help!",,"['differential-geometry', 'riemannian-geometry', 'tensors']"
49,Reference needed: Exterior covariant calculus,Reference needed: Exterior covariant calculus,,"I would like to understand Cartan's formalism of exterior covariant calculus. I think it could be useful for some calculations in physics (But If I am wrong here and it's only good for abstract considerations, please tell me in advance.) I need a reference that explains main ideas (a picture that goes with the formalism) and teaches to apply it and calculate efficiently. It is crucial that it doesn't delve into abstract algebra because I don't have necessary background. I don't mind if it omits more difficult proofs. I want to understand more or less what follows from what, but I don't mind leaving some technicalities to real mathematicians. As for my background: I probably know most of things that are explained in introductory expositions of smooth manifolds (I do know it's a vague statement.) Also some Lie groups and algebras. I know some Riemannian and pseudo-Riemannian geometry (i.e. general relativity), however I'm not satisfied with my level of understanding. In fact I hope that this new formalism will shed some new light. If anyone can suggest me a good source, I will be indebted. I do realize that there are no perfect books and probably none of them will give me everything that I want. But I though that giving more information will not hurt.","I would like to understand Cartan's formalism of exterior covariant calculus. I think it could be useful for some calculations in physics (But If I am wrong here and it's only good for abstract considerations, please tell me in advance.) I need a reference that explains main ideas (a picture that goes with the formalism) and teaches to apply it and calculate efficiently. It is crucial that it doesn't delve into abstract algebra because I don't have necessary background. I don't mind if it omits more difficult proofs. I want to understand more or less what follows from what, but I don't mind leaving some technicalities to real mathematicians. As for my background: I probably know most of things that are explained in introductory expositions of smooth manifolds (I do know it's a vague statement.) Also some Lie groups and algebras. I know some Riemannian and pseudo-Riemannian geometry (i.e. general relativity), however I'm not satisfied with my level of understanding. In fact I hope that this new formalism will shed some new light. If anyone can suggest me a good source, I will be indebted. I do realize that there are no perfect books and probably none of them will give me everything that I want. But I though that giving more information will not hurt.",,"['differential-geometry', 'reference-request', 'exterior-algebra', 'connections']"
50,"How do I express this vector field, given ""in terms of $\mathbb{C}$"", in the standard notation for derivations?","How do I express this vector field, given ""in terms of "", in the standard notation for derivations?",\mathbb{C},"In a set of lecture notes (not available online) that I'm currently working through, one is given the following set-up: Consider rotational vector fields on the plane       $\mathbb{R}^{2}\cong\mathbb{C}$ with coordinates $(x,y)\cong     z=x+\imath y$.  Let $X$ be the vector field given by $X(z)=\imath     z=-y+\imath x\in\mathbb{C}\cong T_{z}\mathbb{C}$, i.e.        $X(x,y)=-y\partial_{x}+x\partial_{y}$. This is all fine by me, but there is one thing that I don't understand: How do I express $X(z)$ in terms of the standard notation for tangent vectors (i.e. I'm looking for the complex equivalent of $X(x,y)=-y\partial_x+x\partial_y$). There are two approaches that seem sensible, but they give irreconcilable results---at least so it seems: Use $z=x+\imath y$ and $\partial_z=\frac{1}{2}(\partial_x-\imath\partial_y)$ and directly ""translate"" the expression in real coordinates. This yields [algebra corrected in edit] $$X(z)=\imath\frac{z-\bar z}{2}(\partial_z+\partial_{\bar z}) +\imath\frac{z+\bar z}{2}(\partial_z-\partial_{\bar z}) =\imath (z\partial_z -\bar z\partial_{\bar z}) $$ Assume that the isomorphism $\mathbb C\cong T_z\mathbb C $ identifies $X(z)\in \mathbb{C}$ with $X(z)\partial_z+0\cdot\partial_{\bar z}$ so that we obtain  $$ X(z)=\imath z \partial_z $$ But when ""translating back"" to real variables one then obtains $$ X(z)=\frac{1}{2}\imath(x+\imath y)(\partial_x-\imath \partial_y) =\frac{1}{2}\Big((\imath x-y)\partial_x+(x+\imath y)\partial_y\Big)$$ At first sight, it seems reasonable to simply say that the second method is based on a wrong assumption, and to simply dismiss it (even though I don't know why it's wrong). However, continuing in the lecture notes I find Its trajectories are given       by $c_{z}(t)=e^{\imath t}z$.  Indeed, $\dot{c}_{z}(t)=\imath     e^{\imath t}z=\imath c_{z}(t)$. Assuming the first approach is correct we indeed obtain something different: It seems like the ""translation"" to the tangent space notation was not only useless (since the solution simply seems to solve the equation $c'(t)=\imath c$ with initial condition $c(0)=z$) but leads to the wrong solution! Of course, the second approach here does give the correct result... My question is therefore twofold: What does the vector field $X$ correspond to in terms of the notation for derivations of smooth functions on $\mathbb C$, and is this at all relevant for finding its integral curves (trajectories)? If the answer to the latter is ""no"", please elaborate! EDIT : After correcting some elementary mistakes pointed out in the answers, some of the confusion is resolved, but part of the question still stands.","In a set of lecture notes (not available online) that I'm currently working through, one is given the following set-up: Consider rotational vector fields on the plane       $\mathbb{R}^{2}\cong\mathbb{C}$ with coordinates $(x,y)\cong     z=x+\imath y$.  Let $X$ be the vector field given by $X(z)=\imath     z=-y+\imath x\in\mathbb{C}\cong T_{z}\mathbb{C}$, i.e.        $X(x,y)=-y\partial_{x}+x\partial_{y}$. This is all fine by me, but there is one thing that I don't understand: How do I express $X(z)$ in terms of the standard notation for tangent vectors (i.e. I'm looking for the complex equivalent of $X(x,y)=-y\partial_x+x\partial_y$). There are two approaches that seem sensible, but they give irreconcilable results---at least so it seems: Use $z=x+\imath y$ and $\partial_z=\frac{1}{2}(\partial_x-\imath\partial_y)$ and directly ""translate"" the expression in real coordinates. This yields [algebra corrected in edit] $$X(z)=\imath\frac{z-\bar z}{2}(\partial_z+\partial_{\bar z}) +\imath\frac{z+\bar z}{2}(\partial_z-\partial_{\bar z}) =\imath (z\partial_z -\bar z\partial_{\bar z}) $$ Assume that the isomorphism $\mathbb C\cong T_z\mathbb C $ identifies $X(z)\in \mathbb{C}$ with $X(z)\partial_z+0\cdot\partial_{\bar z}$ so that we obtain  $$ X(z)=\imath z \partial_z $$ But when ""translating back"" to real variables one then obtains $$ X(z)=\frac{1}{2}\imath(x+\imath y)(\partial_x-\imath \partial_y) =\frac{1}{2}\Big((\imath x-y)\partial_x+(x+\imath y)\partial_y\Big)$$ At first sight, it seems reasonable to simply say that the second method is based on a wrong assumption, and to simply dismiss it (even though I don't know why it's wrong). However, continuing in the lecture notes I find Its trajectories are given       by $c_{z}(t)=e^{\imath t}z$.  Indeed, $\dot{c}_{z}(t)=\imath     e^{\imath t}z=\imath c_{z}(t)$. Assuming the first approach is correct we indeed obtain something different: It seems like the ""translation"" to the tangent space notation was not only useless (since the solution simply seems to solve the equation $c'(t)=\imath c$ with initial condition $c(0)=z$) but leads to the wrong solution! Of course, the second approach here does give the correct result... My question is therefore twofold: What does the vector field $X$ correspond to in terms of the notation for derivations of smooth functions on $\mathbb C$, and is this at all relevant for finding its integral curves (trajectories)? If the answer to the latter is ""no"", please elaborate! EDIT : After correcting some elementary mistakes pointed out in the answers, some of the confusion is resolved, but part of the question still stands.",,"['differential-geometry', 'complex-geometry']"
51,Affine parameterization of null geodesics,Affine parameterization of null geodesics,,"How does one find an affine parameter for a null geodesic? I found this advice on planetmath.org: Take s as an arbitrary parameter; Set $$u^\mu=\frac{dx^\mu}{ds}$$ Then $$u^\mu \nabla_\mu u^\nu = f(s)u^\nu$$ If the RHS is zero, s is affine; if not, s is not affine. Does this make sense? It strikes me that to find an affine parameter all you need is the equations of the curve $x^\mu (s)$ and their derivatives $u^\mu$. Is this true? I was wondering if we need to know the metric tensor $g$ also? I thought one needs to write the geodesic equation  $$\frac{d^2 x^\mu}{ds^2}+\Gamma^\mu_{\nu \sigma}\frac{dx^\nu}{ds}\frac{dx^\sigma}{ds}=0$$ and check if its RHS is zero or not. But then we also need to know the $\Gamma$s or we need to know the metric tensor $g$ if we rewrite the above geodesic equation in terms of $g$ instead of $\Gamma$s.","How does one find an affine parameter for a null geodesic? I found this advice on planetmath.org: Take s as an arbitrary parameter; Set $$u^\mu=\frac{dx^\mu}{ds}$$ Then $$u^\mu \nabla_\mu u^\nu = f(s)u^\nu$$ If the RHS is zero, s is affine; if not, s is not affine. Does this make sense? It strikes me that to find an affine parameter all you need is the equations of the curve $x^\mu (s)$ and their derivatives $u^\mu$. Is this true? I was wondering if we need to know the metric tensor $g$ also? I thought one needs to write the geodesic equation  $$\frac{d^2 x^\mu}{ds^2}+\Gamma^\mu_{\nu \sigma}\frac{dx^\nu}{ds}\frac{dx^\sigma}{ds}=0$$ and check if its RHS is zero or not. But then we also need to know the $\Gamma$s or we need to know the metric tensor $g$ if we rewrite the above geodesic equation in terms of $g$ instead of $\Gamma$s.",,"['differential-geometry', 'geodesic', 'semi-riemannian-geometry']"
52,Connections on principal bundles: Local and Global Formulations.,Connections on principal bundles: Local and Global Formulations.,,"The standard definition of a connection on a principal $G$-bundle $\pi : P \to X$ is a smooth family of subspaces $H_{p}$ of $T_p P$ such that for every $p \in X$ we have a splitting of vector spaces $T_p P = H_p \oplus \mathrm{ker} (\pi_{*})_{p}$ and so that $H_{p g} = (R_{g})_{*} H_{p}$, where $R_g$ is the right action of $G$ on $P$. Equivalently, this is the same as specifying, for every $p \in X$, a right inverse $q_p : T_{\pi(p)} X \to T_p P$ for $(\pi_{*})_p$, or a left inverse $\theta_{p}: T_p P \to \mathrm{ker} (\pi_{*})_{p}$ for the inclusion, by standard theory for exact sequences of vector spaces. All of the above works `fibrewisely'; I would like to know what the global picture is: When will the pullback bundle $\pi^{*}(TX)$ and the kernel $T_V P$ of $\pi_{*}$ be subbundles of $TP$, so that we may write $TP  = T_{V}P \oplus \pi^{*}(TX) $, where this splitting is $G$-invariant? Will this only occur if we can find a $G$-invariant right bundle-morphism inverse for $\pi_{*}$, or a $G$-invariant left bundle-morphism inverse for the inclusion of $T_V P$? More generally, the transition between the local and fibrewise pictures in the category of vector bundles over smooth manifolds is unclear to me, in particular the theory for short exact sequences - is there some standard reference that explains this in detail?","The standard definition of a connection on a principal $G$-bundle $\pi : P \to X$ is a smooth family of subspaces $H_{p}$ of $T_p P$ such that for every $p \in X$ we have a splitting of vector spaces $T_p P = H_p \oplus \mathrm{ker} (\pi_{*})_{p}$ and so that $H_{p g} = (R_{g})_{*} H_{p}$, where $R_g$ is the right action of $G$ on $P$. Equivalently, this is the same as specifying, for every $p \in X$, a right inverse $q_p : T_{\pi(p)} X \to T_p P$ for $(\pi_{*})_p$, or a left inverse $\theta_{p}: T_p P \to \mathrm{ker} (\pi_{*})_{p}$ for the inclusion, by standard theory for exact sequences of vector spaces. All of the above works `fibrewisely'; I would like to know what the global picture is: When will the pullback bundle $\pi^{*}(TX)$ and the kernel $T_V P$ of $\pi_{*}$ be subbundles of $TP$, so that we may write $TP  = T_{V}P \oplus \pi^{*}(TX) $, where this splitting is $G$-invariant? Will this only occur if we can find a $G$-invariant right bundle-morphism inverse for $\pi_{*}$, or a $G$-invariant left bundle-morphism inverse for the inclusion of $T_V P$? More generally, the transition between the local and fibrewise pictures in the category of vector bundles over smooth manifolds is unclear to me, in particular the theory for short exact sequences - is there some standard reference that explains this in detail?",,"['differential-geometry', 'vector-bundles', 'exact-sequence', 'connections', 'principal-bundles']"
53,Why $\dfrac{\partial \sigma}{\partial u}=\dfrac{\partial \sigma}{\partial \bar{u}}$?,Why ?,\dfrac{\partial \sigma}{\partial u}=\dfrac{\partial \sigma}{\partial \bar{u}},"According to Elementary Differential Geometry by A N Pressley: $\Large\textbf{5.3. Conformal Mappings of Surfaces}$ Now that we understand how to measure lengths of curves on surfaces, it is natural to ask about angles. Suppose that two curves $\boldsymbol{\gamma}$ and $\boldsymbol{\tilde\gamma}$ on a surface $\cal S$ intersect at a point $P$ that lies in a surface patch $\boldsymbol{\sigma}$ of $\cal S$. Then, $\boldsymbol\gamma(t)=\boldsymbol\sigma(u(t),v(t))$ and $\boldsymbol{\tilde\gamma}(t)=\boldsymbol\sigma(\tilde u(t),\tilde v(t))$ for some smooth function $u,v,\tilde u$ and $\tilde v$, and for some parameter values $t_0$ and $\tilde {t_0}$, we have $\boldsymbol\sigma(u(t_0),v(t_0))$ $=$ $P$ $=$ $\boldsymbol\sigma(\tilde u(\tilde{t_0}),\tilde v(t_0))$. The angle $\theta$ of intersection of $\boldsymbol{\gamma}$ and $\boldsymbol{\tilde\gamma}$ at $P$ is defined to be the angle between the tangent vectors $\dot{\boldsymbol{\gamma}}$ and $\dot{\boldsymbol{\tilde\gamma}}$ (evaluated at $t\mathop =t_0$ and $t\mathop=\tilde{t_0}$, respectively). Using the dot product formula for the angle between vectors, we see that $\theta$ is given by $$\cos\theta=\frac{\dot{\boldsymbol{\gamma}}\cdot\dot{\boldsymbol{\tilde\gamma}}}{\|\dot{\boldsymbol{\gamma}}\|\|\dot{\boldsymbol{\tilde\gamma}}\|}.$$ By the chain rule, $$\dot{\boldsymbol{\gamma}}=\boldsymbol\sigma_u\dot{u}+\boldsymbol\sigma_v\dot{v},\quad\dot{\boldsymbol{\tilde\gamma}}=\boldsymbol\sigma_u\dot{\tilde u}+\boldsymbol\sigma_v\dot{\tilde v},$$ so $$\begin{align}\dot{\boldsymbol{\gamma}}\cdot\dot{\boldsymbol{\tilde\gamma}}&=(\boldsymbol\sigma_u\dot{u}+\boldsymbol\sigma_v\dot{v})\cdot(\boldsymbol\sigma_u\dot{\tilde u}+\boldsymbol\sigma_v\dot{\tilde v})\\&=(\boldsymbol\sigma_u\cdot\boldsymbol\sigma_u)\dot{u}\dot{\tilde u}+(\boldsymbol\sigma_u\cdot\boldsymbol\sigma_v)(\dot{u}\dot{\tilde v}+\dot{\tilde u}\dot{v})+(\boldsymbol\sigma_v\cdot\boldsymbol\sigma_v)\dot{v}\dot{\tilde v}\\&=E\dot{u}\dot{\tilde u}+F(\dot{u}\dot{\tilde v}+\dot{\tilde u}\dot{v})+G\dot{v}\dot{\tilde v}.\end{align}$$ Replacing $\boldsymbol{\tilde\gamma}$ by $\boldsymbol\gamma$ (resp. $\boldsymbol\gamma$ by $\boldsymbol{\tilde\gamma}$) gives similar expressions for $\|\dot{\boldsymbol{\gamma}}\|^2=\dot{\boldsymbol{\gamma}}\cdot\dot{\boldsymbol{\gamma}}$ (resp. $\|\dot{\boldsymbol{\tilde\gamma}}\|^2$), which finally give the formula $$\cos\theta=\frac{E\dot{u}\dot{\tilde u}+F(\dot{u}\dot{\tilde v}+\dot{\tilde u}\dot{v})+G\dot{v}\dot{\tilde v}}{(E\dot{u}^2+2F\dot{u}\dot{v}+G\dot{v}^2)^{1/2}(E\dot{\tilde u}^2+2F\dot{\tilde u}\dot{\tilde v}+G\dot{\tilde v}^2)^{1/2}}.\tag5$$ (${\bf \sigma}_u=:\dfrac{\partial \sigma}{\partial u}$). The above text several times assuming that $\dfrac{\partial \sigma}{\partial u}=\dfrac{\partial \sigma}{\partial \bar{u}}$ and $\dfrac{\partial \sigma}{\partial v}=\dfrac{\partial \sigma}{\partial \bar{v}}$. Why these assumptions are correct?","According to Elementary Differential Geometry by A N Pressley: $\Large\textbf{5.3. Conformal Mappings of Surfaces}$ Now that we understand how to measure lengths of curves on surfaces, it is natural to ask about angles. Suppose that two curves $\boldsymbol{\gamma}$ and $\boldsymbol{\tilde\gamma}$ on a surface $\cal S$ intersect at a point $P$ that lies in a surface patch $\boldsymbol{\sigma}$ of $\cal S$. Then, $\boldsymbol\gamma(t)=\boldsymbol\sigma(u(t),v(t))$ and $\boldsymbol{\tilde\gamma}(t)=\boldsymbol\sigma(\tilde u(t),\tilde v(t))$ for some smooth function $u,v,\tilde u$ and $\tilde v$, and for some parameter values $t_0$ and $\tilde {t_0}$, we have $\boldsymbol\sigma(u(t_0),v(t_0))$ $=$ $P$ $=$ $\boldsymbol\sigma(\tilde u(\tilde{t_0}),\tilde v(t_0))$. The angle $\theta$ of intersection of $\boldsymbol{\gamma}$ and $\boldsymbol{\tilde\gamma}$ at $P$ is defined to be the angle between the tangent vectors $\dot{\boldsymbol{\gamma}}$ and $\dot{\boldsymbol{\tilde\gamma}}$ (evaluated at $t\mathop =t_0$ and $t\mathop=\tilde{t_0}$, respectively). Using the dot product formula for the angle between vectors, we see that $\theta$ is given by $$\cos\theta=\frac{\dot{\boldsymbol{\gamma}}\cdot\dot{\boldsymbol{\tilde\gamma}}}{\|\dot{\boldsymbol{\gamma}}\|\|\dot{\boldsymbol{\tilde\gamma}}\|}.$$ By the chain rule, $$\dot{\boldsymbol{\gamma}}=\boldsymbol\sigma_u\dot{u}+\boldsymbol\sigma_v\dot{v},\quad\dot{\boldsymbol{\tilde\gamma}}=\boldsymbol\sigma_u\dot{\tilde u}+\boldsymbol\sigma_v\dot{\tilde v},$$ so $$\begin{align}\dot{\boldsymbol{\gamma}}\cdot\dot{\boldsymbol{\tilde\gamma}}&=(\boldsymbol\sigma_u\dot{u}+\boldsymbol\sigma_v\dot{v})\cdot(\boldsymbol\sigma_u\dot{\tilde u}+\boldsymbol\sigma_v\dot{\tilde v})\\&=(\boldsymbol\sigma_u\cdot\boldsymbol\sigma_u)\dot{u}\dot{\tilde u}+(\boldsymbol\sigma_u\cdot\boldsymbol\sigma_v)(\dot{u}\dot{\tilde v}+\dot{\tilde u}\dot{v})+(\boldsymbol\sigma_v\cdot\boldsymbol\sigma_v)\dot{v}\dot{\tilde v}\\&=E\dot{u}\dot{\tilde u}+F(\dot{u}\dot{\tilde v}+\dot{\tilde u}\dot{v})+G\dot{v}\dot{\tilde v}.\end{align}$$ Replacing $\boldsymbol{\tilde\gamma}$ by $\boldsymbol\gamma$ (resp. $\boldsymbol\gamma$ by $\boldsymbol{\tilde\gamma}$) gives similar expressions for $\|\dot{\boldsymbol{\gamma}}\|^2=\dot{\boldsymbol{\gamma}}\cdot\dot{\boldsymbol{\gamma}}$ (resp. $\|\dot{\boldsymbol{\tilde\gamma}}\|^2$), which finally give the formula $$\cos\theta=\frac{E\dot{u}\dot{\tilde u}+F(\dot{u}\dot{\tilde v}+\dot{\tilde u}\dot{v})+G\dot{v}\dot{\tilde v}}{(E\dot{u}^2+2F\dot{u}\dot{v}+G\dot{v}^2)^{1/2}(E\dot{\tilde u}^2+2F\dot{\tilde u}\dot{\tilde v}+G\dot{\tilde v}^2)^{1/2}}.\tag5$$ (${\bf \sigma}_u=:\dfrac{\partial \sigma}{\partial u}$). The above text several times assuming that $\dfrac{\partial \sigma}{\partial u}=\dfrac{\partial \sigma}{\partial \bar{u}}$ and $\dfrac{\partial \sigma}{\partial v}=\dfrac{\partial \sigma}{\partial \bar{v}}$. Why these assumptions are correct?",,['differential-geometry']
54,Diffeomorphism between $\Bbb{R}^{4}$ and the cube,Diffeomorphism between  and the cube,\Bbb{R}^{4},"I'm looking for an explicit diffeomorphism between the four-dimensional euclidean space $\Bbb{R}^{4}$ and the four-dimensional open cube. I wonder whether there is a simple looking map, with simple looking derivatives (I need to induce a metric on the cube from the space, and I'd prefer it didn't look terribly complicated at the end). Is anybody able to help me with this?","I'm looking for an explicit diffeomorphism between the four-dimensional euclidean space $\Bbb{R}^{4}$ and the four-dimensional open cube. I wonder whether there is a simple looking map, with simple looking derivatives (I need to induce a metric on the cube from the space, and I'd prefer it didn't look terribly complicated at the end). Is anybody able to help me with this?",,"['differential-geometry', 'differential-topology', 'riemannian-geometry']"
55,"What is meant by a ""curvature-line parametrization"" of a surface?","What is meant by a ""curvature-line parametrization"" of a surface?",,"Could anyone explain to me what it means if a surface is curvature-line parametrized ? What does it mean intuitively and how exactly is it different from any other parametrization? I've been looking for the answer to this question for quite some time, but can't seem to find and understand it.","Could anyone explain to me what it means if a surface is curvature-line parametrized ? What does it mean intuitively and how exactly is it different from any other parametrization? I've been looking for the answer to this question for quite some time, but can't seem to find and understand it.",,"['differential-geometry', 'curvature']"
56,"Connection between harmonic functions, Bochner Laplacian and Ricci curvature","Connection between harmonic functions, Bochner Laplacian and Ricci curvature",,"I stumbled upon the following claim in a paper: ""We write the (Bochner) Laplacian in suffix notation : $\Delta_B = \nabla ^k \nabla_k$"". after this statement, the following is written: ($M$ is a riemannian manifold, $w:M\rightarrow \mathbb{R}$) $\Delta_Bw=0 \stackrel{(*)}{\Rightarrow} \Delta_Bd_iw \stackrel{(1)}{=} \nabla^k\nabla_i d_kw \stackrel{(2)}{=} (Ric)_i^kd_kw$ where $Ric$ is the Ricci Curvature. (note that the Ricci Curvature is (2,0)-tensor and the notation used here is of (1,1)-tensor, but this is not rellay important, since via the metric we can raise or lower indices as we wish) My questions: (1) What does $\nabla^k, \nabla_k,d_i$ mean? (I guess $d_iw$ is the derivative of $w$ with respect to the i-th coordinate). The meaning of these notations is not clarified in the paper. I think there must be only one answer to that based on equality (2). (2) Why the above equalities ((1),(2)) hold? In particular I do not understand the implication $\stackrel{(*)}{\Rightarrow}$. (This index notation reminds me of taking trace, and I know that by definition $\Delta_B = \nabla ^* \nabla$ where $\nabla$ is a connection on the relevant bundle (here the trivial line bundle over $M$) and $\nabla^*$ is its formal adjoint etc..... but I am still confused about the indices notation)","I stumbled upon the following claim in a paper: ""We write the (Bochner) Laplacian in suffix notation : $\Delta_B = \nabla ^k \nabla_k$"". after this statement, the following is written: ($M$ is a riemannian manifold, $w:M\rightarrow \mathbb{R}$) $\Delta_Bw=0 \stackrel{(*)}{\Rightarrow} \Delta_Bd_iw \stackrel{(1)}{=} \nabla^k\nabla_i d_kw \stackrel{(2)}{=} (Ric)_i^kd_kw$ where $Ric$ is the Ricci Curvature. (note that the Ricci Curvature is (2,0)-tensor and the notation used here is of (1,1)-tensor, but this is not rellay important, since via the metric we can raise or lower indices as we wish) My questions: (1) What does $\nabla^k, \nabla_k,d_i$ mean? (I guess $d_iw$ is the derivative of $w$ with respect to the i-th coordinate). The meaning of these notations is not clarified in the paper. I think there must be only one answer to that based on equality (2). (2) Why the above equalities ((1),(2)) hold? In particular I do not understand the implication $\stackrel{(*)}{\Rightarrow}$. (This index notation reminds me of taking trace, and I know that by definition $\Delta_B = \nabla ^* \nabla$ where $\nabla$ is a connection on the relevant bundle (here the trivial line bundle over $M$) and $\nabla^*$ is its formal adjoint etc..... but I am still confused about the indices notation)",,"['differential-geometry', 'riemannian-geometry']"
57,Metric on Homogeneous Space $G/H$,Metric on Homogeneous Space,G/H,"For simplicity, assume $G$ is compact and semi-simple Lie group, and $H$ is a closed subgroup of $G$. Therefore the homogeneous space is reductvie, say $\mathfrak{g}=\mathfrak{h}+\mathfrak{m}$ where $\mathfrak{g}$, $\mathfrak{h}$ and $\mathfrak{m}$ are Lie algebra of $G$, $H$, and complimentary space to $H$. I know there is a fundamental theorem on the metric $\gamma$ of $G/H$ that “there is a one-to-one correspondence between the $G$-invariant metric $\gamma$ on $G/H$ and the ${\rm ad}_\mathfrak{h}$-invariant inner product $\eta$ on $\mathfrak{m}$”. For semi-simple and compact Lie group, one can always find negative definite Killing form $K$ on $\mathfrak{g}$, which is apparently ${\rm ad}_\mathfrak{h}$-invariant. My question is that, given the Killing form $K$, how many $\mathfrak{m}$ compliment to $\mathfrak{h}$ one can choose, so that $\mathfrak{m}$ is ${\rm ad}_\mathfrak{h}$ invariant. I know that for example one can choose the orthogonal $\mathfrak{m}=\mathfrak{h}^\perp$ by Killing form $K$. Is there any options and if so is there any relation among those metric $\gamma$ or $\eta$ induced by the same Killing form $K$ Thanks very much","For simplicity, assume $G$ is compact and semi-simple Lie group, and $H$ is a closed subgroup of $G$. Therefore the homogeneous space is reductvie, say $\mathfrak{g}=\mathfrak{h}+\mathfrak{m}$ where $\mathfrak{g}$, $\mathfrak{h}$ and $\mathfrak{m}$ are Lie algebra of $G$, $H$, and complimentary space to $H$. I know there is a fundamental theorem on the metric $\gamma$ of $G/H$ that “there is a one-to-one correspondence between the $G$-invariant metric $\gamma$ on $G/H$ and the ${\rm ad}_\mathfrak{h}$-invariant inner product $\eta$ on $\mathfrak{m}$”. For semi-simple and compact Lie group, one can always find negative definite Killing form $K$ on $\mathfrak{g}$, which is apparently ${\rm ad}_\mathfrak{h}$-invariant. My question is that, given the Killing form $K$, how many $\mathfrak{m}$ compliment to $\mathfrak{h}$ one can choose, so that $\mathfrak{m}$ is ${\rm ad}_\mathfrak{h}$ invariant. I know that for example one can choose the orthogonal $\mathfrak{m}=\mathfrak{h}^\perp$ by Killing form $K$. Is there any options and if so is there any relation among those metric $\gamma$ or $\eta$ induced by the same Killing form $K$ Thanks very much",,"['differential-geometry', 'metric-spaces', 'riemannian-geometry', 'vector-bundles', 'homogeneous-spaces']"
58,Ricci flow on surfaces : step in proof,Ricci flow on surfaces : step in proof,,I am trying to realize the paper of richard hamilton's ricci flow on surfaces from the book of benett chow's Ricci flow : An Introduction.Here Hamilton denoted the trace free part of the Hessian of the potential $f$ of the curvature by $$\ M = \nabla \nabla f - \frac 12 \Delta f . g $$ Next taking divergence of $M$ we have $$(div M)_i = \nabla ^j M_{ji}=\nabla _j\nabla_i\nabla^jf-\frac 12 \nabla_i\nabla_j\nabla^jf=R_{ik}\nabla^kf+\frac 12\nabla_i\Delta f=\frac 12(R\nabla_if+\nabla_iR)$$....But in this calculation I can not find what the term $\nabla^j$ means.$\nabla_j$ is covariant derivative...But what about $\nabla^j$...Please anyone help me to understand the calculations...one more here $R_{ik}=\frac R2 g_{ik}$...,I am trying to realize the paper of richard hamilton's ricci flow on surfaces from the book of benett chow's Ricci flow : An Introduction.Here Hamilton denoted the trace free part of the Hessian of the potential $f$ of the curvature by $$\ M = \nabla \nabla f - \frac 12 \Delta f . g $$ Next taking divergence of $M$ we have $$(div M)_i = \nabla ^j M_{ji}=\nabla _j\nabla_i\nabla^jf-\frac 12 \nabla_i\nabla_j\nabla^jf=R_{ik}\nabla^kf+\frac 12\nabla_i\Delta f=\frac 12(R\nabla_if+\nabla_iR)$$....But in this calculation I can not find what the term $\nabla^j$ means.$\nabla_j$ is covariant derivative...But what about $\nabla^j$...Please anyone help me to understand the calculations...one more here $R_{ik}=\frac R2 g_{ik}$...,,"['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
59,Find a surface that has positive constant curvature that is not open subset of sphere,Find a surface that has positive constant curvature that is not open subset of sphere,,Can some one find a surface that has positive constant curvature that is not open subset of sphere. I know every connected and compact surface with positive constant curvature is sphere. I need some hint. Thanks a lot indeed,Can some one find a surface that has positive constant curvature that is not open subset of sphere. I know every connected and compact surface with positive constant curvature is sphere. I need some hint. Thanks a lot indeed,,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'smooth-manifolds']"
60,Points of $4$-contact of an ellipse and a circle,Points of -contact of an ellipse and a circle,4,"Consider an ellipse $x^2 + 4y^2 = 4$ given in parametrised form $(2 \cos t, \sin t)$. At a given point $p_0 = (2 \cos t_0, \sin t_0)$ we want to measure how round the ellipse is (i.e. how similar to a circle it is). To do this, let $C(x,y) = (x-a)^2 + (y-b)^2 - \lambda$ be a circle with centre $(a,b)$. If this circle goes through the point $p_0$ then $$ (2\cos t_0 - a)^2 + (\sin t_0 - b)^2 -\lambda = 0 = g(t_0)$$ A point of $k$ contact between this circle and ellipse is any point for which the first $k-1$ derivatives $g^{(i)}$ vanish and $g^{(k)} \neq 0$. For this example there are only four points for which we can have $4$-point contact. The centres of the corresponding circles are: $(\pm {3 \over 2}, 0), (0, \pm 3)$. My question is: Why are these the only points where $4$-point contact   is possible? Ideally, I would like to gain geometric insight from any answer, if possible. It is clear to me that $3$-point contact is possible at every point on the ellipse.","Consider an ellipse $x^2 + 4y^2 = 4$ given in parametrised form $(2 \cos t, \sin t)$. At a given point $p_0 = (2 \cos t_0, \sin t_0)$ we want to measure how round the ellipse is (i.e. how similar to a circle it is). To do this, let $C(x,y) = (x-a)^2 + (y-b)^2 - \lambda$ be a circle with centre $(a,b)$. If this circle goes through the point $p_0$ then $$ (2\cos t_0 - a)^2 + (\sin t_0 - b)^2 -\lambda = 0 = g(t_0)$$ A point of $k$ contact between this circle and ellipse is any point for which the first $k-1$ derivatives $g^{(i)}$ vanish and $g^{(k)} \neq 0$. For this example there are only four points for which we can have $4$-point contact. The centres of the corresponding circles are: $(\pm {3 \over 2}, 0), (0, \pm 3)$. My question is: Why are these the only points where $4$-point contact   is possible? Ideally, I would like to gain geometric insight from any answer, if possible. It is clear to me that $3$-point contact is possible at every point on the ellipse.",,['differential-geometry']
61,Connectedness of level sets,Connectedness of level sets,,"I have a $C^{1}$ real valued function $f$ defined on a connected manifold $M$, it doesn't have critical points, lets assume that $f^{-1}(0)$ is a (compact) connected submanifold of $M$, does that imply that every level set will be connected?","I have a $C^{1}$ real valued function $f$ defined on a connected manifold $M$, it doesn't have critical points, lets assume that $f^{-1}(0)$ is a (compact) connected submanifold of $M$, does that imply that every level set will be connected?",,['differential-geometry']
62,Ambiguity in definition of $C^r$ maps between manifolds,Ambiguity in definition of  maps between manifolds,C^r,"Let $M$ and $N$ be smooth manifolds with corresponding maximal atlases $A_M$ and $A_N$. We say that a map $f : M \to N$ is of class $C^r$   (or $r$-times continuously differentiable) at $p \in M$ if there exists a chart   $(V, y)$ from $A_N$ with $f(p) \in V$, and a chart $(U, x)$ from $A_M$ with $p \in U$, such that $f (U) \subset V$ and $y\circ f \circ x^{-1}$ is of class $C^r$. The above appears ambiguous to me. What if there are two other charts $(U',x')$ and $(V',y')$ with $p \in U'$ and $f(U') \subset V'$ but $y'\circ f \circ x'^{-1}$ not of class $C^r$? Will $f$ still be of class $C^r$ at $p$?","Let $M$ and $N$ be smooth manifolds with corresponding maximal atlases $A_M$ and $A_N$. We say that a map $f : M \to N$ is of class $C^r$   (or $r$-times continuously differentiable) at $p \in M$ if there exists a chart   $(V, y)$ from $A_N$ with $f(p) \in V$, and a chart $(U, x)$ from $A_M$ with $p \in U$, such that $f (U) \subset V$ and $y\circ f \circ x^{-1}$ is of class $C^r$. The above appears ambiguous to me. What if there are two other charts $(U',x')$ and $(V',y')$ with $p \in U'$ and $f(U') \subset V'$ but $y'\circ f \circ x'^{-1}$ not of class $C^r$? Will $f$ still be of class $C^r$ at $p$?",,"['differential-geometry', 'differential-topology']"
63,Global sections of holomorphic vector bundles,Global sections of holomorphic vector bundles,,"Let $X$ be a complex manifold, and $\mathbb{L}\rightarrow X$ a holomorphic line bundle over $X.$ Can we always find global sections of $\mathbb{L}$? (other from the one that's identically zero) On a real manifold, the answer is of course yes due to the existence of partition of unity. What about an arbitrary holomorphic vector bundle $\mathbb{E}\rightarrow X$ of rank $m$?","Let $X$ be a complex manifold, and $\mathbb{L}\rightarrow X$ a holomorphic line bundle over $X.$ Can we always find global sections of $\mathbb{L}$? (other from the one that's identically zero) On a real manifold, the answer is of course yes due to the existence of partition of unity. What about an arbitrary holomorphic vector bundle $\mathbb{E}\rightarrow X$ of rank $m$?",,"['linear-algebra', 'algebraic-geometry', 'differential-geometry', 'complex-geometry']"
64,What does $[L]=[I]^{-1}[II]$ mean?,What does  mean?,[L]=[I]^{-1}[II],"I have a question about one of the equations in my notes. Matrix representations of Weingarton map, first fundamental form and second fundamental form satisfies $[L]=[I]^{-1}[II]$ According to my understanding, $[II]$ is really the matrix representation of a bilinear map from $T_pM\times T_pM \to R$. And so is $[I]$, so $[I]^{-1}$ represents a map from $R \to T_pM \times T_pM$? But then $L$ is a map that takes in one vector, and outputs anothe vector. So the left hand side and the right hand side doesn't seem to be the same thing at all. Not sure if I'm confusing myself. Any idea?","I have a question about one of the equations in my notes. Matrix representations of Weingarton map, first fundamental form and second fundamental form satisfies $[L]=[I]^{-1}[II]$ According to my understanding, $[II]$ is really the matrix representation of a bilinear map from $T_pM\times T_pM \to R$. And so is $[I]$, so $[I]^{-1}$ represents a map from $R \to T_pM \times T_pM$? But then $L$ is a map that takes in one vector, and outputs anothe vector. So the left hand side and the right hand side doesn't seem to be the same thing at all. Not sure if I'm confusing myself. Any idea?",,"['linear-algebra', 'differential-geometry', 'bilinear-form']"
65,Exterior derivatives involving representations,Exterior derivatives involving representations,,"I have two questions regarding the exterior derivative of vector valued forms when representations are involved: Suppose $V$ is a vector space, $M$ a smooth manifold and $\omega$ is a $V$ valued $k$-form on $M$. Ie, $\omega \in \Omega^k(M;V)$. Suppose furthermore that $\rho_1:G\rightarrow GL(V)$ is a representation for some Lie Group $G$ and $\rho_2:\mathfrak{g}\rightarrow GL(V)$ is the induced Lie algebra representation. The function $\rho_1(g)\circ \omega$ could be considered as a $V$ valued $k$-form on $M$. If $d:\Omega^k(M;V)\rightarrow \Omega^{k+1}(M;V)$ is the exterior derivative for $V$ valued $k$-forms, then $d(\rho(g)\circ \omega)=\rho(g)\circ d\omega$. I am just wondering why this is true? Furthermore, in some lecture notes I'm reading the author also writes for $\eta\in \Omega^1(M;\mathfrak{g})$ that $d(\rho_2(\eta)\circ \omega)=\rho_2(d\eta)\circ \omega-\rho_2(\eta)\wedge d\omega$ I am completely in the dark as to how this equation makes sense. I don't understand how the RHS is a 2-form or where the RHS even comes from. How would you make sense of this equation?","I have two questions regarding the exterior derivative of vector valued forms when representations are involved: Suppose $V$ is a vector space, $M$ a smooth manifold and $\omega$ is a $V$ valued $k$-form on $M$. Ie, $\omega \in \Omega^k(M;V)$. Suppose furthermore that $\rho_1:G\rightarrow GL(V)$ is a representation for some Lie Group $G$ and $\rho_2:\mathfrak{g}\rightarrow GL(V)$ is the induced Lie algebra representation. The function $\rho_1(g)\circ \omega$ could be considered as a $V$ valued $k$-form on $M$. If $d:\Omega^k(M;V)\rightarrow \Omega^{k+1}(M;V)$ is the exterior derivative for $V$ valued $k$-forms, then $d(\rho(g)\circ \omega)=\rho(g)\circ d\omega$. I am just wondering why this is true? Furthermore, in some lecture notes I'm reading the author also writes for $\eta\in \Omega^1(M;\mathfrak{g})$ that $d(\rho_2(\eta)\circ \omega)=\rho_2(d\eta)\circ \omega-\rho_2(\eta)\wedge d\omega$ I am completely in the dark as to how this equation makes sense. I don't understand how the RHS is a 2-form or where the RHS even comes from. How would you make sense of this equation?",,"['differential-geometry', 'manifolds', 'lie-groups', 'lie-algebras', 'differential-forms']"
66,Calculus on Manifolds/Differential Geometry,Calculus on Manifolds/Differential Geometry,,"I'm trying to understand differential forms. My instructor explained them in terms of operators on vector fields that spit out continuous functions. I was trying to understand the geometric meaning of them but he says in his notes ""take a differential form $\omega$ supported on a compact set $K$"", could someone explain what this means, for example, if I took the differential form, $$\omega = (xy)dx + (z-y)dy + z^2dz$$ could someone the whole ""supported on a compact set"" and the geometric idea here?","I'm trying to understand differential forms. My instructor explained them in terms of operators on vector fields that spit out continuous functions. I was trying to understand the geometric meaning of them but he says in his notes ""take a differential form $\omega$ supported on a compact set $K$"", could someone explain what this means, for example, if I took the differential form, $$\omega = (xy)dx + (z-y)dy + z^2dz$$ could someone the whole ""supported on a compact set"" and the geometric idea here?",,['differential-geometry']
67,Vanishing of the Riemann tensor,Vanishing of the Riemann tensor,,"The Riemann tensor in a coordinate basis is $$R^{i}_{\,jkl} = \partial_k \Gamma^i_{jl} - \partial_l \Gamma^i_{jk} + \Gamma^m_{jl}\Gamma^i_{mk} - \Gamma^m_{jk}\Gamma^i_{ml}$$ Consider $\mathbb{R}^2$ in polar coordinates $(r,\theta)$ with a connection with non vanishing components $\Gamma^r_{\theta \theta} = -r$ and $\Gamma^{\theta}_{\theta r} = r^{-1}$.  SHow the Riemann tensor vanishes. Attempt: It is clear that it vanishes since the Riemann tensor is a measure of the deviation of the curvature of the manifold from Euclidean space.  Since we are dealing with (flat) Euclidean space in two dimensions, the tensor vanishes.  I am just not completely sure of what all these indices mean on the Riemann tensor.  I see it is a $(1,3)$ tensor so I think I can write $R^i_{\,jkl} \equiv R(f^a, e_1, e_2, e_3)$ where the arguments are basis for covectors and vectors defined in tangent spaces and co-tangent spaces. Do the values $\left\{ijkl\right\}$ take on values $r$ and $\theta$? I am just not sure what the indices mean and to show it vanishes I would try to evaluate all possible elements $R^i_{\,jkl}$ and show they all vanish? Many thanks!","The Riemann tensor in a coordinate basis is $$R^{i}_{\,jkl} = \partial_k \Gamma^i_{jl} - \partial_l \Gamma^i_{jk} + \Gamma^m_{jl}\Gamma^i_{mk} - \Gamma^m_{jk}\Gamma^i_{ml}$$ Consider $\mathbb{R}^2$ in polar coordinates $(r,\theta)$ with a connection with non vanishing components $\Gamma^r_{\theta \theta} = -r$ and $\Gamma^{\theta}_{\theta r} = r^{-1}$.  SHow the Riemann tensor vanishes. Attempt: It is clear that it vanishes since the Riemann tensor is a measure of the deviation of the curvature of the manifold from Euclidean space.  Since we are dealing with (flat) Euclidean space in two dimensions, the tensor vanishes.  I am just not completely sure of what all these indices mean on the Riemann tensor.  I see it is a $(1,3)$ tensor so I think I can write $R^i_{\,jkl} \equiv R(f^a, e_1, e_2, e_3)$ where the arguments are basis for covectors and vectors defined in tangent spaces and co-tangent spaces. Do the values $\left\{ijkl\right\}$ take on values $r$ and $\theta$? I am just not sure what the indices mean and to show it vanishes I would try to evaluate all possible elements $R^i_{\,jkl}$ and show they all vanish? Many thanks!",,"['differential-geometry', 'riemannian-geometry', 'polar-coordinates', 'curvature', 'connections']"
68,Is there a better way to show the intrinsic curvature of a cylinder is zero?,Is there a better way to show the intrinsic curvature of a cylinder is zero?,,"I am new to differential geometry and Riemannian geometry. I have on two separate occasions (separated by 6 months) encountered exercises where I feel like I am not giving a complete answer. Problem 1: Show that the Gaussian curvature of the surface of a cylinder is zero. Problem 2: Use Cartesian coordinates to write out and solve the geodesic equations for a two-dimensional flat plane and show the solutions are straight lines. In both cases, my argument went something like Define the metric. Show the Christoffel symbols are zero. Use this to show there is no curvature. But I feel like this is just me avoiding the real stuff. In other words, I resort to calculus because I don't actually know what I'm doing. So I make a roundabout argument rather than diving right into the mathematics itself. Is my argument sensible? Is there a more formal way to approach this type of problem? If you could do an example that would be fantastic.","I am new to differential geometry and Riemannian geometry. I have on two separate occasions (separated by 6 months) encountered exercises where I feel like I am not giving a complete answer. Problem 1: Show that the Gaussian curvature of the surface of a cylinder is zero. Problem 2: Use Cartesian coordinates to write out and solve the geodesic equations for a two-dimensional flat plane and show the solutions are straight lines. In both cases, my argument went something like Define the metric. Show the Christoffel symbols are zero. Use this to show there is no curvature. But I feel like this is just me avoiding the real stuff. In other words, I resort to calculus because I don't actually know what I'm doing. So I make a roundabout argument rather than diving right into the mathematics itself. Is my argument sensible? Is there a more formal way to approach this type of problem? If you could do an example that would be fantastic.",,"['differential-geometry', 'riemannian-geometry']"
69,Generators of $H^1(T)$,Generators of,H^1(T),"Let $T$ denote the torus. I am working towards an understanding of de Rham cohomology. I previously worked on finding generators for $H^1(\mathbb R^2 - \{(0,0)\})$ but then realised that for better understanding I had to look at different examples, too. For the purpose of this question I am only interested in finding just one generator, I'll think about finding a second generator later. Can you tell me if this is correct? My work: By definition, $H^1 = {\ker d_2 \over \mathrm{im} d_1}$ where $d_2: \Omega^1 \to \Omega^2$ and $d_1: \Omega^0 \to \Omega^1$ are the exterior derivatives. My goal is to find a differential $1$-form that is closed and not exact, that is, not in the image of $d_1$. My idea is to randomly examine different $1$-forms and verifying their properties, starting with the simplest one that comes to mind: $$ dx + dy$$ Since $$ d(dx + dy) = dx \wedge dy - dx \wedge dy = 0$$ this is a candidate for a generator. The only remaining thing to do is to verify whether this is in the image of $d_1$. If it was in the image of $d_1$, by Stokes' theorem $$ \oint dx + dy$$ would have to vanish as the torus has an empty boundary. I am sure this should not vanish but I'm not sure how to calculate such an integral. One would have to parametrise the torus somehow but this is where stuff gets messy. Is there an easy way to do it? Hence my question: How to calculate $ \oint dx + dy$ on the torus?","Let $T$ denote the torus. I am working towards an understanding of de Rham cohomology. I previously worked on finding generators for $H^1(\mathbb R^2 - \{(0,0)\})$ but then realised that for better understanding I had to look at different examples, too. For the purpose of this question I am only interested in finding just one generator, I'll think about finding a second generator later. Can you tell me if this is correct? My work: By definition, $H^1 = {\ker d_2 \over \mathrm{im} d_1}$ where $d_2: \Omega^1 \to \Omega^2$ and $d_1: \Omega^0 \to \Omega^1$ are the exterior derivatives. My goal is to find a differential $1$-form that is closed and not exact, that is, not in the image of $d_1$. My idea is to randomly examine different $1$-forms and verifying their properties, starting with the simplest one that comes to mind: $$ dx + dy$$ Since $$ d(dx + dy) = dx \wedge dy - dx \wedge dy = 0$$ this is a candidate for a generator. The only remaining thing to do is to verify whether this is in the image of $d_1$. If it was in the image of $d_1$, by Stokes' theorem $$ \oint dx + dy$$ would have to vanish as the torus has an empty boundary. I am sure this should not vanish but I'm not sure how to calculate such an integral. One would have to parametrise the torus somehow but this is where stuff gets messy. Is there an easy way to do it? Hence my question: How to calculate $ \oint dx + dy$ on the torus?",,"['differential-geometry', 'homology-cohomology', 'solution-verification', 'differential-forms']"
70,Geometry of the Covariant Derivative,Geometry of the Covariant Derivative,,"Taking the standard covariant derivative from tensor calculus $ \nabla_{\mu}T_{s} =T_{s|\mu}=T_{s,\mu} $. Could this be geometrically interpreted as the directional derivate of a tensor that has extra terms to compensate for the fact that the manifold in question may not be flat, whereas in the flat case it just generalizes to the regular partial derivate of multivariable calculus?","Taking the standard covariant derivative from tensor calculus $ \nabla_{\mu}T_{s} =T_{s|\mu}=T_{s,\mu} $. Could this be geometrically interpreted as the directional derivate of a tensor that has extra terms to compensate for the fact that the manifold in question may not be flat, whereas in the flat case it just generalizes to the regular partial derivate of multivariable calculus?",,"['differential-geometry', 'tensors']"
71,How to show that geodesics exist for all of time in a compact manifold?,How to show that geodesics exist for all of time in a compact manifold?,,Let $M$ be a compact manifold and the tangent bundle $TM$ have a Riemannian metric $g$ so that it is isomorphic to the cotangent bundle $T^*M$. Consider the pull-back of the canonical symplectic form $\omega_{std}$ to define a symplectic form $\omega_g$ on $TM. $ Assuming the following theorem: The geodesics in $M$ are the images by the standard projection $$\pi: TM \to M$$ of the integral curves of the vector field $X_H$ where $H$ is the norm function squared in TM defined by the metric $g$ I want to show that the geodesics exist for all of time. Please help by giving some ideas!,Let $M$ be a compact manifold and the tangent bundle $TM$ have a Riemannian metric $g$ so that it is isomorphic to the cotangent bundle $T^*M$. Consider the pull-back of the canonical symplectic form $\omega_{std}$ to define a symplectic form $\omega_g$ on $TM. $ Assuming the following theorem: The geodesics in $M$ are the images by the standard projection $$\pi: TM \to M$$ of the integral curves of the vector field $X_H$ where $H$ is the norm function squared in TM defined by the metric $g$ I want to show that the geodesics exist for all of time. Please help by giving some ideas!,,['differential-geometry']
72,Existence of CAT(0)-metrics,Existence of CAT(0)-metrics,,"Given a metrisable, contractible topological space. Under which conditions exists a CAT(0)-metric compatible with the given topology?","Given a metrisable, contractible topological space. Under which conditions exists a CAT(0)-metric compatible with the given topology?",,"['differential-geometry', 'metric-spaces', 'geometric-topology', 'metric-geometry']"
73,"If $F : M^k \to S^n$ is a smooth map, $M$ compact, $n > k$, then $F$ is homotopic to a constant map","If  is a smooth map,  compact, , then  is homotopic to a constant map",F : M^k \to S^n M n > k F,"Q: Let $M^{k}$ be a smooth compact $k$ -manifold and let $F:M \rightarrow S^{n}$ be a smooth map, where $n>k$ . Prove that $F$ is homotopic to a constant map. Proof: Since $n>k$ , by Sard's theorem, the image of $M$ is nowhere dense, hence not surjective. Pick a point not in the image. Using the Riemann projection, we have a homeomorphism $G$ from $S^{n}-\{x\}$ to $\mathbb{R}$ , which is convex, hence there is a homotopy between $G\circ F$ and the constant map. Composing the homotopy with $G^{-1}$ we have the desired homotopy in $S^{n}$ . Does this look correct?","Q: Let be a smooth compact -manifold and let be a smooth map, where . Prove that is homotopic to a constant map. Proof: Since , by Sard's theorem, the image of is nowhere dense, hence not surjective. Pick a point not in the image. Using the Riemann projection, we have a homeomorphism from to , which is convex, hence there is a homotopy between and the constant map. Composing the homotopy with we have the desired homotopy in . Does this look correct?",M^{k} k F:M \rightarrow S^{n} n>k F n>k M G S^{n}-\{x\} \mathbb{R} G\circ F G^{-1} S^{n},"['proof-verification', 'differential-geometry', 'manifolds', 'smooth-manifolds']"
74,Gaussian Curvature,Gaussian Curvature,,"I am able to show that if a curve lies in a plane then it's curvature at a point $p$ is $$\kappa=\lim_{\mu\to 0}\frac{\sigma}{\mu}$$ where $\mu$ is the length of a segment of the curve containing p, and $\sigma$ is the length of the arc on $S^1$ formed by translating the velocity vectors of this segment to the origin. Analogously, it can be shown that the Gaussian curvature at a point p on a surface, is given by $$\lim_{A\to 0}\frac{A^\prime}{A}$$ where $A$ is the area of a region containing $p$ and $A^\prime$ the area of the corresponding region on $S^2$ under the Gauss map. (Apparently this is how Gauss defined the curvature) We also know that the Gaussian curvature is the product of the principal curvatures. But the principal curvatures are the curvatures of plane curves by definition (curvatures of normal sections). Hence the principal curvatures are given by the first limit above. So I guess this means that $$\lim_{A\to 0}\frac{A^\prime}{A}=\left(\lim_{\mu_1\to 0}\frac{\sigma_1}{\mu_1}\right)\left(\lim_{\mu_2\to 0}\frac{\sigma_2}{\mu_2}\right)$$ where $\mu_1,\mu_2,\sigma_1,\sigma_2$ correspond to the two normal sections. How does this happen? Does this mean that the area $A^\prime$ is equal to the product of the two arc lengths $\sigma_1\sigma_2$? It's definitely not true if the region on the sphere is a cap!","I am able to show that if a curve lies in a plane then it's curvature at a point $p$ is $$\kappa=\lim_{\mu\to 0}\frac{\sigma}{\mu}$$ where $\mu$ is the length of a segment of the curve containing p, and $\sigma$ is the length of the arc on $S^1$ formed by translating the velocity vectors of this segment to the origin. Analogously, it can be shown that the Gaussian curvature at a point p on a surface, is given by $$\lim_{A\to 0}\frac{A^\prime}{A}$$ where $A$ is the area of a region containing $p$ and $A^\prime$ the area of the corresponding region on $S^2$ under the Gauss map. (Apparently this is how Gauss defined the curvature) We also know that the Gaussian curvature is the product of the principal curvatures. But the principal curvatures are the curvatures of plane curves by definition (curvatures of normal sections). Hence the principal curvatures are given by the first limit above. So I guess this means that $$\lim_{A\to 0}\frac{A^\prime}{A}=\left(\lim_{\mu_1\to 0}\frac{\sigma_1}{\mu_1}\right)\left(\lim_{\mu_2\to 0}\frac{\sigma_2}{\mu_2}\right)$$ where $\mu_1,\mu_2,\sigma_1,\sigma_2$ correspond to the two normal sections. How does this happen? Does this mean that the area $A^\prime$ is equal to the product of the two arc lengths $\sigma_1\sigma_2$? It's definitely not true if the region on the sphere is a cap!",,"['differential-geometry', 'curvature']"
75,Euler characteristic of closed surface,Euler characteristic of closed surface,,"Assume that you have a closed surface that can be covered by finitely many triangles. Then $K(p)= 6-val(P)$ where P is a vertex and $val(P)$ the number of edges that lead to this vertex. Now, I am supposed to show that $ \sum_{vertices \ p}K(p) = 6 \chi$ where $\chi$ is the Euler-characteristic of the closed surface. Now I know that this is $6\cdot(2-2g)$, but I just don't see the combinatorial argument, why these two things must be the same. I.e. I don't see how the genus is related to the valence.","Assume that you have a closed surface that can be covered by finitely many triangles. Then $K(p)= 6-val(P)$ where P is a vertex and $val(P)$ the number of edges that lead to this vertex. Now, I am supposed to show that $ \sum_{vertices \ p}K(p) = 6 \chi$ where $\chi$ is the Euler-characteristic of the closed surface. Now I know that this is $6\cdot(2-2g)$, but I just don't see the combinatorial argument, why these two things must be the same. I.e. I don't see how the genus is related to the valence.",,"['general-topology', 'discrete-mathematics']"
76,Complex structure on a real vector bundle,Complex structure on a real vector bundle,,"Let $M$ be a smooth manifold and $\pi:E \rightarrow M$ a real vector bundle and note $E_x:=\pi^{-1}(x), \forall x\in M$. We set a bundle $\text{End}(E)=E\otimes E^*$. Now suppose there exists a smooth section $J:M\rightarrow\text{End}(E)$ such that for all $x\in M$, $J_x^2=-\text{Id}_{E_x}$. This gives imidiately that $E$ is of even rang, say $2m$. Now I want to show that the group structure can be reduced to $\text{GL}(m,\mathbb{C})$. Obviously, we can make $E_x$ a $\mathbb{C}$-vector space by defining $i\cdot v=J_xv$, $\forall v\in E_x$. Via a trivialisation $\chi:\pi^{-1}(U)\rightarrow U\times \mathbb{R}^{2m}$ with $x\in U$ we can make $\{x\}\times\mathbb{R}^{2m}$ a $\mathbb{C}$-vector space by setting $i\cdot (x,v)=(x,\chi\circ J_x\circ\chi^{-1}(x,v))$ and then the trivialisation is actually $\mathbb{C}$-linear on $E_x$ However, this doesn't give a desired reduction of the structure group (I guess) and the problem is because the complex structure of $\mathbb{R}^{2m}$ depends on $x$. If we identify $\mathbb{R}^{2m}$ with $\mathbb{C}^{m}$ via some fixed map $J_0$, then the trivialisation is no longer $\mathbb{C}$-linear. Another approach I tried is to give a smooth family of complex bases for $U\times\mathbb{C}^{m}$ through the trivialisation (it is immediate to find such family of real bases). No luck so far.","Let $M$ be a smooth manifold and $\pi:E \rightarrow M$ a real vector bundle and note $E_x:=\pi^{-1}(x), \forall x\in M$. We set a bundle $\text{End}(E)=E\otimes E^*$. Now suppose there exists a smooth section $J:M\rightarrow\text{End}(E)$ such that for all $x\in M$, $J_x^2=-\text{Id}_{E_x}$. This gives imidiately that $E$ is of even rang, say $2m$. Now I want to show that the group structure can be reduced to $\text{GL}(m,\mathbb{C})$. Obviously, we can make $E_x$ a $\mathbb{C}$-vector space by defining $i\cdot v=J_xv$, $\forall v\in E_x$. Via a trivialisation $\chi:\pi^{-1}(U)\rightarrow U\times \mathbb{R}^{2m}$ with $x\in U$ we can make $\{x\}\times\mathbb{R}^{2m}$ a $\mathbb{C}$-vector space by setting $i\cdot (x,v)=(x,\chi\circ J_x\circ\chi^{-1}(x,v))$ and then the trivialisation is actually $\mathbb{C}$-linear on $E_x$ However, this doesn't give a desired reduction of the structure group (I guess) and the problem is because the complex structure of $\mathbb{R}^{2m}$ depends on $x$. If we identify $\mathbb{R}^{2m}$ with $\mathbb{C}^{m}$ via some fixed map $J_0$, then the trivialisation is no longer $\mathbb{C}$-linear. Another approach I tried is to give a smooth family of complex bases for $U\times\mathbb{C}^{m}$ through the trivialisation (it is immediate to find such family of real bases). No luck so far.",,"['differential-geometry', 'vector-bundles', 'smooth-manifolds']"
77,The properness of a submersion,The properness of a submersion,,"Let $M$ and $N$ be two differential manifolds and there is a surjective submersion $f$ from $M$ to $N$ such that $f^{-1}(p)$ is compact and connected for any $p$ on $N$. Can we conclude that $f$ is proper, that is, the preimage of a compact set is compact? Also posted on https://mathoverflow.net/q/186764/16323","Let $M$ and $N$ be two differential manifolds and there is a surjective submersion $f$ from $M$ to $N$ such that $f^{-1}(p)$ is compact and connected for any $p$ on $N$. Can we conclude that $f$ is proper, that is, the preimage of a compact set is compact? Also posted on https://mathoverflow.net/q/186764/16323",,['differential-geometry']
78,Relationship between divergence operators defined with respect to two different volume forms.,Relationship between divergence operators defined with respect to two different volume forms.,,"Let us assume that you have a volume form $\mu$ defined on a manifold $\mathcal{M}$. Then you can define the divergence operator with respect to this metric, such that the following relationship holds for all $\mathcal{U}\subset \mathcal{M}$ and $v \in T\mathcal{M}$  : $$ \int_{\mathcal{U}}{\operatorname{div} v \ \mu} = \int_{\partial \mathcal{U}}{ \mathbf{i}_v  \mu }$$ Now suppose that you have two distinct non degenerate volume forms $\mu_1$ and $\mu_2$. Then there exists a scalar field $\alpha$ such as $\mu_1 = \alpha \mu_2$. How are related (in terms of $\alpha$) the corresponding divergence operators (let's call them $\operatorname{div}_1$ and $\operatorname{div}_2$) ?","Let us assume that you have a volume form $\mu$ defined on a manifold $\mathcal{M}$. Then you can define the divergence operator with respect to this metric, such that the following relationship holds for all $\mathcal{U}\subset \mathcal{M}$ and $v \in T\mathcal{M}$  : $$ \int_{\mathcal{U}}{\operatorname{div} v \ \mu} = \int_{\partial \mathcal{U}}{ \mathbf{i}_v  \mu }$$ Now suppose that you have two distinct non degenerate volume forms $\mu_1$ and $\mu_2$. Then there exists a scalar field $\alpha$ such as $\mu_1 = \alpha \mu_2$. How are related (in terms of $\alpha$) the corresponding divergence operators (let's call them $\operatorname{div}_1$ and $\operatorname{div}_2$) ?",,"['differential-geometry', 'differential-forms', 'differential-operators']"
79,Number of intersections of two closed loops on a genus zero surface,Number of intersections of two closed loops on a genus zero surface,,"I have stumbled onto the following fact and I am quite helpless in seeing why this is true (although I can agree intuitively). Let $M$ be a surface of genus zero (open or closed, with or without boundary). The claim is now that there can't be two closed, smooth and transversal loops $\alpha, \beta : S^1 \rightarrow M$ with  non-zero intersection number . (One loop is required to be simple closed. I am however not sure if this does really matter.) The intersection number is meant to be the oriented intersection number of transversal loops (cf. chapter 3 of Differential topology by Guillemin and Pollack). It basically adds up the signs of each of the intersections. The sign of an intersection is set to $+1$ if loop $\alpha$ crosses loop $\beta$ from left to right and to $-1$ if $\alpha$ crosses $\beta$ from right to left. Transversality and smoothness of the loops is required to define this intersection number. Intuitively it it clear that I can't draw two closed loops on a genus zero surface where $\alpha$ enters the right side of $\beta$ more often than it enters the left side . Does anyone know about a reference where I can read up on this? Many thanks! :)","I have stumbled onto the following fact and I am quite helpless in seeing why this is true (although I can agree intuitively). Let $M$ be a surface of genus zero (open or closed, with or without boundary). The claim is now that there can't be two closed, smooth and transversal loops $\alpha, \beta : S^1 \rightarrow M$ with  non-zero intersection number . (One loop is required to be simple closed. I am however not sure if this does really matter.) The intersection number is meant to be the oriented intersection number of transversal loops (cf. chapter 3 of Differential topology by Guillemin and Pollack). It basically adds up the signs of each of the intersections. The sign of an intersection is set to $+1$ if loop $\alpha$ crosses loop $\beta$ from left to right and to $-1$ if $\alpha$ crosses $\beta$ from right to left. Transversality and smoothness of the loops is required to define this intersection number. Intuitively it it clear that I can't draw two closed loops on a genus zero surface where $\alpha$ enters the right side of $\beta$ more often than it enters the left side . Does anyone know about a reference where I can read up on this? Many thanks! :)",,"['general-topology', 'differential-geometry', 'differential-topology', 'surfaces', 'intersection-theory']"
80,relative sign in Hodge star of tensor product,relative sign in Hodge star of tensor product,,"Let $V$ be a vector space of arbitrary (finite) dimension and let $(V, \langle \ ,\ \rangle, I) = (W_1, \langle\ ,\ \rangle_1, I_1) \oplus (W_2, \langle\ ,\ \rangle_2, I_2)$ be a direct sum decomposition, with respect to scalar products and complex structures, where $W_{1,2}$ are even-dimensional. On $\bigwedge^\bullet V^* = \bigwedge^\bullet W_1^* \otimes \bigwedge^\bullet W_2^*$, for $\delta_i \in \bigwedge^{k_i}W_i^*$, $i=1,2$, the Hodge $\star$-operator of $\delta_1 \otimes \delta_2$ is given by $$ \star(\delta_1 \otimes \delta_2)=(-1)^{k_1k_2}(\star_1\delta_1) \otimes(\star_2 \delta_2)$$ We can limit ourselvers here to the vector spaces and their exterior structures, forgetting about continuous dependence on the point in some manifold, etc. (i.e., this should be a linear algebra question); my QUESTION is: where does the $(-1)^{k_1k_2}$sign come from? (This comes from the proof of Proposition 1.2.31 in the book Compelx Geometry:an Introduction , by Huybrechts) I have an IDEA how to do it, using the fact that (with appropriate notation) $$ (\alpha_1 \otimes \alpha_2)\wedge \star(\beta_1 \otimes \beta_2)= (\alpha_1 \wedge \star_1 \beta_1)\otimes (\alpha_2 \wedge \star_2\beta_2)$$ and then plugging in the desired sign when I swap $\star_1\beta_1$ and $\alpha_2$, but I don't understand why, roughly speaking, the tensor behaves like the wedge, i.e. (e.g. for one-forms) $$ (e_1 \otimes f_1) \wedge (e_2 \otimes f_2)= - (e_1 \wedge e_2)\otimes (f_1 \wedge f_2)$$","Let $V$ be a vector space of arbitrary (finite) dimension and let $(V, \langle \ ,\ \rangle, I) = (W_1, \langle\ ,\ \rangle_1, I_1) \oplus (W_2, \langle\ ,\ \rangle_2, I_2)$ be a direct sum decomposition, with respect to scalar products and complex structures, where $W_{1,2}$ are even-dimensional. On $\bigwedge^\bullet V^* = \bigwedge^\bullet W_1^* \otimes \bigwedge^\bullet W_2^*$, for $\delta_i \in \bigwedge^{k_i}W_i^*$, $i=1,2$, the Hodge $\star$-operator of $\delta_1 \otimes \delta_2$ is given by $$ \star(\delta_1 \otimes \delta_2)=(-1)^{k_1k_2}(\star_1\delta_1) \otimes(\star_2 \delta_2)$$ We can limit ourselvers here to the vector spaces and their exterior structures, forgetting about continuous dependence on the point in some manifold, etc. (i.e., this should be a linear algebra question); my QUESTION is: where does the $(-1)^{k_1k_2}$sign come from? (This comes from the proof of Proposition 1.2.31 in the book Compelx Geometry:an Introduction , by Huybrechts) I have an IDEA how to do it, using the fact that (with appropriate notation) $$ (\alpha_1 \otimes \alpha_2)\wedge \star(\beta_1 \otimes \beta_2)= (\alpha_1 \wedge \star_1 \beta_1)\otimes (\alpha_2 \wedge \star_2\beta_2)$$ and then plugging in the desired sign when I swap $\star_1\beta_1$ and $\alpha_2$, but I don't understand why, roughly speaking, the tensor behaves like the wedge, i.e. (e.g. for one-forms) $$ (e_1 \otimes f_1) \wedge (e_2 \otimes f_2)= - (e_1 \wedge e_2)\otimes (f_1 \wedge f_2)$$",,"['linear-algebra', 'differential-geometry', 'riemannian-geometry', 'hodge-theory']"
81,Wedge product and determinants,Wedge product and determinants,,"I am attempting to self-study differential forms this summer, but I ran into this definition for the wedge product in my book, and it doesn't make any sense to me. Note that $\Bbb R^3_p$ is the tangent space of $p$ in $\Bbb R^3$, and $(\Bbb R^3_p)^{\ast}$ is the space of linear functionals from $\Bbb R^3_p \to \Bbb R$. Is the determinant being referred to here the same as the determinant used in linear algebra? If so, isn't it in most cases a multilinear function? I'm sorry if this is unclear, I'm just very lost...","I am attempting to self-study differential forms this summer, but I ran into this definition for the wedge product in my book, and it doesn't make any sense to me. Note that $\Bbb R^3_p$ is the tangent space of $p$ in $\Bbb R^3$, and $(\Bbb R^3_p)^{\ast}$ is the space of linear functionals from $\Bbb R^3_p \to \Bbb R$. Is the determinant being referred to here the same as the determinant used in linear algebra? If so, isn't it in most cases a multilinear function? I'm sorry if this is unclear, I'm just very lost...",,"['linear-algebra', 'differential-geometry', 'manifolds', 'differential-forms']"
82,Proof of the second Bianchi identity,Proof of the second Bianchi identity,,I'm asked to prove the second Bianchi identity: $$\nabla_{[e}R_{ab]c}^{\;\;\;\;d}=0$$ using the fact that: $$(\nabla_a \nabla_b -\nabla_b \nabla_a)\omega_c=R_{abc}^{\;\;\;d}\omega_d$$ For every diff. form $\omega$. I can't. Using that I'm able to reduce the lhs of the identity to: $$2\nabla_{[e}\nabla_a \nabla_{b]}\omega_c$$ But I can't go further.,I'm asked to prove the second Bianchi identity: $$\nabla_{[e}R_{ab]c}^{\;\;\;\;d}=0$$ using the fact that: $$(\nabla_a \nabla_b -\nabla_b \nabla_a)\omega_c=R_{abc}^{\;\;\;d}\omega_d$$ For every diff. form $\omega$. I can't. Using that I'm able to reduce the lhs of the identity to: $$2\nabla_{[e}\nabla_a \nabla_{b]}\omega_c$$ But I can't go further.,,['differential-geometry']
83,Energy-momentum vector is orthogonal to itself,Energy-momentum vector is orthogonal to itself,,"Let the energy-momentum covector $k$ be $k_idx^i$ in Einstein summation notation where $x^0=t$. Let ${}^3k=k_1dx^1+k_2dx^2+k_3dx^3$ be the space part of $k$. Let $Ee^{ik_{\mu}x^{\mu}}$ be the electric field of a plane wave, where $E=E_jdx^j$. The Maxwell equation implies $${}^3k\wedge E=-ik_0 \star_S E.$$ The subscript $S$ means that the Hodge star is only applied in the space part of Minkowski space-time. Now, the exercice in my book asks to show the following: Prove that $k_{\mu}k^{\mu}=0$. This just means that $\langle k,k\rangle =0$. And the Hodge star is also defined in terms of this inner product: $\omega \wedge \star  \mu = \langle \omega, \mu \rangle vol$. So, I tried to take the wedge of the above equation with an appropriate 1-form, but I did not find one that worked. Another possible approach would be to apply $d$ and then take the wedge with something, but I have no intuition in which direction to go. Can someone give me a hint? Of course, a full solution is also appreciated, but I am well capable of doing calculations, so I am mainly interested in seeing what to do and why to do it.","Let the energy-momentum covector $k$ be $k_idx^i$ in Einstein summation notation where $x^0=t$. Let ${}^3k=k_1dx^1+k_2dx^2+k_3dx^3$ be the space part of $k$. Let $Ee^{ik_{\mu}x^{\mu}}$ be the electric field of a plane wave, where $E=E_jdx^j$. The Maxwell equation implies $${}^3k\wedge E=-ik_0 \star_S E.$$ The subscript $S$ means that the Hodge star is only applied in the space part of Minkowski space-time. Now, the exercice in my book asks to show the following: Prove that $k_{\mu}k^{\mu}=0$. This just means that $\langle k,k\rangle =0$. And the Hodge star is also defined in terms of this inner product: $\omega \wedge \star  \mu = \langle \omega, \mu \rangle vol$. So, I tried to take the wedge of the above equation with an appropriate 1-form, but I did not find one that worked. Another possible approach would be to apply $d$ and then take the wedge with something, but I have no intuition in which direction to go. Can someone give me a hint? Of course, a full solution is also appreciated, but I am well capable of doing calculations, so I am mainly interested in seeing what to do and why to do it.",,['differential-geometry']
84,When is the Hessian contracted with a vector field a closed form?,When is the Hessian contracted with a vector field a closed form?,,"Suppose M is a Riemannian manifold and $g, f : M \rightarrow \mathbb{R}$ are smooth functions. When is the $1$-form Hess$^f(\nabla g, -)$ closed? I'm looking for simple conditions involving f,g and possibly the geometry of M. Thank you.","Suppose M is a Riemannian manifold and $g, f : M \rightarrow \mathbb{R}$ are smooth functions. When is the $1$-form Hess$^f(\nabla g, -)$ closed? I'm looking for simple conditions involving f,g and possibly the geometry of M. Thank you.",,"['differential-geometry', 'riemannian-geometry']"
85,Misuse of Tangent Vector,Misuse of Tangent Vector,,"I am quite confused with the term tangent used in differential geometry books. It seems to me that people use this word quite loosely. For example, one definition about tangent space in my book is as follows. The tangent space $T_p(\mathbb R^n)$ at $p\in\mathbb R^n$ is the vector space of all arrows emanating from $p$. If this is the case, then the tangent space at $p$ can be a vector pointing to any direction. However, intuitively a tangent vector is only meaningful with respect to some kind of geometric object such as a surface or curve where the tangent vector at a point is the vector that only touch the surface or curve at point $p$ if it is extended to a plane or line. My question is how to interpret the word tangent in differential geometry. Is it still consistent with the geometric intuition I have from curve and surfaces, please? Thank you!","I am quite confused with the term tangent used in differential geometry books. It seems to me that people use this word quite loosely. For example, one definition about tangent space in my book is as follows. The tangent space $T_p(\mathbb R^n)$ at $p\in\mathbb R^n$ is the vector space of all arrows emanating from $p$. If this is the case, then the tangent space at $p$ can be a vector pointing to any direction. However, intuitively a tangent vector is only meaningful with respect to some kind of geometric object such as a surface or curve where the tangent vector at a point is the vector that only touch the surface or curve at point $p$ if it is extended to a plane or line. My question is how to interpret the word tangent in differential geometry. Is it still consistent with the geometric intuition I have from curve and surfaces, please? Thank you!",,"['differential-geometry', 'self-learning']"
86,Geodesics and Curves on a Plane,Geodesics and Curves on a Plane,,"Show that if a curve $C ⊂ S$ is both a line of curvature and a geodesic, then $C$ is a plane curve. Give an example of a line of curvature which is a plane curve and not a geodesic. (My thoughts: Take a sphere for $S$ and let the curve $C$ be any of the latitudes of $C$ that are not the equator or the poles.  Then $C$ will be a plane curve.  Additionally, since the curvature is constant on the whole of $S$, every direction is a principle direction (of sorts; this might be the flaw in my argument), so any curve is a line of curvature.  But, $C$ is not a segment of a great circle on $S$, so it is not a geodesic.) Prove that a curve $C ⊂ S$ is both an asymptotic curve and a geodesic if and only if $C$ is a (segment of a) straight line. Can I have some hints?  I am not very good at covariant derivatives yet, so hand-holding with detailed examples there would be nice.","Show that if a curve $C ⊂ S$ is both a line of curvature and a geodesic, then $C$ is a plane curve. Give an example of a line of curvature which is a plane curve and not a geodesic. (My thoughts: Take a sphere for $S$ and let the curve $C$ be any of the latitudes of $C$ that are not the equator or the poles.  Then $C$ will be a plane curve.  Additionally, since the curvature is constant on the whole of $S$, every direction is a principle direction (of sorts; this might be the flaw in my argument), so any curve is a line of curvature.  But, $C$ is not a segment of a great circle on $S$, so it is not a geodesic.) Prove that a curve $C ⊂ S$ is both an asymptotic curve and a geodesic if and only if $C$ is a (segment of a) straight line. Can I have some hints?  I am not very good at covariant derivatives yet, so hand-holding with detailed examples there would be nice.",,['differential-geometry']
87,Local Isometry of Sphere,Local Isometry of Sphere,,"How does one show that there exists no neighborhood of a point on a sphere that may be isometrically mapped into a plane?  I understand that I can find the first fundamental form of the sphere $(u, v, \sqrt{r^2 - u^2 - v^2})$, for fixed $a>0$, which is given by: $E = 1 + \frac{u^{2}}{r^2 - u^2 - v^2}$, $F = \frac{u v}{r^2 - u^2 - v^2}$, and $G = 1 + \frac{v^2}{r^2 - u^2 - v^2}$.  Meanwhile, for the plane $(u,v,0)$, the first fundamental form is given by: $E = 1$, $F = 0$, $G = 1$.  Since these first fundamental forms are not equal, the isometry is impossible. But is this enough?  How do I account for the ""neighborhood"" condition? In some sense, this is a follow up question to ones like that which is given here: There is no isometry between a sphere and a plane. , but it is not truly derived therefrom.  The actual problem statement reads, in its entirety as follows: ""Show that no neighborhood of a point on a sphere may be isometrically mapped into a plane""; this claim is made in utter isolation.  In particular, no mention of a metric is made.","How does one show that there exists no neighborhood of a point on a sphere that may be isometrically mapped into a plane?  I understand that I can find the first fundamental form of the sphere $(u, v, \sqrt{r^2 - u^2 - v^2})$, for fixed $a>0$, which is given by: $E = 1 + \frac{u^{2}}{r^2 - u^2 - v^2}$, $F = \frac{u v}{r^2 - u^2 - v^2}$, and $G = 1 + \frac{v^2}{r^2 - u^2 - v^2}$.  Meanwhile, for the plane $(u,v,0)$, the first fundamental form is given by: $E = 1$, $F = 0$, $G = 1$.  Since these first fundamental forms are not equal, the isometry is impossible. But is this enough?  How do I account for the ""neighborhood"" condition? In some sense, this is a follow up question to ones like that which is given here: There is no isometry between a sphere and a plane. , but it is not truly derived therefrom.  The actual problem statement reads, in its entirety as follows: ""Show that no neighborhood of a point on a sphere may be isometrically mapped into a plane""; this claim is made in utter isolation.  In particular, no mention of a metric is made.",,['differential-geometry']
88,Proof two solutions of a differential equation are linear independent,Proof two solutions of a differential equation are linear independent,,"Given two solutions for a second order diferential equation: $y(x)=e^{a x}$ and $y(x)=x e^{a x}$ How to show these are linear independent? I procede as follow applying the definition of linear independence: $A e^{a x} + B x e^{a x} = 0$ $ \forall x$ Then: $A  + B x  = 0$ Here i dont know exactly how to conclude in a ""formal"" way that $A=B=0$ are the only solutions and hence the two functions are linear independent.","Given two solutions for a second order diferential equation: $y(x)=e^{a x}$ and $y(x)=x e^{a x}$ How to show these are linear independent? I procede as follow applying the definition of linear independence: $A e^{a x} + B x e^{a x} = 0$ $ \forall x$ Then: $A  + B x  = 0$ Here i dont know exactly how to conclude in a ""formal"" way that $A=B=0$ are the only solutions and hence the two functions are linear independent.",,"['linear-algebra', 'differential-geometry']"
89,"Why use Gauss and mean curvature to characterize a surface's deviation from being ""flat"" at one point?","Why use Gauss and mean curvature to characterize a surface's deviation from being ""flat"" at one point?",,"We know for a 2-dimensional surface there are two orthogonal principal directions at every point, where the principal curvatures $\kappa_1$ and $\kappa_2$ are the two ends of the curvature spectrum over all directions at that point. Gauss and mean curvatures are defined as $K=\kappa_1\kappa_2$ and $H=(\kappa_1+\kappa_2)/2$ respectively. My question is why we use these two specific combination of principal curvatures to quantify a surface's deviation from being ""flat"" at that point? why not use for example $\kappa_1^2+\kappa_2^2$? A single number can never describe the curvedness in all directions, so what's the advantage of $K$ and $H$? More generally, what criterions are used to decide whether a definition of curvature is ""good""?","We know for a 2-dimensional surface there are two orthogonal principal directions at every point, where the principal curvatures $\kappa_1$ and $\kappa_2$ are the two ends of the curvature spectrum over all directions at that point. Gauss and mean curvatures are defined as $K=\kappa_1\kappa_2$ and $H=(\kappa_1+\kappa_2)/2$ respectively. My question is why we use these two specific combination of principal curvatures to quantify a surface's deviation from being ""flat"" at that point? why not use for example $\kappa_1^2+\kappa_2^2$? A single number can never describe the curvedness in all directions, so what's the advantage of $K$ and $H$? More generally, what criterions are used to decide whether a definition of curvature is ""good""?",,"['differential-geometry', 'soft-question', 'surfaces', 'curvature']"
90,The Curvature Tensor,The Curvature Tensor,,"I present three different ways I've seen the Riemann curvature written: $R(X,Y)Z=D_XD_YZ-D_YD_XZ-D_{[X,Y]}Z$ $R(e_c,e_d)e_b=D_{e_c}D_{e_d}e_b-D_{e_d}D_{e_c}e_b-D_{[e_c,e_d]}e_b$. $R^{\rho}_{\space \space\sigma \mu \nu}=dx^{\rho}(R(\partial_{\mu},\partial_{\nu})\partial_{\sigma})$ However I'm not told much more and I'm struggling to make sense of when we would need to use one or the other. I'm assuming the $e_a$ in 2. are basis vectors, e.g. $e_a=\frac{\partial}{\partial x^1}$? So the second is just the curvature applied to basis vectors? But why would we want to do that? Also, doesn't $[e_c,e_d]=0$? And with 3. I'm just completely lost. How do you relate $R(X,Y)Z$ and $R^{\rho}_{\space \space \sigma \mu \nu}$? (This is quite an open question on the understanding of what's the intrinsic difference between these three and when we would need to use each in simple calculations. Or even a question about coordinate expressions of tensors in general.)","I present three different ways I've seen the Riemann curvature written: $R(X,Y)Z=D_XD_YZ-D_YD_XZ-D_{[X,Y]}Z$ $R(e_c,e_d)e_b=D_{e_c}D_{e_d}e_b-D_{e_d}D_{e_c}e_b-D_{[e_c,e_d]}e_b$. $R^{\rho}_{\space \space\sigma \mu \nu}=dx^{\rho}(R(\partial_{\mu},\partial_{\nu})\partial_{\sigma})$ However I'm not told much more and I'm struggling to make sense of when we would need to use one or the other. I'm assuming the $e_a$ in 2. are basis vectors, e.g. $e_a=\frac{\partial}{\partial x^1}$? So the second is just the curvature applied to basis vectors? But why would we want to do that? Also, doesn't $[e_c,e_d]=0$? And with 3. I'm just completely lost. How do you relate $R(X,Y)Z$ and $R^{\rho}_{\space \space \sigma \mu \nu}$? (This is quite an open question on the understanding of what's the intrinsic difference between these three and when we would need to use each in simple calculations. Or even a question about coordinate expressions of tensors in general.)",,"['differential-geometry', 'tensors']"
91,Finding the Total Curvature of Plane Curves,Finding the Total Curvature of Plane Curves,,"I'm trying to find the total curvature (or equivalently, rotation index, winding number etc.) of a plane curve (closed plane curves) given by $$\gamma(t)=(\cos(t),\sin(nt)), 0\le t\le 2\pi$$ for each positive integer $n$ . Looking at the image of thess curves makes me believe that the answer is $0$ when $n$ is even and $2\pi$ when $n$ is odd, but how do I prove this? Calculating the integral of the curvature is extremely complicated! I learned in my class that total curvature is invariant under regular homotopy, but how do I construct such a homotopy?","I'm trying to find the total curvature (or equivalently, rotation index, winding number etc.) of a plane curve (closed plane curves) given by for each positive integer . Looking at the image of thess curves makes me believe that the answer is when is even and when is odd, but how do I prove this? Calculating the integral of the curvature is extremely complicated! I learned in my class that total curvature is invariant under regular homotopy, but how do I construct such a homotopy?","\gamma(t)=(\cos(t),\sin(nt)), 0\le t\le 2\pi n 0 n 2\pi n","['differential-geometry', 'curvature']"
92,Parabolic Cusp of an Action on the Upper Half Plane,Parabolic Cusp of an Action on the Upper Half Plane,,"This is a basic definition question. Parabolic bundles are used in certain counting arguments in my research area. I asked my advisor for a reference on these, and he directed me to the paper of Mehta and Seshadri which can be found here: http://repository.ias.ac.in/20407/1/305.pdf On page 207 (the 3rd page of the PDF), they introduce the following notation: My question is: What is the definition of a parabolic cusp? I would also like to know the motivation behind the name. A reference would be nice, as well. Thank you.","This is a basic definition question. Parabolic bundles are used in certain counting arguments in my research area. I asked my advisor for a reference on these, and he directed me to the paper of Mehta and Seshadri which can be found here: http://repository.ias.ac.in/20407/1/305.pdf On page 207 (the 3rd page of the PDF), they introduce the following notation: My question is: What is the definition of a parabolic cusp? I would also like to know the motivation behind the name. A reference would be nice, as well. Thank you.",,"['algebraic-geometry', 'reference-request', 'differential-geometry']"
93,Arround Cauchy Schwarz Inequality in semi riemannian geometry,Arround Cauchy Schwarz Inequality in semi riemannian geometry,,"I have a question. I seen that Cauchy Schwarz inequality is not valide in the case of pseudo riemannian metric because it is not positive ( or negative) define, I would like to know if there is special cases where this inequality holds, for exemple for spacelike, timelike, .. cases. Thank you","I have a question. I seen that Cauchy Schwarz inequality is not valide in the case of pseudo riemannian metric because it is not positive ( or negative) define, I would like to know if there is special cases where this inequality holds, for exemple for spacelike, timelike, .. cases. Thank you",,['differential-geometry']
94,Wave equation on a compact Riemannian surface without boundary: no mass conservation?,Wave equation on a compact Riemannian surface without boundary: no mass conservation?,,"Consider a compact, smooth Riemmanian surface $\mathcal{S} \subset \mathbb{R}^3$ without boundary. I would like to solve the wave equation: $$u_{tt} + \Delta_{\mathcal{S}} u = 0$$ under the conditions: $$u(0,x) = \delta_y(x)\\ u_t(0,x) = 0,$$ where $\Delta_{\mathcal{S}}$ is the Laplace-Beltrami operator on $\mathcal{S}$. If I am not mistaken (please let me know if I am), the solution can be explicitly written down in terms of the Laplace-Beltrami eigenfuctions $\{\phi_k\}_{k\geq 1}$, which form a basis of $L^2(\mathcal{S})$, and the corresponding eigenvalues $\lambda_k$: $$u(t,x) = \sum_{k=1}^{\infty} \cos(\sqrt{\lambda_k}t) \phi_k(y) \phi_k(x)$$ Now, what surprises me, is that ""mass"" is not conserved in the sense that $$\frac{\partial}{\partial t} \int_{\mathcal{S}} u(x,t) dx = \sum_{k=1}^{\infty} -\sqrt{\lambda_k}\sin(\sqrt{\lambda_k}t) \phi_k(y) \int_{\mathcal{S}}\phi_k(x) dx$$ So ""mass"" changes over time depending on the $\lambda_k$ and thus on the geometry of the surface. Question : Is there an intuitive explanation of why $\int_{\mathcal{S}} u(x,t) dx$ is not a conserved quantity?","Consider a compact, smooth Riemmanian surface $\mathcal{S} \subset \mathbb{R}^3$ without boundary. I would like to solve the wave equation: $$u_{tt} + \Delta_{\mathcal{S}} u = 0$$ under the conditions: $$u(0,x) = \delta_y(x)\\ u_t(0,x) = 0,$$ where $\Delta_{\mathcal{S}}$ is the Laplace-Beltrami operator on $\mathcal{S}$. If I am not mistaken (please let me know if I am), the solution can be explicitly written down in terms of the Laplace-Beltrami eigenfuctions $\{\phi_k\}_{k\geq 1}$, which form a basis of $L^2(\mathcal{S})$, and the corresponding eigenvalues $\lambda_k$: $$u(t,x) = \sum_{k=1}^{\infty} \cos(\sqrt{\lambda_k}t) \phi_k(y) \phi_k(x)$$ Now, what surprises me, is that ""mass"" is not conserved in the sense that $$\frac{\partial}{\partial t} \int_{\mathcal{S}} u(x,t) dx = \sum_{k=1}^{\infty} -\sqrt{\lambda_k}\sin(\sqrt{\lambda_k}t) \phi_k(y) \int_{\mathcal{S}}\phi_k(x) dx$$ So ""mass"" changes over time depending on the $\lambda_k$ and thus on the geometry of the surface. Question : Is there an intuitive explanation of why $\int_{\mathcal{S}} u(x,t) dx$ is not a conserved quantity?",,"['differential-geometry', 'partial-differential-equations']"
95,"Grassmannian, Plucker coordinates","Grassmannian, Plucker coordinates",,In which books can I find something about the grassmannian and the plucker coordinates ?,In which books can I find something about the grassmannian and the plucker coordinates ?,,"['differential-geometry', 'reference-request', 'projective-geometry', 'grassmannian', 'schubert-calculus']"
96,Isometric map of geodesic,Isometric map of geodesic,,"Assume a Riemann manifold $(M,g)$ and a smooth map $\sigma:M\times M\rightarrow M$, $(m_{1},m_{2})\rightarrow \sigma_{m_{1}}(m_{2})$, such that: $\forall m\in M$  $\sigma_{m}:M\rightarrow M$ is an isometry and $\sigma_{m}=m$; $\sigma_{m}\circ \sigma_{m}=1_{M}$; $D\sigma_{m}|_{T_{m}M}=-1_{T_{m}M}$; This is part of a definition of a symmetric space. But other part is irrelevant for the problem I have. Now, fix $m\in M$, and let $\gamma (t)$ be a geodesic of $M$ such that $\gamma (0)=m$. Show that: $$\sigma_{m}\gamma (t)=\gamma (-t).$$ I proceeded as follows: $$D(\sigma_{m}\circ \gamma (t))=D\sigma_{m}\circ\gamma^{'}(t).$$ Since $D\sigma_{m}|_{T_{m}M}=-1_{T_{m}M}$, we have: $$D(\sigma_{m}\circ \gamma (t))=-\gamma^{'} (t).$$ Since $-\gamma^{'} (t)=D\gamma (-t)$, we have: $$D(\sigma_{m}\circ \gamma (t))=D\gamma (-t).$$ So, I assume, that we have this equality:  $$\sigma_{m}\circ \gamma (t)=\gamma (-t).$$ But in the question there was an assumption that $\gamma (t)$ is geodesic and I didn't use it. So my question is: is my line of thinking is correct, or I just completely wrong?","Assume a Riemann manifold $(M,g)$ and a smooth map $\sigma:M\times M\rightarrow M$, $(m_{1},m_{2})\rightarrow \sigma_{m_{1}}(m_{2})$, such that: $\forall m\in M$  $\sigma_{m}:M\rightarrow M$ is an isometry and $\sigma_{m}=m$; $\sigma_{m}\circ \sigma_{m}=1_{M}$; $D\sigma_{m}|_{T_{m}M}=-1_{T_{m}M}$; This is part of a definition of a symmetric space. But other part is irrelevant for the problem I have. Now, fix $m\in M$, and let $\gamma (t)$ be a geodesic of $M$ such that $\gamma (0)=m$. Show that: $$\sigma_{m}\gamma (t)=\gamma (-t).$$ I proceeded as follows: $$D(\sigma_{m}\circ \gamma (t))=D\sigma_{m}\circ\gamma^{'}(t).$$ Since $D\sigma_{m}|_{T_{m}M}=-1_{T_{m}M}$, we have: $$D(\sigma_{m}\circ \gamma (t))=-\gamma^{'} (t).$$ Since $-\gamma^{'} (t)=D\gamma (-t)$, we have: $$D(\sigma_{m}\circ \gamma (t))=D\gamma (-t).$$ So, I assume, that we have this equality:  $$\sigma_{m}\circ \gamma (t)=\gamma (-t).$$ But in the question there was an assumption that $\gamma (t)$ is geodesic and I didn't use it. So my question is: is my line of thinking is correct, or I just completely wrong?",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
97,What exactly are n-forms and how are they related to dual vectors?,What exactly are n-forms and how are they related to dual vectors?,,"I'm trying to get a hold of tensor analysis on manifolds and the idea of vectors and tangent spaces are just starting to click, but I don't really get how the differential of a function can be viewed as a dual or covarient(is there any explicit difference or is it just a matter of context and convention between covarient vectors and dual vectors) vectors. I'm coming from physics, so I have a lot of holes in my formal mathematical knowledge, please feel free to be somewhat pedantic to help me refine my language when talking about this stuff. So I am intentionally stretching my understanding so that it can be corrected. It boils down to this: In GR, we want to be able to talk about vector fields on manifolds to describe, for instance, the electric and magnetic fields in space. But the standard definition of vectors in flat space comes in terms of a coordinate system. First, is this a reasonable statement, and why is this a big problem? Why can't we just define vectors in terms of their components in coordinate system provided by some chart from the manifold to $R^n$ and then use our transition maps to see how that vector would be represented in other coordinate systems. What am I missing, why go through all this trouble and say we must talk about vectors in terms of directional derivatives? For whatever reason, we need to find some way to parameterize the tangent space of some point on a manifold. We do this by considering the fact that any curve on the manifold, $M$, is a map from $R \to M$. Then we can say that the set of all derivative of an arbitrary field at a point $P$ on the manifold are a basis for the tangent space at $P$, and we can label these derivatives by their direction in terms of which curve, out of the set of all (smooth?) curves through $P$ they follow. This is where I start to feel like I have no idea what I'm talking about. First off, don't curves have two directions we could follow. What is the space of all curves on the manifold? The space of all $C^{\infty}$ maps from $R \to M\to R^n$? Doesn't this bring in the coordinate charts once again if I am looking for smoothness of the curve in $M$, do we not care for smooth curves, or should I not be thinking of curves as maps from $R \to M$ and instead think of them as an intangible continuum of points with no other properties? If we choose to use the directional derivatives in terms of coordinates as our basis for $T_p(M)$, then dual vectors are differentials of functions. How on earth do differentials act on partial derivative operators? Maybe I'm just letting the notation dictate my thinking too much, but $df \frac{\partial}{\partial x^u} = \frac{\partial f}{\partial x^u}$ bothers me so much. In all the other math I've learned and hopefully understand the idea of taking the derivative of a differential is ill defined at best, but now we have this whole new can of worms, I don't know I just think I need some more convincing that this is a natural or at least useful definition. Are n-forms meant to generalize some other notion that I'm familiar with from more elementary mathematics? I'm particularly troubled because it seems in some sense we are saying that you can take the partial derivative of the gradient of a function, and that's the same as just the dot product of the gradient some vector (in terms of more classical vector constructions) Okay, I think that's long enough, thanks for the help in advance.","I'm trying to get a hold of tensor analysis on manifolds and the idea of vectors and tangent spaces are just starting to click, but I don't really get how the differential of a function can be viewed as a dual or covarient(is there any explicit difference or is it just a matter of context and convention between covarient vectors and dual vectors) vectors. I'm coming from physics, so I have a lot of holes in my formal mathematical knowledge, please feel free to be somewhat pedantic to help me refine my language when talking about this stuff. So I am intentionally stretching my understanding so that it can be corrected. It boils down to this: In GR, we want to be able to talk about vector fields on manifolds to describe, for instance, the electric and magnetic fields in space. But the standard definition of vectors in flat space comes in terms of a coordinate system. First, is this a reasonable statement, and why is this a big problem? Why can't we just define vectors in terms of their components in coordinate system provided by some chart from the manifold to $R^n$ and then use our transition maps to see how that vector would be represented in other coordinate systems. What am I missing, why go through all this trouble and say we must talk about vectors in terms of directional derivatives? For whatever reason, we need to find some way to parameterize the tangent space of some point on a manifold. We do this by considering the fact that any curve on the manifold, $M$, is a map from $R \to M$. Then we can say that the set of all derivative of an arbitrary field at a point $P$ on the manifold are a basis for the tangent space at $P$, and we can label these derivatives by their direction in terms of which curve, out of the set of all (smooth?) curves through $P$ they follow. This is where I start to feel like I have no idea what I'm talking about. First off, don't curves have two directions we could follow. What is the space of all curves on the manifold? The space of all $C^{\infty}$ maps from $R \to M\to R^n$? Doesn't this bring in the coordinate charts once again if I am looking for smoothness of the curve in $M$, do we not care for smooth curves, or should I not be thinking of curves as maps from $R \to M$ and instead think of them as an intangible continuum of points with no other properties? If we choose to use the directional derivatives in terms of coordinates as our basis for $T_p(M)$, then dual vectors are differentials of functions. How on earth do differentials act on partial derivative operators? Maybe I'm just letting the notation dictate my thinking too much, but $df \frac{\partial}{\partial x^u} = \frac{\partial f}{\partial x^u}$ bothers me so much. In all the other math I've learned and hopefully understand the idea of taking the derivative of a differential is ill defined at best, but now we have this whole new can of worms, I don't know I just think I need some more convincing that this is a natural or at least useful definition. Are n-forms meant to generalize some other notion that I'm familiar with from more elementary mathematics? I'm particularly troubled because it seems in some sense we are saying that you can take the partial derivative of the gradient of a function, and that's the same as just the dot product of the gradient some vector (in terms of more classical vector constructions) Okay, I think that's long enough, thanks for the help in advance.",,"['differential-geometry', 'differential-forms']"
98,Intuition behind smooth functions.,Intuition behind smooth functions.,,"Smooth functions $f(t)$ are those such that $\frac{d^nf(t)}{dt^n}$ exists for all $n\in\Bbb{N}$. I understand the intuition behind smoothness for functions like $f(t)=| t|$ and $f(t)=\sqrt{t}$. $f(t)$ has a ""sharp"" (and hence non-smooth) turn at $t=0$. Similarly, $f(t)=\sqrt{t}$ ends abruptly at $t=0$ (and hence is not ""smooth""). However, functions like $f(t)=t^{\frac{1}{3}}$ seem ""smooth"" enough to me! Why does the intuitive understanding of smoothness fail here? Is this just another case of extending a definition of a term to non-intuitive cases? Thanks in advance!","Smooth functions $f(t)$ are those such that $\frac{d^nf(t)}{dt^n}$ exists for all $n\in\Bbb{N}$. I understand the intuition behind smoothness for functions like $f(t)=| t|$ and $f(t)=\sqrt{t}$. $f(t)$ has a ""sharp"" (and hence non-smooth) turn at $t=0$. Similarly, $f(t)=\sqrt{t}$ ends abruptly at $t=0$ (and hence is not ""smooth""). However, functions like $f(t)=t^{\frac{1}{3}}$ seem ""smooth"" enough to me! Why does the intuitive understanding of smoothness fail here? Is this just another case of extending a definition of a term to non-intuitive cases? Thanks in advance!",,[]
99,Are these two 2-manifolds homeomorphic?,Are these two 2-manifolds homeomorphic?,,"I have a 2-Sphere with a finite number $k$ of points removed (at least 3), and I want to equip it with a Riemannian metric of constant negative curvature. My first thought was to take a free subgroup $A_k$ of rank $k$ of the isometries of the hyperbolic plane $H$, which acts fix point free and discontinuous on $H$ (such a group exists). If I take the quotient $H/A_k$, I end up with a complete manifold of constant negative curvature, with isomorphic fundamental group to the punctured Sphere, but are those two manifolds homeomorphic? Maybe this is a terribly clumsy way to try to accomplish this task.","I have a 2-Sphere with a finite number $k$ of points removed (at least 3), and I want to equip it with a Riemannian metric of constant negative curvature. My first thought was to take a free subgroup $A_k$ of rank $k$ of the isometries of the hyperbolic plane $H$, which acts fix point free and discontinuous on $H$ (such a group exists). If I take the quotient $H/A_k$, I end up with a complete manifold of constant negative curvature, with isomorphic fundamental group to the punctured Sphere, but are those two manifolds homeomorphic? Maybe this is a terribly clumsy way to try to accomplish this task.",,"['differential-geometry', 'algebraic-topology', 'riemannian-geometry']"
