,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probabilistic coin weighing [duplicate],Probabilistic coin weighing [duplicate],,"This question already has an answer here : choosing two sets that intersect every given subset in the same amount of points (1 answer) Closed last year . Let $S_1, \ldots, S_k$ be subsets of $\{1, \ldots, n\}$ with $k \leq 1.99 \frac{n}{\log_2(n)}$ , prove that there are two distinct subsets $X,Y$ of $\{1, \ldots, n\}$ , such that for all $1 \leq i \leq k$ we have $|X \cap S_i | = | Y \cap S_i | $ . I am sure this is supposed to be done with some concentration argument, but I have no idea what the right probability space to look at is. I've so far tried to pick X and Y independently with the same distribution by including every number in the set (independently) with some probability $p_j$ . This would then mean that the random variable $|X \cap S_i | - | Y \cap S_i | $ has mean zero and that I could use some concentration inequality to then get a union bound. To make sure that the sets $X$ and $Y$ also are distinct, I need to pick the parameters $p_j$ close enough to $1/2$ . The parameters $p_j$ should also somehow depend on the size of the smallest set covering the element $j$ . But the analysis got too messy and I doubt that this approach is even feasible? Does anybody know what the right space to look at is? Edit: $n$ is supposed to be taken sufficiently large as Mike earnest pointed out.","This question already has an answer here : choosing two sets that intersect every given subset in the same amount of points (1 answer) Closed last year . Let be subsets of with , prove that there are two distinct subsets of , such that for all we have . I am sure this is supposed to be done with some concentration argument, but I have no idea what the right probability space to look at is. I've so far tried to pick X and Y independently with the same distribution by including every number in the set (independently) with some probability . This would then mean that the random variable has mean zero and that I could use some concentration inequality to then get a union bound. To make sure that the sets and also are distinct, I need to pick the parameters close enough to . The parameters should also somehow depend on the size of the smallest set covering the element . But the analysis got too messy and I doubt that this approach is even feasible? Does anybody know what the right space to look at is? Edit: is supposed to be taken sufficiently large as Mike earnest pointed out.","S_1, \ldots, S_k \{1, \ldots, n\} k \leq 1.99 \frac{n}{\log_2(n)} X,Y \{1, \ldots, n\} 1 \leq i \leq k |X \cap S_i | = | Y \cap S_i |  p_j |X \cap S_i | - | Y \cap S_i |  X Y p_j 1/2 p_j j n","['probability', 'combinatorics', 'discrete-mathematics', 'concentration-of-measure', 'probabilistic-method']"
1,Probability of poker pair - what's wrong with this?,Probability of poker pair - what's wrong with this?,,"Thanks to others here, I know the correct way to calculate the probability of one pair in 5-card poker is P(one pair) = $C(13, 1) * C(4, 2) * C(12, 3) * [C(4, 1)]^3 / C(52, 5)$ = 0.4225690276... Why doesn't the following work? The answer comes out to exactly 1/10 of the correct answer (to over 20 decimal places) - I find that highly coincidental but I can't figure out where the factor of 10 comes from. Once you've chosen the first card, you have a 3/51 probability of choosing the matching denomination for a pair. Then you have a 48/50 probability of choosing a different denomination out of the remaining 50 cards for card #3. Then you have a 44/49 probability of choosing another different denomination for card #4. Then you have a 40/48 probability of choosing a fourth different denomination for card #5. P(one pair) = 3/51 * 48/50 * 44/49 * 40/48 = 0.04225690276..., exactly 1/10 the answer above. Thanks!","Thanks to others here, I know the correct way to calculate the probability of one pair in 5-card poker is P(one pair) = = 0.4225690276... Why doesn't the following work? The answer comes out to exactly 1/10 of the correct answer (to over 20 decimal places) - I find that highly coincidental but I can't figure out where the factor of 10 comes from. Once you've chosen the first card, you have a 3/51 probability of choosing the matching denomination for a pair. Then you have a 48/50 probability of choosing a different denomination out of the remaining 50 cards for card #3. Then you have a 44/49 probability of choosing another different denomination for card #4. Then you have a 40/48 probability of choosing a fourth different denomination for card #5. P(one pair) = 3/51 * 48/50 * 44/49 * 40/48 = 0.04225690276..., exactly 1/10 the answer above. Thanks!","C(13, 1) * C(4, 2) * C(12, 3) * [C(4, 1)]^3 / C(52, 5)","['probability', 'poker']"
2,"Given a list of numbers, probability of the first number being the maximum?","Given a list of numbers, probability of the first number being the maximum?",,"So I'm traversing this trivia book which has a question that has intrigued and widely confused me. 1.) Since we have $n$ number of elements, then the probability of it being the largest among the $n$ choices is $\frac{1}{n}$ , which seems intuitive. 2.) The probability of it being larger than the second number $x_{2}$ is: either it will be larger or not, therefore $\frac{1}{2}$ . Similarly, now this process is repeated $(n-1)$ times to check whether $x_{1}$ is larger than all other elements. Then the probability we will arrive at is : $\frac{1}{2^{n-1}}$ I equally believe in both processes, but of course, one is wrong. Apart from knowing which is right, it will be helpful to elucidate on why the other is wrong.","So I'm traversing this trivia book which has a question that has intrigued and widely confused me. 1.) Since we have number of elements, then the probability of it being the largest among the choices is , which seems intuitive. 2.) The probability of it being larger than the second number is: either it will be larger or not, therefore . Similarly, now this process is repeated times to check whether is larger than all other elements. Then the probability we will arrive at is : I equally believe in both processes, but of course, one is wrong. Apart from knowing which is right, it will be helpful to elucidate on why the other is wrong.",n n \frac{1}{n} x_{2} \frac{1}{2} (n-1) x_{1} \frac{1}{2^{n-1}},['probability']
3,Reference request for certain PDE appearing in a probability application,Reference request for certain PDE appearing in a probability application,,"In working on a stochastic processes application, I derived a PDE for the joint transform of some process. It takes the form $$\frac{\partial \zeta(t,z,s)}{\partial t}-(\beta s+1)\frac{\partial\zeta(t,z,s)}{\partial s}=\frac{z}{s}\left(\zeta(t,z,0)-\zeta(t,z,s)\right),$$ where we have boundary conditions $\zeta(0,z,s)=e^{-s}$ , $\zeta(t,0,s)=0$ and $\zeta(t,1,0)=1$ . Here $\beta>0$ is just some scalar. If convenient, I'm fine with setting it to unity. I don't have much experience with PDE, and I'm a bit stuck in this problem because I either want to solve this PDE or I'd like to calculate expressions like $\frac{\partial \zeta(t,z,s)}{\partial z}$ evaluated in $(t,1,0)$ for arbitrary $t>0$ . In this context, it may be helpful to use the expression $\zeta(t,z,s)=\mathbb Ez^{N(t)}e^{-s\Lambda(t)}$ from my probability application. Rewriting the PDE and using this expression gives us ODEs for moments of $N(t),\Lambda(t)$ , but only expressed in higher moments, making a recursive solution inpossible. Therefore I'm looking for something different. I was hoping this PDE belongs to some well-known class, or for some analytical method to solve this PDE; I'm looking for some reference. Any help is much appreciated.","In working on a stochastic processes application, I derived a PDE for the joint transform of some process. It takes the form where we have boundary conditions , and . Here is just some scalar. If convenient, I'm fine with setting it to unity. I don't have much experience with PDE, and I'm a bit stuck in this problem because I either want to solve this PDE or I'd like to calculate expressions like evaluated in for arbitrary . In this context, it may be helpful to use the expression from my probability application. Rewriting the PDE and using this expression gives us ODEs for moments of , but only expressed in higher moments, making a recursive solution inpossible. Therefore I'm looking for something different. I was hoping this PDE belongs to some well-known class, or for some analytical method to solve this PDE; I'm looking for some reference. Any help is much appreciated.","\frac{\partial \zeta(t,z,s)}{\partial t}-(\beta s+1)\frac{\partial\zeta(t,z,s)}{\partial s}=\frac{z}{s}\left(\zeta(t,z,0)-\zeta(t,z,s)\right), \zeta(0,z,s)=e^{-s} \zeta(t,0,s)=0 \zeta(t,1,0)=1 \beta>0 \frac{\partial \zeta(t,z,s)}{\partial z} (t,1,0) t>0 \zeta(t,z,s)=\mathbb Ez^{N(t)}e^{-s\Lambda(t)} N(t),\Lambda(t)","['probability', 'partial-differential-equations', 'reference-request', 'stochastic-processes']"
4,"Given that no yellow balls were chosen, what is the probability that there are exactly $2$ blue balls chosen?","Given that no yellow balls were chosen, what is the probability that there are exactly  blue balls chosen?",2,"I'm struggling with this problem.  Can anyone tell me what I'm doing wrong? Six balls are to be randomly chosen from $9$ blue, $9$ yellow and $14$ green balls.  Given that no yellow balls were chosen, what is the probability that there are exactly $2$ blue balls chosen? I was thinking the answer is: $$\frac{\binom{9}{2} \binom{14}{4}}{\binom{32}{6}}$$ but this isn't right and I really don't know how else to approach it.","I'm struggling with this problem.  Can anyone tell me what I'm doing wrong? Six balls are to be randomly chosen from blue, yellow and green balls.  Given that no yellow balls were chosen, what is the probability that there are exactly blue balls chosen? I was thinking the answer is: but this isn't right and I really don't know how else to approach it.",9 9 14 2 \frac{\binom{9}{2} \binom{14}{4}}{\binom{32}{6}},"['probability', 'combinatorics', 'conditional-probability']"
5,"Probability of winning with $\{1,\dots,9\}$ vs $\{1,\dots,8\}$",Probability of winning with  vs,"\{1,\dots,9\} \{1,\dots,8\}","Assume A and B have access to the set $\{1,\dots,9\}$ and $\{1,\dots,8\}$ , respectively. They choose three numbers from each's set without replacement and form the largest 3-digit number accordingly. For example, 4,2,5 means 542. What's the probability for A getting a larger number than B? My attempt: $P(A\ win) = P(A\ win|A\ with\ 9)P(A\ with\ 9) + P(A\ win|A\ without\ 9)P(A\ without\ 9)=1\times 3/9 + 1/2\times6/9 = 2/3$ . I am not sure if the above works. Specially, it seems $P(A\ win|A\ without\ 9)$ is not $1/2$ given the possibility of tie. Any hint and suggestion? Thanks a lot!","Assume A and B have access to the set and , respectively. They choose three numbers from each's set without replacement and form the largest 3-digit number accordingly. For example, 4,2,5 means 542. What's the probability for A getting a larger number than B? My attempt: . I am not sure if the above works. Specially, it seems is not given the possibility of tie. Any hint and suggestion? Thanks a lot!","\{1,\dots,9\} \{1,\dots,8\} P(A\ win) = P(A\ win|A\ with\ 9)P(A\ with\ 9) + P(A\ win|A\ without\ 9)P(A\ without\ 9)=1\times 3/9 + 1/2\times6/9 = 2/3 P(A\ win|A\ without\ 9) 1/2",['probability']
6,Bound for a sum of poisson probabilities,Bound for a sum of poisson probabilities,,"I'd like to understand a bound that has appeared in a paper I'm reading. It has the following expression: $$\begin{align*}[...] &\leq \sum_{m \geq n }4^mP[Poisson(kt)\geq m] \\&=e^{-kt}\sum_{m \geq n}4^m \sum_{j \geq m}\frac{(kt)^j}{j!} \\&\leq e^{-kt}\sum_{m\geq n}e^{kt}\frac{(4kt)^m}{m!}\\ &{\color{red}\leq} e^{4kt}\frac{(4kt)^n}{\left(\frac{n}{2}\right)^{\frac{n}{2}}} \\&{\color{blue}\leq} e^{-\frac{1}{8}n \log n}\end{align*}$$ if $n \geq (16kt)^8$ . Now, I do understand everything except the two colored inequalities. For the blue one, I believe the idea is the following: Since $n\geq(16kt)^8\implies 4kt\leq \frac{n^{\frac{1}{8}}}{4}$ and so $$e^{4kt}\frac{(4kt)^n}{\left(\frac{n}{2}\right)^{\frac{n}{2}}}\leq e^{\frac{n^{1/8}}{4}}\frac{\left(\frac{n^{1/8}}{4}\right)^n}{\left(\frac{n}{2}\right)^{n/2}} = e^{\frac{n^{1/8}}{4}} n^{n/8}n^{-n/2}4^{-n}2^{n/2} = e^{\frac{n^{1/8}}{4}}n^{-\frac{3}{8}n}2^{-\frac{3}{2}n}$$ $$=\exp\left(\frac{n^{1/8}}{4}-\frac{3}{8}n \log n -\frac{3}{2}n \log 2\right)$$ Now, for $n$ big enough $\frac{n^{\frac{1}{8}}}{4}-\frac{3}{2}n \log 2<0$ and so $\exp\left(\frac{n^{1/8}}{4}-\frac{3}{8}n \log n -\frac{3}{2}n \log 2\right)\leq \exp\left(-\frac{3}{8}n \log n\right)\leq \exp \left(-\frac{1}{8}n \log n\right)$ Now, the red one I have absolutely on idea on how to proceed.","I'd like to understand a bound that has appeared in a paper I'm reading. It has the following expression: if . Now, I do understand everything except the two colored inequalities. For the blue one, I believe the idea is the following: Since and so Now, for big enough and so Now, the red one I have absolutely on idea on how to proceed.","\begin{align*}[...] &\leq \sum_{m \geq n }4^mP[Poisson(kt)\geq m]
\\&=e^{-kt}\sum_{m \geq n}4^m \sum_{j \geq m}\frac{(kt)^j}{j!}
\\&\leq e^{-kt}\sum_{m\geq n}e^{kt}\frac{(4kt)^m}{m!}\\
&{\color{red}\leq} e^{4kt}\frac{(4kt)^n}{\left(\frac{n}{2}\right)^{\frac{n}{2}}}
\\&{\color{blue}\leq} e^{-\frac{1}{8}n \log n}\end{align*} n \geq (16kt)^8 n\geq(16kt)^8\implies 4kt\leq \frac{n^{\frac{1}{8}}}{4} e^{4kt}\frac{(4kt)^n}{\left(\frac{n}{2}\right)^{\frac{n}{2}}}\leq e^{\frac{n^{1/8}}{4}}\frac{\left(\frac{n^{1/8}}{4}\right)^n}{\left(\frac{n}{2}\right)^{n/2}} = e^{\frac{n^{1/8}}{4}} n^{n/8}n^{-n/2}4^{-n}2^{n/2} = e^{\frac{n^{1/8}}{4}}n^{-\frac{3}{8}n}2^{-\frac{3}{2}n} =\exp\left(\frac{n^{1/8}}{4}-\frac{3}{8}n \log n -\frac{3}{2}n \log 2\right) n \frac{n^{\frac{1}{8}}}{4}-\frac{3}{2}n \log 2<0 \exp\left(\frac{n^{1/8}}{4}-\frac{3}{8}n \log n -\frac{3}{2}n \log 2\right)\leq \exp\left(-\frac{3}{8}n \log n\right)\leq \exp \left(-\frac{1}{8}n \log n\right)","['probability', 'poisson-distribution', 'upper-lower-bounds']"
7,Conditional distribution function of one random variable given the sum of two,Conditional distribution function of one random variable given the sum of two,,"I am trying to solve the following exercise in Probability Theory by A. Klenke (3rd version). Let X and Y be independent exponential random variables for some $\theta>0$ . Compute $P[X \leq x | X+Y]$ for $x\geq0$ . My solution is based only on the definition of conditional expectation and in particular on this property: if $\mathbb{E}[\mathbb{1}_A X]=\mathbb{E}[\mathbb{1}_A\mathbb{E}[X|\mathcal{F}]]$ for every $A \in \mathcal{F}$ then $\mathbb{E}[X|\mathcal{F}]$ is called a conditional expectation, where $X\in\mathcal{L}^1(\Omega, \mathcal{A},\mathbb{P})$ and $\mathcal{F}\subset \mathcal{A}$ are two $\sigma$ -algebras. Thus, for every $A\in \sigma(X+Y)$ : $\int_A \mathbb{1}_{X(\omega)\in[0,x]} d\mathbb{P}=\int_A\mathbb{1}_{X(\omega)\in[0,x]} d(\mathbb{P}\circ(X \times (X+Y))^{-1})=\int_A\int_0^t\mathbb{1}_{t-y\in[0,x]} \theta e^{-\theta(t-y)}\theta e^{-\theta y}dydt=\int_A \int_{t-x}^{t} \theta^2e^{-\theta t}dydt=\int_A \frac{x}{t} t\theta^2e^{-\theta t}dt = \int_A \frac{x}{T} d\mathbb{P}$ . So I conclude: $P[X \leq x | X+Y] = \frac{x}{X+Y}$ . In the second equality I obtained the density of $(X,T)$ , where $T=X+Y$ , in this way: $f_{X,T}(x,t)=f_{X,Y}(t-y,y)=f_X(t-y)f_Y(y)$ by the independence property. Is this correct? Edit Taking in the comments made by @D Ford, if I define $T=X+Y$ , then this is the correct chain of equalities: $\int_A \mathbb{1}_{X\in[0,x]}(\omega) d\mathbb{P}= \\ \int_{T(A)}\mathbb{1}_{[0,x]}(X) d(\mathbb{P}\circ(X \times (X+Y))^{-1})=\\ \int_{T(A)}\int_0^t\mathbb{1}_{t-y\in[0,x]} \theta e^{-\theta(t-y)}\theta e^{-\theta y}dydt=\\ \int_{T(A)} \int_{t-x}^{t} \theta^2e^{-\theta t}dydt=\\ \int_{T(A)} \frac{x}{t} t\theta^2e^{-\theta t}dt = \\ \int_A \frac{x}{T} d\mathbb{P}$ .","I am trying to solve the following exercise in Probability Theory by A. Klenke (3rd version). Let X and Y be independent exponential random variables for some . Compute for . My solution is based only on the definition of conditional expectation and in particular on this property: if for every then is called a conditional expectation, where and are two -algebras. Thus, for every : . So I conclude: . In the second equality I obtained the density of , where , in this way: by the independence property. Is this correct? Edit Taking in the comments made by @D Ford, if I define , then this is the correct chain of equalities: .","\theta>0 P[X \leq x | X+Y] x\geq0 \mathbb{E}[\mathbb{1}_A X]=\mathbb{E}[\mathbb{1}_A\mathbb{E}[X|\mathcal{F}]] A \in \mathcal{F} \mathbb{E}[X|\mathcal{F}] X\in\mathcal{L}^1(\Omega, \mathcal{A},\mathbb{P}) \mathcal{F}\subset \mathcal{A} \sigma A\in \sigma(X+Y) \int_A \mathbb{1}_{X(\omega)\in[0,x]} d\mathbb{P}=\int_A\mathbb{1}_{X(\omega)\in[0,x]} d(\mathbb{P}\circ(X \times (X+Y))^{-1})=\int_A\int_0^t\mathbb{1}_{t-y\in[0,x]} \theta e^{-\theta(t-y)}\theta e^{-\theta y}dydt=\int_A \int_{t-x}^{t} \theta^2e^{-\theta t}dydt=\int_A \frac{x}{t} t\theta^2e^{-\theta t}dt = \int_A \frac{x}{T} d\mathbb{P} P[X \leq x | X+Y] = \frac{x}{X+Y} (X,T) T=X+Y f_{X,T}(x,t)=f_{X,Y}(t-y,y)=f_X(t-y)f_Y(y) T=X+Y \int_A \mathbb{1}_{X\in[0,x]}(\omega) d\mathbb{P}= \\
\int_{T(A)}\mathbb{1}_{[0,x]}(X) d(\mathbb{P}\circ(X \times (X+Y))^{-1})=\\
\int_{T(A)}\int_0^t\mathbb{1}_{t-y\in[0,x]} \theta e^{-\theta(t-y)}\theta e^{-\theta y}dydt=\\
\int_{T(A)} \int_{t-x}^{t} \theta^2e^{-\theta t}dydt=\\
\int_{T(A)} \frac{x}{t} t\theta^2e^{-\theta t}dt = \\
\int_A \frac{x}{T} d\mathbb{P}","['probability', 'probability-theory', 'conditional-probability', 'conditional-expectation']"
8,$\mathbf{E} |\xi_n - \xi|^a \to 0 \Rightarrow \mathbf{E} \xi_n^a \to \mathbf{E} \xi^a$.,.,\mathbf{E} |\xi_n - \xi|^a \to 0 \Rightarrow \mathbf{E} \xi_n^a \to \mathbf{E} \xi^a,"Let $\xi_n$ , $\xi$ be nonnegative random variables. Prove or disprove that if $$\mathbf{E} \lvert \xi_n - \xi \rvert^a \to 0 \quad \text{as } n\to \infty$$ for all $a \in (0, \infty)$ , then $$\mathbf{E} \xi_n^a \to   \mathbf{E} \xi^a$$ I know that if $a \in \mathbb{N}$ then the statement is true, but I don't know how to prove it and I don't know anything about the case when $a$ is arbitrary. The following is my attempt. If $a=m \in \mathbb{N}$ we have \begin{align} \lvert \mathbf{E} \xi_n^m - \mathbf{E}  \xi^m \rvert &= \lvert \mathbf{E} (\xi_n - \xi)(\xi_n^{m-1} - \xi_n^{m-2}\xi + \ldots ) \rvert \\ &\le \sqrt{\mathbf{E} (\xi_n - \xi)^2 \mathbf{E}(\xi_n^{m-1} - \xi_n^{m-2}\xi + \ldots )^2} \\ &\to 0 \end{align} because $\mathbf{E}(\xi_n^{m-1} - \xi_n^{m-2}\xi + \ldots )^2$ is bounded. It is bounded because it is a finite sum of terms $\mathbf{E}\xi_n^i \xi^j$ and $$\lvert \mathbf{E}\xi_n^i \xi^j \rvert \le \sqrt{\mathbf{E}\xi_n^{2i} \mathbf{E}\xi^{2j} }$$ So it's sufficient to show that $\mathbf{E}\xi_n^{2i}$ is bounded for every $i$ .","Let , be nonnegative random variables. Prove or disprove that if for all , then I know that if then the statement is true, but I don't know how to prove it and I don't know anything about the case when is arbitrary. The following is my attempt. If we have because is bounded. It is bounded because it is a finite sum of terms and So it's sufficient to show that is bounded for every .","\xi_n \xi \mathbf{E} \lvert \xi_n - \xi \rvert^a \to 0 \quad \text{as } n\to \infty a \in (0, \infty) \mathbf{E} \xi_n^a \to   \mathbf{E} \xi^a a \in \mathbb{N} a a=m \in \mathbb{N} \begin{align}
\lvert \mathbf{E} \xi_n^m - \mathbf{E}  \xi^m \rvert &= \lvert \mathbf{E} (\xi_n - \xi)(\xi_n^{m-1} - \xi_n^{m-2}\xi + \ldots ) \rvert \\
&\le \sqrt{\mathbf{E} (\xi_n - \xi)^2 \mathbf{E}(\xi_n^{m-1} - \xi_n^{m-2}\xi + \ldots )^2} \\
&\to 0
\end{align} \mathbf{E}(\xi_n^{m-1} - \xi_n^{m-2}\xi + \ldots )^2 \mathbf{E}\xi_n^i \xi^j \lvert \mathbf{E}\xi_n^i \xi^j \rvert \le \sqrt{\mathbf{E}\xi_n^{2i} \mathbf{E}\xi^{2j} } \mathbf{E}\xi_n^{2i} i","['probability', 'sequences-and-series', 'probability-theory']"
9,Expectation of maximum from $n$ draws.,Expectation of maximum from  draws.,n,"We have $n$ guys walking down the street, and each can find $1, 2, \ldots $ or $n$ dollars in the street. ( $n$ is the same number of guys and the same number of dollars in the problem). Each of them finds $1$ dollar with probability $\dfrac{1}{2}$ , $2$ dollars with probability $\dfrac{1}{4}$ , $3$ dollars with probability $\dfrac{1}{8}$ , and so on. This is, he finds $x$ number of dollars with probability $\dfrac{1}{2^x}$ . (These probabilities are independent between guys, think that they are walking down different streets; the remaining $1/2^n$ probability can be arbitrarily assigned to getting $n$ (or 0) dollars, whatever is more convenient). In expectation, every agent finds less than $2$ dollars. But: what is the expected number of dollars that the luckiest guy gets? This is, if $x_1, \ldots, x_n$ is the number of dollars that people find, what is $E[\max(x_1, \ldots, x_n)]$ ? Edit: I am interested in obtaining a simple expression for the expectation OR a good upper bound. Idea: Simulations suggest that the answer is around $\log(n)$ . Edit: I tried solving it using Lulu's suggestion. Let $M=\max(x_1, \ldots, x_n)]$ . Then $E[M]=\sum_{i=1}^n Pr(M=i)\cdot i$ . $Pr(M=1)=\frac{1}{2^n}$ . $Pr(M=2)=\frac{3^n}{4^n}-\frac{1}{2^n}$ . $Pr(M=3)=\frac{7^n}{8^n}-\frac{3^n}{4^n}+\frac{1}{2^n}$ . $Pr(M=4)=\frac{15^n}{16^n}-\frac{7^n}{8^n}+\frac{3^n}{4^n}-\frac{1}{2^n}$ . This implies that $E[M]=1 \cdot \frac{1}{2^n} + 2 \cdot (\frac{3^n}{4^n}-\frac{1}{2^n}) + 3 \cdot (\frac{7^n}{8^n}-\frac{3^n}{4^n}+\frac{1}{2^n}) + 4 \cdot (\frac{15^n}{16^n}-\frac{7^n}{8^n}+\frac{3^n}{4^n}-\frac{1}{2^n}) + \ldots$ . But I do not see how that expression converges to something easy to work with - or close to $\log (n)$ . Edit 2: A different approach, using $E[M]= \sum_{k=0}^\infty Pr(M\geq k)$ , gives $E[M]=\sum_{k=0}^\infty 1- \left( \frac{2^{k-1}-1}{2^{k-1}}\right)^n$ , but I am not sure how to expand this term to make it approximately equal to $\log(n)$ .","We have guys walking down the street, and each can find or dollars in the street. ( is the same number of guys and the same number of dollars in the problem). Each of them finds dollar with probability , dollars with probability , dollars with probability , and so on. This is, he finds number of dollars with probability . (These probabilities are independent between guys, think that they are walking down different streets; the remaining probability can be arbitrarily assigned to getting (or 0) dollars, whatever is more convenient). In expectation, every agent finds less than dollars. But: what is the expected number of dollars that the luckiest guy gets? This is, if is the number of dollars that people find, what is ? Edit: I am interested in obtaining a simple expression for the expectation OR a good upper bound. Idea: Simulations suggest that the answer is around . Edit: I tried solving it using Lulu's suggestion. Let . Then . . . . . This implies that . But I do not see how that expression converges to something easy to work with - or close to . Edit 2: A different approach, using , gives , but I am not sure how to expand this term to make it approximately equal to .","n 1, 2, \ldots  n n 1 \dfrac{1}{2} 2 \dfrac{1}{4} 3 \dfrac{1}{8} x \dfrac{1}{2^x} 1/2^n n 2 x_1, \ldots, x_n E[\max(x_1, \ldots, x_n)] \log(n) M=\max(x_1, \ldots, x_n)] E[M]=\sum_{i=1}^n Pr(M=i)\cdot i Pr(M=1)=\frac{1}{2^n} Pr(M=2)=\frac{3^n}{4^n}-\frac{1}{2^n} Pr(M=3)=\frac{7^n}{8^n}-\frac{3^n}{4^n}+\frac{1}{2^n} Pr(M=4)=\frac{15^n}{16^n}-\frac{7^n}{8^n}+\frac{3^n}{4^n}-\frac{1}{2^n} E[M]=1 \cdot \frac{1}{2^n} + 2 \cdot (\frac{3^n}{4^n}-\frac{1}{2^n}) + 3 \cdot (\frac{7^n}{8^n}-\frac{3^n}{4^n}+\frac{1}{2^n}) + 4 \cdot (\frac{15^n}{16^n}-\frac{7^n}{8^n}+\frac{3^n}{4^n}-\frac{1}{2^n}) + \ldots \log (n) E[M]= \sum_{k=0}^\infty Pr(M\geq k) E[M]=\sum_{k=0}^\infty 1- \left( \frac{2^{k-1}-1}{2^{k-1}}\right)^n \log(n)","['probability', 'expected-value', 'order-statistics']"
10,Geometric growth rate and Kelly's Criterion question,Geometric growth rate and Kelly's Criterion question,,"In the Wikipedia page about Kelly Criterion, the author calculated the expected wealth after N bets as $$W * (1+g)^N$$ where $W$ is the initial wealth, and $g$ is the expected geometric growth rate. For example, with \$25 starting wealth, a 60% chance of winning/losing the whatever you wager, if our strategy is to bet 20% of current wealth, then the article says that $1+g = (1+0.2*1)^{0.6}(1-0.2*1)^{0.4} = 1.02034$ and expected wealth at round N is $W_N = 25*(1.02034)^N$ But if I look at it from another perspective: the expected wealth after 1 round is $0.6(1.2W) + 0.4(0.8W) = 1.04W$ . So shouldn't $W_N$ be $25*(1.04)^N$ instead? That is, there should only be one answer for expected wealth at round N, given our paramters p,q,f (here f is known so Kelly Criterion doesn't really come into play). However, the Wiki page has a completely different computation than what I have.","In the Wikipedia page about Kelly Criterion, the author calculated the expected wealth after N bets as where is the initial wealth, and is the expected geometric growth rate. For example, with \$25 starting wealth, a 60% chance of winning/losing the whatever you wager, if our strategy is to bet 20% of current wealth, then the article says that and expected wealth at round N is But if I look at it from another perspective: the expected wealth after 1 round is . So shouldn't be instead? That is, there should only be one answer for expected wealth at round N, given our paramters p,q,f (here f is known so Kelly Criterion doesn't really come into play). However, the Wiki page has a completely different computation than what I have.",W * (1+g)^N W g 1+g = (1+0.2*1)^{0.6}(1-0.2*1)^{0.4} = 1.02034 W_N = 25*(1.02034)^N 0.6(1.2W) + 0.4(0.8W) = 1.04W W_N 25*(1.04)^N,"['probability', 'finance', 'mathematical-modeling', 'economics', 'gambling']"
11,An urn contains 10 balls numbered from 1 to 10. Three balls are drawn without replacement.,An urn contains 10 balls numbered from 1 to 10. Three balls are drawn without replacement.,,"An urn contains 10 balls numbered from 1 to 10. Three balls are drawn without replacement.  What is the probability that the drawn balls have numbers greater than 5? I thought for the first ball, (6,7,8,9,10). The probability is $5/10$ . We took one, and for the second it is $4/9$ . And for the third one it is $3/8$ . Then we multiply these, and it is $1/12$ . But I am not sure for this solution. I am confused.","An urn contains 10 balls numbered from 1 to 10. Three balls are drawn without replacement.  What is the probability that the drawn balls have numbers greater than 5? I thought for the first ball, (6,7,8,9,10). The probability is . We took one, and for the second it is . And for the third one it is . Then we multiply these, and it is . But I am not sure for this solution. I am confused.",5/10 4/9 3/8 1/12,"['probability', 'discrete-mathematics']"
12,Probabilty and Permutations,Probabilty and Permutations,,"A nine digit number is formed using 1 to 9 without repetition, find the probability of forming a number such that the product of any of its five  consecutive digits is divisible by 3 or 5. Now my approach for solving this problem was to first find out the cases where this would not be possible. If the product of five consecutive digits is divisible by 3 or 5, then the digits  must have atleast a multiple of 3 i.e. 3,6 or 9 or 5 as one of the 5 digits. The only case where this would not be possible would be when the special digits {3,6,9,5} are all huddled at one end of the number taking 4 of the 9 available spaces. Now we have 4!=24 ways of arranging the four special digits and 5!=120 ways of arranging the remaining digits. Since the special digits can be huddled either at the end or at the start of the number, there would be twice the numbers not satisfying the condition specified in the question. That results in 2.4!.5!=5760 rebellious numbers. Since the total possible 9 digit numbers will be 9!=362880 , that leaves us with 362880-5760=357120 favourable outcomes. Therefore the required probability should be 357120/362880=0.984 However that's not the answer, the answer specified is 0.96 Can anybody please tell me where I went wrong? (Pardon my formatting skills :)","A nine digit number is formed using 1 to 9 without repetition, find the probability of forming a number such that the product of any of its five  consecutive digits is divisible by 3 or 5. Now my approach for solving this problem was to first find out the cases where this would not be possible. If the product of five consecutive digits is divisible by 3 or 5, then the digits  must have atleast a multiple of 3 i.e. 3,6 or 9 or 5 as one of the 5 digits. The only case where this would not be possible would be when the special digits {3,6,9,5} are all huddled at one end of the number taking 4 of the 9 available spaces. Now we have 4!=24 ways of arranging the four special digits and 5!=120 ways of arranging the remaining digits. Since the special digits can be huddled either at the end or at the start of the number, there would be twice the numbers not satisfying the condition specified in the question. That results in 2.4!.5!=5760 rebellious numbers. Since the total possible 9 digit numbers will be 9!=362880 , that leaves us with 362880-5760=357120 favourable outcomes. Therefore the required probability should be 357120/362880=0.984 However that's not the answer, the answer specified is 0.96 Can anybody please tell me where I went wrong? (Pardon my formatting skills :)",,"['probability', 'permutations', 'divisibility']"
13,Hoeffding type inequality for bounding deviation of a sequence,Hoeffding type inequality for bounding deviation of a sequence,,"I'm am trying to work out an Hoeffding type inequality for upper bounding $$\mathbb{P} \left\{ \bigcap_{n=1}^N \{S_n - \mathbb{E}[S_n] \geq nt\} \right\} $$ where $S_n = \sum_{i=1}^n X_i$ , $X_k$ are iid (note that $S_{n+1}$ and $S_n$ are dependent). We can assume that $X_k$ has bounded support for applying Hoeffding inequality but I can't figure out how to do it. My approach was to consider the complement of the event and to try and use union bound but that's too weak and I end up with a trivial upper bound greater than $1$ .","I'm am trying to work out an Hoeffding type inequality for upper bounding where , are iid (note that and are dependent). We can assume that has bounded support for applying Hoeffding inequality but I can't figure out how to do it. My approach was to consider the complement of the event and to try and use union bound but that's too weak and I end up with a trivial upper bound greater than .",\mathbb{P} \left\{ \bigcap_{n=1}^N \{S_n - \mathbb{E}[S_n] \geq nt\} \right\}  S_n = \sum_{i=1}^n X_i X_k S_{n+1} S_n X_k 1,"['probability', 'probability-theory', 'inequality']"
14,Why is this stochastic process a Markov chain?,Why is this stochastic process a Markov chain?,,"Suppose we have an independent sequence $(X_n)$ such that $P(X_n=1)=P(X_n=0)=\cfrac{1}{2}$ Let $M_n=(X_{n-1},X_n)$ . The exercise I'm working on supposes that $(M_n)_{n \ge 2}$ is a markov chain but it didn't make sense to me because if we have for example $M_4=(X_4,X_3)$ , $M_3=(X_3,X_2)$ , $M_2=(X_2,X_1)$ then $(M_n)$ is a markov chain iff $P(M_4=m_4 | M_3=m_3,M_2=(1,1))=P(M_4=m_4 | M_3=m_3)$ but that didn't make sense to me since the value of $M_3$ also depends on $M_2$ since they share $X_2$ . In other words, if we were to change $X_2$ in $M_2$ to $(0,1)$ then wouldn't $M_3$ change? What am I getting wrong exactly? Edit : Other than that problem, I was asked to give and graph the transition matrix $P$ . How am I going to do that given that the state space is $E=\{(0,0),(0,1),(1,0),(1,1)\}$","Suppose we have an independent sequence such that Let . The exercise I'm working on supposes that is a markov chain but it didn't make sense to me because if we have for example , , then is a markov chain iff but that didn't make sense to me since the value of also depends on since they share . In other words, if we were to change in to then wouldn't change? What am I getting wrong exactly? Edit : Other than that problem, I was asked to give and graph the transition matrix . How am I going to do that given that the state space is","(X_n) P(X_n=1)=P(X_n=0)=\cfrac{1}{2} M_n=(X_{n-1},X_n) (M_n)_{n \ge 2} M_4=(X_4,X_3) M_3=(X_3,X_2) M_2=(X_2,X_1) (M_n) P(M_4=m_4 | M_3=m_3,M_2=(1,1))=P(M_4=m_4 | M_3=m_3) M_3 M_2 X_2 X_2 M_2 (0,1) M_3 P E=\{(0,0),(0,1),(1,0),(1,1)\}","['probability', 'probability-distributions', 'stochastic-processes', 'markov-chains', 'conditional-probability']"
15,Quenched and Annealed measures,Quenched and Annealed measures,,"I apologise in advance if the question is too ""meta"". I'm trying to understand the difference of ""quenched"" and ""annealed"" in the following context: Suppose you have some random quantity $\Lambda$ , given by a law $\nu$ . We have a set of measures, depending on this random quantity $\Lambda$ , said ""quenched"" measures $P^\Lambda$ , defined for every $\Lambda$ . We define an annealed measure $$P(\cdot):=\int_{\Xi}P^\Lambda(\cdot) d\nu(\Lambda),$$ so the ""quenched"" version is a measure in a particular fixed $\Lambda$ , and the annealed is an average of the possible enviroments. A ""quenched"" result would be something like ""If [statement] then $P^\Lambda([event])>[something]$ for $\nu$ -almost every $\Lambda$ "" An ""annealed"" statement would be ""If [statement] then $P([event])>[something]$ "" My question is: How could a result be different for quenched and annealed measures if they are, in a sense, the same thing? In my particular situation I'm studying percolation on a random enviroment, where $\Lambda$ is a gives the random structure of the graph we're using. We're able to define $$p_c(\Lambda) = \sup\{p \in [0,1]: P^\Lambda_p(0 \leftrightarrow \infty)=0\}$$ and by ergodicity it's possible to show in that setting that $p_c$ is independent of $\Lambda$ . The question is, is it possible to find results that are true in a quenched setting and false in the annealed one? For instance, could we find exponential decay below $p_c$ in a quenched setting, whereas in the annealed version that's impossible?","I apologise in advance if the question is too ""meta"". I'm trying to understand the difference of ""quenched"" and ""annealed"" in the following context: Suppose you have some random quantity , given by a law . We have a set of measures, depending on this random quantity , said ""quenched"" measures , defined for every . We define an annealed measure so the ""quenched"" version is a measure in a particular fixed , and the annealed is an average of the possible enviroments. A ""quenched"" result would be something like ""If [statement] then for -almost every "" An ""annealed"" statement would be ""If [statement] then "" My question is: How could a result be different for quenched and annealed measures if they are, in a sense, the same thing? In my particular situation I'm studying percolation on a random enviroment, where is a gives the random structure of the graph we're using. We're able to define and by ergodicity it's possible to show in that setting that is independent of . The question is, is it possible to find results that are true in a quenched setting and false in the annealed one? For instance, could we find exponential decay below in a quenched setting, whereas in the annealed version that's impossible?","\Lambda \nu \Lambda P^\Lambda \Lambda P(\cdot):=\int_{\Xi}P^\Lambda(\cdot) d\nu(\Lambda), \Lambda P^\Lambda([event])>[something] \nu \Lambda P([event])>[something] \Lambda p_c(\Lambda) = \sup\{p \in [0,1]: P^\Lambda_p(0 \leftrightarrow \infty)=0\} p_c \Lambda p_c","['probability', 'percolation']"
16,Independent increments $\iff$ increments independent of natural filtration?,Independent increments  increments independent of natural filtration?,\iff,"Let $X=(X_t)_{t\in T}$ be a stochastic process with $X_0=0$ , and $(\mathcal{F}^X_t)_{t\in T}$ the natural filtration, that is, $\mathcal{F}^X_t=\sigma(X_r : r\le t)$ . Is it true that the following are equivalent? $X$ has independent increments, i.e. for $t_1<\ldots<t_n$ in $T$ we have $(X_{t_n}-X_{t_{n-1}}),\ldots (X_{t_2}-X_{t_1})$ are independent for every $s<t$ in $T$ we have $X_t-X_s$ is independent of $\mathcal{F}^X_s$ . For $1)\implies 2)$ I first thought I could just say that if $1)$ is true then $X_t-X_s$ independent of $X_r-0$ for every $r\le s$ and then conclude that $\sigma(X_t-X_s)$ is independent of $\sigma(X_r : r\le s)$ but it seems I cannot conclude this right away as I saw in this example . For $2)\implies 1)$ I was thinking that if $t_1<\ldots<t_n$ then $2)$ implies that $X_{t_n}-X_{t_{n-1}}$ is independent of $\sigma(X_r : r\le t_{n-1})$ . But then in particular $X_{t_n}-X_{t_{n-1}}$ is independent of $\sigma(X_{t_1},\ldots,X_{t_{n-1}})$ . But considering the measurable map $f(x_1,\ldots,x_{n-1})=(x_{n-1}-x_{n-2},\ldots,x_2-x_1)$ we get that $X_{t_n}-X_{t_{n-1}}$ is independent of $(X_{t_{n-1}}-X_{t_{n-2}},\ldots,X_{t_2}-X_{t_1})$ but I don't think think this allows me to conclude that all the increments are independent.","Let be a stochastic process with , and the natural filtration, that is, . Is it true that the following are equivalent? has independent increments, i.e. for in we have are independent for every in we have is independent of . For I first thought I could just say that if is true then independent of for every and then conclude that is independent of but it seems I cannot conclude this right away as I saw in this example . For I was thinking that if then implies that is independent of . But then in particular is independent of . But considering the measurable map we get that is independent of but I don't think think this allows me to conclude that all the increments are independent.","X=(X_t)_{t\in T} X_0=0 (\mathcal{F}^X_t)_{t\in T} \mathcal{F}^X_t=\sigma(X_r : r\le t) X t_1<\ldots<t_n T (X_{t_n}-X_{t_{n-1}}),\ldots (X_{t_2}-X_{t_1}) s<t T X_t-X_s \mathcal{F}^X_s 1)\implies 2) 1) X_t-X_s X_r-0 r\le s \sigma(X_t-X_s) \sigma(X_r : r\le s) 2)\implies 1) t_1<\ldots<t_n 2) X_{t_n}-X_{t_{n-1}} \sigma(X_r : r\le t_{n-1}) X_{t_n}-X_{t_{n-1}} \sigma(X_{t_1},\ldots,X_{t_{n-1}}) f(x_1,\ldots,x_{n-1})=(x_{n-1}-x_{n-2},\ldots,x_2-x_1) X_{t_n}-X_{t_{n-1}} (X_{t_{n-1}}-X_{t_{n-2}},\ldots,X_{t_2}-X_{t_1})","['probability', 'probability-theory', 'stochastic-processes', 'independence']"
17,Any bound on the Jensen's inequality with absolute value?,Any bound on the Jensen's inequality with absolute value?,,So we have the jensen's inequality: $$|EX| \leq E|X|$$ Any bound on the Jensen gap (upper bound or lower bound)? $$\text{gap}=E|X| - |EX|$$,So we have the jensen's inequality: Any bound on the Jensen gap (upper bound or lower bound)?,|EX| \leq E|X| \text{gap}=E|X| - |EX|,"['probability', 'probability-theory', 'random-variables', 'jensen-inequality']"
18,Why doesn't P(Calvin wins the match by winning 2 more games than his opponent) = $P(C|W_1)P(W_1)+P(C|L_1)P(L_1) = (p)(p) + (1-q)(q)$?,Why doesn't P(Calvin wins the match by winning 2 more games than his opponent) = ?,P(C|W_1)P(W_1)+P(C|L_1)P(L_1) = (p)(p) + (1-q)(q),"Calvin and Hobbes play a match consisting of a series of games, where Calvin has probability $p$ of winning each game (independently). They play with a “win by two” rule: the first player to win two games more than his opponent wins the match. Find the probability that Calvin wins the match (in terms of $p$ ), in two different ways. Blitzstein, Introduction to Probability (2019 2 edn), Chapter 2, Exercise 50, p 94. My attempt Let event $C$ be ""Calvin wins."" $$P(C) = P(C|W_1)P(W_1)+P(C|L_1)P(L_1) = (p)(p) + (1-q)(q)$$ This doesn't match the answer key, $\frac{p^2}{p^2+q^2}$ . I think the conceptual misunderstanding is $P(C|W_1)$ , $P(C|L_1)$ . For $P(C|W_1)$ , my thinking is: if we interpret this problem as the gambler ruin's problem, $i$ is originally at 2, but given that $W_1$ , we have that $i=3$ . Thus, because C occurring corresponds to $i=4$ , $$P(C|W_1) = \text{ (the probability that we move from } i=3 \text{ to } i = 4) = p$$ The same goes for $P(C|L_1)$ : $i$ is originally at 2, but given that $L_1$ , we have that $i=1$ . Thus, because C not occurring corresponds to $i=0$ , $$P(C|L_1) = 1 - P(C^c|L_1) = 1 -\text{ (the probability that we move from } i=1 \text{ to } i = 0) = 1-q$$ I know this is wrong because the gambler ruin's problem would interpret, for example, $P(C|W_1) = p_{i+1}$ . When I first learned the gambler ruin's problem, this made sense. However, now that I'm actually doing a problem that's kind of related, I'm left questioning this: why can't we just $P(C|W_1) = p^{n-i-1}$ , where $n$ represents the # of wins to win the series, $i$ is the original starting spot, and one represents winning the first game And yet, I also don't think the gambler's ruin problem totally applies here; the biggest difference is that given $W_1$ or $L_1$ , the important thing is that we are one spot away from the edge, so the probability of winning or losing one spot from the edge is either $p$ or $q$ , whereas if we were at an $i$ in the ""middle,"" $i$ can shift left, right, and back left, and left some more.","Calvin and Hobbes play a match consisting of a series of games, where Calvin has probability of winning each game (independently). They play with a “win by two” rule: the first player to win two games more than his opponent wins the match. Find the probability that Calvin wins the match (in terms of ), in two different ways. Blitzstein, Introduction to Probability (2019 2 edn), Chapter 2, Exercise 50, p 94. My attempt Let event be ""Calvin wins."" This doesn't match the answer key, . I think the conceptual misunderstanding is , . For , my thinking is: if we interpret this problem as the gambler ruin's problem, is originally at 2, but given that , we have that . Thus, because C occurring corresponds to , The same goes for : is originally at 2, but given that , we have that . Thus, because C not occurring corresponds to , I know this is wrong because the gambler ruin's problem would interpret, for example, . When I first learned the gambler ruin's problem, this made sense. However, now that I'm actually doing a problem that's kind of related, I'm left questioning this: why can't we just , where represents the # of wins to win the series, is the original starting spot, and one represents winning the first game And yet, I also don't think the gambler's ruin problem totally applies here; the biggest difference is that given or , the important thing is that we are one spot away from the edge, so the probability of winning or losing one spot from the edge is either or , whereas if we were at an in the ""middle,"" can shift left, right, and back left, and left some more.",p p C P(C) = P(C|W_1)P(W_1)+P(C|L_1)P(L_1) = (p)(p) + (1-q)(q) \frac{p^2}{p^2+q^2} P(C|W_1) P(C|L_1) P(C|W_1) i W_1 i=3 i=4 P(C|W_1) = \text{ (the probability that we move from } i=3 \text{ to } i = 4) = p P(C|L_1) i L_1 i=1 i=0 P(C|L_1) = 1 - P(C^c|L_1) = 1 -\text{ (the probability that we move from } i=1 \text{ to } i = 0) = 1-q P(C|W_1) = p_{i+1} P(C|W_1) = p^{n-i-1} n i W_1 L_1 p q i i,"['probability', 'gambling']"
19,How can we think of the codomain (range) of a probability density function?,How can we think of the codomain (range) of a probability density function?,,"Let $f$ be a probability density function (PDF) with domain $D$ . How do you think about the codomain (range) of $f$ ? I'm only able to make sense of this when considering $f$ on an interval; $\int f(x) \newcommand{\dx}{\,\mathrm{d}x}\dx$ makes sense, but $f(x)$ does not. Is this the quirk that defining distributions/generalized functions solves? This is the mental block I've hit trying to make the leap from a discrete random variable to a continuous random variable. For example, if your random variable is height in inches and $\int_{(a,b)} f(x) \dx$ gives you the proportion of people in your sample with a height in inches between $a$ and $b$ , then the units on $f(x)$ must be something like percent per inch , and I can't wrap my head around that.","Let be a probability density function (PDF) with domain . How do you think about the codomain (range) of ? I'm only able to make sense of this when considering on an interval; makes sense, but does not. Is this the quirk that defining distributions/generalized functions solves? This is the mental block I've hit trying to make the leap from a discrete random variable to a continuous random variable. For example, if your random variable is height in inches and gives you the proportion of people in your sample with a height in inches between and , then the units on must be something like percent per inch , and I can't wrap my head around that.","f D f f \int f(x) \newcommand{\dx}{\,\mathrm{d}x}\dx f(x) \int_{(a,b)} f(x) \dx a b f(x)","['probability', 'probability-distributions', 'intuition', 'density-function', 'unit-of-measure']"
20,Does squeeze theorem apply for almost sure convergence,Does squeeze theorem apply for almost sure convergence,,"Suppose we are given that $X'_n \leq Z_n \leq X_n$ for random variables $X'_n,Z_n, X_n$ . If we are told that $X_n,X'_n$ converges almost surely to some random variable $Y$ , can we conclude that $Z_n \stackrel{a.s}{\to}Y$ ? The closest variant of this question that I have seen is Squeeze theorem for convergence in distribution . I've considered $\{\omega: \lim_{n \to \infty}Z_n(\omega)=Y(\omega)\}$ , and realized that this set is a superset of the intersection of $\{X_n(\omega)=Y\}$ and $\{X'_n(\omega)=Y\}$ (due to the inequality), but that doesn't allow us to conclude that $Pr(\{\omega: \lim_{n \to \infty}Z_n(\omega)=Y(\omega)\})=1$ unfortunately.","Suppose we are given that for random variables . If we are told that converges almost surely to some random variable , can we conclude that ? The closest variant of this question that I have seen is Squeeze theorem for convergence in distribution . I've considered , and realized that this set is a superset of the intersection of and (due to the inequality), but that doesn't allow us to conclude that unfortunately.","X'_n \leq Z_n \leq X_n X'_n,Z_n, X_n X_n,X'_n Y Z_n \stackrel{a.s}{\to}Y \{\omega: \lim_{n \to \infty}Z_n(\omega)=Y(\omega)\} \{X_n(\omega)=Y\} \{X'_n(\omega)=Y\} Pr(\{\omega: \lim_{n \to \infty}Z_n(\omega)=Y(\omega)\})=1","['probability', 'pointwise-convergence', 'almost-everywhere']"
21,Shannon's proof that joint entropy is less or equal to the sum of marginal entropies,Shannon's proof that joint entropy is less or equal to the sum of marginal entropies,,"I am reading Shannon's famous paper and I stuck on ""It is easily shown that"" part. More precisely I mean the inequality $$H(X, Y)\leq H(X) + H(Y),$$ where $X, Y$ are some discrete random variables. Following the paper we have that $$H(X,Y)=-\sum_{ij}p(i, j)\log(p(i,j)) \\  H(X)=-\sum_{ij}p(i, j)\log\left(\sum_{k}p(i,k)\right) \\ H(Y)=-\sum_{ij}p(i, j)\log\left(\sum_{l}p(l,j)\right)$$ And if we sum $H(X) + H(Y)$ we get that $$H(X) + H(Y) = -\sum_{ij}p(i, j)\log(p(i)p(j)).$$ And this is where I stuck. It is obvious from the above that if $X,Y$ are independent then the equality holds. However, the inequality is a different story. In general $p(i,j)$ and $p(i)p(j)$ are incomparable by simple inequality, thus some other methods must be used. What is the most straightforward proof of this inequality? (Or if one knows, what proof Shannon had in mind?). Shannon states the inequality before defining conditional entropy $H_X(Y)$ so I suspect that it in fact this should be easy... or did he lie?","I am reading Shannon's famous paper and I stuck on ""It is easily shown that"" part. More precisely I mean the inequality where are some discrete random variables. Following the paper we have that And if we sum we get that And this is where I stuck. It is obvious from the above that if are independent then the equality holds. However, the inequality is a different story. In general and are incomparable by simple inequality, thus some other methods must be used. What is the most straightforward proof of this inequality? (Or if one knows, what proof Shannon had in mind?). Shannon states the inequality before defining conditional entropy so I suspect that it in fact this should be easy... or did he lie?","H(X, Y)\leq H(X) + H(Y), X, Y H(X,Y)=-\sum_{ij}p(i, j)\log(p(i,j)) \\ 
H(X)=-\sum_{ij}p(i, j)\log\left(\sum_{k}p(i,k)\right) \\
H(Y)=-\sum_{ij}p(i, j)\log\left(\sum_{l}p(l,j)\right) H(X) + H(Y) H(X) + H(Y) = -\sum_{ij}p(i, j)\log(p(i)p(j)). X,Y p(i,j) p(i)p(j) H_X(Y)","['probability', 'information-theory', 'entropy']"
22,The Probabilistic Method: proving existence of functions satisfying certain property,The Probabilistic Method: proving existence of functions satisfying certain property,,"Let $\mathcal{X}$ be a subset of $\mathbb{R}^n$ and let $\mathcal{F}$ be a space of functions: $$\mathcal{F} = \{f | f: \mathcal{X} \to \mathbb{R} \}$$ Let $P_\mathcal{X}$ be a probability distribution over $\mathcal{X}$ and let $P_\mathcal{F}$ be a probability distribution over $\mathcal{F}$ . Consider $$\mathbb{P} \left( F(X^n) > a \right)$$ where $F$ is a random function picked according to $P_\mathcal{F}$ and $X^n$ is a random sequence picked according to $P_\mathcal{X}$ . Now suppose I showed that $$\mathbb{P} \left( F(X^n) > a \right) \leq \frac{1}{n}$$ This implies (for $n \geq 2$ ) that there exists a deterministic function $f$ and a deterministic $x^n \in \mathcal{X}$ such that $f(x^n) \leq a$ . But I want to make the following statement: for sufficiently large $n$ , there exists a deterministic function $f$ such that with high probability, $f(X^n) \leq a$ , where $X^n$ is random. I call this partial derandomization. Can I make this statement from what I have? If not, what other ways I could explore? PS: $\mathcal{X}$ is compact.","Let be a subset of and let be a space of functions: Let be a probability distribution over and let be a probability distribution over . Consider where is a random function picked according to and is a random sequence picked according to . Now suppose I showed that This implies (for ) that there exists a deterministic function and a deterministic such that . But I want to make the following statement: for sufficiently large , there exists a deterministic function such that with high probability, , where is random. I call this partial derandomization. Can I make this statement from what I have? If not, what other ways I could explore? PS: is compact.",\mathcal{X} \mathbb{R}^n \mathcal{F} \mathcal{F} = \{f | f: \mathcal{X} \to \mathbb{R} \} P_\mathcal{X} \mathcal{X} P_\mathcal{F} \mathcal{F} \mathbb{P} \left( F(X^n) > a \right) F P_\mathcal{F} X^n P_\mathcal{X} \mathbb{P} \left( F(X^n) > a \right) \leq \frac{1}{n} n \geq 2 f x^n \in \mathcal{X} f(x^n) \leq a n f f(X^n) \leq a X^n \mathcal{X},"['probability', 'functions', 'random', 'probabilistic-method']"
23,Threshold probability of the 3-uniform hypertriangle,Threshold probability of the 3-uniform hypertriangle,,"I am stuck on a random hypergraph problem (I am encountering random hypergraphs for the very first time). Let $G_{3}(n, p)$ be a binomial 3-uniform hypergraph. Find a threshold probability for containing a 3-uniform hypertriangle. What I have tried: I saw a similar problem for the existence of triangles in $G(n, d/n)$ . I am trying the same technique here for the hypergraphs. So according to my calculations I am getting $E[x]=\binom{n}{6}p^{3}$ , where $x$ is the number of hypergraphs. Then for the variance part, I get here 5 cases: when the number of common edges are : (i) up to 2, in which case its contribution is $E^{2}[x]$ , (ii) 3, the contribution is $\binom{n}{9}p^{6}$ , (iii) 4, the contribution is $\binom{n}{8}p^{5}$ , (iv) 5, the contribution is $\binom{n}{7}p^{4}$ and (v) 6, the contribution is $\binom{n}{6}p^{3}$ . After this, I do not know how to proceed and somehow, I feel that all this is completely wrong and something entirely different needs to be done for hypergraphs. Any suggestions would be helpful. Thanks in advance. $\textbf{Edit}$ : A 3-uniform hypergraph is a pair $(V, E)$ , where $V$ is a set of its vertices, and $E\subset\binom{V}{3}$ is a set of its edges. And a 3-uniform hypertriangle is a 3-uniform hypergraph with $|V | = 6$ with three edges such that every pair of edges share 1 vertex, and all three edges do not have a common vertex. $G_{3}(n, p)$ is a binomial 3-uniform hypergraph such that $V = \{1, . . . , n\}$ and every hyperedge is chosen independently with probability $p$ . And I got my ideas from a similar calculation for graphs on page 6 of this link : https://www.cs.cmu.edu/~avrim/598/chap4only.pdf","I am stuck on a random hypergraph problem (I am encountering random hypergraphs for the very first time). Let be a binomial 3-uniform hypergraph. Find a threshold probability for containing a 3-uniform hypertriangle. What I have tried: I saw a similar problem for the existence of triangles in . I am trying the same technique here for the hypergraphs. So according to my calculations I am getting , where is the number of hypergraphs. Then for the variance part, I get here 5 cases: when the number of common edges are : (i) up to 2, in which case its contribution is , (ii) 3, the contribution is , (iii) 4, the contribution is , (iv) 5, the contribution is and (v) 6, the contribution is . After this, I do not know how to proceed and somehow, I feel that all this is completely wrong and something entirely different needs to be done for hypergraphs. Any suggestions would be helpful. Thanks in advance. : A 3-uniform hypergraph is a pair , where is a set of its vertices, and is a set of its edges. And a 3-uniform hypertriangle is a 3-uniform hypergraph with with three edges such that every pair of edges share 1 vertex, and all three edges do not have a common vertex. is a binomial 3-uniform hypergraph such that and every hyperedge is chosen independently with probability . And I got my ideas from a similar calculation for graphs on page 6 of this link : https://www.cs.cmu.edu/~avrim/598/chap4only.pdf","G_{3}(n, p) G(n, d/n) E[x]=\binom{n}{6}p^{3} x E^{2}[x] \binom{n}{9}p^{6} \binom{n}{8}p^{5} \binom{n}{7}p^{4} \binom{n}{6}p^{3} \textbf{Edit} (V, E) V E\subset\binom{V}{3} |V | = 6 G_{3}(n, p) V = \{1, . . . , n\} p","['probability', 'probability-theory', 'graph-theory', 'random-graphs', 'hypergraphs']"
24,"$X$ is independent of $\mathcal{G}$, $f(X ,Y)$ is independent of $Y$, $Y$ is $\mathcal{G}$-measurable, then $f(X,Y)$ is independent of $\mathcal{G}$?","is independent of ,  is independent of ,  is -measurable, then  is independent of ?","X \mathcal{G} f(X ,Y) Y Y \mathcal{G} f(X,Y) \mathcal{G}","Let $(\Omega, \mathcal{F}, P)$ be a probability space, $\mathcal{G}\subset \mathcal{F}$ be a sigma algebra, $X, Y : \Omega \to \mathbb{R}^n$ be random vectors, and $f$ be a measurable function on $\mathbb{R}^{2n}$ . Suppose that $X$ is independent of $\mathcal{G}$ , $f(X ,Y)$ is independent of $Y$ , and $Y$ is $\mathcal{G}$ -measurable. Is it true that $f(X,Y)$ is independent of $\mathcal{G}$ ? Motivation: This question arises from a randomized algorithm. In this algorithm, each iteration receives some randomness that is independent of the previous iterations. In my question, $\mathcal{G}$ indeed represents the randomness of the algorithm up to iteration $k$ , $Y$ is a vector generated by iteration $k$ , $X$ is some new randomness injected into the algorithm at iteration $k+1$ , and $f(X,Y)$ is a quantity computed from $X$ and $Y$ . It turns out that $f(X,Y)$ is statistically independent of $Y$ . I would like to prove that $f(X,Y)$ is independent of the first $k$ iterations, which will be interesting and convenient. Any comments or criticism will be appreciated. Thank you. A related question: Uniform distribution on the unit sphere rotated by a random orthogonal matrix .","Let be a probability space, be a sigma algebra, be random vectors, and be a measurable function on . Suppose that is independent of , is independent of , and is -measurable. Is it true that is independent of ? Motivation: This question arises from a randomized algorithm. In this algorithm, each iteration receives some randomness that is independent of the previous iterations. In my question, indeed represents the randomness of the algorithm up to iteration , is a vector generated by iteration , is some new randomness injected into the algorithm at iteration , and is a quantity computed from and . It turns out that is statistically independent of . I would like to prove that is independent of the first iterations, which will be interesting and convenient. Any comments or criticism will be appreciated. Thank you. A related question: Uniform distribution on the unit sphere rotated by a random orthogonal matrix .","(\Omega, \mathcal{F}, P) \mathcal{G}\subset \mathcal{F} X, Y : \Omega \to \mathbb{R}^n f \mathbb{R}^{2n} X \mathcal{G} f(X ,Y) Y Y \mathcal{G} f(X,Y) \mathcal{G} \mathcal{G} k Y k X k+1 f(X,Y) X Y f(X,Y) Y f(X,Y) k","['probability', 'probability-theory', 'stochastic-processes', 'independence', 'stochastic-analysis']"
25,How to prove $P\left(\cup_{i=1}^{\infty}A_i\right)=1$ implies that $P(\{A_i\ i.o.\})=1$,How to prove  implies that,P\left(\cup_{i=1}^{\infty}A_i\right)=1 P(\{A_i\ i.o.\})=1,"Suppose that $\{A_i\}$ is a sequence of independent events with $P\left(\bigcup_{i=1}^\infty A_i\right) = 1$ and $P(A_i)<1$ for all $i\in \mathbb{N}$ . Show that $$ P(A_i \text{ occurs infinitely often})=1  $$ My attempt: We only need to show $P\left(\cap_{i=1}^{\infty} A_i^c \right)=0 \Longrightarrow P(A_i\ i.o.)=1$ . Note that $$ \begin{aligned} P\left(\cap_{i=1}^{\infty} A_i^c \right)&= \prod_{i=1}^{\infty}P(A_i^c)&&\text{(independence)}\\ &= \prod_{i=1}^{\infty}(1-P(A_i)) \end{aligned} $$ For any $k$ , we have \begin{aligned} P\left(\cap_{i=1}^{k} A_i^c \right)&= \prod_{i=1}^{k}P(A_i^c)\\ &= \prod_{i=1}^{k}(1-P(A_i))\\ &\leq \prod_{i=1}^k e^{-P(A_i)}\quad(1-x\leq e^{-x}) \\ &=e^{-\sum_{i=1}^kP(A_i)} \end{aligned} Let $k \to \infty$ , then $0=P\left(\cap_{i=1}^{\infty} A_i^c \right)\leq e^{-\sum_{i=1}^{\infty}P(A_i)}$ . If we can show $e^{-\sum_{i=1}^{\infty}P(A_i)}=0$ , which implies that $\sum_{i=1}^{\infty}P(A_i)=\infty$ , then the result follows by the second Borel-Cantelli Lemma. My question is how to show $e^{-\sum_{i=1}^{\infty}P(A_i)}=0$ . If we cannot, is there any other way to prove this result? I would appreciate if you could explain in details.","Suppose that is a sequence of independent events with and for all . Show that My attempt: We only need to show . Note that For any , we have Let , then . If we can show , which implies that , then the result follows by the second Borel-Cantelli Lemma. My question is how to show . If we cannot, is there any other way to prove this result? I would appreciate if you could explain in details.","\{A_i\} P\left(\bigcup_{i=1}^\infty A_i\right) = 1 P(A_i)<1 i\in \mathbb{N} 
P(A_i \text{ occurs infinitely often})=1 
 P\left(\cap_{i=1}^{\infty} A_i^c \right)=0 \Longrightarrow P(A_i\ i.o.)=1 
\begin{aligned}
P\left(\cap_{i=1}^{\infty} A_i^c \right)&= \prod_{i=1}^{\infty}P(A_i^c)&&\text{(independence)}\\
&= \prod_{i=1}^{\infty}(1-P(A_i))
\end{aligned}
 k \begin{aligned}
P\left(\cap_{i=1}^{k} A_i^c \right)&= \prod_{i=1}^{k}P(A_i^c)\\
&= \prod_{i=1}^{k}(1-P(A_i))\\
&\leq \prod_{i=1}^k e^{-P(A_i)}\quad(1-x\leq e^{-x}) \\
&=e^{-\sum_{i=1}^kP(A_i)}
\end{aligned} k \to \infty 0=P\left(\cap_{i=1}^{\infty} A_i^c \right)\leq e^{-\sum_{i=1}^{\infty}P(A_i)} e^{-\sum_{i=1}^{\infty}P(A_i)}=0 \sum_{i=1}^{\infty}P(A_i)=\infty e^{-\sum_{i=1}^{\infty}P(A_i)}=0","['probability', 'probability-theory']"
26,Riemann–Stieltjes Integral for Multivariate Functions,Riemann–Stieltjes Integral for Multivariate Functions,,"Given two (sufficiently good) single-variable functions \begin{equation}f, g: [a,b] \mapsto \mathbb{R}, \text{ here } a,b \in \mathbb{R}\end{equation} the Riemann–Stieltjes integral is defined as \begin{equation} \int_{a}^{b} f \,dg = \lim_{N\to\infty} \sum_{i=1}^N f\left(a+i\Delta_N\right)\left[ g\left(a+i\Delta_N\right) - g\left(a+(i-1)\Delta_N\right) \right], \\\quad \text{here } \Delta_N=\frac{b-a}{N} \end{equation} I was wondering if there is a Riemann-Stieltjes integral definition for multivariate case, e.g. how to define $\int_S f \, dg$ for multivariate functions, e.g. when both $f, g: S \mapsto \mathbb{R}$ , where $S \subset \mathbb{R}^n $ ? (We can assume $S$ is a hyper-rectangle for simplicity.) This question has arisen from the problem of how to calculate the mean of a function of random vector. E.g., having a random vector $X: \Omega \mapsto \mathbb{R}^n$ with an arbitrary cdf $F_X$ and given a function $g: \mathbb{R}^n \mapsto \mathbb{R}$ , how to numerically approximate $\mathbb{E}[g(X)] = \int_{\mathbb{R}^n} g(x) \, dF_X(x)$ ?","Given two (sufficiently good) single-variable functions the Riemann–Stieltjes integral is defined as I was wondering if there is a Riemann-Stieltjes integral definition for multivariate case, e.g. how to define for multivariate functions, e.g. when both , where ? (We can assume is a hyper-rectangle for simplicity.) This question has arisen from the problem of how to calculate the mean of a function of random vector. E.g., having a random vector with an arbitrary cdf and given a function , how to numerically approximate ?","\begin{equation}f, g: [a,b] \mapsto \mathbb{R}, \text{ here } a,b \in \mathbb{R}\end{equation} \begin{equation}
\int_{a}^{b} f \,dg = \lim_{N\to\infty} \sum_{i=1}^N f\left(a+i\Delta_N\right)\left[ g\left(a+i\Delta_N\right) - g\left(a+(i-1)\Delta_N\right) \right], \\\quad \text{here } \Delta_N=\frac{b-a}{N}
\end{equation} \int_S f \, dg f, g: S \mapsto \mathbb{R} S \subset \mathbb{R}^n  S X: \Omega \mapsto \mathbb{R}^n F_X g: \mathbb{R}^n \mapsto \mathbb{R} \mathbb{E}[g(X)] = \int_{\mathbb{R}^n} g(x) \, dF_X(x)","['probability', 'integration', 'riemann-integration', 'means']"
27,The best way to put balls into boxes,The best way to put balls into boxes,,"There are $36$ identical balls, $12$ boxes numbered $1$ to $12$ , and two $6$ -sided dice. You start by placing each of the balls into one of the boxes. You then repeatedly roll the dice and take a ball from the box numbered with their sum. If there isn't any ball in that box, you just skip the round. What is the best strategy to assign the balls to minimize the expected number of rounds needed to take all balls out? I know how to use min-max Inclusion–exclusion principle to solve the problem which the balls are already assigned. But is there an effecient way to find out the best strategy? And if there is a way to answer the question when the possibility to take a ball from the i-th box is $p_i$ . Thank you for your time.","There are identical balls, boxes numbered to , and two -sided dice. You start by placing each of the balls into one of the boxes. You then repeatedly roll the dice and take a ball from the box numbered with their sum. If there isn't any ball in that box, you just skip the round. What is the best strategy to assign the balls to minimize the expected number of rounds needed to take all balls out? I know how to use min-max Inclusion–exclusion principle to solve the problem which the balls are already assigned. But is there an effecient way to find out the best strategy? And if there is a way to answer the question when the possibility to take a ball from the i-th box is . Thank you for your time.",36 12 1 12 6 p_i,"['probability', 'combinatorics', 'expected-value']"
28,"Let $B$ have distribution $\text{Binomial}(n,p)$. Then what is $ \lim_{n \to \infty} \mathsf P\left[ \frac{B}{n} < p\right]$",Let  have distribution . Then what is,"B \text{Binomial}(n,p)  \lim_{n \to \infty} \mathsf P\left[ \frac{B}{n} < p\right]","Let $B$ have distribution $\text{Binomial}(n,p)$ . What is the tool for analysing $$ \lim_{n \to \infty} \mathsf P\left[ \frac{B}{n} < p\right]$$ ? I think the answer should be $ \lim_{n \to \infty} \mathsf P\left[ \frac{B}{n} < p\right]=\frac{1}{2}$ . My reasoning is that $np$ is roughly the median of $B$ hence the limit should be $1/2$ .  However, I would like to see a proper proof.","Let have distribution . What is the tool for analysing ? I think the answer should be . My reasoning is that is roughly the median of hence the limit should be .  However, I would like to see a proper proof.","B \text{Binomial}(n,p)  \lim_{n \to \infty} \mathsf P\left[ \frac{B}{n} < p\right]  \lim_{n \to \infty} \mathsf P\left[ \frac{B}{n} < p\right]=\frac{1}{2} np B 1/2","['probability', 'probability-theory']"
29,Finding the expected value of a quadratic transformation,Finding the expected value of a quadratic transformation,,"I am given that X is a random variable with a mean of two and variance of 4, as per the question: So, I try to solve the problem by expanding $E[x+2]^2$ $$E[x+2]^2 = E[x+2] * E[x+2]$$ $$E[x+2] = E[x] + E[2] = 2 + 2 = 4$$ $$E[x+2]^2 = 4*4=16$$ However, the answer is 16. I think I am missing something obvious, but I haven't been able to figure it out. Does anyone know why?","I am given that X is a random variable with a mean of two and variance of 4, as per the question: So, I try to solve the problem by expanding However, the answer is 16. I think I am missing something obvious, but I haven't been able to figure it out. Does anyone know why?",E[x+2]^2 E[x+2]^2 = E[x+2] * E[x+2] E[x+2] = E[x] + E[2] = 2 + 2 = 4 E[x+2]^2 = 4*4=16,"['probability', 'expected-value']"
30,Stuck on probability/statistics question,Stuck on probability/statistics question,,"EDIT: Post as been edited to address relevant questions raised in comments. I'm new to the site and I'm stuck on a probability question.  I don't think it's trivial, certainly not to me, as I am relying on a single probability and statistics class I took 20 years ago...  The problem is this: Imagine there are 10 white squares (the number of white squares is not terribly important other than it has to be 5 or greater). The probability of turning a white square black is 25% per attempt. The goal is to maximize the number of black squares you get. You have 10 ""moves"" to do so. Attempting to turn a white square black uses one move. Moving from one square to another also uses one move. You send in your ""moves"" in batches of 10 and, therefore, you cannot adjust subsequent moves regardless of the results of previous moves. Attempting to convert a square that you had previously successfully converted from white to black does not revert it back to white. It just means you wasted a move trying to convert an already black square. How would I even start figuring out the best way to maximize the number of black squares I get (i.e., how many attempts per square before moving to the next square)? Thank you very much!","EDIT: Post as been edited to address relevant questions raised in comments. I'm new to the site and I'm stuck on a probability question.  I don't think it's trivial, certainly not to me, as I am relying on a single probability and statistics class I took 20 years ago...  The problem is this: Imagine there are 10 white squares (the number of white squares is not terribly important other than it has to be 5 or greater). The probability of turning a white square black is 25% per attempt. The goal is to maximize the number of black squares you get. You have 10 ""moves"" to do so. Attempting to turn a white square black uses one move. Moving from one square to another also uses one move. You send in your ""moves"" in batches of 10 and, therefore, you cannot adjust subsequent moves regardless of the results of previous moves. Attempting to convert a square that you had previously successfully converted from white to black does not revert it back to white. It just means you wasted a move trying to convert an already black square. How would I even start figuring out the best way to maximize the number of black squares I get (i.e., how many attempts per square before moving to the next square)? Thank you very much!",,"['probability', 'statistics']"
31,Convergence in distribution-topological interpretation,Convergence in distribution-topological interpretation,,"There are various definitions of convergence of measurable functions: some of them have clear topological interpretation (as coming from suitable norm or metric-for example convergence in $L^p$ or convergence in probability) while some of them not (convergence almost surely does not come from any topology). I would like to understand the notion of convergence in distribution from the point of view of topology. Some properties which shows that one has to be careful are as follows: -one can have two different random variables $X,Y$ which have the same distributions: thus the sequence $X,Y,X,Y,X,Y,...$ would be convergent and have two limits $X,Y$ -this contradicts Hausdorff property (or even being $T_1$ ) -one can have even two different measure spaces $(\Omega_1,\mathcal{F}_1,P_1),(\Omega_2,\mathcal{F}_2,P_2)$ on which $X$ and $Y$ are defined and still they can have the same distribution. Therefore it is not clear on which space should those random variables act (should it be fixed or not?). So to summarize: Does convergence in distribution comes from some topology (Hausdorff topology?) and if the answer is ,,yes'' what is the underlying set on which this topology is defined?","There are various definitions of convergence of measurable functions: some of them have clear topological interpretation (as coming from suitable norm or metric-for example convergence in or convergence in probability) while some of them not (convergence almost surely does not come from any topology). I would like to understand the notion of convergence in distribution from the point of view of topology. Some properties which shows that one has to be careful are as follows: -one can have two different random variables which have the same distributions: thus the sequence would be convergent and have two limits -this contradicts Hausdorff property (or even being ) -one can have even two different measure spaces on which and are defined and still they can have the same distribution. Therefore it is not clear on which space should those random variables act (should it be fixed or not?). So to summarize: Does convergence in distribution comes from some topology (Hausdorff topology?) and if the answer is ,,yes'' what is the underlying set on which this topology is defined?","L^p X,Y X,Y,X,Y,X,Y,... X,Y T_1 (\Omega_1,\mathcal{F}_1,P_1),(\Omega_2,\mathcal{F}_2,P_2) X Y","['probability', 'general-topology', 'probability-distributions', 'random-variables']"
32,Is it true that $E[|X-E[X]|^j] \le E[|X|^j]$?,Is it true that ?,E[|X-E[X]|^j] \le E[|X|^j],"Let $X$ be a random variable and let $j\in\mathbf{N}$ whith $j >2$ , is it true that $$E[|X-E[X]|^j] \leq E[|X|^j]\quad?$$","Let be a random variable and let whith , is it true that",X j\in\mathbf{N} j >2 E[|X-E[X]|^j] \leq E[|X|^j]\quad?,"['probability', 'inequality', 'convex-analysis', 'expected-value']"
33,The probability for two random variables to be independent,The probability for two random variables to be independent,,"I'm learning probability, and many theorems start by assuming that you have a set of mutually independent random variables. However, The condition that two random variables are independent seems to me quite restrictive. Is it? For example: Suppose $(\Omega,p)$ is a finite uniform probability space. How many   pairs of random variables with range in $\{0,1\}$ are   independent?. Does their proportion to the total number of pairs grow as the size of $\Omega$ grows? Thanks","I'm learning probability, and many theorems start by assuming that you have a set of mutually independent random variables. However, The condition that two random variables are independent seems to me quite restrictive. Is it? For example: Suppose is a finite uniform probability space. How many   pairs of random variables with range in are   independent?. Does their proportion to the total number of pairs grow as the size of grows? Thanks","(\Omega,p) \{0,1\} \Omega","['probability', 'probability-theory']"
34,Probability question about meeting people,Probability question about meeting people,,"Here is the problem: You go to a school that last 3 years, and you start in the first year. You meet one new random person everyday and there are 300 days in the school year. In every year, there are 200 people (Do not include yourself as one of them), and so every year the people in the highest year leave and 200 newcomers leave. The question is ""What is probability that you will run out people to meet in school before you leave it?"" For example - In the first year you meet the 200 people in your year and 100 in the year above. Then, next year, you meet all 200 people in the new year below you and another 100 from the year above. In your final year, there are only 200 new people joining the school and you talk to them but you still have 100 days in the year left and so you lost. However, if you had started with the highest year and talked to them and 100 from the year above, then next year you would talk to the 100 remaining from the year above and the 200 in your year, and in the final year you have 400 people to talk to within 300 days, so you would win with 100 to spare.","Here is the problem: You go to a school that last 3 years, and you start in the first year. You meet one new random person everyday and there are 300 days in the school year. In every year, there are 200 people (Do not include yourself as one of them), and so every year the people in the highest year leave and 200 newcomers leave. The question is ""What is probability that you will run out people to meet in school before you leave it?"" For example - In the first year you meet the 200 people in your year and 100 in the year above. Then, next year, you meet all 200 people in the new year below you and another 100 from the year above. In your final year, there are only 200 new people joining the school and you talk to them but you still have 100 days in the year left and so you lost. However, if you had started with the highest year and talked to them and 100 from the year above, then next year you would talk to the 100 remaining from the year above and the 200 in your year, and in the final year you have 400 people to talk to within 300 days, so you would win with 100 to spare.",,"['probability', 'analysis', 'recreational-mathematics', 'puzzle']"
35,Covariance of maxima,Covariance of maxima,,"Let $X_1,\dots,X_n$ and $Y_1,\dots,Y_n$ be random variables. Is it true that \begin{align*} \text{Cov}(\max_i X_i, \max_j Y_j) \leq \sum_{i, j}|\text{Cov}(X_i,Y_j)| \end{align*} My intuition as to why this may be true is from the previous question: variance of maximum I believe the identity $2\text{Cov}(X,Y)=E(X-X')(Y-Y')$ should be relevant, where $(X',Y')$ is an independent copy of the couple $(X,Y)$ , but I'm not sure how to proceed, since we can no longer write the expected value as an integral of the tail probability (since $(X-X')(Y-Y')$ is not necessarily positive).  If needed, we may also assume that all variables are positively correlated with each other, and that they are each marginally distributed as bernoulli coin flips.  But hopefully the more general statement above is true on its own.","Let and be random variables. Is it true that My intuition as to why this may be true is from the previous question: variance of maximum I believe the identity should be relevant, where is an independent copy of the couple , but I'm not sure how to proceed, since we can no longer write the expected value as an integral of the tail probability (since is not necessarily positive).  If needed, we may also assume that all variables are positively correlated with each other, and that they are each marginally distributed as bernoulli coin flips.  But hopefully the more general statement above is true on its own.","X_1,\dots,X_n Y_1,\dots,Y_n \begin{align*}
\text{Cov}(\max_i X_i, \max_j Y_j) \leq \sum_{i, j}|\text{Cov}(X_i,Y_j)|
\end{align*} 2\text{Cov}(X,Y)=E(X-X')(Y-Y') (X',Y') (X,Y) (X-X')(Y-Y')","['probability', 'probability-theory', 'statistics']"
36,Variance of number of distinct values in a collection of iid discrete random variables,Variance of number of distinct values in a collection of iid discrete random variables,,"I'm struggling with the following problem. Let $X_i$ be iid discrete rvs, taking values in $\mathbb{N}$ with arbitrary distribution $\mathrm{P} (X_i = k) = p_k$ . Let $Z_n$ be a number of distinct values in $X_1, \ldots, X_n$ . I need to find its expectation and variance and compare it to Efron-Stein inequality estimate on variance. My reasoning is as follows: let $Y_i$ be indicator rv, assuming $1$ if $X_i$ has value different from $X_1, \ldots, X_{i - 1}$ . Then $$     \mathrm{P} (Y_i = 1) = \sum_{i = k}^{\infty} \mathrm{P} (Y_i = 1 | X_i = k) \mathrm{P} (X_i = k) = \\ = \sum_{k = 1}^{\infty} \mathrm{P} (X_1 \neq k, \ldots X_{i - 1} \neq k) \mathrm{P} (X_i = k) = \sum_{k = 1}^{\infty} (1 - p_k)^{i - 1} p_k. $$ Then, since $Z_n = \sum_{i = 1}^n Y_i$ : $$     \mathrm{E} Z_n = \sum_{i = 1}^n \mathrm{E} Y_i = \sum_{i = 1}^n \sum_{k = 1}^{\infty} (1 - p_k)^{i - 1} p_k. $$ So far so good. I checked my calculations with simulations from Poisson distribution - they agree very closely. Now to variance. Since $Z_n - Z_{n - 1}$ differs at most by one, for function with bounded differences by Efron-Stein inequality we have an estimation on variance: $$     \mathrm{Var} (Z_n) \leq \frac{n}{4}. $$ But I can't calculate variance analytically to compare it to estimation. Unfortunately, $Y_n$ and $Y_m$ are anti-correlated, so simple sum of separate variances won't do. I tried to calculate covariance, but ended up with rather messy formula. Any ideas how I can get a nice expression for $\mathrm{Var} (Z_n)$ ?","I'm struggling with the following problem. Let be iid discrete rvs, taking values in with arbitrary distribution . Let be a number of distinct values in . I need to find its expectation and variance and compare it to Efron-Stein inequality estimate on variance. My reasoning is as follows: let be indicator rv, assuming if has value different from . Then Then, since : So far so good. I checked my calculations with simulations from Poisson distribution - they agree very closely. Now to variance. Since differs at most by one, for function with bounded differences by Efron-Stein inequality we have an estimation on variance: But I can't calculate variance analytically to compare it to estimation. Unfortunately, and are anti-correlated, so simple sum of separate variances won't do. I tried to calculate covariance, but ended up with rather messy formula. Any ideas how I can get a nice expression for ?","X_i \mathbb{N} \mathrm{P} (X_i = k) = p_k Z_n X_1, \ldots, X_n Y_i 1 X_i X_1, \ldots, X_{i - 1} 
    \mathrm{P} (Y_i = 1) = \sum_{i = k}^{\infty} \mathrm{P} (Y_i = 1 | X_i = k) \mathrm{P} (X_i = k) = \\ = \sum_{k = 1}^{\infty} \mathrm{P} (X_1 \neq k, \ldots X_{i - 1} \neq k) \mathrm{P} (X_i = k) = \sum_{k = 1}^{\infty} (1 - p_k)^{i - 1} p_k.
 Z_n = \sum_{i = 1}^n Y_i 
    \mathrm{E} Z_n = \sum_{i = 1}^n \mathrm{E} Y_i = \sum_{i = 1}^n \sum_{k = 1}^{\infty} (1 - p_k)^{i - 1} p_k.
 Z_n - Z_{n - 1} 
    \mathrm{Var} (Z_n) \leq \frac{n}{4}.
 Y_n Y_m \mathrm{Var} (Z_n)","['probability', 'stochastic-processes', 'variance', 'concentration-of-measure']"
37,Possible draws in which exactly one player gets exactly one 8,Possible draws in which exactly one player gets exactly one 8,,"The card deck has 30 cards in three different colors. Cards of each color are numbered 1 to 10. Each player draws 4 cards. The order in which cards are drawn to players' hands is not important. The question is in how many possible draws exist in which exactly one player receives exactly one card which has the number 8 on it.  I thought that there are 2 players, for each player 3 options to draw the 8, $27 \choose 3$ for the three other cards for that player and another $24 \choose 4$ cards for the other player. This totals to 186,486,300 which is not the correct answer. Any guidance would be appreciated.","The card deck has 30 cards in three different colors. Cards of each color are numbered 1 to 10. Each player draws 4 cards. The order in which cards are drawn to players' hands is not important. The question is in how many possible draws exist in which exactly one player receives exactly one card which has the number 8 on it.  I thought that there are 2 players, for each player 3 options to draw the 8, for the three other cards for that player and another cards for the other player. This totals to 186,486,300 which is not the correct answer. Any guidance would be appreciated.",27 \choose 3 24 \choose 4,['probability']
38,Probability that a number passing the Fermat test is prime,Probability that a number passing the Fermat test is prime,,"I'm studying a computer science textbook that has a section on the Fermat test as an example of a probabilistic method. Given a number $n$ , the Fermat test is stated as pick a random number $a < n$ . If $a^n \equiv a\pmod n$ , chances are good that $n$ is prime. Else, $n$ is certainly not prime. Excepting the Carmichael numbers, the book goes on to say: one can prove that, for any $n$ , the condition does not hold for most of the integers $a < n$ unless $n$ is prime. Thus, if $n$ passes the test for some random choice of $a$ , the chances are better than even that $n$ is prime. If $n$ passes the test for two random choices of a, the chances are better than 3 out of 4 that $n$ is prime. By running the test with more and more randomly chosen values of $a$ we can make the probability of error as small as we like. While I understand that repeating the test increases the probability of $n$ being prime, I do not understand how they arrived at those numbers : better than even - testing once, better than 3 out of 4 - testing twice. I can see that, for a random choice of $a$ , the first statement means $P(\text{passing the test}) \lt 0.5$ when $n$ is composite and equal to $1.0$ otherwise. How do I calculate the probability that $n$ is prime, given that the test passes $x$ times?","I'm studying a computer science textbook that has a section on the Fermat test as an example of a probabilistic method. Given a number , the Fermat test is stated as pick a random number . If , chances are good that is prime. Else, is certainly not prime. Excepting the Carmichael numbers, the book goes on to say: one can prove that, for any , the condition does not hold for most of the integers unless is prime. Thus, if passes the test for some random choice of , the chances are better than even that is prime. If passes the test for two random choices of a, the chances are better than 3 out of 4 that is prime. By running the test with more and more randomly chosen values of we can make the probability of error as small as we like. While I understand that repeating the test increases the probability of being prime, I do not understand how they arrived at those numbers : better than even - testing once, better than 3 out of 4 - testing twice. I can see that, for a random choice of , the first statement means when is composite and equal to otherwise. How do I calculate the probability that is prime, given that the test passes times?",n a < n a^n \equiv a\pmod n n n n a < n n n a n n n a n a P(\text{passing the test}) \lt 0.5 n 1.0 n x,"['probability', 'elementary-number-theory', 'conditional-probability', 'primality-test']"
39,If 24 pieces of sausage are randomly put onto a pizza what is the probability that your slice will have 3 pieces of sausage?,If 24 pieces of sausage are randomly put onto a pizza what is the probability that your slice will have 3 pieces of sausage?,,"This Question is from Statistics the Easy Way, third edition, by Douglas Downing Ph.D and Jeffery Clark, Ph.D Chapter 6, Question 1. If 24 pieces of sausage are randomly put onto a pizza that is sliced into 8 pieces (with none of the sausages getting cut), what is the probability that your slice will have 3 pieces of sausage? The answer given in the back of the book is the following: $\binom{24}{3}\cdot \left ( \frac{1}{8} \right )^{3}\cdot \left ( \frac{7}{8} \right )^{21} = 0.006623494492036295$ I do not understand how the authors got this answer. As pieces of sausage are not distinguishable there is only one way to select 3 pieces of sausage. Are the sausage pieces first being labeled and then selected in $\binom{24}{3} $ ways? Isn't this a balls to boxes problem with indistinguishable balls and distinguishable boxes? There are 24 balls and 8 boxes. The number of ways of assigning balls to boxes is $\binom{24+8-1}{8}$ . There is only one way of putting 3 indistinguishable balls in my box and then there are $\binom{21+7-1}{7}$ ways of assigning the other balls to boxes. So the probability that my slice has exactly 3 pieces of sausage on it is $$\frac{\binom{21+7-1}{7}}{\binom{24+8-1}{8}} = 0.11256952169076752$$ As these answers are clearly different could someone please explain the error in the way I have solved the problem?","This Question is from Statistics the Easy Way, third edition, by Douglas Downing Ph.D and Jeffery Clark, Ph.D Chapter 6, Question 1. If 24 pieces of sausage are randomly put onto a pizza that is sliced into 8 pieces (with none of the sausages getting cut), what is the probability that your slice will have 3 pieces of sausage? The answer given in the back of the book is the following: I do not understand how the authors got this answer. As pieces of sausage are not distinguishable there is only one way to select 3 pieces of sausage. Are the sausage pieces first being labeled and then selected in ways? Isn't this a balls to boxes problem with indistinguishable balls and distinguishable boxes? There are 24 balls and 8 boxes. The number of ways of assigning balls to boxes is . There is only one way of putting 3 indistinguishable balls in my box and then there are ways of assigning the other balls to boxes. So the probability that my slice has exactly 3 pieces of sausage on it is As these answers are clearly different could someone please explain the error in the way I have solved the problem?",\binom{24}{3}\cdot \left ( \frac{1}{8} \right )^{3}\cdot \left ( \frac{7}{8} \right )^{21} = 0.006623494492036295 \binom{24}{3}  \binom{24+8-1}{8} \binom{21+7-1}{7} \frac{\binom{21+7-1}{7}}{\binom{24+8-1}{8}} = 0.11256952169076752,"['probability', 'discrete-mathematics']"
40,equation on expectation,equation on expectation,,I am reading a note on the probability theory and they are verifying that the sample mean $\bar y=\frac 1n \sum_{i=1}^n y_i$ is an unbiased estimator of the population mean $\bar Y$ by taking expectation $$E(\bar y)=\frac 1n \frac{1}{{N \choose n}}\sum_{i=1}^{N \choose n}\sum_{i=1}^ny_i. $$ I do not understand how they have gotten the following relation: $$ \sum_{i=1}^{N \choose n}\sum_{i=1}^ny_i={N-1 \choose n-1}\sum_{i=1}^N y_i. $$,I am reading a note on the probability theory and they are verifying that the sample mean is an unbiased estimator of the population mean by taking expectation I do not understand how they have gotten the following relation:,"\bar y=\frac 1n \sum_{i=1}^n y_i \bar Y E(\bar y)=\frac 1n \frac{1}{{N \choose n}}\sum_{i=1}^{N \choose n}\sum_{i=1}^ny_i.
 
\sum_{i=1}^{N \choose n}\sum_{i=1}^ny_i={N-1 \choose n-1}\sum_{i=1}^N y_i.
","['probability', 'statistics', 'expected-value']"
41,W_t^3 martingale or not? two arguments puzzle me.,W_t^3 martingale or not? two arguments puzzle me.,,"I want to study whether $W_t^3$ is a martingale or not?  where $W_t$ is the standard Brownian motion. I have method 1 argument, but I also got  second argument which implies different conclusion. Please help me figure out. Method 1 : Using Ito formula, we have $$W_t^3 = \int_0^t 3 W_s^2~d W_s + \int_0^t 3 W_s~ds$$ The first term on the RHS is a Ito integral, thus a martingale. Consider the second term, notice that a stochastic process $(X_t)_{t\geq 0}$ is martingale if and only if for any bounded stopping time $\tau$ , we have $$\mathbf{E}(X_\tau)=0$$ Back to the second term, $$\mathbf{E}\Big( \int_0^\tau W_s~ds  \Big)=\int_0^T\mathbf{E}(W_{s\wedge \tau})~ds~=~0$$ where $T$ is a finite boundedness for $\tau$ . Thus we proved that $\int_0^t 3 W_s~ds$ is also a martingale. This gives that $W_t^3$ is a martingale. Method 2: Let $\tau$ be the first existing time of $W_t$ from the interval $[-1, 2]$ , then from optional sampling theorem, we know $\mathbf{P}(W_\tau = -1) = {2\over 3},~~\mathbf{P}(W_\tau = 2) = {1\over 3}$ .  Suppose $(W_t^3)_{t\geq 0}$ is also a martingale, then we must have $\mathbf{E}(W_\tau^3) = 0 $ . However by computation, $$\mathbf{E}(W_\tau^3) = (-1)\times {2\over 3} + 8\times {1\over 3} \neq 0.$$ This contradiction implies that $W_t^3$ is not a martingale. Please help me figure out what's wrong with the arguments.","I want to study whether is a martingale or not?  where is the standard Brownian motion. I have method 1 argument, but I also got  second argument which implies different conclusion. Please help me figure out. Method 1 : Using Ito formula, we have The first term on the RHS is a Ito integral, thus a martingale. Consider the second term, notice that a stochastic process is martingale if and only if for any bounded stopping time , we have Back to the second term, where is a finite boundedness for . Thus we proved that is also a martingale. This gives that is a martingale. Method 2: Let be the first existing time of from the interval , then from optional sampling theorem, we know .  Suppose is also a martingale, then we must have . However by computation, This contradiction implies that is not a martingale. Please help me figure out what's wrong with the arguments.","W_t^3 W_t W_t^3 = \int_0^t 3 W_s^2~d W_s + \int_0^t 3 W_s~ds (X_t)_{t\geq 0} \tau \mathbf{E}(X_\tau)=0 \mathbf{E}\Big( \int_0^\tau W_s~ds  \Big)=\int_0^T\mathbf{E}(W_{s\wedge \tau})~ds~=~0 T \tau \int_0^t 3 W_s~ds W_t^3 \tau W_t [-1, 2] \mathbf{P}(W_\tau = -1) = {2\over 3},~~\mathbf{P}(W_\tau = 2) = {1\over 3} (W_t^3)_{t\geq 0} \mathbf{E}(W_\tau^3) = 0  \mathbf{E}(W_\tau^3) = (-1)\times {2\over 3} + 8\times {1\over 3} \neq 0. W_t^3","['probability', 'brownian-motion', 'martingales']"
42,"Independent or dependent events, drawing cards without replacement","Independent or dependent events, drawing cards without replacement",,"Firstly, i want to sorry for asking the question that has been answered. This is because i don't have enough reputation so that i can ask the people who gave the answer. The question that has been answered: Independent events, drawing cards without replacement. Question: Two cards are chosen from a pack of cards without replacement. Are the following events independent? (i)the first card is a heart, (ii)the second card is a picture card. After reading this, i still can not understand why these 2 events are independent. I can prove these 2 are independent: $A$ : First card is a heart. $B$ : Second card is a picture card. \begin{align}     P(A) &= \frac{13}{52} \\      P(B) &= \frac{12}{52} \end{align} If we assume that these two events are independent then : \begin{align}     P(A \cap B) &= P(A).P(B) = \frac{13.12}{52^2} = \frac{3}{52} \end{align} We also have: \begin{split}     P(A \cap B) &= P(\text{first card is a heart card with picture }\cap B) \\ &\quad+  P(f\text{first card is a heart card not picture }\cap B)\\  &=\frac{3}{52}\cdot \frac{11}{51} \; + \frac{10}{52}\cdot\frac{12}{51} = \frac{3}{52} \end{split} So that: \begin{align} P(A \cap B) &= P(A)\cdot P(B)\;\;\textit{is true} \end{align} This proves that these two events are independent. The reason here is that i think that when we pick the first card is a heart then we have two cases : 1) If we pick the first card, it is a heart picture card. So the number of picture cards and total cards in the pack of cards decreases. 2) If we pick the first card, it is a heart but not a picture card. So the number of total cards in the pack of cards decreases. I think on both cases these 2 events are dependent because after the event $A$ happens, it affects to the probability of the event $B$ . After thinking a lot i still can not figure out why they are independent. Thanks a lot for reading and helping me !","Firstly, i want to sorry for asking the question that has been answered. This is because i don't have enough reputation so that i can ask the people who gave the answer. The question that has been answered: Independent events, drawing cards without replacement. Question: Two cards are chosen from a pack of cards without replacement. Are the following events independent? (i)the first card is a heart, (ii)the second card is a picture card. After reading this, i still can not understand why these 2 events are independent. I can prove these 2 are independent: : First card is a heart. : Second card is a picture card. If we assume that these two events are independent then : We also have: So that: This proves that these two events are independent. The reason here is that i think that when we pick the first card is a heart then we have two cases : 1) If we pick the first card, it is a heart picture card. So the number of picture cards and total cards in the pack of cards decreases. 2) If we pick the first card, it is a heart but not a picture card. So the number of total cards in the pack of cards decreases. I think on both cases these 2 events are dependent because after the event happens, it affects to the probability of the event . After thinking a lot i still can not figure out why they are independent. Thanks a lot for reading and helping me !","A B \begin{align}
    P(A) &= \frac{13}{52} \\ 
    P(B) &= \frac{12}{52}
\end{align} \begin{align}
    P(A \cap B) &= P(A).P(B) = \frac{13.12}{52^2} = \frac{3}{52}
\end{align} \begin{split}
    P(A \cap B) &= P(\text{first card is a heart card with picture }\cap B) \\
&\quad+  P(f\text{first card is a heart card not picture }\cap B)\\ 
&=\frac{3}{52}\cdot \frac{11}{51} \; + \frac{10}{52}\cdot\frac{12}{51} = \frac{3}{52}
\end{split} \begin{align}
P(A \cap B) &= P(A)\cdot P(B)\;\;\textit{is true}
\end{align} A B",['probability']
43,Expected number of tries to choose x unique values,Expected number of tries to choose x unique values,,"it's been a long time since I've dealt with probability so I thought I would ask here. I'm sampling elements independently and uniformly and with repetition from a population. Given that the population is of size n, how many tries (in expectation) would it take me to gather x unique elements? Thank you :)","it's been a long time since I've dealt with probability so I thought I would ask here. I'm sampling elements independently and uniformly and with repetition from a population. Given that the population is of size n, how many tries (in expectation) would it take me to gather x unique elements? Thank you :)",,"['probability', 'expected-value', 'sampling', 'bootstrap-sampling']"
44,Birthday Calendar Gaps,Birthday Calendar Gaps,,"I work at a company that posts a birthday calendar. I noticed that there was a string of four consecutive days with no birthdays. What is the probability of that happening? Problem Statement Given $n$ people, what is the probability of a observing a birthday calendar with no gaps of length $g$ or greater. In my case $n = 400$ and $g = 4$ . I'm mostly interested in an analytical solution. Partial Solution We will count the number of birthday assignments that have gaps less than $g$ . To do this, we will count assignments which have exactly $d$ distinct birthdays ( $d = 1, 2, 3, ..., 365$ ) and sum over $d$ . For a given $d$ , we will require a counting of two things: Number of ways to partition $n$ birthdays among $d$ days. Number of ways to select $d$ days from the year with no gaps of $g$ or greater. I found a solution to 1: $S(n,d) \times d!$ where $S(n,d)$ is a Stirling Number Of Second Kind. See solution here: Consecutive birthdays probability I need help on 2.","I work at a company that posts a birthday calendar. I noticed that there was a string of four consecutive days with no birthdays. What is the probability of that happening? Problem Statement Given people, what is the probability of a observing a birthday calendar with no gaps of length or greater. In my case and . I'm mostly interested in an analytical solution. Partial Solution We will count the number of birthday assignments that have gaps less than . To do this, we will count assignments which have exactly distinct birthdays ( ) and sum over . For a given , we will require a counting of two things: Number of ways to partition birthdays among days. Number of ways to select days from the year with no gaps of or greater. I found a solution to 1: where is a Stirling Number Of Second Kind. See solution here: Consecutive birthdays probability I need help on 2.","n g n = 400 g = 4 g d d = 1, 2, 3, ..., 365 d d n d d g S(n,d) \times d! S(n,d)","['probability', 'combinatorics']"
45,"What is the expected number of randomly generated numbers in the range [a, b] required to reach a sum $\geq X$?","What is the expected number of randomly generated numbers in the range [a, b] required to reach a sum ?",\geq X,"We are generating random numbers (integers) in the range $[a, b]$ . All values are equally likely. We will continue to generate random numbers in this range, and add up successive values until their combined sum is greater than or equal to a set number $X$ . What is the expected number of rolls to reach at least $X$ ? Example: a = 1000 b = 2000 X = 5000  Value 1: 1257 (total sum so far = 1257) Value 2: 1889 (total sum so far = 3146) Value 3: 1902 (total sum so far = 5048; all done) So it took $3$ rolls to reach $\geq5000$ . Intuitively, we can say that it will not take more than $5$ rolls if each roll is $1000$ . We can also say that it will not take less than $3$ rolls if each roll was $2000$ . So it stands to reason that in the example above, the expected number of rolls lies somewhere between $3$ and $5$ . How would this be solved in the general case for arbitrary values $[a, b]$ and $X$ ? It's been quite a while since I last took statistics, so I've forgotten how to work with discrete random variables and expected value.","We are generating random numbers (integers) in the range . All values are equally likely. We will continue to generate random numbers in this range, and add up successive values until their combined sum is greater than or equal to a set number . What is the expected number of rolls to reach at least ? Example: a = 1000 b = 2000 X = 5000  Value 1: 1257 (total sum so far = 1257) Value 2: 1889 (total sum so far = 3146) Value 3: 1902 (total sum so far = 5048; all done) So it took rolls to reach . Intuitively, we can say that it will not take more than rolls if each roll is . We can also say that it will not take less than rolls if each roll was . So it stands to reason that in the example above, the expected number of rolls lies somewhere between and . How would this be solved in the general case for arbitrary values and ? It's been quite a while since I last took statistics, so I've forgotten how to work with discrete random variables and expected value.","[a, b] X X 3 \geq5000 5 1000 3 2000 3 5 [a, b] X","['probability', 'discrete-mathematics', 'random-variables']"
46,What is the difference between ergodicity and the law of large numbers?,What is the difference between ergodicity and the law of large numbers?,,"I want to begin by saying that I know absolutely no measure theory. To my knowledge, roughly speaking a stochastic process is ergodic if its time average converges to the expectation (space average) over a long period of time. For an iid sequence $X_{1} \ldots X_{n}$ with finite mean, I noticed that if consider the index as time then the average of this sequence $\frac{1}{n} \sum_{i=1}^{n} X_{i}$ is the very definition of time average. The law of large numbers states this will converge to $E[X_{i}]$ as $n \rightarrow \infty$ . So, I am not sure how the law of large numbers is different from ergodicity? Looks to me they are saying the same thing. Can a stochastic process be ergodic if it isn't iid? I am also not sure how the definition of ergodicity coincides with the definition given in the context of markov chains, where the chain is ergodic if it is aperiodic, irreducible, and finite mean recurrence time.","I want to begin by saying that I know absolutely no measure theory. To my knowledge, roughly speaking a stochastic process is ergodic if its time average converges to the expectation (space average) over a long period of time. For an iid sequence with finite mean, I noticed that if consider the index as time then the average of this sequence is the very definition of time average. The law of large numbers states this will converge to as . So, I am not sure how the law of large numbers is different from ergodicity? Looks to me they are saying the same thing. Can a stochastic process be ergodic if it isn't iid? I am also not sure how the definition of ergodicity coincides with the definition given in the context of markov chains, where the chain is ergodic if it is aperiodic, irreducible, and finite mean recurrence time.",X_{1} \ldots X_{n} \frac{1}{n} \sum_{i=1}^{n} X_{i} E[X_{i}] n \rightarrow \infty,"['probability', 'stochastic-processes', 'markov-chains', 'ergodic-theory', 'law-of-large-numbers']"
47,"Find the probability that A,B,C are connected","Find the probability that A,B,C are connected",,"I was given the following problem as a homework assignment: Denote with $S$ the ball with center $O$ . Three points $A, B$ and $C$ are chosen at random on its surface, their positions being independent and each   uniformly distributed on the surface. Points A and B can be connected   together if the angle $AOB<\pi/2$ . What is the probability that they can be connected (with, for example, $A$ connecting with $B$ via $C$ if necessary)? I was given the answer by my professor as a hint: $(\pi+2)/(4\pi)$ . I thought about it in the following way. Let $r$ denote the line that passes through the center $O$ , which will intersect the ball at a point, call it $A$ . Now, take a plane perpendicular to $r$ and make it pass through $O$ . The plane divides the sphere into $2$ hemispheres, one that contains the point $A$ and one that does not. If $B$ is placed in the hemisphere that contains $A$ , then $AOB<\pi/2$ and so they can connect. Otherwise, they cannot. So the probability of $A$ connecting with $B$ is equivalent to the prbability that $B$ falls in one of the two hemispheres that contains $A$ which is $1/2$ . (The idea of this reasonsing is to keep $A$ fixed and set it at the ""center"" of the hemisphere's surface). Now I am left with calculating the probability that $B$ is placed on the other hemisphere so that $A$ must connect with $B$ through $C$ . Which is again $1/2$ ? What is wrong with this reasoning? And how would one solve this problem?","I was given the following problem as a homework assignment: Denote with the ball with center . Three points and are chosen at random on its surface, their positions being independent and each   uniformly distributed on the surface. Points A and B can be connected   together if the angle . What is the probability that they can be connected (with, for example, connecting with via if necessary)? I was given the answer by my professor as a hint: . I thought about it in the following way. Let denote the line that passes through the center , which will intersect the ball at a point, call it . Now, take a plane perpendicular to and make it pass through . The plane divides the sphere into hemispheres, one that contains the point and one that does not. If is placed in the hemisphere that contains , then and so they can connect. Otherwise, they cannot. So the probability of connecting with is equivalent to the prbability that falls in one of the two hemispheres that contains which is . (The idea of this reasonsing is to keep fixed and set it at the ""center"" of the hemisphere's surface). Now I am left with calculating the probability that is placed on the other hemisphere so that must connect with through . Which is again ? What is wrong with this reasoning? And how would one solve this problem?","S O A, B C AOB<\pi/2 A B C (\pi+2)/(4\pi) r O A r O 2 A B A AOB<\pi/2 A B B A 1/2 A B A B C 1/2","['probability', 'probability-theory', 'geometric-probability']"
48,Kind of converse of Kolmogorov maximal inequality,Kind of converse of Kolmogorov maximal inequality,,"Let $S_n=\zeta_1+...+\zeta_n$ where $\zeta_i$ are independent with $E\zeta_i=0, E\zeta_i^2=\sigma_i^2<\infty, |\zeta_i|<K$ . Then, $P(\max_{1 \leq m  \leq n}|S_m| \leq x) \leq (x+K)^2/\operatorname{var}(S_n)$ . How do we show this?  The hint says that I should use the fact that $S_n^2-\sum_{m \leq n}\sigma_m^2$ is a martingale. But I am totally clueless.... Any hint would be appreciated! Thanks and regards.","Let where are independent with . Then, . How do we show this?  The hint says that I should use the fact that is a martingale. But I am totally clueless.... Any hint would be appreciated! Thanks and regards.","S_n=\zeta_1+...+\zeta_n \zeta_i E\zeta_i=0, E\zeta_i^2=\sigma_i^2<\infty, |\zeta_i|<K P(\max_{1 \leq m  \leq n}|S_m| \leq x) \leq (x+K)^2/\operatorname{var}(S_n) S_n^2-\sum_{m \leq n}\sigma_m^2","['probability', 'probability-theory', 'inequality', 'stochastic-processes', 'martingales']"
49,Your evil probability professor has an urn with 9 balls.,Your evil probability professor has an urn with 9 balls.,,"Your evil probability professor has an urn with 9 balls:  2 red, 3 white and 4 blue.  He draws two balls from the urn without replacement.  Let X be the number of red balls drawn and Y the number of white balls. a) Determine the joint probability mass function of X and Y. b) Are X and Y independent random variables? c) Compute the covariance between X and Y. For point A : $P(0,0)=\frac{4}{9} \cdot \frac{3}{8} = \frac{1}{6}$ That is correct for the solution. $P(0,1)=\frac{4}{9} \cdot \frac{3}{8} + \frac{3}{9} \cdot \frac{4}{8} = \frac{1}{3}$ That is correct for the solution. $P(1,0)=\frac{2}{9} \cdot \frac{4}{8} + \frac{4}{9} \cdot \frac{2}{8}= \frac{2}{9}$ That is correct for the solution. $P(1,1)=\frac{2}{9} \cdot \frac{3}{8} +  \frac{3}{9} \cdot \frac{2}{8}= \frac{1}{6}$ That is correct for the solution. $P(2,0)=\frac{2}{9} \cdot \frac{1}{8} = \frac{1}{36}$ That is correct for the solution. $P(0,2)=\frac{3}{9} \cdot \frac{2}{8} = \frac{1}{12}$ That is correct for the solution. For point B to check the independancy I have just to check if for example $P(X=0,Y=0) = P(X=0) \cdot P(Y=0)$ . $\frac{1}{6} \neq (\frac{7}{9} \cdot \frac{6}{8}) \cdot (\frac{6}{9} \cdot \frac{5}{8})$ . So X and Y are not independent. For point C I know that the covariance $Cov(X,Y)=E[X \cdot Y]-E[X]\cdot E[Y]$ , but how can compute the expectations, do I have to figure put with distribution is? How can I do it? Can someone help me? Thanks in advance, Fabio!","Your evil probability professor has an urn with 9 balls:  2 red, 3 white and 4 blue.  He draws two balls from the urn without replacement.  Let X be the number of red balls drawn and Y the number of white balls. a) Determine the joint probability mass function of X and Y. b) Are X and Y independent random variables? c) Compute the covariance between X and Y. For point A : That is correct for the solution. That is correct for the solution. That is correct for the solution. That is correct for the solution. That is correct for the solution. That is correct for the solution. For point B to check the independancy I have just to check if for example . . So X and Y are not independent. For point C I know that the covariance , but how can compute the expectations, do I have to figure put with distribution is? How can I do it? Can someone help me? Thanks in advance, Fabio!","P(0,0)=\frac{4}{9} \cdot \frac{3}{8} = \frac{1}{6} P(0,1)=\frac{4}{9} \cdot \frac{3}{8} + \frac{3}{9} \cdot \frac{4}{8} = \frac{1}{3} P(1,0)=\frac{2}{9} \cdot \frac{4}{8} + \frac{4}{9} \cdot \frac{2}{8}= \frac{2}{9} P(1,1)=\frac{2}{9} \cdot \frac{3}{8} +  \frac{3}{9} \cdot \frac{2}{8}= \frac{1}{6} P(2,0)=\frac{2}{9} \cdot \frac{1}{8} = \frac{1}{36} P(0,2)=\frac{3}{9} \cdot \frac{2}{8} = \frac{1}{12} P(X=0,Y=0) = P(X=0) \cdot P(Y=0) \frac{1}{6} \neq (\frac{7}{9} \cdot \frac{6}{8}) \cdot (\frac{6}{9} \cdot \frac{5}{8}) Cov(X,Y)=E[X \cdot Y]-E[X]\cdot E[Y]",['probability']
50,Urn Probability Problem containing algebraic variables,Urn Probability Problem containing algebraic variables,,"Urn A contains $x$ red marbles and $y$ white marbles, and Urn B contains $z$ red marbles and $v$ white marbles. If a marble is drawn from Urn A and put into Urn B and then a marble is drawn from Urn B, what is the probability that the second marble is red? I get the answer $\frac{2z+1}{z+v+1}$ , but my book gives the answer $\frac{xz+x+yz}{(x+y)(z+v+1)}$ . I cannot understand how the books answer was obtained.","Urn A contains red marbles and white marbles, and Urn B contains red marbles and white marbles. If a marble is drawn from Urn A and put into Urn B and then a marble is drawn from Urn B, what is the probability that the second marble is red? I get the answer , but my book gives the answer . I cannot understand how the books answer was obtained.",x y z v \frac{2z+1}{z+v+1} \frac{xz+x+yz}{(x+y)(z+v+1)},['probability']
51,Is it possible to determine shape and scale for a gamma distribution from a mean and confidence interval?,Is it possible to determine shape and scale for a gamma distribution from a mean and confidence interval?,,"Having the 95% confidence interval and mean for a distribution and knowing nothing else (other than the data is skewed and will likely follow a gamma distribution) is there any way to determine the shape and scale of that gamma distribution? If not, what are the minimum data you would need to determine these?","Having the 95% confidence interval and mean for a distribution and knowing nothing else (other than the data is skewed and will likely follow a gamma distribution) is there any way to determine the shape and scale of that gamma distribution? If not, what are the minimum data you would need to determine these?",,"['probability', 'probability-distributions', 'gamma-distribution']"
52,Chi-squared distribution tail bound,Chi-squared distribution tail bound,,"I have been studying about tail bounds and I read the following claim: A variable $\xi \sim N(0, 1)$  satisfies the following tail bound for $t \geq 1$: $ \mathbb{P}(\xi \geq t) \leq e^{-t^2/2} $ We also know that if $\mathbf{x} \sim N(0, \text{Id}_n)$ (where $\text{Id}_n$ is the identity matrix belonging in $\mathbb{R}^{n\times n}$) the distribution of its squared Euclidean norm $\|\mathbf{x}\|^2$ is called $\chi^2$-distribution, that has the following tail bound for $t \geq 1$: $ \mathbb{P}(\|\mathbf{x}\|^2 \geq t\cdot n) \leq e^{-t\cdot n/10}$ However somewhere else I have seen the following tail bound for the $\chi^2$-distribution:$ \mathbb{P}(\|\mathbf{x}\|^2 \geq t\cdot 2n) \leq e^{-t\cdot n/10}$ Which of two tail bounds for the $\chi^2$-distribution is correct and can we prove that using the Gaussian tail bound that I gave in the beginning?","I have been studying about tail bounds and I read the following claim: A variable $\xi \sim N(0, 1)$  satisfies the following tail bound for $t \geq 1$: $ \mathbb{P}(\xi \geq t) \leq e^{-t^2/2} $ We also know that if $\mathbf{x} \sim N(0, \text{Id}_n)$ (where $\text{Id}_n$ is the identity matrix belonging in $\mathbb{R}^{n\times n}$) the distribution of its squared Euclidean norm $\|\mathbf{x}\|^2$ is called $\chi^2$-distribution, that has the following tail bound for $t \geq 1$: $ \mathbb{P}(\|\mathbf{x}\|^2 \geq t\cdot n) \leq e^{-t\cdot n/10}$ However somewhere else I have seen the following tail bound for the $\chi^2$-distribution:$ \mathbb{P}(\|\mathbf{x}\|^2 \geq t\cdot 2n) \leq e^{-t\cdot n/10}$ Which of two tail bounds for the $\chi^2$-distribution is correct and can we prove that using the Gaussian tail bound that I gave in the beginning?",,"['probability', 'upper-lower-bounds', 'chi-squared']"
53,Coupling continuous random variables,Coupling continuous random variables,,"Let $X,Y$ be random variables with densities $f_X(x)=x^{-2}1_{[1,\infty)}$ and $f_Y(x)=3x^{-4}1_{[1,\infty)}$. How do I couple these such that $X\leq Y$ with probability 1? Attempt: I know that they intersect at $x=\sqrt{3}$. Then $f_Y(x)>f_X(x)$ for $x<\sqrt{3}$ and $f_Y(x)<f_X(x)$ for $x>\sqrt{3}$. Now we want to find random variables $X'$ and $Y'$ with joint probability function $P'$ such that its marginals return $X$ and $Y$ and $X'\leq Y'$. How do I do this?","Let $X,Y$ be random variables with densities $f_X(x)=x^{-2}1_{[1,\infty)}$ and $f_Y(x)=3x^{-4}1_{[1,\infty)}$. How do I couple these such that $X\leq Y$ with probability 1? Attempt: I know that they intersect at $x=\sqrt{3}$. Then $f_Y(x)>f_X(x)$ for $x<\sqrt{3}$ and $f_Y(x)<f_X(x)$ for $x>\sqrt{3}$. Now we want to find random variables $X'$ and $Y'$ with joint probability function $P'$ such that its marginals return $X$ and $Y$ and $X'\leq Y'$. How do I do this?",,"['probability', 'probability-theory']"
54,Precisely defining the conditional distribution of $X$ given that $Y = y$,Precisely defining the conditional distribution of  given that,X Y = y,"Let $(\Omega,\Sigma,P)$ be a probability space and let $X\colon \Omega \to \mathbb R$ and $Y\colon \Omega \to \mathbb R$ be continuous random variables with density functions $f_X$ and $f_Y$, respectively. I would like to precisely define the conditional distribution of $X$ given that $Y = y$, where $y \in \mathbb R$ and $f_Y(y) > 0$. The difficulty in doing this is that the event $Y = y$ has probability $0$. As a first step, we can attempt to define $P(A \mid Y = y)$, where $A \subset \Omega$ is an event. A key idea is to note that while the event $Y = y$ has measure $0$, the event $Y \in [y, y + \Delta y]$ has positive probability for any number $\Delta y > 0$. This suggests that we can define $$ \tag{1} P(A \mid Y = y) = \lim_{\Delta y \to 0} P(A \mid Y \in [y,y + \Delta y]). $$ Question: Does the limit on the right exist? If so, is the function $P(\cdot \mid Y = y)$ defined in equation (1) a probability measure? Additional question: Is this the standard approach to rigorously defining the conditional distribution of $X$ given that $Y = y$? If not, what is the standard approach? Please recommend a book that explains this clearly, as it is glossed over in most probability books I have looked at.","Let $(\Omega,\Sigma,P)$ be a probability space and let $X\colon \Omega \to \mathbb R$ and $Y\colon \Omega \to \mathbb R$ be continuous random variables with density functions $f_X$ and $f_Y$, respectively. I would like to precisely define the conditional distribution of $X$ given that $Y = y$, where $y \in \mathbb R$ and $f_Y(y) > 0$. The difficulty in doing this is that the event $Y = y$ has probability $0$. As a first step, we can attempt to define $P(A \mid Y = y)$, where $A \subset \Omega$ is an event. A key idea is to note that while the event $Y = y$ has measure $0$, the event $Y \in [y, y + \Delta y]$ has positive probability for any number $\Delta y > 0$. This suggests that we can define $$ \tag{1} P(A \mid Y = y) = \lim_{\Delta y \to 0} P(A \mid Y \in [y,y + \Delta y]). $$ Question: Does the limit on the right exist? If so, is the function $P(\cdot \mid Y = y)$ defined in equation (1) a probability measure? Additional question: Is this the standard approach to rigorously defining the conditional distribution of $X$ given that $Y = y$? If not, what is the standard approach? Please recommend a book that explains this clearly, as it is glossed over in most probability books I have looked at.",,['probability']
55,Two supermartingales and a stopping time,Two supermartingales and a stopping time,,"I have the following task to do: Let $(X_n)$ and $(Y_n)$ be two supermartingales on the probability space $(\Omega, \mathcal{A}, P)$ and $T$ be a stopping time regarding a filtration $(\mathcal{F}_n)$ and $X_T \leq Y_T$ on $\{T< \infty\}$. Define $Z_n = Y_n$ on $\{n<T\}$ and $Z_n = X_n$ on $\{T \leq n\}$. Proof that $(Z_n)$ is a supermartingale. I tried to use $Z_n = Y_nI_{\{n<T\}} + X_nI_{\{T\leq n\}}$ and plug that into $\mathbb{E}[Z_n|\mathcal{F_{n-1}}]$ and use some properties of the conditional expectation, but I don't seem to get to $\leq Z_{n-1}$. Any help is appreciated.","I have the following task to do: Let $(X_n)$ and $(Y_n)$ be two supermartingales on the probability space $(\Omega, \mathcal{A}, P)$ and $T$ be a stopping time regarding a filtration $(\mathcal{F}_n)$ and $X_T \leq Y_T$ on $\{T< \infty\}$. Define $Z_n = Y_n$ on $\{n<T\}$ and $Z_n = X_n$ on $\{T \leq n\}$. Proof that $(Z_n)$ is a supermartingale. I tried to use $Z_n = Y_nI_{\{n<T\}} + X_nI_{\{T\leq n\}}$ and plug that into $\mathbb{E}[Z_n|\mathcal{F_{n-1}}]$ and use some properties of the conditional expectation, but I don't seem to get to $\leq Z_{n-1}$. Any help is appreciated.",,"['probability', 'probability-theory', 'conditional-expectation', 'martingales', 'stopping-times']"
56,Intuitive understanding of conditional density $f_{X \mid Y}(x \mid y)$,Intuitive understanding of conditional density,f_{X \mid Y}(x \mid y),"Let $X$ be a continuous random variable with probability density function $f_X$. The way that I think about the meaning of $f_X$ is this: if $\Delta x$ is a small positive number then $$ P(X \in [x,x+ \Delta x]) \approx f_X(x) \,\Delta x. $$ Now suppose that $Y$ is also a continuous random variable. Is there a similar way to think about the conditional probability density function $f_{X \mid Y}(x \mid y)$? Notice that I cannot write $$ \tag{1} P(X \in [x,x + \Delta x] \mid Y = y) \approx f_{X \mid Y}(x \mid y) \,  \Delta x $$ because the event $Y = y$ has probability $0$, and I can't condition on an event with probability $0$. Question: Since equation (1) does not make sense, how should I think about $f_{X \mid Y}(x \mid y)$? By the way, Bertsekas's book Introduction to Probability defines $f_{X\mid Y}$ like this: $$ f_{X \mid Y}(x \mid y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}. $$ However, I do not find this formula to be intuitive, despite the formula's superficial similarity with the formula $$ P(A \mid B) = \frac{P(A \cap B)}{P(B)}. $$","Let $X$ be a continuous random variable with probability density function $f_X$. The way that I think about the meaning of $f_X$ is this: if $\Delta x$ is a small positive number then $$ P(X \in [x,x+ \Delta x]) \approx f_X(x) \,\Delta x. $$ Now suppose that $Y$ is also a continuous random variable. Is there a similar way to think about the conditional probability density function $f_{X \mid Y}(x \mid y)$? Notice that I cannot write $$ \tag{1} P(X \in [x,x + \Delta x] \mid Y = y) \approx f_{X \mid Y}(x \mid y) \,  \Delta x $$ because the event $Y = y$ has probability $0$, and I can't condition on an event with probability $0$. Question: Since equation (1) does not make sense, how should I think about $f_{X \mid Y}(x \mid y)$? By the way, Bertsekas's book Introduction to Probability defines $f_{X\mid Y}$ like this: $$ f_{X \mid Y}(x \mid y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}. $$ However, I do not find this formula to be intuitive, despite the formula's superficial similarity with the formula $$ P(A \mid B) = \frac{P(A \cap B)}{P(B)}. $$",,['probability']
57,Weak convergence of linear combinations of Dirac measures to a signed measure,Weak convergence of linear combinations of Dirac measures to a signed measure,,"For a signed measure $\mu$ on the Borel $\sigma$-algebra of $\mathbb{R}$ satisfying $\vert \mu \vert < \infty$ is it always possible to find a sequence of measures $\{\mu_n\}$, each a linear combination of Dirac measures, converging weakly to $\mu$? By weakly I mean $$\int f(x) \mu_n(\text{d} x) \rightarrow  \int f(x) \mu(\text{d} x)$$ as $n \rightarrow \infty$ for every bounded, continuous function $f$. If not, does it help to restrict the assumptions, e.g. to positive measures?","For a signed measure $\mu$ on the Borel $\sigma$-algebra of $\mathbb{R}$ satisfying $\vert \mu \vert < \infty$ is it always possible to find a sequence of measures $\{\mu_n\}$, each a linear combination of Dirac measures, converging weakly to $\mu$? By weakly I mean $$\int f(x) \mu_n(\text{d} x) \rightarrow  \int f(x) \mu(\text{d} x)$$ as $n \rightarrow \infty$ for every bounded, continuous function $f$. If not, does it help to restrict the assumptions, e.g. to positive measures?",,"['probability', 'functional-analysis', 'probability-theory', 'measure-theory']"
58,A counterexample of reducible Markov chains about Birkhoff's ergodic theorem,A counterexample of reducible Markov chains about Birkhoff's ergodic theorem,,"In R.Durrett's boos Probability Theory and Examples(5th). There is an example 6.2.4(CH6.2 P301), ""Let $X_{n}$ be an $\textbf{irreducible}$ Markov chain on a countable state space that has a stationary distribution $\pi$..., and applying the ergodic theorem,    $$ \frac{1}{n} \sum_{m=0}^{n-1} f(X_{m}) \longrightarrow \sum_{x}f(x)\pi(x).""$$ I want to know if there exists a counterexample removing the condition ""irreducible"", in other words, how about the reducible Markov chain? In this counterexample, the Birkhoff's ergodic theorem does not hold.","In R.Durrett's boos Probability Theory and Examples(5th). There is an example 6.2.4(CH6.2 P301), ""Let $X_{n}$ be an $\textbf{irreducible}$ Markov chain on a countable state space that has a stationary distribution $\pi$..., and applying the ergodic theorem,    $$ \frac{1}{n} \sum_{m=0}^{n-1} f(X_{m}) \longrightarrow \sum_{x}f(x)\pi(x).""$$ I want to know if there exists a counterexample removing the condition ""irreducible"", in other words, how about the reducible Markov chain? In this counterexample, the Birkhoff's ergodic theorem does not hold.",,"['probability', 'probability-theory']"
59,Probability that $m$ balls will fall into first box,Probability that  balls will fall into first box,m,"Suppose we have $n$ balls that are randomly distributed into $N$ boxes. Find the probability that $m$ balls will fall into the first box. Assume that all $N^m$ arrangements are equally likely. Attempt: First, we notice that for the first box, we have $n$ choices, and for the second box we also have $n$ choices, and so on. Thus, we have $n^N$ ways to place the balls into the boxes. Pick $m$ balls out of the total $n$ balls, that gives ${n \choose m}$ . In how many ways can these $m$ balls go into the first box? Well, in just ${1 \choose 1 }= 1 $ ways. Thus, $$ P = \frac{ {n \choose m } }{n^N } $$ Is this correct?","Suppose we have balls that are randomly distributed into boxes. Find the probability that balls will fall into the first box. Assume that all arrangements are equally likely. Attempt: First, we notice that for the first box, we have choices, and for the second box we also have choices, and so on. Thus, we have ways to place the balls into the boxes. Pick balls out of the total balls, that gives . In how many ways can these balls go into the first box? Well, in just ways. Thus, Is this correct?",n N m N^m n n n^N m n {n \choose m} m {1 \choose 1 }= 1   P = \frac{ {n \choose m } }{n^N } ,"['probability', 'balls-in-bins']"
60,"Probability of $3+3$ cards, out of $6$ cards drawn from a solitaire","Probability of  cards, out of  cards drawn from a solitaire",3+3 6,"A solitaire consists of $52$ cards. We take out $6$ out of them (wihout repetition). Find the probability there are $3+3$ cards of the same type (for example, $3$ ""1"" and $3$ ""5""). Attempt. First approach . There are $\binom{13}{2}$ ways to choose $2$ out of the $13$ types and by the multiplication law of probability, the desired probability is $$\binom{13}{2}\frac{4}{52}\,\frac{3}{51}\,\frac{2}{50}\, \frac{4}{49}\,\frac{3}{48}\,\frac{2}{47}.$$ Second approach . There are $\binom{13}{2}$ ways to choose $2$ out of the $13$ types and the desired probability is $$\binom{13}{2}\frac{\binom{4}{3}\binom{4}{3}\binom{4}{0}\ldots\binom{4}{0}}{\binom{52}{6}}.$$ These numbers don't coincide, so I guess (at least) one of them is not correct. Thanks in advance for the help.","A solitaire consists of $52$ cards. We take out $6$ out of them (wihout repetition). Find the probability there are $3+3$ cards of the same type (for example, $3$ ""1"" and $3$ ""5""). Attempt. First approach . There are $\binom{13}{2}$ ways to choose $2$ out of the $13$ types and by the multiplication law of probability, the desired probability is $$\binom{13}{2}\frac{4}{52}\,\frac{3}{51}\,\frac{2}{50}\, \frac{4}{49}\,\frac{3}{48}\,\frac{2}{47}.$$ Second approach . There are $\binom{13}{2}$ ways to choose $2$ out of the $13$ types and the desired probability is $$\binom{13}{2}\frac{\binom{4}{3}\binom{4}{3}\binom{4}{0}\ldots\binom{4}{0}}{\binom{52}{6}}.$$ These numbers don't coincide, so I guess (at least) one of them is not correct. Thanks in advance for the help.",,"['probability', 'combinatorics', 'combinations']"
61,"What does it mean to ""marginalize noise""?","What does it mean to ""marginalize noise""?",,"Reading this article on the dropout method for neural networks. Here (page 21/30, should jump straight to that page) they talk about viewing the dropout method as a way to introduce noise, and they talk about ""marginalizing this noise"". A Google search didn't yield any results that explained what this means.","Reading this article on the dropout method for neural networks. Here (page 21/30, should jump straight to that page) they talk about viewing the dropout method as a way to introduce noise, and they talk about ""marginalizing this noise"". A Google search didn't yield any results that explained what this means.",,"['probability', 'statistics', 'machine-learning']"
62,How to divide $n$ people into two groups to maximize the probability of finding a lost boy,How to divide  people into two groups to maximize the probability of finding a lost boy,n,"A small boy is lost coming down Mount Washington. The leader of the search team estimates that there is a probability $p$ that he came down on the east side and a probability $1 − p$ that he came down on the west side. He has $n$ people in his search team who will search independently and, if the boy is on the side being searched, each member will find the boy with probability $u$. Determine how he should divide the $n$ people into two groups to search the two sides of the mountain so that he will have the highest probability of finding the boy. How does this depend on $u$? No idea where to start. The answer has couple $\log$s in it. That's from a chapter of the book where I've learned this: https://i.sstatic.net/sbGj0.png . Perhaps I'm supposed to use some kind of derivative over $p$ somewhere along the way? But then I can't really come up with what to differentiate.","A small boy is lost coming down Mount Washington. The leader of the search team estimates that there is a probability $p$ that he came down on the east side and a probability $1 − p$ that he came down on the west side. He has $n$ people in his search team who will search independently and, if the boy is on the side being searched, each member will find the boy with probability $u$. Determine how he should divide the $n$ people into two groups to search the two sides of the mountain so that he will have the highest probability of finding the boy. How does this depend on $u$? No idea where to start. The answer has couple $\log$s in it. That's from a chapter of the book where I've learned this: https://i.sstatic.net/sbGj0.png . Perhaps I'm supposed to use some kind of derivative over $p$ somewhere along the way? But then I can't really come up with what to differentiate.",,['probability']
63,Making a sequence of random variables converge almost surely to $0$,Making a sequence of random variables converge almost surely to,0,"Prove: for every sequence of random variables $X_1,X_2,X_3,\dots$ there exists a sequence $a_1,a_2,a_3,\dots$ of real numbers ($a_i \neq 0$) such that the sequence $\frac{X_1}{a_1},\frac{X_2}{a_2},\frac{X_3}{a_3},\dots$ converges almost surely to the constant $0$. Note: $X_n$ doesn't neccisarily have finite expectation. What I tried: I wanted to use Borel Cantelli lemma, proving that: $$\sum_{i=0}^n P(|\frac{X_n}{a_n}|\geq \epsilon) <\infty \; \;, \; \forall \epsilon >0 $$ Then I got: $$P(|\frac{X_n}{a_n}| \geq \epsilon)=1-F_{X_n}(a_n \epsilon)+F_{X_n}(-a_n \epsilon) $$ When $F_{X_n}$ is the cumulatie distribution function of $X_n$. My ideas was to show that $1-F_{X_n}(a_n \epsilon)+F_{X_n}(-a_n \epsilon) < \frac{C}{n^2} $ for some constant, so the series will converge. To show that I tried using the fact that $\lim \limits_{t \to \infty} F_{X_n}(t) = 1, \lim \limits_{t \to -\infty}F_{X_n}(t)=0$, that is choosing big enough $a_n$ such that $F_{X_n}(-a_n \epsilon)< \frac{1}{n^2} \;$ $, \; F_{X_n}(a_n \epsilon) > 1-  \frac{1}{n^2}$. My problem is that the sequence I get is dependant with $\epsilon$, which is not good (I want one sequence for all $\epsilon$). Is there a way to fix my proof ? or another way to solve?  Thanks.","Prove: for every sequence of random variables $X_1,X_2,X_3,\dots$ there exists a sequence $a_1,a_2,a_3,\dots$ of real numbers ($a_i \neq 0$) such that the sequence $\frac{X_1}{a_1},\frac{X_2}{a_2},\frac{X_3}{a_3},\dots$ converges almost surely to the constant $0$. Note: $X_n$ doesn't neccisarily have finite expectation. What I tried: I wanted to use Borel Cantelli lemma, proving that: $$\sum_{i=0}^n P(|\frac{X_n}{a_n}|\geq \epsilon) <\infty \; \;, \; \forall \epsilon >0 $$ Then I got: $$P(|\frac{X_n}{a_n}| \geq \epsilon)=1-F_{X_n}(a_n \epsilon)+F_{X_n}(-a_n \epsilon) $$ When $F_{X_n}$ is the cumulatie distribution function of $X_n$. My ideas was to show that $1-F_{X_n}(a_n \epsilon)+F_{X_n}(-a_n \epsilon) < \frac{C}{n^2} $ for some constant, so the series will converge. To show that I tried using the fact that $\lim \limits_{t \to \infty} F_{X_n}(t) = 1, \lim \limits_{t \to -\infty}F_{X_n}(t)=0$, that is choosing big enough $a_n$ such that $F_{X_n}(-a_n \epsilon)< \frac{1}{n^2} \;$ $, \; F_{X_n}(a_n \epsilon) > 1-  \frac{1}{n^2}$. My problem is that the sequence I get is dependant with $\epsilon$, which is not good (I want one sequence for all $\epsilon$). Is there a way to fix my proof ? or another way to solve?  Thanks.",,"['probability', 'sequences-and-series', 'convergence-divergence', 'random-variables']"
64,how to find probalility that a student misses at least one test if he/she is absent twice?,how to find probalility that a student misses at least one test if he/she is absent twice?,,The probability that a teacher will give an unannounced test during any class is $\dfrac15$ . If a student is absent twice then probability that he/she misses at least one test is $\\ \hspace{5cm}$ a) $\dfrac23\ \quad $ b) $\dfrac45\ \quad$ c) $\dfrac7{25}\ \quad $ d) $\dfrac9{25}\ $ My attempt: Probability of attending first test & missing $2$ nd test $=\dfrac45\times\dfrac15=\dfrac4{25}$ Probability of missing first test & attending $2$ nd test $=\dfrac15\times\dfrac45=\dfrac4{25}$ Probability of missing both the tests $=\dfrac15\times\dfrac15=\dfrac1{25}$ Total probability of missing at least one test $=\dfrac4{25}+\dfrac4{25}+\dfrac1{25}=\dfrac9{25}$ Can somebody please help me if I am wrong? Thanks.,The probability that a teacher will give an unannounced test during any class is . If a student is absent twice then probability that he/she misses at least one test is a) b) c) d) My attempt: Probability of attending first test & missing nd test Probability of missing first test & attending nd test Probability of missing both the tests Total probability of missing at least one test Can somebody please help me if I am wrong? Thanks.,\dfrac15 \\ \hspace{5cm} \dfrac23\ \quad  \dfrac45\ \quad \dfrac7{25}\ \quad  \dfrac9{25}\  2 =\dfrac45\times\dfrac15=\dfrac4{25} 2 =\dfrac15\times\dfrac45=\dfrac4{25} =\dfrac15\times\dfrac15=\dfrac1{25} =\dfrac4{25}+\dfrac4{25}+\dfrac1{25}=\dfrac9{25},['probability']
65,The difference of two order statistics of exponential distribution,The difference of two order statistics of exponential distribution,,"If we have a random sample $X_1,X_2, \ldots, X_n \stackrel{\text{iid}}\sim f(x\mid\theta)=e^{-(x-\theta)}I(x >\theta)$. We want to prove  $$2\sum X_i-2n X_{(1)} \sim \chi^2_{n-2}$$ where $X_{(1)}$ is the smallest order statistic. I tried:  $$2\sum X_i-2n X_{(1)} =2\left[\sum X_i-n X_{(1)}\right]=2\left[\sum X_{(i)}-n X_{(1)}\right]=2\left[\sum \left(X_{(i)}- X_{(1)}\right)\right]$$  And I was trying to find the distribution of  $$X_{(i)}- X_{(1)}$$ And I searched that $$X_{(i)}-X_{(i-1)} \sim \operatorname{Exp}\left(\frac{1}{n+1-i}\right) \text{ if } X_i \stackrel{\text{iid}}\sim \operatorname{Exp}(1)$$ Any ideas? Thank you~","If we have a random sample $X_1,X_2, \ldots, X_n \stackrel{\text{iid}}\sim f(x\mid\theta)=e^{-(x-\theta)}I(x >\theta)$. We want to prove  $$2\sum X_i-2n X_{(1)} \sim \chi^2_{n-2}$$ where $X_{(1)}$ is the smallest order statistic. I tried:  $$2\sum X_i-2n X_{(1)} =2\left[\sum X_i-n X_{(1)}\right]=2\left[\sum X_{(i)}-n X_{(1)}\right]=2\left[\sum \left(X_{(i)}- X_{(1)}\right)\right]$$  And I was trying to find the distribution of  $$X_{(i)}- X_{(1)}$$ And I searched that $$X_{(i)}-X_{(i-1)} \sim \operatorname{Exp}\left(\frac{1}{n+1-i}\right) \text{ if } X_i \stackrel{\text{iid}}\sim \operatorname{Exp}(1)$$ Any ideas? Thank you~",,"['probability', 'statistics', 'probability-distributions']"
66,Empirical Distribution Function.,Empirical Distribution Function.,,"Suppose $T$ denotes a nonnegative random variable representing the lifetimes of individuals in some population. Let $t_i,i=1,2,...,n,$ denotes an ordered observed value. Then the empirical survivor function(esf) is defined by $$S(t)=\frac{\text{number of observations}>t}{n}.$$ Consider the observed valus of $T$: $9,13,13,18,23,28,31,34,45,48,161$. According to the formula, The values of esf for this data are given below: $$ \begin{array}{c|cccccccccc} t & 9&13&18&23&28&31&34&45&48&161 \\ \hline S(t)&\frac{10}{11}&\frac{8}{11}&\frac{7}{11}&\frac{6}{11}&\frac{5}{11}&\frac{4}{11}&\frac{3}{11}&\frac{2}{11}&\frac{1}{11}&0 \end{array}. $$ My question is: at $t=13$, the first individual with $t=9$ is died. That is, at $t=13$, I have actually $n=10$ individuals remaining. Then why doesn't the denominator (number of individuals) reduces with time in the formula of $S(t)$? Why is the calculation of esf  not like the following? $$ \begin{array}{c|cccccccccc} t & 9&13&18&23&28&31&34&45&48&161 \\ \hline S(t)&\frac{10}{11}&\frac{8}{10}&\frac{7}{8}&\frac{6}{7}&\frac{5}{6}&\frac{4}{5}&\frac{3}{4}&\frac{2}{3}&\frac{1}{2}&0 \end{array}? $$","Suppose $T$ denotes a nonnegative random variable representing the lifetimes of individuals in some population. Let $t_i,i=1,2,...,n,$ denotes an ordered observed value. Then the empirical survivor function(esf) is defined by $$S(t)=\frac{\text{number of observations}>t}{n}.$$ Consider the observed valus of $T$: $9,13,13,18,23,28,31,34,45,48,161$. According to the formula, The values of esf for this data are given below: $$ \begin{array}{c|cccccccccc} t & 9&13&18&23&28&31&34&45&48&161 \\ \hline S(t)&\frac{10}{11}&\frac{8}{11}&\frac{7}{11}&\frac{6}{11}&\frac{5}{11}&\frac{4}{11}&\frac{3}{11}&\frac{2}{11}&\frac{1}{11}&0 \end{array}. $$ My question is: at $t=13$, the first individual with $t=9$ is died. That is, at $t=13$, I have actually $n=10$ individuals remaining. Then why doesn't the denominator (number of individuals) reduces with time in the formula of $S(t)$? Why is the calculation of esf  not like the following? $$ \begin{array}{c|cccccccccc} t & 9&13&18&23&28&31&34&45&48&161 \\ \hline S(t)&\frac{10}{11}&\frac{8}{10}&\frac{7}{8}&\frac{6}{7}&\frac{5}{6}&\frac{4}{5}&\frac{3}{4}&\frac{2}{3}&\frac{1}{2}&0 \end{array}? $$",,"['probability', 'probability-theory', 'statistics']"
67,From Exponential Distributions to Weibull Distribution (CDF),From Exponential Distributions to Weibull Distribution (CDF),,"Problem:  Let $X_1$ and $X_2$ be two independent exponential random variables with the PDFs $f_{X_i}(x_i)={1\over \lambda_i} \exp(-\frac{x_i}{\lambda_i})$ (where $i=1,2$).  Also, let $Y=\frac{(X_1)^2 X_2}{a}$. I want to find $(Y\leq x)$ i.e. $F_Y(x)=\frac{(X_1)^2 X_2}{a} \leq x$. My attempted sol (1): $$\eqalign{&=(X_1)^2  \leq \frac{a  x} {X_2}\\ &=\int_0^\infty     X_1  \leq \sqrt{\frac{a  x} {z_2}}    \quad f_{X_2}(z_2) dz_2\\ &= {1\over \lambda_2} \int_0^\infty     \left(1-\exp\big(-{\sqrt\frac{a  x} {z_2 \lambda_1^2}}\big)\right) \exp(-\frac{z_2}{\lambda_2})   \quad dz_2\\  &=1-{1\over \lambda_2} \int_0^\infty \exp\left(-{\sqrt\frac{c} {z_2}}-\frac{z_2}{\lambda_2}\right) dz_2\tag{1}}$$ I know that $\int_0^\infty \exp\left(-{\frac{\beta} {4z_2}}-{z_2 \gamma}\right) dz_2 = \sqrt{β\over\gamma}K_1(\sqrt{\beta\gamma})$ from Table of Integrals, Series and Products, 7th edition - equation §3.324.1]. However, the final form of above equation contains $\sqrt{}$ and therefore cannot be solved by using §3.324.1. So if you guys can comment or provide any kind of help that would be very helpful. My attempted sol (2): $$\eqalign{&=(X_1)^2  \leq \frac{a  x} {X_2}\\ &=\int_0^\infty     X_2  \leq {\frac{a  x} {z_1^2}}    \quad f_{X_1}(z_1) dz_1\\ &= {1\over \lambda_1} \int_0^\infty     \left(1-\exp\big(-{\frac{a  x} {z_1^2 \lambda_2}}\big)\right) \exp(-\frac{z_1}{\lambda_1})   \quad dz_1\\  &=1-{1\over \lambda_1} \int_0^\infty \exp\left(-{\frac{c} {z_1^2}}-\frac{z_1}{\lambda_1}\right) dz_1\tag{1}}$$ Once again to the best my knowledge this above equation doesn't submit to any closed form solution. So I am stuck here.... Since, X is exponential r.v with mean $\lambda$, then $X^{1\over\gamma}$ is a Weibull (γ, β) random variable. Can we solve it this way? by using the CDF or pdf of weibull during conditioning? Any kind of help will be very much appreciated.","Problem:  Let $X_1$ and $X_2$ be two independent exponential random variables with the PDFs $f_{X_i}(x_i)={1\over \lambda_i} \exp(-\frac{x_i}{\lambda_i})$ (where $i=1,2$).  Also, let $Y=\frac{(X_1)^2 X_2}{a}$. I want to find $(Y\leq x)$ i.e. $F_Y(x)=\frac{(X_1)^2 X_2}{a} \leq x$. My attempted sol (1): $$\eqalign{&=(X_1)^2  \leq \frac{a  x} {X_2}\\ &=\int_0^\infty     X_1  \leq \sqrt{\frac{a  x} {z_2}}    \quad f_{X_2}(z_2) dz_2\\ &= {1\over \lambda_2} \int_0^\infty     \left(1-\exp\big(-{\sqrt\frac{a  x} {z_2 \lambda_1^2}}\big)\right) \exp(-\frac{z_2}{\lambda_2})   \quad dz_2\\  &=1-{1\over \lambda_2} \int_0^\infty \exp\left(-{\sqrt\frac{c} {z_2}}-\frac{z_2}{\lambda_2}\right) dz_2\tag{1}}$$ I know that $\int_0^\infty \exp\left(-{\frac{\beta} {4z_2}}-{z_2 \gamma}\right) dz_2 = \sqrt{β\over\gamma}K_1(\sqrt{\beta\gamma})$ from Table of Integrals, Series and Products, 7th edition - equation §3.324.1]. However, the final form of above equation contains $\sqrt{}$ and therefore cannot be solved by using §3.324.1. So if you guys can comment or provide any kind of help that would be very helpful. My attempted sol (2): $$\eqalign{&=(X_1)^2  \leq \frac{a  x} {X_2}\\ &=\int_0^\infty     X_2  \leq {\frac{a  x} {z_1^2}}    \quad f_{X_1}(z_1) dz_1\\ &= {1\over \lambda_1} \int_0^\infty     \left(1-\exp\big(-{\frac{a  x} {z_1^2 \lambda_2}}\big)\right) \exp(-\frac{z_1}{\lambda_1})   \quad dz_1\\  &=1-{1\over \lambda_1} \int_0^\infty \exp\left(-{\frac{c} {z_1^2}}-\frac{z_1}{\lambda_1}\right) dz_1\tag{1}}$$ Once again to the best my knowledge this above equation doesn't submit to any closed form solution. So I am stuck here.... Since, X is exponential r.v with mean $\lambda$, then $X^{1\over\gamma}$ is a Weibull (γ, β) random variable. Can we solve it this way? by using the CDF or pdf of weibull during conditioning? Any kind of help will be very much appreciated.",,"['probability', 'probability-distributions', 'random-variables']"
68,Selection of three numbers from $0$ to $11$ with sum $12$,Selection of three numbers from  to  with sum,0 11 12,"If  $12$  tickets  numbered  $0,  1,  2, \ldots 11$  are  placed  in  a  bag,  and  three  are  drawn  out,  show that  the  chance that  the  sum  of  the  numbers  on  them  is  equal  to  12  is   $\frac{3n}{(6n-1)(6n-2)}=\frac{3}{55}$ My approach: Let us select three number from $12$: $\binom{12}{3}=220$ Now  I use the concept, I am taking $12$ initially $$ x_1+ x_2+ x_3=12$$ $x_1, x_2, x_3$  are non-negative. Number of Cases are $\binom{12+3-1}{3-1}=\binom{14}{2}=91$ Remove three case $(12,0,0),(0,12,0)$ and $(0,0,12)$, as I have taken $12$ which is not required. Number of Cases are $91-3=88$ My answer is $$\frac{88}{220}=\frac{2}{5}$$ Please help me.","If  $12$  tickets  numbered  $0,  1,  2, \ldots 11$  are  placed  in  a  bag,  and  three  are  drawn  out,  show that  the  chance that  the  sum  of  the  numbers  on  them  is  equal  to  12  is   $\frac{3n}{(6n-1)(6n-2)}=\frac{3}{55}$ My approach: Let us select three number from $12$: $\binom{12}{3}=220$ Now  I use the concept, I am taking $12$ initially $$ x_1+ x_2+ x_3=12$$ $x_1, x_2, x_3$  are non-negative. Number of Cases are $\binom{12+3-1}{3-1}=\binom{14}{2}=91$ Remove three case $(12,0,0),(0,12,0)$ and $(0,0,12)$, as I have taken $12$ which is not required. Number of Cases are $91-3=88$ My answer is $$\frac{88}{220}=\frac{2}{5}$$ Please help me.",,"['probability', 'combinatorics']"
69,Showing that a statistic is minimal sufficient but not complete uniform distribution,Showing that a statistic is minimal sufficient but not complete uniform distribution,,"Let $X_1, \cdots, X_n$ be iid from a uniform distribution    $U[\theta-\frac{1}{2}, \theta+\frac{1}{2}]$ with $\theta \in  \mathbb{R}$ unknown. Show that the statistic $T(\mathbf{X}) =  (X_{(1)}, X_{(n)})$ is minimal sufficient but not complete. I am having trouble proving that it is not complete. My idea is as follows. If I can somehow create two functions of $T(\mathbf{X})$, say $f(X_{(1)}, X_{(n)})$ and $g(X_{(1)}, X_{(n)})$ where $f \neq g$ but show that both are unbiased estimators of $\theta$, then $T(\mathbf{X}) = (X_{(1)}, X_{(n)})$ cannot possibly be complete. Is this the right approach? I am stuck because I am unsure 1) How to find the expectations/distributions of the order statistics and 2) How to construct $f$ and $g$. Any help would be appreciated!","Let $X_1, \cdots, X_n$ be iid from a uniform distribution    $U[\theta-\frac{1}{2}, \theta+\frac{1}{2}]$ with $\theta \in  \mathbb{R}$ unknown. Show that the statistic $T(\mathbf{X}) =  (X_{(1)}, X_{(n)})$ is minimal sufficient but not complete. I am having trouble proving that it is not complete. My idea is as follows. If I can somehow create two functions of $T(\mathbf{X})$, say $f(X_{(1)}, X_{(n)})$ and $g(X_{(1)}, X_{(n)})$ where $f \neq g$ but show that both are unbiased estimators of $\theta$, then $T(\mathbf{X}) = (X_{(1)}, X_{(n)})$ cannot possibly be complete. Is this the right approach? I am stuck because I am unsure 1) How to find the expectations/distributions of the order statistics and 2) How to construct $f$ and $g$. Any help would be appreciated!",,"['probability', 'statistics', 'uniform-distribution', 'sufficient-statistics']"
70,Probability of two events occurring at overlapping times,Probability of two events occurring at overlapping times,,"I am trying to workout something at work and would like some input/feedback. I have a 1km section of road and I would like to figure out the probability of 2 vehicles passing each other over an hour period. Lets say the road runs north-to-south and there are  26 vehicles travelling northbound and 22 vehicles travelling southbound. If the vehicles travel at 50km/h and their arrival is evenly distributed over the hour for each direction, what is the probability that two vehicles will pass each other over the 1km section? Initially I worked through it as follows but i suspect it is not as simple as this; 1km @ 50km/h - 72 seconds per trip. Therefore, over an hour there are 50 72 second blocks. $(26/50)*(22/50) = 22.9%$ This is clearly wrong because it doesn't consider overlapping time periods. Which i'm not sure how to consider. Any help would be great! Thanks.","I am trying to workout something at work and would like some input/feedback. I have a 1km section of road and I would like to figure out the probability of 2 vehicles passing each other over an hour period. Lets say the road runs north-to-south and there are  26 vehicles travelling northbound and 22 vehicles travelling southbound. If the vehicles travel at 50km/h and their arrival is evenly distributed over the hour for each direction, what is the probability that two vehicles will pass each other over the 1km section? Initially I worked through it as follows but i suspect it is not as simple as this; 1km @ 50km/h - 72 seconds per trip. Therefore, over an hour there are 50 72 second blocks. $(26/50)*(22/50) = 22.9%$ This is clearly wrong because it doesn't consider overlapping time periods. Which i'm not sure how to consider. Any help would be great! Thanks.",,"['probability', 'probability-theory']"
71,Group Russian Roulette,Group Russian Roulette,,"This problem is from ""Mathematical Puzzles: A Connoisseur's Collection"" (P. Winkler, AK Peters, 2005) as the opening puzzle in the chapter ""Probability"". There are N armed people. At each chime of a clock everyone spins around and shoots a random other person. That person falls dead. AT THE NEXT CHIME, The survivors shoot again. Eventually either everyone is dead, or there is a single survivor. Given N, what is the chance that this game ends with a single survivor? Winkler's problem asks "" What is the probability of there being a survivor as N increases to infinity. The answer says ""Amazingly, this probability does not tend to a limit as N grows. ... "". The seeming simplicity of this problem made me think it would be easy to find an expression for the probability of a survivor as a function of N. I got nowhere, so i put it out here to see if anyone could provide some insight. I thought it should be pretty straightforward, but it already gets bogged down to compute the probability of there being a survivor even when N is as low as 4 or 5. So, here's my question-   What is the probability, that with N shooters,  one will be left standing??","This problem is from ""Mathematical Puzzles: A Connoisseur's Collection"" (P. Winkler, AK Peters, 2005) as the opening puzzle in the chapter ""Probability"". There are N armed people. At each chime of a clock everyone spins around and shoots a random other person. That person falls dead. AT THE NEXT CHIME, The survivors shoot again. Eventually either everyone is dead, or there is a single survivor. Given N, what is the chance that this game ends with a single survivor? Winkler's problem asks "" What is the probability of there being a survivor as N increases to infinity. The answer says ""Amazingly, this probability does not tend to a limit as N grows. ... "". The seeming simplicity of this problem made me think it would be easy to find an expression for the probability of a survivor as a function of N. I got nowhere, so i put it out here to see if anyone could provide some insight. I thought it should be pretty straightforward, but it already gets bogged down to compute the probability of there being a survivor even when N is as low as 4 or 5. So, here's my question-   What is the probability, that with N shooters,  one will be left standing??",,['probability']
72,Do Gaussians have a Compact Support,Do Gaussians have a Compact Support,,"My understanding of a probability distribution with compact support, means that the set of valid inputs to query the probability for much be compact. And that in this basically mean that that that set must be bounded, and closed. The support for a $n$ dimensional Gaussian distribution is all of $\mathbb{R}^n$. It is not bounded, as far as I can tell -- you give me any point, and I can find a point that is further from the origin. (Or more generally, give me an open ball and I can find an open ball that encloses it). And (importantly perhaps) all mentioned points (in the open balls) are all points that have a chance that they could be sampled from a Gausssian distribution -- so they are actually in the support Thus the Gaussian distribution does not have a compact support. Is my reasoning correct? I ask because I am looking at a paper describing a non-parametric estimator, that only works for estimating distributions with a compact support, and their first example is estimating a Gaussian.","My understanding of a probability distribution with compact support, means that the set of valid inputs to query the probability for much be compact. And that in this basically mean that that that set must be bounded, and closed. The support for a $n$ dimensional Gaussian distribution is all of $\mathbb{R}^n$. It is not bounded, as far as I can tell -- you give me any point, and I can find a point that is further from the origin. (Or more generally, give me an open ball and I can find an open ball that encloses it). And (importantly perhaps) all mentioned points (in the open balls) are all points that have a chance that they could be sampled from a Gausssian distribution -- so they are actually in the support Thus the Gaussian distribution does not have a compact support. Is my reasoning correct? I ask because I am looking at a paper describing a non-parametric estimator, that only works for estimating distributions with a compact support, and their first example is estimating a Gaussian.",,"['probability', 'probability-distributions']"
73,Measure theory in practice,Measure theory in practice,,"I am trying to unite my knowledge of statistics and measure theory by considering the following example. Suppose we have a measurable space $(\Omega_1,B_1)$ and a random variable (measurable function) on the space, call it $X$: $\Omega_1 \rightarrow R$. Suppose we know the distribution function of $X$, say it is normal $X \sim N(0,1)$. Now consider the random variable  $$Y=X +5$$ We know from basic statistics that $Y\sim (5,1)$, but how can we prove that by using the definition of $X$ and composition of functions? Explanations that are step by step greatly appreciated!","I am trying to unite my knowledge of statistics and measure theory by considering the following example. Suppose we have a measurable space $(\Omega_1,B_1)$ and a random variable (measurable function) on the space, call it $X$: $\Omega_1 \rightarrow R$. Suppose we know the distribution function of $X$, say it is normal $X \sim N(0,1)$. Now consider the random variable  $$Y=X +5$$ We know from basic statistics that $Y\sim (5,1)$, but how can we prove that by using the definition of $X$ and composition of functions? Explanations that are step by step greatly appreciated!",,"['probability', 'statistics', 'measure-theory']"
74,Help understand a connection between probabilities of dice outcomes and number of elements of a hypercube,Help understand a connection between probabilities of dice outcomes and number of elements of a hypercube,,"I found a curious connection between probabilities of dice outcomes and number of elements of a hypercube and I can't make sense of it. I was trying to calculate odds of getting $0,1,..,x$ threes when rolling $x$ (hypothetical) 3-sided dice, i.e. when rolling 5 3-sided dice, what are the odds 2 of them will land on threes etc. The (AFAICT correct) odds are (for 0,1,2,3,4,5 threes respectively): 1 dice - $2/3$, $1/3$ 2 dice - $4/9$, $4/9$, $1/9$ 3 dice - $8/27$, $12/27$, $6/27$, $1/27$ 4 dice - $16/81$, $32/81$, $24/81$, $8/81$, $1/81$ 5 dice - $32/243$, $80/243$, $80/243$, $40/243$, $10/243$, $1/243$ Compare it with number of elements in x-dimentional cube (from wikipedia ): 1-cube - 2 vertices, 1 edge 2-cube - 4 vertices, 4 edges, 1 face 3-cube - 8 vertices, 12 edges, 6 faces, 1 cell 4-cube - 16 vertices, 32 edges, 24 faces, 8 cells, 1 4-face 5-cube - 32 vertices, 80 edges, 80 faces, 40 cells, 10 4-faces, 1 5-face This continues as least to 10 dice/dimensions. Same thing happens with 2-side dice (aka coins) and hyper-tetrahedron. Why do probabilities of rolling a certain dice face $y$ number of times on $x$ dice would match a number of elements of a $x$-dimentional shape like that?","I found a curious connection between probabilities of dice outcomes and number of elements of a hypercube and I can't make sense of it. I was trying to calculate odds of getting $0,1,..,x$ threes when rolling $x$ (hypothetical) 3-sided dice, i.e. when rolling 5 3-sided dice, what are the odds 2 of them will land on threes etc. The (AFAICT correct) odds are (for 0,1,2,3,4,5 threes respectively): 1 dice - $2/3$, $1/3$ 2 dice - $4/9$, $4/9$, $1/9$ 3 dice - $8/27$, $12/27$, $6/27$, $1/27$ 4 dice - $16/81$, $32/81$, $24/81$, $8/81$, $1/81$ 5 dice - $32/243$, $80/243$, $80/243$, $40/243$, $10/243$, $1/243$ Compare it with number of elements in x-dimentional cube (from wikipedia ): 1-cube - 2 vertices, 1 edge 2-cube - 4 vertices, 4 edges, 1 face 3-cube - 8 vertices, 12 edges, 6 faces, 1 cell 4-cube - 16 vertices, 32 edges, 24 faces, 8 cells, 1 4-face 5-cube - 32 vertices, 80 edges, 80 faces, 40 cells, 10 4-faces, 1 5-face This continues as least to 10 dice/dimensions. Same thing happens with 2-side dice (aka coins) and hyper-tetrahedron. Why do probabilities of rolling a certain dice face $y$ number of times on $x$ dice would match a number of elements of a $x$-dimentional shape like that?",,"['probability', 'dimension-theory-analysis']"
75,Beginner in Probability Needs Advice/Guidance,Beginner in Probability Needs Advice/Guidance,,"So, I work for SP+ and make garage signs for them. Most of the math I ever need is Geometry and maybe some trigonometry. My memory of calculus is faint, and I can only recall basic concepts of probability. While was at work, a question about probability and chance occurred to me. We had 20 signs made, but 3 had a missing punctuation. I know that means that 15% of the whole stack has to be fixed and that there is a 3 in 20 chance that whichever random sign I picked would need to be altered. My coworker took half the stack. This is when I thought to myself that I didn't know the chances of getting any of the three signs if half of the randomized stack was taken. My first thought was that half of 15% would be 7.5%. In other words, I would then have a 7.5% chance of getting a sign with a missing piece of vinyl (let's just refer to it as M for simplicity's sake). That seems too simple though. I don't think that would work, and even if it did how would I be able to figure out the chances of getting 1, 2, or all 3 signs in my stack? Adding 7.5 with itself doesn't feel correct. I tried asking my wife (she was a math major a few years back), and she didn't know nor really like probability. I tried googling it, but I'm not even sure what this concept would be called. I stumbled upon something called combining multiple probabilities, but I'm unfamiliar with some of the signs and concepts that are used in the equation. I'm basically leaping from basic probability to this complex problem. I need help in trying to figure this out because the question is continuously nagging at me. Where would I start in trying to figure this out? Is there a special name for this particular type of thing in math? And how would I be able to come to an answer for a similar question in the future?","So, I work for SP+ and make garage signs for them. Most of the math I ever need is Geometry and maybe some trigonometry. My memory of calculus is faint, and I can only recall basic concepts of probability. While was at work, a question about probability and chance occurred to me. We had 20 signs made, but 3 had a missing punctuation. I know that means that 15% of the whole stack has to be fixed and that there is a 3 in 20 chance that whichever random sign I picked would need to be altered. My coworker took half the stack. This is when I thought to myself that I didn't know the chances of getting any of the three signs if half of the randomized stack was taken. My first thought was that half of 15% would be 7.5%. In other words, I would then have a 7.5% chance of getting a sign with a missing piece of vinyl (let's just refer to it as M for simplicity's sake). That seems too simple though. I don't think that would work, and even if it did how would I be able to figure out the chances of getting 1, 2, or all 3 signs in my stack? Adding 7.5 with itself doesn't feel correct. I tried asking my wife (she was a math major a few years back), and she didn't know nor really like probability. I tried googling it, but I'm not even sure what this concept would be called. I stumbled upon something called combining multiple probabilities, but I'm unfamiliar with some of the signs and concepts that are used in the equation. I'm basically leaping from basic probability to this complex problem. I need help in trying to figure this out because the question is continuously nagging at me. Where would I start in trying to figure this out? Is there a special name for this particular type of thing in math? And how would I be able to come to an answer for a similar question in the future?",,"['probability', 'probability-theory', 'statistics']"
76,Which one of the following is correct?,Which one of the following is correct?,,"In an examination $30 \%$ of the students failed in Mathematics, $15 \%$ of the students failed in English and   $10 \%$ of the students failed in both Mathematics and English. A student is chosen at random. If he failed in   English then the probability that he passed in Mathematics is $(a)$ $\frac {1} {2}.$ $(b)$ $\frac {1} {10}.$ $(c)$ $\frac {1} {3}.$ $(d)$ $\frac {7} {10}.$ My attempt $:$ Suppose if we take $100$ students as the total number of students in the class. Then out of these $100$ the number of students qualify in Mathematics is $70$ and the number of students qualify in English is $85$. Since $10$ were failed in both the subjects. So the total number of students who qualify in both the subjects is $70+85-90=65.$ So the number of students who have qualified in Mathematics but not in English is $70-65=5.$ Now the total number of students who have not qualified in English is given as $15$ and hence the required probability is $\frac {5} {15}$ which simplifies to $\frac {1} {3}.$ So according to me $(c)$ is the correct option. Is the above reasoning correct at all? Please verify it. Thank you in advance.","In an examination $30 \%$ of the students failed in Mathematics, $15 \%$ of the students failed in English and   $10 \%$ of the students failed in both Mathematics and English. A student is chosen at random. If he failed in   English then the probability that he passed in Mathematics is $(a)$ $\frac {1} {2}.$ $(b)$ $\frac {1} {10}.$ $(c)$ $\frac {1} {3}.$ $(d)$ $\frac {7} {10}.$ My attempt $:$ Suppose if we take $100$ students as the total number of students in the class. Then out of these $100$ the number of students qualify in Mathematics is $70$ and the number of students qualify in English is $85$. Since $10$ were failed in both the subjects. So the total number of students who qualify in both the subjects is $70+85-90=65.$ So the number of students who have qualified in Mathematics but not in English is $70-65=5.$ Now the total number of students who have not qualified in English is given as $15$ and hence the required probability is $\frac {5} {15}$ which simplifies to $\frac {1} {3}.$ So according to me $(c)$ is the correct option. Is the above reasoning correct at all? Please verify it. Thank you in advance.",,['probability']
77,Is $c+Y$ lognormal?,Is  lognormal?,c+Y,"Let $Y$ be a lognormal random variable and let $c>0$ be a constant. Is $c+Y$ lognormal? My attempt: We need to check if $X=\log(c+Y)$ is a normal random variable. Let $F_X$ denote the cumulative distribution function of $X$. Since $Y$ is lognormal, $\log (Y)$ is a normal random variable. In particular this means that $Y>0$. $\begin{aligned}[t] F_X(x)&=P\{X\le x\} \\ &=P\{\log(c+Y)\le x\} \\ &=P\{c+Y\le e^x\} \\ &=P\{Y\le e^x-c\} \end{aligned}$ We have already noted that $Y>0$. So, if $e^x-c$ is negative, $P\{Y\le e^x-c\}=0$. That is, $F_X(x)=0$ if $x<\log c$. But the cumulative distribution function of a normal random variable is always positive. So, $X$ is not a normal random variable. So, $c+Y$ is not lognormal. Is this correct? (I'm very new to probability.)","Let $Y$ be a lognormal random variable and let $c>0$ be a constant. Is $c+Y$ lognormal? My attempt: We need to check if $X=\log(c+Y)$ is a normal random variable. Let $F_X$ denote the cumulative distribution function of $X$. Since $Y$ is lognormal, $\log (Y)$ is a normal random variable. In particular this means that $Y>0$. $\begin{aligned}[t] F_X(x)&=P\{X\le x\} \\ &=P\{\log(c+Y)\le x\} \\ &=P\{c+Y\le e^x\} \\ &=P\{Y\le e^x-c\} \end{aligned}$ We have already noted that $Y>0$. So, if $e^x-c$ is negative, $P\{Y\le e^x-c\}=0$. That is, $F_X(x)=0$ if $x<\log c$. But the cumulative distribution function of a normal random variable is always positive. So, $X$ is not a normal random variable. So, $c+Y$ is not lognormal. Is this correct? (I'm very new to probability.)",,['probability']
78,Probability of $n$ heads if coin is flipped until 8 tails.,Probability of  heads if coin is flipped until 8 tails.,n,"Suppose a fair coin is flipped until 8 tails occur. Let X be the number of heads that appear. What is the probability mass function of X? I answered ${n- 1 \choose 7}*(0.5)^n$, since it is a negative binomial random variable but this got marked wrong. I don't see how to get to any other answer. Any help is appreciated!","Suppose a fair coin is flipped until 8 tails occur. Let X be the number of heads that appear. What is the probability mass function of X? I answered ${n- 1 \choose 7}*(0.5)^n$, since it is a negative binomial random variable but this got marked wrong. I don't see how to get to any other answer. Any help is appreciated!",,"['probability', 'combinatorics', 'statistics']"
79,"If a student is absent twice, then what is the probability that the student will miss at least one test?","If a student is absent twice, then what is the probability that the student will miss at least one test?",,"The probability that a teacher will give an unannounced test during   any class meeting is 1/5 . If a student is absent twice, then the   probability that the student will miss at least one test is ...? Answer given : 9/25 My attempt : Let $G$: event that the student gives the test; $N$: event that the student does not give the test $P(G):1/5$ $P(N):4/5$ Then the sample space is : $(GG, NN, NG, GN)$ Required elements in the sample space is : $\{NN, NG, GN\}$ $P(NG)=P(GN)= 4/25$ and $P(NN)= 16/25$ Required probability = $P(NG)+P(GN)+P(NN)=24/25$ What am I doing wrong here?","The probability that a teacher will give an unannounced test during   any class meeting is 1/5 . If a student is absent twice, then the   probability that the student will miss at least one test is ...? Answer given : 9/25 My attempt : Let $G$: event that the student gives the test; $N$: event that the student does not give the test $P(G):1/5$ $P(N):4/5$ Then the sample space is : $(GG, NN, NG, GN)$ Required elements in the sample space is : $\{NN, NG, GN\}$ $P(NG)=P(GN)= 4/25$ and $P(NN)= 16/25$ Required probability = $P(NG)+P(GN)+P(NN)=24/25$ What am I doing wrong here?",,['probability']
80,Symmetric alpha stable distributions with $X_1+X_2+\cdots+X_n \stackrel{d}{=} n^{1/\alpha}X$ as definition,Symmetric alpha stable distributions with  as definition,X_1+X_2+\cdots+X_n \stackrel{d}{=} n^{1/\alpha}X,"Suppose $X,X_1,X_2,\ldots$ are independent and identically distributed random variables with a symmetric distribution $F$. We say $F$ is symmetric $\alpha$ stable  where $0<\alpha\le 2$, if   $$X_1+X_2+\cdots+X_n \stackrel{d}{=} n^{1/\alpha}X, \ \ \mbox{for all} \ n\in\mathbb{N}$$ I wish to show that the characteristic function of $F$ is given by $\psi(t)=e^{-c|t|^{\alpha}}$. Breiman's probability book solve the general version of this problem (consider stable only, not symmetric). However, it uses infinite divisible distributions and lot of calculations. So I was wondering if there is a short argument for the symmetric case. My try: Note that using the equal in distribution relation $$\psi(t)=\psi\left(\frac{t}{n^{1/\alpha}}\right)^n$$ Enough to take $t>0$ as $\psi(t)=\psi(-t)$. Now taking limit we have $$\psi(t)=\lim_{n\to\infty}\psi\left(\frac{t}{n^{1/\alpha}}\right)^n=\exp\left(-\lim_{x\to 0^+}\frac{1-\psi(tx^{1/\alpha})}{x}\right)=\exp\left(-t^{\alpha}\lim_{z\to 0^+}\frac{1-\psi(z)}{z^\alpha}\right)$$ So it is enough to show that $\displaystyle \lim_{z\to 0^+}\frac{1-\psi(z)}{z^\alpha}$ exists and is non zero. However, I don't have any clue how to proceed from here. Any help/suggestions.","Suppose $X,X_1,X_2,\ldots$ are independent and identically distributed random variables with a symmetric distribution $F$. We say $F$ is symmetric $\alpha$ stable  where $0<\alpha\le 2$, if   $$X_1+X_2+\cdots+X_n \stackrel{d}{=} n^{1/\alpha}X, \ \ \mbox{for all} \ n\in\mathbb{N}$$ I wish to show that the characteristic function of $F$ is given by $\psi(t)=e^{-c|t|^{\alpha}}$. Breiman's probability book solve the general version of this problem (consider stable only, not symmetric). However, it uses infinite divisible distributions and lot of calculations. So I was wondering if there is a short argument for the symmetric case. My try: Note that using the equal in distribution relation $$\psi(t)=\psi\left(\frac{t}{n^{1/\alpha}}\right)^n$$ Enough to take $t>0$ as $\psi(t)=\psi(-t)$. Now taking limit we have $$\psi(t)=\lim_{n\to\infty}\psi\left(\frac{t}{n^{1/\alpha}}\right)^n=\exp\left(-\lim_{x\to 0^+}\frac{1-\psi(tx^{1/\alpha})}{x}\right)=\exp\left(-t^{\alpha}\lim_{z\to 0^+}\frac{1-\psi(z)}{z^\alpha}\right)$$ So it is enough to show that $\displaystyle \lim_{z\to 0^+}\frac{1-\psi(z)}{z^\alpha}$ exists and is non zero. However, I don't have any clue how to proceed from here. Any help/suggestions.",,"['probability', 'probability-theory', 'probability-distributions', 'characteristic-functions']"
81,"60 students are going to be split into two rooms, whats the probability that students A,B,C,D,E (which are super friends) end up toghether?","60 students are going to be split into two rooms, whats the probability that students A,B,C,D,E (which are super friends) end up toghether?",,"As the title says,  60 students are getting split into two rooms of $30$.  What is the probability that Ann, Belle, Clarice, Diego and Evelyn end up in the same room? I can't understand if the number $60$ influences the probability that they end up in the same room.  because if not, then it would be $\left(\frac{1}{2}\right)^5$.  But I do believe we have to take into account the other $55$ students and that the divisions have a limit of $30$ per each.","As the title says,  60 students are getting split into two rooms of $30$.  What is the probability that Ann, Belle, Clarice, Diego and Evelyn end up in the same room? I can't understand if the number $60$ influences the probability that they end up in the same room.  because if not, then it would be $\left(\frac{1}{2}\right)^5$.  But I do believe we have to take into account the other $55$ students and that the divisions have a limit of $30$ per each.",,"['probability', 'combinatorics', 'probability-theory']"
82,Monty Hall - 1000 Exercises in Probability,Monty Hall - 1000 Exercises in Probability,,"The following problem is exercise 1.4.5(a) in One Thousand Exercises in Probability : 5. The Monty Hall problem: goats and cars. (a) Cruel fate has made you a contestant in a game show; you have to choose one of three   doors. One conceals a new car, [sic] two conceal old goats. You   choose, but your choosen door is not opened immediately. Instead, the   presenter opens another door to reveal a goat, and he offers you the   opportunity to change your choice to the third door (unopened and so   far unchosen). Let $p$ be the (conditional) probability that the third   door conceals the car. The value of $p$ depends on the presenter's   protocol. Devise protocols to yield the values $p = \frac{1}{2}$, $p =\frac{2}{3}$.   Show that, for $\alpha \in [\frac{1}{2}, \frac{2}{3}]$,   there exists a protocol such that $p = \alpha$. Are you well advised   to change your choice to the third door? This is the solution given later in the book: 5. (a) One cannot compute probabilities without knowing the rules governing the conditional probabilities. If the first door chosen   conceals a goat, then the presenter has no choice in the door to be   opened, since exactly one of the remaining doors conceals a goat. If   the first door conceals the car, then a choice is necessary, and this   is governed by the protocol of the presenter. Consider two 'extremal'   protocols for this latter situation. (i) The presenter opens a door chosen at random from the two   available. (ii) There is some ordering of the doors (left to right, perhaps) and   the presenter opens the earlier door in this ordering which conceals a   goat. Analysis of the two situations yields $p = \frac{2}{3}$ under (i), and   $p = \frac{1}{2}$ under (ii). Let $\alpha \in [\frac{1}{2}, \frac{2}{3}]$, and suppose the presenter   possesses a coin which falls with heads upwards with probability   $\beta = 6\alpha - 3$. He flips the coin before the show, and adopts   strategy (i) if and only if the coin shows heads. The probability in   question is now $\frac{2}{3} \beta + \frac{1}{2}(1 - \beta) = \alpha$. You never lose by swapping, but whether you gain depends on the   presenter's protocol. This solution seems completely wrong to me for multiple reasons: The deterministic protocol adds information, and the probability shouldn't be reduced with more information. By switching, the contestant is guaranteed the car as long as he does not select the car first, and this outcome is independent of the chosen protocol, since the protocol only applies when the contestant selects the car first. This question appears to have already been answered on StackExchange, and the answer there is not in agreement with this given solution. As far as I can tell, the authors are confusing ""the conditional probability that the third door conceals the car"" with the conditional probability of winning by switching when the location of the car is unknown. To see what I mean, suppose we label the doors 1, 2, and 3, and we let $C^{(d)}$, $G^{(d)}$, and $S^{(d)}$ be the events that the $d$th door contains a car, contains a goat, or is first selected by the contestant, respectively. Let $d_1$, $d_2$, and $d_3$ be the doors first selected by the contestant, revealed by the host, and then leftover, respectively. With this notation, the conditional probability $p$ is $P(C^{(d_3)} | G^{(d_2)}, S^{(d_1)}) = \dfrac{P(C^{(d_3)}, G^{(d_2)} | S^{(d_1)})}{P(G^{(d_2)} | S^{(d_1)})} = \dfrac{\frac{2}{3}}{1} = \dfrac{2}{3}$ However, we can construct a specific situation where the conditional probability is $\frac{1}{2}$: Suppose the host always reveals the smallest numbered door containing a goat. If we take $d_1 = 3$ and $d_2 = 1$, then we have $P(C^{(2)} | G^{(1)}, S^{(3)}) = 1 - P(G^{(2)} | G^{(1)}, S^{(3)}) = 1 - \dfrac{P(G^{(2)}, G^{(1)} | S^{(3)})}{P(G^{(1)} | S^{(3)})} = 1 - \dfrac{\frac{1}{3}}{\frac{2}{3}} = \dfrac{1}{2}$ But this is a specific situation that relies on more than just the protocol of the host, since there is a $\frac{1}{3}$ chance that the car could be behind the first door, so that, by picking the third door and having the second door revealed, we would know with certainty that the car is behind door one before we switch. Thus, the conditional probability of $\frac{1}{2}$ is only attained when the location of the car is unknown after the reveal. (And our sanity check of $\frac{1}{3} \cdot 1 + \frac{2}{3} \cdot \frac{1}{2} = \frac{2}{3}$ agrees with our conditional probability $p$ that the third door contains a car, not knowing which specific doors are opened). That the authors made a mistake is further cemented in the last sentence of their solution: ""whether you gain depends on the presenter's protocol."" In fact, regardless of the presenter's protocol, there is always an event of non-zero probability where you benefit by swapping. It should read, ""whether you have the possibility of not gaining by switching after conditioning depends on the presenter's protocol."" Their solution seems wrong to me, but the authors have fancy credentials (Ph.D.s from Oxford) and positions at Oxford and Cambridge, so I'm hesitant to write it off as an error. It is possible I could have misread the problem or completely miscalculated the conditional probabilities. The details do, after all, seem rather nuanced. Is this problem/solution an error? Am I just nitpicking wording?","The following problem is exercise 1.4.5(a) in One Thousand Exercises in Probability : 5. The Monty Hall problem: goats and cars. (a) Cruel fate has made you a contestant in a game show; you have to choose one of three   doors. One conceals a new car, [sic] two conceal old goats. You   choose, but your choosen door is not opened immediately. Instead, the   presenter opens another door to reveal a goat, and he offers you the   opportunity to change your choice to the third door (unopened and so   far unchosen). Let $p$ be the (conditional) probability that the third   door conceals the car. The value of $p$ depends on the presenter's   protocol. Devise protocols to yield the values $p = \frac{1}{2}$, $p =\frac{2}{3}$.   Show that, for $\alpha \in [\frac{1}{2}, \frac{2}{3}]$,   there exists a protocol such that $p = \alpha$. Are you well advised   to change your choice to the third door? This is the solution given later in the book: 5. (a) One cannot compute probabilities without knowing the rules governing the conditional probabilities. If the first door chosen   conceals a goat, then the presenter has no choice in the door to be   opened, since exactly one of the remaining doors conceals a goat. If   the first door conceals the car, then a choice is necessary, and this   is governed by the protocol of the presenter. Consider two 'extremal'   protocols for this latter situation. (i) The presenter opens a door chosen at random from the two   available. (ii) There is some ordering of the doors (left to right, perhaps) and   the presenter opens the earlier door in this ordering which conceals a   goat. Analysis of the two situations yields $p = \frac{2}{3}$ under (i), and   $p = \frac{1}{2}$ under (ii). Let $\alpha \in [\frac{1}{2}, \frac{2}{3}]$, and suppose the presenter   possesses a coin which falls with heads upwards with probability   $\beta = 6\alpha - 3$. He flips the coin before the show, and adopts   strategy (i) if and only if the coin shows heads. The probability in   question is now $\frac{2}{3} \beta + \frac{1}{2}(1 - \beta) = \alpha$. You never lose by swapping, but whether you gain depends on the   presenter's protocol. This solution seems completely wrong to me for multiple reasons: The deterministic protocol adds information, and the probability shouldn't be reduced with more information. By switching, the contestant is guaranteed the car as long as he does not select the car first, and this outcome is independent of the chosen protocol, since the protocol only applies when the contestant selects the car first. This question appears to have already been answered on StackExchange, and the answer there is not in agreement with this given solution. As far as I can tell, the authors are confusing ""the conditional probability that the third door conceals the car"" with the conditional probability of winning by switching when the location of the car is unknown. To see what I mean, suppose we label the doors 1, 2, and 3, and we let $C^{(d)}$, $G^{(d)}$, and $S^{(d)}$ be the events that the $d$th door contains a car, contains a goat, or is first selected by the contestant, respectively. Let $d_1$, $d_2$, and $d_3$ be the doors first selected by the contestant, revealed by the host, and then leftover, respectively. With this notation, the conditional probability $p$ is $P(C^{(d_3)} | G^{(d_2)}, S^{(d_1)}) = \dfrac{P(C^{(d_3)}, G^{(d_2)} | S^{(d_1)})}{P(G^{(d_2)} | S^{(d_1)})} = \dfrac{\frac{2}{3}}{1} = \dfrac{2}{3}$ However, we can construct a specific situation where the conditional probability is $\frac{1}{2}$: Suppose the host always reveals the smallest numbered door containing a goat. If we take $d_1 = 3$ and $d_2 = 1$, then we have $P(C^{(2)} | G^{(1)}, S^{(3)}) = 1 - P(G^{(2)} | G^{(1)}, S^{(3)}) = 1 - \dfrac{P(G^{(2)}, G^{(1)} | S^{(3)})}{P(G^{(1)} | S^{(3)})} = 1 - \dfrac{\frac{1}{3}}{\frac{2}{3}} = \dfrac{1}{2}$ But this is a specific situation that relies on more than just the protocol of the host, since there is a $\frac{1}{3}$ chance that the car could be behind the first door, so that, by picking the third door and having the second door revealed, we would know with certainty that the car is behind door one before we switch. Thus, the conditional probability of $\frac{1}{2}$ is only attained when the location of the car is unknown after the reveal. (And our sanity check of $\frac{1}{3} \cdot 1 + \frac{2}{3} \cdot \frac{1}{2} = \frac{2}{3}$ agrees with our conditional probability $p$ that the third door contains a car, not knowing which specific doors are opened). That the authors made a mistake is further cemented in the last sentence of their solution: ""whether you gain depends on the presenter's protocol."" In fact, regardless of the presenter's protocol, there is always an event of non-zero probability where you benefit by swapping. It should read, ""whether you have the possibility of not gaining by switching after conditioning depends on the presenter's protocol."" Their solution seems wrong to me, but the authors have fancy credentials (Ph.D.s from Oxford) and positions at Oxford and Cambridge, so I'm hesitant to write it off as an error. It is possible I could have misread the problem or completely miscalculated the conditional probabilities. The details do, after all, seem rather nuanced. Is this problem/solution an error? Am I just nitpicking wording?",,['probability']
83,"On average, how many times will I need to roll a six-sided die before I see ten ONES in total?","On average, how many times will I need to roll a six-sided die before I see ten ONES in total?",,"On average, how many times will I need to roll a six-sided die before I see ten ONES in total? I'd like to be able to extend my knowledge to answer other questions in the same form, such as, ""If only 15% of fish are within the legal size limit, how many fish should I need to catch before I get five keepers? Thanks kindly","On average, how many times will I need to roll a six-sided die before I see ten ONES in total? I'd like to be able to extend my knowledge to answer other questions in the same form, such as, ""If only 15% of fish are within the legal size limit, how many fish should I need to catch before I get five keepers? Thanks kindly",,['probability']
84,absolute value of poisson random variable's deviation from a constant,absolute value of poisson random variable's deviation from a constant,,"Let $q\in \{0,1,2,\dotsc\}$ be a fixed constant and $N$ be a Poisson random variable with parameter $\lambda$. Let $X=|N-q|$. Determine $\mathbb{E}[|N-q|]$, if possible. So, we start out, $\mathbb{E}[X]=\sum_{n=1}^\infty P[X\geq n]=\sum_{n=1}^\infty (1-P[X< n]).$ Now, $P[X<n]=P[|N-q|<n]=P[q-n<N<q+n]=F_N(q+n-1)-F_N(q-n+1)$, where $F_N$ is the cumulative distribution function of $N$. But here I am having trouble simplifying this last expression. The cdf can be written in terms of the (incomplete) gamma function but I'm having trouble using that too. Any suggestions would be appreciated.","Let $q\in \{0,1,2,\dotsc\}$ be a fixed constant and $N$ be a Poisson random variable with parameter $\lambda$. Let $X=|N-q|$. Determine $\mathbb{E}[|N-q|]$, if possible. So, we start out, $\mathbb{E}[X]=\sum_{n=1}^\infty P[X\geq n]=\sum_{n=1}^\infty (1-P[X< n]).$ Now, $P[X<n]=P[|N-q|<n]=P[q-n<N<q+n]=F_N(q+n-1)-F_N(q-n+1)$, where $F_N$ is the cumulative distribution function of $N$. But here I am having trouble simplifying this last expression. The cdf can be written in terms of the (incomplete) gamma function but I'm having trouble using that too. Any suggestions would be appreciated.",,"['probability', 'poisson-distribution']"
85,"Is it possible that $\liminf_{n\to \infty }nU_n>0$ where $U_n\sim \mathcal U[0,1]$?",Is it possible that  where ?,"\liminf_{n\to \infty }nU_n>0 U_n\sim \mathcal U[0,1]","Let $U_n\sim \mathcal U[0,1]$ iid. Is it possible that $$\liminf_{n\to \infty } nU_n>0\ \ ?$$ I said no. Indeed, $\mathbb P\{U_n\leq u\}= u$. Therefore,  $$\sum_{n=1}^\infty \mathbb P\{nU_n\leq \varepsilon\}=\sum_{n=1}^\infty \mathbb P\{U_n\leq \frac{\varepsilon}{n}\}=\varepsilon\sum_{n=1}^\infty \frac{1}{n}=+\infty .$$ Therefore, by Borel-Cantelli 2nd Lemma, $$\mathbb P\{\limsup_{n\to \infty }nU_n\leq \varepsilon\}=1,$$ and thus, $$\limsup_{n\to \infty }nU_n=0\ \ a.s.$$ Since $nU_n\geq 0$ a.s. we have that $\liminf_{n\to \infty }nU_n=0$ a.s. what conclude the claim. Is it correct ?","Let $U_n\sim \mathcal U[0,1]$ iid. Is it possible that $$\liminf_{n\to \infty } nU_n>0\ \ ?$$ I said no. Indeed, $\mathbb P\{U_n\leq u\}= u$. Therefore,  $$\sum_{n=1}^\infty \mathbb P\{nU_n\leq \varepsilon\}=\sum_{n=1}^\infty \mathbb P\{U_n\leq \frac{\varepsilon}{n}\}=\varepsilon\sum_{n=1}^\infty \frac{1}{n}=+\infty .$$ Therefore, by Borel-Cantelli 2nd Lemma, $$\mathbb P\{\limsup_{n\to \infty }nU_n\leq \varepsilon\}=1,$$ and thus, $$\limsup_{n\to \infty }nU_n=0\ \ a.s.$$ Since $nU_n\geq 0$ a.s. we have that $\liminf_{n\to \infty }nU_n=0$ a.s. what conclude the claim. Is it correct ?",,"['probability', 'proof-verification']"
86,Splitting of Poisson processes and Bernoulli trials,Splitting of Poisson processes and Bernoulli trials,,"When a Poisson process is split according to the results of independent Bernoulli trials, two Poisson processes are obtained. It is trivial to prove that these two processes are independent. I was examining the converse. If a Poisson process is split in two Poisson processes, is it necessary that the split takes place according to the results of Bernoulli trials? I was able to prove this on condition that the two processes are independent. Is it possible to prove this without the previous condition?","When a Poisson process is split according to the results of independent Bernoulli trials, two Poisson processes are obtained. It is trivial to prove that these two processes are independent. I was examining the converse. If a Poisson process is split in two Poisson processes, is it necessary that the split takes place according to the results of Bernoulli trials? I was able to prove this on condition that the two processes are independent. Is it possible to prove this without the previous condition?",,"['probability', 'poisson-process']"
87,Logarithm of Brownian Motion - local martingale but not martingale.,Logarithm of Brownian Motion - local martingale but not martingale.,,"I have just started studying stochastic analysis and I am stuck on trying to show that for $B$ a two-dimensional Brownian motion, $\ X_t=\log\left(\left|B_t\right|\right)_t$ is a local martingale but not a martingale. I saw people trying to tackle such questions using Ito integrals, but being one of the first things in my course, I imagine there is an elementary way to think about this, and I would be very curious about it? In particular, what sequence of stopping times should I use?  Intuitively I imagine it has to do with the fact that the stopped process is uniformly integrable, so we can apply Doob's stopping theorem. I would be extremely grateful if someone could please explain these details to me? Thank you very much for your time and help!!","I have just started studying stochastic analysis and I am stuck on trying to show that for $B$ a two-dimensional Brownian motion, $\ X_t=\log\left(\left|B_t\right|\right)_t$ is a local martingale but not a martingale. I saw people trying to tackle such questions using Ito integrals, but being one of the first things in my course, I imagine there is an elementary way to think about this, and I would be very curious about it? In particular, what sequence of stopping times should I use?  Intuitively I imagine it has to do with the fact that the stopped process is uniformly integrable, so we can apply Doob's stopping theorem. I would be extremely grateful if someone could please explain these details to me? Thank you very much for your time and help!!",,"['probability', 'brownian-motion', 'martingales', 'stochastic-analysis']"
88,Probability related to circle,Probability related to circle,,Let we have to select point nearer to center then the circumference of a given circle. What is the probability of finding such points? I am confused that points at distance$\frac{r}{2}$must be favorable or not,Let we have to select point nearer to center then the circumference of a given circle. What is the probability of finding such points? I am confused that points at distance$\frac{r}{2}$must be favorable or not,,['probability']
89,Is there a maximal prime number not being a sum of consecutive primes?,Is there a maximal prime number not being a sum of consecutive primes?,,"Let $\mathcal S=\{p\in\mathbb P|\exists m,n\in\mathbb Z_+:p=p_n+\cdots+p_{n+m}\}$. For ""small"" primes, not much greater than one million, it seems that about half of the primes belong to $\mathcal S$. But the greater primes the more combinations of consecutive primes available. There are $\pi(p)$ primes less than or equal to $p$ and the number of available prime sequences is  $1\cdot\pi(p)+2\cdot(\pi(p)-1)+3(\pi(p)-2)+\cdots+(\pi(p)-1)\cdot 2=$ $\displaystyle\frac{\pi(p)^3+3\pi(p)^2+4\pi(p)}{6}$ (If I calculated it right). I suppose it's possible to use the Prime Number Theorem to estimate the probability of $p\in\mathcal S$, but I'm pretty sure that I would mess it up. My questions are: Does $P(p\in\mathcal S)\to 1$ as $p\to\infty$? Can it be proved that there is a maximal prime number not being a sum of consecutive primes? See also How often is a sum of $k$ consecutive primes also prime? which is a similar but not an equivalent question. This is what I got so far. It doesn't support my intuition, but I will let it run up to $10,000,000$ or more.","Let $\mathcal S=\{p\in\mathbb P|\exists m,n\in\mathbb Z_+:p=p_n+\cdots+p_{n+m}\}$. For ""small"" primes, not much greater than one million, it seems that about half of the primes belong to $\mathcal S$. But the greater primes the more combinations of consecutive primes available. There are $\pi(p)$ primes less than or equal to $p$ and the number of available prime sequences is  $1\cdot\pi(p)+2\cdot(\pi(p)-1)+3(\pi(p)-2)+\cdots+(\pi(p)-1)\cdot 2=$ $\displaystyle\frac{\pi(p)^3+3\pi(p)^2+4\pi(p)}{6}$ (If I calculated it right). I suppose it's possible to use the Prime Number Theorem to estimate the probability of $p\in\mathcal S$, but I'm pretty sure that I would mess it up. My questions are: Does $P(p\in\mathcal S)\to 1$ as $p\to\infty$? Can it be proved that there is a maximal prime number not being a sum of consecutive primes? See also How often is a sum of $k$ consecutive primes also prime? which is a similar but not an equivalent question. This is what I got so far. It doesn't support my intuition, but I will let it run up to $10,000,000$ or more.",,"['probability', 'number-theory', 'prime-numbers', 'conjectures']"
90,How well does probability work in the real world?,How well does probability work in the real world?,,"When I was first introduced to probability at the age of about 13, me and my classmates always used to ridicule the subject in a most immature manner. We used to take a deck of well shuffled cards and 'test' the results of probability. For instance the probability of picking a spade was 25%. That is a 1 in 4 chance. We tested this by picking four cards. We got 3 hearts and a dice. We didn't get the expected 1 spade card neither did we get the expected 2 black cards. Hence we decided the science was a silly one. Looking back at those days when I'm currently majoring in math sure does make me laugh. Though I know that probability has more to it, I have not dealt with it at a theoretical level and neither do I know how to argue with children such as the ones we were once upon a time. If a child comes and claims that he tested the outcomes expected by probability and every test failed against probability's favour, I do not know how to argue with him. All I have are trust in Mathematics and the economics, sociology and quantum theory to which probability has proved to be an asset. But that is my opinion and not a proper answer. But I want to answer the child some day....how is probability justified? What is the difference between a 50-50 chance and an indeterminable probability? Well, the 50-50 chance doesn't mean that the outcomes are going to vary alternatively (head, tail, head, tail....); the outcome is more likely (head, head, tail, tail, tail, head, tail....) doesn't my that mean it's indeterminate? If probability claims that the 50-50 chance works only in ideal situations does that mean that in such a hypothetical ideal world, the toss outcome will alternate uniformly? I'm tempted to tell the child that the answer is that probability deals with idealised situations and that's why the results vary. But I shall be a criminal if the child assumes (because of me) that probability is simply a theoretical study of idealised situations that finds no use in real world situations. I cannot mislead the child and I cannot simply live on opinion and trust. What is the answer to the child's question?","When I was first introduced to probability at the age of about 13, me and my classmates always used to ridicule the subject in a most immature manner. We used to take a deck of well shuffled cards and 'test' the results of probability. For instance the probability of picking a spade was 25%. That is a 1 in 4 chance. We tested this by picking four cards. We got 3 hearts and a dice. We didn't get the expected 1 spade card neither did we get the expected 2 black cards. Hence we decided the science was a silly one. Looking back at those days when I'm currently majoring in math sure does make me laugh. Though I know that probability has more to it, I have not dealt with it at a theoretical level and neither do I know how to argue with children such as the ones we were once upon a time. If a child comes and claims that he tested the outcomes expected by probability and every test failed against probability's favour, I do not know how to argue with him. All I have are trust in Mathematics and the economics, sociology and quantum theory to which probability has proved to be an asset. But that is my opinion and not a proper answer. But I want to answer the child some day....how is probability justified? What is the difference between a 50-50 chance and an indeterminable probability? Well, the 50-50 chance doesn't mean that the outcomes are going to vary alternatively (head, tail, head, tail....); the outcome is more likely (head, head, tail, tail, tail, head, tail....) doesn't my that mean it's indeterminate? If probability claims that the 50-50 chance works only in ideal situations does that mean that in such a hypothetical ideal world, the toss outcome will alternate uniformly? I'm tempted to tell the child that the answer is that probability deals with idealised situations and that's why the results vary. But I shall be a criminal if the child assumes (because of me) that probability is simply a theoretical study of idealised situations that finds no use in real world situations. I cannot mislead the child and I cannot simply live on opinion and trust. What is the answer to the child's question?",,"['probability', 'soft-question']"
91,Intuition on why the density function of a normal law is$\frac{1}{\sqrt{2\pi \sigma^2 }}e^{-\frac{(x-\mu)^2}{2\sigma^2 }}$,Intuition on why the density function of a normal law is,\frac{1}{\sqrt{2\pi \sigma^2 }}e^{-\frac{(x-\mu)^2}{2\sigma^2 }},"What is the intuition of the fact that the density function of a normal law $\mathcal N(\mu,\sigma ^2)$ is given by $$f(x)=\frac{1}{\sqrt{2\pi \sigma^2 }}e^{\large-\frac{(x-\mu)^2}{2\sigma^2 }}?$$ It looks to come from nowhere. For example, the intuition of a poisson law is in fact very natural considering rare event (and binomial law). For the normal law, I really have no idea of the intuition behind, neither why it's so common in the nature ! How did we get to this (incredible) result. How does it work ?","What is the intuition of the fact that the density function of a normal law $\mathcal N(\mu,\sigma ^2)$ is given by $$f(x)=\frac{1}{\sqrt{2\pi \sigma^2 }}e^{\large-\frac{(x-\mu)^2}{2\sigma^2 }}?$$ It looks to come from nowhere. For example, the intuition of a poisson law is in fact very natural considering rare event (and binomial law). For the normal law, I really have no idea of the intuition behind, neither why it's so common in the nature ! How did we get to this (incredible) result. How does it work ?",,"['probability', 'normal-distribution']"
92,$X_n \to 0$ in probability iff $E\left( \frac{|X_n|}{1+|X_n|}\right) \to 0$,in probability iff,X_n \to 0 E\left( \frac{|X_n|}{1+|X_n|}\right) \to 0,"Good day, In class we had the exercise as stated in the title: Show that $X_n \to 0$ in probability for $n\to \infty$ iff $E\left( \frac{|X_n|}{1+|X_n|}\right) \to 0$ for $n \to \infty$. And the solution is the following: $""\Leftarrow""$ Assume that $E\left( \frac{|X_n|}{1+|X_n|}\right)\to 0$ and let $\epsilon>0$. Then, according to Markovs inequality, we have  $$P(|X_n|>\epsilon)\color{red}{=}P\left(\frac{|X_n|}{1+|X_n|}>\frac{\epsilon}{1+\epsilon}\right) \leq \frac{\epsilon}{1+\epsilon} E\left( \frac{|X_n|}{1+|X_n|}\right) \to 0 $$ $""\Rightarrow""$ Assume $X_n \to 0$ in probability, then $$E\left( \frac{|X_n|}{1+|X_n|}\right)\color{orange}{\leq}\frac{\epsilon}{1+\epsilon}\cdot P(|X_n|\leq \epsilon)+1\cdot P(|X_n|>\epsilon) \to \frac{\epsilon}{1+\epsilon} \to 0$$ To be honest I have some problems with the solution. They are as following: $""\color{red}{=}""$ How? My try: $P(|X_n|>\epsilon)=P\left(\frac{|X_n|}{1+|X_n|}>\frac{\epsilon}{1+|X_n|}\right)$ but how do I get this to above formulation? $""\color{orange}{\leq}""$ It seems a bit like $E(X)=\sum x_i p_i$ but I don't get how this inequality is proved. As a hint to the exercise there was: $f(u)=\frac{u}{1+u}$ is strictly increasing on $[0,\infty)$. So this should come into play somewhere in the answer to my questions I guess. Can someone please hep me with these two questions? Thanks a lot, Marvin","Good day, In class we had the exercise as stated in the title: Show that $X_n \to 0$ in probability for $n\to \infty$ iff $E\left( \frac{|X_n|}{1+|X_n|}\right) \to 0$ for $n \to \infty$. And the solution is the following: $""\Leftarrow""$ Assume that $E\left( \frac{|X_n|}{1+|X_n|}\right)\to 0$ and let $\epsilon>0$. Then, according to Markovs inequality, we have  $$P(|X_n|>\epsilon)\color{red}{=}P\left(\frac{|X_n|}{1+|X_n|}>\frac{\epsilon}{1+\epsilon}\right) \leq \frac{\epsilon}{1+\epsilon} E\left( \frac{|X_n|}{1+|X_n|}\right) \to 0 $$ $""\Rightarrow""$ Assume $X_n \to 0$ in probability, then $$E\left( \frac{|X_n|}{1+|X_n|}\right)\color{orange}{\leq}\frac{\epsilon}{1+\epsilon}\cdot P(|X_n|\leq \epsilon)+1\cdot P(|X_n|>\epsilon) \to \frac{\epsilon}{1+\epsilon} \to 0$$ To be honest I have some problems with the solution. They are as following: $""\color{red}{=}""$ How? My try: $P(|X_n|>\epsilon)=P\left(\frac{|X_n|}{1+|X_n|}>\frac{\epsilon}{1+|X_n|}\right)$ but how do I get this to above formulation? $""\color{orange}{\leq}""$ It seems a bit like $E(X)=\sum x_i p_i$ but I don't get how this inequality is proved. As a hint to the exercise there was: $f(u)=\frac{u}{1+u}$ is strictly increasing on $[0,\infty)$. So this should come into play somewhere in the answer to my questions I guess. Can someone please hep me with these two questions? Thanks a lot, Marvin",,"['probability', 'probability-theory', 'proof-verification']"
93,What is the probability of shuffling a deck and not getting a repeating card for the whole deck? [duplicate],What is the probability of shuffling a deck and not getting a repeating card for the whole deck? [duplicate],,"This question already has an answer here : No two identical ranks together in a standard deck of cards (1 answer) Closed 7 years ago . What are the odds of shuffling a deck of 52 cards and going through each card one by one without getting any repeats (like 2 kings back to back). I'm bad at this kind of deduction, but at a high level it seems roughly like 1 in 13 odds over 52 iterations. Can anyone provide a more accurate approach to solving this?","This question already has an answer here : No two identical ranks together in a standard deck of cards (1 answer) Closed 7 years ago . What are the odds of shuffling a deck of 52 cards and going through each card one by one without getting any repeats (like 2 kings back to back). I'm bad at this kind of deduction, but at a high level it seems roughly like 1 in 13 odds over 52 iterations. Can anyone provide a more accurate approach to solving this?",,[]
94,Bridge probability question,Bridge probability question,,"Standard 52-card deck:   suits: clubs (♣), diamonds (♦), hearts (♥) and spades (♠)   each suit possible cards and their values being:A,2,3,4,5,6,7,8,9,10,J,Q,k  now 4 men pick the deck in turn. pick one card each time. at last each one has 13 cards in hand.  The probability question is    <1> what is the probability for at least one men hold 13 cards of same suit.   <2> what is the probability for only the first man hold 13 cards of same suit I think the 1> in halfway and stuck there:      4 *  13! * 39! / 52!, but this number is not the result, I think it still need to be divided by a number, I think the number is just the ways of allocating 13 same balls to 52 boxes.","Standard 52-card deck:   suits: clubs (♣), diamonds (♦), hearts (♥) and spades (♠)   each suit possible cards and their values being:A,2,3,4,5,6,7,8,9,10,J,Q,k  now 4 men pick the deck in turn. pick one card each time. at last each one has 13 cards in hand.  The probability question is    <1> what is the probability for at least one men hold 13 cards of same suit.   <2> what is the probability for only the first man hold 13 cards of same suit I think the 1> in halfway and stuck there:      4 *  13! * 39! / 52!, but this number is not the result, I think it still need to be divided by a number, I think the number is just the ways of allocating 13 same balls to 52 boxes.",,"['probability', 'card-games']"
95,Conditional expectation of a product XY given Z with Y independent of Z,Conditional expectation of a product XY given Z with Y independent of Z,,"Let $X,Y$   and $Z$   be integrable random variables s.t. $XY$   is integrable and $Y$   is independent of $Z$  . I was wondering if there are any helpful/common ways of rewriting $\mathbb{E}[XY\mid Z]$ when $Y$ is independent of $Z$   (and nothing more is known)? For example, if $X$   and $Y$   are conditionally independent given $Z$  , then (more or less by definition - depending on your point of view) $\mathbb{E}[XY\mid Z]=\mathbb{E}[X\mid Z]\mathbb{E}[Y\mid Z]$. But this is quite clearly not true in general.","Let $X,Y$   and $Z$   be integrable random variables s.t. $XY$   is integrable and $Y$   is independent of $Z$  . I was wondering if there are any helpful/common ways of rewriting $\mathbb{E}[XY\mid Z]$ when $Y$ is independent of $Z$   (and nothing more is known)? For example, if $X$   and $Y$   are conditionally independent given $Z$  , then (more or less by definition - depending on your point of view) $\mathbb{E}[XY\mid Z]=\mathbb{E}[X\mid Z]\mathbb{E}[Y\mid Z]$. But this is quite clearly not true in general.",,"['probability', 'measure-theory']"
96,Sigma algebra generated by the stopped process.,Sigma algebra generated by the stopped process.,,"Let $(X_n)_{n \geq 0}$ be a sequence of random variables. Let $\mathcal{F}_n = \sigma (X_0, \dots, X_n)$ be a filtration and $T$ is a $(\mathcal{F}_n)_{n\geq 0}$-stopping time. I want to understand whether $$\sigma (X_{n \wedge T}, n \geq 0) =^? \sigma \left( \mathcal{F}_{n \wedge T}, n \geq 0 \right).$$ My intuition tells me that   $\sigma \left( \mathcal{F}_{n \wedge T}, n \geq 0 \right)$ must be larger, but I can't find an example showing it.","Let $(X_n)_{n \geq 0}$ be a sequence of random variables. Let $\mathcal{F}_n = \sigma (X_0, \dots, X_n)$ be a filtration and $T$ is a $(\mathcal{F}_n)_{n\geq 0}$-stopping time. I want to understand whether $$\sigma (X_{n \wedge T}, n \geq 0) =^? \sigma \left( \mathcal{F}_{n \wedge T}, n \geq 0 \right).$$ My intuition tells me that   $\sigma \left( \mathcal{F}_{n \wedge T}, n \geq 0 \right)$ must be larger, but I can't find an example showing it.",,"['probability', 'random-variables', 'stopping-times', 'filtrations']"
97,Question on proving tight sequences.,Question on proving tight sequences.,,"I was just wondering how you would go about showing that a sequence of random variables is a tight sequence. For example suppose $X_{n}$ is distributed Exponentially($\lambda_n$) how would I show that {$X_{n}$}$_{n}$ is a tight sequence. Is it enough to show that if there exsists some M and $\epsilon > 0$, then if $P(|X_{n}| \ge M) < \epsilon$ it is a tight sequence? $P(|X_{n}| \ge M) < \epsilon$ $\implies$ $1-(1-\rm{e}^{-\lambda_{n}M}) = \rm{e}^{-\lambda_{n}M} < \epsilon$ Then if $M < \infty$ and take $\epsilon = 1$, then as long as $\lambda_{n}$ is bounded away from zero it is a tight sequence. Is this correct? Thank you for any help.","I was just wondering how you would go about showing that a sequence of random variables is a tight sequence. For example suppose $X_{n}$ is distributed Exponentially($\lambda_n$) how would I show that {$X_{n}$}$_{n}$ is a tight sequence. Is it enough to show that if there exsists some M and $\epsilon > 0$, then if $P(|X_{n}| \ge M) < \epsilon$ it is a tight sequence? $P(|X_{n}| \ge M) < \epsilon$ $\implies$ $1-(1-\rm{e}^{-\lambda_{n}M}) = \rm{e}^{-\lambda_{n}M} < \epsilon$ Then if $M < \infty$ and take $\epsilon = 1$, then as long as $\lambda_{n}$ is bounded away from zero it is a tight sequence. Is this correct? Thank you for any help.",,"['probability', 'sequences-and-series', 'measure-theory', 'probability-distributions']"
98,Poisson Distribution from first arrival?,Poisson Distribution from first arrival?,,"Sorry if the question is too obvious or strange, I'm learning about Poisson distributions by myself. Say I have some independent process that follows a Poisson distribution of unknown rate (10 particles in 1D that have to get to a specific position where the process finishes) and that I know the mean time at which the first particle gets to that position (I run simulations and I can identify the first time a particle reaches that position, for example). How can I estimate the mean time at which the 10 particles have arrived to that position? Thanks a lot for any help! I thought it was just 10*time of the first one but that doesn't seem right, does it?","Sorry if the question is too obvious or strange, I'm learning about Poisson distributions by myself. Say I have some independent process that follows a Poisson distribution of unknown rate (10 particles in 1D that have to get to a specific position where the process finishes) and that I know the mean time at which the first particle gets to that position (I run simulations and I can identify the first time a particle reaches that position, for example). How can I estimate the mean time at which the 10 particles have arrived to that position? Thanks a lot for any help! I thought it was just 10*time of the first one but that doesn't seem right, does it?",,"['probability', 'probability-distributions', 'poisson-distribution', 'poisson-process']"
99,Average Perimeter With n Points on the Unit Circle,Average Perimeter With n Points on the Unit Circle,,"A couple days ago, a friend challenged me to solve a problem: You have N vertices, each randomly placed on the edge of a unit circle. What is the formula (given N) that yields the average perimeter of these polygons. Note that the points are not connected by the order in which they were placed, but rather by which points are closest together. i.e. You sweep in a clockwise direction tracing the polygon by the order you come across the points after the points have been randomly placed. After some hard thought, I came up with what I think may be the solution: $$n\int_0^{2\pi} \frac{(n-1)(1-\frac{x}{2\pi})^{n-2}}{2\pi} \times \sqrt{2-2\cos {x}} \, dx$$ This formula finds the average secant length length for $n$ vertices and multiplies that length by the number of sides; however, I have a feeling this does not solve the problem because the lengths of the secants in the polygon depend on each other. I would like someone to confirm my suspicions, tell me that my formula works, or give me a different reason why the formula doesn't work. Please Do Not Solve This Problem For Me I still want to solve it on my own if this is not the solution.","A couple days ago, a friend challenged me to solve a problem: You have N vertices, each randomly placed on the edge of a unit circle. What is the formula (given N) that yields the average perimeter of these polygons. Note that the points are not connected by the order in which they were placed, but rather by which points are closest together. i.e. You sweep in a clockwise direction tracing the polygon by the order you come across the points after the points have been randomly placed. After some hard thought, I came up with what I think may be the solution: $$n\int_0^{2\pi} \frac{(n-1)(1-\frac{x}{2\pi})^{n-2}}{2\pi} \times \sqrt{2-2\cos {x}} \, dx$$ This formula finds the average secant length length for $n$ vertices and multiplies that length by the number of sides; however, I have a feeling this does not solve the problem because the lengths of the secants in the polygon depend on each other. I would like someone to confirm my suspicions, tell me that my formula works, or give me a different reason why the formula doesn't work. Please Do Not Solve This Problem For Me I still want to solve it on my own if this is not the solution.",,"['calculus', 'probability', 'geometry', 'polygons', 'geometric-probability']"
