,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Extreme points of Hilbert cube,Extreme points of Hilbert cube,,"Define the set $$Q:=\prod \limits _{n=1}^\infty \left [0,\frac{1}{n}\right ]$$ as a subspace of $X:=\mathbb{R}^{\mathbb{Z}_{>0}}$ with the product topology. Clearly $Q$ is a convex compact subset of $X$ , hence by the Krein-Milman Theorem we have that $Q$ is the closed convex hull of the set of its extreme points $\mathcal{E}(Q)$ . In the book of Bühler and Salamon it is stated that $$\mathcal{E}(Q)=\prod \limits _{n=1}^\infty \left \{0,\frac{1}{n}\right \},$$ that the convex hull of any finite subset of $\mathcal{E}(Q)$ is nowhere dense in $Q$ and that therefore the convex hull of $\mathcal{E}(Q)$ is not equal to $Q$ . It also says that the last fact follows from Baire Category Theorem. I proved that $\displaystyle \mathcal{E}(Q)=\prod \limits _{n=1}^\infty \left \{0,\frac{1}{n}\right \}$ and that $Q$ is a complete metric space, hence if I could express the convex hull of $\mathcal{E}(Q)$ as a countable union of convex hulls of finite subsets of $\mathcal{E}(Q)$ and prove that each of said convex hulls is nowhere dense in $Q$ , then all the assertions would have been proved. However, I couldn't prove that the convex hull of a finite subset is nowhere dense and I couldn't find a way of expressing the convex hull of $\mathcal{E}(Q)$ as a countable union (it is clearly equal to the union of the convex hulls of all of its subsets, but I don't know which subsets I should discard in order to obtain a countable union). How can I prove these two facts?","Define the set as a subspace of with the product topology. Clearly is a convex compact subset of , hence by the Krein-Milman Theorem we have that is the closed convex hull of the set of its extreme points . In the book of Bühler and Salamon it is stated that that the convex hull of any finite subset of is nowhere dense in and that therefore the convex hull of is not equal to . It also says that the last fact follows from Baire Category Theorem. I proved that and that is a complete metric space, hence if I could express the convex hull of as a countable union of convex hulls of finite subsets of and prove that each of said convex hulls is nowhere dense in , then all the assertions would have been proved. However, I couldn't prove that the convex hull of a finite subset is nowhere dense and I couldn't find a way of expressing the convex hull of as a countable union (it is clearly equal to the union of the convex hulls of all of its subsets, but I don't know which subsets I should discard in order to obtain a countable union). How can I prove these two facts?","Q:=\prod \limits _{n=1}^\infty \left [0,\frac{1}{n}\right ] X:=\mathbb{R}^{\mathbb{Z}_{>0}} Q X Q \mathcal{E}(Q) \mathcal{E}(Q)=\prod \limits _{n=1}^\infty \left \{0,\frac{1}{n}\right \}, \mathcal{E}(Q) Q \mathcal{E}(Q) Q \displaystyle \mathcal{E}(Q)=\prod \limits _{n=1}^\infty \left \{0,\frac{1}{n}\right \} Q \mathcal{E}(Q) \mathcal{E}(Q) Q \mathcal{E}(Q)","['functional-analysis', 'convex-hulls']"
1,Compact integral operator on $H^1(\mathbb{R})$,Compact integral operator on,H^1(\mathbb{R}),"Consider the operator $$ {\mathcal{L}}v=e^{-x}\int_{0}^x v(y)\, dy. $$ Is the operator ${\mathcal{L}}$ compact as an operator from $H^1({\mathbb{R}^+})$ to itself? To give some context to the problem above, let me explain why I am interested in it. I have an operator of the form $$ L\equiv{\mathcal{L}}_0+Q, $$ where ${\mathcal{L}}_0$ is a differential operator I can deal with, i.e. I can compute the spectrum of it, while $Q$ is an integral operator. I would like to prove $Q$ is compact (or not). I was able to prove most of it is compact. The part above given by the integral operator $\mathcal{L}$ is the only term I could not deal with in $Q$ . The difficulty seems to be that it is on $H^1(\mathbb{R^+})$ .","Consider the operator Is the operator compact as an operator from to itself? To give some context to the problem above, let me explain why I am interested in it. I have an operator of the form where is a differential operator I can deal with, i.e. I can compute the spectrum of it, while is an integral operator. I would like to prove is compact (or not). I was able to prove most of it is compact. The part above given by the integral operator is the only term I could not deal with in . The difficulty seems to be that it is on .","
{\mathcal{L}}v=e^{-x}\int_{0}^x v(y)\, dy.
 {\mathcal{L}} H^1({\mathbb{R}^+}) 
L\equiv{\mathcal{L}}_0+Q,
 {\mathcal{L}}_0 Q Q \mathcal{L} Q H^1(\mathbb{R^+})","['functional-analysis', 'operator-theory', 'spectral-theory', 'compact-operators', 'integral-operators']"
2,Spectral radius of the restriction to invariant subspace,Spectral radius of the restriction to invariant subspace,,"Let $(X,\|\cdot\|_{X})$ and $(Y,\|\cdot\|_{Y})$ be two complex Banach spaces such that $X\hookrightarrow Y$ and $X$ is dense in $Y$ . Let $T:Y\to Y$ be a bounded linear operator that leaves $X$ invariant, i.e. $T(X)\subset X$ . Furthermore, suppose that the restriction $T|_X$ is a bounded operator on $X$ . Is it possible to say something about the relation of the spectral radii $r_Y(T)$ and $r_X(T|_X)$ ? In particular, is it possible that $r_X(T|_X)>r_Y(T)$ ? Remark: If one restricts the operator to a subspace the point spectrum can only decrease but it's not clear whether this holds for the whole spectrum.","Let and be two complex Banach spaces such that and is dense in . Let be a bounded linear operator that leaves invariant, i.e. . Furthermore, suppose that the restriction is a bounded operator on . Is it possible to say something about the relation of the spectral radii and ? In particular, is it possible that ? Remark: If one restricts the operator to a subspace the point spectrum can only decrease but it's not clear whether this holds for the whole spectrum.","(X,\|\cdot\|_{X}) (Y,\|\cdot\|_{Y}) X\hookrightarrow Y X Y T:Y\to Y X T(X)\subset X T|_X X r_Y(T) r_X(T|_X) r_X(T|_X)>r_Y(T)","['functional-analysis', 'spectral-theory', 'spectral-radius']"
3,Application of Hahn–Banach theorem to approximation problem.,Application of Hahn–Banach theorem to approximation problem.,,"Theorem 3.5. of Rudin's functional analysis states Suppose $M$ is a subspace of a locally convex space $X$ , and $x_0 \in X$ . If $x_0$ is not in the closure of $M$ , then there exists $\Lambda \in  X^*$ such that $\Lambda x_0 = 1$ but $\Lambda x = 0$ . And a remark below This theorem is the basis of a standard method of treating certain approximation problems: In order to prove that an $x_0 \in X$ lies in the closure of some subspace $M$ of $X$ it is suffices (if $X$ is locally convex) to show that $\Lambda x_0 = 0$ for every continuous linear functional $\Lambda$ on $X$ that vanishes on $M$ . I'd like to see a couple of applications of this in infinite dimension vector space, but I struggle to find any. Can anyone suggest a reference maybe? Or just show a couple of examples?","Theorem 3.5. of Rudin's functional analysis states Suppose is a subspace of a locally convex space , and . If is not in the closure of , then there exists such that but . And a remark below This theorem is the basis of a standard method of treating certain approximation problems: In order to prove that an lies in the closure of some subspace of it is suffices (if is locally convex) to show that for every continuous linear functional on that vanishes on . I'd like to see a couple of applications of this in infinite dimension vector space, but I struggle to find any. Can anyone suggest a reference maybe? Or just show a couple of examples?",M X x_0 \in X x_0 M \Lambda \in  X^* \Lambda x_0 = 1 \Lambda x = 0 x_0 \in X M X X \Lambda x_0 = 0 \Lambda X M,"['functional-analysis', 'hahn-banach-theorem']"
4,Do the canonical commutation relations determine the position and momentum operator?,Do the canonical commutation relations determine the position and momentum operator?,,"Consider the position and momentum operator on $L^2(\mathbb{R})$ defined on a dense domain, say $D(X) = D(P)=\mathscr{S}(\mathbb{R})$ with the position operator being defined as $$ X\phi=x\phi(x) \qquad \forall \phi \in \mathscr{S}(\mathbb{R}) $$ and the momentum operator is defined by $$ P\phi=-i \frac{d}{dx}\phi(x) \qquad \forall \phi \in \mathscr{S}(\mathbb{R}) $$ Then we have the canonical commutation relations $$ [X,P]\phi=i\phi \qquad \forall \phi \in \mathscr{S}(\mathbb{R}) \tag{1}$$ For any unitary operator $U$ (for example the Fourier transform), it is easy to see that $U^{\dagger}PU$ and $U^{\dagger}XU$ satisfy the same commutation relations. Question: If $2$ self-adjoint, densely defined linear operators satisfy (1), are they unitarily equivalent to the position and momentum operator? In other words: Do the canonical commutation relations already determine position and momentum operator up to unitary equvialence? I am asking this question out of curiousity, since it stuck in my head for quite some time. I have thought about (formally) taking operator exponentials, since $\exp(-iX)\phi=e^{ix}\phi(x)$ and $\exp(iaP)\phi=\phi(x+a)$ and then use the Stone-von Neumann theorem for the Heisenberg group, however, the issue with the domain remains and also taking operators exponential is non-trivial for this reason. Feel free to modify my domain to e.g. $D(\cdot)=W^{1,2}(\mathbb{R}),C_c^{\infty}(\mathbb{R}),..$ or whatever you see fit. I am somewhat familiar with the basic spectral theory for unbounded operators and I have already encountered the concept of a rigged Hilbert space, so feel free to use them without elaborating every detail.","Consider the position and momentum operator on defined on a dense domain, say with the position operator being defined as and the momentum operator is defined by Then we have the canonical commutation relations For any unitary operator (for example the Fourier transform), it is easy to see that and satisfy the same commutation relations. Question: If self-adjoint, densely defined linear operators satisfy (1), are they unitarily equivalent to the position and momentum operator? In other words: Do the canonical commutation relations already determine position and momentum operator up to unitary equvialence? I am asking this question out of curiousity, since it stuck in my head for quite some time. I have thought about (formally) taking operator exponentials, since and and then use the Stone-von Neumann theorem for the Heisenberg group, however, the issue with the domain remains and also taking operators exponential is non-trivial for this reason. Feel free to modify my domain to e.g. or whatever you see fit. I am somewhat familiar with the basic spectral theory for unbounded operators and I have already encountered the concept of a rigged Hilbert space, so feel free to use them without elaborating every detail.","L^2(\mathbb{R}) D(X) = D(P)=\mathscr{S}(\mathbb{R}) 
X\phi=x\phi(x) \qquad \forall \phi \in \mathscr{S}(\mathbb{R})
 
P\phi=-i \frac{d}{dx}\phi(x) \qquad \forall \phi \in \mathscr{S}(\mathbb{R})
 
[X,P]\phi=i\phi \qquad \forall \phi \in \mathscr{S}(\mathbb{R})
\tag{1} U U^{\dagger}PU U^{\dagger}XU 2 \exp(-iX)\phi=e^{ix}\phi(x) \exp(iaP)\phi=\phi(x+a) D(\cdot)=W^{1,2}(\mathbb{R}),C_c^{\infty}(\mathbb{R}),..","['functional-analysis', 'hilbert-spaces', 'mathematical-physics']"
5,Find a sequence of measures and a measurable function,Find a sequence of measures and a measurable function,,I am new to measure theory and I'm have a problem finding an example for the problem below: If $C$ is a middle-thirds Cantor set; find a sequence $\{ \mu_{n}\}_{n \geq 1 }$ of measures on Borel $\sigma -$ algebra $C$ and a measurable function $f:C \to R$ such that $\lim_{n \to +\infty} \mu_n(x) = 0$ and $\int f d\mu_{m} = +\infty$ for every $m \geq 1$ . I think that this is the Cantor measure problem but I'm not sure.,I am new to measure theory and I'm have a problem finding an example for the problem below: If is a middle-thirds Cantor set; find a sequence of measures on Borel algebra and a measurable function such that and for every . I think that this is the Cantor measure problem but I'm not sure.,C \{ \mu_{n}\}_{n \geq 1 } \sigma - C f:C \to R \lim_{n \to +\infty} \mu_n(x) = 0 \int f d\mu_{m} = +\infty m \geq 1,"['functional-analysis', 'analysis', 'measure-theory', 'measurable-functions', 'borel-measures']"
6,A step in the proof of the Hille-Yosida theorem from Rudin,A step in the proof of the Hille-Yosida theorem from Rudin,,"I'm getting stuck on perhaps a simple step in the Hille-Yosida theorem from 13.37 in Rudin's functional analysis. I wonder if someone has had this same difficulty before or knows how to get around it - Setup: $A$ is a densely defined operator with domain $\mathcal{D}(A)$ in a Banach space $X$ and there are constants $C, \gamma >0$ such that for every $\lambda > \gamma$ and $m\in \mathbb{N}$ , $$ \| (\lambda I - A)^{-m}\| \leq C(\lambda - \gamma)^{-m}. $$ The claim is then that $A$ is the infinitesimal generator of a semi-group of operators. For small $\varepsilon$ , the bounded operator $S(\varepsilon)$ is defined to be $(I-\varepsilon A)^{-1}:X \to \mathcal{D}(A)$ . It follows from the definitions that $AS(\varepsilon) = \varepsilon^{-1}(S(\varepsilon)-I)$ from which one can show that $e^{tAS(\varepsilon)}$ converges weakly to a bounded $Q(t)$ . Moreover, $\{Q(t) \}$ gives a semi-group. Thus it has an infinitesimal generator $\tilde{A}$ . Using the resolvent formulas for $AS(\varepsilon)$ and $\tilde{A}$ , we have for all $x$ and $\lambda$ sufficiently large, $$ (\lambda I - \tilde{A})^{-1}x = \int_0^\infty e^{-\lambda t} Q(t)x dt $$ and $$ (\lambda I - AS(\varepsilon))^{-1}x = \int_0^\infty e^{-\lambda t} e^{tAS(\varepsilon)}x dt. $$ One can easily justify the limit $$ \lim_{\varepsilon \to 0} \int_0^\infty e^{-\lambda t} e^{tAS(\varepsilon)}x dt = \int_0^\infty e^{-\lambda t} Q(t)x dt. $$ Question: In order to compare $\tilde{A}$ and $A$ , how does one see that $$ \lim_{\varepsilon \to 0} (\lambda I - AS(\varepsilon))^{-1}x = (\lambda I - A)^{-1}x? $$ THANK YOU!","I'm getting stuck on perhaps a simple step in the Hille-Yosida theorem from 13.37 in Rudin's functional analysis. I wonder if someone has had this same difficulty before or knows how to get around it - Setup: is a densely defined operator with domain in a Banach space and there are constants such that for every and , The claim is then that is the infinitesimal generator of a semi-group of operators. For small , the bounded operator is defined to be . It follows from the definitions that from which one can show that converges weakly to a bounded . Moreover, gives a semi-group. Thus it has an infinitesimal generator . Using the resolvent formulas for and , we have for all and sufficiently large, and One can easily justify the limit Question: In order to compare and , how does one see that THANK YOU!","A \mathcal{D}(A) X C, \gamma >0 \lambda > \gamma m\in \mathbb{N} 
\| (\lambda I - A)^{-m}\| \leq C(\lambda - \gamma)^{-m}.
 A \varepsilon S(\varepsilon) (I-\varepsilon A)^{-1}:X \to \mathcal{D}(A) AS(\varepsilon) = \varepsilon^{-1}(S(\varepsilon)-I) e^{tAS(\varepsilon)} Q(t) \{Q(t) \} \tilde{A} AS(\varepsilon) \tilde{A} x \lambda 
(\lambda I - \tilde{A})^{-1}x = \int_0^\infty e^{-\lambda t} Q(t)x dt
 
(\lambda I - AS(\varepsilon))^{-1}x = \int_0^\infty e^{-\lambda t} e^{tAS(\varepsilon)}x dt.
 
\lim_{\varepsilon \to 0} \int_0^\infty e^{-\lambda t} e^{tAS(\varepsilon)}x dt = \int_0^\infty e^{-\lambda t} Q(t)x dt.
 \tilde{A} A 
\lim_{\varepsilon \to 0} (\lambda I - AS(\varepsilon))^{-1}x = (\lambda I - A)^{-1}x?
","['functional-analysis', 'operator-theory', 'semigroup-of-operators']"
7,"Prove that $C^1[0,1]$ is not Hilbert space",Prove that  is not Hilbert space,"C^1[0,1]","Problem: On $C^1[0,1]$ , we define an inner product by $$\langle x, y \rangle = x(0)y(0) + \int_0^1 x^\prime (t) y^\prime (t) dt.$$ Prove that $(C^1[0,1],\langle \cdot,\cdot \rangle)$ is not Hilbert space. My attempt: Suppose that $(C^1[0,1],\langle \cdot,\cdot \rangle)$ is Hilbert space. Next, we denote $\Vert \cdot \Vert$ be the norm induced by $\langle \cdot,\cdot \rangle$ . Thus, for all $x\in C^1[0,1]$ we have $$\Vert x \Vert= \sqrt{x^2(0)+\int_{0}^{1}[x'(t)]^2dt}.$$ Consider $(x_n)_n \subset C^1[0,1]$ defined by $x_n(t)=\dfrac{t^{n+1}}{n+1}$ . I will prove that $(x_n)_n$ is Cauchy sequence as following $$\lim_{n\to+\infty}\Vert x_{n+p}-x_n \Vert^2= \lim_{n\to+\infty}\int_{0}^{1}t^{2n}(t^p-1)^2dt=\int_{0}^{1}\lim_{n\to+\infty}t^{2n}(t^p-1)^2dt=0.$$ Since, $(C^1[0,1],\langle\cdot,\cdot\rangle)$ is Hilbert space, we have $(x_n)$ converges to $x_0 \in (C^1[0,1],\Vert\cdot\Vert)$ . Now, I just have to show that $x_0 \notin C^1[0,1]$ then the problem will be solved but I have stucked. Thanks for any help. P/S: In addition, I also try to solve this problem by choosing a sequence that is the Cauchy sequence but not convergent in $(C^1[0,1],\Vert \cdot \Vert)$ but it does not work.","Problem: On , we define an inner product by Prove that is not Hilbert space. My attempt: Suppose that is Hilbert space. Next, we denote be the norm induced by . Thus, for all we have Consider defined by . I will prove that is Cauchy sequence as following Since, is Hilbert space, we have converges to . Now, I just have to show that then the problem will be solved but I have stucked. Thanks for any help. P/S: In addition, I also try to solve this problem by choosing a sequence that is the Cauchy sequence but not convergent in but it does not work.","C^1[0,1] \langle x, y \rangle = x(0)y(0) + \int_0^1 x^\prime (t) y^\prime (t) dt. (C^1[0,1],\langle \cdot,\cdot \rangle) (C^1[0,1],\langle \cdot,\cdot \rangle) \Vert \cdot \Vert \langle \cdot,\cdot \rangle x\in C^1[0,1] \Vert x \Vert= \sqrt{x^2(0)+\int_{0}^{1}[x'(t)]^2dt}. (x_n)_n \subset C^1[0,1] x_n(t)=\dfrac{t^{n+1}}{n+1} (x_n)_n \lim_{n\to+\infty}\Vert x_{n+p}-x_n \Vert^2= \lim_{n\to+\infty}\int_{0}^{1}t^{2n}(t^p-1)^2dt=\int_{0}^{1}\lim_{n\to+\infty}t^{2n}(t^p-1)^2dt=0. (C^1[0,1],\langle\cdot,\cdot\rangle) (x_n) x_0 \in (C^1[0,1],\Vert\cdot\Vert) x_0 \notin C^1[0,1] (C^1[0,1],\Vert \cdot \Vert)","['functional-analysis', 'hilbert-spaces', 'banach-spaces']"
8,Equivalence of two harmonic problems on different domains,Equivalence of two harmonic problems on different domains,,"I want to solve \begin{cases} \Delta u = 0,&\text{ in }\mathbb{R}^3\setminus B_1(0) \\ u=0,&\text{ as }\Vert x\Vert\rightarrow +\infty \\ u=1,&\text{ on }\partial B_1(0). \end{cases} I know that the solution to this problem is $$ \bar{u}(x) = \Vert x\Vert^{-1}. $$ My question is if by solving the following BVP \begin{cases} \Delta v = 0,&\text{ in }B_R(0)\setminus B_1(0) \\ v=\bar{u}|_{\partial B_R},&\text{ on }\partial B_R(0)\\ v=1,&\text{ on } \partial B_1(0), \end{cases} $R>1$ , I get a solution $v$ which is the restriction of the solution $u$ of the original problem onto the new domain $\Omega = B_R(0)\setminus B_1(0)$ . Namely, if $v = u|_{\Omega}$ . I am claiming this because : If I set $D = \big(\mathbb{R}^3\setminus B_1(0)\big)\cap \big(B_R(0)\setminus B_1(0)\big)$ I can define a third problem over $D$ which is solved by $w=u-v$ on $D$ : \begin{cases} \Delta w = 0,&\text{in }D \\ w = 1-1=0,&\text{on }\partial B_1(0) \\ w = \bar{u}|_{\partial B_R(0)}-\bar{u}|_{\partial B_R(0)}=0,&\text{on }\partial B_R(0) \end{cases} so by maximum principle I can conclude that $$ 0=\min_{x\in \partial D} w \leq w(y) \leq \max_{x\in \partial D} w = 0 $$ for any $y\in D$ and hence that $w=u-v\equiv 0$ .","I want to solve I know that the solution to this problem is My question is if by solving the following BVP , I get a solution which is the restriction of the solution of the original problem onto the new domain . Namely, if . I am claiming this because : If I set I can define a third problem over which is solved by on : so by maximum principle I can conclude that for any and hence that .","\begin{cases}
\Delta u = 0,&\text{ in }\mathbb{R}^3\setminus B_1(0) \\
u=0,&\text{ as }\Vert x\Vert\rightarrow +\infty \\
u=1,&\text{ on }\partial B_1(0).
\end{cases} 
\bar{u}(x) = \Vert x\Vert^{-1}.
 \begin{cases}
\Delta v = 0,&\text{ in }B_R(0)\setminus B_1(0) \\
v=\bar{u}|_{\partial B_R},&\text{ on }\partial B_R(0)\\
v=1,&\text{ on } \partial B_1(0),
\end{cases} R>1 v u \Omega = B_R(0)\setminus B_1(0) v = u|_{\Omega} D = \big(\mathbb{R}^3\setminus B_1(0)\big)\cap \big(B_R(0)\setminus B_1(0)\big) D w=u-v D \begin{cases}
\Delta w = 0,&\text{in }D \\
w = 1-1=0,&\text{on }\partial B_1(0) \\
w = \bar{u}|_{\partial B_R(0)}-\bar{u}|_{\partial B_R(0)}=0,&\text{on }\partial B_R(0)
\end{cases} 
0=\min_{x\in \partial D} w \leq w(y) \leq \max_{x\in \partial D} w = 0
 y\in D w=u-v\equiv 0","['functional-analysis', 'partial-differential-equations', 'harmonic-functions', 'elliptic-equations', 'linear-pde']"
9,Boundedness of Riesz Transform on (subsets of) Hölder spaces?,Boundedness of Riesz Transform on (subsets of) Hölder spaces?,,"Definition and setup The Riesz transform for say $C^\infty_c(\mathbb R^d)$ functions $f$ is defined by a principal value integral, $$ Rf(x) := c_d \operatorname{pv}\!\!\!\int_{\mathbb R^d} \frac{y}{|y|^{d+1}}f(x-y) \, dy := c_d \lim_{\epsilon\downarrow 0} \int_{|y|>\epsilon} \frac{y}{|y|^{d+1}}f(x-y) \, dy,$$ The integral is interpreted componentwise, the constant $c_d$ is chosen so that the Fourier transform $\int_{\mathbb R^d} Rf(x)e^{-2\pi i x\xi} \, dx =  \frac{- i\xi}{|\xi|}. $ Wikipedia link . It is well-known that the Riesz transform is bounded on $L^p$ spaces, $p\in(1,\infty)$ , and commutes with derivatives. Its therefore bounded on Sobolev spaces $W^{s,p}$ , $p\in(1,\infty)$ . Question I think I've seen before that the Riesz transform is bounded as a map $C^\alpha \cap L^p \to C^\alpha \cap L^p$ ? Is this true? A paper I've read casually remarked that the Riesz transform is bounded on Hölder and Sobolev Spaces, and I presume this is the kind of result they mean. I gave it a few naive tries. I can show that under the assumption that $f\in L^p \cap C^\alpha, p\in[1,\infty)$ , the integral form is well-defined and $Rf\in L^\infty$ , with for any $\lambda>0$ $$ |R_jf(x)| \lesssim_d  [f]_\alpha \lambda^\alpha + \|f\|_{L^p} \lambda^{-d/p}$$ or if you try to minimise in $\lambda$ you get something like $\|Rf\|_{L^\infty} \lesssim_d [f]_\alpha^{\frac{d/p}{\alpha+d/p}}\|f\|_{L^p}^{{\frac{\alpha}{\alpha+d/p}}}$ . But I feel like I'm missing a ""standard trick"" to continue to estimate $[Rf]_\alpha$ (in particular I don't know how to use the cancellation), and revisiting some books like Stein's, I couldn't find the result or the trick I feel I need. Any pointers? Update A friend has pointed out that it is in Stein's book, in the form of a ""Further Result"" (i.e. exercise). It is 6.9 on pages 50-51. He gives the hint that if the Kernel $\frac{\Omega(y)}{|y|^d}$ (in our case $\Omega(y) = y/|y|$ ) is sufficiently smooth then the proof is ""elementary"" (NB the quotation marks are Stein's), and directs the reader to 3 references: J. Privalov ""Sur Les fonctions conjuguées,"" Mat. Zeit. 26 (1927), 218-244. A. P. Calderón and A. Zygmund, ""Singular Integrals and Periodic Functions,"" Studia Math. 14 (1954), 249-271. M. H. Taibleson, ""The preservation of Lipschitz spaces under singular integral operators,"" Studia Math. 24 (1963), 105-111. So it might be possible to distill an answer from one of these papers...","Definition and setup The Riesz transform for say functions is defined by a principal value integral, The integral is interpreted componentwise, the constant is chosen so that the Fourier transform Wikipedia link . It is well-known that the Riesz transform is bounded on spaces, , and commutes with derivatives. Its therefore bounded on Sobolev spaces , . Question I think I've seen before that the Riesz transform is bounded as a map ? Is this true? A paper I've read casually remarked that the Riesz transform is bounded on Hölder and Sobolev Spaces, and I presume this is the kind of result they mean. I gave it a few naive tries. I can show that under the assumption that , the integral form is well-defined and , with for any or if you try to minimise in you get something like . But I feel like I'm missing a ""standard trick"" to continue to estimate (in particular I don't know how to use the cancellation), and revisiting some books like Stein's, I couldn't find the result or the trick I feel I need. Any pointers? Update A friend has pointed out that it is in Stein's book, in the form of a ""Further Result"" (i.e. exercise). It is 6.9 on pages 50-51. He gives the hint that if the Kernel (in our case ) is sufficiently smooth then the proof is ""elementary"" (NB the quotation marks are Stein's), and directs the reader to 3 references: J. Privalov ""Sur Les fonctions conjuguées,"" Mat. Zeit. 26 (1927), 218-244. A. P. Calderón and A. Zygmund, ""Singular Integrals and Periodic Functions,"" Studia Math. 14 (1954), 249-271. M. H. Taibleson, ""The preservation of Lipschitz spaces under singular integral operators,"" Studia Math. 24 (1963), 105-111. So it might be possible to distill an answer from one of these papers...","C^\infty_c(\mathbb R^d) f  Rf(x) := c_d \operatorname{pv}\!\!\!\int_{\mathbb R^d} \frac{y}{|y|^{d+1}}f(x-y) \, dy := c_d \lim_{\epsilon\downarrow 0} \int_{|y|>\epsilon} \frac{y}{|y|^{d+1}}f(x-y) \, dy, c_d \int_{\mathbb R^d} Rf(x)e^{-2\pi i x\xi} \, dx =  \frac{- i\xi}{|\xi|}.  L^p p\in(1,\infty) W^{s,p} p\in(1,\infty) C^\alpha \cap L^p \to C^\alpha \cap L^p f\in L^p \cap C^\alpha, p\in[1,\infty) Rf\in L^\infty \lambda>0  |R_jf(x)| \lesssim_d  [f]_\alpha \lambda^\alpha + \|f\|_{L^p} \lambda^{-d/p} \lambda \|Rf\|_{L^\infty} \lesssim_d [f]_\alpha^{\frac{d/p}{\alpha+d/p}}\|f\|_{L^p}^{{\frac{\alpha}{\alpha+d/p}}} [Rf]_\alpha \frac{\Omega(y)}{|y|^d} \Omega(y) = y/|y|","['functional-analysis', 'harmonic-analysis', 'holder-spaces']"
10,"If $T$ is a bounded linear operator from $L^p(\mathbb{R})$ to $L^q(\mathbb{R})$ and $T$ is non-zero, then $p \leq q$","If  is a bounded linear operator from  to  and  is non-zero, then",T L^p(\mathbb{R}) L^q(\mathbb{R}) T p \leq q,"I'm a student in a Fourier Analysis class with a broad background in Functional Analysis. When this question was posed to me, I wasn't sure how to begin. Poking around, I looked at $L^p$ embeddings but $T$ may not be injective into $L^q$ . Trying to solve this problem naively, I considered $f$ to have $L^p$ norm 1 (the sphere) and considered $$(\int_{\mathbb{R}} |Tf(x)|^q)^{\frac{1}{q}} \leq C  $$ where $C$ is the norm of $T$ . Can I ""normalize"" T and assume $C=1$ to get rid of that $\frac{1}{q}$ exponent. How would $f$ having norm 1 help me here? Edit: Would it be possible to ""mod out"" by the kernel of $T$ and consider that as an injective linear operator from $\frac{L^p(\mathbb{R}) }{kerT}$ to $L^q(\mathbb{R})$ ? I don't think I'd be able to use any embedding results here though.","I'm a student in a Fourier Analysis class with a broad background in Functional Analysis. When this question was posed to me, I wasn't sure how to begin. Poking around, I looked at embeddings but may not be injective into . Trying to solve this problem naively, I considered to have norm 1 (the sphere) and considered where is the norm of . Can I ""normalize"" T and assume to get rid of that exponent. How would having norm 1 help me here? Edit: Would it be possible to ""mod out"" by the kernel of and consider that as an injective linear operator from to ? I don't think I'd be able to use any embedding results here though.",L^p T L^q f L^p (\int_{\mathbb{R}} |Tf(x)|^q)^{\frac{1}{q}} \leq C   C T C=1 \frac{1}{q} f T \frac{L^p(\mathbb{R}) }{kerT} L^q(\mathbb{R}),"['functional-analysis', 'lp-spaces', 'harmonic-analysis']"
11,Operator norm of semigroup operator,Operator norm of semigroup operator,,"Let $P_{t}$ be a self-adjoint operator such that $P_{t+s}=P_{t}P_{s}$ . I want to show that $$\|P_{t}\|_{1\to \infty}\leq \|P_{t/2}\|_{1\to 2}\|P_{t/2}\|_{2\to \infty}.$$ For that, I am trying to prove that $$\|P_{t}f\|_{\infty}\leq \|P_{t/2}\|_{1\to 2}\|P_{t/2}\|_{2\to \infty}\|f\|_{1}$$ using that $$\|P_{t}f\|_{\infty}=\sup_{g}\frac{(P_{t}f, g)}{\|g\|_{1}}=\sup_{g}\frac{(P_{t/2}f, P_{t/2}g)}{\|g\|_{1}},$$ but then I am stuck. Can someone help?","Let be a self-adjoint operator such that . I want to show that For that, I am trying to prove that using that but then I am stuck. Can someone help?","P_{t} P_{t+s}=P_{t}P_{s} \|P_{t}\|_{1\to \infty}\leq \|P_{t/2}\|_{1\to 2}\|P_{t/2}\|_{2\to \infty}. \|P_{t}f\|_{\infty}\leq \|P_{t/2}\|_{1\to 2}\|P_{t/2}\|_{2\to \infty}\|f\|_{1} \|P_{t}f\|_{\infty}=\sup_{g}\frac{(P_{t}f, g)}{\|g\|_{1}}=\sup_{g}\frac{(P_{t/2}f, P_{t/2}g)}{\|g\|_{1}},",['functional-analysis']
12,The Newton-Raphson method in Banach spaces,The Newton-Raphson method in Banach spaces,,"Note: the screenshot at the bottom is where my question comes from. This question is quite different from other versions of conditions of convergence of Newton iteration. For example, Kantorovich theorem. I am now analysing the Newton-Raphson iteration in general Banach spaces $E,F$ . Let $x_0\in E$ , and let $f:B_t(x_0)\to F$ be a differentiable function. ( $B$ denotes an open ball with radius $t$ .) $L(E,F)$ is the set of linear mapping from $E$ to $F$ . By definition, $f$ is differentiable at $x$ with derivative $Df_x\in L(E,F)$ (which is a linear functional from $E$ to $F$ ) if $\exists r(h),f(x+h)=f(x)+Df_x(h)+r(h)$ , where $r(h)/\|h\|\to 0$ as $h\to 0$ . To make it simple, I assume that there exist $s>0$ such that $\|f(x_0)\|\leq t/(2s)$ If $x,y\in B_t(x_0)$ then $\|Df_x-Df_y\|\leq 1/(2s)$ $\forall x\in B_t(x_0),\exists J_x\in L(F,E)$ such that $J_xDf_x=Df_xJ_x=I_E$ and $\|J_x\|\leq s$ . Now let's work on the iteration. Let's fix $x\in B_t(x_0)$ . Set $x_n=x_{n-1}-J_x(f(x_{n-1}))$ . In real analysis course, we often take $x=x_{n-1}$ , but here I have to fix $x$ to be anything in $B_t(x_0)$ . Just assume for a moment that $\forall x\in B_t(x_0)$ . I will explain why later. Firstly I have to show that $x_n$ converges. Now I can use the inequality $$ \|f(a)-f(b)-T(a-b)\|\leq \|a-b\|\sup_{c\in [a,b]} \|Df_c-T\|, $$ where $[a,b]$ is the line segment joining $a,b$ , and $T\in L(E,F)$ . To use this inequality, we define $g(y)=J_x(f(y))$ , so $x_n=x_{n-1}-g(x_{n-1})$ , and $Dg_y=J_xDf_y$ .( The reason why I cannnot set $x=x_{n-1}$ is that if I do it that way, then $g(y)=J_y(f(y))$ , and I cannot find the derivative of $g$ in this case.) Since $x$ is fixed, we can assume there is NO $x$ dependence in $g$ . Therefore, $$ \|x_{n+1}-x_{n}\|=\|f(x_{n})-f(x_{n-1})-(x_{n}-x_{n-1})\|\\ \leq \|x_{n}-x_{n-1}\|\sup_{c\in [x_n,x_{n-1}]} \|Dg_c-I\|\\=\|x_{n}-x_{n-1}\|\sup_{c\in [x_n,x_{n-1}]} \|J_xDf_c-J_xDf_x\|\\ \leq \|x_{n}-x_{n-1}\|\|J_x\|\|Df_c-Df_x\|\\ \leq \frac{1}{2} \|x_{n}-x_{n-1}\|. $$ Also, $$ \|x_1-x_0\|=\|J_x(f(x_0))\|\leq t/2 $$ The conclusion is $\|x_n-x_{n-1}\|\leq t/2^n$ . My question: is it really OK to let $x$ be anything fixed in $B_t(x_0)$ ? Does that really work? If it is wrong, how can I fix it? To prove that $f(x_n)$ converges to zero, I feel that I should prove something like $\|f(x_n)\|\leq t/(2^{n+1}s)$ (Suggested in a book of real analysis). I try to start by considering this: $$ \|f(x_n)\|\leq \|Df_x\|\|x_{n+1}-x_n\| $$ but it goes nowhere. From $\|J_x\|\leq s$ we cannot obtain an upper bound on $Df_x$ . So how can I prove $\|f(x_n)\|\leq t/(2^{n+1}s)$ ? It should be clear that $x_n$ is a Cauchy sequence - but it might not converge into $B_t(x_0)$ - is that a problem? It is a long question, so if I have made mistakes please point it out. Please look at the following screenshot if the above is not clear. Source of my problem: A course in mathematical analysis (screenshot) Here is a theorem of Kantorovich which is related but not the same.","Note: the screenshot at the bottom is where my question comes from. This question is quite different from other versions of conditions of convergence of Newton iteration. For example, Kantorovich theorem. I am now analysing the Newton-Raphson iteration in general Banach spaces . Let , and let be a differentiable function. ( denotes an open ball with radius .) is the set of linear mapping from to . By definition, is differentiable at with derivative (which is a linear functional from to ) if , where as . To make it simple, I assume that there exist such that If then such that and . Now let's work on the iteration. Let's fix . Set . In real analysis course, we often take , but here I have to fix to be anything in . Just assume for a moment that . I will explain why later. Firstly I have to show that converges. Now I can use the inequality where is the line segment joining , and . To use this inequality, we define , so , and .( The reason why I cannnot set is that if I do it that way, then , and I cannot find the derivative of in this case.) Since is fixed, we can assume there is NO dependence in . Therefore, Also, The conclusion is . My question: is it really OK to let be anything fixed in ? Does that really work? If it is wrong, how can I fix it? To prove that converges to zero, I feel that I should prove something like (Suggested in a book of real analysis). I try to start by considering this: but it goes nowhere. From we cannot obtain an upper bound on . So how can I prove ? It should be clear that is a Cauchy sequence - but it might not converge into - is that a problem? It is a long question, so if I have made mistakes please point it out. Please look at the following screenshot if the above is not clear. Source of my problem: A course in mathematical analysis (screenshot) Here is a theorem of Kantorovich which is related but not the same.","E,F x_0\in E f:B_t(x_0)\to F B t L(E,F) E F f x Df_x\in L(E,F) E F \exists r(h),f(x+h)=f(x)+Df_x(h)+r(h) r(h)/\|h\|\to 0 h\to 0 s>0 \|f(x_0)\|\leq t/(2s) x,y\in B_t(x_0) \|Df_x-Df_y\|\leq 1/(2s) \forall x\in B_t(x_0),\exists J_x\in L(F,E) J_xDf_x=Df_xJ_x=I_E \|J_x\|\leq s x\in B_t(x_0) x_n=x_{n-1}-J_x(f(x_{n-1})) x=x_{n-1} x B_t(x_0) \forall x\in B_t(x_0) x_n 
\|f(a)-f(b)-T(a-b)\|\leq \|a-b\|\sup_{c\in [a,b]} \|Df_c-T\|,
 [a,b] a,b T\in L(E,F) g(y)=J_x(f(y)) x_n=x_{n-1}-g(x_{n-1}) Dg_y=J_xDf_y x=x_{n-1} g(y)=J_y(f(y)) g x x g 
\|x_{n+1}-x_{n}\|=\|f(x_{n})-f(x_{n-1})-(x_{n}-x_{n-1})\|\\ \leq \|x_{n}-x_{n-1}\|\sup_{c\in [x_n,x_{n-1}]} \|Dg_c-I\|\\=\|x_{n}-x_{n-1}\|\sup_{c\in [x_n,x_{n-1}]} \|J_xDf_c-J_xDf_x\|\\ \leq \|x_{n}-x_{n-1}\|\|J_x\|\|Df_c-Df_x\|\\ \leq \frac{1}{2} \|x_{n}-x_{n-1}\|.
 
\|x_1-x_0\|=\|J_x(f(x_0))\|\leq t/2
 \|x_n-x_{n-1}\|\leq t/2^n x B_t(x_0) f(x_n) \|f(x_n)\|\leq t/(2^{n+1}s) 
\|f(x_n)\|\leq \|Df_x\|\|x_{n+1}-x_n\|
 \|J_x\|\leq s Df_x \|f(x_n)\|\leq t/(2^{n+1}s) x_n B_t(x_0)","['functional-analysis', 'derivatives', 'banach-spaces', 'topological-vector-spaces']"
13,Norm of sum of self-adjoint operators,Norm of sum of self-adjoint operators,,"Let $L$ and $K$ be such self-adjoint operators on a Hilbert space, such that we have $LK=0$ . Show that for the operator norm, we have the equality $$\left\|L+K\right\|=\max\left\{\left\|L\right\|, \left\|K\right\|\right\}.$$ I was able to prove that $\left\|L\right\|\leq \left\|L+K\right\|$ and $\left\|K\right\| \leq \left\|L+K\right\|,$ but I cannot prove the other inequality.","Let and be such self-adjoint operators on a Hilbert space, such that we have . Show that for the operator norm, we have the equality I was able to prove that and but I cannot prove the other inequality.","L K LK=0 \left\|L+K\right\|=\max\left\{\left\|L\right\|, \left\|K\right\|\right\}. \left\|L\right\|\leq \left\|L+K\right\| \left\|K\right\| \leq \left\|L+K\right\|,","['functional-analysis', 'hilbert-spaces']"
14,Hyponormal operator and approximate spectrum,Hyponormal operator and approximate spectrum,,"Let $H$ be a complex Hilbert space. It is well known that if $T:H \to H$ is a normal operator, then $$\sigma(T)=\sigma_{ap}(T),$$ where $\sigma_{ap}(T)$ is defined as: $\lambda \in\sigma_{ap}(T)$ iff there exists a sequence $(x_n)_{n \in \mathbb N}$ with $\Vert x_n \Vert = 1$ for all $n \in \mathbb N$ such that $$\lim_{n \to \infty} \Vert Tx_n - \lambda x_n \Vert = 0,$$ If $T$ is hyponormal i.e. $T^*T\geq TT^*$ , is $$\sigma(T)=\sigma_{ap}(T)?$$ Thanks for your help.","Let be a complex Hilbert space. It is well known that if is a normal operator, then where is defined as: iff there exists a sequence with for all such that If is hyponormal i.e. , is Thanks for your help.","H T:H \to H \sigma(T)=\sigma_{ap}(T), \sigma_{ap}(T) \lambda \in\sigma_{ap}(T) (x_n)_{n \in \mathbb N} \Vert x_n \Vert = 1 n \in \mathbb N \lim_{n \to \infty} \Vert Tx_n - \lambda x_n \Vert = 0, T T^*T\geq TT^* \sigma(T)=\sigma_{ap}(T)?","['functional-analysis', 'operator-theory', 'spectral-theory']"
15,Problem in Ergodic theory,Problem in Ergodic theory,,"Let $(X,T,\mu)$ be a classical dynamical system, where $(X,\mu)$ is a probability measure space and $T$ is a measure preserving invertible transformation. Let $U$ be the unitary on $L^{2}(X,\mu)$ defined by $U(f)(s)=f(T^{-1}s)$ . If $T$ is ergodic and not weak mixing then why is it true that $U$ has at least an eigenvalue other than $1$ ? P.S. Somewhere I found that the underlying Hilbert space can be decomposed into the space generated by eigen vectors and the weak mixing part. I would be delighted someone can give me some suggestions on that.","Let be a classical dynamical system, where is a probability measure space and is a measure preserving invertible transformation. Let be the unitary on defined by . If is ergodic and not weak mixing then why is it true that has at least an eigenvalue other than ? P.S. Somewhere I found that the underlying Hilbert space can be decomposed into the space generated by eigen vectors and the weak mixing part. I would be delighted someone can give me some suggestions on that.","(X,T,\mu) (X,\mu) T U L^{2}(X,\mu) U(f)(s)=f(T^{-1}s) T U 1","['functional-analysis', 'eigenvalues-eigenvectors']"
16,Necessity of the Hahn Banach Theorem for the Gateaux Mean Value Theorem,Necessity of the Hahn Banach Theorem for the Gateaux Mean Value Theorem,,"The following theorem is in Drabek, Milota's Nonlinear Analysis. Like Drabek and Milota, I won't assume a priori Gateaux differentials are continuous nor linear. Theorem . Let $X,Y$ be normed spaces, and $f: X \rightarrow Y$ a map (perhaps not continuous). Fix $a,b \in X$ . Suppose that the Gateaux differential $df(a+t(b-a); b-a)$ exists for all $t \in [0,1]$ . Then, we have the estimate $$ ||f(b)-f(a)||_Y \leq \sup_{t \in [0,1]} ||df(a+t(b-a) ; b-a) ||_Y.$$ The proof uses the Hahn-Banach Theorem (or a corollary thereof) by taking a linear functional $\varphi \in X^*$ such that $||\varphi||_{X^*}=1$ and $\varphi(f(b)-f(a)) = ||f(b)-f(a)||$ . I would like to know if the use of the Hahn-Banach Theorem - or more generally, the Axiom of Choice - is needed to prove the theorem (that is, does there exist a proof that does not make use of choice principles)? I would also be interested in weaker choice principles, such as dependent or countable choice. I have also tried to modify the argument I saw in Cartan's Differential Calculus in the proof of the Mean Value Theorem for differentiable maps $[a,b] \rightarrow Y$ , $Y$ a normed space (the argument requires no choice principles); see Theorem 3.1.1, page 37-39 in Cartan. Somewhat in analogy to Cartan's argument, I have tried to define $$E= \{t \in [0,1] | \text{ for every neighbourhood } U \text{ of } 0, \text{ there is } p \in U \text{ such that } |p| ||f(b)-f(a)||_Y > ||f(a+t(b-a) + p(b-a)) - f(a+t(b-a)) ||_Y \}.$$ Then perhaps one could show $E$ is open in $\mathbb R$ and one notes that $\inf E \notin E$ . I am not sure exactly how to proceed to obtain a contradiction (as in Cartan's proof), however. My ideas for this attempt aren't well-formed, but I thought it would be useful to mention Cartan's proof. Perhaps this stackexchange question is also useful: Does one need the Hahn-Banach theorem to prove the mean value inequality for maps into a normed space? , though I'm interested in the version of the Mean Value theorem involving Gateaux derivatives as stated above. Thanks in advance. Edit: for reference, I'll include Cartan's Theorem here and a sketch of the proof. (The theorem is stated for Banach $Y$ , but completeness is in fact unnecessary). It is the proof of Theorem 3.1.1 I have tried to modify to my particular case, but it seems that I am unsure how to proceed. Theorem (Cartan, 3.1.1) . Let $Y$ be normed, let $f:[c,d] \rightarrow Y, g:[c,d] \rightarrow \mathbb R$ be maps. Suppose that the right derivatives $f'_{+}, g'_{+}$ exists at all points in $(c,d)$ , and assume that $||f'_{+}(x)|| \leq g'_{+}(x)$ for all $x \in (c,d)$ . Then, $$||f(d)-f(c)|| \leq g(d)-g(c).$$ Sketch : Following Cartan, one fixes $\varepsilon>0$ and puts $$U = \{x \in [c,d] | ||f(x)-f(c)|| > g(x)-g(c)+ \varepsilon(x-c) \}.$$ Aiming for a contradiction, suppose $U$ is not empty. Then, $U$ is open and let us define $\alpha= \inf U$ ; then, $\alpha \notin U$ , and in fact, $\alpha>c$ . By the existence of the right derivatives, there is a $\delta>0$ such that for any $\alpha<t<\alpha+\delta$ , one has $$ - \frac{\varepsilon}{2} + \left | \left | \frac{f(t)-f(\alpha)}{t-\alpha} \right | \right | \leq || f'_{+}(\alpha) || \leq g'_{+}(\alpha) < \frac{g(t)-g(\alpha)}{t-\alpha} + \frac{\varepsilon}{2}.$$ It follows that $||f(t)-f(\alpha)|| < g(t)-g(\alpha) + \varepsilon(t-\alpha)$ for every $\alpha<t<\alpha+\delta$ . Since $\alpha \notin U$ , we also have $||f(\alpha)-f(c)|| \leq g(\alpha)-g(c)-\varepsilon(\alpha-c)$ . If $t \in (\alpha, \alpha+\delta)$ , then \begin{align*} ||f(t)-f(c)|| &\leq ||f(t) - f(\alpha)|| + ||f(\alpha)-f(c) || \\ & \leq (g(t)-g(\alpha) + \varepsilon(t-\alpha) ) + (g(\alpha)-g(c)+ \varepsilon(\alpha-c) \\ &= g(t)-g(c)+\varepsilon(t-c).  \end{align*} So, $(\alpha, \alpha+\delta) \cap U = \emptyset$ and supposedly $\alpha = \inf U$ , which is impossible. So in fact $U=\emptyset$ , and thus $b \in U^c$ , from which it follows $||f(b)-f(a)|| \leq g(b)-g(a)+\varepsilon(b-a)$ and $\varepsilon$ was arbitrary. $\blacksquare$ Remark : the Theorem remains true if right differentiability is assumed for all but countably many points in $(c,d)$ . Corollary (Cartan, 3.3.1) . Let $X,Y$ be normed, let $f:U \rightarrow Y $ be a map (where $U \subseteq X$ is open and not empty) and fix $x,y \in U$ . Suppose the line segment between $x$ and $y$ is contained in $U$ , and suppose that $f$ is Frechet differentiable on $U$ . Then, $$||f(x)-f(y)||_Y \leq \sup ||f'(\zeta)||_Y ||x-y||_X,$$ where the sup is taken over the line segment between $x$ and $y$ . (The corollary follows from applying Theorem 3.1.1 to $g:= f \circ \psi$ , where $\psi:[0,1] \rightarrow X, t \mapsto tx+(1-t)y$ ).","The following theorem is in Drabek, Milota's Nonlinear Analysis. Like Drabek and Milota, I won't assume a priori Gateaux differentials are continuous nor linear. Theorem . Let be normed spaces, and a map (perhaps not continuous). Fix . Suppose that the Gateaux differential exists for all . Then, we have the estimate The proof uses the Hahn-Banach Theorem (or a corollary thereof) by taking a linear functional such that and . I would like to know if the use of the Hahn-Banach Theorem - or more generally, the Axiom of Choice - is needed to prove the theorem (that is, does there exist a proof that does not make use of choice principles)? I would also be interested in weaker choice principles, such as dependent or countable choice. I have also tried to modify the argument I saw in Cartan's Differential Calculus in the proof of the Mean Value Theorem for differentiable maps , a normed space (the argument requires no choice principles); see Theorem 3.1.1, page 37-39 in Cartan. Somewhat in analogy to Cartan's argument, I have tried to define Then perhaps one could show is open in and one notes that . I am not sure exactly how to proceed to obtain a contradiction (as in Cartan's proof), however. My ideas for this attempt aren't well-formed, but I thought it would be useful to mention Cartan's proof. Perhaps this stackexchange question is also useful: Does one need the Hahn-Banach theorem to prove the mean value inequality for maps into a normed space? , though I'm interested in the version of the Mean Value theorem involving Gateaux derivatives as stated above. Thanks in advance. Edit: for reference, I'll include Cartan's Theorem here and a sketch of the proof. (The theorem is stated for Banach , but completeness is in fact unnecessary). It is the proof of Theorem 3.1.1 I have tried to modify to my particular case, but it seems that I am unsure how to proceed. Theorem (Cartan, 3.1.1) . Let be normed, let be maps. Suppose that the right derivatives exists at all points in , and assume that for all . Then, Sketch : Following Cartan, one fixes and puts Aiming for a contradiction, suppose is not empty. Then, is open and let us define ; then, , and in fact, . By the existence of the right derivatives, there is a such that for any , one has It follows that for every . Since , we also have . If , then So, and supposedly , which is impossible. So in fact , and thus , from which it follows and was arbitrary. Remark : the Theorem remains true if right differentiability is assumed for all but countably many points in . Corollary (Cartan, 3.3.1) . Let be normed, let be a map (where is open and not empty) and fix . Suppose the line segment between and is contained in , and suppose that is Frechet differentiable on . Then, where the sup is taken over the line segment between and . (The corollary follows from applying Theorem 3.1.1 to , where ).","X,Y f: X \rightarrow Y a,b \in X df(a+t(b-a); b-a) t \in [0,1]  ||f(b)-f(a)||_Y \leq \sup_{t \in [0,1]} ||df(a+t(b-a) ; b-a) ||_Y. \varphi \in X^* ||\varphi||_{X^*}=1 \varphi(f(b)-f(a)) = ||f(b)-f(a)|| [a,b] \rightarrow Y Y E= \{t \in [0,1] | \text{ for every neighbourhood } U \text{ of } 0, \text{ there is } p \in U \text{ such that } |p| ||f(b)-f(a)||_Y > ||f(a+t(b-a) + p(b-a)) - f(a+t(b-a)) ||_Y \}. E \mathbb R \inf E \notin E Y Y f:[c,d] \rightarrow Y, g:[c,d] \rightarrow \mathbb R f'_{+}, g'_{+} (c,d) ||f'_{+}(x)|| \leq g'_{+}(x) x \in (c,d) ||f(d)-f(c)|| \leq g(d)-g(c). \varepsilon>0 U = \{x \in [c,d] | ||f(x)-f(c)|| > g(x)-g(c)+ \varepsilon(x-c) \}. U U \alpha= \inf U \alpha \notin U \alpha>c \delta>0 \alpha<t<\alpha+\delta  - \frac{\varepsilon}{2} + \left | \left | \frac{f(t)-f(\alpha)}{t-\alpha} \right | \right | \leq || f'_{+}(\alpha) || \leq g'_{+}(\alpha) < \frac{g(t)-g(\alpha)}{t-\alpha} + \frac{\varepsilon}{2}. ||f(t)-f(\alpha)|| < g(t)-g(\alpha) + \varepsilon(t-\alpha) \alpha<t<\alpha+\delta \alpha \notin U ||f(\alpha)-f(c)|| \leq g(\alpha)-g(c)-\varepsilon(\alpha-c) t \in (\alpha, \alpha+\delta) \begin{align*} ||f(t)-f(c)|| &\leq ||f(t) - f(\alpha)|| + ||f(\alpha)-f(c) || \\
& \leq (g(t)-g(\alpha) + \varepsilon(t-\alpha) ) + (g(\alpha)-g(c)+ \varepsilon(\alpha-c) \\
&= g(t)-g(c)+\varepsilon(t-c). 
\end{align*} (\alpha, \alpha+\delta) \cap U = \emptyset \alpha = \inf U U=\emptyset b \in U^c ||f(b)-f(a)|| \leq g(b)-g(a)+\varepsilon(b-a) \varepsilon \blacksquare (c,d) X,Y f:U \rightarrow Y  U \subseteq X x,y \in U x y U f U ||f(x)-f(y)||_Y \leq \sup ||f'(\zeta)||_Y ||x-y||_X, x y g:= f \circ \psi \psi:[0,1] \rightarrow X, t \mapsto tx+(1-t)y","['functional-analysis', 'gateaux-derivative']"
17,"If X has beta property, do $(x_i)_i$ points are LUR?","If X has beta property, do  points are LUR?",(x_i)_i,"Let $X$ be a Banach space, $S_X$ its unit sphere and $B_X$ its unit ball. The space $X$ is said to has $\beta$ property if there exists a system $\{(x_i,f_i):i \in I\} \subset S_X \times S_{X^*}$ and $0 \leq \rho <1$ such that (i) $f_i(x_i)=1$ , for all $i \in I$ (ii) $|f_i(x_j)| \leq \rho$ , for all $i \neq j$ (iii) $||x|| = \sup\{|f_i(x)|:i \in I\}$ , for all $x \in X$ A point $x \in S_X$ is called locally uniformly convex (LUR) if for every $\epsilon>0$ there exists $\delta(\epsilon)>0$ such that $y \in S_X, \cfrac{||x+y||}{2}>1-\delta(\epsilon) \Rightarrow ||x-y||<\epsilon $ I'm trying to prove that if $X$ has $\beta$ property and $\dim X >1$ , such points $(x_i)_{i}$ cannot be LUR points. My first attempt at a solution was try to define a sequence $(x_n)$ in $S_X$ such that $||x_n+x_i||$ approaches to $2$ and $||x_n-x_i||$ does not approach to $0$ . It is easy to see that if $x \in S_X \cap \ker{f_i}$ , we have that $||x-x_i|| \geq 1$ , then maybe it is a good idea to define such sequence in $S_X \cap \ker{f_i}$ . Is it a good approach? Any other hints?","Let be a Banach space, its unit sphere and its unit ball. The space is said to has property if there exists a system and such that (i) , for all (ii) , for all (iii) , for all A point is called locally uniformly convex (LUR) if for every there exists such that I'm trying to prove that if has property and , such points cannot be LUR points. My first attempt at a solution was try to define a sequence in such that approaches to and does not approach to . It is easy to see that if , we have that , then maybe it is a good idea to define such sequence in . Is it a good approach? Any other hints?","X S_X B_X X \beta \{(x_i,f_i):i \in I\} \subset S_X \times S_{X^*} 0 \leq \rho <1 f_i(x_i)=1 i \in I |f_i(x_j)| \leq \rho i \neq j ||x|| = \sup\{|f_i(x)|:i \in I\} x \in X x \in S_X \epsilon>0 \delta(\epsilon)>0 y \in S_X, \cfrac{||x+y||}{2}>1-\delta(\epsilon) \Rightarrow ||x-y||<\epsilon  X \beta \dim X >1 (x_i)_{i} (x_n) S_X ||x_n+x_i|| 2 ||x_n-x_i|| 0 x \in S_X \cap \ker{f_i} ||x-x_i|| \geq 1 S_X \cap \ker{f_i}","['functional-analysis', 'banach-spaces']"
18,How to prove that a delta function belongs to the Besov space $B^{-1}$?,How to prove that a delta function belongs to the Besov space ?,B^{-1},"$\def\R{\mathbb{R}}$ $\DeclareMathOperator{\supp}{supp}$ I am trying to understand the definition of the Besov space and to prove that the delta function in $\R^1$ . However I got stuck. First, let us recall that a sequence of smooth functions $\{\phi_i\}_{i\ge-1}$ is called a partition of unity if $\sum_{i=-1}^\infty \phi_i=1$ , $\supp(\phi_{-1})\subset\{x\colon |x|\le 2\}$ ; $\supp(\phi_{i})\subset\{x\colon 2^{i-1}\le |x|\le 2^{i+1}\}$ . The Besov space $B^s_{p,q}$ , where $s\in\R$ , $p,q\ge1$ is defined as the collection of all functions $f$ such that $$ \|f\|_{p,q}^s:=\|(2^{sj}\|F^{-1}\phi_j Ff\|_{L_p})_{j\ge-1}\|_{l_q}<\infty. $$ Here $F$ is the Fourier transform operator. I would like to prove that for any fixed $x\in\R$ the delta function $\delta_x$ is in $B^{-1}_{\infty,\infty}$ . Clearly, $$ F\delta_x(\lambda)=e^{i\lambda x}. $$ But now I am confused. How should we estimate $$ \|F^{-1}\phi_j e^{i\lambda x}\|_{L_\infty}? $$","I am trying to understand the definition of the Besov space and to prove that the delta function in . However I got stuck. First, let us recall that a sequence of smooth functions is called a partition of unity if , ; . The Besov space , where , is defined as the collection of all functions such that Here is the Fourier transform operator. I would like to prove that for any fixed the delta function is in . Clearly, But now I am confused. How should we estimate","\def\R{\mathbb{R}} \DeclareMathOperator{\supp}{supp} \R^1 \{\phi_i\}_{i\ge-1} \sum_{i=-1}^\infty \phi_i=1 \supp(\phi_{-1})\subset\{x\colon |x|\le 2\} \supp(\phi_{i})\subset\{x\colon 2^{i-1}\le |x|\le 2^{i+1}\} B^s_{p,q} s\in\R p,q\ge1 f 
\|f\|_{p,q}^s:=\|(2^{sj}\|F^{-1}\phi_j Ff\|_{L_p})_{j\ge-1}\|_{l_q}<\infty.
 F x\in\R \delta_x B^{-1}_{\infty,\infty} 
F\delta_x(\lambda)=e^{i\lambda x}.
 
\|F^{-1}\phi_j e^{i\lambda x}\|_{L_\infty}?
","['functional-analysis', 'dirac-delta', 'besov-space']"
19,"$X\times\hat A$ homeomorphic to $\widehat{C(X,A)}$ for unital $C^*$-algebras $A$",homeomorphic to  for unital -algebras,"X\times\hat A \widehat{C(X,A)} C^* A","Let $X$ be a compact Hausdorff space and $A$ a unital $C^*$-algebra, then I know that \begin{align*} \Psi:X\times\hat A &\to \widehat{C(X,A)} \\ (x,[\pi]) &\mapsto [\pi\circ\epsilon_x] \end{align*} is a bijection where $\epsilon_x:C(X,A)\to A$ is the point evaluation $\epsilon_x(f):=f(x)$ (see J. Dixmier ""$C^*$-Algebras"" , Corollary 10.4.4). I want to show that $\Psi$ is a homeomorphism with respect to the Hull-Kernel-Topology on the irreducible representations $\hat A$ and $\widehat{C(X,A)}$. I was able to show that $\Psi^{-1}$ is continuous, so I only need the continuity of $\Psi$. $\newcommand\Hull{\operatorname{Hull}}$ $\newcommand\Ker{\operatorname{Ker}}$ So far I am starting with a net $(x_\lambda,[\pi_\lambda])$ that converges to some $(x,[\pi])$ and want to show that $$\Psi(x,[\pi])\in\overline{\Psi(\{(x_\lambda,[\pi_\lambda]\}_\lambda)}=\Hull\Ker\{[\pi_\lambda\circ\epsilon_{x_\lambda}]\}_\lambda$$ To this end let $f\in\Ker\{[\pi_\lambda\circ\epsilon_{x_\lambda}]\}_\lambda$, then we have to show that $\pi(f(x))\equiv\pi\circ\epsilon_x(f)=0$. Since $f\in\ker(\pi_\lambda\circ\epsilon_{x_\lambda})$ for all $\lambda$, we know that $\pi_\lambda(f(x_\lambda))\equiv\pi\circ\epsilon_x(f)=0$ for all $\lambda$. So the continuity of $\Psi$ follows when we can show that $$ [\forall \lambda:\pi_\lambda(f(x_\lambda))=0,\; \pi_\lambda\to\pi,\;x_\lambda\to x] \quad\Rightarrow\quad \pi(f(x))=0 $$ I think it's safe to reduce this to the simpler statement $$ [\forall \lambda:\pi_\lambda(a_\lambda)=0,\; \pi_\lambda\to\pi,\;a_\lambda\to a\in A] \quad\Rightarrow\quad \pi(a)=0 $$ This certainly looks like it should be true, but I'm not able to show this. For the interested reader: One can show the continuity of $\Psi^{-1}$ using nets: if $[\pi_\lambda\circ\epsilon_{x_\lambda}]\to[\pi\circ\epsilon_x]$, then one can proof separately that $[\pi_\lambda]\to[\pi]$ and $x_\lambda\to x$ by contradiction, which shows $(x_\lambda,[\pi_\lambda])\to(x,[\pi])$ . Alternatively one can show for all subsets $X_0\subset X$, $A_0\subset\hat A$, that $$\Ker(\Psi(X_0\times A_0))=I_{X_0,A_0}:=\{f\in C(X,A)\,|\,f(X_0)\subset\ker A_0\}$$ This can be used to show for closed $X_0,A_0$, that $\Psi(X_0\times A_0)$ is also closed, which shows that $\Psi$ is closed, therefore $\Psi^{-1}$ must be continuous.","Let $X$ be a compact Hausdorff space and $A$ a unital $C^*$-algebra, then I know that \begin{align*} \Psi:X\times\hat A &\to \widehat{C(X,A)} \\ (x,[\pi]) &\mapsto [\pi\circ\epsilon_x] \end{align*} is a bijection where $\epsilon_x:C(X,A)\to A$ is the point evaluation $\epsilon_x(f):=f(x)$ (see J. Dixmier ""$C^*$-Algebras"" , Corollary 10.4.4). I want to show that $\Psi$ is a homeomorphism with respect to the Hull-Kernel-Topology on the irreducible representations $\hat A$ and $\widehat{C(X,A)}$. I was able to show that $\Psi^{-1}$ is continuous, so I only need the continuity of $\Psi$. $\newcommand\Hull{\operatorname{Hull}}$ $\newcommand\Ker{\operatorname{Ker}}$ So far I am starting with a net $(x_\lambda,[\pi_\lambda])$ that converges to some $(x,[\pi])$ and want to show that $$\Psi(x,[\pi])\in\overline{\Psi(\{(x_\lambda,[\pi_\lambda]\}_\lambda)}=\Hull\Ker\{[\pi_\lambda\circ\epsilon_{x_\lambda}]\}_\lambda$$ To this end let $f\in\Ker\{[\pi_\lambda\circ\epsilon_{x_\lambda}]\}_\lambda$, then we have to show that $\pi(f(x))\equiv\pi\circ\epsilon_x(f)=0$. Since $f\in\ker(\pi_\lambda\circ\epsilon_{x_\lambda})$ for all $\lambda$, we know that $\pi_\lambda(f(x_\lambda))\equiv\pi\circ\epsilon_x(f)=0$ for all $\lambda$. So the continuity of $\Psi$ follows when we can show that $$ [\forall \lambda:\pi_\lambda(f(x_\lambda))=0,\; \pi_\lambda\to\pi,\;x_\lambda\to x] \quad\Rightarrow\quad \pi(f(x))=0 $$ I think it's safe to reduce this to the simpler statement $$ [\forall \lambda:\pi_\lambda(a_\lambda)=0,\; \pi_\lambda\to\pi,\;a_\lambda\to a\in A] \quad\Rightarrow\quad \pi(a)=0 $$ This certainly looks like it should be true, but I'm not able to show this. For the interested reader: One can show the continuity of $\Psi^{-1}$ using nets: if $[\pi_\lambda\circ\epsilon_{x_\lambda}]\to[\pi\circ\epsilon_x]$, then one can proof separately that $[\pi_\lambda]\to[\pi]$ and $x_\lambda\to x$ by contradiction, which shows $(x_\lambda,[\pi_\lambda])\to(x,[\pi])$ . Alternatively one can show for all subsets $X_0\subset X$, $A_0\subset\hat A$, that $$\Ker(\Psi(X_0\times A_0))=I_{X_0,A_0}:=\{f\in C(X,A)\,|\,f(X_0)\subset\ker A_0\}$$ This can be used to show for closed $X_0,A_0$, that $\Psi(X_0\times A_0)$ is also closed, which shows that $\Psi$ is closed, therefore $\Psi^{-1}$ must be continuous.",,"['functional-analysis', 'c-star-algebras']"
20,Distributional limit of a sequence of Dirac delta,Distributional limit of a sequence of Dirac delta,,"I have to evaluate the following distributional limit: $$ \lim_{n \to \infty} T_n = \lim_{n \to \infty} \frac 1n \sum_{k=-2n}^{5n} \delta_{\frac kn}$$ We have that $$\lim_{n \to \infty}\langle T_n, \phi\rangle =\lim_{n \to \infty} \frac 1n \sum_{k=-2n}^{5n} \phi\left({\frac kn}\right)$$ Now my idea is to use an integral sum to evaluate this limit, in particular, I know that: $$ \lim_{n \to \infty}\underbrace{\frac{b-a}{n} \sum_{k=1}^n g\left(a+\frac{b-a}{n}k\right)}_{\text{integral sum}} = \int_a^b g(x) \: \mathrm{d}x$$ so i put $ \frac kn = a+\frac{b-a}{n}h=-2+\frac 7n h \implies h=\frac{k+2n}{7}$, and substituting this into my summation I get: \begin{align} \lim_{n \to \infty} \frac 1n \sum_{k=-2n}^{5n} \phi\left({\frac kn}\right) &= \lim_{n \to \infty} \frac 1n \sum_{h=0}^{n} \phi\left(-2+\frac 7n k\right)\\ & =\lim_{n \to \infty} \frac 17 \frac 7n \sum_{h=0}^{n} \phi\left(-2+\frac 7n k\right)\\ &=\frac 17 \int_{-2}^{5} \phi(x) \: \mathrm{d}x \end{align} Is that correct? Because my book says that the result should be what I got but without that $\frac 17$ coefficient. EDIT: I just realized that my substitution $h=\frac{k+2n}{7}$ doesn't seem correct since $h$ is not an integer in general as $k$ varies... so any idea?","I have to evaluate the following distributional limit: $$ \lim_{n \to \infty} T_n = \lim_{n \to \infty} \frac 1n \sum_{k=-2n}^{5n} \delta_{\frac kn}$$ We have that $$\lim_{n \to \infty}\langle T_n, \phi\rangle =\lim_{n \to \infty} \frac 1n \sum_{k=-2n}^{5n} \phi\left({\frac kn}\right)$$ Now my idea is to use an integral sum to evaluate this limit, in particular, I know that: $$ \lim_{n \to \infty}\underbrace{\frac{b-a}{n} \sum_{k=1}^n g\left(a+\frac{b-a}{n}k\right)}_{\text{integral sum}} = \int_a^b g(x) \: \mathrm{d}x$$ so i put $ \frac kn = a+\frac{b-a}{n}h=-2+\frac 7n h \implies h=\frac{k+2n}{7}$, and substituting this into my summation I get: \begin{align} \lim_{n \to \infty} \frac 1n \sum_{k=-2n}^{5n} \phi\left({\frac kn}\right) &= \lim_{n \to \infty} \frac 1n \sum_{h=0}^{n} \phi\left(-2+\frac 7n k\right)\\ & =\lim_{n \to \infty} \frac 17 \frac 7n \sum_{h=0}^{n} \phi\left(-2+\frac 7n k\right)\\ &=\frac 17 \int_{-2}^{5} \phi(x) \: \mathrm{d}x \end{align} Is that correct? Because my book says that the result should be what I got but without that $\frac 17$ coefficient. EDIT: I just realized that my substitution $h=\frac{k+2n}{7}$ doesn't seem correct since $h$ is not an integer in general as $k$ varies... so any idea?",,"['functional-analysis', 'distribution-theory', 'dirac-delta']"
21,Weak convergence implies strong convergence,Weak convergence implies strong convergence,,"Assume that the sequence $(A_n)$ of bounded linear operators on a Hilbert space $H$ converges weakly to an operator $A$. Assume also that $\|A_nx\|\to \|Ax\|$ for all $x\in H$.         Prove that $(A_n)$ converges strongly to $A$, i.e. $A_n x\to Ax$ for all $x\in H$. To be honest, I don't have too much of an idea on this one. We have $$<A_n,x> \to <A,x> \leq ||A_nx-Ax||xx||$$ I am thinking it is likely going to be a trick with the inequality (and I'm pretty sure the above isn't correct). It seems to me obvious but yet it is eluding me. I think my struggle is figuring out what that inner product looks like for the weak convergence of an operator.","Assume that the sequence $(A_n)$ of bounded linear operators on a Hilbert space $H$ converges weakly to an operator $A$. Assume also that $\|A_nx\|\to \|Ax\|$ for all $x\in H$.         Prove that $(A_n)$ converges strongly to $A$, i.e. $A_n x\to Ax$ for all $x\in H$. To be honest, I don't have too much of an idea on this one. We have $$<A_n,x> \to <A,x> \leq ||A_nx-Ax||xx||$$ I am thinking it is likely going to be a trick with the inequality (and I'm pretty sure the above isn't correct). It seems to me obvious but yet it is eluding me. I think my struggle is figuring out what that inner product looks like for the weak convergence of an operator.",,['functional-analysis']
22,Every separable Hilbert space has an orthonormal basis,Every separable Hilbert space has an orthonormal basis,,"Prove the following: Every non trivial separable Hilbert space $H$ has an orthonormal   basis, i.e., an orthonormal set whose linear span is dense in $H$ My attempt : Let $V = (v_n)_{n\geq1}$ be a dense countable set of vectors in $H$. Remove all  vectors that are $0$, and then, skim the sequence from the left to the right and remove every vector that is a linear combination of the previous ones. Call the obtained sequence, which is possibly finite, $(y_n)_{n\geq1}$. By construction, this sequence of vectors is linearly independent, so we can apply the Gram-Schmidt (GS) algorithm to find a sequence $(\phi_n)_n$ of vectors such that $O := \{\phi_n\mid n\}$ is an orthonormal set of vectors. It now suffices to show that the linear span of $O$ is dense in $H$, in order to conclude that $O$ is an orthonormal basis. For this, it suffices to show that $O^\perp = \{0\}$. So, let $v \in O^\perp$. Then $\langle v,\phi\rangle = 0$ for every $\phi \in O$, and by linearity of the inner product, it follows that $v \in \operatorname{span}(O)^\perp$. By continuity of the inner product, it follows that $v \in \left(\overline{\operatorname{span}(O)}\right)^\perp$. Now, $\operatorname{span} O = \operatorname{span}\{\phi_n \mid n\} =^{GS} \operatorname{span}\{y_n\mid n\} = \operatorname{span} V$ so that $\left(\overline{\operatorname{span}(O)}\right)^\perp = \left(\overline{\operatorname{span(V)}}\right)^\perp \subseteq \operatorname{span}(\overline{V})^\perp = \operatorname{span}(H)^\perp = H^\perp = \{0\}$, where we used that $X \subseteq Y \implies Y^\perp \subseteq X^\perp$ and hence $v = 0$ Is this correct?","Prove the following: Every non trivial separable Hilbert space $H$ has an orthonormal   basis, i.e., an orthonormal set whose linear span is dense in $H$ My attempt : Let $V = (v_n)_{n\geq1}$ be a dense countable set of vectors in $H$. Remove all  vectors that are $0$, and then, skim the sequence from the left to the right and remove every vector that is a linear combination of the previous ones. Call the obtained sequence, which is possibly finite, $(y_n)_{n\geq1}$. By construction, this sequence of vectors is linearly independent, so we can apply the Gram-Schmidt (GS) algorithm to find a sequence $(\phi_n)_n$ of vectors such that $O := \{\phi_n\mid n\}$ is an orthonormal set of vectors. It now suffices to show that the linear span of $O$ is dense in $H$, in order to conclude that $O$ is an orthonormal basis. For this, it suffices to show that $O^\perp = \{0\}$. So, let $v \in O^\perp$. Then $\langle v,\phi\rangle = 0$ for every $\phi \in O$, and by linearity of the inner product, it follows that $v \in \operatorname{span}(O)^\perp$. By continuity of the inner product, it follows that $v \in \left(\overline{\operatorname{span}(O)}\right)^\perp$. Now, $\operatorname{span} O = \operatorname{span}\{\phi_n \mid n\} =^{GS} \operatorname{span}\{y_n\mid n\} = \operatorname{span} V$ so that $\left(\overline{\operatorname{span}(O)}\right)^\perp = \left(\overline{\operatorname{span(V)}}\right)^\perp \subseteq \operatorname{span}(\overline{V})^\perp = \operatorname{span}(H)^\perp = H^\perp = \{0\}$, where we used that $X \subseteq Y \implies Y^\perp \subseteq X^\perp$ and hence $v = 0$ Is this correct?",,"['functional-analysis', 'proof-verification']"
23,When are two measures equal?,When are two measures equal?,,"I am having trouble with a certain technical part of solving a problem. The question can be formulated as the following: Let $X$ be a locally compact Hausdorff space and $M(X)$ be the space of all regular Borel complex measures on $X$. Pick any $\mu, \nu \in M(X)$. We have that $$\int f \ d\mu = \int f \ d\nu$$ for every bounded continuous function $f$ on $X$. Is it sufficient to conclude that $\mu = \nu$? If not,then what additional condition is needed? I believe that since $C_0(X) \subset C_b(X)$ and $C_0(X)$ is a separating family of functions, it should be true.","I am having trouble with a certain technical part of solving a problem. The question can be formulated as the following: Let $X$ be a locally compact Hausdorff space and $M(X)$ be the space of all regular Borel complex measures on $X$. Pick any $\mu, \nu \in M(X)$. We have that $$\int f \ d\mu = \int f \ d\nu$$ for every bounded continuous function $f$ on $X$. Is it sufficient to conclude that $\mu = \nu$? If not,then what additional condition is needed? I believe that since $C_0(X) \subset C_b(X)$ and $C_0(X)$ is a separating family of functions, it should be true.",,"['functional-analysis', 'measure-theory']"
24,inequality for second fundamental form in distribution sense,inequality for second fundamental form in distribution sense,,"I'm trying to read this paper ( Schoen-Simon-Yau '74 ) and I'm struggling to understand the comment to (1.34). (See also here for another question on this paper.) SSY are showing an estimate for the second fundamental form of an immersed $n$-dimensional Riemannian manifold $M$ in an ambient $(n+1)$-dimensional Riemanninan manifold $N$. The inequality of interest is  \begin{align} \tag{*} |A| \, \Delta |A| + |A|^4 &\geq \frac 2 {(1+\varepsilon) \, n} \, |\nabla |A||^2 - \frac {n \, (n-1)} {2 \, \varepsilon} \, (K_1 - K_2)^2 \\ &\quad - 2 \, c \, |A| + n \, (2 \, K_2 - K_1) \, |A|^2, \end{align} where $|A|^2 = \sum_{i,j} h^2_{ij}$ with $h_{ij}$ the second fundamental form of $M$, $\nabla$ the covariant derivative on $M$, $K_1 \leq K_2 \in \mathbb R$  and $c \in \mathbb R$ constants. Now my question is due to the comment: ""[$(*)$ holds] at all points where $|A| \neq 0$. Actually since $|A| \, \Delta |A| = \frac 1 2 \Delta |A|^2 - |\nabla|A||^2$ we can in fact   see that this inequality must be globally true in the distribution sense, even if $|A|$ vanishes at various points."" I suppose the problem here is, that since $|A|$ involves a square root, any derivative term would yield infinity if $|A| = 0$. Since with the identity $|A| \, \Delta |A| = \frac 1 2 \Delta |A|^2 - |\nabla|A||^2$ there is no more square root in the first term, I suppose the problematic term is the latter. Now, it should be somehow possible to get rid of the derivatives by multiplying with a test function and integrating by parts. However, I can't see how this works. EDIT 1 What I tried is to get rid of derivatives of $|A|$ (without the square). Let $\varphi \in C^\infty_c(M)$, then $$\int |\nabla |A||^2 \, \varphi = \underbrace{\int \nabla \cdot (|A|\, \nabla |A| \, \varphi)}_{=0} - \int |A| \, \nabla |A| \cdot \nabla \varphi - \int |A| \, \Delta |A| \, \varphi$$ Now the first term is total divergence, so it will vanish. But how about the second? How do I get rid of the derivative in front of $|A|$? EDIT 2 Eric Silva mentioned in the comments below, that $|A|$ would satisfy an elliptic PDE, as shown in Simons' paper. However, in Simons' paper (and in Holck-Minicozzi's book, eq. (2.16)) I can only find an elliptic PDE for $|A|^2$, whence I still have no clue about the regularity of $|A|$. Or am I wrong here? EDIT 3 I think what could work is a convergence argument. Observe that upon multiplication with $|A|^2$ all the (possibly) singular terms behave smoothly. Now I want to show that for $\varphi \in C^\infty_c(M)$ with $\varphi_\varepsilon = \frac 1 \varepsilon \, \min\{\varepsilon,|A|^2\} \to \varphi \,\, (\varepsilon \to 0)$ we have $$\int_M |\nabla |A||^2 \, \varphi = \lim_{\varepsilon \to 0} \int_M |\nabla |A||^2 \, \varphi_\varepsilon < \infty$$ Does someone have an idea or a tip for me? Thanks a lot in advance!","I'm trying to read this paper ( Schoen-Simon-Yau '74 ) and I'm struggling to understand the comment to (1.34). (See also here for another question on this paper.) SSY are showing an estimate for the second fundamental form of an immersed $n$-dimensional Riemannian manifold $M$ in an ambient $(n+1)$-dimensional Riemanninan manifold $N$. The inequality of interest is  \begin{align} \tag{*} |A| \, \Delta |A| + |A|^4 &\geq \frac 2 {(1+\varepsilon) \, n} \, |\nabla |A||^2 - \frac {n \, (n-1)} {2 \, \varepsilon} \, (K_1 - K_2)^2 \\ &\quad - 2 \, c \, |A| + n \, (2 \, K_2 - K_1) \, |A|^2, \end{align} where $|A|^2 = \sum_{i,j} h^2_{ij}$ with $h_{ij}$ the second fundamental form of $M$, $\nabla$ the covariant derivative on $M$, $K_1 \leq K_2 \in \mathbb R$  and $c \in \mathbb R$ constants. Now my question is due to the comment: ""[$(*)$ holds] at all points where $|A| \neq 0$. Actually since $|A| \, \Delta |A| = \frac 1 2 \Delta |A|^2 - |\nabla|A||^2$ we can in fact   see that this inequality must be globally true in the distribution sense, even if $|A|$ vanishes at various points."" I suppose the problem here is, that since $|A|$ involves a square root, any derivative term would yield infinity if $|A| = 0$. Since with the identity $|A| \, \Delta |A| = \frac 1 2 \Delta |A|^2 - |\nabla|A||^2$ there is no more square root in the first term, I suppose the problematic term is the latter. Now, it should be somehow possible to get rid of the derivatives by multiplying with a test function and integrating by parts. However, I can't see how this works. EDIT 1 What I tried is to get rid of derivatives of $|A|$ (without the square). Let $\varphi \in C^\infty_c(M)$, then $$\int |\nabla |A||^2 \, \varphi = \underbrace{\int \nabla \cdot (|A|\, \nabla |A| \, \varphi)}_{=0} - \int |A| \, \nabla |A| \cdot \nabla \varphi - \int |A| \, \Delta |A| \, \varphi$$ Now the first term is total divergence, so it will vanish. But how about the second? How do I get rid of the derivative in front of $|A|$? EDIT 2 Eric Silva mentioned in the comments below, that $|A|$ would satisfy an elliptic PDE, as shown in Simons' paper. However, in Simons' paper (and in Holck-Minicozzi's book, eq. (2.16)) I can only find an elliptic PDE for $|A|^2$, whence I still have no clue about the regularity of $|A|$. Or am I wrong here? EDIT 3 I think what could work is a convergence argument. Observe that upon multiplication with $|A|^2$ all the (possibly) singular terms behave smoothly. Now I want to show that for $\varphi \in C^\infty_c(M)$ with $\varphi_\varepsilon = \frac 1 \varepsilon \, \min\{\varepsilon,|A|^2\} \to \varphi \,\, (\varepsilon \to 0)$ we have $$\int_M |\nabla |A||^2 \, \varphi = \lim_{\varepsilon \to 0} \int_M |\nabla |A||^2 \, \varphi_\varepsilon < \infty$$ Does someone have an idea or a tip for me? Thanks a lot in advance!",,"['functional-analysis', 'differential-geometry', 'riemannian-geometry', 'minimal-surfaces']"
25,Why is $C^{-\infty}$ useful?,Why is  useful?,C^{-\infty},"So, $C^{-\infty}(\Omega) := (C_c^{\infty}(\Omega))'$, that is the space of  all continuous linear functionals over the space of compactly supported smooth functions. $C^{-\infty}(\mathbb{R}^n)$ is larger than tempered distributions $S'(\mathbb{R}^n)$ and we would get elements of $C^{-\infty}$ that aren't in  $S'$ if we took for example the integral pairing, $ u \Psi \to \int \phi \Psi$ for some $\phi \in C^{\infty}$. My question is what is the motivation behind these very general distributions? Are there examples where being in tempered distributions is not general enough? We have for example that Fourier transform is an isomorphism on $S'$ which is pretty useful but we don't have nice properties (I should say that I don't know any) on the very general $C^{-\infty}$, so I am wondering where  they are needed. Thank you!","So, $C^{-\infty}(\Omega) := (C_c^{\infty}(\Omega))'$, that is the space of  all continuous linear functionals over the space of compactly supported smooth functions. $C^{-\infty}(\mathbb{R}^n)$ is larger than tempered distributions $S'(\mathbb{R}^n)$ and we would get elements of $C^{-\infty}$ that aren't in  $S'$ if we took for example the integral pairing, $ u \Psi \to \int \phi \Psi$ for some $\phi \in C^{\infty}$. My question is what is the motivation behind these very general distributions? Are there examples where being in tempered distributions is not general enough? We have for example that Fourier transform is an isomorphism on $S'$ which is pretty useful but we don't have nice properties (I should say that I don't know any) on the very general $C^{-\infty}$, so I am wondering where  they are needed. Thank you!",,"['functional-analysis', 'dual-spaces']"
26,Dual space of $L^p$ using existence of minimisers.,Dual space of  using existence of minimisers.,L^p,"Exercise 14 from Terence Tao's notes on Hilbert spaces( https://terrytao.wordpress.com/2009/01/17/254a-notes-5-hilbert-spaces/ ) wants me to show that when $1<p<\infty$ , the dual space of $L^p(\mu)$ is $L^q(\mu)$ where $\mu$ is $\sigma-$ finite and $q$ is the dual exponent of $p$ . He wants me to do this using Exercise 11 and Proposition 1 which are as follows: Proposition 1 . (Existence of minimisers) Let $H$ be a Hilbert space, let $K$ be a non-empty closed convex subset of $H$ , and let $x$ be a point in $H$ .  Then there exists a unique $y$ in $K$ that minimises the distance $\|y-x\|$ to $x$ .  Furthermore, for any other $z$ in $K$ , we have $\hbox{Re} \langle z-y, y-x \rangle \geq 0$ . Exercise 11. Using the Hanner inequalities (Exercise 6), show that Proposition 1 also holds for the $L^p$ spaces as long as $1 < p < \infty$ .  (The specific feature of the $L^p$ spaces that is allowing this is known as uniform convexity.) Give counterexamples to show that the propsition can fail for $L^1$ and for $L^\infty$ . I tried to do something similar to the proof of the Riesz Representation theorem for the dual of a Hilbert space but have been unable to bring in $L^q$ into the picture. Specifically, let $S$ be the closed subspace of $L^p$ which is the kernel of a given linear functional $\lambda$ on $L^p$ . We choose a subspace $M$ such that $L^p$ is the direct sum of $M$ and $S$ . Now, $M$ has to be one dimensional because else we can find a non zero combination of linearly independent vectors in $M$ such that $\lambda$ assigns them the value $0$ . I have no idea if anything can be done after this. Another thing I tried was to consider the linear transformation $T:L^q\rightarrow(L^p)^*$ which maps $g$ to the linear functional $\lambda_g(f)=\int fgd\mu$ . Now, we let $S$ be the closed subspace $T(L^q)$ . Proposition 1 says that to any continuous linear functional $\lambda$ , there exists a closest functional in $S$ . Hence, I need to show that if I have a specific $\lambda_g$ as an approximation to $\lambda$ , I can always make the approximation a bit better(hence weaker than showing that $S$ is dense) by considering some $\lambda_h$ such that $h$ differs from $g$ on atleast a set of measure zero, to qualify as a different $L^q$ function. Hence, I need to somehow modify $g$ to reduce the quantity $\text{sup}\{|\lambda(f)-\int fgd\mu|:\|f\|=1\}$ , but I am unable to tackle the problem that if I modify $g$ keeping some specific $f$ in mind, another $f$ might increase the value to keep the supremum from decreasing.","Exercise 14 from Terence Tao's notes on Hilbert spaces( https://terrytao.wordpress.com/2009/01/17/254a-notes-5-hilbert-spaces/ ) wants me to show that when , the dual space of is where is finite and is the dual exponent of . He wants me to do this using Exercise 11 and Proposition 1 which are as follows: Proposition 1 . (Existence of minimisers) Let be a Hilbert space, let be a non-empty closed convex subset of , and let be a point in .  Then there exists a unique in that minimises the distance to .  Furthermore, for any other in , we have . Exercise 11. Using the Hanner inequalities (Exercise 6), show that Proposition 1 also holds for the spaces as long as .  (The specific feature of the spaces that is allowing this is known as uniform convexity.) Give counterexamples to show that the propsition can fail for and for . I tried to do something similar to the proof of the Riesz Representation theorem for the dual of a Hilbert space but have been unable to bring in into the picture. Specifically, let be the closed subspace of which is the kernel of a given linear functional on . We choose a subspace such that is the direct sum of and . Now, has to be one dimensional because else we can find a non zero combination of linearly independent vectors in such that assigns them the value . I have no idea if anything can be done after this. Another thing I tried was to consider the linear transformation which maps to the linear functional . Now, we let be the closed subspace . Proposition 1 says that to any continuous linear functional , there exists a closest functional in . Hence, I need to show that if I have a specific as an approximation to , I can always make the approximation a bit better(hence weaker than showing that is dense) by considering some such that differs from on atleast a set of measure zero, to qualify as a different function. Hence, I need to somehow modify to reduce the quantity , but I am unable to tackle the problem that if I modify keeping some specific in mind, another might increase the value to keep the supremum from decreasing.","1<p<\infty L^p(\mu) L^q(\mu) \mu \sigma- q p H K H x H y K \|y-x\| x z K \hbox{Re} \langle z-y, y-x \rangle \geq 0 L^p 1 < p < \infty L^p L^1 L^\infty L^q S L^p \lambda L^p M L^p M S M M \lambda 0 T:L^q\rightarrow(L^p)^* g \lambda_g(f)=\int fgd\mu S T(L^q) \lambda S \lambda_g \lambda S \lambda_h h g L^q g \text{sup}\{|\lambda(f)-\int fgd\mu|:\|f\|=1\} g f f","['functional-analysis', 'banach-spaces', 'lp-spaces']"
27,How do I prove that this space is a Banach space?,How do I prove that this space is a Banach space?,,"We define the following space  $$ L^{\Phi}(\Omega)=\left\{u:\Omega\rightarrow \mathbb{R}~\text{measurable};~\int_{\Omega}\Phi\left(\frac{u}{\lambda}\right) dx<+\infty, ~\text{for any}~\lambda>0\right\} $$ where $\Phi:\mathbb{R}\to\mathbb{R}^+$ satisfies the following conditions: $(i)$ $\Phi$ is a continuous and a convex function; $(ii)$ $\Phi(t)=0$ if, and only if $t=0$; $(iii)$ $\displaystyle\frac{\Phi(t)}{t}\overset{t\rightarrow0}{\longrightarrow}0$ and $\displaystyle\frac{\Phi(t)}{t}\overset{t\rightarrow+\infty}{\longrightarrow}+\infty$; $(iv)$ $\Phi$ is even (that is $\Phi(t)=\Phi(-t)$) Endowed with the norm: $$ ||u||_{\Phi}=\inf \left\{\lambda>0; \int_{\Omega}\Phi\left(\frac{u}{\lambda}\right)dx\leq 1\right\} $$ I start the proof by : Let $(f_n)\subset L^{\Phi}(\Omega)$ be a Cauchy sequence that is $||f_n-f_m||_{\Phi}\to0$ when $m,n\to\infty$ How do we find $f\in L^{\Phi}(\Omega)$ such that $||f_n-f||_{\Phi}\to0$ ? Thank you","We define the following space  $$ L^{\Phi}(\Omega)=\left\{u:\Omega\rightarrow \mathbb{R}~\text{measurable};~\int_{\Omega}\Phi\left(\frac{u}{\lambda}\right) dx<+\infty, ~\text{for any}~\lambda>0\right\} $$ where $\Phi:\mathbb{R}\to\mathbb{R}^+$ satisfies the following conditions: $(i)$ $\Phi$ is a continuous and a convex function; $(ii)$ $\Phi(t)=0$ if, and only if $t=0$; $(iii)$ $\displaystyle\frac{\Phi(t)}{t}\overset{t\rightarrow0}{\longrightarrow}0$ and $\displaystyle\frac{\Phi(t)}{t}\overset{t\rightarrow+\infty}{\longrightarrow}+\infty$; $(iv)$ $\Phi$ is even (that is $\Phi(t)=\Phi(-t)$) Endowed with the norm: $$ ||u||_{\Phi}=\inf \left\{\lambda>0; \int_{\Omega}\Phi\left(\frac{u}{\lambda}\right)dx\leq 1\right\} $$ I start the proof by : Let $(f_n)\subset L^{\Phi}(\Omega)$ be a Cauchy sequence that is $||f_n-f_m||_{\Phi}\to0$ when $m,n\to\infty$ How do we find $f\in L^{\Phi}(\Omega)$ such that $||f_n-f||_{\Phi}\to0$ ? Thank you",,"['functional-analysis', 'banach-spaces', 'orlicz-spaces']"
28,Some functional calculus of commuting positive operators,Some functional calculus of commuting positive operators,,"Let $A,B$ be two positive operators on a complex Hilbert space. We know that we can define $A^a$ for any $a\geq0$. If $A$ commutes with $B$, then do we have $(AB)^a=A^aB^a$? I believe this is correct but I am not too sure whether my proof is correct (it uses the spectral theorem)? I would appreciate any hint. Thanks in advance.","Let $A,B$ be two positive operators on a complex Hilbert space. We know that we can define $A^a$ for any $a\geq0$. If $A$ commutes with $B$, then do we have $(AB)^a=A^aB^a$? I believe this is correct but I am not too sure whether my proof is correct (it uses the spectral theorem)? I would appreciate any hint. Thanks in advance.",,['functional-analysis']
29,Help understand the proof of the Multivalued opertor version of the Hille-Yosida Theorem in Ethier-Kurtz,Help understand the proof of the Multivalued opertor version of the Hille-Yosida Theorem in Ethier-Kurtz,,"I am looking at the proof of the following version of the Hille-Yosida theorem given in Ethier and Kurtz' Markov Process. Some Definitions. Here, $A$ is a (multivalued) linear operator on $L$, i.e. a subset $A$ of $L \times L$ with domain $D(A)=\{f:(f,g)\in A \;\text{for some}\;g\}$ and range $R(A)=\{g: (f,g)\in A \; \text{for some}\;f\}$. $A\subset L\times L$ is said to be linear if $A$ is a subspace of $L\times L$. If $A$  is linear, then $A$ is said to be single-valued if $(0,g)\in A$ implies $g=0$, in this case, $A$ is a graph of a linear operator on $L$, also denoted by $A$, so we write $Af=g$ if $(f,g)\in A$. If $A\subset L\times L$ is linear, then $A$ is said to be dissipative if $\Vert \lambda f-g\Vert \ge \lambda \Vert f\Vert $ for all $(f,g)\in A$ and $\lambda >0$; the closure $\bar{A}$ of $A$ is just the closure in $L\times L$ of the subspace $A$. Finally, we define $\lambda - A=\{(f,\lambda f-g):(f,g)\in A\}$ for each $\lambda >0$. Lemma preceding the theorem. Below is the Theorem. Now in the below part of the proof, I don't understand why $\Vert \lambda(\lambda - \bar{A})^{-1}f-f\Vert = \Vert(\lambda - \bar{A})^{-1}g\Vert$ which is above (4.2). Also, why is the domain of $(\lambda - \bar{A})^{-1}$ given as $R(\lambda - A_0)$? Shouldn't it be $R(\lambda-\bar{A})$ by definition? Finally, I don't understand why the range is $D(A_0)$ either. I would greatly appreciate if anyone could explain these to me.","I am looking at the proof of the following version of the Hille-Yosida theorem given in Ethier and Kurtz' Markov Process. Some Definitions. Here, $A$ is a (multivalued) linear operator on $L$, i.e. a subset $A$ of $L \times L$ with domain $D(A)=\{f:(f,g)\in A \;\text{for some}\;g\}$ and range $R(A)=\{g: (f,g)\in A \; \text{for some}\;f\}$. $A\subset L\times L$ is said to be linear if $A$ is a subspace of $L\times L$. If $A$  is linear, then $A$ is said to be single-valued if $(0,g)\in A$ implies $g=0$, in this case, $A$ is a graph of a linear operator on $L$, also denoted by $A$, so we write $Af=g$ if $(f,g)\in A$. If $A\subset L\times L$ is linear, then $A$ is said to be dissipative if $\Vert \lambda f-g\Vert \ge \lambda \Vert f\Vert $ for all $(f,g)\in A$ and $\lambda >0$; the closure $\bar{A}$ of $A$ is just the closure in $L\times L$ of the subspace $A$. Finally, we define $\lambda - A=\{(f,\lambda f-g):(f,g)\in A\}$ for each $\lambda >0$. Lemma preceding the theorem. Below is the Theorem. Now in the below part of the proof, I don't understand why $\Vert \lambda(\lambda - \bar{A})^{-1}f-f\Vert = \Vert(\lambda - \bar{A})^{-1}g\Vert$ which is above (4.2). Also, why is the domain of $(\lambda - \bar{A})^{-1}$ given as $R(\lambda - A_0)$? Shouldn't it be $R(\lambda-\bar{A})$ by definition? Finally, I don't understand why the range is $D(A_0)$ either. I would greatly appreciate if anyone could explain these to me.",,"['functional-analysis', 'analysis', 'markov-process', 'semigroup-of-operators']"
30,weak*-convergence and weak operator topology - multiplication operator,weak*-convergence and weak operator topology - multiplication operator,,"The setting : let $(\Omega,\mu)$ $\sigma$-finite measure space and let $M_\phi : L^2(\Omega,\mu) \to L^2(\Omega,\mu)$ the multiplication operator with $\phi \in L^{\infty}(\Omega,\mu)$ I want to show  : If $M_{\phi_{i}} \to M_\phi $ in weak operator topology, then $\phi_i \to \phi$ in weak*-topology I already managed to show the reverse statement. I don't know if this helps or even is true : Maybe I can write every $f \in L^1$ as product of two functions in $L^2$ ?","The setting : let $(\Omega,\mu)$ $\sigma$-finite measure space and let $M_\phi : L^2(\Omega,\mu) \to L^2(\Omega,\mu)$ the multiplication operator with $\phi \in L^{\infty}(\Omega,\mu)$ I want to show  : If $M_{\phi_{i}} \to M_\phi $ in weak operator topology, then $\phi_i \to \phi$ in weak*-topology I already managed to show the reverse statement. I don't know if this helps or even is true : Maybe I can write every $f \in L^1$ as product of two functions in $L^2$ ?",,"['functional-analysis', 'operator-theory']"
31,Existence and uniqueness of $-\Delta u + u^3 =f$,Existence and uniqueness of,-\Delta u + u^3 =f,"I want to show the existence and uniqueness of the equation of the form $-\Delta u+u^3=f\in L^2(\Omega),\quad u=0~\mbox{on}~ \partial\Omega,~$ $\Omega\subset\mathbb{R}^3$-bounded I know one proof using Minty-Browder theorem and by direct method of calculus of variations, I'm looking for other proofs. Any hints? What about $\mathbb{R}^2$. I would be really thankful","I want to show the existence and uniqueness of the equation of the form $-\Delta u+u^3=f\in L^2(\Omega),\quad u=0~\mbox{on}~ \partial\Omega,~$ $\Omega\subset\mathbb{R}^3$-bounded I know one proof using Minty-Browder theorem and by direct method of calculus of variations, I'm looking for other proofs. Any hints? What about $\mathbb{R}^2$. I would be really thankful",,"['functional-analysis', 'partial-differential-equations', 'elliptic-equations', 'nonlinear-analysis']"
32,Is $x * d/dx$ closed on $L^2(\mathbb{R})$?,Is  closed on ?,x * d/dx L^2(\mathbb{R}),"More formally, sticking to the one-dimensional case for this problem, let $M_x$ be the multiplication-by-$x$ operator, $$\begin{split} \mathfrak{D}(M_x) &= \lbrace f(x) \in L^2(\mathbb{R}): x f(x) \in L^2(\mathbb{R}) \rbrace \\ M_x [f](x) &= x f(x) \end{split},$$ and let $D$ be the differentiation-by-$x$ operator $$ \begin{split} \mathfrak{D}(D) & = \lbrace f(x) \in L^2(\mathbb{R}): f^{\prime}(x) \in L^2(\mathbb{R}) \rbrace ( = \mathcal{H}^1(\mathbb{R}))\\ D[f](x) &= f^{\prime}(x) \end{split},$$ where we allow $f^{\prime}(x)$ to be a distributional derivative.  (Of course, thanks to the Fourier Transform $\mathcal{F}$, $$Df(x)  = \mathcal{F}^{-1} \left[i \xi \mathcal{F}[f](\xi) \right](x),$$ perhaps multiplied by a constant depending on the convention on the Fourier Transform.)  Of course, $M_x$ is closed and self-adjoint (e.g., Reed/Simon, Functional Analysis, Chap. VIII, Section 3, Prop. 1), and $D$ is closed by the same reasoning (being a constant multiple of the self-adjoint $i \frac{d}{dx}$). Question: Is $M_x \circ D$ closed on the natural domain, i.e., $ \mathfrak{D}(M_X \circ D) = \lbrace f(x) \in L^2(\mathbb{R}): f^{\prime}(x) \in L^2(\mathbb{R}), xf^{\prime}(x) \in L^2(\mathbb{R}) \rbrace$ ? Note: Of course, replacing $\frac{d}{dx}$ by $i \frac{d}{dx}$ may be simpler to allow self-adjointness, but I prefer to state it in the more elementary way.  Of course, if the proof is easier with $i \frac{d}{dx}$, then please just use that. Work so far: Let us set up a standard closure proof, so suppose that $f_n(x) \in \mathfrak{D}(M_X \circ D)$ and $f(x) \in L^2(\mathbb{R})$ satisfy \begin{align} f_n(x) &\overset{L^2}{\rightarrow} f(x) \tag{1}\\ x f_n^{\prime}(x) &\overset{L^2}{\rightarrow} g(x);  \tag{2} \end{align} we wish to show that $f(x) \in \mathfrak{D}(M_X \circ D)$ and $x f_n^{\prime}(x) \overset{L^2}{\rightarrow} x f^{\prime}(x)$. Claim: It suffices to show that  $$f_n^{\prime}(x) \overset{L^2}{\rightarrow} h(x) \tag{3} $$ for some $L^2$-function $h$. Proof: Suppose that (1), (2), and (3) hold (for some $L^2$ functions $\left(f_n\right)_{n = 1}^{\infty}$, $f$, $g$, and $h$).  By (1), (3), and the closure of $D$, it follows that $f(x) \in \mathfrak{D}(D)$ and $f_n^{\prime}(x) \overset{L^2}{\rightarrow} f^{\prime}(x)$, i.e., $h(x) = f^{\prime}(x)$.  Letting $h_n(x) = f_n^{\prime}(x)$, (3) now reads $$h_n(x) \overset{L^2}{\rightarrow} h(x), \tag{3*}$$ and (2) now reads $$x h_n(x) \overset{L^2}{\rightarrow} g(x), \tag{2*}$$ so by the closure of $M_x$, $h \in \mathfrak{D}(M_x)$ and $x h_n(x) \overset{L^2}{\rightarrow} x h(x)$, i.e., $g(x) = x h(x)$.  Remembering that $h_n(x) = f_n^{\prime}(x)$ and $h(x) = f^{\prime}(x)$, we have that $f^{\prime}(x) \in \mathfrak{D}(M_x)$, i.e., $f(x) \in \mathfrak{D}(M_x \circ D)$, and $x f_n^{\prime}(x) \overset{L^2}{\rightarrow} x f^{\prime}(x)$.  The closure proof is complete. $\square$ Thus, the problem reduces to proving the claim.  Certainly, for any $\delta > 0$, we can define the bounded measurable function $$\varphi_{\delta}(x) = \begin{cases} \frac{1}{x}, & |x| \geq \delta \\ 0, & |x| < \delta \end{cases},$$ which as a multiplier of course defines a bounded (hence continuous) linear operator on $L^2(\mathbb{R})$, so applying to (2), $$\varphi_{\delta}(x) \cdot x f_n^{\prime}(x) \overset{L^2}{\rightarrow} \varphi_{\delta}(x) g(x). $$ Of course, $\varphi_{\delta}(x) \cdot x $ is the characteristic function $\mathbb{1}_{|x| \geq \delta}(x)$, so $$ \mathbb{1}_{|x| \geq \delta}(x) \cdot f_n^{\prime}(x) \overset{L^2}{\rightarrow} \varphi_{\delta}(x) g(x). \tag{4} $$ Thus, we seem to have two options: (A) show for some small $\delta$ that $\mathbb{1}_{|x| < \delta}(x) f_n^{\prime}(x)$ also converges to some $L^2$ function, (B) carefully take the limit in (4) as $\delta \to 0$. [I regard (B) as nonobvious: clearly as $\delta \to 0$, for each $n$ separately, the left-hand side tends to $f_n^{\prime}(x)$ in $L^2$-norm, but without any uniformity in $n$, it would be difficult.  Certainly, the right-hand-side will get worse as $\delta \to 0$, without an additional observation.]  Here is where I am stuck.","More formally, sticking to the one-dimensional case for this problem, let $M_x$ be the multiplication-by-$x$ operator, $$\begin{split} \mathfrak{D}(M_x) &= \lbrace f(x) \in L^2(\mathbb{R}): x f(x) \in L^2(\mathbb{R}) \rbrace \\ M_x [f](x) &= x f(x) \end{split},$$ and let $D$ be the differentiation-by-$x$ operator $$ \begin{split} \mathfrak{D}(D) & = \lbrace f(x) \in L^2(\mathbb{R}): f^{\prime}(x) \in L^2(\mathbb{R}) \rbrace ( = \mathcal{H}^1(\mathbb{R}))\\ D[f](x) &= f^{\prime}(x) \end{split},$$ where we allow $f^{\prime}(x)$ to be a distributional derivative.  (Of course, thanks to the Fourier Transform $\mathcal{F}$, $$Df(x)  = \mathcal{F}^{-1} \left[i \xi \mathcal{F}[f](\xi) \right](x),$$ perhaps multiplied by a constant depending on the convention on the Fourier Transform.)  Of course, $M_x$ is closed and self-adjoint (e.g., Reed/Simon, Functional Analysis, Chap. VIII, Section 3, Prop. 1), and $D$ is closed by the same reasoning (being a constant multiple of the self-adjoint $i \frac{d}{dx}$). Question: Is $M_x \circ D$ closed on the natural domain, i.e., $ \mathfrak{D}(M_X \circ D) = \lbrace f(x) \in L^2(\mathbb{R}): f^{\prime}(x) \in L^2(\mathbb{R}), xf^{\prime}(x) \in L^2(\mathbb{R}) \rbrace$ ? Note: Of course, replacing $\frac{d}{dx}$ by $i \frac{d}{dx}$ may be simpler to allow self-adjointness, but I prefer to state it in the more elementary way.  Of course, if the proof is easier with $i \frac{d}{dx}$, then please just use that. Work so far: Let us set up a standard closure proof, so suppose that $f_n(x) \in \mathfrak{D}(M_X \circ D)$ and $f(x) \in L^2(\mathbb{R})$ satisfy \begin{align} f_n(x) &\overset{L^2}{\rightarrow} f(x) \tag{1}\\ x f_n^{\prime}(x) &\overset{L^2}{\rightarrow} g(x);  \tag{2} \end{align} we wish to show that $f(x) \in \mathfrak{D}(M_X \circ D)$ and $x f_n^{\prime}(x) \overset{L^2}{\rightarrow} x f^{\prime}(x)$. Claim: It suffices to show that  $$f_n^{\prime}(x) \overset{L^2}{\rightarrow} h(x) \tag{3} $$ for some $L^2$-function $h$. Proof: Suppose that (1), (2), and (3) hold (for some $L^2$ functions $\left(f_n\right)_{n = 1}^{\infty}$, $f$, $g$, and $h$).  By (1), (3), and the closure of $D$, it follows that $f(x) \in \mathfrak{D}(D)$ and $f_n^{\prime}(x) \overset{L^2}{\rightarrow} f^{\prime}(x)$, i.e., $h(x) = f^{\prime}(x)$.  Letting $h_n(x) = f_n^{\prime}(x)$, (3) now reads $$h_n(x) \overset{L^2}{\rightarrow} h(x), \tag{3*}$$ and (2) now reads $$x h_n(x) \overset{L^2}{\rightarrow} g(x), \tag{2*}$$ so by the closure of $M_x$, $h \in \mathfrak{D}(M_x)$ and $x h_n(x) \overset{L^2}{\rightarrow} x h(x)$, i.e., $g(x) = x h(x)$.  Remembering that $h_n(x) = f_n^{\prime}(x)$ and $h(x) = f^{\prime}(x)$, we have that $f^{\prime}(x) \in \mathfrak{D}(M_x)$, i.e., $f(x) \in \mathfrak{D}(M_x \circ D)$, and $x f_n^{\prime}(x) \overset{L^2}{\rightarrow} x f^{\prime}(x)$.  The closure proof is complete. $\square$ Thus, the problem reduces to proving the claim.  Certainly, for any $\delta > 0$, we can define the bounded measurable function $$\varphi_{\delta}(x) = \begin{cases} \frac{1}{x}, & |x| \geq \delta \\ 0, & |x| < \delta \end{cases},$$ which as a multiplier of course defines a bounded (hence continuous) linear operator on $L^2(\mathbb{R})$, so applying to (2), $$\varphi_{\delta}(x) \cdot x f_n^{\prime}(x) \overset{L^2}{\rightarrow} \varphi_{\delta}(x) g(x). $$ Of course, $\varphi_{\delta}(x) \cdot x $ is the characteristic function $\mathbb{1}_{|x| \geq \delta}(x)$, so $$ \mathbb{1}_{|x| \geq \delta}(x) \cdot f_n^{\prime}(x) \overset{L^2}{\rightarrow} \varphi_{\delta}(x) g(x). \tag{4} $$ Thus, we seem to have two options: (A) show for some small $\delta$ that $\mathbb{1}_{|x| < \delta}(x) f_n^{\prime}(x)$ also converges to some $L^2$ function, (B) carefully take the limit in (4) as $\delta \to 0$. [I regard (B) as nonobvious: clearly as $\delta \to 0$, for each $n$ separately, the left-hand side tends to $f_n^{\prime}(x)$ in $L^2$-norm, but without any uniformity in $n$, it would be difficult.  Certainly, the right-hand-side will get worse as $\delta \to 0$, without an additional observation.]  Here is where I am stuck.",,"['functional-analysis', 'operator-theory', 'differential-operators']"
33,Trace term in the Itō formula,Trace term in the Itō formula,,"I'm reading Stochastic Differential Equations in Infinite Dimensions and don't understand what the authors do in Chapter 2.3.1 . Let me introduce the necessary objects: Let $K$ and $H$ be real Hilbert spaces $Q\in\mathfrak L(K)$ be nonnegative and symmetric $K_Q:=Q^{1/2}K$ $(\Omega,\mathcal A,\operatorname P)$ be a probability space $\Phi:\Omega\times[0,\infty)\to\operatorname{HS}(K_Q,H)$ and $\varphi:\Omega\times[0,\infty)\to H$ $F:[0,\infty)\times H\to\mathbb R$ and $F_{xx}$ be the second Fréchet derivative of $F$ with respect to the second variable I don't understand the term $$\operatorname{tr}\left[F_{xx}(t,x)\left(\Phi_tQ^{\frac 12}\right)\left(\Phi_tQ^{\frac 12}\right)^\ast\right]\tag 1$$ which occurs in equation (2.53). By definition, $F_{xx}$ is an element of $\mathfrak L(H,\mathfrak L(H,\mathbb R))$. However, the authors obviously use the fact that $\mathfrak L(H,\mathbb R)\cong H$ and hence $F_{xx}$ can be identified with an element of $\mathfrak L(H)$. With this interpretation, we've got $$\underbrace{F_{xx}(t,x)}_{\in\mathfrak L(H)}\underbrace{\underbrace{\left(\Phi_tQ^{\frac 12}\right)}_{\in\mathfrak L(K_Q,H)}\underbrace{\left(\Phi_tQ^{\frac 12}\right)^\ast}_{\in\mathfrak L(H,K_Q)}}_{\in\mathfrak L(H)}\in\mathfrak L(H)\;.$$ Thus, at least it makes sense to talk about the trace of this expression. However, can we rewrite the expression $(1)$ without the identification? Above $\mathfrak L(A,B)$ and $\operatorname{HS}(A,B)$ denote the space of bounded, linear operators and Hilbert-Schmidt operators from $A$ to $B$, respectively. Moreover, $\mathfrak L(A):=\mathfrak L(A,A)$ and $L^\ast$ denotes the adjoint of a bounded, linear operator $L$.","I'm reading Stochastic Differential Equations in Infinite Dimensions and don't understand what the authors do in Chapter 2.3.1 . Let me introduce the necessary objects: Let $K$ and $H$ be real Hilbert spaces $Q\in\mathfrak L(K)$ be nonnegative and symmetric $K_Q:=Q^{1/2}K$ $(\Omega,\mathcal A,\operatorname P)$ be a probability space $\Phi:\Omega\times[0,\infty)\to\operatorname{HS}(K_Q,H)$ and $\varphi:\Omega\times[0,\infty)\to H$ $F:[0,\infty)\times H\to\mathbb R$ and $F_{xx}$ be the second Fréchet derivative of $F$ with respect to the second variable I don't understand the term $$\operatorname{tr}\left[F_{xx}(t,x)\left(\Phi_tQ^{\frac 12}\right)\left(\Phi_tQ^{\frac 12}\right)^\ast\right]\tag 1$$ which occurs in equation (2.53). By definition, $F_{xx}$ is an element of $\mathfrak L(H,\mathfrak L(H,\mathbb R))$. However, the authors obviously use the fact that $\mathfrak L(H,\mathbb R)\cong H$ and hence $F_{xx}$ can be identified with an element of $\mathfrak L(H)$. With this interpretation, we've got $$\underbrace{F_{xx}(t,x)}_{\in\mathfrak L(H)}\underbrace{\underbrace{\left(\Phi_tQ^{\frac 12}\right)}_{\in\mathfrak L(K_Q,H)}\underbrace{\left(\Phi_tQ^{\frac 12}\right)^\ast}_{\in\mathfrak L(H,K_Q)}}_{\in\mathfrak L(H)}\in\mathfrak L(H)\;.$$ Thus, at least it makes sense to talk about the trace of this expression. However, can we rewrite the expression $(1)$ without the identification? Above $\mathfrak L(A,B)$ and $\operatorname{HS}(A,B)$ denote the space of bounded, linear operators and Hilbert-Schmidt operators from $A$ to $B$, respectively. Moreover, $\mathfrak L(A):=\mathfrak L(A,A)$ and $L^\ast$ denotes the adjoint of a bounded, linear operator $L$.",,"['functional-analysis', 'stochastic-processes', 'operator-theory', 'stochastic-calculus', 'stochastic-analysis']"
34,Application of Hölder's inequality on $\mathbb R^n$,Application of Hölder's inequality on,\mathbb R^n,"Let $1 \leq p < q \leq \infty$ ($p$ and $q$ are not otherwise related). Given $\|x\|_q\leq\|x\|_p $ $\forall$ $ x \in \mathbb R^n$ how can I use Hölder's inequality to show $\|x\|_p\leq n^{\frac{1}{p}-\frac{1}{q}}\|x\|_q$ . I can see this link is a related topic but I could not recognize Hölder's inequality usage in there. Am I missing anything? I am assuming I need to say $\|x\|_p \leq \|x\|_1\leq...$ and here I need to find functions $f$ $g$ such that $\|x\|_1 \leq \|fg\|_1$. Is there a general ""rule of thumb"" for picking functions on these cases?","Let $1 \leq p < q \leq \infty$ ($p$ and $q$ are not otherwise related). Given $\|x\|_q\leq\|x\|_p $ $\forall$ $ x \in \mathbb R^n$ how can I use Hölder's inequality to show $\|x\|_p\leq n^{\frac{1}{p}-\frac{1}{q}}\|x\|_q$ . I can see this link is a related topic but I could not recognize Hölder's inequality usage in there. Am I missing anything? I am assuming I need to say $\|x\|_p \leq \|x\|_1\leq...$ and here I need to find functions $f$ $g$ such that $\|x\|_1 \leq \|fg\|_1$. Is there a general ""rule of thumb"" for picking functions on these cases?",,['functional-analysis']
35,Closed subspaces and weak topology,Closed subspaces and weak topology,,"Let $B$ be a Banach space, and $E$ a closed subspace of $B$. I have a sequence $x_n \in E$ and some $x \in E$. Is it true that  $x_n \to x$ in the weak topology of $E$ if and only if $x_n \to x$ in the weak topology of $B$? To me this seems obvious, I just want to make sure I don't make a basis mistake: Proof $\Rightarrow$ Let $f \in B'$ be a functional. Then the restriction $f|_E \in E'$ and hence  $$ f(x_n)=f|_E(x_n) \to f|_E(x) = f(x)  $$ $\Leftarrow$ Let $f \in E'$. Then By Hahn-Banach we can extend this to $g \in B'$ and then we have $$f(x_n)=g(x_n) \to g(x) =f(x) $$ Is this correct, or am I missing something? P.S. If this is correct, does anyone have a reference for this?","Let $B$ be a Banach space, and $E$ a closed subspace of $B$. I have a sequence $x_n \in E$ and some $x \in E$. Is it true that  $x_n \to x$ in the weak topology of $E$ if and only if $x_n \to x$ in the weak topology of $B$? To me this seems obvious, I just want to make sure I don't make a basis mistake: Proof $\Rightarrow$ Let $f \in B'$ be a functional. Then the restriction $f|_E \in E'$ and hence  $$ f(x_n)=f|_E(x_n) \to f|_E(x) = f(x)  $$ $\Leftarrow$ Let $f \in E'$. Then By Hahn-Banach we can extend this to $g \in B'$ and then we have $$f(x_n)=g(x_n) \to g(x) =f(x) $$ Is this correct, or am I missing something? P.S. If this is correct, does anyone have a reference for this?",,"['functional-analysis', 'weak-convergence']"
36,Linear span in the intersection of Hilbert spaces,Linear span in the intersection of Hilbert spaces,,"Let $V$ be a vector space. Assume $H_1$ and $H_2$ are subspaces of $V$, and that both $H_1$ and $H_2$ are Hilbert spaces with inner-products $\langle \cdot, \cdot\rangle_1$ and $\langle \cdot,\cdot\rangle_2$ respectively. Let $x\in H_1$, and let $\left\{h_n,\,n\in\mathbb{N}\right\}$ be an orthonormal set in $H_1$ (not necessarily a basis) such that $$\big\Vert x - \sum_{k=1}^n\langle x, h_k\rangle_1 h_k\big\Vert_1 \underset{n\rightarrow\infty}\longrightarrow 0,$$ that is, $x$ lies in the closed linear span of $\left\{h_n\right\}$. Assume now that $x\in H_2$ and $\left\{h_n\right\}\subset H_2$. Notice that since $\left\{h_n\right\}$ is orthonormal in $H_1$, it is linearly independent in $H_1$ and hence in $V$ and $H_2$, but not necessarily orthogonal in $H_2$. Let $\left\{e_n,\,n\in\mathbb{N}\right\}$ be an orthonormal set in $H_2$ obtained by a Gram-Schmidt process on $\left\{h_n\right\}$, that is, such that $\mbox{span}\left\{e_1,\dots,e_n\right\} = \mbox{span}\left\{h_1,\dots,h_n\right\}$ for each $n$. Is it true that $$\big\Vert x - \sum_{k=1}^n\langle x, e_k\rangle_2 e_k\big\Vert_2 \underset{n\rightarrow\infty}\longrightarrow 0?$$ Edited In response to user gerw: let me be more specific and maybe we can relate the two norms. Given two probability measures $\mu$ and $\nu$ on $(\mathbb{R},\mathcal{B})$, both equivalent to Lebesgue measure , let $V$ be the vector space of $\mu$-equivalence classes of measurable functions $f:\mathbb{R}\rightarrow\mathbb{R}$ (which is of course equal to the set of $\nu$-equivalence classes of such functions), let $H_1 = L^2(\mu)$ and $H_2 = L^2(\nu)$. Let $T_\mu:L^2(\mu)\rightarrow L^2(\mu)$ be the positive Hilbert-Schmidt operator defined by $$T_\mu f(x) = \int c(x,y) f(y) d\mu(y),\qquad f\in L^2(\mu)$$ where $c$ is a bounded, measurable kernel . Define $T_\nu$ similarly. I am given a certain bounded measurable function $\varphi$ such that both $$\big\Vert \varphi - \sum_{k=1}^n\langle \varphi, h^\mu_k\rangle_1 h^\mu_k\big\Vert_1 \underset{n\rightarrow\infty}\longrightarrow 0\quad \mbox{and} \quad\big\Vert \varphi - \sum_{k=1}^n\langle \varphi, h^\nu_k\rangle_2 h^\nu_k\big\Vert_2 \underset{n\rightarrow\infty}\longrightarrow 0$$ hold, where $\left\{h^\mu_n\right\}$ is the orthonormal set of eigenfunctions of $T_\mu$, and similarly for $\left\{h^\nu_n\right\}$. I'd like to show that $\varphi$ is the $\Vert\cdot\Vert_2$-limit of linear combinations of the $h^\mu_n$. My question can be rephrased as follows: is the $\Vert\cdot\Vert_2$-closure of $\mbox{span}\left\{h_n^\mu\right\}$ equal to the $\Vert\cdot\Vert_2$-closure of $\mbox{span}\left\{h_n^\nu\right\}$?","Let $V$ be a vector space. Assume $H_1$ and $H_2$ are subspaces of $V$, and that both $H_1$ and $H_2$ are Hilbert spaces with inner-products $\langle \cdot, \cdot\rangle_1$ and $\langle \cdot,\cdot\rangle_2$ respectively. Let $x\in H_1$, and let $\left\{h_n,\,n\in\mathbb{N}\right\}$ be an orthonormal set in $H_1$ (not necessarily a basis) such that $$\big\Vert x - \sum_{k=1}^n\langle x, h_k\rangle_1 h_k\big\Vert_1 \underset{n\rightarrow\infty}\longrightarrow 0,$$ that is, $x$ lies in the closed linear span of $\left\{h_n\right\}$. Assume now that $x\in H_2$ and $\left\{h_n\right\}\subset H_2$. Notice that since $\left\{h_n\right\}$ is orthonormal in $H_1$, it is linearly independent in $H_1$ and hence in $V$ and $H_2$, but not necessarily orthogonal in $H_2$. Let $\left\{e_n,\,n\in\mathbb{N}\right\}$ be an orthonormal set in $H_2$ obtained by a Gram-Schmidt process on $\left\{h_n\right\}$, that is, such that $\mbox{span}\left\{e_1,\dots,e_n\right\} = \mbox{span}\left\{h_1,\dots,h_n\right\}$ for each $n$. Is it true that $$\big\Vert x - \sum_{k=1}^n\langle x, e_k\rangle_2 e_k\big\Vert_2 \underset{n\rightarrow\infty}\longrightarrow 0?$$ Edited In response to user gerw: let me be more specific and maybe we can relate the two norms. Given two probability measures $\mu$ and $\nu$ on $(\mathbb{R},\mathcal{B})$, both equivalent to Lebesgue measure , let $V$ be the vector space of $\mu$-equivalence classes of measurable functions $f:\mathbb{R}\rightarrow\mathbb{R}$ (which is of course equal to the set of $\nu$-equivalence classes of such functions), let $H_1 = L^2(\mu)$ and $H_2 = L^2(\nu)$. Let $T_\mu:L^2(\mu)\rightarrow L^2(\mu)$ be the positive Hilbert-Schmidt operator defined by $$T_\mu f(x) = \int c(x,y) f(y) d\mu(y),\qquad f\in L^2(\mu)$$ where $c$ is a bounded, measurable kernel . Define $T_\nu$ similarly. I am given a certain bounded measurable function $\varphi$ such that both $$\big\Vert \varphi - \sum_{k=1}^n\langle \varphi, h^\mu_k\rangle_1 h^\mu_k\big\Vert_1 \underset{n\rightarrow\infty}\longrightarrow 0\quad \mbox{and} \quad\big\Vert \varphi - \sum_{k=1}^n\langle \varphi, h^\nu_k\rangle_2 h^\nu_k\big\Vert_2 \underset{n\rightarrow\infty}\longrightarrow 0$$ hold, where $\left\{h^\mu_n\right\}$ is the orthonormal set of eigenfunctions of $T_\mu$, and similarly for $\left\{h^\nu_n\right\}$. I'd like to show that $\varphi$ is the $\Vert\cdot\Vert_2$-limit of linear combinations of the $h^\mu_n$. My question can be rephrased as follows: is the $\Vert\cdot\Vert_2$-closure of $\mbox{span}\left\{h_n^\mu\right\}$ equal to the $\Vert\cdot\Vert_2$-closure of $\mbox{span}\left\{h_n^\nu\right\}$?",,"['functional-analysis', 'hilbert-spaces']"
37,"A vector $x$ is orthogonal to a set $E$ closed under scalar multiplication if and only if $\operatorname{dist}(x,E)=\|x\|$",A vector  is orthogonal to a set  closed under scalar multiplication if and only if,"x E \operatorname{dist}(x,E)=\|x\|","Let $X$ be an inner product space. Let $E\subset X$ be closed under scalar multiplication and $x \in X$. Then $x \perp E$ if and only if $\operatorname{dist}(x,E)=||x||$. I am able to show the forward part but not able to prove the backward part i.e. $\operatorname{dist}(x,E)=||x|| \implies x \perp E$ Please provide some hints!","Let $X$ be an inner product space. Let $E\subset X$ be closed under scalar multiplication and $x \in X$. Then $x \perp E$ if and only if $\operatorname{dist}(x,E)=||x||$. I am able to show the forward part but not able to prove the backward part i.e. $\operatorname{dist}(x,E)=||x|| \implies x \perp E$ Please provide some hints!",,"['functional-analysis', 'inner-products']"
38,A closed subspace of a separable Hilbert Space is Separable,A closed subspace of a separable Hilbert Space is Separable,,"Suppose $X$ is a Hilbert Space which is separable. Let $Y$ be a closed Subspace of $X$. I need to show that $Y$ is separable. Since $X$ is separable it has a countable dense subset say $M$. Taking the help from the hint suggested, for every $m \in M$, there exists a unique $y$ in $Y$ such that $d(m,Y)=||y-m||$. So I define a map $P:M\to Y$ such that $p(m)=y$ for which  $d(m,Y)=||y-m||$. This is well defined. Now $S=\{p(m)|m \in M\}$. Now I claim that $\bar{S}=Y$. Let $y_0 \in Y$. Let $r \gt 0$.Then since $\bar{M}=X$, there exists $m_0\in M$ such that $||m_0-y_0|| \lt r$. Corresponding to $m_0$, there exists a unique $P(m_0) \in Y$ such that $||m_0-Y||=||m_0-p(m_0)|| \le ||m_0-y_0|| \lt r$. And we are done. Thanks for the help!!","Suppose $X$ is a Hilbert Space which is separable. Let $Y$ be a closed Subspace of $X$. I need to show that $Y$ is separable. Since $X$ is separable it has a countable dense subset say $M$. Taking the help from the hint suggested, for every $m \in M$, there exists a unique $y$ in $Y$ such that $d(m,Y)=||y-m||$. So I define a map $P:M\to Y$ such that $p(m)=y$ for which  $d(m,Y)=||y-m||$. This is well defined. Now $S=\{p(m)|m \in M\}$. Now I claim that $\bar{S}=Y$. Let $y_0 \in Y$. Let $r \gt 0$.Then since $\bar{M}=X$, there exists $m_0\in M$ such that $||m_0-y_0|| \lt r$. Corresponding to $m_0$, there exists a unique $P(m_0) \in Y$ such that $||m_0-Y||=||m_0-p(m_0)|| \le ||m_0-y_0|| \lt r$. And we are done. Thanks for the help!!",,"['functional-analysis', 'hilbert-spaces']"
39,structure theorem for Banach spaces,structure theorem for Banach spaces,,"The following is a theorem in the Banach Algebra Techniques in Operator Theory by Douglas: Here are my questions : Could one come up with some reference (or proof) regarding the remark right after the proof: if $\mathscr{X}$ is separable, then $X$ can be taken into the closed unit interval $[0,1]$? Why does the remark say that the canonical $X$ associated with $\mathscr{X}$ is absent? Isn't it $(\mathscr{X}^*)_1$ (the closed unit ball in $\mathscr{X}^*$)?","The following is a theorem in the Banach Algebra Techniques in Operator Theory by Douglas: Here are my questions : Could one come up with some reference (or proof) regarding the remark right after the proof: if $\mathscr{X}$ is separable, then $X$ can be taken into the closed unit interval $[0,1]$? Why does the remark say that the canonical $X$ associated with $\mathscr{X}$ is absent? Isn't it $(\mathscr{X}^*)_1$ (the closed unit ball in $\mathscr{X}^*$)?",,[]
40,Fractional powers of positive self-adjoint operators,Fractional powers of positive self-adjoint operators,,"Consider two positive unbounded operators $A$ and $B$ densely defined on a Hilbert space $H$ self-adjoint on a domain $\mathcal{D}(A) = \mathcal{D}(B) = H_1$. By the spectral theorem, we can define the fractional powers of $A$ and $B$ as self-adjoint linear operators on $H$. My question is, is $\mathcal{D}(A^{\alpha}) = \mathcal{D}(B^\alpha)$, where $\alpha \in (0, 1)$ necessarily? Is this part of the spectral theorem? If yes, where can I find such a statement?","Consider two positive unbounded operators $A$ and $B$ densely defined on a Hilbert space $H$ self-adjoint on a domain $\mathcal{D}(A) = \mathcal{D}(B) = H_1$. By the spectral theorem, we can define the fractional powers of $A$ and $B$ as self-adjoint linear operators on $H$. My question is, is $\mathcal{D}(A^{\alpha}) = \mathcal{D}(B^\alpha)$, where $\alpha \in (0, 1)$ necessarily? Is this part of the spectral theorem? If yes, where can I find such a statement?",,"['functional-analysis', 'reference-request', 'operator-theory']"
41,An interesting semi-linear PDE problem,An interesting semi-linear PDE problem,,"Assume $u\in H^1(\mathbb{R}^n)$ has compact support, and assume that it is a weak solution of the semi linear equation   $$ -\Delta u+c(u)=f\;\;\text{in}\;\mathbb{R^n} $$   where $f\in L^2(\mathbb{R^n})$ and $c:\mathbb{R}\to\mathbb{R}$ is a smooth function with $c(0)=0$ and $c'\ge 0$. Prove that $u\in H^2(\mathbb{R^n})$. I know exactly how to prove this following the hint in textbook by ""difference quotient"" method. However, my friend told me it can be proved by Fourier transformation and don't assume $c' \ge 0$. Any hint? Thanks!","Assume $u\in H^1(\mathbb{R}^n)$ has compact support, and assume that it is a weak solution of the semi linear equation   $$ -\Delta u+c(u)=f\;\;\text{in}\;\mathbb{R^n} $$   where $f\in L^2(\mathbb{R^n})$ and $c:\mathbb{R}\to\mathbb{R}$ is a smooth function with $c(0)=0$ and $c'\ge 0$. Prove that $u\in H^2(\mathbb{R^n})$. I know exactly how to prove this following the hint in textbook by ""difference quotient"" method. However, my friend told me it can be proved by Fourier transformation and don't assume $c' \ge 0$. Any hint? Thanks!",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
42,amenable groups versus amenable graphs,amenable groups versus amenable graphs,,"In operator algebras, one is often concerned with amenable groups, defined by one of many equivalent conditions. http://en.wikipedia.org/wiki/Amenable_group#Equivalent_conditions_for_amenability In percolation theory and ""random geometry"" one is often concerned with amenable graphs, i.e. those with Cheeger constant $0$. Are these two notions of amenability related?","In operator algebras, one is often concerned with amenable groups, defined by one of many equivalent conditions. http://en.wikipedia.org/wiki/Amenable_group#Equivalent_conditions_for_amenability In percolation theory and ""random geometry"" one is often concerned with amenable graphs, i.e. those with Cheeger constant $0$. Are these two notions of amenability related?",,"['functional-analysis', 'probability-theory', 'graph-theory', 'operator-algebras', 'percolation']"
43,Little $\lambda$-Lipschitz functions,Little -Lipschitz functions,\lambda,"I've read in a few papers that for $\lambda \in (0,1)$ the set of functions given by $$c^{0,\lambda}([0,1]) = \lbrace f:[0,1]\to\mathbb{R}: \lim_{x\to y} \frac{|f(x)-f(y)|}{|x-y|^{\lambda}} = 0 \rbrace $$ is a closed subspace of $$C^{0,\lambda}([0,1]) = \lbrace f:[0,1]\to\mathbb{R} : \sup_{x\neq y} \frac{|f(x)-f(y)|}{|x-y|^{\lambda}} < \infty \rbrace$$ equipped with the norm $\|f\|_{C^{0,\lambda}([0,1])} = \|f\|_{\infty}+\sup_{x\neq y} \frac{|f(x)-f(y)|}{|x-y|^{\lambda}}$. However, I can not find a proof for this. Any help would be greatly appreciated for an explanation!","I've read in a few papers that for $\lambda \in (0,1)$ the set of functions given by $$c^{0,\lambda}([0,1]) = \lbrace f:[0,1]\to\mathbb{R}: \lim_{x\to y} \frac{|f(x)-f(y)|}{|x-y|^{\lambda}} = 0 \rbrace $$ is a closed subspace of $$C^{0,\lambda}([0,1]) = \lbrace f:[0,1]\to\mathbb{R} : \sup_{x\neq y} \frac{|f(x)-f(y)|}{|x-y|^{\lambda}} < \infty \rbrace$$ equipped with the norm $\|f\|_{C^{0,\lambda}([0,1])} = \|f\|_{\infty}+\sup_{x\neq y} \frac{|f(x)-f(y)|}{|x-y|^{\lambda}}$. However, I can not find a proof for this. Any help would be greatly appreciated for an explanation!",,['functional-analysis']
44,"Weakly convergence in $W^{1,p}_0$ and strong convergence in $L^p$",Weakly convergence in  and strong convergence in,"W^{1,p}_0 L^p","I have a bounded sequence $(u_n)$ from $W^{1,p}_0(\Omega)$ that converges weakly to $u\in W^{1,p}_0(\Omega)$ and converges strongly to $u$ in $L^p(\Omega)$. We define a function $f:\Omega\times \mathbb{R}\rightarrow \mathbb{R}$ a bounded Carathéodory function such that $\lim_{s\rightarrow+\infty} f(x,s)=f^{+\infty}(x)$ My question is why $$\lim_{n\rightarrow +\infty} \int_{\Omega}f(x,u_n)(u_n-u) dx=0$$ and $$\lim_{n\rightarrow +\infty}\int_{\Omega} |u_n|^{p-2} u_n(u_n-u) dx=0$$ for the first integral, I'm trying to apply Lebesgue dominated convergence, but I have no idea. For the second integral, when $p=2$ I have no problems, because in this case we have not $|u_n|^{p-2}$ it is equal to 1 and then I just have to do $u_n(u_n-u)=(u_n-u+u)(u_n-u)$ and I use the Cauchy-Schwarz inequality, but when $p$ is not equal to 2, I have no idea. Thank you","I have a bounded sequence $(u_n)$ from $W^{1,p}_0(\Omega)$ that converges weakly to $u\in W^{1,p}_0(\Omega)$ and converges strongly to $u$ in $L^p(\Omega)$. We define a function $f:\Omega\times \mathbb{R}\rightarrow \mathbb{R}$ a bounded Carathéodory function such that $\lim_{s\rightarrow+\infty} f(x,s)=f^{+\infty}(x)$ My question is why $$\lim_{n\rightarrow +\infty} \int_{\Omega}f(x,u_n)(u_n-u) dx=0$$ and $$\lim_{n\rightarrow +\infty}\int_{\Omega} |u_n|^{p-2} u_n(u_n-u) dx=0$$ for the first integral, I'm trying to apply Lebesgue dominated convergence, but I have no idea. For the second integral, when $p=2$ I have no problems, because in this case we have not $|u_n|^{p-2}$ it is equal to 1 and then I just have to do $u_n(u_n-u)=(u_n-u+u)(u_n-u)$ and I use the Cauchy-Schwarz inequality, but when $p$ is not equal to 2, I have no idea. Thank you",,"['analysis', 'functional-analysis', 'lebesgue-integral', 'weak-convergence']"
45,References for hemicontinuity?,References for hemicontinuity?,,"Let $X$ be a real vector space, $K\subset X$ be a nonempty and convex set.  The mapping $f:X\rightarrow\mathbb{R}$ is said to be hemicontinuous if for every $u,v\in K$, the mapping $g(t):[0,1]\rightarrow\mathbb{R}$ given by $g(t)=f(tu+(1-t)v)$ is continuous. I would like to find references and properties for this function. Thank you for all kind help and comments.","Let $X$ be a real vector space, $K\subset X$ be a nonempty and convex set.  The mapping $f:X\rightarrow\mathbb{R}$ is said to be hemicontinuous if for every $u,v\in K$, the mapping $g(t):[0,1]\rightarrow\mathbb{R}$ given by $g(t)=f(tu+(1-t)v)$ is continuous. I would like to find references and properties for this function. Thank you for all kind help and comments.",,"['functional-analysis', 'vector-spaces', 'convex-analysis', 'convex-optimization']"
46,Closed subspace. A Hahn–Banach theorem consequence,Closed subspace. A Hahn–Banach theorem consequence,,"I am trying to prove: If M is a subspace of a normed space $X$, that $\overline{M}=\bigcap\{\ker(\phi):\phi|_{M} = 0 \}$ It is really easy to see that $\overline{M} \subset \bigcap\{\ker(\phi):\phi|_{M} = 0 \}$. However, I don't know how to use the Hahn-Banach theorem to prove the other inclusion.","I am trying to prove: If M is a subspace of a normed space $X$, that $\overline{M}=\bigcap\{\ker(\phi):\phi|_{M} = 0 \}$ It is really easy to see that $\overline{M} \subset \bigcap\{\ker(\phi):\phi|_{M} = 0 \}$. However, I don't know how to use the Hahn-Banach theorem to prove the other inclusion.",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
47,T is not compact operator,T is not compact operator,,"I want to show that if $T$ is a bounded operator between two Hilbert spaces and $T$ is not compact then there exists an orthonormal sequence $y_{n}$ and an $R>0$ such that $\forall n\in \mathbb{N}\,\,\,\|T(y_{n})\|\geq R$. I understand that there exists a sequence $y_{n}\in B[0,1]$ satisfying the above condition (because there exists a sequence doesn't contain any convergent subsequence), but i can't find an orthonormal one","I want to show that if $T$ is a bounded operator between two Hilbert spaces and $T$ is not compact then there exists an orthonormal sequence $y_{n}$ and an $R>0$ such that $\forall n\in \mathbb{N}\,\,\,\|T(y_{n})\|\geq R$. I understand that there exists a sequence $y_{n}\in B[0,1]$ satisfying the above condition (because there exists a sequence doesn't contain any convergent subsequence), but i can't find an orthonormal one",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'compact-operators']"
48,Composition of projections has a fixed point in a Hilbert space,Composition of projections has a fixed point in a Hilbert space,,"Let Let H be a Hilbert space with an  inner product ⟨⋅,⋅⟩ : H×H→R, and induced norm $∥⋅∥ : H→R_+$ Let $C_1$ and $C_2$ be closed, convex, nonempty, disjoint subsets of $H$ with at least one of them compact. And $P_X:H→X$ the metric projection onto X, i.e., $P_X(x):=argmin_{y∈X}∥x−y∥$ for convex compact nonempty subsets of H and $x \in H$. Let $P: C_1 → C_1$ be given by $P(x) = (P_{C_1} \circ P_{C_2})(x) $ for $x \in C_1$ I want to prove the following: Let $x \in C_1$ fixed, then the succession $(P^n(x))^{\infty}_{n=1}$ converges to a fixed point. I tried (unsuccessfully) to prove that it $(P^n(x))^{\infty}_{n=1}$ is a Cauchy succession and so it converges to a point in $C_1$, I know that $P_x$ is firmly non-expansive i.e. $\left\| P_X(x) - P_X(y) \right\|^2 \leq \langle x-y, P_X(x) - P_X(y) \rangle$ and hence non-expansive i.e. $\left\| P_X(x) - P_X(y) \right\|^2 \leq \left\| x-y\right\|^2$ I also proved previously that if x is a fixed point of P then x minimizes the distance between $C_1$ and $C_2$. I also tried to prove that $P(x)$ strictly metric i.e. the inequality is strict for every two different points.  So I could use some modification of the contraction mapping theorem. I also believe that P is continuous, because it is a composition of continuous functions, and so there exist a fixed point (either $C_1$ or $C_2$ is compact and convex). Also I've read that any non-expansive function from a closed convex bounded set onto itself has at least one  fixed point. However, how can I prove that  $(P^n(x))^{\infty}_{n=1}$ converges to a fixed point? Any advice would be greatly appreciated. I really think that the key is to prove that  $(P^n(x))^{\infty}_{n=1}$ is Cauchy, however I haven't been able to prove that.","Let Let H be a Hilbert space with an  inner product ⟨⋅,⋅⟩ : H×H→R, and induced norm $∥⋅∥ : H→R_+$ Let $C_1$ and $C_2$ be closed, convex, nonempty, disjoint subsets of $H$ with at least one of them compact. And $P_X:H→X$ the metric projection onto X, i.e., $P_X(x):=argmin_{y∈X}∥x−y∥$ for convex compact nonempty subsets of H and $x \in H$. Let $P: C_1 → C_1$ be given by $P(x) = (P_{C_1} \circ P_{C_2})(x) $ for $x \in C_1$ I want to prove the following: Let $x \in C_1$ fixed, then the succession $(P^n(x))^{\infty}_{n=1}$ converges to a fixed point. I tried (unsuccessfully) to prove that it $(P^n(x))^{\infty}_{n=1}$ is a Cauchy succession and so it converges to a point in $C_1$, I know that $P_x$ is firmly non-expansive i.e. $\left\| P_X(x) - P_X(y) \right\|^2 \leq \langle x-y, P_X(x) - P_X(y) \rangle$ and hence non-expansive i.e. $\left\| P_X(x) - P_X(y) \right\|^2 \leq \left\| x-y\right\|^2$ I also proved previously that if x is a fixed point of P then x minimizes the distance between $C_1$ and $C_2$. I also tried to prove that $P(x)$ strictly metric i.e. the inequality is strict for every two different points.  So I could use some modification of the contraction mapping theorem. I also believe that P is continuous, because it is a composition of continuous functions, and so there exist a fixed point (either $C_1$ or $C_2$ is compact and convex). Also I've read that any non-expansive function from a closed convex bounded set onto itself has at least one  fixed point. However, how can I prove that  $(P^n(x))^{\infty}_{n=1}$ converges to a fixed point? Any advice would be greatly appreciated. I really think that the key is to prove that  $(P^n(x))^{\infty}_{n=1}$ is Cauchy, however I haven't been able to prove that.",,"['functional-analysis', 'operator-theory', 'convex-analysis', 'hilbert-spaces', 'fixed-point-theorems']"
49,Existence of integral equation solution,Existence of integral equation solution,,"I am trying to prove a differentiable solution in some open interval about the origin for the equation: $$u(x) + u(x)^2 + \int_0^x (1+\cos(x+u(y))) dy = 0$$ I have been trying to prove it as a contraction on some specifically suited Banach space of continuous functions, but it's not working out like I need it to. I'm uncomfortable with the $u(x)^2$ term, but am currently treating this like a linear Volterra integral equation. My question is if there is a better approach to nonlinear terms of the function, e..g $u(x)^2$?","I am trying to prove a differentiable solution in some open interval about the origin for the equation: $$u(x) + u(x)^2 + \int_0^x (1+\cos(x+u(y))) dy = 0$$ I have been trying to prove it as a contraction on some specifically suited Banach space of continuous functions, but it's not working out like I need it to. I'm uncomfortable with the $u(x)^2$ term, but am currently treating this like a linear Volterra integral equation. My question is if there is a better approach to nonlinear terms of the function, e..g $u(x)^2$?",,"['functional-analysis', 'integral-equations']"
50,"Show that $C^1([0,1])$ is not reflexive",Show that  is not reflexive,"C^1([0,1])","Aim of this exercise is proving that $(C^1([0,1]),\|\cdot\|_{C^1})$ is not reflexive. We know that, if $(f_h)_h\subset C^1([0,1])$ is a sequence that weakly converges to $f\in C^1([0,1])$ (that is $f_h \rightharpoonup f$),then $(f_h)_h$ and $(f'_h)_h$ pointwise converge to, respectively, $f$ and $f'$  $(*)$. Now, let $f_h(x)=\frac{x^h}{h}$, for $x\in[0,1]$. From $(*)$ it follows that $f_h(x)$ does not weakly converges in $C^1([0,1])$, because $f'_h=x^{h-1}$ pointwise converges to a discontinuous function. From this we want to conclude that $(C^1([0,1]),\|\cdot\|_{C^1})$ is not reflexive arguing by contraposition. So, suppose that $(C^1([0,1]),\|\cdot\|_{C^1})$ is reflexive. Then the unit closed ball $B$ is sequentially weakly compact. Now, to reach the absurd, I guess I have to use the sequence $(f_h)$ where $f_h=\frac{x^h}{h}$, but $\|f_h\|_{C^1}=1/h+1>1$. So, what I have to do?","Aim of this exercise is proving that $(C^1([0,1]),\|\cdot\|_{C^1})$ is not reflexive. We know that, if $(f_h)_h\subset C^1([0,1])$ is a sequence that weakly converges to $f\in C^1([0,1])$ (that is $f_h \rightharpoonup f$),then $(f_h)_h$ and $(f'_h)_h$ pointwise converge to, respectively, $f$ and $f'$  $(*)$. Now, let $f_h(x)=\frac{x^h}{h}$, for $x\in[0,1]$. From $(*)$ it follows that $f_h(x)$ does not weakly converges in $C^1([0,1])$, because $f'_h=x^{h-1}$ pointwise converges to a discontinuous function. From this we want to conclude that $(C^1([0,1]),\|\cdot\|_{C^1})$ is not reflexive arguing by contraposition. So, suppose that $(C^1([0,1]),\|\cdot\|_{C^1})$ is reflexive. Then the unit closed ball $B$ is sequentially weakly compact. Now, to reach the absurd, I guess I have to use the sequence $(f_h)$ where $f_h=\frac{x^h}{h}$, but $\|f_h\|_{C^1}=1/h+1>1$. So, what I have to do?",,"['functional-analysis', 'convergence-divergence', 'banach-spaces', 'weak-convergence']"
51,"$\widehat{f\ast g}= \hat{f} \cdot \hat{g}$ for $f, \hat{f} \in L^{p}(\mathbb R)\cap C(\mathbb R) (1<p<\infty, p\neq 2), g\in \mathcal{S}(\mathbb R)$?",for ?,"\widehat{f\ast g}= \hat{f} \cdot \hat{g} f, \hat{f} \in L^{p}(\mathbb R)\cap C(\mathbb R) (1<p<\infty, p\neq 2), g\in \mathcal{S}(\mathbb R)","It is well-known that, for $f,g \in L^{1}(\mathbb R).$ Then, by Fubini's theorem, one can derive, $\widehat{f\ast g} = \hat{f} \cdot \hat{g},$ (that is, Fourier transform takes, convolution to point wise multiplication). Also, we note that the fact, that, for $f, g\in L^{2}(\mathbb R)$ one has, $\widehat{f\ast g} =\hat{f} \cdot \hat{g}.$ Suppose $f, \hat{f} \in L^{p}(\mathbb R)\cap C(\mathbb R) (1<p<\infty, p\neq 2),$ and $g\in \mathcal{S}(\mathbb R),$ (Schwartz space) My Question is : Can we expect, $\widehat{f\ast g}= \hat{f} \cdot \hat{g}$ ? If yes, how to prove it ? Edited :(with hope may be this is helpful). For $f\in L^{1}(\mathbb R), $ we define $f^{\vee}(x):=\hat{f}(-x)=\int_{\mathbb R} f(\xi) e^{2\pi i \xi\cdot x} d\xi, (x\in \mathbb R).$ Let $f, g\in L^{2}(\mathbb R).$ Then $\hat{f}\hat{g}\in L^{1},$ by Plancherel's theorem and H\""olders inequality, so $(\hat{f}\hat{g})^{\vee}$ make sense. Given $x\in \mathbb R,$ let $h(y)=\overline{g(x-y)}.$ It is easy to see that, $\hat{h}(\xi)=\overline{\hat{g}(\xi)}e^{-2\pi i\xi \cdot x},$ so since $\mathcal{F}$ is unitary on $L^{2},$ $$f\ast g (x)= \int f\bar{h}= \int \hat{f}\bar{\hat{h}}=\int \hat{f}(\xi)\hat{g}(\xi)e^{2\pi i \xi \cdot x} d\xi =(\hat{f}\hat{g})^{\vee}(x).$$ Thanks,","It is well-known that, for $f,g \in L^{1}(\mathbb R).$ Then, by Fubini's theorem, one can derive, $\widehat{f\ast g} = \hat{f} \cdot \hat{g},$ (that is, Fourier transform takes, convolution to point wise multiplication). Also, we note that the fact, that, for $f, g\in L^{2}(\mathbb R)$ one has, $\widehat{f\ast g} =\hat{f} \cdot \hat{g}.$ Suppose $f, \hat{f} \in L^{p}(\mathbb R)\cap C(\mathbb R) (1<p<\infty, p\neq 2),$ and $g\in \mathcal{S}(\mathbb R),$ (Schwartz space) My Question is : Can we expect, $\widehat{f\ast g}= \hat{f} \cdot \hat{g}$ ? If yes, how to prove it ? Edited :(with hope may be this is helpful). For $f\in L^{1}(\mathbb R), $ we define $f^{\vee}(x):=\hat{f}(-x)=\int_{\mathbb R} f(\xi) e^{2\pi i \xi\cdot x} d\xi, (x\in \mathbb R).$ Let $f, g\in L^{2}(\mathbb R).$ Then $\hat{f}\hat{g}\in L^{1},$ by Plancherel's theorem and H\""olders inequality, so $(\hat{f}\hat{g})^{\vee}$ make sense. Given $x\in \mathbb R,$ let $h(y)=\overline{g(x-y)}.$ It is easy to see that, $\hat{h}(\xi)=\overline{\hat{g}(\xi)}e^{-2\pi i\xi \cdot x},$ so since $\mathcal{F}$ is unitary on $L^{2},$ $$f\ast g (x)= \int f\bar{h}= \int \hat{f}\bar{\hat{h}}=\int \hat{f}(\xi)\hat{g}(\xi)e^{2\pi i \xi \cdot x} d\xi =(\hat{f}\hat{g})^{\vee}(x).$$ Thanks,",,"['analysis', 'functional-analysis', 'fourier-analysis', 'lp-spaces', 'harmonic-analysis']"
52,Compact operator on invariant subspace is compact,Compact operator on invariant subspace is compact,,"Statement: Let $T \in \mathscr{B}(\mathscr{H})$, where $T$ is a compact operator. Let $M$ be a closed invariant subspace of $T$. Show that the restriction of $T$ to $M$ is compact. Attempted Proof: Let $\{m_n\}_{n=1}^{\infty}$ be a bounded sequence in $M$. Since $T$ is compact it contains a convergent subsequence $T(m_{n_k}) \rightarrow \mu$. Now since $M$ is closed and invariant under $T$ it contains all of its limit points, so $\mu \in M$. Hence we are compact. Q.E.D.","Statement: Let $T \in \mathscr{B}(\mathscr{H})$, where $T$ is a compact operator. Let $M$ be a closed invariant subspace of $T$. Show that the restriction of $T$ to $M$ is compact. Attempted Proof: Let $\{m_n\}_{n=1}^{\infty}$ be a bounded sequence in $M$. Since $T$ is compact it contains a convergent subsequence $T(m_{n_k}) \rightarrow \mu$. Now since $M$ is closed and invariant under $T$ it contains all of its limit points, so $\mu \in M$. Hence we are compact. Q.E.D.",,"['analysis', 'functional-analysis', 'proof-verification', 'operator-theory', 'hilbert-spaces']"
53,Is the Neumann series a compact operator?,Is the Neumann series a compact operator?,,"Let $X$ be an infinite dimensional Banach space and $A:X\to X$ be a compact operator with the operator norm $\|A\|<1$. Then $I-A$ is invertible and the Neumann series  $$ S_N = \sum_{k=0}^N A^k $$ converges in the operator norm to $(I-A)^{-1}$: $$ \|S_N-(I-A)^{-1}\| \to 0, \ \text{ as } \ N\to \infty $$ Now I think all $S_N$ are compact operators hence the limit $(I-A)^{-1}$ is also compact. However this cannot be the case because then $$ I=(I-A)(I-A)^{-1} $$ would be compact, which is not possible for infinite dimension $X$. What is wrong in my argument?","Let $X$ be an infinite dimensional Banach space and $A:X\to X$ be a compact operator with the operator norm $\|A\|<1$. Then $I-A$ is invertible and the Neumann series  $$ S_N = \sum_{k=0}^N A^k $$ converges in the operator norm to $(I-A)^{-1}$: $$ \|S_N-(I-A)^{-1}\| \to 0, \ \text{ as } \ N\to \infty $$ Now I think all $S_N$ are compact operators hence the limit $(I-A)^{-1}$ is also compact. However this cannot be the case because then $$ I=(I-A)(I-A)^{-1} $$ would be compact, which is not possible for infinite dimension $X$. What is wrong in my argument?",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'compact-operators']"
54,How to determine measure from the integral equation?,How to determine measure from the integral equation?,,"Let $\{c_{n}\}_{n\in \mathbb Z}\subset \mathbb C$  and $\sum_{n\in \mathbb Z} |c_{n}| < \infty$ (that is, the series $\sum c_{n}$ is absolutely  converges); we define $F:\mathbb R \to \mathbb C$ such that  $F(y)= \sum_{n\in \mathbb Z}( c_{n}\cdot e^{iny})$, $(y\in \mathbb R).$ Suppose there exists bounded complex Borel measure on $\mathbb R$ such that $$F(y)= \int_{\mathbb R} e^{-iyx} d\mu(x);  \  (y\in \mathbb R).$$ My Questions : (1) What can we say about $\mu$ ?    (2) Can we expect to determine $\mu$  just from the above information; or we need to have some more information to determine $\mu$ ?  Can you suggests some method to determine $\mu$ in such a situation ? Thanks,","Let $\{c_{n}\}_{n\in \mathbb Z}\subset \mathbb C$  and $\sum_{n\in \mathbb Z} |c_{n}| < \infty$ (that is, the series $\sum c_{n}$ is absolutely  converges); we define $F:\mathbb R \to \mathbb C$ such that  $F(y)= \sum_{n\in \mathbb Z}( c_{n}\cdot e^{iny})$, $(y\in \mathbb R).$ Suppose there exists bounded complex Borel measure on $\mathbb R$ such that $$F(y)= \int_{\mathbb R} e^{-iyx} d\mu(x);  \  (y\in \mathbb R).$$ My Questions : (1) What can we say about $\mu$ ?    (2) Can we expect to determine $\mu$  just from the above information; or we need to have some more information to determine $\mu$ ?  Can you suggests some method to determine $\mu$ in such a situation ? Thanks,",,"['analysis', 'functional-analysis', 'measure-theory', 'fourier-analysis', 'harmonic-analysis']"
55,How to find formal adjoint operators for operators $\Gamma(E) \to \Gamma(T^*M \otimes E)$,How to find formal adjoint operators for operators,\Gamma(E) \to \Gamma(T^*M \otimes E),"Let $(M,g)$ be a Riemannian manifold and let $E \to M$ be a real vector bundle over $M$. Let $d_A = d+A$ be a covariant derivative on $E$. It is an $\mathbb R$-linear map $d_A \colon \Gamma(E) \to \Gamma(T^*M \otimes E)$. Then the formal adjoint map $d_A^*$ acts from $\Gamma(T^*M \otimes E^*)$ to $\Gamma(E^*)$. But how to find explicitely this map? I know the answer but I don't know how to obtain it. If we had $\Gamma(T^*M \otimes E^*) \cong \Gamma(T^*M \otimes E)$ and $\Gamma(E^*) \cong \Gamma(E)$ and if we had scalar products defined on these two spaces then I could obtain the answer starting from the formula $\langle d_A s, \omega \rangle = \langle s, d_A^* \omega \rangle$, where $s \in \Gamma(E)$, $\omega \in \Gamma(T^*M \otimes E)$ and $\langle \cdot , \cdot \rangle$ are corresponding scalar products, but it's not so clear for me what to do in the case when we have no scalar products in these spaces. I think that we need to give some sense to $\langle \cdot, \cdot \rangle$. Given $(s,v) \in \Gamma(E) \times\Gamma(E^*)$ we can define $\bigl(v(s)\bigr)_x = v_x(s_x)$ to be a $C^\infty$-function on $M$ so we can define $\langle s, v \rangle = \langle v(s) \rangle_{L_2(M)}$. On the other hand, given $(\omega \otimes s, \eta \otimes v) \in \Gamma(T^*M \otimes E) \times \Gamma(T^* M \otimes E^*)$ (locally)  we can define $\langle \omega \otimes s, \eta \otimes v\rangle = \int_M v(s) \omega \wedge *\eta$ and using these two expressions for $\langle \cdot , \cdot \rangle$ we can find formal adjoints as in the case of scalar product spaces. But are these considerations correct or there is some other way to find formal adjoint to $d_A$?","Let $(M,g)$ be a Riemannian manifold and let $E \to M$ be a real vector bundle over $M$. Let $d_A = d+A$ be a covariant derivative on $E$. It is an $\mathbb R$-linear map $d_A \colon \Gamma(E) \to \Gamma(T^*M \otimes E)$. Then the formal adjoint map $d_A^*$ acts from $\Gamma(T^*M \otimes E^*)$ to $\Gamma(E^*)$. But how to find explicitely this map? I know the answer but I don't know how to obtain it. If we had $\Gamma(T^*M \otimes E^*) \cong \Gamma(T^*M \otimes E)$ and $\Gamma(E^*) \cong \Gamma(E)$ and if we had scalar products defined on these two spaces then I could obtain the answer starting from the formula $\langle d_A s, \omega \rangle = \langle s, d_A^* \omega \rangle$, where $s \in \Gamma(E)$, $\omega \in \Gamma(T^*M \otimes E)$ and $\langle \cdot , \cdot \rangle$ are corresponding scalar products, but it's not so clear for me what to do in the case when we have no scalar products in these spaces. I think that we need to give some sense to $\langle \cdot, \cdot \rangle$. Given $(s,v) \in \Gamma(E) \times\Gamma(E^*)$ we can define $\bigl(v(s)\bigr)_x = v_x(s_x)$ to be a $C^\infty$-function on $M$ so we can define $\langle s, v \rangle = \langle v(s) \rangle_{L_2(M)}$. On the other hand, given $(\omega \otimes s, \eta \otimes v) \in \Gamma(T^*M \otimes E) \times \Gamma(T^* M \otimes E^*)$ (locally)  we can define $\langle \omega \otimes s, \eta \otimes v\rangle = \int_M v(s) \omega \wedge *\eta$ and using these two expressions for $\langle \cdot , \cdot \rangle$ we can find formal adjoints as in the case of scalar product spaces. But are these considerations correct or there is some other way to find formal adjoint to $d_A$?",,"['functional-analysis', 'riemannian-geometry', 'vector-bundles', 'adjoint-operators']"
56,"What ""standard estimates for the laplacian"" do the authors of this paper mean?","What ""standard estimates for the laplacian"" do the authors of this paper mean?",,"I am trying to follow the proof of lemma 2.1 in this paper. The setup. Consider a solution $v$ to the nonlinear equation $$ -\Delta v = ic \partial_1 v + v(1-\vert v\vert^2) ~\mbox{on}~ \mathbb{R}^N$$ with finite energy, i.e., $$\Vert Dv \Vert_{L^2(\mathbb{R}^N)}+ \Vert 1-\vert v \vert^2 \Vert_{L^2(\mathbb{R}^N)} < \infty. $$ Here, $c$ is a real constant and $i$ the imaginary unit. The question. The authors want to prove the following statement. There is a constant $K(c,k,N)>0$ such that $\Vert v \Vert_{C^k(\mathbb{R}^N)} \leq K(c,k,N), \forall k \in \mathbb{R}.$ All they say is: ""One invokes standard estimates for the laplacian"". What standard estimates do they mean? What, precisely, is the argument here? More information. I don't know if this helps, but from the first part of the lemma in the paper, we already know the following: $\Vert 1 - \vert v \vert \Vert_{L^\infty(\mathbb{R}^N)} \leq \max \lbrace 1, \frac{c}{2} \rbrace$ $\Vert \nabla v \Vert_{L^\infty(\mathbb{R}^N)} \leq K(N) \left( 1+ \frac{c^2}{4} \right)^{\frac{3}{2}}$ v is smooth and bounded. Any help is much appreciated!","I am trying to follow the proof of lemma 2.1 in this paper. The setup. Consider a solution $v$ to the nonlinear equation $$ -\Delta v = ic \partial_1 v + v(1-\vert v\vert^2) ~\mbox{on}~ \mathbb{R}^N$$ with finite energy, i.e., $$\Vert Dv \Vert_{L^2(\mathbb{R}^N)}+ \Vert 1-\vert v \vert^2 \Vert_{L^2(\mathbb{R}^N)} < \infty. $$ Here, $c$ is a real constant and $i$ the imaginary unit. The question. The authors want to prove the following statement. There is a constant $K(c,k,N)>0$ such that $\Vert v \Vert_{C^k(\mathbb{R}^N)} \leq K(c,k,N), \forall k \in \mathbb{R}.$ All they say is: ""One invokes standard estimates for the laplacian"". What standard estimates do they mean? What, precisely, is the argument here? More information. I don't know if this helps, but from the first part of the lemma in the paper, we already know the following: $\Vert 1 - \vert v \vert \Vert_{L^\infty(\mathbb{R}^N)} \leq \max \lbrace 1, \frac{c}{2} \rbrace$ $\Vert \nabla v \Vert_{L^\infty(\mathbb{R}^N)} \leq K(N) \left( 1+ \frac{c^2}{4} \right)^{\frac{3}{2}}$ v is smooth and bounded. Any help is much appreciated!",,"['functional-analysis', 'partial-differential-equations']"
57,"What is the closure of the Laplacian on $L^2(0, \infty)$ with domain $D(\Delta):=C^\infty_0(0, \infty)$?",What is the closure of the Laplacian on  with domain ?,"L^2(0, \infty) D(\Delta):=C^\infty_0(0, \infty)","Let $\Delta$ be the operator on $L^2(0, \infty)$ defined as follows: $\Delta \phi:= \phi''$, with domain $D(\Delta):=C^\infty_0(0, \infty)$. Is $\Delta$ closed or closable? In the case, what is its closure?","Let $\Delta$ be the operator on $L^2(0, \infty)$ defined as follows: $\Delta \phi:= \phi''$, with domain $D(\Delta):=C^\infty_0(0, \infty)$. Is $\Delta$ closed or closable? In the case, what is its closure?",,['functional-analysis']
58,Almost Everywhere pointwise limit measurable functions measurable?,Almost Everywhere pointwise limit measurable functions measurable?,,"I'm having difficulties verifying a remark in Raymond Ryan's treatment of the Bochner Integral. $\bf{\text{Remark:}}$ If $\mu$ is $\sigma$-finite, and $(f_{n})_{n=1}^{\infty}$ is a sequence of $\mu$-measurable functions which converges to $f$ almost everywhere, then $f$ is $\mu$-measurable. $\bf{\text{Edit:}}$ At this point I am currently looking for an authoritative answer on what the hypothesis of this remark should be, given the comments below. $\bf{\text{Background:}}$ Let $(\Omega,\Sigma,\mu)$ be a $\sigma$-finite measure space, and $X$ be a Banach space. A function $f:\Omega\to X$ is simple if it assumes only finitely many values.  That is, there exists subsets $E_{1}, ... , E_{n}$ of $\Omega$ and scalars $x_{1}, ... , x_{n}\in X$ such that $f = \sum_{i=1}^{n}\chi_{E_{i}}x_{i}$. If the sets $E_{i}$ can be chosen from $\Sigma$, then $f$ is $\mu$-measurable simple. A function $f:\Omega\to X$ is $\mu$-measurable if it is the limit of a sequence of $\mu$-measurable simple functions (almost everywhere). A function $f:\Omega\to X$ is $\mu$-essentially separately valued if there exists $E\in \Sigma$ such that $\mu(\Omega\backslash E) = 0$ and $f(E)\subset Y$ for some separable subspace $Y$ of $X$. These are the immediately preceding results (which may or may not be useful). $\bf{\text{Lemma:}}$  Let $\mu$ be $\sigma$-finite.  $f:\Omega\to X$ is $\mu$-measurable if and only if $\chi_{E}f$ is $\mu$-measurable for every $E\in \Sigma$, $\mu(E) < \infty$. Proof (My previous question): Fact about measurable functions defined on $\sigma$-finite measure spaces. $\bf{\text{(Pettis Measurability Theorem)}}$  Let $\mu$ be a $\sigma$-finite measure.  The following are equivalent for $f:\Omega\to X$. (i) $f$ is $\mu$-measurable. (ii) $f$ is weakly $\mu$-measurable and $\mu$-essentially separately valued. (iii) $f$ is Borel measurable and $\mu$-essentially separately valued. Sorry for not having much of a start yet.  My ideas consisted of trying to adapt the solution given as an answer to my previous question: Fact about measurable functions defined on $\sigma$-finite measure spaces. but sadly went nowhere.  I'm just looking for a hint not a full solution if possible. $\bf{\text{Regarding My Issues Below:}}$ In Norbert's proof: Case (1): The functions $f_{n}$ are each $\mu$-measurable simple as they can be written as $f_{n} = \chi_{\phi}$ and $\phi\in\Sigma$.  Since $f_{n}\to\chi_{F}$ at every point outside of $F$, then by definition, $\chi_{F}$ is $\mu$-measurable.  So I don't think a contradiction exists here. Case (2): Before completeness is invoked, we have that since $f_{n}$ is $\mu$-measurable, $x^{*}\circ f_{n}$ is a $\mu$-measurable scalar valued function on $E$ for every $x^{*}\in X^{*}$.  Therefore it is concluded that $x^{*}\circ f$ is a $\mu$-measurable scalar valued function on $E$ for every $x^{*}\in X^{*}$.  I cannot manage to prove the details on this last step; it seems to actually require the remark which is to be proved? $\bf{\text{Follow Up:}}$  I think I have found the heart of the matter, which I have posted as a separate question: Contradiction achieved with the Pettis Measurability Theorem?","I'm having difficulties verifying a remark in Raymond Ryan's treatment of the Bochner Integral. $\bf{\text{Remark:}}$ If $\mu$ is $\sigma$-finite, and $(f_{n})_{n=1}^{\infty}$ is a sequence of $\mu$-measurable functions which converges to $f$ almost everywhere, then $f$ is $\mu$-measurable. $\bf{\text{Edit:}}$ At this point I am currently looking for an authoritative answer on what the hypothesis of this remark should be, given the comments below. $\bf{\text{Background:}}$ Let $(\Omega,\Sigma,\mu)$ be a $\sigma$-finite measure space, and $X$ be a Banach space. A function $f:\Omega\to X$ is simple if it assumes only finitely many values.  That is, there exists subsets $E_{1}, ... , E_{n}$ of $\Omega$ and scalars $x_{1}, ... , x_{n}\in X$ such that $f = \sum_{i=1}^{n}\chi_{E_{i}}x_{i}$. If the sets $E_{i}$ can be chosen from $\Sigma$, then $f$ is $\mu$-measurable simple. A function $f:\Omega\to X$ is $\mu$-measurable if it is the limit of a sequence of $\mu$-measurable simple functions (almost everywhere). A function $f:\Omega\to X$ is $\mu$-essentially separately valued if there exists $E\in \Sigma$ such that $\mu(\Omega\backslash E) = 0$ and $f(E)\subset Y$ for some separable subspace $Y$ of $X$. These are the immediately preceding results (which may or may not be useful). $\bf{\text{Lemma:}}$  Let $\mu$ be $\sigma$-finite.  $f:\Omega\to X$ is $\mu$-measurable if and only if $\chi_{E}f$ is $\mu$-measurable for every $E\in \Sigma$, $\mu(E) < \infty$. Proof (My previous question): Fact about measurable functions defined on $\sigma$-finite measure spaces. $\bf{\text{(Pettis Measurability Theorem)}}$  Let $\mu$ be a $\sigma$-finite measure.  The following are equivalent for $f:\Omega\to X$. (i) $f$ is $\mu$-measurable. (ii) $f$ is weakly $\mu$-measurable and $\mu$-essentially separately valued. (iii) $f$ is Borel measurable and $\mu$-essentially separately valued. Sorry for not having much of a start yet.  My ideas consisted of trying to adapt the solution given as an answer to my previous question: Fact about measurable functions defined on $\sigma$-finite measure spaces. but sadly went nowhere.  I'm just looking for a hint not a full solution if possible. $\bf{\text{Regarding My Issues Below:}}$ In Norbert's proof: Case (1): The functions $f_{n}$ are each $\mu$-measurable simple as they can be written as $f_{n} = \chi_{\phi}$ and $\phi\in\Sigma$.  Since $f_{n}\to\chi_{F}$ at every point outside of $F$, then by definition, $\chi_{F}$ is $\mu$-measurable.  So I don't think a contradiction exists here. Case (2): Before completeness is invoked, we have that since $f_{n}$ is $\mu$-measurable, $x^{*}\circ f_{n}$ is a $\mu$-measurable scalar valued function on $E$ for every $x^{*}\in X^{*}$.  Therefore it is concluded that $x^{*}\circ f$ is a $\mu$-measurable scalar valued function on $E$ for every $x^{*}\in X^{*}$.  I cannot manage to prove the details on this last step; it seems to actually require the remark which is to be proved? $\bf{\text{Follow Up:}}$  I think I have found the heart of the matter, which I have posted as a separate question: Contradiction achieved with the Pettis Measurability Theorem?",,"['functional-analysis', 'measure-theory']"
59,definition of the Fourier transform of function on the sphere,definition of the Fourier transform of function on the sphere,,Let $f: S^{n-1}\longrightarrow R^n$ be  even continuous function. What is the Fourier transform of $f$?,Let $f: S^{n-1}\longrightarrow R^n$ be  even continuous function. What is the Fourier transform of $f$?,,"['functional-analysis', 'fourier-analysis', 'definition', 'spherical-harmonics']"
60,Cyclic vectors of an irreducible representation of a C*-algebra,Cyclic vectors of an irreducible representation of a C*-algebra,,"Let $\mathcal{A}$ be a C*-algebra and $(H,\pi)$ an irreducible representation of $\mathcal{A}$. I want to prove the statement:  all $\xi \in H$ are cyclic or $\pi(\mathcal{A})=\{0\}$ and $H=\mathbb{C}$. How can one approach this problem? Suppose there is a $\hat{\xi}\in H$ that is not cyclic, then $\{a\hat\xi:a\in \pi(\mathcal{A})\}$ is not dense in H, i.e. $\{a\hat\xi:a\in \pi(\mathcal{A})\}^{\perp}\neq \{0\}$. From here on, I don't know how to conclude that $\pi(\mathcal{A})=\{0\}$ and $H=\mathbb{C}$.","Let $\mathcal{A}$ be a C*-algebra and $(H,\pi)$ an irreducible representation of $\mathcal{A}$. I want to prove the statement:  all $\xi \in H$ are cyclic or $\pi(\mathcal{A})=\{0\}$ and $H=\mathbb{C}$. How can one approach this problem? Suppose there is a $\hat{\xi}\in H$ that is not cyclic, then $\{a\hat\xi:a\in \pi(\mathcal{A})\}$ is not dense in H, i.e. $\{a\hat\xi:a\in \pi(\mathcal{A})\}^{\perp}\neq \{0\}$. From here on, I don't know how to conclude that $\pi(\mathcal{A})=\{0\}$ and $H=\mathbb{C}$.",,"['functional-analysis', 'representation-theory', 'operator-algebras', 'c-star-algebras']"
61,How does the Hahn-Banach theorem implies the existence of weak solution?,How does the Hahn-Banach theorem implies the existence of weak solution?,,"I came across the following question when I read chapter 17 of Hormander's book ""Tha Analysis of Linear Partial Differential Operators"", and the theorem is Let $a_{jk}(x)$ be Lipschitz continuous in an open set $X\subset\mathbb{R}^n$, $a_{ij}=a_{ji}$, and assume that $(\Re a_{ij}(x))$ is positive definite.  Then $$ \sum_{ij} D_j(a_{jk}D_ku)=f $$ has a solution $u\in H_{(2)}^{loc}(X)$ for every $f\in L_{loc}^2(X)$ The auther then says if we can show that  $$ |(f,\phi)|\leq \|M \cdot\sum_{ij}  D_j(\bar{a_{jk}}D_k\phi) \|_{L^2}, \quad \phi\in C_c^{\infty}(X) $$ for some positive continuous function $M$, then by Hahn-Banach theorem there exists some $g\in L^2$ $$   (f,\phi)=\left(g,M\cdot\sum_{ij}  D_j(\bar{a_{jk}}D_k\phi)\right) $$ which inplies that the weak solution is $u=Mg$. what confuses me is how the Hahn-Banach theorem is used here to show the existence of $g$. Thanks for your help","I came across the following question when I read chapter 17 of Hormander's book ""Tha Analysis of Linear Partial Differential Operators"", and the theorem is Let $a_{jk}(x)$ be Lipschitz continuous in an open set $X\subset\mathbb{R}^n$, $a_{ij}=a_{ji}$, and assume that $(\Re a_{ij}(x))$ is positive definite.  Then $$ \sum_{ij} D_j(a_{jk}D_ku)=f $$ has a solution $u\in H_{(2)}^{loc}(X)$ for every $f\in L_{loc}^2(X)$ The auther then says if we can show that  $$ |(f,\phi)|\leq \|M \cdot\sum_{ij}  D_j(\bar{a_{jk}}D_k\phi) \|_{L^2}, \quad \phi\in C_c^{\infty}(X) $$ for some positive continuous function $M$, then by Hahn-Banach theorem there exists some $g\in L^2$ $$   (f,\phi)=\left(g,M\cdot\sum_{ij}  D_j(\bar{a_{jk}}D_k\phi)\right) $$ which inplies that the weak solution is $u=Mg$. what confuses me is how the Hahn-Banach theorem is used here to show the existence of $g$. Thanks for your help",,"['functional-analysis', 'partial-differential-equations']"
62,Show that any convex function is locally bounded,Show that any convex function is locally bounded,,"Show that a convex function $f:\mathbb{R}^n \rightarrow \overline{\mathbb{R}}$ is bounded in a neighborhood of $x\in \text{ri}(\text{dom}(f))$. Showing that it has an upper bound is not difficult using Jensen's inequality. To show that it has a lower bound I showed that if it wasn't bound in $B(x,\delta)$, then the epigraph in this region would be $B(x,\delta)\times \langle-\infty,+\infty \rangle$, but to do this I made a weird assumption which might or might not be true. If $f$ didn't had a lower bound in  $B(x,\delta)$, then for every $M\in \mathbb{R}$ it exists an $x_M$ such that $f(x_M)<M$. Naturally $(x_M,M)\in \text{epi}(f_{|B(x_0,\delta)})$ and since $\text{epi}(f_{|B(x_0,\delta)})$ is convex for any $(x,\lambda) \in \text{epi}(f_{|B(x_0,\delta)})$ it would follow that $(tx+(1-t)x_M,t\lambda+(1-t)M)\in \text{epi}(f_{|B(x_0,\delta)})$ for any $t\in ]0,1[$. My assumption is that with this convex combination I can reach any point in $B(x,\delta)\times \langle-\infty,+\infty \rangle$. Any help regarding my assumption or another way to show  that there's a real lower bound would be welcome, thanks in advance. For this problem $\overline{\mathbb{R}}=\mathbb{R}\cup\{+\infty\}$,$\text{dom}(f)=\{x\in \mathbb{R}^n/ f(x)<+\infty\}$ and $\text{ri}(C)$ is the relative interior of $C$. After reading some books I found that not only is the function bound but it's uniformly continuous, the proof wasn't that simple. I feel there must be an easy way to find the lower bound maybe showing that it's lower semicontinuous at a neighborhood of $x$?","Show that a convex function $f:\mathbb{R}^n \rightarrow \overline{\mathbb{R}}$ is bounded in a neighborhood of $x\in \text{ri}(\text{dom}(f))$. Showing that it has an upper bound is not difficult using Jensen's inequality. To show that it has a lower bound I showed that if it wasn't bound in $B(x,\delta)$, then the epigraph in this region would be $B(x,\delta)\times \langle-\infty,+\infty \rangle$, but to do this I made a weird assumption which might or might not be true. If $f$ didn't had a lower bound in  $B(x,\delta)$, then for every $M\in \mathbb{R}$ it exists an $x_M$ such that $f(x_M)<M$. Naturally $(x_M,M)\in \text{epi}(f_{|B(x_0,\delta)})$ and since $\text{epi}(f_{|B(x_0,\delta)})$ is convex for any $(x,\lambda) \in \text{epi}(f_{|B(x_0,\delta)})$ it would follow that $(tx+(1-t)x_M,t\lambda+(1-t)M)\in \text{epi}(f_{|B(x_0,\delta)})$ for any $t\in ]0,1[$. My assumption is that with this convex combination I can reach any point in $B(x,\delta)\times \langle-\infty,+\infty \rangle$. Any help regarding my assumption or another way to show  that there's a real lower bound would be welcome, thanks in advance. For this problem $\overline{\mathbb{R}}=\mathbb{R}\cup\{+\infty\}$,$\text{dom}(f)=\{x\in \mathbb{R}^n/ f(x)<+\infty\}$ and $\text{ri}(C)$ is the relative interior of $C$. After reading some books I found that not only is the function bound but it's uniformly continuous, the proof wasn't that simple. I feel there must be an easy way to find the lower bound maybe showing that it's lower semicontinuous at a neighborhood of $x$?",,"['functional-analysis', 'convex-analysis', 'convex-optimization']"
63,How to decompose a representation into direct sum of cyclic representation?,How to decompose a representation into direct sum of cyclic representation?,,"Let $U$ be the bilateral shift operator on $\ell^2(\mathbb Z)$ , and let $T=U+U^*$ . How to calculate the spectrum $\sigma(T)$ ? And how to show there is no cyclic vector for the action of $C^*(T,I)$ ? Further how to decompose this representation to direct sum of cyclic representations? Something I know so far: if there is a cyclic vector for the action of $C^*(T,I)$ , then the commutant $C^*(T,I)'$ will be commutative. But I don't know how to identify this commutant.","Let be the bilateral shift operator on , and let . How to calculate the spectrum ? And how to show there is no cyclic vector for the action of ? Further how to decompose this representation to direct sum of cyclic representations? Something I know so far: if there is a cyclic vector for the action of , then the commutant will be commutative. But I don't know how to identify this commutant.","U \ell^2(\mathbb Z) T=U+U^* \sigma(T) C^*(T,I) C^*(T,I) C^*(T,I)'","['functional-analysis', 'operator-theory', 'c-star-algebras']"
64,Using Lax Milgram to find a weak solution in an intersection of Sobolev spaces,Using Lax Milgram to find a weak solution in an intersection of Sobolev spaces,,"I am trying to prove the existence of a weak solution of the problem: $$ -\Delta^2 u = f \in L^2(U)\\ \\ u|_{\partial U}=\Delta u|_{\partial U} = 0 $$ on the bounded open set $U\subset\mathbb{R}^n$ which has smooth boundary. The weak formulation follows from multiplying by the test function $v$ and integration by parts: $$ \int_U fv\,dx= \int_U \, (\Delta^2 u) v\, dx= \int_U \Delta u \Delta v \, dx + \int_{\partial U} (v \frac{\partial \Delta u}{\partial n} - \frac{\partial v}{\partial n}\Delta u)dS. $$ The second boundary vanishes for $\Delta u|_{\partial U} = 0$ and to make the first boundary term vanish we require $v$ to be in the Sobolev space $H^1_0(U)\cap H^2(U)$, so that $v=0$ on the boundary. Therefore $u\in H^1_0(U)\cap H^2(U)$ is a weak solution if: $$ \int_U \Delta u \Delta v \, dx = \int_U fv\,dx\,\,\,\, \forall v\in H^1_0(U)\cap H^2(U). $$ Now I want to use the Lax-Milgram theorem on the bilinear form $B[u,v]=\int_U \Delta u \Delta v \, dx$. My problem is: what norm on $H^1_0(U)\cap H^2(U)$ should I use? At first I thought I could use either one of the norms of $H^1_0(U)$ or $H^2(U)$, since clearly $H^1_0(U)\cap H^2(U)$ is a closed subspace of both spaces. However I realized that this argument must be wrong, otherwise I might as well use the norm of the subspace $H^{8}(U)$ and conclude there exists a weak solution in that space. Or should I use Lax Milgram for both $H^1_0(U)$ and $H^2(U)$ and conclude that the weak solution is in their intersection? My second problem: when proving the coercivity of $B[u,v]$, I think I need an inequality like $\int_U |\Delta u|^2 dx \geq C\int_U u^2 dx$ for some constant $C$. I know this holds for $u\in H^2_0(U)$ but I don't see why this should hold in $H^1_0(U)\cap H^2(U)$?","I am trying to prove the existence of a weak solution of the problem: $$ -\Delta^2 u = f \in L^2(U)\\ \\ u|_{\partial U}=\Delta u|_{\partial U} = 0 $$ on the bounded open set $U\subset\mathbb{R}^n$ which has smooth boundary. The weak formulation follows from multiplying by the test function $v$ and integration by parts: $$ \int_U fv\,dx= \int_U \, (\Delta^2 u) v\, dx= \int_U \Delta u \Delta v \, dx + \int_{\partial U} (v \frac{\partial \Delta u}{\partial n} - \frac{\partial v}{\partial n}\Delta u)dS. $$ The second boundary vanishes for $\Delta u|_{\partial U} = 0$ and to make the first boundary term vanish we require $v$ to be in the Sobolev space $H^1_0(U)\cap H^2(U)$, so that $v=0$ on the boundary. Therefore $u\in H^1_0(U)\cap H^2(U)$ is a weak solution if: $$ \int_U \Delta u \Delta v \, dx = \int_U fv\,dx\,\,\,\, \forall v\in H^1_0(U)\cap H^2(U). $$ Now I want to use the Lax-Milgram theorem on the bilinear form $B[u,v]=\int_U \Delta u \Delta v \, dx$. My problem is: what norm on $H^1_0(U)\cap H^2(U)$ should I use? At first I thought I could use either one of the norms of $H^1_0(U)$ or $H^2(U)$, since clearly $H^1_0(U)\cap H^2(U)$ is a closed subspace of both spaces. However I realized that this argument must be wrong, otherwise I might as well use the norm of the subspace $H^{8}(U)$ and conclude there exists a weak solution in that space. Or should I use Lax Milgram for both $H^1_0(U)$ and $H^2(U)$ and conclude that the weak solution is in their intersection? My second problem: when proving the coercivity of $B[u,v]$, I think I need an inequality like $\int_U |\Delta u|^2 dx \geq C\int_U u^2 dx$ for some constant $C$. I know this holds for $u\in H^2_0(U)$ but I don't see why this should hold in $H^1_0(U)\cap H^2(U)$?",,"['functional-analysis', 'partial-differential-equations', 'hilbert-spaces', 'normed-spaces']"
65,Cross Product for functions,Cross Product for functions,,"So functions are just uncountabley-infinite dimensional vectors, and as such there's a nice generalization of the inner product between two functions (the integral of their product).  Is their a similar generalization for the cross product between two functions?!","So functions are just uncountabley-infinite dimensional vectors, and as such there's a nice generalization of the inner product between two functions (the integral of their product).  Is their a similar generalization for the cross product between two functions?!",,"['functional-analysis', 'functions', 'cross-product']"
66,Is the image of every open set under a non-zero discontinuous linear function dense in $\mathbb{R}$?,Is the image of every open set under a non-zero discontinuous linear function dense in ?,\mathbb{R},"Given a normed space $V$ over $\mathbb{R}$, is it true that the image of every open set of $V$ under a non-zero discontinuous linear function $V\to\mathbb{R}$ is dense in $\mathbb{R}$? I couldnt prove or disprove yet , thanks.","Given a normed space $V$ over $\mathbb{R}$, is it true that the image of every open set of $V$ under a non-zero discontinuous linear function $V\to\mathbb{R}$ is dense in $\mathbb{R}$? I couldnt prove or disprove yet , thanks.",,"['functional-analysis', 'normed-spaces']"
67,Kernel of adjoint operator,Kernel of adjoint operator,,"This problem is puzzling me, even though it should be really simple. Let $L=-\partial_x^2 + \frac 1 2 x^{-2}$ be an operator defined on $D(L)=C^\infty_c(0,+\infty)\subset L^2(0,+\infty)$. Its adjoint operator on $L^2$, will then be $L^*=-\partial_x^2 + \frac 1 2 x^{-2}$ with domain $D(L^*)=\{u\in L^2\colon\: (-\partial_x^2 + \frac 1 2 x^{-2})u\in L^2 \text{ in the sense of distributions} \}$. Now, I want to find the kernel of $L^*$, that I know to have dimension $1$. Hence, I solve $(-\partial_x^2 + \frac 1 2 x^{-2})u=0$, and find that it has two solutions: $x^{\frac{1\pm\sqrt 3} 2}$. The problem is that, while both of these functions are in $L^2$ near $0$, none of them is in $L^2$ at $+\infty$. Which is the right way to reason here? I cannot just consider the functions near $0$, otherwise I would end up with two of them, nor I see any justification in taking their sum as the generator of the kernel. Thank you for any answers!","This problem is puzzling me, even though it should be really simple. Let $L=-\partial_x^2 + \frac 1 2 x^{-2}$ be an operator defined on $D(L)=C^\infty_c(0,+\infty)\subset L^2(0,+\infty)$. Its adjoint operator on $L^2$, will then be $L^*=-\partial_x^2 + \frac 1 2 x^{-2}$ with domain $D(L^*)=\{u\in L^2\colon\: (-\partial_x^2 + \frac 1 2 x^{-2})u\in L^2 \text{ in the sense of distributions} \}$. Now, I want to find the kernel of $L^*$, that I know to have dimension $1$. Hence, I solve $(-\partial_x^2 + \frac 1 2 x^{-2})u=0$, and find that it has two solutions: $x^{\frac{1\pm\sqrt 3} 2}$. The problem is that, while both of these functions are in $L^2$ near $0$, none of them is in $L^2$ at $+\infty$. Which is the right way to reason here? I cannot just consider the functions near $0$, otherwise I would end up with two of them, nor I see any justification in taking their sum as the generator of the kernel. Thank you for any answers!",,"['functional-analysis', 'ordinary-differential-equations', 'operator-theory', 'quantum-mechanics']"
68,Variation of the fundamental lemma of calculus of variation,Variation of the fundamental lemma of calculus of variation,,"Let $$C^1_0[a,b]:=\{f \ C^1[a,b]|f(a)=f(b)=0\}.$$ Providing $C^1_0[a,b]$ is dense in $L^2[a,b]$, I want to prove the following statement: if for $g,h\in L^2[a,b]$, $$\int_a^b g \phi \,dx =\int_a^b h \phi \,dx$$  for all test functions $\phi\in C^1_0[a,b]$, then $g = h$ almost everywhere. It seems to be similar with fundamental lemma of calculus of variation, how can I extend the the result to $L^2$ functions? My guess is using density argument, along with one of convergence theorems, but I failed to construct the proof. Please help me out here. Thank you.","Let $$C^1_0[a,b]:=\{f \ C^1[a,b]|f(a)=f(b)=0\}.$$ Providing $C^1_0[a,b]$ is dense in $L^2[a,b]$, I want to prove the following statement: if for $g,h\in L^2[a,b]$, $$\int_a^b g \phi \,dx =\int_a^b h \phi \,dx$$  for all test functions $\phi\in C^1_0[a,b]$, then $g = h$ almost everywhere. It seems to be similar with fundamental lemma of calculus of variation, how can I extend the the result to $L^2$ functions? My guess is using density argument, along with one of convergence theorems, but I failed to construct the proof. Please help me out here. Thank you.",,"['functional-analysis', 'calculus-of-variations']"
69,"Show $T\colon H\rightarrow K$ is defined by $Tx=\sum_{n=1}^{\infty} \langle x,u_n\rangle v_n$ is compact",Show  is defined by  is compact,"T\colon H\rightarrow K Tx=\sum_{n=1}^{\infty} \langle x,u_n\rangle v_n","$H$ and $K$ are Hilbert Spaces, $(u_n)$ and $(v_n)$ are sequences in $H$ and $K$ respectively. $\sum_{n=1}^{n=\infty} \|u_n\|\|v_n\| $ converges. $T\colon H\rightarrow K$ is defined by $Tx=\sum_{n=1}^{\infty} \langle x,u_n\rangle v_n$. I need to show that $T$ is compact, and I am frankly clueless. All I can think to say is that the first sum converging means each series is bounded, but I don't know if that is even relevant. And hints/help would be appreciated. Thanks","$H$ and $K$ are Hilbert Spaces, $(u_n)$ and $(v_n)$ are sequences in $H$ and $K$ respectively. $\sum_{n=1}^{n=\infty} \|u_n\|\|v_n\| $ converges. $T\colon H\rightarrow K$ is defined by $Tx=\sum_{n=1}^{\infty} \langle x,u_n\rangle v_n$. I need to show that $T$ is compact, and I am frankly clueless. All I can think to say is that the first sum converging means each series is bounded, but I don't know if that is even relevant. And hints/help would be appreciated. Thanks",,"['analysis', 'functional-analysis', 'hilbert-spaces', 'compactness', 'compact-operators']"
70,Alternate definition for boundedness in a TVS,Alternate definition for boundedness in a TVS,,Let $X$ be a topological vector space over $\mathbb R$ or $\mathbb C$. A subset $B\subset X$ is defined to be bounded if for any open neighborhood $N$ of $0$ there is a number $\lambda>0$   such that $B\subset \mu N$ for any $\mu>\lambda$. I was wondering whether this notion of boundedness is equivalent to saying that for any open neighborhood $N$ of $0$ there is a $\mu>0$ such that $B\subset \mu N.$ By definition $\mu N:=\{\mu\cdot x\colon x\in N\}$.,Let $X$ be a topological vector space over $\mathbb R$ or $\mathbb C$. A subset $B\subset X$ is defined to be bounded if for any open neighborhood $N$ of $0$ there is a number $\lambda>0$   such that $B\subset \mu N$ for any $\mu>\lambda$. I was wondering whether this notion of boundedness is equivalent to saying that for any open neighborhood $N$ of $0$ there is a $\mu>0$ such that $B\subset \mu N.$ By definition $\mu N:=\{\mu\cdot x\colon x\in N\}$.,,"['functional-analysis', 'definition', 'examples-counterexamples', 'topological-vector-spaces']"
71,Question about example of non-separable Hilbert space,Question about example of non-separable Hilbert space,,"I have come across the following example of a non-separable Hilbert space: Example 2.84. Let $I$ be a set, equipped with the discrete topology and the counting measure $\lambda_{\text{ count}}$ defined on the $\sigma$-algebra $\Bbb P(I)$ of all subsets of $I$. Then    $$\ell^2(I)=L^2\big(I,\Bbb P(I),\lambda_{\text{ count}}\big)$$   is a Hilbert space, and it comprises all functions $a:I\to\Bbb R$ (or $\Bbb C$) for which the support    $$F=\{i\in I : a(i)\ne0\},$$   is finite or countable, and for which $\sum_{i\in I}|a_i|^2=\sum_{i\in F}|a_i|^2\lt\infty$. Why do I need the discrete topology on $I$? Or more generally: why do I need a topology? If we talk about $L^p$ spaces in general, we only want a measure space and we don't mention a topology because $f \in L^p$ doesn't have to be continuous. Thanks for your help.","I have come across the following example of a non-separable Hilbert space: Example 2.84. Let $I$ be a set, equipped with the discrete topology and the counting measure $\lambda_{\text{ count}}$ defined on the $\sigma$-algebra $\Bbb P(I)$ of all subsets of $I$. Then    $$\ell^2(I)=L^2\big(I,\Bbb P(I),\lambda_{\text{ count}}\big)$$   is a Hilbert space, and it comprises all functions $a:I\to\Bbb R$ (or $\Bbb C$) for which the support    $$F=\{i\in I : a(i)\ne0\},$$   is finite or countable, and for which $\sum_{i\in I}|a_i|^2=\sum_{i\in F}|a_i|^2\lt\infty$. Why do I need the discrete topology on $I$? Or more generally: why do I need a topology? If we talk about $L^p$ spaces in general, we only want a measure space and we don't mention a topology because $f \in L^p$ doesn't have to be continuous. Thanks for your help.",,"['functional-analysis', 'measure-theory', 'hilbert-spaces']"
72,Dependence of the Sobolev embedding constants on the domain,Dependence of the Sobolev embedding constants on the domain,,"Let $\Omega$ be a sufficiently nice domain in $\mathbb{R}^n$. If $ 1 \leq p < n $ and $ p^* = \frac{np}{n-p} $ then there exists a constant $C_1$ such that for all $ u \in W^{1,p}(\Omega) $ we have $$ (I)~~~~||u||_{L^{p^*}(\Omega)} \leq C_1||u||_{W^{1,p}(\Omega)}. $$  If $ p > n $ then there exists a constant $C_2$ such that for all $ u \in W^{1,p}(\Omega) $ we have $$ (II)~~~~||u||_{L^{\infty}(\Omega)} \leq C_2||u||_{W^{1,p}(\Omega)}. $$ In general, the constants $C_i$ depend on the domain $\Omega$. Can someone point me to some references that discuss the dependence between the embedding constants and the domain? I'm interested in conditions under which, given some family of domains $ \Omega_\alpha $, I can get Sobolev embedding inequalities as above with a constant that doesn't depend on $\alpha$. To be even more specific, I'm interested in the case $ n = 2 $ and when the domains are families of balls or annuli. For example, if I consider inequality (II) and a family of balls, then an obvious sufficient condition is to have both an upper and a lower bound on the radii of the balls. One can't get away without a lower bound (consider the function $u \equiv 1$) but can get away without an upper bound by using a translation argument. What about inequality (I)? What can I use to answer such questions? Since one way to prove the inequalities above is to use an extension operator, and then ""steal"" the inequality from $\mathbb{R}^n$, this question is related to dependence of the minimal norm of an extension operator $W^{1,p}(\Omega) \rightarrow W^{1,p}(\mathbb{R}^n)$ on the domain","Let $\Omega$ be a sufficiently nice domain in $\mathbb{R}^n$. If $ 1 \leq p < n $ and $ p^* = \frac{np}{n-p} $ then there exists a constant $C_1$ such that for all $ u \in W^{1,p}(\Omega) $ we have $$ (I)~~~~||u||_{L^{p^*}(\Omega)} \leq C_1||u||_{W^{1,p}(\Omega)}. $$  If $ p > n $ then there exists a constant $C_2$ such that for all $ u \in W^{1,p}(\Omega) $ we have $$ (II)~~~~||u||_{L^{\infty}(\Omega)} \leq C_2||u||_{W^{1,p}(\Omega)}. $$ In general, the constants $C_i$ depend on the domain $\Omega$. Can someone point me to some references that discuss the dependence between the embedding constants and the domain? I'm interested in conditions under which, given some family of domains $ \Omega_\alpha $, I can get Sobolev embedding inequalities as above with a constant that doesn't depend on $\alpha$. To be even more specific, I'm interested in the case $ n = 2 $ and when the domains are families of balls or annuli. For example, if I consider inequality (II) and a family of balls, then an obvious sufficient condition is to have both an upper and a lower bound on the radii of the balls. One can't get away without a lower bound (consider the function $u \equiv 1$) but can get away without an upper bound by using a translation argument. What about inequality (I)? What can I use to answer such questions? Since one way to prove the inequalities above is to use an extension operator, and then ""steal"" the inequality from $\mathbb{R}^n$, this question is related to dependence of the minimal norm of an extension operator $W^{1,p}(\Omega) \rightarrow W^{1,p}(\mathbb{R}^n)$ on the domain",,"['functional-analysis', 'sobolev-spaces']"
73,Compact operator norm estimate,Compact operator norm estimate,,"I found the next exercise in Haim Brezis's book Functional Analysis, Sobolev Spaces and Partial Differential Equations. I feel like I solved the problem, but I'm not sure. The problem is: Let $E,F$ be two Banach spaces with norms $\|\cdot \|_E,\| \cdot \|_F$. Assume that $E$ is reflexive. Let $T :E \to F$ be a compact operator. Consider on $E$ another norm $| \cdot |$ weaker than $\|\cdot \|_E$, i.e. $|u|\leq C \|u\|_E$. Prove that for every $\varepsilon >0$ ther exists $C_\varepsilon>0$ such that   $$ \|Tu\|_F \leq \varepsilon \|u\|_E +C_\varepsilon |u| $$ My approach is the following: Assume that the conclusion does not hold. Then there is an $\varepsilon>0$ and a sequence $u_n$ in $E$ such that $$ \|Tu_n\|_F > \varepsilon \|u_n\|_E+n|u_n|$$ We can normalize the sequence such that $\|Tu_n\|=1$. Then $u_n$ is bounded in $E$, and because $E$ is reflexive then without loss of generality we can assume that $u_n$ converges weakly to $u \in E$. Since compact operators map weakly convergent sequences onto strongly convergent sequences it follows that $Tu_n \to Tu$ in $F$, so $\|Tu\|_F=1$, which means that $u\neq 0$. On the other hand $|u_n|<1/n$ so that $u_n$ converges to $0$ in the weaker norm $|\cdot |$. Is this enough to prove that $u=0$ and reach a contradiction? If my approach does not lead to a good end then what else should I try?","I found the next exercise in Haim Brezis's book Functional Analysis, Sobolev Spaces and Partial Differential Equations. I feel like I solved the problem, but I'm not sure. The problem is: Let $E,F$ be two Banach spaces with norms $\|\cdot \|_E,\| \cdot \|_F$. Assume that $E$ is reflexive. Let $T :E \to F$ be a compact operator. Consider on $E$ another norm $| \cdot |$ weaker than $\|\cdot \|_E$, i.e. $|u|\leq C \|u\|_E$. Prove that for every $\varepsilon >0$ ther exists $C_\varepsilon>0$ such that   $$ \|Tu\|_F \leq \varepsilon \|u\|_E +C_\varepsilon |u| $$ My approach is the following: Assume that the conclusion does not hold. Then there is an $\varepsilon>0$ and a sequence $u_n$ in $E$ such that $$ \|Tu_n\|_F > \varepsilon \|u_n\|_E+n|u_n|$$ We can normalize the sequence such that $\|Tu_n\|=1$. Then $u_n$ is bounded in $E$, and because $E$ is reflexive then without loss of generality we can assume that $u_n$ converges weakly to $u \in E$. Since compact operators map weakly convergent sequences onto strongly convergent sequences it follows that $Tu_n \to Tu$ in $F$, so $\|Tu\|_F=1$, which means that $u\neq 0$. On the other hand $|u_n|<1/n$ so that $u_n$ converges to $0$ in the weaker norm $|\cdot |$. Is this enough to prove that $u=0$ and reach a contradiction? If my approach does not lead to a good end then what else should I try?",,"['functional-analysis', 'normed-spaces', 'compact-operators']"
74,Separating vectors for $C^*$-algebras,Separating vectors for -algebras,C^*,"Let $A$ be a C$^*$-algebra, concretely acting on a Hilbert space $H$.  Suppose that $\xi_0\in H$ is cyclic and separating for $A$ (that is, the map $A\rightarrow H, a\mapsto a(\xi_0)$ is injective with dense range).  Let $M=A''$ the von Neumann algebra generated by $A$. Need $\xi_0$ still be separating for $M$?  That is, $x\in M, x(\xi_0)=0 \implies x=0$? Actually, I think I can prove this.  We turn $\mathfrak A = \{ a(\xi_0) : a\in A \}$ into a left Hilbert algebra algebra in the obvious way.  Then run the Tomita-Takesaki machinery (actually not needed in full generality as we start with a state, not a weight).  Then the von Neumann algebra generated by $\mathfrak A$ is nothing but $M$, and so the general theory tells us that $\varphi(x) = \|x\xi_0\|$ will be a faithful weight on $M$, which is what we need. Is this right?  Surely this argument is far, far more complicated then necessary? No, I don't think this is right: there seems no reason why the Tomita operator $S:a(\xi_0)\mapsto a^*(\xi_0)$ is preclosed.","Let $A$ be a C$^*$-algebra, concretely acting on a Hilbert space $H$.  Suppose that $\xi_0\in H$ is cyclic and separating for $A$ (that is, the map $A\rightarrow H, a\mapsto a(\xi_0)$ is injective with dense range).  Let $M=A''$ the von Neumann algebra generated by $A$. Need $\xi_0$ still be separating for $M$?  That is, $x\in M, x(\xi_0)=0 \implies x=0$? Actually, I think I can prove this.  We turn $\mathfrak A = \{ a(\xi_0) : a\in A \}$ into a left Hilbert algebra algebra in the obvious way.  Then run the Tomita-Takesaki machinery (actually not needed in full generality as we start with a state, not a weight).  Then the von Neumann algebra generated by $\mathfrak A$ is nothing but $M$, and so the general theory tells us that $\varphi(x) = \|x\xi_0\|$ will be a faithful weight on $M$, which is what we need. Is this right?  Surely this argument is far, far more complicated then necessary? No, I don't think this is right: there seems no reason why the Tomita operator $S:a(\xi_0)\mapsto a^*(\xi_0)$ is preclosed.",,"['functional-analysis', 'operator-algebras']"
75,Subspace of $C_0(\mathbb R)$ contained in $L^2(\mathbb R)$,Subspace of  contained in,C_0(\mathbb R) L^2(\mathbb R),"Let $W$ be a closed subspace of $C_0(\mathbb R)$ which is continuously contained as also a closed subspace of $L^2(\mathbb R)$. That is, there are constants $c_1$, $c_2$ such that $c_1 \|f\|_\infty \leq \|f\|_2 \leq c_2 \|f\|_\infty$ for all $f\in W$. Must $W$ be finite dimensional? What if we replace $L^2$ with $L^p$ for $p\geq 1$?","Let $W$ be a closed subspace of $C_0(\mathbb R)$ which is continuously contained as also a closed subspace of $L^2(\mathbb R)$. That is, there are constants $c_1$, $c_2$ such that $c_1 \|f\|_\infty \leq \|f\|_2 \leq c_2 \|f\|_\infty$ for all $f\in W$. Must $W$ be finite dimensional? What if we replace $L^2$ with $L^p$ for $p\geq 1$?",,['functional-analysis']
76,A complete eigenvector basis for the restricted operator,A complete eigenvector basis for the restricted operator,,"Let $X$ be a (not necessarily bounded) selfadjoint linear operator on a Hilbert space $H$ and let $M$ be a closed subspace such that $X(M) \subset M$. Suppose that $X$ admits an orthonormal basis of eigenvectors. Does it follow that $X|_M$ admits an orthonormal basis of eigenvectors too? I think that the answer is 'yes' if $X$ commutes with the orthoprojection of range $M$: $$PX \subset XP,$$ but I don't know what happens without this hypothesis. What do you think? Thank you.","Let $X$ be a (not necessarily bounded) selfadjoint linear operator on a Hilbert space $H$ and let $M$ be a closed subspace such that $X(M) \subset M$. Suppose that $X$ admits an orthonormal basis of eigenvectors. Does it follow that $X|_M$ admits an orthonormal basis of eigenvectors too? I think that the answer is 'yes' if $X$ commutes with the orthoprojection of range $M$: $$PX \subset XP,$$ but I don't know what happens without this hypothesis. What do you think? Thank you.",,"['functional-analysis', 'hilbert-spaces', 'operator-theory']"
77,Criterion for a bounded linear operator to be compact,Criterion for a bounded linear operator to be compact,,"Let $X,Y$ be Banach spaces. $T\colon X\to Y$ be a bounded linear operator. How can I prove that $T$ is compact if and only if there is $\lbrace x_n^*\rbrace\subset X^*$ such that $\|x_n^*\|\to 0$ and $\|T(x)\|\leq \operatorname{sup}_n|x_n^*(x)|$ for every $x\in X$?","Let $X,Y$ be Banach spaces. $T\colon X\to Y$ be a bounded linear operator. How can I prove that $T$ is compact if and only if there is $\lbrace x_n^*\rbrace\subset X^*$ such that $\|x_n^*\|\to 0$ and $\|T(x)\|\leq \operatorname{sup}_n|x_n^*(x)|$ for every $x\in X$?",,"['functional-analysis', 'banach-spaces', 'operator-theory', 'compact-operators']"
78,"Let $A$ be a unital $C^*$-algebra, $a\in A,\ x,y\in A_{sa}$. Does there exist a state $\phi$ on $A$ such that $\phi(xa^*ay)=\lVert a\rVert^2\phi(xy)$?","Let  be a unital -algebra, . Does there exist a state  on  such that ?","A C^* a\in A,\ x,y\in A_{sa} \phi A \phi(xa^*ay)=\lVert a\rVert^2\phi(xy)","If $A$ is a commutative, unital $C^*$ -algebra, then $A=C(X)$ for some compact, $T_2$ space $X$ . Then $a=f,x=g$ and $y=h$ are continuous functions on $X$ . Then there is $x_0\in X$ such that $\lVert f\rVert=|f(x_0)|$ . Take $\phi=\hat{x_0}$ . Then $\phi(xa^*ay)=g(x_0)|f(x_0)|^2h(x_0)=\lVert f\rVert^2\phi(gh)=\lVert a\rVert^2\phi(xy)$ . I'm doubtful about the non-commutative case here. If $x,y=1$ , then the we consider the (commutative) $C^*$ -algebra generated by $a^*a$ , and then extend to whole of $A$ by Hahn-Banach. But here $x,y,a^*a$ may not commute with each other, so the $C^*$ -algebra generated by $x,y,a^*a$ may not be commutative. Therefore, I cannot apply the above argument. Can anyone help me with the non-commutative case? Thanks for your help in advance.","If is a commutative, unital -algebra, then for some compact, space . Then and are continuous functions on . Then there is such that . Take . Then . I'm doubtful about the non-commutative case here. If , then the we consider the (commutative) -algebra generated by , and then extend to whole of by Hahn-Banach. But here may not commute with each other, so the -algebra generated by may not be commutative. Therefore, I cannot apply the above argument. Can anyone help me with the non-commutative case? Thanks for your help in advance.","A C^* A=C(X) T_2 X a=f,x=g y=h X x_0\in X \lVert f\rVert=|f(x_0)| \phi=\hat{x_0} \phi(xa^*ay)=g(x_0)|f(x_0)|^2h(x_0)=\lVert f\rVert^2\phi(gh)=\lVert a\rVert^2\phi(xy) x,y=1 C^* a^*a A x,y,a^*a C^* x,y,a^*a","['functional-analysis', 'operator-algebras', 'c-star-algebras']"
79,A sufficient condition for tightness of probability measures,A sufficient condition for tightness of probability measures,,"For a sequence $\mu_{n}$ of Borel Probability measures, does $\int f\,d\mu_{n}$ converging for all $f\in C_{b}(\Bbb{R})$ imply that $\mu_{n}$ is a tight sequence? This is pertaining to the question here . Users(with sufficient privileges) can  view my deleted answer where I made the horribly stupid mistake of approximating $\mathbf{1}_{[-M,M]}$ under the supremum norm  by continuous bounded functions . The condition reeks of an application of Uniform Boundedness Principle , but it only yields a bound with the $L^{\infty}$ norm of the form $\sup_{n}|\int f\,d\mu_{n}|\leq C||f||_{L^{\infty}}$ which is not very helpful as we would like to approximate $\mathbf{1}_{[-M,M]}$ by a sequence say $g_{k}$ of continuous bounded functions . So ideally, a bound with the $L^{1}$ norm is what would do the job. Then we can approximate as $k\to\infty$ (uniformly in $n$ ) $\mu_{n}[-M,M]$ with $\int g_{k}\,d\mu_{n}$ and then use Cauchyness of the sequence $\int g_{k}\,d\mu_{n}$ to prove that $\mu([-M,M])$ is tight. However, I find no easy way of countering this . I might be having a brain freeze so please excuse my stupidity if I am missing something very easy.","For a sequence of Borel Probability measures, does converging for all imply that is a tight sequence? This is pertaining to the question here . Users(with sufficient privileges) can  view my deleted answer where I made the horribly stupid mistake of approximating under the supremum norm  by continuous bounded functions . The condition reeks of an application of Uniform Boundedness Principle , but it only yields a bound with the norm of the form which is not very helpful as we would like to approximate by a sequence say of continuous bounded functions . So ideally, a bound with the norm is what would do the job. Then we can approximate as (uniformly in ) with and then use Cauchyness of the sequence to prove that is tight. However, I find no easy way of countering this . I might be having a brain freeze so please excuse my stupidity if I am missing something very easy.","\mu_{n} \int f\,d\mu_{n} f\in C_{b}(\Bbb{R}) \mu_{n} \mathbf{1}_{[-M,M]} L^{\infty} \sup_{n}|\int f\,d\mu_{n}|\leq C||f||_{L^{\infty}} \mathbf{1}_{[-M,M]} g_{k} L^{1} k\to\infty n \mu_{n}[-M,M] \int g_{k}\,d\mu_{n} \int g_{k}\,d\mu_{n} \mu([-M,M])","['functional-analysis', 'probability-theory', 'weak-convergence', 'weak-topology']"
80,"Find linear functional $\ell$ s.t. $\frac{1}{2n}\int_{-n}^{n}g(x)\, dx \to \ell(g)$",Find linear functional  s.t.,"\ell \frac{1}{2n}\int_{-n}^{n}g(x)\, dx \to \ell(g)","(Update below) I'm studying for my Functional Analysis final, and I found an interesting exercise in one of the old exams. There is one part where I am unsure, maybe someone could point me in the right direction. Consider the Banach space $V:= L^\infty(\Bbb{R})$ with the supremum norm. For each $n \in \Bbb{N}$ , define $$ l_n(g) = \frac{1}{2n}\int_{-n}^ng(x)\, dx, \,\,\, \forall g\in V. $$ Prove that there exists $l \in V^*$ and a subsequence $(n_k)_{k \in \Bbb{N}}$ such that $(l_{n_k})$ converges weak- $*$ to $l$ as $k \to \infty$ . If I understood the convergence in the weak- $*$ sense correctly, I need to find a linear functional $l \in V^*$ such that $l_n(g) \to l(g)$ for all $g \in V$ (or rather, we have convergence along a subsequence). My initial thought was just defining $l(g) = \lim_{n\to \infty} l_n(g)$ , but I see no reason why this limit should exist for all $g$ . I then proceeded to define $l$ as above on the subspace of $V$ given by $\{g \in V \mid lim_{x\to \infty}g(x)\text{ and }\lim_{x \to -\infty}g(x) \text{ exist.}\}$ , where $l_n(g)$ should converge. Using Hahn-Banach, I can then extend this functional to all of $V$ . Now, since $l_n(g)$ is a bounded sequence, by Bolzano-Weierstrass we can extract a converging subsequence, which should give exactly the subsequence $(l_{n_k})_{k\in \Bbb{N}}$ we are looking for. Am I on the right track here? I'm particularly unsure about the characterization of weak- $*$ convergence, which is a subject I am still struggling a bit. Any help is greatly appreciated. Update As mentioned by @Ofek Arian in his answer, my argument does not work, because just finding for all $g \in V$ a subsequence s.t. $l_{n_k}(g)$ converges is not enough to conclude there is a subsequence s.t. $(l_{n_k})$ converges for all $g \in V$ . Based on @David Mitra's comment, the statement that the exercise wants me to prove might actually not even be true. I will try to flesh out his argument here, I hope I understood correctly. If we look at $l_n$ as an element of $L^1$ , say $l_n(x) = \frac{1}{2n}\chi_{[-n,n]}(x)$ , then the weak- $*$ convergence in the exercise is the same as weak convergence of $l_n$ in $L^1$ . We have that $l_n(x) \to 0$ pointwise and if a sequence of elements in $L^1$ converges pointwise (a.e.), as well as weakly in $L^1$ , then the two limits must agree. (See e.g., Pointwise a.e. convergence and weak convergence in Lp ). So the weak limit along any subsequence would need to be the zero function. But for $g \equiv 1$ , the constant $1$ function, we have $l_n(g) = 1 \, \forall n \in \Bbb{N}$ , showing that $l_n$ can't possibly converge weakly to the zero function along any subsequence. Since the first part of the exercise was 'state the Banach-Alaoglu Theorem', I am led to believe that the intention might have been what @Ofek Arian mentioned in his comment, namely to invoke Banach-Alaoglu to deduce that the closed unit ball of $V^*$ is weak- $*$ compact, and use this fact to extract a converging subsequence. But compactness and sequential compactness need not agree in the weak- $*$ topology, and it is in fact different in the case of $(L^\infty)^*$ . It's possible that this is just a mistake in the exercise... Update 2 As @SeverinSchraven noticed, one needs to be careful when arguing that such subsequence cannot exist. It is a priori not clear, that the weak- $*$ limit of $l_n$ can be represented by a function in $L^1$ , so the linked result cannot be directly applied. Nonetheless, this can be fixed, as @DavidMitra argued: If we had weak- $*$ convergence in $(L^\infty)^*$ , we would get a weak Cauchy sequence (in $L^1$ ), and in $L^1$ , weak Cauchy implies weakly convergent. See e.g., Weak limit of an $L^1$ sequence . Thus, we may actually apply the linked result as done above to argue that no such subsequence can exist. (I hope I have written down your argument faithfully).","(Update below) I'm studying for my Functional Analysis final, and I found an interesting exercise in one of the old exams. There is one part where I am unsure, maybe someone could point me in the right direction. Consider the Banach space with the supremum norm. For each , define Prove that there exists and a subsequence such that converges weak- to as . If I understood the convergence in the weak- sense correctly, I need to find a linear functional such that for all (or rather, we have convergence along a subsequence). My initial thought was just defining , but I see no reason why this limit should exist for all . I then proceeded to define as above on the subspace of given by , where should converge. Using Hahn-Banach, I can then extend this functional to all of . Now, since is a bounded sequence, by Bolzano-Weierstrass we can extract a converging subsequence, which should give exactly the subsequence we are looking for. Am I on the right track here? I'm particularly unsure about the characterization of weak- convergence, which is a subject I am still struggling a bit. Any help is greatly appreciated. Update As mentioned by @Ofek Arian in his answer, my argument does not work, because just finding for all a subsequence s.t. converges is not enough to conclude there is a subsequence s.t. converges for all . Based on @David Mitra's comment, the statement that the exercise wants me to prove might actually not even be true. I will try to flesh out his argument here, I hope I understood correctly. If we look at as an element of , say , then the weak- convergence in the exercise is the same as weak convergence of in . We have that pointwise and if a sequence of elements in converges pointwise (a.e.), as well as weakly in , then the two limits must agree. (See e.g., Pointwise a.e. convergence and weak convergence in Lp ). So the weak limit along any subsequence would need to be the zero function. But for , the constant function, we have , showing that can't possibly converge weakly to the zero function along any subsequence. Since the first part of the exercise was 'state the Banach-Alaoglu Theorem', I am led to believe that the intention might have been what @Ofek Arian mentioned in his comment, namely to invoke Banach-Alaoglu to deduce that the closed unit ball of is weak- compact, and use this fact to extract a converging subsequence. But compactness and sequential compactness need not agree in the weak- topology, and it is in fact different in the case of . It's possible that this is just a mistake in the exercise... Update 2 As @SeverinSchraven noticed, one needs to be careful when arguing that such subsequence cannot exist. It is a priori not clear, that the weak- limit of can be represented by a function in , so the linked result cannot be directly applied. Nonetheless, this can be fixed, as @DavidMitra argued: If we had weak- convergence in , we would get a weak Cauchy sequence (in ), and in , weak Cauchy implies weakly convergent. See e.g., Weak limit of an $L^1$ sequence . Thus, we may actually apply the linked result as done above to argue that no such subsequence can exist. (I hope I have written down your argument faithfully).","V:= L^\infty(\Bbb{R}) n \in \Bbb{N}  l_n(g) = \frac{1}{2n}\int_{-n}^ng(x)\, dx, \,\,\, \forall g\in V.  l \in V^* (n_k)_{k \in \Bbb{N}} (l_{n_k}) * l k \to \infty * l \in V^* l_n(g) \to l(g) g \in V l(g) = \lim_{n\to \infty} l_n(g) g l V \{g \in V \mid lim_{x\to \infty}g(x)\text{ and }\lim_{x \to -\infty}g(x) \text{ exist.}\} l_n(g) V l_n(g) (l_{n_k})_{k\in \Bbb{N}} * g \in V l_{n_k}(g) (l_{n_k}) g \in V l_n L^1 l_n(x) = \frac{1}{2n}\chi_{[-n,n]}(x) * l_n L^1 l_n(x) \to 0 L^1 L^1 g \equiv 1 1 l_n(g) = 1 \, \forall n \in \Bbb{N} l_n V^* * * (L^\infty)^* * l_n L^1 * (L^\infty)^* L^1 L^1","['functional-analysis', 'weak-convergence']"
81,Relation between the Hilbert-Hankel operator and Laplace transform on $L^2(\mathbb R_{>0})$,Relation between the Hilbert-Hankel operator and Laplace transform on,L^2(\mathbb R_{>0}),"Let $\mathbb R_{>0} = (0, \infty)$ . The Hilbert-Hankel operator $H$ is the integral kernel operator on $L^2(\mathbb R_{>0})$ defined as $$(Hf)(x) = \int_0^\infty \frac{f(y)}{x+y}\, dy$$ Prove that $H = \mathcal L^2$ , where $\mathcal L$ is (the Laplace transform) the integral kernel operator on $L^2(\mathbb R_{>0})$ defined as $$(\mathcal L f)(x) = \int_0^\infty e^{-xy} f(y)\, dy$$ Thus, conclude that $\|H\| =  \pi$ . Questions : The task is to show that $\mathcal L$ is a square root of the Hilbert-Hankel operator, i.e. $H = \mathcal L^2$ . Is this square root unique , i.e. does it make sense to define $H^{1/2}:= \mathcal L$ ? Is my proof (in particular the applicability of Fubini's theorem) correct? I worry because $\frac{1}{\sqrt x} \to \infty$ as $x\to 0$ , so I am not sure if Fubini's theorem is really applicable? Although, we only have to fix $x \in (0, \infty)$ and then evaluate the integrals - in which case, $\frac{1}{\sqrt x}$ is certainly just a finite number. So I wonder, are there any interesting results known about $\mathcal L^n$ , for $n\in \mathbb N$ ? Also, can we find the $n$ th root of the Hilbert-Hankel operator, i.e. what is $H^{1/n}$ for $n\in \mathbb N$ ? My work: If $H = \mathcal L^2$ , it is easy to see that $\|H\| = \|\mathcal L^2\| = \|\mathcal L\|^2 = \pi$ . This follows since $\|\mathcal L\| = \sqrt\pi$ and $\mathcal L$ is self-adjoint, as shown in this post. For self-adjoint operators $A$ (and more generally, for normal operators) it is true that $\|A\|^2 = \|A^2\|$ . The main effort lies in showing $H = \mathcal L^2$ . Directly from definitions, we have $$\begin{align} \mathcal L^2f(x) &= \int_0^\infty \int_0^\infty e^{-xy-yz} f(z)\, dz\, dy\\ &= \int_0^\infty\int_0^\infty e^{-xy-yz} f(z)\, dy\, dz\\ &= \int_0^\infty f(z) \int_0^\infty e^{-xy-yz} \, dy \, dz\\ &= \int_0^\infty \frac{f(z)}{x+z}\, dz\\ &= Hf(x) \end{align}$$ where we have used Fubini's theorem. Fubini's theorem is applicable because $$\begin{align} \int_0^\infty\int_0^\infty e^{-xy-yz} |f(z)| dz dy &\le \|f\|_2 \int_0^\infty \left(\int_0^\infty e^{-2xy-2yz} \, dz\right)^{1/2}\, dy\\ &= \|f\|_2 \int_0^\infty \frac{e^{-xy}}{\sqrt{2y}}\, dy \\ &= \sqrt{\frac{\pi}{2x}} \|f\|_2 < \infty  \end{align}$$ for $0 < x < \infty$ . Thanks a lot!","Let . The Hilbert-Hankel operator is the integral kernel operator on defined as Prove that , where is (the Laplace transform) the integral kernel operator on defined as Thus, conclude that . Questions : The task is to show that is a square root of the Hilbert-Hankel operator, i.e. . Is this square root unique , i.e. does it make sense to define ? Is my proof (in particular the applicability of Fubini's theorem) correct? I worry because as , so I am not sure if Fubini's theorem is really applicable? Although, we only have to fix and then evaluate the integrals - in which case, is certainly just a finite number. So I wonder, are there any interesting results known about , for ? Also, can we find the th root of the Hilbert-Hankel operator, i.e. what is for ? My work: If , it is easy to see that . This follows since and is self-adjoint, as shown in this post. For self-adjoint operators (and more generally, for normal operators) it is true that . The main effort lies in showing . Directly from definitions, we have where we have used Fubini's theorem. Fubini's theorem is applicable because for . Thanks a lot!","\mathbb R_{>0} = (0, \infty) H L^2(\mathbb R_{>0}) (Hf)(x) = \int_0^\infty \frac{f(y)}{x+y}\, dy H = \mathcal L^2 \mathcal L L^2(\mathbb R_{>0}) (\mathcal L f)(x) = \int_0^\infty e^{-xy} f(y)\, dy \|H\| =  \pi \mathcal L H = \mathcal L^2 H^{1/2}:= \mathcal L \frac{1}{\sqrt x} \to \infty x\to 0 x \in (0, \infty) \frac{1}{\sqrt x} \mathcal L^n n\in \mathbb N n H^{1/n} n\in \mathbb N H = \mathcal L^2 \|H\| = \|\mathcal L^2\| = \|\mathcal L\|^2 = \pi \|\mathcal L\| = \sqrt\pi \mathcal L A \|A\|^2 = \|A^2\| H = \mathcal L^2 \begin{align}
\mathcal L^2f(x) &= \int_0^\infty \int_0^\infty e^{-xy-yz} f(z)\, dz\, dy\\ &= \int_0^\infty\int_0^\infty e^{-xy-yz} f(z)\, dy\, dz\\
&= \int_0^\infty f(z) \int_0^\infty e^{-xy-yz} \, dy \, dz\\ &= \int_0^\infty \frac{f(z)}{x+z}\, dz\\ &= Hf(x)
\end{align} \begin{align}
\int_0^\infty\int_0^\infty e^{-xy-yz} |f(z)| dz dy &\le \|f\|_2 \int_0^\infty \left(\int_0^\infty e^{-2xy-2yz} \, dz\right)^{1/2}\, dy\\ &= \|f\|_2 \int_0^\infty \frac{e^{-xy}}{\sqrt{2y}}\, dy \\ &= \sqrt{\frac{\pi}{2x}} \|f\|_2 < \infty 
\end{align} 0 < x < \infty","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'harmonic-analysis', 'fubini-tonelli-theorems']"
82,Some Geometric intuition behind self-adjoint operators,Some Geometric intuition behind self-adjoint operators,,"In my Functional Analysis class, we have been studying self-adjoint compact operators for the past week or so (more specifically their spectrums). I have a geometric idea of what it means for an operator to be compact (the image of any subset is relatively compact in the codomain) and I have a vague geometric notion of the adjoint in my head (define a new operator whose image is the complement of the original operator's kernel and vice versa). I'd like some intuition for what exactly it means for an operator in a Hilbert space to be self-adjoint . Obviously this isn't a question with a right answer; I'd just like to know how people think about/visualize self-adjointness, and I'd appreciate the thoughts of anyone who's tried to do so!","In my Functional Analysis class, we have been studying self-adjoint compact operators for the past week or so (more specifically their spectrums). I have a geometric idea of what it means for an operator to be compact (the image of any subset is relatively compact in the codomain) and I have a vague geometric notion of the adjoint in my head (define a new operator whose image is the complement of the original operator's kernel and vice versa). I'd like some intuition for what exactly it means for an operator in a Hilbert space to be self-adjoint . Obviously this isn't a question with a right answer; I'd just like to know how people think about/visualize self-adjointness, and I'd appreciate the thoughts of anyone who's tried to do so!",,"['functional-analysis', 'soft-question', 'intuition', 'adjoint-operators']"
83,How is this property equivalent to the Reiter Property?,How is this property equivalent to the Reiter Property?,,"We have the Reiter Property $(R_2)$ for an action of a group G on a set X: For any $\epsilon>0$ , any finite subset $S$ of G, there exists $\phi\in{\ell^2(X)}$ such that $\|s\phi-\phi\|_{\ell^2}<\epsilon{\|\phi\|_{\ell^2}}$ for all $s\in{S}$ . I am trying to show this is equivalent to the alternative property $(R_2)'$ : for any $\epsilon>0$ , any finite subset $S$ of G, there exists $\phi\in{\ell^2(X)}$ such that $$\left\|\frac{1}{|S|}\sum_{s\in{S}}{s\phi}\right\|_{\ell^2}>(1-\epsilon)\|\phi\|_{\ell^2}$$ but I am completely stuck. I have tried using some uniform convexity since $\ell^2$ has an inner product, but can only get anything out of it when $|S|=2$ , I have heard from someone else that this is related to adjoint operators, so I have tried defining $T:\ell^2(X)\rightarrow\ell^2(X)$ by $T(\phi)=\frac{1}{|S|}\sum_{s\in{S}}{s\phi}$ and can deduce that it has norm 1 and, if we extend S to also contain the inverses of all its elements, is self adjoint, but I can't see how this could be helpful to solve the problem. Many thanks.","We have the Reiter Property for an action of a group G on a set X: For any , any finite subset of G, there exists such that for all . I am trying to show this is equivalent to the alternative property : for any , any finite subset of G, there exists such that but I am completely stuck. I have tried using some uniform convexity since has an inner product, but can only get anything out of it when , I have heard from someone else that this is related to adjoint operators, so I have tried defining by and can deduce that it has norm 1 and, if we extend S to also contain the inverses of all its elements, is self adjoint, but I can't see how this could be helpful to solve the problem. Many thanks.",(R_2) \epsilon>0 S \phi\in{\ell^2(X)} \|s\phi-\phi\|_{\ell^2}<\epsilon{\|\phi\|_{\ell^2}} s\in{S} (R_2)' \epsilon>0 S \phi\in{\ell^2(X)} \left\|\frac{1}{|S|}\sum_{s\in{S}}{s\phi}\right\|_{\ell^2}>(1-\epsilon)\|\phi\|_{\ell^2} \ell^2 |S|=2 T:\ell^2(X)\rightarrow\ell^2(X) T(\phi)=\frac{1}{|S|}\sum_{s\in{S}}{s\phi},"['functional-analysis', 'group-theory', 'group-actions', 'fixed-point-theorems', 'amenability']"
84,Abelian C*-algebras are stably finite?,Abelian C*-algebras are stably finite?,,"I would like to know if the following is true: Is every abelian $C^*$ -algebra stably finite? I could not find this in any book, so I am a little suspicious about the following argument I came up with: Since a $C^*$ -algebra is stably finite if-f it's unitization is stably finite and using Gelfand's theorem, we have only to deal with $C^*$ -algebras of the form $C(X)$ , where $X$ is a compact, Hausdorff space. Now it is a known fact that, if $A$ is a unital $C^*$ -algebra, then $A$ is finite if and only if $s^*s=1_A\implies ss^*=1_A$ for all $s\in A$ , i.e. every isometry is a unitary. Let $n\geq1$ . We have that $M_n(C(X))\cong C(X,M_n(\mathbb{C}))$ . Now let $s\in C(X,M_n(\mathbb{C}))$ be an isometry, i.e. $s^*s=1_{C(X,M_n)}$ , i.e. $s(x)^*s(x)=1_{M_n}$ for all $x\in X$ . Since $M_n(\mathbb{C})$ is finite (obviously) we conclude that $s(x)s(x)^*=1_{M_n}$ for all $x\in X$ , thus $ss^*=1_{C(X,M_n)}$ and this shows that $C(X)$ is stably finite. Is this correct or am I missing something? Anyone knows of any resource that refers to this? Edit: I can think of a second proof for the separable case (i.e. if-f $X$ is metrizable): if so, then $C(X)$ admits a faithful tracial state and then so do $M_n(C(X))$ , so all of those are finite $C^*$ -algebras. And even more generally, it seems like $C(X,A)$ is stably finite whenever $A$ is (since $M_n(C(X,A))\cong M_n\otimes C(X)\otimes A\cong C(X)\otimes M_n(A)\cong C(X,M_n(A))$ ).","I would like to know if the following is true: Is every abelian -algebra stably finite? I could not find this in any book, so I am a little suspicious about the following argument I came up with: Since a -algebra is stably finite if-f it's unitization is stably finite and using Gelfand's theorem, we have only to deal with -algebras of the form , where is a compact, Hausdorff space. Now it is a known fact that, if is a unital -algebra, then is finite if and only if for all , i.e. every isometry is a unitary. Let . We have that . Now let be an isometry, i.e. , i.e. for all . Since is finite (obviously) we conclude that for all , thus and this shows that is stably finite. Is this correct or am I missing something? Anyone knows of any resource that refers to this? Edit: I can think of a second proof for the separable case (i.e. if-f is metrizable): if so, then admits a faithful tracial state and then so do , so all of those are finite -algebras. And even more generally, it seems like is stably finite whenever is (since ).","C^* C^* C^* C(X) X A C^* A s^*s=1_A\implies ss^*=1_A s\in A n\geq1 M_n(C(X))\cong C(X,M_n(\mathbb{C})) s\in C(X,M_n(\mathbb{C})) s^*s=1_{C(X,M_n)} s(x)^*s(x)=1_{M_n} x\in X M_n(\mathbb{C}) s(x)s(x)^*=1_{M_n} x\in X ss^*=1_{C(X,M_n)} C(X) X C(X) M_n(C(X)) C^* C(X,A) A M_n(C(X,A))\cong M_n\otimes C(X)\otimes A\cong C(X)\otimes M_n(A)\cong C(X,M_n(A))","['functional-analysis', 'solution-verification', 'operator-algebras', 'c-star-algebras']"
85,Why is Banach-Alaoglu theorem so important?,Why is Banach-Alaoglu theorem so important?,,"According to Lawrence Narici and Edward Beckenstein, the Alaoglu theorem is a ""very important result - maybe the most important fact about the weak-* topology - [that] echos throughout functional analysis."" (Source: Wikipedia) It is a well-known fact (by Riesz) that the compactness of the unit ball with respect to the norm topology characterizes finite dimensional vector spaces. In a infinite dimensional setting, Banach-Alaoglu recovers the compactness of the unit ball in the weak*-topology which seems to come to relief of a lot of analyst. I have come across a thread recently about the importance of Hahn-Banach which I found very illuminating. I would be interested about the different takes people have on Banach-Alaoglu. Why is it so important? What if we were not to recover the compactness of the unit ball?","According to Lawrence Narici and Edward Beckenstein, the Alaoglu theorem is a ""very important result - maybe the most important fact about the weak-* topology - [that] echos throughout functional analysis."" (Source: Wikipedia) It is a well-known fact (by Riesz) that the compactness of the unit ball with respect to the norm topology characterizes finite dimensional vector spaces. In a infinite dimensional setting, Banach-Alaoglu recovers the compactness of the unit ball in the weak*-topology which seems to come to relief of a lot of analyst. I have come across a thread recently about the importance of Hahn-Banach which I found very illuminating. I would be interested about the different takes people have on Banach-Alaoglu. Why is it so important? What if we were not to recover the compactness of the unit ball?",,['functional-analysis']
86,What can be said of Neumann eigenfunctions with non-vanishing derivative?,What can be said of Neumann eigenfunctions with non-vanishing derivative?,,"There is a theorem which states that if $f$ is an eigenfunction of the Dirichlet problem of the Laplacian: $$-\Delta f =\lambda f$$ $$f|_{\partial \Omega }=0$$ Then if $f$ has a single nodal domain (meaning, the set { $x\in \Omega|f(x)\neq 0$ } has a single connected component), then the corresponding eigenvalue $\lambda$ is the first eigenvalue of the Laplacian, and it is a simple eigenvalue. I was wondering if there is a similar result for the case where instead of the Dirichlet problem we're looking at the Neumann problem (where the normal derivative of $f$ vanishes at the boundary), and we replace the assumption that $f$ has a single nodal domain with the assumption that the derivative of $f$ does not vanish in $\Omega$ (only at the boundary). Can I say anything 'interesting' about the eigenfunction/eigenvalue in this case? The proof I know of the theorem above (which uses orthogonality of the eigenfunctions) cannot be applied for this case since $f$ does not have a constant sign in $\Omega$ . I know that in the Neumann case, the first eigenvalue must be $0$ , so unless $f$ is constant (and we assume it's not, since it's derivative does not vanish) then the eigenvalue $\lambda$ will definitely not be the first eigenvalue. But maybe it has to be the second? Or maybe it still needs to be simple or something? If anyone knows of a relevant result (or an interesting counter example) - please let me know. I'm looking for anything which can be said about $f$ or $\lambda$ based on only the given assumptions. I'm interested mainly in results for manifolds and metric graphs, but feel free to share anything related. Thanks a lot in advance.","There is a theorem which states that if is an eigenfunction of the Dirichlet problem of the Laplacian: Then if has a single nodal domain (meaning, the set { } has a single connected component), then the corresponding eigenvalue is the first eigenvalue of the Laplacian, and it is a simple eigenvalue. I was wondering if there is a similar result for the case where instead of the Dirichlet problem we're looking at the Neumann problem (where the normal derivative of vanishes at the boundary), and we replace the assumption that has a single nodal domain with the assumption that the derivative of does not vanish in (only at the boundary). Can I say anything 'interesting' about the eigenfunction/eigenvalue in this case? The proof I know of the theorem above (which uses orthogonality of the eigenfunctions) cannot be applied for this case since does not have a constant sign in . I know that in the Neumann case, the first eigenvalue must be , so unless is constant (and we assume it's not, since it's derivative does not vanish) then the eigenvalue will definitely not be the first eigenvalue. But maybe it has to be the second? Or maybe it still needs to be simple or something? If anyone knows of a relevant result (or an interesting counter example) - please let me know. I'm looking for anything which can be said about or based on only the given assumptions. I'm interested mainly in results for manifolds and metric graphs, but feel free to share anything related. Thanks a lot in advance.",f -\Delta f =\lambda f f|_{\partial \Omega }=0 f x\in \Omega|f(x)\neq 0 \lambda f f f \Omega f \Omega 0 f \lambda f \lambda,"['functional-analysis', 'partial-differential-equations', 'operator-theory', 'boundary-value-problem', 'laplacian']"
87,"Convolution of tempered distribution($K$) and gaussian. if $K = K*e^{-\pi |x|^2}$, then $K$ is first degree polynomial.","Convolution of tempered distribution() and gaussian. if , then  is first degree polynomial.",K K = K*e^{-\pi |x|^2} K,"Q : I need to prove that if $K$ is tempered distribution on $\mathbb{R}$ satisfying: \begin{equation} K = K*e^{-\pi |x|^2} \end{equation} then $K$ is first degree polynomial. mean $K(x) = Ax + b$ Remark: The question was changed. The original was to prove that if $K = K * e^{-\pi |x|^2}$ then $K$ is constant, which is false. The first thing I did is to apply fourier transform on both sides to work with multiplication instead of convolution. and I got $\hat{K} = e^{-\pi |x|^2} \hat{K}$ . I succeeded to prove $\hat{K}$ is supported at the origin and by theorem 1.7 at page 110, from Stein and Shakarchi functional analysis(Can't find the pdf online) or theorem 6.25 at page 165 from Rudin Functional analysis : \begin{equation} \hat{K} =\sum_{|\alpha| \leq N} a_{\alpha} \partial^{\alpha}\delta \end{equation} . Now, if I apply the inverse fourier transform I get that $K$ is a polynomial. The solution will arise if I will prove that if $p$ is a polyomial in $\mathbb{R}^{d}$ satisfying $p*e^{-\pi |x|^2} = p$ , then $p$ is constant. It sounds true(which is not, please see the comments) but I think it is kind of ""ugly"" to prove and I am pretty sure that there is another way for me to continue. Hot to continue? Thanks :)","Q : I need to prove that if is tempered distribution on satisfying: then is first degree polynomial. mean Remark: The question was changed. The original was to prove that if then is constant, which is false. The first thing I did is to apply fourier transform on both sides to work with multiplication instead of convolution. and I got . I succeeded to prove is supported at the origin and by theorem 1.7 at page 110, from Stein and Shakarchi functional analysis(Can't find the pdf online) or theorem 6.25 at page 165 from Rudin Functional analysis : . Now, if I apply the inverse fourier transform I get that is a polynomial. The solution will arise if I will prove that if is a polyomial in satisfying , then is constant. It sounds true(which is not, please see the comments) but I think it is kind of ""ugly"" to prove and I am pretty sure that there is another way for me to continue. Hot to continue? Thanks :)","K \mathbb{R} \begin{equation}
K = K*e^{-\pi |x|^2}
\end{equation} K K(x) = Ax + b K = K * e^{-\pi |x|^2} K \hat{K} = e^{-\pi |x|^2} \hat{K} \hat{K} \begin{equation}
\hat{K} =\sum_{|\alpha| \leq N} a_{\alpha} \partial^{\alpha}\delta
\end{equation} K p \mathbb{R}^{d} p*e^{-\pi |x|^2} = p p","['functional-analysis', 'distribution-theory', 'convolution', 'harmonic-analysis', 'gaussian']"
88,Convergence in a generating algebra $\Rightarrow$ convergence in the weak* topology?,Convergence in a generating algebra  convergence in the weak* topology?,\Rightarrow,"Let $M$ be a compact metric space and $\mathcal{B}$ its Borelian $\sigma$ -algebra. Consider $\{\mu_{n}\}_{n\in\mathbb N}$ as a sequence of Borelian probabilities on $M$ . Suppose that there exists a Borelian probability $\mu$ on $M$ and a generating algebra $\mathcal{A}$ ( i.e. $\mathcal A$ is an algebra and $\sigma(\mathcal{A}) = \mathcal B$ ) such that $$\mu_n(A)\longrightarrow \mu(A),\ \forall\ A\in \mathcal A\ \text{and}\ \mu(\partial A)=0,\  \forall \ A\in\mathcal{A}. \quad \quad      (*)$$ I would like to know if $(*)$ implies that $\mu_n\to\mu$ in the weak* topology, i.e. for every continuous function $f: M \to \mathbb R$ $$\int_M f\ \text{d}\mu_n \longrightarrow \int_M f\ \text{d}\mu. $$ My attempt I tried to use the monotone class theorem for functions . I defined the set $$\mathcal H:=\left\{f:M\to\mathbb R;\ f \text{ is bounded, measurable and }\int_M f\ \text{d}\mu_n \longrightarrow \int_M f\ \text{d}\mu\right\}. $$ So if we prove that if $A\in \mathcal A\Rightarrow$ $1_A \in \mathcal H,$ if $f,g\in\mathcal H$ $\Rightarrow$ $f+cg \in\mathcal{H}$ , for any real number $c$ , if $f_n \in \mathcal{H}$ is a sequence of non-negative functions that increase to a bounded function $f$ $\Rightarrow$ $f \in \mathcal{H}$ , holds then, by the monotone class theorem for functions, $\mathcal H$ will all the bounded measurable functions, and we are done. The conditions $1$ and $2$ are obvious to be checked. However, I was not able to conclude the last condition. Can anyone help me? Edit: I was thinking and this approach does not make sense since the condition that I am trying to check is a way stronger than convergence in the weak* topology.","Let be a compact metric space and its Borelian -algebra. Consider as a sequence of Borelian probabilities on . Suppose that there exists a Borelian probability on and a generating algebra ( i.e. is an algebra and ) such that I would like to know if implies that in the weak* topology, i.e. for every continuous function My attempt I tried to use the monotone class theorem for functions . I defined the set So if we prove that if if , for any real number , if is a sequence of non-negative functions that increase to a bounded function , holds then, by the monotone class theorem for functions, will all the bounded measurable functions, and we are done. The conditions and are obvious to be checked. However, I was not able to conclude the last condition. Can anyone help me? Edit: I was thinking and this approach does not make sense since the condition that I am trying to check is a way stronger than convergence in the weak* topology.","M \mathcal{B} \sigma \{\mu_{n}\}_{n\in\mathbb N} M \mu M \mathcal{A} \mathcal A \sigma(\mathcal{A}) = \mathcal B \mu_n(A)\longrightarrow \mu(A),\ \forall\ A\in \mathcal A\ \text{and}\ \mu(\partial A)=0,\  \forall \ A\in\mathcal{A}. \quad \quad      (*) (*) \mu_n\to\mu f: M \to \mathbb R \int_M f\ \text{d}\mu_n \longrightarrow \int_M f\ \text{d}\mu.  \mathcal H:=\left\{f:M\to\mathbb R;\ f \text{ is bounded, measurable and }\int_M f\ \text{d}\mu_n \longrightarrow \int_M f\ \text{d}\mu\right\}.  A\in \mathcal A\Rightarrow 1_A \in \mathcal H, f,g\in\mathcal H \Rightarrow f+cg \in\mathcal{H} c f_n \in \mathcal{H} f \Rightarrow f \in \mathcal{H} \mathcal H 1 2","['functional-analysis', 'measure-theory', 'ergodic-theory']"
89,"Show that a set is compact on $C^K[0,1]$",Show that a set is compact on,"C^K[0,1]","Show that the set of the functions $A_M:=\{f ∈ C^{k+1}([0, 1]) : \|f\|_{C^{K+1}} ≤ M\}$ is compact in $C^{k}[0,1]\ \  \forall M \geq 0$ . N.B.: $$\| f\|_{C^{K+1}}=\|f\|_{C^{0}}+\|f^{(k+1)}\|_{C^{0}}$$ I started by showing that $C^{k}[0,1]$ is complete with the $C^{k}$ norm. I'd like to use this to show that the set is complete. Then prove that it is totally bounded and so compact. But I don't have an idea of how to do it... Thanks.",Show that the set of the functions is compact in . N.B.: I started by showing that is complete with the norm. I'd like to use this to show that the set is complete. Then prove that it is totally bounded and so compact. But I don't have an idea of how to do it... Thanks.,"A_M:=\{f ∈ C^{k+1}([0, 1]) : \|f\|_{C^{K+1}} ≤ M\} C^{k}[0,1]\ \  \forall M \geq 0 \| f\|_{C^{K+1}}=\|f\|_{C^{0}}+\|f^{(k+1)}\|_{C^{0}} C^{k}[0,1] C^{k}",['functional-analysis']
90,Exact coefficient in equivalence of norm in finite dimensional space.,Exact coefficient in equivalence of norm in finite dimensional space.,,"Let $X$ be a $d$ -dimensional Banach space with norm $\| \cdot \|$ and bases $e _1 , e _2 , \ldots , e _ d$ .  By the equivalence of all norms in finite dimensional space, there exists $c> 0$ such that $$ \left \| \sum ^{d}_{i=1} \lambda _i e _i \right \| \geq c \sqrt{\sum ^{d}_{i=1} \lambda ^2 _i}  $$ holds for any real numbers $\lambda _1 , \lambda _2 ,\ldots ,\lambda _d$ . As far as I see the proof, constant $c> 0$ possibly depends on the choice of basis and it is difficult to deduce explicit formula of $c $ . However, in J. Lindenstrauss, Bull. Amer. Math. Soc. 72 (1966), 967–970, the following fact is used: there exist a basis $e ' _1 , e '_2 , \ldots , e '_ d$ such that $\| e '_i \| =1 $ and $$ \left \| \sum ^{d}_{i=1} \lambda _i e' _i \right \| \geq \frac{ \sqrt{\sum ^{d}_{i=1} \lambda ^2 _i} }{d^2} $$ holds for any $\lambda _1 , \lambda _2 ,\ldots ,\lambda _d$ . This mean that we can choose a suitable normal basis so that we can take $c = 1 / d ^2 $ above. Do you know how to prove it or construct such a basis that $c$ only depends on the dimension $d$ (not necessarily $c =1 / d^ 2 $ )?","Let be a -dimensional Banach space with norm and bases .  By the equivalence of all norms in finite dimensional space, there exists such that holds for any real numbers . As far as I see the proof, constant possibly depends on the choice of basis and it is difficult to deduce explicit formula of . However, in J. Lindenstrauss, Bull. Amer. Math. Soc. 72 (1966), 967–970, the following fact is used: there exist a basis such that and holds for any . This mean that we can choose a suitable normal basis so that we can take above. Do you know how to prove it or construct such a basis that only depends on the dimension (not necessarily )?","X d \| \cdot \| e _1 , e _2 , \ldots , e _ d c> 0 
\left \| \sum ^{d}_{i=1} \lambda _i e _i \right \|
\geq c \sqrt{\sum ^{d}_{i=1} \lambda ^2 _i} 
 \lambda _1 , \lambda _2 ,\ldots ,\lambda _d c> 0 c  e ' _1 , e '_2 , \ldots , e '_ d \| e '_i \| =1  
\left \| \sum ^{d}_{i=1} \lambda _i e' _i \right \|
\geq \frac{ \sqrt{\sum ^{d}_{i=1} \lambda ^2 _i} }{d^2}
 \lambda _1 , \lambda _2 ,\ldots ,\lambda _d c = 1 / d ^2  c d c =1 / d^ 2 ","['functional-analysis', 'banach-spaces', 'normed-spaces']"
91,Computing a Feynman integral,Computing a Feynman integral,,"Reading the lectures notes by A. Connes and M. Marcolli I have some difficulty undestanding how they compute the Feynman integrals using integration by parts. Consider the following integral of formulas (1.32), (1.34): $$   I = \mathcal N_0∫ φ(x)φ(y) \, \exp(iS_0(φ)) \, \mathcal D[φ], $$ where $\mathcal N_0$ is a normalization factor $$   \mathcal N_0^{-1} = ∫ \exp(iS_0(φ)) \, \mathcal D[φ], $$ and $$   S_O(φ) = (2\pi)^{-D} ∫ \frac 1 2 (p^2 - m^2) \hat φ(p) \hat φ(-p) \, d^D p, \\ \hat φ(p) = ∫ \exp(-i p x) φ(x) \, d^D x. $$ The authors say that using formal integration by parts (note that the the integrand is a product of two linear forms in the fields times the exponent of a quadratic form in the fields) one gets something like: $$ I = i (2\pi)^D ∫ \frac{\delta(p_1+p_2)}{p_1^2-m^2} e^{\pm ip(x-y)} d^D p_1 d^D p_2 $$ I do not understand this computation. Could you please explain it?","Reading the lectures notes by A. Connes and M. Marcolli I have some difficulty undestanding how they compute the Feynman integrals using integration by parts. Consider the following integral of formulas (1.32), (1.34): where is a normalization factor and The authors say that using formal integration by parts (note that the the integrand is a product of two linear forms in the fields times the exponent of a quadratic form in the fields) one gets something like: I do not understand this computation. Could you please explain it?","
  I = \mathcal N_0∫ φ(x)φ(y) \, \exp(iS_0(φ)) \, \mathcal D[φ],
 \mathcal N_0 
  \mathcal N_0^{-1} = ∫ \exp(iS_0(φ)) \, \mathcal D[φ],
 
  S_O(φ) = (2\pi)^{-D} ∫ \frac 1 2 (p^2 - m^2) \hat φ(p) \hat φ(-p) \, d^D p, \\
\hat φ(p) = ∫ \exp(-i p x) φ(x) \, d^D x.
 
I = i (2\pi)^D ∫ \frac{\delta(p_1+p_2)}{p_1^2-m^2} e^{\pm ip(x-y)} d^D p_1 d^D p_2
","['functional-analysis', 'quantum-mechanics', 'quantum-field-theory']"
92,Is Lax-Miligram theorem a generalization of Riesz representation?,Is Lax-Miligram theorem a generalization of Riesz representation?,,"Let $H$ a hilbert space with inner product $\left<.,.\right>$ . We denote $\|\cdot \|$ the norm induced by the inner product. Lax-miligram tels us that there is a one-to-one correspondance between Continuous and elliptic bilinear form $a:H\times H\to \mathbb R$ and continuous linear functional $L:H\to \mathbb R$ . I.e. that if $a$ is continuous (i.e. $a(u,v)\leq K\|u\|\|v\|$ ), elliptic (i.e. $a(u,u)\geq C\|u\|^2$ ) and if $L$ is a $L:H\to \mathbb R$ is continuous an linear, then there is a unique $u\in H$ s.t. for all $v\in H$ , $$a(u,v)=L(v).$$ Is this a sort of generalization of Riezs representation theorem ? Because it looks very similar, but a bit more general.","Let a hilbert space with inner product . We denote the norm induced by the inner product. Lax-miligram tels us that there is a one-to-one correspondance between Continuous and elliptic bilinear form and continuous linear functional . I.e. that if is continuous (i.e. ), elliptic (i.e. ) and if is a is continuous an linear, then there is a unique s.t. for all , Is this a sort of generalization of Riezs representation theorem ? Because it looks very similar, but a bit more general.","H \left<.,.\right> \|\cdot \| a:H\times H\to \mathbb R L:H\to \mathbb R a a(u,v)\leq K\|u\|\|v\| a(u,u)\geq C\|u\|^2 L L:H\to \mathbb R u\in H v\in H a(u,v)=L(v).",['functional-analysis']
93,Alternative proof of Taylor's formula by only using the linear approximation property,Alternative proof of Taylor's formula by only using the linear approximation property,,"So a function $f: E \to F$ between the normed spaces $E,F$ is called differentiable in $x \in E$ if there exists a bounded linear map $Df(x): E \to F$ such that for every $h \in E$ we have $$f(x+h)=f(x)+Df(x)h + o(||h||). \tag{1}$$ If $f$ is differentiable for every $x \in E$ and $Df: x \mapsto Df(x)$ is differentiable for every $x \in E$ too we get analogously $$Df(x+e)=Df(x)+D^2f(x)e+o(||e||). \tag{2}$$ Then $f$ is called twice differentiable and for every $h\in E$ we have the ""Taylor expansion of second degree"" $$f(x+h)=f(x)+Df(x)h+\frac{1}{2}D^2f(x)[h] + o(||h||^2), \tag{3}$$ where $D^2f(x)[h]:=(D^2f(x)h)h$ for better readability. I have two questions: How can $(3)$ be proven without resorting to the ""standard proof"" of using integrals? I want to show it by only using the linear approximations  given in $(1)$ and $(2)$ . Inserting $(2)$ in $(1)$ doesn't result in something useful though. Can this be done? Can $(3)$ be used as an alternative definition off twice-differentiability? Analogously what about  the general case of $n$ -times differentiability: $$ f(x+h) = f(x) + \sum_{j=1}^{n} \frac{1}{j!} D^jf(x)[h] + o(\|h\|^n) \tag{4}$$","So a function between the normed spaces is called differentiable in if there exists a bounded linear map such that for every we have If is differentiable for every and is differentiable for every too we get analogously Then is called twice differentiable and for every we have the ""Taylor expansion of second degree"" where for better readability. I have two questions: How can be proven without resorting to the ""standard proof"" of using integrals? I want to show it by only using the linear approximations  given in and . Inserting in doesn't result in something useful though. Can this be done? Can be used as an alternative definition off twice-differentiability? Analogously what about  the general case of -times differentiability:","f: E \to F E,F x \in E Df(x): E \to F h \in E f(x+h)=f(x)+Df(x)h + o(||h||). \tag{1} f x \in E Df: x \mapsto Df(x) x \in E Df(x+e)=Df(x)+D^2f(x)e+o(||e||). \tag{2} f h\in E f(x+h)=f(x)+Df(x)h+\frac{1}{2}D^2f(x)[h] + o(||h||^2), \tag{3} D^2f(x)[h]:=(D^2f(x)h)h (3) (1) (2) (2) (1) (3) n  f(x+h) = f(x) + \sum_{j=1}^{n} \frac{1}{j!} D^jf(x)[h] + o(\|h\|^n) \tag{4}","['functional-analysis', 'taylor-expansion', 'banach-spaces', 'alternative-proof', 'frechet-derivative']"
94,Is the space of real sequences normable,Is the space of real sequences normable,,"Intuition says the vector space of real sequences $R^N$ ( $N$ the natural numbers, pointwise addition of real coordinates) is not normable. I have found this surprisingly hard to prove. I am aware that $R^N$ in the product (Tychonoff) topology is not normable (but metrizable i.e. is a Frechet space). This is proven for instance in Aliprantis–Border: Infinite Dimensional Analysis (2006, p. 207), a reference which I found on Is a metrizable topological vector space normable? in the answer by @triple_sec which I understand and appreciate. However, this leaves open whether a TVS topology on $R^N$ stronger than the product topology could be normable. Here are my attempts to prove there is no norm defined everywhere on $R^N$ making it a TVS with topology at least as strong as the product topology i.e. with continuous coordinate functions. I aim for an indirect proof: assume there is a norm on $R^N$ and try to get a contradiction. a) Banach space arguments: complete the normed space and apply Banach space technology like Uniform Boundedness, Open Mapping etc.. I could not find any proof along this line. (In particular, I found it hard to control whether the completion of $R^N$ in the assumed norm would not make the original normed space ""bigger"" i.e. adding ideal points outside of $R^N$ ). But since experts in the field might well know a good argument, I mention the attempt. b) Geometric argument - construct a vector with an infinite norm: begin with the ""unit"" vectors $e_n = (0,..., 1, 0, ...) \in R^N, n\in N$ with a $1$ in the n-th coordinate and $0$ elsewhere. Rescale every $e_n$ to have the norm $||e_n||=1$ which is just a coordinate change. Now try $v=(1, 2, 3, ...) \in R^N$ to obtain a vector $v$ with norm $||v||\geq n$ $\forall n$ - are we done? I think no, because the norm $||v||$ of a vector $v=(p_1, p_2, p_3, ...)$ with non-negative real coordinates $p_i, i\in N$ is in general (unlike in the standard sequence spaces $l^p$ ) not a non-decreasing function of its real coordinates. So I wonder how to argue strictly that $||v||\geq n$ $\forall n$ . I tried flipping the signs of each coordinate i.e. consider $v=(\pm 1, \pm 2, \pm 3, ...)$ and use the fact that for arbitrary $v, x$ in a normed space one of $||v+x||$ and $||v-x||$ must be not smaller than $||v||$ and $||x||$ (triangle inequality). But to generate an optimal $v$ with maximal (infinite) norm $||v||$ I face (countably) infinitely many flips depending all on each other. I have no idea how to control (countably) infinitely many sign flips to make such an argument rigorous, but perhaps somebody else has. The idea seems to be included in the answer of @David C. Ullrich to Can the real vector space of all real sequences be normed so that it is complete ? . There is also an answer and a comment by @paul garrett which indicates what I am trying to prove here is an obvious matter of fact to the experts. However LF-spaces are currently too advanced for me, so I tried the same geometric argument one more time, but now ""weakly"": c) Geometric argument - construct a ""weakly unbounded"" vector: we start again with unit vectors $e_n, n\in N$ like in b), and take the dual sequence of linear functionals $p_n\in (R^N)^*, \forall n \in N$ projecting an arbitrary vector $v$ to its $n$ th coordinate. These coordinate functionals are continuous by assumption, and since $p_n(e_n)=1$ , the functional norm $||p_n||$ is $\geq 1$ . Now we consider the vector $v=(1||p_1||, 2||p_2||, 3||p_3||, ..., n||p_n||, ...)$ and estimate $||v||$ from below: $||v|| \geq |p_n(v)|/||p_n|| =n$ $\forall n \in N$ . My question: is the geometric argument in (c) good enough for a reasonable proof? Remark upon my original motivation: reading that a product of barreled spaces is barrelled - ""Un produit d'espaces tonnelés est tonnelé."" on the french https://fr.wikipedia.org/wiki/Espace_tonnel%C3%A9 (the fact is not yet on the english page https://en.wikipedia.org/wiki/Barrelled_space ) I tried to prove this. I looked at $R^N$ as one of the simplest non-trivial examples of a product of barrelled spaces: are in there any other barrels except closures of finite products of convex open balls=intervals (all remaining factors equal $R$ )? Answer: there are not. For the ingeneous Bourbaki this was so obvious to write in http://www.numdam.org/article/AIF_1950__2__5_0.pdf on page 6 mere one sentence: ""On montre sans peine que ... tout produit d'espaces tonnelés est tonnelé.""","Intuition says the vector space of real sequences ( the natural numbers, pointwise addition of real coordinates) is not normable. I have found this surprisingly hard to prove. I am aware that in the product (Tychonoff) topology is not normable (but metrizable i.e. is a Frechet space). This is proven for instance in Aliprantis–Border: Infinite Dimensional Analysis (2006, p. 207), a reference which I found on Is a metrizable topological vector space normable? in the answer by @triple_sec which I understand and appreciate. However, this leaves open whether a TVS topology on stronger than the product topology could be normable. Here are my attempts to prove there is no norm defined everywhere on making it a TVS with topology at least as strong as the product topology i.e. with continuous coordinate functions. I aim for an indirect proof: assume there is a norm on and try to get a contradiction. a) Banach space arguments: complete the normed space and apply Banach space technology like Uniform Boundedness, Open Mapping etc.. I could not find any proof along this line. (In particular, I found it hard to control whether the completion of in the assumed norm would not make the original normed space ""bigger"" i.e. adding ideal points outside of ). But since experts in the field might well know a good argument, I mention the attempt. b) Geometric argument - construct a vector with an infinite norm: begin with the ""unit"" vectors with a in the n-th coordinate and elsewhere. Rescale every to have the norm which is just a coordinate change. Now try to obtain a vector with norm - are we done? I think no, because the norm of a vector with non-negative real coordinates is in general (unlike in the standard sequence spaces ) not a non-decreasing function of its real coordinates. So I wonder how to argue strictly that . I tried flipping the signs of each coordinate i.e. consider and use the fact that for arbitrary in a normed space one of and must be not smaller than and (triangle inequality). But to generate an optimal with maximal (infinite) norm I face (countably) infinitely many flips depending all on each other. I have no idea how to control (countably) infinitely many sign flips to make such an argument rigorous, but perhaps somebody else has. The idea seems to be included in the answer of @David C. Ullrich to Can the real vector space of all real sequences be normed so that it is complete ? . There is also an answer and a comment by @paul garrett which indicates what I am trying to prove here is an obvious matter of fact to the experts. However LF-spaces are currently too advanced for me, so I tried the same geometric argument one more time, but now ""weakly"": c) Geometric argument - construct a ""weakly unbounded"" vector: we start again with unit vectors like in b), and take the dual sequence of linear functionals projecting an arbitrary vector to its th coordinate. These coordinate functionals are continuous by assumption, and since , the functional norm is . Now we consider the vector and estimate from below: . My question: is the geometric argument in (c) good enough for a reasonable proof? Remark upon my original motivation: reading that a product of barreled spaces is barrelled - ""Un produit d'espaces tonnelés est tonnelé."" on the french https://fr.wikipedia.org/wiki/Espace_tonnel%C3%A9 (the fact is not yet on the english page https://en.wikipedia.org/wiki/Barrelled_space ) I tried to prove this. I looked at as one of the simplest non-trivial examples of a product of barrelled spaces: are in there any other barrels except closures of finite products of convex open balls=intervals (all remaining factors equal )? Answer: there are not. For the ingeneous Bourbaki this was so obvious to write in http://www.numdam.org/article/AIF_1950__2__5_0.pdf on page 6 mere one sentence: ""On montre sans peine que ... tout produit d'espaces tonnelés est tonnelé.""","R^N N R^N R^N R^N R^N R^N R^N e_n = (0,..., 1, 0, ...) \in R^N, n\in N 1 0 e_n ||e_n||=1 v=(1, 2, 3, ...) \in R^N v ||v||\geq n \forall n ||v|| v=(p_1, p_2, p_3, ...) p_i, i\in N l^p ||v||\geq n \forall n v=(\pm 1, \pm 2, \pm 3, ...) v, x ||v+x|| ||v-x|| ||v|| ||x|| v ||v|| e_n, n\in N p_n\in (R^N)^*, \forall n \in N v n p_n(e_n)=1 ||p_n|| \geq 1 v=(1||p_1||, 2||p_2||, 3||p_3||, ..., n||p_n||, ...) ||v|| ||v|| \geq |p_n(v)|/||p_n|| =n \forall n \in N R^N R","['functional-analysis', 'normed-spaces', 'topological-vector-spaces']"
95,Two PDE for one unknown?,Two PDE for one unknown?,,"Let $x \in (0,L)$ , $t \in (0,T)$ , and let $f_1 = f_1(x,t) \in \mathbb{R}$ , $f_2 = f_2(x,t) \in \mathbb{R}$ , $u^0 = u^0(x) \in \mathbb{R}$ and $g= g(t) \in \mathbb{R}$ be continuous functions. My question is: Can we find a function $u = u(x,t) \in \mathbb{R}$ that satisfies \begin{equation}  \partial_t u(x,t) = u(x,t) f_1(x,t) \qquad \text{in } (0,L)\times(0,T) \end{equation} and \begin{equation}  \partial_x u(x,t) = u(x,t) f_2(x,t) \qquad \text{in } (0,L)\times(0,T) \end{equation} with additional initial and boundary conditions: \begin{align*} u(x,0) &= u^0(x) \qquad \text{for }x \in (0,L)\\ u(0,t) &= g(t) \qquad \text{for }t \in (0,T). \end{align*} (Here $\partial_t$ and $\partial_x$ denote the partial derivative with respect to time and space respectively.) I had though about choosing $u$ as the solution of the transport equation \begin{align*} \begin{cases} \partial_t u + \partial_x u = (f_1+f_2)u & \text{in }(0,L)\times (0,T)\\ u(x,0) = u^0(x) & \text{for }x \in (0,L)\\ u(0,t) = g(t) & \text{for }t \in (0,T). \end{cases} \end{align*} However, I do not know if some supplementary assumption may allow to have $u$ satisfying both equations $\partial_t u = u f_1$ and $\partial_x u = u f_2$ separately. Any suggestion, reference (e.g. where a function has to satisfy two separate equations as for here), explanation of why it is/is not possible, would be welcome. Thank you.","Let , , and let , , and be continuous functions. My question is: Can we find a function that satisfies and with additional initial and boundary conditions: (Here and denote the partial derivative with respect to time and space respectively.) I had though about choosing as the solution of the transport equation However, I do not know if some supplementary assumption may allow to have satisfying both equations and separately. Any suggestion, reference (e.g. where a function has to satisfy two separate equations as for here), explanation of why it is/is not possible, would be welcome. Thank you.","x \in (0,L) t \in (0,T) f_1 = f_1(x,t) \in \mathbb{R} f_2 = f_2(x,t) \in \mathbb{R} u^0 = u^0(x) \in \mathbb{R} g= g(t) \in \mathbb{R} u = u(x,t) \in \mathbb{R} \begin{equation} 
\partial_t u(x,t) = u(x,t) f_1(x,t) \qquad \text{in } (0,L)\times(0,T)
\end{equation} \begin{equation} 
\partial_x u(x,t) = u(x,t) f_2(x,t) \qquad \text{in } (0,L)\times(0,T)
\end{equation} \begin{align*}
u(x,0) &= u^0(x) \qquad \text{for }x \in (0,L)\\
u(0,t) &= g(t) \qquad \text{for }t \in (0,T).
\end{align*} \partial_t \partial_x u \begin{align*}
\begin{cases}
\partial_t u + \partial_x u = (f_1+f_2)u & \text{in }(0,L)\times (0,T)\\
u(x,0) = u^0(x) & \text{for }x \in (0,L)\\
u(0,t) = g(t) & \text{for }t \in (0,T).
\end{cases}
\end{align*} u \partial_t u = u f_1 \partial_x u = u f_2","['functional-analysis', 'partial-differential-equations', 'linear-pde']"
96,Functional analysis on manifolds,Functional analysis on manifolds,,"The basic object of functional analysis is the topological vector space, so vector spaces with some topology, we can add additional structure by introducing metrics etc, but the underlying object is a linear space anyway. I was wondering if there's any field of math that still studies functionals, but defined on manifolds instead of vector spaces.","The basic object of functional analysis is the topological vector space, so vector spaces with some topology, we can add additional structure by introducing metrics etc, but the underlying object is a linear space anyway. I was wondering if there's any field of math that still studies functionals, but defined on manifolds instead of vector spaces.",,"['functional-analysis', 'differential-geometry', 'soft-question']"
97,Operator norm on Lebesgue integrable functions,Operator norm on Lebesgue integrable functions,,"Let $L_1([0,1],m)$ be the Banach space of $\mathbb{K}$ -valued integrable functions with respect to Lebesgue measure $m$ , where $\mathbb{K}$ is either $\mathbb{R}$ or $\mathbb{C}$ . The norm on this space is defined like this: $||f||_1=\int_{[0,1]}|f| \ dm$ . I have to show that: $a)$ For $n \geq 2$ the operator $\varphi_n(f)=\int_{[0,1]}\ f g_n \ dm$ , where $g_n(x)=n \sin(n^2x)$ for $x \in [0,1]$ is bounded with $||\varphi_n||=n$ . $b)$ Show that there exists $f \in L_1([0,1],m)$ such that $\lim_{n \to \infty} |\varphi_n( f)|=\infty$ . MY ATTEMPT: $g_n$ is Lebesgue integrable on $[0,1]$ since it's Riemann integrable. Hence $fg_n \in L_1([0,1],m)$ and $|\int_{[0,1]}fg_n\ dm| \leq \int_{[0,1]}|fg_n| \ dm$ . We also have that $||fg_n||_1 \leq ||f||_1||g_n||_\infty$ . Thus $||\varphi_n(f)||=|\int_{[0,1]}fg_n\ dm| \leq \int_{[0,1]}|fg_n|\ dm=||fg_n||_1 \leq ||f||_1 ||g_n||_\infty$ , i.e. $\varphi_n$ is bounded. Now $||g_n||_\infty=n$ since it's continuous on a bounded interval and the $essential$ $supremum$ is the same as the $max$ . Now I would like to attain the equality with some function, and once that I find it I can use in part $b)$ . Any ideas on the function?","Let be the Banach space of -valued integrable functions with respect to Lebesgue measure , where is either or . The norm on this space is defined like this: . I have to show that: For the operator , where for is bounded with . Show that there exists such that . MY ATTEMPT: is Lebesgue integrable on since it's Riemann integrable. Hence and . We also have that . Thus , i.e. is bounded. Now since it's continuous on a bounded interval and the is the same as the . Now I would like to attain the equality with some function, and once that I find it I can use in part . Any ideas on the function?","L_1([0,1],m) \mathbb{K} m \mathbb{K} \mathbb{R} \mathbb{C} ||f||_1=\int_{[0,1]}|f| \ dm a) n \geq 2 \varphi_n(f)=\int_{[0,1]}\ f g_n \ dm g_n(x)=n \sin(n^2x) x \in [0,1] ||\varphi_n||=n b) f \in L_1([0,1],m) \lim_{n \to \infty} |\varphi_n( f)|=\infty g_n [0,1] fg_n \in L_1([0,1],m) |\int_{[0,1]}fg_n\ dm| \leq \int_{[0,1]}|fg_n| \ dm ||fg_n||_1 \leq ||f||_1||g_n||_\infty ||\varphi_n(f)||=|\int_{[0,1]}fg_n\ dm| \leq \int_{[0,1]}|fg_n|\ dm=||fg_n||_1 \leq ||f||_1 ||g_n||_\infty \varphi_n ||g_n||_\infty=n essential supremum max b)","['functional-analysis', 'lebesgue-integral', 'lebesgue-measure', 'normed-spaces']"
98,Countably additive finite signed measures form a Banach Space.,Countably additive finite signed measures form a Banach Space.,,"I'm currently studying some topics in measure theory and I am not sure how to prove the following: Let $X$ a set, $\mathcal A$ a $\sigma$ -algebra on X. Consider the set: $$ca(\mathcal A) = \{\mu:\mathcal A \to \mathbb R|\; \mu \; \text{is a  finite signed measure} \}$$ Note that $ca(\mathcal A)$ is a subspace of $l_\infty(\mathcal A)$ . I   want to prove the following: $\|\mu\|\stackrel{def}{=} |\mu|(X)$ defines a norm on $ca(\mathcal A)$ ; $(ca(\mathcal A), \| \cdot \|)$ is a Banach Space The following inequality holds: $$\|\mu\|_\infty \leq \|\mu\| \leq 2\|\mu\|_\infty,$$ where $\|\mu\|_\infty\stackrel{def}{=}  \sup\limits_{A\in \mathcal A} |\mu(A)|$ I was able to prove (1) using Hahn-Jordan decomposition and the inequality on (3) is straightforward. Although I could not prove (2). What I tried: If $(\mu_n)_{n\in \mathbb N}$ is Cauchy sequence on $ca(\mathcal A)$ , it follows from (3) that $(\mu_n)$ is point-wise convergent to $\nu\stackrel{def}{=} \lim \mu_n$ : Given $\varepsilon >0$ , there is $n_0 \geq 1$ such that: $$m>n \geq n_0 \implies \|(\mu_m - \mu_n)\|_\infty\leq \|\mu_m - \mu_n\| <\varepsilon.$$ Hence, for all $A\in \mathcal A$ , $(\mu_n(A))$ is convergent and $\nu$ is well defined. I am not sure how to prove that $\nu$ is a signed measure in $ca(\mathcal A)$ : $\nu(\emptyset)=\lim\mu_n(\emptyset) = 0$ ; Since $(\mu_n(X))$ is convergent sequence on $\mathbb R$ , it is bounded. So $\nu(X) = \lim \mu_n(X)$ is finite. Why, given a family $(A_i)_{i \in \mathbb N}\subset \mathcal A$ of disjoint sets, we have: $$\nu (\bigcup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty}\nu(A_i)$$ EDIT: I had an idea: Given a family $(A_i)_{i \in \mathbb N}\subset \mathcal A$ of disjoint sets, define $B_i = \bigcup\limits_{j=1}^i A_j$ . The family of $(B_i)$ is increasing, $\cup B_i = \cup A_i$ , and: \begin{align*}  \nu(\bigcup_{i=1}^\infty A_i) &=  \nu(\bigcup_{i=1}^\infty B_i) \\   &=  \lim_{i} \nu(B_i)\\ &= \lim_{i} \lim_{n} \mu_n (\bigcup_{j=1}^i A_j)\\ &= \lim_{i} \lim_{n} \sum_{j=1}^i \mu_n(A_j)\\ &= \lim_{i} \sum_{j=1}^i \lim_{n} \mu_n(A_j) \\ &= \sum_{i=1}^\infty \nu(A_i). \end{align*} Can anyone check if this is correct? EDIT2: I forgot to check the convergence $\mu_n \stackrel{\|\cdot\|}{\to}\nu$ and I struggling with it.","I'm currently studying some topics in measure theory and I am not sure how to prove the following: Let a set, a -algebra on X. Consider the set: Note that is a subspace of . I   want to prove the following: defines a norm on ; is a Banach Space The following inequality holds: where I was able to prove (1) using Hahn-Jordan decomposition and the inequality on (3) is straightforward. Although I could not prove (2). What I tried: If is Cauchy sequence on , it follows from (3) that is point-wise convergent to : Given , there is such that: Hence, for all , is convergent and is well defined. I am not sure how to prove that is a signed measure in : ; Since is convergent sequence on , it is bounded. So is finite. Why, given a family of disjoint sets, we have: EDIT: I had an idea: Given a family of disjoint sets, define . The family of is increasing, , and: Can anyone check if this is correct? EDIT2: I forgot to check the convergence and I struggling with it.","X \mathcal A \sigma ca(\mathcal A) = \{\mu:\mathcal A \to \mathbb R|\; \mu \; \text{is a
 finite signed measure} \} ca(\mathcal A) l_\infty(\mathcal A) \|\mu\|\stackrel{def}{=} |\mu|(X) ca(\mathcal A) (ca(\mathcal A), \| \cdot \|) \|\mu\|_\infty \leq \|\mu\| \leq 2\|\mu\|_\infty, \|\mu\|_\infty\stackrel{def}{=}
 \sup\limits_{A\in \mathcal A} |\mu(A)| (\mu_n)_{n\in \mathbb N} ca(\mathcal A) (\mu_n) \nu\stackrel{def}{=} \lim \mu_n \varepsilon >0 n_0 \geq 1 m>n \geq n_0 \implies \|(\mu_m - \mu_n)\|_\infty\leq \|\mu_m - \mu_n\| <\varepsilon. A\in \mathcal A (\mu_n(A)) \nu \nu ca(\mathcal A) \nu(\emptyset)=\lim\mu_n(\emptyset) = 0 (\mu_n(X)) \mathbb R \nu(X) = \lim \mu_n(X) (A_i)_{i \in \mathbb N}\subset \mathcal A \nu (\bigcup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty}\nu(A_i) (A_i)_{i \in \mathbb N}\subset \mathcal A B_i = \bigcup\limits_{j=1}^i A_j (B_i) \cup B_i = \cup A_i \begin{align*} 
\nu(\bigcup_{i=1}^\infty A_i) &=  \nu(\bigcup_{i=1}^\infty B_i) \\ 
 &=  \lim_{i} \nu(B_i)\\
&= \lim_{i} \lim_{n} \mu_n (\bigcup_{j=1}^i A_j)\\
&= \lim_{i} \lim_{n} \sum_{j=1}^i \mu_n(A_j)\\
&= \lim_{i} \sum_{j=1}^i \lim_{n} \mu_n(A_j) \\
&= \sum_{i=1}^\infty \nu(A_i).
\end{align*} \mu_n \stackrel{\|\cdot\|}{\to}\nu","['functional-analysis', 'measure-theory', 'signed-measures']"
99,What does the Riesz representation theorem say?,What does the Riesz representation theorem say?,,"$\newcommand{\R}{\mathbf R}$ $\newcommand{\C}{\mathbf C}$ I am getting confused by the various different statements of the Riesz representation theorem found on the internet. So I want to clear up the confusion once and for all. Let $X$ be a compact metric space. $\bullet$ $M_s(X)$ denotes the set of all the finite signed Borel measures on $X$ . $\bullet$ $M_c(X)$ denotes the set of all the complex Borel measures on $X$ . $\bullet$ $M(X)$ denotes the set of all the finite (positive) Borel measures on $X$ . $\bullet$ $C(X, \R)$ denotes the space of all the real valued continuous maps on $X$ in the sup-norm topology. This is naturally a real linear space. $\bullet$ $C(X, \C)$ denotes the space of all the complex values continuous maps in the sup-norm topology. This is naturally a complex linear space. $\bullet$ $C(X, \R)^*$ denotes the space of all the real valued bounded real-linear maps with domain $C(X, \R)$ . $\bullet$ $C(X, \C)^*$ denotes the set of all the complex valued bounded complex-linear maps with $C(X, \C)$ as the domain. A member $F\in C(X, \R)^*$ or $C(X, \C)^*$ is said to be positive if $F(f)\geq 0$ whenever $f\geq 0$ . RRT1. The map $M_s(X)\to C(X, \R)^*$ defined by $\mu\mapsto (f\mapsto\int_Xf\ d\mu)$ is bijective. RRT2. The map $M(X)\to C(X, \R)^*$ defined by $\mu\mapsto (f\mapsto\int_Xf\ d\mu)$ is injective and has its image as the set of all the positive members of $C(X, \R)^*$ . RRT3 The map $M_c(X)\to C(X, \C)^*$ defined as $\mu\mapsto (f\mapsto \int_X f\ d\mu)$ is bijective. RRT4 The map $M(X)\to C(X, \C)^*$ defined by $\mu\mapsto (f\mapsto\int_X f\ d\mu)$ is injective and has its image as the set of all the positive members of $C(X, \C)^*$ . Which of the above is/are true?",I am getting confused by the various different statements of the Riesz representation theorem found on the internet. So I want to clear up the confusion once and for all. Let be a compact metric space. denotes the set of all the finite signed Borel measures on . denotes the set of all the complex Borel measures on . denotes the set of all the finite (positive) Borel measures on . denotes the space of all the real valued continuous maps on in the sup-norm topology. This is naturally a real linear space. denotes the space of all the complex values continuous maps in the sup-norm topology. This is naturally a complex linear space. denotes the space of all the real valued bounded real-linear maps with domain . denotes the set of all the complex valued bounded complex-linear maps with as the domain. A member or is said to be positive if whenever . RRT1. The map defined by is bijective. RRT2. The map defined by is injective and has its image as the set of all the positive members of . RRT3 The map defined as is bijective. RRT4 The map defined by is injective and has its image as the set of all the positive members of . Which of the above is/are true?,"\newcommand{\R}{\mathbf R} \newcommand{\C}{\mathbf C} X \bullet M_s(X) X \bullet M_c(X) X \bullet M(X) X \bullet C(X, \R) X \bullet C(X, \C) \bullet C(X, \R)^* C(X, \R) \bullet C(X, \C)^* C(X, \C) F\in C(X, \R)^* C(X, \C)^* F(f)\geq 0 f\geq 0 M_s(X)\to C(X, \R)^* \mu\mapsto (f\mapsto\int_Xf\ d\mu) M(X)\to C(X, \R)^* \mu\mapsto (f\mapsto\int_Xf\ d\mu) C(X, \R)^* M_c(X)\to C(X, \C)^* \mu\mapsto (f\mapsto \int_X f\ d\mu) M(X)\to C(X, \C)^* \mu\mapsto (f\mapsto\int_X f\ d\mu) C(X, \C)^*","['functional-analysis', 'measure-theory']"
