,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Motivating differential geometry to high school students,Motivating differential geometry to high school students,,What is the best way to motivate and explain what differential geometry to an audience of high school students? Any tips and suggestions are welcomed!,What is the best way to motivate and explain what differential geometry to an audience of high school students? Any tips and suggestions are welcomed!,,['differential-geometry']
1,Connections in non-Riemannian geometry,Connections in non-Riemannian geometry,,"In case of Riemannian geometry the connection $\Gamma^i_{jk}$ as is derived from the derivatives of the metric tensor $g_{ij}$ is ought to be symmetric wrt to its lower two indices. But in the case of Non-Riemannian Geometry that need not be the case, so the question is how do you actually construct such connections? Do you again use the metric tensor?","In case of Riemannian geometry the connection $\Gamma^i_{jk}$ as is derived from the derivatives of the metric tensor $g_{ij}$ is ought to be symmetric wrt to its lower two indices. But in the case of Non-Riemannian Geometry that need not be the case, so the question is how do you actually construct such connections? Do you again use the metric tensor?",,"['differential-geometry', 'riemannian-geometry', 'gauge-theory']"
2,Product rule for gradient of cross product,Product rule for gradient of cross product,,"The book I am reading gives a list of product rules, among them the following: $$\nabla \cdot (v\times w) =(\nabla \cdot v) w-v\nabla \cdot w.$$ However, the left-hand side is a number whereas the right-hand side is a vector. So clearly, something is wrong, maybe a dot should be replaced by a cross product, but I have not found a similar correct expression. What is the formula that the authors tried to write?","The book I am reading gives a list of product rules, among them the following: $$\nabla \cdot (v\times w) =(\nabla \cdot v) w-v\nabla \cdot w.$$ However, the left-hand side is a number whereas the right-hand side is a vector. So clearly, something is wrong, maybe a dot should be replaced by a cross product, but I have not found a similar correct expression. What is the formula that the authors tried to write?",,"['differential-geometry', 'cross-product']"
3,Proving $\dfrac{dN}{ds}=-\kappa T+\tau B$,Proving,\dfrac{dN}{ds}=-\kappa T+\tau B,"Currently revising for a differential geometry exam. The question I am working on is one of those types where the next part of the question follows from the last. I've gotten to the point where I have proven $T\cdot \dfrac{dN}{ds}=-\kappa$, and the next part is where I got stuck, which is to prove $\dfrac{dN}{ds}=-\kappa T+\tau B$. I looked at the mark scheme and it said ""Follows from previous item, and $B=T\times N$"". I simply don't see how it follows, though.","Currently revising for a differential geometry exam. The question I am working on is one of those types where the next part of the question follows from the last. I've gotten to the point where I have proven $T\cdot \dfrac{dN}{ds}=-\kappa$, and the next part is where I got stuck, which is to prove $\dfrac{dN}{ds}=-\kappa T+\tau B$. I looked at the mark scheme and it said ""Follows from previous item, and $B=T\times N$"". I simply don't see how it follows, though.",,"['differential-geometry', 'plane-curves']"
4,Tensor Laplacian,Tensor Laplacian,,"For a general tensor $T_{\mu_1 \dots \mu_n}$ on a (pseudo-)Riemannian manifold, is it true that $$\Delta (T_{\mu_1 \dots \mu_n})= (\Delta T)_{\mu_1 \dots \mu_n}?$$ In general, it is not true that $(\nabla_{\nu}T)_{\mu}$ versus $\nabla_{\nu}(T_{\mu}),$ where $\nabla$ is the induced covariant derivative. However, the coordinate formula given in this article seems to imply that equality does hold for the Laplacian. Attempt at a solution: If I consider the simplest case where $T$ is a $(1,0)$ vector field, then $$\Delta (T_{\mu}) = \Delta (T(dx^{\mu})) = \Delta T (dx^{\mu})+ 2 \nabla^{\lambda} T \nabla_{\lambda} (dx^{\mu}) + T(\Delta (dx^{\mu})).$$ So it would suffice to show that the second and third term on the right hand side vanish. However, I don't see why they should...","For a general tensor $T_{\mu_1 \dots \mu_n}$ on a (pseudo-)Riemannian manifold, is it true that $$\Delta (T_{\mu_1 \dots \mu_n})= (\Delta T)_{\mu_1 \dots \mu_n}?$$ In general, it is not true that $(\nabla_{\nu}T)_{\mu}$ versus $\nabla_{\nu}(T_{\mu}),$ where $\nabla$ is the induced covariant derivative. However, the coordinate formula given in this article seems to imply that equality does hold for the Laplacian. Attempt at a solution: If I consider the simplest case where $T$ is a $(1,0)$ vector field, then $$\Delta (T_{\mu}) = \Delta (T(dx^{\mu})) = \Delta T (dx^{\mu})+ 2 \nabla^{\lambda} T \nabla_{\lambda} (dx^{\mu}) + T(\Delta (dx^{\mu})).$$ So it would suffice to show that the second and third term on the right hand side vanish. However, I don't see why they should...",,"['differential-geometry', 'riemannian-geometry', 'tensors', 'general-relativity']"
5,submanifold of Euclidean space is oriented if and only if normal bundle is an oriented vector bundle.,submanifold of Euclidean space is oriented if and only if normal bundle is an oriented vector bundle.,,"Let $f:M\longrightarrow \mathbb{R}^{n+k}$ be an immersion of $n$-dimensional manifold $M$ into $\mathbb{R}^n$. Let $\nu(M)$ be the normal bundle of $M$. Prove that $M$ is oriented if and only if $\nu(M)$ is an oriented vector bundle. The hint is as follows: Using  $\Lambda(V\oplus W)=\Lambda(V)\otimes \Lambda(W)$, prove $\Lambda^nTM\otimes \Lambda^k\nu(M)$ is a trivial bundle. I have proved this. But I do not know how to use this to solve the original question. Thank you a lot. Is the condition that $M$ is a submanifold of $\mathbb{R}^n$ essential? How about a submanifold of an oriented riemannian manifold?","Let $f:M\longrightarrow \mathbb{R}^{n+k}$ be an immersion of $n$-dimensional manifold $M$ into $\mathbb{R}^n$. Let $\nu(M)$ be the normal bundle of $M$. Prove that $M$ is oriented if and only if $\nu(M)$ is an oriented vector bundle. The hint is as follows: Using  $\Lambda(V\oplus W)=\Lambda(V)\otimes \Lambda(W)$, prove $\Lambda^nTM\otimes \Lambda^k\nu(M)$ is a trivial bundle. I have proved this. But I do not know how to use this to solve the original question. Thank you a lot. Is the condition that $M$ is a submanifold of $\mathbb{R}^n$ essential? How about a submanifold of an oriented riemannian manifold?",,"['calculus', 'differential-geometry', 'manifolds', 'differential-topology', 'tensor-products']"
6,About a curious cross-product/determinant identity,About a curious cross-product/determinant identity,,"Whilst proving the fact that one definition of area for a domain inside a parameterisation of some surface embedded in $\mathbb{R}^3$ is well defined, my lecturer made a claim ""by linear algebra"" that amounts to: If $A$ is a $3$ by $2$ matrix and $B$ is a $2$ by $2$ matrix, $ABv\wedge ABw = \det{B}(Av\wedge Aw)$ for any vectors $v,w \in \mathbb{R}^2$. (The claim was actually made for $v=e_1,w=e_2$, but this result is equivalent to the one above (I think).) I spent a long time trying to prove it using things like the Levi-Civita symbol, and was unsuccessful. I eventually did prove it by resorting to writing $B$ as a $2$ by $2$ matrix and doing the explicit calculation, but this felt unsatisfactory, so my question is: Is there less computation-based method of proving this? Even better, is there a more general result that this is a special case of? I'm curious because it looks like a simple vector calculus formula that should be easy to prove without calculation, and the links between determinants, cross products and volume make me think that there should be some kind of more general version. On the other hand it may be true because of the link to differential geometry and so doesn't generalise...","Whilst proving the fact that one definition of area for a domain inside a parameterisation of some surface embedded in $\mathbb{R}^3$ is well defined, my lecturer made a claim ""by linear algebra"" that amounts to: If $A$ is a $3$ by $2$ matrix and $B$ is a $2$ by $2$ matrix, $ABv\wedge ABw = \det{B}(Av\wedge Aw)$ for any vectors $v,w \in \mathbb{R}^2$. (The claim was actually made for $v=e_1,w=e_2$, but this result is equivalent to the one above (I think).) I spent a long time trying to prove it using things like the Levi-Civita symbol, and was unsuccessful. I eventually did prove it by resorting to writing $B$ as a $2$ by $2$ matrix and doing the explicit calculation, but this felt unsatisfactory, so my question is: Is there less computation-based method of proving this? Even better, is there a more general result that this is a special case of? I'm curious because it looks like a simple vector calculus formula that should be easy to prove without calculation, and the links between determinants, cross products and volume make me think that there should be some kind of more general version. On the other hand it may be true because of the link to differential geometry and so doesn't generalise...",,"['linear-algebra', 'differential-geometry']"
7,How to motivate vectors as derivations?,How to motivate vectors as derivations?,,"In a manifold it's easy to motivate the definition of vectors as equivalence classes of curves. On the other hand the definition as derivations is harder to motivate. I know how to show that the space obtained with derivations is isomorphic to the space obtained with curves, so I know that defining with derivations works. My doubt it is: how would I motivate the usage of derivations? This question is, how can it be intuitively visible that linearity and Leibniz rule alone are sufficient for assuring that the operator is a directional derivative? I've seem some discussion about it on the ""Applied Differential Geometry"" book from William Burke where he tries to motivate this saying that a differential operator measures terms in the Taylor series and that Leibniz rule assures the operator is sensible only to first order terms. But I didn't get this idea yet.","In a manifold it's easy to motivate the definition of vectors as equivalence classes of curves. On the other hand the definition as derivations is harder to motivate. I know how to show that the space obtained with derivations is isomorphic to the space obtained with curves, so I know that defining with derivations works. My doubt it is: how would I motivate the usage of derivations? This question is, how can it be intuitively visible that linearity and Leibniz rule alone are sufficient for assuring that the operator is a directional derivative? I've seem some discussion about it on the ""Applied Differential Geometry"" book from William Burke where he tries to motivate this saying that a differential operator measures terms in the Taylor series and that Leibniz rule assures the operator is sensible only to first order terms. But I didn't get this idea yet.",,"['differential-geometry', 'manifolds', 'intuition', 'vectors', 'motivation']"
8,Any books on isospectral manifolds?,Any books on isospectral manifolds?,,"I was searching stuff related to M.Kac's famous question "" Can one hear the shape of the drum ?"" I further found results due to Gordon, Webb and Wolpert in the 2D case using Sunada method. Are there any books on this topic explaining the above mentioned stuff and the recent advances? Thanks.","I was searching stuff related to M.Kac's famous question "" Can one hear the shape of the drum ?"" I further found results due to Gordon, Webb and Wolpert in the 2D case using Sunada method. Are there any books on this topic explaining the above mentioned stuff and the recent advances? Thanks.",,"['reference-request', 'differential-geometry', 'riemannian-geometry']"
9,How is the action of a Lie group element on a tangent vector defined?,How is the action of a Lie group element on a tangent vector defined?,,"I am trying to understand the concept of a left-invariant vector field, much as in this question here. I am not clear on what is meant by ""derivative of left-multiplication by $g$"". How is this derivative defined? How is the action of an element of the group on an element of the tangent space defined?","I am trying to understand the concept of a left-invariant vector field, much as in this question here. I am not clear on what is meant by ""derivative of left-multiplication by $g$"". How is this derivative defined? How is the action of an element of the group on an element of the tangent space defined?",,"['differential-geometry', 'lie-groups']"
10,Submanifold is complete,Submanifold is complete,,"If $M$ is a complete manifold and $N\subset M$ is a closed, embedded submanifold with the induced Riemannian metric, show that $N$ is complete. I really don't know where to start. This is not homework, please help! Thank you very much.","If $M$ is a complete manifold and $N\subset M$ is a closed, embedded submanifold with the induced Riemannian metric, show that $N$ is complete. I really don't know where to start. This is not homework, please help! Thank you very much.",,['differential-geometry']
11,Why the space of skew-symmetric tensors $\Lambda^{n}V$ is a one dimensional if $dim(V)=n$,Why the space of skew-symmetric tensors  is a one dimensional if,\Lambda^{n}V dim(V)=n,"While reading Liviu Nicolaescu  Lectures on the geometry of manifolds, I came accross the notion of ""determinant line"": Definition: Lev $V$ be an n-dimensional R-vector space. The one dimensional vector space $\Lambda^{n}V$ is called the determinant line . Here, $\Lambda^{n}V$ is a space of skew-symmetric (a.k.a. antisymmetric) tensors. My question is why $\Lambda^{n}V$ is a one-dimensional vector space? I think that this has something to do with the fact that the degrees of the tensors in that spaces is equal to the dimension of $V$, i.e. $n=dim V$. But I cann't figure this one out. Any guidance would be very appreciated.","While reading Liviu Nicolaescu  Lectures on the geometry of manifolds, I came accross the notion of ""determinant line"": Definition: Lev $V$ be an n-dimensional R-vector space. The one dimensional vector space $\Lambda^{n}V$ is called the determinant line . Here, $\Lambda^{n}V$ is a space of skew-symmetric (a.k.a. antisymmetric) tensors. My question is why $\Lambda^{n}V$ is a one-dimensional vector space? I think that this has something to do with the fact that the degrees of the tensors in that spaces is equal to the dimension of $V$, i.e. $n=dim V$. But I cann't figure this one out. Any guidance would be very appreciated.",,"['differential-geometry', 'vector-spaces', 'tensors']"
12,Question about differential form,Question about differential form,,"$\omega = y dx + dz$ is a differential form in $\mathbb{R}^3$, then what is ${\rm ker}(\omega)$? Is ${\rm ker}(\omega)$ integrable? Can you teach me about this question in details? Many thanks!","$\omega = y dx + dz$ is a differential form in $\mathbb{R}^3$, then what is ${\rm ker}(\omega)$? Is ${\rm ker}(\omega)$ integrable? Can you teach me about this question in details? Many thanks!",,"['differential-geometry', 'differential-forms']"
13,a question about compact tangent bundle,a question about compact tangent bundle,,I have a question about tangent bundles. Is there a compact tangent bundle? Or what conditions do we need to be sure that tangent bundle of a manifold be compact?,I have a question about tangent bundles. Is there a compact tangent bundle? Or what conditions do we need to be sure that tangent bundle of a manifold be compact?,,"['differential-geometry', 'manifolds', 'vector-bundles']"
14,Line bundle over $S^2$,Line bundle over,S^2,"I'm trying to study line bundle over $S^2$. In this post was outlined the method based on clutching functions. But now I'm interesting in another approach. For the sphere there is two maps : upper hemisphere and lower hemisphere with intersection as $[-\epsilon,\epsilon]\times S^1$. For the upper hemisphere and lower hemisphere its well-known that bundles over this spaces is trivial. (Any bundle over a contractible base is trivial). So to prove the fact that line bundle over $S^2$ is trivial we must create continuation of trivialization from upper hemisphere (for example) to the lower hemisphere through ""border"" $[-\epsilon,\epsilon]\times S^1$. As I understand it is sufficient to continue trivialization from the ""border"" to the center of the ""disk"". (I think here it is possible to use a partition of unity, but I'm not sure). I can't formalize this reasoning.","I'm trying to study line bundle over $S^2$. In this post was outlined the method based on clutching functions. But now I'm interesting in another approach. For the sphere there is two maps : upper hemisphere and lower hemisphere with intersection as $[-\epsilon,\epsilon]\times S^1$. For the upper hemisphere and lower hemisphere its well-known that bundles over this spaces is trivial. (Any bundle over a contractible base is trivial). So to prove the fact that line bundle over $S^2$ is trivial we must create continuation of trivialization from upper hemisphere (for example) to the lower hemisphere through ""border"" $[-\epsilon,\epsilon]\times S^1$. As I understand it is sufficient to continue trivialization from the ""border"" to the center of the ""disk"". (I think here it is possible to use a partition of unity, but I'm not sure). I can't formalize this reasoning.",,"['differential-geometry', 'vector-bundles']"
15,Existence of differential form on a manifold,Existence of differential form on a manifold,,"I have a fundamental question about the existence of differential forms on manifolds. A $k$-form on a manifold in local coordinates looks like $f(x_1,...,x_n)dx_{i_1}...dx_{i_k}$, where $f$ is a smooth function. Given any smooth function $f$, is $f(x_1,...,x_n)dx_i$ a $1$-form for every $i$? In general does the existence of a smooth function ($0$-form) imply the existence of a $k$-form for all $k<n+1$? I can just multiply the function by the desired number if $dx$'s. Thanks","I have a fundamental question about the existence of differential forms on manifolds. A $k$-form on a manifold in local coordinates looks like $f(x_1,...,x_n)dx_{i_1}...dx_{i_k}$, where $f$ is a smooth function. Given any smooth function $f$, is $f(x_1,...,x_n)dx_i$ a $1$-form for every $i$? In general does the existence of a smooth function ($0$-form) imply the existence of a $k$-form for all $k<n+1$? I can just multiply the function by the desired number if $dx$'s. Thanks",,"['differential-geometry', 'manifolds', 'differential-topology', 'definition']"
16,Injectivity radius estmiates,Injectivity radius estmiates,,"Let $x\in M$ be a point, whose injectivity radius is $r_x$. So is it true that for any point $y \in B(x, r_x)$, the injectivity radius at $y$ is at least $r_x- d(x, y)$? is there any book has this result or if it is false what is the count example?","Let $x\in M$ be a point, whose injectivity radius is $r_x$. So is it true that for any point $y \in B(x, r_x)$, the injectivity radius at $y$ is at least $r_x- d(x, y)$? is there any book has this result or if it is false what is the count example?",,['differential-geometry']
17,Manifold non-orientable iff. frame bundle is connected,Manifold non-orientable iff. frame bundle is connected,,"Let $M$ be a connected smooth manifold and $L(M):=\bigcup_{x\in M}L_xM$ its frame bundle where $L_xM:=\{(v_1,\dots,v_n):\{v_1,\dots,v_n\}\text{ is a basis of }T_xM\}$. $M$ is non-orientable iff. $L(M)$ is connected. I think I have managed to prove, that if $L(M)$ is connected then $M$ is non-orientable by assuming $M$ is orientable and showing that then $L(M)$ has two disjoint components, namely the set of all positively oriented bases and the ""rest"". However, I struggle on proving the converse. My idea is to use non-orientability to show path-connectedness but I cannot construct such a continuous path in $L(M)$.","Let $M$ be a connected smooth manifold and $L(M):=\bigcup_{x\in M}L_xM$ its frame bundle where $L_xM:=\{(v_1,\dots,v_n):\{v_1,\dots,v_n\}\text{ is a basis of }T_xM\}$. $M$ is non-orientable iff. $L(M)$ is connected. I think I have managed to prove, that if $L(M)$ is connected then $M$ is non-orientable by assuming $M$ is orientable and showing that then $L(M)$ has two disjoint components, namely the set of all positively oriented bases and the ""rest"". However, I struggle on proving the converse. My idea is to use non-orientability to show path-connectedness but I cannot construct such a continuous path in $L(M)$.",,"['differential-geometry', 'manifolds', 'principal-bundles']"
18,Values of the Christoffel symbols,Values of the Christoffel symbols,,Are the values of the christoffel symbols the same for all coordinate systems on a surface/manifold? I would love to see an example for the cone in two different parametrizations.,Are the values of the christoffel symbols the same for all coordinate systems on a surface/manifold? I would love to see an example for the cone in two different parametrizations.,,['differential-geometry']
19,"I've solved this problem, but why is this differentiable?","I've solved this problem, but why is this differentiable?",,"Let $\alpha:\mathbb R\rightarrow \mathbb R^3$ be a smooth curve (i.e., $\alpha \in C^\infty(\mathbb R)$). Suppose there exists $X_0$ such that for every normal line to $\alpha$, $X_0$ belongs to it. Show that $\alpha$ is part of a circumference. Part of solution: Let $n(s)$ be the normal vector to $\alpha$ on $s$. For every $s \in \mathbb R$ there exists an unique real number $\lambda$ such that $\alpha(s)+\lambda n(s)=X_0$. Now let $\lambda(s)$ be the function that associates every real number $s$ to this number. I've finished this question, but I have derivated $\lambda(s)$ and I don't know why I can do it. Can someone tell me why is $\lambda$ differentiable?","Let $\alpha:\mathbb R\rightarrow \mathbb R^3$ be a smooth curve (i.e., $\alpha \in C^\infty(\mathbb R)$). Suppose there exists $X_0$ such that for every normal line to $\alpha$, $X_0$ belongs to it. Show that $\alpha$ is part of a circumference. Part of solution: Let $n(s)$ be the normal vector to $\alpha$ on $s$. For every $s \in \mathbb R$ there exists an unique real number $\lambda$ such that $\alpha(s)+\lambda n(s)=X_0$. Now let $\lambda(s)$ be the function that associates every real number $s$ to this number. I've finished this question, but I have derivated $\lambda(s)$ and I don't know why I can do it. Can someone tell me why is $\lambda$ differentiable?",,[]
20,Sphere parameterization with 6 patches,Sphere parameterization with 6 patches,,"I am looking for a parameterization of the sphere with 6 patches, like in http://www.image.ucar.edu/staff/rnair/research09.html and the inverse of this parameterization. As well, I would need a method to determine, for a point $x$ (which coordinates are known of course) on the sphere, which patch (patches for boundaries) $x$ lies in (with patches defined by the above parametrization). Thanks.","I am looking for a parameterization of the sphere with 6 patches, like in http://www.image.ucar.edu/staff/rnair/research09.html and the inverse of this parameterization. As well, I would need a method to determine, for a point $x$ (which coordinates are known of course) on the sphere, which patch (patches for boundaries) $x$ lies in (with patches defined by the above parametrization). Thanks.",,['calculus']
21,The wedge product,The wedge product,,"I have seen the wedge-product as being defined in differential geometry in the definition of a differential form or p-form. Now in the course we have proven the basic properties of this product and how to take the differential. Now when we apply this to the differentiation of a function in on a curved manifold, we make the following change in the integral $\int dx^n\rightarrow\int dx^0\wedge dx^1\wedge...\wedge dx^{n-1}$. I don't see how the wedge product is related to the volume element, I was hoping that you guys might be able to clear that up for me ? Second, I already asked around about this, the wedge product is said to be the generalisation of the cross vector product and the 3D volume element to higher dimensions. I was woundering of anyone could explain that ?","I have seen the wedge-product as being defined in differential geometry in the definition of a differential form or p-form. Now in the course we have proven the basic properties of this product and how to take the differential. Now when we apply this to the differentiation of a function in on a curved manifold, we make the following change in the integral $\int dx^n\rightarrow\int dx^0\wedge dx^1\wedge...\wedge dx^{n-1}$. I don't see how the wedge product is related to the volume element, I was hoping that you guys might be able to clear that up for me ? Second, I already asked around about this, the wedge product is said to be the generalisation of the cross vector product and the 3D volume element to higher dimensions. I was woundering of anyone could explain that ?",,"['differential-geometry', 'exterior-algebra']"
22,Does this proof work to prove that the greatest area of a triangle inside a circle is when the triangle is equilateral?,Does this proof work to prove that the greatest area of a triangle inside a circle is when the triangle is equilateral?,,Does this proof work to prove that the greatest area of a triangle inside a circle is when the triangle is equilateral? I gather it doesn't because most of the proofs I've seen use derivatives etc. If so why doesn't it work? Consider a triangle $ABC$ inscribed inside a circle $\Gamma$. Assume WLOG one of the sided is fixed then one can easily see that the other two sides being equal maximizes the area of the triangle (it has the greatest height). Now consider one of the two equal sides - using that side as a base we can see from the same argument as before that the triangle must in fact be equilateral to maximize the area (this triangle has the greatest height as before). Thanks in advance.,Does this proof work to prove that the greatest area of a triangle inside a circle is when the triangle is equilateral? I gather it doesn't because most of the proofs I've seen use derivatives etc. If so why doesn't it work? Consider a triangle $ABC$ inscribed inside a circle $\Gamma$. Assume WLOG one of the sided is fixed then one can easily see that the other two sides being equal maximizes the area of the triangle (it has the greatest height). Now consider one of the two equal sides - using that side as a base we can see from the same argument as before that the triangle must in fact be equilateral to maximize the area (this triangle has the greatest height as before). Thanks in advance.,,"['differential-geometry', 'euclidean-geometry', 'circles', 'triangles']"
23,Compactness of semisimple Lie algebra,Compactness of semisimple Lie algebra,,"I want to prove that on a semisimple Lie algebra $\mathfrak{g}$ over ${\bf R}$: $\mathfrak{g}$ is compact if and only if the Killing form is strictly   negative definite. Here the Lie algebra is compact if Int$(\mathfrak{g})$, which is a Lie group of $\{ ad_X | X\in \mathfrak{g}\}$, is compact. I am reading a Helgason's book : The proof is short and I cannot catch the strategy. The proof : If Killing form $B$ is strictly negative definitie then $O(B)$ is a set of all linear transformations which leave $B$ invariant. Then $O(B)$ is compact.  I cannot understand. Thank you in advance.","I want to prove that on a semisimple Lie algebra $\mathfrak{g}$ over ${\bf R}$: $\mathfrak{g}$ is compact if and only if the Killing form is strictly   negative definite. Here the Lie algebra is compact if Int$(\mathfrak{g})$, which is a Lie group of $\{ ad_X | X\in \mathfrak{g}\}$, is compact. I am reading a Helgason's book : The proof is short and I cannot catch the strategy. The proof : If Killing form $B$ is strictly negative definitie then $O(B)$ is a set of all linear transformations which leave $B$ invariant. Then $O(B)$ is compact.  I cannot understand. Thank you in advance.",,"['differential-geometry', 'lie-algebras', 'semisimple-lie-algebras']"
24,Smooth maps on a manifold lie group,Smooth maps on a manifold lie group,,"$$ \operatorname{GL}_n(\mathbb R) = \{ A \in M_{n\times n} | \det A \ne 0 \} \\ \begin{align} &n = 1, \operatorname{GL}_n(\mathbb R) = \mathbb R - \{0\} \\ &n = 2, \operatorname{GL}_n(\mathbb R) = \left\{\begin{bmatrix}a&b\\c&d\end{bmatrix}\Bigg| ad-bc \ne 0\right\} \end{align} $$ $(\operatorname{GL}_n(\mathbb R),\cdot)$ is a group. $AB$ is invertible if $A$ and $B$ are invertible. $A(BC)=(AB)C$ $I=\begin{bmatrix}1&0\\0&1\end{bmatrix}$ $A^{-1}$ is invertible if $A$ is invertible. $$(\operatorname{GL}_n(\mathbb R) := \det{}^{-1}(\{0\}))$$ $\det{}^{-1}(\{0\})$ is open in $M_{n\times n}(\mathbb R)$. $\det : M_{n\times n}(\mathbb R) \to \mathbb R$ is continuous, why? $\dim \operatorname{GL}_n(\mathbb R) = n^2 - 1$, why? $(\operatorname{GL}_n(\mathbb R),\cdot)$ is a Lie group if: $$ \mu : G\times G \to G \\ \mu(A,B) = A\cdot B \:\text{ is smooth} \\ I(A) = A^{-1} \:\text{ is smooth} $$ How can I show this? I want to show that general special linear group is Lie group. I could not show the my last step. How can I show that $AB$ and $A^{-1}$ are smooth? please help me I want to learn this. Thanks Here the my handwritten notes https://i.sstatic.net/tkoMy.jpg","$$ \operatorname{GL}_n(\mathbb R) = \{ A \in M_{n\times n} | \det A \ne 0 \} \\ \begin{align} &n = 1, \operatorname{GL}_n(\mathbb R) = \mathbb R - \{0\} \\ &n = 2, \operatorname{GL}_n(\mathbb R) = \left\{\begin{bmatrix}a&b\\c&d\end{bmatrix}\Bigg| ad-bc \ne 0\right\} \end{align} $$ $(\operatorname{GL}_n(\mathbb R),\cdot)$ is a group. $AB$ is invertible if $A$ and $B$ are invertible. $A(BC)=(AB)C$ $I=\begin{bmatrix}1&0\\0&1\end{bmatrix}$ $A^{-1}$ is invertible if $A$ is invertible. $$(\operatorname{GL}_n(\mathbb R) := \det{}^{-1}(\{0\}))$$ $\det{}^{-1}(\{0\})$ is open in $M_{n\times n}(\mathbb R)$. $\det : M_{n\times n}(\mathbb R) \to \mathbb R$ is continuous, why? $\dim \operatorname{GL}_n(\mathbb R) = n^2 - 1$, why? $(\operatorname{GL}_n(\mathbb R),\cdot)$ is a Lie group if: $$ \mu : G\times G \to G \\ \mu(A,B) = A\cdot B \:\text{ is smooth} \\ I(A) = A^{-1} \:\text{ is smooth} $$ How can I show this? I want to show that general special linear group is Lie group. I could not show the my last step. How can I show that $AB$ and $A^{-1}$ are smooth? please help me I want to learn this. Thanks Here the my handwritten notes https://i.sstatic.net/tkoMy.jpg",,"['real-analysis', 'linear-algebra', 'general-topology', 'differential-geometry', 'manifolds']"
25,Orientation preserving diffeomorphism.,Orientation preserving diffeomorphism.,,I am stuck with the question. I guess that I need to write jacobian matrix. But I could not do. Please help me thank you,I am stuck with the question. I guess that I need to write jacobian matrix. But I could not do. Please help me thank you,,"['linear-algebra', 'differential-geometry', 'manifolds']"
26,Computing $n$-th external power of standard simplectic form,Computing -th external power of standard simplectic form,n,I need some help: Define a 2-form on $R^n$ by $\omega=dx_1\wedge dx_2+dx_3\wedge dx_4+...+dx_{2n-1}\wedge dx_{2n}$. How to compute $\omega^n:=\omega\wedge\omega\wedge\ldots\wedge\omega$?,I need some help: Define a 2-form on $R^n$ by $\omega=dx_1\wedge dx_2+dx_3\wedge dx_4+...+dx_{2n-1}\wedge dx_{2n}$. How to compute $\omega^n:=\omega\wedge\omega\wedge\ldots\wedge\omega$?,,"['differential-geometry', 'differential-forms']"
27,Is $\omega_n$ exact in $\mathbb R^n -\{0 \}$?,Is  exact in ?,\omega_n \mathbb R^n -\{0 \},"For $n \ge 2$ consider the differential form $\omega_n=r^{-n} \sum_{i=1}^n(-1)^{i-1}x_idx_1 \wedge \ldots \wedge dx_{i-1} \wedge dx_{i+1} \wedge \ldots \wedge dx_n$, defined on $\mathbb R^n \setminus \{ \bf0\}$. (where, $r=\sqrt{x_1^2+\ldots + x_n^2}$). Is it exact there? I think the answer is no, and I've verified my answer for $n=2,3$ by integrating $\omega_n$ over the unit $(n-1)$-sphere $S^{n-1}$ to a nonzero result. I guess it's true for all values of $n$, but the calculations become very cumbersome (many $(n-1) \times (n-1)$ Jacobians to find...). I also need to prove that the boundaries are empty. Is there a more sophisticated way of proving that $\omega_n$ is not exact? If not, can anyone help my with the calculations?","For $n \ge 2$ consider the differential form $\omega_n=r^{-n} \sum_{i=1}^n(-1)^{i-1}x_idx_1 \wedge \ldots \wedge dx_{i-1} \wedge dx_{i+1} \wedge \ldots \wedge dx_n$, defined on $\mathbb R^n \setminus \{ \bf0\}$. (where, $r=\sqrt{x_1^2+\ldots + x_n^2}$). Is it exact there? I think the answer is no, and I've verified my answer for $n=2,3$ by integrating $\omega_n$ over the unit $(n-1)$-sphere $S^{n-1}$ to a nonzero result. I guess it's true for all values of $n$, but the calculations become very cumbersome (many $(n-1) \times (n-1)$ Jacobians to find...). I also need to prove that the boundaries are empty. Is there a more sophisticated way of proving that $\omega_n$ is not exact? If not, can anyone help my with the calculations?",,"['real-analysis', 'differential-geometry', 'differential-forms']"
28,Selecting Differential Geometry Exercises,Selecting Differential Geometry Exercises,,"I'm self-studying differential geometry with Do Carmo's books ""Differential Geometry of Curves and Surfaces"" and ""Riemannian Geometry"" and I find those books very good, however I feel a little confused when selecting which exercises to do. What's the best way to select exercises when studying that kind of math? I know this question seems silly, it's like : ""how can someone don't know which exercises to do?"", but it's just the case that there's no time to work on all of them, so I feel a little confused in which to work more. Thanks in advance, and sorry again if the question is not fitted to this website.","I'm self-studying differential geometry with Do Carmo's books ""Differential Geometry of Curves and Surfaces"" and ""Riemannian Geometry"" and I find those books very good, however I feel a little confused when selecting which exercises to do. What's the best way to select exercises when studying that kind of math? I know this question seems silly, it's like : ""how can someone don't know which exercises to do?"", but it's just the case that there's no time to work on all of them, so I feel a little confused in which to work more. Thanks in advance, and sorry again if the question is not fitted to this website.",,"['differential-geometry', 'soft-question', 'self-learning']"
29,Prove that two normed linear spaces are equivalent as metric spaces if and only if the norms are equivalent?,Prove that two normed linear spaces are equivalent as metric spaces if and only if the norms are equivalent?,,"We have the two norms $\|\cdot\|_a$ and $\|\cdot\|_b$ on the vectorspace V. They're equivalent if there exists a $k>0$ and $K>0$ so that  $k\|\cdot\|_a\le\|\cdot\|_b\le$ K$\|\cdot\|_a$ for all $v\in V$. I've proved this is an equivalence relation on the set of norms. I now have to prove, that $d_{\|\cdot\|_a}$ is equivalent to $d_{\|\cdot\|_b}$ if and only if $\|\cdot\|_a$ is equivalent to $\|\cdot\|_b$. I've already proven the ""if""-statement, I just have to prove the ""only if""-statement now, and I don't really have any ideas how to do it. I would appreciate a little help very much.","We have the two norms $\|\cdot\|_a$ and $\|\cdot\|_b$ on the vectorspace V. They're equivalent if there exists a $k>0$ and $K>0$ so that  $k\|\cdot\|_a\le\|\cdot\|_b\le$ K$\|\cdot\|_a$ for all $v\in V$. I've proved this is an equivalence relation on the set of norms. I now have to prove, that $d_{\|\cdot\|_a}$ is equivalent to $d_{\|\cdot\|_b}$ if and only if $\|\cdot\|_a$ is equivalent to $\|\cdot\|_b$. I've already proven the ""if""-statement, I just have to prove the ""only if""-statement now, and I don't really have any ideas how to do it. I would appreciate a little help very much.",,"['differential-geometry', 'metric-spaces']"
30,$k$-forms as modules over $C^\infty(M)$,-forms as modules over,k C^\infty(M),"Let $M$ be an $n$-dimension manifold. Is $E^k(M)$ a finite dimension module over $C^\infty(M)$? Here $E^k(M)$ is the space of $k$-form on $M$, $k<n$.","Let $M$ be an $n$-dimension manifold. Is $E^k(M)$ a finite dimension module over $C^\infty(M)$? Here $E^k(M)$ is the space of $k$-form on $M$, $k<n$.",,['differential-geometry']
31,Gentle introduction to quasi-geodesics,Gentle introduction to quasi-geodesics,,"Compared to the concept of geodesics the concept of quasi-geodesics seems to be substantially harder to grasp and digest. I was given a promising hint to the concept of quasi-geodesics here but the usual references didn't reveal something like an ""easy access"" to the concept: Google [the very first hit pointing to a paper of G. Perelman] Wikipedia Encyclopedia of Mathematics So I am still looking for something like a ""gentle introduction to quasi-geodesics"".","Compared to the concept of geodesics the concept of quasi-geodesics seems to be substantially harder to grasp and digest. I was given a promising hint to the concept of quasi-geodesics here but the usual references didn't reveal something like an ""easy access"" to the concept: Google [the very first hit pointing to a paper of G. Perelman] Wikipedia Encyclopedia of Mathematics So I am still looking for something like a ""gentle introduction to quasi-geodesics"".",,"['reference-request', 'differential-geometry']"
32,Trivial bundle on sphere,Trivial bundle on sphere,,"I have an exercises as follows: Let $E$ be a trivial bundle on $S^n$. Prove that the Whitney sum $TS^n\oplus E$ is also trivial. The hint is using the normal bundle of $TS^n$, but I don't know how to use it. Some one can help me? Thanks a lot!","I have an exercises as follows: Let $E$ be a trivial bundle on $S^n$. Prove that the Whitney sum $TS^n\oplus E$ is also trivial. The hint is using the normal bundle of $TS^n$, but I don't know how to use it. Some one can help me? Thanks a lot!",,"['differential-geometry', 'differential-topology']"
33,graphic tools for mean curvature flow,graphic tools for mean curvature flow,,Does anyone have any suggestions for software that could graphically represent evolution of curves/surfaces under mean curvature flow? Thanks!,Does anyone have any suggestions for software that could graphically represent evolution of curves/surfaces under mean curvature flow? Thanks!,,"['differential-geometry', 'math-software', 'mean-curvature-flows']"
34,Birational geometry as local algebraic geometry,Birational geometry as local algebraic geometry,,"Technically birational geometry is local geometry of algebraic varieties, yet it feels completely different from local differential geometry, which is more or less trivial. Is there some subtle similarity between them?","Technically birational geometry is local geometry of algebraic varieties, yet it feels completely different from local differential geometry, which is more or less trivial. Is there some subtle similarity between them?",,"['algebraic-geometry', 'differential-geometry']"
35,$f$ a differentiable map between manifolds of same dimension; $df(p)$ is nonsingular - show $f$ is an open map,a differentiable map between manifolds of same dimension;  is nonsingular - show  is an open map,f df(p) f,"Let $f: X \to Y$ be a differentiable map of manifolds where $dim \;X = dim\;Y = n$. If $df(p)$ is nonsingular for all $p \in X$, show $f$ is an open map. So here is what I was thinking: As $df(p)$ is nonsingular for all $p \in X$, that is, it is an isomorphism between tangent spaces (bijective homomorphism), then for an open subset, $U \subset \mathcal{R}^n$, s.t. $U \overset{\text{$f$ is injective & continuous}}{\longrightarrow} \mathcal{R}^n$, then the image of $U$ ($f(U) \subset \mathcal{R}^n$) is open, as well as $f$ is a homeomorphism betweeen $U$ and $f(U)$ (homeomorphism meaning bijective and continuous $f$ and $f^{-1}$ [via the claim $df(p)$ is nonsingular]). Is this, and quoting Brouwer's fixed point theorem enough to reasonably answer this question?","Let $f: X \to Y$ be a differentiable map of manifolds where $dim \;X = dim\;Y = n$. If $df(p)$ is nonsingular for all $p \in X$, show $f$ is an open map. So here is what I was thinking: As $df(p)$ is nonsingular for all $p \in X$, that is, it is an isomorphism between tangent spaces (bijective homomorphism), then for an open subset, $U \subset \mathcal{R}^n$, s.t. $U \overset{\text{$f$ is injective & continuous}}{\longrightarrow} \mathcal{R}^n$, then the image of $U$ ($f(U) \subset \mathcal{R}^n$) is open, as well as $f$ is a homeomorphism betweeen $U$ and $f(U)$ (homeomorphism meaning bijective and continuous $f$ and $f^{-1}$ [via the claim $df(p)$ is nonsingular]). Is this, and quoting Brouwer's fixed point theorem enough to reasonably answer this question?",,"['differential-geometry', 'differential-topology']"
36,How to find the maximal integral submanifold in a concrete case?,How to find the maximal integral submanifold in a concrete case?,,"Take $M=\mathbb{R}^3$ be a smooth manifold. Consider a distribution $\Delta_{(x,y,z)} = Span\{y\frac{\partial}{\partial x}-x\frac{\partial}{\partial y}, z\frac{\partial}{\partial x} - x\frac{\partial}{\partial z} \}$. 1) Show that the distribution is integrable. 2) Describe the maximal integral submanifolds. Here is some of my drafts: Take $V = y\frac{\partial}{\partial x}-x\frac{\partial}{\partial y}$ and $W = z\frac{\partial}{\partial x} - x\frac{\partial}{\partial z}$, then the Lie bracket $[V,W]=VW-WV=-y\frac{\partial}{\partial z}+z\frac{\partial}{\partial y}$. If $[V_p, W_p]\in \Delta_p$, then the distribution is involutive and further integrable. However, for $p=(0,y,z)$, $V_p=y\frac{\partial}{\partial x}$, $W_p = z\frac{\partial}{\partial x}$, and $[V_p, W_p]=-y\frac{\partial}{\partial z}+z\frac{\partial}{\partial y}$. Easy to see the Lie bracket is not in the span. If this is true, then the distribution is not integrable. Could anyone remind me what is wrong? As to the second part, I did not have a clear clue of how to complete. A concrete computation would be appreciated.","Take $M=\mathbb{R}^3$ be a smooth manifold. Consider a distribution $\Delta_{(x,y,z)} = Span\{y\frac{\partial}{\partial x}-x\frac{\partial}{\partial y}, z\frac{\partial}{\partial x} - x\frac{\partial}{\partial z} \}$. 1) Show that the distribution is integrable. 2) Describe the maximal integral submanifolds. Here is some of my drafts: Take $V = y\frac{\partial}{\partial x}-x\frac{\partial}{\partial y}$ and $W = z\frac{\partial}{\partial x} - x\frac{\partial}{\partial z}$, then the Lie bracket $[V,W]=VW-WV=-y\frac{\partial}{\partial z}+z\frac{\partial}{\partial y}$. If $[V_p, W_p]\in \Delta_p$, then the distribution is involutive and further integrable. However, for $p=(0,y,z)$, $V_p=y\frac{\partial}{\partial x}$, $W_p = z\frac{\partial}{\partial x}$, and $[V_p, W_p]=-y\frac{\partial}{\partial z}+z\frac{\partial}{\partial y}$. Easy to see the Lie bracket is not in the span. If this is true, then the distribution is not integrable. Could anyone remind me what is wrong? As to the second part, I did not have a clear clue of how to complete. A concrete computation would be appreciated.",,['differential-geometry']
37,The diffeomorphism of $\mathbb R^n$,The diffeomorphism of,\mathbb R^n,"If $f$ is a diffeomorphism of $\mathbb R^n$ and $K$ is a compact set in $\mathbb R^n$, can we find another diffeomorphism $\tilde f$ of $\mathbb R^n$ such that: (1)$f=\tilde f$ on a neighborhood of $K$. (2)There is a bounded set $V$ and $\tilde f=id$ outside $V$?","If $f$ is a diffeomorphism of $\mathbb R^n$ and $K$ is a compact set in $\mathbb R^n$, can we find another diffeomorphism $\tilde f$ of $\mathbb R^n$ such that: (1)$f=\tilde f$ on a neighborhood of $K$. (2)There is a bounded set $V$ and $\tilde f=id$ outside $V$?",,['differential-geometry']
38,Smoothness of level curves,Smoothness of level curves,,"Lets $f:\mathbb{R}^2 \to \mathbb{R} $, where $f$ is harmonic, continuous and non-constant. How do I go about showing that the level curves of $f$ are smooth? Thanks!","Lets $f:\mathbb{R}^2 \to \mathbb{R} $, where $f$ is harmonic, continuous and non-constant. How do I go about showing that the level curves of $f$ are smooth? Thanks!",,"['real-analysis', 'differential-geometry']"
39,Direction of the second derivative of an arclength parametrized curve,Direction of the second derivative of an arclength parametrized curve,,"I have a question, it's so simple and stupid ._.  If I have a planar curve parametrized by arc length, it's easy to show that the second derivate is orthogonal to the first derivate vector (tangent vector), thus if I rotate the tangent vector by an angle of $\pi/2$, I have a new vector (call it N), clearly N and the second derivate are parallel, the question is, is it true that the second derivate vector always lies ""inside"" the curve?","I have a question, it's so simple and stupid ._.  If I have a planar curve parametrized by arc length, it's easy to show that the second derivate is orthogonal to the first derivate vector (tangent vector), thus if I rotate the tangent vector by an angle of $\pi/2$, I have a new vector (call it N), clearly N and the second derivate are parallel, the question is, is it true that the second derivate vector always lies ""inside"" the curve?",,"['differential-geometry', 'plane-curves']"
40,Computing Curvatures,Computing Curvatures,,"What are some manifolds other than products of space forms for which the various curvature quantities can be computed easily? I'm interested in odd (real) dimensions just as much even, so I'd like to stay away from complex manifolds.","What are some manifolds other than products of space forms for which the various curvature quantities can be computed easily? I'm interested in odd (real) dimensions just as much even, so I'd like to stay away from complex manifolds.",,"['differential-geometry', 'riemannian-geometry']"
41,triangulation of manifolds,triangulation of manifolds,,"Good evening, When does a n-manifold have a triangulation? Thank you in advance","Good evening, When does a n-manifold have a triangulation? Thank you in advance",,"['general-topology', 'differential-geometry', 'triangulation']"
42,To what extent do the stories on manifolds carry over to schemes?,To what extent do the stories on manifolds carry over to schemes?,,"This is a follow-up (refinement?) of this question . In learning some algebraic topology, I've learned to think of an affine scheme as spec $R$.  (I've been told that this is a legitimate use of terminology because it provides an embedding of $Rings^{op}$ into a larger category.)  One construction we can do, for example, is create the ""tangent scheme"", which is obtained by localizing and completing.  The examples I've been looking at are $\hat{\mathbb{G}}_a$, $\hat{\mathbb{G}}_m$, $(\mathbb{Z}[[t]],F)$ (FGLs (1-dimensional, commutative) more generally), $T_1C^k(\hat{\mathbb{G}}_a,\hat{\mathbb{G}}_m)\cong C^k(\hat{\mathbb{G}}_a,\hat{\mathbb{G}}_a)$ (""commutative $k$-variate FGLs satisfying the 2-cocycle condition""), etc.  We then have exponential maps, which e.g. in the last case is $exp:C^k(\hat{\mathbb{G}}_a,\hat{\mathbb{G}}_a) \rightarrow C^k(\hat{\mathbb{G}}_a,\hat{\mathbb{G}}_m)$ given by $g\mapsto 1+g$. Just to test the waters, here is my question (although please feel free to push it further or in a different direction).  Presumably these exponential maps are not always injective.  Once we apply this picture to a particular ring (or perhaps even before?), can we translate differential-geometric ideas like conjugate points, geodesics, ""$exp$ is a local isomorphism"", etc. into algebro-geometric language?  When we can, which theorems for manifolds carry over to schemes and which must we discard?","This is a follow-up (refinement?) of this question . In learning some algebraic topology, I've learned to think of an affine scheme as spec $R$.  (I've been told that this is a legitimate use of terminology because it provides an embedding of $Rings^{op}$ into a larger category.)  One construction we can do, for example, is create the ""tangent scheme"", which is obtained by localizing and completing.  The examples I've been looking at are $\hat{\mathbb{G}}_a$, $\hat{\mathbb{G}}_m$, $(\mathbb{Z}[[t]],F)$ (FGLs (1-dimensional, commutative) more generally), $T_1C^k(\hat{\mathbb{G}}_a,\hat{\mathbb{G}}_m)\cong C^k(\hat{\mathbb{G}}_a,\hat{\mathbb{G}}_a)$ (""commutative $k$-variate FGLs satisfying the 2-cocycle condition""), etc.  We then have exponential maps, which e.g. in the last case is $exp:C^k(\hat{\mathbb{G}}_a,\hat{\mathbb{G}}_a) \rightarrow C^k(\hat{\mathbb{G}}_a,\hat{\mathbb{G}}_m)$ given by $g\mapsto 1+g$. Just to test the waters, here is my question (although please feel free to push it further or in a different direction).  Presumably these exponential maps are not always injective.  Once we apply this picture to a particular ring (or perhaps even before?), can we translate differential-geometric ideas like conjugate points, geodesics, ""$exp$ is a local isomorphism"", etc. into algebro-geometric language?  When we can, which theorems for manifolds carry over to schemes and which must we discard?",,"['algebraic-geometry', 'differential-geometry']"
43,Understanding Newtonian mechanics using concepts from differential geometry,Understanding Newtonian mechanics using concepts from differential geometry,,"In a book I'm reading ( Friedrich and Agricola ), I encountered the following definition of a ""Newtonian system"": An autonomous Newtonian system is a triple ( $M^m$ , $g$ , $X$ ) consiting of a manifold $M^m$ , a Riemanian metric $g$ , and a vector field on the space $TM$ such that $d\pi \circ X = Id_{TM^m}$ , where $\pi$ is the canonical projection from $TM$ to $M$ . Rationale for definition is that ""not all vector fields are allowed, since a force can act only in space"". I'm having trouble understanding the definition, because the composition of $d\pi$ and $X$ being identity is equivalent to $X$ having only components of the form $\frac{\partial}{\partial x^i}$ (and no components $\frac{\partial}{\partial v^i}$ ). The book then provides the following example on $TM \cong \mathbb{R^2}$ where $M=\mathbb{R}$ : $X = \dot{x} \frac{\partial}{\partial x} + \frac{1}{m}(-k^2x-\rho\dot{x})\frac{\partial}{\partial \dot{x}}$ which does not seem to fit!","In a book I'm reading ( Friedrich and Agricola ), I encountered the following definition of a ""Newtonian system"": An autonomous Newtonian system is a triple ( , , ) consiting of a manifold , a Riemanian metric , and a vector field on the space such that , where is the canonical projection from to . Rationale for definition is that ""not all vector fields are allowed, since a force can act only in space"". I'm having trouble understanding the definition, because the composition of and being identity is equivalent to having only components of the form (and no components ). The book then provides the following example on where : which does not seem to fit!",M^m g X M^m g TM d\pi \circ X = Id_{TM^m} \pi TM M d\pi X X \frac{\partial}{\partial x^i} \frac{\partial}{\partial v^i} TM \cong \mathbb{R^2} M=\mathbb{R} X = \dot{x} \frac{\partial}{\partial x} + \frac{1}{m}(-k^2x-\rho\dot{x})\frac{\partial}{\partial \dot{x}},"['differential-geometry', 'physics', 'differential-forms', 'classical-mechanics']"
44,Why the tautological bundle of the Grassmannian has only zero as global sections?,Why the tautological bundle of the Grassmannian has only zero as global sections?,,"I'm in a course on Complex Geometry, and I have been studying the Grassmannian $G_r(\mathbb{C}^N)$ as a complex manifold and the construction of its tautological bundle. As in the case of the tautological bundle of $\mathbb{CP}^n$ , there are no global sections except the zero section, but I don't know how to prove this using complex geometry techniques. A global section is also defined by a family of holomorphic functions $\{s_\alpha : U_\alpha \rightarrow \mathbb{C}^r \}$ , where $U_\alpha$ are open subsets of $G_r(\mathbb{C}^N)$ , satisfying the cocycle conditions $s_\alpha (x)= g_{\alpha \beta} (x) s_\beta(x)$ for all $x\in U_\alpha \cap U_\beta$ . We can describe $U_\alpha=\{[A]: \operatorname{det}A_\alpha \not = 0 \}$ , where $A_\alpha$ is a $k\times k$ -minor matrix of $A$ . Can anyone prove that the tautological bundle of $G_r(\mathbb{C}^N)$ has no global sections except the zero section using these results? Thanks.","I'm in a course on Complex Geometry, and I have been studying the Grassmannian as a complex manifold and the construction of its tautological bundle. As in the case of the tautological bundle of , there are no global sections except the zero section, but I don't know how to prove this using complex geometry techniques. A global section is also defined by a family of holomorphic functions , where are open subsets of , satisfying the cocycle conditions for all . We can describe , where is a -minor matrix of . Can anyone prove that the tautological bundle of has no global sections except the zero section using these results? Thanks.",G_r(\mathbb{C}^N) \mathbb{CP}^n \{s_\alpha : U_\alpha \rightarrow \mathbb{C}^r \} U_\alpha G_r(\mathbb{C}^N) s_\alpha (x)= g_{\alpha \beta} (x) s_\beta(x) x\in U_\alpha \cap U_\beta U_\alpha=\{[A]: \operatorname{det}A_\alpha \not = 0 \} A_\alpha k\times k A G_r(\mathbb{C}^N),"['differential-geometry', 'algebraic-geometry', 'complex-geometry', 'grassmannian']"
45,Prove that the Riemann curvature tensor is a tensor,Prove that the Riemann curvature tensor is a tensor,,"How would I prove that the Riemann curvature tensor $R: \scr X(M)^3  \scr X(M)$ , $R(X, Y )Z := \nabla_X\nabla_Y Z  \nabla_Y \nabla_XZ  \nabla_{[X,Y ]}Z$ , is indeed a tensor ? I thought I could use  this: (pag 41 in https://radbouduniversitypress.nl/site/books/m/10.54195/EFVF4478/ ) and simply prove that $R(fX_1+gX_2, Y )Z=fR(X_1, Y )Z+gR(X_2, Y )Z$ ...(1) $R(X, fY_1+gY_2 )Z=fR(X,Y_1)Z+gR(X, Y_2 )Z$ ...(2) and $R(X, Y )(fZ_1+gZ_2)=fR(X,Y)Z_1+gR(X, Y )Z_2$ ...(3) Am I on the right track?Isn't doing this indeed using proposition 2.7? My T.A said I cannot use 2.7 it as it is stated, but I don't see why And then how do I use proposition 2.7 then?","How would I prove that the Riemann curvature tensor , , is indeed a tensor ? I thought I could use  this: (pag 41 in https://radbouduniversitypress.nl/site/books/m/10.54195/EFVF4478/ ) and simply prove that ...(1) ...(2) and ...(3) Am I on the right track?Isn't doing this indeed using proposition 2.7? My T.A said I cannot use 2.7 it as it is stated, but I don't see why And then how do I use proposition 2.7 then?","R: \scr X(M)^3  \scr X(M) R(X, Y )Z := \nabla_X\nabla_Y Z  \nabla_Y \nabla_XZ  \nabla_{[X,Y ]}Z R(fX_1+gX_2, Y )Z=fR(X_1, Y )Z+gR(X_2, Y )Z R(X, fY_1+gY_2 )Z=fR(X,Y_1)Z+gR(X, Y_2 )Z R(X, Y )(fZ_1+gZ_2)=fR(X,Y)Z_1+gR(X, Y )Z_2","['differential-geometry', 'riemannian-geometry', 'tensors', 'general-relativity']"
46,Is this map a smooth embedding?,Is this map a smooth embedding?,,"Take the map $\gamma: (1,\infty) \to \mathbb{R}^2$ be defined by $t \mapsto (\frac{1}{t}\cos(2\pi t),\frac{1}{t}\sin(2\pi t))$ . I'm able to show that it is an injective smooth immersion. Now, I'd like to show that it is a smooth embedding. To this regard, I have to show that $\gamma: (1,\infty) \to \gamma((1,\infty))$ is a homeomorphism. Well, I suppose that it is sufficient to show that the above map is open or closed. I have no clue. In fact, taking an open set $U$ of $(1,\infty)$ , how to describe its image? Or at least, how to see that its image contains an open set? However, in Guillemin & Pollack's book I found that it is sufficient to show that the map is proper, i.e. the preimage of compact sets is again a compact set. Hence I take a compact $K \subseteq \gamma((1,\infty))$ . Then $K$ is compact in $\mathbb{R}^2$ , so that it is closed and bounded. What about its preimages? It is quite difficult to work with the function $\gamma$ !","Take the map be defined by . I'm able to show that it is an injective smooth immersion. Now, I'd like to show that it is a smooth embedding. To this regard, I have to show that is a homeomorphism. Well, I suppose that it is sufficient to show that the above map is open or closed. I have no clue. In fact, taking an open set of , how to describe its image? Or at least, how to see that its image contains an open set? However, in Guillemin & Pollack's book I found that it is sufficient to show that the map is proper, i.e. the preimage of compact sets is again a compact set. Hence I take a compact . Then is compact in , so that it is closed and bounded. What about its preimages? It is quite difficult to work with the function !","\gamma: (1,\infty) \to \mathbb{R}^2 t \mapsto (\frac{1}{t}\cos(2\pi t),\frac{1}{t}\sin(2\pi t)) \gamma: (1,\infty) \to \gamma((1,\infty)) U (1,\infty) K \subseteq \gamma((1,\infty)) K \mathbb{R}^2 \gamma","['differential-geometry', 'differential-topology']"
47,Why aren't integrals invariant over coordinate transformations?,Why aren't integrals invariant over coordinate transformations?,,"I am reading chapter 16 of Introduction to smooth manifolds by Lee and at the beginning of the chapter it is stated that  an integral is clearly not invariant under coordinate transformations. Why is that? It looks to me that it is the opposite I mean for instance if I change from  cartesian to polar coordinates the integral should be the same, no matter what coordinates I use","I am reading chapter 16 of Introduction to smooth manifolds by Lee and at the beginning of the chapter it is stated that  an integral is clearly not invariant under coordinate transformations. Why is that? It looks to me that it is the opposite I mean for instance if I change from  cartesian to polar coordinates the integral should be the same, no matter what coordinates I use",,"['differential-geometry', 'smooth-manifolds', 'differential-forms']"
48,Energy minimization doesn't seem to yield a geodesic,Energy minimization doesn't seem to yield a geodesic,,"I'm minimizing (through optimization using gradient descent) the energy $E(\gamma)=\int_{t_1}^{t_2} g_{\alpha\beta}(\gamma^{\alpha})'(\gamma^{\beta})'\operatorname{d}\!t$ of a curve using the inner product induced by the metric tensor. In my case the metric tensor is from information geometry (the Fisher metric) which is very simple for a univariate gaussian. However, given that I'm using the Fisher metric as the metric tensor, I would expect that a geodesic of a univariate gaussian to follow an arc (e.g. shortest path between two univariate gaussian distributions is not a straight line as shown here ). However, after optimizing the curve to minimize the energy, I'm always getting a straight line as distance between two univariate gaussians (using the same start/end points of the linked article from geomstats). Am I missing something ? More details: I'm using a parametrized cubic spline curve (just as in here ), just to give more details about which curve I'm using. Trying to make the question more simple I'm using the following metric (the Fisher metric as linked above) for computing the inner products: $[ 1/scale, 2/scale ]$ (the matrix is 2x2, this is the diagonal, other elements are zero) I have 2 parameters (mean, scale), and as you can see, the metric depends only on the scale. These parameters are parametrizing a univariate gaussian distribution (w/ mean and scale), and it is known that this metric induces an hyperbolic geometry (you can understand this better by looking at this animation , just click and drag and you will see the curve geodesic in the parameter space). (note that y is my scale and x is mean, the dark black arc line is the geodesic, but this is not what I'm getting ) Now, if I minimize $E(\gamma)$ (using gradient descent) to optimize the curve parameters, what I get is a straight line connecting the parameters in the parameter space, while I would expect it to be curved as induced by the metric tensor.","I'm minimizing (through optimization using gradient descent) the energy of a curve using the inner product induced by the metric tensor. In my case the metric tensor is from information geometry (the Fisher metric) which is very simple for a univariate gaussian. However, given that I'm using the Fisher metric as the metric tensor, I would expect that a geodesic of a univariate gaussian to follow an arc (e.g. shortest path between two univariate gaussian distributions is not a straight line as shown here ). However, after optimizing the curve to minimize the energy, I'm always getting a straight line as distance between two univariate gaussians (using the same start/end points of the linked article from geomstats). Am I missing something ? More details: I'm using a parametrized cubic spline curve (just as in here ), just to give more details about which curve I'm using. Trying to make the question more simple I'm using the following metric (the Fisher metric as linked above) for computing the inner products: (the matrix is 2x2, this is the diagonal, other elements are zero) I have 2 parameters (mean, scale), and as you can see, the metric depends only on the scale. These parameters are parametrizing a univariate gaussian distribution (w/ mean and scale), and it is known that this metric induces an hyperbolic geometry (you can understand this better by looking at this animation , just click and drag and you will see the curve geodesic in the parameter space). (note that y is my scale and x is mean, the dark black arc line is the geodesic, but this is not what I'm getting ) Now, if I minimize (using gradient descent) to optimize the curve parameters, what I get is a straight line connecting the parameters in the parameter space, while I would expect it to be curved as induced by the metric tensor.","E(\gamma)=\int_{t_1}^{t_2} g_{\alpha\beta}(\gamma^{\alpha})'(\gamma^{\beta})'\operatorname{d}\!t [ 1/scale, 2/scale ] E(\gamma)","['differential-geometry', 'fisher-information', 'information-geometry']"
49,Doubt hindering my intution about vector bundles,Doubt hindering my intution about vector bundles,,"Lee, Introduction to smooth manifolds, defines a vector bundle $\pi :E \rightarrow M$ via some local trivialization maps $\pi^{-1}(U) \rightarrow U \times R^k$ , where $U \subset M$ . There is something about this that is a bit hindering my intuition. Do I have to consider $R^k$ here as some coordinates of a vector space, or as a fixed vector space itself? Why did not Lee define just a fixed a vector space $V$ and define trivializations as functions $\pi^{-1}(U) \rightarrow U \times V$ ?. A vector space $V$ is still a manifold and in some sense this definition is less confusing for me because $R^k$ can be either considered as a fixed vector space, or some coordinates after fixing a base in $V$ ... $U \times R^k$ looks to me a bit weird since $U$ is just a subset of a manifold, whereas $R^k$ looks like some coordinates in a chart. Please be patient and consider that I am still trying to build a basic understanding/intuition..","Lee, Introduction to smooth manifolds, defines a vector bundle via some local trivialization maps , where . There is something about this that is a bit hindering my intuition. Do I have to consider here as some coordinates of a vector space, or as a fixed vector space itself? Why did not Lee define just a fixed a vector space and define trivializations as functions ?. A vector space is still a manifold and in some sense this definition is less confusing for me because can be either considered as a fixed vector space, or some coordinates after fixing a base in ... looks to me a bit weird since is just a subset of a manifold, whereas looks like some coordinates in a chart. Please be patient and consider that I am still trying to build a basic understanding/intuition..",\pi :E \rightarrow M \pi^{-1}(U) \rightarrow U \times R^k U \subset M R^k V \pi^{-1}(U) \rightarrow U \times V V R^k V U \times R^k U R^k,"['general-topology', 'differential-geometry', 'manifolds', 'self-learning']"
50,"Prove that if $M$ is simply connected and $H^2(g) = 0$, then $M$ is symplectomorphic to an adjoint orbit.","Prove that if  is simply connected and , then  is symplectomorphic to an adjoint orbit.",M H^2(g) = 0 M,"A manifold $M$ is said to be homogeneous if there exists a transitive action $G  M$ . Let $(M,)$ be a homogeneous symplectic manifold, i.e., there exists a transitive and symplectic action $G  M$ . Prove that if $M$ is simply connected and $H^2(g) = 0$ , then $M$ is symplectomorphic to an adjoint orbit. Here $g$ is the lie algera of $G$ (the action group) and $H^*(g)$ is the  Chevalley-Eilenberg cohomology of the lie algebra $g$ . I would appreciate it if someone could help me understand and prove this statement. Specifically, I would like to know the steps and reasoning behind the proof. Could you please provide a detailed explanation or point me to any relevant resources that can help me grasp this concept? Thank you in advance for your assistance!","A manifold is said to be homogeneous if there exists a transitive action . Let be a homogeneous symplectic manifold, i.e., there exists a transitive and symplectic action . Prove that if is simply connected and , then is symplectomorphic to an adjoint orbit. Here is the lie algera of (the action group) and is the  Chevalley-Eilenberg cohomology of the lie algebra . I would appreciate it if someone could help me understand and prove this statement. Specifically, I would like to know the steps and reasoning behind the proof. Could you please provide a detailed explanation or point me to any relevant resources that can help me grasp this concept? Thank you in advance for your assistance!","M G  M (M,) G  M M H^2(g) = 0 M g G H^*(g) g","['differential-geometry', 'manifolds', 'lie-groups', 'group-actions', 'symplectic-geometry']"
51,how to prove a torus in $\mathbb{R}^3$ is a smooth manifold,how to prove a torus in  is a smooth manifold,\mathbb{R}^3,"I want to prove that $T^2=\{(x,y,z)\in\mathbb{R}^3:(\sqrt{x^2+y^2}-R)^2+z^2=r^2\}\ (r<R)$ is a smooth manifold. Since I am a student in physics and haven't learned much math, so I want to prove it by constructing an atlas with smooth transition functions. I tried taking something like $U_1=T^2\backslash\{(R\cos\theta,R\sin\theta,r):\theta\in[0,2\pi)\}\cup\{(R+r\cos\theta,0,R+r\sin\theta):\theta\in[0,2\pi)\}$ (namely a torus deleting the circle on the top and the circle in half plane $y=0,x>0$ ) and $\phi_1:U_1\to(0,2\pi)\times(0,2\pi):(R\cos\theta+r\cos\theta\sin\phi,R\sin\theta+r\sin\theta\sin\phi,r\cos\phi)\to(\theta,\phi)$ . Then I found that it seems I need to construct 2 more similar charts to get an atlas. Am I correct? Can we construct it more elegantly?","I want to prove that is a smooth manifold. Since I am a student in physics and haven't learned much math, so I want to prove it by constructing an atlas with smooth transition functions. I tried taking something like (namely a torus deleting the circle on the top and the circle in half plane ) and . Then I found that it seems I need to construct 2 more similar charts to get an atlas. Am I correct? Can we construct it more elegantly?","T^2=\{(x,y,z)\in\mathbb{R}^3:(\sqrt{x^2+y^2}-R)^2+z^2=r^2\}\ (r<R) U_1=T^2\backslash\{(R\cos\theta,R\sin\theta,r):\theta\in[0,2\pi)\}\cup\{(R+r\cos\theta,0,R+r\sin\theta):\theta\in[0,2\pi)\} y=0,x>0 \phi_1:U_1\to(0,2\pi)\times(0,2\pi):(R\cos\theta+r\cos\theta\sin\phi,R\sin\theta+r\sin\theta\sin\phi,r\cos\phi)\to(\theta,\phi)","['differential-geometry', 'smooth-manifolds', 'submanifold']"
52,Find an $\omega \in \text{Alt}^2(\Bbb R^4)$ such that $\omega \wedge \omega \ne 0$.,Find an  such that .,\omega \in \text{Alt}^2(\Bbb R^4) \omega \wedge \omega \ne 0,"Find an $\omega \in \text{Alt}^2(\Bbb R^4)$ such that $\omega \wedge \omega \ne 0$ . What is the intuition for the problem? Since $\omega \in \text{Alt}^2(\Bbb R^4)$ we know that $\omega : \Bbb R^4 \to \Bbb R$ is an alternating $4$ -linear map. That is $$\omega(x_1,x_2,x_3,x_4) \in \Bbb R$$ and that $$\omega(x_1,x_2,x_3,x_4) = -\omega(x_2,x_1,x_3,x_4)$$ for example. I've also seen that this $\omega \wedge \omega$ can be tought of as the volume of a parallelotope so is the question asking me to find an $\omega \in \text{Alt}^2(\Bbb R^4)$ such that the ""volume"" with itself is nonzero? Was it not true that the wedge product of any $n$ -form with itself was always $0$ ?","Find an such that . What is the intuition for the problem? Since we know that is an alternating -linear map. That is and that for example. I've also seen that this can be tought of as the volume of a parallelotope so is the question asking me to find an such that the ""volume"" with itself is nonzero? Was it not true that the wedge product of any -form with itself was always ?","\omega \in \text{Alt}^2(\Bbb R^4) \omega \wedge \omega \ne 0 \omega \in \text{Alt}^2(\Bbb R^4) \omega : \Bbb R^4 \to \Bbb R 4 \omega(x_1,x_2,x_3,x_4) \in \Bbb R \omega(x_1,x_2,x_3,x_4) = -\omega(x_2,x_1,x_3,x_4) \omega \wedge \omega \omega \in \text{Alt}^2(\Bbb R^4) n 0","['differential-geometry', 'exterior-algebra']"
53,Definition of the formal $L^2$-adjoint $T^*$ of a linear operator $T:C^\infty(T^*M\odot T^*M)\to C^\infty(M)$,Definition of the formal -adjoint  of a linear operator,L^2 T^* T:C^\infty(T^*M\odot T^*M)\to C^\infty(M),"Let $(M,g)$ be a Riemannian manifold, $C^\infty(T^*M\odot T^*M)$ the space of all smooth symmetric $2$ -tensor fields on $M$ , and $C^\infty(M)$ the space of all smooth functions on $M$ . I'd like to know the definition of the formal $L^2$ -adjoint $T^*$ of a linear operator $T:C^\infty(T^*M\odot T^*M)\to C^\infty(M)$ . For a concrete example of $T$ , one can see Linearization of scalar curvature: $DR|_g(h)=-\Delta_g(\mathrm{tr}_g h)+\mathrm{div}_g(\mathrm{div}_g h)-\langle\mathrm{Ric}_g,h\rangle_g$ to know about the linearized scalar curvature. In a linear algebra course or a functional analysis course, it is a standard practice to define the adjoint of a linear operator between inner product spaces, but somehow I didn't find too much reference on formal adjoints . So far, I've got only one example: given a closed manifold, we know the gradient operator $\mathrm{grad}$ and $-\mathrm{div}$ are the formal adjoints of each other in the sense that $$\int_M\langle\mathrm{grad}f,X\rangle_g dV_g=\int_M f(-\mathrm{div}X) dV_g\tag{1}$$ for every $f\in C^\infty(M)$ and every smooth vector field $X$ in $\mathfrak{X}(M)$ . How about $T^*$ ? By analogy with the previous example and my experience of ordinary adjoint operators, it seems like I have to find a linear operator $T^*$ that goes from $C^\infty(M)$ to $C^\infty(T^*M\odot T^*M)$ and satisfies $$\langle T(A),f\rangle_{L^2}=\langle A,T^*(f)\rangle_\color{red}{?}\tag{2}$$ for every $A\in C^\infty(T^*M\odot T^*M)$ and every $f\in C^\infty(M)$ . Having learned the Lebesgue space $L^p(M)$ , I don't feel pressured about the $L^2$ bracket in (2), but what should I do with the mysterious bracket in the same equation? Is that an inner product of covariant $2$ -tensor fields? Much is appreciated if someone could offer an authoritative reference that clearly defines the formal adjoint of a mapping between spaces of smooth sections of vector bundles. Thank you.","Let be a Riemannian manifold, the space of all smooth symmetric -tensor fields on , and the space of all smooth functions on . I'd like to know the definition of the formal -adjoint of a linear operator . For a concrete example of , one can see Linearization of scalar curvature: to know about the linearized scalar curvature. In a linear algebra course or a functional analysis course, it is a standard practice to define the adjoint of a linear operator between inner product spaces, but somehow I didn't find too much reference on formal adjoints . So far, I've got only one example: given a closed manifold, we know the gradient operator and are the formal adjoints of each other in the sense that for every and every smooth vector field in . How about ? By analogy with the previous example and my experience of ordinary adjoint operators, it seems like I have to find a linear operator that goes from to and satisfies for every and every . Having learned the Lebesgue space , I don't feel pressured about the bracket in (2), but what should I do with the mysterious bracket in the same equation? Is that an inner product of covariant -tensor fields? Much is appreciated if someone could offer an authoritative reference that clearly defines the formal adjoint of a mapping between spaces of smooth sections of vector bundles. Thank you.","(M,g) C^\infty(T^*M\odot T^*M) 2 M C^\infty(M) M L^2 T^* T:C^\infty(T^*M\odot T^*M)\to C^\infty(M) T DR|_g(h)=-\Delta_g(\mathrm{tr}_g h)+\mathrm{div}_g(\mathrm{div}_g h)-\langle\mathrm{Ric}_g,h\rangle_g \mathrm{grad} -\mathrm{div} \int_M\langle\mathrm{grad}f,X\rangle_g dV_g=\int_M f(-\mathrm{div}X) dV_g\tag{1} f\in C^\infty(M) X \mathfrak{X}(M) T^* T^* C^\infty(M) C^\infty(T^*M\odot T^*M) \langle T(A),f\rangle_{L^2}=\langle A,T^*(f)\rangle_\color{red}{?}\tag{2} A\in C^\infty(T^*M\odot T^*M) f\in C^\infty(M) L^p(M) L^2 2","['differential-geometry', 'riemannian-geometry', 'curvature', 'adjoint-operators']"
54,Are there homomorphisms $SU(2) \xrightarrow{} SU(2)$ with higher homotopy?,Are there homomorphisms  with higher homotopy?,SU(2) \xrightarrow{} SU(2),"I am quite new to the subject, so I apologize in advance for anything sloppy which I may write. The homotopy group $\pi_3(SU(2))= \mathbb{Z}$ classifies maps of the form $S^3 \simeq SU(2) \xrightarrow{} SU(2)$ , where $\mathbb{Z}$ , roughly speaking, measures how many times $SU(2)$ wraps onto itself. These maps, and their homotopy classification, appear in the standard construction of instantons via bundles. For example, we have that the map $g_0: x \in S^3 \mapsto e \in SU(2)$ , with $e$ being the identity, belongs to the class $0$ of $\pi_3(SU(2))$ . The following map belongs to the class $1$ : $g_1: (x_1,x_2,x_3,x_4)\in S^3 \mapsto \frac{1}{r} (x^4 \mathbb{1} + \sum_i x_i \sigma_i) \in SU(2)$ , where $r^2=x_1^2 + x_2^2 + x_3^2 +x_4^2$ , $\sigma_i$ are the Pauli matrices and $\mathbb{1}$ is the identity. For $n>1$ , the map $g_n: x \mapsto r^{-n}(x^4 \mathbb{1} + \sum_i x_i \sigma_i)^n$ belongs to the class $n$ of $\pi_3(SU(2))$ . Clearly, all these maps can be thought to be maps from $SU(2)$ to $SU(2)$ . $g_0$ and $g_1$ are homomorphisms, i.e. $g(x y)=g(x)g(y)$ . However, since $SU(2)$ is not abelian, it is evident that $g_n$ with $n>1$ is $not$ a homomorphism. Now, finally to my question: are there homomorphisms $SU(2) \xrightarrow{} SU(2)$ that belong to the class $n$ of $\pi_3(SU(2))$ for $n>1$ ? If so, could you give me an example? Thanks in advance!","I am quite new to the subject, so I apologize in advance for anything sloppy which I may write. The homotopy group classifies maps of the form , where , roughly speaking, measures how many times wraps onto itself. These maps, and their homotopy classification, appear in the standard construction of instantons via bundles. For example, we have that the map , with being the identity, belongs to the class of . The following map belongs to the class : , where , are the Pauli matrices and is the identity. For , the map belongs to the class of . Clearly, all these maps can be thought to be maps from to . and are homomorphisms, i.e. . However, since is not abelian, it is evident that with is a homomorphism. Now, finally to my question: are there homomorphisms that belong to the class of for ? If so, could you give me an example? Thanks in advance!","\pi_3(SU(2))= \mathbb{Z} S^3 \simeq SU(2) \xrightarrow{} SU(2) \mathbb{Z} SU(2) g_0: x \in S^3 \mapsto e \in SU(2) e 0 \pi_3(SU(2)) 1 g_1: (x_1,x_2,x_3,x_4)\in S^3 \mapsto \frac{1}{r} (x^4 \mathbb{1} + \sum_i x_i \sigma_i) \in SU(2) r^2=x_1^2 + x_2^2 + x_3^2 +x_4^2 \sigma_i \mathbb{1} n>1 g_n: x \mapsto r^{-n}(x^4 \mathbb{1} + \sum_i x_i \sigma_i)^n n \pi_3(SU(2)) SU(2) SU(2) g_0 g_1 g(x y)=g(x)g(y) SU(2) g_n n>1 not SU(2) \xrightarrow{} SU(2) n \pi_3(SU(2)) n>1","['differential-geometry', 'lie-groups', 'homotopy-theory', 'group-homomorphism', 'unitary-matrices']"
55,Isotropy group of a totally geodesic submanifold in a Riemannian homogeneous space acts transitively on the submanifold,Isotropy group of a totally geodesic submanifold in a Riemannian homogeneous space acts transitively on the submanifold,,"I was wondering if the following holds: Let $G/H$ be a (complete) Riemannian homogeneous manifold (i.e., a homogeneous manifold with a prescribed Riemannian metric on it, and $G$ acts transitively on $G/H$ through isometries). Suppose $\xi_0$ is a totally geodesic submanifold of $G/H$ , and let $H_0 = \left\lbrace g \in G | g \cdot \xi_0 = \xi_0 \right\rbrace$ be its isotropy group. Can we say that $H_0$ acts transitively on $\xi_0$ ? It seems to be true in simple cases of $\mathbb{R}^n$ and $\mathbb{S}^n$ . In the first case, $G$ is the group of rigid motions characterized by the matrices of the type $\left[ \begin{matrix} A & b \\ 0& 1 \end{matrix} \right]$ , where $A \in O(n)$ and $b \in \mathbb{R}^n$ , with the action given by $\left[ \begin{matrix} A & b \\ 0& 1 \end{matrix} \right] \cdot x = Ax + b$ , for $x \in \mathbb{R}^n$ . Here, if I consider $\mathbb{R}^{n - 1}$ as a totally geodesic submanifold of $\mathbb{R}^n$ , we get its isotropy group to be $$H_0 = \left\lbrace \left[ \begin{matrix} A & 0 & b \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{matrix} \right] : A \in SO(n-1) \text{ and } b \in \mathbb{R}^{n - 1} \right\rbrace \cup \left\lbrace \left[ \begin{matrix} A & 0 & b \\ 0 & -1 & 0 \\ 0 & 0 & 1 \end{matrix} \right] : A \in O^{-}(n-1) \text{ and } b \in \mathbb{R}^{n - 1} \right\rbrace,$$ where $O^{-}(n-1)$ is the set of all orthogonal matrices with determinant negative. From this characterization, it is easy to see that $H_0$ does act transitively on $\xi_0$ (through translations alone!). Similar computations can be done for the case of $\mathbb{S}^n$ , where the totally geodesic submanifolds are lower dimensional spheres. Now, I want to generalize this to arbitrary Riemannian homogeneous manifolds (that need not be embedded in any Euclidean space, like $\mathbb{S}^n$ ). I have an intuition that this should be true. That is because, just like the case of $\mathbb{R}^n$ , there are group elements from $G$ that take one point to another, and then there are elements from $H_0$ and do not take us outside $\xi_0$ . Therefore, it seems that by choosing proper element, we will remain inside $\xi_0$ and yet be able to go from one point to another using elements of $H_0$ . Any help in formalizing these ideas (or disproving them) will be highly appreciated!","I was wondering if the following holds: Let be a (complete) Riemannian homogeneous manifold (i.e., a homogeneous manifold with a prescribed Riemannian metric on it, and acts transitively on through isometries). Suppose is a totally geodesic submanifold of , and let be its isotropy group. Can we say that acts transitively on ? It seems to be true in simple cases of and . In the first case, is the group of rigid motions characterized by the matrices of the type , where and , with the action given by , for . Here, if I consider as a totally geodesic submanifold of , we get its isotropy group to be where is the set of all orthogonal matrices with determinant negative. From this characterization, it is easy to see that does act transitively on (through translations alone!). Similar computations can be done for the case of , where the totally geodesic submanifolds are lower dimensional spheres. Now, I want to generalize this to arbitrary Riemannian homogeneous manifolds (that need not be embedded in any Euclidean space, like ). I have an intuition that this should be true. That is because, just like the case of , there are group elements from that take one point to another, and then there are elements from and do not take us outside . Therefore, it seems that by choosing proper element, we will remain inside and yet be able to go from one point to another using elements of . Any help in formalizing these ideas (or disproving them) will be highly appreciated!","G/H G G/H \xi_0 G/H H_0 = \left\lbrace g \in G | g \cdot \xi_0 = \xi_0 \right\rbrace H_0 \xi_0 \mathbb{R}^n \mathbb{S}^n G \left[ \begin{matrix} A & b \\ 0& 1 \end{matrix} \right] A \in O(n) b \in \mathbb{R}^n \left[ \begin{matrix} A & b \\ 0& 1 \end{matrix} \right] \cdot x = Ax + b x \in \mathbb{R}^n \mathbb{R}^{n - 1} \mathbb{R}^n H_0 = \left\lbrace \left[ \begin{matrix} A & 0 & b \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{matrix} \right] : A \in SO(n-1) \text{ and } b \in \mathbb{R}^{n - 1} \right\rbrace \cup \left\lbrace \left[ \begin{matrix} A & 0 & b \\ 0 & -1 & 0 \\ 0 & 0 & 1 \end{matrix} \right] : A \in O^{-}(n-1) \text{ and } b \in \mathbb{R}^{n - 1} \right\rbrace, O^{-}(n-1) H_0 \xi_0 \mathbb{S}^n \mathbb{S}^n \mathbb{R}^n G H_0 \xi_0 \xi_0 H_0","['differential-geometry', 'riemannian-geometry', 'lie-groups', 'group-actions', 'homogeneous-spaces']"
56,Do we have $\int_M \mathcal L_X\omega=0$ for $m$-form $\omega$?,Do we have  for -form ?,\int_M \mathcal L_X\omega=0 m \omega,"Let $M$ be an oriented $m$ -manifold without boundary, $X\in \mathfrak X(M)$ be a vector field, and $\omega \in \Omega^m_c(M)$ be a compactly supported top-degree differential form. Question : Do we always have $$\int_M \mathcal L_X\omega=0,$$ where $\mathcal L_X$ is the Lie derivative? Motivation : The integration operation has a diffeomorphism invariance, i.e., if $F:M\to M$ is an orientation-preserving diffeomorphism, then $$\int_M \omega = \int_M F^*\omega.$$ Now, suppose that the diffeomorphism $F$ is infinitesimal, i.e., $F$ maps each $p\in M$ to a point that is infinitesimally separated from $p$ . Such infinitesimal diffeomorphism can be heuristically represented by a vector field $X\in \mathfrak X(M)$ , which is an 'arrow' from $p$ to $F(p)$ . Furthermore, the infinitesimal version of the pullback $F^*\omega$ is the Lie derivative $\mathcal L_X\omega$ . Hence, I suspect that the infinitesimal statement of the diffeomorphism invariance of integral should be $$\int_M \mathcal L_X\omega=0.$$","Let be an oriented -manifold without boundary, be a vector field, and be a compactly supported top-degree differential form. Question : Do we always have where is the Lie derivative? Motivation : The integration operation has a diffeomorphism invariance, i.e., if is an orientation-preserving diffeomorphism, then Now, suppose that the diffeomorphism is infinitesimal, i.e., maps each to a point that is infinitesimally separated from . Such infinitesimal diffeomorphism can be heuristically represented by a vector field , which is an 'arrow' from to . Furthermore, the infinitesimal version of the pullback is the Lie derivative . Hence, I suspect that the infinitesimal statement of the diffeomorphism invariance of integral should be","M m X\in \mathfrak X(M) \omega \in \Omega^m_c(M) \int_M \mathcal L_X\omega=0, \mathcal L_X F:M\to M \int_M \omega = \int_M F^*\omega. F F p\in M p X\in \mathfrak X(M) p F(p) F^*\omega \mathcal L_X\omega \int_M \mathcal L_X\omega=0.","['differential-geometry', 'lie-derivative']"
57,finding the volume form under a change of metric,finding the volume form under a change of metric,,"Let $(M,g_{ij})$ be a smooth Riemannian manifold. We introduce a new metric $\tilde{g}_{ij}: = (e^{\phi} g)_{ij}$ where $\phi:M \to \mathbb{R}$ is a smooth function. Now we want to calculate the volume form w.r.t. the new metric in terms of the old volume form. All of this in local coordinates. I found two ways to do this: Let $(U,x_1,...,x_n)$ be the local coordinates on M, such that the frame $(\partial x_1,..., \partial x_n)$ is orthonormal w.r.t. $g_{ij}$ . the ""old"" volume form is then just $vol = dx_1 \wedge dx_2 \wedge ... \wedge dx_n$ . an orthonormal frame $(f_1,...,f_n)$ w.r.t. $\tilde{g}_{ij}$ is then given by $f_i := e^{-\frac{\phi}{2}} \partial{x_i}$ . So that we get the new volume form: $vol_{new} = e^{-\frac{\phi}{2}} d{x_1} \wedge ... \wedge e^{-\frac{\phi}{2}}d{x_n} = e^{-n\frac{\phi}{2}} vol$ $vol_{new} = \sqrt{det(\tilde{g}_{ij}})dx_1 \wedge ... \wedge dx_n = e^{n \frac{\phi}{2}}\sqrt{(det(g_{ij})}dx_1 \wedge...\wedge dx_n = e^{n \frac{\phi}{2}} vol$ . Now why don't I get the same result ?","Let be a smooth Riemannian manifold. We introduce a new metric where is a smooth function. Now we want to calculate the volume form w.r.t. the new metric in terms of the old volume form. All of this in local coordinates. I found two ways to do this: Let be the local coordinates on M, such that the frame is orthonormal w.r.t. . the ""old"" volume form is then just . an orthonormal frame w.r.t. is then given by . So that we get the new volume form: . Now why don't I get the same result ?","(M,g_{ij}) \tilde{g}_{ij}: = (e^{\phi} g)_{ij} \phi:M \to \mathbb{R} (U,x_1,...,x_n) (\partial x_1,..., \partial x_n) g_{ij} vol = dx_1 \wedge dx_2 \wedge ... \wedge dx_n (f_1,...,f_n) \tilde{g}_{ij} f_i := e^{-\frac{\phi}{2}} \partial{x_i} vol_{new} = e^{-\frac{\phi}{2}} d{x_1} \wedge ... \wedge e^{-\frac{\phi}{2}}d{x_n} = e^{-n\frac{\phi}{2}} vol vol_{new} = \sqrt{det(\tilde{g}_{ij}})dx_1 \wedge ... \wedge dx_n = e^{n \frac{\phi}{2}}\sqrt{(det(g_{ij})}dx_1 \wedge...\wedge dx_n = e^{n \frac{\phi}{2}} vol","['differential-geometry', 'riemannian-geometry', 'volume', 'change-of-basis']"
58,Every diagrammatic map has only finitely many double points,Every diagrammatic map has only finitely many double points,,"Definition: A smooth map $\gamma\colon \Bbb S^1\to \Bbb R^2$ is called diagrammatic if the following conditions are satisfied: $(1)$ the map is an immersion, i.e., derivative at each point is non-zero, $(2)$ if $z\neq w\in \Bbb S^1$ satisfy $\gamma(z)=\gamma(w)$ , then $\gamma'(z)$ and $\gamma'(w)$ are linearly independent, $(3)$ given any $p\in \gamma(\Bbb S^1)$ , the preimage $\gamma^{-1}(p)$ consists of either one or two points. Furthermore, any $p\in \gamma(\Bbb S^1)$ for which there exist $z\neq w\in  \Bbb S^1$ with $\gamma(z)=p=\gamma(w)$ is called a double point of $\gamma$ . I am solving the following Problem: Problem: Every diagrammatic map has only finitely many double points. My Idea: Suppose not, then there is a sequence $\{p_n\}$ of distinct double points of $\gamma$ . Passing to a subsequence, if needed, and using compactness of $\gamma(\Bbb S^1)$ , we may assume that $p_n\to \ell\in \gamma(\Bbb S^1)$ . Write $\{z_n,w_n\}=\gamma^{-1}(p_n)$ . Passing to subsequence and compactness of $\Bbb S^1$ , let $z_n\to z$ . Thus $\gamma(z)=\ell$ . Now, $\gamma'(z_n)\to \gamma'(z)$ and $\gamma'(w_n)\to \gamma'(z)$ as $\gamma$ is $C^\infty$ -smooth. Since $\gamma'(z_n)$ and $\gamma'(w_n)$ are linearly independent, $\gamma'(z)=0$ , a contradiction to the assumption that $\gamma$ is an immersion. Is my idea correct??","Definition: A smooth map is called diagrammatic if the following conditions are satisfied: the map is an immersion, i.e., derivative at each point is non-zero, if satisfy , then and are linearly independent, given any , the preimage consists of either one or two points. Furthermore, any for which there exist with is called a double point of . I am solving the following Problem: Problem: Every diagrammatic map has only finitely many double points. My Idea: Suppose not, then there is a sequence of distinct double points of . Passing to a subsequence, if needed, and using compactness of , we may assume that . Write . Passing to subsequence and compactness of , let . Thus . Now, and as is -smooth. Since and are linearly independent, , a contradiction to the assumption that is an immersion. Is my idea correct??","\gamma\colon \Bbb S^1\to \Bbb R^2 (1) (2) z\neq w\in \Bbb S^1 \gamma(z)=\gamma(w) \gamma'(z) \gamma'(w) (3) p\in \gamma(\Bbb S^1) \gamma^{-1}(p) p\in \gamma(\Bbb S^1) z\neq w\in
 \Bbb S^1 \gamma(z)=p=\gamma(w) \gamma \{p_n\} \gamma \gamma(\Bbb S^1) p_n\to \ell\in \gamma(\Bbb S^1) \{z_n,w_n\}=\gamma^{-1}(p_n) \Bbb S^1 z_n\to z \gamma(z)=\ell \gamma'(z_n)\to \gamma'(z) \gamma'(w_n)\to \gamma'(z) \gamma C^\infty \gamma'(z_n) \gamma'(w_n) \gamma'(z)=0 \gamma","['differential-geometry', 'algebraic-topology', 'differential-topology', 'smooth-manifolds', 'knot-theory']"
59,Properties within a single chart on a topological manifold and smoothness,Properties within a single chart on a topological manifold and smoothness,,"Reading on Wikipedia it is stated that A topological manifold looks locally like a Euclidean space in a rather weak manner: while for each individual chart it is possible to distinguish differentiable functions or measure distances and angles, merely by virtue of being a topological manifold a space does not have any particular and consistent choice of such concepts.[7] Within a single chart, is there a well-defined concept of distance? Further, if this is the case, what other structures, that would otherwise be traditionally be added to a topological manifold, like a symplectic structure, is present in a single chart? As a second question, I am trying to understand exactly what goes wrong for performing calculus when the transition maps of a manifold are not smooth? i.e what exactly does the smoothness of transition maps bring? [7] Kervaire, M. (1961). ""A Manifold which does not admit any differentiable structure"". Comment. Math. Helv. 35 (1): 114. doi:10.1007/BF02565940. S2CID 120977898.","Reading on Wikipedia it is stated that A topological manifold looks locally like a Euclidean space in a rather weak manner: while for each individual chart it is possible to distinguish differentiable functions or measure distances and angles, merely by virtue of being a topological manifold a space does not have any particular and consistent choice of such concepts.[7] Within a single chart, is there a well-defined concept of distance? Further, if this is the case, what other structures, that would otherwise be traditionally be added to a topological manifold, like a symplectic structure, is present in a single chart? As a second question, I am trying to understand exactly what goes wrong for performing calculus when the transition maps of a manifold are not smooth? i.e what exactly does the smoothness of transition maps bring? [7] Kervaire, M. (1961). ""A Manifold which does not admit any differentiable structure"". Comment. Math. Helv. 35 (1): 114. doi:10.1007/BF02565940. S2CID 120977898.",,"['differential-geometry', 'differential-topology']"
60,"What does the dual parallel transport, or conjugate affine connection, actually do?","What does the dual parallel transport, or conjugate affine connection, actually do?",,"I'm reading both Frank Nielsen's An Elementary Introduction to Information Geometry as well as Amari's Information geometry and its applications , and confused by something they use (I'll focus on AEITIG here). He first introduces the concept of an affine connection $\nabla$ , which is basically a covariant derivative on vector fields, so if we have vector fields $X, Y$ , it tells us how to calculate $\nabla_X Y$ , i.e., how $Y$ changes as we move in the $X$ direction, at each point. If we have the basis $(\partial_i) = (\frac{\partial}{\partial x_i})$ for a smooth chart $(U, x)$ , then exactly what the connection does is defined in terms of the Christoffel symbols: $\nabla_{\partial_i} \partial_j = \Gamma_{ij}^k \partial_k$ This all makes sense to me. Then, from what I understand, if we want to transport a vector from the tangent plane at one point to another, we could do some sort of integration of that derivative over the path taken, and that would give the final vector. He then introduces (section 3) the concept of a conjugate connection $\nabla^\ast$ that's conjugate to a given connection $\nabla$ . He mentions a few properties of it, like an identity that must be satisfied for it to be conjugate, but never what it actually does or how to figure it out. Here's that identity: What I don't understand is the following: What does the conjugate connection actually do to a vector ? I.e., for the regular connection, it's clear that it's saying how it's changing the basis vectors. Given a connection $\nabla$ , how does one actually find the conjugate $\nabla^\ast$ ? I have a couple guesses but they're only that. My guess for (1) is that if the primal connection tells us how the basis vectors change, $\nabla_{\partial_i} \partial_j$ , then maybe the conjugate one tells us how the reciprocal basis vectors $\partial^i$ change, i.e., $\nabla_{\partial^i} \partial^j$ . This is somewhat complicated by the fact that (like I asked about in my previous question ) his dual basis isn't the covector dual basis $dx_i$ I'm used to from earlier differential geometry, it's the dual (covector) basis with the ""sharp"" operator applied to it, making it a vector again, such that we have two ways of expressing the same vector . For (2), I'm even less sure, but he notes that if we have a pair of conjugate connections $\nabla, \nabla^\ast$ that are coupled with the metric connection $g$ , then the mean connection must equal the Levi-Civita connection, so $\nabla^{LC} = \overline \nabla = \frac{\nabla + \nabla^\ast}{2}$ Since we can figure out the Christoffel symbols of the LC connection from the metric $g$ , it seems like given the symbols defining $\nabla$ , we could figure out an explicit form for $\nabla^\ast$ . Is this right, or is there an easier way?","I'm reading both Frank Nielsen's An Elementary Introduction to Information Geometry as well as Amari's Information geometry and its applications , and confused by something they use (I'll focus on AEITIG here). He first introduces the concept of an affine connection , which is basically a covariant derivative on vector fields, so if we have vector fields , it tells us how to calculate , i.e., how changes as we move in the direction, at each point. If we have the basis for a smooth chart , then exactly what the connection does is defined in terms of the Christoffel symbols: This all makes sense to me. Then, from what I understand, if we want to transport a vector from the tangent plane at one point to another, we could do some sort of integration of that derivative over the path taken, and that would give the final vector. He then introduces (section 3) the concept of a conjugate connection that's conjugate to a given connection . He mentions a few properties of it, like an identity that must be satisfied for it to be conjugate, but never what it actually does or how to figure it out. Here's that identity: What I don't understand is the following: What does the conjugate connection actually do to a vector ? I.e., for the regular connection, it's clear that it's saying how it's changing the basis vectors. Given a connection , how does one actually find the conjugate ? I have a couple guesses but they're only that. My guess for (1) is that if the primal connection tells us how the basis vectors change, , then maybe the conjugate one tells us how the reciprocal basis vectors change, i.e., . This is somewhat complicated by the fact that (like I asked about in my previous question ) his dual basis isn't the covector dual basis I'm used to from earlier differential geometry, it's the dual (covector) basis with the ""sharp"" operator applied to it, making it a vector again, such that we have two ways of expressing the same vector . For (2), I'm even less sure, but he notes that if we have a pair of conjugate connections that are coupled with the metric connection , then the mean connection must equal the Levi-Civita connection, so Since we can figure out the Christoffel symbols of the LC connection from the metric , it seems like given the symbols defining , we could figure out an explicit form for . Is this right, or is there an easier way?","\nabla X, Y \nabla_X Y Y X (\partial_i) = (\frac{\partial}{\partial x_i}) (U, x) \nabla_{\partial_i} \partial_j = \Gamma_{ij}^k \partial_k \nabla^\ast \nabla \nabla \nabla^\ast \nabla_{\partial_i} \partial_j \partial^i \nabla_{\partial^i} \partial^j dx_i \nabla, \nabla^\ast g \nabla^{LC} = \overline \nabla = \frac{\nabla + \nabla^\ast}{2} g \nabla \nabla^\ast","['differential-geometry', 'information-geometry']"
61,Two ways of defining connection coefficients,Two ways of defining connection coefficients,,"I am relatively new to general relativity, and I am puzzled about the relationship between two ways of introducing connection coefficients on a differentiable manifold. One way (e.g. in S. Carroll's ""Spacetime & Geometry"") defines the connection coefficients, $\Gamma^\nu_{\mu\lambda}$ , as arising from a linear correction added to the partial derivative of a vector field, $\partial_\mu V^{\nu}$ , to make the whole thing --- $\nabla_\mu V^\nu = \partial_\mu V^{\nu} + \Gamma^\nu_{\mu\lambda}V^\lambda$ --- transform like a tensor. To achieve this, the $\Gamma^\nu_{\mu\lambda}$ have to satisfy a certain transformation law, but otherwise there are no constraints. So it seems this leaves us with a lot of freedom in choosing the connection coefficients: Fixing a coordinate system, I can choose any combination of $4\cdot 4\cdot 4 = 64$ smooth functions to define my connection coefficients. The other way introduces connection coefficients (as far as I understand) as arising from the change in the basis vectors when traveling between tangent spaces (as seen from the perspective of the basis of the original tangent space): \begin{align} &\partial_\mu \left(V^{\nu}\cdot \mathbf{e}_{(\nu)}\right)\\ =& \left(\partial_\mu V^\nu\right)\cdot \mathbf{e}_{(\nu)} + V^\lambda \cdot \left(\partial_\mu \mathbf{e}_{(\lambda)}\right)\\ =& \left(\partial_\mu V^\nu\right)\cdot \mathbf{e}_{(\nu)} + V^\lambda \cdot \left(\Gamma^\nu_{\mu\lambda}\mathbf{e}_{(\nu)}\right)\\ =&\left(\partial_\mu V^\nu + V^\lambda \Gamma^\nu_{\mu\lambda}\right)\cdot \mathbf{e}_{(\nu)}  \end{align} where in the third step we have defined $\Gamma^\nu_{\mu\lambda}\mathbf{e}_{(\nu)} := \partial_\mu \mathbf{e}_{(\lambda)}$ . I'm puzzled because this second way of defining the connection coefficients doesn't seem to come with the same freedom in choosing the coefficients: By fixing a chart, we already fix a basis of the tangent space at each point within the chart's domain, and so it seems we automatically fix the connection coefficients as expressed in that chart. Whereas previously we could choose the connection coefficients by freely choosing $64$ different functions, now there seems to be a unique connection (at least within that part of the chart's domain which doesn't overlap with any other chart's domain). What am I getting wrong here?","I am relatively new to general relativity, and I am puzzled about the relationship between two ways of introducing connection coefficients on a differentiable manifold. One way (e.g. in S. Carroll's ""Spacetime & Geometry"") defines the connection coefficients, , as arising from a linear correction added to the partial derivative of a vector field, , to make the whole thing --- --- transform like a tensor. To achieve this, the have to satisfy a certain transformation law, but otherwise there are no constraints. So it seems this leaves us with a lot of freedom in choosing the connection coefficients: Fixing a coordinate system, I can choose any combination of smooth functions to define my connection coefficients. The other way introduces connection coefficients (as far as I understand) as arising from the change in the basis vectors when traveling between tangent spaces (as seen from the perspective of the basis of the original tangent space): where in the third step we have defined . I'm puzzled because this second way of defining the connection coefficients doesn't seem to come with the same freedom in choosing the coefficients: By fixing a chart, we already fix a basis of the tangent space at each point within the chart's domain, and so it seems we automatically fix the connection coefficients as expressed in that chart. Whereas previously we could choose the connection coefficients by freely choosing different functions, now there seems to be a unique connection (at least within that part of the chart's domain which doesn't overlap with any other chart's domain). What am I getting wrong here?","\Gamma^\nu_{\mu\lambda} \partial_\mu V^{\nu} \nabla_\mu V^\nu = \partial_\mu V^{\nu} + \Gamma^\nu_{\mu\lambda}V^\lambda \Gamma^\nu_{\mu\lambda} 4\cdot 4\cdot 4 = 64 \begin{align}
&\partial_\mu \left(V^{\nu}\cdot \mathbf{e}_{(\nu)}\right)\\
=& \left(\partial_\mu V^\nu\right)\cdot \mathbf{e}_{(\nu)} + V^\lambda \cdot \left(\partial_\mu \mathbf{e}_{(\lambda)}\right)\\
=& \left(\partial_\mu V^\nu\right)\cdot \mathbf{e}_{(\nu)} + V^\lambda \cdot \left(\Gamma^\nu_{\mu\lambda}\mathbf{e}_{(\nu)}\right)\\
=&\left(\partial_\mu V^\nu + V^\lambda \Gamma^\nu_{\mu\lambda}\right)\cdot \mathbf{e}_{(\nu)} 
\end{align} \Gamma^\nu_{\mu\lambda}\mathbf{e}_{(\nu)} := \partial_\mu \mathbf{e}_{(\lambda)} 64","['differential-geometry', 'connections', 'general-relativity']"
62,Is this the correct understanding of how a geometric surface works?,Is this the correct understanding of how a geometric surface works?,,"I'm reading ""Elementary Differential Geometry"" by Barrett O'Neill. Most of the book is spent looking at surfaces in $\mathbb R^3$ , but eventually he introduces the ""abstract surface"", which I understand to be a surface $M$ which doesn't (necessarily) ""live"" in $\mathbb R^3$ , but still has its points referred to by ""abstract patches"" $x(u, v)$ . I.e., a region of $M$ is covered by the image of some patch $x(u,v)$ , but we don't have an explicit form for $x$ like we did when surfaces were embedded in $\mathbb R^3$ . Later, he introduces the concept of a metric tensor $g$ , and says: surface + metric tensor = geometric surface My understanding is as follows: previously, to do calculations on a surface embedded in $\mathbb R^3$ , we might have an explicit equation for a patch $x(u,v)$ and calculate its derivatives $x_u, x_v$ , which would let us calculate things like a frame  field, unit normal field, curvature, etc. Now, because the geometric surface is an abstract surface that doesn't have some explicit form for $x(u,v)$ , we calculate those same things using the metric tensor $g$ , but we still don't explicitly have an expression for $x(u,v)$ . Now, $g$ is just the tool that tells us what the inner product of $x_u, x_v$ is as a function of $(u,v)$ . Is that correct?","I'm reading ""Elementary Differential Geometry"" by Barrett O'Neill. Most of the book is spent looking at surfaces in , but eventually he introduces the ""abstract surface"", which I understand to be a surface which doesn't (necessarily) ""live"" in , but still has its points referred to by ""abstract patches"" . I.e., a region of is covered by the image of some patch , but we don't have an explicit form for like we did when surfaces were embedded in . Later, he introduces the concept of a metric tensor , and says: surface + metric tensor = geometric surface My understanding is as follows: previously, to do calculations on a surface embedded in , we might have an explicit equation for a patch and calculate its derivatives , which would let us calculate things like a frame  field, unit normal field, curvature, etc. Now, because the geometric surface is an abstract surface that doesn't have some explicit form for , we calculate those same things using the metric tensor , but we still don't explicitly have an expression for . Now, is just the tool that tells us what the inner product of is as a function of . Is that correct?","\mathbb R^3 M \mathbb R^3 x(u, v) M x(u,v) x \mathbb R^3 g \mathbb R^3 x(u,v) x_u, x_v x(u,v) g x(u,v) g x_u, x_v (u,v)",['differential-geometry']
63,Can germs be defined as a quotient of vector spaces?,Can germs be defined as a quotient of vector spaces?,,"Summary: Let $M$ be a smooth manifold and $p\in M$ . I know of two notions of germs of functions at $p$ , the more restrictive of which can be written as a quotient vector space. I am curious whether the more general notion can also be written as a quotient vector space. Let $U$ be a neighborhood of $p$ , let $\mathscr C^\infty(U)$ denote the set of smooth functions from $U$ to $\mathbb R$ , and let $I_p(U)\subseteq\mathscr C^\infty(U)$ denote the subspace of functions that vanish in a neighborhood of $p$ . Then, as is noted here , the space of germs of functions on $U$ at $p$ can be defined as $$C^\infty_p(U)=\frac{\mathscr C^\infty(U)}{I_p(U)}.$$ This is a nice definition because the resulting space is automatically a vector space. However, the restriction to $U$ is undesirable. If $M$ were an analytic manifold, we might want smooth functions on some neighborhood of $p$ to have an associated germ, regardless of whether the function extends to the whole manifold. Let $\mathscr C^\infty_p$ denote the set of pairs $(f,U)$ , where $U$ is a neighborhood of $p$ and $f:U\to\mathbb R$ is smooth. Define the equivalence relation $(f,U)\sim_p(g,V)$ if $f$ and $g$ are identical on a common neighborhood of $p$ . Then we can define $$C^\infty_p=\mathscr C^\infty_p\big/\sim_p.$$ It turns out that $C^\infty_p$ is a vector space when we define addition and scalar multiplication in a natural way: $[(f,U)]+[(g,V)]=[f|_{U\cap V}+g|_{U\cap V},U\cap V]$ and $a[(f,U)]=[(af,U)]$ . But it takes some extra work to show that these operations are well defined and that the vector space axioms are satisfied. Moreover, this seems like a coincidence, because $\mathscr C^\infty_p$ does not have an obvious vector space structure. Can we define $C^\infty_p$ as a quotient of two vector spaces, in a similar way to $C^\infty_p(U)$ ?","Summary: Let be a smooth manifold and . I know of two notions of germs of functions at , the more restrictive of which can be written as a quotient vector space. I am curious whether the more general notion can also be written as a quotient vector space. Let be a neighborhood of , let denote the set of smooth functions from to , and let denote the subspace of functions that vanish in a neighborhood of . Then, as is noted here , the space of germs of functions on at can be defined as This is a nice definition because the resulting space is automatically a vector space. However, the restriction to is undesirable. If were an analytic manifold, we might want smooth functions on some neighborhood of to have an associated germ, regardless of whether the function extends to the whole manifold. Let denote the set of pairs , where is a neighborhood of and is smooth. Define the equivalence relation if and are identical on a common neighborhood of . Then we can define It turns out that is a vector space when we define addition and scalar multiplication in a natural way: and . But it takes some extra work to show that these operations are well defined and that the vector space axioms are satisfied. Moreover, this seems like a coincidence, because does not have an obvious vector space structure. Can we define as a quotient of two vector spaces, in a similar way to ?","M p\in M p U p \mathscr C^\infty(U) U \mathbb R I_p(U)\subseteq\mathscr C^\infty(U) p U p C^\infty_p(U)=\frac{\mathscr C^\infty(U)}{I_p(U)}. U M p \mathscr C^\infty_p (f,U) U p f:U\to\mathbb R (f,U)\sim_p(g,V) f g p C^\infty_p=\mathscr C^\infty_p\big/\sim_p. C^\infty_p [(f,U)]+[(g,V)]=[f|_{U\cap V}+g|_{U\cap V},U\cap V] a[(f,U)]=[(af,U)] \mathscr C^\infty_p C^\infty_p C^\infty_p(U)","['differential-geometry', 'smooth-manifolds', 'quotient-spaces', 'smooth-functions', 'germs']"
64,Making Figure-8 into a manifold,Making Figure-8 into a manifold,,"So I am using the map in Lee's Smooth manifold book $\beta(t) = (\sin 2 t, \sin t)$ . This is an injective immersion where $t \in (-\pi, \pi).$ Now the image is not a manifold of $\mathbb{R}^2$ because an open ball around near the origin gives a picture of ""X"" and that doesn't look like $\mathbb{R}$ ? Can we make it a 1-manifold in $\mathbb{R}^2$ ? Or would that require the ""X"" to look like $\mathbb{R}$ ? Which is not possible. Is that the problem with self-intersections on $\mathbb{R}^2$ ? Because it would create pictures like ""X"" or "" $\bot$ "" and those don't look like $\mathbb{R}$ ? Next, I've been told that if we look use the induced topology by $\beta$ from $(-\pi, \pi)$ , this can be made into a manifold (of $\mathbb{R}$ ?) 3.Even if I look near $0$ with an open interval in the image set, I am still going to get an ""X"" shape no? Or do they mean that if I delete the intersection point, a neighborhood near the center would ""ignore"" the other three pieces of the ""X""?","So I am using the map in Lee's Smooth manifold book . This is an injective immersion where Now the image is not a manifold of because an open ball around near the origin gives a picture of ""X"" and that doesn't look like ? Can we make it a 1-manifold in ? Or would that require the ""X"" to look like ? Which is not possible. Is that the problem with self-intersections on ? Because it would create pictures like ""X"" or "" "" and those don't look like ? Next, I've been told that if we look use the induced topology by from , this can be made into a manifold (of ?) 3.Even if I look near with an open interval in the image set, I am still going to get an ""X"" shape no? Or do they mean that if I delete the intersection point, a neighborhood near the center would ""ignore"" the other three pieces of the ""X""?","\beta(t) = (\sin 2 t, \sin t) t \in (-\pi, \pi). \mathbb{R}^2 \mathbb{R} \mathbb{R}^2 \mathbb{R} \mathbb{R}^2 \bot \mathbb{R} \beta (-\pi, \pi) \mathbb{R} 0","['general-topology', 'differential-geometry', 'manifolds', 'differential-topology', 'intuition']"
65,What is wrong with this surface? (principle directions),What is wrong with this surface? (principle directions),,"The surface is specified, for simplicity, using an explicit function $f(x,y)$ : $$ f: \mathbb{R}^2 \rightarrow \mathbb{R} $$ The shape of this surface at point $[x=0,y=0]$ can be described by figure . It shows the xy-plane, where black lines are straight lines with function value $f(black)=R$ and red lines are circles with the center at $[x=0,y=0]$ and radius equal to $R$ . I can construct this function by blending the plane function and sphere function according to the angle in polar coordinates using the following formula: $$ f(\phi,r)=f_{blend}(\phi) \cdot f_{plane}(\phi,r)+(1-f_{blend}(\phi)) \cdot f_{sphere}(\phi,r) $$ Where, i.e.: $$ f_{blend}(\phi)=\frac{1}{2}\sin(4\phi)+\frac{1}{2} $$ $$ f_{plane}(\phi,r)=R $$ $$ f_{sphere}(\phi,r)=\sqrt{R^2-r^2} $$ I am interested in principle curvatures at point $[x=0,y=0]$ and in principle directions. Since Euler's theorem says that principle directions should be perpendicular and principle curvatures should be the maximum and the minimum value of normal curvature at these points, there has to be some problem with the smoothness of this surface. I tried to find partial derivatives for this instance and express the curvature as a function of angle coordinate: $$ f(\phi,r)=(\frac{1}{2}\sin(4\phi)+\frac{1}{2}) \cdot R + (1-(\frac{1}{2}\sin(4\phi)+\frac{1}{2})) \cdot \sqrt{R^2-r^2} $$ $$ \frac{\partial f(\phi,r)}{\partial r}=-\frac{r(\sin(4\phi)+1)}{2\sqrt{R^2-r^2}} $$ $$ \frac{\partial^2 f(\phi,r)}{\partial r^2}=-\frac{\sin(4\phi)+1}{2R} $$ For $r=0$ I get: $$ \frac{\partial f(\phi,r=0)}{\partial r}=0 $$ $$ \frac{\partial^2 f(\phi,r=0)}{\partial r^2}=-\frac{\sin(4\phi)+1}{2R} $$ If I use a formula for the curvature of a curve given by explicit function $y:f(x)$ to express the normal curvature as a function of angle coordinate, I get: $$ k=\frac{\lvert y'' \rvert}{\sqrt{(1+(y')^2)^3}} $$ $$ k(\phi)=\frac{\lvert -\sin(4\phi)+1 \rvert}{2R} $$ This result says that the minimum and maximum values of normal curvature are not perpendicular. I know that it is wrong, and there is basically some problem with smoothness at this point, but I don't see what exactly it is.","The surface is specified, for simplicity, using an explicit function : The shape of this surface at point can be described by figure . It shows the xy-plane, where black lines are straight lines with function value and red lines are circles with the center at and radius equal to . I can construct this function by blending the plane function and sphere function according to the angle in polar coordinates using the following formula: Where, i.e.: I am interested in principle curvatures at point and in principle directions. Since Euler's theorem says that principle directions should be perpendicular and principle curvatures should be the maximum and the minimum value of normal curvature at these points, there has to be some problem with the smoothness of this surface. I tried to find partial derivatives for this instance and express the curvature as a function of angle coordinate: For I get: If I use a formula for the curvature of a curve given by explicit function to express the normal curvature as a function of angle coordinate, I get: This result says that the minimum and maximum values of normal curvature are not perpendicular. I know that it is wrong, and there is basically some problem with smoothness at this point, but I don't see what exactly it is.","f(x,y) 
f: \mathbb{R}^2 \rightarrow \mathbb{R}
 [x=0,y=0] f(black)=R [x=0,y=0] R 
f(\phi,r)=f_{blend}(\phi) \cdot f_{plane}(\phi,r)+(1-f_{blend}(\phi)) \cdot f_{sphere}(\phi,r)
 
f_{blend}(\phi)=\frac{1}{2}\sin(4\phi)+\frac{1}{2}
 
f_{plane}(\phi,r)=R
 
f_{sphere}(\phi,r)=\sqrt{R^2-r^2}
 [x=0,y=0] 
f(\phi,r)=(\frac{1}{2}\sin(4\phi)+\frac{1}{2}) \cdot R + (1-(\frac{1}{2}\sin(4\phi)+\frac{1}{2})) \cdot \sqrt{R^2-r^2}
 
\frac{\partial f(\phi,r)}{\partial r}=-\frac{r(\sin(4\phi)+1)}{2\sqrt{R^2-r^2}}
 
\frac{\partial^2 f(\phi,r)}{\partial r^2}=-\frac{\sin(4\phi)+1}{2R}
 r=0 
\frac{\partial f(\phi,r=0)}{\partial r}=0
 
\frac{\partial^2 f(\phi,r=0)}{\partial r^2}=-\frac{\sin(4\phi)+1}{2R}
 y:f(x) 
k=\frac{\lvert y'' \rvert}{\sqrt{(1+(y')^2)^3}}
 
k(\phi)=\frac{\lvert -\sin(4\phi)+1 \rvert}{2R}
","['differential-geometry', 'surfaces', 'curvature']"
66,How can I find the curves whose curvature is $k(s)=\frac{1}{as+b}$? [closed],How can I find the curves whose curvature is ? [closed],k(s)=\frac{1}{as+b},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Improve this question I'm trying to find the curves whose curvature is $k(s)=\frac{1}{as+b}$ . I guess that they are Logarithmic Spirals. Parametric form of Logarithmic spirals: $x(t)=ae^{(bt)}\cos(t)$ and $y(t)=ae^{(bt)}\sin(t).$ I'm having problems, I have tried to find de angle or to find $T(s)$ and $N(s)$ . We know for Frenet that $T'(s)=k(s)N(s)=\alpha''(s)$ $N'(s)=-k(s)T(s)$ . I don't know how to solve it.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Improve this question I'm trying to find the curves whose curvature is . I guess that they are Logarithmic Spirals. Parametric form of Logarithmic spirals: and I'm having problems, I have tried to find de angle or to find and . We know for Frenet that . I don't know how to solve it.",k(s)=\frac{1}{as+b} x(t)=ae^{(bt)}\cos(t) y(t)=ae^{(bt)}\sin(t). T(s) N(s) T'(s)=k(s)N(s)=\alpha''(s) N'(s)=-k(s)T(s),"['differential-geometry', 'curves', 'curvature', 'plane-curves']"
67,Definition of orientation on manifolds and global continuous frame,Definition of orientation on manifolds and global continuous frame,,In Tu and Lee books on smooth manifolds the definition of orientation on a manifolds $M$ is given by We first assign a pointwise orientation : for every $p \in M$ we choose a class of oriented basis of $T_pM$ . Next we say that this pointwise orientation is continuous if for every $p \in M$ there is a local frame on neighbourhood $U$ of $p$ that is positively oriented at each point of $U$ . So an orientation of $M$ is a continuous pointwise orientation . My question is why don't we use a global frame on $M$ to define orientation ? Is there example of manifolds that doesn't admit global frame but are orientable ? Is there a like with parallelizable manifolds ?,In Tu and Lee books on smooth manifolds the definition of orientation on a manifolds is given by We first assign a pointwise orientation : for every we choose a class of oriented basis of . Next we say that this pointwise orientation is continuous if for every there is a local frame on neighbourhood of that is positively oriented at each point of . So an orientation of is a continuous pointwise orientation . My question is why don't we use a global frame on to define orientation ? Is there example of manifolds that doesn't admit global frame but are orientable ? Is there a like with parallelizable manifolds ?,M p \in M T_pM p \in M U p U M M,"['differential-geometry', 'manifolds', 'definition', 'smooth-manifolds', 'orientation']"
68,The pullback orientation on $M$ induced by a local diffeomorphism $F:M\to N$,The pullback orientation on  induced by a local diffeomorphism,M F:M\to N,"I'd like to understand the proof of the following proposition, cited from Lee's Introduction to Smooth Manifolds . Proposition 15.15 (The Pullback Orientation). Suppose $M$ and $N$ are smooth manifolds with or without boundary. If $F:M\to N$ is a local diffeomorphism and $N$ is oriented, then $M$ has a unique orientation, called the pullback orientation induced by $F$ , such that $F$ is orientation-preserving. Proof. For each $p\in M$ , there is a unique orientation on $T_p M$ that makes the isomorphism $dF_p:T_p M\to T_{F(p)}N$ orientation-preserving. This defines a pointwise orientation on $M$ ... Why does there exist a unique orientation on $T_p M$ that makes the isomorphism $dF_p:T_p M\to T_{F(p)}N$ orientation-preserving? Since $dF_p$ is an isomorphism, it must carry a basis for $T_p M$ to a basis for $T_{F(p)}N$ . But, this is not enough. To show $dF_p$ is orientation-preserving, one must equip $T_p M$ with a choice of orientations (keep in mind that $T_p M$ is not oriented initially) and prove that $dF_p$ carries a positively-oriented basis to a positively-oriented basis, where I have been stuck. I think the question can be taken care of properly by appealing to linear algebra, but somehow I don't know how to start it. Can anyone give me a piece of advice? If possible, please do not refer to any differential forms. Thank you. Note. Two bases for a vector space are said to be consistently oriented if the change-of-coordinate matrix between them has positive determinant. Being consistently oriented characterizes an equivalence relation on bases, and we define an orientation on a vector space to be an equivalence class of bases.","I'd like to understand the proof of the following proposition, cited from Lee's Introduction to Smooth Manifolds . Proposition 15.15 (The Pullback Orientation). Suppose and are smooth manifolds with or without boundary. If is a local diffeomorphism and is oriented, then has a unique orientation, called the pullback orientation induced by , such that is orientation-preserving. Proof. For each , there is a unique orientation on that makes the isomorphism orientation-preserving. This defines a pointwise orientation on ... Why does there exist a unique orientation on that makes the isomorphism orientation-preserving? Since is an isomorphism, it must carry a basis for to a basis for . But, this is not enough. To show is orientation-preserving, one must equip with a choice of orientations (keep in mind that is not oriented initially) and prove that carries a positively-oriented basis to a positively-oriented basis, where I have been stuck. I think the question can be taken care of properly by appealing to linear algebra, but somehow I don't know how to start it. Can anyone give me a piece of advice? If possible, please do not refer to any differential forms. Thank you. Note. Two bases for a vector space are said to be consistently oriented if the change-of-coordinate matrix between them has positive determinant. Being consistently oriented characterizes an equivalence relation on bases, and we define an orientation on a vector space to be an equivalence class of bases.",M N F:M\to N N M F F p\in M T_p M dF_p:T_p M\to T_{F(p)}N M T_p M dF_p:T_p M\to T_{F(p)}N dF_p T_p M T_{F(p)}N dF_p T_p M T_p M dF_p,"['differential-geometry', 'smooth-manifolds']"
69,A couple of basic questions on contact structures,A couple of basic questions on contact structures,,"Consider the following definition of contact structures: A contact structure on an n dimensional smooth manifold is a codimension 1 tangent distribution $\xi$ whose first curvature $\beta:\xi\times \xi\to TM/\xi$ , defined by $\beta_p:=[-,-]_p\mod \xi_p$ , is a non singular at every point. Can we automatically infer that the manifold is odd-dimensional? What is the proof of that? Can we define contact structures simply as bracket-generating codimension 1 distributions? If the distribution is weakly regular, meaning that the Lie flag consists of subbundles, it seems an equivalent definition. Am I wrong?","Consider the following definition of contact structures: A contact structure on an n dimensional smooth manifold is a codimension 1 tangent distribution whose first curvature , defined by , is a non singular at every point. Can we automatically infer that the manifold is odd-dimensional? What is the proof of that? Can we define contact structures simply as bracket-generating codimension 1 distributions? If the distribution is weakly regular, meaning that the Lie flag consists of subbundles, it seems an equivalent definition. Am I wrong?","\xi \beta:\xi\times \xi\to TM/\xi \beta_p:=[-,-]_p\mod \xi_p","['differential-geometry', 'differential-topology', 'contact-topology', 'contact-geometry']"
70,Warped Product Metric: assumption on the metric,Warped Product Metric: assumption on the metric,,"I am studying a book of differential geometry where the author says: Let $(M,g)$ be a Riemannian manifold of dimension $2$ with coordinates $(t,x)$ endowed with the following warped product metric: \begin{align*} M=\mathbb{R} \times \mathbb{S}^1, \quad g(t,x)=dt^2+f^2(t) dx^2, \end{align*} where $f: \mathbb{R} \rightarrow (0,\infty)$ is smooth, odd with $f^{\prime}(0)=1$ . Could you please explain to me these assumptions on $f$ ? For example, I speculate that $f$ must be smooth and odd so that one can extend it to all of $\mathbb{R}$ , right? But why do we need $f^{\prime}(0)=1$ ? Is this without loss of generality?","I am studying a book of differential geometry where the author says: Let be a Riemannian manifold of dimension with coordinates endowed with the following warped product metric: where is smooth, odd with . Could you please explain to me these assumptions on ? For example, I speculate that must be smooth and odd so that one can extend it to all of , right? But why do we need ? Is this without loss of generality?","(M,g) 2 (t,x) \begin{align*}
M=\mathbb{R} \times \mathbb{S}^1, \quad g(t,x)=dt^2+f^2(t) dx^2,
\end{align*} f: \mathbb{R} \rightarrow (0,\infty) f^{\prime}(0)=1 f f \mathbb{R} f^{\prime}(0)=1","['differential-geometry', 'riemannian-geometry', 'surfaces']"
71,Does the Whitney embedding theorem induce an equivalence of categories?,Does the Whitney embedding theorem induce an equivalence of categories?,,"It is well known that every abstract (say real, smooth) manifold can be embedded in $\mathbb R^n$ for $n$ sufficiently large. Is it possible to turn this into a functorial construction? If yes, is it an equivalence between the categories of smooth manifolds and smooth submanifolds of euclidean spaces? For clarity: a morphism, say form $M\subset \mathbb R^n$ to $N\subset \mathbb R^m$ in the category of smooth embedded submanifolds of some euclidean space are the smooth maps $M \to N$ when we regard $M$ and $N$ as subsets of $\mathbb R^n$ and $\mathbb R^m$ respectively.","It is well known that every abstract (say real, smooth) manifold can be embedded in for sufficiently large. Is it possible to turn this into a functorial construction? If yes, is it an equivalence between the categories of smooth manifolds and smooth submanifolds of euclidean spaces? For clarity: a morphism, say form to in the category of smooth embedded submanifolds of some euclidean space are the smooth maps when we regard and as subsets of and respectively.",\mathbb R^n n M\subset \mathbb R^n N\subset \mathbb R^m M \to N M N \mathbb R^n \mathbb R^m,"['differential-geometry', 'category-theory', 'differential-topology', 'geometric-topology']"
72,How to understand the explanation of conjugate point in Petersen's Riemannian geometry,How to understand the explanation of conjugate point in Petersen's Riemannian geometry,,"I am reading Petersen's Riemannian geometry.He uses distance function to establish three equations. 1. $L_{\partial_{r}} g=2 \operatorname{Hess} r$ 2. $\left(\nabla_{\partial_{r}} \operatorname{Hess} r\right)(X, Y)+\operatorname{Hess}^{2} r(X, Y)=-R\left(X, \partial_{r}, \partial_{r}, Y\right)$ 3. $\left(L_{\partial_{r}} \operatorname{Hess} r\right)(X, Y)-\operatorname{Hess}^{2} r(X, Y)=-R\left(X, \partial_{r}, \partial_{r}, Y\right)$ Then he says if we assume that the curvature is bounded, then equation (2) tells us that, if the Hessian blows up, then it must be decreasing as r increases, hence it can only go to $-\infty$ : I'm not sure what 'blow up'here means here, and I cannot understand why this implies that Hessian is decreasing. He also says A conjugate point occurs when the Hessian of r becomes undefined as we solve the differential equation for it. I cannot imagine when and why will the Hessian of r becomes undefined. Other places in this section are difficult to understand too since there's only literal explanation without examples or calculations. Any help will be thanked.","I am reading Petersen's Riemannian geometry.He uses distance function to establish three equations. 1. 2. 3. Then he says if we assume that the curvature is bounded, then equation (2) tells us that, if the Hessian blows up, then it must be decreasing as r increases, hence it can only go to : I'm not sure what 'blow up'here means here, and I cannot understand why this implies that Hessian is decreasing. He also says A conjugate point occurs when the Hessian of r becomes undefined as we solve the differential equation for it. I cannot imagine when and why will the Hessian of r becomes undefined. Other places in this section are difficult to understand too since there's only literal explanation without examples or calculations. Any help will be thanked.","L_{\partial_{r}} g=2 \operatorname{Hess} r \left(\nabla_{\partial_{r}} \operatorname{Hess} r\right)(X, Y)+\operatorname{Hess}^{2} r(X, Y)=-R\left(X, \partial_{r}, \partial_{r}, Y\right) \left(L_{\partial_{r}} \operatorname{Hess} r\right)(X, Y)-\operatorname{Hess}^{2} r(X, Y)=-R\left(X, \partial_{r}, \partial_{r}, Y\right) -\infty","['differential-geometry', 'riemannian-geometry']"
73,Local form of a fundamental vector field,Local form of a fundamental vector field,,"Let $M$ be a smooth manifold of dimension $2l$ on which acts a lie group $G$ . Let $X$ be a element in the lie algebra $\mathfrak{g}$ of $G$ , we associate to it the vector field $X_M$ defined by $X_M(m)= \frac{d}{dt}\biggr\vert_{t=0} e^{-tX}.m$ . Let $p$ be a zero of the vector field $X_M$ . In the page 6 of the article [1], the authors say that we can find  some local coordinates $x_1,...,x_{2l}$ around $p$ such that the vector field $X_M$ is linearized: $$X_M= a_1 \left( x_2 \frac{\partial}{\partial x_1} -x_1 \frac{\partial}{\partial x_2} \right)+\ldots+a_l\left(x_{2l} \frac{\partial}{\partial x_{2l-1}}-x_{2l-1}\frac{\partial}{\partial x_{2l}}\right),$$ $a_1,..,a_l \in \mathbb{R}.$ How can we prove that $X_M$ has the above form locally (around p)? References [1] Michle Vergne, ""Cohomologie quivariante et thorme de Stokes"" (rdig par Sylvie Paycha) (French) Analysis on Lie groups and representation theory. Proceedings of the summer school, Knitra, France, 1999 , Sminaires et Congrs 7, Paris: Socit Mathmatique de France (ISBN 2-85629-142-2/pbk), pp. 1-43 (2003), MR2038647 , Zbl 1045.57021 .","Let be a smooth manifold of dimension on which acts a lie group . Let be a element in the lie algebra of , we associate to it the vector field defined by . Let be a zero of the vector field . In the page 6 of the article [1], the authors say that we can find  some local coordinates around such that the vector field is linearized: How can we prove that has the above form locally (around p)? References [1] Michle Vergne, ""Cohomologie quivariante et thorme de Stokes"" (rdig par Sylvie Paycha) (French) Analysis on Lie groups and representation theory. Proceedings of the summer school, Knitra, France, 1999 , Sminaires et Congrs 7, Paris: Socit Mathmatique de France (ISBN 2-85629-142-2/pbk), pp. 1-43 (2003), MR2038647 , Zbl 1045.57021 .","M 2l G X \mathfrak{g} G X_M X_M(m)= \frac{d}{dt}\biggr\vert_{t=0} e^{-tX}.m p X_M x_1,...,x_{2l} p X_M X_M= a_1 \left( x_2 \frac{\partial}{\partial x_1} -x_1 \frac{\partial}{\partial x_2} \right)+\ldots+a_l\left(x_{2l} \frac{\partial}{\partial x_{2l-1}}-x_{2l-1}\frac{\partial}{\partial x_{2l}}\right), a_1,..,a_l \in \mathbb{R}. X_M","['differential-geometry', 'group-actions']"
74,The differential of inclusion from S^{2} to R^{3},The differential of inclusion from S^{2} to R^{3},,"I've found this question on Loring Tu's ""Introduction to Manifolds"", numbered 11.4 and titled ""Differential of the inclusion map"" On the upper hemisphere of the unit sphere $S^{2}$ we have the coordinate map $\phi = (u,v)$ , where $u(a,b,c) = a, \ v(a,b,c) = b$ Let $i: S^{2} \to \mathbb{R^3}$ be the inclusion, and $i_*$ it's differential. Calculate: $$ i_*(\frac{\partial}{\partial u}), \ \  i_*(\frac{\partial}{\partial v})  $$ in terms of $ \frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z}$ , where x,y,z are the standard coordinates I've fiddled with it a bit, and the closest I've came is something like: $$i_*(\frac{\partial}{\partial u})(x) = (\frac{\partial}{\partial u})(x \circ i)  = (\frac{\partial}{\partial u}) (u) = 1\\ i_*(\frac{\partial}{\partial u})(y) = (\frac{\partial}{\partial u})(y \circ i) = 0 \\ i_*(\frac{\partial}{\partial u})(z) = (\frac{\partial}{\partial u}) (z \circ i) $$ I can't really wrap my head around calculating $(\frac{\partial}{\partial u}) (z \circ i)$ . Some guidance would be very much appreciated.","I've found this question on Loring Tu's ""Introduction to Manifolds"", numbered 11.4 and titled ""Differential of the inclusion map"" On the upper hemisphere of the unit sphere we have the coordinate map , where Let be the inclusion, and it's differential. Calculate: in terms of , where x,y,z are the standard coordinates I've fiddled with it a bit, and the closest I've came is something like: I can't really wrap my head around calculating . Some guidance would be very much appreciated.","S^{2} \phi = (u,v) u(a,b,c) = a, \ v(a,b,c) = b i: S^{2} \to \mathbb{R^3} i_* 
i_*(\frac{\partial}{\partial u}), \ \ 
i_*(\frac{\partial}{\partial v}) 
  \frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z} i_*(\frac{\partial}{\partial u})(x) = (\frac{\partial}{\partial u})(x \circ i)  = (\frac{\partial}{\partial u}) (u) = 1\\
i_*(\frac{\partial}{\partial u})(y) = (\frac{\partial}{\partial u})(y \circ i) = 0 \\
i_*(\frac{\partial}{\partial u})(z) = (\frac{\partial}{\partial u}) (z \circ i)
 (\frac{\partial}{\partial u}) (z \circ i)","['differential-geometry', 'smooth-manifolds', 'differential']"
75,Constructing non-equivalent atlases,Constructing non-equivalent atlases,,"In a lecture on differential geometry, we had the following definition of equivalent atlases: Two atlases $\mathcal A$ and $\mathcal B$ on $M$ are called equivalent if $\mathcal A \cup \mathcal B$ is an atlas on $\mathcal M$ . The definition of atlas we had is the following: Let $M$ be a second countable Hausdorff topological space. An $n$ - dimensional smooth atlas on $M$ is a collection of maps $$\mathcal A = \left\{ \left(\varphi_i, U_i\right) \mid i\in A\right\}, \quad \varphi_i: U_i\rightarrow \varphi_i(U_i)\subset \mathbb R^n,$$ such that all $U_i \subset M$ are open, all $\varphi_i$ are homeomorphisms, and $\{U_i, i\in I\}$ is an open covering of $\mathcal M$ $\varphi_i\circ \varphi_j^{-1}: \varphi_j\left(U_i\cap U_j\right)\rightarrow \varphi_i\left( U_i\cap U_j\right)$ are smooth for all $i, j\in I$ . Now, this thread gives the following ""recipe"" for constructing non-equivalent atlases: Here is a very easy way to construct inequivalent atlases on the same differentiable manifold $X$ , e.g. $X=\mathbb{R}$ or $X=\mathbb{S}^1$ . Pick any homeomorphism $f : X \to X$ which is not a diffeomorphism (one always exists). For each chart in the given atlas $(U,\phi)$ , define a chart $(f^{-1}(U),\phi \circ f)$ in the new atlas. The overlap condition holds between charts in this new atlas because the $f$ 's cancel out. But an overlap between a chart in the new atlas and one in the old is not smooth, because the $f$ does not cancel out and it would follow that $f$ is smooth which it isn't. Question : Why exactly cannot $f$ be a diffeomorphism? Or to ask it differently: For example, let's assume that $f$ is ""only"" a $C^{1}$ diffeomorphism, wouldn't the recipe still hold, because a $C^{1}$ diffeomorphism is in general not smooth, i.e. $C^{}$ ? EDIT : This is the definition of smoothness that we had for a map $f$ between two smooth manifolds: Let $M$ and $N$ be two smooth manifolds. A continuous map $f:M\to N$ is called smooth if for all charts $(\varphi, U)$ of $M$ , $(\psi, V)$ of $N$ , $$\psi\circ f\circ \varphi^{-1}: \varphi(U\cap f^{-1}(V)) \to \psi(V)$$ is smooth. If I apply this to our case, I get: $$\phi_{\alpha}^{-1}\circ h\circ \phi_{\alpha}: \phi_{\alpha}^{-1}(\phi_{\alpha}^{-1}(U_{\alpha})\cap h^{-1}(\phi_{\alpha}^{-1}(U_{\alpha}))) \to \phi_{\alpha}^{-1}(\phi_{\alpha}^{-1}(U_{\alpha})).$$ We've tried to convince ourselves that $f$ is not differentiable at $\phi_{\alpha}^{-1}(0)$ , but is $\phi_{\alpha}^{-1}(0)$ an element of the domain of $\phi_{\alpha}^{-1}\circ h\circ \phi_{\alpha}$ ? I don't think so for the following reason: $$h^{-1}(\phi_{\alpha}^{-1}(U_{\alpha})) = h^{-1}(\{x\in U_{\alpha}\mid \phi_{\alpha}(x)\in U_{\alpha}\}) = \{y\in B_{1}(0) \mid h(y)\in\{x\in U_{\alpha}\mid \phi_{\alpha}(x)\in U_{\alpha}\}\}.$$ And here comes my problem : We know that $h: B_{1}(0)\to B_{1}(0)$ , so how can $h(y)$ be an element of the set $\{x\in U_{\alpha}\mid \dots\}$ , which is a subset of $U_{\alpha}$ ? After all, $B_{1}(0)$ and $U_{\alpha}$ are in no way related to each other.","In a lecture on differential geometry, we had the following definition of equivalent atlases: Two atlases and on are called equivalent if is an atlas on . The definition of atlas we had is the following: Let be a second countable Hausdorff topological space. An - dimensional smooth atlas on is a collection of maps such that all are open, all are homeomorphisms, and is an open covering of are smooth for all . Now, this thread gives the following ""recipe"" for constructing non-equivalent atlases: Here is a very easy way to construct inequivalent atlases on the same differentiable manifold , e.g. or . Pick any homeomorphism which is not a diffeomorphism (one always exists). For each chart in the given atlas , define a chart in the new atlas. The overlap condition holds between charts in this new atlas because the 's cancel out. But an overlap between a chart in the new atlas and one in the old is not smooth, because the does not cancel out and it would follow that is smooth which it isn't. Question : Why exactly cannot be a diffeomorphism? Or to ask it differently: For example, let's assume that is ""only"" a diffeomorphism, wouldn't the recipe still hold, because a diffeomorphism is in general not smooth, i.e. ? EDIT : This is the definition of smoothness that we had for a map between two smooth manifolds: Let and be two smooth manifolds. A continuous map is called smooth if for all charts of , of , is smooth. If I apply this to our case, I get: We've tried to convince ourselves that is not differentiable at , but is an element of the domain of ? I don't think so for the following reason: And here comes my problem : We know that , so how can be an element of the set , which is a subset of ? After all, and are in no way related to each other.","\mathcal A \mathcal B M \mathcal A \cup \mathcal B \mathcal M M n M \mathcal A = \left\{ \left(\varphi_i, U_i\right) \mid i\in A\right\}, \quad \varphi_i: U_i\rightarrow \varphi_i(U_i)\subset \mathbb R^n, U_i \subset M \varphi_i \{U_i, i\in I\} \mathcal M \varphi_i\circ \varphi_j^{-1}: \varphi_j\left(U_i\cap U_j\right)\rightarrow \varphi_i\left( U_i\cap U_j\right) i, j\in I X X=\mathbb{R} X=\mathbb{S}^1 f : X \to X (U,\phi) (f^{-1}(U),\phi \circ f) f f f f f C^{1} C^{1} C^{} f M N f:M\to N (\varphi, U) M (\psi, V) N \psi\circ f\circ \varphi^{-1}: \varphi(U\cap f^{-1}(V)) \to \psi(V) \phi_{\alpha}^{-1}\circ h\circ \phi_{\alpha}: \phi_{\alpha}^{-1}(\phi_{\alpha}^{-1}(U_{\alpha})\cap h^{-1}(\phi_{\alpha}^{-1}(U_{\alpha}))) \to \phi_{\alpha}^{-1}(\phi_{\alpha}^{-1}(U_{\alpha})). f \phi_{\alpha}^{-1}(0) \phi_{\alpha}^{-1}(0) \phi_{\alpha}^{-1}\circ h\circ \phi_{\alpha} h^{-1}(\phi_{\alpha}^{-1}(U_{\alpha})) = h^{-1}(\{x\in U_{\alpha}\mid \phi_{\alpha}(x)\in U_{\alpha}\}) = \{y\in B_{1}(0) \mid h(y)\in\{x\in U_{\alpha}\mid \phi_{\alpha}(x)\in U_{\alpha}\}\}. h: B_{1}(0)\to B_{1}(0) h(y) \{x\in U_{\alpha}\mid \dots\} U_{\alpha} B_{1}(0) U_{\alpha}","['differential-geometry', 'manifolds']"
76,What is the definition of the vector field which is generated by rotations of the circle,What is the definition of the vector field which is generated by rotations of the circle,,"I'm reading the first lines of page 5 in the article which called ""Cohomologie quivariante et thorme de Stokes"", which says Let $M$ be a smooth manifold on which $S^1$ acts. Let $J$ be the vector field generated by the rotations of a circle. We denote by $\mathcal{L}(J)$ the lie derivative in the direction of $J$ . If $\xi$ is a vector field which vanishes at a point $p$ , then $\mathcal{L}(J)$ induces an invertible transformation on $T_pM$ . What does it mean that $J$ is the vector field generated by rotations of a circle?","I'm reading the first lines of page 5 in the article which called ""Cohomologie quivariante et thorme de Stokes"", which says Let be a smooth manifold on which acts. Let be the vector field generated by the rotations of a circle. We denote by the lie derivative in the direction of . If is a vector field which vanishes at a point , then induces an invertible transformation on . What does it mean that is the vector field generated by rotations of a circle?",M S^1 J \mathcal{L}(J) J \xi p \mathcal{L}(J) T_pM J,"['differential-geometry', 'group-actions', 'vector-fields']"
77,Reference Request on a Necessary and Sufficient Condition for Isothermality,Reference Request on a Necessary and Sufficient Condition for Isothermality,,"I am getting acquainted with the fundamentals of differential geometry for the sake of a problem I have been thinking about. In Green, G. M. ""Some Geometric Characterization of Isothermal Nets on a Curved Surface."" Transactions of the American Mathematical Society, Vol. 18, No. 4, (1917) pp. 480-488, the author makes the following preamble: 'If a surface $S$ , whose equations are $$ \begin{equation} x=x(u,v), \hspace{2mm} y=y(u,v), \hspace{2mm}z=z(u,v), \end{equation} $$ be referred to an orthogonal net of parameter curves, its first fundamental form is $$ \begin{equation} ds^2=Edu^2+Gdv^2, \end{equation} $$ where $E$ and $G$ are functions of $u$ and $v$ . This orthogonal net is called isothermal , if by a proper transformation $\bar{u}=\phi(u),\bar{v}=\psi(v)$ of the parameters the first fundamental form may be reduced to $$\begin{equation} ds^2=\bar{\lambda}(\bar{u},\bar{v})(d\bar{u}^2+d\bar{v}^2). \end{equation}$$ A necessary and sufficient condition that such a reduction may be effected upon the form as first written is, that the equation $$ \begin{equation} \frac{\partial^2}{\partial u \partial v} log \Big(\frac{E}{G} \Big)=0 \end{equation} $$ be satisfied identically.' I would like to know the name of this result (if any); where it originated; whether it has variants pertaining to the classification of surfaces where the middle term of the first fundamental form does not vanish. Textbooks that would answer my questions are welcome. Thanks for your attention!","I am getting acquainted with the fundamentals of differential geometry for the sake of a problem I have been thinking about. In Green, G. M. ""Some Geometric Characterization of Isothermal Nets on a Curved Surface."" Transactions of the American Mathematical Society, Vol. 18, No. 4, (1917) pp. 480-488, the author makes the following preamble: 'If a surface , whose equations are be referred to an orthogonal net of parameter curves, its first fundamental form is where and are functions of and . This orthogonal net is called isothermal , if by a proper transformation of the parameters the first fundamental form may be reduced to A necessary and sufficient condition that such a reduction may be effected upon the form as first written is, that the equation be satisfied identically.' I would like to know the name of this result (if any); where it originated; whether it has variants pertaining to the classification of surfaces where the middle term of the first fundamental form does not vanish. Textbooks that would answer my questions are welcome. Thanks for your attention!","S 
\begin{equation}
x=x(u,v), \hspace{2mm} y=y(u,v), \hspace{2mm}z=z(u,v),
\end{equation}
 
\begin{equation}
ds^2=Edu^2+Gdv^2,
\end{equation}
 E G u v \bar{u}=\phi(u),\bar{v}=\psi(v) \begin{equation}
ds^2=\bar{\lambda}(\bar{u},\bar{v})(d\bar{u}^2+d\bar{v}^2).
\end{equation} 
\begin{equation}
\frac{\partial^2}{\partial u \partial v} log \Big(\frac{E}{G} \Big)=0
\end{equation}
","['differential-geometry', 'reference-request', 'surfaces']"
78,Relation between $\eta\wedge \bar{\eta}\wedge \omega^{n-1}$ and $||\eta||^2\omega^n$,Relation between  and,\eta\wedge \bar{\eta}\wedge \omega^{n-1} ||\eta||^2\omega^n,"Let $X$ bet a compact Kahler manifold of dimension $\dim_{\mathbb{C}}(X)=n$ with Kahler form $\omega$ . Let $\eta\in\Omega^{1,0}(X)$ be a differential form. I would like to know if there is a way to relate the forms $\eta\wedge \bar{\eta}\wedge \omega^{n-1}$ and $||\eta||^2\omega^n$ or in a weaker way the integrals $\int_X\eta\wedge \bar{\eta}\wedge \omega^{n-1}$ and $\int_X||\eta||^2\omega^n$ .",Let bet a compact Kahler manifold of dimension with Kahler form . Let be a differential form. I would like to know if there is a way to relate the forms and or in a weaker way the integrals and .,"X \dim_{\mathbb{C}}(X)=n \omega \eta\in\Omega^{1,0}(X) \eta\wedge \bar{\eta}\wedge \omega^{n-1} ||\eta||^2\omega^n \int_X\eta\wedge \bar{\eta}\wedge \omega^{n-1} \int_X||\eta||^2\omega^n","['differential-geometry', 'complex-geometry', 'differential-forms', 'kahler-manifolds']"
79,Proving ${\mathbb{P}}^n$ is Hausdorff,Proving  is Hausdorff,{\mathbb{P}}^n,"I am trying to understand and complete the proof that the real projective space ${\mathbb{P}}^n$ is Hausdorff.In my notes it is modeled as ${\mathbb{R}}^{n+1}\setminus \{0\}/\sim  $ and it goes like this: It is enough to construct, given two different points $[a]$ and $[b]$ a continuous function $f:{\mathbb{P}}^n \rightarrow {\mathbb{R}} $ such that $f[a] \neq f[b] $ (why ?.......(1)) We fix $\omega$ in ${\mathbb{R}}^{n+1}\setminus \{0\}$ and define $f[\nu]$ as the squared of the distance from $\omega$ to the vector line $R\nu$ generated by $\nu$ . Since $f\circ \pi(\nu) = f[\nu] = |\omega|^2-(\omega . \nu)^2/|\nu|^2$ , it follows that $f \circ \pi $ is continuous and hence $f$ is continuous...(why?........(2)) ( $\pi$ is the canonical projection $\pi : {\mathbb{R}}^{n+1}\setminus \{0\} \rightarrow {\mathbb{P}}^{n} $ ) It is then enough to take $w \sim a$ to have $f[a] = 0 \neq f[b]$ ...(*) I have two questions: 1)why is (1) true ? At first I thought I could justify (1) like this: Since ${\mathbb{R}}$ is Hausdorff, $\exists $ open sets $A,B$ such that for $f[a] \neq f[b] $ , $f[a] \in A$ and $f[b] \in B$ , with $A \cap B = \emptyset$ . By hypothesis then $[a] \neq [b] $ and since $f$ is continuous, $f^{-1}(A) $ and $f^{-1}(B) $ are open sets of ${\mathbb{P}}^n$ containing $[a]$ and $[b]$ respectively such that $f^{-1}(A) \cap f^{-1}(B) = f^{-1}(A\cap B)=f^{-1}(\emptyset)=\emptyset $ . Then ${\mathbb{P}}^n$ is Hausdorff But I don't think my proof is correct since  for it to work we need $f$ to have the property stated at (1) but the function $f$ that they propose later has that property only when taking one of the points fixed, say $a$ as $a \sim w$ as done in (*), and not for any two points as needed for the definition of Hausdorff space. Besides if w is the center of a circle (in the 2-dimensional case for instance there are two lines that have the same distance to w, that is the tangent lines, so (1) does not hold for any two different $[a] $ and $[b]$ ) 2)why $f \circ \pi $ continuous implies $f$ is continuous? don't think  I can compose with a continuous $\pi^{-1}$ , since that function is not well defined since $\pi$ is not injective","I am trying to understand and complete the proof that the real projective space is Hausdorff.In my notes it is modeled as and it goes like this: It is enough to construct, given two different points and a continuous function such that (why ?.......(1)) We fix in and define as the squared of the distance from to the vector line generated by . Since , it follows that is continuous and hence is continuous...(why?........(2)) ( is the canonical projection ) It is then enough to take to have ...(*) I have two questions: 1)why is (1) true ? At first I thought I could justify (1) like this: Since is Hausdorff, open sets such that for , and , with . By hypothesis then and since is continuous, and are open sets of containing and respectively such that . Then is Hausdorff But I don't think my proof is correct since  for it to work we need to have the property stated at (1) but the function that they propose later has that property only when taking one of the points fixed, say as as done in (*), and not for any two points as needed for the definition of Hausdorff space. Besides if w is the center of a circle (in the 2-dimensional case for instance there are two lines that have the same distance to w, that is the tangent lines, so (1) does not hold for any two different and ) 2)why continuous implies is continuous? don't think  I can compose with a continuous , since that function is not well defined since is not injective","{\mathbb{P}}^n {\mathbb{R}}^{n+1}\setminus \{0\}/\sim   [a] [b] f:{\mathbb{P}}^n \rightarrow {\mathbb{R}}  f[a] \neq f[b]  \omega {\mathbb{R}}^{n+1}\setminus \{0\} f[\nu] \omega R\nu \nu f\circ \pi(\nu) = f[\nu] = |\omega|^2-(\omega . \nu)^2/|\nu|^2 f \circ \pi  f \pi \pi : {\mathbb{R}}^{n+1}\setminus \{0\} \rightarrow {\mathbb{P}}^{n}  w \sim a f[a] = 0 \neq f[b] {\mathbb{R}} \exists  A,B f[a] \neq f[b]  f[a] \in A f[b] \in B A \cap B = \emptyset [a] \neq [b]  f f^{-1}(A)  f^{-1}(B)  {\mathbb{P}}^n [a] [b] f^{-1}(A) \cap f^{-1}(B) = f^{-1}(A\cap B)=f^{-1}(\emptyset)=\emptyset  {\mathbb{P}}^n f f a a \sim w [a]  [b] f \circ \pi  f \pi^{-1} \pi","['general-topology', 'differential-geometry', 'quotient-spaces', 'projective-space']"
80,$S^1$-valued function on $T^n$,-valued function on,S^1 T^n,"Let $f:T^n\to S^1$ be a smooth function on the $n$ -torus $T^n=S^1\times \cdots \times S^1$ . The differential $df$ can be viewed as a closed 1-form on $T^n$ (not exact). Moreover, it should give a nonzero cohomology class $[df]$ in $H^1(T^n;\mathbb Z)$ in $\mathbb Z$ -coefficients. Concerning the natural isomorphism $H^1(T^n;\mathbb Z)\cong \mathrm{Hom}(\pi_1(T^n),\mathbb Z)$ , this should mean the map sending a loop $\sigma$ in $T^n$ to the integer $\mathrm{deg}(f\circ \sigma)$ . (Note that $f\circ \sigma: S^1\to S^1$ ) I believe all these are standard, but I fail to find a reference or write down enough details to convince myself. Could you help me to make this clear? Or, maybe I was mistaken somewhere?","Let be a smooth function on the -torus . The differential can be viewed as a closed 1-form on (not exact). Moreover, it should give a nonzero cohomology class in in -coefficients. Concerning the natural isomorphism , this should mean the map sending a loop in to the integer . (Note that ) I believe all these are standard, but I fail to find a reference or write down enough details to convince myself. Could you help me to make this clear? Or, maybe I was mistaken somewhere?","f:T^n\to S^1 n T^n=S^1\times \cdots \times S^1 df T^n [df] H^1(T^n;\mathbb Z) \mathbb Z H^1(T^n;\mathbb Z)\cong \mathrm{Hom}(\pi_1(T^n),\mathbb Z) \sigma T^n \mathrm{deg}(f\circ \sigma) f\circ \sigma: S^1\to S^1","['differential-geometry', 'algebraic-topology', 'differential-topology', 'differential-forms']"
81,The tangent space $T_x \mathbb S^n$ consists of such points in $\mathbb R^{n+1}$ that are perpendicular to $x$,The tangent space  consists of such points in  that are perpendicular to,T_x \mathbb S^n \mathbb R^{n+1} x,"I'm trying to prove the characteristic of the tangent space of a $n$ -sphere. Could you have a check on my proof? Theorem: Consider the $n$ -sphere $\mathbb S^n \subseteq \mathbb R^{n+1}$ and $x \in \mathbb S^n$ . Then $T_x \mathbb S^n$ consists of such points in $\mathbb R^{n+1}$ that are perpendicular to $x$ . Proof: First, $T_x \mathbb S^n$ is a $n$ -dimensional vector subspace of $\mathbb R^{n+1}$ . Wlog, we assume $x_{n+1}>0$ . Let $S:= \{x \in \mathbb S^n \mid x_{n+1}>0\}$ . Then $S$ is open in $\mathbb S^n$ and $x \in S$ . Consider the map $$\varphi: \mathbb B_{\mathbb R^{n}} (0,1) \to S, y \mapsto \left (y_1, \ldots, y_n, \sqrt{1-(y_1^2+\cdots+ y_n^2)} \right ).$$ Then $\varphi$ is a local parameterization around $x$ . Let $y := \varphi^{-1} (x)$ and $\varphi^i$ be the $i$ -th coordinate of $\varphi$ . Then $\mathrm d \varphi_y^i: \mathbb R^{n} \to \mathbb R, z \mapsto z_i$ for all $i=1, \ldots, n$ . The partial derivative of $\varphi^{n+1}$ w.r.t. the $i$ -th coordinate of $y$ is $$\frac{\partial \varphi^{n+1}}{\partial y_i}= - \frac{y_i}{\sqrt{1-(y_1^2+\cdots+ y_n^2)}}, \quad i=1,\ldots,n.$$ Then $$\mathrm d \varphi^{n+1}_{y}: \mathbb R^{n} \to \mathbb R, z \mapsto - \frac{z_1y_1 + \cdots+z_ny_n}{\sqrt{1-(y_1^2+\cdots+ y_n^2)}}.$$ Hence $$\mathrm d \varphi_y: \mathbb R^{n} \to \mathbb R^{n+1}, z \mapsto \left (z_1, \ldots, z_n, - \frac{z_1y_1 + \cdots+z_ny_n}{\sqrt{1-(y_1^2+\cdots+ y_n^2)}} \right ).$$ It follows from $y = \varphi^{-1} (x)$ that $x_{n+1} = \sqrt{1-(y_1^2+\cdots+ y_n^2)}$ and $x_i = y_i$ for all $i=1,\ldots,n$ . Thus $$\langle \mathrm d \varphi_y (z), x \rangle = z_1x_1 + \cdots + z_nx_n - \frac{z_1y_1 + \cdots+z_ny_n}{\sqrt{1-(y_1^2+\cdots+ y_n^2)}}x_{n+1} = 0.$$ This completes the proof.","I'm trying to prove the characteristic of the tangent space of a -sphere. Could you have a check on my proof? Theorem: Consider the -sphere and . Then consists of such points in that are perpendicular to . Proof: First, is a -dimensional vector subspace of . Wlog, we assume . Let . Then is open in and . Consider the map Then is a local parameterization around . Let and be the -th coordinate of . Then for all . The partial derivative of w.r.t. the -th coordinate of is Then Hence It follows from that and for all . Thus This completes the proof.","n n \mathbb S^n \subseteq \mathbb R^{n+1} x \in \mathbb S^n T_x \mathbb S^n \mathbb R^{n+1} x T_x \mathbb S^n n \mathbb R^{n+1} x_{n+1}>0 S:= \{x \in \mathbb S^n \mid x_{n+1}>0\} S \mathbb S^n x \in S \varphi: \mathbb B_{\mathbb R^{n}} (0,1) \to S, y \mapsto \left (y_1, \ldots, y_n, \sqrt{1-(y_1^2+\cdots+ y_n^2)} \right ). \varphi x y := \varphi^{-1} (x) \varphi^i i \varphi \mathrm d \varphi_y^i: \mathbb R^{n} \to \mathbb R, z \mapsto z_i i=1, \ldots, n \varphi^{n+1} i y \frac{\partial \varphi^{n+1}}{\partial y_i}= - \frac{y_i}{\sqrt{1-(y_1^2+\cdots+ y_n^2)}}, \quad i=1,\ldots,n. \mathrm d \varphi^{n+1}_{y}: \mathbb R^{n} \to \mathbb R, z \mapsto - \frac{z_1y_1 + \cdots+z_ny_n}{\sqrt{1-(y_1^2+\cdots+ y_n^2)}}. \mathrm d \varphi_y: \mathbb R^{n} \to \mathbb R^{n+1}, z \mapsto \left (z_1, \ldots, z_n, - \frac{z_1y_1 + \cdots+z_ny_n}{\sqrt{1-(y_1^2+\cdots+ y_n^2)}} \right ). y = \varphi^{-1} (x) x_{n+1} = \sqrt{1-(y_1^2+\cdots+ y_n^2)} x_i = y_i i=1,\ldots,n \langle \mathrm d \varphi_y (z), x \rangle = z_1x_1 + \cdots + z_nx_n - \frac{z_1y_1 + \cdots+z_ny_n}{\sqrt{1-(y_1^2+\cdots+ y_n^2)}}x_{n+1} = 0.","['differential-geometry', 'solution-verification', 'smooth-manifolds', 'spheres']"
82,"Algebraic, Projective, and Riemannian Geometry: How do they interact?","Algebraic, Projective, and Riemannian Geometry: How do they interact?",,"The aim of this question is to understand the interaction between projective algebraic varieties (over the complex or real numbers), Riemannian manifolds, and projective space, through shared concepts - that is, to understand which concepts can be defined intrinsically in more than one of these structures, and whether these concepts agree when a space admits more than one of these structures. I'll start with motivation: In the usual Euclidean geometry of the plane, one has the concept of straight lines. It is well known that these arise from the Riemannian structure of the Euclidean plane as geodesics - that is, if one looks at the Euclidean plane only as a Riemannian manifold (without the vector space structure, etc.) one can still recover the straight lines as locally distance-minimizing curves. Interestingly, however, one can also forget the metrical\Riemannian structure and look at the projective plane, and somehow still talk about straight lines - straight lines still make sense in projective geometry, even though there is no metric structure and thus no geodesics. Projective varieties are in some sense a generalization of projective geometry to spaces that are not necessarily 'linear'. In projective varieties, is there a concept generalizing straight lines or geodesics? Another generalization of projective geometry to curved spaces is manifolds with projective connections ; in these spaces, there is indeed an appropriate notion of geodesics. So, do smooth projective varieties (at least over the real numbers) have a natural projective connection that somehow agrees with the variety structure? If there was such a natural connection, this would provide a natural extensions of the concept of straight lines to projective varieties. The two questions that I'd like to ask are: Which concepts from projective geometry and from Riemannian geometry have natural analogs in the intrinsic geometry of projective varieties? Is there a relationship between the structure of a (smooth) projective variety and the structure of a manifold with a projective connection? Are there spaces which have both of these structures and they somehow agree with each other? Some concepts I already know that generalize from projective geometry to general algebraic varieties are dimension, the automorphism group of the variety (which for projective space is the projective general linear group), subvarieties, polynomial functions, and for one-dimensional varieties, the cross-ratio (this has a generalization to any Riemann surface). As raised above, what about straight lines? Do these have a generalization to projective surfaces/varieties? What about the degree of an embedded subvariety (for projective space this is defined using straight lines/hypersurfaces)? And are there Riemannian concepts which have natural analogs on algebraic varieties, such as curvature? connection? geodesics? holonomy? This question is rather broad, but I'll appreciate any partial answers, perspectives on this, or even references or names that can point me to relevant material.","The aim of this question is to understand the interaction between projective algebraic varieties (over the complex or real numbers), Riemannian manifolds, and projective space, through shared concepts - that is, to understand which concepts can be defined intrinsically in more than one of these structures, and whether these concepts agree when a space admits more than one of these structures. I'll start with motivation: In the usual Euclidean geometry of the plane, one has the concept of straight lines. It is well known that these arise from the Riemannian structure of the Euclidean plane as geodesics - that is, if one looks at the Euclidean plane only as a Riemannian manifold (without the vector space structure, etc.) one can still recover the straight lines as locally distance-minimizing curves. Interestingly, however, one can also forget the metrical\Riemannian structure and look at the projective plane, and somehow still talk about straight lines - straight lines still make sense in projective geometry, even though there is no metric structure and thus no geodesics. Projective varieties are in some sense a generalization of projective geometry to spaces that are not necessarily 'linear'. In projective varieties, is there a concept generalizing straight lines or geodesics? Another generalization of projective geometry to curved spaces is manifolds with projective connections ; in these spaces, there is indeed an appropriate notion of geodesics. So, do smooth projective varieties (at least over the real numbers) have a natural projective connection that somehow agrees with the variety structure? If there was such a natural connection, this would provide a natural extensions of the concept of straight lines to projective varieties. The two questions that I'd like to ask are: Which concepts from projective geometry and from Riemannian geometry have natural analogs in the intrinsic geometry of projective varieties? Is there a relationship between the structure of a (smooth) projective variety and the structure of a manifold with a projective connection? Are there spaces which have both of these structures and they somehow agree with each other? Some concepts I already know that generalize from projective geometry to general algebraic varieties are dimension, the automorphism group of the variety (which for projective space is the projective general linear group), subvarieties, polynomial functions, and for one-dimensional varieties, the cross-ratio (this has a generalization to any Riemann surface). As raised above, what about straight lines? Do these have a generalization to projective surfaces/varieties? What about the degree of an embedded subvariety (for projective space this is defined using straight lines/hypersurfaces)? And are there Riemannian concepts which have natural analogs on algebraic varieties, such as curvature? connection? geodesics? holonomy? This question is rather broad, but I'll appreciate any partial answers, perspectives on this, or even references or names that can point me to relevant material.",,"['differential-geometry', 'algebraic-geometry', 'projective-geometry', 'geodesic', 'projective-varieties']"
83,How to check singular cochains are not sheaves?,How to check singular cochains are not sheaves?,,"Let $\mathcal{S}^{q}$ be a presheaf of singular cochain on a topological space $X$ , that is the functor $\mathcal{S}^{q} \colon \mathcal{O}(X)^{op} \to \mathbb{Z}$ - $\mathsf{mod}$ is given by $\mathcal{S}^{q}(U)= \operatorname{Hom}(S_{q}(U), \mathbb{Z})$ , where $S_q(U)$ is a singular chain on X. This is a well known fact that these cochains are presheaves but not sheaves. However, I cannot check this fact by myself. I am reading Warner's Foundations of Differential Manifolds and Lie Groups . Let $\{ U_{\alpha} \}_{\alpha \in A}$ be a covering of an open set $U \subset X$ . I learned that a presheaf $\mathcal{F}\colon \mathcal{O}(X)^{op} \to \mathbb{Z}$ - $\mathsf{mod}$ is called a sheaf if following conditions 1 and 2 are satisfied. If there are $s, t \in \mathcal{F}(U)$ satisfing $\ s|_{U_{\alpha}} = t|_{U_{\alpha}}$ for arbitrary $\alpha \in A$ , then $s=t$ . If there is a family $\{f_{\alpha} \in \mathcal{F}(U_{\alpha}) \}_{\alpha \in A}$ satisfing $s_{\alpha}|_{U_{\alpha} \cap U_{\beta}} = s_{\beta}|_{U_{\alpha} \cap U_{\beta}} \ $ for $\ \alpha, \beta \in A, \ $ there exists a global section $f \in \mathcal{F}(U) $ such that $f|_{U_{\alpha}} = f_{\alpha}$ for $\alpha \in A$ . In this book of page 192 insist that the presheaf $\mathcal{S}^{q} \colon \mathcal{O}(X)^{op} \to \mathbb{Z}$ - $\mathsf{mod}$ ( for $q  \ge 1$ )  satisfies later condition 2 only. I can not check this. How should I do to confirm these fact?(It is satisfied with 2 and not 1.)","Let be a presheaf of singular cochain on a topological space , that is the functor - is given by , where is a singular chain on X. This is a well known fact that these cochains are presheaves but not sheaves. However, I cannot check this fact by myself. I am reading Warner's Foundations of Differential Manifolds and Lie Groups . Let be a covering of an open set . I learned that a presheaf - is called a sheaf if following conditions 1 and 2 are satisfied. If there are satisfing for arbitrary , then . If there is a family satisfing for there exists a global section such that for . In this book of page 192 insist that the presheaf - ( for )  satisfies later condition 2 only. I can not check this. How should I do to confirm these fact?(It is satisfied with 2 and not 1.)","\mathcal{S}^{q} X \mathcal{S}^{q} \colon \mathcal{O}(X)^{op} \to \mathbb{Z} \mathsf{mod} \mathcal{S}^{q}(U)= \operatorname{Hom}(S_{q}(U), \mathbb{Z}) S_q(U) \{ U_{\alpha} \}_{\alpha \in A} U \subset X \mathcal{F}\colon \mathcal{O}(X)^{op} \to \mathbb{Z} \mathsf{mod} s, t \in \mathcal{F}(U) \ s|_{U_{\alpha}} = t|_{U_{\alpha}} \alpha \in A s=t \{f_{\alpha} \in \mathcal{F}(U_{\alpha}) \}_{\alpha \in A} s_{\alpha}|_{U_{\alpha} \cap U_{\beta}} = s_{\beta}|_{U_{\alpha} \cap U_{\beta}} \  \ \alpha, \beta \in A, \  f \in \mathcal{F}(U)  f|_{U_{\alpha}} = f_{\alpha} \alpha \in A \mathcal{S}^{q} \colon \mathcal{O}(X)^{op} \to \mathbb{Z} \mathsf{mod} q 
\ge 1","['differential-geometry', 'algebraic-topology', 'sheaf-theory']"
84,Intuition on chart compatibility for smooth manifolds,Intuition on chart compatibility for smooth manifolds,,"Let $M= \mathbb{R}$ . Consider the charts, $A_1 =\{(\mathbb{R}, \phi_1:t\to t)\}$ and $A_2 =\{(\mathbb{R}, \phi_1),(\mathbb{R},\phi_2:t \to t^3) \}$ . Then it is clear that $M$ is a 1 dimensional manifold with respect to $A_1$ but with respect to $A_2$ , the transition map $\phi^{-1}_2 o$ $\phi_1: \mathbb{R}\to \mathbb{R}$ given by $t \to t^{1/3}$ is not a differentiable function at 0 and hence fails to provide a differentiable structure for $M$ . But what I am not able to understand (or confusing) is that, in $A_2$ one of the chart is simply the identity map. If we consider the chart $\{(\mathbb{R}, \phi_2)\}$ , then this is a differentiable structure for $M$ , however just adding an extra chart $(\mathbb{R},\phi_1)$ (which essentially is a identity map) to the chart $\{(\mathbb{R},\phi_2)\}$ fails to give a differentiable structure as described in previous paragraph. How is this idea captured via the condition that transition maps should be compatible at the non empty intersection between two different charts? I hope I make sense in what I ask. What am I getting wrong or failing to understand properly?","Let . Consider the charts, and . Then it is clear that is a 1 dimensional manifold with respect to but with respect to , the transition map given by is not a differentiable function at 0 and hence fails to provide a differentiable structure for . But what I am not able to understand (or confusing) is that, in one of the chart is simply the identity map. If we consider the chart , then this is a differentiable structure for , however just adding an extra chart (which essentially is a identity map) to the chart fails to give a differentiable structure as described in previous paragraph. How is this idea captured via the condition that transition maps should be compatible at the non empty intersection between two different charts? I hope I make sense in what I ask. What am I getting wrong or failing to understand properly?","M= \mathbb{R} A_1 =\{(\mathbb{R}, \phi_1:t\to t)\} A_2 =\{(\mathbb{R}, \phi_1),(\mathbb{R},\phi_2:t \to t^3) \} M A_1 A_2 \phi^{-1}_2 o \phi_1: \mathbb{R}\to \mathbb{R} t \to t^{1/3} M A_2 \{(\mathbb{R}, \phi_2)\} M (\mathbb{R},\phi_1) \{(\mathbb{R},\phi_2)\}","['differential-geometry', 'smooth-manifolds']"
85,Deducing vanishing of a cohomology class from pairings,Deducing vanishing of a cohomology class from pairings,,"Let $M$ be an oriented closed manifold and $G$ a group. Let $x$ be a class in $H^*(M;\mathbb{Q})$ . Suppose that for every class $y\in H^*(BG,\mathbb{Q})$ and every continuous map $$f\colon M\to BG,$$ we have that $$\langle x\cup f^*y,[M]\rangle=0,$$ where $[M]$ is the fundamental class in $H_*(M,\mathbb{Q})$ . Question: Does it follow that $x=0$ ? Comment: I guess it doesn't really matter whether we are working over the rationals or some other ring, or whether $M$ is a manifold, but this is the situation I'm looking at so I've included these details.","Let be an oriented closed manifold and a group. Let be a class in . Suppose that for every class and every continuous map we have that where is the fundamental class in . Question: Does it follow that ? Comment: I guess it doesn't really matter whether we are working over the rationals or some other ring, or whether is a manifold, but this is the situation I'm looking at so I've included these details.","M G x H^*(M;\mathbb{Q}) y\in H^*(BG,\mathbb{Q}) f\colon M\to BG, \langle x\cup f^*y,[M]\rangle=0, [M] H_*(M,\mathbb{Q}) x=0 M","['differential-geometry', 'algebraic-topology', 'classifying-spaces']"
86,How can I prove certain properties of these vector fields on $S^3$?,How can I prove certain properties of these vector fields on ?,S^3,"On the unit 3-sphere in 4-dimensional Cartesian coordinate space, one can find a set of three orthonormal vector fields that parallelize the 3-sphere. (Utilize the correspondence between the unit 3-sphere and the coordinates of a geometric algebra rotor, and then infinitesimal displacements on the 3-sphere map to/from infinitesimal rotations in 3 orthogonal directions. See below for explicit expressions of the vector fields.) It turns out it is easiest to find the vector fields in terms of the extrinsic 4d coordinates on the 3-sphere - they are just linear functions (and very simple ones at that) of the 4d coordinates. But there are some properties of these vector fields that I want to prove - namely, that they satisfy certain commutation relations (analogous to the commutation relations of the angular momentum operators in quantum mechanics) and that the vector fields are divergence-free - that I only know how to prove by introducing an intrinsic 3d coordinate system. But doing so is laborious. My question is, is there a simple/elegant way to prove the commutation and divergence properties of these vector fields without introducing an intrinsic coordinate system, e.g. by using their symmetry properties or the fact that they generate infinitesimal rotations in orthogonal directions? For further info: on the 3-sphere characterized by the set of points $(w,x,y,z)$ such that $w^2+x^2+y^2+z^2=1$ , the three vector fields are: $$e_1=(-x,w,z,-y)$$ $$e_2=(-y,-z,w,x)$$ $$e_3=(-z,y,-x,w)$$ And the Lie brackets that I want to prove are: $$[e_i,e_j]=2\epsilon_{ijk}e_k$$","On the unit 3-sphere in 4-dimensional Cartesian coordinate space, one can find a set of three orthonormal vector fields that parallelize the 3-sphere. (Utilize the correspondence between the unit 3-sphere and the coordinates of a geometric algebra rotor, and then infinitesimal displacements on the 3-sphere map to/from infinitesimal rotations in 3 orthogonal directions. See below for explicit expressions of the vector fields.) It turns out it is easiest to find the vector fields in terms of the extrinsic 4d coordinates on the 3-sphere - they are just linear functions (and very simple ones at that) of the 4d coordinates. But there are some properties of these vector fields that I want to prove - namely, that they satisfy certain commutation relations (analogous to the commutation relations of the angular momentum operators in quantum mechanics) and that the vector fields are divergence-free - that I only know how to prove by introducing an intrinsic 3d coordinate system. But doing so is laborious. My question is, is there a simple/elegant way to prove the commutation and divergence properties of these vector fields without introducing an intrinsic coordinate system, e.g. by using their symmetry properties or the fact that they generate infinitesimal rotations in orthogonal directions? For further info: on the 3-sphere characterized by the set of points such that , the three vector fields are: And the Lie brackets that I want to prove are:","(w,x,y,z) w^2+x^2+y^2+z^2=1 e_1=(-x,w,z,-y) e_2=(-y,-z,w,x) e_3=(-z,y,-x,w) [e_i,e_j]=2\epsilon_{ijk}e_k","['differential-geometry', 'vector-fields']"
87,Isomorphisms in tangent bundles,Isomorphisms in tangent bundles,,"Given the tangent bundle $T$ , is the following isomorphism $$\Lambda^{d-1}T\simeq T^*\otimes\Lambda^dT^* $$ true on a $d$ -dimensional manifold? i.e. are $(d-1)$ -vectors equivalent to objects which are tensor products of a 1 form and a $d$ form? And if so, why?","Given the tangent bundle , is the following isomorphism true on a -dimensional manifold? i.e. are -vectors equivalent to objects which are tensor products of a 1 form and a form? And if so, why?",T \Lambda^{d-1}T\simeq T^*\otimes\Lambda^dT^*  d (d-1) d,"['differential-geometry', 'fiber-bundles', 'tangent-bundle']"
88,How is this a tangent vector?,How is this a tangent vector?,,"Let $\pi :E\to M$ be a vector bundle with typical fiber $V$ . Suppose that $\pi^*E$ is the pullback bundle of $E$ by $\pi$ . If $(\zeta, \xi) \in \pi^*E$ , then the map $\pi(\zeta +t\xi)$ is constant in $t$ , because both $\zeta$ and $\xi$ are in the same fiber, call it $E_p$ . In my textbook ( Differential Geometric Structures by Poor), it is said that the map $\mathcal J:\pi^*E\to TE$ given by $$\mathcal J(\zeta +t\xi) = \frac d{dt}\Big|_{t=0}(\zeta +t\xi)$$ actually maps into the vertical bundle $\mathcal VE$ . My questions are: How is $\frac d{dt}\Big|_{t =0} (\zeta + t\xi) \in TE$ ? And How is it in $\mathcal VE$ ?","Let be a vector bundle with typical fiber . Suppose that is the pullback bundle of by . If , then the map is constant in , because both and are in the same fiber, call it . In my textbook ( Differential Geometric Structures by Poor), it is said that the map given by actually maps into the vertical bundle . My questions are: How is ? And How is it in ?","\pi :E\to M V \pi^*E E \pi (\zeta, \xi) \in \pi^*E \pi(\zeta +t\xi) t \zeta \xi E_p \mathcal J:\pi^*E\to TE \mathcal J(\zeta +t\xi) = \frac d{dt}\Big|_{t=0}(\zeta +t\xi) \mathcal VE \frac d{dt}\Big|_{t =0} (\zeta + t\xi) \in TE \mathcal VE","['differential-geometry', 'vector-bundles', 'tangent-bundle']"
89,Derive the Jacobi equation from a specific geodesic variation,Derive the Jacobi equation from a specific geodesic variation,,"Construction of a specific geodesic variation: Let $\tau = \{\exp_{x_0}(tX):t\in[0,1]\}$ be a geodesic on a complete Riemannian manifold $(M,g)$ , starting from $x_0\in M$ with velocity $X\in T_{x_0} M$ . Let $V$ be a vector attached to $x_0$ that is not parallel to $X$ . Suppose that both $X$ and $V$ have unit length, i.e., $g_{x_0}(X,X) = g_{x_0}(V,V) = 1$ . Now we introduce the geodesic starting from $x_0$ with velocity $V$ by $$y_s := \exp_{x_0}(sV).$$ Denote the parallel transport of $X$ along $\gamma = \{y_s\}$ by $$X(s) := \Gamma(\gamma)_0^s (X).$$ Then we get a family of geodesics starting from $y_s$ with velocity $X(s)$ , $$\tau^s := \{ \exp_{y_s} (tX(s)):t\in[0,1]\},$$ which forms a variation of the geodesic $\tau$ . So the following vector field along $\tau$ should be the Jacobi field , $$J(t) := \frac{\partial}{\partial s}\bigg|_{s=0} \exp_{y_s} (tX(s)),$$ which means \begin{equation}\tag{1} \frac{D^2}{dt^2} J(t) + R(J(t), \dot \tau(t))\dot \tau(t) =0, \end{equation} where $D$ denotes the covariant derivative with respect to the Levi-Civita connection, $R$ the Riemann curvature tensor. The question is, how to derive the Jacobi equation (1) from this contruction? I tried a lot but failed. This question acturally arises from this paper at its equation (26). Could anyone figure this out? TIA...","Construction of a specific geodesic variation: Let be a geodesic on a complete Riemannian manifold , starting from with velocity . Let be a vector attached to that is not parallel to . Suppose that both and have unit length, i.e., . Now we introduce the geodesic starting from with velocity by Denote the parallel transport of along by Then we get a family of geodesics starting from with velocity , which forms a variation of the geodesic . So the following vector field along should be the Jacobi field , which means where denotes the covariant derivative with respect to the Levi-Civita connection, the Riemann curvature tensor. The question is, how to derive the Jacobi equation (1) from this contruction? I tried a lot but failed. This question acturally arises from this paper at its equation (26). Could anyone figure this out? TIA...","\tau = \{\exp_{x_0}(tX):t\in[0,1]\} (M,g) x_0\in M X\in T_{x_0} M V x_0 X X V g_{x_0}(X,X) = g_{x_0}(V,V) = 1 x_0 V y_s := \exp_{x_0}(sV). X \gamma = \{y_s\} X(s) := \Gamma(\gamma)_0^s (X). y_s X(s) \tau^s := \{ \exp_{y_s} (tX(s)):t\in[0,1]\}, \tau \tau J(t) := \frac{\partial}{\partial s}\bigg|_{s=0} \exp_{y_s} (tX(s)), \begin{equation}\tag{1}
\frac{D^2}{dt^2} J(t) + R(J(t), \dot \tau(t))\dot \tau(t) =0,
\end{equation} D R","['differential-geometry', 'riemannian-geometry', 'geodesic', 'connections']"
90,"For a norm function $f$, do we have a bound on $f([X, Y])$ for two vector field $X$ and $Y$?","For a norm function , do we have a bound on  for two vector field  and ?","f f([X, Y]) X Y","Since $[X, Y]$ is related to the commutator of the flows generated by $X$ and $Y$ , if $X$ and $Y$ are sufficiently smooth, there should be an upper bound on $f([X, Y])$ , say a function of $f(X)$ , $f(Y)$ and Lipschitz constants of $X$ and $Y$ ? I couldn't imagine it become arbitrarily large. And is it true that at least one of the inequality $f([X, Y]) < f(X)$ , $f([X, Y]) < f(Y)$ holds? If it doesn't hold for general vector field, does it hold in some Lie algebra where the vector fields are left invariant?","Since is related to the commutator of the flows generated by and , if and are sufficiently smooth, there should be an upper bound on , say a function of , and Lipschitz constants of and ? I couldn't imagine it become arbitrarily large. And is it true that at least one of the inequality , holds? If it doesn't hold for general vector field, does it hold in some Lie algebra where the vector fields are left invariant?","[X, Y] X Y X Y f([X, Y]) f(X) f(Y) X Y f([X, Y]) < f(X) f([X, Y]) < f(Y)","['differential-geometry', 'lie-algebras', 'vector-fields']"
91,Why does the factor of 1/2 appear in implicit summation of 2-form?,Why does the factor of 1/2 appear in implicit summation of 2-form?,,"I've been watching some videos on differential forms, and I found this brilliant chap. What confuses me is at about 6:12, he calls the other component redundant, and I'm confused what allows him to do so. Consider two 1-forms, $\omega,\tau\in\Omega^1(\mathbb{R}^2)$ , and then consider their wedge \begin{align} \epsilon & = \omega \wedge \tau\\ &= \omega_\mu \tau_\nu dx^\mu \wedge dx^\nu \\ & = \epsilon_{\mu\nu}dx^\mu \wedge dx^\nu \end{align} using implicit summation. Expanding this sum, $$ \epsilon = \epsilon_{11}dx^1 \wedge dx^1 + \epsilon_{12}dx^1 \wedge dx^2 + \epsilon_{21}dx^2 \wedge dx^1 + \epsilon_{22}dx^2 \wedge dx^2, $$ but since these ( $dx^\mu$ ) are $1$ -forms, $dx^\mu \wedge dx^\mu = 0$ , and $dx^\mu \wedge dx^\nu = - dx^\nu \wedge dx^\mu $ , so we may cut out two terms and reduce the others to \begin{align} \epsilon & = \epsilon_{12} dx^1 \wedge dx^2 + \epsilon_{21} dx^2 \wedge dx^1 \\ & = (\epsilon_{12} -\epsilon_{21})dx^1 \wedge dx^2. \end{align} Now, I know that this method (implicit summation) double counts, and hence the full expression reads $\epsilon = \frac{1}{2}\epsilon_{\mu\nu}dx^\mu \wedge dx^\nu$ in the end, but why can I say that $\epsilon_{12}=-\epsilon_{21}$ ? I know that for an antisymmetric matrix this must be true, but what allows me to say this just from the mathematics of wedge products, and the properties of the coefficients? Sorry if this is quite a rudimentary question, I'm just trying to get my head around it.","I've been watching some videos on differential forms, and I found this brilliant chap. What confuses me is at about 6:12, he calls the other component redundant, and I'm confused what allows him to do so. Consider two 1-forms, , and then consider their wedge using implicit summation. Expanding this sum, but since these ( ) are -forms, , and , so we may cut out two terms and reduce the others to Now, I know that this method (implicit summation) double counts, and hence the full expression reads in the end, but why can I say that ? I know that for an antisymmetric matrix this must be true, but what allows me to say this just from the mathematics of wedge products, and the properties of the coefficients? Sorry if this is quite a rudimentary question, I'm just trying to get my head around it.","\omega,\tau\in\Omega^1(\mathbb{R}^2) \begin{align}
\epsilon & = \omega \wedge \tau\\
&= \omega_\mu \tau_\nu dx^\mu \wedge dx^\nu \\
& = \epsilon_{\mu\nu}dx^\mu \wedge dx^\nu
\end{align} 
\epsilon = \epsilon_{11}dx^1 \wedge dx^1 + \epsilon_{12}dx^1 \wedge dx^2 + \epsilon_{21}dx^2 \wedge dx^1 + \epsilon_{22}dx^2 \wedge dx^2,
 dx^\mu 1 dx^\mu \wedge dx^\mu = 0 dx^\mu \wedge dx^\nu = - dx^\nu \wedge dx^\mu  \begin{align}
\epsilon & = \epsilon_{12} dx^1 \wedge dx^2 + \epsilon_{21} dx^2 \wedge dx^1 \\
& = (\epsilon_{12} -\epsilon_{21})dx^1 \wedge dx^2.
\end{align} \epsilon = \frac{1}{2}\epsilon_{\mu\nu}dx^\mu \wedge dx^\nu \epsilon_{12}=-\epsilon_{21}","['differential-geometry', 'differential-forms', 'exterior-algebra']"
92,Geodesic deviation in flat space,Geodesic deviation in flat space,,"Suppose that $x^\mu(t,s)$ represents a family of curves. Let $v^\mu$ represents the the tangent vector to a curve $x^\mu(t,s_0)$ with $s_0$ fixed that is $v^{\mu}=\partial x^{\mu} / \partial t$ and deviation vector is given by $\xi^{\alpha}=\partial x^{\alpha} / \partial s$ . In the usual derivation of the geodesic deviation equation it is showed that $\xi$ is lie transposed through $v$ that is $$L_v\xi=0$$ where $L$ stands for the lie derivative. To make the discussion more clear let us suppose we are in flat spacetime with  usual Cartesian coordinates $x^0=t,x^1,x^2,x^3$ . We choose $x^\mu(t,s)=(t,st,0,0)$ and so $v^\mu=(1,s,0,0)$ and $\xi^{\alpha}=(0,t,0,0)$ we have $$L_v\xi=\left[\frac{\partial}{\partial t}+s\frac{\partial}{\partial x^{1}},t\frac{\partial}{\partial x^{1}} \right]=\frac{\partial}{\partial x^1}-\frac{\partial s}{\partial x^1}\frac{\partial}{\partial x^1}$$ So we choose the parameter $s$ for example to $2x^1$ we would have $L_v\xi \ne0$ Isn't this a contradiction?",Suppose that represents a family of curves. Let represents the the tangent vector to a curve with fixed that is and deviation vector is given by . In the usual derivation of the geodesic deviation equation it is showed that is lie transposed through that is where stands for the lie derivative. To make the discussion more clear let us suppose we are in flat spacetime with  usual Cartesian coordinates . We choose and so and we have So we choose the parameter for example to we would have Isn't this a contradiction?,"x^\mu(t,s) v^\mu x^\mu(t,s_0) s_0 v^{\mu}=\partial x^{\mu} / \partial t \xi^{\alpha}=\partial x^{\alpha} / \partial s \xi v L_v\xi=0 L x^0=t,x^1,x^2,x^3 x^\mu(t,s)=(t,st,0,0) v^\mu=(1,s,0,0) \xi^{\alpha}=(0,t,0,0) L_v\xi=\left[\frac{\partial}{\partial t}+s\frac{\partial}{\partial x^{1}},t\frac{\partial}{\partial x^{1}} \right]=\frac{\partial}{\partial x^1}-\frac{\partial s}{\partial x^1}\frac{\partial}{\partial x^1} s 2x^1 L_v\xi \ne0",['differential-geometry']
93,Showing that a bundle homomorphism is a smooth isomorphism.,Showing that a bundle homomorphism is a smooth isomorphism.,,"This is Lee's problem $10-11$ in his Introduction to Smooth Manifolds . If $\pi:E\to M$ and $\pi':E'\to M$ are vector bundles over the smooth manifold $M$ and if $F:E\to E'$ is a bijective smooth bundle homomorphism, then $F$ is a smooth bundle isomorphism. Here is my attempt. My question is at the very end. We need to show that $F^{-1}$ is smooth. So, let $p\in E.$ There are open sets $U,U'\subseteq M$ such that $p\in U, F(p)\in U'$ and such that there are local trivializations $\Psi:\pi^{-1}(U)\to U\times \mathbb R^n\ $ and $\Psi':\pi'^{-1}(U')\to U'\times \mathbb R^n.$ Define $f=\Psi'\circ F\circ \Psi^{-1}$ on a sufficiently small open set containing $\Psi (p)$ so that the diagram from which the following data follow makes sense: $\tag 1 \pi_U\circ \Psi=\pi$ $\tag 2 \pi_{U'}\circ \Psi'=\pi'$ $\tag 3 \pi'\circ F=\pi$ Now, take $x\times v$ in this open set. Using $(1),(2),(3),$ we can show that $f$ sends $x\times v$ to $x\times w$ for some $w\in \mathbb R^n.$ Since $\Psi, \Psi'$ are diffeomorphisms and and $F$ is bijective, $f$ is bijective. We also have that $f\big |_{ \{x\}\times \mathbb R^n}$ is a vector space isomorphism. This means that there is an invertible linear transformation $\tau_x:\mathbb R^n\to \mathbb R^n$ such that $f(x,v)=(x,\tau_x(v)).$ Then, $f^{-1}(x,v)=(x,\tau_x^{-1}(v)).$ To finish, just note that $f^{-1}=\Psi\circ F^{-1}\circ \Psi'^{-1}$ and  that the composition $(x,v)\mapsto (x,\tau_x(v))\mapsto (x,\tau_x^{-1}(v))$ is smooth. Inversion is smooth but it is not clear to me why the first one is. Edit: the first map is smooth just because it is just $f=\Psi'\circ F\circ \Psi^{-1},$ which is smooth.","This is Lee's problem in his Introduction to Smooth Manifolds . If and are vector bundles over the smooth manifold and if is a bijective smooth bundle homomorphism, then is a smooth bundle isomorphism. Here is my attempt. My question is at the very end. We need to show that is smooth. So, let There are open sets such that and such that there are local trivializations and Define on a sufficiently small open set containing so that the diagram from which the following data follow makes sense: Now, take in this open set. Using we can show that sends to for some Since are diffeomorphisms and and is bijective, is bijective. We also have that is a vector space isomorphism. This means that there is an invertible linear transformation such that Then, To finish, just note that and  that the composition is smooth. Inversion is smooth but it is not clear to me why the first one is. Edit: the first map is smooth just because it is just which is smooth.","10-11 \pi:E\to M \pi':E'\to M M F:E\to E' F F^{-1} p\in E. U,U'\subseteq M p\in U, F(p)\in U' \Psi:\pi^{-1}(U)\to U\times \mathbb R^n\  \Psi':\pi'^{-1}(U')\to U'\times \mathbb R^n. f=\Psi'\circ F\circ \Psi^{-1} \Psi (p) \tag 1 \pi_U\circ \Psi=\pi \tag 2 \pi_{U'}\circ \Psi'=\pi' \tag 3 \pi'\circ F=\pi x\times v (1),(2),(3), f x\times v x\times w w\in \mathbb R^n. \Psi, \Psi' F f f\big |_{ \{x\}\times \mathbb R^n} \tau_x:\mathbb R^n\to \mathbb R^n f(x,v)=(x,\tau_x(v)). f^{-1}(x,v)=(x,\tau_x^{-1}(v)). f^{-1}=\Psi\circ F^{-1}\circ \Psi'^{-1} (x,v)\mapsto (x,\tau_x(v))\mapsto (x,\tau_x^{-1}(v)) f=\Psi'\circ F\circ \Psi^{-1},","['differential-geometry', 'manifolds', 'smooth-manifolds']"
94,"Action of $S^1$ as a Lie Group on $S^2$ by ""rotation""","Action of  as a Lie Group on  by ""rotation""",S^1 S^2,"I'm studying Lie Groups and their actions on manifolds and I was looking for a ""concrete"" example of an action. All the stuff about $GL(n;\mathbb{R})$ acting on $\mathbb{R}^n$ is ok but I can't visualise it well, so I thought of an action by the Lie group $S^1$ on $S^2$ by ""rotation"" in this sense: every element of $S^1$ can be identified by and angle $\alpha$ given by the anti-clockwise rotation around the center $(0,0)$ ; in the same way we can parametrize $S^2$ using latitude and colatitude. The action that I came up with is simply $$ \begin{gather} S^1 \times S^2 \longrightarrow S^2 \\ (\alpha,(\theta, \varphi))\longmapsto (\alpha + \theta, \varphi) \end{gather} $$ which ""spins"" $S^2$ around the vertical axis. Is this actually an example of a Lie group acting on $S^2$ ? Are there any other more ""concrete"" examples I can look at?","I'm studying Lie Groups and their actions on manifolds and I was looking for a ""concrete"" example of an action. All the stuff about acting on is ok but I can't visualise it well, so I thought of an action by the Lie group on by ""rotation"" in this sense: every element of can be identified by and angle given by the anti-clockwise rotation around the center ; in the same way we can parametrize using latitude and colatitude. The action that I came up with is simply which ""spins"" around the vertical axis. Is this actually an example of a Lie group acting on ? Are there any other more ""concrete"" examples I can look at?","GL(n;\mathbb{R}) \mathbb{R}^n S^1 S^2 S^1 \alpha (0,0) S^2 
\begin{gather}
S^1 \times S^2 \longrightarrow S^2 \\
(\alpha,(\theta, \varphi))\longmapsto (\alpha + \theta, \varphi)
\end{gather}
 S^2 S^2","['differential-geometry', 'lie-groups', 'group-actions']"
95,Transversality in $\mathbb{R}^2$,Transversality in,\mathbb{R}^2,"Define, for some $a\in\mathbb{R}, f_{a}:\mathbb{R}\to\mathbb{R}^{2}$ by $f_{a}(p)=(p,a)$ and consider $N\subset\mathbb{R}^{2}, \ N=\{(x,x^2); x\in\mathbb{R}\}.$ Analysis of the transversality of $f_{a}$ with $N.$ Could someone help me, please? Geometrically, we can see that for $a\leq 0,$ $f_{a}$ isn't transversality to $N$ . How to prove it? So, $d(f_{a})_{p}(v)=(v,0)$ and $T_{(p,p^2)}N=\{(v,2pv)| v \in \mathbb{R}\}.$ How and why does $ a $ influence this?","Define, for some by and consider Analysis of the transversality of with Could someone help me, please? Geometrically, we can see that for isn't transversality to . How to prove it? So, and How and why does influence this?","a\in\mathbb{R}, f_{a}:\mathbb{R}\to\mathbb{R}^{2} f_{a}(p)=(p,a) N\subset\mathbb{R}^{2}, \ N=\{(x,x^2); x\in\mathbb{R}\}. f_{a} N. a\leq 0, f_{a} N d(f_{a})_{p}(v)=(v,0) T_{(p,p^2)}N=\{(v,2pv)| v \in \mathbb{R}\}.  a ",['differential-geometry']
96,Is every real vector bundle immersed in the tangent bundle of a Manifold?,Is every real vector bundle immersed in the tangent bundle of a Manifold?,,"For me ""manifold"" = "" $C^\infty$ -manifold"" and also ""vector bundle"" = ""smooth vector bundle"" There's not much context, im learning about Vector Bundles and I wonder if every vector bundle over a manifold can be inmerse in the tangent bundle of a Manifold. Even stronger, let $E$ be a vector bundle over a manifold $M$ with fibers of dimension equal to $dim (M)$ , I would like to know if there is a diffeomorphism $f:M \rightarrow M$ whose push-out $f_* :E \rightarrow T(M)$ is a vector bundle isomorphism. If the answer to the last one is negative, are there some hypothesis over $M$ and/or $E$ to make it true? For example, I've just realised you can take many different vector bundles over $S^1$ not ishomorphic (because they make a different amount of Twists).","For me ""manifold"" = "" -manifold"" and also ""vector bundle"" = ""smooth vector bundle"" There's not much context, im learning about Vector Bundles and I wonder if every vector bundle over a manifold can be inmerse in the tangent bundle of a Manifold. Even stronger, let be a vector bundle over a manifold with fibers of dimension equal to , I would like to know if there is a diffeomorphism whose push-out is a vector bundle isomorphism. If the answer to the last one is negative, are there some hypothesis over and/or to make it true? For example, I've just realised you can take many different vector bundles over not ishomorphic (because they make a different amount of Twists).",C^\infty E M dim (M) f:M \rightarrow M f_* :E \rightarrow T(M) M E S^1,"['differential-geometry', 'smooth-manifolds', 'vector-bundles']"
97,smooth vector fields over the 2-sphere is not a free module,smooth vector fields over the 2-sphere is not a free module,,"I keep seeing that the hairy ball theorem implies that smooth vector fields over $S^2$ are not a free module is implied by the hairy ball theorem; I don't understand how. How do I fill in the gaps? The hairy ball theorem tells us that we cannot have a smooth nonvanishing vector field over $S^2$ . For contradiction, assume that $\mathfrak X(S^2)$ is a free module over the ring $C^\infty (S^2)$ . Thus, $\mathfrak X(S^2) \simeq \oplus_i C^\infty(S^2)$ , since a free module is isomorphic to a direct sum of copies the ring. I am unsure how to continue. I have some ideas: First, see that we need at least two copies of $C^\infty(S^2)$ , because the sphere locally looks like $\mathbb R^2$ . If we have exactly two basis vector fields $V_1, V_2$ , then these must both vanish at points $p_1$ , $p_2$ by the hairy ball theorem. Consider the neighbourhood of $p_1$ : since $v_1$ vanishes, we have only one vector field $V_2$ which is not sufficient to locally span $\mathbb R^2$ . If we have three vector fields, we can have $V_{1, 2, 3}$ vanish at distinct $p_{1 2, 3}$ thereby leaving two vector fields even when one of them vanishes. However, now we can pick a point where none of $V_{1, 2, 3}$ vanish. (Why does such a point exist?). At this point, locally, we have three degrees of freedom $V_{1, 2, 3}$ , but the vector space looks like $\mathbb R^2$ so they cannot be linearly independent. Unfortunately, as is obvious from the above, I have no idea how to make this rigorous. I would appreciate whether this proof is repairable, and if now, how does one actually prove that smooth vector fields over $S^2$ are not  free module?","I keep seeing that the hairy ball theorem implies that smooth vector fields over are not a free module is implied by the hairy ball theorem; I don't understand how. How do I fill in the gaps? The hairy ball theorem tells us that we cannot have a smooth nonvanishing vector field over . For contradiction, assume that is a free module over the ring . Thus, , since a free module is isomorphic to a direct sum of copies the ring. I am unsure how to continue. I have some ideas: First, see that we need at least two copies of , because the sphere locally looks like . If we have exactly two basis vector fields , then these must both vanish at points , by the hairy ball theorem. Consider the neighbourhood of : since vanishes, we have only one vector field which is not sufficient to locally span . If we have three vector fields, we can have vanish at distinct thereby leaving two vector fields even when one of them vanishes. However, now we can pick a point where none of vanish. (Why does such a point exist?). At this point, locally, we have three degrees of freedom , but the vector space looks like so they cannot be linearly independent. Unfortunately, as is obvious from the above, I have no idea how to make this rigorous. I would appreciate whether this proof is repairable, and if now, how does one actually prove that smooth vector fields over are not  free module?","S^2 S^2 \mathfrak X(S^2) C^\infty (S^2) \mathfrak X(S^2) \simeq \oplus_i C^\infty(S^2) C^\infty(S^2) \mathbb R^2 V_1, V_2 p_1 p_2 p_1 v_1 V_2 \mathbb R^2 V_{1, 2, 3} p_{1 2, 3} V_{1, 2, 3} V_{1, 2, 3} \mathbb R^2 S^2","['differential-geometry', 'modules', 'differential-topology']"
98,Proving that $SU(n)$ is a smooth manifold,Proving that  is a smooth manifold,SU(n),"Considering this post: Show that $SL(n, \mathbb{R})$ is a $(n^2 -1)$ smooth submanifold of $M(n,\mathbb{R})$ I dont understand how the manipulations in the limit are done, for instance: $$ \det(A+tA)=(1+t)^n \det(A)$$ and how the limit overall evaluates to: $n \det(A)$","Considering this post: Show that $SL(n, \mathbb{R})$ is a $(n^2 -1)$ smooth submanifold of $M(n,\mathbb{R})$ I dont understand how the manipulations in the limit are done, for instance: and how the limit overall evaluates to:", \det(A+tA)=(1+t)^n \det(A) n \det(A),"['differential-geometry', 'manifolds', 'lie-groups', 'determinant', 'smooth-manifolds']"
99,Is homotopy of smooth maps $M \to \mathbb{S}^n$ equivalent to smooth homotopy?,Is homotopy of smooth maps  equivalent to smooth homotopy?,M \to \mathbb{S}^n,"I'm trying to solve the following exercise from Milnor's Topology from the Differentiable Viewpoint Let $M$ be a compact smooth manifold, show that every continuous map $M \to \mathbb{S}^n$ can be uniformly approximated by a smooth map. If  two smooth maps are continuously homotopic, show that they are smoothly homotopic. I solved the first part approximating every coordinate thanks to Stone-Weierstrass' Theorem and normalizing. I think it should work. Then I tried to use the first part to solve the second one (about smooth homotopy), but I'm not able to understand how I should use approximation to change a continuous map to a smooth one. How could I solve this problem?","I'm trying to solve the following exercise from Milnor's Topology from the Differentiable Viewpoint Let be a compact smooth manifold, show that every continuous map can be uniformly approximated by a smooth map. If  two smooth maps are continuously homotopic, show that they are smoothly homotopic. I solved the first part approximating every coordinate thanks to Stone-Weierstrass' Theorem and normalizing. I think it should work. Then I tried to use the first part to solve the second one (about smooth homotopy), but I'm not able to understand how I should use approximation to change a continuous map to a smooth one. How could I solve this problem?",M M \to \mathbb{S}^n,"['differential-geometry', 'manifolds', 'smooth-manifolds', 'homotopy-theory', 'smooth-functions']"
