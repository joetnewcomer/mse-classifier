,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to calculate $ \lim_{n\to \infty}\left(\sum_{k=1}^{n}\frac{1}{3k+1}-\frac{\ln n}{3}\right)$,How to calculate, \lim_{n\to \infty}\left(\sum_{k=1}^{n}\frac{1}{3k+1}-\frac{\ln n}{3}\right),When I learned harmonic series. I met this limit. $\displaystyle \lim_{n\to \infty}\left(\sum_{k=0}^{n}\frac{1}{3k+1}-\frac{\ln n}{3}\right)=\frac{\gamma}{3}+\frac{\sqrt3\pi}{18}+\frac{\ln3}{2}$ $\gamma$ is EulerGamma. But i don't know how to prove it.And naturally i got: $\displaystyle \lim_{n\to \infty}\left(\sum_{k=0}^{n}\frac{1}{pk+1}-\frac{\ln n}{p}\right)\qquad p\in N$ Could someone help me to solve the two limits?,When I learned harmonic series. I met this limit. $\displaystyle \lim_{n\to \infty}\left(\sum_{k=0}^{n}\frac{1}{3k+1}-\frac{\ln n}{3}\right)=\frac{\gamma}{3}+\frac{\sqrt3\pi}{18}+\frac{\ln3}{2}$ $\gamma$ is EulerGamma. But i don't know how to prove it.And naturally i got: $\displaystyle \lim_{n\to \infty}\left(\sum_{k=0}^{n}\frac{1}{pk+1}-\frac{\ln n}{p}\right)\qquad p\in N$ Could someone help me to solve the two limits?,,"['calculus', 'sequences-and-series', 'analysis', 'limits']"
1,How to prove the closed form of an integral,How to prove the closed form of an integral,,"How to prove the following identity: $${1\over 2\pi}\int_{0}^{2\pi}\ln(1-2r\cos x+r^{2})\,dx=2\ln r,\text{ where } r\gt 1.$$ I was asked to use the following result to prove it: $$\lim_{n\to\infty}\sqrt[n]{f_{1n}f_{2n}\cdots f_{nn}}=\exp\left\{{1\over{b-a}}\int_a^b \ln f(x)\,dx\right\}$$ provided $f\in C[a,b]$, $f\gt 0$, and $f_{vn}=f(a+v\delta_n), \delta_n={{b-a}\over n}$ It's easy to prove the hint by checking the definition of Riemann integral,but I was trapped in using it to prove the original identity. Thanks for help!","How to prove the following identity: $${1\over 2\pi}\int_{0}^{2\pi}\ln(1-2r\cos x+r^{2})\,dx=2\ln r,\text{ where } r\gt 1.$$ I was asked to use the following result to prove it: $$\lim_{n\to\infty}\sqrt[n]{f_{1n}f_{2n}\cdots f_{nn}}=\exp\left\{{1\over{b-a}}\int_a^b \ln f(x)\,dx\right\}$$ provided $f\in C[a,b]$, $f\gt 0$, and $f_{vn}=f(a+v\delta_n), \delta_n={{b-a}\over n}$ It's easy to prove the hint by checking the definition of Riemann integral,but I was trapped in using it to prove the original identity. Thanks for help!",,"['calculus', 'integration', 'sequences-and-series', 'limits']"
2,Delta epsilon proof with $x \rightarrow \infty$,Delta epsilon proof with,x \rightarrow \infty,I have a rational function that reaches a horizontal asymptote as $x \rightarrow \infty$ . How would you do a delta-epsilon proof with $x\to\infty$ . Here is the limit statement: $$\lim_{x\to\infty}\frac{3x+7}{2x-1} = \frac{3}{2}.$$ Hope some one can help. Paulo,I have a rational function that reaches a horizontal asymptote as . How would you do a delta-epsilon proof with . Here is the limit statement: Hope some one can help. Paulo,x \rightarrow \infty x\to\infty \lim_{x\to\infty}\frac{3x+7}{2x-1} = \frac{3}{2}.,"['calculus', 'probability-limit-theorems']"
3,How to Evaluate $ \int \! \frac{dx}{1+2\cos x} $ ? [duplicate],How to Evaluate  ? [duplicate], \int \! \frac{dx}{1+2\cos x} ,"This question already has answers here : Closed 11 years ago . Possible Duplicate: How do you integrate $\int \frac{1}{a + \cos x} dx$? I have come across this integral and I tried various methods of solving. The thing that gets in the way is the constant $2$ on the $\cos(x)$ term. I tried the conjugate (works without the 2 $\cos x$), Weierstrass Substitution (not sure if I was applying it correctly), and others. Is there a way to solve this integral elegantly or some unknown (sneaky) trick when you come across families of similar integrals as this one?: $$ \int \! \frac{dx}{1+2\cos x} $$","This question already has answers here : Closed 11 years ago . Possible Duplicate: How do you integrate $\int \frac{1}{a + \cos x} dx$? I have come across this integral and I tried various methods of solving. The thing that gets in the way is the constant $2$ on the $\cos(x)$ term. I tried the conjugate (works without the 2 $\cos x$), Weierstrass Substitution (not sure if I was applying it correctly), and others. Is there a way to solve this integral elegantly or some unknown (sneaky) trick when you come across families of similar integrals as this one?: $$ \int \! \frac{dx}{1+2\cos x} $$",,"['calculus', 'integration']"
4,Convex and bounded function is constant [duplicate],Convex and bounded function is constant [duplicate],,"This question already has answers here : Show bounded and convex function on $\mathbb R$ is constant (4 answers) Closed 10 years ago . Let f be a convex and  bounded function, meaning there is a constant $C$, such that $f(x) < C$ for every $x$. I need to prove that $f$ is a constant function. Thanks!","This question already has answers here : Show bounded and convex function on $\mathbb R$ is constant (4 answers) Closed 10 years ago . Let f be a convex and  bounded function, meaning there is a constant $C$, such that $f(x) < C$ for every $x$. I need to prove that $f$ is a constant function. Thanks!",,[]
5,Integral's computation does not match WolframAlpha result,Integral's computation does not match WolframAlpha result,,"So I'm computing the following integral: \begin{align} \int_0^1 \frac{\tan^{-1}(x)\ln(x)}{x}dx \end{align} I started out with a simple integration by parts which yielded: \begin{align} -\int_0^1 \frac{\ln^2(x)}{x^2 + 1}dx \end{align} A nifty substitution $x \to \frac{1}{x}$ and adding the new integral to the original gives: \begin{align} -\frac 12 \int_0^{\infty} \frac{\ln^2(x)}{x^2 + 1}dx \end{align} The integral now warrants a fairly obvious substitution $x \to \tan x$ : \begin{align} -\frac 12 \int_0^{\frac{\pi}{2}}\ln^2(\tan x) dx \end{align} Which may be written as: \begin{align} -\frac 12 \frac{d^2}{ds^2} \left ( \int_0^{\frac{\pi}{2}} \tan^s (x)dx \right )_{s = 0} \end{align} Using the beta function yields: \begin{align} -\frac{\pi}{4} \frac{d^2}{ds^2} \left [ \sec \left ( \frac{\pi s}{2} \right ) \right ]_{s=0} = -\frac{\pi^3}{16} \end{align} However, Wolfram Alpha notes the answer to be $-\frac{\pi^3}{32}$ , if the descrepancy has been noticed, I'd be grateful!","So I'm computing the following integral: I started out with a simple integration by parts which yielded: A nifty substitution and adding the new integral to the original gives: The integral now warrants a fairly obvious substitution : Which may be written as: Using the beta function yields: However, Wolfram Alpha notes the answer to be , if the descrepancy has been noticed, I'd be grateful!","\begin{align}
\int_0^1 \frac{\tan^{-1}(x)\ln(x)}{x}dx
\end{align} \begin{align}
-\int_0^1 \frac{\ln^2(x)}{x^2 + 1}dx
\end{align} x \to \frac{1}{x} \begin{align}
-\frac 12 \int_0^{\infty} \frac{\ln^2(x)}{x^2 + 1}dx
\end{align} x \to \tan x \begin{align}
-\frac 12 \int_0^{\frac{\pi}{2}}\ln^2(\tan x) dx
\end{align} \begin{align}
-\frac 12 \frac{d^2}{ds^2} \left ( \int_0^{\frac{\pi}{2}} \tan^s (x)dx \right )_{s = 0}
\end{align} \begin{align}
-\frac{\pi}{4} \frac{d^2}{ds^2} \left [ \sec \left ( \frac{\pi s}{2} \right ) \right ]_{s=0} = -\frac{\pi^3}{16}
\end{align} -\frac{\pi^3}{32}","['calculus', 'integration']"
6,Compute $\int_0^{\pi/2} x^2\left(\sum_{n=1}^\infty (-1)^{n-1} \cos^n(x)\cos(nx)\right)dx$,Compute,\int_0^{\pi/2} x^2\left(\sum_{n=1}^\infty (-1)^{n-1} \cos^n(x)\cos(nx)\right)dx,"How to prove $$I=\int_0^{\pi/2} x^2\left(\sum_{n=1}^\infty (-1)^{n-1} \cos^n(x)\cos(nx)\right)dx=\frac16\left(\frac{\pi^3}{12}-\pi\operatorname{Li}_2\left(\frac13\right)\right)$$ This problem is proposed by Cornel which can be found here where he suggested that the problem can be solved with and without harmonic series. Here is my approach but I got stuck at the blue integral: Using the common identity $$ \sum_{n=1}^{\infty}p^n \cos(nx)=\frac{p(\cos(x)-p)}{1-2p\cos(x)+p^2}, \ |p|<1$$ Set $p=-\cos(x)$ we get $$ \sum_{n=1}^{\infty}(-1)^n \cos^n(x) \cos(nx)=-\frac{2\cos^2(x)}{1+3\cos^2(x)}=-\frac23+\frac23\frac1{1+3\cos^2(x)}$$ Multiply both sides by $-x^2$ then integrate from $x=0$ to $\pi/2$ we get $$\int_0^{\pi/2} x^2\left(\sum_{n=1}^\infty (-1)^{n-1} \cos^n(x)\cos(nx)\right)dx=\frac23\int_0^{\pi/2} x^2dx-\frac23\color{blue}{\int_0^{\pi/2}\frac{x^2}{1+3\cos^2(x)}dx}\\=\frac{\pi^3}{36}-\frac23\left(\color{blue}{\frac{\pi^3}{48}+\frac{\pi}{4}\operatorname{Li}_2\left(\frac13\right)}\right)=\frac{\pi^3}{72}-\frac{\pi}{6}\operatorname{Li}_2\left(\frac13\right)$$ I have two Questions: 1) Can we evaluate $I$ in a different way? 2) How to finish the blue integral? My try to the blue integral is using integration by parts $$\int\frac{dx}{1+3\cos^2(x)}=\frac12\tan^{-1}\left(\frac{\tan(x)}{2}\right)=-\frac12\tan^{-1}\left(2\cot(x)\right)$$ which gives us $$\int_0^{\pi/2}\frac{x^2}{1+3\cos^2(x)}dx=\frac{\pi^3}{16}-\int_0^{\pi/2}x\tan^{-1}\left(\frac{\tan(x)}{2}\right)dx$$ Or $$\int_0^{\pi/2}\frac{x^2}{1+3\cos^2(x)}dx=\int_0^{\pi/2}x\tan^{-1}\left(2\cot(x)\right)dx$$ I also tried the trick $x\to \pi/2-x$ but got complicated Proof of the identity: \begin{align} \sum_{n=0}^\infty p^ne^{inx}&=\sum_{n=0}^\infty\left(p e^{ix}\right)^n=\frac{1}{1-pe^{ix}},\quad |p|<1\\&=\frac{1}{1-p\cos(x)-ip\sin(x)}=\frac{1-p\cos(x)+ip\sin(x)}{1-2p\cos(x)+p^2}\\ &=\frac{1-p\cos(x)}{1-2p\cos(x)+p^2}+i\frac{p\sin(x)}{1-2p\cos(x)+p^2} \end{align} By comparing the real and imaginary parts, we get $$\sum_{n=\color{blue}{0}}^\infty p^n \cos(nx)=\frac{1-p\cos(x)}{1-2p\cos(x)+p^2}\Longrightarrow \sum_{n=\color{blue}{1}}^\infty p^{n-1} \cos(nx)=\frac{\cos(x)-p}{1-2p\cos(x)+p^2}$$ and $$\sum_{n=\color{red}{0}}^\infty p^n \sin(nx)=\frac{p\sin(x)}{1-2p\cos(x)+p^2}\Longrightarrow \sum_{n=\color{red}{1}}^\infty p^n \sin(nx)=\frac{p\sin(x)}{1-2p\cos(x)+p^2}$$","How to prove This problem is proposed by Cornel which can be found here where he suggested that the problem can be solved with and without harmonic series. Here is my approach but I got stuck at the blue integral: Using the common identity Set we get Multiply both sides by then integrate from to we get I have two Questions: 1) Can we evaluate in a different way? 2) How to finish the blue integral? My try to the blue integral is using integration by parts which gives us Or I also tried the trick but got complicated Proof of the identity: By comparing the real and imaginary parts, we get and","I=\int_0^{\pi/2} x^2\left(\sum_{n=1}^\infty (-1)^{n-1} \cos^n(x)\cos(nx)\right)dx=\frac16\left(\frac{\pi^3}{12}-\pi\operatorname{Li}_2\left(\frac13\right)\right)  \sum_{n=1}^{\infty}p^n \cos(nx)=\frac{p(\cos(x)-p)}{1-2p\cos(x)+p^2}, \ |p|<1 p=-\cos(x)  \sum_{n=1}^{\infty}(-1)^n \cos^n(x) \cos(nx)=-\frac{2\cos^2(x)}{1+3\cos^2(x)}=-\frac23+\frac23\frac1{1+3\cos^2(x)} -x^2 x=0 \pi/2 \int_0^{\pi/2} x^2\left(\sum_{n=1}^\infty (-1)^{n-1} \cos^n(x)\cos(nx)\right)dx=\frac23\int_0^{\pi/2} x^2dx-\frac23\color{blue}{\int_0^{\pi/2}\frac{x^2}{1+3\cos^2(x)}dx}\\=\frac{\pi^3}{36}-\frac23\left(\color{blue}{\frac{\pi^3}{48}+\frac{\pi}{4}\operatorname{Li}_2\left(\frac13\right)}\right)=\frac{\pi^3}{72}-\frac{\pi}{6}\operatorname{Li}_2\left(\frac13\right) I \int\frac{dx}{1+3\cos^2(x)}=\frac12\tan^{-1}\left(\frac{\tan(x)}{2}\right)=-\frac12\tan^{-1}\left(2\cot(x)\right) \int_0^{\pi/2}\frac{x^2}{1+3\cos^2(x)}dx=\frac{\pi^3}{16}-\int_0^{\pi/2}x\tan^{-1}\left(\frac{\tan(x)}{2}\right)dx \int_0^{\pi/2}\frac{x^2}{1+3\cos^2(x)}dx=\int_0^{\pi/2}x\tan^{-1}\left(2\cot(x)\right)dx x\to \pi/2-x \begin{align}
\sum_{n=0}^\infty p^ne^{inx}&=\sum_{n=0}^\infty\left(p e^{ix}\right)^n=\frac{1}{1-pe^{ix}},\quad |p|<1\\&=\frac{1}{1-p\cos(x)-ip\sin(x)}=\frac{1-p\cos(x)+ip\sin(x)}{1-2p\cos(x)+p^2}\\
&=\frac{1-p\cos(x)}{1-2p\cos(x)+p^2}+i\frac{p\sin(x)}{1-2p\cos(x)+p^2}
\end{align} \sum_{n=\color{blue}{0}}^\infty p^n \cos(nx)=\frac{1-p\cos(x)}{1-2p\cos(x)+p^2}\Longrightarrow \sum_{n=\color{blue}{1}}^\infty p^{n-1} \cos(nx)=\frac{\cos(x)-p}{1-2p\cos(x)+p^2} \sum_{n=\color{red}{0}}^\infty p^n \sin(nx)=\frac{p\sin(x)}{1-2p\cos(x)+p^2}\Longrightarrow \sum_{n=\color{red}{1}}^\infty p^n \sin(nx)=\frac{p\sin(x)}{1-2p\cos(x)+p^2}","['calculus', 'integration', 'sequences-and-series', 'harmonic-numbers', 'polylogarithm']"
7,Prove that there exists no differentiable real function $g(x)$ such that $g(g(x))=-x^3+x+1$.,Prove that there exists no differentiable real function  such that .,g(x) g(g(x))=-x^3+x+1,"Prove that there exists no differentiable real function $g(x)$ such that $g(g(x))=-x^3+x+1$. I have googled it but find nothing useful. Now I know it's a Iterated function problem. It's an exercise problem after the chapter DERIVATIVE , so I guess maybe it's not too difficult. Could you give me a hint to solve this problem? Could you give me a book list about the  systematic introduction about Iterated function?","Prove that there exists no differentiable real function $g(x)$ such that $g(g(x))=-x^3+x+1$. I have googled it but find nothing useful. Now I know it's a Iterated function problem. It's an exercise problem after the chapter DERIVATIVE , so I guess maybe it's not too difficult. Could you give me a hint to solve this problem? Could you give me a book list about the  systematic introduction about Iterated function?",,['calculus']
8,An integral of rational function with third power of cosine hyperbolic function,An integral of rational function with third power of cosine hyperbolic function,,"Prove $$\int_{-\infty}^{\infty}\frac{1}{(5 \pi^2 + 8 \pi x + 16x^2)  }\frac{\cosh\left(x+\frac{\pi}{4} \right)}{\cosh^3(x)}dx =  \frac{2}{\pi^3}\left(\pi \cosh\left(\frac{\pi}{4} \right)-4\sinh\left(  \frac{\pi}{4}\right) \right)$$ Attempt Note that $$\cosh\left( x+\frac{\pi}{4}\right) = \cosh(x)\cosh\left(\frac{\pi}{4} \right)+\sinh(x)\sinh\left( \frac{\pi}{4}\right)$$ Then the integral could be rewritten as $$I = \cosh\left(\frac{\pi}{4} \right)\int_{-\infty}^{\infty}\frac{\mathrm{sech} ^2(x)}{(5 \pi^2 + 8 \pi x + 16x^2) }dx\\+\sinh\left(\frac{\pi}{4} \right)\int_{-\infty}^{\infty}\frac{\sinh(x)}{(5 \pi^2 + 8 \pi x + 16x^2) \cosh(x)^3}dx$$ You can then integrate by part the second integral $$\int^{\infty}_{-\infty}\left[\frac{\cosh\left(\frac{\pi}{4} \right)}{(5 \pi^2 + 8 \pi x + 16x^2)}-\frac{ 4\sinh\left( \frac{\pi}{4}\right)(\pi+ 4 x)}{(5 \pi^2 + 8 \pi x + 16 x^2)^2}\right]\mathrm{sech}^2(x)\,dx $$ Integrating again $$I=-\int^{\infty}_{-\infty}\left[\frac{(8 (4 x + \pi) (32 x + 8 \pi) \sinh(\pi/4))}{(16 x^2 + 8 \pi x + 5 \pi^2)^3} - \frac{(16 \sinh(\pi/4)}{(16 x^2 + 8 \pi x + 5 \pi^2)^2}\\ - \frac{((32 x + 8 \pi) \cosh(\pi/4)}{(16 x^2 + 8 \pi x + 5 \pi^2)^2} \right]\tanh(x)\,dx$$ Note that $$\tanh(x) = 8  \sum_{k=1}^\infty \frac{x}{(1 - 2 k)^2 \pi^2 + 4 x^2}$$ Consider $R(x)$ a rational function then $$\int^{\infty}_{-\infty}R(x) \tanh(x) = 8  \sum_{k=1}^\infty \int^{\infty}_{-\infty}R(x)\frac{x}{(1 - 2 k)^2 \pi^2 + 4 x^2} \,dx$$ Any integral of that form could be found (I think) using the residue theorem then the resulting sum can be evaluated using the Digamma function. Question Although I think this approach will result in the correct answer I feel that a contour method will be so much easier, any idea ? Maybe there is an easier method considering the nice closed form ?","Prove $$\int_{-\infty}^{\infty}\frac{1}{(5 \pi^2 + 8 \pi x + 16x^2)  }\frac{\cosh\left(x+\frac{\pi}{4} \right)}{\cosh^3(x)}dx =  \frac{2}{\pi^3}\left(\pi \cosh\left(\frac{\pi}{4} \right)-4\sinh\left(  \frac{\pi}{4}\right) \right)$$ Attempt Note that $$\cosh\left( x+\frac{\pi}{4}\right) = \cosh(x)\cosh\left(\frac{\pi}{4} \right)+\sinh(x)\sinh\left( \frac{\pi}{4}\right)$$ Then the integral could be rewritten as $$I = \cosh\left(\frac{\pi}{4} \right)\int_{-\infty}^{\infty}\frac{\mathrm{sech} ^2(x)}{(5 \pi^2 + 8 \pi x + 16x^2) }dx\\+\sinh\left(\frac{\pi}{4} \right)\int_{-\infty}^{\infty}\frac{\sinh(x)}{(5 \pi^2 + 8 \pi x + 16x^2) \cosh(x)^3}dx$$ You can then integrate by part the second integral $$\int^{\infty}_{-\infty}\left[\frac{\cosh\left(\frac{\pi}{4} \right)}{(5 \pi^2 + 8 \pi x + 16x^2)}-\frac{ 4\sinh\left( \frac{\pi}{4}\right)(\pi+ 4 x)}{(5 \pi^2 + 8 \pi x + 16 x^2)^2}\right]\mathrm{sech}^2(x)\,dx $$ Integrating again $$I=-\int^{\infty}_{-\infty}\left[\frac{(8 (4 x + \pi) (32 x + 8 \pi) \sinh(\pi/4))}{(16 x^2 + 8 \pi x + 5 \pi^2)^3} - \frac{(16 \sinh(\pi/4)}{(16 x^2 + 8 \pi x + 5 \pi^2)^2}\\ - \frac{((32 x + 8 \pi) \cosh(\pi/4)}{(16 x^2 + 8 \pi x + 5 \pi^2)^2} \right]\tanh(x)\,dx$$ Note that $$\tanh(x) = 8  \sum_{k=1}^\infty \frac{x}{(1 - 2 k)^2 \pi^2 + 4 x^2}$$ Consider $R(x)$ a rational function then $$\int^{\infty}_{-\infty}R(x) \tanh(x) = 8  \sum_{k=1}^\infty \int^{\infty}_{-\infty}R(x)\frac{x}{(1 - 2 k)^2 \pi^2 + 4 x^2} \,dx$$ Any integral of that form could be found (I think) using the residue theorem then the resulting sum can be evaluated using the Digamma function. Question Although I think this approach will result in the correct answer I feel that a contour method will be so much easier, any idea ? Maybe there is an easier method considering the nice closed form ?",,"['calculus', 'integration', 'definite-integrals', 'contour-integration']"
9,How to calculate $3^{\sqrt{2}}$ with a simple calculator?,How to calculate  with a simple calculator?,3^{\sqrt{2}},"How to calculate $3^{\sqrt{2}}$ with a simple calculator ?. What is a simple calculator here ?: It is a calculator which can only do the $4$ main calculus and radicals $\left(\,\sqrt{}\,\right)$. And it can only show up to seven digits. We want to calculate $3^{\sqrt{2}}$ with this calculator up to $6$ decimals. In the question is written that the question has a nice solution don't find the answer just by using the calculator. What to do here ?. I tried to divid it to a number, multiply, etc$\ldots$ But I can find a good way to calculate it.","How to calculate $3^{\sqrt{2}}$ with a simple calculator ?. What is a simple calculator here ?: It is a calculator which can only do the $4$ main calculus and radicals $\left(\,\sqrt{}\,\right)$. And it can only show up to seven digits. We want to calculate $3^{\sqrt{2}}$ with this calculator up to $6$ decimals. In the question is written that the question has a nice solution don't find the answer just by using the calculator. What to do here ?. I tried to divid it to a number, multiply, etc$\ldots$ But I can find a good way to calculate it.",,"['calculus', 'radicals']"
10,How to deal with misapplying mathematical rules? [closed],How to deal with misapplying mathematical rules? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 8 years ago . Improve this question I have noticed that though I understand the mathematical material in my classes nigh perfectly, I still make frequent careless mistakes. Roughly 55% (95% CI: (37, 72) of these errors are due to me misapplying mathematical rules. For example, I may in a derivation go from $a = 4(c + b)$ to $a = 4c + b$, even though I am aware that $q(r + v) \neq qr + v$ in general. How can I make this misapplication of rules less devastating on tests? I am slow at math, and my tests are fast-paced, so I usually barely have enough time to finish tests when dong several steps at once and not checking my work. This prevents me from using many techniques. It has been suggested to solve problems multiple times in the same way, which I rarely have time to do. It has also been suggested to not do multiple steps in a single line, but again, I seldom have time to do this, and even when I do do it, it only slightly decreases the number of errors I make. The scientific papers I've seen don't help much. I currently keep a journal of errors, but I have found few patterns in them, so I have a hard time determining what errors to check for. It has been suggested to continue practicing, as this will make me eventually improve. However, despite practicing roughly forty hours per week, I have not noticed an improvement other than ones that resulting from me improving my techniques. One way I have succeeded in improving my techniques is by first checking to see if the solution seems correct, for example by seeing if it seems reasonable or plugging the answer to an algebra problem into the original equation. Then, if the answer is incorrect, I go back to the first line in the derivation, cover up the next, determine what the next line should be, look to see if that is what was written, and then repeat this for all lines. The problem with this is that it if time-consuming, which prevents me from finishing the test, and it only prevents roughly half of errors. So, how can I deal with misapplying mathematical rules?","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 8 years ago . Improve this question I have noticed that though I understand the mathematical material in my classes nigh perfectly, I still make frequent careless mistakes. Roughly 55% (95% CI: (37, 72) of these errors are due to me misapplying mathematical rules. For example, I may in a derivation go from $a = 4(c + b)$ to $a = 4c + b$, even though I am aware that $q(r + v) \neq qr + v$ in general. How can I make this misapplication of rules less devastating on tests? I am slow at math, and my tests are fast-paced, so I usually barely have enough time to finish tests when dong several steps at once and not checking my work. This prevents me from using many techniques. It has been suggested to solve problems multiple times in the same way, which I rarely have time to do. It has also been suggested to not do multiple steps in a single line, but again, I seldom have time to do this, and even when I do do it, it only slightly decreases the number of errors I make. The scientific papers I've seen don't help much. I currently keep a journal of errors, but I have found few patterns in them, so I have a hard time determining what errors to check for. It has been suggested to continue practicing, as this will make me eventually improve. However, despite practicing roughly forty hours per week, I have not noticed an improvement other than ones that resulting from me improving my techniques. One way I have succeeded in improving my techniques is by first checking to see if the solution seems correct, for example by seeing if it seems reasonable or plugging the answer to an algebra problem into the original equation. Then, if the answer is incorrect, I go back to the first line in the derivation, cover up the next, determine what the next line should be, look to see if that is what was written, and then repeat this for all lines. The problem with this is that it if time-consuming, which prevents me from finishing the test, and it only prevents roughly half of errors. So, how can I deal with misapplying mathematical rules?",,"['calculus', 'linear-algebra', 'algebra-precalculus', 'soft-question']"
11,How to prove $(\frac 1n)^n+(\frac 2n)^n+\cdots+(\frac nn)^n\geqslant\frac{3n+1}{2n+2}$,How to prove,(\frac 1n)^n+(\frac 2n)^n+\cdots+(\frac nn)^n\geqslant\frac{3n+1}{2n+2},"How to prove $$   \Bigl(\dfrac 1n\Bigr)^n + \Bigl(\frac 2n\Bigr)^n + \cdots +    \Bigl(\frac nn\Bigr)^n \geqslant \frac{3n+1}{2n+2}  \qquad (n\in\mathbb{N}) $$ I tried: let $f(x)=x^n$ and $f''(x)\geqslant 0$ for $n>1$, let $x_i=\frac in$, and we have $$   \sum f(x_i)\geqslant nf\biggl(\frac{\sum x_i}{n}\biggr). $$ But the $RHS<\dfrac{3n+1}{2n+2}$. So it doesn't work. Could someone give me a neat proof? Thanks!","How to prove $$   \Bigl(\dfrac 1n\Bigr)^n + \Bigl(\frac 2n\Bigr)^n + \cdots +    \Bigl(\frac nn\Bigr)^n \geqslant \frac{3n+1}{2n+2}  \qquad (n\in\mathbb{N}) $$ I tried: let $f(x)=x^n$ and $f''(x)\geqslant 0$ for $n>1$, let $x_i=\frac in$, and we have $$   \sum f(x_i)\geqslant nf\biggl(\frac{\sum x_i}{n}\biggr). $$ But the $RHS<\dfrac{3n+1}{2n+2}$. So it doesn't work. Could someone give me a neat proof? Thanks!",,"['calculus', 'sequences-and-series', 'inequality']"
12,Is there a geometric interpretation of the product integral?,Is there a geometric interpretation of the product integral?,,"Riemann's ""way to the Integral"" is loosely speaking the limit of sums of this kind \begin{equation} \sum_if(x_i)\Delta x_i \end{equation} Now, if we replace the sum with a product and the multiplication by $\Delta x_i$ with exponentiation, we are led to the idea of a ""product"" integral: \begin{equation} \prod_if(x_i)^{\Delta x_i} \end{equation} The relation with the usual integral and the ""product"" integral is the following: \begin{equation} \prod f(x)^{dx}=\ e^{\int \ln f(x) dx} \end{equation} My question is: is there a geometrical (or measure-theoretical) interpretation of the product integral? As we all know the usual integral (in one variable) is the signed area under the graph of $f$.","Riemann's ""way to the Integral"" is loosely speaking the limit of sums of this kind \begin{equation} \sum_if(x_i)\Delta x_i \end{equation} Now, if we replace the sum with a product and the multiplication by $\Delta x_i$ with exponentiation, we are led to the idea of a ""product"" integral: \begin{equation} \prod_if(x_i)^{\Delta x_i} \end{equation} The relation with the usual integral and the ""product"" integral is the following: \begin{equation} \prod f(x)^{dx}=\ e^{\int \ln f(x) dx} \end{equation} My question is: is there a geometrical (or measure-theoretical) interpretation of the product integral? As we all know the usual integral (in one variable) is the signed area under the graph of $f$.",,"['calculus', 'integration', 'products']"
13,How can I prove the convergence of a power-tower? [duplicate],How can I prove the convergence of a power-tower? [duplicate],,"This question already has answers here : Convergence of tetration sequence. (2 answers) Closed 9 years ago . In here, I saw that $$x^{x^{x^{x^{x^{x^{x^{.{^{.^{.}}}}}}}}}}$$ exists as a real number (convergent) if and only if $$x\in[e^{-e}, e^\frac{1}{e}].$$ How can I prove this??","This question already has answers here : Convergence of tetration sequence. (2 answers) Closed 9 years ago . In here, I saw that $$x^{x^{x^{x^{x^{x^{x^{.{^{.^{.}}}}}}}}}}$$ exists as a real number (convergent) if and only if $$x\in[e^{-e}, e^\frac{1}{e}].$$ How can I prove this??",,"['calculus', 'convergence-divergence']"
14,"Closed-form of $\int_0^{\pi/2}\frac{\sin^2x\arctan\left(\cos^2x\right)}{\sin^4x+\cos^4x}\,dx$",Closed-form of,"\int_0^{\pi/2}\frac{\sin^2x\arctan\left(\cos^2x\right)}{\sin^4x+\cos^4x}\,dx","I have just seen two active posts about integrals of inverse trigonometric function, $\arctan(x)$, here on MSE. So I decide to post this question. This integral comes from a friend of mine (it's not a homework problem) and we have tried to evaluate it but no success so far. I have discussed it in chatroom with @ Chris'ssis but she gave me a horrible closed-form without proof. You may have a look here and here . My friend doesn't know the closed-form either. Here is the problem: $$\int_0^{\pi/2}\frac{\sin^2x\arctan\left(\cos^2x\right)}{\sin^4x+\cos^4x}\,dx$$ Any idea? Any help would be appreciated. Thanks in advance.","I have just seen two active posts about integrals of inverse trigonometric function, $\arctan(x)$, here on MSE. So I decide to post this question. This integral comes from a friend of mine (it's not a homework problem) and we have tried to evaluate it but no success so far. I have discussed it in chatroom with @ Chris'ssis but she gave me a horrible closed-form without proof. You may have a look here and here . My friend doesn't know the closed-form either. Here is the problem: $$\int_0^{\pi/2}\frac{\sin^2x\arctan\left(\cos^2x\right)}{\sin^4x+\cos^4x}\,dx$$ Any idea? Any help would be appreciated. Thanks in advance.",,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'closed-form']"
15,"How to find closed-form of $\int_{0}^{+\infty} \operatorname{sech}^2 (x^2)\,dx$",How to find closed-form of,"\int_{0}^{+\infty} \operatorname{sech}^2 (x^2)\,dx","How to find this integral closed form: $$I=\int_{0}^{+\infty}\operatorname{sech}^2{(x^2)}\,dx$$ where $\operatorname{sech}{(x)}$ is defined as secant of hyperbolic function . This problem form is very simple and it's interesting problem, but I use computer to help me to find its closed-form and W|A turns its numerical result $$I=\int_{0}^{+\infty}\operatorname{sech}^2{(x^2)}\,dx\approx 0.952781\ldots$$ Thank you for your help.","How to find this integral closed form: where is defined as secant of hyperbolic function . This problem form is very simple and it's interesting problem, but I use computer to help me to find its closed-form and W|A turns its numerical result Thank you for your help.","I=\int_{0}^{+\infty}\operatorname{sech}^2{(x^2)}\,dx \operatorname{sech}{(x)} I=\int_{0}^{+\infty}\operatorname{sech}^2{(x^2)}\,dx\approx 0.952781\ldots","['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
16,Humorous integration example?,Humorous integration example?,,"I was just reading though an introductory calculus book and it has the note: NOTE When integrating quotients, do not integrate the numerator and denominator separately. This is no more valid in integration than it is in differentiation. Now that's fair enough to point out and it gives a nice example too. But out of curiosity... Are there examples of functions $f ,g: \Bbb R \rightarrow \Bbb R $ whereby: $\int \frac {f}{g} =\frac {\int f}{\int g}$. Say for clarity you have a choice of the constants in the  antiderivatives, and $f \not\equiv 0$. I imagine it might possibly be easier if you choose definite integrals, just none spring to mind! Maybe there's a link to a similar question on here?","I was just reading though an introductory calculus book and it has the note: NOTE When integrating quotients, do not integrate the numerator and denominator separately. This is no more valid in integration than it is in differentiation. Now that's fair enough to point out and it gives a nice example too. But out of curiosity... Are there examples of functions $f ,g: \Bbb R \rightarrow \Bbb R $ whereby: $\int \frac {f}{g} =\frac {\int f}{\int g}$. Say for clarity you have a choice of the constants in the  antiderivatives, and $f \not\equiv 0$. I imagine it might possibly be easier if you choose definite integrals, just none spring to mind! Maybe there's a link to a similar question on here?",,"['calculus', 'integration', 'soft-question', 'examples-counterexamples']"
17,What is the difference between diffeomorphism and isomorphism?,What is the difference between diffeomorphism and isomorphism?,,"What is the difference between diffeomorphisms and isomorphisms? I know isomorphisms already from my abstract algebra/group theory course, and now I'm studying analysis on (sub)manifolds, where this definition is new for me. Can anybody explain what the difference between the two is? Or in other words: how can I relate those two concepts? Thanks :)","What is the difference between diffeomorphisms and isomorphisms? I know isomorphisms already from my abstract algebra/group theory course, and now I'm studying analysis on (sub)manifolds, where this definition is new for me. Can anybody explain what the difference between the two is? Or in other words: how can I relate those two concepts? Thanks :)",,"['calculus', 'abstract-algebra', 'analysis']"
18,Solve $f(x)=\int_{x-1}^{x+1} f(t) \text{d}t$,Solve,f(x)=\int_{x-1}^{x+1} f(t) \text{d}t,"Solve $f(x)=\int_{x-1}^{x+1} f(t) \text{d}t$. We know that $f(x)=0$ is a solution, are there any other solutions? I suppose I can start with $f(x)=\frac{dg(x)}{dx}$, and then: $$\begin{align*} \frac{dg(x)}{dx}&=\int_{x-1}^{x+1} \frac{dg(t)}{dt} dt \\ \frac{dg(x)}{dx}&=g(x+1)-g(x-1) \\ \end{align*}$$ But then I'm stuck.","Solve $f(x)=\int_{x-1}^{x+1} f(t) \text{d}t$. We know that $f(x)=0$ is a solution, are there any other solutions? I suppose I can start with $f(x)=\frac{dg(x)}{dx}$, and then: $$\begin{align*} \frac{dg(x)}{dx}&=\int_{x-1}^{x+1} \frac{dg(t)}{dt} dt \\ \frac{dg(x)}{dx}&=g(x+1)-g(x-1) \\ \end{align*}$$ But then I'm stuck.",,"['calculus', 'integration']"
19,Funny integral inequality [closed],Funny integral inequality [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Assume $f(x) \in C^1([0,1])$,and $\int_0^{\frac{1}{2}}f(x)\text{d}x=0$,show that: $$\left(\int_0^1f(x)\text{d}x\right)^2 \leq \frac{1}{12}\int_0^1[f'(x)]^2\text{d}x$$ and how to find the smallest constant $C$ which satisfies  $$\left(\int_0^1f(x)\text{d}x\right)^2 \leq C\int_0^1[f'(x)]^2\text{d}x$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Assume $f(x) \in C^1([0,1])$,and $\int_0^{\frac{1}{2}}f(x)\text{d}x=0$,show that: $$\left(\int_0^1f(x)\text{d}x\right)^2 \leq \frac{1}{12}\int_0^1[f'(x)]^2\text{d}x$$ and how to find the smallest constant $C$ which satisfies  $$\left(\int_0^1f(x)\text{d}x\right)^2 \leq C\int_0^1[f'(x)]^2\text{d}x$$",,"['calculus', 'integration', 'inequality']"
20,Why does gradient descent work?,Why does gradient descent work?,,"On Wikipedia, this is the following description of gradient descent: Gradient descent is based on the observation that if the multivariable function $F(\mathbf{x})$ is defined and differentiable in a neighborhood of a point $\mathbf{a}$, then $F(\mathbf{x})$ decreases fastest if one goes from $\mathbf{a}$ in the direction of the negative gradient of $F$ at $\mathbf{a}$. Now I have several doubts in this description. First of all I have an example of $f(x)=x^2$ in my mind and my starting point is, say, $x=5$. What is the meaning of ""decreases fastest""? I mean, I can go straight from $x=5$ to $x=0$ (which is minimum point), then what's the point of fastest decrease? What is the notion of fast here? Where did this observation come from? I didn't see the proof of this observation.","On Wikipedia, this is the following description of gradient descent: Gradient descent is based on the observation that if the multivariable function $F(\mathbf{x})$ is defined and differentiable in a neighborhood of a point $\mathbf{a}$, then $F(\mathbf{x})$ decreases fastest if one goes from $\mathbf{a}$ in the direction of the negative gradient of $F$ at $\mathbf{a}$. Now I have several doubts in this description. First of all I have an example of $f(x)=x^2$ in my mind and my starting point is, say, $x=5$. What is the meaning of ""decreases fastest""? I mean, I can go straight from $x=5$ to $x=0$ (which is minimum point), then what's the point of fastest decrease? What is the notion of fast here? Where did this observation come from? I didn't see the proof of this observation.",,"['calculus', 'optimization', 'intuition', 'numerical-optimization', 'gradient-descent']"
21,"Integrating $\int\nolimits_0^{\infty}{\frac{e^{-ax}-e^{-bx}}{x}\sin{mx} \, dx} \quad (a > 0 \, , b >0)$",Integrating,"\int\nolimits_0^{\infty}{\frac{e^{-ax}-e^{-bx}}{x}\sin{mx} \, dx} \quad (a > 0 \, , b >0)","I have this integral $$\int\nolimits_0^{\infty}{\frac{e^{-ax}-e^{-bx}}{x}\sin{mx} \, dx} \quad (a > 0 \, , b >0)$$ What I did was this $$ \begin{align} \int_0^{\infty}{\frac{e^{-ax}-e^{-bx}}{x}\sin{(mx)} \, dx} &= \int_0^{\infty}{\left[\int_a^b{e^{-xy} \, dy}\right]\sin{(mx)} \, dx}\\ &= \int_a^b{\left[\int_0^{\infty}{e^{-xy}\sin{(mx)} \, dx}\right] \, dy}\\ &= \int_a^b{\frac{m}{m^2+y^2} \, dy}\\ &= \tan^{-1}\left(\frac{b}{m}\right) - \tan^{-1}\left(\frac{a}{m}\right) \end{align}$$ So my first question is. Is this procedure ok? Also the book suggests to use parametric differentiation to solve this, but I don't see how to apply it in here, so my second question would be. How can I use parametric differentiation to solve this integral? Any help is appreciated, thanks.","I have this integral $$\int\nolimits_0^{\infty}{\frac{e^{-ax}-e^{-bx}}{x}\sin{mx} \, dx} \quad (a > 0 \, , b >0)$$ What I did was this $$ \begin{align} \int_0^{\infty}{\frac{e^{-ax}-e^{-bx}}{x}\sin{(mx)} \, dx} &= \int_0^{\infty}{\left[\int_a^b{e^{-xy} \, dy}\right]\sin{(mx)} \, dx}\\ &= \int_a^b{\left[\int_0^{\infty}{e^{-xy}\sin{(mx)} \, dx}\right] \, dy}\\ &= \int_a^b{\frac{m}{m^2+y^2} \, dy}\\ &= \tan^{-1}\left(\frac{b}{m}\right) - \tan^{-1}\left(\frac{a}{m}\right) \end{align}$$ So my first question is. Is this procedure ok? Also the book suggests to use parametric differentiation to solve this, but I don't see how to apply it in here, so my second question would be. How can I use parametric differentiation to solve this integral? Any help is appreciated, thanks.",,"['calculus', 'integration']"
22,How to find the solution to $4^x + 9^x = 4?$,How to find the solution to,4^x + 9^x = 4?,"I tried to solve this equation algebraically but couldn't. Maybe there isn't a way to extract the solution from the equation algebraically. If it's the latter, I'd really like to know why. Also, is there a general solution to equations with the form $a^x + b^x = c$ where $a, b,$ and $c$ are all different real numbers? Thanks.","I tried to solve this equation algebraically but couldn't. Maybe there isn't a way to extract the solution from the equation algebraically. If it's the latter, I'd really like to know why. Also, is there a general solution to equations with the form where and are all different real numbers? Thanks.","a^x + b^x = c a, b, c","['calculus', 'algebra-precalculus']"
23,An integral involving a smooth function,An integral involving a smooth function,,"Let $f : [0,1] \to \mathbb [0,1]$ be a smooth function (class $C^\infty$) that is not necessarily real-analytic. Let $g : (-1, \infty) \to \mathbb R$ be the function defined by $g(x) = \int_0^1 f(t) \, t^x dt$. Is $g$ necessarily a real-analytic function on $(-1, \infty)$?","Let $f : [0,1] \to \mathbb [0,1]$ be a smooth function (class $C^\infty$) that is not necessarily real-analytic. Let $g : (-1, \infty) \to \mathbb R$ be the function defined by $g(x) = \int_0^1 f(t) \, t^x dt$. Is $g$ necessarily a real-analytic function on $(-1, \infty)$?",,"['calculus', 'analyticity', 'analytic-functions']"
24,Derivative of a square matrix to a power,Derivative of a square matrix to a power,,"Suppose I have a function $f(x) = A^n$ where $A$ is a square matrix, $x$ is a positive real scalar, and $n$ is a natural number. I would like to calculate the derivative of $f$ with respect to $x$ (each entry in $A$ is a function of $x$). Is there a simple formula for this in general or do I need to know what $n$ is and use the product rule? I found this , but I don't understand it (in particular I don't understand what $DS(A)$ or $S(A)$ means). edit: Each entry in $A$ is differentiable.","Suppose I have a function $f(x) = A^n$ where $A$ is a square matrix, $x$ is a positive real scalar, and $n$ is a natural number. I would like to calculate the derivative of $f$ with respect to $x$ (each entry in $A$ is a function of $x$). Is there a simple formula for this in general or do I need to know what $n$ is and use the product rule? I found this , but I don't understand it (in particular I don't understand what $DS(A)$ or $S(A)$ means). edit: Each entry in $A$ is differentiable.",,"['calculus', 'matrices', 'derivatives', 'matrix-calculus']"
25,Using Rolle's Theorem to prove roots.,Using Rolle's Theorem to prove roots.,,"Show that $x^5+10x+3=0$ has exactly one real solution using Rolle's Theorem. I am referencing a closely related stack answer here .  So I have tried letting $y=x^5+10x+3$. Then $y'=5x^4+10$. Set $y'=0$ $$0=5x^4+10$$ $f$ is continuous on $\mathbb{R}$ and $f$ is differentiable on $\mathbb{R}$ but I need a closed interval $[a.b]$ of continuity that corresponds to an open interval $(a,b)$ of differentiation. Where $f(a)=f(b)$. I do not see any real solution such as they were able to find in the provided link. As well as I do not see how to satisfy $f(a)=f(b)$. Any help and explanation is appreciated!","Show that $x^5+10x+3=0$ has exactly one real solution using Rolle's Theorem. I am referencing a closely related stack answer here .  So I have tried letting $y=x^5+10x+3$. Then $y'=5x^4+10$. Set $y'=0$ $$0=5x^4+10$$ $f$ is continuous on $\mathbb{R}$ and $f$ is differentiable on $\mathbb{R}$ but I need a closed interval $[a.b]$ of continuity that corresponds to an open interval $(a,b)$ of differentiation. Where $f(a)=f(b)$. I do not see any real solution such as they were able to find in the provided link. As well as I do not see how to satisfy $f(a)=f(b)$. Any help and explanation is appreciated!",,"['calculus', 'derivatives', 'roots', 'rolles-theorem']"
26,Limit of the sequence $\left(\sum_{k=0}^n f\!\left(\frac{k}{n^2}\right)\right)_n$.,Limit of the sequence .,\left(\sum_{k=0}^n f\!\left(\frac{k}{n^2}\right)\right)_n,"Following this post on Meta , I am going to regularly ask questions from competitive mathematics exams, on a variety of topics; and provide a solution a few days later. The goal is not only to list interesting (I hope) exercises for the sake of self-study, but also to obtain (again, hopefully) a variety of techniques to solve them. Let $f\colon\mathbb{R}\to\mathbb{R}$ be differentiable at $0$ , and such that $f(0)=0$ . Letting $s_n\stackrel{\rm def}{=} \sum_{k=1}^n f\!\left(\frac{k}{n^2}\right)$ for $n\geq 1$ , find the limit of the sequence $(s_n)_{n\geq 1}$ . Reference: Exercise 4.26 in Exercices de mathématiques: oraux X-ENS (Analyse I) , by Francinou, Gianella, and Nicolas (2014) ISBN 978-2842252137.","Following this post on Meta , I am going to regularly ask questions from competitive mathematics exams, on a variety of topics; and provide a solution a few days later. The goal is not only to list interesting (I hope) exercises for the sake of self-study, but also to obtain (again, hopefully) a variety of techniques to solve them. Let be differentiable at , and such that . Letting for , find the limit of the sequence . Reference: Exercise 4.26 in Exercices de mathématiques: oraux X-ENS (Analyse I) , by Francinou, Gianella, and Nicolas (2014) ISBN 978-2842252137.",f\colon\mathbb{R}\to\mathbb{R} 0 f(0)=0 s_n\stackrel{\rm def}{=} \sum_{k=1}^n f\!\left(\frac{k}{n^2}\right) n\geq 1 (s_n)_{n\geq 1},"['calculus', 'sequences-and-series']"
27,Why are the coefficients of the equation of a plane the normal vector of a plane?,Why are the coefficients of the equation of a plane the normal vector of a plane?,,"Why are the coefficients of the equation of a plane the normal vector of a plane? I borrowed the below picture from Pauls Online Calculus 3 notes: http://tutorial.math.lamar.edu/Classes/CalcIII/EqnsOfPlanes.aspx And I think the explanation he provides is great, however, I don't understand how one of the concepts work. If the equation of a plane is $ax+by+cz=d$ how is it that $\overrightarrow n = \langle a,b,c \rangle$?  From the picture below I suppose I can see this since $\overrightarrow r_0$, if continued past the plane, would clearly be perpendicular, but what about $\overrightarrow r$?  That one is clearly not perpendicular if extended past the plane? Sorry if what I'm asking is confusing.","Why are the coefficients of the equation of a plane the normal vector of a plane? I borrowed the below picture from Pauls Online Calculus 3 notes: http://tutorial.math.lamar.edu/Classes/CalcIII/EqnsOfPlanes.aspx And I think the explanation he provides is great, however, I don't understand how one of the concepts work. If the equation of a plane is $ax+by+cz=d$ how is it that $\overrightarrow n = \langle a,b,c \rangle$?  From the picture below I suppose I can see this since $\overrightarrow r_0$, if continued past the plane, would clearly be perpendicular, but what about $\overrightarrow r$?  That one is clearly not perpendicular if extended past the plane? Sorry if what I'm asking is confusing.",,"['calculus', 'multivariable-calculus', 'vectors', 'plane-geometry']"
28,How to find the maximum and minimum value of $2^{\sin x}+2^{\cos x}$,How to find the maximum and minimum value of,2^{\sin x}+2^{\cos x},"My try: Let $y$ =  $2^{\sin x}+2^{\cos x}$ Applying AM GM inequality I get  $y$ $> 2.2^{(\sin x+\cos x)/2}$.  Now, the highest value of R.H.S is $2^{\frac{\left(2+\sqrt{2}\right)}{2}}$. Should this mean that $y$ is always greater than $2^{\frac{ \left ( 2+\sqrt{2}\right ) }{2}}$? But this is not true (we can see in the graph). Calculus method: $dy/dx$ = $\ln\left(2\right){\cdot}{2}^{\sin\left(x\right)}\cos\left(x\right){-\ln\left(2\right){\cdot}{2}^{\cos\left(x\right)}\sin\left(x\right)}$ When $dy/dx$ =0, $\tan x = 2^{\sin x- \cos x}$ and I am stuck here. https://www.desmos.com/calculator/p3zfvkq2mn","My try: Let $y$ =  $2^{\sin x}+2^{\cos x}$ Applying AM GM inequality I get  $y$ $> 2.2^{(\sin x+\cos x)/2}$.  Now, the highest value of R.H.S is $2^{\frac{\left(2+\sqrt{2}\right)}{2}}$. Should this mean that $y$ is always greater than $2^{\frac{ \left ( 2+\sqrt{2}\right ) }{2}}$? But this is not true (we can see in the graph). Calculus method: $dy/dx$ = $\ln\left(2\right){\cdot}{2}^{\sin\left(x\right)}\cos\left(x\right){-\ln\left(2\right){\cdot}{2}^{\cos\left(x\right)}\sin\left(x\right)}$ When $dy/dx$ =0, $\tan x = 2^{\sin x- \cos x}$ and I am stuck here. https://www.desmos.com/calculator/p3zfvkq2mn",,"['calculus', 'trigonometry']"
29,Single Variable Calculus Reference Recommendations,Single Variable Calculus Reference Recommendations,,"This question is a generalization of the common question asking for calculus references. It is here to abstract away the repetition, and give a canonical resource for calculus references. I'm looking for a resources to learn single-variable calculus.","This question is a generalization of the common question asking for calculus references. It is here to abstract away the repetition, and give a canonical resource for calculus references. I'm looking for a resources to learn single-variable calculus.",,"['calculus', 'reference-request', 'book-recommendation', 'faq']"
30,Notation regarding different derivatives,Notation regarding different derivatives,,"I am currently reading up on partial derivatives and differentials in general. And there are a few points that seem unlcear to me (notation-wise). For example, if $f:\mathbb R\to\mathbb R,x\mapsto f(x)$ is a function, then is the following notation correct? $$\frac{d}{dx}f(x)=\frac{df}{dx}(x)=\frac{\partial}{\partial x}f(x)=\frac{\partial f}{\partial x}(x)=f'(x)$$ Now, in one of my lectures we wrote $$g(x):=\frac{\partial \log (f(x))}{\partial x}=\log'f(x)\cdot f'(x)=f'(x)/f(x)$$ The part about differentiating the function  is clear, using the normal chain rule $(h\circ f)=(h'\circ f)\cdot f'$. What  confuses me a bit is the notation since $x$ seems to have more than one meaning. Would it be ""more"" correct to write $$g(x):=\frac{\partial \log (f(y))}{\partial y}\Bigg|_{y=x}$$ as in we differentiate w.r.t. $y$ and then plug in $x$ for $y$? Also, in this particular case, could we replace $\partial$ by $d$, or would this lead to different implications? And lastly, what does $df$ or $dy$ even mean? I read that the differential of $y=f(x)$ is defined to be $dy=f'(x)dx$. But how can we interpret this formula? This becomes specifically confusing when I look at the differential chain rule $$\frac{dh}{df}=\frac{dh}{dg}\cdot\frac{dg}{df}$$ What I find strange is that one seems to be using $g$ as a function as well as a variable. How does this work exactly?","I am currently reading up on partial derivatives and differentials in general. And there are a few points that seem unlcear to me (notation-wise). For example, if $f:\mathbb R\to\mathbb R,x\mapsto f(x)$ is a function, then is the following notation correct? $$\frac{d}{dx}f(x)=\frac{df}{dx}(x)=\frac{\partial}{\partial x}f(x)=\frac{\partial f}{\partial x}(x)=f'(x)$$ Now, in one of my lectures we wrote $$g(x):=\frac{\partial \log (f(x))}{\partial x}=\log'f(x)\cdot f'(x)=f'(x)/f(x)$$ The part about differentiating the function  is clear, using the normal chain rule $(h\circ f)=(h'\circ f)\cdot f'$. What  confuses me a bit is the notation since $x$ seems to have more than one meaning. Would it be ""more"" correct to write $$g(x):=\frac{\partial \log (f(y))}{\partial y}\Bigg|_{y=x}$$ as in we differentiate w.r.t. $y$ and then plug in $x$ for $y$? Also, in this particular case, could we replace $\partial$ by $d$, or would this lead to different implications? And lastly, what does $df$ or $dy$ even mean? I read that the differential of $y=f(x)$ is defined to be $dy=f'(x)dx$. But how can we interpret this formula? This becomes specifically confusing when I look at the differential chain rule $$\frac{dh}{df}=\frac{dh}{dg}\cdot\frac{dg}{df}$$ What I find strange is that one seems to be using $g$ as a function as well as a variable. How does this work exactly?",,"['calculus', 'derivatives', 'notation', 'partial-derivative', 'differential']"
31,Irrational numbers and Borel Sets,Irrational numbers and Borel Sets,,"Is the set of all irrational numbers in [0; 1] a Borel set? If yes, what is its Lebesgue measure? I have been trying to answer this for a long time now. I know that the set of rational numbers is infinitely countable but I am having trouble with the proof of this question. I am not necessarily looking for an answer just confirmation that I am doing the correct thing. I have already tried the following: The set of rationals is countable between 0 and 1 and is therefore a Borel Set. Since it is countable its lebesgue measure is 0","Is the set of all irrational numbers in [0; 1] a Borel set? If yes, what is its Lebesgue measure? I have been trying to answer this for a long time now. I know that the set of rational numbers is infinitely countable but I am having trouble with the proof of this question. I am not necessarily looking for an answer just confirmation that I am doing the correct thing. I have already tried the following: The set of rationals is countable between 0 and 1 and is therefore a Borel Set. Since it is countable its lebesgue measure is 0",,"['calculus', 'probability']"
32,"Another math contest problem: $\int_0^{\frac{\ln^22}4}\,\frac{\arccos\frac{\exp\sqrt x}{\sqrt2}}{1-\exp\sqrt{4\,x}}dx$",Another math contest problem:,"\int_0^{\frac{\ln^22}4}\,\frac{\arccos\frac{\exp\sqrt x}{\sqrt2}}{1-\exp\sqrt{4\,x}}dx","Prove:   $$ {\Large\int_{0}^{\ln^{2}\left(2\right) \over4}}\, \frac{\arccos\left(\vphantom{\huge A} {\exp\left(\vphantom{\large A}\sqrt{x\,}\right) \over \sqrt{\vphantom{\large A}2\,}}\right)} {1-\exp\left(\sqrt{4x\,}\,\right)} \,{\rm d}x = -\,\frac{\,\,\pi^{3}}{192} $$ I haven't solved it yet.","Prove:   $$ {\Large\int_{0}^{\ln^{2}\left(2\right) \over4}}\, \frac{\arccos\left(\vphantom{\huge A} {\exp\left(\vphantom{\large A}\sqrt{x\,}\right) \over \sqrt{\vphantom{\large A}2\,}}\right)} {1-\exp\left(\sqrt{4x\,}\,\right)} \,{\rm d}x = -\,\frac{\,\,\pi^{3}}{192} $$ I haven't solved it yet.",,"['calculus', 'integration', 'trigonometry', 'contest-math', 'closed-form']"
33,does $\intop_{1}^{\infty}x\sin(x^{3})dx$ really converge?,does  really converge?,\intop_{1}^{\infty}x\sin(x^{3})dx,"I'm trying to find a continuous function $f(x)$ on $[0,\infty)$ such that:  $\intop_{1}^{\infty}f(x)dx$ converges while $f(x)$ isn't bounded. I came up with  $f(x)=x\sin(x^{3})dx$, as a function which oscillates like crazy when x tends to infinity, and much faster than x, which is the direction IMO. Wolfram says it converges, and plugging big numbers shows Cauchy's criterion holds, but I wasn't able to rigorously prove the convergence. A few questions: Is there a ""nice"" way of showing this integral converges? (general question) is Wolfram's numeric approximation always positive? is the claim actually true (there exists a function which has an improper integral but isn't bounded)? Many thanks!","I'm trying to find a continuous function $f(x)$ on $[0,\infty)$ such that:  $\intop_{1}^{\infty}f(x)dx$ converges while $f(x)$ isn't bounded. I came up with  $f(x)=x\sin(x^{3})dx$, as a function which oscillates like crazy when x tends to infinity, and much faster than x, which is the direction IMO. Wolfram says it converges, and plugging big numbers shows Cauchy's criterion holds, but I wasn't able to rigorously prove the convergence. A few questions: Is there a ""nice"" way of showing this integral converges? (general question) is Wolfram's numeric approximation always positive? is the claim actually true (there exists a function which has an improper integral but isn't bounded)? Many thanks!",,"['calculus', 'improper-integrals']"
34,Necessary and sufficient conditions for differentiability.,Necessary and sufficient conditions for differentiability.,,"Apologizes if I'm missing something in my question or if my question seems trivial; this is my first question on this site. As motivation for my question, consider the following standard first year calculus question. Consider this piecewise function:   $    f(x) = \left\{      \begin{array}{lr}        ax^2+b & \text{ if } x \le-2\\        12x-5 & \text{ if } x >-2      \end{array}    \right. $ For what values of $a$ and $b$ will $f(x)$ be differentiable? To solve this question, I would like to propose the following theorem: $\mathbf{Theorem:}$ A function $f(x)$ is differentiable iff $f'(x)$ is continuous. If this theorem is true, then I can solve for $a$ first by noting that: $    f'(x) = \left\{      \begin{array}{lr}        2ax & \text{ if } x \le-2\\        12 & \text{ if } x >-2      \end{array}    \right. $ Thus, since by my theorem $f'(x)$ must be continuous, we have: $$\begin{align*} \lim_{x \rightarrow -2^-}f'(x) &= \lim_{x \rightarrow -2^+}f'(x)\\ \lim_{x \rightarrow -2^-}2ax &= \lim_{x \rightarrow -2^+}12\\ 2a(-2) &= 12\\ -4a &= 12 \\ a &= -3 \\ \end{align*}$$ Hence, since differentiability implies continuity, we can solve for $b$ as follows: $$\begin{align*} \lim_{x \rightarrow -2^-}f(x) &= \lim_{x \rightarrow -2^+}f(x)\\ \lim_{x \rightarrow -2^-}-3x^2+b &= \lim_{x \rightarrow -2^+}12x-5\\ -3(-2)^2+b &= 12(-2)-5\\ b-12 &= -29\\ b &= -17 \\ \end{align*}$$ so that our differentiable function is: $$    f(x) = \left\{      \begin{array}{lr}        -3x^2-17 & \text{ if } x \le-2\\        12x-5 & \text{ if } x >-2      \end{array}    \right. $$ Anyways. My question is: Is my proposed theorem actually a thing? I've looked through my calculus textbook and it doesn't seem to explicitly state it, yet I don't know how to solve this question otherwise. If this theorem turns out to be false, how else can you solve this problem? Thanks in advance. =]","Apologizes if I'm missing something in my question or if my question seems trivial; this is my first question on this site. As motivation for my question, consider the following standard first year calculus question. Consider this piecewise function:   $    f(x) = \left\{      \begin{array}{lr}        ax^2+b & \text{ if } x \le-2\\        12x-5 & \text{ if } x >-2      \end{array}    \right. $ For what values of $a$ and $b$ will $f(x)$ be differentiable? To solve this question, I would like to propose the following theorem: $\mathbf{Theorem:}$ A function $f(x)$ is differentiable iff $f'(x)$ is continuous. If this theorem is true, then I can solve for $a$ first by noting that: $    f'(x) = \left\{      \begin{array}{lr}        2ax & \text{ if } x \le-2\\        12 & \text{ if } x >-2      \end{array}    \right. $ Thus, since by my theorem $f'(x)$ must be continuous, we have: $$\begin{align*} \lim_{x \rightarrow -2^-}f'(x) &= \lim_{x \rightarrow -2^+}f'(x)\\ \lim_{x \rightarrow -2^-}2ax &= \lim_{x \rightarrow -2^+}12\\ 2a(-2) &= 12\\ -4a &= 12 \\ a &= -3 \\ \end{align*}$$ Hence, since differentiability implies continuity, we can solve for $b$ as follows: $$\begin{align*} \lim_{x \rightarrow -2^-}f(x) &= \lim_{x \rightarrow -2^+}f(x)\\ \lim_{x \rightarrow -2^-}-3x^2+b &= \lim_{x \rightarrow -2^+}12x-5\\ -3(-2)^2+b &= 12(-2)-5\\ b-12 &= -29\\ b &= -17 \\ \end{align*}$$ so that our differentiable function is: $$    f(x) = \left\{      \begin{array}{lr}        -3x^2-17 & \text{ if } x \le-2\\        12x-5 & \text{ if } x >-2      \end{array}    \right. $$ Anyways. My question is: Is my proposed theorem actually a thing? I've looked through my calculus textbook and it doesn't seem to explicitly state it, yet I don't know how to solve this question otherwise. If this theorem turns out to be false, how else can you solve this problem? Thanks in advance. =]",,"['calculus', 'continuity']"
35,A $\log$ integral with a parameter,A  integral with a parameter,\log,"Prove that:  $$\int_0^\infty \frac{\ln x}{x^a+1}\;\text{d}x=-\left( \frac{\pi }{a} \right)\cot \left( \frac{\pi }{a} \right)\csc \left( \frac{\pi }{a} \right),\ \ a>1$$ For this one I consider to have $\displaystyle\int_0^\infty \ln x\int_0^\infty \text{e}^{-y(1+x^a)} \, \text{d}y \, \text{d}x$. And use $\displaystyle{\Gamma}'(s)=\int_0^\infty \ln(x) x^{s-1} \text{e}^{-x} \, \text{d}x$, but then I just stuck...","Prove that:  $$\int_0^\infty \frac{\ln x}{x^a+1}\;\text{d}x=-\left( \frac{\pi }{a} \right)\cot \left( \frac{\pi }{a} \right)\csc \left( \frac{\pi }{a} \right),\ \ a>1$$ For this one I consider to have $\displaystyle\int_0^\infty \ln x\int_0^\infty \text{e}^{-y(1+x^a)} \, \text{d}y \, \text{d}x$. And use $\displaystyle{\Gamma}'(s)=\int_0^\infty \ln(x) x^{s-1} \text{e}^{-x} \, \text{d}x$, but then I just stuck...",,"['calculus', 'sequences-and-series', 'integration', 'improper-integrals', 'gamma-function']"
36,Show $\frac{d}{dx} \tan^3{x}-3 \tan{x}+3x = 3 \tan^4{x}$,Show,\frac{d}{dx} \tan^3{x}-3 \tan{x}+3x = 3 \tan^4{x},"How do I go about doing this? Show $\frac{d}{dx} \tan^3{x}-3 \tan{x}+3x = 3 \tan^4{x}$. My work. $$ \begin{align*} \frac{d}{dx} \tan^3 x -3 \tan x+3x  &= 3 \tan^2 x \sec^2 x - 3 \sec^2 x + 3 \\ &= 3 \frac{\sin^2 x}{\cos^2 x} \frac{1}{\cos^2 x} - 3 \frac{1}{\cos^2 x} + 3 \\ &= 3 \frac{\sin^2 x}{\cos^4 x} - 3 \frac{1}{\cos^2 x} + 3 \\ &= \frac{3\sin^2 x - 3\cos^2 x + 3\cos^4 x}{\cos^4 x}  \\ &= \frac{3(\sin^2 x - \cos^2 x + \cos^4 x)}{\cos^4 x}.  \end{align*} $$ I got here so far, did I make a mistake or something?","How do I go about doing this? Show $\frac{d}{dx} \tan^3{x}-3 \tan{x}+3x = 3 \tan^4{x}$. My work. $$ \begin{align*} \frac{d}{dx} \tan^3 x -3 \tan x+3x  &= 3 \tan^2 x \sec^2 x - 3 \sec^2 x + 3 \\ &= 3 \frac{\sin^2 x}{\cos^2 x} \frac{1}{\cos^2 x} - 3 \frac{1}{\cos^2 x} + 3 \\ &= 3 \frac{\sin^2 x}{\cos^4 x} - 3 \frac{1}{\cos^2 x} + 3 \\ &= \frac{3\sin^2 x - 3\cos^2 x + 3\cos^4 x}{\cos^4 x}  \\ &= \frac{3(\sin^2 x - \cos^2 x + \cos^4 x)}{\cos^4 x}.  \end{align*} $$ I got here so far, did I make a mistake or something?",,['calculus']
37,L'Hopital's rule and series convergence,L'Hopital's rule and series convergence,,"I teach freshman calculus, and have recently been discussing series. In one question on a recent test, I asked whether $\sum\frac{n^2}{n^3+1}$ converges or diverges. One student got the correct answer by the following incorrect reasoning. They used L'Hopital's rule to conclude that $\frac{n^2}{n^3+1}$ has the same limit as $\frac{2n}{3n^2}$ and as $\frac{2}{6n}$ (which is true so far). They then claimed that because $\sum\frac{2}{6n}$ diverges, the original series must diverge. This, of course, does not follow from anything they've been taught. L'Hopital's rule merely says that if $\frac{2}{6n}$ approaches zero, we can conclude that $\frac{n^2}{n^3+1}$ approaches zero. But L'Hopital's rule, as typically stated, says nothing about the ""rate"" at which $\frac{n^2}{n^3+1}$ approaches zero. However, the following conjecture seems to be true for many expressions, such as $\frac{x^a}{e^x}$, $\frac{\ln x}{x^a}$, and $\frac{x}{x^2(\ln x)^a}$. Can anyone help me come up with the ""correct"" conjecture, and a proof? CONJECTURE: If $f(x)$ and $g(x)$ belong to a ""nice"" class of functions (which approach infinity with $x$), then the infinite series $\sum_n\frac{f(n)}{g(n)}$ and $\sum_n\frac{f'(n)}{g'(n)}$ either both converge or both diverge. EDIT: It appears essentially the same question has already been asked. And a nice answer was given by Robert Israel. However, he requires that $f$ and $g$ be meromorphic. It would be nice if there were a slightly more general answer that included logarithms, OR a counterexample using functions built out of logarithms. When does l'Hospital's rule work for series?","I teach freshman calculus, and have recently been discussing series. In one question on a recent test, I asked whether $\sum\frac{n^2}{n^3+1}$ converges or diverges. One student got the correct answer by the following incorrect reasoning. They used L'Hopital's rule to conclude that $\frac{n^2}{n^3+1}$ has the same limit as $\frac{2n}{3n^2}$ and as $\frac{2}{6n}$ (which is true so far). They then claimed that because $\sum\frac{2}{6n}$ diverges, the original series must diverge. This, of course, does not follow from anything they've been taught. L'Hopital's rule merely says that if $\frac{2}{6n}$ approaches zero, we can conclude that $\frac{n^2}{n^3+1}$ approaches zero. But L'Hopital's rule, as typically stated, says nothing about the ""rate"" at which $\frac{n^2}{n^3+1}$ approaches zero. However, the following conjecture seems to be true for many expressions, such as $\frac{x^a}{e^x}$, $\frac{\ln x}{x^a}$, and $\frac{x}{x^2(\ln x)^a}$. Can anyone help me come up with the ""correct"" conjecture, and a proof? CONJECTURE: If $f(x)$ and $g(x)$ belong to a ""nice"" class of functions (which approach infinity with $x$), then the infinite series $\sum_n\frac{f(n)}{g(n)}$ and $\sum_n\frac{f'(n)}{g'(n)}$ either both converge or both diverge. EDIT: It appears essentially the same question has already been asked. And a nice answer was given by Robert Israel. However, he requires that $f$ and $g$ be meromorphic. It would be nice if there were a slightly more general answer that included logarithms, OR a counterexample using functions built out of logarithms. When does l'Hospital's rule work for series?",,"['calculus', 'sequences-and-series', 'analysis', 'convergence-divergence']"
38,How to evaluate $\int^{\infty}_0 \frac{x^{1010}}{(1 + x)^{2022}} dx$?,How to evaluate ?,\int^{\infty}_0 \frac{x^{1010}}{(1 + x)^{2022}} dx,How to evaluate the following integral? $$\int^{\infty}_0 \frac{x^{1010}}{(1 + x)^{2022}} dx$$ Here's my work: $$\begin{align}I &= \int_0^\infty \dfrac{x^{1010}}{(1+x)^{2022}} dx  \\&=\int_0^\infty \dfrac{1}{x^{1012}(1 + \frac1x)^{2022}}dx\end{align}$$ Putting $( 1 + \frac1x) = t$ $$\begin{align}\implies I& =\int^1_\infty -\dfrac{1}{(\frac1{1-t})^{1010}(t)^{2022}}dx\\& =\int_1^\infty \dfrac{1}{(\frac1{1-t})^{1010}(t)^{2022}}dx \\&=\int_1^\infty \dfrac{1}{(\frac1{1-t})^{1010}\cdot t^{1010} \cdot (t)^{1012}}dx \\&=\int_1^\infty \dfrac{1}{(\frac t{1-t})^{1010} \cdot (t)^{1012}}dx\\& =\int_1^\infty \dfrac{1}{(\frac 1{1/t-1})^{1010} \cdot (t)^{1012}}dx \\&=\int_1^\infty \dfrac{(1/t-1)^{1010}}{ (t)^{1012}}dx \\&=\int_1^\infty \dfrac{(\frac{1-t}{t})^{1010}}{ t^2\cdot (t)^{1010}}dx \\& = \int_1^\infty\dfrac{1}{t^2} \cdot\left( \dfrac{1-t}{t^2}\right)^{1010} dx \end{align} $$ I don't know how to continue from here. I also thought that Integration by parts would work but not sure how to apply here.,How to evaluate the following integral? Here's my work: Putting I don't know how to continue from here. I also thought that Integration by parts would work but not sure how to apply here.,\int^{\infty}_0 \frac{x^{1010}}{(1 + x)^{2022}} dx \begin{align}I &= \int_0^\infty \dfrac{x^{1010}}{(1+x)^{2022}} dx  \\&=\int_0^\infty \dfrac{1}{x^{1012}(1 + \frac1x)^{2022}}dx\end{align} ( 1 + \frac1x) = t \begin{align}\implies I& =\int^1_\infty -\dfrac{1}{(\frac1{1-t})^{1010}(t)^{2022}}dx\\& =\int_1^\infty \dfrac{1}{(\frac1{1-t})^{1010}(t)^{2022}}dx \\&=\int_1^\infty \dfrac{1}{(\frac1{1-t})^{1010}\cdot t^{1010} \cdot (t)^{1012}}dx \\&=\int_1^\infty \dfrac{1}{(\frac t{1-t})^{1010} \cdot (t)^{1012}}dx\\& =\int_1^\infty \dfrac{1}{(\frac 1{1/t-1})^{1010} \cdot (t)^{1012}}dx \\&=\int_1^\infty \dfrac{(1/t-1)^{1010}}{ (t)^{1012}}dx \\&=\int_1^\infty \dfrac{(\frac{1-t}{t})^{1010}}{ t^2\cdot (t)^{1010}}dx \\& = \int_1^\infty\dfrac{1}{t^2} \cdot\left( \dfrac{1-t}{t^2}\right)^{1010} dx \end{align} ,"['calculus', 'integration']"
39,The sum of infinite fours: $\sqrt{4^0+\sqrt{4^1+ \sqrt{4^2+ \dots}}}=?$,The sum of infinite fours:,\sqrt{4^0+\sqrt{4^1+ \sqrt{4^2+ \dots}}}=?,"$\sqrt{4^0+\sqrt{4^1+\sqrt{4^2+\sqrt{4^3+\cdots}}}}=?$ I found this problem in a book. I tried to solve this but couldn't. Using calculator, I found the value close to $2$ . But how can this problem be solved with proper procedure?","I found this problem in a book. I tried to solve this but couldn't. Using calculator, I found the value close to . But how can this problem be solved with proper procedure?",\sqrt{4^0+\sqrt{4^1+\sqrt{4^2+\sqrt{4^3+\cdots}}}}=? 2,"['calculus', 'nested-radicals']"
40,Why isn't the area under the sine curve from $0$ to $\frac{\pi}{2}$ equal to the area of a quarter of the unit circle?,Why isn't the area under the sine curve from  to  equal to the area of a quarter of the unit circle?,0 \frac{\pi}{2},"I was thinking about the graph of the curve $\sin(x)$ . I know that we can generate the graph of $\sin(x)$ by plotting the heights given on the unit circle for various angle measures. Following this line of reasoning, I reasoned that we could find the are under a sine curve by simply looking at the area of that part of the unit circle. However, if we try (integrating using the anti-derivative) $\int_{0}^{\pi/2} \sin x \,dx$ , we get the answer of $1$ . A glance at the unit circle would suggest that the answer would be $\pi/4$ , as this is the area of the quarter-circle. What went wrong?","I was thinking about the graph of the curve . I know that we can generate the graph of by plotting the heights given on the unit circle for various angle measures. Following this line of reasoning, I reasoned that we could find the are under a sine curve by simply looking at the area of that part of the unit circle. However, if we try (integrating using the anti-derivative) , we get the answer of . A glance at the unit circle would suggest that the answer would be , as this is the area of the quarter-circle. What went wrong?","\sin(x) \sin(x) \int_{0}^{\pi/2} \sin x \,dx 1 \pi/4","['calculus', 'geometry']"
41,Does the sum of two functions satisfying the intermediate value property also have this property?,Does the sum of two functions satisfying the intermediate value property also have this property?,,"If functions $f$ and $g$ both satisfy the intermediate value property, does their sum also satisfy this property? If not, what if I suppose in addition that $f$ is continuous? Thanks in advance! Edit: I found the second part of my question here: Is the sum of a Darboux function and a continuous function Darboux?","If functions and both satisfy the intermediate value property, does their sum also satisfy this property? If not, what if I suppose in addition that is continuous? Thanks in advance! Edit: I found the second part of my question here: Is the sum of a Darboux function and a continuous function Darboux?",f g f,"['calculus', 'analysis', 'continuity']"
42,Derivative of moment generating function,Derivative of moment generating function,,"If the moment generating function of $X$ exists, i.e., $$M_X(t)=E[e^{tX}],$$ then the derivative with respect to $t$ is usually taken as $$\frac{dM_X(t)}{dt}=E[Xe^{tX}].$$ Usually, if we want to change the order of derivative and calculus, there are some conditions need to verified. Why the derivative goes inside for the moment generating function?","If the moment generating function of $X$ exists, i.e., $$M_X(t)=E[e^{tX}],$$ then the derivative with respect to $t$ is usually taken as $$\frac{dM_X(t)}{dt}=E[Xe^{tX}].$$ Usually, if we want to change the order of derivative and calculus, there are some conditions need to verified. Why the derivative goes inside for the moment generating function?",,"['calculus', 'probability', 'derivatives', 'moment-generating-functions']"
43,(Reference Request) Calculus on Banach Spaces,(Reference Request) Calculus on Banach Spaces,,"I'm reading Lang's Real and Functional Analysis, and I am surprised that one can still do a fair amount of calculus (differential/integral) on abstract Banach spaces, not just $\mathbb{R}$ of $\mathbb{R}^N$. For example, Lang writes about Bochner integrals - which is slightly different from the 'usual' Lebesgue integral - which gives you a way to integrate Banach-space-valued maps. Also, he uses theorems of differential calculus (of Banach spaces) to prove results about flows on manifolds, which is quite fundamental to differential geometry. I'm on chapter 7 right now, and I wonder what other good books are there, dealing with this subject: calculus on Banach spaces. After dealing with integration and differentiation (in that order), Lang moves on to 'functional analysis', but I want to see more applications and examples of calculus; for example, Banach-space-valued power series (on $z\in\mathbb{C}$, say), whether one can use the familiar techniques of complex analysis in that case (e.g. Cauchy integral formula), or how the theory is used for differential topology/geometry. Can anyone suggest a text that gives a complete/thorough treatment of calculus in Banach spaces? (Ones with geometric flavor are even nicer!) Any advice is welcome.","I'm reading Lang's Real and Functional Analysis, and I am surprised that one can still do a fair amount of calculus (differential/integral) on abstract Banach spaces, not just $\mathbb{R}$ of $\mathbb{R}^N$. For example, Lang writes about Bochner integrals - which is slightly different from the 'usual' Lebesgue integral - which gives you a way to integrate Banach-space-valued maps. Also, he uses theorems of differential calculus (of Banach spaces) to prove results about flows on manifolds, which is quite fundamental to differential geometry. I'm on chapter 7 right now, and I wonder what other good books are there, dealing with this subject: calculus on Banach spaces. After dealing with integration and differentiation (in that order), Lang moves on to 'functional analysis', but I want to see more applications and examples of calculus; for example, Banach-space-valued power series (on $z\in\mathbb{C}$, say), whether one can use the familiar techniques of complex analysis in that case (e.g. Cauchy integral formula), or how the theory is used for differential topology/geometry. Can anyone suggest a text that gives a complete/thorough treatment of calculus in Banach spaces? (Ones with geometric flavor are even nicer!) Any advice is welcome.",,"['calculus', 'functional-analysis', 'reference-request', 'banach-spaces', 'book-recommendation']"
44,How can we show that $\int_{0}^{\pi/2}x\cos(8x)\ln\left(1+\tan x\over 1-\tan x\right)\mathrm dx={\pi\over 12}?$,How can we show that,\int_{0}^{\pi/2}x\cos(8x)\ln\left(1+\tan x\over 1-\tan x\right)\mathrm dx={\pi\over 12}?,"Consider the integral $(1)$ $$\int_{0}^{\pi/2}x\cos(8x)\ln\left(1+\tan x\over 1-\tan x\right)\mathrm dx={\pi\over 12}\tag1$$ An attempt: Rewrite $(1)$ as $$\int_{0}^{\pi/2}x\cos(8x)\ln\tan\left(x+{\pi\over 4}\right)\mathrm dx\tag2$$ $$\int_{0}^{\pi/2}x\cdot{1-\tan^2(4x)\over 1+\tan^2(4x)}\ln\tan\left(x+{\pi\over 4}\right)\mathrm dx\tag3$$ Or we can rewrite $(1)$ as $$\color{red}{\int_{0}^{\pi/2}x\cos^2(4x)\ln\tan\left(x+{\pi\over 4}\right)\mathrm dx}-\int_{0}^{\pi/2}x\sin^2(4x)\ln\tan\left(x+{\pi\over 4}\right)\mathrm dx=I_1+I_2\tag4$$ Applying $\ln\tan x$ series to the red part $I_1$ becomes $$I_1=\int_{0}^{\pi/2}x\cos^2(4x)\ln\left(x+{\pi\over 4}\right)\mathrm dx+\sum_{n=1}^{\infty}{2^{2n}(2^{2n-1}-1)B_n\over n(2n)!}\int_{0}^{\pi/2}x(x+\pi/4)^{2n}\cos^2(4x)\mathrm dx\tag5$$ This looked too complicate, how else can we prove $(1)?$","Consider the integral $(1)$ $$\int_{0}^{\pi/2}x\cos(8x)\ln\left(1+\tan x\over 1-\tan x\right)\mathrm dx={\pi\over 12}\tag1$$ An attempt: Rewrite $(1)$ as $$\int_{0}^{\pi/2}x\cos(8x)\ln\tan\left(x+{\pi\over 4}\right)\mathrm dx\tag2$$ $$\int_{0}^{\pi/2}x\cdot{1-\tan^2(4x)\over 1+\tan^2(4x)}\ln\tan\left(x+{\pi\over 4}\right)\mathrm dx\tag3$$ Or we can rewrite $(1)$ as $$\color{red}{\int_{0}^{\pi/2}x\cos^2(4x)\ln\tan\left(x+{\pi\over 4}\right)\mathrm dx}-\int_{0}^{\pi/2}x\sin^2(4x)\ln\tan\left(x+{\pi\over 4}\right)\mathrm dx=I_1+I_2\tag4$$ Applying $\ln\tan x$ series to the red part $I_1$ becomes $$I_1=\int_{0}^{\pi/2}x\cos^2(4x)\ln\left(x+{\pi\over 4}\right)\mathrm dx+\sum_{n=1}^{\infty}{2^{2n}(2^{2n-1}-1)B_n\over n(2n)!}\int_{0}^{\pi/2}x(x+\pi/4)^{2n}\cos^2(4x)\mathrm dx\tag5$$ This looked too complicate, how else can we prove $(1)?$",,"['calculus', 'integration', 'definite-integrals']"
45,Find maximum of $xy$ subject to $(x+1)^2 + y^2 = 4$ without using Calculus techniques,Find maximum of  subject to  without using Calculus techniques,xy (x+1)^2 + y^2 = 4,"Find maximum of $xy$ subject to $(x+1)^2 + y^2 = 4$. It is easy if we apply Calculus techniques (e.g., derivatives, Lagrange multipliers, etc). However, the problem is assigned for students who have not yet learned Calculus. Is there a way to find the maximum without using Calculus techniques? I have a few ideas: Apply geometric means: $xy \leq \frac{x^2+y^2}{2} = -x + 3/2 $. Change object function to $(xy)^2$, then we have $(xy)^2 = x^2(4-(x+1)^2)=x^2(-x^2 - 2x +3)$. That is, maximize  $x^2(-x^2 - 2x +3)$ on $(-3,1)$.","Find maximum of $xy$ subject to $(x+1)^2 + y^2 = 4$. It is easy if we apply Calculus techniques (e.g., derivatives, Lagrange multipliers, etc). However, the problem is assigned for students who have not yet learned Calculus. Is there a way to find the maximum without using Calculus techniques? I have a few ideas: Apply geometric means: $xy \leq \frac{x^2+y^2}{2} = -x + 3/2 $. Change object function to $(xy)^2$, then we have $(xy)^2 = x^2(4-(x+1)^2)=x^2(-x^2 - 2x +3)$. That is, maximize  $x^2(-x^2 - 2x +3)$ on $(-3,1)$.",,"['calculus', 'inequality', 'optimization', 'nonlinear-optimization']"
46,"Conjectured closed form for $\int_0^1\frac{\operatorname{li}^4(x)}{x^4}\,dx$",Conjectured closed form for,"\int_0^1\frac{\operatorname{li}^4(x)}{x^4}\,dx","It has been conjectured by Kirill that $$\int_0^1\frac{\operatorname{li}^4(x)}{x^4}\,dx=\int_0^\infty\operatorname{Ei}^4(-x)\,e^{3x}\,dx\stackrel{\color{gray}?}=\frac{26\pi^4}{135}+\frac49\left(\pi^2\ln^22-\ln^42\right)-\frac{32}{3}\operatorname{Li}_4\!\left(\tfrac12\right).$$ Can we prove this conjecture?","It has been conjectured by Kirill that $$\int_0^1\frac{\operatorname{li}^4(x)}{x^4}\,dx=\int_0^\infty\operatorname{Ei}^4(-x)\,e^{3x}\,dx\stackrel{\color{gray}?}=\frac{26\pi^4}{135}+\frac49\left(\pi^2\ln^22-\ln^42\right)-\frac{32}{3}\operatorname{Li}_4\!\left(\tfrac12\right).$$ Can we prove this conjecture?",,"['calculus', 'integration', 'definite-integrals', 'special-functions', 'closed-form']"
47,Confused about differentiability/continuity/partial derivative existence,Confused about differentiability/continuity/partial derivative existence,,"Ok, so in my notes it says Prop 1: If a function is differentiable, it will be continuous AND it will also have partial derivatives. Prop 2: If a function is continuous, or has partial derivatives, or has both, it does not guarantee the function is differentiable. And the example to follow for prop 2 is: $f(x,y)=\frac{y^3}{x^2+y^2}$ if $(x,y )\ne (0,0)$ $f(x,y)=0 $ if $(x,y)=(0,0)$ $f_x(0,0)=0$ $f_y(0,0)=1$ (how????) The function is also continuous at $(0,0)$ since $\lim f(x,y)=0$ (using squeeze theorem) So it says the partial derivatives exist. My first question is, why is $f_y(0,0)=1$? shouldn't it be $0$? Not that it makes a difference. The partials will exist regardless. My second question is, it says that this function is not differentiable. How do they know that? My third question: It says in the calculus textbook, one of the theorems (theorem 8 of chapter 14.4 for stewert's book): If the partial derivatives $f_x$ and $f_y$ exist near $(a,b)$ and are continuous at $(a,b)$ then $f$ is differentiable at $(a,b)$. How does this make sense? The example in my notes just said a function can be continuous and have partials, but still not be differentiable","Ok, so in my notes it says Prop 1: If a function is differentiable, it will be continuous AND it will also have partial derivatives. Prop 2: If a function is continuous, or has partial derivatives, or has both, it does not guarantee the function is differentiable. And the example to follow for prop 2 is: $f(x,y)=\frac{y^3}{x^2+y^2}$ if $(x,y )\ne (0,0)$ $f(x,y)=0 $ if $(x,y)=(0,0)$ $f_x(0,0)=0$ $f_y(0,0)=1$ (how????) The function is also continuous at $(0,0)$ since $\lim f(x,y)=0$ (using squeeze theorem) So it says the partial derivatives exist. My first question is, why is $f_y(0,0)=1$? shouldn't it be $0$? Not that it makes a difference. The partials will exist regardless. My second question is, it says that this function is not differentiable. How do they know that? My third question: It says in the calculus textbook, one of the theorems (theorem 8 of chapter 14.4 for stewert's book): If the partial derivatives $f_x$ and $f_y$ exist near $(a,b)$ and are continuous at $(a,b)$ then $f$ is differentiable at $(a,b)$. How does this make sense? The example in my notes just said a function can be continuous and have partials, but still not be differentiable",,"['calculus', 'multivariable-calculus', 'derivatives']"
48,Solving $x^2+bx^{1+\varepsilon}+c =0$,Solving,x^2+bx^{1+\varepsilon}+c =0,"Let $x \in \mathbb{R}$. Is it possible to find the roots of $x^2+bx^{1+\varepsilon}+c =0$ where $b,c \in \mathbb{R}$ and $\varepsilon$ is small. I am guessing that an explicit expression might not be possible but is it possible to write the roots as an expansion?","Let $x \in \mathbb{R}$. Is it possible to find the roots of $x^2+bx^{1+\varepsilon}+c =0$ where $b,c \in \mathbb{R}$ and $\varepsilon$ is small. I am guessing that an explicit expression might not be possible but is it possible to write the roots as an expansion?",,"['calculus', 'analysis', 'roots']"
49,Being ready to study calculus,Being ready to study calculus,,"Some background: I have a degree in computer science, but the math was limited and this was 10 years ago. High school was way before that.  A year ago I relearnt algebra (factoring, solving linear equations, etc).  However, I have probably forgotten some of that. I never really studied trigonometry properly. I want to self study calculus and other advanced math, but I feel there are some holes that I should fill before starting.  I planned on using MIT OCW for calculus but they don't have a revision course. Is there a video course or book that covers all of this up to calculus?  (No textbooks with endless exercises please.) I would like to complete this in a few weeks. Given my background, I think this is possible.","Some background: I have a degree in computer science, but the math was limited and this was 10 years ago. High school was way before that.  A year ago I relearnt algebra (factoring, solving linear equations, etc).  However, I have probably forgotten some of that. I never really studied trigonometry properly. I want to self study calculus and other advanced math, but I feel there are some holes that I should fill before starting.  I planned on using MIT OCW for calculus but they don't have a revision course. Is there a video course or book that covers all of this up to calculus?  (No textbooks with endless exercises please.) I would like to complete this in a few weeks. Given my background, I think this is possible.",,"['calculus', 'algebra-precalculus', 'reference-request', 'trigonometry', 'self-learning']"
50,How to calculate the asymptotic expansion of $\sum \sqrt{k}$?,How to calculate the asymptotic expansion of ?,\sum \sqrt{k},"Denote $u_n:=\sum_{k=1}^n \sqrt{k}$. We can easily see that $$ k^{1/2} = \frac{2}{3} (k^{3/2} - (k-1)^{3/2}) + O(k^{-1/2}),$$ hence $\sum_1^n \sqrt{k} = \frac{2}{3}n^{3/2} + O(n^{1/2})$, because $\sum_1^n O(k^{-1/2}) =O(n^{1/2})$. With some more calculations, we get $$ k^{1/2} = \frac{2}{3} (k^{3/2} - (k-1)^{3/2}) + \frac{1}{2} (k^{1/2}-(k-1)^{-3/2}) +  O(k^{-1/2}),$$ hence $\sum_1^n \sqrt{k} = \frac{2}{3}n^{3/2} + \frac{1}{2} n^{1/2} + C + O(n^{1/2})$ for some constant $C$, because $\sum_n^\infty O(k^{-3/2}) = O(n^{-1/2})$. Now let's go further. I have made the following calculation $$k^{1/2} = \frac{3}{2} \Delta_{3/2}(k) + \frac{1}{2} \Delta_{1/2}(k) + \frac{1}{24} \Delta_{-1/2}(k) + O(k^{-5/2}),$$ where $\Delta_\alpha(k) = k^\alpha-(k-1)^{\alpha}$. Hence : $$\sum_{k=1}^n \sqrt{k} = \frac{2}{3} n^{3/2} + \frac{1}{2} n^{1/2} + C + \frac{1}{24} n^{-1/2} + O(n^{-3/2}).$$ And one can continue ad vitam aeternam, but the only term I don't know how to compute is the constant term. How do we find $C$ ?","Denote $u_n:=\sum_{k=1}^n \sqrt{k}$. We can easily see that $$ k^{1/2} = \frac{2}{3} (k^{3/2} - (k-1)^{3/2}) + O(k^{-1/2}),$$ hence $\sum_1^n \sqrt{k} = \frac{2}{3}n^{3/2} + O(n^{1/2})$, because $\sum_1^n O(k^{-1/2}) =O(n^{1/2})$. With some more calculations, we get $$ k^{1/2} = \frac{2}{3} (k^{3/2} - (k-1)^{3/2}) + \frac{1}{2} (k^{1/2}-(k-1)^{-3/2}) +  O(k^{-1/2}),$$ hence $\sum_1^n \sqrt{k} = \frac{2}{3}n^{3/2} + \frac{1}{2} n^{1/2} + C + O(n^{1/2})$ for some constant $C$, because $\sum_n^\infty O(k^{-3/2}) = O(n^{-1/2})$. Now let's go further. I have made the following calculation $$k^{1/2} = \frac{3}{2} \Delta_{3/2}(k) + \frac{1}{2} \Delta_{1/2}(k) + \frac{1}{24} \Delta_{-1/2}(k) + O(k^{-5/2}),$$ where $\Delta_\alpha(k) = k^\alpha-(k-1)^{\alpha}$. Hence : $$\sum_{k=1}^n \sqrt{k} = \frac{2}{3} n^{3/2} + \frac{1}{2} n^{1/2} + C + \frac{1}{24} n^{-1/2} + O(n^{-3/2}).$$ And one can continue ad vitam aeternam, but the only term I don't know how to compute is the constant term. How do we find $C$ ?",,"['calculus', 'sequences-and-series', 'summation', 'radicals']"
51,Prove that $(e+x)^{e-x}>(e-x)^{e+x}$,Prove that,(e+x)^{e-x}>(e-x)^{e+x},"I get stuck with proving that $$(e+x)^{e-x}>(e-x)^{e+x}$$ for $x \in (0, e)$. All I know, is that it is doable with Jensen inequality, and I started with defining $$f(x)=(e+x)^{e-x}$$ and further $$g(x)=\ln \cdot f(x)$$ and... nothing more come to my mind, I kindly ask for any help & hints. Thanks","I get stuck with proving that $$(e+x)^{e-x}>(e-x)^{e+x}$$ for $x \in (0, e)$. All I know, is that it is doable with Jensen inequality, and I started with defining $$f(x)=(e+x)^{e-x}$$ and further $$g(x)=\ln \cdot f(x)$$ and... nothing more come to my mind, I kindly ask for any help & hints. Thanks",,"['calculus', 'analysis', 'inequality', 'exponential-function']"
52,How do you take the derivative with respect to a function?,How do you take the derivative with respect to a function?,,"I'm trying to figure out how to take a derivative that looks like  $\displaystyle \frac{d}{d(\ln(a))}$, of a function $F(a)$, where $a = a(t)$.  In the paper I'm reading (where this appears), they give the following result in the case that $F(a) = \frac{\dot{a}}{a}$ (where the ""dot"" is a derivative with respect to $t$): $$\frac{d(1/F^2)}{d\ln(a)} = \frac{-2\dot{F}}{F^4},$$ but I can't see how they're getting this.  Any insight would be much appreciated.","I'm trying to figure out how to take a derivative that looks like  $\displaystyle \frac{d}{d(\ln(a))}$, of a function $F(a)$, where $a = a(t)$.  In the paper I'm reading (where this appears), they give the following result in the case that $F(a) = \frac{\dot{a}}{a}$ (where the ""dot"" is a derivative with respect to $t$): $$\frac{d(1/F^2)}{d\ln(a)} = \frac{-2\dot{F}}{F^4},$$ but I can't see how they're getting this.  Any insight would be much appreciated.",,['calculus']
53,Why is it called 'King's Property of Integration'?,Why is it called 'King's Property of Integration'?,,"Recently I learned about ""King's Property"" or ""King's Rule"" and I was wondering about its etymology? I understand that it's a basic change of variables but it has a name for a reason. I've been unable to find this reason online. I speculate that the person who first encountered it had the popular surname King. In case terminology is different elsewhere, here's what I'm talking about: $$\int_{a}^{b}f(x)dx=\int_{a}^{b}f(a+b-x)dx$$","Recently I learned about ""King's Property"" or ""King's Rule"" and I was wondering about its etymology? I understand that it's a basic change of variables but it has a name for a reason. I've been unable to find this reason online. I speculate that the person who first encountered it had the popular surname King. In case terminology is different elsewhere, here's what I'm talking about:",\int_{a}^{b}f(x)dx=\int_{a}^{b}f(a+b-x)dx,"['calculus', 'integration', 'definite-integrals', 'soft-question', 'math-history']"
54,"Evaluate $3\int_{0}^{2\pi} \sin(t) \cos(t) \,{\rm d}t$",Evaluate,"3\int_{0}^{2\pi} \sin(t) \cos(t) \,{\rm d}t","$$3\int_{0}^{2\pi} \sin(t) \cos(t) \,{\rm d}t$$ My calculus is a bit rusty and I can not find where I get it wrong. Setting $u= \sin(t)$ , I get ${\rm d} u=\cos(t) \,{\rm d} t$ and, thus, $$3\int_{u=0}^{u=0}u \,{\rm d}u=0$$","My calculus is a bit rusty and I can not find where I get it wrong. Setting , I get and, thus,","3\int_{0}^{2\pi} \sin(t) \cos(t) \,{\rm d}t u= \sin(t) {\rm d} u=\cos(t) \,{\rm d} t 3\int_{u=0}^{u=0}u \,{\rm d}u=0","['calculus', 'integration', 'definite-integrals']"
55,Proving $-\frac{1}{a}<\int_a^b \sin(x^2) dx<\frac{1}{a}$,Proving,-\frac{1}{a}<\int_a^b \sin(x^2) dx<\frac{1}{a},"I have encountered a question: Prove $$-\frac{1}{a}<\int_a^b \sin(x^2) dx<\frac{1}{a}$$ There are plenty of solutions to $\int_0^{\infty} \sin(x^2) dx$ online, but there seems to be no solution to the boundary of $\int_a^b \sin(x^2) dx$ . Could anyone help me with this please? I tried to calculate the integral directly, but I cannot cancel out b and get a boundary only with $a$ . Applying inequality to the integrand $\sin(x^2)<x^2$ does not work either.","I have encountered a question: Prove There are plenty of solutions to online, but there seems to be no solution to the boundary of . Could anyone help me with this please? I tried to calculate the integral directly, but I cannot cancel out b and get a boundary only with . Applying inequality to the integrand does not work either.",-\frac{1}{a}<\int_a^b \sin(x^2) dx<\frac{1}{a} \int_0^{\infty} \sin(x^2) dx \int_a^b \sin(x^2) dx a \sin(x^2)<x^2,['calculus']
56,Maximum and minimum value of $\int_0^1 f(x)dx $ given $|f'(x)|<2$,Maximum and minimum value of  given,\int_0^1 f(x)dx  |f'(x)|<2,"Let $f:\mathbb R\to \mathbb R$ be a differentiable function such that $f(0)=  0$ and $f(1)= 1$ and $|f'(x)|<2 ~ \forall x \in \mathbb R$ , if $a$ and $b$ are real numbers such that the set of possible values of $\displaystyle\int_0^1  f(x)dx $ is the open interval $(a,b)$ , then $b-a$ is: ? Attempt: $$I = \int_0^1 1.f(x) dx$$ $$\implies I = 1 - \int_0^1 xf'(x)dx $$ (Integration by parts) $$-2 < f'(x) < 2$$ $$\implies -2x <xf'(x)< 2x$$ for $x>0$ $$\implies -1 < \int_0^1 xf'(x) dx < 1$$ Therefore $I_{max} = 2$ and $I_{min} = 0$ $\implies b- a = 2$ but answer given is $b-a = \dfrac 3 4$ . Please let me know my mistake, and the correct way to solve it.","Let be a differentiable function such that and and , if and are real numbers such that the set of possible values of is the open interval , then is: ? Attempt: (Integration by parts) for Therefore and but answer given is . Please let me know my mistake, and the correct way to solve it.","f:\mathbb R\to \mathbb R f(0)=
 0 f(1)= 1 |f'(x)|<2 ~ \forall x \in \mathbb R a b \displaystyle\int_0^1
 f(x)dx  (a,b) b-a I = \int_0^1 1.f(x) dx \implies I = 1 - \int_0^1 xf'(x)dx  -2 < f'(x) < 2 \implies -2x <xf'(x)< 2x x>0 \implies -1 < \int_0^1 xf'(x) dx < 1 I_{max} = 2 I_{min} = 0 \implies b- a = 2 b-a = \dfrac 3 4","['calculus', 'integration', 'definite-integrals', 'maxima-minima']"
57,"A function that grows faster than any function in the sequence $e^x, e^{e^x}, e^{e^{e^x}}$...",A function that grows faster than any function in the sequence ...,"e^x, e^{e^x}, e^{e^{e^x}}","Is there a continuous function constructed by elementary functions, or by integral formula involved only elementary functions (like Gamma function) that grows faster than any $e^{e^{e...^x}}$ ($e$ appears $n$ times)? I ask for the answer with a single formula. Gluing continuous function together is too trivial. The function need not to be defined on whole $\mathbb{R}$, the domain $(a, \infty)$ is acceptable.","Is there a continuous function constructed by elementary functions, or by integral formula involved only elementary functions (like Gamma function) that grows faster than any $e^{e^{e...^x}}$ ($e$ appears $n$ times)? I ask for the answer with a single formula. Gluing continuous function together is too trivial. The function need not to be defined on whole $\mathbb{R}$, the domain $(a, \infty)$ is acceptable.",,"['calculus', 'functions', 'exponential-function', 'elementary-functions']"
58,What is the derivative of $x^n$?,What is the derivative of ?,x^n,"If $n$ is an integer I can evaluate the limit in the ""difference quotient"" to see that the derivative of $x^n$ is $nx^{n-1}$.  If $n=p/q$ is rational then I can write x as a $q$th root of $x^p$ and since $p$ is an integer I can evaluate the limit in the difference quotient. But what if $n$ is an irrational number?","If $n$ is an integer I can evaluate the limit in the ""difference quotient"" to see that the derivative of $x^n$ is $nx^{n-1}$.  If $n=p/q$ is rational then I can write x as a $q$th root of $x^p$ and since $p$ is an integer I can evaluate the limit in the difference quotient. But what if $n$ is an irrational number?",,['calculus']
59,"Closed form for ${\large\int}_0^\pi\frac{x\,\cos\frac x3}{\sqrt[3]{\sin x}}dx$",Closed form for,"{\large\int}_0^\pi\frac{x\,\cos\frac x3}{\sqrt[3]{\sin x}}dx","I'm trying to find a closed form for the integral below and I found the following conjecture using computer search (and some lucky guesses): $$\int_0^\pi\frac{x\,\cos\frac x3}{\sqrt[3]{\sin x}}dx\stackrel{\color{#A0A0A0}?}=\frac{\pi\sqrt[3]2}{24}\big(7\pi\sqrt3-9\ln3\big).\tag1$$ Could you please help me to find a proof of it?","I'm trying to find a closed form for the integral below and I found the following conjecture using computer search (and some lucky guesses): $$\int_0^\pi\frac{x\,\cos\frac x3}{\sqrt[3]{\sin x}}dx\stackrel{\color{#A0A0A0}?}=\frac{\pi\sqrt[3]2}{24}\big(7\pi\sqrt3-9\ln3\big).\tag1$$ Could you please help me to find a proof of it?",,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'closed-form']"
60,Integral of the convolution of two functions: $\int_{-\infty}^{\infty} (f*g)(x)dx$,Integral of the convolution of two functions:,\int_{-\infty}^{\infty} (f*g)(x)dx,There is this proof for the integral of convolution between two functions: $$\begin{align}\int_{-\infty}^{\infty} (f*g)(x)dx&=\int_{-\infty}^{\infty}\left [ \int_{-\infty}^{\infty}f(x-\xi)g(\xi)d\xi \right ] dx \\&=\int_{-\infty}^{\infty}g(\xi)\left [ \int_{-\infty}^{\infty}f(x-\xi)dx \right ] d\xi \\ &=\int_{-\infty}^{\infty}g(\xi)\left [ \int_{-\infty}^{\infty}f(\eta)d\eta \right ] d\xi\\&=\int_{-\infty}^{\infty}g(\xi) d\xi \int_{-\infty}^{\infty}f(\eta)d\eta\end{align}$$ What confuses me is the way author has easily changed the order of terms under integral sign. I'll appreciate any explanation.,There is this proof for the integral of convolution between two functions: $$\begin{align}\int_{-\infty}^{\infty} (f*g)(x)dx&=\int_{-\infty}^{\infty}\left [ \int_{-\infty}^{\infty}f(x-\xi)g(\xi)d\xi \right ] dx \\&=\int_{-\infty}^{\infty}g(\xi)\left [ \int_{-\infty}^{\infty}f(x-\xi)dx \right ] d\xi \\ &=\int_{-\infty}^{\infty}g(\xi)\left [ \int_{-\infty}^{\infty}f(\eta)d\eta \right ] d\xi\\&=\int_{-\infty}^{\infty}g(\xi) d\xi \int_{-\infty}^{\infty}f(\eta)d\eta\end{align}$$ What confuses me is the way author has easily changed the order of terms under integral sign. I'll appreciate any explanation.,,"['calculus', 'integration', 'functional-analysis', 'convergence-divergence', 'convolution']"
61,Evaluate $\int_{1}^{\infty}e^{-x}\ln^{2}\left(x\right)dx$,Evaluate,\int_{1}^{\infty}e^{-x}\ln^{2}\left(x\right)dx,Evaluate :$$\int_{1}^{\infty}e^{-x}\ln^{2}\left(x\right)\mathrm{d}x$$ I've tried to solve this with some elegant substitutions like $t=e^x$ or $t=\ln\left(x\right)$ . I've also tried to integrate by parts without any success. any help would be good.,Evaluate :$$\int_{1}^{\infty}e^{-x}\ln^{2}\left(x\right)\mathrm{d}x$$ I've tried to solve this with some elegant substitutions like $t=e^x$ or $t=\ln\left(x\right)$ . I've also tried to integrate by parts without any success. any help would be good.,,['calculus']
62,Confused about an integral from MIT integration bee 2012,Confused about an integral from MIT integration bee 2012,,"One of the integrals is: $$\int \frac{\mathrm{d}x}{2+2\sin x + \cos x}\, \mathrm{d}x $$ How can there be two $\mathrm{d}x$? MIT's Integration Bee","One of the integrals is: $$\int \frac{\mathrm{d}x}{2+2\sin x + \cos x}\, \mathrm{d}x $$ How can there be two $\mathrm{d}x$? MIT's Integration Bee",,['calculus']
63,Methods to solve differential equations,Methods to solve differential equations,,"We are given the equation $$\frac{1}{f(x)} \cdot \frac{d\left(f(x)\right)}{dx} = x^3.$$  To solve it, ""multiply by $dx$"" and integrate: $\frac{x^4}{4} + C = \ln \left( f(x) \right)$  But $dx$ is not a number, what does it mean when I multiply by $dx$, what am I doing, why does it work, and how can I solve it without multiplying by $dx$? Second question: Suppose we have the equation $$\frac{d^2f(x)}{dx^2}=(x^2-1)f(x)$$ Then for large $x$, we have $\frac{d^2f(x)}{dx^2}\approx x^2f(x)$, with the approximate solution $ke \cdot \exp \left (\frac{x^2}{2} \right)$ Why is it then reasonable to suspect, or assume, that the solution to the original equation, will be of the form $f(x)=e^{x^2/2} \cdot g(x)$, where $g(x)$ has a simpler form then $f(x)$? When does it not work? Third question: The method of replacing all occurences of $f(x)$, and its derivatives by a power series, $\sum a_nx^n$, for which equations does this work or lead to a simpler equation? Do we lose any solutions this way?","We are given the equation $$\frac{1}{f(x)} \cdot \frac{d\left(f(x)\right)}{dx} = x^3.$$  To solve it, ""multiply by $dx$"" and integrate: $\frac{x^4}{4} + C = \ln \left( f(x) \right)$  But $dx$ is not a number, what does it mean when I multiply by $dx$, what am I doing, why does it work, and how can I solve it without multiplying by $dx$? Second question: Suppose we have the equation $$\frac{d^2f(x)}{dx^2}=(x^2-1)f(x)$$ Then for large $x$, we have $\frac{d^2f(x)}{dx^2}\approx x^2f(x)$, with the approximate solution $ke \cdot \exp \left (\frac{x^2}{2} \right)$ Why is it then reasonable to suspect, or assume, that the solution to the original equation, will be of the form $f(x)=e^{x^2/2} \cdot g(x)$, where $g(x)$ has a simpler form then $f(x)$? When does it not work? Third question: The method of replacing all occurences of $f(x)$, and its derivatives by a power series, $\sum a_nx^n$, for which equations does this work or lead to a simpler equation? Do we lose any solutions this way?",,"['calculus', 'ordinary-differential-equations']"
64,Prove that $\lim \limits_{n\to\infty}\frac{n}{n^2+1}  = 0$ from the definition,Prove that  from the definition,\lim \limits_{n\to\infty}\frac{n}{n^2+1}  = 0,"This is a homework question: Prove, using the definition of a limit, that   $$\lim_{n\to\infty}\frac{n}{n^2+1}  = 0.$$ Now this is what I have so far but I'm not sure if it is correct: Let $\epsilon$ be any number, so we need to find an $M$ such that: $$\left|\frac{n}{n^2 + 1}\right| < \epsilon \text{ whenever }x \gt M.$$ $$ n \lt \epsilon(n^2 + 1) $$ $$n \lt  \epsilon n^2 + \epsilon$$ Now what? I am completely clueless on how to do this!","This is a homework question: Prove, using the definition of a limit, that   $$\lim_{n\to\infty}\frac{n}{n^2+1}  = 0.$$ Now this is what I have so far but I'm not sure if it is correct: Let $\epsilon$ be any number, so we need to find an $M$ such that: $$\left|\frac{n}{n^2 + 1}\right| < \epsilon \text{ whenever }x \gt M.$$ $$ n \lt \epsilon(n^2 + 1) $$ $$n \lt  \epsilon n^2 + \epsilon$$ Now what? I am completely clueless on how to do this!",,"['calculus', 'limits', 'epsilon-delta']"
65,Showing there's no closed-form: $\sum_{n=0}^\infty(-1)^n\frac{\cos^2({3^nx})}{3^n}$,Showing there's no closed-form:,\sum_{n=0}^\infty(-1)^n\frac{\cos^2({3^nx})}{3^n},"Problem_ Compute $$\sum_{n=0}^\infty(-1)^n\frac{\cos^2({3^nx})}{3^n}$$ The problem is pretty simple, but it was hard for me to segregate into the partial fractions(I wanted to make a form of telescoping). Hmmmm... My attempts were: $$\sum_{n\ge0}(-1)^n\frac{\cos^2({3^nx})}{3^n}=\sum_{n\ge0}(-1)^n\frac{1+\cos(2\cdot3^nx)}{2\cdot3^n}={1\over2}\sum_{n\ge0}\left(-{1\over3}\right)^n+\Re \sum_{n\ge0}\frac{(-1)^ne^{i\cdot2\cdot3^nx}}{2\cdot3^n}$$ From here, could you please suggest me the idea in order to continue the calculation? I still cannot solve the series $$\sum_{n\ge0}\frac{(-1)^ne^{i\cdot2\cdot3^nx}}{2\cdot3^n}$$ because there is another exponents in the exponents of the natural constant $e$ . I'm also pleasure to have a hint in a different perspective. Thanks for your interest. [ EDIT_1 ] I surely think that there must be some typo on the given series - for example, mistyping $\pi$ as $x$ as SangchulLee and DougM mentioned through the comments, or the location of $n$ (such as $3nx\rightarrow3^nx$ ). But I suddenly wanted to deeply focus on this series, and I just started to doubtful about the existence of closed-form of it. Furthermore, just for the curious of math, if there's no closed-form, I want to prove that . [ EDIT_2 ] It's also welcome to suggest another possible typo. I'm still waiting the various opinions, suggestions, ideas, and creative solutions of the series. Besides, I'm also wondering whether there is a typical method to prove that the given series has no closed-form. [ EDIT_3 ] Can we evaluate the series with exponents in the denominator? I recommend to skim what I've discussed so far. You don't have to reply all the questions. Thanks for your interest one more time.","Problem_ Compute The problem is pretty simple, but it was hard for me to segregate into the partial fractions(I wanted to make a form of telescoping). Hmmmm... My attempts were: From here, could you please suggest me the idea in order to continue the calculation? I still cannot solve the series because there is another exponents in the exponents of the natural constant . I'm also pleasure to have a hint in a different perspective. Thanks for your interest. [ EDIT_1 ] I surely think that there must be some typo on the given series - for example, mistyping as as SangchulLee and DougM mentioned through the comments, or the location of (such as ). But I suddenly wanted to deeply focus on this series, and I just started to doubtful about the existence of closed-form of it. Furthermore, just for the curious of math, if there's no closed-form, I want to prove that . [ EDIT_2 ] It's also welcome to suggest another possible typo. I'm still waiting the various opinions, suggestions, ideas, and creative solutions of the series. Besides, I'm also wondering whether there is a typical method to prove that the given series has no closed-form. [ EDIT_3 ] Can we evaluate the series with exponents in the denominator? I recommend to skim what I've discussed so far. You don't have to reply all the questions. Thanks for your interest one more time.",\sum_{n=0}^\infty(-1)^n\frac{\cos^2({3^nx})}{3^n} \sum_{n\ge0}(-1)^n\frac{\cos^2({3^nx})}{3^n}=\sum_{n\ge0}(-1)^n\frac{1+\cos(2\cdot3^nx)}{2\cdot3^n}={1\over2}\sum_{n\ge0}\left(-{1\over3}\right)^n+\Re \sum_{n\ge0}\frac{(-1)^ne^{i\cdot2\cdot3^nx}}{2\cdot3^n} \sum_{n\ge0}\frac{(-1)^ne^{i\cdot2\cdot3^nx}}{2\cdot3^n} e \pi x n 3nx\rightarrow3^nx,"['calculus', 'sequences-and-series', 'trigonometry']"
66,How to evaluate $\int_{0}^{1}\frac{\arctan x}{x} \log{\left(\frac{ 1+ x}{\sqrt{1+x^2}}\right)}\mathrm dx$,How to evaluate,\int_{0}^{1}\frac{\arctan x}{x} \log{\left(\frac{ 1+ x}{\sqrt{1+x^2}}\right)}\mathrm dx,"How to evaluate $$\int_{0}^{1}\frac{\arctan x}{x} \log{\left(\frac{1+ x}{\sqrt{1+x^2}}\right)}\mathrm dx$$ I tried to integrate by parts, but no way so far, help me, thanks.","How to evaluate I tried to integrate by parts, but no way so far, help me, thanks.",\int_{0}^{1}\frac{\arctan x}{x} \log{\left(\frac{1+ x}{\sqrt{1+x^2}}\right)}\mathrm dx,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'harmonic-numbers']"
67,How to calculate the derivative of $\int_0^x \left(\frac{1}{t}-[\frac{1}{t}]\right)dt$ at $x=0$?,How to calculate the derivative of  at ?,\int_0^x \left(\frac{1}{t}-[\frac{1}{t}]\right)dt x=0,"Let $F(x):=\int_0^x \left(\frac{1}{t}-[\frac{1}{t}]\right)dt$ ,where $[\frac{1}{t}]$ is the largest integer no more than $\frac{1}{t}$ .Prove $F'(0)=\frac{1}{2}$ . I have tried in this way: \begin{equation} \begin{aligned} \lim_{n\to\infty}nF\left(\frac{1}{n}\right)&=\lim_{n\to\infty}n\sum_{k=n}^\infty\int_\frac{1}{k+1}^\frac{1}{k}\left(\frac{1}{t}-\left[\frac{1}{t}\right]\right)dt\\&=\lim_{n\to\infty}n\sum_{k=n}^\infty\int_\frac{1}{k+1}^\frac{1}{k}\left(\frac{1}{t}-k\right) dt\\&=\lim_{n\to\infty}n\sum_{k=n}^\infty \left(\ln(1+\frac{1}{k})-\frac{1}{k+1}\right)\\&=\lim_{n\to\infty}n\sum_{k=n}^\infty \left(\frac{1}{k}-\frac{1}{k+1}\right)\\&=1. \end{aligned} \end{equation} Please give me some ideas,thank you!","Let ,where is the largest integer no more than .Prove . I have tried in this way: Please give me some ideas,thank you!","F(x):=\int_0^x \left(\frac{1}{t}-[\frac{1}{t}]\right)dt [\frac{1}{t}] \frac{1}{t} F'(0)=\frac{1}{2} \begin{equation}
\begin{aligned}
\lim_{n\to\infty}nF\left(\frac{1}{n}\right)&=\lim_{n\to\infty}n\sum_{k=n}^\infty\int_\frac{1}{k+1}^\frac{1}{k}\left(\frac{1}{t}-\left[\frac{1}{t}\right]\right)dt\\&=\lim_{n\to\infty}n\sum_{k=n}^\infty\int_\frac{1}{k+1}^\frac{1}{k}\left(\frac{1}{t}-k\right) dt\\&=\lim_{n\to\infty}n\sum_{k=n}^\infty \left(\ln(1+\frac{1}{k})-\frac{1}{k+1}\right)\\&=\lim_{n\to\infty}n\sum_{k=n}^\infty \left(\frac{1}{k}-\frac{1}{k+1}\right)\\&=1.
\end{aligned}
\end{equation}","['calculus', 'analysis']"
68,"Integration using ""method of judicious guessing""","Integration using ""method of judicious guessing""",,"My calculus-book gives an example of integration using the method of judicious guessing. But I do not intuit the method very well. QUESTION: How does the derivative of $f_{mn}(x)$ ""suggest that we try"" $I=Px^4\left(\log {x}\right)^2 +Qx^4\log{x}+Rx^4+C$? Where does this trial formula come from? The example goes as follows: Find the derivative of $f_{mn}(x)=x^m\left(\log {x}\right)^n$ and use the result to suggest a trial formula for $I=\int x^3\left(\log {x}\right)^2dx$. Thus evaluate this integral. Solution: We have   $$f'_{mn}(x)=mx^{m-1}\left(\log {x}\right)^n+nx^{m-1}\left(\log {x}\right)^{n-1}.$$   This suggests that we try   $$I=Px^4\left(\log {x}\right)^2+Qx^4\log{x}+Rx^4+C$$   for constants $P$, $Q$, $R$ and $C$. Differentiating we get   $$\frac{dI}{dx} = 4Px^3\left(\log {x}\right)^2 + 2Px^3\log{x} + 4Qx^3\log{x} + Qx^3 + 4Rx^3 = x^3\left(\log {x}\right)^2,$$   solving for $P$, $Q$ and $R$ we arrive at the right answer:   $$\int x^3\left(\log {x}\right)^2dx=\frac{1}{4}x^4\left(\log {x}\right)^2-\frac{1}{8}x^4\log{x}+\frac{1}{32}x^4+C.$$ Please note my level of mathematics is still ""in development"": I am learning without a teacher. BACKGROUND: In my efforts I did notice the following, which also results in the right answer: $$\frac{d}{dx}x^m\left(\log {x}\right)^n=mx^{m-1}\left(\log {x}\right)^n+nx^{m-1}\left(\log {x}\right)^{n-1}.$$ Integrating both sides we get: $$x^m\left(\log {x}\right)^n=m\int x^{m-1}\left(\log {x}\right)^n dx+n\int x^{m-1}\left(\log {x}\right)^{n-1}dx.$$ Now we can define $g_{mn}(x)$ as follows: $$g_{mn}\left(x\right)=\int x^{m-1}\left(\log {x}\right)^n dx=\frac{1}{m}x^m\left(\log {x}\right)^n-\frac{n}{m}\int x^{m-1}\left(\log {x}\right)^{n-1}dx.$$ Taking $m=4$ and $n=2$ we get: \begin{align} I&=\int x^3\left(\log {x}\right)^2dx=g_{42}(x)=\frac{1}{4}x^4\left(\log {x}\right)^2-\frac{1}{2}\int x^3\log{x}\,dx\\ &=\frac{1}{4}x^4\left(\log {x}\right)^2-\frac{1}{2}g_{41}(x)=\frac{1}{4}x^4\left(\log {x}\right)^2-\frac{1}{8}x^4\log{x}+\frac{1}{32}x^4+C. \end{align}","My calculus-book gives an example of integration using the method of judicious guessing. But I do not intuit the method very well. QUESTION: How does the derivative of $f_{mn}(x)$ ""suggest that we try"" $I=Px^4\left(\log {x}\right)^2 +Qx^4\log{x}+Rx^4+C$? Where does this trial formula come from? The example goes as follows: Find the derivative of $f_{mn}(x)=x^m\left(\log {x}\right)^n$ and use the result to suggest a trial formula for $I=\int x^3\left(\log {x}\right)^2dx$. Thus evaluate this integral. Solution: We have   $$f'_{mn}(x)=mx^{m-1}\left(\log {x}\right)^n+nx^{m-1}\left(\log {x}\right)^{n-1}.$$   This suggests that we try   $$I=Px^4\left(\log {x}\right)^2+Qx^4\log{x}+Rx^4+C$$   for constants $P$, $Q$, $R$ and $C$. Differentiating we get   $$\frac{dI}{dx} = 4Px^3\left(\log {x}\right)^2 + 2Px^3\log{x} + 4Qx^3\log{x} + Qx^3 + 4Rx^3 = x^3\left(\log {x}\right)^2,$$   solving for $P$, $Q$ and $R$ we arrive at the right answer:   $$\int x^3\left(\log {x}\right)^2dx=\frac{1}{4}x^4\left(\log {x}\right)^2-\frac{1}{8}x^4\log{x}+\frac{1}{32}x^4+C.$$ Please note my level of mathematics is still ""in development"": I am learning without a teacher. BACKGROUND: In my efforts I did notice the following, which also results in the right answer: $$\frac{d}{dx}x^m\left(\log {x}\right)^n=mx^{m-1}\left(\log {x}\right)^n+nx^{m-1}\left(\log {x}\right)^{n-1}.$$ Integrating both sides we get: $$x^m\left(\log {x}\right)^n=m\int x^{m-1}\left(\log {x}\right)^n dx+n\int x^{m-1}\left(\log {x}\right)^{n-1}dx.$$ Now we can define $g_{mn}(x)$ as follows: $$g_{mn}\left(x\right)=\int x^{m-1}\left(\log {x}\right)^n dx=\frac{1}{m}x^m\left(\log {x}\right)^n-\frac{n}{m}\int x^{m-1}\left(\log {x}\right)^{n-1}dx.$$ Taking $m=4$ and $n=2$ we get: \begin{align} I&=\int x^3\left(\log {x}\right)^2dx=g_{42}(x)=\frac{1}{4}x^4\left(\log {x}\right)^2-\frac{1}{2}\int x^3\log{x}\,dx\\ &=\frac{1}{4}x^4\left(\log {x}\right)^2-\frac{1}{2}g_{41}(x)=\frac{1}{4}x^4\left(\log {x}\right)^2-\frac{1}{8}x^4\log{x}+\frac{1}{32}x^4+C. \end{align}",,"['calculus', 'integration']"
69,Smoothstep sigmoid-like function: Can anyone prove this relation?,Smoothstep sigmoid-like function: Can anyone prove this relation?,,"The Smoothstep sigmoid-like function is defined as the polynomial $$ \begin{align} \operatorname{S}_N(x) &= x^{N+1} \sum_{n=0}^{N} \binom{N+n}{n} \binom{2N+1}{N-n} (-x)^{n} \qquad N \in \mathbb{Z} \ge 0 \\                       &= \sum_{n=0}^{N}  (-1)^n \binom{N+n}{n} \binom{2N+1}{N-n} x^{N+n+1} \\                       &= \sum_{n=0}^{N}        \binom{-N-1}{n} \binom{2N+1}{N-n} x^{N+n+1} \\ \end{align} $$ The first 7 examples are: $$\begin{align} \operatorname{S}_0(x) &= x \\ \operatorname{S}_1(x) &= -2x^3 + 3x^2 \\ \operatorname{S}_2(x) &= 6x^5 - 15x^4 + 10x^3 \\ \operatorname{S}_3(x) &= -20x^7 + 70x^6 - 84x^5 + 35x^4 \\ \operatorname{S}_4(x) &= 70x^9 - 315x^8 + 540x^7 - 420x^6 + 126x^5 \\ \operatorname{S}_5(x) &= -252x^{11} + 1386x^{10} - 3080x^9 + 3465x^8 - 1980x^7 + 462x^6 \\ \operatorname{S}_6(x) &= 924x^{13} - 6006x^{12} + 16380x^{11} - 24024x^{10} + 20020x^9 - 9009x^8 + 1716x^7 \\ \\ \end{align} $$ It is purported, for all non-negative integer $N$, that $\operatorname{S}_N(0) = 0$ and $\operatorname{S}_N(1) = 1$ and, at those two points , as many derivatives equal zero as possible.  I think it is also purported that $\operatorname{S}_N(\tfrac12) = \tfrac12$ and that this polynomial display odd-symmetry about the point at $x=\tfrac12$ If we define a linearly-scaled and offset version of the Smoothstep polynomial as: $$ \operatorname{R}_N(x) = 2\operatorname{S}_N\left( \tfrac12(x+1) \right) - 1  $$ Then this means that $\operatorname{R}_N(-1) = -1$, $\operatorname{R}_N(1) = 1$, and as many derivatives as possible at those two points are zero.  And we see that $\operatorname{R}_N(0) = 0$ and that  odd-symmetry exists: $\operatorname{R}_N(-x) = -\operatorname{R}_N(x)$ Can anyone show, with the least amount of pain possible, that the derivative of $\operatorname{R}_N(x)$ becomes $$\begin{align} \operatorname{R}^{'}_{N}(x) &= \operatorname{S}^{'}_{N}\left( \tfrac12(x+1) \right)  \\ &= \left( \sum\limits_{n=0}^{N} \frac{N!}{n! (N-n)!} \frac{(-1)^n}{2n+1} \right)^{-1} (1-x^2)^{N} \qquad ? \\ \end{align}$$ This is not homework (I haven't been in skool since the early '80s). This DSP question and answer show the previous work I have done with this.  It's just a little bit bitchy and I am not sure the least painful way to go about doing this. I guess that I am trying to show that $$\begin{align} \operatorname{S}^{'}_{N}\left( \tfrac12(x+1) \right) &= \sum_{n=0}^{N} \binom{-N-1}{n}\binom{2N+1}{N-n}(N+n+1) \left(\tfrac12(x+1)\right)^{N+n}  \\ &= \left( \sum\limits_{n=0}^{N} \frac{N!}{n!(N-n)!} \frac{(-1)^n}{2n+1} \right)^{-1} (1-x^2)^{N} \\ \end{align}$$ This really looks like a copulating female canine to me. EDIT: Here is the clearest way for me to state the question: Let $x \in \mathbb{R}, \ N \ge 0 \in \mathbb{Z}$. Define: $$\begin{align}  f_N & \triangleq \int\limits_{0}^{1} \big(1 - u^2 \big)^{N} \ du \\      & = \sum\limits_{n=0}^{N} \binom{N}{n} \frac{(-1)^n}{2n+1} \\ \end{align}$$ Define: $$ \operatorname{R}_N(x) \triangleq \frac{1}{f_N} \int\limits_{0}^{x} \big(1 - u^2 \big)^{N} \ du $$ Define from the Wikipedia definition of the Smoothstep sigmoid-like function : $$\operatorname{S}_N(x) \triangleq \sum\limits_{n=0}^{N} \binom{-N-1}{n}\binom{2N+1}{N-n} x^{N+n+1} $$ Prove: $$ \operatorname{R}_N(x) = 2\operatorname{S}_N\big(\tfrac12 (x+1) \big) - 1 $$ It suffices to prove that their first derivatives of the left-hand and right-hand sides are equal, because we know the left-hand and right-hand sides are equal at $x=-1$.  This means it is sufficient to show that: $$ \frac{1}{f_N} (1-x^2)^{N} = \frac{d}{du}\,\operatorname{S}_N(u) \Bigg|_{u=\frac12 (x+1)} $$ or $$ \frac{1}{f_N} (1-x^2)^{N} = \sum_{n=0}^{N} \binom{-N-1}{n}\binom{2N+1}{N-n} (N+n+1) \left(\tfrac12(x+1)\right)^{N+n} $$ or, explicitly: $$ \left( \sum\limits_{n=0}^{N} \binom{N}{n} \frac{(-1)^n}{2n+1} \right)^{-1} (1-x^2)^{N} = \sum_{n=0}^{N} \binom{-N-1}{n}\binom{2N+1}{N-n} (N+n+1) \left(\tfrac12(x+1)\right)^{N+n} $$","The Smoothstep sigmoid-like function is defined as the polynomial $$ \begin{align} \operatorname{S}_N(x) &= x^{N+1} \sum_{n=0}^{N} \binom{N+n}{n} \binom{2N+1}{N-n} (-x)^{n} \qquad N \in \mathbb{Z} \ge 0 \\                       &= \sum_{n=0}^{N}  (-1)^n \binom{N+n}{n} \binom{2N+1}{N-n} x^{N+n+1} \\                       &= \sum_{n=0}^{N}        \binom{-N-1}{n} \binom{2N+1}{N-n} x^{N+n+1} \\ \end{align} $$ The first 7 examples are: $$\begin{align} \operatorname{S}_0(x) &= x \\ \operatorname{S}_1(x) &= -2x^3 + 3x^2 \\ \operatorname{S}_2(x) &= 6x^5 - 15x^4 + 10x^3 \\ \operatorname{S}_3(x) &= -20x^7 + 70x^6 - 84x^5 + 35x^4 \\ \operatorname{S}_4(x) &= 70x^9 - 315x^8 + 540x^7 - 420x^6 + 126x^5 \\ \operatorname{S}_5(x) &= -252x^{11} + 1386x^{10} - 3080x^9 + 3465x^8 - 1980x^7 + 462x^6 \\ \operatorname{S}_6(x) &= 924x^{13} - 6006x^{12} + 16380x^{11} - 24024x^{10} + 20020x^9 - 9009x^8 + 1716x^7 \\ \\ \end{align} $$ It is purported, for all non-negative integer $N$, that $\operatorname{S}_N(0) = 0$ and $\operatorname{S}_N(1) = 1$ and, at those two points , as many derivatives equal zero as possible.  I think it is also purported that $\operatorname{S}_N(\tfrac12) = \tfrac12$ and that this polynomial display odd-symmetry about the point at $x=\tfrac12$ If we define a linearly-scaled and offset version of the Smoothstep polynomial as: $$ \operatorname{R}_N(x) = 2\operatorname{S}_N\left( \tfrac12(x+1) \right) - 1  $$ Then this means that $\operatorname{R}_N(-1) = -1$, $\operatorname{R}_N(1) = 1$, and as many derivatives as possible at those two points are zero.  And we see that $\operatorname{R}_N(0) = 0$ and that  odd-symmetry exists: $\operatorname{R}_N(-x) = -\operatorname{R}_N(x)$ Can anyone show, with the least amount of pain possible, that the derivative of $\operatorname{R}_N(x)$ becomes $$\begin{align} \operatorname{R}^{'}_{N}(x) &= \operatorname{S}^{'}_{N}\left( \tfrac12(x+1) \right)  \\ &= \left( \sum\limits_{n=0}^{N} \frac{N!}{n! (N-n)!} \frac{(-1)^n}{2n+1} \right)^{-1} (1-x^2)^{N} \qquad ? \\ \end{align}$$ This is not homework (I haven't been in skool since the early '80s). This DSP question and answer show the previous work I have done with this.  It's just a little bit bitchy and I am not sure the least painful way to go about doing this. I guess that I am trying to show that $$\begin{align} \operatorname{S}^{'}_{N}\left( \tfrac12(x+1) \right) &= \sum_{n=0}^{N} \binom{-N-1}{n}\binom{2N+1}{N-n}(N+n+1) \left(\tfrac12(x+1)\right)^{N+n}  \\ &= \left( \sum\limits_{n=0}^{N} \frac{N!}{n!(N-n)!} \frac{(-1)^n}{2n+1} \right)^{-1} (1-x^2)^{N} \\ \end{align}$$ This really looks like a copulating female canine to me. EDIT: Here is the clearest way for me to state the question: Let $x \in \mathbb{R}, \ N \ge 0 \in \mathbb{Z}$. Define: $$\begin{align}  f_N & \triangleq \int\limits_{0}^{1} \big(1 - u^2 \big)^{N} \ du \\      & = \sum\limits_{n=0}^{N} \binom{N}{n} \frac{(-1)^n}{2n+1} \\ \end{align}$$ Define: $$ \operatorname{R}_N(x) \triangleq \frac{1}{f_N} \int\limits_{0}^{x} \big(1 - u^2 \big)^{N} \ du $$ Define from the Wikipedia definition of the Smoothstep sigmoid-like function : $$\operatorname{S}_N(x) \triangleq \sum\limits_{n=0}^{N} \binom{-N-1}{n}\binom{2N+1}{N-n} x^{N+n+1} $$ Prove: $$ \operatorname{R}_N(x) = 2\operatorname{S}_N\big(\tfrac12 (x+1) \big) - 1 $$ It suffices to prove that their first derivatives of the left-hand and right-hand sides are equal, because we know the left-hand and right-hand sides are equal at $x=-1$.  This means it is sufficient to show that: $$ \frac{1}{f_N} (1-x^2)^{N} = \frac{d}{du}\,\operatorname{S}_N(u) \Bigg|_{u=\frac12 (x+1)} $$ or $$ \frac{1}{f_N} (1-x^2)^{N} = \sum_{n=0}^{N} \binom{-N-1}{n}\binom{2N+1}{N-n} (N+n+1) \left(\tfrac12(x+1)\right)^{N+n} $$ or, explicitly: $$ \left( \sum\limits_{n=0}^{N} \binom{N}{n} \frac{(-1)^n}{2n+1} \right)^{-1} (1-x^2)^{N} = \sum_{n=0}^{N} \binom{-N-1}{n}\binom{2N+1}{N-n} (N+n+1) \left(\tfrac12(x+1)\right)^{N+n} $$",,"['calculus', 'sequences-and-series', 'polynomials', 'binomial-coefficients', 'binomial-theorem']"
70,Prove or disprove: $\sum_{k=1}^{\infty}\frac{\sqrt{k+1}-\sqrt{k}}{k\sqrt{k}}$ is convergent,Prove or disprove:  is convergent,\sum_{k=1}^{\infty}\frac{\sqrt{k+1}-\sqrt{k}}{k\sqrt{k}},"Prove or disprove: The following series is convergent $$\sum_{k=1}^{\infty}\frac{\sqrt{k+1}-\sqrt{k}}{k\sqrt{k}}$$ $$\frac{\sqrt{k+1}-\sqrt{k}}{k\sqrt{k}}= \frac{\left(\sqrt{k+1}-\sqrt{k}\right)\cdot \left(\sqrt{k+1} + \sqrt{k}\right)}{k\sqrt{k} \cdot \left(\sqrt{k+1} + \sqrt{k}\right)}= \frac{k+1-k}{k\sqrt{k} \cdot \left(\sqrt{k+1}+\sqrt{k}\right)}$$ $$=\frac{1}{k\sqrt{k} \cdot \left(\sqrt{k+1}+\sqrt{k}\right)}=\frac{1}{\left(k\sqrt{k}\right)\cdot \left(\sqrt{k+1}\right)+k\sqrt{k}\cdot\sqrt{k}}= \frac{1}{k\sqrt{k}\cdot \left(\sqrt{k+1}\right)+k^{2}}< \frac{1}{k^{2}}$$ $$\Rightarrow\sum_{k=1}^{\infty}\frac{1}{k^{2}}$$ This is a convergent series and thus the original series is convergent as well. Did I do everything correcty (I'm especially not sure about the last step where I used ""<"")? Is there another way of proofing convergence here without that much work? I have tried ratio test too but it got so complicated and I couldn't solve it","Prove or disprove: The following series is convergent $$\sum_{k=1}^{\infty}\frac{\sqrt{k+1}-\sqrt{k}}{k\sqrt{k}}$$ $$\frac{\sqrt{k+1}-\sqrt{k}}{k\sqrt{k}}= \frac{\left(\sqrt{k+1}-\sqrt{k}\right)\cdot \left(\sqrt{k+1} + \sqrt{k}\right)}{k\sqrt{k} \cdot \left(\sqrt{k+1} + \sqrt{k}\right)}= \frac{k+1-k}{k\sqrt{k} \cdot \left(\sqrt{k+1}+\sqrt{k}\right)}$$ $$=\frac{1}{k\sqrt{k} \cdot \left(\sqrt{k+1}+\sqrt{k}\right)}=\frac{1}{\left(k\sqrt{k}\right)\cdot \left(\sqrt{k+1}\right)+k\sqrt{k}\cdot\sqrt{k}}= \frac{1}{k\sqrt{k}\cdot \left(\sqrt{k+1}\right)+k^{2}}< \frac{1}{k^{2}}$$ $$\Rightarrow\sum_{k=1}^{\infty}\frac{1}{k^{2}}$$ This is a convergent series and thus the original series is convergent as well. Did I do everything correcty (I'm especially not sure about the last step where I used ""<"")? Is there another way of proofing convergence here without that much work? I have tried ratio test too but it got so complicated and I couldn't solve it",,"['calculus', 'sequences-and-series', 'analysis', 'convergence-divergence']"
71,How to prove that $\int_{0}^{1}\ln{(x/(1-x))}\ln{(1+x-x^2)}\frac{dx}{x}=-\frac{2}{5}\zeta{(3)}$,How to prove that,\int_{0}^{1}\ln{(x/(1-x))}\ln{(1+x-x^2)}\frac{dx}{x}=-\frac{2}{5}\zeta{(3)},"$$\int_{0}^{1}\ln{\big(\frac{x}{1-x}\big)}\ln{(1+x-x^2)}\frac{dx}{x}=-\frac{2}{5}\zeta{(3)}$$ Put  $$\frac{x}{1-x}=y$$  $$I=\int_{0}^{\infty}\ln{y}\ln{(1+3y+y^2)}\frac{dy}{y(y+1)}=\frac{8}{5}\zeta{(3)}$$  Simple integral at first sight, however I cannot prove that. I would appreciate your help.","$$\int_{0}^{1}\ln{\big(\frac{x}{1-x}\big)}\ln{(1+x-x^2)}\frac{dx}{x}=-\frac{2}{5}\zeta{(3)}$$ Put  $$\frac{x}{1-x}=y$$  $$I=\int_{0}^{\infty}\ln{y}\ln{(1+3y+y^2)}\frac{dy}{y(y+1)}=\frac{8}{5}\zeta{(3)}$$  Simple integral at first sight, however I cannot prove that. I would appreciate your help.",,"['calculus', 'integration', 'definite-integrals']"
72,"Closed form for ${\large\int}_0^\infty\frac{\arctan(x)\,\operatorname{arccot}(x+1)}{x}dx$",Closed form for,"{\large\int}_0^\infty\frac{\arctan(x)\,\operatorname{arccot}(x+1)}{x}dx","I'm looking for a closed form for this integral: $$I=\int_0^\infty\frac{\arctan(x)\,\operatorname{arccot}(x+1)}{x}dx.$$ Mathematica and Maple could not evaluate it symbolically. Numerically, $$I\approx1.3513049368715095284050230093075694014884142059538...$$ WolframAlpha and ISC+ could not find a plausible closed form for this number. Still, I hope that it exists, because the integral looks nice.","I'm looking for a closed form for this integral: $$I=\int_0^\infty\frac{\arctan(x)\,\operatorname{arccot}(x+1)}{x}dx.$$ Mathematica and Maple could not evaluate it symbolically. Numerically, $$I\approx1.3513049368715095284050230093075694014884142059538...$$ WolframAlpha and ISC+ could not find a plausible closed form for this number. Still, I hope that it exists, because the integral looks nice.",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'trigonometry']"
73,$\int_{0}^{\pi/2}\ln\left(1+4\sin^4 x\right)\mathrm{d}x$ and the golden ratio,and the golden ratio,\int_{0}^{\pi/2}\ln\left(1+4\sin^4 x\right)\mathrm{d}x,"We already know that, for any real number $t$ such that $t\geq-1$, $$ \int_{0}^{\pi/2} \ln \left(1+t \sin^2 x\right) \mathrm{d}x = \pi \ln \left( \frac{1+\sqrt{1+t}}{2} \right). $$ Prove that $$ \int_{0}^{\pi/2} \ln \left(1+4\sin^4 x\right) \mathrm{d}x = \pi \ln \left( \frac{\varphi+\sqrt{\varphi}}{2} \right) $$    where $\displaystyle \varphi = \frac{1+\sqrt{5}}{2}$ is the golden ratio.","We already know that, for any real number $t$ such that $t\geq-1$, $$ \int_{0}^{\pi/2} \ln \left(1+t \sin^2 x\right) \mathrm{d}x = \pi \ln \left( \frac{1+\sqrt{1+t}}{2} \right). $$ Prove that $$ \int_{0}^{\pi/2} \ln \left(1+4\sin^4 x\right) \mathrm{d}x = \pi \ln \left( \frac{\varphi+\sqrt{\varphi}}{2} \right) $$    where $\displaystyle \varphi = \frac{1+\sqrt{5}}{2}$ is the golden ratio.",,"['calculus', 'integration', 'definite-integrals', 'logarithms', 'golden-ratio']"
74,How to prove this limit exists: $a_{n+2}=\sqrt{a_{n+1}}+\sqrt{a_{n}}$,How to prove this limit exists:,a_{n+2}=\sqrt{a_{n+1}}+\sqrt{a_{n}},"Question: Consider a sequence $\{a_{n}\}$ such that $a_{1},a_{2}>0$ , and for all $n \in \mathbb{N}$ we have: $$a_{n+2}=\sqrt{a_{n+1}}+\sqrt{a_{n}}$$ Prove that : $\displaystyle\lim_{n\to\infty}a_{n}$ exists and find this limit. My work: If this limit exists, let $\displaystyle\lim_{n\to\infty}a_{n}=x>0$ ; then we have $$x=\sqrt{x}+\sqrt{x}\Longrightarrow x=4$$ But I can't see how to prove the limit of $\{a_{n}\}$ exists. Thank you for you help!","Question: Consider a sequence such that , and for all we have: Prove that : exists and find this limit. My work: If this limit exists, let ; then we have But I can't see how to prove the limit of exists. Thank you for you help!","\{a_{n}\} a_{1},a_{2}>0 n \in \mathbb{N} a_{n+2}=\sqrt{a_{n+1}}+\sqrt{a_{n}} \displaystyle\lim_{n\to\infty}a_{n} \displaystyle\lim_{n\to\infty}a_{n}=x>0 x=\sqrt{x}+\sqrt{x}\Longrightarrow x=4 \{a_{n}\}",['calculus']
75,What was the largest ratio (result size)/(integrand size) you have seen?,What was the largest ratio (result size)/(integrand size) you have seen?,,"Sometimes a definite or indefinite integral of a simple-looking one-liner integrand can give astonishingly huge result. What was the largest ratio of the size of shortest known closed-form result to the size of the corresponding integrand you have seen? I am particularly interested in unexpectedly large results, not those, for example, that occur from an intentionally large exponent in the integrand or otherwise obviously tailored for that purpose.","Sometimes a definite or indefinite integral of a simple-looking one-liner integrand can give astonishingly huge result. What was the largest ratio of the size of shortest known closed-form result to the size of the corresponding integrand you have seen? I am particularly interested in unexpectedly large results, not those, for example, that occur from an intentionally large exponent in the integrand or otherwise obviously tailored for that purpose.",,"['calculus', 'integration', 'soft-question', 'definite-integrals', 'big-list']"
76,Evaluate $\int_0^1 \frac{\ln(1+bx)}{1+x} dx $,Evaluate,\int_0^1 \frac{\ln(1+bx)}{1+x} dx ,"What is $ \displaystyle\int_0^1 \frac{\ln(1+bx)}{1+x} dx $? I call it $f(b)$ and differentiate with respect to be $b,$ a bit of partial fractions and the $x$ integral can be done. Then I integrate with respect to $b$ and get a bit lost. Can some of the terms be expressed in terms of dilogarithms? I get lost in the details! Could we avoid all this just go straight to dilogarithms (with a cunning substitution)?","What is $ \displaystyle\int_0^1 \frac{\ln(1+bx)}{1+x} dx $? I call it $f(b)$ and differentiate with respect to be $b,$ a bit of partial fractions and the $x$ integral can be done. Then I integrate with respect to $b$ and get a bit lost. Can some of the terms be expressed in terms of dilogarithms? I get lost in the details! Could we avoid all this just go straight to dilogarithms (with a cunning substitution)?",,"['calculus', 'integration', 'special-functions']"
77,Is using L'Hospital's Rule to prove $\lim \limits_{x \to 0} \sin{x}/x$ circular? [duplicate],Is using L'Hospital's Rule to prove  circular? [duplicate],\lim \limits_{x \to 0} \sin{x}/x,"This question already has answers here : L'Hopital's rule and $\frac{\sin x}x$ (5 answers) Closed 4 years ago . If  $\frac{d(\sin{x})}{dx}= \cos{x}$  is proven using the limit $\lim \limits_{x \to 0}\frac{\sin{x}}{x}=1$ (as it is in most textbooks), would it be circular to then use $\frac{d(\sin{x})}{dx}= {\cos{x}}$ and L'Hospital to prove the limit $\lim \limits_{x \to 0}\frac{\sin{x}}{x}=1$ (because limit $\lim \limits_{x \to 0}\frac{\sin{x}}{x}= \frac{\cos{0}}{1})$ later in the same textbook?","This question already has answers here : L'Hopital's rule and $\frac{\sin x}x$ (5 answers) Closed 4 years ago . If  $\frac{d(\sin{x})}{dx}= \cos{x}$  is proven using the limit $\lim \limits_{x \to 0}\frac{\sin{x}}{x}=1$ (as it is in most textbooks), would it be circular to then use $\frac{d(\sin{x})}{dx}= {\cos{x}}$ and L'Hospital to prove the limit $\lim \limits_{x \to 0}\frac{\sin{x}}{x}=1$ (because limit $\lim \limits_{x \to 0}\frac{\sin{x}}{x}= \frac{\cos{0}}{1})$ later in the same textbook?",,['calculus']
78,Derivative of Mean Squared Error,Derivative of Mean Squared Error,,"I'm studying with a book and I'm at the Linear Regression part. The author is showing that we have to calculate the derivative of each part of the equation that leads to the loss. But he's using the MSE to calculate the loss and so, I tried to calculate the derivative of MSE: the derivative of $ (y-p)^2 $ with respect to y (the target) is equal to $2(y-p)$ but  in the book it is written $-1*(2(y-p))$ which is simplified as $-2(y-p)$ . Why do I have different values ? Where is this $-1$ coming from?","I'm studying with a book and I'm at the Linear Regression part. The author is showing that we have to calculate the derivative of each part of the equation that leads to the loss. But he's using the MSE to calculate the loss and so, I tried to calculate the derivative of MSE: the derivative of with respect to y (the target) is equal to but  in the book it is written which is simplified as . Why do I have different values ? Where is this coming from?", (y-p)^2  2(y-p) -1*(2(y-p)) -2(y-p) -1,"['calculus', 'machine-learning', 'linear-regression', 'neural-networks']"
79,Does $\int_0^\infty\frac{\ln(1+x)}{x(1+x^n)}dx$ have a general form?,Does  have a general form?,\int_0^\infty\frac{\ln(1+x)}{x(1+x^n)}dx,"Does $$I_n=\int_0^\infty\frac{\ln(1+x)}{x(1+x^n)}dx$$ have a general form? I tried to evaluate some small $n$ s. For $n=1$ , $I_1$ is obviously $\frac16\pi^2$ . For $n=2$ , see here . $I_2=\frac5{48}\pi^2$ . For $n=3$ , I put it in Mathematica and get $$\small{\frac{1}{108} \left(9 \left(4 \left(\text{Li}_2\left(\frac{\sqrt[6]{-1}}{\sqrt{3}}\right)+\text{Li}_2\left(-\frac{(-1)^{5/6}}{\sqrt{3}}\right)\right)+\log ^2(3)\right)+5 \pi ^2\right)}$$ Use the result $$\Re\operatorname{Li}_2\left(\frac{1+ti}2\right)=\frac1{12}\pi^2-\frac12\arctan^2t-\frac18\ln^2\frac{1+t^2}4,$$ I'm able to show $I_3=\frac5{54}\pi^2$ . For $n=4$ , I numerically found $I_4=\frac{17}{192}\pi^2$ . I'm not able to find the general form with $n\in \mathbb{Z}^+$ .","Does have a general form? I tried to evaluate some small s. For , is obviously . For , see here . . For , I put it in Mathematica and get Use the result I'm able to show . For , I numerically found . I'm not able to find the general form with .","I_n=\int_0^\infty\frac{\ln(1+x)}{x(1+x^n)}dx n n=1 I_1 \frac16\pi^2 n=2 I_2=\frac5{48}\pi^2 n=3 \small{\frac{1}{108} \left(9 \left(4 \left(\text{Li}_2\left(\frac{\sqrt[6]{-1}}{\sqrt{3}}\right)+\text{Li}_2\left(-\frac{(-1)^{5/6}}{\sqrt{3}}\right)\right)+\log ^2(3)\right)+5 \pi ^2\right)} \Re\operatorname{Li}_2\left(\frac{1+ti}2\right)=\frac1{12}\pi^2-\frac12\arctan^2t-\frac18\ln^2\frac{1+t^2}4, I_3=\frac5{54}\pi^2 n=4 I_4=\frac{17}{192}\pi^2 n\in \mathbb{Z}^+","['calculus', 'integration', 'definite-integrals']"
80,Can endpoints be local minimum?,Can endpoints be local minimum?,,"My textbook defines local maximum as follows: A function $f$ has local maximum value at point $c$ within its   domain $D$ if $f(x)\leq f(c)$ for all $x$ in its domain lying in some   open interval containing $c$ . The question asks to find any local maximum or minimum values in the function $$g(x)=x^2-4x+4$$ in the domain $1\leq x<+\infty$ . The answer at the back has the point $(1,1)$ , which is the endpoint. According to the definition given in the textbook, I would think endpoints cannot be local minimum or maximum given that they cannot be in an open interval containing themselves. (ex: the open interval $(1,3)$ does not contain $1$ ). Where am I wrong?","My textbook defines local maximum as follows: A function has local maximum value at point within its   domain if for all in its domain lying in some   open interval containing . The question asks to find any local maximum or minimum values in the function in the domain . The answer at the back has the point , which is the endpoint. According to the definition given in the textbook, I would think endpoints cannot be local minimum or maximum given that they cannot be in an open interval containing themselves. (ex: the open interval does not contain ). Where am I wrong?","f c D f(x)\leq f(c) x c g(x)=x^2-4x+4 1\leq x<+\infty (1,1) (1,3) 1",['calculus']
81,"A reason for the value of $\int_{0}^{1}\log{(x)}\log{(1-x)}\,\mathrm{d}x$",A reason for the value of,"\int_{0}^{1}\log{(x)}\log{(1-x)}\,\mathrm{d}x","In this .pdf document, which is just a list of Putnam-style undergraduate-level problems from various sources, the third question is as I have stated it below (up to a change of notation). Evaluate $$I=\int_{0}^{1}\log{(x)}\log{(1-x)}\,\mathrm{d}x.$$ Feel free to take a moment to try to solve this yourself, if you have never seen it before. My answer is as follows. In the interval $(0,1)$, we may expand $\log{(1-x)}$ as a power series:  \begin{eqnarray*} \log{(1-x)} & = & -\left(x+\frac{x^{2}}{2}+\frac{x^{3}}{3}+\ldots+\frac{x^{r}}{r}+\ldots\right)\\ & = & -\sum_{k=0}^{\infty}\frac{x^{k}}{k} \end{eqnarray*} Now for any $p\in\mathbb{N}$, using integration by parts we see that $$\int_{0}^{1}x^{p}\log{x}\,\mathrm{d}x = -\frac{1}{(p+1)^{2}}.$$ Combining the above results, we have: \begin{eqnarray*} \int_{0}^{1}\log{(x)}\log{(1-x)}\,\mathrm{d}x & = & \int_{0}^{1}\log{(x)}\left[-\sum_{k=1}^{\infty}\frac{x^{k}}{k}\right]\,\mathrm{d}x\\ & = & -\sum_{k=1}^{\infty}\frac{1}{k}\left[\int_{0}^{1}x^{k}\log{x}\,\mathrm{d}x\right]\\ & = & \sum_{k=1}^{\infty}\frac{1}{k(k+1)^{2}}\\ & = & \sum_{k=1}^{\infty}\left[\frac{1}{k(k+1)}-\frac{1}{(k+1)^{2}}\right]\\ & = & \sum_{k=1}^{\infty}\frac{1}{k(k+1)}-\sum_{k=1}^{\infty}\frac{1}{(k+1)^{2}}\\ & = & 1-(\frac{\pi^{2}}{6}-1)\\ & = & 2-\frac{\pi^{2}}{6}, \end{eqnarray*} where we have evaluated one of the two series at the end via a telescoping sum, the details of which I have left out, and the value of the other series is well-known. I found the result surprising. I performed a small sanity check by attempting to sketch the graph within the interval; Wolfram|Alpha agrees with my sketch and agrees with my answer, but, to me at least, this information is uninformative about why the result is true. To be more precise, I don't understand how or why the answer relates to the original elements of the question. My question : Is there any reason why one would expect $\pi$ to appear in this answer? Is there some tricky change of variables or some unbeknownst-to-me complex analysis way of evaluating this integral which sheds more light on the relation between it and $\zeta(2)$? With this in mind, I should also be precise about what I am accepting as an answer: T's & C's : If no such ""deeper relation"" between question and answer is apparent to anyone at all , then I will accept ""it's just a coincidence"" as an answer. If a connection is apparent to somebody, but it involves mathematics that you fear may be beyond me, feel free to post it anyway if you wish, and I'll do my best to understand what you've said. By a ""deeper relation"", I mean any interpretation or rephrasing of the question into terms beyond elementary calculus; other areas of mathematics, or even physical interpretations, will do. Other integrals which are surprising in a similar way may also be helpful.","In this .pdf document, which is just a list of Putnam-style undergraduate-level problems from various sources, the third question is as I have stated it below (up to a change of notation). Evaluate $$I=\int_{0}^{1}\log{(x)}\log{(1-x)}\,\mathrm{d}x.$$ Feel free to take a moment to try to solve this yourself, if you have never seen it before. My answer is as follows. In the interval $(0,1)$, we may expand $\log{(1-x)}$ as a power series:  \begin{eqnarray*} \log{(1-x)} & = & -\left(x+\frac{x^{2}}{2}+\frac{x^{3}}{3}+\ldots+\frac{x^{r}}{r}+\ldots\right)\\ & = & -\sum_{k=0}^{\infty}\frac{x^{k}}{k} \end{eqnarray*} Now for any $p\in\mathbb{N}$, using integration by parts we see that $$\int_{0}^{1}x^{p}\log{x}\,\mathrm{d}x = -\frac{1}{(p+1)^{2}}.$$ Combining the above results, we have: \begin{eqnarray*} \int_{0}^{1}\log{(x)}\log{(1-x)}\,\mathrm{d}x & = & \int_{0}^{1}\log{(x)}\left[-\sum_{k=1}^{\infty}\frac{x^{k}}{k}\right]\,\mathrm{d}x\\ & = & -\sum_{k=1}^{\infty}\frac{1}{k}\left[\int_{0}^{1}x^{k}\log{x}\,\mathrm{d}x\right]\\ & = & \sum_{k=1}^{\infty}\frac{1}{k(k+1)^{2}}\\ & = & \sum_{k=1}^{\infty}\left[\frac{1}{k(k+1)}-\frac{1}{(k+1)^{2}}\right]\\ & = & \sum_{k=1}^{\infty}\frac{1}{k(k+1)}-\sum_{k=1}^{\infty}\frac{1}{(k+1)^{2}}\\ & = & 1-(\frac{\pi^{2}}{6}-1)\\ & = & 2-\frac{\pi^{2}}{6}, \end{eqnarray*} where we have evaluated one of the two series at the end via a telescoping sum, the details of which I have left out, and the value of the other series is well-known. I found the result surprising. I performed a small sanity check by attempting to sketch the graph within the interval; Wolfram|Alpha agrees with my sketch and agrees with my answer, but, to me at least, this information is uninformative about why the result is true. To be more precise, I don't understand how or why the answer relates to the original elements of the question. My question : Is there any reason why one would expect $\pi$ to appear in this answer? Is there some tricky change of variables or some unbeknownst-to-me complex analysis way of evaluating this integral which sheds more light on the relation between it and $\zeta(2)$? With this in mind, I should also be precise about what I am accepting as an answer: T's & C's : If no such ""deeper relation"" between question and answer is apparent to anyone at all , then I will accept ""it's just a coincidence"" as an answer. If a connection is apparent to somebody, but it involves mathematics that you fear may be beyond me, feel free to post it anyway if you wish, and I'll do my best to understand what you've said. By a ""deeper relation"", I mean any interpretation or rephrasing of the question into terms beyond elementary calculus; other areas of mathematics, or even physical interpretations, will do. Other integrals which are surprising in a similar way may also be helpful.",,"['calculus', 'integration', 'definite-integrals', 'soft-question', 'logarithms']"
82,How can I find the fixed points of a function?,How can I find the fixed points of a function?,,"Using calculus, I want to determine all the fixed points of the function $f^3$ where $f$ is given by: $$ f:[0,1]\rightarrow[0,1];\;f(x)=4x(1-x) $$ and such that those fixed points are not fixed points of the functions $f^2$ and $f$ .  If we can not determine them explicitly, are there any argument to justify that such points exist? Thanks in advance.","Using calculus, I want to determine all the fixed points of the function where is given by: and such that those fixed points are not fixed points of the functions and .  If we can not determine them explicitly, are there any argument to justify that such points exist? Thanks in advance.","f^3 f 
f:[0,1]\rightarrow[0,1];\;f(x)=4x(1-x)
 f^2 f","['calculus', 'analysis', 'functions', 'fixed-point-theorems']"
83,"Having fun integral $\int_0^{\pi/4} \cos x \arctan(\cos x)\, dx$",Having fun integral,"\int_0^{\pi/4} \cos x \arctan(\cos x)\, dx","Playing around with the inverse trigonometric function integration, I found a nice closed-form of the following integral $$\int_0^{\pi/4} \cos x \arctan(\cos x)\, dx=\frac{3\sqrt{2}-1}{4}\pi-\frac{3\sqrt{2}}{2}\arctan\sqrt{2}$$ which numerically agrees with output of Wolfram Alpha. I am wondering, what is the nicest way ( or the most complicated way) to obtain the given result. I would love to see how Mathematics SE users prove it. Any method is welcome. Thank you. (>‿◠)✌","Playing around with the inverse trigonometric function integration, I found a nice closed-form of the following integral $$\int_0^{\pi/4} \cos x \arctan(\cos x)\, dx=\frac{3\sqrt{2}-1}{4}\pi-\frac{3\sqrt{2}}{2}\arctan\sqrt{2}$$ which numerically agrees with output of Wolfram Alpha. I am wondering, what is the nicest way ( or the most complicated way) to obtain the given result. I would love to see how Mathematics SE users prove it. Any method is welcome. Thank you. (>‿◠)✌",,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'alternative-proof']"
84,Indefinite integral. Where is the mistake?,Indefinite integral. Where is the mistake?,,"The problem was to compute $I=\int x^2\sin^{-1}(x)\ dx$ (where $\sin^{-1}(x)$ is the inverse function of $\sin(x)$). The answer of my students: firstly, we put $u=\sin^{-1}(x)$, so $x=\sin(u)$ and $dx=\cos(u)\ du$. Thus, the given integral is $$I=\int u\cos(u)\sin^2(u)\ du$$ Now, we do the substitution $v=\pi-u$, so $dv=-du$ and  $$I=-\int (\pi-v)\cos(\pi-v)\sin^2(\pi-v)\ dv$$ Since $\cos(\pi-v)=-\cos(v)$ and $\sin(\pi-v)=\sin(v)$, it follows that $$I=\int (\pi-v)\cos(v)\sin^2(v)\ dv$$ As a consequence, $$I=\int\pi\cos(v)\sin^2(v)\ dv-I=\frac{\pi\sin^3(v)}{3}-I=\frac{\pi x^3}{3}-I$$. Finally, $$I=\frac{\pi x^3}{6}+C$$ This result is obviously false but where is the mistake? My only guess is that $u\in(-\frac{\pi}{2},\frac{\pi}{2})$ and $u\in(\frac{\pi}{2},\frac{3\pi}{2})$, so $\int v\cos(v)\sin^2(v)\ dv$ is not equal to $I$ but I am not totally convinced.","The problem was to compute $I=\int x^2\sin^{-1}(x)\ dx$ (where $\sin^{-1}(x)$ is the inverse function of $\sin(x)$). The answer of my students: firstly, we put $u=\sin^{-1}(x)$, so $x=\sin(u)$ and $dx=\cos(u)\ du$. Thus, the given integral is $$I=\int u\cos(u)\sin^2(u)\ du$$ Now, we do the substitution $v=\pi-u$, so $dv=-du$ and  $$I=-\int (\pi-v)\cos(\pi-v)\sin^2(\pi-v)\ dv$$ Since $\cos(\pi-v)=-\cos(v)$ and $\sin(\pi-v)=\sin(v)$, it follows that $$I=\int (\pi-v)\cos(v)\sin^2(v)\ dv$$ As a consequence, $$I=\int\pi\cos(v)\sin^2(v)\ dv-I=\frac{\pi\sin^3(v)}{3}-I=\frac{\pi x^3}{3}-I$$. Finally, $$I=\frac{\pi x^3}{6}+C$$ This result is obviously false but where is the mistake? My only guess is that $u\in(-\frac{\pi}{2},\frac{\pi}{2})$ and $u\in(\frac{\pi}{2},\frac{3\pi}{2})$, so $\int v\cos(v)\sin^2(v)\ dv$ is not equal to $I$ but I am not totally convinced.",,"['calculus', 'fake-proofs']"
85,prove $f(x)$ has at least $2n$ roots,prove  has at least  roots,f(x) 2n,"Let $f(x)$ be continuous function in $(0,\pi)$,for any integer $k$ where $1\leq k\leq n$,we have $$ \int_{0}^{\pi}f(x)\cos kxdx=\int_{0}^{\pi}f(x)\sin kxdx=0 $$ Prove that:$f(x)$ has at least $2n$ roots on $(0,\pi)$. I can only solve the cases when $n=1$,Can anyone help me? Thank you very much!","Let $f(x)$ be continuous function in $(0,\pi)$,for any integer $k$ where $1\leq k\leq n$,we have $$ \int_{0}^{\pi}f(x)\cos kxdx=\int_{0}^{\pi}f(x)\sin kxdx=0 $$ Prove that:$f(x)$ has at least $2n$ roots on $(0,\pi)$. I can only solve the cases when $n=1$,Can anyone help me? Thank you very much!",,['calculus']
86,Axiomatic approach to differential calculus?,Axiomatic approach to differential calculus?,,"Normally we develop differential calculus by defining a derivative constructively as something related to a quotient (maybe an $\epsilon$-$\delta$-style limit of a quotient, or maybe the standard part of a $dy/dx$ quotient in NSA). I've been toying with the idea of developing the subject axiomatically instead. It seems like the following axioms allow me to do a reasonable amount of calculus: Z. $\exists f : f'\ne 0$ U. $1'=0$ A. $(f+g)'=f'+g'$ C. $(g \circ f)'=(g'\circ f)f'$ P. $(fg)'=f'g+g'f$ (I'm leaving out the obvious $\forall f \forall g$ on most of these.) For example, I can prove that $(cf)'=cf'$ for any rational number $c$, and that $(x^c)'=cx^{c-1}$ if $c$ is rational, at points where $x^{c-1}$ is defined. I think I can also prove the right result for, e.g., $x^\sqrt{2}$, since $(x^\sqrt{2})^\sqrt{2}=x^2$. Some things I haven't figured out: (1) It's not obvious to me how one could start from this system and make contact with the usual constructive approaches and with transcendental functions. (2) Does it follow from these axioms that the derivative is local? Maybe issues 1 and 2 above tell us that we need another axiom relating to continuity or something...? Although I can't figure out how to prove P from the other axioms, I also can't figure out how to construct a model in which P fails, so it's not clear to me whether P is independent of the others. Can anyone construct such a model? The system fails, as it should, to prove that a derivative exists at a point where the standard treatment of calculus says the function is nondifferentiable. On the other hand, none of the axioms allow us to prove affirmatively that any function is ever nondifferentiable.","Normally we develop differential calculus by defining a derivative constructively as something related to a quotient (maybe an $\epsilon$-$\delta$-style limit of a quotient, or maybe the standard part of a $dy/dx$ quotient in NSA). I've been toying with the idea of developing the subject axiomatically instead. It seems like the following axioms allow me to do a reasonable amount of calculus: Z. $\exists f : f'\ne 0$ U. $1'=0$ A. $(f+g)'=f'+g'$ C. $(g \circ f)'=(g'\circ f)f'$ P. $(fg)'=f'g+g'f$ (I'm leaving out the obvious $\forall f \forall g$ on most of these.) For example, I can prove that $(cf)'=cf'$ for any rational number $c$, and that $(x^c)'=cx^{c-1}$ if $c$ is rational, at points where $x^{c-1}$ is defined. I think I can also prove the right result for, e.g., $x^\sqrt{2}$, since $(x^\sqrt{2})^\sqrt{2}=x^2$. Some things I haven't figured out: (1) It's not obvious to me how one could start from this system and make contact with the usual constructive approaches and with transcendental functions. (2) Does it follow from these axioms that the derivative is local? Maybe issues 1 and 2 above tell us that we need another axiom relating to continuity or something...? Although I can't figure out how to prove P from the other axioms, I also can't figure out how to construct a model in which P fails, so it's not clear to me whether P is independent of the others. Can anyone construct such a model? The system fails, as it should, to prove that a derivative exists at a point where the standard treatment of calculus says the function is nondifferentiable. On the other hand, none of the axioms allow us to prove affirmatively that any function is ever nondifferentiable.",,['calculus']
87,Modified Intermediate Theorem Implies Continuity... Counterexample to Question from Spivak,Modified Intermediate Theorem Implies Continuity... Counterexample to Question from Spivak,,"Question 13b of chapter 7 in Spivak's Calculus (which I've been slowly working through over the last few months) says this: 'Suppose that f satisfies the conclusion of the Intermediate Value Theorem, and that f takes on each value only once . Prove that f is continuous.' What I think he means by this is that if, for some $f$ defined on [a,b] and for all $u$, if $f(a)\leq u \leq f(b)$, then there is one and only one $c$ in $[a,b]$ such that $f(c) = u$. If this is true then $f$ is continuous. I spent a few minutes trying to prove this, but in the end created a 'counterexample'. Right now I'm just wondering where I've gone wrong... $$  f(x) =   \begin{cases}    x+\frac{1}{2} & \text{if } 0 \leq x \leq\frac{1}{2} \\    1-x       & \text{if } \frac{1}{2} < x \leq 1   \end{cases} $$ $f$ is not continuous on $[0,1]$ but the IVT definitely holds over this interval and, furthermore, there's a 1-1 correspondence between $x$ values and $f(x)$ values over this interval. Where have I gone wrong??? Thanks","Question 13b of chapter 7 in Spivak's Calculus (which I've been slowly working through over the last few months) says this: 'Suppose that f satisfies the conclusion of the Intermediate Value Theorem, and that f takes on each value only once . Prove that f is continuous.' What I think he means by this is that if, for some $f$ defined on [a,b] and for all $u$, if $f(a)\leq u \leq f(b)$, then there is one and only one $c$ in $[a,b]$ such that $f(c) = u$. If this is true then $f$ is continuous. I spent a few minutes trying to prove this, but in the end created a 'counterexample'. Right now I'm just wondering where I've gone wrong... $$  f(x) =   \begin{cases}    x+\frac{1}{2} & \text{if } 0 \leq x \leq\frac{1}{2} \\    1-x       & \text{if } \frac{1}{2} < x \leq 1   \end{cases} $$ $f$ is not continuous on $[0,1]$ but the IVT definitely holds over this interval and, furthermore, there's a 1-1 correspondence between $x$ values and $f(x)$ values over this interval. Where have I gone wrong??? Thanks",,"['calculus', 'analysis']"
88,integration of a function,integration of a function,,"I found this explanation in a journal paper but I could not understand it. Can someone give me an explanation or possibly a proof that: If $$\frac{\mathrm{d}V(t)}{\mathrm{d}t}=\sqrt{2}\sum_{h=1}^{H}h\omega V_{h}\cos\left(h\omega t+\frac{\pi }{2}\right),$$ then why integration over whole period is: $$\frac{1}{T}\int_{0}^{T}  \left( \frac{\mathrm{d} V(t)}{\mathrm{d} t}  \right)^{2}dt=\omega \sum_{h=1}^{H}h^{2}V_{h}^{2}.$$ I have problem with the power of $\omega$; my solution returns $\omega^2$, while the power of $\omega$ in answer is one. Here is my solution: $$\frac{1}{T}\int_{0}^{T}\ \left( \frac{dV}{dt} \right)^{2}dt=\frac{2\omega ^{2}}{T}\int_{0}^{T}\sum_{h=1}^{H}h^{2}V_{h}^{2}\sin^{2}(h\omega t)dt$$ and over whole period: $$\frac{1}{T}\int_{0}^{T}\sin^{2}(h\omega t)dt=\frac{1}{2}$$ then we will have  $$\omega ^{2}\sum h^{2}V_{h}^{2} $$ not $$\omega \sum h^{2}V_{h}^{2}$$ Why?","I found this explanation in a journal paper but I could not understand it. Can someone give me an explanation or possibly a proof that: If $$\frac{\mathrm{d}V(t)}{\mathrm{d}t}=\sqrt{2}\sum_{h=1}^{H}h\omega V_{h}\cos\left(h\omega t+\frac{\pi }{2}\right),$$ then why integration over whole period is: $$\frac{1}{T}\int_{0}^{T}  \left( \frac{\mathrm{d} V(t)}{\mathrm{d} t}  \right)^{2}dt=\omega \sum_{h=1}^{H}h^{2}V_{h}^{2}.$$ I have problem with the power of $\omega$; my solution returns $\omega^2$, while the power of $\omega$ in answer is one. Here is my solution: $$\frac{1}{T}\int_{0}^{T}\ \left( \frac{dV}{dt} \right)^{2}dt=\frac{2\omega ^{2}}{T}\int_{0}^{T}\sum_{h=1}^{H}h^{2}V_{h}^{2}\sin^{2}(h\omega t)dt$$ and over whole period: $$\frac{1}{T}\int_{0}^{T}\sin^{2}(h\omega t)dt=\frac{1}{2}$$ then we will have  $$\omega ^{2}\sum h^{2}V_{h}^{2} $$ not $$\omega \sum h^{2}V_{h}^{2}$$ Why?",,"['calculus', 'integration', 'definite-integrals']"
89,How to evaluate $ \sum\limits_{k=0} ^{\infty} \frac{(-1)^k}{4k+3}$?,How to evaluate ?, \sum\limits_{k=0} ^{\infty} \frac{(-1)^k}{4k+3},I was trying to solve the integral $\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}}dx$ and I noticed I can do the following: $$\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}}dx=\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}} \sec^2(x) -\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}} \tan^2(x) dx $$ $$=\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}} \sec^2(x) -\int_0 ^{\frac{\pi}{4}} \tan^{2+\frac{1}{2}}(x) \sec^2(x)dx + \int_0 ^{\frac{\pi}{4}} \tan^{4+\frac{1}{2}}(x) $$ continue with that and we will get $$\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}}dx=\sum_{k=0}^n \left(\int_0 ^{\frac{\pi}{4}} \tan^{2k+\frac{1}{2}}(x) \sec^2(x)dx \right) + (-1)^{n+1}\int_0 ^{\frac{\pi}{4}} \tan^{2n+2+\frac{1}{2}}(x) dx$$ since for any converging positive sequence $a_n$ $(\sum a_k)^n >\sum (a_k ^n)$ $\int_0 ^{\frac{\pi}{4}} \tan^{n}(x) dx <\left( \int_0 ^{\frac{\pi}{4}} \tan(x) dx \right) ^n \to 0$ so we get $$ \int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}}dx=2 \ \lim_{n \to \infty } \sum_{k=0} ^ n \frac{(-1)^k}{4k+3}=\frac{\pi +\ln{(3-2 \sqrt{2})}}{2 \sqrt{2}} $$ I don't know if my approach is correct or not but even if it is correct I am interested in finding out if there are any other more obvious ways to evaluate $ \sum\limits_{k=0} ^{\infty} \frac{(-1)^k}{4k+3}$ as my approach is very difficult to notice if try to solve $ \sum\limits_{k=0} ^{\infty} \frac{(-1)^k}{4k+3}$ without any mention of the integral. another question can we generalise this result  for all $m \in \mathbb{R}$ st $m>1$ $$ \int_0 ^{\frac{\pi}{4}} \left(\tan{x} \right)^{\frac{1}{m}} dx=m \  \sum_{k=0} ^ {\infty } \frac{(-1)^k}{2mk+m+1} $$,I was trying to solve the integral and I noticed I can do the following: continue with that and we will get since for any converging positive sequence so we get I don't know if my approach is correct or not but even if it is correct I am interested in finding out if there are any other more obvious ways to evaluate as my approach is very difficult to notice if try to solve without any mention of the integral. another question can we generalise this result  for all st,\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}}dx \int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}}dx=\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}} \sec^2(x) -\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}} \tan^2(x) dx  =\int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}} \sec^2(x) -\int_0 ^{\frac{\pi}{4}} \tan^{2+\frac{1}{2}}(x) \sec^2(x)dx + \int_0 ^{\frac{\pi}{4}} \tan^{4+\frac{1}{2}}(x)  \int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}}dx=\sum_{k=0}^n \left(\int_0 ^{\frac{\pi}{4}} \tan^{2k+\frac{1}{2}}(x) \sec^2(x)dx \right) + (-1)^{n+1}\int_0 ^{\frac{\pi}{4}} \tan^{2n+2+\frac{1}{2}}(x) dx a_n (\sum a_k)^n >\sum (a_k ^n) \int_0 ^{\frac{\pi}{4}} \tan^{n}(x) dx <\left( \int_0 ^{\frac{\pi}{4}} \tan(x) dx \right) ^n \to 0  \int_0 ^{\frac{\pi}{4}} \sqrt{\tan{x}}dx=2 \ \lim_{n \to \infty } \sum_{k=0} ^ n \frac{(-1)^k}{4k+3}=\frac{\pi +\ln{(3-2 \sqrt{2})}}{2 \sqrt{2}}   \sum\limits_{k=0} ^{\infty} \frac{(-1)^k}{4k+3}  \sum\limits_{k=0} ^{\infty} \frac{(-1)^k}{4k+3} m \in \mathbb{R} m>1  \int_0 ^{\frac{\pi}{4}} \left(\tan{x} \right)^{\frac{1}{m}} dx=m \  \sum_{k=0} ^ {\infty } \frac{(-1)^k}{2mk+m+1} ,"['calculus', 'sequences-and-series', 'limits', 'definite-integrals', 'summation']"
90,A conjectured asymptotic expansion of a function related to the sine and cosine integrals,A conjectured asymptotic expansion of a function related to the sine and cosine integrals,,"Recall the definitions of the sine and cosine integrals:$$\operatorname{Si}(x)=\int_0^x\frac{\sin t}t dt,\quad\operatorname{si}(x)=-\int_x^\infty\frac{\sin t}t dt=\operatorname{Si}(x)-\frac\pi2,\tag1$$ $$\operatorname{Ci}(x)=-\int_x^\infty\frac{\cos t}t dt.\tag2$$ In this question, we are only interested in positive real values of the argument: $x\in\mathbb R^+$. We prefer using $\operatorname{si}(z)$ rather than $\operatorname{Si}(z)$, because the former decays on infinity in a manner similar to $\operatorname{Ci}(z)$. We will also need the definition of the exponential integral (of a complex argument): $$\operatorname{Ei}(z)=\int_{-z}^\infty\frac{e^{-t}}t dt.\tag3$$ Note that $$\Re\operatorname{Ei}(ix)=\operatorname{Ci}(x),\quad\Im\operatorname{Ei}(ix)=\operatorname{si}(x)+\frac\pi2.\tag4$$ We want to factor $\operatorname{si}(z)$ and $\operatorname{Ci}(z)$ into an amplitude $A(x)$ and a phase $\Phi(x)$, both of which are continuous monotonic functions. We follow an approach from this paper , where it is applied to Bessel functions. Let $$\operatorname{si}(x)=A(x)\cdot\sin\Phi(x),\quad\operatorname{Ci}(x)=A(x)\cdot\cos\Phi(x),\tag5$$ where $$A(x)=\Big|\!\operatorname{Ei}(ix)-i\pi\Big|=\sqrt{\operatorname{si}^2(x)+\operatorname{Ci}^2(x)},\tag6$$ $$\Phi(x)=\arg\left((\operatorname{Ei}(ix)-i\pi)\,e^{-ix}\right) + x=\arctan\frac{\operatorname{si}(x)}{\operatorname{Ci}(x)}\color{gray}{+2\pi n}.\tag7$$ On the right of $(7)$, $n$ is an integer depending on $x$. This last term is present to compensate for jump discontinuitues introduced by $\arctan$ and to make the phase $\Phi(x)$ continuous monotone function (the former representation using $\arg$ is already continuous as it stands). It is convenient to consider the derivative of the phase $\Phi'(x)$ rather than the phase itself, because this way we do not need to care about jump discontinuities, the closed form looks more manageable, and coefficients discussed below will assume simpler integer form: $$\Phi'(x)=\frac{\operatorname{Ci}(x)\cdot\sin x-\operatorname{si}(x)\cdot\cos x}{\left(\operatorname{si}^2(x)+\operatorname{Ci}^2(x)\right)\cdot x}.\tag8$$ I'm interested in the asymptotic expansion of $\Phi'(x)$ for $x\to\infty$. Numerical evidence based on Wynn's epsilon method strongly suggests the following expansion: $$\Phi'(x)\sim1+\frac1{x^2}-\frac{13}{x^4}+\frac{461}{x^6}-\frac{29093}{x^8}+\frac{2829325}{x^{10}}-\frac{392743957}{x^{12}}+O\left(\frac1{x^{14}}\right).\tag9$$ In fact, I have obtained conjectured coefficients up to a much higher order. You can find them here . There are some additional evidence that these coefficients are not just random artifacts of round-off errors, despite being computed by approximate numeric methods. They are stable across different numeric algorithms, appear to be exact integers to a very high precision, and follow certain patterns: alternating signs, periodic modulo some integers, etc. But so far these all are just empirical results. I am looking for a proof that the asymptotic expansion $(9)$ really holds, and my conjectured values of its coefficients are indeed correct. Also, I am looking for some general formula or recurrence relation for these coefficients. Related questions: (1) , (2) .","Recall the definitions of the sine and cosine integrals:$$\operatorname{Si}(x)=\int_0^x\frac{\sin t}t dt,\quad\operatorname{si}(x)=-\int_x^\infty\frac{\sin t}t dt=\operatorname{Si}(x)-\frac\pi2,\tag1$$ $$\operatorname{Ci}(x)=-\int_x^\infty\frac{\cos t}t dt.\tag2$$ In this question, we are only interested in positive real values of the argument: $x\in\mathbb R^+$. We prefer using $\operatorname{si}(z)$ rather than $\operatorname{Si}(z)$, because the former decays on infinity in a manner similar to $\operatorname{Ci}(z)$. We will also need the definition of the exponential integral (of a complex argument): $$\operatorname{Ei}(z)=\int_{-z}^\infty\frac{e^{-t}}t dt.\tag3$$ Note that $$\Re\operatorname{Ei}(ix)=\operatorname{Ci}(x),\quad\Im\operatorname{Ei}(ix)=\operatorname{si}(x)+\frac\pi2.\tag4$$ We want to factor $\operatorname{si}(z)$ and $\operatorname{Ci}(z)$ into an amplitude $A(x)$ and a phase $\Phi(x)$, both of which are continuous monotonic functions. We follow an approach from this paper , where it is applied to Bessel functions. Let $$\operatorname{si}(x)=A(x)\cdot\sin\Phi(x),\quad\operatorname{Ci}(x)=A(x)\cdot\cos\Phi(x),\tag5$$ where $$A(x)=\Big|\!\operatorname{Ei}(ix)-i\pi\Big|=\sqrt{\operatorname{si}^2(x)+\operatorname{Ci}^2(x)},\tag6$$ $$\Phi(x)=\arg\left((\operatorname{Ei}(ix)-i\pi)\,e^{-ix}\right) + x=\arctan\frac{\operatorname{si}(x)}{\operatorname{Ci}(x)}\color{gray}{+2\pi n}.\tag7$$ On the right of $(7)$, $n$ is an integer depending on $x$. This last term is present to compensate for jump discontinuitues introduced by $\arctan$ and to make the phase $\Phi(x)$ continuous monotone function (the former representation using $\arg$ is already continuous as it stands). It is convenient to consider the derivative of the phase $\Phi'(x)$ rather than the phase itself, because this way we do not need to care about jump discontinuities, the closed form looks more manageable, and coefficients discussed below will assume simpler integer form: $$\Phi'(x)=\frac{\operatorname{Ci}(x)\cdot\sin x-\operatorname{si}(x)\cdot\cos x}{\left(\operatorname{si}^2(x)+\operatorname{Ci}^2(x)\right)\cdot x}.\tag8$$ I'm interested in the asymptotic expansion of $\Phi'(x)$ for $x\to\infty$. Numerical evidence based on Wynn's epsilon method strongly suggests the following expansion: $$\Phi'(x)\sim1+\frac1{x^2}-\frac{13}{x^4}+\frac{461}{x^6}-\frac{29093}{x^8}+\frac{2829325}{x^{10}}-\frac{392743957}{x^{12}}+O\left(\frac1{x^{14}}\right).\tag9$$ In fact, I have obtained conjectured coefficients up to a much higher order. You can find them here . There are some additional evidence that these coefficients are not just random artifacts of round-off errors, despite being computed by approximate numeric methods. They are stable across different numeric algorithms, appear to be exact integers to a very high precision, and follow certain patterns: alternating signs, periodic modulo some integers, etc. But so far these all are just empirical results. I am looking for a proof that the asymptotic expansion $(9)$ really holds, and my conjectured values of its coefficients are indeed correct. Also, I am looking for some general formula or recurrence relation for these coefficients. Related questions: (1) , (2) .",,"['calculus', 'sequences-and-series', 'analysis', 'asymptotics', 'special-functions']"
91,Find the value of $\sum_{n=1}^\infty \frac{1}{n(2n-1)}$,Find the value of,\sum_{n=1}^\infty \frac{1}{n(2n-1)},"I will show two solutions of this problem. First solution : $$\sum_{n=1}^\infty \frac{1}{n(2n-1)}=\sum_{n=1}^\infty \left(\frac{2}{2n-1}-\frac{1}{n}\right)$$ $$=\sum_{n=1}^\infty \left(\int_0^1 (2x^{2n-2}-x^{n-1})dx\right)$$ $$=\int_0^1 \left( \sum_{n=1}^\infty(2x^{2n-2}-x^{n-1})\right)dx$$ $$=\int_0^1 \left( \frac{2}{1-x^2}-\frac{1}{1-x} \right) dx $$ $$=\int_0^1  \frac{1}{1+x}dx $$ $$=\ln 2$$ Second solution : $$\sum_{n=1}^\infty \frac{1}{n(2n-1)}=\sum_{n=1}^\infty \left(\frac{2}{2n-1}-\frac{1}{n}\right)$$ $$=\sum_{n=1}^\infty \left(\int_0^1 (2x^{2n-2}-2x^{2n-1})dx\right)$$ $$=\int_0^1 \left( \sum_{n=1}^\infty(2x^{2n-2}-2x^{2n-1})\right)dx$$ $$=\int_0^1 \left( \frac{2}{1-x^2}-\frac{2x}{1-x^2} \right) dx $$ $$=\int_0^1  \frac{2}{1+x}dx $$ $$=2\ln 2$$ In fact, $\displaystyle\sum_{n=1}^\infty \frac{1}{n(2n-1)}=2\ln 2$. Why the first solution is false but the second is true ? I have known that uniformly convergent series can be integrated term by term. Is this mean that $\sum_{n=1}^\infty(2x^{2n-2}-2x^{2n-1})$ ; second solution,  is  uniformly convergent but $\sum_{n=1}^\infty(2x^{2n-2}-x^{n-1})$ ; first solution,  is not ?","I will show two solutions of this problem. First solution : $$\sum_{n=1}^\infty \frac{1}{n(2n-1)}=\sum_{n=1}^\infty \left(\frac{2}{2n-1}-\frac{1}{n}\right)$$ $$=\sum_{n=1}^\infty \left(\int_0^1 (2x^{2n-2}-x^{n-1})dx\right)$$ $$=\int_0^1 \left( \sum_{n=1}^\infty(2x^{2n-2}-x^{n-1})\right)dx$$ $$=\int_0^1 \left( \frac{2}{1-x^2}-\frac{1}{1-x} \right) dx $$ $$=\int_0^1  \frac{1}{1+x}dx $$ $$=\ln 2$$ Second solution : $$\sum_{n=1}^\infty \frac{1}{n(2n-1)}=\sum_{n=1}^\infty \left(\frac{2}{2n-1}-\frac{1}{n}\right)$$ $$=\sum_{n=1}^\infty \left(\int_0^1 (2x^{2n-2}-2x^{2n-1})dx\right)$$ $$=\int_0^1 \left( \sum_{n=1}^\infty(2x^{2n-2}-2x^{2n-1})\right)dx$$ $$=\int_0^1 \left( \frac{2}{1-x^2}-\frac{2x}{1-x^2} \right) dx $$ $$=\int_0^1  \frac{2}{1+x}dx $$ $$=2\ln 2$$ In fact, $\displaystyle\sum_{n=1}^\infty \frac{1}{n(2n-1)}=2\ln 2$. Why the first solution is false but the second is true ? I have known that uniformly convergent series can be integrated term by term. Is this mean that $\sum_{n=1}^\infty(2x^{2n-2}-2x^{2n-1})$ ; second solution,  is  uniformly convergent but $\sum_{n=1}^\infty(2x^{2n-2}-x^{n-1})$ ; first solution,  is not ?",,"['calculus', 'sequences-and-series']"
92,Evaluating $~\int_0^1\sqrt{\frac{1+x^n}{1-x^n}}~dx~$ and $~\int_0^1\sqrt[n]{\frac{1+x^2}{1-x^2}}~dx$,Evaluating  and,~\int_0^1\sqrt{\frac{1+x^n}{1-x^n}}~dx~ ~\int_0^1\sqrt[n]{\frac{1+x^2}{1-x^2}}~dx,"How could we prove that $$\int_0^1\sqrt{\frac{1+x^n}{1-x^n}}~dx~=~a\cdot2^{a-1}~\bigg[\frac12~B\bigg(\frac a2,~\frac a2\bigg)~+~B\bigg(\dfrac{a+1}2,~\dfrac{a+1}2\bigg)\bigg],$$ where $a=+~\dfrac1n$ , and $$\int_0^1\sqrt[n]{\frac{1+x^2}{1-x^2}}~dx~=~a\cdot2^{a-1}~\bigg[\frac12~B\bigg(\frac a2,~\frac a2\bigg)~-~B\bigg(\dfrac{a+1}2,~\dfrac{a+1}2\bigg)\bigg],$$ where $a=-~\dfrac1n$ ? This question arose as a generalization of the fact that the arc length of the $($co$)$sine function over an interval of the form $\bigg(k~\dfrac\pi2,~m~\dfrac\pi2\bigg)$, with $k,~m\in\mathbb Z$, can be expressed in terms of $\Gamma$ functions , which was somewhat surprising, since the evaluation of such arc lengths usually involves elliptic integrals ; indeed, it was one of the main historical reasons for defining them in the first place. I tried substituting $x^n=\cos2t$, and then employing the well-known trigonometric formulas for $1\pm\cos2t$, in the hopes of reducing the original problem to a beta function by means of Wallis' integrals , since $\sqrt{\dfrac{1+x^n}{1-x^n}}~=~\cot(t)$, but this approach ultimately lead me nowhere $($which is not to imply that the same method might not prove fruitful in someone else's skilled hands$)$.","How could we prove that $$\int_0^1\sqrt{\frac{1+x^n}{1-x^n}}~dx~=~a\cdot2^{a-1}~\bigg[\frac12~B\bigg(\frac a2,~\frac a2\bigg)~+~B\bigg(\dfrac{a+1}2,~\dfrac{a+1}2\bigg)\bigg],$$ where $a=+~\dfrac1n$ , and $$\int_0^1\sqrt[n]{\frac{1+x^2}{1-x^2}}~dx~=~a\cdot2^{a-1}~\bigg[\frac12~B\bigg(\frac a2,~\frac a2\bigg)~-~B\bigg(\dfrac{a+1}2,~\dfrac{a+1}2\bigg)\bigg],$$ where $a=-~\dfrac1n$ ? This question arose as a generalization of the fact that the arc length of the $($co$)$sine function over an interval of the form $\bigg(k~\dfrac\pi2,~m~\dfrac\pi2\bigg)$, with $k,~m\in\mathbb Z$, can be expressed in terms of $\Gamma$ functions , which was somewhat surprising, since the evaluation of such arc lengths usually involves elliptic integrals ; indeed, it was one of the main historical reasons for defining them in the first place. I tried substituting $x^n=\cos2t$, and then employing the well-known trigonometric formulas for $1\pm\cos2t$, in the hopes of reducing the original problem to a beta function by means of Wallis' integrals , since $\sqrt{\dfrac{1+x^n}{1-x^n}}~=~\cot(t)$, but this approach ultimately lead me nowhere $($which is not to imply that the same method might not prove fruitful in someone else's skilled hands$)$.",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'beta-function']"
93,Volume of the intersection of two cylinders,Volume of the intersection of two cylinders,,"I have two infinite cylinders of unit radius in $\mathbb{R}^3$, whose axes are skew lines. Say that the axis of one is centered on the $x$-axis, and the axis of the other is determined by the two points $a$ and $b$. Is there a formula for the volume of their intersection, as a function of $a$ and $b$?","I have two infinite cylinders of unit radius in $\mathbb{R}^3$, whose axes are skew lines. Say that the axis of one is centered on the $x$-axis, and the axis of the other is determined by the two points $a$ and $b$. Is there a formula for the volume of their intersection, as a function of $a$ and $b$?",,"['calculus', 'geometry', 'multivariable-calculus', 'volume', 'faq']"
94,Prove that the series is convergent and calculate the sum.,Prove that the series is convergent and calculate the sum.,,"Let's say  that $$x_{1} \gt 0$$  We define the sequence by the formula   $$x_{n+1} = - \ln(x_{1} +x_{2}+x_{3}+\dots+x_{n}) $$   Prove that the series $$\sum_{n=2}^{ \infty } x_{n}$$ is convergent and find the sum of it. My attempt was to use the identity $$\ln(1+x)\lt x$$ somehow, but without any results.  I've also determined that the elements of the sequence are positive and that $$x_{n+1} = - \ln(x_{1} +x_{2}+x_{3}+\dots+x_{n}) = \ln\left(\frac{1}{x_{1} +x_{2}+x_{3}+\dots+x_{n}}\right)$$","Let's say  that $$x_{1} \gt 0$$  We define the sequence by the formula   $$x_{n+1} = - \ln(x_{1} +x_{2}+x_{3}+\dots+x_{n}) $$   Prove that the series $$\sum_{n=2}^{ \infty } x_{n}$$ is convergent and find the sum of it. My attempt was to use the identity $$\ln(1+x)\lt x$$ somehow, but without any results.  I've also determined that the elements of the sequence are positive and that $$x_{n+1} = - \ln(x_{1} +x_{2}+x_{3}+\dots+x_{n}) = \ln\left(\frac{1}{x_{1} +x_{2}+x_{3}+\dots+x_{n}}\right)$$",,"['calculus', 'sequences-and-series']"
95,"Simplification of $G_{2,4}^{4,2}\left(\frac18,\frac12\middle|\begin{array}{c}\frac12,\frac12\\0,0,\frac12,\frac12\\\end{array}\right)$",Simplification of,"G_{2,4}^{4,2}\left(\frac18,\frac12\middle|\begin{array}{c}\frac12,\frac12\\0,0,\frac12,\frac12\\\end{array}\right)","In this post Cleo gives a misterious result containing the following generalized Meijer G-function : $$G_{2,4}^{4,2}\left(\frac18,\frac12\middle|\begin{array}{c}\frac12,\frac12\\0,0,\frac12,\frac12\\\end{array}\right)$$ Is it possible to represent it in terms of simpler (including hypergeometric) functions?","In this post Cleo gives a misterious result containing the following generalized Meijer G-function : $$G_{2,4}^{4,2}\left(\frac18,\frac12\middle|\begin{array}{c}\frac12,\frac12\\0,0,\frac12,\frac12\\\end{array}\right)$$ Is it possible to represent it in terms of simpler (including hypergeometric) functions?",,"['calculus', 'integration', 'complex-analysis', 'special-functions', 'closed-form']"
96,Advice in Bachelor Degree,Advice in Bachelor Degree,,"First of all, I´m very sorry for my bad english, especially writing. Ok,  for differents problems i´m studing a Bachelor degree in Mathematics. These degree is online. Now, the problem with my school is that it is new (created in 2009 for the Mexican Government ) and that implies that it is very bad in quality. Let me explain, they don´t have researchers, a decent teachers, the content (I mean the content in the subject is very low in quality if you compare with more prestiges universities in Mexico like ITAM, UNAM). Besides, they assign you a ""teacher"" and when you ask him a question (by email) never respond you, so it is on you to learn mathematics. After that, i´m here to ask for help,tips and recommendation about books, pages or materials that help me to learn very well, with the condition that these materials have to be very well explained, remember I´m learning myself. I dont care the difficult that implies learn yourself mathematics because I like and it is my passion. My advantage, if you let me say that ,I sort of know english. Right now, I now about MIT opencourseware, Harvard video classes an so on, and i´m taking these videos like my courses to learn complementing with reading, examns. As you can see i´m interested in learning a decent international level in mathematics because im planning a master in economics in USA or England, so the point is prepare myself for that kind of level. Actually these is my list of subjects of fourth-mester (it is a course during four months, sorry i dont know how called it): Linear Algebra I - watching course MIT opencourseware Gilbert Strang. Book: Linear Algebra, G. Strang. Probability I :  Watching course ""Statistics 110"" with professor Joe Blitzstein from Harvard. Book: Statistical Mathematics and Data Analysis. J. Rice Discrete Mathematics:  Watching course ""Mathematics for computing Sciencies"". Book.: Discrete and Combinatorial Mathematics. Grimaldi. For clarification, when I say ""watch course"" it means i already got the lectures, homeworks and exams for the three subjects. I´m taking other subjects but it is about economics and history in Mexico, so for this purpose it doesn´t matter. If any could help me about where i can get introductory materials about this subject I will be really thankful. What do you think about these courses and books? may be a better introductory book or video course?, advices about how to learn mathematics?. I read that some people is in Harvard, MIT and thousands of universities top rank in the world, and i would really like that those people tell me some tips because they have a better experience and I think the internet is the best way to catch that. I have to say that any advice it would an enormous help. Thank you very much indeed for any suggestions. JAPS. Update: sorry, my mistake. My bachelor degree is formed by twelve ""fourth- mester"". I mean twelve units of fourth months each one. right now im in the unit four and these is For now, I already took diferencial and integral calculus both with Apostol ""Calculus; Vol. I and II"", introduction to logic (no book), Geometry I (Book: Wooldrige "" a modern approach to geometry""), and other subjects of different kind. Before i go too far, I prefer ask my doubts and catch all kinds of tips. in the future, I will take Mathematics Analysis I and II, differential ecuationsI and II, partial ecuations, Geometry NO-Euclidean, Estocastic Process, modeling estocastic process, estatistics I, II and II, Topology I, Complex variable I and II,  Linear ALgebra I and II, Modern Algebra I and II,  Combinatorial ANalysis,  Numerical Analysis I and II.. and I think that´s it. Once again, I really appreciate to take the times for respond guys. JAPS","First of all, I´m very sorry for my bad english, especially writing. Ok,  for differents problems i´m studing a Bachelor degree in Mathematics. These degree is online. Now, the problem with my school is that it is new (created in 2009 for the Mexican Government ) and that implies that it is very bad in quality. Let me explain, they don´t have researchers, a decent teachers, the content (I mean the content in the subject is very low in quality if you compare with more prestiges universities in Mexico like ITAM, UNAM). Besides, they assign you a ""teacher"" and when you ask him a question (by email) never respond you, so it is on you to learn mathematics. After that, i´m here to ask for help,tips and recommendation about books, pages or materials that help me to learn very well, with the condition that these materials have to be very well explained, remember I´m learning myself. I dont care the difficult that implies learn yourself mathematics because I like and it is my passion. My advantage, if you let me say that ,I sort of know english. Right now, I now about MIT opencourseware, Harvard video classes an so on, and i´m taking these videos like my courses to learn complementing with reading, examns. As you can see i´m interested in learning a decent international level in mathematics because im planning a master in economics in USA or England, so the point is prepare myself for that kind of level. Actually these is my list of subjects of fourth-mester (it is a course during four months, sorry i dont know how called it): Linear Algebra I - watching course MIT opencourseware Gilbert Strang. Book: Linear Algebra, G. Strang. Probability I :  Watching course ""Statistics 110"" with professor Joe Blitzstein from Harvard. Book: Statistical Mathematics and Data Analysis. J. Rice Discrete Mathematics:  Watching course ""Mathematics for computing Sciencies"". Book.: Discrete and Combinatorial Mathematics. Grimaldi. For clarification, when I say ""watch course"" it means i already got the lectures, homeworks and exams for the three subjects. I´m taking other subjects but it is about economics and history in Mexico, so for this purpose it doesn´t matter. If any could help me about where i can get introductory materials about this subject I will be really thankful. What do you think about these courses and books? may be a better introductory book or video course?, advices about how to learn mathematics?. I read that some people is in Harvard, MIT and thousands of universities top rank in the world, and i would really like that those people tell me some tips because they have a better experience and I think the internet is the best way to catch that. I have to say that any advice it would an enormous help. Thank you very much indeed for any suggestions. JAPS. Update: sorry, my mistake. My bachelor degree is formed by twelve ""fourth- mester"". I mean twelve units of fourth months each one. right now im in the unit four and these is For now, I already took diferencial and integral calculus both with Apostol ""Calculus; Vol. I and II"", introduction to logic (no book), Geometry I (Book: Wooldrige "" a modern approach to geometry""), and other subjects of different kind. Before i go too far, I prefer ask my doubts and catch all kinds of tips. in the future, I will take Mathematics Analysis I and II, differential ecuationsI and II, partial ecuations, Geometry NO-Euclidean, Estocastic Process, modeling estocastic process, estatistics I, II and II, Topology I, Complex variable I and II,  Linear ALgebra I and II, Modern Algebra I and II,  Combinatorial ANalysis,  Numerical Analysis I and II.. and I think that´s it. Once again, I really appreciate to take the times for respond guys. JAPS",,"['calculus', 'probability', 'self-learning', 'numerical-linear-algebra', 'learning']"
97,A series converges absolutely if and only if every subseries converges,A series converges absolutely if and only if every subseries converges,,"Question: A subseries of the series $\sum _{n=1}^\infty a_n$ is defined to be a series of the form $\sum _{n=1}^\infty a_{n_k}$, for $n_k \subseteq \Bbb N$. Prove that $\sum _{n=1}^\infty a_n$ converges absolutely if and only if each subseries $\sum _{n=1}^\infty a_{n_k}$ converges. Suggested solution: $\Rightarrow$ We assume $\sum _{n=1}^\infty a_n$ converges absolutely $\Rightarrow \lim_{n \to \infty} |a_n|$=0. We know from the definition of series that it's actually the sequence of partial sums so $\sum _{n=1}^\infty a_n = S_n$. Therefore we can treat it like a sequence and say that it converges to L. Since $S_n$ converges to L, each of it's sub sequences also converge to L. Therefore $\sum _{n=1}^\infty a_{n_k} =S_{n_k} \to L$ as well. $\Leftarrow$ We assume each subseries converges. Specifically the sub series $\sum _{\Bbb N even} a_n = A$  $\sum _{\Bbb N odd} a_n = B$ . Since these two series comprise all of the naturals, then  $\sum _{n=1}^\infty a_n =\sum _{\Bbb N even} a_n+\sum _{\Bbb N odd} a_n = A+B$ . Therefore it converges to A+B. I would like to verify this proof, because I've given it a lot of thought, and still not 100 percent sure about it. Please hint me, and notify me about any mistakes. Thanks.","Question: A subseries of the series $\sum _{n=1}^\infty a_n$ is defined to be a series of the form $\sum _{n=1}^\infty a_{n_k}$, for $n_k \subseteq \Bbb N$. Prove that $\sum _{n=1}^\infty a_n$ converges absolutely if and only if each subseries $\sum _{n=1}^\infty a_{n_k}$ converges. Suggested solution: $\Rightarrow$ We assume $\sum _{n=1}^\infty a_n$ converges absolutely $\Rightarrow \lim_{n \to \infty} |a_n|$=0. We know from the definition of series that it's actually the sequence of partial sums so $\sum _{n=1}^\infty a_n = S_n$. Therefore we can treat it like a sequence and say that it converges to L. Since $S_n$ converges to L, each of it's sub sequences also converge to L. Therefore $\sum _{n=1}^\infty a_{n_k} =S_{n_k} \to L$ as well. $\Leftarrow$ We assume each subseries converges. Specifically the sub series $\sum _{\Bbb N even} a_n = A$  $\sum _{\Bbb N odd} a_n = B$ . Since these two series comprise all of the naturals, then  $\sum _{n=1}^\infty a_n =\sum _{\Bbb N even} a_n+\sum _{\Bbb N odd} a_n = A+B$ . Therefore it converges to A+B. I would like to verify this proof, because I've given it a lot of thought, and still not 100 percent sure about it. Please hint me, and notify me about any mistakes. Thanks.",,"['calculus', 'sequences-and-series', 'absolute-convergence']"
98,What is the difference between Green's Theorem and Stokes Theorem?,What is the difference between Green's Theorem and Stokes Theorem?,,"I don't quite understand the difference between Green's Theorem and Stokes Theorem. I know that Green's Theorem is in $\mathbb{R}^2$ and Stokes Theorem is in $\mathbb{R}^3$ and my lecture notes give Greens Theorem and Stokes Theorem as $$\int \!\! \int_{\Omega} curl \, \underline{v} \, \mathrm{d}A  = \int_{\partial \Omega} \underline{v} \, \mathrm{d} \underline{r}$$ and $$\int \!\! \int_\Omega \nabla \times \underline{v} . \underline{n} \, \mathrm{d}A = \int_{\partial \Omega} \underline{v} \, \mathrm{d} \underline{r}$$ respectively. So why does being in $\mathbb{R}^3$ constitute the unit normal $\underline{n}$ to be dotted with the curl? Thanks!","I don't quite understand the difference between Green's Theorem and Stokes Theorem. I know that Green's Theorem is in $\mathbb{R}^2$ and Stokes Theorem is in $\mathbb{R}^3$ and my lecture notes give Greens Theorem and Stokes Theorem as $$\int \!\! \int_{\Omega} curl \, \underline{v} \, \mathrm{d}A  = \int_{\partial \Omega} \underline{v} \, \mathrm{d} \underline{r}$$ and $$\int \!\! \int_\Omega \nabla \times \underline{v} . \underline{n} \, \mathrm{d}A = \int_{\partial \Omega} \underline{v} \, \mathrm{d} \underline{r}$$ respectively. So why does being in $\mathbb{R}^3$ constitute the unit normal $\underline{n}$ to be dotted with the curl? Thanks!",,['calculus']
99,How to prove that $\lim\limits_{h \to 0} \frac{a^h - 1}{h} = \ln a$,How to prove that,\lim\limits_{h \to 0} \frac{a^h - 1}{h} = \ln a,"In order to find the derivative of a exponential function, on its general form $a^x$ by the definition, I used limits. $\begin{align*} \frac{d}{dx} a^x & = \lim_{h \to 0} \left [ \frac{a^{x+h}-a^x}{h} \right ]\\  \\ & =\lim_{h \to 0} \left [ \frac{a^x \cdot a^h-a^x}{h} \right ] \\  \\  &=\lim_{h \to 0} \left [ \frac{a^x \cdot (a^h-1)}{h} \right ] \\  \\ &=a^x \cdot \lim_{h \to 0} \left [\frac {a^h-1}{h} \right ] \end{align*}$ I know that this last limit is equal to $\ln(a)$ but how can I prove it by using basic Algebra and Exponential and Logarithms properties? Thanks","In order to find the derivative of a exponential function, on its general form $a^x$ by the definition, I used limits. $\begin{align*} \frac{d}{dx} a^x & = \lim_{h \to 0} \left [ \frac{a^{x+h}-a^x}{h} \right ]\\  \\ & =\lim_{h \to 0} \left [ \frac{a^x \cdot a^h-a^x}{h} \right ] \\  \\  &=\lim_{h \to 0} \left [ \frac{a^x \cdot (a^h-1)}{h} \right ] \\  \\ &=a^x \cdot \lim_{h \to 0} \left [\frac {a^h-1}{h} \right ] \end{align*}$ I know that this last limit is equal to $\ln(a)$ but how can I prove it by using basic Algebra and Exponential and Logarithms properties? Thanks",,"['calculus', 'limits']"
