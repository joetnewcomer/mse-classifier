,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,$x^x = (x-1)^{x+1}$,,x^x = (x-1)^{x+1},"Background: I was trying to estimate the size of $21^{21}$ for some problem and decided to use $20^{22}$ as hopefully a rough approximate ( $20^{22} = 2^{22} \cdot 10^{22} \approx 10^{28}$ ). But then I wanted to see if that was over or underestimate and got into this rabbithole of when they are equal. Anyways, I was doing some thinking and wanted to get an analytical solution to when $x^x = (x-1)^{x+1}$ . My original question was which was bigger for $x=21$ , but transitioned when I noticed that the $x^x > (x-1)^{x+1}$ for small $x$ , and then it flips when I go from $x=4$ to $x=5$ . I threw it in Desmos and got an approximate value of 4.141 (and I went woahhh that's $\pi +1$ but unfortunately that's only true to a couple decimal places :( ). Can anyone help me find an analytical or algebraic (as opposed to numerical/approximate) way of finding the value for x when these two expressions are equal? I was trying to approach it in a similar way to when $a^b$ grows faster than $b^a$ using logarithms but was struggling and would love some help if anyone has any suggestions. There is also this post which is similar but only talks about the inequality whereas I am more concerned about the equality. EDIT I found this paper which connects  the $x$ value of the solution to the original equation to be equal to $\alpha_0$ where $1+\frac{1}{(1+\frac{1}{(1+\frac{1}{...})^{\alpha}})^{\alpha}}$ converges for all $0 < \alpha < \alpha_0$ and diverges for all $\alpha > \alpha_0$ . Very interesting stuff. PS: I have an interesting follow up for $x^x$ vs $(x-n)^{x+n}$ that I would like to ask about but maybe some insight on this question will allow me to explore the following on my own :) Thanks!","Background: I was trying to estimate the size of for some problem and decided to use as hopefully a rough approximate ( ). But then I wanted to see if that was over or underestimate and got into this rabbithole of when they are equal. Anyways, I was doing some thinking and wanted to get an analytical solution to when . My original question was which was bigger for , but transitioned when I noticed that the for small , and then it flips when I go from to . I threw it in Desmos and got an approximate value of 4.141 (and I went woahhh that's but unfortunately that's only true to a couple decimal places :( ). Can anyone help me find an analytical or algebraic (as opposed to numerical/approximate) way of finding the value for x when these two expressions are equal? I was trying to approach it in a similar way to when grows faster than using logarithms but was struggling and would love some help if anyone has any suggestions. There is also this post which is similar but only talks about the inequality whereas I am more concerned about the equality. EDIT I found this paper which connects  the value of the solution to the original equation to be equal to where converges for all and diverges for all . Very interesting stuff. PS: I have an interesting follow up for vs that I would like to ask about but maybe some insight on this question will allow me to explore the following on my own :) Thanks!",21^{21} 20^{22} 20^{22} = 2^{22} \cdot 10^{22} \approx 10^{28} x^x = (x-1)^{x+1} x=21 x^x > (x-1)^{x+1} x x=4 x=5 \pi +1 a^b b^a x \alpha_0 1+\frac{1}{(1+\frac{1}{(1+\frac{1}{...})^{\alpha}})^{\alpha}} 0 < \alpha < \alpha_0 \alpha > \alpha_0 x^x (x-n)^{x+n},"['calculus', 'algebra-precalculus']"
1,If $T:\ \mathbb R^n\longrightarrow\mathbb R^n$ is additive then $T$ is linear,If  is additive then  is linear,T:\ \mathbb R^n\longrightarrow\mathbb R^n T,"Let the bijection $T:\, \mathbb R^n\longrightarrow\mathbb R^n,\ n\geq2$ satisfy \begin{align} T(u+v)=T(u)+T(v),\ \forall u,v\in\mathbb R^n\tag1 \end{align} and \begin{align} T\big(\langle u\rangle\big)=\big<T(u) \big>,\ \forall u\in\mathbb R^n,\tag2 \end{align} this means \begin{align} \forall u\in\mathbb R^n,\ \forall\lambda\in\mathbb R,\ \exists\,\mu=\mu(\lambda)\in\mathbb R:\ T(\lambda u)=\mu(\lambda,u)T(u),\tag3 \end{align} Moreover, we assume that \begin{align} T(\lambda u)\,=\lambda T(u),\ \forall\lambda\in\mathbb Q. \tag4 \end{align} Then is $T$ $\mathbb R-$ linear ? My attempt : Let us define the maps as follow \begin{align} \mathbb R\,\overset{f}{\longrightarrow}\,\langle u\rangle\,\overset{T}{\longrightarrow}\,\big< T(u)\big>\,\overset{g}{\longrightarrow}\,\mathbb R \end{align} given by \begin{align} \lambda\,&\longmapsto\,f(\lambda)=\lambda u \\ \lambda u\,&\longmapsto\,T(\lambda u)=\mu T(u) \\ \mu T(u)\,&\longmapsto\,g\big(\mu T(u)\big)=\mu. \end{align} From the additivity of $T$ ,we can show that \begin{align} \mu(\lambda+\varepsilon,u)&=\,\mu(\lambda,u)+\mu(\varepsilon,u) \end{align} In other hand, we have \begin{align} \mu(\lambda\varepsilon,u)T(u) \,=\,T(\lambda\varepsilon u)\,&=\,\mu(\lambda,\varepsilon u)T(\varepsilon u) \\ &=\,\mu(\lambda,\varepsilon u)\mu(\varepsilon,u)T(u) \end{align} Thus \begin{align} \mu(\lambda\varepsilon,u)\,=\,\mu(\lambda,\varepsilon u)\mu(\varepsilon,u) \end{align} I want to show that the function $\mu(\cdot,u)$ is multiplication preserving, and in order to get that, the first thing I think to show is \begin{align} \mu(\lambda,\varepsilon u)\,=\,\mu(\lambda,u).\tag5 \end{align} Then, we can use this fact to show that $\mu(\epsilon^2,u)=\mu(\epsilon,u)^2$ , this will implies $\mu(\lambda,u)>0,\ \forall \lambda >0$ . Hence $$\mu(\lambda,u)-\mu(\varepsilon,u)\,=\,\mu(\lambda-\varepsilon,u)\,>\,0,\ \forall \lambda >\varepsilon. $$ Thus $\mu$ is strictly increasing. Let $\lambda\in\mathbb R$ , suppose $\lambda <\mu(\lambda,u)$ . By density of $\mathbb R$ , there exists $q\in\mathbb Q$ such that $\lambda<q<\mu(\lambda,u)$ . Since $\lambda<q$ , we have $\mu(\lambda,u)<\mu(q,u)=q$ from (4), a contradiction. By similar deduce, we claim that $\lambda=\mu(\lambda,u)$ . So all remains is to show (5), but it seems not trivial. My another try is to consider the function \begin{align} f:\ \mathbb R&\longrightarrow\mathbb R \\ \lambda&\longmapsto f(\lambda)=T(\lambda u)\cdot v \end{align} for a fixed $v\in\mathbb R^n$ . From additivity of $T$ , we have $f(\lambda+\varepsilon)=f(\lambda)+f(\varepsilon),\ \forall\lambda,\varepsilon$ . Since $f(\lambda)$ is a inner product with respect to $u$ , I think we can someway show that $f(\lambda)$ is continuous, which will lead $f$ is linear. But this is not simple. May anyone provide me some interesting hint ? Thanks","Let the bijection satisfy and this means Moreover, we assume that Then is linear ? My attempt : Let us define the maps as follow given by From the additivity of ,we can show that In other hand, we have Thus I want to show that the function is multiplication preserving, and in order to get that, the first thing I think to show is Then, we can use this fact to show that , this will implies . Hence Thus is strictly increasing. Let , suppose . By density of , there exists such that . Since , we have from (4), a contradiction. By similar deduce, we claim that . So all remains is to show (5), but it seems not trivial. My another try is to consider the function for a fixed . From additivity of , we have . Since is a inner product with respect to , I think we can someway show that is continuous, which will lead is linear. But this is not simple. May anyone provide me some interesting hint ? Thanks","T:\, \mathbb R^n\longrightarrow\mathbb R^n,\ n\geq2 \begin{align}
T(u+v)=T(u)+T(v),\ \forall u,v\in\mathbb R^n\tag1
\end{align} \begin{align}
T\big(\langle u\rangle\big)=\big<T(u) \big>,\ \forall u\in\mathbb R^n,\tag2
\end{align} \begin{align}
\forall u\in\mathbb R^n,\ \forall\lambda\in\mathbb R,\ \exists\,\mu=\mu(\lambda)\in\mathbb R:\ T(\lambda u)=\mu(\lambda,u)T(u),\tag3
\end{align} \begin{align}
T(\lambda u)\,=\lambda T(u),\ \forall\lambda\in\mathbb Q. \tag4
\end{align} T \mathbb R- \begin{align}
\mathbb R\,\overset{f}{\longrightarrow}\,\langle u\rangle\,\overset{T}{\longrightarrow}\,\big< T(u)\big>\,\overset{g}{\longrightarrow}\,\mathbb R
\end{align} \begin{align}
\lambda\,&\longmapsto\,f(\lambda)=\lambda u
\\ \lambda u\,&\longmapsto\,T(\lambda u)=\mu T(u)
\\ \mu T(u)\,&\longmapsto\,g\big(\mu T(u)\big)=\mu.
\end{align} T \begin{align}
\mu(\lambda+\varepsilon,u)&=\,\mu(\lambda,u)+\mu(\varepsilon,u)
\end{align} \begin{align}
\mu(\lambda\varepsilon,u)T(u) \,=\,T(\lambda\varepsilon u)\,&=\,\mu(\lambda,\varepsilon u)T(\varepsilon u)
\\ &=\,\mu(\lambda,\varepsilon u)\mu(\varepsilon,u)T(u)
\end{align} \begin{align}
\mu(\lambda\varepsilon,u)\,=\,\mu(\lambda,\varepsilon u)\mu(\varepsilon,u)
\end{align} \mu(\cdot,u) \begin{align}
\mu(\lambda,\varepsilon u)\,=\,\mu(\lambda,u).\tag5
\end{align} \mu(\epsilon^2,u)=\mu(\epsilon,u)^2 \mu(\lambda,u)>0,\ \forall \lambda >0 \mu(\lambda,u)-\mu(\varepsilon,u)\,=\,\mu(\lambda-\varepsilon,u)\,>\,0,\ \forall \lambda >\varepsilon.  \mu \lambda\in\mathbb R \lambda <\mu(\lambda,u) \mathbb R q\in\mathbb Q \lambda<q<\mu(\lambda,u) \lambda<q \mu(\lambda,u)<\mu(q,u)=q \lambda=\mu(\lambda,u) \begin{align}
f:\ \mathbb R&\longrightarrow\mathbb R
\\ \lambda&\longmapsto f(\lambda)=T(\lambda u)\cdot v
\end{align} v\in\mathbb R^n T f(\lambda+\varepsilon)=f(\lambda)+f(\varepsilon),\ \forall\lambda,\varepsilon f(\lambda) u f(\lambda) f","['calculus', 'linear-algebra', 'euclidean-geometry', 'affine-geometry']"
2,Can this integral be calculated in closed form?,Can this integral be calculated in closed form?,,"I'm trying to calculate the following integral: $$ \int_{0}^{1}x\,\mathrm{J}_{2}\!\left(\,bx\,\right) \sin\left(\,a\,\sqrt{\,1 - x^{2}\,}\,\right)\,\mathrm{d}x $$where $a$ and $b$ are parameters ( independent of $x$ ). Things I have tried so far, without success (but possibly not driven through far enough): look up in tables: no joy. The ''closest'' match I have found is eq. (6.738.1) in Gradshteyn and Ryzhik, but that result is for the first factor being $x^3$ instead of $x$; use WolframAlpha (Standard): does not give values for general $a$ and $b$; only for assigned selected $a$ and $b$. Since I need results for a wide range of values for both $a$ and $b$, this (or any numerical quadrature for arbitrary $a$ and $b$) is not practical; use an integral representation for Bessel functions: \begin{align} J_2(bx) = \frac{1}{\pi} \int^\pi_0 \cos(2\theta - bx \sin\theta) d\theta \end{align} then swap the order of integration. However, the outer integration (i.e., with respect to $\theta$) then becomes problematic; use a recurrence relation for Bessel functions: \begin{align} J_2(bx) = (2/(bx)) J_1(bx) - J_0(bx) \end{align} This does not seem to simplify matters, because the square root in sin() remains a difficulty. attempt partial integration: since the integrand contains three factors, the choice is not obvious. I tried grouping the first two factors and use the partial integral result \begin{align} \int x^m J_n(x) dx = -x^m J_{n-1}(x) + (m+n-1) \int x^{m-1} J_{n-1}(x) dx \end{align} for $m=1$ , $n=2$, i.e., \begin{align} \int x J_2(x) dx = -x J_{1}(x) - 2 J_{0}(x) + C\end{align} but the derivative of $\sin(a\sqrt{1-x^2})$ with respect to $x$ complicates the remaining integration; use a series representation of the Bessel function: this leads to a double summation of integrals (one sum is semi-infinite) of the form \begin{align} \int^1_0 u^{2m+1} \sin(a u) du \end{align}  but this integral is a itself a difference of hypergeometric functions (or alternatively an additional series representation). Such a double or triple summation is again impractical for calculating for parametrized $a$ and $b$; converting the original integral to \begin{align} \int^1_0 y J_2 (b \sqrt{1-y^2}) \sin(a y) dx \end{align} where $y=\sqrt{1-x^2}$ and repeating the previous approaches; attempt     a trigonometric substitution such as $x = \sin \alpha$ and repeat the     previous approaches. Can you find a solution or give further suggestions what could be attempted?","I'm trying to calculate the following integral: $$ \int_{0}^{1}x\,\mathrm{J}_{2}\!\left(\,bx\,\right) \sin\left(\,a\,\sqrt{\,1 - x^{2}\,}\,\right)\,\mathrm{d}x $$where $a$ and $b$ are parameters ( independent of $x$ ). Things I have tried so far, without success (but possibly not driven through far enough): look up in tables: no joy. The ''closest'' match I have found is eq. (6.738.1) in Gradshteyn and Ryzhik, but that result is for the first factor being $x^3$ instead of $x$; use WolframAlpha (Standard): does not give values for general $a$ and $b$; only for assigned selected $a$ and $b$. Since I need results for a wide range of values for both $a$ and $b$, this (or any numerical quadrature for arbitrary $a$ and $b$) is not practical; use an integral representation for Bessel functions: \begin{align} J_2(bx) = \frac{1}{\pi} \int^\pi_0 \cos(2\theta - bx \sin\theta) d\theta \end{align} then swap the order of integration. However, the outer integration (i.e., with respect to $\theta$) then becomes problematic; use a recurrence relation for Bessel functions: \begin{align} J_2(bx) = (2/(bx)) J_1(bx) - J_0(bx) \end{align} This does not seem to simplify matters, because the square root in sin() remains a difficulty. attempt partial integration: since the integrand contains three factors, the choice is not obvious. I tried grouping the first two factors and use the partial integral result \begin{align} \int x^m J_n(x) dx = -x^m J_{n-1}(x) + (m+n-1) \int x^{m-1} J_{n-1}(x) dx \end{align} for $m=1$ , $n=2$, i.e., \begin{align} \int x J_2(x) dx = -x J_{1}(x) - 2 J_{0}(x) + C\end{align} but the derivative of $\sin(a\sqrt{1-x^2})$ with respect to $x$ complicates the remaining integration; use a series representation of the Bessel function: this leads to a double summation of integrals (one sum is semi-infinite) of the form \begin{align} \int^1_0 u^{2m+1} \sin(a u) du \end{align}  but this integral is a itself a difference of hypergeometric functions (or alternatively an additional series representation). Such a double or triple summation is again impractical for calculating for parametrized $a$ and $b$; converting the original integral to \begin{align} \int^1_0 y J_2 (b \sqrt{1-y^2}) \sin(a y) dx \end{align} where $y=\sqrt{1-x^2}$ and repeating the previous approaches; attempt     a trigonometric substitution such as $x = \sin \alpha$ and repeat the     previous approaches. Can you find a solution or give further suggestions what could be attempted?",,"['calculus', 'integration']"
3,"On $_2F_1(\tfrac13,\tfrac23;\tfrac56;\tfrac{27}{32}) = \tfrac85$ and $_2F_1(\tfrac14,\tfrac34;\tfrac78;\tfrac{48}{49}) = \tfrac{\sqrt7}3(1+\sqrt2)$",On  and,"_2F_1(\tfrac13,\tfrac23;\tfrac56;\tfrac{27}{32}) = \tfrac85 _2F_1(\tfrac14,\tfrac34;\tfrac78;\tfrac{48}{49}) = \tfrac{\sqrt7}3(1+\sqrt2)","Consider the rather interesting and new evaluations for $_2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac{n}{n+1}};z\right)$, $$\begin{aligned} _2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac23};\tfrac{2^2\times3^3}{121}\right) &= \large\tfrac{\sqrt{33}}{3}\\[2mm] _2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac56};-\tfrac{135}{121}\right) &=\large\tfrac{\sqrt{33}}{10^{5/6}}\\[2mm] _2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac78};\tfrac{48}{49}\right) &= \tfrac{\sqrt7}3(1+\sqrt2)\\[2mm] _2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac9{10}};\tfrac{4}{5}\right) &=\large \tfrac1{5^{1/4}}\,\phi^{3/2}\end{aligned}$$ and golden ratio $\phi$, with the last a transformed version of Nemo's answer . The transformation, $$_2F_1\left(\tfrac14,\tfrac34;c;\tfrac{4z(z-1)}{(1-2z)^2}\right)=\sqrt{1-2z}\,(1-z)^{1-c}\,_2F_1\left(-c+\tfrac32,\,c-\tfrac12;c;z\right)$$ allows it to be transformed to another form also with $a+b=-c+\tfrac32+c-\tfrac12 =1$. For example, the second one yields,  $$\,_2F_1\left(\tfrac13,\tfrac23;\color{blue}{\tfrac56};\tfrac{5}{32}\right) = \large\tfrac4{5^{5/6}}$$ which is related to the the known , $$\,_2F_1\left(\tfrac13,\tfrac23;\color{blue}{\tfrac56};\tfrac{27}{32}\right) = \tfrac85$$ However, only the first one is known to belong to an infinite family . The others apparently cannot be transformed to the group of families with $a+b = c$, nor to this group with $\,_2F_1\left(a,a;a+\tfrac12;z\right)$, and seem to be isolated results. However, the ""sensible"" form of the $z$, i.e. note the squares and that $\tfrac{135}{121}+1=\big(\tfrac{16}{11}\big)^2$, may suggest the others also are just the smallest members of an infinite family of algebraic numbers. P.S. Both the silver ratio $\sigma = 1+\sqrt2$ and golden ratio $\phi$ are fundamental units . Questions: Using transformations, can we in fact derive the three from any of the families in the linked posts? What other examples are there of ""isolated"" results?","Consider the rather interesting and new evaluations for $_2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac{n}{n+1}};z\right)$, $$\begin{aligned} _2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac23};\tfrac{2^2\times3^3}{121}\right) &= \large\tfrac{\sqrt{33}}{3}\\[2mm] _2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac56};-\tfrac{135}{121}\right) &=\large\tfrac{\sqrt{33}}{10^{5/6}}\\[2mm] _2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac78};\tfrac{48}{49}\right) &= \tfrac{\sqrt7}3(1+\sqrt2)\\[2mm] _2F_1\left(\tfrac14,\tfrac34;\color{blue}{\tfrac9{10}};\tfrac{4}{5}\right) &=\large \tfrac1{5^{1/4}}\,\phi^{3/2}\end{aligned}$$ and golden ratio $\phi$, with the last a transformed version of Nemo's answer . The transformation, $$_2F_1\left(\tfrac14,\tfrac34;c;\tfrac{4z(z-1)}{(1-2z)^2}\right)=\sqrt{1-2z}\,(1-z)^{1-c}\,_2F_1\left(-c+\tfrac32,\,c-\tfrac12;c;z\right)$$ allows it to be transformed to another form also with $a+b=-c+\tfrac32+c-\tfrac12 =1$. For example, the second one yields,  $$\,_2F_1\left(\tfrac13,\tfrac23;\color{blue}{\tfrac56};\tfrac{5}{32}\right) = \large\tfrac4{5^{5/6}}$$ which is related to the the known , $$\,_2F_1\left(\tfrac13,\tfrac23;\color{blue}{\tfrac56};\tfrac{27}{32}\right) = \tfrac85$$ However, only the first one is known to belong to an infinite family . The others apparently cannot be transformed to the group of families with $a+b = c$, nor to this group with $\,_2F_1\left(a,a;a+\tfrac12;z\right)$, and seem to be isolated results. However, the ""sensible"" form of the $z$, i.e. note the squares and that $\tfrac{135}{121}+1=\big(\tfrac{16}{11}\big)^2$, may suggest the others also are just the smallest members of an infinite family of algebraic numbers. P.S. Both the silver ratio $\sigma = 1+\sqrt2$ and golden ratio $\phi$ are fundamental units . Questions: Using transformations, can we in fact derive the three from any of the families in the linked posts? What other examples are there of ""isolated"" results?",,"['calculus', 'radicals', 'hypergeometric-function', 'experimental-mathematics']"
4,Multiple integrals involving product of gamma functions,Multiple integrals involving product of gamma functions,,"The following integral was posted a few days back on Integrals and Series forum: $$\int_0^{2\pi} \int_0^{2\pi} \int_0^{2\pi} \frac{dk_1\,dk_2\,dk_3}{1-\frac{1}{3}\left(\cos k_1+\cos k_2+ \cos k_3\right)}=\frac{\sqrt{6}}{4}\Gamma\left(\frac{1}{24}\right)\Gamma\left(\frac{5}{24}\right)\Gamma\left(\frac{7}{24}\right)\Gamma\left(\frac{11}{24}\right)$$ I am curious if there is a closed form solution for: $$\int_{\large[0,2\pi]^n} \frac{dk_1\,dk_2\,dk_3\,\cdots \,dk_n}{1-\frac{1}{n}\left(\cos k_1+\cos k_2+\cos k_3+\cdots +\cos k_n\right)}$$ Since $\left|\dfrac{\cos k_1 + \cos k_2 + \cos k_3}{3}\right|<1$, $$\int_0^{2\pi} \int_0^{2\pi} \int_0^{2\pi} \frac{dk_1\,dk_2\,dk_3}{1 - \frac 1 3 \left( \cos k_1 + \cos k_2 + \cos k_3 \right)}$$ $$=8\int_0^{\pi} \int_0^{\pi} \int_0^{\pi} \frac{dk_1\,dk_2\,dk_3}{1 - \frac 1 3 \left( \cos k_1 + \cos k_2 + \cos k_3 \right)}$$ $$=8\sum_{n=0}^{\infty} \frac{1}{3^n} \int_0^{\pi} \int_0^{\pi} \int_0^{\pi} \left( \cos k_1 + \cos k_2 + \cos k_3 \right)^n\,dk_1\,dk_2\,dk_3 $$ We can ignore the odd values of $n$ as the integral is zero for them. Also, for even values of $n$, the exponents of cosines in the expansion of $\left( \cos k_1 + \cos k_2 + \cos k_3 \right)^{2n}$ must be even. Hence, from multinomial therem, we can write: $$8\sum_{n=0}^{\infty}\,\,\sum_{m_1+m_2+m_3=n} \frac{1}{3^{2n}}\frac{(2n)!}{(2m_1)! (2m_2)! (2m_3)!} \int_0^{\pi} \int_0^{\pi} \int_0^{\pi} \cos^{2m_1}k_1\cos^{2m_2}k_2 \cos^{2m_3}k_3\,dk_1\,dk_2\,dk_3$$ $$ = 16\sum_{n=0}^{\infty}\,\,\sum_{m_1+m_2+m_3=n} \frac{1}{3^{2n}}\frac{(2n)!}{(2m_1)! (2m_2)! (2m_3)!} \int_0^{\pi/2} \int_0^{\pi/2} \int_0^{\pi/2} \cos^{2m_1}k_1\cos^{2m_2}k_2 \cos^{2m_3}k_3\,dk_1\,dk_2\,dk_3$$ Using the result: $\int_0^{\pi/2} \cos^{2k}x\,dx=\frac{(2k)!}{4^k (k!)^2}\frac{\pi}{2}$, the integral is, $$2\pi^3 \sum_{n=0}^{\infty}\,\,\sum_{m_1+m_2+m_3=n} \frac{1}{36^n}\frac{(2n)!}{(m_1!)^2 (m_2!)^2 (m_3!)^2}$$ I am stuck here. Any help is appreciated. Thanks!","The following integral was posted a few days back on Integrals and Series forum: $$\int_0^{2\pi} \int_0^{2\pi} \int_0^{2\pi} \frac{dk_1\,dk_2\,dk_3}{1-\frac{1}{3}\left(\cos k_1+\cos k_2+ \cos k_3\right)}=\frac{\sqrt{6}}{4}\Gamma\left(\frac{1}{24}\right)\Gamma\left(\frac{5}{24}\right)\Gamma\left(\frac{7}{24}\right)\Gamma\left(\frac{11}{24}\right)$$ I am curious if there is a closed form solution for: $$\int_{\large[0,2\pi]^n} \frac{dk_1\,dk_2\,dk_3\,\cdots \,dk_n}{1-\frac{1}{n}\left(\cos k_1+\cos k_2+\cos k_3+\cdots +\cos k_n\right)}$$ Since $\left|\dfrac{\cos k_1 + \cos k_2 + \cos k_3}{3}\right|<1$, $$\int_0^{2\pi} \int_0^{2\pi} \int_0^{2\pi} \frac{dk_1\,dk_2\,dk_3}{1 - \frac 1 3 \left( \cos k_1 + \cos k_2 + \cos k_3 \right)}$$ $$=8\int_0^{\pi} \int_0^{\pi} \int_0^{\pi} \frac{dk_1\,dk_2\,dk_3}{1 - \frac 1 3 \left( \cos k_1 + \cos k_2 + \cos k_3 \right)}$$ $$=8\sum_{n=0}^{\infty} \frac{1}{3^n} \int_0^{\pi} \int_0^{\pi} \int_0^{\pi} \left( \cos k_1 + \cos k_2 + \cos k_3 \right)^n\,dk_1\,dk_2\,dk_3 $$ We can ignore the odd values of $n$ as the integral is zero for them. Also, for even values of $n$, the exponents of cosines in the expansion of $\left( \cos k_1 + \cos k_2 + \cos k_3 \right)^{2n}$ must be even. Hence, from multinomial therem, we can write: $$8\sum_{n=0}^{\infty}\,\,\sum_{m_1+m_2+m_3=n} \frac{1}{3^{2n}}\frac{(2n)!}{(2m_1)! (2m_2)! (2m_3)!} \int_0^{\pi} \int_0^{\pi} \int_0^{\pi} \cos^{2m_1}k_1\cos^{2m_2}k_2 \cos^{2m_3}k_3\,dk_1\,dk_2\,dk_3$$ $$ = 16\sum_{n=0}^{\infty}\,\,\sum_{m_1+m_2+m_3=n} \frac{1}{3^{2n}}\frac{(2n)!}{(2m_1)! (2m_2)! (2m_3)!} \int_0^{\pi/2} \int_0^{\pi/2} \int_0^{\pi/2} \cos^{2m_1}k_1\cos^{2m_2}k_2 \cos^{2m_3}k_3\,dk_1\,dk_2\,dk_3$$ Using the result: $\int_0^{\pi/2} \cos^{2k}x\,dx=\frac{(2k)!}{4^k (k!)^2}\frac{\pi}{2}$, the integral is, $$2\pi^3 \sum_{n=0}^{\infty}\,\,\sum_{m_1+m_2+m_3=n} \frac{1}{36^n}\frac{(2n)!}{(m_1!)^2 (m_2!)^2 (m_3!)^2}$$ I am stuck here. Any help is appreciated. Thanks!",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'gamma-function']"
5,Log Sine: $\int_0^\pi \theta^2 \ln^2\big(2\sin\frac{\theta}{2}\big)d \theta.$,Log Sine:,\int_0^\pi \theta^2 \ln^2\big(2\sin\frac{\theta}{2}\big)d \theta.,"Hi I am trying to calculate $$ I:=\int_0^\pi \theta^2 \ln^2\big(2\sin\frac{\theta}{2}\big)d \theta. $$ Here is a related Integral $\int_0^\pi \theta^2 \ln^2\big(2\cos\frac{\theta}{2}\big)d \theta$. .  This paper may also be of interest to people here : http://www.math.uwo.ca/~dborwein/cv/zeta4.pdf . We can expand the log in the integral to obtain three interals, one trivial, the other 2 are not so easy, any ideas? I tried doing the following $$ \left( \ln 2 +\ln \sin \frac{\theta}{2} \right)^2=\ln^2(2)+\ln^2\sin\frac{\theta}{2}+2\ln (2)\ln \sin\big(\frac{\theta}{2}\big). $$ We can write I as  $$ I=\ln^2(2)\int_0^\pi \theta^2d\theta  +\int_0^\pi\theta^2 \ln^2 \sin \frac{\theta}{2}d\theta+2\ln 2 \int_0^\pi\theta^2 \ln \sin{\frac{\theta}{2}}d\theta. $$ Change of variables $x=\theta/2$ and performing the trivial integral we obtain $$ I=\frac{\pi^3\ln^2 2}{3}+8\int_0^{\pi/2} x^2 \ln^2 \sin x\, dx+16\ln 2\int_0^{\pi/2} x^2 \ln \sin x \, dx. $$ I am stuck at this point, I was trying to somehow work these two integrals into the form of $$ \int_0^{\pi/2} \ln \sin x dx= \frac{-\pi\ln(2)}{2}\approx -1.08879 $$ but couldn't do so.  Thanks.","Hi I am trying to calculate $$ I:=\int_0^\pi \theta^2 \ln^2\big(2\sin\frac{\theta}{2}\big)d \theta. $$ Here is a related Integral $\int_0^\pi \theta^2 \ln^2\big(2\cos\frac{\theta}{2}\big)d \theta$. .  This paper may also be of interest to people here : http://www.math.uwo.ca/~dborwein/cv/zeta4.pdf . We can expand the log in the integral to obtain three interals, one trivial, the other 2 are not so easy, any ideas? I tried doing the following $$ \left( \ln 2 +\ln \sin \frac{\theta}{2} \right)^2=\ln^2(2)+\ln^2\sin\frac{\theta}{2}+2\ln (2)\ln \sin\big(\frac{\theta}{2}\big). $$ We can write I as  $$ I=\ln^2(2)\int_0^\pi \theta^2d\theta  +\int_0^\pi\theta^2 \ln^2 \sin \frac{\theta}{2}d\theta+2\ln 2 \int_0^\pi\theta^2 \ln \sin{\frac{\theta}{2}}d\theta. $$ Change of variables $x=\theta/2$ and performing the trivial integral we obtain $$ I=\frac{\pi^3\ln^2 2}{3}+8\int_0^{\pi/2} x^2 \ln^2 \sin x\, dx+16\ln 2\int_0^{\pi/2} x^2 \ln \sin x \, dx. $$ I am stuck at this point, I was trying to somehow work these two integrals into the form of $$ \int_0^{\pi/2} \ln \sin x dx= \frac{-\pi\ln(2)}{2}\approx -1.08879 $$ but couldn't do so.  Thanks.",,"['calculus', 'integration', 'complex-analysis', 'definite-integrals', 'improper-integrals']"
6,Proving that $\sum_{k=0}^{\infty}\frac{1}{(k+1)(2k+1)(4k+1)}=\frac{\pi}{3}$,Proving that,\sum_{k=0}^{\infty}\frac{1}{(k+1)(2k+1)(4k+1)}=\frac{\pi}{3},"The following problem(p.668, 7) is from Integrals and Series [ Интегралы и ряды , А.П. Прудников, Ю.А. Брычков, О.И. Маричев.] states that $$\sum_{k=0}^{\infty}\frac{1}{(k+1)(2k+1)(4k+1)}=\frac{\pi}{3}$$ How one can show that?","The following problem(p.668, 7) is from Integrals and Series [ Интегралы и ряды , А.П. Прудников, Ю.А. Брычков, О.И. Маричев.] states that $$\sum_{k=0}^{\infty}\frac{1}{(k+1)(2k+1)(4k+1)}=\frac{\pi}{3}$$ How one can show that?",,"['calculus', 'sequences-and-series']"
7,A Functional Differential Equation: $f^\prime(x) =\frac{f(2x)}{2f(x)}$,A Functional Differential Equation:,f^\prime(x) =\frac{f(2x)}{2f(x)},"I was having a play with some trig. identities and noticed the following: $$\cos{x}=\frac{\sin{2x}}{2\sin{x}}.\tag{1}$$ Now, $\cos{x} = \frac{d}{dx}\sin{x}$ so I made the following analogous  differential equation: $$f^\prime(x) =\frac{f(2x)}{2f(x)} \tag{2}$$ I have not seen a differential equation which relates a function's derivative to a change in its argument, so I was wondering whether anyone knew what these were called? Somewhat predictably, $f_1(x)=\sin{x}$ is not the only solution, I found that $f_2(x)=A\sin(\omega x)$ where $a\omega=1$ is also a solution. I then guessed another solution, $e^{\lambda x}$ , and found that $f_3(x)=e^{\frac{1}{2}x}$ is also a solution. My main questions are: What are these type of equations called? and are there any other solutions to this one? Thanks for reading.","I was having a play with some trig. identities and noticed the following: Now, so I made the following analogous  differential equation: I have not seen a differential equation which relates a function's derivative to a change in its argument, so I was wondering whether anyone knew what these were called? Somewhat predictably, is not the only solution, I found that where is also a solution. I then guessed another solution, , and found that is also a solution. My main questions are: What are these type of equations called? and are there any other solutions to this one? Thanks for reading.",\cos{x}=\frac{\sin{2x}}{2\sin{x}}.\tag{1} \cos{x} = \frac{d}{dx}\sin{x} f^\prime(x) =\frac{f(2x)}{2f(x)} \tag{2} f_1(x)=\sin{x} f_2(x)=A\sin(\omega x) a\omega=1 e^{\lambda x} f_3(x)=e^{\frac{1}{2}x},"['calculus', 'ordinary-differential-equations', 'trigonometry', 'functional-equations']"
8,Show that there are no functions $f: \mathbb R \to \mathbb R$ which have the intermediate value property and $f(f(x))=\cos^2(x)$,Show that there are no functions  which have the intermediate value property and,f: \mathbb R \to \mathbb R f(f(x))=\cos^2(x),"Show that there are no functions $f: \mathbb R \to \mathbb R$ which have the Darboux property (the intermediate value property) and $f(f(x))=\cos^2(x) ; \  \forall \ x\in \mathbb R$. I guess that I'd have to use the fact that $f(f(x)) \in [0,1]$, but I'm not sure how","Show that there are no functions $f: \mathbb R \to \mathbb R$ which have the Darboux property (the intermediate value property) and $f(f(x))=\cos^2(x) ; \  \forall \ x\in \mathbb R$. I guess that I'd have to use the fact that $f(f(x)) \in [0,1]$, but I'm not sure how",,['calculus']
9,Evaluate Integral (Romanian Olympiad),Evaluate Integral (Romanian Olympiad),,$$ \int\cos x\cdot\cos^2(2x)\cdot\cos^3(3x)\cdot\cos^4(4x)\cdot\ldots\cdot\cos^{2002}(2002x)dx $$ Taken from the 2002 Romanian olympiad,$$ \int\cos x\cdot\cos^2(2x)\cdot\cos^3(3x)\cdot\cos^4(4x)\cdot\ldots\cdot\cos^{2002}(2002x)dx $$ Taken from the 2002 Romanian olympiad,,"['calculus', 'integration', 'contest-math']"
10,What is the derivative of a summation with respect to its upper limit?,What is the derivative of a summation with respect to its upper limit?,,"For the moment, consider the corresponding problem involving integration. Let $s(x)$ be the explicit solution to the following integral. $ \displaystyle s(x)=\int_a^x f(t) \, dt $ The function $s'(x)$ is equivalent to the derivative of the integral with respect to it's upper limit and may be expressed in integral form. $ \displaystyle s'(x)=\partial _x\left(\int_a^x f(t) \, dt\right)=f(a)+\int_a^x f'(t) \, dt $ Now let $s(x)$ be the explicit solution to the following summation. $ \displaystyle s(x)=\sum _{t=a}^x f(t) $ The function $s'(x)$ is equivalent to the derivative of the summation with respect to it's upper limit. What is the derivative of $s(x)$ expressed in summation form? $ \displaystyle s'(x)=\partial _x\left(\sum _{t=a}^x f(t)\right)=\ ? $","For the moment, consider the corresponding problem involving integration. Let $s(x)$ be the explicit solution to the following integral. $ \displaystyle s(x)=\int_a^x f(t) \, dt $ The function $s'(x)$ is equivalent to the derivative of the integral with respect to it's upper limit and may be expressed in integral form. $ \displaystyle s'(x)=\partial _x\left(\int_a^x f(t) \, dt\right)=f(a)+\int_a^x f'(t) \, dt $ Now let $s(x)$ be the explicit solution to the following summation. $ \displaystyle s(x)=\sum _{t=a}^x f(t) $ The function $s'(x)$ is equivalent to the derivative of the summation with respect to it's upper limit. What is the derivative of $s(x)$ expressed in summation form? $ \displaystyle s'(x)=\partial _x\left(\sum _{t=a}^x f(t)\right)=\ ? $",,"['calculus', 'asymptotics', 'summation']"
11,List of techniques to evaluate limits?,List of techniques to evaluate limits?,,"I'd like to make a complete list of techniques to evaluate a limit. Definition of the limit Continuous functions Algebra of limits Addition, multiplication, division Composition Inverse function Showing inequalities Squeeze theorem Rewriting, try to factor out common factors in numerator and denominator Rationalizing the denominator Substitutions, in particular the $1/t$ substitution. Use of derivatives, l'Hôpital's rule and Taylor series. If $\lim_{x\to a} f(x)=1$ and $\lim_{x\to a} g(x)=\infty$ then $$\lim_{x\to a} f(x)^{g(x)} = e^{\lim_{x\to a} g(x)[f(x)-1]}$$ for $$0^0\quad and\quad \infty^0 \quad form \implies $$ $$\lim_{x\to a} f(x)^{g(x)}=e^{\lim_{x\to a}[g(x) \log_e{f(x)}]}$$ However the list seems so short. Are there any other good strategies or techniques to solve limits?","I'd like to make a complete list of techniques to evaluate a limit. Definition of the limit Continuous functions Algebra of limits Addition, multiplication, division Composition Inverse function Showing inequalities Squeeze theorem Rewriting, try to factor out common factors in numerator and denominator Rationalizing the denominator Substitutions, in particular the substitution. Use of derivatives, l'Hôpital's rule and Taylor series. If and then for However the list seems so short. Are there any other good strategies or techniques to solve limits?",1/t \lim_{x\to a} f(x)=1 \lim_{x\to a} g(x)=\infty \lim_{x\to a} f(x)^{g(x)} = e^{\lim_{x\to a} g(x)[f(x)-1]} 0^0\quad and\quad \infty^0 \quad form \implies  \lim_{x\to a} f(x)^{g(x)}=e^{\lim_{x\to a}[g(x) \log_e{f(x)}]},"['calculus', 'limits']"
12,Prove or disprove the inequality $\sqrt{1+\sin b}-\sqrt{1+\sin a}\leq\frac{b-a}{2}$,Prove or disprove the inequality,\sqrt{1+\sin b}-\sqrt{1+\sin a}\leq\frac{b-a}{2},"I'm asked to prove or to disprove the inequality $$\sqrt{1+\sin b}-\sqrt{1+\sin a}\leq\frac{b-a}{2}$$ for all $0<a<b<\pi/2$. I believe that it is true. Proof : Let $f(x):=\sqrt{1+\sin x}$. The function $f(x)$ is continuous on the interval $[a,b]\subseteq[0,\pi/2]$ and is differentiable on $(a,b)$. Thus, by the mean value theorem there exists a point $c\in (a,b)$ such that $$f'(c)=\frac{\cos c}{2\sqrt{1+\sin c}}=\frac{f(b)-f(a)}{b-a}$$ and because $0<c<\pi/2$, $$\frac{\cos c}{2\sqrt{1+\sin c}}<\frac{\cos 0}{2\sqrt{1+\sin 0}}=\frac{1}{2}$$ And thus: $$f'(c)=\frac{f(b)-f(a)}{b-a}<\frac{1}{2} \Rightarrow \sqrt{1+\sin b}-\sqrt{1+\sin a}\leq\frac{b-a}{2}$$ Is it correct?","I'm asked to prove or to disprove the inequality $$\sqrt{1+\sin b}-\sqrt{1+\sin a}\leq\frac{b-a}{2}$$ for all $0<a<b<\pi/2$. I believe that it is true. Proof : Let $f(x):=\sqrt{1+\sin x}$. The function $f(x)$ is continuous on the interval $[a,b]\subseteq[0,\pi/2]$ and is differentiable on $(a,b)$. Thus, by the mean value theorem there exists a point $c\in (a,b)$ such that $$f'(c)=\frac{\cos c}{2\sqrt{1+\sin c}}=\frac{f(b)-f(a)}{b-a}$$ and because $0<c<\pi/2$, $$\frac{\cos c}{2\sqrt{1+\sin c}}<\frac{\cos 0}{2\sqrt{1+\sin 0}}=\frac{1}{2}$$ And thus: $$f'(c)=\frac{f(b)-f(a)}{b-a}<\frac{1}{2} \Rightarrow \sqrt{1+\sin b}-\sqrt{1+\sin a}\leq\frac{b-a}{2}$$ Is it correct?",,"['calculus', 'proof-verification']"
13,Something Isn't Right With My Parking,Something Isn't Right With My Parking,,"A few days ago in my Calculus BC class we were given a page of 6 challenging end of the year problems. That was a refreshing change from the drudgery we usually do (WebAssign). One of them went like this: There is a street of length 4 on which cars of length 1 wish to park.  However, instead of parking in a nice organized way, they park at random, picking uniformly from the available positions to park (they are apparently jerks).  Assuming no cars leave, and continue to arrive until no more can fit, what is the expected number of cars that will fit? I tried solving the problem by finding the probabilities of 2 and 3 cars. When I looked up the answer at https://cornellmath.wordpress.com/2008/01/08/the-efficiency-of-random-parking/ the answer was transcendental while mine was rational. I messed up somewhere along the way or in one of my assumptions. I'd like to know why my solution is incorrect. My Solution: So we start with a street of length $4$ which can be represented by a number line starting from $0$ and ending at $4$, i.e. the interval $[0, 4]$. Say the first car takes up the interval $[a_1, a_1+1]$, where $0\le a_1 \le 3$. Now, the choice of parking for the first car limits where the second car can park. Let the left endpoint of the second car be $a_2$. Then, just as above, we have $0\le a_2 \le 3$. Additionally, $a_2$ must either be greater than or equal to the right endpoint of the first car ($a_2 \ge a_1 + 1$), or lesser than or equal to one minus the left endpoint of the first car($a_2 \le a_1 - 1$). These restrictions determine a ""sample space"" (I think that is the appropriate term but I am not sure) of tuples $(a_1, a_2)$. This sample space can then be depicted by a region bounded between curves in cartesian coordinates. I have uploaded a picture of my hand drawn graph. The shaded region represents the sample space. I will now explain how I got the boundaries for the sample space. If $0\le a_1\le 2$ then, from what I said previously, we have $a_1 +1 \le a_2\le3$. Similarly, if $1\le a_1\le3$ then $0\ge a_2\ge a_1-1$. Note that when $1\le a_1\le2$ we take the union of the described regions. Now this is the home stretch. It is clear that the choice of $(a_1, a_2)$ dictates whether a third car will fit or not. So the question becomes ""what percentage of tuples allow for a third car to fit?"" If we look at the interval where $1\le a_1\le2$ we see that regardless of where we place the second car there will always be room for a third. So this region is part of the answer. Let's look at when $0\le a_1\le1$. In this case, no cars can fit before the first, so a third car could only fit if there was an empty space of length one between the second car and the right end of the street, or if there was enough space between the first and second car. The first case is true when $a_2\le2$. The second is true when $a_2\ge a_1 + 2$. Symmetry can be used to find analogous boundaries when $2\le a_1\le3$. All of these inequalities form bounded regions whose areas can be easily calculated. In the end the probability of fitting 3 cars comes out to $\frac{3}{4}$! WHAT IS WRONG WITH THIS SOLUTION?!?!","A few days ago in my Calculus BC class we were given a page of 6 challenging end of the year problems. That was a refreshing change from the drudgery we usually do (WebAssign). One of them went like this: There is a street of length 4 on which cars of length 1 wish to park.  However, instead of parking in a nice organized way, they park at random, picking uniformly from the available positions to park (they are apparently jerks).  Assuming no cars leave, and continue to arrive until no more can fit, what is the expected number of cars that will fit? I tried solving the problem by finding the probabilities of 2 and 3 cars. When I looked up the answer at https://cornellmath.wordpress.com/2008/01/08/the-efficiency-of-random-parking/ the answer was transcendental while mine was rational. I messed up somewhere along the way or in one of my assumptions. I'd like to know why my solution is incorrect. My Solution: So we start with a street of length $4$ which can be represented by a number line starting from $0$ and ending at $4$, i.e. the interval $[0, 4]$. Say the first car takes up the interval $[a_1, a_1+1]$, where $0\le a_1 \le 3$. Now, the choice of parking for the first car limits where the second car can park. Let the left endpoint of the second car be $a_2$. Then, just as above, we have $0\le a_2 \le 3$. Additionally, $a_2$ must either be greater than or equal to the right endpoint of the first car ($a_2 \ge a_1 + 1$), or lesser than or equal to one minus the left endpoint of the first car($a_2 \le a_1 - 1$). These restrictions determine a ""sample space"" (I think that is the appropriate term but I am not sure) of tuples $(a_1, a_2)$. This sample space can then be depicted by a region bounded between curves in cartesian coordinates. I have uploaded a picture of my hand drawn graph. The shaded region represents the sample space. I will now explain how I got the boundaries for the sample space. If $0\le a_1\le 2$ then, from what I said previously, we have $a_1 +1 \le a_2\le3$. Similarly, if $1\le a_1\le3$ then $0\ge a_2\ge a_1-1$. Note that when $1\le a_1\le2$ we take the union of the described regions. Now this is the home stretch. It is clear that the choice of $(a_1, a_2)$ dictates whether a third car will fit or not. So the question becomes ""what percentage of tuples allow for a third car to fit?"" If we look at the interval where $1\le a_1\le2$ we see that regardless of where we place the second car there will always be room for a third. So this region is part of the answer. Let's look at when $0\le a_1\le1$. In this case, no cars can fit before the first, so a third car could only fit if there was an empty space of length one between the second car and the right end of the street, or if there was enough space between the first and second car. The first case is true when $a_2\le2$. The second is true when $a_2\ge a_1 + 2$. Symmetry can be used to find analogous boundaries when $2\le a_1\le3$. All of these inequalities form bounded regions whose areas can be easily calculated. In the end the probability of fitting 3 cars comes out to $\frac{3}{4}$! WHAT IS WRONG WITH THIS SOLUTION?!?!",,"['calculus', 'probability', 'analytic-geometry', 'solution-verification']"
14,"How is the shape of the curve $f(x)$, near $x=a$, affected by $f'''(a)$","How is the shape of the curve , near , affected by",f(x) x=a f'''(a),"In introductory calculus classes we learn the utility of calculating $f'(x)$ and $f''(x)$ for sketching the curve $f(x)$. My question is given $f'''(a)$, how does this value affect the shape a curve $f(x)$ for $x$ near $a$? Consider an example where $f'(x)>0$ and $f''(x)<0$ on the whole domain. How does the sign of $f'''(x)$ change the shape of the curve?","In introductory calculus classes we learn the utility of calculating $f'(x)$ and $f''(x)$ for sketching the curve $f(x)$. My question is given $f'''(a)$, how does this value affect the shape a curve $f(x)$ for $x$ near $a$? Consider an example where $f'(x)>0$ and $f''(x)<0$ on the whole domain. How does the sign of $f'''(x)$ change the shape of the curve?",,['calculus']
15,Integral of $\sqrt{x^3 + 8}$?,Integral of ?,\sqrt{x^3 + 8},"I have issues solving the following integral: $$\int\sqrt{x^3+8}~dx$$ I tried substitution and integration by parts, but with no use.  I'm guessing I have to use some trigonometric substitution. Can anybody help solve this integral?","I have issues solving the following integral: $$\int\sqrt{x^3+8}~dx$$ I tried substitution and integration by parts, but with no use.  I'm guessing I have to use some trigonometric substitution. Can anybody help solve this integral?",,"['calculus', 'integration', 'indefinite-integrals']"
16,"What is the coefficient of $x^{2k}$ in the $n$-th iterate, $f^{(n)}(x)$, if $f(x)=1+x^2$?","What is the coefficient of  in the -th iterate, , if ?",x^{2k} n f^{(n)}(x) f(x)=1+x^2,"Let $f(x)=1+x^2$, and its $n$-th compositional iterate $f^{(n)}=\sum_{k=0}^N  c_{k,n} x^{2k}$, where $N=2^{n-1}$.  What do we know about $c_{k,n}$?","Let $f(x)=1+x^2$, and its $n$-th compositional iterate $f^{(n)}=\sum_{k=0}^N  c_{k,n} x^{2k}$, where $N=2^{n-1}$.  What do we know about $c_{k,n}$?",,"['calculus', 'sequences-and-series']"
17,Folium of Descartes,Folium of Descartes,,"A colleague came to me with an interesting observation: Consider the folium of Descartes, $$x^3+y^3=3axy$$ which upon implicit differentiation of the latter yields $$\frac{\mathrm dy}{\mathrm dx}=\frac{ay-x^2}{y^2-ax}$$ Now, the interesting observation is that if one considers the set of curves parametrized by $m\in\mathbb{R}$ $$ay-x^2=m(y^2-ax),$$ then all the curves intersect at a single point within the loop of the folium (namely, $(a,a)$). Further experimentation yielded similar results for the family of curves $$x^n+y^n=naxy.$$  It is clear how this all ""works,"" but what is unclear is Why should these curves intersect? Furthermore, Is there a name to describe this behavior/phenomenon? To clarify further, the point of intersection corresponds to the value where both the numerator and denominator in the derivative vanish (this also happens at the origin).  This is what is meant by how this ""works."" Thanks! Edit:  Added a picture to hopefully aid in my explanation.  (Curves correspond to $a=2, m=1, \frac12, -\frac{1}{2}$.) Edit2: Fixed derivative formula.","A colleague came to me with an interesting observation: Consider the folium of Descartes, $$x^3+y^3=3axy$$ which upon implicit differentiation of the latter yields $$\frac{\mathrm dy}{\mathrm dx}=\frac{ay-x^2}{y^2-ax}$$ Now, the interesting observation is that if one considers the set of curves parametrized by $m\in\mathbb{R}$ $$ay-x^2=m(y^2-ax),$$ then all the curves intersect at a single point within the loop of the folium (namely, $(a,a)$). Further experimentation yielded similar results for the family of curves $$x^n+y^n=naxy.$$  It is clear how this all ""works,"" but what is unclear is Why should these curves intersect? Furthermore, Is there a name to describe this behavior/phenomenon? To clarify further, the point of intersection corresponds to the value where both the numerator and denominator in the derivative vanish (this also happens at the origin).  This is what is meant by how this ""works."" Thanks! Edit:  Added a picture to hopefully aid in my explanation.  (Curves correspond to $a=2, m=1, \frac12, -\frac{1}{2}$.) Edit2: Fixed derivative formula.",,"['calculus', 'algebraic-geometry', 'plane-curves']"
18,Evaluating $\int\limits_0^\infty{\frac{1}{1+x^2+x^\alpha}dx}$,Evaluating,\int\limits_0^\infty{\frac{1}{1+x^2+x^\alpha}dx},"I'm trying to evaluate$$f(\alpha)=\int\limits_0^\infty{\frac{1}{1+x^2+x^\alpha}dx}$$ I proved: $f(\alpha)$ converges when $\alpha\in\mathbb{R}$ $f(2-\alpha)=f(\alpha)$ $f(0)=f(2)=\frac{\pi}{2\sqrt{2}}$ $f(1)=\frac{2\pi}{3\sqrt{3}}$ $f(-\infty)=f(\infty)=\frac{\pi}{4}$ Similar question:$$\int\limits_0^\infty{\frac{1}{1+x^\alpha}dx}=\frac{\pi}{\alpha}\csc\frac{\pi}{\alpha}$$ I tried all of the techniques can be used in evaluating this integral, but I still cannot get the answer. When I was using complex analysis, I found that the poles of $\frac{1}{1+x^2+x^\alpha}$ is hard to be found.","I'm trying to evaluate$$f(\alpha)=\int\limits_0^\infty{\frac{1}{1+x^2+x^\alpha}dx}$$ I proved: $f(\alpha)$ converges when $\alpha\in\mathbb{R}$ $f(2-\alpha)=f(\alpha)$ $f(0)=f(2)=\frac{\pi}{2\sqrt{2}}$ $f(1)=\frac{2\pi}{3\sqrt{3}}$ $f(-\infty)=f(\infty)=\frac{\pi}{4}$ Similar question:$$\int\limits_0^\infty{\frac{1}{1+x^\alpha}dx}=\frac{\pi}{\alpha}\csc\frac{\pi}{\alpha}$$ I tried all of the techniques can be used in evaluating this integral, but I still cannot get the answer. When I was using complex analysis, I found that the poles of $\frac{1}{1+x^2+x^\alpha}$ is hard to be found.",,"['calculus', 'integration', 'complex-analysis', 'definite-integrals']"
19,"Suppose $f$ is continuous on $[0,2]$ and $f(0) = f(2)$. For which $a\in(0,2)$ must there exist $x,y\in[0,2]$ so that $|y − x| = a$ and $f(x) = f(y)$?",Suppose  is continuous on  and . For which  must there exist  so that  and ?,"f [0,2] f(0) = f(2) a\in(0,2) x,y\in[0,2] |y − x| = a f(x) = f(y)","Suppose $f$ is continuous on $[0,2]$ and $f(0) = f(2)$.  For which $a\in(0,2)$ must there exist $x,y\in[0,2]$ so that $\lvert y − x\rvert = a$ and $f(x) = f(y)$ I'm really unsure how to approach this problem ...we did a similar problem where $a=1$, by defining $g(x) = f(x+1)-f(x)$ on $[0,1]$, then applying the IVT. Is this problem approached in a similar way? If not, what's a good starting point? Thank you for any ideas!","Suppose $f$ is continuous on $[0,2]$ and $f(0) = f(2)$.  For which $a\in(0,2)$ must there exist $x,y\in[0,2]$ so that $\lvert y − x\rvert = a$ and $f(x) = f(y)$ I'm really unsure how to approach this problem ...we did a similar problem where $a=1$, by defining $g(x) = f(x+1)-f(x)$ on $[0,1]$, then applying the IVT. Is this problem approached in a similar way? If not, what's a good starting point? Thank you for any ideas!",,['calculus']
20,Exponential integral: something is wrong.,Exponential integral: something is wrong.,,"Consider the function  $$ E(z)=\int_{-\infty}^z\frac{e^t}{t}dt.\quad (1) $$ Substituting $t\mapsto -u$ one obtains $$ E(z)=-\int_{-z}^{\infty}\frac{e^{-u}}{u}du\equiv Ei(z).\quad (2) $$ It is already surprising that the ugly definiton (2) and not (1) is usually used for $Ei(z)$. Much worser is the fact that both definitions lead to different results upon expanding the functions. For this we use the usual trick (standard branch cut along the negative real semi-axis is assumed, if necessary): $$ Ei(z)=-\int_{-z}^{\infty}\frac{e^{-u}}{u}du +\int_0^{-z}\frac{1-e^{-u}}{u}du-\int_0^{-z}\frac{1-e^{-u}}{u}du\\ =\left[\left.-e^{-u}\ln u\right|_{-z}^\infty-\int_{-z}^\infty e^{-u}\ln u du\right]+\left[\left.(1-e^{-u})\ln u\right|_0^{-z}-\int_0^{-z}e^{-u}\ln u du\right]+\int_0^z\frac{e^t-1}{t}dt\\ =\ln(-z)+\gamma+\sum_{n=1}^\infty\frac{z^n}{n!n}. $$ Applying the same trick for (1) one obtains: $$ E(z)=\int_{-\infty}^z\frac{e^{u}}{u}du- \int_0^{z}\frac{e^{u}-1}{u}du+\int_0^{z}\frac{e^{u}-1}{u}du\\ =\left[\left.e^{u}\ln u\right|_{-\infty}^z-\int_{-\infty}^z e^{u}\ln u du\right]-\left[\left.(e^{u}-1)\ln u\right|_0^{z}-\int_0^{z}e^{u}\ln u du\right]+\int_0^z\frac{e^u-1}{u}dt\\ =\ln(z)-\int_{-\infty}^0e^u\ln u du+\sum_{n=1}^\infty\frac{z^n}{n!n}= \ln(z)-\int_0^{\infty}e^{-t}\ln(-t)dt+\sum_{n=1}^\infty\frac{z^n}{n!n}\\ =\ln(z)-\int_0^{\infty}e^{-t}(\ln t+i\pi)dt+\sum_{n=1}^\infty\frac{z^n}{n!n} =\ln(z)-i\pi+\gamma+\sum_{n=1}^\infty\frac{z^n}{n!n}. $$ The problem is that the equality $\ln(-z)=\ln(z)-i\pi$ with usual restriction $-i\pi<\arg(z)\le i\pi$ is valid only in the upper complex half-plane (including the negative real semi-axis). In the lower complex half-plane (including the positive real semi-axis) the two values differs by $2\pi i$. Which result is correct? Where is hidden the error, resulting in the contradiction?","Consider the function  $$ E(z)=\int_{-\infty}^z\frac{e^t}{t}dt.\quad (1) $$ Substituting $t\mapsto -u$ one obtains $$ E(z)=-\int_{-z}^{\infty}\frac{e^{-u}}{u}du\equiv Ei(z).\quad (2) $$ It is already surprising that the ugly definiton (2) and not (1) is usually used for $Ei(z)$. Much worser is the fact that both definitions lead to different results upon expanding the functions. For this we use the usual trick (standard branch cut along the negative real semi-axis is assumed, if necessary): $$ Ei(z)=-\int_{-z}^{\infty}\frac{e^{-u}}{u}du +\int_0^{-z}\frac{1-e^{-u}}{u}du-\int_0^{-z}\frac{1-e^{-u}}{u}du\\ =\left[\left.-e^{-u}\ln u\right|_{-z}^\infty-\int_{-z}^\infty e^{-u}\ln u du\right]+\left[\left.(1-e^{-u})\ln u\right|_0^{-z}-\int_0^{-z}e^{-u}\ln u du\right]+\int_0^z\frac{e^t-1}{t}dt\\ =\ln(-z)+\gamma+\sum_{n=1}^\infty\frac{z^n}{n!n}. $$ Applying the same trick for (1) one obtains: $$ E(z)=\int_{-\infty}^z\frac{e^{u}}{u}du- \int_0^{z}\frac{e^{u}-1}{u}du+\int_0^{z}\frac{e^{u}-1}{u}du\\ =\left[\left.e^{u}\ln u\right|_{-\infty}^z-\int_{-\infty}^z e^{u}\ln u du\right]-\left[\left.(e^{u}-1)\ln u\right|_0^{z}-\int_0^{z}e^{u}\ln u du\right]+\int_0^z\frac{e^u-1}{u}dt\\ =\ln(z)-\int_{-\infty}^0e^u\ln u du+\sum_{n=1}^\infty\frac{z^n}{n!n}= \ln(z)-\int_0^{\infty}e^{-t}\ln(-t)dt+\sum_{n=1}^\infty\frac{z^n}{n!n}\\ =\ln(z)-\int_0^{\infty}e^{-t}(\ln t+i\pi)dt+\sum_{n=1}^\infty\frac{z^n}{n!n} =\ln(z)-i\pi+\gamma+\sum_{n=1}^\infty\frac{z^n}{n!n}. $$ The problem is that the equality $\ln(-z)=\ln(z)-i\pi$ with usual restriction $-i\pi<\arg(z)\le i\pi$ is valid only in the upper complex half-plane (including the negative real semi-axis). In the lower complex half-plane (including the positive real semi-axis) the two values differs by $2\pi i$. Which result is correct? Where is hidden the error, resulting in the contradiction?",,"['calculus', 'complex-analysis']"
21,An extremely mysterious integral: $\int_0^1 \frac{k \tan^{-1}(t)}{k^2 + t^2}\mathrm d t$,An extremely mysterious integral:,\int_0^1 \frac{k \tan^{-1}(t)}{k^2 + t^2}\mathrm d t,"$$f(n) = \int_0^1 \frac{n \tan^{-1}(t)}{n^2 + t^2}\mathrm d t \tag{n > 2}$$ Introduction: This is one of the most beautiful and mysterious integrals I've every encountered. It's very simple, but my conjectured closed form is one of the most bizzare I've ever seen. What I know: All of the closed forms that Mathematica gives have the following form: $$\frac18 \big(\tan^{-1}(a_n)^2 - 4i \cot^{-1}(n) \log(b_n) +     2 i \tan^{-1}(a_n) \log(b_n) - 2 (\text{Li}_2(c_n - id_n) + \text{Li}_2(c_n + id_n)-        \text{Li}_2(\frac{1}{b_n}) \big{)}$$ Pretty ugly, I know. But the really amazing part is what comes next. The Conjecture: $$a_n= \frac{\left.   \begin{cases}     2n & \text{n even}  \\     n & \text{n odd }   \end{cases}   \right\}}{\text{lcm}(n+1,n-1)} \\ b_n=  \frac{\left.   \begin{cases}     n+1 & \text{n even}  \\     \frac{n+1}{2} & \text{n odd }   \end{cases}   \right\}}{\left.   \begin{cases}     \frac{n}{2} & \text{n even}  \\     n & \text{n odd }   \end{cases}   \right\} \\} \\ c_n =  \frac{\text{(n-1) * largest prime factor of } n-1}{\text{largest odd divisor of } n^2 + 1} $$   And I have no idea what $d_n$ could be. The conjecture holds for at least the first 20 values of n, as well as 20 other random higher values of n, and I think it's too simple to just be a coincidence. So, my questions are: What is $d_n$? How can I prove or disprove this conjecture? Any help is appreciated, thanks!","$$f(n) = \int_0^1 \frac{n \tan^{-1}(t)}{n^2 + t^2}\mathrm d t \tag{n > 2}$$ Introduction: This is one of the most beautiful and mysterious integrals I've every encountered. It's very simple, but my conjectured closed form is one of the most bizzare I've ever seen. What I know: All of the closed forms that Mathematica gives have the following form: $$\frac18 \big(\tan^{-1}(a_n)^2 - 4i \cot^{-1}(n) \log(b_n) +     2 i \tan^{-1}(a_n) \log(b_n) - 2 (\text{Li}_2(c_n - id_n) + \text{Li}_2(c_n + id_n)-        \text{Li}_2(\frac{1}{b_n}) \big{)}$$ Pretty ugly, I know. But the really amazing part is what comes next. The Conjecture: $$a_n= \frac{\left.   \begin{cases}     2n & \text{n even}  \\     n & \text{n odd }   \end{cases}   \right\}}{\text{lcm}(n+1,n-1)} \\ b_n=  \frac{\left.   \begin{cases}     n+1 & \text{n even}  \\     \frac{n+1}{2} & \text{n odd }   \end{cases}   \right\}}{\left.   \begin{cases}     \frac{n}{2} & \text{n even}  \\     n & \text{n odd }   \end{cases}   \right\} \\} \\ c_n =  \frac{\text{(n-1) * largest prime factor of } n-1}{\text{largest odd divisor of } n^2 + 1} $$   And I have no idea what $d_n$ could be. The conjecture holds for at least the first 20 values of n, as well as 20 other random higher values of n, and I think it's too simple to just be a coincidence. So, my questions are: What is $d_n$? How can I prove or disprove this conjecture? Any help is appreciated, thanks!",,"['calculus', 'integration', 'definite-integrals', 'special-functions']"
22,"Intuition behind the ""infinite velocity"" of a falling ladder","Intuition behind the ""infinite velocity"" of a falling ladder",,"In Calculus there is a ""classic"" related rates problem involving a falling ladder.  Say the ladder is $25$ ft tall and is leaning against a wall.  The bottom edge of the ladder is pulled away from the wall at a constant rate of $2$ ft/sec; as it moves, the top of the ladder slides down the wall.  The student is asked to express the downward velocity of the top of the ladder in terms of the position $x$ of the bottom of the ladder, and finds that $$\frac{dy}{dt}=-\frac{2x}{\sqrt{625-x^2}}$$ Of course it makes sense that the velocity should only be defined up to $x=25$, because beyond that point the ladder comes away from the wall.  But it seems strange (even to me, who has taught this stuff) that the downward velocity approaches $\infty$ as $x \to 25$.  Why is that a ""reasonable"" result?  If I imagine a speedometer attached to the top of the ladder, it's hard for me to believe that in the moments before the ladder hits the ground the speedometer readout increases without bound. Is there an intuitive explanation of why the downward velocity of the top of the ladder ought to diverge to infinity as the ladder hits the ground?","In Calculus there is a ""classic"" related rates problem involving a falling ladder.  Say the ladder is $25$ ft tall and is leaning against a wall.  The bottom edge of the ladder is pulled away from the wall at a constant rate of $2$ ft/sec; as it moves, the top of the ladder slides down the wall.  The student is asked to express the downward velocity of the top of the ladder in terms of the position $x$ of the bottom of the ladder, and finds that $$\frac{dy}{dt}=-\frac{2x}{\sqrt{625-x^2}}$$ Of course it makes sense that the velocity should only be defined up to $x=25$, because beyond that point the ladder comes away from the wall.  But it seems strange (even to me, who has taught this stuff) that the downward velocity approaches $\infty$ as $x \to 25$.  Why is that a ""reasonable"" result?  If I imagine a speedometer attached to the top of the ladder, it's hard for me to believe that in the moments before the ladder hits the ground the speedometer readout increases without bound. Is there an intuitive explanation of why the downward velocity of the top of the ladder ought to diverge to infinity as the ladder hits the ground?",,"['calculus', 'physics', 'intuition']"
23,Confusion about differentials,Confusion about differentials,,"If we have some differentiable function $f(x)$, then by the definition, we have: $$\mathrm{d}y = f'(x) \mathrm{d}x$$ This makes sense; the differential $\mathrm{d}y$ can be thought of as a function that expresses the linear change in $y$ given a finite change $\mathrm{d}x$ in $x$. Now, what confuses me is why we can simply do this: $$\int \mathrm{d}y = \int f'(x) \mathrm{d}x$$ and just magically append integrals to both sides of the equation. Some people tell me that the ""differentials"" in the integrand aren't really being multiplied by the integrand, and others tell me that they are. If they are not multiplied by the integrand, then I don't see why that above step is justified. $\mathrm{d}y$ has changed from a finite quantity to a ""closing parentheses"" on the integral once we performed the integration. But somehow, this method works, and it is essentially how most students are taught (including myself) to solve very simple differential equations. To complicate matters further, my physics teacher explained that $\frac{dy}{dx}$ is a quotient of infinitesimal changes, and therefore $\mathrm{d}y = f'(x) \mathrm{d} x$ is quite easy to see. The integration symbols are just summing these infinitesimals over a given region (whether it be an area, a volume, or in the above case, a simple one dimensional segment). From this viewpoint, we are actually multiplying the integrand by $\mathrm{d}x$. Although this ""definition"" of differentials disagrees with their definition as finite quantities (as described at the top of the question) , it does seem to satisfy my intuition quite nicely. For instance, it solves the mystery of ""magically appending"" integrals to both sides of an equation. For example, consider the integral: $$\int x \cos\left(x^2\right) \mathrm{d}x = \frac{1}{2} \int \cos(u) \mathrm{d}u$$ where I have simply replaced $x \times \mathrm{d}x$ with $\frac{1}{2} \mathrm{d}u$. If the differentials weren't part of the product, and were just ""closing parentheses"" (as some people have told me), then why does this work? Viewing the differential as an infinitesimal part of a product therefore has nice properties; not only is it dimensionally accurate, but it also makes these $u$-substitutions quite intuitive. If $\mathrm{d}x$ were just a closing parentheses on the integral, I don't see how we can substitute $x$ times a closing parentheses with another closing parentheses. But recently, in my multivariable class, we learned that: $$\mathrm{d}x \mathrm{d}y = \left| \frac{\partial(x, y)}{\partial(u, v)}\right| \mathrm{d}u \mathrm{d}v$$. and we learned that the differential element $\mathrm{d}A = \mathrm{d}x \mathrm{d}y$ is the area of an infinitesimally small rectangle. Under the transformation of the jacobian, an infinitesimally small rectangle area in $uv$-space differs from that of a rectangle in $xy$-space by a factor of the jacobian's determinant. This matrix is essentially transforming $uv$-space areas into $xy$-space areas. This makes sense, but when coupled with the definition of a differential, I see an apparent contradiction. Consider the polar coordinate transformation, in which we have $x = r \cos{\theta}$ and $y = r\sin{\theta}$. By the above equation, we have that $\mathrm{d}x \mathrm{d}y = r \mathrm{d}r \mathrm{d}\theta$. But if we were to compute the differentials of $x$ and $y$ and multiply them together, expanding the product would not give us $r \mathrm{d}r \mathrm{d}\theta$. It would give us a bunch of ugly stuff, and I'm not even sure this ""stuff"" is meaningful. If the differentials were truly being multiplied by one other, then after expanding their product (which I am not going to do here), the result would be $r \mathrm{d}r \mathrm{d}\theta$. But this is not the case. So in the end, neither the viewpoint of differentials as ""infinitesimals"" multiplied to the integrand, nor the viewpoint of differentials as linear changes makes sense to me. If differentials were infinitesimals multiplied to an integrand, then why does expanding the product $\mathrm{d} x(r, \theta) \times \mathrm{d}y(r, \theta)$ not yield $r \mathrm{d}r \mathrm{d}\theta$? If differentials were finite, linear changes, why can we just magically ""slap on"" integrals on both sides of the equation $\mathrm{d}y = f'(x) \mathrm{d}x$? And probably most importantly, are differentials just closing parantheses, or are they actually multiplied by the integrand? If we consider them as part of an infinitesimal product, then this makes appending integrals to both sides justified. But if they are just ""closing parantheses"", then why is appending integrals to both sides of an equation justified? A finite quantity ($\mathrm{d}x$) cannot magically ""transform"" into a piece of notation by simply writing an integral symbol on both sides of the equation. I am very confused about differentials, and I would appreciate if someone could clarify exacty why multiplying them doesn't work in the intuitive way described above, and why we are allowed to just append integrals to both sides of an equation.","If we have some differentiable function $f(x)$, then by the definition, we have: $$\mathrm{d}y = f'(x) \mathrm{d}x$$ This makes sense; the differential $\mathrm{d}y$ can be thought of as a function that expresses the linear change in $y$ given a finite change $\mathrm{d}x$ in $x$. Now, what confuses me is why we can simply do this: $$\int \mathrm{d}y = \int f'(x) \mathrm{d}x$$ and just magically append integrals to both sides of the equation. Some people tell me that the ""differentials"" in the integrand aren't really being multiplied by the integrand, and others tell me that they are. If they are not multiplied by the integrand, then I don't see why that above step is justified. $\mathrm{d}y$ has changed from a finite quantity to a ""closing parentheses"" on the integral once we performed the integration. But somehow, this method works, and it is essentially how most students are taught (including myself) to solve very simple differential equations. To complicate matters further, my physics teacher explained that $\frac{dy}{dx}$ is a quotient of infinitesimal changes, and therefore $\mathrm{d}y = f'(x) \mathrm{d} x$ is quite easy to see. The integration symbols are just summing these infinitesimals over a given region (whether it be an area, a volume, or in the above case, a simple one dimensional segment). From this viewpoint, we are actually multiplying the integrand by $\mathrm{d}x$. Although this ""definition"" of differentials disagrees with their definition as finite quantities (as described at the top of the question) , it does seem to satisfy my intuition quite nicely. For instance, it solves the mystery of ""magically appending"" integrals to both sides of an equation. For example, consider the integral: $$\int x \cos\left(x^2\right) \mathrm{d}x = \frac{1}{2} \int \cos(u) \mathrm{d}u$$ where I have simply replaced $x \times \mathrm{d}x$ with $\frac{1}{2} \mathrm{d}u$. If the differentials weren't part of the product, and were just ""closing parentheses"" (as some people have told me), then why does this work? Viewing the differential as an infinitesimal part of a product therefore has nice properties; not only is it dimensionally accurate, but it also makes these $u$-substitutions quite intuitive. If $\mathrm{d}x$ were just a closing parentheses on the integral, I don't see how we can substitute $x$ times a closing parentheses with another closing parentheses. But recently, in my multivariable class, we learned that: $$\mathrm{d}x \mathrm{d}y = \left| \frac{\partial(x, y)}{\partial(u, v)}\right| \mathrm{d}u \mathrm{d}v$$. and we learned that the differential element $\mathrm{d}A = \mathrm{d}x \mathrm{d}y$ is the area of an infinitesimally small rectangle. Under the transformation of the jacobian, an infinitesimally small rectangle area in $uv$-space differs from that of a rectangle in $xy$-space by a factor of the jacobian's determinant. This matrix is essentially transforming $uv$-space areas into $xy$-space areas. This makes sense, but when coupled with the definition of a differential, I see an apparent contradiction. Consider the polar coordinate transformation, in which we have $x = r \cos{\theta}$ and $y = r\sin{\theta}$. By the above equation, we have that $\mathrm{d}x \mathrm{d}y = r \mathrm{d}r \mathrm{d}\theta$. But if we were to compute the differentials of $x$ and $y$ and multiply them together, expanding the product would not give us $r \mathrm{d}r \mathrm{d}\theta$. It would give us a bunch of ugly stuff, and I'm not even sure this ""stuff"" is meaningful. If the differentials were truly being multiplied by one other, then after expanding their product (which I am not going to do here), the result would be $r \mathrm{d}r \mathrm{d}\theta$. But this is not the case. So in the end, neither the viewpoint of differentials as ""infinitesimals"" multiplied to the integrand, nor the viewpoint of differentials as linear changes makes sense to me. If differentials were infinitesimals multiplied to an integrand, then why does expanding the product $\mathrm{d} x(r, \theta) \times \mathrm{d}y(r, \theta)$ not yield $r \mathrm{d}r \mathrm{d}\theta$? If differentials were finite, linear changes, why can we just magically ""slap on"" integrals on both sides of the equation $\mathrm{d}y = f'(x) \mathrm{d}x$? And probably most importantly, are differentials just closing parantheses, or are they actually multiplied by the integrand? If we consider them as part of an infinitesimal product, then this makes appending integrals to both sides justified. But if they are just ""closing parantheses"", then why is appending integrals to both sides of an equation justified? A finite quantity ($\mathrm{d}x$) cannot magically ""transform"" into a piece of notation by simply writing an integral symbol on both sides of the equation. I am very confused about differentials, and I would appreciate if someone could clarify exacty why multiplying them doesn't work in the intuitive way described above, and why we are allowed to just append integrals to both sides of an equation.",,"['calculus', 'ordinary-differential-equations', 'multivariable-calculus']"
24,"Integral formula for $\int_{0}^{\infty}e^{-3\pi x^{2}}((\sinh \pi x)/(\sinh 3\pi x))\,dx$ by Ramanujan",Integral formula for  by Ramanujan,"\int_{0}^{\infty}e^{-3\pi x^{2}}((\sinh \pi x)/(\sinh 3\pi x))\,dx","Towards the end of G. N. Watson's (one of the joint authors of famous book ""A Course of Modern Analysis"") paper ""The Final Problem: An Account of the Mock Theta Functions"" the following formula of Ramanujan is mentioned: $$\int_{0}^{\infty}e^{-3\pi x^{2}}\frac{\sinh \pi x}{\sinh 3\pi x}\,dx = \frac{1}{e^{2\pi/3}\sqrt{3}}\sum_{n = 0}^{\infty}\frac{e^{-2n(n + 1)\pi}}{(1 + e^{-\pi})^{2}(1 + e^{-3\pi})^{2}\dots(1 + e^{-(2n + 1)\pi})^{2}}\tag{1}$$ where the term corresponding to $n = 0$ in the sum on the right is $1$. Is there way to establish this exotic integral formula? Or a reference to any existing proof of $(1)$ would be of great help.","Towards the end of G. N. Watson's (one of the joint authors of famous book ""A Course of Modern Analysis"") paper ""The Final Problem: An Account of the Mock Theta Functions"" the following formula of Ramanujan is mentioned: $$\int_{0}^{\infty}e^{-3\pi x^{2}}\frac{\sinh \pi x}{\sinh 3\pi x}\,dx = \frac{1}{e^{2\pi/3}\sqrt{3}}\sum_{n = 0}^{\infty}\frac{e^{-2n(n + 1)\pi}}{(1 + e^{-\pi})^{2}(1 + e^{-3\pi})^{2}\dots(1 + e^{-(2n + 1)\pi})^{2}}\tag{1}$$ where the term corresponding to $n = 0$ in the sum on the right is $1$. Is there way to establish this exotic integral formula? Or a reference to any existing proof of $(1)$ would be of great help.",,"['calculus', 'integration', 'definite-integrals']"
25,Evaluating the double limit $\lim_{m \to \infty} \lim_{n \to \infty} \cos^{2m}(n! \pi x)$,Evaluating the double limit,\lim_{m \to \infty} \lim_{n \to \infty} \cos^{2m}(n! \pi x),I have to find out the following limit $$\lim_{m\to\infty}\lim_{n\to\infty}[\cos(n!πx)^{2m}]$$ for $x$ rational and irrational. for $x$ rational $x$ can be written as $\frac{p}{q}$ and as $n!$ will have $q$ as its factor the limit should be equal to 1. the second part of irrational is giving me problems. I first thought that limit should be zero as absolute value of cosine term is less than 1 and power it to infinity you should get $0$. But then I realised that it was wrong. I brought the limit down to this form. $$e^{-\sin^2(n!πx)m}$$ after this I find the question quite ambiguous as they have just said $x$ is irrational. If I take $x$ as $\frac{1}{n!π\sqrt{m}}$ I get the limit as $\frac{1}{e}$ but if I take  $x$ as $\frac{2}{n!π\sqrt{m}}$ I get the limit as $\frac{1}{e^4}$. please help me and tell me where have I gone wrong?,I have to find out the following limit $$\lim_{m\to\infty}\lim_{n\to\infty}[\cos(n!πx)^{2m}]$$ for $x$ rational and irrational. for $x$ rational $x$ can be written as $\frac{p}{q}$ and as $n!$ will have $q$ as its factor the limit should be equal to 1. the second part of irrational is giving me problems. I first thought that limit should be zero as absolute value of cosine term is less than 1 and power it to infinity you should get $0$. But then I realised that it was wrong. I brought the limit down to this form. $$e^{-\sin^2(n!πx)m}$$ after this I find the question quite ambiguous as they have just said $x$ is irrational. If I take $x$ as $\frac{1}{n!π\sqrt{m}}$ I get the limit as $\frac{1}{e}$ but if I take  $x$ as $\frac{2}{n!π\sqrt{m}}$ I get the limit as $\frac{1}{e^4}$. please help me and tell me where have I gone wrong?,,"['calculus', 'limits']"
26,"Evaluate $\int\limits_0^1\frac{(1-x)e^x}{x+e^x}\,dx$",Evaluate,"\int\limits_0^1\frac{(1-x)e^x}{x+e^x}\,dx","I`m trying to evaluate this integral $$\int\limits_0^1\frac{(1-x)e^x}{x+e^x}\,dx.$$ Would you please give me any idea?","I`m trying to evaluate this integral $$\int\limits_0^1\frac{(1-x)e^x}{x+e^x}\,dx.$$ Would you please give me any idea?",,"['calculus', 'integration']"
27,"Evaluate or simplify $\int\frac{1}{\ln x}\,dx$",Evaluate or simplify,"\int\frac{1}{\ln x}\,dx","I did a bit of work on this, but I'm not so sure about the parts towards the end. Starting with$$\int\frac{1}{\ln x}\,dx$$$$u=\ln x,1=\frac{dx}{du}\frac{1}{x},dx=x\,du,dx=e^{\ln x}du,dx=e^u\,du$$$$\int\frac{e^u}{u}\,du=\int\frac{1}{u}e^u\,du=\int\frac1u\sum_{n=1}^\infty\frac{u^n}{n!}\,du=\int\sum_{n=1}^\infty\frac{u^{n-1}}{n!}\,du$$$$\sum_{n=1}^\infty\frac{u^n}{n\cdot n!}=\sum_{n=1}^\infty\frac{\ln(x)^n}{n\cdot n!}$$which WolframAlpha tells me converges to $-\ln\left(-\ln x\right)-\Gamma\left(0,-\ln x\right)-\gamma$. I'm not sure what happened in this last step.","I did a bit of work on this, but I'm not so sure about the parts towards the end. Starting with$$\int\frac{1}{\ln x}\,dx$$$$u=\ln x,1=\frac{dx}{du}\frac{1}{x},dx=x\,du,dx=e^{\ln x}du,dx=e^u\,du$$$$\int\frac{e^u}{u}\,du=\int\frac{1}{u}e^u\,du=\int\frac1u\sum_{n=1}^\infty\frac{u^n}{n!}\,du=\int\sum_{n=1}^\infty\frac{u^{n-1}}{n!}\,du$$$$\sum_{n=1}^\infty\frac{u^n}{n\cdot n!}=\sum_{n=1}^\infty\frac{\ln(x)^n}{n\cdot n!}$$which WolframAlpha tells me converges to $-\ln\left(-\ln x\right)-\Gamma\left(0,-\ln x\right)-\gamma$. I'm not sure what happened in this last step.",,"['calculus', 'sequences-and-series', 'integration', 'special-functions']"
28,Integral In Ramanujan's Letter To G.H. Hardy,Integral In Ramanujan's Letter To G.H. Hardy,,"In Ramanujan's first letter to G.H. Hardy he defines a function $\phi(n)$ as such $$ \phi(n) = \int_{0}^{\infty} \frac{\cos n x}{e^{2 \pi \sqrt{x}}-1} d x $$ And then he gives a functional equation $$ \int_{0}^{\infty} \frac{\sin n x}{e^{2 \pi \sqrt{x}}-1} d x=\phi(n)-\frac{1}{2 n}+\phi\left(\frac{\pi^{2}}{n}\right) \sqrt{\frac{2 \pi^{3}}{n^{3}}}$$ How does one prove this functional equation? I am relatively unfamiliar with the methods one would use to solve this, and therefore do not have a proper attempt to share in this question. Thank you","In Ramanujan's first letter to G.H. Hardy he defines a function as such And then he gives a functional equation How does one prove this functional equation? I am relatively unfamiliar with the methods one would use to solve this, and therefore do not have a proper attempt to share in this question. Thank you","\phi(n) 
\phi(n) = \int_{0}^{\infty} \frac{\cos n x}{e^{2 \pi \sqrt{x}}-1} d x
 
\int_{0}^{\infty} \frac{\sin n x}{e^{2 \pi \sqrt{x}}-1} d x=\phi(n)-\frac{1}{2 n}+\phi\left(\frac{\pi^{2}}{n}\right) \sqrt{\frac{2 \pi^{3}}{n^{3}}}","['calculus', 'integration']"
29,Bear of an integral,Bear of an integral,,"I have a pretty ferocious integral to solve, and would be over the moon if I were able to get some sort of analytic expression / insight for it. $$ I = \int_{r}^{\infty} r_0^{-5/2} W_{-i\alpha'/2, \nu}\left(\frac{-ir_0^2\omega'}{L}\right) W_{-i\alpha/2, \nu}\left(\frac{-ir_0^2\omega}{L}\right) (i^\beta J_{\beta}\left(-i\hat{k}r_0\right)) dr_0$$ All I've really done so far is look at the integrand in Mathematica (plotting Abs(integrand)): Where $W$ is the $W$ Whittaker function ( http://mathworld.wolfram.com/WhittakerFunction.html ) and $J$ is the Bessel function of the first kind ( http://mathworld.wolfram.com/BesselFunctionoftheFirstKind.html ) And also expand the integrand for small $r_0$ to gain some insight as to what happens at small $r$ , but this is far too imprecise for the application  (particular solution of a  differential equation using Sturm-Liouville theory). For the application, the best thing I could do is write $I = I_0 + f(r)$ where $I_0$ is some analytically determined constant. r-dependence is the first datum of importance, and then $\hat{k},\omega',\alpha, \beta, \omega, \alpha'$ dependence. Note that these constants should be positive. If it helps, note that $\omega' = \omega + \hat{\omega}$ and $\alpha = k^2L/2\omega, \alpha' = (k+\hat{k})^2 L /(2 \omega')$","I have a pretty ferocious integral to solve, and would be over the moon if I were able to get some sort of analytic expression / insight for it. All I've really done so far is look at the integrand in Mathematica (plotting Abs(integrand)): Where is the Whittaker function ( http://mathworld.wolfram.com/WhittakerFunction.html ) and is the Bessel function of the first kind ( http://mathworld.wolfram.com/BesselFunctionoftheFirstKind.html ) And also expand the integrand for small to gain some insight as to what happens at small , but this is far too imprecise for the application  (particular solution of a  differential equation using Sturm-Liouville theory). For the application, the best thing I could do is write where is some analytically determined constant. r-dependence is the first datum of importance, and then dependence. Note that these constants should be positive. If it helps, note that and"," I = \int_{r}^{\infty} r_0^{-5/2} W_{-i\alpha'/2, \nu}\left(\frac{-ir_0^2\omega'}{L}\right) W_{-i\alpha/2, \nu}\left(\frac{-ir_0^2\omega}{L}\right) (i^\beta J_{\beta}\left(-i\hat{k}r_0\right)) dr_0 W W J r_0 r I = I_0 + f(r) I_0 \hat{k},\omega',\alpha, \beta, \omega, \alpha' \omega' = \omega + \hat{\omega} \alpha = k^2L/2\omega, \alpha' = (k+\hat{k})^2 L /(2 \omega')","['calculus', 'asymptotics', 'special-functions']"
30,Convergence of tetration sequence.,Convergence of tetration sequence.,,This question arose from here . I am interested to find a nice proof about the convergence of $${^n}a=\underbrace{a^{a^{\ .^{\ .^{\ .^a}}}}}_{n\ \text{times}}.$$ I find with google a necessary and sufficient condition to have the convergence is $\frac{1}{e^e} \leq a \leq e^{1/e}$ but the part for $a\le1$ need some ugly work. Does anyone have an elegant/slick proof ?,This question arose from here . I am interested to find a nice proof about the convergence of $${^n}a=\underbrace{a^{a^{\ .^{\ .^{\ .^a}}}}}_{n\ \text{times}}.$$ I find with google a necessary and sufficient condition to have the convergence is $\frac{1}{e^e} \leq a \leq e^{1/e}$ but the part for $a\le1$ need some ugly work. Does anyone have an elegant/slick proof ?,,"['calculus', 'sequences-and-series', 'convergence-divergence']"
31,"If $(f ∘ f)$ is differentiable, is $f$ also differentiable?","If  is differentiable, is  also differentiable?",(f ∘ f) f,"Question: If $(f \circ f)$ is differentiable on $\mathbb R$, then $f$ is differentiable on $\mathbb R$. Is this statement true or false and why? I have had a look at this question and really can't get my head around it. I have thought that it is False, because if we let $f(x) = 2$, $(f\circ f)$ can't be defined as $(f(f(2))$ doesn't exist.  So the statement would be false as we can't define $(f\circ f)$ so it can't be differentiable on $\mathbb R$. Is this way of looking at it right or not?","Question: If $(f \circ f)$ is differentiable on $\mathbb R$, then $f$ is differentiable on $\mathbb R$. Is this statement true or false and why? I have had a look at this question and really can't get my head around it. I have thought that it is False, because if we let $f(x) = 2$, $(f\circ f)$ can't be defined as $(f(f(2))$ doesn't exist.  So the statement would be false as we can't define $(f\circ f)$ so it can't be differentiable on $\mathbb R$. Is this way of looking at it right or not?",,"['calculus', 'functions', 'derivatives', 'function-and-relation-composition']"
32,Which one is the variable? (Derivatives),Which one is the variable? (Derivatives),,"I'm very confuzzled as to where the variable is here. I don't know where to differentiate. Here's the question, differentiate: $$y = \frac{\sin(\theta)}{2} + \frac{c}{\theta}$$ Do I solve for $f(c)$ or $f(\theta)$? I tried solving it for $f(c)$ treating theta as a constant, but I'm unsure if that's correct.","I'm very confuzzled as to where the variable is here. I don't know where to differentiate. Here's the question, differentiate: $$y = \frac{\sin(\theta)}{2} + \frac{c}{\theta}$$ Do I solve for $f(c)$ or $f(\theta)$? I tried solving it for $f(c)$ treating theta as a constant, but I'm unsure if that's correct.",,"['calculus', 'derivatives']"
33,How to prove that $\lim\limits_{x\to0}\frac{\tan x}x=1$?,How to prove that ?,\lim\limits_{x\to0}\frac{\tan x}x=1,How to prove that  $$\lim\limits_{x\to0}\frac{\tan x}x=1?$$ I'm looking for a method besides L'Hospital's rule.,How to prove that  $$\lim\limits_{x\to0}\frac{\tan x}x=1?$$ I'm looking for a method besides L'Hospital's rule.,,"['calculus', 'limits', 'trigonometry', 'derivatives', 'alternative-proof']"
34,"Find the sum of an alternating, non-geometric series","Find the sum of an alternating, non-geometric series",,"Looking to the following series: $$\sum_{n=1}^\infty \frac{(-1)^n(4n)}{4n^2-1}$$ It converges according to Leibniz criteria. However it does not seem to be a telescopic series (if you take partial fractions, you end up with two positive terms), neither a geometric one, so I can not figure out a way to find its sum. Maybe I am missing something here. Thanks for your time and I appreciate any help.","Looking to the following series: $$\sum_{n=1}^\infty \frac{(-1)^n(4n)}{4n^2-1}$$ It converges according to Leibniz criteria. However it does not seem to be a telescopic series (if you take partial fractions, you end up with two positive terms), neither a geometric one, so I can not figure out a way to find its sum. Maybe I am missing something here. Thanks for your time and I appreciate any help.",,"['calculus', 'sequences-and-series']"
35,How to compute the  formula $\sum  \limits_{r=1}^d r \cdot 2^r$?,How to compute the  formula ?,\sum  \limits_{r=1}^d r \cdot 2^r,"Given $$1\cdot 2^1 + 2\cdot 2^2 + 3\cdot 2^3 + 4\cdot 2^4 + \cdots + d \cdot 2^d = \sum_{r=1}^d r \cdot 2^r,$$ how can we infer to the following solution? $$2 (d-1) \cdot 2^d + 2. $$ Thank you","Given $$1\cdot 2^1 + 2\cdot 2^2 + 3\cdot 2^3 + 4\cdot 2^4 + \cdots + d \cdot 2^d = \sum_{r=1}^d r \cdot 2^r,$$ how can we infer to the following solution? $$2 (d-1) \cdot 2^d + 2. $$ Thank you",,"['calculus', 'sequences-and-series', 'discrete-mathematics', 'summation']"
36,How do I evaluate $\int \frac{\mathrm{d}x}{e^x + 1} $?,How do I evaluate ?,\int \frac{\mathrm{d}x}{e^x + 1} ,How do I solve evaluate $$\int \frac{\mathrm{d}x}{e^x + 1}\ ?$$ I know that I have to use $u$ substitution but I can't seem to find something to substitute with.,How do I solve evaluate $$\int \frac{\mathrm{d}x}{e^x + 1}\ ?$$ I know that I have to use $u$ substitution but I can't seem to find something to substitute with.,,"['calculus', 'integration', 'indefinite-integrals']"
37,"How do you construct a function that is continuous over $(0,1)$ whose image is the entire real line?",How do you construct a function that is continuous over  whose image is the entire real line?,"(0,1)","How do you construct a continuous function over the interval $(0,1)$ whose image is the entire real line? When I first saw this problem, I thought $\frac{1}{x(x-1)}$ might work since it is continuous on $(0,1)$, but when I graphed it, I saw that there is a minimum at $(1/2,4)$, so the image is $[4,\infty)$ and not $(-\infty,\infty)$. Apparently, one answer to this question is: $$\frac{2x-1}{x(x-1)}$$ But how is one supposed to arrive at this answer without using a  graphing calculator?","How do you construct a continuous function over the interval $(0,1)$ whose image is the entire real line? When I first saw this problem, I thought $\frac{1}{x(x-1)}$ might work since it is continuous on $(0,1)$, but when I graphed it, I saw that there is a minimum at $(1/2,4)$, so the image is $[4,\infty)$ and not $(-\infty,\infty)$. Apparently, one answer to this question is: $$\frac{2x-1}{x(x-1)}$$ But how is one supposed to arrive at this answer without using a  graphing calculator?",,"['calculus', 'algebra-precalculus']"
38,Is the catenary the trajectory of anything?,Is the catenary the trajectory of anything?,,"Notice that the parabola, defined by certain properties, is also the trajectory of a cannon ball. Does the same sort of thing hold for the catenary? That is, is the catenary, defined by certain properties, also the trajectory of something?","Notice that the parabola, defined by certain properties, is also the trajectory of a cannon ball. Does the same sort of thing hold for the catenary? That is, is the catenary, defined by certain properties, also the trajectory of something?",,[]
39,What is the result of $\lim_{x \rightarrow 0}\left(\frac1x - \frac1{\sin x}\right)$?,What is the result of ?,\lim_{x \rightarrow 0}\left(\frac1x - \frac1{\sin x}\right),Find the limit: $$\lim_{x \rightarrow 0}\left(\frac1x - \frac1{\sin x}\right)$$ I am not able to find it because I don't know how to prove or disprove $0$ is the answer.,Find the limit: $$\lim_{x \rightarrow 0}\left(\frac1x - \frac1{\sin x}\right)$$ I am not able to find it because I don't know how to prove or disprove $0$ is the answer.,,"['calculus', 'limits']"
40,Compute the integral: $\int_{0}^{\frac{\pi}{2}}\ln(\sec(x)+\tan(x))\csc(x)dx$,Compute the integral:,\int_{0}^{\frac{\pi}{2}}\ln(\sec(x)+\tan(x))\csc(x)dx,"This question is originally a simplified version from a qualifying exam problem from Archimedean Integration Bee (Cambridge University). I tried doing angular symmetry but that gives me $$\int_{0}^{\frac{\pi}{2}}\ln(\csc(x)+\cot(x))\sec(x)dx.$$ I thought I could add both integrals and perform reverse product rule, but unfortunately $$\frac{d}{dx}\left [ \ln(\sec(x)+\tan(x))\ln(\csc(x)+\cot(x)) \right ]=\sec(x)\ln(\csc(x)+\cot(x))-\csc(x)\ln(\sec(x)+\tan(x)).$$ According to wolframalpha, the answer is $\frac{\pi^2}{4}$ . This made me think that it uses some sort of Taylor Series somewhere, or a certain identity, but what's the quick solution to this problem?","This question is originally a simplified version from a qualifying exam problem from Archimedean Integration Bee (Cambridge University). I tried doing angular symmetry but that gives me I thought I could add both integrals and perform reverse product rule, but unfortunately According to wolframalpha, the answer is . This made me think that it uses some sort of Taylor Series somewhere, or a certain identity, but what's the quick solution to this problem?",\int_{0}^{\frac{\pi}{2}}\ln(\csc(x)+\cot(x))\sec(x)dx. \frac{d}{dx}\left [ \ln(\sec(x)+\tan(x))\ln(\csc(x)+\cot(x)) \right ]=\sec(x)\ln(\csc(x)+\cot(x))-\csc(x)\ln(\sec(x)+\tan(x)). \frac{\pi^2}{4},"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'trigonometric-integrals']"
41,Why has $\int \sin (\sin x) dx$ not been solved yet?,Why has  not been solved yet?,\int \sin (\sin x) dx,"I have Calculus 2 background, so please try to keep your answers around that level. I inly want a brief explanation. What is it about $\sin (\sin x)$ that makes it difficult to integrate? Also, what makes us think that we express $\int \sin (\sin x) dx$ in terms of already known functions? I imagine if we didn't think we can express it in known functions, then we would've already given it a name and defined it as a special function with its own name.","I have Calculus 2 background, so please try to keep your answers around that level. I inly want a brief explanation. What is it about $\sin (\sin x)$ that makes it difficult to integrate? Also, what makes us think that we express $\int \sin (\sin x) dx$ in terms of already known functions? I imagine if we didn't think we can express it in known functions, then we would've already given it a name and defined it as a special function with its own name.",,"['calculus', 'soft-question', 'special-functions', 'indefinite-integrals']"
42,How to prove absolute summability of sinc function?,How to prove absolute summability of sinc function?,,"We know that $$\int_0^\infty \left(\frac{\sin x}{x}\right)^2 dx=\int_0^\infty \frac{\sin x}{x} \, dx=\frac{\pi}{2}.$$ How do I show that $$\int_0^\infty \left\vert\frac{\sin x}{x} \right\vert \, dx$$ converges?",We know that How do I show that converges?,"\int_0^\infty \left(\frac{\sin x}{x}\right)^2 dx=\int_0^\infty \frac{\sin x}{x} \, dx=\frac{\pi}{2}. \int_0^\infty \left\vert\frac{\sin x}{x} \right\vert \, dx",['calculus']
43,How to solve this series: $\sum_{k=0}^{2n+1} (-1)^kk $,How to solve this series:,\sum_{k=0}^{2n+1} (-1)^kk ,"$$\sum_{k=0}^{2n+1} (-1)^kk $$ The answer given is $-n-1$. I have searched for how to do it, but I have problems simplifying the sum and solving it.  How do you go about solving this?","$$\sum_{k=0}^{2n+1} (-1)^kk $$ The answer given is $-n-1$. I have searched for how to do it, but I have problems simplifying the sum and solving it.  How do you go about solving this?",,"['calculus', 'sequences-and-series', 'summation']"
44,Integral of $1/x^2$ without power rule,Integral of  without power rule,1/x^2,"I was wondering if it was possible to evaluate the following integral without using the power rule for negative exponents \begin{equation*}   \int \frac{1}{x^2} \; dx \end{equation*} When using integration by parts, you end up with the same integral in the rhs so it seems out of luck \begin{equation*}   \int \frac{1}{x^2} \; dx = \frac{\ln x}{x} + \int \frac{\ln x}{x^2} \; dx \end{equation*} This question is inspired by this blackpenredpen's video Using integration by parts with $u = \frac{1}{x^2}$ and $v = x$ is NOT accepted. If you write \begin{equation*}   \int \frac{1}{x^2} \; dx = \frac{1}{x} + 2 \int \frac{1}{x^2} \; dx \end{equation*} you are still implicitly using the power rule to compute the derivative of $\frac{1}{x^2}$ so it is not correct per the rules. The same rules apply for $u$ -substitution which implicitly use the power rule. See the following with $u = \frac{1}{x}$ such that \begin{equation*}     \int \frac{1}{\left(\frac{1}{x}\right)^2} \left(\frac{1}{x}\right)' \; dx = \int \frac{1}{u^2} \; du \end{equation*} and here the power rule is also considered used to compute the derivative of $\frac{1}{x}$ although it can be subject to discussion (geometric proof, limit definition of derivative, etc...)","I was wondering if it was possible to evaluate the following integral without using the power rule for negative exponents When using integration by parts, you end up with the same integral in the rhs so it seems out of luck This question is inspired by this blackpenredpen's video Using integration by parts with and is NOT accepted. If you write you are still implicitly using the power rule to compute the derivative of so it is not correct per the rules. The same rules apply for -substitution which implicitly use the power rule. See the following with such that and here the power rule is also considered used to compute the derivative of although it can be subject to discussion (geometric proof, limit definition of derivative, etc...)","\begin{equation*}
  \int \frac{1}{x^2} \; dx
\end{equation*} \begin{equation*}
  \int \frac{1}{x^2} \; dx = \frac{\ln x}{x} + \int \frac{\ln x}{x^2} \; dx
\end{equation*} u = \frac{1}{x^2} v = x \begin{equation*}
  \int \frac{1}{x^2} \; dx = \frac{1}{x} + 2 \int \frac{1}{x^2} \; dx
\end{equation*} \frac{1}{x^2} u u = \frac{1}{x} \begin{equation*}
    \int \frac{1}{\left(\frac{1}{x}\right)^2} \left(\frac{1}{x}\right)' \; dx = \int \frac{1}{u^2} \; du
\end{equation*} \frac{1}{x}","['calculus', 'integration', 'recreational-mathematics']"
45,Why does the power rule work?,Why does the power rule work?,,"If $$f(x)=x^u$$ then the derivative function will always be $$f'(x)=u*x^{u-1}$$ I've been trying to figure out why that makes sense and I can't quite get there. I know it can be proven with limits, but I'm looking for something more basic, something I can  picture in my head. The derivative should be the slope of the function. If $$f(x)=x^3=x^2*x$$ then the slope should be $x^2$. But it isn't. The power rule says it's $3x^2$. I understand that it has to do with having variables where in a more simple equation there would be a constant. I'm trying to understand how that exactly translates into the power rule.","If $$f(x)=x^u$$ then the derivative function will always be $$f'(x)=u*x^{u-1}$$ I've been trying to figure out why that makes sense and I can't quite get there. I know it can be proven with limits, but I'm looking for something more basic, something I can  picture in my head. The derivative should be the slope of the function. If $$f(x)=x^3=x^2*x$$ then the slope should be $x^2$. But it isn't. The power rule says it's $3x^2$. I understand that it has to do with having variables where in a more simple equation there would be a constant. I'm trying to understand how that exactly translates into the power rule.",,"['calculus', 'derivatives', 'intuition', 'exponentiation']"
46,Calculate $\sum_{n=2}^{\infty}\left (n^2 \ln (1-\frac{1}{n^2})+1\right)$,Calculate,\sum_{n=2}^{\infty}\left (n^2 \ln (1-\frac{1}{n^2})+1\right),"I am interested in evaluating $$\sum_{n=2}^{\infty}\left (n^2 \ln\left(1-\frac{1}{n^2}\right)+1\right)$$ I am given the solution for the question is $\,\ln (\pi)-\frac{3}{2}\,.$ $$\sum_{n=2}^{\infty}\left(n^2\ln\left(\!1\!-\!\frac{1}{n^2}\!\right)+1\right)=4\ln\left(\!\frac{3}{4}\!\right)+1+9\ln\left(\!\frac{8}{9}\!\right)+1+\ldots$$ Any tricks to solve it?",I am interested in evaluating I am given the solution for the question is Any tricks to solve it?,"\sum_{n=2}^{\infty}\left (n^2 \ln\left(1-\frac{1}{n^2}\right)+1\right) \,\ln (\pi)-\frac{3}{2}\,. \sum_{n=2}^{\infty}\left(n^2\ln\left(\!1\!-\!\frac{1}{n^2}\!\right)+1\right)=4\ln\left(\!\frac{3}{4}\!\right)+1+9\ln\left(\!\frac{8}{9}\!\right)+1+\ldots","['calculus', 'sequences-and-series']"
47,Alternative way to solve a limit problem,Alternative way to solve a limit problem,,"$$ \lim _{n \rightarrow \infty} \frac{1}{1+n^{2}}+\frac{2}{2+n^{2}}+\cdots+\frac{n}{n+n^{2}} $$ I want to find the limit of this infinite series which I found in a book. The answer is $1/2$ . The solution to this limit was given by Sandwich/Squeeze Theorem, which was basically that the above function lies between: $$ \frac{1}{n+n^{2}}+\frac{2}{n+n^{2}}+\frac{3}{n+n^{2}}+\cdots+\frac{n}{n+n^{2}} $$ And, $$ \frac{1}{1+n^{2}}+\frac{2}{1+n^{2}}+\cdots+\frac{n}{1+n^{2}} $$ series and the limit of both of these series tend to $1/2$ as $n \to \infty$ . I fully understood the solution, but I find that this isn't something that naturally/intuitively comes to your mind. I mean we need to find two different series by trial and error, both of which need to converge to a single number. Is there any different solution to this limit problem, like dividing by powers of n, or maybe telescoping sums?","I want to find the limit of this infinite series which I found in a book. The answer is . The solution to this limit was given by Sandwich/Squeeze Theorem, which was basically that the above function lies between: And, series and the limit of both of these series tend to as . I fully understood the solution, but I find that this isn't something that naturally/intuitively comes to your mind. I mean we need to find two different series by trial and error, both of which need to converge to a single number. Is there any different solution to this limit problem, like dividing by powers of n, or maybe telescoping sums?","
\lim _{n \rightarrow \infty} \frac{1}{1+n^{2}}+\frac{2}{2+n^{2}}+\cdots+\frac{n}{n+n^{2}}
 1/2 
\frac{1}{n+n^{2}}+\frac{2}{n+n^{2}}+\frac{3}{n+n^{2}}+\cdots+\frac{n}{n+n^{2}}
 
\frac{1}{1+n^{2}}+\frac{2}{1+n^{2}}+\cdots+\frac{n}{1+n^{2}}
 1/2 n \to \infty","['calculus', 'sequences-and-series', 'limits', 'telescopic-series']"
48,Proof of this integration shortcut: $\int_a^b \frac{dx}{\sqrt{(x-a)(b-x)}}=\pi$,Proof of this integration shortcut:,\int_a^b \frac{dx}{\sqrt{(x-a)(b-x)}}=\pi,"I came across this as one of the shortcuts in my textbook without any proof. When  $b\gt a$, $$\int\limits_a^b \dfrac{dx}{\sqrt{(x-a)(b-x)}}=\pi$$ My attempt : I notice that the the denominator is $0$ at both the bounds. I thought of substituting $x=a+(b-a)t$ so that the integral becomes $$\int\limits_0^1 \dfrac{dt}{\sqrt{t(1-t)}}$$ This doesn't look simple, but I'm wondering if the answer can be seen using symmetry/geometry ?","I came across this as one of the shortcuts in my textbook without any proof. When  $b\gt a$, $$\int\limits_a^b \dfrac{dx}{\sqrt{(x-a)(b-x)}}=\pi$$ My attempt : I notice that the the denominator is $0$ at both the bounds. I thought of substituting $x=a+(b-a)t$ so that the integral becomes $$\int\limits_0^1 \dfrac{dt}{\sqrt{t(1-t)}}$$ This doesn't look simple, but I'm wondering if the answer can be seen using symmetry/geometry ?",,"['calculus', 'integration', 'definite-integrals']"
49,Evaluating $\lim\limits_{x\to \infty}\sqrt[6]{x^{6}+x^{5}}-\sqrt[6]{x^{6}-x^{5}}$,Evaluating,\lim\limits_{x\to \infty}\sqrt[6]{x^{6}+x^{5}}-\sqrt[6]{x^{6}-x^{5}},"How would you evaluate the following limit:   $$\lim_{x\to \infty}\sqrt[6]{x^{6}+x^{5}}-\sqrt[6]{x^{6}-x^{5}}$$ I tried to use this formula: $a^{3}-b^{3}=(a-b)(a^{2}+ab+b^{2})$,  It didn't work. Any hints?","How would you evaluate the following limit:   $$\lim_{x\to \infty}\sqrt[6]{x^{6}+x^{5}}-\sqrt[6]{x^{6}-x^{5}}$$ I tried to use this formula: $a^{3}-b^{3}=(a-b)(a^{2}+ab+b^{2})$,  It didn't work. Any hints?",,['calculus']
50,Calculus: Why do we ignore dx? [duplicate],Calculus: Why do we ignore dx? [duplicate],,"This question already has answers here : Why is $d(x^2)= 2xdx$? (5 answers) Closed 3 years ago . I'm new to calculus and I find it really confusing why we just ignore the dx at the end. For example, when working on derivation of $x^2$ , at the last step, we're left with $f'(x)= 2x + dx$ But I've heard people in videos say: ""Since $dx$ is super super super small, we can safely ignore it. But just ignoring it bugs me. If we choose to ignore it, should it not actually look like this: $f'(x) \approx 2x $ Thanks for your time. Cheers :)","This question already has answers here : Why is $d(x^2)= 2xdx$? (5 answers) Closed 3 years ago . I'm new to calculus and I find it really confusing why we just ignore the dx at the end. For example, when working on derivation of , at the last step, we're left with But I've heard people in videos say: ""Since is super super super small, we can safely ignore it. But just ignoring it bugs me. If we choose to ignore it, should it not actually look like this: Thanks for your time. Cheers :)",x^2 f'(x)= 2x + dx dx f'(x) \approx 2x ,"['calculus', 'limits', 'derivatives']"
51,Can distance between two closed sets be zero? [duplicate],Can distance between two closed sets be zero? [duplicate],,"This question already has answers here : Find two closed subsets or real numbers such that $d(A,B)=0$ but $A\cap B=\varnothing$ (4 answers) Closed 6 years ago . Is given metric space $(M, d)$. Let $A\cap B = \emptyset; \,\,\text{dist}(A,B):=\inf\{d(x,y):x\in A, y\in B\}$. $A, B$ are both closed sets. Is it possible that $\text{dist}(A,B)=0$? The first thought comes into mind is that obviously $\text{dist}(A,B)>0$, but possibly there are some tricky $d$ and $A, B$ so that it's untrue. Thanks in advance!","This question already has answers here : Find two closed subsets or real numbers such that $d(A,B)=0$ but $A\cap B=\varnothing$ (4 answers) Closed 6 years ago . Is given metric space $(M, d)$. Let $A\cap B = \emptyset; \,\,\text{dist}(A,B):=\inf\{d(x,y):x\in A, y\in B\}$. $A, B$ are both closed sets. Is it possible that $\text{dist}(A,B)=0$? The first thought comes into mind is that obviously $\text{dist}(A,B)>0$, but possibly there are some tricky $d$ and $A, B$ so that it's untrue. Thanks in advance!",,['calculus']
52,"Find two positive real numbers, whose difference is 100 and whose product is a minimum","Find two positive real numbers, whose difference is 100 and whose product is a minimum",,"First off, this is a single-variable calculus optimization problem. At first glance, the problem seemed extremely trivial, however the solution to it seems to be deceptively tricky (at least to me at this moment in time). Problem: Find two positive numbers whose difference is $100$ and whose product is a minimum My Attempted Solution : Let's assume, $a, b \in \mathbb{R^+}$, $b < a$ First we set up an equation for the difference of $a, b$, I've used absolute values to restrict $a,b$ to values $\geq 0$ $$|a| - |b| = 100$$ $$\implies |a| = 100 + |b|$$ Next we set up an equation for the product of $a, b$ $$(|a|)(|b|) = b^2 +  100|b| \ \ \ \ $$ Defining a function $f$, to minimize to product of $a , b$ : $$f(b) = b^2 + 100|b|$$ $$\implies      f'(b) = \begin{cases} 2b +100, \ \ \ \text{if} \ \ b \geq 0 \ \ \ \ (1)\\ 2b - 100, \ \ \ \text{if} \ \ b < 0 \  \ \ \ (2)\\ \end{cases}  $$ Solving for $f'(b) =0$, with case $(1)$, yields $b = -50$, an immediate contradiction. Solving for $f'(b) =0$, with case $(2)$, gives $b=50$, $a=150$. Although that is a valid solution ( EDIT: As correctly pointed out in an answer below, this is also a contradiction ), they are not the minimum values. The correct values, just thinking about it should be, $a = 100$, $b = 0$. However, trying to minimize it, using the equations I set up, don't yield the correct solution. Why is that so? . I don't seem to have made any mistakes as far as I can tell","First off, this is a single-variable calculus optimization problem. At first glance, the problem seemed extremely trivial, however the solution to it seems to be deceptively tricky (at least to me at this moment in time). Problem: Find two positive numbers whose difference is $100$ and whose product is a minimum My Attempted Solution : Let's assume, $a, b \in \mathbb{R^+}$, $b < a$ First we set up an equation for the difference of $a, b$, I've used absolute values to restrict $a,b$ to values $\geq 0$ $$|a| - |b| = 100$$ $$\implies |a| = 100 + |b|$$ Next we set up an equation for the product of $a, b$ $$(|a|)(|b|) = b^2 +  100|b| \ \ \ \ $$ Defining a function $f$, to minimize to product of $a , b$ : $$f(b) = b^2 + 100|b|$$ $$\implies      f'(b) = \begin{cases} 2b +100, \ \ \ \text{if} \ \ b \geq 0 \ \ \ \ (1)\\ 2b - 100, \ \ \ \text{if} \ \ b < 0 \  \ \ \ (2)\\ \end{cases}  $$ Solving for $f'(b) =0$, with case $(1)$, yields $b = -50$, an immediate contradiction. Solving for $f'(b) =0$, with case $(2)$, gives $b=50$, $a=150$. Although that is a valid solution ( EDIT: As correctly pointed out in an answer below, this is also a contradiction ), they are not the minimum values. The correct values, just thinking about it should be, $a = 100$, $b = 0$. However, trying to minimize it, using the equations I set up, don't yield the correct solution. Why is that so? . I don't seem to have made any mistakes as far as I can tell",,"['calculus', 'optimization']"
53,What is the use of Calculus?,What is the use of Calculus?,,"I know this may seem like a really broad question , but I will narrow it down . I really want to know the purpose of some of the things my teacher is emphasizing in my calc class. For example why it so important to know: \begin{align} \frac{d}{dx}\sin\left(x\right)&=\cos\left(x\right),\\ \frac{d}{dx}\left(\sec\left(x\right)\right)&=\sec\left(x\right)\tan\left(x\right), \text{ or }\\ \lim _{x\to 0}\left(\frac{\sin\left(x\right)}{x}\right)&=1? \end{align} I am looking for a real world benefit or application to knowing these things. Yes, its cool to be able to prove things like $\lim\limits _{x\to -\infty \:}\left(\sqrt{4\cdot \:x^2-5\cdot \:x}+2\cdot \:x\right) = \frac{5}{4}$ , but how does all these toplics like: End Behavior , Limits , difference quotients , derivatives come into play in real world applications So, far we learned the difference quotient to find the average rate of change. We learned the end behavior, so we can learn what occurs if a parameter approaches infinity. We learned limits so we can work around computing values at points where the function is not defined. Ex: Dividing by 0. Now we are learning derivatives which is the limit of a difference quotient as $h\to 0$ . But we haven't had any questions yet, that this is used in a practical problem. The questions we are asked in class are purely proofs and computations. Ex: Find $\frac{d}{dx}\left(\frac{d}{dx}\left(\frac{1}{\sqrt{2\pi \:}}e^{-\frac{x^2}{2}}\right)\right)$ Ex: $$ f(x) = \left\{         \begin{array}{ll}             4x^2+1 & \quad x > 2 \\             17 & \quad x = 2 \\             16x-15 & \quad x < 2         \end{array}     \right. $$ I asked my teacher this question and he mentioned the purpose of calculus is to find the global and local extrema , finding roots ,calculating instantaneous rates of change , but didn't really go into to many real world applications. So far my Calc class has been prove blablabla because you have the math skills to do so. In classes like algebra 2 we didn't just learn algebra, but we learned many real world practical applications for it. My proffessor mentioned Calculus is used a lot in the real world to find area under curves and rates of change . Can you give me some examples on real world applications where I would need to find the area under the curve? Or find the instantaneous rate of change?","I know this may seem like a really broad question , but I will narrow it down . I really want to know the purpose of some of the things my teacher is emphasizing in my calc class. For example why it so important to know: I am looking for a real world benefit or application to knowing these things. Yes, its cool to be able to prove things like , but how does all these toplics like: End Behavior , Limits , difference quotients , derivatives come into play in real world applications So, far we learned the difference quotient to find the average rate of change. We learned the end behavior, so we can learn what occurs if a parameter approaches infinity. We learned limits so we can work around computing values at points where the function is not defined. Ex: Dividing by 0. Now we are learning derivatives which is the limit of a difference quotient as . But we haven't had any questions yet, that this is used in a practical problem. The questions we are asked in class are purely proofs and computations. Ex: Find Ex: I asked my teacher this question and he mentioned the purpose of calculus is to find the global and local extrema , finding roots ,calculating instantaneous rates of change , but didn't really go into to many real world applications. So far my Calc class has been prove blablabla because you have the math skills to do so. In classes like algebra 2 we didn't just learn algebra, but we learned many real world practical applications for it. My proffessor mentioned Calculus is used a lot in the real world to find area under curves and rates of change . Can you give me some examples on real world applications where I would need to find the area under the curve? Or find the instantaneous rate of change?","\begin{align}
\frac{d}{dx}\sin\left(x\right)&=\cos\left(x\right),\\
\frac{d}{dx}\left(\sec\left(x\right)\right)&=\sec\left(x\right)\tan\left(x\right), \text{ or }\\
\lim _{x\to 0}\left(\frac{\sin\left(x\right)}{x}\right)&=1?
\end{align} \lim\limits _{x\to -\infty \:}\left(\sqrt{4\cdot \:x^2-5\cdot \:x}+2\cdot \:x\right) = \frac{5}{4} h\to 0 \frac{d}{dx}\left(\frac{d}{dx}\left(\frac{1}{\sqrt{2\pi \:}}e^{-\frac{x^2}{2}}\right)\right) 
f(x) = \left\{
        \begin{array}{ll}
            4x^2+1 & \quad x > 2 \\
            17 & \quad x = 2 \\
            16x-15 & \quad x < 2
        \end{array}
    \right.
","['calculus', 'limits', 'derivatives', 'soft-question', 'applications']"
54,How can a function have an antiderivative that can't be written?,How can a function have an antiderivative that can't be written?,,"If a function's integral can't be written, then how can we find exact values for it over areas? Can we only ever estimate it? Why can't we make new functions to define these strange unwritable anti-derivatives?","If a function's integral can't be written, then how can we find exact values for it over areas? Can we only ever estimate it? Why can't we make new functions to define these strange unwritable anti-derivatives?",,"['calculus', 'integration', 'indefinite-integrals']"
55,How to solve an exponential equation with two different bases: $3^x - 2^x = 5$,How to solve an exponential equation with two different bases:,3^x - 2^x = 5,Can anyone tell me how to solve this equation   $$3^x - 2^x = 5$$   other than graphically? I'm stunned. I don't know what to do in the first step.,Can anyone tell me how to solve this equation   $$3^x - 2^x = 5$$   other than graphically? I'm stunned. I don't know what to do in the first step.,,"['calculus', 'roots']"
56,How can I prove $\int_{0}^{1} \frac {x-1}{\log(x) (1+x^3)}dx=\frac {\log3}{2}$,How can I prove,\int_{0}^{1} \frac {x-1}{\log(x) (1+x^3)}dx=\frac {\log3}{2},"Question:- Prove that $$\int_0^1 \frac {x-1}{\log(x) (1+x^3)} \, dx = \frac {\log(3)}{2}$$ I saw this problem as an comment on a youtube video few hours ago but I don't know how to prove this one as integration by parts doesn't works here. Also I wasn't able to figure out any proper subsitution that would simplify the integral. Can someone suggests me some hints?",Question:- Prove that I saw this problem as an comment on a youtube video few hours ago but I don't know how to prove this one as integration by parts doesn't works here. Also I wasn't able to figure out any proper subsitution that would simplify the integral. Can someone suggests me some hints?,"\int_0^1 \frac {x-1}{\log(x) (1+x^3)} \, dx = \frac {\log(3)}{2}","['calculus', 'integration', 'definite-integrals']"
57,Calculate $\int_{0}^{1}\frac{\arctan(x)}{x\sqrt{1-x^2}}dx$,Calculate,\int_{0}^{1}\frac{\arctan(x)}{x\sqrt{1-x^2}}dx,"I am preparing for a calculus exam and I was asked to calculate $$\int_{0}^{1}\frac{\arctan(x)}{x\sqrt{1-x^2}}dx$$ Using the hint that $$\frac{\arctan(x)}{x}=\int_{0}^{1}\frac{dy}{1+x^2y^2}$$ I ran into some trouble and would appreciate help. What I did: I used the hint, $$\int_{0}^{1}\frac{\arctan(x)}{x\sqrt{1-x^2}}dx=\int_{0}^{1}\int_{0}^{1}\frac{1}{(1+x^2y^2)\sqrt{1-x^2}}dydx$$ Since $x,y$ move between $0,1$ I thought maybe it is best to used the transform $x=r\cos\theta$ , $y=r\sin\theta$. $r \in [0,1]$, $\theta \in [0, \frac{\pi}{2}]$ But I didn't get anything meaningful, I didn't end up an something that is easy / possible to integrate. And I honestly can't think of a way to integrate this as it is.","I am preparing for a calculus exam and I was asked to calculate $$\int_{0}^{1}\frac{\arctan(x)}{x\sqrt{1-x^2}}dx$$ Using the hint that $$\frac{\arctan(x)}{x}=\int_{0}^{1}\frac{dy}{1+x^2y^2}$$ I ran into some trouble and would appreciate help. What I did: I used the hint, $$\int_{0}^{1}\frac{\arctan(x)}{x\sqrt{1-x^2}}dx=\int_{0}^{1}\int_{0}^{1}\frac{1}{(1+x^2y^2)\sqrt{1-x^2}}dydx$$ Since $x,y$ move between $0,1$ I thought maybe it is best to used the transform $x=r\cos\theta$ , $y=r\sin\theta$. $r \in [0,1]$, $\theta \in [0, \frac{\pi}{2}]$ But I didn't get anything meaningful, I didn't end up an something that is easy / possible to integrate. And I honestly can't think of a way to integrate this as it is.",,"['calculus', 'integration', 'multivariable-calculus']"
58,"Prove that $E(X) = \int_{0}^{\infty} P(X>x)\,dx = \int_{0}^{\infty} (1-F_X(x))\,dx$.",Prove that .,"E(X) = \int_{0}^{\infty} P(X>x)\,dx = \int_{0}^{\infty} (1-F_X(x))\,dx","Let $X$ be a continuous non-negative random variable (i.e. $R_x$ has only non-negative values). Prove that $$E(X) = \int_{0}^{\infty} P(X>x)\,dx  = \int_{0}^{\infty} (1-F_X(x))\,dx$$ where $F_X(x)$ is the CDF for $X$. Using this result, find $E(X)$ for an exponential ($\lambda$) random variable. I know that by definition, $F_X(x) = P(X \leq x)$ and so $1 - F_X(x) = P(X>x)$ The solution is: $$\int_{0}^{\infty} \int_{x}^{\infty} f(y)\,dy dx    = \int_{0}^{\infty} \int_{0}^{y} f(y)\,dy dx  = \int_{0}^{\infty} yf(y) dy.$$ I'm really confused as to where the double integral came from. I'm also rusty on multivariate calc, so I'm confused about the swapping of $x$ and $\infty$ to $0$ and $y$. Any help would be greatly appreciated!","Let $X$ be a continuous non-negative random variable (i.e. $R_x$ has only non-negative values). Prove that $$E(X) = \int_{0}^{\infty} P(X>x)\,dx  = \int_{0}^{\infty} (1-F_X(x))\,dx$$ where $F_X(x)$ is the CDF for $X$. Using this result, find $E(X)$ for an exponential ($\lambda$) random variable. I know that by definition, $F_X(x) = P(X \leq x)$ and so $1 - F_X(x) = P(X>x)$ The solution is: $$\int_{0}^{\infty} \int_{x}^{\infty} f(y)\,dy dx    = \int_{0}^{\infty} \int_{0}^{y} f(y)\,dy dx  = \int_{0}^{\infty} yf(y) dy.$$ I'm really confused as to where the double integral came from. I'm also rusty on multivariate calc, so I'm confused about the swapping of $x$ and $\infty$ to $0$ and $y$. Any help would be greatly appreciated!",,"['calculus', 'probability', 'integration']"
59,Point of discontinuity,Point of discontinuity,,"I have a function:  $$f(x) = x$$ Defined over the domain $\mathbb{R} \backslash 0$. Is it correct to say that: The function is continuous, but it has a point of discontinuity at $x=0$?","I have a function:  $$f(x) = x$$ Defined over the domain $\mathbb{R} \backslash 0$. Is it correct to say that: The function is continuous, but it has a point of discontinuity at $x=0$?",,['calculus']
60,Are all functions that have a primitive differentiable?,Are all functions that have a primitive differentiable?,,"Are all functions that have a primitive differentiable? For some background, I know that not all functions that are integrable are differentiable. For example: $$ f =  \begin{cases} 0 & x \neq 0 \\ 1 & x = 0 \end{cases} $$ is integrable over $\mathbb{R}$ , and $\int_{a}^{b} f(x) dx = 0$ . However, a function $F(x)$ such that $F'(x) = f(x) \space \forall x \in \mathbb{R}$ does not exist. But I can't find a counterexample to the statement: ""All functions that have a primitive are differentiable"". These functions are guaranteed to be continuous due to the fundamental theorem of calculus, but not every continuous function is differentiable, hence the question. Thanks ! Edit: here is a very important comment from @HenningMakholm that I thought would be useful for other students encountering this question Also, (real) functions that have a primitive are not necessarily continuous. For example, $$ f(x) =  \begin{cases} 0 & \text{for } x = 0 \\ 2x \sin(\frac{1}{x}) - \cos(\frac{1}{x}) & \text{otherwise} \end{cases} $$ is discontinuous at $x=0$ , but nevertheless the derivative of $$ F(x) =  \begin{cases} 0 & \text{ for } x = 0 \\ x^2 \sin(\frac{1}{x}) & \text{ otherwise} \end{cases} $$ Functions that have a primitive do have the intermediate-value property but that is weaker than being continuous.","Are all functions that have a primitive differentiable? For some background, I know that not all functions that are integrable are differentiable. For example: is integrable over , and . However, a function such that does not exist. But I can't find a counterexample to the statement: ""All functions that have a primitive are differentiable"". These functions are guaranteed to be continuous due to the fundamental theorem of calculus, but not every continuous function is differentiable, hence the question. Thanks ! Edit: here is a very important comment from @HenningMakholm that I thought would be useful for other students encountering this question Also, (real) functions that have a primitive are not necessarily continuous. For example, is discontinuous at , but nevertheless the derivative of Functions that have a primitive do have the intermediate-value property but that is weaker than being continuous.","
f = 
\begin{cases}
0 & x \neq 0 \\
1 & x = 0
\end{cases}
 \mathbb{R} \int_{a}^{b} f(x) dx = 0 F(x) F'(x) = f(x) \space \forall x \in \mathbb{R} 
f(x) = 
\begin{cases}
0 & \text{for } x = 0 \\
2x \sin(\frac{1}{x}) - \cos(\frac{1}{x}) & \text{otherwise}
\end{cases}
 x=0 
F(x) = 
\begin{cases}
0 & \text{ for } x = 0 \\
x^2 \sin(\frac{1}{x}) & \text{ otherwise}
\end{cases}
",['calculus']
61,How can I calculate the derivative of $g(z)=\int_{z^2}^{z^3}\frac{1}{\sqrt{1+t^2}} dt$?,How can I calculate the derivative of ?,g(z)=\int_{z^2}^{z^3}\frac{1}{\sqrt{1+t^2}} dt,How can I calculate the derivative of $$g(z)=\int_{z^2}^{z^3}\frac{1}{\sqrt{1+t^2}} dt$$ Is there anything I can do apart from calculating the integral and then derivate?,How can I calculate the derivative of $$g(z)=\int_{z^2}^{z^3}\frac{1}{\sqrt{1+t^2}} dt$$ Is there anything I can do apart from calculating the integral and then derivate?,,"['calculus', 'integration', 'derivatives']"
62,Indefinite integral question: $\int \frac{1}{x\sqrt{x^2+x}}dx$,Indefinite integral question:,\int \frac{1}{x\sqrt{x^2+x}}dx,How can I solve this integral: $$\int \frac{1}{x\sqrt{x^2+x}}dx$$ I first completed the square and got: $$\int \frac{1}{x\sqrt{(x+\frac{1}{2})^2-\frac{1}{4}}}dx$$ Then I factored out 1/4 and got: $$2\int \frac{1}{x\sqrt{(2x+1)^2-1}}dx$$ Then I substituted $2x+1$ with $t$ and got: $$2\int \frac{1}{(t-1)\sqrt{t^2-1}}dt$$ I'm not sure what to do next. Please give me a hint ;),How can I solve this integral: $$\int \frac{1}{x\sqrt{x^2+x}}dx$$ I first completed the square and got: $$\int \frac{1}{x\sqrt{(x+\frac{1}{2})^2-\frac{1}{4}}}dx$$ Then I factored out 1/4 and got: $$2\int \frac{1}{x\sqrt{(2x+1)^2-1}}dx$$ Then I substituted $2x+1$ with $t$ and got: $$2\int \frac{1}{(t-1)\sqrt{t^2-1}}dt$$ I'm not sure what to do next. Please give me a hint ;),,"['calculus', 'integration', 'indefinite-integrals', 'closed-form']"
63,Show that $e^x \geq (3/2) x^2$ for all non-negative $x$,Show that  for all non-negative,e^x \geq (3/2) x^2 x,"I am attempting to solve a two-part problem, posed in Buck's Advanced Calculus on page 153. It asks ""Show that $e^x \geq \frac{3}{2}x^2$  $\forall x\geq 0$. Can $3/2$ be replaced by a larger constant?"" This is after the section regarding Taylor polynomials, so I have been attempting to leverage the Taylor expansion for $e^x$ at $0$. $e^x \geq 1+x+\frac{x^2}{2}$, and by quadratic formula, we have $1+x+\frac{x^2}{2}\geq \frac{3}{2}x^2$ for $x\in [0, \frac{1+\sqrt{5}}{2}]$. Now also $e^x\geq 1+x+\frac{x^2}{2}+\frac{x^3}{6}$. We know there exists a $c\in \mathbb{R}^{\geq 0}$ such that for all $x\geq c$, we have $1+x+\frac{x^2}{2}+\frac{x^3}{6}\geq \frac{3}{2}x^2$. I want to find this point without messing with the cubic formula, etc. I think I am missing a simpler way. Any ideas?","I am attempting to solve a two-part problem, posed in Buck's Advanced Calculus on page 153. It asks ""Show that $e^x \geq \frac{3}{2}x^2$  $\forall x\geq 0$. Can $3/2$ be replaced by a larger constant?"" This is after the section regarding Taylor polynomials, so I have been attempting to leverage the Taylor expansion for $e^x$ at $0$. $e^x \geq 1+x+\frac{x^2}{2}$, and by quadratic formula, we have $1+x+\frac{x^2}{2}\geq \frac{3}{2}x^2$ for $x\in [0, \frac{1+\sqrt{5}}{2}]$. Now also $e^x\geq 1+x+\frac{x^2}{2}+\frac{x^3}{6}$. We know there exists a $c\in \mathbb{R}^{\geq 0}$ such that for all $x\geq c$, we have $1+x+\frac{x^2}{2}+\frac{x^3}{6}\geq \frac{3}{2}x^2$. I want to find this point without messing with the cubic formula, etc. I think I am missing a simpler way. Any ideas?",,"['calculus', 'inequality', 'taylor-expansion']"
64,How to integrate$\int_0^1 \frac{\ln x}{x-1}dx$ without power series expansion,How to integrate without power series expansion,\int_0^1 \frac{\ln x}{x-1}dx,"I happen to watch the video here , which gives a solution to the definite integral below using the power series approach. Then answer is $\frac{\pi^2}{6}$ , given by: $$\int_0^1 \frac{\ln x}{x-1}dx=\int_{-1}^0 \frac{\ln(1+u)}{u}du=\sum_{n=0}^{\infty}\frac{1}{(n+1)^2}=\frac{\pi^2}{6},$$ where the power seires expansion of the function $\ln(1+u)$ is used. I tried for some time, but could not find another approach. Does anyone know any alternative methods to evaluate above definite integral without using the infinite series expansion? Any comments, or ideas, are really appreciated.","I happen to watch the video here , which gives a solution to the definite integral below using the power series approach. Then answer is , given by: where the power seires expansion of the function is used. I tried for some time, but could not find another approach. Does anyone know any alternative methods to evaluate above definite integral without using the infinite series expansion? Any comments, or ideas, are really appreciated.","\frac{\pi^2}{6} \int_0^1 \frac{\ln x}{x-1}dx=\int_{-1}^0 \frac{\ln(1+u)}{u}du=\sum_{n=0}^{\infty}\frac{1}{(n+1)^2}=\frac{\pi^2}{6}, \ln(1+u)","['calculus', 'integration', 'definite-integrals']"
65,How to calculate $\int_{-a}^{a} \sqrt{a^2-x^2}\ln(\sqrt{a^2-x^2})\mathrm{dx}$,How to calculate,\int_{-a}^{a} \sqrt{a^2-x^2}\ln(\sqrt{a^2-x^2})\mathrm{dx},"Well,this is a homework problem. I need to calculate the differential entropy of random variable $X\sim f(x)=\sqrt{a^2-x^2},\quad -a<x<a$ and $0$ otherwise. Just how to calculate $$ \int_{-a}^a \sqrt{a^2-x^2}\ln(\sqrt{a^2-x^2})\,\mathrm{d}x $$ I can get the result with Mathematica,but failed to calculate it by hand.Please give me some idea.","Well,this is a homework problem. I need to calculate the differential entropy of random variable $X\sim f(x)=\sqrt{a^2-x^2},\quad -a<x<a$ and $0$ otherwise. Just how to calculate $$ \int_{-a}^a \sqrt{a^2-x^2}\ln(\sqrt{a^2-x^2})\,\mathrm{d}x $$ I can get the result with Mathematica,but failed to calculate it by hand.Please give me some idea.",,['calculus']
66,Evaluating $\lim\limits_{x\to0}\frac{1-\cos(x)}{x}$,Evaluating,\lim\limits_{x\to0}\frac{1-\cos(x)}{x},$$\lim_{x\to0}\frac{1-\cos(x)}{x}$$ Could someone help me with this trigonometric limit? I am trying to evaluate it without l'Hôpital's rule and derivation.,Could someone help me with this trigonometric limit? I am trying to evaluate it without l'Hôpital's rule and derivation.,\lim_{x\to0}\frac{1-\cos(x)}{x},"['calculus', 'limits', 'limits-without-lhopital']"
67,Why adjoining non-Archimedean element doesn't work as calculus foundation?,Why adjoining non-Archimedean element doesn't work as calculus foundation?,,Consider the smallest ordered field that contains R and does not satisfy the Archimedean property . I assume this is a much simpler construction than ultrafilters and other big caliber artillery used in non-standard analysis. Why does this approach fail?,Consider the smallest ordered field that contains R and does not satisfy the Archimedean property . I assume this is a much simpler construction than ultrafilters and other big caliber artillery used in non-standard analysis. Why does this approach fail?,,"['calculus', 'abstract-algebra', 'nonstandard-analysis']"
68,Area under the curve - Integrals (Antiderivatives),Area under the curve - Integrals (Antiderivatives),,"I have a question regarding antiderivatives and area under the curve. I've learned that first, you must to a graph to see if the area is above or below the curve. If it is above the $x$ -axis the area is ""positive"" and I must use $A=\int f(x) dx $ . If it is below the $x$ -axis the area is ""negative"" and I must use $A=-\int f(x) dx $ . In this last one, I've understood that negative outside the integral is because the integration alone will be negative because is under $x$ -axis, but an area can't be negative so that's why is multiply by that negative. I've also seen this with absolute value $A=|\int f(x) dx| $ that I think have the same purpose. This is an example of an exercise: Determine the area of the region bounded by the curve of the function $f(x)=4x^3-16x$ the $x$ -axis and the lines $x=-2$ y $x=2$ . Ok. I'll show you my work. I first do the graph. I see that between $-2$ and $0$ the region bounded is above the $x$ -axis so is positive, and that between $0$ and $2$ the region bounded is below the $x$ -axis so is negative. So I'll call the first one $A_1$ and the second $A_2$ . $$A_{total}=\int_{-2}^2 (4x^3-16x) dx$$ $$A_{total}=A_1+A_2$$ $$A_{total}=\int_{-2}^0 f(x) dx+(-\int_0^2 f(x) dx)$$ $$A_{total}=\int_{-2}^0 (4x^3-16x) dx+(-\int_0^2 (4x^3-16x) dx)$$ $$A_{total}=[\frac{4x^4}{4}-\frac{16x^2}{2}]|^{0}_{-2} - [\frac{4x^4}{4}-\frac{16x^2}{2}]|^{2}_{0} $$ $$A_{total}=[x^4-8x^2]|^{0}_{-2} - [x^4-8x^2]|^{2}_{0} $$ $$A_{total}=[((0)^4-8(0)^2)-((-2)^4-8(-2)^2)]-[((2)^4-8(2)^2)-((0)^4-8(0)^2)]$$ $$A_{total}=[-(16-32)]-[16-32]$$ $$A_{total}=[-(-16)]-[-16]$$ $$A_{total}=16+16$$ $$A_{total}=32u^2$$ So I got that the total area is 32 square units. But I was wondering why is this different from doing the integration of $\int_{-2}^2 (4x^3-16x) dx$ . This gives $0$ . $$\int_{-2}^2 (4x^3-16x) dx$$ $$=[\frac{4x^4}{4}-\frac{16x^2}{2}]|^{2}_{-2}$$ $$=[x^4-8x^2]|^{2}_{-2}$$ $$=[(2)^4-8(2)^2]-[(-2)^4-8(-2)^2]$$ $$=[16-32]-[16-32]$$ $$=-16-[-16]$$ $$=-16+16$$ $$=0$$ So I'm a bit confused. Which is one correct? Please help.","I have a question regarding antiderivatives and area under the curve. I've learned that first, you must to a graph to see if the area is above or below the curve. If it is above the -axis the area is ""positive"" and I must use . If it is below the -axis the area is ""negative"" and I must use . In this last one, I've understood that negative outside the integral is because the integration alone will be negative because is under -axis, but an area can't be negative so that's why is multiply by that negative. I've also seen this with absolute value that I think have the same purpose. This is an example of an exercise: Determine the area of the region bounded by the curve of the function the -axis and the lines y . Ok. I'll show you my work. I first do the graph. I see that between and the region bounded is above the -axis so is positive, and that between and the region bounded is below the -axis so is negative. So I'll call the first one and the second . So I got that the total area is 32 square units. But I was wondering why is this different from doing the integration of . This gives . So I'm a bit confused. Which is one correct? Please help.",x A=\int f(x) dx  x A=-\int f(x) dx  x A=|\int f(x) dx|  f(x)=4x^3-16x x x=-2 x=2 -2 0 x 0 2 x A_1 A_2 A_{total}=\int_{-2}^2 (4x^3-16x) dx A_{total}=A_1+A_2 A_{total}=\int_{-2}^0 f(x) dx+(-\int_0^2 f(x) dx) A_{total}=\int_{-2}^0 (4x^3-16x) dx+(-\int_0^2 (4x^3-16x) dx) A_{total}=[\frac{4x^4}{4}-\frac{16x^2}{2}]|^{0}_{-2} - [\frac{4x^4}{4}-\frac{16x^2}{2}]|^{2}_{0}  A_{total}=[x^4-8x^2]|^{0}_{-2} - [x^4-8x^2]|^{2}_{0}  A_{total}=[((0)^4-8(0)^2)-((-2)^4-8(-2)^2)]-[((2)^4-8(2)^2)-((0)^4-8(0)^2)] A_{total}=[-(16-32)]-[16-32] A_{total}=[-(-16)]-[-16] A_{total}=16+16 A_{total}=32u^2 \int_{-2}^2 (4x^3-16x) dx 0 \int_{-2}^2 (4x^3-16x) dx =[\frac{4x^4}{4}-\frac{16x^2}{2}]|^{2}_{-2} =[x^4-8x^2]|^{2}_{-2} =[(2)^4-8(2)^2]-[(-2)^4-8(-2)^2] =[16-32]-[16-32] =-16-[-16] =-16+16 =0,"['calculus', 'integration', 'definite-integrals']"
69,The value of the integral $\int_0^2\left(\sqrt{1+x^3}+\sqrt[3]{x^2+2x}\:\right)dx$,The value of the integral,\int_0^2\left(\sqrt{1+x^3}+\sqrt[3]{x^2+2x}\:\right)dx,"The value of definite integral $$\int\limits_{0}^{2}\left(\sqrt{1+x^3}+\sqrt[3]{x^2+2x}\:\right)dx$$ is $$(A)\,4 \quad(B)\,5 \quad (C)\,6  \quad(D)\,7$$ My attempt: I tried using $\int\limits_{0}^{a}f(x)dx=\int\limits_{0}^{a}f(a-x)dx$ but not working. I tried putting $x^3+1=\tan^2\theta$, its also not working. Can someone help me solve this problem?","The value of definite integral $$\int\limits_{0}^{2}\left(\sqrt{1+x^3}+\sqrt[3]{x^2+2x}\:\right)dx$$ is $$(A)\,4 \quad(B)\,5 \quad (C)\,6  \quad(D)\,7$$ My attempt: I tried using $\int\limits_{0}^{a}f(x)dx=\int\limits_{0}^{a}f(a-x)dx$ but not working. I tried putting $x^3+1=\tan^2\theta$, its also not working. Can someone help me solve this problem?",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'radicals']"
70,How do you calculate this limit $\lim_{n\to\infty}\sum_{k=1}^{n} \frac{k}{n^2+k^2}$?,How do you calculate this limit ?,\lim_{n\to\infty}\sum_{k=1}^{n} \frac{k}{n^2+k^2},"How to find the value of $\lim_{n\to\infty}S(n)$, where $S(n)$ is given by $$S(n)=\displaystyle\sum_{k=1}^{n} \dfrac{k}{n^2+k^2}$$ Wolfram alpha is unable to calculate it. This is a question from a questions booklet, and the options for the answer are-- $\begin{align} &A) \dfrac{\pi}{2} \\ &B) \log 2 \\ &C) \dfrac{\pi}{4} \\ &D) \dfrac{1}{2} \log 2 \end{align}$","How to find the value of $\lim_{n\to\infty}S(n)$, where $S(n)$ is given by $$S(n)=\displaystyle\sum_{k=1}^{n} \dfrac{k}{n^2+k^2}$$ Wolfram alpha is unable to calculate it. This is a question from a questions booklet, and the options for the answer are-- $\begin{align} &A) \dfrac{\pi}{2} \\ &B) \log 2 \\ &C) \dfrac{\pi}{4} \\ &D) \dfrac{1}{2} \log 2 \end{align}$",,"['calculus', 'sequences-and-series', 'limits', 'summation', 'riemann-sum']"
71,Why is a function at sharp point not differentiable?,Why is a function at sharp point not differentiable?,,I am learning about differentiability of functions and came to know that a function at sharp point is not differentiable. For eg. $$f(x)=|x|$$ I could find out that $f(x)$ is not differentiable at $x=0$ because $$\lim_{x\to 0^-}f'(x) \ne \lim_{x\to 0^+}f'(x) $$ This is all mathematical but I couldn't understand where the sharp point plays its role here ? How sharp point makes these limits to evaluate different ?,I am learning about differentiability of functions and came to know that a function at sharp point is not differentiable. For eg. $$f(x)=|x|$$ I could find out that $f(x)$ is not differentiable at $x=0$ because $$\lim_{x\to 0^-}f'(x) \ne \lim_{x\to 0^+}f'(x) $$ This is all mathematical but I couldn't understand where the sharp point plays its role here ? How sharp point makes these limits to evaluate different ?,,"['calculus', 'limits']"
72,prove $f'(x)=f(x)$,prove,f'(x)=f(x),"Given a function $f$ satisfying the following two conditions for all $x$ and $y$: (a) $f(x+y)=f(x)\cdot f(y)$, (b) $f(x)=1+xg(x)$, where $\displaystyle \lim_{x\rightarrow 0}g(x)=1$. Prove that $f'(x)=f(x)$. The only thing I know is that $f'(x)=f(x)$ is true for $x=\{0,1\}$ , but how do we know that it's true for all $x$?","Given a function $f$ satisfying the following two conditions for all $x$ and $y$: (a) $f(x+y)=f(x)\cdot f(y)$, (b) $f(x)=1+xg(x)$, where $\displaystyle \lim_{x\rightarrow 0}g(x)=1$. Prove that $f'(x)=f(x)$. The only thing I know is that $f'(x)=f(x)$ is true for $x=\{0,1\}$ , but how do we know that it's true for all $x$?",,['calculus']
73,Is it always safe to assume that a integral is zero if it has equal bounds?,Is it always safe to assume that a integral is zero if it has equal bounds?,,"I'm still a ""newbie"" on mathematical analysis and I stumbled upon this integral. This is my solution: $$\int_0^{2\pi}{\frac{x\cos x}{1+\sin^2x}dx}$$ Now I substitued with $t=\sin x$ $$=\int_0^0{\frac{a\sin x}{1+t^2}dt} = 0$$ But I found that the integral $\displaystyle\int_0^\pi{\frac{\cos x}{\sin^2 x}dx}$ which I solved by the same substitution is not $0$ but it is indeterminate. Not sure if this is right.","I'm still a ""newbie"" on mathematical analysis and I stumbled upon this integral. This is my solution: $$\int_0^{2\pi}{\frac{x\cos x}{1+\sin^2x}dx}$$ Now I substitued with $t=\sin x$ $$=\int_0^0{\frac{a\sin x}{1+t^2}dt} = 0$$ But I found that the integral $\displaystyle\int_0^\pi{\frac{\cos x}{\sin^2 x}dx}$ which I solved by the same substitution is not $0$ but it is indeterminate. Not sure if this is right.",,"['calculus', 'integration', 'analysis']"
74,Evaluate $ \int_{0}^{\pi/4}\left(\cos 2x \right)^{11/2}\cdot \cos x\;dx $,Evaluate, \int_{0}^{\pi/4}\left(\cos 2x \right)^{11/2}\cdot \cos x\;dx ,"Evaluate the definite integral $$ I=\int_{0}^{\pi/4}(\cos 2x)^{11/2}\cdot \cos x\;dx $$ My Attempt: $$ I = \int \left(1-2\sin^2 x\right)^{11/2}\cdot \cos x\;dx $$ Now, substitute $\sin x=t$ with $\cos x \,dx = dt$: $$ I = \int (1-2t^2)^{11/2}\;dt $$ How can I complete the solution from this point?","Evaluate the definite integral $$ I=\int_{0}^{\pi/4}(\cos 2x)^{11/2}\cdot \cos x\;dx $$ My Attempt: $$ I = \int \left(1-2\sin^2 x\right)^{11/2}\cdot \cos x\;dx $$ Now, substitute $\sin x=t$ with $\cos x \,dx = dt$: $$ I = \int (1-2t^2)^{11/2}\;dt $$ How can I complete the solution from this point?",,"['calculus', 'integration', 'definite-integrals', 'trigonometric-integrals']"
75,Multiple root of a polynomial is also a root of the derivative,Multiple root of a polynomial is also a root of the derivative,,"Suppose $a\in\Bbb R$ is a root of $f(x)$ in $\Bbb R[x]$. Show that $a$ is a multiple root of $f(x)$ if and only if $f'(a) = 0$, if and only if the graph of $y = f(x)$ is tangent to the $x$-axis at $x=a$. So for a I know that if $f'(a) = 0$, then $f(a)$ is a local extremum so $a$ is a root but I do not see why a would be a multiple root.","Suppose $a\in\Bbb R$ is a root of $f(x)$ in $\Bbb R[x]$. Show that $a$ is a multiple root of $f(x)$ if and only if $f'(a) = 0$, if and only if the graph of $y = f(x)$ is tangent to the $x$-axis at $x=a$. So for a I know that if $f'(a) = 0$, then $f(a)$ is a local extremum so $a$ is a root but I do not see why a would be a multiple root.",,"['calculus', 'derivatives', 'polynomials', 'roots']"
76,"If a particle travels $30$ meters every $3$ seconds, does it necessarily travel $20$ meters every $2$ seconds? [closed]","If a particle travels  meters every  seconds, does it necessarily travel  meters every  seconds? [closed]",30 3 20 2,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Is it possible if its motion were discontinuous? I'm trying to understand if there is a function that has this property, but I chose to say it in terms of motion because it's easier to explain.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Is it possible if its motion were discontinuous? I'm trying to understand if there is a function that has this property, but I chose to say it in terms of motion because it's easier to explain.",,['calculus']
77,Don't understand why this binomial expansion is not valid for x > 1,Don't understand why this binomial expansion is not valid for x > 1,,"today I'm studying binomial expansion and I'm a little confused about when certain expressions are valid. E.g. take this solution from my textbook: I understand that $(1-x)^{-1}$ has an infinite expansion. I also understand that it is invalid when $x=1$ as $0^{-1}$ is undefined. However, could someone explain to me why this is invalid for $x>1$? What is invalid about $(1-2)^{-1}$ i.e. $-\frac{1}{1} = -1$? Thanks! Edit: Also take the next question. I incorrectly guessed it would be valid for all x greater than or equal to 0, as you can take the square root of any positive number greater than 0. So why is this valid when $\mod{x} < 1$?","today I'm studying binomial expansion and I'm a little confused about when certain expressions are valid. E.g. take this solution from my textbook: I understand that $(1-x)^{-1}$ has an infinite expansion. I also understand that it is invalid when $x=1$ as $0^{-1}$ is undefined. However, could someone explain to me why this is invalid for $x>1$? What is invalid about $(1-2)^{-1}$ i.e. $-\frac{1}{1} = -1$? Thanks! Edit: Also take the next question. I incorrectly guessed it would be valid for all x greater than or equal to 0, as you can take the square root of any positive number greater than 0. So why is this valid when $\mod{x} < 1$?",,"['calculus', 'sequences-and-series', 'convergence-divergence', 'taylor-expansion']"
78,Prove $\int_0^\infty\frac{\ln x}{x^3-1}\mathrm{d}x=\frac{4\pi^2}{27}$,Prove,\int_0^\infty\frac{\ln x}{x^3-1}\mathrm{d}x=\frac{4\pi^2}{27},"Proof of the integral $$\int_0^\infty\frac{\ln x}{x^3-1}\mathrm{d}x=\frac{4\pi^2}{27}$$ I try to substitute $u = \ln x$ . Then $x = e^u,\>\mathrm{d}x = e^u\mathrm{d}u$ and the limits $(0,\infty)\to (-\infty,\infty)$ . The integral becomes $$\int_{-\infty}^\infty \frac{ue^u}{e^{3u}-1}\mathrm{d}u.$$",Proof of the integral I try to substitute . Then and the limits . The integral becomes,"\int_0^\infty\frac{\ln x}{x^3-1}\mathrm{d}x=\frac{4\pi^2}{27} u = \ln x x = e^u,\>\mathrm{d}x = e^u\mathrm{d}u (0,\infty)\to (-\infty,\infty) \int_{-\infty}^\infty \frac{ue^u}{e^{3u}-1}\mathrm{d}u.","['calculus', 'integration', 'improper-integrals']"
79,Evaluating limit (iterated sine function),Evaluating limit (iterated sine function),,"The limit is $$\lim_{x\rightarrow0} \frac{x-\sin_n(x)}{x^3},$$ where $\sin_n(x)$ is the $\sin(x)$ function composed with itself $n$ times: $$\sin_n(x) = \sin(\sin(\dots \sin(x)))$$ For $n=1$ the limit is $\frac{1}{6}$, $n=2$, the limit is $\frac{1}{3}$ and so on. Can we define a recurrent relation upon that given hypothesis? Also, how do I involve $n$ into calculation, because the final limit will depend on it? Any suggestions on how to tackle this? Thank you!","The limit is $$\lim_{x\rightarrow0} \frac{x-\sin_n(x)}{x^3},$$ where $\sin_n(x)$ is the $\sin(x)$ function composed with itself $n$ times: $$\sin_n(x) = \sin(\sin(\dots \sin(x)))$$ For $n=1$ the limit is $\frac{1}{6}$, $n=2$, the limit is $\frac{1}{3}$ and so on. Can we define a recurrent relation upon that given hypothesis? Also, how do I involve $n$ into calculation, because the final limit will depend on it? Any suggestions on how to tackle this? Thank you!",,"['calculus', 'limits', 'trigonometry']"
80,How to prove $\frac{x}{1+x^2}<\arctan x<x$ for $x>0$?,How to prove  for ?,\frac{x}{1+x^2}<\arctan x<x x>0,"How to prove for $x>0$, $\dfrac{x}{1+x^2}<\arctan x<x$? I started with saying $0<\arctan x<\frac{\pi}{2}$  when $x>0$ I'm just not sure how to proceed with this proof, it works when I take random  values but I cant see how to prove that it works for any $x$.","How to prove for $x>0$, $\dfrac{x}{1+x^2}<\arctan x<x$? I started with saying $0<\arctan x<\frac{\pi}{2}$  when $x>0$ I'm just not sure how to proceed with this proof, it works when I take random  values but I cant see how to prove that it works for any $x$.",,"['calculus', 'inequality']"
81,Heaviside step function fourier transform and principal values,Heaviside step function fourier transform and principal values,,"I found the following answer on Math.SE: Fourier transform of unit step? However, it is still not clear to me and maybe somebody could explain it clearer. Problem I have the following in my notes of a theoretical physics course: $$ \hat{\Theta}(\omega) = \int_{-\infty}^\infty \Theta (t) e^{i\omega t} \mathrm{d} t  = \lim_{\varepsilon \to 0} \int_0^\infty e^{i\omega t - \varepsilon t} \mathrm{d}t = \pi \delta(\omega) + \mathrm{P} \frac{i}{\omega}, $$ where the $\mathrm{P}$ denotes the Cauchy's principal value. Question I understand why I get a delta function in this computation, but I have no idea why I have $\mathrm{P} \frac{i}{\omega}$ instead of just $\frac{i}{\omega}$ in the resulting expression.","I found the following answer on Math.SE: Fourier transform of unit step? However, it is still not clear to me and maybe somebody could explain it clearer. Problem I have the following in my notes of a theoretical physics course: $$ \hat{\Theta}(\omega) = \int_{-\infty}^\infty \Theta (t) e^{i\omega t} \mathrm{d} t  = \lim_{\varepsilon \to 0} \int_0^\infty e^{i\omega t - \varepsilon t} \mathrm{d}t = \pi \delta(\omega) + \mathrm{P} \frac{i}{\omega}, $$ where the $\mathrm{P}$ denotes the Cauchy's principal value. Question I understand why I get a delta function in this computation, but I have no idea why I have $\mathrm{P} \frac{i}{\omega}$ instead of just $\frac{i}{\omega}$ in the resulting expression.",,"['calculus', 'fourier-analysis', 'distribution-theory']"
82,A Series For the Golden Ratio,A Series For the Golden Ratio,,Question: Can we show that $$\phi=\frac{1}{2}+\frac{11}{2}\sum_{n=0}^\infty\frac{(2n)!}{5^{3n+1}(n!)^2} $$ ; where $\phi={1+\sqrt{5} \above 1.5pt 2}$ is the golden ratio ? Some background and motivation: Wikipedia only provides one series for the golden ratio - see also the link in the comment by @Zacky. I became curious if I could construct another series for the Golden Ratio based on a slight modification to a known series representation of the $\sqrt{2}.$ At first I considered $$\sqrt{2}=\sum_{n=0}^\infty(-1)^{n+1}\frac{(2n+1)!!}{(2n)!!}$$ ; which series can be accelerated via an Euler transform to yield $$\sqrt{2}=\sum_{n=0}^\infty(-1)^{n+1}\frac{(2n+1)!!}{2^{3n+1}(n!)^2}$$ This last series became the impetus to try and and get to the Golden ratio. Through trial and error I stumbled upon $$\frac{\sqrt{5}}{11}=\sum_{n=0}^\infty\frac{(2n)!}{5^{3n+1}(n!)^2}$$,Question: Can we show that ; where is the golden ratio ? Some background and motivation: Wikipedia only provides one series for the golden ratio - see also the link in the comment by @Zacky. I became curious if I could construct another series for the Golden Ratio based on a slight modification to a known series representation of the At first I considered ; which series can be accelerated via an Euler transform to yield This last series became the impetus to try and and get to the Golden ratio. Through trial and error I stumbled upon,\phi=\frac{1}{2}+\frac{11}{2}\sum_{n=0}^\infty\frac{(2n)!}{5^{3n+1}(n!)^2}  \phi={1+\sqrt{5} \above 1.5pt 2} \sqrt{2}. \sqrt{2}=\sum_{n=0}^\infty(-1)^{n+1}\frac{(2n+1)!!}{(2n)!!} \sqrt{2}=\sum_{n=0}^\infty(-1)^{n+1}\frac{(2n+1)!!}{2^{3n+1}(n!)^2} \frac{\sqrt{5}}{11}=\sum_{n=0}^\infty\frac{(2n)!}{5^{3n+1}(n!)^2},"['calculus', 'sequences-and-series', 'golden-ratio']"
83,"Hints on calculating the integral $\int_0^1\frac{x^{19}-1}{\ln x}\,dx$",Hints on calculating the integral,"\int_0^1\frac{x^{19}-1}{\ln x}\,dx","I would be happy to get some hints on the following integral: $$ \int_0^1\frac{x^{19}-1}{\ln x}\,dx $$","I would be happy to get some hints on the following integral: $$ \int_0^1\frac{x^{19}-1}{\ln x}\,dx $$",,"['calculus', 'integration', 'definite-integrals', 'logarithms', 'improper-integrals']"
84,How to compare logarithms $\log_4 5$ and $\log_5 6$? [duplicate],How to compare logarithms  and ? [duplicate],\log_4 5 \log_5 6,This question already has answers here : How to know if $\log_78 > \log_89$ without using a calculator? (6 answers) Closed last year . I need to compare $\log_4 5$ and $\log_5 6$ .  I can estimate both numbers like $1.16$ and $1.11$ . Then I took smallest fraction $\frac{8}{7}$ which is greater than $1.11$ and smaller than $1.16$ and proove two inequalities: $$\log_4 5 > \frac{8}{7}$$ $$\frac{7}{8}\log_4 5 > 1$$ $$\log_{4^8} 5^7 > 1$$ $$\log_{65536} 78125 > 1$$ and $$\log_5 6 < \frac{8}{7}$$ $$\frac{7}{8}\log_5 6 < 1$$ $$\log_{5^8} 6^7 < 1$$ $$\log_{390625} 279936 < 1$$ thats why I have $\log_5 6 < \frac{8}{7} < \log_4 5$ . But for proving I need estimation both logarithms (without this estimation I cannot find the fraction for comparing). Can you help me to find more clear solution (without graphs),This question already has answers here : How to know if $\log_78 > \log_89$ without using a calculator? (6 answers) Closed last year . I need to compare and .  I can estimate both numbers like and . Then I took smallest fraction which is greater than and smaller than and proove two inequalities: and thats why I have . But for proving I need estimation both logarithms (without this estimation I cannot find the fraction for comparing). Can you help me to find more clear solution (without graphs),\log_4 5 \log_5 6 1.16 1.11 \frac{8}{7} 1.11 1.16 \log_4 5 > \frac{8}{7} \frac{7}{8}\log_4 5 > 1 \log_{4^8} 5^7 > 1 \log_{65536} 78125 > 1 \log_5 6 < \frac{8}{7} \frac{7}{8}\log_5 6 < 1 \log_{5^8} 6^7 < 1 \log_{390625} 279936 < 1 \log_5 6 < \frac{8}{7} < \log_4 5,"['calculus', 'algebra-precalculus', 'inequality', 'logarithms', 'a.m.-g.m.-inequality']"
85,Where is my argument that $\int_{-1}^{1} \sqrt{1-x^2}dx=0$ wrong?,Where is my argument that  wrong?,\int_{-1}^{1} \sqrt{1-x^2}dx=0,"$$\int_{-1}^{1} \sqrt{1-x^2}dx$$ I let $u = 1-x^2$ , $x = (1-u)^{1/2}$ $du = -2x dx$ $$-\frac{1}{2}\int_{0}^{0} \frac{u^{1/2}}{(1-u)^{1/2}}du = 0$$ because $$\int_{a}^{a} f(x)dx = 0$$ But it isn't zero. Why?????","I let , because But it isn't zero. Why?????",\int_{-1}^{1} \sqrt{1-x^2}dx u = 1-x^2 x = (1-u)^{1/2} du = -2x dx -\frac{1}{2}\int_{0}^{0} \frac{u^{1/2}}{(1-u)^{1/2}}du = 0 \int_{a}^{a} f(x)dx = 0,"['calculus', 'integration', 'definite-integrals']"
86,How to evaluate the trigonometric integral $\int \frac{1}{\cos x+\tan x }dx$,How to evaluate the trigonometric integral,\int \frac{1}{\cos x+\tan x }dx,$$\int \dfrac{1}{\cos x+\tan x }dx$$ This can be converted to $$\int \dfrac{\cos x}{\sin x+\cos^2x}dx$$ But from here I get stuck. Using t substitution will get you into a mess. Are there any tricks  which can split the fraction into simpler forms?,$$\int \dfrac{1}{\cos x+\tan x }dx$$ This can be converted to $$\int \dfrac{\cos x}{\sin x+\cos^2x}dx$$ But from here I get stuck. Using t substitution will get you into a mess. Are there any tricks  which can split the fraction into simpler forms?,,"['calculus', 'integration', 'trigonometry', 'indefinite-integrals']"
87,Solving $\lim\limits_{x\to0} \frac{x - \sin(x)}{x^2}$ without L'Hospital's Rule.,Solving  without L'Hospital's Rule.,\lim\limits_{x\to0} \frac{x - \sin(x)}{x^2},"How to solve $\lim\limits_{x\to 0} \frac{x - \sin(x)}{x^2}$ Without L'Hospital's Rule? you can use trigonometric identities and inequalities, but you can't use series or more advanced stuff.","How to solve $\lim\limits_{x\to 0} \frac{x - \sin(x)}{x^2}$ Without L'Hospital's Rule? you can use trigonometric identities and inequalities, but you can't use series or more advanced stuff.",,"['calculus', 'limits', 'limits-without-lhopital']"
88,"How to evaluate $\int_0^1 \frac{1-x}{\ln x}(x+x^2+x^{2^2}+x^{2^3}+x^{2^4}+\ldots) \, dx$?",How to evaluate ?,"\int_0^1 \frac{1-x}{\ln x}(x+x^2+x^{2^2}+x^{2^3}+x^{2^4}+\ldots) \, dx","Evaluate the definite integral: $$\int_0^1 \frac{1-x}{\ln x}(x+x^2+x^{2^2}+x^{2^3}+x^{2^4}+\ldots) \, dx$$ I think the series involving $x$ converges because $x\in[0,1]$, but I cannot form an expression for the series. If I let $$ u_n=x^{2^{n-1}} \\ \frac{\ln u_n}{\ln x}=2^{n-1} $$ but then this series does not converge. Even WolframAlpha cannot evaluate a definite integral together with an infinite series, so I am stuck on this.","Evaluate the definite integral: $$\int_0^1 \frac{1-x}{\ln x}(x+x^2+x^{2^2}+x^{2^3}+x^{2^4}+\ldots) \, dx$$ I think the series involving $x$ converges because $x\in[0,1]$, but I cannot form an expression for the series. If I let $$ u_n=x^{2^{n-1}} \\ \frac{\ln u_n}{\ln x}=2^{n-1} $$ but then this series does not converge. Even WolframAlpha cannot evaluate a definite integral together with an infinite series, so I am stuck on this.",,"['calculus', 'sequences-and-series', 'definite-integrals']"
89,"Prove this limit without using these techniques, and for beginner students: $\lim_{x\to0} \frac{e^x-1-x}{x^2}=\frac12$","Prove this limit without using these techniques, and for beginner students:",\lim_{x\to0} \frac{e^x-1-x}{x^2}=\frac12,"How can we prove that  $$\lim_{x\rightarrow 0}\cfrac{e^x-1-x}{x^2}=\cfrac{1}{2}$$ Without using L'hopital rule, and Taylor expansions? Thanks","How can we prove that  $$\lim_{x\rightarrow 0}\cfrac{e^x-1-x}{x^2}=\cfrac{1}{2}$$ Without using L'hopital rule, and Taylor expansions? Thanks",,"['calculus', 'limits', 'exponential-function', 'limits-without-lhopital']"
90,Why does the minimum value of $x^x$ equal $1/e$?,Why does the minimum value of  equal ?,x^x 1/e,"The graph of $y=x^x$ looks like this: As we can see, the graph has a minimum value at a turning point. According to WolframAlpha, this point is at $x=1/e$. I know that $e$ is the number for exponential growth and $\frac{d}{dx}e^x=e^x$, but these ideas seem unrelated to the fact that the mimum value of $x^x$ is $1/e$. Is this just pure coincidence, or could someone provide an intuitive explanation (i.e. more than just a proof) of why this is?","The graph of $y=x^x$ looks like this: As we can see, the graph has a minimum value at a turning point. According to WolframAlpha, this point is at $x=1/e$. I know that $e$ is the number for exponential growth and $\frac{d}{dx}e^x=e^x$, but these ideas seem unrelated to the fact that the mimum value of $x^x$ is $1/e$. Is this just pure coincidence, or could someone provide an intuitive explanation (i.e. more than just a proof) of why this is?",,"['calculus', 'exponential-function', 'exponentiation']"
91,Proof without using induction [duplicate],Proof without using induction [duplicate],,"This question already has answers here : Proving $\sum_{k=1}^n{k^2}=\frac{n(n+1)(2n+1)}{6}$ without induction [duplicate] (5 answers) Closed 9 years ago . How to prove that  $$1^2+2^2+...+n^2=\frac{n(n+1)(2n+1)}{6}$$ without using induction. If we don't know the right side of this expression, how to get right expression. I tried with partial sums and binomial formula but can't get it. So the problem is: $$1^2+2^2+...+n^2=?$$ Thanks for replies.","This question already has answers here : Proving $\sum_{k=1}^n{k^2}=\frac{n(n+1)(2n+1)}{6}$ without induction [duplicate] (5 answers) Closed 9 years ago . How to prove that  $$1^2+2^2+...+n^2=\frac{n(n+1)(2n+1)}{6}$$ without using induction. If we don't know the right side of this expression, how to get right expression. I tried with partial sums and binomial formula but can't get it. So the problem is: $$1^2+2^2+...+n^2=?$$ Thanks for replies.",,"['calculus', 'algebra-precalculus', 'induction']"
92,What does $dx$ mean in differential form?,What does  mean in differential form?,dx,"This question relates to this post . From what I know in calculus and standard analysis, strictly speaking, there is no meaning of $dx$. It only makes sense when combining with another $d$, e.g. $df/dx$ as derivative or integration, e.g. $\int f(x) dx$. The $dx$ in derivative or integration has a definite meaning inside the definition of derivative or integration, respectively. However, in differential form, it is given as $\omega = \frac{ \omega_{\mu_1,\cdots, \mu_r}}{r!} dx^{\mu_1} \wedge\cdots\wedge dx^{\mu_r} $ where $dx$ appears explicitly. What does $dx$ mean in differential form? Physicist usually say it is infinitesimal. However, infinitesimal does not mean anything in standard analysis, or I am completely mistaken?","This question relates to this post . From what I know in calculus and standard analysis, strictly speaking, there is no meaning of $dx$. It only makes sense when combining with another $d$, e.g. $df/dx$ as derivative or integration, e.g. $\int f(x) dx$. The $dx$ in derivative or integration has a definite meaning inside the definition of derivative or integration, respectively. However, in differential form, it is given as $\omega = \frac{ \omega_{\mu_1,\cdots, \mu_r}}{r!} dx^{\mu_1} \wedge\cdots\wedge dx^{\mu_r} $ where $dx$ appears explicitly. What does $dx$ mean in differential form? Physicist usually say it is infinitesimal. However, infinitesimal does not mean anything in standard analysis, or I am completely mistaken?",,"['calculus', 'differential-geometry']"
93,Nonpiecewise Function Defined at a Point but Not Continuous There,Nonpiecewise Function Defined at a Point but Not Continuous There,,"I make a big fuss that my calculus students provide a ""continuity argument"" to evaluate limits such as $\lim_{x \rightarrow 0} 2x + 1$, by which I mean they should tell me that $2x+1$ is a polynomial, polynomials are continuous on $(-\infty, \infty)$, and therefore $\lim_{x \rightarrow 0} 2x + 1 = 2 \cdot 0 + 1 = 1$. All the examples they encounter where it is not correct to simply evaluate at $a$ when $x \rightarrow a$ fall into one of two categories: The function is not defined at $a$. The function is piecewise and expressly constructed to have a discontinuity at $a$. I'd like to find a function $f$ with the following properties: $f(a)$ exists $f(a)$ is not (obviously) piecewise defined $f(x)$ is not continuous at $a$ $f$ is reasonably familiar to a Calculus I student - trigonometry would be admissible, but power series would not (though they might   still make for interesting reading)","I make a big fuss that my calculus students provide a ""continuity argument"" to evaluate limits such as $\lim_{x \rightarrow 0} 2x + 1$, by which I mean they should tell me that $2x+1$ is a polynomial, polynomials are continuous on $(-\infty, \infty)$, and therefore $\lim_{x \rightarrow 0} 2x + 1 = 2 \cdot 0 + 1 = 1$. All the examples they encounter where it is not correct to simply evaluate at $a$ when $x \rightarrow a$ fall into one of two categories: The function is not defined at $a$. The function is piecewise and expressly constructed to have a discontinuity at $a$. I'd like to find a function $f$ with the following properties: $f(a)$ exists $f(a)$ is not (obviously) piecewise defined $f(x)$ is not continuous at $a$ $f$ is reasonably familiar to a Calculus I student - trigonometry would be admissible, but power series would not (though they might   still make for interesting reading)",,"['calculus', 'limits', 'functions', 'continuity', 'examples-counterexamples']"
94,Evaluating $\int^{\infty}_{0}{\frac{\ln x}{(1+x^2)^2}dx}$,Evaluating,\int^{\infty}_{0}{\frac{\ln x}{(1+x^2)^2}dx},"$$\int^{\infty}_{0}{\frac{\ln x}{(1+x^2)^2}dx}$$ I've done a similar one: $\int^{\infty}_{1}{\frac{\ln^n x}{x^2}dx}$ using IBP, but in this case I've tried IBP multiple times, differentiating all of the possible choices, and it's only getting more convoluted. Also, no substitution I've tried like $x=e^u$ or $u=1+x^2$made the integral simpler. I'd appreciate a hint at this point, since I don't think it can be that hard.","$$\int^{\infty}_{0}{\frac{\ln x}{(1+x^2)^2}dx}$$ I've done a similar one: $\int^{\infty}_{1}{\frac{\ln^n x}{x^2}dx}$ using IBP, but in this case I've tried IBP multiple times, differentiating all of the possible choices, and it's only getting more convoluted. Also, no substitution I've tried like $x=e^u$ or $u=1+x^2$made the integral simpler. I'd appreciate a hint at this point, since I don't think it can be that hard.",,['calculus']
95,Simple Maclaurin Series $e^{\tan(x)}$,Simple Maclaurin Series,e^{\tan(x)},"In a multichoice online test that I did the other day, I was required to select the Maclaurin series for $e^{\tan(x)}$. It was necessary for me to find the first four terms in order to establish which answer was correct. In the end of year exam, I will have reference to a Useful Information booklet (this contains a generalized Taylor polynomial approximation and Maclaurin series of $e^x$, $(1+x)^n$, $\sin(x)$, $\cos(x)$ and $\ln(1+x)$), and no calculator - hence throughout all of of my work, including online tests (which do contribute to my grade), I choose only to work with this resource, as preparation for this exam. As my approach for this problem, I used the generalized Taylor polynomial approximation to find the Maclaurin series for $\tan(x)$ and substituted this series in place of $x$ into the given Maclaurin series for $e^x$, and double-checked my answer once I had finished every other question by using the generalized Taylor polynomial approximation to find the Maclaurin series for $e^{\tan(x)}$. Obviously, as you can imagine, both of these methods were very time consuming (especially when you consider that the other nineteen questions in the test collectively took me less than ten minutes to answer). I'm probably missing a simple concept here. Can you please help me to establish a more elegant approach to this problem? The choices I was given were as follows:","In a multichoice online test that I did the other day, I was required to select the Maclaurin series for $e^{\tan(x)}$. It was necessary for me to find the first four terms in order to establish which answer was correct. In the end of year exam, I will have reference to a Useful Information booklet (this contains a generalized Taylor polynomial approximation and Maclaurin series of $e^x$, $(1+x)^n$, $\sin(x)$, $\cos(x)$ and $\ln(1+x)$), and no calculator - hence throughout all of of my work, including online tests (which do contribute to my grade), I choose only to work with this resource, as preparation for this exam. As my approach for this problem, I used the generalized Taylor polynomial approximation to find the Maclaurin series for $\tan(x)$ and substituted this series in place of $x$ into the given Maclaurin series for $e^x$, and double-checked my answer once I had finished every other question by using the generalized Taylor polynomial approximation to find the Maclaurin series for $e^{\tan(x)}$. Obviously, as you can imagine, both of these methods were very time consuming (especially when you consider that the other nineteen questions in the test collectively took me less than ten minutes to answer). I'm probably missing a simple concept here. Can you please help me to establish a more elegant approach to this problem? The choices I was given were as follows:",,['calculus']
96,"If $f$ is continuous and $f(x+y)=f(x)f(y)$, then $\lim\limits_{x \rightarrow 0} \frac{f(x)-f(0)}{x}$ exists","If  is continuous and , then  exists",f f(x+y)=f(x)f(y) \lim\limits_{x \rightarrow 0} \frac{f(x)-f(0)}{x},"I'm solving the functional equation $f(x+y)=f(x)f(y)$ and I know that I have a continuous function $f:[0,\infty\rangle \to \langle 0,\infty\rangle$ s.t. $f(0)=1$. In one of the steps, I want to show that the limit $$\lim_{x \rightarrow 0} \frac{f(x)-1}{x}$$ exists and is finite? I'm just looking for a hint.","I'm solving the functional equation $f(x+y)=f(x)f(y)$ and I know that I have a continuous function $f:[0,\infty\rangle \to \langle 0,\infty\rangle$ s.t. $f(0)=1$. In one of the steps, I want to show that the limit $$\lim_{x \rightarrow 0} \frac{f(x)-1}{x}$$ exists and is finite? I'm just looking for a hint.",,"['calculus', 'limits', 'functional-equations']"
97,Cat Dog problem using integration,Cat Dog problem using integration,,"Consider this equation : $$\sqrt{\left( \frac{dy\cdot u\,dt}{L}\right)^2+(dy)^2}=v\,dt,$$ where $t$ varies from $0$ to $T$ , and $y$ varies from $0$ to $L$ .  Now how to proceed ? This equation arises out of following problem : A cat sitting in a field suddenly sees a standing dog. To save its life, the cat runs away in a straight line with speed $u$ . Without any delay, the dog starts with running with constant speed $v>u$ to catch the cat. Initially, $v$ is perpendicular to $u$ and $L$ is the initial separation between the two. If the dog always changes its direction so that it is always heading directly at the cat, find the time the dog takes to catch the cat in terms of $v, u$ and $L$ . See my solution below : Let initially dog be at $D$ and cat at $C$ and after time $dt$ they are at $D'$ and $C'$ respectively. Dog velocity is always pointing towards cat. Let $DA = dy, \;AD' = dx$ Let $CC'=udt,\;DD' = vdt$ as interval is very small so $DD'$ can be taken straight line. Also we have $\frac{DA}{DC}= \frac{AD'}{ CC'}$ using triangle property. $\frac{dy}{L}= \frac{dx}{udt}\\ dx = \frac{dy.udt}{L}$ $\sqrt{(dx)^2 + (dy)^2} = DD' = vdt \\ \sqrt{(\frac{dy.udt}{L})^2 + (dy)^2} = vdt $ Here $t$ varies from $0-T$ , and $y$ varies from $0-L$ . Now how to proceed?","Consider this equation : where varies from to , and varies from to .  Now how to proceed ? This equation arises out of following problem : A cat sitting in a field suddenly sees a standing dog. To save its life, the cat runs away in a straight line with speed . Without any delay, the dog starts with running with constant speed to catch the cat. Initially, is perpendicular to and is the initial separation between the two. If the dog always changes its direction so that it is always heading directly at the cat, find the time the dog takes to catch the cat in terms of and . See my solution below : Let initially dog be at and cat at and after time they are at and respectively. Dog velocity is always pointing towards cat. Let Let as interval is very small so can be taken straight line. Also we have using triangle property. Here varies from , and varies from . Now how to proceed?","\sqrt{\left( \frac{dy\cdot u\,dt}{L}\right)^2+(dy)^2}=v\,dt, t 0 T y 0 L u v>u v u L v, u L D C dt D' C' DA = dy, \;AD' = dx CC'=udt,\;DD' = vdt DD' \frac{DA}{DC}= \frac{AD'}{ CC'} \frac{dy}{L}= \frac{dx}{udt}\\ dx = \frac{dy.udt}{L} \sqrt{(dx)^2 + (dy)^2} = DD' = vdt \\ \sqrt{(\frac{dy.udt}{L})^2 + (dy)^2} = vdt  t 0-T y 0-L","['calculus', 'ordinary-differential-equations', 'integration', 'physics', 'mathematical-modeling']"
98,How to find the function $f$ given $f(f(x)) = 2x$?,How to find the function  given ?,f f(f(x)) = 2x,"I was wondered how to find the function in this equality: $f(f(x))=2x$.  Also $f$ is continuous. I don't need the answer, how to find it is more important.","I was wondered how to find the function in this equality: $f(f(x))=2x$.  Also $f$ is continuous. I don't need the answer, how to find it is more important.",,"['calculus', 'functional-equations']"
99,"Is there a different approach to evaluate $\int \ln(x)\,\mathrm{d}x?$",Is there a different approach to evaluate,"\int \ln(x)\,\mathrm{d}x?","The usual method of evaluating $\int \ln(x)\,\mathrm{d}x$ requires you to rewrite it as  $$ \int \ln(x) \cdot \color{brown}1\,\mathrm{d}x $$ and apply integration by parts. Letting $u=\ln(x)$ and $\mathrm{d}v=\color{brown}1 \,\mathrm{d}x$, we get that $\mathrm{d}u=\frac{1}{x} \,\mathrm{d}x$ and $v=\int \color{brown}1 \,\mathrm{d}x = x$, so our integral becomes \begin{align} \int \ln(x) \cdot \color{brown}1\,\mathrm{d}x &=uv-\int v\,\mathrm{d}u \\[0.5em] &=x\ln(x)-\int x\cdot\frac{1}{x}\,\mathrm{d}x \\[0.5em] &=x\ln(x)-\int \mathrm{d}x \\[0.5em] &=x\ln(x)-x+c \end{align} After looking through many calculus books, this is the only method I've found to integrate $\ln(x)$. Are there any other methods one could use to integrate the function $\ln(x)?$","The usual method of evaluating $\int \ln(x)\,\mathrm{d}x$ requires you to rewrite it as  $$ \int \ln(x) \cdot \color{brown}1\,\mathrm{d}x $$ and apply integration by parts. Letting $u=\ln(x)$ and $\mathrm{d}v=\color{brown}1 \,\mathrm{d}x$, we get that $\mathrm{d}u=\frac{1}{x} \,\mathrm{d}x$ and $v=\int \color{brown}1 \,\mathrm{d}x = x$, so our integral becomes \begin{align} \int \ln(x) \cdot \color{brown}1\,\mathrm{d}x &=uv-\int v\,\mathrm{d}u \\[0.5em] &=x\ln(x)-\int x\cdot\frac{1}{x}\,\mathrm{d}x \\[0.5em] &=x\ln(x)-\int \mathrm{d}x \\[0.5em] &=x\ln(x)-x+c \end{align} After looking through many calculus books, this is the only method I've found to integrate $\ln(x)$. Are there any other methods one could use to integrate the function $\ln(x)?$",,"['calculus', 'integration']"
