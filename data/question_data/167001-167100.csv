,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Bayesian inference,Bayesian inference,,"I'm a bit confused with arranging the Bayes equation to update probability. Say, I have the following data: $P(\text{blue birds in the whole study area}) = 0.16$; $P(\text{all except blue colored birds in the whole study area}) = 0.84$; $P(\text{birds in NW of the study area is blue}) = 0.22$; and  $P(\text{blue birds outside the NW part of the study area}) = 0.11$; Is that correct if I write: $P(\text{blue|NW}) = \frac{P(\text{blue}) \cdot P(\text{NW|blue})}{P(\text{blue}) \cdot P(\text{NW|blue}) + P(\neg \text{blue}) \cdot P(\text{blue|}\neg\text{NW})} = \frac{0.16 \cdot 0.22}{0.16 \cdot 0.22 + 0.84 \cdot 0.1}  = 0.28$? Therefore, the probability of finding a blue bird in the NW of the study site has increased from the prior estimate of $16%$ to $28%$. The confusing part is that we also know: $P(\text{birds in NW that are not blue}) = 0.78$ and if I use this information in the equation as $P(\neg\text{blue|NW})$, then the calculation stands as: $0.16*0.22/(0.16*0.22 + 0.84*0.78) = 0.054$ or $5.4\%$ only (though the probability of finding a blue bird in the NW is supposed to increase)?!? In sum, which one is correct to use: $P(\text{blue|}\neg\text{NW})$ or $P(\neg\text{blue|NW})$ in this particular case or the whole idea is wrong?? Thanks.","I'm a bit confused with arranging the Bayes equation to update probability. Say, I have the following data: $P(\text{blue birds in the whole study area}) = 0.16$; $P(\text{all except blue colored birds in the whole study area}) = 0.84$; $P(\text{birds in NW of the study area is blue}) = 0.22$; and  $P(\text{blue birds outside the NW part of the study area}) = 0.11$; Is that correct if I write: $P(\text{blue|NW}) = \frac{P(\text{blue}) \cdot P(\text{NW|blue})}{P(\text{blue}) \cdot P(\text{NW|blue}) + P(\neg \text{blue}) \cdot P(\text{blue|}\neg\text{NW})} = \frac{0.16 \cdot 0.22}{0.16 \cdot 0.22 + 0.84 \cdot 0.1}  = 0.28$? Therefore, the probability of finding a blue bird in the NW of the study site has increased from the prior estimate of $16%$ to $28%$. The confusing part is that we also know: $P(\text{birds in NW that are not blue}) = 0.78$ and if I use this information in the equation as $P(\neg\text{blue|NW})$, then the calculation stands as: $0.16*0.22/(0.16*0.22 + 0.84*0.78) = 0.054$ or $5.4\%$ only (though the probability of finding a blue bird in the NW is supposed to increase)?!? In sum, which one is correct to use: $P(\text{blue|}\neg\text{NW})$ or $P(\neg\text{blue|NW})$ in this particular case or the whole idea is wrong?? Thanks.",,"['statistics', 'bayesian']"
1,Pearson's Chi Squared / Cochran–Mantel–Haenszel test analog to N-way ANOVA,Pearson's Chi Squared / Cochran–Mantel–Haenszel test analog to N-way ANOVA,,"A test was given to two sets of students, CONTROL and EXPERIMENT, that had question A and question B.  I want to know if students who got question A right were more likely to get question B right, and I want to know if being in the CONTROL or EXPERIMENT groups made a difference in this relationship. I know I can't use ANOVA, because the data results are CORRECT or INCORRECT, not normally distributed data.  I thought maybe I could use Pearson's Chi-Squared test, but that only seems to deal with one factor at a time.  I looked at the Cochran–Mantel–Haenszel test (the example given here: http://udel.edu/~mcdonald/statcmh.html ) but I can't seem to figure out if I can make it fit my question. This has to be a common question.  I'm trying to help someone who conducted an experiment with this, but I have very limited stats experience.  Any help is appreciated.","A test was given to two sets of students, CONTROL and EXPERIMENT, that had question A and question B.  I want to know if students who got question A right were more likely to get question B right, and I want to know if being in the CONTROL or EXPERIMENT groups made a difference in this relationship. I know I can't use ANOVA, because the data results are CORRECT or INCORRECT, not normally distributed data.  I thought maybe I could use Pearson's Chi-Squared test, but that only seems to deal with one factor at a time.  I looked at the Cochran–Mantel–Haenszel test (the example given here: http://udel.edu/~mcdonald/statcmh.html ) but I can't seem to figure out if I can make it fit my question. This has to be a common question.  I'm trying to help someone who conducted an experiment with this, but I have very limited stats experience.  Any help is appreciated.",,['statistics']
2,Confusion on the meaning of confidence interval,Confusion on the meaning of confidence interval,,"The standard deviation of test scores on a certain achievement test is  10.9. A random sample of 60 scores on this test had a mean of  72.1. Based on this sample, find a 95% confidence interval for the true mean of all scores. The formula for confidence interval in this case is then we look up from the z table we get Confusion starts here : 95% confidence interval means there's 47.5% to the left 47.5% to the right if the sample mean is in the middle Suppose that our sample mean, 72.1, is below the actual mean of the population. We have the following graph, just by looking at the graph, you can tell there's more area under the curve to the right of 72.1 than there is area to the left How is it possible that the area to the left is 47.5% and area to the right is 47.5% ?? im confused.....How can we say that confidence interval is equal distant $\approx$ 2.758 (distance to the left and distance to the right) from the sample mean? the graph above is the sampling distribution of sample means","The standard deviation of test scores on a certain achievement test is  10.9. A random sample of 60 scores on this test had a mean of  72.1. Based on this sample, find a 95% confidence interval for the true mean of all scores. The formula for confidence interval in this case is then we look up from the z table we get Confusion starts here : 95% confidence interval means there's 47.5% to the left 47.5% to the right if the sample mean is in the middle Suppose that our sample mean, 72.1, is below the actual mean of the population. We have the following graph, just by looking at the graph, you can tell there's more area under the curve to the right of 72.1 than there is area to the left How is it possible that the area to the left is 47.5% and area to the right is 47.5% ?? im confused.....How can we say that confidence interval is equal distant 2.758 (distance to the left and distance to the right) from the sample mean? the graph above is the sampling distribution of sample means",\approx,['statistics']
3,"Working out the ""best"" score based on quantity and ratio","Working out the ""best"" score based on quantity and ratio",,"I'm not an expert with mathematics so I hope I'm posting in the right place! I've got a lot of products which can be rated good, bad and OK by a user. What I'm having trouble with is finding which is rated the ""best""- similar to Amazon's sort by rating. Getting the average rating won't work as I want a product with 99 good ratings and 1 bad rating to rank higher than a product with just 2 good ratings. Any ideas on what type of formula to use? - ANSWER, SORT OF: Thanks to Raskolnikov's comment I've found out what I need is either the Wilson Score Interval (which at the minute is way too complicated) or the Bayesian rating, which can be found here- http://www.thebroth.com/blog/118/bayesian-rating . Now I know at least what the formula I want is called, I can figure out how to get what I want.","I'm not an expert with mathematics so I hope I'm posting in the right place! I've got a lot of products which can be rated good, bad and OK by a user. What I'm having trouble with is finding which is rated the ""best""- similar to Amazon's sort by rating. Getting the average rating won't work as I want a product with 99 good ratings and 1 bad rating to rank higher than a product with just 2 good ratings. Any ideas on what type of formula to use? - ANSWER, SORT OF: Thanks to Raskolnikov's comment I've found out what I need is either the Wilson Score Interval (which at the minute is way too complicated) or the Bayesian rating, which can be found here- http://www.thebroth.com/blog/118/bayesian-rating . Now I know at least what the formula I want is called, I can figure out how to get what I want.",,"['statistics', 'algorithms', 'data-analysis']"
4,Approximation of sample mean distribution,Approximation of sample mean distribution,,"Suppose that we have an iid sample $X_1,\dots,X_n$ with a distribution function $F$.  Denote $\bar X_n:=\frac{1}{n}\sum_{i=1}^n X_i$ and $\bar X_n^*:=\frac{1}{n}\sum_{i=1}^n X_i^*,$ where $X_1^*,\dots,X_n^*$ are iid from the empirical distribution function $\hat F$ given the sample $X_1,\dots,X_n$. Does it then follow that  $$\sup_x|\mathbb P(\sqrt{n}\bar X_n \leq x) - \mathbb P(\sqrt{n}\bar X_n^* \leq x)| \rightarrow 0 \ \ \mathrm{a.s.}$$","Suppose that we have an iid sample $X_1,\dots,X_n$ with a distribution function $F$.  Denote $\bar X_n:=\frac{1}{n}\sum_{i=1}^n X_i$ and $\bar X_n^*:=\frac{1}{n}\sum_{i=1}^n X_i^*,$ where $X_1^*,\dots,X_n^*$ are iid from the empirical distribution function $\hat F$ given the sample $X_1,\dots,X_n$. Does it then follow that  $$\sup_x|\mathbb P(\sqrt{n}\bar X_n \leq x) - \mathbb P(\sqrt{n}\bar X_n^* \leq x)| \rightarrow 0 \ \ \mathrm{a.s.}$$",,['statistics']
5,Fourier (Hankel?) transform of a discrete set of radial points (question from a chemist!),Fourier (Hankel?) transform of a discrete set of radial points (question from a chemist!),,"I'm sorry because I'm not a mathematician so that my question may look a little bit messy. I have tabulated values [1] of a 3 dimensional radial function $f(r)$:   $f(x_1,x_2,x_3)=f(\sqrt{x_1^2+x_2^2+x_3^2})=f(r)$ I'd like to Fourier transform it in order to get $f(k)$ (or when having $f(k)$ transforming it to $f(r)$. I have looked around and understood this is a Hankel transform of order? (2 or 3, did not get it). And I did not find a practical way of doing this transformation. I have access to web, fortran and mathematica 7. Could you please, please, please help me? [1] To be more practical: I have a picture where is plotted the static structure factor $S(k)$ of a inhomogeneous fluid as obtained by neutron diffraction. I can extract points $(k:S(k))$ from this picture. $S(k)$ is related to the direct correlation function $C(k)$ as defined by Ornstein-Zernike through $S(k)=(1-nC(k))^{-1}$ where $n$ is a constant. I'd like to plot $C(r)$.","I'm sorry because I'm not a mathematician so that my question may look a little bit messy. I have tabulated values [1] of a 3 dimensional radial function $f(r)$:   $f(x_1,x_2,x_3)=f(\sqrt{x_1^2+x_2^2+x_3^2})=f(r)$ I'd like to Fourier transform it in order to get $f(k)$ (or when having $f(k)$ transforming it to $f(r)$. I have looked around and understood this is a Hankel transform of order? (2 or 3, did not get it). And I did not find a practical way of doing this transformation. I have access to web, fortran and mathematica 7. Could you please, please, please help me? [1] To be more practical: I have a picture where is plotted the static structure factor $S(k)$ of a inhomogeneous fluid as obtained by neutron diffraction. I can extract points $(k:S(k))$ from this picture. $S(k)$ is related to the direct correlation function $C(k)$ as defined by Ornstein-Zernike through $S(k)=(1-nC(k))^{-1}$ where $n$ is a constant. I'd like to plot $C(r)$.",,"['statistics', 'fourier-analysis', 'numerical-methods', 'physics', 'chemistry']"
6,How to generate and use random trees?,How to generate and use random trees?,,"I have the assignment to implement a random tree classifier in MATLAB. The lecture says: Input: observations and lables While stopping criterion not reached: 1. Node optimization: - several split candidates are randomly generated    - the best splitting function is chosen according to some quality measure 2. Data splitting: observations are pushed to the left or right branch. 3. Move to next node  Stopping criteria:        Quality measure - Number of data points in the current node/leaf My problem now is I do not understand how to get the randomly generated split candidates?  Get them from the input values? But then I would get a decision tree  (pick a random element and say >x right node, < x left node.) Also I do not understand what the difference between the random tree and the decision tree is in the end. Also the lecture says: Choosing the best candidates: according to a quality measures Out-of-bag error (OOB)  -  Minimize error rate after splitting using a test set Information gain  -  Maximize information gain after splitting But what test set should I use? The test set already in the tree used for training? Wikipedia and Google did not help me either. The code of the MATLAB stub can be found here: http://pastebin.com/iuzqF8gG I appreciate your help.","I have the assignment to implement a random tree classifier in MATLAB. The lecture says: Input: observations and lables While stopping criterion not reached: 1. Node optimization: - several split candidates are randomly generated    - the best splitting function is chosen according to some quality measure 2. Data splitting: observations are pushed to the left or right branch. 3. Move to next node  Stopping criteria:        Quality measure - Number of data points in the current node/leaf My problem now is I do not understand how to get the randomly generated split candidates?  Get them from the input values? But then I would get a decision tree  (pick a random element and say >x right node, < x left node.) Also I do not understand what the difference between the random tree and the decision tree is in the end. Also the lecture says: Choosing the best candidates: according to a quality measures Out-of-bag error (OOB)  -  Minimize error rate after splitting using a test set Information gain  -  Maximize information gain after splitting But what test set should I use? The test set already in the tree used for training? Wikipedia and Google did not help me either. The code of the MATLAB stub can be found here: http://pastebin.com/iuzqF8gG I appreciate your help.",,"['statistics', 'matlab', 'machine-learning']"
7,Who invented linearization of exponential datasets to find their approximating functions?,Who invented linearization of exponential datasets to find their approximating functions?,,"I just learned how to find the exponential function that approximates a dataset by taking the logarithm of the data points, doing a linear regression on that data, then working out the exponential equation from that. This is very clever. Who invented this technique?","I just learned how to find the exponential function that approximates a dataset by taking the logarithm of the data points, doing a linear regression on that data, then working out the exponential equation from that. This is very clever. Who invented this technique?",,"['statistics', 'math-history', 'regression']"
8,When to use Poisson distribution?,When to use Poisson distribution?,,"I'm still very confused regarding when to use probability distributions. For instance, this is the assumptions to use Poisson distribution, according to Wikipedia: k is the number of times an event occurs in an interval and k can take values 0, 1, 2, ... The occurrence of one event does not affect the probability that a second event will occur. That is, events occur independently. The average rate at which events occur is independent of any occurrences. For simplicity, this is usually assumed to be constant, but may in practice vary with time. Two events cannot occur at exactly the same instant; instead, at each very small sub-interval, either exactly one event occurs, or no event occurs. Does that mean that I can assume that any event that follow this assumptions follow a Poisson distribution? If that is the case, why do so many books have exercises mentioning ""assume that ... follow a Poisson distribution""? Isn't that unnecessary? For instance: Let's say I work in a call-centre and I observe that I have 2 calls in the first hour, 3 in the second, 10 in the fourth, 5 in the fifith... I want to know the probability of getting 5 calls in a period of 10 hours. Can I use Poisson?","I'm still very confused regarding when to use probability distributions. For instance, this is the assumptions to use Poisson distribution, according to Wikipedia: k is the number of times an event occurs in an interval and k can take values 0, 1, 2, ... The occurrence of one event does not affect the probability that a second event will occur. That is, events occur independently. The average rate at which events occur is independent of any occurrences. For simplicity, this is usually assumed to be constant, but may in practice vary with time. Two events cannot occur at exactly the same instant; instead, at each very small sub-interval, either exactly one event occurs, or no event occurs. Does that mean that I can assume that any event that follow this assumptions follow a Poisson distribution? If that is the case, why do so many books have exercises mentioning ""assume that ... follow a Poisson distribution""? Isn't that unnecessary? For instance: Let's say I work in a call-centre and I observe that I have 2 calls in the first hour, 3 in the second, 10 in the fourth, 5 in the fifith... I want to know the probability of getting 5 calls in a period of 10 hours. Can I use Poisson?",,"['statistics', 'poisson-distribution']"
9,Understanding nearest neighbors in high-dimensional data,Understanding nearest neighbors in high-dimensional data,,"Let's have a random sample of points in an euclidean $n$ -space: assume a iid sample from a standard normal distribution. To each point $p$ , I assign the number $N(p)$ defined as ""how many times does $p$ occur in $10$ nearest neighbors of some other point""? I would like to understand the distribution of $N(p)$ and how it depends on dimension. Some experimental results from python are quite surprising to me. In low dimensions, for $n=2,3,4$ this distribution is close to normal, while in higher dimensions it's very skewed, with most point being no nearest neighbours to anything else, and a few points being nearest neighbours to a lot of other points. I always generate 1000 exampels here (not that it matters), here are some histograms: I have some intuition / idea that the relation with dimension may boil down to something like this: in dim $1$ , a point can be nearest neighbor of at most 2 points, one on the left and one on the right in dim $2$ , a point can be nearest neighbor of 5 or 6 points, forming a regualr hexagon around it and so on. I also checked if those points that are NN of many other points are more like in cluster center -- which is intuitively expected. The answer is yes, here is an example in dimension 32: However, I'm not sure why is the dependency on dimension so crucial? The motivation comes from searching for nearest neighbours where the data represent some real objects, and nearest neighbours represent search of a user. Should I use rather smaller dimension, if I want to support the idea that each element should get a chance of being found? Thanks for any insight. (Related: https://ai.stackexchange.com/questions/40525/nearest-neighbour-search-in-high-dimension-retrieves-certain-points-too-often )","Let's have a random sample of points in an euclidean -space: assume a iid sample from a standard normal distribution. To each point , I assign the number defined as ""how many times does occur in nearest neighbors of some other point""? I would like to understand the distribution of and how it depends on dimension. Some experimental results from python are quite surprising to me. In low dimensions, for this distribution is close to normal, while in higher dimensions it's very skewed, with most point being no nearest neighbours to anything else, and a few points being nearest neighbours to a lot of other points. I always generate 1000 exampels here (not that it matters), here are some histograms: I have some intuition / idea that the relation with dimension may boil down to something like this: in dim , a point can be nearest neighbor of at most 2 points, one on the left and one on the right in dim , a point can be nearest neighbor of 5 or 6 points, forming a regualr hexagon around it and so on. I also checked if those points that are NN of many other points are more like in cluster center -- which is intuitively expected. The answer is yes, here is an example in dimension 32: However, I'm not sure why is the dependency on dimension so crucial? The motivation comes from searching for nearest neighbours where the data represent some real objects, and nearest neighbours represent search of a user. Should I use rather smaller dimension, if I want to support the idea that each element should get a chance of being found? Thanks for any insight. (Related: https://ai.stackexchange.com/questions/40525/nearest-neighbour-search-in-high-dimension-retrieves-certain-points-too-often )","n p N(p) p 10 N(p) n=2,3,4 1 2","['statistics', 'data-structure', 'topological-data-analysis']"
10,How to calculate the R square if not given the number of points,How to calculate the R square if not given the number of points,,"This is an interview problem I encountered and I have no idea about how to deal with it. Hope to get any hint or help for the first step. Suppose there is a unit circle centered at origin, we randomly sample N points on it. There is also another point (K, K), where K >> 1. Now we do a linear regression to these N+1 points, please calculate the $R^2$","This is an interview problem I encountered and I have no idea about how to deal with it. Hope to get any hint or help for the first step. Suppose there is a unit circle centered at origin, we randomly sample N points on it. There is also another point (K, K), where K >> 1. Now we do a linear regression to these N+1 points, please calculate the",R^2,"['statistics', 'linear-regression']"
11,MVUE problem related to splitting joint variables into independent ones.,MVUE problem related to splitting joint variables into independent ones.,,"Hi please help me with this problem. With the random samples $X_1,\dots,X_n$ from $\operatorname{Exp}(\mu, \sigma)$ , I need to attain the MVUE of $\eta = \mathbb{P}(X_1>a)$ . I used the Lehmann-Scheffe and Basu theorem to get close to my goal. However, I can't attain the distribution of ancillary statistic. My solution so far is as below. We have CSS of $(\mu, \sigma)$ , $T = (X_{(1)}, \sum^n_{i=1}(X_i - X_{(1)})$ and since $\eta = \mathbb{E}_\theta\mathbb{I}(X_1>a)$ } by Lehmann-Scheffe, $$\eta^{MVUE} = \mathbb{P}(X_1>a|X_{(1)}=x, S=s) \text{ where  $S=\sum^n_{i=1}(X_i - X_{(1)})$}\\ =\mathbb{P}\Big(\frac{X_1-X_{(1)}}{S}>\frac{a-x}{s}\Big)\qquad (\because \text{Basu})\\ =\begin{cases} 1 \ (a < x) \\ \mathbb{P}(\frac{X_1-X_{(1)}}{S}>\frac{a-x}{s}) \ (a\geq x) \end{cases}\\ =\begin{cases} 1 \ (a < x) \\ \mathbb{P}(\frac{X_1-X_{(1)}}{S}>\frac{a-x}{s}, X_1 > X_{(1)}) \ (a\geq x) \end{cases}\\ $$ Let us consider the distribution of the ancillary statistic from now. WLOG take $\mu=0, \sigma=1$ , and since $X_1 > X_{(1)}$ , $X_{(1)} = \min_{2\leq i \leq n}X_i = \min_{1\leq i \leq m}Z_i$ ,  where $Z_1,\dots,Z_m \sim \text{i.i.d. } \operatorname{Exp}(1)$ . Observe that $X_1, Z_{(1)}, \sum^m_{i=1}(Z_i-Z_{(i)})$ are independent by exponential spacing. Then we have $$ \frac{X_1-X_{(1)}}{S}=\frac{X_1 - Z_{(1)}}{X_1 - Z_{(1)} + \sum^m_{i=1}(Z_i-Z_{(1)})} $$ As you can see by implementing this new $Z$ variable, the joint distribution we had which was dependent is now jointly independent. With the transformation of variables we also have $$ \operatorname{pdf}_{X_1-Z_{(1)}}(y) = \frac{m}{m+1}e^{-y}\mathbb{I}(y>0),\sum^m_{i=1}(Z_i-Z_{(1)}) \sim \Gamma(m-1,1) $$ My gut is telling me that this is Beta Distribution. However, I can't figure out its parameters. Can anyone help me through this? Also, if anyone can think of some easier way please let me know. @StubbornAtoms answered the same question but I want to attain the ""specific"" beta distribution. But his solution explains why I split the variable of $X$ 's into $X$ 's and $Z$ 's.","Hi please help me with this problem. With the random samples from , I need to attain the MVUE of . I used the Lehmann-Scheffe and Basu theorem to get close to my goal. However, I can't attain the distribution of ancillary statistic. My solution so far is as below. We have CSS of , and since } by Lehmann-Scheffe, Let us consider the distribution of the ancillary statistic from now. WLOG take , and since , ,  where . Observe that are independent by exponential spacing. Then we have As you can see by implementing this new variable, the joint distribution we had which was dependent is now jointly independent. With the transformation of variables we also have My gut is telling me that this is Beta Distribution. However, I can't figure out its parameters. Can anyone help me through this? Also, if anyone can think of some easier way please let me know. @StubbornAtoms answered the same question but I want to attain the ""specific"" beta distribution. But his solution explains why I split the variable of 's into 's and 's.","X_1,\dots,X_n \operatorname{Exp}(\mu, \sigma) \eta = \mathbb{P}(X_1>a) (\mu, \sigma) T = (X_{(1)}, \sum^n_{i=1}(X_i - X_{(1)}) \eta = \mathbb{E}_\theta\mathbb{I}(X_1>a) \eta^{MVUE} = \mathbb{P}(X_1>a|X_{(1)}=x, S=s) \text{ where 
S=\sum^n_{i=1}(X_i - X_{(1)})}\\
=\mathbb{P}\Big(\frac{X_1-X_{(1)}}{S}>\frac{a-x}{s}\Big)\qquad (\because \text{Basu})\\
=\begin{cases}
1 \ (a < x) \\
\mathbb{P}(\frac{X_1-X_{(1)}}{S}>\frac{a-x}{s}) \ (a\geq x)
\end{cases}\\
=\begin{cases}
1 \ (a < x) \\
\mathbb{P}(\frac{X_1-X_{(1)}}{S}>\frac{a-x}{s}, X_1 > X_{(1)}) \ (a\geq x)
\end{cases}\\
 \mu=0, \sigma=1 X_1 > X_{(1)} X_{(1)} = \min_{2\leq i \leq n}X_i = \min_{1\leq i \leq m}Z_i Z_1,\dots,Z_m \sim \text{i.i.d. } \operatorname{Exp}(1) X_1, Z_{(1)}, \sum^m_{i=1}(Z_i-Z_{(i)}) 
\frac{X_1-X_{(1)}}{S}=\frac{X_1 - Z_{(1)}}{X_1 - Z_{(1)} + \sum^m_{i=1}(Z_i-Z_{(1)})}
 Z 
\operatorname{pdf}_{X_1-Z_{(1)}}(y) = \frac{m}{m+1}e^{-y}\mathbb{I}(y>0),\sum^m_{i=1}(Z_i-Z_{(1)}) \sim \Gamma(m-1,1)
 X X Z","['statistics', 'probability-distributions', 'statistical-inference', 'exponential-distribution', 'order-statistics']"
12,Multiclass Linear Discriminant Analysis,Multiclass Linear Discriminant Analysis,,"This question is based on the Multiclass Linear Discriminant Analysis (MLDA) describe in Lectures slides by Olga Veksler , which is a generalization of Fisher's Linear Discriminant. My use in MLDA is to reduce dimensionality and transform multi-dimensional data into ""well separated"" clusters in lower dimensions. Short review of the theory and mathematical formalism: Suppose we have $N$ samples in $C$ classes or clusters. Each have $N_c$ samples which are $d$ -dimensional, that is $x^{(c)}_{i} \in \mathbb{R}^d$ for $c = 1,...,C$ and $i = 1,...,N_c$ . Each class $\omega_c$ have mean and covariance: $$ \mu_c = \frac{1}{N_c} \sum_{x_i \in \omega_c} x_i, \qquad S_c = \frac{1}{N_c}\sum_{x_i \in \omega_c} (x_i - \mu_c) (x_i - \mu_c)^T $$ The ""average"" scatter within classes is defined as $$ S_w = \sum_{c=1}^C S_c \in \mathbb{R}^{d \times d} $$ and the scatter between classes is defines as $$ S_b = \sum_{c=1}^{C} N_c (\mu_c - \mu)(\mu_c - \mu)^T \in \mathbb{R}^{d \times d} $$ where $\mu = (1/N)\sum_{j=1}^n x_j$ is the mean over all the samples. In order to find the best separating dimensionality reduction, given by projection $y = W^T x$ , we want to maximize the following objective function: $$ J(W) = \frac{\det(W^T S_b W)}{\det(W^T S_w W)} $$ The idea is to maximize the scatter between while minimizing the scatter within each class. Differentiating the objective function with respect to $W$ one gets the following generalized eigenvalue problem: $$ S_b W_c = J(W_c) S_w W_c = \lambda S_w W_c $$ where $J(W_c) \in \mathbb{R}$ is a scalar eigenvalue. From matrix rank consideration one can show that there are at most $C-1$ non-zero eigenvectors. The projection weights are the $C-1$ eigenvectors corresponding to the $C-1$ largest eigenvalues. We stack the eigenvectors in a matrix and get the weight matrix $$ W = \left[ W_1 | ... | W_{C-1} \right] \in \mathbb{R}^{d \times (C-1)} $$ Then the projection is $y = W^T x$ (verify dimensions: $(C-1) \times 1 = ((C-1) \times d) \cdot (d \times 1)$ ). This projection is called LDA or MDA. The new means after LDA are given by $\tilde{\mu}_c = W^T \mu_c$ and the covariances after LDA are given by $$ \tilde{S}_c = W^T S_c W \in \mathbb{R}^{(C-1) \times (C-1)} $$ Here I have few questions: Is the after-LDA covariance matrix of each class, $\tilde{S}_c$ is diagonal? The $W^T S_c W$ is sort of a whitening transformation and if $W^T = W^{-1}$ it is diagonalization. How to solve the generalized eigenvalues problem $S_b v = \lambda S_w v$ ? If I tried different algorithms in Python such as SciPy's eig or eigh functions with D, V = eig(S_b, S_w) , or inverting $S_w$ and then solve $S_r v = S_w^{-1} S_b v = \lambda v$ and D, V = eigh(S_r) , or trying SVD: V, D, Vh = svd(S_r) I get different eigenvalues and eigenvactors. How to use SVD to solve the generalized eigenvalues problem? If I use sklearn LDA class I also get different results, but the algorithm therein is more complicated and include shrinkage covariance estimator, and priors terms. The best results were obtained with from scipy.linalg import pinv, eig, eigh  # Solving for eigenvectors by inverting cov_within inv_cov_within = pinv(cov_within) D, V = eigh(inv_cov_within @ cov_between)      # Sort according to eigenvalues in descending order idx = np.argsort(np.real(D))[::-1] D = D[idx] W = V[:, idx]  # The weights are (n_features, n_classes-1) weights = W[:, 0:n_classes-1] I used pinv because the scatter within may not be invertible (e.g. when $d >> N$ , more dimensions than samples), so I use pseudo-inverse. Using SVD may also solve this issue (how?). Hypothesis for 1: The class covariances are diagonal only if $\forall c : S_c = S$ , i.e. all the classes have the same covariance matrix. References: Lectures slides by Olga Veksker https://www.analyticsvidhya.com/ Intelligent Data Analysis and Probabilistic Inference Lecture 15 Optimal $\mathbf{W}$'s columns are the generalized eigenvectors in $\mathbf{S}_\text{B}\mathbf{v}_i = \lambda_i \mathbf{S}_\text{W} \mathbf{v}_i$","This question is based on the Multiclass Linear Discriminant Analysis (MLDA) describe in Lectures slides by Olga Veksler , which is a generalization of Fisher's Linear Discriminant. My use in MLDA is to reduce dimensionality and transform multi-dimensional data into ""well separated"" clusters in lower dimensions. Short review of the theory and mathematical formalism: Suppose we have samples in classes or clusters. Each have samples which are -dimensional, that is for and . Each class have mean and covariance: The ""average"" scatter within classes is defined as and the scatter between classes is defines as where is the mean over all the samples. In order to find the best separating dimensionality reduction, given by projection , we want to maximize the following objective function: The idea is to maximize the scatter between while minimizing the scatter within each class. Differentiating the objective function with respect to one gets the following generalized eigenvalue problem: where is a scalar eigenvalue. From matrix rank consideration one can show that there are at most non-zero eigenvectors. The projection weights are the eigenvectors corresponding to the largest eigenvalues. We stack the eigenvectors in a matrix and get the weight matrix Then the projection is (verify dimensions: ). This projection is called LDA or MDA. The new means after LDA are given by and the covariances after LDA are given by Here I have few questions: Is the after-LDA covariance matrix of each class, is diagonal? The is sort of a whitening transformation and if it is diagonalization. How to solve the generalized eigenvalues problem ? If I tried different algorithms in Python such as SciPy's eig or eigh functions with D, V = eig(S_b, S_w) , or inverting and then solve and D, V = eigh(S_r) , or trying SVD: V, D, Vh = svd(S_r) I get different eigenvalues and eigenvactors. How to use SVD to solve the generalized eigenvalues problem? If I use sklearn LDA class I also get different results, but the algorithm therein is more complicated and include shrinkage covariance estimator, and priors terms. The best results were obtained with from scipy.linalg import pinv, eig, eigh  # Solving for eigenvectors by inverting cov_within inv_cov_within = pinv(cov_within) D, V = eigh(inv_cov_within @ cov_between)      # Sort according to eigenvalues in descending order idx = np.argsort(np.real(D))[::-1] D = D[idx] W = V[:, idx]  # The weights are (n_features, n_classes-1) weights = W[:, 0:n_classes-1] I used pinv because the scatter within may not be invertible (e.g. when , more dimensions than samples), so I use pseudo-inverse. Using SVD may also solve this issue (how?). Hypothesis for 1: The class covariances are diagonal only if , i.e. all the classes have the same covariance matrix. References: Lectures slides by Olga Veksker https://www.analyticsvidhya.com/ Intelligent Data Analysis and Probabilistic Inference Lecture 15 Optimal $\mathbf{W}$'s columns are the generalized eigenvectors in $\mathbf{S}_\text{B}\mathbf{v}_i = \lambda_i \mathbf{S}_\text{W} \mathbf{v}_i$","N C N_c d x^{(c)}_{i} \in \mathbb{R}^d c = 1,...,C i = 1,...,N_c \omega_c 
\mu_c = \frac{1}{N_c} \sum_{x_i \in \omega_c} x_i, \qquad S_c = \frac{1}{N_c}\sum_{x_i \in \omega_c} (x_i - \mu_c) (x_i - \mu_c)^T
 
S_w = \sum_{c=1}^C S_c \in \mathbb{R}^{d \times d}
 
S_b = \sum_{c=1}^{C} N_c (\mu_c - \mu)(\mu_c - \mu)^T \in \mathbb{R}^{d \times d}
 \mu = (1/N)\sum_{j=1}^n x_j y = W^T x 
J(W) = \frac{\det(W^T S_b W)}{\det(W^T S_w W)}
 W 
S_b W_c = J(W_c) S_w W_c = \lambda S_w W_c
 J(W_c) \in \mathbb{R} C-1 C-1 C-1 
W = \left[ W_1 | ... | W_{C-1} \right] \in \mathbb{R}^{d \times (C-1)}
 y = W^T x (C-1) \times 1 = ((C-1) \times d) \cdot (d \times 1) \tilde{\mu}_c = W^T \mu_c 
\tilde{S}_c = W^T S_c W \in \mathbb{R}^{(C-1) \times (C-1)}
 \tilde{S}_c W^T S_c W W^T = W^{-1} S_b v = \lambda S_w v S_w S_r v = S_w^{-1} S_b v = \lambda v d >> N \forall c : S_c = S","['linear-algebra', 'statistics', 'eigenvalues-eigenvectors', 'machine-learning', 'python']"
13,Find the 0.95 quantile such that $P(Y \le \phi_{.95})=0.95$,Find the 0.95 quantile such that,P(Y \le \phi_{.95})=0.95,"Suppose I have the density function $f(y) = 6y(1-y), 0 \le y \le 1$ , find the 0.95 quantile such that $P(Y \le \phi_{.95})=0.95.$ What I have tried: $$6\int_0^{\phi_{.95}}y(1-y)dy=6\left[\frac{y^2}{2}-\frac{y^3}{3} \right]_0^{\phi_{.95}}=0.95$$ $$\implies6\left[\frac{(\phi_{.95})^2}{2}-\frac{(\phi_{.95})^3}{3} \right]=0.95$$ Now I'm not sure on how to proceed from here, the booklet answer shows $\phi_{0.95} = 0.865$ , I had thought that I would have to re-arrange the integral result to find for $\phi$ though I cannot seem to isolate it. Using the Newton approximation method as suggested $$f(x_0)=f(x_0)-\frac{f(x_0)}{f'(x_0)}$$ When picking $f(x_0) = 0.95$ After I re-arranged the equation above into a cubic I get $$\implies f(x_0) = 0.95-\frac{2(0.95)^3-3(0.95)^2+0.95}{6(0.95)^3-6(0.95)^2}\approx 0.8$$ $$\implies f(x_1) = 0.8-\frac{2(0.8)^3-3(0.8)^2+0.95}{6(0.8)^3-6(0.8)^2}\approx 0.865$$","Suppose I have the density function , find the 0.95 quantile such that What I have tried: Now I'm not sure on how to proceed from here, the booklet answer shows , I had thought that I would have to re-arrange the integral result to find for though I cannot seem to isolate it. Using the Newton approximation method as suggested When picking After I re-arranged the equation above into a cubic I get","f(y) = 6y(1-y), 0 \le y \le 1 P(Y \le \phi_{.95})=0.95. 6\int_0^{\phi_{.95}}y(1-y)dy=6\left[\frac{y^2}{2}-\frac{y^3}{3} \right]_0^{\phi_{.95}}=0.95 \implies6\left[\frac{(\phi_{.95})^2}{2}-\frac{(\phi_{.95})^3}{3} \right]=0.95 \phi_{0.95} = 0.865 \phi f(x_0)=f(x_0)-\frac{f(x_0)}{f'(x_0)} f(x_0) = 0.95 \implies f(x_0) = 0.95-\frac{2(0.95)^3-3(0.95)^2+0.95}{6(0.95)^3-6(0.95)^2}\approx 0.8 \implies f(x_1) = 0.8-\frac{2(0.8)^3-3(0.8)^2+0.95}{6(0.8)^3-6(0.8)^2}\approx 0.865","['integration', 'statistics']"
14,Spherical trigonometry and statistics in higher dimensions,Spherical trigonometry and statistics in higher dimensions,,"Until recently I never properly fully assimilated the spherical laws of sines and cosines into my understanding, and thinking about those, I see some parallels with some things in statistics. Segments from the center of a sphere of unit radius to the three vertices of a triangle on the sphere meet at angles $\alpha,\beta,\gamma.$ The sides of the triangle are arcs of great circles and the two arcs at the vertex that is the endpoint of that one of the aforementioned segments that does not meet either of the others at angle $\alpha$ meet at angle $\mathbb A,$ and as $\alpha$ is related to $\mathbb A$ , so also are $\beta,\gamma$ to $\mathbb B,\mathbb C$ respectively. The spherical law of cosines then says $$ \cos\beta = \cos\alpha\cos\gamma+\sin\alpha\sin\gamma\cos\mathbb B. \tag 1 $$ Now consider vectors $x=(x_1,\ldots,x_n), y=(y_1,\ldots,y_n)\in\mathbb R^n.$ Let $\overline x=(x_1+\cdots+x_n)/n$ and similarly define $\overline y.$ Let $s_x^2=\big((x_1-\overline x)^2 + \cdots + (x_n-\overline x)^2\big)/n,\, s_x>0$ and similarly define $s_y^2.$ (Sometimes you see $n-1$ rather than $n$ in the denominator, but that won't change anything that concerns us here. It is often remarked that the correlation $\displaystyle \frac{\sum_{i=1}^n (x_i-\overline x)(y_i-\overline y) }{s_xs_y} $ is the cosine of the angle between the two unit vectors $\left( \frac{x_i-\overline x}{s_x} : i=1,\ldots,n \right)$ and $\left( \frac{y_i-\overline y}{s_y} : i=1,\ldots,n \right),$ known as the standardizations of $x$ and $y.$ Now consider a third vector $z=(z_1,\ldots,z_n)$ with $\overline z$ and $s_z$ defined similarly. Let $\alpha$ be the angle between the standardizations of $x$ and $y$ and similarly $\beta$ between $y$ and $z$ and $\gamma$ between $z$ and $x.$ And let $\mathbb C$ correspond to $\gamma$ as above. I leave it as an exercise to see that $\mathbb C$ is a certain dihedral angle and $\cos^2\mathbb C$ is the quantity that statisticians know as the coefficient of determination , which is the proportion of the variability in $z$ that is ""explained"" by the variability of $x$ and $y$ when $z$ is regressed on $x$ and $y,$ the ""unexplained"" part being the sum of squares of residuals that is minimized when regression is done be the method of ordinary least squares. A coordinate system in the $3$ -dimensional space spanned by the standardizations of $x,y,z$ may be chosen so that the standardization of $x$ becomes $\left[ \begin{array}{c} 1 \\ 0 \\ 0 \end{array} \right],$ and that of $y$ is $\left[ \begin{array}{c} \cos\alpha \\ \sin\alpha \\ 0 \end{array} \right],$ and that of $z$ is $\left[ \begin{array}{c} \cos\gamma \\ \sin\gamma\cos\mathbb B \\ \sin\gamma\sin\mathbb B \end{array} \right].$ Then the ordinary dot product between those last two vectors gives is the law of cosines of line $(1)$ above. But coefficients of determination are not used only in regressing one variable on exactly two others; they are used when one regresses one variable on $p$ others, and then they are the square of the cosine of the angle between a line corresponding to the response variable and a $p$ -dimensional space corresponding to the predictors. So can the relationship between spherical trigonometry and statistics be fruitfully extended to higher dimensions? Appendix: The total sum of squares is $\sum_{i=1}^n (z_i-\overline z)^2.$ The fitted values are $\widehat z_i = \widehat a + \widehat b x_i + \widehat c y_i$ where $\widehat a,\widehat b, \widehat c$ are the least-squares estimates. The residuals are $z_i - \widehat z_i.$ The unexplained sum of squares is the sum of squares of residuals when fitting is done by least squares: $\sum_{i=1}^n (z_i - \widehat z_i)^2$ The explained sum of squares is $\sum_{i=1}^n (\widehat z_i - \overline z)^2.$ The coefficient of determination is the proportion of variability in $z$ that is explained by $x$ and $y,$ i.e. it is $$ \frac{\text{explained sum of squares}}{\text{total sum of squares}}. $$ Exercise: The total sum of squares is the sum of the explained and unexplained sums of squares. (This can be reduced to showing that the vectors of residuals and of fitted values are mutually orthogonal.) $$ \sum_{i=1}^n (z_i-\overline z)^2 = \sum_{i=1}^n (\widehat z_i - \overline z)^2 + \sum_{i=1}^n (z_i - \widehat z_i)^2 $$","Until recently I never properly fully assimilated the spherical laws of sines and cosines into my understanding, and thinking about those, I see some parallels with some things in statistics. Segments from the center of a sphere of unit radius to the three vertices of a triangle on the sphere meet at angles The sides of the triangle are arcs of great circles and the two arcs at the vertex that is the endpoint of that one of the aforementioned segments that does not meet either of the others at angle meet at angle and as is related to , so also are to respectively. The spherical law of cosines then says Now consider vectors Let and similarly define Let and similarly define (Sometimes you see rather than in the denominator, but that won't change anything that concerns us here. It is often remarked that the correlation is the cosine of the angle between the two unit vectors and known as the standardizations of and Now consider a third vector with and defined similarly. Let be the angle between the standardizations of and and similarly between and and between and And let correspond to as above. I leave it as an exercise to see that is a certain dihedral angle and is the quantity that statisticians know as the coefficient of determination , which is the proportion of the variability in that is ""explained"" by the variability of and when is regressed on and the ""unexplained"" part being the sum of squares of residuals that is minimized when regression is done be the method of ordinary least squares. A coordinate system in the -dimensional space spanned by the standardizations of may be chosen so that the standardization of becomes and that of is and that of is Then the ordinary dot product between those last two vectors gives is the law of cosines of line above. But coefficients of determination are not used only in regressing one variable on exactly two others; they are used when one regresses one variable on others, and then they are the square of the cosine of the angle between a line corresponding to the response variable and a -dimensional space corresponding to the predictors. So can the relationship between spherical trigonometry and statistics be fruitfully extended to higher dimensions? Appendix: The total sum of squares is The fitted values are where are the least-squares estimates. The residuals are The unexplained sum of squares is the sum of squares of residuals when fitting is done by least squares: The explained sum of squares is The coefficient of determination is the proportion of variability in that is explained by and i.e. it is Exercise: The total sum of squares is the sum of the explained and unexplained sums of squares. (This can be reduced to showing that the vectors of residuals and of fitted values are mutually orthogonal.)","\alpha,\beta,\gamma. \alpha \mathbb A, \alpha \mathbb A \beta,\gamma \mathbb B,\mathbb C 
\cos\beta = \cos\alpha\cos\gamma+\sin\alpha\sin\gamma\cos\mathbb B. \tag 1
 x=(x_1,\ldots,x_n), y=(y_1,\ldots,y_n)\in\mathbb R^n. \overline x=(x_1+\cdots+x_n)/n \overline y. s_x^2=\big((x_1-\overline x)^2 + \cdots + (x_n-\overline x)^2\big)/n,\, s_x>0 s_y^2. n-1 n \displaystyle \frac{\sum_{i=1}^n (x_i-\overline x)(y_i-\overline y) }{s_xs_y}  \left( \frac{x_i-\overline x}{s_x} : i=1,\ldots,n \right) \left( \frac{y_i-\overline y}{s_y} : i=1,\ldots,n \right), x y. z=(z_1,\ldots,z_n) \overline z s_z \alpha x y \beta y z \gamma z x. \mathbb C \gamma \mathbb C \cos^2\mathbb C z x y z x y, 3 x,y,z x \left[ \begin{array}{c} 1 \\ 0 \\ 0 \end{array} \right], y \left[ \begin{array}{c} \cos\alpha \\ \sin\alpha \\ 0 \end{array} \right], z \left[ \begin{array}{c} \cos\gamma \\ \sin\gamma\cos\mathbb B \\ \sin\gamma\sin\mathbb B \end{array} \right]. (1) p p \sum_{i=1}^n (z_i-\overline z)^2. \widehat z_i = \widehat a + \widehat b x_i + \widehat c y_i \widehat a,\widehat b, \widehat c z_i - \widehat z_i. \sum_{i=1}^n (z_i - \widehat z_i)^2 \sum_{i=1}^n (\widehat z_i - \overline z)^2. z x y,  \frac{\text{explained sum of squares}}{\text{total sum of squares}}.   \sum_{i=1}^n (z_i-\overline z)^2 = \sum_{i=1}^n (\widehat z_i - \overline z)^2 + \sum_{i=1}^n (z_i - \widehat z_i)^2 ","['statistics', 'linear-regression', 'spherical-trigonometry']"
15,The limit of an integral (with statistical backgrounds),The limit of an integral (with statistical backgrounds),,"I would like to compute the following limit of an integral $$I=\lim_{n\to+\infty}\int_0^n\frac{x^n\text{e}^{-x}}{n!}\text{d}x$$ which I encountered in a statistics problem. I can easily do this using Gamma distribution and Central Limit Theorem: Consider a random variable $X_n$ with PDF $f_n(x)=\frac{x^n\text{e}^{-x}}{n!}$ . From the properties of Gamma distribution, it can be decomposed into exponential distributions, $X_n=\sum_{k=1}^n X_k$ where $X_k\sim\text{Exp}(1)$ . Now let $F_n(x)=\text{P}(\frac{X_n-n}{\sqrt n}\leq x)$ ; from Central Limit Theorem, $$\lim_{n\to+\infty}F_n(x)=\lim_{n\to+\infty}\text{P}\left(\frac{\sum_{k=1}^n X_k -n}{\sqrt n}\leq x\right)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^x\text{e}^{\frac{-t^2}{2}}\text{d}t$$ Plugging $x=0$ in gives $I=\frac 1 2$ . Nevertheless, I would like to know if there are any pure math methods for solving this (that don't involve anything statistical). The integral itself, from Wolfram|Alpha , is $$\int_0^n\frac{x^n\text{e}^{-x}}{n!}\text{d}x=\frac{\Gamma(n+1)-\Gamma(n+1,n)}{n!}$$ which doesn't seem to be very useful (it's just rewriting this integral in a Gamma function form). Any help would be appreciated.","I would like to compute the following limit of an integral which I encountered in a statistics problem. I can easily do this using Gamma distribution and Central Limit Theorem: Consider a random variable with PDF . From the properties of Gamma distribution, it can be decomposed into exponential distributions, where . Now let ; from Central Limit Theorem, Plugging in gives . Nevertheless, I would like to know if there are any pure math methods for solving this (that don't involve anything statistical). The integral itself, from Wolfram|Alpha , is which doesn't seem to be very useful (it's just rewriting this integral in a Gamma function form). Any help would be appreciated.","I=\lim_{n\to+\infty}\int_0^n\frac{x^n\text{e}^{-x}}{n!}\text{d}x X_n f_n(x)=\frac{x^n\text{e}^{-x}}{n!} X_n=\sum_{k=1}^n X_k X_k\sim\text{Exp}(1) F_n(x)=\text{P}(\frac{X_n-n}{\sqrt n}\leq x) \lim_{n\to+\infty}F_n(x)=\lim_{n\to+\infty}\text{P}\left(\frac{\sum_{k=1}^n X_k -n}{\sqrt n}\leq x\right)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^x\text{e}^{\frac{-t^2}{2}}\text{d}t x=0 I=\frac 1 2 \int_0^n\frac{x^n\text{e}^{-x}}{n!}\text{d}x=\frac{\Gamma(n+1)-\Gamma(n+1,n)}{n!}",['calculus']
16,How to compute median without storing all the values?,How to compute median without storing all the values?,,"I have a source of data that continuously gives me measurement results. At some point I compute the mean. Luckily to this end, I don't need to store all the values, I only store the sum and the number of results, so I can divide one by the other. It is important because of efficiency reason, as I have loads of such sources operating concurrently. The requirement has just changed and I was asked for the median instead of the mean. In order to compute the median, one needs all the values from the data set, which in my case would exhaust computer memory, thus I am thinking of an improvement. The idea I have is storing histograms and approximating medians from them. Nevertheless, creating a histogram object for each data source (which I have millions) might not pay back for sources that produce very few values. In short, I'd appreciate any comments related to median, quartiles and median absolute deviation computations optimization.","I have a source of data that continuously gives me measurement results. At some point I compute the mean. Luckily to this end, I don't need to store all the values, I only store the sum and the number of results, so I can divide one by the other. It is important because of efficiency reason, as I have loads of such sources operating concurrently. The requirement has just changed and I was asked for the median instead of the mean. In order to compute the median, one needs all the values from the data set, which in my case would exhaust computer memory, thus I am thinking of an improvement. The idea I have is storing histograms and approximating medians from them. Nevertheless, creating a histogram object for each data source (which I have millions) might not pay back for sources that produce very few values. In short, I'd appreciate any comments related to median, quartiles and median absolute deviation computations optimization.",,"['statistics', 'data-analysis', 'median']"
17,What are sufficient conditions such that consistency of ML estimate implies consistency of MAP estimate?,What are sufficient conditions such that consistency of ML estimate implies consistency of MAP estimate?,,"I am interested in under what conditions the frequentist consistency of a Maximum-Likelihood estimator is enough to give the consistency of a maximum-a-posteriori point estimate, with the further restriction of i.i.d. models. That is, consider $y_1,\ldots,y_n$ $ \overset{\text{i.i.d.}}{\sim}$ $p(y\mid \theta_0)$ , and suppose that a sequence of maximum likelihood estimators $\hat{\theta}_n : = \underset{\theta}{\operatorname{argmax}} M_n(\theta),$ where $M_n(\theta):=\  \frac{1}{n} \sum_i\ln p(y_i\mid\theta)$ , exists and is consistent, that means $\hat{\theta}_n \overset {\mathbb{P}_{\theta_0}}{\rightarrow} \theta_0$ . Now consider some prior $p(\theta)$ and define the posterior mode estimate as $\hat{\theta}^\text{MAP}_n :=\underset{\theta}{\arg \max} \ M_n(\theta) + \frac{1}{n} \ln p(\theta))$ .  The question would be now, which conditions are sufficient such that, together with the consistency of $\hat{\theta}_n$ , they imply the consistency of the MAP estimate: $\hat{\theta}^\text{MAP}_n \overset {\mathbb{P}_{\theta_0}}{\rightarrow} \theta_0$ . Naturally, one should assume that the prior puts positive mass on $\theta_0$ , i.e. $p(\theta) >0$ in some neighborhood of $\theta_0$ . Besides of that , I could find that the following conditions from [1] are sufficient: Define $M(\theta) = \mathbb{E}_{\theta_0}[\ln p(y\mid \theta)]$ . If we have that $$ \sup_\theta \left| M_n(\theta) - M(\theta)\right| \overset{\mathbb{P_{\theta_0}}}{\rightarrow} 0 $$ $$  \sup_{\theta \,:\, d(\theta,\theta_0) \,\geq\, \varepsilon} M(\theta) < M(\theta_0) , \ \forall \varepsilon,$$ then $\hat{\theta}^\text{MAP}_n \overset {\mathbb{P}_{\theta_0}} {\rightarrow} \theta_0$ . The proof is basically the same as in [1]. This, however is unsatisfactory for at least 2 reasons: First, one has to make strong assumptions about the likelihood function, that may be too restrictive. Second, by imposing these restrictions, we are also implicitly proving the consistency of the $ML$ estimator again.  It would be nicer to have less assumptions on the likelihood or even have conditions that directly work with the fact that $\theta_n$ is consistent. Regarding the former, I tried to modify other proofs given in [1] regarding consistency of ML-estimates, but with these it seems to me that additional assumptions are needed. So my question would be: - What are sufficient conditions for consistency of MAP estimates, given consistency of the ML? Edit: I will add some thoughts so that one can see the place where I am stuck and maybe someone else knows some solution. Assume we have that the prior is as above and we can bound it from above. Consider some small $\varepsilon$ . Then we have $$ (\hat{\theta}_n^{MAP} \notin B_{\varepsilon}(\theta_0))  \implies M_n(\hat{\theta}_n^{MAP}) + \frac{\ln p(\hat{\theta}_n^{MAP})}{n} \geq M_n(\hat{\theta}_n)  + \frac{\ln p(\hat{\theta}_n)}{n} \\ $$ By the consistency of $\hat{\theta}_n$ and the continuity and positivity of the prior, we can replace the last term on the right by $\frac{\ln p(\theta_0)}{n} - \delta$ for some arbitrarily small $\delta$ for large enough $n$ , and we can definitely replace the term involving the prior on the left by it's supremum. We then have $$M_n(\hat{\theta}_n^{MAP}) + \frac{\underset{\theta}{\sup} \ln p(\theta) - \ln p(\theta_0)}{n}   + \delta  \geq M_n(\hat{\theta}_n)$$ At this point then it seems to me that one needs some additional assumptions. If the convergence to the limit function $M(\theta)$ is uniform, and the limit function is well-separated, then of course the above inequality will be fulfilled with arbitrarily small probability. This is why the conditions given above work. [1] van der Vaart, A. W. , Asymptotic statistics , Cambridge Series in Statistical and Probabilistic Mathematics, 3. Cambridge: Cambridge Univ. Press. xv, 443 p. (1998). ZBL0910.62001 .","I am interested in under what conditions the frequentist consistency of a Maximum-Likelihood estimator is enough to give the consistency of a maximum-a-posteriori point estimate, with the further restriction of i.i.d. models. That is, consider , and suppose that a sequence of maximum likelihood estimators where , exists and is consistent, that means . Now consider some prior and define the posterior mode estimate as .  The question would be now, which conditions are sufficient such that, together with the consistency of , they imply the consistency of the MAP estimate: . Naturally, one should assume that the prior puts positive mass on , i.e. in some neighborhood of . Besides of that , I could find that the following conditions from [1] are sufficient: Define . If we have that then . The proof is basically the same as in [1]. This, however is unsatisfactory for at least 2 reasons: First, one has to make strong assumptions about the likelihood function, that may be too restrictive. Second, by imposing these restrictions, we are also implicitly proving the consistency of the estimator again.  It would be nicer to have less assumptions on the likelihood or even have conditions that directly work with the fact that is consistent. Regarding the former, I tried to modify other proofs given in [1] regarding consistency of ML-estimates, but with these it seems to me that additional assumptions are needed. So my question would be: - What are sufficient conditions for consistency of MAP estimates, given consistency of the ML? Edit: I will add some thoughts so that one can see the place where I am stuck and maybe someone else knows some solution. Assume we have that the prior is as above and we can bound it from above. Consider some small . Then we have By the consistency of and the continuity and positivity of the prior, we can replace the last term on the right by for some arbitrarily small for large enough , and we can definitely replace the term involving the prior on the left by it's supremum. We then have At this point then it seems to me that one needs some additional assumptions. If the convergence to the limit function is uniform, and the limit function is well-separated, then of course the above inequality will be fulfilled with arbitrarily small probability. This is why the conditions given above work. [1] van der Vaart, A. W. , Asymptotic statistics , Cambridge Series in Statistical and Probabilistic Mathematics, 3. Cambridge: Cambridge Univ. Press. xv, 443 p. (1998). ZBL0910.62001 .","y_1,\ldots,y_n  \overset{\text{i.i.d.}}{\sim} p(y\mid \theta_0) \hat{\theta}_n : = \underset{\theta}{\operatorname{argmax}} M_n(\theta), M_n(\theta):=\  \frac{1}{n} \sum_i\ln p(y_i\mid\theta) \hat{\theta}_n \overset {\mathbb{P}_{\theta_0}}{\rightarrow} \theta_0 p(\theta) \hat{\theta}^\text{MAP}_n :=\underset{\theta}{\arg \max} \ M_n(\theta) + \frac{1}{n} \ln p(\theta)) \hat{\theta}_n \hat{\theta}^\text{MAP}_n \overset {\mathbb{P}_{\theta_0}}{\rightarrow} \theta_0 \theta_0 p(\theta) >0 \theta_0 M(\theta) = \mathbb{E}_{\theta_0}[\ln p(y\mid \theta)]  \sup_\theta \left| M_n(\theta) - M(\theta)\right| \overset{\mathbb{P_{\theta_0}}}{\rightarrow} 0    \sup_{\theta \,:\, d(\theta,\theta_0) \,\geq\, \varepsilon} M(\theta) < M(\theta_0) , \ \forall \varepsilon, \hat{\theta}^\text{MAP}_n \overset {\mathbb{P}_{\theta_0}} {\rightarrow} \theta_0 ML \theta_n \varepsilon  (\hat{\theta}_n^{MAP} \notin B_{\varepsilon}(\theta_0))  \implies M_n(\hat{\theta}_n^{MAP}) + \frac{\ln p(\hat{\theta}_n^{MAP})}{n} \geq M_n(\hat{\theta}_n)  + \frac{\ln p(\hat{\theta}_n)}{n} \\  \hat{\theta}_n \frac{\ln p(\theta_0)}{n} - \delta \delta n M_n(\hat{\theta}_n^{MAP}) + \frac{\underset{\theta}{\sup} \ln p(\theta) - \ln p(\theta_0)}{n}   + \delta  \geq M_n(\hat{\theta}_n) M(\theta)","['statistics', 'asymptotics', 'bayesian', 'maximum-likelihood', 'probability-limit-theorems']"
18,Why does Logistic Regression need Normalized data,Why does Logistic Regression need Normalized data,,"I am trying to implement logistic regression in some problem, but while using normal data gives me some nan results. When I normalize the data I get correct results, so why does Logistic Regression need normalize data? Thanks.","I am trying to implement logistic regression in some problem, but while using normal data gives me some nan results. When I normalize the data I get correct results, so why does Logistic Regression need normalize data? Thanks.",,"['statistics', 'machine-learning', 'logistic-regression']"
19,Perfect Sampling - Reuse of random bits,Perfect Sampling - Reuse of random bits,,"I'm currently studying the Perfect Sampling approach to Markov Chain Monte Carlo proposed by Propp and Wilson in 1996.Though having understood most important aspects, I'm still struggling to figure out their example used for explaining that one must reuse the random numbers generated in earlier iterations. The example reads as follows and is allegedly ""simple to check"". It is sometimes desirable to view the process as an iterative one, in which one successively starts up $n$ copies of the chain at times $-1$ , $-2$ , etc., until one has gone sufficiently far back in the past to allow the different histories to coalesce by time $0$ . However, when one adopts this point of view (and we will want to do this in the next subsection), it is important to bear in mind that the random bits that one uses in going from time $t$ to time $t+1$ must be the same for the many sweeps one might make through this time-step. If one ignores this requirement, then there will in general be bias in the samples that one generates. The curious reader may verify this by considering the Markov chain whose states are $0$ , $1$ , and $2$ , and in which transitions are implemented using a fair coin, by the rule that one moves from state $i$ to state $\min(i+1,2)$ if the coin comes up heads and to state $\max(i-1,O)$ otherwise. It is simple to check that if one runs an incorrect version of our scheme in which entirely new random bits are used every time the chain gets restarted further into the past, the samples one gets will be biased in favor of the extreme states $0$ and $2$ . So obviously the transition matrix of the described Markov Chain is $$ P = \begin{pmatrix}  1/2 & 1/2 & 0 \\ 1/2 & 0 & 1/2 \\ 0 & 1/2 & 1/2 \end{pmatrix} $$ with state space $S = \lbrace 0,1,2 \rbrace$ . So the stationary distribution is $ \pi = \begin{pmatrix} 1/3 & 1/3 & 1/3 \end{pmatrix}$ and the claim is that when applying Perfect Sampling wrongly( that is with regeneration of the random transitions) we would get states $0$ and $2$ with a higher frequency than $1/3$ . I tried modeling the dynamics of the coupled Markov-Chains started at each of the 3 different states. To do so I defined the following $2$ -dimensional Markov-Chain $$ X_t = (X_t^1, X_t^2), $$ where $X_t^1$ denotes the number of the $3$ -chains currently in state $0$ and $X_t^2$ denotes the number of the $3$ -chains currently in state $1$ . The number of chains in state $2$ would then follow from $3 = X_t^1 + X_t^2$ . Then the state space of $X$ is $$ S = \lbrace (0,0), (0,1), (0,2), (0,3), (1,0), (1,1), (1,2), (2,0), (2,1), (3,0) \rbrace $$ and the respective transition matrix I came up with is (in R code) m <- matrix(c(.5, 0, 0, .5, 0, 0, 0, 0, 0, 0,                .25, 0, .25, 0, .25, 0, .25, 0, 0, 0,                .25, .25, 0, 0, 0, 0, 0, .25, .25, 0,                .5,  0, 0, 0, 0, 0, 0, 0, 0, .5,                0, .25, 0, .25, .25, 0, .25, 0, 0, 0,                0, .125, .125, 0, .125, .25, .125, .125, .125, 0,                0, .25, 0, 0, .25, 0, 0, 0, .25, .25,                0, 0, .25, .25, 0, 0, 0, .25, .25, 0,                0, 0, .25, 0, 0, 0, .25, .25, 0, .25,                0, 0, 0, .5, 0, 0, 0, 0, 0, .5),              byrow=TRUE, nrow=10) But using this transition matrix and computing the distributions for a start in the initial state $(1,1)$ suggests that the $3$ ""coalescence states"" $(3,0), (0,3) $ and $(0,0)$ have equal probability.","I'm currently studying the Perfect Sampling approach to Markov Chain Monte Carlo proposed by Propp and Wilson in 1996.Though having understood most important aspects, I'm still struggling to figure out their example used for explaining that one must reuse the random numbers generated in earlier iterations. The example reads as follows and is allegedly ""simple to check"". It is sometimes desirable to view the process as an iterative one, in which one successively starts up copies of the chain at times , , etc., until one has gone sufficiently far back in the past to allow the different histories to coalesce by time . However, when one adopts this point of view (and we will want to do this in the next subsection), it is important to bear in mind that the random bits that one uses in going from time to time must be the same for the many sweeps one might make through this time-step. If one ignores this requirement, then there will in general be bias in the samples that one generates. The curious reader may verify this by considering the Markov chain whose states are , , and , and in which transitions are implemented using a fair coin, by the rule that one moves from state to state if the coin comes up heads and to state otherwise. It is simple to check that if one runs an incorrect version of our scheme in which entirely new random bits are used every time the chain gets restarted further into the past, the samples one gets will be biased in favor of the extreme states and . So obviously the transition matrix of the described Markov Chain is with state space . So the stationary distribution is and the claim is that when applying Perfect Sampling wrongly( that is with regeneration of the random transitions) we would get states and with a higher frequency than . I tried modeling the dynamics of the coupled Markov-Chains started at each of the 3 different states. To do so I defined the following -dimensional Markov-Chain where denotes the number of the -chains currently in state and denotes the number of the -chains currently in state . The number of chains in state would then follow from . Then the state space of is and the respective transition matrix I came up with is (in R code) m <- matrix(c(.5, 0, 0, .5, 0, 0, 0, 0, 0, 0,                .25, 0, .25, 0, .25, 0, .25, 0, 0, 0,                .25, .25, 0, 0, 0, 0, 0, .25, .25, 0,                .5,  0, 0, 0, 0, 0, 0, 0, 0, .5,                0, .25, 0, .25, .25, 0, .25, 0, 0, 0,                0, .125, .125, 0, .125, .25, .125, .125, .125, 0,                0, .25, 0, 0, .25, 0, 0, 0, .25, .25,                0, 0, .25, .25, 0, 0, 0, .25, .25, 0,                0, 0, .25, 0, 0, 0, .25, .25, 0, .25,                0, 0, 0, .5, 0, 0, 0, 0, 0, .5),              byrow=TRUE, nrow=10) But using this transition matrix and computing the distributions for a start in the initial state suggests that the ""coalescence states"" and have equal probability.","n -1 -2 0 t t+1 0 1 2 i \min(i+1,2) \max(i-1,O) 0 2 
P = \begin{pmatrix} 
1/2 & 1/2 & 0 \\
1/2 & 0 & 1/2 \\
0 & 1/2 & 1/2
\end{pmatrix}
 S = \lbrace 0,1,2 \rbrace  \pi = \begin{pmatrix} 1/3 & 1/3 & 1/3 \end{pmatrix} 0 2 1/3 2 
X_t = (X_t^1, X_t^2),
 X_t^1 3 0 X_t^2 3 1 2 3 = X_t^1 + X_t^2 X 
S = \lbrace (0,0), (0,1), (0,2), (0,3), (1,0), (1,1), (1,2), (2,0), (2,1), (3,0) \rbrace
 (1,1) 3 (3,0), (0,3)  (0,0)","['statistics', 'markov-chains', 'monte-carlo']"
20,Estimating the value of $\sigma$ for Brownian motion,Estimating the value of  for Brownian motion,\sigma,"Let $X_t=\sigma W_t$ be a stochastic process, where $W_t$ is the Wiener process and $\sigma$ is an unknown parameter. I want a formula to estimate the value of $\sigma$ (which could not be found in my book) from $n$ successive measurements $(x_{t_k})_{k=1}^n$ . Now, I understand that $(X_{t_k})_{k=1}^n$ is a normally distributed vector in $\mathbb R^n$ , but so I could NOT estimate its co-variance matrix because I only have the sample of ONE vector in $\mathbb R^n$ , and co-variance could NOT be estimated from ONE sample. That stops me from estimating $\sigma$ . How could I estimate $\sigma$ ?","Let be a stochastic process, where is the Wiener process and is an unknown parameter. I want a formula to estimate the value of (which could not be found in my book) from successive measurements . Now, I understand that is a normally distributed vector in , but so I could NOT estimate its co-variance matrix because I only have the sample of ONE vector in , and co-variance could NOT be estimated from ONE sample. That stops me from estimating . How could I estimate ?",X_t=\sigma W_t W_t \sigma \sigma n (x_{t_k})_{k=1}^n (X_{t_k})_{k=1}^n \mathbb R^n \mathbb R^n \sigma \sigma,"['statistics', 'stochastic-processes', 'brownian-motion', 'parameter-estimation']"
21,Looking for density estimator with time complexity $< \mathcal O(n^2)$,Looking for density estimator with time complexity,< \mathcal O(n^2),"I am doing univariate non-parametric density estimation on a dataset $D$ , and I want to 1) Train a density estimator on $D$ 2) Compute the estimated density at each point in $D$ These two operations should have an aggregate time complexity $< \mathcal O(n^2)$ , and the PDF estimate should be differentiable. An $\mathcal O(n)$ time complexity of the aggregate process is possible with the histogram estimator. However, the PDF estimate is not differentiable. The Gaussian kernel density estimator gives a differentiable PDF estimate. However, the time complexity of the aggregate process is $\mathcal O(n^2)$ . With Gaussian KDE, density estimation of a single point is $\mathcal O(n)$ , so density estimation of all points in the dataset would be $\mathcal O(n^2)$ . Thus this method does not have an aggregate time complexity $< \mathcal O(n^2)$ . Does there exist a density estimator that would satisfy both conditions? EDIT: I found a way to have an aggregate time complexity of $\mathcal O(n)$ with Gaussian KDE. See the following link... http://www-stat.wharton.upenn.edu/~lzhao/papers/MyPublication/Fast_jcgs.2010.pdf","I am doing univariate non-parametric density estimation on a dataset , and I want to 1) Train a density estimator on 2) Compute the estimated density at each point in These two operations should have an aggregate time complexity , and the PDF estimate should be differentiable. An time complexity of the aggregate process is possible with the histogram estimator. However, the PDF estimate is not differentiable. The Gaussian kernel density estimator gives a differentiable PDF estimate. However, the time complexity of the aggregate process is . With Gaussian KDE, density estimation of a single point is , so density estimation of all points in the dataset would be . Thus this method does not have an aggregate time complexity . Does there exist a density estimator that would satisfy both conditions? EDIT: I found a way to have an aggregate time complexity of with Gaussian KDE. See the following link... http://www-stat.wharton.upenn.edu/~lzhao/papers/MyPublication/Fast_jcgs.2010.pdf",D D D < \mathcal O(n^2) \mathcal O(n) \mathcal O(n^2) \mathcal O(n) \mathcal O(n^2) < \mathcal O(n^2) \mathcal O(n),"['statistics', 'machine-learning', 'density-function']"
22,"Write the likelihood in terms of the unknown parameter β, $f_x$ and g","Write the likelihood in terms of the unknown parameter β,  and g",f_x,"Consider $n$ i.i.d. pairs of random variables $(X_i, Y_i), i = 1, . . . , n,$ where $X_i ∈ R_p (p ≥ 1)$ and $Y_i ∈ R_p$. For each $i$, write    $Y_i = X′_i\beta + \varepsilon_i$, where $E[\varepsilon_i] = 0, cov(X_i, \varepsilon_i) = 0$ and $\beta$ is an unknown vector, that we want to estimate. Assume that for all $x ∈ R_p$, $\varepsilon_1$ has a conditional density given $X_1 = x$, denoted by $f_x$ and that $X_1$ has a density, which we denote by $g$. $Y_i = X′_i\beta + ε_i$; $f(Y_i=y)=f(X′_i\beta+\varepsilon_i=y)=\sum_{i=1}^pf(X′_i\beta+\varepsilon_i=y|X_i=x)g(X_i=x)=\sum_{i=1}^pf(\varepsilon_i=y-x\beta|X_i=x)g(X_i)=\sum_{i=1}^pf(ε_i=y-x\beta|X_i=x)g(X_i)=f(\varepsilon_1=y-x\beta|X_1=x)g(X_1)+\sum_2^pf(\varepsilon_i=y-x\beta|X_i=x)g(X_i)=f_xg+\sum_2^pf(\varepsilon_i=y-x\beta|X_i=x)g(X_i)$ where I can go from here? Can I assume that $ε_i$ and $X_i$ are independent? I think, no since the fact that covariance is zero does imply independence only for linear variables, and $\varepsilon$ can be anything. $\prod_{i=1}^pf(Y_i=y)=\prod_{i=1}^p(f_xg+\sum_2^pf(\varepsilon_i=y-x\beta|X_i=x)g(X_i=x))$ Can you give me a hint?","Consider $n$ i.i.d. pairs of random variables $(X_i, Y_i), i = 1, . . . , n,$ where $X_i ∈ R_p (p ≥ 1)$ and $Y_i ∈ R_p$. For each $i$, write    $Y_i = X′_i\beta + \varepsilon_i$, where $E[\varepsilon_i] = 0, cov(X_i, \varepsilon_i) = 0$ and $\beta$ is an unknown vector, that we want to estimate. Assume that for all $x ∈ R_p$, $\varepsilon_1$ has a conditional density given $X_1 = x$, denoted by $f_x$ and that $X_1$ has a density, which we denote by $g$. $Y_i = X′_i\beta + ε_i$; $f(Y_i=y)=f(X′_i\beta+\varepsilon_i=y)=\sum_{i=1}^pf(X′_i\beta+\varepsilon_i=y|X_i=x)g(X_i=x)=\sum_{i=1}^pf(\varepsilon_i=y-x\beta|X_i=x)g(X_i)=\sum_{i=1}^pf(ε_i=y-x\beta|X_i=x)g(X_i)=f(\varepsilon_1=y-x\beta|X_1=x)g(X_1)+\sum_2^pf(\varepsilon_i=y-x\beta|X_i=x)g(X_i)=f_xg+\sum_2^pf(\varepsilon_i=y-x\beta|X_i=x)g(X_i)$ where I can go from here? Can I assume that $ε_i$ and $X_i$ are independent? I think, no since the fact that covariance is zero does imply independence only for linear variables, and $\varepsilon$ can be anything. $\prod_{i=1}^pf(Y_i=y)=\prod_{i=1}^p(f_xg+\sum_2^pf(\varepsilon_i=y-x\beta|X_i=x)g(X_i=x))$ Can you give me a hint?",,"['statistics', 'regression', 'maximum-likelihood']"
23,A book on statistics similar to Michael Spivak's Calculus,A book on statistics similar to Michael Spivak's Calculus,,"I'm looking for an book on statistics that's similar to Michael Spivak's Calculus . It should be rigorous, starting with some fundamental axioms and build layers of theorems on top of it, and it should be concise.","I'm looking for an book on statistics that's similar to Michael Spivak's Calculus . It should be rigorous, starting with some fundamental axioms and build layers of theorems on top of it, and it should be concise.",,"['statistics', 'reference-request', 'book-recommendation']"
24,On the rate of convergence of the central limit theorem,On the rate of convergence of the central limit theorem,,"As I have seen, there are many questions on this site concerning the rate of convergence of the central limit theorem: for example this , this , this , and this . In particular, the third question of this list concerns quantitative bounds on the convergence in distribution $$ \frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \to_D Z \sim \mathcal{N}(0,1). $$ One commenter points out the Berry-Essen theorem which gives a bound on the CDF of $(\overline{X}_n - \mu)/(\sigma/\sqrt{n})$ and the standard normal random variable based on the third absolute moment $\rho := \Bbb E[|X-\mu|^3]$. Specifically, if $F_n$ is the CDF of $(\overline{X}_n - \mu)/(\sigma/\sqrt{n})$ and $\Phi$ of the standard normal random variable, then the theorem states that the difference between these is bounded as $$ |F_n(x) - \Phi(x)| \le \frac{C\rho}{\sigma^3\sqrt{n}}, \text{ for all } x \in \Bbb R, \text{ $C$ constant}. $$ However, despite the existence of a concrete quantitative error bound on the approximation of $(\overline{X}_n - \mu)/(\sigma/\sqrt{n})$, introductory statistics classes often treat $(\overline{X}_n - \mu)/(\sigma/\sqrt{n})$ as either unapproximable at all by a normal random variable or perfectly normal, with $n = 30$ as a seemingly arbitrary cutoff between the two. Presumably, whether a given sample should be approximated as normal depends highly on $\rho$ and $\sigma$, not just $n$. My questions: Why isn't the error in the normal approximation taken into account when performing statistical inference or making confidence intervals using the CLT? Does computing $$ \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i, \: s := \sqrt{ \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2}, $$ and some unbiased consistent estimate $\hat{\rho}$ of $\rho$ and computing $C\hat{\rho}/s^3\sqrt{n}$ give a ""better"" heuristic for whether one should use a large sample CLT approximation than simply looking at $n\ge 30$? If so, why is $n\ge 30$ approximation so ubiquitous in introductory statistics classes?","As I have seen, there are many questions on this site concerning the rate of convergence of the central limit theorem: for example this , this , this , and this . In particular, the third question of this list concerns quantitative bounds on the convergence in distribution $$ \frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \to_D Z \sim \mathcal{N}(0,1). $$ One commenter points out the Berry-Essen theorem which gives a bound on the CDF of $(\overline{X}_n - \mu)/(\sigma/\sqrt{n})$ and the standard normal random variable based on the third absolute moment $\rho := \Bbb E[|X-\mu|^3]$. Specifically, if $F_n$ is the CDF of $(\overline{X}_n - \mu)/(\sigma/\sqrt{n})$ and $\Phi$ of the standard normal random variable, then the theorem states that the difference between these is bounded as $$ |F_n(x) - \Phi(x)| \le \frac{C\rho}{\sigma^3\sqrt{n}}, \text{ for all } x \in \Bbb R, \text{ $C$ constant}. $$ However, despite the existence of a concrete quantitative error bound on the approximation of $(\overline{X}_n - \mu)/(\sigma/\sqrt{n})$, introductory statistics classes often treat $(\overline{X}_n - \mu)/(\sigma/\sqrt{n})$ as either unapproximable at all by a normal random variable or perfectly normal, with $n = 30$ as a seemingly arbitrary cutoff between the two. Presumably, whether a given sample should be approximated as normal depends highly on $\rho$ and $\sigma$, not just $n$. My questions: Why isn't the error in the normal approximation taken into account when performing statistical inference or making confidence intervals using the CLT? Does computing $$ \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i, \: s := \sqrt{ \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2}, $$ and some unbiased consistent estimate $\hat{\rho}$ of $\rho$ and computing $C\hat{\rho}/s^3\sqrt{n}$ give a ""better"" heuristic for whether one should use a large sample CLT approximation than simply looking at $n\ge 30$? If so, why is $n\ge 30$ approximation so ubiquitous in introductory statistics classes?",,"['statistics', 'approximation', 'central-limit-theorem']"
25,Maximum Likelihood Estimator (MLE ) for the Gaussian-noise simple linear regression model,Maximum Likelihood Estimator (MLE ) for the Gaussian-noise simple linear regression model,,I am reviewing the method of maximum likelihood  and I was looking at the Gaussian-noise simple linear regression model at this link . I understand up to equation (3) on page 2. I assumed it followed by finding MLE parameters using derivative with respect to $\hat{\beta_0}$ and $\hat{\beta_1}$ and $\hat{\sigma^2}$.  When I tried to solve this myslef I obtained the $\hat{\beta_1}$ and $\hat{\beta_2}$ as follows: $\hat{\beta}_0 = \frac{\sum_{i=1}^{n} y_i - \hat{\beta}_{1}x_i}{n}=\bar{y}-{\hat{\beta}_1}\bar{x}$ $\hat{\beta}_1 = \frac{\sum_{i=1}^{n} x_iy_i - \hat{\beta}_{0}x_i}{\sum_{i=1}^{n}x_i^2}$ or $\bar{xy} - \hat{\beta_0}\bar{x} - \hat{\beta_1}\bar{x^2} =0$ I don't understand how the closed form solution shown below is obtained: $\hat{\beta}_1 = \frac{c_{xy}}{{s_x^2}} = \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2} $ (written in equation 4) Can anyone help to clarify this please?,I am reviewing the method of maximum likelihood  and I was looking at the Gaussian-noise simple linear regression model at this link . I understand up to equation (3) on page 2. I assumed it followed by finding MLE parameters using derivative with respect to $\hat{\beta_0}$ and $\hat{\beta_1}$ and $\hat{\sigma^2}$.  When I tried to solve this myslef I obtained the $\hat{\beta_1}$ and $\hat{\beta_2}$ as follows: $\hat{\beta}_0 = \frac{\sum_{i=1}^{n} y_i - \hat{\beta}_{1}x_i}{n}=\bar{y}-{\hat{\beta}_1}\bar{x}$ $\hat{\beta}_1 = \frac{\sum_{i=1}^{n} x_iy_i - \hat{\beta}_{0}x_i}{\sum_{i=1}^{n}x_i^2}$ or $\bar{xy} - \hat{\beta_0}\bar{x} - \hat{\beta_1}\bar{x^2} =0$ I don't understand how the closed form solution shown below is obtained: $\hat{\beta}_1 = \frac{c_{xy}}{{s_x^2}} = \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2} $ (written in equation 4) Can anyone help to clarify this please?,,"['statistics', 'closed-form', 'regression', 'parameter-estimation', 'maximum-likelihood']"
26,Leverage points in linear regression,Leverage points in linear regression,,"From the wikipedia , leverage of a point is defined as the measure of how far away the independent variable values of an observation are from those of the other observations. Mathematically for point(observation) $x_i$, it is given by $h_{ii}=x_i^T(X^TX)^{-1}x_i$, where rows of matrix $X \in R^{n*d}$ contains points. Now my question is how does the formula leads to the interpretation given in first line. This is how I see it, If we calculate the covariance matrix from the observation to find mahalanobis type distance metric we have covariance as $(X^TX-\frac{1}{n^2}X^T \mathbf{1} X)$, ( note rows of X are our points) where $\mu^T=\frac{1}{n}[1,1...,1]X$ and $\mathbf{1} \in R^{n*n}$ is matrix of all $1$'s. And now if we use this as distance metric shouldn't the leverage be defined as $\hat{h_{ii}}=(x_i-\mu)^T(X^TX-\frac{1}{n^2}X^T \mathbf{1} X)^{-1}(x_i-\mu)$ ? How does one come up with the interpretation? Also I am curious what properties of colspace of $X$ does leverage score(leverage of each point) help us understand? Any help, comments, hints are greatly appreciated. Thanks.","From the wikipedia , leverage of a point is defined as the measure of how far away the independent variable values of an observation are from those of the other observations. Mathematically for point(observation) $x_i$, it is given by $h_{ii}=x_i^T(X^TX)^{-1}x_i$, where rows of matrix $X \in R^{n*d}$ contains points. Now my question is how does the formula leads to the interpretation given in first line. This is how I see it, If we calculate the covariance matrix from the observation to find mahalanobis type distance metric we have covariance as $(X^TX-\frac{1}{n^2}X^T \mathbf{1} X)$, ( note rows of X are our points) where $\mu^T=\frac{1}{n}[1,1...,1]X$ and $\mathbf{1} \in R^{n*n}$ is matrix of all $1$'s. And now if we use this as distance metric shouldn't the leverage be defined as $\hat{h_{ii}}=(x_i-\mu)^T(X^TX-\frac{1}{n^2}X^T \mathbf{1} X)^{-1}(x_i-\mu)$ ? How does one come up with the interpretation? Also I am curious what properties of colspace of $X$ does leverage score(leverage of each point) help us understand? Any help, comments, hints are greatly appreciated. Thanks.",,"['statistics', 'numerical-linear-algebra', 'linear-regression']"
27,PCA derivation by minimizing reconstrution squared error plus orthonormality constraints,PCA derivation by minimizing reconstrution squared error plus orthonormality constraints,,"I'm trying to better understand the link between PCA and Matrix Factorization of the form $X \approx WH$. I've read somewhere that the PCA solution can be also derived from the following cost function (I'm not even sure whether this is the right norm to use) \begin{align} argmin_{W,H} \frac{1}{N}\sum_{n=1}^N|| \mathbf{x}_n - \mathbf{Wh}_n ||^2 \qquad \text{subject to } W^{T} W = I \end{align} which seems similar, if not equal, to the idea of the minimum-error formulation of PCA. According to the PCA derivation, $\mathbf{W}$ is the matrix of the eigenvectors of the covariance matrix of $\mathbf{X}$, and $\mathbf{h}_n$ is the projection of $\mathbf{x}_n$ given by $\mathbf{h}_n = \mathbf{W}^T \mathbf{x}_n$. I have followed the derivation of the minimum-error formulation in Bishop's PRML book , but I find it a bit unintuitive. What is the shortest way to derive the above minimization problem? (I'm thinking, for instance, of using Lagrangians)","I'm trying to better understand the link between PCA and Matrix Factorization of the form $X \approx WH$. I've read somewhere that the PCA solution can be also derived from the following cost function (I'm not even sure whether this is the right norm to use) \begin{align} argmin_{W,H} \frac{1}{N}\sum_{n=1}^N|| \mathbf{x}_n - \mathbf{Wh}_n ||^2 \qquad \text{subject to } W^{T} W = I \end{align} which seems similar, if not equal, to the idea of the minimum-error formulation of PCA. According to the PCA derivation, $\mathbf{W}$ is the matrix of the eigenvectors of the covariance matrix of $\mathbf{X}$, and $\mathbf{h}_n$ is the projection of $\mathbf{x}_n$ given by $\mathbf{h}_n = \mathbf{W}^T \mathbf{x}_n$. I have followed the derivation of the minimum-error formulation in Bishop's PRML book , but I find it a bit unintuitive. What is the shortest way to derive the above minimization problem? (I'm thinking, for instance, of using Lagrangians)",,"['statistics', 'optimization', 'matrix-decomposition']"
28,ML estimator of an double exponential distribution,ML estimator of an double exponential distribution,,"Im trying to figure out the ML estimator of $$f_X(x)=\frac{1}{2\beta}\exp\left(-\frac{|x|}{\beta}\right)$$ as well as the variance of this estimator. So far I have  $$L(\beta;x)=\prod_{i=1}^n\frac{1}{2\beta}\exp\left(-\frac{|x_i|}{\beta}\right),$$  $$\ln[L(\beta;x)]=\sum_{i=1}^n\left[-\ln(2\beta)-\frac{|x_i|}{\beta}\right] =-n\ln(2\beta)-\frac{1}{\beta}\sum_{i=1}^n|x_i|,$$  $$\frac{\partial \ln[L(\beta;x)]}{\partial\beta}=-n\beta+\frac{1}{\beta^2}\sum_{i=1}^n|x_i|=0.$$  So I get $$\hat\beta=\frac{1}{n}\sum_{i=1}^n|X|$$ and with a hint in my textbook $\text{Var}(|X|)=\beta^2$  $$\text{Var}(\hat\beta)=\frac{1}{n^2}\sum_{i=1}^n \text{Var}(|X|)=\frac{\beta^2}{n}$$  Unfortunately this variance does not correspond with the variance in my distribution summary for an double exponential distribution, which is $2\beta^2$. I think my mistake arises from the absolute value. I hope someone can figure it out. Thanks!","Im trying to figure out the ML estimator of $$f_X(x)=\frac{1}{2\beta}\exp\left(-\frac{|x|}{\beta}\right)$$ as well as the variance of this estimator. So far I have  $$L(\beta;x)=\prod_{i=1}^n\frac{1}{2\beta}\exp\left(-\frac{|x_i|}{\beta}\right),$$  $$\ln[L(\beta;x)]=\sum_{i=1}^n\left[-\ln(2\beta)-\frac{|x_i|}{\beta}\right] =-n\ln(2\beta)-\frac{1}{\beta}\sum_{i=1}^n|x_i|,$$  $$\frac{\partial \ln[L(\beta;x)]}{\partial\beta}=-n\beta+\frac{1}{\beta^2}\sum_{i=1}^n|x_i|=0.$$  So I get $$\hat\beta=\frac{1}{n}\sum_{i=1}^n|X|$$ and with a hint in my textbook $\text{Var}(|X|)=\beta^2$  $$\text{Var}(\hat\beta)=\frac{1}{n^2}\sum_{i=1}^n \text{Var}(|X|)=\frac{\beta^2}{n}$$  Unfortunately this variance does not correspond with the variance in my distribution summary for an double exponential distribution, which is $2\beta^2$. I think my mistake arises from the absolute value. I hope someone can figure it out. Thanks!",,"['statistics', 'statistical-inference', 'estimation', 'parameter-estimation']"
29,"Standard Error, why divide by square root of 2?","Standard Error, why divide by square root of 2?",,"I am currently reading the book Options, Futures and Other Derivatives from John C. Hull. In the Chapter of Introducing the Balck-Scholes Model, it says: The standard error of this estimate can be shown to be approximately   $\hat{\sigma}/\sqrt{2n}$, where $\hat{\sigma}$ is the estimated sample   standard deviation, $n$ is the number of samples. Does anyone have any idea why is $\sqrt{2n}$ and not $\sqrt{n}$? P.S. I have sent a Email to Prof. John C. Hull, he says: ""It is tied in with the properties of the Chi squared distribution"", anyone has a clue?","I am currently reading the book Options, Futures and Other Derivatives from John C. Hull. In the Chapter of Introducing the Balck-Scholes Model, it says: The standard error of this estimate can be shown to be approximately   $\hat{\sigma}/\sqrt{2n}$, where $\hat{\sigma}$ is the estimated sample   standard deviation, $n$ is the number of samples. Does anyone have any idea why is $\sqrt{2n}$ and not $\sqrt{n}$? P.S. I have sent a Email to Prof. John C. Hull, he says: ""It is tied in with the properties of the Chi squared distribution"", anyone has a clue?",,['statistics']
30,Variance of exponential moving average,Variance of exponential moving average,,I'm not quite sure what the form for the rolling recursive variance should look like. I have that the recursive average is $m_t = \alpha x_t +(1-a)m_{t-1}$. Then would the rolling recursive variance be $V_t = \alpha (x_t-m_t)^2 +(1-\alpha)V_{t-1}^2$ or  $V_t = \alpha (x_t-m_t)^2 +(1-\alpha)V_{t-1}$?,I'm not quite sure what the form for the rolling recursive variance should look like. I have that the recursive average is $m_t = \alpha x_t +(1-a)m_{t-1}$. Then would the rolling recursive variance be $V_t = \alpha (x_t-m_t)^2 +(1-\alpha)V_{t-1}^2$ or  $V_t = \alpha (x_t-m_t)^2 +(1-\alpha)V_{t-1}$?,,"['statistics', 'recursion', 'average', 'standard-deviation', 'time-series']"
31,Calculating the normalizing factor in the VonMises-Fisher distribution on $S^p$,Calculating the normalizing factor in the VonMises-Fisher distribution on,S^p,"I'm going quickly through the VonMises-Fisher distribution $M$ on $S^p$ and its properties. Its probability density function is: $$f(x; \kappa,\mu)= c(\kappa)\exp(\kappa x^T\mu)$$ where $\kappa \times \mu \in[0,\infty)\times S^p$ are fixed parameters and $c(\kappa)$ is a normalizing constant so the whole thing will integrate 1$ My question is How do you derive the value of $c(\kappa)$? I've checked Mardia and Jupp's Directional Statistics (1999) which seems to be the standard reference, but I'm still bedazzled by its reasoning which goes like: ""To verify that the density integrates to 1, note that the intersection of $S^p$ with the hyperplane through $t\mu$ and normal $\mu$ is a $(p- 2)$-dimensional sphere of radius $\sqrt{1-t^2}$. Since the modified Bessel function of the first kind and order $\nu$ is $$I_\nu = \frac{(\kappa/2)^\nu}{\Gamma(\nu +\frac12)\Gamma(\frac12)}\int_{-1}^1e^{\kappa t}(1-t^2)^{\nu -\frac12}dt$$ it follows that $$\int_{S^{p-1}}\exp(\kappa\mu^Tx)dx = B\left(\frac{p-1}2,\frac12\right)^{-1}\int_{-1}^1e^{\kappa t}(1-t^2)^{\frac{p-3}2}dt$$   with $B(\cdot,\cdot)$ the beta function We can conclude then $$c(\kappa) = \left(\frac\kappa2\right)^{p/2-1}\frac1{\Gamma(\frac p2)I_{p/2-1}(\kappa)}$$ My question is: How do you get the highlighted equality?","I'm going quickly through the VonMises-Fisher distribution $M$ on $S^p$ and its properties. Its probability density function is: $$f(x; \kappa,\mu)= c(\kappa)\exp(\kappa x^T\mu)$$ where $\kappa \times \mu \in[0,\infty)\times S^p$ are fixed parameters and $c(\kappa)$ is a normalizing constant so the whole thing will integrate 1$ My question is How do you derive the value of $c(\kappa)$? I've checked Mardia and Jupp's Directional Statistics (1999) which seems to be the standard reference, but I'm still bedazzled by its reasoning which goes like: ""To verify that the density integrates to 1, note that the intersection of $S^p$ with the hyperplane through $t\mu$ and normal $\mu$ is a $(p- 2)$-dimensional sphere of radius $\sqrt{1-t^2}$. Since the modified Bessel function of the first kind and order $\nu$ is $$I_\nu = \frac{(\kappa/2)^\nu}{\Gamma(\nu +\frac12)\Gamma(\frac12)}\int_{-1}^1e^{\kappa t}(1-t^2)^{\nu -\frac12}dt$$ it follows that $$\int_{S^{p-1}}\exp(\kappa\mu^Tx)dx = B\left(\frac{p-1}2,\frac12\right)^{-1}\int_{-1}^1e^{\kappa t}(1-t^2)^{\frac{p-3}2}dt$$   with $B(\cdot,\cdot)$ the beta function We can conclude then $$c(\kappa) = \left(\frac\kappa2\right)^{p/2-1}\frac1{\Gamma(\frac p2)I_{p/2-1}(\kappa)}$$ My question is: How do you get the highlighted equality?",,"['statistics', 'multivariable-calculus', 'probability-distributions']"
32,Negative Binomial convolution,Negative Binomial convolution,,"I've seen a couple of questions where some users provide some help on how to calculate the convolution of two independent variables $X\sim NB(r,p)$ and $Y\sim NB(s,p)$ link 1 , link 2 . However they always stop the demonstration when they arrive to: $$\displaystyle \sum_{j=0}^k {j+r-1 \choose j}\cdot {k-j +s-1 \choose k-j}={k+r+s-1 \choose k}$$ How can this be proved? Thank you very much","I've seen a couple of questions where some users provide some help on how to calculate the convolution of two independent variables $X\sim NB(r,p)$ and $Y\sim NB(s,p)$ link 1 , link 2 . However they always stop the demonstration when they arrive to: $$\displaystyle \sum_{j=0}^k {j+r-1 \choose j}\cdot {k-j +s-1 \choose k-j}={k+r+s-1 \choose k}$$ How can this be proved? Thank you very much",,"['statistics', 'convolution', 'negative-binomial']"
33,Are there any good statistical inference exercise and solutions books?,Are there any good statistical inference exercise and solutions books?,,"I was wondering if anyone was aware of any exercise and solutions books on statistical inference at a graduate level (ie, UMVUE, UMP tests, hypothesis testing) that contains nothing but exercises and solutions? I would like to do a look of problems to strengthen my understanding of inference and am interested in finding a book that is similar to 1000 Exercises in Probability by Grimmett and Stirzaker . In this book, they have over 1000 exercises with corresponding solutions. Thanks in advance for the recommendations!","I was wondering if anyone was aware of any exercise and solutions books on statistical inference at a graduate level (ie, UMVUE, UMP tests, hypothesis testing) that contains nothing but exercises and solutions? I would like to do a look of problems to strengthen my understanding of inference and am interested in finding a book that is similar to 1000 Exercises in Probability by Grimmett and Stirzaker . In this book, they have over 1000 exercises with corresponding solutions. Thanks in advance for the recommendations!",,"['statistics', 'reference-request', 'book-recommendation']"
34,How to combine percentiles from different datasets,How to combine percentiles from different datasets,,"I'm trying to combine percentiles (50th and 90th) from 2 different datasets. I don't have access to the datasets at the time of combining. Apart from the percentiles I have the number of elements on each dataset. Now, I know that any attempt at combining them will be only an approximation to the real percentile of the combined datasets, but I just want to know what would be the ""most"" correct solution. The options I was considering were:  - Weighted average  - Take the percentile for the biggest dataset The output will be used to build a graph, as I get these percentiles periodically.","I'm trying to combine percentiles (50th and 90th) from 2 different datasets. I don't have access to the datasets at the time of combining. Apart from the percentiles I have the number of elements on each dataset. Now, I know that any attempt at combining them will be only an approximation to the real percentile of the combined datasets, but I just want to know what would be the ""most"" correct solution. The options I was considering were:  - Weighted average  - Take the percentile for the biggest dataset The output will be used to build a graph, as I get these percentiles periodically.",,"['statistics', 'percentile']"
35,Mean and variance on a metric space,Mean and variance on a metric space,,"It is my first post, so please correct me if I am not following the rules/etiquette. Assume that we are given a space $\mathcal{S}$ composed by vectors $x\in\mathbb{R}^L$, constrained by $$\sum x_i=1,\\ 0\le x_i \le 1,$$  where $x_i$ is the $i$-th element of the vector $x$. We also assume to be able to measure the distance between the elements, $$d(x,y)=\sqrt{x^TAy},$$ where $A$ is a given positive semi-definite matrix. If I stand correct, we cannot define a vector space because of the constraints on the vectors, i.e. the sum of two element in $\mathcal{S}$ does not belong to $\mathcal{S}$. I would like to compute quantities related to a set of elements belonging to $\mathcal{S}$, for example the mean and the variance. We define such set as $\{y^n\}_{n=1}^N\text{ where } y^n\in\mathcal{S}$. I thought of considering the Frechet mean/variance and solve the following optimization problem: $$ \min_{x \in \mathcal{S}} \sum_{n=1}^N d^2(x,y^n) = \min_{x\in\mathcal{S}} \sum_{n=1}^N x^TAy^n=\min_{x\in\mathcal{S}}x^TA\bar{y},$$ where $\bar{y} = \sum_{n=1}^N y^n$. This looks like an LP program that could be easily solved. The minimizer would be the Frechet mean and the argument would be the Frechet variance. It looks ok to me, but I am afraid that I have missed some details around that could not allow the solution of the optimization problem. 1) Is this the approach correct? 2) I could not find much information by searching around and I was wondering if there were some pointers around for similar works.","It is my first post, so please correct me if I am not following the rules/etiquette. Assume that we are given a space $\mathcal{S}$ composed by vectors $x\in\mathbb{R}^L$, constrained by $$\sum x_i=1,\\ 0\le x_i \le 1,$$  where $x_i$ is the $i$-th element of the vector $x$. We also assume to be able to measure the distance between the elements, $$d(x,y)=\sqrt{x^TAy},$$ where $A$ is a given positive semi-definite matrix. If I stand correct, we cannot define a vector space because of the constraints on the vectors, i.e. the sum of two element in $\mathcal{S}$ does not belong to $\mathcal{S}$. I would like to compute quantities related to a set of elements belonging to $\mathcal{S}$, for example the mean and the variance. We define such set as $\{y^n\}_{n=1}^N\text{ where } y^n\in\mathcal{S}$. I thought of considering the Frechet mean/variance and solve the following optimization problem: $$ \min_{x \in \mathcal{S}} \sum_{n=1}^N d^2(x,y^n) = \min_{x\in\mathcal{S}} \sum_{n=1}^N x^TAy^n=\min_{x\in\mathcal{S}}x^TA\bar{y},$$ where $\bar{y} = \sum_{n=1}^N y^n$. This looks like an LP program that could be easily solved. The minimizer would be the Frechet mean and the argument would be the Frechet variance. It looks ok to me, but I am afraid that I have missed some details around that could not allow the solution of the optimization problem. 1) Is this the approach correct? 2) I could not find much information by searching around and I was wondering if there were some pointers around for similar works.",,"['statistics', 'metric-spaces', 'means']"
36,Generating a sample of Epanechnikov Kernel,Generating a sample of Epanechnikov Kernel,,"So I am really struggling with this problem and could use some help. Consider the Epanechnikov kernel given by $$f_e(x)=\frac{3}{4}\left( 1-x^2 \right)$$ According to Devorye and Gyofri to generate a sample of a distribution having $f_e$ as its density function we can use the following method Generate iid $U_1,U_2,U_3 \sim \operatorname{Uniform}(-1,1)$. If $\left| U_3\right| \geq \left| U_2\right|$ and $\left| U_3\right| \geq \left| U_1\right|$, deliver $U_2$; otherwise deliver $U_3$. I have to prove this works. I thought this was related to either the acceptance-rejection method or maybe order statistics. I have spent a fair bit of time trying both approaches but I am stuck. Any pointers will be greatly appreciated.","So I am really struggling with this problem and could use some help. Consider the Epanechnikov kernel given by $$f_e(x)=\frac{3}{4}\left( 1-x^2 \right)$$ According to Devorye and Gyofri to generate a sample of a distribution having $f_e$ as its density function we can use the following method Generate iid $U_1,U_2,U_3 \sim \operatorname{Uniform}(-1,1)$. If $\left| U_3\right| \geq \left| U_2\right|$ and $\left| U_3\right| \geq \left| U_1\right|$, deliver $U_2$; otherwise deliver $U_3$. I have to prove this works. I thought this was related to either the acceptance-rejection method or maybe order statistics. I have spent a fair bit of time trying both approaches but I am stuck. Any pointers will be greatly appreciated.",,"['statistics', 'order-statistics']"
37,How to derive Clopper-Pearson interval's F and beta approximation?,How to derive Clopper-Pearson interval's F and beta approximation?,,"It is well-known that there is an approximation of the Clopper-Pearson exact Confident Interval for binomial test. Wiki It just simply claimed, without any reference that: Because of a relationship between the cumulative binomial distribution   and the beta distribution, the Clopper-Pearson interval is sometimes   presented in an alternate format that uses quantiles from the beta   distribution. $$B\left(\frac{\alpha}{2}; x, n - x + 1\right) < \theta < B\left(1 - \frac{\alpha}{2}; x + 1, n - x\right) $$ And later I found in C-P that this canbe regarded as an interpolation of the binomial c.d.f. due to the CI-belt discrete arguement. But I still have no clue about how it is derived. $$\left( 1 + \frac{n - x + 1}{x\,\,F\!\left[1 - \frac{1}{2}\alpha; 2x, 2(n - x + 1)\right]} \right)^{-1}< \theta < \left( 1 + \frac{n - x}{\left[x + 1\right]\,F\!\left[\frac{\alpha}{2}; 2(x + 1), 2(n - x)\right]} \right)^{-1} $$ And then Agresti also touched it in his Categorical Data Analysis, 3ed and leave it: ...from connections between binomial sums and the incomplete beta   function and related cdf's of beta and F distributions, the confidence   interval is... Now I want to ask for a reference which gives full details about the proof of this approximation form to Clopper-Pearson CI since I have already spent quite a while on it. FYI: Agresti and C-P did not solve the problem in their papers, I want a paper or a book which fully gives the arguement about the incomplete Beta function calculation since I myself is not familiar with this sort of manipulation. Thanks. The cross-validated link CrossValidated","It is well-known that there is an approximation of the Clopper-Pearson exact Confident Interval for binomial test. Wiki It just simply claimed, without any reference that: Because of a relationship between the cumulative binomial distribution   and the beta distribution, the Clopper-Pearson interval is sometimes   presented in an alternate format that uses quantiles from the beta   distribution. $$B\left(\frac{\alpha}{2}; x, n - x + 1\right) < \theta < B\left(1 - \frac{\alpha}{2}; x + 1, n - x\right) $$ And later I found in C-P that this canbe regarded as an interpolation of the binomial c.d.f. due to the CI-belt discrete arguement. But I still have no clue about how it is derived. $$\left( 1 + \frac{n - x + 1}{x\,\,F\!\left[1 - \frac{1}{2}\alpha; 2x, 2(n - x + 1)\right]} \right)^{-1}< \theta < \left( 1 + \frac{n - x}{\left[x + 1\right]\,F\!\left[\frac{\alpha}{2}; 2(x + 1), 2(n - x)\right]} \right)^{-1} $$ And then Agresti also touched it in his Categorical Data Analysis, 3ed and leave it: ...from connections between binomial sums and the incomplete beta   function and related cdf's of beta and F distributions, the confidence   interval is... Now I want to ask for a reference which gives full details about the proof of this approximation form to Clopper-Pearson CI since I have already spent quite a while on it. FYI: Agresti and C-P did not solve the problem in their papers, I want a paper or a book which fully gives the arguement about the incomplete Beta function calculation since I myself is not familiar with this sort of manipulation. Thanks. The cross-validated link CrossValidated",,"['statistics', 'reference-request', 'binomial-distribution', 'beta-function']"
38,sufficient statistics of a sequence of normal random variable,sufficient statistics of a sequence of normal random variable,,"If $X_1, X_2\ldots,X_n$ are independent variables with $X_i \sim \mathcal N(i\theta,1)$, $\theta$ is an unknown parameter. What is a one dimensional sufficient statistic $T$ of this sample? I have a intuition guess that the answer is $\frac{1}{n}\sum_{i=1}^n \frac{X_i}{i}$, but I don't know how to prove it through definition or get it using factorization. Can anyone give me a hint on how to derive it? Thanks!","If $X_1, X_2\ldots,X_n$ are independent variables with $X_i \sim \mathcal N(i\theta,1)$, $\theta$ is an unknown parameter. What is a one dimensional sufficient statistic $T$ of this sample? I have a intuition guess that the answer is $\frac{1}{n}\sum_{i=1}^n \frac{X_i}{i}$, but I don't know how to prove it through definition or get it using factorization. Can anyone give me a hint on how to derive it? Thanks!",,"['statistics', 'sufficient-statistics']"
39,Is this alternative hypothesis valid?,Is this alternative hypothesis valid?,,"Could anyone check that the alternative hypothesis is making sense? I wanted to prove that the ""Mahalanobis distance ($\mathbf{(x_i - \bar{x})^T \Sigma^{-1}(x_i - \bar{x})}$)"" is a Log Likelihood Ratio Test statistics. For validating the following hypothesis, (all notations are vector notation) \begin{cases} H_0 : \mathbf{x_i} \sim N(\mathbf{x_i} | \mathbf{\mu, \Sigma})  \\  H_1 : \mathbf{x_i} \sim N(\mathbf{x_i} | \mathbf{\mu + \delta_i,  \Sigma}),\;\; \mathbf{\delta_i := (x_i - \bar{x})} \end{cases} I used the Log Likelihood Ratio Test (LRT) as followed. \begin{split}  \lambda_i &= \log \left( \frac{ N(\mathbf{x_i} |  \mathbf{\mu + \delta_i, \Sigma} )  }{N(\mathbf{x_i} | \mathbf{\mu, \Sigma} )} \right) \\  &= -\frac{1}{2} \left( (\mathbf{x_i - \mu - \delta_i})^T\mathbf{\Sigma}^{-1}(\mathbf{x_i - \mu - \delta_i}) - (\mathbf{x_i - \mu})^T \mathbf{\Sigma}^{-1}(\mathbf{x_i - \mu})\right) \\  &= -\frac{1}{2} \left( \mathbf{\delta_i}^T \mathbf{\Sigma}^{-1}\mathbf{\delta_i} - 2(\mathbf{x_i - \bar{x}})^T\mathbf{\Sigma}^{-1}\mathbf{\delta_i} \right)\\ & \approx \frac{1}{2} (\mathbf{x-\bar{x}})^T \mathbf{\Sigma}^{-1}(\mathbf{x-\bar{x}}) \end{split} One thing that I cannot be certain is that the alternative hypothesis (H1) can have such a form (dependent to xi). Is the above hypothesis testing formulation valid?","Could anyone check that the alternative hypothesis is making sense? I wanted to prove that the ""Mahalanobis distance ($\mathbf{(x_i - \bar{x})^T \Sigma^{-1}(x_i - \bar{x})}$)"" is a Log Likelihood Ratio Test statistics. For validating the following hypothesis, (all notations are vector notation) \begin{cases} H_0 : \mathbf{x_i} \sim N(\mathbf{x_i} | \mathbf{\mu, \Sigma})  \\  H_1 : \mathbf{x_i} \sim N(\mathbf{x_i} | \mathbf{\mu + \delta_i,  \Sigma}),\;\; \mathbf{\delta_i := (x_i - \bar{x})} \end{cases} I used the Log Likelihood Ratio Test (LRT) as followed. \begin{split}  \lambda_i &= \log \left( \frac{ N(\mathbf{x_i} |  \mathbf{\mu + \delta_i, \Sigma} )  }{N(\mathbf{x_i} | \mathbf{\mu, \Sigma} )} \right) \\  &= -\frac{1}{2} \left( (\mathbf{x_i - \mu - \delta_i})^T\mathbf{\Sigma}^{-1}(\mathbf{x_i - \mu - \delta_i}) - (\mathbf{x_i - \mu})^T \mathbf{\Sigma}^{-1}(\mathbf{x_i - \mu})\right) \\  &= -\frac{1}{2} \left( \mathbf{\delta_i}^T \mathbf{\Sigma}^{-1}\mathbf{\delta_i} - 2(\mathbf{x_i - \bar{x}})^T\mathbf{\Sigma}^{-1}\mathbf{\delta_i} \right)\\ & \approx \frac{1}{2} (\mathbf{x-\bar{x}})^T \mathbf{\Sigma}^{-1}(\mathbf{x-\bar{x}}) \end{split} One thing that I cannot be certain is that the alternative hypothesis (H1) can have such a form (dependent to xi). Is the above hypothesis testing formulation valid?",,"['statistics', 'hypothesis-testing']"
40,How to perform nonlinear regression with regressors affected by gaussian error?,How to perform nonlinear regression with regressors affected by gaussian error?,,"I am trying to calibrate a sensor and I have a data set consisting of several observations of a 3-dimensional vector $X_i$, with $X_i=w_i + \epsilon_i$ where $w_i$ is the value that the sensor should measure (if uncalibrated but unaffected by noise) which is fixed for each $i$ and unobservable, and $\epsilon_i$ is gaussian error vector with zero mean and a known diagonal covariance matrix, which is the same for all $i$. The error vectors $\epsilon_i$ are uncorrelated for different $i$. The response variable is $Y_i=\|C(w_i-B)\|=1$ for all $i$. $C$ is a 3x3 matrix that can be eigendecomposed by $C=R(\psi,\theta,\phi)\,E\,R(\psi,\theta,\phi)^T$, where $R$ is a rotation matrix parametrized by the three angles $\psi,\theta,\phi$. $E$ is a diagonal matrix where each entry in the diagonal is positive and bounded from above by a known value. $B$ is a 3x1 vector. This is a typical nonlinear regression with additive measurement error, but without additional additive error in $Y$ (as opposed to the traditional setting of this problem that I have seen so far). Is it possible to obtain an unbiased estimate of the model parameters $p$ (the three attitude angles that parametrize $R$, the three diagonal entries of $E$ and the vector $B$) from the observations $X_i$? Alternatively, is there a way to find out if solving the nonlinear least squares problem $\hat{p}= \min_p \sum_{i=1}^n (\|C(X_i-B)\|-1)^2$ yields an unbiased estimate of $p$?","I am trying to calibrate a sensor and I have a data set consisting of several observations of a 3-dimensional vector $X_i$, with $X_i=w_i + \epsilon_i$ where $w_i$ is the value that the sensor should measure (if uncalibrated but unaffected by noise) which is fixed for each $i$ and unobservable, and $\epsilon_i$ is gaussian error vector with zero mean and a known diagonal covariance matrix, which is the same for all $i$. The error vectors $\epsilon_i$ are uncorrelated for different $i$. The response variable is $Y_i=\|C(w_i-B)\|=1$ for all $i$. $C$ is a 3x3 matrix that can be eigendecomposed by $C=R(\psi,\theta,\phi)\,E\,R(\psi,\theta,\phi)^T$, where $R$ is a rotation matrix parametrized by the three angles $\psi,\theta,\phi$. $E$ is a diagonal matrix where each entry in the diagonal is positive and bounded from above by a known value. $B$ is a 3x1 vector. This is a typical nonlinear regression with additive measurement error, but without additional additive error in $Y$ (as opposed to the traditional setting of this problem that I have seen so far). Is it possible to obtain an unbiased estimate of the model parameters $p$ (the three attitude angles that parametrize $R$, the three diagonal entries of $E$ and the vector $B$) from the observations $X_i$? Alternatively, is there a way to find out if solving the nonlinear least squares problem $\hat{p}= \min_p \sum_{i=1}^n (\|C(X_i-B)\|-1)^2$ yields an unbiased estimate of $p$?",,"['statistics', 'regression']"
41,Bivariate Normal Distribution Problem vs Marginals,Bivariate Normal Distribution Problem vs Marginals,,"If $X_1 \sim N(0,1)$ and $X_2 \sim N(X_1^2, 1)$ then does $(X_1, X_2)$ follow a bivariate normal distribution? My thinking is that $X_1 ^2$ is $\chi^2_1 $ since it's the square of a $N(0,1)$ random variable. And then since $X_2$ has a $\chi^2_1$ as its mean, the joint can't be normal? Thanks for any help!","If $X_1 \sim N(0,1)$ and $X_2 \sim N(X_1^2, 1)$ then does $(X_1, X_2)$ follow a bivariate normal distribution? My thinking is that $X_1 ^2$ is $\chi^2_1 $ since it's the square of a $N(0,1)$ random variable. And then since $X_2$ has a $\chi^2_1$ as its mean, the joint can't be normal? Thanks for any help!",,['statistics']
42,showing that $E[(\hat\theta -\theta)^2] \lt Var(\bar X)=\dfrac{1}{n}$. [closed],showing that . [closed],E[(\hat\theta -\theta)^2] \lt Var(\bar X)=\dfrac{1}{n},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Suppose $X_1, X_2, \dots, X_n$ are i.i.d $N(\theta, 1),\theta_0 \lt\theta$ ,  Find the MLE of $\theta$ and show that it is better than the sample mean $\bar X$ in the sense of having smaller mean squared error. Trial: Here MLE of $\theta$ is $$\hat\theta = \begin{cases} \theta_0, &\bar X \lt \theta_0\\ \bar X, &\theta_0 \le \bar X  \\ \end{cases}$$ I can't show that $E[(\hat\theta -\theta)^2] \lt Var(\bar X)=\dfrac{1}{n}$.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Suppose $X_1, X_2, \dots, X_n$ are i.i.d $N(\theta, 1),\theta_0 \lt\theta$ ,  Find the MLE of $\theta$ and show that it is better than the sample mean $\bar X$ in the sense of having smaller mean squared error. Trial: Here MLE of $\theta$ is $$\hat\theta = \begin{cases} \theta_0, &\bar X \lt \theta_0\\ \bar X, &\theta_0 \le \bar X  \\ \end{cases}$$ I can't show that $E[(\hat\theta -\theta)^2] \lt Var(\bar X)=\dfrac{1}{n}$.",,"['statistics', 'statistical-inference']"
43,sampling from a multivariate guassian: intuition behind using cholesky decomposition,sampling from a multivariate guassian: intuition behind using cholesky decomposition,,"I'm trying to understand how sampling from a multivariate gaussian works and why the cholesky decomposition is a way to do it. Let's say we have a 25 dimensional multivariate with a 25x25 covariance matrix formed by using an RBF kernel. We want one sample which would have 25 points. One way to do this is multiply the lower triangular matrix (from a cholesky decomposition) with a 25x1 vector of sampled points from a univariate guassian. Furthermore, the following shows the relationship when predicting f2 given f1. This intuitively makes sense to me and I verified that the calculations using the lower triangular matrix comes out to this. However, I do not understand the intuition behind the calculations for the third point in this sample. I believe both the mean and variance of that point would be affected by f1, f2 as well as the covariances for those two points, but how exactly? I'm not sure how to think about what the distribution for f3, f4, f5 ... fn looks like. How are those calculated and how are they affected by the distributions before them?","I'm trying to understand how sampling from a multivariate gaussian works and why the cholesky decomposition is a way to do it. Let's say we have a 25 dimensional multivariate with a 25x25 covariance matrix formed by using an RBF kernel. We want one sample which would have 25 points. One way to do this is multiply the lower triangular matrix (from a cholesky decomposition) with a 25x1 vector of sampled points from a univariate guassian. Furthermore, the following shows the relationship when predicting f2 given f1. This intuitively makes sense to me and I verified that the calculations using the lower triangular matrix comes out to this. However, I do not understand the intuition behind the calculations for the third point in this sample. I believe both the mean and variance of that point would be affected by f1, f2 as well as the covariances for those two points, but how exactly? I'm not sure how to think about what the distribution for f3, f4, f5 ... fn looks like. How are those calculated and how are they affected by the distributions before them?",,"['statistics', 'normal-distribution', 'covariance']"
44,"Deriving $Cov(X,Y,Z)$, is it even a thing?","Deriving , is it even a thing?","Cov(X,Y,Z)","So I am trying to derive a nice general formula for $Cov(X,Y,Z)$ and $Corr(X,Y,Z)$, I defined it as such  $$ Cov(X,Y,Z) = E[(X-E[X])(Y-E[Y])(Z-E[Z])] $$ $$ Corr(X,Y,Z) = \frac {Cov(X,Y,Z)} {\sqrt{Var[X]Var[Y]Var[Z]}} $$ Now doing some algebra got me to this expression:  $$ Cov(X,Y,Z) = E[XYZ]-E[Z]E[XY]-E[X]E[ZY]-E[Y]E[XZ]+2E[X]E[Y]E[Z] $$ When I apply this formula however, my correlation is sometimes over 1 and below -1. I have two questions: 1) Is the covariance ever defined this way (because I notice people always refer to the covariance matrix)? 2) Was my algebra wrong, or is the property $ |COV|\le1 $ is not transferable to 3 r.v.s?","So I am trying to derive a nice general formula for $Cov(X,Y,Z)$ and $Corr(X,Y,Z)$, I defined it as such  $$ Cov(X,Y,Z) = E[(X-E[X])(Y-E[Y])(Z-E[Z])] $$ $$ Corr(X,Y,Z) = \frac {Cov(X,Y,Z)} {\sqrt{Var[X]Var[Y]Var[Z]}} $$ Now doing some algebra got me to this expression:  $$ Cov(X,Y,Z) = E[XYZ]-E[Z]E[XY]-E[X]E[ZY]-E[Y]E[XZ]+2E[X]E[Y]E[Z] $$ When I apply this formula however, my correlation is sometimes over 1 and below -1. I have two questions: 1) Is the covariance ever defined this way (because I notice people always refer to the covariance matrix)? 2) Was my algebra wrong, or is the property $ |COV|\le1 $ is not transferable to 3 r.v.s?",,"['statistics', 'expectation', 'covariance']"
45,Can the limit of the MSE of an estimator be infinity?,Can the limit of the MSE of an estimator be infinity?,,"Is it ever possible for the limit of the MSE of an estimator be infinity? I was doing an exercise and it turns out that the estimator is consistent but the limit of the MSE is infinity, so I am wondering if this result makes sense or did I make a mistake somewhere. I do know that just because the estimator is consistent, that does not mean that the limit of its MSE must be 0. But I did not expect that the limit of an MSE can ever be infinity. If this is true, then what is the interpretation of this kind of estimator?","Is it ever possible for the limit of the MSE of an estimator be infinity? I was doing an exercise and it turns out that the estimator is consistent but the limit of the MSE is infinity, so I am wondering if this result makes sense or did I make a mistake somewhere. I do know that just because the estimator is consistent, that does not mean that the limit of its MSE must be 0. But I did not expect that the limit of an MSE can ever be infinity. If this is true, then what is the interpretation of this kind of estimator?",,"['statistics', 'estimation']"
46,How big should the sample size be to disprove this article?,How big should the sample size be to disprove this article?,,There is a new poker computer that is claimed to be unbeatable. http://www.theguardian.com/science/2015/jan/08/poker-program-cepheus-unbeatable I beat this computer on my first try today but my friend says that my 100 rounds against the computer was too small of a sample size to prove that the computer's strategy is not optimal. How big should my sample size be? Edit: This is heads up texas hold'em poker (1 vs 1),There is a new poker computer that is claimed to be unbeatable. http://www.theguardian.com/science/2015/jan/08/poker-program-cepheus-unbeatable I beat this computer on my first try today but my friend says that my 100 rounds against the computer was too small of a sample size to prove that the computer's strategy is not optimal. How big should my sample size be? Edit: This is heads up texas hold'em poker (1 vs 1),,['statistics']
47,"A conditional normal rv sequence, does the mean converges in probability","A conditional normal rv sequence, does the mean converges in probability",,"$X_1, X_2, \dots, X_n$, are $n$ mutually independent r.v.s. $Y_1,\dots,Y_n$ are another set of mutually independent r.v.s. $X_k\mid Y_k=y_k\sim N(y_k,y_k^2)$ and $Y_k\sim\text{uniform}(-k,k)$ for $k=1,\dots,n$. Define $\bar{X}_n=\frac{\sum_{i=1}^nX_i}{n}$ the sample mean of $X_i$'s. I've calculated E$[\bar{X}_n]=0$ and Var$(\bar{X}_n)=\frac{n(n+1)(2n+1)}{9n^2}=\frac{(n+1)(2n+1)}{9n}$. How can we prove that $\bar{X}_n$ doesn't converge to E$[\bar{X}_n]$ in probability? Thanks!","$X_1, X_2, \dots, X_n$, are $n$ mutually independent r.v.s. $Y_1,\dots,Y_n$ are another set of mutually independent r.v.s. $X_k\mid Y_k=y_k\sim N(y_k,y_k^2)$ and $Y_k\sim\text{uniform}(-k,k)$ for $k=1,\dots,n$. Define $\bar{X}_n=\frac{\sum_{i=1}^nX_i}{n}$ the sample mean of $X_i$'s. I've calculated E$[\bar{X}_n]=0$ and Var$(\bar{X}_n)=\frac{n(n+1)(2n+1)}{9n^2}=\frac{(n+1)(2n+1)}{9n}$. How can we prove that $\bar{X}_n$ doesn't converge to E$[\bar{X}_n]$ in probability? Thanks!",,"['statistics', 'convergence-divergence', 'central-limit-theorem']"
48,Standard Deviation of 2D vector data,Standard Deviation of 2D vector data,,"Given a sample set of wind data (speed and direction parallel to the earth), I would like to identify the consistency of wind samples. Standard deviation comes to mind, but I don't know if it is appropriate for use with vector data. I am proposing that the mean vector $\vec{V}$ is defined as: $\vec{V} = \frac{1}{N} \sum_{i=1}^N \vec{v}_i$ And the standard deviation $s$ is defined as: $s = \sqrt{\frac{1}{N-1} \sum_{i=1}^N (\vec{v}_i - \vec{V})^2}.$ Is this sort of calculation ever used? Is it statistically relevant, or is there a better way of measuring variation in vector data?","Given a sample set of wind data (speed and direction parallel to the earth), I would like to identify the consistency of wind samples. Standard deviation comes to mind, but I don't know if it is appropriate for use with vector data. I am proposing that the mean vector $\vec{V}$ is defined as: $\vec{V} = \frac{1}{N} \sum_{i=1}^N \vec{v}_i$ And the standard deviation $s$ is defined as: $s = \sqrt{\frac{1}{N-1} \sum_{i=1}^N (\vec{v}_i - \vec{V})^2}.$ Is this sort of calculation ever used? Is it statistically relevant, or is there a better way of measuring variation in vector data?",,"['statistics', 'vectors', 'standard-deviation']"
49,Bayesian Shrinkage Factor,Bayesian Shrinkage Factor,,"Vasicek(1973), referenced in this paper (See bottom of page 16) explains a method of shrinking individual betas $\beta^{TS}$ toward a cross-sectional mean $\beta^{XS}$ as follows: for each time $t$, the shrinkage $\beta$ for stock $i$ is defined as; $\beta_i^{shrink} = w_i * \beta_i^{TS} + (1 - w_i) * \beta^{XS}$ The shrinkage weight is defined as: $w_i = 1 - \frac{\sigma_{i,TS}^2}{\sigma_{i,TS}^2 + \sigma_{XS}^2}$ where  $\sigma_{i,TS}^2$ is the variance of the individual beta, and where $\sigma^2_{XS}$ is the variance of the cross-sectional variance of betas (dispersion of betas in the cross-section). I would like to extend this methodology as follows: Imagine now I have standard deviation estimates, instead of beta estimates, that I would like to shrink. I have individual standard deviation values $s_i^{TS}$ and a cross-sectional standard deviation value $s^{XS}$ at each time $t$. I would like to do the following: $s^2_{i,shrink} = w_i * s^2_{i, TS} + (1 - w_i) * s^2_{XS}$ How can best define the shrinkage weight $w_i$ in this case? Thanks!","Vasicek(1973), referenced in this paper (See bottom of page 16) explains a method of shrinking individual betas $\beta^{TS}$ toward a cross-sectional mean $\beta^{XS}$ as follows: for each time $t$, the shrinkage $\beta$ for stock $i$ is defined as; $\beta_i^{shrink} = w_i * \beta_i^{TS} + (1 - w_i) * \beta^{XS}$ The shrinkage weight is defined as: $w_i = 1 - \frac{\sigma_{i,TS}^2}{\sigma_{i,TS}^2 + \sigma_{XS}^2}$ where  $\sigma_{i,TS}^2$ is the variance of the individual beta, and where $\sigma^2_{XS}$ is the variance of the cross-sectional variance of betas (dispersion of betas in the cross-section). I would like to extend this methodology as follows: Imagine now I have standard deviation estimates, instead of beta estimates, that I would like to shrink. I have individual standard deviation values $s_i^{TS}$ and a cross-sectional standard deviation value $s^{XS}$ at each time $t$. I would like to do the following: $s^2_{i,shrink} = w_i * s^2_{i, TS} + (1 - w_i) * s^2_{XS}$ How can best define the shrinkage weight $w_i$ in this case? Thanks!",,"['statistics', 'standard-deviation', 'bayesian']"
50,Proof for the distribution of a two-sample t-test with unequal population variances.,Proof for the distribution of a two-sample t-test with unequal population variances.,,"I am having trouble finding documentation showing a proof, or at least some outline for it, illustrating how to derive the distribution and degrees of freedom of the test statistic for a two-sample t-test when the population variances are assumed to be different, $\sigma_1^2\ne \sigma_2^2$. If $ \overline{X}=\frac{1}{n_1}\sum\limits_{i=1}^{n_1}X_i$ where $X_1, \ldots, X_{n_1}$ are i.i.d. $\text{N}\left(\mu_1, \sigma_1^2 \right)$, $ \overline{Y}=\frac{1}{n_2}\sum\limits_{i=1}^{n_2}Y_i$ where $Y_1, \ldots, Y_{n_2}$ are i.i.d. $\text{N}\left(\mu_2, \sigma_2^2 \right)$, $S_1^2$ and $S_2^2$ are the unbiased sample variances for $X_i$ and $Y_i$ respectively, the t-statistic is: $$\frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{S_1^2}{n_1}+\frac{S_2^2}{n_2}}}\sim t(\nu) $$ which has a t-distribution with $\nu$ degrees of freedom equal to: $$\Large \nu=\frac{\left(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2} \right)^2}{\frac{\left(\frac{s_1^2}{n_1} \right)^2}{n_1-1}+\frac{\left(\frac{s_2^2}{n_2}\right)^2}{n_2-1}}  $$ Actually, I read that this statistic only approximates a t-distribution. Regardless, is there any resource where I can read more about this? I only see resources citing this result with no references giving/outlining a proof for this.","I am having trouble finding documentation showing a proof, or at least some outline for it, illustrating how to derive the distribution and degrees of freedom of the test statistic for a two-sample t-test when the population variances are assumed to be different, $\sigma_1^2\ne \sigma_2^2$. If $ \overline{X}=\frac{1}{n_1}\sum\limits_{i=1}^{n_1}X_i$ where $X_1, \ldots, X_{n_1}$ are i.i.d. $\text{N}\left(\mu_1, \sigma_1^2 \right)$, $ \overline{Y}=\frac{1}{n_2}\sum\limits_{i=1}^{n_2}Y_i$ where $Y_1, \ldots, Y_{n_2}$ are i.i.d. $\text{N}\left(\mu_2, \sigma_2^2 \right)$, $S_1^2$ and $S_2^2$ are the unbiased sample variances for $X_i$ and $Y_i$ respectively, the t-statistic is: $$\frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{S_1^2}{n_1}+\frac{S_2^2}{n_2}}}\sim t(\nu) $$ which has a t-distribution with $\nu$ degrees of freedom equal to: $$\Large \nu=\frac{\left(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2} \right)^2}{\frac{\left(\frac{s_1^2}{n_1} \right)^2}{n_1-1}+\frac{\left(\frac{s_2^2}{n_2}\right)^2}{n_2-1}}  $$ Actually, I read that this statistic only approximates a t-distribution. Regardless, is there any resource where I can read more about this? I only see resources citing this result with no references giving/outlining a proof for this.",,"['statistics', 'probability-distributions']"
51,Holt's linear trend method and optimal smoothing parameters,Holt's linear trend method and optimal smoothing parameters,,"I am learning about time series and forecasting and I stumbled across exponential smoothing and other derived methods. In an exponential smoothing model, each prediction is given by a level equation together with a smoothing equation, namely $$\begin{array}{l} \tilde{y}_{t+1} = \ell_t, \\ \ell_t = \alpha y_{t-1} + (1-\alpha)\ell_{t-1}. \end{array}$$ The forecaster can guess $\alpha$ based in different reasons and not all of them are necessarely purely mathematical, but it is usual to estimate it by minimizing the sum of the squared errors. That is, considering a one-step forecast model and then miniziming the sum $$\sum_{t = 2}^N e_t^2 = \sum_{t=2}^N\left(\tilde{y}_t-y_t\right)^2$$ where in this one-step model we consider $\ell_{t-2}=y_{t-2}$, so we have $$\tilde{y}_t=\ell_t=\alpha y_{t-1} + (1-\alpha)y_{t-2}.$$ Performing the necessary calculations we can derive the formula $$\alpha = \cfrac{ \sum_{t=2}^N(y_{t}-y_{t-2})(y_{t-1}-y_{t-2})}{ \sum_{t=2}^N (y_{t-1}-y_{t-2})^2}.$$ Exponential smoothing can be upgraded to a method that takes trends into account, this is the so-called Holt's linear trend method and is given by the following expressions: $$\begin{array}{l} \tilde{y}_{t+h} = \ell_t + hb_t, \\ \ell_t = \alpha y_{t-1} + (1-\alpha)(\ell_{t-2} + b_{t-2}),\\ b_t=\beta(\ell_t-\ell_{t-1})+(1-\beta)b_{t-2}. \end{array}$$ In order to estimate the parameters $\alpha$ and $\beta$, all the literature I've been able to read suggests to follow the same path as with regular exponential smoothing, that is, minimizing the squared error, but none does actually give any insights on the process. This is where I decided to try it myself, taking the same approach: we consider a one-step forecast model, so $h=1$ and the equations are thus given by $$\begin{array}{l} \tilde{y}_{t} = \ell_{t-1} + b_{t-1}, \\ \ell_{t-1} = \alpha y_{t-1} + (1-\alpha)(2y_{t-2} - y_{t-1}),\\ b_{t-1}=\beta(\ell_{t-1}-y_{t-2})+(1-\beta)(y_{t-2}-y_{t-1}). \end{array}$$ More precissely, we are considering $\ell_{t-2} = y_{t-2}$ and $b_{t-2} = y_{t-2}-y_{t-1}$ ($b_t$ is meant to be the slope of the straight line going through the last couple of points before the forecast one). Minimizing the squred error now requires performing multi-variable optimization, so taking both derivatives and equalising to zero I get, after many calculations, the following formula: $$\beta = \frac{ \sum_{t=3}^N (2y_{t-2}-y_{t-3}-y_{t-1})(3y_{t-2}-2y_{t-3}-y_t)}{\alpha \sum_{t=3}^N (y_{t-1}-2y_{t-2}+y_{t-3})^2} - 1.$$ Now, the problem here is that I get the same expression for both derivatives, namely that both $$\frac{\partial}{\partial \alpha} \sum_{t=3}^N e_t^2 = 0$$ and $$\frac{\partial}{\partial \beta} \sum_{t=3}^N e_t^2 = 0$$ will lead to the same formula, implying that the system has infinitely many solutions and that there is actually a whole curve of minima. Personally, I find this hard to believe but no matter how much I look to my computations I won't find any mistakes. My question is if my reasoning is correct and if somebody could verify my approach. In case that this is indeed correct, would it be reasonable to estimate $\alpha$ as if in regular exponential smoothing and then use this parameter to estimate a $\beta$ for Holt's method? Thank you very much.","I am learning about time series and forecasting and I stumbled across exponential smoothing and other derived methods. In an exponential smoothing model, each prediction is given by a level equation together with a smoothing equation, namely $$\begin{array}{l} \tilde{y}_{t+1} = \ell_t, \\ \ell_t = \alpha y_{t-1} + (1-\alpha)\ell_{t-1}. \end{array}$$ The forecaster can guess $\alpha$ based in different reasons and not all of them are necessarely purely mathematical, but it is usual to estimate it by minimizing the sum of the squared errors. That is, considering a one-step forecast model and then miniziming the sum $$\sum_{t = 2}^N e_t^2 = \sum_{t=2}^N\left(\tilde{y}_t-y_t\right)^2$$ where in this one-step model we consider $\ell_{t-2}=y_{t-2}$, so we have $$\tilde{y}_t=\ell_t=\alpha y_{t-1} + (1-\alpha)y_{t-2}.$$ Performing the necessary calculations we can derive the formula $$\alpha = \cfrac{ \sum_{t=2}^N(y_{t}-y_{t-2})(y_{t-1}-y_{t-2})}{ \sum_{t=2}^N (y_{t-1}-y_{t-2})^2}.$$ Exponential smoothing can be upgraded to a method that takes trends into account, this is the so-called Holt's linear trend method and is given by the following expressions: $$\begin{array}{l} \tilde{y}_{t+h} = \ell_t + hb_t, \\ \ell_t = \alpha y_{t-1} + (1-\alpha)(\ell_{t-2} + b_{t-2}),\\ b_t=\beta(\ell_t-\ell_{t-1})+(1-\beta)b_{t-2}. \end{array}$$ In order to estimate the parameters $\alpha$ and $\beta$, all the literature I've been able to read suggests to follow the same path as with regular exponential smoothing, that is, minimizing the squared error, but none does actually give any insights on the process. This is where I decided to try it myself, taking the same approach: we consider a one-step forecast model, so $h=1$ and the equations are thus given by $$\begin{array}{l} \tilde{y}_{t} = \ell_{t-1} + b_{t-1}, \\ \ell_{t-1} = \alpha y_{t-1} + (1-\alpha)(2y_{t-2} - y_{t-1}),\\ b_{t-1}=\beta(\ell_{t-1}-y_{t-2})+(1-\beta)(y_{t-2}-y_{t-1}). \end{array}$$ More precissely, we are considering $\ell_{t-2} = y_{t-2}$ and $b_{t-2} = y_{t-2}-y_{t-1}$ ($b_t$ is meant to be the slope of the straight line going through the last couple of points before the forecast one). Minimizing the squred error now requires performing multi-variable optimization, so taking both derivatives and equalising to zero I get, after many calculations, the following formula: $$\beta = \frac{ \sum_{t=3}^N (2y_{t-2}-y_{t-3}-y_{t-1})(3y_{t-2}-2y_{t-3}-y_t)}{\alpha \sum_{t=3}^N (y_{t-1}-2y_{t-2}+y_{t-3})^2} - 1.$$ Now, the problem here is that I get the same expression for both derivatives, namely that both $$\frac{\partial}{\partial \alpha} \sum_{t=3}^N e_t^2 = 0$$ and $$\frac{\partial}{\partial \beta} \sum_{t=3}^N e_t^2 = 0$$ will lead to the same formula, implying that the system has infinitely many solutions and that there is actually a whole curve of minima. Personally, I find this hard to believe but no matter how much I look to my computations I won't find any mistakes. My question is if my reasoning is correct and if somebody could verify my approach. In case that this is indeed correct, would it be reasonable to estimate $\alpha$ as if in regular exponential smoothing and then use this parameter to estimate a $\beta$ for Holt's method? Thank you very much.",,"['statistics', 'optimization', 'time-series', 'parameter-estimation']"
52,Bayesian linear regression cost function,Bayesian linear regression cost function,,"I am studying classification using linear regression . Now, I want to map it in Bayesian regression. Let talk about binary classification using linear regression again. Assume that I have a set $X=${$x_1,x_2...x_n$} and binary lable $y$={$0,1$}. Binary classification using linear regression task can embedded in to minimum loss function, where: $h(x)=ax+b$ is linear regression line.  $$L=\sum(h(x)-y)^2$$ It is very clear fomular and discussed in lecture note . Now I want to map it in Bayesian rule. Bayesian rule can express: $$\max(p(y=0;1\mid X,a,b))$$ We have: $$p(y=0;1\mid X,a,b)=p(X\mid y,a,b)\cdot P(X)$$ Hence, the loss function with Bayesian classification case are given $$L_{Bayesian}=\sum(p(X\mid y=1,a,b)\cdot P(X)-p(X\mid y=0,a,b)\cdot P(X))$$ Is the Bayesian's loss fomular correct? Thank you so much.","I am studying classification using linear regression . Now, I want to map it in Bayesian regression. Let talk about binary classification using linear regression again. Assume that I have a set $X=${$x_1,x_2...x_n$} and binary lable $y$={$0,1$}. Binary classification using linear regression task can embedded in to minimum loss function, where: $h(x)=ax+b$ is linear regression line.  $$L=\sum(h(x)-y)^2$$ It is very clear fomular and discussed in lecture note . Now I want to map it in Bayesian rule. Bayesian rule can express: $$\max(p(y=0;1\mid X,a,b))$$ We have: $$p(y=0;1\mid X,a,b)=p(X\mid y,a,b)\cdot P(X)$$ Hence, the loss function with Bayesian classification case are given $$L_{Bayesian}=\sum(p(X\mid y=1,a,b)\cdot P(X)-p(X\mid y=0,a,b)\cdot P(X))$$ Is the Bayesian's loss fomular correct? Thank you so much.",,"['linear-algebra', 'statistics', 'regression', 'bayesian']"
53,Should I use odds ratio or risk ratio?,Should I use odds ratio or risk ratio?,,"I am doing a retrospective cohort study with sample size 600 and disease prevalence rate greater than 10%. I am leaning more towards using risk ratio because it is easier to interpret and because disease prevalence is over 10%. Do you have any thoughts on this matter? Also, if possible can someone briefly explain the differences between odds ratio and risk ratio? A specific and brief example would be helpful. Thanks in advance.","I am doing a retrospective cohort study with sample size 600 and disease prevalence rate greater than 10%. I am leaning more towards using risk ratio because it is easier to interpret and because disease prevalence is over 10%. Do you have any thoughts on this matter? Also, if possible can someone briefly explain the differences between odds ratio and risk ratio? A specific and brief example would be helpful. Thanks in advance.",,['statistics']
54,What is the math symbol ~ with ind over it?,What is the math symbol ~ with ind over it?,,The symbol I'm talking about is from a statistics article here:,The symbol I'm talking about is from a statistics article here:,,"['statistics', 'notation', 'noise']"
55,Confidence intervals for the variance. What if data is not normally distributed?,Confidence intervals for the variance. What if data is not normally distributed?,,"I am writing an essay about confidence intervals for the variance and there is a lot of information available under the assumption that our data is normally distributed, but there is not much said about other possible distributions. How can we find confidence intervals for the variance if we assume our data is e.g. uniformly distributed? Can it be done? Can it be done for other distributions?","I am writing an essay about confidence intervals for the variance and there is a lot of information available under the assumption that our data is normally distributed, but there is not much said about other possible distributions. How can we find confidence intervals for the variance if we assume our data is e.g. uniformly distributed? Can it be done? Can it be done for other distributions?",,['statistics']
56,Statistics of Lists,Statistics of Lists,,"To start, let me say i am a programmer and not a math wiz, so this question might be very simple. I have a data set of prices that sort of looks like this 1399.00 13.99 13.97 13.83 13.48 ... ~9 So what happens is everyone ""bids"" a few cents lower than everyone else, and one person had an ""error"" that resulted in 1399 isk instead of 13.99 (I cannot sanitize the data, read on) The data is presented to me in the following XML format: <marketstat><type id=""34""> <buy> <volume>16831614476</volume> <avg>4.60</avg> <max>4.73</max> <min>2.96</min> <stddev>0.45</stddev> <median>4.69</median> <percentile>4.72</percentile> </buy> Using only these data points, is it possible to predict the ""true"" max, ie discard the ridiculously high price and provide a value near the ""max""?","To start, let me say i am a programmer and not a math wiz, so this question might be very simple. I have a data set of prices that sort of looks like this 1399.00 13.99 13.97 13.83 13.48 ... ~9 So what happens is everyone ""bids"" a few cents lower than everyone else, and one person had an ""error"" that resulted in 1399 isk instead of 13.99 (I cannot sanitize the data, read on) The data is presented to me in the following XML format: <marketstat><type id=""34""> <buy> <volume>16831614476</volume> <avg>4.60</avg> <max>4.73</max> <min>2.96</min> <stddev>0.45</stddev> <median>4.69</median> <percentile>4.72</percentile> </buy> Using only these data points, is it possible to predict the ""true"" max, ie discard the ridiculously high price and provide a value near the ""max""?",,['statistics']
57,Please verify this Proportion Hypothesis Test (Statistics),Please verify this Proportion Hypothesis Test (Statistics),,"Questions: $120$ voters, $39$ identify with radical movement. does this provide sufficient evidence that more than $25\%$ of voters identify with radical movement? use $p$-value approach. My Steps: (0) Check Requirements $(120)(.25)>10$ and $(120)(.75)>10$ -- passes requirements. (1) Hypothesis will be using a right tailed test. $H_0 : p = .25; H_1 : p > .25$ (2) No alpha (level of significance) is given, so default to $0.05$. (3) $Z_t (\text{Test Statistic}) = ((.325-.25)/(\sqrt{(.25)(.75)/120} = 1.897$ (4) $P(Z \ge 1.897) \ge 1 - (\text{about}).9713 = .0287$. Reject $H_o$ if $p$-value is less than alpha. (5) At the $.05$ level of significance, there is sufficient evidence to support that more than $25\%$ of voters identify with the radical movement. Does that all look correct? Thank you :-)","Questions: $120$ voters, $39$ identify with radical movement. does this provide sufficient evidence that more than $25\%$ of voters identify with radical movement? use $p$-value approach. My Steps: (0) Check Requirements $(120)(.25)>10$ and $(120)(.75)>10$ -- passes requirements. (1) Hypothesis will be using a right tailed test. $H_0 : p = .25; H_1 : p > .25$ (2) No alpha (level of significance) is given, so default to $0.05$. (3) $Z_t (\text{Test Statistic}) = ((.325-.25)/(\sqrt{(.25)(.75)/120} = 1.897$ (4) $P(Z \ge 1.897) \ge 1 - (\text{about}).9713 = .0287$. Reject $H_o$ if $p$-value is less than alpha. (5) At the $.05$ level of significance, there is sufficient evidence to support that more than $25\%$ of voters identify with the radical movement. Does that all look correct? Thank you :-)",,['statistics']
58,Boltzmann machines - motivation for the energy function,Boltzmann machines - motivation for the energy function,,"I've been studying Boltzmann machines lately and was wondering if anyone could give me a ""high-level"" explanation or motivation for the energy function used: $$E = -\sum_{i<j} w_{ij} \, s_i \, s_j - \sum_i \theta_i \, s_i$$ where: $w_{ij}$ is the connection strength between unit $j$ and unit $i$, $s_i$ is the state, $s_i \in \{0,1\}$, of unit $i$. $\theta_i$ is the threshold of unit $i$ Why do we use this particular function? What is the motivation? Is it modelled after some real world phenomena? Could we use a different one?","I've been studying Boltzmann machines lately and was wondering if anyone could give me a ""high-level"" explanation or motivation for the energy function used: $$E = -\sum_{i<j} w_{ij} \, s_i \, s_j - \sum_i \theta_i \, s_i$$ where: $w_{ij}$ is the connection strength between unit $j$ and unit $i$, $s_i$ is the state, $s_i \in \{0,1\}$, of unit $i$. $\theta_i$ is the threshold of unit $i$ Why do we use this particular function? What is the motivation? Is it modelled after some real world phenomena? Could we use a different one?",,"['statistics', 'computer-science', 'dynamical-systems', 'mathematical-modeling', 'machine-learning']"
59,Intuition for Fisher information metric,Intuition for Fisher information metric,,"In statistical maniolds $S=\{p_\theta\}$,$\theta=(\theta_1,\dots,\theta_n)$, the Riemaanian metric usually defined is the Fisher information metric $$g_{ij}(\partial_i,\partial_j)=\int \partial_i(\log p_\theta) \partial_i(\log p_\theta)~p_\theta~dx$$ The associated connection coefficients are defined by $$\Gamma_{ij}^k=\int \partial_i\partial_j(\log p_\theta)\partial_k (\log p_\theta)~ p_{\theta}~dx$$ My question is, what is the intuition behind defining these? Is there a way to prove using the above metric and connection that the linear family of probability distributions $$L=\{p:\int f_i(x)p(x)~dx=m_i, i=1,\dots,k\}$$ intersects ""orthogonally"" the associated exponential family $$\mathcal{E}=\{p:p(x)=c(\theta)q(x)\exp(-\sum_{i=1}^k\theta_i f_i(x))\}$$ in the sense that $L\cap\mathcal{E}=\{p^*\}$ where $p^*$ satisfies $$D(p\|q)=D(p\|p^*)+D(p^*\|q)$$ for every $p\in L, q\in \mathcal{E}$.","In statistical maniolds $S=\{p_\theta\}$,$\theta=(\theta_1,\dots,\theta_n)$, the Riemaanian metric usually defined is the Fisher information metric $$g_{ij}(\partial_i,\partial_j)=\int \partial_i(\log p_\theta) \partial_i(\log p_\theta)~p_\theta~dx$$ The associated connection coefficients are defined by $$\Gamma_{ij}^k=\int \partial_i\partial_j(\log p_\theta)\partial_k (\log p_\theta)~ p_{\theta}~dx$$ My question is, what is the intuition behind defining these? Is there a way to prove using the above metric and connection that the linear family of probability distributions $$L=\{p:\int f_i(x)p(x)~dx=m_i, i=1,\dots,k\}$$ intersects ""orthogonally"" the associated exponential family $$\mathcal{E}=\{p:p(x)=c(\theta)q(x)\exp(-\sum_{i=1}^k\theta_i f_i(x))\}$$ in the sense that $L\cap\mathcal{E}=\{p^*\}$ where $p^*$ satisfies $$D(p\|q)=D(p\|p^*)+D(p^*\|q)$$ for every $p\in L, q\in \mathcal{E}$.",,"['statistics', 'riemannian-geometry', 'information-theory']"
60,Can a sample space depend on the parameter to be estimated (example: # of cabs in a city),Can a sample space depend on the parameter to be estimated (example: # of cabs in a city),,"In our intro statistic lecture the following we said that the following components made up an estimation problem an at most countable space $\mathcal{X}$ of all possible samples we can observe a family $(P_\theta)_{\theta \in \Theta} $ of distributions on $\mathcal{X}$ a function $f:\Theta \rightarrow \mathbb{R}$ that we would like to estimate Then we discussed an example were the aim was to find out how many cabs there are in this city: We assumed that -> all cabs within the city are numbered with numbers from the set $\{1,\ldots,M\}$ -> we observe cabs with numbers $t_1<\ldots<t_m$ The problem I have with this example is that we said that $\mathcal{X}$ is the set of all subsets of size $m$ of $\{1,\ldots,M\}$. What bothers me about that, is that $M$ is a parameter it $\Theta=\mathbb{N}$, which we wish to estimate, so our space $\mathcal{X}$ actually depends on it: Thus we actually have a family $(\mathcal{X}_M)_{M\in \Theta}$ instead of a fixed $\mathcal{X}$. Is that allowed ? I thought in the general definition above that $\mathcal{X}$  shouldn't depend on $\theta$; otherwise it should have been written $(\mathcal{X}_\theta)_{\theta\in \Theta}$.","In our intro statistic lecture the following we said that the following components made up an estimation problem an at most countable space $\mathcal{X}$ of all possible samples we can observe a family $(P_\theta)_{\theta \in \Theta} $ of distributions on $\mathcal{X}$ a function $f:\Theta \rightarrow \mathbb{R}$ that we would like to estimate Then we discussed an example were the aim was to find out how many cabs there are in this city: We assumed that -> all cabs within the city are numbered with numbers from the set $\{1,\ldots,M\}$ -> we observe cabs with numbers $t_1<\ldots<t_m$ The problem I have with this example is that we said that $\mathcal{X}$ is the set of all subsets of size $m$ of $\{1,\ldots,M\}$. What bothers me about that, is that $M$ is a parameter it $\Theta=\mathbb{N}$, which we wish to estimate, so our space $\mathcal{X}$ actually depends on it: Thus we actually have a family $(\mathcal{X}_M)_{M\in \Theta}$ instead of a fixed $\mathcal{X}$. Is that allowed ? I thought in the general definition above that $\mathcal{X}$  shouldn't depend on $\theta$; otherwise it should have been written $(\mathcal{X}_\theta)_{\theta\in \Theta}$.",,"['statistics', 'definition']"
61,Existence of a UMP test for two binomial random variables,Existence of a UMP test for two binomial random variables,,"Let $X$ and $Y$ be independent random variables, distributed as Binomial($p, n$) and Binomial($p^2, m$), respectively.  Does a UMP test (for fixed level $\alpha$) exist for:  $H_0: p \leq p_0 \text{ vs. } H_1: p > p_0$? In order to invoke the Karlin-Rubin theorem the monotone likelihood property is required, but it's not clear to me if we have that.","Let $X$ and $Y$ be independent random variables, distributed as Binomial($p, n$) and Binomial($p^2, m$), respectively.  Does a UMP test (for fixed level $\alpha$) exist for:  $H_0: p \leq p_0 \text{ vs. } H_1: p > p_0$? In order to invoke the Karlin-Rubin theorem the monotone likelihood property is required, but it's not clear to me if we have that.",,['statistics']
62,Regression model for a shearing process,Regression model for a shearing process,,"30 Widgets are randomly assigned to a shearing process. There are 3 such processes, each getting 10 widgets. The lengths of each widget are recorded before undergoing the shearing. The amount that was sheared off is recorded after. $$ \begin{array}{c|lcr} & \text{Process A Length} & \text{Process B Length} & \text{Process C Length} \\ \hline & \text{Before} \ / \ \text{Sheared} & \text{Before} \ / \ \text{Sheared} & \text{Before} \ / \ \text{Sheared}\\ 1& 10 / 3 & 11 / 2 & 12/4 \\ 2& 9.5/2 & 15/7 & 17.5/2 \\ 3& etc &etc &etc \\ 4& \\ 5& \\ 6& \\ 7& \\ 8& \\ 9& \\ 10& \\ \end{array} $$ I need a model for this to do an analysis, to the effect of, recommending which process is better for shearing. Something of the form: $$  \hat{y} = \beta_0 + \beta_1X_1+\beta_2X_2+\beta_3X_3+\epsilon $$ But I'm not entirely sure what it should be. Thanks.","30 Widgets are randomly assigned to a shearing process. There are 3 such processes, each getting 10 widgets. The lengths of each widget are recorded before undergoing the shearing. The amount that was sheared off is recorded after. $$ \begin{array}{c|lcr} & \text{Process A Length} & \text{Process B Length} & \text{Process C Length} \\ \hline & \text{Before} \ / \ \text{Sheared} & \text{Before} \ / \ \text{Sheared} & \text{Before} \ / \ \text{Sheared}\\ 1& 10 / 3 & 11 / 2 & 12/4 \\ 2& 9.5/2 & 15/7 & 17.5/2 \\ 3& etc &etc &etc \\ 4& \\ 5& \\ 6& \\ 7& \\ 8& \\ 9& \\ 10& \\ \end{array} $$ I need a model for this to do an analysis, to the effect of, recommending which process is better for shearing. Something of the form: $$  \hat{y} = \beta_0 + \beta_1X_1+\beta_2X_2+\beta_3X_3+\epsilon $$ But I'm not entirely sure what it should be. Thanks.",,"['statistics', 'regression', 'mathematical-modeling']"
63,Balls in a box probabilities,Balls in a box probabilities,,"A box is filled out by $1,000$ balls. The box can be thought of as containing $V$ sites and $V$ balls, with $V=1,000$. The box is repeatedly shaken, so that each ball has enough time to visit all $1,000$ sites. The ball are identical, except for being uniquely numbered from $1$ to $1,000$. What is the probability that all of the balls labeled from $1$ to $100$ lie in the left hand side of the box? What is the probability that exactly $P$ of the balls labeled $1$ to $100$ lie in the left hand side of the box? Using Stirling's approximation, show that this probability is approximately Gaussian. Calculate the mean of $P$.  calculate the root mean square fluctuations of $P$ about the mean. Is the Gaussian approximation good? Any insight is greatly appreciated.","A box is filled out by $1,000$ balls. The box can be thought of as containing $V$ sites and $V$ balls, with $V=1,000$. The box is repeatedly shaken, so that each ball has enough time to visit all $1,000$ sites. The ball are identical, except for being uniquely numbered from $1$ to $1,000$. What is the probability that all of the balls labeled from $1$ to $100$ lie in the left hand side of the box? What is the probability that exactly $P$ of the balls labeled $1$ to $100$ lie in the left hand side of the box? Using Stirling's approximation, show that this probability is approximately Gaussian. Calculate the mean of $P$.  calculate the root mean square fluctuations of $P$ about the mean. Is the Gaussian approximation good? Any insight is greatly appreciated.",,['statistics']
64,Correlation in errors,Correlation in errors,,"I'm not good in statistics, so please excuse my noob question. We want to ask a question from people (say what is $2+2$). They might make mistake. We assume that they give the correct answer with the same probability $p$. In case their error rates are not correlated, the probability that they both give the wrong answer is $(1-p)^2$ However, their error rates are not independent, they are correlated. In this case, how can we reason about the accuracy of the result ? Do we need to know the distribution of answers?","I'm not good in statistics, so please excuse my noob question. We want to ask a question from people (say what is $2+2$). They might make mistake. We assume that they give the correct answer with the same probability $p$. In case their error rates are not correlated, the probability that they both give the wrong answer is $(1-p)^2$ However, their error rates are not independent, they are correlated. In this case, how can we reason about the accuracy of the result ? Do we need to know the distribution of answers?",,"['statistics', 'correlation']"
65,NFC SuperBowl coin toss hot streak --> hypothesis testing and power calculation,NFC SuperBowl coin toss hot streak --> hypothesis testing and power calculation,,"There are many Q&A's on SE related to coin tossing - the simplest stochastic process. My Q is about relating mathematics and statistics to what in biomedicine and healthcare is termed ""evidence"" based on real world data. In 46 SuperBowls, NFC teams have won the last 15 coin tosses and overall lead AFC teams ~2:1. A graphic of the realized process (up to SuperBowl XLV) superimposed on pseudorandom tosses generated with Mathematica is shown on my infotainment site understars (shameless promo). There's no reason to presume the coins and tosses are biased (unless NFC teams have developed telekinesis lately) - the streak and bias is obviously a coincidence, however the probability of 15 wins in a row is 1/32,000 I think. I would be glad to offer a bounty for statisticians to explain and compute all the standard study-design related parameters associated with this process, like power and p-values associated with the null hypothesis of unbiased, independent tosses. If you believe this is a trivial issue, I'll remind you that healthcare is about 15% of US GDP and much of the evidence is quantified based on statistical analysis with sample sizes often in the hundreds - not much larger than the number of SuperBowls.","There are many Q&A's on SE related to coin tossing - the simplest stochastic process. My Q is about relating mathematics and statistics to what in biomedicine and healthcare is termed ""evidence"" based on real world data. In 46 SuperBowls, NFC teams have won the last 15 coin tosses and overall lead AFC teams ~2:1. A graphic of the realized process (up to SuperBowl XLV) superimposed on pseudorandom tosses generated with Mathematica is shown on my infotainment site understars (shameless promo). There's no reason to presume the coins and tosses are biased (unless NFC teams have developed telekinesis lately) - the streak and bias is obviously a coincidence, however the probability of 15 wins in a row is 1/32,000 I think. I would be glad to offer a bounty for statisticians to explain and compute all the standard study-design related parameters associated with this process, like power and p-values associated with the null hypothesis of unbiased, independent tosses. If you believe this is a trivial issue, I'll remind you that healthcare is about 15% of US GDP and much of the evidence is quantified based on statistical analysis with sample sizes often in the hundreds - not much larger than the number of SuperBowls.",,['statistics']
66,dynamic mean: measurement of randomly distributed events,dynamic mean: measurement of randomly distributed events,,"Aim is to estimate an error on a stochastic event rate. I read out the event counter second-wise, every black $1$ is a counted event (new events over time, see the plot below). During the measurement I am estimating the event rate, so as more statistics is accumulated, mean event rate (red) should asymptotically become more accurate. as one can see, the mean value oscillates around true value of 0.5 even after one order of magnitude more events collected. Practical question: How can one calculate the number of events needed to estimate the mean value to a maximum error ($0.5\pm \sigma$)? - error should fall by $\sqrt{N}$ Theoretically: Can this oscillation be described analytically? Can you suggest further reading? The events are radiation counts, so they are uncorrelated, may by Poisson-distribution applied? addendum: idealized first approximation - every 10th event is non-zero: may be this curve is superimposed with the realer-life example above, is here any techniques of partitioning in arbitrary functions applicable?","Aim is to estimate an error on a stochastic event rate. I read out the event counter second-wise, every black $1$ is a counted event (new events over time, see the plot below). During the measurement I am estimating the event rate, so as more statistics is accumulated, mean event rate (red) should asymptotically become more accurate. as one can see, the mean value oscillates around true value of 0.5 even after one order of magnitude more events collected. Practical question: How can one calculate the number of events needed to estimate the mean value to a maximum error ($0.5\pm \sigma$)? - error should fall by $\sqrt{N}$ Theoretically: Can this oscillation be described analytically? Can you suggest further reading? The events are radiation counts, so they are uncorrelated, may by Poisson-distribution applied? addendum: idealized first approximation - every 10th event is non-zero: may be this curve is superimposed with the realer-life example above, is here any techniques of partitioning in arbitrary functions applicable?",,"['statistics', 'stochastic-processes', 'physics', 'applications']"
67,order statistics,order statistics,,I would like to understand the relationship between the asymptotic moments of order statistics and the moments of the distribution of the mother distribution. I will appreciate any references on this matter.,I would like to understand the relationship between the asymptotic moments of order statistics and the moments of the distribution of the mother distribution. I will appreciate any references on this matter.,,['statistics']
68,"Stats 101 - Exam Question Fail, or just tricky to answer?","Stats 101 - Exam Question Fail, or just tricky to answer?",,"This appeared on a friends Stats 101 exam: You have a random sample of 2000   respondents who's mean age is 47.3. A   friend of yours, (who is knowledgeable   about such things) claims that   republican voters are, on average,   older and demonstrate a mean age of   50.   Using your data, demonstrate if he is correct, or incorrect to a 90%   confidence level The natural reaction for most of us here is that there isn't enough data in the question to even guess at the accuracy of the statement. When asked, the professor said ""It isn't relevant to the problem"". Are we being trolled or is there a way, mathematically speaking, to state that there's insufficient information for a conclusion... or / gasp / is there actually an answer ? edit I just now saw that there is a stackexchange specifically for Stats :( If someone has the ability, I don't mind this being moved to a more appropriate forum.","This appeared on a friends Stats 101 exam: You have a random sample of 2000   respondents who's mean age is 47.3. A   friend of yours, (who is knowledgeable   about such things) claims that   republican voters are, on average,   older and demonstrate a mean age of   50.   Using your data, demonstrate if he is correct, or incorrect to a 90%   confidence level The natural reaction for most of us here is that there isn't enough data in the question to even guess at the accuracy of the statement. When asked, the professor said ""It isn't relevant to the problem"". Are we being trolled or is there a way, mathematically speaking, to state that there's insufficient information for a conclusion... or / gasp / is there actually an answer ? edit I just now saw that there is a stackexchange specifically for Stats :( If someone has the ability, I don't mind this being moved to a more appropriate forum.",,['statistics']
69,A question about $F$-distribution,A question about -distribution,F,"Let $f(m,n,w)$ be the probability density function of $F$ variable with $m$ numerator $df$ and $n$ denominator $df$ , i.e. $$f(m,n,w)=\frac{\Gamma\left(\frac{m+n}{2}\right)(m/n)^{m/2}}{\Gamma(m/2)\Gamma(n/2)}w^{(m/2)-1}\left(1+\frac{mw}{n}\right)^{-(m+n)/2}$$ I am interested in the infimum of $\int_1^\infty f(m,n,w) dw$ over all $m,n$ . From my exploration, this seems to be $$1-\mbox{erf}(1/\sqrt{2})\approx 0.3173$$ where $\mbox{erf}(x)=\frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt$ . Can anyone prove this or point me to a reference?","Let be the probability density function of variable with numerator and denominator , i.e. I am interested in the infimum of over all . From my exploration, this seems to be where . Can anyone prove this or point me to a reference?","f(m,n,w) F m df n df f(m,n,w)=\frac{\Gamma\left(\frac{m+n}{2}\right)(m/n)^{m/2}}{\Gamma(m/2)\Gamma(n/2)}w^{(m/2)-1}\left(1+\frac{mw}{n}\right)^{-(m+n)/2} \int_1^\infty f(m,n,w) dw m,n 1-\mbox{erf}(1/\sqrt{2})\approx 0.3173 \mbox{erf}(x)=\frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt",['statistics']
70,Predictive distribution with divergent integral,Predictive distribution with divergent integral,,"I am having some trouble understanding the basic definition of a posterior predictive distribution and how to apply it to simple examples. I have that if $$y \sim g(y\mid \theta, x)$$ then the predictive posterior distribution is $$g(y\mid x)=\int g(y\mid\theta,x)\pi(\theta\mid x) \,d\theta$$ So I am trying to work through an example of this where $x \sim \operatorname{Normal}(\theta, \sigma^2)$ and $y \sim \operatorname{Normal}(ex,\sigma^2)$ and $\pi(\theta,\sigma^2)=\frac{1}{\sigma^2}$ And I am not sure I understand all the notations correctly. I don't have any examples either of actually solving for this, but I would be interested in seeing any. So I know that $$\pi(\theta\mid x)  \propto \pi(x\mid\theta) \pi(\theta)$$ so $$\pi(\theta,\sigma^2\mid x) \propto \exp\left(\frac{-1}{2\sigma^2}{(x-\theta)^2}\right) \frac{1}{\sigma^2}$$ But then I am not sure how to proceed. I assume I am looking for $\pi(Y\mid X=x)$ Well $P(Y\mid X=x,\theta , \sigma^2) = \exp(\frac{-1}{2\sigma^2}(y-ex)^2)$ so, $$P(Y\mid X=x,\theta , \sigma^2) \pi(\theta,\sigma^2 \mid x)= \frac{1}{\sigma^2} \exp\left(\frac{-1}{2\sigma^2}[(y-ex)^2+(x-\theta)^2]\right)$$ Note that if we try to double integral to normalise over $\pi(x\mid\theta , \sigma^{2})\pi(\theta,\sigma^2)$ we get a divergent integral. So we cannot make equality.","I am having some trouble understanding the basic definition of a posterior predictive distribution and how to apply it to simple examples. I have that if then the predictive posterior distribution is So I am trying to work through an example of this where and and And I am not sure I understand all the notations correctly. I don't have any examples either of actually solving for this, but I would be interested in seeing any. So I know that so But then I am not sure how to proceed. I assume I am looking for Well so, Note that if we try to double integral to normalise over we get a divergent integral. So we cannot make equality.","y \sim g(y\mid \theta, x) g(y\mid x)=\int g(y\mid\theta,x)\pi(\theta\mid x) \,d\theta x \sim \operatorname{Normal}(\theta, \sigma^2) y \sim \operatorname{Normal}(ex,\sigma^2) \pi(\theta,\sigma^2)=\frac{1}{\sigma^2} \pi(\theta\mid x)  \propto \pi(x\mid\theta) \pi(\theta) \pi(\theta,\sigma^2\mid x) \propto \exp\left(\frac{-1}{2\sigma^2}{(x-\theta)^2}\right) \frac{1}{\sigma^2} \pi(Y\mid X=x) P(Y\mid X=x,\theta , \sigma^2) = \exp(\frac{-1}{2\sigma^2}(y-ex)^2) P(Y\mid X=x,\theta , \sigma^2) \pi(\theta,\sigma^2 \mid x)= \frac{1}{\sigma^2} \exp\left(\frac{-1}{2\sigma^2}[(y-ex)^2+(x-\theta)^2]\right) \pi(x\mid\theta , \sigma^{2})\pi(\theta,\sigma^2)","['integration', 'statistics', 'probability-distributions', 'improper-integrals', 'bayesian']"
71,How to solve this equation with error functions?,How to solve this equation with error functions?,,"I'd like to solve the following equation for $S$, in terms of $p, x,$ and $\sigma$: $$ p = \int_0^x\sqrt{\frac{2}{\pi}} \frac{e^{\frac{-(S-\mu)^2}{2\sigma^2}}}{\mathrm{erf}\left(\frac{S}{\sqrt{2}\sigma}\right)- \mathrm{erf}\left(\frac{S-1}{\sqrt{2}\sigma}\right)} d\mu $$ Solving the integral as Mhenni suggested yields: $$ p = \frac{\frac{\sqrt{2}}{2}\left(\mathrm{erf}\left(\frac{S-x}{\sqrt{2}\sigma}\right) - \mathrm{erf}\left(\frac{S}{\sqrt{2}\sigma}\right) \right)}{{\mathrm{erf}\left(\frac{S}{\sqrt{2}\sigma}\right)- \mathrm{erf}\left(\frac{S-1}{\sqrt{2}\sigma}\right)}} $$ The problem now is dealing with the $S$'s inside the error functions. I know there's an inverse error function ($\mathrm{erf}^{-1}$), but I don't see how this is ultimately solvable for $S$. Is this possible? Thanks for any help!","I'd like to solve the following equation for $S$, in terms of $p, x,$ and $\sigma$: $$ p = \int_0^x\sqrt{\frac{2}{\pi}} \frac{e^{\frac{-(S-\mu)^2}{2\sigma^2}}}{\mathrm{erf}\left(\frac{S}{\sqrt{2}\sigma}\right)- \mathrm{erf}\left(\frac{S-1}{\sqrt{2}\sigma}\right)} d\mu $$ Solving the integral as Mhenni suggested yields: $$ p = \frac{\frac{\sqrt{2}}{2}\left(\mathrm{erf}\left(\frac{S-x}{\sqrt{2}\sigma}\right) - \mathrm{erf}\left(\frac{S}{\sqrt{2}\sigma}\right) \right)}{{\mathrm{erf}\left(\frac{S}{\sqrt{2}\sigma}\right)- \mathrm{erf}\left(\frac{S-1}{\sqrt{2}\sigma}\right)}} $$ The problem now is dealing with the $S$'s inside the error functions. I know there's an inverse error function ($\mathrm{erf}^{-1}$), but I don't see how this is ultimately solvable for $S$. Is this possible? Thanks for any help!",,"['integration', 'statistics']"
72,How can a board/card game be considered to be only moderately based on chance? [closed],How can a board/card game be considered to be only moderately based on chance? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question I'm not sure if this is the right forum to ask this, but I guess it's related to statistics... My intuition is that, if a game has any element where luck is involved (e.g. rolling a dice or dealing shuffled cards), then that ultimately renders the game being entirely based on luck/chance. And yet, different games have different 'chance' ratings. For example, Monopoly's chance rating is high while Catan's rating is low/moderate. I don't know if my question makes sense but hopefully someone understands what I'm trying to get at.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question I'm not sure if this is the right forum to ask this, but I guess it's related to statistics... My intuition is that, if a game has any element where luck is involved (e.g. rolling a dice or dealing shuffled cards), then that ultimately renders the game being entirely based on luck/chance. And yet, different games have different 'chance' ratings. For example, Monopoly's chance rating is high while Catan's rating is low/moderate. I don't know if my question makes sense but hopefully someone understands what I'm trying to get at.",,"['statistics', 'card-games']"
73,"Is it possible to obtain Cov(X,Y) from only Var(X) and Var(Y)?","Is it possible to obtain Cov(X,Y) from only Var(X) and Var(Y)?",,"Am trying to write a simple program that can take an arbitrary data-set of [x,y] pairs from given file, analyzes and prints any interesting statistical characteristics. Of the things am interested in, is printing some statistical description of the data based on things like statistical correlation. But now my problem is that their is no information given to the program about the probability distribution from which the sample was taken, and thus such things as Cov(X,Y) seem to evade me since the formula: $$Cov(X,Y)=\langle XY\rangle - \mu_x\mu_y$$ requires that am able to calculate the Expectation of XY, which in turn requires that I know the probability density function of the source. So what can I do to obtain the $Cov(XY)$ when I can only calculate $mean(x), mean(y) ,var(x) $ and $var(y)$? Eventually, am interested in saying something about the correlation between X and Y.","Am trying to write a simple program that can take an arbitrary data-set of [x,y] pairs from given file, analyzes and prints any interesting statistical characteristics. Of the things am interested in, is printing some statistical description of the data based on things like statistical correlation. But now my problem is that their is no information given to the program about the probability distribution from which the sample was taken, and thus such things as Cov(X,Y) seem to evade me since the formula: $$Cov(X,Y)=\langle XY\rangle - \mu_x\mu_y$$ requires that am able to calculate the Expectation of XY, which in turn requires that I know the probability density function of the source. So what can I do to obtain the $Cov(XY)$ when I can only calculate $mean(x), mean(y) ,var(x) $ and $var(y)$? Eventually, am interested in saying something about the correlation between X and Y.",,['statistics']
74,Minimizing RSS by taking partial derivative,Minimizing RSS by taking partial derivative,,"I am learning about linear regression, and the goal is to find parameters $\beta$, that minimize the RSS. My textbook accomplishes this by finding $\partial \text{ RSS} /\partial \beta = 0$ However, I am slightly stuck on the following step: They define: $RSS(\beta) = (\mathbf{y} - \mathbf{X}\beta)^{T} (\mathbf{y}-\mathbf{X}\beta$, where $\beta$ are scalars, $y$ is a column vector, and $X$ is a matrix. They find that $\frac{\partial RSS}{\partial \beta} = -2\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)$ I tried deriving this result. I first wrote: $(\mathbf{y} - \mathbf{X}\beta)^{T} (\mathbf{y}-\mathbf{X}\beta) = (\mathbf{y}^{T} - \mathbf{X}^{T}\beta)(\mathbf{y} - \mathbf{X}\beta)$ I then expanded the two terms in brackets: $\mathbf{y}^{T}\mathbf{y} - \mathbf{y}^{T}\mathbf{X}\beta - \mathbf{y}\mathbf{X}^{T}\beta + \mathbf{X}^{T}\mathbf{X}\beta^2$ Now, I differentiate this with respect to $\beta$: $-\mathbf{y}^{T}\mathbf{X} - \mathbf{y}\mathbf{X}^{T} + 2\beta \mathbf{X}^{T}\mathbf{X}$ This is where I get stuck, comparing my result with the derived result, we both have the $2\beta \mathbf{X}^{T}\mathbf{X}$ term, but I don't know how my first 2 terms should simplify to give $-2\mathbf{X}^{T}\mathbf{y}$.","I am learning about linear regression, and the goal is to find parameters $\beta$, that minimize the RSS. My textbook accomplishes this by finding $\partial \text{ RSS} /\partial \beta = 0$ However, I am slightly stuck on the following step: They define: $RSS(\beta) = (\mathbf{y} - \mathbf{X}\beta)^{T} (\mathbf{y}-\mathbf{X}\beta$, where $\beta$ are scalars, $y$ is a column vector, and $X$ is a matrix. They find that $\frac{\partial RSS}{\partial \beta} = -2\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)$ I tried deriving this result. I first wrote: $(\mathbf{y} - \mathbf{X}\beta)^{T} (\mathbf{y}-\mathbf{X}\beta) = (\mathbf{y}^{T} - \mathbf{X}^{T}\beta)(\mathbf{y} - \mathbf{X}\beta)$ I then expanded the two terms in brackets: $\mathbf{y}^{T}\mathbf{y} - \mathbf{y}^{T}\mathbf{X}\beta - \mathbf{y}\mathbf{X}^{T}\beta + \mathbf{X}^{T}\mathbf{X}\beta^2$ Now, I differentiate this with respect to $\beta$: $-\mathbf{y}^{T}\mathbf{X} - \mathbf{y}\mathbf{X}^{T} + 2\beta \mathbf{X}^{T}\mathbf{X}$ This is where I get stuck, comparing my result with the derived result, we both have the $2\beta \mathbf{X}^{T}\mathbf{X}$ term, but I don't know how my first 2 terms should simplify to give $-2\mathbf{X}^{T}\mathbf{y}$.",,"['calculus', 'statistics', 'optimization', 'maxima-minima']"
75,"Show that if $\eta \sim N(0, \sigma^2)$ then $\mathbb{E} [\eta^4] = 3 \sigma^4$?",Show that if  then ?,"\eta \sim N(0, \sigma^2) \mathbb{E} [\eta^4] = 3 \sigma^4","For the normally distributed random variable $\eta \sim N(0, \sigma^2)$ I am trying to show that $$ \mathbb{E} [\eta^4] = 3 \sigma^4 $$ Can anyone help me to understand how this might be done?","For the normally distributed random variable $\eta \sim N(0, \sigma^2)$ I am trying to show that $$ \mathbb{E} [\eta^4] = 3 \sigma^4 $$ Can anyone help me to understand how this might be done?",,"['statistics', 'stochastic-processes']"
76,How to understand that a distribution has no mean?,How to understand that a distribution has no mean?,,"I've learned that Cauchy distribution doesn't have mean, i.e. the integral $\int_{-\infty}^\infty xf(x,x_0,\gamma)dx$ diverges. But it still has Cauchy principal value equal to location parameter $x_0$. So from the divergence of the integral I might conclude that sequence of averages of larger and larger samples won't converge to anything in any sense. But is it really true, or does the existence of Cauchy principal value still allow the sequence of averages to converge to $x_0$?","I've learned that Cauchy distribution doesn't have mean, i.e. the integral $\int_{-\infty}^\infty xf(x,x_0,\gamma)dx$ diverges. But it still has Cauchy principal value equal to location parameter $x_0$. So from the divergence of the integral I might conclude that sequence of averages of larger and larger samples won't converge to anything in any sense. But is it really true, or does the existence of Cauchy principal value still allow the sequence of averages to converge to $x_0$?",,"['statistics', 'probability-distributions', 'means']"
77,Complex Permutation,Complex Permutation,,"How can we make $4$ letter words using $4$ letters (A,B,C,D) which satisfy following condition: The word cant starts or ends with A. A letter can be repeated more than once. Same letters can not seat together. Example: BADC (correct) BCDC (correct) ABCD (incorrect) BCDA (incorrect) BCCD (incorrect) As A is not allowed at first position, the four positions of the word can be arranged in $3\cdot3\cdot3\cdot3=81$ ways. Out of this, there will be $21$ cases where A will be at last position. I have got those $21$ cases manually. But I am looking for a formula or method which can be used for any $N$ and $R$. Any help will be appreciated.","How can we make $4$ letter words using $4$ letters (A,B,C,D) which satisfy following condition: The word cant starts or ends with A. A letter can be repeated more than once. Same letters can not seat together. Example: BADC (correct) BCDC (correct) ABCD (incorrect) BCDA (incorrect) BCCD (incorrect) As A is not allowed at first position, the four positions of the word can be arranged in $3\cdot3\cdot3\cdot3=81$ ways. Out of this, there will be $21$ cases where A will be at last position. I have got those $21$ cases manually. But I am looking for a formula or method which can be used for any $N$ and $R$. Any help will be appreciated.",,"['statistics', 'discrete-mathematics', 'permutations']"
78,Minimizing a function - sum of squares,Minimizing a function - sum of squares,,I'm hoping you can help with this problem. I haven't taken calculus in years and I don't know where to start... The sum of squares of a sample of data is minimized when the sample mean is used as the basis of the calculation. $$g(c) = \sum_{i=1}^n(X_i-c)^2$$ Show that the function is minimized where $c = \overline {X} $.,I'm hoping you can help with this problem. I haven't taken calculus in years and I don't know where to start... The sum of squares of a sample of data is minimized when the sample mean is used as the basis of the calculation. $$g(c) = \sum_{i=1}^n(X_i-c)^2$$ Show that the function is minimized where $c = \overline {X} $.,,"['calculus', 'statistics', 'functions']"
79,Why $\Delta(c^2)=2c(\Delta c) $?,Why ?,\Delta(c^2)=2c(\Delta c) ,I read a solution of find relative error for $c^2 = a^2 + b^2 -2ab\cdot\cos(\alpha) $ and it written there the equation $\Delta(c^2)=2c(\Delta c) $ .can someone explain how to developing this equation ? Edit : definition of $\Delta: \Delta(x) = |(x-x^*)|  $ when $x^*$ is is the $x$ with the error .,I read a solution of find relative error for $c^2 = a^2 + b^2 -2ab\cdot\cos(\alpha) $ and it written there the equation $\Delta(c^2)=2c(\Delta c) $ .can someone explain how to developing this equation ? Edit : definition of $\Delta: \Delta(x) = |(x-x^*)|  $ when $x^*$ is is the $x$ with the error .,,"['calculus', 'statistics']"
80,Why is $P(X<0)$ the same as $P(X\le 0)$ for continuous distributions?,Why is  the same as  for continuous distributions?,P(X<0) P(X\le 0),"In uniform distribution, a continuous distribution, for example where $A = -1$ and $B = 1$,  $P(X < 0)$ is said to be the same as $P(X \le 0)$. Why is this?","In uniform distribution, a continuous distribution, for example where $A = -1$ and $B = 1$,  $P(X < 0)$ is said to be the same as $P(X \le 0)$. Why is this?",,"['statistics', 'probability-distributions', 'uniform-distribution']"
81,Unbiased estimator of variance,Unbiased estimator of variance,,My question is why is the best and most commonly used estimator for the variance (in a Gaussian distribution) the sample variance with constant 1/n-1 when the sample variance with constant 1/n+1 instead has a lower mean squared error?,My question is why is the best and most commonly used estimator for the variance (in a Gaussian distribution) the sample variance with constant 1/n-1 when the sample variance with constant 1/n+1 instead has a lower mean squared error?,,"['statistics', 'normal-distribution', 'statistical-inference', 'parameter-estimation']"
82,Prove that the estimators are biased.,Prove that the estimators are biased.,,"Given the following sentences: Let $X_1,..., X_n$ be a random sample from a $Pois(\mu)$ distribution. Consider the following estimator for $e^{-\mu}=P(X_i=0)$ : $T=e^{-\overline{X_n}}$ . The independent random variables $X_1;...;X_n$ have a geometric distribution with parameter $p$ . Look at the following estimator for $p$ : $S=\frac{1}{\overline{X_n}}$ . Prove that the estimators are biased. In my opinion both estimators are unbiased: $E[T]=e^{E[\overline{X_n}]}=e^{-\mu}$ that is unbiased for the parameter $e^{-\mu}$ . $E[S]=\frac{1}{E[\overline{X_n}]}=\frac{1}{1/p}=p$ that is unbiased for the parameter $p$ . Why I'm wrong in both cases? Where are my mistakes? Thanks.",Given the following sentences: Let be a random sample from a distribution. Consider the following estimator for : . The independent random variables have a geometric distribution with parameter . Look at the following estimator for : . Prove that the estimators are biased. In my opinion both estimators are unbiased: that is unbiased for the parameter . that is unbiased for the parameter . Why I'm wrong in both cases? Where are my mistakes? Thanks.,"X_1,..., X_n Pois(\mu) e^{-\mu}=P(X_i=0) T=e^{-\overline{X_n}} X_1;...;X_n p p S=\frac{1}{\overline{X_n}} E[T]=e^{E[\overline{X_n}]}=e^{-\mu} e^{-\mu} E[S]=\frac{1}{E[\overline{X_n}]}=\frac{1}{1/p}=p p",['statistics']
83,Looking for a proof of : variance of sum is the sum of variances.,Looking for a proof of : variance of sum is the sum of variances.,,"For independent random variables X and Y, the variance of their sum or   difference is the sum of their variances: I can see why above should be true : if $x_1<X<x_1$ and $y_1 <Y < y_2$ , then clearly $x_1+y_1 <X+Y<x_2+y_2$ . But proving this seems a bit hard. Here is my attempt : $\mathbb {var(X) = \sum[x_i - mean(X)]^2p_i}$ $\mathbb {var(Y) = \sum[y_i - mean(Y)]^2p_i}$ , then I guess the variance of sum should be : $\mathbb {var(X+Y) = \sum[(x_i+y_i) - mean(X+Y)]^2\color{red}{p_{??}}}$ There is no way something like (a+b+m)^2 simplifies to (a+m)^2 + (b+m)^2 .  I'm kinda stuck here, any help ?","For independent random variables X and Y, the variance of their sum or   difference is the sum of their variances: I can see why above should be true : if and , then clearly . But proving this seems a bit hard. Here is my attempt : , then I guess the variance of sum should be : There is no way something like (a+b+m)^2 simplifies to (a+m)^2 + (b+m)^2 .  I'm kinda stuck here, any help ?",x_1<X<x_1 y_1 <Y < y_2 x_1+y_1 <X+Y<x_2+y_2 \mathbb {var(X) = \sum[x_i - mean(X)]^2p_i} \mathbb {var(Y) = \sum[y_i - mean(Y)]^2p_i} \mathbb {var(X+Y) = \sum[(x_i+y_i) - mean(X+Y)]^2\color{red}{p_{??}}},"['statistics', 'random-variables']"
84,Anyone can integrate $e^{-\frac{x^2}{3}}$ by hands?,Anyone can integrate  by hands?,e^{-\frac{x^2}{3}},"I just used wolfram integral calculator and the result is weird, there is something called error function. $$ \int_{-\infty}^\infty e^{-\frac{x^2}{3}}\,\mathrm dx $$ Hint says that change of variable might be helpful, but can't think of what to change and substitute. Anyone can do this by hands?","I just used wolfram integral calculator and the result is weird, there is something called error function. $$ \int_{-\infty}^\infty e^{-\frac{x^2}{3}}\,\mathrm dx $$ Hint says that change of variable might be helpful, but can't think of what to change and substitute. Anyone can do this by hands?",,"['calculus', 'integration', 'statistics']"
85,How to compute the sum of geometric distribution [closed],How to compute the sum of geometric distribution [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question How to compute the sum of random variables of geometric distribution $X_{i}(i=0,1,2..n)$ is the independent random variables of geometric distribution, that is, $P(X_{i}=x)=p(1-p)^{x}$, then how to compute the PDF of $\sum_{i=1}^{n}X_{i}$ a negative binomial distribution $P(Y)=\binom{r+y-1}{y}p^{r}(1-p)^{y}$,  Prove that sum of random variables of geometric distribution become a negative binomial distribution? how to do this deduction?? can help here? Thanks!!!","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question How to compute the sum of random variables of geometric distribution $X_{i}(i=0,1,2..n)$ is the independent random variables of geometric distribution, that is, $P(X_{i}=x)=p(1-p)^{x}$, then how to compute the PDF of $\sum_{i=1}^{n}X_{i}$ a negative binomial distribution $P(Y)=\binom{r+y-1}{y}p^{r}(1-p)^{y}$,  Prove that sum of random variables of geometric distribution become a negative binomial distribution? how to do this deduction?? can help here? Thanks!!!",,"['statistics', 'probability-distributions', 'random-variables']"
86,Statistical Analysis and Techniques,Statistical Analysis and Techniques,,"The lifetime in hours of a tubelight is a random variable $X$ having a probability density function $f(x) = 4xe^{-2x}$, where $x>0$. If $Y= -3X+10$, then find the Expected Value of $Y$, and variance of $Y$.","The lifetime in hours of a tubelight is a random variable $X$ having a probability density function $f(x) = 4xe^{-2x}$, where $x>0$. If $Y= -3X+10$, then find the Expected Value of $Y$, and variance of $Y$.",,['statistics']
87,Median of a set of Integer,Median of a set of Integer,,"The median of a set containing odd number of integer is the middle element after sorting. What about the case of even number of terms. Some places mention of average of the two middle value, but I heard that precise definition allows any number from the left middle number to the right middle number. For example, {1 2 3 4}, any number between and including 2 and 3 is valid.","The median of a set containing odd number of integer is the middle element after sorting. What about the case of even number of terms. Some places mention of average of the two middle value, but I heard that precise definition allows any number from the left middle number to the right middle number. For example, {1 2 3 4}, any number between and including 2 and 3 is valid.",,['statistics']
88,Alternative hypothesis when null hypothesis is ambiguous?,Alternative hypothesis when null hypothesis is ambiguous?,,"This is more of a textbook semantics issue.  Is the alternative hypothesis always two-tailed when all that is known is a null hypothesis $H_0$ where $p$ equals some arbitrary figure, where an arbitrary sample proportion and significance level are also given (assuming all requirements are met)?","This is more of a textbook semantics issue.  Is the alternative hypothesis always two-tailed when all that is known is a null hypothesis $H_0$ where $p$ equals some arbitrary figure, where an arbitrary sample proportion and significance level are also given (assuming all requirements are met)?",,['statistics']
89,Why do we calculate variance if standard deviation serves the ends well?,Why do we calculate variance if standard deviation serves the ends well?,,"I don't understand why we even care for square units. How does it make sense that if you take the squared difference of each data set and mean, then divided it by $n-1$ gives us a measure of spread? Variance is not as intuitive to me as standard deviation, which makes absolute sense. Can anyone help me understand the importance of variance and how its formula makes sense?","I don't understand why we even care for square units. How does it make sense that if you take the squared difference of each data set and mean, then divided it by gives us a measure of spread? Variance is not as intuitive to me as standard deviation, which makes absolute sense. Can anyone help me understand the importance of variance and how its formula makes sense?",n-1,"['statistics', 'variance', 'standard-deviation']"
90,(Sheldon Ross) Proving the independence of sample mean and sample variance,(Sheldon Ross) Proving the independence of sample mean and sample variance,,"Please refer to the proof given in : Sheldon Rose, A first course in probability : The author says that since $\{Y, X_i − \overline X, i = 1, \cdots , n\}$ and $\{\overline X, (X_i − \overline X), i = 1, \cdots, n\}$ have the same joint distribution, thus showing that $\overline X$ is independent of the sequence of deviations $X_i − \overline X, i = 1, \cdots n.$ Somehow, the statement in bold doesn't look too obvious. Could someone please clarify? Am I missing something?","Please refer to the proof given in : Sheldon Rose, A first course in probability : The author says that since and have the same joint distribution, thus showing that is independent of the sequence of deviations Somehow, the statement in bold doesn't look too obvious. Could someone please clarify? Am I missing something?","\{Y, X_i − \overline X, i = 1, \cdots , n\} \{\overline X, (X_i − \overline X), i = 1, \cdots, n\} \overline X X_i − \overline X, i = 1, \cdots n.","['statistics', 'normal-distribution']"
91,Understanding the formula for variance,Understanding the formula for variance,,I have read both my textbook and the wikipedia page but there is a nuance about the notation that I am lost about. The variance is defined as: $E((X-\mu)^2)$ Assume we are on a finite case. Does that mean that the expansion is: $\sum (x_i-\mu)^2p(x_i)$ Or: $\sum (x_ip(x_i)-\mu)^2$,I have read both my textbook and the wikipedia page but there is a nuance about the notation that I am lost about. The variance is defined as: $E((X-\mu)^2)$ Assume we are on a finite case. Does that mean that the expansion is: $\sum (x_i-\mu)^2p(x_i)$ Or: $\sum (x_ip(x_i)-\mu)^2$,,"['statistics', 'expectation', 'variance']"
92,Can a linear regression be quadratic?,Can a linear regression be quadratic?,,"The following is from a comp. sci. book that discusses regression.  The passage seems to say that while a function fitted to a data set may be quadratic, it may yet be considered linear. This seems contradictory, and I'm not entirely sure what I'm missing. Could someone please point me in the right direction? For example, when we fit a quadratic, we get a model of the form $y=ax^2 + bx +c$. In such a model, the value of the dependent variable $y$ is linear in the independent variables $x^2 , x^1$ and $x^0$ and the coefficients $a, b$ and $c$.","The following is from a comp. sci. book that discusses regression.  The passage seems to say that while a function fitted to a data set may be quadratic, it may yet be considered linear. This seems contradictory, and I'm not entirely sure what I'm missing. Could someone please point me in the right direction? For example, when we fit a quadratic, we get a model of the form $y=ax^2 + bx +c$. In such a model, the value of the dependent variable $y$ is linear in the independent variables $x^2 , x^1$ and $x^0$ and the coefficients $a, b$ and $c$.",,"['statistics', 'regression', 'regression-analysis', 'linear-regression']"
93,Why is sample variance divided by $n-1$ and not $n$ [duplicate],Why is sample variance divided by  and not  [duplicate],n-1 n,"This question already has answers here : Why do statisticians like ""$n-1$"" instead of ""$n$""? (5 answers) Closed 9 years ago . Sample Variance, customarily denoted, $s^2$, as in the formula below, is the average of the squared deviations , except that we divide by $n-1$ instead of $n$. $$s^2 = \frac{1}{n-1} \sum\limits_{i=1}^{n} (X_i - \overline{X})^2$$ My question is : Why do we divide by $n-1$ instead of $n$? Does it have anything to with having a ""binary"" operation, meaning two ( bi -nary) operands? This may be a duplicate question.","This question already has answers here : Why do statisticians like ""$n-1$"" instead of ""$n$""? (5 answers) Closed 9 years ago . Sample Variance, customarily denoted, $s^2$, as in the formula below, is the average of the squared deviations , except that we divide by $n-1$ instead of $n$. $$s^2 = \frac{1}{n-1} \sum\limits_{i=1}^{n} (X_i - \overline{X})^2$$ My question is : Why do we divide by $n-1$ instead of $n$? Does it have anything to with having a ""binary"" operation, meaning two ( bi -nary) operands? This may be a duplicate question.",,"['statistics', 'standard-deviation']"
94,MLE of multivariate (bivariate) normal distribution,MLE of multivariate (bivariate) normal distribution,,"Suppose that $X$ ($n$ by $2$ matrix) follows a bivariate normal distribution $N(\mu,\sigma^2I)$, where $I$ is the $2\times 2$ identity matrix. How to find the maximum likelihood estimates of $\mu$ and $\sigma^2$?","Suppose that $X$ ($n$ by $2$ matrix) follows a bivariate normal distribution $N(\mu,\sigma^2I)$, where $I$ is the $2\times 2$ identity matrix. How to find the maximum likelihood estimates of $\mu$ and $\sigma^2$?",,"['statistics', 'normal-distribution']"
95,Error propagation on weighted mean,Error propagation on weighted mean,,"I understand that, if errors are random and independent, the addition (or difference) of two measured quantities, say $x$ and $y$, is equal to the quadratic sum of the two errors. In other words, the error of $x + y$ is given by $\sqrt{e_1^2 + e_2^2}$, where $e_1$ and $e_2$ and the errors of $x$ and $y$, respectively. However, I have not yet been able to find how to calculate the error of both the arithmetic mean and the weighted mean of the two measured quantities. How do errors propagate in these cases?","I understand that, if errors are random and independent, the addition (or difference) of two measured quantities, say $x$ and $y$, is equal to the quadratic sum of the two errors. In other words, the error of $x + y$ is given by $\sqrt{e_1^2 + e_2^2}$, where $e_1$ and $e_2$ and the errors of $x$ and $y$, respectively. However, I have not yet been able to find how to calculate the error of both the arithmetic mean and the weighted mean of the two measured quantities. How do errors propagate in these cases?",,"['statistics', 'error-propagation']"
96,Calculating interquartile range,Calculating interquartile range,,"I have the following numbers: $$\{0, 1, 2, 5, 8, 8, 9, 10, 12, 14, 18, 20, 21, 23, 25, 27, 34, 43\}$$ and need to calculate the IQR. My calculations gave me: $$18/4=4.5$$ $$Q1=(5+8)/2=6.5$$ $$Q2=(12+14)/2=24$$ $$Q3=(23+25)/2=24$$ $$IQR=Q3-Q1=24-6.5=17.5$$ The book says they're: $$Q1=7.25, Q2=13, Q3=23.5, IQR=16.25$$ and Wolfram|Alpha gives: $$Q1=8, Q3=23, IQR=15$$ Could someone please explain all these discrepancies?","I have the following numbers: $$\{0, 1, 2, 5, 8, 8, 9, 10, 12, 14, 18, 20, 21, 23, 25, 27, 34, 43\}$$ and need to calculate the IQR. My calculations gave me: $$18/4=4.5$$ $$Q1=(5+8)/2=6.5$$ $$Q2=(12+14)/2=24$$ $$Q3=(23+25)/2=24$$ $$IQR=Q3-Q1=24-6.5=17.5$$ The book says they're: $$Q1=7.25, Q2=13, Q3=23.5, IQR=16.25$$ and Wolfram|Alpha gives: $$Q1=8, Q3=23, IQR=15$$ Could someone please explain all these discrepancies?",,['statistics']
97,method of moments of an uniform distribution,method of moments of an uniform distribution,,"Let  $ X_1, ... X_n $ a sample of independent random variables with uniform distribution $(0,$$ \theta  $$ ) $ Find a $ $$ \widehat\theta  $$  $ estimator for theta using the method of moments Thanks I think using the indicatrix used in this type of problems that can not be derived, but not as used","Let  $ X_1, ... X_n $ a sample of independent random variables with uniform distribution $(0,$$ \theta  $$ ) $ Find a $ $$ \widehat\theta  $$  $ estimator for theta using the method of moments Thanks I think using the indicatrix used in this type of problems that can not be derived, but not as used",,['statistics']
98,How much noise will the average of N noisy signals have?,How much noise will the average of N noisy signals have?,,"(Inspired by this question on the photography site) Say you have N copies of the same signal, each with a layer of noise on top. You average these copies together in an attempt to reduce the effect of noise. How much noise will the average have?","(Inspired by this question on the photography site) Say you have N copies of the same signal, each with a layer of noise on top. You average these copies together in an attempt to reduce the effect of noise. How much noise will the average have?",,"['statistics', 'signal-processing', 'noise']"
99,Finding critical value using t-distribution in Excel,Finding critical value using t-distribution in Excel,,"Alright, I'm trying to figure out how to calculate a  critical value using t-distribution in Microsoft Excel... ex. a one-tailed area of 0.05 with 39 degrees of freedom: t=1.685 I know the answer, but how do I get this? I've tried TDIST() TINV() and TTEST() but they all give me different answers. This web calculator: http://www.danielsoper.com/statcalc/calc10.aspx always gives me what I'm looking for but I cannot manage to get Excel to do the same. Any help would be greatly appreciated!","Alright, I'm trying to figure out how to calculate a  critical value using t-distribution in Microsoft Excel... ex. a one-tailed area of 0.05 with 39 degrees of freedom: t=1.685 I know the answer, but how do I get this? I've tried TDIST() TINV() and TTEST() but they all give me different answers. This web calculator: http://www.danielsoper.com/statcalc/calc10.aspx always gives me what I'm looking for but I cannot manage to get Excel to do the same. Any help would be greatly appreciated!",,['statistics']
