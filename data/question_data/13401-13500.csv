,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Show a C-infinity function is a polynomial,Show a C-infinity function is a polynomial,,"Suppose $f\in C^\infty(\mathbb{R})$ and for any $x\in\mathbb{R}$, there exists $N\in\mathbb{N}$ such that $f^{(N)}(x)=0$. Show that $f$ is a polynomial. This is from one of the Analysis qualifying exam problems. I can show there exists an interval $(a,b)$ on which $f$ is a polynomial by using Baire category theorem, but I can't extend it to the real line. Any suggestion? I think I get some new ideas about this problem. First I can find an interval $I=(a,b)$ by using Baire theorem (same idea from the question that Clement C. added.) where $f$ coincides with a polynomial $g$ on $I$. Then we consider $f^{(i)}(a), i\leq N_g$ where $N_g$ is the degree of $g$. We must have $f^{(N_g)}(a)=0$ because $f^{(i)}(a^+)=f^{(i)}(a)=g^{(i)}(a), i\in\mathbb{N}$. So if we apply the Taylor's theorem at $x=a$, we can extend $I=(a,b)$ to $I_\epsilon=(a-\epsilon,b)$ such that $f=g$ on $I_\epsilon$. Following the same idea, we can show that $$\inf\{a:f=g \text{  on  } (a,b) \}=-\infty$$ Similarly we can show $f=g$ on $\mathbb{R}$. Update: I just found that the idea above might not work after I was trying to write down a rigorous proof. The main problem is $C^\infty$ function is not neccesarily analytic. (For example, let $f(x)=0$ on $(-\infty,0]$ and $f(x)=e^{-1/x}$ on $(0,\infty)$). So I can only extend $(a,b)$ to some larger (or equal) interval $(c,d)$ if I only use the $C^\infty$ property. So the claim above $$\inf\{a:f=g \text{  on  } (a,b) \}=-\infty$$ might not be true. I really have no idea how to extend this interval to the real line now.","Suppose $f\in C^\infty(\mathbb{R})$ and for any $x\in\mathbb{R}$, there exists $N\in\mathbb{N}$ such that $f^{(N)}(x)=0$. Show that $f$ is a polynomial. This is from one of the Analysis qualifying exam problems. I can show there exists an interval $(a,b)$ on which $f$ is a polynomial by using Baire category theorem, but I can't extend it to the real line. Any suggestion? I think I get some new ideas about this problem. First I can find an interval $I=(a,b)$ by using Baire theorem (same idea from the question that Clement C. added.) where $f$ coincides with a polynomial $g$ on $I$. Then we consider $f^{(i)}(a), i\leq N_g$ where $N_g$ is the degree of $g$. We must have $f^{(N_g)}(a)=0$ because $f^{(i)}(a^+)=f^{(i)}(a)=g^{(i)}(a), i\in\mathbb{N}$. So if we apply the Taylor's theorem at $x=a$, we can extend $I=(a,b)$ to $I_\epsilon=(a-\epsilon,b)$ such that $f=g$ on $I_\epsilon$. Following the same idea, we can show that $$\inf\{a:f=g \text{  on  } (a,b) \}=-\infty$$ Similarly we can show $f=g$ on $\mathbb{R}$. Update: I just found that the idea above might not work after I was trying to write down a rigorous proof. The main problem is $C^\infty$ function is not neccesarily analytic. (For example, let $f(x)=0$ on $(-\infty,0]$ and $f(x)=e^{-1/x}$ on $(0,\infty)$). So I can only extend $(a,b)$ to some larger (or equal) interval $(c,d)$ if I only use the $C^\infty$ property. So the claim above $$\inf\{a:f=g \text{  on  } (a,b) \}=-\infty$$ might not be true. I really have no idea how to extend this interval to the real line now.",,"['calculus', 'functional-analysis', 'polynomials', 'baire-category']"
1,Horizontal tangent line of a parametric curve,Horizontal tangent line of a parametric curve,,"Suppose $x=t^2,y=t^3$ is a parametric curve. Here's a quote from my textbook: The origin, which corresponds to $t=0$, is a singular point of the parametric curve, because $dx/dt=2t,dy/dt=3t^2$ are both zero when $t=0$. So far so good. But then they write: However, the curve has a horizontal tangent line at the origin, because for all $t\neq 0$:   $$\frac{dy}{dx}=\frac{dy/dt}{dx/dt}=\frac{3}{2}t$$   And thus:   $$\lim_{t\to 0^+} \frac{dy}{dx}=\lim_{t\to 0^-} \frac{dy}{dx}=0$$ It looked a little odd for me. Nevertheless, I decided to use the same argument to show that the parametric curve $x=2\cos t - \cos (2t), y=2\sin t - \sin(2t)$ has a horizontal tangent line at $t=0$, that is at $(1,0)$. However my professor said that this is wrong (""because the derivative is not zero"" - indeed, $\frac{dy}{dx}\Big|_{t=0}$ is undefined - ""$0/0$""). So who is right? Is the existence of the limit a sufficient condition for the (horizontal) tangent line to exist, as my textbook says, or not? I'm confused. Thanks. Short version of the question : can a parametric curve have a horizontal tangent line at a singular point? I.e. is $\lim_{t\to 0} \frac{dy}{dx}=0$ a sufficient condition for a horizontal line to exist (at $t=0$)? (even if the derivative $\frac{dy}{dx}\Big |_{t=0}$ itself doesn't exist).","Suppose $x=t^2,y=t^3$ is a parametric curve. Here's a quote from my textbook: The origin, which corresponds to $t=0$, is a singular point of the parametric curve, because $dx/dt=2t,dy/dt=3t^2$ are both zero when $t=0$. So far so good. But then they write: However, the curve has a horizontal tangent line at the origin, because for all $t\neq 0$:   $$\frac{dy}{dx}=\frac{dy/dt}{dx/dt}=\frac{3}{2}t$$   And thus:   $$\lim_{t\to 0^+} \frac{dy}{dx}=\lim_{t\to 0^-} \frac{dy}{dx}=0$$ It looked a little odd for me. Nevertheless, I decided to use the same argument to show that the parametric curve $x=2\cos t - \cos (2t), y=2\sin t - \sin(2t)$ has a horizontal tangent line at $t=0$, that is at $(1,0)$. However my professor said that this is wrong (""because the derivative is not zero"" - indeed, $\frac{dy}{dx}\Big|_{t=0}$ is undefined - ""$0/0$""). So who is right? Is the existence of the limit a sufficient condition for the (horizontal) tangent line to exist, as my textbook says, or not? I'm confused. Thanks. Short version of the question : can a parametric curve have a horizontal tangent line at a singular point? I.e. is $\lim_{t\to 0} \frac{dy}{dx}=0$ a sufficient condition for a horizontal line to exist (at $t=0$)? (even if the derivative $\frac{dy}{dx}\Big |_{t=0}$ itself doesn't exist).",,"['calculus', 'derivatives', 'parametric', 'curves']"
2,Evaluation of $ \lim_{n\rightarrow \infty}\left[\prod^{n}_{r=1}\left(1+\frac{n}{r}\right)^{\frac{r}{n}}\right]^{\frac{1}{n}}$,Evaluation of, \lim_{n\rightarrow \infty}\left[\prod^{n}_{r=1}\left(1+\frac{n}{r}\right)^{\frac{r}{n}}\right]^{\frac{1}{n}},"Evaluation of $\displaystyle \lim_{n\rightarrow \infty}\left[(1+n)^{\frac{1}{n}}\cdot \left(1+\frac{n}{2}\right)^{\frac{2}{n}}\cdot \left(1+\frac{n}{3}\right)^{\frac{3}{n}}.........2\right]^{\frac{1}{n}}$ $\bf{My\; Try::}$ Let $$ y = \lim_{n\rightarrow \infty}\left[(1+n)^{\frac{1}{n}}\cdot \left(1+\frac{n}{2}\right)^{\frac{2}{n}}\cdot \left(1+\frac{n}{3}\right)^{\frac{3}{n}}.........2\right]^{\frac{1}{n}}$$ Now taking $$ \ln y = \lim_{n\rightarrow \infty}\frac{1}{n}\cdot \ln\left[(1+n)^{\frac{1}{n}}\cdot \left(1+\frac{n}{2}\right)^{\frac{2}{n}}\cdot \left(1+\frac{n}{3}\right)^{\frac{3}{n}}.........2\right]$$ So we get $$\ln y = \lim_{n\rightarrow \infty}\frac{1}{n}\left[\frac{1}{n}\cdot \ln(1+n)+\frac{2}{n}\ln\left(1+\frac{n}{2}\right)+........+\frac{n}{n}\ln\left(1+\frac{n}{n}\right)\right]$$ So $$\ln y = \lim_{n\rightarrow \infty}\frac{1}{n}\sum^{n}_{r=1}\frac{r}{n}\ln\left(1+\frac{n}{r}\right)$$ Now Convertinto Reinmann Sum of Integral So put $\displaystyle \frac{r}{n} = x\;,$ Then $\displaystyle \frac{1}{n}=dx$ and Calculate limit So we get $$\ln y = \int_{0}^{1}x\cdot \ln\left(1+\frac{1}{x}\right)dx=\int_{0}^{1}x\cdot \left[\ln(1+x)-\ln x\right]dx$$ So we get $$\ln y = \int_{0}^{1}x\cdot \ln(x+1)dx-\int_{0}^{1}x\ln xdx$$ Now after Integrate we wil get $$\ln y = \frac{1}{2}\ln 2+\frac{1}{4}-\frac{1}{2}\ln 2+\frac{1}{4} = \frac{1}{2}$$ So we get $$\ln y = \frac{1}{2}\Rightarrow y = e^{\frac{1}{2}}=\sqrt{e}$$ Can we solve it any Shorter way, If yes then plz explain here Thanks","Evaluation of $\displaystyle \lim_{n\rightarrow \infty}\left[(1+n)^{\frac{1}{n}}\cdot \left(1+\frac{n}{2}\right)^{\frac{2}{n}}\cdot \left(1+\frac{n}{3}\right)^{\frac{3}{n}}.........2\right]^{\frac{1}{n}}$ $\bf{My\; Try::}$ Let $$ y = \lim_{n\rightarrow \infty}\left[(1+n)^{\frac{1}{n}}\cdot \left(1+\frac{n}{2}\right)^{\frac{2}{n}}\cdot \left(1+\frac{n}{3}\right)^{\frac{3}{n}}.........2\right]^{\frac{1}{n}}$$ Now taking $$ \ln y = \lim_{n\rightarrow \infty}\frac{1}{n}\cdot \ln\left[(1+n)^{\frac{1}{n}}\cdot \left(1+\frac{n}{2}\right)^{\frac{2}{n}}\cdot \left(1+\frac{n}{3}\right)^{\frac{3}{n}}.........2\right]$$ So we get $$\ln y = \lim_{n\rightarrow \infty}\frac{1}{n}\left[\frac{1}{n}\cdot \ln(1+n)+\frac{2}{n}\ln\left(1+\frac{n}{2}\right)+........+\frac{n}{n}\ln\left(1+\frac{n}{n}\right)\right]$$ So $$\ln y = \lim_{n\rightarrow \infty}\frac{1}{n}\sum^{n}_{r=1}\frac{r}{n}\ln\left(1+\frac{n}{r}\right)$$ Now Convertinto Reinmann Sum of Integral So put $\displaystyle \frac{r}{n} = x\;,$ Then $\displaystyle \frac{1}{n}=dx$ and Calculate limit So we get $$\ln y = \int_{0}^{1}x\cdot \ln\left(1+\frac{1}{x}\right)dx=\int_{0}^{1}x\cdot \left[\ln(1+x)-\ln x\right]dx$$ So we get $$\ln y = \int_{0}^{1}x\cdot \ln(x+1)dx-\int_{0}^{1}x\ln xdx$$ Now after Integrate we wil get $$\ln y = \frac{1}{2}\ln 2+\frac{1}{4}-\frac{1}{2}\ln 2+\frac{1}{4} = \frac{1}{2}$$ So we get $$\ln y = \frac{1}{2}\Rightarrow y = e^{\frac{1}{2}}=\sqrt{e}$$ Can we solve it any Shorter way, If yes then plz explain here Thanks",,['calculus']
3,Newton's way of getting a Taylor expansion,Newton's way of getting a Taylor expansion,,I don't understand how Newton find the Taylor expansion of $\frac{a^2}{b+x}$ by the following method : **This screenshot is from : The method of fluxions and infinite series Any idea ?,I don't understand how Newton find the Taylor expansion of $\frac{a^2}{b+x}$ by the following method : **This screenshot is from : The method of fluxions and infinite series Any idea ?,,"['calculus', 'algebra-precalculus', 'taylor-expansion', 'math-history']"
4,Leibniz's Derivative Rule for Integral in Measure Theory,Leibniz's Derivative Rule for Integral in Measure Theory,,"I saw the extension of Leibniz rule for integrals for measure theory on Wiki , although I am not sure if the proposition there is correct. Besides there is no proof for it. Can anybody please introduce a reference for the measure theoretic version of it? The statement on wiki is as follows: Let $X$ be an open subset of $\mathbb{R}$ , and $\Omega$ be a measure space. Suppose $f: X \times \Omega \rightarrow \mathbb{R} $ satisfies the following conditions: ::(1) $f(x,\omega)$ is a Lebesgue-integrable function of $\omega$ for each $x \in X$ ::(2) For almost all $\omega \in \Omega$ , the derivative $f_x$ exists for all $x \in X$ ::(3) There is an integrable function $ \theta: \Omega \rightarrow \mathbb{R}$ such that $|f_x(x,\omega)| \leq \theta ( \omega)$ for all $x \in X$ Then for all $x \in X$ ::$ \frac{\mathrm{d}}{\mathrm{d} x} \int_{\Omega} \, f(x, \omega) \mathrm{d} \omega = \int_{\Omega}  \, f_x ( x, \omega) \mathrm{d} \omega $","I saw the extension of Leibniz rule for integrals for measure theory on Wiki , although I am not sure if the proposition there is correct. Besides there is no proof for it. Can anybody please introduce a reference for the measure theoretic version of it? The statement on wiki is as follows: Let $X$ be an open subset of $\mathbb{R}$ , and $\Omega$ be a measure space. Suppose $f: X \times \Omega \rightarrow \mathbb{R} $ satisfies the following conditions: ::(1) $f(x,\omega)$ is a Lebesgue-integrable function of $\omega$ for each $x \in X$ ::(2) For almost all $\omega \in \Omega$ , the derivative $f_x$ exists for all $x \in X$ ::(3) There is an integrable function $ \theta: \Omega \rightarrow \mathbb{R}$ such that $|f_x(x,\omega)| \leq \theta ( \omega)$ for all $x \in X$ Then for all $x \in X$ ::$ \frac{\mathrm{d}}{\mathrm{d} x} \int_{\Omega} \, f(x, \omega) \mathrm{d} \omega = \int_{\Omega}  \, f_x ( x, \omega) \mathrm{d} \omega $",,"['calculus', 'integration', 'measure-theory', 'derivatives']"
5,Proof that the product of two differentiable functions is also differentiable,Proof that the product of two differentiable functions is also differentiable,,"Let $f:A\subset \mathbb{R^p}\rightarrow\mathbb{R^q}$ and $\phi:A\subset \mathbb{R^p}\rightarrow\mathbb{R}$ differentiable in $c\in A$ . I have to prove that $g(x)=\phi (x)f(x)$ is differentiable, where $Dg(c)u=(D \phi(c)u)f(c)+\phi(c)(Df(c)u)$ for any $u \in \mathbb{R^p}$ . I have done the following: $g(x)=\phi (x)f(x)$ is differentiable if and only if: $$\lim_{x\to c}\frac{||g(x)-g(c)-Dg(c)(x-c)||}{||x-c||}=0$$ $$\lim_{x\to c}\frac{||\phi (x)f(x)-\phi (c)f(c)-D \phi(c)(x-c))f(c)-\phi(c)(Df(c)(x-c))||}{||x-c||}=\lim_{x\to c}\frac{||\phi (x)f(x)-\phi (c)f(c)-\phi(c)f(x)+ \phi(c)f(x)-D \phi(c)(x-c))f(c)-\phi(c)(Df(c)(x-c))||}{||x-c||}< \lim_{x\to c}\frac{|\phi(c)| ||f(x)-f(c)-(Df(c)(x-c))||}{||x-c||} +  \lim_{x\to c}\frac{||\phi (x)f(x)-\phi(c)f(x)-D \phi(c)(x-c))f(c)||}{||x-c||}<|\phi(c)|\lim_{x\to c}\frac{ ||f(x)-f(c)-(Df(c)(x-c))||}{||x-c||} + \lim_{x\to c}\frac{||\phi (x)f(x)-\phi(c)f(x)-D \phi(c)(x-c))f(c)||}{||x-c||}<\lim_{x\to c}\frac{||\phi (x)f(x)-\phi(c)f(x)-D \phi(c)(x-c))f(c)||}{||x-c||}...$$ What can I do with the second part? thank you very much!","Let and differentiable in . I have to prove that is differentiable, where for any . I have done the following: is differentiable if and only if: What can I do with the second part? thank you very much!","f:A\subset \mathbb{R^p}\rightarrow\mathbb{R^q} \phi:A\subset \mathbb{R^p}\rightarrow\mathbb{R} c\in A g(x)=\phi (x)f(x) Dg(c)u=(D \phi(c)u)f(c)+\phi(c)(Df(c)u) u \in \mathbb{R^p} g(x)=\phi (x)f(x) \lim_{x\to c}\frac{||g(x)-g(c)-Dg(c)(x-c)||}{||x-c||}=0 \lim_{x\to c}\frac{||\phi (x)f(x)-\phi (c)f(c)-D \phi(c)(x-c))f(c)-\phi(c)(Df(c)(x-c))||}{||x-c||}=\lim_{x\to c}\frac{||\phi (x)f(x)-\phi (c)f(c)-\phi(c)f(x)+ \phi(c)f(x)-D \phi(c)(x-c))f(c)-\phi(c)(Df(c)(x-c))||}{||x-c||}< \lim_{x\to c}\frac{|\phi(c)| ||f(x)-f(c)-(Df(c)(x-c))||}{||x-c||} +
 \lim_{x\to c}\frac{||\phi (x)f(x)-\phi(c)f(x)-D \phi(c)(x-c))f(c)||}{||x-c||}<|\phi(c)|\lim_{x\to c}\frac{ ||f(x)-f(c)-(Df(c)(x-c))||}{||x-c||} + \lim_{x\to c}\frac{||\phi (x)f(x)-\phi(c)f(x)-D \phi(c)(x-c))f(c)||}{||x-c||}<\lim_{x\to c}\frac{||\phi (x)f(x)-\phi(c)f(x)-D \phi(c)(x-c))f(c)||}{||x-c||}...","['calculus', 'multivariable-calculus']"
6,Definite integral $\int_0^{2\pi}\frac{ab}{\sqrt{b^2\cos^2(\theta)+a^2\sin^2(\theta))}}\cos^2(\theta) d\theta$,Definite integral,\int_0^{2\pi}\frac{ab}{\sqrt{b^2\cos^2(\theta)+a^2\sin^2(\theta))}}\cos^2(\theta) d\theta,"Could you help me finding the following definite integral, with $a$ and $b$ constants?  Thank you! $$\int_0^{2\pi}\frac{ab}{\sqrt{b^2\cos^2(\theta)+a^2\sin^2(\theta))}}\cos^2(\theta) d\theta$$","Could you help me finding the following definite integral, with $a$ and $b$ constants?  Thank you! $$\int_0^{2\pi}\frac{ab}{\sqrt{b^2\cos^2(\theta)+a^2\sin^2(\theta))}}\cos^2(\theta) d\theta$$",,"['calculus', 'integration']"
7,A dominated convergence theorem applied to $e$ number definition,A dominated convergence theorem applied to  number definition,e,"I want to show that: $$\lim_{n\to\infty}\left(1+\frac{1}{n}\right)^n=\sum_{k=0}^\infty \frac{1}{k!}.$$ By the binomial theorem $$\lim_{n\to\infty}\left(1+\frac{1}{n}\right)^n = \lim_{n\to\infty}\sum_{k=0}^n \frac{1}{k!} \frac{n(n-1)\cdots(n-k+1)}{n^k}=\lim_{n\to\infty}\sum_{k=0}^n f_n(k).$$ Here I have problems with limits, since the limit of the sum depends on $n$ and also the summation terms. I tried to fix it with the following: Let $g_n:=f_n\chi_{P_n}\colon \mathbb{N}\to \mathbb{R}$ measurable functions in the counting measure $\mu$ in $\mathbb{N}$  we have that $$g_n(k)=f_n(k)\chi_{P_n}(k)\to \frac{1}{k!}$$ for each $k\in\mathbb{N}$ and $P_n=\{1,\ldots,n\}$. But $$|g_n(k)|\leq \frac{1}{k!}:=f(k)\quad\text{and}\quad \int_{\mathbb{N}}f(k)d\mu(k)=\sum_{k=0}^\infty \frac{1}{k!}<3<\infty.$$ So by the Lebesgue Dominated Convergence Theorem, \begin{align} \lim_{n\to\infty}\left(1+\frac{1}{n}\right)^n&=\lim_{n\to\infty}\sum_{k=0}^n f_n(k)\\ &=\lim_{n\to\infty}\int_{P_n}f_n(k)d\mu(k)\\ &=\lim_{n\to\infty}\int_{\mathbb{N}}\chi_{P_n}(k) f_n(k)d\mu(k)\\ &=\lim_{n\to\infty}\int_{\mathbb{N}}g_n(k)d\mu(k)\\ &=\int_{\mathbb{N}}\lim_{n\to\infty}g_n(k)d\mu(k)\\ &=\int_{\mathbb{N}}f(k)d\mu(k)\\ &=\int_{\mathbb{N}}\frac{1}{k!}d\mu(k)\\ &=\sum_{k=0}^\infty \frac{1}{k!}. \end{align} Am I right?","I want to show that: $$\lim_{n\to\infty}\left(1+\frac{1}{n}\right)^n=\sum_{k=0}^\infty \frac{1}{k!}.$$ By the binomial theorem $$\lim_{n\to\infty}\left(1+\frac{1}{n}\right)^n = \lim_{n\to\infty}\sum_{k=0}^n \frac{1}{k!} \frac{n(n-1)\cdots(n-k+1)}{n^k}=\lim_{n\to\infty}\sum_{k=0}^n f_n(k).$$ Here I have problems with limits, since the limit of the sum depends on $n$ and also the summation terms. I tried to fix it with the following: Let $g_n:=f_n\chi_{P_n}\colon \mathbb{N}\to \mathbb{R}$ measurable functions in the counting measure $\mu$ in $\mathbb{N}$  we have that $$g_n(k)=f_n(k)\chi_{P_n}(k)\to \frac{1}{k!}$$ for each $k\in\mathbb{N}$ and $P_n=\{1,\ldots,n\}$. But $$|g_n(k)|\leq \frac{1}{k!}:=f(k)\quad\text{and}\quad \int_{\mathbb{N}}f(k)d\mu(k)=\sum_{k=0}^\infty \frac{1}{k!}<3<\infty.$$ So by the Lebesgue Dominated Convergence Theorem, \begin{align} \lim_{n\to\infty}\left(1+\frac{1}{n}\right)^n&=\lim_{n\to\infty}\sum_{k=0}^n f_n(k)\\ &=\lim_{n\to\infty}\int_{P_n}f_n(k)d\mu(k)\\ &=\lim_{n\to\infty}\int_{\mathbb{N}}\chi_{P_n}(k) f_n(k)d\mu(k)\\ &=\lim_{n\to\infty}\int_{\mathbb{N}}g_n(k)d\mu(k)\\ &=\int_{\mathbb{N}}\lim_{n\to\infty}g_n(k)d\mu(k)\\ &=\int_{\mathbb{N}}f(k)d\mu(k)\\ &=\int_{\mathbb{N}}\frac{1}{k!}d\mu(k)\\ &=\sum_{k=0}^\infty \frac{1}{k!}. \end{align} Am I right?",,"['calculus', 'lebesgue-integral']"
8,What is the name of this property of a function,What is the name of this property of a function,,"I'm trying to find the right vocab word to describe a concept: In computational geometry, there's a concept of a polygon ""monotone"" with respect to a line.  Which means that the polygon intersects the line and all lines parallel to it in at most two places.  I want to find the equivalent concept for real valued functions.  That is, I want a property that describes a function that intersects a given line and lines parallel to it (in this case I'm interested in lines of the form $f(x) = c$, for all values of $c$, ie: horizontal lines) in at most two places. The obvious analog, monotone functions, isn't what I want at all, since it limits the first derivative to always have the same sign, and even allows it to go flat for a bit. The most sophisticated example I can think of: $\sin(x)$ over the interval $[0, 2\pi)$.  If the interval was increased at all in either direction, there'd exist a horizontal line that intersects the function in 3 places.  But if it's limited to just $[0, 2\pi)$, $\sin(x)$ only ever crosses any given horizontal line twice or less.  From this example, there doesn't seem to be any rules you can impose on the first or second (or higher) derivatives, which was my initial thought. Motivation: I'm thinking it's possible to decompose an oscillating (but not necessarily periodic) function in to chunks like this to help numerical root finders.  eg: $f(x)=\sin(x)+c$ (for all $c$) evaluated over all possible intervals exactly $2 \pi$ wide will have this property.  So if you break $\sin(x)+c$ in to $2\pi$ sized chunks, you know each chunk has at most two roots.  Smaller intervals (no matter how small) can still have up to two roots, so $2\pi$ is the largest interval that still guarantees this property.","I'm trying to find the right vocab word to describe a concept: In computational geometry, there's a concept of a polygon ""monotone"" with respect to a line.  Which means that the polygon intersects the line and all lines parallel to it in at most two places.  I want to find the equivalent concept for real valued functions.  That is, I want a property that describes a function that intersects a given line and lines parallel to it (in this case I'm interested in lines of the form $f(x) = c$, for all values of $c$, ie: horizontal lines) in at most two places. The obvious analog, monotone functions, isn't what I want at all, since it limits the first derivative to always have the same sign, and even allows it to go flat for a bit. The most sophisticated example I can think of: $\sin(x)$ over the interval $[0, 2\pi)$.  If the interval was increased at all in either direction, there'd exist a horizontal line that intersects the function in 3 places.  But if it's limited to just $[0, 2\pi)$, $\sin(x)$ only ever crosses any given horizontal line twice or less.  From this example, there doesn't seem to be any rules you can impose on the first or second (or higher) derivatives, which was my initial thought. Motivation: I'm thinking it's possible to decompose an oscillating (but not necessarily periodic) function in to chunks like this to help numerical root finders.  eg: $f(x)=\sin(x)+c$ (for all $c$) evaluated over all possible intervals exactly $2 \pi$ wide will have this property.  So if you break $\sin(x)+c$ in to $2\pi$ sized chunks, you know each chunk has at most two roots.  Smaller intervals (no matter how small) can still have up to two roots, so $2\pi$ is the largest interval that still guarantees this property.",,"['calculus', 'functions']"
9,"Prove that if a continuous function is injective, then it is monotonic","Prove that if a continuous function is injective, then it is monotonic",,"It is intuitive and it seems very obvious that if a function $f : X \rightarrow Y$ is continuous on whole $X$ and it's injective, then it must be monotonic, but I can't come up with any neat proof for that. Could you maybe help me?","It is intuitive and it seems very obvious that if a function $f : X \rightarrow Y$ is continuous on whole $X$ and it's injective, then it must be monotonic, but I can't come up with any neat proof for that. Could you maybe help me?",,['calculus']
10,Inspecting the function $f(x)=-x\sqrt{1-x^2}$,Inspecting the function,f(x)=-x\sqrt{1-x^2},"We are just wrapping up the first semester calculus with drawing graphs of functions. I sometimes feel like my reasoning is a bit shady when I am doing that, so I decided to ask you people from Math.SE. I am supposed to draw a graph (and show my working) of the function $f(x)=-x\sqrt{1-x^2}$: Below is my work, I'd be very grateful for any comments on possible loopholes in my reasoning (the results should be correct), thanks! $$\text{1. } f(x)=-x\sqrt{1-x^2}$$ Domain : We have a square-root function, therefore we need $1-x^2\geq0$. From that we get$x\in[-1,1]$. As this is the only necessary condition, $D(f)=[-1,1]$. The function is also continuous on this interval as there is nothing that would produce a discontinuity. Symmetry : $f(x)$ is an odd function, as $-f(x)=f(-x)$, as demonstrated here: $$-f(x)=f(-x)$$ $$-(-x\sqrt{1-x^2})=-(-x)\sqrt{1-(-x)^2}$$ $$x\sqrt{1-x^2}=x\sqrt{1-x^2}$$ Therefore we are only interested in the interval $[0,1]$, as the function will behave symmetrically on $[-1,0]$. x and y intercepts : $f(x)=0$ holds when $x=0,1$, those are then the x-intercepts . Thus also the y-intercept is at $(0,0)$ First derivative $$\begin{align} \ f'(x) &=(-x\sqrt{1-x^2})' \\  & = (-x)'\sqrt{1-x^2}+(-x)(\sqrt{1-x^2})' \\   & = -\sqrt{1-x^2}+(-x)\frac{1}{2\sqrt{1-x^2}}(-2x) \\   & = -\frac{1-x^2}{\sqrt{1-x^2}}+\frac{x^2}{\sqrt{1-x^2}} \\   & = \frac{2x^2-1}{\sqrt{1-x^2}} \\  \end{align}$$ Local minima and maxima: The equality $\frac{2x^2-1}{\sqrt{1-x^2}}=0$ yields $x=\frac{1}{\sqrt2}$. As $f(\frac{1}{\sqrt2})=-\frac{1}{2}$ and because we know the x-intercepts, we can conclude that this is the local minimum and the function is decreasing at $x\in [0,\frac{1}{\sqrt2})$ and increasing at $x\in(\frac{1}{\sqrt2},1]$. That can also be concluded from the fact that $f′≤0$ on the interval $[0,\frac{1}{\sqrt2}]$ and $f′≥0$ on the interval $[\frac{1}{\sqrt2},1]$. Second derivative $$\begin{align} \ f''(x) &=(\frac{2x^2-1}{\sqrt{1-x^2}})' \\  & = \frac{(2x^2-1)'\sqrt{1-x^2}-(2x^2-1)(\sqrt{1-x^2})'}{1-x^2} \\   & = \frac{4x\sqrt{1-x^2}-(2x^2-1)\frac{-x}{\sqrt{1-x^2}}}{1-x^2} \\   & = \frac{4x\frac{1-x^2}{\sqrt{1-x^2}}-(2x^2-1)\frac{-x}{\sqrt{1-x^2}}}{1-x^2} \\   & = \frac{\frac{-2x^3+3x}{\sqrt{1-x^2}}}{1-x^2} \\   & = \frac{-2x^3+3x}{\sqrt{(1-x^2)^3}} \\  \end{align}$$ Inflection point and concavity : $f''(x)=0$ has only one result and that is $x=0$. If we look at the inequality for $x\in(0,1]$. $$\begin{align} \ 0&<f''(x) \\ 0&<\frac{-2x^3+3x}{\sqrt{(1-x^2)^3}} \\ 0&<-2x^3+3x \\ 2x^3&<3x \\ 2x^2&<3 \\ x^2&<3/2 \\ \end{align}$$ We can see that $x^2<3/2$ is satisfied on $x\in(0,1]$, thus the function is convex on this interval. Conclusion: Using the symmetricity of the function, we can conclude that the function is increasing on $[-1,-\frac{1}{\sqrt2}]$ and $[\frac{1}{\sqrt2},1]$ and decreasing on $[-\frac{1}{\sqrt2},\frac{1}{\sqrt2}]$. It has local minimum at $x=\frac{1}{\sqrt2}$ and local maximum at $x=-\frac{1}{\sqrt2}$. It is concave on $[-1,0]$ and convex on $[0,1]$, with point of inflection at $x=0$.","We are just wrapping up the first semester calculus with drawing graphs of functions. I sometimes feel like my reasoning is a bit shady when I am doing that, so I decided to ask you people from Math.SE. I am supposed to draw a graph (and show my working) of the function $f(x)=-x\sqrt{1-x^2}$: Below is my work, I'd be very grateful for any comments on possible loopholes in my reasoning (the results should be correct), thanks! $$\text{1. } f(x)=-x\sqrt{1-x^2}$$ Domain : We have a square-root function, therefore we need $1-x^2\geq0$. From that we get$x\in[-1,1]$. As this is the only necessary condition, $D(f)=[-1,1]$. The function is also continuous on this interval as there is nothing that would produce a discontinuity. Symmetry : $f(x)$ is an odd function, as $-f(x)=f(-x)$, as demonstrated here: $$-f(x)=f(-x)$$ $$-(-x\sqrt{1-x^2})=-(-x)\sqrt{1-(-x)^2}$$ $$x\sqrt{1-x^2}=x\sqrt{1-x^2}$$ Therefore we are only interested in the interval $[0,1]$, as the function will behave symmetrically on $[-1,0]$. x and y intercepts : $f(x)=0$ holds when $x=0,1$, those are then the x-intercepts . Thus also the y-intercept is at $(0,0)$ First derivative $$\begin{align} \ f'(x) &=(-x\sqrt{1-x^2})' \\  & = (-x)'\sqrt{1-x^2}+(-x)(\sqrt{1-x^2})' \\   & = -\sqrt{1-x^2}+(-x)\frac{1}{2\sqrt{1-x^2}}(-2x) \\   & = -\frac{1-x^2}{\sqrt{1-x^2}}+\frac{x^2}{\sqrt{1-x^2}} \\   & = \frac{2x^2-1}{\sqrt{1-x^2}} \\  \end{align}$$ Local minima and maxima: The equality $\frac{2x^2-1}{\sqrt{1-x^2}}=0$ yields $x=\frac{1}{\sqrt2}$. As $f(\frac{1}{\sqrt2})=-\frac{1}{2}$ and because we know the x-intercepts, we can conclude that this is the local minimum and the function is decreasing at $x\in [0,\frac{1}{\sqrt2})$ and increasing at $x\in(\frac{1}{\sqrt2},1]$. That can also be concluded from the fact that $f′≤0$ on the interval $[0,\frac{1}{\sqrt2}]$ and $f′≥0$ on the interval $[\frac{1}{\sqrt2},1]$. Second derivative $$\begin{align} \ f''(x) &=(\frac{2x^2-1}{\sqrt{1-x^2}})' \\  & = \frac{(2x^2-1)'\sqrt{1-x^2}-(2x^2-1)(\sqrt{1-x^2})'}{1-x^2} \\   & = \frac{4x\sqrt{1-x^2}-(2x^2-1)\frac{-x}{\sqrt{1-x^2}}}{1-x^2} \\   & = \frac{4x\frac{1-x^2}{\sqrt{1-x^2}}-(2x^2-1)\frac{-x}{\sqrt{1-x^2}}}{1-x^2} \\   & = \frac{\frac{-2x^3+3x}{\sqrt{1-x^2}}}{1-x^2} \\   & = \frac{-2x^3+3x}{\sqrt{(1-x^2)^3}} \\  \end{align}$$ Inflection point and concavity : $f''(x)=0$ has only one result and that is $x=0$. If we look at the inequality for $x\in(0,1]$. $$\begin{align} \ 0&<f''(x) \\ 0&<\frac{-2x^3+3x}{\sqrt{(1-x^2)^3}} \\ 0&<-2x^3+3x \\ 2x^3&<3x \\ 2x^2&<3 \\ x^2&<3/2 \\ \end{align}$$ We can see that $x^2<3/2$ is satisfied on $x\in(0,1]$, thus the function is convex on this interval. Conclusion: Using the symmetricity of the function, we can conclude that the function is increasing on $[-1,-\frac{1}{\sqrt2}]$ and $[\frac{1}{\sqrt2},1]$ and decreasing on $[-\frac{1}{\sqrt2},\frac{1}{\sqrt2}]$. It has local minimum at $x=\frac{1}{\sqrt2}$ and local maximum at $x=-\frac{1}{\sqrt2}$. It is concave on $[-1,0]$ and convex on $[0,1]$, with point of inflection at $x=0$.",,['calculus']
11,"Is the ""Constant Rank Theorem"" the same as the ""Domain Straightening Theorem""? Which theorem is which?","Is the ""Constant Rank Theorem"" the same as the ""Domain Straightening Theorem""? Which theorem is which?",,"Wikipedia says that the inverse function theorem is a special case of the "" constant rank theorem "". I'm pretty sure this is supposed to be the same theorem as the ""Rank Theorem"" on p. 47 of Boothby (especially because the wikipedia article also footnotes to Boothby...), and then in Boothby, he says in a footnote that it is also known as the ""Straightening Out Theorem."" Wikipedia also has an article on a "" Domain Straightening Theorem "". Which seems vaguely related but does not explicitly discuss anything about rank. Could someone please help me sort out which theorem is which? My main goal is to find a more in-depth discussion of the ""Constant Rank Theorem"" (or whatever the true general case of the IFT is) (reading suggestions welcome!), but I would also like to know which of these names refers to the same theorem, and which doesn't.","Wikipedia says that the inverse function theorem is a special case of the "" constant rank theorem "". I'm pretty sure this is supposed to be the same theorem as the ""Rank Theorem"" on p. 47 of Boothby (especially because the wikipedia article also footnotes to Boothby...), and then in Boothby, he says in a footnote that it is also known as the ""Straightening Out Theorem."" Wikipedia also has an article on a "" Domain Straightening Theorem "". Which seems vaguely related but does not explicitly discuss anything about rank. Could someone please help me sort out which theorem is which? My main goal is to find a more in-depth discussion of the ""Constant Rank Theorem"" (or whatever the true general case of the IFT is) (reading suggestions welcome!), but I would also like to know which of these names refers to the same theorem, and which doesn't.",,"['calculus', 'linear-algebra', 'differential-geometry', 'multivariable-calculus', 'coordinate-systems']"
12,Is there any identity for $\sum_{k=1}^{n}\tan\left(\theta+\frac{k\pi}{\color{red} {2n+1}}\right)$?,Is there any identity for ?,\sum_{k=1}^{n}\tan\left(\theta+\frac{k\pi}{\color{red} {2n+1}}\right),"Is there any identity for $\sum_{k=1}^{n}\tan\left(\theta+\frac{k\pi}{\color{red} {2n+1}}\right)$ or $\sum_{k=1}^{n}\tan\left(\frac{k\pi}{\color{red} {2n+1}}\right)$ ? I thought maybe wrongly that given: $\sum_{k=1}^{n}\cot\left(\frac{k\pi}{\color{red} {2n+1}}\right)=\sum_{k=1}^{n}-\tan\left(\frac{\pi}{ {2}}+\frac{k\pi}{\color{red} {2n+1}}\right)$ and since $n \cot(nx)$ is the logarithmic derivative of $\sin(nx)$ and $\cot\left(x+\frac{\pi k}{n}\right)$ is the logarithmic derivative of $\sin\left(x+\frac{\pi k}{n}\right)$ , I tried manipulating the identity: $2^n \prod_{k=1}^n \sin\left(\frac{k\pi}{2n+1}\right)=\sqrt{2n+1}$ but I kept getting stuck. The variation $\sum_{k=0}^{n-1}\tan\left(\theta+\frac{k\pi}{n}\right)=−n\cot\left(\frac{n\pi}{2}+n\theta\right)$ is seen to work quite nicely.","Is there any identity for or ? I thought maybe wrongly that given: and since is the logarithmic derivative of and is the logarithmic derivative of , I tried manipulating the identity: but I kept getting stuck. The variation is seen to work quite nicely.",\sum_{k=1}^{n}\tan\left(\theta+\frac{k\pi}{\color{red} {2n+1}}\right) \sum_{k=1}^{n}\tan\left(\frac{k\pi}{\color{red} {2n+1}}\right) \sum_{k=1}^{n}\cot\left(\frac{k\pi}{\color{red} {2n+1}}\right)=\sum_{k=1}^{n}-\tan\left(\frac{\pi}{ {2}}+\frac{k\pi}{\color{red} {2n+1}}\right) n \cot(nx) \sin(nx) \cot\left(x+\frac{\pi k}{n}\right) \sin\left(x+\frac{\pi k}{n}\right) 2^n \prod_{k=1}^n \sin\left(\frac{k\pi}{2n+1}\right)=\sqrt{2n+1} \sum_{k=0}^{n-1}\tan\left(\theta+\frac{k\pi}{n}\right)=−n\cot\left(\frac{n\pi}{2}+n\theta\right),"['calculus', 'sequences-and-series', 'complex-analysis', 'trigonometry', 'summation']"
13,"Does there exist a function $f(x)$, which is “parallel” to $e^x$ and has a finite “norm”?","Does there exist a function , which is “parallel” to  and has a finite “norm”?",f(x) e^x,"Does there exist a function $f: \mathbb{R} \rightarrow \mathbb{R}$ such that $$ \lim_{M \rightarrow +\infty}\frac{\int_{-M}^{M}f(x)e^xdx}{\Big(\int_{-M}^{M}(f(x))^2dx\int_{-M}^{M}(e^x)^2dx\Big)^{1/2}}=1 $$ but also the limit $$ \lim_{M \rightarrow +\infty} \int_{-M}^{M} (f(x))^2 dx  $$ exists and finite? I suppose the answer is no, but I don’t know how to prove it. Motivation. I think of the first limit as of some generalization of the cosine between two vectors (as it is somehow similar to a dot product of two vectors divided by their norms). So the first limit says that functions $f(x)$ and $e^x$ are parallel in some sense (although not in the common sense as there is a limit before the whole fraction). The second limit says that that we are looking for a function $f(x)$ with a finite $L_2$ -norm (again, not exactly the norm, but maybe its principal value ). Functions $f(x) = ae^x$ with $a \in \mathbb{R}_+$ satisfy the first condition (as they are parallel to $e^x$ ), but do not satisfy the second (as their “norm” is infinite). I wonder if there exists such $f(x)$ which satisfies both.","Does there exist a function such that but also the limit exists and finite? I suppose the answer is no, but I don’t know how to prove it. Motivation. I think of the first limit as of some generalization of the cosine between two vectors (as it is somehow similar to a dot product of two vectors divided by their norms). So the first limit says that functions and are parallel in some sense (although not in the common sense as there is a limit before the whole fraction). The second limit says that that we are looking for a function with a finite -norm (again, not exactly the norm, but maybe its principal value ). Functions with satisfy the first condition (as they are parallel to ), but do not satisfy the second (as their “norm” is infinite). I wonder if there exists such which satisfies both.","f: \mathbb{R} \rightarrow \mathbb{R} 
\lim_{M \rightarrow +\infty}\frac{\int_{-M}^{M}f(x)e^xdx}{\Big(\int_{-M}^{M}(f(x))^2dx\int_{-M}^{M}(e^x)^2dx\Big)^{1/2}}=1
 
\lim_{M \rightarrow +\infty} \int_{-M}^{M} (f(x))^2 dx 
 f(x) e^x f(x) L_2 f(x) = ae^x a \in \mathbb{R}_+ e^x f(x)","['calculus', 'functional-analysis']"
14,Find extrema of $\cos\left(\frac\pi2\cos x\right)+\cos\left(\frac\pi2\sin x\right)$ without differentiation,Find extrema of  without differentiation,\cos\left(\frac\pi2\cos x\right)+\cos\left(\frac\pi2\sin x\right),"Question is: find minimum and maximum of $f(x)$ : $$f(x)=\cos\left(\frac\pi2\cos x\right)+\cos\left(\frac\pi2\sin x\right)$$ without differentiation. This problem is supposed to be solved only with pre-calculus knowledge, but I have no idea how to do it. $f(x)$ decreases monotonically from $\frac{n\pi}2$ to $\frac{n\pi}2+\frac\pi4$ , and monotonically increases from $\frac{n\pi}2+\frac\pi4$ to $\frac{(n+1)\pi}2$ , but how can it be proved the monotonicity without calculus? I also tried to transform the expression into \begin{align}f(x)=&2\cos\left(\frac\pi4(\cos x+\sin x)\right)\cos\left(\frac\pi4(\cos x-\sin x)\right)\\=&2\cos\left(\frac{\sqrt2\pi}4\sin \left(x+\frac\pi4\right)\right)\cos\left(\frac{\sqrt2\pi}4\sin\left(-x+\frac\pi4\right)\right)\end{align} but found it has the same issue of proving the monotonicity.","Question is: find minimum and maximum of : without differentiation. This problem is supposed to be solved only with pre-calculus knowledge, but I have no idea how to do it. decreases monotonically from to , and monotonically increases from to , but how can it be proved the monotonicity without calculus? I also tried to transform the expression into but found it has the same issue of proving the monotonicity.",f(x) f(x)=\cos\left(\frac\pi2\cos x\right)+\cos\left(\frac\pi2\sin x\right) f(x) \frac{n\pi}2 \frac{n\pi}2+\frac\pi4 \frac{n\pi}2+\frac\pi4 \frac{(n+1)\pi}2 \begin{align}f(x)=&2\cos\left(\frac\pi4(\cos x+\sin x)\right)\cos\left(\frac\pi4(\cos x-\sin x)\right)\\=&2\cos\left(\frac{\sqrt2\pi}4\sin \left(x+\frac\pi4\right)\right)\cos\left(\frac{\sqrt2\pi}4\sin\left(-x+\frac\pi4\right)\right)\end{align},"['calculus', 'algebra-precalculus']"
15,What is the infinite product series for $\exp(\sin(x))-1$?,What is the infinite product series for ?,\exp(\sin(x))-1,$e^{\sin(x)}-1$ has the same roots as $\sin(x)$ . What is the difference between infinite product series expansions of $\sin(x)$ and $e^{\sin(x)}-1$ if they both have same infinite roots ?,has the same roots as . What is the difference between infinite product series expansions of and if they both have same infinite roots ?,e^{\sin(x)}-1 \sin(x) \sin(x) e^{\sin(x)}-1,['calculus']
16,Determine convergence of harmonic series with a minus every third term,Determine convergence of harmonic series with a minus every third term,,"I want to evaluate the following sum: $$ 1 + \frac{1}{2} - \frac{1}{3} + \frac{1}{4} + \frac{1}{5} - \frac{1}{6}+\ldots $$ call the sequence $a_k$. That is, the harmonic series, with the sign flipped every third term. I tried to approach this in two ways. One way is by defining a sequence $b_k = \left(\frac{1}{3k-2} + \frac{1}{3k-1} -\frac{1}{3k}\right)$. Then, we can see that $\sum b_k$ is the series $\sum a_k$ after we gather every three terms. Then, $b_k = \frac{9k^2-2}{3k(3k-2)(3k-1)}$, and $b_k\sim \frac{1}{3}\frac{1}{k}$, and therefore $\sum b_k$ diverges. Can I conclude that $\sum a_k$ diverge? The other way is by partial sums. I concluded the following inequality $$ S_{3n-2} < S_{3n} < S_{3n-1} $$ But also, I discovered that $S_{3n-2},S_{3n-1},S_{3n}$ are increasing, and I was unable to find a bound for them. Now, for the first way, it is kind of implying that the series diverges, since we learned at our calculus class that if $\sum a_n$ converges, then any way of putting brackets will result in a convergence. On the other way, if a series is created by putting brackets in another series with bounded bracket length, then if it is convergent then the original series converges. Does this series diverge?","I want to evaluate the following sum: $$ 1 + \frac{1}{2} - \frac{1}{3} + \frac{1}{4} + \frac{1}{5} - \frac{1}{6}+\ldots $$ call the sequence $a_k$. That is, the harmonic series, with the sign flipped every third term. I tried to approach this in two ways. One way is by defining a sequence $b_k = \left(\frac{1}{3k-2} + \frac{1}{3k-1} -\frac{1}{3k}\right)$. Then, we can see that $\sum b_k$ is the series $\sum a_k$ after we gather every three terms. Then, $b_k = \frac{9k^2-2}{3k(3k-2)(3k-1)}$, and $b_k\sim \frac{1}{3}\frac{1}{k}$, and therefore $\sum b_k$ diverges. Can I conclude that $\sum a_k$ diverge? The other way is by partial sums. I concluded the following inequality $$ S_{3n-2} < S_{3n} < S_{3n-1} $$ But also, I discovered that $S_{3n-2},S_{3n-1},S_{3n}$ are increasing, and I was unable to find a bound for them. Now, for the first way, it is kind of implying that the series diverges, since we learned at our calculus class that if $\sum a_n$ converges, then any way of putting brackets will result in a convergence. On the other way, if a series is created by putting brackets in another series with bounded bracket length, then if it is convergent then the original series converges. Does this series diverge?",,"['calculus', 'sequences-and-series']"
17,A difficult integral (expectation of the function of a random variable),A difficult integral (expectation of the function of a random variable),,"For $H>L$ , $p,q,\alpha,\beta>0$, and B(.,.) the beta functon, trying to solve this integral: $$\mathbb{E}(X)_0^H=\frac{\alpha  H }{\beta  B(p,q)}\int_0^H \frac{x \left(\frac{-H \log \left(\frac{H-x}{H}\right)}{\beta }\right)^{\alpha  p-1} \left(\left(\frac{-H \log \left(\frac{H-x}{H}\right)}{\beta }\right)^{\alpha }+1\right)^{-p-q}}{H-x} \, \mathrm{d}x$$ ${\bf Motivation: }$ This is the partial expectation of the random variable $X \in[0,H]$, a  transformation of a r.v. following the generalized Beta distribution of second kind (also known as the Beta prime distribution). ${\bf Note: }$ I simplified the question and changed the support from $X \in [L,H]$ to $X \in [0,H]$.","For $H>L$ , $p,q,\alpha,\beta>0$, and B(.,.) the beta functon, trying to solve this integral: $$\mathbb{E}(X)_0^H=\frac{\alpha  H }{\beta  B(p,q)}\int_0^H \frac{x \left(\frac{-H \log \left(\frac{H-x}{H}\right)}{\beta }\right)^{\alpha  p-1} \left(\left(\frac{-H \log \left(\frac{H-x}{H}\right)}{\beta }\right)^{\alpha }+1\right)^{-p-q}}{H-x} \, \mathrm{d}x$$ ${\bf Motivation: }$ This is the partial expectation of the random variable $X \in[0,H]$, a  transformation of a r.v. following the generalized Beta distribution of second kind (also known as the Beta prime distribution). ${\bf Note: }$ I simplified the question and changed the support from $X \in [L,H]$ to $X \in [0,H]$.",,"['calculus', 'integration', 'probability-theory', 'probability-distributions', 'beta-function']"
18,An integral with $e^{1+e^x}$ I had trouble working through,An integral with  I had trouble working through,e^{1+e^x},"I had an analysis test earlier this morning and came across this integral, which I couldn't figure out. Parts of it are easy, but after integrating $y$ you're left integrating $xe^{1+e^x}$ which had me stumped. $\displaystyle\int^1_0 \int^{1 + e^x}_x xe^y dy dx$ What did I miss? I couldn't think of any substitutions or any change of variables that would help me here. Wolfram alpha gives me the numerical solution, but doesn't provide the step-by-step, otherwise I'd walk through that.","I had an analysis test earlier this morning and came across this integral, which I couldn't figure out. Parts of it are easy, but after integrating $y$ you're left integrating $xe^{1+e^x}$ which had me stumped. $\displaystyle\int^1_0 \int^{1 + e^x}_x xe^y dy dx$ What did I miss? I couldn't think of any substitutions or any change of variables that would help me here. Wolfram alpha gives me the numerical solution, but doesn't provide the step-by-step, otherwise I'd walk through that.",,"['calculus', 'integration', 'analysis']"
19,"How do I  find, algorithmically,  which parts of a given function are interesting to graph?","How do I  find, algorithmically,  which parts of a given function are interesting to graph?",,"I'm building a program that does 2D graphing, and was wondering: How can I determine the default zoom level and x/y extents to display on screen, in such a way as to maximise the 'interesting' parts of a function that are shown? ""Interesting parts"" would include: Minimums/maximums/plateaus, Parts of the space where you can actually see the function, Roots, Discontinuities, and anything else that helps understand what the function looks like and what it does. I am not necessarily looking for a perfect solution, just something that works well for most common cases, hopefully without having to solve the equation the user entered. Is there a general method I can use? Or a book/reference that might help? Thanks!","I'm building a program that does 2D graphing, and was wondering: How can I determine the default zoom level and x/y extents to display on screen, in such a way as to maximise the 'interesting' parts of a function that are shown? ""Interesting parts"" would include: Minimums/maximums/plateaus, Parts of the space where you can actually see the function, Roots, Discontinuities, and anything else that helps understand what the function looks like and what it does. I am not necessarily looking for a perfect solution, just something that works well for most common cases, hopefully without having to solve the equation the user entered. Is there a general method I can use? Or a book/reference that might help? Thanks!",,"['calculus', 'functions', 'graphing-functions', 'calculator']"
20,Is it feasible to use Operator Calculus to solve for $f(t)=\underbrace{\exp(\exp(\dots\exp}_{t}(0)\dots))$ over $\mathbb{R}$,Is it feasible to use Operator Calculus to solve for  over,f(t)=\underbrace{\exp(\exp(\dots\exp}_{t}(0)\dots)) \mathbb{R},"Consider the function $f(t)=\exp^{(t)}(0)$ where $\exp^{(0)}(0)=0$ and $\exp^{(t+1)}(0)=\exp(\exp^{(t)}(0))$ . That is, $$f(t)=\underbrace{\exp(\exp(\dots\exp}_{t}(0)\dots)).$$ Such a function is not short of prior study on this website before, as finding such an analytic interpolation allows for construction of functions like $h(x)$ , where $$h(h(x))=\exp(x),$$ by taking $h(x)=f\left(\frac{1}{2}+f^{-1}\left(x\right)\right)$ , as described in this answer . There are infinitely many continuous constructions for $f$ over the reals, but AFAIK, an analytic, or even an infinitely smooth example is elusive. As inspired by this video , my question is, using Operator Calculus , is it possible to solve for a (potentially analytic) solution to $f$ ? My idea comes from the fact that, by definition, $$f(x+1)=\exp(f(x))\iff\tau f(x)=\exp(f(x)),$$ where $\tau$ is the Shift Operator . Hence, using Operator Calculus, we find the expression $$e^D f(x) = e^{f(x)}\iff\sum_{n=0}^\infty \frac{D^n f(x)}{n!}=\sum_{n=0}^\infty \frac{(f(x))^n}{n!},$$ where $D=\frac{d}{dx}$ . Furthermore, $f$ also has the property that $$\frac{f'(x)}{f(x)}=f'(x-1)\iff \tau\frac{Df(x)}{f(x)}=Df(x).$$ From these facts, is it possible to solve for a solution? Update: Using the aforementioned method, I was able to deduce the inductive relation: $$D^{n+1}f(1)=\sum_{k=0}^n{n \choose k} (D^{n-k+1}f(0))(D^{k}f(1)).$$ Thus, assuming $D^{m}f(0)=m!c_m$ for $m\in\mathbb{N}$ when $$f(x)=\sum_{n=0}^\infty c_n x^n,$$ we find that $$D^{n+1}f(1)=\sum_{k=0}^n \frac{n!}{k!}(n-k+1)c_{n-k+1}(D^{k}f(1)).$$ With this, given that $$D^{n}f(1)=\sum_{k=n}^{\infty}\frac{k!}{(k-n)!}c_k x^{k-n},$$ I assume we have enough information to solve for the coefficients $(c_k)_{k\in\mathbb{N}}$ . However, this seemingly surmounts to solving a countably infinite system of equations, to which I am dumbfounded at where to begin.","Consider the function where and . That is, Such a function is not short of prior study on this website before, as finding such an analytic interpolation allows for construction of functions like , where by taking , as described in this answer . There are infinitely many continuous constructions for over the reals, but AFAIK, an analytic, or even an infinitely smooth example is elusive. As inspired by this video , my question is, using Operator Calculus , is it possible to solve for a (potentially analytic) solution to ? My idea comes from the fact that, by definition, where is the Shift Operator . Hence, using Operator Calculus, we find the expression where . Furthermore, also has the property that From these facts, is it possible to solve for a solution? Update: Using the aforementioned method, I was able to deduce the inductive relation: Thus, assuming for when we find that With this, given that I assume we have enough information to solve for the coefficients . However, this seemingly surmounts to solving a countably infinite system of equations, to which I am dumbfounded at where to begin.","f(t)=\exp^{(t)}(0) \exp^{(0)}(0)=0 \exp^{(t+1)}(0)=\exp(\exp^{(t)}(0)) f(t)=\underbrace{\exp(\exp(\dots\exp}_{t}(0)\dots)). h(x) h(h(x))=\exp(x), h(x)=f\left(\frac{1}{2}+f^{-1}\left(x\right)\right) f f f(x+1)=\exp(f(x))\iff\tau f(x)=\exp(f(x)), \tau e^D f(x) = e^{f(x)}\iff\sum_{n=0}^\infty \frac{D^n f(x)}{n!}=\sum_{n=0}^\infty \frac{(f(x))^n}{n!}, D=\frac{d}{dx} f \frac{f'(x)}{f(x)}=f'(x-1)\iff \tau\frac{Df(x)}{f(x)}=Df(x). D^{n+1}f(1)=\sum_{k=0}^n{n \choose k} (D^{n-k+1}f(0))(D^{k}f(1)). D^{m}f(0)=m!c_m m\in\mathbb{N} f(x)=\sum_{n=0}^\infty c_n x^n, D^{n+1}f(1)=\sum_{k=0}^n \frac{n!}{k!}(n-k+1)c_{n-k+1}(D^{k}f(1)). D^{n}f(1)=\sum_{k=n}^{\infty}\frac{k!}{(k-n)!}c_k x^{k-n}, (c_k)_{k\in\mathbb{N}}","['calculus', 'derivatives', 'functional-equations', 'differential-operators']"
21,Definite integral of $\int e^{-\sin^2x}\cos\Bigl(6x-\frac{\sin(2x)}{2}\Bigr)dx$,Definite integral of,\int e^{-\sin^2x}\cos\Bigl(6x-\frac{\sin(2x)}{2}\Bigr)dx,"I have the integral with $\sin()$ sum expression in $\cos()$ argument: $$\int_0^{2\pi}e^{-\sin^2x}\cos\Bigl(6x-\frac{\sin(2x)}{2}\Bigr)dx.$$ Can anyone please explain an algorithm for solving it? I've tried so far: Weierstrass substitution (if I can use it with $\int \cos(f(x))dx$ ), Euler formula, integration by parts, formula of $\cos(x-y)$ and $\sin(2x)$ formula and everything not seems to work or I make actions not in the right order. Need some fresh view on the problem. Thanks!","I have the integral with sum expression in argument: Can anyone please explain an algorithm for solving it? I've tried so far: Weierstrass substitution (if I can use it with ), Euler formula, integration by parts, formula of and formula and everything not seems to work or I make actions not in the right order. Need some fresh view on the problem. Thanks!",\sin() \cos() \int_0^{2\pi}e^{-\sin^2x}\cos\Bigl(6x-\frac{\sin(2x)}{2}\Bigr)dx. \int \cos(f(x))dx \cos(x-y) \sin(2x),"['integration', 'definite-integrals', 'trigonometric-integrals']"
22,Calculate in closed form: $\int_{0}^{\pi/2}\arctan\left(\frac{1}{\sqrt{2\sin x}}\right)dx$,Calculate in closed form:,\int_{0}^{\pi/2}\arctan\left(\frac{1}{\sqrt{2\sin x}}\right)dx,"I did the replacement, $u = \sqrt{2\sin x}$ , but I did not succeed. $u = \sqrt{2\sin x}$ . I found, $$ \int_{0}^{\pi/2}\arctan(x)\cot(x)\,dx, \quad \int_{0}^{\pi/2}\arctan(\sin x)\,dx $$ But the techniques used in these integrals did not help much. Thank you for any help.","I did the replacement, , but I did not succeed. . I found, But the techniques used in these integrals did not help much. Thank you for any help.","u = \sqrt{2\sin x} u = \sqrt{2\sin x} 
\int_{0}^{\pi/2}\arctan(x)\cot(x)\,dx, \quad \int_{0}^{\pi/2}\arctan(\sin x)\,dx
","['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
23,Regarding the sum $\sum_{p \ \text{prime}} \sin p$,Regarding the sum,\sum_{p \ \text{prime}} \sin p,"I'm very confident that  $$\sum_{p \ \text{prime}} \sin p $$ diverges. Of course, it suffices to show that there are arbitrarily large primes which are not in the set $\bigcup_{n \geq 1} (\pi n - \epsilon, \pi n + \epsilon)$ for sufficiently small $\epsilon$. More strongly, it seems that $\sin p$ for prime $p$ is dense in $[-1,1]$. This problem doesn't seem that hard though. Here's something that (to me) seems harder. If $p_n$ is the nth prime, what is $$\limsup_{n \to +\infty} \sum_{p \ \text{prime} \leq p_n} \sin p?$$   What is $$\sup_{n \in \mathbb{N}} \sum_{p \ \text{prime} \leq p_n} \sin p? $$ Of course, we can ask analogous questions for $\inf$. I'm happy with partial answers or ideas. For example, merely an upper bound.","I'm very confident that  $$\sum_{p \ \text{prime}} \sin p $$ diverges. Of course, it suffices to show that there are arbitrarily large primes which are not in the set $\bigcup_{n \geq 1} (\pi n - \epsilon, \pi n + \epsilon)$ for sufficiently small $\epsilon$. More strongly, it seems that $\sin p$ for prime $p$ is dense in $[-1,1]$. This problem doesn't seem that hard though. Here's something that (to me) seems harder. If $p_n$ is the nth prime, what is $$\limsup_{n \to +\infty} \sum_{p \ \text{prime} \leq p_n} \sin p?$$   What is $$\sup_{n \in \mathbb{N}} \sum_{p \ \text{prime} \leq p_n} \sin p? $$ Of course, we can ask analogous questions for $\inf$. I'm happy with partial answers or ideas. For example, merely an upper bound.",,"['calculus', 'real-analysis', 'sequences-and-series']"
24,"Integrating $\int_{0}^{\infty} \frac{p^6 dp }{1 + a p^4 + b p^6 } \int_{0}^{\pi}\frac{\sin^5 \theta \,d\theta}{1 + a |p-k|^4 + b |p-k|^6 }$",Integrating,"\int_{0}^{\infty} \frac{p^6 dp }{1 + a p^4 + b p^6 } \int_{0}^{\pi}\frac{\sin^5 \theta \,d\theta}{1 + a |p-k|^4 + b |p-k|^6 }","This is my first question here, so I hope I'm not giving too little/too much information. I need some help calculating (or even approximating) an integral which I've been wrestling with for a while. As part of my internship, I need to calculate or even just approximate a power spectrum which boils down to the following integral: $$I(k)=\int \frac{d^3p}{(2\pi)^3} (1 - \kappa^2)(1-\lambda^2) \frac{\left\lvert p \right\rvert^2}{(1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6)}  \frac{\left\lvert p-k \right\rvert^2}{(1 + a \left\lvert p-k \right\rvert^4 + b \left\lvert p-k \right\rvert^6)}$$ where $\kappa = \hat{k}.\hat{p}$ and $\lambda = \hat{k}.\widehat{k-p}$ (Obviously $\left\lvert p-k \right\rvert^2 = p^2 + k^2 - 2 p k \cos \theta$). I need the answer in terms of $a,b$, two positive constants that I'd like to vary to describe different physical situations. First attempt at a solution: I moved into spherical coordinates and (I'm reasonably sure that) the integral reduces to: $$\int \frac{d^3p}{(2\pi)^3} \frac{\left\lvert p \right\rvert^2}{1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6 }  \frac{\left\lvert p \right\rvert^2\sin^4 \theta}{1 + a \left\lvert p-k \right\rvert^4 + b \left\lvert p-k \right\rvert^6 }$$ So naturally I considered performing the integration $$\frac{1}{2\pi^2}\int_{0}^{\infty} \frac{\left\lvert p \right\rvert^6 dp }{1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6 }  \int_{0}^{\pi}\frac{\sin^5 \theta \,d\theta}{1 + a \left\lvert p-k \right\rvert^4 + b \left\lvert p-k \right\rvert^6 }$$ Sadly, this doesn't really help me too much since these integrals are still pretty hard. Mathematica does manage to calculate them, but the results are really far too cumbersome to handle. Further attempts: As an approximation, I considered sloppily breaking the integral into $p<k$ and $p>k$, which leads me to something of the form (modulo constants): $$\frac{1}{1 + a \left\lvert k \right\rvert^4 + b \left\lvert k \right\rvert^6 }\int_{0}^{k} \frac{\left\lvert p \right\rvert^6 dp}{1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6} +\int_{k}^{\infty} \frac{\left\lvert p \right\rvert^6 dp}{(1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6)^2 }  $$ But I found even these ""simpler"" integrals too hard to calculate, and I'm not particularly fond of the approximation either. Questions: 1) Does anyone know of a way I could solve or even approximate any of the above integrals as a function of the parameters $a$ and $b$? 2) It reminds me slightly on a convolution product, though not exactly since it's the norm of the vector $\left\lvert p-k \right\rvert$, which means I can't use the convolution theorem (can I?). 3) I know how to use the Feynman Parametrization for terms that are quadratic in the denominator. But I don't think it would work with $\left\lvert p\right\rvert^6$ (would it?). 3) The parameters $a$ and $b$ are quite small ($a$ is of the order of $10^{-2}$ and $b$ around the same), I was wondering if I could use that to my advantage, maybe perform some sort of Taylor expansion in either of them, reducing the integral to something more manageable, but I'm not sure that's allowed, and at any rate such integrals seem to diverge. Thanks!","This is my first question here, so I hope I'm not giving too little/too much information. I need some help calculating (or even approximating) an integral which I've been wrestling with for a while. As part of my internship, I need to calculate or even just approximate a power spectrum which boils down to the following integral: $$I(k)=\int \frac{d^3p}{(2\pi)^3} (1 - \kappa^2)(1-\lambda^2) \frac{\left\lvert p \right\rvert^2}{(1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6)}  \frac{\left\lvert p-k \right\rvert^2}{(1 + a \left\lvert p-k \right\rvert^4 + b \left\lvert p-k \right\rvert^6)}$$ where $\kappa = \hat{k}.\hat{p}$ and $\lambda = \hat{k}.\widehat{k-p}$ (Obviously $\left\lvert p-k \right\rvert^2 = p^2 + k^2 - 2 p k \cos \theta$). I need the answer in terms of $a,b$, two positive constants that I'd like to vary to describe different physical situations. First attempt at a solution: I moved into spherical coordinates and (I'm reasonably sure that) the integral reduces to: $$\int \frac{d^3p}{(2\pi)^3} \frac{\left\lvert p \right\rvert^2}{1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6 }  \frac{\left\lvert p \right\rvert^2\sin^4 \theta}{1 + a \left\lvert p-k \right\rvert^4 + b \left\lvert p-k \right\rvert^6 }$$ So naturally I considered performing the integration $$\frac{1}{2\pi^2}\int_{0}^{\infty} \frac{\left\lvert p \right\rvert^6 dp }{1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6 }  \int_{0}^{\pi}\frac{\sin^5 \theta \,d\theta}{1 + a \left\lvert p-k \right\rvert^4 + b \left\lvert p-k \right\rvert^6 }$$ Sadly, this doesn't really help me too much since these integrals are still pretty hard. Mathematica does manage to calculate them, but the results are really far too cumbersome to handle. Further attempts: As an approximation, I considered sloppily breaking the integral into $p<k$ and $p>k$, which leads me to something of the form (modulo constants): $$\frac{1}{1 + a \left\lvert k \right\rvert^4 + b \left\lvert k \right\rvert^6 }\int_{0}^{k} \frac{\left\lvert p \right\rvert^6 dp}{1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6} +\int_{k}^{\infty} \frac{\left\lvert p \right\rvert^6 dp}{(1 + a \left\lvert p \right\rvert^4 + b \left\lvert p \right\rvert^6)^2 }  $$ But I found even these ""simpler"" integrals too hard to calculate, and I'm not particularly fond of the approximation either. Questions: 1) Does anyone know of a way I could solve or even approximate any of the above integrals as a function of the parameters $a$ and $b$? 2) It reminds me slightly on a convolution product, though not exactly since it's the norm of the vector $\left\lvert p-k \right\rvert$, which means I can't use the convolution theorem (can I?). 3) I know how to use the Feynman Parametrization for terms that are quadratic in the denominator. But I don't think it would work with $\left\lvert p\right\rvert^6$ (would it?). 3) The parameters $a$ and $b$ are quite small ($a$ is of the order of $10^{-2}$ and $b$ around the same), I was wondering if I could use that to my advantage, maybe perform some sort of Taylor expansion in either of them, reducing the integral to something more manageable, but I'm not sure that's allowed, and at any rate such integrals seem to diverge. Thanks!",,"['calculus', 'definite-integrals', 'physics', 'convolution', 'approximate-integration']"
25,Why do these two integrals use roots of reciprocal polynomials?,Why do these two integrals use roots of reciprocal polynomials?,,"There is the nice integral by V. Reshetnikov, $$\int_0^1\frac{dx}{\sqrt[3]x\ \sqrt[6]{1-x}\ \sqrt{1-x\,\alpha^2}}=\frac{1}{N}\,\frac{2\pi}{\sqrt{3}\;\alpha}\tag1$$ also discussed in this post . By direct analogy, we can consider its cousin, $$\int_0^1\frac{dx}{\sqrt[4]x\ \sqrt[4]{1-x}\ \sqrt{1-x\,\beta^2}}=\frac{1}{N}\,\frac{2\pi}{\sqrt{2}\;\beta}\tag{2a}$$ and the version investigated also by Reshetnikov, $$\int_0^1\frac{dx}{\sqrt[4]x\ \sqrt{1-x}\ \sqrt[4]{1-x\,\gamma^2}}=\frac{1}{N}\,\frac{2\pi}{\sqrt{2\gamma}}\tag{2b}$$ Given some integer/rational $N$ , it entails finding algebraic numbers $\alpha, \beta, \gamma$ such that, $$\begin{aligned} \frac{1}{N}=I\left(\alpha^2;\ \tfrac12,\tfrac13\right)= \frac{B\left(\alpha^2;\ \tfrac12,\tfrac13\right)}{B\left(\tfrac12,\tfrac13\right)} \end{aligned} $$ $$\begin{aligned} \frac{1}{N}=I\left(\beta^2;\ \tfrac12,\tfrac14\right)= \frac{B\left(\beta^2;\ \tfrac12,\tfrac14\right)}{B\left(\tfrac12,\tfrac14\right)}\\ \end{aligned}$$ $$\begin{aligned} \frac{1}{N}=I\left(\gamma^2;\ \tfrac14,\tfrac14\right)= \frac{B\left(\gamma^2;\ \tfrac14,\tfrac14\right)}{B\left(\tfrac14,\tfrac14\right)}\\ \end{aligned}$$ with regularized beta $I(z;a,b)$ , incomplete beta $B(z;a,b)$ , and beta function $B(a,b)$ . Solutions for $\alpha, \beta, \gamma$ for $N=2,3,5,7,11$ are known, for the latter two as, $$\begin{array}{|c|c|c|} \hline N & P(\beta)=0 &P(\gamma)=0 \\ \hline 2 & -4 + 4 \beta^2 + \beta^4 & -1 + 2 \gamma^2\\ 3 & -2 - 2 \beta + \beta^2 & - 1 + 2 \gamma + 2 \gamma^2\\ 5 & -4 + 8 \beta + 4 \beta^2 - 8 \beta^3 + \beta^4 & - 1 + 8 \gamma - 4 \gamma^2 - 8 \gamma^3 + 4 \gamma^4\\ \hline \end{array}$$ with $N=7$ a $12$ -deg, and $N=11$ a $30$ -deg , both reciprocals. (Polynomials for $\alpha$ are given here .) Q: For $\beta$ and $\gamma$ , why are they roots of reciprocal polynomials when $N=3,5,7,11$ (and presumably others), but different polynomials when $N=2$ ? Ex. For $N=5$ and using $(2a)$ yields the succinct $\beta = 1-\tan\tfrac{3\pi}{20}$ hence, $$\int_0^1\frac{dx}{\sqrt[4]x\ \sqrt[4]{1-x}\ \sqrt{1-x\big(1-\tan\tfrac{3\pi}{20}\big)^2}}=\frac{\sqrt{2}\,\pi}{5\big(1-\tan\tfrac{3\pi}{20}\big)}$$","There is the nice integral by V. Reshetnikov, also discussed in this post . By direct analogy, we can consider its cousin, and the version investigated also by Reshetnikov, Given some integer/rational , it entails finding algebraic numbers such that, with regularized beta , incomplete beta , and beta function . Solutions for for are known, for the latter two as, with a -deg, and a -deg , both reciprocals. (Polynomials for are given here .) Q: For and , why are they roots of reciprocal polynomials when (and presumably others), but different polynomials when ? Ex. For and using yields the succinct hence,","\int_0^1\frac{dx}{\sqrt[3]x\ \sqrt[6]{1-x}\ \sqrt{1-x\,\alpha^2}}=\frac{1}{N}\,\frac{2\pi}{\sqrt{3}\;\alpha}\tag1 \int_0^1\frac{dx}{\sqrt[4]x\ \sqrt[4]{1-x}\ \sqrt{1-x\,\beta^2}}=\frac{1}{N}\,\frac{2\pi}{\sqrt{2}\;\beta}\tag{2a} \int_0^1\frac{dx}{\sqrt[4]x\ \sqrt{1-x}\ \sqrt[4]{1-x\,\gamma^2}}=\frac{1}{N}\,\frac{2\pi}{\sqrt{2\gamma}}\tag{2b} N \alpha, \beta, \gamma \begin{aligned}
\frac{1}{N}=I\left(\alpha^2;\ \tfrac12,\tfrac13\right)= \frac{B\left(\alpha^2;\ \tfrac12,\tfrac13\right)}{B\left(\tfrac12,\tfrac13\right)}
\end{aligned}  \begin{aligned}
\frac{1}{N}=I\left(\beta^2;\ \tfrac12,\tfrac14\right)= \frac{B\left(\beta^2;\ \tfrac12,\tfrac14\right)}{B\left(\tfrac12,\tfrac14\right)}\\
\end{aligned} \begin{aligned}
\frac{1}{N}=I\left(\gamma^2;\ \tfrac14,\tfrac14\right)= \frac{B\left(\gamma^2;\ \tfrac14,\tfrac14\right)}{B\left(\tfrac14,\tfrac14\right)}\\
\end{aligned} I(z;a,b) B(z;a,b) B(a,b) \alpha, \beta, \gamma N=2,3,5,7,11 \begin{array}{|c|c|c|}
\hline
N & P(\beta)=0 &P(\gamma)=0 \\
\hline
2 & -4 + 4 \beta^2 + \beta^4 & -1 + 2 \gamma^2\\
3 & -2 - 2 \beta + \beta^2 & - 1 + 2 \gamma + 2 \gamma^2\\
5 & -4 + 8 \beta + 4 \beta^2 - 8 \beta^3 + \beta^4 & - 1 + 8 \gamma - 4 \gamma^2 - 8 \gamma^3 + 4 \gamma^4\\
\hline
\end{array} N=7 12 N=11 30 \alpha \beta \gamma N=3,5,7,11 N=2 N=5 (2a) \beta = 1-\tan\tfrac{3\pi}{20} \int_0^1\frac{dx}{\sqrt[4]x\ \sqrt[4]{1-x}\ \sqrt{1-x\big(1-\tan\tfrac{3\pi}{20}\big)^2}}=\frac{\sqrt{2}\,\pi}{5\big(1-\tan\tfrac{3\pi}{20}\big)}","['calculus', 'integration', 'polynomials', 'closed-form', 'beta-function']"
26,Evaluate $\sum_{n=0}^{\infty} \frac{n!}{(n^2)!}$,Evaluate,\sum_{n=0}^{\infty} \frac{n!}{(n^2)!},"I'm interested in a method of evaluating $\sum_{n=0}^{\infty} \frac{n!}{(n^2)!}$. If there was a linear equation with leading coefficient $1$ in the denominator or a quadratic  with leading coefficient $1$  and a coefficient of $0$ on $x$ in the numerator I would've used partial fraction, or a method seen in this answer by Jack Evaluate $\frac{0!}{4!}+\frac{1!}{5!}+\frac{2!}{6!}+\frac{3!}{7!}+\frac{4!}{8!}+\cdots$ . But those approaches don't seem to be working for this specific series. Is it even possible to evaluate this to get a closed form?","I'm interested in a method of evaluating $\sum_{n=0}^{\infty} \frac{n!}{(n^2)!}$. If there was a linear equation with leading coefficient $1$ in the denominator or a quadratic  with leading coefficient $1$  and a coefficient of $0$ on $x$ in the numerator I would've used partial fraction, or a method seen in this answer by Jack Evaluate $\frac{0!}{4!}+\frac{1!}{5!}+\frac{2!}{6!}+\frac{3!}{7!}+\frac{4!}{8!}+\cdots$ . But those approaches don't seem to be working for this specific series. Is it even possible to evaluate this to get a closed form?",,"['calculus', 'sequences-and-series']"
27,Evaluate $\int_2^3 {\text{d}x\over x \log(x + 5)}$ [closed],Evaluate  [closed],\int_2^3 {\text{d}x\over x \log(x + 5)},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I have this integral to solve. I have tried both integration by substitution and integration by parts but couldn't solve it. $$\int_2^3 {\text{d}x\over x \log(x + 5)}$$ How do i solve this?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I have this integral to solve. I have tried both integration by substitution and integration by parts but couldn't solve it. $$\int_2^3 {\text{d}x\over x \log(x + 5)}$$ How do i solve this?",,"['calculus', 'integration', 'definite-integrals']"
28,Find the limit of $ \lim_{n\to\infty}\frac{n}{\ln{n}}\left(\frac{1}{p+1}-na_{n}^{p+1}\right) $,Find the limit of, \lim_{n\to\infty}\frac{n}{\ln{n}}\left(\frac{1}{p+1}-na_{n}^{p+1}\right) ,"Problem:Let postive real sequence$\{a_{n}\}$ satisfy $\displaystyle\lim_{n\to\infty}a_{n}\left(\sum_{i=1}^{n}a_{i}^{p}\right)=1$,where $p>-1$,Find the limit. $$ \lim_{n\to\infty}\frac{n}{\ln{n}}\left(\frac{1}{p+1}-na_{n}^{p+1}\right) $$ Here is my approach: First let estimate $a_{n}^{p+1}$,Let us note $S_{n}=\sum_{i=1}^{n}a_{i}^{p}$,it is easy to check  $$\lim_{n\to\infty}{a_{n}}=0,\lim_{n\to\infty}S_{n}=+\infty$$ and by O.Stolz Theorem we have $$\lim_{n\to\infty}na_{n}^{p+1}=\lim_{n\to\infty}a_{n}^{p+1}S_{n}^{p+1}\cdot\lim_{n\to\infty}\frac{n}{S_{n}^{p+1}}=\lim_{n\to\infty}\frac{1}{S_{n+1}^{p+1}-S_{n}^{p+1}} $$ but \begin{align*}  S_{n+1}^{p+1}-S_{n}^{p+1}&=S_{n+1}^{p+1}-(S_{n+1}-a_{n+1}^{p})^{p+1}\\ &=S_{n+1}^{p+1}-\sum_{k=0}^{p+1}C_{p+1}^{k}(-1)^{k}S_{n+1}^{p+1-k}\cdot a_{n+1}^{pk}\\ &=(p+1)S_{n+1}^{p}a_{n+1}^{p}-\frac{(p+1)p}{2!}S_{n+1}^{p-1}a_{n+1}^{2p}+o(S_{n+1}^{p-1}a_{n+1}^{2p})\\ &=(p+1)+o(1) \qquad (n\to+\infty) \end{align*} Therefore $$(p+1)a_{n}^{p+1}\sim \frac{1}{n} $$ to be convince note $A=\frac{1}{p+1}$, \begin{align*} &\lim_{n\to\infty}\frac{n}{\ln{n}}\left(A-na_{n}^{p+1}\right)\\ &=\lim_{n\to\infty}\frac{AS_{n}^{p+1}-na_{n}^{p+1}S_{n}^{p+1}}{\ln{n}}\cdot\lim_{n\to\infty}\frac{na_{n}^{p+1}}{S_{n}^{p+1}a_{n}^{p+1}}\\ &=\frac{1}{p+1}\lim_{n\to\infty}\frac{AS_{n}^{p+1}-na_{n}^{p+1}S_{n}^{p+1}}{\ln{n}}\\ &=\frac{1}{p+1}\lim_{n\to\infty}\frac{A(S_{n+1}^{p+1}-S_{n}^{p+1})-[(n+1)a_{n+1}^{p+1}-na_{n}^{p+1}S_{n}^{p+1}]}{\ln\left(1+\frac{1}{n}\right)}\\ &=\frac{1}{p+1}\lim_{n\to\infty}n\left[A\left(S_{n+1}^{p+1}-(S_{n+1}-a_{n+1}^{p})^{p+1}\right)-((n+1)a_{n+1}^{p+1}S_{n+1}^{p+1}-na_{n}^{p+1}S_{n}^{p+1}) \right]\\ &=\frac{1}{p+1}\lim_{n\to\infty}n\left[\frac{1}{p+1}\left((p+1)S_{n+1}^{p}a_{n+1}^{p}-\frac{(p+1)p}{2}S_{n+1}^{p-1}a_{n+1}^{2p}+o(S_{n+1}^{p-1}a_{n+1}^{2p}) \right)-((n+1)a_{n+1}^{p+1}S_{n+1}^{p+1}-na_{n}^{p+1}S_{n}^{p+1})\right]\\ &=\frac{1}{p+1}\lim_{n\to\infty}n\left[S_{n+1}^{p}a_{n+1}^{p}-(n+1)S_{n+1}^{p+1}a_{n+1}^{p+1}+na_{n}^{p+1}S_{n}^{p+1}-\frac{p}{2}S_{n+1}^{p-1}a_{n+1}^{2p} \right] \end{align*} I want to prove  $$ \mathop {\lim }\limits_{n \to \infty } n\left[ {S_{n + 1}^pa_{n + 1}^p - \left( {n + 1} \right)S_{n + 1}^{p + 1}a_{n + 1}^{p + 1} + na_n^{p + 1}S_n^{p + 1}} \right] = 0$$ But I stuck here.Can someone help me? Thank you very much!","Problem:Let postive real sequence$\{a_{n}\}$ satisfy $\displaystyle\lim_{n\to\infty}a_{n}\left(\sum_{i=1}^{n}a_{i}^{p}\right)=1$,where $p>-1$,Find the limit. $$ \lim_{n\to\infty}\frac{n}{\ln{n}}\left(\frac{1}{p+1}-na_{n}^{p+1}\right) $$ Here is my approach: First let estimate $a_{n}^{p+1}$,Let us note $S_{n}=\sum_{i=1}^{n}a_{i}^{p}$,it is easy to check  $$\lim_{n\to\infty}{a_{n}}=0,\lim_{n\to\infty}S_{n}=+\infty$$ and by O.Stolz Theorem we have $$\lim_{n\to\infty}na_{n}^{p+1}=\lim_{n\to\infty}a_{n}^{p+1}S_{n}^{p+1}\cdot\lim_{n\to\infty}\frac{n}{S_{n}^{p+1}}=\lim_{n\to\infty}\frac{1}{S_{n+1}^{p+1}-S_{n}^{p+1}} $$ but \begin{align*}  S_{n+1}^{p+1}-S_{n}^{p+1}&=S_{n+1}^{p+1}-(S_{n+1}-a_{n+1}^{p})^{p+1}\\ &=S_{n+1}^{p+1}-\sum_{k=0}^{p+1}C_{p+1}^{k}(-1)^{k}S_{n+1}^{p+1-k}\cdot a_{n+1}^{pk}\\ &=(p+1)S_{n+1}^{p}a_{n+1}^{p}-\frac{(p+1)p}{2!}S_{n+1}^{p-1}a_{n+1}^{2p}+o(S_{n+1}^{p-1}a_{n+1}^{2p})\\ &=(p+1)+o(1) \qquad (n\to+\infty) \end{align*} Therefore $$(p+1)a_{n}^{p+1}\sim \frac{1}{n} $$ to be convince note $A=\frac{1}{p+1}$, \begin{align*} &\lim_{n\to\infty}\frac{n}{\ln{n}}\left(A-na_{n}^{p+1}\right)\\ &=\lim_{n\to\infty}\frac{AS_{n}^{p+1}-na_{n}^{p+1}S_{n}^{p+1}}{\ln{n}}\cdot\lim_{n\to\infty}\frac{na_{n}^{p+1}}{S_{n}^{p+1}a_{n}^{p+1}}\\ &=\frac{1}{p+1}\lim_{n\to\infty}\frac{AS_{n}^{p+1}-na_{n}^{p+1}S_{n}^{p+1}}{\ln{n}}\\ &=\frac{1}{p+1}\lim_{n\to\infty}\frac{A(S_{n+1}^{p+1}-S_{n}^{p+1})-[(n+1)a_{n+1}^{p+1}-na_{n}^{p+1}S_{n}^{p+1}]}{\ln\left(1+\frac{1}{n}\right)}\\ &=\frac{1}{p+1}\lim_{n\to\infty}n\left[A\left(S_{n+1}^{p+1}-(S_{n+1}-a_{n+1}^{p})^{p+1}\right)-((n+1)a_{n+1}^{p+1}S_{n+1}^{p+1}-na_{n}^{p+1}S_{n}^{p+1}) \right]\\ &=\frac{1}{p+1}\lim_{n\to\infty}n\left[\frac{1}{p+1}\left((p+1)S_{n+1}^{p}a_{n+1}^{p}-\frac{(p+1)p}{2}S_{n+1}^{p-1}a_{n+1}^{2p}+o(S_{n+1}^{p-1}a_{n+1}^{2p}) \right)-((n+1)a_{n+1}^{p+1}S_{n+1}^{p+1}-na_{n}^{p+1}S_{n}^{p+1})\right]\\ &=\frac{1}{p+1}\lim_{n\to\infty}n\left[S_{n+1}^{p}a_{n+1}^{p}-(n+1)S_{n+1}^{p+1}a_{n+1}^{p+1}+na_{n}^{p+1}S_{n}^{p+1}-\frac{p}{2}S_{n+1}^{p-1}a_{n+1}^{2p} \right] \end{align*} I want to prove  $$ \mathop {\lim }\limits_{n \to \infty } n\left[ {S_{n + 1}^pa_{n + 1}^p - \left( {n + 1} \right)S_{n + 1}^{p + 1}a_{n + 1}^{p + 1} + na_n^{p + 1}S_n^{p + 1}} \right] = 0$$ But I stuck here.Can someone help me? Thank you very much!",,['calculus']
29,Limit of a product of trigonometric functions [closed],Limit of a product of trigonometric functions [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I have to find the following limit: $$J=\lim_{N\to\infty}\prod_{k=1}^N \cos\left(\frac{\pi}{k^2}\right).$$ How can I calculate it? Thanks","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I have to find the following limit: $$J=\lim_{N\to\infty}\prod_{k=1}^N \cos\left(\frac{\pi}{k^2}\right).$$ How can I calculate it? Thanks",,"['calculus', 'limits']"
30,Nasty Integral - Closed form solution?,Nasty Integral - Closed form solution?,,"Any suggestions on how to integrate this beast?: $$\int_0^{\omega_t}\int_{\omega_t}^f\sin^2\left(\frac{\omega_{12}}{2}\right)\sin^2\left(\frac{\omega_{23}}{2}\right)d\omega_{23}d\omega_{12}$$ where: $f{} = 2\pi+2\tan^{-1}(y,x)$ $y = -A^2\sin^2(\omega_{12}/2)\cos(\omega_t/2)-r\cos(\omega_{12}/2)$ $x = A\sin(\omega_{12}/2)[\cos(\omega_t/2)\cos(\omega_{12}/2)-r]$ $r = \sqrt{A^2\sin^2(\omega_{12}/2)[A^2\sin^2(\omega_{12}/2)+\cos^2(\omega_{12}/2)-\cos^2(\omega_t/2)]}$ I can perform the first integration fine, but when you evaluate it at f you get something nasty that I can't seem to integrate. Here is the result after the first integration: $$\int_0^{\omega_t}\sin^2(\omega_{12}/2)\left[\left(\pi+\tan^{-1}(y,x)-\frac{xy}{x^2+y^2}\right)-\left(\frac{\omega_t}{2}-\sin(\omega_t/2)\cos(\omega_t/2)\right)\right]d\omega_{12}$$ Note: $\tan^{-1}(y,x)$ is the two argument inverse tangent function, a.k.a. atan2.","Any suggestions on how to integrate this beast?: where: I can perform the first integration fine, but when you evaluate it at f you get something nasty that I can't seem to integrate. Here is the result after the first integration: Note: is the two argument inverse tangent function, a.k.a. atan2.","\int_0^{\omega_t}\int_{\omega_t}^f\sin^2\left(\frac{\omega_{12}}{2}\right)\sin^2\left(\frac{\omega_{23}}{2}\right)d\omega_{23}d\omega_{12} f{} = 2\pi+2\tan^{-1}(y,x) y = -A^2\sin^2(\omega_{12}/2)\cos(\omega_t/2)-r\cos(\omega_{12}/2) x = A\sin(\omega_{12}/2)[\cos(\omega_t/2)\cos(\omega_{12}/2)-r] r = \sqrt{A^2\sin^2(\omega_{12}/2)[A^2\sin^2(\omega_{12}/2)+\cos^2(\omega_{12}/2)-\cos^2(\omega_t/2)]} \int_0^{\omega_t}\sin^2(\omega_{12}/2)\left[\left(\pi+\tan^{-1}(y,x)-\frac{xy}{x^2+y^2}\right)-\left(\frac{\omega_t}{2}-\sin(\omega_t/2)\cos(\omega_t/2)\right)\right]d\omega_{12} \tan^{-1}(y,x)","['calculus', 'analysis', 'integration', 'trigonometry', 'multivariable-calculus']"
31,How to determine if a vector field is the curl of another vector field?,How to determine if a vector field is the curl of another vector field?,,"I want to see if the Stokes theorem can be applied to a given flux integral of the vector field $F$.  To do so, I need to determine if the vector field $F$ is the curl of some other vector field.  How would I determine this?","I want to see if the Stokes theorem can be applied to a given flux integral of the vector field $F$.  To do so, I need to determine if the vector field $F$ is the curl of some other vector field.  How would I determine this?",,"['calculus', 'multivariable-calculus', 'stokes-theorem']"
32,Is the set of elementary functions which do not have elementary integrals bigger than set of elementary functions which have elementary integrals?,Is the set of elementary functions which do not have elementary integrals bigger than set of elementary functions which have elementary integrals?,,It increasingly seems to me that the functions that have elementary integrals are quite rare in comparison to the ones that don't have them. Even raising an elementary function to a different power may result in it not having an elementary integral . Ex. $\sqrt{\arctan (x)}$ Also many seemingly simple functions do not have elementary integrals. Ex. $\frac {\sin (x)}{x}$ or $ \sin \left( \frac{1}{x} \right) $ So my question is that can we write a formal proof to prove/disprove that the set of elementary functions which do not have elementary integrals is bigger than set of elementary functions which have elementary integrals?,It increasingly seems to me that the functions that have elementary integrals are quite rare in comparison to the ones that don't have them. Even raising an elementary function to a different power may result in it not having an elementary integral . Ex. Also many seemingly simple functions do not have elementary integrals. Ex. or So my question is that can we write a formal proof to prove/disprove that the set of elementary functions which do not have elementary integrals is bigger than set of elementary functions which have elementary integrals?,\sqrt{\arctan (x)} \frac {\sin (x)}{x}  \sin \left( \frac{1}{x} \right) ,"['calculus', 'integration', 'elementary-set-theory', 'conjectures']"
33,limit question: $\lim\limits_{n\to \infty } \frac{n}{2^n}=0$,limit question:,\lim\limits_{n\to \infty } \frac{n}{2^n}=0,"$$ \lim_{n\to\infty}\frac n{2^n}=0. $$ I know how to prove it by using the trick, $2^n=(1+1)^n=1+n+\frac{n(n-1)}{2}+\text{...}$ But how to prove it without using this?","$$ \lim_{n\to\infty}\frac n{2^n}=0. $$ I know how to prove it by using the trick, $2^n=(1+1)^n=1+n+\frac{n(n-1)}{2}+\text{...}$ But how to prove it without using this?",,"['calculus', 'limits', 'alternative-proof']"
34,Why is a derivative defined using limits? [closed],Why is a derivative defined using limits? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question From our childhood, we learn mathematics along with a gradual progression where topics are sequentially related to each other. The discussion of calculus, almost, always starts with the concept of limits . This is where most beginners start to gasp for air. The concept of limit is a disconnected concept which superficially connects algebra and calculus. Why is a derivative defined using the concept of limit?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question From our childhood, we learn mathematics along with a gradual progression where topics are sequentially related to each other. The discussion of calculus, almost, always starts with the concept of limits . This is where most beginners start to gasp for air. The concept of limit is a disconnected concept which superficially connects algebra and calculus. Why is a derivative defined using the concept of limit?",,"['calculus', 'derivatives']"
35,Proof of derivative of $e^x$ is $e^x$ without using chain rule,Proof of derivative of  is  without using chain rule,e^x e^x,"Is there a way to prove that the derivative of $e^x$ is $e^x$ without using chain rule? If so, what is it? Thanks.","Is there a way to prove that the derivative of $e^x$ is $e^x$ without using chain rule? If so, what is it? Thanks.",,"['calculus', 'derivatives', 'exponential-function']"
36,Find the limit of $\lim_{x\to0}{\frac{\ln(1+e^x)-\ln2}{x}}$ without L'Hospital's rule,Find the limit of  without L'Hospital's rule,\lim_{x\to0}{\frac{\ln(1+e^x)-\ln2}{x}},I have to find: $$\lim_{x\to0}{\frac{\ln(1+e^x)-\ln2}{x}}$$ and I want to calculate it without using L'Hospital's rule. With L'Hospital's I know that it gives $1/2$. Any ideas?,I have to find: $$\lim_{x\to0}{\frac{\ln(1+e^x)-\ln2}{x}}$$ and I want to calculate it without using L'Hospital's rule. With L'Hospital's I know that it gives $1/2$. Any ideas?,,"['calculus', 'limits', 'limits-without-lhopital', 'indeterminate-forms']"
37,$\lim\limits_{x\to 0} \frac{\tan x - \sin x}{x^3}$?,?,\lim\limits_{x\to 0} \frac{\tan x - \sin x}{x^3},$$\lim_{x\to 0} \frac{\tan x - \sin x}{x^3}$$ Solution \begin{align}\lim_{x\to 0} \frac{\tan x - \sin x}{x^3}&=\\&=\lim_{x\to 0} \frac{\tan x}{x^3} - \lim_{x\to 0} \frac{\sin x}{x^3}\\ &= \lim_{x\to 0}\frac{\tan x}{x}\lim_{x\to 0} \frac{1}{x^2} -\lim_{x\to 0} \frac{\sin x}{x}\lim_{x\to 0} \frac{1}{x^2}\\&= \lim_{x\to 0} \frac{1}{x^2} -\lim_{x\to 0} \frac{1}{x^2}\\ &= \lim_{x\to 0} \frac{1}{x^2} -\frac{1}{x^2}\\&=0 \end{align} But the answer is $\dfrac{1}{2}$ by L'Hopital's Rule.,Solution But the answer is by L'Hopital's Rule.,"\lim_{x\to 0} \frac{\tan x - \sin x}{x^3} \begin{align}\lim_{x\to 0} \frac{\tan x - \sin x}{x^3}&=\\&=\lim_{x\to 0} \frac{\tan x}{x^3} - \lim_{x\to 0} \frac{\sin x}{x^3}\\
&= \lim_{x\to 0}\frac{\tan x}{x}\lim_{x\to 0} \frac{1}{x^2} -\lim_{x\to 0} \frac{\sin x}{x}\lim_{x\to 0} \frac{1}{x^2}\\&= \lim_{x\to 0} \frac{1}{x^2} -\lim_{x\to 0} \frac{1}{x^2}\\
&= \lim_{x\to 0} \frac{1}{x^2} -\frac{1}{x^2}\\&=0 \end{align} \dfrac{1}{2}","['calculus', 'limits', 'proof-verification', 'limits-without-lhopital']"
38,How unique is $e$?,How unique is ?,e,"Is the property of a function being its own derivative unique to $e^x$, or are there other functions with this property? My working for $e$ is that for any $y=a^x$, $ln(y)=x\ln a$, so $\frac{dy}{dx}=\ln(a)a^x$, which equals $a^x$ if and only if $a=e$. Considering equations of different forms, for example $y=mx+c$ we get $\frac{dy}{dx}=m$ and $mx+c=m$ only when $m=0$ and $c=0$, so there is not solution other than $y=0$. For $y=x^a$, $\frac{dy}{dx}=ax^{a-1}$, which I think equals $x^a$ only when $a=x$ and therefore no solutions for a constant a exist other than the trivial $y=0$. Is this property unique to equations of the form $y=a^x$, or do there exist other cases where it is true? I think this is possibly a question that could be answered through differential equations, although I am unfortunately not familiar with them yet!","Is the property of a function being its own derivative unique to $e^x$, or are there other functions with this property? My working for $e$ is that for any $y=a^x$, $ln(y)=x\ln a$, so $\frac{dy}{dx}=\ln(a)a^x$, which equals $a^x$ if and only if $a=e$. Considering equations of different forms, for example $y=mx+c$ we get $\frac{dy}{dx}=m$ and $mx+c=m$ only when $m=0$ and $c=0$, so there is not solution other than $y=0$. For $y=x^a$, $\frac{dy}{dx}=ax^{a-1}$, which I think equals $x^a$ only when $a=x$ and therefore no solutions for a constant a exist other than the trivial $y=0$. Is this property unique to equations of the form $y=a^x$, or do there exist other cases where it is true? I think this is possibly a question that could be answered through differential equations, although I am unfortunately not familiar with them yet!",,"['calculus', 'ordinary-differential-equations', 'derivatives', 'exponential-function']"
39,"If $\,x>1$, then $\lim\limits_{n\rightarrow\infty}\frac{\left\lfloor x^{n+1} \right\rfloor}{\left\lfloor x^n \right\rfloor}=x$. [closed]","If , then . [closed]","\,x>1 \lim\limits_{n\rightarrow\infty}\frac{\left\lfloor x^{n+1} \right\rfloor}{\left\lfloor x^n \right\rfloor}=x","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How can I prove that $$ \lim_{n\rightarrow\infty}\frac{\left\lfloor x^{n+1} \right\rfloor}{\left\lfloor x^n \right\rfloor}=x, $$ whenever $x>1$. Here $\left\lfloor \cdot\right\rfloor$ denotes the floor function, or the integer part function. The integer part $\lfloor z\rfloor$ of $z$ is the largest integer, which does not exceed $z$. Thanks for your answer.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How can I prove that $$ \lim_{n\rightarrow\infty}\frac{\left\lfloor x^{n+1} \right\rfloor}{\left\lfloor x^n \right\rfloor}=x, $$ whenever $x>1$. Here $\left\lfloor \cdot\right\rfloor$ denotes the floor function, or the integer part function. The integer part $\lfloor z\rfloor$ of $z$ is the largest integer, which does not exceed $z$. Thanks for your answer.",,"['calculus', 'sequences-and-series', 'limits', 'convergence-divergence', 'ceiling-and-floor-functions']"
40,Calculating the shortest possible distance between points,Calculating the shortest possible distance between points,,"Question : Given the points $A(3,3)$, $B(0,1)$ and $C(x,0)$ where $0 < x < 3$, $AC$ is the distance between $A$ and $C$ and $BC$ is the distance between $B$ and $C$. What is x for the distance $AC + BC$ to be minimal? What have I done? I defined the function $AC + BC$ as: $\mathrm{f}\left( x\right) =\sqrt{{1}^{2}+{x}^{2}}+\sqrt{{3}^{2}+{\left( 3-x\right) }^{2}}$ And the first derivative: $\mathrm{f'}\left( x\right) =\frac{x}{\sqrt{{x}^{2}+1}}+\frac{3-x}{\sqrt{{x}^{2}-6\,x+18}}$ We need to find the values for $\mathrm{f'}\left( x\right) = 0$, so by summing and multiplying both sides I got to the equation: $2x^4 - 12x^3  + 19x^2 -6x+18 = 0$ But I don't think the purpose should be to solve a 4th grade equation, there should be another way I'm missing..","Question : Given the points $A(3,3)$, $B(0,1)$ and $C(x,0)$ where $0 < x < 3$, $AC$ is the distance between $A$ and $C$ and $BC$ is the distance between $B$ and $C$. What is x for the distance $AC + BC$ to be minimal? What have I done? I defined the function $AC + BC$ as: $\mathrm{f}\left( x\right) =\sqrt{{1}^{2}+{x}^{2}}+\sqrt{{3}^{2}+{\left( 3-x\right) }^{2}}$ And the first derivative: $\mathrm{f'}\left( x\right) =\frac{x}{\sqrt{{x}^{2}+1}}+\frac{3-x}{\sqrt{{x}^{2}-6\,x+18}}$ We need to find the values for $\mathrm{f'}\left( x\right) = 0$, so by summing and multiplying both sides I got to the equation: $2x^4 - 12x^3  + 19x^2 -6x+18 = 0$ But I don't think the purpose should be to solve a 4th grade equation, there should be another way I'm missing..",,"['calculus', 'trigonometry', 'derivatives']"
41,How do I simplify and evaluate the limit of $(\sqrt x - 1)/(\sqrt[3] x - 1)$ as $x\to 1$?,How do I simplify and evaluate the limit of  as ?,(\sqrt x - 1)/(\sqrt[3] x - 1) x\to 1,"Consider this limit: $$ \lim_{x \to 1} \frac{\sqrt x -  1}{ \sqrt[3] x -  1}  $$  The answer is given to be 2 in the textbook.  Our math professor skipped this question telling us it is not in our syllabus, but how can it be solved?","Consider this limit: $$ \lim_{x \to 1} \frac{\sqrt x -  1}{ \sqrt[3] x -  1}  $$  The answer is given to be 2 in the textbook.  Our math professor skipped this question telling us it is not in our syllabus, but how can it be solved?",,"['calculus', 'limits', 'derivatives', 'radicals']"
42,Prove the following limit $ \lim_{n\to \infty} (3^n + 4^n)^{1/n} = 4 $,Prove the following limit, \lim_{n\to \infty} (3^n + 4^n)^{1/n} = 4 ,"How do i prove the limit below? I've tried, but i got nothing. $ \lim\limits_{n\to \infty} (3^n + 4^n)^{1/n} = 4. $ Thanks for any help.","How do i prove the limit below? I've tried, but i got nothing. $ \lim\limits_{n\to \infty} (3^n + 4^n)^{1/n} = 4. $ Thanks for any help.",,"['calculus', 'limits']"
43,$\int_0^\pi \cos^2 x$ - Where did I go wrong?,- Where did I go wrong?,\int_0^\pi \cos^2 x,"So when looking at the question: $$\int_{0}^{\pi} \cos^2 x \ \text{d}x$$ I would just subtract $\cos^2(0)$ from $\cos^2(\pi)$ , but doing so would get me 1 - 1 = 0. When the answer is $\pi/2$ . Where did I go wrong? What am I missing? Thanks so much for all your help! :-)","So when looking at the question: I would just subtract from , but doing so would get me 1 - 1 = 0. When the answer is . Where did I go wrong? What am I missing? Thanks so much for all your help! :-)",\int_{0}^{\pi} \cos^2 x \ \text{d}x \cos^2(0) \cos^2(\pi) \pi/2,"['calculus', 'integration', 'trigonometry', 'definite-integrals']"
44,Evaluate $ \lim_{x \to 0} \left( {\frac{1}{x^2}} - {\frac{1} {\sin^2 x} }\right) $,Evaluate, \lim_{x \to 0} \left( {\frac{1}{x^2}} - {\frac{1} {\sin^2 x} }\right) ,"$$\lim_{x\to0}\left({\frac{1}{x^2}}-{\frac{1}{\sin^2x}}\right)$$ Using the L'Hospital Rule I obtained the value $-1/4$ , but the answer is given to be $-1/3$ . I can't find the mistake. Here's what I did; please point out the mistake. \begin{align} \lim_{x\to0}\left({\frac{1}{x^2}}-{\frac{1}{\sin^2x}}\right)&=\lim_{x\to0}\frac{(\sin x+x)(\sin x-x)}{(x\sin x)(x\sin x)} \\[1ex] &=\lim_{x\to0}\left(\frac{\sin x+x}{x\sin x}\right)\lim_{x\to0}\left(\frac{\sin x-x}{x\sin x}\right) \\[1ex] &=\lim_{x\to0}\left(\frac{\cos x+1}{\sin x+x\cos x}\right)\lim_{x\to0}\left(\frac{\cos x-1}{\sin x+x\cos x}\right) \\[1ex] &=\lim_{x\to0}\:(\cos x+1)\,\lim_{x\to0}\left(\frac{\cos x-1}{(\sin x+x\cos x)^2}\right) \\[1ex] &=\lim_{x\to0}\frac{-\sin x}{(\sin x+x\cos x)(2\cos x-x\sin x)} \\[1ex] &=-\lim_{x\to0}\left[\frac{1}{1+\cos x\left(\frac{x}{\sin x}\right)}\right]\left(\frac{1}{2\cos x-x\sin x}\right) \\[1ex] &=-\frac{1}{2}\left[\lim_{x\to0}\,\frac{1}{1+\cos x}\right] \\[1ex] &=-\frac{1}{4} \end{align}","Using the L'Hospital Rule I obtained the value , but the answer is given to be . I can't find the mistake. Here's what I did; please point out the mistake.","\lim_{x\to0}\left({\frac{1}{x^2}}-{\frac{1}{\sin^2x}}\right) -1/4 -1/3 \begin{align}
\lim_{x\to0}\left({\frac{1}{x^2}}-{\frac{1}{\sin^2x}}\right)&=\lim_{x\to0}\frac{(\sin x+x)(\sin x-x)}{(x\sin x)(x\sin x)} \\[1ex]
&=\lim_{x\to0}\left(\frac{\sin x+x}{x\sin x}\right)\lim_{x\to0}\left(\frac{\sin x-x}{x\sin x}\right) \\[1ex]
&=\lim_{x\to0}\left(\frac{\cos x+1}{\sin x+x\cos x}\right)\lim_{x\to0}\left(\frac{\cos x-1}{\sin x+x\cos x}\right) \\[1ex]
&=\lim_{x\to0}\:(\cos x+1)\,\lim_{x\to0}\left(\frac{\cos x-1}{(\sin x+x\cos x)^2}\right) \\[1ex]
&=\lim_{x\to0}\frac{-\sin x}{(\sin x+x\cos x)(2\cos x-x\sin x)} \\[1ex]
&=-\lim_{x\to0}\left[\frac{1}{1+\cos x\left(\frac{x}{\sin x}\right)}\right]\left(\frac{1}{2\cos x-x\sin x}\right) \\[1ex]
&=-\frac{1}{2}\left[\lim_{x\to0}\,\frac{1}{1+\cos x}\right] \\[1ex]
&=-\frac{1}{4}
\end{align}","['calculus', 'limits']"
45,Why Doesn't This Series Converge?,Why Doesn't This Series Converge?,,"I am teaching a Calc II course and came across the following series when finding the interval of convergence for the Taylor series of $f(x)=\sqrt{x}$ centered at $x=1$: $$ \sum_{n=2}^\infty \frac{1\cdot 3\cdot 5\cdot 7\cdots (2n-3)}{2^nn!}. $$ I know that it doesn't converge, but how do you show it?  I would like to be able to use only the technology of a Calc II course, but any answer would be enlightening. Edit: I probably should mention that the reason I did not think it converged was Wikipedia said so. After the wonderful answers below, I fixed it. Beware of Wikipedia.  And thanks MathStacks!","I am teaching a Calc II course and came across the following series when finding the interval of convergence for the Taylor series of $f(x)=\sqrt{x}$ centered at $x=1$: $$ \sum_{n=2}^\infty \frac{1\cdot 3\cdot 5\cdot 7\cdots (2n-3)}{2^nn!}. $$ I know that it doesn't converge, but how do you show it?  I would like to be able to use only the technology of a Calc II course, but any answer would be enlightening. Edit: I probably should mention that the reason I did not think it converged was Wikipedia said so. After the wonderful answers below, I fixed it. Beware of Wikipedia.  And thanks MathStacks!",,"['calculus', 'education']"
46,What is $\int\frac{dx}{\sin x}$?,What is ?,\int\frac{dx}{\sin x},I'm looking for the antiderivatives of $1/\sin x$. Is there even a closed form of the antiderivatives? Thanks in advance.,I'm looking for the antiderivatives of $1/\sin x$. Is there even a closed form of the antiderivatives? Thanks in advance.,,"['calculus', 'integration', 'indefinite-integrals']"
47,How to integrate $\int 1/(x^7 -x) dx$?,How to integrate ?,\int 1/(x^7 -x) dx,"How should I proceed about this integral?  $$\int {1/(x^7 -x)} dx$$ I've tried integration by parts or substitution but I can't seem to solve it. Can I have some hints on how should I get started? These are some of the things I've tried: IBP: $u = \frac {1}{x^6-1}$, $du = \frac {-5x^6}{x^6-1}$, $dv = \frac 1x dx$, $v = \ln|x|$ Tried substitution method, but not successful.","How should I proceed about this integral?  $$\int {1/(x^7 -x)} dx$$ I've tried integration by parts or substitution but I can't seem to solve it. Can I have some hints on how should I get started? These are some of the things I've tried: IBP: $u = \frac {1}{x^6-1}$, $du = \frac {-5x^6}{x^6-1}$, $dv = \frac 1x dx$, $v = \ln|x|$ Tried substitution method, but not successful.",,"['calculus', 'integration', 'rational-functions']"
48,Calculating the limit of $[(2n)!/(n!)^2]^{1/n}$ as $n$ tends to $\infty$,Calculating the limit of  as  tends to,[(2n)!/(n!)^2]^{1/n} n \infty,"Analysis textbook by Shanti Narayan, is asking to prove the limit $\lim {\left({\dfrac{(2n)!}{(n!)^2}}\right)}^{1/n} \to \frac{1}{4}$ as $n \to \infty$. I tried but was unable to find the solution. Even Wolfram Alpha is telling the limit to be $4$. Please help!","Analysis textbook by Shanti Narayan, is asking to prove the limit $\lim {\left({\dfrac{(2n)!}{(n!)^2}}\right)}^{1/n} \to \frac{1}{4}$ as $n \to \infty$. I tried but was unable to find the solution. Even Wolfram Alpha is telling the limit to be $4$. Please help!",,"['calculus', 'limits']"
49,Compute trigonometric limit without use of de L'Hospital's rule,Compute trigonometric limit without use of de L'Hospital's rule,,"$$ \lim_{x\to 0} \frac{(x+c)\sin(x^2)}{1-\cos(x)}, c \in \mathbb{R^+} $$ Using de L'Hospital's rule twice it is possible to show that this limit equals $2c$. However, without the use of de L'Hospital's rule I'm lost with the trigonometric identities. I can begin by showing  $$ \lim\frac{x\sin (x^2)(1+\cos(x))}{\sin^2x}+\frac{c\sin x^2(1+\cos x)}{\sin^2x}=\lim\frac{\sin (x^2)(1+\cos(x))}{\sin x}+\frac{c\sin x^2(1+\cos x)}{\sin^2x}, $$ and here I'm getting stuck. I will appreciate any help.","$$ \lim_{x\to 0} \frac{(x+c)\sin(x^2)}{1-\cos(x)}, c \in \mathbb{R^+} $$ Using de L'Hospital's rule twice it is possible to show that this limit equals $2c$. However, without the use of de L'Hospital's rule I'm lost with the trigonometric identities. I can begin by showing  $$ \lim\frac{x\sin (x^2)(1+\cos(x))}{\sin^2x}+\frac{c\sin x^2(1+\cos x)}{\sin^2x}=\lim\frac{\sin (x^2)(1+\cos(x))}{\sin x}+\frac{c\sin x^2(1+\cos x)}{\sin^2x}, $$ and here I'm getting stuck. I will appreciate any help.",,"['calculus', 'limits', 'trigonometry', 'limits-without-lhopital']"
50,Prove that $xy \leq\frac{x^p}{p} + \frac{y^q}{q}$,Prove that,xy \leq\frac{x^p}{p} + \frac{y^q}{q},"OK guys I have this problem: For $x,y,p,q>0$ and $ \frac {1} {p} + \frac {1}{q}=1 $ prove that $ xy \leq\frac{x^p}{p} + \frac{y^q}{q}$ It says I should use Jensen's inequality, but I can't figure out how to apply it in this case. Any ideas about the solution?","OK guys I have this problem: For $x,y,p,q>0$ and $ \frac {1} {p} + \frac {1}{q}=1 $ prove that $ xy \leq\frac{x^p}{p} + \frac{y^q}{q}$ It says I should use Jensen's inequality, but I can't figure out how to apply it in this case. Any ideas about the solution?",,"['calculus', 'inequality', 'a.m.-g.m.-inequality', 'young-inequality', 'jensen-inequality']"
51,Approximating cube roots to high precision.,Approximating cube roots to high precision.,,"I learned that to approximate $\sqrt{n}$ to one digit of precision (where $n$ is a real number), we find the closest square to $n$ ( $s^2$ ), take the square root of that, and add the following $$\frac{n-s^2}{2s}\tag{1}$$ where the two in the denominator of $(1)$ comes from the two in the denominator of the power ( $\sqrt{n}=n^{1/2}$ ). I thought that to approximate cube roots, we replace that two with a three and we choose the closest cube instead. However, I don’t get great approximations when doing that. For example, using this method we get that the cube root of 200 is about 6.1, which isn’t the desired $5.8$ . So how can we approximate cube roots for at least one decimal digit without technical assistance? Edit: By ""technical assistance"" I originally meant computers, calculators, or any machinery that computes expressions quickly. But this now includes things like no big coefficients, radicals, or anything too complicated. The purpose of this question was to be able to compute cube roots mentally.","I learned that to approximate to one digit of precision (where is a real number), we find the closest square to ( ), take the square root of that, and add the following where the two in the denominator of comes from the two in the denominator of the power ( ). I thought that to approximate cube roots, we replace that two with a three and we choose the closest cube instead. However, I don’t get great approximations when doing that. For example, using this method we get that the cube root of 200 is about 6.1, which isn’t the desired . So how can we approximate cube roots for at least one decimal digit without technical assistance? Edit: By ""technical assistance"" I originally meant computers, calculators, or any machinery that computes expressions quickly. But this now includes things like no big coefficients, radicals, or anything too complicated. The purpose of this question was to be able to compute cube roots mentally.",\sqrt{n} n n s^2 \frac{n-s^2}{2s}\tag{1} (1) \sqrt{n}=n^{1/2} 5.8,"['calculus', 'approximation', 'radicals']"
52,Proof: If $f'=0$ then is $f$ is constant,Proof: If  then is  is constant,f'=0 f,"I'm trying to prove that if $f'=0$ then is $f$ is constant WITHOUT using the Mean Value Theorem. My attempt [sketch of proof]: Assume that $f$ is not constant. Identify interval $I_1$ such that $f$ is not constant. Identify $I_2$ within $I_1$ such that $f$ is not constant. Repeat this and by the Nested Intervals Principle, there is a point $c$ within $I_n$ for any $n$ such that $f(c)$ is not constant... This is where I realized that my approach might be wrong. Even if it isn't I don't know how to proceed. Thanks for reading and any help/suggestions/corrections would be appreciated.","I'm trying to prove that if $f'=0$ then is $f$ is constant WITHOUT using the Mean Value Theorem. My attempt [sketch of proof]: Assume that $f$ is not constant. Identify interval $I_1$ such that $f$ is not constant. Identify $I_2$ within $I_1$ such that $f$ is not constant. Repeat this and by the Nested Intervals Principle, there is a point $c$ within $I_n$ for any $n$ such that $f(c)$ is not constant... This is where I realized that my approach might be wrong. Even if it isn't I don't know how to proceed. Thanks for reading and any help/suggestions/corrections would be appreciated.",,['calculus']
53,Minimum value of $2^{\sin^2x}+2^{\cos^2x}$,Minimum value of,2^{\sin^2x}+2^{\cos^2x},The question is what is the minimum value of $$2^{\sin^2x}+2^{\cos^2x}$$ I think if I put $x=\frac\pi4$ then I get a minimum of $2\sqrt2$. But how do I prove this?,The question is what is the minimum value of $$2^{\sin^2x}+2^{\cos^2x}$$ I think if I put $x=\frac\pi4$ then I get a minimum of $2\sqrt2$. But how do I prove this?,,"['calculus', 'algebra-precalculus', 'trigonometry']"
54,How to integrate $\int_{-\infty}^\infty e^{- \frac{1}{2} ax^2 } x^{2n}dx$,How to integrate,\int_{-\infty}^\infty e^{- \frac{1}{2} ax^2 } x^{2n}dx,"How can I approach this integral? ($0<a \in \mathbb{R}$  and $n \in \mathbb{N}$) $$\large\int_{-\infty}^\infty e^{- \frac{1}{2} ax^2 } x^{2n}\, dx$$ Integration by parts doesn't seem to make it any simpler. Hints please? :)","How can I approach this integral? ($0<a \in \mathbb{R}$  and $n \in \mathbb{N}$) $$\large\int_{-\infty}^\infty e^{- \frac{1}{2} ax^2 } x^{2n}\, dx$$ Integration by parts doesn't seem to make it any simpler. Hints please? :)",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'gaussian-integral']"
55,Evaluate the indefinite integral $\int\frac{dx}{(x^2+1)\sqrt{x^2+1}}$ without trigonometric substitution.,Evaluate the indefinite integral  without trigonometric substitution.,\int\frac{dx}{(x^2+1)\sqrt{x^2+1}},"In order to find $$ \int\frac{dx}{(x^2+1)\sqrt{x^2+1}} $$ we set $t=\arctan x$ . Then $x=\tan t$ and $dt=\frac{dx}{x^2+1}$ , so $$ \int\frac{dx}{(x^2+1)\sqrt{x^2+1}}=\int\frac{dt}{\sqrt{\frac{1}{\cos^2t}}}=\int\cos tdt\\ =\sin t+C=\sin(\arctan x)+C $$ Now, since $$ \sin(\arctan x)=\sqrt{\frac{\tan^2(\arctan x)}{\tan^2(\arctan x)+1}} $$ the answer is $\frac{x}{\sqrt{x^2+1}}+C$ . My Question : Is there another way to find this integral without using trigonometry?","In order to find we set . Then and , so Now, since the answer is . My Question : Is there another way to find this integral without using trigonometry?","
\int\frac{dx}{(x^2+1)\sqrt{x^2+1}}
 t=\arctan x x=\tan t dt=\frac{dx}{x^2+1} 
\int\frac{dx}{(x^2+1)\sqrt{x^2+1}}=\int\frac{dt}{\sqrt{\frac{1}{\cos^2t}}}=\int\cos tdt\\
=\sin t+C=\sin(\arctan x)+C
 
\sin(\arctan x)=\sqrt{\frac{\tan^2(\arctan x)}{\tan^2(\arctan x)+1}}
 \frac{x}{\sqrt{x^2+1}}+C","['calculus', 'integration', 'indefinite-integrals']"
56,Derivative of $\arcsin(x)$,Derivative of,\arcsin(x),"I was trying to find the derivative of  $$\arcsin(x) = \sin^{-1}(x)$$ I thought that I could use the rule of inversion: $$({f^{-1}})'(x) = \dfrac{1}{f(x)'}$$ Therefor the derivative of $\arcsin(x)$ should be: $$\dfrac{1}{\cos(x)}$$ But for some reason, this seems to only work for small $x$. Where did I do a mistake? Greetings, Finn","I was trying to find the derivative of  $$\arcsin(x) = \sin^{-1}(x)$$ I thought that I could use the rule of inversion: $$({f^{-1}})'(x) = \dfrac{1}{f(x)'}$$ Therefor the derivative of $\arcsin(x)$ should be: $$\dfrac{1}{\cos(x)}$$ But for some reason, this seems to only work for small $x$. Where did I do a mistake? Greetings, Finn",,"['calculus', 'trigonometry', 'derivatives', 'inverse-function']"
57,Determine whether the series converges or diverges.,Determine whether the series converges or diverges.,,"Determine whether the series converges or diverges. $$  \sum _{n=1}^{\infty }\:\left(\frac{19}{n!}\right) $$ I know that this question a lot easier if I use ratio test but I  have not learned ratio test yet. The only option I have is divergence, comparison, limit comparison, and integral test. How can I prove that this series converges by using the limited tests. Thanks in advance.","Determine whether the series converges or diverges. $$  \sum _{n=1}^{\infty }\:\left(\frac{19}{n!}\right) $$ I know that this question a lot easier if I use ratio test but I  have not learned ratio test yet. The only option I have is divergence, comparison, limit comparison, and integral test. How can I prove that this series converges by using the limited tests. Thanks in advance.",,"['calculus', 'sequences-and-series', 'convergence-divergence', 'factorial', 'fractions']"
58,Compute the value of Fresnel's Integral,Compute the value of Fresnel's Integral,,"So, my teacher wants us to compute the value of the Fresnel integral: $$\int_0^\infty\cos(x^2)dx=\sqrt{\frac{\pi}{8}}$$ The problem is that we cannot use complex analysis to prove that and we should do that using the Euler identity: $$\int_0^\infty\cos(x^2)dx=\frac{1}{2}\int_0^\infty e^{iw^2}dw+\frac{1}{2}\int_0^\infty e^{-iw^2}dw$$ But I have that integral of $e^{-iw^2}$ and I cannot solve that :( I am an engineering student, so basically, I only have the ""basic"" calculus, just simple/double/triple integrals, some notions about series, ODE's and PDE's, but nothing as deep as in the regular Math degree, so probably there's no need to use hard stuff to figure this out.","So, my teacher wants us to compute the value of the Fresnel integral: The problem is that we cannot use complex analysis to prove that and we should do that using the Euler identity: But I have that integral of and I cannot solve that :( I am an engineering student, so basically, I only have the ""basic"" calculus, just simple/double/triple integrals, some notions about series, ODE's and PDE's, but nothing as deep as in the regular Math degree, so probably there's no need to use hard stuff to figure this out.",\int_0^\infty\cos(x^2)dx=\sqrt{\frac{\pi}{8}} \int_0^\infty\cos(x^2)dx=\frac{1}{2}\int_0^\infty e^{iw^2}dw+\frac{1}{2}\int_0^\infty e^{-iw^2}dw e^{-iw^2},"['calculus', 'complex-analysis', 'hyperbolic-functions', 'elementary-functions', 'fresnel-integrals']"
59,Why does this infinite series equal one? $\sum_{k=1}^\infty \binom{2k}{k} \frac{1}{4^k(k+1)}=1$,Why does this infinite series equal one?,\sum_{k=1}^\infty \binom{2k}{k} \frac{1}{4^k(k+1)}=1,Why does $$\sum_{k=1}^\infty \binom{2k}{k} \frac{1}{4^k(k+1)}=1$$ Is there an intuitive method by which to derive this equality?,Why does $$\sum_{k=1}^\infty \binom{2k}{k} \frac{1}{4^k(k+1)}=1$$ Is there an intuitive method by which to derive this equality?,,"['calculus', 'sequences-and-series', 'limits', 'binomial-coefficients', 'taylor-expansion']"
60,Integrate $e^{ax}\sin(bx)?$,Integrate,e^{ax}\sin(bx)?,Is there a general formula for finding the primitive of $$e^{ax}\sin(bx)?$$ I've done this manually with $a=9$ and $b=4$ using Euler's formulas. But it takes a bit of time. Is there a pattern here?,Is there a general formula for finding the primitive of $$e^{ax}\sin(bx)?$$ I've done this manually with $a=9$ and $b=4$ using Euler's formulas. But it takes a bit of time. Is there a pattern here?,,"['calculus', 'integration']"
61,L'Hôpital's rule: number of iterations...,L'Hôpital's rule: number of iterations...,,"I have this exercise : $$ \lim_{x\to\infty} {(\ln x)^9\over x} $$ Now, I know I must use the L'Hôpital's rule to solve this one, until I reach: somthing*$ 1/x^2 $ ,because each time I get infinity/infinity, I am allowed to use L'Hospital's rule. My question is: Is there any shortcut to solve such problems? Sorry for bad English.","I have this exercise : $$ \lim_{x\to\infty} {(\ln x)^9\over x} $$ Now, I know I must use the L'Hôpital's rule to solve this one, until I reach: somthing*$ 1/x^2 $ ,because each time I get infinity/infinity, I am allowed to use L'Hospital's rule. My question is: Is there any shortcut to solve such problems? Sorry for bad English.",,"['calculus', 'infinity']"
62,Indefinite integral of $\sin(x)$ without using the derivative of $\cos(x)$,Indefinite integral of  without using the derivative of,\sin(x) \cos(x),"I can prove that $$\int\sin(x)dx=-\cos(x)+C$$ by using $\cos'(x)=-\sin(x)$ and $\sin'(x)=\cos(x)$. Are there other proofs not involving this (at least, not explicitly) ?","I can prove that $$\int\sin(x)dx=-\cos(x)+C$$ by using $\cos'(x)=-\sin(x)$ and $\sin'(x)=\cos(x)$. Are there other proofs not involving this (at least, not explicitly) ?",,['calculus']
63,Why does the limit of this function not exist: $\lim_{x\to \infty} \frac{1}{1+\cos(x)}$,Why does the limit of this function not exist:,\lim_{x\to \infty} \frac{1}{1+\cos(x)},"In this question the asker mentions that the limit of this does not exist: $$\lim_{x\to \infty} \frac{1}{1+\cos(x)}$$ Graphically I can see that the limit doesn't exist, but I'd like to know what the proof is. I'm also wondering if there is a general rule that can be applied to any limit to tell if the limit exists. Sorry if this question is a bit dumb, and thanks in advance for any answers.","In this question the asker mentions that the limit of this does not exist: $$\lim_{x\to \infty} \frac{1}{1+\cos(x)}$$ Graphically I can see that the limit doesn't exist, but I'd like to know what the proof is. I'm also wondering if there is a general rule that can be applied to any limit to tell if the limit exists. Sorry if this question is a bit dumb, and thanks in advance for any answers.",,"['calculus', 'limits', 'trigonometry']"
64,Injective function that is not surjective,Injective function that is not surjective,,I'm trying to find an example of a continuously differentiable function from $\mathbb{R}$ to $\mathbb{R}$ that is injective but not surjective. I can easily find one from $\mathbb{Z}$ to $\mathbb{Z}$ but I'm having difficulty finding one for the reals.,I'm trying to find an example of a continuously differentiable function from $\mathbb{R}$ to $\mathbb{R}$ that is injective but not surjective. I can easily find one from $\mathbb{Z}$ to $\mathbb{Z}$ but I'm having difficulty finding one for the reals.,,['calculus']
65,Find the sign of $\int_{0}^{2 \pi}\frac{\sin x}{x} dx$,Find the sign of,\int_{0}^{2 \pi}\frac{\sin x}{x} dx,I'd love your help with finding the sign of the following integral: $$\int_{0}^{2 \pi}\frac{\sin x}{x} dx$$ I know that computing it is impossible.  I tried to use integration by parts and maybe to learn about the sign of each part and conclude something but It didn't work for me. Any suggestions?,I'd love your help with finding the sign of the following integral: I know that computing it is impossible.  I tried to use integration by parts and maybe to learn about the sign of each part and conclude something but It didn't work for me. Any suggestions?,\int_{0}^{2 \pi}\frac{\sin x}{x} dx,['calculus']
66,Why isn't there a good product formula for antiderivatives?,Why isn't there a good product formula for antiderivatives?,,"Computing antiderivatives is more challenging than computing derivatives, in part due to the lack of a ``product formula''; namely, while $(fg)'$ can be expressed in terms of $f,f',g,g'$, there seems to be no way to express $\int fg$ in terms of $f, \int f, g \int g$ and related quantities. Is there any intuitive reason or heuristic explanation for why no such formula exists? I'm looking for a non-rigorous explanation which can be understood by first-year calculus students.","Computing antiderivatives is more challenging than computing derivatives, in part due to the lack of a ``product formula''; namely, while $(fg)'$ can be expressed in terms of $f,f',g,g'$, there seems to be no way to express $\int fg$ in terms of $f, \int f, g \int g$ and related quantities. Is there any intuitive reason or heuristic explanation for why no such formula exists? I'm looking for a non-rigorous explanation which can be understood by first-year calculus students.",,['calculus']
67,Is there is a something like function of functions?,Is there is a something like function of functions?,,"I've seen an answer in which the user defined a function called $D$ where this function takes and input $f$ and gives output $f'$ like an example : if $f(x)=x^2$ then $D(f)=f'=2x$ but is there is a something really like function of functions well acorrding to the function $D$ it takes a function as an input an gives another function as an output but the definition of function that i've studied is that a function defined by it's graph where a function $f=$$\{ (a,f(a)) \}$ which is a set of ordered pairs acorrding to this defintion then there isn't something called function of functions because we can't define a specific graph to it like if we defined another function like $I$ where it takes input a function and gives it's integral out like \begin{gather} I(2x) =x^2 \end{gather} we can't define a graph to this function correct me if I said something wrong",I've seen an answer in which the user defined a function called where this function takes and input and gives output like an example : if then but is there is a something really like function of functions well acorrding to the function it takes a function as an input an gives another function as an output but the definition of function that i've studied is that a function defined by it's graph where a function which is a set of ordered pairs acorrding to this defintion then there isn't something called function of functions because we can't define a specific graph to it like if we defined another function like where it takes input a function and gives it's integral out like we can't define a graph to this function correct me if I said something wrong,"D f f' f(x)=x^2 D(f)=f'=2x D f=\{ (a,f(a)) \} I \begin{gather} I(2x) =x^2 \end{gather}","['calculus', 'functions']"
68,Finding the limit of $\frac{\sqrt{x}}{\sqrt{x}+\sin\sqrt{x}}$,Finding the limit of,\frac{\sqrt{x}}{\sqrt{x}+\sin\sqrt{x}},How would one find the limit of $\displaystyle\lim_{x\to 0}\frac{\sqrt{x}}{\sqrt{x}+\sin\sqrt{x}}$ I know I have to use the L'Hospital rule. $\displaystyle\lim_{x\to 0}\frac{\frac{1}{2}x^{-1/2}}{\frac{1}{2}\frac{1}{\sqrt{x}}+\frac{1}{2}\frac{1}{\sqrt{x}}\cos\sqrt{x}}$ But I find myself stuck,How would one find the limit of $\displaystyle\lim_{x\to 0}\frac{\sqrt{x}}{\sqrt{x}+\sin\sqrt{x}}$ I know I have to use the L'Hospital rule. $\displaystyle\lim_{x\to 0}\frac{\frac{1}{2}x^{-1/2}}{\frac{1}{2}\frac{1}{\sqrt{x}}+\frac{1}{2}\frac{1}{\sqrt{x}}\cos\sqrt{x}}$ But I find myself stuck,,"['calculus', 'limits']"
69,Understanding the proof that $L_\infty$ norm is equal to $\max\{f(x_i)\}$,Understanding the proof that  norm is equal to,L_\infty \max\{f(x_i)\},"Attached is a proof I found. It is probably very basic, but I can not understand the marked thing. Why this term is zero? I hope someone can explain it for me. Edit(elaboration): A Norm is a function that takes a function $f$ and returns a number. Discreet norm's input is not the function itself but it's values at certain defined points. Each discreet norm has it's own set of points $\{x_i\}$ (and also weights $\{w_i\}$ ). There are some conditions it should follow to be called a norm (you can google it). Here, $f_i$ is short notation of $f(x_i)$, and the $L_p$ norm is defined as  $$L_p \equiv (\sum{|f_i|^p w_i})^{1/p} $$ $|f_i|$ is simply absolute value. And of course $f$ should be defined at $\{x_i\}$ points. If we send $p$ to infinity then we get the infinity norm $L_\infty$.","Attached is a proof I found. It is probably very basic, but I can not understand the marked thing. Why this term is zero? I hope someone can explain it for me. Edit(elaboration): A Norm is a function that takes a function $f$ and returns a number. Discreet norm's input is not the function itself but it's values at certain defined points. Each discreet norm has it's own set of points $\{x_i\}$ (and also weights $\{w_i\}$ ). There are some conditions it should follow to be called a norm (you can google it). Here, $f_i$ is short notation of $f(x_i)$, and the $L_p$ norm is defined as  $$L_p \equiv (\sum{|f_i|^p w_i})^{1/p} $$ $|f_i|$ is simply absolute value. And of course $f$ should be defined at $\{x_i\}$ points. If we send $p$ to infinity then we get the infinity norm $L_\infty$.",,['calculus']
70,"Can we represent an improper integral as $\int_{-\infty}^{\infty} f(x)\,dx = \lim_{a \to \infty} \int_{-a}^a f(x)\,dx$?",Can we represent an improper integral as ?,"\int_{-\infty}^{\infty} f(x)\,dx = \lim_{a \to \infty} \int_{-a}^a f(x)\,dx","I was reading on improper integrals, and came across : $$\int_{-\infty}^{\infty} f(x)\,dx = \lim_{A \to -\infty} \int_A^Cf(x)\,dx + \lim_{B \to \infty} \int_C^B f(x)\,dx$$ My question is a rather silly one: Is it any different if I write the above as : $$\int_{-\infty}^{\infty} f(x)\,dx = \lim_{a \to \infty} \int_{-a}^a f(x)\,dx$$ If it's correct, is there any specific reason why it is written that way? Or is looking at it in that way any more beneficial than my way? If it's not, why is it incorrect to write it this way? (Any counter-example also appreciated)","I was reading on improper integrals, and came across : My question is a rather silly one: Is it any different if I write the above as : If it's correct, is there any specific reason why it is written that way? Or is looking at it in that way any more beneficial than my way? If it's not, why is it incorrect to write it this way? (Any counter-example also appreciated)","\int_{-\infty}^{\infty} f(x)\,dx = \lim_{A \to -\infty}
\int_A^Cf(x)\,dx + \lim_{B \to \infty} \int_C^B f(x)\,dx \int_{-\infty}^{\infty} f(x)\,dx = \lim_{a \to \infty} \int_{-a}^a f(x)\,dx","['calculus', 'integration', 'soft-question', 'improper-integrals']"
71,Interesting integral: $\int_0^1{\frac{nx^{n-1}}{x+1}}dx$,Interesting integral:,\int_0^1{\frac{nx^{n-1}}{x+1}}dx,Find the value of $$\int_0^1{\frac{nx^{n-1}}{x+1}}dx.$$ I had no luck while integrating it. I also tried differentiating w.r.t n but still couldn't reach anywhere. Need help.,Find the value of $$\int_0^1{\frac{nx^{n-1}}{x+1}}dx.$$ I had no luck while integrating it. I also tried differentiating w.r.t n but still couldn't reach anywhere. Need help.,,"['calculus', 'integration', 'definite-integrals']"
72,"How to ""fix"" $\int_{-1}^1 \frac {dx}{x^2}$ with complex numbers?","How to ""fix""  with complex numbers?",\int_{-1}^1 \frac {dx}{x^2},"Given the following definite integral, $$\int_{-1}^1 \frac {dx}{x^2}$$ I can see that it is an improper integral because of the asymptote at $x=0$ and I know from the graph of $\frac 1{x^2}$ that both parts on either side of the $y$-axis are identical. Hence, computing only the part on the right of the $y$-axis I find that the integral $\int_{-1}^1 \frac {dx}{x^2}$ is divergent since $-$as expected from the graph of $\frac 1{x^2}-$ this part goes to $\infty$: $$\lim_{\epsilon\to 0^+}\int_{0+\epsilon}^1 \frac {dx}{x^2} \;=\; \lim_{\epsilon\to 0^+}-\frac 1x \;\bigg|_{\,0+\epsilon}^1 \;=\; -1-\left(\lim_{\epsilon\to 0^+}-\frac 1{0+\epsilon}\right) \;=\; \infty\;.$$ If I intentionally overlook that and blindly compute the integral, I get the silly result $$\int_{-1}^1 \frac {dx}{x^2} = -2\;.$$ That is, a negative value for the area under a function that is above the $x$-axis everywhere. I was told that $\int_{-1}^1 \frac {dx}{x^2}$ can be ""fixed"" using imaginary numbers by a T.A. but neither of us had the time to expand on that point. I understand complex numbers and how they work so I am left to wonder; how can I ""fix"" an improper integral using complex numbers?","Given the following definite integral, $$\int_{-1}^1 \frac {dx}{x^2}$$ I can see that it is an improper integral because of the asymptote at $x=0$ and I know from the graph of $\frac 1{x^2}$ that both parts on either side of the $y$-axis are identical. Hence, computing only the part on the right of the $y$-axis I find that the integral $\int_{-1}^1 \frac {dx}{x^2}$ is divergent since $-$as expected from the graph of $\frac 1{x^2}-$ this part goes to $\infty$: $$\lim_{\epsilon\to 0^+}\int_{0+\epsilon}^1 \frac {dx}{x^2} \;=\; \lim_{\epsilon\to 0^+}-\frac 1x \;\bigg|_{\,0+\epsilon}^1 \;=\; -1-\left(\lim_{\epsilon\to 0^+}-\frac 1{0+\epsilon}\right) \;=\; \infty\;.$$ If I intentionally overlook that and blindly compute the integral, I get the silly result $$\int_{-1}^1 \frac {dx}{x^2} = -2\;.$$ That is, a negative value for the area under a function that is above the $x$-axis everywhere. I was told that $\int_{-1}^1 \frac {dx}{x^2}$ can be ""fixed"" using imaginary numbers by a T.A. but neither of us had the time to expand on that point. I understand complex numbers and how they work so I am left to wonder; how can I ""fix"" an improper integral using complex numbers?",,"['calculus', 'integration']"
73,Prove that $\sum\limits_{n=1}^\infty \frac{n^2(n-1)}{2^n} = 20$,Prove that,\sum\limits_{n=1}^\infty \frac{n^2(n-1)}{2^n} = 20,"This sum  $\displaystyle \sum_{n=1}^\infty \frac{n^2(n-1)}{2^n} $showed up as I was computing the expected value of a random variable. My calculator tells me that  $\,\,\displaystyle \sum_{n=1}^\infty \frac{n^2(n-1)}{2^n} = 20$. How can I show that? I know how to find the value of the sum $\,\displaystyle \sum_{n=1}^\infty \frac{n^2}{2^n},\,$ but I can't deal with $\displaystyle \sum_{n=1}^\infty \frac{n^3}{2^n}$","This sum  $\displaystyle \sum_{n=1}^\infty \frac{n^2(n-1)}{2^n} $showed up as I was computing the expected value of a random variable. My calculator tells me that  $\,\,\displaystyle \sum_{n=1}^\infty \frac{n^2(n-1)}{2^n} = 20$. How can I show that? I know how to find the value of the sum $\,\displaystyle \sum_{n=1}^\infty \frac{n^2}{2^n},\,$ but I can't deal with $\displaystyle \sum_{n=1}^\infty \frac{n^3}{2^n}$",,"['calculus', 'sequences-and-series', 'summation', 'power-series']"
74,Where does this trigonometric substitution go wrong?,Where does this trigonometric substitution go wrong?,,"$$I =\int\frac{1}{\sqrt{25-x^2}}dx$$ ( $\theta$ on left corner) $$\tag 1 5\cos(\theta)=x$$ $$\tag 2 5\sin(\theta)=\sqrt{25-x^2}$$ $$\tag 1 -5\sin(\theta)\,d\theta=dx$$ $$I=\int\frac{1}{5\sin(\theta)} \cdot (-5) \sin(\theta) \, d\theta$$ $$I=\int-d\theta$$ $$\tag 1 \theta=\arccos(x/5)$$ $$I = -\arccos\left(\frac{x}{5}\right)+c$$ However, putting this integral into WA gives $\arcsin\left(\frac{x}{5}\right)+c$ and two are clearly not equivalent.","( on left corner) However, putting this integral into WA gives and two are clearly not equivalent.","I =\int\frac{1}{\sqrt{25-x^2}}dx \theta \tag 1 5\cos(\theta)=x \tag 2 5\sin(\theta)=\sqrt{25-x^2} \tag 1 -5\sin(\theta)\,d\theta=dx I=\int\frac{1}{5\sin(\theta)} \cdot (-5) \sin(\theta) \, d\theta I=\int-d\theta \tag 1 \theta=\arccos(x/5) I = -\arccos\left(\frac{x}{5}\right)+c \arcsin\left(\frac{x}{5}\right)+c","['calculus', 'integration']"
75,Show that $\int_{0}^{\pi/6} {\cos (x^2)}\mathrm{d}x\ge\frac12$.,Show that .,\int_{0}^{\pi/6} {\cos (x^2)}\mathrm{d}x\ge\frac12,"Prove that $\displaystyle\int_{0}^{\frac\pi 6} {\cos ({x^2)}\mathrm{d}x\ge\dfrac12}$ . I know this is a Fresnel integral but without going into advanced calculus is there a way to show that this is true? using calculus 1 knowledge, I tried Riemann's sum to prove this and got stuck. Thanks for any help.","Prove that . I know this is a Fresnel integral but without going into advanced calculus is there a way to show that this is true? using calculus 1 knowledge, I tried Riemann's sum to prove this and got stuck. Thanks for any help.",\displaystyle\int_{0}^{\frac\pi 6} {\cos ({x^2)}\mathrm{d}x\ge\dfrac12},"['calculus', 'integration', 'inequality', 'definite-integrals', 'integral-inequality']"
76,Proving that $\lim_{n\to\infty} \left(1+\frac{1}{f(n)}\right)^{g(n)} = 1$,Proving that,\lim_{n\to\infty} \left(1+\frac{1}{f(n)}\right)^{g(n)} = 1,"I want to prove that $$\lim_{n\to\infty} \left(1+\frac{1}{f(n)}\right)^{g(n)} = 1$$ if $f(n)$ grows faster than $g(n)$ for $n\to\infty$ and $\lim_{n\to\infty} f(n) = +\infty = \lim_{n\to\infty}g(n)$ . It is quite easy to see that if $f = g$ the limit is $e$ , but I can't find a good strategy to solve this problem.","I want to prove that if grows faster than for and . It is quite easy to see that if the limit is , but I can't find a good strategy to solve this problem.",\lim_{n\to\infty} \left(1+\frac{1}{f(n)}\right)^{g(n)} = 1 f(n) g(n) n\to\infty \lim_{n\to\infty} f(n) = +\infty = \lim_{n\to\infty}g(n) f = g e,"['calculus', 'sequences-and-series', 'limits', 'exponentiation']"
77,Integration - fraction part of square root of x,Integration - fraction part of square root of x,,"Question $\int_{0}^{100}\left\{ \sqrt{x}\right\} \,dx$ Where $\{.\}$ denotes the fractional part of x. My Approach We know that $\left[x\right]$+$\left\{ x\right\} $=x $\Longrightarrow$$\left\{ x\right\} =x-\left[x\right]$ $\int_{0}^{100}\left\{ \sqrt{x}\right\} \,dx$ =$\int_{0}^{100}$$\sqrt{x}\,dx$ -$\int_{0}^{100}$$\left[\sqrt{x}\right]\,dx$=$\left[\frac{\sqrt{x^{3}}}{\frac{3}{2}}\right]_{0}^{100}-$$\int_{0}^{100}\left[\sqrt{x}\right]\,dx$. I cannot solve $\int_{0}^{100}\left[\sqrt{x}\right]\,dx$. But I have an idea if somehow I can prove that $\left[\sqrt{x}\right]$ is a periodic function with period $p$ such that $p|100$ then $p\int_{0}^{\frac{100}{p}}\left[\sqrt{x}\right]\,dx$. That would be easy to solve.","Question $\int_{0}^{100}\left\{ \sqrt{x}\right\} \,dx$ Where $\{.\}$ denotes the fractional part of x. My Approach We know that $\left[x\right]$+$\left\{ x\right\} $=x $\Longrightarrow$$\left\{ x\right\} =x-\left[x\right]$ $\int_{0}^{100}\left\{ \sqrt{x}\right\} \,dx$ =$\int_{0}^{100}$$\sqrt{x}\,dx$ -$\int_{0}^{100}$$\left[\sqrt{x}\right]\,dx$=$\left[\frac{\sqrt{x^{3}}}{\frac{3}{2}}\right]_{0}^{100}-$$\int_{0}^{100}\left[\sqrt{x}\right]\,dx$. I cannot solve $\int_{0}^{100}\left[\sqrt{x}\right]\,dx$. But I have an idea if somehow I can prove that $\left[\sqrt{x}\right]$ is a periodic function with period $p$ such that $p|100$ then $p\int_{0}^{\frac{100}{p}}\left[\sqrt{x}\right]\,dx$. That would be easy to solve.",,"['calculus', 'definite-integrals']"
78,Integrating $\displaystyle\int \frac{1+x^2}{1+x^4}dx$,Integrating,\displaystyle\int \frac{1+x^2}{1+x^4}dx,"I am trying to integrate this function, which I got while solving $\int\frac{1}{\sin^4( x) + \cos^4 (x)}$ : $$\int \frac{1+x^2}{1+x^4}\mathrm dx$$ I think to factorise the denominator, and use partial fractions. But I cant seem to find roots of denominator. I also am unable to think substitution.","I am trying to integrate this function, which I got while solving : I think to factorise the denominator, and use partial fractions. But I cant seem to find roots of denominator. I also am unable to think substitution.",\int\frac{1}{\sin^4( x) + \cos^4 (x)} \int \frac{1+x^2}{1+x^4}\mathrm dx,"['calculus', 'integration']"
79,Solve this integral:$\int_0^\infty\frac{\arctan x}{x(x^2+1)}\mathrm dx$,Solve this integral:,\int_0^\infty\frac{\arctan x}{x(x^2+1)}\mathrm dx,"I occasionally found that $\displaystyle\int_0^{\Large\frac{\pi}{2}}\dfrac{x}{\tan x}=\dfrac{\pi}{2}\ln 2$. I tried that $$\int_0^{\Large\frac{\pi}{2}}\dfrac{x}{\tan x}=\int_0^{\Large\frac{\pi}{2}}x   \ \mathrm d(\ln \sin x)=-\int_0^{\Large\frac{\pi}{2}}\ln (\sin x)=\dfrac{\pi}{2}\ln 2$$ Then I tried another method  $$\int_0^{\Large\frac{\pi}{2}}\dfrac{x}{\tan x}=\int_0^\infty\dfrac{\arctan x}{x(x^2+1)}\mathrm dx$$ I tried to expand $\arctan x$ and $\dfrac{1}{1+x^2}$, but got nothing, also I was confused that whether $\displaystyle\int_0^\infty$ and $\displaystyle\sum_{i=0}^\infty$ can exchange or not? If yes, on what condition? Sincerely thanks your help!","I occasionally found that $\displaystyle\int_0^{\Large\frac{\pi}{2}}\dfrac{x}{\tan x}=\dfrac{\pi}{2}\ln 2$. I tried that $$\int_0^{\Large\frac{\pi}{2}}\dfrac{x}{\tan x}=\int_0^{\Large\frac{\pi}{2}}x   \ \mathrm d(\ln \sin x)=-\int_0^{\Large\frac{\pi}{2}}\ln (\sin x)=\dfrac{\pi}{2}\ln 2$$ Then I tried another method  $$\int_0^{\Large\frac{\pi}{2}}\dfrac{x}{\tan x}=\int_0^\infty\dfrac{\arctan x}{x(x^2+1)}\mathrm dx$$ I tried to expand $\arctan x$ and $\dfrac{1}{1+x^2}$, but got nothing, also I was confused that whether $\displaystyle\int_0^\infty$ and $\displaystyle\sum_{i=0}^\infty$ can exchange or not? If yes, on what condition? Sincerely thanks your help!",,"['calculus', 'integration', 'sequences-and-series', 'definite-integrals', 'closed-form']"
80,Compute $ \int_{-\infty}^{\infty} \frac{x^2}{(1+x^2)^2} dx$,Compute, \int_{-\infty}^{\infty} \frac{x^2}{(1+x^2)^2} dx,Compute $$ \int_{-\infty}^{\infty} \frac{x^2}{(1+x^2)^2} dx$$ Of course we have $$ \int_{-\infty}^{\infty} \frac{x^2}{(1+x^2)^2} dx = 2 \int_{0}^{\infty} \frac{x^2}{(1+x^2)^2} dx = 2 \int_{0}^{\infty} \left( \frac{x}{1+x^2}  \right) ^2 dx =  \lim_{ A \to \infty }  \int_{0}^{A} \left( \frac{x}{1+x^2}  \right) ^2 dx $$ I think that firstly I should compute $ \int \left( \frac{x}{1+x^2}  \right) ^2 dx $ but I don't have idea.,Compute $$ \int_{-\infty}^{\infty} \frac{x^2}{(1+x^2)^2} dx$$ Of course we have $$ \int_{-\infty}^{\infty} \frac{x^2}{(1+x^2)^2} dx = 2 \int_{0}^{\infty} \frac{x^2}{(1+x^2)^2} dx = 2 \int_{0}^{\infty} \left( \frac{x}{1+x^2}  \right) ^2 dx =  \lim_{ A \to \infty }  \int_{0}^{A} \left( \frac{x}{1+x^2}  \right) ^2 dx $$ I think that firstly I should compute $ \int \left( \frac{x}{1+x^2}  \right) ^2 dx $ but I don't have idea.,,['calculus']
81,"The negation of a limit condition, Spivak style.","The negation of a limit condition, Spivak style.",,"I got stuck on this bit from Spivak's Calculus : When proving that $f$ does not approach $l$ at $a$ , be sure to negate the definition correctly: If it is not true that for every $\varepsilon>0$ there is some $\delta>0$ such that, for all $x$ , if $0<|x-a|<\delta$ , then $|f(x)-l|<\varepsilon,$ then there is some $\varepsilon>0$ such that for every $\delta>0$ there is some $x$ which satisfies $0<|x-a|<\delta$ but not $|f(x)-l|<\varepsilon.$ I don't understand why the negation of the top sentence is given by the bottom sentence. Thank you so much! EDIT My problem is not why ""continuous functions are those that let you interchange limits"". It's more just a question about how you can negate sentences in general.","I got stuck on this bit from Spivak's Calculus : When proving that does not approach at , be sure to negate the definition correctly: If it is not true that for every there is some such that, for all , if , then then there is some such that for every there is some which satisfies but not I don't understand why the negation of the top sentence is given by the bottom sentence. Thank you so much! EDIT My problem is not why ""continuous functions are those that let you interchange limits"". It's more just a question about how you can negate sentences in general.","f l a \varepsilon>0 \delta>0 x 0<|x-a|<\delta |f(x)-l|<\varepsilon, \varepsilon>0 \delta>0 x 0<|x-a|<\delta |f(x)-l|<\varepsilon.",['calculus']
82,Can an indefinite integral be expressed as a definite integral with variable bounds?,Can an indefinite integral be expressed as a definite integral with variable bounds?,,"If I have a function $f(t)$ , and an indefinite integral of this function, $g(x) = \int f(t)\, dt$ , is there any way I can express $g(x)$ as a definite integral whose bounds depend on $x$ ? I thought I saw somewhere that I could express it as $$g(x) = \int_a^x f(t)\, dt$$ but I don't know what $a$ is. Is this representation correct? Or is there a better way to express $g$ ?","If I have a function , and an indefinite integral of this function, , is there any way I can express as a definite integral whose bounds depend on ? I thought I saw somewhere that I could express it as but I don't know what is. Is this representation correct? Or is there a better way to express ?","f(t) g(x) = \int f(t)\, dt g(x) x g(x) = \int_a^x f(t)\, dt a g","['calculus', 'definite-integrals', 'indefinite-integrals']"
83,"Which number is greater, $2^\sqrt2$ or $e$?","Which number is greater,  or ?",2^\sqrt2 e,"Claim: $\color{red}{2^\sqrt2<e}$ Note: $2^\sqrt2=e^{\sqrt2\ln2}$ Different approach : We show $e^{x-1}>x^\sqrt x$ for $x>2$. Let $f(x) = x -1 - \sqrt{x} \ln x $. We have $f'(x) = 1 - \frac{ \ln x }{2 \sqrt{x} } - \frac{1}{\sqrt{x}}$. By inspection, note that $f'(1)=0$ and since for $x>1$, pick $x=4$, for instance, we have $f'(4)=1- \frac{ \ln 4 }{4} - \frac{1}{2} = \frac{1}{2} - \frac{ \ln 2 }2 > 2$, then we know $f(x)$ is increasing for $x> 1$, Thus $$ f(x) > f(1) \implies x - 1 - \sqrt{x} \ln x > 0 \implies x - 1 \geq \sqrt{x} \ln  x \implies e^{x-1} > x^{\sqrt{x}}  $$ Putting $x=2$, we obtain $$e>2^\sqrt2$$ What do you think about this approach? Is there an easier way?","Claim: $\color{red}{2^\sqrt2<e}$ Note: $2^\sqrt2=e^{\sqrt2\ln2}$ Different approach : We show $e^{x-1}>x^\sqrt x$ for $x>2$. Let $f(x) = x -1 - \sqrt{x} \ln x $. We have $f'(x) = 1 - \frac{ \ln x }{2 \sqrt{x} } - \frac{1}{\sqrt{x}}$. By inspection, note that $f'(1)=0$ and since for $x>1$, pick $x=4$, for instance, we have $f'(4)=1- \frac{ \ln 4 }{4} - \frac{1}{2} = \frac{1}{2} - \frac{ \ln 2 }2 > 2$, then we know $f(x)$ is increasing for $x> 1$, Thus $$ f(x) > f(1) \implies x - 1 - \sqrt{x} \ln x > 0 \implies x - 1 \geq \sqrt{x} \ln  x \implies e^{x-1} > x^{\sqrt{x}}  $$ Putting $x=2$, we obtain $$e>2^\sqrt2$$ What do you think about this approach? Is there an easier way?",,"['calculus', 'inequality']"
84,Find the limit: $\lim\limits_{x\to1}\dfrac{x^{1/5}-1}{x^{1/3}-1}$,Find the limit:,\lim\limits_{x\to1}\dfrac{x^{1/5}-1}{x^{1/3}-1},Find the limit of $$\lim_{x\to 1}\frac{x^{1/5}-1}{x^{1/3}-1}$$ How should I approach it?  I tried to use L'Hopital's Rule but it's just keep giving me 0/0.,Find the limit of $$\lim_{x\to 1}\frac{x^{1/5}-1}{x^{1/3}-1}$$ How should I approach it?  I tried to use L'Hopital's Rule but it's just keep giving me 0/0.,,['calculus']
85,"How prove this $\int_{0}^{\infty}\sin{x}\sin{\sqrt{x}}\,dx=\frac{\sqrt{\pi}}{2}\sin{\left(\frac{3\pi-1}{4}\right)}$",How prove this,"\int_{0}^{\infty}\sin{x}\sin{\sqrt{x}}\,dx=\frac{\sqrt{\pi}}{2}\sin{\left(\frac{3\pi-1}{4}\right)}","Prove that $$\int_{0}^{\infty}\sin{x}\sin{\sqrt{x}}\,dx=\frac{\sqrt{\pi}}{2}\sin{\left(\frac{3\pi-1}{4}\right)}$$ I have some question. Using this , find this integral is not converge, I'm wrong? Thank you everyone","Prove that I have some question. Using this , find this integral is not converge, I'm wrong? Thank you everyone","\int_{0}^{\infty}\sin{x}\sin{\sqrt{x}}\,dx=\frac{\sqrt{\pi}}{2}\sin{\left(\frac{3\pi-1}{4}\right)}","['calculus', 'integration']"
86,Solving the improper integral $\int_0^{\infty}\frac{dx}{1+x^3}$,Solving the improper integral,\int_0^{\infty}\frac{dx}{1+x^3},"$$\int_0^{\infty} \frac{dx}{1+x^3}$$ So far I have found the indefinite integral, which is: $$-\frac{1}{6} \ln |x^2-x+1|+\frac{1}{\sqrt{3}} \arctan\left(\frac{2x-1}{\sqrt{3}}\right)+\frac{1}{3}\ln|x+1|$$ Now what do I need to do in order to calculate the improper integral?","$$\int_0^{\infty} \frac{dx}{1+x^3}$$ So far I have found the indefinite integral, which is: $$-\frac{1}{6} \ln |x^2-x+1|+\frac{1}{\sqrt{3}} \arctan\left(\frac{2x-1}{\sqrt{3}}\right)+\frac{1}{3}\ln|x+1|$$ Now what do I need to do in order to calculate the improper integral?",,"['calculus', 'improper-integrals']"
87,Evaluate the sum $\sum_{k=0}^{\infty}\frac{1}{(4k+1)(4k+2)(4k+3)(4k+4)}$?,Evaluate the sum ?,\sum_{k=0}^{\infty}\frac{1}{(4k+1)(4k+2)(4k+3)(4k+4)},Evaluate the series    $$\sum_{k=0}^{\infty}\frac{1}{(4k+1)(4k+2)(4k+3)(4k+4)}=?$$ Can you help me ? This is a past contest problem.,Evaluate the series    $$\sum_{k=0}^{\infty}\frac{1}{(4k+1)(4k+2)(4k+3)(4k+4)}=?$$ Can you help me ? This is a past contest problem.,,"['calculus', 'sequences-and-series', 'contest-math']"
88,"Evaluate $\int_{0}^{1} \frac{\operatorname{arsinh}x}{x\sqrt{1-x^4}} \,\mathrm{d}x$",Evaluate,"\int_{0}^{1} \frac{\operatorname{arsinh}x}{x\sqrt{1-x^4}} \,\mathrm{d}x","The problem is to show $$\int_{0}^{1} \frac{\operatorname{arsinh}x}{x\sqrt{1-x^4}} \,\mathrm{d}x = \frac{\pi^2}{8}$$ which is a typical integral emerges in many specific value, yet I have no more insight how to prove this one directly (any possible method other than the example below is acceptable). Here is an example when the integral pops out in Legendre-chi function $\chi_2$ , like (1) in this post , we have $$ \int_{0}^{\pi/2} {\arctan(\sin x) \,\mathrm{d}x} = 2\chi_2(\sqrt2-1) = \frac{\pi^2}{8} - \frac{\ln^{2}(\sqrt{2}+1)}{2} $$ which is a very typical integral, like in this post , from where we already know that $$ \int_{0}^{\pi/2} {\arctan(\sin x) \,\mathrm{d}x} = \int_{0}^{1} {\frac{\arctan x}{\sqrt{1-x^2}} \,\mathrm{d}x} = \int_{0}^{1} {\frac{\operatorname{arsinh}x}{x\sqrt{1+x^{2}}} \,\mathrm{d}x} $$ or $$ \int_{0}^{\pi/4} {\arcsin(\tan x) \,\mathrm{d}x} = \frac{\pi^2}{8} - \int_{0}^{\pi/2} {\arctan(\sin x) \,\mathrm{d}x} = \frac{\ln^{2}(\sqrt{2}+1)}{2} $$ Now, for $a<1$ consider the following parameterization $$ I(a) = \int_{0}^{\pi/4} {\arcsin(a\tan x) \,\mathrm{d}x} $$ let $u=\tan x$ and $y^2=(1-a^2u^2)/(1+u^2)$ in its derivative $$ \begin{aligned} I'(a) &= \int_{0}^{\pi/4} {\frac{\tan x}{\sqrt{1-a^2\tan^2x}} \,\mathrm{d}x} = \int_{0}^{1} {\frac{u}{(1+u^2)\sqrt{1-a^2u^2}} \,\mathrm{d}u} \\ &= \frac1{\sqrt{1+a^2}}\int_{\sqrt{(1-a^2)/2}}^{1} {\frac{\mathrm{d}y}{\sqrt{a^2+y^2}}} = \frac1{\sqrt{1+a^2}}\operatorname{arsinh}\left(\frac{y}{a}\right)\biggr|_{y=\sqrt{(1-a^2)/2}}^{1} \\ &= \frac{1}{\sqrt{1+a^{2}}} \operatorname{arsinh}\frac1{a} - \frac{1}{\sqrt{1+a^{2}}} \operatorname{arsinh}\sqrt{\frac{1-a^2}{2a^2}} \end{aligned} $$ Integrtation by parts gives $$ \begin{aligned} \int_{0}^{\pi/4} {\arcsin(\tan x) \,\mathrm{d}x}  &= \int_{0}^{1} \frac{1}{\sqrt{1+a^{2}}} \operatorname{arsinh}\frac1{a} \,\mathrm{d}x - \int_{0}^{1} \frac{1}{\sqrt{1+a^{2}}} \operatorname{arsinh}\sqrt{\frac{1-a^2}{2a^2}} \,\mathrm{d}x \\ &= \operatorname{arsinh}^2(1) + \int_{0}^{1} {\frac{\operatorname{arsinh}a}{a\sqrt{1+a^{2}}}\,\mathrm{d}a} - \int_{0}^{1} \frac{\operatorname{arsinh}a}{a\sqrt{1-a^4}} \,\mathrm{d}a \end{aligned} $$ Combining all the special case of $\chi_2(\sqrt2-1)$ from above, we will find the required integral. And there are other equivalent form of required integral, for example $$ \int_{0}^{1} \frac{\operatorname{arsinh}x}{x\sqrt{1-x^4}} \,\mathrm{d}x = \frac1{2} \int_{0}^{1} \frac{1}{\sqrt{1+x^2}} \operatorname{arcosh}\frac1{x^2} \,\mathrm{d}x = \frac1{4} \int_{0}^{1} \frac{1}{\sqrt{x(1+x)}} \operatorname{arcosh}\frac1{x} \,\mathrm{d}x $$ Yet, I still can not find any convenience for further calculation. Thanks in advance for any help.","The problem is to show which is a typical integral emerges in many specific value, yet I have no more insight how to prove this one directly (any possible method other than the example below is acceptable). Here is an example when the integral pops out in Legendre-chi function , like (1) in this post , we have which is a very typical integral, like in this post , from where we already know that or Now, for consider the following parameterization let and in its derivative Integrtation by parts gives Combining all the special case of from above, we will find the required integral. And there are other equivalent form of required integral, for example Yet, I still can not find any convenience for further calculation. Thanks in advance for any help.","\int_{0}^{1} \frac{\operatorname{arsinh}x}{x\sqrt{1-x^4}} \,\mathrm{d}x = \frac{\pi^2}{8} \chi_2 
\int_{0}^{\pi/2} {\arctan(\sin x) \,\mathrm{d}x} = 2\chi_2(\sqrt2-1) = \frac{\pi^2}{8} - \frac{\ln^{2}(\sqrt{2}+1)}{2}
 
\int_{0}^{\pi/2} {\arctan(\sin x) \,\mathrm{d}x} = \int_{0}^{1} {\frac{\arctan x}{\sqrt{1-x^2}} \,\mathrm{d}x} = \int_{0}^{1} {\frac{\operatorname{arsinh}x}{x\sqrt{1+x^{2}}} \,\mathrm{d}x}
 
\int_{0}^{\pi/4} {\arcsin(\tan x) \,\mathrm{d}x} = \frac{\pi^2}{8} - \int_{0}^{\pi/2} {\arctan(\sin x) \,\mathrm{d}x} = \frac{\ln^{2}(\sqrt{2}+1)}{2}
 a<1 
I(a) = \int_{0}^{\pi/4} {\arcsin(a\tan x) \,\mathrm{d}x}
 u=\tan x y^2=(1-a^2u^2)/(1+u^2) 
\begin{aligned}
I'(a) &= \int_{0}^{\pi/4} {\frac{\tan x}{\sqrt{1-a^2\tan^2x}} \,\mathrm{d}x} = \int_{0}^{1} {\frac{u}{(1+u^2)\sqrt{1-a^2u^2}} \,\mathrm{d}u} \\
&= \frac1{\sqrt{1+a^2}}\int_{\sqrt{(1-a^2)/2}}^{1} {\frac{\mathrm{d}y}{\sqrt{a^2+y^2}}} = \frac1{\sqrt{1+a^2}}\operatorname{arsinh}\left(\frac{y}{a}\right)\biggr|_{y=\sqrt{(1-a^2)/2}}^{1} \\
&= \frac{1}{\sqrt{1+a^{2}}} \operatorname{arsinh}\frac1{a} - \frac{1}{\sqrt{1+a^{2}}} \operatorname{arsinh}\sqrt{\frac{1-a^2}{2a^2}}
\end{aligned}
 
\begin{aligned}
\int_{0}^{\pi/4} {\arcsin(\tan x) \,\mathrm{d}x} 
&= \int_{0}^{1} \frac{1}{\sqrt{1+a^{2}}} \operatorname{arsinh}\frac1{a} \,\mathrm{d}x - \int_{0}^{1} \frac{1}{\sqrt{1+a^{2}}} \operatorname{arsinh}\sqrt{\frac{1-a^2}{2a^2}} \,\mathrm{d}x \\
&= \operatorname{arsinh}^2(1) + \int_{0}^{1} {\frac{\operatorname{arsinh}a}{a\sqrt{1+a^{2}}}\,\mathrm{d}a} - \int_{0}^{1} \frac{\operatorname{arsinh}a}{a\sqrt{1-a^4}} \,\mathrm{d}a
\end{aligned}
 \chi_2(\sqrt2-1) 
\int_{0}^{1} \frac{\operatorname{arsinh}x}{x\sqrt{1-x^4}} \,\mathrm{d}x = \frac1{2} \int_{0}^{1} \frac{1}{\sqrt{1+x^2}} \operatorname{arcosh}\frac1{x^2} \,\mathrm{d}x = \frac1{4} \int_{0}^{1} \frac{1}{\sqrt{x(1+x)}} \operatorname{arcosh}\frac1{x} \,\mathrm{d}x
","['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
89,Double integral bounds of integration polar change of coordinate,Double integral bounds of integration polar change of coordinate,,"I hope that someone can help me determine the the bounds of integration for this problem. Evaluate $$\iint\limits_{R}xydA$$ where, $$R={(x,y): \frac{x^2}{36}+\frac{y^2}{16}\leq1, x\geq0,y\geq0}$$ my attempt, r=1, since $${(x,y): \frac{x^2}{36}+\frac{y^2}{16}\leq1}$$ The region of integration is in the first quadrant since $${x\geq0,y\geq0}$$ I change from cartesion to polar $$f(x,y)=xy $$ $$f(r,\theta)=rcos(\theta)rsin(\theta)$$ $$dA=rdrd\theta$$ So from everything above I thought the bounds would be r=0 to r=1 and $\theta=0$ to $\theta=\frac{\pi}{2}$ When I put everything together I get $$\int\limits_{0}^\frac{\pi}{2}\int\limits_{0}^{1}rcos(\theta)rsin(\theta)rdrd\theta$$ If I compute the integral above I get $\frac{1}{8}$ , I know that $\frac{1}{8}$ is not the correct answer since the question is multiple choice and the options are (a) 5 (b) 25 (c) 55 (d) 72 (e) 73. I don't know where to go from here I assume that my error has to do with $(x,y): \frac{x^2}{36}+\frac{y^2}{16}\leq1$ since I don't use $0\leq{y}\leq4$ and $0\leq{x}\leq6$ I'm just not sure how to incorporate the fractions are they part of r? Any help would be greatly appreciated, thank you.","I hope that someone can help me determine the the bounds of integration for this problem. Evaluate where, my attempt, r=1, since The region of integration is in the first quadrant since I change from cartesion to polar So from everything above I thought the bounds would be r=0 to r=1 and to When I put everything together I get If I compute the integral above I get , I know that is not the correct answer since the question is multiple choice and the options are (a) 5 (b) 25 (c) 55 (d) 72 (e) 73. I don't know where to go from here I assume that my error has to do with since I don't use and I'm just not sure how to incorporate the fractions are they part of r? Any help would be greatly appreciated, thank you.","\iint\limits_{R}xydA R={(x,y): \frac{x^2}{36}+\frac{y^2}{16}\leq1, x\geq0,y\geq0} {(x,y): \frac{x^2}{36}+\frac{y^2}{16}\leq1} {x\geq0,y\geq0} f(x,y)=xy  f(r,\theta)=rcos(\theta)rsin(\theta) dA=rdrd\theta \theta=0 \theta=\frac{\pi}{2} \int\limits_{0}^\frac{\pi}{2}\int\limits_{0}^{1}rcos(\theta)rsin(\theta)rdrd\theta \frac{1}{8} \frac{1}{8} (x,y): \frac{x^2}{36}+\frac{y^2}{16}\leq1 0\leq{y}\leq4 0\leq{x}\leq6","['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'polar-coordinates']"
90,Tricky real integral: $\int_0^{2 \pi} e^{\cos(2 t)} \cos(\sin(2 t)) =2\pi$,Tricky real integral:,\int_0^{2 \pi} e^{\cos(2 t)} \cos(\sin(2 t)) =2\pi,"I'm trying to prove the following: $$ \int_0^{2 \pi} e^{\cos(2 t)} \cos(\sin(2 t))  =2\pi $$ Numerical analysis agrees with this to very high accuracy, so I'm almost sure it's true. Mathematica gives this answer after thinking for a long, but gives an insane antiderivative in terms of exponential integrals. I'd like to evaluate the integral with purely real methods (I've never done complex analysis), as elegantly as possible. How can I tackle this integral?","I'm trying to prove the following: Numerical analysis agrees with this to very high accuracy, so I'm almost sure it's true. Mathematica gives this answer after thinking for a long, but gives an insane antiderivative in terms of exponential integrals. I'd like to evaluate the integral with purely real methods (I've never done complex analysis), as elegantly as possible. How can I tackle this integral?", \int_0^{2 \pi} e^{\cos(2 t)} \cos(\sin(2 t))  =2\pi ,"['calculus', 'integration', 'definite-integrals']"
91,How do you Evaluate $\int_{-\infty}^\infty \frac{\cos(x)}{x^2+1}dx$ Without Using Residue Calculus,How do you Evaluate  Without Using Residue Calculus,\int_{-\infty}^\infty \frac{\cos(x)}{x^2+1}dx,"So I'm having trouble computing this integral: $$\int_{-\infty}^\infty \frac{\cos(x)}{x^2+1}dx$$ After seeing some other answers on this website, I've realized that many people are using residues to get an answer. However, I know nothing about complex analysis, so I wanted to know if there is a better way of doing it without it. I started by finding the indefinite integral which is: $$-\dfrac{\sinh\left(1\right)\left(\operatorname{Si}\left(x+\mathrm{i}\right)+\operatorname{Si}\left(x-\mathrm{i}\right)\right)-\mathrm{i}\cosh\left(1\right)\left(\operatorname{Ci}\left(x+\mathrm{i}\right)-\operatorname{Ci}\left(x-\mathrm{i}\right)\right)}{2}$$ but finding what this function comes out to when finding the limit of it towards $\infty$ and $-\infty$ I get $-\pi\sinh(1)$ Now, I could be very wrong with both the indefinite integral and the value. Am I doing something wrong? Am I forgetting to take into account something I should be? Thanks in advanced!","So I'm having trouble computing this integral: $$\int_{-\infty}^\infty \frac{\cos(x)}{x^2+1}dx$$ After seeing some other answers on this website, I've realized that many people are using residues to get an answer. However, I know nothing about complex analysis, so I wanted to know if there is a better way of doing it without it. I started by finding the indefinite integral which is: $$-\dfrac{\sinh\left(1\right)\left(\operatorname{Si}\left(x+\mathrm{i}\right)+\operatorname{Si}\left(x-\mathrm{i}\right)\right)-\mathrm{i}\cosh\left(1\right)\left(\operatorname{Ci}\left(x+\mathrm{i}\right)-\operatorname{Ci}\left(x-\mathrm{i}\right)\right)}{2}$$ but finding what this function comes out to when finding the limit of it towards $\infty$ and $-\infty$ I get $-\pi\sinh(1)$ Now, I could be very wrong with both the indefinite integral and the value. Am I doing something wrong? Am I forgetting to take into account something I should be? Thanks in advanced!",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
92,which one is bigger $100^n+99^n$ or $101^n$,which one is bigger  or,100^n+99^n 101^n,"Suppose $n \in \mathbb{N} , n>1000$ now how can we prove :which one is bigger $$100^n+99^n \text{ or  }  101^n \text{ ? }$$  I tried to use $\log$ but get nothing . Then I tried for binomial expansion...but  I get stuck on this . can someone help me ? thanks in advance.","Suppose $n \in \mathbb{N} , n>1000$ now how can we prove :which one is bigger $$100^n+99^n \text{ or  }  101^n \text{ ? }$$  I tried to use $\log$ but get nothing . Then I tried for binomial expansion...but  I get stuck on this . can someone help me ? thanks in advance.",,"['calculus', 'algebra-precalculus', 'number-theory', 'elementary-number-theory']"
93,Solve $\int \frac{1}{\sin ^{\frac{1}{2}}x \cos^{\frac{7}{2}}x}dx$,Solve,\int \frac{1}{\sin ^{\frac{1}{2}}x \cos^{\frac{7}{2}}x}dx,So it's given this indefinite integral $$\int \frac{1}{\sin ^{\frac{1}{2}}x \cos^{\frac{7}{2}}x}dx$$ Is there anyone could solve this integral? Thanks in advance.,So it's given this indefinite integral $$\int \frac{1}{\sin ^{\frac{1}{2}}x \cos^{\frac{7}{2}}x}dx$$ Is there anyone could solve this integral? Thanks in advance.,,"['calculus', 'integration', 'indefinite-integrals']"
94,Evaluate: $\int_{0}^{\pi}\frac{\cos 2017x}{5-4\cos x}dx$,Evaluate:,\int_{0}^{\pi}\frac{\cos 2017x}{5-4\cos x}dx,Evaluate: $\int\limits_{0}^{\pi}\dfrac{\cos 2017x}{5-4\cos x}~dx$ I thought of using some series but could not get it,Evaluate: $\int\limits_{0}^{\pi}\dfrac{\cos 2017x}{5-4\cos x}~dx$ I thought of using some series but could not get it,,"['calculus', 'integration', 'definite-integrals']"
95,How to find $\int \frac{x^2-1}{x^3\sqrt{2x^4-2x^2+1}} dx$ [closed],How to find  [closed],\int \frac{x^2-1}{x^3\sqrt{2x^4-2x^2+1}} dx,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How to find ?$$\int \frac{x^2-1}{x^3\sqrt{2x^4-2x^2+1}} dx$$ I tried using the substitution $x^2=z$.But that did not help much.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How to find ?$$\int \frac{x^2-1}{x^3\sqrt{2x^4-2x^2+1}} dx$$ I tried using the substitution $x^2=z$.But that did not help much.",,['calculus']
96,$\sum\limits_{n=1}^{10000000000000000} \frac{1}{n}$,,\sum\limits_{n=1}^{10000000000000000} \frac{1}{n},How does wolfram alpha solve $$\sum\limits_{n=1}^{10000000000000000} \frac{1}{n}\approx 37.4186$$so quickly? It solved it in like 3 seconds is there a equation or something,How does wolfram alpha solve $$\sum\limits_{n=1}^{10000000000000000} \frac{1}{n}\approx 37.4186$$so quickly? It solved it in like 3 seconds is there a equation or something,,"['calculus', 'summation']"
97,How do I derive $1 + 4 + 9 + \cdots + n^2 = \frac{n (n + 1) (2n + 1)} 6$ [duplicate],How do I derive  [duplicate],1 + 4 + 9 + \cdots + n^2 = \frac{n (n + 1) (2n + 1)} 6,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Proof that $\sum\limits_{k=1}^nk^2 = \frac{n(n+1)(2n+1)}{6}$? I am introducing my daughter to calculus/integration by approximating the area under y = f(x*x) by calculating small rectangles below the curve. This is very intuitive and I think she understands the concept however what I need now is an intuitive way to arrive at $\frac{n (n + 1) (2n + 1)} 6$ when I start from $1 + 4 + 9 + \cdots + n^2$. In other words, just how came the first ancient mathematician up with this formula - what were the first steps leading to this equation? That is what I am interested in, not the actual proof (that would be the second step).","This question already has answers here : Closed 11 years ago . Possible Duplicate: Proof that $\sum\limits_{k=1}^nk^2 = \frac{n(n+1)(2n+1)}{6}$? I am introducing my daughter to calculus/integration by approximating the area under y = f(x*x) by calculating small rectangles below the curve. This is very intuitive and I think she understands the concept however what I need now is an intuitive way to arrive at $\frac{n (n + 1) (2n + 1)} 6$ when I start from $1 + 4 + 9 + \cdots + n^2$. In other words, just how came the first ancient mathematician up with this formula - what were the first steps leading to this equation? That is what I am interested in, not the actual proof (that would be the second step).",,"['calculus', 'summation', 'intuition']"
98,How to evaluate the integral $I = \int_o^{\infty} \frac{x}{\sqrt{e^{2\pi\sqrt{x}}-1}}dx$?,How to evaluate the integral ?,I = \int_o^{\infty} \frac{x}{\sqrt{e^{2\pi\sqrt{x}}-1}}dx,"$$I = \int_{0}^{\infty} \frac{x}{\sqrt{e^{2\pi\sqrt{x}}-1}}\,dx$$ . I tried to solve by substituting $t = 2\pi\sqrt x \implies t^2 = 4{\pi}^2x \implies tdt = 2\pi^2dx$ $$I = \frac1{8\pi^4}\int_0^{\infty}\frac{t^3}{\sqrt{e^t-1}}dt.$$ But now I'm unable to solve from here.",. I tried to solve by substituting But now I'm unable to solve from here.,"I = \int_{0}^{\infty} \frac{x}{\sqrt{e^{2\pi\sqrt{x}}-1}}\,dx t = 2\pi\sqrt x \implies t^2 = 4{\pi}^2x \implies tdt = 2\pi^2dx I = \frac1{8\pi^4}\int_0^{\infty}\frac{t^3}{\sqrt{e^t-1}}dt.","['calculus', 'integration']"
99,Why is this inequality true? $(a+b)^2\leq 2(a^2+b^2)$,Why is this inequality true?,(a+b)^2\leq 2(a^2+b^2),"Why is this inequality true? $a,b$ are real numbers. $$ (a+b)^2=a^2+2ab+b^2\leq 2(a^2+b^2) $$ I know $(a+b)^2=a^2+2ab+b^2 \geq 0$, but then?","Why is this inequality true? $a,b$ are real numbers. $$ (a+b)^2=a^2+2ab+b^2\leq 2(a^2+b^2) $$ I know $(a+b)^2=a^2+2ab+b^2 \geq 0$, but then?",,"['calculus', 'inequality']"
