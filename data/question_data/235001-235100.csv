,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Prove that if $x$ is the greatest lower bound of $U$, then $x$ is the least upper bound of $B$","Prove that if  is the greatest lower bound of , then  is the least upper bound of",x U x B,"Suppose $R$ is a partial order on $A$ , $B \subseteq A$ . Let $U$ be the set for all upper bounds for $B$ . Prove that if $x$ is the greatest lower bound (or g.l.b) of $U$ , then $x$ is the least upper bound (or l.u.b) of $B$ . My attempt: Suppose $L_u$ is the set containing all lower bounds of $U$ . Suppose $x$ is g.l.b. of $U$ . Take arbitrary $b \in B$ Take $u \in U$ . We know that $bRu$ . Since $u$ was arbitrary, we conclude that $b$ is lower bound for $U$ , which means $b \in L_u$ Since $x$ is g.l.b. of $U$ , we have $x \in L_u$ and $bRx$ . Since $b$ was arbitrary element of $B$ , it follows that $x$ is upper bound of $B$ , thus $x \in U$ . Since $x \in L_u$ , it also follows that for all $u \in U$ , we have $xRu$ , hence $x$ is the smallest element of $U$ , which implies that $x$ is l.u.b. of $B$ . $\Box$ Is it correct?","Suppose is a partial order on , . Let be the set for all upper bounds for . Prove that if is the greatest lower bound (or g.l.b) of , then is the least upper bound (or l.u.b) of . My attempt: Suppose is the set containing all lower bounds of . Suppose is g.l.b. of . Take arbitrary Take . We know that . Since was arbitrary, we conclude that is lower bound for , which means Since is g.l.b. of , we have and . Since was arbitrary element of , it follows that is upper bound of , thus . Since , it also follows that for all , we have , hence is the smallest element of , which implies that is l.u.b. of . Is it correct?",R A B \subseteq A U B x U x B L_u U x U b \in B u \in U bRu u b U b \in L_u x U x \in L_u bRx b B x B x \in U x \in L_u u \in U xRu x U x B \Box,"['proof-verification', 'elementary-set-theory']"
1,Why is $\bigcap_{\lambda\ge0}I^\lambda_0 = \bigcap_{\lambda\lt0}I^\lambda_0$?,Why is ?,\bigcap_{\lambda\ge0}I^\lambda_0 = \bigcap_{\lambda\lt0}I^\lambda_0,"In ""Introductory Mathematics: Algebra and Analysis"" by Smith the excercise 1.2 (k) reads: "" ... write down the set which is different ... In parts (j) and (k), the symbol $I^s_r$ denotes the set of real numbers $\{\eta\ |\ r\le\eta\lt s\}$ where $r$ and $s$ are themselves real numbers. (k) (i) $\bigcap_{\lambda\gt0}I^\lambda_0$ ,  (ii) $\bigcap_{\lambda\ge0}I^\lambda_0$ ,   (iii) $\bigcap_{\lambda\lt0}I^\lambda_0$ "" My thinking is that (i)=(ii) which is a set of 0 to $\lambda$ , but not included. The (iii) will always have {} because $\lambda\lt0$ will never satisfy $I^\lambda_0$ ; $\{\eta\ |\ 0\le\eta\lt \lambda\}$ . The answer on the other hand says that (i) differs from the other two; which implies (ii)=(iii). Why?","In ""Introductory Mathematics: Algebra and Analysis"" by Smith the excercise 1.2 (k) reads: "" ... write down the set which is different ... In parts (j) and (k), the symbol denotes the set of real numbers where and are themselves real numbers. (k) (i) ,  (ii) ,   (iii) "" My thinking is that (i)=(ii) which is a set of 0 to , but not included. The (iii) will always have {} because will never satisfy ; . The answer on the other hand says that (i) differs from the other two; which implies (ii)=(iii). Why?",I^s_r \{\eta\ |\ r\le\eta\lt s\} r s \bigcap_{\lambda\gt0}I^\lambda_0 \bigcap_{\lambda\ge0}I^\lambda_0 \bigcap_{\lambda\lt0}I^\lambda_0 \lambda \lambda\lt0 I^\lambda_0 \{\eta\ |\ 0\le\eta\lt \lambda\},[]
2,Set theory notation.,Set theory notation.,,"I came across this notation $$\bigcap _{i\in\mathbb{N} }(A_i \cup B_i)$$ while reading a paper on elementary set theory, but I'm not sure of what it means. (Perhaps the intersection of all sets $A_i \cup B_i$ ?) Could anybody tell me?","I came across this notation while reading a paper on elementary set theory, but I'm not sure of what it means. (Perhaps the intersection of all sets ?) Could anybody tell me?",\bigcap _{i\in\mathbb{N} }(A_i \cup B_i) A_i \cup B_i,['elementary-set-theory']
3,Proof A × (B ∩ C) = (A × B) ∩ (A × C),Proof A × (B ∩ C) = (A × B) ∩ (A × C),,"Is this proof enough? A × (B ∩ C) = (A × B) ∩ (A × C) L = A × (B ∩ C) = = {(a, b) | a ∈ A, b ∈ (B ∩ C)} = = {(a, b) | a ∈ A ∧ (b ∈ B ∧ b ∈ C)} = = {(a, b) | (a ∈ A ∧ b ∈ B) ∧ (a ∈ A ∧ b ∈ C)} R = (A × B) ∩ (A × C) = = {(a, b) | (a, b) ∈ (A × B) ∧ (a, b) ∈ (A × C)} = = {(a, b) | (a ∈ A ∧ b ∈ B) ∧ (a ∈ A ∧ b ∈ C)} L = R","Is this proof enough? A × (B ∩ C) = (A × B) ∩ (A × C) L = A × (B ∩ C) = = {(a, b) | a ∈ A, b ∈ (B ∩ C)} = = {(a, b) | a ∈ A ∧ (b ∈ B ∧ b ∈ C)} = = {(a, b) | (a ∈ A ∧ b ∈ B) ∧ (a ∈ A ∧ b ∈ C)} R = (A × B) ∩ (A × C) = = {(a, b) | (a, b) ∈ (A × B) ∧ (a, b) ∈ (A × C)} = = {(a, b) | (a ∈ A ∧ b ∈ B) ∧ (a ∈ A ∧ b ∈ C)} L = R",,['elementary-set-theory']
4,Techniques for set operation proofs?,Techniques for set operation proofs?,,"Techniques for set operation proofs? Particularly, Consider e.g. $$E \cup F = (E \setminus F)\cup(F \setminus E) \cup (E \cap F)$$ I can see this true from Venn diagrams, but I struggle as to how to write it algebraically. So how to approach it and other kinds? Show that $A \cup B = (A$ \ $B ) \cup (A \cap B) \cup (B$ \ $A)$","Techniques for set operation proofs? Particularly, Consider e.g. I can see this true from Venn diagrams, but I struggle as to how to write it algebraically. So how to approach it and other kinds? Show that $A \cup B = (A$ \ $B ) \cup (A \cap B) \cup (B$ \ $A)$",E \cup F = (E \setminus F)\cup(F \setminus E) \cup (E \cap F),['elementary-set-theory']
5,How to apply SETs properties in this example?,How to apply SETs properties in this example?,,"Let $$ A=\{1,2,3,4,5\}$$ and $$ B=\{1,2,3,6,7\}$$ and $$ C=\{1,2,3,8,9\}$$ is it correct to state: $$(A \cup B)-C = \{1,2,3,4,5,6,7\}-\{1,2,3,8,9\}=\{4,5,6,7\}$$ $$A \cup (B-C) = \{1,2,3,4,5\} \cup \{6,7\}=\{1,2,3,4,5,6,7\}$$ hence $$(A \cup B)-C\neq A \cup (B-C)$$",Let and and is it correct to state: hence," A=\{1,2,3,4,5\}  B=\{1,2,3,6,7\}  C=\{1,2,3,8,9\} (A \cup B)-C = \{1,2,3,4,5,6,7\}-\{1,2,3,8,9\}=\{4,5,6,7\} A \cup (B-C) = \{1,2,3,4,5\} \cup \{6,7\}=\{1,2,3,4,5,6,7\} (A \cup B)-C\neq A \cup (B-C)",['elementary-set-theory']
6,Is this solution correct? Show that a set $A$ of open intervals satisfies $|A| \leq \aleph_0$,Is this solution correct? Show that a set  of open intervals satisfies,A |A| \leq \aleph_0,"$A$ is a set of open and non-empty intervals (real intervals) such that for all $B,C,D \in A$ we have $B \cap C\cap D= \emptyset$ . Show that $|A| \leq \aleph_0$ . This is what I did and I would like to know if it is correct. For all $q \in \mathbb{Q}$ define $A_q = \{B \in A : q \in B\}$ . Obviously $A= \cup_{q \in \Bbb{Q}} A_q$ because every non-empty interval contains a rational number. However, since every three intervals in $A$ do not intersect, we must have $|A_q| <3$ for every rational number $q$ . Therefore we represented $A$ as a countable union of countable sets, and therefore $A$ is countable (here by countable I mean at most $\aleph_0$ ). Is it correct?","is a set of open and non-empty intervals (real intervals) such that for all we have . Show that . This is what I did and I would like to know if it is correct. For all define . Obviously because every non-empty interval contains a rational number. However, since every three intervals in do not intersect, we must have for every rational number . Therefore we represented as a countable union of countable sets, and therefore is countable (here by countable I mean at most ). Is it correct?","A B,C,D \in A B \cap C\cap D= \emptyset |A| \leq \aleph_0 q \in \mathbb{Q} A_q = \{B \in A : q \in B\} A= \cup_{q \in \Bbb{Q}} A_q A |A_q| <3 q A A \aleph_0",['elementary-set-theory']
7,An equation involving multisets,An equation involving multisets,,"For multisets $A, B, C, A', B', C'$ , if $A \uplus B \uplus \{B \uplus C\} \uplus \{A \uplus \{C\}\}$ = $A' \uplus B' \uplus \{B' \uplus C'\} \uplus \{A' \uplus \{C'\}\}$ , must $A=A',B=B',C=C'$ , where $\uplus$ denotes mutliset sum as defined here https://oeis.org/wiki/Multisets#Multiset_sum EDIT: Here's why I'm interested in this question. In simply relationally typed higher-order languages following Orey ""Model Theory for the Higher Order Predicate Calculus"" (1959), predicates have different syntactic types, which are identified with sequences of types. The idea is that, if a predicate is of type $\langle t_1,\dots,t_n\rangle$ , then it combines with $n$ arguments respectively of types $t_1,\dots,t_n$ in that order to form a formula. I'm interested in how to think about higher-order languages like this except where, intuitively, the argument-places of predicates are unordered; to form a formula by combining a predicate with some arguments you can't just list the arguments -- instead (simplifying somewhat) you biject arguments with argument-places of the predicate. In this framework, types of predicates aren't identified with sequences of types, but with multisets of types, since multisets are basically unordered sequences. The reason I'm interested in the particular equation above is that, in thinking about how to do combinatory logic in such a higher-order language, it turns out that the analogue of what are usually called B combinators end up having types of the above form, and I'm interested in whether these combinators, in this setting, are uniquely determined by their types, or whether there could be distinct B-like combinators of the same type. (Intuitively, such a combinator of type $A \uplus B \uplus \{B \uplus C\} \uplus \{A \uplus \{C\}\}$ can combine with arguments $a_1,...,a_n$ the multiplicity of the types of which is $A$ , $b_1,...,b_m$ the multiplicity of the types of which is $B$ , a predicate of type $\{B \uplus C\}$ , and a predicate of type $\{A \uplus \{C\}\}$ to form a formula. For example, if $A=B=C=\{e\}$ (where $e$ is the base type of individuals), the relevant B-like combinator will be analogous to the simply relationally-typed lambda-term $\beta := (\lambda x^ey^eX^{\langle e,e\rangle}Y^{\langle e,\langle e\rangle\rangle}.Yx(\lambda z^e.Xyz))$ , which combines with terms $a$ and $b$ of type $e$ , a predicate $R$ of type $\langle e,e\rangle$ , and a predicate $S$ of type $\langle e, \langle e\rangle\rangle$ , to form a formula $\beta abRS$ which we can think of as saying that individual $a$ stands in relation $S$ to the property of being $R$ -related to individual $b$ .)","For multisets , if = , must , where denotes mutliset sum as defined here https://oeis.org/wiki/Multisets#Multiset_sum EDIT: Here's why I'm interested in this question. In simply relationally typed higher-order languages following Orey ""Model Theory for the Higher Order Predicate Calculus"" (1959), predicates have different syntactic types, which are identified with sequences of types. The idea is that, if a predicate is of type , then it combines with arguments respectively of types in that order to form a formula. I'm interested in how to think about higher-order languages like this except where, intuitively, the argument-places of predicates are unordered; to form a formula by combining a predicate with some arguments you can't just list the arguments -- instead (simplifying somewhat) you biject arguments with argument-places of the predicate. In this framework, types of predicates aren't identified with sequences of types, but with multisets of types, since multisets are basically unordered sequences. The reason I'm interested in the particular equation above is that, in thinking about how to do combinatory logic in such a higher-order language, it turns out that the analogue of what are usually called B combinators end up having types of the above form, and I'm interested in whether these combinators, in this setting, are uniquely determined by their types, or whether there could be distinct B-like combinators of the same type. (Intuitively, such a combinator of type can combine with arguments the multiplicity of the types of which is , the multiplicity of the types of which is , a predicate of type , and a predicate of type to form a formula. For example, if (where is the base type of individuals), the relevant B-like combinator will be analogous to the simply relationally-typed lambda-term , which combines with terms and of type , a predicate of type , and a predicate of type , to form a formula which we can think of as saying that individual stands in relation to the property of being -related to individual .)","A, B, C, A', B', C' A \uplus B \uplus \{B \uplus C\} \uplus \{A \uplus \{C\}\} A' \uplus B' \uplus \{B' \uplus C'\} \uplus \{A' \uplus \{C'\}\} A=A',B=B',C=C' \uplus \langle t_1,\dots,t_n\rangle n t_1,\dots,t_n A \uplus B \uplus \{B \uplus C\} \uplus \{A \uplus \{C\}\} a_1,...,a_n A b_1,...,b_m B \{B \uplus C\} \{A \uplus \{C\}\} A=B=C=\{e\} e \beta := (\lambda x^ey^eX^{\langle e,e\rangle}Y^{\langle e,\langle e\rangle\rangle}.Yx(\lambda z^e.Xyz)) a b e R \langle e,e\rangle S \langle e, \langle e\rangle\rangle \beta abRS a S R b","['elementary-set-theory', 'type-theory', 'multisets', 'higher-order-logic', 'combinatory-logic']"
8,Which elements are in $\mathcal{P}(\emptyset)\backslash \emptyset$,Which elements are in,\mathcal{P}(\emptyset)\backslash \emptyset,"We have $\mathcal{P}(\emptyset)\ = \{\emptyset\}$ . And $x \in \mathcal{P}(\emptyset)\backslash \emptyset$ means that $x \in \{\emptyset\} $ and $x \notin \emptyset$ . I think that $\emptyset \in \{\emptyset\}$ and $\emptyset \notin \emptyset$ . Hence $\mathcal{P}(\emptyset)\backslash \emptyset = \{\emptyset \}$ , but the solution for this task says that $|\mathcal{P}(\emptyset)\backslash \emptyset| = 0$ .","We have . And means that and . I think that and . Hence , but the solution for this task says that .",\mathcal{P}(\emptyset)\ = \{\emptyset\} x \in \mathcal{P}(\emptyset)\backslash \emptyset x \in \{\emptyset\}  x \notin \emptyset \emptyset \in \{\emptyset\} \emptyset \notin \emptyset \mathcal{P}(\emptyset)\backslash \emptyset = \{\emptyset \} |\mathcal{P}(\emptyset)\backslash \emptyset| = 0,['elementary-set-theory']
9,Preimage of Union is Union of Preimage,Preimage of Union is Union of Preimage,,"Struggling on what steps to take to construct a successful proof for this. This will be the last. Can I get a verification? I think the approach and logic is wrong. Prove: If $f:A \rightarrow B$ is a function with domain $A$ and $T_i$ with $i \in I$ is a family of sets where $\forall i \in I$ , $T_i \subseteq B$ then $f^{-1}(  \bigcup\limits_{i \in I} T_{i})= \bigcup\limits_{i \in I}f^{-1} (T_{i})$ Proving Subset both ways Prove $f^{-1}(  \bigcup\limits_{i \in I} T_{i}) \subseteq \bigcup\limits_{i \in I}f^{-1} (T_{i})$ Assume $s \in f^{-1}(  \bigcup\limits_{i \in I} T_{i})$ $\implies$ $f(s) \in \bigcup\limits_{i \in I} T_{i}$ $(\exists i \in I)$ s.t. $f(s) \in  T_{i}$ $(\exists i \in I)$ s.t. $s \in f^{-1} (T_{i})$ So $f^{-1}(  \bigcup\limits_{i \in I} T_{i}) \subseteq \bigcup\limits_{i \in I}f^{-1} (T_{i})$ Next Prove $f^{-1}(  \bigcup\limits_{i \in I} T_{i}) \supseteq \bigcup\limits_{i \in I}f^{-1} (T_{i})$ Assume $s \in \bigcup\limits_{i \in I}f^{-1} (T_{i})$ $\implies (\exists i \in I)$ s.t. $s \in f^{-1}(T_i)$ $\implies (\exists i \in I)$ s.t. $f(s) \in T_i$ $\implies f(s)\in  \bigcup\limits_{i \in I}T_{i}$ $\implies s \in f^{-1}(\bigcup\limits_{i \in I}T_{i})$","Struggling on what steps to take to construct a successful proof for this. This will be the last. Can I get a verification? I think the approach and logic is wrong. Prove: If is a function with domain and with is a family of sets where , then Proving Subset both ways Prove Assume s.t. s.t. So Next Prove Assume s.t. s.t.","f:A \rightarrow B A T_i i \in I \forall i \in I T_i \subseteq B f^{-1}( 
\bigcup\limits_{i \in I} T_{i})= \bigcup\limits_{i \in I}f^{-1} (T_{i}) f^{-1}( 
\bigcup\limits_{i \in I} T_{i}) \subseteq \bigcup\limits_{i \in I}f^{-1} (T_{i}) s \in f^{-1}( 
\bigcup\limits_{i \in I} T_{i}) \implies f(s) \in \bigcup\limits_{i \in I} T_{i} (\exists i \in I) f(s) \in  T_{i} (\exists i \in I) s \in f^{-1} (T_{i}) f^{-1}( 
\bigcup\limits_{i \in I} T_{i}) \subseteq \bigcup\limits_{i \in I}f^{-1} (T_{i}) f^{-1}( 
\bigcup\limits_{i \in I} T_{i}) \supseteq \bigcup\limits_{i \in I}f^{-1} (T_{i}) s \in \bigcup\limits_{i \in I}f^{-1} (T_{i}) \implies (\exists i \in I) s \in f^{-1}(T_i) \implies (\exists i \in I) f(s) \in T_i \implies f(s)\in  \bigcup\limits_{i \in I}T_{i} \implies s \in f^{-1}(\bigcup\limits_{i \in I}T_{i})",['elementary-set-theory']
10,"Prove that for any set A and B, the cardinality of the set of all functions mapping A to B is $\vert B \vert ^ {\vert A \vert}$","Prove that for any set A and B, the cardinality of the set of all functions mapping A to B is",\vert B \vert ^ {\vert A \vert},"What I do is for finite sets A, B, let $A={a_1, a_2, ...a_n}$ and $B={b_1, b_2, ...b_m}$ A function f assigns each element $a_i$ of $A$ to an element $b_j = f (a_i)$ of $B$ ; there are $m$ possibilities for each element of $A$ , we have $m, m, ...m=m^n= \vert B \vert ^ {\vert A \vert}$ possible functions. Since A and B are any sets, how can we extend above to an infinite countable or uncountable sets?","What I do is for finite sets A, B, let and A function f assigns each element of to an element of ; there are possibilities for each element of , we have possible functions. Since A and B are any sets, how can we extend above to an infinite countable or uncountable sets?","A={a_1, a_2, ...a_n} B={b_1, b_2, ...b_m} a_i A b_j = f (a_i) B m A m, m, ...m=m^n=
\vert B \vert ^ {\vert A \vert}","['elementary-set-theory', 'cardinals']"
11,Proof verifications for set equality,Proof verifications for set equality,,"Can I get a proof verification? Are there any flaws in this proof? The examples in the book are only for sets bounded either above or below. Prove $$\cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})=(0,1)$$ Assume $x \in \cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})$ . Thus $\exists n_x \in \mathbb{N}$ such that $x \in (0,\frac{n_x}{n_x+1})$ $\implies 0<x<\frac{n_x}{n_x+1}$ also since $0<1 \implies$ $n_x<n_x+1 \implies \frac{n_x}{n_x+1}<1$ We have $0<x<\frac{n_x}{n_x+1}<1$ Thus $x \in (0,1)$ So $$\cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})\subseteq(0,1)$$ Assume $0<x<1$ Then since $0<1-x$ , $\frac{x}{1-x} \in \mathbb{R}$ By the Archimedean property $\exists n \in  \mathbb{N}$ such that $n>\frac{x}{1-x}$ Thus $0<x< \frac{n}{n+1}$ So $x \in \cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})$ And $$\cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})\supseteq(0,1)$$","Can I get a proof verification? Are there any flaws in this proof? The examples in the book are only for sets bounded either above or below. Prove Assume . Thus such that also since We have Thus So Assume Then since , By the Archimedean property such that Thus So And","\cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})=(0,1) x \in \cup_{n\in \mathbb{N}}(0,\frac{n}{n+1}) \exists n_x \in \mathbb{N} x \in (0,\frac{n_x}{n_x+1}) \implies 0<x<\frac{n_x}{n_x+1} 0<1 \implies n_x<n_x+1 \implies \frac{n_x}{n_x+1}<1 0<x<\frac{n_x}{n_x+1}<1 x \in (0,1) \cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})\subseteq(0,1) 0<x<1 0<1-x \frac{x}{1-x} \in \mathbb{R} \exists n \in 
\mathbb{N} n>\frac{x}{1-x} 0<x< \frac{n}{n+1} x \in \cup_{n\in \mathbb{N}}(0,\frac{n}{n+1}) \cup_{n\in \mathbb{N}}(0,\frac{n}{n+1})\supseteq(0,1)",['proof-verification']
12,A Question of Ordinal - İnitial Segment,A Question of Ordinal - İnitial Segment,,"Let $\alpha$ be an ordinal. Let $z$ be an initial segment of $\alpha$ . Then either $z=\alpha$ or $z\in\alpha$ . Thus, an initial segment of an ordinal is an ordinal. Proof. If $z\neq\alpha$ , then $\alpha\setminus z$ does have a minimal element, say $x$ . Then $$z=\left\{y\in\alpha : y<\alpha\right\}=\left\{y\in\alpha : y\in\alpha\right\}=x\in\alpha.$$ I have a question in the proof: How did writer connect from $\left\{y\in\alpha : y<\alpha\right\}$ to the set $\left\{y\in\alpha : y\in\alpha\right\}=x\in\alpha.$ Can you explain?","Let be an ordinal. Let be an initial segment of . Then either or . Thus, an initial segment of an ordinal is an ordinal. Proof. If , then does have a minimal element, say . Then I have a question in the proof: How did writer connect from to the set Can you explain?",\alpha z \alpha z=\alpha z\in\alpha z\neq\alpha \alpha\setminus z x z=\left\{y\in\alpha : y<\alpha\right\}=\left\{y\in\alpha : y\in\alpha\right\}=x\in\alpha. \left\{y\in\alpha : y<\alpha\right\} \left\{y\in\alpha : y\in\alpha\right\}=x\in\alpha.,"['proof-verification', 'elementary-set-theory']"
13,What is the definition of a set?,What is the definition of a set?,,"From what I have been told, everything in mathematics has a definition and everything is based on the rules of logic. For example, whether or not $0^0$ is $1$ is a simple matter of definition . My question is what the definition of a set is? I have noticed that many other definitions start with a set and then something. A group is a set with an operation, an equivalence relation is a set, a function can be considered a set , even the natural numbers can be defined as sets of other sets containing the empty set. I understand that there is a whole area of mathematics (and philosophy?) that deals with set theory . I have looked at a book about this and I understand next to nothing. From what little I can get, it seems a sets are ""anything"" that satisfies the axioms of set theory. It isn't enough to just say that a set is any collection of elements because of various paradoxes. So is it, for example, a right definition to say that a set is anything that satisfies the ZFC list of axioms?","From what I have been told, everything in mathematics has a definition and everything is based on the rules of logic. For example, whether or not $0^0$ is $1$ is a simple matter of definition . My question is what the definition of a set is? I have noticed that many other definitions start with a set and then something. A group is a set with an operation, an equivalence relation is a set, a function can be considered a set , even the natural numbers can be defined as sets of other sets containing the empty set. I understand that there is a whole area of mathematics (and philosophy?) that deals with set theory . I have looked at a book about this and I understand next to nothing. From what little I can get, it seems a sets are ""anything"" that satisfies the axioms of set theory. It isn't enough to just say that a set is any collection of elements because of various paradoxes. So is it, for example, a right definition to say that a set is anything that satisfies the ZFC list of axioms?",,"['algebra-precalculus', 'set-theory', 'definition', 'foundations']"
14,Prove $(A\times B)^C \sim A^C\times B^C$,Prove,(A\times B)^C \sim A^C\times B^C,"Let A,B,C be sets. Prove $(A\times B)^C \sim A^C\times B^C$ In order to prove it, we need to define a function and show: The function is to range of defined function. The function is injective. The function is surjective. My question is only regarding the first step. Proof of first step: We define a function $H: A^C\times B^C \to (A\times B)^C$ with the following rule: $\forall(f,g)\in A^C\times B^C$ , $H((f,g))$ is a function from $C$ to $A\times B$ which defined by the following rule: $\forall x\in C, (H(f,g))(x)=(f(x),g(x))$ . Let be an arbitrary element $p\in Img(H)$ , we need to show $p\in (A\times B)^C$ to complete this part of the proof. $p\in Img(H)$ then exist $m\in A^C\times B^C$ such that $H(m)=p$ . My difficult is to show formally the first step, I mean, we need to show $Img(H)\subseteq (A\times B)^C$ and since it is very clear, I found a difficulty to formalize it. While defining the function above, I have tried a lot to define the function H when the domain is the $(A\times B)^C$ and the range is $A^C\times B^C$ bijective. However, I did not succeed write it formally, so I will be glad to see the if it could be defined formally. (Where the issue? $\forall g\in (A\times B)^C$ , $H(g)=(g^{-1}\cap A\times A,g^{-1}\cap B\times B)$ How can I be sure that $g$ is inverse(bijective) when I define it, is it fine or I need first to show that is bijective so $g$ is inverse?)","Let A,B,C be sets. Prove In order to prove it, we need to define a function and show: The function is to range of defined function. The function is injective. The function is surjective. My question is only regarding the first step. Proof of first step: We define a function with the following rule: , is a function from to which defined by the following rule: . Let be an arbitrary element , we need to show to complete this part of the proof. then exist such that . My difficult is to show formally the first step, I mean, we need to show and since it is very clear, I found a difficulty to formalize it. While defining the function above, I have tried a lot to define the function H when the domain is the and the range is bijective. However, I did not succeed write it formally, so I will be glad to see the if it could be defined formally. (Where the issue? , How can I be sure that is inverse(bijective) when I define it, is it fine or I need first to show that is bijective so is inverse?)","(A\times B)^C \sim A^C\times B^C H: A^C\times B^C \to (A\times B)^C \forall(f,g)\in A^C\times B^C H((f,g)) C A\times B \forall x\in C, (H(f,g))(x)=(f(x),g(x)) p\in Img(H) p\in (A\times B)^C p\in Img(H) m\in A^C\times B^C H(m)=p Img(H)\subseteq (A\times B)^C (A\times B)^C A^C\times B^C \forall g\in (A\times B)^C H(g)=(g^{-1}\cap A\times A,g^{-1}\cap B\times B) g g",['elementary-set-theory']
15,"If $f: A \rightarrow B$ and $g: B \rightarrow C$, is $(g \circ f)^{-1}(C) = f^{-1}(B)$?","If  and , is ?",f: A \rightarrow B g: B \rightarrow C (g \circ f)^{-1}(C) = f^{-1}(B),"Let $f: A \rightarrow B$ and $g: B \rightarrow C$ . I have a question that is asking me to come up with and prove some theorems about the images and inverse images of sets under $g \circ f$ . This is a theorem and proof that I have so far (sorry, I'm not great at writing proofs): Theorem: Suppose $f: A \rightarrow B$ and $g: B \rightarrow C$ . Then $(g \circ f)^{-1}(C) = f^{-1}(B)$ . $(\subseteq)$ Suppose $x \in (g \circ f)^{-1}(C)$ . This implies that $x \in A$ . Since $x \in A$ and $f: A \rightarrow B$ is a function, then $f(x) \in B$ . Thus, since $x \in A$ and $f(x) \in B$ , it follows that $x \in f^{-1}(B)$ . $(\supseteq)$ Suppose $x \in f^{-1}(B)$ . This implies that $x \in A$ and $f(x) \in B$ . Since $f(x) \in B$ and $g: B \rightarrow C$ is a function, then $g(f(x)) \in C$ . Thus, since $x \in A$ and $g(f(x))=(g \circ f)(x) \in C$ , it follows that $x \in (g \circ f)^{-1}(C)$ . Is this a valid theorem and proof, or is this not always true? I'm having trouble trying to come up with a counterexample.","Let and . I have a question that is asking me to come up with and prove some theorems about the images and inverse images of sets under . This is a theorem and proof that I have so far (sorry, I'm not great at writing proofs): Theorem: Suppose and . Then . Suppose . This implies that . Since and is a function, then . Thus, since and , it follows that . Suppose . This implies that and . Since and is a function, then . Thus, since and , it follows that . Is this a valid theorem and proof, or is this not always true? I'm having trouble trying to come up with a counterexample.",f: A \rightarrow B g: B \rightarrow C g \circ f f: A \rightarrow B g: B \rightarrow C (g \circ f)^{-1}(C) = f^{-1}(B) (\subseteq) x \in (g \circ f)^{-1}(C) x \in A x \in A f: A \rightarrow B f(x) \in B x \in A f(x) \in B x \in f^{-1}(B) (\supseteq) x \in f^{-1}(B) x \in A f(x) \in B f(x) \in B g: B \rightarrow C g(f(x)) \in C x \in A g(f(x))=(g \circ f)(x) \in C x \in (g \circ f)^{-1}(C),"['functions', 'proof-verification', 'elementary-set-theory']"
16,"Proof of : "" Union of all R-equivalence classes on A is included in A"" based on "" R is a subset of A² "". ( Q° on Ayres, Problems Modern Algebra)","Proof of : "" Union of all R-equivalence classes on A is included in A"" based on "" R is a subset of A² "". ( Q° on Ayres, Problems Modern Algebra)",,"I'm studying Ayres Theory and Problems of Modern Algebra . In Chapter 2, Solved Problem 6, the question is asked to prove that "" An equivalence relation R on a set S effects a partition of S."" Ayers notes T(a) , T(b), T(c), etc.  the equivalence classes of ( respectively) the elements a, b, c , etc belonging to the set S. Aiming at proving first that the union of all equivalent classes is equal to S (which is the first condition for the set of equivalence classes to be a partition of S), Ayres only says : "" Since p belongs to [p] , it is clear that S is the union of all the distinct subsets T(a), T(b), T(c)."" My question is: knowing that to prove a set equality, a reciprocal inclusion has to be shown, does the argument given by Ayres prove inclusion in both directions ? May I develop Ayre's argument in the following way? (1) Proving that S is included in the union of the family of equivalence classes. Suppose p belongs to A. Since pRp ( given reflexivity) , p belongs to the R-equivalence class [p]. But the union of the set of R-equivalence classes on A is { x | x belongs to at least one R-equivalence class on A}. So, knowing that [p] is an R-equivalence class on A and that p belongs to [p], it follows that p belongs to at least one R-equivalence class on A , and, therefore, to the union of the set of R-equivalence classes on A. (2) Proving that the union of R-equivalence classes on A is included in A. Suppose that x belongs to the union of R-equivalence classes. It means that x belongs to at least one equivalence class ( by the definition of "" union"") , say the class [a]. So there exists an element a belonging to A such that : xRa , that is such that (x,a) belongs to R. But R ( being a relation on A) is a subset of A². So (x,a) belongs to A² . But A² is the set of all pairs such that both their first and second element belong to A. So the first element of (x,a) belongs to A. So x belongs to A. Since x was arbitrary, we can conclude that for all x, if x belongs to the union of the set of R-equivalence classes on A, then x belongs to A; in other words, that the union of the set of R-equiv classes is included in A.","I'm studying Ayres Theory and Problems of Modern Algebra . In Chapter 2, Solved Problem 6, the question is asked to prove that "" An equivalence relation R on a set S effects a partition of S."" Ayers notes T(a) , T(b), T(c), etc.  the equivalence classes of ( respectively) the elements a, b, c , etc belonging to the set S. Aiming at proving first that the union of all equivalent classes is equal to S (which is the first condition for the set of equivalence classes to be a partition of S), Ayres only says : "" Since p belongs to [p] , it is clear that S is the union of all the distinct subsets T(a), T(b), T(c)."" My question is: knowing that to prove a set equality, a reciprocal inclusion has to be shown, does the argument given by Ayres prove inclusion in both directions ? May I develop Ayre's argument in the following way? (1) Proving that S is included in the union of the family of equivalence classes. Suppose p belongs to A. Since pRp ( given reflexivity) , p belongs to the R-equivalence class [p]. But the union of the set of R-equivalence classes on A is { x | x belongs to at least one R-equivalence class on A}. So, knowing that [p] is an R-equivalence class on A and that p belongs to [p], it follows that p belongs to at least one R-equivalence class on A , and, therefore, to the union of the set of R-equivalence classes on A. (2) Proving that the union of R-equivalence classes on A is included in A. Suppose that x belongs to the union of R-equivalence classes. It means that x belongs to at least one equivalence class ( by the definition of "" union"") , say the class [a]. So there exists an element a belonging to A such that : xRa , that is such that (x,a) belongs to R. But R ( being a relation on A) is a subset of A². So (x,a) belongs to A² . But A² is the set of all pairs such that both their first and second element belong to A. So the first element of (x,a) belongs to A. So x belongs to A. Since x was arbitrary, we can conclude that for all x, if x belongs to the union of the set of R-equivalence classes on A, then x belongs to A; in other words, that the union of the set of R-equiv classes is included in A.",,['abstract-algebra']
17,Does this proof that $\mathbb{D}$ is countable work?,Does this proof that  is countable work?,\mathbb{D},"I am trying to prove that the set $\mathbb{D}$ of finite decimals is countable. My proof seems too simple to work out - I simply list the all of the decimals with $N$ digits for all $N\geq 1$ , starting with $N=1$ and working up from there. It seems like I would reach every single decimal eventually and end up with a bijection with $\mathbb{N}$ , as there are only a finite number of decimals with $N$ digits. Does this proof work?","I am trying to prove that the set of finite decimals is countable. My proof seems too simple to work out - I simply list the all of the decimals with digits for all , starting with and working up from there. It seems like I would reach every single decimal eventually and end up with a bijection with , as there are only a finite number of decimals with digits. Does this proof work?",\mathbb{D} N N\geq 1 N=1 \mathbb{N} N,['elementary-set-theory']
18,"Can the distinction between membership and inclusion be used to answer the question "" how could a line be made of indivisible points""? [closed]","Can the distinction between membership and inclusion be used to answer the question "" how could a line be made of indivisible points""? [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 5 years ago . Improve this question A little dialogue aiming at explaining the question: A - What is a line ? B - A set of points that has no width, no depth, but has length, "" a line is a breadthless length"" ( Euclid, Bk1, Df2) A - What is a point? B - Something indivisible, ""that which has no part"" ( Bk1, Df1) says Euclid,  no ""extension"". A - How could a line be extended in length  if its parts have absolutely no length? For, having no part, points certainly  have no length either. B - I said a line is a set of points .  But did I say that these points were the parts of the line? (The context of this question is basic geometry. ) My question: how to caracterize the mistake made by person A? is person B right when she explains the mistake in terms of membership/ inclusion confusion? Can one clarify the loose expression ""being made of points"" by saying (1) yes a line is made of points as elements ( = members)  , but(2) it is not made of points as parts ( the parts of the line being not points, but subsets of points)?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 5 years ago . Improve this question A little dialogue aiming at explaining the question: A - What is a line ? B - A set of points that has no width, no depth, but has length, "" a line is a breadthless length"" ( Euclid, Bk1, Df2) A - What is a point? B - Something indivisible, ""that which has no part"" ( Bk1, Df1) says Euclid,  no ""extension"". A - How could a line be extended in length  if its parts have absolutely no length? For, having no part, points certainly  have no length either. B - I said a line is a set of points .  But did I say that these points were the parts of the line? (The context of this question is basic geometry. ) My question: how to caracterize the mistake made by person A? is person B right when she explains the mistake in terms of membership/ inclusion confusion? Can one clarify the loose expression ""being made of points"" by saying (1) yes a line is made of points as elements ( = members)  , but(2) it is not made of points as parts ( the parts of the line being not points, but subsets of points)?",,['geometry']
19,Set containing a set containing itself,Set containing a set containing itself,,"I have to prove that for sets $x_0,x_1,\dots,x_n$ , it is impossible that $x_0\in x_1\in\dots\in x_n\in x_0$ . I tried to prove this statement using induction. For $n=0$ , this is clear to me, it follows immediately from the axiom of regularity. However, I even failed to prove this for $n=1$ so far. I thought I should again somehow use the axiom of regularity, as it appears to me that this is the only axiom with which one can disprove the existence of a set. Nevertheless, I am stuck, and I would appreciate any help in clearing things up.","I have to prove that for sets , it is impossible that . I tried to prove this statement using induction. For , this is clear to me, it follows immediately from the axiom of regularity. However, I even failed to prove this for so far. I thought I should again somehow use the axiom of regularity, as it appears to me that this is the only axiom with which one can disprove the existence of a set. Nevertheless, I am stuck, and I would appreciate any help in clearing things up.","x_0,x_1,\dots,x_n x_0\in x_1\in\dots\in x_n\in x_0 n=0 n=1",['elementary-set-theory']
20,Constructing posets from collections of posets,Constructing posets from collections of posets,,"Say you have a bunch of posets consisting of partial orders over the set of, let's just say, letters in the English language (a, b, c, etc). Say you collect a bunch of these posets as objects of a discrete category, let's name it $\textbf{Conf}$ for ""confused,"" because I am. I'm wondering if it is possible to talk about constructing a particular poset over the set of English letters from the objects in this category. Suppose for example that you have 26 posets in the category labeled A, B, C, etc., and luckily $a$ is the ""greatest"" object in $A$ , $b$ is the ""second greatest"" object in $B$ , etc. It seems like it should be perfectly logical to say that you can draw a functor from this category to an individual poset that consists of $ z \leq ... \leq b \leq a$ . It would map $A$ to $a$ and so on, and the empty set of morphisms from $B$ to $A$ to the singleton set of morphisms from $b$ to $a$ and so on. In fact, I don't think you even need to say anything about $a$ being greatest in $A$ , $b$ being second greatest in $B$ , etc., nor about having 26 posets. You can just map however you like, really. But say you have a different rule. Say that $a$ is the terminal object for all objects of $\textbf{Conf}$ . Is it possible to have a functor that says ""if an element is a terminal object for all the posets in $\textbf{Conf}$ , then make it the terminal element in the poset that is the target of the functor from $\textbf{Conf}$ ""? On the one hand, doing so seems extremely intuitive. On the other hand, I don't understand how to do so. The objects of $\textbf{Conf}$ ""are"" posets, but only in the same way that, say, the elements of the set of mountain ranges ""are"" mountain ranges. It is not like the set of mountain ranges would be incredibly heavy to lift. Elements of sets don't have terminal objects, that's something a category itself has, so how can the posets in $\textbf{Conf}$ have terminal objects, and therefore, how can such a rule be constructed? I feel like this should be incredibly obvious, but I can't figure it out. Basically, I feel like collecting the posets into $\textbf{Conf}$ ""deletes"" the morphisms within each individual poset, and so I don't understand conceptually how to refer back to them. I thought that I had thought of a way to do it, which is to stick all the morphisms of each of the posets in $\textbf{Conf}$ into a single category with the letters of the English alphabet as objects and a morphism from $a$ to $b$ for each instance that a poset in $\textbf{Conf}$ has a morphism from $a$ to $b$ , and a morphism from $b$ to $a$ for each instance that a poset in $\textbf{Conf}$ has a morphism from $b$ to $a$ . So this category is no longer a poset (I don't know what it's called anymore), but it doesn't ""delete"" the morphisms. Then if $a$ was terminal for every poset in $\textbf{Conf}$ , it would still be terminal in this new category. But I don't believe that you can in general construct a poset from this new category since if it's true in this new category that $a \to b$ and $b \to a$ , then you cannot establish a functor from this new category to a poset since you will either fail to preserve composition or violate antisymmetry of the target poset. So...I guess my question is really just: how do you get a poset out of a collection of posets, and how exactly should you collect them in order to do it? And relatedly, what am I doing wrong? Here's some extra context.","Say you have a bunch of posets consisting of partial orders over the set of, let's just say, letters in the English language (a, b, c, etc). Say you collect a bunch of these posets as objects of a discrete category, let's name it for ""confused,"" because I am. I'm wondering if it is possible to talk about constructing a particular poset over the set of English letters from the objects in this category. Suppose for example that you have 26 posets in the category labeled A, B, C, etc., and luckily is the ""greatest"" object in , is the ""second greatest"" object in , etc. It seems like it should be perfectly logical to say that you can draw a functor from this category to an individual poset that consists of . It would map to and so on, and the empty set of morphisms from to to the singleton set of morphisms from to and so on. In fact, I don't think you even need to say anything about being greatest in , being second greatest in , etc., nor about having 26 posets. You can just map however you like, really. But say you have a different rule. Say that is the terminal object for all objects of . Is it possible to have a functor that says ""if an element is a terminal object for all the posets in , then make it the terminal element in the poset that is the target of the functor from ""? On the one hand, doing so seems extremely intuitive. On the other hand, I don't understand how to do so. The objects of ""are"" posets, but only in the same way that, say, the elements of the set of mountain ranges ""are"" mountain ranges. It is not like the set of mountain ranges would be incredibly heavy to lift. Elements of sets don't have terminal objects, that's something a category itself has, so how can the posets in have terminal objects, and therefore, how can such a rule be constructed? I feel like this should be incredibly obvious, but I can't figure it out. Basically, I feel like collecting the posets into ""deletes"" the morphisms within each individual poset, and so I don't understand conceptually how to refer back to them. I thought that I had thought of a way to do it, which is to stick all the morphisms of each of the posets in into a single category with the letters of the English alphabet as objects and a morphism from to for each instance that a poset in has a morphism from to , and a morphism from to for each instance that a poset in has a morphism from to . So this category is no longer a poset (I don't know what it's called anymore), but it doesn't ""delete"" the morphisms. Then if was terminal for every poset in , it would still be terminal in this new category. But I don't believe that you can in general construct a poset from this new category since if it's true in this new category that and , then you cannot establish a functor from this new category to a poset since you will either fail to preserve composition or violate antisymmetry of the target poset. So...I guess my question is really just: how do you get a poset out of a collection of posets, and how exactly should you collect them in order to do it? And relatedly, what am I doing wrong? Here's some extra context.",\textbf{Conf} a A b B  z \leq ... \leq b \leq a A a B A b a a A b B a \textbf{Conf} \textbf{Conf} \textbf{Conf} \textbf{Conf} \textbf{Conf} \textbf{Conf} \textbf{Conf} a b \textbf{Conf} a b b a \textbf{Conf} b a a \textbf{Conf} a \to b b \to a,"['elementary-set-theory', 'category-theory']"
21,Is there a standard formulation of a 'null element'?,Is there a standard formulation of a 'null element'?,,"I want to define the set $F$ of functions on a set $X$ that can be generated from a finite number of selected operations defined on $X$ (the set from which these operations are selected need not be finite, but each function needs to expressible using a finite number of operations). At first I had considered a subset of the infinite product... $$F(X)\subseteq X^X=\prod_{x\in X}X$$ ...for which $f\in F(X)$ is a function (whose value at $x$ is $f(x)=f_x$ ) but then I realized that said product does not include obvious cases where a function is undefined at a point in its domain, for example $f(0)$ where $f:\mathbb{C}\to\mathbb{C};\ f(z)=1/z$ . The easiest solution I could think of was to define a 'nonelement' $\bot$ so that if $f:X\to X$ , then $f(x)\ \text{undefined}\iff f(x)=\bot$ . This is basically saying that the set of solutions $y$ to the equation $y=f(x)$ is empty. For example, I might have $f:\mathbb{C}\to\mathbb{C};\ f(z)=1/z\implies f(0)=\bot$ . Then I can modify the product accordingly to include functions which are undefined at some point... $$F(X)\subseteq\prod_{x\in X}X\cup\{\bot\}$$ Obviously, there are some problems with having such a 'null element' a few of which were addressed in this question , but none of them are too daunting on their own. The real difficulty is getting various definitions to work together. I can see a lot of use for a null element, so imagine someone has already done this. Is there an accepted convention for such an element? are there any sources which look at it in detail? Abstract/universal algebra tag is for context - If $(X,S_{op})$ is the algebraic structure consisting of the set $X$ and the collection of operations $S_{op}$ , then $F(X)$ as described above is the equivalent of the class of elementary functions in $(X,S_{op})$ .","I want to define the set of functions on a set that can be generated from a finite number of selected operations defined on (the set from which these operations are selected need not be finite, but each function needs to expressible using a finite number of operations). At first I had considered a subset of the infinite product... ...for which is a function (whose value at is ) but then I realized that said product does not include obvious cases where a function is undefined at a point in its domain, for example where . The easiest solution I could think of was to define a 'nonelement' so that if , then . This is basically saying that the set of solutions to the equation is empty. For example, I might have . Then I can modify the product accordingly to include functions which are undefined at some point... Obviously, there are some problems with having such a 'null element' a few of which were addressed in this question , but none of them are too daunting on their own. The real difficulty is getting various definitions to work together. I can see a lot of use for a null element, so imagine someone has already done this. Is there an accepted convention for such an element? are there any sources which look at it in detail? Abstract/universal algebra tag is for context - If is the algebraic structure consisting of the set and the collection of operations , then as described above is the equivalent of the class of elementary functions in .","F X X F(X)\subseteq X^X=\prod_{x\in X}X f\in F(X) x f(x)=f_x f(0) f:\mathbb{C}\to\mathbb{C};\ f(z)=1/z \bot f:X\to X f(x)\ \text{undefined}\iff f(x)=\bot y y=f(x) f:\mathbb{C}\to\mathbb{C};\ f(z)=1/z\implies f(0)=\bot F(X)\subseteq\prod_{x\in X}X\cup\{\bot\} (X,S_{op}) X S_{op} F(X) (X,S_{op})","['abstract-algebra', 'elementary-set-theory', 'reference-request', 'universal-algebra']"
22,"Let $S=\{q \in \Bbb Q :0<q<1\}$. We can define a number $b \in (0,1)$ that is not in the list of elements of S. Is $b$ rational?",Let . We can define a number  that is not in the list of elements of S. Is  rational?,"S=\{q \in \Bbb Q :0<q<1\} b \in (0,1) b","Let $S=\{q \in \Bbb Q :0\lt q \lt 1\}$ .  We know $S$ is countable, and thus can enumerate its elements: $q_1, q_2, q_3,\dots$ Since each of these rational numbers has an infinite decimal expansion $q_i=0.q_{i1}q_{i2}q_{i3}\dots$ , one can define a real number $b \in (0,1)$ that is not in the list as in Cantor's diagonal argument.  Is $b$ a rational number? My immediate thought is just no, as it is not in the list of all possible rational numbers in $(0,1)$ , but I've nothing but intuition here.","Let .  We know is countable, and thus can enumerate its elements: Since each of these rational numbers has an infinite decimal expansion , one can define a real number that is not in the list as in Cantor's diagonal argument.  Is a rational number? My immediate thought is just no, as it is not in the list of all possible rational numbers in , but I've nothing but intuition here.","S=\{q \in \Bbb Q :0\lt q \lt 1\} S q_1, q_2, q_3,\dots q_i=0.q_{i1}q_{i2}q_{i3}\dots b \in (0,1) b (0,1)",['elementary-set-theory']
23,Increasing limit of sets is in union of families,Increasing limit of sets is in union of families,,"Let $A_1 \subseteq A_2 \subseteq \cdots$ be a sequence of sets such that $A_i \in \cal{F}_i$ , where $\cal{F}_i \supseteq \cal{F}_{i-1} \forall i$ Let $A = \bigcup_{i \in \mathbb{N}} {A_i}, \cal{F} = \bigcup_{i \in \mathbb{N}} {\cal{F}_i}$ How can I say that $A \in \cal{F}$ ?  This seems true, but I'm not able to get the argument. Edit: Not true.  See comment below.","Let be a sequence of sets such that , where Let How can I say that ?  This seems true, but I'm not able to get the argument. Edit: Not true.  See comment below.","A_1 \subseteq A_2 \subseteq \cdots A_i \in \cal{F}_i \cal{F}_i \supseteq \cal{F}_{i-1} \forall i A = \bigcup_{i \in \mathbb{N}} {A_i}, \cal{F} = \bigcup_{i \in \mathbb{N}} {\cal{F}_i} A \in \cal{F}",['elementary-set-theory']
24,Can P vs NP be written as a statement in set theory?,Can P vs NP be written as a statement in set theory?,,"For the problem of $P\neq NP$ it would be useful to have a precise mathematical statement of the question in some logic like set theory or some generalisation of it. And then we could ask given the axioms of this logic is the statement true of false. So far I've only seen statements that use English words like, ""runs for n steps"" and so on. Is there a precise statement in some logic that can encode even the question of $N\neq NP$ ? (Or is that part of the problem?)","For the problem of it would be useful to have a precise mathematical statement of the question in some logic like set theory or some generalisation of it. And then we could ask given the axioms of this logic is the statement true of false. So far I've only seen statements that use English words like, ""runs for n steps"" and so on. Is there a precise statement in some logic that can encode even the question of ? (Or is that part of the problem?)",P\neq NP N\neq NP,"['elementary-set-theory', 'logic']"
25,Are there any simple and interesting conclusions from the Collatz Conjecture?,Are there any simple and interesting conclusions from the Collatz Conjecture?,,"The Collatz Conjecture here is the original conjecture. For example, for which $n$ 's we have $L(n)=L(n+1)$ , where $L(n)$ is the steps needed to reach the integer 1 for the first time? I have examined the $n$ 's from 1 to 100, and have found quite a number of them, but I can hardly find any pattern. The only verified form is $$ n=8k+4, where\ k = 0, 1, 2, ... $$ Of course, numbers of the form $$ n=16k+4,\\ n=16k+12,\\ n=32k+20\\ ... $$ are some other forms, but they all can be treated as a special form of $n=8k+4$ . So are there any other forms that don't exceed 100 and satisfy this property? To be exact, for the pattern $n=8k+4$ , it requires only three steps of computation to show that $L(n)=L(n+1)$ since they both reach the same number. So I guess there's an interesting problem: given any positive integer $m$ , for what positive constant integers $a, b$ , integers $ak+b$ and $ak+b+1(k = 0, 1, 2, 3,...)$ will reach the same integer after at most $m$ steps? Also, besides the question on consecutive numbers, are there any other interesting conclusions relevant to the Collatz conjecture that can be easily verified? Thank you!","The Collatz Conjecture here is the original conjecture. For example, for which 's we have , where is the steps needed to reach the integer 1 for the first time? I have examined the 's from 1 to 100, and have found quite a number of them, but I can hardly find any pattern. The only verified form is Of course, numbers of the form are some other forms, but they all can be treated as a special form of . So are there any other forms that don't exceed 100 and satisfy this property? To be exact, for the pattern , it requires only three steps of computation to show that since they both reach the same number. So I guess there's an interesting problem: given any positive integer , for what positive constant integers , integers and will reach the same integer after at most steps? Also, besides the question on consecutive numbers, are there any other interesting conclusions relevant to the Collatz conjecture that can be easily verified? Thank you!","n L(n)=L(n+1) L(n) n 
n=8k+4, where\ k = 0, 1, 2, ...
 
n=16k+4,\\
n=16k+12,\\
n=32k+20\\
...
 n=8k+4 n=8k+4 L(n)=L(n+1) m a, b ak+b ak+b+1(k = 0, 1, 2, 3,...) m","['number-theory', 'elementary-set-theory']"
26,Prove the existence of countable unions,Prove the existence of countable unions,,"I recently picked up the elementary set theory and I have reached the concept of sequences. The text then asks to prove the existence of the the set of all finite sequences of elements of a set , i.e., for any set $A$ , the set, $$\bigcup_{n\in \mathbb N}A^n$$ exists. Further, if this does exist, I suspect that countable union of existing set also exist. Can anyone prove this? I tried to prove that there is such a set $S\in \mathbb N$ that $\{A^n | n \in S\}$ exists, and $0 \in S$ , $n \in S$ implies $n+1 \in S$ , so that together with the axiom of union the prove is complete. But I failed to construct such a set. BTW, the farthest axiom I have reached is the axiom of infinity that basically grants the existence of inductive set. So it would be helpful if a proof given is based on that and anything before (axiom of union, power set, schema of comprehension, pair, existence and extensionality).","I recently picked up the elementary set theory and I have reached the concept of sequences. The text then asks to prove the existence of the the set of all finite sequences of elements of a set , i.e., for any set , the set, exists. Further, if this does exist, I suspect that countable union of existing set also exist. Can anyone prove this? I tried to prove that there is such a set that exists, and , implies , so that together with the axiom of union the prove is complete. But I failed to construct such a set. BTW, the farthest axiom I have reached is the axiom of infinity that basically grants the existence of inductive set. So it would be helpful if a proof given is based on that and anything before (axiom of union, power set, schema of comprehension, pair, existence and extensionality).",A \bigcup_{n\in \mathbb N}A^n S\in \mathbb N \{A^n | n \in S\} 0 \in S n \in S n+1 \in S,['elementary-set-theory']
27,"Prove if $F\in\mathcal{A}$, then we have $\bigcap\mathcal{A}\subseteq F \subseteq \bigcup\mathcal{A}$","Prove if , then we have",F\in\mathcal{A} \bigcap\mathcal{A}\subseteq F \subseteq \bigcup\mathcal{A},"Prove that if $F\in\mathcal{A}$ , then we have $$\bigcap\mathcal{A}\subseteq F \subseteq \bigcup\mathcal{A}$$ . Note: $\bigcap\mathcal{A}=\bigcap_{U\in\mathcal{A}}U$ and $\bigcup\mathcal{A}=\bigcup_{U\in\mathcal{A}}U$ . My proof. Let $F\in\mathcal{A}.$ $(\subseteq)$ . Let $x\in\bigcap\mathcal{A}=\bigcap_{U\in\mathcal{A}}U$ . It means that $x\in U$ for all $U\in\mathcal{A}$ , so $x\in F$ because $F\in\mathcal{A}$ . Hence $$\bigcap\mathcal{A}\subseteq F.$$ $(\supseteq).$ $x\in\bigcup U$ iff there is a some $U\in \mathcal{A}$ such that $x\in A$ . But $F$ is an exactly such an $U$ . Can you check my proof? Thankss...","Prove that if , then we have . Note: and . My proof. Let . Let . It means that for all , so because . Hence iff there is a some such that . But is an exactly such an . Can you check my proof? Thankss...",F\in\mathcal{A} \bigcap\mathcal{A}\subseteq F \subseteq \bigcup\mathcal{A} \bigcap\mathcal{A}=\bigcap_{U\in\mathcal{A}}U \bigcup\mathcal{A}=\bigcup_{U\in\mathcal{A}}U F\in\mathcal{A}. (\subseteq) x\in\bigcap\mathcal{A}=\bigcap_{U\in\mathcal{A}}U x\in U U\in\mathcal{A} x\in F F\in\mathcal{A} \bigcap\mathcal{A}\subseteq F. (\supseteq). x\in\bigcup U U\in \mathcal{A} x\in A F U,['proof-verification']
28,Closure of $AB$,Closure of,AB,"I'm trying to understand what the closure of $AB$ looks likes... $AB = \{ab: a \in A, b\in B\}$ So I know the closure of $AB = AB \cup (AB)'  = \{ab: a \in A, b\in B\}\cup\{ab: a \in A', b\in B'\} $ . But is this equal to $\{ab: a \in A\cup A', b\in B\cup B'\}$ ?  If yes, is this my properties of sets or just because of the closure?","I'm trying to understand what the closure of looks likes... So I know the closure of . But is this equal to ?  If yes, is this my properties of sets or just because of the closure?","AB AB = \{ab: a \in A, b\in B\} AB = AB \cup (AB)'  = \{ab: a \in A, b\in B\}\cup\{ab: a \in A', b\in B'\}  \{ab: a \in A\cup A', b\in B\cup B'\}","['analysis', 'elementary-set-theory', 'topological-groups']"
29,Show Three Sets are Equal,Show Three Sets are Equal,,"Say I have three sets $S_1, S_2, S_3$ , and I want to show that they are equal. Is it enough to show that $S_1 \subset S_2$ , $S_2 \subset S_3$ , and $S_3 \subset S_1$ ? I think yes: (1) If $S_1 \subset S_2$ and $S_2 \subset S_3$ , then $S_1 \subset S_3$ . This result, together with $S_3 \subset S_1$ , implies that $S_1 = S_3$ . (2) If, $S_1 = S_3$ and $S_1 \subset S_2$ , then $S_3 \subset S_2$ . This result, with $S_2 \subset S_3$ shows that $S_2 = S_3$ . (3) If $S_1 = S_3$ and $S_2 = S_3$ , then $S_1 = S_2$ . So I think yes, but I'm planning to use this idea to prove something else, and I don't want to waste my time on a faulty premise! Thanks.","Say I have three sets , and I want to show that they are equal. Is it enough to show that , , and ? I think yes: (1) If and , then . This result, together with , implies that . (2) If, and , then . This result, with shows that . (3) If and , then . So I think yes, but I'm planning to use this idea to prove something else, and I don't want to waste my time on a faulty premise! Thanks.","S_1, S_2, S_3 S_1 \subset S_2 S_2 \subset S_3 S_3 \subset S_1 S_1 \subset S_2 S_2 \subset S_3 S_1 \subset S_3 S_3 \subset S_1 S_1 = S_3 S_1 = S_3 S_1 \subset S_2 S_3 \subset S_2 S_2 \subset S_3 S_2 = S_3 S_1 = S_3 S_2 = S_3 S_1 = S_2","['elementary-set-theory', 'proof-writing']"
30,In the set $(\mathbb N^{+})^{\mathbb N}$ we have partially ordered set,In the set  we have partially ordered set,(\mathbb N^{+})^{\mathbb N},"In the set $(\mathbb N^{+})^{\mathbb N}$ we have partially ordered set: $$f \le g \Leftrightarrow (\forall n \in \mathbb N) f(n)|g(n).$$ (a) Whether the partially ordered set $\left\langle (\mathbb N^{+})^{\mathbb N}, \le\right\rangle $ has the smallest element? (b) Let $A=\left\{ f \in (\mathbb N^{+})^{\mathbb N}: (\forall n \in \mathbb N) f(n) \ge 2\right\} $ . Prove that set of all minimal elements of $A$ is infinite. (c) Let $f_{1}: \mathbb N \rightarrow \mathbb N^{+}$ where $f_{1}(n)=n+1$ and $f_{2}: \mathbb N \rightarrow \mathbb N^{+}$ is a function which is constantly equal to $2$ for every $n \in \mathbb N$ . Find supremum $\left\{ f_{1}, f_{2} \right\} $ in the partialy ordered set $\left\langle (\mathbb N^{+})^{\mathbb N}, \le\right\rangle $ . My solution: (a) I think the answer is $0$ because if $f(n)=g(n)$ then remainder of the division $f(n)$ by $g(n)$ is $0$ . However I don't know how to prove it. Moreover I don't have idea how to do other tasks: (b) and (c). Can you help me and talk me what to look for to learn to do this type of task?",In the set we have partially ordered set: (a) Whether the partially ordered set has the smallest element? (b) Let . Prove that set of all minimal elements of is infinite. (c) Let where and is a function which is constantly equal to for every . Find supremum in the partialy ordered set . My solution: (a) I think the answer is because if then remainder of the division by is . However I don't know how to prove it. Moreover I don't have idea how to do other tasks: (b) and (c). Can you help me and talk me what to look for to learn to do this type of task?,"(\mathbb N^{+})^{\mathbb N} f \le g \Leftrightarrow (\forall n \in \mathbb N) f(n)|g(n). \left\langle (\mathbb N^{+})^{\mathbb N}, \le\right\rangle  A=\left\{ f \in (\mathbb N^{+})^{\mathbb N}: (\forall n \in \mathbb N) f(n) \ge 2\right\}  A f_{1}: \mathbb N \rightarrow \mathbb N^{+} f_{1}(n)=n+1 f_{2}: \mathbb N \rightarrow \mathbb N^{+} 2 n \in \mathbb N \left\{ f_{1}, f_{2} \right\}  \left\langle (\mathbb N^{+})^{\mathbb N}, \le\right\rangle  0 f(n)=g(n) f(n) g(n) 0","['elementary-set-theory', 'order-theory']"
31,"Proof verification- $ \sigma $ - Algebra, Algebra, Ring","Proof verification-  - Algebra, Algebra, Ring", \sigma ,"I want to prove following  for a set $ X \neq \emptyset $ : $ M \subset P(X) $ , where $ P(X) $ is the power set. 1) Any Ring is an Algebra 2) Any Algebra is a Ring 3) Any Ring is a $ \sigma $ -Algebra 4) Any Algebra is a $ \sigma $ - Algebra 5) Any $ \sigma $ - Algebra is an Algebra For a set $ X \neq \emptyset $ , $M$ is a) A Ring if $ \emptyset \in M$ $ A,B \in M \rightarrow A \cup B \in M $ $ A,B \in M \rightarrow B \backslash A \in M $ b) An Algebra, if $ M$ Ring , and $ X \in M $ c) A $ \sigma $ -Algebra if $ X \in M $ $ A \in M \rightarrow X \backslash A \in M $ $ (A_i)_{i \in \mathbb{N}} \in M  \rightarrow \cup_{i=0}^{ \infty} A_i \in M $ for 1) For $ A \subset X $ is M:={ \emptyset   , A} a Ring, but for $ A \neq X$ not an Algebra. 2) let be $ A,B \in M $ $ A \backslash  B =  ( A^c \cup B )^c \in M $ So M is also a ring. 3) I guess I can use the same example as for 1)? 4) let be $ X= \mathbb{N} , M:= \{ A \subset X : A $ or $ A^c $ finite $\}$ is this a right example for an Alegbra , which is not a s.Algeba? 5) $A,B \in M $ $ X= X \backslash \emptyset \in M $ $ A\backslash B = A \cap B^c  = ( A^c \cup B)^c \in M $ any union you can discribe as : $ A \cup B = A \cup B \cup \emptyset \cup ...\emptyset \in M $ so any s. Algebra is also an Algebra. are my arguments correct and formally right? any adjustments? Appreciate any of your help !","I want to prove following  for a set : , where is the power set. 1) Any Ring is an Algebra 2) Any Algebra is a Ring 3) Any Ring is a -Algebra 4) Any Algebra is a - Algebra 5) Any - Algebra is an Algebra For a set , is a) A Ring if b) An Algebra, if Ring , and c) A -Algebra if for 1) For is M:={ \emptyset   , A} a Ring, but for not an Algebra. 2) let be So M is also a ring. 3) I guess I can use the same example as for 1)? 4) let be or finite is this a right example for an Alegbra , which is not a s.Algeba? 5) any union you can discribe as : so any s. Algebra is also an Algebra. are my arguments correct and formally right? any adjustments? Appreciate any of your help !"," X \neq \emptyset   M \subset P(X)   P(X)   \sigma   \sigma   \sigma   X \neq \emptyset  M  \emptyset \in M  A,B \in M \rightarrow A \cup B \in M   A,B \in M \rightarrow B \backslash A \in M   M  X \in M   \sigma   X \in M   A \in M \rightarrow X \backslash A \in M   (A_i)_{i \in \mathbb{N}} \in M  \rightarrow \cup_{i=0}^{ \infty} A_i \in M   A \subset X   A \neq X  A,B \in M   A \backslash  B =  ( A^c \cup B )^c \in M   X= \mathbb{N} , M:= \{ A \subset X : A   A^c  \} A,B \in M   X= X \backslash \emptyset \in M   A\backslash B = A \cap B^c  = ( A^c \cup B)^c \in M   A \cup B = A \cup B \cup \emptyset \cup ...\emptyset \in M ","['real-analysis', 'measure-theory', 'proof-verification', 'elementary-set-theory']"
32,Proof verification for the equivalence of two sets.,Proof verification for the equivalence of two sets.,,"I have constructed two identical draft proofs for the following question using implications and words. Can you please verify whether they are logically correct. Should I have used De Morgan's Laws? Exercise: Suppose that $C,D$ are subsets of a set $X$ . Prove that $$(X\setminus C){\,}\cap{\,}D =D\setminus C.$$ Proof 1: Suppose that $x\in{(X\setminus C){\,}\cap{\,}D}$ . Then $x\in{(X\setminus C)}$ and $x\in{D}$ . Then ( $x\in{X}$ and $x\notin{C}$ ) and $x\in{D}$ . Then ( $x\in{X}$ and $x\in{D}$ ) and ( $x\in{D}$ and $x\notin {C}$ ). Then $x\in(X \cap D) \cap (D \setminus C)$ . Thus, $x\in(D \setminus C)$ . So, $(X \setminus C) {\,} \cap D \subseteq (D \setminus C)$ . Conversely, suppose that $x\in (D\setminus C)$ . Then $(x\in{D}$ and $x\notin{C})$ . Then $(x\in X$ and $x\in{D}$ ) and $x\notin{C}$ . Then $(x\in{X}$ and $x\notin{C})$ and $x\in{D}$ . Thus $x\in(X\setminus {C})\cap{D}$ . So, $(D\setminus{C}) \subseteq{(X\setminus{C}})\cap{D}$ . Since $(X \setminus C) {\,} \cap D \subseteq (D \setminus C)$ and $(D\setminus{C}) \subseteq{(X\setminus{C}})\cap{D}$ , we have that $(X \setminus C) {\,} \cap D = (D \setminus C)\\$ . Proof 2: Suppose that $x\in{(X\setminus C){\,}\cap{\,}D}$ . Then, \begin{align} &\implies x\in{(X\setminus C)}{\,}{\,}\text{and}{\,}D \\ &\implies(x\in{X} {\,}\text{and} {\,}x\notin{C}) {\,}\text{and}{\,} x\in{D} \\ &\implies (x\in{X} {\,}\text{and}{\,} x\in{D}) {\,}\text{and} {\,}(x\in{D} {\,}\text{and}{\,} x\notin {C})\\ &\implies x\in(X \cap D) \cap (D \setminus C)\\ &\implies  x\in(D \setminus C).\\ \\ \text{Thus}, (X \setminus C) {\,} \cap D \subseteq (D \setminus C).\\ \\ \end{align} Conversely, suppose $x\in (D\setminus C)$ . Then, \begin{align} &\implies (x\in{D} {\,}\text{and}{\,} x\notin{C}) \\ &\implies (x\in X {\,}\text{and}{\,} x\in{D}){\,}\text{and}{\,} x\notin{C} \\ &\implies (x\in{X}{\,}\text{and}{\,} x\notin{C}){\,}\text{and}{\,} x\in{D} \\ &\implies x\in(X\setminus {C})\cap{D}. \\ \\ \text{Thus,}{\,}(D\setminus{C}) \subseteq{(X\setminus{C}})\cap{D}. \end{align} Since $(X \setminus C) {\,} \cap D \subseteq (D \setminus C)$ and $(D\setminus{C}) \subseteq{(X\setminus{C}})\cap{D}$ , we have that $(X \setminus C) {\,} \cap D = (D \setminus C)$ .","I have constructed two identical draft proofs for the following question using implications and words. Can you please verify whether they are logically correct. Should I have used De Morgan's Laws? Exercise: Suppose that are subsets of a set . Prove that Proof 1: Suppose that . Then and . Then ( and ) and . Then ( and ) and ( and ). Then . Thus, . So, . Conversely, suppose that . Then and . Then and ) and . Then and and . Thus . So, . Since and , we have that . Proof 2: Suppose that . Then, Conversely, suppose . Then, Since and , we have that .","C,D X (X\setminus C){\,}\cap{\,}D =D\setminus C. x\in{(X\setminus C){\,}\cap{\,}D} x\in{(X\setminus C)} x\in{D} x\in{X} x\notin{C} x\in{D} x\in{X} x\in{D} x\in{D} x\notin {C} x\in(X \cap D) \cap (D \setminus C) x\in(D \setminus C) (X \setminus C) {\,} \cap D \subseteq (D \setminus C) x\in (D\setminus C) (x\in{D} x\notin{C}) (x\in X x\in{D} x\notin{C} (x\in{X} x\notin{C}) x\in{D} x\in(X\setminus {C})\cap{D} (D\setminus{C}) \subseteq{(X\setminus{C}})\cap{D} (X \setminus C) {\,} \cap D \subseteq (D \setminus C) (D\setminus{C}) \subseteq{(X\setminus{C}})\cap{D} (X \setminus C) {\,} \cap D = (D \setminus C)\\ x\in{(X\setminus C){\,}\cap{\,}D} \begin{align}
&\implies x\in{(X\setminus C)}{\,}{\,}\text{and}{\,}D \\
&\implies(x\in{X} {\,}\text{and} {\,}x\notin{C}) {\,}\text{and}{\,} x\in{D} \\
&\implies (x\in{X} {\,}\text{and}{\,} x\in{D}) {\,}\text{and} {\,}(x\in{D} {\,}\text{and}{\,} x\notin {C})\\
&\implies x\in(X \cap D) \cap (D \setminus C)\\
&\implies  x\in(D \setminus C).\\ \\
\text{Thus}, (X \setminus C) {\,} \cap D \subseteq (D \setminus C).\\ \\
\end{align} x\in (D\setminus C) \begin{align}
&\implies (x\in{D} {\,}\text{and}{\,} x\notin{C}) \\
&\implies (x\in X {\,}\text{and}{\,} x\in{D}){\,}\text{and}{\,} x\notin{C} \\
&\implies (x\in{X}{\,}\text{and}{\,} x\notin{C}){\,}\text{and}{\,} x\in{D} \\
&\implies x\in(X\setminus {C})\cap{D}. \\ \\
\text{Thus,}{\,}(D\setminus{C}) \subseteq{(X\setminus{C}})\cap{D}.
\end{align} (X \setminus C) {\,} \cap D \subseteq (D \setminus C) (D\setminus{C}) \subseteq{(X\setminus{C}})\cap{D} (X \setminus C) {\,} \cap D = (D \setminus C)",['proof-verification']
33,Notation for using a relation as a function from an element to set?,Notation for using a relation as a function from an element to set?,,"Let $R \subseteq X \times Y$ Is there a commonly used term/notation for the functions $f:X\rightarrow \mathcal{P}(Y)$ and $g:Y\rightarrow \mathcal{P}(X)$ defined as follows?: $$f(x) = \{ y \mid (x, y) \in R\}$$ $$g(y) = \{ x \mid (x, y) \in R\}$$ Since these values are a very elementary part of the structure of a relation, I'd think that this shows up commonly and might have a name. If there is notation for $f$ then perhaps $g$ doesn't need different notation as $g$ is just $f$ on $R^{-1}$","Let Is there a commonly used term/notation for the functions and defined as follows?: Since these values are a very elementary part of the structure of a relation, I'd think that this shows up commonly and might have a name. If there is notation for then perhaps doesn't need different notation as is just on","R \subseteq X \times Y f:X\rightarrow \mathcal{P}(Y) g:Y\rightarrow \mathcal{P}(X) f(x) = \{ y \mid (x, y) \in R\} g(y) = \{ x \mid (x, y) \in R\} f g g f R^{-1}","['elementary-set-theory', 'notation', 'terminology', 'relations']"
34,Clarification on set definitions from How to Prove it (Velleman) Chapter 2.3,Clarification on set definitions from How to Prove it (Velleman) Chapter 2.3,,"I am reading the first two paragraphs of Chapter 2.3 in How to Prove It (Velleman) and I am unclear about why $x \in \{n^2 | n \in \Bbb{N}\}$ is the same as $\exists n \in \Bbb{N}(x = n^2)$ I will lay out Velleman's explanation and my understanding of it, I would love some feedback on if I'm thinking about this correctly. For the reader, up until this point in the book, we know two ways to define sets. list elements in brackets $$\{1, 2, 3, 4\}$$ use elementhood notation $$\{x \ |\ P(x)\}$$ Velleman suggests that it is common to replace the $x$ in front of the vertical line with a more complex expression. He uses the example of $S$ , the set of perfect squares $$S = \{n^2\ |\ n \in \Bbb{N}\}\tag{1}$$ He claims that (1) can be written as $$S = \{x \ |\ \exists n \in \Bbb{N}(x=n^2)\}\tag{2}$$ Thus $$S = \{n^2\ |\ n \in \Bbb{N}\} = \{x \ |\ \exists n \in \Bbb{N}(x=n^2)\}$$ At this point I'm still with Velleman. Replacing x before the vertical line with a more complex expression is intuitive. Putting the statement ""x is a perfect square"" into the form $\exists n \in \Bbb{N}(x=n^2)$ and defining the set S using that logical statement as an elementhood test - $S = \{x\ |\ \exists n \in \Bbb{N}(x=n^2)\}$ - makes sense ( this question is a good discussion. on eq 2 ) Velleman continues and therefore $x \in \{n^2\ |\ n \in \Bbb{N}\}$ means the same thing as $\exists n \in \Bbb{N}(x = n^2)$ I am missing the jump to this final conclusion, here are my thoughts so far. First thought Perhaps a step Velleman is taking (and assumes reader will make) is that $x \in \{n^2\ |\ n \in \Bbb{N}\}$ is the same as $x \in \{x\ |\ \exists n \in \Bbb{N}(x = n^2)\}$ . And then, using the following from Chapter 1.3, in general, the statement $y \in \{x\ |\ P(x)\}$ means the same thing as P(y)...a statement about y but not x. from this, we can see that $x \in \{x\ |\ \exists n \in \Bbb{N}(x = n^2)\}$ means the same thing as $\exists n \in \Bbb{N}(x = n^2)$ , and then arrive at the conclusion. Second thought (not entirely unrelated way of thinking about it) $\exists n \in \Bbb{N}(x = n^2)$ and $x \in \{n^2\ |\ n \in \Bbb{N}\}$ are both statements about x, where x is a free variable. These statement can be evaluated to true or false, but that will depend on the value of x that is used. They will always evaluate to the same truth/false value, therefore they mean the same thing.","I am reading the first two paragraphs of Chapter 2.3 in How to Prove It (Velleman) and I am unclear about why is the same as I will lay out Velleman's explanation and my understanding of it, I would love some feedback on if I'm thinking about this correctly. For the reader, up until this point in the book, we know two ways to define sets. list elements in brackets use elementhood notation Velleman suggests that it is common to replace the in front of the vertical line with a more complex expression. He uses the example of , the set of perfect squares He claims that (1) can be written as Thus At this point I'm still with Velleman. Replacing x before the vertical line with a more complex expression is intuitive. Putting the statement ""x is a perfect square"" into the form and defining the set S using that logical statement as an elementhood test - - makes sense ( this question is a good discussion. on eq 2 ) Velleman continues and therefore means the same thing as I am missing the jump to this final conclusion, here are my thoughts so far. First thought Perhaps a step Velleman is taking (and assumes reader will make) is that is the same as . And then, using the following from Chapter 1.3, in general, the statement means the same thing as P(y)...a statement about y but not x. from this, we can see that means the same thing as , and then arrive at the conclusion. Second thought (not entirely unrelated way of thinking about it) and are both statements about x, where x is a free variable. These statement can be evaluated to true or false, but that will depend on the value of x that is used. They will always evaluate to the same truth/false value, therefore they mean the same thing.","x \in \{n^2 | n \in \Bbb{N}\} \exists n \in \Bbb{N}(x = n^2) \{1, 2, 3, 4\} \{x \ |\ P(x)\} x S S = \{n^2\ |\ n \in \Bbb{N}\}\tag{1} S = \{x \ |\ \exists n \in \Bbb{N}(x=n^2)\}\tag{2} S = \{n^2\ |\ n \in \Bbb{N}\} = \{x \ |\ \exists n \in \Bbb{N}(x=n^2)\} \exists n \in \Bbb{N}(x=n^2) S = \{x\ |\ \exists n \in \Bbb{N}(x=n^2)\} x \in \{n^2\ |\ n \in \Bbb{N}\} \exists n \in \Bbb{N}(x = n^2) x \in \{n^2\ |\ n \in \Bbb{N}\} x \in \{x\ |\ \exists n \in \Bbb{N}(x = n^2)\} y \in \{x\ |\ P(x)\} x \in \{x\ |\ \exists n \in \Bbb{N}(x = n^2)\} \exists n \in \Bbb{N}(x = n^2) \exists n \in \Bbb{N}(x = n^2) x \in \{n^2\ |\ n \in \Bbb{N}\}","['elementary-set-theory', 'logic', 'proof-explanation', 'predicate-logic']"
35,Let A be a denumerable subset of an uncountable set X. Prove that X/A is uncountable,Let A be a denumerable subset of an uncountable set X. Prove that X/A is uncountable,,I'd like to know if my proof is correct: Assume $A$ is denumerable and and $A\subseteq X$ Assume X is uncountable (X uncountable means X is not finite and X is not denumerable) $X=(X\backslash A) \cup (X \cap A)=(X\backslash A)\cup A$ (as $A \subseteq X$ ) Therefore $X$ is uncountable $\implies (X\backslash A) \cup (X \cap A)$ uncountable. Now using the Theorem: If A and B are denumerable sets then $A\cup B$ is denumerable. The contrapositive of this statement is: If $A\cup B$ is not denumerable then A is not denumerable or B is not denumerable. Now applying the contrapositive to what we have so far $(X\backslash A) \cup A)$ uncountable(not denumerable) $\implies(X\backslash A)$ uncountable or $A$ is uncountable. (by the contrapositive of the theorem) By assumption A is denumerable and therefore countable hence X\A is uncountable as required.,I'd like to know if my proof is correct: Assume is denumerable and and Assume X is uncountable (X uncountable means X is not finite and X is not denumerable) (as ) Therefore is uncountable uncountable. Now using the Theorem: If A and B are denumerable sets then is denumerable. The contrapositive of this statement is: If is not denumerable then A is not denumerable or B is not denumerable. Now applying the contrapositive to what we have so far uncountable(not denumerable) uncountable or is uncountable. (by the contrapositive of the theorem) By assumption A is denumerable and therefore countable hence X\A is uncountable as required.,A A\subseteq X X=(X\backslash A) \cup (X \cap A)=(X\backslash A)\cup A A \subseteq X X \implies (X\backslash A) \cup (X \cap A) A\cup B A\cup B (X\backslash A) \cup A) \implies(X\backslash A) A,"['proof-verification', 'elementary-set-theory']"
36,How to Prove It - Ch2 Sec 2 Exercise 2a,How to Prove It - Ch2 Sec 2 Exercise 2a,,"Question: I am uncertain if my initial formulation of the logical form of the below statement is correct. How to Prove It (Velleman) Chapter 2, Section 2, Exercise 2a Negate these statements and then reexpress the results as equivalent positive statements. (it is implied that you put into logical form first based on worked examples in the chapter) 2(a) ""There is someone in the freshman class who doesn't have a roommate."" I have written this (prior to negation) $$\begin{equation}\begin{aligned} \exists x[F(x) \rightarrow \forall y \neg R(x,y)] \\ \\ F(x): \text{x is in the freshman class}\\ R(x, y): \text{x is roommates with y}\\ \end{aligned}\end{equation}\tag{1}$$ I thought this was the correct formulation however, I found two blogs online that formulate the phrase as follows (again, before negation) $$\begin{equation}\begin{aligned} \exists x[F(x) \wedge \neg\exists yR(x,y)] \end{aligned}\end{equation}\tag{2}$$ I checked to make sure equations (1) and (2) are not equivalent $$\begin{equation}\begin{aligned} \exists x[F(x) \rightarrow \forall y \neg R(x,y)] \qquad &\text{(1)}\\ \exists x[F(x) \rightarrow \neg \exists yR(x,y)] \qquad &\text{quantifier negation}\\ \exists x[\neg F(x) \vee \neg \exists yR(x,y)] \qquad &\text{conditional law}\\ \exists x\neg[F(x) \wedge \exists yR(x,y)] \qquad &\text{DeMorgans}\\ \neg\forall x[F(x) \wedge \exists yR(x,y)] \qquad &\text{quantifier negation}\\ \end{aligned}\end{equation}$$ I am trying to convince myself that (2) is correct, but can't see why (1) is incorrect. Is it because it's somewhat speculative (""There exists someone x, where if that person x is a freshman then for all people y, person x and person y are not roommates"") vs declarative (""There is someone who is a freshman and for all people y, that person and person y are not roommates"")?","Question: I am uncertain if my initial formulation of the logical form of the below statement is correct. How to Prove It (Velleman) Chapter 2, Section 2, Exercise 2a Negate these statements and then reexpress the results as equivalent positive statements. (it is implied that you put into logical form first based on worked examples in the chapter) 2(a) ""There is someone in the freshman class who doesn't have a roommate."" I have written this (prior to negation) I thought this was the correct formulation however, I found two blogs online that formulate the phrase as follows (again, before negation) I checked to make sure equations (1) and (2) are not equivalent I am trying to convince myself that (2) is correct, but can't see why (1) is incorrect. Is it because it's somewhat speculative (""There exists someone x, where if that person x is a freshman then for all people y, person x and person y are not roommates"") vs declarative (""There is someone who is a freshman and for all people y, that person and person y are not roommates"")?","\begin{equation}\begin{aligned}
\exists x[F(x) \rightarrow \forall y \neg R(x,y)]
\\ \\
F(x): \text{x is in the freshman class}\\
R(x, y): \text{x is roommates with y}\\
\end{aligned}\end{equation}\tag{1} \begin{equation}\begin{aligned}
\exists x[F(x) \wedge \neg\exists yR(x,y)]
\end{aligned}\end{equation}\tag{2} \begin{equation}\begin{aligned}
\exists x[F(x) \rightarrow \forall y \neg R(x,y)] \qquad &\text{(1)}\\
\exists x[F(x) \rightarrow \neg \exists yR(x,y)] \qquad &\text{quantifier negation}\\
\exists x[\neg F(x) \vee \neg \exists yR(x,y)] \qquad &\text{conditional law}\\
\exists x\neg[F(x) \wedge \exists yR(x,y)] \qquad &\text{DeMorgans}\\
\neg\forall x[F(x) \wedge \exists yR(x,y)] \qquad &\text{quantifier negation}\\
\end{aligned}\end{equation}","['elementary-set-theory', 'logic', 'proof-writing', 'quantifiers']"
37,An example of a valuation function,An example of a valuation function,,"Let $F$ be the set of all functions from $\mathbb{N}$ into $\mathbb{N}$ . For $f,g\in F$ define $\text{val}(f,g)=\begin{cases}\min\{n\in\Bbb N~:~f(n)\neq g(n)\}&\text{if}~f\neq g\\\infty&\text{if}~f=g\end{cases}$ where $\infty$ is a new symbol. Question. For $n\in\mathbb{N}$ let $s_n\in F$ be the constant function that takes the value $n$ for all variables. For $n,m\in\mathbb{N}$ find $val(s_n,s_m)$ . My answer. Assume $s_n\neq s_m$ . Note that $s_n(x)=n$ for all $x$ and $s_m(x)=m$ for all $x$ . So, what I say about $\min\{n\in\Bbb N~:~f(n)\neq g(n)\}$ ? Can you help?","Let be the set of all functions from into . For define where is a new symbol. Question. For let be the constant function that takes the value for all variables. For find . My answer. Assume . Note that for all and for all . So, what I say about ? Can you help?","F \mathbb{N} \mathbb{N} f,g\in F \text{val}(f,g)=\begin{cases}\min\{n\in\Bbb N~:~f(n)\neq g(n)\}&\text{if}~f\neq g\\\infty&\text{if}~f=g\end{cases} \infty n\in\mathbb{N} s_n\in F n n,m\in\mathbb{N} val(s_n,s_m) s_n\neq s_m s_n(x)=n x s_m(x)=m x \min\{n\in\Bbb N~:~f(n)\neq g(n)\}",[]
38,Proving that a function with two variables is bijective,Proving that a function with two variables is bijective,,"In a study of cardinality and infinity, I have to prove that the following function is a bijection (first of all that it's injective). $v : \mathbb{N} \times \mathbb{N} \to \mathbb{N}$ defined by $$v(g,b)=1/2·b^2+1/2·b·(2·g-1)+1/2·g^2-3/2·g+1$$ Can anybody help me, please?","In a study of cardinality and infinity, I have to prove that the following function is a bijection (first of all that it's injective). defined by Can anybody help me, please?","v : \mathbb{N} \times \mathbb{N} \to \mathbb{N} v(g,b)=1/2·b^2+1/2·b·(2·g-1)+1/2·g^2-3/2·g+1",['functions']
39,What is the terminology for a subset of a product of sets that is the product of its cross-sections?,What is the terminology for a subset of a product of sets that is the product of its cross-sections?,,"Let $X$ and $Y$ be non-empty sets. For every $x \in X$ , let $S_x$ be a non-empty subset of $Y$ . Define $S := \prod_{x \in X}S_x$ . $S$ is a subset of $Y^X$ . I think I once saw a name given to this kind of subset, namely one that is the product of its cross sections. Perhaps a pipe, or a tube, or a cylinder, or a cube, or a rectangle, or a prism. I can't recall. Is there a commonly accepted terminology for this kind of subset?","Let and be non-empty sets. For every , let be a non-empty subset of . Define . is a subset of . I think I once saw a name given to this kind of subset, namely one that is the product of its cross sections. Perhaps a pipe, or a tube, or a cylinder, or a cube, or a rectangle, or a prism. I can't recall. Is there a commonly accepted terminology for this kind of subset?",X Y x \in X S_x Y S := \prod_{x \in X}S_x S Y^X,"['functions', 'elementary-set-theory', 'terminology', 'infinite-product', 'cross-sections']"
40,"Suppose $\kappa$ is a cardinal, such that $2 \kappa = \kappa$. Can it be proven that $\kappa ! = 2^\kappa$ without choice?","Suppose  is a cardinal, such that . Can it be proven that  without choice?",\kappa 2 \kappa = \kappa \kappa ! = 2^\kappa,"The original question is given in an exercise. The first part of the problem is to show that if $\left|A\right| = \left|A\right| +\left|A\right|$ for some set $A$ , then there exists a partition of $A$ , with every cell in the partition having cardinality $2$ (i.e. a partition of $A$ into pairs). The second part of the problem is to show that the cardinality of the set of permutations of $A$ is $2^{\left|A\right|}$ . Using the first part of the problem, it's not hard to show that that cardinality of set of permutations of $A$ is bounded between $2^{\left|A\right|}$ and $\left|A\right|^{\left|A\right|}$ . But I couldn't find a way to proceed from here without assuming that $\left|A\right| = \left|A\right|\cdot\left|A\right|$ . Is it possible to complete the proof without choice?","The original question is given in an exercise. The first part of the problem is to show that if for some set , then there exists a partition of , with every cell in the partition having cardinality (i.e. a partition of into pairs). The second part of the problem is to show that the cardinality of the set of permutations of is . Using the first part of the problem, it's not hard to show that that cardinality of set of permutations of is bounded between and . But I couldn't find a way to proceed from here without assuming that . Is it possible to complete the proof without choice?",\left|A\right| = \left|A\right| +\left|A\right| A A 2 A A 2^{\left|A\right|} A 2^{\left|A\right|} \left|A\right|^{\left|A\right|} \left|A\right| = \left|A\right|\cdot\left|A\right|,"['elementary-set-theory', 'cardinals']"
41,Disjoint Events iff $P(A \cap B) = 0$,Disjoint Events iff,P(A \cap B) = 0,"I found for example here that: $A$ and $B$ are disjoint iff $P(A\cap B) == 0$ . I don't understand why. Take for example: $A = \{$ ""rolling a six-sided dice a 7 shows up"" $\}$ $B = \{""$ rolling a six-sided dice a 7 shows up"" $\}$ A and B are not disjoint, yet $P(A\cap B) = 0$ holds.  Where am I wrong? Edit: A better example (Thanks to Gerry Myerson): $C = \{$ ""choosing 1/2  from a uniform random distribution [0,1]"" $\}$ $D = \{""$ choosing 1/2 from a uniform random distribution [0,1]"" $\}$ C and D are not disjoint, yet $P(C\cap D) = 0$ holds.","I found for example here that: and are disjoint iff . I don't understand why. Take for example: ""rolling a six-sided dice a 7 shows up"" rolling a six-sided dice a 7 shows up"" A and B are not disjoint, yet holds.  Where am I wrong? Edit: A better example (Thanks to Gerry Myerson): ""choosing 1/2  from a uniform random distribution [0,1]"" choosing 1/2 from a uniform random distribution [0,1]"" C and D are not disjoint, yet holds.","A B P(A\cap B) == 0 A = \{ \} B = \{"" \} P(A\cap B) = 0 C = \{ \} D = \{"" \} P(C\cap D) = 0","['probability-theory', 'elementary-set-theory']"
42,Comparing enumerations on the same infinite set,Comparing enumerations on the same infinite set,,"Given two enumerations $A:S \to \mathbb{N}$ , $B:S \to \mathbb{N}$ on the same countably infinite set $S$ , are there infinitely many elements $s \in S$ with $A(s) \geq B(s)$ ? My feeling is that there must be, i.e. that it cannot be the case that all but a finite number of elements of S appear in B before A, but I can't come up with a proof to support this feeling. Am I correct? If so, could I have a hint for a proof?","Given two enumerations , on the same countably infinite set , are there infinitely many elements with ? My feeling is that there must be, i.e. that it cannot be the case that all but a finite number of elements of S appear in B before A, but I can't come up with a proof to support this feeling. Am I correct? If so, could I have a hint for a proof?",A:S \to \mathbb{N} B:S \to \mathbb{N} S s \in S A(s) \geq B(s),"['elementary-set-theory', 'order-theory']"
43,Is there an idempotent element in a finite semigroup?,Is there an idempotent element in a finite semigroup?,,"Let $(G,\cdot)$ be a non-empty finite semigroup . Is there any $a\in G$ such that: $$a^2=a$$ It seems to be true in view of theorem 2.2.1 page 97 of this book (I'm not sure).  But is there an elementary proof? Theorem 2.2.1. [R. Ellis] Let $S$ be a compact right topological semigroup. Then there exists an idempotent in it. This theorem is also known as Ellis–Numakura lemma .",Let be a non-empty finite semigroup . Is there any such that: It seems to be true in view of theorem 2.2.1 page 97 of this book (I'm not sure).  But is there an elementary proof? Theorem 2.2.1. [R. Ellis] Let be a compact right topological semigroup. Then there exists an idempotent in it. This theorem is also known as Ellis–Numakura lemma .,"(G,\cdot) a\in G a^2=a S","['abstract-algebra', 'alternative-proof']"
44,Symmetry of function and symmetry of level sets.,Symmetry of function and symmetry of level sets.,,":)  I've been thinking about the following:  if $f: \mathbb{R}^n \to [0,\infty)$ is an even and continuous function, then it's super level sets $S_t= \{x : f(x)\geq t\}$ are symmetric about the origin for every $t>0$ .  This seems to be intuitively clear, but I worry that I am wrong. Any additional opinions would be appreciated!",":)  I've been thinking about the following:  if is an even and continuous function, then it's super level sets are symmetric about the origin for every .  This seems to be intuitively clear, but I worry that I am wrong. Any additional opinions would be appreciated!","f: \mathbb{R}^n \to [0,\infty) S_t= \{x : f(x)\geq t\} t>0","['calculus', 'real-analysis', 'elementary-set-theory']"
45,"$x\in\triangle_{i=1}^{n}A_i$ if and only $x$ belongs to an odd number of $A_1,A_2,\dots,A_n$",if and only  belongs to an odd number of,"x\in\triangle_{i=1}^{n}A_i x A_1,A_2,\dots,A_n","Is the following argument correct? Proposition . Given an arbitrary $x$ and sets $A_1,A_2,\dots,A_n$ , we have $x\in A_1\triangle A_2\triangle \dots\triangle A_n$ if and only if $x$ belongs to an odd number of $A_1,A_2,\dots,A_n$ , here $A_1\triangle A_2 = (A_1\backslash A_2)\cup(A_2\backslash A_1)$ . Proof. We contruct the proof by recourse to Mathematical-Induction, the proof of the base case is trivial. We therefore proceed with the inductive step. Assume for an arbitrary $k\in\mathbf{N}$ that given any $k$ sets $A_1,A_2,\dots,A_k$ , $x\in A_1\triangle A_2\triangle \dots\triangle A_n$ if and only if $x$ belongs to an odd number of $A_1,A_2,\dots,A_n$ . Now let $X_1,X_2,\dots,X_k,X_{k+1}$ be any $k+1$ arbitrary sets. We prove both conditionals as follows $(\Rightarrow).$ Assume $x\in (\triangle_{j=1}^{k}X_j)\triangle X_{k+1}$ , then either $x\in(\triangle_{j=1}^{k}X_j)\backslash X_{k+1}$ in which case the inductive hypothesis readily implies that $x$ belongs to an odd number of of $X_1,X_2,\dots,X_k$ , the claim in question is the evident, or $x\in X_{k+1}\backslash(\triangle_{j=1}^{k}X_j)$ but then $x\not\in \triangle_{j=1}^{k}X_j$ , and thus by inductive hypothesis $x$ belongs to  an even number of $X_1,X_2,\dots,X_k$ which together with $x\in X_{k+1}$ , implies that $x$ belongs to an odd number of $X_1,X_2,\dots,X_k,X_{k+1}$ . $(\Leftarrow).$ Now assume that $x$ belongs to an odd number of $X_1,X_2,\dots,X_{k},X_{k+1}$ . Now either $x\in X_{k+1}$ , in which case $x$ belongs to an even number of $X_1,X_2,\dots,X_k$ which by inductive hypothesis implies that $x\not\in\triangle_{j=1}^{k}X_j$ and by extension $x\in X_{k+1}\backslash(\triangle_{j=1}^{k}X_j)\subseteq X_{k+1}(\triangle_{j=1}^{k+1}X_j)$ , or $x\not\in X_{k+1}$ , but then $x$ belongs to an odd number of $X_1,X_2,\dots,X_k$ and by inductive hypothesis $x\in \triangle_{j=1}^{k}X_j$ , thus $x\in (\triangle_{j=1}^{k}X_j)\backslash X_{k+1}\subseteq \triangle_{j=1}^{k+1}X_j$ . $\blacksquare$","Is the following argument correct? Proposition . Given an arbitrary and sets , we have if and only if belongs to an odd number of , here . Proof. We contruct the proof by recourse to Mathematical-Induction, the proof of the base case is trivial. We therefore proceed with the inductive step. Assume for an arbitrary that given any sets , if and only if belongs to an odd number of . Now let be any arbitrary sets. We prove both conditionals as follows Assume , then either in which case the inductive hypothesis readily implies that belongs to an odd number of of , the claim in question is the evident, or but then , and thus by inductive hypothesis belongs to  an even number of which together with , implies that belongs to an odd number of . Now assume that belongs to an odd number of . Now either , in which case belongs to an even number of which by inductive hypothesis implies that and by extension , or , but then belongs to an odd number of and by inductive hypothesis , thus .","x A_1,A_2,\dots,A_n x\in A_1\triangle A_2\triangle \dots\triangle A_n x A_1,A_2,\dots,A_n A_1\triangle A_2 = (A_1\backslash A_2)\cup(A_2\backslash A_1) k\in\mathbf{N} k A_1,A_2,\dots,A_k x\in A_1\triangle A_2\triangle \dots\triangle A_n x A_1,A_2,\dots,A_n X_1,X_2,\dots,X_k,X_{k+1} k+1 (\Rightarrow). x\in (\triangle_{j=1}^{k}X_j)\triangle X_{k+1} x\in(\triangle_{j=1}^{k}X_j)\backslash X_{k+1} x X_1,X_2,\dots,X_k x\in X_{k+1}\backslash(\triangle_{j=1}^{k}X_j) x\not\in \triangle_{j=1}^{k}X_j x X_1,X_2,\dots,X_k x\in X_{k+1} x X_1,X_2,\dots,X_k,X_{k+1} (\Leftarrow). x X_1,X_2,\dots,X_{k},X_{k+1} x\in X_{k+1} x X_1,X_2,\dots,X_k x\not\in\triangle_{j=1}^{k}X_j x\in X_{k+1}\backslash(\triangle_{j=1}^{k}X_j)\subseteq X_{k+1}(\triangle_{j=1}^{k+1}X_j) x\not\in X_{k+1} x X_1,X_2,\dots,X_k x\in \triangle_{j=1}^{k}X_j x\in (\triangle_{j=1}^{k}X_j)\backslash X_{k+1}\subseteq \triangle_{j=1}^{k+1}X_j \blacksquare","['proof-verification', 'elementary-set-theory']"
46,A proof of Transfinite Induction,A proof of Transfinite Induction,,"This is my proof of Transfinite Induction by filling the gaps in my textbook. It would be great if someone help me verify if i correctly understand what is meant by the authors! Let $P(\alpha)$ is a property defined for all ordinals $\alpha$ . Suppose that $P(\alpha)$ is true for all $\alpha<\beta$ implies $P(\beta)$ is also true. Then $P(\alpha)$ is true for all ordinals $\alpha$ . My attempt: Assume the contrary that $P(\gamma)$ is not true for some ordinal $\gamma$ . Let $F:=\{\alpha \in\gamma\cup\{\gamma\}\mid P(\alpha) \text{ is not true}\}$ . It follows that $\gamma\in F$ and thus $F\neq\emptyset$ , and that $F$ is a set of ordinals and thus is well-ordered. Let $\beta=\min F$ . Then $\alpha\notin F$ for all $\alpha<\beta$ . This implies that $P(\alpha)$ is true for all $\alpha<\beta$ . By inductive hypothesis, $P(\beta)$ is also true and thus $\beta\notin F$ . This is a contradiction. Hence $P(\alpha)$ is true for all ordinals $\alpha$ .","This is my proof of Transfinite Induction by filling the gaps in my textbook. It would be great if someone help me verify if i correctly understand what is meant by the authors! Let is a property defined for all ordinals . Suppose that is true for all implies is also true. Then is true for all ordinals . My attempt: Assume the contrary that is not true for some ordinal . Let . It follows that and thus , and that is a set of ordinals and thus is well-ordered. Let . Then for all . This implies that is true for all . By inductive hypothesis, is also true and thus . This is a contradiction. Hence is true for all ordinals .",P(\alpha) \alpha P(\alpha) \alpha<\beta P(\beta) P(\alpha) \alpha P(\gamma) \gamma F:=\{\alpha \in\gamma\cup\{\gamma\}\mid P(\alpha) \text{ is not true}\} \gamma\in F F\neq\emptyset F \beta=\min F \alpha\notin F \alpha<\beta P(\alpha) \alpha<\beta P(\beta) \beta\notin F P(\alpha) \alpha,"['elementary-set-theory', 'proof-verification', 'ordinals']"
47,"Is ""The empty set is a subset of any set"" a convention?","Is ""The empty set is a subset of any set"" a convention?",,"Recently I learned that for any set A, we have $\varnothing\subset A$. I found some explanation of why it holds. $\varnothing\subset A$ means ""for every object $x$, if $x$ belongs to the empty set, then $x$ also belongs to the set A"". This is a vacuous truth, because the antecedent ($x$ belongs to the empty set) could never be true, so the conclusion always holds ($x$ also belongs to the set A). So $\varnothing\subset A$ holds. What confused me was that, the following expression was also a vacuous truth. For every object  $x$, if $x$ belongs to the empty set, then $x$ doesn't belong to the set A. According to the definition of the vacuous truth, the conclusion ($x$ doesn't belong to the set A) holds, so $\varnothing\not\subset A$ would be true, too. Which one is correct? Or is it just a convention to let $\varnothing\subset A$?","Recently I learned that for any set A, we have $\varnothing\subset A$. I found some explanation of why it holds. $\varnothing\subset A$ means ""for every object $x$, if $x$ belongs to the empty set, then $x$ also belongs to the set A"". This is a vacuous truth, because the antecedent ($x$ belongs to the empty set) could never be true, so the conclusion always holds ($x$ also belongs to the set A). So $\varnothing\subset A$ holds. What confused me was that, the following expression was also a vacuous truth. For every object  $x$, if $x$ belongs to the empty set, then $x$ doesn't belong to the set A. According to the definition of the vacuous truth, the conclusion ($x$ doesn't belong to the set A) holds, so $\varnothing\not\subset A$ would be true, too. Which one is correct? Or is it just a convention to let $\varnothing\subset A$?",,"['elementary-set-theory', 'logic']"
48,Define an injection from $2^{\Bbb N}$ to $\Bbb R$,Define an injection from  to,2^{\Bbb N} \Bbb R,"Define an injection from $2^{\Bbb N}$ to $\Bbb R$ Does this proof look fine or contain logical gaps and flaws? Thank you for your help! We define a mapping $F:2^{\Bbb N} \to \Bbb R$ by $$\forall f\in2^{\Bbb N}: F(f)=\sum_{n=0}^{\infty}\dfrac{f(n)}{3^{n+1}}$$ It's clear that for all $f\in 2^{\Bbb N}$ : $$F(f)=\lim_{k\to\infty}\sum_{n=0}^{n=k}\dfrac{f(n)}{3^{n+1}}$$ and $$F(f)=\sum_{n=0}^{\infty}\dfrac{f(n)}{3^{n+1}}\le \sum_{n=0}^{\infty}\dfrac{1}{3^{n+1}} = \dfrac{1}{2}$$ Thus $F(f)$ is the limit of a strictly increasing and bounded above sequence of rational numbers. Hence $F(f)$ exists for all $f\in 2^{\Bbb N}$ . For $f_1,f_2\in 2^{\Bbb N}$ and $f_1\neq f_2$ , let $N=\min\{n\in\Bbb N\mid f_1(n)\neq f_2(n)\}$ . $|F(f_1)-F(f_2)|=\left |\sum_{n=0}^{\infty}\dfrac{f_1(n)}{3^{n+1}}-\sum_{n=0}^{\infty}\dfrac{f_2(n)}{3^{n+1}} \right |=\left |\sum_{n=0}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right |= \left |\sum_{n=N}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right |= \left |\dfrac{f_1(N)-f_2(N)}{3^{n+1}}+\sum_{n=N+1}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right | \ge \left |\dfrac{f_1(N)-f_2(N)}{3^{N+1}}\right |- \left |\sum_{n=N+1}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right |=\dfrac{1}{3^{N+1}}- \left |\sum_{n=N+1}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right |\ge \dfrac{1}{3^{N+1}}- \sum_{n=N+1}^{\infty}\left |\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right | \ge \dfrac{1}{3^{N+1}}- \sum_{n=N+1}^{\infty}\dfrac{1}{3^{n+1}} =\dfrac{1}{3^{N+1}}- \dfrac{1}{2.3^{N+1}}=\dfrac{1}{2.3^{N+1}}>0.$ Hence $f_1\neq f_2\implies F(f_1)\neq F(f_2)$ . Thus $F$ is injective.","Define an injection from to Does this proof look fine or contain logical gaps and flaws? Thank you for your help! We define a mapping by It's clear that for all : and Thus is the limit of a strictly increasing and bounded above sequence of rational numbers. Hence exists for all . For and , let . Hence . Thus is injective.","2^{\Bbb N} \Bbb R F:2^{\Bbb N} \to \Bbb R \forall f\in2^{\Bbb N}: F(f)=\sum_{n=0}^{\infty}\dfrac{f(n)}{3^{n+1}} f\in 2^{\Bbb N} F(f)=\lim_{k\to\infty}\sum_{n=0}^{n=k}\dfrac{f(n)}{3^{n+1}} F(f)=\sum_{n=0}^{\infty}\dfrac{f(n)}{3^{n+1}}\le \sum_{n=0}^{\infty}\dfrac{1}{3^{n+1}} = \dfrac{1}{2} F(f) F(f) f\in 2^{\Bbb N} f_1,f_2\in 2^{\Bbb N} f_1\neq f_2 N=\min\{n\in\Bbb N\mid f_1(n)\neq f_2(n)\} |F(f_1)-F(f_2)|=\left |\sum_{n=0}^{\infty}\dfrac{f_1(n)}{3^{n+1}}-\sum_{n=0}^{\infty}\dfrac{f_2(n)}{3^{n+1}} \right |=\left |\sum_{n=0}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right |= \left |\sum_{n=N}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right |= \left |\dfrac{f_1(N)-f_2(N)}{3^{n+1}}+\sum_{n=N+1}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right | \ge \left |\dfrac{f_1(N)-f_2(N)}{3^{N+1}}\right |- \left |\sum_{n=N+1}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right |=\dfrac{1}{3^{N+1}}- \left |\sum_{n=N+1}^{\infty}\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right |\ge \dfrac{1}{3^{N+1}}- \sum_{n=N+1}^{\infty}\left |\dfrac{f_1(n)-f_2(n)}{3^{n+1}} \right | \ge \dfrac{1}{3^{N+1}}- \sum_{n=N+1}^{\infty}\dfrac{1}{3^{n+1}} =\dfrac{1}{3^{N+1}}- \dfrac{1}{2.3^{N+1}}=\dfrac{1}{2.3^{N+1}}>0. f_1\neq f_2\implies F(f_1)\neq F(f_2) F","['functions', 'elementary-set-theory', 'proof-verification']"
49,"In Cantor's Diagonalization Argument, why are you allowed to assume you have a bijection from naturals to rationals but not from naturals to reals?","In Cantor's Diagonalization Argument, why are you allowed to assume you have a bijection from naturals to rationals but not from naturals to reals?",,"Firstly I'm not saying that I don't believe in Cantor's diagonalization arguments, I know that there is a deficiency in my knowledge so I'm asking this question to patch those gaps in my understanding. From my understanding of Cantor's Diagonalization argument, if you apply diagonalization to a mapping from one set of numbers to another, you will always obtain a number that is not in the mapping. So this works to prove that the reals aren't countable because if you have a mapping from the naturals to the reals then you can use diagonalization to obtain a number that's not in the mapping, and this number is a real obviously, so the mapping isn't a surjection. We're not allowed to assume that the mapping from the naturals to the reals is a bijection to begin with. But when people explain why the diagonalization process doesn't produce a rational from a mapping from naturals to rationals we are allowed to assume that the mapping is a bijection to begin with? In the questions asked here: Why does Cantor's diagonal argument not work for rational numbers? The answers says: To be precise, the procedure does not let you guarantee that the   number you obtain has a periodic decimal expansion (that is, that it   is a rational number), and so you are unable to show that the   ""diagonal number"" is a rational that was not in the original list. In   fact, if your original list is given explicitly by some bijection,   then one is able to show just as explicitly that the number you obtain   is not a rational. Why are we allowed to assume that the original list is a bijection? Is there some way to prove that the mapping from the naturals to the rationals is a bijection that is not susceptible to diagonalization? If we can assume that the mapping from naturals to rationals is an undiagonalizable bijection why can't we do the same for the mapping from naturals to reals?","Firstly I'm not saying that I don't believe in Cantor's diagonalization arguments, I know that there is a deficiency in my knowledge so I'm asking this question to patch those gaps in my understanding. From my understanding of Cantor's Diagonalization argument, if you apply diagonalization to a mapping from one set of numbers to another, you will always obtain a number that is not in the mapping. So this works to prove that the reals aren't countable because if you have a mapping from the naturals to the reals then you can use diagonalization to obtain a number that's not in the mapping, and this number is a real obviously, so the mapping isn't a surjection. We're not allowed to assume that the mapping from the naturals to the reals is a bijection to begin with. But when people explain why the diagonalization process doesn't produce a rational from a mapping from naturals to rationals we are allowed to assume that the mapping is a bijection to begin with? In the questions asked here: Why does Cantor's diagonal argument not work for rational numbers? The answers says: To be precise, the procedure does not let you guarantee that the   number you obtain has a periodic decimal expansion (that is, that it   is a rational number), and so you are unable to show that the   ""diagonal number"" is a rational that was not in the original list. In   fact, if your original list is given explicitly by some bijection,   then one is able to show just as explicitly that the number you obtain   is not a rational. Why are we allowed to assume that the original list is a bijection? Is there some way to prove that the mapping from the naturals to the rationals is a bijection that is not susceptible to diagonalization? If we can assume that the mapping from naturals to rationals is an undiagonalizable bijection why can't we do the same for the mapping from naturals to reals?",,['elementary-set-theory']
50,"Cardinality, bijections, infinite sets","Cardinality, bijections, infinite sets",,"We know that if there is a bijection from finite set $A$ to finite set $B$ , we can remove one element from both sets and still be able to form a bijection. Similarly, removing sets of equal cardinalities from finite sets still allows us to form bijections. But this result does not hold for infinite sets. Let the removed infinite sets be $A'$ and $B'$ , such that they are both proper subsets of $A$ and $B$ respectively. Let $A=B=B'=\mathbb{N}$ . Let $A'$ be the set of odd numbers. Then, $A-A'$ is the set of even numbers. The cardinality of $(A-A')$ is $\mathbb{N}$ . $B-B'= \emptyset$ so the cardinality of $(A-A')$ is not equal to $(B-B')$ . Hence, I have proved that the finite set rule I described above does not hold for infinite sets. Is this correct?","We know that if there is a bijection from finite set to finite set , we can remove one element from both sets and still be able to form a bijection. Similarly, removing sets of equal cardinalities from finite sets still allows us to form bijections. But this result does not hold for infinite sets. Let the removed infinite sets be and , such that they are both proper subsets of and respectively. Let . Let be the set of odd numbers. Then, is the set of even numbers. The cardinality of is . so the cardinality of is not equal to . Hence, I have proved that the finite set rule I described above does not hold for infinite sets. Is this correct?",A B A' B' A B A=B=B'=\mathbb{N} A' A-A' (A-A') \mathbb{N} B-B'= \emptyset (A-A') (B-B'),['elementary-set-theory']
51,"Cardinality of $\{(x, y)\mid x \in y \}$ for Finite Stages of von Neumann Universe",Cardinality of  for Finite Stages of von Neumann Universe,"\{(x, y)\mid x \in y \}","first time posting here, please feel free correct any formatting mistakes, thanks! We are familiar with the definition of the von Neumann universe. Of interests here are the finite stages: $$ V_0 = \emptyset \\ V_{n+1} = \mathcal{P}(V_n) $$ So my question is the following: for each $V_n$ , what is the cardinality of the membership relation $\{(x, y) \in V_n \times V_n\mid x \in y \}$ ? Thank you very much!","first time posting here, please feel free correct any formatting mistakes, thanks! We are familiar with the definition of the von Neumann universe. Of interests here are the finite stages: So my question is the following: for each , what is the cardinality of the membership relation ? Thank you very much!","
V_0 = \emptyset \\ V_{n+1} = \mathcal{P}(V_n)
 V_n \{(x, y) \in V_n \times V_n\mid x \in y \}","['combinatorics', 'elementary-set-theory']"
52,Why did the authors use $\prec$ instead of $\preccurlyeq$ in the definitions of $S_c$ and $S_{c^\ast}$?,Why did the authors use  instead of  in the definitions of  and ?,\prec \preccurlyeq S_c S_{c^\ast},"Recently, I have read the proof of theorem 5.3 from textbook Introduction to Set Theory by Karel Hrbacek and Thomas Jech. I would like to know why the authors didn't define $S_c=\{p\in P\mid p \prec c\}$ or $S_{c^\ast}=\{p\in P\mid p \prec^\ast c^\ast\}$ . I think that $S_c$ would not necessarily equal to $S_{c^\ast}$ as mentioned in the last line if the authors defined as I mentioned. 5.3 Theorem Let $(P, <)$ be a dense linearly ordered set without endpoints. Then there exists a complete linearly ordered set $(C,\prec)$ such that (a) $P\subseteq C$ . (b) If $p,q\in P$ then $p < q$ if and only if $p \prec q$ ( $<$ coincides with $\prec$ on $P$ ). (c) $P$ is dense in $C$ , i.e., for any $a,b\in C$ such that $a\prec b$ , there is $p\in P$ with $a\prec p \prec b$ . (d) $C$ does not have endpoints. Moreover, this complete linearly ordered set $(C,\prec)$ is unique up to isomorphism over $P$ . In other words, if $(C^\ast,\prec^\ast)$ is a complete linearly ordered set which satisfies (a)-(d), then there is an isomorphism $h$ between $(C,\prec)$ and $(C^\ast,\prec^\ast)$ such that $h(x) = x$ for each $x \in P$ . The linearly ordered set $(C,\prec)$ is called the completion of $(P, <)$ . As is usual in theorems of this type, the uniqueness part of the theorem is   easier to prove. For that reason, we do it first. Proof of Uniqueness of Completion. Let $(C,\prec)$ and $(C^\ast,\prec^\ast)$ be two complete linearly ordered sets satisfying (a)-(d). We show that there is an isomorphism $h$ of $C$ onto $C^\ast$ such that $h(x)=x$ for each $x\in P$ . If $c\in C$ , let $S_c=\{p\in P\mid p \preccurlyeq  c\}$ . Similarly, let $S_{c^\ast}=\{p\in P\mid p\preccurlyeq^\ast c^\ast\}$ for $c^\ast\in C^\ast$ . If $S$ is a nonempty subset of $P$ bounded from above, let $\sup S$ be the supremum of $S$ in $(C,\prec)$ and $\sup^\ast S$ be the supremum of $S$ in $(C^\ast,\prec^\ast)$ . Notice that $\sup S_c=c$ , $\sup^\ast S_{c^\ast}=c^\ast$ . We define the mapping $h$ as follows: $h(c)=\sup^\ast S_c$ . Clearl, $h$ is a mapping of $C$ into $C^\ast$ ; we have to show that the mapping is onto and that (a) If $c\prec d$ , then $h(c)\prec^\ast h(d)$ . (b) $h(x)=x$ for each $x\in P$ . To show that $h$ is onto, let $c^\ast\in C^\ast$ be arbitrary. Then $c^\ast=\sup^\ast S_{c^\ast}$ , and if we let $c=\sup S_{c^\ast}$ , then $S_c=S_{c^\ast}$ and $c^\ast=h(c)$ . Below is the reasoning for my conclusion. Could you please have a check on my it? I would like to verify that $\sup S_c=c$ and $\sup^\ast S_{c^\ast}=c^\ast$ . Since $S_c=\{p\in P\mid p \preccurlyeq c\}$ , $\sup S_c\preccurlyeq c$ . If $\sup S_c\prec c$ , then there exists $p\in P$ such that $\sup S_c\prec p \prec c$ . Thus $p\in S_c$ and $\sup S_c\prec p$ . This is clearly a contradiction. Hence $\sup S_c= c$ . Similarly, we can prove that $\sup^\ast S_{c^\ast}=c^\ast$ . If we change the definition of $S_c$ to $S_c=\{p\in P\mid p \prec c\}$ and that of $S_{c^\ast}$ to $S_{c^\ast}=\{p\in P\mid p \prec^\ast c^\ast\}$ , we still have $\sup S_c=c$ and $\sup^\ast S_{c^\ast}=c^\ast$ . Since $S_c=\{p\in P\mid p \prec c\}$ , $\sup S_c\preccurlyeq c$ . If $\sup S_c\prec c$ , then there exists $p\in P$ such that $\sup S_c\prec p \prec c$ . Thus $p\in S_c$ and $\sup S_c\prec p$ . This is clearly a contradiction. Hence $\sup S_c= c$ . Similarly, we can prove that $\sup^\ast S_{c^\ast}=c^\ast$ . I would like to verify that $S_c=S_{c^\ast}$ as mentioned in the last line. For $c^\ast \in C^\ast$ , $S_{c^\ast}=\{p\in P\mid p \preccurlyeq^\ast c^\ast\}$ . Let $c=\sup S_{c^\ast}$ , then $c\in C$ . We have $S_c=\{p\in P\mid p \preccurlyeq c\}$ . Notice that $S_{c^\ast} \subseteq P$ and $S_c \subseteq P$ . For any $p\in S_c$ , $p \preccurlyeq c$ and thus $p \preccurlyeq \sup S_{c^\ast}$ . Then $p \preccurlyeq p'$ for some $p' \in S_{c^\ast}$ . If not, $p' \prec p$ for all $p' \in S_{c^\ast}$ and thus $p' \prec p \preccurlyeq \sup S_{c^\ast}$ for all $p' \in S_{c^\ast}$ . Then $p=\sup S_{c^\ast}$ and thus $S_c$ has only one element. This clearly contradicts the fact that $P$ does not have a least element. Hence $p \preccurlyeq p'\preccurlyeq^\ast c^\ast$ for some $p' \in S_{c^\ast}$ and consequently $p \preccurlyeq^\ast c^\ast$ . Thus $p\in S_{c^\ast}$ . To sum up, $p\in S_c \implies p\in S_{c^\ast}$ and thus $S_c\subseteq S_{c^\ast}$ . For any $p\in S_{c^\ast}$ , $p \preccurlyeq \sup S_{c^\ast}$ and thus $p \preccurlyeq c$ . Then $p\in S_c$ . Hence $S_{c^\ast} \subseteq S_c$ . As a result, $S_{c^\ast}=S_{c^\ast}$ . I'm quite curious about why the authors didn't define $S_c=\{p\in P\mid p \prec c\}$ or $S_{c^\ast}$ to $S_{c^\ast}=\{p\in P\mid p \prec^\ast c^\ast\}$ . I think that $S_c$ would not necessarily equal to $S_{c^\ast}$ as mentioned in the last line if the authors defined as such. For example, we instead define $S_c=\{p\in P\mid p \prec c\}$ and keep $S_{c^\ast}=\{p\in P\mid p \preccurlyeq^\ast c^\ast\}$ . I found that the first reasoning in 3. is still applicable here. Thus $S_c\subseteq S_{c^\ast}$ . But the second reasoning falls apart because: $p \preccurlyeq \sup S_{c^\ast}=c$ , but $p$ is not necessarily strictly less than $c$ . Hence $p$ does not necessarily belong to $S_c$ and consequently $S_{c^\ast}$ is not necessarily a subset of $S_c$ . To sum up, $S_{c^\ast}$ is not necessarily equal to $S_c$ . Similarly, we instead define $S_c=\{p\in P\mid p \prec c\}$ and $S_{c^\ast}=\{p\in P\mid p \prec^\ast c^\ast\}$ . Then $S_{c^\ast}$ is not necessarily equal to $S_c$ .","Recently, I have read the proof of theorem 5.3 from textbook Introduction to Set Theory by Karel Hrbacek and Thomas Jech. I would like to know why the authors didn't define or . I think that would not necessarily equal to as mentioned in the last line if the authors defined as I mentioned. 5.3 Theorem Let be a dense linearly ordered set without endpoints. Then there exists a complete linearly ordered set such that (a) . (b) If then if and only if ( coincides with on ). (c) is dense in , i.e., for any such that , there is with . (d) does not have endpoints. Moreover, this complete linearly ordered set is unique up to isomorphism over . In other words, if is a complete linearly ordered set which satisfies (a)-(d), then there is an isomorphism between and such that for each . The linearly ordered set is called the completion of . As is usual in theorems of this type, the uniqueness part of the theorem is   easier to prove. For that reason, we do it first. Proof of Uniqueness of Completion. Let and be two complete linearly ordered sets satisfying (a)-(d). We show that there is an isomorphism of onto such that for each . If , let . Similarly, let for . If is a nonempty subset of bounded from above, let be the supremum of in and be the supremum of in . Notice that , . We define the mapping as follows: . Clearl, is a mapping of into ; we have to show that the mapping is onto and that (a) If , then . (b) for each . To show that is onto, let be arbitrary. Then , and if we let , then and . Below is the reasoning for my conclusion. Could you please have a check on my it? I would like to verify that and . Since , . If , then there exists such that . Thus and . This is clearly a contradiction. Hence . Similarly, we can prove that . If we change the definition of to and that of to , we still have and . Since , . If , then there exists such that . Thus and . This is clearly a contradiction. Hence . Similarly, we can prove that . I would like to verify that as mentioned in the last line. For , . Let , then . We have . Notice that and . For any , and thus . Then for some . If not, for all and thus for all . Then and thus has only one element. This clearly contradicts the fact that does not have a least element. Hence for some and consequently . Thus . To sum up, and thus . For any , and thus . Then . Hence . As a result, . I'm quite curious about why the authors didn't define or to . I think that would not necessarily equal to as mentioned in the last line if the authors defined as such. For example, we instead define and keep . I found that the first reasoning in 3. is still applicable here. Thus . But the second reasoning falls apart because: , but is not necessarily strictly less than . Hence does not necessarily belong to and consequently is not necessarily a subset of . To sum up, is not necessarily equal to . Similarly, we instead define and . Then is not necessarily equal to .","S_c=\{p\in P\mid p \prec c\} S_{c^\ast}=\{p\in P\mid p \prec^\ast c^\ast\} S_c S_{c^\ast} (P, <) (C,\prec) P\subseteq C p,q\in P p < q p \prec q < \prec P P C a,b\in C a\prec b p\in P a\prec p \prec b C (C,\prec) P (C^\ast,\prec^\ast) h (C,\prec) (C^\ast,\prec^\ast) h(x) = x x \in P (C,\prec) (P, <) (C,\prec) (C^\ast,\prec^\ast) h C C^\ast h(x)=x x\in P c\in C S_c=\{p\in P\mid p \preccurlyeq  c\} S_{c^\ast}=\{p\in P\mid p\preccurlyeq^\ast c^\ast\} c^\ast\in C^\ast S P \sup S S (C,\prec) \sup^\ast S S (C^\ast,\prec^\ast) \sup S_c=c \sup^\ast S_{c^\ast}=c^\ast h h(c)=\sup^\ast S_c h C C^\ast c\prec d h(c)\prec^\ast h(d) h(x)=x x\in P h c^\ast\in C^\ast c^\ast=\sup^\ast S_{c^\ast} c=\sup S_{c^\ast} S_c=S_{c^\ast} c^\ast=h(c) \sup S_c=c \sup^\ast S_{c^\ast}=c^\ast S_c=\{p\in P\mid p \preccurlyeq c\} \sup S_c\preccurlyeq c \sup S_c\prec c p\in P \sup S_c\prec p \prec c p\in S_c \sup S_c\prec p \sup S_c= c \sup^\ast S_{c^\ast}=c^\ast S_c S_c=\{p\in P\mid p \prec c\} S_{c^\ast} S_{c^\ast}=\{p\in P\mid p \prec^\ast c^\ast\} \sup S_c=c \sup^\ast S_{c^\ast}=c^\ast S_c=\{p\in P\mid p \prec c\} \sup S_c\preccurlyeq c \sup S_c\prec c p\in P \sup S_c\prec p \prec c p\in S_c \sup S_c\prec p \sup S_c= c \sup^\ast S_{c^\ast}=c^\ast S_c=S_{c^\ast} c^\ast \in C^\ast S_{c^\ast}=\{p\in P\mid p \preccurlyeq^\ast c^\ast\} c=\sup S_{c^\ast} c\in C S_c=\{p\in P\mid p \preccurlyeq c\} S_{c^\ast} \subseteq P S_c \subseteq P p\in S_c p \preccurlyeq c p \preccurlyeq \sup S_{c^\ast} p \preccurlyeq p' p' \in S_{c^\ast} p' \prec p p' \in S_{c^\ast} p' \prec p \preccurlyeq \sup S_{c^\ast} p' \in S_{c^\ast} p=\sup S_{c^\ast} S_c P p \preccurlyeq p'\preccurlyeq^\ast c^\ast p' \in S_{c^\ast} p \preccurlyeq^\ast c^\ast p\in S_{c^\ast} p\in S_c \implies p\in S_{c^\ast} S_c\subseteq S_{c^\ast} p\in S_{c^\ast} p \preccurlyeq \sup S_{c^\ast} p \preccurlyeq c p\in S_c S_{c^\ast} \subseteq S_c S_{c^\ast}=S_{c^\ast} S_c=\{p\in P\mid p \prec c\} S_{c^\ast} S_{c^\ast}=\{p\in P\mid p \prec^\ast c^\ast\} S_c S_{c^\ast} S_c=\{p\in P\mid p \prec c\} S_{c^\ast}=\{p\in P\mid p \preccurlyeq^\ast c^\ast\} S_c\subseteq S_{c^\ast} p \preccurlyeq \sup S_{c^\ast}=c p c p S_c S_{c^\ast} S_c S_{c^\ast} S_c S_c=\{p\in P\mid p \prec c\} S_{c^\ast}=\{p\in P\mid p \prec^\ast c^\ast\} S_{c^\ast} S_c","['elementary-set-theory', 'proof-explanation']"
53,"Proving f is onto given if $g \circ f = h \circ f$, then g = h","Proving f is onto given if , then g = h",g \circ f = h \circ f,"I realize that there has already been an answer to this problem. But I want to know if my proof was correct. Thank you for your time. Problem Suppose A,B, and C are sets and $f: A \rightarrow B$ Suppose that C has at least two elements, and for all functions $g$ and $h$ from B to C, if $g \circ h = h \circ f$ then $g = h$ . Prove that $f$ is onto. Proof Suppose f is not onto. Then there is $b_1$ such that for all $a \in A$ , $f(a) \neq b_1$ . Suppose $(b_1, c_1) \in g$ and $(b_1, c_2) \in h$ . For the assumption that $g \circ h = h \circ f$ then $g = h$ to be true, $(b_1, c_1) = (b_1, c_2)$ whenever $g \circ f = h \circ f $ . Assume $g \circ f = h \circ f$ . Since $b_1 \notin Ran(f)$ , $(a,c_1) \notin g \circ f$ and $(a,c_2) \notin h \circ f$ . This means that as long as there are at least two elements in C, it is possible that $(b_1, c_2) \neq (b_1, c_2)$ while $g \circ f = h \circ f$ . (Even if $c_1 \neq c_2$ , it can still be true that $g \circ f = h \circ f$ since $c_1$ and $c_2$ are not in the range of $g \circ f$ and $h \circ f$ .) This is a contradiction, hence $f$ is onto.","I realize that there has already been an answer to this problem. But I want to know if my proof was correct. Thank you for your time. Problem Suppose A,B, and C are sets and Suppose that C has at least two elements, and for all functions and from B to C, if then . Prove that is onto. Proof Suppose f is not onto. Then there is such that for all , . Suppose and . For the assumption that then to be true, whenever . Assume . Since , and . This means that as long as there are at least two elements in C, it is possible that while . (Even if , it can still be true that since and are not in the range of and .) This is a contradiction, hence is onto.","f: A \rightarrow B g h g \circ h = h \circ f g = h f b_1 a \in A f(a) \neq b_1 (b_1, c_1) \in g (b_1, c_2) \in h g \circ h = h \circ f g = h (b_1, c_1) = (b_1, c_2) g \circ f = h \circ f  g \circ f = h \circ f b_1 \notin Ran(f) (a,c_1) \notin g \circ f (a,c_2) \notin h \circ f (b_1, c_2) \neq (b_1, c_2) g \circ f = h \circ f c_1 \neq c_2 g \circ f = h \circ f c_1 c_2 g \circ f h \circ f f","['functions', 'proof-verification', 'elementary-set-theory', 'proof-writing', 'function-and-relation-composition']"
54,"Suppose that $f:A\to B$ is a mapping, that $A,B$ are finite, and that $|A| > |B|$. Then $f$ is not injective","Suppose that  is a mapping, that  are finite, and that . Then  is not injective","f:A\to B A,B |A| > |B| f","Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help! Suppose that $f$ is a mapping from a set $A$ to a finite set $B$ . If $A$ is finite and $|A| > |B|$ , then $f$ is not injective. If $A$ is infinite, then there exists $b \in B$ such that $f^{−1}[\{b\}]$ is infinite. If $A$ is finite and $|A| > |B|$ , then $f$ is not injective Lemma: Suppose that $B$ is finite and that $g:B\to A$ is surjective. Then $A$ is finite and $|A|\le|B|$ . (I presented a proof here ) Assume the contrary that $f$ is injective. We define a mapping $g$ from $B$ to $A$ by $g(b)=f^{-1}(b)$ for all $b\in\operatorname{ran}f$ and $g(b)=\bar a$ for all $b \in B\setminus \operatorname{ran}f$ for some $\bar a \in A$ . We have $f^{-1}[\operatorname{ran}f]= \operatorname{dom}f$ $=A$ . Thus $g[\operatorname{ran}f]=A$ . Hence $g:B\to A$ is surjective. Moreover, $B$ is finite, then $A$ is finite and $|A|\le|B|$ by Lemma . This contradicts the fact that $|A|>|B|$ . Hence $f$ is not injective. If $A$ is infinite, then there exists $b \in B$ such that $f^{−1}[\{b\}]$ is infinite Lemma: Finite union of finite sets is finite Assume the contrary that $f^{−1}[\{b\}]$ is finite for all $b\in B$ . It's clear that $\bigcup\limits_{b\in B}f^{−1}[\{b\}]=A$ . Furthermore, $\bigcup\limits_{b\in B}f^{−1}[\{b\}]$ is a finite union of finite sets. It follows from the Lemma that $A=\bigcup\limits_{b\in B}f^{−1}[\{b\}]$ is finite. This contradicts the fact that $A$ is infinite. Hence there exists $b\in B$ such that $f^{−1}[\{b\}]$ is infinite.","Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help! Suppose that is a mapping from a set to a finite set . If is finite and , then is not injective. If is infinite, then there exists such that is infinite. If is finite and , then is not injective Lemma: Suppose that is finite and that is surjective. Then is finite and . (I presented a proof here ) Assume the contrary that is injective. We define a mapping from to by for all and for all for some . We have . Thus . Hence is surjective. Moreover, is finite, then is finite and by Lemma . This contradicts the fact that . Hence is not injective. If is infinite, then there exists such that is infinite Lemma: Finite union of finite sets is finite Assume the contrary that is finite for all . It's clear that . Furthermore, is a finite union of finite sets. It follows from the Lemma that is finite. This contradicts the fact that is infinite. Hence there exists such that is infinite.",f A B A |A| > |B| f A b \in B f^{−1}[\{b\}] A |A| > |B| f B g:B\to A A |A|\le|B| f g B A g(b)=f^{-1}(b) b\in\operatorname{ran}f g(b)=\bar a b \in B\setminus \operatorname{ran}f \bar a \in A f^{-1}[\operatorname{ran}f]= \operatorname{dom}f =A g[\operatorname{ran}f]=A g:B\to A B A |A|\le|B| |A|>|B| f A b \in B f^{−1}[\{b\}] f^{−1}[\{b\}] b\in B \bigcup\limits_{b\in B}f^{−1}[\{b\}]=A \bigcup\limits_{b\in B}f^{−1}[\{b\}] A=\bigcup\limits_{b\in B}f^{−1}[\{b\}] A b\in B f^{−1}[\{b\}],"['elementary-set-theory', 'proof-verification']"
55,Converting English to Set Theory Notation,Converting English to Set Theory Notation,,"I am having trouble finding expressions for the following. My attempts are separated from the question with a semicolon. Let $A$, $B$, and $C$ be events. Find expressions for: only $A$ occurs; $A \cap \neg B \cap \neg C$ only $A$ doesn't occur; $\neg A \cap B \cap C $ $A$ and $B$ don't occur, but $C$ does; $\neg A \cap \neg B \cap C$ $A$ and $B$ occur, but $C$ doesn't occur; $A \cap B \cap \neg C$ at least one of $A$ and $B$, but not $C$ occurs; $(A \cup B) \cap \neg C $ at least one of the events occur; $A \cup B \cup C$ at least two of the events occur; $(A \cup B) \cup (B \cup C) \cup (C \cup A)$ all three events occur; $A \cap B \cap C$ none of the events occur; $\neg A \cap \neg B \cap \neg C$ at most one of the events occurs; $(A - (A \cap B \cap C)) \cup (B - (A \cap B \cap C)) \cup (C - (A\cap B\cap C))$  . Could someone please let me know if my reasoning is correct?","I am having trouble finding expressions for the following. My attempts are separated from the question with a semicolon. Let $A$, $B$, and $C$ be events. Find expressions for: only $A$ occurs; $A \cap \neg B \cap \neg C$ only $A$ doesn't occur; $\neg A \cap B \cap C $ $A$ and $B$ don't occur, but $C$ does; $\neg A \cap \neg B \cap C$ $A$ and $B$ occur, but $C$ doesn't occur; $A \cap B \cap \neg C$ at least one of $A$ and $B$, but not $C$ occurs; $(A \cup B) \cap \neg C $ at least one of the events occur; $A \cup B \cup C$ at least two of the events occur; $(A \cup B) \cup (B \cup C) \cup (C \cup A)$ all three events occur; $A \cap B \cap C$ none of the events occur; $\neg A \cap \neg B \cap \neg C$ at most one of the events occurs; $(A - (A \cap B \cap C)) \cup (B - (A \cap B \cap C)) \cup (C - (A\cap B\cap C))$  . Could someone please let me know if my reasoning is correct?",,['elementary-set-theory']
56,"For any two sets $A$ and $B$, $|A|\le |B|$ or $|B|\le |A|$","For any two sets  and ,  or",A B |A|\le |B| |B|\le |A|,"Definition: $|A|\le |B| \iff$ there exists an injection from $A$ to $B$ . Theorem: For any two sets $A$ and $B$ , $|A|\le |B|$ or $|B|\le |A|$ . My attempt: Assume $|B| \not\le |A|$ , I will prove $|A|\le |B|$ . Let $X=\{f:A'\to B \mid A'\subseteq A \text{ and } f\text{ is injective}\}$ . We define a partial order $<$ on $X$ by $$f_1<f_2 \iff f_1\subseteq f_2$$ Since $f:\emptyset\to B$ is injective, $f\in X$ . Thus $X\neq\emptyset$ . For any chain $Y$ from $X$ , let $f^\ast=\bigcup Y$ . $f^\ast$ is a mapping For $(a,b_1),(a,b_2)\in f^\ast$ , there are $f_1,f_2 \in Y$ such that $(a,b_1)\in f_1$ and $(a,b_2)\in f_2$ . Since $Y$ is a chain, we can safely assume $f_1 < f_2$ . It follows that $f_1 \subseteq f_2$ . Thus $(a,b_1),(a,b_2)\in f_2$ and consequently $b_1=b_2$ by the fact that $f_2$ is a mapping. $f^\ast$ is injective Assume $(a_1,b),(a_2,b)\in f^\ast$ . Then there exists $f_1,f_2 \in Y$ such that $(a_1,b) \in f_1$ and $(a_2,b) \in f_2$ . Since $Y$ is a chain, we can safely assume $f_1 < f_2$ . It follows that $f_1 \subseteq f_2$ . Thus $f_1(a_1)=f_2(a_1)$ and consequently $f_2(a_2)=b=f_1(a_1)=f_2(a_1)$ . Hence $f_2(a_2)=f_2(a_1)$ and consequently $a_2=a_1$ by the fact that $f_2$ is injective. It follows that $f^\ast$ is injective. To sum up, $f^\ast$ is injective and thus $f^\ast \in X$ . Furthermore, $f^\ast$ is an upper bound of chain $Y$ . Thus $X$ satisfies the requirement of Zorn's Lemma and hence has a maximal element $\bar{f}:\bar{A} \to B$ . Let $\bar{B}=\operatorname{ran}\bar{f}$ . Then $\bar{f}:\bar{A} \to \bar{B}$ is bijective. I claim that $\bar{B}\subsetneq B$ . If not, $\bar{B} = B$ . Then $\bar{f}:\bar{A} \to B$ is bijective and thus $\bar{f}^{-1}:B \to \bar{A} \subseteq A$ is bijective. This contradicts our very first assumption that $|B| \not\le |A|$ . Hence $\bar{B}\subsetneq B$ and thus $\exists b'\in B\setminus \bar{B}$ . It follows that $b'\notin \bar{B}=\operatorname{ran}\bar{f}$ . I claim that $\bar{A}=A$ . If not, $A\setminus \bar{A} \neq \emptyset$ . Thus there exits $a'\in A\setminus \bar{A}$ . It follows that $a'\notin \bar{A} = \operatorname{dom}\bar{f}$ . We define $F:\bar{A}\cup\{a'\} \to \bar{B}\cup\{b'\}$ by $F(a)=\bar{f}(a)$ for all $a\in\bar{A}$ and $F(a')=b'$ . It's clear that $F$ is   a bijection from $\bar{A}\cup\{a'\}$ to $\bar{B}\cup\{b'\}$ and that $\bar{f}\subsetneq F$ . Then $F$ is an injection from $\bar{A}\cup\{a'\}$ to $B$ and $\bar{f}\subsetneq F$ . This contradicts the maximality of $\bar{f}$ . Hence $\bar{A}=A$ . To sum up, $\bar{f}:A \to B$ is injective and thus $|A|\le |B|$ . Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","Definition: there exists an injection from to . Theorem: For any two sets and , or . My attempt: Assume , I will prove . Let . We define a partial order on by Since is injective, . Thus . For any chain from , let . is a mapping For , there are such that and . Since is a chain, we can safely assume . It follows that . Thus and consequently by the fact that is a mapping. is injective Assume . Then there exists such that and . Since is a chain, we can safely assume . It follows that . Thus and consequently . Hence and consequently by the fact that is injective. It follows that is injective. To sum up, is injective and thus . Furthermore, is an upper bound of chain . Thus satisfies the requirement of Zorn's Lemma and hence has a maximal element . Let . Then is bijective. I claim that . If not, . Then is bijective and thus is bijective. This contradicts our very first assumption that . Hence and thus . It follows that . I claim that . If not, . Thus there exits . It follows that . We define by for all and . It's clear that is   a bijection from to and that . Then is an injection from to and . This contradicts the maximality of . Hence . To sum up, is injective and thus . Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","|A|\le |B| \iff A B A B |A|\le |B| |B|\le |A| |B| \not\le |A| |A|\le |B| X=\{f:A'\to B \mid A'\subseteq A \text{ and } f\text{ is injective}\} < X f_1<f_2 \iff f_1\subseteq f_2 f:\emptyset\to B f\in X X\neq\emptyset Y X f^\ast=\bigcup Y f^\ast (a,b_1),(a,b_2)\in f^\ast f_1,f_2 \in Y (a,b_1)\in f_1 (a,b_2)\in f_2 Y f_1 < f_2 f_1 \subseteq f_2 (a,b_1),(a,b_2)\in f_2 b_1=b_2 f_2 f^\ast (a_1,b),(a_2,b)\in f^\ast f_1,f_2 \in Y (a_1,b) \in f_1 (a_2,b) \in f_2 Y f_1 < f_2 f_1 \subseteq f_2 f_1(a_1)=f_2(a_1) f_2(a_2)=b=f_1(a_1)=f_2(a_1) f_2(a_2)=f_2(a_1) a_2=a_1 f_2 f^\ast f^\ast f^\ast \in X f^\ast Y X \bar{f}:\bar{A} \to B \bar{B}=\operatorname{ran}\bar{f} \bar{f}:\bar{A} \to \bar{B} \bar{B}\subsetneq B \bar{B} = B \bar{f}:\bar{A} \to B \bar{f}^{-1}:B \to \bar{A} \subseteq A |B| \not\le |A| \bar{B}\subsetneq B \exists b'\in B\setminus \bar{B} b'\notin \bar{B}=\operatorname{ran}\bar{f} \bar{A}=A A\setminus \bar{A} \neq \emptyset a'\in A\setminus \bar{A} a'\notin \bar{A} = \operatorname{dom}\bar{f} F:\bar{A}\cup\{a'\} \to \bar{B}\cup\{b'\} F(a)=\bar{f}(a) a\in\bar{A} F(a')=b' F \bar{A}\cup\{a'\} \bar{B}\cup\{b'\} \bar{f}\subsetneq F F \bar{A}\cup\{a'\} B \bar{f}\subsetneq F \bar{f} \bar{A}=A \bar{f}:A \to B |A|\le |B|","['elementary-set-theory', 'proof-verification']"
57,Another proof for impossibility of covering $\mathbb{R}^{n}$ with a set of varieties of cardinality less than $2^{\aleph_0}$,Another proof for impossibility of covering  with a set of varieties of cardinality less than,\mathbb{R}^{n} 2^{\aleph_0},"Let $\mathbb{R}^{n}$ be the affine $n$-space. Let $\{V_{\alpha} \}_{\alpha \in \Gamma}$ be a set of real varieteis such that $\mathbb{R}^{n} \subseteq {\bigcup V_{\alpha}}.$ Prove that $|\Gamma| \geq 2^{\aleph_{0}}$ I know that one can take the set $A =\{(t^{a_{1}},...,t^{a_{n}}) | t \in [0,1],\hspace{0.2cm} a_{1},...,a_{n} \text{ such that they are linearly independent over} \hspace{0.2cm}\mathbb{Q}\}$ and show that every polynomial intersects with this set in finitly many points and prove the statement. But now does anyone know rather a different proof of this statement?","Let $\mathbb{R}^{n}$ be the affine $n$-space. Let $\{V_{\alpha} \}_{\alpha \in \Gamma}$ be a set of real varieteis such that $\mathbb{R}^{n} \subseteq {\bigcup V_{\alpha}}.$ Prove that $|\Gamma| \geq 2^{\aleph_{0}}$ I know that one can take the set $A =\{(t^{a_{1}},...,t^{a_{n}}) | t \in [0,1],\hspace{0.2cm} a_{1},...,a_{n} \text{ such that they are linearly independent over} \hspace{0.2cm}\mathbb{Q}\}$ and show that every polynomial intersects with this set in finitly many points and prove the statement. But now does anyone know rather a different proof of this statement?",,"['elementary-set-theory', 'algebraic-geometry', 'alternative-proof']"
58,"Let $\alpha,\beta,\gamma$ be cardinal numbers where $\aleph_0\le\gamma$, $\alpha+\beta=\gamma$, and $\alpha<\gamma$. Then $\beta=\gamma$","Let  be cardinal numbers where , , and . Then","\alpha,\beta,\gamma \aleph_0\le\gamma \alpha+\beta=\gamma \alpha<\gamma \beta=\gamma","Let $\alpha,\beta,\gamma$ be cardinal numbers. We define $\alpha+\beta=|S|$ , where $S=A\cup B$ with $|A|=\alpha$ , $|B|=\beta$ , and $A\cap B=\emptyset$ . If $\alpha\le\beta$ and $\aleph_0\le\beta$ , then $\alpha+\beta=\beta$ . If $\alpha+\beta=\gamma$ , $\aleph_0\le\gamma$ , and $\alpha<\gamma$ , then $\beta=\gamma$ . My attempt: Lemma: $\aleph_0\le\beta\implies \beta+\beta=\beta$ (I presented a proof here ) We first prove claim 1: We have $\beta\le\alpha+\beta\le\beta+\beta$ and $\beta+\beta=\beta$ by Lemma . Thus $\alpha+\beta=\beta$ . We next prove claim 2: We have $\alpha+\beta=\gamma$ , then $\beta\le\gamma$ . Assume the contrary that $\beta\neq\gamma$ , then $\beta<\gamma$ . If $\alpha\le\beta$ , then $\alpha+\beta=\beta$ by Claim 1. It follows that $\alpha+\beta=\beta<\gamma$ , which is a contradiction. If $\beta<\alpha$ , then $\alpha+\beta=\alpha$ by Claim 1. It follows that $\alpha+\beta=\alpha<\gamma$ , which is a contradiction. Hence $\beta=\gamma$ . Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","Let be cardinal numbers. We define , where with , , and . If and , then . If , , and , then . My attempt: Lemma: (I presented a proof here ) We first prove claim 1: We have and by Lemma . Thus . We next prove claim 2: We have , then . Assume the contrary that , then . If , then by Claim 1. It follows that , which is a contradiction. If , then by Claim 1. It follows that , which is a contradiction. Hence . Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","\alpha,\beta,\gamma \alpha+\beta=|S| S=A\cup B |A|=\alpha |B|=\beta A\cap B=\emptyset \alpha\le\beta \aleph_0\le\beta \alpha+\beta=\beta \alpha+\beta=\gamma \aleph_0\le\gamma \alpha<\gamma \beta=\gamma \aleph_0\le\beta\implies \beta+\beta=\beta \beta\le\alpha+\beta\le\beta+\beta \beta+\beta=\beta \alpha+\beta=\beta \alpha+\beta=\gamma \beta\le\gamma \beta\neq\gamma \beta<\gamma \alpha\le\beta \alpha+\beta=\beta \alpha+\beta=\beta<\gamma \beta<\alpha \alpha+\beta=\alpha \alpha+\beta=\alpha<\gamma \beta=\gamma","['elementary-set-theory', 'proof-verification']"
59,"If $X$ is infinite, then $X$ and $X\times X$ are equinumerous","If  is infinite, then  and  are equinumerous",X X X\times X,"If $X$ is infinite, then $X$ and $X\times X$ are equinumerous. Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help! My attempt: We denote $A$ and $B$ are equinumerous by $A\sim B$ . Let $Y=\{(A,f) \mid A \in\mathcal{P}(X) \text{ and } f:A \to A\times A\text{ is bijective }\}$ . We define a partial order $<$ on $Y$ by $$(A_1,f_1) < (A_2,f_2) \iff A_1 \subseteq A_2 \text{ and } f_1\subseteq f_2$$ Since $X$ is infinite, there exists $A\subseteq X$ such that $A \sim \Bbb N$ (Here we assume Axiom of Countable Choice). Thus $A\sim \Bbb N\sim \Bbb N\times \Bbb N\sim A\times A$ . Hence there is a bijection $f:A\to A\times A$ , and consequently $f\in Y$ and $Y\neq\emptyset$ . For any chain $Z$ in $Y$ , let $F=\{f \mid \exists A \in\mathcal{P}(X),(A,f)\in Z\}$ and $f^\ast=\bigcup\limits_{f\in F}f$ . $f^\ast$ is a mapping For $(a,x_1),(a,x_2)\in f^\ast$ , there are $(A_1,f_1),(A_2,f_2) \in Z$ such that $(a,x_1)\in f_1$ and $(a,x_2)\in f_2$ . Since $Z$ is a chain, we can safely assume $(A_1,f_1) < (A_2,f_2)$ . It follows that $f_1 \subseteq f_2$ . Thus $(a,x_1),(a,x_2)\in f_2$ and consequently $x_1=x_2$ by the fact that $f_2$ is a mapping. Let $A^\ast=\operatorname{dom}f^\ast$ , then $A^\ast=\bigcup\limits_{f\in F} \operatorname{dom}f$ . $f^\ast$ is surjective For all $f\in F$ , $f$ is a bijection from $\operatorname{dom}f$ to $\operatorname{dom}f\times\operatorname{dom}f$ , and thus $\operatorname{ran}f = \operatorname{dom}f\times\operatorname{dom}f$ . $\operatorname{ran}f^\ast=\bigcup\limits_{f\in F} \operatorname{ran}f =\bigcup\limits_{f\in F} (\operatorname{dom}f \times \operatorname{dom}f) \subseteq (\bigcup\limits_{f\in F} \operatorname{dom}f) \times(\bigcup\limits_{f\in F} \operatorname{dom}f) =$ $\operatorname{dom}f^\ast \times \operatorname{dom}f^\ast$ $= A^\ast \times A^\ast$ . Thus $\operatorname{ran}f^\ast\subseteq A^\ast\times A^\ast$ . For any $(a_1,a_2)\in A^\ast\times A^\ast$ , since $A^\ast=\bigcup\limits_{f\in F} \operatorname{dom}f$ , there exist $(A_1,f_1),(A_2,f_2)\in Z$ such that $a_1\in A_1$ and $a_2\in A_2$ . Since $Z$ is a chain, we can safely assume that $(A_1,f_1)<(A_2,f_2)$ , then $A_1 \subseteq A_2$ , then $a_1,a_2\in A_2$ , then $(a_1,a_2)\in A_2\times A_2$ . Since $f_2$ is bijective, there exists $a\in A_2\subseteq A^\ast$ such that $f(a)=f^\ast(a)=(a_1,a_2)\in A_2\times A_2\subseteq A^\ast\times A^\ast$ . Hence there exists $a\in A^\ast$ such that $f^\ast(a)=(a_1,a_2)$ for any $(a_1,a_2)\in A^\ast\times A^\ast$ . Thus $f^\ast$ is surjective. $f^\ast$ is injective Assume $(a_1,x),(a_2,x)\in f^\ast$ . Then there exists $(A_1,f_1),(A_2,f_2) \in Z$ such that $(a_1,x) \in f_1$ and $(a_2,x) \in f_2$ . Since $Z$ is a chain, we can safely assume $(A_1,f_1) < (A_2,f_2)$ . It follows that $f_1 \subseteq f_2$ . Thus $f_1(a_1)=f_2(a_1)$ and consequently $f_2(a_2)=x=f_1(a_1)=f_2(a_1)$ . Hence $f_2(a_2)=f_2(a_1)$ and consequently $a_2=a_1$ by the fact that $f_2$ is injective. It follows that $f^\ast$ is injective. To sum up, $f^\ast:A^\ast\to A^\ast\times A^\ast$ is bijective and hence $A^\ast\sim A^\ast\times A^\ast$ and $f^\ast \in Y$ . Furthermore, $f^\ast$ is an upper bound of $Z$ by definition. Thus $Y$ satisfies the requirement of Zorn's Lemma and hence has a maximal element $(\bar{A},\bar{f})$ . $X\sim X\times X$ First, we prove $X\sim \bar{A}$ . If not, then $X\setminus \bar{A}$ is infinite and consequently there exists $C\subseteq X\setminus \bar{A}$ such that $C\sim \Bbb N\sim \Bbb N \times\Bbb N \sim C\times C$ . Thus there is a bijection $\underline f:C \to C\times C$ . Hence $g=\bar{f} \cup \underline f$ is a bijection from $\bar{A}\cup C$ to $(\bar{A}\times\bar{A})\cup (C\times C)$ . Hence $\bar{A}\cup C \sim (\bar{A}\times\bar{A})\cup (C\times C)$ . Since $C\sim \Bbb N$ , $(\bar{A}\times\bar{A})\cup (C\times C) \sim \bar{A}\times\bar{A} \sim (\bar{A}\cup C)\times(\bar{A}\cup C)$ by Lemma . It follows that $\bar{A}\cup C\sim (\bar{A}\cup C)\times(\bar{A}\cup C)$ and consequently there exists a bijection $G:\bar{A}\cup C\to (\bar{A}\cup C)\times(\bar{A}\cup C)$ . Thus $(\bar{A}\cup C,G)\in Y$ and $\bar{f}\subsetneq G$ . This contradicts the maximality of $(\bar{A},\bar{f})$ . Hence $X\sim\bar{A}\sim \bar{A}\times \bar{A}\sim X\times X$ . This completes the proof. Update: I fixed Part 4 as follows: We denote: $X\sim Y \iff$ $X$ and $Y$ are equinumerous. $|X|+|Y|:=|A\cup B|$ for $X\sim A$ , $Y\sim B$ , and $A\cap B=\emptyset$ . $|X|.|Y|:=|X\times Y|$ . Lemma 1: If $\aleph_0\le |Z|$ , $|X|+|Y|=|Z|$ , and $|X|<|Z|$ . Then $|Y|=|Z|$ . (I presented a proof here ) Lemma 2: If $\aleph_0\le |X|=|Y|$ . Then $|X|+|Y|=|X|$ . (I presented a proof here ) $X\sim X\times X$ We first prove $\bar{A}\sim X$ . Assume the contrary that $|\bar{A}|\neq |X|$ , then $|\bar{A}|< |X|$ . We have $\bar{A} \cup (X\setminus \bar{A})=X$ , $\bar{A} \cap (X\setminus \bar{A})=\emptyset$ , and $|\bar{A}|<|X|$ . Then $|X\setminus \bar{A}|=|X|$ by Lemma 1 . It follows that there exists $C\subseteq X\setminus \bar{A}$ such that $|C|=|\bar{A}|<|X\setminus \bar{A}|=|X|$ . Consider $$D=(C\times \bar{A})\cup(\bar{A}\times C)\cup(C\times C)$$ We have the following claims: a. $(\bar{A}\times \bar{A})\cup D=(\bar{A}\times \bar{A})\cup(C\times \bar{A})\cup(\bar{A}\times C)\cup(C\times C)=(\bar A\cup C)\times(\bar A\cup C)$ by the definition of Cartesian product. b. Since $|C|=|\bar{A}|$ , $|C\times \bar{A}|=|\bar{A}\times C|=|C\times C|=|\bar{A}\times \bar{A}|=|\bar{A}|$ [since $\bar{f}:\bar{A}\to\bar{A}\times \bar{A}$ is bijective]. c. Since $|C\times \bar{A}|=|\bar{A}\times C|=|C\times C|=|\bar{A}\times \bar{A}|=|\bar{A}|\ge\aleph_0$ and they are pairwise-disjoint [Since $\bar A\cap C=\emptyset$ ], $|D|=|\bar{A}|$ by Lemma 2 . d. Since $|C|=|\bar{A}|=|D|$ , $|C|=|D|$ . Thus there exists a bijection $\underline f: C\to D$ . Let $G=\bar f\cup \underline f$ , then $G:\bar A\cup C\to (\bar A\times\bar A)\cup D$ is bijective since $\bar f, \underline f$ are bijective, or equivalently $G:\bar A\cup C\to(\bar A\cup C)\times(\bar A\cup C)$ is bijective. It follows that $\bar f\subsetneq G$ and $(\bar A\cup C,G)\in Y$ . This contradicts the maximality of $(\bar f,\bar A)$ . Hence $X\sim\bar A\sim \bar A\times\bar A\sim A\times X$ . $$\tag*{$\blacksquare$}$$","If is infinite, then and are equinumerous. Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help! My attempt: We denote and are equinumerous by . Let . We define a partial order on by Since is infinite, there exists such that (Here we assume Axiom of Countable Choice). Thus . Hence there is a bijection , and consequently and . For any chain in , let and . is a mapping For , there are such that and . Since is a chain, we can safely assume . It follows that . Thus and consequently by the fact that is a mapping. Let , then . is surjective For all , is a bijection from to , and thus . . Thus . For any , since , there exist such that and . Since is a chain, we can safely assume that , then , then , then . Since is bijective, there exists such that . Hence there exists such that for any . Thus is surjective. is injective Assume . Then there exists such that and . Since is a chain, we can safely assume . It follows that . Thus and consequently . Hence and consequently by the fact that is injective. It follows that is injective. To sum up, is bijective and hence and . Furthermore, is an upper bound of by definition. Thus satisfies the requirement of Zorn's Lemma and hence has a maximal element . First, we prove . If not, then is infinite and consequently there exists such that . Thus there is a bijection . Hence is a bijection from to . Hence . Since , by Lemma . It follows that and consequently there exists a bijection . Thus and . This contradicts the maximality of . Hence . This completes the proof. Update: I fixed Part 4 as follows: We denote: and are equinumerous. for , , and . . Lemma 1: If , , and . Then . (I presented a proof here ) Lemma 2: If . Then . (I presented a proof here ) We first prove . Assume the contrary that , then . We have , , and . Then by Lemma 1 . It follows that there exists such that . Consider We have the following claims: a. by the definition of Cartesian product. b. Since , [since is bijective]. c. Since and they are pairwise-disjoint [Since ], by Lemma 2 . d. Since , . Thus there exists a bijection . Let , then is bijective since are bijective, or equivalently is bijective. It follows that and . This contradicts the maximality of . Hence .","X X X\times X A B A\sim B Y=\{(A,f) \mid A \in\mathcal{P}(X) \text{ and } f:A \to A\times A\text{ is bijective }\} < Y (A_1,f_1) < (A_2,f_2) \iff A_1 \subseteq A_2 \text{ and } f_1\subseteq f_2 X A\subseteq X A \sim \Bbb N A\sim \Bbb N\sim \Bbb N\times \Bbb N\sim A\times A f:A\to A\times A f\in Y Y\neq\emptyset Z Y F=\{f \mid \exists A \in\mathcal{P}(X),(A,f)\in Z\} f^\ast=\bigcup\limits_{f\in F}f f^\ast (a,x_1),(a,x_2)\in f^\ast (A_1,f_1),(A_2,f_2) \in Z (a,x_1)\in f_1 (a,x_2)\in f_2 Z (A_1,f_1) < (A_2,f_2) f_1 \subseteq f_2 (a,x_1),(a,x_2)\in f_2 x_1=x_2 f_2 A^\ast=\operatorname{dom}f^\ast A^\ast=\bigcup\limits_{f\in F} \operatorname{dom}f f^\ast f\in F f \operatorname{dom}f \operatorname{dom}f\times\operatorname{dom}f \operatorname{ran}f = \operatorname{dom}f\times\operatorname{dom}f \operatorname{ran}f^\ast=\bigcup\limits_{f\in F} \operatorname{ran}f =\bigcup\limits_{f\in F} (\operatorname{dom}f \times \operatorname{dom}f) \subseteq (\bigcup\limits_{f\in F} \operatorname{dom}f) \times(\bigcup\limits_{f\in F} \operatorname{dom}f) = \operatorname{dom}f^\ast \times \operatorname{dom}f^\ast = A^\ast \times A^\ast \operatorname{ran}f^\ast\subseteq A^\ast\times A^\ast (a_1,a_2)\in A^\ast\times A^\ast A^\ast=\bigcup\limits_{f\in F} \operatorname{dom}f (A_1,f_1),(A_2,f_2)\in Z a_1\in A_1 a_2\in A_2 Z (A_1,f_1)<(A_2,f_2) A_1 \subseteq A_2 a_1,a_2\in A_2 (a_1,a_2)\in A_2\times A_2 f_2 a\in A_2\subseteq A^\ast f(a)=f^\ast(a)=(a_1,a_2)\in A_2\times A_2\subseteq A^\ast\times A^\ast a\in A^\ast f^\ast(a)=(a_1,a_2) (a_1,a_2)\in A^\ast\times A^\ast f^\ast f^\ast (a_1,x),(a_2,x)\in f^\ast (A_1,f_1),(A_2,f_2) \in Z (a_1,x) \in f_1 (a_2,x) \in f_2 Z (A_1,f_1) < (A_2,f_2) f_1 \subseteq f_2 f_1(a_1)=f_2(a_1) f_2(a_2)=x=f_1(a_1)=f_2(a_1) f_2(a_2)=f_2(a_1) a_2=a_1 f_2 f^\ast f^\ast:A^\ast\to A^\ast\times A^\ast A^\ast\sim A^\ast\times A^\ast f^\ast \in Y f^\ast Z Y (\bar{A},\bar{f}) X\sim X\times X X\sim \bar{A} X\setminus \bar{A} C\subseteq X\setminus \bar{A} C\sim \Bbb N\sim \Bbb N \times\Bbb N \sim C\times C \underline f:C \to C\times C g=\bar{f} \cup \underline f \bar{A}\cup C (\bar{A}\times\bar{A})\cup (C\times C) \bar{A}\cup C \sim (\bar{A}\times\bar{A})\cup (C\times C) C\sim \Bbb N (\bar{A}\times\bar{A})\cup (C\times C) \sim \bar{A}\times\bar{A} \sim (\bar{A}\cup C)\times(\bar{A}\cup C) \bar{A}\cup C\sim (\bar{A}\cup C)\times(\bar{A}\cup C) G:\bar{A}\cup C\to (\bar{A}\cup C)\times(\bar{A}\cup C) (\bar{A}\cup C,G)\in Y \bar{f}\subsetneq G (\bar{A},\bar{f}) X\sim\bar{A}\sim \bar{A}\times \bar{A}\sim X\times X X\sim Y \iff X Y |X|+|Y|:=|A\cup B| X\sim A Y\sim B A\cap B=\emptyset |X|.|Y|:=|X\times Y| \aleph_0\le |Z| |X|+|Y|=|Z| |X|<|Z| |Y|=|Z| \aleph_0\le |X|=|Y| |X|+|Y|=|X| X\sim X\times X \bar{A}\sim X |\bar{A}|\neq |X| |\bar{A}|< |X| \bar{A} \cup (X\setminus \bar{A})=X \bar{A} \cap (X\setminus \bar{A})=\emptyset |\bar{A}|<|X| |X\setminus \bar{A}|=|X| C\subseteq X\setminus \bar{A} |C|=|\bar{A}|<|X\setminus \bar{A}|=|X| D=(C\times \bar{A})\cup(\bar{A}\times C)\cup(C\times C) (\bar{A}\times \bar{A})\cup D=(\bar{A}\times \bar{A})\cup(C\times \bar{A})\cup(\bar{A}\times C)\cup(C\times C)=(\bar A\cup C)\times(\bar A\cup C) |C|=|\bar{A}| |C\times \bar{A}|=|\bar{A}\times C|=|C\times C|=|\bar{A}\times \bar{A}|=|\bar{A}| \bar{f}:\bar{A}\to\bar{A}\times \bar{A} |C\times \bar{A}|=|\bar{A}\times C|=|C\times C|=|\bar{A}\times \bar{A}|=|\bar{A}|\ge\aleph_0 \bar A\cap C=\emptyset |D|=|\bar{A}| |C|=|\bar{A}|=|D| |C|=|D| \underline f: C\to D G=\bar f\cup \underline f G:\bar A\cup C\to (\bar A\times\bar A)\cup D \bar f, \underline f G:\bar A\cup C\to(\bar A\cup C)\times(\bar A\cup C) \bar f\subsetneq G (\bar A\cup C,G)\in Y (\bar f,\bar A) X\sim\bar A\sim \bar A\times\bar A\sim A\times X \tag*{\blacksquare}","['elementary-set-theory', 'proof-verification', 'infinity']"
60,Let $X$ be uncountable and $A$ be a countable subset of $X$. Then $X$ and $X \setminus A$ are equinumerous,Let  be uncountable and  be a countable subset of . Then  and  are equinumerous,X A X X X \setminus A,"Let $X$ be uncountable and $A$ be a countable subset of $X$. Then $X$ and $X \setminus A$ are equinumerous. I have previously proved that Suppose that $X$ is infinite and that $A$ is a finite subset of $X$. Then $X$ and $X\setminus A$ are equinumerous here . I have a feeling that the result can be extended by this theorem, so I tried to give a shot. Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help! My attempt: Lemma 1 : If $A \sim \Bbb N$ and $B \sim \Bbb N$, then $A\cup B \sim \Bbb N$. Lemma 2 : If $X$ is uncountable, then there exists $B\subsetneq X$ such that $B \sim \Bbb N$. There are only two cases. $A$ is finite (I presented a proof here ) $A$ is infinite Then $A$ is countably infinite and consequently $A\sim\Bbb N$. Since $X$ is uncountable and $A$ is countable, then $X\setminus A$ is uncountable. By Lemma 2 , there exists $B\subsetneq X\setminus A$ such that $B \sim \Bbb N$. Let $f_1:(X\setminus A)\setminus B \to (X\setminus A)\setminus B$ be the identity map on $(X\setminus A)\setminus B$, then $f_1$ is a bijection. Since $A\cup B\sim \Bbb N$ by Lemma 1 and $A \sim \Bbb N$, there exists a bijection $f_2:B \to A\cup B$. We define $f:X\setminus A \to X$ by $f(x)=f_1(x)$ for all $x\in (X\setminus A)\setminus B$ and $f(x)=f_2(x)$ for all $x\in B$. Thus $f$ is a bijection. Hence $X\setminus A \sim X$.","Let $X$ be uncountable and $A$ be a countable subset of $X$. Then $X$ and $X \setminus A$ are equinumerous. I have previously proved that Suppose that $X$ is infinite and that $A$ is a finite subset of $X$. Then $X$ and $X\setminus A$ are equinumerous here . I have a feeling that the result can be extended by this theorem, so I tried to give a shot. Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help! My attempt: Lemma 1 : If $A \sim \Bbb N$ and $B \sim \Bbb N$, then $A\cup B \sim \Bbb N$. Lemma 2 : If $X$ is uncountable, then there exists $B\subsetneq X$ such that $B \sim \Bbb N$. There are only two cases. $A$ is finite (I presented a proof here ) $A$ is infinite Then $A$ is countably infinite and consequently $A\sim\Bbb N$. Since $X$ is uncountable and $A$ is countable, then $X\setminus A$ is uncountable. By Lemma 2 , there exists $B\subsetneq X\setminus A$ such that $B \sim \Bbb N$. Let $f_1:(X\setminus A)\setminus B \to (X\setminus A)\setminus B$ be the identity map on $(X\setminus A)\setminus B$, then $f_1$ is a bijection. Since $A\cup B\sim \Bbb N$ by Lemma 1 and $A \sim \Bbb N$, there exists a bijection $f_2:B \to A\cup B$. We define $f:X\setminus A \to X$ by $f(x)=f_1(x)$ for all $x\in (X\setminus A)\setminus B$ and $f(x)=f_2(x)$ for all $x\in B$. Thus $f$ is a bijection. Hence $X\setminus A \sim X$.",,"['functions', 'elementary-set-theory', 'proof-verification', 'infinity']"
61,Suppose that $f:\mathcal{P}(A) \to \mathcal{P}(A)$ is an increasing mapping. Then there exists $G\subseteq A$ such that $f(G)=G$,Suppose that  is an increasing mapping. Then there exists  such that,f:\mathcal{P}(A) \to \mathcal{P}(A) G\subseteq A f(G)=G,"Suppose that $f:\mathcal{P}(A) \to \mathcal{P}(A)$ is an increasing mapping with respect to $\subseteq$, i.e. if $B\subseteq C$ then $f(B)\subseteq f(C)$. Then there exists $G\subseteq A$ such that $f(G)=G$. My attempt: Let $\mathcal G=\{B\in \mathcal{P}(A) \mid B\subseteq f(B)\}$ and $G=\bigcup\limits_{B\in\mathcal G}B$. If $B\in\mathcal G$ then $B\subseteq G$ and consequently $f(B)\subseteq f(G)$. Thus $B\subseteq f(B)\subseteq f(G)$ for all $B\in\mathcal G$ and thus $G=\bigcup\limits_{B\in\mathcal G}B \subseteq f(G)$. Hence $G\in\mathcal G$. Since $G\subseteq f(G),f(G)\subseteq f(f(G))$. As a result, $f(G)\in \mathcal G$. It follows that $f(G)\subseteq G$. To sum up, we have $G\subseteq f(G)$ and $f(G)\subseteq G$. This implies that $f(G)=G$. Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","Suppose that $f:\mathcal{P}(A) \to \mathcal{P}(A)$ is an increasing mapping with respect to $\subseteq$, i.e. if $B\subseteq C$ then $f(B)\subseteq f(C)$. Then there exists $G\subseteq A$ such that $f(G)=G$. My attempt: Let $\mathcal G=\{B\in \mathcal{P}(A) \mid B\subseteq f(B)\}$ and $G=\bigcup\limits_{B\in\mathcal G}B$. If $B\in\mathcal G$ then $B\subseteq G$ and consequently $f(B)\subseteq f(G)$. Thus $B\subseteq f(B)\subseteq f(G)$ for all $B\in\mathcal G$ and thus $G=\bigcup\limits_{B\in\mathcal G}B \subseteq f(G)$. Hence $G\in\mathcal G$. Since $G\subseteq f(G),f(G)\subseteq f(f(G))$. As a result, $f(G)\in \mathcal G$. It follows that $f(G)\subseteq G$. To sum up, we have $G\subseteq f(G)$ and $f(G)\subseteq G$. This implies that $f(G)=G$. Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!",,"['elementary-set-theory', 'proof-verification']"
62,Subsets of an equivalence relation- terminology question,Subsets of an equivalence relation- terminology question,,"Let $(A_n)_{n\in\mathbb N}$ be an increasing sequence of sets and let, for any $n\in\mathbb N$, $R_n$ be a relation on $A_n$ (i.e. a subset of $A_n\times A_n$, such that the following hold For any $n\in\mathbb N$, the relation $R_n$ is reflexive and symmetric on $A_n$, For any $n\le m\le k$, given $a_n\in A_n$, $a_m\in A_m$ and $a_k\in A_k$, such that $a_n R_m a_m$ and $a_m R_k a_k$, there exists some $l\ge k$ such that $a_n R_l a_k$. That is to say, the relations $R_n$ themselves are not necessarily equivalence relations, but their union is an equivalence on $A_n$. I was wondering if such a phenomenon has a commonly used name (e.g. pre-equivalence or graded equivalence relation). I came upon a sequence of relations of this sort recently, and would rather use the commonly used name, if such exists. Thank you!","Let $(A_n)_{n\in\mathbb N}$ be an increasing sequence of sets and let, for any $n\in\mathbb N$, $R_n$ be a relation on $A_n$ (i.e. a subset of $A_n\times A_n$, such that the following hold For any $n\in\mathbb N$, the relation $R_n$ is reflexive and symmetric on $A_n$, For any $n\le m\le k$, given $a_n\in A_n$, $a_m\in A_m$ and $a_k\in A_k$, such that $a_n R_m a_m$ and $a_m R_k a_k$, there exists some $l\ge k$ such that $a_n R_l a_k$. That is to say, the relations $R_n$ themselves are not necessarily equivalence relations, but their union is an equivalence on $A_n$. I was wondering if such a phenomenon has a commonly used name (e.g. pre-equivalence or graded equivalence relation). I came upon a sequence of relations of this sort recently, and would rather use the commonly used name, if such exists. Thank you!",,"['elementary-set-theory', 'relations', 'equivalence-relations']"
63,"Assuming the Axiom of Countable Choice, an infinite set $A$ is Dedekind-infinite","Assuming the Axiom of Countable Choice, an infinite set  is Dedekind-infinite",A,"Theorem: Assuming the Axiom of Countable Choice, an infinite set $A$ is Dedekind-infinite. Lemma 1 : assuming the Axiom of Countable Choice, if $A$ is an infinite set, then $A$ contains a countably infinite subset. Please check my below proof! Thank you for your help! By Lemma 1 , there exists a countably infinite subset $B$ of $A$. Let $(b_1,b_2,\cdots)$ be a listing of the elements of $B$, without repetition. We define a function $f:A \to A$ by $f(b_i)=b_{2i}$ for all $i \in \mathbb N$ and $f(a)=a$ for all $a \in A \setminus B$. Then $f$ is clearly injective. Furthermore, $f(A)=A \setminus \{b_1,b_3,b_5,\cdots\}$, then $f(A) \subsetneq A$.  Hence $f:A \to f(A)$ is a bijection from $A$ to a proper subset of $A$. Consequently, $A$ is Dedekind-infinite.","Theorem: Assuming the Axiom of Countable Choice, an infinite set $A$ is Dedekind-infinite. Lemma 1 : assuming the Axiom of Countable Choice, if $A$ is an infinite set, then $A$ contains a countably infinite subset. Please check my below proof! Thank you for your help! By Lemma 1 , there exists a countably infinite subset $B$ of $A$. Let $(b_1,b_2,\cdots)$ be a listing of the elements of $B$, without repetition. We define a function $f:A \to A$ by $f(b_i)=b_{2i}$ for all $i \in \mathbb N$ and $f(a)=a$ for all $a \in A \setminus B$. Then $f$ is clearly injective. Furthermore, $f(A)=A \setminus \{b_1,b_3,b_5,\cdots\}$, then $f(A) \subsetneq A$.  Hence $f:A \to f(A)$ is a bijection from $A$ to a proper subset of $A$. Consequently, $A$ is Dedekind-infinite.",,"['elementary-set-theory', 'proof-verification']"
64,How to minimize the cardinality of the intersection of two sets of pairs from a cyclic group?,How to minimize the cardinality of the intersection of two sets of pairs from a cyclic group?,,"I was in a group of 10 persons and we wanted to make a know-each-other-better game, so we did the following thing: 5 of us were standing in the middle (inner circle) and the other five were standing in the front of a person from the inner circle (this was the outer circle). There was another person (not from this group) asking 5 the questions. After each question, the outer circle would have to shift to the right. After the first round, we wanted to mix up and start another one, but we observed that a lot of the pairs from the first round were also again in the second round. This made me think a bit at home. Given a group of $2n$ people, and two subsets of $n$ people from the original group, I want to know the answer to the following questions: With $n$ questions per round ($n$ shifts), how the people must re-arrange so that the cardinality of the intersection between the generated sets of pairs in the two rounds is minimum? Same question, but with $n - 1$ questions (shifts) per round I think this is a really interesting problem and of course, it can be generalized using cyclic groups and combinatorics and the goal would be to find a permutation/function, but I wasn't able to figure it out. Can some of you give me some ideas about this? Thanks!","I was in a group of 10 persons and we wanted to make a know-each-other-better game, so we did the following thing: 5 of us were standing in the middle (inner circle) and the other five were standing in the front of a person from the inner circle (this was the outer circle). There was another person (not from this group) asking 5 the questions. After each question, the outer circle would have to shift to the right. After the first round, we wanted to mix up and start another one, but we observed that a lot of the pairs from the first round were also again in the second round. This made me think a bit at home. Given a group of $2n$ people, and two subsets of $n$ people from the original group, I want to know the answer to the following questions: With $n$ questions per round ($n$ shifts), how the people must re-arrange so that the cardinality of the intersection between the generated sets of pairs in the two rounds is minimum? Same question, but with $n - 1$ questions (shifts) per round I think this is a really interesting problem and of course, it can be generalized using cyclic groups and combinatorics and the goal would be to find a permutation/function, but I wasn't able to figure it out. Can some of you give me some ideas about this? Thanks!",,"['combinatorics', 'number-theory', 'elementary-set-theory', 'permutations', 'cyclic-groups']"
65,Equally dividing a set of integers into parts of as equal sums as possible while maintaining a close number of integers within each set,Equally dividing a set of integers into parts of as equal sums as possible while maintaining a close number of integers within each set,,"Say for example, I have a set of integers $$S = \{1, 2, 3, \cdots , 8, 9, 10\}$$ and I want to divide these integers into $4$ sets, each set with a similar number of integers, but simultaneously with each set having similar sums. One solution might be like: $$S_1 = \{10, 3, 2\}, S_2 = \{9, 4, 1\}, S_3 = \{8, 5\}, S_4 = \{7, 6\}$$, where the sums are $$S_1 = 15, S_2=14, S_3=13, S_4=13$$, and the number of integers in each set are $$S_1 = 3, S_2=3, S_3=2, S_4=2$$. So the sums are ""pretty close"" to each other, as well as the number of integers in each set. Of course there are other solutions, but is there a general way I can find solutions with larger sets of integers? Like if I had $100$ random integers, how would I go about finding one of the solutions to that problem?","Say for example, I have a set of integers $$S = \{1, 2, 3, \cdots , 8, 9, 10\}$$ and I want to divide these integers into $4$ sets, each set with a similar number of integers, but simultaneously with each set having similar sums. One solution might be like: $$S_1 = \{10, 3, 2\}, S_2 = \{9, 4, 1\}, S_3 = \{8, 5\}, S_4 = \{7, 6\}$$, where the sums are $$S_1 = 15, S_2=14, S_3=13, S_4=13$$, and the number of integers in each set are $$S_1 = 3, S_2=3, S_3=2, S_4=2$$. So the sums are ""pretty close"" to each other, as well as the number of integers in each set. Of course there are other solutions, but is there a general way I can find solutions with larger sets of integers? Like if I had $100$ random integers, how would I go about finding one of the solutions to that problem?",,"['elementary-number-theory', 'elementary-set-theory', 'optimization']"
66,Prove that the ordering relation $<_Z$ on the integers is well defined.,Prove that the ordering relation  on the integers is well defined.,<_Z,"I am in the beginning of learning set theory, and the author constructs $\mathbb{R}$, $\mathbb{Q}$ and lastly $\mathbb{Z}$, before $\mathbb{N}$. Definition of $\sim$ The relation $\sim$ between ordered pairs of natural numbers is defined as:  $a+d = c+b \implies (a,b)\sim (c,d)$ Definition of an Integer The equivalence class under this equivalence relation for an ordered pair $(a,b)$, i.e. the set $\{(c,d)\in \mathbb{N}\times \mathbb{N}: (a,b)\sim (c,d)$} Question Assume $(a,b),(a',b'),(c,d),(c',d') \in \mathbb{N}\times \mathbb{N}$ and $(a,b)\sim (a',b')$ and $(c,d)\sim (c',d')$. Use the standard properties of $\mathbb{N}$ to show that $a+_N d <_N c+_N b \iff a'+_N d'<_N c'+_N b'$. (The reason for the title is that later $<_Z$ is defined as: integer$(a,b) <_Z $integer$(c,d)$ if $a+_Nd<c+_Nb$) Attempt As far as I understand, since we work with $\mathbb{N}$ to define $\mathbb{Z}$, subtraction and division are not generally defined. I know the following (all operations are those defined in $\mathbb{N}$): (1.) $a+b'=a'+b$ (2.) $c+d'=c'+d$ I start by assuming $a+d < c+b$ and want to show that then $a'+d' < c'+b'$ From here I just feel stuck, because I would have wanted to maybe from (1.) and (2.) rewrite $a,b,c,d$ in terms of $a',b',c',d'$ but that requires subtraction or division which is not well defined. Overall I just feel very limited to do any algebra that I am used to when working with inequalities and equations because that usually requires subtraction or division. I would appreciate a hint how to start, and possibly if you have time a solution underneath so that I can try to solve it myself.","I am in the beginning of learning set theory, and the author constructs $\mathbb{R}$, $\mathbb{Q}$ and lastly $\mathbb{Z}$, before $\mathbb{N}$. Definition of $\sim$ The relation $\sim$ between ordered pairs of natural numbers is defined as:  $a+d = c+b \implies (a,b)\sim (c,d)$ Definition of an Integer The equivalence class under this equivalence relation for an ordered pair $(a,b)$, i.e. the set $\{(c,d)\in \mathbb{N}\times \mathbb{N}: (a,b)\sim (c,d)$} Question Assume $(a,b),(a',b'),(c,d),(c',d') \in \mathbb{N}\times \mathbb{N}$ and $(a,b)\sim (a',b')$ and $(c,d)\sim (c',d')$. Use the standard properties of $\mathbb{N}$ to show that $a+_N d <_N c+_N b \iff a'+_N d'<_N c'+_N b'$. (The reason for the title is that later $<_Z$ is defined as: integer$(a,b) <_Z $integer$(c,d)$ if $a+_Nd<c+_Nb$) Attempt As far as I understand, since we work with $\mathbb{N}$ to define $\mathbb{Z}$, subtraction and division are not generally defined. I know the following (all operations are those defined in $\mathbb{N}$): (1.) $a+b'=a'+b$ (2.) $c+d'=c'+d$ I start by assuming $a+d < c+b$ and want to show that then $a'+d' < c'+b'$ From here I just feel stuck, because I would have wanted to maybe from (1.) and (2.) rewrite $a,b,c,d$ in terms of $a',b',c',d'$ but that requires subtraction or division which is not well defined. Overall I just feel very limited to do any algebra that I am used to when working with inequalities and equations because that usually requires subtraction or division. I would appreciate a hint how to start, and possibly if you have time a solution underneath so that I can try to solve it myself.",,['elementary-set-theory']
67,"Is there a difference between preference order and preference relation and if yes, what?","Is there a difference between preference order and preference relation and if yes, what?",,While reading about utility theory (in context of Game theory) I came across two terms: preference order and preference relation. I am not clear about the distinction between them. Reference Link: http://www.cs.cornell.edu/courses/cs5846/2017sp/2%20utility.pdf,While reading about utility theory (in context of Game theory) I came across two terms: preference order and preference relation. I am not clear about the distinction between them. Reference Link: http://www.cs.cornell.edu/courses/cs5846/2017sp/2%20utility.pdf,,"['functions', 'elementary-set-theory', 'order-theory', 'game-theory', 'algorithmic-game-theory']"
68,Notation for a matrix populated with a Cartesian product of sets,Notation for a matrix populated with a Cartesian product of sets,,"I have several sets, e.g. $$A_1 = \{1,2,3\}$$ $$A_2 = \{a,b,c\}$$ $$\vdots$$ $$A_P = \{\alpha,\beta\}$$ And their Cartesian product: $$A_1 \times A_2 \times \dots \times A_P = \{(a_1,a_2,\dots,a_P) \mid  a_1 \in A_1, a_2 \in A_2, \dots, a_P \in A_P\}$$ What would be a proper way to indicate that the following matrix is populated by the ordered elements from the Cartesian product above? $E_{N\times P} = $ \begin{bmatrix}  		\epsilon_{1,1} & \epsilon_{1,2}  & \dots & \epsilon_{1,P}\\ 		\epsilon_{2,1} & \ddots  & &\epsilon_{2,P}\\ 		\vdots &   &  &\vdots\\ 		\epsilon_{N,1} & \epsilon_{N,2}  & \dots & \epsilon_{N,P}\\ \end{bmatrix} A concrete example with only the three sets above would lead to the following $18\times3$ matrix: \begin{bmatrix}  		1 & a  & \alpha\\ 		1 & a  & \beta\\ 		1 & b  & \alpha\\         1 & b  & \beta\\ 		1 & c  & \alpha\\         1 & c  & \beta\\         2 & a  & \alpha\\         \vdots&\vdots&\vdots\\         3 & c  & \alpha\\         3 & c  & \beta\\ \end{bmatrix} I'm looking either for a mathematical expression, or a simple sentence. So far I have: The rows of $E_{N\times P}$ are populated by the ordered elements in the   Cartesian product of the sets $A_p, \forall p=1,...,P$. But I feel that's a bit heavy and perhaps incorrect (i.e. not sure how to express the idea of ""ordered elements"" referring to the order in the example).","I have several sets, e.g. $$A_1 = \{1,2,3\}$$ $$A_2 = \{a,b,c\}$$ $$\vdots$$ $$A_P = \{\alpha,\beta\}$$ And their Cartesian product: $$A_1 \times A_2 \times \dots \times A_P = \{(a_1,a_2,\dots,a_P) \mid  a_1 \in A_1, a_2 \in A_2, \dots, a_P \in A_P\}$$ What would be a proper way to indicate that the following matrix is populated by the ordered elements from the Cartesian product above? $E_{N\times P} = $ \begin{bmatrix}  		\epsilon_{1,1} & \epsilon_{1,2}  & \dots & \epsilon_{1,P}\\ 		\epsilon_{2,1} & \ddots  & &\epsilon_{2,P}\\ 		\vdots &   &  &\vdots\\ 		\epsilon_{N,1} & \epsilon_{N,2}  & \dots & \epsilon_{N,P}\\ \end{bmatrix} A concrete example with only the three sets above would lead to the following $18\times3$ matrix: \begin{bmatrix}  		1 & a  & \alpha\\ 		1 & a  & \beta\\ 		1 & b  & \alpha\\         1 & b  & \beta\\ 		1 & c  & \alpha\\         1 & c  & \beta\\         2 & a  & \alpha\\         \vdots&\vdots&\vdots\\         3 & c  & \alpha\\         3 & c  & \beta\\ \end{bmatrix} I'm looking either for a mathematical expression, or a simple sentence. So far I have: The rows of $E_{N\times P}$ are populated by the ordered elements in the   Cartesian product of the sets $A_p, \forall p=1,...,P$. But I feel that's a bit heavy and perhaps incorrect (i.e. not sure how to express the idea of ""ordered elements"" referring to the order in the example).",,"['matrices', 'elementary-set-theory', 'notation']"
69,Suggestion for a textbook including Von Neumann definition of ordinal numbers,Suggestion for a textbook including Von Neumann definition of ordinal numbers,,"I'm interested in the generalization of natural numbers and especially ordinals. I have searched through some set theory textbooks but unable to find Von Neumann definition of ordinal numbers. I have read somewhere that Von Neumann definition of ordinal numbers is elegent, so please suggest me some textbooks that mention Von Neumann definition of ordinal numbers. Thank you so much!","I'm interested in the generalization of natural numbers and especially ordinals. I have searched through some set theory textbooks but unable to find Von Neumann definition of ordinal numbers. I have read somewhere that Von Neumann definition of ordinal numbers is elegent, so please suggest me some textbooks that mention Von Neumann definition of ordinal numbers. Thank you so much!",,"['elementary-set-theory', 'reference-request', 'ordinals']"
70,Using a function in set-builder notation?,Using a function in set-builder notation?,,"I want to formulate a set $K$ with the set-builder notation, but I am not sure if I am ""allowed"" to use a function, $m$, as a predicate without explicitly defining the function. I want to accomplish the following: Given two sets $A$ and $B$, I want to define set $K$ in way that members of $K$ are also members of either set $A$ or $B$, provided that the function $m$ of $k$ evaluates to $e$, where $k \in K$ and $e \in E$. Furthermore, the ""inner workings"" of $m$ are irrelevant, it only matters that $m$ maps members of $K$ to members of $E$. I tried to formulate it as follows: Suppose $m: K \rightarrow E$ and $e \in E$, then $K$ is: $K = \{x \in (A \cup B)\ :\ e = m(x)\}$","I want to formulate a set $K$ with the set-builder notation, but I am not sure if I am ""allowed"" to use a function, $m$, as a predicate without explicitly defining the function. I want to accomplish the following: Given two sets $A$ and $B$, I want to define set $K$ in way that members of $K$ are also members of either set $A$ or $B$, provided that the function $m$ of $k$ evaluates to $e$, where $k \in K$ and $e \in E$. Furthermore, the ""inner workings"" of $m$ are irrelevant, it only matters that $m$ maps members of $K$ to members of $E$. I tried to formulate it as follows: Suppose $m: K \rightarrow E$ and $e \in E$, then $K$ is: $K = \{x \in (A \cup B)\ :\ e = m(x)\}$",,['elementary-set-theory']
71,Singletons and Pair Sets,Singletons and Pair Sets,,"Are pair sets a consequence of singleton sets and a pairwise union? I'm using Tao's Analysis and though he states at the beginning of the chapter (chapter three, for reference) that some axioms in the book are redundant, he somewhat implies later on that the singleton/pair sets-axiom isn't.","Are pair sets a consequence of singleton sets and a pairwise union? I'm using Tao's Analysis and though he states at the beginning of the chapter (chapter three, for reference) that some axioms in the book are redundant, he somewhat implies later on that the singleton/pair sets-axiom isn't.",,['elementary-set-theory']
72,"Is there an ""easy"" way to prove the general version Hall's Marriage Theorem?","Is there an ""easy"" way to prove the general version Hall's Marriage Theorem?",,"Hall's theorem: Suppose that $\mathcal{R}$ is a relation, $A=\mathrm{dom}(\mathcal{R})$ and $B=\mathrm{ran}(\mathcal{R})$ are finite, $h(A')=\{b\in B\mid \exists a\in A'\text{ such that } a\mathcal{R}b\}$ for $A'\subseteq A$ , and that $|A'|\leq|h(A')|$ for all $A'\subseteq A$ . Then there exists an injection $f:A\to B$ such that $f\subseteq\mathcal{R}$ . I have two questions regarding this theorem. I have spent a week to give a shot, but I'm not sure if it contains error. Please check my below proof. We will prove this theorem by induction on $|A|$ . It's clear that the theorem is true for $|A|=1$ . Assume it is true for $|A|=n$ . For $|A|=n+1$ . Consider two cases. a. $|A'|<|h(A')|$ for all $A'\subseteq A$ Let $A_1=A-\{a\}$ for some $a\in A$ , and $b\in h(\{a\})$ . Then $|A_1|=n$ . For all $A'\subseteq A_1$ , $|A'|<|h(A')|\leq|h(A')-\{b\}|+1$ . So $|A'|\leq |h(A')-\{b\}|$ . Since the theorem is true for $|A|=n$ , there is an injection $f':A_1\to B-\{b\}$ such that $f'\subseteq\mathcal{R}$ . Since $(a,b)\notin f'$ and $(a,b)\in\mathcal{R}$ , $f=f'\cup\{(a,b)\}$ is the required function. b. There exists $\varnothing\neq A^{*}\subseteq A$ such that $|A^{*}|=|h(A^{*})|$ Let $A_1=A-A^{*}$ . We will prove that for all $A'\subseteq A_1,|A'|\leq |h(A')-h(A^{*})|$ . Assume the contrary, there exists $A'\subseteq A_1$ such that $|A'|>|h(A')-h(A^{*})|$ . Therefore, $|A'\cup A^{*}|=|A'|+|A^{*}|>|h(A')-h(A^{*})|+|h(A^{*})|=|(h(A')-h(A^{*}))\cup h(A^{*})|$ $=|h(A')\cup h(A^{*})|=|h(A'\cup A^{*})|.$ To sum up, $|A'\cup A^{*}|>|h(A'\cup A^{*})|$ . This contradicts the fact that $|A'\cup A^{*}|\leq|h(A'\cup A^{*})|$ [Since $A'\cup A^{*}\subseteq A$ ]. Thus for all $A'\subseteq A_1,|A'|\leq |h(A')-h(A^{*})|$ . So there is an injection $f_1:A_1\to B-h(A^{*})$ such that $f_1\subseteq\mathcal{R}$ . We also have an injection $f_2:A^{*}\to h(A^{*})$ such that $f_2\subseteq\mathcal{R}$ . Since $f_1\cap f_2=\varnothing$ , $f=f_1\cup f_2$ is the required function. Is there any ""easy"" way to prove the more general version of this theorem in which $A$ is NOT necessarily finite, i.e. $A$ can be infinite. I read one proof from https://proofwiki.org/wiki/Hall%27s_Marriage_Theorem/General_Set and figured out one possible mistake ( I posted a thread to confirm this mistake at Is this a mistake in the proof of Hall's Marriage Theorem from https://proofwiki.org? , but have not received any answer). Besides containing a possible error, the proof in that link appeals to Cowen-Engeler Lemma which appeals to Ultrafilter Lemma. I'm not exposed to any of these knowledge. I would like to ask if there is any way to prove the more general version without using Cowen-Engeler Lemma or Ultrafilter Lemma.","Hall's theorem: Suppose that is a relation, and are finite, for , and that for all . Then there exists an injection such that . I have two questions regarding this theorem. I have spent a week to give a shot, but I'm not sure if it contains error. Please check my below proof. We will prove this theorem by induction on . It's clear that the theorem is true for . Assume it is true for . For . Consider two cases. a. for all Let for some , and . Then . For all , . So . Since the theorem is true for , there is an injection such that . Since and , is the required function. b. There exists such that Let . We will prove that for all . Assume the contrary, there exists such that . Therefore, To sum up, . This contradicts the fact that [Since ]. Thus for all . So there is an injection such that . We also have an injection such that . Since , is the required function. Is there any ""easy"" way to prove the more general version of this theorem in which is NOT necessarily finite, i.e. can be infinite. I read one proof from https://proofwiki.org/wiki/Hall%27s_Marriage_Theorem/General_Set and figured out one possible mistake ( I posted a thread to confirm this mistake at Is this a mistake in the proof of Hall's Marriage Theorem from https://proofwiki.org? , but have not received any answer). Besides containing a possible error, the proof in that link appeals to Cowen-Engeler Lemma which appeals to Ultrafilter Lemma. I'm not exposed to any of these knowledge. I would like to ask if there is any way to prove the more general version without using Cowen-Engeler Lemma or Ultrafilter Lemma.","\mathcal{R} A=\mathrm{dom}(\mathcal{R}) B=\mathrm{ran}(\mathcal{R}) h(A')=\{b\in B\mid \exists a\in A'\text{ such that } a\mathcal{R}b\} A'\subseteq A |A'|\leq|h(A')| A'\subseteq A f:A\to B f\subseteq\mathcal{R} |A| |A|=1 |A|=n |A|=n+1 |A'|<|h(A')| A'\subseteq A A_1=A-\{a\} a\in A b\in h(\{a\}) |A_1|=n A'\subseteq A_1 |A'|<|h(A')|\leq|h(A')-\{b\}|+1 |A'|\leq |h(A')-\{b\}| |A|=n f':A_1\to B-\{b\} f'\subseteq\mathcal{R} (a,b)\notin f' (a,b)\in\mathcal{R} f=f'\cup\{(a,b)\} \varnothing\neq A^{*}\subseteq A |A^{*}|=|h(A^{*})| A_1=A-A^{*} A'\subseteq A_1,|A'|\leq |h(A')-h(A^{*})| A'\subseteq A_1 |A'|>|h(A')-h(A^{*})| |A'\cup A^{*}|=|A'|+|A^{*}|>|h(A')-h(A^{*})|+|h(A^{*})|=|(h(A')-h(A^{*}))\cup h(A^{*})| =|h(A')\cup h(A^{*})|=|h(A'\cup A^{*})|. |A'\cup A^{*}|>|h(A'\cup A^{*})| |A'\cup A^{*}|\leq|h(A'\cup A^{*})| A'\cup A^{*}\subseteq A A'\subseteq A_1,|A'|\leq |h(A')-h(A^{*})| f_1:A_1\to B-h(A^{*}) f_1\subseteq\mathcal{R} f_2:A^{*}\to h(A^{*}) f_2\subseteq\mathcal{R} f_1\cap f_2=\varnothing f=f_1\cup f_2 A A","['elementary-set-theory', 'proof-verification']"
73,"Help with the proof: union $A\cup B$ of two countably infinite sets $A,B$ is countably infinite",Help with the proof: union  of two countably infinite sets  is countably infinite,"A\cup B A,B","There are many questions and answers on this proof here, but I would still appreciate the help with the proof that I tried on my own. Disjoined sets It is enough to show what happens with the countability of a union of two disjoint sets, because if they have an intersection, the union can be reformmulated as a union of the intersection and original sets with the intersection removed. If $A \cap B \ne \emptyset$, then if $C = A \cap B, A'=A \setminus C, B' = B  \setminus C$, we get $A \cup B = A' \cup B' \cup C$ and $A' \cap B' \cap C = \emptyset$, so it is enough to show that $A' \cup B'$ is countably infinite, as $(A' \cup B')$ and $C$ are also disjoint. Therefore, it makes no difference if $A \cap B = \emptyset$ or not, so it is assumed that $A \cap B = \emptyset$. Proof If $A$ is countably infinite, $\exists$ a bijection $f : A \to \mathbb{N}$. A bijection $g : A \to \mathbb{N}^{2n-1}$ is introduced $g(i) = 2 f(a_i) - 1, a_i \in A$. (1) If $B$ is countably infinite, $\exists$ a bijection $h : B \to \mathbb{N}$. A bijection $j : B \to \mathbb{N}^{2n}$ is introduced $j(i) = 2 f(b_i), b_i \in B$. (2) The elements of $A \cup B$ can be arbitrarily ordered, so they can be ordered in pairs, taking one element of A, then one from B, like this: $A \cup B = \{a_{1_1}, b_{2_1}, a_{3_2}, b_{4_2}, a_{5_3}, b_{6_3}, ...,  a_{2n-1_n}, b_{2n_n} \}=\{a_{g(i)}, b_{j(i)}:  i \in \mathbb{N}, a_{g(i)} \in A, b_{g(i)} \in B \} $ Because $\forall i \in \mathbb{N}$ the pair $(2i-1, 2i)$ is unique. From $(g(i), j(i))$ a unique $i$ can be computed from either $g$ or $j$, giving $a_i \in A$ and $b_i \in B$. Therefore,  $i \to (g(i), j(i))$ is bijective so $A \cup B$ is also countably infinite. Is this OK? Edit : Jerry asked for the finite + countably infinite set combination. Say that $A$ is finite and $B$ is countably infinite. Then $|A| = C_A \in \mathbb{N}$. Their union can be written by inserting $A$ at the beginning of $B$ (because A is finite): $A \cup B = \{a_1, a_2, a_3, ... a_{C_A}, b_{1+C_A}, b_{2+C_A}, b_{3+C_A}, ... \} = \{b_i\}$ and $\{1,2,3,...,C_A,C_A+1,C_A+2,...\}=\mathbb{N}$, so $A\cup B$ is countably infinite. Is this OK as well?","There are many questions and answers on this proof here, but I would still appreciate the help with the proof that I tried on my own. Disjoined sets It is enough to show what happens with the countability of a union of two disjoint sets, because if they have an intersection, the union can be reformmulated as a union of the intersection and original sets with the intersection removed. If $A \cap B \ne \emptyset$, then if $C = A \cap B, A'=A \setminus C, B' = B  \setminus C$, we get $A \cup B = A' \cup B' \cup C$ and $A' \cap B' \cap C = \emptyset$, so it is enough to show that $A' \cup B'$ is countably infinite, as $(A' \cup B')$ and $C$ are also disjoint. Therefore, it makes no difference if $A \cap B = \emptyset$ or not, so it is assumed that $A \cap B = \emptyset$. Proof If $A$ is countably infinite, $\exists$ a bijection $f : A \to \mathbb{N}$. A bijection $g : A \to \mathbb{N}^{2n-1}$ is introduced $g(i) = 2 f(a_i) - 1, a_i \in A$. (1) If $B$ is countably infinite, $\exists$ a bijection $h : B \to \mathbb{N}$. A bijection $j : B \to \mathbb{N}^{2n}$ is introduced $j(i) = 2 f(b_i), b_i \in B$. (2) The elements of $A \cup B$ can be arbitrarily ordered, so they can be ordered in pairs, taking one element of A, then one from B, like this: $A \cup B = \{a_{1_1}, b_{2_1}, a_{3_2}, b_{4_2}, a_{5_3}, b_{6_3}, ...,  a_{2n-1_n}, b_{2n_n} \}=\{a_{g(i)}, b_{j(i)}:  i \in \mathbb{N}, a_{g(i)} \in A, b_{g(i)} \in B \} $ Because $\forall i \in \mathbb{N}$ the pair $(2i-1, 2i)$ is unique. From $(g(i), j(i))$ a unique $i$ can be computed from either $g$ or $j$, giving $a_i \in A$ and $b_i \in B$. Therefore,  $i \to (g(i), j(i))$ is bijective so $A \cup B$ is also countably infinite. Is this OK? Edit : Jerry asked for the finite + countably infinite set combination. Say that $A$ is finite and $B$ is countably infinite. Then $|A| = C_A \in \mathbb{N}$. Their union can be written by inserting $A$ at the beginning of $B$ (because A is finite): $A \cup B = \{a_1, a_2, a_3, ... a_{C_A}, b_{1+C_A}, b_{2+C_A}, b_{3+C_A}, ... \} = \{b_i\}$ and $\{1,2,3,...,C_A,C_A+1,C_A+2,...\}=\mathbb{N}$, so $A\cup B$ is countably infinite. Is this OK as well?",,['elementary-set-theory']
74,Metaphysical/psychological aspects of describing a formal language (mentioned in Bourbaki),Metaphysical/psychological aspects of describing a formal language (mentioned in Bourbaki),,"In the introduction to Bourbaki vol. 1, we read: ""It goes without saying that the description of the formalized language is made in ordinary language, just as the rules of chess are. We do not propose to enter into a discussion of the psychological and metaphysical problems which underlie the use of ordinary language in such circumstances (for example, the possibility of recognizing that a letter of the alphabet is ""the same"" in two different places on the page, etc.)."" I would really like to read more about such ""psychological and metaphysical"" aspects mentioned here. What is meant by ""letter of alphabet being the same in two places""? I'd appreciate it if someone could introduce some literature/books that discuss these issues.","In the introduction to Bourbaki vol. 1, we read: ""It goes without saying that the description of the formalized language is made in ordinary language, just as the rules of chess are. We do not propose to enter into a discussion of the psychological and metaphysical problems which underlie the use of ordinary language in such circumstances (for example, the possibility of recognizing that a letter of the alphabet is ""the same"" in two different places on the page, etc.)."" I would really like to read more about such ""psychological and metaphysical"" aspects mentioned here. What is meant by ""letter of alphabet being the same in two places""? I'd appreciate it if someone could introduce some literature/books that discuss these issues.",,"['elementary-set-theory', 'logic', 'philosophy', 'foundations', 'meta-math']"
75,Determine whether or not $card(A^B)>card(C^D)$?,Determine whether or not ?,card(A^B)>card(C^D),"Let's say I have $4$ sets: $A,B,C,D$, is there a way to determine whether or not $\left|A^B\right|>\left|C^D\right|$? I thought about this question because it is easy to show that $\left|n^\Bbb N\right|=\left|m^\Bbb N\right|$ forall $n,m\in\Bbb N$, but also $\left|\Bbb N^\Bbb N\right|$ is equal to the above. I was also told that  $\left|\Bbb R^\Bbb N\right|$ is equal to them(although I didn't prove that one), so $\left|n^\Bbb N\right|=\left|\Bbb N^\Bbb N\right|=\left|\Bbb R^1\right|=\left|\Bbb R^\Bbb N\right|$, it means that simply compare $|B|$ with $|D|$ and $|A|$ with $|C|$ won't be enough. Also, what about the other direction? If $\left|A^B\right|>\left|C^D\right|$ what can we say about the relation of the cardinality of $A,B,C,D$?","Let's say I have $4$ sets: $A,B,C,D$, is there a way to determine whether or not $\left|A^B\right|>\left|C^D\right|$? I thought about this question because it is easy to show that $\left|n^\Bbb N\right|=\left|m^\Bbb N\right|$ forall $n,m\in\Bbb N$, but also $\left|\Bbb N^\Bbb N\right|$ is equal to the above. I was also told that  $\left|\Bbb R^\Bbb N\right|$ is equal to them(although I didn't prove that one), so $\left|n^\Bbb N\right|=\left|\Bbb N^\Bbb N\right|=\left|\Bbb R^1\right|=\left|\Bbb R^\Bbb N\right|$, it means that simply compare $|B|$ with $|D|$ and $|A|$ with $|C|$ won't be enough. Also, what about the other direction? If $\left|A^B\right|>\left|C^D\right|$ what can we say about the relation of the cardinality of $A,B,C,D$?",,"['elementary-set-theory', 'cardinals']"
76,Proof Verification: All subsets of the natural numbers are at most countable.,Proof Verification: All subsets of the natural numbers are at most countable.,,"Proof: Suppose $X\subset\Bbb{N}$ and $X\neq\emptyset$; By the well-ordering principle $X$ has a minimum element. $\forall X'=X\setminus\{x_0\}\subset\Bbb{N}$ such that $x_0\leq m,\forall m\in X$, we know that that $X'$ still has a minimum element $x_1$, by the well-ordering principle. Clearly, $x_1$ is the next least element in $X$. By defining a function $f:\Bbb{N}\rightarrow X$ such that if $x_n$ is the least element of $X_n\subset\Bbb{N}$ and $x_{n+k}$ is the least element of $X_n=X\setminus\{x_n,x_{n+1},...,x_{n+k-1}\}\subset\Bbb{N}$, then \begin{align}f(0)=x_n\quad and\quad f(n+k)=x_{n+k}\end{align} for all $n,k\in\Bbb{N}$. Thus, $f$ is surjective. Furthermore, if $f(j)=f(i)$ then $x_{n+j}=x_{n+i}$. Since $x_{n+i}$ is the least element of $X_{n+i}=X_n\setminus\{x_n,...,x_{n+i-1}\}$ and $x_{n+j}$ is the least element of $X_{n+j}$. We know by the well-ordering principle that the least element is unique. Suppose $X_{n+i}\neq X_{n+j}$ such that $X_{n+i}\subset X_{n+j}$ where $X_{n+j}=X_n\setminus\{x_n,...,x_{n+i},...,x_{n+j-1}\}$. Since $x_{n+i}\notin X_{n+j}$, then it cannot be the least element of $X_{n+j}$ and $x_{n+i}\neq x_{n+j}$, a contradiction. Therefore, it must be that $X_{n+i}=X_{n+j}$ which means $\vert X_{n+j}\vert =\vert X_{n+i}\vert$ and $i=j$. Hence, $f$ is also injective.","Proof: Suppose $X\subset\Bbb{N}$ and $X\neq\emptyset$; By the well-ordering principle $X$ has a minimum element. $\forall X'=X\setminus\{x_0\}\subset\Bbb{N}$ such that $x_0\leq m,\forall m\in X$, we know that that $X'$ still has a minimum element $x_1$, by the well-ordering principle. Clearly, $x_1$ is the next least element in $X$. By defining a function $f:\Bbb{N}\rightarrow X$ such that if $x_n$ is the least element of $X_n\subset\Bbb{N}$ and $x_{n+k}$ is the least element of $X_n=X\setminus\{x_n,x_{n+1},...,x_{n+k-1}\}\subset\Bbb{N}$, then \begin{align}f(0)=x_n\quad and\quad f(n+k)=x_{n+k}\end{align} for all $n,k\in\Bbb{N}$. Thus, $f$ is surjective. Furthermore, if $f(j)=f(i)$ then $x_{n+j}=x_{n+i}$. Since $x_{n+i}$ is the least element of $X_{n+i}=X_n\setminus\{x_n,...,x_{n+i-1}\}$ and $x_{n+j}$ is the least element of $X_{n+j}$. We know by the well-ordering principle that the least element is unique. Suppose $X_{n+i}\neq X_{n+j}$ such that $X_{n+i}\subset X_{n+j}$ where $X_{n+j}=X_n\setminus\{x_n,...,x_{n+i},...,x_{n+j-1}\}$. Since $x_{n+i}\notin X_{n+j}$, then it cannot be the least element of $X_{n+j}$ and $x_{n+i}\neq x_{n+j}$, a contradiction. Therefore, it must be that $X_{n+i}=X_{n+j}$ which means $\vert X_{n+j}\vert =\vert X_{n+i}\vert$ and $i=j$. Hence, $f$ is also injective.",,"['elementary-set-theory', 'proof-verification']"
77,Is this a bijection between $\mathcal{P}(\mathbb{R})$ and $\mathbb{R}^\mathbb{R}$,Is this a bijection between  and,\mathcal{P}(\mathbb{R}) \mathbb{R}^\mathbb{R},"I wish to prove the existence of a bijection $\mathcal{P}(\mathbb{R}) \sim\mathbb{R}^\mathbb{R}$ So, I know (and have proven) that $\mathcal{P}(\mathbb{R}\times\mathbb{R}) \sim \mathcal{P}(\mathbb{R})$, so I thought I would use that. My strategy is to construct two injective maps  \begin{align} \phi &: \mathbb{R}^\mathbb{R} \rightarrow \mathcal{P}(\mathbb{R}\times\mathbb{R}) \\ \psi &: \mathcal{P}(\mathbb{R}\times\mathbb{R}) \rightarrow \mathbb{R}^\mathbb{R} \end{align} in order to use the Schröder-Bernstein theorem to prove the existence of a bijection. For $f\in \mathbb{R}^\mathbb{R}$, let $\phi(f) = \{(x,f(x)) : x \in \mathbb{R} \}$. Clearly, if $\phi(f)=\phi(g)$ then $f(x)=g(x)$ for all $x\in \mathbb{R}$ by the definition of $\phi$, so it is injective. For $S\in \mathcal{P}(\mathbb{R}\times\mathbb{R})$, first map it bijectively to $S' \in \mathcal{P}(\mathbb{R})$ via the bijection I know exists between $\mathcal{P}(\mathbb{R}\times\mathbb{R})$ and $\mathcal{P}(\mathbb{R})$. Now, let $\psi(S')(x) = \begin{cases} 0 &\text{if } x \notin S' \\ 1 &\text{if } x \in S'\end{cases}$ Suppose that $\phi(S_1)=\psi(S_2)$, i.e. $\psi(S_1)(x) = \psi(S_2)(x)$ for all $x\in \mathbb{R}$. Then clearly $x\in S_1 \iff x\in S_2$ and $x \notin S_1 \iff x \notin S_2$, so $S_1 = S_2$ and the map is injective. Now, with these injective maps, the bijection I know exists and the Schröder-Bernstein theorem, I have $\mathcal{P}(\mathbb{R}\times\mathbb{R}) \sim \mathcal{P}(\mathbb{R}) \sim \mathbb{R}^\mathbb{R}$. Is this correct? Are there improvements I can make? Is there an easier way to go about this proof? Thank you in advance.","I wish to prove the existence of a bijection $\mathcal{P}(\mathbb{R}) \sim\mathbb{R}^\mathbb{R}$ So, I know (and have proven) that $\mathcal{P}(\mathbb{R}\times\mathbb{R}) \sim \mathcal{P}(\mathbb{R})$, so I thought I would use that. My strategy is to construct two injective maps  \begin{align} \phi &: \mathbb{R}^\mathbb{R} \rightarrow \mathcal{P}(\mathbb{R}\times\mathbb{R}) \\ \psi &: \mathcal{P}(\mathbb{R}\times\mathbb{R}) \rightarrow \mathbb{R}^\mathbb{R} \end{align} in order to use the Schröder-Bernstein theorem to prove the existence of a bijection. For $f\in \mathbb{R}^\mathbb{R}$, let $\phi(f) = \{(x,f(x)) : x \in \mathbb{R} \}$. Clearly, if $\phi(f)=\phi(g)$ then $f(x)=g(x)$ for all $x\in \mathbb{R}$ by the definition of $\phi$, so it is injective. For $S\in \mathcal{P}(\mathbb{R}\times\mathbb{R})$, first map it bijectively to $S' \in \mathcal{P}(\mathbb{R})$ via the bijection I know exists between $\mathcal{P}(\mathbb{R}\times\mathbb{R})$ and $\mathcal{P}(\mathbb{R})$. Now, let $\psi(S')(x) = \begin{cases} 0 &\text{if } x \notin S' \\ 1 &\text{if } x \in S'\end{cases}$ Suppose that $\phi(S_1)=\psi(S_2)$, i.e. $\psi(S_1)(x) = \psi(S_2)(x)$ for all $x\in \mathbb{R}$. Then clearly $x\in S_1 \iff x\in S_2$ and $x \notin S_1 \iff x \notin S_2$, so $S_1 = S_2$ and the map is injective. Now, with these injective maps, the bijection I know exists and the Schröder-Bernstein theorem, I have $\mathcal{P}(\mathbb{R}\times\mathbb{R}) \sim \mathcal{P}(\mathbb{R}) \sim \mathbb{R}^\mathbb{R}$. Is this correct? Are there improvements I can make? Is there an easier way to go about this proof? Thank you in advance.",,"['elementary-set-theory', 'proof-verification']"
78,Set theory - Logic proof verification,Set theory - Logic proof verification,,"Prove that: $$ \mathscr P(U_{i\in I}A_i)\subset U_{i\in I}\mathscr P(A_i) \rightarrow \exists i \in I\ \forall j \in I (A_j \subset A_i) $$ Here are the definitions I've used to figure out how to prove it: $$ U{i\in I} A_i = \{ k \text{ | }\exists i \in I(k\in A_i) \}\\ U{i\in I} \mathscr P(A_i) = \{ k \text{ | }\exists i \in I(k\in \mathscr P(A_i)) \} = \{ k \text{ | }\exists i \in I(k \subset A_i) \} $$ Here's my proof. It's true that $\forall j \in I: A_j \subset U_{i\in I}A_i$, thus $A_j \in \mathscr P(U_{i\in I}A_i)$. Therefore $\forall j \in I:A_j \in U_{i\in I}\mathscr P(A_i)$ which is the same as $ \forall j \in I: \big( \exists i \in I (A_j \subset A_i) \big)$. But I want to prove that:  $$ \exists i \in I: \big( \forall j \in I (A_j \subset  A_i) \big) $$ So now I'll prove : $\forall j \in I: \big( \exists i \in I (A_j \subset  A_i) \big) \rightarrow \exists i \in I: \big( \forall j \in I (A_j \subset  A_i) \big)$ by contradiction. Let $i$ be an arbitrary element of $I$. Therefore $A_{j0} \not\subset  A_i$. That contradicts the fact that $ \forall j \in I: \big( \exists i \in I (A_j \subset  A_i) \big) $, hence $\exists i \in I: \big( \forall j \in I (A_j \subset  A_i) \big)$. I'm new to math formalism and I struggled to get this. Is everything correct? I know that I'm using a lot of logic symbols, but it's because it's still more clear to me to write a proof like that then write it using plain English. I'm open to constructive criticism, and hope for a help. Thanks!","Prove that: $$ \mathscr P(U_{i\in I}A_i)\subset U_{i\in I}\mathscr P(A_i) \rightarrow \exists i \in I\ \forall j \in I (A_j \subset A_i) $$ Here are the definitions I've used to figure out how to prove it: $$ U{i\in I} A_i = \{ k \text{ | }\exists i \in I(k\in A_i) \}\\ U{i\in I} \mathscr P(A_i) = \{ k \text{ | }\exists i \in I(k\in \mathscr P(A_i)) \} = \{ k \text{ | }\exists i \in I(k \subset A_i) \} $$ Here's my proof. It's true that $\forall j \in I: A_j \subset U_{i\in I}A_i$, thus $A_j \in \mathscr P(U_{i\in I}A_i)$. Therefore $\forall j \in I:A_j \in U_{i\in I}\mathscr P(A_i)$ which is the same as $ \forall j \in I: \big( \exists i \in I (A_j \subset A_i) \big)$. But I want to prove that:  $$ \exists i \in I: \big( \forall j \in I (A_j \subset  A_i) \big) $$ So now I'll prove : $\forall j \in I: \big( \exists i \in I (A_j \subset  A_i) \big) \rightarrow \exists i \in I: \big( \forall j \in I (A_j \subset  A_i) \big)$ by contradiction. Let $i$ be an arbitrary element of $I$. Therefore $A_{j0} \not\subset  A_i$. That contradicts the fact that $ \forall j \in I: \big( \exists i \in I (A_j \subset  A_i) \big) $, hence $\exists i \in I: \big( \forall j \in I (A_j \subset  A_i) \big)$. I'm new to math formalism and I struggled to get this. Is everything correct? I know that I'm using a lot of logic symbols, but it's because it's still more clear to me to write a proof like that then write it using plain English. I'm open to constructive criticism, and hope for a help. Thanks!",,"['elementary-set-theory', 'proof-verification']"
79,Top-down proof of a lemma used in Schröder-Bernstein theorem,Top-down proof of a lemma used in Schröder-Bernstein theorem,,"Please have a check whether it is fine or contains any error! Thank you so much! Lemma: Suppose that $Z \subseteq Y \subseteq X$ and that $f:X \to Z$ is bijective, then there exists a bijection $g : X \to Y$. Proof: Without loss of generality, we assume $Y \subsetneq X$. Let $\mathcal{F}=\{ V\subseteq X | (X-Y) \subseteq V \text{ and } f(V) \subseteq V \}$ and $A=\bigcap_{V\in \mathcal{F}}V$ 1. $A \in \mathcal{F}$ $\forall V \in\mathcal{F}, X-Y\subseteq V\implies X-Y\subseteq \bigcap_{V\in\mathcal{F}}V\implies X-Y\subseteq A$. $x\in A\implies \forall V \in\mathcal{F},x\in V \implies \forall V \in\mathcal{F},f(x)\in f(V)\subseteq V \implies \forall V\in\mathcal{F},f(x)\in V$ $\implies f(x)\in\bigcap_{V\in\mathcal{F}}V\implies f(x)\in A\implies f(A)\subseteq A$. To sum up, $X-Y\subseteq A$ and $f(A)\subseteq A \implies A\in\mathcal{F}$. Furthermore, $\forall V\in \mathcal{F}: A \subseteq V\implies A$ is the minimal element of $\mathcal{F}$. 2. We prove $A \neq \varnothing$ $X-Y \subseteq X$ and $f(X)=Z \subseteq X \implies X \in \mathcal{F} \implies \mathcal{F} \neq \varnothing.$ As a result, $f(A) \subseteq A$ and $(X-Y) \subseteq A$. $\mathcal{F} \neq \varnothing$ and $\forall V \in \mathcal{F}, (X-Y) \subseteq V \implies (X-Y) \subseteq \bigcap_{V\in \mathcal{F}}V \implies (X-Y) \subseteq A \implies$ $A \neq \varnothing.$ 3. We prove $f(A)=A \cap Y$ (Here I figure out two ways to prove this and I present both of them) a. Approach 1 Let $B=f(A) \cup (X-Y)$ $f(A) \subseteq A$ and $(X-Y) \subseteq A \implies B \subseteq A$. $f(A) \subseteq A \implies f(f(A)) \subseteq f(A)$; $(X-Y) \subseteq A \implies f(X-Y) \subseteq f(A)$. First, $B=f(A) \cup (X-Y) \implies (X-Y) \subseteq B$. Second, $f(B)=f(f(A) \cup (X-Y))=f(f(A)) \cup f(X-Y) \subseteq f(A) \subseteq B.$ Finally, $(X-Y) \subseteq B$ and $f(B) \subseteq B \implies B \in \mathcal{F},$ but $B \subseteq A$. From the minimality of $A$, $B=A$. $A \cap Y=B \cap Y= (f(A) \cup (X-Y)) \cap Y=(f(A) \cap Y) \cup ((X-Y) \cap Y)=f(A) \cup \varnothing = f(A)$. b. Approach 2 $f(A) \subseteq A$ and $f(A) \subseteq Z \subseteq Y \implies f(A) \subseteq (A \cap Y)$. Assume $(A\cap Y) \not\subseteq f(A) \implies \exists p\in (A\cap Y)$ such that $p \notin f(A) \implies p \in Y$. Let $B=A-\{p\}$. First, $p \in Y \wedge (X-Y) \subseteq A \implies X-Y \subseteq A-\{p\} \implies (X-Y) \subseteq B$. Second, $f(B)=f(A-\{p\})=f(A)-f(\{p\})$ [Since $f$ is injective] $\subseteq f(A) \subseteq f(A)-\{p\}$ [Since $p \notin f(A)$] $\subseteq A-\{p\}$ [Since $f(A) \subseteq A$]$=B$. To sum up, we have $(X-Y) \subseteq B$ and $f(B)\subseteq B$, then $B \in \mathcal{F}$, but $B \subsetneq A$. This contradicts to the minimality of $A \implies (A \cap Y) \subseteq f(A)$. $f(A) \subseteq (A \cap Y)$ and $A \cap Y \subseteq f(A) \implies A \cap Y=f(A)$. 4. $f(A) \cup (X-A)=Y$ and $f(A) \cap (X-A)=\varnothing$ $X-Y \subseteq A \implies X-A \subseteq X-(X-Y)=Y$. $f(A) \cup (X-A)=(A \cap Y)\cup (X-A)=(A\cup (X-A)\cap (Y\cup (X-A))=X\cap (Y\cup (X-A))=Y\cup (X-A) \subseteq Y \cup Y=Y \implies f(A) \cup (X-A)=Y$. $f(A) \cap (X-A)=(A \cap Y) \cap (X-A)=Y \cap (A \cap (X-A))=Y \cap \varnothing=\varnothing.$ 5. We generate $g$ as follows $$ g(x) = \begin{cases} \ f(x)      & \text {if $x \in A$} \\ x   & \text {if $x \in X \setminus A$} \\ \end{cases} $$","Please have a check whether it is fine or contains any error! Thank you so much! Lemma: Suppose that $Z \subseteq Y \subseteq X$ and that $f:X \to Z$ is bijective, then there exists a bijection $g : X \to Y$. Proof: Without loss of generality, we assume $Y \subsetneq X$. Let $\mathcal{F}=\{ V\subseteq X | (X-Y) \subseteq V \text{ and } f(V) \subseteq V \}$ and $A=\bigcap_{V\in \mathcal{F}}V$ 1. $A \in \mathcal{F}$ $\forall V \in\mathcal{F}, X-Y\subseteq V\implies X-Y\subseteq \bigcap_{V\in\mathcal{F}}V\implies X-Y\subseteq A$. $x\in A\implies \forall V \in\mathcal{F},x\in V \implies \forall V \in\mathcal{F},f(x)\in f(V)\subseteq V \implies \forall V\in\mathcal{F},f(x)\in V$ $\implies f(x)\in\bigcap_{V\in\mathcal{F}}V\implies f(x)\in A\implies f(A)\subseteq A$. To sum up, $X-Y\subseteq A$ and $f(A)\subseteq A \implies A\in\mathcal{F}$. Furthermore, $\forall V\in \mathcal{F}: A \subseteq V\implies A$ is the minimal element of $\mathcal{F}$. 2. We prove $A \neq \varnothing$ $X-Y \subseteq X$ and $f(X)=Z \subseteq X \implies X \in \mathcal{F} \implies \mathcal{F} \neq \varnothing.$ As a result, $f(A) \subseteq A$ and $(X-Y) \subseteq A$. $\mathcal{F} \neq \varnothing$ and $\forall V \in \mathcal{F}, (X-Y) \subseteq V \implies (X-Y) \subseteq \bigcap_{V\in \mathcal{F}}V \implies (X-Y) \subseteq A \implies$ $A \neq \varnothing.$ 3. We prove $f(A)=A \cap Y$ (Here I figure out two ways to prove this and I present both of them) a. Approach 1 Let $B=f(A) \cup (X-Y)$ $f(A) \subseteq A$ and $(X-Y) \subseteq A \implies B \subseteq A$. $f(A) \subseteq A \implies f(f(A)) \subseteq f(A)$; $(X-Y) \subseteq A \implies f(X-Y) \subseteq f(A)$. First, $B=f(A) \cup (X-Y) \implies (X-Y) \subseteq B$. Second, $f(B)=f(f(A) \cup (X-Y))=f(f(A)) \cup f(X-Y) \subseteq f(A) \subseteq B.$ Finally, $(X-Y) \subseteq B$ and $f(B) \subseteq B \implies B \in \mathcal{F},$ but $B \subseteq A$. From the minimality of $A$, $B=A$. $A \cap Y=B \cap Y= (f(A) \cup (X-Y)) \cap Y=(f(A) \cap Y) \cup ((X-Y) \cap Y)=f(A) \cup \varnothing = f(A)$. b. Approach 2 $f(A) \subseteq A$ and $f(A) \subseteq Z \subseteq Y \implies f(A) \subseteq (A \cap Y)$. Assume $(A\cap Y) \not\subseteq f(A) \implies \exists p\in (A\cap Y)$ such that $p \notin f(A) \implies p \in Y$. Let $B=A-\{p\}$. First, $p \in Y \wedge (X-Y) \subseteq A \implies X-Y \subseteq A-\{p\} \implies (X-Y) \subseteq B$. Second, $f(B)=f(A-\{p\})=f(A)-f(\{p\})$ [Since $f$ is injective] $\subseteq f(A) \subseteq f(A)-\{p\}$ [Since $p \notin f(A)$] $\subseteq A-\{p\}$ [Since $f(A) \subseteq A$]$=B$. To sum up, we have $(X-Y) \subseteq B$ and $f(B)\subseteq B$, then $B \in \mathcal{F}$, but $B \subsetneq A$. This contradicts to the minimality of $A \implies (A \cap Y) \subseteq f(A)$. $f(A) \subseteq (A \cap Y)$ and $A \cap Y \subseteq f(A) \implies A \cap Y=f(A)$. 4. $f(A) \cup (X-A)=Y$ and $f(A) \cap (X-A)=\varnothing$ $X-Y \subseteq A \implies X-A \subseteq X-(X-Y)=Y$. $f(A) \cup (X-A)=(A \cap Y)\cup (X-A)=(A\cup (X-A)\cap (Y\cup (X-A))=X\cap (Y\cup (X-A))=Y\cup (X-A) \subseteq Y \cup Y=Y \implies f(A) \cup (X-A)=Y$. $f(A) \cap (X-A)=(A \cap Y) \cap (X-A)=Y \cap (A \cap (X-A))=Y \cap \varnothing=\varnothing.$ 5. We generate $g$ as follows $$ g(x) = \begin{cases} \ f(x)      & \text {if $x \in A$} \\ x   & \text {if $x \in X \setminus A$} \\ \end{cases} $$",,"['elementary-set-theory', 'proof-verification', 'proof-writing']"
80,$I \subseteq I_n$ and $I \neq \varnothing \implies I$ has the greatest element [Proof Verification],and  has the greatest element [Proof Verification],I \subseteq I_n I \neq \varnothing \implies I,"Please check my below proof. Thank you for your help! Definition: $I_n=\{m \in \mathbb{N} \mid m \leq n\}$ Theorem: $I \subseteq I_n$ and $I \neq \varnothing \implies I$ has the greatest element. Proof: Let $M$ be $\{m \in \mathbb{N} \mid \forall i \in I, i \leq m\}$ . Then $n \in M \implies M \neq \varnothing$ . By well-ordering theorem, $M$ has the least element $m_0$ . Now we prove $m_0 \in I$ . There are two possible cases. $m_0=0$ $\implies I=\{0\} \implies I$ has only one element $0$ and $0$ is also the greatest element of $I$ . $m_0>0$ $\implies m_0=k+1$ . If $m_0 \not \in I$ , then $\forall i \in I, i < m_0$ . Thus $\forall i \in I, i \leq k \implies k \in M \implies k+1$ is not the least element of $M \implies m_0$ is not the least element of $M$ . (CONTRADICTION). As a result, $m_0 \in I$ . So we have that $I$ has the greatest element.","Please check my below proof. Thank you for your help! Definition: Theorem: and has the greatest element. Proof: Let be . Then . By well-ordering theorem, has the least element . Now we prove . There are two possible cases. has only one element and is also the greatest element of . . If , then . Thus is not the least element of is not the least element of . (CONTRADICTION). As a result, . So we have that has the greatest element.","I_n=\{m \in \mathbb{N} \mid m \leq n\} I \subseteq I_n I \neq \varnothing \implies I M \{m \in \mathbb{N} \mid \forall i \in I, i \leq m\} n \in M \implies M \neq \varnothing M m_0 m_0 \in I m_0=0 \implies I=\{0\} \implies I 0 0 I m_0>0 \implies m_0=k+1 m_0 \not \in I \forall i \in I, i < m_0 \forall i \in I, i \leq k \implies k \in M \implies k+1 M \implies m_0 M m_0 \in I I","['elementary-set-theory', 'proof-verification', 'proof-writing']"
81,Finite union of countable sets is countable.,Finite union of countable sets is countable.,,"Question Is my proof that the union of countable sets is countable correct? If $A_1, A_2, A_3,\dots, A_n$ is a collection of countable sets, then the union: $$A_1\cup A_2\cup A_3 \cup \dots A_n$$ is countable as well. Attempted Proof We attempt to prove the claim by induction. Base case: Consider the set $$B=A_2\setminus A_1$$ Clearly, $B\subseteq A_2$ ( $B$ is countable) and $A_1\cup B$ = $A_1\cup A_2$ . If $B$ is finite, then $$B= \{b_1, b_2, b_3, b_4, \dots, b_j \}\quad j\in\mathbb{N}_0$$ and so we can construct a bijection $$f(n)=\begin{cases} b_n\quad n\leq j\\ a_{n-j}\quad n> j \end{cases}$$ If $B$ is infinite, then we can construct a bijection $$f(n)=\begin{cases} b_{\frac n2}\quad n\text{ even}\\ a_{\frac{n+1}{2}}\quad n\text{ odd} \end{cases}$$ Now, suppose the statement holds for $n= k\geq 2$ , that is, $$A_1\cup A_2\cup A_3 \cup \dots A_k$$ is a countable set. Observe that $$(A_1\cup A_2\cup A_3 \cup \dots A_k)\cup A_{k+1}$$ is a union of two countable sets which, by the base case, is also countable. Thus, by induction, the statement holds for all $n\in\mathbb{N}.\qquad\square$","Question Is my proof that the union of countable sets is countable correct? If is a collection of countable sets, then the union: is countable as well. Attempted Proof We attempt to prove the claim by induction. Base case: Consider the set Clearly, ( is countable) and = . If is finite, then and so we can construct a bijection If is infinite, then we can construct a bijection Now, suppose the statement holds for , that is, is a countable set. Observe that is a union of two countable sets which, by the base case, is also countable. Thus, by induction, the statement holds for all","A_1, A_2, A_3,\dots, A_n A_1\cup A_2\cup A_3 \cup \dots A_n B=A_2\setminus A_1 B\subseteq A_2 B A_1\cup B A_1\cup A_2 B B= \{b_1, b_2, b_3, b_4, \dots, b_j \}\quad j\in\mathbb{N}_0 f(n)=\begin{cases}
b_n\quad n\leq j\\
a_{n-j}\quad n> j
\end{cases} B f(n)=\begin{cases}
b_{\frac n2}\quad n\text{ even}\\
a_{\frac{n+1}{2}}\quad n\text{ odd}
\end{cases} n= k\geq 2 A_1\cup A_2\cup A_3 \cup \dots A_k (A_1\cup A_2\cup A_3 \cup \dots A_k)\cup A_{k+1} n\in\mathbb{N}.\qquad\square","['elementary-set-theory', 'solution-verification', 'proof-writing']"
82,Is this composition associative?,Is this composition associative?,,"Given a set $X=\{1,\dots,n\}$. In Dempster–Shafer theory a BBA is a function $m:\mathcal P(X)\to[0,1]$, with the two properties that $m(\emptyset)=0$ and $\sum_{A\subseteq X}m(A)=1$. The Dempster's rule of combination of two BBAs is defined $(m_1\oplus m_2)(\emptyset)=0$ and $(m_1\oplus m_2)(A)=\frac{1}{1-K}\sum_{B\cap C=A}m_1(B)m_2(C)$, where  $K=\sum_{B\cap C=\emptyset}m_1(B)m_2(C)$. My question is if this composition of BBAs is associative. I can't find anything anywhere about that.","Given a set $X=\{1,\dots,n\}$. In Dempster–Shafer theory a BBA is a function $m:\mathcal P(X)\to[0,1]$, with the two properties that $m(\emptyset)=0$ and $\sum_{A\subseteq X}m(A)=1$. The Dempster's rule of combination of two BBAs is defined $(m_1\oplus m_2)(\emptyset)=0$ and $(m_1\oplus m_2)(A)=\frac{1}{1-K}\sum_{B\cap C=A}m_1(B)m_2(C)$, where  $K=\sum_{B\cap C=\emptyset}m_1(B)m_2(C)$. My question is if this composition of BBAs is associative. I can't find anything anywhere about that.",,"['functions', 'elementary-set-theory', 'reference-request', 'bayesian', 'associativity']"
83,Notation for function spaces,Notation for function spaces,,"I'd like to have suggestions (maybe existing well-established practice?) for rigorous notation of certain operations on functions and function spaces (with the category of sets in mind, so no additional implied structure). Notes: the requested notation is intended to be used in / processed by a computer system (as opposed to human reading only); therefore, it needs to be 100% accurate and must be fully explicit and unambiguous (cannot use implied contextual information, for example) the term ""function"" is used in the category theory sense, i.e. each function's definition includes the domain, the codomain and the graph of the function. Two functions are considered identical iff all three of the above are identical. (In fact, defining the graph establishes the domain as well, but it is customary to have it separately anyway. However, for a given graph, all sorts of different codomains may be chosen, each yielding a different function in the intended sense.) I know that some of the guys here have an urge to respond to such questions with ""use whatever you like but define your notation"". I am well aware of that, but the reason for asking a community is to find notation which is intuitive and not arbitrary, so I would appreciate actual suggestions, if possible. Spaces These are the spaces I need notation for: (1) Set of functions with given domain $X$ and codomain $Y$ . This is the most basic one. Note that only functions with domain / codomain matching exactly should be included. Existing notation that may be considered: $X \rightarrow Y$ , $X \longrightarrow Y$ , $Y^X$ . The shorter arrow is used as a logical operator for implication, so the longer arrow is preferred. (2) Set of functions with given domain $X$ , and codomain $Y ^\prime \subset Y$ (for given $Y$ ) . Very similar in concept to (1). In practice, it is customary not to make a difference at all between (1) and (2). However, because of the nature of the use case, a different notation is required, as the sets defined by (1) and (2) are different sets. (3) Same as (2) but limited to functions that are surjective to their own codomain. This is an important practical concept: the set constructed this way essentially has a ""canonical"" representant member for all graphs mapping $X$ to $Y$ (namely, the function whose codomain is equal to its image). (2) does not have this property: any given graph (unless surjective to the whole $Y$ ) will have different representants (by choosing $Y^\prime$ to be a set containing the image, each such $Y^\prime$ will yield a different function by definition) Union of functions (4) Given two functions, $f : X \longrightarrow Y$ and $g : Z \longrightarrow W$ , one can take the pairwise union of the domains, the codomains and the graphs. However, the ""object"" constructed this way is not necessarily a function. Therefore, the notation $f \cup g$ is not expressive enough in all scenarios. There are three possible scenarios and maybe required notations: (4a) ""disjoint function union"" : operator which is only valid if the domains of $f$ and $g$ are disjoint. Maybe something like $f \sqcup g$ ? (4b) ""matching function union"" : this operator would yield a valid value if $f$ and $g$ are identical on the intersection $X \cap Z$ . Maybe something like $f ⊍ g$ ? (4c) ""overriding function union"" : this operator would always yield a function. On the intersection of the domains, $g$ would ""override"" $f$ (I know wikipedia suggests the circled plus operator for this, but, frankly, I have never met anyone using that operator for this purpose) Union Space (5) In practical scenarios it would be nice to construct the following space as well: given an arbitrary $X = \lbrace x_1, x_2, \ldots, x_n \rbrace$ , and arbitrary sets $Y_1, Y_2,\ldots, Y_n$ , the set of functions that contains all $f$ such that the domain of $f$ is $X$ , the graph satisfies $\forall i f(x_i) \in Y_i$ , and the codomain of f is equal to the range of $f$ . Note that $X$ is finite in practice but $Y_i$ can be any set. Of course, this can be naturally extended to infinite $X$ as well. Extension of the codomain of a function We all know the notation for restriction : for the function $f:D \longrightarrow C$ and any $D^\prime \subset D$ , the notation $f|_{D^\prime}$ defines a new function $f|_{D^\prime}:D^\prime \longrightarrow C$ , with the graph of this new function being equal to $f \cap (D^\prime \times C)$ . (6) A very similar concept would be to extend the codomain, i.e. for a function $f:D \longrightarrow C$ and any $C^\prime \supset C$ , we can construct the new function, which has the same graph as $f$ , but the codomain is extended to be $C^\prime$ . I have never seen notation for that, though.","I'd like to have suggestions (maybe existing well-established practice?) for rigorous notation of certain operations on functions and function spaces (with the category of sets in mind, so no additional implied structure). Notes: the requested notation is intended to be used in / processed by a computer system (as opposed to human reading only); therefore, it needs to be 100% accurate and must be fully explicit and unambiguous (cannot use implied contextual information, for example) the term ""function"" is used in the category theory sense, i.e. each function's definition includes the domain, the codomain and the graph of the function. Two functions are considered identical iff all three of the above are identical. (In fact, defining the graph establishes the domain as well, but it is customary to have it separately anyway. However, for a given graph, all sorts of different codomains may be chosen, each yielding a different function in the intended sense.) I know that some of the guys here have an urge to respond to such questions with ""use whatever you like but define your notation"". I am well aware of that, but the reason for asking a community is to find notation which is intuitive and not arbitrary, so I would appreciate actual suggestions, if possible. Spaces These are the spaces I need notation for: (1) Set of functions with given domain and codomain . This is the most basic one. Note that only functions with domain / codomain matching exactly should be included. Existing notation that may be considered: , , . The shorter arrow is used as a logical operator for implication, so the longer arrow is preferred. (2) Set of functions with given domain , and codomain (for given ) . Very similar in concept to (1). In practice, it is customary not to make a difference at all between (1) and (2). However, because of the nature of the use case, a different notation is required, as the sets defined by (1) and (2) are different sets. (3) Same as (2) but limited to functions that are surjective to their own codomain. This is an important practical concept: the set constructed this way essentially has a ""canonical"" representant member for all graphs mapping to (namely, the function whose codomain is equal to its image). (2) does not have this property: any given graph (unless surjective to the whole ) will have different representants (by choosing to be a set containing the image, each such will yield a different function by definition) Union of functions (4) Given two functions, and , one can take the pairwise union of the domains, the codomains and the graphs. However, the ""object"" constructed this way is not necessarily a function. Therefore, the notation is not expressive enough in all scenarios. There are three possible scenarios and maybe required notations: (4a) ""disjoint function union"" : operator which is only valid if the domains of and are disjoint. Maybe something like ? (4b) ""matching function union"" : this operator would yield a valid value if and are identical on the intersection . Maybe something like ? (4c) ""overriding function union"" : this operator would always yield a function. On the intersection of the domains, would ""override"" (I know wikipedia suggests the circled plus operator for this, but, frankly, I have never met anyone using that operator for this purpose) Union Space (5) In practical scenarios it would be nice to construct the following space as well: given an arbitrary , and arbitrary sets , the set of functions that contains all such that the domain of is , the graph satisfies , and the codomain of f is equal to the range of . Note that is finite in practice but can be any set. Of course, this can be naturally extended to infinite as well. Extension of the codomain of a function We all know the notation for restriction : for the function and any , the notation defines a new function , with the graph of this new function being equal to . (6) A very similar concept would be to extend the codomain, i.e. for a function and any , we can construct the new function, which has the same graph as , but the codomain is extended to be . I have never seen notation for that, though.","X Y X \rightarrow Y X \longrightarrow Y Y^X X Y ^\prime \subset Y Y X Y Y Y^\prime Y^\prime f : X \longrightarrow Y g : Z \longrightarrow W f \cup g f g f \sqcup g f g X \cap Z f ⊍ g g f X = \lbrace x_1, x_2, \ldots, x_n \rbrace Y_1, Y_2,\ldots, Y_n f f X \forall i f(x_i) \in Y_i f X Y_i X f:D \longrightarrow C D^\prime \subset D f|_{D^\prime} f|_{D^\prime}:D^\prime \longrightarrow C f \cap (D^\prime \times C) f:D \longrightarrow C C^\prime \supset C f C^\prime","['functions', 'elementary-set-theory', 'notation']"
84,Multiplication cancellation property by Peano axioms,Multiplication cancellation property by Peano axioms,,"I am trying to prove cancellation property of multiplication of natural numbers, $xy=xz$ implies $y=z$, with Peano axioms and arithmetic but not using or defining order on natural numbers. It can be done for addition. But for proving multiplication cancellation property one uses order. Why is that so?","I am trying to prove cancellation property of multiplication of natural numbers, $xy=xz$ implies $y=z$, with Peano axioms and arithmetic but not using or defining order on natural numbers. It can be done for addition. But for proving multiplication cancellation property one uses order. Why is that so?",,['peano-axioms']
85,Books on logic and ZFC set theory for physicist,Books on logic and ZFC set theory for physicist,,"I am undergraduate student in physics with not that many mathematics courses done in my career. Nevertheless, I am very interested in mathematical physics. I started studying from the lectures ""Geometrical anatomy of theoretical physics"" which can be found at https://youtu.be/V49i_LM8B0E . From the lectures I have gained some sort of intuition but I feel that for my satisfaction I want to learn a little bit more. For you to better understand my interests, I want to mention what kind of things I would like to learn next. The general idea is that I do not want to go very deep in these exciting and interesting topics but I want to know enough so that I can learn topics like topology, manifolds, bundles and so on that are necessary for physics without stumbling across things that come from logic or set theory. For example, while I can prove basic things in topology (which basically just use set-theoretical arguments), I am sometimes dissatisfied because I can prove things ""intuitively"" but if some day I wanted to make my proofs formal, I am afraid that I couldn't. This is certainly something I would like to change. Propositional and predicate logic. Proofs and rules of inference. I feel satisfied with classical logic which defined proposition and predicate in an intuitive way and which defined operators using truth tables. This is enough rigor for me and I am willing to accept this. I am also willing to accept the philosophy that logic goes first and then I use it to tell what set theory is. The thing I have the most problems with in logic is how to make formal proof. In the lectures I heard the recipe (proof is sequence of propositions which are either axioms, tautologies or ""modus ponens""), but I have trouble proving many things as I am unsure if I am doing it right. I would be happy for some reference that could show some examples on how to make formal proofs, so that I would have a nice feeling that if someone in the future would not believe my proof then I could go back to logic and write a nice, billion lines long formal proof. ZFC set theory. My whole life I have been using ""naive set theory"" without a doubt but once I got introduced to Russell's paradox I feel uneasy about it. That is indeed possible that in my whole physics career I will always be able to prove and write everything in terms of naive set theory, but something just feels wrong. That being said, I would like to receive some reference about ZFC set theory for beginners. I am not interested in some deep topics in the set theory - I just want to be sure that I know what axioms are (that are now considered to be consistent) so that I could consult them whenever I get too confused in my mathematical journey. I would appreciate any suggestions and/or comments from your personal experience!","I am undergraduate student in physics with not that many mathematics courses done in my career. Nevertheless, I am very interested in mathematical physics. I started studying from the lectures ""Geometrical anatomy of theoretical physics"" which can be found at https://youtu.be/V49i_LM8B0E . From the lectures I have gained some sort of intuition but I feel that for my satisfaction I want to learn a little bit more. For you to better understand my interests, I want to mention what kind of things I would like to learn next. The general idea is that I do not want to go very deep in these exciting and interesting topics but I want to know enough so that I can learn topics like topology, manifolds, bundles and so on that are necessary for physics without stumbling across things that come from logic or set theory. For example, while I can prove basic things in topology (which basically just use set-theoretical arguments), I am sometimes dissatisfied because I can prove things ""intuitively"" but if some day I wanted to make my proofs formal, I am afraid that I couldn't. This is certainly something I would like to change. Propositional and predicate logic. Proofs and rules of inference. I feel satisfied with classical logic which defined proposition and predicate in an intuitive way and which defined operators using truth tables. This is enough rigor for me and I am willing to accept this. I am also willing to accept the philosophy that logic goes first and then I use it to tell what set theory is. The thing I have the most problems with in logic is how to make formal proof. In the lectures I heard the recipe (proof is sequence of propositions which are either axioms, tautologies or ""modus ponens""), but I have trouble proving many things as I am unsure if I am doing it right. I would be happy for some reference that could show some examples on how to make formal proofs, so that I would have a nice feeling that if someone in the future would not believe my proof then I could go back to logic and write a nice, billion lines long formal proof. ZFC set theory. My whole life I have been using ""naive set theory"" without a doubt but once I got introduced to Russell's paradox I feel uneasy about it. That is indeed possible that in my whole physics career I will always be able to prove and write everything in terms of naive set theory, but something just feels wrong. That being said, I would like to receive some reference about ZFC set theory for beginners. I am not interested in some deep topics in the set theory - I just want to be sure that I know what axioms are (that are now considered to be consistent) so that I could consult them whenever I get too confused in my mathematical journey. I would appreciate any suggestions and/or comments from your personal experience!",,"['elementary-set-theory', 'logic', 'reference-request', 'book-recommendation']"
86,Is $f(x) = x^2$ surjective on $\mathbb N$? Improving proof notation,Is  surjective on ? Improving proof notation,f(x) = x^2 \mathbb N,"Definition of surjective: Let $A$ and $B$ be sets and let $f: A → B$ be a function. $f$ is surjective if for each $b ∈ B$ there is some $a ∈ A$ such that $f(a) = b$ Solution attempt: In this case, $f(x) = x^2$,  $A$ and $B$ are both $\mathbb N$ $f: A → B$ $f: ℕ → ℕ$ Let $b = 3$ There is no $a ∈ ℕ$ s.t. $f(a) = a^2 = b $ Therefore $f(x) = x^2$ is not surjective on $ℕ$ Is this proof correct?, and if so, what notation can I use to make the distinction between an element of $ℕ$ as a pre-image and another as image of that element. In this case solved as ""$a$"" being a pre-image of $f: ℕ → ℕ$ and ""$b$"" the image of a on $f$.","Definition of surjective: Let $A$ and $B$ be sets and let $f: A → B$ be a function. $f$ is surjective if for each $b ∈ B$ there is some $a ∈ A$ such that $f(a) = b$ Solution attempt: In this case, $f(x) = x^2$,  $A$ and $B$ are both $\mathbb N$ $f: A → B$ $f: ℕ → ℕ$ Let $b = 3$ There is no $a ∈ ℕ$ s.t. $f(a) = a^2 = b $ Therefore $f(x) = x^2$ is not surjective on $ℕ$ Is this proof correct?, and if so, what notation can I use to make the distinction between an element of $ℕ$ as a pre-image and another as image of that element. In this case solved as ""$a$"" being a pre-image of $f: ℕ → ℕ$ and ""$b$"" the image of a on $f$.",,"['elementary-set-theory', 'proof-verification']"
87,Axiom of Dependent Choice implies Axiom of Countable Choice,Axiom of Dependent Choice implies Axiom of Countable Choice,,"I have formalized Noah Schweber's idea to prove that Axiom of Dependent Choice implies Axiom of Countable Choice, but I'm not sure if my below proof is correct or not. Please have a look and check! Thank you for your help! Axiom of Dependent Choice Let $T \neq\varnothing$ and $\mathcal{R} \subseteq T^2$ such that $\forall a \in T, \exists b \in T: a\mathcal{R}b$. Then there exists $(x_n \mid n \in \mathbb N)$ such that $x_n \mathcal{R} x_{n+1}$. Axiom of Countable Choice Let $(A_n \mid n \in \mathbb N)$ be a sequence of non-empty sets and $X=\bigcup_{n \in \mathbb N} A_n$. Then there exists a mapping $f: \mathbb N \to X$ such that $f(n) \in A_n$. Here is my take: Let $\mathcal{R}=\{(x,y) \in X^2 \mid \exists n \in \mathbb N \text{ such that } x \in A_n \text{ and } y \in A_{n+1} \}$. Clearly, $\mathcal{R}$ satisfies the requirement of DC. Hence there is a sequence $(x_i \mid i \in \mathbb N)$ where for some $n,x_i \in A_{i+n}$ $\forall i \in \mathbb N$. Let $f: \mathbb N \to X$ in which $f(i) \in A_i$ $\forall i<n$ and $f(i)=x_{i−n}$ $ \forall i \geqslant n$. Defining $f$ in this way, we have the desired function.","I have formalized Noah Schweber's idea to prove that Axiom of Dependent Choice implies Axiom of Countable Choice, but I'm not sure if my below proof is correct or not. Please have a look and check! Thank you for your help! Axiom of Dependent Choice Let $T \neq\varnothing$ and $\mathcal{R} \subseteq T^2$ such that $\forall a \in T, \exists b \in T: a\mathcal{R}b$. Then there exists $(x_n \mid n \in \mathbb N)$ such that $x_n \mathcal{R} x_{n+1}$. Axiom of Countable Choice Let $(A_n \mid n \in \mathbb N)$ be a sequence of non-empty sets and $X=\bigcup_{n \in \mathbb N} A_n$. Then there exists a mapping $f: \mathbb N \to X$ such that $f(n) \in A_n$. Here is my take: Let $\mathcal{R}=\{(x,y) \in X^2 \mid \exists n \in \mathbb N \text{ such that } x \in A_n \text{ and } y \in A_{n+1} \}$. Clearly, $\mathcal{R}$ satisfies the requirement of DC. Hence there is a sequence $(x_i \mid i \in \mathbb N)$ where for some $n,x_i \in A_{i+n}$ $\forall i \in \mathbb N$. Let $f: \mathbb N \to X$ in which $f(i) \in A_i$ $\forall i<n$ and $f(i)=x_{i−n}$ $ \forall i \geqslant n$. Defining $f$ in this way, we have the desired function.",,"['elementary-set-theory', 'proof-verification', 'axiom-of-choice']"
88,Limit Supremum of Sets and Functions,Limit Supremum of Sets and Functions,,"Let $f:X\longrightarrow Y$ be a function, $A,A_1,A_2$ subsets of $X$ and $B,B_1,B_2$ be subsets of $Y$1 Prove that $f(\lim\sup A_n)\subset \lim\sup f(A_n)$. $\textbf{Proof:}$ Assume $y\in f(\lim\sup A_n).$ Then $\exists x\in\lim\sup A_n$ such that $y=f(x)$ I know my ultimate goal here is to show that $y\in\lim\sup f(A_n)$ but im not sure how to go about proceeding to the next step. What does it mean for the existence of $x\in\lim\sup A_n$? Please help on proceeding to the next step.","Let $f:X\longrightarrow Y$ be a function, $A,A_1,A_2$ subsets of $X$ and $B,B_1,B_2$ be subsets of $Y$1 Prove that $f(\lim\sup A_n)\subset \lim\sup f(A_n)$. $\textbf{Proof:}$ Assume $y\in f(\lim\sup A_n).$ Then $\exists x\in\lim\sup A_n$ such that $y=f(x)$ I know my ultimate goal here is to show that $y\in\lim\sup f(A_n)$ but im not sure how to go about proceeding to the next step. What does it mean for the existence of $x\in\lim\sup A_n$? Please help on proceeding to the next step.",,['elementary-set-theory']
89,Prove that if $\mathcal P(A) \cup \mathcal P(B)= \mathcal P(A\cup B)$ then either $A \subseteq B$ or $B \subseteq A$. [duplicate],Prove that if  then either  or . [duplicate],\mathcal P(A) \cup \mathcal P(B)= \mathcal P(A\cup B) A \subseteq B B \subseteq A,"This question already has answers here : Stuck with proof for $\forall A\forall B(\mathcal{P}(A)\cup\mathcal{P}(B)=\mathcal{P}(A\cup B)\rightarrow A\subseteq B \vee B\subseteq A)$ (3 answers) Closed 11 years ago . Prove that for any sets $A$ or $B$, if $\mathcal P(A) \cup \mathcal P(B)= \mathcal P(A\cup B)$ then either $A \subseteq B$ or $B \subseteq A$. ($\mathcal P$ is the power set.) I'm having trouble making any progress with this proof at all. I've assumed that $\mathcal P(A) \cup \mathcal P(B)= \mathcal P(A\cup B)$, and am trying to figure out some cases I can use to help me prove that either $A \subseteq B$ or $B \subseteq A$. The statement that $\mathcal P(A) \cup \mathcal P(B)= \mathcal P(A\cup B)$ seems to be somewhat useless though. I can't seem to make any inferences with it that yield any new information about any of the sets it applies to or elements therein. The only ""progress"" I seem to be able to make is that I can conclude that $A \subseteq A \cup B$, or that $B \subseteq A \cup B$, but I don't think this gives me anything I don't already know. I've tried going down the contradiction path as well but I haven't been able to find anything there either. I feel like I am missing something obvious here though...","This question already has answers here : Stuck with proof for $\forall A\forall B(\mathcal{P}(A)\cup\mathcal{P}(B)=\mathcal{P}(A\cup B)\rightarrow A\subseteq B \vee B\subseteq A)$ (3 answers) Closed 11 years ago . Prove that for any sets $A$ or $B$, if $\mathcal P(A) \cup \mathcal P(B)= \mathcal P(A\cup B)$ then either $A \subseteq B$ or $B \subseteq A$. ($\mathcal P$ is the power set.) I'm having trouble making any progress with this proof at all. I've assumed that $\mathcal P(A) \cup \mathcal P(B)= \mathcal P(A\cup B)$, and am trying to figure out some cases I can use to help me prove that either $A \subseteq B$ or $B \subseteq A$. The statement that $\mathcal P(A) \cup \mathcal P(B)= \mathcal P(A\cup B)$ seems to be somewhat useless though. I can't seem to make any inferences with it that yield any new information about any of the sets it applies to or elements therein. The only ""progress"" I seem to be able to make is that I can conclude that $A \subseteq A \cup B$, or that $B \subseteq A \cup B$, but I don't think this gives me anything I don't already know. I've tried going down the contradiction path as well but I haven't been able to find anything there either. I feel like I am missing something obvious here though...",,"['elementary-set-theory', 'proof-writing']"
90,Prove that $f(\limsup A_n)\subset \limsup f(A_n)$.,Prove that .,f(\limsup A_n)\subset \limsup f(A_n),Prove that $f(\limsup A_n)\subset \limsup f(A_n)$. Give an example where $f(\limsup A_n)\neq \limsup f(A_n)$. I guess where I'm having trouble with this is what exactly does it mean to $f(\limsup A_n)$. I know what the $\limsup A_n$ but when it turns into a function then I dont know where to go from there.,Prove that $f(\limsup A_n)\subset \limsup f(A_n)$. Give an example where $f(\limsup A_n)\neq \limsup f(A_n)$. I guess where I'm having trouble with this is what exactly does it mean to $f(\limsup A_n)$. I know what the $\limsup A_n$ but when it turns into a function then I dont know where to go from there.,,"['real-analysis', 'elementary-set-theory']"
91,set-theoretic difference of multisets,set-theoretic difference of multisets,,"What is the result of $A \backslash B$ , if $A$ and $B$ are multisets? For instance, if $A = \{1,1,3\}$ and $B = \{1,2\}$, would the result of $A \backslash B$ be $\{1,3\}$ or $\{3\}$?","What is the result of $A \backslash B$ , if $A$ and $B$ are multisets? For instance, if $A = \{1,1,3\}$ and $B = \{1,2\}$, would the result of $A \backslash B$ be $\{1,3\}$ or $\{3\}$?",,['elementary-set-theory']
92,"Show that for each $k\in\Bbb{N}$, $\Bbb{N}_k$ is finite","Show that for each ,  is finite",k\in\Bbb{N} \Bbb{N}_k,"So, I'm studying mathematics on my own and I took a book about Proofs in Abstract Mathematics with the following exercise: For each $k\in\Bbb{N}$ we have that $\Bbb{N}_k$ is finite Just to give some context on what theorems and definitions we can use: Definition: $\Bbb{N}_k = \{1, 2, ..., k \} $ Definition: A set $S$ is infinite iff there exists a one-to-one but not onto $\ f:S\to S$ Definition: $A\sim B$ means $A$ is equipotent to (or same cardinality of) $B$ Theorem: if $A$ is infinite and $A\sim B$, then $B$ is infinite Theorem: if $A$ is infinite and $f:A\to B$ is one-to-one, then $B$ is infinite Theorem: Let $\ f:A \to B$ be one-to-one and $C\subseteq A$ then $\ g:C \to B$, $\ g(x)=f(x)\ $ for any $\ x\in C$, is also one-to-one Lemma: Let $k\in\Bbb{N}$, then $\Bbb{N}_k- \{x\} \sim \Bbb{N}_{k-1}$ for any $x\in \Bbb{N}_k$ What I did was: Suppose that $\Bbb{N}_K$ is not finite for every $k\in\Bbb{N}$, then by the Well-Ordering Principle, there is a smallest element $k\in\Bbb{N}$ such that $\Bbb{N}_k$ is infinite. Let $x_0\in\Bbb{N}_k\ $ be the smallest element of $\Bbb{N}_k$ and define $C=\Bbb{N}_k - \{x_0\}$. Let $f:\Bbb{N}_k \to C\ $ be $\ f(n)=n+1$.  We will prove that $f$ is one-to-one. Let $x_1,x_2\in\Bbb{N}_k$ such that $f(x_1)=f(x_2)$, then $x_1+1=x_2+1$. Hence $x_1=x_2$, what proves that $f$ is one-to-one. Thus we have that $C$ is infinite. Then $C\sim \Bbb{N}_{k-1}$ and thus we must have that $\Bbb{N}_{k-1}$ is infinite. However this contradicts our hypothesis that $k$ is the least element such that $\Bbb{N}_k$ is infinite. Thus it must be that for each $k\in \Bbb{N}$ we have $\Bbb{N}_k$ is finite. My question is if the proof above, especially when creating the function $f:\Bbb{N}_k\to C$ has any flaw. The book explicitly says we should use the 6th theorem listed above, but I didn't find any explicitly use of it. Maybe is there another way to prove it? Edited: As some of you commented, the proof above was wrong. The function I created was not defined to $k+1$. I think this one is correct: If $\Bbb{N}_k$ is not finite for every $k \in \Bbb{N}$, then by the Well-Ordering principle there exists a least element $k \in \Bbb{N}$ such that $\Bbb{N}_k$ is infinite. By definition, there exists $f:\Bbb{N}_k \to \Bbb{N}_k$ such that $f$ is one-to-one but not onto. Then, because $f$ is not onto, there exists $y\in\Bbb{N}_k$ such that $y\neq f(x)$ for every $x\in \Bbb{N}_k$. Pick $x_0\neq y$ and define $A=\Bbb{N}_k-\{x_0\}$. Let $g:A\to A$ be defined as: $$g(x)= \begin{cases} f(x) \ if \ f(x)\neq x_0 \\ f(x_0) \ if \ f(x) = x_0 \end{cases}$$ We will prove that $g$ is one-to-one but not onto. First we show $g$ is one-to-one. Let $x_1,x_2 \in A$ such that $x_1\neq x_2$. Since $f$ is one-to-one, $f(x_1)\neq f(x_2)$. If $f(x_1)=x_0$, then  $f(x_2)\neq x_0$. Hence $g(x_1)=f(x_0)$ and $g(x_2)=f(x_2)$. Since $x_0\neq x_2$, then $f(x_0)\neq f(x_2)$ and thus $g(x_1)\neq g(x_2)$. Without loss of generality, if $f(x_2)=x_0$, then $g(x_1)\neq g(x_2)$. If $f(x_1)\neq x_0$ and $f(x_1)\neq x_0$, then $g(x_1)=f(x_1)$ and $g(x_2)=f(x_2)$. Hence $g(x_1)\neq g(x_2)$. We have that $g$ is one-to-one. We now show that $g$ is not onto. Note that, because $x_0\neq y$, such that $y\neq f(x)$ for all $x\in\Bbb{N}_k$, we have $y\in A=\Bbb{N}_k-\{x_0\}$. Let $x\in A$. If $f(x)=x_0$, then $g(x)=f(x_0)\neq y$. If $f(x)\neq x_0$, then $g(x)=f(x)\neq y$. Hence there exists $y \in A$ such that for any $x \in A$ we have $g(x)\neq y$. Thus, $g$ is not onto. We have demonstrated that $g:A\to A$ is one-to-one, but not onto, hence A is infinite by definition. Giving that $A=\Bbb{N}_k-\{x_0\}$ and our lemma, we have that $\Bbb{N}_{k-1}$ is also infinite. However this contradicts our hypothesis that $k$ is the smallest element such that $\Bbb{N}_k$ is infinite. Hence it must be that for every $k\in\Bbb{N}$ we have $\Bbb{N}_k$ is finite. Sorry if my proof writing is bad in anyway. If you have any stylistic suggestion, or any suggestion at all, I would gladly read it :)","So, I'm studying mathematics on my own and I took a book about Proofs in Abstract Mathematics with the following exercise: For each $k\in\Bbb{N}$ we have that $\Bbb{N}_k$ is finite Just to give some context on what theorems and definitions we can use: Definition: $\Bbb{N}_k = \{1, 2, ..., k \} $ Definition: A set $S$ is infinite iff there exists a one-to-one but not onto $\ f:S\to S$ Definition: $A\sim B$ means $A$ is equipotent to (or same cardinality of) $B$ Theorem: if $A$ is infinite and $A\sim B$, then $B$ is infinite Theorem: if $A$ is infinite and $f:A\to B$ is one-to-one, then $B$ is infinite Theorem: Let $\ f:A \to B$ be one-to-one and $C\subseteq A$ then $\ g:C \to B$, $\ g(x)=f(x)\ $ for any $\ x\in C$, is also one-to-one Lemma: Let $k\in\Bbb{N}$, then $\Bbb{N}_k- \{x\} \sim \Bbb{N}_{k-1}$ for any $x\in \Bbb{N}_k$ What I did was: Suppose that $\Bbb{N}_K$ is not finite for every $k\in\Bbb{N}$, then by the Well-Ordering Principle, there is a smallest element $k\in\Bbb{N}$ such that $\Bbb{N}_k$ is infinite. Let $x_0\in\Bbb{N}_k\ $ be the smallest element of $\Bbb{N}_k$ and define $C=\Bbb{N}_k - \{x_0\}$. Let $f:\Bbb{N}_k \to C\ $ be $\ f(n)=n+1$.  We will prove that $f$ is one-to-one. Let $x_1,x_2\in\Bbb{N}_k$ such that $f(x_1)=f(x_2)$, then $x_1+1=x_2+1$. Hence $x_1=x_2$, what proves that $f$ is one-to-one. Thus we have that $C$ is infinite. Then $C\sim \Bbb{N}_{k-1}$ and thus we must have that $\Bbb{N}_{k-1}$ is infinite. However this contradicts our hypothesis that $k$ is the least element such that $\Bbb{N}_k$ is infinite. Thus it must be that for each $k\in \Bbb{N}$ we have $\Bbb{N}_k$ is finite. My question is if the proof above, especially when creating the function $f:\Bbb{N}_k\to C$ has any flaw. The book explicitly says we should use the 6th theorem listed above, but I didn't find any explicitly use of it. Maybe is there another way to prove it? Edited: As some of you commented, the proof above was wrong. The function I created was not defined to $k+1$. I think this one is correct: If $\Bbb{N}_k$ is not finite for every $k \in \Bbb{N}$, then by the Well-Ordering principle there exists a least element $k \in \Bbb{N}$ such that $\Bbb{N}_k$ is infinite. By definition, there exists $f:\Bbb{N}_k \to \Bbb{N}_k$ such that $f$ is one-to-one but not onto. Then, because $f$ is not onto, there exists $y\in\Bbb{N}_k$ such that $y\neq f(x)$ for every $x\in \Bbb{N}_k$. Pick $x_0\neq y$ and define $A=\Bbb{N}_k-\{x_0\}$. Let $g:A\to A$ be defined as: $$g(x)= \begin{cases} f(x) \ if \ f(x)\neq x_0 \\ f(x_0) \ if \ f(x) = x_0 \end{cases}$$ We will prove that $g$ is one-to-one but not onto. First we show $g$ is one-to-one. Let $x_1,x_2 \in A$ such that $x_1\neq x_2$. Since $f$ is one-to-one, $f(x_1)\neq f(x_2)$. If $f(x_1)=x_0$, then  $f(x_2)\neq x_0$. Hence $g(x_1)=f(x_0)$ and $g(x_2)=f(x_2)$. Since $x_0\neq x_2$, then $f(x_0)\neq f(x_2)$ and thus $g(x_1)\neq g(x_2)$. Without loss of generality, if $f(x_2)=x_0$, then $g(x_1)\neq g(x_2)$. If $f(x_1)\neq x_0$ and $f(x_1)\neq x_0$, then $g(x_1)=f(x_1)$ and $g(x_2)=f(x_2)$. Hence $g(x_1)\neq g(x_2)$. We have that $g$ is one-to-one. We now show that $g$ is not onto. Note that, because $x_0\neq y$, such that $y\neq f(x)$ for all $x\in\Bbb{N}_k$, we have $y\in A=\Bbb{N}_k-\{x_0\}$. Let $x\in A$. If $f(x)=x_0$, then $g(x)=f(x_0)\neq y$. If $f(x)\neq x_0$, then $g(x)=f(x)\neq y$. Hence there exists $y \in A$ such that for any $x \in A$ we have $g(x)\neq y$. Thus, $g$ is not onto. We have demonstrated that $g:A\to A$ is one-to-one, but not onto, hence A is infinite by definition. Giving that $A=\Bbb{N}_k-\{x_0\}$ and our lemma, we have that $\Bbb{N}_{k-1}$ is also infinite. However this contradicts our hypothesis that $k$ is the smallest element such that $\Bbb{N}_k$ is infinite. Hence it must be that for every $k\in\Bbb{N}$ we have $\Bbb{N}_k$ is finite. Sorry if my proof writing is bad in anyway. If you have any stylistic suggestion, or any suggestion at all, I would gladly read it :)",,"['elementary-set-theory', 'proof-verification', 'cardinals']"
93,Why is the set of all infinite binary sequences uncountable but the set of all natural numbers are countable? [duplicate],Why is the set of all infinite binary sequences uncountable but the set of all natural numbers are countable? [duplicate],,"This question already has an answer here : Is the set of all possible binary strings countable? (1 answer) Closed 6 years ago . From Cantor's diagonalization argument, the set B of all infinite binary sequences is uncountable. Yet, the set A of all natural numbers are countable. Is there not a one-to-one mapping from B to A ? It seems all natural numbers can be represented as a binary number (in base 2) and vice versa.","This question already has an answer here : Is the set of all possible binary strings countable? (1 answer) Closed 6 years ago . From Cantor's diagonalization argument, the set B of all infinite binary sequences is uncountable. Yet, the set A of all natural numbers are countable. Is there not a one-to-one mapping from B to A ? It seems all natural numbers can be represented as a binary number (in base 2) and vice versa.",,"['elementary-set-theory', 'infinity']"
94,Understanding a proposition about $\mathcal R$-section in ordered sets (VERY EDITED),Understanding a proposition about -section in ordered sets (VERY EDITED),\mathcal R,"The correct title must be: Proof of Theorem 90 of Appendix of Kelley's book General Topology or, Proving a theorem about $\mathcal R$-sections or Prove of this prove that proof aboutTheorem 90 of Appendix of Kelley's book General Topology . Proposition. Let $(X,\mathcal R)$ be an ordered set (or class). If $Y\subset X$ is an $\mathcal R$-section and every element $y\in Y$ is also an $\mathcal R$-section of $X$, then $\bigcup Y$ and $\bigcap Y$ are $\mathcal R$-sections of $X$. EDIT 1: The statement was misunderstood by me. The real porposition is: Let $I$ non-empty (possibly $I$ is a set). If every element $y\in I$ is an $\mathcal R$-section of $X$, then $\bigcup I$ and $\bigcap I$ are also. So the comment of @WilliamElliot is unnecesary, because in any momment we have said $I\subset X$. And probably it may be false. In my opinion, $I$ plays the role of an index set. Addendum 1. This statement corresponds to the Appendix of J. L. Kelley General Topology , Theorem 90 (p. 264). EDIT 2: Below is the rest of my question. Whit the new remarks it has no sense. My problem is that I can't understand why (or how) an element $y\in Y$ can be an $\mathcal R$-section of $X$ if $y$ is not a subset of $X$ (as least as far as I know). It would have sense for me if the text said $\{y\}$, which is actually a subset of $X$. The same applies to $\bigcup Y$ and $\bigcap Y$: by DEFINITION, both are sets (classes) formed by elements of sets in $Y$: $$ \bigcup Y= \{x:\exists y\in Y \mbox{ such that } x\in y\}\\ \bigcap Y= \{x|x\in y \;\forall y\in Y\}. $$ Again, to be an $\mathcal R$-section, we should consider $\{\bigcup Y\}$ and $\{\bigcap Y\}$. Addendum 2. (Real questions) Once I have understood the proposition, the result seems me evident. However, I don't know how how to prove it rigorously. I know I have a collection of sets $\{y:y\in I\}$ such that $$ \mbox{if } y_1,y_2\in Y \mbox{ with } y_1\neq y_2 \Longrightarrow y_1\subset y_2 \mbox{ or } y_2\subset y_1 , $$ So I actually have a descendent chain of sets $$ y\supset y' \supset y'' \supset \cdots $$ 1.- Proof for $\bigcup I$. With the above in mind, I think $bigcup I = y$ which is an $\mathcal R$-section by hypothesis. 2.- Proof for $\bigcap I$. I think the definition of $\mathcal R$-section avoids there is some $y\in I$ such that $y=\emptyset$. So I think all them has a common element, the least element $y_0$, and thus $\bigcap I$ is non-empty. Now, let $x\in X$ and $y\in\bigcap I$ with $x\mathcal R y$ and suppose $x\notin \bigcap I$. That implies that $x$ is less than the least element $y_0$. But then, $x$ wouldn't below either to $y\in I$, which is a contradiction, because $y$ was an $\mathcal R$-section$. So $\bigcap I$ is an $\mathcal R$-section. Questions about this proof: 1.- Is the proof of $bigcup I$ correct? 2.- Is the proof of $\bigcap I$ correct? 3.- In 2., do you think I need to proove $y_0\in \bigcap I$? Is there a shorter proof? 4.- If all the inclusions are proper, then is it possible to show that $\bigcap I=\{y_0\}$? Definition. Let $\mathcal R$ be a well-order in $X$. An $\mathcal R$-section is $Y\subset X$ such that if $x\in X$ and $y\in Y$ with $x\mathcal R y$, then $x\in Y$. Informally, a set (class) $Y$ is said to be an $\mathcal R$-section if there is no element in $X\setminus Y$ that precedes the elements of $Y$. Final Remark. I have prefered keep the old question and add the edits and corrections, because I think that is more proper. Sorry if it is a bad idea. Thanks a lot for your patience.","The correct title must be: Proof of Theorem 90 of Appendix of Kelley's book General Topology or, Proving a theorem about $\mathcal R$-sections or Prove of this prove that proof aboutTheorem 90 of Appendix of Kelley's book General Topology . Proposition. Let $(X,\mathcal R)$ be an ordered set (or class). If $Y\subset X$ is an $\mathcal R$-section and every element $y\in Y$ is also an $\mathcal R$-section of $X$, then $\bigcup Y$ and $\bigcap Y$ are $\mathcal R$-sections of $X$. EDIT 1: The statement was misunderstood by me. The real porposition is: Let $I$ non-empty (possibly $I$ is a set). If every element $y\in I$ is an $\mathcal R$-section of $X$, then $\bigcup I$ and $\bigcap I$ are also. So the comment of @WilliamElliot is unnecesary, because in any momment we have said $I\subset X$. And probably it may be false. In my opinion, $I$ plays the role of an index set. Addendum 1. This statement corresponds to the Appendix of J. L. Kelley General Topology , Theorem 90 (p. 264). EDIT 2: Below is the rest of my question. Whit the new remarks it has no sense. My problem is that I can't understand why (or how) an element $y\in Y$ can be an $\mathcal R$-section of $X$ if $y$ is not a subset of $X$ (as least as far as I know). It would have sense for me if the text said $\{y\}$, which is actually a subset of $X$. The same applies to $\bigcup Y$ and $\bigcap Y$: by DEFINITION, both are sets (classes) formed by elements of sets in $Y$: $$ \bigcup Y= \{x:\exists y\in Y \mbox{ such that } x\in y\}\\ \bigcap Y= \{x|x\in y \;\forall y\in Y\}. $$ Again, to be an $\mathcal R$-section, we should consider $\{\bigcup Y\}$ and $\{\bigcap Y\}$. Addendum 2. (Real questions) Once I have understood the proposition, the result seems me evident. However, I don't know how how to prove it rigorously. I know I have a collection of sets $\{y:y\in I\}$ such that $$ \mbox{if } y_1,y_2\in Y \mbox{ with } y_1\neq y_2 \Longrightarrow y_1\subset y_2 \mbox{ or } y_2\subset y_1 , $$ So I actually have a descendent chain of sets $$ y\supset y' \supset y'' \supset \cdots $$ 1.- Proof for $\bigcup I$. With the above in mind, I think $bigcup I = y$ which is an $\mathcal R$-section by hypothesis. 2.- Proof for $\bigcap I$. I think the definition of $\mathcal R$-section avoids there is some $y\in I$ such that $y=\emptyset$. So I think all them has a common element, the least element $y_0$, and thus $\bigcap I$ is non-empty. Now, let $x\in X$ and $y\in\bigcap I$ with $x\mathcal R y$ and suppose $x\notin \bigcap I$. That implies that $x$ is less than the least element $y_0$. But then, $x$ wouldn't below either to $y\in I$, which is a contradiction, because $y$ was an $\mathcal R$-section$. So $\bigcap I$ is an $\mathcal R$-section. Questions about this proof: 1.- Is the proof of $bigcup I$ correct? 2.- Is the proof of $\bigcap I$ correct? 3.- In 2., do you think I need to proove $y_0\in \bigcap I$? Is there a shorter proof? 4.- If all the inclusions are proper, then is it possible to show that $\bigcap I=\{y_0\}$? Definition. Let $\mathcal R$ be a well-order in $X$. An $\mathcal R$-section is $Y\subset X$ such that if $x\in X$ and $y\in Y$ with $x\mathcal R y$, then $x\in Y$. Informally, a set (class) $Y$ is said to be an $\mathcal R$-section if there is no element in $X\setminus Y$ that precedes the elements of $Y$. Final Remark. I have prefered keep the old question and add the edits and corrections, because I think that is more proper. Sorry if it is a bad idea. Thanks a lot for your patience.",,['elementary-set-theory']
95,Simple Probability problem with circle and triangle,Simple Probability problem with circle and triangle,,"A clock is hanging on the wall and has diameter 6cm. An isosceles triangle is inscribed with the vertices touching the rim of the clock at 9:00, 12:00, and 3:00. If a dart is thrown at the clock, assuming it's equally as likely to hit anywhere in the clock and it will definitely hit the clock, what's the probability it lands inside the triangle? I've found that the area of the circle is 9pi and that of the triangle is 9. Therefore the Probability to be in the triangle is 1/pi and the probability it lands outside the triangle is 1-1/pi.  Can somebody confirm that I have it right?","A clock is hanging on the wall and has diameter 6cm. An isosceles triangle is inscribed with the vertices touching the rim of the clock at 9:00, 12:00, and 3:00. If a dart is thrown at the clock, assuming it's equally as likely to hit anywhere in the clock and it will definitely hit the clock, what's the probability it lands inside the triangle? I've found that the area of the circle is 9pi and that of the triangle is 9. Therefore the Probability to be in the triangle is 1/pi and the probability it lands outside the triangle is 1-1/pi.  Can somebody confirm that I have it right?",,"['probability', 'elementary-set-theory']"
96,Infimum and supremum And Net,Infimum and supremum And Net,,"We know that every Partially Ordered Set has to satisfy three conditions : Reflexive Anti-Symmetric Transitive If we have the partially ordered set $S$ with a relation $R$, and $S$ also satisfies the following two conditions: For any two elements $a$ and $b$ such that  $a \subseteq S$ and  $b \subseteq S$: there is always $m \subseteq S$ where $m$ is equal to $\inf\,\{a,b\}$;   (the infimum of $a$ and $b$), and also there will be  $n \subseteq S$ where $n$ is equal to $\sup\,\{a,b\}$;   (the supremum of $a$ and $b$) In this case, does the set $S$ has a special name? Is it possible to define a net on this set? I know my question is so silly but I am beginner in this field. I also want to ask if we have  a net $N$ has been defined on a partially ordered set $S$ that satisfies the previous conditions (1, 2) AND also: Every subset of $S$ also satisfies the same conditions (1, 2), in this case,  what can we call The net $N$? Any help will mean a lot.","We know that every Partially Ordered Set has to satisfy three conditions : Reflexive Anti-Symmetric Transitive If we have the partially ordered set $S$ with a relation $R$, and $S$ also satisfies the following two conditions: For any two elements $a$ and $b$ such that  $a \subseteq S$ and  $b \subseteq S$: there is always $m \subseteq S$ where $m$ is equal to $\inf\,\{a,b\}$;   (the infimum of $a$ and $b$), and also there will be  $n \subseteq S$ where $n$ is equal to $\sup\,\{a,b\}$;   (the supremum of $a$ and $b$) In this case, does the set $S$ has a special name? Is it possible to define a net on this set? I know my question is so silly but I am beginner in this field. I also want to ask if we have  a net $N$ has been defined on a partially ordered set $S$ that satisfies the previous conditions (1, 2) AND also: Every subset of $S$ also satisfies the same conditions (1, 2), in this case,  what can we call The net $N$? Any help will mean a lot.",,"['elementary-set-theory', 'relations', 'order-theory', 'nets']"
97,How can a class not be a set? [duplicate],How can a class not be a set? [duplicate],,"This question already has answers here : What are the differences between class, set, family, and collection? (3 answers) Closed 6 years ago . I just read on this wikipedia page , about the difference between a class and a set. A class that is not a set (informally in Zermelo–Fraenkel) is called a proper class, and a class that is a set is sometimes called a small class. So apparently, there are classes that are not sets. However, in the definition of class on the same page it says: a class is a collection of sets (or sometimes other mathematical objects) that can be unambiguously defined by a property that all its members share. If we take collection to be a synonym of set, then these two statements contradict eachother . I don't see the difference between ""collection"" and ""set"" . So my question is: How can a class not be a set, if it is defined to be a ""collection"" (i.e. set) of objects based on a well defined property?","This question already has answers here : What are the differences between class, set, family, and collection? (3 answers) Closed 6 years ago . I just read on this wikipedia page , about the difference between a class and a set. A class that is not a set (informally in Zermelo–Fraenkel) is called a proper class, and a class that is a set is sometimes called a small class. So apparently, there are classes that are not sets. However, in the definition of class on the same page it says: a class is a collection of sets (or sometimes other mathematical objects) that can be unambiguously defined by a property that all its members share. If we take collection to be a synonym of set, then these two statements contradict eachother . I don't see the difference between ""collection"" and ""set"" . So my question is: How can a class not be a set, if it is defined to be a ""collection"" (i.e. set) of objects based on a well defined property?",,['elementary-set-theory']
98,"Find number of binary operations on given set $S=\{a_{1},a_{2},...,a_{n}\}$",Find number of binary operations on given set,"S=\{a_{1},a_{2},...,a_{n}\}","Let $S=\{a_{1},a_{2},...,a_{n}\}$ (i)Find number of binary relations $(*)$ on $S$ which are commutative. (ii)Find number of binary relations on $S$ such that $a_{i}*a_{j}\neq a_{i}*a_{k},\forall j\neq k.$ (iii)Let $a_{1},a_{2},...,a_{n}$ be the distinct real numbers,then find total number of binary relations on $S$ such that $a_{i}*a_{j}\leq a_{i}*a_{j+1}\forall i,j$ My Attempt : (i)Total number of pairs $(a_{i}*a_{j})$ possible are $\binom{n}{2}+n$ i.e.$\frac{n^2+n}{2}$. Each pair has $n$ choices. So number of binary relations should be $n^{\left(\frac{n^2+n}{2}\right)}$. But how many of these will be commutative. (ii)Now, $(a_{i}*a_{1})$ has $n$ choices so  $(a_{i}*a_{2})$ has $(n-1)$ choices and ....so on. So $(a_{i}*a_{j})$ has $n!$ choices. So for all $i$ required number of binary relations should be $(n!)^n$ (iii)How to define $*$ if $\leq$ is to be invoked.","Let $S=\{a_{1},a_{2},...,a_{n}\}$ (i)Find number of binary relations $(*)$ on $S$ which are commutative. (ii)Find number of binary relations on $S$ such that $a_{i}*a_{j}\neq a_{i}*a_{k},\forall j\neq k.$ (iii)Let $a_{1},a_{2},...,a_{n}$ be the distinct real numbers,then find total number of binary relations on $S$ such that $a_{i}*a_{j}\leq a_{i}*a_{j+1}\forall i,j$ My Attempt : (i)Total number of pairs $(a_{i}*a_{j})$ possible are $\binom{n}{2}+n$ i.e.$\frac{n^2+n}{2}$. Each pair has $n$ choices. So number of binary relations should be $n^{\left(\frac{n^2+n}{2}\right)}$. But how many of these will be commutative. (ii)Now, $(a_{i}*a_{1})$ has $n$ choices so  $(a_{i}*a_{2})$ has $(n-1)$ choices and ....so on. So $(a_{i}*a_{j})$ has $n!$ choices. So for all $i$ required number of binary relations should be $(n!)^n$ (iii)How to define $*$ if $\leq$ is to be invoked.",,"['elementary-set-theory', 'relations']"
99,The possible number of elements in a convex set,The possible number of elements in a convex set,,"Let $(X,\|\cdot \|)$ be a normed space over $\mathbb{K}$ ($\mathbb{R}$ or $\mathbb{C}$), and let $M\subseteq X$ be a subspace. Let $\phi\in \mathcal L(M,\mathbb{K})$, and let $A$ be the set of all bounded linear functionals $f$ such that $f|_M=\phi$ and $\|f\|=\|\phi\|$. What is the possible number of elements in $A$? Hint: Show that $A$ is a non-empty convex set, and use it to determine the possible number. What I did : First, I have proven that $A$ is a non-empty convex set. I am not sure how to determine the possible number. Pick $f_1,f_2\in A$ and let $\alpha\in [0,1]$, and write $f_3=\alpha f_1+(1-\alpha) f_2$.  If $f_1=f_2$, then $f_3=f_1$ is the only map in $A$, ie. it is unique, so $A$ must be finite if each element in $A$ are equal to some other. If $f_1\neq f_2$, then $f_3=\alpha f_1+(1-\alpha) f_2$ belongs to $A$ and it is not unique. There are infinitely many such maps, so $A$ is infinite, if at least one of the elements in $A$ is not equal to the rest. If my reason is correct, is there a better/rigorious way to formulate?","Let $(X,\|\cdot \|)$ be a normed space over $\mathbb{K}$ ($\mathbb{R}$ or $\mathbb{C}$), and let $M\subseteq X$ be a subspace. Let $\phi\in \mathcal L(M,\mathbb{K})$, and let $A$ be the set of all bounded linear functionals $f$ such that $f|_M=\phi$ and $\|f\|=\|\phi\|$. What is the possible number of elements in $A$? Hint: Show that $A$ is a non-empty convex set, and use it to determine the possible number. What I did : First, I have proven that $A$ is a non-empty convex set. I am not sure how to determine the possible number. Pick $f_1,f_2\in A$ and let $\alpha\in [0,1]$, and write $f_3=\alpha f_1+(1-\alpha) f_2$.  If $f_1=f_2$, then $f_3=f_1$ is the only map in $A$, ie. it is unique, so $A$ must be finite if each element in $A$ are equal to some other. If $f_1\neq f_2$, then $f_3=\alpha f_1+(1-\alpha) f_2$ belongs to $A$ and it is not unique. There are infinitely many such maps, so $A$ is infinite, if at least one of the elements in $A$ is not equal to the rest. If my reason is correct, is there a better/rigorious way to formulate?",,"['functional-analysis', 'elementary-set-theory']"
