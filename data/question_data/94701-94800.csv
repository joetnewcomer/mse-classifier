,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Analytic function such that $f(1/n)=(-1)^n/n, n=1,2,\dots?$",Analytic function such that,"f(1/n)=(-1)^n/n, n=1,2,\dots?","Question is prove or disprove: There exists an analytic function such that  $f(1/n)=(-1)^n/n, n=1,2\dots$, with $0$ in the domain of $f.$ My attempt: If it exists, then clearly $f(z)=z^kg(z)$, where $k\ge0$ is the order of zero [or possible zero,I have included this by $k\gt0$] $z=0$ of $f(z).$Also,$g(0)\ne0$ So, $g(1/n)=f(1/n)n^k\implies g(1/n)=n^k\{\frac{(-1)^n}n\}$ Now the $\lim_{n\to\infty}\{\frac{(-1)^nn^k}n\}$ does not exist[of course,when $k\ge1$]$\implies g(0)$ doesn't exist. But this is a contradiction to my assumption that $f$ is analytic.So such an $f$ doesn't exist. And in case of $k=0$,above limit $\lim_{n\to\infty}g(1/n)=0$,which is again a contradiction. Is there something wrong in above procedure?Please guide me through if there is some.I'll appreciate any help towards this.Thanks in advance! PS:I stated that $g(0)\implies$ ""contradiction to my assumption that $f$ is analytic"".Well,I stated so because since by assumption $f$ is analytic and $z^k$ is entire[$k\ge0$],so $g$ must be analytic in the domain of $f$.","Question is prove or disprove: There exists an analytic function such that  $f(1/n)=(-1)^n/n, n=1,2\dots$, with $0$ in the domain of $f.$ My attempt: If it exists, then clearly $f(z)=z^kg(z)$, where $k\ge0$ is the order of zero [or possible zero,I have included this by $k\gt0$] $z=0$ of $f(z).$Also,$g(0)\ne0$ So, $g(1/n)=f(1/n)n^k\implies g(1/n)=n^k\{\frac{(-1)^n}n\}$ Now the $\lim_{n\to\infty}\{\frac{(-1)^nn^k}n\}$ does not exist[of course,when $k\ge1$]$\implies g(0)$ doesn't exist. But this is a contradiction to my assumption that $f$ is analytic.So such an $f$ doesn't exist. And in case of $k=0$,above limit $\lim_{n\to\infty}g(1/n)=0$,which is again a contradiction. Is there something wrong in above procedure?Please guide me through if there is some.I'll appreciate any help towards this.Thanks in advance! PS:I stated that $g(0)\implies$ ""contradiction to my assumption that $f$ is analytic"".Well,I stated so because since by assumption $f$ is analytic and $z^k$ is entire[$k\ge0$],so $g$ must be analytic in the domain of $f$.",,['complex-analysis']
1,Showing $ \int_0^{2 \pi } \frac{dt}{a^2 \cos^2 t + b^2 \sin^2 t} = \frac{2 \pi}{ab}$ [duplicate],Showing  [duplicate], \int_0^{2 \pi } \frac{dt}{a^2 \cos^2 t + b^2 \sin^2 t} = \frac{2 \pi}{ab},"This question already has answers here : Calculate the integral $\int_{0}^{2\pi}\frac{1}{a^{2}\cos^2t+b^{2}\sin^{2}t}dt$, by deformation theorem. (2 answers) Closed 9 years ago . The question: Let $\gamma$ be a contour such that $0 \in I(\gamma),$ where $I$ is the interior of the contour. Show that $$\int_\gamma z^n \, \text{d}z = \begin{cases} 2\pi i & \text{if }  n = -1 \\ 0 & \text{otherwise} \end{cases}$$ By taking $\gamma$ as the ellipse $$\{ (x,y) : \frac{x^2}{a^2} + \frac{y^2}{b^2} = 1 \},$$ show that $$ \int_0^{2 \pi } \frac{dt}{a^2 \cos^2 t + b^2 \sin^2 t} = \frac{2 \pi}{ab}.$$ The question's answer uses the Deformation theorem and the fact that the first integral has the given value if the contour is a unit circle. However, the two contours must not overlap, so it seems like this should only be true for a contour that either always has magnitude less than one or greater than one. In Mathematica, the final integral was true for the case that $a = 1.5$ and $b=0.4$. What am I missing? Edit: The radius of the circle cancels in the integral if $n = -1$, so then it does hold irrespective of the radius.","This question already has answers here : Calculate the integral $\int_{0}^{2\pi}\frac{1}{a^{2}\cos^2t+b^{2}\sin^{2}t}dt$, by deformation theorem. (2 answers) Closed 9 years ago . The question: Let $\gamma$ be a contour such that $0 \in I(\gamma),$ where $I$ is the interior of the contour. Show that $$\int_\gamma z^n \, \text{d}z = \begin{cases} 2\pi i & \text{if }  n = -1 \\ 0 & \text{otherwise} \end{cases}$$ By taking $\gamma$ as the ellipse $$\{ (x,y) : \frac{x^2}{a^2} + \frac{y^2}{b^2} = 1 \},$$ show that $$ \int_0^{2 \pi } \frac{dt}{a^2 \cos^2 t + b^2 \sin^2 t} = \frac{2 \pi}{ab}.$$ The question's answer uses the Deformation theorem and the fact that the first integral has the given value if the contour is a unit circle. However, the two contours must not overlap, so it seems like this should only be true for a contour that either always has magnitude less than one or greater than one. In Mathematica, the final integral was true for the case that $a = 1.5$ and $b=0.4$. What am I missing? Edit: The radius of the circle cancels in the integral if $n = -1$, so then it does hold irrespective of the radius.",,"['complex-analysis', 'contour-integration']"
2,Showing that certain function does not exist,Showing that certain function does not exist,,"I am trying to prove that there is no a continuous map $ \phi : \mathbb{C} \times I \to \mathbb{C} $ ( $I = [0,1] $) $\phi_{\alpha}(z) = \phi(z,\alpha) $ satisfying the following: for each $\alpha \in I$, $\phi_{\alpha } : \mathbb{C} \to \mathbb{C} $ is $\mathbb{R}$-linear, $\phi_{\alpha}(1) \neq 0 $ and $\phi_{\alpha}(zw) = \phi_{\alpha}(z)\phi_{\alpha}(w) $; and $\phi_0(i) = i , \phi_1(i) = -i $. Perhaps there is one such a function. If so, how can we construct it?","I am trying to prove that there is no a continuous map $ \phi : \mathbb{C} \times I \to \mathbb{C} $ ( $I = [0,1] $) $\phi_{\alpha}(z) = \phi(z,\alpha) $ satisfying the following: for each $\alpha \in I$, $\phi_{\alpha } : \mathbb{C} \to \mathbb{C} $ is $\mathbb{R}$-linear, $\phi_{\alpha}(1) \neq 0 $ and $\phi_{\alpha}(zw) = \phi_{\alpha}(z)\phi_{\alpha}(w) $; and $\phi_0(i) = i , \phi_1(i) = -i $. Perhaps there is one such a function. If so, how can we construct it?",,[]
3,Composition of harmonic and holomorphic function,Composition of harmonic and holomorphic function,,"Simmiliar to this question my problem is as following: If $u$ is harmonic, and $f$ is holomorphic function, are $u \circ f$ and $f \circ u$ harmonic? I tried to do it like this:  $$\Delta (u \circ f)= 1/4 (u \circ f)_{z\bar{z}}=1/4[(u_z\circ f)f_z]_{\bar{z}}=1/4[(u_{z \bar{z}}\circ f)f_{\bar{z}}f_z + (u_z \circ f) f_{z{\bar{z}}})]=0$$ since $f_{\bar{z}}=0$ and $f_{z\bar{z}}=0$. In second case at the end I get: $(f_{z\bar{z}}\circ u)u_z + (f_z\circ u)u_{z\bar{z}}$. The first term is again zero, and why (if at all) is second zero? So, my question is, did I make some mistake?","Simmiliar to this question my problem is as following: If $u$ is harmonic, and $f$ is holomorphic function, are $u \circ f$ and $f \circ u$ harmonic? I tried to do it like this:  $$\Delta (u \circ f)= 1/4 (u \circ f)_{z\bar{z}}=1/4[(u_z\circ f)f_z]_{\bar{z}}=1/4[(u_{z \bar{z}}\circ f)f_{\bar{z}}f_z + (u_z \circ f) f_{z{\bar{z}}})]=0$$ since $f_{\bar{z}}=0$ and $f_{z\bar{z}}=0$. In second case at the end I get: $(f_{z\bar{z}}\circ u)u_z + (f_z\circ u)u_{z\bar{z}}$. The first term is again zero, and why (if at all) is second zero? So, my question is, did I make some mistake?",,"['complex-analysis', 'derivatives', 'harmonic-functions']"
4,Limit of bounded harmonic functions is harmonic,Limit of bounded harmonic functions is harmonic,,"I am trying to solve this old qual problem: Suppose $\{u_n\}_{n=1}^\infty$ is a sequence of functions harmonic on an open set $U \subset \mathbb{C}$ and uniformly bounded by 1.  Suppose there is a function $u : U \to \mathbb{R}$ such that $u_n \to u$ pointwise.  Show $u$ is harmonic on $U$. I would like to solve this using only elementary complex analysis.  My idea is this: Pick a point $z \in U$ and a disk $D_r(z) \subset U$.  Since the disk is simply connected, each $u_n$ is the real part of some holomorphic $f_n$.  Now, we would like to show that $f_n$ converges uniformly on compact subsets... I haven't gotten any further than this. Will this approach work?  Other ideas which use complex analysis are appreciated.","I am trying to solve this old qual problem: Suppose $\{u_n\}_{n=1}^\infty$ is a sequence of functions harmonic on an open set $U \subset \mathbb{C}$ and uniformly bounded by 1.  Suppose there is a function $u : U \to \mathbb{R}$ such that $u_n \to u$ pointwise.  Show $u$ is harmonic on $U$. I would like to solve this using only elementary complex analysis.  My idea is this: Pick a point $z \in U$ and a disk $D_r(z) \subset U$.  Since the disk is simply connected, each $u_n$ is the real part of some holomorphic $f_n$.  Now, we would like to show that $f_n$ converges uniformly on compact subsets... I haven't gotten any further than this. Will this approach work?  Other ideas which use complex analysis are appreciated.",,"['complex-analysis', 'harmonic-analysis', 'harmonic-functions']"
5,"Show that if $z_0$ is a solution to $(2z-1)^{2014}=(2z+1)^{2014}$, then $\Re(z_0)=0$","Show that if  is a solution to , then",z_0 (2z-1)^{2014}=(2z+1)^{2014} \Re(z_0)=0,"Show that if $z_0$ is a solution to $(2z-1)^{2014}=(2z+1)^{2014}$, then $\Re(z_0)=0$. My attempt: $(2z-1)^{2014}=(2z+1)^{2014}\\ \implies \left(\dfrac{2z-1}{2z+1}\right)^{2014}=1=e^{2k\pi i}, k=0\space \ldots \space 2013$ Let $\omega:=e^{2k\pi i}$ Then $\dfrac{2z-1}{2z+1}=\omega\\ \implies 2z-1=\omega(2z+1)\\ \implies 2z-1=2z\omega+\omega\\ \implies 2z-2z\omega=\omega +1\\ \implies z(2-2\omega)=\omega +1\\ \implies z=\dfrac{\omega +1}{2-2\omega}$ is what I thought would be right, but upon further inspection I noticed that $2-2\omega=0$, so that's not going to work. Any suggestions as to finding $z$?","Show that if $z_0$ is a solution to $(2z-1)^{2014}=(2z+1)^{2014}$, then $\Re(z_0)=0$. My attempt: $(2z-1)^{2014}=(2z+1)^{2014}\\ \implies \left(\dfrac{2z-1}{2z+1}\right)^{2014}=1=e^{2k\pi i}, k=0\space \ldots \space 2013$ Let $\omega:=e^{2k\pi i}$ Then $\dfrac{2z-1}{2z+1}=\omega\\ \implies 2z-1=\omega(2z+1)\\ \implies 2z-1=2z\omega+\omega\\ \implies 2z-2z\omega=\omega +1\\ \implies z(2-2\omega)=\omega +1\\ \implies z=\dfrac{\omega +1}{2-2\omega}$ is what I thought would be right, but upon further inspection I noticed that $2-2\omega=0$, so that's not going to work. Any suggestions as to finding $z$?",,['complex-analysis']
6,"Integrate $\int_{0}^{2\pi} \frac{R^{2}-r^{2}}{R^{2}-2Rr\cos \theta +r^{2}} d\theta= 2\pi$, by deformation theorem","Integrate , by deformation theorem",\int_{0}^{2\pi} \frac{R^{2}-r^{2}}{R^{2}-2Rr\cos \theta +r^{2}} d\theta= 2\pi,"I need prove that: $$\int_{0}^{2\pi} \frac{R^{2}-r^{2}}{R^{2}-2Rr\cos \theta +r^{2}} d\theta= 2\pi$$ By deformation theorem, with $0<r<R$. Professor gave us the hint to use the function $f(z)= \frac{R+z}{z(R-z)}$, and define an adequate $\gamma : [a,b]\rightarrow \mathbb{C}$ circular curve and with deformation theorem, we could find the integral. But I have been able to find the curve $\gamma$. Any advice is very helpful","I need prove that: $$\int_{0}^{2\pi} \frac{R^{2}-r^{2}}{R^{2}-2Rr\cos \theta +r^{2}} d\theta= 2\pi$$ By deformation theorem, with $0<r<R$. Professor gave us the hint to use the function $f(z)= \frac{R+z}{z(R-z)}$, and define an adequate $\gamma : [a,b]\rightarrow \mathbb{C}$ circular curve and with deformation theorem, we could find the integral. But I have been able to find the curve $\gamma$. Any advice is very helpful",,"['calculus', 'complex-analysis', 'complex-numbers']"
7,Projections on the Riemann Sphere are antipodal,Projections on the Riemann Sphere are antipodal,,"Prove that given two points $z,w\in\mathbb{C}$, we have that their projections on the Riemann sphere are antipodal if and only if: $z\bar{w}=-1$.","Prove that given two points $z,w\in\mathbb{C}$, we have that their projections on the Riemann sphere are antipodal if and only if: $z\bar{w}=-1$.",,"['complex-analysis', 'complex-numbers']"
8,"If $f$ is an entire function with $|f(z)|\le 100\log|z|$ and $f(i)=2i$, what is $f(1)$?","If  is an entire function with  and , what is ?",f |f(z)|\le 100\log|z| f(i)=2i f(1),"Let $f$ be an entire function with $|f(z)|\le 100\log|z|,\forall |z|\ge 2,f(i)=2i, \text{ Then} f(1)=?$ I have no idea how to solve this one! $g(z)={f(z)\over \log|z|}$ Then Can I say $g$ is constant by Liouville Theorem?","Let $f$ be an entire function with $|f(z)|\le 100\log|z|,\forall |z|\ge 2,f(i)=2i, \text{ Then} f(1)=?$ I have no idea how to solve this one! $g(z)={f(z)\over \log|z|}$ Then Can I say $g$ is constant by Liouville Theorem?",,['complex-analysis']
9,Type of singularities of $\frac{z}{e^z-1}$,Type of singularities of,\frac{z}{e^z-1},"I don't really understand how one can find the type of singularities for a given function. Say if  $$f(z) = \frac{z}{e^z-1}$$ then I know that the singularities are at $z = 2n\pi i$ However, how do I find the type? If I try to write out Laurent series for this by using $$e^z = 1 + z + z^2/2! + z^3/3! + \cdots $$, then I got a summation in the denominator, which I don't know how to rearrange as a Laurent series. Can anyone please give me a hint?","I don't really understand how one can find the type of singularities for a given function. Say if  $$f(z) = \frac{z}{e^z-1}$$ then I know that the singularities are at $z = 2n\pi i$ However, how do I find the type? If I try to write out Laurent series for this by using $$e^z = 1 + z + z^2/2! + z^3/3! + \cdots $$, then I got a summation in the denominator, which I don't know how to rearrange as a Laurent series. Can anyone please give me a hint?",,"['complex-analysis', 'laurent-series']"
10,If $f$ is analytic where $f$ is represented as $f=g.h$ where $g$ is analytic . From here can we conclude that $h$ is analytic?,If  is analytic where  is represented as  where  is analytic . From here can we conclude that  is analytic?,f f f=g.h g h,"If $f$ is analytic, where  $f$ is represented as $f=g \cdot h,$ where $g$ is analytic. From here can we conclude that $h$ is analytic?","If $f$ is analytic, where  $f$ is represented as $f=g \cdot h,$ where $g$ is analytic. From here can we conclude that $h$ is analytic?",,"['complex-analysis', 'derivatives', 'analyticity']"
11,Is there a harmonic function in the whole plane that is positive everywhere?,Is there a harmonic function in the whole plane that is positive everywhere?,,"This is one of the past qualifying exam problems that I was working on. I know that, when we let $z=x+iy$, ${|z|}^2=x^2+y^2$ is not harmonic. I do not know where to start to prove that there is no harmonic function that is positive everywhere. Any help or ideas idea will be really appreciated. Thank you in advance.","This is one of the past qualifying exam problems that I was working on. I know that, when we let $z=x+iy$, ${|z|}^2=x^2+y^2$ is not harmonic. I do not know where to start to prove that there is no harmonic function that is positive everywhere. Any help or ideas idea will be really appreciated. Thank you in advance.",,['complex-analysis']
12,How to find $(-64\mathrm{i}) ^{1/3}$?,How to find ?,(-64\mathrm{i}) ^{1/3},How to find $$(-64\mathrm{i})^{\frac{1}{3}}$$ This is a complex variables question. I need help by show step by step. Thanks a lot.,How to find $$(-64\mathrm{i})^{\frac{1}{3}}$$ This is a complex variables question. I need help by show step by step. Thanks a lot.,,"['complex-analysis', 'complex-numbers', 'computational-complexity']"
13,Proof that an analytic function that takes on real values on the boundary of a circle is a real [duplicate],Proof that an analytic function that takes on real values on the boundary of a circle is a real [duplicate],,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Let f(z) be entire function. Show that if $f(z)$ is real when $|z| = 1$, then $f(z)$ must be a constant function using Maximum Modulus theorem I'm having trouble proving that an analytic function that takes on only real values on the boundary of a circle is a real constant. I started by writing $f(r, \theta) = u(r, \theta) + i v(r, \theta)$ By definition, $v(r, \theta ) = 0$, so $\frac{d}{d\theta} v = 0$, and in fact, the nth derivative of $v(r,\theta)$ with respect to $\theta$  is 0. The Cauchy Riemann equations in polar coordinates imply that $\frac{d}{ dr} u(r, \theta ) = 0$ Unfortunately, I'm stuck here -  I think I need to prove that all nth derivatives of u and v with respect to both r and \theta$ are 0, so that I can move in any direction without inducing a change in f, but at this point I'm stuck. I've played around with this a fair bit but keep running in circles (no pun intended), so there must be something simple that I am missing. What am I doing wrong, and how does one complete the proof?","This question already has answers here : Closed 11 years ago . Possible Duplicate: Let f(z) be entire function. Show that if $f(z)$ is real when $|z| = 1$, then $f(z)$ must be a constant function using Maximum Modulus theorem I'm having trouble proving that an analytic function that takes on only real values on the boundary of a circle is a real constant. I started by writing $f(r, \theta) = u(r, \theta) + i v(r, \theta)$ By definition, $v(r, \theta ) = 0$, so $\frac{d}{d\theta} v = 0$, and in fact, the nth derivative of $v(r,\theta)$ with respect to $\theta$  is 0. The Cauchy Riemann equations in polar coordinates imply that $\frac{d}{ dr} u(r, \theta ) = 0$ Unfortunately, I'm stuck here -  I think I need to prove that all nth derivatives of u and v with respect to both r and \theta$ are 0, so that I can move in any direction without inducing a change in f, but at this point I'm stuck. I've played around with this a fair bit but keep running in circles (no pun intended), so there must be something simple that I am missing. What am I doing wrong, and how does one complete the proof?",,['complex-analysis']
14,Finding the image of a mapping over a region.,Finding the image of a mapping over a region.,,"I'm having a very hard time understanding the concept of images and mappings in the complex plane. Considering the map $w=e^{z}=e^{x}e^{iy}$, find the image of the region $\left\lbrace x+iy:x\geq 0, 0\leq y \leq\pi \right\rbrace$. Based on my current understanding, I have rewritten $w=e^z$ by breaking it apart with Euler's Formula: $$w=e^{x}\left(\cos{y}+i\sin{y}\right)=e^{x}\cos{y}+ie^{x}\sin{y}.$$ From here, we know that $u(x,y)=e^{x}\cos{y}$ and $v(x,y)=e^x\sin{y}$. Could I then rewrite the mapping as $f(x,y)=\left(e^{x}\cos{y},e^x\sin{y}\right)$ in order to sketch the seperate $xy$ and $uv$ planes?","I'm having a very hard time understanding the concept of images and mappings in the complex plane. Considering the map $w=e^{z}=e^{x}e^{iy}$, find the image of the region $\left\lbrace x+iy:x\geq 0, 0\leq y \leq\pi \right\rbrace$. Based on my current understanding, I have rewritten $w=e^z$ by breaking it apart with Euler's Formula: $$w=e^{x}\left(\cos{y}+i\sin{y}\right)=e^{x}\cos{y}+ie^{x}\sin{y}.$$ From here, we know that $u(x,y)=e^{x}\cos{y}$ and $v(x,y)=e^x\sin{y}$. Could I then rewrite the mapping as $f(x,y)=\left(e^{x}\cos{y},e^x\sin{y}\right)$ in order to sketch the seperate $xy$ and $uv$ planes?",,"['complex-analysis', 'complex-numbers']"
15,Show a function is holomorphic,Show a function is holomorphic,,"Let $\phi: [0,1] \rightarrow \mathbb{C}$ be a continuous function. For all $z \in \mathbb{C} \setminus [0,1] $ define $f(z) = \int_0^1\frac{\phi(t)}{t-z} \ dt$. Prove that f is holomorphic on $\mathbb{C} \setminus [0,1]$. I can't express $f$ as a composition of holomorphic functions, is there another way to prove $f$ is holomorphic? Thanks in advance!","Let $\phi: [0,1] \rightarrow \mathbb{C}$ be a continuous function. For all $z \in \mathbb{C} \setminus [0,1] $ define $f(z) = \int_0^1\frac{\phi(t)}{t-z} \ dt$. Prove that f is holomorphic on $\mathbb{C} \setminus [0,1]$. I can't express $f$ as a composition of holomorphic functions, is there another way to prove $f$ is holomorphic? Thanks in advance!",,['complex-analysis']
16,showing a function defined from an integral is entire,showing a function defined from an integral is entire,,"Let $f$ be a continuous complex-valued function on the unit interval. For any complex number $z$, define $F(z)=\int _0 ^1 f(t) e^{zt} dt$. How do I show that $F$ is entire?","Let $f$ be a continuous complex-valued function on the unit interval. For any complex number $z$, define $F(z)=\int _0 ^1 f(t) e^{zt} dt$. How do I show that $F$ is entire?",,['complex-analysis']
17,Solving for coefficients on a Laurent series,Solving for coefficients on a Laurent series,,"I am having an issue with the following complex analysis problem. I am suppose to  find the coefficients of $z^{-1}$, $z^{-2}$ and $z^{-3}$ in the  Laurent series for  $\displaystyle \frac{1}{\sin z}$ around $z_0 = 0$ which is valid for $2\pi < |z| < 3\pi$. One way I thought of doing it was to say  $$ \frac{1}{\sin z} = \frac{1}{(z - 2\pi)(z - 3\pi)}\frac{(z - 2\pi)(z - 3\pi)}{\sin z} $$ Let $H(z) = \displaystyle \frac{(z - 2\pi)(z - 3\pi)}{\sin z} $. Then we have  $$ \frac{1}{\sin z} = H(z)\left[ \frac{A}{z - 2\pi} - \frac{B}{z - 3\pi} \right] 	= H(z)\left[ \sum_{k = 0}^\infty \frac{A(2\pi)^k}{z^{k + 1}}  		+ \sum_{k = 0}^\infty \frac{Bz^k}{(3\pi)^{k + 1}} \right]. $$ This seems to get me part of the way of where i need to go, but leaves me having to find a series that works for $H(z)$. I was going to continue in this way, but I though that perhaps it was giving me an entire series, and the problem seems to be suggesting to only solve for 3 of the coefficients. Another way to solve for the coefficients is  $\displaystyle a_k = \frac{1}{2\pi i} \int_\gamma \frac{f(w)}{(w - z_0)^{k + 1}} dw$, where $\gamma$ is a circle, of say radius $R$, that is in the annulus. I tried to do this just for $a_{-1}$ and I got the following $$ \int_0^{2\pi} \frac{Rie^{it}}{\sin(Re^{it})} dt = \int_{u(0)}^{u(2\pi)} \frac{1}{\sin(u)} du $$ where $u = Re^{it}$, so $u(0) = R$ and $u(2\pi) = R$. Thus I'm integrating from  $R$ to $R$, so $a_{-1} = 0$. However the $u$ substitution seems like something went wrong. I am not even sure if I can actually do a $u$ substitution like that, but I can't see how to solve the integral any other way. I am not sure what direction to go with this problem, and it seems like I am making it a lot harder than it is suppose to be. Can anyone give me some direction on it? Should I be attempting to solve the integrals, or do something like I was at the beginning?","I am having an issue with the following complex analysis problem. I am suppose to  find the coefficients of $z^{-1}$, $z^{-2}$ and $z^{-3}$ in the  Laurent series for  $\displaystyle \frac{1}{\sin z}$ around $z_0 = 0$ which is valid for $2\pi < |z| < 3\pi$. One way I thought of doing it was to say  $$ \frac{1}{\sin z} = \frac{1}{(z - 2\pi)(z - 3\pi)}\frac{(z - 2\pi)(z - 3\pi)}{\sin z} $$ Let $H(z) = \displaystyle \frac{(z - 2\pi)(z - 3\pi)}{\sin z} $. Then we have  $$ \frac{1}{\sin z} = H(z)\left[ \frac{A}{z - 2\pi} - \frac{B}{z - 3\pi} \right] 	= H(z)\left[ \sum_{k = 0}^\infty \frac{A(2\pi)^k}{z^{k + 1}}  		+ \sum_{k = 0}^\infty \frac{Bz^k}{(3\pi)^{k + 1}} \right]. $$ This seems to get me part of the way of where i need to go, but leaves me having to find a series that works for $H(z)$. I was going to continue in this way, but I though that perhaps it was giving me an entire series, and the problem seems to be suggesting to only solve for 3 of the coefficients. Another way to solve for the coefficients is  $\displaystyle a_k = \frac{1}{2\pi i} \int_\gamma \frac{f(w)}{(w - z_0)^{k + 1}} dw$, where $\gamma$ is a circle, of say radius $R$, that is in the annulus. I tried to do this just for $a_{-1}$ and I got the following $$ \int_0^{2\pi} \frac{Rie^{it}}{\sin(Re^{it})} dt = \int_{u(0)}^{u(2\pi)} \frac{1}{\sin(u)} du $$ where $u = Re^{it}$, so $u(0) = R$ and $u(2\pi) = R$. Thus I'm integrating from  $R$ to $R$, so $a_{-1} = 0$. However the $u$ substitution seems like something went wrong. I am not even sure if I can actually do a $u$ substitution like that, but I can't see how to solve the integral any other way. I am not sure what direction to go with this problem, and it seems like I am making it a lot harder than it is suppose to be. Can anyone give me some direction on it? Should I be attempting to solve the integrals, or do something like I was at the beginning?",,['complex-analysis']
18,Question about holomorphic functions.,Question about holomorphic functions.,,"While reading through various notes dealing with holomorphic function, I came across this (seemingly innocent) question that caught my eye: If $f(z)$ is holomorphic in a domain $D \subset \mathbb{C}$, must $\sqrt{f(z)}$ have a branch point at every zero of f? Can anyone provide some insight to this question? Thank you!","While reading through various notes dealing with holomorphic function, I came across this (seemingly innocent) question that caught my eye: If $f(z)$ is holomorphic in a domain $D \subset \mathbb{C}$, must $\sqrt{f(z)}$ have a branch point at every zero of f? Can anyone provide some insight to this question? Thank you!",,['complex-analysis']
19,Laurent series for an even function,Laurent series for an even function,,"Show that if the Laurent series $\sum_{n=-\infty}^{\infty}a_n(z-z_0)^n$ represents an even function, then $a_{2n+1}=0$ for $n=0,\pm 1,\pm 2,\ldots$, and if it represents an odd function, then $a_{2n}=0$ for $n=0,\pm 1,\pm 2,\ldots$. where $a_n=\frac{1}{2\pi i}\int_C \frac{f(z)}{(z-z_0)^{n+1}}dz$ I know the fact that if $f(-z)=f(z)$ then $f$ is even. But I have difficulty applying this to show what i need to have.","Show that if the Laurent series $\sum_{n=-\infty}^{\infty}a_n(z-z_0)^n$ represents an even function, then $a_{2n+1}=0$ for $n=0,\pm 1,\pm 2,\ldots$, and if it represents an odd function, then $a_{2n}=0$ for $n=0,\pm 1,\pm 2,\ldots$. where $a_n=\frac{1}{2\pi i}\int_C \frac{f(z)}{(z-z_0)^{n+1}}dz$ I know the fact that if $f(-z)=f(z)$ then $f$ is even. But I have difficulty applying this to show what i need to have.",,['complex-analysis']
20,Proving a function is constant,Proving a function is constant,,"Let $f$ be an analytic function such that $f(z)$ is an element of $\mathbb R$ for all $z$ element of $\mathbb C$. Prove $f$ is constant. Here's what I have done - $f(z) = c + i0$, where $c$ is an element of $\mathbb R$ So i have component functions $u(x,y) = c$,  $v(x,y) = 0$ The partial derivative $u_x = 0$ and the partial derivative $v_x = 0$ The derivative, $f'(z)$ = $u_x +i v_x$, so I have $f'(z) = 0$ As $f'(z) = 0$ the function must be constant. Does that seem right? One thing that I noticed when looking at question is that if $f(z)$ is an element of $\mathbb R$ then it is automatically constant...isn't that correct? But I would expect they are looking for more than that in an exam situation...","Let $f$ be an analytic function such that $f(z)$ is an element of $\mathbb R$ for all $z$ element of $\mathbb C$. Prove $f$ is constant. Here's what I have done - $f(z) = c + i0$, where $c$ is an element of $\mathbb R$ So i have component functions $u(x,y) = c$,  $v(x,y) = 0$ The partial derivative $u_x = 0$ and the partial derivative $v_x = 0$ The derivative, $f'(z)$ = $u_x +i v_x$, so I have $f'(z) = 0$ As $f'(z) = 0$ the function must be constant. Does that seem right? One thing that I noticed when looking at question is that if $f(z)$ is an element of $\mathbb R$ then it is automatically constant...isn't that correct? But I would expect they are looking for more than that in an exam situation...",,['complex-analysis']
21,Norm inequality on Complex Numbers.,Norm inequality on Complex Numbers.,,"For $z,w \in \mathbb{C}$, it is true that $ 2 | z w| \leq |z|^2 + |w|^2 $. How does this imply the identity: $$|z+w|^2 \leq 2(|z|^2 + |w|^2 )? $$","For $z,w \in \mathbb{C}$, it is true that $ 2 | z w| \leq |z|^2 + |w|^2 $. How does this imply the identity: $$|z+w|^2 \leq 2(|z|^2 + |w|^2 )? $$",,"['complex-analysis', 'inequality']"
22,Complex Analysis: Radius of convergence of Power Series,Complex Analysis: Radius of convergence of Power Series,,"Let p be a polynomial of degree $k>0$. Prove that $\sum p(n)z^n$ has radius of convergence $1$ and that there exists a polynomial $q(z)$ of degree $k$ such that $$\sum_{n=0}^{\infty} p(n) z^n=q(z)(1-z)^{-(k+1)}, \qquad  (|z|<1)$$ I've shown the radius of convergence is $1$; not sure how to apporach the second part.","Let p be a polynomial of degree $k>0$. Prove that $\sum p(n)z^n$ has radius of convergence $1$ and that there exists a polynomial $q(z)$ of degree $k$ such that $$\sum_{n=0}^{\infty} p(n) z^n=q(z)(1-z)^{-(k+1)}, \qquad  (|z|<1)$$ I've shown the radius of convergence is $1$; not sure how to apporach the second part.",,"['complex-analysis', 'convergence-divergence', 'power-series']"
23,Real and imaginary parts of the Möbius transformation,Real and imaginary parts of the Möbius transformation,,"Given that the Möbius transformation is: $f(z) = \dfrac{az+b}{cz+d} ,\, (a d-b c) \neq 0$ and with $a,b,c$ and $d$ complex numbers written  $a= a_1 + a_2i$ etc. I think I must be missing something because when separating the Möbius transformation in to its real and imaginary parts I got this: $\dfrac{(a_1c_1+a_2c_2)z^2 + (b_1c_1+b_2c_2)z +(a_1d_1+a_2d_2)z +(b_1d_1+b_2d_2)}{|c|^2z^2 + |d|^2}$ for the real part... and $\dfrac{(a_1c_1-a_2c_2)z^2 + (b_1c_1-b_2c_2)z +(a_1d_1-a_2d_2)z +(b_1d_1-b_2d_2)}{|c|^2z^2 + |d|^2}i$ as the imaginary. It really looks awful, is there a better way to write this? Update. Duh. Dumb mistake, reworking them I get this, the point is it's still ugly. Real: $\dfrac{(a_1x-a_2y+b_1)(c_1x-c_2y+d_1) -(a_2x+a_1y+b_2)(c_2x+c_1y+d_2)}{(c_1x-c_2y+d_1)^2 - (c_2x+c_1y+d_2)^2}$ $\dfrac{R(ac)x^2 - 2(a_1c_2 + a_2c_1)xy + (R(ad) + R(bc))x - (R(ab) + R(bc))y - R(ac)y^2 + R(bd)}{(c_1x-c_2y+d_1)^2 - (c_2x+c_1y+d_2)^2}$ Imag: $\dfrac{(a_2x-a_1y+b_2)(c_1x-c_2y+d_1) -(a_1x+a_2y+b_1)(c_2x+c_1y+d_2)}{(c_1x-c_2y+d_1)^2 - (c_2x+c_1y+d_2)^2}$","Given that the Möbius transformation is: $f(z) = \dfrac{az+b}{cz+d} ,\, (a d-b c) \neq 0$ and with $a,b,c$ and $d$ complex numbers written  $a= a_1 + a_2i$ etc. I think I must be missing something because when separating the Möbius transformation in to its real and imaginary parts I got this: $\dfrac{(a_1c_1+a_2c_2)z^2 + (b_1c_1+b_2c_2)z +(a_1d_1+a_2d_2)z +(b_1d_1+b_2d_2)}{|c|^2z^2 + |d|^2}$ for the real part... and $\dfrac{(a_1c_1-a_2c_2)z^2 + (b_1c_1-b_2c_2)z +(a_1d_1-a_2d_2)z +(b_1d_1-b_2d_2)}{|c|^2z^2 + |d|^2}i$ as the imaginary. It really looks awful, is there a better way to write this? Update. Duh. Dumb mistake, reworking them I get this, the point is it's still ugly. Real: $\dfrac{(a_1x-a_2y+b_1)(c_1x-c_2y+d_1) -(a_2x+a_1y+b_2)(c_2x+c_1y+d_2)}{(c_1x-c_2y+d_1)^2 - (c_2x+c_1y+d_2)^2}$ $\dfrac{R(ac)x^2 - 2(a_1c_2 + a_2c_1)xy + (R(ad) + R(bc))x - (R(ab) + R(bc))y - R(ac)y^2 + R(bd)}{(c_1x-c_2y+d_1)^2 - (c_2x+c_1y+d_2)^2}$ Imag: $\dfrac{(a_2x-a_1y+b_2)(c_1x-c_2y+d_1) -(a_1x+a_2y+b_1)(c_2x+c_1y+d_2)}{(c_1x-c_2y+d_1)^2 - (c_2x+c_1y+d_2)^2}$",,['complex-analysis']
24,Draw an area on the complex plane,Draw an area on the complex plane,,"On the complex plane draw the area: $$  \begin{equation}     \begin{cases}        |z+4i| < 3 \\        |\arg(z-5-5i)|<\frac{\pi}{3}     \end{cases} \end{equation} $$ Where $ \arg(z) \in (-\pi, \pi ]$ I can draw $|z+4i| < 3$ : $|x + iy + 4i|<3 \Rightarrow \sqrt{x^2 + (y + 4)^2}<3 \Rightarrow x^2 + (y + 4)^2<9$ : However, I have no idea how to draw and intersect with $|arg(z-5-5i)|<\frac{\pi}{3}$","On the complex plane draw the area: Where I can draw : : However, I have no idea how to draw and intersect with"," 
\begin{equation}
    \begin{cases}
       |z+4i| < 3 \\
       |\arg(z-5-5i)|<\frac{\pi}{3}
    \end{cases}
\end{equation}
  \arg(z) \in (-\pi, \pi ] |z+4i| < 3 |x + iy + 4i|<3 \Rightarrow \sqrt{x^2 + (y + 4)^2}<3 \Rightarrow x^2 + (y + 4)^2<9 |arg(z-5-5i)|<\frac{\pi}{3}","['linear-algebra', 'complex-analysis', 'complex-numbers', 'graphing-functions']"
25,"Investigate for convergence in $z\in\mathbb{C}, \ |z|<1$: $\Sigma_{k=1}^{+\infty}\left(\cos (z^k)-1\right).$",Investigate for convergence in :,"z\in\mathbb{C}, \ |z|<1 \Sigma_{k=1}^{+\infty}\left(\cos (z^k)-1\right).","Investigate for convergence in $z\in\mathbb{C}, \ |z|<1$ : $$\Sigma_{k=1}^{+\infty}\left(\cos (z^k)-1\right).$$ We were recommended to use $\cos(z^k)$ expansion first: $$ \Sigma_{k=1}^{+\infty}\left(\cos (z^k)-1\right)=\Sigma_{k=1}^{+\infty}\Sigma_{n=1}^{+\infty}\left(\frac{(-1)^n z^{2kn}}{(2n)!}\right) = $$ here we need to reference some theorem that says that $n$ and $k$ changing places $\Sigma_{k=1}^{+\infty}\Sigma_{n=1}^{+\infty}\left(\frac{(-1)^n z^{2kn}}{(2n)!}\right)=\Sigma_{n=1}^{+\infty}\Sigma_{k=1}^{+\infty}\left(\frac{(-1)^n z^{2kn}}{(2n)!}\right)$ is allowed. I don't remember such theorem, and failed to google it. I don't see why $n$ and $k$ changing places would not always be okay. I would be very grateful if someone could give a statement of the theorem. $$=\Sigma_{n=1}^{+\infty}\frac{(-1)^n}{(2n)!}\Sigma_{k=1}^{+\infty}   \ z^{2kn}=\Sigma_{n=1}^{+\infty}\left(\frac{(-1)^n}{(2n)!}\cdot\frac{z^{2n}}{1-z^{2n}}\right)$$ Ratio test: $$\frac{(-1)^{n+1} z^{2n+2}}{(2n+2)! \ (1-z^{2n+2})} \cdot \frac{(2n)! \ (1-z^{2n})}{(-1)^n \ z^{2n}}  =  \frac{(-1) z^{2}(1-z^{2n})}{(2n+1)(2n+2) \ (1-z^{2n+2})} \longrightarrow_{n \longrightarrow \infty} 0 < 1, $$ so the original series is convergent in the given region. I feel like my solution is wrong. If it is, could someone please point out mistakes, and give hints or explain how to solve correctly? Thank you.","Investigate for convergence in : We were recommended to use expansion first: here we need to reference some theorem that says that and changing places is allowed. I don't remember such theorem, and failed to google it. I don't see why and changing places would not always be okay. I would be very grateful if someone could give a statement of the theorem. Ratio test: so the original series is convergent in the given region. I feel like my solution is wrong. If it is, could someone please point out mistakes, and give hints or explain how to solve correctly? Thank you.","z\in\mathbb{C}, \ |z|<1 \Sigma_{k=1}^{+\infty}\left(\cos (z^k)-1\right). \cos(z^k) 
\Sigma_{k=1}^{+\infty}\left(\cos (z^k)-1\right)=\Sigma_{k=1}^{+\infty}\Sigma_{n=1}^{+\infty}\left(\frac{(-1)^n z^{2kn}}{(2n)!}\right) =
 n k \Sigma_{k=1}^{+\infty}\Sigma_{n=1}^{+\infty}\left(\frac{(-1)^n z^{2kn}}{(2n)!}\right)=\Sigma_{n=1}^{+\infty}\Sigma_{k=1}^{+\infty}\left(\frac{(-1)^n z^{2kn}}{(2n)!}\right) n k =\Sigma_{n=1}^{+\infty}\frac{(-1)^n}{(2n)!}\Sigma_{k=1}^{+\infty} 
 \ z^{2kn}=\Sigma_{n=1}^{+\infty}\left(\frac{(-1)^n}{(2n)!}\cdot\frac{z^{2n}}{1-z^{2n}}\right) \frac{(-1)^{n+1} z^{2n+2}}{(2n+2)! \ (1-z^{2n+2})} \cdot \frac{(2n)! \ (1-z^{2n})}{(-1)^n \ z^{2n}} 
= 
\frac{(-1) z^{2}(1-z^{2n})}{(2n+1)(2n+2) \ (1-z^{2n+2})} \longrightarrow_{n \longrightarrow \infty} 0 < 1, ","['complex-analysis', 'convergence-divergence', 'solution-verification']"
26,Please help me evaluate the following integral analytically [closed],Please help me evaluate the following integral analytically [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question $$\int_{0}^{5} \left(\arccos\left(\frac{2}{x+2}\right)\right)^2 \, dx $$ I tried evaluating this integral using traditional techniques such as integration by parts,  u-substitution and trigonometric identities, however, I was unsuccessful. If this integral is analytically derivable, please specify the technique or analysis framework that could yield results, including multivariable calculus, complex analysis or tricks (such as Feynman's trick). I would prefer a closed-form solution to this integral if possible, for the positive real numbers. Thanks in advance!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I tried evaluating this integral using traditional techniques such as integration by parts,  u-substitution and trigonometric identities, however, I was unsuccessful. If this integral is analytically derivable, please specify the technique or analysis framework that could yield results, including multivariable calculus, complex analysis or tricks (such as Feynman's trick). I would prefer a closed-form solution to this integral if possible, for the positive real numbers. Thanks in advance!","\int_{0}^{5} \left(\arccos\left(\frac{2}{x+2}\right)\right)^2 \, dx
","['calculus', 'complex-analysis', 'multivariable-calculus', 'definite-integrals', 'indefinite-integrals']"
27,Moebius transformations preserving unit circle,Moebius transformations preserving unit circle,,"Find all Moebius Transformations preserving unit circle Note : I am more interested if I got these computations right than the answer. Approach-1 From page-124 of Needham, a general moebius transformation of form $f(z) = \frac{az+b}{cz+d}$ can be decomposed as: $z \to z + \frac{d}{c}$ (translate) $z \to \frac{1}{z}$ (inversion) $z \to -\frac{ad-bc}{c^2}z$ (rotation and dilation) $z \to z + \frac{a}{c}$ (translate) It is clear to me that if it is to preserve the unit circle than 1. and 4. must be opposite , so I have: $$ \frac{d}{c} = - \frac{a}{c} \implies d = -a \tag{1}$$ We also need that in 3. the magnitude should be preserved ( no other dilations), we have: $$ c^2 = e^{it} ( a^2+bc)  \implies c^2 e^{-it} -bc = a^2 \implies \pm \sqrt{c^2 e^{-it} -bc }=a\tag{2}$$ Putting the $d=-a$ in our function and then using (2), we have: $$ f(z) = \frac{\pm \sqrt{c^2 e^{-it} -bc }z+b}{cz-\pm \sqrt{c^2 e^{-it} -bc }}$$ Is this all the simplification possible or is it possible to kill any more variables? Approach-2 This is based on a discussion with a friend. The idea is to begin with the symmetric principle i.e: symmetric points are mapped to symmetric point under moebius transformations, we have: $$ w= f(0) = \frac{b}{d}$$ $$ \frac{1}{w} = \frac{a}{c}$$ This leads to the following constraint: $$ w=  \frac{b}{d} = \frac{c}{a}$$ Or, $$ b = dw$$ and, $$ c=aw$$ Leading to: $$ f(z) = \frac{az+dw}{awz+d}= \frac {\frac{az}{d} + w}{\frac{a}{d} wz + 1}$$ Letting $\frac{a}{w} = \lambda$ , we have: $$ f(z) = \frac{\lambda z+w}{\lambda w z +1} \tag{3}$$ Now, without loss of generality let's suppose that point $1$ gets sent to some point $e^{it}$ on the unit circle, we have: $$ \frac{\lambda + w}{ \lambda w +1} = e^{it}$$ $$ \lambda ( 1-e^{it} w)= e^{it} -w$$ $$ \lambda = \frac{e^{it} - w} {1- e^{it} w} \tag{4}$$ Can the expression received after plugging (3) into (4) be simplified any more? Also, how exactly could I know how many independent variables there would be at them end of this problem?","Find all Moebius Transformations preserving unit circle Note : I am more interested if I got these computations right than the answer. Approach-1 From page-124 of Needham, a general moebius transformation of form can be decomposed as: (translate) (inversion) (rotation and dilation) (translate) It is clear to me that if it is to preserve the unit circle than 1. and 4. must be opposite , so I have: We also need that in 3. the magnitude should be preserved ( no other dilations), we have: Putting the in our function and then using (2), we have: Is this all the simplification possible or is it possible to kill any more variables? Approach-2 This is based on a discussion with a friend. The idea is to begin with the symmetric principle i.e: symmetric points are mapped to symmetric point under moebius transformations, we have: This leads to the following constraint: Or, and, Leading to: Letting , we have: Now, without loss of generality let's suppose that point gets sent to some point on the unit circle, we have: Can the expression received after plugging (3) into (4) be simplified any more? Also, how exactly could I know how many independent variables there would be at them end of this problem?",f(z) = \frac{az+b}{cz+d} z \to z + \frac{d}{c} z \to \frac{1}{z} z \to -\frac{ad-bc}{c^2}z z \to z + \frac{a}{c}  \frac{d}{c} = - \frac{a}{c} \implies d = -a \tag{1}  c^2 = e^{it} ( a^2+bc)  \implies c^2 e^{-it} -bc = a^2 \implies \pm \sqrt{c^2 e^{-it} -bc }=a\tag{2} d=-a  f(z) = \frac{\pm \sqrt{c^2 e^{-it} -bc }z+b}{cz-\pm \sqrt{c^2 e^{-it} -bc }}  w= f(0) = \frac{b}{d}  \frac{1}{w} = \frac{a}{c}  w=  \frac{b}{d} = \frac{c}{a}  b = dw  c=aw  f(z) = \frac{az+dw}{awz+d}= \frac {\frac{az}{d} + w}{\frac{a}{d} wz + 1} \frac{a}{w} = \lambda  f(z) = \frac{\lambda z+w}{\lambda w z +1} \tag{3} 1 e^{it}  \frac{\lambda + w}{ \lambda w +1} = e^{it}  \lambda ( 1-e^{it} w)= e^{it} -w  \lambda = \frac{e^{it} - w} {1- e^{it} w} \tag{4},"['complex-analysis', 'complex-numbers', 'solution-verification', 'mobius-transformation']"
28,$\lim_{\vert z\vert\to\infty}\frac{zf'(z)}{f(z)}=n\in\mathbb{N}$ implies $f$ is a polynomial,implies  is a polynomial,\lim_{\vert z\vert\to\infty}\frac{zf'(z)}{f(z)}=n\in\mathbb{N} f,"Let $f$ be an entire function, meaning $$f:\mathbb{C}\to\mathbb{C}$$ is holomorphic. If $f\not\equiv0$ and $$\lim_{\vert z\vert\to\infty}\frac{zf'(z)}{f(z)}=n\in\mathbb{N}_0$$ then $f$ have to be a polynomial of degree $n$ . I was able to proof that $f$ can only have finitely many roots, using $$\frac{zf'(z)}{f(z)}=\frac{z}{z-z_1}+\frac{z}{z-z_2}+...$$ where $z_n$ are the roots. Taking the limit this series diverges if there were infintely many roots. This also already proofed, that $f$ has exactly $n$ roots. Nonetheless doing this is only valid, if $f$ even has any roots. If there are no roots, $f$ can not be a non-constant polynomial. So it's either constant or it is a transcendental entire function. So proving that $f$ can not be an transcendental entire function would imply the case what happens when $f$ has no roots. I would appreciate any hints how to prove, that $f$ is a polynomial.","Let be an entire function, meaning is holomorphic. If and then have to be a polynomial of degree . I was able to proof that can only have finitely many roots, using where are the roots. Taking the limit this series diverges if there were infintely many roots. This also already proofed, that has exactly roots. Nonetheless doing this is only valid, if even has any roots. If there are no roots, can not be a non-constant polynomial. So it's either constant or it is a transcendental entire function. So proving that can not be an transcendental entire function would imply the case what happens when has no roots. I would appreciate any hints how to prove, that is a polynomial.",f f:\mathbb{C}\to\mathbb{C} f\not\equiv0 \lim_{\vert z\vert\to\infty}\frac{zf'(z)}{f(z)}=n\in\mathbb{N}_0 f n f \frac{zf'(z)}{f(z)}=\frac{z}{z-z_1}+\frac{z}{z-z_2}+... z_n f n f f f f f,"['complex-analysis', 'entire-functions']"
29,Determine all complex numbers which satisfy conditions - $|z|=2$ $\space$ and $\space$ Im$(z^6)=8$ Im$(z^3)$,Determine all complex numbers which satisfy conditions -   and  Im Im,|z|=2 \space \space (z^6)=8 (z^3),"Determine all complex numbers $z$ which satisfy following conditions: $|z|=2$ $\space$ and $\space$ Im $(z^6)=8$ Im $(z^3)$ I first calculated $z^3$ and $z^6$ . $z^3=x^3-3xy^2+3x^2yi-y^3i$ $z^6=(x+yi)^6=\binom{6}{0}x^6+\binom{6}{1}x^5yi+\binom{6}{2}x^4(yi)^2+\binom{6}{3}x^3(yi)^3+\binom{6}{4}x^2(yi)^4+\binom{6}{5}x(yi)^5+\binom{6}{6}(yi)^6$ $=x^6+6x^5yi+15x^4(-y^2)+20x^3(-y^3i)+15x^2y^4+6xy^5i-y^6$ Then I put imaginary parts in equation Im $(z^6)=8$ Im $(z^3)$ and got following $6x^5y-20x^3y^3+6xy^5=8(3x^2y-y^3)$ $2xy(x^2-3y^2)\require{cancel} \cancel{(3x^2-y^2)}=8y\require{cancel} \cancel{(3x^2-y^2)}$ (*) $x(x^2-3y^2)=4$ $\space$ (1) from $|z|=2$ follows $\sqrt{x^2+y^2}=2$ $\space$ $\rightarrow$ $y^2=4-x^2$ (2) after putting (2) in (1) I got $x^3-3x=1$ and then $x=2\cos\varphi$ equation $8\cos^3\varphi-6\cos\varphi=1$ can be tranformed to $2\cos3\varphi=1$ (I got this with help of identity of $\cos {3x}$ ) and then $\varphi_1=\frac{\pi}{9}+\frac{2k\pi}{3}$ $\varphi_2=-\frac{\pi}{9}+\frac{2k\pi}{3}$ , $\space$ $k \in \mathbb{Z}$ Written differently solution is $\varphi_1=\frac{\pi}{9}+2k\pi$ $\varphi_2=\frac{5\pi}{9}+2k\pi$ $\varphi_3=\frac{7\pi}{9}+2k\pi$ $\varphi_4=\frac{11\pi}{9}+2k\pi$ $\varphi_5=\frac{13\pi}{9}+2k\pi$ $\varphi_6=\frac{17\pi}{9}+2k\pi$ In line with (*) expresions $3x^2-y^2$ are striked out. We have to include that $3x^2-y^2=0$ $3x^2-(4-x^2)=0$ $4x^2=4$ $x^2=1$ $(2\cos\varphi)^2=1$ $\cos^2\varphi=\frac{1}{4}$ After solving this equation we get $\varphi_7=\frac{\pi}{3}+2k\pi$ $\varphi_8=\frac{2\pi}{3}+2k\pi$ $\varphi_9=\frac{4\pi}{3}+2k\pi$ $\varphi_{10}=\frac{5\pi}{3}+2k\pi$ Solution from my textbook: $\require{enclose}      \enclose{horizontalstrike}{z_1=2(\cos\frac{2\pi}{3}+i\sin\frac{2\pi}{3})}$ . $\require{enclose}      \enclose{horizontalstrike}{z_2=2(\cos\frac{5\pi}{3}+i\sin\frac{5\pi}{3})}$ . $\require{enclose}      \enclose{horizontalstrike}{z_3=2(\cos\frac{7\pi}{3}+i\sin\frac{7\pi}{3})}$ . Can someone help me find a mistake? If you find mistake feel free to edit. On the picture bellow are all 10 solutions.","Determine all complex numbers which satisfy following conditions: and Im Im I first calculated and . Then I put imaginary parts in equation Im Im and got following (*) (1) from follows (2) after putting (2) in (1) I got and then equation can be tranformed to (I got this with help of identity of ) and then , Written differently solution is In line with (*) expresions are striked out. We have to include that After solving this equation we get Solution from my textbook: . . . Can someone help me find a mistake? If you find mistake feel free to edit. On the picture bellow are all 10 solutions.","z |z|=2 \space \space (z^6)=8 (z^3) z^3 z^6 z^3=x^3-3xy^2+3x^2yi-y^3i z^6=(x+yi)^6=\binom{6}{0}x^6+\binom{6}{1}x^5yi+\binom{6}{2}x^4(yi)^2+\binom{6}{3}x^3(yi)^3+\binom{6}{4}x^2(yi)^4+\binom{6}{5}x(yi)^5+\binom{6}{6}(yi)^6 =x^6+6x^5yi+15x^4(-y^2)+20x^3(-y^3i)+15x^2y^4+6xy^5i-y^6 (z^6)=8 (z^3) 6x^5y-20x^3y^3+6xy^5=8(3x^2y-y^3) 2xy(x^2-3y^2)\require{cancel} \cancel{(3x^2-y^2)}=8y\require{cancel} \cancel{(3x^2-y^2)} x(x^2-3y^2)=4 \space |z|=2 \sqrt{x^2+y^2}=2 \space \rightarrow y^2=4-x^2 x^3-3x=1 x=2\cos\varphi 8\cos^3\varphi-6\cos\varphi=1 2\cos3\varphi=1 \cos {3x} \varphi_1=\frac{\pi}{9}+\frac{2k\pi}{3} \varphi_2=-\frac{\pi}{9}+\frac{2k\pi}{3} \space k \in \mathbb{Z} \varphi_1=\frac{\pi}{9}+2k\pi \varphi_2=\frac{5\pi}{9}+2k\pi \varphi_3=\frac{7\pi}{9}+2k\pi \varphi_4=\frac{11\pi}{9}+2k\pi \varphi_5=\frac{13\pi}{9}+2k\pi \varphi_6=\frac{17\pi}{9}+2k\pi 3x^2-y^2 3x^2-y^2=0 3x^2-(4-x^2)=0 4x^2=4 x^2=1 (2\cos\varphi)^2=1 \cos^2\varphi=\frac{1}{4} \varphi_7=\frac{\pi}{3}+2k\pi \varphi_8=\frac{2\pi}{3}+2k\pi \varphi_9=\frac{4\pi}{3}+2k\pi \varphi_{10}=\frac{5\pi}{3}+2k\pi \require{enclose}
     \enclose{horizontalstrike}{z_1=2(\cos\frac{2\pi}{3}+i\sin\frac{2\pi}{3})} \require{enclose}
     \enclose{horizontalstrike}{z_2=2(\cos\frac{5\pi}{3}+i\sin\frac{5\pi}{3})} \require{enclose}
     \enclose{horizontalstrike}{z_3=2(\cos\frac{7\pi}{3}+i\sin\frac{7\pi}{3})}","['complex-analysis', 'complex-numbers', 'complex-geometry']"
30,"Average decrease of a random number in ""subtracting every prime by one in factorization""","Average decrease of a random number in ""subtracting every prime by one in factorization""",,"Question : Consider $n=p_1^{\alpha_1}\cdots p_\omega^{\alpha_\omega}$ be the prime factorization of $n$ . Define $a(n)=(p_1-1)^{\alpha_1}\cdots (p_\omega-1)^{\alpha_\omega}$ and $A(n)=\sum_{k\le n}a(k)$ . Calculate the value of $$\lim_{n\to\infty}\frac{A(n)}{n^2/2}.$$ Hence deduce the average order of $a(n)$ . Quick Result $a$ is a completely multiplicative function with $a(p)=p-1$ . Attempt It is not hard to see $a$ is the Dirichlet inverse of $\mu\cdot\varphi$ , where $\cdot$ denotes the ordinary multiplication. Hence, the Dirichlet generating function of $a$ is $$\left(\sum_{n=1}^\infty\frac{\mu(n)\varphi(n)}{n^s}\right)^{-1}=\prod_{p}\frac{1}{1-p^{-s}(p-1)}$$ But the Dirichlet g.f. can be also written as $$\sum_{n=1}^{\infty}{\frac{a(n)}{n^s}}=1+\sum_{n=1}^{\infty}{A(n) \left( \frac{1}{n^s}-\frac{1}{\left( n+1 \right) ^s} \right)}=1+s\int_1^{\infty}{\frac{A( x )}{x^{s+1}}\mathrm{d}x}$$ Apply inverse Mellin transform, for $x>1$ , $$A( x ) =\frac{1}{2\pi}\int_{-\infty}^{\infty}{\frac{x^z}{z}\left( \sum_{n=1}^{\infty}{\frac{a(n)}{n^z}} -1 \right) \text{d}t},\ (z=\sigma +it,\ \sigma>2) \\ =\frac{1}{2\pi}\int_{-\infty}^{\infty}{\frac{x^z}{z} \prod_p\frac{1}{1-p^{-z}( p-1 )} \mathrm{d}t}-1 $$ So the next thing may be investigating $\prod_p\frac{1}{1-p^{-z}\ ( p-1 )}$ , but I am not able to do that. Computational Result Mathematica suggests that the limit $\lim_{n\to\infty}\frac{A(n)}{n^2}\approx0.25727$ and even $A(n)=Cn^2+o(n\ln n)$ for some constant $C$ .","Question : Consider be the prime factorization of . Define and . Calculate the value of Hence deduce the average order of . Quick Result is a completely multiplicative function with . Attempt It is not hard to see is the Dirichlet inverse of , where denotes the ordinary multiplication. Hence, the Dirichlet generating function of is But the Dirichlet g.f. can be also written as Apply inverse Mellin transform, for , So the next thing may be investigating , but I am not able to do that. Computational Result Mathematica suggests that the limit and even for some constant .","n=p_1^{\alpha_1}\cdots p_\omega^{\alpha_\omega} n a(n)=(p_1-1)^{\alpha_1}\cdots (p_\omega-1)^{\alpha_\omega} A(n)=\sum_{k\le n}a(k) \lim_{n\to\infty}\frac{A(n)}{n^2/2}. a(n) a a(p)=p-1 a \mu\cdot\varphi \cdot a \left(\sum_{n=1}^\infty\frac{\mu(n)\varphi(n)}{n^s}\right)^{-1}=\prod_{p}\frac{1}{1-p^{-s}(p-1)} \sum_{n=1}^{\infty}{\frac{a(n)}{n^s}}=1+\sum_{n=1}^{\infty}{A(n) \left( \frac{1}{n^s}-\frac{1}{\left( n+1 \right) ^s} \right)}=1+s\int_1^{\infty}{\frac{A( x )}{x^{s+1}}\mathrm{d}x} x>1 A( x ) =\frac{1}{2\pi}\int_{-\infty}^{\infty}{\frac{x^z}{z}\left( \sum_{n=1}^{\infty}{\frac{a(n)}{n^z}} -1 \right) \text{d}t},\ (z=\sigma +it,\ \sigma>2)
\\
=\frac{1}{2\pi}\int_{-\infty}^{\infty}{\frac{x^z}{z} \prod_p\frac{1}{1-p^{-z}( p-1 )} \mathrm{d}t}-1
 \prod_p\frac{1}{1-p^{-z}\ ( p-1 )} \lim_{n\to\infty}\frac{A(n)}{n^2}\approx0.25727 A(n)=Cn^2+o(n\ln n) C","['complex-analysis', 'number-theory', 'limits', 'asymptotics']"
31,What exactly is the relationship between the concepts of conjugate complex vector space and conjugations/real structures?,What exactly is the relationship between the concepts of conjugate complex vector space and conjugations/real structures?,,"I started studying the book of Daniel Huybrechts, Complex Geometry An Introduction. I tried studying backwards as much as possible, but I have been stuck on the concepts of almost complex structures and complexification . I have studied several books and articles on the matter including ones by Keith Conrad , Jordan Bell , Gregory W. Moore , Steven Roman , Suetin, Kostrikin and Mainin , Gauthier I have several questions on the concepts of almost complex structures and complexification. Here is one: Assumptions, notations and what I understand so far : Let $V$ be a $\mathbb C$ -vector space. Let $W$ be an $\mathbb R$ -vector space. Let $V_{\mathbb R}$ be the realification of $V$ . For any almost complex structure $I$ on $V_{\mathbb R}$ , denote by $(V_{\mathbb R},I)$ as the unique $\mathbb C$ -vector space whose complex structure is given $(a+bi) \cdot v := av + bI(v)$ . Let $i^{\sharp}$ be the unique almost complex structure on $V_{\mathbb R}$ such that $V=(V_{\mathbb R},i^{\sharp})$ . Let $W^{\mathbb C}$ denote the complexification of $W$ given by $W^{\mathbb C} := (W^2,J)$ , where $J$ is the ' canonical ' almost complex structure on $W^2$ given by $J(v,w):=(-w,v)$ . The map $\chi: W^2 \to W^2$ , $\chi(v,w):=(v,-w)$ is such that $\chi^J: W^{\mathbb C} \to W^{\mathbb C}$ , which is $\chi$ now viewed as a map on $W^{\mathbb C}$ instead of $W^2$ , is the 'canonical' conjugation/real structure . Here, 'canonical' is meant in the sense that we would use $J$ and $\chi$ to define complexifications of $W$ and of elements of $End_{\mathbb R}(W)$ . (See here .) Then the complex conjugate of $V$ is defined $\overline V := (V_{\mathbb R},-i^{\sharp})$ . Question : What exactly is  the relationship between the concept of $\overline V$ , the conjugation of $V$ and the concept of conjugations/real structures on $V$ ?","I started studying the book of Daniel Huybrechts, Complex Geometry An Introduction. I tried studying backwards as much as possible, but I have been stuck on the concepts of almost complex structures and complexification . I have studied several books and articles on the matter including ones by Keith Conrad , Jordan Bell , Gregory W. Moore , Steven Roman , Suetin, Kostrikin and Mainin , Gauthier I have several questions on the concepts of almost complex structures and complexification. Here is one: Assumptions, notations and what I understand so far : Let be a -vector space. Let be an -vector space. Let be the realification of . For any almost complex structure on , denote by as the unique -vector space whose complex structure is given . Let be the unique almost complex structure on such that . Let denote the complexification of given by , where is the ' canonical ' almost complex structure on given by . The map , is such that , which is now viewed as a map on instead of , is the 'canonical' conjugation/real structure . Here, 'canonical' is meant in the sense that we would use and to define complexifications of and of elements of . (See here .) Then the complex conjugate of is defined . Question : What exactly is  the relationship between the concept of , the conjugation of and the concept of conjugations/real structures on ?","V \mathbb C W \mathbb R V_{\mathbb R} V I V_{\mathbb R} (V_{\mathbb R},I) \mathbb C (a+bi) \cdot v := av + bI(v) i^{\sharp} V_{\mathbb R} V=(V_{\mathbb R},i^{\sharp}) W^{\mathbb C} W W^{\mathbb C} := (W^2,J) J W^2 J(v,w):=(-w,v) \chi: W^2 \to W^2 \chi(v,w):=(v,-w) \chi^J: W^{\mathbb C} \to W^{\mathbb C} \chi W^{\mathbb C} W^2 J \chi W End_{\mathbb R}(W) V \overline V := (V_{\mathbb R},-i^{\sharp}) \overline V V V","['linear-algebra', 'abstract-algebra', 'complex-analysis', 'complex-geometry', 'almost-complex']"
32,Asymptotics of Hypergeometric $_2F_1(a;b;c;z)$ for large $|z| \to \infty$?,Asymptotics of Hypergeometric  for large ?,_2F_1(a;b;c;z) |z| \to \infty,"I found this list of asymptotics of the Gauss Hypergeometric function $_2F_1(a;b;c;z)$ here on Wolfram's site for large $|z| \to \infty$ In particular there is a general formula for $|z| \to \infty$ $$ _2F_1(a;b;c;z) \approx \frac{\Gamma(b-a)\Gamma(c)}{\Gamma(b)\Gamma(c-a)} (-z)^{-a} +\frac{\Gamma(a-b)\Gamma(c)}{\Gamma(a)\Gamma(c-b)} (-z)^{-b} $$ How is this derived? Also, is this always true (meaning, for all $a$ , $b$ , $c$ )? There are no sources on the site I linked. Is there also a way to determine the next-order terms?","I found this list of asymptotics of the Gauss Hypergeometric function here on Wolfram's site for large In particular there is a general formula for How is this derived? Also, is this always true (meaning, for all , , )? There are no sources on the site I linked. Is there also a way to determine the next-order terms?","_2F_1(a;b;c;z) |z| \to \infty |z| \to \infty 
_2F_1(a;b;c;z) \approx \frac{\Gamma(b-a)\Gamma(c)}{\Gamma(b)\Gamma(c-a)} (-z)^{-a} +\frac{\Gamma(a-b)\Gamma(c)}{\Gamma(a)\Gamma(c-b)} (-z)^{-b}
 a b c","['complex-analysis', 'asymptotics', 'power-series', 'hypergeometric-function']"
33,Evaluate $\int_{|z|=3}\frac{dz}{z^3(z^{10}-2)}$,Evaluate,\int_{|z|=3}\frac{dz}{z^3(z^{10}-2)},"$$\int_{|z|=3}\frac{dz}{z^3(z^{10}-2)}$$ There are singularities at $z=0$ and $z^{10}=2\iff z=\sqrt[10]{2}e^{\frac{i\pi k}{5}} \text{  where   } k=0,1,...9$ so we need to find $10$ residues? or have I got it wrong?","$$\int_{|z|=3}\frac{dz}{z^3(z^{10}-2)}$$ There are singularities at $z=0$ and $z^{10}=2\iff z=\sqrt[10]{2}e^{\frac{i\pi k}{5}} \text{  where   } k=0,1,...9$ so we need to find $10$ residues? or have I got it wrong?",,"['complex-analysis', 'contour-integration', 'residue-calculus']"
34,Conformal map from $\mathbb C\setminus \{0\}$ to the open unit disk.,Conformal map from  to the open unit disk.,\mathbb C\setminus \{0\},"Is there a conformal/analytic map from $\mathbb C\setminus \{0\}$ to the open unit disk? I think the answer is no but I'm not sure how to prove it. I know that the former is not simply connected and the latter is simply-connected, but I'm not sure why this is useful or relevant since analytic maps are not necessarily homeomorphisms.","Is there a conformal/analytic map from $\mathbb C\setminus \{0\}$ to the open unit disk? I think the answer is no but I'm not sure how to prove it. I know that the former is not simply connected and the latter is simply-connected, but I'm not sure why this is useful or relevant since analytic maps are not necessarily homeomorphisms.",,[]
35,Higher dimensional equivalent of complex numbers,Higher dimensional equivalent of complex numbers,,"If complex numbers are in some sense 2 dimensional numbers, would it be useful or logical to extend the complex number system to a system of 3-dimensional or even n-dimensional numbers? If this does not make sense in general, why does it make sense only to extend from the 1st dimension to the 2nd dimension? What is special about 2-dimensional numbers that they are needed but n-dimensional numbers are not? I know that we have $R^k$, which is in some sense a field of $k$ dimensional numbers, but that is very different from the way in which complex numbers are constructed. So my question is could the complex numbers be extended to a 3rd dimension (or even an nth dimension) in the same way that the real numbers are extended to the complex numbers, in which the properties of complex numbers are preserved as a subset of this higher dimensional space?","If complex numbers are in some sense 2 dimensional numbers, would it be useful or logical to extend the complex number system to a system of 3-dimensional or even n-dimensional numbers? If this does not make sense in general, why does it make sense only to extend from the 1st dimension to the 2nd dimension? What is special about 2-dimensional numbers that they are needed but n-dimensional numbers are not? I know that we have $R^k$, which is in some sense a field of $k$ dimensional numbers, but that is very different from the way in which complex numbers are constructed. So my question is could the complex numbers be extended to a 3rd dimension (or even an nth dimension) in the same way that the real numbers are extended to the complex numbers, in which the properties of complex numbers are preserved as a subset of this higher dimensional space?",,"['real-analysis', 'complex-analysis']"
36,An entire function whose imaginary part is bounded is constant [duplicate],An entire function whose imaginary part is bounded is constant [duplicate],,"This question already has answers here : An entire function whose real part is bounded above must be constant. (3 answers) Closed 6 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved I need to prove the following question Question Let $g(z)$ be an entire function such that there exists an $\alpha > 0$ such that $\left|\operatorname{Im}(g(z))\right| \le \alpha$. Prove that $g(z)$ is a constant function. My first thought was to use Liouville's theorem. As that states, for an entire function $g$, if $g$ is bounded , then $g$ is constant. So if we could prove that $g$ is bounded, then by Liouville's theorem, $g$ is constant. I have attempted to prove that $g$ is bounded, but I am struggling. Some help would be much appreciated.","This question already has answers here : An entire function whose real part is bounded above must be constant. (3 answers) Closed 6 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved I need to prove the following question Question Let $g(z)$ be an entire function such that there exists an $\alpha > 0$ such that $\left|\operatorname{Im}(g(z))\right| \le \alpha$. Prove that $g(z)$ is a constant function. My first thought was to use Liouville's theorem. As that states, for an entire function $g$, if $g$ is bounded , then $g$ is constant. So if we could prove that $g$ is bounded, then by Liouville's theorem, $g$ is constant. I have attempted to prove that $g$ is bounded, but I am struggling. Some help would be much appreciated.",,"['complex-analysis', 'proof-explanation', 'entire-functions']"
37,Derivative of the conjugate of a function,Derivative of the conjugate of a function,,"In short, is the derivative of the conjugate of a function, the conjugate of the derivative of that function? We assume that the function is complex-valued. I think this property is true when the derivation variable is real, but my question is: if this is the case, can't we always do a change of variable so that we change from a real variable to a complex one? It's a bit confusing to me.","In short, is the derivative of the conjugate of a function, the conjugate of the derivative of that function? We assume that the function is complex-valued. I think this property is true when the derivation variable is real, but my question is: if this is the case, can't we always do a change of variable so that we change from a real variable to a complex one? It's a bit confusing to me.",,['complex-analysis']
38,How to find the residue of a pole?,How to find the residue of a pole?,,"I am trying to integrate the function $f(z)=\frac{z}{1-\cos z}$ inside the unit circle. I found the only singular point inside the unit circle to be $z=0$ since $\cos(x+iy)=1\Leftrightarrow y=0,x=2 \pi n$ is this correct way in doing this? I also found out that this singular point is a pole because $\lim \limits_{z \to 0}f(z)$ does not exist but $\lim \limits_{z \to 0}\frac{1}{f(z)}$ does exist thus $z=0$ is a pole of $f(z)$. How can I now proceed to find the residue at this point?","I am trying to integrate the function $f(z)=\frac{z}{1-\cos z}$ inside the unit circle. I found the only singular point inside the unit circle to be $z=0$ since $\cos(x+iy)=1\Leftrightarrow y=0,x=2 \pi n$ is this correct way in doing this? I also found out that this singular point is a pole because $\lim \limits_{z \to 0}f(z)$ does not exist but $\lim \limits_{z \to 0}\frac{1}{f(z)}$ does exist thus $z=0$ is a pole of $f(z)$. How can I now proceed to find the residue at this point?",,['complex-analysis']
39,How do I show that the complex conjugate of an integral is equal the integral of the conjugate?,How do I show that the complex conjugate of an integral is equal the integral of the conjugate?,,"$f:[a,b]\mapsto \mathbb{C}$ is Riemann integrable. It is given also that $a,b \in\ $ and that $a<b $. How do I show that: $\int_{a}^{b} \! \overline{f(x)} \, dx=\overline{\int_{a}^{b} \! f(x) \, dx } $ $\int f(x) dx = \int \operatorname{Re} f(x) dx + i\int \operatorname{Im} f(x) dx$ $\int_{a}^{b} \! \overline{ \operatorname{Re} f(x)  + i\int \operatorname{Im} } \, dx=\overline{\int_{a}^{b} \!  \operatorname{Re} f(x) + i\int \operatorname{Im} \, dx } $ $\int_{a}^{b} \!{\operatorname{Re} f(x) dx - i\int \operatorname{Im} f(x) } \, dx={\int_{a}^{b} \! \operatorname{Re} f(x) dx - i\int \operatorname{Im} f(x) dx } $ Is that all that I need for proof?","$f:[a,b]\mapsto \mathbb{C}$ is Riemann integrable. It is given also that $a,b \in\ $ and that $a<b $. How do I show that: $\int_{a}^{b} \! \overline{f(x)} \, dx=\overline{\int_{a}^{b} \! f(x) \, dx } $ $\int f(x) dx = \int \operatorname{Re} f(x) dx + i\int \operatorname{Im} f(x) dx$ $\int_{a}^{b} \! \overline{ \operatorname{Re} f(x)  + i\int \operatorname{Im} } \, dx=\overline{\int_{a}^{b} \!  \operatorname{Re} f(x) + i\int \operatorname{Im} \, dx } $ $\int_{a}^{b} \!{\operatorname{Re} f(x) dx - i\int \operatorname{Im} f(x) } \, dx={\int_{a}^{b} \! \operatorname{Re} f(x) dx - i\int \operatorname{Im} f(x) dx } $ Is that all that I need for proof?",,['complex-analysis']
40,Why should one be fascinated with $e^{i \pi} +1 = 0$? [closed],Why should one be fascinated with ? [closed],e^{i \pi} +1 = 0,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 7 years ago . Improve this question I know some people say that $e^{i \pi} +1= 0$ is cool because it links fundamental yet disparate constants. But to me, the existence of a ""nice"" equation like this is not surprising. For hundreds of years mathematicians have been trying to make everything as ""nice"" as possible; we define trigonometry to line up with the informal notion of the unit circle (as opposed to the $2$ units circle, or the $.352546...$ units circle), we always try to make sure our functions are differentiable or at least continous when we extend them, we define complexes so that the reals are nicely embedded in them, etc. So to me it just doesn't seem that surprising that after hundreds of years of fine-tuning our definitions to be nice, the definitions come full circle and spit out some nice equations.","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 7 years ago . Improve this question I know some people say that $e^{i \pi} +1= 0$ is cool because it links fundamental yet disparate constants. But to me, the existence of a ""nice"" equation like this is not surprising. For hundreds of years mathematicians have been trying to make everything as ""nice"" as possible; we define trigonometry to line up with the informal notion of the unit circle (as opposed to the $2$ units circle, or the $.352546...$ units circle), we always try to make sure our functions are differentiable or at least continous when we extend them, we define complexes so that the reals are nicely embedded in them, etc. So to me it just doesn't seem that surprising that after hundreds of years of fine-tuning our definitions to be nice, the definitions come full circle and spit out some nice equations.",,"['complex-analysis', 'complex-numbers', 'soft-question']"
41,Relationship between the quaternionic group and quaternionic numbers?,Relationship between the quaternionic group and quaternionic numbers?,,"The quaternionic group $\mathcal{Q}$ consists of the elements $1$, $-1$, $i$, $-i$,$j$,$-j$,$k$,$-k$ that satisfy the multiplication rules $$i^2=j^2=k^2=-1$$ $$ ij=-ji=k$$ $$jk=-kj=i$$ $$ki=-ik=j$$ The quaternionic numbers $$a+ib+cj+dk$$ form a division dividion algebra. In Group Theory in a Nutshell on p61 A.Zee writes that those two structures are completely unrelated, but I almost cant swallow this. Are the quaternionic group and the quaternionic numbers really completely unrelated?","The quaternionic group $\mathcal{Q}$ consists of the elements $1$, $-1$, $i$, $-i$,$j$,$-j$,$k$,$-k$ that satisfy the multiplication rules $$i^2=j^2=k^2=-1$$ $$ ij=-ji=k$$ $$jk=-kj=i$$ $$ki=-ik=j$$ The quaternionic numbers $$a+ib+cj+dk$$ form a division dividion algebra. In Group Theory in a Nutshell on p61 A.Zee writes that those two structures are completely unrelated, but I almost cant swallow this. Are the quaternionic group and the quaternionic numbers really completely unrelated?",,"['complex-analysis', 'group-theory', 'quaternions']"
42,Relation between moduli of curves and Teichmüller theory,Relation between moduli of curves and Teichmüller theory,,"Both the theory of moduli of curves and Teichmüller theory seem to be concerned with the moduli of Riemann surfaces. However, they appear to belong to different fields within mathematics. Could someone explain in which ways these approaches to studying Riemann surfaces differ and wherein their similarities lie? Also, I have seen that in both theories compactifications appear to play an important role and I would be interested to hear if these are somehow related. I have heard that to compactify, one has to add curves of a different genus. Does this apply to both theories?","Both the theory of moduli of curves and Teichmüller theory seem to be concerned with the moduli of Riemann surfaces. However, they appear to belong to different fields within mathematics. Could someone explain in which ways these approaches to studying Riemann surfaces differ and wherein their similarities lie? Also, I have seen that in both theories compactifications appear to play an important role and I would be interested to hear if these are somehow related. I have heard that to compactify, one has to add curves of a different genus. Does this apply to both theories?",,"['complex-analysis', 'algebraic-geometry', 'algebraic-curves', 'riemann-surfaces', 'teichmueller-theory']"
43,Finding Residue,Finding Residue,,"I am having difficulty with with calculating the residue for $$\text{res}[\frac{\exp(\frac{1}{z})}{z^{2}-16,},z=0]$$   I was able to calculate the residues when $z=4$ and $z=-4$. However Im not sure how to approach this part of the question.","I am having difficulty with with calculating the residue for $$\text{res}[\frac{\exp(\frac{1}{z})}{z^{2}-16,},z=0]$$   I was able to calculate the residues when $z=4$ and $z=-4$. However Im not sure how to approach this part of the question.",,['complex-analysis']
44,Are real numbers complex conjugates of one another?,Are real numbers complex conjugates of one another?,,"I'm just stuck with a technical part of my proof that might just be a triviality:  if two different numbers are both real, are they complex conjugates of each other? Thanks,","I'm just stuck with a technical part of my proof that might just be a triviality:  if two different numbers are both real, are they complex conjugates of each other? Thanks,",,"['calculus', 'real-analysis', 'complex-analysis', 'complex-numbers', 'real-numbers']"
45,Prove that $\left|\frac{z_1-z_2}{1-z_1\bar{z_2}}\right|\lt 1$ [duplicate],Prove that  [duplicate],\left|\frac{z_1-z_2}{1-z_1\bar{z_2}}\right|\lt 1,"This question already has answers here : Show that $\left|\frac{\alpha - \beta}{1-\bar{\alpha}\beta}\right| < 1$ when $|\alpha|,|\beta| < 1$ (4 answers) Closed 6 years ago . Question: Prove that $\left|\dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right|\lt 1$ if $|z_1|\lt1$, $ |z_2|\lt 1$ My solution: I had no idea how to go about this one so instead I started simplifying the inequality and my solution is as follows:- $$\begin{equation} \left|\dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right|\lt 1 \\ \implies \left|\dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right|^2\lt 1 \\  \implies \left( \dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right)\overline{\left({\dfrac{z_1-z_2}{1-z_1\bar{z_2}}}\right)} \lt 1 \\ \implies |z_1|^2+|z_2|^2 \lt 1 +|z_1|^2|z_2|^2 \\ \implies (|z_1|^2-1)(1-|z_2|^2) \lt 0 \end{equation}$$ Now as $|z_1| \lt 1$, so $(|z_1|^2-1) \lt 0$ and similarly $(1-|z_2|^2) \gt 0$, hence we can safely conclude that the above inequality holds. Whats my question about:- Now the book that I am solving from also gave the same solution it just further factored $(|z_1|^2-1)(1-|z_2|^2)$. This doesn't seem a good enough proof for me. If anyone can suggest a proof which doesn't simply verify the statement to be proved. P.S.:- This question has also been asked here , but I don't think I have the same query as the OP of that post.","This question already has answers here : Show that $\left|\frac{\alpha - \beta}{1-\bar{\alpha}\beta}\right| < 1$ when $|\alpha|,|\beta| < 1$ (4 answers) Closed 6 years ago . Question: Prove that $\left|\dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right|\lt 1$ if $|z_1|\lt1$, $ |z_2|\lt 1$ My solution: I had no idea how to go about this one so instead I started simplifying the inequality and my solution is as follows:- $$\begin{equation} \left|\dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right|\lt 1 \\ \implies \left|\dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right|^2\lt 1 \\  \implies \left( \dfrac{z_1-z_2}{1-z_1\bar{z_2}}\right)\overline{\left({\dfrac{z_1-z_2}{1-z_1\bar{z_2}}}\right)} \lt 1 \\ \implies |z_1|^2+|z_2|^2 \lt 1 +|z_1|^2|z_2|^2 \\ \implies (|z_1|^2-1)(1-|z_2|^2) \lt 0 \end{equation}$$ Now as $|z_1| \lt 1$, so $(|z_1|^2-1) \lt 0$ and similarly $(1-|z_2|^2) \gt 0$, hence we can safely conclude that the above inequality holds. Whats my question about:- Now the book that I am solving from also gave the same solution it just further factored $(|z_1|^2-1)(1-|z_2|^2)$. This doesn't seem a good enough proof for me. If anyone can suggest a proof which doesn't simply verify the statement to be proved. P.S.:- This question has also been asked here , but I don't think I have the same query as the OP of that post.",,"['complex-analysis', 'algebra-precalculus', 'inequality', 'complex-numbers', 'complex-geometry']"
46,"If a function $f$ is holomorphic on the closed unit disk centered at the origin and is real valued whenever $|z| = 1$, then $f$ is constant.","If a function  is holomorphic on the closed unit disk centered at the origin and is real valued whenever , then  is constant.",f |z| = 1 f,"I am preparing for qualifying exams, and this is a question from the Penn State Qualifying Exam for Fall 2015. It is stated as follows Let $\epsilon > 0$ and let $f$ be holomorphic (analytic) on the disk $S = \{z \in \mathbb{C} \ | \ |z| < 1 + \epsilon \}$. Suppose that $f(z)$ is real valued whenever $|z| = 1$. Prove that $f$ is constant. I have tried a few things in showing this to be true, but I keep finding holes in my logic. My largest issue is that the portion of the domain in which $f$ is real valued is not open, and so I'm not able to use many of the theorems I otherwise feel would be helpful (Open Mapping Theorem, Cauchy-Riemann Equations, Maximum Modulus, etc.). Most of my attacks towards this problem have centered around showing things for the unit disk $\mathbb{D}$ instead of $S$, because I figure if I can show that $f$ is constant on $\mathbb{D}$, then I can use the Identity Theorem to extend it to $S$. However, since I don't know anything about the specific values that $f$ obtains, I can't use Schwarz' Lemma either. I played with the idea, also, of suggesting that, if we consider the closure of $\mathbb{D}$, then $f(\partial{\mathbb{D}}) \in \mathbb{R}$. Since $\partial\mathbb{D}$ is closed and bounded and $f$ is analytic, it's image should also be bounded. That would put, for some $M \in \mathbb{R}$, $f(\partial{\mathbb{D}}) \in [-M,M]$, which is bounded and obtains a maximum (since $f$ is continuous and real valued here). I know that this set isn't open, but there is a Corollary in my text (Complex Analysis - Freitag) that says the following: ""If $K$ is a compact subset of the domain $D$ and $f:D \rightarrow \mathbb{C}$ is analytic, then the restriction of $f|K$ being a continuous function has a maximal modulus on $K$. By the Maximum Modulus Principle, we can moreover affirm that the maximal modulus value is necessarily taken on the boundary of $\mathbb{D}$."" The proof of that statement follows from the Open Mapping Theorem. Would it be appropriate to use that in this case, then? If $K = \partial \mathbb{D}$, even though it's technically not an open set, can I say that $f$ obtains its maximum on $\mathbb{D}$, state that it's constant, and then extend this to $S$ using the Identity Theorem? My issue here is that the constant itself isn't actually in $\mathbb{D}$, I appreciate any help for this problem (or any tips for showing that complex functions will be constant, as these types of problems show up often). Edit: My function $f$ is not necessarily entire, so Liouville's Theorem does not apply","I am preparing for qualifying exams, and this is a question from the Penn State Qualifying Exam for Fall 2015. It is stated as follows Let $\epsilon > 0$ and let $f$ be holomorphic (analytic) on the disk $S = \{z \in \mathbb{C} \ | \ |z| < 1 + \epsilon \}$. Suppose that $f(z)$ is real valued whenever $|z| = 1$. Prove that $f$ is constant. I have tried a few things in showing this to be true, but I keep finding holes in my logic. My largest issue is that the portion of the domain in which $f$ is real valued is not open, and so I'm not able to use many of the theorems I otherwise feel would be helpful (Open Mapping Theorem, Cauchy-Riemann Equations, Maximum Modulus, etc.). Most of my attacks towards this problem have centered around showing things for the unit disk $\mathbb{D}$ instead of $S$, because I figure if I can show that $f$ is constant on $\mathbb{D}$, then I can use the Identity Theorem to extend it to $S$. However, since I don't know anything about the specific values that $f$ obtains, I can't use Schwarz' Lemma either. I played with the idea, also, of suggesting that, if we consider the closure of $\mathbb{D}$, then $f(\partial{\mathbb{D}}) \in \mathbb{R}$. Since $\partial\mathbb{D}$ is closed and bounded and $f$ is analytic, it's image should also be bounded. That would put, for some $M \in \mathbb{R}$, $f(\partial{\mathbb{D}}) \in [-M,M]$, which is bounded and obtains a maximum (since $f$ is continuous and real valued here). I know that this set isn't open, but there is a Corollary in my text (Complex Analysis - Freitag) that says the following: ""If $K$ is a compact subset of the domain $D$ and $f:D \rightarrow \mathbb{C}$ is analytic, then the restriction of $f|K$ being a continuous function has a maximal modulus on $K$. By the Maximum Modulus Principle, we can moreover affirm that the maximal modulus value is necessarily taken on the boundary of $\mathbb{D}$."" The proof of that statement follows from the Open Mapping Theorem. Would it be appropriate to use that in this case, then? If $K = \partial \mathbb{D}$, even though it's technically not an open set, can I say that $f$ obtains its maximum on $\mathbb{D}$, state that it's constant, and then extend this to $S$ using the Identity Theorem? My issue here is that the constant itself isn't actually in $\mathbb{D}$, I appreciate any help for this problem (or any tips for showing that complex functions will be constant, as these types of problems show up often). Edit: My function $f$ is not necessarily entire, so Liouville's Theorem does not apply",,"['complex-analysis', 'analyticity', 'maximum-principle']"
47,$\int_0^\infty \frac{ x^{1/3}}{(x+a)(x+b)} dx $,,\int_0^\infty \frac{ x^{1/3}}{(x+a)(x+b)} dx ,$$\int_0^\infty \frac{ x^{1/3}}{(x+a)(x+b)} dx$$ where $a>b>0$ What shall I do? I have diffucty when I meet multi value function.,$$\int_0^\infty \frac{ x^{1/3}}{(x+a)(x+b)} dx$$ where $a>b>0$ What shall I do? I have diffucty when I meet multi value function.,,"['complex-analysis', 'improper-integrals']"
48,Use complex substitution to evaluate integral,Use complex substitution to evaluate integral,,Use the substitution $z = e^{i\theta}$ to evaluate $$\int_{0}^{2\pi} \frac{d\theta}{\sin(\theta)-2}$$ Can somebody point me in the right direction?,Use the substitution $z = e^{i\theta}$ to evaluate $$\int_{0}^{2\pi} \frac{d\theta}{\sin(\theta)-2}$$ Can somebody point me in the right direction?,,['complex-analysis']
49,Meromorphic Function on Extended Plane,Meromorphic Function on Extended Plane,,How do I prove that every meromorphic function on the extended plane is a rational function?,How do I prove that every meromorphic function on the extended plane is a rational function?,,"['complex-analysis', 'power-series', 'taylor-expansion', 'laurent-series', 'singularity-theory']"
50,What happens to poles lying on branch cuts in contour integration?,What happens to poles lying on branch cuts in contour integration?,,"Inverse the Laplace Transform $$\frac{1}{\sqrt{s}}\cdot\frac{1}{1 + s}$$ back to time domain requires evaluation of Bromwich integration: $$\frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i\infty} \frac{1}{\sqrt{s}}\cdot\frac{1}{1 + s} e^{st} ds$$ The $\sqrt{s}$ term causes a branch cut along the negative half $x$ -axis, including the origin. My question is what happens to the point $(-1, 0)$ : it is both a pole, and lies on the branch cut. More specifically, when constructing the contour integration path, could I just ignore the pole because the branch cut removes it (figure A), or I should deform the contour as half circles around the pole, once on each side of the branch cut (figure B), as if the pole is duplicated ? Figure A and B: contour integration path","Inverse the Laplace Transform back to time domain requires evaluation of Bromwich integration: The term causes a branch cut along the negative half -axis, including the origin. My question is what happens to the point : it is both a pole, and lies on the branch cut. More specifically, when constructing the contour integration path, could I just ignore the pole because the branch cut removes it (figure A), or I should deform the contour as half circles around the pole, once on each side of the branch cut (figure B), as if the pole is duplicated ? Figure A and B: contour integration path","\frac{1}{\sqrt{s}}\cdot\frac{1}{1 + s} \frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i\infty} \frac{1}{\sqrt{s}}\cdot\frac{1}{1 + s} e^{st} ds \sqrt{s} x (-1, 0)","['complex-analysis', 'laplace-transform', 'contour-integration', 'cauchy-principal-value']"
51,Complex Integration with trignometric function,Complex Integration with trignometric function,,Verify that   $\int_0^{\frac{\pi}{2}}\frac{d\theta}{a+\sin^2\theta}=\frac{\pi}{2[(a(a+1)]^\frac{1}{2}}$ I know that $\sin\theta=\frac{e^{i\theta}-e^{-i\theta}}{2}$ then I did $$\int_0^{\frac{\pi}{2}}\frac{d\theta}{a+\sin^2\theta}=\int_0^{\frac{\pi}{2}}\frac{d\theta}{a+\frac{1}{4}(e^{i\theta}-e^{-i\theta})^2}=\int_0^{\frac{\pi}{2}}\frac{4d\theta}{4a+(e^{i\theta}-e^{-i\theta})^2}$$ I do not know if this is right but I'm really stuck,Verify that   $\int_0^{\frac{\pi}{2}}\frac{d\theta}{a+\sin^2\theta}=\frac{\pi}{2[(a(a+1)]^\frac{1}{2}}$ I know that $\sin\theta=\frac{e^{i\theta}-e^{-i\theta}}{2}$ then I did $$\int_0^{\frac{\pi}{2}}\frac{d\theta}{a+\sin^2\theta}=\int_0^{\frac{\pi}{2}}\frac{d\theta}{a+\frac{1}{4}(e^{i\theta}-e^{-i\theta})^2}=\int_0^{\frac{\pi}{2}}\frac{4d\theta}{4a+(e^{i\theta}-e^{-i\theta})^2}$$ I do not know if this is right but I'm really stuck,,"['complex-analysis', 'complex-numbers', 'residue-calculus', 'complex-integration']"
52,Evaluating past exam problem: $\int_C \frac{\sin z}{(z+1)^7} \mathrm{d}z$,Evaluating past exam problem:,\int_C \frac{\sin z}{(z+1)^7} \mathrm{d}z,"I want to evaluate the following: $$\int_C \frac{\sin z}{(z+1)^7} \mathrm{d}z$$ Where $C$ is the circle of radius $5$, centre $0$, positively oriented. Now this has one root at $z=-1$. Now I should probably use the Cauchy integral formula: Then I get $$\int_C \frac{\sin z}{(z+1)^7} \mathrm{d}z=\int_C \frac{\sin z /(z+1)^6}{z-(-1)}\mathrm{d}z$$ But I have the same problem in regards to wanting to avoid $z=1$ How else should I go about this.","I want to evaluate the following: $$\int_C \frac{\sin z}{(z+1)^7} \mathrm{d}z$$ Where $C$ is the circle of radius $5$, centre $0$, positively oriented. Now this has one root at $z=-1$. Now I should probably use the Cauchy integral formula: Then I get $$\int_C \frac{\sin z}{(z+1)^7} \mathrm{d}z=\int_C \frac{\sin z /(z+1)^6}{z-(-1)}\mathrm{d}z$$ But I have the same problem in regards to wanting to avoid $z=1$ How else should I go about this.",,"['complex-analysis', 'contour-integration']"
53,Why do we assume the complex plane is curvey at infinity?,Why do we assume the complex plane is curvey at infinity?,,"In at least a few areas (i.e., those that I have happened across) when we have a need to capture a half-plane we do so by taking a semi-circle of radius $r$ in that half, and taking the limit as $r\rightarrow\infty$. For example, the positive-imaginary half-plane for Jordan's Lemma, or the positive-real half-plane to construct the Nyquist Contour. What motivates this model? It would seem to me that in a 'Cartesian-like' grid, we should have to take a semi-square of side length $s$ (that is, an $s, 2s$ sided rectangle) in the limit $s\rightarrow\infty$. How do we know the semi-circle construction is equivalent? (Or, why am I wrong, and the rectangular construction doesn't work?) I have a sort of sketchy idea from discussion in comments of @texasfloods' answer that I can't think how to formalise - that given the unit circle $x^2+y^2=r^2$ it seems intuitive that taking $\lim_{r\rightarrow\infty}$ is identical to $\lim_{\sqrt{x^2+y^2}\rightarrow\infty}$, the hypotenuse of the right triangle, and by a bit of hand-waving, ""done"". Also from @pbs' comment below, it seems reasonable to say that for any open set $A$ of points enclosed by any 'contour shape' $\Gamma, \forall z\in A$ there exists a 'large-enough' construction of $\Gamma$ to enclose $z$. I'm fairly convinced, but I'd still be interested in a more 'proper'/rigorous proof or explanation if anyone cares to offer one.","In at least a few areas (i.e., those that I have happened across) when we have a need to capture a half-plane we do so by taking a semi-circle of radius $r$ in that half, and taking the limit as $r\rightarrow\infty$. For example, the positive-imaginary half-plane for Jordan's Lemma, or the positive-real half-plane to construct the Nyquist Contour. What motivates this model? It would seem to me that in a 'Cartesian-like' grid, we should have to take a semi-square of side length $s$ (that is, an $s, 2s$ sided rectangle) in the limit $s\rightarrow\infty$. How do we know the semi-circle construction is equivalent? (Or, why am I wrong, and the rectangular construction doesn't work?) I have a sort of sketchy idea from discussion in comments of @texasfloods' answer that I can't think how to formalise - that given the unit circle $x^2+y^2=r^2$ it seems intuitive that taking $\lim_{r\rightarrow\infty}$ is identical to $\lim_{\sqrt{x^2+y^2}\rightarrow\infty}$, the hypotenuse of the right triangle, and by a bit of hand-waving, ""done"". Also from @pbs' comment below, it seems reasonable to say that for any open set $A$ of points enclosed by any 'contour shape' $\Gamma, \forall z\in A$ there exists a 'large-enough' construction of $\Gamma$ to enclose $z$. I'm fairly convinced, but I'd still be interested in a more 'proper'/rigorous proof or explanation if anyone cares to offer one.",,"['complex-analysis', 'limits', 'coordinate-systems']"
54,Is entire function a polynomial? [duplicate],Is entire function a polynomial? [duplicate],,"This question already has answers here : Entire function with vanishing derivatives? (3 answers) Closed 9 years ago . Let $f:\mathbb{C}\to \mathbb{C}$ be an entire function, and suppose that for every $z\in \mathbb{C}$ there exists $n_z\in \mathbb{N}$ such that $f^{(n_z)}(z)=0$. Is $f$ necessarily a polynomial?","This question already has answers here : Entire function with vanishing derivatives? (3 answers) Closed 9 years ago . Let $f:\mathbb{C}\to \mathbb{C}$ be an entire function, and suppose that for every $z\in \mathbb{C}$ there exists $n_z\in \mathbb{N}$ such that $f^{(n_z)}(z)=0$. Is $f$ necessarily a polynomial?",,['complex-analysis']
55,Laurent series of $\frac{1}{\sin(z)}$,Laurent series of,\frac{1}{\sin(z)},"Let $\sum_{n=-\infty}^\infty a_n z^n$ be the Laurent series of $\frac{1}{\sin (z)}$ for $|z| < \pi$. I'm asked to prove that if $n < -1$ or $n$ is even, then $a_n = 0$. I'm also asked to compute $a_{-1}$ and $a_1$. What's a good way to approach this problem?","Let $\sum_{n=-\infty}^\infty a_n z^n$ be the Laurent series of $\frac{1}{\sin (z)}$ for $|z| < \pi$. I'm asked to prove that if $n < -1$ or $n$ is even, then $a_n = 0$. I'm also asked to compute $a_{-1}$ and $a_1$. What's a good way to approach this problem?",,['complex-analysis']
56,Show that holomorphic function $f: \mathbb{C} \rightarrow \mathbb{C}$ is constant,Show that holomorphic function  is constant,f: \mathbb{C} \rightarrow \mathbb{C},Let's $f: \mathbb{C} \rightarrow \mathbb{C}$ be a holomorphic function such that values $f$ are on line $y=ax+b$. Show that $f$ is constant. I think I should use Cauchy-Riemann equations but I don't know what does mean that values $f$ are on line $y=ax+b$. Can you explain me that? Thanks in advance.,Let's $f: \mathbb{C} \rightarrow \mathbb{C}$ be a holomorphic function such that values $f$ are on line $y=ax+b$. Show that $f$ is constant. I think I should use Cauchy-Riemann equations but I don't know what does mean that values $f$ are on line $y=ax+b$. Can you explain me that? Thanks in advance.,,['complex-analysis']
57,The Laurent series of $1/(z^2+1)^2$ in the annulus $0<|z-i|<2$,The Laurent series of  in the annulus,1/(z^2+1)^2 0<|z-i|<2,I can't figure it out how to solve this problem: Find the Laurent Series of the function $$f(z)=\frac{1}{(z^2+1)^2}$$ valid in $A=\{z \in \mathbb{C} : 0 < |z-i|<2\}$ I think that it is impossible because we have the $-i$ singularity that restrict $A$.,I can't figure it out how to solve this problem: Find the Laurent Series of the function $$f(z)=\frac{1}{(z^2+1)^2}$$ valid in $A=\{z \in \mathbb{C} : 0 < |z-i|<2\}$ I think that it is impossible because we have the $-i$ singularity that restrict $A$.,,"['complex-analysis', 'laurent-series']"
58,Divisor and Riemann Zeta functions series proofs,Divisor and Riemann Zeta functions series proofs,,"Where d(n) is the number of divisors of n, show that $\sum_{n=1}^\infty d(n)z^n = \sum_{k=1}^\infty \frac{z^k}{1-z^k}$ where both sides converge for |z|<1 and show that $\sum_{n=1}^\infty \frac{d(n)}{n^s} = (ζ(s))^2$ I've tried playing around with various forms of the divisor function and the Riemann Zeta function, but I can't seem to get anywhere with the first part of the problem. I would really appreciate some help getting started","Where d(n) is the number of divisors of n, show that $\sum_{n=1}^\infty d(n)z^n = \sum_{k=1}^\infty \frac{z^k}{1-z^k}$ where both sides converge for |z|<1 and show that $\sum_{n=1}^\infty \frac{d(n)}{n^s} = (ζ(s))^2$ I've tried playing around with various forms of the divisor function and the Riemann Zeta function, but I can't seem to get anywhere with the first part of the problem. I would really appreciate some help getting started",,"['complex-analysis', 'riemann-zeta']"
59,"Comparison of the consequences of uniform convergence between the real and complex variable cases,","Comparison of the consequences of uniform convergence between the real and complex variable cases,",,"In the real variable case, I think that uniform convergence preserves continuity and integrability, i.e., for an integral of a sequence of continuous (or integrable) functions, which converge uniformly to some function over a set E, then we know that this function is continuous (or integrable) -- and then the limit of the integrals is equal to the integral of the limit function.  (the stronger version of this integration theorem, the dominated convergence theorem, only requires pointwise convergence of the functions, in order to take the limit inside the integral.) What else can we get from uniform convergence in the real variable case?  Does it preserve differentiability?  Or, in general it does not? And, I think in the complex variable setting, uniform convergence preserves all of continuity, integrability, and differentiability. ...anything else to be aware of? Thanks in advance,","In the real variable case, I think that uniform convergence preserves continuity and integrability, i.e., for an integral of a sequence of continuous (or integrable) functions, which converge uniformly to some function over a set E, then we know that this function is continuous (or integrable) -- and then the limit of the integrals is equal to the integral of the limit function.  (the stronger version of this integration theorem, the dominated convergence theorem, only requires pointwise convergence of the functions, in order to take the limit inside the integral.) What else can we get from uniform convergence in the real variable case?  Does it preserve differentiability?  Or, in general it does not? And, I think in the complex variable setting, uniform convergence preserves all of continuity, integrability, and differentiability. ...anything else to be aware of? Thanks in advance,",,"['real-analysis', 'complex-analysis', 'uniform-convergence']"
60,Why is a Möbius transform uniquely determined based on known mappings of three points?,Why is a Möbius transform uniquely determined based on known mappings of three points?,,"Why can the Möbius transform $\displaystyle{\frac{az+b}{cz+d}}$ be uniquely determined if one is aware that $\{p_1,p_2,p_3\}$ maps to $\{q_1,q_2,q_3\}$ where $p_1,\dots,q_3\in\Bbb{C}$? Seeing as there are four unknowns $a,b,c,d$, shouldn't the mappings be known for four points instead of three?","Why can the Möbius transform $\displaystyle{\frac{az+b}{cz+d}}$ be uniquely determined if one is aware that $\{p_1,p_2,p_3\}$ maps to $\{q_1,q_2,q_3\}$ where $p_1,\dots,q_3\in\Bbb{C}$? Seeing as there are four unknowns $a,b,c,d$, shouldn't the mappings be known for four points instead of three?",,[]
61,"Let $f$ be a holomorphic in $D(0,1)$, with Re$\,f(z) >0$ and $f(0)=1.$ Then $\lvert\, f'(0)\rvert\leq 2$","Let  be a holomorphic in , with Re and  Then","f D(0,1) \,f(z) >0 f(0)=1. \lvert\, f'(0)\rvert\leq 2","Let $f:D(0,1) \to \mathbb{C}$ be a holomorphic function, such that $$ \mathrm{Re} \,f(z) >0\quad \text{and}\quad f(0)=1. $$ How to prove $\lvert\, f'(0)\rvert\leq 2 \ ?$ This is now a self-answered question.","Let $f:D(0,1) \to \mathbb{C}$ be a holomorphic function, such that $$ \mathrm{Re} \,f(z) >0\quad \text{and}\quad f(0)=1. $$ How to prove $\lvert\, f'(0)\rvert\leq 2 \ ?$ This is now a self-answered question.",,"['complex-analysis', 'inequality', 'derivatives', 'absolute-value']"
62,"Find a meromorphic function $f$ with poles at $\dots,-3,-2,-1$",Find a meromorphic function  with poles at,"f \dots,-3,-2,-1","I need help with the following problem: Find a meromorphic function $f:\mathbb{C}\longrightarrow \mathbb{C}$ whose only singularities are simple poles at $\dots,-3,-2,-1$ with residues $n$ at $z=-n$. Any hint would be appreciated.","I need help with the following problem: Find a meromorphic function $f:\mathbb{C}\longrightarrow \mathbb{C}$ whose only singularities are simple poles at $\dots,-3,-2,-1$ with residues $n$ at $z=-n$. Any hint would be appreciated.",,"['complex-analysis', 'functions']"
63,Show that $\int_\gamma \frac{f'(z)}{f(z)}=0$ for every closed curve $\gamma$ in $\Omega$,Show that  for every closed curve  in,\int_\gamma \frac{f'(z)}{f(z)}=0 \gamma \Omega,"I have just started taking complex analysis course,The following problem is given in my class.Please help me solving it. Thnx in advance. Suppose $f(z)$ is analytic and satisfies the relation $|f(z)-1| < 1 $ in a region $\Omega$ Show that $\displaystyle \int_\gamma \frac{f'(z)}{f(z)}=0$ for every closed curve $\gamma$ in $\Omega$ I am only taught upto Cauchy's Theorem which I think is applicable for disc. Now here nothing is mentioned about $\Omega$ , only thing I know that it is open connected.So how can I apply Cauchy's Theorem here? Being very new to complex analysis I appologise if I am missing something very simple or doing something very much wrong. Please help me to solve this question. Thnx again.","I have just started taking complex analysis course,The following problem is given in my class.Please help me solving it. Thnx in advance. Suppose is analytic and satisfies the relation in a region Show that for every closed curve in I am only taught upto Cauchy's Theorem which I think is applicable for disc. Now here nothing is mentioned about , only thing I know that it is open connected.So how can I apply Cauchy's Theorem here? Being very new to complex analysis I appologise if I am missing something very simple or doing something very much wrong. Please help me to solve this question. Thnx again.",f(z) |f(z)-1| < 1  \Omega \displaystyle \int_\gamma \frac{f'(z)}{f(z)}=0 \gamma \Omega \Omega,['complex-analysis']
64,The set of zeros of a holomorphic function is finite in compact sets,The set of zeros of a holomorphic function is finite in compact sets,,"Statement Let $f:\mathbb \Omega \to \mathbb C$ be a holomorphic function, $f \neq 0$ ($\Omega$ is a region, i.e., an open, nonempty, connected set). Prove that in every compact subset $K$ of $\Omega$, the set of zeros of $f$ is finite. I've read in Stein's textbook a proof of the statement ""Suppose $f$ is a holomorphic function in a region $\Omega$ that vanishes on a sequence of distinct points with a limit point in $\Omega$. Then $f$ is identically zero."" From that statement, one can easily deduce that the zeros of $f$ are isolated. I've written a proof of the original statement using that fact. I would like to know if my proof is correct and also to encourage to give an answer to anyone who has an alternative solution (or my corrected solution, should some step of mine be wrong). Proof of statement The proof is by contradiction. I'll denote $S=\{z \in K : f(z)=0\}$. Define $\{F_j\}_{\{j \in \mathcal J\}}$ to be $\{F_j\}_{\{j \in \mathcal J\}}=\bigcup_{\{i \in \mathcal I\}} B(z_i,\delta_i) \cup \ C$, where $C$ is an open cover for $S^c$, and  $B(z_i,\delta_{i})$ is an open ball centered at $z_i$ with a radius chosen such that $z \not \in B(z_i,\delta_{i})$ for $z \in S$ different from $z_i$, for each $z_i \in S$ . It is clear that $\{F_j\}_{\{j \in \mathcal J\}}$ is an open cover for $K$. Now, since $K$ is compact, there exists a finite subcover $\{F_{j'}\}_{\{j' \in \mathcal J' \subset J\}}$, with $J'$ finite. By the way the original cover was defined, the subcover must be of the form  $\{F_{j'}\}_{\{j' \in \mathcal J' \subset J\}}=\bigcup_{\{i' \in \mathcal I'\}} B(z_{i'},\delta_{i'}) \cup \ C'$, where $I'$ is a finite subset of $I$ and $C'$ is a finite subcover extracted from $C$. Now choose $z \in S$ with $z \neq z_{i'}$ for all $i' \in I'$ (we can do this since the set of zeros is supposed to be infinite). By the way the open balls were chosen, $z \not \in \bigcup_{\{i' \in \mathcal I'\}} B(z_{i'},\delta_{i'})$, but $z \in K=\bigcup_{\{i' \in \mathcal I'\}} B(z_{i'},\delta_{i'}) \cup \ C'$, so $z$ must be in $C'$, but this is clearly absurd since $C'$ is a cover of $S^c$. The absurd comes from the assumption that $S$ is infinite, then $S$ must be finite.","Statement Let $f:\mathbb \Omega \to \mathbb C$ be a holomorphic function, $f \neq 0$ ($\Omega$ is a region, i.e., an open, nonempty, connected set). Prove that in every compact subset $K$ of $\Omega$, the set of zeros of $f$ is finite. I've read in Stein's textbook a proof of the statement ""Suppose $f$ is a holomorphic function in a region $\Omega$ that vanishes on a sequence of distinct points with a limit point in $\Omega$. Then $f$ is identically zero."" From that statement, one can easily deduce that the zeros of $f$ are isolated. I've written a proof of the original statement using that fact. I would like to know if my proof is correct and also to encourage to give an answer to anyone who has an alternative solution (or my corrected solution, should some step of mine be wrong). Proof of statement The proof is by contradiction. I'll denote $S=\{z \in K : f(z)=0\}$. Define $\{F_j\}_{\{j \in \mathcal J\}}$ to be $\{F_j\}_{\{j \in \mathcal J\}}=\bigcup_{\{i \in \mathcal I\}} B(z_i,\delta_i) \cup \ C$, where $C$ is an open cover for $S^c$, and  $B(z_i,\delta_{i})$ is an open ball centered at $z_i$ with a radius chosen such that $z \not \in B(z_i,\delta_{i})$ for $z \in S$ different from $z_i$, for each $z_i \in S$ . It is clear that $\{F_j\}_{\{j \in \mathcal J\}}$ is an open cover for $K$. Now, since $K$ is compact, there exists a finite subcover $\{F_{j'}\}_{\{j' \in \mathcal J' \subset J\}}$, with $J'$ finite. By the way the original cover was defined, the subcover must be of the form  $\{F_{j'}\}_{\{j' \in \mathcal J' \subset J\}}=\bigcup_{\{i' \in \mathcal I'\}} B(z_{i'},\delta_{i'}) \cup \ C'$, where $I'$ is a finite subset of $I$ and $C'$ is a finite subcover extracted from $C$. Now choose $z \in S$ with $z \neq z_{i'}$ for all $i' \in I'$ (we can do this since the set of zeros is supposed to be infinite). By the way the open balls were chosen, $z \not \in \bigcup_{\{i' \in \mathcal I'\}} B(z_{i'},\delta_{i'})$, but $z \in K=\bigcup_{\{i' \in \mathcal I'\}} B(z_{i'},\delta_{i'}) \cup \ C'$, so $z$ must be in $C'$, but this is clearly absurd since $C'$ is a cover of $S^c$. The absurd comes from the assumption that $S$ is infinite, then $S$ must be finite.",,"['complex-analysis', 'compactness']"
65,existence of sequence of polynomial,existence of sequence of polynomial,,"Is there a sequence of polynomials $P_n$ such that $\displaystyle\lim_{n \to \infty} P_n(z) = \begin{cases} 1, & \text{Im } z > 0\\ 0, & z \text{ is real,} \\ -1, & \text{Im } z < 0 \end{cases}$ I have no clue where to start from. Please provide some hints. Thanks in advance.","Is there a sequence of polynomials $P_n$ such that $\displaystyle\lim_{n \to \infty} P_n(z) = \begin{cases} 1, & \text{Im } z > 0\\ 0, & z \text{ is real,} \\ -1, & \text{Im } z < 0 \end{cases}$ I have no clue where to start from. Please provide some hints. Thanks in advance.",,['complex-analysis']
66,Prove that a complex valued polynomial over two variables has infinitely many zeroes,Prove that a complex valued polynomial over two variables has infinitely many zeroes,,"This is a homework question that I am struggling with. Given a polynomial over the complex numbers in two variables, show that the polynomial has infinitely many zeroes. So let's say that the polynomial is a functions of $u$ and $v$. Let's consider the polynomial as a function of $u$, with $v$ as a parameter: $P_v(u)$. Then for each $v$ there is going to be a finite set of values. So now I should be able to proceed by contradiction by finding a suitable value or constraint on $v$, but I'm not sure how to proceed.","This is a homework question that I am struggling with. Given a polynomial over the complex numbers in two variables, show that the polynomial has infinitely many zeroes. So let's say that the polynomial is a functions of $u$ and $v$. Let's consider the polynomial as a function of $u$, with $v$ as a parameter: $P_v(u)$. Then for each $v$ there is going to be a finite set of values. So now I should be able to proceed by contradiction by finding a suitable value or constraint on $v$, but I'm not sure how to proceed.",,"['complex-analysis', 'algebraic-geometry']"
67,Roots of $e^z=1+z$ on complex plane,Roots of  on complex plane,e^z=1+z,"What are the roots in the complex plane of $e^z=1+z$? Clearly $z=0$ is one root. On the real line, we can show that $e^x>1+x$ for all $x\neq 0$. But what about the rest of the complex plane?","What are the roots in the complex plane of $e^z=1+z$? Clearly $z=0$ is one root. On the real line, we can show that $e^x>1+x$ for all $x\neq 0$. But what about the rest of the complex plane?",,"['complex-analysis', 'complex-numbers', 'roots']"
68,Stability of Analytic Continuation,Stability of Analytic Continuation,,"Let $f(z)$ be an analytic function in an open set $U\subset\Bbb{C}$.  Recall that an analytic continuation of $f$ is a pair $(F,V)$ such that $U\subset V\subset\Bbb{C}$, $F$ is analytic on $V$, and $F(z)=f(z)$ for all $z\in U$. My question is, how stable is this process?  If $\|f-g\|$ is small, are we guaranteed $\|F-G\|$ small in any reasonable sense?  If not, are there easy counterexamples?  If the answer depends on the choice of norm, I would find that interesting as well. References gladly accepted in lieu of obvious arguments.  Thanks!","Let $f(z)$ be an analytic function in an open set $U\subset\Bbb{C}$.  Recall that an analytic continuation of $f$ is a pair $(F,V)$ such that $U\subset V\subset\Bbb{C}$, $F$ is analytic on $V$, and $F(z)=f(z)$ for all $z\in U$. My question is, how stable is this process?  If $\|f-g\|$ is small, are we guaranteed $\|F-G\|$ small in any reasonable sense?  If not, are there easy counterexamples?  If the answer depends on the choice of norm, I would find that interesting as well. References gladly accepted in lieu of obvious arguments.  Thanks!",,"['complex-analysis', 'reference-request']"
69,Contour integration for functions with residues that form an infinite oscillating sequence,Contour integration for functions with residues that form an infinite oscillating sequence,,"I would like to evaluate some complicated integrals involving the hyperbolic secant, but the extension of the usual contour integration evaluation using the residue theorem isn't clear to me. I've been considering a simple example with a known solution $$\int_{-\infty}^{\infty} \text{Sech}\Big(\frac{\pi s}{2}\Big) \ d s \ = \ 2$$ This question is related as it discusses functions with an infinite number of poles, but there it is assumed that the sum of the residues converges. As is explained in that question, we are only ever actually considering bounded contours and then taking the limit that they grow arbitrarily large but I am not sure how that justifies my approach in this problem. Suppose I am quite cavalier and I attempt to evaluate this integral by closing the contour along a semi-circle in the upper-half complex plane. Without really checking, I claim that the integral along the circular part of the contour vanishes and thus the integral over the real line is given by $$\sum_{n=0}^{\infty} 2 \pi i \ \text{Res}\Big( \text{Sech}\Big(i\pi\big (n+\frac{1}{2}\big)\Big) = 4-4+4-4 \ . . .$$ which clearly does not converge. However, if we consider the average of the first $m$ partial sums $$\frac{1}{m}(4+0+4+0+ \ . . . ) = \left \{ \begin{array}{lr} 2 & \  m \in  \text{evens}\\ 2 + \frac{4}{m}& m \in \text{odds} \end{array} \right.$$ which goes to $2$ as $m \to \infty$. This procedure seems totally ad hoc, even magical, but it predicts the correct answer. The first question is, why does the limit of the average of the partial sums give the correct answer? Another way of regularizing this problem is to instead compute $$\lim_{\eta \to 0}\int_{-\infty}^{\infty} \text{Sech}\Big(\frac{\pi s}{2}\Big) e^{i  \eta \ s} \ d s $$ and then using the same procedure $$\lim_{\eta \to 0}\sum_{n=0}^{\infty} 2 \pi i \ \text{Res}\Big( \text{Sech}\Big(i\pi\big (n+\frac{1}{2}\big) e^{-\eta (2n-1)}\Big) =\lim_{\eta \to 0} \frac{4e^{\eta}}{1+e^{2\eta}} = 2$$ also gives the correct answer. So, there seems to be something to this method. If I am more careful about the circular piece of the contour, I can show that its contribution is exponentially small almost everywhere. $\text{Sech}(x + iy)$ clearly decreases exponentially when $x$ is large, but what about when $y$ is large and $x$ is small? By rewriting $x + iy = re^{i \theta}$ and taking the absolute value, I can show that when $\theta = \frac{\pi}{2} +\epsilon, \ \left|\epsilon\right|<1$ (ie we are close to the imaginary axis), then $$\left| \text{Sech}(re^{i\theta})\right|\sim e^{-\frac{1}{2}\pi r \left|\epsilon\right| } : \ \ r\to \infty$$ My understanding of the Riemann integral suggests that the single point where $\epsilon = 0$ does not change the value of the integral along the contour. So, it seems like I do have good reason to argue that the contribution from the circular contour vanishes. Is there a way, then, to justify my regularized sum of the residues as the correct answer in general or is it just an accident for this special case?","I would like to evaluate some complicated integrals involving the hyperbolic secant, but the extension of the usual contour integration evaluation using the residue theorem isn't clear to me. I've been considering a simple example with a known solution $$\int_{-\infty}^{\infty} \text{Sech}\Big(\frac{\pi s}{2}\Big) \ d s \ = \ 2$$ This question is related as it discusses functions with an infinite number of poles, but there it is assumed that the sum of the residues converges. As is explained in that question, we are only ever actually considering bounded contours and then taking the limit that they grow arbitrarily large but I am not sure how that justifies my approach in this problem. Suppose I am quite cavalier and I attempt to evaluate this integral by closing the contour along a semi-circle in the upper-half complex plane. Without really checking, I claim that the integral along the circular part of the contour vanishes and thus the integral over the real line is given by $$\sum_{n=0}^{\infty} 2 \pi i \ \text{Res}\Big( \text{Sech}\Big(i\pi\big (n+\frac{1}{2}\big)\Big) = 4-4+4-4 \ . . .$$ which clearly does not converge. However, if we consider the average of the first $m$ partial sums $$\frac{1}{m}(4+0+4+0+ \ . . . ) = \left \{ \begin{array}{lr} 2 & \  m \in  \text{evens}\\ 2 + \frac{4}{m}& m \in \text{odds} \end{array} \right.$$ which goes to $2$ as $m \to \infty$. This procedure seems totally ad hoc, even magical, but it predicts the correct answer. The first question is, why does the limit of the average of the partial sums give the correct answer? Another way of regularizing this problem is to instead compute $$\lim_{\eta \to 0}\int_{-\infty}^{\infty} \text{Sech}\Big(\frac{\pi s}{2}\Big) e^{i  \eta \ s} \ d s $$ and then using the same procedure $$\lim_{\eta \to 0}\sum_{n=0}^{\infty} 2 \pi i \ \text{Res}\Big( \text{Sech}\Big(i\pi\big (n+\frac{1}{2}\big) e^{-\eta (2n-1)}\Big) =\lim_{\eta \to 0} \frac{4e^{\eta}}{1+e^{2\eta}} = 2$$ also gives the correct answer. So, there seems to be something to this method. If I am more careful about the circular piece of the contour, I can show that its contribution is exponentially small almost everywhere. $\text{Sech}(x + iy)$ clearly decreases exponentially when $x$ is large, but what about when $y$ is large and $x$ is small? By rewriting $x + iy = re^{i \theta}$ and taking the absolute value, I can show that when $\theta = \frac{\pi}{2} +\epsilon, \ \left|\epsilon\right|<1$ (ie we are close to the imaginary axis), then $$\left| \text{Sech}(re^{i\theta})\right|\sim e^{-\frac{1}{2}\pi r \left|\epsilon\right| } : \ \ r\to \infty$$ My understanding of the Riemann integral suggests that the single point where $\epsilon = 0$ does not change the value of the integral along the contour. So, it seems like I do have good reason to argue that the contribution from the circular contour vanishes. Is there a way, then, to justify my regularized sum of the residues as the correct answer in general or is it just an accident for this special case?",,"['complex-analysis', 'contour-integration', 'regularization']"
70,Does $Re\left( \int_{\gamma} f \right) = \int_{\gamma} Re(f)$?,Does ?,Re\left( \int_{\gamma} f \right) = \int_{\gamma} Re(f),"I'm currently studying complex analysis. My current thinking is as follows: Let $f(t)=x(t)+iy(t)$. By definition, $$\int_{\gamma} f(t) \, \mathrm{d}t = \int_{a}^{b} f(\gamma(t)) \gamma'(t) \, \mathrm{d}t$$ and so by substitution, $$\int_{\gamma} f(t) \, \mathrm{d}t = \int_{a}^{b}x(\gamma(t))\gamma'(t) \, \mathrm{d}t + i \int_{a}^{b} y(\gamma(t))\gamma'(t) \, \mathrm{d}t.$$ Thus, $$Re\left( \int_{\gamma} f \right) =\int_{a}^{b}x(\gamma(t))\gamma'(t) \, \mathrm{d}t.$$ Now, $$\int_{\gamma} Re(f(t))\, \mathrm{d}t = \int_{\gamma}x(t) \, \mathrm{d}t = \int_{a}^{b} x(\gamma(t))\gamma'(t) \, \mathrm{d}t.$$ We see that these expressions are indeed the same, and so $Re\left( \int_{\gamma} f \right) = \int_{\gamma} Re(f)$. This seems so straightforward, and I've been trying for ages to come up with a counter example, but I haven't been able to find one. What are your thoughts?","I'm currently studying complex analysis. My current thinking is as follows: Let $f(t)=x(t)+iy(t)$. By definition, $$\int_{\gamma} f(t) \, \mathrm{d}t = \int_{a}^{b} f(\gamma(t)) \gamma'(t) \, \mathrm{d}t$$ and so by substitution, $$\int_{\gamma} f(t) \, \mathrm{d}t = \int_{a}^{b}x(\gamma(t))\gamma'(t) \, \mathrm{d}t + i \int_{a}^{b} y(\gamma(t))\gamma'(t) \, \mathrm{d}t.$$ Thus, $$Re\left( \int_{\gamma} f \right) =\int_{a}^{b}x(\gamma(t))\gamma'(t) \, \mathrm{d}t.$$ Now, $$\int_{\gamma} Re(f(t))\, \mathrm{d}t = \int_{\gamma}x(t) \, \mathrm{d}t = \int_{a}^{b} x(\gamma(t))\gamma'(t) \, \mathrm{d}t.$$ We see that these expressions are indeed the same, and so $Re\left( \int_{\gamma} f \right) = \int_{\gamma} Re(f)$. This seems so straightforward, and I've been trying for ages to come up with a counter example, but I haven't been able to find one. What are your thoughts?",,['complex-analysis']
71,Complex analysis and analytic functions,Complex analysis and analytic functions,,"I'm having a really tough time understanding complex analysis. The assignment is to find a function $f$, given $z = x + iy$, so that f is analytic on the complex plane, so that $\mathrm{Re}(f) = x^3 y - x y^3$. I tried beginning with the Cauchy-Riemann method and found the partial derivatives for the function $u(x, y)$ but I have no idea how to get to the original function $f$. Any help here?","I'm having a really tough time understanding complex analysis. The assignment is to find a function $f$, given $z = x + iy$, so that f is analytic on the complex plane, so that $\mathrm{Re}(f) = x^3 y - x y^3$. I tried beginning with the Cauchy-Riemann method and found the partial derivatives for the function $u(x, y)$ but I have no idea how to get to the original function $f$. Any help here?",,['complex-analysis']
72,A positive harmonic function on the punctured plane is constant,A positive harmonic function on the punctured plane is constant,,Let $f(z)$ be a positive harmonic function on $\mathbb{C}\backslash  \{0\}$. Prove that $f(z)$ is constant. I have no idea to prove this statement.,Let $f(z)$ be a positive harmonic function on $\mathbb{C}\backslash  \{0\}$. Prove that $f(z)$ is constant. I have no idea to prove this statement.,,"['complex-analysis', 'harmonic-functions']"
73,Is it true that a complex function has a global antiderivative if and only if it integrates to zero over every closed curve?,Is it true that a complex function has a global antiderivative if and only if it integrates to zero over every closed curve?,,"I am somehow thinking that these properties must be equivalent, unfortunately I do not know a theorem that says it: $f$ has a global antiderivative iff the line integral $ \int_{\gamma}f$ over every closed curve in the domain of f is zero? Is this correct?","I am somehow thinking that these properties must be equivalent, unfortunately I do not know a theorem that says it: $f$ has a global antiderivative iff the line integral $ \int_{\gamma}f$ over every closed curve in the domain of f is zero? Is this correct?",,['calculus']
74,Path independence of an integral?,Path independence of an integral?,,"I'm studying for a test (that's why I've been asking so much today,) and one of the questions is about saying if an integral is path independent and then solving for it.  I was reading online about path independence and it's all about vector fields, and I'm very, very lost. This is the integral $$\int_{0}^{i} \frac{dz}{1-z^2}$$ So should I find another equation that gives the same result with those boundaries? I honestly just don't know how to approach the problem, any links or topics to read on would be appreciated as well. Thank you!","I'm studying for a test (that's why I've been asking so much today,) and one of the questions is about saying if an integral is path independent and then solving for it.  I was reading online about path independence and it's all about vector fields, and I'm very, very lost. This is the integral $$\int_{0}^{i} \frac{dz}{1-z^2}$$ So should I find another equation that gives the same result with those boundaries? I honestly just don't know how to approach the problem, any links or topics to read on would be appreciated as well. Thank you!",,"['complex-analysis', 'definite-integrals']"
75,How can I show that circles in the complex plane correspond to circles on the Riemann sphere? How about lines?,How can I show that circles in the complex plane correspond to circles on the Riemann sphere? How about lines?,,"Suppose $ T \subset \mathbb{C} $. Show that the corresponding set $ S \subset \Sigma $ is a. a circle if $ T $ is a circle. b. a circle minus (0, 0, 1) if $ T $ is a line. Here we are defining $ \Sigma $ to be the Riemann sphere, given by the set: $$ \Sigma = \left \{(\xi, \eta, \zeta) : \xi^{2} + \eta^{2} + (\zeta - \frac{1}{2})^{2} = \frac{1}{4} \right \} $$ To take a point from $ \mathbb{C} $ to $ \Sigma $ we can use the following: $$ \xi = \frac{x}{x^{2} + y^{2} + 1}; \eta = \frac{y}{x^{2} + y^{2} + 1}; \zeta = \frac{x^{2} + y^{2}}{x^{2} + y^{2} + 1} $$ We define a circle on $ \Sigma $ to be the intersection of a plane of the form $ A\xi + B\eta + C\zeta = D $ with $ \Sigma $. We also know the converse of this problem is true, that the intersection above yeilds a set in $ \mathbb{C} $ with the following property: $ (C - D)(x^{2} + y^{2}) + Ax + By = D $. As you can see, when C = D, then an equation for a line is yeilded, otherwise it is a circle. I really am at a  loss about how to solve this problem. The only thing I can think to do is to pick 3 points on a circle or radius $ r $ with center $ z_{0} $, use these points to find two vectors in $ \Sigma $, take their cross product to get a normal vector, use this normal vector to get a plane. Once I have the plane in form $ A\xi + B\eta + C\zeta = D $ then I could prove that the circle I had chosen corresponds exactly with $ (C - D)(x^{2} + y^{2}) + Ax + By = D $. Is there not an easier, less computation way to do this?","Suppose $ T \subset \mathbb{C} $. Show that the corresponding set $ S \subset \Sigma $ is a. a circle if $ T $ is a circle. b. a circle minus (0, 0, 1) if $ T $ is a line. Here we are defining $ \Sigma $ to be the Riemann sphere, given by the set: $$ \Sigma = \left \{(\xi, \eta, \zeta) : \xi^{2} + \eta^{2} + (\zeta - \frac{1}{2})^{2} = \frac{1}{4} \right \} $$ To take a point from $ \mathbb{C} $ to $ \Sigma $ we can use the following: $$ \xi = \frac{x}{x^{2} + y^{2} + 1}; \eta = \frac{y}{x^{2} + y^{2} + 1}; \zeta = \frac{x^{2} + y^{2}}{x^{2} + y^{2} + 1} $$ We define a circle on $ \Sigma $ to be the intersection of a plane of the form $ A\xi + B\eta + C\zeta = D $ with $ \Sigma $. We also know the converse of this problem is true, that the intersection above yeilds a set in $ \mathbb{C} $ with the following property: $ (C - D)(x^{2} + y^{2}) + Ax + By = D $. As you can see, when C = D, then an equation for a line is yeilded, otherwise it is a circle. I really am at a  loss about how to solve this problem. The only thing I can think to do is to pick 3 points on a circle or radius $ r $ with center $ z_{0} $, use these points to find two vectors in $ \Sigma $, take their cross product to get a normal vector, use this normal vector to get a plane. Once I have the plane in form $ A\xi + B\eta + C\zeta = D $ then I could prove that the circle I had chosen corresponds exactly with $ (C - D)(x^{2} + y^{2}) + Ax + By = D $. Is there not an easier, less computation way to do this?",,"['complex-analysis', 'complex-numbers']"
76,"$f$ continuous on a circle, then there is a diameter at which ends $f$ has the same value","continuous on a circle, then there is a diameter at which ends  has the same value",f f,Let $f$ be a continuous function on a circle. Show that there is a diameter for which the value of $f$ are equal at the diameter ends. I don't know how to approah this problem. Is a diameter any chord of the circle? I tried to consider $f(\theta) = e^{i\theta}$ which satisfies the condition for the chord $y=f(\pi/4)$. I don't see how to extend this to a general continuous function.,Let $f$ be a continuous function on a circle. Show that there is a diameter for which the value of $f$ are equal at the diameter ends. I don't know how to approah this problem. Is a diameter any chord of the circle? I tried to consider $f(\theta) = e^{i\theta}$ which satisfies the condition for the chord $y=f(\pi/4)$. I don't see how to extend this to a general continuous function.,,['real-analysis']
77,Laurent series expansion of $f(z)=\frac{1}{(z-1)^2(z+1)^2}$,Laurent series expansion of,f(z)=\frac{1}{(z-1)^2(z+1)^2},"Let $f(z)=\frac{1}{(z-1)^2(z+1)^2}$ .  While trying to expand this function into the Laurent series, convergent in $P(0,1,2):=\lbrace z\in\mathbb{C}:1<|z|<2\rbrace$ , a few questions popped into my mind. We can write $f(z)=\frac{1}{4}\left(\frac{1}{(z-1)^2}+\frac{1}{(z+1)^2}\right)$ . Both functions inside parentheses are complex derivatives of functions which have immediate Laurent series expansion: $\frac{1}{1-z}$ and $-\frac{1}{z+1}$ . Now, can we differentiate the obtained series term by term to get the desired expansion of $f$ ? If so, is it because the Laurent series is convergent almost uniformly? Could someone verify that the Laurent series of $f$ is convergent in $P(0,1,\infty)$ ?","Let .  While trying to expand this function into the Laurent series, convergent in , a few questions popped into my mind. We can write . Both functions inside parentheses are complex derivatives of functions which have immediate Laurent series expansion: and . Now, can we differentiate the obtained series term by term to get the desired expansion of ? If so, is it because the Laurent series is convergent almost uniformly? Could someone verify that the Laurent series of is convergent in ?","f(z)=\frac{1}{(z-1)^2(z+1)^2} P(0,1,2):=\lbrace z\in\mathbb{C}:1<|z|<2\rbrace f(z)=\frac{1}{4}\left(\frac{1}{(z-1)^2}+\frac{1}{(z+1)^2}\right) \frac{1}{1-z} -\frac{1}{z+1} f f P(0,1,\infty)","['complex-analysis', 'laurent-series']"
78,Find $I:=\lim\limits_{R\to \infty}\int\limits_{-R}^R \frac{x \sin(3x)}{x ^2+4}dx$ using residues,Find  using residues,I:=\lim\limits_{R\to \infty}\int\limits_{-R}^R \frac{x \sin(3x)}{x ^2+4}dx,Find $I:=\lim\limits_{R\to \infty}\int\limits_{-R}^R \frac{x \sin(3x)}{x ^2+4}dx$ using residues. Let $f(z)= \frac{z \sin(3z)}{z ^2+4}$. First define two contours: $$\Gamma_1: z=t \text{ where } -R\leq t \leq R$$ $$\Gamma_2: z=Re^{i\theta} \text{ where } 0\leq \theta \leq \pi$$ And $\Gamma_3=\Gamma_1+\Gamma_2$. Basically $\Gamma_3$ is the closed half circle in the upper half of the complex plane and $\Gamma_1$ runs along the real axis from $-R$ to $R$. Now we have: $$I=\lim\limits_{R\to \infty}\int\limits_{\Gamma_1}f(z)dz=\lim\limits_{R\to \infty}\oint_{\Gamma_3}f(z)dz-\lim\limits_{R\to \infty}\int_{\Gamma_2}f(z)dz$$ We can compute $\lim\limits_{R\to \infty}\oint_{\Gamma_3}f(z)dz=\lim\limits_{R\to \infty}\oint_{\Gamma_3}\frac{z\sin(3z)}{(z+2i)(z-2i)}dz$ fairly easily after recognizing that it has simple poles at $z_0=\pm 2i$ and only $z_0=2i$ is enclosed in $\Gamma_3$. By the residue theorem: $$\lim\limits_{R\to \infty}\oint_{\Gamma_3}f(z)dz=2\pi i \left(\mathop{Res} _{z=2i}(f)\right)=2\pi i \lim\limits_{z\to 2i}(z-2i)f(z)=2\pi i \frac{2  i\sin(6 i)}{2 i +2i}=\pi i \sin(6i)$$ Now the only obstacle to finding the value of our original integral is finding $\lim\limits_{R\to \infty}\int_{\Gamma_2}f(z)dz$. If $f(z)$ were such that the degree of the polynomial in the denominator was at least 2 higher then the polynomial in the numerator (ignoring the $\sin$) we could easily show that the integral vanishes. I still think this last integral should vanish but find it hard to show why. Any help would be appreciated. Also any suggestions on different methods of solving for $I$ are welcome. Thanks!,Find $I:=\lim\limits_{R\to \infty}\int\limits_{-R}^R \frac{x \sin(3x)}{x ^2+4}dx$ using residues. Let $f(z)= \frac{z \sin(3z)}{z ^2+4}$. First define two contours: $$\Gamma_1: z=t \text{ where } -R\leq t \leq R$$ $$\Gamma_2: z=Re^{i\theta} \text{ where } 0\leq \theta \leq \pi$$ And $\Gamma_3=\Gamma_1+\Gamma_2$. Basically $\Gamma_3$ is the closed half circle in the upper half of the complex plane and $\Gamma_1$ runs along the real axis from $-R$ to $R$. Now we have: $$I=\lim\limits_{R\to \infty}\int\limits_{\Gamma_1}f(z)dz=\lim\limits_{R\to \infty}\oint_{\Gamma_3}f(z)dz-\lim\limits_{R\to \infty}\int_{\Gamma_2}f(z)dz$$ We can compute $\lim\limits_{R\to \infty}\oint_{\Gamma_3}f(z)dz=\lim\limits_{R\to \infty}\oint_{\Gamma_3}\frac{z\sin(3z)}{(z+2i)(z-2i)}dz$ fairly easily after recognizing that it has simple poles at $z_0=\pm 2i$ and only $z_0=2i$ is enclosed in $\Gamma_3$. By the residue theorem: $$\lim\limits_{R\to \infty}\oint_{\Gamma_3}f(z)dz=2\pi i \left(\mathop{Res} _{z=2i}(f)\right)=2\pi i \lim\limits_{z\to 2i}(z-2i)f(z)=2\pi i \frac{2  i\sin(6 i)}{2 i +2i}=\pi i \sin(6i)$$ Now the only obstacle to finding the value of our original integral is finding $\lim\limits_{R\to \infty}\int_{\Gamma_2}f(z)dz$. If $f(z)$ were such that the degree of the polynomial in the denominator was at least 2 higher then the polynomial in the numerator (ignoring the $\sin$) we could easily show that the integral vanishes. I still think this last integral should vanish but find it hard to show why. Any help would be appreciated. Also any suggestions on different methods of solving for $I$ are welcome. Thanks!,,"['complex-analysis', 'contour-integration']"
79,An entire function with two periods,An entire function with two periods,,"Can anybody help me with this question: If $f(z)$ is an entire periodic function and it has to periods $2$ and $2i$, how can I find all other periods?","Can anybody help me with this question: If $f(z)$ is an entire periodic function and it has to periods $2$ and $2i$, how can I find all other periods?",,['complex-analysis']
80,Formula for integration bounds of recursively defined polynomial sequence,Formula for integration bounds of recursively defined polynomial sequence,,We can recursively define a sequence of polynomials by $$P_0(x) := 1$$ and then with the definite integral $$P_n(x) := \int_{c_n}^x P_{n-1}(t) ~\mathrm dt$$ where the $c_n$ are to be chosen so that $$\int_0^1 P_n(t)~\mathrm dt = 0$$ so for $n = 1$ we have $P_1(x) = x - c_1$ so $c_1 = 1/2$. However already for $n=2$ it becomes difficult since $\int_{c_2}^x (t-1/2)~\mathrm dt =  t^2/2 - t/2- c_2^2/2 + c_2/2$ and to have $\int_0^1 P_2(t)~\mathrm dt = 0$ there are two solutions for $c_2$ namely $$c_2 = 1/2 \pm \sqrt 3/6.$$ So $P_2(x) = x^2/2 - x/2 + 1/12$. For $n=3$ we get $c_3 = 0$ and $P_3(x) = x^3/6 - x^2/4 + x/12$ however for $n=4$ we have $c_4=1/2 - 1/2\sqrt (1 - 2/15\sqrt 30)$ (and 3 other solutions) for $P_4(x)=x^4/24 - x^3/12 + x^2/24 - 1/720$. For $n=5$ again $c_5=0$ (however there are another 4 solutions). Is there some general Formula for the $c_n$ so we could have a shortcut for calculating the coefficients of $P_n(x)$? Also with an eye to fractional calculus it would be nice to know if for the Riemann-Liouville integral $$\frac1{\Gamma(\alpha)} \int_c^x P(t) (x-t)^{\alpha-1}~\mathrm dt$$ and $$\int_0^1 P(t)~\mathrm dt = 0$$ if there even is a solution for this - let alone if it would fit in the previously defined sequence. The dream result would of course be not only to have a formula for $c_n$ but a function $c(n)$ that continuously defines such a polynomial sequence. But that seems very remote since even in simple cases with for example $\alpha = 1/2$ and $c>0$ the integral produces complex values...,We can recursively define a sequence of polynomials by $$P_0(x) := 1$$ and then with the definite integral $$P_n(x) := \int_{c_n}^x P_{n-1}(t) ~\mathrm dt$$ where the $c_n$ are to be chosen so that $$\int_0^1 P_n(t)~\mathrm dt = 0$$ so for $n = 1$ we have $P_1(x) = x - c_1$ so $c_1 = 1/2$. However already for $n=2$ it becomes difficult since $\int_{c_2}^x (t-1/2)~\mathrm dt =  t^2/2 - t/2- c_2^2/2 + c_2/2$ and to have $\int_0^1 P_2(t)~\mathrm dt = 0$ there are two solutions for $c_2$ namely $$c_2 = 1/2 \pm \sqrt 3/6.$$ So $P_2(x) = x^2/2 - x/2 + 1/12$. For $n=3$ we get $c_3 = 0$ and $P_3(x) = x^3/6 - x^2/4 + x/12$ however for $n=4$ we have $c_4=1/2 - 1/2\sqrt (1 - 2/15\sqrt 30)$ (and 3 other solutions) for $P_4(x)=x^4/24 - x^3/12 + x^2/24 - 1/720$. For $n=5$ again $c_5=0$ (however there are another 4 solutions). Is there some general Formula for the $c_n$ so we could have a shortcut for calculating the coefficients of $P_n(x)$? Also with an eye to fractional calculus it would be nice to know if for the Riemann-Liouville integral $$\frac1{\Gamma(\alpha)} \int_c^x P(t) (x-t)^{\alpha-1}~\mathrm dt$$ and $$\int_0^1 P(t)~\mathrm dt = 0$$ if there even is a solution for this - let alone if it would fit in the previously defined sequence. The dream result would of course be not only to have a formula for $c_n$ but a function $c(n)$ that continuously defines such a polynomial sequence. But that seems very remote since even in simple cases with for example $\alpha = 1/2$ and $c>0$ the integral produces complex values...,,"['calculus', 'real-analysis']"
81,Mapping of Analytic Functions,Mapping of Analytic Functions,,"I have another question that is really catching me off guard, but it looks very promising and wholesome as it combines complex analysis theory and algebra. The question is as below: Let $f$ be entire and have the property that  if $B \subset \mathbb{C}$ is any bounded set,$\hspace{1.7in}$ then $f^{-1}(B)$ is bounded (or perhaps empty). Could it be shown that for any $\omega \in \mathbb{C}$,  there $\hspace{0.7in}$ exists $z \in \mathbb{C}$ such that $f(z)=\omega$. Also, can one show that $f(\mathbb{C})$ is both open and $\hspace{1.1in}$  closed and deduce that $f(\mathbb{C})=\mathbb{C}$. Apply this result to polynomials to deduce $\hspace{1.4in}$ yet another proof of the Fundamental Theorem of Algebra.","I have another question that is really catching me off guard, but it looks very promising and wholesome as it combines complex analysis theory and algebra. The question is as below: Let $f$ be entire and have the property that  if $B \subset \mathbb{C}$ is any bounded set,$\hspace{1.7in}$ then $f^{-1}(B)$ is bounded (or perhaps empty). Could it be shown that for any $\omega \in \mathbb{C}$,  there $\hspace{0.7in}$ exists $z \in \mathbb{C}$ such that $f(z)=\omega$. Also, can one show that $f(\mathbb{C})$ is both open and $\hspace{1.1in}$  closed and deduce that $f(\mathbb{C})=\mathbb{C}$. Apply this result to polynomials to deduce $\hspace{1.4in}$ yet another proof of the Fundamental Theorem of Algebra.",,['complex-analysis']
82,How do you show that an $L^p$ entire (holomorphic on the complex plane) function is $0$?,How do you show that an  entire (holomorphic on the complex plane) function is ?,L^p 0,"Just to clarify, I want to show that: If $f$ is entire and $\int_{\mathbb{C}} |f|^p dxdy <\infty$, then $f=0$. I think I can show that this is the case for $p=2$, but I'm not sure about other values of $p$...","Just to clarify, I want to show that: If $f$ is entire and $\int_{\mathbb{C}} |f|^p dxdy <\infty$, then $f=0$. I think I can show that this is the case for $p=2$, but I'm not sure about other values of $p$...",,[]
83,Is Schwarz's Lemma true for squares?,Is Schwarz's Lemma true for squares?,,"In a recent complex analysis exam, we were asked which step(s) in the proof of the Riemann Mapping Theorem fail, when you replace every instance of the open unit ball $\mathbb{E}$ with the square $$\mathbb{S} = \{z\in\mathbb{C}:|Re(z)|, |Im(z)| < 1 \}$$ One error that arose is that the square root function is not a self map of $\mathbb{S}$ . But what I thought was a problem was that we used Schwarz's Lemma, in particular Given a holomorphic $f:\mathbb{E}\to \mathbb{E}$ that fixes $0$ , we have $|f'(0)|\leq 1$ The proof for this goes by noting that we can find a holomorphic $g$ such that $$f(z)= zg(z)$$ and then for $0<r<1$ since $|g|$ achieves it's maximum on $\overline{B(0,r)}$ at a point $z_r\in\partial B(0,1)$ , we have $$|g(0)|\leq \frac{|f(z_r)|}{|z_r|} \leq \frac{1}{r}$$ where this last inequality follows since the codomain of $f$ is $\mathbb{E}$ , and $z$ in $\partial B(0,r)$ implies $|z| = r$ . In the case of $\mathbb{S}$ however, it may happen that $|z_r| = r$ , but our only obvious bound for the numerator is $$|f_r(z)|< \sqrt{2}$$ So we get only that $$|f'(0)| < \sqrt{2}$$ But of course, just because this proof doesn't work, doesn't mean the result is not true, but it is suspicious. Hence Question: Prove or disprove Schwarz's Lemma for $\mathbb{S}$ If it is true, can the same be said for all simply connected open sets? If it is false, is the disc the only geometry for which this result holds?","In a recent complex analysis exam, we were asked which step(s) in the proof of the Riemann Mapping Theorem fail, when you replace every instance of the open unit ball with the square One error that arose is that the square root function is not a self map of . But what I thought was a problem was that we used Schwarz's Lemma, in particular Given a holomorphic that fixes , we have The proof for this goes by noting that we can find a holomorphic such that and then for since achieves it's maximum on at a point , we have where this last inequality follows since the codomain of is , and in implies . In the case of however, it may happen that , but our only obvious bound for the numerator is So we get only that But of course, just because this proof doesn't work, doesn't mean the result is not true, but it is suspicious. Hence Question: Prove or disprove Schwarz's Lemma for If it is true, can the same be said for all simply connected open sets? If it is false, is the disc the only geometry for which this result holds?","\mathbb{E} \mathbb{S} = \{z\in\mathbb{C}:|Re(z)|, |Im(z)| < 1 \} \mathbb{S} f:\mathbb{E}\to \mathbb{E} 0 |f'(0)|\leq 1 g f(z)= zg(z) 0<r<1 |g| \overline{B(0,r)} z_r\in\partial B(0,1) |g(0)|\leq \frac{|f(z_r)|}{|z_r|} \leq \frac{1}{r} f \mathbb{E} z \partial B(0,r) |z| = r \mathbb{S} |z_r| = r |f_r(z)|< \sqrt{2} |f'(0)| < \sqrt{2} \mathbb{S}","['real-analysis', 'complex-analysis', 'analysis', 'inequality']"
84,prove the existence of a fixed point,prove the existence of a fixed point,,"Prove that every holomorphic function $f$ on the closed disk $\overline{D}(0,1)$ with $|f(z)|<1$ when $z\in  \overline{D}(0,1)$ has at least one fixed point in $D(0,1)$ . My attempt: Since $f$ is holomorphic on $\mathbb{D}$ , $f$ is either constant or attains its maximum on boundary. If $f$ is constant, we finish. If $f$ is not constant, then $f$ attains its maximum on $\partial\mathbb{D}$ . According to Maximum modulus principle, we have $$|f(z)|\leq |f(z_0)|\quad\forall z\in\mathbb{D}\quad (\text{for some }|z_0|=1).$$ I don't know how to continue. I haven't used the hypothesis $|f(z)|<1\quad\forall z\in\overline{D}(0,1)$ . Could someone have any idea how to solve this problem?","Prove that every holomorphic function on the closed disk with when has at least one fixed point in . My attempt: Since is holomorphic on , is either constant or attains its maximum on boundary. If is constant, we finish. If is not constant, then attains its maximum on . According to Maximum modulus principle, we have I don't know how to continue. I haven't used the hypothesis . Could someone have any idea how to solve this problem?","f \overline{D}(0,1) |f(z)|<1 z\in
 \overline{D}(0,1) D(0,1) f \mathbb{D} f f f f \partial\mathbb{D} |f(z)|\leq |f(z_0)|\quad\forall z\in\mathbb{D}\quad (\text{for some }|z_0|=1). |f(z)|<1\quad\forall z\in\overline{D}(0,1)",['complex-analysis']
85,Prove an entire function is constant on complex plane,Prove an entire function is constant on complex plane,,"Let $f(z)$ , $F(z)$ be two analytic functions on $\Bbb C$ satisfies $f(z)=F(\overline{f(z)})$ . Here $\overline{f(z)}$ is the complex conjugate of $f(z)$ . Prove that $f(z)$ is constant on $\Bbb C$ . I tried to use Cauchy-Riemann equations but I didn't work, and I don't know what else I can do. Any help would be appreciated.","Let , be two analytic functions on satisfies . Here is the complex conjugate of . Prove that is constant on . I tried to use Cauchy-Riemann equations but I didn't work, and I don't know what else I can do. Any help would be appreciated.",f(z) F(z) \Bbb C f(z)=F(\overline{f(z)}) \overline{f(z)} f(z) f(z) \Bbb C,"['complex-analysis', 'analytic-functions', 'entire-functions', 'cauchy-riemann-equations']"
86,A clean way to identify $\nabla(|f|^2)$ with $2f\overline{f'}$ for a holomorphic $f$.,A clean way to identify  with  for a holomorphic .,\nabla(|f|^2) 2f\overline{f'} f,"Let $\Omega \subset \Bbb C$ be an open domain and $f\colon \Omega \to \Bbb C$ be a holomorphic function. By identifying the point $z = x+iy$ with $(x,y) \in \Bbb R^2$ , we may write $f(z) = u(x,y) + i v(x,y)$ where $u,v$ are real-valued functions on $\Omega$ (considered as a subset of $\Bbb R^2$ ). We can then define a real-valued function $$ W(x,y) = |f(z)|^2 = u(x,y)^2 + v(x,y)^2. $$ It is not hard to verify that $W$ is differentiable and its gradient is $$ \nabla W = 2\begin{bmatrix} uu_x+vv_x \\ uu_y + vv_y \end{bmatrix} =2\begin{bmatrix} uu_x+vv_x \\ -uv_x + vu_x \end{bmatrix}, $$ where we used the Cauchy-Riemann equation to substitute $u_x = v_y$ and $u_y = -v_x$ . Again, by the Cauchy-Riemann equation, we know that $f'(z) = u_x(z) + iv_x(z)$ and hence $$ f\overline{f'} = (u+iv)(u_x-iv_x) = (uu_x + vv_x) + i(-uv_x + vu_x). $$ One would be tempted to identify the real gradient of the real-valued function $W$ with the complex number $2f\overline{f'}$ and write $$ \nabla W(x,y) = 2 f(z)\overline{f'(z)}. $$ Is there a neat way to derive this ""identity"" $\nabla W = 2 f\overline{f'}$ ? Of course, this looks suspiciously like the identity $(g^2)' = 2gg'$ for a differentiable $g\colon\Bbb R\to\Bbb R$ , but with a complex conjugation sign, so I think it is reasonable to expect that one should be able to derive it using a product rule or chain rule of some kind. I tried writing $W = f\bar f$ , thinking of $f,\bar f$ as $\Bbb R^2$ -valued functions, and then differentiated it. Alas, I am quite bad at complex analysis and couldn't recover the desired identity. One of the problems I encountered is that the $2\times2$ Jacobian matrix $D(\bar f)$ cannot be identified with $\overline {f'}$ . In fact, $D(\bar f)$ doesn't even represent any complex number (since $f$ is holomorphic). By that I meant the identification of $\Bbb C$ as isomorphic to the subalgebra of $M^{2\times 2}(\Bbb R)$ $$ \left\{ \begin{bmatrix} a &-b \\ b &a \end{bmatrix}  : a,b \in \Bbb R \right\} \cong \left\{ z = a+ib : a,b \in \Bbb R  \right\} \cong \Bbb C.  $$","Let be an open domain and be a holomorphic function. By identifying the point with , we may write where are real-valued functions on (considered as a subset of ). We can then define a real-valued function It is not hard to verify that is differentiable and its gradient is where we used the Cauchy-Riemann equation to substitute and . Again, by the Cauchy-Riemann equation, we know that and hence One would be tempted to identify the real gradient of the real-valued function with the complex number and write Is there a neat way to derive this ""identity"" ? Of course, this looks suspiciously like the identity for a differentiable , but with a complex conjugation sign, so I think it is reasonable to expect that one should be able to derive it using a product rule or chain rule of some kind. I tried writing , thinking of as -valued functions, and then differentiated it. Alas, I am quite bad at complex analysis and couldn't recover the desired identity. One of the problems I encountered is that the Jacobian matrix cannot be identified with . In fact, doesn't even represent any complex number (since is holomorphic). By that I meant the identification of as isomorphic to the subalgebra of","\Omega \subset \Bbb C f\colon \Omega \to \Bbb C z = x+iy (x,y) \in \Bbb R^2 f(z) = u(x,y) + i v(x,y) u,v \Omega \Bbb R^2 
W(x,y) = |f(z)|^2 = u(x,y)^2 + v(x,y)^2.
 W 
\nabla W = 2\begin{bmatrix}
uu_x+vv_x \\
uu_y + vv_y
\end{bmatrix}
=2\begin{bmatrix}
uu_x+vv_x \\
-uv_x + vu_x
\end{bmatrix},
 u_x = v_y u_y = -v_x f'(z) = u_x(z) + iv_x(z) 
f\overline{f'} = (u+iv)(u_x-iv_x) = (uu_x + vv_x) + i(-uv_x + vu_x).
 W 2f\overline{f'} 
\nabla W(x,y) = 2 f(z)\overline{f'(z)}.
 \nabla W = 2 f\overline{f'} (g^2)' = 2gg' g\colon\Bbb R\to\Bbb R W = f\bar f f,\bar f \Bbb R^2 2\times2 D(\bar f) \overline {f'} D(\bar f) f \Bbb C M^{2\times 2}(\Bbb R) 
\left\{ \begin{bmatrix}
a &-b \\
b &a
\end{bmatrix}  : a,b \in \Bbb R \right\} \cong \left\{ z = a+ib : a,b \in \Bbb R  \right\} \cong \Bbb C. 
","['real-analysis', 'complex-analysis', 'multivariable-calculus', 'partial-differential-equations']"
87,Book recommendation on complex analysis with historical motivation,Book recommendation on complex analysis with historical motivation,,"I am looking for a ""thick"" book on complex analysis, which also has historical details such as the motivation behind it. Which problem lead to the creation/discovery of a certain topic. E.g. what is the reason behind fundamental groups how is it in connection with topology. Thanks in advance.","I am looking for a ""thick"" book on complex analysis, which also has historical details such as the motivation behind it. Which problem lead to the creation/discovery of a certain topic. E.g. what is the reason behind fundamental groups how is it in connection with topology. Thanks in advance.",,"['complex-analysis', 'book-recommendation']"
88,Dirac delta distribution in the complex plane,Dirac delta distribution in the complex plane,,"In the complex plane, one can write $$\delta(x) \delta(y) = \dfrac{1}{\pi} \partial_z \dfrac{1}{\bar{z}}.$$ How to prove this relation has been answered before and identifies $$ 2\pi \delta(x) \delta(y) = \partial_x \left(\dfrac{x}{x^2 + y^2}  \right) + \partial_y \left(\dfrac{y}{x^2 + y^2}  \right).  $$ However, I have not been able to show that this relation indeed holds. How can I prove that it is indeed true?","In the complex plane, one can write How to prove this relation has been answered before and identifies However, I have not been able to show that this relation indeed holds. How can I prove that it is indeed true?",\delta(x) \delta(y) = \dfrac{1}{\pi} \partial_z \dfrac{1}{\bar{z}}.  2\pi \delta(x) \delta(y) = \partial_x \left(\dfrac{x}{x^2 + y^2}  \right) + \partial_y \left(\dfrac{y}{x^2 + y^2}  \right).  ,"['complex-analysis', 'distribution-theory', 'dirac-delta']"
89,Sum of $\sum_0^\infty \frac1{n^4+a^4}$ [duplicate],Sum of  [duplicate],\sum_0^\infty \frac1{n^4+a^4},"This question already has answers here : Closed form for $\sum_{n=-\infty}^{\infty} \frac{1}{n^4+a^4}$ (4 answers) Closed 1 year ago . How to find the following series as pretty closed form by $a$ ? $$S=\sum_0^\infty \frac1{n^4+a^4}$$ I first considered applying Herglotz trick, simply because the expressions are similar. So I changed it like this... $$2S-a^{-4}=\sum_{-\infty}^\infty \frac1{n^4+a^4}$$ However, the attempt failed to find such an appropriate function like $\pi\cot\pi z$ in this post . Next I found this post and used Fourier transform in a similar way, and the result was a nightmare! How on earth can I calculate the value of this series?","This question already has answers here : Closed form for $\sum_{n=-\infty}^{\infty} \frac{1}{n^4+a^4}$ (4 answers) Closed 1 year ago . How to find the following series as pretty closed form by ? I first considered applying Herglotz trick, simply because the expressions are similar. So I changed it like this... However, the attempt failed to find such an appropriate function like in this post . Next I found this post and used Fourier transform in a similar way, and the result was a nightmare! How on earth can I calculate the value of this series?",a S=\sum_0^\infty \frac1{n^4+a^4} 2S-a^{-4}=\sum_{-\infty}^\infty \frac1{n^4+a^4} \pi\cot\pi z,"['complex-analysis', 'fourier-transform']"
90,How to understand the notation $\frac{\partial}{\partial z}$ and $\frac{\partial}{\partial \bar{z}}$ (Wirtinger derivatives)?,How to understand the notation  and  (Wirtinger derivatives)?,\frac{\partial}{\partial z} \frac{\partial}{\partial \bar{z}},"The Wirtinger derivatives are defined as $$\frac{\partial}{\partial z}:=\frac{1}{2}\left(\frac{\partial}{\partial x} - i\frac{\partial}{\partial y}\right)\quad \quad\frac{\partial}{\partial \bar{z}}:=\frac{1}{2}\left(\frac{\partial}{\partial x} + i\frac{\partial}{\partial y}\right)$$ I wonder why we use the notation partial derivative $\frac{\partial}{\partial z}$ and $\frac{\partial}{\partial \bar{z}}$ to represent Wirtinger derivatives. Does this suggest Wirtinger derivatives are a kind of partial derivative with respect to $z$ or $\bar{z}$ ? I am confused by this fact: $z$ and $\bar{z}$ are not independent. Here by not independent I mean $\bar{z}$ is a function of $z$ . This leads to several following problems. Let $f$ be the function $f(z)=\bar{z}$ . As a function of $z$ , the partial derivative of $f$ with respect to $z$ should not equal to 0. However, according the definition of Wirtinger derivatives, $\frac{\partial f}{\partial z} = 0$ . Let $f:\mathbb{C} \to \mathbb{C}$ be a function. Can we write $f(z) = g(z,\bar{z})$ for some function $g:\mathbb{C}^2 \to \mathbb{C}$ and regard $\frac{\partial f}{\partial z}$ as $\frac{\partial g}{\partial z}$ , where $\frac{\partial g}{\partial z}$ means partial derivative instead of Wirtinger derivative ? If so, when we compute partial derivative of $g$ respect to $z$ , we should fix the second variable $\bar{z}$ . But fixing $\bar{z}$ also means fixing $z$ , then how does partial derivative make sence? By the definition of Wirtinger derivatives, it's easy to get $\frac{\partial \bar{z}^n}{\partial \bar{z}} = n\bar{z}^{n-1}$ , similar to partial derivative. For arbitrary $f:\mathbb{C} \to \mathbb{C}$ , can we get a right answer like this, computing Wirtinger derivative as partial derivative ? If so, how to prove it? I believe the notation $\frac{\partial}{\partial z}$ and $\frac{\partial}{\partial \bar{z}}$ suggest Wirtinger derivatives are a kind of partial derivative, but I can't solve the problems above. Could you please give me a rigorous answer? Thanks for your help.","The Wirtinger derivatives are defined as I wonder why we use the notation partial derivative and to represent Wirtinger derivatives. Does this suggest Wirtinger derivatives are a kind of partial derivative with respect to or ? I am confused by this fact: and are not independent. Here by not independent I mean is a function of . This leads to several following problems. Let be the function . As a function of , the partial derivative of with respect to should not equal to 0. However, according the definition of Wirtinger derivatives, . Let be a function. Can we write for some function and regard as , where means partial derivative instead of Wirtinger derivative ? If so, when we compute partial derivative of respect to , we should fix the second variable . But fixing also means fixing , then how does partial derivative make sence? By the definition of Wirtinger derivatives, it's easy to get , similar to partial derivative. For arbitrary , can we get a right answer like this, computing Wirtinger derivative as partial derivative ? If so, how to prove it? I believe the notation and suggest Wirtinger derivatives are a kind of partial derivative, but I can't solve the problems above. Could you please give me a rigorous answer? Thanks for your help.","\frac{\partial}{\partial z}:=\frac{1}{2}\left(\frac{\partial}{\partial x} - i\frac{\partial}{\partial y}\right)\quad \quad\frac{\partial}{\partial \bar{z}}:=\frac{1}{2}\left(\frac{\partial}{\partial x} + i\frac{\partial}{\partial y}\right) \frac{\partial}{\partial z} \frac{\partial}{\partial \bar{z}} z \bar{z} z \bar{z} \bar{z} z f f(z)=\bar{z} z f z \frac{\partial f}{\partial z} = 0 f:\mathbb{C} \to \mathbb{C} f(z) = g(z,\bar{z}) g:\mathbb{C}^2 \to \mathbb{C} \frac{\partial f}{\partial z} \frac{\partial g}{\partial z} \frac{\partial g}{\partial z} g z \bar{z} \bar{z} z \frac{\partial \bar{z}^n}{\partial \bar{z}} = n\bar{z}^{n-1} f:\mathbb{C} \to \mathbb{C} \frac{\partial}{\partial z} \frac{\partial}{\partial \bar{z}}",['complex-analysis']
91,Asymptotic Notations: $\sim$ vs $\asymp$ and PNT,Asymptotic Notations:  vs  and PNT,\sim \asymp,"Is the only difference between $f(x) \sim g(x)$ and $f(x)\asymp g(x)$ the constant which their ratio approaches? My understanding is that $f(x)\asymp g(x)$ means that $f(x)=O(g(x))$ and $g(x)=O(f(x))$ , and that this is equvialent to saying that $$\lim\frac{f(x)}{g(x)}$$ exists (or at least, $\limsup$ ) and is some fixed number. On the other hand, $f(x)\sim g(x)$ means that this limit is specifically $1$ . I ask this question because it doesn't feel like one is that much stronger than the other, they both establish that $f(x)$ and $g(x)$ are the same ""kind"" of function with respect to their growth (they feel more or less the same qualitatively), $\asymp$ is more akin to ""proportional to"" in the limit, rather than $\sim$ which is sort of like ""equal to"" in the limit. In particular, I'm surprised how easy the proof of Chebychev's theorem $\pi(x)\asymp x/\log x$ is when compared with the PNT $\pi(x)\sim x/\log x$ .","Is the only difference between and the constant which their ratio approaches? My understanding is that means that and , and that this is equvialent to saying that exists (or at least, ) and is some fixed number. On the other hand, means that this limit is specifically . I ask this question because it doesn't feel like one is that much stronger than the other, they both establish that and are the same ""kind"" of function with respect to their growth (they feel more or less the same qualitatively), is more akin to ""proportional to"" in the limit, rather than which is sort of like ""equal to"" in the limit. In particular, I'm surprised how easy the proof of Chebychev's theorem is when compared with the PNT .",f(x) \sim g(x) f(x)\asymp g(x) f(x)\asymp g(x) f(x)=O(g(x)) g(x)=O(f(x)) \lim\frac{f(x)}{g(x)} \limsup f(x)\sim g(x) 1 f(x) g(x) \asymp \sim \pi(x)\asymp x/\log x \pi(x)\sim x/\log x,"['real-analysis', 'complex-analysis', 'number-theory', 'asymptotics']"
92,Proof that no holomorphic function exists such that $|f(z)| > |z|$,Proof that no holomorphic function exists such that,|f(z)| > |z|,I need to proof that no holomorphic function exists such that $|f(z)| > |z|$ . I defined $g(z) = \frac{z}{f(z)}$ . It follows that $|g(z)| < 1$ and with Liouville's theorem follows that $g$ has to be constant. How can I show that $f$ is constant? As I see it $f$ must be linear but not constant.,I need to proof that no holomorphic function exists such that . I defined . It follows that and with Liouville's theorem follows that has to be constant. How can I show that is constant? As I see it must be linear but not constant.,|f(z)| > |z| g(z) = \frac{z}{f(z)} |g(z)| < 1 g f f,['complex-analysis']
93,Pointwise prove.,Pointwise prove.,,"Prove that $$f_n =\begin{cases} n\sin(nx) &\text{for} \space 0 \leq nx \leq \pi\\ 0 & \text{otherwise}\end{cases}$$ converges pointwise to 0 as $n \to \infty$ , being n a integer and for all x satisfying the properties. I retired this question from a book about complex numbers/functions exercise. Now i just get a counterpoint, see: Adote $x = \pi/2n$ , so that $f_n = nsin(\pi/2)=n$ . Now this certainly does not tends to 0. What am i doing wrong? I mean, i just found a counterprove to what i should prove, so i think or the enunciate is wrong or am i wrong, so, if i am wrong, where is my error?","Prove that converges pointwise to 0 as , being n a integer and for all x satisfying the properties. I retired this question from a book about complex numbers/functions exercise. Now i just get a counterpoint, see: Adote , so that . Now this certainly does not tends to 0. What am i doing wrong? I mean, i just found a counterprove to what i should prove, so i think or the enunciate is wrong or am i wrong, so, if i am wrong, where is my error?",f_n =\begin{cases} n\sin(nx) &\text{for} \space 0 \leq nx \leq \pi\\ 0 & \text{otherwise}\end{cases} n \to \infty x = \pi/2n f_n = nsin(\pi/2)=n,"['complex-analysis', 'limits']"
94,Show that $\int^{\infty}_{-\infty}\frac{dx}{(x^2-4x+5)^2} = \frac{\pi}{2}$ using residue theory,Show that  using residue theory,\int^{\infty}_{-\infty}\frac{dx}{(x^2-4x+5)^2} = \frac{\pi}{2},"I'm trying to evaluate some complex integrals using residue theory. I've read a number of articles with different examples here on Stack Exchange, but I'm still really lost and could use some help. Show that $\int^{\infty}_{-\infty}\frac{dx}{(x^2-4x+5)^2} = \frac{\pi}{2}$ . First, I found the poles of the function as $2-i$ and $2+i$ . Both of these poles are of order $2$ . I am also considering my region as the semicircle of radius $R$ in the upper half-plane with the line segment between $x=−R$ and $x=R$ on the real axis. So I know that I need to evaulate $$\int_{\Gamma}f(z)dz = 2\pi iRes(f,2+i) + 2\pi iRes(f,2-i)$$ At this point, I'm really stuck on what to do from here. I tried evaluating the residues and was getting some really weird answers. My work was really messy and likely completely wrong, so hopefully it's OK if I don't reproduce it here. I'm not sure how to finish solving this. Similarly, I'm having trouble with this integral: $\int_{|z| = 1}z^3e^{1/z}\sin(\frac{1}{z}) dz$ I know that there is a pole at $z = 0$ . So that means I need to evaluate $$ \int_{|z| = 1}z^3e^{1/z}\sin(\frac{1}{z}) dz = 2\pi i Res(f,0)$$ Do I consider this pole of order $1$ or order $2$ and how do I find this residue?","I'm trying to evaluate some complex integrals using residue theory. I've read a number of articles with different examples here on Stack Exchange, but I'm still really lost and could use some help. Show that . First, I found the poles of the function as and . Both of these poles are of order . I am also considering my region as the semicircle of radius in the upper half-plane with the line segment between and on the real axis. So I know that I need to evaulate At this point, I'm really stuck on what to do from here. I tried evaluating the residues and was getting some really weird answers. My work was really messy and likely completely wrong, so hopefully it's OK if I don't reproduce it here. I'm not sure how to finish solving this. Similarly, I'm having trouble with this integral: I know that there is a pole at . So that means I need to evaluate Do I consider this pole of order or order and how do I find this residue?","\int^{\infty}_{-\infty}\frac{dx}{(x^2-4x+5)^2} = \frac{\pi}{2} 2-i 2+i 2 R x=−R x=R \int_{\Gamma}f(z)dz = 2\pi iRes(f,2+i) + 2\pi iRes(f,2-i) \int_{|z| = 1}z^3e^{1/z}\sin(\frac{1}{z}) dz z = 0  \int_{|z| = 1}z^3e^{1/z}\sin(\frac{1}{z}) dz = 2\pi i Res(f,0) 1 2",[]
95,How to calculate the Fourier transform of the Kaiser-Bessel window?,How to calculate the Fourier transform of the Kaiser-Bessel window?,,"According to Wikipedia: https://en.wikipedia.org/wiki/Kaiser_window , the Fourier transform of the Kaiser-Bessel window $w_0(x) :=  \left\{ \begin{array}{**lr**} \frac{I_0(\pi \alpha \sqrt{1-{(2x/L)}^2})}{I_0(\pi \alpha)}, &  |x| \leq \frac{L}{2}\\                0, & |x| > \frac{L}{2}\\                \end{array} \right.  $ is $W(f) := \frac{L\cdot \sinh(\pi\alpha\sqrt{1-(Lf/\alpha)^2})}{I_0(\pi\alpha) \cdot \pi\alpha\sqrt{1-(Lf/\alpha)^2}}$ , where $I_0(x) := \sum\limits_{m=0}^{\infty}\frac{1}{(m!)^2}(\frac{x}{2})^{2m}$ is the zeroth-order modified Bessel function of the first kind ( https://en.wikipedia.org/wiki/Bessel_function#Modified_Bessel_functions:_I%CE%B1,_K%CE%B1 ). I have made many attempts but fail to deduce the closed-form solution of the Fourier transform of the Kaiser-Bessel window. First, I tried to expand $I_0(x)$ , which was quite difficult to calculate since it involved infinite series. Second,  I tried to calculate the Fourier transform from the opposite side, i.e., $W(f)$ , but got no result. Finally, I tried to use Mathematica Professional 12, but it failed to offer a result after long time calculation. I have also found some literature online, e.g., [1] On the use of the I0-sinh window for spectrum analysis, IEEE Transactions on Acoustics, Speech, and Signal Processing, J. Kaiser, R. Schafer, 1980, doi: 10.1109/TASSP.1980.1163349. [2] On the use of windows for harmonic analysis with the discrete Fourier transform, Proceedings of the IEEE, F.J. Harris, 1978, doi: 10.1109/PROC.1978.10837. [3] https://www.dsprelated.com/freebooks/sasp/Kaiser_Window.html [4] Verification of Fourier transformation of Io-sinh function (MathStackExchange; No answer yet). Neither of them deduces the closed form of the Fourier transform of the Kaiser-Bessel window. Some references, e.g., [1] and [3], point to an old unavailable book named ""System Analysis by Digital Computer"". Kaiser-Bessel window is a widely used window function in signal processing. However, it is really difficult to find relevant literature online. Additionally, I am not sure whether the Fourier transform provided in https://en.wikipedia.org/wiki/Kaiser_window is a closed-form or an approximation. I deeply appreciate your help or hints.","According to Wikipedia: https://en.wikipedia.org/wiki/Kaiser_window , the Fourier transform of the Kaiser-Bessel window is , where is the zeroth-order modified Bessel function of the first kind ( https://en.wikipedia.org/wiki/Bessel_function#Modified_Bessel_functions:_I%CE%B1,_K%CE%B1 ). I have made many attempts but fail to deduce the closed-form solution of the Fourier transform of the Kaiser-Bessel window. First, I tried to expand , which was quite difficult to calculate since it involved infinite series. Second,  I tried to calculate the Fourier transform from the opposite side, i.e., , but got no result. Finally, I tried to use Mathematica Professional 12, but it failed to offer a result after long time calculation. I have also found some literature online, e.g., [1] On the use of the I0-sinh window for spectrum analysis, IEEE Transactions on Acoustics, Speech, and Signal Processing, J. Kaiser, R. Schafer, 1980, doi: 10.1109/TASSP.1980.1163349. [2] On the use of windows for harmonic analysis with the discrete Fourier transform, Proceedings of the IEEE, F.J. Harris, 1978, doi: 10.1109/PROC.1978.10837. [3] https://www.dsprelated.com/freebooks/sasp/Kaiser_Window.html [4] Verification of Fourier transformation of Io-sinh function (MathStackExchange; No answer yet). Neither of them deduces the closed form of the Fourier transform of the Kaiser-Bessel window. Some references, e.g., [1] and [3], point to an old unavailable book named ""System Analysis by Digital Computer"". Kaiser-Bessel window is a widely used window function in signal processing. However, it is really difficult to find relevant literature online. Additionally, I am not sure whether the Fourier transform provided in https://en.wikipedia.org/wiki/Kaiser_window is a closed-form or an approximation. I deeply appreciate your help or hints.","w_0(x) :=  \left\{ \begin{array}{**lr**} \frac{I_0(\pi \alpha \sqrt{1-{(2x/L)}^2})}{I_0(\pi \alpha)}, &  |x| \leq \frac{L}{2}\\  
             0, & |x| > \frac{L}{2}\\  
             \end{array} \right.   W(f) := \frac{L\cdot \sinh(\pi\alpha\sqrt{1-(Lf/\alpha)^2})}{I_0(\pi\alpha) \cdot \pi\alpha\sqrt{1-(Lf/\alpha)^2}} I_0(x) := \sum\limits_{m=0}^{\infty}\frac{1}{(m!)^2}(\frac{x}{2})^{2m} I_0(x) W(f)","['calculus', 'complex-analysis', 'fourier-transform', 'signal-processing']"
96,Uniformly convergent sequence of holomorphic function in every compact subset converges to holomorphic function,Uniformly convergent sequence of holomorphic function in every compact subset converges to holomorphic function,,"$\{f_n\}^\infty_{n=1}$ is a sequence of holomorphic functions that converges uniformly to a function $f$ in every compact subset of $\Omega$ , then $f$ is holomorphic in $\Omega$ . We let $D$ be any disc whose closure is contained in $\Omega$ . Then for any triangle $T$ contained in $D$ , by Goursat's theorem, we have $\int _T f_n(z)dz=0$ . It then asserts that $$\int_T f_n(z)dz\to \int_T f(z)dz\text{ as }z\to \infty$$ in the closure of $D$ , because of the uniform convergence of $f_n$ . This seems a basic question, but can anybody please elaborate what is happening here?","is a sequence of holomorphic functions that converges uniformly to a function in every compact subset of , then is holomorphic in . We let be any disc whose closure is contained in . Then for any triangle contained in , by Goursat's theorem, we have . It then asserts that in the closure of , because of the uniform convergence of . This seems a basic question, but can anybody please elaborate what is happening here?",\{f_n\}^\infty_{n=1} f \Omega f \Omega D \Omega T D \int _T f_n(z)dz=0 \int_T f_n(z)dz\to \int_T f(z)dz\text{ as }z\to \infty D f_n,['complex-analysis']
97,On the dependence between $\bar{z}$ and $z$,On the dependence between  and,\bar{z} z,"I was introduced the following example to illustrate the dependence between $z$ and $\bar{z}$ , which is the complex conjugate of $z\in \mathbb{C}$ : \begin{equation} g(z)=\int_{0}^{2 \pi} \frac{d \theta}{2 \pi} \frac{1}{z-e^{i \theta}}=\oint \frac{d w}{2 \pi i} \frac{1}{w(z-w)} \end{equation} which appears to only depend on $z$ . However, $g\left(z, \bar{z}\right)=\theta\left(|z|^{2}-1\right) / z$ is non-analytic, and depends on $\textbf{both}$ $z$ and $\bar{z}$ . I don't understand this last sentence.  If we know $z$ , then we know $|z|^2$ and also $\bar{z}$ . All in all, I do not understand why we have to write $g(z,\bar{z})$ as a function of two different variables.","I was introduced the following example to illustrate the dependence between and , which is the complex conjugate of : which appears to only depend on . However, is non-analytic, and depends on and . I don't understand this last sentence.  If we know , then we know and also . All in all, I do not understand why we have to write as a function of two different variables.","z \bar{z} z\in \mathbb{C} \begin{equation}
g(z)=\int_{0}^{2 \pi} \frac{d \theta}{2 \pi} \frac{1}{z-e^{i \theta}}=\oint \frac{d w}{2 \pi i} \frac{1}{w(z-w)}
\end{equation} z g\left(z, \bar{z}\right)=\theta\left(|z|^{2}-1\right) / z \textbf{both} z \bar{z} z |z|^2 \bar{z} g(z,\bar{z})","['complex-analysis', 'analysis', 'complex-integration']"
98,Using roots of unity to factorize polynomials,Using roots of unity to factorize polynomials,,"Engel's Problem Solving Strategies has the following exercise (p.260 #28). Show $x^4 +x^3+x^2+x+1 \hspace{0.1cm}\big{|}\hspace{0.1cm}x^{44}+x^{33}+x^{22}+x^{11}+1$ . I've been working through these problems and have seen the following strategy implemented quite a bit. Essentially it boils down to the following: Let $\omega^5=1$ be a fifth root of unity excluding $1$ ; then any $\omega$ satisfying this equation is simultaneously a root for the polynomial $x^4 +x^3+x^2+x+1$ and $x^{44}+x^{33}+x^{22}+x^{11}+1$ , so claim follows. Here is my question. Is it true that for every value of $n$ , the roots of unity $\omega$ satisfying $\omega^n=1$ , excluding $1$ , are exactly the roots of the polynomial $\sum_{j=0}^{n-1}x^j$ ? Or, e.g., only prime $n$ ? Thank you.","Engel's Problem Solving Strategies has the following exercise (p.260 #28). Show . I've been working through these problems and have seen the following strategy implemented quite a bit. Essentially it boils down to the following: Let be a fifth root of unity excluding ; then any satisfying this equation is simultaneously a root for the polynomial and , so claim follows. Here is my question. Is it true that for every value of , the roots of unity satisfying , excluding , are exactly the roots of the polynomial ? Or, e.g., only prime ? Thank you.",x^4 +x^3+x^2+x+1 \hspace{0.1cm}\big{|}\hspace{0.1cm}x^{44}+x^{33}+x^{22}+x^{11}+1 \omega^5=1 1 \omega x^4 +x^3+x^2+x+1 x^{44}+x^{33}+x^{22}+x^{11}+1 n \omega \omega^n=1 1 \sum_{j=0}^{n-1}x^j n,"['complex-analysis', 'number-theory', 'polynomials']"
99,Complex analysis. Continuous and differentiable function in polar form,Complex analysis. Continuous and differentiable function in polar form,,"Given a function $f:\mathbb{R} \rightarrow \mathbb{C}$ that is continuous and differentiable everywhere. Is it true that I can write $f(t)$ as: $$f(t) = r(t)e^{i\theta(t)}$$ for some $r(t)$ and $\theta(t)$ that are real, continuous and differentiable everywhere. Intuitively the answer seems yes to me. I can choose $$r(t) = |f(t)|$$ I can start with $$\theta(t) = arg(f(t))$$ for nonzero $f(t)$ and modify it to remove discontinuities by adding or subtracting $2\pi$ at discontinuous t values. At values where $f(t) = 0$ ,  I can choose $\theta(t)$ to maintain continuity. But I'm interested in a rigorous answer. Thanks.","Given a function that is continuous and differentiable everywhere. Is it true that I can write as: for some and that are real, continuous and differentiable everywhere. Intuitively the answer seems yes to me. I can choose I can start with for nonzero and modify it to remove discontinuities by adding or subtracting at discontinuous t values. At values where ,  I can choose to maintain continuity. But I'm interested in a rigorous answer. Thanks.",f:\mathbb{R} \rightarrow \mathbb{C} f(t) f(t) = r(t)e^{i\theta(t)} r(t) \theta(t) r(t) = |f(t)| \theta(t) = arg(f(t)) f(t) 2\pi f(t) = 0 \theta(t),"['complex-analysis', 'polar-coordinates']"
