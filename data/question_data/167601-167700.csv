,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is this an exponential distribution? (Variant of Gumbel distribution),Is this an exponential distribution? (Variant of Gumbel distribution),,"The distribution function is $$F_x(x\mid\lambda) = e^{-e^{-\lambda x}}, \qquad \lambda > 0$$ Is this an exponential family? The pdf that I obtained was $$f(x\mid\lambda) = \lambda e^{-\lambda x} e^{-e^{-\lambda x}}$$ and the joint pdf of an iid sample is $$f(x^n\mid\lambda) = \lambda^n e^{-\lambda \sum_{i=1}^n x_i} e^{-\sum_{i=1}^n (e^{-\lambda x_i})}$$ I don't see how I can bring this to the form that is required for it to be an exponential family. Am I right in concluding that this isn't an exponential family? Also, is it possible to use the Karlin Rubin theorem to obtain a UMP test and thus a  confidence interval for $\lambda$?","The distribution function is $$F_x(x\mid\lambda) = e^{-e^{-\lambda x}}, \qquad \lambda > 0$$ Is this an exponential family? The pdf that I obtained was $$f(x\mid\lambda) = \lambda e^{-\lambda x} e^{-e^{-\lambda x}}$$ and the joint pdf of an iid sample is $$f(x^n\mid\lambda) = \lambda^n e^{-\lambda \sum_{i=1}^n x_i} e^{-\sum_{i=1}^n (e^{-\lambda x_i})}$$ I don't see how I can bring this to the form that is required for it to be an exponential family. Am I right in concluding that this isn't an exponential family? Also, is it possible to use the Karlin Rubin theorem to obtain a UMP test and thus a  confidence interval for $\lambda$?",,['statistics']
1,Data/Feature normalization,Data/Feature normalization,,"Let's say I have a set of random elements of the interval $(-1,1)$. $$S=\{0.03,-0.1,0.5,-0.45,...\}$$ I'm looking for a bijective function $f(x)$ which normalizes the elements of $S$ such that the mean is close to 0 and the variance is close to 1. Since I need those elements as input for a neural network with thanh activation function, it's very important that the normalizing function is bijective. I thought about something like the normal distribution which gives control over the mean and standard deviation. Maybe someone knows a specific function with the required attributes or a procedure to solve this  task.","Let's say I have a set of random elements of the interval $(-1,1)$. $$S=\{0.03,-0.1,0.5,-0.45,...\}$$ I'm looking for a bijective function $f(x)$ which normalizes the elements of $S$ such that the mean is close to 0 and the variance is close to 1. Since I need those elements as input for a neural network with thanh activation function, it's very important that the normalizing function is bijective. I thought about something like the normal distribution which gives control over the mean and standard deviation. Maybe someone knows a specific function with the required attributes or a procedure to solve this  task.",,"['statistics', 'functions', 'neural-networks']"
2,How to compute variance of a conditional expectation and vice versa,How to compute variance of a conditional expectation and vice versa,,"I am trying to use the law of total variance which is $$\operatorname{Var}(X) = \text{Var}(E(X\mid Y)) + E(\operatorname{Var}(X\mid Y))$$ But I honestly have no idea how to compute either one of these terms. I have the following example: Let $y$ be the value you get when rolling a 4-sided die. Then you roll $y$ 6-sided dice. Let $x$ be the sum of all the values. What is the variance of $x$? I know that $E(y) = 5/2$ and $\operatorname{Var}(y) = 5/4$ by use of $\operatorname{Var}(y) = E(y^2) - E(y)^2$, but I don't know how to compute the conditional terms properly above. I already know the answer is $1085/48$ but want to know how to get there.","I am trying to use the law of total variance which is $$\operatorname{Var}(X) = \text{Var}(E(X\mid Y)) + E(\operatorname{Var}(X\mid Y))$$ But I honestly have no idea how to compute either one of these terms. I have the following example: Let $y$ be the value you get when rolling a 4-sided die. Then you roll $y$ 6-sided dice. Let $x$ be the sum of all the values. What is the variance of $x$? I know that $E(y) = 5/2$ and $\operatorname{Var}(y) = 5/4$ by use of $\operatorname{Var}(y) = E(y^2) - E(y)^2$, but I don't know how to compute the conditional terms properly above. I already know the answer is $1085/48$ but want to know how to get there.",,"['probability', 'number-theory', 'statistics', 'expectation', 'variance']"
3,Why is the classical Secretary Problem about Ranks?,Why is the classical Secretary Problem about Ranks?,,"The Secretary Problem goes like this: To an observer there are presented objects in a row. He may either choose the object one it is presented or move on - there is no turning back. Objective: stop at the best Item. Some were confused by the notations to come. I would like to try to explain what this is about. Consider the literal setting of the problem. You get candidates and know nothing about their quality in advance, yet have to stop at the best candidate with the highest probability possible. When this problem is put into math usually the papers start with just looking at the rank. But then you get trouble (you have to model again) if you want to consider the same problem with knowing for an example the candidates are normal distributed and you just do not know the parameters. (The winning chance rises to about 0.58 asymptotically) The way I propose the problem it is consistent for these cases and I now consider the classical problem as a special case to gain information on dealing with the more abstract problem. Think of the problem like this: The items are $F^{-1}(X_1),...,F^{-1}(X_n)$ were the $X_i$are iid. uniformly distributed on $[0,1]$ and $F^{-1}$ is the pseudo inverse of a cumulative distribution function $F$, thus $F^{-1}(X_i) \sim{ F}$. $F$ may be any continuous distribution function (jumps seem to give the observer an advantage because he does not miss chances so easy, but that is another story). Let $D: \mathbb{R}^n \rightarrow \{1,...,n\}$ be a stopping time. The problem then would be to get $\Delta$ such that: $\max_{D}\inf_{F} P(F^{-1}(X)_{D(F^-1(X))}=\max_{i \leq n} F^{-1}(X_i)) = \max_{D}\inf_{F} P(X_{D(F^{-1}(X))}=\max_{i \leq n} X_i)=\inf_{F} P(X_{\Delta(F^-1(X))}=\max_{i \leq n} X_i)$ Most of the time in literature the problem is solved by finding $\Delta$ with: $\max_{D}P(X_{D(R(X))}=\max_{i \leq n} X_i)= P(X_{\Delta(R(X))}=\max_{i \leq n} X_i)$. Here $R(X)=R(X_1,...,X_n)=(R_1(X_1),R_2(X_1,X_2),...,R_n(X_1,...,X_n))$ and $R_i(X_1,...,X_i) = \sum^{i}_{k=1}\mathbf{1}_{X_k \leq X_i}$, the relative rank of the observed item. My question: Why exactly are the first expressions of my terms the same? So my question is why does hold: $\max_{D}\inf_{F} P(F^{-1}(X)_{D(F^-1(X))}=\max_{i \leq n} F^{-1}(X_i))=\max_{D}P(X_{D(R(X))}=\max_{i \leq n} X_i)$ Which is solved provided someone proves: $\inf_{F} P(X_{D(F^{-1}(X))}=\max_{i \leq n} X_i) \leq P(X_{D(R(X))}=\max_{i \leq n} X_i)$ Note that taking ranks is some sort of protection against any distribution - you do the same thing no matter the distribution. We just need a distribution so vicious that we rather take ranks. Thank you very much for your support. Any comment is very welcome.","The Secretary Problem goes like this: To an observer there are presented objects in a row. He may either choose the object one it is presented or move on - there is no turning back. Objective: stop at the best Item. Some were confused by the notations to come. I would like to try to explain what this is about. Consider the literal setting of the problem. You get candidates and know nothing about their quality in advance, yet have to stop at the best candidate with the highest probability possible. When this problem is put into math usually the papers start with just looking at the rank. But then you get trouble (you have to model again) if you want to consider the same problem with knowing for an example the candidates are normal distributed and you just do not know the parameters. (The winning chance rises to about 0.58 asymptotically) The way I propose the problem it is consistent for these cases and I now consider the classical problem as a special case to gain information on dealing with the more abstract problem. Think of the problem like this: The items are $F^{-1}(X_1),...,F^{-1}(X_n)$ were the $X_i$are iid. uniformly distributed on $[0,1]$ and $F^{-1}$ is the pseudo inverse of a cumulative distribution function $F$, thus $F^{-1}(X_i) \sim{ F}$. $F$ may be any continuous distribution function (jumps seem to give the observer an advantage because he does not miss chances so easy, but that is another story). Let $D: \mathbb{R}^n \rightarrow \{1,...,n\}$ be a stopping time. The problem then would be to get $\Delta$ such that: $\max_{D}\inf_{F} P(F^{-1}(X)_{D(F^-1(X))}=\max_{i \leq n} F^{-1}(X_i)) = \max_{D}\inf_{F} P(X_{D(F^{-1}(X))}=\max_{i \leq n} X_i)=\inf_{F} P(X_{\Delta(F^-1(X))}=\max_{i \leq n} X_i)$ Most of the time in literature the problem is solved by finding $\Delta$ with: $\max_{D}P(X_{D(R(X))}=\max_{i \leq n} X_i)= P(X_{\Delta(R(X))}=\max_{i \leq n} X_i)$. Here $R(X)=R(X_1,...,X_n)=(R_1(X_1),R_2(X_1,X_2),...,R_n(X_1,...,X_n))$ and $R_i(X_1,...,X_i) = \sum^{i}_{k=1}\mathbf{1}_{X_k \leq X_i}$, the relative rank of the observed item. My question: Why exactly are the first expressions of my terms the same? So my question is why does hold: $\max_{D}\inf_{F} P(F^{-1}(X)_{D(F^-1(X))}=\max_{i \leq n} F^{-1}(X_i))=\max_{D}P(X_{D(R(X))}=\max_{i \leq n} X_i)$ Which is solved provided someone proves: $\inf_{F} P(X_{D(F^{-1}(X))}=\max_{i \leq n} X_i) \leq P(X_{D(R(X))}=\max_{i \leq n} X_i)$ Note that taking ranks is some sort of protection against any distribution - you do the same thing no matter the distribution. We just need a distribution so vicious that we rather take ranks. Thank you very much for your support. Any comment is very welcome.",,"['probability', 'statistics']"
4,How to find the expected value of this game?,How to find the expected value of this game?,,"How can I create a function that figures out the expected value for a value that can change. Example: I can flip a (fair) coin $n$ number of times. The pot starts at $\$1$. If I lose, $50$ cents is added to the pot. If I win, I take what is in the pot and the pot is reset to $\$1$. How can I figure out my expected value over $n$ number of coin flips? The best I have come up with so far is: $$\sum_{i=0}^n ((\text{currentPot} + (\text{incrmntOnLoss} \cdot \text{ numOfLosses})) \cdot \text{winChance})$$ but this doesn't take into account that the value can reset to $\$1$ after any flip. It seems to be me that it would be some sort of recursive solution, but I'm unsure how that would be solved in math form","How can I create a function that figures out the expected value for a value that can change. Example: I can flip a (fair) coin $n$ number of times. The pot starts at $\$1$. If I lose, $50$ cents is added to the pot. If I win, I take what is in the pot and the pot is reset to $\$1$. How can I figure out my expected value over $n$ number of coin flips? The best I have come up with so far is: $$\sum_{i=0}^n ((\text{currentPot} + (\text{incrmntOnLoss} \cdot \text{ numOfLosses})) \cdot \text{winChance})$$ but this doesn't take into account that the value can reset to $\$1$ after any flip. It seems to be me that it would be some sort of recursive solution, but I'm unsure how that would be solved in math form",,"['probability', 'statistics']"
5,sequential anova r,sequential anova r,,"I am a really confused. Assume we have a multiple regression model: $$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 +\cdots+ \beta_k x_k  $$ Using R we can make a test: $$ H0: \beta_1 = \beta_2 = \cdots = \beta_k\\ H1: \beta_j \neq 0 \; \text{for at least one $j$},  $$ by the procedure summary(lm(Y~X1+X2+..+Xk, data = data)), which gives us value of F-statistics and p-value. Everything is clear. Also, we can make a partial F-test, for example for first coefficient, using anova(lm(Y~X2+..+Xk, data = data) , lm(Y~X1+X2+..+Xk, data = data)). This is also clear. I cannot understand, what we get by the following: anova(lm(Y~X1+X2+..+Xk, data = data)). It gives us k lines with F values and p values which I cannot understand... I tried to read the description and it says that this is a sequential testing of coefficients (nested models). Ok, if I run the following: anova(lm(Y~1, data = data), lm(Y~X1, data = data)) it does not give the same results for F and p as it was in the first line in anova(lm(Y~X1+X2+..+Xk, data = data)). Could you, please, make it clear and sorry if the question is stupid.","I am a really confused. Assume we have a multiple regression model: $$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 +\cdots+ \beta_k x_k  $$ Using R we can make a test: $$ H0: \beta_1 = \beta_2 = \cdots = \beta_k\\ H1: \beta_j \neq 0 \; \text{for at least one $j$},  $$ by the procedure summary(lm(Y~X1+X2+..+Xk, data = data)), which gives us value of F-statistics and p-value. Everything is clear. Also, we can make a partial F-test, for example for first coefficient, using anova(lm(Y~X2+..+Xk, data = data) , lm(Y~X1+X2+..+Xk, data = data)). This is also clear. I cannot understand, what we get by the following: anova(lm(Y~X1+X2+..+Xk, data = data)). It gives us k lines with F values and p values which I cannot understand... I tried to read the description and it says that this is a sequential testing of coefficients (nested models). Ok, if I run the following: anova(lm(Y~1, data = data), lm(Y~X1, data = data)) it does not give the same results for F and p as it was in the first line in anova(lm(Y~X1+X2+..+Xk, data = data)). Could you, please, make it clear and sorry if the question is stupid.",,"['statistics', 'statistical-inference', 'descriptive-statistics', 'regression-analysis', 'linear-regression']"
6,Calculating the Confidence Interval,Calculating the Confidence Interval,,"It is found that in a random sample of 100 Science students, there are 48 studying statistics . To test whether the true proportion of students in statistics is 50% or not, suitable null and alternative hypotheses are: (a) H0 :p=0.48;H1 :p̸=0.48 (b) H0 :p=0.5;H1 :p>0.5 (c) H0 :p=0.5;H1 :p<0.5 (d) H0 :p=0.5;H1 :p=0.48 (e) H0 :p=0.5;H1 :p̸=0.5 Find a 95% Confidence Interval for p in Q1. I have determined the answer to Q 1), which I believe is e). For question 2), I have been told the CI= estimator +/- (table value)(Standard error). The estimator is 0.48, and I have found the SE to be 0.05. However, I am unsure about how to calculate the ""table value"". Thank you.","It is found that in a random sample of 100 Science students, there are 48 studying statistics . To test whether the true proportion of students in statistics is 50% or not, suitable null and alternative hypotheses are: (a) H0 :p=0.48;H1 :p̸=0.48 (b) H0 :p=0.5;H1 :p>0.5 (c) H0 :p=0.5;H1 :p<0.5 (d) H0 :p=0.5;H1 :p=0.48 (e) H0 :p=0.5;H1 :p̸=0.5 Find a 95% Confidence Interval for p in Q1. I have determined the answer to Q 1), which I believe is e). For question 2), I have been told the CI= estimator +/- (table value)(Standard error). The estimator is 0.48, and I have found the SE to be 0.05. However, I am unsure about how to calculate the ""table value"". Thank you.",,"['statistics', 'confidence-interval']"
7,Trying to understand what is a p value,Trying to understand what is a p value,,"I am trying to understand what a p value is and what is its importance in statistics, from this example. For $50$ specimens of alloy steel the rock hardness scale measured an average of $62$ with standard deviation $8$ he manufacturer claims that the alloy has average strength of $64$ at significance of $0.01$ can you refute this? Well I did this problem and saw no at this level you cant refute it , I use the null being that the hardness was $64$ and the alternate that the hardness was less then $64$. From the data we observe a $z=-1.7677$ but the chart is $z=-2.33$ and so we cant refute null at this level. But now I want to understand what the p value would be , I thought it was that the p-value is the probability of getting the observed value of the test or a value with even more evidence against the null if the null is actually true. So using that I just look on the z chart, the probability of seeing Z greater then $1.7677$ is $0.0384$, so is that the p value?","I am trying to understand what a p value is and what is its importance in statistics, from this example. For $50$ specimens of alloy steel the rock hardness scale measured an average of $62$ with standard deviation $8$ he manufacturer claims that the alloy has average strength of $64$ at significance of $0.01$ can you refute this? Well I did this problem and saw no at this level you cant refute it , I use the null being that the hardness was $64$ and the alternate that the hardness was less then $64$. From the data we observe a $z=-1.7677$ but the chart is $z=-2.33$ and so we cant refute null at this level. But now I want to understand what the p value would be , I thought it was that the p-value is the probability of getting the observed value of the test or a value with even more evidence against the null if the null is actually true. So using that I just look on the z chart, the probability of seeing Z greater then $1.7677$ is $0.0384$, so is that the p value?",,"['statistics', 'hypothesis-testing']"
8,why is the geometric mean less than the logarithmic mean? [duplicate],why is the geometric mean less than the logarithmic mean? [duplicate],,"This question already has answers here : Proof of the following inequality $ \frac{x - y}{\log x - \log y} > \sqrt{xy} $, $x>y$. (6 answers) Closed 4 years ago . Can someone explain why the geometric mean is less than the logarithmic mean? $$\sqrt{ab} \leq  \frac{b-a}{\log b-\log a} $$","This question already has answers here : Proof of the following inequality $ \frac{x - y}{\log x - \log y} > \sqrt{xy} $, $x>y$. (6 answers) Closed 4 years ago . Can someone explain why the geometric mean is less than the logarithmic mean? $$\sqrt{ab} \leq  \frac{b-a}{\log b-\log a} $$",,"['calculus', 'statistics']"
9,Calculating the variation coefficient when the arithmetic mean is zero,Calculating the variation coefficient when the arithmetic mean is zero,,"Introduction I'm just learning statistics so bare with me. I understand that the variance is $\sigma^2 = \frac{1}{n}\sum\limits_{i=1}^n (x_i-\mu)^2 $ and the standard deviation being the square root of that. Since the variation coefficient is expressed as $\rho = \frac{\sigma}{\mu}$ what do I do in case the average mean $\mu = 0$? When evaluating $\sigma$ all the values are being squared and become positive thus the only way $\sigma$ can be zero is if $x_1=x_2=x_3=...=x_n$ thus the variance is zero and the deviation is zero (because there is no difference between the elements obviously). Situation 1 If I have a set of numbers {0, 0, 0, 0} $\mu = 0$, $\sigma = 0$ thus $\rho = \frac{0}{0}$. What do I say my variation coefficient is as this isn't defined? Straight forward guess is saying that its zero but I cant do that? Situation 2 If I have the set {-1, 0, 1} $\sigma = 1$ and $\mu = 0$ thus $\rho = \frac{1}{0}$ Is this any different from Situation 1 ? What do I do in these cases?","Introduction I'm just learning statistics so bare with me. I understand that the variance is $\sigma^2 = \frac{1}{n}\sum\limits_{i=1}^n (x_i-\mu)^2 $ and the standard deviation being the square root of that. Since the variation coefficient is expressed as $\rho = \frac{\sigma}{\mu}$ what do I do in case the average mean $\mu = 0$? When evaluating $\sigma$ all the values are being squared and become positive thus the only way $\sigma$ can be zero is if $x_1=x_2=x_3=...=x_n$ thus the variance is zero and the deviation is zero (because there is no difference between the elements obviously). Situation 1 If I have a set of numbers {0, 0, 0, 0} $\mu = 0$, $\sigma = 0$ thus $\rho = \frac{0}{0}$. What do I say my variation coefficient is as this isn't defined? Straight forward guess is saying that its zero but I cant do that? Situation 2 If I have the set {-1, 0, 1} $\sigma = 1$ and $\mu = 0$ thus $\rho = \frac{1}{0}$ Is this any different from Situation 1 ? What do I do in these cases?",,"['statistics', 'standard-deviation']"
10,Why this statistical equation is true?,Why this statistical equation is true?,,"Pardon my ignorance. I also don't know how to properly show the equation. So I attached URL of latex... Why this equation is true for any real number $k$, when $\overline{X}$ is average of individual Xs. $$\sum_{i=1}^{n}(X_i-k)^2 = \sum_{i=1}^{n}(X_i-\overline{X})^2 + n(k-\overline{X})^2$$ The above equation will have minimum vale when $k=\overline{X}$. What's meaning of that, statistically?","Pardon my ignorance. I also don't know how to properly show the equation. So I attached URL of latex... Why this equation is true for any real number $k$, when $\overline{X}$ is average of individual Xs. $$\sum_{i=1}^{n}(X_i-k)^2 = \sum_{i=1}^{n}(X_i-\overline{X})^2 + n(k-\overline{X})^2$$ The above equation will have minimum vale when $k=\overline{X}$. What's meaning of that, statistically?",,"['statistics', 'average']"
11,Statistical Testing of a Biased Coin,Statistical Testing of a Biased Coin,,"Somebody comes up to you and says that the quarter he has in his hand is unfair. How do we know if he's telling the truth? First of all, what are the possible hypotheses? The coin could be completely fixed ($p = 1$) and only land on heads (maybe both sides are the same). The coin could be completely fair ($p = 0.5$) and land on both heads and tails with equal frequency. Or the coin could be between these two extremes ($p \in (0.5, 1)$) and have a varying degree of bias. So we design an experiment. Let $C$ be the random variable representing the number of times the coin lands on the most frequent side (wlog). $C \sim Binomial(n, p)$. We flip the suspected coin $n$ times and observe that it comes up heads $k$ times. What is $P[p = x | C = k]$? We know that by Bayes theorem that $P[p = x | C = k] = \frac{P[C = k | p = x] P[p = x]}{P[C = k]}$ However, here is the problem: $p$ needs to be assigned a continuous probability distribution over the support of $(0.5, 1)$, but that entails that $P[p = x] = 0$ for any value of $x$. How do I overcome this?","Somebody comes up to you and says that the quarter he has in his hand is unfair. How do we know if he's telling the truth? First of all, what are the possible hypotheses? The coin could be completely fixed ($p = 1$) and only land on heads (maybe both sides are the same). The coin could be completely fair ($p = 0.5$) and land on both heads and tails with equal frequency. Or the coin could be between these two extremes ($p \in (0.5, 1)$) and have a varying degree of bias. So we design an experiment. Let $C$ be the random variable representing the number of times the coin lands on the most frequent side (wlog). $C \sim Binomial(n, p)$. We flip the suspected coin $n$ times and observe that it comes up heads $k$ times. What is $P[p = x | C = k]$? We know that by Bayes theorem that $P[p = x | C = k] = \frac{P[C = k | p = x] P[p = x]}{P[C = k]}$ However, here is the problem: $p$ needs to be assigned a continuous probability distribution over the support of $(0.5, 1)$, but that entails that $P[p = x] = 0$ for any value of $x$. How do I overcome this?",,"['statistics', 'hypothesis-testing']"
12,Show the Statistic is Complete,Show the Statistic is Complete,,"Consider a random sample $Y_1,\ldots,Y_n$ of the Uniform Distribution on the Interval $[-\phi,\phi]$ I'm wondering how I can show that the Statistic $$ T(\mathbf{Y}) = ( Y_{(1)} , Y_{(n)}) $$ is a Complete Statistic. Thoughts so far : the pdf of $T$ can be represented as $$ f(x,y) = n(n-1) \left(\frac{y-x}{2 \phi} \right)^{n-2} \frac{1}{4 \phi^2}  \; \; \; \; - \phi < x < y < \phi $$ The expectation of any measurable function  of $T$ can be represented as $$E[g(T)] = \int_{- \phi}^{\phi} \int_{x}^{\phi} g(x,y) f(x,y) \,dy\,dx $$ Setting this equal to $0$ however does not really let me continue very far. I cant deduce completeness I can only guess that  I'm on the wrong track but I dont know how else to attempt this.","Consider a random sample $Y_1,\ldots,Y_n$ of the Uniform Distribution on the Interval $[-\phi,\phi]$ I'm wondering how I can show that the Statistic $$ T(\mathbf{Y}) = ( Y_{(1)} , Y_{(n)}) $$ is a Complete Statistic. Thoughts so far : the pdf of $T$ can be represented as $$ f(x,y) = n(n-1) \left(\frac{y-x}{2 \phi} \right)^{n-2} \frac{1}{4 \phi^2}  \; \; \; \; - \phi < x < y < \phi $$ The expectation of any measurable function  of $T$ can be represented as $$E[g(T)] = \int_{- \phi}^{\phi} \int_{x}^{\phi} g(x,y) f(x,y) \,dy\,dx $$ Setting this equal to $0$ however does not really let me continue very far. I cant deduce completeness I can only guess that  I'm on the wrong track but I dont know how else to attempt this.",,['statistics']
13,Why is autocorrelation used without normalization in signal processing field?,Why is autocorrelation used without normalization in signal processing field?,,"According to Wikipedia , autocorrelation has two definitions. Oh my god! In statistics, the autocorrelation between times $s$ and $t$ is defined as: $$\displaystyle R(s,t) = \frac{\mathbb{E}[(X_t-\mu_t)(X_s-\mu_s)]}{\sigma_t\sigma_s}$$ However, in signal processing, the above definition is often used without normalization. According to digital communication written by Bernard Sklar, $$R_x(\tau)=\int_{-\infty}^{\infty}x(t)x(t+\tau)du$$ $$R_X(\tau)=\mathbb{E}\{X(t)X(t+\tau)\}$$ Where \begin{array}{a} \tau & \mbox{ is the difference between } t \mbox{ and }s.\\ x(t) & \mbox{ is real-valued energy signal.}\\ X(t) & \mbox{ is a random process. }\end{array}","According to Wikipedia , autocorrelation has two definitions. Oh my god! In statistics, the autocorrelation between times and is defined as: However, in signal processing, the above definition is often used without normalization. According to digital communication written by Bernard Sklar, Where","s t \displaystyle R(s,t) = \frac{\mathbb{E}[(X_t-\mu_t)(X_s-\mu_s)]}{\sigma_t\sigma_s} R_x(\tau)=\int_{-\infty}^{\infty}x(t)x(t+\tau)du R_X(\tau)=\mathbb{E}\{X(t)X(t+\tau)\} \begin{array}{a}
\tau & \mbox{ is the difference between } t \mbox{ and }s.\\
x(t) & \mbox{ is real-valued energy signal.}\\
X(t) & \mbox{ is a random process. }\end{array}","['statistics', 'signal-processing', 'correlation']"
14,Mixing process in statistics vs. mixing in classical ergodic theory texts,Mixing process in statistics vs. mixing in classical ergodic theory texts,,"In dynamical systems a transformation $T$ is strongly mixing if $\lim_{n\rightarrow \infty} P(A \cap T^{-n} B) = P(A)P(B)$ (e.g., Patrick Billingsley's Ergodic Theory and Information) For stochastic processes, mixing is usually defined differently through mixing coefficients, e.g. $\alpha$-mixing: https://en.wikipedia.org/wiki/Mixing_(mathematics)#Mixing_in_stochastic_processes Since a stochastic process can also be modeled as a dynamical system (as opposed to a sequence of random variables), I'm wondering how the notion of mixing in dynamical systems is related to that in statistics. In particular, is $\alpha$-mixing coefficient simply the rate at which $|P(A \cap T^{-n} B)- P(A)P(B)|$ converges to zero?","In dynamical systems a transformation $T$ is strongly mixing if $\lim_{n\rightarrow \infty} P(A \cap T^{-n} B) = P(A)P(B)$ (e.g., Patrick Billingsley's Ergodic Theory and Information) For stochastic processes, mixing is usually defined differently through mixing coefficients, e.g. $\alpha$-mixing: https://en.wikipedia.org/wiki/Mixing_(mathematics)#Mixing_in_stochastic_processes Since a stochastic process can also be modeled as a dynamical system (as opposed to a sequence of random variables), I'm wondering how the notion of mixing in dynamical systems is related to that in statistics. In particular, is $\alpha$-mixing coefficient simply the rate at which $|P(A \cap T^{-n} B)- P(A)P(B)|$ converges to zero?",,"['statistics', 'stochastic-processes', 'dynamical-systems', 'mixing']"
15,Approximating one random variable by a function of other random variables,Approximating one random variable by a function of other random variables,,"Suppose $(X,Y)$ is a continuous bivariate random variable and we want to approximate $Y$ by a function of $X$ ,that means we seek a function say $h(x)$ whose outcomes are the minimum expected squared distance from the outcome of $Y$ , in other words we want to minimize $$\mathbb{E}[(Y-h(X))^2] = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(y-h(x))^2 f(x,y)dxdy$$ My question is ,how can we mathematically prove that the optimal choice of approximating function is the regression function i.e $h(x)= E(Y|x)$ ?","Suppose $(X,Y)$ is a continuous bivariate random variable and we want to approximate $Y$ by a function of $X$ ,that means we seek a function say $h(x)$ whose outcomes are the minimum expected squared distance from the outcome of $Y$ , in other words we want to minimize $$\mathbb{E}[(Y-h(X))^2] = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(y-h(x))^2 f(x,y)dxdy$$ My question is ,how can we mathematically prove that the optimal choice of approximating function is the regression function i.e $h(x)= E(Y|x)$ ?",,"['statistics', 'expectation', 'conditional-expectation']"
16,Standard deviation without square,Standard deviation without square,,"For $(x_i)_{1 \leq i \leq N}$ , the standard deviation is of course $$\sigma = \sqrt{\frac{1}{N} \sum_i (x_i - m)^2},$$ where $m$ is the mean value of the $(x_i)$ . We can say that the variance $\sigma^2$ is the average of the squared distance between each sample and the mean. I know why the fact of having this square is helpful (for many formulas), and that $\sigma$ is much more used than : $$\alpha =\frac{1}{N} \sum_i |x_i - m|,$$ that could seem a natural measure of the average distance between each sample and the mean. Question: Even if $\alpha$ is rarely used, is there a single-word name for $\alpha$ ?","For , the standard deviation is of course where is the mean value of the . We can say that the variance is the average of the squared distance between each sample and the mean. I know why the fact of having this square is helpful (for many formulas), and that is much more used than : that could seem a natural measure of the average distance between each sample and the mean. Question: Even if is rarely used, is there a single-word name for ?","(x_i)_{1 \leq i \leq N} \sigma = \sqrt{\frac{1}{N} \sum_i (x_i - m)^2}, m (x_i) \sigma^2 \sigma \alpha =\frac{1}{N} \sum_i |x_i - m|, \alpha \alpha","['statistics', 'terminology', 'standard-deviation', 'means']"
17,"3 Urns, dimes and pennies. If two of the three coins are dimes. What is the probability that the coin selected from urn I was a dime?","3 Urns, dimes and pennies. If two of the three coins are dimes. What is the probability that the coin selected from urn I was a dime?",,"Problem said: Urns I, II and III contain three pennies and four dimes, two pennies   and five dimes and three pennies and one dime, respectively. One coin   is selected at random from each urn. (a) What is the probability that all three selected coins have the   same denomination? P(a:same denomination)=(3/7) (2/7) (3/7)+(4/7) (5/7) (1/4)= 19/98 (b) If two of the three coins are dimes, what is the probability that the coin selected from urn I was a dime? My concern: I have no clue where I am suppose to start to solve this exercise, any help will be apprecited. Thanks!","Problem said: Urns I, II and III contain three pennies and four dimes, two pennies   and five dimes and three pennies and one dime, respectively. One coin   is selected at random from each urn. (a) What is the probability that all three selected coins have the   same denomination? P(a:same denomination)=(3/7) (2/7) (3/7)+(4/7) (5/7) (1/4)= 19/98 (b) If two of the three coins are dimes, what is the probability that the coin selected from urn I was a dime? My concern: I have no clue where I am suppose to start to solve this exercise, any help will be apprecited. Thanks!",,"['probability', 'statistics', 'probability-distributions']"
18,What is the rule of $1.96$ for estimating confidence intervals?,What is the rule of  for estimating confidence intervals?,1.96,"I have a sequence of A/B currency exchanges for some days. With that data I can calculate the daily returns, and that's what I did. I need to calculate the confidence interval for the expected daily returns of the A/B currency exchange by using the $1.96$ rule. What is this $1.96$ rule? Why exactly that number? Why is it related to compute confidence intervals? So, how can we use it in general to compute confidence intervals? There's an article on Wikipedia, but honestly I am not understanding it, and why it is related to the calculation of the confidence interval of the expectation. Note that for now I am not asking specifically about how to solve my problem, but how what I am asking about is related to my problem (after answering those questions).","I have a sequence of A/B currency exchanges for some days. With that data I can calculate the daily returns, and that's what I did. I need to calculate the confidence interval for the expected daily returns of the A/B currency exchange by using the $1.96$ rule. What is this $1.96$ rule? Why exactly that number? Why is it related to compute confidence intervals? So, how can we use it in general to compute confidence intervals? There's an article on Wikipedia, but honestly I am not understanding it, and why it is related to the calculation of the confidence interval of the expectation. Note that for now I am not asking specifically about how to solve my problem, but how what I am asking about is related to my problem (after answering those questions).",,['statistics']
19,An alternative measure of scatter.,An alternative measure of scatter.,,"The context: Let $X$ be a random variable. A familiar measure for its scatter is variance $$\text{Var}(X)=\mathbb{E} \left( \left( X- \mathbb{E}(X) \right)^2 \right),$$ which has several nice properties. A less common alterative is the ""$L_1$-version"" of variance $$\text{MAD}(X)=\mathbb{E} \left( \, \left| X- \mathbb{E}(X) \right| \, \right)$$ that is a lot more difficult to deal with theoretically. However, sometimes when considering samples of observations following a heavy-tailed distribution, this quantity is more useful for applications since it is more robust against extreme values. The question: Let $X$ and $Y$ be i.i.d. Clearly $$\text{Var}(X+Y) = \text{Var}(X)+ \text{Var}(Y) \geq \text{Var}(X).$$ Do we have a similar inequality for MAD? I.e. is it true that $$\text{MAD}(X+Y) \geq \text{MAD}(X)?$$ Intuitively, yes, but I'm not sure what to do. Tried Google, but no luck.","The context: Let $X$ be a random variable. A familiar measure for its scatter is variance $$\text{Var}(X)=\mathbb{E} \left( \left( X- \mathbb{E}(X) \right)^2 \right),$$ which has several nice properties. A less common alterative is the ""$L_1$-version"" of variance $$\text{MAD}(X)=\mathbb{E} \left( \, \left| X- \mathbb{E}(X) \right| \, \right)$$ that is a lot more difficult to deal with theoretically. However, sometimes when considering samples of observations following a heavy-tailed distribution, this quantity is more useful for applications since it is more robust against extreme values. The question: Let $X$ and $Y$ be i.i.d. Clearly $$\text{Var}(X+Y) = \text{Var}(X)+ \text{Var}(Y) \geq \text{Var}(X).$$ Do we have a similar inequality for MAD? I.e. is it true that $$\text{MAD}(X+Y) \geq \text{MAD}(X)?$$ Intuitively, yes, but I'm not sure what to do. Tried Google, but no luck.",,"['probability', 'statistics']"
20,How many tickets should I buy to win a prize in lottery? [closed],How many tickets should I buy to win a prize in lottery? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Each ticket in a lottery contain a single ""hidden"" number according to the following scheme: 55% of the tickets contain a 1, 35% contain a 2, and 10% contain a 3. A participant in the lottery wins a prize by obtaining all three numbers 1,2 and 3. Can you please help me to describe an experiment that could be used to determine how many tickets you would expect to buy to win a prize? Thank you!!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Each ticket in a lottery contain a single ""hidden"" number according to the following scheme: 55% of the tickets contain a 1, 35% contain a 2, and 10% contain a 3. A participant in the lottery wins a prize by obtaining all three numbers 1,2 and 3. Can you please help me to describe an experiment that could be used to determine how many tickets you would expect to buy to win a prize? Thank you!!",,"['probability', 'statistics']"
21,"$2^\text{nd}$ Derivative of normal distribution, evaluated at one standard deviation","Derivative of normal distribution, evaluated at one standard deviation",2^\text{nd},"What is the $2^{nd}$ derivative of the normal distribution at one standard deviation? The normal distribution is given by $N(x,\mu ,\sigma)=\frac{1}{\sigma\sqrt{2\pi }}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$. To make this problem easier, lets say I have a standard normal distribution($\mu =0,\sigma =1$). So $N\left(x,0,1\right)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$. $$\frac{d}{dx}N(x,0,1)=\frac{d}{dx}\left(\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}\right)$$ $$\frac{d}{dx}N\left(x,0,1\right)=\frac{1}{\:\sqrt{2\pi}}\frac{d}{dx}\left(e^{-\frac{x^2}{2}}\right)$$ $$\frac{d}{dx}N\left(x,0,1\right)=\frac{1}{\:\sqrt{2\pi}}e^{-\frac{\left(x\:\right)^2}{2}\cdot \frac{d}{dx}\left(-\frac{x^2}{2}\right)}$$ $$\frac{d}{dx}N\left(x,0,1\right)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot -x}$$ So, $$\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot\:-x}$$ is the first derivative. To get the second, I took the derivative of the first. $$\frac{d}{dx}\left(\frac{d}{dx}N\left(x,0,1\right)\right)=\frac{d}{dx}\left(\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot \:-x}\right)$$ $$\frac{d}{dx}\left(\frac{d}{dx}N\left(x,0,1\right)\right)=\frac{1}{\:\sqrt{2\pi }}\frac{d}{dx}\left(e^{-\frac{x^2}{2}\cdot\:-x}\right)$$ $$\frac{d}{dx}\left(\frac{d}{dx}N(x,0,1)\right)=\frac{1}{\:\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot\:-x}\cdot \frac{d}{dx\:}\left(-\frac{x^2}{2}\cdot \:-x\right)$$ $$\frac{d}{dx}\left(\frac{d}{dx}N\left(x,0,1\right)\right)=\frac{1}{\sqrt{2\pi}}\left(e^{-\frac{(x^2}{2}\cdot \:-x}\right)\cdot \left(3\frac{x^2}{2}\right)$$ So now I evaluate $$\frac{1}{\sqrt{2\pi}}\left(e^{-\frac{x^2}{2}\cdot -x}\right)\cdot \left(3\cdot \frac{x^2}{2}\right),$$ at the standard deviation which I set to $\sigma =1$ So, $$\frac{1}{\sqrt{2\cdot :\pi}}\left(e^{-\frac{1^2}{2}\cdot -1}\right)\cdot \left(3\cdot\frac{1^2}{2}\right)$$ $$\frac{1}{\sqrt{2\pi}}\left(e^{-\frac{(1)^2}{2}\cdot\,-1}\right)\cdot \left(3\cdot \frac{1^2}{2}\right)=\frac{3\sqrt{e}}{2\sqrt{2\cdot\pi}}$$ But my teacher says the answer is suppose to be $0$? What am I doing wrong? Side Note: I am new to Calculus. So an elaborate explanation will be appreciated.","What is the $2^{nd}$ derivative of the normal distribution at one standard deviation? The normal distribution is given by $N(x,\mu ,\sigma)=\frac{1}{\sigma\sqrt{2\pi }}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$. To make this problem easier, lets say I have a standard normal distribution($\mu =0,\sigma =1$). So $N\left(x,0,1\right)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$. $$\frac{d}{dx}N(x,0,1)=\frac{d}{dx}\left(\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}\right)$$ $$\frac{d}{dx}N\left(x,0,1\right)=\frac{1}{\:\sqrt{2\pi}}\frac{d}{dx}\left(e^{-\frac{x^2}{2}}\right)$$ $$\frac{d}{dx}N\left(x,0,1\right)=\frac{1}{\:\sqrt{2\pi}}e^{-\frac{\left(x\:\right)^2}{2}\cdot \frac{d}{dx}\left(-\frac{x^2}{2}\right)}$$ $$\frac{d}{dx}N\left(x,0,1\right)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot -x}$$ So, $$\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot\:-x}$$ is the first derivative. To get the second, I took the derivative of the first. $$\frac{d}{dx}\left(\frac{d}{dx}N\left(x,0,1\right)\right)=\frac{d}{dx}\left(\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot \:-x}\right)$$ $$\frac{d}{dx}\left(\frac{d}{dx}N\left(x,0,1\right)\right)=\frac{1}{\:\sqrt{2\pi }}\frac{d}{dx}\left(e^{-\frac{x^2}{2}\cdot\:-x}\right)$$ $$\frac{d}{dx}\left(\frac{d}{dx}N(x,0,1)\right)=\frac{1}{\:\sqrt{2\pi}}e^{-\frac{x^2}{2}\cdot\:-x}\cdot \frac{d}{dx\:}\left(-\frac{x^2}{2}\cdot \:-x\right)$$ $$\frac{d}{dx}\left(\frac{d}{dx}N\left(x,0,1\right)\right)=\frac{1}{\sqrt{2\pi}}\left(e^{-\frac{(x^2}{2}\cdot \:-x}\right)\cdot \left(3\frac{x^2}{2}\right)$$ So now I evaluate $$\frac{1}{\sqrt{2\pi}}\left(e^{-\frac{x^2}{2}\cdot -x}\right)\cdot \left(3\cdot \frac{x^2}{2}\right),$$ at the standard deviation which I set to $\sigma =1$ So, $$\frac{1}{\sqrt{2\cdot :\pi}}\left(e^{-\frac{1^2}{2}\cdot -1}\right)\cdot \left(3\cdot\frac{1^2}{2}\right)$$ $$\frac{1}{\sqrt{2\pi}}\left(e^{-\frac{(1)^2}{2}\cdot\,-1}\right)\cdot \left(3\cdot \frac{1^2}{2}\right)=\frac{3\sqrt{e}}{2\sqrt{2\cdot\pi}}$$ But my teacher says the answer is suppose to be $0$? What am I doing wrong? Side Note: I am new to Calculus. So an elaborate explanation will be appreciated.",,"['calculus', 'statistics', 'derivatives', 'normal-distribution']"
22,Fixed Effects Estimation,Fixed Effects Estimation,,"Consider the following panel data regression model: $$y_{it}=X_{it}\beta+\alpha_{i}+u_{it},$$ where $\alpha_{i}$ indicate the nuisance parameters (indiviudal specific), $y_{it}$ is an $nt\times1$ vector of the dependent variable, $i$ represents individual $i$ , $t$ represents the time period, $X_{it}$ is an $nt\times k$ matrix of the regressors, $\beta$ is a $k\times1$ vector of coefficients that need to be estimated and $u_{it}$ is an $nt\times1$ vector of the error terms assumed to be orthogonal to the regressors, conditional on $\alpha_{i}$. When we estimate this panel data model by fixed effects, we include a dummy variable for every individual, effectively removing the nuisance paramter. This is equivalent to demeaning the data and estimating $(y_{it}-\bar{y_{i})}=(X_{it}-\bar{X_{i}})\beta+(u_{it}-\bar{u})$. In a sense, we are 'controlling' for time invariant individual unboservables in order to get unbiased estimates of our parameters of interest. Intuitively, I was wondering if the parameter estimates we obtain are equivalent to estimating the coefficients separetely for each individual and then averaging over all individuals?","Consider the following panel data regression model: $$y_{it}=X_{it}\beta+\alpha_{i}+u_{it},$$ where $\alpha_{i}$ indicate the nuisance parameters (indiviudal specific), $y_{it}$ is an $nt\times1$ vector of the dependent variable, $i$ represents individual $i$ , $t$ represents the time period, $X_{it}$ is an $nt\times k$ matrix of the regressors, $\beta$ is a $k\times1$ vector of coefficients that need to be estimated and $u_{it}$ is an $nt\times1$ vector of the error terms assumed to be orthogonal to the regressors, conditional on $\alpha_{i}$. When we estimate this panel data model by fixed effects, we include a dummy variable for every individual, effectively removing the nuisance paramter. This is equivalent to demeaning the data and estimating $(y_{it}-\bar{y_{i})}=(X_{it}-\bar{X_{i}})\beta+(u_{it}-\bar{u})$. In a sense, we are 'controlling' for time invariant individual unboservables in order to get unbiased estimates of our parameters of interest. Intuitively, I was wondering if the parameter estimates we obtain are equivalent to estimating the coefficients separetely for each individual and then averaging over all individuals?",,"['statistics', 'statistical-inference']"
23,Statistics dice question,Statistics dice question,,"$6$ people, $A, B, C, D, E, F$ sit in a circle to play a dice game. Rule of game : as you roll a die and get a number which is a multiple of $3$ , give the die to the person on the right(counterclockwise). If the number is not a multiple of $3$ , give it to the person on the left. What is the probability that $B$ has the die after five trials starting from $A$ ? My approach: The probability that the die would go right is $\frac 13$ and left is $\frac 23$ . Am I supposed to find all the possible outcomes and add the probabilities? For example, it could go $A-B-C-D-C-B$ . So $\frac 13\times \frac 13 \times \frac 13 \times \frac 23 \times \frac 23$ . Do I find all the paths that it could take and add all these probabilities? Or is there another way to solve this??","people, sit in a circle to play a dice game. Rule of game : as you roll a die and get a number which is a multiple of , give the die to the person on the right(counterclockwise). If the number is not a multiple of , give it to the person on the left. What is the probability that has the die after five trials starting from ? My approach: The probability that the die would go right is and left is . Am I supposed to find all the possible outcomes and add the probabilities? For example, it could go . So . Do I find all the paths that it could take and add all these probabilities? Or is there another way to solve this??","6 A, B, C, D, E, F 3 3 B A \frac 13 \frac 23 A-B-C-D-C-B \frac 13\times \frac 13 \times \frac 13 \times \frac 23 \times \frac 23","['probability', 'statistics', 'dice']"
24,Three-phased probability,Three-phased probability,,"In a TV show, you must pass 3 phases to make it to the live show. From the first phase, $80$% of the people go home, the rest can continue to the second phase. From the second phase, $70$% of the people go home, those who made it this far, have to get throught the third pase, there, only $25$% of the people succeed. There are $3$ several tasks, I wrote my ideas in each of them: 1, How many percent of the people can make it live? My idea: Let us have $X$ people in the beginning. After the first phase, only $\frac2{10}X$ people are still in. After the second phase, only $\frac3{10}*\frac2{10}X$ people are still in, and after the last phase, only $\frac14 * \frac3{10} * \frac2{10} X$ people are in, which is $\frac{3}{200}X$($1,5$% of the original) 2, There is one person, and we only know, that he made throught the first phase. What is the probability, that we will see him live? My idea: Since he made through the first phase, now he only need to make through the rest, which is $\frac{3}{10} * \frac{1}{4} = \frac{3}{40}$. 3, Examine the people, who didn't make it live. How many of them went home after the first, second and third phase? If we have $X$ people, $\frac{8}{10}X$ went home after the first phase, $\frac{2}{10}*\frac{7}{10}X$ went home after the second phase, and $\frac{2}{10}*\frac{3}{10}*\frac{3}{4}X$ went home after the last phase. Sorry for the long task, but I am quite new to this subject. Are my approaches correct? Thanks for any help!","In a TV show, you must pass 3 phases to make it to the live show. From the first phase, $80$% of the people go home, the rest can continue to the second phase. From the second phase, $70$% of the people go home, those who made it this far, have to get throught the third pase, there, only $25$% of the people succeed. There are $3$ several tasks, I wrote my ideas in each of them: 1, How many percent of the people can make it live? My idea: Let us have $X$ people in the beginning. After the first phase, only $\frac2{10}X$ people are still in. After the second phase, only $\frac3{10}*\frac2{10}X$ people are still in, and after the last phase, only $\frac14 * \frac3{10} * \frac2{10} X$ people are in, which is $\frac{3}{200}X$($1,5$% of the original) 2, There is one person, and we only know, that he made throught the first phase. What is the probability, that we will see him live? My idea: Since he made through the first phase, now he only need to make through the rest, which is $\frac{3}{10} * \frac{1}{4} = \frac{3}{40}$. 3, Examine the people, who didn't make it live. How many of them went home after the first, second and third phase? If we have $X$ people, $\frac{8}{10}X$ went home after the first phase, $\frac{2}{10}*\frac{7}{10}X$ went home after the second phase, and $\frac{2}{10}*\frac{3}{10}*\frac{3}{4}X$ went home after the last phase. Sorry for the long task, but I am quite new to this subject. Are my approaches correct? Thanks for any help!",,"['probability', 'statistics']"
25,Why are there different methods to finding quartiles?,Why are there different methods to finding quartiles?,,"On different programs and types of technologies there are different algorithms used to find quartiles. Ti 83 Plus will spit out an answer different from Excel or minitab etc. Why are there so many different methods? Why is it okay to have different answers for quartiles from different programs? I am getting different answers from each method and I am unsure of which one should be correct, if any are.","On different programs and types of technologies there are different algorithms used to find quartiles. Ti 83 Plus will spit out an answer different from Excel or minitab etc. Why are there so many different methods? Why is it okay to have different answers for quartiles from different programs? I am getting different answers from each method and I am unsure of which one should be correct, if any are.",,"['statistics', 'algorithms', 'computer-science', 'calculator']"
26,What is the chance of a sample in white noise to be a local extremum?,What is the chance of a sample in white noise to be a local extremum?,,"I draw a long sequence of values from a uniform or normal distribution. Observing the resulting sequence, what is the chance of any point in the sequence (aside from the first and last where it is not defined) to be a local extremum? I.e. either a local maximum (the point is larger than both its neighbors) or a local minimum (the point is smaller than both its neighbors). At first glance, you would think that once you've drawn the 1st point,  the expectancy of the 2nd to be smaller\bigger than the 1st is 50% and then the 3rd is bigger\smaller in 50% hence 0.5*0.5 + 0.5*0.5 = 0.5 chance. However there is additional information in the 2nd point being larger than the 1st and hence a bigger (than 50%) chance that the 3rd point is also smaller than the 2nd. A matlab code which calculates these chances result a chance of 2/3 (0.66%) : sum(diff(sign(diff(normrnd(0,1,1,10000))))~=0)/10000 % Normal distribution sum(diff(sign(diff(rand(1,10000))))~=0)/10000 % Uniform distribution Iv'e tried to apply a combinatoric reasoning to explain this result : As being extremum is defined by 3 points only, let's narrow the problem to observe only 3 points. There are 6 possible orderings to 3 points, in 4 of which the second point is a local extremum, hence the 2/3 chance. Is this a correct reasoning? Are there other better ways to approach the problem (Integrating the probability density function)?","I draw a long sequence of values from a uniform or normal distribution. Observing the resulting sequence, what is the chance of any point in the sequence (aside from the first and last where it is not defined) to be a local extremum? I.e. either a local maximum (the point is larger than both its neighbors) or a local minimum (the point is smaller than both its neighbors). At first glance, you would think that once you've drawn the 1st point,  the expectancy of the 2nd to be smaller\bigger than the 1st is 50% and then the 3rd is bigger\smaller in 50% hence 0.5*0.5 + 0.5*0.5 = 0.5 chance. However there is additional information in the 2nd point being larger than the 1st and hence a bigger (than 50%) chance that the 3rd point is also smaller than the 2nd. A matlab code which calculates these chances result a chance of 2/3 (0.66%) : sum(diff(sign(diff(normrnd(0,1,1,10000))))~=0)/10000 % Normal distribution sum(diff(sign(diff(rand(1,10000))))~=0)/10000 % Uniform distribution Iv'e tried to apply a combinatoric reasoning to explain this result : As being extremum is defined by 3 points only, let's narrow the problem to observe only 3 points. There are 6 possible orderings to 3 points, in 4 of which the second point is a local extremum, hence the 2/3 chance. Is this a correct reasoning? Are there other better ways to approach the problem (Integrating the probability density function)?",,"['combinatorics', 'statistics', 'matlab', 'data-analysis', 'order-statistics']"
27,Proof of multivariate regression plane maximizes correlation in normals,Proof of multivariate regression plane maximizes correlation in normals,,"I am doing a homework sheet as practice for an upcoming course in multivariate statistics and been stuck on the following problem: Let $(Y,X_1,X_2,\ldots,X_p)^T\stackrel{d}{=}\mathcal{N}_{p+1}(0,\mathbf{C})$. Prove that $\mathbb{E}(Y|X_1,X_2,\ldots,X_p)$ maximizes Corr($Y,f(X_1,X_2,\ldots,X_p)$) in the space of $f$ linear functions. My attempt so far: Proof of the conditional expectation being linear and calculating its value: We omit the linearly dependent cases due to their triviality. First as a starting point, we prove that the regression is minimized by a linear combination of the $X_i$s, and calculate the coefficients of this.  Partition $\mathbf{C}$ and use the well-known identity for block matrices, using $Var Y:=\sigma^2$, $Var X_i=\sigma_i^2=c_{ii}$, $Cov(X_i,Y)=c_i$ and $Cov(X_i,X_j)=c_{ij}$: \begin{equation} \mathbf{C}=\begin{pmatrix} \sigma^2&\mathbf{c}^T\\ \mathbf{c}&\mathbf{D}\\ \end{pmatrix}\qquad  \mathbf{C}^{-1}=\begin{pmatrix} \sigma^2&\mathbf{c}^T\\ \mathbf{c}&\mathbf{D}\\ \end{pmatrix}^{-1}= \begin{pmatrix} (\sigma^2-\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c})^{-1}& -\sigma^{-2}\mathbf{c}^T(\mathbf{D}-\mathbf{c}^T\mathbf{c})^{-1}\\ -\sigma^{-2}(\mathbf{D}-\mathbf{c}^T\mathbf{c})^{-1}\mathbf{c}& (\mathbf{D}-\mathbf{c}^T\mathbf{c})^{-1}\\ \end{pmatrix}=:\begin{pmatrix} \alpha^2&\beta^T\\ \beta&\delta\\ \end{pmatrix} \end{equation} With extra assumption $\det\mathbf{C}\det\mathbf{D}\neq 0$. Also note that $Var(\mathbf{a}^T\mathbf{X})=\mathbf{a}^T\mathbf{D}\mathbf{a}$.  Thus their joint density function is: \begin{equation} f(y,\mathbf{x})=\frac{1}{\sqrt{(2\pi)^{p+1}\det\mathbf{C} }}\exp\left(-\frac{1}{2}\left((y,\mathbf{x})^T\mathbf{C}^{-1}(y,\mathbf{x})\right)\right)=\frac{1}{\sqrt{(2\pi)^{p+1}\det\mathbf{C} }}\exp\left(-\frac{\alpha^2y^2+2\beta^T\mathbf{x}y+\mathbf{x}^T\delta\mathbf{x}}{2}\right)= \end{equation} \begin{equation} =\frac{1}{\sqrt{(2\pi)^{p+1}\det\mathbf{C} }}\exp\left(-\frac{1}{2}\left(\alpha y-\frac{\mathbf{x}^T\beta}{\alpha}\right)^2-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right) \end{equation} We know from the notes that $\mathbb{E}(Y-g(X_1,\ldots,X_p))^2$ is minimized by: \begin{equation} \mathbb{E}(Y|X_1,\ldots, X_p)=\frac{\displaystyle \int_{-\infty}^{\infty}yf(y,\mathbf{x})\,\mathrm{d}{y}}{\displaystyle \int_{-\infty}^{\infty}f(y,\mathbf{x})\,\mathrm{d}{y}}=\frac{\mathbf{x}^T\beta}{\alpha^2}= \boxed{-(\mathbf{x}^T\sigma^{-2}(\mathbf{D}-\mathbf{c}^T\mathbf{c})^{-1}\mathbf{c})(\sigma^2-\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c})} \end{equation} The denominator: \begin{equation} \int_{-\infty}^{\infty}\frac{1}{\sqrt{(2\pi)^{p+1}\det\mathbf{C} }}\exp\left(-\frac{1}{2}\left(\alpha y-\frac{\mathbf{x}^T\beta}{\alpha}\right)^2-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right)\,\mathrm{d}{y}=\frac{1}{\sqrt{(2\pi)^{p}\det\mathbf{C} }\alpha}\exp\left(-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right) \end{equation} The numerator is an expectation of a normal random variable with mean $\displaystyle\frac{\mathbf{x}^T\beta}{\alpha}$: \begin{equation} \int_{-\infty}^{\infty}\frac{y}{\sqrt{(2\pi)^{p+1}\det\mathbf{C}}}\exp\left(-\frac{1}{2}\left(\alpha y-\frac{\mathbf{x}^T\beta}{\alpha}\right)^2-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right)\,\mathrm{d}{y} =\frac{\mathbf{x}^T\beta}{\sqrt{(2\pi)^{p}\det\mathbf{C} }\alpha^3}\exp\left(-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right) \end{equation} which proves it is linear. We have to minimize $\displaystyle \mathbb{E}\left(Y-b-\sum_{i=1}^{p}a_iX_i\right)^2$. This is from the exponential family, thus we can switch the order of integration and differentiation: \begin{equation} \mathbb{E}\left(\frac{\partial}{\partial a_i}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=-2c_i+2\sum_{j=1}^{p}a_ic_{ij}\qquad \mathbb{E}\left(\frac{\partial}{\partial b}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=2b \end{equation} \begin{equation} \mathbb{E}\left(\frac{\partial^2}{\partial a_i^2}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=2c_{ii}\qquad \mathbb{E}\left(\frac{\partial^2}{\partial b^2}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=2 \end{equation} \begin{equation} \mathbb{E}\left(\frac{\partial}{\partial a_i \partial a_j}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=2c_{ij}\qquad \mathbb{E}\left(\frac{\partial}{\partial a_i \partial b}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=0 \end{equation} So the Hessian is positive definite at this point, meaning that the minimum is obtained a when: \begin{equation} \mathbf{D}\mathbf{a}=\mathbf{c}\Rightarrow \boxed{\mathbf{a}=\mathbf{D}^{-1}\mathbf{c}\qquad b=0} \end{equation} And that it is the maximum We want to find the maximum in the direction $\mathbf{v}$, so take $t(X_{i=1}^p,u)=(\mathbf{D}^{-1}\mathbf{c}+u\mathbf{v})^T\mathbf{X}$, then using $\mathbf{D}^T=\mathbf{D}$: \begin{equation} {Corr}(Y,t(X_{i=1}^p,u))=\frac{Cov(Y,(\mathbf{D}^{-1}\mathbf{c}+u\mathbf{v})^T\mathbf{X})}{\sqrt{Var Y Var((\mathbf{D}^{-1}\mathbf{c}+u\mathbf{v})^T\mathbf{X})}}= \frac{(\mathbf{D}^{-1}\mathbf{c}+ u\mathbf{v})^T\mathbf{c}} {\sigma\sqrt{\mathbf{c}^T\mathbf{D}^{-1}\mathbf{D}\mathbf{D}^{-1}\mathbf{c}+2u\mathbf{v}^T\mathbf{D}\mathbf{D}^{-1}\mathbf{c}+u^2\mathbf{v}^T\mathbf{D}\mathbf{v}}}= \end{equation} \begin{equation} =\frac{\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}+ u\mathbf{v}^T\mathbf{c}} {\sqrt{\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}+ 2u\mathbf{v}^T\mathbf{c}+ u^2\mathbf{v}^T\mathbf{D}\mathbf{v}}} \end{equation} \begin{equation} \frac{\partial}{\partial u}{Corr}(Y,t(X_{i=1}^p,u))= \frac{u((\mathbf{c}^T\mathbf{v})^2-\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{v}^T\mathbf{D}\mathbf{v})} {\sigma(\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}+2u\mathbf{v}^T\mathbf{c}+u^2\mathbf{v}^T\mathbf{D}\mathbf{v})^{3/2}} \end{equation} With some straightforward and lengthy calculations, we have: \begin{equation} \left.\frac{\partial^2}{\partial u^2}{Corr}(Y,t(X_{i=1}^p,u))\right|_{u=0}=-\frac{\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{v}^T\mathbf{D}\mathbf{v}-(\mathbf{c}^T\mathbf{v})^2}{(\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c})^{3/2}} \end{equation} So we must have $u=0$ or $(\mathbf{v}^T\mathbf{c})^2-\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{v}^T\mathbf{D}\mathbf{v}=0$, meaning that the correlation is constant in the direction of $\mathbf{v}$. Let $\mathbf{v}=\mathbf{v}_\perp+\lambda\mathbf{c}$, where $\mathbf{v}_\perp$ is orthogonal to $\mathbf{c}$, thus: \begin{equation} \mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{v}^T\mathbf{D}\mathbf{v}-(\mathbf{v}\mathbf{c}^T)^2=\lambda^2\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{c}^T\mathbf{D}\mathbf{c}+\lambda\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{c}^T\mathbf{D}\mathbf{v}_\perp-(\lambda\mathbf{c}^T\mathbf{c})^2 \end{equation} If $\mathbf{Y}$ is independent, then the correlation is $0$. If that's not the case, with scaling we can achieve $\textbf{c}^T\textbf{c}=1$. $\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{c}^T\mathbf{D}\mathbf{c}=(\mathbf{c}^T\mathbf{c})^2$ And there I'm just stuck, any ideas how to continue?","I am doing a homework sheet as practice for an upcoming course in multivariate statistics and been stuck on the following problem: Let $(Y,X_1,X_2,\ldots,X_p)^T\stackrel{d}{=}\mathcal{N}_{p+1}(0,\mathbf{C})$. Prove that $\mathbb{E}(Y|X_1,X_2,\ldots,X_p)$ maximizes Corr($Y,f(X_1,X_2,\ldots,X_p)$) in the space of $f$ linear functions. My attempt so far: Proof of the conditional expectation being linear and calculating its value: We omit the linearly dependent cases due to their triviality. First as a starting point, we prove that the regression is minimized by a linear combination of the $X_i$s, and calculate the coefficients of this.  Partition $\mathbf{C}$ and use the well-known identity for block matrices, using $Var Y:=\sigma^2$, $Var X_i=\sigma_i^2=c_{ii}$, $Cov(X_i,Y)=c_i$ and $Cov(X_i,X_j)=c_{ij}$: \begin{equation} \mathbf{C}=\begin{pmatrix} \sigma^2&\mathbf{c}^T\\ \mathbf{c}&\mathbf{D}\\ \end{pmatrix}\qquad  \mathbf{C}^{-1}=\begin{pmatrix} \sigma^2&\mathbf{c}^T\\ \mathbf{c}&\mathbf{D}\\ \end{pmatrix}^{-1}= \begin{pmatrix} (\sigma^2-\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c})^{-1}& -\sigma^{-2}\mathbf{c}^T(\mathbf{D}-\mathbf{c}^T\mathbf{c})^{-1}\\ -\sigma^{-2}(\mathbf{D}-\mathbf{c}^T\mathbf{c})^{-1}\mathbf{c}& (\mathbf{D}-\mathbf{c}^T\mathbf{c})^{-1}\\ \end{pmatrix}=:\begin{pmatrix} \alpha^2&\beta^T\\ \beta&\delta\\ \end{pmatrix} \end{equation} With extra assumption $\det\mathbf{C}\det\mathbf{D}\neq 0$. Also note that $Var(\mathbf{a}^T\mathbf{X})=\mathbf{a}^T\mathbf{D}\mathbf{a}$.  Thus their joint density function is: \begin{equation} f(y,\mathbf{x})=\frac{1}{\sqrt{(2\pi)^{p+1}\det\mathbf{C} }}\exp\left(-\frac{1}{2}\left((y,\mathbf{x})^T\mathbf{C}^{-1}(y,\mathbf{x})\right)\right)=\frac{1}{\sqrt{(2\pi)^{p+1}\det\mathbf{C} }}\exp\left(-\frac{\alpha^2y^2+2\beta^T\mathbf{x}y+\mathbf{x}^T\delta\mathbf{x}}{2}\right)= \end{equation} \begin{equation} =\frac{1}{\sqrt{(2\pi)^{p+1}\det\mathbf{C} }}\exp\left(-\frac{1}{2}\left(\alpha y-\frac{\mathbf{x}^T\beta}{\alpha}\right)^2-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right) \end{equation} We know from the notes that $\mathbb{E}(Y-g(X_1,\ldots,X_p))^2$ is minimized by: \begin{equation} \mathbb{E}(Y|X_1,\ldots, X_p)=\frac{\displaystyle \int_{-\infty}^{\infty}yf(y,\mathbf{x})\,\mathrm{d}{y}}{\displaystyle \int_{-\infty}^{\infty}f(y,\mathbf{x})\,\mathrm{d}{y}}=\frac{\mathbf{x}^T\beta}{\alpha^2}= \boxed{-(\mathbf{x}^T\sigma^{-2}(\mathbf{D}-\mathbf{c}^T\mathbf{c})^{-1}\mathbf{c})(\sigma^2-\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c})} \end{equation} The denominator: \begin{equation} \int_{-\infty}^{\infty}\frac{1}{\sqrt{(2\pi)^{p+1}\det\mathbf{C} }}\exp\left(-\frac{1}{2}\left(\alpha y-\frac{\mathbf{x}^T\beta}{\alpha}\right)^2-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right)\,\mathrm{d}{y}=\frac{1}{\sqrt{(2\pi)^{p}\det\mathbf{C} }\alpha}\exp\left(-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right) \end{equation} The numerator is an expectation of a normal random variable with mean $\displaystyle\frac{\mathbf{x}^T\beta}{\alpha}$: \begin{equation} \int_{-\infty}^{\infty}\frac{y}{\sqrt{(2\pi)^{p+1}\det\mathbf{C}}}\exp\left(-\frac{1}{2}\left(\alpha y-\frac{\mathbf{x}^T\beta}{\alpha}\right)^2-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right)\,\mathrm{d}{y} =\frac{\mathbf{x}^T\beta}{\sqrt{(2\pi)^{p}\det\mathbf{C} }\alpha^3}\exp\left(-\frac{\mathbf{x}^T\delta\mathbf{x}}{2}+\frac{(\mathbf{x}^T\beta)^2}{2\alpha^2}\right) \end{equation} which proves it is linear. We have to minimize $\displaystyle \mathbb{E}\left(Y-b-\sum_{i=1}^{p}a_iX_i\right)^2$. This is from the exponential family, thus we can switch the order of integration and differentiation: \begin{equation} \mathbb{E}\left(\frac{\partial}{\partial a_i}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=-2c_i+2\sum_{j=1}^{p}a_ic_{ij}\qquad \mathbb{E}\left(\frac{\partial}{\partial b}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=2b \end{equation} \begin{equation} \mathbb{E}\left(\frac{\partial^2}{\partial a_i^2}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=2c_{ii}\qquad \mathbb{E}\left(\frac{\partial^2}{\partial b^2}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=2 \end{equation} \begin{equation} \mathbb{E}\left(\frac{\partial}{\partial a_i \partial a_j}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=2c_{ij}\qquad \mathbb{E}\left(\frac{\partial}{\partial a_i \partial b}\left(Y-b-\sum_{j=1}^{p}a_jX_j\right)^2\right)=0 \end{equation} So the Hessian is positive definite at this point, meaning that the minimum is obtained a when: \begin{equation} \mathbf{D}\mathbf{a}=\mathbf{c}\Rightarrow \boxed{\mathbf{a}=\mathbf{D}^{-1}\mathbf{c}\qquad b=0} \end{equation} And that it is the maximum We want to find the maximum in the direction $\mathbf{v}$, so take $t(X_{i=1}^p,u)=(\mathbf{D}^{-1}\mathbf{c}+u\mathbf{v})^T\mathbf{X}$, then using $\mathbf{D}^T=\mathbf{D}$: \begin{equation} {Corr}(Y,t(X_{i=1}^p,u))=\frac{Cov(Y,(\mathbf{D}^{-1}\mathbf{c}+u\mathbf{v})^T\mathbf{X})}{\sqrt{Var Y Var((\mathbf{D}^{-1}\mathbf{c}+u\mathbf{v})^T\mathbf{X})}}= \frac{(\mathbf{D}^{-1}\mathbf{c}+ u\mathbf{v})^T\mathbf{c}} {\sigma\sqrt{\mathbf{c}^T\mathbf{D}^{-1}\mathbf{D}\mathbf{D}^{-1}\mathbf{c}+2u\mathbf{v}^T\mathbf{D}\mathbf{D}^{-1}\mathbf{c}+u^2\mathbf{v}^T\mathbf{D}\mathbf{v}}}= \end{equation} \begin{equation} =\frac{\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}+ u\mathbf{v}^T\mathbf{c}} {\sqrt{\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}+ 2u\mathbf{v}^T\mathbf{c}+ u^2\mathbf{v}^T\mathbf{D}\mathbf{v}}} \end{equation} \begin{equation} \frac{\partial}{\partial u}{Corr}(Y,t(X_{i=1}^p,u))= \frac{u((\mathbf{c}^T\mathbf{v})^2-\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{v}^T\mathbf{D}\mathbf{v})} {\sigma(\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}+2u\mathbf{v}^T\mathbf{c}+u^2\mathbf{v}^T\mathbf{D}\mathbf{v})^{3/2}} \end{equation} With some straightforward and lengthy calculations, we have: \begin{equation} \left.\frac{\partial^2}{\partial u^2}{Corr}(Y,t(X_{i=1}^p,u))\right|_{u=0}=-\frac{\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{v}^T\mathbf{D}\mathbf{v}-(\mathbf{c}^T\mathbf{v})^2}{(\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c})^{3/2}} \end{equation} So we must have $u=0$ or $(\mathbf{v}^T\mathbf{c})^2-\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{v}^T\mathbf{D}\mathbf{v}=0$, meaning that the correlation is constant in the direction of $\mathbf{v}$. Let $\mathbf{v}=\mathbf{v}_\perp+\lambda\mathbf{c}$, where $\mathbf{v}_\perp$ is orthogonal to $\mathbf{c}$, thus: \begin{equation} \mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{v}^T\mathbf{D}\mathbf{v}-(\mathbf{v}\mathbf{c}^T)^2=\lambda^2\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{c}^T\mathbf{D}\mathbf{c}+\lambda\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{c}^T\mathbf{D}\mathbf{v}_\perp-(\lambda\mathbf{c}^T\mathbf{c})^2 \end{equation} If $\mathbf{Y}$ is independent, then the correlation is $0$. If that's not the case, with scaling we can achieve $\textbf{c}^T\textbf{c}=1$. $\mathbf{c}^T\mathbf{D}^{-1}\mathbf{c}\mathbf{c}^T\mathbf{D}\mathbf{c}=(\mathbf{c}^T\mathbf{c})^2$ And there I'm just stuck, any ideas how to continue?",,"['statistics', 'inequality', 'matrix-equations']"
28,Distribution of a product of Multinomials,Distribution of a product of Multinomials,,"Consider the following: $(X_1, X_2, X_3, X_4) \sim \mathrm{Multinomial} (n,\mathbf{p})$ where $\mathbf{p} = (p_1,p_2,p_3,p_4)$.  I would like to find the distribution of $X_1 X_4$, or at least know some bounds on the variance of $X_1 X_4$.  I know that $E(X_1X_4) = n^2 p_1 p_4 - np_1 p_4 = n(np_1p_4 - p_1p_4)$.  Is $X_1X_4$ in any way","Consider the following: $(X_1, X_2, X_3, X_4) \sim \mathrm{Multinomial} (n,\mathbf{p})$ where $\mathbf{p} = (p_1,p_2,p_3,p_4)$.  I would like to find the distribution of $X_1 X_4$, or at least know some bounds on the variance of $X_1 X_4$.  I know that $E(X_1X_4) = n^2 p_1 p_4 - np_1 p_4 = n(np_1p_4 - p_1p_4)$.  Is $X_1X_4$ in any way",,"['probability', 'statistics']"
29,Why are these following variance and expected value computations legitimate?,Why are these following variance and expected value computations legitimate?,,"I spent over an hour of my exam's given time to calculate the variances and expected values as given here: Let $p,q\in (0,1)$. The number of costumers entering a supermarket is a r.v. $X$ with geometric distribution with parameter $q$. Every costumer buys a product with probability $p$ or buys nothing, with $1-p$. Let $Y$ be the number of products purchased (or bought? Is there a difference?). What is $E[Y]$? $V[Y]$? The problematic part is that after a long computation, I arrived at $p\over q$. The formal answers simply argued: $E(Y)=E(Y|X)=\color{green}{E(pX)}=pE(X)={p\over q}$, where the green part is an argument never have I ever encountered. I couldn't compute the second one for it became too intricate(That is a really long multiple choice test.), but the formal answers used that again:  $V(Y)=E(V(Y|X))+V(E(Y|X))=\color{green}{E(p(1-p)X)+V(pX)}$, and I wonder, why is $E(X|Y)=E(E(X)Y)$? I would appreciate your help. Okay I am under the impression that suggesting free points is unorthodox or illegitimate here. I will wait as long as it enables me, for an answer to be given, and share my points with the answer I happen to see as best in my view.","I spent over an hour of my exam's given time to calculate the variances and expected values as given here: Let $p,q\in (0,1)$. The number of costumers entering a supermarket is a r.v. $X$ with geometric distribution with parameter $q$. Every costumer buys a product with probability $p$ or buys nothing, with $1-p$. Let $Y$ be the number of products purchased (or bought? Is there a difference?). What is $E[Y]$? $V[Y]$? The problematic part is that after a long computation, I arrived at $p\over q$. The formal answers simply argued: $E(Y)=E(Y|X)=\color{green}{E(pX)}=pE(X)={p\over q}$, where the green part is an argument never have I ever encountered. I couldn't compute the second one for it became too intricate(That is a really long multiple choice test.), but the formal answers used that again:  $V(Y)=E(V(Y|X))+V(E(Y|X))=\color{green}{E(p(1-p)X)+V(pX)}$, and I wonder, why is $E(X|Y)=E(E(X)Y)$? I would appreciate your help. Okay I am under the impression that suggesting free points is unorthodox or illegitimate here. I will wait as long as it enables me, for an answer to be given, and share my points with the answer I happen to see as best in my view.",,"['probability', 'statistics']"
30,Calculating cumulant from data set,Calculating cumulant from data set,,"Given a data set $x = \{ x(n) \mid n=1,\ldots,m\}$ how do I calculate the $p^{th}$-order cumulant? In particular I need to calculate the 4th-order cumulant. I found that I can calculate the cumulant from moments, but I also don't know how to calculate moments. I found how to calculate the 4th central moment (kurtosis) but I am not sure if/how they are related. Since I have to implement the calculation of the cumulant in C++ I would be interested in a general explanation (to understand what I am doing) but also hints on how to implement the calculation efficiently would be appreciated. How can one interpret the 4th-order cumulant? I am sorry if this is a trivial question but I don't have a strong mathematical background and was not able to find the answer online.","Given a data set $x = \{ x(n) \mid n=1,\ldots,m\}$ how do I calculate the $p^{th}$-order cumulant? In particular I need to calculate the 4th-order cumulant. I found that I can calculate the cumulant from moments, but I also don't know how to calculate moments. I found how to calculate the 4th central moment (kurtosis) but I am not sure if/how they are related. Since I have to implement the calculation of the cumulant in C++ I would be interested in a general explanation (to understand what I am doing) but also hints on how to implement the calculation efficiently would be appreciated. How can one interpret the 4th-order cumulant? I am sorry if this is a trivial question but I don't have a strong mathematical background and was not able to find the answer online.",,['statistics']
31,Confidence Intervals that Contain the Mean: Designing an Activity,Confidence Intervals that Contain the Mean: Designing an Activity,,"This past Wednesday, I had my stat class do the following exercise: Roll a fair 6 sided dice 25 times. Take the sample mean of the face value. Using the standard deviation of the uniform probability distribution, construct confidence intervals with $C=.90, .95, .99$. I had 16 groups total doing this exercise. All 16 groups found their 90% confidence intervals containing the the mean of the probability distribution (3.5.). I thought I would have at least one confidence intervals that wouldn't contain the mean... considering that the probability that all 16 confidence intervals contains $\mu$ would be $.90^{16} \simeq .1853$. Is my prediction completely flawed? Or was I just unlucky? Or is there something inherently wrong with my experiment?","This past Wednesday, I had my stat class do the following exercise: Roll a fair 6 sided dice 25 times. Take the sample mean of the face value. Using the standard deviation of the uniform probability distribution, construct confidence intervals with $C=.90, .95, .99$. I had 16 groups total doing this exercise. All 16 groups found their 90% confidence intervals containing the the mean of the probability distribution (3.5.). I thought I would have at least one confidence intervals that wouldn't contain the mean... considering that the probability that all 16 confidence intervals contains $\mu$ would be $.90^{16} \simeq .1853$. Is my prediction completely flawed? Or was I just unlucky? Or is there something inherently wrong with my experiment?",,"['probability', 'statistics', 'statistical-inference', 'central-limit-theorem']"
32,Conditional probability confusion,Conditional probability confusion,,"I have a continuous random variable X and I am told to find the following probability: $ P(X\ge 3 | X \le 4)$ I understand that: $ P(A|B)=\frac{P(A \cap B)}{P(B)} $ However, in my head it seems logical to say: $ P(X\ge 3 | X \le 4) = P(3 \le X \le 4)$ Why is this not correct? Thanks, Matt","I have a continuous random variable X and I am told to find the following probability: $ P(X\ge 3 | X \le 4)$ I understand that: $ P(A|B)=\frac{P(A \cap B)}{P(B)} $ However, in my head it seems logical to say: $ P(X\ge 3 | X \le 4) = P(3 \le X \le 4)$ Why is this not correct? Thanks, Matt",,"['probability', 'statistics']"
33,Why isn' t high order polynomial a good fit?,Why isn' t high order polynomial a good fit?,,"Let's say I have a set of data points $(x_i,y_i), i=1,2,...,N$, and I want to approximate it using a polynomial $p(x)=\sum_{i=0}^n a_i x^i$ with a least squares fit (so $n<N$). I know that the coefficient $R^2$ is a measure for goodness of fit. But as I increase the order $n$ of the polynomial $p$, $R^2$ approaches $1$. (In the extreme case when $n=N$ the fit is an interpolation with $R^2=1$.) But a high order polynomial fit is likely an unphysical result and doesn't describe the population well. So is there a mathematical characteristic or coefficient or model that describes and explains this?","Let's say I have a set of data points $(x_i,y_i), i=1,2,...,N$, and I want to approximate it using a polynomial $p(x)=\sum_{i=0}^n a_i x^i$ with a least squares fit (so $n<N$). I know that the coefficient $R^2$ is a measure for goodness of fit. But as I increase the order $n$ of the polynomial $p$, $R^2$ approaches $1$. (In the extreme case when $n=N$ the fit is an interpolation with $R^2=1$.) But a high order polynomial fit is likely an unphysical result and doesn't describe the population well. So is there a mathematical characteristic or coefficient or model that describes and explains this?",,"['statistics', 'statistical-inference']"
34,How was the explicit closed form for this implicit function derived?,How was the explicit closed form for this implicit function derived?,,"The problem comes from reading this [0] paper but I think I can express it in a self contained question. Consider the implicit function $H(z)$ defined by the relation: $$F_z(z+H(z))-F_z(z-H(z))=0.5$$ Where $F_z$ is the CDF of an absolutly continuous, unimodal distribution. The authors point out that when $F'_z=f_z=\max(1-|z|,0)$ (the triangle distribution with parameters $a=-1,c=0$ and $b=1$), $$H(z)= \begin{cases}    1-\sqrt{1/2-z^2} & \text{if } |z| \leq 1/2 \\    |z|       & \text{if } |z| > 1/2   \end{cases}$$ (p387, bottom of the article I linked to) My questions are: How was the explicit formulation for $H(z)$ derived? Can it also be done for other values of $c$, i.e. $c=1$ [0] Ola Hössjer, Peter J. Rousseeuw and Christophe Croux.  Asymptotics of an estimator of a robust spread functional. Statistica Sinica 6(1996), 375-388.","The problem comes from reading this [0] paper but I think I can express it in a self contained question. Consider the implicit function $H(z)$ defined by the relation: $$F_z(z+H(z))-F_z(z-H(z))=0.5$$ Where $F_z$ is the CDF of an absolutly continuous, unimodal distribution. The authors point out that when $F'_z=f_z=\max(1-|z|,0)$ (the triangle distribution with parameters $a=-1,c=0$ and $b=1$), $$H(z)= \begin{cases}    1-\sqrt{1/2-z^2} & \text{if } |z| \leq 1/2 \\    |z|       & \text{if } |z| > 1/2   \end{cases}$$ (p387, bottom of the article I linked to) My questions are: How was the explicit formulation for $H(z)$ derived? Can it also be done for other values of $c$, i.e. $c=1$ [0] Ola Hössjer, Peter J. Rousseeuw and Christophe Croux.  Asymptotics of an estimator of a robust spread functional. Statistica Sinica 6(1996), 375-388.",,"['statistics', 'self-learning']"
35,Show that the variance is biased,Show that the variance is biased,,"I am trying to understand the proof that the uncorrected sample variance is biased (given here ) $$  \begin{eqnarray}    E[S^2] &=& E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \bar X)^2 \right ] \\    &=& E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} \left ( (X_i - \mu)- (\bar X - \mu) \right)^2 \right ] \label{eq:s2q1p2p1}\\    &=& E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu)^2 - 2(\bar X -\mu)  \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu) + (\bar X - \mu)^2 \right ]  \\    &=& E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu)^2 -  (\bar X - \mu)^2 \right ]  \\    &=& \sigma^2 - E \left [(\bar X - \mu)^2 \right ]  < \sigma^2  \end{eqnarray}  $$ Conceptually I do understand everything, but I don't understand how to get from $$ E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu)^2 - 2(\bar X -\mu)  \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu) + (\bar X - \mu)^2 \right ] $$ to $$ E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu)^2 -  (\bar X - \mu)^2 \right ]. $$","I am trying to understand the proof that the uncorrected sample variance is biased (given here ) $$  \begin{eqnarray}    E[S^2] &=& E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \bar X)^2 \right ] \\    &=& E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} \left ( (X_i - \mu)- (\bar X - \mu) \right)^2 \right ] \label{eq:s2q1p2p1}\\    &=& E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu)^2 - 2(\bar X -\mu)  \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu) + (\bar X - \mu)^2 \right ]  \\    &=& E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu)^2 -  (\bar X - \mu)^2 \right ]  \\    &=& \sigma^2 - E \left [(\bar X - \mu)^2 \right ]  < \sigma^2  \end{eqnarray}  $$ Conceptually I do understand everything, but I don't understand how to get from $$ E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu)^2 - 2(\bar X -\mu)  \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu) + (\bar X - \mu)^2 \right ] $$ to $$ E \left [ \frac{1}{n} \sum \limits_{i=1}^{n} (X_i - \mu)^2 -  (\bar X - \mu)^2 \right ]. $$",,"['statistics', 'estimation']"
36,Identifiying Biased and Unbiased Samples,Identifiying Biased and Unbiased Samples,,"My little nephew asked me a question about biased/unbiased samples in which is teachers answer is something I disagree with to say the least (I don't agree with the assumption made by the teacher nor the lack of critical thinking within his answer). The question is, ""If Johnny took a handful of photographs and threw them up in the air, and selected 7 that landed on the rug- would this be a biased sampling?"" The teachers answer is simply, ""No, each photograph has an equal chance of landing on the rug therefore it is an unbiased sample."" I couldn't disagree more. The equal probability of each photographs landing on the rug has many dependent factors, how big is the rug compared to the room, where are you in the room when tossing the photos in the air, what is your current position relative to the rug, in what way are you tossing the photos into the air, and how were you holding them when do did it... In fact I think we could continue to give factors that would be relevant, was the window open and a breeze coming through, in what direction etc, but in only a few case of the vastly many are there the situation where the probability of landing on the rug is equal for all photographs given that the size of the rug doesn't take up the entire room. Since the question give very little to no information required to actually determine if the sampling would be biased or unbiased, can we not infer this is likely a biased sample since perfect circumstances would be needed in the room to guarantee each photograph having an equal chance of landing on the rug (because there are infinitely more ways the perfect circumstance could fail to exist if the rug isn't as big as the room)? My nephew couldn't follow what I was trying to explain so I gave him this to think about. If I stood in a big room with the rug across the room and toss the pictures in the air, there is zero probability that any will land on the rug.. I repeat this each time, inching closer to the rug, until eventually seven cards landed on the rug. Now just because the sample amount you wish to take has finally landed on the rug- is that enough to guarantee that all photographs tossed up in air during this iteration of the experiment had an equal probability of landing on the rug? If given the situation where there is enough information loss so that determining the equal distribution of probabilities for an event to occur is impossible then isn't it reasonable to assume there there may exist some bias in the result?","My little nephew asked me a question about biased/unbiased samples in which is teachers answer is something I disagree with to say the least (I don't agree with the assumption made by the teacher nor the lack of critical thinking within his answer). The question is, ""If Johnny took a handful of photographs and threw them up in the air, and selected 7 that landed on the rug- would this be a biased sampling?"" The teachers answer is simply, ""No, each photograph has an equal chance of landing on the rug therefore it is an unbiased sample."" I couldn't disagree more. The equal probability of each photographs landing on the rug has many dependent factors, how big is the rug compared to the room, where are you in the room when tossing the photos in the air, what is your current position relative to the rug, in what way are you tossing the photos into the air, and how were you holding them when do did it... In fact I think we could continue to give factors that would be relevant, was the window open and a breeze coming through, in what direction etc, but in only a few case of the vastly many are there the situation where the probability of landing on the rug is equal for all photographs given that the size of the rug doesn't take up the entire room. Since the question give very little to no information required to actually determine if the sampling would be biased or unbiased, can we not infer this is likely a biased sample since perfect circumstances would be needed in the room to guarantee each photograph having an equal chance of landing on the rug (because there are infinitely more ways the perfect circumstance could fail to exist if the rug isn't as big as the room)? My nephew couldn't follow what I was trying to explain so I gave him this to think about. If I stood in a big room with the rug across the room and toss the pictures in the air, there is zero probability that any will land on the rug.. I repeat this each time, inching closer to the rug, until eventually seven cards landed on the rug. Now just because the sample amount you wish to take has finally landed on the rug- is that enough to guarantee that all photographs tossed up in air during this iteration of the experiment had an equal probability of landing on the rug? If given the situation where there is enough information loss so that determining the equal distribution of probabilities for an event to occur is impossible then isn't it reasonable to assume there there may exist some bias in the result?",,"['probability', 'statistics']"
37,"Find the cutoff level for the highest 15% in normal distribution, given the mean and standard deviation [closed]","Find the cutoff level for the highest 15% in normal distribution, given the mean and standard deviation [closed]",,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question The cholesterol levels of adult American women are approximately normal with the mean of 188 mg/dl and a standard deviation of 24 mg/dl. a company wants to test a certain medication for women falling in the highest 15% of cholesterol readings. What is the lowest cholesterol reading a women might have and still be in the test group? Never done these type of problems so it would like help on this one so I could do others.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question The cholesterol levels of adult American women are approximately normal with the mean of 188 mg/dl and a standard deviation of 24 mg/dl. a company wants to test a certain medication for women falling in the highest 15% of cholesterol readings. What is the lowest cholesterol reading a women might have and still be in the test group? Never done these type of problems so it would like help on this one so I could do others.",,"['statistics', 'normal-distribution']"
38,$E[X^2]$ of the Beta Distribution,of the Beta Distribution,E[X^2],"So I know the Beta distribution is $$f(x) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\cdot x^{a-1}\cdot(1-x)^{b-1}$$ I know the $E[X^r] = \dfrac{\Gamma(a+b)\Gamma(a+r)}{\Gamma(a)\Gamma(a+r+b)}$ And I know plugging in $1$ for $r$ to get $E[X]$ (or $\mu$ mean) gives you $a/(a+b)$ because I know $\Gamma(n+1) = n\Gamma(n)$. However, what do you do if you have $r=2$ or anything higher than $1$? How would I find $E[X^2]$? I am a actuary major so I don't know how to correctly format the question to make it look all nice and neat. Feel free to help edit and adjust the way the question looks to make it look next (i.e. actually put the greek letter gamma or Beta or integral signs in). Again, sorry for the slopping format. You can hate all you want.","So I know the Beta distribution is $$f(x) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\cdot x^{a-1}\cdot(1-x)^{b-1}$$ I know the $E[X^r] = \dfrac{\Gamma(a+b)\Gamma(a+r)}{\Gamma(a)\Gamma(a+r+b)}$ And I know plugging in $1$ for $r$ to get $E[X]$ (or $\mu$ mean) gives you $a/(a+b)$ because I know $\Gamma(n+1) = n\Gamma(n)$. However, what do you do if you have $r=2$ or anything higher than $1$? How would I find $E[X^2]$? I am a actuary major so I don't know how to correctly format the question to make it look all nice and neat. Feel free to help edit and adjust the way the question looks to make it look next (i.e. actually put the greek letter gamma or Beta or integral signs in). Again, sorry for the slopping format. You can hate all you want.",,"['statistics', 'probability-distributions', 'beta-function']"
39,"Chebyshev's theorem, is my answer correct to this question?","Chebyshev's theorem, is my answer correct to this question?",,"I was wondering if you guys could confirm if my answer is correct for this question regarding Chebyshev's theorem. A random variable $X$ has a mean of $\mu=5$ and a variance $\sigma^2=36$ (i.e.: a standard deviation of $\sigma=6$). Using Chebyshev's theorem, find the value of the constant $c$ such that $$P(|x-5|\geq c)\leq 0.75$$ My answer was $\displaystyle c = 6 \sqrt{\frac{4}{3}}$. Thought process: I first found the k value associated with a probability of .25 since this k value would tell me what range of data fall within 25% of the mean. After I obtained k, I just multiplied it by the standard deviation 6 and designated it as c since the probability of finding any random variable greater than c is going to be at max .75 since we are excluding all probabilities less than c. Thanks!","I was wondering if you guys could confirm if my answer is correct for this question regarding Chebyshev's theorem. A random variable $X$ has a mean of $\mu=5$ and a variance $\sigma^2=36$ (i.e.: a standard deviation of $\sigma=6$). Using Chebyshev's theorem, find the value of the constant $c$ such that $$P(|x-5|\geq c)\leq 0.75$$ My answer was $\displaystyle c = 6 \sqrt{\frac{4}{3}}$. Thought process: I first found the k value associated with a probability of .25 since this k value would tell me what range of data fall within 25% of the mean. After I obtained k, I just multiplied it by the standard deviation 6 and designated it as c since the probability of finding any random variable greater than c is going to be at max .75 since we are excluding all probabilities less than c. Thanks!",,"['statistics', 'inequality']"
40,Expected number of output letters to get desired word,Expected number of output letters to get desired word,,"I am using a letter set of four letters, say {A,B,C,D}, which is used to output a random string of letters. I want to calculate the expected output length until the word ABCD is obtained; that is, the letters A B C D appearing consecutively in that order. I have referenced this question (Expected Number of Coin Tosses to Get Five Consecutive Heads) , but have found a complexity in our case; when we obtain, say, ABA, then we can't say that the chain resets, since we have the next potentially successful chain already being started. I have tried the approach below, but am not sure if it is completely correct. I would be grateful for assertion that this approach is ok, as well as for any alternative methods to approach this issue. Let e be the expected number of output letters needed to get the target string ABCD. Also, let f be the expected number of output letters needed to get the target string ABCD given we obtained the letter A . The table for expected length and probability for e would be |                          | Exp Len | Prob | |--------------------------|---------|------| | if first letter is [BCD] |   e+1   | 3/4  | | if A then [CD]           |   e+2   | 1/8  | | if A then A              |   f+1   | 1/16 | | if AB then [BD]          |   e+3   | 1/32 | | if AB then A             |   f+2   | 1/64 | | if ABC then [BC]         |   e+4   | 1/128| | if ABC then A            |   f+3   | 1/256| | if ABCD                  |    4    | 1/256| --------------------------------------------- and a similar table for f after we obtained the letter A would be |                       | Exp Len | Prob | |-----------------------|---------|------| |if first letter is [CD]|   e+2   | 1/2  | |if first letter is A   |   f+1   | 1/4  | |if B then [BD]         |   e+3   | 1/8  | |if B then A            |   f+2   | 1/16 | |if BC then [BC]        |   e+4   | 1/32 | |if BC then A           |   f+3   | 1/64 | |if BCD                 |    4    | 1/64 | ------------------------------------------ The expected length e is equal to the sum of each (Probability)*(Expected Length) product set from the first table, giving $$ e\, =\, \frac{3}{4}(e+1)\, +\, \frac{1}{8}(e+2)\, +\, \frac{1}{16}(f+1)\, +\, \frac{1}{32}(e+3 )\, +\, \frac{1}{64}(f+2)\, +\, \frac{1}{128}(e+4)\, +\, \frac{1}{256}(f+3)\, +\, \frac{1}{256}(4) \\-----\\ e\, \, =\, \frac{117}{128}e\, +\, \frac{21}{256}f\, +\, \frac{319}{256} \\\\ 22e\, =\, 21f\, +\, 319 \: \: \:  ---(1) \\ 44e\, =\, 42f\, +\, 638 \: \: \:  ---(1')  $$ A similar approach for f yields  $$ f\, =\, \frac{1}{2}(e+2)\, +\, \frac{1}{4}(f+1)\, +\, \frac{1}{8}(e+3)\, +\, \frac{1}{16}(f+2 )\, +\, \frac{1}{32}(e+4)\, +\, \frac{1}{64}(f+3)\,+\, \frac{1}{64}(4) \\-----\\ f\, \, =\, \frac{21}{32}e\, +\, \frac{21}{64}f\, +\, \frac{127}{64} \\\\ 43f\, =\, 42e\, +\, 127 \: \: \:  ---(2) $$ Combining these, we obtain $$ (2)-(1')\Rightarrow f\, =\, -2e\, +\, 765 \: \: \:  ---(3)\\ (3)\rightarrow (1)\Rightarrow 22e = 21(-2e+765)+319 \\ e=256 \\ f=253 $$ So the expected length seems to be 256 letters output. I notice this is exactly what we would expect from the naive approach, from the fact that each letter has a 1 in 4 chance appearing each time, and after any four letters' output, the chance of ABCD appearing is  $$ \left( \frac{1}{4} \right) ^ 4 = \frac{1}{256} .  $$ which is slightly worrying, since the question about five consecutive heads has a probability of 1/32, but a differing number of 62 for the expected length. 2014/09/16 addition: After the above, I also calculated the expected length until I obtain either of TWO target strings; I used ABCD and CDBA as my targets, if it matters. The result was not the intuitive 128, but was 136 instead, by methodology similar to that above. Using the answers provided, I will also try to check this result using new tactics proposed in the answers.","I am using a letter set of four letters, say {A,B,C,D}, which is used to output a random string of letters. I want to calculate the expected output length until the word ABCD is obtained; that is, the letters A B C D appearing consecutively in that order. I have referenced this question (Expected Number of Coin Tosses to Get Five Consecutive Heads) , but have found a complexity in our case; when we obtain, say, ABA, then we can't say that the chain resets, since we have the next potentially successful chain already being started. I have tried the approach below, but am not sure if it is completely correct. I would be grateful for assertion that this approach is ok, as well as for any alternative methods to approach this issue. Let e be the expected number of output letters needed to get the target string ABCD. Also, let f be the expected number of output letters needed to get the target string ABCD given we obtained the letter A . The table for expected length and probability for e would be |                          | Exp Len | Prob | |--------------------------|---------|------| | if first letter is [BCD] |   e+1   | 3/4  | | if A then [CD]           |   e+2   | 1/8  | | if A then A              |   f+1   | 1/16 | | if AB then [BD]          |   e+3   | 1/32 | | if AB then A             |   f+2   | 1/64 | | if ABC then [BC]         |   e+4   | 1/128| | if ABC then A            |   f+3   | 1/256| | if ABCD                  |    4    | 1/256| --------------------------------------------- and a similar table for f after we obtained the letter A would be |                       | Exp Len | Prob | |-----------------------|---------|------| |if first letter is [CD]|   e+2   | 1/2  | |if first letter is A   |   f+1   | 1/4  | |if B then [BD]         |   e+3   | 1/8  | |if B then A            |   f+2   | 1/16 | |if BC then [BC]        |   e+4   | 1/32 | |if BC then A           |   f+3   | 1/64 | |if BCD                 |    4    | 1/64 | ------------------------------------------ The expected length e is equal to the sum of each (Probability)*(Expected Length) product set from the first table, giving $$ e\, =\, \frac{3}{4}(e+1)\, +\, \frac{1}{8}(e+2)\, +\, \frac{1}{16}(f+1)\, +\, \frac{1}{32}(e+3 )\, +\, \frac{1}{64}(f+2)\, +\, \frac{1}{128}(e+4)\, +\, \frac{1}{256}(f+3)\, +\, \frac{1}{256}(4) \\-----\\ e\, \, =\, \frac{117}{128}e\, +\, \frac{21}{256}f\, +\, \frac{319}{256} \\\\ 22e\, =\, 21f\, +\, 319 \: \: \:  ---(1) \\ 44e\, =\, 42f\, +\, 638 \: \: \:  ---(1')  $$ A similar approach for f yields  $$ f\, =\, \frac{1}{2}(e+2)\, +\, \frac{1}{4}(f+1)\, +\, \frac{1}{8}(e+3)\, +\, \frac{1}{16}(f+2 )\, +\, \frac{1}{32}(e+4)\, +\, \frac{1}{64}(f+3)\,+\, \frac{1}{64}(4) \\-----\\ f\, \, =\, \frac{21}{32}e\, +\, \frac{21}{64}f\, +\, \frac{127}{64} \\\\ 43f\, =\, 42e\, +\, 127 \: \: \:  ---(2) $$ Combining these, we obtain $$ (2)-(1')\Rightarrow f\, =\, -2e\, +\, 765 \: \: \:  ---(3)\\ (3)\rightarrow (1)\Rightarrow 22e = 21(-2e+765)+319 \\ e=256 \\ f=253 $$ So the expected length seems to be 256 letters output. I notice this is exactly what we would expect from the naive approach, from the fact that each letter has a 1 in 4 chance appearing each time, and after any four letters' output, the chance of ABCD appearing is  $$ \left( \frac{1}{4} \right) ^ 4 = \frac{1}{256} .  $$ which is slightly worrying, since the question about five consecutive heads has a probability of 1/32, but a differing number of 62 for the expected length. 2014/09/16 addition: After the above, I also calculated the expected length until I obtain either of TWO target strings; I used ABCD and CDBA as my targets, if it matters. The result was not the intuitive 128, but was 136 instead, by methodology similar to that above. Using the answers provided, I will also try to check this result using new tactics proposed in the answers.",,"['probability', 'combinatorics', 'statistics']"
41,"List of well-known submodular function in physics, statistics, math?","List of well-known submodular function in physics, statistics, math?",,"Can you please share a list of well-known submodular functions (have the diminishing return property) that you know? In physics, stats, math, etc? I am searching for a submodular function for my research problem, which is a bit too much to describe here. So simply share your knowledge about some submodular functions here would very much appreciated. Ideally, I look for a function that is well-known and has been used often or popularly in sciences, such as entropy, etc. You can discard those simple ones, such as square-root or so. Thanks","Can you please share a list of well-known submodular functions (have the diminishing return property) that you know? In physics, stats, math, etc? I am searching for a submodular function for my research problem, which is a bit too much to describe here. So simply share your knowledge about some submodular functions here would very much appreciated. Ideally, I look for a function that is well-known and has been used often or popularly in sciences, such as entropy, etc. You can discard those simple ones, such as square-root or so. Thanks",,"['statistics', 'functions', 'physics', 'mathematical-physics']"
42,Conditional Probability matching socks,Conditional Probability matching socks,,"A drawer contains eight different pairs of socks. If six socks are taken at random without replacement, compute the probability that there is at least one matching pair among these six socks. Hint: compute the probability that there is not a matching pair first. Sorry guys, I'm really awful at this class, I'm trying to train my brain to think the right way to solve these on my own but it's hard.","A drawer contains eight different pairs of socks. If six socks are taken at random without replacement, compute the probability that there is at least one matching pair among these six socks. Hint: compute the probability that there is not a matching pair first. Sorry guys, I'm really awful at this class, I'm trying to train my brain to think the right way to solve these on my own but it's hard.",,"['probability', 'statistics', 'conditional-probability']"
43,Understanding an application of Fubini's theorem,Understanding an application of Fubini's theorem,,"I'm going over some lecture notes for a course in statistical theory. There is a ""proof"" that the density for a $k$-dimensional multivariate normal random variable (with non-singular covariance) is, in fact, a density. In this proof there is a line: $$ \int \prod_{i=1}^k \phi(y_i) \, d\boldsymbol{y} = \prod_{i=1}^k \int \phi(y_i) \, dy_i \quad \textrm{(by Fubini)}$$ Where $\phi(\cdot)$ is the density function for a standard normal, $d\boldsymbol{y} = d(y_1, \ldots, y_k)$ (I suppose) indicates integration with respect to Lebesgue measure on $\mathbb{R}^k$ and $dy_i$ indicates integration with respect to Lebesgue measure on $\mathbb{R}$. My understanding of product spaces is a little weak and I'm struggling to see how Fubini's theorem produces this. Can anyone help to fill in the blank? EDIT: Removed reference to the integrals evaluating to 1. I'm asking for an explanation of the measure theory setup behind the equality of the two integral expression that Dilip mentions in his comment below. Sorry for the confusion.","I'm going over some lecture notes for a course in statistical theory. There is a ""proof"" that the density for a $k$-dimensional multivariate normal random variable (with non-singular covariance) is, in fact, a density. In this proof there is a line: $$ \int \prod_{i=1}^k \phi(y_i) \, d\boldsymbol{y} = \prod_{i=1}^k \int \phi(y_i) \, dy_i \quad \textrm{(by Fubini)}$$ Where $\phi(\cdot)$ is the density function for a standard normal, $d\boldsymbol{y} = d(y_1, \ldots, y_k)$ (I suppose) indicates integration with respect to Lebesgue measure on $\mathbb{R}^k$ and $dy_i$ indicates integration with respect to Lebesgue measure on $\mathbb{R}$. My understanding of product spaces is a little weak and I'm struggling to see how Fubini's theorem produces this. Can anyone help to fill in the blank? EDIT: Removed reference to the integrals evaluating to 1. I'm asking for an explanation of the measure theory setup behind the equality of the two integral expression that Dilip mentions in his comment below. Sorry for the confusion.",,"['real-analysis', 'probability', 'statistics']"
44,Is this function concave or can it be made concave?,Is this function concave or can it be made concave?,,"I am working with a point process with an event arrival rate of: $$ \lambda(t) =  \mu +  \sum\limits_{t_i<t}{\alpha e^{-\beta(t-t_i)}}$$ where $ t_1,..t_n $ are the event arrival times. The log likelihood function is therefore: $$  - t_n \mu + \frac{\alpha}{\beta} \sum{( e^{-\beta(t_n-t_i)}-1 )} + \sum\limits_{i<j}{\ln(\mu+\alpha e^{-\beta(t_j-t_i)})} $$ To obtain the maximum likelihood estimate (MLE) I need to maximize this log likelihood function under the restrictions that $\mu, \alpha, \beta > 0$ and $\beta > \alpha$. Is the log likelihood function concave? The parameters are  $\mu, \alpha, \beta$. If not, is there a reparameterization that would make it concave? In R code the log likelihood is l.loglik <- function(params, data, opt=TRUE) {   mu <- params[1]   alpha <- params[2]   beta <- params[3]   t <- sort(data)   r <- rep(0,length(t))   for(i in 2:length(t)) {     r[i] <- exp(-beta*(t[i]-t[i-1]))*(1+r[i-1])   }   loglik <- -tail(t,1)*mu   loglik <- loglik+alpha/beta*sum(exp(-beta*(tail(t,1)-t))-1)   loglik <- loglik+sum(log(mu+alpha*r))   if(!opt) {     return(list(negloglik=-loglik, mu=mu, alpha=alpha, beta=beta, t=t,                 r=r))   }   else {     return(loglik)   } }","I am working with a point process with an event arrival rate of: $$ \lambda(t) =  \mu +  \sum\limits_{t_i<t}{\alpha e^{-\beta(t-t_i)}}$$ where $ t_1,..t_n $ are the event arrival times. The log likelihood function is therefore: $$  - t_n \mu + \frac{\alpha}{\beta} \sum{( e^{-\beta(t_n-t_i)}-1 )} + \sum\limits_{i<j}{\ln(\mu+\alpha e^{-\beta(t_j-t_i)})} $$ To obtain the maximum likelihood estimate (MLE) I need to maximize this log likelihood function under the restrictions that $\mu, \alpha, \beta > 0$ and $\beta > \alpha$. Is the log likelihood function concave? The parameters are  $\mu, \alpha, \beta$. If not, is there a reparameterization that would make it concave? In R code the log likelihood is l.loglik <- function(params, data, opt=TRUE) {   mu <- params[1]   alpha <- params[2]   beta <- params[3]   t <- sort(data)   r <- rep(0,length(t))   for(i in 2:length(t)) {     r[i] <- exp(-beta*(t[i]-t[i-1]))*(1+r[i-1])   }   loglik <- -tail(t,1)*mu   loglik <- loglik+alpha/beta*sum(exp(-beta*(tail(t,1)-t))-1)   loglik <- loglik+sum(log(mu+alpha*r))   if(!opt) {     return(list(negloglik=-loglik, mu=mu, alpha=alpha, beta=beta, t=t,                 r=r))   }   else {     return(loglik)   } }",,['statistics']
45,What is the intuition or proof behind the conditional Bayes' theorem?,What is the intuition or proof behind the conditional Bayes' theorem?,,"In the book ""Probability and statistics"" by Morris H. DeGroot and Mark J. Schervish, on page 80, the conditional version of Bayes' theorem is given with no explanation: $$\Pr(B_i\mid A \cap C) = \dfrac{\Pr(B_i\mid C) \cdot \Pr(A\mid B_i \cap C)}{\sum (\Pr(B_i\mid C)\cdot \Pr(A\mid B_i \cap C))}$$ What is the intuition or mathematical proof behind this?","In the book ""Probability and statistics"" by Morris H. DeGroot and Mark J. Schervish, on page 80, the conditional version of Bayes' theorem is given with no explanation: What is the intuition or mathematical proof behind this?",\Pr(B_i\mid A \cap C) = \dfrac{\Pr(B_i\mid C) \cdot \Pr(A\mid B_i \cap C)}{\sum (\Pr(B_i\mid C)\cdot \Pr(A\mid B_i \cap C))},"['statistics', 'proof-writing', 'bayes-theorem']"
46,"Given every horse's probability of winning a race, what is the probability that a specific horse will finish 2nd and 3rd?","Given every horse's probability of winning a race, what is the probability that a specific horse will finish 2nd and 3rd?",,"This question is a follow-on from this question . I am trying to determine the probability of each horse finishing 2nd and each horse finishing 3rd. I have developed code to calculate the probabilities by implementing the formulas provided in the above mentioned question. Each horse is represented by a 'horseData' object containing variables such as the horse id (a unique number to identify the horse), the probability of winning (Pw), the probability of finishing 2nd (P2nd), the probability of finishing third (P3rd) among other variables. All of the HorseData objects are contained in a List called hdList. The following code implements the formula: $$ P(i,2)= \sum_{i \neq x} (P_x . \frac {P_i}{(1 - P_x)  }) $$ // Calc 2nd place for each horse for (HorseData hdi : hdList) {     for (HorseData hdx : hdList) {         if (hdi.id != hdx.id) {             term = hdx.Pw * hdi.Pw / (1 - hdx.Pw);             hd.addToP2nd(term);         }     } } This calculates the probability of finishing 2nd for each horse. The sum of these probabilities adds to one. All good so far. The following code implements the formula: $$ P(i,3)= \sum_{i \neq x \neq y}( P_x . P_{y2nd} .\frac {P_i}{(1 - P_x - P_{y2nd})  }) $$ // Calc prob 3rd place for each horse for (HorseData hdi : hdList) {     for (HorseData hdx : hdList) {         if (hdi.id != hdx.id) {             for (HorseData hdy : hdList) {                 if ((hdx.id != hdy.id) & (hdi.id != hdy.id)) {                     term = hdx.Pw * hdy.P2nd * hdi.Pw / (1 - hdx.Pw - hdy.P2nd);                     hd.addToP3rd(term);                 }             }         }     } } This calculates the probability of finishing 3rd for each horse. However the sum of these probabilities does not add to one. For testing, I have a 5 horse race, with the Pw = 0.2 for all horses. The code to calculate P2nd returns 0.2 for each horse, however the code to calculate P3rd returns 0.16 for each horse (whereas I think it should be 0.2). Any assistance in reviewing the formulas and the code implementation would be appreciated.","This question is a follow-on from this question . I am trying to determine the probability of each horse finishing 2nd and each horse finishing 3rd. I have developed code to calculate the probabilities by implementing the formulas provided in the above mentioned question. Each horse is represented by a 'horseData' object containing variables such as the horse id (a unique number to identify the horse), the probability of winning (Pw), the probability of finishing 2nd (P2nd), the probability of finishing third (P3rd) among other variables. All of the HorseData objects are contained in a List called hdList. The following code implements the formula: $$ P(i,2)= \sum_{i \neq x} (P_x . \frac {P_i}{(1 - P_x)  }) $$ // Calc 2nd place for each horse for (HorseData hdi : hdList) {     for (HorseData hdx : hdList) {         if (hdi.id != hdx.id) {             term = hdx.Pw * hdi.Pw / (1 - hdx.Pw);             hd.addToP2nd(term);         }     } } This calculates the probability of finishing 2nd for each horse. The sum of these probabilities adds to one. All good so far. The following code implements the formula: $$ P(i,3)= \sum_{i \neq x \neq y}( P_x . P_{y2nd} .\frac {P_i}{(1 - P_x - P_{y2nd})  }) $$ // Calc prob 3rd place for each horse for (HorseData hdi : hdList) {     for (HorseData hdx : hdList) {         if (hdi.id != hdx.id) {             for (HorseData hdy : hdList) {                 if ((hdx.id != hdy.id) & (hdi.id != hdy.id)) {                     term = hdx.Pw * hdy.P2nd * hdi.Pw / (1 - hdx.Pw - hdy.P2nd);                     hd.addToP3rd(term);                 }             }         }     } } This calculates the probability of finishing 3rd for each horse. However the sum of these probabilities does not add to one. For testing, I have a 5 horse race, with the Pw = 0.2 for all horses. The code to calculate P2nd returns 0.2 for each horse, however the code to calculate P3rd returns 0.16 for each horse (whereas I think it should be 0.2). Any assistance in reviewing the formulas and the code implementation would be appreciated.",,"['probability', 'statistics', 'conditional-probability']"
47,"Rating system for 2 vs 2, 2 vs 1 and 1 vs 1 game","Rating system for 2 vs 2, 2 vs 1 and 1 vs 1 game",,"We play football table in such configurations: 2 vs 2 players 2 vs 1 1 vs 1 Team (consisting of 1 or 2 players) wins the single game when they score 10th goal. I would like to introduce a rating system for individual players only. Teams are volatile, people freely pair with others, just depends who is near the table and who wants to play. I've read about Elo rating system , but it was designed for 1 vs 1 games, in which you can either win, draw or lose. In table football we have different players configurations and 20 different game outcomes: Winning 10:0, 10:1, ...,  10:9. Losing 0:10, 1:10, ..., 9:10. No draws. It could be made that we treat it like chess, i.e. only win or loss, but I think we drop too much information in such approach. Winning 10:0 is far better than winning 10:9. Can you propose a rating system dedicated for described table football game?","We play football table in such configurations: 2 vs 2 players 2 vs 1 1 vs 1 Team (consisting of 1 or 2 players) wins the single game when they score 10th goal. I would like to introduce a rating system for individual players only. Teams are volatile, people freely pair with others, just depends who is near the table and who wants to play. I've read about Elo rating system , but it was designed for 1 vs 1 games, in which you can either win, draw or lose. In table football we have different players configurations and 20 different game outcomes: Winning 10:0, 10:1, ...,  10:9. Losing 0:10, 1:10, ..., 9:10. No draws. It could be made that we treat it like chess, i.e. only win or loss, but I think we drop too much information in such approach. Winning 10:0 is far better than winning 10:9. Can you propose a rating system dedicated for described table football game?",,"['statistics', 'algorithms', 'scoring-algorithm']"
48,-ln(0.1) equalling to ln(10)?,-ln(0.1) equalling to ln(10)?,,I am having quite a headache wrapping my head around this solution. I do not understand the first line where they get lambda = ln(10) from statement to the left. Somebody please explain this to me. Ignore the problem itself please.,I am having quite a headache wrapping my head around this solution. I do not understand the first line where they get lambda = ln(10) from statement to the left. Somebody please explain this to me. Ignore the problem itself please.,,"['algebra-precalculus', 'statistics', 'logarithms']"
49,A random variable $X$ with differentiable distribution function has a density,A random variable  with differentiable distribution function has a density,X,"Setting: My professor defined A random variable $X: \Omega \to \mathbb{R}$ has a density $f:\mathbb{R} \to \mathbb{R}$ if for all $B \in \mathscr{B}$ $$P(X^{-1} (B)) = \int_\mathbb{R} 1_{B}(\lambda) f(\lambda) d\lambda.$$ Here $\mathscr B$ denotes the Borel- $\sigma$ -Algebra on $\mathbb{R}$ . My Problem: I have to prove that a random variable $X : \Omega \to \mathbb{R}$ with continuously differentiable distribution function $F$ has a density $f$ . What I did so far: Since $F$ is continuously differentiable, I set $f:=F'$ . Then $$ \int_\mathbb{R} 1_{(-\infty,c]} f(\lambda) d\lambda=\int_{-\infty}^cf(\lambda)d\lambda = F(c)-\lim_{c \to -\infty} F(c) = F(c) - \lim_{c \to -\infty} P(X\leq c)=F(c) = P(X^{-1}((-\infty,c]))$$ which shows the statement for sets of the form $B=(-\infty,c]$ . Where I failed: I can't show that this also holds for general $B \in \mathscr{B}$ . I know that the sets $(-\infty,c]$ constitute a basis for the Borel- $\sigma$ -Algebra but I don't know how to generalize the proof to more general Borel sets. Can someone give me a just a hint on how to start? Any help is much appreciated! P.S. I know that most books define ""density"" only by means of the sets $(-\infty,c]$ but my professor did not and I need to use his definitions.","Setting: My professor defined A random variable has a density if for all Here denotes the Borel- -Algebra on . My Problem: I have to prove that a random variable with continuously differentiable distribution function has a density . What I did so far: Since is continuously differentiable, I set . Then which shows the statement for sets of the form . Where I failed: I can't show that this also holds for general . I know that the sets constitute a basis for the Borel- -Algebra but I don't know how to generalize the proof to more general Borel sets. Can someone give me a just a hint on how to start? Any help is much appreciated! P.S. I know that most books define ""density"" only by means of the sets but my professor did not and I need to use his definitions.","X: \Omega \to \mathbb{R} f:\mathbb{R} \to \mathbb{R} B \in \mathscr{B} P(X^{-1} (B)) = \int_\mathbb{R} 1_{B}(\lambda) f(\lambda) d\lambda. \mathscr B \sigma \mathbb{R} X : \Omega \to \mathbb{R} F f F f:=F'  \int_\mathbb{R} 1_{(-\infty,c]} f(\lambda) d\lambda=\int_{-\infty}^cf(\lambda)d\lambda = F(c)-\lim_{c \to -\infty} F(c) = F(c) - \lim_{c \to -\infty} P(X\leq c)=F(c) = P(X^{-1}((-\infty,c])) B=(-\infty,c] B \in \mathscr{B} (-\infty,c] \sigma (-\infty,c]","['probability', 'statistics', 'stochastic-calculus']"
50,Show that $E(Y\mid X=x)$ is a linear function in $x$,Show that  is a linear function in,E(Y\mid X=x) x,"Let $Y$ and $X$ be bivariate normal distributed with expectationvector $\mu=(\mu_Y,\mu_X)^T$ and covariance matrix $\Sigma=\begin{pmatrix}\sigma_Y^2 & p_{XY}\\p_{XY} & \sigma_X^2\end{pmatrix}$. Show that the conditional expectation $E(Y\mid X=x)$ is a linear function in $x$. Hello! To my knowledge it is $$ E(Y\mid X=x)=\int_{\mathbb{R}}y\cdot f_{Y\mid X}(y\mid x)\, dy. $$ So first I tried to determine $f_{Y\mid X}(y\mid x)$ by $$ f_{Y\mid X}(y\mid x)=\frac{f_{Y,X}(y,x)}{f_X(x)}. $$ To my calculation this is $$ f_{Y\mid X}(y\mid x)=\frac{\sigma_X}{\sqrt{2\pi}\sqrt{\sigma_Y^2\sigma_X^2-p_{XY}^2}}\exp\left(-\frac{1}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}\cdot(\sigma_X^2(y-\mu_Y)^2-2p_{XY}(x-\mu_X)(y-\mu_Y)+\sigma_Y^2(x-\mu_X)^2)+\frac{1}{2}\frac{(x-\mu_X)^2}{\sigma_X^2}\right) $$ Is that right? In case it is: How can I know determine $$ \int y\cdot f_{Y\mid X}(y\mid x)\, dy, $$ i.e. how can I determine $$ \frac{\sigma_X}{\sqrt{2\pi}\sqrt{\sigma_Y^2\sigma_X^2-p_{XY}^2}}\int_{\mathbb{R}}y\cdot\exp\left(-\frac{1}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}\cdot(\sigma_X^2(y-\mu_Y)^2-2p_{XY}(x-\mu_X)(y-\mu_Y)+\sigma_Y^2(x-\mu_X)^2)+\frac{1}{2}\frac{(x-\mu_X)^2}{\sigma_X^2}\right)\, dy? $$ Edit: If I set  $$ c:=-\frac{\sigma_X^2}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}, d:=\frac{2p_{XY}(x-\mu_X)}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}, q:=\frac{\sigma_Y^2(x-\mu_X)^2}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)} $$ and $$ w:=\frac{(x-\mu_X)^2}{2\sigma_X^2} $$ then I have to calculate the following: $$ \frac{\sigma_X\exp(-q+w)}{\sqrt{2\pi}\sqrt{\sigma_Y^2\sigma_X^2-p_{XY}^2}}\int y\cdot\exp(c(y-\mu_Y)^2+d(y-\mu_Y))\, dy $$","Let $Y$ and $X$ be bivariate normal distributed with expectationvector $\mu=(\mu_Y,\mu_X)^T$ and covariance matrix $\Sigma=\begin{pmatrix}\sigma_Y^2 & p_{XY}\\p_{XY} & \sigma_X^2\end{pmatrix}$. Show that the conditional expectation $E(Y\mid X=x)$ is a linear function in $x$. Hello! To my knowledge it is $$ E(Y\mid X=x)=\int_{\mathbb{R}}y\cdot f_{Y\mid X}(y\mid x)\, dy. $$ So first I tried to determine $f_{Y\mid X}(y\mid x)$ by $$ f_{Y\mid X}(y\mid x)=\frac{f_{Y,X}(y,x)}{f_X(x)}. $$ To my calculation this is $$ f_{Y\mid X}(y\mid x)=\frac{\sigma_X}{\sqrt{2\pi}\sqrt{\sigma_Y^2\sigma_X^2-p_{XY}^2}}\exp\left(-\frac{1}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}\cdot(\sigma_X^2(y-\mu_Y)^2-2p_{XY}(x-\mu_X)(y-\mu_Y)+\sigma_Y^2(x-\mu_X)^2)+\frac{1}{2}\frac{(x-\mu_X)^2}{\sigma_X^2}\right) $$ Is that right? In case it is: How can I know determine $$ \int y\cdot f_{Y\mid X}(y\mid x)\, dy, $$ i.e. how can I determine $$ \frac{\sigma_X}{\sqrt{2\pi}\sqrt{\sigma_Y^2\sigma_X^2-p_{XY}^2}}\int_{\mathbb{R}}y\cdot\exp\left(-\frac{1}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}\cdot(\sigma_X^2(y-\mu_Y)^2-2p_{XY}(x-\mu_X)(y-\mu_Y)+\sigma_Y^2(x-\mu_X)^2)+\frac{1}{2}\frac{(x-\mu_X)^2}{\sigma_X^2}\right)\, dy? $$ Edit: If I set  $$ c:=-\frac{\sigma_X^2}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}, d:=\frac{2p_{XY}(x-\mu_X)}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)}, q:=\frac{\sigma_Y^2(x-\mu_X)^2}{2(\sigma_Y^2\sigma_X^2-p_{XY}^2)} $$ and $$ w:=\frac{(x-\mu_X)^2}{2\sigma_X^2} $$ then I have to calculate the following: $$ \frac{\sigma_X\exp(-q+w)}{\sqrt{2\pi}\sqrt{\sigma_Y^2\sigma_X^2-p_{XY}^2}}\int y\cdot\exp(c(y-\mu_Y)^2+d(y-\mu_Y))\, dy $$",,['statistics']
51,Source needed: Does asymptotic normality yield asymptotic unbiasedness and consistency?,Source needed: Does asymptotic normality yield asymptotic unbiasedness and consistency?,,"Assume that $$\sqrt{n}(\hat g - g(\theta)) \xrightarrow{d} Z, $$ where $Z$ is $N(0,\sigma^2)$. Does this already imply asymptotic unbiasedness and/or consistency, i.e., $$ E[\hat g] \rightarrow g(\theta) ~~~\mbox{and/or}~~~ \hat g \xrightarrow{P} g(\theta)?$$ I am aware of this post, but it does not answer my question as I do not know the distributions of $\hat g$ for finite $n$. Can anyone point to some literature that answers these questions positively or negatively? Any help is much appreciated!","Assume that $$\sqrt{n}(\hat g - g(\theta)) \xrightarrow{d} Z, $$ where $Z$ is $N(0,\sigma^2)$. Does this already imply asymptotic unbiasedness and/or consistency, i.e., $$ E[\hat g] \rightarrow g(\theta) ~~~\mbox{and/or}~~~ \hat g \xrightarrow{P} g(\theta)?$$ I am aware of this post, but it does not answer my question as I do not know the distributions of $\hat g$ for finite $n$. Can anyone point to some literature that answers these questions positively or negatively? Any help is much appreciated!",,"['statistics', 'probability-distributions', 'asymptotics', 'normal-distribution']"
52,Algorithm to find best in class of groups with weighting?,Algorithm to find best in class of groups with weighting?,,"I have widgets and a single widget will have attributes of: Name Weight (decimal from 0-1) Group (letter A-F) Price (an integer from 1 - 100) I must pick one widget from each Group (A-F) for a total of 6 widgets. How do I write an algorithm to find the 6 widgets that give me the aggregate highest Price while at the same time keeping the aggregate Weight less-than or equal to 1? Obviously, a lot of combinations will have an aggregate weight less than 1, but I need to come up with a way to get the combination that ALSO results in the highest Price. I suppose I could solve this with a Monte Carlo simulation, but I'm hoping there is a better way.","I have widgets and a single widget will have attributes of: Name Weight (decimal from 0-1) Group (letter A-F) Price (an integer from 1 - 100) I must pick one widget from each Group (A-F) for a total of 6 widgets. How do I write an algorithm to find the 6 widgets that give me the aggregate highest Price while at the same time keeping the aggregate Weight less-than or equal to 1? Obviously, a lot of combinations will have an aggregate weight less than 1, but I need to come up with a way to get the combination that ALSO results in the highest Price. I suppose I could solve this with a Monte Carlo simulation, but I'm hoping there is a better way.",,"['linear-algebra', 'statistics', 'monte-carlo']"
53,Poisson distrubution proof question.,Poisson distrubution proof question.,,"I was reading over the proof for the Poisson distribution and came across this sentence:  ""But since $$\left[1-\frac{\lambda}{n}\right]^n\rightarrow e^{-\lambda}$$ as $$n\rightarrow\infty$$, ..."" Can someone explain how they have arrived at that result and why the above term doesn't simply become $$1^n=1$$? By the way $$\lambda=np$$ where p is the probability and n is the number of data points.","I was reading over the proof for the Poisson distribution and came across this sentence:  ""But since $$\left[1-\frac{\lambda}{n}\right]^n\rightarrow e^{-\lambda}$$ as $$n\rightarrow\infty$$, ..."" Can someone explain how they have arrived at that result and why the above term doesn't simply become $$1^n=1$$? By the way $$\lambda=np$$ where p is the probability and n is the number of data points.",,"['calculus', 'probability', 'statistics']"
54,How would I solve this poker statistics question with an infinite deck?,How would I solve this poker statistics question with an infinite deck?,,"My professor threw out this question for the class as an extra credit question. I'm not asking for an answer, but rather, a nudge in the right direction to solve the problem. I'm currently stuck because this question is not discrete because it doesn't deal with a finite amount of stuff. I mean, sure, I could code a little program and let it run though a million simulations to figure it out, but there has to be some math behind it, right? The question: Suppose you have a truly shuffled deck of cards that is infinitely large and holds all 52 standard cards in equal probability (that is, each card has an equal chance of being drawn and the chance does not change at all if you draw any cards beforehand). Figure out the average amount of cards you have to draw (one at a time) before you get a 5-of-a-kind of anything (eg 5 As, 10s, Ks, etc).","My professor threw out this question for the class as an extra credit question. I'm not asking for an answer, but rather, a nudge in the right direction to solve the problem. I'm currently stuck because this question is not discrete because it doesn't deal with a finite amount of stuff. I mean, sure, I could code a little program and let it run though a million simulations to figure it out, but there has to be some math behind it, right? The question: Suppose you have a truly shuffled deck of cards that is infinitely large and holds all 52 standard cards in equal probability (that is, each card has an equal chance of being drawn and the chance does not change at all if you draw any cards beforehand). Figure out the average amount of cards you have to draw (one at a time) before you get a 5-of-a-kind of anything (eg 5 As, 10s, Ks, etc).",,['statistics']
55,evaluating moment generating functions [duplicate],evaluating moment generating functions [duplicate],,"This question already has an answer here : Finding the Moment Generating Function of $X^2$ when $X\sim N(0,1)$ (1 answer) Closed 3 years ago . Let $Z_1,Z_2,\ldots,Z_{14} $ be 14 independent N(0,1) variables, and let $Y=Z_1^2+Z_2^2+\cdots+Z_{14}^2$. Provide answers to the following to two decimal places. Evaluate the moment generating function $M_{Z^2_1}(t)$ of $Z_1^2$ at the point $t=0.14$ First I tried to find the new MGF for $Z^2_n$ $$M_{Z^2_1}(t)=E(e^{X^2t})$$ $$=\left(\frac1{\sqrt{2\pi}}\right)\int_{-\infty}^{\infty}e^{\left(\frac12\right)x^2(1-2t)} \, dx$$ then I have no idea how to integrate it....I know the solved integral and answer but don't know how to solve it","This question already has an answer here : Finding the Moment Generating Function of $X^2$ when $X\sim N(0,1)$ (1 answer) Closed 3 years ago . Let $Z_1,Z_2,\ldots,Z_{14} $ be 14 independent N(0,1) variables, and let $Y=Z_1^2+Z_2^2+\cdots+Z_{14}^2$. Provide answers to the following to two decimal places. Evaluate the moment generating function $M_{Z^2_1}(t)$ of $Z_1^2$ at the point $t=0.14$ First I tried to find the new MGF for $Z^2_n$ $$M_{Z^2_1}(t)=E(e^{X^2t})$$ $$=\left(\frac1{\sqrt{2\pi}}\right)\int_{-\infty}^{\infty}e^{\left(\frac12\right)x^2(1-2t)} \, dx$$ then I have no idea how to integrate it....I know the solved integral and answer but don't know how to solve it",,"['statistics', 'moment-generating-functions']"
56,Why is statistical properties of mode and median are difficult to determine?,Why is statistical properties of mode and median are difficult to determine?,,I have read a book saying that statistical properties of the mode and the median are difficult to determine compared to the mean. I am not entirely sure why is so. And the book does not provide further explanation. Is it correct that because the mean can be put into mathematical functions more easily compared to the mode and median? What does it mean by statistical properties? What does it mean by determining statistical properties? If anyone could provide more explanations or examples of some sort. Thanks for all the help!,I have read a book saying that statistical properties of the mode and the median are difficult to determine compared to the mean. I am not entirely sure why is so. And the book does not provide further explanation. Is it correct that because the mean can be put into mathematical functions more easily compared to the mode and median? What does it mean by statistical properties? What does it mean by determining statistical properties? If anyone could provide more explanations or examples of some sort. Thanks for all the help!,,"['statistics', 'descriptive-statistics']"
57,Maximum and minimum Correlation Coefficient,Maximum and minimum Correlation Coefficient,,"I have a question regarding the correlation coefficient. The inspiration is from a story where a student collected a set of $(X,Y)$ pairs, but lost the pairings. Hence, he is left with two sets of values of $X$ and $Y$. Say we have eight readings each and the values of $X$ are $\left\{ 4, 6, 7, 3, 3, 1, 9, 4\right\}$ and the the values of $Y$ are $\left\{ 4, 5, 2, 2, 4, 2,7, 9\right\}$. I am asked to find the highest and lowest possible correlation coefficient given these values. Now, the naive way to find this is to maximize and minimze $\mathbb E (XY)$ since $\rho_{X,Y}= (\mathbb E(XY) - \mathbb E (X) \mathbb E(Y))/\sigma_X \sigma_y$ and the respective (unconditioned, of course) means and variances are fixed. So what I did was to arrange the values of $X$ and $Y$ in ascending order, multiply the paired values to get $\mathbb E_{\text{max}} (XY) = 25.75$ and so $\rho_{X,Y_{\text{max}}}=0.9619$. To get the minimum, I multiply the minimum of $X$ with the maximum of $Y$ and move backwards up the list of $Y$ to get $\mathbb E_{\text{min}} (XY) = 15.13$ and so $\rho_{X,Y_{\text{min}}}=-0.891$. My question is that is there a more elegant way like a differentiation method to do so? I believe someone here could enlighten me. I do not feel comfortable with this result as it feels like I am brute forcing my way through, and cannot find a way to convincingly say the values are the maximum or minimum.","I have a question regarding the correlation coefficient. The inspiration is from a story where a student collected a set of $(X,Y)$ pairs, but lost the pairings. Hence, he is left with two sets of values of $X$ and $Y$. Say we have eight readings each and the values of $X$ are $\left\{ 4, 6, 7, 3, 3, 1, 9, 4\right\}$ and the the values of $Y$ are $\left\{ 4, 5, 2, 2, 4, 2,7, 9\right\}$. I am asked to find the highest and lowest possible correlation coefficient given these values. Now, the naive way to find this is to maximize and minimze $\mathbb E (XY)$ since $\rho_{X,Y}= (\mathbb E(XY) - \mathbb E (X) \mathbb E(Y))/\sigma_X \sigma_y$ and the respective (unconditioned, of course) means and variances are fixed. So what I did was to arrange the values of $X$ and $Y$ in ascending order, multiply the paired values to get $\mathbb E_{\text{max}} (XY) = 25.75$ and so $\rho_{X,Y_{\text{max}}}=0.9619$. To get the minimum, I multiply the minimum of $X$ with the maximum of $Y$ and move backwards up the list of $Y$ to get $\mathbb E_{\text{min}} (XY) = 15.13$ and so $\rho_{X,Y_{\text{min}}}=-0.891$. My question is that is there a more elegant way like a differentiation method to do so? I believe someone here could enlighten me. I do not feel comfortable with this result as it feels like I am brute forcing my way through, and cannot find a way to convincingly say the values are the maximum or minimum.",,"['statistics', 'correlation']"
58,Truncated Mean Squared,Truncated Mean Squared,,"Suppose that $X_{\sigma} \sim \mathcal{N}(\mu,\sigma^{2})$.   I am interested in whether $f(\sigma)=\mathbb{E} (X_{\sigma}^2 1_{\{X_{\sigma}>0\}})$ is monotonic in $\sigma$ for all $\mu$. I ran a Monte Carlo and it does appear monotonic but I can't rigourous prove it.","Suppose that $X_{\sigma} \sim \mathcal{N}(\mu,\sigma^{2})$.   I am interested in whether $f(\sigma)=\mathbb{E} (X_{\sigma}^2 1_{\{X_{\sigma}>0\}})$ is monotonic in $\sigma$ for all $\mu$. I ran a Monte Carlo and it does appear monotonic but I can't rigourous prove it.",,"['probability', 'statistics', 'normal-distribution']"
59,How to arrive at a specific formulation of the relative median deviation? Related to integration and statistics.,How to arrive at a specific formulation of the relative median deviation? Related to integration and statistics.,,"So my title is not very specific but here is the question in more detail. I am an economist currently working with this book: Frank Cowell - Measuring Inequality On page 25 a formulation of the relative mean deviation is given as follows: $$ M = 2 \left[ F\left(\bar{y}\right) - \Phi(\bar{y}) \right] $$ $F$ is the CDF, $\Phi$ is the proportion of total income received by persons who have an income less than or equal to $y$ ( per the book's definition: $\Phi=\frac{1}{\bar{y}} \int_0^y zdF(z)$), and $\bar{y}$ is the mean.  All this is also defined on page 152 in the appendix.  The appendix also gives a definition of $M$: $$ M = \int \left| \frac{y}{\bar{y}} -1\right|dF $$ The book says that the former formulation can be derived from the latter, but I have no idea how to begin with this. How do I perform the integration here and get to the first formulation? Any help would be greatly appreciated.","So my title is not very specific but here is the question in more detail. I am an economist currently working with this book: Frank Cowell - Measuring Inequality On page 25 a formulation of the relative mean deviation is given as follows: $$ M = 2 \left[ F\left(\bar{y}\right) - \Phi(\bar{y}) \right] $$ $F$ is the CDF, $\Phi$ is the proportion of total income received by persons who have an income less than or equal to $y$ ( per the book's definition: $\Phi=\frac{1}{\bar{y}} \int_0^y zdF(z)$), and $\bar{y}$ is the mean.  All this is also defined on page 152 in the appendix.  The appendix also gives a definition of $M$: $$ M = \int \left| \frac{y}{\bar{y}} -1\right|dF $$ The book says that the former formulation can be derived from the latter, but I have no idea how to begin with this. How do I perform the integration here and get to the first formulation? Any help would be greatly appreciated.",,"['calculus', 'probability', 'integration', 'statistics', 'probability-distributions']"
60,"Esoteric knowledge regarding statistic tests like $F$-test, $t$-test and $X^2$ (Chi-Square) etc.","Esoteric knowledge regarding statistic tests like -test, -test and  (Chi-Square) etc.",F t X^2,"For a year or two I've been doing/learning statistics using books written both for engineers and semi-professionals. I know how to apply most of the theory that statisticians use on job, but I'm still searching for answers why the theory behind statistics is the way it is. In books it is written when to use an $F$-test, $t$-test or $X^2$ (Chi-Square) etc. to solve problems, but the reason why these tests are used are never stated and the theory behind them is completely left out. Why are the theory that goes behind statistics so esoteric (hidden) ? Is it because it is very hard to understand ? Why are the theory / reasons for using these tests not shown in books ? Could someone tell me where to look up the theory, since doing something where you don't have the ""background"" knowledge seems unappealing to me.","For a year or two I've been doing/learning statistics using books written both for engineers and semi-professionals. I know how to apply most of the theory that statisticians use on job, but I'm still searching for answers why the theory behind statistics is the way it is. In books it is written when to use an $F$-test, $t$-test or $X^2$ (Chi-Square) etc. to solve problems, but the reason why these tests are used are never stated and the theory behind them is completely left out. Why are the theory that goes behind statistics so esoteric (hidden) ? Is it because it is very hard to understand ? Why are the theory / reasons for using these tests not shown in books ? Could someone tell me where to look up the theory, since doing something where you don't have the ""background"" knowledge seems unappealing to me.",,"['statistics', 'soft-question']"
61,"If X has beta distribution, how do you show that 1 - X also has beta distribution with parameters switched?","If X has beta distribution, how do you show that 1 - X also has beta distribution with parameters switched?",,This is problem presented to me: Suppose that $X$ has the beta distribution with parameters $\alpha$ and $\beta$. Show that $1 - X$ has the beta distribution with parameters $\beta$ and $\alpha$. Do you simply plug in $(1 - x)$ as $x$ into the beta distribution p.d.f.? Any help is greatly appreciated. Thanks.,This is problem presented to me: Suppose that $X$ has the beta distribution with parameters $\alpha$ and $\beta$. Show that $1 - X$ has the beta distribution with parameters $\beta$ and $\alpha$. Do you simply plug in $(1 - x)$ as $x$ into the beta distribution p.d.f.? Any help is greatly appreciated. Thanks.,,"['probability', 'statistics']"
62,unbiased estimator of the area of the circle,unbiased estimator of the area of the circle,,"the radius of a circle is measured with an error of measurement which is distributed normal with mean $0$ and variance $\sigma^2$ , $\sigma^2$ unknown.Given $n$ independent measurements of the radius , find an unbiased estimator of the area of the circle. By using Maximum Likelihood Estimator I found $$\hat\sigma^2=\frac{\sum e_i^2}{n}$$ where $r=r_o+e_i$ is the radius of the circle and $e_i\sim N(0,\sigma^2)$ . Then i am stucked to find the unbiased estimator of the area of the circle","the radius of a circle is measured with an error of measurement which is distributed normal with mean and variance , unknown.Given independent measurements of the radius , find an unbiased estimator of the area of the circle. By using Maximum Likelihood Estimator I found where is the radius of the circle and . Then i am stucked to find the unbiased estimator of the area of the circle","0 \sigma^2 \sigma^2 n \hat\sigma^2=\frac{\sum e_i^2}{n} r=r_o+e_i e_i\sim N(0,\sigma^2)","['statistics', 'normal-distribution', 'statistical-inference', 'estimation', 'sampling']"
63,Can you really tell the relationship between mean and median in a skewed graph?,Can you really tell the relationship between mean and median in a skewed graph?,,"In two old statistics textbooks, I found the following pictures:- Without any explanation, they both inferred the following:- When it is right skewed (as in fig. 3.2), mean > median. (And is the otherwise for the left skewed.) I wonder if the claim is always true? If it is, is there any simple proof? [By simple, I mean something like by inspection or simple logical reasoning but not deep into the statistical theory please.]","In two old statistics textbooks, I found the following pictures:- Without any explanation, they both inferred the following:- When it is right skewed (as in fig. 3.2), mean > median. (And is the otherwise for the left skewed.) I wonder if the claim is always true? If it is, is there any simple proof? [By simple, I mean something like by inspection or simple logical reasoning but not deep into the statistical theory please.]",,['statistics']
64,"Baseball, batting average, and probability","Baseball, batting average, and probability",,"A baseball player's batting average is equivalent to the probability he will get a hit for any given at-bat (at-bats don't include Errors, Walks, or HBP and a few other exceptions).  So for a specific player with a specific batting average, the probability that he will get a hit against an unknown pitcher is exactly equivalent to his batting average. Similar to the AVG statistic for hitters, pitchers have a statistic called Batting Average Against (BAA).  This statistic is calculated in the exact same way as hitters except it's done for a pitcher.  It's equivalent to Hits divided by At-Bats of opposing batmen (na na na na).  So for a specific pitcher with a specific BAA, the probability that he will allow a hit against an unknown batter is exactly equivalent to his batting average against. Intuitively, it seems obvious to me that a batter, no matter his personal batting average, is more likely to get a hit against a pitcher with a high BAA, and less likely to get a hit against a pitcher with a low BAA.  Additionally, a pitcher, no matter his own BAA, is more likely to allow a hit when facing a batter with a high AVG than when facing a batter with a low AVG. So the question is, given a specific batter with a specific AVG and a specific pitcher with a specific BAA, how do we calculate the probability that that specific batter will earn a Hit against that specific pitcher? EDIT: It's fair to assume we're talking about MLB, and we have an overwhelming wealth of extra information.  Assume we're talking about a batter with thousands of at-bats recorded, a pitcher with thousands of batters faced, and we know all the information about the average league AVG, average league BAA, etc., but this specific batter and this specific pitcher have never faced each other.  How would we calculate the probability of a Hit? EDIT2: Let's not get bogged down with vsLHP, vsRHP, RISP, and other statistics.  These are merely statistics that can be used to give a more accurate probability.  The method for calculating the probability should remain basically the same.  Let's just suppose we have Batter A who has an AVG of .300, and the average BAA of the pitchers he's faced (weighted to account for facing some pitchers more frequently etc) is .250.  And we have Pitcher B who has a BAA of .225, and the average AVG of the batters he's faced (again, weighted) is .250.  Batter A has never faced Pitcher B before, but both have thousands of At-Bats/Batters-Faced.  How do we calculate the probability of a Hit versus an Out?","A baseball player's batting average is equivalent to the probability he will get a hit for any given at-bat (at-bats don't include Errors, Walks, or HBP and a few other exceptions).  So for a specific player with a specific batting average, the probability that he will get a hit against an unknown pitcher is exactly equivalent to his batting average. Similar to the AVG statistic for hitters, pitchers have a statistic called Batting Average Against (BAA).  This statistic is calculated in the exact same way as hitters except it's done for a pitcher.  It's equivalent to Hits divided by At-Bats of opposing batmen (na na na na).  So for a specific pitcher with a specific BAA, the probability that he will allow a hit against an unknown batter is exactly equivalent to his batting average against. Intuitively, it seems obvious to me that a batter, no matter his personal batting average, is more likely to get a hit against a pitcher with a high BAA, and less likely to get a hit against a pitcher with a low BAA.  Additionally, a pitcher, no matter his own BAA, is more likely to allow a hit when facing a batter with a high AVG than when facing a batter with a low AVG. So the question is, given a specific batter with a specific AVG and a specific pitcher with a specific BAA, how do we calculate the probability that that specific batter will earn a Hit against that specific pitcher? EDIT: It's fair to assume we're talking about MLB, and we have an overwhelming wealth of extra information.  Assume we're talking about a batter with thousands of at-bats recorded, a pitcher with thousands of batters faced, and we know all the information about the average league AVG, average league BAA, etc., but this specific batter and this specific pitcher have never faced each other.  How would we calculate the probability of a Hit? EDIT2: Let's not get bogged down with vsLHP, vsRHP, RISP, and other statistics.  These are merely statistics that can be used to give a more accurate probability.  The method for calculating the probability should remain basically the same.  Let's just suppose we have Batter A who has an AVG of .300, and the average BAA of the pitchers he's faced (weighted to account for facing some pitchers more frequently etc) is .250.  And we have Pitcher B who has a BAA of .225, and the average AVG of the batters he's faced (again, weighted) is .250.  Batter A has never faced Pitcher B before, but both have thousands of At-Bats/Batters-Faced.  How do we calculate the probability of a Hit versus an Out?",,"['probability', 'statistics']"
65,Proving MLE for normal distribution,Proving MLE for normal distribution,,"I need to prove that using maximum likelihood estimation on both parameters of normal distribution indeed maximises likelihood function. So, the log-likelihood function for parameters $\sigma$ and $m$ is $$ \ln L = -\frac{n}{2}\ln2 \pi - n \ln \sigma - \sum_{i=1}^n\dfrac{1}{2\sigma^2}(x_i - m)^2 $$ After differentiating we get two equations $$ \dfrac{\partial \ln L}{\partial \sigma} = - \dfrac{n}{\sigma} +  \sum_{i=1}^n\dfrac{1}{\sigma^3}(x_i - m)^2 = 0$$ $$ \dfrac{\partial \ln L}{\partial m} = \sum_{i=1}^n\dfrac{1}{\sigma^2}(x_i - m) = 0 $$ And now we get the estimators: $$ m = \dfrac{\sum_{i=1}^n x_i}{n} $$ $$ \sigma = \sqrt{\dfrac{\sum_{i=1}^n\left(x_i - \dfrac{\sum_{i=1}^n x_i}{n}\right)^2}{n}}$$ Now I need to prove that this is local maximum. To do this I need to get second-order derivatives, and check that Hessian matrix is negative-definite. The derivatives are $$  A = \dfrac{\partial^2 \ln L}{\partial \sigma^2} = \dfrac{n}{\sigma^2} -  \sum_{i=1}^n\dfrac{3}{\sigma^4}(x_i - m)^2 = \dfrac{-2n^2}{\sum_{i=1}^n\left(x_i - \dfrac{\sum_{i=1}^n x_i}{n}\right)^2} $$ $$ C = \dfrac{\partial^2 \ln L}{\partial m^2} = -\dfrac{n}{\sigma^2} = -\dfrac{n^2}{\sum_{i=1}^n\left(x_i - \dfrac{\sum_{i=1}^n x_i}{n}\right)^2} $$ $$ B^2 = \left(\dfrac{\partial^2 \ln L}{\partial m \partial \sigma}\right)^2 =  \left(\dfrac{-2\sum_{i=1}^n (x_i-m)}{\sigma^3}\right)^2 = \dfrac{4\left[\sum_{i=1}^n\left(x_i - \dfrac{\sum_{i=1}^n x_i}{n}\right)\right]^2}{\left(\sum_{i=1}^n(x_i - m)^2\right)^3} $$ And that's where I get lost. I should prove that $AC - B^2 > 0$ but it doesn't look to me as something clearly positive.","I need to prove that using maximum likelihood estimation on both parameters of normal distribution indeed maximises likelihood function. So, the log-likelihood function for parameters $\sigma$ and $m$ is $$ \ln L = -\frac{n}{2}\ln2 \pi - n \ln \sigma - \sum_{i=1}^n\dfrac{1}{2\sigma^2}(x_i - m)^2 $$ After differentiating we get two equations $$ \dfrac{\partial \ln L}{\partial \sigma} = - \dfrac{n}{\sigma} +  \sum_{i=1}^n\dfrac{1}{\sigma^3}(x_i - m)^2 = 0$$ $$ \dfrac{\partial \ln L}{\partial m} = \sum_{i=1}^n\dfrac{1}{\sigma^2}(x_i - m) = 0 $$ And now we get the estimators: $$ m = \dfrac{\sum_{i=1}^n x_i}{n} $$ $$ \sigma = \sqrt{\dfrac{\sum_{i=1}^n\left(x_i - \dfrac{\sum_{i=1}^n x_i}{n}\right)^2}{n}}$$ Now I need to prove that this is local maximum. To do this I need to get second-order derivatives, and check that Hessian matrix is negative-definite. The derivatives are $$  A = \dfrac{\partial^2 \ln L}{\partial \sigma^2} = \dfrac{n}{\sigma^2} -  \sum_{i=1}^n\dfrac{3}{\sigma^4}(x_i - m)^2 = \dfrac{-2n^2}{\sum_{i=1}^n\left(x_i - \dfrac{\sum_{i=1}^n x_i}{n}\right)^2} $$ $$ C = \dfrac{\partial^2 \ln L}{\partial m^2} = -\dfrac{n}{\sigma^2} = -\dfrac{n^2}{\sum_{i=1}^n\left(x_i - \dfrac{\sum_{i=1}^n x_i}{n}\right)^2} $$ $$ B^2 = \left(\dfrac{\partial^2 \ln L}{\partial m \partial \sigma}\right)^2 =  \left(\dfrac{-2\sum_{i=1}^n (x_i-m)}{\sigma^3}\right)^2 = \dfrac{4\left[\sum_{i=1}^n\left(x_i - \dfrac{\sum_{i=1}^n x_i}{n}\right)\right]^2}{\left(\sum_{i=1}^n(x_i - m)^2\right)^3} $$ And that's where I get lost. I should prove that $AC - B^2 > 0$ but it doesn't look to me as something clearly positive.",,"['statistics', 'multivariable-calculus', 'normal-distribution']"
66,Does this quantity have a name in statistics?,Does this quantity have a name in statistics?,,I'm interested to know if there is some known statistical context for the following quantity $Q$: $$Q = \text{Mean} + \sqrt{(n-1)\cdot\text{Variance}}$$ where as usual $$\text{Mean} = \frac{\sum_{k=1}^n x_k}n$$ $$\text{Variance} =\frac{\sum_{k=1}^n (x_k - \text{Mean})^2}n$$ My co-worker says that $Q$ looks vaguely familiar from somewhere. Is $Q$ a known statistical quantity?,I'm interested to know if there is some known statistical context for the following quantity $Q$: $$Q = \text{Mean} + \sqrt{(n-1)\cdot\text{Variance}}$$ where as usual $$\text{Mean} = \frac{\sum_{k=1}^n x_k}n$$ $$\text{Variance} =\frac{\sum_{k=1}^n (x_k - \text{Mean})^2}n$$ My co-worker says that $Q$ looks vaguely familiar from somewhere. Is $Q$ a known statistical quantity?,,"['statistics', 'reference-request']"
67,"Poisson Distribution ,Expected Value, and $\lambda$","Poisson Distribution ,Expected Value, and",\lambda,"Suppose that our editor makes an average of two and one-half typographical errors per page.  You select a 30-page chapter on this text at random and let C denote the total number of typos in the chapter. (a)  Find $\mu_C$ Alright this looks like a really simple question, but I'm so confused.  It says in my text: Mean and Variance of a Poisson Random Variable Suppose that Z is a Poisson random variable with parameter $\lambda$ .  Then $E[Z]=Var[Z] =\lambda$ So $\mu_C$ is just the expected value and at first I thought the solution is just 2.5, but its really $2.5*30=75$ .  Can someone please explain what I am misunderstanding with lambda and the theorem in my book?  Thank you in advance.","Suppose that our editor makes an average of two and one-half typographical errors per page.  You select a 30-page chapter on this text at random and let C denote the total number of typos in the chapter. (a)  Find Alright this looks like a really simple question, but I'm so confused.  It says in my text: Mean and Variance of a Poisson Random Variable Suppose that Z is a Poisson random variable with parameter .  Then So is just the expected value and at first I thought the solution is just 2.5, but its really .  Can someone please explain what I am misunderstanding with lambda and the theorem in my book?  Thank you in advance.",\mu_C \lambda E[Z]=Var[Z] =\lambda \mu_C 2.5*30=75,"['probability', 'statistics']"
68,"Expected length of the ""greedy"" increasing sub-sequence?","Expected length of the ""greedy"" increasing sub-sequence?",,"Given a sequence of random unique integers of length $n$, if I select every element that is the largest so far how how many elements should I expect to select? This seems superficially similar to this problem but based on some trivial counter examples ($9,8,7,6,5,...$) has different results.","Given a sequence of random unique integers of length $n$, if I select every element that is the largest so far how how many elements should I expect to select? This seems superficially similar to this problem but based on some trivial counter examples ($9,8,7,6,5,...$) has different results.",,"['sequences-and-series', 'statistics', 'random']"
69,Gaussian Curve Fitting - Parameter Estimation,Gaussian Curve Fitting - Parameter Estimation,,"I was redirected here because someone in SO pointed out this is more of a math question than a programming question: I have to fit a Gaussian curve to a noisy set of data and then take it's FWHM for a certain application. I used MATLAB to demo the concept, and curve fitting in MATLAB is extremely easy. However, I eventually have to translate the code into Java/Android. I tried looking for libraries in Android that would help me fit a Gaussian curve to data set, but I couldn't find anything. Consequently, I started trying to learn all the math involved so I could do it manually. My question: How do I go about estimating the three parameters (center, width, height) for a single-term gaussian model? I tried looking into the Expectation-Maximization algorithm but that went way over my head. In general, I assume it would have something to do with error minimization? I'm just having trouble figuring out the step-by-step method of fitting a gaussian curve to my data. Thanks for the help! Alec EDIT: One of the things I tried already involved taking the natural log of my data, fitting a parabola to the result using LSQR, and then transforming back. However, the results I'm getting aren't accurate, probably because this method is biased in some way or another. If you don't know how to do parameter estimation, do you have any other suggestions of fitting a curve to my data? (Remember, it has to be manual since Android seems to be fairly limited on it's statistics libraries)","I was redirected here because someone in SO pointed out this is more of a math question than a programming question: I have to fit a Gaussian curve to a noisy set of data and then take it's FWHM for a certain application. I used MATLAB to demo the concept, and curve fitting in MATLAB is extremely easy. However, I eventually have to translate the code into Java/Android. I tried looking for libraries in Android that would help me fit a Gaussian curve to data set, but I couldn't find anything. Consequently, I started trying to learn all the math involved so I could do it manually. My question: How do I go about estimating the three parameters (center, width, height) for a single-term gaussian model? I tried looking into the Expectation-Maximization algorithm but that went way over my head. In general, I assume it would have something to do with error minimization? I'm just having trouble figuring out the step-by-step method of fitting a gaussian curve to my data. Thanks for the help! Alec EDIT: One of the things I tried already involved taking the natural log of my data, fitting a parabola to the result using LSQR, and then transforming back. However, the results I'm getting aren't accurate, probably because this method is biased in some way or another. If you don't know how to do parameter estimation, do you have any other suggestions of fitting a curve to my data? (Remember, it has to be manual since Android seems to be fairly limited on it's statistics libraries)",,"['statistics', 'estimation']"
70,Sum of two independent exponential functions,Sum of two independent exponential functions,,"Hey, I need a little help with this question. Let $X$ and $Y$ be independent, exponentially distributed random variables. What is the distribution of $Z=\frac X {X+Y}$? I just can't figure it out because of the sum on the denominator, thank you for your help.","Hey, I need a little help with this question. Let $X$ and $Y$ be independent, exponentially distributed random variables. What is the distribution of $Z=\frac X {X+Y}$? I just can't figure it out because of the sum on the denominator, thank you for your help.",,"['statistics', 'probability-distributions']"
71,Projections of multivariate normal distribution,Projections of multivariate normal distribution,,"Given a random vector X with the multivariate normal distribution F( X ), we know that, for two vectors a and b , the projections $A=\sum_j a_j X_j $  and  $B=\sum_i b_i X_i $ are univariate normal. I'm interested in the joint distribution of A and B. Is their joint distribution normal? Is the dependence between A and B described only by their correlation? (do they have only linear dependence?)  Thank you for any insight. References are highly appreciated as well.","Given a random vector X with the multivariate normal distribution F( X ), we know that, for two vectors a and b , the projections $A=\sum_j a_j X_j $  and  $B=\sum_i b_i X_i $ are univariate normal. I'm interested in the joint distribution of A and B. Is their joint distribution normal? Is the dependence between A and B described only by their correlation? (do they have only linear dependence?)  Thank you for any insight. References are highly appreciated as well.",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
72,Probability that we choose a two headed coin,Probability that we choose a two headed coin,,"We have a $501$ coins on the table, and assume that they have all been flipped onto that table (i.e., there is a mix of heads and tails). This also includes a two-headed coing. Now if we pick up $1$ coin and its heads, what is the probability it is also the two-headed coin? I've seen questions similar to this, but not the exact same. I did this out but want to hear your thoughts, before I explain how I arrived at the probability.","We have a $501$ coins on the table, and assume that they have all been flipped onto that table (i.e., there is a mix of heads and tails). This also includes a two-headed coing. Now if we pick up $1$ coin and its heads, what is the probability it is also the two-headed coin? I've seen questions similar to this, but not the exact same. I did this out but want to hear your thoughts, before I explain how I arrived at the probability.",,"['probability', 'statistics']"
73,How do I calculate typical group size?,How do I calculate typical group size?,,"If I have a set of groups of individuals (e.g. people), and I want to calculate the typical group size (as observed by individuals), how do I do this? Wikipedia refers to this as ""mean crowding"" or ""Typical Group Size"" but doesn't give a formula: http://en.wikipedia.org/wiki/Group_size_measures I believe the ""typical group size"" for a set of group sizes $\{a_1, a_2,..., a_n\}$ is simply: $$\sqrt{\frac{1}{n}\sum_{i=1}^na_i^2 }$$ i.e. the root mean square or quadratic mean. Is that correct? Is there a better way to characterise typical group size?","If I have a set of groups of individuals (e.g. people), and I want to calculate the typical group size (as observed by individuals), how do I do this? Wikipedia refers to this as ""mean crowding"" or ""Typical Group Size"" but doesn't give a formula: http://en.wikipedia.org/wiki/Group_size_measures I believe the ""typical group size"" for a set of group sizes $\{a_1, a_2,..., a_n\}$ is simply: $$\sqrt{\frac{1}{n}\sum_{i=1}^na_i^2 }$$ i.e. the root mean square or quadratic mean. Is that correct? Is there a better way to characterise typical group size?",,['statistics']
74,How to interpret summation signs,How to interpret summation signs,,"I'm taking a course in statistics, and I really need to brush up my math to be able to follow the book at times. I'm looking at formulas for sum of squares, and I am slightly confused about the capital sigma letter and how to interpret an equation with several signs like this: $$SS_a = \sum^a_{i=1} \sum^b_{j=1} \sum^n_{k=1} (\bar{X}_i - \bar{X})^2 $$ I mean, it's only i which is used  the summation signs, but when I try it out (ignoring b and n ) it seems like I get it wrong, and that it should be something like this: $ b * n * \sum^a_{i=1}(\bar{X}_i -\bar{X})^2 $ Is this correct, and what is the rule behind it? PS. I wasn't sure what tags really fits into this question, might it be basic algebra? DS","I'm taking a course in statistics, and I really need to brush up my math to be able to follow the book at times. I'm looking at formulas for sum of squares, and I am slightly confused about the capital sigma letter and how to interpret an equation with several signs like this: $$SS_a = \sum^a_{i=1} \sum^b_{j=1} \sum^n_{k=1} (\bar{X}_i - \bar{X})^2 $$ I mean, it's only i which is used  the summation signs, but when I try it out (ignoring b and n ) it seems like I get it wrong, and that it should be something like this: $ b * n * \sum^a_{i=1}(\bar{X}_i -\bar{X})^2 $ Is this correct, and what is the rule behind it? PS. I wasn't sure what tags really fits into this question, might it be basic algebra? DS",,"['statistics', 'notation']"
75,"Probability density function of $W = X + Y$ where $X \sim \mathrm{Unif}[0,1]$ and $Y \sim \mathrm{Exp}(\lambda)$ are independent random variables?",Probability density function of  where  and  are independent random variables?,"W = X + Y X \sim \mathrm{Unif}[0,1] Y \sim \mathrm{Exp}(\lambda)","This is the question that I was given: And this was the provided solution: I can't seem to make sense of it - firstly, what exactly is the question asking you to do? How did they know to divide the range of $w$ in that way? And why did they use those particular limits for the integrals?","This is the question that I was given: And this was the provided solution: I can't seem to make sense of it - firstly, what exactly is the question asking you to do? How did they know to divide the range of $w$ in that way? And why did they use those particular limits for the integrals?",,"['statistics', 'probability-distributions']"
76,"How do you calculate the probability of army loss in Risk, but with modifiers to dice?","How do you calculate the probability of army loss in Risk, but with modifiers to dice?",,"I was wondering how you can calculate the outcome of dice rolls in the board game Risk, but with modifiers, assuming 3 attackers and 2 defenders. In Risk the attacker rolls 3 dice, and the defender rolls 2. The highest two of each sets of dice (the attacker's and defender's) are compared, the highest to the highest, and the second highest to the second highest. If a die is higher than the one it is compared to, the opposing player loses a unit. The defender wins on a tie. Each player can lose up to two units this way, or each can lose one. I want to know how to calculate the probability if you add a value to the 1st, 2nd, or 3rd highest dice of each set. For example, how do the probabilities change if you add 2 to the attacker's 2nd highest die and add 1 to the defender's highest die, after the dice have already been paired for comparison. I would like to know how to calculate the odds when adding any value to any of the attacker's or defender's dice. Thanks in advance for anyone who can help me with this problem!","I was wondering how you can calculate the outcome of dice rolls in the board game Risk, but with modifiers, assuming 3 attackers and 2 defenders. In Risk the attacker rolls 3 dice, and the defender rolls 2. The highest two of each sets of dice (the attacker's and defender's) are compared, the highest to the highest, and the second highest to the second highest. If a die is higher than the one it is compared to, the opposing player loses a unit. The defender wins on a tie. Each player can lose up to two units this way, or each can lose one. I want to know how to calculate the probability if you add a value to the 1st, 2nd, or 3rd highest dice of each set. For example, how do the probabilities change if you add 2 to the attacker's 2nd highest die and add 1 to the defender's highest die, after the dice have already been paired for comparison. I would like to know how to calculate the odds when adding any value to any of the attacker's or defender's dice. Thanks in advance for anyone who can help me with this problem!",,"['probability', 'statistics', 'dice', 'bayes-theorem']"
77,What does it mean to take an integral of a probability?,What does it mean to take an integral of a probability?,,"My understanding is that you have some function $y=f(x)$ to represent a probability density function, correct? For instance for a uniform random variable it looks like a giant rectangular block. I don't really know what a density function tells you but for a uniform variable it's $1\over(b-a)$. I assumed this meant ""the probability that you 'land' in this area is $1\over(b-a)$"" but then I read that taking the integral of the density function gives you the probability? And then somehow I see that sometimes you can take the integral of the probability function, for example if you want to know the probability that the sum of n random variables exceeds x, it requires taking the integral of a probability function and so on and so forth. For example see http://mathworld.wolfram.com/UniformSumDistribution.html after the line ""while the sum of $n-1$ variates being less than 1 is."" I am getting lost in my understanding of what the integral of this and that represents. Is there a simple way to understand what is what, here?","My understanding is that you have some function $y=f(x)$ to represent a probability density function, correct? For instance for a uniform random variable it looks like a giant rectangular block. I don't really know what a density function tells you but for a uniform variable it's $1\over(b-a)$. I assumed this meant ""the probability that you 'land' in this area is $1\over(b-a)$"" but then I read that taking the integral of the density function gives you the probability? And then somehow I see that sometimes you can take the integral of the probability function, for example if you want to know the probability that the sum of n random variables exceeds x, it requires taking the integral of a probability function and so on and so forth. For example see http://mathworld.wolfram.com/UniformSumDistribution.html after the line ""while the sum of $n-1$ variates being less than 1 is."" I am getting lost in my understanding of what the integral of this and that represents. Is there a simple way to understand what is what, here?",,"['probability', 'statistics']"
78,Why is this Poisson distribution incorrect?,Why is this Poisson distribution incorrect?,,"Assume power failures occur independently of each other at a uniform rate through the months of the year, with little chance of $2$ or more occurring simultaneously. Suppose that $80\%$ of months have no power failures. What is the probability that a month has more than one power failure. I used a Poisson distribution with parameters $\lambda=0.2$ and $t=1$. Letting $X$ be the total number of failures in the month, I calculated $1-P(X=0)-P(X=1)$ and obtained $1-e^{-0.2}-0.2e^{-0.2}\approx 0.017523$. However, the book gives a solution of $0.0215$. Which step was I wrong?","Assume power failures occur independently of each other at a uniform rate through the months of the year, with little chance of $2$ or more occurring simultaneously. Suppose that $80\%$ of months have no power failures. What is the probability that a month has more than one power failure. I used a Poisson distribution with parameters $\lambda=0.2$ and $t=1$. Letting $X$ be the total number of failures in the month, I calculated $1-P(X=0)-P(X=1)$ and obtained $1-e^{-0.2}-0.2e^{-0.2}\approx 0.017523$. However, the book gives a solution of $0.0215$. Which step was I wrong?",,"['probability', 'statistics', 'probability-distributions']"
79,Integration with pdfs and cdfs,Integration with pdfs and cdfs,,"I was reading an article in econometrics when I stumbled upon an interesting thing. Essentially, what is done is this: $$ \int_\chi f(x)g(x)dx=\int_\chi f(x)dG(x) $$ where $x \in \chi$ and $G(x)=\int_{-\infty}^x g(t)dt$, i.e. the cdf of the pdf $g(x)$. I discussed this with a friend, and while it helped a little I haven't completely understood this yet. What does it mean to integrate with respect to $G(x)$, and does this equality hold in general? I think what confuses me is that it's not $dx$ anymore and the implication of that. If someone could 'prove' (show) this, then I would be grateful.","I was reading an article in econometrics when I stumbled upon an interesting thing. Essentially, what is done is this: $$ \int_\chi f(x)g(x)dx=\int_\chi f(x)dG(x) $$ where $x \in \chi$ and $G(x)=\int_{-\infty}^x g(t)dt$, i.e. the cdf of the pdf $g(x)$. I discussed this with a friend, and while it helped a little I haven't completely understood this yet. What does it mean to integrate with respect to $G(x)$, and does this equality hold in general? I think what confuses me is that it's not $dx$ anymore and the implication of that. If someone could 'prove' (show) this, then I would be grateful.",,"['calculus', 'statistics', 'integration']"
80,Minimize the coefficient of asymptotic normality,Minimize the coefficient of asymptotic normality,,"I need to minimize this complicated function: $$\dfrac{\Gamma(2x+1)-\Gamma(x+1)^2}{x^2 \Gamma(x+1)^2}$$ (For people wondering where this function came from — it's the (multiple of) coefficient of asymptotic normality of the estimator $\widehat{\alpha}$ for parameter $\alpha$ of exponential distribution obtained by method of moments using the sample function $t^x$ ($x$ is parameter here)). Since the coefficient of asymptotic normality must be positive, I need to find the minimum only for $x > -\dfrac{1}{2}$. Simple analysis shows that minimum exists, because function tends to infinity both at $x \rightarrow -\dfrac{1}{2}$ and $x \rightarrow \infty$. Consideration of only discrete arguments indicates that $\dfrac{(2k)! - (k!)^2}{k^2 (k!)^2}$ attains its minimum at $k = 1$. The graph also shows that $1$ has to be a minimum of this function. Is there a way to prove it analytically? Thank you in advance.","I need to minimize this complicated function: $$\dfrac{\Gamma(2x+1)-\Gamma(x+1)^2}{x^2 \Gamma(x+1)^2}$$ (For people wondering where this function came from — it's the (multiple of) coefficient of asymptotic normality of the estimator $\widehat{\alpha}$ for parameter $\alpha$ of exponential distribution obtained by method of moments using the sample function $t^x$ ($x$ is parameter here)). Since the coefficient of asymptotic normality must be positive, I need to find the minimum only for $x > -\dfrac{1}{2}$. Simple analysis shows that minimum exists, because function tends to infinity both at $x \rightarrow -\dfrac{1}{2}$ and $x \rightarrow \infty$. Consideration of only discrete arguments indicates that $\dfrac{(2k)! - (k!)^2}{k^2 (k!)^2}$ attains its minimum at $k = 1$. The graph also shows that $1$ has to be a minimum of this function. Is there a way to prove it analytically? Thank you in advance.",,"['calculus', 'statistics', 'gamma-function']"
81,Stochastic Process Examples,Stochastic Process Examples,,I was wondering if people could give me examples of how stochastic processes are seen and used in research in real life.,I was wondering if people could give me examples of how stochastic processes are seen and used in research in real life.,,"['probability', 'statistics', 'stochastic-processes', 'martingales']"
82,Request for Statistics textbook [duplicate],Request for Statistics textbook [duplicate],,"This question already has answers here : Recommend a statistics fundamentals book (6 answers) Closed 3 years ago . I am looking for a textbook on Statistical Analysis. Unfortunately most of the books I have seen, such as Statistics by DeGroot et al., are quite the opposite of the terse and lean textbooks I prefer (such as any book by Milnor). Can someone suggest to me an introductory or perhaps even intermediate statistics textbook which is under 300 pages. It can assume that I know measure theory but not much probability theory (though I doubt that would be necessary). The textbook should teach me enough statistical analysis as is required in an (Business/Financial) Analysts job. Thank you for the suggestions.","This question already has answers here : Recommend a statistics fundamentals book (6 answers) Closed 3 years ago . I am looking for a textbook on Statistical Analysis. Unfortunately most of the books I have seen, such as Statistics by DeGroot et al., are quite the opposite of the terse and lean textbooks I prefer (such as any book by Milnor). Can someone suggest to me an introductory or perhaps even intermediate statistics textbook which is under 300 pages. It can assume that I know measure theory but not much probability theory (though I doubt that would be necessary). The textbook should teach me enough statistical analysis as is required in an (Business/Financial) Analysts job. Thank you for the suggestions.",,"['statistics', 'reference-request']"
83,How to correct/filter inaccurate speeds calculated from a GPS track,How to correct/filter inaccurate speeds calculated from a GPS track,,"I am working on a simple application that allows the user to do a lot of different things with a GPX file (GPS track).  Some things computed are: average speed, max speed, etc.  The max speed values I'm getting are very unrealistic, and when I look at a plot of the data, it's clear that there are spikes that represent inaccuracies.  See the image below, which was a snowboarding run I did the other day... there are two spikes of ~57mph and 70mph, which I know are inaccurate. I'm a bit rusty on my statistics, but I know there are probably multiple approaches to filtering/smoothing/correcting this data to remove the erroneous values, while retaining the quality I desire. What is the best approach to accomplish that goal, and why? A quick explanation of how the values in the plot are generated: each point logged by the GPS unit contains latitude/longitude values and a time value.  Using the spherical law of cosines, the distance between any neighboring points in the track can be calculated, and that along with the time elapsed gives the average speed for the segment between those two points.  This is repeated for each set of neighboring points in the track to generate the plot above.  Obviously the inaccurate speed values are a result of positioning error from the GPS unit... if it logs me too far backward for one logged point, and then too far forward for the next point, the distance covered in that segment is calculated as much higher than it really was, and therefore so is my speed.  In the segment leading up to the highest spike in the plot above, I supposedly increased my speed from ~12mph to 70mph over a segment of 100ft.","I am working on a simple application that allows the user to do a lot of different things with a GPX file (GPS track).  Some things computed are: average speed, max speed, etc.  The max speed values I'm getting are very unrealistic, and when I look at a plot of the data, it's clear that there are spikes that represent inaccuracies.  See the image below, which was a snowboarding run I did the other day... there are two spikes of ~57mph and 70mph, which I know are inaccurate. I'm a bit rusty on my statistics, but I know there are probably multiple approaches to filtering/smoothing/correcting this data to remove the erroneous values, while retaining the quality I desire. What is the best approach to accomplish that goal, and why? A quick explanation of how the values in the plot are generated: each point logged by the GPS unit contains latitude/longitude values and a time value.  Using the spherical law of cosines, the distance between any neighboring points in the track can be calculated, and that along with the time elapsed gives the average speed for the segment between those two points.  This is repeated for each set of neighboring points in the track to generate the plot above.  Obviously the inaccurate speed values are a result of positioning error from the GPS unit... if it logs me too far backward for one logged point, and then too far forward for the next point, the distance covered in that segment is calculated as much higher than it really was, and therefore so is my speed.  In the segment leading up to the highest spike in the plot above, I supposedly increased my speed from ~12mph to 70mph over a segment of 100ft.",,['statistics']
84,Negative Binomial Question Without Exact Values,Negative Binomial Question Without Exact Values,,"The question I am working on is: Three brothers and their wives decide to have children until each family has two female children. What is the pmf $X=$ the total number of of male children born to the brothers?   What is E(X), and how does it compare to the expected   number of male children born to each brother? So, the probability that we have x amount of failures preceding the final birth, which will be the birth of the 6th girl, is $P(X=x) = nb(x;6,p(S)) = {{x+6-1}\choose{6-1}} \cdot[p(S)]^6 \cdot [p(F)]^x$ And the expected value would be $E(X)= \frac{6 \cdot p(F)}{p(S)}$ I know that this make be an incredulous claim, but I can't figure out why the answer to the very last question is 6. I know 6 represents the total number of girls among the three families, two per family, but what does the ratio of $\frac{p(F)}{p(S)}$ portray? Intuition tells me the number of boys in each family will be the same...","The question I am working on is: Three brothers and their wives decide to have children until each family has two female children. What is the pmf $X=$ the total number of of male children born to the brothers?   What is E(X), and how does it compare to the expected   number of male children born to each brother? So, the probability that we have x amount of failures preceding the final birth, which will be the birth of the 6th girl, is $P(X=x) = nb(x;6,p(S)) = {{x+6-1}\choose{6-1}} \cdot[p(S)]^6 \cdot [p(F)]^x$ And the expected value would be $E(X)= \frac{6 \cdot p(F)}{p(S)}$ I know that this make be an incredulous claim, but I can't figure out why the answer to the very last question is 6. I know 6 represents the total number of girls among the three families, two per family, but what does the ratio of $\frac{p(F)}{p(S)}$ portray? Intuition tells me the number of boys in each family will be the same...",,"['probability', 'statistics', 'probability-distributions']"
85,Taking the derivative of definite integral?,Taking the derivative of definite integral?,,"I'm having trouble understanding the derivative of definite integral. For example, why is the following true? $\frac{d}{dx}\displaystyle\int_{0}^{x}F_{1}(x-v)f_{1}(v)\, \mathrm{d}v = \displaystyle\int_{0}^{x}f_{1}(x-v)f_{1}(v)\, \mathrm{d}v $ I mean I know that $\frac{d}{dx}F_{1}(x) = f_{1}(x)$ by the fundamental theorem of calculus, but the example I gave confuses me...what if the integration limit $x$ is a constant? Doesn't the derivative then equal $0$? Could someone give me intuitive explanation? I understand it somehow, but I don't really get the intuition, perhaps the limits of integration or the notation confuses me... here is a link to my original question, where I was asking about the $\chi^2$-distribution: Help with understanding the $\chi^2$-distribution I'd be thankful if someone could maybe write it out step by step so I could see what's going on :)","I'm having trouble understanding the derivative of definite integral. For example, why is the following true? $\frac{d}{dx}\displaystyle\int_{0}^{x}F_{1}(x-v)f_{1}(v)\, \mathrm{d}v = \displaystyle\int_{0}^{x}f_{1}(x-v)f_{1}(v)\, \mathrm{d}v $ I mean I know that $\frac{d}{dx}F_{1}(x) = f_{1}(x)$ by the fundamental theorem of calculus, but the example I gave confuses me...what if the integration limit $x$ is a constant? Doesn't the derivative then equal $0$? Could someone give me intuitive explanation? I understand it somehow, but I don't really get the intuition, perhaps the limits of integration or the notation confuses me... here is a link to my original question, where I was asking about the $\chi^2$-distribution: Help with understanding the $\chi^2$-distribution I'd be thankful if someone could maybe write it out step by step so I could see what's going on :)",,"['probability', 'statistics', 'integration', 'derivatives', 'definite-integrals']"
86,"Basic Statistics Question (sample, normal distribution)","Basic Statistics Question (sample, normal distribution)",,"I am working on a question for an econometrics class that involves using the program Stata. It is as follows Suppose $X_i$, $i=1,2,...,n$ are i.i.d random variables, each distributed $N$($19,9$). Define $\bar{X}$ to be the mean value of the $n$ random variables. Find $Pr(19.5 \leq \bar{X} \leq 20)$ for $n=25$, $n=100$, $n=500$, and $n=1000$. What do you expect the value of $Pr(19.5 \leq \bar{X} \leq 20)$ would approach if $n$ were to approach infinity? How is this result related to the Law of Large Numbers? We are to use the normal() function in Stata to compute the probability. I want to check to see if my approach is correct. I believe that I use $$Z= \frac{\bar{X} - \mu}{\sigma /\sqrt{n}} $$ to standardize, with $\mu = 19$ and $\sigma = \sqrt{9}=3$. So, for the question, with $n=25$, I would use $$Pr(\frac{\bar{X} - \mu}{\sigma /\sqrt{n}} \leq \bar{X} \leq \frac{\bar{X} - \mu}{\sigma /\sqrt{n}})$$ $$Pr(\frac{19.5 - 19}{3 /\sqrt{25}} \leq \bar{X} \leq \frac{20 - 19}{3 /\sqrt{25}})$$ I would then repeat for the other values of $n$. Then I simply use the standardized values to find the probabilities with Stata's normal() function. This just involves putting a value in the brackets, for instance normal(1), which returns a value $.84134475$. I would expect the value of $Pr(19.5 \leq \bar{X} \leq 20)$ to approach $0$ as $n$  approaches infinity, because the sample mean should approach the population mean of 19.","I am working on a question for an econometrics class that involves using the program Stata. It is as follows Suppose $X_i$, $i=1,2,...,n$ are i.i.d random variables, each distributed $N$($19,9$). Define $\bar{X}$ to be the mean value of the $n$ random variables. Find $Pr(19.5 \leq \bar{X} \leq 20)$ for $n=25$, $n=100$, $n=500$, and $n=1000$. What do you expect the value of $Pr(19.5 \leq \bar{X} \leq 20)$ would approach if $n$ were to approach infinity? How is this result related to the Law of Large Numbers? We are to use the normal() function in Stata to compute the probability. I want to check to see if my approach is correct. I believe that I use $$Z= \frac{\bar{X} - \mu}{\sigma /\sqrt{n}} $$ to standardize, with $\mu = 19$ and $\sigma = \sqrt{9}=3$. So, for the question, with $n=25$, I would use $$Pr(\frac{\bar{X} - \mu}{\sigma /\sqrt{n}} \leq \bar{X} \leq \frac{\bar{X} - \mu}{\sigma /\sqrt{n}})$$ $$Pr(\frac{19.5 - 19}{3 /\sqrt{25}} \leq \bar{X} \leq \frac{20 - 19}{3 /\sqrt{25}})$$ I would then repeat for the other values of $n$. Then I simply use the standardized values to find the probabilities with Stata's normal() function. This just involves putting a value in the brackets, for instance normal(1), which returns a value $.84134475$. I would expect the value of $Pr(19.5 \leq \bar{X} \leq 20)$ to approach $0$ as $n$  approaches infinity, because the sample mean should approach the population mean of 19.",,['statistics']
87,Dependent Bernoulli trials,Dependent Bernoulli trials,,"The probability of a sequence of n independent Bernoulli trials can be easily expressed as $$p(x_1,...,x_n|p_1,...,p_n)=\prod_{i=1}^np_i^{x_i}(1-p_i)^{1-x_i}$$ but what if the trials are not independent? how would one express the probability to capture the dependence?","The probability of a sequence of n independent Bernoulli trials can be easily expressed as $$p(x_1,...,x_n|p_1,...,p_n)=\prod_{i=1}^np_i^{x_i}(1-p_i)^{1-x_i}$$ but what if the trials are not independent? how would one express the probability to capture the dependence?",,"['probability', 'combinatorics', 'statistics', 'probability-distributions', 'machine-learning']"
88,Calculating the Odds of Victory in Risk,Calculating the Odds of Victory in Risk,,"I am trying to write an odds calculator for risk that calculates the percentage chance of winning a combat between a number of given Attackers and given Defenders. The calculator will use basic risk rules, that is, the attacker roles dice equal to the number of attackers but no more than 3. The defender does the same but is limited to 2 dice. The resulting roles are sorted and then combat is determined by comparing the two top dice and removing them from the stack. The side with the lower die roll loses one troop. This process continues until one side wins. What I want to know is if their is an equation that can be used to solve this without creating the normal statistics tree. Creating that tree, while it works, becomes unmanageable after either side goes above 10 or more troops. My current solution is to simulate 100,000 combats and then take the number of times the Attacker wins/100,000 to get the percent chance of winning the combat. This solution also works, however, since it is based on random chance itself the results can be off by significant amounts. It also requires simulating a lot of combat. Is there some function I could use to calculate this result without having to use one of the previously mentioned solutions?","I am trying to write an odds calculator for risk that calculates the percentage chance of winning a combat between a number of given Attackers and given Defenders. The calculator will use basic risk rules, that is, the attacker roles dice equal to the number of attackers but no more than 3. The defender does the same but is limited to 2 dice. The resulting roles are sorted and then combat is determined by comparing the two top dice and removing them from the stack. The side with the lower die roll loses one troop. This process continues until one side wins. What I want to know is if their is an equation that can be used to solve this without creating the normal statistics tree. Creating that tree, while it works, becomes unmanageable after either side goes above 10 or more troops. My current solution is to simulate 100,000 combats and then take the number of times the Attacker wins/100,000 to get the percent chance of winning the combat. This solution also works, however, since it is based on random chance itself the results can be off by significant amounts. It also requires simulating a lot of combat. Is there some function I could use to calculate this result without having to use one of the previously mentioned solutions?",,"['probability', 'statistics']"
89,Where does the guassian function/normal or bell curve come from?,Where does the guassian function/normal or bell curve come from?,,"I am confused as to where the function for the normal distribtuion comes from.  Where does the e and pi come from?  In my textbook I am presented with the function,but I am unsure about where it came from.  I have spent hours on google and have yet to find a good proof that i can understand.  Come someone provide a source that shows an elementary proof of the normal curve function.","I am confused as to where the function for the normal distribtuion comes from.  Where does the e and pi come from?  In my textbook I am presented with the function,but I am unsure about where it came from.  I have spent hours on google and have yet to find a good proof that i can understand.  Come someone provide a source that shows an elementary proof of the normal curve function.",,"['statistics', 'normal-distribution']"
90,Interpreting Coin Toss Data. Biased or Not?,Interpreting Coin Toss Data. Biased or Not?,,"We have run an experiment in which some good chap has sat down and flipped a coin 100 times. At the end of the 100 flips he has tallied 40 Heads and 60 Tails. Now this seems like something is up with the coin. The question is whether or not this coin is biased. I have already determined that the mean p=1/2 and the standard deviation is 5. If we take the mean as a random variable of a normal distribution about the mean, then the experimental results we obtained are 2sigma from the mean. My first question is what does it mean if the results are outside one sigma? Next I proceeded to find the probability that the p-value of the getting a heads was instead 4/10. I used the function 100C40 *p^40 *(1-p)^60 and integrated this (dp) from 0.35 to 0.45. My result was 0.006. Now does this mean that the probability of getting a p is between 0.35 and 0.45 is 0.006 ? But I feel in this method I should be comparing this p against something. I suppose my problem really lies in interpreting the results and their meaning.","We have run an experiment in which some good chap has sat down and flipped a coin 100 times. At the end of the 100 flips he has tallied 40 Heads and 60 Tails. Now this seems like something is up with the coin. The question is whether or not this coin is biased. I have already determined that the mean p=1/2 and the standard deviation is 5. If we take the mean as a random variable of a normal distribution about the mean, then the experimental results we obtained are 2sigma from the mean. My first question is what does it mean if the results are outside one sigma? Next I proceeded to find the probability that the p-value of the getting a heads was instead 4/10. I used the function 100C40 *p^40 *(1-p)^60 and integrated this (dp) from 0.35 to 0.45. My result was 0.006. Now does this mean that the probability of getting a p is between 0.35 and 0.45 is 0.006 ? But I feel in this method I should be comparing this p against something. I suppose my problem really lies in interpreting the results and their meaning.",,"['probability', 'statistics']"
91,"Beta distribution, find the general expression for $E(X^{r}(1-X)^{s})$.","Beta distribution, find the general expression for .",E(X^{r}(1-X)^{s}),"I have the following question given to me about the beta distribution. I have been stuck on this one for hours now. Let $X$ have a beta distribution with parameters $\alpha$ and $\beta$, let $r$ and $s$ be given positive numbers. Find the general expression for $E(X^{r}(1-X)^{s})$. Beta distribution form I have been using is: $$\frac{\Gamma (\alpha +\beta )}{\Gamma (\alpha )\Gamma (\beta )}x^{\alpha -1}(1-x)^{\beta -1}\qquad\alpha >0, \beta >0$$ $x$ is between $0$ and $1$.","I have the following question given to me about the beta distribution. I have been stuck on this one for hours now. Let $X$ have a beta distribution with parameters $\alpha$ and $\beta$, let $r$ and $s$ be given positive numbers. Find the general expression for $E(X^{r}(1-X)^{s})$. Beta distribution form I have been using is: $$\frac{\Gamma (\alpha +\beta )}{\Gamma (\alpha )\Gamma (\beta )}x^{\alpha -1}(1-x)^{\beta -1}\qquad\alpha >0, \beta >0$$ $x$ is between $0$ and $1$.",,['statistics']
92,I am trying to prove the identity $ \sum_{k=m}^{n} k^{\downarrow m }{n \choose k} = n^{\downarrow m } 2^{n-m}$,I am trying to prove the identity, \sum_{k=m}^{n} k^{\downarrow m }{n \choose k} = n^{\downarrow m } 2^{n-m},"Prove algebraically $\sum_{k=m}^{n} k^{\downarrow m }{n \choose k} = n^{\downarrow m } 2^{n-m}$ I have an idea as to how to prove it when m = 1, but am having trouble otherwise. When m=1, we just have $\sum_{k=1}^{n} k^{\downarrow 1 }{n \choose k} = n^{\downarrow 1 } 2^{n-1} = n2^{n-1} $ I would appreciate any insight you guys could give would be appreciated.  I do understand the identity combinatorially but am having issues with the algebra. Longtime lurker, 1st time poster, so please forgive if I am not following proper protocol.","Prove algebraically $\sum_{k=m}^{n} k^{\downarrow m }{n \choose k} = n^{\downarrow m } 2^{n-m}$ I have an idea as to how to prove it when m = 1, but am having trouble otherwise. When m=1, we just have $\sum_{k=1}^{n} k^{\downarrow 1 }{n \choose k} = n^{\downarrow 1 } 2^{n-1} = n2^{n-1} $ I would appreciate any insight you guys could give would be appreciated.  I do understand the identity combinatorially but am having issues with the algebra. Longtime lurker, 1st time poster, so please forgive if I am not following proper protocol.",,"['probability', 'combinatorics', 'statistics']"
93,Closing 3 numbers,Closing 3 numbers,,"I have 3 numbers that physically must add up to zero.  Unfortunately, each is obtained from a noisy measurement and they don't add up exactly.  Assuming the noise is Gaussian and given 3 corresponding standard deviations (one for each number), what is the correct way to change the numbers so that they add up correctly?  It seems like the number with the smallest stdev should be moved least, etc... It feels like a least squares problem, and I think I can do this with an optimizer like Nelder Mead or something, but a closed form solution would be very welcome.","I have 3 numbers that physically must add up to zero.  Unfortunately, each is obtained from a noisy measurement and they don't add up exactly.  Assuming the noise is Gaussian and given 3 corresponding standard deviations (one for each number), what is the correct way to change the numbers so that they add up correctly?  It seems like the number with the smallest stdev should be moved least, etc... It feels like a least squares problem, and I think I can do this with an optimizer like Nelder Mead or something, but a closed form solution would be very welcome.",,"['statistics', 'optimization']"
94,Cumulative Distribution Function calculation,Cumulative Distribution Function calculation,,"I've got a question here that I've been working and I've ran into some difficulty. ""Let X be a mixed random variable with distribution function: F(x) = 0 if x < 0 cx + 1/4 if 0 <= x < 1 (c is some constant)     1/3  if 1 <= x <2     1    if x >= 2 As for my notation above, I'm unfamiliar with LaTex, but what I'm trying to show you is a piecewise function. Here <= means ""less than or equal to"". Now the question asks to find the value of c, given the expected value is 1. Here is what I have done: First, find the values of the probabilities at 0,1 and 2 Using limits, we find P(X=0) is 1/4. Similiarly, we find P(X=1) is 1/12 -c (here I subtracted c+1/4 from 1/3, using the idea of limits again) Finally, we find P(X=2) is 1- 1/3 = 2/3. Now, use these values to calculate the expected value: Here is where the confusion arises. First, I split the E[X] into three components: 1) the definite integral of d/dx [(cx + 1/4)times x] between 0 and 1 2) 1/12 - c times 1 3) 2 times 2/3 Now, I add these all up and equate: c/2 +4/3 +1/12 -c = 1, hence solving c = 5/6, however this leads to a negative probability for P(X=1), as 1/12 - 5/6 is less than zero. Where have I gone wrong in my above calculations? I think it's to do with my expected value calculation.","I've got a question here that I've been working and I've ran into some difficulty. ""Let X be a mixed random variable with distribution function: F(x) = 0 if x < 0 cx + 1/4 if 0 <= x < 1 (c is some constant)     1/3  if 1 <= x <2     1    if x >= 2 As for my notation above, I'm unfamiliar with LaTex, but what I'm trying to show you is a piecewise function. Here <= means ""less than or equal to"". Now the question asks to find the value of c, given the expected value is 1. Here is what I have done: First, find the values of the probabilities at 0,1 and 2 Using limits, we find P(X=0) is 1/4. Similiarly, we find P(X=1) is 1/12 -c (here I subtracted c+1/4 from 1/3, using the idea of limits again) Finally, we find P(X=2) is 1- 1/3 = 2/3. Now, use these values to calculate the expected value: Here is where the confusion arises. First, I split the E[X] into three components: 1) the definite integral of d/dx [(cx + 1/4)times x] between 0 and 1 2) 1/12 - c times 1 3) 2 times 2/3 Now, I add these all up and equate: c/2 +4/3 +1/12 -c = 1, hence solving c = 5/6, however this leads to a negative probability for P(X=1), as 1/12 - 5/6 is less than zero. Where have I gone wrong in my above calculations? I think it's to do with my expected value calculation.",,[]
95,Statistics - Confidence Interval for a Population Proportion Formula,Statistics - Confidence Interval for a Population Proportion Formula,,"I am having a conceptual hard time understanding where this formula came from. It does not seem to make any sense to me. Could someone shed some light on this: ""The natural estimator p is $\hat p = \frac{X}{n}$, the same fraction of success. Since $\hat p$ is just $X$ multiplied by a constant, $\hat p$ has an approximately normal distribution. $E(\hat p) = p$ and $\sigma_{\hat p} = \sqrt{\frac{p(1-p)}{n}}$. Standardizing, this implies that: $$P\left(-z_{\alpha/2} < \frac{\hat p- p}{\sqrt{p(1-p)/n}} < z_{\alpha/2}\right) \approx 1 - \alpha $$"" Could someone derive this equation so that it makes sense to someone who's never seen this before?","I am having a conceptual hard time understanding where this formula came from. It does not seem to make any sense to me. Could someone shed some light on this: ""The natural estimator p is $\hat p = \frac{X}{n}$, the same fraction of success. Since $\hat p$ is just $X$ multiplied by a constant, $\hat p$ has an approximately normal distribution. $E(\hat p) = p$ and $\sigma_{\hat p} = \sqrt{\frac{p(1-p)}{n}}$. Standardizing, this implies that: $$P\left(-z_{\alpha/2} < \frac{\hat p- p}{\sqrt{p(1-p)/n}} < z_{\alpha/2}\right) \approx 1 - \alpha $$"" Could someone derive this equation so that it makes sense to someone who's never seen this before?",,['statistics']
96,Finding the covariance,Finding the covariance,,"Can you help me find the covariance of $\mathrm{Cov}(5X+3Y, 7X-Y)$  I've been looking up formulas all day and I can not find on that adds both x and y just constants.  Thank you! $Mx=2, My=7, \mathrm{Var}X=4, \mathrm{Var} Y=9$, and $\mathrm{Cov}(X,Y)=-2$","Can you help me find the covariance of $\mathrm{Cov}(5X+3Y, 7X-Y)$  I've been looking up formulas all day and I can not find on that adds both x and y just constants.  Thank you! $Mx=2, My=7, \mathrm{Var}X=4, \mathrm{Var} Y=9$, and $\mathrm{Cov}(X,Y)=-2$",,['statistics']
97,Bayes point estimate using mode of a Gamma posterior distribution,Bayes point estimate using mode of a Gamma posterior distribution,,"Let's say the posterior distribution of $\theta$ is Gamma with $$\alpha = 40, \qquad \beta = \frac{1}{0.5 + \sum_{i = 1}^{10} X_i}$$ What is the Bayes point estimate using the mode of the posterior distribution?","Let's say the posterior distribution of $\theta$ is Gamma with $$\alpha = 40, \qquad \beta = \frac{1}{0.5 + \sum_{i = 1}^{10} X_i}$$ What is the Bayes point estimate using the mode of the posterior distribution?",,"['probability', 'statistics']"
98,Statistics: Minimized parameters of an error function in regression,Statistics: Minimized parameters of an error function in regression,,"My question today is about the minimization of an error function with two parameters. It is a function that measures the error of a set of points. The two parameters are the weights of a regressor. $$\frac{1}{N}\sum_{t=1}^{N}[r^t-(w_1x^t+w_0)]^2$$ The minimum should be calculated by taking partial derivates of the error function above with respect to $w_1$ and $w_0$. Setting them equal to $0$ and solving for the unknown. However I didn't reach the solutions given. The solutions should be: $$w_1=\frac{\sum_tx^tr^t-\sum_t\frac{x^t}{N}\sum_t\frac{r^t}{N}N}{\sum_t(x^t)^2-N(\sum_t\frac{x^t}{N})^2}$$ $$w_0=\sum_t\frac{r^t}{N}-w_1\sum^t\frac{x^t}{N}$$ They are performing well in practice. But my question is, can I reach them by taking the partial derivatives and setting them equal to $0$? Can anybody help me, at least with one? Thank you. UPDATE: This is the regressor I get by using the $w_1$ and $w_0$ listed above. As you can see, the two model the data very well so they must be right. UPDATE 2: I will post the passage from the book that lists $w_1$ and $w_0$ as the solution. Maybe you'll get the idea better.","My question today is about the minimization of an error function with two parameters. It is a function that measures the error of a set of points. The two parameters are the weights of a regressor. $$\frac{1}{N}\sum_{t=1}^{N}[r^t-(w_1x^t+w_0)]^2$$ The minimum should be calculated by taking partial derivates of the error function above with respect to $w_1$ and $w_0$. Setting them equal to $0$ and solving for the unknown. However I didn't reach the solutions given. The solutions should be: $$w_1=\frac{\sum_tx^tr^t-\sum_t\frac{x^t}{N}\sum_t\frac{r^t}{N}N}{\sum_t(x^t)^2-N(\sum_t\frac{x^t}{N})^2}$$ $$w_0=\sum_t\frac{r^t}{N}-w_1\sum^t\frac{x^t}{N}$$ They are performing well in practice. But my question is, can I reach them by taking the partial derivatives and setting them equal to $0$? Can anybody help me, at least with one? Thank you. UPDATE: This is the regressor I get by using the $w_1$ and $w_0$ listed above. As you can see, the two model the data very well so they must be right. UPDATE 2: I will post the passage from the book that lists $w_1$ and $w_0$ as the solution. Maybe you'll get the idea better.",,"['statistics', 'derivatives']"
99,Discrete Probability Problem: determining probability mass function and cumulative distribution function,Discrete Probability Problem: determining probability mass function and cumulative distribution function,,"Three couples and two single individuals have been invited to an investment seminar and have agreed to attend. Suppose the probability that any particular couple or individual arrives late is .4 (a couple will travel together in the same vehicle, so either both people will be on time or else both will arrive late). Assume that different couples and individuals are on time or late independently of one another. Let X = the number of people who arrive late for the seminar. a) Determine the probability mass function of X. [Hint: label the three couples #1, #2, and #3, and the two individuals #4 and #5.] b) Obtain the cumulative distribution function of X, and use it to calculate P(2 <= X <= 6).","Three couples and two single individuals have been invited to an investment seminar and have agreed to attend. Suppose the probability that any particular couple or individual arrives late is .4 (a couple will travel together in the same vehicle, so either both people will be on time or else both will arrive late). Assume that different couples and individuals are on time or late independently of one another. Let X = the number of people who arrive late for the seminar. a) Determine the probability mass function of X. [Hint: label the three couples #1, #2, and #3, and the two individuals #4 and #5.] b) Obtain the cumulative distribution function of X, and use it to calculate P(2 <= X <= 6).",,"['probability', 'statistics', 'probability-distributions']"
