,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Non-abelian group with infinitely many abelian subgroups,Non-abelian group with infinitely many abelian subgroups,,I'm looking for a non-abelian group which has infinitely many abelian subgroups. Do you know any examples of such groups?,I'm looking for a non-abelian group which has infinitely many abelian subgroups. Do you know any examples of such groups?,,"['abstract-algebra', 'group-theory', 'examples-counterexamples', 'abelian-groups']"
1,"Is any finite-dimensional extension of a field, say $F$, algebraic and finitely generated?","Is any finite-dimensional extension of a field, say , algebraic and finitely generated?",F,"As title,  Is any finite-dimensional extension of a field, say $F$, algebraic and finitely generated? Say if $K/F$ is a finite extension when $K$ is a finite-dimensional vector space of $F$. Clearly, this implies that $K$ is finitely generated (as an algebra) over $F$, since a basis is a generating set. So every finite extension is finitely generated. So indeed they all are, is my logic correct?","As title,  Is any finite-dimensional extension of a field, say $F$, algebraic and finitely generated? Say if $K/F$ is a finite extension when $K$ is a finite-dimensional vector space of $F$. Clearly, this implies that $K$ is finitely generated (as an algebra) over $F$, since a basis is a generating set. So every finite extension is finitely generated. So indeed they all are, is my logic correct?",,"['abstract-algebra', 'field-theory', 'extension-field']"
2,"A binary operation, closed over the reals, that is associative, but not commutative","A binary operation, closed over the reals, that is associative, but not commutative",,"I am aware that matrix multiplication as well as function composition is associative, but not commutative, but are there any other binary operations, specifically that are closed over the reals, that holds this property? And can you give a specific example?","I am aware that matrix multiplication as well as function composition is associative, but not commutative, but are there any other binary operations, specifically that are closed over the reals, that holds this property? And can you give a specific example?",,"['abstract-algebra', 'group-theory', 'functions', 'examples-counterexamples', 'associativity']"
3,Non-distributive fields?,Non-distributive fields?,,"I am thinking about construction of a structure that ""obeys"" all of the axioms for a field except an axiom of distributivity of multiplication over addition, and I am not sure is that possible at all? I mean, it ought to be possible, because, it seems that an axiom of distributivity is not necessarily redundant in a sense that it is implied by other axioms of a field. But I am really really not sure. Do you have somewhere already an example of such a structure, it could even be some familiar field with addition and multiplication specially defined to suit the purpose.","I am thinking about construction of a structure that ""obeys"" all of the axioms for a field except an axiom of distributivity of multiplication over addition, and I am not sure is that possible at all? I mean, it ought to be possible, because, it seems that an axiom of distributivity is not necessarily redundant in a sense that it is implied by other axioms of a field. But I am really really not sure. Do you have somewhere already an example of such a structure, it could even be some familiar field with addition and multiplication specially defined to suit the purpose.",,"['abstract-algebra', 'field-theory']"
4,Why is the fact that a quotient group is a group relevant?,Why is the fact that a quotient group is a group relevant?,,"I'm studying the basics of quotient groups. I understand that if you build a quotient set from cosets of a group and the subgroup you are using to build them is normal then you end up with a group. I fail to see why the fact that we can define operations in the quotient set and make it into a group is meaningful. What is the motivation to do it? Either historical perspective, practical perspective or any other to understand why we care about this is welcome.","I'm studying the basics of quotient groups. I understand that if you build a quotient set from cosets of a group and the subgroup you are using to build them is normal then you end up with a group. I fail to see why the fact that we can define operations in the quotient set and make it into a group is meaningful. What is the motivation to do it? Either historical perspective, practical perspective or any other to understand why we care about this is welcome.",,"['abstract-algebra', 'group-theory', 'soft-question', 'motivation', 'quotient-group']"
5,Is the homomorphic image of an ideal an ideal?,Is the homomorphic image of an ideal an ideal?,,"Let $f:A\to B $ be a homomorphism between the rings $A$ and $B$ and let $J$ be an ideal of $A$, then $f(J)$ is an ideal of $B$. If $f(x)\in f(J)$ and $f(y)\in B$ then $f(x)f(y)=f(xy)$ and since $x\in J$ then $xy\in J$ and therefore $f(x)f(y)\in f(J)$. For $f(x),f(y) \in f(J)$ then $f(x)-f(y)=f(x-y)\in f(J)$ since $x,y \in J$ and $J$ is closed under subtraction. However, nowhere in this proof did I use the fact that $\text {ker} f \subset J$, which was a part of the problem statement, leading me to believe that my proof is wrong or incomplete. I cannot see my mistake, are there hidden assumptions I am making?","Let $f:A\to B $ be a homomorphism between the rings $A$ and $B$ and let $J$ be an ideal of $A$, then $f(J)$ is an ideal of $B$. If $f(x)\in f(J)$ and $f(y)\in B$ then $f(x)f(y)=f(xy)$ and since $x\in J$ then $xy\in J$ and therefore $f(x)f(y)\in f(J)$. For $f(x),f(y) \in f(J)$ then $f(x)-f(y)=f(x-y)\in f(J)$ since $x,y \in J$ and $J$ is closed under subtraction. However, nowhere in this proof did I use the fact that $\text {ker} f \subset J$, which was a part of the problem statement, leading me to believe that my proof is wrong or incomplete. I cannot see my mistake, are there hidden assumptions I am making?",,"['abstract-algebra', 'ring-theory']"
6,"If $f(x) \in \mathbb{Q}[x]$ is irreducible, then is $f(x^2)$irreducible?","If  is irreducible, then is irreducible?",f(x) \in \mathbb{Q}[x] f(x^2),"I found a set of practice questions, one of which asks whether or not $f(x) \in \mathbb{Q}[x]$ irreducible implies $f(x^2)$ irreducible. Is this true? I'm having trouble thinking of a counterexample. Is there an irreducibility criterion that we could use?","I found a set of practice questions, one of which asks whether or not $f(x) \in \mathbb{Q}[x]$ irreducible implies $f(x^2)$ irreducible. Is this true? I'm having trouble thinking of a counterexample. Is there an irreducibility criterion that we could use?",,['abstract-algebra']
7,Quick way to show a finite field always has prime power order? [duplicate],Quick way to show a finite field always has prime power order? [duplicate],,This question already has answers here : Closed 11 years ago . Possible Duplicate: Order of finite fields is $p^n$ Is there a quick way to prove that finite fields always have cardinality that is the power of a prime p?,This question already has answers here : Closed 11 years ago . Possible Duplicate: Order of finite fields is $p^n$ Is there a quick way to prove that finite fields always have cardinality that is the power of a prime p?,,"['abstract-algebra', 'field-theory', 'finite-fields']"
8,Congruent Modulo $n$: definition,Congruent Modulo : definition,n,"In an Introduction to Abstract Algebra by Thomas Whitelaw, he gives examples of the congruence mod operation, such as $13 \equiv5 \pmod4$,  and $9 \equiv -1 \pmod 5$. But when I first learned about the modulo operation my junior year, I would have told you that $13 \equiv 1 \pmod 4$, and that $9 \equiv 4 \pmod 5$. Is this just a difference in the definition of modulo? Or is this pretty typical (to not take it to the largest factor, or one over)?","In an Introduction to Abstract Algebra by Thomas Whitelaw, he gives examples of the congruence mod operation, such as $13 \equiv5 \pmod4$,  and $9 \equiv -1 \pmod 5$. But when I first learned about the modulo operation my junior year, I would have told you that $13 \equiv 1 \pmod 4$, and that $9 \equiv 4 \pmod 5$. Is this just a difference in the definition of modulo? Or is this pretty typical (to not take it to the largest factor, or one over)?",,"['abstract-algebra', 'elementary-number-theory', 'modular-arithmetic', 'definition']"
9,"If $a$ commutes with $b$, does $a^{-1}$ commute with $b$?","If  commutes with , does  commute with ?",a b a^{-1} b,"$a,b$ are group elements. If $a$ commutes with $b$, does $a^{-1}$ commute with $b$? And how can I prove this?","$a,b$ are group elements. If $a$ commutes with $b$, does $a^{-1}$ commute with $b$? And how can I prove this?",,"['abstract-algebra', 'group-theory']"
10,How to prove that algebraic numbers form a field? [duplicate],How to prove that algebraic numbers form a field? [duplicate],,"This question already has answers here : How to prove that the sum and product of two algebraic numbers is algebraic? [duplicate] (5 answers) Closed 3 years ago . I'd like to know how to prove that algebraic numbers form a field by using Kronecker Product, but not sure exactly how to do it. Edit: This question is different from the suggested duplicated one in that this question asks for an answer to prove that algebraic numbers form a field in unconventional ways such as using Kronecker Product. As the result, answers are very different from the one suggested duplicated. So this question deserves to remain open.","This question already has answers here : How to prove that the sum and product of two algebraic numbers is algebraic? [duplicate] (5 answers) Closed 3 years ago . I'd like to know how to prove that algebraic numbers form a field by using Kronecker Product, but not sure exactly how to do it. Edit: This question is different from the suggested duplicated one in that this question asks for an answer to prove that algebraic numbers form a field in unconventional ways such as using Kronecker Product. As the result, answers are very different from the one suggested duplicated. So this question deserves to remain open.",,"['abstract-algebra', 'field-theory', 'splitting-field']"
11,Is the difference between additive groups and multiplicative groups just a matter of notation?,Is the difference between additive groups and multiplicative groups just a matter of notation?,,"Groups are sometimes written additively, like $(G,+)$ , and sometimes they are written multiplicatively, like $(G,\times)$ . But is there really a difference? Is it all just a matter of notation, nothing more? If it is something beyond notation, what is the difference, exactly?","Groups are sometimes written additively, like , and sometimes they are written multiplicatively, like . But is there really a difference? Is it all just a matter of notation, nothing more? If it is something beyond notation, what is the difference, exactly?","(G,+) (G,\times)","['abstract-algebra', 'group-theory', 'notation']"
12,$\mathbb{Z}[X]/(X^2-1)$ is not isomorphic with $\mathbb{Z}\times \mathbb{Z}$,is not isomorphic with,\mathbb{Z}[X]/(X^2-1) \mathbb{Z}\times \mathbb{Z},"I have to show that the ring $\mathbb{Z}[X]/(X^2-1)$ is not isomorphic with $\mathbb{Z}\times \mathbb{Z}$ . I know that $(\mathbb{Z}\times\mathbb{Z})^*=\{(\pm1,\pm1)\}$ , so I thought I should be looking for elements which have inverses in $\mathbb{Z}[X]/(X^2-1)$ and hopefully find more or less than 4. But I didn't succeed, so I need hints. Thanks.","I have to show that the ring is not isomorphic with . I know that , so I thought I should be looking for elements which have inverses in and hopefully find more or less than 4. But I didn't succeed, so I need hints. Thanks.","\mathbb{Z}[X]/(X^2-1) \mathbb{Z}\times \mathbb{Z} (\mathbb{Z}\times\mathbb{Z})^*=\{(\pm1,\pm1)\} \mathbb{Z}[X]/(X^2-1)","['abstract-algebra', 'ring-theory']"
13,Are abelian subgroups normal?,Are abelian subgroups normal?,,"Let $G$ be a group, and let $H < G$ be such that all the elements of $H$ commute with each other, i.e. $H$ is abelian. Then is $H$ necessarily normal in $G$, i.e. $H \unlhd G$?","Let $G$ be a group, and let $H < G$ be such that all the elements of $H$ commute with each other, i.e. $H$ is abelian. Then is $H$ necessarily normal in $G$, i.e. $H \unlhd G$?",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'normal-subgroups']"
14,"Finite field, every element is a square implies char equal 2","Finite field, every element is a square implies char equal 2",,"If $F$ is a finite field such that every element is a square, why must $char(F)=2$?","If $F$ is a finite field such that every element is a square, why must $char(F)=2$?",,['abstract-algebra']
15,Product of two ideals doesn't equal the intersection,Product of two ideals doesn't equal the intersection,,"The product of two ideals is defined as the set of all finite sums $\sum  f_i  g_i$, with $f_i$ an element of $I$, and $g_i$ an element of $J$. I'm trying to think of an example in which $IJ$ does not equal $I \cap J$. I'm thinking of letting $I = 2\mathbb{Z}$, and $J = \mathbb{Z}$, and $I\cap J = 2\mathbb{Z}$? Can someone point out anything faulty about this logic of working with an even ideal and then an odd ideal? Thanks in advance.","The product of two ideals is defined as the set of all finite sums $\sum  f_i  g_i$, with $f_i$ an element of $I$, and $g_i$ an element of $J$. I'm trying to think of an example in which $IJ$ does not equal $I \cap J$. I'm thinking of letting $I = 2\mathbb{Z}$, and $J = \mathbb{Z}$, and $I\cap J = 2\mathbb{Z}$? Can someone point out anything faulty about this logic of working with an even ideal and then an odd ideal? Thanks in advance.",,"['abstract-algebra', 'ring-theory']"
16,"The ideal $I= \langle x,y \rangle\subset k[x,y]$ is not principal [closed]",The ideal  is not principal [closed],"I= \langle x,y \rangle\subset k[x,y]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question The ideal $I= \langle x,y \rangle\subset k[x,y]$ is not a principal ideal. I don't know how to consider it. Any suggestions?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question The ideal $I= \langle x,y \rangle\subset k[x,y]$ is not a principal ideal. I don't know how to consider it. Any suggestions?",,"['abstract-algebra', 'ideals']"
17,Can a cubic equation have three complex roots?,Can a cubic equation have three complex roots?,,"I have read somewhere that: If $x+ iy$ is a root of a cubic equation $ax^3+bx^2+cx+d=0$, then $x-iy$ is also a root of this equation. My question is: Can $k-il$ be the other root of this equation if $l\neq 0$? If yes, then it would seem that $k+ il$ should also be a root, but in that case the cubic equation would have four roots which is impossible. Where is the mistake in my logic? ($i$ denotes $\sqrt {-1}$, and is sometimes pronounced as $iota$.)","I have read somewhere that: If $x+ iy$ is a root of a cubic equation $ax^3+bx^2+cx+d=0$, then $x-iy$ is also a root of this equation. My question is: Can $k-il$ be the other root of this equation if $l\neq 0$? If yes, then it would seem that $k+ il$ should also be a root, but in that case the cubic equation would have four roots which is impossible. Where is the mistake in my logic? ($i$ denotes $\sqrt {-1}$, and is sometimes pronounced as $iota$.)",,"['abstract-algebra', 'algebra-precalculus']"
18,Existance of multiple of $n$ with only 0 and 1 as it's digits [duplicate],Existance of multiple of  with only 0 and 1 as it's digits [duplicate],n,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Proof that a natural number multiplied by some integer results in a number with only one and zero as digits I read this somewhere recently: For any natural number $n$ , there exists a multiple of $n$ , such that the multiple has only 0 and 1 as its digits. $2 \to 10$ $3 \to 111$ $4 \to 100$ $5 \to 10$ $6 \to 1110$ $7 \to 1001$ Any ideas how to go about proving this?","This question already has answers here : Closed 11 years ago . Possible Duplicate: Proof that a natural number multiplied by some integer results in a number with only one and zero as digits I read this somewhere recently: For any natural number , there exists a multiple of , such that the multiple has only 0 and 1 as its digits. Any ideas how to go about proving this?",n n 2 \to 10 3 \to 111 4 \to 100 5 \to 10 6 \to 1110 7 \to 1001,"['abstract-algebra', 'pigeonhole-principle']"
19,Are ideals also rings?,Are ideals also rings?,,I am learning about rings and ideals. But I am confused about something. My book (Gallian) says that an ideal of a ring by definition is a subring. But I have talked to other people who insist that an ideal is not a ring itself. I am confused about this. According to Wikipedia an ideal isn't necessarily a subring. But maybe it follows from the definition in Wikipedia that an ideal is a subring? So my question is: is an ideal a ring?,I am learning about rings and ideals. But I am confused about something. My book (Gallian) says that an ideal of a ring by definition is a subring. But I have talked to other people who insist that an ideal is not a ring itself. I am confused about this. According to Wikipedia an ideal isn't necessarily a subring. But maybe it follows from the definition in Wikipedia that an ideal is a subring? So my question is: is an ideal a ring?,,"['abstract-algebra', 'definition', 'ideals']"
20,What is the kernel of a homomorphism?,What is the kernel of a homomorphism?,,I've done a lot of problems before but I am trying to get a really basic   definition of kernel so that I may apply to any possible given question that I may be presented with. Would  I be correct in saying that the kernel (of a  homomorphism) is basically what I can multiply any given function by to get the identity?,I've done a lot of problems before but I am trying to get a really basic   definition of kernel so that I may apply to any possible given question that I may be presented with. Would  I be correct in saying that the kernel (of a  homomorphism) is basically what I can multiply any given function by to get the identity?,,"['abstract-algebra', 'group-theory', 'definition']"
21,Torsion Subgroup (Just a set) for an abelian (non abelian) group.,Torsion Subgroup (Just a set) for an abelian (non abelian) group.,,"Let $G$ be an abelian Group. Question is to prove that $T(G)=\{g\in G : |g|<\infty \}$ is a subgroup of G. I tried in following way: let $g_1,g_2\in T(G)$ say, $|g_1|=n_1$ and $|g_2|=n_2$; Now, $(g_1g_2)^{n_1n_2}=g_1^{n_1n_2}g_2^{n_1n_2}$ [This is because G is abelian]. $(g_1g_2)^{n_1n_2}=g_1^{n_1n_2}g_2^{n_1n_2}=(g_1^{n_1})^{n_2}(g_2^{n_2})^{n_1}=e^{n_2}e^{n_1}=e$ Thus, if $g_1,g_2$ have finite order, so is $g_1g_2$.So, $T(G)$ is closed under group operation. As $|g|< \infty$, suppose $|g|=n$ then, $g^n=e=g.g^{n-1}$ So, if we can see that $g^{n-1}$ is in $T(G)$, then we are done as $g^{n-1}$ would be inverse of $g$ in $T(G)$. Now, $(g^{n-1})^n=(g^n)^{n-1}=e^{n-1}=e$. So, $g^{n-1}$ is in $T(G)$ and thus we are done.[we did not use abelian property of G in proving existence of inverse] So, we have $T(G)$ which is closed under group operation and inverse. Thus $T(G)$ is subgroup of $G$. As i have not used abelianness (Sorry for this word :D) in one of the properties, Natural Question would be Is $T(G)=\{g\in G : |g|<\infty \}$ a subgroup of G for non abelian G. Only Non abelian Infinite Group that comes to my mind is $Gl_n(\mathbb{R})$ for a fixed $n\in \mathbb{N}$ It does not look so obvious for me to say $|A|<\infty, |B|<\infty$ implies $|AB|<\infty$, I am not able to find an (an easy) example $A,B\in Gl_n(\mathbb{R})$ with $|A|<\infty, |B|<\infty$ but, $|AB|$ is not finite. I am looking for an example (as requested above) and if possible another example of a nonabelian group of infinite order in which $T(G)$ would be seen to be not a subgroup with less effort/or atleast which you feel anybody should know. Thanks in advance, Regards, Praphulla Koushik","Let $G$ be an abelian Group. Question is to prove that $T(G)=\{g\in G : |g|<\infty \}$ is a subgroup of G. I tried in following way: let $g_1,g_2\in T(G)$ say, $|g_1|=n_1$ and $|g_2|=n_2$; Now, $(g_1g_2)^{n_1n_2}=g_1^{n_1n_2}g_2^{n_1n_2}$ [This is because G is abelian]. $(g_1g_2)^{n_1n_2}=g_1^{n_1n_2}g_2^{n_1n_2}=(g_1^{n_1})^{n_2}(g_2^{n_2})^{n_1}=e^{n_2}e^{n_1}=e$ Thus, if $g_1,g_2$ have finite order, so is $g_1g_2$.So, $T(G)$ is closed under group operation. As $|g|< \infty$, suppose $|g|=n$ then, $g^n=e=g.g^{n-1}$ So, if we can see that $g^{n-1}$ is in $T(G)$, then we are done as $g^{n-1}$ would be inverse of $g$ in $T(G)$. Now, $(g^{n-1})^n=(g^n)^{n-1}=e^{n-1}=e$. So, $g^{n-1}$ is in $T(G)$ and thus we are done.[we did not use abelian property of G in proving existence of inverse] So, we have $T(G)$ which is closed under group operation and inverse. Thus $T(G)$ is subgroup of $G$. As i have not used abelianness (Sorry for this word :D) in one of the properties, Natural Question would be Is $T(G)=\{g\in G : |g|<\infty \}$ a subgroup of G for non abelian G. Only Non abelian Infinite Group that comes to my mind is $Gl_n(\mathbb{R})$ for a fixed $n\in \mathbb{N}$ It does not look so obvious for me to say $|A|<\infty, |B|<\infty$ implies $|AB|<\infty$, I am not able to find an (an easy) example $A,B\in Gl_n(\mathbb{R})$ with $|A|<\infty, |B|<\infty$ but, $|AB|$ is not finite. I am looking for an example (as requested above) and if possible another example of a nonabelian group of infinite order in which $T(G)$ would be seen to be not a subgroup with less effort/or atleast which you feel anybody should know. Thanks in advance, Regards, Praphulla Koushik",,['abstract-algebra']
22,Do we gain anything interesting if the stabilizer subgroup of a point is normal?,Do we gain anything interesting if the stabilizer subgroup of a point is normal?,,"Let $G$ be a group and $S$ a $G$-set with action $(g,s) \mapsto gs$.  For some $s \in S$, let the stabilizer of $s$, $G_s=\{g \in G\,|\,gs=s\}$ be normal in $G$.  What does this let us say about the action of $G$ on $S$? I thought it might be interesting to look at an action of $G/G_s$ on $S$.  However, something like $(gG_s,s) \mapsto gs$ isn't even well-defined in general. Are there situations in which we can recover anything interesting?","Let $G$ be a group and $S$ a $G$-set with action $(g,s) \mapsto gs$.  For some $s \in S$, let the stabilizer of $s$, $G_s=\{g \in G\,|\,gs=s\}$ be normal in $G$.  What does this let us say about the action of $G$ on $S$? I thought it might be interesting to look at an action of $G/G_s$ on $S$.  However, something like $(gG_s,s) \mapsto gs$ isn't even well-defined in general. Are there situations in which we can recover anything interesting?",,"['abstract-algebra', 'group-theory', 'group-actions']"
23,"why is a nullary operation a special element, usually 0 or 1?","why is a nullary operation a special element, usually 0 or 1?",,"Does a nullary operation mean an operation not taking any argument? Then why is a nullary operation a special element, usually 0 or 1, in an algebraic structure? Thanks!","Does a nullary operation mean an operation not taking any argument? Then why is a nullary operation a special element, usually 0 or 1, in an algebraic structure? Thanks!",,"['abstract-algebra', 'universal-algebra']"
24,Are there algebraic structures with more than one neutral element and/or more than one inverse element?,Are there algebraic structures with more than one neutral element and/or more than one inverse element?,,"I was reading a book on groups, it points out about the uniqueness of the neutral element and the inverse element. I got curious, are there algebraic structures with more than one neutral element and/or more than one inverse element?","I was reading a book on groups, it points out about the uniqueness of the neutral element and the inverse element. I got curious, are there algebraic structures with more than one neutral element and/or more than one inverse element?",,['abstract-algebra']
25,The group of roots of unity in an algebraic number field,The group of roots of unity in an algebraic number field,,"Is the following proposition true? If yes, how would you prove this? Proposition. Let $K$ be an algebraic number field. The group of roots of unity in $K$ is finite. In other words, the torsion subgroup of $K^*$ is finite. Motivation. Let $A$ be the ring of algebraic integers in $K$ . A root of unity in $K$ is a unit (i.e. an invertible element of $A$ ). It is important to determine the structure of the group of units in $K$ to investigate the arithmetic properties of $K$ . Remark. Perhaps, the following fact can be used in the proof. Every conjugate of a root of unity in $K$ has absolute value 1. Related question: The group of roots of unity in the cyclotomic number field of an odd prime order Is an algebraic integer all of whose conjugates have absolute value 1 a root of unity?","Is the following proposition true? If yes, how would you prove this? Proposition. Let be an algebraic number field. The group of roots of unity in is finite. In other words, the torsion subgroup of is finite. Motivation. Let be the ring of algebraic integers in . A root of unity in is a unit (i.e. an invertible element of ). It is important to determine the structure of the group of units in to investigate the arithmetic properties of . Remark. Perhaps, the following fact can be used in the proof. Every conjugate of a root of unity in has absolute value 1. Related question: The group of roots of unity in the cyclotomic number field of an odd prime order Is an algebraic integer all of whose conjugates have absolute value 1 a root of unity?",K K K^* A K K A K K K,"['abstract-algebra', 'algebraic-number-theory']"
26,"Every proper ideal is contained in a maximal ideal, in a commutative ring with identity.","Every proper ideal is contained in a maximal ideal, in a commutative ring with identity.",,"The statement is: In a commutative ring with 1, every proper ideal is contained in a maximal ideal. and we prove it using Zorn's lemma, that is, $I$ is an ideal, $P=\{I\subset  A\mid A\text{ is an ideal}\} $, then by set inclusion, every totally ordered subset has a bound, then $P$ has a maximal element $M$. My question is why $M$ must contain $I$?","The statement is: In a commutative ring with 1, every proper ideal is contained in a maximal ideal. and we prove it using Zorn's lemma, that is, $I$ is an ideal, $P=\{I\subset  A\mid A\text{ is an ideal}\} $, then by set inclusion, every totally ordered subset has a bound, then $P$ has a maximal element $M$. My question is why $M$ must contain $I$?",,"['abstract-algebra', 'ring-theory', 'commutative-algebra']"
27,Show that $\mathbb{Z}_{2} \times \mathbb{Z}_{4}$ is not a cyclic group,Show that  is not a cyclic group,\mathbb{Z}_{2} \times \mathbb{Z}_{4},"Show that $\mathbb{Z}_{2} \times \mathbb{Z}_{4}$ is not a cyclic group. This question is from the book 'Of Abstract Algebra' by Pinter. Now $\mathbb{Z}_{2} \times \mathbb{Z}_{4}$ containt 8 elements. I found them to be as follows: $$(0,0),(0,1),(0,2),(0,3),(1,0),(1,1),(1,2),(1,3)$$ Now if $\mathbb{Z}_{2} \times \mathbb{Z}_{4}$ were cyclic, one of these elements should be a generator of the entire group. However, for every element listed we find that repeated repetitions of the group operation yields the identity element already before having to apply the group operation eight times. Therefore, using any of these elements as a single element would result in a subgroup of order less than 8, in this case it will have either order 4, order 2 or order 1. Therefore the group is not cyclic. Now I am quite sure this constitutes a correct proof but I am wondering if a more elegant way exist to show this result. This might be especially useful when investigating similar questions for much larger groups. Thanks in advance P.S. I have been posting more questions from this book because I find them very interesting, but I am reading it on my own so I am sometimes unsure if the methods I use are the most elegant and quick. So far I have received great help and I am grateful to the stackexchange community for this :)","Show that $\mathbb{Z}_{2} \times \mathbb{Z}_{4}$ is not a cyclic group. This question is from the book 'Of Abstract Algebra' by Pinter. Now $\mathbb{Z}_{2} \times \mathbb{Z}_{4}$ containt 8 elements. I found them to be as follows: $$(0,0),(0,1),(0,2),(0,3),(1,0),(1,1),(1,2),(1,3)$$ Now if $\mathbb{Z}_{2} \times \mathbb{Z}_{4}$ were cyclic, one of these elements should be a generator of the entire group. However, for every element listed we find that repeated repetitions of the group operation yields the identity element already before having to apply the group operation eight times. Therefore, using any of these elements as a single element would result in a subgroup of order less than 8, in this case it will have either order 4, order 2 or order 1. Therefore the group is not cyclic. Now I am quite sure this constitutes a correct proof but I am wondering if a more elegant way exist to show this result. This might be especially useful when investigating similar questions for much larger groups. Thanks in advance P.S. I have been posting more questions from this book because I find them very interesting, but I am reading it on my own so I am sometimes unsure if the methods I use are the most elegant and quick. So far I have received great help and I am grateful to the stackexchange community for this :)",,"['abstract-algebra', 'group-theory', 'finite-groups']"
28,Does this definition of an epimorphism work?,Does this definition of an epimorphism work?,,"I'm reading through Aluffi's Algebra Chapter 0 and one of the exercises is to come up with a definition of an epimorphism and show that a map $f \colon A \to B$ is surjective iff it is an epimorphism. In hindsight it's obvious to say that (Definition 1) $f$ is an epimorphism if for all maps $g_1, g_2 \colon B \to Z$ , if $g_1 \circ f = g_2 \circ f$ , then $g_1 = g_2$ (right-cancellation). However, when I first approached the problem I had something about existence in mind and I came up with the following diagram: Here, I wanted to define an epimorphism as follows: (Definition 2) $f$ is an epimorphism if for all maps $g \colon Z \to B$ , there exists a map $h \colon Z \to A$ such that $g = f \circ h$ . In that case, a proof would go as follows (I will assume all sets $A,B,Z$ are nonempty): Suppose $f$ is surjective. Then, for all $b \in B$ , the preimage $f^{-1}(\{b\})$ is nonempty, so we can pick an element $a_b \in A$ such that $a_b \overset{f}{\mapsto} b$ . Now if $z \overset{g}{\mapsto} b$ for $z \in Z$ , then we can let $h(z)=a_b$ . We can repeat this exercise for any $b' \in B$ that is mapped to under $g$ . On the other hand, suppose $f$ is an epimorphism according to Definition 2. Choose an element $b \in B$ and let $g$ be the constant map $g(z) \equiv b$ . Then there exists a map $h \colon Z \to A$ such that $f(h(z))=g(z)=b$ , so there is some $a \in A$ mapping to $b \in B$ under $f$ . Again we can repeat this for any $b' \in B$ . Question 1 Is my proof correct and the definition sound? Question 2 If the answer to Q1 is yes, then I assume I didn't just invent some new property in category theory but rather that this is some property that possibly has a name. (Would it qualify as a universal property?)","I'm reading through Aluffi's Algebra Chapter 0 and one of the exercises is to come up with a definition of an epimorphism and show that a map is surjective iff it is an epimorphism. In hindsight it's obvious to say that (Definition 1) is an epimorphism if for all maps , if , then (right-cancellation). However, when I first approached the problem I had something about existence in mind and I came up with the following diagram: Here, I wanted to define an epimorphism as follows: (Definition 2) is an epimorphism if for all maps , there exists a map such that . In that case, a proof would go as follows (I will assume all sets are nonempty): Suppose is surjective. Then, for all , the preimage is nonempty, so we can pick an element such that . Now if for , then we can let . We can repeat this exercise for any that is mapped to under . On the other hand, suppose is an epimorphism according to Definition 2. Choose an element and let be the constant map . Then there exists a map such that , so there is some mapping to under . Again we can repeat this for any . Question 1 Is my proof correct and the definition sound? Question 2 If the answer to Q1 is yes, then I assume I didn't just invent some new property in category theory but rather that this is some property that possibly has a name. (Would it qualify as a universal property?)","f \colon A \to B f g_1, g_2 \colon B \to Z g_1 \circ f = g_2 \circ f g_1 = g_2 f g \colon Z \to B h \colon Z \to A g = f \circ h A,B,Z f b \in B f^{-1}(\{b\}) a_b \in A a_b \overset{f}{\mapsto} b z \overset{g}{\mapsto} b z \in Z h(z)=a_b b' \in B g f b \in B g g(z) \equiv b h \colon Z \to A f(h(z))=g(z)=b a \in A b \in B f b' \in B","['abstract-algebra', 'category-theory']"
29,$\mathbb Z\times\mathbb Z$ is principal but is not a PID,is principal but is not a PID,\mathbb Z\times\mathbb Z,"I need to find an example of a ring that is not a PID but every ideal is principal. I know that $\mathbb Z\times\mathbb Z$ is not an integral domain, so certainly is not a PID, but here every ideal is principal. I already proved that if $R$ and $S$ are ring every ideal in $R \times S$ is $I \times J$ with ideals in the original ring. But I cant follow from that that $\mathbb Z\times\mathbb Z$ has only principal ideals. Explicitly, if $I$ is an ideal $(a)\times(b)$ which would be its generator $(c,d)$ in $\mathbb Z\times\mathbb Z$ ? Thanks.","I need to find an example of a ring that is not a PID but every ideal is principal. I know that is not an integral domain, so certainly is not a PID, but here every ideal is principal. I already proved that if and are ring every ideal in is with ideals in the original ring. But I cant follow from that that has only principal ideals. Explicitly, if is an ideal which would be its generator in ? Thanks.","\mathbb Z\times\mathbb Z R S R \times S I \times J \mathbb Z\times\mathbb Z I (a)\times(b) (c,d) \mathbb Z\times\mathbb Z","['abstract-algebra', 'ring-theory', 'ideals', 'principal-ideal-domains']"
30,"Prove that the ideal $(X_1-a_1,...,X_n-a_n)$ is maximal in $K[X_1,\dots,X_n]$",Prove that the ideal  is maximal in,"(X_1-a_1,...,X_n-a_n) K[X_1,\dots,X_n]","Let $K$ be a field, and $a_1,\dots,a_n \in K$. Prove that the ideal $$(X_1-a_1,\dots,X_n-a_n)$$ is maximal in $K[X_1,\dots,X_n]$. I tried proving that the only elements outside the ideal are the invertibles of $K$ (I should still prove that this implies maximality, but it shouldn't be too difficult). Is there a better strategy, or another stategy?","Let $K$ be a field, and $a_1,\dots,a_n \in K$. Prove that the ideal $$(X_1-a_1,\dots,X_n-a_n)$$ is maximal in $K[X_1,\dots,X_n]$. I tried proving that the only elements outside the ideal are the invertibles of $K$ (I should still prove that this implies maximality, but it shouldn't be too difficult). Is there a better strategy, or another stategy?",,"['abstract-algebra', 'ring-theory', 'ideals']"
31,"An ""atom"" in Boolean algebra","An ""atom"" in Boolean algebra",,"Could someone explain what an atom in Boolean algebra means? I am acquainted with ring theory and group theory but not Boolean algebra. As far as I can tell from browsing around, it is something like a generator, but then again not exactly... Your help will be very much appreciated. Thanks in advance. Added: It would be particularly helpful if it could be placed in the context of rings or groups. I think there are such entities as Boolean rings...","Could someone explain what an atom in Boolean algebra means? I am acquainted with ring theory and group theory but not Boolean algebra. As far as I can tell from browsing around, it is something like a generator, but then again not exactly... Your help will be very much appreciated. Thanks in advance. Added: It would be particularly helpful if it could be placed in the context of rings or groups. I think there are such entities as Boolean rings...",,"['abstract-algebra', 'group-theory', 'ring-theory', 'boolean-algebra']"
32,Finding all normal subgroups of a group,Finding all normal subgroups of a group,,"On my homework today, we had to find all the normal subgroups of $D_{n}$, the dihedral group of order 2n. I solved the problem by looking at how the conjugacy classes change based on whether n is even or odd and then constructed the normal subgroups as unions of the conjugacy classes. I have 2 questions: (i) Is there a better way to approach the problem than looking at the conjugacy classes? (ii) Could someone explain why we want to find all the normal subgroups of a particular group?   How does this provide us additional insight into the structure of the group we are studying? (Right now, this exercise feels more like a 'computation' to me than a way of understanding $D_{n}$) Thanks :)","On my homework today, we had to find all the normal subgroups of $D_{n}$, the dihedral group of order 2n. I solved the problem by looking at how the conjugacy classes change based on whether n is even or odd and then constructed the normal subgroups as unions of the conjugacy classes. I have 2 questions: (i) Is there a better way to approach the problem than looking at the conjugacy classes? (ii) Could someone explain why we want to find all the normal subgroups of a particular group?   How does this provide us additional insight into the structure of the group we are studying? (Right now, this exercise feels more like a 'computation' to me than a way of understanding $D_{n}$) Thanks :)",,"['abstract-algebra', 'group-theory', 'intuition']"
33,"Solution Manual for Chapters 13 and 14, Dummit & Foote","Solution Manual for Chapters 13 and 14, Dummit & Foote",,"I bought the third edition of ""Abstract Algebra"" by Dummit and Foote. In my opinion this is the best ""algebra book"" that has been written. I found several solution manual but none has solutions for Chapters 13 and 14 (Field extensions and Galois theory respectively) Is there a solution manual for these chapters?","I bought the third edition of ""Abstract Algebra"" by Dummit and Foote. In my opinion this is the best ""algebra book"" that has been written. I found several solution manual but none has solutions for Chapters 13 and 14 (Field extensions and Galois theory respectively) Is there a solution manual for these chapters?",,"['abstract-algebra', 'reference-request']"
34,Two principal ideals coincide if and only if their generators are associated,Two principal ideals coincide if and only if their generators are associated,,"Suppose we have a ring $R$ and $(a),(b)$ are both ideals of $R$. Is it always true that $(a)=(b)$ if and only if there exists a unit $c$ such that $a=bc$ (i.e., $a$ and $b$ are associate)? I have already verified that the forwards direction is true. But I have no idea on the backward direction. If it is true, can someone provide a proof to me? Backward direction: Suppose that there exists a unit $c \in R$ such that $a=bc$. This implies that $(a)\subset (b)$. By using the same thing, (i.e., $b$ and $a$ are associate), there exists a unit $d \in R$ such that $b=ad$. This implies that $(b) \subset (a)$. is this correct?","Suppose we have a ring $R$ and $(a),(b)$ are both ideals of $R$. Is it always true that $(a)=(b)$ if and only if there exists a unit $c$ such that $a=bc$ (i.e., $a$ and $b$ are associate)? I have already verified that the forwards direction is true. But I have no idea on the backward direction. If it is true, can someone provide a proof to me? Backward direction: Suppose that there exists a unit $c \in R$ such that $a=bc$. This implies that $(a)\subset (b)$. By using the same thing, (i.e., $b$ and $a$ are associate), there exists a unit $d \in R$ such that $b=ad$. This implies that $(b) \subset (a)$. is this correct?",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
35,Follow-up to question: Aut(G) for G = Klein 4-group is isomorphic to $S_3$,Follow-up to question: Aut(G) for G = Klein 4-group is isomorphic to,S_3,"This is most likely a lack of understanding of wording on my part. I was considerind the Klein 4-group as the set of four permutations: the identity permutation, and three other permutations of four elements, where each of those is made up of two transposes, (i.e., 1 $\rightarrow$ 2, 2 $\rightarrow$ 1 and 3 $\rightarrow$ 4, 4 $\rightarrow$ 3) taken over the three possible such combinations of four elements. Here, then, is my question. I am assuming (?) that Aut(G) in this case is the set of permutations of the four elements of the Klein 4-group - or the three non-identity ones for the purpose of showing isomorphic to $S_3$. If this is the case, what does it mean to have a permutation of these three permutations that I mentioned above? As always, thanks for your help.","This is most likely a lack of understanding of wording on my part. I was considerind the Klein 4-group as the set of four permutations: the identity permutation, and three other permutations of four elements, where each of those is made up of two transposes, (i.e., 1 $\rightarrow$ 2, 2 $\rightarrow$ 1 and 3 $\rightarrow$ 4, 4 $\rightarrow$ 3) taken over the three possible such combinations of four elements. Here, then, is my question. I am assuming (?) that Aut(G) in this case is the set of permutations of the four elements of the Klein 4-group - or the three non-identity ones for the purpose of showing isomorphic to $S_3$. If this is the case, what does it mean to have a permutation of these three permutations that I mentioned above? As always, thanks for your help.",,['abstract-algebra']
36,Order of products of elements in a finite Abelian group,Order of products of elements in a finite Abelian group,,"We want to show that if $a,b\in G$ where $G$ is a finite Abelian group, we have  $\operatorname{LCM}(|a|,|b|) = |ab|$ given that $ab \neq e$. How I approached this question was by saying let $\operatorname{LCM}(|a|,|b|) = L$. Then if we show that $L$ divides $|ab|$ and $|ab|$ divides $L$ then $|ab| = L$. Showing that $|ab|$ divides $L$ was fine. But then I am having trouble with the second part that is showing $L$ divides $|ab|$. For this, so far I have: Consider $(ab)^{|ab|} = e = a^{|ab|}b^{|ab|} $  since we know $a \neq b^{-1}$ by assumption then we can conclude that $|a|$ divides $|ab|$ and $|b|$ divides $|ab|$. We know that $L = \frac{|a||b|}{\operatorname{gcd}(|a|,|b|)}$ from here can we conclude that $L$ divides $|ab|$?","We want to show that if $a,b\in G$ where $G$ is a finite Abelian group, we have  $\operatorname{LCM}(|a|,|b|) = |ab|$ given that $ab \neq e$. How I approached this question was by saying let $\operatorname{LCM}(|a|,|b|) = L$. Then if we show that $L$ divides $|ab|$ and $|ab|$ divides $L$ then $|ab| = L$. Showing that $|ab|$ divides $L$ was fine. But then I am having trouble with the second part that is showing $L$ divides $|ab|$. For this, so far I have: Consider $(ab)^{|ab|} = e = a^{|ab|}b^{|ab|} $  since we know $a \neq b^{-1}$ by assumption then we can conclude that $|a|$ divides $|ab|$ and $|b|$ divides $|ab|$. We know that $L = \frac{|a||b|}{\operatorname{gcd}(|a|,|b|)}$ from here can we conclude that $L$ divides $|ab|$?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
37,Why are distinct maximal ideals coprime?,Why are distinct maximal ideals coprime?,,"I have a problem. As I've understand it two proper ideals $I$ and $J$ of a ring $R$ is said to be $coprime$ if $I+J=(1)$. For a set of distinct maximal ideals of $R$ say $\{I_i\}$, $0\leq i\leq n$, how can I see that these are pairvise coprime..? $R$ is assumed to be a Noetherian domain. I can't see how to work this out without using the concept of GCD, and that is not a welldefined concept in such a ring.","I have a problem. As I've understand it two proper ideals $I$ and $J$ of a ring $R$ is said to be $coprime$ if $I+J=(1)$. For a set of distinct maximal ideals of $R$ say $\{I_i\}$, $0\leq i\leq n$, how can I see that these are pairvise coprime..? $R$ is assumed to be a Noetherian domain. I can't see how to work this out without using the concept of GCD, and that is not a welldefined concept in such a ring.",,"['abstract-algebra', 'commutative-algebra', 'algebraic-number-theory']"
38,Are these two quotient rings of $\Bbb Z[x]$ isomorphic?,Are these two quotient rings of  isomorphic?,\Bbb Z[x],"Are the rings $\mathbb{Z}[x]/(x^2+7)$ and $\mathbb{Z}[x]/(2x^2+7)$ isomorphic? Attempted Solution: My guess is that they are not isomorphic. I am having trouble demonstrating this. Any hints, as to how i should approach this?","Are the rings $\mathbb{Z}[x]/(x^2+7)$ and $\mathbb{Z}[x]/(2x^2+7)$ isomorphic? Attempted Solution: My guess is that they are not isomorphic. I am having trouble demonstrating this. Any hints, as to how i should approach this?",,"['abstract-algebra', 'ring-theory']"
39,Number of permutations for a cycle-type,Number of permutations for a cycle-type,,"In the proof that the alternating group $A_5$ is a simple group, we first write cycle-types of the conjugacy classes of $S_5$ which correspond to cycle-types $$1, 2^1, 2^2, 3^1, 2^13^1, 4^1, 5^1$$ and clearly the permutations of cycle-types $1, 2^2, 3^1, 5^1$ are even. But then my lecture notes state that there is $1$ permutation of cycle type $1$, $15$ of type $2^2$, $20$ of type $3^1$ and $24$ of type $5^1$ making $60$ in total. My question is how did they find the number of permutations for each cycle-type? A follow up question is that my lecture notes then state that: 'The problem is that these classes are in $S_n$, and two permutations could conceivably be conjugate in $S_n$ but not in $A_n$.' Is this because it could be possible that the element $f \in G$ which 'links' two elements in the same conjugacy classes could be in $S_n$ but not in $A_n$? Thanks!","In the proof that the alternating group $A_5$ is a simple group, we first write cycle-types of the conjugacy classes of $S_5$ which correspond to cycle-types $$1, 2^1, 2^2, 3^1, 2^13^1, 4^1, 5^1$$ and clearly the permutations of cycle-types $1, 2^2, 3^1, 5^1$ are even. But then my lecture notes state that there is $1$ permutation of cycle type $1$, $15$ of type $2^2$, $20$ of type $3^1$ and $24$ of type $5^1$ making $60$ in total. My question is how did they find the number of permutations for each cycle-type? A follow up question is that my lecture notes then state that: 'The problem is that these classes are in $S_n$, and two permutations could conceivably be conjugate in $S_n$ but not in $A_n$.' Is this because it could be possible that the element $f \in G$ which 'links' two elements in the same conjugacy classes could be in $S_n$ but not in $A_n$? Thanks!",,['abstract-algebra']
40,Combinatorial group theory books,Combinatorial group theory books,,"I would please like some recommendations for an introductory level book on combinatorial group theory, by which I mean a group theory book which places emphasis on generators and relations and free groups, and then discusses common concepts such as quotient groups in terms of these. Thank you.","I would please like some recommendations for an introductory level book on combinatorial group theory, by which I mean a group theory book which places emphasis on generators and relations and free groups, and then discusses common concepts such as quotient groups in terms of these. Thank you.",,"['abstract-algebra', 'group-theory', 'soft-question', 'book-recommendation']"
41,How should I show that the Lie algebra so(6) of SO(6) is isomorphic to the Lie algebra su(4) of SU(4)?,How should I show that the Lie algebra so(6) of SO(6) is isomorphic to the Lie algebra su(4) of SU(4)?,,"As far as I can see, an isomorphism of Lie algebras is a bijective map which preserves the Lie bracket. I need to show that $\mathfrak{so}(6)$ (the Lie algebra of SO(6)) is isomorphic to the $\mathfrak{su}(4)$ (the Lie algebra of SO(4)). I know that $\mathfrak{so}(6)$ is the set of 6x6 real antisymmetric matrices and $\mathfrak{su}(4)$ is the set of 4x4 anti Hermitian matrices. Both types of matrices have 15 real independent components. Is this enough to say that both are isomorphic to $\mathbb{R}^{15}$? Since the Lie bracket of $\mathbb{R}^{15}$ is $[x,y]=0$, the preservation of the Lie bracket under the maps appears to be trivial. At first I hoped that this would be enough to prove that $\mathfrak{su}(4)$ and $\mathfrak{so}(6)$ were isomorphic, but I don't think the map from $\mathfrak{su}(4)$ to $\mathbb{R}^{15}$ to $\mathfrak{so}(6)$ would preserve the Lie bracket. Am I right in saying that Lie algebra homomorphism need not be transitive, i.e. $\psi : \mathscr{A} \rightarrow \mathscr{B}, \ \phi : \mathscr{B} \rightarrow \mathscr{C}$ Lie algebra homomorphisms need not imply $\phi \circ \psi : \mathscr{A} \rightarrow \mathscr{C}$ a Lie algebra homomorphism. Getting back to the original problem, how should I show that $\mathfrak{su}(4)$ and $\mathfrak{so}(6)$ are isomorphic? I suppose I need to explicitly find a map between them and show that it's an isomorphism? Is there a somewhat general way of finding such a map? This is my first time posting here, so sorry if my question is a little bit long winded! Thanks, Alex","As far as I can see, an isomorphism of Lie algebras is a bijective map which preserves the Lie bracket. I need to show that $\mathfrak{so}(6)$ (the Lie algebra of SO(6)) is isomorphic to the $\mathfrak{su}(4)$ (the Lie algebra of SO(4)). I know that $\mathfrak{so}(6)$ is the set of 6x6 real antisymmetric matrices and $\mathfrak{su}(4)$ is the set of 4x4 anti Hermitian matrices. Both types of matrices have 15 real independent components. Is this enough to say that both are isomorphic to $\mathbb{R}^{15}$? Since the Lie bracket of $\mathbb{R}^{15}$ is $[x,y]=0$, the preservation of the Lie bracket under the maps appears to be trivial. At first I hoped that this would be enough to prove that $\mathfrak{su}(4)$ and $\mathfrak{so}(6)$ were isomorphic, but I don't think the map from $\mathfrak{su}(4)$ to $\mathbb{R}^{15}$ to $\mathfrak{so}(6)$ would preserve the Lie bracket. Am I right in saying that Lie algebra homomorphism need not be transitive, i.e. $\psi : \mathscr{A} \rightarrow \mathscr{B}, \ \phi : \mathscr{B} \rightarrow \mathscr{C}$ Lie algebra homomorphisms need not imply $\phi \circ \psi : \mathscr{A} \rightarrow \mathscr{C}$ a Lie algebra homomorphism. Getting back to the original problem, how should I show that $\mathfrak{su}(4)$ and $\mathfrak{so}(6)$ are isomorphic? I suppose I need to explicitly find a map between them and show that it's an isomorphism? Is there a somewhat general way of finding such a map? This is my first time posting here, so sorry if my question is a little bit long winded! Thanks, Alex",,['abstract-algebra']
42,"What are the differences between Jacobson's ""Basic Algebra"" and ""Lectures in Abstract Algebra""?","What are the differences between Jacobson's ""Basic Algebra"" and ""Lectures in Abstract Algebra""?",,"Nathan Jacobson's books ""Basic Algebra I, II"" and ""Lectures in Abstract Algebra - Volumes I, II, III (GTM 30, 31, 32)"". What are the differences between these two books? 1) The subject. The material of the two books overlap, which one is better? 2) Does ""Lectures in Abstract Algebra"" aim to undergraduate? 3) ""Basic Algebra I, II"" Cannot edit a word! Really? 4) Is it necessary to read the two books? Thanks a lot!","Nathan Jacobson's books ""Basic Algebra I, II"" and ""Lectures in Abstract Algebra - Volumes I, II, III (GTM 30, 31, 32)"". What are the differences between these two books? 1) The subject. The material of the two books overlap, which one is better? 2) Does ""Lectures in Abstract Algebra"" aim to undergraduate? 3) ""Basic Algebra I, II"" Cannot edit a word! Really? 4) Is it necessary to read the two books? Thanks a lot!",,"['abstract-algebra', 'reference-request']"
43,Does $\varphi(1)=1$ if $\varphi$ is a field homomorphism?,Does  if  is a field homomorphism?,\varphi(1)=1 \varphi,"Is it by definition that $\varphi(1)=1$ if $\varphi$ is a field homomorphism ? My field theory lecture said that yes, but now $\varphi\equiv0$ is not a field homomorphism... What is the 'standard' in mathematics ? (i.e. if someone says that $\varphi$ is a field homomorphism does it imply $\varphi(1)=1$ ?)","Is it by definition that $\varphi(1)=1$ if $\varphi$ is a field homomorphism ? My field theory lecture said that yes, but now $\varphi\equiv0$ is not a field homomorphism... What is the 'standard' in mathematics ? (i.e. if someone says that $\varphi$ is a field homomorphism does it imply $\varphi(1)=1$ ?)",,"['abstract-algebra', 'terminology', 'field-theory']"
44,"Is there an ""algebraic"" way to construct the reals?","Is there an ""algebraic"" way to construct the reals?",,"It's possible to construct $\mathbb{Q}$ from $\mathbb{Z}$ by constructing $\mathbb{Z}$ 's field of fractions, and it's possible to construct $\mathbb{C}$ from $\mathbb{R}$ by adjoining $\sqrt{-1}$ to $\mathbb{R}$ . In both cases, the construction is done purely algebraically. I.e. we only rely on the operations of our given structure to build the new structure. But at no point do we have to rely on the order properties of $\mathbb{Z}$ or $\mathbb{R}$ to get to $\mathbb{Q}$ or $\mathbb{C}$ . Every construction of $\mathbb{R}$ that I'm familiar with ultimately comes down to endowing $\mathbb{Q}$ with its usual order, and then imposing the completeness axiom on it to recover the rest of the real numbers. Is it possible to get to $\mathbb{R}$ from $\mathbb{Q}$ without relying on the ordering properties of $\mathbb{Q}$ ? Alternatively (relatedly?): There is the notion of a greatest common divisor for an arbitrary ring. This notion doesn't rely on any ordering properties; just algebraic ones. Is it possible to recover an order relation on $\mathbb{Q}$ using the GCD relation on $\mathbb{Z}$ , then to impose completeness on $\mathbb{Q}$ and obtain $\mathbb{R}$ , and then subsequently re-cast completeness in some algebraic manner? Thus defining $\mathbb{R}$ in purely algebraic terms?","It's possible to construct from by constructing 's field of fractions, and it's possible to construct from by adjoining to . In both cases, the construction is done purely algebraically. I.e. we only rely on the operations of our given structure to build the new structure. But at no point do we have to rely on the order properties of or to get to or . Every construction of that I'm familiar with ultimately comes down to endowing with its usual order, and then imposing the completeness axiom on it to recover the rest of the real numbers. Is it possible to get to from without relying on the ordering properties of ? Alternatively (relatedly?): There is the notion of a greatest common divisor for an arbitrary ring. This notion doesn't rely on any ordering properties; just algebraic ones. Is it possible to recover an order relation on using the GCD relation on , then to impose completeness on and obtain , and then subsequently re-cast completeness in some algebraic manner? Thus defining in purely algebraic terms?",\mathbb{Q} \mathbb{Z} \mathbb{Z} \mathbb{C} \mathbb{R} \sqrt{-1} \mathbb{R} \mathbb{Z} \mathbb{R} \mathbb{Q} \mathbb{C} \mathbb{R} \mathbb{Q} \mathbb{R} \mathbb{Q} \mathbb{Q} \mathbb{Q} \mathbb{Z} \mathbb{Q} \mathbb{R} \mathbb{R},"['abstract-algebra', 'real-numbers']"
45,If $G$ is cyclic then $G/H$ is cyclic?,If  is cyclic then  is cyclic?,G G/H,"If $G$ is cyclic, then $G/H$ is cyclic? The proof I got goes like this: $G$ is cyclic, so $G=<g>$ for some $g\in G$. So any coset in $G/H$ would be of the form $Hg'=Hg^n$ for some $n$. So $Hg$ is an generator of $G/H$. Thus, $G/H$ is cyclic. I might just be confusing myself, but we have only shown that $Hg'$ is in form of $(Hg)^n$. But what if we are missing some $n\in\mathbb{N}$? That is, there is no quotient group of the form $Hg^2$, for example. To make myself a little bit clearer, I think what the above proof has done was showing that $\forall Hg'\in G/H, Hg'\in <Hg>$, thus $G/H \subset <Hg>$. I feel that this is not a complete proof.","If $G$ is cyclic, then $G/H$ is cyclic? The proof I got goes like this: $G$ is cyclic, so $G=<g>$ for some $g\in G$. So any coset in $G/H$ would be of the form $Hg'=Hg^n$ for some $n$. So $Hg$ is an generator of $G/H$. Thus, $G/H$ is cyclic. I might just be confusing myself, but we have only shown that $Hg'$ is in form of $(Hg)^n$. But what if we are missing some $n\in\mathbb{N}$? That is, there is no quotient group of the form $Hg^2$, for example. To make myself a little bit clearer, I think what the above proof has done was showing that $\forall Hg'\in G/H, Hg'\in <Hg>$, thus $G/H \subset <Hg>$. I feel that this is not a complete proof.",,"['abstract-algebra', 'group-theory', 'cyclic-groups', 'quotient-group']"
46,GCD in polynomial rings with coefficients in a field extension,GCD in polynomial rings with coefficients in a field extension,,"Let $E/F $ be a field extension and $f,g$ $\in$ $F[x]$ (the polynomial ring with coefficients in $F$ ). Let's denote with $\gcd_F(f,g)$ the greatest common divisor of $f$ and $g$ in $F[x]$. Is it true that $\gcd_F(f,g)$ $=$ $\gcd_E(f,g)$ ?","Let $E/F $ be a field extension and $f,g$ $\in$ $F[x]$ (the polynomial ring with coefficients in $F$ ). Let's denote with $\gcd_F(f,g)$ the greatest common divisor of $f$ and $g$ in $F[x]$. Is it true that $\gcd_F(f,g)$ $=$ $\gcd_E(f,g)$ ?",,"['abstract-algebra', 'ring-theory', 'field-theory']"
47,$F[x]/(x^2)\cong F[x]/(x^2 - 1)$ if and only if F has characteristic 2,if and only if F has characteristic 2,F[x]/(x^2)\cong F[x]/(x^2 - 1),"Artin's Algebra, Chapter 10 problem 5.16 states: Let $F$ be a field. Prove that the rings $F[x]/(x^2)$ and $F[x]/(x^2-1)$ are isomorphic if and only if $F$ has characteristic 2. As a pedantic concern: if F has characteristic 0, then surely this isomorphism still holds? So maybe it should be ""characteristic at most 2""? More seriously, it seems like $F[x]/(x^2)=\left\{f_0 + f_1 x\right\}$ since we're just setting $x^2=0$. Similarly, it seems like $f_0 + f_1x / (x^2-1) = f_0 + f_1 x$, which implies that $F[x]/(x^2)=F[x]/(x^2-1)$ independent of the characteristic of $F$. To prove this we need to show that $\text{deg}(fg)=\text{deg}(f)+\text{deg}(g)$,  which I believe is true in at least integral domains. What is my mistake here?","Artin's Algebra, Chapter 10 problem 5.16 states: Let $F$ be a field. Prove that the rings $F[x]/(x^2)$ and $F[x]/(x^2-1)$ are isomorphic if and only if $F$ has characteristic 2. As a pedantic concern: if F has characteristic 0, then surely this isomorphism still holds? So maybe it should be ""characteristic at most 2""? More seriously, it seems like $F[x]/(x^2)=\left\{f_0 + f_1 x\right\}$ since we're just setting $x^2=0$. Similarly, it seems like $f_0 + f_1x / (x^2-1) = f_0 + f_1 x$, which implies that $F[x]/(x^2)=F[x]/(x^2-1)$ independent of the characteristic of $F$. To prove this we need to show that $\text{deg}(fg)=\text{deg}(f)+\text{deg}(g)$,  which I believe is true in at least integral domains. What is my mistake here?",,"['abstract-algebra', 'ring-theory', 'field-theory']"
48,Cancellation law in a ring without unity,Cancellation law in a ring without unity,,"When discussing rings, integral domains, fields etc, I'm told that the cancellation law holds in any ring that has no zero divisors. By cancellation law, I mean that if we have no zero divisors, we can look at the equation $ab = ac$ and ""cancel"" the a on the left-hand side, and thus know that $b=c$. (I believe that the proof of this comes out of saying that $(ab-ac) = a(b-c) = 0$ thus implying that $(b-c) = 0$ if $a \neq 0$, and so $b=c$). What I'm confused about, is that the requirement for the cancliation law is simply that our ring has no zero divsors, there's no mention of our ring containg unity. However, if our ring doesn't contain unity, but the cancellation law holds, then what can we make of the equation $a^2 = a$? Every time I try to simplify this, I find the need to use unity, which I don't believe I am guaranteed to have in my ring. Does saying that our ring has no zero divisors, in fact, imply that our ring contains unity? Can somone help explain/correct this apparent paradox for me please?","When discussing rings, integral domains, fields etc, I'm told that the cancellation law holds in any ring that has no zero divisors. By cancellation law, I mean that if we have no zero divisors, we can look at the equation $ab = ac$ and ""cancel"" the a on the left-hand side, and thus know that $b=c$. (I believe that the proof of this comes out of saying that $(ab-ac) = a(b-c) = 0$ thus implying that $(b-c) = 0$ if $a \neq 0$, and so $b=c$). What I'm confused about, is that the requirement for the cancliation law is simply that our ring has no zero divsors, there's no mention of our ring containg unity. However, if our ring doesn't contain unity, but the cancellation law holds, then what can we make of the equation $a^2 = a$? Every time I try to simplify this, I find the need to use unity, which I don't believe I am guaranteed to have in my ring. Does saying that our ring has no zero divisors, in fact, imply that our ring contains unity? Can somone help explain/correct this apparent paradox for me please?",,"['abstract-algebra', 'ring-theory', 'inverse', 'integral-domain']"
49,"Could the concept of ""finite free groups"" be possible?","Could the concept of ""finite free groups"" be possible?",,"Is it possible to define ""finite free groups"" ? could that make it easier to deal with group presentations ?","Is it possible to define ""finite free groups"" ? could that make it easier to deal with group presentations ?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'free-groups']"
50,When is a cyclotomic polynomial over a finite field a minimal polynomial? [duplicate],When is a cyclotomic polynomial over a finite field a minimal polynomial? [duplicate],,This question already has answers here : Irreducible cyclotomic polynomial (2 answers) Closed 7 years ago . When is the cyclotomic polynomial $f(x)$ over a finite field $\mathrm{F}_q$ also the minimal polynomial of some element $\alpha \in \mathrm{F}_q$?,This question already has answers here : Irreducible cyclotomic polynomial (2 answers) Closed 7 years ago . When is the cyclotomic polynomial $f(x)$ over a finite field $\mathrm{F}_q$ also the minimal polynomial of some element $\alpha \in \mathrm{F}_q$?,,"['abstract-algebra', 'polynomials', 'finite-fields', 'irreducible-polynomials', 'cyclotomic-polynomials']"
51,Is every field the field of fractions for some integral domain?,Is every field the field of fractions for some integral domain?,,"Given an integral domain $R$, one can construct its field of fractions (or quotients) $\operatorname{Quot}(R)$ which is of course a field. Does every field arise in this way? That is: Given a field $\mathbb{F}$, does there exist an integral domain $R$ such that $\operatorname{Quot}(R) \cong \mathbb{F}$?","Given an integral domain $R$, one can construct its field of fractions (or quotients) $\operatorname{Quot}(R)$ which is of course a field. Does every field arise in this way? That is: Given a field $\mathbb{F}$, does there exist an integral domain $R$ such that $\operatorname{Quot}(R) \cong \mathbb{F}$?",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
52,Prove that the intersection of all subfields of the reals is the rationals,Prove that the intersection of all subfields of the reals is the rationals,,"I'm reading through Abstract Algebra by Hungerford and he makes the remark that the intersection of all subfields of the real numbers is the rational numbers. Despite considerable deliberation, I'm unsure of the steps to take to show that the subfield is $\mathbb Q$. Any insight?","I'm reading through Abstract Algebra by Hungerford and he makes the remark that the intersection of all subfields of the real numbers is the rational numbers. Despite considerable deliberation, I'm unsure of the steps to take to show that the subfield is $\mathbb Q$. Any insight?",,"['abstract-algebra', 'galois-theory']"
53,Structure of $\mathbb{Z}[[x]]/(x-n)$,Structure of,\mathbb{Z}[[x]]/(x-n),"Is $\mathbb{Z}[[x]]/(x-6) \cong \widehat{\mathbb{Z}}_2 \times \widehat{\mathbb{Z}}_3$? It seems intuitive that $\mathbb{Z}[[x]]/(x-p)$ is the p -adic numbers, and I think this is not too hard to show formally.  Really, it doesn't seem too hard to show this is true for any number p , not just primes.  This gives a nice explicit description of $\mathbb{Z}[[x]]/(x-n)$, when combined with the well known (and hopefully well remembered) facts that $p^k$-adics is just a fancy name for p -adics, and that n -adics in general are the direct product of the p -adics for the distinct primes p dividing n . Everything was fine and good until I tried to show this direct product decomposition directly in the ring $\mathbb{Z}[[x]]/(x-6)$.  I want to use Chinese remainder theorem on the ideals $(x-2)$, $(x-3)$, and $(x-6)$.  Clearly $(x-2)+(x-3) = (1)$, but I think it is also pretty clear that $(x-6) \neq (x-2) \cap (x-3)$. Indeed, I don't think $x-6$ is even an element of $(x-2)$, since $$\frac{x-6}{x-2} = 3 + x + \tfrac12 x^2 + \ldots + \tfrac1{2^n} x^{n+1} + \ldots \notin \mathbb{Z}[[x]]$$ What has gone wrong?","Is $\mathbb{Z}[[x]]/(x-6) \cong \widehat{\mathbb{Z}}_2 \times \widehat{\mathbb{Z}}_3$? It seems intuitive that $\mathbb{Z}[[x]]/(x-p)$ is the p -adic numbers, and I think this is not too hard to show formally.  Really, it doesn't seem too hard to show this is true for any number p , not just primes.  This gives a nice explicit description of $\mathbb{Z}[[x]]/(x-n)$, when combined with the well known (and hopefully well remembered) facts that $p^k$-adics is just a fancy name for p -adics, and that n -adics in general are the direct product of the p -adics for the distinct primes p dividing n . Everything was fine and good until I tried to show this direct product decomposition directly in the ring $\mathbb{Z}[[x]]/(x-6)$.  I want to use Chinese remainder theorem on the ideals $(x-2)$, $(x-3)$, and $(x-6)$.  Clearly $(x-2)+(x-3) = (1)$, but I think it is also pretty clear that $(x-6) \neq (x-2) \cap (x-3)$. Indeed, I don't think $x-6$ is even an element of $(x-2)$, since $$\frac{x-6}{x-2} = 3 + x + \tfrac12 x^2 + \ldots + \tfrac1{2^n} x^{n+1} + \ldots \notin \mathbb{Z}[[x]]$$ What has gone wrong?",,"['number-theory', 'abstract-algebra']"
54,Is $\frac{1}{\alpha} \in \mathbb{Q}[\alpha]$ for irrational $\alpha$?,Is  for irrational ?,\frac{1}{\alpha} \in \mathbb{Q}[\alpha] \alpha,"I have been trying to pick up abstract algebra and just attempted an exercise from Landin's An Introduction to Algebraic Structures which asks to prove whether $\frac{1}{\pi} \in \mathbb{Q}[\pi]$ , and would like to ask a (slightly) more general question. Let $\alpha$ be an irrational number. Is $\frac1\alpha \in \mathbb{Q}[\alpha]$ ? $\mathbb{Q}[\alpha]$ being the ring of numbers of the form $a_0 +a_1\alpha+a_2\alpha^2\dots a_n\alpha^n$ with $a_i\in\mathbb{Q}$ . I'm really not sure where to begin, and haven't found a similar question on MSE (perhaps because the solution is simpler than I realize.) I am stuck on what we can conclude about $\frac{1}{\alpha}$ other than that it is an irrational number greater than $1$ . Clearly, $\alpha^k n \in \mathbb{Q}[\alpha]$ , but I'm reluctant to make any claims about $\frac{1}{\alpha}$ and $\alpha^k n$ , as I'm sure a solution would use other simpler methods. *edited title and parts of the body because $\alpha$ need not be less than one.","I have been trying to pick up abstract algebra and just attempted an exercise from Landin's An Introduction to Algebraic Structures which asks to prove whether , and would like to ask a (slightly) more general question. Let be an irrational number. Is ? being the ring of numbers of the form with . I'm really not sure where to begin, and haven't found a similar question on MSE (perhaps because the solution is simpler than I realize.) I am stuck on what we can conclude about other than that it is an irrational number greater than . Clearly, , but I'm reluctant to make any claims about and , as I'm sure a solution would use other simpler methods. *edited title and parts of the body because need not be less than one.",\frac{1}{\pi} \in \mathbb{Q}[\pi] \alpha \frac1\alpha \in \mathbb{Q}[\alpha] \mathbb{Q}[\alpha] a_0 +a_1\alpha+a_2\alpha^2\dots a_n\alpha^n a_i\in\mathbb{Q} \frac{1}{\alpha} 1 \alpha^k n \in \mathbb{Q}[\alpha] \frac{1}{\alpha} \alpha^k n \alpha,"['abstract-algebra', 'polynomials', 'ring-theory', 'irrational-numbers']"
55,How to find normal subgroups from a character table?,How to find normal subgroups from a character table?,,I know that normal subgroups are the union of some conjugacy classes Conjugacy classes are represented by the the columns in a matrix How could we use character values in the table to determine normal subgroups?,I know that normal subgroups are the union of some conjugacy classes Conjugacy classes are represented by the the columns in a matrix How could we use character values in the table to determine normal subgroups?,,"['abstract-algebra', 'representation-theory', 'normal-subgroups', 'characters']"
56,Let $G$ be a finite group with $|G|>2$. Prove that ${\rm Aut}(G)$ contains at least two elements.,Let  be a finite group with . Prove that  contains at least two elements.,G |G|>2 {\rm Aut}(G),"Let $G$ be a finite group with $|G|>2$ . Prove that ${\rm Aut}(G)$ contains at least two elements. We know that ${\rm Aut}(G)$ contains the identity function $f: G \to G: x \mapsto x$ . If $G$ is non-abelian, look at $g : G \to G: x \mapsto gxg^{-1}$ , for $g\neq e$ . This is an inner automorphism unequal to the identity function, so we have at least two elements in ${\rm Aut}(G).$ Now assume $G$ is abelian. Then the only inner automorphism is the identity function. Now look at the mapping $\varphi: G \to G : x \mapsto x^{-1}$ . This is an homomorphism because $\varphi (xy) = (xy)^{-1} = y^{-1} x^{-1} = x^{-1} y^{-1} = \varphi (x) \varphi (y)$ . Here we use the fact that $G$ is abelian. This mapping is clearly bijective, and thus an automorphism. This automorphism is unequal to the identity function only if there exists an element $x \in G$ such that $x \neq x^{-1}$ . In other words, there must be an element of order greater than $2$ . Now assume $G$ is abelian and every non-identity element has order $2$ . By Cauchy's theorem we know that the group must have order $2^n$ . I got stuck at this point. I've looked at this other post, $|G|>2$ implies $G$ has non trivial automorphism , but I don't know what they do in the last part (when they start talking about vector spaces). How should this prove be finished, without resorting to vector spaces if possible? Thanks in advance","Let be a finite group with . Prove that contains at least two elements. We know that contains the identity function . If is non-abelian, look at , for . This is an inner automorphism unequal to the identity function, so we have at least two elements in Now assume is abelian. Then the only inner automorphism is the identity function. Now look at the mapping . This is an homomorphism because . Here we use the fact that is abelian. This mapping is clearly bijective, and thus an automorphism. This automorphism is unequal to the identity function only if there exists an element such that . In other words, there must be an element of order greater than . Now assume is abelian and every non-identity element has order . By Cauchy's theorem we know that the group must have order . I got stuck at this point. I've looked at this other post, implies has non trivial automorphism , but I don't know what they do in the last part (when they start talking about vector spaces). How should this prove be finished, without resorting to vector spaces if possible? Thanks in advance",G |G|>2 {\rm Aut}(G) {\rm Aut}(G) f: G \to G: x \mapsto x G g : G \to G: x \mapsto gxg^{-1} g\neq e {\rm Aut}(G). G \varphi: G \to G : x \mapsto x^{-1} \varphi (xy) = (xy)^{-1} = y^{-1} x^{-1} = x^{-1} y^{-1} = \varphi (x) \varphi (y) G x \in G x \neq x^{-1} 2 G 2 2^n |G|>2 G,"['abstract-algebra', 'group-theory', 'finite-groups', 'automorphism-group']"
57,What is the order of the symmetry group of the cube?,What is the order of the symmetry group of the cube?,,"I figured out that there are 24 rotational symmetries, shown below. Rotation fixing: faces = 9, diagonals = 8, edges = 6, identity = 1, total = 24 Now, I don't know why the symmetry group of the 3-cube has 48 elements; I know it has to do something with reflection but am unable to picture this. Also, my teacher attached the following hint that I have hard time understanding: ""Consider the action of the symmetry group on the set of four diagonals."" How is this relevant?","I figured out that there are 24 rotational symmetries, shown below. Rotation fixing: faces = 9, diagonals = 8, edges = 6, identity = 1, total = 24 Now, I don't know why the symmetry group of the 3-cube has 48 elements; I know it has to do something with reflection but am unable to picture this. Also, my teacher attached the following hint that I have hard time understanding: ""Consider the action of the symmetry group on the set of four diagonals."" How is this relevant?",,"['abstract-algebra', 'group-theory', 'symmetry']"
58,Maximal Ideals in the Ring of Complex Entire Functions,Maximal Ideals in the Ring of Complex Entire Functions,,"Let $X = \mathcal{C}([0,1],\mathbb{R})$ be the ring of all continuous real-valued functions $f:[0,1] \to \mathbb{R}$ . For $x \in [0,1]$ , let $$M_{x} = \{ f \in X \ | \ f(x)=0\}.$$ One can show by using compactness of $[0,1]$ that every maximal ideal is of this form. Extending the question to entire functions : Let $\mathsf{C}(z)$ be the ring of complex entire functions. For $ \lambda \in \mathsf{C}$ let $M_{\lambda}$ denote the set of all entire functions which have a zero at $\lambda$ . Then is $M_{\lambda}$ a maximal ideal in $\mathsf{C}(z)$ , and does every ideal happen to be of this form? I don't know how to prove this!","Let be the ring of all continuous real-valued functions . For , let One can show by using compactness of that every maximal ideal is of this form. Extending the question to entire functions : Let be the ring of complex entire functions. For let denote the set of all entire functions which have a zero at . Then is a maximal ideal in , and does every ideal happen to be of this form? I don't know how to prove this!","X = \mathcal{C}([0,1],\mathbb{R}) f:[0,1] \to \mathbb{R} x \in [0,1] M_{x} = \{ f \in X \ | \ f(x)=0\}. [0,1] \mathsf{C}(z)  \lambda \in \mathsf{C} M_{\lambda} \lambda M_{\lambda} \mathsf{C}(z)",['analysis']
59,Are there more groups than rings?,Are there more groups than rings?,,"It seems pretty clear to me that both of these are at least uncountable (which I think I could prove with some work). It also seems that you should be able to make some diagonal argument about the two, but I'm not really sure how to make that. I've been trying to think of functions between groups and rings and ways to create groups out of rings and vice-versa, and I even think I've found some injective and/or surjective functions, but I didn't seem to be getting anywhere. Any suggestions would be great!","It seems pretty clear to me that both of these are at least uncountable (which I think I could prove with some work). It also seems that you should be able to make some diagonal argument about the two, but I'm not really sure how to make that. I've been trying to think of functions between groups and rings and ways to create groups out of rings and vice-versa, and I even think I've found some injective and/or surjective functions, but I didn't seem to be getting anywhere. Any suggestions would be great!",,"['abstract-algebra', 'group-theory', 'ring-theory', 'cardinals']"
60,Multiplicative inverse of $0$,Multiplicative inverse of,0,"If I'm not mistaken, in a ring with identity, the additive identity cannot have a multiplicative inverse. I'm trying to prove this. Here's my attempt so far: Suppose $0\cdot a=1$ $$0\cdot a=1$$ $$0\cdot (a + n) = 0\cdot a + 0\cdot n$$ It's easy to see here that if $n$ were a positive integer (same works for negative): $$n=1+1+1+\cdots$$ $$0\cdot a + 0\cdot (1 + 1 + 1+\cdots )$$ $$0 \cdot a + 0 + 0 + 0 + \dots = 0\cdot a$$ $$\therefore 0\cdot n = 0$$ If $a$ is some whole number of multiplicative inverses summed together, then this is a contradiction. This hinges on the assumption that $n$ is some integer multiple of the multiplicative unit, which it may not be. This also got me thinking about whether the distributivity of multiplication over addition is discretized in whole terms (you can only use operators with whole numbers of terms) or whether the concept of distrubitivity actually goes deeper than this. Mainly I'd like a proof that the additive identity can not have a multiplicative inverse and why $0\neq 1$. But some deep insight into why the properties of a ring lead to this would be a bonus.","If I'm not mistaken, in a ring with identity, the additive identity cannot have a multiplicative inverse. I'm trying to prove this. Here's my attempt so far: Suppose $0\cdot a=1$ $$0\cdot a=1$$ $$0\cdot (a + n) = 0\cdot a + 0\cdot n$$ It's easy to see here that if $n$ were a positive integer (same works for negative): $$n=1+1+1+\cdots$$ $$0\cdot a + 0\cdot (1 + 1 + 1+\cdots )$$ $$0 \cdot a + 0 + 0 + 0 + \dots = 0\cdot a$$ $$\therefore 0\cdot n = 0$$ If $a$ is some whole number of multiplicative inverses summed together, then this is a contradiction. This hinges on the assumption that $n$ is some integer multiple of the multiplicative unit, which it may not be. This also got me thinking about whether the distributivity of multiplication over addition is discretized in whole terms (you can only use operators with whole numbers of terms) or whether the concept of distrubitivity actually goes deeper than this. Mainly I'd like a proof that the additive identity can not have a multiplicative inverse and why $0\neq 1$. But some deep insight into why the properties of a ring lead to this would be a bonus.",,"['abstract-algebra', 'ring-theory', 'inverse']"
61,"Why is it okay to say two groups are the same, when they're really isomorphic?","Why is it okay to say two groups are the same, when they're really isomorphic?",,"This is a pet peeve of mine.  Both my textbook and my instructor, often say $G$ is $G'$, when really what they mean is $G$ is isomorphic to $G'$.  Why is this an accepted convention?","This is a pet peeve of mine.  Both my textbook and my instructor, often say $G$ is $G'$, when really what they mean is $G$ is isomorphic to $G'$.  Why is this an accepted convention?",,"['abstract-algebra', 'soft-question']"
62,"If every element of G/H has finite order and every element of H has finite order, then every element of G has finite order","If every element of G/H has finite order and every element of H has finite order, then every element of G has finite order",,"Let $G$ a group with normal subgroup $H$. If every element of $G/H$ has   finite order and  every element of $H$ has finite order, then every   element of $G$ has finite order Proof: Let G be a group with normal subgroup H. Suppose that every element of G/H has finite order and that every element of H has finite order. We want to show $G$ has finite order. Let $x \in G$ then by coset and quotient group definition, $Hx \in G/H$ has $Hx$ has finite order $n$ or in other words $(Hx)^n=e$. Also for some $h \in H$, it also has a finite order where $h^m=e$ I'm stuck on how to link it together. Any input?","Let $G$ a group with normal subgroup $H$. If every element of $G/H$ has   finite order and  every element of $H$ has finite order, then every   element of $G$ has finite order Proof: Let G be a group with normal subgroup H. Suppose that every element of G/H has finite order and that every element of H has finite order. We want to show $G$ has finite order. Let $x \in G$ then by coset and quotient group definition, $Hx \in G/H$ has $Hx$ has finite order $n$ or in other words $(Hx)^n=e$. Also for some $h \in H$, it also has a finite order where $h^m=e$ I'm stuck on how to link it together. Any input?",,['abstract-algebra']
63,"Any set with Associativity, Left Identity, Left Inverse, is a Group. - Fraleigh p.49 4.38","Any set with Associativity, Left Identity, Left Inverse, is a Group. - Fraleigh p.49 4.38",,"I couldn't unravel the 3rd para. in a similar post . Proof that left identity element = right identity element: $\begin{align} \color{#1E90FF}e*e &= \color{darkorange}  {e} \\ \color{#1E90FF}{a^{-1}*a}*e& =\color{darkorange}  {a^{-1}*a} \\ \color{purple}{(a^{-1})^{-1}*}\color{#1E90FF}{a^{-1}*a}*e& =\color{purple}{(a^{-1})^{-1}*}\color{darkorange}  {a^{-1}*a} \\ \color{purple}{[(a^{-1})^{-1}*}\color{#1E90FF}{a^{-1}] *a}*e& =\color{purple}{[(a^{-1})^{-1}*}\color{darkorange}  {a^{-1}]*a} \\ \color{#1E90FF}{a}*e& = \qquad \qquad \qquad \quad\color{darkorange}  {a}  \end{align}$ Proof that left inverse = right inverse, $\begin{align}a^{-1} * a & = e \\ a^{-1} * a \color{#1E90FF}{* a^{-1}} &= e \color{#1E90FF}{* a^{-1}}  \\ a^{-1} * a \color{#1E90FF}{* a^{-1}} &=  \color{#1E90FF}{a^{-1}} \\ \color{magenta}{[(a^{-1})^{-1}*}a^{-1}] * a \color{#1E90FF}{* a^{-1}} &= \color{magenta}{(a^{-1})^{-1}*} \color{#1E90FF}{a^{-1}} \\  a \color{#1E90FF}{* a^{-1}} &= e \end{align}$ How can you prognosticate the tricky algebra here? You must rewrite $e$ as $a*a^{-1}$ and must know what to multiply by. Can someone please make this less prescient? Why does a one-sided definition of a group have to be all left sided or right sided?  I'm NOT asking about the algebra...I'm asking for the intuition? If one-sided definitions are correct for groups, why not use them instead of the standard two-sided definitions? Reference: Fraleigh, A First Course in Abstract Algebra , p. 49 Question 4.38.","I couldn't unravel the 3rd para. in a similar post . Proof that left identity element = right identity element: $\begin{align} \color{#1E90FF}e*e &= \color{darkorange}  {e} \\ \color{#1E90FF}{a^{-1}*a}*e& =\color{darkorange}  {a^{-1}*a} \\ \color{purple}{(a^{-1})^{-1}*}\color{#1E90FF}{a^{-1}*a}*e& =\color{purple}{(a^{-1})^{-1}*}\color{darkorange}  {a^{-1}*a} \\ \color{purple}{[(a^{-1})^{-1}*}\color{#1E90FF}{a^{-1}] *a}*e& =\color{purple}{[(a^{-1})^{-1}*}\color{darkorange}  {a^{-1}]*a} \\ \color{#1E90FF}{a}*e& = \qquad \qquad \qquad \quad\color{darkorange}  {a}  \end{align}$ Proof that left inverse = right inverse, $\begin{align}a^{-1} * a & = e \\ a^{-1} * a \color{#1E90FF}{* a^{-1}} &= e \color{#1E90FF}{* a^{-1}}  \\ a^{-1} * a \color{#1E90FF}{* a^{-1}} &=  \color{#1E90FF}{a^{-1}} \\ \color{magenta}{[(a^{-1})^{-1}*}a^{-1}] * a \color{#1E90FF}{* a^{-1}} &= \color{magenta}{(a^{-1})^{-1}*} \color{#1E90FF}{a^{-1}} \\  a \color{#1E90FF}{* a^{-1}} &= e \end{align}$ How can you prognosticate the tricky algebra here? You must rewrite $e$ as $a*a^{-1}$ and must know what to multiply by. Can someone please make this less prescient? Why does a one-sided definition of a group have to be all left sided or right sided?  I'm NOT asking about the algebra...I'm asking for the intuition? If one-sided definitions are correct for groups, why not use them instead of the standard two-sided definitions? Reference: Fraleigh, A First Course in Abstract Algebra , p. 49 Question 4.38.",,['abstract-algebra']
64,Is every Artinian module over an Artinian ring finitely generated?,Is every Artinian module over an Artinian ring finitely generated?,,"I know that if $R$ is Artinian, then a f.g. $R$-module is Artinian. Is f.g. a necessary condition?","I know that if $R$ is Artinian, then a f.g. $R$-module is Artinian. Is f.g. a necessary condition?",,"['abstract-algebra', 'commutative-algebra']"
65,How to solve system of equations with mod?,How to solve system of equations with mod?,,"I'm trying to solve for $a$ and $b$: $$5 \equiv (4a + b)\bmod{26}\quad\text{and}\quad22\equiv (7a + b)\bmod{26}.$$ I tried looking it up online, and the thing that seemed most similar was the Chinese remainder theorem; however, I couldn't find an instance where it fit something more like what I want to solve. A simple explanation or a reference to one would be most appreciated. With my (limited) knowledge of algebra, I figured out that $x\ \textrm{mod}\ 26 = x - 26\lfloor\frac{x}{26}\rfloor$, so I tried substituting that into my equations: $$5=(4a+b)-26\left\lfloor\frac{4a+b}{26}\right\rfloor\quad\text{and}\quad 22=(7a+b)-26\left\lfloor\frac{7a+b}{26}\right\rfloor.$$ And I figured I could do something with that since I got rid of the mod, but... I have never solved an equation with a floor function before.","I'm trying to solve for $a$ and $b$: $$5 \equiv (4a + b)\bmod{26}\quad\text{and}\quad22\equiv (7a + b)\bmod{26}.$$ I tried looking it up online, and the thing that seemed most similar was the Chinese remainder theorem; however, I couldn't find an instance where it fit something more like what I want to solve. A simple explanation or a reference to one would be most appreciated. With my (limited) knowledge of algebra, I figured out that $x\ \textrm{mod}\ 26 = x - 26\lfloor\frac{x}{26}\rfloor$, so I tried substituting that into my equations: $$5=(4a+b)-26\left\lfloor\frac{4a+b}{26}\right\rfloor\quad\text{and}\quad 22=(7a+b)-26\left\lfloor\frac{7a+b}{26}\right\rfloor.$$ And I figured I could do something with that since I got rid of the mod, but... I have never solved an equation with a floor function before.",,"['abstract-algebra', 'modular-arithmetic']"
66,Constructive proof of the existence of an algebraic closure,Constructive proof of the existence of an algebraic closure,,"It is well-known that, assuming the axiom of the choice (in the form of Zorn's lemma), one can prove that any field $F$ has an algebraic closure. One proof roughly goes as follows: consider the partially-ordered set of algebraic extensions $K/F$, ordered by inclusion; show that it satisfies the hypotheses of Zorn's lemma; then Zorn's lemma implies the existence of a maximal element; show that this maximal element is algebraically closed. Now, in my Algebraic Number theory class, the professor gave a ""constructive"" proof of this fact: let $S$ be the set consisting of all non constant polynomials in $F[X]$, and construct the ring $R=F[X_f:f\in S]$ (that is, a polynomial ring with one variable for each element of $S$); let $A_0$ be the ideal of $R$ generated by polynomial $\{f(X_f):f\in S\}$; show that it is a proper ideal, and so it is contained in a maximal ideal $A$; the quotient $R/A$ is thus a field, which contains $F$ as a subfield; iterate, and take the union of all these fields; then, this union is the algebraic closure of $F$. He also mentionned (if I recall correctly) that one can prove that after only one iteration, you get the algebraic closure. Now, I put quotation marks around ""constructive"", because I suspect that one still needs the axiom of choice at some point to prove that, indeed, you have the algebraic closure (although I haven't checked the details). So, here's my question: Is it the case that this proof is constructive? Another question: Can one prove the existence of an algebraic closure within ZF (without the axiom of choice)? Thanks in advance.","It is well-known that, assuming the axiom of the choice (in the form of Zorn's lemma), one can prove that any field $F$ has an algebraic closure. One proof roughly goes as follows: consider the partially-ordered set of algebraic extensions $K/F$, ordered by inclusion; show that it satisfies the hypotheses of Zorn's lemma; then Zorn's lemma implies the existence of a maximal element; show that this maximal element is algebraically closed. Now, in my Algebraic Number theory class, the professor gave a ""constructive"" proof of this fact: let $S$ be the set consisting of all non constant polynomials in $F[X]$, and construct the ring $R=F[X_f:f\in S]$ (that is, a polynomial ring with one variable for each element of $S$); let $A_0$ be the ideal of $R$ generated by polynomial $\{f(X_f):f\in S\}$; show that it is a proper ideal, and so it is contained in a maximal ideal $A$; the quotient $R/A$ is thus a field, which contains $F$ as a subfield; iterate, and take the union of all these fields; then, this union is the algebraic closure of $F$. He also mentionned (if I recall correctly) that one can prove that after only one iteration, you get the algebraic closure. Now, I put quotation marks around ""constructive"", because I suspect that one still needs the axiom of choice at some point to prove that, indeed, you have the algebraic closure (although I haven't checked the details). So, here's my question: Is it the case that this proof is constructive? Another question: Can one prove the existence of an algebraic closure within ZF (without the axiom of choice)? Thanks in advance.",,"['abstract-algebra', 'field-theory', 'axiom-of-choice']"
67,Nonabelian semidirect products of order $pq$?,Nonabelian semidirect products of order ?,pq,"I just constructed the semidirect product in Lang, and I'm trying to tie some facts together. From Ash's Algebra, I know that if $p\lt q$ are distinct primes, if $q\not\equiv 1\pmod{p}$, then any group $G$ of order $pq$ is abelian. Is the converse true, that for any primes $p\lt q$, if $q\equiv 1\pmod{p}$ then there exists a nonabelian group of order $pq$? One example I found online is that $\mathbb{Z}_3\ltimes \mathbb{Z}_7$ is nonabelian, and here $7\equiv 1\pmod{3}$. I was considering then semidirect products $\mathbb{Z}_p\ltimes\mathbb{Z}_q$ where $q\equiv 1\pmod{p}$ and some homomorphism $\phi\colon \mathbb{Z}_p\to\operatorname{Aut}(\mathbb{Z}_q)$ I calculate that  $$ (1,0)(0,1)=(1+0,\phi_0(0)+1)=(1,1) $$ and $$ (0,1)(1,0)=(0+1,\phi_{-1}(1)+0)=(1,\phi_{p-1}(1)). $$ Is it true somehow that $\phi_{p-1}(1)\neq 1$ in each case to show the group is nonabelian? I guess if it did this would imply $\phi_{p-1}$ is the trivial automorphism, so maybe there's something there? If not, is there a way to show $\mathbb{Z}_p\ltimes\mathbb{Z}_q$ is nonabelian in these cases in general? Thanks.","I just constructed the semidirect product in Lang, and I'm trying to tie some facts together. From Ash's Algebra, I know that if $p\lt q$ are distinct primes, if $q\not\equiv 1\pmod{p}$, then any group $G$ of order $pq$ is abelian. Is the converse true, that for any primes $p\lt q$, if $q\equiv 1\pmod{p}$ then there exists a nonabelian group of order $pq$? One example I found online is that $\mathbb{Z}_3\ltimes \mathbb{Z}_7$ is nonabelian, and here $7\equiv 1\pmod{3}$. I was considering then semidirect products $\mathbb{Z}_p\ltimes\mathbb{Z}_q$ where $q\equiv 1\pmod{p}$ and some homomorphism $\phi\colon \mathbb{Z}_p\to\operatorname{Aut}(\mathbb{Z}_q)$ I calculate that  $$ (1,0)(0,1)=(1+0,\phi_0(0)+1)=(1,1) $$ and $$ (0,1)(1,0)=(0+1,\phi_{-1}(1)+0)=(1,\phi_{p-1}(1)). $$ Is it true somehow that $\phi_{p-1}(1)\neq 1$ in each case to show the group is nonabelian? I guess if it did this would imply $\phi_{p-1}$ is the trivial automorphism, so maybe there's something there? If not, is there a way to show $\mathbb{Z}_p\ltimes\mathbb{Z}_q$ is nonabelian in these cases in general? Thanks.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'semidirect-product']"
68,Every finite commutative ring with no zero divisors contains a multiplicative identity?,Every finite commutative ring with no zero divisors contains a multiplicative identity?,,"There is an easy argument which shows that a finite integral domain (commutative unital ring with no zero divisors) is a field. Here I wonder whether this result still stands if the term ""unital"" is dropped. In other words, can a finite commutative ring with no zero divisors always contain a multiplicative identity? More generally, if this is true, can we even generalize Wedderburn's little theorem: every finite ring with no zero divisors is a field?","There is an easy argument which shows that a finite integral domain (commutative unital ring with no zero divisors) is a field. Here I wonder whether this result still stands if the term ""unital"" is dropped. In other words, can a finite commutative ring with no zero divisors always contain a multiplicative identity? More generally, if this is true, can we even generalize Wedderburn's little theorem: every finite ring with no zero divisors is a field?",,"['abstract-algebra', 'ring-theory']"
69,Examples of properties not preserved under homomorphism,Examples of properties not preserved under homomorphism,,"An isomorphism indicates that two structures are the same, using different names for the elements. Therefore it's obvious that every (algebraic) property of the first structure must be present in the second. However, homomorphisms only indicate that the two structures are ""similar"", so it's not quite as obvious that every property will be preserved. Yet all the properties I've ever seen are preserved under homomorphism: commutativity, cyclicality, solvability... What are some examples of properties of algebraic structures not preserved under homomorphism? Feel free to use any algebraic structures you like, but I'm particularly interested in your garden variety structures: group and rings, say.","An isomorphism indicates that two structures are the same, using different names for the elements. Therefore it's obvious that every (algebraic) property of the first structure must be present in the second. However, homomorphisms only indicate that the two structures are ""similar"", so it's not quite as obvious that every property will be preserved. Yet all the properties I've ever seen are preserved under homomorphism: commutativity, cyclicality, solvability... What are some examples of properties of algebraic structures not preserved under homomorphism? Feel free to use any algebraic structures you like, but I'm particularly interested in your garden variety structures: group and rings, say.",,"['abstract-algebra', 'group-theory', 'ring-theory', 'big-list']"
70,Constructing a degree 4 rational polynomial satisfying $f(\sqrt{2}+\sqrt{3}) = 0$,Constructing a degree 4 rational polynomial satisfying,f(\sqrt{2}+\sqrt{3}) = 0,"Goal: Find $f \in \mathbb{Q}[x]$ such that $f(\sqrt{2}+\sqrt{3}) = 0$. A direct approach is to look at the following $$ \begin{align} (\sqrt{2}+\sqrt{3})^2 &= 5+2\sqrt{6} \\ (\sqrt{2}+\sqrt{3})^4 &= (5+2\sqrt{6})^2 = 49+20\sqrt{6} \\ \end{align} $$ Putting those together gives $$ -1 + 10(\sqrt{2}+\sqrt{3})^2 - (\sqrt{2}+\sqrt{3})^4 = 0, $$ so $f(x) = -1 + 10x^2 - x^4$ satisfies $f(\sqrt{2}+\sqrt{3}) = 0$. Is there a more mechanical approach? Perhaps not entirely mechanical, but something more abstract.","Goal: Find $f \in \mathbb{Q}[x]$ such that $f(\sqrt{2}+\sqrt{3}) = 0$. A direct approach is to look at the following $$ \begin{align} (\sqrt{2}+\sqrt{3})^2 &= 5+2\sqrt{6} \\ (\sqrt{2}+\sqrt{3})^4 &= (5+2\sqrt{6})^2 = 49+20\sqrt{6} \\ \end{align} $$ Putting those together gives $$ -1 + 10(\sqrt{2}+\sqrt{3})^2 - (\sqrt{2}+\sqrt{3})^4 = 0, $$ so $f(x) = -1 + 10x^2 - x^4$ satisfies $f(\sqrt{2}+\sqrt{3}) = 0$. Is there a more mechanical approach? Perhaps not entirely mechanical, but something more abstract.",,"['abstract-algebra', 'polynomials', 'soft-question']"
71,"If a group $G$ has only finitely many subgroups, then show that $G$ is a finite group. [duplicate]","If a group  has only finitely many subgroups, then show that  is a finite group. [duplicate]",G G,"This question already has answers here : Finite number of subgroups $\Rightarrow$  finite group (2 answers) Closed 11 years ago . If a group $G$ has only finitely many subgroups, then show that $G$ is a finite group.  I have no idea on how to start this question. Can anyone guide me?","This question already has answers here : Finite number of subgroups $\Rightarrow$  finite group (2 answers) Closed 11 years ago . If a group $G$ has only finitely many subgroups, then show that $G$ is a finite group.  I have no idea on how to start this question. Can anyone guide me?",,"['abstract-algebra', 'group-theory']"
72,The notation $\prod_{g\in G} g$ for a finite group not well-defined.,The notation  for a finite group not well-defined.,\prod_{g\in G} g,"I want to solve the following exercise. Let $G$ be a finite group, with exactly one element $f$ of order $2$.   Prove that $\prod_{g\in G} g = f$. I have a question regarding the notation, the expression $\prod_{g\in G} g$ stands for the product over all elements of $G$? But then it is not well-defined for non-abelian group, cause the order in which this product is evaluated matters? Or for what else can $\prod_{g\in G} g$ stand? EDIT:  I have taken the exercise from an algebra book, and I just looked up the homepage of the author and found an errata. And indeed, the exercise is wrongly stated! The group must be assumed to be abelian. http://www.math.fsu.edu/~aluffi/algebraerrata/Errata.html","I want to solve the following exercise. Let $G$ be a finite group, with exactly one element $f$ of order $2$.   Prove that $\prod_{g\in G} g = f$. I have a question regarding the notation, the expression $\prod_{g\in G} g$ stands for the product over all elements of $G$? But then it is not well-defined for non-abelian group, cause the order in which this product is evaluated matters? Or for what else can $\prod_{g\in G} g$ stand? EDIT:  I have taken the exercise from an algebra book, and I just looked up the homepage of the author and found an errata. And indeed, the exercise is wrongly stated! The group must be assumed to be abelian. http://www.math.fsu.edu/~aluffi/algebraerrata/Errata.html",,"['abstract-algebra', 'group-theory']"
73,Example of a group,Example of a group,,"Can one give an example of a finite group $G$, with a subset $H$ containing identity, such that $gHg^{-1}=H$ for all $g\in G$, $|H|$ divides $|G|$, but $H$ is not a subgroup of $G$. Motivation ( Theorem of Frobenius ): If $G$ acts on a set $X$ tranitively ( $|X|>1$), such that stabilizers are non-trivial but intersection of any two stabilizers is trivial, then the set $K$ of elements of $G$ which have no fixed point, together with identity, form a normal subgroup of $G$. It is easy to see that the condition of normality is easily verified, but to prove that it is a subgroup of $G$, character theory has been used. While proving this theorem, the necessary conditions are: $|K|$ should divide $|G|$ $gKg^{-1}=K$ for all $g\in G$. I would like to see an example, where subset of $G$ (containing identity) which satisfies these two conditions but it is not a subgroup of $G$.","Can one give an example of a finite group $G$, with a subset $H$ containing identity, such that $gHg^{-1}=H$ for all $g\in G$, $|H|$ divides $|G|$, but $H$ is not a subgroup of $G$. Motivation ( Theorem of Frobenius ): If $G$ acts on a set $X$ tranitively ( $|X|>1$), such that stabilizers are non-trivial but intersection of any two stabilizers is trivial, then the set $K$ of elements of $G$ which have no fixed point, together with identity, form a normal subgroup of $G$. It is easy to see that the condition of normality is easily verified, but to prove that it is a subgroup of $G$, character theory has been used. While proving this theorem, the necessary conditions are: $|K|$ should divide $|G|$ $gKg^{-1}=K$ for all $g\in G$. I would like to see an example, where subset of $G$ (containing identity) which satisfies these two conditions but it is not a subgroup of $G$.",,['abstract-algebra']
74,"$\ker \phi = (x_1-a_1, ..., x_n-a_n)$ for a ring homomorphism $\phi: R[x_1, ..., x_n] \to R$",for a ring homomorphism,"\ker \phi = (x_1-a_1, ..., x_n-a_n) \phi: R[x_1, ..., x_n] \to R","Let $R$ be a commutative ring, $a_1, ..., a_n$ its elements and $\phi: R[x_1, ..., x_n] \to R$ defined by $ \phi(f(x_1, ..., x_n)) = f(a_1, ... ,a_n)$ a ring homomorphism. Prove: $\ker \phi = (x_1-a_1, ..., x_n-a_n)$ It is obvious that $(x_1 - a_1, ..., x_n -a_n) \subseteq \ker \phi$. I'm not sure how to prove the converse. At this point I don't know any division algorithms for multivariable polynomials, only for the ones in $R[x]$(and the book from where I taken the exercise doesn't assume the reader to know something beyond basics of rings and ideals, and the division algorithm for $R[x]$). Though I know this could be solved for $i = 1$ by dividing by $x-a$: Let $f(x) \in \ker \phi$, divide by $x-a: f(x) = q(x)(x-a) + r, f(a) = r = 0$, so $f(x) = q(x)(x-a) \in (x-a)$.","Let $R$ be a commutative ring, $a_1, ..., a_n$ its elements and $\phi: R[x_1, ..., x_n] \to R$ defined by $ \phi(f(x_1, ..., x_n)) = f(a_1, ... ,a_n)$ a ring homomorphism. Prove: $\ker \phi = (x_1-a_1, ..., x_n-a_n)$ It is obvious that $(x_1 - a_1, ..., x_n -a_n) \subseteq \ker \phi$. I'm not sure how to prove the converse. At this point I don't know any division algorithms for multivariable polynomials, only for the ones in $R[x]$(and the book from where I taken the exercise doesn't assume the reader to know something beyond basics of rings and ideals, and the division algorithm for $R[x]$). Though I know this could be solved for $i = 1$ by dividing by $x-a$: Let $f(x) \in \ker \phi$, divide by $x-a: f(x) = q(x)(x-a) + r, f(a) = r = 0$, so $f(x) = q(x)(x-a) \in (x-a)$.",,"['abstract-algebra', 'polynomials', 'ring-theory']"
75,Classification of Finite Topologies,Classification of Finite Topologies,,"Does there exist a classification of finite topologies? I define a finite topology as a finite Set $T$ of Sets which respects the following properties: $\forall a,b \in T:  a \cap b \in T$, $\forall a,b \in T: a \cup b \in T$, $ \emptyset \in T$, $\exists S\in T\ |\ \forall a \in T , a \subseteq S$. This seems like a natural thing to do in the vein of classifying finite groups, so i'm curious what current research in this area looks like.","Does there exist a classification of finite topologies? I define a finite topology as a finite Set $T$ of Sets which respects the following properties: $\forall a,b \in T:  a \cap b \in T$, $\forall a,b \in T: a \cup b \in T$, $ \emptyset \in T$, $\exists S\in T\ |\ \forall a \in T , a \subseteq S$. This seems like a natural thing to do in the vein of classifying finite groups, so i'm curious what current research in this area looks like.",,"['abstract-algebra', 'general-topology', 'universal-algebra']"
76,Group with exactly two subgroups of index 2,Group with exactly two subgroups of index 2,,I am looking for a group $G$ such that $G$ has exactly two subgroups of index 2. I have searched by GAP but I couldn't find it.,I am looking for a group such that has exactly two subgroups of index 2. I have searched by GAP but I couldn't find it.,G G,"['abstract-algebra', 'group-theory']"
77,Is every $1$-dimensional vector space a field?,Is every -dimensional vector space a field?,1,"We say that every field $F$ ""is"" a $1$ -D vector space over itself. By this we mean that if we consider the elements of $F$ as both vectors and scalars, then we get a vector space by using the addition and multiplication from $F$ . It seems just as easy to go in the other direction and interpret any $1$ -D vector space as a field. But I've never seen it written that every $1$ -D vector space ""is"" a field. Why?","We say that every field ""is"" a -D vector space over itself. By this we mean that if we consider the elements of as both vectors and scalars, then we get a vector space by using the addition and multiplication from . It seems just as easy to go in the other direction and interpret any -D vector space as a field. But I've never seen it written that every -D vector space ""is"" a field. Why?",F 1 F F 1 1,"['abstract-algebra', 'vector-spaces', 'field-theory', 'terminology']"
78,Does there exist some sort of classification of incompressible groups?,Does there exist some sort of classification of incompressible groups?,,"It is well known, that any finite group of order $n$ is isomorphic to a subgroup of $S_n$ . Let’s call a finite group $G$ incompressible iff it is not isomorphic to any subgroup of $S_{|G|-1}$ . Does there exist some sort of classification of incompressible groups? What I currently know: Any  non-trivial incompressible group has non-trivial center If the center of a group $G$ is trivial, then it acts faithfully by conjugation on $G \setminus \{e\}$ . If an incompressible group is non-trivially decomposed into a direct product of two its subgroups, it is isomorphic to $C_2 \times C_2$ One can construct a faithful action of $H \times K$ on $H \cup K$ . It is defined as $(h, k)h_0 \mapsto hh_0$ and $(h, k)h_0 \mapsto kk_0$ for $h, h_0 \in H$ , $k, k_0 \in K$ . $|H| + |K| \geq |H||K|$ iff either one of the groups is trivial, or both of them are isomorphic to $C_2$ . $C_2 \times C_2$ is the only possible group and indeed is not contained in $S_3$ . I also conjecture, that «direct product» in this statement can be replaced with «semidirect product», but do not know how to prove that. All cyclic $p$ -groups are incompressible If $p$ is prime, then $S_{p^n - 1}$ does not have an element of order $p^n$ $Q_8$ is incompressible $S_7$ does not contain $Q_8$ as a subgroup","It is well known, that any finite group of order is isomorphic to a subgroup of . Let’s call a finite group incompressible iff it is not isomorphic to any subgroup of . Does there exist some sort of classification of incompressible groups? What I currently know: Any  non-trivial incompressible group has non-trivial center If the center of a group is trivial, then it acts faithfully by conjugation on . If an incompressible group is non-trivially decomposed into a direct product of two its subgroups, it is isomorphic to One can construct a faithful action of on . It is defined as and for , . iff either one of the groups is trivial, or both of them are isomorphic to . is the only possible group and indeed is not contained in . I also conjecture, that «direct product» in this statement can be replaced with «semidirect product», but do not know how to prove that. All cyclic -groups are incompressible If is prime, then does not have an element of order is incompressible does not contain as a subgroup","n S_n G S_{|G|-1} G G \setminus \{e\} C_2 \times C_2 H \times K H \cup K (h, k)h_0 \mapsto hh_0 (h, k)h_0 \mapsto kk_0 h, h_0 \in H k, k_0 \in K |H| + |K| \geq |H||K| C_2 C_2 \times C_2 S_3 p p S_{p^n - 1} p^n Q_8 S_7 Q_8","['abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups', 'group-actions']"
79,Understanding Serre-Chevalley relations,Understanding Serre-Chevalley relations,,"I was studying Chevalley-Serre relations, which can be summed up to these $$\tag{S1}\left[h_{i},\,h_{j}\right]=0$$ $$\tag{S2}\left[e_{i},\,f_{i}\right]=h_{i}  \quad   \left[e_{i},\,f_{j}\right]=0  \quad\text{for } i\neq j$$ $$\tag{S3} \left[h_{i},\,e_{j}\right]=A_{ij}e_{j} \quad \left[h_{i},\,f_{j}\right]=-A_{ij}f_{j}$$ $$\tag{S4} \text{ad}\left(e_{i}\right)^{1-A_{ij}}\left(e_{j}\right)=0 \quad\;\; \text{ad}\left(f_{i}\right)^{1-A_{ij}}\left(f_{j}\right)=0 \quad\text{for } i\neq j$$ where $A_{ij}$ are the coefficients of the Cartan matrix. Now it seems to me that relations (S1),(S2), and (S3) are really quite natural, but I don't fully understand relations in (S4). Does anybody has an insight on what does those relations mean?","I was studying Chevalley-Serre relations, which can be summed up to these where are the coefficients of the Cartan matrix. Now it seems to me that relations (S1),(S2), and (S3) are really quite natural, but I don't fully understand relations in (S4). Does anybody has an insight on what does those relations mean?","\tag{S1}\left[h_{i},\,h_{j}\right]=0 \tag{S2}\left[e_{i},\,f_{i}\right]=h_{i}  \quad   \left[e_{i},\,f_{j}\right]=0  \quad\text{for } i\neq j \tag{S3} \left[h_{i},\,e_{j}\right]=A_{ij}e_{j}
\quad \left[h_{i},\,f_{j}\right]=-A_{ij}f_{j} \tag{S4} \text{ad}\left(e_{i}\right)^{1-A_{ij}}\left(e_{j}\right)=0
\quad\;\; \text{ad}\left(f_{i}\right)^{1-A_{ij}}\left(f_{j}\right)=0 \quad\text{for } i\neq j A_{ij}","['abstract-algebra', 'representation-theory', 'lie-groups', 'lie-algebras']"
80,Algebraic geometry in representation theory?,Algebraic geometry in representation theory?,,"I heard that today algebraic geometry plays some significant role in representation theory, which is a little surprising because when I learnt representation theory it is basically algebra, topology, differential geometry and a little functional analysis. I am wondering whether someone can tell me how algebraic geometry enters the picture. I do not know much algebraic geometry so I am just looking for some expository, so maybe we can forget the technicalities for now. Thanks very much!","I heard that today algebraic geometry plays some significant role in representation theory, which is a little surprising because when I learnt representation theory it is basically algebra, topology, differential geometry and a little functional analysis. I am wondering whether someone can tell me how algebraic geometry enters the picture. I do not know much algebraic geometry so I am just looking for some expository, so maybe we can forget the technicalities for now. Thanks very much!",,"['abstract-algebra', 'algebraic-geometry', 'representation-theory', 'intuition', 'big-list']"
81,Quadratic subfield of cyclotomic field [duplicate],Quadratic subfield of cyclotomic field [duplicate],,"This question already has answers here : Unique quadratic subfield of $\mathbb{Q}(\zeta_p)$ is $\mathbb{Q}(\sqrt{p})$ if $p \equiv 1$ $(4)$, and $\mathbb{Q}(\sqrt{-p})$ if $p \equiv 3$ $(4)$ (4 answers) Closed 5 years ago . Let $p$ be prime and let $\zeta_p$ be a primitive $p$th root of unity. Consider the quadratic subfield of $\mathbb{Q}(\zeta_p)$. For instance, for $p=5$ we get the quadratic subfield to be $\mathbb{Q}(\sqrt5)$ obtained by the relation between the golden ratio and $\cos(2\pi/5)$ (the minimal polynomial of the golden ratio $\phi$ is $x^2-x-1$ and so the extension is quadratic). Also $\cos(\pi/5)=\phi/2\implies \cos(2\pi/5)=\phi^2/2-1$ by double angle identity. Is it true that in general the quadratic extension is $\mathbb{Q}(\sqrt{\pm p})$ where $\pm$ depends on whether $p$ is $1$ or $-1$ $\pmod 4$? Please prove or disprove.","This question already has answers here : Unique quadratic subfield of $\mathbb{Q}(\zeta_p)$ is $\mathbb{Q}(\sqrt{p})$ if $p \equiv 1$ $(4)$, and $\mathbb{Q}(\sqrt{-p})$ if $p \equiv 3$ $(4)$ (4 answers) Closed 5 years ago . Let $p$ be prime and let $\zeta_p$ be a primitive $p$th root of unity. Consider the quadratic subfield of $\mathbb{Q}(\zeta_p)$. For instance, for $p=5$ we get the quadratic subfield to be $\mathbb{Q}(\sqrt5)$ obtained by the relation between the golden ratio and $\cos(2\pi/5)$ (the minimal polynomial of the golden ratio $\phi$ is $x^2-x-1$ and so the extension is quadratic). Also $\cos(\pi/5)=\phi/2\implies \cos(2\pi/5)=\phi^2/2-1$ by double angle identity. Is it true that in general the quadratic extension is $\mathbb{Q}(\sqrt{\pm p})$ where $\pm$ depends on whether $p$ is $1$ or $-1$ $\pmod 4$? Please prove or disprove.",,"['abstract-algebra', 'field-theory', 'galois-theory', 'cyclic-groups', 'roots-of-unity']"
82,A finite dimensional commutative algebra is a finite product of commutative local algebras,A finite dimensional commutative algebra is a finite product of commutative local algebras,,"A finite dimensional commutative algebra is a finite product of commutative local algebras. Why? In fact, every commutative semiperfect ring is a basic ring and isomorphic to a finite product of local rings, but I do not how to prove it.","A finite dimensional commutative algebra is a finite product of commutative local algebras. Why? In fact, every commutative semiperfect ring is a basic ring and isomorphic to a finite product of local rings, but I do not how to prove it.",,"['abstract-algebra', 'commutative-algebra']"
83,Integer Solutions to $x^2+y^2=5z^2$,Integer Solutions to,x^2+y^2=5z^2,"I'm looking for a formula to generate all solutions $x$, $y$, $z$ for $x^2 + y^2 = 5z^2$. Any advice?","I'm looking for a formula to generate all solutions $x$, $y$, $z$ for $x^2 + y^2 = 5z^2$. Any advice?",,"['abstract-algebra', 'diophantine-equations']"
84,Does every field have a non-trivial Galois extension?,Does every field have a non-trivial Galois extension?,,"Clearly a field $F$ with no Galois extensions must have only non-separable elements in any extension (otherwise, take the minimal polynomial of some separable element over $F$ - its splitting field will be a Galois extension of $F$). This argument reduces the possible examples to non-perfect fields, or in other words - infinite fields of positive characteristic. However, I can't come up with an example of such a field with no separable elements over it. Are there any such examples? EDIT: I should have been clearer - I'm looking for a field that has non-trivial algebraic extensions, but has no non-trivial Galois extensions.","Clearly a field $F$ with no Galois extensions must have only non-separable elements in any extension (otherwise, take the minimal polynomial of some separable element over $F$ - its splitting field will be a Galois extension of $F$). This argument reduces the possible examples to non-perfect fields, or in other words - infinite fields of positive characteristic. However, I can't come up with an example of such a field with no separable elements over it. Are there any such examples? EDIT: I should have been clearer - I'm looking for a field that has non-trivial algebraic extensions, but has no non-trivial Galois extensions.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
85,"How to understand ""tensor"" in commutative algebra?","How to understand ""tensor"" in commutative algebra?",,"Tensor is sure an important concept in commutative algebra, but the definition is kind of abstract, so is there any way to understand it which is easier? Thanks advance! The definition I see is the one defined by modules. Proposition 2.12. Let $M, N$ be $A$ -modules. Then there exists a pair $(T,g)$ consisting of an $A$ -module $T$ and an $A$ -bilinear mapping $g \colon M \times N \to T$ , with the following property: Given any $A$ -module $P$ and any $A$ -bilinear mapping $f \colon M \times N \to P$ , there exists a unique $A$ -linear mapping $f' \colon T \to P$ such that $f = f' \circ g$ (in other words, every bilinear function on $M \times N$ factors through $T$ ). Moreover, if $(T,g)$ and $(T',g')$ are two pairs with this property, then there exists a unique isomorphism $j \colon T \to T'$ such that $j \circ g = g'$ .","Tensor is sure an important concept in commutative algebra, but the definition is kind of abstract, so is there any way to understand it which is easier? Thanks advance! The definition I see is the one defined by modules. Proposition 2.12. Let be -modules. Then there exists a pair consisting of an -module and an -bilinear mapping , with the following property: Given any -module and any -bilinear mapping , there exists a unique -linear mapping such that (in other words, every bilinear function on factors through ). Moreover, if and are two pairs with this property, then there exists a unique isomorphism such that .","M, N A (T,g) A T A g \colon M \times N \to T A P A f \colon M \times N \to P A f' \colon T \to P f = f' \circ g M \times N T (T,g) (T',g') j \colon T \to T' j \circ g = g'","['abstract-algebra', 'commutative-algebra', 'tensor-products']"
86,Noncyclic Abelian Group of order 51,Noncyclic Abelian Group of order 51,,"The problem is to prove or disprove that there is a noncyclic abelian group of order $51$. I don't think such a group exists. Here is a brief outline of my proof: Assume for a contradiction that there exists a noncyclic abelian group of order $51$. We know that every element (except the identity) has order $3$ or $17$. Assume that $|a|=3$ and $|b|=17$. Then I managed to prove that the subgroups generated by $a$ and $b$ only intersect at the identity element, from which we can show that $ab$ is a generator of the whole group, so it is cyclic. Contradiction. So every element (except the identity) has the same order $p$, where $p$ is either $3$ or $17$. If $p=17$, take $a$ not equal to the identity, and take $b$ not in the subgroup generated by $a$. Then we can prove that $a^kb^l$ where $k,l$ are integers between $0$ and $16$ inclusive are distinct, hence the group has more than $51$ elements, contradiction. If $p=3$, take $a$ not equal to the identity and take $b$ not in the subgroup generated by $a$. Then we can prove that $a^kb^l$ where $k,l$ are integers betwen $0$ and $2$ inclusive are distinct. This subgroup has $9$ elements so we can find $c$ that's not of the form $a^kb^l$. Then we can prove that $a^kb^lc^m$ where $k,l,m$ are integers betwen $0$ and $2$ inclusive are distinct. Then this subgroup has $27$ elements so we can find $d$ that's not of the form $a^kb^lc^m$. Then we prove that $a^kb^lc^md^n$ where $k,l,m,n$ are integers between $0$ and $2$ inclusive are distinct, this being $81$ elements. Contradiction.","The problem is to prove or disprove that there is a noncyclic abelian group of order $51$. I don't think such a group exists. Here is a brief outline of my proof: Assume for a contradiction that there exists a noncyclic abelian group of order $51$. We know that every element (except the identity) has order $3$ or $17$. Assume that $|a|=3$ and $|b|=17$. Then I managed to prove that the subgroups generated by $a$ and $b$ only intersect at the identity element, from which we can show that $ab$ is a generator of the whole group, so it is cyclic. Contradiction. So every element (except the identity) has the same order $p$, where $p$ is either $3$ or $17$. If $p=17$, take $a$ not equal to the identity, and take $b$ not in the subgroup generated by $a$. Then we can prove that $a^kb^l$ where $k,l$ are integers between $0$ and $16$ inclusive are distinct, hence the group has more than $51$ elements, contradiction. If $p=3$, take $a$ not equal to the identity and take $b$ not in the subgroup generated by $a$. Then we can prove that $a^kb^l$ where $k,l$ are integers betwen $0$ and $2$ inclusive are distinct. This subgroup has $9$ elements so we can find $c$ that's not of the form $a^kb^l$. Then we can prove that $a^kb^lc^m$ where $k,l,m$ are integers betwen $0$ and $2$ inclusive are distinct. Then this subgroup has $27$ elements so we can find $d$ that's not of the form $a^kb^lc^m$. Then we prove that $a^kb^lc^md^n$ where $k,l,m,n$ are integers between $0$ and $2$ inclusive are distinct, this being $81$ elements. Contradiction.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
87,Prove $\alpha \in R[[x]]$ is a unit iff $a_0 \in R$ is a unit [duplicate],Prove  is a unit iff  is a unit [duplicate],\alpha \in R[[x]] a_0 \in R,"This question already has answers here : If $a_0\in R$ is a unit, then  $\sum_{k=0}^{\infty}a_k x^k$ is a unit in $R[[x]]$ (3 answers) Closed 1 year ago . Prove $\alpha \in R[[x]]$ is a unit iff $a_0 \in R$ is a unit. $""\Rightarrow""$ suppose $\alpha \in R[[x]]$ is a unit, where $\alpha = \sum_{n=0}^{\infty} a_nx^n$ then there exists an inverse $\beta = \sum_{n=0}^{\infty} b_nx^n$ stuck at this spot, $(\sum_{n=0}^{\infty} a_nx^n)(\sum_{n=0}^{\infty} b_nx^n) = \sum_{n=0}^{\infty}(\sum_{k=0}^{n}(a_kb_{n-k}))x^n$ A little mixed up on how this becomes $1 = \sum_{n=0}^{\infty}e_nx^n$ where $e_0 =1, e_{n>0} = 0$ and why that would make $a_0b_0 = 1$ which would make $a_0 \in R$ a unit. I haven't tried the other direction yet. EDIT Maybe I get it, because we assumed this sum is a unit then its inverse exists and so the $x^0=1$ and all $a_ib_i=1$ thus $a_0b_0=1$ which gives $a_0$ is a unit in $R$","This question already has answers here : If $a_0\in R$ is a unit, then  $\sum_{k=0}^{\infty}a_k x^k$ is a unit in $R[[x]]$ (3 answers) Closed 1 year ago . Prove $\alpha \in R[[x]]$ is a unit iff $a_0 \in R$ is a unit. $""\Rightarrow""$ suppose $\alpha \in R[[x]]$ is a unit, where $\alpha = \sum_{n=0}^{\infty} a_nx^n$ then there exists an inverse $\beta = \sum_{n=0}^{\infty} b_nx^n$ stuck at this spot, $(\sum_{n=0}^{\infty} a_nx^n)(\sum_{n=0}^{\infty} b_nx^n) = \sum_{n=0}^{\infty}(\sum_{k=0}^{n}(a_kb_{n-k}))x^n$ A little mixed up on how this becomes $1 = \sum_{n=0}^{\infty}e_nx^n$ where $e_0 =1, e_{n>0} = 0$ and why that would make $a_0b_0 = 1$ which would make $a_0 \in R$ a unit. I haven't tried the other direction yet. EDIT Maybe I get it, because we assumed this sum is a unit then its inverse exists and so the $x^0=1$ and all $a_ib_i=1$ thus $a_0b_0=1$ which gives $a_0$ is a unit in $R$",,"['abstract-algebra', 'ring-theory', 'power-series']"
88,How does Cauchy's theorem follow from Sylow's theorem?,How does Cauchy's theorem follow from Sylow's theorem?,,"Very quickly, Sylow's first theorem says a Sylow $p$ -subgroup of order $p^r$ exists and Cauchy's theorem says if $p \mid |G|$ then there is an element of order $p$ . It's often said that Cauchy's follows easily from Sylow's, but I just don't see it! I don't see why a Sylow $p$ -subgroup must have an element of order $p$ ; why couldn't they all be of order $p^n,\ 2<n<r$ ?","Very quickly, Sylow's first theorem says a Sylow -subgroup of order exists and Cauchy's theorem says if then there is an element of order . It's often said that Cauchy's follows easily from Sylow's, but I just don't see it! I don't see why a Sylow -subgroup must have an element of order ; why couldn't they all be of order ?","p p^r p \mid |G| p p p p^n,\ 2<n<r","['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
89,Manipulating quotients and direct sums of abelian groups,Manipulating quotients and direct sums of abelian groups,,"I'm studying homology from Hatcher's Algebraic Topology . I feel that there is a gap in my group theory knowledge that is making me struggle with this chapter. In particular, the book (and material online) use the following without proof: If $A/B \cong C$ , where $A,B$ are abelian groups and $C$ is abelian and free, then $A \cong B \oplus C$ . If $\mathbb{Z}^n/A \cong \mathbb{Z}$ , then $A \cong \mathbb{Z}^{n-1}$ . These two seem very related. I'm looking for a proof that doesn't use exact sequences or Category Theory (not introduced in the book at that point yet). I know the fundamental theorem of finitely generated abelian groups, Sylow theorems, and the basics of ring theory (ideals, domains, CRM, etc). Basically, I read most of Artin's Algebra . Thank you.","I'm studying homology from Hatcher's Algebraic Topology . I feel that there is a gap in my group theory knowledge that is making me struggle with this chapter. In particular, the book (and material online) use the following without proof: If , where are abelian groups and is abelian and free, then . If , then . These two seem very related. I'm looking for a proof that doesn't use exact sequences or Category Theory (not introduced in the book at that point yet). I know the fundamental theorem of finitely generated abelian groups, Sylow theorems, and the basics of ring theory (ideals, domains, CRM, etc). Basically, I read most of Artin's Algebra . Thank you.","A/B \cong C A,B C A \cong B \oplus C \mathbb{Z}^n/A \cong \mathbb{Z} A \cong \mathbb{Z}^{n-1}","['abstract-algebra', 'group-theory', 'abelian-groups']"
90,Irreducible Components of the Prime Spectrum of a Quotient Ring and Primary Decomposition,Irreducible Components of the Prime Spectrum of a Quotient Ring and Primary Decomposition,,"Recently I encountered a problem (the first exercise from chapter four of Atiyah & McDonald's Introduction to Commutative Algebra ) stating that if $\mathfrak{a}$ is a decomposable ideal of $A$ (a commutative ring with unity), then the prime spectrum of $A/ \mathfrak{a}$ has finitely many irreducible components. This follows easily from the recognition that the maximal irreducible subspaces of $\textrm{ Spec } (A / \mathfrak{a})$ are precisely the ""zero loci"" of the minimal prime ideals of $A /\mathfrak{a}$. I'm curious about the converse - the proof isn't easily reversed since the notion of minimal ideals of $\mathfrak{a} $ doesn't make sense before we know what we are trying to prove. My intuition says that it is false based on the general premise that images are badly-behaved (and the fact that it isn't part of the exercise.) However, I've had some difficulty constructing a counterexample, so that the main purpose of this post is to ask for a reasonable procedure or heuristic for doing so (or, of course, proof that my intuition is false.) If it helps, if $\textrm{Spec }(A / \mathfrak{a})$ is irreducible then the nilradical $\mathcal{R}_{A /\mathfrak{a}}$ is prime so that $r(\mathfrak{a}) = \rho^{-1} ( \mathcal{R}_{A / \mathfrak{a}} ) = \displaystyle\cap_{i=1}^n \rho^{-1} (p_i),$ where $p_i$ are the minimal prime ideals of $A /\mathfrak{a}$ and $\rho $ is the associated projection, is also prime. Thanks!","Recently I encountered a problem (the first exercise from chapter four of Atiyah & McDonald's Introduction to Commutative Algebra ) stating that if $\mathfrak{a}$ is a decomposable ideal of $A$ (a commutative ring with unity), then the prime spectrum of $A/ \mathfrak{a}$ has finitely many irreducible components. This follows easily from the recognition that the maximal irreducible subspaces of $\textrm{ Spec } (A / \mathfrak{a})$ are precisely the ""zero loci"" of the minimal prime ideals of $A /\mathfrak{a}$. I'm curious about the converse - the proof isn't easily reversed since the notion of minimal ideals of $\mathfrak{a} $ doesn't make sense before we know what we are trying to prove. My intuition says that it is false based on the general premise that images are badly-behaved (and the fact that it isn't part of the exercise.) However, I've had some difficulty constructing a counterexample, so that the main purpose of this post is to ask for a reasonable procedure or heuristic for doing so (or, of course, proof that my intuition is false.) If it helps, if $\textrm{Spec }(A / \mathfrak{a})$ is irreducible then the nilradical $\mathcal{R}_{A /\mathfrak{a}}$ is prime so that $r(\mathfrak{a}) = \rho^{-1} ( \mathcal{R}_{A / \mathfrak{a}} ) = \displaystyle\cap_{i=1}^n \rho^{-1} (p_i),$ where $p_i$ are the minimal prime ideals of $A /\mathfrak{a}$ and $\rho $ is the associated projection, is also prime. Thanks!",,"['abstract-algebra', 'algebraic-geometry']"
91,How to describe Algebraic Closure of $\mathbb{C}(x)$?,How to describe Algebraic Closure of ?,\mathbb{C}(x),"Let $\mathbb{C}$ be the set of complex numbers, and $x$ be an indeterminate. Let $\overline{\mathbb{C}(x)}$ be an algebraic closure of $\mathbb{C}(x)$. Then what are the elements of $\overline{\mathbb{C}(x)}$? Obviously, elements like $\sqrt[n]{x}, \sqrt[n]{f(x)}$ (where $f(x)\in\mathbb{C}(x)$), etc. will be in the set. But is it easy to describe the full set?","Let $\mathbb{C}$ be the set of complex numbers, and $x$ be an indeterminate. Let $\overline{\mathbb{C}(x)}$ be an algebraic closure of $\mathbb{C}(x)$. Then what are the elements of $\overline{\mathbb{C}(x)}$? Obviously, elements like $\sqrt[n]{x}, \sqrt[n]{f(x)}$ (where $f(x)\in\mathbb{C}(x)$), etc. will be in the set. But is it easy to describe the full set?",,['abstract-algebra']
92,Why is cofiniteness included in the definition of direct sum of submodules?,Why is cofiniteness included in the definition of direct sum of submodules?,,"In contrast to the possibility of taking  an arbitrary sequence of elements of submodules in the definition of direct product, the definition for the direct sum of submodules of a module requires the indexed elements to vanish cofinitely(i.e. except finitely many times). More precisely, Let $R$ be a ring, and $\{M_i : i ∈ I\}$ a family of left $R-$modules indexed by the set $I$. The direct sum of ${M_i}$ is then defined to be the set of all sequences $(α_i)$ where $\alpha_i \in M_i$ and $α_i = 0$ for cofinitely many indices $i$. (The direct product is analogous but the indices do not need to cofinitely vanish.)(Source Wikipedia: Direct sum of modules .)We have similar definition for the sum of submodules. I have not yet understood what pathology would be incurred without assuming or what simplification (if any) would be gained in assuming cofiniteness. Can you please explain this in simple terms (possibly, with examples) ? Thanks.","In contrast to the possibility of taking  an arbitrary sequence of elements of submodules in the definition of direct product, the definition for the direct sum of submodules of a module requires the indexed elements to vanish cofinitely(i.e. except finitely many times). More precisely, Let $R$ be a ring, and $\{M_i : i ∈ I\}$ a family of left $R-$modules indexed by the set $I$. The direct sum of ${M_i}$ is then defined to be the set of all sequences $(α_i)$ where $\alpha_i \in M_i$ and $α_i = 0$ for cofinitely many indices $i$. (The direct product is analogous but the indices do not need to cofinitely vanish.)(Source Wikipedia: Direct sum of modules .)We have similar definition for the sum of submodules. I have not yet understood what pathology would be incurred without assuming or what simplification (if any) would be gained in assuming cofiniteness. Can you please explain this in simple terms (possibly, with examples) ? Thanks.",,"['abstract-algebra', 'modules']"
93,"Why is $\mathbb{Z}[x]/(1-x,p)$ isomorphic to $\mathbb{Z}_{p}$, where $p$ is a prime integer.","Why is  isomorphic to , where  is a prime integer.","\mathbb{Z}[x]/(1-x,p) \mathbb{Z}_{p} p","I want to know why $\mathbb{Z}[x]/(1-x,p)$ is isomorphic to $\mathbb{Z}_{p}$, where $p$ is a prime integer? Here's what I have so far, but I am unsure if I am correct.   Every $f\in \mathbb{Z}[x]$ can be written as $(1-x)q+ r$ where $q\in \mathbb{Z}[x]$ and $r$ is in $\mathbb{Z}$.   Does It follows that there are $p$ cosets of $(1-x,p)$  ( namely 0+(1-x,p), 1+(1-x,p),2+(1-x,p)  etc ..) That would imply $\mathbb{Z}[x]/(1-x,p)$ is isomorphic to $\mathbb{Z_{p}}$","I want to know why $\mathbb{Z}[x]/(1-x,p)$ is isomorphic to $\mathbb{Z}_{p}$, where $p$ is a prime integer? Here's what I have so far, but I am unsure if I am correct.   Every $f\in \mathbb{Z}[x]$ can be written as $(1-x)q+ r$ where $q\in \mathbb{Z}[x]$ and $r$ is in $\mathbb{Z}$.   Does It follows that there are $p$ cosets of $(1-x,p)$  ( namely 0+(1-x,p), 1+(1-x,p),2+(1-x,p)  etc ..) That would imply $\mathbb{Z}[x]/(1-x,p)$ is isomorphic to $\mathbb{Z_{p}}$",,['abstract-algebra']
94,Meaning of the antipode in Hopf algebras?,Meaning of the antipode in Hopf algebras?,,"What I understand so far is that Hopf algebra is a vector space which is both algebra and coalgebra. In addition to this, there is a linear operation $S$, which for each element gives a so-called 'anitpode'. Can anyone give an intuitive explanation of what is the 'antiopde' element? Why is it essential for the representation theory? What is the meaning of the axiom related to it (#3 on wiki)? (looks like without that axiom the product and co-product would be unrelated to each other) Thanks.","What I understand so far is that Hopf algebra is a vector space which is both algebra and coalgebra. In addition to this, there is a linear operation $S$, which for each element gives a so-called 'anitpode'. Can anyone give an intuitive explanation of what is the 'antiopde' element? Why is it essential for the representation theory? What is the meaning of the axiom related to it (#3 on wiki)? (looks like without that axiom the product and co-product would be unrelated to each other) Thanks.",,"['abstract-algebra', 'representation-theory', 'hopf-algebras', 'coalgebras']"
95,Where has this unusually imaginary number been sighted?,Where has this unusually imaginary number been sighted?,,"POSTSCRIPT: Haste makes waste.  I wrote ""no member of $\mathbb C\cup\{\infty\}$ behaves like this"".  In fact $\infty$ does the job.  Accordingly, I have revised the question at the bottom of this post. END OF POSTSCRIPT $\newcommand{\d}{\diamond}$In this previous question I asked something about the binary operation $$ a\d b = \frac{a+b}{1+ab}, $$ which is conjugate via the involution $a\mapsto\dfrac{1-a}{1+a}$ to multiplication.  I think of the domain as being the set $D=(\mathbb C\cup\{\infty\})^2\setminus\{(\pm1,\mp1)\}$. I have noticed that $$ \frac 1 a \d b = a\d \frac 1 b = \frac 1 {a\d b}. \tag 1 $$ Since this operation is associative, this identity seems to invite us to imagine a number $R$ (for ""reciprocal"") such that for all $a$ we have $$ R\d a = \frac 1 a $$ so that $(1)$ would say $$ (R\d a)\d b = a\d (R\d b) = R\d (a\d b). $$ However, no member of $\mathbb C\cup\{\infty\}$ behaves like this. This reminds me of the identity $f'\ast g = f\ast g'=(f\ast g)'$ where ""$\ast$"" is convolution.  There is no function whose convolution with $f$ is $f'$, but there is the ""generalized function"" $\delta'$, the derivative of Dirac's delta function. So MY QUESTION IS whether this creature that I have called $R$ has been sighted in literature that can be cited?  (Construe ""literature"" broadly to include all the crap on the internet, etc.) Later revision of the question: Are the identities $(1)$ and $\infty\d a=\dfrac 1 a$ ""out there"" somewhere? (My interest in all this is really an interest in applying this to some geometry problems, concerning which I haven't sorted out all of my thoughts yet.) (I disagree with the deprecation of the ""algebra"" tag or I'd have used it here.)","POSTSCRIPT: Haste makes waste.  I wrote ""no member of $\mathbb C\cup\{\infty\}$ behaves like this"".  In fact $\infty$ does the job.  Accordingly, I have revised the question at the bottom of this post. END OF POSTSCRIPT $\newcommand{\d}{\diamond}$In this previous question I asked something about the binary operation $$ a\d b = \frac{a+b}{1+ab}, $$ which is conjugate via the involution $a\mapsto\dfrac{1-a}{1+a}$ to multiplication.  I think of the domain as being the set $D=(\mathbb C\cup\{\infty\})^2\setminus\{(\pm1,\mp1)\}$. I have noticed that $$ \frac 1 a \d b = a\d \frac 1 b = \frac 1 {a\d b}. \tag 1 $$ Since this operation is associative, this identity seems to invite us to imagine a number $R$ (for ""reciprocal"") such that for all $a$ we have $$ R\d a = \frac 1 a $$ so that $(1)$ would say $$ (R\d a)\d b = a\d (R\d b) = R\d (a\d b). $$ However, no member of $\mathbb C\cup\{\infty\}$ behaves like this. This reminds me of the identity $f'\ast g = f\ast g'=(f\ast g)'$ where ""$\ast$"" is convolution.  There is no function whose convolution with $f$ is $f'$, but there is the ""generalized function"" $\delta'$, the derivative of Dirac's delta function. So MY QUESTION IS whether this creature that I have called $R$ has been sighted in literature that can be cited?  (Construe ""literature"" broadly to include all the crap on the internet, etc.) Later revision of the question: Are the identities $(1)$ and $\infty\d a=\dfrac 1 a$ ""out there"" somewhere? (My interest in all this is really an interest in applying this to some geometry problems, concerning which I haven't sorted out all of my thoughts yet.) (I disagree with the deprecation of the ""algebra"" tag or I'd have used it here.)",,"['abstract-algebra', 'reference-request']"
96,On irreducible factors of $x^{2^n}+x+1$ in $\mathbb Z_2[x]$,On irreducible factors of  in,x^{2^n}+x+1 \mathbb Z_2[x],"Prove that each irreducible factor of $f(x)=x^{2^n}+x+1$ in $\mathbb Z_2[x]$ has degree $k$, where $k\mid 2n$. Edit. I know I should somehow relate the question to an extension of $\mathbb Z_2$ of degree $2n$, say $GF(2^{2n})$. By this way I will be able to correspond each irreducible factor of $f(x)$ to a subfield of $GF(2^{2n})$ that obviously has degree $k$, where $k\mid 2n$.","Prove that each irreducible factor of $f(x)=x^{2^n}+x+1$ in $\mathbb Z_2[x]$ has degree $k$, where $k\mid 2n$. Edit. I know I should somehow relate the question to an extension of $\mathbb Z_2$ of degree $2n$, say $GF(2^{2n})$. By this way I will be able to correspond each irreducible factor of $f(x)$ to a subfield of $GF(2^{2n})$ that obviously has degree $k$, where $k\mid 2n$.",,"['abstract-algebra', 'polynomials', 'field-theory', 'finite-fields']"
97,Power of commutator formula,Power of commutator formula,,"A few people remember a commutator formula of the form $[a,b]^n = (a^{-1} b^{-1})^n (ab)^n c$ where $c$ is a product of only a few commutators (say $n-1$) of them.  Here $a,b$ are in a (free) group and $[a,b] := a^{-1} b^{-1} a b$. Does anyone remember such a formula with proof? Some such formula must exist where $c$ is in the commutator subgroup of $\langle a,b\rangle$, but my recollection is that $c$ is a product of something more like $n^2$ commutators. Answers that only work for $n=2$ are less interesting to me. There should be a radical difference for $n \geq 3$.","A few people remember a commutator formula of the form $[a,b]^n = (a^{-1} b^{-1})^n (ab)^n c$ where $c$ is a product of only a few commutators (say $n-1$) of them.  Here $a,b$ are in a (free) group and $[a,b] := a^{-1} b^{-1} a b$. Does anyone remember such a formula with proof? Some such formula must exist where $c$ is in the commutator subgroup of $\langle a,b\rangle$, but my recollection is that $c$ is a product of something more like $n^2$ commutators. Answers that only work for $n=2$ are less interesting to me. There should be a radical difference for $n \geq 3$.",,"['abstract-algebra', 'group-theory', 'free-groups', 'p-groups']"
98,Field of fractions of a finite $\mathbb{Z}$-module is finite extension of $\mathbb{Q}$,Field of fractions of a finite -module is finite extension of,\mathbb{Z} \mathbb{Q},"Let $A$ be a ring which is also a finitely generated $\mathbb{Z}$ -module. If $A$ is an integral domain and $K$ is its field of fractions and $K$ has characteristic zero, then why is $K$ a finite dimensional vector space over $\mathbb{Q}$ ? I see that $K$ contains $\mathbb{Q}$ but why is the extension finite?","Let be a ring which is also a finitely generated -module. If is an integral domain and is its field of fractions and has characteristic zero, then why is a finite dimensional vector space over ? I see that contains but why is the extension finite?",A \mathbb{Z} A K K K \mathbb{Q} K \mathbb{Q},"['abstract-algebra', 'commutative-algebra', 'algebraic-number-theory']"
99,Counting binary operations on a set with $n$ elements,Counting binary operations on a set with  elements,n,I am trying to solve following problem but not able to find any way to proceed. Let $S$ be a set having $n$ elements. Can we count about number of binary operations that can be defined on a set? Can we also count number of commutative binary operations defined on  $S$? Thanks for the help and suggestions,I am trying to solve following problem but not able to find any way to proceed. Let $S$ be a set having $n$ elements. Can we count about number of binary operations that can be defined on a set? Can we also count number of commutative binary operations defined on  $S$? Thanks for the help and suggestions,,"['abstract-algebra', 'combinatorics', 'elementary-set-theory']"
