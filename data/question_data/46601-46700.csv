,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Product of characters in representation theory,Product of characters in representation theory,,"Is it true that if $\phi_1$ and $\phi_2$ are characters then $\phi_1\phi_2$ is a character of a representation? I think this is true, say for instance if $R_1$ is a matrix representation with character $\phi_1$ of $G$ and $R_2$ is a matrix representation of $H$ with character $\phi_2$, then we can say $\phi_1\phi_2$ as the character of the matrix representation of $G\times H$ if we define $\phi_1\phi_2(g, h)=\phi_1(g)\phi_2(h)$. Will this suffice to prove our claim?","Is it true that if $\phi_1$ and $\phi_2$ are characters then $\phi_1\phi_2$ is a character of a representation? I think this is true, say for instance if $R_1$ is a matrix representation with character $\phi_1$ of $G$ and $R_2$ is a matrix representation of $H$ with character $\phi_2$, then we can say $\phi_1\phi_2$ as the character of the matrix representation of $G\times H$ if we define $\phi_1\phi_2(g, h)=\phi_1(g)\phi_2(h)$. Will this suffice to prove our claim?",,"['abstract-algebra', 'modules', 'representation-theory', 'tensor-products', 'characters']"
1,Is this generalization of Boolean algebras a variety?,Is this generalization of Boolean algebras a variety?,,"I'm interested in the class of structures $\langle S,\top,\neg,\wedge\rangle$ defined by the axioms: $p \wedge q=q \wedge p$ $p \wedge (q \wedge r) = (p\wedge q)\wedge r$ $p = p \wedge p$ $p = \neg\neg p$ $p \vee(q\wedge r) = (p\vee q)\wedge(p\vee r)$ $p = p\wedge \top$ $p \vee\top = p \vee \neg p$ If $p \wedge q = p \vee q$ and $q \wedge r = q \vee r$, then $p \wedge r = p \vee r$. where $p \vee q =_{df} \neg(\neg p \wedge\neg q)$. I have three questions about this class of structures: (i) Do they form a variety? (ii) If so, what are some equations that define them? (iii) If not, what is an example of a structure satisfying 1-7 but not 8? (I've read about Birkhoff's HSP theorem, but having only a limited background in algebra I'm not sure how to go about trying to apply it.) Some background : These structures are a generalization of Boolean algebras in which neither the absorption laws nor $p \vee \top = \top$ are guaranteed to hold. They are isomorphic to the class of structures $\langle P, \top, \neg, \wedge\rangle$ such that, for some Boolean algebra $A = \langle S_A,\top_A,\neg_A,\wedge_A\rangle$ and bounded meet-semilattice $B = \langle S_B,\wedge_B,\top_B\rangle$, $P\subseteq S_A\times S_B$; $\top = \langle\top_A,\top_B\rangle\in P$; $\neg: P\to P$ such that $\neg\langle a,b\rangle = \langle\neg_Aa,b\rangle$; $\wedge: (P\times P)\to P$ such that $\langle a,b\rangle\wedge\langle a',b'\rangle=\langle a\wedge_A a',b\wedge_B b'\rangle$. Intuitively, we might think of $\langle a,b\rangle\in P$ as a 'proposition' with 'logical content' $a$ and 'non-logical content' $b$, where the idea is that logical contents form a Boolean algebra, propositions' non-logical contents aggregate under conjunction and are unchanged by negation, and the tautology $\top$ has minimal non-logical content. Update : I figured out part (iii) of my question: Kleene's weak three-valued truth table is a model of (1)-(7) but not of (8). http://en.wikipedia.org/wiki/Many-valued_logic#Bochvar.27s_internal_three-valued_logic_.28also_known_as_Kleene.27s_weak_three-valued_logic.29","I'm interested in the class of structures $\langle S,\top,\neg,\wedge\rangle$ defined by the axioms: $p \wedge q=q \wedge p$ $p \wedge (q \wedge r) = (p\wedge q)\wedge r$ $p = p \wedge p$ $p = \neg\neg p$ $p \vee(q\wedge r) = (p\vee q)\wedge(p\vee r)$ $p = p\wedge \top$ $p \vee\top = p \vee \neg p$ If $p \wedge q = p \vee q$ and $q \wedge r = q \vee r$, then $p \wedge r = p \vee r$. where $p \vee q =_{df} \neg(\neg p \wedge\neg q)$. I have three questions about this class of structures: (i) Do they form a variety? (ii) If so, what are some equations that define them? (iii) If not, what is an example of a structure satisfying 1-7 but not 8? (I've read about Birkhoff's HSP theorem, but having only a limited background in algebra I'm not sure how to go about trying to apply it.) Some background : These structures are a generalization of Boolean algebras in which neither the absorption laws nor $p \vee \top = \top$ are guaranteed to hold. They are isomorphic to the class of structures $\langle P, \top, \neg, \wedge\rangle$ such that, for some Boolean algebra $A = \langle S_A,\top_A,\neg_A,\wedge_A\rangle$ and bounded meet-semilattice $B = \langle S_B,\wedge_B,\top_B\rangle$, $P\subseteq S_A\times S_B$; $\top = \langle\top_A,\top_B\rangle\in P$; $\neg: P\to P$ such that $\neg\langle a,b\rangle = \langle\neg_Aa,b\rangle$; $\wedge: (P\times P)\to P$ such that $\langle a,b\rangle\wedge\langle a',b'\rangle=\langle a\wedge_A a',b\wedge_B b'\rangle$. Intuitively, we might think of $\langle a,b\rangle\in P$ as a 'proposition' with 'logical content' $a$ and 'non-logical content' $b$, where the idea is that logical contents form a Boolean algebra, propositions' non-logical contents aggregate under conjunction and are unchanged by negation, and the tautology $\top$ has minimal non-logical content. Update : I figured out part (iii) of my question: Kleene's weak three-valued truth table is a model of (1)-(7) but not of (8). http://en.wikipedia.org/wiki/Many-valued_logic#Bochvar.27s_internal_three-valued_logic_.28also_known_as_Kleene.27s_weak_three-valued_logic.29",,"['abstract-algebra', 'universal-algebra', 'algebraic-logic']"
2,What are all the integral domains that are not division rings?,What are all the integral domains that are not division rings?,,"A commutative division ring is an integral domain. But what are all the integral domains that are not division rings? The examples I currently know are the following: $\mathbb{Z}$, $\mathbb{Z}[i]$, $\mathbb{Z}[\sqrt 2]$, $\mathbb{Z}[\sqrt k]$ where $k$ is not a perfect square, and the ring of polynomials $R[x]$ over any integral domain $R$. But what are all other examples? Edit: I am a self-learner, so excuse me if the question is trival or stupid.","A commutative division ring is an integral domain. But what are all the integral domains that are not division rings? The examples I currently know are the following: $\mathbb{Z}$, $\mathbb{Z}[i]$, $\mathbb{Z}[\sqrt 2]$, $\mathbb{Z}[\sqrt k]$ where $k$ is not a perfect square, and the ring of polynomials $R[x]$ over any integral domain $R$. But what are all other examples? Edit: I am a self-learner, so excuse me if the question is trival or stupid.",,"['abstract-algebra', 'ring-theory']"
3,Nilpotent elements in the quotient ring of a polynomial ring,Nilpotent elements in the quotient ring of a polynomial ring,,"If $F$ is a field and $p(x) \in F[x]$, prove that the ring $R=F[x]/(p(x))$ has no nonzero nilpotent elements iff $p(x)$ is not divisible by the square of any polynomial. (==>) $R$ has no nonzero nilpotent element, but $p(x)$ is divisible by the square of some $g(x)\in F[x], \deg g(x)>0$ Say $p(x)=(g(x))^2h(x)$ for some $h(x)\in F[x]$, then consider $g(x)h(x)\in F[x]$, $0<\deg g(x)h(x)=\deg g(x)+\deg h(x)\le \deg p(x)$, but $(g(x)h(x))^2=g^2(x)h^2(x)=p(x)h(x)=\bar{0}$ in $F[x]/(p(x))$, it is a contradition. (<==) $p(x)$ is not divisible by the square of any polynomial, and there is nonzero nilpotent element, say $f(x), (f(x))^n=0$, for some n. Then, $p(x)|(f(x))^n$ but $p(x)\nmid f(x)$. Then I don't know how to continue... Also, is there any way to proof directly?","If $F$ is a field and $p(x) \in F[x]$, prove that the ring $R=F[x]/(p(x))$ has no nonzero nilpotent elements iff $p(x)$ is not divisible by the square of any polynomial. (==>) $R$ has no nonzero nilpotent element, but $p(x)$ is divisible by the square of some $g(x)\in F[x], \deg g(x)>0$ Say $p(x)=(g(x))^2h(x)$ for some $h(x)\in F[x]$, then consider $g(x)h(x)\in F[x]$, $0<\deg g(x)h(x)=\deg g(x)+\deg h(x)\le \deg p(x)$, but $(g(x)h(x))^2=g^2(x)h^2(x)=p(x)h(x)=\bar{0}$ in $F[x]/(p(x))$, it is a contradition. (<==) $p(x)$ is not divisible by the square of any polynomial, and there is nonzero nilpotent element, say $f(x), (f(x))^n=0$, for some n. Then, $p(x)|(f(x))^n$ but $p(x)\nmid f(x)$. Then I don't know how to continue... Also, is there any way to proof directly?",,"['abstract-algebra', 'ring-theory']"
4,Show an ideal is a finitely generated projective module via a split exact sequence,Show an ideal is a finitely generated projective module via a split exact sequence,,"Let $I$ be an ideal of $R$ such that the mapping $f:I\otimes_R\operatorname{Hom}_R (I,R)→R$ defined (on the generators) by $f(i\otimes α)=α(i)$ for all $i∈I$ and $α∈\operatorname{Hom}_R (I,R)$ is onto. Show that $I$ is a finitely generated projective $R$-module. Here is the hint I have been given: Show there is a split exact sequence $0→K→F→I→0$, where $F$ is a finitely generated free $R$-module. Any help is appreciated, thanks a lot.","Let $I$ be an ideal of $R$ such that the mapping $f:I\otimes_R\operatorname{Hom}_R (I,R)→R$ defined (on the generators) by $f(i\otimes α)=α(i)$ for all $i∈I$ and $α∈\operatorname{Hom}_R (I,R)$ is onto. Show that $I$ is a finitely generated projective $R$-module. Here is the hint I have been given: Show there is a split exact sequence $0→K→F→I→0$, where $F$ is a finitely generated free $R$-module. Any help is appreciated, thanks a lot.",,"['abstract-algebra', 'commutative-algebra', 'modules', 'tensor-products', 'exact-sequence']"
5,One-sided nilpotent ideal not in the Jacobson radical?,One-sided nilpotent ideal not in the Jacobson radical?,,"Problem XVII.5a of Lang's Algebra, revised 3rd edition, is: Suppose $N$ is a two-sided nilpotent ideal of a ring $R$. Show that   $N$ is contained in the Jacobson radical $J: = \{ \cap\, I: I \text{ a  maximal left ideal of } R \}$. I put my solution below the fold. My question is: can't we generalize a bit more? It seems that all we need is that $N$ is a nil ideal; further, I don't see why $N$ can't be merely a one-sided ideal. I assume there's some error in my thinking here... Solution: Take $y \in N$, and show that $1-xy$ has a left inverse for all $x\in R$ (this is an equivalent characterization of the Jacobson radical, see here ). The way to construct the left inverse is to note that $xy \in N$, so $\exists k$ s.t. $(xy)^k= 0$, so $(1 + xy + \dotsb + (xy)^{k-1})(1-xy)=1$.","Problem XVII.5a of Lang's Algebra, revised 3rd edition, is: Suppose $N$ is a two-sided nilpotent ideal of a ring $R$. Show that   $N$ is contained in the Jacobson radical $J: = \{ \cap\, I: I \text{ a  maximal left ideal of } R \}$. I put my solution below the fold. My question is: can't we generalize a bit more? It seems that all we need is that $N$ is a nil ideal; further, I don't see why $N$ can't be merely a one-sided ideal. I assume there's some error in my thinking here... Solution: Take $y \in N$, and show that $1-xy$ has a left inverse for all $x\in R$ (this is an equivalent characterization of the Jacobson radical, see here ). The way to construct the left inverse is to note that $xy \in N$, so $\exists k$ s.t. $(xy)^k= 0$, so $(1 + xy + \dotsb + (xy)^{k-1})(1-xy)=1$.",,"['abstract-algebra', 'ring-theory', 'ideals']"
6,"If $G \setminus H$ be a finite set, then $G$ is finite?","If  be a finite set, then  is finite?",G \setminus H G,"Let $G$ be a group and $H$ be a proper subgroup of it. I should prove that if $G \setminus H$ be a finite set, then $G$ is finite group. Any suggestion?","Let $G$ be a group and $H$ be a proper subgroup of it. I should prove that if $G \setminus H$ be a finite set, then $G$ is finite group. Any suggestion?",,"['abstract-algebra', 'group-theory']"
7,"Assume $P$ is a prime ideal s.t. $K \subset P$, show $f(P)$ is a prime ideal","Assume  is a prime ideal s.t. , show  is a prime ideal",P K \subset P f(P),"I'm currently trying to solve this problem. Let $f: R \rightarrow S$ be a surjective ring homomorphism. Let $K = \ker(f)$. Assume $P$ is a prime ideal s.t. $K \subset P$. Show $f(P)$ is a prime ideal in $S$. I solved the ideal part. Let $y \in f(P)$, by definition then $y = f(x)$ for some $x \in P$. Now let $s \in S$. Then since $f$ is surjective $\exists r \in R$ s.t. $f(r) = s$. So then since $f$ is a homomorphism we have $f(x)\cdot s = f(x) \cdot f(r) = f(x\cdot r)$. Then since $P$ is ideal and $x \in P$, $x\cdot r \in P$, so $f(x \cdot r) = f(x)\cdot s \in f(P)$ so $f(P)$ is closed under multiplication by an element in $S$. Now let $y, y' \in f(P)$, again by definition we have $x, x' \in R$ s.t. $f(x) = y, f(x') = y'$. By $f$ homomorphism we have $y - y' = f(x) - f(x') = f(x-x')$. Then by $P$ ideal we have $x-x' \in P$, thus $y-y' \in f(P)$. Therefore $f(P)$ is an ideal. The part I'm having trouble with is showing that $P$ prime implies $f(P)$ prime. I started off let $AB \subset f(P)$, by definition we know we have $C \subset P$ s.t. $f(C) = AB$. From here I need to arrive at showing that either $A \subset f(P)$ or $B \subset f(P)$. I'm not really sure how to move forward from here but I know I somehow need to involve the fact that $K \subset P$ since I haven't used that yet. Any help would be appreciated. Note: I'm not assuming that $R$ or $S$ is commutative, I already know how to solve it if they are using the commutative definition of prime.","I'm currently trying to solve this problem. Let $f: R \rightarrow S$ be a surjective ring homomorphism. Let $K = \ker(f)$. Assume $P$ is a prime ideal s.t. $K \subset P$. Show $f(P)$ is a prime ideal in $S$. I solved the ideal part. Let $y \in f(P)$, by definition then $y = f(x)$ for some $x \in P$. Now let $s \in S$. Then since $f$ is surjective $\exists r \in R$ s.t. $f(r) = s$. So then since $f$ is a homomorphism we have $f(x)\cdot s = f(x) \cdot f(r) = f(x\cdot r)$. Then since $P$ is ideal and $x \in P$, $x\cdot r \in P$, so $f(x \cdot r) = f(x)\cdot s \in f(P)$ so $f(P)$ is closed under multiplication by an element in $S$. Now let $y, y' \in f(P)$, again by definition we have $x, x' \in R$ s.t. $f(x) = y, f(x') = y'$. By $f$ homomorphism we have $y - y' = f(x) - f(x') = f(x-x')$. Then by $P$ ideal we have $x-x' \in P$, thus $y-y' \in f(P)$. Therefore $f(P)$ is an ideal. The part I'm having trouble with is showing that $P$ prime implies $f(P)$ prime. I started off let $AB \subset f(P)$, by definition we know we have $C \subset P$ s.t. $f(C) = AB$. From here I need to arrive at showing that either $A \subset f(P)$ or $B \subset f(P)$. I'm not really sure how to move forward from here but I know I somehow need to involve the fact that $K \subset P$ since I haven't used that yet. Any help would be appreciated. Note: I'm not assuming that $R$ or $S$ is commutative, I already know how to solve it if they are using the commutative definition of prime.",,"['abstract-algebra', 'maximal-and-prime-ideals']"
8,"Prove that if the equation $x^{2} \equiv a\pmod{pq}$ has any solutions, then it has four solutions.","Prove that if the equation  has any solutions, then it has four solutions.",x^{2} \equiv a\pmod{pq},"Suppose $n = pq$ with $p$ and $q$ distinct odd primes.   Suppose that $\gcd(a,pq)=1$. Prove that if the equation $x^{2} \equiv a\pmod n$ has any solutions, then it has four solutions. Proof: Suppose $n = pq$ with $p$ and $q$ distinct odd primes and that gcd($a,pq$) = 1. Let us have the equation $x^{2} \equiv a\pmod n$. Then, $x^{2} \equiv a$ (mod $pq$), $p \not = q$. By definition, we can separate the equation into two equations such that $y^{2} \equiv a \equiv b$ (mod $p$) and $z^{2} \equiv a \equiv c$ (mod $q$). Let $g_{p}$ be a primitive root modulo $p$ and $g_{q}$ be a primitive root modulo $q$. Then, $b$ is equal to some power of $g_{p}$ and $c$ is equal to some power of $g_{q}$. With the fact that $b$ has a square root modulo $p$ (i.e. $r^{2} \equiv b$(mod $\ p)$) and $c$ has a square root modulo $q$ (i.e. $t^{2} \equiv c$(mod $\ q)$), there is an even power of $g_{p}$ and of $g_{q}$ such that $b = g_{p}^{2k_{1}}$(mod $\ p)$ and $c = g_{q}^{2k_{2}}$(mod $\ q)$ for some $k_{1}, k_{2} \in Z$. By computing, we have the following: $r^{2} \equiv b$(mod $\ p)$       $\equiv b^{(p + 1) / 2}($mod $\ p)$       $\equiv (g_{p}^{2k_{1}})^{(p + 1) / 2}($mod $\ p)$       $\equiv (g_{p}^{p + 1})^{k_{1}}($mod $\ p)$       $\equiv g_{p}^{2k_{1} + (p - 1)k_{1}}($mod $\ p)$       $\equiv b \cdot g_{p}^{(p - 1)k_{1}}($mod $\ p)$       $\equiv b$ and $t^{2} \equiv c$(mod $\ q)$        $\equiv c^{(q + 1) / 2}($mod $\ q)$        $\equiv (g_{q}^{2k_{2}})^{(q + 1) / 2}($mod $\ q)$        $\equiv (g_{q}^{q + 1})^{k_{2}}($mod $\ q)$        $\equiv g_{q}^{2k_{2} + (q - 1)k_{2}}($mod $\ q)$        $\equiv c \cdot g_{q}^{(q - 1)k_{2}}($mod $\ q)$        $\equiv c$ Hence, $r$ is a square root of a modulo $p$ and $t$ is a square root of a modulo $q$, which means there are two solutions for each $p$ and $q$. Since $p \not = q \in \mathbb{Z}_{n}$, we have isomorphism such that $\mathbb{Z}_{n} \simeq \mathbb{Z}_{p} \cdot \mathbb{Z}_{q}$. Therefore, if the equation $x^{2} \equiv a$ (mod $n$) has any solutions, it must have four solutions. $\blacklozenge$ What do you think about the proof I wrote?","Suppose $n = pq$ with $p$ and $q$ distinct odd primes.   Suppose that $\gcd(a,pq)=1$. Prove that if the equation $x^{2} \equiv a\pmod n$ has any solutions, then it has four solutions. Proof: Suppose $n = pq$ with $p$ and $q$ distinct odd primes and that gcd($a,pq$) = 1. Let us have the equation $x^{2} \equiv a\pmod n$. Then, $x^{2} \equiv a$ (mod $pq$), $p \not = q$. By definition, we can separate the equation into two equations such that $y^{2} \equiv a \equiv b$ (mod $p$) and $z^{2} \equiv a \equiv c$ (mod $q$). Let $g_{p}$ be a primitive root modulo $p$ and $g_{q}$ be a primitive root modulo $q$. Then, $b$ is equal to some power of $g_{p}$ and $c$ is equal to some power of $g_{q}$. With the fact that $b$ has a square root modulo $p$ (i.e. $r^{2} \equiv b$(mod $\ p)$) and $c$ has a square root modulo $q$ (i.e. $t^{2} \equiv c$(mod $\ q)$), there is an even power of $g_{p}$ and of $g_{q}$ such that $b = g_{p}^{2k_{1}}$(mod $\ p)$ and $c = g_{q}^{2k_{2}}$(mod $\ q)$ for some $k_{1}, k_{2} \in Z$. By computing, we have the following: $r^{2} \equiv b$(mod $\ p)$       $\equiv b^{(p + 1) / 2}($mod $\ p)$       $\equiv (g_{p}^{2k_{1}})^{(p + 1) / 2}($mod $\ p)$       $\equiv (g_{p}^{p + 1})^{k_{1}}($mod $\ p)$       $\equiv g_{p}^{2k_{1} + (p - 1)k_{1}}($mod $\ p)$       $\equiv b \cdot g_{p}^{(p - 1)k_{1}}($mod $\ p)$       $\equiv b$ and $t^{2} \equiv c$(mod $\ q)$        $\equiv c^{(q + 1) / 2}($mod $\ q)$        $\equiv (g_{q}^{2k_{2}})^{(q + 1) / 2}($mod $\ q)$        $\equiv (g_{q}^{q + 1})^{k_{2}}($mod $\ q)$        $\equiv g_{q}^{2k_{2} + (q - 1)k_{2}}($mod $\ q)$        $\equiv c \cdot g_{q}^{(q - 1)k_{2}}($mod $\ q)$        $\equiv c$ Hence, $r$ is a square root of a modulo $p$ and $t$ is a square root of a modulo $q$, which means there are two solutions for each $p$ and $q$. Since $p \not = q \in \mathbb{Z}_{n}$, we have isomorphism such that $\mathbb{Z}_{n} \simeq \mathbb{Z}_{p} \cdot \mathbb{Z}_{q}$. Therefore, if the equation $x^{2} \equiv a$ (mod $n$) has any solutions, it must have four solutions. $\blacklozenge$ What do you think about the proof I wrote?",,"['abstract-algebra', 'elementary-number-theory', 'proof-verification']"
9,Differentiation on matrix algebra,Differentiation on matrix algebra,,"Describe all differentiation on matrix algebra $M_n(F)$ over an associative commutative ring with identity $F$ Well as I understand that task I have Leibniz notation which says that every differentiation must satisfy $D(F,G) = F*D(G)+D(F)*G$. Also we have differentiation that looks like $D_A(B) = A*B-B*A$. So to describe I should to find how matrix A looks like. But how to do that?","Describe all differentiation on matrix algebra $M_n(F)$ over an associative commutative ring with identity $F$ Well as I understand that task I have Leibniz notation which says that every differentiation must satisfy $D(F,G) = F*D(G)+D(F)*G$. Also we have differentiation that looks like $D_A(B) = A*B-B*A$. So to describe I should to find how matrix A looks like. But how to do that?",,['abstract-algebra']
10,Topology of the ring of formal power series,Topology of the ring of formal power series,,"I'm interested in defining a topology on the ring $R[[X_i]]$ of formal power series in $(X_i)_{i\in I}$, where $R$ is a topological ring and $I$ is a (possibly infinite) index set. The wiki article discusses several options for this, and it seems that the most natural topology satisfies $(x_n)_{n\in\infty}$ converges iff for every monomial $X^\alpha$ (i.e. $\alpha$ is a finite multiset of indexes in $I$), $([X^\alpha]x_n)_{n\in\infty}$ converges in the topology on $R$. (The other main option discussed as a natural topology for $R[[X_i]]$ is equivalent to this one where $R$'s topology is ignored and replaced by the discrete topology.) My question is: How is this topology defined in terms of open sets? Can it be described as a special case of another topology, i.e. Krull topology or product topology? (The wiki answers this question in the univariate case but I'm more interested in the multivariate case.) More generally, this can be seen as a question of how to translate a specification of a topology in terms of convergence to an explicit definition from open sets. Is this topology metrizable (assuming $R$ is)? Again, the wiki discusses this in the case when $R$ is discrete and there is only one variable via $d(x,y)=2^{-k}$ where $k$ is the smallest nonzero coefficient of $x-y$, but leaves the multivariate case for the reader.","I'm interested in defining a topology on the ring $R[[X_i]]$ of formal power series in $(X_i)_{i\in I}$, where $R$ is a topological ring and $I$ is a (possibly infinite) index set. The wiki article discusses several options for this, and it seems that the most natural topology satisfies $(x_n)_{n\in\infty}$ converges iff for every monomial $X^\alpha$ (i.e. $\alpha$ is a finite multiset of indexes in $I$), $([X^\alpha]x_n)_{n\in\infty}$ converges in the topology on $R$. (The other main option discussed as a natural topology for $R[[X_i]]$ is equivalent to this one where $R$'s topology is ignored and replaced by the discrete topology.) My question is: How is this topology defined in terms of open sets? Can it be described as a special case of another topology, i.e. Krull topology or product topology? (The wiki answers this question in the univariate case but I'm more interested in the multivariate case.) More generally, this can be seen as a question of how to translate a specification of a topology in terms of convergence to an explicit definition from open sets. Is this topology metrizable (assuming $R$ is)? Again, the wiki discusses this in the case when $R$ is discrete and there is only one variable via $d(x,y)=2^{-k}$ where $k$ is the smallest nonzero coefficient of $x-y$, but leaves the multivariate case for the reader.",,"['abstract-algebra', 'general-topology', 'ring-theory', 'metric-spaces']"
11,Is there a formalism for a universal mathematical representation of algorithms?,Is there a formalism for a universal mathematical representation of algorithms?,,"I don't know if my question is correct so excuse me if I'm not 100% clear about what I would want to know. Is there a formalism which can capture all possible algorithms (mathematically speaking) ? Is there an ""algorithms"" space where algorithms can be expressed (in more than one way may be ?) kind of like vectors in a vector space ? I mean thinking about it, we can compose algorithms to make more complex ones, apply them sequentially and find simplified versions or may be faster versions of some of them.  I might be wrong thinking about it this way, but I see for example the algorithms used to solve the ""matrix multiplication"" problem such as Strassen's algorithm, the parallel matrix multiplication method and the old naïve version of the algorithm as three representations in the algorithms space of the same individual, or point (the multiplication algorithm) but seen from three different perspectives, having three different spatial and temporal complexities.  There might be a way (not discovered yet I suppose) to perform a ""problem reduction"" procedure to go from one form to another (like a PCA if I may say, but instead of maximizing the variance, we would be aiming at minimizing the temporal complexity given that the complexity of the algorithm itself my become greater (a longer algorithm to write)) I'm just imagining here. I don't think that this level of reduction power or algorithms understanding has been reached yet, but I'm just wondering if the concept itself is approachable from this angle. So, back to the question and back to the planet earth, is there a universal mathematical formalism for algorithms representation ? (either in a vectors-like form or any other one, may be using an advanced kind of logic) & Thanks in advance :)","I don't know if my question is correct so excuse me if I'm not 100% clear about what I would want to know. Is there a formalism which can capture all possible algorithms (mathematically speaking) ? Is there an ""algorithms"" space where algorithms can be expressed (in more than one way may be ?) kind of like vectors in a vector space ? I mean thinking about it, we can compose algorithms to make more complex ones, apply them sequentially and find simplified versions or may be faster versions of some of them.  I might be wrong thinking about it this way, but I see for example the algorithms used to solve the ""matrix multiplication"" problem such as Strassen's algorithm, the parallel matrix multiplication method and the old naïve version of the algorithm as three representations in the algorithms space of the same individual, or point (the multiplication algorithm) but seen from three different perspectives, having three different spatial and temporal complexities.  There might be a way (not discovered yet I suppose) to perform a ""problem reduction"" procedure to go from one form to another (like a PCA if I may say, but instead of maximizing the variance, we would be aiming at minimizing the temporal complexity given that the complexity of the algorithm itself my become greater (a longer algorithm to write)) I'm just imagining here. I don't think that this level of reduction power or algorithms understanding has been reached yet, but I'm just wondering if the concept itself is approachable from this angle. So, back to the question and back to the planet earth, is there a universal mathematical formalism for algorithms representation ? (either in a vectors-like form or any other one, may be using an advanced kind of logic) & Thanks in advance :)",,"['abstract-algebra', 'algorithms']"
12,A walkthrough of how to apply Eisenstein's criteria to show that a multivariate polynomial is irreductible.,A walkthrough of how to apply Eisenstein's criteria to show that a multivariate polynomial is irreductible.,,"I have found a few resources such as 2.0.3 here . There however are a series of ""identifications"" such as saying $k[x,y,z] = k[y,z][x]$ Why can I make these identifications? can I ALWAYS do so? I see that in the polynomial in their example $x^2 + y^2 + z^2$ that we have the same degree polynomial and there is no term with mixed variables. What if I wanted to check reducibility on something such as $xy + z^2$? The example goes on to say that it suffices to show that $y^2 + z^2$ is divisible by some prime $p$ in $k(z)[y]$, and not by $p^2$. Thus It suffices to show that $y^2 + z^2$ is not a unit, and has no repeated factor, in $k(z)[y]$. So it seems as if we are just taking the polynomials in $k(z)$ and appending the variable y to it, is this correct i.e. $k(z) + a \cdot y$? Now I understand Eisenstein's criteria but all of the resources I find only apply it in a single variable - otherwise they mention that it ""suffices to show"" and I fail to see the connection.  I could really use a walkthrough of how these work, more concretely, a walkthrough on why $xy + z^2$ is irrreducible. Thanks.","I have found a few resources such as 2.0.3 here . There however are a series of ""identifications"" such as saying $k[x,y,z] = k[y,z][x]$ Why can I make these identifications? can I ALWAYS do so? I see that in the polynomial in their example $x^2 + y^2 + z^2$ that we have the same degree polynomial and there is no term with mixed variables. What if I wanted to check reducibility on something such as $xy + z^2$? The example goes on to say that it suffices to show that $y^2 + z^2$ is divisible by some prime $p$ in $k(z)[y]$, and not by $p^2$. Thus It suffices to show that $y^2 + z^2$ is not a unit, and has no repeated factor, in $k(z)[y]$. So it seems as if we are just taking the polynomials in $k(z)$ and appending the variable y to it, is this correct i.e. $k(z) + a \cdot y$? Now I understand Eisenstein's criteria but all of the resources I find only apply it in a single variable - otherwise they mention that it ""suffices to show"" and I fail to see the connection.  I could really use a walkthrough of how these work, more concretely, a walkthrough on why $xy + z^2$ is irrreducible. Thanks.",,"['abstract-algebra', 'irreducible-polynomials']"
13,Abstract Algebra in analyzing computer science,Abstract Algebra in analyzing computer science,,I would like to know of some uses of algebraic structures to study computer science. Parallels of what I am looking for would be stuff like the fundamental group/homology/cohomology in topology and class fields in number theory where groups/rings are used to represent information about the object we are studying. I am not asking for examples like the graph isomorphism problem. Is there any equivalent in computer science? I would very much appreciate references too.,I would like to know of some uses of algebraic structures to study computer science. Parallels of what I am looking for would be stuff like the fundamental group/homology/cohomology in topology and class fields in number theory where groups/rings are used to represent information about the object we are studying. I am not asking for examples like the graph isomorphism problem. Is there any equivalent in computer science? I would very much appreciate references too.,,"['abstract-algebra', 'reference-request', 'computer-science']"
14,Galois group of $X^4 + 2X^2+4$,Galois group of,X^4 + 2X^2+4,"Find the Galois group of $f(X) = X^4 + 2X^2+4$ over $\mathbb{Q}$. Let $L$ be the splitting field of $f$ over $\mathbb{Q}$.  Finding the roots of this polynomial, I got $$X^2 = \frac{-2\pm \sqrt{4-16}}{2} = -1 \pm \sqrt{3}i$$ so the roots are $\alpha_1 = \sqrt{-1+\sqrt{3}i}, \alpha_2 =\sqrt{-1-\sqrt{3}}i, \alpha_3 =  -\sqrt{-1+\sqrt{3}i}$ and  $ \alpha_4 -\sqrt{-1-\sqrt{3}}i$.  Now $L = \mathbb{Q}(\alpha_1, \alpha_2)$, and since $$\alpha_1 \alpha_2  = \sqrt{(-1 + \sqrt{3}i)(-1-\sqrt{3}i)} = \sqrt{1+3} = 2$$ we see that $L = \mathbb{Q}(\alpha_1) = \mathbb{Q}(\alpha_2)$.  It's not difficult to see that $[\mathbb{Q}(\alpha_1) : \mathbb{Q}] = 4$, so the Galois group of $L/\mathbb{Q}$ over $\mathbb{Q}$ is is either $\mathbb{Z}/4\mathbb{Z}$ or $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$. My guess is that this Galois group is cyclic, since I think that $\mathbb{Q}(\sqrt{3}i)$ (a cyclotomic extension by a cubic root of unity) is the only intermediate subfield of $L/\mathbb{Q}$.  How can I know for sure?","Find the Galois group of $f(X) = X^4 + 2X^2+4$ over $\mathbb{Q}$. Let $L$ be the splitting field of $f$ over $\mathbb{Q}$.  Finding the roots of this polynomial, I got $$X^2 = \frac{-2\pm \sqrt{4-16}}{2} = -1 \pm \sqrt{3}i$$ so the roots are $\alpha_1 = \sqrt{-1+\sqrt{3}i}, \alpha_2 =\sqrt{-1-\sqrt{3}}i, \alpha_3 =  -\sqrt{-1+\sqrt{3}i}$ and  $ \alpha_4 -\sqrt{-1-\sqrt{3}}i$.  Now $L = \mathbb{Q}(\alpha_1, \alpha_2)$, and since $$\alpha_1 \alpha_2  = \sqrt{(-1 + \sqrt{3}i)(-1-\sqrt{3}i)} = \sqrt{1+3} = 2$$ we see that $L = \mathbb{Q}(\alpha_1) = \mathbb{Q}(\alpha_2)$.  It's not difficult to see that $[\mathbb{Q}(\alpha_1) : \mathbb{Q}] = 4$, so the Galois group of $L/\mathbb{Q}$ over $\mathbb{Q}$ is is either $\mathbb{Z}/4\mathbb{Z}$ or $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}$. My guess is that this Galois group is cyclic, since I think that $\mathbb{Q}(\sqrt{3}i)$ (a cyclotomic extension by a cubic root of unity) is the only intermediate subfield of $L/\mathbb{Q}$.  How can I know for sure?",,"['abstract-algebra', 'galois-theory']"
15,Galois group of $x^5 + x^2 + 1$ over the field $\mathbb{F}_{2}$,Galois group of  over the field,x^5 + x^2 + 1 \mathbb{F}_{2},"I'm uncertain if I am doing this problem correctly. This is an old algebra prelim problem regarding Galois theory. We have to find the Galois group of the irreducible polynomial (the problem already assumes so) $f(x)=x^5 + x^2 + 1$ over the field of two elements, i.e. $\mathbb{F}_{2}$. My attempt at a solution: Let $F$ be a splitting field of $f(x)= x^5 + x^2 + 1$ over $\mathbb{F}_{2}$. Now let $\alpha$ be a root of $f(x)$. Since any finite extension of $\mathbb{F}_{p}$ is Galois for $p$ prime, in this case we have $F= \mathbb{F}_{2}(\alpha)$. In the particular case of this problem, then the Galois extension $F/\mathbb{F}_{2}$ has degree $[F:\mathbb{F}_{2}]=5$ since $f(x)$ is irreducible of degree $5$ over $\mathbb{F}_{2}$. I want to say that the Galois group of $f(x)$ over $\mathbb{F}_{2}$ is cyclic of order $5$, but I don't think that's correct. My reasoning: If I ended up with the result that $\textit{Gal}(F/\mathbb{F}_{2}) \cong \mathbb{Z}_{5}$, that would have meant that $F$ was isomorphic to the splitting field of $x^{2^5}-x$, i.e. $\mathbb{F}_{2^5}$. Because of this, it would follow that $$ \textit{Gal}(F/\mathbb{F}_{2})= \langle \sigma_{2} \rangle \cong \mathbb{Z}_{5},$$ where $\sigma_{2}$ is the Frobenius automorphism for $p=2$. So my question is, is it true that $F= \mathbb{F}_{2^5}$, or is it isomorphic to it? Am I on the right track?","I'm uncertain if I am doing this problem correctly. This is an old algebra prelim problem regarding Galois theory. We have to find the Galois group of the irreducible polynomial (the problem already assumes so) $f(x)=x^5 + x^2 + 1$ over the field of two elements, i.e. $\mathbb{F}_{2}$. My attempt at a solution: Let $F$ be a splitting field of $f(x)= x^5 + x^2 + 1$ over $\mathbb{F}_{2}$. Now let $\alpha$ be a root of $f(x)$. Since any finite extension of $\mathbb{F}_{p}$ is Galois for $p$ prime, in this case we have $F= \mathbb{F}_{2}(\alpha)$. In the particular case of this problem, then the Galois extension $F/\mathbb{F}_{2}$ has degree $[F:\mathbb{F}_{2}]=5$ since $f(x)$ is irreducible of degree $5$ over $\mathbb{F}_{2}$. I want to say that the Galois group of $f(x)$ over $\mathbb{F}_{2}$ is cyclic of order $5$, but I don't think that's correct. My reasoning: If I ended up with the result that $\textit{Gal}(F/\mathbb{F}_{2}) \cong \mathbb{Z}_{5}$, that would have meant that $F$ was isomorphic to the splitting field of $x^{2^5}-x$, i.e. $\mathbb{F}_{2^5}$. Because of this, it would follow that $$ \textit{Gal}(F/\mathbb{F}_{2})= \langle \sigma_{2} \rangle \cong \mathbb{Z}_{5},$$ where $\sigma_{2}$ is the Frobenius automorphism for $p=2$. So my question is, is it true that $F= \mathbb{F}_{2^5}$, or is it isomorphic to it? Am I on the right track?",,"['abstract-algebra', 'galois-theory', 'finite-fields']"
16,Symmetric Group Action on a Set of Functions,Symmetric Group Action on a Set of Functions,,"I'm not understanding the following passage and I'm hoping someone could elucidate (for context, this is in the lead up to the definition of the sign of a permutation) where the author says: Let $f$ be a function of $n$ variables, say $f\space\colon\mathbb{Z}^n\to\mathbb{Z}$, so we can evaluate $f\left(x_1,\ldots,x_n\right)$. Let $\sigma$ be a permutation of $J_n$ (the author previously defined $J_n=\left\{1,\ldots,n\right\}$). We define the function $\pi\left(\sigma\right)f$ by $$\pi\left(\sigma\right)f\left(x_1,\ldots,x_n\right)=f\left(x_{\sigma\left(1\right)},\ldots,x_{\sigma\left(n\right)}\right).$$   Then for $\sigma,\tau\in{S_n}$ we have $\pi\left(\sigma\tau\right)=\pi\left(\sigma\right)\pi\left(\tau\right)$. Indeed, we use the definition applied to the function $g=\pi\left(\tau\right)f$ to get   \begin{align*} \pi\left(\sigma\right)\pi\left(\tau\right)f\left(x_1,\ldots,x_n\right)&=\left(\pi\left(\tau\right)f\right)\left(x_{\sigma\left(1\right)},\ldots,x_{\sigma\left(n\right)}\right)\\ &=f\left(x_{\sigma\tau\left(1\right)},\ldots,x_{\sigma\tau\left(n\right)}\right) \\ &=\pi\left(\sigma\tau\right)f\left(x_{1},\ldots,x_{n}\right). \end{align*}   Since the identity in $S_n$ operates as the identity on functions, it follows that we have obtained an operation of $S_n$ on the set of functions. Now if I let $G$ be the set of functions $\mathbb{Z}^n\to\mathbb{Z}$, then I agree  the mapping $S_n\times G\to G$ defined by $\left(\varpi,f\left(x_1,\ldots,x_n\right)\right)\mapsto{f\left(x_{\varpi\left(1\right)},\ldots,x_{\varpi\left(n\right)}\right)}$ is well-defined since functions are well-defined, by definition. Where I get lost is (and let me note how pleased I am that the align* environment works) \begin{align*} \pi\left(\sigma\right)\pi\left(\tau\right)f\left(x_1,\ldots,x_n\right)&=\left(\pi\left(\tau\right)f\right)\left(x_{\sigma\left(1\right)},\ldots,x_{\sigma\left(n\right)}\right)\\ &=f\left(x_{\sigma\tau\left(1\right)},\ldots,x_{\sigma\tau\left(n\right)}\right) \\ &=\pi\left(\sigma\tau\right)f\left(x_{1},\ldots,x_{n}\right). \end{align*} I would go about it as \begin{align*} \pi\left(\sigma\right)\pi\left(\tau\right)f\left(x_1,\ldots,x_n\right)&=\pi\left(\sigma\right)f\left(x_{\tau\left(1\right)},\ldots,x_{\tau\left(n\right)}\right)\\ &=f\left(x_{\sigma\tau\left(1\right)},\ldots,x_{\sigma\tau\left(n\right)}\right) \\ &=\pi\left(\sigma\tau\right)f\left(x_{1},\ldots,x_{n}\right). \end{align*} I'm not sure why the author used $\left(\pi\left(\tau\right)f\right)$ in the RHS of the first line of the aligned equation instead of  $\left(\pi\left(\tau\right)f\left(x_{\sigma\left(1\right)},\ldots,x_{\sigma\left(n\right)}\right)\right)$ and I don't follow why the $\pi(\sigma)$ term 'acts' first. I get why we can take out $\sigma\tau$ since function composition is associative, thus, $(\sigma\circ\tau)(1)=\sigma(\tau(1))$.","I'm not understanding the following passage and I'm hoping someone could elucidate (for context, this is in the lead up to the definition of the sign of a permutation) where the author says: Let $f$ be a function of $n$ variables, say $f\space\colon\mathbb{Z}^n\to\mathbb{Z}$, so we can evaluate $f\left(x_1,\ldots,x_n\right)$. Let $\sigma$ be a permutation of $J_n$ (the author previously defined $J_n=\left\{1,\ldots,n\right\}$). We define the function $\pi\left(\sigma\right)f$ by $$\pi\left(\sigma\right)f\left(x_1,\ldots,x_n\right)=f\left(x_{\sigma\left(1\right)},\ldots,x_{\sigma\left(n\right)}\right).$$   Then for $\sigma,\tau\in{S_n}$ we have $\pi\left(\sigma\tau\right)=\pi\left(\sigma\right)\pi\left(\tau\right)$. Indeed, we use the definition applied to the function $g=\pi\left(\tau\right)f$ to get   \begin{align*} \pi\left(\sigma\right)\pi\left(\tau\right)f\left(x_1,\ldots,x_n\right)&=\left(\pi\left(\tau\right)f\right)\left(x_{\sigma\left(1\right)},\ldots,x_{\sigma\left(n\right)}\right)\\ &=f\left(x_{\sigma\tau\left(1\right)},\ldots,x_{\sigma\tau\left(n\right)}\right) \\ &=\pi\left(\sigma\tau\right)f\left(x_{1},\ldots,x_{n}\right). \end{align*}   Since the identity in $S_n$ operates as the identity on functions, it follows that we have obtained an operation of $S_n$ on the set of functions. Now if I let $G$ be the set of functions $\mathbb{Z}^n\to\mathbb{Z}$, then I agree  the mapping $S_n\times G\to G$ defined by $\left(\varpi,f\left(x_1,\ldots,x_n\right)\right)\mapsto{f\left(x_{\varpi\left(1\right)},\ldots,x_{\varpi\left(n\right)}\right)}$ is well-defined since functions are well-defined, by definition. Where I get lost is (and let me note how pleased I am that the align* environment works) \begin{align*} \pi\left(\sigma\right)\pi\left(\tau\right)f\left(x_1,\ldots,x_n\right)&=\left(\pi\left(\tau\right)f\right)\left(x_{\sigma\left(1\right)},\ldots,x_{\sigma\left(n\right)}\right)\\ &=f\left(x_{\sigma\tau\left(1\right)},\ldots,x_{\sigma\tau\left(n\right)}\right) \\ &=\pi\left(\sigma\tau\right)f\left(x_{1},\ldots,x_{n}\right). \end{align*} I would go about it as \begin{align*} \pi\left(\sigma\right)\pi\left(\tau\right)f\left(x_1,\ldots,x_n\right)&=\pi\left(\sigma\right)f\left(x_{\tau\left(1\right)},\ldots,x_{\tau\left(n\right)}\right)\\ &=f\left(x_{\sigma\tau\left(1\right)},\ldots,x_{\sigma\tau\left(n\right)}\right) \\ &=\pi\left(\sigma\tau\right)f\left(x_{1},\ldots,x_{n}\right). \end{align*} I'm not sure why the author used $\left(\pi\left(\tau\right)f\right)$ in the RHS of the first line of the aligned equation instead of  $\left(\pi\left(\tau\right)f\left(x_{\sigma\left(1\right)},\ldots,x_{\sigma\left(n\right)}\right)\right)$ and I don't follow why the $\pi(\sigma)$ term 'acts' first. I get why we can take out $\sigma\tau$ since function composition is associative, thus, $(\sigma\circ\tau)(1)=\sigma(\tau(1))$.",,['abstract-algebra']
17,A question on the relation of the Galois group as field automorphisms and the Galois group as permutations of roots,A question on the relation of the Galois group as field automorphisms and the Galois group as permutations of roots,,"Let $f\in K[X]$ be a monic separable polynomial and $L$ a splitting field of $f$. Let $M=\{l_1,\ldots,l_n\}$ be the set of roots of $f$ in $L$, i.e. $$ f=(X-l_1)\cdots(X-l_n). $$ The Galois group $Gal(L/K)$ is defined to be group of automorphisms $\delta:L\to L$ fixing $K$. There is a well defined injective group homomorphism $$ \begin{array}{rcl} h: Gal(L/K) & \to &\Sigma(M)\\ \delta &\mapsto & (l_i\mapsto \delta(l_i)) \end{array} $$ with $\Sigma(M)$ the group of permutations of the elements of $M$. I want to identify the image of $h$ in $\Sigma(M)$ and I have heard something like this: ''The Galois group consists of the permutations $\sigma$ of the roots of $f$ such that every algebraic equation in the roots with coefficients in the ground field $K$ remains true after applying $\sigma$.'' In interpreted this as the following statement: The image of $h$ consists exactly of the permutations $\sigma\in\Sigma(M)$ such that for each polynomial $g\in K[X_1,\ldots,X_n]$ with the property that $g(l_1,\ldots,l_n)=0$ holds, the statement $g(\sigma(l_1),\ldots,\sigma(l_n))=0$ is also true. My question is: Does this really describe the image of $h$ and how can I see that? Thank you very much. Update: I found the statement on page 44 in Milne's book on fields and Galois theory but unfortunately no prove is given there. So the question on how to proof remains.","Let $f\in K[X]$ be a monic separable polynomial and $L$ a splitting field of $f$. Let $M=\{l_1,\ldots,l_n\}$ be the set of roots of $f$ in $L$, i.e. $$ f=(X-l_1)\cdots(X-l_n). $$ The Galois group $Gal(L/K)$ is defined to be group of automorphisms $\delta:L\to L$ fixing $K$. There is a well defined injective group homomorphism $$ \begin{array}{rcl} h: Gal(L/K) & \to &\Sigma(M)\\ \delta &\mapsto & (l_i\mapsto \delta(l_i)) \end{array} $$ with $\Sigma(M)$ the group of permutations of the elements of $M$. I want to identify the image of $h$ in $\Sigma(M)$ and I have heard something like this: ''The Galois group consists of the permutations $\sigma$ of the roots of $f$ such that every algebraic equation in the roots with coefficients in the ground field $K$ remains true after applying $\sigma$.'' In interpreted this as the following statement: The image of $h$ consists exactly of the permutations $\sigma\in\Sigma(M)$ such that for each polynomial $g\in K[X_1,\ldots,X_n]$ with the property that $g(l_1,\ldots,l_n)=0$ holds, the statement $g(\sigma(l_1),\ldots,\sigma(l_n))=0$ is also true. My question is: Does this really describe the image of $h$ and how can I see that? Thank you very much. Update: I found the statement on page 44 in Milne's book on fields and Galois theory but unfortunately no prove is given there. So the question on how to proof remains.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
18,Equivalence of two relations in Braid groups,Equivalence of two relations in Braid groups,,"Let $B_n$ be the braid group; that is, a group generated by $\sigma_1,\cdots,\sigma_{n-1}$ with relations $\sigma_i\sigma_{i+1}\sigma_i=\sigma_{i+1}\sigma_i\sigma_{i+1}$ for $i=1,\cdots,n-2$; $\sigma_i\sigma_j=\sigma_j\sigma_i$ if $i,j\in\{1,\cdots,n-1\}$ and $|i-j|\geq 2$. For $1\leq i<j\leq n$, let the usual generator $A_{i,j}$ of pure braid groups be defined as $$A_{i,j}=(\sigma_{j-1}\sigma_{j-2}\cdots\sigma_{i+1})\sigma_i^2(\sigma_{i+1}^{-1}\cdots\sigma_{j-2}^{-1}\sigma_{j-1}^{-1}).$$ I need to prove that the following two sets have the same normal closure: The set of all $[A_{j,k},h^{-1}A_{j,k}h]$, where $1\leq j<k\leq n$ and $h$ is an element of the subgroup generated by $A_{j,j+1},A_{j,j+2},\cdots,A_{j,n}$. The set of all $[A_{j,k},g^{-1}A_{j,k}g]$, where $1\leq j<k\leq n$ and $g$ is an element of the subgroup generated by $A_{1,k},A_{2,k},\cdots,A_{k-1,k}$. My attempt: I believe once we proved that $1\Rightarrow2$, the other direction should be similar. Then I am planning to prove that assuming 1 is true, for each $i=1,\cdots,k-1$, $[A_{j,k},A_{i,k}^{-1}A_{j,k}A_{i,k}]=1$. But the difficulty is : I do not see any obvious way to prove this. Should I use the ususal presentation of pure braid group? If yes, how? Even if I can prove $[A_{j,k},A_{i,k}^{-1}A_{j,k}A_{i,k}]=1$, does this imply 2? Anyway, generally in a group $G$ where $a,b,g\in G$, $g$ commutes with $g^a$ and $g^b$  does not imply that $g$ commutes with $g^{ab}$, where $g^a=a^{-1}ga$.","Let $B_n$ be the braid group; that is, a group generated by $\sigma_1,\cdots,\sigma_{n-1}$ with relations $\sigma_i\sigma_{i+1}\sigma_i=\sigma_{i+1}\sigma_i\sigma_{i+1}$ for $i=1,\cdots,n-2$; $\sigma_i\sigma_j=\sigma_j\sigma_i$ if $i,j\in\{1,\cdots,n-1\}$ and $|i-j|\geq 2$. For $1\leq i<j\leq n$, let the usual generator $A_{i,j}$ of pure braid groups be defined as $$A_{i,j}=(\sigma_{j-1}\sigma_{j-2}\cdots\sigma_{i+1})\sigma_i^2(\sigma_{i+1}^{-1}\cdots\sigma_{j-2}^{-1}\sigma_{j-1}^{-1}).$$ I need to prove that the following two sets have the same normal closure: The set of all $[A_{j,k},h^{-1}A_{j,k}h]$, where $1\leq j<k\leq n$ and $h$ is an element of the subgroup generated by $A_{j,j+1},A_{j,j+2},\cdots,A_{j,n}$. The set of all $[A_{j,k},g^{-1}A_{j,k}g]$, where $1\leq j<k\leq n$ and $g$ is an element of the subgroup generated by $A_{1,k},A_{2,k},\cdots,A_{k-1,k}$. My attempt: I believe once we proved that $1\Rightarrow2$, the other direction should be similar. Then I am planning to prove that assuming 1 is true, for each $i=1,\cdots,k-1$, $[A_{j,k},A_{i,k}^{-1}A_{j,k}A_{i,k}]=1$. But the difficulty is : I do not see any obvious way to prove this. Should I use the ususal presentation of pure braid group? If yes, how? Even if I can prove $[A_{j,k},A_{i,k}^{-1}A_{j,k}A_{i,k}]=1$, does this imply 2? Anyway, generally in a group $G$ where $a,b,g\in G$, $g$ commutes with $g^a$ and $g^b$  does not imply that $g$ commutes with $g^{ab}$, where $g^a=a^{-1}ga$.",,"['abstract-algebra', 'group-theory', 'braid-groups']"
19,Nice proof that $\mathbb{Z}[\sqrt{6}]$ is a Euclidean domain wrt absolute norm map,Nice proof that  is a Euclidean domain wrt absolute norm map,\mathbb{Z}[\sqrt{6}],"I know that $\mathbb{Z}\left[\sqrt{6}\,\right]$ is a Euclidean domain with respect to the absolute valued norm map $x+y\sqrt{6} \mapsto |x^2-6y^2|$. I think I proved this result with some common techniques, but the proof is a bit sloppy and it requires a lot of cases. (Basically, I checked that for every $z \in \mathbb{Q}(\sqrt{6})$ there is $\gamma \in \mathbb{Z}[\sqrt{6}]$ such that $|N(z-\gamma)|<1$.) Does there exist a short proof for this result, with less cases or a more, say, enlightening method? Many thanks.","I know that $\mathbb{Z}\left[\sqrt{6}\,\right]$ is a Euclidean domain with respect to the absolute valued norm map $x+y\sqrt{6} \mapsto |x^2-6y^2|$. I think I proved this result with some common techniques, but the proof is a bit sloppy and it requires a lot of cases. (Basically, I checked that for every $z \in \mathbb{Q}(\sqrt{6})$ there is $\gamma \in \mathbb{Z}[\sqrt{6}]$ such that $|N(z-\gamma)|<1$.) Does there exist a short proof for this result, with less cases or a more, say, enlightening method? Many thanks.",,"['abstract-algebra', 'algebraic-number-theory']"
20,Show that a finite group G generated by two elements of order 2 is isomorphic to a dihedral group $D_{2n}$ for some n. (Proof Verification),Show that a finite group G generated by two elements of order 2 is isomorphic to a dihedral group  for some n. (Proof Verification),D_{2n},"Show that a finite group G generated by two elements of order 2 is isomorphic to a dihedral group $D_{2n}$ for some n. (Proof Verification) Proof: Let G be generated by c, b, where $c^2 = b^2 = 1$. Let $a = cb$ be an element of order, say n. The element a is of finite order since G is finite. G is clearly generated by a, b since $c = cbb = ab$ is generated by a, b. Note that $a^{-1} = bc$ since $bca = bccb = 1$. Therefore $bab = bcbb = bc = a^{-1}$. Let $\alpha$ be the rotation of $2\pi/n$ degree and $\beta$ the reflection along the line formed by $v_0$ and the origin in $D_{2n}$. Let $f: G \to D_{2n}$ be defined by $f(a^kb^l) = \alpha^k\beta^l$ for $0 \leq k \leq n$ and $0 \leq l \leq 1$. It is clear that $f$ is homomorphic and injective. Now, we need to prove that $f$ is surjective. It is sufficient to show that f is surjective by showing that G has $2n$ elements since $f$ is injective. The group G contains 2 subgroups $H_1 = <a>$ and $H_2 = <b>$ of order n and 2, respectively. If we can show that $H_1 \cap H_2 = 1$, then G must contain $2n$ elements. Clearly $b \notin H_1$ . If $a^i = b$, for $1 \leq i \leq n - 1$  then $a^{i-1} = a^ibc = bbc = c$, which is a contradiction to the fact that a is of order n. We also know that $a \neq b$, else c will be the identity, which is a contradiction. This implies that $a^i \notin H_2$ Hence, the result.","Show that a finite group G generated by two elements of order 2 is isomorphic to a dihedral group $D_{2n}$ for some n. (Proof Verification) Proof: Let G be generated by c, b, where $c^2 = b^2 = 1$. Let $a = cb$ be an element of order, say n. The element a is of finite order since G is finite. G is clearly generated by a, b since $c = cbb = ab$ is generated by a, b. Note that $a^{-1} = bc$ since $bca = bccb = 1$. Therefore $bab = bcbb = bc = a^{-1}$. Let $\alpha$ be the rotation of $2\pi/n$ degree and $\beta$ the reflection along the line formed by $v_0$ and the origin in $D_{2n}$. Let $f: G \to D_{2n}$ be defined by $f(a^kb^l) = \alpha^k\beta^l$ for $0 \leq k \leq n$ and $0 \leq l \leq 1$. It is clear that $f$ is homomorphic and injective. Now, we need to prove that $f$ is surjective. It is sufficient to show that f is surjective by showing that G has $2n$ elements since $f$ is injective. The group G contains 2 subgroups $H_1 = <a>$ and $H_2 = <b>$ of order n and 2, respectively. If we can show that $H_1 \cap H_2 = 1$, then G must contain $2n$ elements. Clearly $b \notin H_1$ . If $a^i = b$, for $1 \leq i \leq n - 1$  then $a^{i-1} = a^ibc = bbc = c$, which is a contradiction to the fact that a is of order n. We also know that $a \neq b$, else c will be the identity, which is a contradiction. This implies that $a^i \notin H_2$ Hence, the result.",,"['abstract-algebra', 'proof-verification']"
21,Group objects in category of $\mathcal{Set}$ are groups - How to prove it?,Group objects in category of  are groups - How to prove it?,\mathcal{Set},"Reading about group objects in categories, it's a fact that a group object is in the category of $\mathcal{Set}$ just a common group. I am trying to give an actual proof of this, but I'm a bit confused on how to connect the group axioms to the definition of a group object - mainly because the group axioms work with elements inside of a group, but in category theory, the elements of an object don't really play a role. So I wonder how to actually proof that a group object in $\mathcal{Set}$ is indeed a group. The definition of a group object as I know is the following, given by Richard Pink in ""Finite group schemes"": A (commutative) group object in the category $\mathcal{C}$ is a pair consisting of an object $G \in ob(\mathcal{C})$ and a morphism $\mu : G \times G \to G$ such that for any object $Z \in ob(\mathcal{C})$ the map $G(Z) \times G(Z) \to G(Z)$, $(g, g') \mapsto \mu \circ (g, g')$ defines a (commutative) group. Where $G(Z)$ is the set of morphisms $Z \to G$. Im also not sure if this is a proper definition (e.g. shouldn't it be explained what is ment by ""define a group"").","Reading about group objects in categories, it's a fact that a group object is in the category of $\mathcal{Set}$ just a common group. I am trying to give an actual proof of this, but I'm a bit confused on how to connect the group axioms to the definition of a group object - mainly because the group axioms work with elements inside of a group, but in category theory, the elements of an object don't really play a role. So I wonder how to actually proof that a group object in $\mathcal{Set}$ is indeed a group. The definition of a group object as I know is the following, given by Richard Pink in ""Finite group schemes"": A (commutative) group object in the category $\mathcal{C}$ is a pair consisting of an object $G \in ob(\mathcal{C})$ and a morphism $\mu : G \times G \to G$ such that for any object $Z \in ob(\mathcal{C})$ the map $G(Z) \times G(Z) \to G(Z)$, $(g, g') \mapsto \mu \circ (g, g')$ defines a (commutative) group. Where $G(Z)$ is the set of morphisms $Z \to G$. Im also not sure if this is a proper definition (e.g. shouldn't it be explained what is ment by ""define a group"").",,"['abstract-algebra', 'group-theory', 'category-theory']"
22,How to define a taxonomy of non associative operations?,How to define a taxonomy of non associative operations?,,"Let $A$ be a set, and let $a,b,c\in A$. Let also $\circ: A\times A\rightarrow A$ be a binary operation on $A$. We agree as usual to write $a\circ b$ to mean $\circ(a,b)$. We say that $\circ$ is associative if for any $a,b,c\in A$ the following holds: \begin{equation} (a\circ b)\circ c=a\circ (b\circ c) \end{equation} That's OK, but given three elements in $A$ there are many ways to compose them. In particular, we can compute the following $12$ compositions: \begin{equation} (a\circ b)\circ c\qquad\qquad a\circ (b\circ c)\\ (a\circ c)\circ b\qquad\qquad a\circ (c\circ b)\\ (b\circ a)\circ c \qquad\qquad b\circ (a\circ c) \\ (b\circ c) \circ a \qquad\qquad b\circ (c \circ a) \\ (c\circ a)\circ b \qquad\qquad c\circ (a\circ b) \\ (c\circ b)\circ a \qquad\qquad c\circ (b\circ a) \end{equation} They are of course $12$ because we are permuting $3$ objects and for each permutation we have $2$ ways of putting meaningful parentheses, so $3!\cdot 2 = 12$. Associativity means that we identify the first (top left) object with the second (top right); this has a strong meaning to us because usual number fields ($\mathbb{R},\mathbb{C}$) behave in this way. My question is: what happens if we identify the first relation with a different one taken from the other $11$? Are there some relevant (i.e. studied in literature) examples of such structures? The only examples I could find of non associative structures like this are defined over more complex objects, for example the cross product on $\mathbb{R}^3$ or generally a Lie bracket is not associative but is defined over a vector space. I don't even know what exactly to search for to organise my thoughts.","Let $A$ be a set, and let $a,b,c\in A$. Let also $\circ: A\times A\rightarrow A$ be a binary operation on $A$. We agree as usual to write $a\circ b$ to mean $\circ(a,b)$. We say that $\circ$ is associative if for any $a,b,c\in A$ the following holds: \begin{equation} (a\circ b)\circ c=a\circ (b\circ c) \end{equation} That's OK, but given three elements in $A$ there are many ways to compose them. In particular, we can compute the following $12$ compositions: \begin{equation} (a\circ b)\circ c\qquad\qquad a\circ (b\circ c)\\ (a\circ c)\circ b\qquad\qquad a\circ (c\circ b)\\ (b\circ a)\circ c \qquad\qquad b\circ (a\circ c) \\ (b\circ c) \circ a \qquad\qquad b\circ (c \circ a) \\ (c\circ a)\circ b \qquad\qquad c\circ (a\circ b) \\ (c\circ b)\circ a \qquad\qquad c\circ (b\circ a) \end{equation} They are of course $12$ because we are permuting $3$ objects and for each permutation we have $2$ ways of putting meaningful parentheses, so $3!\cdot 2 = 12$. Associativity means that we identify the first (top left) object with the second (top right); this has a strong meaning to us because usual number fields ($\mathbb{R},\mathbb{C}$) behave in this way. My question is: what happens if we identify the first relation with a different one taken from the other $11$? Are there some relevant (i.e. studied in literature) examples of such structures? The only examples I could find of non associative structures like this are defined over more complex objects, for example the cross product on $\mathbb{R}^3$ or generally a Lie bracket is not associative but is defined over a vector space. I don't even know what exactly to search for to organise my thoughts.",,"['abstract-algebra', 'reference-request', 'binary-operations', 'associativity']"
23,"If $df_e: T_eG_1\to T_eG_2$ is surjective, and $G_2$ connected Lie group, then $f$ is surjective.","If  is surjective, and  connected Lie group, then  is surjective.",df_e: T_eG_1\to T_eG_2 G_2 f,"Suppose $f$ is a morphism of Lie groups, and $df_e\colon T_eG_1\to T_eG_2$ is a surjective map of the tangent spaces of two Lie groups, where $G_2$ is connected. I read that by the Inverse Function Theorem, $df_e$ surjective implies $f$ is surjective onto a neighborhood $U$ of $e$ in $G_2$. Then since $G_2$ is connected, it is well known that $U$ generates $G_2$. Since $U$ is the image of $f$, hence a subgroup, $U=G_2$, and $f$ is surjective. My question is, how does the Inverse function theorem come into play? I know that the IFT for manifolds says that if $df_p\colon T_pM\to T_{f(p)}N$ is invertible, then there exist connected nhbds $U\ni p$ and $V\ni f(p)$ such that $f|U\colon U\to V$ is a diffeomorphism. I don't see how we can apply it if $df_e$ is just known to be surjective.","Suppose $f$ is a morphism of Lie groups, and $df_e\colon T_eG_1\to T_eG_2$ is a surjective map of the tangent spaces of two Lie groups, where $G_2$ is connected. I read that by the Inverse Function Theorem, $df_e$ surjective implies $f$ is surjective onto a neighborhood $U$ of $e$ in $G_2$. Then since $G_2$ is connected, it is well known that $U$ generates $G_2$. Since $U$ is the image of $f$, hence a subgroup, $U=G_2$, and $f$ is surjective. My question is, how does the Inverse function theorem come into play? I know that the IFT for manifolds says that if $df_p\colon T_pM\to T_{f(p)}N$ is invertible, then there exist connected nhbds $U\ni p$ and $V\ni f(p)$ such that $f|U\colon U\to V$ is a diffeomorphism. I don't see how we can apply it if $df_e$ is just known to be surjective.",,"['abstract-algebra', 'lie-groups']"
24,Group of order $1575$ problem,Group of order  problem,1575,"Problem Let $G$ be a group with $|G|=1575$. If $H \lhd G$ and $|H|=9$, then $H \subseteq Z(G)$. What I've done so far is $|G|=1575=3^25^27$. I consider $G$ acting on $H$ by conjugation, or, in other words, I consider the morphism $$\phi: G \to Aut(H)$$$$g \to ghg^{-1}, \forall h$$ Since $H$ is normal, it is clear that $\phi(g) \in Aut(H)$. Now, $$H=\coprod_{h\in H} \mathcal O_h,$$ where $\mathcal O_h=\{x \in H: ghg^{-1}=x\}$. If I could show that each of these orbits has one element, then it easy to see that $h \in Z(G)$  for all $h \in H$. One can define a bijection between each $\mathcal O_h$ and $G/ G_h$, where $ G_h=\{g \in G :ghg^{-1}=h\}$, so $1=|\mathcal O_h|=\dfrac{|G|}{|G_h|}$. Then, $|G_h|=|G|$, at this point I got completely stuck, another thing I know is that if $|H|=3^2$ and $H$ is a normal subgroup, then $H$ is the only $3$-Sylow subgroup of $G$. I would appreciate some suggestions, thanks in advance.","Problem Let $G$ be a group with $|G|=1575$. If $H \lhd G$ and $|H|=9$, then $H \subseteq Z(G)$. What I've done so far is $|G|=1575=3^25^27$. I consider $G$ acting on $H$ by conjugation, or, in other words, I consider the morphism $$\phi: G \to Aut(H)$$$$g \to ghg^{-1}, \forall h$$ Since $H$ is normal, it is clear that $\phi(g) \in Aut(H)$. Now, $$H=\coprod_{h\in H} \mathcal O_h,$$ where $\mathcal O_h=\{x \in H: ghg^{-1}=x\}$. If I could show that each of these orbits has one element, then it easy to see that $h \in Z(G)$  for all $h \in H$. One can define a bijection between each $\mathcal O_h$ and $G/ G_h$, where $ G_h=\{g \in G :ghg^{-1}=h\}$, so $1=|\mathcal O_h|=\dfrac{|G|}{|G_h|}$. Then, $|G_h|=|G|$, at this point I got completely stuck, another thing I know is that if $|H|=3^2$ and $H$ is a normal subgroup, then $H$ is the only $3$-Sylow subgroup of $G$. I would appreciate some suggestions, thanks in advance.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'normal-subgroups']"
25,Ring with convolution product,Ring with convolution product,,"Let $M$ be a monoid and $R$ a ring, $f,g \in R^{(M)}$ (the functions from $M$ to $R$ with finite support), we define the convolution product as $$x\in M \implies (f*g)(x)=\sum_{yz=x} f(y)g(z).$$ Show that $R[M]:=(R^{(M)},+,*)$ is a ring (the operation $+$ is defined by $(f+g)(x)=f(x)+_Rg(x)$. I could prove that $R[M]$ is an abelian group with $+$ and the distribution property. I had problems proving that $R[M]$ is a monoid with $*$. I've tried to show that $f$ defined as $f(x)=1_R$ for all $x\in M$ is the identity for $*$, so if I take $g$, then $$(f*g)(x)=\sum_{yz=x}f(y)g(z)=\sum_{yz=x}1_R.g(z)=\sum_{yz=x}g(z).$$ I would like to conclude that $\sum_{yz=x}g(z)=g(x)$. I suppose that this is true since this sum doesn't depend on $y$ but only on $z$, so instead of $yz=x$, it is $z=x$ Would this be correct? My major doubt is about the associativity: let $f,g,h$, then $$((f*g)*h)(x)=\sum_{yz=x}((f*g)(y))h(z)=\sum_{yz=x}(\sum_{wt=y}f(w)g(t))h(z).$$ I got stuck at that point. I've already verified closure under $*$, I would appreciate if someone could tell me how to prove associativity and to check if what I've done for existence of identity element under $*$ is correct.","Let $M$ be a monoid and $R$ a ring, $f,g \in R^{(M)}$ (the functions from $M$ to $R$ with finite support), we define the convolution product as $$x\in M \implies (f*g)(x)=\sum_{yz=x} f(y)g(z).$$ Show that $R[M]:=(R^{(M)},+,*)$ is a ring (the operation $+$ is defined by $(f+g)(x)=f(x)+_Rg(x)$. I could prove that $R[M]$ is an abelian group with $+$ and the distribution property. I had problems proving that $R[M]$ is a monoid with $*$. I've tried to show that $f$ defined as $f(x)=1_R$ for all $x\in M$ is the identity for $*$, so if I take $g$, then $$(f*g)(x)=\sum_{yz=x}f(y)g(z)=\sum_{yz=x}1_R.g(z)=\sum_{yz=x}g(z).$$ I would like to conclude that $\sum_{yz=x}g(z)=g(x)$. I suppose that this is true since this sum doesn't depend on $y$ but only on $z$, so instead of $yz=x$, it is $z=x$ Would this be correct? My major doubt is about the associativity: let $f,g,h$, then $$((f*g)*h)(x)=\sum_{yz=x}((f*g)(y))h(z)=\sum_{yz=x}(\sum_{wt=y}f(w)g(t))h(z).$$ I got stuck at that point. I've already verified closure under $*$, I would appreciate if someone could tell me how to prove associativity and to check if what I've done for existence of identity element under $*$ is correct.",,"['abstract-algebra', 'ring-theory']"
26,Plane curves isomorphic to the affine line,Plane curves isomorphic to the affine line,,"Let $C$ be a plane curve parametrized by $x=f(t),y=g(t)$ where $f(t),g(t)\in k[t]$. We can easily see that the coordinate ring of $C$ is isomorphic to $k[f(t),g(t)]\subset k[t]$. So $C$ is isomorphic to the affine line $\mathbb{A}^1$ if $k[f(t),g(t)]=k[t]$. For example, the curve given by $x=t+t^4,y=t^2$ is isomorphic to the affine line. My question is that whether all curves that are given by $x=f(t),y=g(t)$ with $k[f(t),g(t)]=k[t]$ are of such kind, i.e., satisfy a relation of the form $x-ay^n=bt+c$ or $y-ax^n=bt+c$ for some $n\in \mathbb{Z}$ and constants $a,b,c$? In algebraic terms, I am asking the following question: If $k[f(t),g(t)]=k[t]$, does it necessary that the relation of $f(t),g(t)$ and $t$ is of the form $f-ag^n=bt+c$ or $g-af^n=bt+c$? Note: The Abhyankar–Moh theorem states that if $k[f(t),g(t)]=k[t]$, then $\deg f$ divides $\deg g$ or $\deg g$ divides $\deg f$. We may take $k=\mathbb{C}$ if necessary.","Let $C$ be a plane curve parametrized by $x=f(t),y=g(t)$ where $f(t),g(t)\in k[t]$. We can easily see that the coordinate ring of $C$ is isomorphic to $k[f(t),g(t)]\subset k[t]$. So $C$ is isomorphic to the affine line $\mathbb{A}^1$ if $k[f(t),g(t)]=k[t]$. For example, the curve given by $x=t+t^4,y=t^2$ is isomorphic to the affine line. My question is that whether all curves that are given by $x=f(t),y=g(t)$ with $k[f(t),g(t)]=k[t]$ are of such kind, i.e., satisfy a relation of the form $x-ay^n=bt+c$ or $y-ax^n=bt+c$ for some $n\in \mathbb{Z}$ and constants $a,b,c$? In algebraic terms, I am asking the following question: If $k[f(t),g(t)]=k[t]$, does it necessary that the relation of $f(t),g(t)$ and $t$ is of the form $f-ag^n=bt+c$ or $g-af^n=bt+c$? Note: The Abhyankar–Moh theorem states that if $k[f(t),g(t)]=k[t]$, then $\deg f$ divides $\deg g$ or $\deg g$ divides $\deg f$. We may take $k=\mathbb{C}$ if necessary.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
27,Square-free factorization of polynomials over finite fields,Square-free factorization of polynomials over finite fields,,"For any $f\in\mathbb{F}_q[X]$, I want to derive an algorithm which computes a factorization $$f=\prod_{i=1}^kf_i^i\tag{1}$$ with square-free polynomials $f_i$. My Ideas: If $f'=0$, we're done ($f\in\mathbb{F}_q$) Otherwise consider $$g_1:=\gcd(f,f')$$ If $g_1=1$ we're done ($f$ is square-free) Otherwise $$f_1:=\frac{f}{g_1}$$ is square-free Now consider $$g_2:=\gcd(g_1,g_1')$$ If $g_2=1$ we're done ($f=f_1g_1$ is a square-free factorization) Otherwise $$f_2:=\frac{g_1}{g_2}$$ is square-free And so on ... This process yields a square-free factorization $$f=f_1\cdots f_{k-1}g_k\tag{2}$$ after $k<\infty$ steps. However, (2) is not the factorization (1) I'm searching for. How can I find the factorization (1) and what's the benefit from the factorization (1) in comparison to factorization (2)? EDIT Elsewhere, I've found an algorithm which exactly does what I've described, but returns $$h_i:=\frac{f_i}{f_{i+1}}\;\;\;\;\;(1\le i<k,f_k:=g_k)$$ and states the $h_i$ would fulfill $$f=\prod_{i=1}^kh_i^i$$ I don't see why this should hold.","For any $f\in\mathbb{F}_q[X]$, I want to derive an algorithm which computes a factorization $$f=\prod_{i=1}^kf_i^i\tag{1}$$ with square-free polynomials $f_i$. My Ideas: If $f'=0$, we're done ($f\in\mathbb{F}_q$) Otherwise consider $$g_1:=\gcd(f,f')$$ If $g_1=1$ we're done ($f$ is square-free) Otherwise $$f_1:=\frac{f}{g_1}$$ is square-free Now consider $$g_2:=\gcd(g_1,g_1')$$ If $g_2=1$ we're done ($f=f_1g_1$ is a square-free factorization) Otherwise $$f_2:=\frac{g_1}{g_2}$$ is square-free And so on ... This process yields a square-free factorization $$f=f_1\cdots f_{k-1}g_k\tag{2}$$ after $k<\infty$ steps. However, (2) is not the factorization (1) I'm searching for. How can I find the factorization (1) and what's the benefit from the factorization (1) in comparison to factorization (2)? EDIT Elsewhere, I've found an algorithm which exactly does what I've described, but returns $$h_i:=\frac{f_i}{f_{i+1}}\;\;\;\;\;(1\le i<k,f_k:=g_k)$$ and states the $h_i$ would fulfill $$f=\prod_{i=1}^kh_i^i$$ I don't see why this should hold.",,"['abstract-algebra', 'polynomials', 'finite-fields', 'computer-algebra-systems']"
28,Generators of the Relations of a Galois Extension,Generators of the Relations of a Galois Extension,,"Let $K$ be a Galois extension of $\mathbb{Q}$ of degree $n$. Pick some primitive element and take the roots $a_1, ..., a_n$ of its minimal polynomial. Then the evaluation map $\mathbb{Q}[x_1, ..., x_n] \to K$ with $x_i \mapsto a_i$ gives a surjection to $K$. The kernel is a maximal ideal $M$ of algebraic relations between $a_1, ..., a_n$. Is it true that $M$ is generated as an ideal by the polynomials of $\mathbb{Q}[x_1, ..., x_n]$ that are fixed by the Galois group of $K$ acting on $\mathbb{Q}[x_1, ..., x_n]$ and are contained within $M$?","Let $K$ be a Galois extension of $\mathbb{Q}$ of degree $n$. Pick some primitive element and take the roots $a_1, ..., a_n$ of its minimal polynomial. Then the evaluation map $\mathbb{Q}[x_1, ..., x_n] \to K$ with $x_i \mapsto a_i$ gives a surjection to $K$. The kernel is a maximal ideal $M$ of algebraic relations between $a_1, ..., a_n$. Is it true that $M$ is generated as an ideal by the polynomials of $\mathbb{Q}[x_1, ..., x_n]$ that are fixed by the Galois group of $K$ acting on $\mathbb{Q}[x_1, ..., x_n]$ and are contained within $M$?",,"['abstract-algebra', 'field-theory']"
29,group-like structure texts.,group-like structure texts.,,"I was reading Dummit and Foote to be ready for my group theory text, but my teacher seems to be paying special attention to things with less structure than groups, for example monoids, semigroups, and other things I don't know the name for in english. We have proves problems similar to the 2001 A1 problem or the 2012 A2 problem. We also saw if $S$ is a semigroup with left and right cancelation then $S$ is a monoid, I later realized on my own $S$ is also a group. I would like to obtain certain mastery and intuition on these group like structures, I am looking for texts, or references of any sort that will help me become better at dealing with these things. Thank you very much in advance. Regards.","I was reading Dummit and Foote to be ready for my group theory text, but my teacher seems to be paying special attention to things with less structure than groups, for example monoids, semigroups, and other things I don't know the name for in english. We have proves problems similar to the 2001 A1 problem or the 2012 A2 problem. We also saw if $S$ is a semigroup with left and right cancelation then $S$ is a monoid, I later realized on my own $S$ is also a group. I would like to obtain certain mastery and intuition on these group like structures, I am looking for texts, or references of any sort that will help me become better at dealing with these things. Thank you very much in advance. Regards.",,"['abstract-algebra', 'group-theory', 'reference-request', 'monoid']"
30,Ext functor commutes with connecting homomorphisms?,Ext functor commutes with connecting homomorphisms?,,"Suppose we have an exact sequence $0 \to L \to M \to N \to 0$ and a morphism $f \colon A \to B$ of $R$-modules. If $\delta \colon \text{Ext}^{i}_{R}(B,N) \to \text{Ext}^{i+1}_{R}(B,L)$ and $\delta' \colon \text{Ext}^{i}_{R}(A,N) \to \text{Ext}^{i+1}_{R}(A,L)$ are the natural connecting homomorphisms, I'm trying to figure out why $(*)$ $ \delta' \circ \text{Ext}^{i}(f,N) = \text{Ext}^{i+1}(f,L) \circ \delta? $ My confusion: If we let $T^{i} = \text{Ext}^{i}(B,-)$ and $U^{i} = \text{Ext}^{i}(A,-)$ we know there are unique natural transformations $\psi^{i} \colon T^{i} \to U^{i}$ such that $\delta' \circ \psi^{i}(N) = \psi^{i+1}(L) \circ \delta$ for each $i \geq 0$ and $\psi^{0} = \text{Hom}(f,-)$. (Northcott, An introduction to homological algebra , pp. 115, theorem 10). So this would solve my question if I knew that $\psi^{i}(C) = \text{Ext}^{i}(f,C)$ for all $R$-modules $C$. Now this is probably true.. but I don't see why. The maps $\text{Ext}^{i}(f,C)$ (as I know) are defined by taking injective resolutions of $B$ and $A$ , then taking the chain map induced by $f$ and applying $\text{Hom}(-,C)$ and then cohomology.. now if we define them this way... why would they commute with the connecting homomorphism as in $(*)$?","Suppose we have an exact sequence $0 \to L \to M \to N \to 0$ and a morphism $f \colon A \to B$ of $R$-modules. If $\delta \colon \text{Ext}^{i}_{R}(B,N) \to \text{Ext}^{i+1}_{R}(B,L)$ and $\delta' \colon \text{Ext}^{i}_{R}(A,N) \to \text{Ext}^{i+1}_{R}(A,L)$ are the natural connecting homomorphisms, I'm trying to figure out why $(*)$ $ \delta' \circ \text{Ext}^{i}(f,N) = \text{Ext}^{i+1}(f,L) \circ \delta? $ My confusion: If we let $T^{i} = \text{Ext}^{i}(B,-)$ and $U^{i} = \text{Ext}^{i}(A,-)$ we know there are unique natural transformations $\psi^{i} \colon T^{i} \to U^{i}$ such that $\delta' \circ \psi^{i}(N) = \psi^{i+1}(L) \circ \delta$ for each $i \geq 0$ and $\psi^{0} = \text{Hom}(f,-)$. (Northcott, An introduction to homological algebra , pp. 115, theorem 10). So this would solve my question if I knew that $\psi^{i}(C) = \text{Ext}^{i}(f,C)$ for all $R$-modules $C$. Now this is probably true.. but I don't see why. The maps $\text{Ext}^{i}(f,C)$ (as I know) are defined by taking injective resolutions of $B$ and $A$ , then taking the chain map induced by $f$ and applying $\text{Hom}(-,C)$ and then cohomology.. now if we define them this way... why would they commute with the connecting homomorphism as in $(*)$?",,"['abstract-algebra', 'homological-algebra', 'derived-functors']"
31,Where can I find an ontology of algebraic structures?,Where can I find an ontology of algebraic structures?,,"A group is a monoid where every element admits an inverse, A ring is a monoid under multiplication that distributes over a commutative group A field is a ring whose non-zero elements form a group under multiplication and so on... These type of relationships form an ontology of algebraic structures. Is there a formal ontology of mathematics available somewhere, perhaps in the OWL/RDF format? edit: to give you an idea of the motivation, it would be nice to automatically extract dependency graph for an algebraic structure. I quickly drew an (incomplete) one for an Abelian variety.","A group is a monoid where every element admits an inverse, A ring is a monoid under multiplication that distributes over a commutative group A field is a ring whose non-zero elements form a group under multiplication and so on... These type of relationships form an ontology of algebraic structures. Is there a formal ontology of mathematics available somewhere, perhaps in the OWL/RDF format? edit: to give you an idea of the motivation, it would be nice to automatically extract dependency graph for an algebraic structure. I quickly drew an (incomplete) one for an Abelian variety.",,"['abstract-algebra', 'meta-math']"
32,"Understanding the proof of $|ST||S\cap T| = |S||T|$ where $S, T$ are subgroups of a finite group",Understanding the proof of  where  are subgroups of a finite group,"|ST||S\cap T| = |S||T| S, T","I'm trying to understand the proof of the following theorem: Theorem 2.20 (Product Formula). If $S$ and $T$ are subgroups of a finite group $G$, then $$|ST|\, |S \cap T| = |S|\,|T|.$$ Remark. The subset $ST$ need not be a subgroup. Proof. Define a function $\varphi: S \times T \to ST$ by $(s, t) \mapsto st$. Since $\varphi$ is a surjection, it suffices to show that if $x \in ST$, then $|\varphi^{-1}(x)| = |S \cap T|$. We show that $\varphi^{-1}(x) = \{(sd, d^{-1}t): d \in S \cap T\}$. It is clear that $\varphi^{-1}(x)$ contains the right side. For the reverse inclusion, let $(s, t), (\sigma, \tau) \in \varphi^{-1}(x)$; that is, $s, \sigma \in S$, $t, \tau \in T$, and $st = x = \sigma \tau$. Thus, $s^{-1}\sigma = t\tau^{-1} \in S \cap T$; let $d = s^{-1}\sigma = t\tau^{-1}$ denote their common value. Then $\sigma = s(s^{-1}\sigma) = sd$ and $d^{-1}t = \tau t^{-1}t = \tau$, as desired. $\quad \square$ I think they're using that  \begin{equation}\tag{1} S \times T = \text{Dom} \varphi = \bigcup_{x \in \text{Im}\varphi} \varphi^{-1}(x) = \bigcup_{x \in ST} \varphi^{-1}(x), \end{equation} and so, $$|S||T|=|S \times T|=\sum_{x \in ST} |\varphi^{-1}(x)| = \sum_{x \in ST} |S \cap T| = |ST||S\cap T|.$$ But if that's what they're using, I don't understand why they say ""Since $\varphi$ is a surjection, it suffices..."", because to prove $(1)$ we don't need that $\phi$ is a surjection, it's valid for all functions. So, why do they say that?","I'm trying to understand the proof of the following theorem: Theorem 2.20 (Product Formula). If $S$ and $T$ are subgroups of a finite group $G$, then $$|ST|\, |S \cap T| = |S|\,|T|.$$ Remark. The subset $ST$ need not be a subgroup. Proof. Define a function $\varphi: S \times T \to ST$ by $(s, t) \mapsto st$. Since $\varphi$ is a surjection, it suffices to show that if $x \in ST$, then $|\varphi^{-1}(x)| = |S \cap T|$. We show that $\varphi^{-1}(x) = \{(sd, d^{-1}t): d \in S \cap T\}$. It is clear that $\varphi^{-1}(x)$ contains the right side. For the reverse inclusion, let $(s, t), (\sigma, \tau) \in \varphi^{-1}(x)$; that is, $s, \sigma \in S$, $t, \tau \in T$, and $st = x = \sigma \tau$. Thus, $s^{-1}\sigma = t\tau^{-1} \in S \cap T$; let $d = s^{-1}\sigma = t\tau^{-1}$ denote their common value. Then $\sigma = s(s^{-1}\sigma) = sd$ and $d^{-1}t = \tau t^{-1}t = \tau$, as desired. $\quad \square$ I think they're using that  \begin{equation}\tag{1} S \times T = \text{Dom} \varphi = \bigcup_{x \in \text{Im}\varphi} \varphi^{-1}(x) = \bigcup_{x \in ST} \varphi^{-1}(x), \end{equation} and so, $$|S||T|=|S \times T|=\sum_{x \in ST} |\varphi^{-1}(x)| = \sum_{x \in ST} |S \cap T| = |ST||S\cap T|.$$ But if that's what they're using, I don't understand why they say ""Since $\varphi$ is a surjection, it suffices..."", because to prove $(1)$ we don't need that $\phi$ is a surjection, it's valid for all functions. So, why do they say that?",,"['abstract-algebra', 'group-theory', 'proof-explanation']"
33,Prove that $x^2+1$ is reducible in $\mathbb{Z}_p[x]$.,Prove that  is reducible in .,x^2+1 \mathbb{Z}_p[x],"Prove that $x^2+1$ is reducible in $\mathbb{Z}_p[x]$ if and only if there exists integers $a$ and $b$ such that $a+b=p$ and $ab \equiv 1 \pmod{p}$. (Here $\mathbb{Z}_p$ means the integers modulo a prime $p$). I'm having trouble with the 'only if' direction of this proof, the 'if' direction is pretty trivial. After assuming $f$ is reducible, I've been able to use the Factor Theorem to show that $f$ is of the form $f(x)=c(x-a)(x-b)$ for $a,b,c \in \mathbb{Z}_p$, so $x^2+1=cx^2-c(a+b)x+c(ab)$. Comparing coefficients, we see that $c=1$, so we must have $ab=1$ and $a+b=0$, hence, $a+b \equiv 0 \pmod{p}$ and $ab \equiv 1 \pmod {p}$. Id like to show that $a+b=p$. This seems to be the case, but I'm having difficulty proving it. Is it okay here to assume that $a<p$ and $b<p$ (since they are elements of $\mathbb{Z}_p$), and assume without loss of generality that $a\leq b$, so that $a\leq b < p$, and use this to deduce that if $a+b=\alpha p$ for some $\alpha \in \mathbb{Z}$ with $\alpha \geq 0$, then we must have $\alpha =1$? I want to say something like, if either $a=0$ or $b=0$, then $ab \equiv 0 \pmod{p}$, a contradiction, so we must have $a+b\geq 2$, so we cannot have $\alpha=0$. If $2\leq \alpha$, then since $a\leq b < p$, we have $a+b<p+b<2p\leq \alpha p$, contradicting that fact that $a+b=\alpha p$, so we must have $\alpha =1$. I have a strong feeling I'm over-thinking this problem, thanks in advance for any help!","Prove that $x^2+1$ is reducible in $\mathbb{Z}_p[x]$ if and only if there exists integers $a$ and $b$ such that $a+b=p$ and $ab \equiv 1 \pmod{p}$. (Here $\mathbb{Z}_p$ means the integers modulo a prime $p$). I'm having trouble with the 'only if' direction of this proof, the 'if' direction is pretty trivial. After assuming $f$ is reducible, I've been able to use the Factor Theorem to show that $f$ is of the form $f(x)=c(x-a)(x-b)$ for $a,b,c \in \mathbb{Z}_p$, so $x^2+1=cx^2-c(a+b)x+c(ab)$. Comparing coefficients, we see that $c=1$, so we must have $ab=1$ and $a+b=0$, hence, $a+b \equiv 0 \pmod{p}$ and $ab \equiv 1 \pmod {p}$. Id like to show that $a+b=p$. This seems to be the case, but I'm having difficulty proving it. Is it okay here to assume that $a<p$ and $b<p$ (since they are elements of $\mathbb{Z}_p$), and assume without loss of generality that $a\leq b$, so that $a\leq b < p$, and use this to deduce that if $a+b=\alpha p$ for some $\alpha \in \mathbb{Z}$ with $\alpha \geq 0$, then we must have $\alpha =1$? I want to say something like, if either $a=0$ or $b=0$, then $ab \equiv 0 \pmod{p}$, a contradiction, so we must have $a+b\geq 2$, so we cannot have $\alpha=0$. If $2\leq \alpha$, then since $a\leq b < p$, we have $a+b<p+b<2p\leq \alpha p$, contradicting that fact that $a+b=\alpha p$, so we must have $\alpha =1$. I have a strong feeling I'm over-thinking this problem, thanks in advance for any help!",,"['abstract-algebra', 'polynomials']"
34,Normal subgroups in $GL_2(\mathbb F_3)$,Normal subgroups in,GL_2(\mathbb F_3),"I'm searching for all the normal subgroups of $G:=GL_2(\mathbb F_3)$. Till now I found $N:=SL_2(\mathbb F_3)$ subgroup of index $2$, $Q_8$ subgroup of index $6$ and the center $Z:=Z(G)=\{\pm\mathbb I_2\}$ of index $24$. First question: are there other normal subgroups? My attempt : let $M\unlhd G$. Then we have to separate two cases: $Z\le M$ and $Z\nleq M$. In the first case $M$ must be one of the subgroup I've already written. In the latter case, first we note that $N, M\unlhd G\Rightarrow M\cap N\unlhd G\Rightarrow M\cap N\unlhd N$. But $Z=\{\pm\mathbb I\}$ and we know that $g=-\mathbb I$ is the only element of order $2$ in $N$. Hence the condition $Z\nleq M$ means that $M$ doesn't contain any element of order $2$ and so neither $M\cap N$ can contain any element of order $2$. But $|N|=3\cdot2^3$ hence by Cauchy we have that $M\cap N$ must have oder $3$, i.e. $M\cap N\in\operatorname{Syl}_3(N)$. So we would have only one $3$-Sylow in $N$ and this is absurd since we know that $n_3(N)=4$. Thus we conclude that a normal subgroup in $G$ must necessarely be in $\{Z,Q_8,N\}$. Am I right? Is this correct? The following problem is already solved, so you can not look at that. EDIT 2: we know that $\overline N:=N/Z\simeq A_4$; then $G/Z:=\overline G$ acts on $\overline N$ with conjugation: $$ \gamma:G/Z\longrightarrow\operatorname{Aut}(N/Z)\\xZ\longmapsto\gamma_{xZ}:nZ\mapsto n^xZ $$ and $\ker(\gamma)=C_{\overline G}(\overline N)=:\overline C$. I have to prove that $|\overline C|=1$. Now $\;\overline C\cap\overline N=Z(\overline N)=Z(A_4)=1$. I know that $\overline N$ contains $8$ element of order $3$ (which corresponds to the $8$ element of order $3$ in $N$ and the $8$ element of order $6$ in $N$) so I deduced that $\overline N$ can't contain any element of order $3$ (but in order to make this precise as it should be, I'd have to prove that $G$ doesn't contain any other element of order $3$ or $6$). Hence $|\overline C|\in\{1,2,4,8\}$ (in fact $|\overline G|=3\cdot2^3$). Now I'm able to show that $|\overline C|=2$ leads to a contradiction (but it's long and I won't write it). Second question: how can I show that $|\overline C|\neq4,8$? Moreover it's clear that $|\overline G:\overline N|=2$ but I can't know how to use it. Thank you all","I'm searching for all the normal subgroups of $G:=GL_2(\mathbb F_3)$. Till now I found $N:=SL_2(\mathbb F_3)$ subgroup of index $2$, $Q_8$ subgroup of index $6$ and the center $Z:=Z(G)=\{\pm\mathbb I_2\}$ of index $24$. First question: are there other normal subgroups? My attempt : let $M\unlhd G$. Then we have to separate two cases: $Z\le M$ and $Z\nleq M$. In the first case $M$ must be one of the subgroup I've already written. In the latter case, first we note that $N, M\unlhd G\Rightarrow M\cap N\unlhd G\Rightarrow M\cap N\unlhd N$. But $Z=\{\pm\mathbb I\}$ and we know that $g=-\mathbb I$ is the only element of order $2$ in $N$. Hence the condition $Z\nleq M$ means that $M$ doesn't contain any element of order $2$ and so neither $M\cap N$ can contain any element of order $2$. But $|N|=3\cdot2^3$ hence by Cauchy we have that $M\cap N$ must have oder $3$, i.e. $M\cap N\in\operatorname{Syl}_3(N)$. So we would have only one $3$-Sylow in $N$ and this is absurd since we know that $n_3(N)=4$. Thus we conclude that a normal subgroup in $G$ must necessarely be in $\{Z,Q_8,N\}$. Am I right? Is this correct? The following problem is already solved, so you can not look at that. EDIT 2: we know that $\overline N:=N/Z\simeq A_4$; then $G/Z:=\overline G$ acts on $\overline N$ with conjugation: $$ \gamma:G/Z\longrightarrow\operatorname{Aut}(N/Z)\\xZ\longmapsto\gamma_{xZ}:nZ\mapsto n^xZ $$ and $\ker(\gamma)=C_{\overline G}(\overline N)=:\overline C$. I have to prove that $|\overline C|=1$. Now $\;\overline C\cap\overline N=Z(\overline N)=Z(A_4)=1$. I know that $\overline N$ contains $8$ element of order $3$ (which corresponds to the $8$ element of order $3$ in $N$ and the $8$ element of order $6$ in $N$) so I deduced that $\overline N$ can't contain any element of order $3$ (but in order to make this precise as it should be, I'd have to prove that $G$ doesn't contain any other element of order $3$ or $6$). Hence $|\overline C|\in\{1,2,4,8\}$ (in fact $|\overline G|=3\cdot2^3$). Now I'm able to show that $|\overline C|=2$ leads to a contradiction (but it's long and I won't write it). Second question: how can I show that $|\overline C|\neq4,8$? Moreover it's clear that $|\overline G:\overline N|=2$ but I can't know how to use it. Thank you all",,"['abstract-algebra', 'group-theory', 'finite-groups']"
35,Show that $f:\mathbb{R}^+ \longrightarrow \mathbb{C}^\times$ defined by $f(x)=e^{ix}$ is a homomorphism,Show that  defined by  is a homomorphism,f:\mathbb{R}^+ \longrightarrow \mathbb{C}^\times f(x)=e^{ix},"Can someone please verify my proof? Show that $f:\mathbb{R}^+ \longrightarrow \mathbb{C}^\times$ defined by $f(x)=e^{ix}$ is a homomorphism, and determine its kernel and image. Let $x$ and $y$ be arbitrary elements of $\mathbb{R}^+$. Then, \begin{eqnarray} f(x+y) &=& e^{i(x+y)} \\ &=& e^{ix}e^{iy} \\ &=& f(x)\times f(y) \end{eqnarray} Also, \begin{eqnarray} \operatorname{Im}(f) &=& \{e^{ix}:x \in \mathbb{R}^+\} \\ &=& \{x \in \mathbb{C}: |x|=1\} \end{eqnarray} And, \begin{eqnarray} \operatorname{ker}(f)&=&\{x \in \mathbb{R}^+:e^{ix}=1\} \\ &=& \{2 \pi n: n \in \mathbb{Z}\} \end{eqnarray}","Can someone please verify my proof? Show that $f:\mathbb{R}^+ \longrightarrow \mathbb{C}^\times$ defined by $f(x)=e^{ix}$ is a homomorphism, and determine its kernel and image. Let $x$ and $y$ be arbitrary elements of $\mathbb{R}^+$. Then, \begin{eqnarray} f(x+y) &=& e^{i(x+y)} \\ &=& e^{ix}e^{iy} \\ &=& f(x)\times f(y) \end{eqnarray} Also, \begin{eqnarray} \operatorname{Im}(f) &=& \{e^{ix}:x \in \mathbb{R}^+\} \\ &=& \{x \in \mathbb{C}: |x|=1\} \end{eqnarray} And, \begin{eqnarray} \operatorname{ker}(f)&=&\{x \in \mathbb{R}^+:e^{ix}=1\} \\ &=& \{2 \pi n: n \in \mathbb{Z}\} \end{eqnarray}",,"['abstract-algebra', 'proof-verification']"
36,Necessary conditions for $A=K+\operatorname{Ker}(\phi)$,Necessary conditions for,A=K+\operatorname{Ker}(\phi),"Consider the homomorphism between a field $K$ and $A$ which is finitely generated $K$-algebra (that is it can be written $K[x_1,...,x_n]$). If $\phi: A \to K$ is a homomorphism between $K$-algebras does it always hold that $A=K+\operatorname{Ker}(\phi)$? I have never encountered this rule so what are sufficient conditions for this to hold?","Consider the homomorphism between a field $K$ and $A$ which is finitely generated $K$-algebra (that is it can be written $K[x_1,...,x_n]$). If $\phi: A \to K$ is a homomorphism between $K$-algebras does it always hold that $A=K+\operatorname{Ker}(\phi)$? I have never encountered this rule so what are sufficient conditions for this to hold?",,"['abstract-algebra', 'ring-theory']"
37,"Definition of ""Order of a group ""","Definition of ""Order of a group """,,"According to Wikipedia , the order of a group $G$ is its cardinality, i.e., the number of elements in its set and denoted by $|G|$. The definition given in the book Robinson, ""A course in the theory of group"", Page 2, is also same. But according to this book , page 5, the definition is as follows: The order of a group $G$ is the cardinality $|G|$, either a positive integer or $\infty$. So according to this book, the order of any infinite group is same and it is $\infty$. Is this CORRECT? If not then i would like to know the order of groups $\mathbb{Z}$, $\mathbb{R}$ and $\mathbb{C}$. Thanks for any help in this regard.","According to Wikipedia , the order of a group $G$ is its cardinality, i.e., the number of elements in its set and denoted by $|G|$. The definition given in the book Robinson, ""A course in the theory of group"", Page 2, is also same. But according to this book , page 5, the definition is as follows: The order of a group $G$ is the cardinality $|G|$, either a positive integer or $\infty$. So according to this book, the order of any infinite group is same and it is $\infty$. Is this CORRECT? If not then i would like to know the order of groups $\mathbb{Z}$, $\mathbb{R}$ and $\mathbb{C}$. Thanks for any help in this regard.",,"['abstract-algebra', 'group-theory']"
38,Lemma about extra special group of order $p^3$,Lemma about extra special group of order,p^3,"I am trying to understand the proof of the following lemma: Assume $P$ is a nonabelian group of order $p^3$ where $p$ is an odd prime. Assume also that $P$ has exponent $p^2$. Then $O_p(\text{Out}(P)) \in \text{Syl}_p(\text{Out}(P))$. I can follow most of the steps in the proof: first you realize that $P$ contains a unique subgroup $Q<P$ where $Q \cong C_p\times C_p$. So $Q$ is characteristic in $P$. Also you can see that $\Phi(P) = [P, P] = Z(P) \le Q$ and $[P, P] \cong C_p$. then one considers the homomorphism $\varphi: \text{Aut}(P)\rightarrow \text{Aut}(P/Q)\times \text{Aut}(Q/[P, P]) \cong C_{p-1}\times C_{p-1}$ and then I have another lemma saying that $\ker{\varphi}$ is a normal $p$-subgroup of $\text{Aut}(P)$, so $\ker{\varphi} \subseteq O_p(\text{Aut}(P))$. You can also argue the converse, that $O_p(\text{Aut}(P)) \subseteq \ker{\varphi}$. And then the proof of the lemma stops. What I don't understand is why $\ker{\varphi} = O_p(\text{Aut}(P))$ leads to the fact that $O_p(\text{Out}(P)) \in \text{Syl}_p(\text{Out}(P))$. Also, I am not sure how $\varphi$ is actually defined.","I am trying to understand the proof of the following lemma: Assume $P$ is a nonabelian group of order $p^3$ where $p$ is an odd prime. Assume also that $P$ has exponent $p^2$. Then $O_p(\text{Out}(P)) \in \text{Syl}_p(\text{Out}(P))$. I can follow most of the steps in the proof: first you realize that $P$ contains a unique subgroup $Q<P$ where $Q \cong C_p\times C_p$. So $Q$ is characteristic in $P$. Also you can see that $\Phi(P) = [P, P] = Z(P) \le Q$ and $[P, P] \cong C_p$. then one considers the homomorphism $\varphi: \text{Aut}(P)\rightarrow \text{Aut}(P/Q)\times \text{Aut}(Q/[P, P]) \cong C_{p-1}\times C_{p-1}$ and then I have another lemma saying that $\ker{\varphi}$ is a normal $p$-subgroup of $\text{Aut}(P)$, so $\ker{\varphi} \subseteq O_p(\text{Aut}(P))$. You can also argue the converse, that $O_p(\text{Aut}(P)) \subseteq \ker{\varphi}$. And then the proof of the lemma stops. What I don't understand is why $\ker{\varphi} = O_p(\text{Aut}(P))$ leads to the fact that $O_p(\text{Out}(P)) \in \text{Syl}_p(\text{Out}(P))$. Also, I am not sure how $\varphi$ is actually defined.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'p-groups']"
39,"If $f$ is an anti-symmetric polynomial, then $f=g\prod_{1\leq i < j\leq n}(X_i-X_j)$ for some $g$ symmetric","If  is an anti-symmetric polynomial, then  for some  symmetric",f f=g\prod_{1\leq i < j\leq n}(X_i-X_j) g,"So we have the situation that $f\in K[X_1,...,X_n]$ is anti-symmetric, which means that $\sigma (f)=\pm f$ where it is a plus if $\sigma$ is an even permutation on the $X_i$ and a minus if it is not an even permutation. Now I have to prove that there exists a $g$ which is symmetric such that $f=g\prod_{1\leq i < j\leq n}(X_i-X_j)$. This is what I thought I should do to prove the statement: If we have permutation $\sigma=(12)$ ,which sends $X_1\mapsto X_2$ and $X_2\mapsto X_1$, then $\sigma(f)=-f$. This implies that $X_1-X_2$ divides $f$ (this is the statement which I am not so sure of). Now we can do this for every permutation $\sigma=(ij)$ where $i\neq j$. Then we have that $\prod_{1\leq i < j\leq n}(X_i-X_j)$ divides $f$. It follows immediately that $g$ must be symmetric. Is this proof valid? Thanks for looking at it.","So we have the situation that $f\in K[X_1,...,X_n]$ is anti-symmetric, which means that $\sigma (f)=\pm f$ where it is a plus if $\sigma$ is an even permutation on the $X_i$ and a minus if it is not an even permutation. Now I have to prove that there exists a $g$ which is symmetric such that $f=g\prod_{1\leq i < j\leq n}(X_i-X_j)$. This is what I thought I should do to prove the statement: If we have permutation $\sigma=(12)$ ,which sends $X_1\mapsto X_2$ and $X_2\mapsto X_1$, then $\sigma(f)=-f$. This implies that $X_1-X_2$ divides $f$ (this is the statement which I am not so sure of). Now we can do this for every permutation $\sigma=(ij)$ where $i\neq j$. Then we have that $\prod_{1\leq i < j\leq n}(X_i-X_j)$ divides $f$. It follows immediately that $g$ must be symmetric. Is this proof valid? Thanks for looking at it.",,"['abstract-algebra', 'polynomials', 'symmetric-polynomials']"
40,Construction of the Brauer Group,Construction of the Brauer Group,,"I've proven that the $K$ tensor product of two central simple $K$ algebras is itself central simple, and I've proven Wedderburn's theorem, but I now need to construct the Brauer group. I've been told that two algebras $A\cong M_n(D)$ and $B\cong M_m(D')$ are Brauer equivalent if $D\cong D'$. The operation on equivalence classes is defined as $[A][B]=[A\otimes B]$. Having shown closure, I need to show: That the operation is independent of representative That $[K]$ is the identity in the Brauer group. If the composition is independent of representative then I can use $k$ and all I have to show is that $A\otimes K\cong A$. I think an argument on dimensions does this. That every equivalence class has an inverse. I have been told that the inverse of $A$ is $A^{op}$, so I'd have to show that $A\otimes A^{op}=M_n(K)$ for some $n$. Most of the resources I've found online state these as fact and don't bother proving them. If anyone could refer me to a resource that covers the construction of the Brauer group in detail, I'd be very appreciative.","I've proven that the $K$ tensor product of two central simple $K$ algebras is itself central simple, and I've proven Wedderburn's theorem, but I now need to construct the Brauer group. I've been told that two algebras $A\cong M_n(D)$ and $B\cong M_m(D')$ are Brauer equivalent if $D\cong D'$. The operation on equivalence classes is defined as $[A][B]=[A\otimes B]$. Having shown closure, I need to show: That the operation is independent of representative That $[K]$ is the identity in the Brauer group. If the composition is independent of representative then I can use $k$ and all I have to show is that $A\otimes K\cong A$. I think an argument on dimensions does this. That every equivalence class has an inverse. I have been told that the inverse of $A$ is $A^{op}$, so I'd have to show that $A\otimes A^{op}=M_n(K)$ for some $n$. Most of the resources I've found online state these as fact and don't bother proving them. If anyone could refer me to a resource that covers the construction of the Brauer group in detail, I'd be very appreciative.",,"['abstract-algebra', 'reference-request', 'tensor-products', 'brauer-group']"
41,Galois Group of $x^{14}+x^7-1$ over $\mathbb{Q}$,Galois Group of  over,x^{14}+x^7-1 \mathbb{Q},"So consider the polynomial $f(x)=x^{14}+x^7-1$ defined over $\mathbb{Q}$. We want to determine its Galois Group. So let's look for the splitting field, $L$ say, to give us an idea of the size of the Galois Group. Note that letting $y=x^7$ we see that $y$ satisfies $y^2+y-1=0$ gives us that $y=\frac{1\pm \sqrt5}{2}$ as roots. Clearly these must be in the splitting field of $f$ since for any root of $f$ each of its powers must be in the splitting field and these are the seventh powers of the roots of $f$. So $\mathbb{Q}(\sqrt5) \subset L$ and thus $2| [L:\mathbb{Q}]$. Now I don't  know where to go from here. We see that $\alpha^7=\frac{1\pm \sqrt5}{2}$ for any root $\alpha$, but how do I work out the size of the extension $[L:\mathbb{Q}(\sqrt5)]$?","So consider the polynomial $f(x)=x^{14}+x^7-1$ defined over $\mathbb{Q}$. We want to determine its Galois Group. So let's look for the splitting field, $L$ say, to give us an idea of the size of the Galois Group. Note that letting $y=x^7$ we see that $y$ satisfies $y^2+y-1=0$ gives us that $y=\frac{1\pm \sqrt5}{2}$ as roots. Clearly these must be in the splitting field of $f$ since for any root of $f$ each of its powers must be in the splitting field and these are the seventh powers of the roots of $f$. So $\mathbb{Q}(\sqrt5) \subset L$ and thus $2| [L:\mathbb{Q}]$. Now I don't  know where to go from here. We see that $\alpha^7=\frac{1\pm \sqrt5}{2}$ for any root $\alpha$, but how do I work out the size of the extension $[L:\mathbb{Q}(\sqrt5)]$?",,"['abstract-algebra', 'galois-theory']"
42,Localization in formal power series,Localization in formal power series,,"I saw in a textbook the following assertion: Let $R$ be a commutative ring with unity, and $R[[X]]$ be the ring of power series in one indeterminate $X$. If the homomorphism $\phi∶ R[[X]] \to R$ sending $X$ to $0$ takes a maximal ideal $M$ of $R[[X]]$ to a maximal ideal $\mathfrak{m}$ in $R$, then the two localizations $R[[X]]_M$ and $R_{\mathfrak{m}}[[X]]$ are equal. I think this problem is some fishy, and would appreciate anyone helping me solve it. Thanks in advance.","I saw in a textbook the following assertion: Let $R$ be a commutative ring with unity, and $R[[X]]$ be the ring of power series in one indeterminate $X$. If the homomorphism $\phi∶ R[[X]] \to R$ sending $X$ to $0$ takes a maximal ideal $M$ of $R[[X]]$ to a maximal ideal $\mathfrak{m}$ in $R$, then the two localizations $R[[X]]_M$ and $R_{\mathfrak{m}}[[X]]$ are equal. I think this problem is some fishy, and would appreciate anyone helping me solve it. Thanks in advance.",,"['abstract-algebra', 'commutative-algebra', 'algebraic-number-theory']"
43,Primary descomposition of ideals,Primary descomposition of ideals,,"I'd appreciate if someone could help me a bit with this problem. Considering $\mathfrak{p}=(x,y), \mathfrak{q}=(x,z)$ and $\mathfrak{m}=(x,y,z)$ ideals in $k[x,y,z], k$ field. Is $\mathfrak{p}\mathfrak{q}=\mathfrak{p}\cap \mathfrak{q}\cap\mathfrak{m}^2$ a minimal primary descomposition of $\mathfrak{p}\mathfrak{q}$ ? Which component is isolated and which are embbeded? I tell you what I've thought: It's known that $k[x,y,z]/\mathfrak{m}\cong k$ and $k$ field, so the ideal $\mathfrak{m}=(x,y,z)$ is maximal $\Rightarrow $ $\mathfrak{m}^k$ are $\mathfrak{m}$ -primary, so, particulary $\mathfrak{m}^2$ is $\mathfrak{m}$ -primary. $\mathfrak{p}, \mathfrak{q}$ are prime ideals in $k[x,y,z]$ , because it's known that ideals $(x_1,...,x_i), 1\leq i \leq n$ are prime in $k[x_1,...,x_n]$ . Hence $\mathfrak{p}, \mathfrak{q}$ are primary ideals. How could I continue? Thanks.","I'd appreciate if someone could help me a bit with this problem. Considering and ideals in field. Is a minimal primary descomposition of ? Which component is isolated and which are embbeded? I tell you what I've thought: It's known that and field, so the ideal is maximal are -primary, so, particulary is -primary. are prime ideals in , because it's known that ideals are prime in . Hence are primary ideals. How could I continue? Thanks.","\mathfrak{p}=(x,y), \mathfrak{q}=(x,z) \mathfrak{m}=(x,y,z) k[x,y,z], k \mathfrak{p}\mathfrak{q}=\mathfrak{p}\cap \mathfrak{q}\cap\mathfrak{m}^2 \mathfrak{p}\mathfrak{q} k[x,y,z]/\mathfrak{m}\cong k k \mathfrak{m}=(x,y,z) \Rightarrow  \mathfrak{m}^k \mathfrak{m} \mathfrak{m}^2 \mathfrak{m} \mathfrak{p}, \mathfrak{q} k[x,y,z] (x_1,...,x_i), 1\leq i \leq n k[x_1,...,x_n] \mathfrak{p}, \mathfrak{q}","['abstract-algebra', 'commutative-algebra', 'ideals']"
44,$\frac{G_1\times G_2}{N_1\times N_2}\cong \bigg(\frac{G_1}{N_1}\bigg)\times \bigg(\frac{G_2}{N_2}\bigg)$,,\frac{G_1\times G_2}{N_1\times N_2}\cong \bigg(\frac{G_1}{N_1}\bigg)\times \bigg(\frac{G_2}{N_2}\bigg),"Is my solution to this question correct? If $N_1\triangleleft G_1,N_2\triangleleft G_2$, then $(N_1\times > N_2)\triangleleft (G_1\times G_2)$ and $\frac{G_1\times G_2}{N_1\times  N_2}\cong \bigg(\frac{G_1}{N_1}\bigg)\times  \bigg(\frac{G_2}{N_2}\bigg)$ First part $(g_1,g_2)\in G_1\times G_2$ and $(n_1,n_2)\in N_1\times N_2$, then $(g_1,g_2)(n_1,n_2)(g_1^{-1},g_2^{-1})=(g_1n_1g^{-1}_1,g_2n_2g^{-1}_2)\in N_1\times N_2$, since $N_1$ and $N_2$ are normal subgroups of $G_1$ and $G_2$ respectively. Second part Let $\varphi: G_1\times G_2\to \frac{G_1}{N_1}\times\frac{G_2}{N_2}$ be the canonical epimorphism given by $(a,b)\mapsto(a+N_1,b+N_2)$. Note that $\ker \varphi =N_1\times N_2$, because obviously $N_1\times N_2\subset \ker\varphi$ and let $(a,b)\in \ker\varphi\implies\varphi(a,b)=(a+N_2,b+N_2)=(0+N_1,0+N_2)\implies a\in N_1$ and $b\in N_2\implies (a,b)\in N_1\times N_2$. Thus by first isomorphism theorem we have $\frac{G_1\times G_2}{N_1\times N_2}\cong \frac{G_1}{N_1}\times \frac{G_2}{N_2}$. Thanks in advance","Is my solution to this question correct? If $N_1\triangleleft G_1,N_2\triangleleft G_2$, then $(N_1\times > N_2)\triangleleft (G_1\times G_2)$ and $\frac{G_1\times G_2}{N_1\times  N_2}\cong \bigg(\frac{G_1}{N_1}\bigg)\times  \bigg(\frac{G_2}{N_2}\bigg)$ First part $(g_1,g_2)\in G_1\times G_2$ and $(n_1,n_2)\in N_1\times N_2$, then $(g_1,g_2)(n_1,n_2)(g_1^{-1},g_2^{-1})=(g_1n_1g^{-1}_1,g_2n_2g^{-1}_2)\in N_1\times N_2$, since $N_1$ and $N_2$ are normal subgroups of $G_1$ and $G_2$ respectively. Second part Let $\varphi: G_1\times G_2\to \frac{G_1}{N_1}\times\frac{G_2}{N_2}$ be the canonical epimorphism given by $(a,b)\mapsto(a+N_1,b+N_2)$. Note that $\ker \varphi =N_1\times N_2$, because obviously $N_1\times N_2\subset \ker\varphi$ and let $(a,b)\in \ker\varphi\implies\varphi(a,b)=(a+N_2,b+N_2)=(0+N_1,0+N_2)\implies a\in N_1$ and $b\in N_2\implies (a,b)\in N_1\times N_2$. Thus by first isomorphism theorem we have $\frac{G_1\times G_2}{N_1\times N_2}\cong \frac{G_1}{N_1}\times \frac{G_2}{N_2}$. Thanks in advance",,"['abstract-algebra', 'solution-verification']"
45,Problem of Galois Extension,Problem of Galois Extension,,"$\Bbb K$ is a non-Galois extension of $\Bbb Q$ and $[K:\Bbb Q]=4$. If $\Bbb F$ is the Galois closure of $\Bbb K$ then show that $Gal(\Bbb F/\Bbb Q)$ is either $S_4, A_4$ or $D_8$ with order 8. Further, I want to prove that $Gal(\Bbb F/\Bbb Q) = D_8$ iff $\Bbb K$ contains a quadratic extension of $\Bbb Q$.","$\Bbb K$ is a non-Galois extension of $\Bbb Q$ and $[K:\Bbb Q]=4$. If $\Bbb F$ is the Galois closure of $\Bbb K$ then show that $Gal(\Bbb F/\Bbb Q)$ is either $S_4, A_4$ or $D_8$ with order 8. Further, I want to prove that $Gal(\Bbb F/\Bbb Q) = D_8$ iff $\Bbb K$ contains a quadratic extension of $\Bbb Q$.",,"['abstract-algebra', 'group-theory', 'field-theory', 'galois-theory']"
46,Construction of a polynomial,Construction of a polynomial,,"Let $ m \in \mathbb{N}$ be fixed and $q=p^n$ (a variable prime power) for $n \in \mathbb{N}$  and $p$ prime. We define  $$c_m=|\left\lbrace f \in \mathbb{F}_q[X]; f \ \text{irreducible, monic, deg}(f)=m \right\rbrace|. $$ I want to prove the following statements: (A) $q$ relatively prime to $m$ $\Longrightarrow$ $q \mid c_m$ (B) $\exists$ a monic polynomial $C_m \in \mathbb{Z}[X]$ with $\text{deg}(C_m)=m$ so that $c_m=\frac{C_m(q)}{m}$ for all $q$.","Let $ m \in \mathbb{N}$ be fixed and $q=p^n$ (a variable prime power) for $n \in \mathbb{N}$  and $p$ prime. We define  $$c_m=|\left\lbrace f \in \mathbb{F}_q[X]; f \ \text{irreducible, monic, deg}(f)=m \right\rbrace|. $$ I want to prove the following statements: (A) $q$ relatively prime to $m$ $\Longrightarrow$ $q \mid c_m$ (B) $\exists$ a monic polynomial $C_m \in \mathbb{Z}[X]$ with $\text{deg}(C_m)=m$ so that $c_m=\frac{C_m(q)}{m}$ for all $q$.",,"['abstract-algebra', 'polynomials', 'finite-fields', 'irreducible-polynomials']"
47,"Is $\langle a,b\; |\;a^7 = 1, ab = b^3a^3\rangle$ finite?",Is  finite?,"\langle a,b\; |\;a^7 = 1, ab = b^3a^3\rangle",I've been playing a little with group definitions to see what kind of things I can make up. I'm struggling to prove that this group is finite. Can anyone point me in the right direction?,I've been playing a little with group definitions to see what kind of things I can make up. I'm struggling to prove that this group is finite. Can anyone point me in the right direction?,,"['abstract-algebra', 'group-theory', 'finite-groups']"
48,Criterion for being a simple group,Criterion for being a simple group,,In this work it's written that A group $G$ is simple if and only if the diagonal subgroup of $G \times G$ is a   maximal subgroup. How can I prove it?,In this work it's written that A group $G$ is simple if and only if the diagonal subgroup of $G \times G$ is a   maximal subgroup. How can I prove it?,,"['abstract-algebra', 'group-theory', 'simple-groups']"
49,uniqueness of groups in an exact sequence,uniqueness of groups in an exact sequence,,"I was wondering how unique are the groups making up to an exact sequence. Suppose we have three groups $A, B, C$ such that the sequence $$ A \rightarrow B \rightarrow C $$ is exact. I wanted to know how many different groups $B$ are there for fixed groups $A$ and $C$. After some web search I've came to understand that this is something called a group extension problem and that the group $B$ need not be unique in general. Therefore my question is - what if we were to add some assumptions? Let's say that all the groups are abelian, and perhaps add some more elements to the sequence: $$A_1 \rightarrow A_2 \rightarrow ... \rightarrow A_{n-1} \rightarrow A_n $$ is then the group $A_{n-1}$ unique up to an isomorphism? What if we start with a 0? $$0 \rightarrow A_1 \rightarrow A_2 \rightarrow ... \rightarrow A_{n-1} \rightarrow A_n $$ Finally, what if we end and start with a 0? $$0 \rightarrow A_1 \rightarrow A_2 \rightarrow ... \rightarrow A_{n-1} \rightarrow A_n \rightarrow 0$$ In general - are there any sufficient conditions known to make a group appearing in an exact sequence unique? edit - forgot to mention - throughout the whole question I assume of course all the groups $A_i$ for $i \not= n-1$ fixed","I was wondering how unique are the groups making up to an exact sequence. Suppose we have three groups $A, B, C$ such that the sequence $$ A \rightarrow B \rightarrow C $$ is exact. I wanted to know how many different groups $B$ are there for fixed groups $A$ and $C$. After some web search I've came to understand that this is something called a group extension problem and that the group $B$ need not be unique in general. Therefore my question is - what if we were to add some assumptions? Let's say that all the groups are abelian, and perhaps add some more elements to the sequence: $$A_1 \rightarrow A_2 \rightarrow ... \rightarrow A_{n-1} \rightarrow A_n $$ is then the group $A_{n-1}$ unique up to an isomorphism? What if we start with a 0? $$0 \rightarrow A_1 \rightarrow A_2 \rightarrow ... \rightarrow A_{n-1} \rightarrow A_n $$ Finally, what if we end and start with a 0? $$0 \rightarrow A_1 \rightarrow A_2 \rightarrow ... \rightarrow A_{n-1} \rightarrow A_n \rightarrow 0$$ In general - are there any sufficient conditions known to make a group appearing in an exact sequence unique? edit - forgot to mention - throughout the whole question I assume of course all the groups $A_i$ for $i \not= n-1$ fixed",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'exact-sequence']"
50,A non-zero and non-invertible element in a noetherian integral domain has a decomposition into irreducible elements,A non-zero and non-invertible element in a noetherian integral domain has a decomposition into irreducible elements,,"Let $R$ be a noetherian integral domain. I want to show that any non-zero and non-invertible element $a$ can be written as a finite product of irreducible elements. my ideas: I should argue by contradiction and consider the set $M$ of the ideals generated by elements, which cannot be written as a product of irreducibles. Since R noetherian, we find a maximal element $(b)$ of $M$. Moreover we find a minimal overlying prime ideal $I$ of $(b)$. But now I'm stuck. I wanted to show that all minimal overlying prime ideals of $(b)$ are principal ideals, but that doesn't hold generally (I think).","Let $R$ be a noetherian integral domain. I want to show that any non-zero and non-invertible element $a$ can be written as a finite product of irreducible elements. my ideas: I should argue by contradiction and consider the set $M$ of the ideals generated by elements, which cannot be written as a product of irreducibles. Since R noetherian, we find a maximal element $(b)$ of $M$. Moreover we find a minimal overlying prime ideal $I$ of $(b)$. But now I'm stuck. I wanted to show that all minimal overlying prime ideals of $(b)$ are principal ideals, but that doesn't hold generally (I think).",,"['abstract-algebra', 'ring-theory', 'ideals', 'noetherian']"
51,gcd's in non-UFD rings,gcd's in non-UFD rings,,"In a UFD ring we have that for coprime $a,b \in R$, i.e. $(a,b)=1$: $$ a|cb \Rightarrow a|c $$ Does this property hold for non-UFD rings? I think not but do not recall a standard counter-example. NOTE: In a non-UFD ring the elements $a,b$ may not even have a gcd, but I am assuming here they do have one.","In a UFD ring we have that for coprime $a,b \in R$, i.e. $(a,b)=1$: $$ a|cb \Rightarrow a|c $$ Does this property hold for non-UFD rings? I think not but do not recall a standard counter-example. NOTE: In a non-UFD ring the elements $a,b$ may not even have a gcd, but I am assuming here they do have one.",,"['abstract-algebra', 'ring-theory', 'divisibility', 'unique-factorization-domains']"
52,Irreducibility of $p(x)=x^4-4x^2+8x+2$ over $\mathbb{Q}(\sqrt{-2})$- Dummit Foote Abstract algebra $9.4.10$,Irreducibility of  over - Dummit Foote Abstract algebra,p(x)=x^4-4x^2+8x+2 \mathbb{Q}(\sqrt{-2}) 9.4.10,"Question is : Prove that the polynomial $p(x)=x^4-4x^2+8x+2$ is irreducible over the quadratic field $F=\mathbb{Q}(\sqrt{-2})$. [Hint : first use the method of proposition $11$ for the U.F.D $\mathbb{Z}[\sqrt{-2}]$(cf.Exercise $8$, Section $8.1$) to show that if $\alpha \in \mathbb{Z}[\sqrt{-2}]$ is a root of $p(x)$ then $\alpha$ is a divisor of $2$ in $\mathbb{Z}[\sqrt{-2}]$ . Conclude that $\alpha$ must be $\pm 1,\pm \sqrt{-2}$ or $\pm 2$ and hence show that $p(x)$ has no linear factor over $F$. Show similarly that $p(x)$ is not the product of quadratics with coefficients in $F$.] What I have done so far is : Suppose $\alpha \in\mathbb{Z}[\sqrt{-2}]$ is a root of $p(x)=x^4-4x^2+8x+2$ we would then have : $p(\alpha)=\alpha^4-4\alpha^2+8\alpha+2=0\Rightarrow 2=\alpha(-\alpha^3+4\alpha-8)$ i.e., $\alpha$ is a divisor of $2$ in $\mathbb{Z}[\sqrt{-2}]$. so, I have used the method of proposition $11$ for the U.F.D $\mathbb{Z}[\sqrt{-2}]$(cf.Exercise $8$, Section $8.1$) to show that if $\alpha \in \mathbb{Z}[\sqrt{-2}]$ is a root of $p(x)$ then $\alpha$ is a divisor of $2$ in $\mathbb{Z}[\sqrt{-2}]$ I do not understand why does he mentioned that $\mathbb{Z}[\sqrt{-2}]$ is U.F.D and all... I do not use that at all... It is unnecessarily confusing me or i am unnecessarily getting confused.. hint is actually misleading me :( Now, I have to prove that $\alpha$ must be $\pm 1,\pm \sqrt{-2}$ or $\pm 2$ i.e., suppose I have $2=ab$ in $\mathbb{Z}[\sqrt{-2}]$ then, $N(2)=N(ab)\Rightarrow 4=N(a)N(b)$ i.e.,$N(a)=1\text{ or }2\text{ or } 4$ i.e., $p^2+2q^2=1\text{ or }2\text{ or } 4$ for $a=p+\sqrt{-2}q$ $p^2+2q^2=1\Rightarrow p=\pm 1 \Rightarrow a=\pm 1$ $p^2+2q^2=2\Rightarrow q=\pm 1\Rightarrow a=\pm\sqrt{-2}$ $p^2+2q^2=4\Rightarrow p=\pm 2\Rightarrow a=\pm 2$ Once I prove that those are the only divisors then I would consider : $p(1)=(1)^4-4(1)^2+8(1)+2\neq 0$ $p(-1)=(-1)^4-4(-1)^2+8(-1)+2\neq 0$ $p(\sqrt{-2})=(\sqrt{-2})^4-4(\sqrt{-2})^2+8(\sqrt{-2})+2\neq 0$ $p(-\sqrt{-2})=(-\sqrt{-2})^4-4(-\sqrt{-2})^2+8(-\sqrt{-2})+2\neq 0$ $p(2)=(2)^4-4(2)^2+8(2)+2\neq 0$ $p(-2)=(-2)^4-4(-2)^2+8(-2)+2\neq 0$ So, no divisor of $2$ is a root.. Thus $p(x)$ do not have a root in $\mathbb{Z}[\sqrt{-2}]$ suppose I have something like : $$x^4-4x^2+8x+2=(x^2+ax+b)(x^2+cx+d)=x^4+(a+c)x^3+(b+d+ac)x^2+(ad+bc)x+bd$$ But then, $bd=2\Rightarrow \text { b,d  are  a divisors of 2 in $\mathbb{Z}\sqrt{-2}$}$ But then we have seen that only divisors of $2$ in $\mathbb{Z}\sqrt{-2}$ are $\pm 1,\pm \sqrt{-2}$ or $\pm 2$ So, only possibilities are $x^4-4x^2+8x+2=(x^2+ax\pm 1)(x^2+cx\mp 2)$ $x^4-4x^2+8x+2=(x^2+ax\pm \sqrt{-2})(x^2+cx\mp \sqrt{-2})$ But these are not possible... This only tells that $p(x)$ is irreducible in $\mathbb{Z}[\sqrt{-2}]$ but then how do i show this is irreducible in $\mathbb{Q}(\sqrt{-2})$ I was expecting gauss lemma to help but it only works for integers and rationals... So, please help me to clear this.. Thank you... P.S : Proposition $11$ is Rational root theorem and Exercise $8$ is that ring of integers of $\mathbb{Q}(\sqrt{-2})$ is an Euclidean domain.","Question is : Prove that the polynomial $p(x)=x^4-4x^2+8x+2$ is irreducible over the quadratic field $F=\mathbb{Q}(\sqrt{-2})$. [Hint : first use the method of proposition $11$ for the U.F.D $\mathbb{Z}[\sqrt{-2}]$(cf.Exercise $8$, Section $8.1$) to show that if $\alpha \in \mathbb{Z}[\sqrt{-2}]$ is a root of $p(x)$ then $\alpha$ is a divisor of $2$ in $\mathbb{Z}[\sqrt{-2}]$ . Conclude that $\alpha$ must be $\pm 1,\pm \sqrt{-2}$ or $\pm 2$ and hence show that $p(x)$ has no linear factor over $F$. Show similarly that $p(x)$ is not the product of quadratics with coefficients in $F$.] What I have done so far is : Suppose $\alpha \in\mathbb{Z}[\sqrt{-2}]$ is a root of $p(x)=x^4-4x^2+8x+2$ we would then have : $p(\alpha)=\alpha^4-4\alpha^2+8\alpha+2=0\Rightarrow 2=\alpha(-\alpha^3+4\alpha-8)$ i.e., $\alpha$ is a divisor of $2$ in $\mathbb{Z}[\sqrt{-2}]$. so, I have used the method of proposition $11$ for the U.F.D $\mathbb{Z}[\sqrt{-2}]$(cf.Exercise $8$, Section $8.1$) to show that if $\alpha \in \mathbb{Z}[\sqrt{-2}]$ is a root of $p(x)$ then $\alpha$ is a divisor of $2$ in $\mathbb{Z}[\sqrt{-2}]$ I do not understand why does he mentioned that $\mathbb{Z}[\sqrt{-2}]$ is U.F.D and all... I do not use that at all... It is unnecessarily confusing me or i am unnecessarily getting confused.. hint is actually misleading me :( Now, I have to prove that $\alpha$ must be $\pm 1,\pm \sqrt{-2}$ or $\pm 2$ i.e., suppose I have $2=ab$ in $\mathbb{Z}[\sqrt{-2}]$ then, $N(2)=N(ab)\Rightarrow 4=N(a)N(b)$ i.e.,$N(a)=1\text{ or }2\text{ or } 4$ i.e., $p^2+2q^2=1\text{ or }2\text{ or } 4$ for $a=p+\sqrt{-2}q$ $p^2+2q^2=1\Rightarrow p=\pm 1 \Rightarrow a=\pm 1$ $p^2+2q^2=2\Rightarrow q=\pm 1\Rightarrow a=\pm\sqrt{-2}$ $p^2+2q^2=4\Rightarrow p=\pm 2\Rightarrow a=\pm 2$ Once I prove that those are the only divisors then I would consider : $p(1)=(1)^4-4(1)^2+8(1)+2\neq 0$ $p(-1)=(-1)^4-4(-1)^2+8(-1)+2\neq 0$ $p(\sqrt{-2})=(\sqrt{-2})^4-4(\sqrt{-2})^2+8(\sqrt{-2})+2\neq 0$ $p(-\sqrt{-2})=(-\sqrt{-2})^4-4(-\sqrt{-2})^2+8(-\sqrt{-2})+2\neq 0$ $p(2)=(2)^4-4(2)^2+8(2)+2\neq 0$ $p(-2)=(-2)^4-4(-2)^2+8(-2)+2\neq 0$ So, no divisor of $2$ is a root.. Thus $p(x)$ do not have a root in $\mathbb{Z}[\sqrt{-2}]$ suppose I have something like : $$x^4-4x^2+8x+2=(x^2+ax+b)(x^2+cx+d)=x^4+(a+c)x^3+(b+d+ac)x^2+(ad+bc)x+bd$$ But then, $bd=2\Rightarrow \text { b,d  are  a divisors of 2 in $\mathbb{Z}\sqrt{-2}$}$ But then we have seen that only divisors of $2$ in $\mathbb{Z}\sqrt{-2}$ are $\pm 1,\pm \sqrt{-2}$ or $\pm 2$ So, only possibilities are $x^4-4x^2+8x+2=(x^2+ax\pm 1)(x^2+cx\mp 2)$ $x^4-4x^2+8x+2=(x^2+ax\pm \sqrt{-2})(x^2+cx\mp \sqrt{-2})$ But these are not possible... This only tells that $p(x)$ is irreducible in $\mathbb{Z}[\sqrt{-2}]$ but then how do i show this is irreducible in $\mathbb{Q}(\sqrt{-2})$ I was expecting gauss lemma to help but it only works for integers and rationals... So, please help me to clear this.. Thank you... P.S : Proposition $11$ is Rational root theorem and Exercise $8$ is that ring of integers of $\mathbb{Q}(\sqrt{-2})$ is an Euclidean domain.",,['abstract-algebra']
53,Have action/predicate systems (or similar) been considered in the literature?,Have action/predicate systems (or similar) been considered in the literature?,,"Question. Has the following concept, or anything similar, been considered in the literature? Definition. An action/predicate system consists of sets $A$ (the actions) and $X$ (the predicates) such that the following hold. $A$ forms a monoid $X$ forms a Boolean lattice There is a monoid action $A \times X \rightarrow X$ denoted $ax$, such that for all $a \in A$ we have that the function $x \in X \mapsto ax \in X$ is an endomorphism of $X$. Intuitively, $ax$ means ""the predicate that returns $\mathtt{True}$ in precisely those states where $a$ brings about $x$."" There is a function $\sim \,: A \times A \rightarrow X$ subject to the following axioms. Intuitively, $a \sim b$ means ""the predicate that returns $\mathtt{True}$ in precisely those states where $a$ has the same effect as $b$."" Reflexivity.   $\forall a \in A : \top \leq (a \sim a)$ Symmetry.      $\forall a,b \in A : (a \sim b) \leq (b \sim a)$ Transitivity.  $\forall a,b,c \in A : (a \sim b) \wedge (b \sim c) \leq (a \sim c)$ Compatibility I. $$\forall a,b,c \in A : (a \sim b) \leq (ac \sim bc),\quad \forall a,b,c \in A : (a \sim b) \leq (ca \sim cb)$$ Compatibility II. $\forall a,b \in A,\;\forall x \in X : (a \sim b) \leq (ax \leftrightarrow bx)$ Reiteration of Question. Has this been considered in the literature? And if so, what is the correct terminology for such structures, and where can I learn more? Intuition. Firstly, we can think of actions as being ""commands"" in a programming language; they move the machine to a new state, depending on its current state. The unit $1 \in A$ is the command that does nothing; furthermore, if $a$ and $b$ are commands, then $ab$ is the result of first performing $a$, then $b$. Secondly, we can think of predicates as being... well, predicates; in the sense of returning true/false depending on the current state of the machine. Furthermore, if $a$ is an action and $x$ is a predicate, then $ax$ can be thought of as the predicate that returns $\mathtt{true}$ for precisely those states in which the action $a$, if performed, would bring about $x$. Thus we may read ""$ax""$ as ""$a$ brings about $x$."" Thirdly, the stipulation that the aforementioned action be a homomorphism of boolean algebras can be motivated by the observation that the following statements ought to be equivalent. We're in a state such that performing $a$ would bring about $x \vee y$. We're in a state such that either performing $a$ would bring about $x$, or performing $a$ would bring about $y$. This corresponds to the axiom $a(x \vee y) = ax \vee ay$. Similar linguistic reasoning can motivate the remainder of the homomorphism stipulation. Fourthly and finally, the function $\sim : A \times A \rightarrow X$ can be given the following interpretation. If $a,b \in A$ are actions, then $a \sim b$ is the predicate that returns $\mathtt{true}$ for precisely those states in which enacting $a$ would change the machine to the same state as would enacting $b$. The axioms associated with $\sim$ are motivated on this basis. A bit more motivation. Here's some basic stuff that we can express in this language. In any state where $x$ holds, we have that $a$ brings about $y$. $$x \leq ay$$ In general, the action $a$ brings about that $x$ implies $y$. $$\top \leq a(x \rightarrow y)$$ In any state where $x$ holds, $a$ has the same effect as $b$. $$x \leq (a \sim b)$$","Question. Has the following concept, or anything similar, been considered in the literature? Definition. An action/predicate system consists of sets $A$ (the actions) and $X$ (the predicates) such that the following hold. $A$ forms a monoid $X$ forms a Boolean lattice There is a monoid action $A \times X \rightarrow X$ denoted $ax$, such that for all $a \in A$ we have that the function $x \in X \mapsto ax \in X$ is an endomorphism of $X$. Intuitively, $ax$ means ""the predicate that returns $\mathtt{True}$ in precisely those states where $a$ brings about $x$."" There is a function $\sim \,: A \times A \rightarrow X$ subject to the following axioms. Intuitively, $a \sim b$ means ""the predicate that returns $\mathtt{True}$ in precisely those states where $a$ has the same effect as $b$."" Reflexivity.   $\forall a \in A : \top \leq (a \sim a)$ Symmetry.      $\forall a,b \in A : (a \sim b) \leq (b \sim a)$ Transitivity.  $\forall a,b,c \in A : (a \sim b) \wedge (b \sim c) \leq (a \sim c)$ Compatibility I. $$\forall a,b,c \in A : (a \sim b) \leq (ac \sim bc),\quad \forall a,b,c \in A : (a \sim b) \leq (ca \sim cb)$$ Compatibility II. $\forall a,b \in A,\;\forall x \in X : (a \sim b) \leq (ax \leftrightarrow bx)$ Reiteration of Question. Has this been considered in the literature? And if so, what is the correct terminology for such structures, and where can I learn more? Intuition. Firstly, we can think of actions as being ""commands"" in a programming language; they move the machine to a new state, depending on its current state. The unit $1 \in A$ is the command that does nothing; furthermore, if $a$ and $b$ are commands, then $ab$ is the result of first performing $a$, then $b$. Secondly, we can think of predicates as being... well, predicates; in the sense of returning true/false depending on the current state of the machine. Furthermore, if $a$ is an action and $x$ is a predicate, then $ax$ can be thought of as the predicate that returns $\mathtt{true}$ for precisely those states in which the action $a$, if performed, would bring about $x$. Thus we may read ""$ax""$ as ""$a$ brings about $x$."" Thirdly, the stipulation that the aforementioned action be a homomorphism of boolean algebras can be motivated by the observation that the following statements ought to be equivalent. We're in a state such that performing $a$ would bring about $x \vee y$. We're in a state such that either performing $a$ would bring about $x$, or performing $a$ would bring about $y$. This corresponds to the axiom $a(x \vee y) = ax \vee ay$. Similar linguistic reasoning can motivate the remainder of the homomorphism stipulation. Fourthly and finally, the function $\sim : A \times A \rightarrow X$ can be given the following interpretation. If $a,b \in A$ are actions, then $a \sim b$ is the predicate that returns $\mathtt{true}$ for precisely those states in which enacting $a$ would change the machine to the same state as would enacting $b$. The axioms associated with $\sim$ are motivated on this basis. A bit more motivation. Here's some basic stuff that we can express in this language. In any state where $x$ holds, we have that $a$ brings about $y$. $$x \leq ay$$ In general, the action $a$ brings about that $x$ implies $y$. $$\top \leq a(x \rightarrow y)$$ In any state where $x$ holds, $a$ has the same effect as $b$. $$x \leq (a \sim b)$$",,"['abstract-algebra', 'reference-request', 'terminology', 'computer-science', 'automata']"
54,"Can something like $\text{Hom}(V,K)$ be visualised?",Can something like  be visualised?,"\text{Hom}(V,K)","I have no trouble visualising vector spaces like $\Bbb R^3$ and (e.g.) a subspace of dimension $2$, which would just be a plane through the origin of a $3$-D space, but I'm having trouble visualising something like ""$W°$ is a subspace of $V^*$"" when you know that: $V$ is a vector space, $W$ is a subspace of $V$, $W°:=\{f\in V^*:W\subseteq \ker f\}$, $V^*=\operatorname{Hom}_{_K}(V,K)$. Even visualising $V^*$ is something I don't understand: it's a collection of functions; so how can it be a vector space? I have the proof, and I understand it, but it seems impossible to intuitively ""see"" things like that. Is it even possible?","I have no trouble visualising vector spaces like $\Bbb R^3$ and (e.g.) a subspace of dimension $2$, which would just be a plane through the origin of a $3$-D space, but I'm having trouble visualising something like ""$W°$ is a subspace of $V^*$"" when you know that: $V$ is a vector space, $W$ is a subspace of $V$, $W°:=\{f\in V^*:W\subseteq \ker f\}$, $V^*=\operatorname{Hom}_{_K}(V,K)$. Even visualising $V^*$ is something I don't understand: it's a collection of functions; so how can it be a vector space? I have the proof, and I understand it, but it seems impossible to intuitively ""see"" things like that. Is it even possible?",,"['abstract-algebra', 'vector-spaces', 'visualization', 'continuous-homomorphisms', 'geometric-interpretation']"
55,What is the order of the element $14+\langle8\rangle$ in the factor group $\mathbb Z_{24}/\langle8\rangle$. [closed],What is the order of the element  in the factor group . [closed],14+\langle8\rangle \mathbb Z_{24}/\langle8\rangle,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question What is the order of the element $14+\langle8\rangle$ in the factor group $\mathbb Z_{24}/\langle8\rangle$.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question What is the order of the element $14+\langle8\rangle$ in the factor group $\mathbb Z_{24}/\langle8\rangle$.",,['abstract-algebra']
56,So Gröbner bases lead to nothing new for the Beal polynomial $x^a + y^b - z^c$?,So Gröbner bases lead to nothing new for the Beal polynomial ?,x^a + y^b - z^c,"I'm learning about Gröbner bases.  And $f(x,y,z) = x^a + y^b - z^c$, is a single monic polynomial in any monomial ordering, $I = (f)$ has Gröbner basis $\{f\}$.  So there's nothing interesting to look at.  What am I missing? Thanks.","I'm learning about Gröbner bases.  And $f(x,y,z) = x^a + y^b - z^c$, is a single monic polynomial in any monomial ordering, $I = (f)$ has Gröbner basis $\{f\}$.  So there's nothing interesting to look at.  What am I missing? Thanks.",,"['abstract-algebra', 'commutative-algebra', 'groebner-generators']"
57,"Are systems of equations inherently ""more expressible"" than single equations?","Are systems of equations inherently ""more expressible"" than single equations?",,"The main, broader question is whether a solution set of a system of equations can ever be such that it can't be described by a single equation. To be more precise, suppose I have a system of $m$ equations in $n$ variables $f_1(x_1,x_2,...,x_n)=0,  f_2(x_1,x_2,...,x_n)=0, ... f_m(x_1,x_2,...,x_n)=0$ (The $f_i$s are assumed to be polynomials for the purpose of this post). If one restricts the variables and the values of the $f$s to the real number the answer to the above question is no. The equation $f_1(x_1,x_2,...,x_n)^2+f_2(x_1,x_2,...,x_n)^2+...+f_m(x_1,x_2,...,x_n)^2=0$ has the same solution set as the system of equations. How about if one restricts the values to complex numbers? Is there any known context where systems of equations are more expressible than single equations in the above sense?","The main, broader question is whether a solution set of a system of equations can ever be such that it can't be described by a single equation. To be more precise, suppose I have a system of $m$ equations in $n$ variables $f_1(x_1,x_2,...,x_n)=0,  f_2(x_1,x_2,...,x_n)=0, ... f_m(x_1,x_2,...,x_n)=0$ (The $f_i$s are assumed to be polynomials for the purpose of this post). If one restricts the variables and the values of the $f$s to the real number the answer to the above question is no. The equation $f_1(x_1,x_2,...,x_n)^2+f_2(x_1,x_2,...,x_n)^2+...+f_m(x_1,x_2,...,x_n)^2=0$ has the same solution set as the system of equations. How about if one restricts the values to complex numbers? Is there any known context where systems of equations are more expressible than single equations in the above sense?",,"['abstract-algebra', 'algebraic-geometry']"
58,"Let $L,F$ be extensions over the field $K$ and $L,F$ are contained in a common field (cont)",Let  be extensions over the field  and  are contained in a common field (cont),"L,F K L,F","Let $L,F$ be extensions over the field $K$ and $L,F$ are contained in a common field. Prove that $\left[LF:K\right]\leq\left[L:K\right]\left[F:K\right]$ Help me. Thanks a lot.","Let $L,F$ be extensions over the field $K$ and $L,F$ are contained in a common field. Prove that $\left[LF:K\right]\leq\left[L:K\right]\left[F:K\right]$ Help me. Thanks a lot.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
59,Question about the infinite products of formal power series,Question about the infinite products of formal power series,,"I need a proof for this: Let $(F_j)_{j\ge 0}$ be a sequence of formal power series. The infinite product $\prod_{j\geq0}(1+F_j(x))$ , where $F_j(0)=0$ , converges if and only if $\lim_{j\to\infty}\deg F_j(x)=\infty$ . In this case, the series $G_I(x)=\prod_{i\in I}F_i$ , with $|I|< \infty $ is summable and $\prod_{j\geq0}(1+F_j(x))= \lim_{n \to \infty} \prod_{j=0}^n (1+F_j(x)) = \sum_{|I| \leq 0}G_I(x)$ . I don't even know where to begin. Thanks in advance.","I need a proof for this: Let be a sequence of formal power series. The infinite product , where , converges if and only if . In this case, the series , with is summable and . I don't even know where to begin. Thanks in advance.",(F_j)_{j\ge 0} \prod_{j\geq0}(1+F_j(x)) F_j(0)=0 \lim_{j\to\infty}\deg F_j(x)=\infty G_I(x)=\prod_{i\in I}F_i |I|< \infty  \prod_{j\geq0}(1+F_j(x))= \lim_{n \to \infty} \prod_{j=0}^n (1+F_j(x)) = \sum_{|I| \leq 0}G_I(x),"['abstract-algebra', 'discrete-mathematics', 'power-series']"
60,Finite extension of perfect field is perfect,Finite extension of perfect field is perfect,,"Let $E/F$ be a finite extension and $F$ be a perfect field. Here, perfect field means $char(F)=0$ or $char(F)=p$ and $F^p=F$. How to prove $E$ is also perfect field? For $char(F)=0$ case, it's trivial, but for $char(F)=p$, no improvement at all... Give me some hints","Let $E/F$ be a finite extension and $F$ be a perfect field. Here, perfect field means $char(F)=0$ or $char(F)=p$ and $F^p=F$. How to prove $E$ is also perfect field? For $char(F)=0$ case, it's trivial, but for $char(F)=p$, no improvement at all... Give me some hints",,"['abstract-algebra', 'field-theory']"
61,"Prime ideals in $C[0,1]$ and ultrafilters",Prime ideals in  and ultrafilters,"C[0,1]","I'm looking for prime ideals in the ring $C[0,1]$ of continuous functions $[0,1]\longrightarrow \mathbb{R}$. I raised that question recently and got good answers but now I'd like to improve a bit the construction with ultrafilters. So, could you help me? Consider an ultrafilter $\mathcal{F}$ of subsets of $[0,1]$ such that for each $x\in [0,1]$ there exists $U\in \mathcal{F}$ such that $x\notin U$ (there exists such ultrafilter indeed). Now we build an ideal $I\lhd C[0,1]$ which consists of all continuous $f:[0,1]\longrightarrow\mathbb{R}$ such that $f^{-1}(0)\in \mathcal{F}$. It is easy to see that $I$ is an ideal indeed: Suppose $f,g\in I$, i.e. $f^{-1}(0),g^{-1}(0)\in \mathcal{F}$. Then $(f+g)^{-1}(0)$ contains $f^{-1}(0)\cap g^{-1}(0)$ which is in $\mathcal{F}$, so $f+g\in I$ also. Other properties can be proved similarly. Also it can be shown that $I$ is a prime ideal. Is it true that $I$ is never maximal? Each maximal ideal in $C[0,1]$ is $\mathrm{Ker}(ev_x)$ ($ev_x$ is an evaluation map), so we are to show that $\forall x\in [0,1]$ there exists $f\in I$ such that $f(x)\ne 0$. So, if we take $x\in [0,1]$ we can find $U\in \mathcal{F}$ such that $x\notin U$. However we cannot finish this reasoning by 'but there exists $f:[0,1]\longrightarrow \mathbb{R}$ such that $U=f^{-1}(0)$'. Well, could you improve this?","I'm looking for prime ideals in the ring $C[0,1]$ of continuous functions $[0,1]\longrightarrow \mathbb{R}$. I raised that question recently and got good answers but now I'd like to improve a bit the construction with ultrafilters. So, could you help me? Consider an ultrafilter $\mathcal{F}$ of subsets of $[0,1]$ such that for each $x\in [0,1]$ there exists $U\in \mathcal{F}$ such that $x\notin U$ (there exists such ultrafilter indeed). Now we build an ideal $I\lhd C[0,1]$ which consists of all continuous $f:[0,1]\longrightarrow\mathbb{R}$ such that $f^{-1}(0)\in \mathcal{F}$. It is easy to see that $I$ is an ideal indeed: Suppose $f,g\in I$, i.e. $f^{-1}(0),g^{-1}(0)\in \mathcal{F}$. Then $(f+g)^{-1}(0)$ contains $f^{-1}(0)\cap g^{-1}(0)$ which is in $\mathcal{F}$, so $f+g\in I$ also. Other properties can be proved similarly. Also it can be shown that $I$ is a prime ideal. Is it true that $I$ is never maximal? Each maximal ideal in $C[0,1]$ is $\mathrm{Ker}(ev_x)$ ($ev_x$ is an evaluation map), so we are to show that $\forall x\in [0,1]$ there exists $f\in I$ such that $f(x)\ne 0$. So, if we take $x\in [0,1]$ we can find $U\in \mathcal{F}$ such that $x\notin U$. However we cannot finish this reasoning by 'but there exists $f:[0,1]\longrightarrow \mathbb{R}$ such that $U=f^{-1}(0)$'. Well, could you improve this?",,['abstract-algebra']
62,Help with proof of Frobenius Theorem,Help with proof of Frobenius Theorem,,"Let $D$ be a finite dimensional associative division algebra over $\mathbb{R}$ with unit $1_{D}$. For all $a\in\mathbb{R}$ we identify the elements of the form $a\cdot1_{D}$ with $a$ itself and consider $\mathbb{R}$ to be a sub-ring of $D$. We will also idenitfy $1_{D}$ with $1\in\mathbb{R}.$ Theorem (Frobenius): Every finite dimensional associative division algebra over $\mathbb{R}$   is isomorphic to $\mathbb{R},  \mathbb{C}$  or $\mathbb{H}$   (the quaternions) Guidance: Given $x\in D$ show than the mapping $m_{x}:D\to D$ defined by $m_{x}\left(d\right)=x\cdot d$ is a linear transformation. Conclude using Cayley-Hamilton Theorem that $x$ is a zero of a polynomial with real coefficients. (Done) Use the Fundamental Theorem of Algebra to show $x$ is a zero a real polynomial of degree 1 or 2 (Done) Show that if each $x\in D$ is a zero of real polynomial of degree 1 then $D\cong\mathbb{R}$ (Done) Show than if the following claim is unture then there is an $x\in D$ satisfying the equation $x^{2}=-1$ (identifying $-1$ of the ring with the real $-1$ ) - (No clue) Show that if in the conditions of the previous claim $D$ is a vector space of dimension $2$ over $\mathbb{R}$ then $D\cong\mathbb{C}$ (Done) Show that if $\dim D>2$ then the collection $V=\left\{ x\in D\,|\, x^{2}\leq0\right\}$ is a sub-space of $D$ of codimension $1$. (When writing for $d\in D$ that $d\leq0$ we assume that $d$ is in $\mathbb{R}$ as a subring of $D$ ) - (No idea how to show the part about the dimension) Show that the mapping $B:V\to V$ given by $B\left(a,b\right)=-ab-ba$ is an inner product on $V$ (Done). Given an orthonormal basis of $V$ relative to $B$ denoted $\left\{ e_{1},....,e_{n}\right\}    (n\geq2)$ if $n=3$ then $D\cong \mathbb{H}$ and otherwise there is no such algebra $D$ for which the conditions of the theorem hold (No clue) I'd really appreciate help (or really a proof) for parts 4,6,8. Thanks in advance!","Let $D$ be a finite dimensional associative division algebra over $\mathbb{R}$ with unit $1_{D}$. For all $a\in\mathbb{R}$ we identify the elements of the form $a\cdot1_{D}$ with $a$ itself and consider $\mathbb{R}$ to be a sub-ring of $D$. We will also idenitfy $1_{D}$ with $1\in\mathbb{R}.$ Theorem (Frobenius): Every finite dimensional associative division algebra over $\mathbb{R}$   is isomorphic to $\mathbb{R},  \mathbb{C}$  or $\mathbb{H}$   (the quaternions) Guidance: Given $x\in D$ show than the mapping $m_{x}:D\to D$ defined by $m_{x}\left(d\right)=x\cdot d$ is a linear transformation. Conclude using Cayley-Hamilton Theorem that $x$ is a zero of a polynomial with real coefficients. (Done) Use the Fundamental Theorem of Algebra to show $x$ is a zero a real polynomial of degree 1 or 2 (Done) Show that if each $x\in D$ is a zero of real polynomial of degree 1 then $D\cong\mathbb{R}$ (Done) Show than if the following claim is unture then there is an $x\in D$ satisfying the equation $x^{2}=-1$ (identifying $-1$ of the ring with the real $-1$ ) - (No clue) Show that if in the conditions of the previous claim $D$ is a vector space of dimension $2$ over $\mathbb{R}$ then $D\cong\mathbb{C}$ (Done) Show that if $\dim D>2$ then the collection $V=\left\{ x\in D\,|\, x^{2}\leq0\right\}$ is a sub-space of $D$ of codimension $1$. (When writing for $d\in D$ that $d\leq0$ we assume that $d$ is in $\mathbb{R}$ as a subring of $D$ ) - (No idea how to show the part about the dimension) Show that the mapping $B:V\to V$ given by $B\left(a,b\right)=-ab-ba$ is an inner product on $V$ (Done). Given an orthonormal basis of $V$ relative to $B$ denoted $\left\{ e_{1},....,e_{n}\right\}    (n\geq2)$ if $n=3$ then $D\cong \mathbb{H}$ and otherwise there is no such algebra $D$ for which the conditions of the theorem hold (No clue) I'd really appreciate help (or really a proof) for parts 4,6,8. Thanks in advance!",,"['abstract-algebra', 'algebras']"
63,a principal ideal contains a monic polynomial of least degree n,a principal ideal contains a monic polynomial of least degree n,,"Q11.3.11 Artin Algebra 2nd Let $R$ be a ring, and let $I$ be an ideal of the polynomial ring $R[x]$.        Let $n$ be the lowest degree among nonzero elements of $I$.        Prove or disprove the following:       $I$ contains a monic polynomial of degree $n$ if and only if it       is a principal ideal. I've proved the first direction, now I want to prove: a principal ideal contains a monic polynomial of least degree $n$ Is it trivial? I kind of missing the starting point, and can not find any resources on this, any help? Thanks in advance~","Q11.3.11 Artin Algebra 2nd Let $R$ be a ring, and let $I$ be an ideal of the polynomial ring $R[x]$.        Let $n$ be the lowest degree among nonzero elements of $I$.        Prove or disprove the following:       $I$ contains a monic polynomial of degree $n$ if and only if it       is a principal ideal. I've proved the first direction, now I want to prove: a principal ideal contains a monic polynomial of least degree $n$ Is it trivial? I kind of missing the starting point, and can not find any resources on this, any help? Thanks in advance~",,"['abstract-algebra', 'polynomials', 'ring-theory', 'ideals']"
64,Is injectivity of algebras preserved by tensor products?,Is injectivity of algebras preserved by tensor products?,,"Suppose $R' \subset R$, $S'\subset S$ are inclusion of $k$-algebras. Does it hold that $R'\otimes_kS' \rightarrow R \otimes_k S$ is injective ? I know there're counterexamples for modules, but why does the algebra make things different? I found it used as a lemma in the Stacks project to prove Lemma 00I3 .","Suppose $R' \subset R$, $S'\subset S$ are inclusion of $k$-algebras. Does it hold that $R'\otimes_kS' \rightarrow R \otimes_k S$ is injective ? I know there're counterexamples for modules, but why does the algebra make things different? I found it used as a lemma in the Stacks project to prove Lemma 00I3 .",,['abstract-algebra']
65,Algorithm for Finitely Presented Torsion-Free Nilpotent Groups,Algorithm for Finitely Presented Torsion-Free Nilpotent Groups,,"I am studying some finitely presented, torsion-free and nilpotent groups $G$ and need to consider the following question: Let $H$ be a subgroup of $G$ and suppose that $H$ is generated by $h_1,\cdots,h_t$. Is there any algorithm finding a minimal generating set $A$ of $H$? By $A$ being a minimal generating set of $H$ I mean $A$ generates $H$ and any proper subset of $A$ does not generate $H$. Is the cardinality of $A$ unique? If yes, is there any algorithm (I mean one which is easier than the one in my first question, if the answer to my first question is ""yes"") finding the cardinality of $A$? I am aware that there is a paper studying algorithms of nilpotent groups: Some general algorithms. II. Nilpotent groups . But I am not an expert in computational group theory and I find the paper difficult to understand. Can any one help me by providing an Easy-to-Read Version of the algorithm, given that my groups are finitely presented, torsion-free and nilpotent?","I am studying some finitely presented, torsion-free and nilpotent groups $G$ and need to consider the following question: Let $H$ be a subgroup of $G$ and suppose that $H$ is generated by $h_1,\cdots,h_t$. Is there any algorithm finding a minimal generating set $A$ of $H$? By $A$ being a minimal generating set of $H$ I mean $A$ generates $H$ and any proper subset of $A$ does not generate $H$. Is the cardinality of $A$ unique? If yes, is there any algorithm (I mean one which is easier than the one in my first question, if the answer to my first question is ""yes"") finding the cardinality of $A$? I am aware that there is a paper studying algorithms of nilpotent groups: Some general algorithms. II. Nilpotent groups . But I am not an expert in computational group theory and I find the paper difficult to understand. Can any one help me by providing an Easy-to-Read Version of the algorithm, given that my groups are finitely presented, torsion-free and nilpotent?",,"['abstract-algebra', 'group-theory', 'computational-mathematics', 'gap', 'computational-algebra']"
66,Prove that a doubly transitive group is primitive.,Prove that a doubly transitive group is primitive.,,"A transitive permutation group on a set $A$ is called doubly transitive if for any (hence all) $a \in A$ the subgroup $G_a$ is transitive on the set $A - \{ a \}$ . (a) Prove that $S_n$ is doubly transitive on $\{1, 2, \dotsc, n\}$ for all $n ≥ 2$ . (b) Prove that a doubly transitive group is primitive. Deduce that $D_8$ is not doubly transitive in its action on the $4$ vertices of a square. ( Original image ) My Attempt: (a) $S_n$ is transitive on $\{1,2,\dotsc,n\}$ and for any $(i,j)\in G_a$ , $(i,j)i=j$ whence $G_a$ is transitive on $\{1,2,\dotsc,n\}-\{a\}$ . (b) Without loss of generality let $|A|\ge2$ . Case I: $|A|=2$ or $3$ then $|A-\{a\}|=1$ or $2$ whence the blocks became trivial. So $G$ become primitive in this case. Case II: $|A|\ge4$ then $|A-\{a\}|\ge3$ . $A-\{a\}$ can’t have a nontrivial block $B$ since for any $i\in \{A-a\}-B$ and $j\in B$ , $(i,j)\in G_a$ and $(i,j)(B)$ is neither equal or disjoint with $B$ . Hence the result. $D_8$ is not doubly transitive: Label the four vertices as $1,2,3,4$ consecutively. Consider the action of $G_4,$ the stabilizer of $4,$ on $\{1,2,3\}$ . Then $\{1,3\}$ is a nontrivial block since $G_4$ contains only the reflection about the line of symmetry passing through $4$ and the identity. My Questions: Is my attempt correct? Do we define ‘blocks’ (and hence ‘primitive’) only when $A$ is finite ? (Even though in this exercise I never used finiteness of $A$ this question comes into my mind from their definition as given in Dummit-Foote text: Let $G$ be a transitive permutation group on a finite set $A$ . A block is a nonempty subset $B$ of $A$ such that for all $\sigma \in G$ , either $\sigma(B) = B$ or $\sigma(B) \cap B = \emptyset$ (here $\sigma(B)$ is the set $\{ \sigma(b) \mid b \in B \}$ . (a) Prove that if $B$ is a block containing the element $a$ of $A$ , then the set $G_B$ defined by $G_B = \{ \sigma \in G \mid \sigma(B) = B \}$ is a subgroup of $G$ containing $G_a$ . (b) Show that if $B$ is a block and $\sigma_1(B), \sigma_2(B), \dotsc, \sigma_n(B)$ are all the distinct images of $B$ under the elements of $G$ , then these form a partition of $A$ . (c) A (transitive) group $G$ on a set $A$ is said to be primitive if the only blocks in $A$ are the trivial ones: the sets of size $1$ and $A$ itself. Show that $S_4$ is primitive on $A = \{1, 2, 3, 4\}$ . Show that $D_8$ is not primitive as a permutation group on the four vertices of a square. (Original image)","A transitive permutation group on a set is called doubly transitive if for any (hence all) the subgroup is transitive on the set . (a) Prove that is doubly transitive on for all . (b) Prove that a doubly transitive group is primitive. Deduce that is not doubly transitive in its action on the vertices of a square. ( Original image ) My Attempt: (a) is transitive on and for any , whence is transitive on . (b) Without loss of generality let . Case I: or then or whence the blocks became trivial. So become primitive in this case. Case II: then . can’t have a nontrivial block since for any and , and is neither equal or disjoint with . Hence the result. is not doubly transitive: Label the four vertices as consecutively. Consider the action of the stabilizer of on . Then is a nontrivial block since contains only the reflection about the line of symmetry passing through and the identity. My Questions: Is my attempt correct? Do we define ‘blocks’ (and hence ‘primitive’) only when is finite ? (Even though in this exercise I never used finiteness of this question comes into my mind from their definition as given in Dummit-Foote text: Let be a transitive permutation group on a finite set . A block is a nonempty subset of such that for all , either or (here is the set . (a) Prove that if is a block containing the element of , then the set defined by is a subgroup of containing . (b) Show that if is a block and are all the distinct images of under the elements of , then these form a partition of . (c) A (transitive) group on a set is said to be primitive if the only blocks in are the trivial ones: the sets of size and itself. Show that is primitive on . Show that is not primitive as a permutation group on the four vertices of a square. (Original image)","A a \in A G_a A - \{ a \} S_n \{1, 2, \dotsc, n\} n ≥ 2 D_8 4 S_n \{1,2,\dotsc,n\} (i,j)\in G_a (i,j)i=j G_a \{1,2,\dotsc,n\}-\{a\} |A|\ge2 |A|=2 3 |A-\{a\}|=1 2 G |A|\ge4 |A-\{a\}|\ge3 A-\{a\} B i\in \{A-a\}-B j\in B (i,j)\in G_a (i,j)(B) B D_8 1,2,3,4 G_4, 4, \{1,2,3\} \{1,3\} G_4 4 A A G A B A \sigma \in G \sigma(B) = B \sigma(B) \cap B = \emptyset \sigma(B) \{ \sigma(b) \mid b \in B \} B a A G_B G_B = \{ \sigma \in G \mid \sigma(B) = B \} G G_a B \sigma_1(B), \sigma_2(B), \dotsc, \sigma_n(B) B G A G A A 1 A S_4 A = \{1, 2, 3, 4\} D_8","['abstract-algebra', 'group-theory', 'group-actions']"
67,Left and Right Ideal Generated by Two Matrices.,Left and Right Ideal Generated by Two Matrices.,,"Let $R= {\rm Mat}_2(\Bbb R)$ be the ring (with $1$) of $2\times2$-matrices with entries in $\Bbb R$. Let $$M = \left\{\begin{pmatrix}1&0 \\0&0\end{pmatrix},\begin{pmatrix}0&1\\0&0\end{pmatrix}\right\},$$ i.e. a set of two matrices. What are the left and right ideal generated by $M$ in $R$? I tried to write my answer by it won't accept it. I don't know how to write Matrices (and their product) in the right format. Is this correct:  For left ideal: $$\begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}1&0\\0&0\end{pmatrix}=\begin{pmatrix}a&0\\c&0\end{pmatrix} \quad \text{ and } \quad \begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}0&1\\0&0\end{pmatrix}=\begin{pmatrix}0&a\\0&c\end{pmatrix}$$ hence $L = \begin{pmatrix}a&a\\c&c\end{pmatrix}$. For right ideal: $$\begin{pmatrix}1&0\\0&0\end{pmatrix}\begin{pmatrix}a&b\\c&d\end{pmatrix}=\begin{pmatrix}a&b\\0&0\end{pmatrix} \quad \text{ and } \quad \begin{pmatrix}0&1\\0&0\end{pmatrix}\begin{pmatrix}a&b\\c&d\end{pmatrix}=\begin{pmatrix}c&d\\0&0\end{pmatrix}$$ hence $R = \begin{pmatrix}a+c&b+d\\0&0\end{pmatrix}$.","Let $R= {\rm Mat}_2(\Bbb R)$ be the ring (with $1$) of $2\times2$-matrices with entries in $\Bbb R$. Let $$M = \left\{\begin{pmatrix}1&0 \\0&0\end{pmatrix},\begin{pmatrix}0&1\\0&0\end{pmatrix}\right\},$$ i.e. a set of two matrices. What are the left and right ideal generated by $M$ in $R$? I tried to write my answer by it won't accept it. I don't know how to write Matrices (and their product) in the right format. Is this correct:  For left ideal: $$\begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}1&0\\0&0\end{pmatrix}=\begin{pmatrix}a&0\\c&0\end{pmatrix} \quad \text{ and } \quad \begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}0&1\\0&0\end{pmatrix}=\begin{pmatrix}0&a\\0&c\end{pmatrix}$$ hence $L = \begin{pmatrix}a&a\\c&c\end{pmatrix}$. For right ideal: $$\begin{pmatrix}1&0\\0&0\end{pmatrix}\begin{pmatrix}a&b\\c&d\end{pmatrix}=\begin{pmatrix}a&b\\0&0\end{pmatrix} \quad \text{ and } \quad \begin{pmatrix}0&1\\0&0\end{pmatrix}\begin{pmatrix}a&b\\c&d\end{pmatrix}=\begin{pmatrix}c&d\\0&0\end{pmatrix}$$ hence $R = \begin{pmatrix}a+c&b+d\\0&0\end{pmatrix}$.",,"['abstract-algebra', 'ring-theory', 'ideals', 'noncommutative-algebra']"
68,Does this algebraic structure have a name?,Does this algebraic structure have a name?,,"Consider an ordered set $(X,\geq)$ with a binary operation $*$ that satisfies the following axioms: A1 (Closure) $\forall a,b\in X, a*b \in X$ A2 (Associativity) $\forall a,b,c\in X, (a*b)*c = a*(b*c)$ A3 (Identity) $\exists e\in X$ s.t. $\forall a\in X, a*e=a$ A4 (Commutativity) $\forall a,b\in X, a*b=b*a$ A5 (???) $\forall a,b\in X, a*b \geq a$ A6 (???) $\forall a,b\in X$ s.t.  $a\geq b, \exists c\in X$  s.t  $b*c=a$ So, it's a bit like an Abelian group with two modifications: It's an ordered set and the ""sum"" is always bigger than its components (A5) Invertability is replaced with a certain ""divisibility"" (A6) Axiom A6 seems like a ""natural"" replacement for invertability given A5.  (Note that A5 precludes the existence of an inverse) Do axioms A5 and A6 have standard names? Are they familiar from other structures? Does this overall structure have a name?","Consider an ordered set $(X,\geq)$ with a binary operation $*$ that satisfies the following axioms: A1 (Closure) $\forall a,b\in X, a*b \in X$ A2 (Associativity) $\forall a,b,c\in X, (a*b)*c = a*(b*c)$ A3 (Identity) $\exists e\in X$ s.t. $\forall a\in X, a*e=a$ A4 (Commutativity) $\forall a,b\in X, a*b=b*a$ A5 (???) $\forall a,b\in X, a*b \geq a$ A6 (???) $\forall a,b\in X$ s.t.  $a\geq b, \exists c\in X$  s.t  $b*c=a$ So, it's a bit like an Abelian group with two modifications: It's an ordered set and the ""sum"" is always bigger than its components (A5) Invertability is replaced with a certain ""divisibility"" (A6) Axiom A6 seems like a ""natural"" replacement for invertability given A5.  (Note that A5 precludes the existence of an inverse) Do axioms A5 and A6 have standard names? Are they familiar from other structures? Does this overall structure have a name?",,['abstract-algebra']
69,Counterexample to a lemma about modules,Counterexample to a lemma about modules,,"Let R be a ring with identity and not necessarily commutative. Let $M_1, M_2$ be left $R$-modules with submodules $S_1, S_2$ respectively such that $M_1/S_1 \cong M_2$ and $M_2/S_2 \cong M_1.$ Is it necessarily true that $M_1\cong M_2$ ? What if we also assume the modules are finitely generated? It is true in the vector space case when $R$ is a field, but I doubt it remains true generally. Can someone help me find a counterexample?","Let R be a ring with identity and not necessarily commutative. Let $M_1, M_2$ be left $R$-modules with submodules $S_1, S_2$ respectively such that $M_1/S_1 \cong M_2$ and $M_2/S_2 \cong M_1.$ Is it necessarily true that $M_1\cong M_2$ ? What if we also assume the modules are finitely generated? It is true in the vector space case when $R$ is a field, but I doubt it remains true generally. Can someone help me find a counterexample?",,"['abstract-algebra', 'modules', 'examples-counterexamples']"
70,Lagrange's theorem (Group Theory) applications,Lagrange's theorem (Group Theory) applications,,How can we prove that every finite group $G$ has a generating set of size not more than $\log_2|G|$? Can someone give me an hint.,How can we prove that every finite group $G$ has a generating set of size not more than $\log_2|G|$? Can someone give me an hint.,,['abstract-algebra']
71,Left Invertible Elements of a monoid,Left Invertible Elements of a monoid,,"It is true in general that the set of all invertible elements of a Monoid form a subgroup. The proof is trivial. However, after some thought, I feel that if we restrict invertible to left or right invertible only, then it does not form a group. It seems so because I cannot imagine a way to prove otherwise. I am looking for examples of Monoids whose left invertible elements do not form a subgroup or else proof that it does form a group.","It is true in general that the set of all invertible elements of a Monoid form a subgroup. The proof is trivial. However, after some thought, I feel that if we restrict invertible to left or right invertible only, then it does not form a group. It seems so because I cannot imagine a way to prove otherwise. I am looking for examples of Monoids whose left invertible elements do not form a subgroup or else proof that it does form a group.",,"['abstract-algebra', 'group-theory', 'monoid']"
72,Principal Ideal Groupring,Principal Ideal Groupring,,"Let $R[G]$ be a groupring (not necessarily commutative). Under which conditions on $R$ and $G$ is $R[G]$ a Principal Ideal Ring, respectively a Principal Ideal Domain (not commutative either)?","Let $R[G]$ be a groupring (not necessarily commutative). Under which conditions on $R$ and $G$ is $R[G]$ a Principal Ideal Ring, respectively a Principal Ideal Domain (not commutative either)?",,"['abstract-algebra', 'ring-theory']"
73,Extension of residue fields and algebraic independence,Extension of residue fields and algebraic independence,,"Let $A$ be a Noetherian integral domain, $B$ a ring extension of $A$ that is an integral domain, $P \in \operatorname{Spec} B, \, p = P \cap A$. Denote by $\kappa(p),\ \kappa(P)$ the residue fields of the two prime ideals. Then we see that there is a field extension $\kappa(p) \hookrightarrow \kappa(P)$. Let $t$ be a non-negative integer such that $t \le {\rm tr}.\deg_{\kappa(p)} \kappa(P)$. Matsumura in his Commutative Ring Theory, proof of Theorem 15.5, says ""let $c_1,\dots,c_t \in B$ such that their images modulo $P$ are algebraically independent over $A/p$."" Question: Why would such elements exist? (Edited) Remark: Matsumura wants to prove that $\operatorname{ht}(P)+\operatorname{tr.deg}_{\kappa(p)} \kappa(P) \le \operatorname{ht}(p)+ \operatorname{tr.deg}_A B$ and he starts by proving that we can assume that $B$ is a finitely generated $A$-algebra. Specifically, he is showing that we can construct a subring $C$ of $B$ that is a finitely-generated $A$-algebra, and that if the theorem is true for $C$, then it is true of $B$. My question relates to his argument of ""why we can assume that"". Consequently, in answering my question, we can not make the assumption that $B$ is a finitely generated $A$-algebra.","Let $A$ be a Noetherian integral domain, $B$ a ring extension of $A$ that is an integral domain, $P \in \operatorname{Spec} B, \, p = P \cap A$. Denote by $\kappa(p),\ \kappa(P)$ the residue fields of the two prime ideals. Then we see that there is a field extension $\kappa(p) \hookrightarrow \kappa(P)$. Let $t$ be a non-negative integer such that $t \le {\rm tr}.\deg_{\kappa(p)} \kappa(P)$. Matsumura in his Commutative Ring Theory, proof of Theorem 15.5, says ""let $c_1,\dots,c_t \in B$ such that their images modulo $P$ are algebraically independent over $A/p$."" Question: Why would such elements exist? (Edited) Remark: Matsumura wants to prove that $\operatorname{ht}(P)+\operatorname{tr.deg}_{\kappa(p)} \kappa(P) \le \operatorname{ht}(p)+ \operatorname{tr.deg}_A B$ and he starts by proving that we can assume that $B$ is a finitely generated $A$-algebra. Specifically, he is showing that we can construct a subring $C$ of $B$ that is a finitely-generated $A$-algebra, and that if the theorem is true for $C$, then it is true of $B$. My question relates to his argument of ""why we can assume that"". Consequently, in answering my question, we can not make the assumption that $B$ is a finitely generated $A$-algebra.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'field-theory']"
74,characteristic prime or zero,characteristic prime or zero,,"Let $R$ be a ring with $1$ and without zero-divisors. I have to show that the characteristic of $R$ is a prime or zero. This is my attempt: This is equivalent to finding the kernel of the homomorphism $f\colon \mathbb{Z}\rightarrow R$ which has the form $n\mathbb{Z}$. There are two cases. Suppose $f$ is injective, then only $f(0)=0$. Suppose now that $f$ is not injective, thus there exist $m,n\in \mathbb{Z}$ such that $f(m)=f(n)$. This implies $f(m-n)=0$ thus $m-n$ is in the kernel and so is every multiple of $m-n$ thus $(m-n)\mathbb{Z}$ is the kernel (I think this is not 100% correct). Suppose now that $m-n$ is not a prime. Then there exist $a,b\in \mathbb{Z}$ such that $m-n=ab$. $f(a)\neq 0\neq f(b)$ because then $a\mathbb{Z}$ or $b\mathbb{Z}$ would be the kernel because $a<m-n$ and also $b<m-n$. Then $0=f(ab)=f(a)f(b)$. This contradicts the fact that there are no zero-divisors. Is this proof correct? If not what is wrong? Thanks.","Let $R$ be a ring with $1$ and without zero-divisors. I have to show that the characteristic of $R$ is a prime or zero. This is my attempt: This is equivalent to finding the kernel of the homomorphism $f\colon \mathbb{Z}\rightarrow R$ which has the form $n\mathbb{Z}$. There are two cases. Suppose $f$ is injective, then only $f(0)=0$. Suppose now that $f$ is not injective, thus there exist $m,n\in \mathbb{Z}$ such that $f(m)=f(n)$. This implies $f(m-n)=0$ thus $m-n$ is in the kernel and so is every multiple of $m-n$ thus $(m-n)\mathbb{Z}$ is the kernel (I think this is not 100% correct). Suppose now that $m-n$ is not a prime. Then there exist $a,b\in \mathbb{Z}$ such that $m-n=ab$. $f(a)\neq 0\neq f(b)$ because then $a\mathbb{Z}$ or $b\mathbb{Z}$ would be the kernel because $a<m-n$ and also $b<m-n$. Then $0=f(ab)=f(a)f(b)$. This contradicts the fact that there are no zero-divisors. Is this proof correct? If not what is wrong? Thanks.",,"['abstract-algebra', 'ring-theory']"
75,Isomorphisms of $\mathbb P^1$,Isomorphisms of,\mathbb P^1,"Prove that every iso morphism of $\mathbb P^1$ (over an algebrically closed field $\mathbb K$) is of the form    $$ \phi(x_0: x_1) = (ax_0+bx_1 : cx_0 + dx_1) $$   where $\begin{pmatrix} a & b \\c & d\end{pmatrix} \in GL(2, \mathbb K).$ There are some hints; I show you what I've done. 1 . Show that the action of $PGL(2, \mathbb K)$ on $\mathbb P^1$ is transitive. Well, I think this is quite intuitive, but I can't find a rigorous proof. Let us pick two distinct points $x=(x_0:x_1)$ and $y=(y_0 : y_1)$. I want to find an invertible matrix $A$ s.t. $Ax = y$. It is easy to see that this system (the unknowns are the entries of $A$) has always solutions (and maybe one can find one solution s.t. $ad-bc \ne 0$). My question is: is there an easier way to see that this action is transitive? Is it enough to say ""It's trivially true in the affine case so it must be true in the projective space as well""? 2 . Using the fact that every isomorphism of $\mathbb A^1$ is of the form $t \mapsto at+b$ (for some $a \ne 0$), prove the claim for morphisms s.t. $\phi(0:1)=(0:1)$. Suppose $\phi$ is a morphism s.t. $\phi(0:1)=(0:1)$. If we restrict $\phi\vert_{U_0}$ we obtain a morphism of $U_0 \simeq \mathbb A^1$, hence it must of the form  $$ \phi(1:x) = (1:ax+b)  $$ i.e.  $$ \phi(x_0:x_1) = (x_0:ax_0+bx_1)  $$ Is this correct? Why shall I assume that $(0:1) \mapsto (0:1)$? 3. Conclude. I don't see how to conclude at this point, I'm puzzled. Could you please help me? Thanks.","Prove that every iso morphism of $\mathbb P^1$ (over an algebrically closed field $\mathbb K$) is of the form    $$ \phi(x_0: x_1) = (ax_0+bx_1 : cx_0 + dx_1) $$   where $\begin{pmatrix} a & b \\c & d\end{pmatrix} \in GL(2, \mathbb K).$ There are some hints; I show you what I've done. 1 . Show that the action of $PGL(2, \mathbb K)$ on $\mathbb P^1$ is transitive. Well, I think this is quite intuitive, but I can't find a rigorous proof. Let us pick two distinct points $x=(x_0:x_1)$ and $y=(y_0 : y_1)$. I want to find an invertible matrix $A$ s.t. $Ax = y$. It is easy to see that this system (the unknowns are the entries of $A$) has always solutions (and maybe one can find one solution s.t. $ad-bc \ne 0$). My question is: is there an easier way to see that this action is transitive? Is it enough to say ""It's trivially true in the affine case so it must be true in the projective space as well""? 2 . Using the fact that every isomorphism of $\mathbb A^1$ is of the form $t \mapsto at+b$ (for some $a \ne 0$), prove the claim for morphisms s.t. $\phi(0:1)=(0:1)$. Suppose $\phi$ is a morphism s.t. $\phi(0:1)=(0:1)$. If we restrict $\phi\vert_{U_0}$ we obtain a morphism of $U_0 \simeq \mathbb A^1$, hence it must of the form  $$ \phi(1:x) = (1:ax+b)  $$ i.e.  $$ \phi(x_0:x_1) = (x_0:ax_0+bx_1)  $$ Is this correct? Why shall I assume that $(0:1) \mapsto (0:1)$? 3. Conclude. I don't see how to conclude at this point, I'm puzzled. Could you please help me? Thanks.",,"['algebraic-geometry', 'projective-geometry', 'abstract-algebra']"
76,which of the following is/are algebraic over rationals,which of the following is/are algebraic over rationals,,"which of the following is/are true? $\sin 7^\circ$ is an algebraic over $\mathbb{Q}$ $\sin^{-1}(1)$ is algebraic over $\mathbb{Q}$ $\cos (\pi/7)$ is algebraic over $\mathbb{Q}$ $\sqrt{2}+\sqrt{\pi} $ is algebraic over $\mathbb{Q}(\pi)$ an algebraic number is a number that is a root of a non-zero polynomial in one variable with rational coefficients, I am perfectly sure that option $1$, $3$ are  algebraic number. could any one help me to find out others option?","which of the following is/are true? $\sin 7^\circ$ is an algebraic over $\mathbb{Q}$ $\sin^{-1}(1)$ is algebraic over $\mathbb{Q}$ $\cos (\pi/7)$ is algebraic over $\mathbb{Q}$ $\sqrt{2}+\sqrt{\pi} $ is algebraic over $\mathbb{Q}(\pi)$ an algebraic number is a number that is a root of a non-zero polynomial in one variable with rational coefficients, I am perfectly sure that option $1$, $3$ are  algebraic number. could any one help me to find out others option?",,"['abstract-algebra', 'field-theory']"
77,What are the main relationships between exclusive OR / logical biconditional?,What are the main relationships between exclusive OR / logical biconditional?,,"Let $\mathbb{B} = \{0,1\}$ denote the Boolean domain. Its well known that both exclusive OR and logical biconditional make $\mathbb{B}$ into an Abelian group (in the former case the identity is $0$, in the latter the identity is $1$). Furthermore, I was playing around and noticed that these two operations 'associate' over each other, in the sense that $(x \leftrightarrow y) \oplus z$ is equivalent to $x \leftrightarrow (y \oplus z).$ This is easily seen via the following chain of equivalences. $(x \leftrightarrow y) \oplus z$ $(x \leftrightarrow y) \leftrightarrow \neg z$ $x \leftrightarrow (y \leftrightarrow \neg z)$ $x \leftrightarrow (y \oplus z)$ Anyway, my question is, what are the major connections between the operations of negation, biconditional, and exclusive OR? Furthermore, does $(\mathbb{B},\leftrightarrow,\oplus,\neg)$ form any familiar structure? I know that the binary operations don't distribute over each other, so its not a ring.","Let $\mathbb{B} = \{0,1\}$ denote the Boolean domain. Its well known that both exclusive OR and logical biconditional make $\mathbb{B}$ into an Abelian group (in the former case the identity is $0$, in the latter the identity is $1$). Furthermore, I was playing around and noticed that these two operations 'associate' over each other, in the sense that $(x \leftrightarrow y) \oplus z$ is equivalent to $x \leftrightarrow (y \oplus z).$ This is easily seen via the following chain of equivalences. $(x \leftrightarrow y) \oplus z$ $(x \leftrightarrow y) \leftrightarrow \neg z$ $x \leftrightarrow (y \leftrightarrow \neg z)$ $x \leftrightarrow (y \oplus z)$ Anyway, my question is, what are the major connections between the operations of negation, biconditional, and exclusive OR? Furthermore, does $(\mathbb{B},\leftrightarrow,\oplus,\neg)$ form any familiar structure? I know that the binary operations don't distribute over each other, so its not a ring.",,"['abstract-algebra', 'logic', 'abelian-groups']"
78,Degree of splitting field extensions,Degree of splitting field extensions,,"The problem states: Let $f (x) = x^3+px+q$ be an irreducible cubic polynomial with rational coefficients   and let $K$ be the splitting field of $ f(x) $ over $\mathbb{Q}$. Prove that $ [K : \mathbb{Q}] = 3 $ if and only if $ -4p^3 - 27q^2 $ is a square in $\mathbb{Q}$. Here is how far I've come on the problem. Since $f$ is cubic and the degree of the extension is $3$, then non of the roots are in $\mathbb{Q}$ hence they are in $K$. Now, I am having trouble connecting this piece of information with the given value being a square in $\mathbb{Q}$. Thanks in advance.","The problem states: Let $f (x) = x^3+px+q$ be an irreducible cubic polynomial with rational coefficients   and let $K$ be the splitting field of $ f(x) $ over $\mathbb{Q}$. Prove that $ [K : \mathbb{Q}] = 3 $ if and only if $ -4p^3 - 27q^2 $ is a square in $\mathbb{Q}$. Here is how far I've come on the problem. Since $f$ is cubic and the degree of the extension is $3$, then non of the roots are in $\mathbb{Q}$ hence they are in $K$. Now, I am having trouble connecting this piece of information with the given value being a square in $\mathbb{Q}$. Thanks in advance.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
79,"Show that If k is odd, then $\Bbb{Q}_{4k}$ is isomorphic to $\Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_4$ for some $\alpha$","Show that If k is odd, then  is isomorphic to  for some",\Bbb{Q}_{4k} \Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_4 \alpha,"Show that if k is odd, then $\Bbb{Q}_{4k}$ is isomorphic to $\Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_4$ for some $\alpha: \Bbb{Z}_4 \rightarrow Aut(\Bbb{Z}_k)$ . Calculate $\alpha$ explicitly. We know that $\Bbb{Q}_{4k} = \{ b^k_{2n}, b^k_{2n}a | 0 \leq k < 2n \}$ , and that everything outside of the cyclic group $\langle b \rangle$ is of order 4. What confuses me is that we only have one cyclic group in $\Bbb{Q}$ , right? However, in order to write it of the form $\Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_4$ , we need to find a normal cyclic group of order k in $\Bbb{Q}_{4k}$ , and I can't really see that. For example, in the group $\Bbb{Q}_{12} = \{e, b, b^2, b^3, b^4, b^5, a, ab, ab^2, ab^3, ab^4, ab^5\}$ , we only have $\langle b \rangle$ as the cyclic group. I cannot see any normal cyclic group of order 3 here. For the second part of the problem, suppose we accept the fact that $\Bbb{Q}_{4k} = \Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_4$ for some $\alpha: \Bbb{Z}_4 \rightarrow Aut(\Bbb{Z}_k)$ . There is a theorem in the textbook that states: Corollary Let $\bar{m}$ have exponent k in $\Bbb{Z}^×_n$ , and let $α : \Bbb{Z}_k → \Bbb{Z}^×_n$ be the homomorphism that takes the generator to $\bar{m}$ . Then writing $\Bbb{Z}_n = \langle b \rangle$ , $\Bbb{Z}_k = \langle a \rangle$ , and identifying $\Bbb{Z}^×_n$ with $Aut(\Bbb{Z}_n)$ , we obtain $$\Bbb{Z}_n \rtimes_{α} \Bbb{Z}_k = \{b^ia^j | 0 ≤ i < n, 0 ≤ j < k\},$$ where b has order n, a has order k, and the multiplication is given by $$b^ia^jb^{i'}a^{j'} = b^{i+m^ji'}a^{j+j'}.$$ Moreover, the nk elements $\{b^ia^j | 0 \leq i < n, 0 \leq j < k\}.$ Since we know that $aba^{-1}=b^{-1}$ in quaternionics, we need to find an $\bar{m}$ such that $b^0aba^{-1}= b^{0+m}a^{-1+1} = b^{-1}$ . So $\bar{m} = \bar{-1}$ , and $\alpha$ must be send the generator to $\bar{-1}$ . I guess this is what the question is asking for when it tells us the calculate $\alpha$ ""explicitly"". Is that correct? However, I cannot say that until I prove that $\Bbb{Q}_{4k} \cong \Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_{4}$ , so I was wondering if anybody could help me with that. Thank you in advance","Show that if k is odd, then is isomorphic to for some . Calculate explicitly. We know that , and that everything outside of the cyclic group is of order 4. What confuses me is that we only have one cyclic group in , right? However, in order to write it of the form , we need to find a normal cyclic group of order k in , and I can't really see that. For example, in the group , we only have as the cyclic group. I cannot see any normal cyclic group of order 3 here. For the second part of the problem, suppose we accept the fact that for some . There is a theorem in the textbook that states: Corollary Let have exponent k in , and let be the homomorphism that takes the generator to . Then writing , , and identifying with , we obtain where b has order n, a has order k, and the multiplication is given by Moreover, the nk elements Since we know that in quaternionics, we need to find an such that . So , and must be send the generator to . I guess this is what the question is asking for when it tells us the calculate ""explicitly"". Is that correct? However, I cannot say that until I prove that , so I was wondering if anybody could help me with that. Thank you in advance","\Bbb{Q}_{4k} \Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_4 \alpha: \Bbb{Z}_4 \rightarrow Aut(\Bbb{Z}_k) \alpha \Bbb{Q}_{4k} = \{ b^k_{2n}, b^k_{2n}a | 0 \leq k < 2n \} \langle b \rangle \Bbb{Q} \Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_4 \Bbb{Q}_{4k} \Bbb{Q}_{12} = \{e, b, b^2, b^3, b^4, b^5, a, ab, ab^2, ab^3, ab^4, ab^5\} \langle b \rangle \Bbb{Q}_{4k} = \Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_4 \alpha: \Bbb{Z}_4 \rightarrow Aut(\Bbb{Z}_k) \bar{m} \Bbb{Z}^×_n α : \Bbb{Z}_k → \Bbb{Z}^×_n \bar{m} \Bbb{Z}_n = \langle b \rangle \Bbb{Z}_k = \langle a \rangle \Bbb{Z}^×_n Aut(\Bbb{Z}_n) \Bbb{Z}_n \rtimes_{α} \Bbb{Z}_k = \{b^ia^j | 0 ≤ i < n, 0 ≤ j < k\}, b^ia^jb^{i'}a^{j'} = b^{i+m^ji'}a^{j+j'}. \{b^ia^j | 0 \leq i < n, 0 \leq j < k\}. aba^{-1}=b^{-1} \bar{m} b^0aba^{-1}= b^{0+m}a^{-1+1} = b^{-1} \bar{m} = \bar{-1} \alpha \bar{-1} \alpha \Bbb{Q}_{4k} \cong \Bbb{Z}_k \rtimes_{\alpha} \Bbb{Z}_{4}",['abstract-algebra']
80,which of the following statements are true in ring theory,which of the following statements are true in ring theory,,which of the following statements are true in ring theory? (a) Let $R$ is a commutative ring with unity and $I$ be an ideal. Then $R/I$ is an integral domain. (b) If $R$ is a commutative ring with unity the units of $R[x]$ are the units in $R$. (a) I think it is not true as $R/I$ is an integral domain iff I is an prime ideal but I have no counter example. (b) I have no idea. can I get some help.Thanks for your cooperation.,which of the following statements are true in ring theory? (a) Let $R$ is a commutative ring with unity and $I$ be an ideal. Then $R/I$ is an integral domain. (b) If $R$ is a commutative ring with unity the units of $R[x]$ are the units in $R$. (a) I think it is not true as $R/I$ is an integral domain iff I is an prime ideal but I have no counter example. (b) I have no idea. can I get some help.Thanks for your cooperation.,,['abstract-algebra']
81,Submodules of an $R$-module where $R$ is the set of $n\times n$ upper triangular matrices,Submodules of an -module where  is the set of  upper triangular matrices,R R n\times n,"Let $R$ be the ring of $n\times n$ upper triangular matrices with coefficients in a field $K$. Let $V$ be the $R$-module consisting of all $1\times n$ matrices with coefficients in $K$. Define $$V_r = \{(x_1,\dots,x_n) \in V\mid x_i = 0 \text{ for all } i \text{ less than or equal to } r\}.$$ How can I show that $V_0, V_1,\dots,V_n$ are the only $R$-submodules of $V$?","Let $R$ be the ring of $n\times n$ upper triangular matrices with coefficients in a field $K$. Let $V$ be the $R$-module consisting of all $1\times n$ matrices with coefficients in $K$. Define $$V_r = \{(x_1,\dots,x_n) \in V\mid x_i = 0 \text{ for all } i \text{ less than or equal to } r\}.$$ How can I show that $V_0, V_1,\dots,V_n$ are the only $R$-submodules of $V$?",,"['abstract-algebra', 'modules']"
82,How to show polynomial is irreducible in extension field of rationals?,How to show polynomial is irreducible in extension field of rationals?,,"How would one show this? is there any test? say $x^3 - 2x - 5$ over $\mathbb{Q}[\sqrt{2}]$ This is just a made-up example, but I'm interested in the general process and how it differs from showing irreducible over $\mathbb{Q}$.","How would one show this? is there any test? say $x^3 - 2x - 5$ over $\mathbb{Q}[\sqrt{2}]$ This is just a made-up example, but I'm interested in the general process and how it differs from showing irreducible over $\mathbb{Q}$.",,"['abstract-algebra', 'polynomials']"
83,"If $\phi:G\to\bar{G}$ is an isomorphism and if $H$ is a normal subgroup of $G$, then $\phi(H)$ is a normal subgroup of $\bar{G}$.","If  is an isomorphism and if  is a normal subgroup of , then  is a normal subgroup of .",\phi:G\to\bar{G} H G \phi(H) \bar{G},"If $\phi:G\to\bar{G}$ is an isomorphism and if $H$ is a normal subgroup of $G$, then $\phi(H)$ is a normal subgroup of $\bar{G}$. I am struggling with getting started with the problem. I know that we want to show that for some $b \in \bar{G}$, then $b\phi(H)b^{-1} \in \phi(H)$ but not sure how to do it. Other approaches are also welcome.","If $\phi:G\to\bar{G}$ is an isomorphism and if $H$ is a normal subgroup of $G$, then $\phi(H)$ is a normal subgroup of $\bar{G}$. I am struggling with getting started with the problem. I know that we want to show that for some $b \in \bar{G}$, then $b\phi(H)b^{-1} \in \phi(H)$ but not sure how to do it. Other approaches are also welcome.",,"['group-theory', 'abstract-algebra']"
84,How to find the splitting field and Galois group of $x^6 -4x^3 +1$?,How to find the splitting field and Galois group of ?,x^6 -4x^3 +1,"I am trying to find the splitting field $L$ of the $x^6 -4x^3 +1$ over $\mathbb{Q}$, and its Galois group. Here are some things I have figured out. I did the usual trick of solving for $x^3 = 2\pm \sqrt{3}$, which shows that $i, \sqrt{3}$ are both in the Galois group.  I know that $\mathrm{Gal}(L/\mathbb{Q})$ is non-abelian and I tried reducing mod primes to see what cycles might appear. For example, $$x^6 -4x^3 +1 \equiv (x-6)(x^2+6x+3)(x-2)(x^2+2x+4)\bmod 11,$$ which shows that the Galois group has a $4$-cycle. But generally I am stuck beyond these things and it would be great if someone could at least tell me of a simple way of calculating the degree of the splitting field. Edit:  Thank you for your help Steve and Hurkyl! After reading your solutions, I think I figured out a concrete way to verifying that the Galois group is $D_{12}$ once we know that the group has order 12. Let $\alpha = \sqrt[3]{2+\sqrt{3}}, \beta =  \omega \sqrt[3]{2+\sqrt{3}},  \gamma = \omega^2 \sqrt[3]{2+\sqrt{3}}$. We know that the roots come in pairs $\alpha, \alpha^{-1}, \beta, \beta^{-1}, \gamma, \gamma^{-1}$ and the Galois group takes pairs to pairs. Also,  $\alpha \beta \gamma =1$ and so the triple $\alpha, \beta, \gamma$  either goes to the same triple $\alpha, \beta, \gamma$ or to the triple $\alpha^{-1}, \beta^{-1}, \gamma^{-1}$.  Now if we label the vertices of a hexagon with the roots so that the pairs of roots are opposite vertices, then we see that the Galois group must be a symmetry of the hexagon (here must use both the relations that the pairs of roots go to pairs and that triples go to triples). Thus we see that the Galois group is contained in $D_{12}$ under this identification. Since the order of the group is $12$, the group must be $D_{12}$.","I am trying to find the splitting field $L$ of the $x^6 -4x^3 +1$ over $\mathbb{Q}$, and its Galois group. Here are some things I have figured out. I did the usual trick of solving for $x^3 = 2\pm \sqrt{3}$, which shows that $i, \sqrt{3}$ are both in the Galois group.  I know that $\mathrm{Gal}(L/\mathbb{Q})$ is non-abelian and I tried reducing mod primes to see what cycles might appear. For example, $$x^6 -4x^3 +1 \equiv (x-6)(x^2+6x+3)(x-2)(x^2+2x+4)\bmod 11,$$ which shows that the Galois group has a $4$-cycle. But generally I am stuck beyond these things and it would be great if someone could at least tell me of a simple way of calculating the degree of the splitting field. Edit:  Thank you for your help Steve and Hurkyl! After reading your solutions, I think I figured out a concrete way to verifying that the Galois group is $D_{12}$ once we know that the group has order 12. Let $\alpha = \sqrt[3]{2+\sqrt{3}}, \beta =  \omega \sqrt[3]{2+\sqrt{3}},  \gamma = \omega^2 \sqrt[3]{2+\sqrt{3}}$. We know that the roots come in pairs $\alpha, \alpha^{-1}, \beta, \beta^{-1}, \gamma, \gamma^{-1}$ and the Galois group takes pairs to pairs. Also,  $\alpha \beta \gamma =1$ and so the triple $\alpha, \beta, \gamma$  either goes to the same triple $\alpha, \beta, \gamma$ or to the triple $\alpha^{-1}, \beta^{-1}, \gamma^{-1}$.  Now if we label the vertices of a hexagon with the roots so that the pairs of roots are opposite vertices, then we see that the Galois group must be a symmetry of the hexagon (here must use both the relations that the pairs of roots go to pairs and that triples go to triples). Thus we see that the Galois group is contained in $D_{12}$ under this identification. Since the order of the group is $12$, the group must be $D_{12}$.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
85,Character theory exercises [closed],Character theory exercises [closed],,"This question is unlikely to help any future visitors; it is only relevant to a small geographic area, a specific moment in time, or an extraordinarily narrow situation that is not generally applicable to the worldwide audience of the internet. For help making this question more broadly applicable, visit the help center . Closed 11 years ago . I'm doing the exercises from chapter 2 of M.Isaacs' Character theory of finite groups, and I'm having problems with some of them. In particular, I would need help with these ones. Thank you very much in advance!! :) (2.8) Let $\chi$ be a faithful character of a group $G$. Show that $H\subseteq G $ is abelian if and only if every irreducible constituent of $\chi_{H} $ is linear. (2.12) Let $|G|=n$ and let $g\in G$. Show that $\chi(g)$ is rational for every character$\chi$ of $G$ if and only if $g$ is conjugate to $g^m$ for every integer $m$ with $(m,n)=1$ (2.15) Let $\chi\in Irr(G)$ be faithful and suppose $H\subseteq G$ and $\chi_{H} \in Irr(H)$. Show that $C_{G}(H)=Z(G)$","This question is unlikely to help any future visitors; it is only relevant to a small geographic area, a specific moment in time, or an extraordinarily narrow situation that is not generally applicable to the worldwide audience of the internet. For help making this question more broadly applicable, visit the help center . Closed 11 years ago . I'm doing the exercises from chapter 2 of M.Isaacs' Character theory of finite groups, and I'm having problems with some of them. In particular, I would need help with these ones. Thank you very much in advance!! :) (2.8) Let $\chi$ be a faithful character of a group $G$. Show that $H\subseteq G $ is abelian if and only if every irreducible constituent of $\chi_{H} $ is linear. (2.12) Let $|G|=n$ and let $g\in G$. Show that $\chi(g)$ is rational for every character$\chi$ of $G$ if and only if $g$ is conjugate to $g^m$ for every integer $m$ with $(m,n)=1$ (2.15) Let $\chi\in Irr(G)$ be faithful and suppose $H\subseteq G$ and $\chi_{H} \in Irr(H)$. Show that $C_{G}(H)=Z(G)$",,"['abstract-algebra', 'group-theory', 'finite-groups', 'representation-theory', 'characters']"
86,An identity involving the powers of a nilpotent element in a unital commutative ring,An identity involving the powers of a nilpotent element in a unital commutative ring,,"Suppose $R$ is a commutative unital ring with identity $1$ such that the equation $nx = 1$ has a unique solution for each integer $n \ge 1$, and let $\xi$ be a nilpotent element of $R$ with nilpotency index $v$. Then fix a positive integer $k$ and set $a = \sum_{i=0}^{v-1} \binom{1/k}{i} \xi^i$. Is it true that $a^k = 1 + \xi$?","Suppose $R$ is a commutative unital ring with identity $1$ such that the equation $nx = 1$ has a unique solution for each integer $n \ge 1$, and let $\xi$ be a nilpotent element of $R$ with nilpotency index $v$. Then fix a positive integer $k$ and set $a = \sum_{i=0}^{v-1} \binom{1/k}{i} \xi^i$. Is it true that $a^k = 1 + \xi$?",,"['abstract-algebra', 'ring-theory', 'arithmetic', 'power-series']"
87,Idealizer of one-sided ideal,Idealizer of one-sided ideal,,Let $A$ be a ring and let $J$ be a right-sided ideal of $A$. We call the set $I_{A}(J)=\lbrace a \in A \mid aJ\subset J\rbrace$ the idealizer of $J$. Show that $I_{A}(J)$ is the largest subring of that $A$ containing $J$ as an ideal.,Let $A$ be a ring and let $J$ be a right-sided ideal of $A$. We call the set $I_{A}(J)=\lbrace a \in A \mid aJ\subset J\rbrace$ the idealizer of $J$. Show that $I_{A}(J)$ is the largest subring of that $A$ containing $J$ as an ideal.,,"['abstract-algebra', 'ring-theory', 'ideals']"
88,A question of the book Elements of the Representation Theory of Associative Algebras: Volume 1,A question of the book Elements of the Representation Theory of Associative Algebras: Volume 1,,"I am reading the book Elements of the Representation Theory of Associative Algebras: Volume 1 . I have a question on page 9, line -7 ( see Page 9 here ). It is said that $$f_X(x_2) = x_2e_{21} = x_2e_{21}e_{11}.$$ It seems that $e_{11}$ has not been defined and $e_{21}$ is a $2 \times 2$ matrix. How can $e_{21}$ act on $x_2$? Thank you very much. Edit: On -9, how to show that  $x_1a_{11} + x_2a_{21}$ is an element in $X_1$? It seems that $x_2a_{21}=f_X(x_2)a_{21}$. But this cannot be true since the left hand side is in $X_2$ and the right hand side is in $X_1$.","I am reading the book Elements of the Representation Theory of Associative Algebras: Volume 1 . I have a question on page 9, line -7 ( see Page 9 here ). It is said that $$f_X(x_2) = x_2e_{21} = x_2e_{21}e_{11}.$$ It seems that $e_{11}$ has not been defined and $e_{21}$ is a $2 \times 2$ matrix. How can $e_{21}$ act on $x_2$? Thank you very much. Edit: On -9, how to show that  $x_1a_{11} + x_2a_{21}$ is an element in $X_1$? It seems that $x_2a_{21}=f_X(x_2)a_{21}$. But this cannot be true since the left hand side is in $X_2$ and the right hand side is in $X_1$.",,"['abstract-algebra', 'representation-theory']"
89,Irreducibility of the polynomial $f (x) = x^{2p} − x ^p + t$,Irreducibility of the polynomial,f (x) = x^{2p} − x ^p + t,"If $k$ is a ﬁeld of characteristic $p > 0$ and $f (x) = x^{2p} − x ^p + t \in k(t)[x]$, how can we show  that $f (x)$ is an irreducible polynomial in $k(t)[x]$ and that $f (x)$ is inseparable? If $f(x)$ is irreducible then $D_xf(x) = 0 \implies( f, D_xf) = ( f, 0) = f$. Hence, if $f(x)$ is irreducible then $( f, D_xf) \neq 1 \implies f(x)$ is inseparable.","If $k$ is a ﬁeld of characteristic $p > 0$ and $f (x) = x^{2p} − x ^p + t \in k(t)[x]$, how can we show  that $f (x)$ is an irreducible polynomial in $k(t)[x]$ and that $f (x)$ is inseparable? If $f(x)$ is irreducible then $D_xf(x) = 0 \implies( f, D_xf) = ( f, 0) = f$. Hence, if $f(x)$ is irreducible then $( f, D_xf) \neq 1 \implies f(x)$ is inseparable.",,['abstract-algebra']
90,Artinian rings and associated prime ideals,Artinian rings and associated prime ideals,,"Let $R$ be a commutative ring with unity. Show that $R$ is artinian ring if and only if there exists a finite length $R$-module $M$, such that   $$\{r\in R \mid rm=0 ,\forall m\in M\}=(0).$$ The only thing I can think of is that I need to find $M$ such that $\mathrm{Ass}_{R}M=(0)$, but I'm not sure how to do this. $\mathrm{Ass}_{R}M$ is the set of all associated prime ideals of $M$.","Let $R$ be a commutative ring with unity. Show that $R$ is artinian ring if and only if there exists a finite length $R$-module $M$, such that   $$\{r\in R \mid rm=0 ,\forall m\in M\}=(0).$$ The only thing I can think of is that I need to find $M$ such that $\mathrm{Ass}_{R}M=(0)$, but I'm not sure how to do this. $\mathrm{Ass}_{R}M$ is the set of all associated prime ideals of $M$.",,"['abstract-algebra', 'commutative-algebra']"
91,Free groups and relations. Showing that $G\simeq FG^{(3)}/N$ for $N$ the normal subgroup generated by a set of relations.,Free groups and relations. Showing that  for  the normal subgroup generated by a set of relations.,G\simeq FG^{(3)}/N N,"Let $FG^{(3)}$ denote the free group generated by $3$ elements. Let $Z=(\Bbb Z^3,\oplus,{\bf 0})$ denote the group with addition $$(a_1,a_2,a_3)\oplus (b_1,b_2,b_3)=(a_1+b_1+a_2b_3,a_2+b_2,a_3+b_3)$$ Let $G$ be the group defined by the relations $$x_2x_1=x_3x_1x_2\\x_1x_3=x_3x_1\\x_2x_3=x_3x_2$$ on $FG^{(3)}$. Note the first equation can be written as $x_2x_1=x_1x_2x_3$. I ought to show $G\simeq Z$. For starters, note that for any element of $\Bbb Z^3$ we can write $$(a,b,c)=ae_1\oplus ce_3\oplus be_2$$ so that $\{e_1,e_2,e_3\}$ genereate $Z$. Moreover, $e_1,e_2,e_3$ fulfill the relations with $x_1=e_3,x_2=e_2,x_3=e_1$. We thus consdier the natural (canonical) homomorphism $FG^{(3)}\to \Bbb Z^3$ by sending $x_1\to e_3$, $x_2\to e_2$ and $x_3\to e_1$. How can I show that the kernel of this homomoprhism is the normal subgroup generated by the elements obtained when equating the relations to the unity? It is clear that the normal subgroup is contained in this kernel, but how does one show it is actually the kernel? ADD This is all the author says about relations on free groups: ""A group $G$ is said to be finitely generated if it contains a finite group of generators $\{a_1;1\leq a_i\leq r\}$. Then we have the homomorphism $\eta$ of $FG^{(r)}$ sending $x_i\to a_i$. Since the $a_i$ generate $G$, this is an epimorphism and $G\simeq FG^{(r)}/K$ where $K$ is the kernel of $\eta$. The normal subgroup $K$ is called the set of relations connecting the generators $a_i$. If $S$ is a subset of a group, we can define the normal subgroup generated by $S$ to be the intersection of all normal subgroups of the group containing $S$. If $S$ is a subset of $FG^{(r)}$ we say that $G$ is defined by the relations $S$ if $G\simeq FG^{(r)}/K$ where $K$ is the normal subgroup generated by $S$. If $S$ is finite, then we say that $G$ is a finitely presented group."" The author gave an example on how to show two groups are isomorphic. It went something like this: Let $D_n$ be the dihedral group. We show that it is defined by the relations $$\tag 1 x^n,y^2,xyxy$$ on the free group generated by two elements. It is clear that $D_n$ is generated by the rotation $R$ by $2\pi /n$ and the reflection $S$ through the $x$-axis. Moreover $R^n=1$, $S^2=1$ and $SRS=R^{-1}$. Hence $D_n$ is homomorphic to $FG^{(2)}/K$ where $K$ is the normal subgroup generated by the elements in $(1)$. To show that it is isomorphic, we show that $FG^{(2)}/K$ has order less than $2n$. Let $\bar x=xK$ and $\bar y =yK$. Then $\bar x^n=1$, $\bar y^2=1$ and $\bar x\bar y\bar x\bar y=1$. Moreover, $ \bar y\bar x =\bar x^{-1} \bar y$ from the above implies that $\bar x^k =\bar x^{-k}\bar y$. Consider the set $\{\bar x^k,\bar x^k \bar y:1\leq k\leq n-1\}$. Then the product of any two elements is one of these elements, it contains $1$ and is closed under inverses. Hence it is a subgroup, but since it contains the generators $\bar x$ and $\bar y$, it is all of $FG^{(2)}/K$. Thus $|FG^{(2)}/K|\leq 2n$, which implies $D_n\simeq FG^{(2)}/K$. Questions $(1)$ I understand the reasoning by after ""Hence $D_n$ is homomorphic..."" but I don't know if I understand why this is so. Let $\eta$ be the natural homomorphism that sends $R\to x$, $S\to y$, and let $\zeta$ be $x\mapsto xK=\bar x$. We then use the homomorphism ""natural"" homomoprhism $R\mapsto \bar x$ and $S\mapsto \bar y$? $(2)$ Can a similar argument be used on the exercise I am given? I see that $\Bbb Z^3$ is not finite at all, so I don't see how this can be used.","Let $FG^{(3)}$ denote the free group generated by $3$ elements. Let $Z=(\Bbb Z^3,\oplus,{\bf 0})$ denote the group with addition $$(a_1,a_2,a_3)\oplus (b_1,b_2,b_3)=(a_1+b_1+a_2b_3,a_2+b_2,a_3+b_3)$$ Let $G$ be the group defined by the relations $$x_2x_1=x_3x_1x_2\\x_1x_3=x_3x_1\\x_2x_3=x_3x_2$$ on $FG^{(3)}$. Note the first equation can be written as $x_2x_1=x_1x_2x_3$. I ought to show $G\simeq Z$. For starters, note that for any element of $\Bbb Z^3$ we can write $$(a,b,c)=ae_1\oplus ce_3\oplus be_2$$ so that $\{e_1,e_2,e_3\}$ genereate $Z$. Moreover, $e_1,e_2,e_3$ fulfill the relations with $x_1=e_3,x_2=e_2,x_3=e_1$. We thus consdier the natural (canonical) homomorphism $FG^{(3)}\to \Bbb Z^3$ by sending $x_1\to e_3$, $x_2\to e_2$ and $x_3\to e_1$. How can I show that the kernel of this homomoprhism is the normal subgroup generated by the elements obtained when equating the relations to the unity? It is clear that the normal subgroup is contained in this kernel, but how does one show it is actually the kernel? ADD This is all the author says about relations on free groups: ""A group $G$ is said to be finitely generated if it contains a finite group of generators $\{a_1;1\leq a_i\leq r\}$. Then we have the homomorphism $\eta$ of $FG^{(r)}$ sending $x_i\to a_i$. Since the $a_i$ generate $G$, this is an epimorphism and $G\simeq FG^{(r)}/K$ where $K$ is the kernel of $\eta$. The normal subgroup $K$ is called the set of relations connecting the generators $a_i$. If $S$ is a subset of a group, we can define the normal subgroup generated by $S$ to be the intersection of all normal subgroups of the group containing $S$. If $S$ is a subset of $FG^{(r)}$ we say that $G$ is defined by the relations $S$ if $G\simeq FG^{(r)}/K$ where $K$ is the normal subgroup generated by $S$. If $S$ is finite, then we say that $G$ is a finitely presented group."" The author gave an example on how to show two groups are isomorphic. It went something like this: Let $D_n$ be the dihedral group. We show that it is defined by the relations $$\tag 1 x^n,y^2,xyxy$$ on the free group generated by two elements. It is clear that $D_n$ is generated by the rotation $R$ by $2\pi /n$ and the reflection $S$ through the $x$-axis. Moreover $R^n=1$, $S^2=1$ and $SRS=R^{-1}$. Hence $D_n$ is homomorphic to $FG^{(2)}/K$ where $K$ is the normal subgroup generated by the elements in $(1)$. To show that it is isomorphic, we show that $FG^{(2)}/K$ has order less than $2n$. Let $\bar x=xK$ and $\bar y =yK$. Then $\bar x^n=1$, $\bar y^2=1$ and $\bar x\bar y\bar x\bar y=1$. Moreover, $ \bar y\bar x =\bar x^{-1} \bar y$ from the above implies that $\bar x^k =\bar x^{-k}\bar y$. Consider the set $\{\bar x^k,\bar x^k \bar y:1\leq k\leq n-1\}$. Then the product of any two elements is one of these elements, it contains $1$ and is closed under inverses. Hence it is a subgroup, but since it contains the generators $\bar x$ and $\bar y$, it is all of $FG^{(2)}/K$. Thus $|FG^{(2)}/K|\leq 2n$, which implies $D_n\simeq FG^{(2)}/K$. Questions $(1)$ I understand the reasoning by after ""Hence $D_n$ is homomorphic..."" but I don't know if I understand why this is so. Let $\eta$ be the natural homomorphism that sends $R\to x$, $S\to y$, and let $\zeta$ be $x\mapsto xK=\bar x$. We then use the homomorphism ""natural"" homomoprhism $R\mapsto \bar x$ and $S\mapsto \bar y$? $(2)$ Can a similar argument be used on the exercise I am given? I see that $\Bbb Z^3$ is not finite at all, so I don't see how this can be used.",,"['abstract-algebra', 'group-theory']"
92,Do the polynomial germs generate all the ring of germs?,Do the polynomial germs generate all the ring of germs?,,"I'm trying to understand some equality that comes up in stability theory involving sets of germs and I think I need a result like the next one, so if anyone knows anything about this and helps me it would be wonderful! Let $C^{\infty}_0(\mathbb{R}^n)$ be the ring of germs at $0\in \mathbb{R}^n$ of smooth maps from $\mathbb{R}^n \to \mathbb{R}$. We write $[f]\in C^{\infty}_0$ to denote the germ of a smooth function $f \colon \mathbb{R}^n \to \mathbb{R}$, and define the set $$\mathrm{Pol}_k(x_1, \cdots,x_n)=\{x_1^{i_1} x_2^{i_2}\dots x_n^{i_n}\in K[X]\;| \;i_1+i_2+\dots+ i_n=k \},$$ where $K[X]$ is the polynomial ring in $n$ variables. Now, we can think of $C^{\infty}_0(\mathbb{R}^n)$ as a module over itself so the question is, Does the class of all polynomials generate $C^{\infty}_0(\mathbb{R}^n)$? Specifically, is this true? $$C^{\infty}_0(\mathbb{R}^n) = \langle 1,[\mathrm{Pol}_1(x_1,\cdots,x_n)],[\mathrm{Pol}_2(x_1,\cdots,x_n)],\cdots\rangle_{\mathbb{R}}$$ where by $\langle [f_1],\cdots,[f_n]\rangle_{\mathbb{R}} \subset C^{\infty}_0(\mathbb{R}^n)$ we mean the $\mathbb{R}$-submodule generated by $[f_1],\cdots,[f_n]\in C^{\infty}_0(\mathbb{R}^n)$. --I'm sorry I don't think I expressed correctly what I had in mind. Actually what I was trying to ask is something like this: If we denote by $\mathfrak{m}(n)$ the maximal ideal in $C^{\infty}_0(\mathbb{R}^n)$ consisting of elements in $[f]\in C^{\infty}_0(\mathbb{R}^n)$ such that their representatives have $f(0)=0$. Is this equality (or a similar result) correct? $$C^{\infty}_0(\mathbb{R}^n) = \langle 1,[\mathrm{Pol}_1(x_1,\cdots,x_n)],\cdots,[\mathrm{Pol}_n(x_1,\cdots,x_n)]\rangle_{\mathbb{R}} +\mathfrak{m}(n)^n$$ It looks to me that it could be right. I mean at least if $f$, a representative of $[f]\in C^{\infty}_0(\mathbb{R}^n)$, is equal to it's Taylor series it looks like true, but then again there are functions like $e^{-1/x^2}$...","I'm trying to understand some equality that comes up in stability theory involving sets of germs and I think I need a result like the next one, so if anyone knows anything about this and helps me it would be wonderful! Let $C^{\infty}_0(\mathbb{R}^n)$ be the ring of germs at $0\in \mathbb{R}^n$ of smooth maps from $\mathbb{R}^n \to \mathbb{R}$. We write $[f]\in C^{\infty}_0$ to denote the germ of a smooth function $f \colon \mathbb{R}^n \to \mathbb{R}$, and define the set $$\mathrm{Pol}_k(x_1, \cdots,x_n)=\{x_1^{i_1} x_2^{i_2}\dots x_n^{i_n}\in K[X]\;| \;i_1+i_2+\dots+ i_n=k \},$$ where $K[X]$ is the polynomial ring in $n$ variables. Now, we can think of $C^{\infty}_0(\mathbb{R}^n)$ as a module over itself so the question is, Does the class of all polynomials generate $C^{\infty}_0(\mathbb{R}^n)$? Specifically, is this true? $$C^{\infty}_0(\mathbb{R}^n) = \langle 1,[\mathrm{Pol}_1(x_1,\cdots,x_n)],[\mathrm{Pol}_2(x_1,\cdots,x_n)],\cdots\rangle_{\mathbb{R}}$$ where by $\langle [f_1],\cdots,[f_n]\rangle_{\mathbb{R}} \subset C^{\infty}_0(\mathbb{R}^n)$ we mean the $\mathbb{R}$-submodule generated by $[f_1],\cdots,[f_n]\in C^{\infty}_0(\mathbb{R}^n)$. --I'm sorry I don't think I expressed correctly what I had in mind. Actually what I was trying to ask is something like this: If we denote by $\mathfrak{m}(n)$ the maximal ideal in $C^{\infty}_0(\mathbb{R}^n)$ consisting of elements in $[f]\in C^{\infty}_0(\mathbb{R}^n)$ such that their representatives have $f(0)=0$. Is this equality (or a similar result) correct? $$C^{\infty}_0(\mathbb{R}^n) = \langle 1,[\mathrm{Pol}_1(x_1,\cdots,x_n)],\cdots,[\mathrm{Pol}_n(x_1,\cdots,x_n)]\rangle_{\mathbb{R}} +\mathfrak{m}(n)^n$$ It looks to me that it could be right. I mean at least if $f$, a representative of $[f]\in C^{\infty}_0(\mathbb{R}^n)$, is equal to it's Taylor series it looks like true, but then again there are functions like $e^{-1/x^2}$...",,"['abstract-algebra', 'differential-geometry', 'ring-theory', 'singularity-theory']"
93,Alternative proof of Wedderburn's little theorem,Alternative proof of Wedderburn's little theorem,,"I have this exercise where I'm proving: ""Every finite division ring is a field"". I need only a part (c) of it: (a) show that a subalgebra of a finite dimensional central division algebra is a finite dimensional division algebra. (DONE) (b) show that if $D$ is a finite dimensional central division algebra and $K\neq Z(D)$ is any subfield, then $D$ is generated as an $Z(D)$-algebra by $\bigcup_{d\in D^*}d^{-1}Kd$. (DONE) (c) Conclude, without using the Noether-Skolem theorem, that a finite division ring is a field. (NEEDED...) Thanks, G.","I have this exercise where I'm proving: ""Every finite division ring is a field"". I need only a part (c) of it: (a) show that a subalgebra of a finite dimensional central division algebra is a finite dimensional division algebra. (DONE) (b) show that if $D$ is a finite dimensional central division algebra and $K\neq Z(D)$ is any subfield, then $D$ is generated as an $Z(D)$-algebra by $\bigcup_{d\in D^*}d^{-1}Kd$. (DONE) (c) Conclude, without using the Noether-Skolem theorem, that a finite division ring is a field. (NEEDED...) Thanks, G.",,"['abstract-algebra', 'ring-theory', 'division-algebras']"
94,Every ideal in ring of integers contains a natural number,Every ideal in ring of integers contains a natural number,,"Let $O$ be the ring of integers of some number field and $I$ any nonzero ideal of $O$ . Prove that there is some number $n \in \mathbb{Z}_+$ that is in ideal $I$ . I suppose I should use that $O$ is Dedekind domain, so every ideal can be written as product of prime ideals, but I don't know how to use that. Any help is appreciated.","Let be the ring of integers of some number field and any nonzero ideal of . Prove that there is some number that is in ideal . I suppose I should use that is Dedekind domain, so every ideal can be written as product of prime ideals, but I don't know how to use that. Any help is appreciated.",O I O n \in \mathbb{Z}_+ I O,"['abstract-algebra', 'algebraic-number-theory']"
95,Problem on a quotient group of a matrix,Problem on a quotient group of a matrix,,"Let $G=\left\{\begin{bmatrix}a & b \\ c & d\end{bmatrix}:a,b,c,d\in\mathbb{Z}\right\}$ be the group under matrix addition and $H$ be the subgroup of $G$ consisting of matrices with even entries. Find the order of the quotient group $G/H$. How should I solve this problem?","Let $G=\left\{\begin{bmatrix}a & b \\ c & d\end{bmatrix}:a,b,c,d\in\mathbb{Z}\right\}$ be the group under matrix addition and $H$ be the subgroup of $G$ consisting of matrices with even entries. Find the order of the quotient group $G/H$. How should I solve this problem?",,['abstract-algebra']
96,Hom functor and left exactness,Hom functor and left exactness,,"How can I prove that if $$0\longrightarrow\mathrm{Hom}(M,A)\xrightarrow{\;\;i_*\;\;}\mathrm{Hom}(M,B)\xrightarrow{\;\;j_*\;\;}\mathrm{Hom}(M,C)$$ is left exact, then $$0\longrightarrow A\xrightarrow{\;\;i\;\;} B\xrightarrow{\;\;j\;\;} C$$ is left exact. I have seen proofs showing that if the second chain is left exact, then the first chain is left exact, but what about proving the converse without depending on the projective module concept.","How can I prove that if $$0\longrightarrow\mathrm{Hom}(M,A)\xrightarrow{\;\;i_*\;\;}\mathrm{Hom}(M,B)\xrightarrow{\;\;j_*\;\;}\mathrm{Hom}(M,C)$$ is left exact, then $$0\longrightarrow A\xrightarrow{\;\;i\;\;} B\xrightarrow{\;\;j\;\;} C$$ is left exact. I have seen proofs showing that if the second chain is left exact, then the first chain is left exact, but what about proving the converse without depending on the projective module concept.",,['abstract-algebra']
97,number of subgroups of $\mathbb{Z}_{5}\times\mathbb{Z}_{5}$,number of subgroups of,\mathbb{Z}_{5}\times\mathbb{Z}_{5},"I have to show that the number of subgroups of $\mathbb{Z}_{5}\times\mathbb{Z}_{5}$ (other than identity and itself) is six, but I am a bit confused. please help! P.S. can someone also tell if there is some method to determine the subgroups of direct products of cyclic groups?","I have to show that the number of subgroups of $\mathbb{Z}_{5}\times\mathbb{Z}_{5}$ (other than identity and itself) is six, but I am a bit confused. please help! P.S. can someone also tell if there is some method to determine the subgroups of direct products of cyclic groups?",,"['abstract-algebra', 'galois-theory']"
98,how to find all simple modules for the given path algebra,how to find all simple modules for the given path algebra,,"Let $A = KQ$, where $Q$ is the quiver $$\begin{array}{ccc} & \alpha & \\ 1 & \rightleftarrows & 2 \\ & \beta& \end{array}$$ are there simple right $A$-modules with dimension $\geq3$? In generally, how to  find all  simple modules  for the given path algebra, especially the infinitely dimensional case?","Let $A = KQ$, where $Q$ is the quiver $$\begin{array}{ccc} & \alpha & \\ 1 & \rightleftarrows & 2 \\ & \beta& \end{array}$$ are there simple right $A$-modules with dimension $\geq3$? In generally, how to  find all  simple modules  for the given path algebra, especially the infinitely dimensional case?",,"['abstract-algebra', 'representation-theory', 'quiver']"
99,Dicyclic group as subgroup of $S_6$?,Dicyclic group as subgroup of ?,S_6,"I have the dicyclic group $G$ of order 12 generated by $x,y$ satisfying $x^4 = y^3 = 1$ and $xyx^{-1} = y^2$, and am trying to determine whether the symmetric group $S_6$ contains a subgroup isomorphic to it. So far I've tried looking for an appropriate set of 6 elements for $G$ to act on, and hoping that the permutation representation $ \phi: G \to S_6$ is injective, but haven't had any luck: $ \phi$ is not injective for the action of $G$ conjugating its set of 6 elements of order 4, nor is it injective for the action of $G$ translating its set of 6 cosets of a subgroup of order 2. Is it even true that $S_6$ does contain such a subgroup isomorphic to $G$, and if so how would I construct the isomorphism?","I have the dicyclic group $G$ of order 12 generated by $x,y$ satisfying $x^4 = y^3 = 1$ and $xyx^{-1} = y^2$, and am trying to determine whether the symmetric group $S_6$ contains a subgroup isomorphic to it. So far I've tried looking for an appropriate set of 6 elements for $G$ to act on, and hoping that the permutation representation $ \phi: G \to S_6$ is injective, but haven't had any luck: $ \phi$ is not injective for the action of $G$ conjugating its set of 6 elements of order 4, nor is it injective for the action of $G$ translating its set of 6 cosets of a subgroup of order 2. Is it even true that $S_6$ does contain such a subgroup isomorphic to $G$, and if so how would I construct the isomorphism?",,"['abstract-algebra', 'group-theory']"
