,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Rewrite $ \int_{\mathcal{S}}dP_X=1 $ as conditions on boxes in $\mathbb{R}^d$,Rewrite  as conditions on boxes in, \int_{\mathcal{S}}dP_X=1  \mathbb{R}^d,"Take $r\in \mathbb{N}$ and let $d\equiv r+\binom{r}{2}$ . Consider a d-dimensional random  vector $X\equiv (X_1,...,X_d)$ . Let $P_X$ be the probability distribution of $X$ . Assume that $$ \int_{\mathcal{S}}dP_X=1 $$ where $$ \begin{aligned} \mathcal{S}\equiv \{(b_1,b_2,..., b_d)\in \mathbb{R}^{d}: \text{ } & b_{r+1}=b_1-b_2, b_{r+2}=b_1-b_3, ...,b_{2r-1}=b_1-b_r, \\ &b_{2r}=b_2-b_3, ..., b_{3r-3}=b_2-b_r,\\ &...,\\ & b_d=b_{r-1}-b_r\} \end{aligned} $$ For example, when $r=2$ ( $d=3$ ) we have the surface $$ \begin{aligned} \mathcal{S}\equiv \{(b_1,b_2,b_3)\in \mathbb{R}^{3}: \text{ } & b_3=b_1-b_2\}=\{(b_1,b_2,b_3)\in \mathbb{R}^{3}: \text{ } & b_1=b_2+b_3\} \end{aligned} $$ When $r=3$ ( $d=6$ ) we have $$ \begin{aligned} \mathcal{S}\equiv \{(b_1,..., b_6)\in \mathbb{R}^{6}: \text{ } & b_4=b_1-b_2, b_5=b_1-b_3, b_6=b_2-b_3\} \end{aligned} $$ My final goal: I'm interested in rewriting the condition $\int_{\mathcal{S}}dP_X=1$ as a collection of zero probability measure conditions on d-dimensional ""boxes"" in $\mathbb{R}^d$ . The idea is that any box in $\mathbb{R}^d$ not intersecting $\mathcal{S}$ should have probability measure equal to zero. Therefore, if we consider enough of these boxes, we should be able to equivalently rewrite $\int_{\mathcal{S}}dP_X=1$ . When $r=2$ ( $d=3$ ), my goal is achieved by the following claim Claim: For any two real numbers $(b,c)\in \mathbb{R}^2$ , define the boxes $$B(b,c)\equiv \{(x,y,z)\text{ s.t. } x> b+c, y\leq b, z\leq c\}$$ and $$Q(b,c)\equiv \{(x,y,z)\text{ s.t. } x\leq  b+c, y>b, z>c\}$$ If $P_{X}(B(b,c))=0$ and $P_{X}(Q(b,c))=0$ $\forall(b,c)\in \mathbb{Q}^2$ , then $\int_{\mathcal{S}}dP_{X}=1$ . The proof of the claim is provided here I would like your help to generalise the claim (and possibly the proof) to any $r$ . What I find challenging is defining the relevant boxes for any $r>2$ . I really can't see how to generalise the box definitions from $r=2$ to any $r$ .","Take and let . Consider a d-dimensional random  vector . Let be the probability distribution of . Assume that where For example, when ( ) we have the surface When ( ) we have My final goal: I'm interested in rewriting the condition as a collection of zero probability measure conditions on d-dimensional ""boxes"" in . The idea is that any box in not intersecting should have probability measure equal to zero. Therefore, if we consider enough of these boxes, we should be able to equivalently rewrite . When ( ), my goal is achieved by the following claim Claim: For any two real numbers , define the boxes and If and , then . The proof of the claim is provided here I would like your help to generalise the claim (and possibly the proof) to any . What I find challenging is defining the relevant boxes for any . I really can't see how to generalise the box definitions from to any .","r\in \mathbb{N} d\equiv r+\binom{r}{2} X\equiv (X_1,...,X_d) P_X X 
\int_{\mathcal{S}}dP_X=1
 
\begin{aligned}
\mathcal{S}\equiv \{(b_1,b_2,..., b_d)\in \mathbb{R}^{d}: \text{ } & b_{r+1}=b_1-b_2, b_{r+2}=b_1-b_3, ...,b_{2r-1}=b_1-b_r, \\
&b_{2r}=b_2-b_3, ..., b_{3r-3}=b_2-b_r,\\
&...,\\
& b_d=b_{r-1}-b_r\}
\end{aligned}
 r=2 d=3 
\begin{aligned}
\mathcal{S}\equiv \{(b_1,b_2,b_3)\in \mathbb{R}^{3}: \text{ } & b_3=b_1-b_2\}=\{(b_1,b_2,b_3)\in \mathbb{R}^{3}: \text{ } & b_1=b_2+b_3\}
\end{aligned}
 r=3 d=6 
\begin{aligned}
\mathcal{S}\equiv \{(b_1,..., b_6)\in \mathbb{R}^{6}: \text{ } & b_4=b_1-b_2, b_5=b_1-b_3, b_6=b_2-b_3\}
\end{aligned}
 \int_{\mathcal{S}}dP_X=1 \mathbb{R}^d \mathbb{R}^d \mathcal{S} \int_{\mathcal{S}}dP_X=1 r=2 d=3 (b,c)\in \mathbb{R}^2 B(b,c)\equiv \{(x,y,z)\text{ s.t. } x> b+c, y\leq b, z\leq c\} Q(b,c)\equiv \{(x,y,z)\text{ s.t. } x\leq  b+c, y>b, z>c\} P_{X}(B(b,c))=0 P_{X}(Q(b,c))=0 \forall(b,c)\in \mathbb{Q}^2 \int_{\mathcal{S}}dP_{X}=1 r r>2 r=2 r","['probability', 'geometry', 'probability-theory', 'measure-theory', 'lebesgue-measure']"
1,"$\Pr[\sum_i X_i^2 Y_i^2\ge t]$, Chernoff bound for sum of pairs of squared Normal random variables",", Chernoff bound for sum of pairs of squared Normal random variables",\Pr[\sum_i X_i^2 Y_i^2\ge t],"I'm interested in finding tail bound for $\sum_{i=1}^k X_i^2 Y_i^2$ , where $X_i$ and $Y_i$ are independent standard normal random variables. It should be roughly as tight as the standard Chernoff bound, something like $e^{-\Omega(k\sqrt t)}$ would be nice. My first instinct was to look at the mgf. $\exp(t X^2 Y^2)$ , but naturally it doesn't exist. I looked at $\exp(i t X^2 Y^2) = e^{i/(8t)} K_0(i/(8t))/\sqrt{\pi i t}$ , but I don't know how to get a tail bound using the characteristic function. I also considered moment bounds. We have $E(X^2 Y^2)^k=2^{2k}\Gamma(k+1/2)^2/\pi\le2(2k/e)^{2k}$ , but to get a tail bound I need $E(\sum_i X_i^2 Y_i^2)^k$ , which is of course a lot harder to estimate. I also considered the Cauchy Schwarz bound: $E(\sum_i X_i^2 Y_i^2)^k\le E(\sum_i X_i^4)^{k/2}(\sum_i Y_i^4)^{k/2}=E(\sum_i X_i^4)^{k}$ , but even those moments seem pretty involved. We have that $\Pr[\sum_{i=1}^kX_iY_i\ge tk]\le \exp\left(\frac{-t^2k}{2+t}\right)$ by Chernoff bounds, which is close to gaussian at least for small $t$ . Perhaps we might also expect that $\sum X^2_iY^2_i$ is close to Chi-Squared for small $t$ ? Does anyone know if there is a standard bound for this sum? Or if one of my approaches might be workable?","I'm interested in finding tail bound for , where and are independent standard normal random variables. It should be roughly as tight as the standard Chernoff bound, something like would be nice. My first instinct was to look at the mgf. , but naturally it doesn't exist. I looked at , but I don't know how to get a tail bound using the characteristic function. I also considered moment bounds. We have , but to get a tail bound I need , which is of course a lot harder to estimate. I also considered the Cauchy Schwarz bound: , but even those moments seem pretty involved. We have that by Chernoff bounds, which is close to gaussian at least for small . Perhaps we might also expect that is close to Chi-Squared for small ? Does anyone know if there is a standard bound for this sum? Or if one of my approaches might be workable?",\sum_{i=1}^k X_i^2 Y_i^2 X_i Y_i e^{-\Omega(k\sqrt t)} \exp(t X^2 Y^2) \exp(i t X^2 Y^2) = e^{i/(8t)} K_0(i/(8t))/\sqrt{\pi i t} E(X^2 Y^2)^k=2^{2k}\Gamma(k+1/2)^2/\pi\le2(2k/e)^{2k} E(\sum_i X_i^2 Y_i^2)^k E(\sum_i X_i^2 Y_i^2)^k\le E(\sum_i X_i^4)^{k/2}(\sum_i Y_i^4)^{k/2}=E(\sum_i X_i^4)^{k} \Pr[\sum_{i=1}^kX_iY_i\ge tk]\le \exp\left(\frac{-t^2k}{2+t}\right) t \sum X^2_iY^2_i t,"['probability', 'probability-distributions', 'normal-distribution', 'distribution-tails']"
2,Every finite state Markov chain has a stationary probability distribution,Every finite state Markov chain has a stationary probability distribution,,"I am trying to understand the following proof that every finite-state Markov chain has a stationary distribution. The proof is from here . Let $P$ be the $k \times k$ (stochastic) transition probability matrix for our Markov chain. Now, ... $1$ is an eigenvalue for $P$ and therefore also for $P^t$ .   Writing a $P^t$ invariant $v$ as $v = v^+ − v^−$ with $v^+ , v^− \in ( > \mathbb{R}_+ )^k$ , we obtain $P^t v^± = v^±$ because $P^t$ preserves   the positive cone; if $v^+\neq 0$ take $ν = ( \sum v^+_i )^{-1} · v^+,$ otherwise normalize $v^−$ . The main thing I don't understand is we obtain $P^t v^± = v^±$ because $P^t$ preserves   the positive cone Why is this true? I also don't understand why $( \sum v^+_i )^{-1} · v^+$ works if $v^+ \neq 0$ . Is there any easier way to show that every finite state Markov chain has a stationary probability distribution?","I am trying to understand the following proof that every finite-state Markov chain has a stationary distribution. The proof is from here . Let be the (stochastic) transition probability matrix for our Markov chain. Now, ... is an eigenvalue for and therefore also for .   Writing a invariant as with , we obtain because preserves   the positive cone; if take otherwise normalize . The main thing I don't understand is we obtain because preserves   the positive cone Why is this true? I also don't understand why works if . Is there any easier way to show that every finite state Markov chain has a stationary probability distribution?","P k \times k 1 P P^t P^t v v = v^+ − v^− v^+ , v^− \in (
> \mathbb{R}_+ )^k P^t v^± = v^± P^t v^+\neq 0 ν = ( \sum v^+_i )^{-1} · v^+, v^− P^t v^± = v^± P^t ( \sum v^+_i )^{-1} · v^+ v^+ \neq 0","['probability', 'proof-verification', 'markov-chains', 'stochastic-matrices']"
3,"There are 50 misprints in a book which has 250 pages, find the probability that page 100 has no misprints? (Use theoretically correct distribution)","There are 50 misprints in a book which has 250 pages, find the probability that page 100 has no misprints? (Use theoretically correct distribution)",,"My question is where this should be modelled as a binomial distribution problem or a Poisson distribution problem. Any hint/advice helps, thanks in advance!","My question is where this should be modelled as a binomial distribution problem or a Poisson distribution problem. Any hint/advice helps, thanks in advance!",,"['probability', 'probability-distributions', 'poisson-distribution', 'binomial-distribution']"
4,Why are these two summations in the calculation of the variance equal?,Why are these two summations in the calculation of the variance equal?,,"Background: The screenshot below is the book solution to a 1st year probability question (Sheldon Ross self test 7.12). I understand everything except the last equality. My Question: Is the red box equal to the blue box below? Can you show me step by step how to do it? I'm guessing there's some identity that will make it easier... My Attempt: Unfortunately in lieu of being able to solve the question using math I put it in python and got different results for the red and blue box... but my script could be wrong. Thanks for your help. n = 5  redBox = 0 for i in range(1,n):     for j in range(i+1,n+1):         redBox += (i-1)*(j-n) redBox = 2*redBox / ((n-2)**2 * (n-1))  blueBox = 0 for i in range(1,n):     blueBox += (i-1)*(n-i)*(n-i-1) blueBox = -blueBox / ((n-2)*(n-1)**2)  print(redBox,blueBox) and for $n=5$ I get $\text{red box} = -0.277$ vs $\text{blue box} = -0.20833$ . Thanks. Book solution","Background: The screenshot below is the book solution to a 1st year probability question (Sheldon Ross self test 7.12). I understand everything except the last equality. My Question: Is the red box equal to the blue box below? Can you show me step by step how to do it? I'm guessing there's some identity that will make it easier... My Attempt: Unfortunately in lieu of being able to solve the question using math I put it in python and got different results for the red and blue box... but my script could be wrong. Thanks for your help. n = 5  redBox = 0 for i in range(1,n):     for j in range(i+1,n+1):         redBox += (i-1)*(j-n) redBox = 2*redBox / ((n-2)**2 * (n-1))  blueBox = 0 for i in range(1,n):     blueBox += (i-1)*(n-i)*(n-i-1) blueBox = -blueBox / ((n-2)*(n-1)**2)  print(redBox,blueBox) and for I get vs . Thanks. Book solution",n=5 \text{red box} = -0.277 \text{blue box} = -0.20833,"['probability', 'algebra-precalculus']"
5,Why doesn't the order matter in Probability,Why doesn't the order matter in Probability,,"I got a horrible doubt in probability. Kindly help me. (in permutation and combination chapter) Now our teacher has started probability Everything was almost clear unless and until I came with the second pic. When we are doing ""10c1*15c1"" the order is already being counted in this. Then why should I multiply it with two? Or in other language if we consider that order does not matter then it should be 10*15/2 and in denominator 25C2 And if we consider order matters then 10×15 (Here 1st one green 2nd one red /or / 1st one red and second one green has already been counted___as I did in the 1st pic) And in denominator 25×24","I got a horrible doubt in probability. Kindly help me. (in permutation and combination chapter) Now our teacher has started probability Everything was almost clear unless and until I came with the second pic. When we are doing ""10c1*15c1"" the order is already being counted in this. Then why should I multiply it with two? Or in other language if we consider that order does not matter then it should be 10*15/2 and in denominator 25C2 And if we consider order matters then 10×15 (Here 1st one green 2nd one red /or / 1st one red and second one green has already been counted___as I did in the 1st pic) And in denominator 25×24",,"['probability', 'combinatorics', 'algebra-precalculus', 'permutations']"
6,BlackJack Card Probability when Counting Cards,BlackJack Card Probability when Counting Cards,,"In a single deck blackjack game - if you're not counting cards - the probability that the next card will be a 10/J/Q/K is 16/52. I'm trying to figure out how to adjust the probabilities when you are counting cards.  For those that might not be familiar, a common card counting system (HiLo) works by keeping a running ""count"", when you see a 2-6 you add 1 to the count, when you see a T/J/Q/K/A you subtract 1 from the count.  When the count is positive it means the odds are better for the player (the remaining deck(s) is richer in high cards vs low cards). Let say that it's a 2 deck game, and half the cards have already been dealt - 52 cards remain.  The count is +5, that means there have been 5 more low cards seen so far than high cards.  What is the probability that the next card dealt will be a 10/J/Q/K? It's gotta be more than 16/52, because we know the deck is richer in high cards based on the count.  I just don't know how to model/calculate it.","In a single deck blackjack game - if you're not counting cards - the probability that the next card will be a 10/J/Q/K is 16/52. I'm trying to figure out how to adjust the probabilities when you are counting cards.  For those that might not be familiar, a common card counting system (HiLo) works by keeping a running ""count"", when you see a 2-6 you add 1 to the count, when you see a T/J/Q/K/A you subtract 1 from the count.  When the count is positive it means the odds are better for the player (the remaining deck(s) is richer in high cards vs low cards). Let say that it's a 2 deck game, and half the cards have already been dealt - 52 cards remain.  The count is +5, that means there have been 5 more low cards seen so far than high cards.  What is the probability that the next card dealt will be a 10/J/Q/K? It's gotta be more than 16/52, because we know the deck is richer in high cards based on the count.  I just don't know how to model/calculate it.",,"['probability', 'statistics', 'card-games']"
7,"Durrett's Probability problem 3.1.1, show $\prod_{j=1}^n (1+c_{j,n}) \to e^\lambda$","Durrett's Probability problem 3.1.1, show","\prod_{j=1}^n (1+c_{j,n}) \to e^\lambda","Given: $$\max_{1\leq j \leq n} |c_{j,n}| \to 0$$ $$\sum_{j=1}^n  c_{j,n} \to \lambda$$ $$\sup_n \sum_{j=1}^n |c_{j,n}| < \infty,$$ show that: $$ \prod_{j=1}^n (1 + c_{j,n}) \to e^\lambda.$$ My partial solution: Taking the log of both sides, the conclusion is equivalent to $$ \sum_{j=1}^n \ln (1 + c_{j,n}) \to \lambda.$$ Indeed, $$ \sum_{j=1}^n \ln (1 + c_{j,n}) =  \sum_{j=1}^n  \frac{\ln (1 + c_{j,n})}{c_{j,n}} c_{j,n}.$$ Let $$ \overline{c}_{j,n} := \max_{1\leq j \leq n} c_{j,n},$$ $$ \underline{c}_{j,n} := \min_{1\leq j \leq n} c_{j,n}.$$ Now define $$k_n := \frac{\ln (1 + \underline{c}_{j,n})}{\underline{c}_{j,n}},$$  and  $$l_n := \frac{\ln (1 + \overline{c}_{j,n})}{\overline{c}_{j,n}}.$$  Clearly, for all $n$ and all $1 \leq j \leq n$, $$ l_n \leq \frac{\ln (1 + c_{j,n})}{c_{j,n}} \leq k_n.$$ Using the first assumption, $l_n,k_n \to 1$. Assuming that $\lambda>0$, we write $$ l_n \sum_{j=1}^n c_{j,n} \leq \sum_{j=1}^n  \frac{\ln (1 + c_{j,n})}{c_{j,n}} c_{j,n} \leq k_n \sum_{j=1}^n c_{j,n},$$ and finally, using the squeeze theorem, and the second assumption, our result follows. (If $\lambda<0$, the inequalities switch sides.) My question: I haven't used the last assumtion, so I'm guessing something is missing in my solution.","Given: $$\max_{1\leq j \leq n} |c_{j,n}| \to 0$$ $$\sum_{j=1}^n  c_{j,n} \to \lambda$$ $$\sup_n \sum_{j=1}^n |c_{j,n}| < \infty,$$ show that: $$ \prod_{j=1}^n (1 + c_{j,n}) \to e^\lambda.$$ My partial solution: Taking the log of both sides, the conclusion is equivalent to $$ \sum_{j=1}^n \ln (1 + c_{j,n}) \to \lambda.$$ Indeed, $$ \sum_{j=1}^n \ln (1 + c_{j,n}) =  \sum_{j=1}^n  \frac{\ln (1 + c_{j,n})}{c_{j,n}} c_{j,n}.$$ Let $$ \overline{c}_{j,n} := \max_{1\leq j \leq n} c_{j,n},$$ $$ \underline{c}_{j,n} := \min_{1\leq j \leq n} c_{j,n}.$$ Now define $$k_n := \frac{\ln (1 + \underline{c}_{j,n})}{\underline{c}_{j,n}},$$  and  $$l_n := \frac{\ln (1 + \overline{c}_{j,n})}{\overline{c}_{j,n}}.$$  Clearly, for all $n$ and all $1 \leq j \leq n$, $$ l_n \leq \frac{\ln (1 + c_{j,n})}{c_{j,n}} \leq k_n.$$ Using the first assumption, $l_n,k_n \to 1$. Assuming that $\lambda>0$, we write $$ l_n \sum_{j=1}^n c_{j,n} \leq \sum_{j=1}^n  \frac{\ln (1 + c_{j,n})}{c_{j,n}} c_{j,n} \leq k_n \sum_{j=1}^n c_{j,n},$$ and finally, using the squeeze theorem, and the second assumption, our result follows. (If $\lambda<0$, the inequalities switch sides.) My question: I haven't used the last assumtion, so I'm guessing something is missing in my solution.",,"['probability', 'sequences-and-series']"
8,What is the necessary and sufficient condition of Markov chain sample average converging to the expectation wrt the stationary distribution?,What is the necessary and sufficient condition of Markov chain sample average converging to the expectation wrt the stationary distribution?,,"The ergodic theorem says that for an irreducible and positive-recurrent Markov chain $P$, any distribution $\lambda$, and $x_n (n\geq0) \sim Markov(\lambda, P)$ then it follows that for any bounded function $f:I\rightarrow R$ $$P(\frac{1}{n}\sum^{n-1}_{k=0}f(x_k)\rightarrow \bar{f} \text{as } n\rightarrow\infty)=1$$ where $\bar{f}=\sum_{i\in I}\pi_if_i $ and $\pi$ is the unique stationary distribution (ref: ergodic theorem ). It seems being irreducible and positive-recurrent is a sufficient but not necessary condition here. As I can think of a reducible and transient Markov chain that has the same property (please correct if I'm wrong) $$P=\left[\begin{matrix}1&0\\1&0\end{matrix}\right]$$ where the unique stationary distribution is $\pi=[1,0]$. So what is the necessary and sufficient condition for such property to hold? It seems the only case that this property will fail is when the limit of the average probability is not equal to the stationary distribution $$\lim_{n\rightarrow\infty}\frac{1}{n}\sum^{n-1}_{k=0}p(x_k)\neq \pi.$$ The only case I can think of is when there're more than one closed classes, so is the necessary and sufficient condition having one closed and positive recurrent communicating class (basically go from irreducible to one closed class compared to the original sufficient condition)?","The ergodic theorem says that for an irreducible and positive-recurrent Markov chain $P$, any distribution $\lambda$, and $x_n (n\geq0) \sim Markov(\lambda, P)$ then it follows that for any bounded function $f:I\rightarrow R$ $$P(\frac{1}{n}\sum^{n-1}_{k=0}f(x_k)\rightarrow \bar{f} \text{as } n\rightarrow\infty)=1$$ where $\bar{f}=\sum_{i\in I}\pi_if_i $ and $\pi$ is the unique stationary distribution (ref: ergodic theorem ). It seems being irreducible and positive-recurrent is a sufficient but not necessary condition here. As I can think of a reducible and transient Markov chain that has the same property (please correct if I'm wrong) $$P=\left[\begin{matrix}1&0\\1&0\end{matrix}\right]$$ where the unique stationary distribution is $\pi=[1,0]$. So what is the necessary and sufficient condition for such property to hold? It seems the only case that this property will fail is when the limit of the average probability is not equal to the stationary distribution $$\lim_{n\rightarrow\infty}\frac{1}{n}\sum^{n-1}_{k=0}p(x_k)\neq \pi.$$ The only case I can think of is when there're more than one closed classes, so is the necessary and sufficient condition having one closed and positive recurrent communicating class (basically go from irreducible to one closed class compared to the original sufficient condition)?",,"['probability', 'stochastic-processes', 'markov-chains']"
9,A longer series is better for a better team: Can you see this at a glance?,A longer series is better for a better team: Can you see this at a glance?,,"Here is problem 6 from chapter 2 of Introduction to Probability by Bertsekas and Tsitsiklis: The Celtics and the Lakers are set to play a playoff series of $n$   basketball games, where $n$ is odd. The Celtics have a probability $p$   of winning any one game, independent of other games. For any positive   integer $k$, find the values for $p$ for which $n = 2k + 1$ is better   for the Celtics than $n = 2k-1$. When I read this problem statement, I quickly felt certain based on intuition that a longer series is better when $p > 1/2$. Question: Is there a short proof that allows us to see this result at a glance ? Here is a solution to the problem which seems overly complicated, given how obvious the result is intuitively. The calculation below is surely not what my brain did in order to be certain that the answer must be $p > 1/2$. Imagine that the two teams play $2k + 1$ games, and let the random   variable $N$ be the number of games won by the Celtics during the   first $2k -1$ games. The probability $p_{2k+1}$ of the Celtics winning   the ""best of $2k+1$"" series (which requires winning at least $k + 1$   games in the series) is $$ \tag{1}p_{2k+1} = P(N \geq k+1) + P(N = k)(1 - (1-p)^2) + P(N = k-1)p^2. $$ On the other hand, the probability   $p_{2k-1}$ of the Celtics winning a ""best of $2k - 1$"" series is  $$ \tag{2} p_{2k-1} = P(N \geq k + 1) + P(N=k). $$ Notice that $P(N=k) = \binom{2k-1}{k}p^k(1-p)^{k-1}$ and $$ P(N = k-1) = \binom{2k-1}{k-1}p^{k-1}(1-p)^k = \binom{2k-1}{k}p^{k-1}(1-p)^k. $$   Comparing $(1)$ and $(2)$, we see that \begin{align} p_{2k+1} > p_{2k-1}  &\iff P(N=k-1)p^2 > P(N=k)(1-p)^2 \\ &\iff p^{k+1}(1-p)^k > p^k(1-p)^{k+1} \\ &\iff p > \frac12. \end{align} If there is no simpler proof, then why are we so certain at the outset of what the answer must be?","Here is problem 6 from chapter 2 of Introduction to Probability by Bertsekas and Tsitsiklis: The Celtics and the Lakers are set to play a playoff series of $n$   basketball games, where $n$ is odd. The Celtics have a probability $p$   of winning any one game, independent of other games. For any positive   integer $k$, find the values for $p$ for which $n = 2k + 1$ is better   for the Celtics than $n = 2k-1$. When I read this problem statement, I quickly felt certain based on intuition that a longer series is better when $p > 1/2$. Question: Is there a short proof that allows us to see this result at a glance ? Here is a solution to the problem which seems overly complicated, given how obvious the result is intuitively. The calculation below is surely not what my brain did in order to be certain that the answer must be $p > 1/2$. Imagine that the two teams play $2k + 1$ games, and let the random   variable $N$ be the number of games won by the Celtics during the   first $2k -1$ games. The probability $p_{2k+1}$ of the Celtics winning   the ""best of $2k+1$"" series (which requires winning at least $k + 1$   games in the series) is $$ \tag{1}p_{2k+1} = P(N \geq k+1) + P(N = k)(1 - (1-p)^2) + P(N = k-1)p^2. $$ On the other hand, the probability   $p_{2k-1}$ of the Celtics winning a ""best of $2k - 1$"" series is  $$ \tag{2} p_{2k-1} = P(N \geq k + 1) + P(N=k). $$ Notice that $P(N=k) = \binom{2k-1}{k}p^k(1-p)^{k-1}$ and $$ P(N = k-1) = \binom{2k-1}{k-1}p^{k-1}(1-p)^k = \binom{2k-1}{k}p^{k-1}(1-p)^k. $$   Comparing $(1)$ and $(2)$, we see that \begin{align} p_{2k+1} > p_{2k-1}  &\iff P(N=k-1)p^2 > P(N=k)(1-p)^2 \\ &\iff p^{k+1}(1-p)^k > p^k(1-p)^{k+1} \\ &\iff p > \frac12. \end{align} If there is no simpler proof, then why are we so certain at the outset of what the answer must be?",,"['probability', 'alternative-proof']"
10,Where is the mistake in the argument? (And two conjectures),Where is the mistake in the argument? (And two conjectures),,"Let $n$ be a natural number. $\Omega = \{ d : d | n \}$, For $A\subset \Omega$ define the probability for $A$ as : $$P(A) = \frac{1}{\sigma(n)}\sum_{d\in A}{d}$$ Consider the set $B = \{d \in \Omega |d \equiv 0 (2) \}$. Let $a = v_2(n)$. Then (first conjecture) $$P(B) = \frac{2^{a+1}-2}{2^{a+1}-1}$$ We have $E(d) = \sum_{d|n} {d \cdot P(d)} = \sum_{d|n} { d \cdot \frac{d}{\sigma(n)}} = \frac{\sigma_2(n)}{\sigma(n)}$ Second conjecture: $|B| = a \cdot b$, where $n = 2^a \cdot p_1^{a_1}\cdots p_r^{a_r}$ is the factorization of $n$, with $a$ possibly $=0$ and $b = (a_1+1)\dots(a_r+1)$. Consider $Z = \sum_{d \in B} {d}$ and consider the random variable: $Y_d = 1$ if $d \equiv 0 ( 2) $, otherwise $= 0$. Then $Z = \sum_{d|n} Y_d d$ is a random variable. Then on the one hand we have: $E(Z) = \sum_{d \in B}{E(d)} = \sum_{d \in B}{\frac{\sigma_2(n)}{\sigma(n)}} = a b \frac{\sigma_2(n)}{\sigma(n)}$ On the other hand we have $P(B) = \frac{Z}{\sigma(n)}$ hence solving for $Z$ we get: $$Z = \sum_{d|n}{d} \cdot \frac{2^{a+1}-2}{2^{a+1}-1}$$ From this it follows that: $$E(Z) =  \frac{2^{a+1}-2}{2^{a+1}-1} \sum_{d|n}{E(d)} =  \frac{2^{a+1}-2}{2^{a+1}-1} \sum_{d|n}{\frac{\sigma_2(n)}{\sigma(n)}} = \frac{2^{a+1}-2}{2^{a+1}-1} \tau(n) \cdot \frac{\sigma_2(n)}{\sigma(n)}$$ Hence we get: $$a b \frac{\sigma_2(n)}{\sigma(n)} = \frac{2^{a+1}-2}{2^{a+1}-1} \tau(n) \cdot \frac{\sigma_2(n)}{\sigma(n)}$$ from which it follows: $$ab = \tau(n) \cdot \frac{2^{a+1}-2}{2^{a+1}-1}$$ But for example for $n=6$ this is wrong, so where is the mistake in the argument? If you happen to have a proof for one of the conjectures, that would also be fine.","Let $n$ be a natural number. $\Omega = \{ d : d | n \}$, For $A\subset \Omega$ define the probability for $A$ as : $$P(A) = \frac{1}{\sigma(n)}\sum_{d\in A}{d}$$ Consider the set $B = \{d \in \Omega |d \equiv 0 (2) \}$. Let $a = v_2(n)$. Then (first conjecture) $$P(B) = \frac{2^{a+1}-2}{2^{a+1}-1}$$ We have $E(d) = \sum_{d|n} {d \cdot P(d)} = \sum_{d|n} { d \cdot \frac{d}{\sigma(n)}} = \frac{\sigma_2(n)}{\sigma(n)}$ Second conjecture: $|B| = a \cdot b$, where $n = 2^a \cdot p_1^{a_1}\cdots p_r^{a_r}$ is the factorization of $n$, with $a$ possibly $=0$ and $b = (a_1+1)\dots(a_r+1)$. Consider $Z = \sum_{d \in B} {d}$ and consider the random variable: $Y_d = 1$ if $d \equiv 0 ( 2) $, otherwise $= 0$. Then $Z = \sum_{d|n} Y_d d$ is a random variable. Then on the one hand we have: $E(Z) = \sum_{d \in B}{E(d)} = \sum_{d \in B}{\frac{\sigma_2(n)}{\sigma(n)}} = a b \frac{\sigma_2(n)}{\sigma(n)}$ On the other hand we have $P(B) = \frac{Z}{\sigma(n)}$ hence solving for $Z$ we get: $$Z = \sum_{d|n}{d} \cdot \frac{2^{a+1}-2}{2^{a+1}-1}$$ From this it follows that: $$E(Z) =  \frac{2^{a+1}-2}{2^{a+1}-1} \sum_{d|n}{E(d)} =  \frac{2^{a+1}-2}{2^{a+1}-1} \sum_{d|n}{\frac{\sigma_2(n)}{\sigma(n)}} = \frac{2^{a+1}-2}{2^{a+1}-1} \tau(n) \cdot \frac{\sigma_2(n)}{\sigma(n)}$$ Hence we get: $$a b \frac{\sigma_2(n)}{\sigma(n)} = \frac{2^{a+1}-2}{2^{a+1}-1} \tau(n) \cdot \frac{\sigma_2(n)}{\sigma(n)}$$ from which it follows: $$ab = \tau(n) \cdot \frac{2^{a+1}-2}{2^{a+1}-1}$$ But for example for $n=6$ this is wrong, so where is the mistake in the argument? If you happen to have a proof for one of the conjectures, that would also be fine.",,"['probability', 'proof-verification']"
11,Why is the probability of picking an odd number from the set of natural numbers not $\frac{1}{2}$?,Why is the probability of picking an odd number from the set of natural numbers not ?,\frac{1}{2},"Why is the probability of picking an odd number from the set of natural numbers not $\dfrac{1}{2}$? Could anyone explain it to me in simple terms? I am only curious about the reason why and that's the reason why I asked for a ""simple"" explanation. I remember my teacher mentioning that it is because the set is infinite. Is that right? can someone elaborate?","Why is the probability of picking an odd number from the set of natural numbers not $\dfrac{1}{2}$? Could anyone explain it to me in simple terms? I am only curious about the reason why and that's the reason why I asked for a ""simple"" explanation. I remember my teacher mentioning that it is because the set is infinite. Is that right? can someone elaborate?",,['probability']
12,Bounding tail conditional expectation of a random variable given variance,Bounding tail conditional expectation of a random variable given variance,,"Given a random variable $X$ with CDF $F(X)$, mean $E(X)=0$, and variance $Var(X) =\sigma^2$, I would like to bound the tail conditional expectation where $X$ is in the tail with probability $1-p$: $E(X|X\geq F^{-1}(p)) = \frac{1}{1-p}\int_{F^{-1}(p)}^\infty X dF(X)$ A nice way to get an upper bound is via a Chebyshev-type inequality: https://projecteuclid.org/download/pdf_1/euclid.aoms/1177697276 , which suggests: $E(X|X\geq F^{-1}(p)) \leq \sigma \sqrt{\frac{p}{1-p}}$ But how can we get a lower bound? Intuitively, since $E(X) = 0$, we must have: $E(X|X\geq F^{-1}(p)) \geq 0$ But that doesn't use the dispersion of the RV at all. Intuitively, if $\sigma$ is large and $E(X)=0$, the lower bound should be large, so the lower bound should grow with $\sigma$. But I have no idea how to formalize it. Any ideas would be greatly appreciated.","Given a random variable $X$ with CDF $F(X)$, mean $E(X)=0$, and variance $Var(X) =\sigma^2$, I would like to bound the tail conditional expectation where $X$ is in the tail with probability $1-p$: $E(X|X\geq F^{-1}(p)) = \frac{1}{1-p}\int_{F^{-1}(p)}^\infty X dF(X)$ A nice way to get an upper bound is via a Chebyshev-type inequality: https://projecteuclid.org/download/pdf_1/euclid.aoms/1177697276 , which suggests: $E(X|X\geq F^{-1}(p)) \leq \sigma \sqrt{\frac{p}{1-p}}$ But how can we get a lower bound? Intuitively, since $E(X) = 0$, we must have: $E(X|X\geq F^{-1}(p)) \geq 0$ But that doesn't use the dispersion of the RV at all. Intuitively, if $\sigma$ is large and $E(X)=0$, the lower bound should be large, so the lower bound should grow with $\sigma$. But I have no idea how to formalize it. Any ideas would be greatly appreciated.",,"['probability', 'probability-theory', 'random-variables', 'conditional-expectation', 'upper-lower-bounds']"
13,Distribution continuity of an AR(1) process,Distribution continuity of an AR(1) process,,"Let $\epsilon_n$ be i.i.d. random variables with mean $0$ and finite positive variance. Let $X=\sum_{k=0}^\infty \rho^k \epsilon_k$, where $0<|\rho|<1$. The series converges a.s. by the variance criterion. My question is: can one prove or disprove the claim $P(X=x)=0$ ($X$ has a continuous distribution)? Remark 1: The motivation comes from understanding the distribution property of the stationary solution of the AR(1) equation: $X_n=\rho X_{n-1}+\epsilon_n$, which has the same distribution as $X$ above. Remark 2: If $\epsilon_n$ has a continuous distribution, then the claim can be shown as follows: note that $X$ has the same distribution as $\rho X+\epsilon$, where $\epsilon$ is independent of $X$ and has the same distribution as $\epsilon_n$. Then by independence (disintegration), $$ P(X=x)=P(\rho X+\epsilon=x)=\int P(\epsilon=x-\rho u)~ dP_X(u)=0. $$ where $P_X$ is the distribution of $X$. Remark 3: A positive example of the claim when $\epsilon_n$ is discrete: if $P(\epsilon_n=\pm 1)=1/2$, $\rho=1/2$, then it is well-known that $X$ is uniformly distributed on [-2,2].","Let $\epsilon_n$ be i.i.d. random variables with mean $0$ and finite positive variance. Let $X=\sum_{k=0}^\infty \rho^k \epsilon_k$, where $0<|\rho|<1$. The series converges a.s. by the variance criterion. My question is: can one prove or disprove the claim $P(X=x)=0$ ($X$ has a continuous distribution)? Remark 1: The motivation comes from understanding the distribution property of the stationary solution of the AR(1) equation: $X_n=\rho X_{n-1}+\epsilon_n$, which has the same distribution as $X$ above. Remark 2: If $\epsilon_n$ has a continuous distribution, then the claim can be shown as follows: note that $X$ has the same distribution as $\rho X+\epsilon$, where $\epsilon$ is independent of $X$ and has the same distribution as $\epsilon_n$. Then by independence (disintegration), $$ P(X=x)=P(\rho X+\epsilon=x)=\int P(\epsilon=x-\rho u)~ dP_X(u)=0. $$ where $P_X$ is the distribution of $X$. Remark 3: A positive example of the claim when $\epsilon_n$ is discrete: if $P(\epsilon_n=\pm 1)=1/2$, $\rho=1/2$, then it is well-known that $X$ is uniformly distributed on [-2,2].",,"['probability', 'measure-theory', 'random-variables', 'time-series']"
14,Number of hand of cards with exactly 3 aces (Unsure if answer is correct),Number of hand of cards with exactly 3 aces (Unsure if answer is correct),,"Problem A pokerhand is 5 card subset, which is picked from 52 cards in total. Four of all cards are aces. Now how many there are such pokerhands that contain exactly 3 aces and 2 cards that can be anything. Also what is probability for obtaining exactly Attempt to solve Now we can pick 3 aces from total of 4 aces and pick any two cards that are not aces. $$ (\text{number of possible aces})(\text{number of possible not aces}) $$ $$ {{4}\choose{3}} {{48}\choose{2}}=54155$$ Now the probability would be simply: $$ \frac{\text{number of hands with aces}}{\text{number of all hands}} $$ $$ \frac{{{4}\choose{3}} {{48}\choose{2}}}{{{52}\choose{5}}}\approx 1.736079047\cdot 10^{-4}$$ We get very small probability of $\approx 0.017\%$ Combinatorics isn't strong point of mine so if someone could point out possible flaws that there are with my approach that would be highly appreciated. Also if the approach seems correct please comment that this seems correct.","Problem A pokerhand is 5 card subset, which is picked from 52 cards in total. Four of all cards are aces. Now how many there are such pokerhands that contain exactly 3 aces and 2 cards that can be anything. Also what is probability for obtaining exactly Attempt to solve Now we can pick 3 aces from total of 4 aces and pick any two cards that are not aces. $$ (\text{number of possible aces})(\text{number of possible not aces}) $$ $$ {{4}\choose{3}} {{48}\choose{2}}=54155$$ Now the probability would be simply: $$ \frac{\text{number of hands with aces}}{\text{number of all hands}} $$ $$ \frac{{{4}\choose{3}} {{48}\choose{2}}}{{{52}\choose{5}}}\approx 1.736079047\cdot 10^{-4}$$ We get very small probability of $\approx 0.017\%$ Combinatorics isn't strong point of mine so if someone could point out possible flaws that there are with my approach that would be highly appreciated. Also if the approach seems correct please comment that this seems correct.",,"['probability', 'combinatorics', 'proof-verification']"
15,Simple upper bound on the probability that the sum of $n$ dices rolls is equal to the most likely total,Simple upper bound on the probability that the sum of  dices rolls is equal to the most likely total,n,"Suppose $n$ $s$-sided (and fair) dice and are rolled, and consider the most likely value their total will take. Is there a simple / easy to state upper-bound on the probability that this total is rolled? I know you can bound this accurately using generating functions, but to use in the proof I'm working on requires summing over this probability for a range of (large) $n$ values,  which gets too complicated. I imagine it can also be approximated it using some distribution, but it's for a crypto proof so I really need an upper bound. I'm crudely upper bounding this with $1/s$ at the moment for all $n$. This follows by induction on n. Letting $X_i$ denote the distribution of the $i$th dice roll For $n = 1, Prob[X_1 = z] = 1/s$ for all $z \in [1, s]$, so the base case holds. Assume true for $n=k$, so $max_{z \in [k, ks]} Prob[\sum_{i = 1}^k {X_i} = z] \leq  1/s$. Then for $n = k+1$, and each $z \in [k+1, (k+1)s]$: $Prob[\sum_{i = 1}^{k+1} {X_i}=z$]                      $ = \sum_{h \in [k, ks]} Prob[X_{k+1} = z - \sum_{i = 1}^k X_i | \sum_{i = 1}^k X_i = h]Prob[\sum_{i = 1}^k X_i = h]$ $\leq \sum_{h \in [z - s, z-1]}1/s^2 = 1/s$, where the final inequality follows since by the induction hypothesis $Prob[\sum_{i = 1}^k X_i = h]\leq 1/s$ and $Prob[X_{k+1} = z - h] = 1/s$ if $h \in[z - s, z-1]$ and $0$ otherwise. I was wondering if there is any tighter (for large $n$) but still simple upper bound?","Suppose $n$ $s$-sided (and fair) dice and are rolled, and consider the most likely value their total will take. Is there a simple / easy to state upper-bound on the probability that this total is rolled? I know you can bound this accurately using generating functions, but to use in the proof I'm working on requires summing over this probability for a range of (large) $n$ values,  which gets too complicated. I imagine it can also be approximated it using some distribution, but it's for a crypto proof so I really need an upper bound. I'm crudely upper bounding this with $1/s$ at the moment for all $n$. This follows by induction on n. Letting $X_i$ denote the distribution of the $i$th dice roll For $n = 1, Prob[X_1 = z] = 1/s$ for all $z \in [1, s]$, so the base case holds. Assume true for $n=k$, so $max_{z \in [k, ks]} Prob[\sum_{i = 1}^k {X_i} = z] \leq  1/s$. Then for $n = k+1$, and each $z \in [k+1, (k+1)s]$: $Prob[\sum_{i = 1}^{k+1} {X_i}=z$]                      $ = \sum_{h \in [k, ks]} Prob[X_{k+1} = z - \sum_{i = 1}^k X_i | \sum_{i = 1}^k X_i = h]Prob[\sum_{i = 1}^k X_i = h]$ $\leq \sum_{h \in [z - s, z-1]}1/s^2 = 1/s$, where the final inequality follows since by the induction hypothesis $Prob[\sum_{i = 1}^k X_i = h]\leq 1/s$ and $Prob[X_{k+1} = z - h] = 1/s$ if $h \in[z - s, z-1]$ and $0$ otherwise. I was wondering if there is any tighter (for large $n$) but still simple upper bound?",,"['probability', 'combinatorics', 'statistics', 'cryptography']"
16,Estimator examples of non-normal probability distributions?,Estimator examples of non-normal probability distributions?,,"The maximum likelihood estimators for expectation $\mu$ and variance $\sigma^{2}$ of a normal distribution are: $$\hat{\mu} = \frac{1}{n}\sum_{i=1}^{n} \Big(x_{i}\Big)$$ and $$\hat{\sigma^{2}} = \frac{1}{n}\sum_{i=1}^{n}\Big((\hat{\mu}-x_{i})^{2}\Big)$$ They are used so frequently in statistics that it is easy to think that they apply to all probability distributions. What would be the mean, variance (or other parameter of the distribution) estimators for some of the non-normal probability distributions?","The maximum likelihood estimators for expectation $\mu$ and variance $\sigma^{2}$ of a normal distribution are: $$\hat{\mu} = \frac{1}{n}\sum_{i=1}^{n} \Big(x_{i}\Big)$$ and $$\hat{\sigma^{2}} = \frac{1}{n}\sum_{i=1}^{n}\Big((\hat{\mu}-x_{i})^{2}\Big)$$ They are used so frequently in statistics that it is easy to think that they apply to all probability distributions. What would be the mean, variance (or other parameter of the distribution) estimators for some of the non-normal probability distributions?",,"['probability', 'statistics', 'estimation']"
17,Conditional Expectation and the Tower Law,Conditional Expectation and the Tower Law,,"Let $X,Y$ be two independent random variables with a uniform distribution on the unit interval. The questions first asks for $E(X^k)$ where $k$ is some fixed constant that is at least 0. This calculation is easy, as it is just  $$\int_{0}^{1}x^{k}f_X(x)dx = \frac{1}{k+1}$$ Now, the question gets slightly trickier, and this is where my understanding of conditional expectation and conditional probability gets fuzzy. The question asks: what is $E(X^Y)$.? A hint is given, saying to use the tower law, i.e the fact that $E(X) = E(E(X|Y)) $. First, I am not sure what the inner expectation means. Most textbooks say it is a function of $Y$, which makes sense, but is not completely sound to me. Setting up this particular example with the tower law, we have: $$E(X^Y) = E(E(X^Y|Y))$$ After this I am somewhat stuck. I attempted to use the following: $$E(X^Y|Y) = \int_{0}^{\infty}yf_{X^Y|Y}(x,y)dy$$ but I am fairly unsure as to what this statement actually means . If someone could help me develop a better understanding of conditional expectation of R.Vs and conditional probability in general, I would appreciate it, moreso than just an answer to this question.","Let $X,Y$ be two independent random variables with a uniform distribution on the unit interval. The questions first asks for $E(X^k)$ where $k$ is some fixed constant that is at least 0. This calculation is easy, as it is just  $$\int_{0}^{1}x^{k}f_X(x)dx = \frac{1}{k+1}$$ Now, the question gets slightly trickier, and this is where my understanding of conditional expectation and conditional probability gets fuzzy. The question asks: what is $E(X^Y)$.? A hint is given, saying to use the tower law, i.e the fact that $E(X) = E(E(X|Y)) $. First, I am not sure what the inner expectation means. Most textbooks say it is a function of $Y$, which makes sense, but is not completely sound to me. Setting up this particular example with the tower law, we have: $$E(X^Y) = E(E(X^Y|Y))$$ After this I am somewhat stuck. I attempted to use the following: $$E(X^Y|Y) = \int_{0}^{\infty}yf_{X^Y|Y}(x,y)dy$$ but I am fairly unsure as to what this statement actually means . If someone could help me develop a better understanding of conditional expectation of R.Vs and conditional probability in general, I would appreciate it, moreso than just an answer to this question.",,"['calculus', 'probability', 'statistics', 'random-variables', 'conditional-expectation']"
18,Probabilistic Bounds for Balanced Random Walk,Probabilistic Bounds for Balanced Random Walk,,"For a balanced random walk with $2n$ steps, i.e. a walk that contains $n$ up-movements and $n$ down-movements, I'm trying to estimate some probabilistic results for the maximal deviation during the walk, i.e. how likely the walk is to stray far from the origin. This is akin to selecting from a bag of $2n$ balls, $n$ of which are red and $n$ of which are blue, without replacement. All walks must, of course, start and end at $(0,0$ and finish at $(2n,0)$. This is the same setup as the Ballot Problem with $p=q$. I'll define the maximal deviation $M$ by: $$ M: = \max_{1 \leq i \leq 2n}\left(\left| S_i\right|\right) $$ where $S_i$ is the partial sum of the values from the first $i$ steps. I'm initially interested in the expected maximal deviation $\mathbb{E}[M]$ and bounds of the form $\mathbb{P}[M \geq \alpha] \leq C_\alpha$. Now $\frac{S_i}{2n-i}$ is a Martingale, so Doob's maximal equality should be helpful for the latter, but I can't quite get there. Any help appreciated.","For a balanced random walk with $2n$ steps, i.e. a walk that contains $n$ up-movements and $n$ down-movements, I'm trying to estimate some probabilistic results for the maximal deviation during the walk, i.e. how likely the walk is to stray far from the origin. This is akin to selecting from a bag of $2n$ balls, $n$ of which are red and $n$ of which are blue, without replacement. All walks must, of course, start and end at $(0,0$ and finish at $(2n,0)$. This is the same setup as the Ballot Problem with $p=q$. I'll define the maximal deviation $M$ by: $$ M: = \max_{1 \leq i \leq 2n}\left(\left| S_i\right|\right) $$ where $S_i$ is the partial sum of the values from the first $i$ steps. I'm initially interested in the expected maximal deviation $\mathbb{E}[M]$ and bounds of the form $\mathbb{P}[M \geq \alpha] \leq C_\alpha$. Now $\frac{S_i}{2n-i}$ is a Martingale, so Doob's maximal equality should be helpful for the latter, but I can't quite get there. Any help appreciated.",,"['probability', 'combinatorics', 'random-walk']"
19,"If $n$ birds are sitting in circle, each pecks its left or right bird with equal probability. What is the distribution of number of pecked birds?","If  birds are sitting in circle, each pecks its left or right bird with equal probability. What is the distribution of number of pecked birds?",n,"If n birds are sitting in circle, each pecks its left or right bird with equal probability. What is the distribution of number of pecked birds? Note at least $\frac{n}{2}$ birds get pecked, so it cannot be binomial. Also note that analysis for number of unpecked birds is $\frac{n}{4}$ for $n > 2$, which is actually just a coincidence if you assume binomial. For $n=1$ and $n=2$ all birds are necessarily pecked. Also if there are $5$ birds a,b,c,d,e in order, if c is not pecked then both a and e must be pecked, so treating them as independent events are also not correct. The distribution looks like this for various values of $n$. (Divide by $2^n$ as to get probability) 1   {1 -> 2} 2   {2 -> 4} 3   {2 -> 6, 3 -> 2} 4   {2 -> 4, 3 -> 8, 4 -> 4} 5   {3 -> 10, 4 -> 20, 5 -> 2} 6   {4 -> 36, 5 -> 24, 6 -> 4} 7   {4 -> 14, 5 -> 70, 6 -> 42, 7 -> 2} 8   {4 -> 4, 5 -> 48, 6 -> 152, 7 -> 48, 8 -> 4} 9   {5 -> 18, 6 -> 168, 7 -> 252, 8 -> 72, 9 -> 2} 10  {6 -> 100, 7 -> 400, 8 -> 440, 9 -> 80, 10 -> 4} 11  {6 -> 22, 7 -> 330, 8 -> 924, 9 -> 660, 10 -> 110, 11 -> 2} 12  {6 -> 4, 7 -> 120, 8 -> 1020, 9 -> 1808, 10 -> 1020, 11 -> 120, 12 -> 4} 13  {7 -> 26, 8 -> 572, 9 -> 2574, 10 -> 3432, 11 -> 1430, 12 -> 156, 13 -> 2} 14  {8 -> 196, 9 -> 1960, 10 -> 6076, 11 -> 5936, 12 -> 2044, 13 -> 168, 14 -> 4} 15  {8 -> 30, 9 -> 910, 10 -> 6006, 11 -> 12870, 12 -> 10010, 13 -> 2730, 14 -> 210, 15 -> 2} 16  {8 -> 4, 9 -> 224, 10 -> 3696, 11 -> 15904, 12 -> 25880, 13 -> 15904, 14 -> 3696, 15 -> 224, 16 -> 4} 17  {9 -> 34, 10 -> 1360, 11 -> 12376, 12 -> 38896, 13 -> 48620, 14 -> 24752, 15 -> 4760, 16 -> 272, 17 -> 2} 18  {10 -> 324, 11 -> 6048, 12 -> 37296, 13 -> 87264, 14 -> 87768, 15 -> 36960, 16 -> 6192, 17 -> 288, 18 -> 4} 19  {10 -> 38, 11 -> 1938, 12 -> 23256, 13 -> 100776, 14 -> 184756, 15 -> 151164, 16 -> 54264, 17 -> 7752, 18 -> 342, 19 -> 2} 20  {10 -> 4, 11 -> 360, 12 -> 9780, 13 -> 77280, 14 -> 252360, 15 -> 369008, 16 -> 252360, 17 -> 77280, 18 -> 9780, 19 -> 360, 20 -> 4} 21  {11 -> 42, 12 -> 2660, 13 -> 40698, 14 -> 232560, 15 -> 587860, 16 -> 705432, 17 -> 406980, 18 -> 108528, 19 -> 11970, 20 -> 420, 21 -> 2} 22  {12 -> 484, 13 -> 14520, 14 -> 149556, 15 -> 638880, 16 -> 1294216, 17 -> 1292368, 18 -> 640200, 19 -> 148896, 20 -> 14740, 21 -> 440, 22 -> 4} 23  {12 -> 46, 13 -> 3542, 14 -> 67298, 15 -> 490314, 16 -> 1634380, 17 -> 2704156, 18 -> 2288132, 19 -> 980628, 20 -> 201894, 21 -> 17710, 22 -> 506, 23 -> 2} 24  {12 -> 4, 13 -> 528, 14 -> 21384, 15 -> 268752, 16 -> 1471932, 17 -> 3920928, 18 -> 5410160, 19 -> 3920928, 20 -> 1471932, 21 -> 268752, 22 -> 21384, 23 -> 528, 24 -> 4} 25  {13 -> 50, 14 -> 4600, 15 -> 106260, 16 -> 961400, 17 -> 4085950, 18 -> 8914800, 19 -> 10400600, 20 -> 6537520, 21 -> 2163150, 22 -> 354200, 23 -> 25300, 24 -> 600, 25 -> 2} 26  {14 -> 676, 15 -> 29744, 16 -> 461032, 17 -> 3123120, 18 -> 10626044, 19 -> 19311968, 20 -> 19318832, 21 -> 10620896, 22 -> 3125980, 23 -> 459888, 24 -> 30056, 25 -> 624, 26 -> 4} 27  {14 -> 54, 15 -> 5850, 16 -> 161460, 17 -> 1776060, 18 -> 9373650, 19 -> 26075790, 20 -> 40116600, 21 -> 34767720, 22 -> 16872570, 23 -> 4440150, 24 -> 592020, 25 -> 35100, 26 -> 702, 27 -> 2} 28  {14 -> 4, 15 -> 728, 16 -> 41132, 17 -> 752752, 18 -> 6218212, 19 -> 26242216, 20 -> 60849516, 21 -> 80226336, 22 -> 60849516, 23 -> 26242216, 24 -> 6218212, 25 -> 752752, 26 -> 41132, 27 -> 728, 28 -> 4} 29  {15 -> 58, 16 -> 7308, 17 -> 237510, 18 -> 3121560, 19 -> 20030010, 20 -> 69194580, 21 -> 135727830, 22 -> 155117520, 23 -> 103791870, 24 -> 40060020, 25 -> 8584290, 26 -> 950040, 27 -> 47502, 28 -> 812, 29 -> 2}","If n birds are sitting in circle, each pecks its left or right bird with equal probability. What is the distribution of number of pecked birds? Note at least $\frac{n}{2}$ birds get pecked, so it cannot be binomial. Also note that analysis for number of unpecked birds is $\frac{n}{4}$ for $n > 2$, which is actually just a coincidence if you assume binomial. For $n=1$ and $n=2$ all birds are necessarily pecked. Also if there are $5$ birds a,b,c,d,e in order, if c is not pecked then both a and e must be pecked, so treating them as independent events are also not correct. The distribution looks like this for various values of $n$. (Divide by $2^n$ as to get probability) 1   {1 -> 2} 2   {2 -> 4} 3   {2 -> 6, 3 -> 2} 4   {2 -> 4, 3 -> 8, 4 -> 4} 5   {3 -> 10, 4 -> 20, 5 -> 2} 6   {4 -> 36, 5 -> 24, 6 -> 4} 7   {4 -> 14, 5 -> 70, 6 -> 42, 7 -> 2} 8   {4 -> 4, 5 -> 48, 6 -> 152, 7 -> 48, 8 -> 4} 9   {5 -> 18, 6 -> 168, 7 -> 252, 8 -> 72, 9 -> 2} 10  {6 -> 100, 7 -> 400, 8 -> 440, 9 -> 80, 10 -> 4} 11  {6 -> 22, 7 -> 330, 8 -> 924, 9 -> 660, 10 -> 110, 11 -> 2} 12  {6 -> 4, 7 -> 120, 8 -> 1020, 9 -> 1808, 10 -> 1020, 11 -> 120, 12 -> 4} 13  {7 -> 26, 8 -> 572, 9 -> 2574, 10 -> 3432, 11 -> 1430, 12 -> 156, 13 -> 2} 14  {8 -> 196, 9 -> 1960, 10 -> 6076, 11 -> 5936, 12 -> 2044, 13 -> 168, 14 -> 4} 15  {8 -> 30, 9 -> 910, 10 -> 6006, 11 -> 12870, 12 -> 10010, 13 -> 2730, 14 -> 210, 15 -> 2} 16  {8 -> 4, 9 -> 224, 10 -> 3696, 11 -> 15904, 12 -> 25880, 13 -> 15904, 14 -> 3696, 15 -> 224, 16 -> 4} 17  {9 -> 34, 10 -> 1360, 11 -> 12376, 12 -> 38896, 13 -> 48620, 14 -> 24752, 15 -> 4760, 16 -> 272, 17 -> 2} 18  {10 -> 324, 11 -> 6048, 12 -> 37296, 13 -> 87264, 14 -> 87768, 15 -> 36960, 16 -> 6192, 17 -> 288, 18 -> 4} 19  {10 -> 38, 11 -> 1938, 12 -> 23256, 13 -> 100776, 14 -> 184756, 15 -> 151164, 16 -> 54264, 17 -> 7752, 18 -> 342, 19 -> 2} 20  {10 -> 4, 11 -> 360, 12 -> 9780, 13 -> 77280, 14 -> 252360, 15 -> 369008, 16 -> 252360, 17 -> 77280, 18 -> 9780, 19 -> 360, 20 -> 4} 21  {11 -> 42, 12 -> 2660, 13 -> 40698, 14 -> 232560, 15 -> 587860, 16 -> 705432, 17 -> 406980, 18 -> 108528, 19 -> 11970, 20 -> 420, 21 -> 2} 22  {12 -> 484, 13 -> 14520, 14 -> 149556, 15 -> 638880, 16 -> 1294216, 17 -> 1292368, 18 -> 640200, 19 -> 148896, 20 -> 14740, 21 -> 440, 22 -> 4} 23  {12 -> 46, 13 -> 3542, 14 -> 67298, 15 -> 490314, 16 -> 1634380, 17 -> 2704156, 18 -> 2288132, 19 -> 980628, 20 -> 201894, 21 -> 17710, 22 -> 506, 23 -> 2} 24  {12 -> 4, 13 -> 528, 14 -> 21384, 15 -> 268752, 16 -> 1471932, 17 -> 3920928, 18 -> 5410160, 19 -> 3920928, 20 -> 1471932, 21 -> 268752, 22 -> 21384, 23 -> 528, 24 -> 4} 25  {13 -> 50, 14 -> 4600, 15 -> 106260, 16 -> 961400, 17 -> 4085950, 18 -> 8914800, 19 -> 10400600, 20 -> 6537520, 21 -> 2163150, 22 -> 354200, 23 -> 25300, 24 -> 600, 25 -> 2} 26  {14 -> 676, 15 -> 29744, 16 -> 461032, 17 -> 3123120, 18 -> 10626044, 19 -> 19311968, 20 -> 19318832, 21 -> 10620896, 22 -> 3125980, 23 -> 459888, 24 -> 30056, 25 -> 624, 26 -> 4} 27  {14 -> 54, 15 -> 5850, 16 -> 161460, 17 -> 1776060, 18 -> 9373650, 19 -> 26075790, 20 -> 40116600, 21 -> 34767720, 22 -> 16872570, 23 -> 4440150, 24 -> 592020, 25 -> 35100, 26 -> 702, 27 -> 2} 28  {14 -> 4, 15 -> 728, 16 -> 41132, 17 -> 752752, 18 -> 6218212, 19 -> 26242216, 20 -> 60849516, 21 -> 80226336, 22 -> 60849516, 23 -> 26242216, 24 -> 6218212, 25 -> 752752, 26 -> 41132, 27 -> 728, 28 -> 4} 29  {15 -> 58, 16 -> 7308, 17 -> 237510, 18 -> 3121560, 19 -> 20030010, 20 -> 69194580, 21 -> 135727830, 22 -> 155117520, 23 -> 103791870, 24 -> 40060020, 25 -> 8584290, 26 -> 950040, 27 -> 47502, 28 -> 812, 29 -> 2}",,"['probability', 'probability-distributions']"
20,Average shortest distance between some random points in a box,Average shortest distance between some random points in a box,,"Suppose there is a square box with side length $m$ (measured in pixels). Let there be $n$ points in this box, distributed uniformly within the box (with integer coordinates, aligned to a pixel grid). If we take from each point the Euclidean distance to its nearest neighbor, what would be the expected value of this distance averaged over all points? My actual problem is about a discrete pixel grid, an $m\times m$ bitmap image, but if that's easier I would be happy with a continuous solution. A more general solution e.g. for a rectangle instead of a square box is welcome, but at this point it is not necessary. I found similar questions about the continous case, but without answers. For me it wouldn't be easy to generalise the case for two points only.","Suppose there is a square box with side length $m$ (measured in pixels). Let there be $n$ points in this box, distributed uniformly within the box (with integer coordinates, aligned to a pixel grid). If we take from each point the Euclidean distance to its nearest neighbor, what would be the expected value of this distance averaged over all points? My actual problem is about a discrete pixel grid, an $m\times m$ bitmap image, but if that's easier I would be happy with a continuous solution. A more general solution e.g. for a rectangle instead of a square box is welcome, but at this point it is not necessary. I found similar questions about the continous case, but without answers. For me it wouldn't be easy to generalise the case for two points only.",,"['probability', 'discrete-mathematics', 'euclidean-geometry', 'uniform-distribution', 'geometric-probability']"
21,"Simple probability question, with faulty screws.","Simple probability question, with faulty screws.",,"I have translated the problem as follows: A factory produces screws, the probability of them being faulty is 0.01 independently. The factory makes a box with 10 screws and recalls the boxes containing 2 or more faulty screws. What is the percentage of boxes that the factory has to recall?","I have translated the problem as follows: A factory produces screws, the probability of them being faulty is 0.01 independently. The factory makes a box with 10 screws and recalls the boxes containing 2 or more faulty screws. What is the percentage of boxes that the factory has to recall?",,"['probability', 'combinatorics', 'percentages']"
22,First to 1000 rolls wins,First to 1000 rolls wins,,"You and your friend each have a standard $6$-sided die with sides numbered $1, 2, \ldots 6$, every side has an equal probability of arising in a random roll. You throw the cube first* the number that land, is the amount of times your friend need to throw his cube. The sum of all the numbers that landed from the amount of times your friend threw, is the amount of times you need to throw your dice. The sum of all the numbers that landed from the amount of times your friend threw, is the amount of times you need to throw your dice. And then it goes and goes. What is the probability that you will be the first one who need to throw more than $1000$ throws.  For example: You threw 3 Your friend threw 3 times and got: 2,5,6. The sum is 13. You threw $13$ times and got: $5,2,3,4,6,1,2,5,3,4,1,3,6$. The sum is $45$. Your friend threw $45$ times and got: ..... The sum is $X$ You threw $X$ times and got: .... The sum is $Y$ .... What is the probability that you threw before your friend more than $1000$ throws. *I think it would be interesting the same question but you throw second.","You and your friend each have a standard $6$-sided die with sides numbered $1, 2, \ldots 6$, every side has an equal probability of arising in a random roll. You throw the cube first* the number that land, is the amount of times your friend need to throw his cube. The sum of all the numbers that landed from the amount of times your friend threw, is the amount of times you need to throw your dice. The sum of all the numbers that landed from the amount of times your friend threw, is the amount of times you need to throw your dice. And then it goes and goes. What is the probability that you will be the first one who need to throw more than $1000$ throws.  For example: You threw 3 Your friend threw 3 times and got: 2,5,6. The sum is 13. You threw $13$ times and got: $5,2,3,4,6,1,2,5,3,4,1,3,6$. The sum is $45$. Your friend threw $45$ times and got: ..... The sum is $X$ You threw $X$ times and got: .... The sum is $Y$ .... What is the probability that you threw before your friend more than $1000$ throws. *I think it would be interesting the same question but you throw second.",,['probability']
23,What is the probability of traversing through an $n \times n$ board in exactly $K$ moves by moving uniformly at random?,What is the probability of traversing through an  board in exactly  moves by moving uniformly at random?,n \times n K,"On a $n$-row $n$-column board, we want to move a piece from the square on the lower left corner to the square on the upper right corner following the commands of a light that blinks in $3$ different colors: Each color represents a move: up, right, or diagonal (up and to the right) . The probability of each one blinking is equal. What is the probability of reaching the square in the upper right corner using $K$ moves, knowing that when the piece reaches a square that it's impossible to make $1$ of the $3$ moves, that color stops blinking?","On a $n$-row $n$-column board, we want to move a piece from the square on the lower left corner to the square on the upper right corner following the commands of a light that blinks in $3$ different colors: Each color represents a move: up, right, or diagonal (up and to the right) . The probability of each one blinking is equal. What is the probability of reaching the square in the upper right corner using $K$ moves, knowing that when the piece reaches a square that it's impossible to make $1$ of the $3$ moves, that color stops blinking?",,"['probability', 'combinatorics']"
24,Number of ways to divide a group of N people into 2 groups,Number of ways to divide a group of N people into 2 groups,,"I've seen a bunch of questions about dividing a group of $N$ into groups of a specified size, but I am unsure about how to calculate the total number of ways to divide a group of $N$ people into $2$ distinct groups.. The questions states that one group could be empty, and that a group could have sizes from $0, 1, 2, ..., N$. The question then goes on to ask what is the probability that one of the groups has exactly $3$ people in it. I presume this would be calculated by dividing $N\choose 3$ by the total number of ways calculated above, but any other comments would be greatly appreciated!","I've seen a bunch of questions about dividing a group of $N$ into groups of a specified size, but I am unsure about how to calculate the total number of ways to divide a group of $N$ people into $2$ distinct groups.. The questions states that one group could be empty, and that a group could have sizes from $0, 1, 2, ..., N$. The question then goes on to ask what is the probability that one of the groups has exactly $3$ people in it. I presume this would be calculated by dividing $N\choose 3$ by the total number of ways calculated above, but any other comments would be greatly appreciated!",,"['probability', 'combinatorics', 'permutations', 'combinations']"
25,Understanding the notations of the expectation of a random variable,Understanding the notations of the expectation of a random variable,,"We know that if $P$ is a probability in the measurable space $(\mathbb{R}, \mathcal{B})$ , then we can define a distribuition function $F$ as following: $$F(x):= P((-\infty,x])), \quad \forall x \in \mathbb{R}$$ By the Carathéodory's extension theorem we can prove that the converse is also valid, that is: if $F$ is a distibuition function, then there is a unique $P_{\small{F}}$ in $(\mathbb{R}, \mathcal{B})$ that $$F(x)= P_{\small{F}}((-\infty,x])),\quad \forall x \in \mathbb{R}$$ In other words, there is a one-to-one correspondence between the set of probabilities in $(\mathbb{R}, \mathcal{B})$ and the set of all distribuition functions. $Remake:$ :: If $X:(\Omega,\mathcal{F}, \mu) \to \mathbb{R}$ is a random variable, we can define a probability in $(\mathbb{R}, \mathcal{B})$ and a distribuition function, respectively, as following: $$P_{\small{X}}(B) := \mu(X \in B),\quad B \in \mathcal{B}$$ $$F_{\small{X}}(x) := P_{\small{X}}((-\infty, x]))= \mu(X \leq x), \quad x \in \mathbb{R}$$ A random variable is continue (absolutly?) if there is a density (non negative) function $f$ such that $$F_{\small{X}}(x) = \int_{-\infty}^{x}f(y)dy$$ I dont will write the Lebesgue integral definition, but it is supossed that the classical definition is well known. I would like to remember its notations $$E(X) = \int_{\Omega}Xd\mu = \int_{\Omega}X^{+}d\mu - \int_{\Omega}X^{-}d\mu$$ Although I consider the one-to-one correspondence between $F_{X}$ and $P_X$ , I can not find, besides the notations justificatives, good arguments for the following equivalences (for each iquality) $$\int_{\Omega}Xd\mu = \int_{\mathbb{R}} xdF_{\small{X}}(x) = \int_{\mathbb{R}} xdP_{\small{X}}(x) = \int_{\mathbb{R}} x f(x)dx$$ Some justificatives?","We know that if is a probability in the measurable space , then we can define a distribuition function as following: By the Carathéodory's extension theorem we can prove that the converse is also valid, that is: if is a distibuition function, then there is a unique in that In other words, there is a one-to-one correspondence between the set of probabilities in and the set of all distribuition functions. :: If is a random variable, we can define a probability in and a distribuition function, respectively, as following: A random variable is continue (absolutly?) if there is a density (non negative) function such that I dont will write the Lebesgue integral definition, but it is supossed that the classical definition is well known. I would like to remember its notations Although I consider the one-to-one correspondence between and , I can not find, besides the notations justificatives, good arguments for the following equivalences (for each iquality) Some justificatives?","P (\mathbb{R}, \mathcal{B}) F F(x):= P((-\infty,x])), \quad \forall x \in \mathbb{R} F P_{\small{F}} (\mathbb{R}, \mathcal{B}) F(x)= P_{\small{F}}((-\infty,x])),\quad \forall x \in \mathbb{R} (\mathbb{R}, \mathcal{B}) Remake: X:(\Omega,\mathcal{F}, \mu) \to \mathbb{R} (\mathbb{R}, \mathcal{B}) P_{\small{X}}(B) := \mu(X \in B),\quad B \in \mathcal{B} F_{\small{X}}(x) := P_{\small{X}}((-\infty, x]))= \mu(X \leq x), \quad x \in \mathbb{R} f F_{\small{X}}(x) = \int_{-\infty}^{x}f(y)dy E(X) = \int_{\Omega}Xd\mu = \int_{\Omega}X^{+}d\mu - \int_{\Omega}X^{-}d\mu F_{X} P_X \int_{\Omega}Xd\mu = \int_{\mathbb{R}} xdF_{\small{X}}(x) = \int_{\mathbb{R}} xdP_{\small{X}}(x) = \int_{\mathbb{R}} x f(x)dx","['probability', 'notation', 'expected-value']"
26,Finding the mgf when moments are given,Finding the mgf when moments are given,,"Let $X$ be a random variable and it is known that the mgf of $X$ exists. If the $k$th moment is given by $m_k=\mathbb E[X^k]=\frac{(2k+1)!}{k!2^k}$ for $k=0, 1, ...$ Problem: Find the mgf of $X$. My attempt: The mgf of $X$ is $M_X (t)= \sum_{k=0}^\infty \frac{m_k}{k!}t^k=\sum_{k=0}^\infty \frac{(2k+1)!}{(k!)^22^k}t^k$. However, I have no idea how to proceed further. What should I do?","Let $X$ be a random variable and it is known that the mgf of $X$ exists. If the $k$th moment is given by $m_k=\mathbb E[X^k]=\frac{(2k+1)!}{k!2^k}$ for $k=0, 1, ...$ Problem: Find the mgf of $X$. My attempt: The mgf of $X$ is $M_X (t)= \sum_{k=0}^\infty \frac{m_k}{k!}t^k=\sum_{k=0}^\infty \frac{(2k+1)!}{(k!)^22^k}t^k$. However, I have no idea how to proceed further. What should I do?",,"['probability', 'statistics', 'moment-generating-functions']"
27,Is the Monotone Likelihood Ratio Property (MLRP) preserved under mean-preserving spreads?,Is the Monotone Likelihood Ratio Property (MLRP) preserved under mean-preserving spreads?,,"I have a spent a long time trying to find an answer to this question, so any help would be much appreciated. Let $X_1$ be a random variable (r.v.) with distribution $f_1$ and $X_2$ be a r.v. with distribution $f_2$. Suppose $f_1$ and $f_2$ satisfy the monotone likelihood ratio property (MLRP) such that \begin{equation} \frac{f_1(x_1)}{f_2(x_1)}\geq \frac{f_1(x_0)}{f_2(x_0)} ; \ \forall x_1\geq x_0  \end{equation} Let $Y_i = X_i + e_i $ be a mean preserving spread of $X_i$, with $e_i$ ~ $N(0,1)$, and with distribution $g_i(y)$, for $i=1,2$.  Does the MLRP hold for $g_1(y)$ and $g_2(y)$?","I have a spent a long time trying to find an answer to this question, so any help would be much appreciated. Let $X_1$ be a random variable (r.v.) with distribution $f_1$ and $X_2$ be a r.v. with distribution $f_2$. Suppose $f_1$ and $f_2$ satisfy the monotone likelihood ratio property (MLRP) such that \begin{equation} \frac{f_1(x_1)}{f_2(x_1)}\geq \frac{f_1(x_0)}{f_2(x_0)} ; \ \forall x_1\geq x_0  \end{equation} Let $Y_i = X_i + e_i $ be a mean preserving spread of $X_i$, with $e_i$ ~ $N(0,1)$, and with distribution $g_i(y)$, for $i=1,2$.  Does the MLRP hold for $g_1(y)$ and $g_2(y)$?",,"['probability', 'probability-theory', 'statistics']"
28,Entropy of bits on a chessboard,Entropy of bits on a chessboard,,"Suppose we have an $n$ by $n$ chessboard and each square can be in two states: ""on"" or ""off"". At time $t=0$ all bits are off. Every second one square is selected at random uniformly out of the $n^2$ squares and the corresponding bit is flipped. How to define entropy of ""on"" bits in this process and show that it increases? This came out of a model of a gas in a container, where we divide the container using a grid. Each grid point is ""on"" or ""off"" iff there is a gas molecule in the corresponding square. It should increase on average right? Seems to me it could be related to the variance of the ""on"" squares but I am no expert in the field, any hints? Thanks in advance!","Suppose we have an $n$ by $n$ chessboard and each square can be in two states: ""on"" or ""off"". At time $t=0$ all bits are off. Every second one square is selected at random uniformly out of the $n^2$ squares and the corresponding bit is flipped. How to define entropy of ""on"" bits in this process and show that it increases? This came out of a model of a gas in a container, where we divide the container using a grid. Each grid point is ""on"" or ""off"" iff there is a gas molecule in the corresponding square. It should increase on average right? Seems to me it could be related to the variance of the ""on"" squares but I am no expert in the field, any hints? Thanks in advance!",,"['probability', 'geometry', 'statistics', 'markov-process']"
29,"If I double my lottery tickets, do I double my chances of winning? [duplicate]","If I double my lottery tickets, do I double my chances of winning? [duplicate]",,"This question already has answers here : Probability of winning the lottery the more you play it? (4 answers) Closed last year . After I buy one lottery ticket with odds of $14M$ to one, if I buy another ticket with different numbers, does this slash the odds to $7M$ to one? If so, if I double my tickets again to $4$ Tickets, it will halve again to $3.5M$ to one? So $8$ tickets will be $1.75M$ to one? $16$ Tickets $\rightarrow.875M$ to one $32 \rightarrow .4475$ M to one $64 \rightarrow 218750$ to one $128 \rightarrow 109375$ to one $256 \rightarrow 54587$ to one Something seems wrong here?","This question already has answers here : Probability of winning the lottery the more you play it? (4 answers) Closed last year . After I buy one lottery ticket with odds of to one, if I buy another ticket with different numbers, does this slash the odds to to one? If so, if I double my tickets again to Tickets, it will halve again to to one? So tickets will be to one? Tickets to one M to one to one to one to one Something seems wrong here?",14M 7M 4 3.5M 8 1.75M 16 \rightarrow.875M 32 \rightarrow .4475 64 \rightarrow 218750 128 \rightarrow 109375 256 \rightarrow 54587,"['probability', 'lotteries']"
30,show $(1+\frac{a}{n})^{n-k}=e^a(1-\frac{a(a+k)}{2n})+o(\frac{1}{n})$ for a fixed nonnegative integer $k$ as $n\to\infty$?,show  for a fixed nonnegative integer  as ?,(1+\frac{a}{n})^{n-k}=e^a(1-\frac{a(a+k)}{2n})+o(\frac{1}{n}) k n\to\infty,"How to show $(1+\frac{a}{n})^{n-k}=e^a(1-\frac{a(a+k)}{2n})+o(\frac{1}{n})$ for a fixed nonnegative integer $k$ as $n\to\infty$? We already known that $(1+\frac{a}{n})^{n}\to e^a$ as $n\to\infty$, but I don't know how to deal with $(1+\frac{a}{n})^{-k}$. Could someone kindly help? Thanks. http://sites.stat.psu.edu/~dhunter/asymp/fall2004/lectures/edgeworth.pdf","How to show $(1+\frac{a}{n})^{n-k}=e^a(1-\frac{a(a+k)}{2n})+o(\frac{1}{n})$ for a fixed nonnegative integer $k$ as $n\to\infty$? We already known that $(1+\frac{a}{n})^{n}\to e^a$ as $n\to\infty$, but I don't know how to deal with $(1+\frac{a}{n})^{-k}$. Could someone kindly help? Thanks. http://sites.stat.psu.edu/~dhunter/asymp/fall2004/lectures/edgeworth.pdf",,"['calculus', 'probability', 'asymptotics', 'approximation']"
31,Why is variance defined this way? [duplicate],Why is variance defined this way? [duplicate],,"This question already has answers here : Motivation behind standard deviation? (6 answers) Closed 7 years ago . I don't understand why $Var(X) = E((X-\mu)^2)$. It's defined as the ""expected value of the square of the deviation of $X$ from the mean"" but I don't understand why it couldn't be $E(X-\mu)$ as that seems more intuitive for ""deviation from the mean"". Is the purpose of the squaring to make deviations positive? Because if so, why not just $E(|X-\mu|)$ instead? What's the point of the squaring?","This question already has answers here : Motivation behind standard deviation? (6 answers) Closed 7 years ago . I don't understand why $Var(X) = E((X-\mu)^2)$. It's defined as the ""expected value of the square of the deviation of $X$ from the mean"" but I don't understand why it couldn't be $E(X-\mu)$ as that seems more intuitive for ""deviation from the mean"". Is the purpose of the squaring to make deviations positive? Because if so, why not just $E(|X-\mu|)$ instead? What's the point of the squaring?",,"['probability', 'statistics', 'standard-deviation', 'variance']"
32,Central Limit Theorem Proof using Characteristic Functions,Central Limit Theorem Proof using Characteristic Functions,,"I have my proof of the Central Limit Theorem using characteristic functions in which the main steps are: Set up: Let $X_1, X_2, \dots, X_n$ be a sequence of iid random variables with mean $\mu$ and variance $\sigma^2$. Let $Y_i=\frac{X_i-\mu}{\sigma}$ and $S_n=\sum_{i=1}^{n}\frac{1}{\sqrt{n}}Y_i$. 1) Expand the characteristic function $\psi_{S_n}(t)=\psi_{Y}\left(\frac{t}{\sqrt{n}}\right)^n$ 2)Taylor expand the characteristic function: $$ \psi_{S_n}=(1+\frac{it}{\sqrt{n}}\mathbb{E}(Y)-\frac{t^2}{2n}\mathbb{E}(Y^2)+\dots)^n $$ Which we can then truncate with a bounded function $H(t)$: $$ \psi_{S_n}=(1+\frac{it}{\sqrt{n}}\mathbb{E}(Y)-\frac{t^2}{2n}\mathbb{E}(Y^2)+n^{-\frac{3}{2}}H(t))^n $$ 3) Using $\mathbb{E}(Y)=0$ and $\mathbb{V}(Y)=1$ we get: $$ \psi_{S_n}=(1+-\frac{t^2}{2n}+n^{-\frac{3}{2}}H(t))^n $$ Which if we take logs and the limit $n\to\infty$ we can show that, using  $$ \frac{\log(1+x)}{x}\to1 $$ As $x\to 0$, we get $\log(\psi_{S_n})\to-\frac{t^2}{2}$ and then it exponate each term we recover that $\psi_{S_n}$ tends to the characteristic function of a $N(0,1)$ distribution. My question is, how do we know that $H(t)$ is bounded and will tend to zero as $n\to\infty$? I thought it had something to do with the moments of a $N(0,1)$ distribution being finite since we have $\mathbb{E}(Y)=0$ and $\mathbb{V}(Y)=1$ but I am not sure this is correct. I have tried to read papers online, but they usually just use little-o notation for this part of the proof, and don't explain how they know that we can essentially disregard this term. Thanks for any help.","I have my proof of the Central Limit Theorem using characteristic functions in which the main steps are: Set up: Let $X_1, X_2, \dots, X_n$ be a sequence of iid random variables with mean $\mu$ and variance $\sigma^2$. Let $Y_i=\frac{X_i-\mu}{\sigma}$ and $S_n=\sum_{i=1}^{n}\frac{1}{\sqrt{n}}Y_i$. 1) Expand the characteristic function $\psi_{S_n}(t)=\psi_{Y}\left(\frac{t}{\sqrt{n}}\right)^n$ 2)Taylor expand the characteristic function: $$ \psi_{S_n}=(1+\frac{it}{\sqrt{n}}\mathbb{E}(Y)-\frac{t^2}{2n}\mathbb{E}(Y^2)+\dots)^n $$ Which we can then truncate with a bounded function $H(t)$: $$ \psi_{S_n}=(1+\frac{it}{\sqrt{n}}\mathbb{E}(Y)-\frac{t^2}{2n}\mathbb{E}(Y^2)+n^{-\frac{3}{2}}H(t))^n $$ 3) Using $\mathbb{E}(Y)=0$ and $\mathbb{V}(Y)=1$ we get: $$ \psi_{S_n}=(1+-\frac{t^2}{2n}+n^{-\frac{3}{2}}H(t))^n $$ Which if we take logs and the limit $n\to\infty$ we can show that, using  $$ \frac{\log(1+x)}{x}\to1 $$ As $x\to 0$, we get $\log(\psi_{S_n})\to-\frac{t^2}{2}$ and then it exponate each term we recover that $\psi_{S_n}$ tends to the characteristic function of a $N(0,1)$ distribution. My question is, how do we know that $H(t)$ is bounded and will tend to zero as $n\to\infty$? I thought it had something to do with the moments of a $N(0,1)$ distribution being finite since we have $\mathbb{E}(Y)=0$ and $\mathbb{V}(Y)=1$ but I am not sure this is correct. I have tried to read papers online, but they usually just use little-o notation for this part of the proof, and don't explain how they know that we can essentially disregard this term. Thanks for any help.",,"['probability', 'probability-theory', 'statistics', 'proof-verification', 'central-limit-theorem']"
33,are constants the only stationary martingales?,are constants the only stationary martingales?,,"Let $(X_n,\mathcal{F}_n)_{n\in\mathbb{Z}_+}$ be a nonnegative bounded martingale. Assume that the process $X_n$ is strictly stationary. Does it imply that $X_n$ is constant almost surely?","Let $(X_n,\mathcal{F}_n)_{n\in\mathbb{Z}_+}$ be a nonnegative bounded martingale. Assume that the process $X_n$ is strictly stationary. Does it imply that $X_n$ is constant almost surely?",,"['probability', 'stochastic-processes', 'martingales']"
34,Zero-sum game with positive expectation?,Zero-sum game with positive expectation?,,"Suppose $A$ and $B$ are playing the following game. They each possess a fair coin, and individually flip their own coins until they get a tail. Whomever had a longer sequence of consecutive tosses that came up heads wins, and the loser has to pay the winner an amount that depends on the number of heads the loser flipped. If they tossed an equal number of heads before their respective first tail, there is a tie. That is, denote the number of heads flipped by $A$ before the first tail by $a$, and call the number of heads flipped by $B$ before the first tail $b$. Then $A$'s payoffs in monetary terms from this game is given by $$ p(a,b) = \begin{cases} 4^b & \text{if }a>b \\ 0 &\text{if } a=b \\ -4^a &\text{if }a<b  \end{cases} $$ Straightforward calculations show that $$ \operatorname{E}[p(a,b)] = \frac{1}{2} $$ How can a zero-sum game have positive expected payoff? In other words, how can both players expect to gain from playing this game when the amount that one player wins is exactly the amount that the other loses? To see the expected value calculation, note that $$ \operatorname E\left[4^b \vert a>b, b \right] \cdot \Pr (a>b \vert b) = 4^b \cdot \frac{1}{2^{b+1}} =\frac{1}{2}\cdot2^b $$ $$ \operatorname E\left[4^a \vert a<b, b \right] \cdot \Pr (a<b \vert b) = \sum_{k=0}^{b-1}4^k\cdot \frac{1}{2^{k+1}} = \frac{1}{2}\left(2^b - 1 \right) $$ Which means that $\operatorname E [p(a,b)\vert b] = \frac{1}{2}$. The conditional expectation is independent of $b$, so it must equal the unconditional expectation. I suspect there is some connection to the St. Petersburg paradox , but I'm not quite certain what exactly the relation is.","Suppose $A$ and $B$ are playing the following game. They each possess a fair coin, and individually flip their own coins until they get a tail. Whomever had a longer sequence of consecutive tosses that came up heads wins, and the loser has to pay the winner an amount that depends on the number of heads the loser flipped. If they tossed an equal number of heads before their respective first tail, there is a tie. That is, denote the number of heads flipped by $A$ before the first tail by $a$, and call the number of heads flipped by $B$ before the first tail $b$. Then $A$'s payoffs in monetary terms from this game is given by $$ p(a,b) = \begin{cases} 4^b & \text{if }a>b \\ 0 &\text{if } a=b \\ -4^a &\text{if }a<b  \end{cases} $$ Straightforward calculations show that $$ \operatorname{E}[p(a,b)] = \frac{1}{2} $$ How can a zero-sum game have positive expected payoff? In other words, how can both players expect to gain from playing this game when the amount that one player wins is exactly the amount that the other loses? To see the expected value calculation, note that $$ \operatorname E\left[4^b \vert a>b, b \right] \cdot \Pr (a>b \vert b) = 4^b \cdot \frac{1}{2^{b+1}} =\frac{1}{2}\cdot2^b $$ $$ \operatorname E\left[4^a \vert a<b, b \right] \cdot \Pr (a<b \vert b) = \sum_{k=0}^{b-1}4^k\cdot \frac{1}{2^{k+1}} = \frac{1}{2}\left(2^b - 1 \right) $$ Which means that $\operatorname E [p(a,b)\vert b] = \frac{1}{2}$. The conditional expectation is independent of $b$, so it must equal the unconditional expectation. I suspect there is some connection to the St. Petersburg paradox , but I'm not quite certain what exactly the relation is.",,"['probability', 'game-theory']"
35,"Let $X, X$ ~ $N (120,4)$ be an independent measure, what is the probability that three measurements are equal, when measured three times?","Let  ~  be an independent measure, what is the probability that three measurements are equal, when measured three times?","X, X N (120,4)","The voltage (in volts) of a given circuit is a random variable $ X $ that is normally distributed with the parameters $ μ = 120 $ and $ σ ^ 2 = 4 $ If three independent measurements are taken, what is the probability that the three measurements are between $ 116 $ and $ 118 $ volts? My idea is to first get a probability of success $ p $, which I will calculate by standardizing $ X $, and then finding the probability that $ X $ is between $ 116 $ and $ 118 $. Since I need to count the number of measurements, each one with probability of success $ p $ and each measurement attempt is done independently, I would do it with another variable $ Y $ ~ $ B (3, p) $ The answer to the question would be $ P (Y = 3) $, but in this case $ n = y = 3 $ then $ P (Y = 3) = p ^ 3 $ $Z=\dfrac{X-μ}{σ}=\dfrac{X-120}{2}\Rightarrow p = (116<X<118) = P(\dfrac{116-120}{2}<Z<\dfrac{118-120}{2}) = $ $P(-2<Z<-1) = \Phi(-1) - \Phi(-2) = 0,13786 - 0,01831 = 0,11955 \Rightarrow p^3 = 0,001708633$ Is the correct way I'm thinking the solution to the exercise? Thank you very much.","The voltage (in volts) of a given circuit is a random variable $ X $ that is normally distributed with the parameters $ μ = 120 $ and $ σ ^ 2 = 4 $ If three independent measurements are taken, what is the probability that the three measurements are between $ 116 $ and $ 118 $ volts? My idea is to first get a probability of success $ p $, which I will calculate by standardizing $ X $, and then finding the probability that $ X $ is between $ 116 $ and $ 118 $. Since I need to count the number of measurements, each one with probability of success $ p $ and each measurement attempt is done independently, I would do it with another variable $ Y $ ~ $ B (3, p) $ The answer to the question would be $ P (Y = 3) $, but in this case $ n = y = 3 $ then $ P (Y = 3) = p ^ 3 $ $Z=\dfrac{X-μ}{σ}=\dfrac{X-120}{2}\Rightarrow p = (116<X<118) = P(\dfrac{116-120}{2}<Z<\dfrac{118-120}{2}) = $ $P(-2<Z<-1) = \Phi(-1) - \Phi(-2) = 0,13786 - 0,01831 = 0,11955 \Rightarrow p^3 = 0,001708633$ Is the correct way I'm thinking the solution to the exercise? Thank you very much.",,"['probability', 'probability-theory', 'probability-distributions', 'binomial-distribution']"
36,More precise expression of the answer,More precise expression of the answer,,"So the problem says ""Let $X$ be the sum of outcomes of rolling $2$ dice, where the outcome for each dice appears with equal probability. What is the pmf of $X$?"" I got: $X$ could take on any value in the set $\{2,3,4,5,6,7,8,9,10,11,12\}$ The probability mass function is $$f(x) = \begin{cases}\frac1 {36} & \text{ if }  x∈{2,12}\\\frac1 {18} & \text{ if }  x∈{3,11}\\ \frac1 {12} & \text{ if }  x∈{4,10}\\ \frac1 {9} & \text{ if }  x∈{5,9}\\\frac5 {36} & \text{ if }  x∈{6,8}\\\frac1 {6} & \text{ if }  x∈{7}\\ \ 0 & \text{ if }  other\end{cases}$$ Is the answer correct? If so, is there any way I can write the answer in a more precise way instead of listing all the values of $x$?","So the problem says ""Let $X$ be the sum of outcomes of rolling $2$ dice, where the outcome for each dice appears with equal probability. What is the pmf of $X$?"" I got: $X$ could take on any value in the set $\{2,3,4,5,6,7,8,9,10,11,12\}$ The probability mass function is $$f(x) = \begin{cases}\frac1 {36} & \text{ if }  x∈{2,12}\\\frac1 {18} & \text{ if }  x∈{3,11}\\ \frac1 {12} & \text{ if }  x∈{4,10}\\ \frac1 {9} & \text{ if }  x∈{5,9}\\\frac5 {36} & \text{ if }  x∈{6,8}\\\frac1 {6} & \text{ if }  x∈{7}\\ \ 0 & \text{ if }  other\end{cases}$$ Is the answer correct? If so, is there any way I can write the answer in a more precise way instead of listing all the values of $x$?",,"['probability', 'statistics', 'probability-distributions']"
37,Probability of winning an election while losing the popular vote,Probability of winning an election while losing the popular vote,,"Suppose a country with 'E' electorates and 'V' voters in each electorate, were to hold an election. Each vote is independent of all others, and has a 50% chance of being for party A and a 50% chance of being for party B. Let 'E' and 'V' both be odd, and the party with a majority of votes in a particular electorate win that seat, and the party which wins the majority of seats win the election overall. What is the probability, as a function of E and V, that the party which wins the election overall loses the popular vote? For instance, I can calculate as follows with E=V=3: There are 9 voters, so 2^9 total possibilities. For a party to win the election overall but lose the popular vote, it must win exactly 2 votes in 2 seats, and 0 votes in the third seat. The number of ways this could happen is 2 (parties which could win overall) * 3 (seats in which the winning party could get 0 votes) * 3 (electors which could vote against the winning party in the first seat won by them) * 3 (electors which could vote against the winning party in the second seat won by them). Thus the overall probability is 27/256. Is there a general formula for calculating this probability as a function of E and V?","Suppose a country with 'E' electorates and 'V' voters in each electorate, were to hold an election. Each vote is independent of all others, and has a 50% chance of being for party A and a 50% chance of being for party B. Let 'E' and 'V' both be odd, and the party with a majority of votes in a particular electorate win that seat, and the party which wins the majority of seats win the election overall. What is the probability, as a function of E and V, that the party which wins the election overall loses the popular vote? For instance, I can calculate as follows with E=V=3: There are 9 voters, so 2^9 total possibilities. For a party to win the election overall but lose the popular vote, it must win exactly 2 votes in 2 seats, and 0 votes in the third seat. The number of ways this could happen is 2 (parties which could win overall) * 3 (seats in which the winning party could get 0 votes) * 3 (electors which could vote against the winning party in the first seat won by them) * 3 (electors which could vote against the winning party in the second seat won by them). Thus the overall probability is 27/256. Is there a general formula for calculating this probability as a function of E and V?",,"['probability', 'voting-theory']"
38,"How can I show that $\{[\frac{i}{2^n},\frac{i+1}{2^n})\mid i\in \mathbb Z, n\in\mathbb N\}$ is a $\pi-$system.",How can I show that  is a system.,"\{[\frac{i}{2^n},\frac{i+1}{2^n})\mid i\in \mathbb Z, n\in\mathbb N\} \pi-","Let $P$ and $Q$ two probability on $\mathbb R$ and let $$\mathcal A=\left\{\left[\frac{i}{2^n},\frac{i+1}{2^n}\right)\mid i\in \mathbb Z, n\in\mathbb N\right\}.$$ We have that $P(A)=Q(A)$ for all $A\in \mathcal A$. And I need to show that $P=Q$ on $\mathbb R$. I have already proved that $\mathcal B(\mathbb R)=\sigma (\mathcal A)$, and thus, I think I have to prove that $\mathcal A$ is a $\pi-$system. The problem, is a failed. First, I can take $A,B\in \mathcal A$ s.t. $A\cap B=\emptyset$, and $\emptyset\notin \mathcal A$, shall I add it in $\mathcal A$ ? And secondely, If $A\cap B\neq \emptyset$, I think that I have to show that either $A\subset B$ or $B\subset A$, but I also failed. How can I conclude ?","Let $P$ and $Q$ two probability on $\mathbb R$ and let $$\mathcal A=\left\{\left[\frac{i}{2^n},\frac{i+1}{2^n}\right)\mid i\in \mathbb Z, n\in\mathbb N\right\}.$$ We have that $P(A)=Q(A)$ for all $A\in \mathcal A$. And I need to show that $P=Q$ on $\mathbb R$. I have already proved that $\mathcal B(\mathbb R)=\sigma (\mathcal A)$, and thus, I think I have to prove that $\mathcal A$ is a $\pi-$system. The problem, is a failed. First, I can take $A,B\in \mathcal A$ s.t. $A\cap B=\emptyset$, and $\emptyset\notin \mathcal A$, shall I add it in $\mathcal A$ ? And secondely, If $A\cap B\neq \emptyset$, I think that I have to show that either $A\subset B$ or $B\subset A$, but I also failed. How can I conclude ?",,"['probability', 'measure-theory']"
39,Is $g(u)= \frac{E [ \frac{1}{\sqrt{X}} e^{-\frac{a^2u^2}{2X}} ] }{E [ \frac{1}{\sqrt{X}} e^{-\frac{u^2}{2X}} ]}$ decreasing in $u$,Is  decreasing in,g(u)= \frac{E [ \frac{1}{\sqrt{X}} e^{-\frac{a^2u^2}{2X}} ] }{E [ \frac{1}{\sqrt{X}} e^{-\frac{u^2}{2X}} ]} u,"Let $X$ be a positive random variable, let us define a function \begin{align} g(u,a)= \frac{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{a^2u^2}{2X}} \right] }{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{u^2}{2X}} \right]}. \end{align} Question: Can we show that the above integral is monotonically decreasing in $u$ ( for $u>0$ ) for all $a > 1$. Note that $X$ here represents the variance of standard normal. That is we consider the variance to be a random variable. I can show that $g(u,a)$ is bounded by $1$ and continuous but can not establish that it is decreasing.  Also, note that the function $g(u,a)$ is symmetric around $u=0$. What I tried: I was able to show that  for $p,q\ge 1$ and $\frac{1}{q}+\frac{1}{p}=1$ and $a^2 \ge \frac{1}{p}$ we have \begin{align} g(u,a) \le  \left( g( \beta \cdot u, a ) \right)^{\frac{1}{q}}, \end{align} where $\beta=\sqrt{\frac{q(a^2-\frac{1}{p})}{a^2}}$. Proof: By using Holder's inequality \begin{align} E \left[ \frac{1}{\sqrt{X}} e^{-\frac{a^2u^2}{2X}} \right] &=E \left[ \frac{1}{\sqrt{X}} e^{-\frac{ (a^2-\frac{1}{p})u^2}{2X}} e^{-\frac{ \frac{1}{p}u^2}{2X}}  \right] \\ &\le E^\frac{1}{q} \left[ \frac{1}{\sqrt{X}} e^{-\frac{ q(a^2-\frac{1}{p})u^2}{2X}}   \right]  E^\frac{1}{p} \left[ \frac{1}{\sqrt{X}}  e^{-\frac{ u^2}{2X}}  \right]. \end{align} Therefore, \begin{align} g(u,a) \le \left( \frac{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{q(a^2-\frac{1}{p})u^2}{2X}} \right] }{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{u^2}{2X}} \right]} \right) ^\frac{1}{q} &=  \left( g( \beta \cdot u, a ) \right)^{\frac{1}{q}}, \end{align} and \begin{align} g(u,a) \le  \left( g( \beta \cdot u, a ) \right)^{\frac{1}{q}}, \end{align} where $\beta=\sqrt{\frac{q(a^2-\frac{1}{p})}{a^2}}$. Thank you. Looking forward to seeing your approaches.","Let $X$ be a positive random variable, let us define a function \begin{align} g(u,a)= \frac{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{a^2u^2}{2X}} \right] }{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{u^2}{2X}} \right]}. \end{align} Question: Can we show that the above integral is monotonically decreasing in $u$ ( for $u>0$ ) for all $a > 1$. Note that $X$ here represents the variance of standard normal. That is we consider the variance to be a random variable. I can show that $g(u,a)$ is bounded by $1$ and continuous but can not establish that it is decreasing.  Also, note that the function $g(u,a)$ is symmetric around $u=0$. What I tried: I was able to show that  for $p,q\ge 1$ and $\frac{1}{q}+\frac{1}{p}=1$ and $a^2 \ge \frac{1}{p}$ we have \begin{align} g(u,a) \le  \left( g( \beta \cdot u, a ) \right)^{\frac{1}{q}}, \end{align} where $\beta=\sqrt{\frac{q(a^2-\frac{1}{p})}{a^2}}$. Proof: By using Holder's inequality \begin{align} E \left[ \frac{1}{\sqrt{X}} e^{-\frac{a^2u^2}{2X}} \right] &=E \left[ \frac{1}{\sqrt{X}} e^{-\frac{ (a^2-\frac{1}{p})u^2}{2X}} e^{-\frac{ \frac{1}{p}u^2}{2X}}  \right] \\ &\le E^\frac{1}{q} \left[ \frac{1}{\sqrt{X}} e^{-\frac{ q(a^2-\frac{1}{p})u^2}{2X}}   \right]  E^\frac{1}{p} \left[ \frac{1}{\sqrt{X}}  e^{-\frac{ u^2}{2X}}  \right]. \end{align} Therefore, \begin{align} g(u,a) \le \left( \frac{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{q(a^2-\frac{1}{p})u^2}{2X}} \right] }{E \left[ \frac{1}{\sqrt{X}} e^{-\frac{u^2}{2X}} \right]} \right) ^\frac{1}{q} &=  \left( g( \beta \cdot u, a ) \right)^{\frac{1}{q}}, \end{align} and \begin{align} g(u,a) \le  \left( g( \beta \cdot u, a ) \right)^{\frac{1}{q}}, \end{align} where $\beta=\sqrt{\frac{q(a^2-\frac{1}{p})}{a^2}}$. Thank you. Looking forward to seeing your approaches.",,"['real-analysis', 'probability', 'probability-theory', 'expectation']"
40,How likely are two events to occur at the same time?,How likely are two events to occur at the same time?,,"Let's think of two events $1$ and $2$. Both events happen randomly $n_1$/$n_2$-times during a given time $T$ and last for a time of $t_1$/$t_2$. What is probability $P$, that both events happen simultaneously at some moment? EXAMPLE 1: $T = 60$ min Event $1$ - looking out of the office window: $n_1 = 8$  and $t_1 = 1$ min Event $2$ - a green car is on the street visible:  $n_2 = 20$  and $t_2 = 0.5$ min $P$: How likely do I see a green car during these $60$ min?","Let's think of two events $1$ and $2$. Both events happen randomly $n_1$/$n_2$-times during a given time $T$ and last for a time of $t_1$/$t_2$. What is probability $P$, that both events happen simultaneously at some moment? EXAMPLE 1: $T = 60$ min Event $1$ - looking out of the office window: $n_1 = 8$  and $t_1 = 1$ min Event $2$ - a green car is on the street visible:  $n_2 = 20$  and $t_2 = 0.5$ min $P$: How likely do I see a green car during these $60$ min?",,"['probability', 'probability-theory', 'statistics', 'random', 'stochastic-approximation']"
41,Probability that no car is parked next to a car of the same type,Probability that no car is parked next to a car of the same type,,"A university's faculties have 30 cars of exactly 3 types: BMW, Toyota and Mazda.  University has build a new parking lot which has 30 parking slots. Each faculty  member randomly arrives to the parking lot till 11:00 AM and parks his car in any available slot. What is the probability that at 11:00 AM each parking slot has different type of car next to it?(That is no BMW is next to a BMW and no Toyota is next to a Toyota and no Mazda is next to a Mazda) My attempt to solve this: number of elements in Sample Space   = number of arrangements of 30 cars in 30 slots   = 30(Permutation)30   = 265252859812191058636308480000000 I just was not able to count my events i.e., each parking slot has different type of car next to it. What should I do?","A university's faculties have 30 cars of exactly 3 types: BMW, Toyota and Mazda.  University has build a new parking lot which has 30 parking slots. Each faculty  member randomly arrives to the parking lot till 11:00 AM and parks his car in any available slot. What is the probability that at 11:00 AM each parking slot has different type of car next to it?(That is no BMW is next to a BMW and no Toyota is next to a Toyota and no Mazda is next to a Mazda) My attempt to solve this: number of elements in Sample Space   = number of arrangements of 30 cars in 30 slots   = 30(Permutation)30   = 265252859812191058636308480000000 I just was not able to count my events i.e., each parking slot has different type of car next to it. What should I do?",,"['probability', 'permutations']"
42,Conditional probability using single die.,Conditional probability using single die.,,"""A single die is rolled. Find the probability that the die lands on 5, given that the outcome is an odd number."" I'm not sure of the correct way to do this. I think its 1/3 because 5 is one of the three odd numbers, but I'm not sure of the work to get there.","""A single die is rolled. Find the probability that the die lands on 5, given that the outcome is an odd number."" I'm not sure of the correct way to do this. I think its 1/3 because 5 is one of the three odd numbers, but I'm not sure of the work to get there.",,"['probability', 'statistics']"
43,Index where first half exceeds second half,Index where first half exceeds second half,,"Let $n$ be a positive integer, and independently randomize numbers $x_1,\dots,x_n,y_1,\dots,y_n$ from $(0,1)$ uniformly. Let $i(x)$ be the least index such that $$x_1+\dots+x_{i(x)}>x_{i(x)+1}+\dots+x_n.$$ Define $i(y)$ similarly. As $n$ grows, is it true that the probability that $i(x)=i(y)$ approaches $0$? Since the number of indices grows with $n$, the probability that $i(x)=i(y)$ should go down because it is unlikely that they will coincide. But how can this be shown formally?","Let $n$ be a positive integer, and independently randomize numbers $x_1,\dots,x_n,y_1,\dots,y_n$ from $(0,1)$ uniformly. Let $i(x)$ be the least index such that $$x_1+\dots+x_{i(x)}>x_{i(x)+1}+\dots+x_n.$$ Define $i(y)$ similarly. As $n$ grows, is it true that the probability that $i(x)=i(y)$ approaches $0$? Since the number of indices grows with $n$, the probability that $i(x)=i(y)$ should go down because it is unlikely that they will coincide. But how can this be shown formally?",,['probability']
44,Covariance zero for two gaussian variables,Covariance zero for two gaussian variables,,"Say we have two random variables $X$ and $Y$ and both of them have a gaussian distribution. Further, we know that $cov(X,Y) = 0$, where $cov(X,Y)$ is the covariance of two variables (i.e $cov(X,Y) = E[(X-E[X])(Y-E[Y])]$, where $E[X]$ is the mean (expectation) of variable $X$. Can we say that $X$ and $Y$ are independent variables? I know that, in general, $cov(X,Y)= 0 $ does not imply that $X$ and $Y$ are independent, but what about the case when $X$ and $Y$ have a gaussian(normal) distribution? Can we take this as a theorem?","Say we have two random variables $X$ and $Y$ and both of them have a gaussian distribution. Further, we know that $cov(X,Y) = 0$, where $cov(X,Y)$ is the covariance of two variables (i.e $cov(X,Y) = E[(X-E[X])(Y-E[Y])]$, where $E[X]$ is the mean (expectation) of variable $X$. Can we say that $X$ and $Y$ are independent variables? I know that, in general, $cov(X,Y)= 0 $ does not imply that $X$ and $Y$ are independent, but what about the case when $X$ and $Y$ have a gaussian(normal) distribution? Can we take this as a theorem?",,"['probability', 'statistics']"
45,$P(X_1 < X_2 < X_3)$ for Exponential Random Variables,for Exponential Random Variables,P(X_1 < X_2 < X_3),"Let $X_1 \sim \exp(\lambda_1)$, $X_2 \sim \exp(\lambda_2)$ and $X_3 \sim \exp(\lambda_3)$ be independent random variables, where the exponential density I'm using is $$ f_X(x) = \frac{1}{\lambda}e^{-x/\lambda} $$ I'm trying to calculate $P(X_1 < X_2 < X_3)$ but am stuck.  So far, I've rewritten this as $$ P(X_1 < X_2 < X_3) = P(X_1 < X_2 \cap X_2 < X_3) = P(Y_1 < 0 \cap Y_2 < 0) \tag{$*$} $$ where $Y_1 = X_1 - X_2$ and $Y_2 = X_2 - X_3$.  I've also worked out the marginal distributions for $Y_1$ and $Y_2$.  Here's the pdf for $Y_1$: $$ f_{Y_1}(y) = \begin{cases} \dfrac{e^{-y/\lambda_1}}{\lambda_1 + \lambda_2}, \qquad y > 0 \\[6pt] \dfrac{e^{y/\lambda_2}}{\lambda_1 + \lambda_2}, \qquad y \leq 0 \end{cases} $$ But, I need the joint pdf of $(Y_1, Y_2)$ to calculate $(*)$ since the two are not independent.  I can write the vector $(Y_1, Y_2)$ as $$ \begin{pmatrix} Y_1 \\ Y_2 \end{pmatrix} =  \begin{pmatrix} 1 & -1 & 0 \\ 0 & 1 & -1 \end{pmatrix} \begin{pmatrix} X_1 \\ X_2 \\ X_3 \end{pmatrix} $$ but this doesn't seem to help me work out the joint distribution as it does for linear combinations of normals.","Let $X_1 \sim \exp(\lambda_1)$, $X_2 \sim \exp(\lambda_2)$ and $X_3 \sim \exp(\lambda_3)$ be independent random variables, where the exponential density I'm using is $$ f_X(x) = \frac{1}{\lambda}e^{-x/\lambda} $$ I'm trying to calculate $P(X_1 < X_2 < X_3)$ but am stuck.  So far, I've rewritten this as $$ P(X_1 < X_2 < X_3) = P(X_1 < X_2 \cap X_2 < X_3) = P(Y_1 < 0 \cap Y_2 < 0) \tag{$*$} $$ where $Y_1 = X_1 - X_2$ and $Y_2 = X_2 - X_3$.  I've also worked out the marginal distributions for $Y_1$ and $Y_2$.  Here's the pdf for $Y_1$: $$ f_{Y_1}(y) = \begin{cases} \dfrac{e^{-y/\lambda_1}}{\lambda_1 + \lambda_2}, \qquad y > 0 \\[6pt] \dfrac{e^{y/\lambda_2}}{\lambda_1 + \lambda_2}, \qquad y \leq 0 \end{cases} $$ But, I need the joint pdf of $(Y_1, Y_2)$ to calculate $(*)$ since the two are not independent.  I can write the vector $(Y_1, Y_2)$ as $$ \begin{pmatrix} Y_1 \\ Y_2 \end{pmatrix} =  \begin{pmatrix} 1 & -1 & 0 \\ 0 & 1 & -1 \end{pmatrix} \begin{pmatrix} X_1 \\ X_2 \\ X_3 \end{pmatrix} $$ but this doesn't seem to help me work out the joint distribution as it does for linear combinations of normals.",,"['probability', 'probability-distributions']"
46,Proof of Binomial Sum via Double Counting,Proof of Binomial Sum via Double Counting,,I have attempted to double count the following equivalence but to no avail. I'm unable to arrive at the Left Hand Side. $\displaystyle \sum_{k=0}^n \frac{(-1)^k}{k+3} \binom{n}{k} = \frac{2}{(n+1)(n+2)(n+3)} = \frac{1}{n+1}-\frac{2}{n+2}+\frac{1}{n+3}$,I have attempted to double count the following equivalence but to no avail. I'm unable to arrive at the Left Hand Side. $\displaystyle \sum_{k=0}^n \frac{(-1)^k}{k+3} \binom{n}{k} = \frac{2}{(n+1)(n+2)(n+3)} = \frac{1}{n+1}-\frac{2}{n+2}+\frac{1}{n+3}$,,"['probability', 'combinatorics', 'binomial-coefficients', 'combinatorial-proofs']"
47,Find average and sample deviation of the set of samples,Find average and sample deviation of the set of samples,,"Let we have a sample of $N$ idependent identical normally distributed random variables with expectation $a$ and variance $\sigma$. Now we take $k$ samples of initial $N$ to $m$ elements in each. I need to find the average and sample deviation of averages in 2 cases: (a) sampling with replacement (b) sampling without replacement. I try to write an example to clarify the statement. Let we have 1000 people and measure their height. We know that their height is disributed normally with average 175 sm and dispersion 4 sm. Now we 25 times choose 20 people out of 1000. And in each such group of 20 people compute the average height. So we will have 25 numbers that indicate the average height in each group. And I need to calculate the average and variance of the average heights of 25 groups in two following cases: a) Every time we choose 20 random distinct people of 1000 (it can be two same samples for example) b) We do not choose people who we chose before, ie, after the first sampling, we will only select from the remaining 980, then 960, etc. I have an idea that in the case (a) every subsample will have the same average as the whole sample. So in the case (a) all averages will be the same and we have the answer $a$ and dipersion $0$. Am I right? And I absolutely do not know what to do in case (b). Great thanks for the help!","Let we have a sample of $N$ idependent identical normally distributed random variables with expectation $a$ and variance $\sigma$. Now we take $k$ samples of initial $N$ to $m$ elements in each. I need to find the average and sample deviation of averages in 2 cases: (a) sampling with replacement (b) sampling without replacement. I try to write an example to clarify the statement. Let we have 1000 people and measure their height. We know that their height is disributed normally with average 175 sm and dispersion 4 sm. Now we 25 times choose 20 people out of 1000. And in each such group of 20 people compute the average height. So we will have 25 numbers that indicate the average height in each group. And I need to calculate the average and variance of the average heights of 25 groups in two following cases: a) Every time we choose 20 random distinct people of 1000 (it can be two same samples for example) b) We do not choose people who we chose before, ie, after the first sampling, we will only select from the remaining 980, then 960, etc. I have an idea that in the case (a) every subsample will have the same average as the whole sample. So in the case (a) all averages will be the same and we have the answer $a$ and dipersion $0$. Am I right? And I absolutely do not know what to do in case (b). Great thanks for the help!",,"['probability', 'probability-theory', 'statistics']"
48,Uniqueness of the uniform spherical distribution,Uniqueness of the uniform spherical distribution,,"Suppose that $X,Y$ are random vectors on some (possibly different) probability spaces mapping to $\mathbb R^n$ for some $n\in\mathbb N$. Suppose furthermore that $\|X\|=r>0$ for all realizations of the sample space on which $X$ is defined, $\|Y\|=r$, if $U$ is an orthogonal matrix, then $U X$ and $X$ have the same distribution, and if $U$ is an orthogonal matrix, then $U Y$ and $Y$ have the same distribution. I want to show that $X$ and $Y$ must generate the same Borel probability distribution on $\mathbb R^n$. That is, there is a unique uniform distribution on the surface of the $n$-dimensional sphere of radius $r$. I tried showing that the characteristic functions corresponding to $X$ and $Y$ must coincide. In doing so, I managed to derive that if the characteristic function of $X$ is, say, $\varphi:\mathbb R^n\to\mathbb C$, then the following must hold for any $t\in\mathbb R^n$ and any orthogonal matrix $U\in\mathbb R^{n\times n}$: $$\varphi(t)=\varphi(U^{\mathsf T}t).$$ Any further hints would be appreciated.","Suppose that $X,Y$ are random vectors on some (possibly different) probability spaces mapping to $\mathbb R^n$ for some $n\in\mathbb N$. Suppose furthermore that $\|X\|=r>0$ for all realizations of the sample space on which $X$ is defined, $\|Y\|=r$, if $U$ is an orthogonal matrix, then $U X$ and $X$ have the same distribution, and if $U$ is an orthogonal matrix, then $U Y$ and $Y$ have the same distribution. I want to show that $X$ and $Y$ must generate the same Borel probability distribution on $\mathbb R^n$. That is, there is a unique uniform distribution on the surface of the $n$-dimensional sphere of radius $r$. I tried showing that the characteristic functions corresponding to $X$ and $Y$ must coincide. In doing so, I managed to derive that if the characteristic function of $X$ is, say, $\varphi:\mathbb R^n\to\mathbb C$, then the following must hold for any $t\in\mathbb R^n$ and any orthogonal matrix $U\in\mathbb R^{n\times n}$: $$\varphi(t)=\varphi(U^{\mathsf T}t).$$ Any further hints would be appreciated.",,"['probability', 'probability-theory', 'measure-theory']"
49,"For a group of 7 people, find the probability that all of their birthdays do not occur in the winter using the stars and bars counting method","For a group of 7 people, find the probability that all of their birthdays do not occur in the winter using the stars and bars counting method",,"So for a group a 7 people, find the probability that all of their birthdays do not occur in the winter. That is, all of their birthdays occur either in the spring, summer or fall. Assume that the probability of being born in each season is equally likely. So the answer to this one is pretty simple as it is just $\frac{3}{4}^7=0.133$. However, I thought I would try it with a different method. I did it by using the stars and bars counting method. I counted how many ways there are to arrange 7 people into 3 seasons and also how many ways there are to arrange 7 people into 4 seasons. Ie. $$P(no\; birthdays\; in\; the\; winter) = \frac{\binom{7+3-1}{3}}{\binom{7+4-1}{4}}=0.4$$ Why is this not getting the same answer?","So for a group a 7 people, find the probability that all of their birthdays do not occur in the winter. That is, all of their birthdays occur either in the spring, summer or fall. Assume that the probability of being born in each season is equally likely. So the answer to this one is pretty simple as it is just $\frac{3}{4}^7=0.133$. However, I thought I would try it with a different method. I did it by using the stars and bars counting method. I counted how many ways there are to arrange 7 people into 3 seasons and also how many ways there are to arrange 7 people into 4 seasons. Ie. $$P(no\; birthdays\; in\; the\; winter) = \frac{\binom{7+3-1}{3}}{\binom{7+4-1}{4}}=0.4$$ Why is this not getting the same answer?",,"['probability', 'combinatorics']"
50,Marginally Gaussian not Bivariate Gaussian - Ito Integral,Marginally Gaussian not Bivariate Gaussian - Ito Integral,,"Let $(W_t)_{0\leq t\leq 1}$ be a Wiener process defined up to time $1$ on some probability space. Consider the random vector $$\left(W_{1},\int_0^1 \operatorname{sgn}(W_s) \, dW_s\right)=:(W_1,X_1)$$ where the integral expression is an Ito integral. Using properties of the properties of the Ito integral and the P. Levy characterization of Brownian motion, it is not hard to show that both marginals are $\mathcal{N}(0,1)$. Furthermore, it is claimed that this random vector is not bivariate Gaussian. I'm having trouble seeing this last bit. My attempt so far is as follows: Assume the contrary. Then since \begin{align*} \operatorname{E}\left[W_1\int_0^1\operatorname{sgn}(W_s)\,dW_s\right] & = \operatorname{E}\left[\left(\int_0^1 \, dW_s\right)\cdot\left(\int_0^1 \operatorname{sgn}(W_s) \, dW_s \right)\right]\\[6pt] & = \operatorname{E}\left[\int_0^1 \operatorname{sgn}(W_s) \, ds\right] \\[6pt] &=\int_0^1 \operatorname{E} \left[\operatorname{sgn}(W_s)\right] \, ds\\[6pt] &=0, \end{align*} where we use the Ito isometry, Fubini-Tonelli, and the symmetry of the normal distribution, we would then have that $W_1$ and $X_1$ are uncorrelated hence independent $\mathcal{N}(0,1)$ random variables. I am not sure where to rigorously go from here. One thing that's clear to me from John Dawkins comment is that the process $(W_{t},X_{t})_{0\leq t\leq 1}$ is not Gaussian, since $$aW_{t}+X_{t}=\int_{0}^{t}(a+\text{sgn}(W_{s}))dW_{s}$$ and therefore $$\langle{aW+X}\rangle_{t}=\int_{0}^{t}(a+\text{sgn}(W_{s}))^{2}ds,$$ which is not deterministic. Since Gaussian martingales have deterministic quadratic variation, the process is not Gaussian. So there is some collection of times $t_{1}<\cdots<t_{n}$ such that the finite-dimensional distribution is not multivariate Gaussian. But why does it follow that $(W_{1},X_{1})$ is not Gaussian?","Let $(W_t)_{0\leq t\leq 1}$ be a Wiener process defined up to time $1$ on some probability space. Consider the random vector $$\left(W_{1},\int_0^1 \operatorname{sgn}(W_s) \, dW_s\right)=:(W_1,X_1)$$ where the integral expression is an Ito integral. Using properties of the properties of the Ito integral and the P. Levy characterization of Brownian motion, it is not hard to show that both marginals are $\mathcal{N}(0,1)$. Furthermore, it is claimed that this random vector is not bivariate Gaussian. I'm having trouble seeing this last bit. My attempt so far is as follows: Assume the contrary. Then since \begin{align*} \operatorname{E}\left[W_1\int_0^1\operatorname{sgn}(W_s)\,dW_s\right] & = \operatorname{E}\left[\left(\int_0^1 \, dW_s\right)\cdot\left(\int_0^1 \operatorname{sgn}(W_s) \, dW_s \right)\right]\\[6pt] & = \operatorname{E}\left[\int_0^1 \operatorname{sgn}(W_s) \, ds\right] \\[6pt] &=\int_0^1 \operatorname{E} \left[\operatorname{sgn}(W_s)\right] \, ds\\[6pt] &=0, \end{align*} where we use the Ito isometry, Fubini-Tonelli, and the symmetry of the normal distribution, we would then have that $W_1$ and $X_1$ are uncorrelated hence independent $\mathcal{N}(0,1)$ random variables. I am not sure where to rigorously go from here. One thing that's clear to me from John Dawkins comment is that the process $(W_{t},X_{t})_{0\leq t\leq 1}$ is not Gaussian, since $$aW_{t}+X_{t}=\int_{0}^{t}(a+\text{sgn}(W_{s}))dW_{s}$$ and therefore $$\langle{aW+X}\rangle_{t}=\int_{0}^{t}(a+\text{sgn}(W_{s}))^{2}ds,$$ which is not deterministic. Since Gaussian martingales have deterministic quadratic variation, the process is not Gaussian. So there is some collection of times $t_{1}<\cdots<t_{n}$ such that the finite-dimensional distribution is not multivariate Gaussian. But why does it follow that $(W_{1},X_{1})$ is not Gaussian?",,"['probability', 'probability-theory', 'stochastic-processes', 'brownian-motion', 'stochastic-integrals']"
51,Bounding the variance of a sum of independent random variables,Bounding the variance of a sum of independent random variables,,"Suppose $\{X_i\}_{i=1}^n$ is a sequence of independently distributed random variables that take values in $[0,1]$.  Let $\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$ denote the average of the sequence. I'd like to find an upper bound for $\text{Var}(\bar{X})$. My strategy was to use Hoeffding's inequality, which states that $$ \Pr(|\bar X_n - E\bar X_n| \geq t) \leq e^{-2nt^2} $$ We therefore have \begin{align} E\left(|\bar X_n - E\bar X_n|^2\right) &= \int_{x \in [0,1]:\, \left(x - E\bar X_n\right)^2 \geq t}|\bar X_n - E\bar X_n|^2dP + \int_{x \in [0,1]:\, \left(x - E\bar X_n\right)^2 < t}|\bar X_n - E\bar X_n|^2dP \\ &\leq e^{-2nt^2} + t(1-e^{-2nt^2}) \end{align} for all $t$. Minimizing the right-hand side with respect to $t$ gives a bound for any $n$. Is it possible to provide a tighter bound than this? Thanks!","Suppose $\{X_i\}_{i=1}^n$ is a sequence of independently distributed random variables that take values in $[0,1]$.  Let $\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$ denote the average of the sequence. I'd like to find an upper bound for $\text{Var}(\bar{X})$. My strategy was to use Hoeffding's inequality, which states that $$ \Pr(|\bar X_n - E\bar X_n| \geq t) \leq e^{-2nt^2} $$ We therefore have \begin{align} E\left(|\bar X_n - E\bar X_n|^2\right) &= \int_{x \in [0,1]:\, \left(x - E\bar X_n\right)^2 \geq t}|\bar X_n - E\bar X_n|^2dP + \int_{x \in [0,1]:\, \left(x - E\bar X_n\right)^2 < t}|\bar X_n - E\bar X_n|^2dP \\ &\leq e^{-2nt^2} + t(1-e^{-2nt^2}) \end{align} for all $t$. Minimizing the right-hand side with respect to $t$ gives a bound for any $n$. Is it possible to provide a tighter bound than this? Thanks!",,"['probability', 'probability-theory', 'inequality', 'random-variables']"
52,The probability that no person has the same birthday month,The probability that no person has the same birthday month,,If there are $12$ people in the room what the chances are that no two people will have the same birthday month? I tried to think of it in this way: The total number of options is $12^{12}$ The option that no one will have the same birthday month is: $12 * 11 * ... 1$ which means $12!$ So I think the answer is: $$\frac{12!}{12^{12}}=0.0000537$$ What do you think? Thank you!,If there are people in the room what the chances are that no two people will have the same birthday month? I tried to think of it in this way: The total number of options is The option that no one will have the same birthday month is: which means So I think the answer is: What do you think? Thank you!,12 12^{12} 12 * 11 * ... 1 12! \frac{12!}{12^{12}}=0.0000537,"['probability', 'combinatorics', 'birthday']"
53,Conditional expectation of 1st arrival in merged poisson process conditioned on 1st arrival comes from process A,Conditional expectation of 1st arrival in merged poisson process conditioned on 1st arrival comes from process A,,"There are two Poisson processes, process A with rate $\lambda$ and process B with rate $\mu$. These to processes (A and B) can be merged and yield again a Poisson process C with rate $\lambda + \mu$.  Let D be the event that the first arrival of the merged process C is from process A. Then, the probability of event D is $$P(D)=\frac{\lambda}{\lambda + \mu}$$ Let $T$ be the time until the first arrival in the merged process C. Then the expectation of $T$ is: $$E[T]=\frac{1}{\lambda + \mu}$$ Now my question is: What is the conditional expectation of the time until the first arrival in the merged process C conditioned on the event D (that the first arrival is from the first process, i.e. what is $$E[T\mid D]?$$ Is it $E[T\mid D]=\frac{1}{\lambda}$ or $E[T\mid D]=\frac{1}{\lambda+\mu}$, and especially why? I tried to find the PDF $f_{T\mid D}$ but I did get nowhere since it comes down to finding the probability $$P(T \geq t \,\cap D)$$ and I could not do that. The question comes from trying problem 3 of http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041sc-probabilistic-systems-analysis-and-applied-probability-fall-2013/unit-iii/lecture-15/MIT6_041SCF13_assn07.pdf","There are two Poisson processes, process A with rate $\lambda$ and process B with rate $\mu$. These to processes (A and B) can be merged and yield again a Poisson process C with rate $\lambda + \mu$.  Let D be the event that the first arrival of the merged process C is from process A. Then, the probability of event D is $$P(D)=\frac{\lambda}{\lambda + \mu}$$ Let $T$ be the time until the first arrival in the merged process C. Then the expectation of $T$ is: $$E[T]=\frac{1}{\lambda + \mu}$$ Now my question is: What is the conditional expectation of the time until the first arrival in the merged process C conditioned on the event D (that the first arrival is from the first process, i.e. what is $$E[T\mid D]?$$ Is it $E[T\mid D]=\frac{1}{\lambda}$ or $E[T\mid D]=\frac{1}{\lambda+\mu}$, and especially why? I tried to find the PDF $f_{T\mid D}$ but I did get nowhere since it comes down to finding the probability $$P(T \geq t \,\cap D)$$ and I could not do that. The question comes from trying problem 3 of http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041sc-probabilistic-systems-analysis-and-applied-probability-fall-2013/unit-iii/lecture-15/MIT6_041SCF13_assn07.pdf",,"['probability', 'poisson-process']"
54,State space for 8-queen problem,State space for 8-queen problem,,"While reading Artificial Intelligence a Modern Approach I came across the following formulation for the 8-queen problem : Initial state : No queens on the board. States : Arrangements of n queens (0 <= n <= 8), one per column in the leftmost n columns, with no queen attacking another are states. Successor function : Add a queen to any square in the leftmost empty colum such that it is not attacked by any other queen. I have been trying to find some pattern that would allow me to sort out the number of states for each n given the constraints above but I have not been succeeded for n > 2. So, for: n=1 => 8 states n=2 => 42 states ... Even though I could generate all the possible combinations for each n and then filter out all those that do not represent a valid state, I would rather not go that way because it would be really time and space consuming for n, say, greater or equal than 10. To sum up, is there any sort of formula to find the number of states given n and at the same time taking into account the following constrains?","While reading Artificial Intelligence a Modern Approach I came across the following formulation for the 8-queen problem : Initial state : No queens on the board. States : Arrangements of n queens (0 <= n <= 8), one per column in the leftmost n columns, with no queen attacking another are states. Successor function : Add a queen to any square in the leftmost empty colum such that it is not attacked by any other queen. I have been trying to find some pattern that would allow me to sort out the number of states for each n given the constraints above but I have not been succeeded for n > 2. So, for: n=1 => 8 states n=2 => 42 states ... Even though I could generate all the possible combinations for each n and then filter out all those that do not represent a valid state, I would rather not go that way because it would be really time and space consuming for n, say, greater or equal than 10. To sum up, is there any sort of formula to find the number of states given n and at the same time taking into account the following constrains?",,"['probability', 'combinatorics', 'artificial-intelligence']"
55,Weak convergence and convergence of moments,Weak convergence and convergence of moments,,"Consider a random variable $X$ defined on the probability space $(\Omega, \mathcal{F}, P)$ such that $X:\Omega\rightarrow \mathbb{R}$. Suppose that $X\sim N(\mu, \sigma^2)$. Consider a random function $T(X):\mathbb{R}\rightarrow \mathbb{R}$. Let $\{Y_n\}$ be a sequence of random variables all defined on the probability space $(\Omega_n, \mathcal{F}_n, P_n)$ such that $Y_ n:\Omega_n\rightarrow \mathbb{R}$ $\forall n$. Assume $Y_n=O_{P_n}(1)$ and $Y_n\rightarrow_d T(X)$ as $n\rightarrow \infty$ where the meaning of $O_{P_n}(\cdot)$ is described here . Can I conclude that $\lim_{n\rightarrow \infty}E_{P_n}(Y_n)=E_P(T(X))$? In negative case, which additional assumptions would be sufficient? This question is from proof of Theorem 15.1 in van der Vaart ""Asymptotic Statistics"" p.216 when the author writes "" Because $\phi_n$ are unformly bounded $E_h\phi_n\rightarrow E_hT$ "".","Consider a random variable $X$ defined on the probability space $(\Omega, \mathcal{F}, P)$ such that $X:\Omega\rightarrow \mathbb{R}$. Suppose that $X\sim N(\mu, \sigma^2)$. Consider a random function $T(X):\mathbb{R}\rightarrow \mathbb{R}$. Let $\{Y_n\}$ be a sequence of random variables all defined on the probability space $(\Omega_n, \mathcal{F}_n, P_n)$ such that $Y_ n:\Omega_n\rightarrow \mathbb{R}$ $\forall n$. Assume $Y_n=O_{P_n}(1)$ and $Y_n\rightarrow_d T(X)$ as $n\rightarrow \infty$ where the meaning of $O_{P_n}(\cdot)$ is described here . Can I conclude that $\lim_{n\rightarrow \infty}E_{P_n}(Y_n)=E_P(T(X))$? In negative case, which additional assumptions would be sufficient? This question is from proof of Theorem 15.1 in van der Vaart ""Asymptotic Statistics"" p.216 when the author writes "" Because $\phi_n$ are unformly bounded $E_h\phi_n\rightarrow E_hT$ "".",,"['probability', 'asymptotics']"
56,"There are 6 white balls and 9 black balls. Probability of drawing two white, then two black?","There are 6 white balls and 9 black balls. Probability of drawing two white, then two black?",,"From A First Course in Probability (9th Edition) : 3.5 An urn contains 6 white and 9 black balls. If 4 balls are to be   randomly selected without replacement, what is the probability that   the first 2 selected are white and the last 2 black? This method is straightforward and results in the correct answer (according to the book): $$\frac{6}{15} \cdot \frac{5}{14} \cdot \frac{9}{13} \cdot \frac{8}{12} = \frac{6}{91} $$ (This is just the multiplication principle and probability of drawing the color of that ball at that time) However, I want to understand this in terms of conditional probability. I don't understand why this doesn't work: $$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{6 \choose{2}}{9 \choose 2}}{{15 \choose{2}}{13 \choose 2}}}÷{\frac{{6 \choose{2}}}{{15 \choose{2}}}} = {\frac{{9 \choose 2}}{{13 \choose 2}}} = \frac{6}{13} \ne \frac{6}{91}$$ $\frac{6}{13}$ is exactly 7 times more than the previous answer. Why does this method fail to work? What mistake have I made? I tried to use the exact same method used in question 3.3, where this resulted in the correct answer. Optional – About 3.3 3.3 Use Equation (2.1) to compute in a hand of bridge the conditional  probability that East has 3 spades given taht North and South have a  combined total of 8 spades. Here, we see that: $$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{13 \choose{8}}{39 \choose 18}{5 \choose 3}{21 \choose 10}}    {{52 \choose{26}}{26 \choose 13}}}÷{\frac{{13 \choose{8}}{39 \choose 18}}{{52 \choose{26}}}} = {\frac{{5 \choose 3}{21 \choose 10}}{{26 \choose 13}}} = \frac{29}{115} \approx 0.339$$ Which is the answer in the back of the book.","From A First Course in Probability (9th Edition) : 3.5 An urn contains 6 white and 9 black balls. If 4 balls are to be   randomly selected without replacement, what is the probability that   the first 2 selected are white and the last 2 black? This method is straightforward and results in the correct answer (according to the book): $$\frac{6}{15} \cdot \frac{5}{14} \cdot \frac{9}{13} \cdot \frac{8}{12} = \frac{6}{91} $$ (This is just the multiplication principle and probability of drawing the color of that ball at that time) However, I want to understand this in terms of conditional probability. I don't understand why this doesn't work: $$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{6 \choose{2}}{9 \choose 2}}{{15 \choose{2}}{13 \choose 2}}}÷{\frac{{6 \choose{2}}}{{15 \choose{2}}}} = {\frac{{9 \choose 2}}{{13 \choose 2}}} = \frac{6}{13} \ne \frac{6}{91}$$ $\frac{6}{13}$ is exactly 7 times more than the previous answer. Why does this method fail to work? What mistake have I made? I tried to use the exact same method used in question 3.3, where this resulted in the correct answer. Optional – About 3.3 3.3 Use Equation (2.1) to compute in a hand of bridge the conditional  probability that East has 3 spades given taht North and South have a  combined total of 8 spades. Here, we see that: $$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{13 \choose{8}}{39 \choose 18}{5 \choose 3}{21 \choose 10}}    {{52 \choose{26}}{26 \choose 13}}}÷{\frac{{13 \choose{8}}{39 \choose 18}}{{52 \choose{26}}}} = {\frac{{5 \choose 3}{21 \choose 10}}{{26 \choose 13}}} = \frac{29}{115} \approx 0.339$$ Which is the answer in the back of the book.",,[]
57,Computational methods for the limiting distribution of a finite ergodic Markov chain,Computational methods for the limiting distribution of a finite ergodic Markov chain,,"We wish to show what can be discovered about the limit of a finite, homogeneous, ergodic Markov Chain $X_1, X_2, \dots,$ using simple methods of computation and simulation. Specifically, consider the chain with state space $S = \{0, 1, 2\}$ and transition matrix $P =  \begin{bmatrix}p & q & 0 \\0 & p & q \\q & 0 & p \end{bmatrix},$ where $0 < p < 1$ and $q = 1 - p.$ Imagine states arranged clockwise around a circle, with  3 adjacent to 0. At a transition, a particle moves one state clockwise with probability $q$ and stays put with probability $p$. This is an ergodic chain because $P^2$ has all positive elements. [Alternatively, it would be enough to observe that 'round trip' transitions $0 \rightarrow 1 \rightarrow 2 \rightarrow 0$ are possible (the chain has a single class), and that there positive elements on the principal disgonal (aperiodic).] Also, in our example, the transition matrix $P$ is doubly stochastic (columns, as well as rows, sum to unity), we know that the limiting distribution of the chain is uniform on $S.$  That is $\lim_{n \rightarrow \infty} P(X_n = k | X_1 = j) = 1/3,$ for $j, k \in S.$ We say that the limiting distribution of this ergodic Markov chain is the probability vector $\lambda = (1/3, 1/3, 1/3)$. In our initial answer to this question, we use various algebraic and simulation methods to illustrate this limiting process. Additional Answers on related theoretical and computational topics are welcome.","We wish to show what can be discovered about the limit of a finite, homogeneous, ergodic Markov Chain $X_1, X_2, \dots,$ using simple methods of computation and simulation. Specifically, consider the chain with state space $S = \{0, 1, 2\}$ and transition matrix $P =  \begin{bmatrix}p & q & 0 \\0 & p & q \\q & 0 & p \end{bmatrix},$ where $0 < p < 1$ and $q = 1 - p.$ Imagine states arranged clockwise around a circle, with  3 adjacent to 0. At a transition, a particle moves one state clockwise with probability $q$ and stays put with probability $p$. This is an ergodic chain because $P^2$ has all positive elements. [Alternatively, it would be enough to observe that 'round trip' transitions $0 \rightarrow 1 \rightarrow 2 \rightarrow 0$ are possible (the chain has a single class), and that there positive elements on the principal disgonal (aperiodic).] Also, in our example, the transition matrix $P$ is doubly stochastic (columns, as well as rows, sum to unity), we know that the limiting distribution of the chain is uniform on $S.$  That is $\lim_{n \rightarrow \infty} P(X_n = k | X_1 = j) = 1/3,$ for $j, k \in S.$ We say that the limiting distribution of this ergodic Markov chain is the probability vector $\lambda = (1/3, 1/3, 1/3)$. In our initial answer to this question, we use various algebraic and simulation methods to illustrate this limiting process. Additional Answers on related theoretical and computational topics are welcome.",,"['probability', 'markov-chains', 'simulation']"
58,Transformed probability distribution function (non-continuous transformation),Transformed probability distribution function (non-continuous transformation),,Let $$ F_X(x) = \left\{ \begin{array}{ll} \frac{1}{3}e^x & x < 0\\ 1 - \frac{1}{2}e^{-x} & x \geq 0 \end{array} \right . $$ What is the distribution of $Y = F(X)$? I have a hard time using common-known results due to the discontinuity and lack of inverse of $F$. I'm not looking for an answer but rather a general method to solve such problems. Thanks.,Let $$ F_X(x) = \left\{ \begin{array}{ll} \frac{1}{3}e^x & x < 0\\ 1 - \frac{1}{2}e^{-x} & x \geq 0 \end{array} \right . $$ What is the distribution of $Y = F(X)$? I have a hard time using common-known results due to the discontinuity and lack of inverse of $F$. I'm not looking for an answer but rather a general method to solve such problems. Thanks.,,"['probability', 'probability-theory', 'probability-distributions']"
59,"Convergence in distribution, $X_n \xrightarrow{d} X$ and $|X_n-Y_n| \xrightarrow{P} 0$ implies $Y_n \xrightarrow{d} X$","Convergence in distribution,  and  implies",X_n \xrightarrow{d} X |X_n-Y_n| \xrightarrow{P} 0 Y_n \xrightarrow{d} X,"I find this problem and I'd like to know if my answer is correct. Thank you Let $(X, \mathscr{A}, P)$ a probability space. Suppose that $X$ is a r.v. and $\{ X_n \}$ is a sequence of r.v.'s such that $X_n \xrightarrow{d} X$ (convergence in distribution) and $\{Y_n\}$ a sequence of r.v.'s such that $|X_n-Y_n| \xrightarrow{P} 0$. Then $Y_n \xrightarrow{d} X$ Proof: Let $f: \mathbb R \to \mathbb R$ be bounded and uniformly continous function. Let $K$ a constant such that $|f|\le K$ and let $\epsilon>0$ given, so there is a $\delta>0$ such that for $|x-y|<\delta$ then $|f(x)-f(y)|<\epsilon$. Thus \begin{align*} |E f(X_n)-& Ef(Y_n)|\le  E |f(X_n)- f(Y_n)|\\ &=\int_{\{|X_n- Y_n|<\delta\}} |f(X_n)- f(Y_n)| dP+E |f(X_n)- f(Y_n)|+\int_{\{|X_n- Y_n|\ge \delta\}} |f(X_n)- f(Y_n)| dP\\ &\le \epsilon P \{|X_n- Y_n|<\delta\} +2K P\{|X_n- Y_n|\ge\delta\}\\ &\le \epsilon + 2K P\{|X_n- Y_n|\ge\delta\} \end{align*} Letting $n\to \infty$ we have $|E f(X_n)- Ef(Y_n)|\le \epsilon$ and since $\epsilon$ was arbitrary thus $\{Ef(y_n)\}$ converges at the same value that $\{Ef(X_n)\}$, that is, $\{Ef(y_n)\}\to Ef(X)$ and since this holds for all uniformly continuous and bounded function thus $Y_n \xrightarrow{d} X$","I find this problem and I'd like to know if my answer is correct. Thank you Let $(X, \mathscr{A}, P)$ a probability space. Suppose that $X$ is a r.v. and $\{ X_n \}$ is a sequence of r.v.'s such that $X_n \xrightarrow{d} X$ (convergence in distribution) and $\{Y_n\}$ a sequence of r.v.'s such that $|X_n-Y_n| \xrightarrow{P} 0$. Then $Y_n \xrightarrow{d} X$ Proof: Let $f: \mathbb R \to \mathbb R$ be bounded and uniformly continous function. Let $K$ a constant such that $|f|\le K$ and let $\epsilon>0$ given, so there is a $\delta>0$ such that for $|x-y|<\delta$ then $|f(x)-f(y)|<\epsilon$. Thus \begin{align*} |E f(X_n)-& Ef(Y_n)|\le  E |f(X_n)- f(Y_n)|\\ &=\int_{\{|X_n- Y_n|<\delta\}} |f(X_n)- f(Y_n)| dP+E |f(X_n)- f(Y_n)|+\int_{\{|X_n- Y_n|\ge \delta\}} |f(X_n)- f(Y_n)| dP\\ &\le \epsilon P \{|X_n- Y_n|<\delta\} +2K P\{|X_n- Y_n|\ge\delta\}\\ &\le \epsilon + 2K P\{|X_n- Y_n|\ge\delta\} \end{align*} Letting $n\to \infty$ we have $|E f(X_n)- Ef(Y_n)|\le \epsilon$ and since $\epsilon$ was arbitrary thus $\{Ef(y_n)\}$ converges at the same value that $\{Ef(X_n)\}$, that is, $\{Ef(y_n)\}\to Ef(X)$ and since this holds for all uniformly continuous and bounded function thus $Y_n \xrightarrow{d} X$",,"['probability', 'probability-distributions']"
60,Expected Value Diverges?,Expected Value Diverges?,,Given the probability density function $f(x) = \frac{1}{x^2}$ for $x > 1$. The expected value of this function is: $$E[X] = \int_1^\infty \frac{1}{x} dx = \infty$$ Can someone please explain this? Is $E[X]$ only finite under certain condition? Is $\infty$ really the expected value for this probability density function?,Given the probability density function $f(x) = \frac{1}{x^2}$ for $x > 1$. The expected value of this function is: $$E[X] = \int_1^\infty \frac{1}{x} dx = \infty$$ Can someone please explain this? Is $E[X]$ only finite under certain condition? Is $\infty$ really the expected value for this probability density function?,,['probability']
61,Rate of convergence of random series,Rate of convergence of random series,,"$X_1,X_2,\cdots$ are iid with $E(|X_i|^{p})<\infty$ for some real $p\ge 1$ and $E(X_i)=\mu$. I am trying to find the largest $\alpha>0$ such that $n^{\alpha}\left[\dfrac{S_n}{n}-\mu\right]\to 0$ almost surely. I am able to find $\alpha$ for $p$ even and show convergence in $\mathbb{L}^p$ and almost sure. Any hints on how I can proceed with this problem? Thanks!","$X_1,X_2,\cdots$ are iid with $E(|X_i|^{p})<\infty$ for some real $p\ge 1$ and $E(X_i)=\mu$. I am trying to find the largest $\alpha>0$ such that $n^{\alpha}\left[\dfrac{S_n}{n}-\mu\right]\to 0$ almost surely. I am able to find $\alpha$ for $p$ even and show convergence in $\mathbb{L}^p$ and almost sure. Any hints on how I can proceed with this problem? Thanks!",,['probability']
62,What is the probability that the number of zeros of a binary sequence with length $m$ is at least $q$?,What is the probability that the number of zeros of a binary sequence with length  is at least ?,m q,"For a practical problem for a project (not educational) for a friend I need your help. We have a sequence $b$ of $m$ binary values: $$b_1,...,b_m $$ Update: We have sequence b'of m' hexadecimal ($b_i$=0,1,...15) values: $$b_1,...b'_m$$ $n<m$ of them have value 1, the other $m-n$ elements have value 0 $n'<m'$ of them don't have value 0 (but 1-15), the other $(m'-n')$ elements have value 0 We choose $x<m$ elements and randomly change their values (independenty). So if $b_j$ is one of those $x$ elements, then the probability that its value is 0 is $1/2$ and the probability that its value if 1 is $1/2$ after modifying. We choose $x'<m'$ elements and randomly change their values (independenty). So if $b_j$ is one of those $x'$ elements, the probability that its value  is 0 is $1/16$ and the probability that its value is not 0 is $15/16$ after modifying. After that I want to know what the probability is for having at least $q<m$ zeros in the modified elements. After that I want to know what the probability is for having at least $q'<m'$ zeros in the modified elements. I need a method to calculate this probability $P(m,n,x,q)$. I need a method to calculate this probability $P'(m',n',x',q')$. $m > 1000$ $0<n<0.3m$ $0<x<0.6m$ $0.5m <q < m$ Any idea? Thanks a lot ! In addition: if a mathematical approach is not available, I will also accept any answer that contains a complete java or matlab code where I just can plug in $m,n,x$ and $q$ with output $P$.","For a practical problem for a project (not educational) for a friend I need your help. We have a sequence $b$ of $m$ binary values: $$b_1,...,b_m $$ Update: We have sequence b'of m' hexadecimal ($b_i$=0,1,...15) values: $$b_1,...b'_m$$ $n<m$ of them have value 1, the other $m-n$ elements have value 0 $n'<m'$ of them don't have value 0 (but 1-15), the other $(m'-n')$ elements have value 0 We choose $x<m$ elements and randomly change their values (independenty). So if $b_j$ is one of those $x$ elements, then the probability that its value is 0 is $1/2$ and the probability that its value if 1 is $1/2$ after modifying. We choose $x'<m'$ elements and randomly change their values (independenty). So if $b_j$ is one of those $x'$ elements, the probability that its value  is 0 is $1/16$ and the probability that its value is not 0 is $15/16$ after modifying. After that I want to know what the probability is for having at least $q<m$ zeros in the modified elements. After that I want to know what the probability is for having at least $q'<m'$ zeros in the modified elements. I need a method to calculate this probability $P(m,n,x,q)$. I need a method to calculate this probability $P'(m',n',x',q')$. $m > 1000$ $0<n<0.3m$ $0<x<0.6m$ $0.5m <q < m$ Any idea? Thanks a lot ! In addition: if a mathematical approach is not available, I will also accept any answer that contains a complete java or matlab code where I just can plug in $m,n,x$ and $q$ with output $P$.",,"['calculus', 'probability', 'combinatorics', 'algebra-precalculus', 'limits']"
63,Show the sigma algebra of a countable set is generated by a partition,Show the sigma algebra of a countable set is generated by a partition,,"A $\sigma$-algebra $F$ is said to be generated by a partition if there     is some partition $\{B_i\}$ of $\Omega$ so that every set $A$ in $F$ is a     union of some parts in the partition, and every such union in in $F$.     Show that any $\sigma$-algebra on a countable set $\Omega$ is generated     by a partition of $\Omega$. Proof: Let $\Omega$ be a countable set and $F$ be a $\sigma$-algebra on $\Omega$, then $F$ $\subset$ $2^\Omega$. Let $x\in\Omega$, consider $\cap_i A_i$ such that $x\in A_i$ for all $i$, and $A_i \in F$. Note there maybe uncountably many $A_i \in F$ such that $x \in A_i$, but since $\Omega$ is countable, $\cap_i A_i$ can be written as an intersection of sets in $F$, so $\cap A_i \in F$. I know that I need to work work with the intersections and see if the sigma algebra can or cannot distinguish $x,y \in \Omega$. But my question is how do I prove the intersections of all sets $A_i$ containing $x$ can be written as intersections of sets in $F$?","A $\sigma$-algebra $F$ is said to be generated by a partition if there     is some partition $\{B_i\}$ of $\Omega$ so that every set $A$ in $F$ is a     union of some parts in the partition, and every such union in in $F$.     Show that any $\sigma$-algebra on a countable set $\Omega$ is generated     by a partition of $\Omega$. Proof: Let $\Omega$ be a countable set and $F$ be a $\sigma$-algebra on $\Omega$, then $F$ $\subset$ $2^\Omega$. Let $x\in\Omega$, consider $\cap_i A_i$ such that $x\in A_i$ for all $i$, and $A_i \in F$. Note there maybe uncountably many $A_i \in F$ such that $x \in A_i$, but since $\Omega$ is countable, $\cap_i A_i$ can be written as an intersection of sets in $F$, so $\cap A_i \in F$. I know that I need to work work with the intersections and see if the sigma algebra can or cannot distinguish $x,y \in \Omega$. But my question is how do I prove the intersections of all sets $A_i$ containing $x$ can be written as intersections of sets in $F$?",,"['probability', 'probability-theory', 'measure-theory']"
64,Point of maximal error in the normal approximation of the binomial distribution,Point of maximal error in the normal approximation of the binomial distribution,,"I am sorry for the long question! Thanks for taking the time reading the question and for your answers! Context: Let $B_n\sim\text{Binomial(n,p)}$ be the number of successes in $n$ Bernoulli trials of probability $p\in(0,1)$. Let $$\tilde B_n=\frac{B_n-np}{\sqrt{np(1-p)}}$$ be the standardized random variable and let $N\sim\text{N}(0,1)$ have the standardized normal distribution. Let $\epsilon_n(x)$ be the error between the cumulative distribution function of $\tilde B_n$ and $N$, i.e. $$\epsilon_n(x) = \left|\mathcal P(\tilde B_n \le x)-\mathcal P(N \le x)\right|$$ The central limit Theorem shows, that $\lim_{n\to\infty} \epsilon_n = 0$ (uniform in $x$). By doing numerical calculations I get always the result, that the supremum of $\epsilon_n$ is attained for $x\in[-1,1]$ (see below). My question: Is there a proof, that the maximal error of $\epsilon_n(x) = \left|\mathcal P(\tilde B_n \le x)-\mathcal P(N \le x)\right|$ is always attained in the interval $x\in[-1;1]$, i.e. that the point $x$ where $\left|\mathcal P(\tilde B_n \le x)-\mathcal P(N \le x)\right|$ is maximal fulfills $-1\le x\le 1$? Is this true? Some diagrams: Here is a plot of $f(x)=\mathcal P(\tilde B_n \le x)-\mathcal P(N \le x)$ for $p=0.336$ and $n=762$: Here is a plot showing the position of the maximal error, i.e the point $x$ where $\epsilon_n(x)$ is maximal. On the x-axis is the value $p\in(0,1)$. The y-axis shows the point $x$ where $\epsilon_n(x)$ is maximal in the calculation: You can see, that the maximal error is always attained for $-1\le x \le 1$. Note: I know, that because $\mathcal P(\tilde B_n \le x)$ has steps, the function $\epsilon_n$ is not continuous and thus $\sup_{x\in\mathbb R}\epsilon_n(x)$ may not be attained. But as you can see in the diagram the preimage of a sufficiently small neighborhood of $\sup_{x\in\mathbb R}\epsilon_n(x)$ lies in $[-1;1]$... This question is also related to my follow up question Normal approximation of tail probability in binomial distribution (which describes my motivations behind this question).","I am sorry for the long question! Thanks for taking the time reading the question and for your answers! Context: Let $B_n\sim\text{Binomial(n,p)}$ be the number of successes in $n$ Bernoulli trials of probability $p\in(0,1)$. Let $$\tilde B_n=\frac{B_n-np}{\sqrt{np(1-p)}}$$ be the standardized random variable and let $N\sim\text{N}(0,1)$ have the standardized normal distribution. Let $\epsilon_n(x)$ be the error between the cumulative distribution function of $\tilde B_n$ and $N$, i.e. $$\epsilon_n(x) = \left|\mathcal P(\tilde B_n \le x)-\mathcal P(N \le x)\right|$$ The central limit Theorem shows, that $\lim_{n\to\infty} \epsilon_n = 0$ (uniform in $x$). By doing numerical calculations I get always the result, that the supremum of $\epsilon_n$ is attained for $x\in[-1,1]$ (see below). My question: Is there a proof, that the maximal error of $\epsilon_n(x) = \left|\mathcal P(\tilde B_n \le x)-\mathcal P(N \le x)\right|$ is always attained in the interval $x\in[-1;1]$, i.e. that the point $x$ where $\left|\mathcal P(\tilde B_n \le x)-\mathcal P(N \le x)\right|$ is maximal fulfills $-1\le x\le 1$? Is this true? Some diagrams: Here is a plot of $f(x)=\mathcal P(\tilde B_n \le x)-\mathcal P(N \le x)$ for $p=0.336$ and $n=762$: Here is a plot showing the position of the maximal error, i.e the point $x$ where $\epsilon_n(x)$ is maximal. On the x-axis is the value $p\in(0,1)$. The y-axis shows the point $x$ where $\epsilon_n(x)$ is maximal in the calculation: You can see, that the maximal error is always attained for $-1\le x \le 1$. Note: I know, that because $\mathcal P(\tilde B_n \le x)$ has steps, the function $\epsilon_n$ is not continuous and thus $\sup_{x\in\mathbb R}\epsilon_n(x)$ may not be attained. But as you can see in the diagram the preimage of a sufficiently small neighborhood of $\sup_{x\in\mathbb R}\epsilon_n(x)$ lies in $[-1;1]$... This question is also related to my follow up question Normal approximation of tail probability in binomial distribution (which describes my motivations behind this question).",,"['probability', 'statistics', 'reference-request', 'normal-distribution', 'central-limit-theorem']"
65,Show $(\mathbb{E}\vert X^2 - \mathbb{E}[X^2]\vert)^2 \leq 4\mathbb{E}[X^2](\mathbb{E}[X^2]-\mathbb{E}[X]^2)$,Show,(\mathbb{E}\vert X^2 - \mathbb{E}[X^2]\vert)^2 \leq 4\mathbb{E}[X^2](\mathbb{E}[X^2]-\mathbb{E}[X]^2),"Anyone have any leads on this? X has a finite second moment and is nonnegative. \begin{equation} (\mathbb{E}\vert X^2 - \mathbb{E}[X^2]\vert)^2 \leq 4\mathbb{E}[X^2](\mathbb{E}[X^2]-\mathbb{E}[X]^2) \end{equation} Here's what I have: $\mathbb{E}[4X^2]^{1/2}[\mathbb{E}[(X-\mathbb{E}[X])^2]^{1/2}\geq \mathbb{E}\vert 2X(X-\mathbb{E}[X])\vert = \mathbb{E}\vert 2X^2 - X\mathbb{E}[X]\vert $ By Cauchy-Schwarz, and then squaring both sides we get: $[\mathbb{E}\vert 2X^2 - X\mathbb{E}[X]\vert]^2\leq \mathbb{E}[4X^2][\mathbb{E}[(X-\mathbb{E}[X]^2]$ But I cant figure out what to do next or if this is even in the right direction.","Anyone have any leads on this? X has a finite second moment and is nonnegative. \begin{equation} (\mathbb{E}\vert X^2 - \mathbb{E}[X^2]\vert)^2 \leq 4\mathbb{E}[X^2](\mathbb{E}[X^2]-\mathbb{E}[X]^2) \end{equation} Here's what I have: $\mathbb{E}[4X^2]^{1/2}[\mathbb{E}[(X-\mathbb{E}[X])^2]^{1/2}\geq \mathbb{E}\vert 2X(X-\mathbb{E}[X])\vert = \mathbb{E}\vert 2X^2 - X\mathbb{E}[X]\vert $ By Cauchy-Schwarz, and then squaring both sides we get: $[\mathbb{E}\vert 2X^2 - X\mathbb{E}[X]\vert]^2\leq \mathbb{E}[4X^2][\mathbb{E}[(X-\mathbb{E}[X]^2]$ But I cant figure out what to do next or if this is even in the right direction.",,"['probability', 'probability-theory']"
66,Probability Bayesian network problem,Probability Bayesian network problem,,"The diagram above is the Bayesian network of my problem. I want to find  $$\Pr(B=F \mid E=F, A=T)$$ I have evaluated it into the following steps, then I got a bit stuck: $$\Pr(B=F \mid E=F, A=T) = \frac{\Pr(B=F,E=F,A=T)}{\Pr(E=F,A=T)}$$ $$=\frac{\Pr(B=F,E=F,A=T)}{\Pr(A=T\mid E=F)\times\Pr(E=F)}$$ $$$$ I was able to get $\Pr(B=F,E=F,A=T)$ from: $\Pr(B=F,E=F,A=T)=\Pr(A=T\mid B=F,E=F) \times \Pr(B=F,E=F)$ $\Pr(B=F,E=F,A=T)=\Pr(A=T\mid B=F,E=F) \times \Pr(B=F)\times \Pr(E=F)$ Am I right so far? So now the part that I got stuck is I am not sure how to get $$\Pr(A=T\mid E=F)$$ Any help would be appreciated. Thanks!","The diagram above is the Bayesian network of my problem. I want to find  $$\Pr(B=F \mid E=F, A=T)$$ I have evaluated it into the following steps, then I got a bit stuck: $$\Pr(B=F \mid E=F, A=T) = \frac{\Pr(B=F,E=F,A=T)}{\Pr(E=F,A=T)}$$ $$=\frac{\Pr(B=F,E=F,A=T)}{\Pr(A=T\mid E=F)\times\Pr(E=F)}$$ $$$$ I was able to get $\Pr(B=F,E=F,A=T)$ from: $\Pr(B=F,E=F,A=T)=\Pr(A=T\mid B=F,E=F) \times \Pr(B=F,E=F)$ $\Pr(B=F,E=F,A=T)=\Pr(A=T\mid B=F,E=F) \times \Pr(B=F)\times \Pr(E=F)$ Am I right so far? So now the part that I got stuck is I am not sure how to get $$\Pr(A=T\mid E=F)$$ Any help would be appreciated. Thanks!",,"['probability', 'bayesian-network']"
67,Find $\sum_{k=0}^{\infty}(1-1/n)^{2k}\frac{e^{-n\theta}(n\theta)^{k}}{k!}$ (the variance of $(1-1/n)^{X_1+\cdots+X_n}$),Find  (the variance of ),\sum_{k=0}^{\infty}(1-1/n)^{2k}\frac{e^{-n\theta}(n\theta)^{k}}{k!} (1-1/n)^{X_1+\cdots+X_n},"Given a random sample $X_1,\ldots,X_n$ from Poisson distribution with an unknown parameter $\theta>0$.$T:=(1-1/n)^{X_1+\cdots+X_n}$. Find $\operatorname{var}(T)$. My work: I find $T$ is a UMVUE of $e^{-\theta}$. But I cannot use C-R lower bound since not all UMVUE achieve lower bound. My scheme is using transformation to get the pdf of $T$. And then get the variance. Is there any other easier to solve it? Added: Let $a=(1-1/n)$ and $Y=a^{X_1+\cdots+X_n}$. Then, one has $f_{Y}(y)=\frac{e^{-n\theta}(n\theta)^{\log_a y}}{(y \ln a)(\log_a y!)}$. But it seems too complicated for me.","Given a random sample $X_1,\ldots,X_n$ from Poisson distribution with an unknown parameter $\theta>0$.$T:=(1-1/n)^{X_1+\cdots+X_n}$. Find $\operatorname{var}(T)$. My work: I find $T$ is a UMVUE of $e^{-\theta}$. But I cannot use C-R lower bound since not all UMVUE achieve lower bound. My scheme is using transformation to get the pdf of $T$. And then get the variance. Is there any other easier to solve it? Added: Let $a=(1-1/n)$ and $Y=a^{X_1+\cdots+X_n}$. Then, one has $f_{Y}(y)=\frac{e^{-n\theta}(n\theta)^{\log_a y}}{(y \ln a)(\log_a y!)}$. But it seems too complicated for me.",,"['calculus', 'probability', 'sequences-and-series', 'statistics', 'statistical-inference']"
68,Combinatoric Birthday Paradox,Combinatoric Birthday Paradox,,"There is likely a closed form solution for this problem but it's had me puzzled for days. This is about a variant on the classic birthday paradox. To recap, the birthday paradox is where given only 23 students the probability that two have the same birthday is > 0.5. The variant is this: If each student has two (or K ) special days, what is the probability that given N students each student has at least one special day that is unique to them. I stumbled across this problem while working on a related cryptographic algorithm. Another way of phrasing this is in terms of a lottery: If a lottery drawing consists of 5 random numbers (with repetition) drawn from a set of 100 numbers, after N drawings what is the probability that each drawing had at least one unique number among it's 5. Explicitly, given these variables: $C = $ the size of the set of choices (e.g. 100 for the lottery or 365 for the special days) $K = $ # of random choices for each event (e.g. 5 for the lottery, 2 for the special days) $N = $ # of events that have taken place (e.g. lottery drawings, or number of students) Here is what I'm trying to solve for: $P(C, K, N) = $ the probability that after N events, where each draws K random items from a set of C items, each event has at least one item that was not drawn in any other event. Note that $P(C, 1, N)$ provides the solution to the classic birthday paradox. To be clear, repetition is allowed. That is, a student could have the same special day twice, or the lottery drawing could be (5, 5, 78, 10, 5). In that event, if at least one of those numbers was never seen before, it counts as unique. The best I've come up with is this: Given a function, $Q(C, K, N)$ that computes the probability that the $N^{th}$ event has at least one unique value: We would get these values in the student scenario: $$ Q(2, 365, 0) = 1 - \frac{0}{365}\frac{0}{365} = 1.00000 $$ $$ Q(2, 365, 1) = 1 - \frac{2}{365}\frac{2}{365} = 0.99996 $$ $$ Q(2, 365, 2) = 1 - \frac{4}{365}\frac{4}{365} = 0.99987 $$ And similarly for the lottery drawing: $$ Q(5, 100, 0) = 1 - \frac{0}{100}\frac{0}{100}   = 1.00000 $$ $$ Q(5, 100, 1) = 1 - \frac{5}{100}\frac{5}{100}   = 0.99999 $$ $$ Q(5, 100, 2) = 1 - \frac{10}{100}\frac{10}{100} = 0.99999 $$ This generalizes to: $$ Q(C, K, N) = 1 - (\frac{N * K}{C})^K $$ If $Q$ computes the probability of any given student having at least one unique day than the probability of N events all having at least one unique day is just multiplying all of the probabilities together: $$P(C, K, N) = \prod_{n=0}^N 1 - (\frac{n * K}{C})^{K}$$ This looks promising because for the case where $K = 1$, this simplifies to: $$\prod_{n=0}^N \frac{C - n}{C}$$ which is the formula for the traditional birthday paradox. The problem is that this proposed formula, beyond $K=1$, isn't actually correct, as verified by a monte-carlo simulation I've been running to compare it against. I can't seem to wrap my head around what the problem is though. I've tried about a dozen different ways to approach the problem. It seems that there may be no closed form solution, unfortunately.","There is likely a closed form solution for this problem but it's had me puzzled for days. This is about a variant on the classic birthday paradox. To recap, the birthday paradox is where given only 23 students the probability that two have the same birthday is > 0.5. The variant is this: If each student has two (or K ) special days, what is the probability that given N students each student has at least one special day that is unique to them. I stumbled across this problem while working on a related cryptographic algorithm. Another way of phrasing this is in terms of a lottery: If a lottery drawing consists of 5 random numbers (with repetition) drawn from a set of 100 numbers, after N drawings what is the probability that each drawing had at least one unique number among it's 5. Explicitly, given these variables: $C = $ the size of the set of choices (e.g. 100 for the lottery or 365 for the special days) $K = $ # of random choices for each event (e.g. 5 for the lottery, 2 for the special days) $N = $ # of events that have taken place (e.g. lottery drawings, or number of students) Here is what I'm trying to solve for: $P(C, K, N) = $ the probability that after N events, where each draws K random items from a set of C items, each event has at least one item that was not drawn in any other event. Note that $P(C, 1, N)$ provides the solution to the classic birthday paradox. To be clear, repetition is allowed. That is, a student could have the same special day twice, or the lottery drawing could be (5, 5, 78, 10, 5). In that event, if at least one of those numbers was never seen before, it counts as unique. The best I've come up with is this: Given a function, $Q(C, K, N)$ that computes the probability that the $N^{th}$ event has at least one unique value: We would get these values in the student scenario: $$ Q(2, 365, 0) = 1 - \frac{0}{365}\frac{0}{365} = 1.00000 $$ $$ Q(2, 365, 1) = 1 - \frac{2}{365}\frac{2}{365} = 0.99996 $$ $$ Q(2, 365, 2) = 1 - \frac{4}{365}\frac{4}{365} = 0.99987 $$ And similarly for the lottery drawing: $$ Q(5, 100, 0) = 1 - \frac{0}{100}\frac{0}{100}   = 1.00000 $$ $$ Q(5, 100, 1) = 1 - \frac{5}{100}\frac{5}{100}   = 0.99999 $$ $$ Q(5, 100, 2) = 1 - \frac{10}{100}\frac{10}{100} = 0.99999 $$ This generalizes to: $$ Q(C, K, N) = 1 - (\frac{N * K}{C})^K $$ If $Q$ computes the probability of any given student having at least one unique day than the probability of N events all having at least one unique day is just multiplying all of the probabilities together: $$P(C, K, N) = \prod_{n=0}^N 1 - (\frac{n * K}{C})^{K}$$ This looks promising because for the case where $K = 1$, this simplifies to: $$\prod_{n=0}^N \frac{C - n}{C}$$ which is the formula for the traditional birthday paradox. The problem is that this proposed formula, beyond $K=1$, isn't actually correct, as verified by a monte-carlo simulation I've been running to compare it against. I can't seem to wrap my head around what the problem is though. I've tried about a dozen different ways to approach the problem. It seems that there may be no closed form solution, unfortunately.",,"['probability', 'combinatorics', 'birthday']"
69,Probability of consecutive floors on an elevator with more people,Probability of consecutive floors on an elevator with more people,,"Another user posted this question about elevator occupants, which made me curious about a harder question. In a $t$ -story building (with no basement), $n$ people get on an elevator on the first floor.  Each person will uniformly at random independently wish to go to one of the higher floors and will press the corresponding button for the floor assuming it hasn't already been pressed. What is the probability that three consecutive floors will be visited at some point during the elevator's trip carrying these passengers? Note, I am not asking for the probability that there are only three floors visited and they all happen to be consecutive, but rather, that among the floors visited, there is a subset of them of size three that are adjacent. My initial thoughts on the problem is that we might want to approach via ""bad words"" and strings, letting ""+"" represent that the floor was visited and ""0"" represent that the floor was not, we ask for the probability that the sequence of visited or not contains no substring ""+++"", but this doesn't account for the fact that multiple people might choose to go to the same floor, etc... An easy approach would be simply to run simulations, but that is uninteresting so I ask if anyone has an idea on a pen+paper approach. If someone wants specific numbers to work with, try with $n=t=10$ , as that was how I mistakenly read the other user's question at first glance.","Another user posted this question about elevator occupants, which made me curious about a harder question. In a -story building (with no basement), people get on an elevator on the first floor.  Each person will uniformly at random independently wish to go to one of the higher floors and will press the corresponding button for the floor assuming it hasn't already been pressed. What is the probability that three consecutive floors will be visited at some point during the elevator's trip carrying these passengers? Note, I am not asking for the probability that there are only three floors visited and they all happen to be consecutive, but rather, that among the floors visited, there is a subset of them of size three that are adjacent. My initial thoughts on the problem is that we might want to approach via ""bad words"" and strings, letting ""+"" represent that the floor was visited and ""0"" represent that the floor was not, we ask for the probability that the sequence of visited or not contains no substring ""+++"", but this doesn't account for the fact that multiple people might choose to go to the same floor, etc... An easy approach would be simply to run simulations, but that is uninteresting so I ask if anyone has an idea on a pen+paper approach. If someone wants specific numbers to work with, try with , as that was how I mistakenly read the other user's question at first glance.",t n n=t=10,"['probability', 'combinatorics']"
70,Limit of a binomial probability,Limit of a binomial probability,,"I am doing some self-study on measure theory and probability. This question is taken from Jacod and Protter's Essentials of Probability, Chapter 5 (Q15): Let $X$ be a binomial random variable, $X\sim \mathrm{Binomial}(p=\frac{1}{2}, n)$, where $n=2m$. Let $a(m,k)=\dfrac{4^{m}}{2m \choose m} P(X=m+k)$. Show that $\lim_{m\to \infty} (a(m,k))^{m}=e^{-k^{2}}$. So far I have been able to get: \begin{align*} [a(m,k)]^{m}&=\left[ \frac{4^{m}}{2m \choose m} P(X=m+k) \right]^{m}\\ &=\left[ \frac{4^{m}}{2m \choose m} {2m \choose (m+k)}p^{m+k}(1-p)^{2m-(m+k)} \right]^{m}\\ &=\left[ 4^{m} \frac{(m!)^2}{(m-k)!(m+k)!}\left(\frac{1}{2}\right)^{m+k} \left(\frac{1}{2}\right)^{m-k} \right]^{m}\\ &=\left[\frac{(m!)^2}{(m-k)!(m+k)!}\right]^{m}\\ &\approx\left[\left(\frac{m}{\sqrt{(m-k)(m+k)}}\right)\left(\frac{m}{e}\right)^{2m}\left(\frac{e}{m-k}\right)^{m-k}\left(\frac{e}{m+k}\right)^{m+k}\right]^{m}\text{, by stirling}\\ &=\left[\frac{m^{2m+1}}{(m-k)^{m-k+0.5}(m+k)^{m+k+0.5}}\right]^{m}\\ \end{align*} However, I am unable to get the answer from here. I think I am close, but have been working with it for a while and can't get anywhere. I hate moving on without understanding where I am making a mistake (especially with self-study). If anyone feels up to the challenge any help would be greatly appreciated.","I am doing some self-study on measure theory and probability. This question is taken from Jacod and Protter's Essentials of Probability, Chapter 5 (Q15): Let $X$ be a binomial random variable, $X\sim \mathrm{Binomial}(p=\frac{1}{2}, n)$, where $n=2m$. Let $a(m,k)=\dfrac{4^{m}}{2m \choose m} P(X=m+k)$. Show that $\lim_{m\to \infty} (a(m,k))^{m}=e^{-k^{2}}$. So far I have been able to get: \begin{align*} [a(m,k)]^{m}&=\left[ \frac{4^{m}}{2m \choose m} P(X=m+k) \right]^{m}\\ &=\left[ \frac{4^{m}}{2m \choose m} {2m \choose (m+k)}p^{m+k}(1-p)^{2m-(m+k)} \right]^{m}\\ &=\left[ 4^{m} \frac{(m!)^2}{(m-k)!(m+k)!}\left(\frac{1}{2}\right)^{m+k} \left(\frac{1}{2}\right)^{m-k} \right]^{m}\\ &=\left[\frac{(m!)^2}{(m-k)!(m+k)!}\right]^{m}\\ &\approx\left[\left(\frac{m}{\sqrt{(m-k)(m+k)}}\right)\left(\frac{m}{e}\right)^{2m}\left(\frac{e}{m-k}\right)^{m-k}\left(\frac{e}{m+k}\right)^{m+k}\right]^{m}\text{, by stirling}\\ &=\left[\frac{m^{2m+1}}{(m-k)^{m-k+0.5}(m+k)^{m+k+0.5}}\right]^{m}\\ \end{align*} However, I am unable to get the answer from here. I think I am close, but have been working with it for a while and can't get anywhere. I hate moving on without understanding where I am making a mistake (especially with self-study). If anyone feels up to the challenge any help would be greatly appreciated.",,"['probability', 'limits', 'binomial-distribution']"
71,"Probability, that a random number has no ""small"" prime factors","Probability, that a random number has no ""small"" prime factors",,"What is the probability, that a random number $N$ with $k$ digits has no prime factor with at most $l$ digits ? I came across the formula $\frac{e^{-\gamma}}{log(p)}$ , giving the approximate probability that a very large number (much larger than $p$) has no prime factor below $p$, if $p$ itself is ""large"". But neither do I know how the author came to this formula, nor do I know how accurate this formula is. How good is the approximation, if the probability that a $100$ digit-number     has no prime factor below $10^{30}$ has to be calculated ? A $100$-digit number starting with a $1$ has much higher probability that it is a product of two distinct $50$-digit primes than a $100$-digit number starting with a $9$. Is there a formula accurate enough to approve this fact ? The problem, I am struggling with, is : If $N$ is a random number in the range $[42^{61}-10^{12},42^{61}+10^{12}]$, which has no prime factor below $10^{30}$, is composite and no prime power, what is the probability that $N$ is the product of two distinct $50$-didit primes ?","What is the probability, that a random number $N$ with $k$ digits has no prime factor with at most $l$ digits ? I came across the formula $\frac{e^{-\gamma}}{log(p)}$ , giving the approximate probability that a very large number (much larger than $p$) has no prime factor below $p$, if $p$ itself is ""large"". But neither do I know how the author came to this formula, nor do I know how accurate this formula is. How good is the approximation, if the probability that a $100$ digit-number     has no prime factor below $10^{30}$ has to be calculated ? A $100$-digit number starting with a $1$ has much higher probability that it is a product of two distinct $50$-digit primes than a $100$-digit number starting with a $9$. Is there a formula accurate enough to approve this fact ? The problem, I am struggling with, is : If $N$ is a random number in the range $[42^{61}-10^{12},42^{61}+10^{12}]$, which has no prime factor below $10^{30}$, is composite and no prime power, what is the probability that $N$ is the product of two distinct $50$-didit primes ?",,"['probability', 'number-theory', 'prime-factorization']"
72,Transference of properties from marginals to joint density functions,Transference of properties from marginals to joint density functions,,"Let $(X,Y)$ be an absolutely continuous random vector and denote by $f_{(X,Y)}(x,y)$ its joint density function and $f_X(x)$, resp. $f_Y(y)$ the marginal density functions. If $f_X$ and $f_Y$ are continuous and $X$ and $Y$ are independent then $f_{(X,Y)}(x,y)=f_X(x)f_Y(y)$ and hence $f_{(X,Y)}$ is continuous as well. So, let us assume $X$ and $Y$ are not independent. How can one obtain regularity of the joint density having only properties from the marginal densities? Is it possible? Is there any criteria? Maybe an illustrative example of a random vector with marginal continuous densities but discontinuous joint density would help. Is there a toy example of this? Thanks a lot!","Let $(X,Y)$ be an absolutely continuous random vector and denote by $f_{(X,Y)}(x,y)$ its joint density function and $f_X(x)$, resp. $f_Y(y)$ the marginal density functions. If $f_X$ and $f_Y$ are continuous and $X$ and $Y$ are independent then $f_{(X,Y)}(x,y)=f_X(x)f_Y(y)$ and hence $f_{(X,Y)}$ is continuous as well. So, let us assume $X$ and $Y$ are not independent. How can one obtain regularity of the joint density having only properties from the marginal densities? Is it possible? Is there any criteria? Maybe an illustrative example of a random vector with marginal continuous densities but discontinuous joint density would help. Is there a toy example of this? Thanks a lot!",,"['calculus', 'real-analysis', 'probability', 'analysis', 'probability-distributions']"
73,Probability when cutting the stick twice,Probability when cutting the stick twice,,"Given a stick of length $l$. We cut the stick twice. Let $X$ be the random variable defined by the length of the stick after the first cut, and $Y$ be the random variable defined by the length of the stick after the second cut. What is the probability for $Y>\frac{l}{4}$? First, the PDF of $X$ is uniform, thus $f_{X}(x)=\frac{1}{l}$ (since $0\le X\le l$). $Y$ is uniform in $[0,X]$, then $f_{Y|X}(y|x)=\frac{1}{x}$. Then the probability of $Y>\frac{l}{4}$ is $$\int_{l/4}^{x}\frac{1}{x}dy=1-\frac{l}{4x}$$ On the other hand, we have $$f_{X,Y}=f_Xf_{Y|X}=\frac{1}{lx}$$  We write the probability of $Y>\frac{l}{4}$ as follow: $$P\left(\frac{l}{4}<Y<x|\frac{l}{4}\le X \le l\right)=\frac{P(l/4<Y<x,l/4\le X \le l)}{P(l/4\le X\le l)}=\frac{\int_{l/4}^{x}\int_{l/4}^{l} \frac{1}{lx}dxdy}{\frac{1}{l}}$$ which leads to a different result from $1-\frac{l}{4x}$. My question is which of the solution is correct, and what's wrong with the incorrect solution? Thanks in advance.","Given a stick of length $l$. We cut the stick twice. Let $X$ be the random variable defined by the length of the stick after the first cut, and $Y$ be the random variable defined by the length of the stick after the second cut. What is the probability for $Y>\frac{l}{4}$? First, the PDF of $X$ is uniform, thus $f_{X}(x)=\frac{1}{l}$ (since $0\le X\le l$). $Y$ is uniform in $[0,X]$, then $f_{Y|X}(y|x)=\frac{1}{x}$. Then the probability of $Y>\frac{l}{4}$ is $$\int_{l/4}^{x}\frac{1}{x}dy=1-\frac{l}{4x}$$ On the other hand, we have $$f_{X,Y}=f_Xf_{Y|X}=\frac{1}{lx}$$  We write the probability of $Y>\frac{l}{4}$ as follow: $$P\left(\frac{l}{4}<Y<x|\frac{l}{4}\le X \le l\right)=\frac{P(l/4<Y<x,l/4\le X \le l)}{P(l/4\le X\le l)}=\frac{\int_{l/4}^{x}\int_{l/4}^{l} \frac{1}{lx}dxdy}{\frac{1}{l}}$$ which leads to a different result from $1-\frac{l}{4x}$. My question is which of the solution is correct, and what's wrong with the incorrect solution? Thanks in advance.",,['probability']
74,Equivalence between conditions for convergence,Equivalence between conditions for convergence,,"Let $(X_k)$ be independant random variables such that $X_k\sim\mathcal{P}(p_k)$ (Poisson distribution with parameter $p_k$). So in particular we have $ \sum_{n=1}^NX_k \sim \mathcal{P}(\sum _{n=1}^Np_k)$ and $\mathbb{E}(X_k)=p_k$. By hypothesis $np_n\to \infty$ and can be write : $p_n=b(n)/n$ where $b(n)$ is slowly varying function. A function $f$ defined on $\mathbb{R}$ is a slowly varying function if for every $\delta >0$, $n^{\delta }f(n)$ is increasing and $n^{\delta }f(n)$ is decreasing if $n$ is large enough. So in particular we have $p_n\to 0$. I want to show equivalence between the following conditions : i) a.s. $\forall t \neq 0 \in \mathbb{T}, \, \sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}}e^{2i\pi kt}=o( \sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}})$ when $N\to \infty$. ii)a.s. $\forall t \neq 0 \in \mathbb{T}, \, \sum_{k=1}^NX_ke^{2i\pi kt}=o( \sum_{k=1}^NX_k)$ when $N\to \infty$. iii)a.s. $\forall t \neq 0 \in \mathbb{T}, \, \sum_{k=1}^NX_ke^{2i\pi kt}=o( \sum_{k=1}^Np_k)$ when $N\to \infty$. The notation $\sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}}e^{2i\pi kt}=o( \sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}})$ means that $$ \frac{\sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}}e^{2i\pi kt}}{\sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}}}\to 0$$ when $N\to \infty$. The torus will be denoted by $\mathbb{T}=[0,1)=\mathbb{R}\setminus  \mathbb{Z}$. First observe that $\sum _k p_k=\infty $. But we can obtain a more precise estimation : $\sum _k^N p_k=a_N\log (N)$ where $a_N\to \infty$ when $N\to \infty$. So by using Chernoff bound we can show (cf Mickael's answer) that $ii)\implies iii)$ since $ \sum _k X_k\leq M \sum _k p_k$ with probability one. The same argument can be used to show that with probability one $ \sum _k p_k\leq m \sum _k X_k$. So $ii)\Leftrightarrow iii)$. It remains to show the equivalence between $i)$ and $ii)$ and $iii)\implies ii)$. I suggest the following argument. Let $Y_k=X_k-\mathbf{1}_{\{ X_k>0\}}$, $\mathbb{P}(Y_k>0)=e^{-p_k}\sum _{n\geq 2}\frac{p_k^n}{n!}$. So $\sum _k\mathbb{P}(Y_k>0)<\sum _n \sum _k \frac{p_k^2}{n!}<+\infty $ (we can assume that $0<p_k<1$ and by hypothesis $\sum p_k^2=\sum b(k)^2/k^2<+\infty$). By Borel-Cantelli lemma $Y_k=0$ a.s. for sufficiently large $k$. Since $\sum _k X_k \to \infty$ the result follows.","Let $(X_k)$ be independant random variables such that $X_k\sim\mathcal{P}(p_k)$ (Poisson distribution with parameter $p_k$). So in particular we have $ \sum_{n=1}^NX_k \sim \mathcal{P}(\sum _{n=1}^Np_k)$ and $\mathbb{E}(X_k)=p_k$. By hypothesis $np_n\to \infty$ and can be write : $p_n=b(n)/n$ where $b(n)$ is slowly varying function. A function $f$ defined on $\mathbb{R}$ is a slowly varying function if for every $\delta >0$, $n^{\delta }f(n)$ is increasing and $n^{\delta }f(n)$ is decreasing if $n$ is large enough. So in particular we have $p_n\to 0$. I want to show equivalence between the following conditions : i) a.s. $\forall t \neq 0 \in \mathbb{T}, \, \sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}}e^{2i\pi kt}=o( \sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}})$ when $N\to \infty$. ii)a.s. $\forall t \neq 0 \in \mathbb{T}, \, \sum_{k=1}^NX_ke^{2i\pi kt}=o( \sum_{k=1}^NX_k)$ when $N\to \infty$. iii)a.s. $\forall t \neq 0 \in \mathbb{T}, \, \sum_{k=1}^NX_ke^{2i\pi kt}=o( \sum_{k=1}^Np_k)$ when $N\to \infty$. The notation $\sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}}e^{2i\pi kt}=o( \sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}})$ means that $$ \frac{\sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}}e^{2i\pi kt}}{\sum_{k=1}^N\mathbf{1}_{\{ X_k>0\}}}\to 0$$ when $N\to \infty$. The torus will be denoted by $\mathbb{T}=[0,1)=\mathbb{R}\setminus  \mathbb{Z}$. First observe that $\sum _k p_k=\infty $. But we can obtain a more precise estimation : $\sum _k^N p_k=a_N\log (N)$ where $a_N\to \infty$ when $N\to \infty$. So by using Chernoff bound we can show (cf Mickael's answer) that $ii)\implies iii)$ since $ \sum _k X_k\leq M \sum _k p_k$ with probability one. The same argument can be used to show that with probability one $ \sum _k p_k\leq m \sum _k X_k$. So $ii)\Leftrightarrow iii)$. It remains to show the equivalence between $i)$ and $ii)$ and $iii)\implies ii)$. I suggest the following argument. Let $Y_k=X_k-\mathbf{1}_{\{ X_k>0\}}$, $\mathbb{P}(Y_k>0)=e^{-p_k}\sum _{n\geq 2}\frac{p_k^n}{n!}$. So $\sum _k\mathbb{P}(Y_k>0)<\sum _n \sum _k \frac{p_k^2}{n!}<+\infty $ (we can assume that $0<p_k<1$ and by hypothesis $\sum p_k^2=\sum b(k)^2/k^2<+\infty$). By Borel-Cantelli lemma $Y_k=0$ a.s. for sufficiently large $k$. Since $\sum _k X_k \to \infty$ the result follows.",,"['probability', 'sequences-and-series', 'convergence-divergence']"
75,Roll eleven dice such that the product is prime,Roll eleven dice such that the product is prime,,"So the problem is: What is the probability of rolling eleven dice such that their product is prime. The dice is numbered from 1 to 6 and there is an equal chance of getting each number. So in order for the product to be prime, all but one of the numbers must be 1. The number that is not 1 must be either 2, 3, or 5.  So the total number of ways that 2, 3, or 5 can be formed through multiplication is 3*11 = 33. I then divided 33 by the total number of products that can be formed, or $6^{11}$. My original solution yields basically the same numerical value, but I'm doubtful of it's correctness. By the binomial probability theorem, the probability of rolling a 1 ten times and a number besides 1 is $$_{11}C_{10} \left(\frac{1}{6}\right)^{10}\left(\frac{5}{6}\right)^{1} $$ Given that the remaining number is not 1, the probability of rolling 2, 3, or 5 is $\frac{3}{5}$. Hence we multiply them together to get the probability $$_{11}C_{10} \left(\frac{1}{6}\right)^{10}\left(\frac{5}{6}\right)^{1}\left(\frac{3}{5}\right)$$ This problem was originally a test question, but many of my peers got a different answer of $$ \left(\frac{(3*11)}{6^{11}}\right)\left(\frac{11!}{10!}\right)$$ If their answer is correct could someone please explain to me why mines is incorrect? I would also greatly appreciate it if you could explain how to get the correct answer.","So the problem is: What is the probability of rolling eleven dice such that their product is prime. The dice is numbered from 1 to 6 and there is an equal chance of getting each number. So in order for the product to be prime, all but one of the numbers must be 1. The number that is not 1 must be either 2, 3, or 5.  So the total number of ways that 2, 3, or 5 can be formed through multiplication is 3*11 = 33. I then divided 33 by the total number of products that can be formed, or $6^{11}$. My original solution yields basically the same numerical value, but I'm doubtful of it's correctness. By the binomial probability theorem, the probability of rolling a 1 ten times and a number besides 1 is $$_{11}C_{10} \left(\frac{1}{6}\right)^{10}\left(\frac{5}{6}\right)^{1} $$ Given that the remaining number is not 1, the probability of rolling 2, 3, or 5 is $\frac{3}{5}$. Hence we multiply them together to get the probability $$_{11}C_{10} \left(\frac{1}{6}\right)^{10}\left(\frac{5}{6}\right)^{1}\left(\frac{3}{5}\right)$$ This problem was originally a test question, but many of my peers got a different answer of $$ \left(\frac{(3*11)}{6^{11}}\right)\left(\frac{11!}{10!}\right)$$ If their answer is correct could someone please explain to me why mines is incorrect? I would also greatly appreciate it if you could explain how to get the correct answer.",,['probability']
76,Probability of throwing balls into bins.,Probability of throwing balls into bins.,,"Suppose we have $M$ balls placed randomly into $N$ boxes, wherein each ball has an equal chance of landing in each bin. How would we go about finding the expected number of balls in the first box? I assumed we could use a binomial distribution, wherein we would regard a ball being thrown into the first box as a success, and the probability of success is $1/N$. Hence, from this, the expected value of balls in the first box is $M/N$. Is this a correct approach?","Suppose we have $M$ balls placed randomly into $N$ boxes, wherein each ball has an equal chance of landing in each bin. How would we go about finding the expected number of balls in the first box? I assumed we could use a binomial distribution, wherein we would regard a ball being thrown into the first box as a success, and the probability of success is $1/N$. Hence, from this, the expected value of balls in the first box is $M/N$. Is this a correct approach?",,['probability']
77,Number of ways to set 3 queens to attack each other [closed],Number of ways to set 3 queens to attack each other [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question We play chess and want to set 3 queens to attack each other. How many ways we can do it? I know to solve this problem when I have 2 queens. I see the chess board as 4 squares, from an outer square (the 28 squares on the edges and corners) to the inner square, the 4 squares in the center of the board.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question We play chess and want to set 3 queens to attack each other. How many ways we can do it? I know to solve this problem when I have 2 queens. I see the chess board as 4 squares, from an outer square (the 28 squares on the edges and corners) to the inner square, the 4 squares in the center of the board.",,"['probability', 'combinatorics', 'probability-theory', 'combinations']"
78,How to set up normal approximation for binomial,How to set up normal approximation for binomial,,"In a particular school, 25% of first grade students do not enjoy reading. 22% of second graders do not enjoy reading.  A random sample is taken of 100 first grade students, and another independent sample of 100 second graders is taken. Part 1: Use normal approximation to find the probability that less than 30 first grade students in the sample do not enjoy reading. Part 2:  Use normal approximation to find the probability that 5 more second graders than first graders in the samples do not enjoy reading. For part 1, after doing the 0.5 correction, I got $$ O \  follows \  N(25, 18.75) $$ $$ P(O \le 29.5) = 0.851 $$ Is that right? And for part 2, I'm not exactly sure how to set it up. Thanks!","In a particular school, 25% of first grade students do not enjoy reading. 22% of second graders do not enjoy reading.  A random sample is taken of 100 first grade students, and another independent sample of 100 second graders is taken. Part 1: Use normal approximation to find the probability that less than 30 first grade students in the sample do not enjoy reading. Part 2:  Use normal approximation to find the probability that 5 more second graders than first graders in the samples do not enjoy reading. For part 1, after doing the 0.5 correction, I got $$ O \  follows \  N(25, 18.75) $$ $$ P(O \le 29.5) = 0.851 $$ Is that right? And for part 2, I'm not exactly sure how to set it up. Thanks!",,"['probability', 'normal-distribution', 'binomial-distribution']"
79,A Qual Problem:Convergence of sum of Poisson random variable over sum of their mean,A Qual Problem:Convergence of sum of Poisson random variable over sum of their mean,,"Assume that $X_i$'s are independent  Poisson$(\lambda_i)$, and $\sum_i^\infty\lambda_i=\infty$. Show that $\frac{\sum_i^n X_i}{\sum_i^n\lambda_i}\rightarrow1$ almost surely. I also tried to show weaker version: convergence in probability, yet I could not succeed. We know that $\sum_i^\infty\lambda_i=\infty$ implies $\sum_i^\infty X_i=\infty$ almost surely but i could not connect their rate of convergence to solve the problem. For any help/hint/solution, thanks in advance.","Assume that $X_i$'s are independent  Poisson$(\lambda_i)$, and $\sum_i^\infty\lambda_i=\infty$. Show that $\frac{\sum_i^n X_i}{\sum_i^n\lambda_i}\rightarrow1$ almost surely. I also tried to show weaker version: convergence in probability, yet I could not succeed. We know that $\sum_i^\infty\lambda_i=\infty$ implies $\sum_i^\infty X_i=\infty$ almost surely but i could not connect their rate of convergence to solve the problem. For any help/hint/solution, thanks in advance.",,"['probability', 'probability-theory', 'probability-distributions']"
80,How to show that $p$th moment being finite is equivalent to a limit existing,How to show that th moment being finite is equivalent to a limit existing,p,"Let $p \in (0,2)$ and let $\xi_n, n \geq 1$, be iid random variables. Show that the following two conditions are equivalent: With probability one, the limit $$ \lim_{n \rightarrow \infty} \frac{1}{n^{1/p}} \sum_{k=1}^n \xi_k$$ exists and is finite. $\mathbb{E}\lvert \xi_i \rvert^p < \infty$ AND either $\mathbb{E} \xi = 0$ or $p \leq 1$. I have tried using Holder's inequality but didn't really get anywhere. I don't really have any idea how to approach the problem for either direction...","Let $p \in (0,2)$ and let $\xi_n, n \geq 1$, be iid random variables. Show that the following two conditions are equivalent: With probability one, the limit $$ \lim_{n \rightarrow \infty} \frac{1}{n^{1/p}} \sum_{k=1}^n \xi_k$$ exists and is finite. $\mathbb{E}\lvert \xi_i \rvert^p < \infty$ AND either $\mathbb{E} \xi = 0$ or $p \leq 1$. I have tried using Holder's inequality but didn't really get anywhere. I don't really have any idea how to approach the problem for either direction...",,"['probability', 'probability-theory']"
81,Expected number of trials until first success,Expected number of trials until first success,,"I am trying to calculate the expected number of attempts to obtain a character in a game. The way the game works is there is a certain probability in order to capture the character. Given that you capture the character, there is now another probability that you will actually obtain (aka Recruit) the character. If the recruit fails, the probability to recruit increases by a certain amount. For example: There is a 25% chance to capture CharX. Given CharX is captured, there is now a 10% chance to recruit CharX. If not recruited, the chance to recruit on the next try jumps to 15% instead of 10%. I can calculate the probability of recruiting based on one trial, but am not able to calculate the number of overall attempts expected because of the increasing probability on each trial. Can someone please help? Thanks. EDIT: if not clear, on each trial you have to successfully capture AND recruit in order to obtain the character. code: from random import randint  repetitions = 10000 trials = 0 caps = 0 recs = 0  for i in range(0, repetitions):     captureRate = 25     recruitRate = 10     failed = True     while failed:         trials += 1         num = randint(1,100)         if num <= captureRate:             caps += 1             num2 = randint(1,100)             if num2 <= recruitRate:                 recs += 1                 failed = False             else:                 recruitRate += 5                 if recruitRate > 100:                     recruitRate = 100 recRate = (float(recs) / float(trials)) print 'Recruit Rate: %0.6f  ->  1 / %0.6f' % (recRate, 1.0 / recRate) Output of this being: Recruit Rate: 0.055254  ->  1 / 18.098260","I am trying to calculate the expected number of attempts to obtain a character in a game. The way the game works is there is a certain probability in order to capture the character. Given that you capture the character, there is now another probability that you will actually obtain (aka Recruit) the character. If the recruit fails, the probability to recruit increases by a certain amount. For example: There is a 25% chance to capture CharX. Given CharX is captured, there is now a 10% chance to recruit CharX. If not recruited, the chance to recruit on the next try jumps to 15% instead of 10%. I can calculate the probability of recruiting based on one trial, but am not able to calculate the number of overall attempts expected because of the increasing probability on each trial. Can someone please help? Thanks. EDIT: if not clear, on each trial you have to successfully capture AND recruit in order to obtain the character. code: from random import randint  repetitions = 10000 trials = 0 caps = 0 recs = 0  for i in range(0, repetitions):     captureRate = 25     recruitRate = 10     failed = True     while failed:         trials += 1         num = randint(1,100)         if num <= captureRate:             caps += 1             num2 = randint(1,100)             if num2 <= recruitRate:                 recs += 1                 failed = False             else:                 recruitRate += 5                 if recruitRate > 100:                     recruitRate = 100 recRate = (float(recs) / float(trials)) print 'Recruit Rate: %0.6f  ->  1 / %0.6f' % (recRate, 1.0 / recRate) Output of this being: Recruit Rate: 0.055254  ->  1 / 18.098260",,['probability']
82,Solution Verification: Probability That a Binary String of length $16$ has exactly eight $1$s,Solution Verification: Probability That a Binary String of length  has exactly eight s,16 1,"The Question What is the probability that a binary string of length 16, chosen uniformly from all binary strings of length 16, has exactly eight 1s. My Work There are $2^{16}$ binary strings of length 16. Therefore, our sample space is $2^{16}$. We can make a binary string of length 16 like so: Select 8 spaces to place our $1$s $\binom{16}{8}$ ways to do this, and then fill the remaining spaces with $0$s. Therefore, the probability of our event = $\frac{\binom{16}{8}}{2^{16}}$ My Question I don't have a solution for this question available (Checked book and internet). Wondering if what I did was correct","The Question What is the probability that a binary string of length 16, chosen uniformly from all binary strings of length 16, has exactly eight 1s. My Work There are $2^{16}$ binary strings of length 16. Therefore, our sample space is $2^{16}$. We can make a binary string of length 16 like so: Select 8 spaces to place our $1$s $\binom{16}{8}$ ways to do this, and then fill the remaining spaces with $0$s. Therefore, the probability of our event = $\frac{\binom{16}{8}}{2^{16}}$ My Question I don't have a solution for this question available (Checked book and internet). Wondering if what I did was correct",,"['probability', 'combinatorics', 'discrete-mathematics', 'solution-verification']"
83,Duration of a Gambler's Ruin game against an opponent with infinite credit,Duration of a Gambler's Ruin game against an opponent with infinite credit,,"A gambler enters the casino with $x\$$ in his pocket and sits on some table. At each iteration he bets $1\$$ and either wins $1\$$ with probability $p\leq\frac{1}{2}$ or loses $1\$$ . Assuming that the casino has unlimited credit, it's simple to see that the gambler will eventually get bankrupt. How is the time till bankruptcy distributed? Is the expected time till bankruptcy == $\infty$ ?","A gambler enters the casino with in his pocket and sits on some table. At each iteration he bets and either wins with probability or loses . Assuming that the casino has unlimited credit, it's simple to see that the gambler will eventually get bankrupt. How is the time till bankruptcy distributed? Is the expected time till bankruptcy == ?",x\ 1\ 1\ p\leq\frac{1}{2} 1\ \infty,"['probability', 'probability-distributions', 'recurrence-relations', 'random-variables', 'random-walk']"
84,prove this martingale inequality,prove this martingale inequality,,"The problem is like this: Let $Y_1,Y_2,\ldots$ be nonnegative i.i.d. random variables with $E(Y_m)=1$. Let $X_n=\prod_{m\leq n} Y_m$, show that $\lim_{n\rightarrow \infty}X_n=0$ if $P(Y_m=1)<1$. What I have reached is that $E(log(Y_m))<\log(E(Y_m))=0$, we denote it with a constant $c<0$. But to prove the conclusion I will have to prove that $\sum_{m\leq n}\log Y_m=-\infty$ and then $e^{\sum_{m\leq n}\log Y_m}=0$. However the conclusion I have is just abou tits expectation, and SLLN should be used here but I don't know how. Any help?","The problem is like this: Let $Y_1,Y_2,\ldots$ be nonnegative i.i.d. random variables with $E(Y_m)=1$. Let $X_n=\prod_{m\leq n} Y_m$, show that $\lim_{n\rightarrow \infty}X_n=0$ if $P(Y_m=1)<1$. What I have reached is that $E(log(Y_m))<\log(E(Y_m))=0$, we denote it with a constant $c<0$. But to prove the conclusion I will have to prove that $\sum_{m\leq n}\log Y_m=-\infty$ and then $e^{\sum_{m\leq n}\log Y_m}=0$. However the conclusion I have is just abou tits expectation, and SLLN should be used here but I don't know how. Any help?",,"['probability', 'inequality', 'martingales', 'law-of-large-numbers']"
85,How to solve probability circular table problem with neighbors.,How to solve probability circular table problem with neighbors.,,"7 people are seated around a round table eating dinner. They then all get up, get dessert and then sit down at random. What is the probability that each person has two new neighbors? What is the answer to this question if there are 8 people? How about for 9 people?","7 people are seated around a round table eating dinner. They then all get up, get dessert and then sit down at random. What is the probability that each person has two new neighbors? What is the answer to this question if there are 8 people? How about for 9 people?",,['probability']
86,Game between Alice and Bob involving extremal numbers,Game between Alice and Bob involving extremal numbers,,"Alice generates $4$ numbers in $(0,1)$ independently and uniformly at random. She discloses one of the numbers to Bob, who is requested to guess whether the disclosed number is extremal ( i.e. the smallest or the greatest among all generated numbers) or not. Is there a deterministic strategy for Alice to make sure that the chances that Bob is guessing right are at most 50%.","Alice generates $4$ numbers in $(0,1)$ independently and uniformly at random. She discloses one of the numbers to Bob, who is requested to guess whether the disclosed number is extremal ( i.e. the smallest or the greatest among all generated numbers) or not. Is there a deterministic strategy for Alice to make sure that the chances that Bob is guessing right are at most 50%.",,"['probability', 'game-theory']"
87,Geometric distribution with multiple successes,Geometric distribution with multiple successes,,"Here's the question: ""A sales representative vows to keep knocking on doors until he makes two sales. Given that his probability of success is $u$, let $X$ = the number of doors he knocks on. Find the probability mass function of $X$"" My thought is that $x$ cannot be less than $2$, since he would have to knock on two doors to make two sales. I'm thinking the function would be $\displaystyle\binom{x}{2} (u^2)(1-u)^{x-2}.$ But when I go to find $E(x)$, that doesn't lend itself well to the geometric form I've learned to love. Am I on the right track at least? Thanks for any help.","Here's the question: ""A sales representative vows to keep knocking on doors until he makes two sales. Given that his probability of success is $u$, let $X$ = the number of doors he knocks on. Find the probability mass function of $X$"" My thought is that $x$ cannot be less than $2$, since he would have to knock on two doors to make two sales. I'm thinking the function would be $\displaystyle\binom{x}{2} (u^2)(1-u)^{x-2}.$ But when I go to find $E(x)$, that doesn't lend itself well to the geometric form I've learned to love. Am I on the right track at least? Thanks for any help.",,['probability']
88,Distribution of $\frac{X}{|Y|}$ where $X$ and $Y$ are independent standard normal r.v.'s,Distribution of  where  and  are independent standard normal r.v.'s,\frac{X}{|Y|} X Y,"Let X and Y be independent standard normal random variables. What is the distribution of $\large \frac{X}{|Y|}$? Attempt: Let $\large U = \frac{X}{|Y|}$ and $ V = |Y|$. This transformation is not one-to-one. We can make it one-to-one by restricting consideration to either positive or negative values of y. Let $A_1 = $ {$(x,y): y > 0$} $, A_2 = ${$(x,y): y < 0$},  $A_0 = $ {$(x,y): y = 0$}. $B = ${$ (u,v): v > 0$} is the image of both $A_1$ and $A_2$. The inverse transformations are given by: $y = v, x = uv$ for B to $A_1$, and $ y = -v, x = -uv$ for B to $A_2$. Both Jacobians $J_1$ and $J_2$ are equal to v. Then the joint distribution of U,V is given by: $f_{U,V}(u,v) = \Large \frac{1}{2\pi}e^{-uv^2/2}e^{-v^2/2}*v+\frac{1}{2\pi}e^{-uv^2/2}e^{-(-v^2/2)}*v $ $= \Large \frac{v}{\pi}e^{-(u^2+1)v^2/2}$, $-\infty < u < \infty, 0 < v < \infty$. To find the marginal pdf of U, integrate out V: $ f_{U}(U) = \Large \int_0^\infty\frac{v}{\pi}e^{-(u^2+1)v^2/2}dv$ $ = \Large \frac{1}{2\pi}\int_0^\infty e^{-(u^2+1)z/2}dz$, where $z = v^2$ $ = \Large \frac{1}{2\pi} \frac{2}{(u^2+1)}$ (integrand is kernel of exponential ($\beta = 2/(u^2+1)))$ $= \Large \frac{1}{\pi (u^2+1)},$ $-\infty < u < \infty$, which is a Cauchy random variable.","Let X and Y be independent standard normal random variables. What is the distribution of $\large \frac{X}{|Y|}$? Attempt: Let $\large U = \frac{X}{|Y|}$ and $ V = |Y|$. This transformation is not one-to-one. We can make it one-to-one by restricting consideration to either positive or negative values of y. Let $A_1 = $ {$(x,y): y > 0$} $, A_2 = ${$(x,y): y < 0$},  $A_0 = $ {$(x,y): y = 0$}. $B = ${$ (u,v): v > 0$} is the image of both $A_1$ and $A_2$. The inverse transformations are given by: $y = v, x = uv$ for B to $A_1$, and $ y = -v, x = -uv$ for B to $A_2$. Both Jacobians $J_1$ and $J_2$ are equal to v. Then the joint distribution of U,V is given by: $f_{U,V}(u,v) = \Large \frac{1}{2\pi}e^{-uv^2/2}e^{-v^2/2}*v+\frac{1}{2\pi}e^{-uv^2/2}e^{-(-v^2/2)}*v $ $= \Large \frac{v}{\pi}e^{-(u^2+1)v^2/2}$, $-\infty < u < \infty, 0 < v < \infty$. To find the marginal pdf of U, integrate out V: $ f_{U}(U) = \Large \int_0^\infty\frac{v}{\pi}e^{-(u^2+1)v^2/2}dv$ $ = \Large \frac{1}{2\pi}\int_0^\infty e^{-(u^2+1)z/2}dz$, where $z = v^2$ $ = \Large \frac{1}{2\pi} \frac{2}{(u^2+1)}$ (integrand is kernel of exponential ($\beta = 2/(u^2+1)))$ $= \Large \frac{1}{\pi (u^2+1)},$ $-\infty < u < \infty$, which is a Cauchy random variable.",,"['probability', 'probability-distributions', 'normal-distribution']"
89,Details from a Proof that a Tournament has Property $S_k$,Details from a Proof that a Tournament has Property,S_k,"(Edit: While the context is not central to my question, I decided to include it anyway to make the question a little more searchable.) Some technical details are omitted from a theorem in Alon and Spencer's The Probabilistic Method . A tournament on $n$ players is said to have property $S_k$ if, for any selection of $k$ players, there is another player that beats them all. The theorem states that a tournament has this property provided  $$ \binom{n}{k}(1 - 2^{-k})^{n-k} < 1. $$ Let $f(k)$ denote the smallest $n$ satisfying the inequality above (as a function of $k$). In order to find an upper bound on $f(k)$, the author makes the following replacements: $$ \binom{n}{k} \leq \left(\frac{en}{k}\right)^k $$ and $$ (1 - 2^{-k})^{n-k} \leq e^{-(n-k)/2^k}. $$ I believe the implication is now to write $n$ as a function of $k$ given that $n$ satisfies $$ \left(\frac{en}{k}\right)^k e^{-(n-k)/2^k} < 1. $$ How can I isolate $n$ in this expression? The details are omitted, but the author states $$ n \geq k^2 2^k (\ln 2) (1 + o(1)), $$ so $$ f(k) \leq k^2 2^k (\ln 2) (1 + o(1)). $$","(Edit: While the context is not central to my question, I decided to include it anyway to make the question a little more searchable.) Some technical details are omitted from a theorem in Alon and Spencer's The Probabilistic Method . A tournament on $n$ players is said to have property $S_k$ if, for any selection of $k$ players, there is another player that beats them all. The theorem states that a tournament has this property provided  $$ \binom{n}{k}(1 - 2^{-k})^{n-k} < 1. $$ Let $f(k)$ denote the smallest $n$ satisfying the inequality above (as a function of $k$). In order to find an upper bound on $f(k)$, the author makes the following replacements: $$ \binom{n}{k} \leq \left(\frac{en}{k}\right)^k $$ and $$ (1 - 2^{-k})^{n-k} \leq e^{-(n-k)/2^k}. $$ I believe the implication is now to write $n$ as a function of $k$ given that $n$ satisfies $$ \left(\frac{en}{k}\right)^k e^{-(n-k)/2^k} < 1. $$ How can I isolate $n$ in this expression? The details are omitted, but the author states $$ n \geq k^2 2^k (\ln 2) (1 + o(1)), $$ so $$ f(k) \leq k^2 2^k (\ln 2) (1 + o(1)). $$",,"['probability', 'graph-theory', 'asymptotics', 'exponential-function']"
90,Strategies to guess choices for multiple choice questions,Strategies to guess choices for multiple choice questions,,"Multiple choice questions (MCQs) are common in examinations over here in Singapore. A set of, say, $40$ questions are given to students, and each is accompanied with a list of $4$ choices of answer, $A, B, C$ or $D$. Suppose a student did not study for a particular test. Out of desperation, he decides to ""guess"" a choice for each question to secure at least some points. He considers two possible strategies: For each question, he picks a random choice as his answer. He picks a random choice, say, $B$ and uses it for all his answer. Assuming the correct answers are randomly distributed and his guess is completely random, which strategy would give a higher probability of securing more correct answers than the other? Intuitively, the second strategy would give a higher probability of securing more marks. However, I am unable to come up with a mathematical proof (or disproof). For the second strategy, we only need consider the probability that the correct answer is the choice that was picked. Under the assumption that the correct answers are randomly distributed, the probability of a particular choice being the correct answer is $\frac{1}{4}$. Hence, the student would get approximately $25\%$ of his guesses correct. However, we can also use the same argument for the first strategy to say that the student would also get approximately $25\%$ of his guesses correct. This would imply that both strategies are equally effective, but I am pretty sure the second strategy is more effective. EDIT: In order to prevent psychological factors from distorting reality,  I decided to write a program (in C#) that simulates the aforementioned MCQ tests. I configured the program to simulate the taking of $1000$ randomly generated MCQ tests with $40$ questions each using both strategies. It turns out that the percentage scores for both strategies have the same average ($\approx25\%$) and the same standard deviation ($\approx 6.84$)! Code: static Random rng = new Random((int)DateTime.Now.Ticks);  static void GenerateAnswers(int[] answers) {     for (int i = 0; i < answers.Length; i++)     {         answers[i] = rng.Next(4);     } }  static int Strategy1(int[] answers) {     int score = 0;     foreach (int answer in answers)     {         if (rng.Next(4) == answer)         {             score++;         }     }     return score; }  static int Strategy2(int[] answers) {     int choice = rng.Next(4);     return answers.Count(x => x == choice); }","Multiple choice questions (MCQs) are common in examinations over here in Singapore. A set of, say, $40$ questions are given to students, and each is accompanied with a list of $4$ choices of answer, $A, B, C$ or $D$. Suppose a student did not study for a particular test. Out of desperation, he decides to ""guess"" a choice for each question to secure at least some points. He considers two possible strategies: For each question, he picks a random choice as his answer. He picks a random choice, say, $B$ and uses it for all his answer. Assuming the correct answers are randomly distributed and his guess is completely random, which strategy would give a higher probability of securing more correct answers than the other? Intuitively, the second strategy would give a higher probability of securing more marks. However, I am unable to come up with a mathematical proof (or disproof). For the second strategy, we only need consider the probability that the correct answer is the choice that was picked. Under the assumption that the correct answers are randomly distributed, the probability of a particular choice being the correct answer is $\frac{1}{4}$. Hence, the student would get approximately $25\%$ of his guesses correct. However, we can also use the same argument for the first strategy to say that the student would also get approximately $25\%$ of his guesses correct. This would imply that both strategies are equally effective, but I am pretty sure the second strategy is more effective. EDIT: In order to prevent psychological factors from distorting reality,  I decided to write a program (in C#) that simulates the aforementioned MCQ tests. I configured the program to simulate the taking of $1000$ randomly generated MCQ tests with $40$ questions each using both strategies. It turns out that the percentage scores for both strategies have the same average ($\approx25\%$) and the same standard deviation ($\approx 6.84$)! Code: static Random rng = new Random((int)DateTime.Now.Ticks);  static void GenerateAnswers(int[] answers) {     for (int i = 0; i < answers.Length; i++)     {         answers[i] = rng.Next(4);     } }  static int Strategy1(int[] answers) {     int score = 0;     foreach (int answer in answers)     {         if (rng.Next(4) == answer)         {             score++;         }     }     return score; }  static int Strategy2(int[] answers) {     int choice = rng.Next(4);     return answers.Count(x => x == choice); }",,['probability']
91,Uniform sampling with replacement item frequency,Uniform sampling with replacement item frequency,,"Suppose we are sampling from $N$ distinct items uniformly with replacement $M$ times. What can be said about the distribution of frequencies of items drawn? For example, if I sort all the frequencies from greatest to smallest and plot them, what will be the shape of the curve fitting this data? For one particular item everything is more or less clear to me: expected number of times being drawn is $\frac{M}{N}$, variance is $\frac{M(N-1)}{N^2}$. But I don't understand how to get any general results. EDIT: at the time I was writing the question I was just too confused about the whole experiment, so I couldn't formulate a precise question. After @Euxpraxis1981's answer and running some simulations myself here is what I am interested in. Suppose $N \ll M$, we perform the described experiment and count how many items were drawn $0$ times, $1$ time, $2$ times, etc. If we plot these ""item counts"" for each ""frequency"", what will be the shape of the graph? I tried with $N=100$ and different $M$ from $1000$ to $100000$. The histograms I got look a lot like binomial distribution pmf, with a mean (the greatest number of items being drawn) of $\frac{M}{N}$.","Suppose we are sampling from $N$ distinct items uniformly with replacement $M$ times. What can be said about the distribution of frequencies of items drawn? For example, if I sort all the frequencies from greatest to smallest and plot them, what will be the shape of the curve fitting this data? For one particular item everything is more or less clear to me: expected number of times being drawn is $\frac{M}{N}$, variance is $\frac{M(N-1)}{N^2}$. But I don't understand how to get any general results. EDIT: at the time I was writing the question I was just too confused about the whole experiment, so I couldn't formulate a precise question. After @Euxpraxis1981's answer and running some simulations myself here is what I am interested in. Suppose $N \ll M$, we perform the described experiment and count how many items were drawn $0$ times, $1$ time, $2$ times, etc. If we plot these ""item counts"" for each ""frequency"", what will be the shape of the graph? I tried with $N=100$ and different $M$ from $1000$ to $100000$. The histograms I got look a lot like binomial distribution pmf, with a mean (the greatest number of items being drawn) of $\frac{M}{N}$.",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'sampling']"
92,Conditions on Poisson random variables to convergence in probability,Conditions on Poisson random variables to convergence in probability,,"Let $X_1,X_2,...$ denote iid random variables such that $X_j$ has a Poisson distribution with mean $\lambda t_j$ where $\lambda$ > 0 and $t_1, t_2,...$are known positive constants. a)Find conditions on $t_1, t_2,...$so that $\Large Y_n = \frac{\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j - \lambda  }{\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)}$ converges in distribution to a standard normal variable. b) Suppose that, for each $j = 1,...,t_j$ lies in the interval $(a,b)$ where $0 < a < b < \infty$. Does it follow that $Y_n$ converges in distribution to a standard normal variable? c) Suppose that $t_j$ = j, j = 1,... Does it follow that $Y_n$ converges in distribution to a standard normal variable? Attempt at a): Since the characteristic function of a Poisson distribution with mean $\lambda $ is given by: $\hspace{15mm} \exp (\lambda[\exp(it)-1])$, we then have the following characteristic function of $Y_n$: $\hspace{15mm}$$\phi_n(t) = \exp ((\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^2\lambda[\exp(it/\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j))-(\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j))^2 - \operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)it]$ By Lemma 2.1 in Severini's ""Elements of Distribution Theory"": $\exp(it) = \sum\limits_{j=0}^n \frac{(it)^j}{j!} + R_n(t)$ where $\hspace{15mm}|R_n(t)|\leq \min(|t|^{n+1}/(n+1)!, 2|t|^n /n!$ Hence, $\hspace{15mm}exp(it/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)) = 1 + it/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j) - 1/2t^2/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^2 + R_2(t)$ where $\hspace{15mm} |R_2(t)|\leq 1/6t^3/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^{2/3}$. It follows that $\hspace{15mm}\phi_n(t) = exp(-t^2/2 + Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^2 R_2(t)$ and that $\hspace{15mm} \lim_{ Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)\to \infty}$ $Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)R_2(t) = 0$, $-\infty < t < \infty$. Hence, $\hspace{15mm}\lim_{ Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)\to \infty}$$\phi_n(t) = exp(-t^2/2), -\infty < t < \infty$,the characteristic function of a standard normal variable. However, I can not identify the constraints on $t_1,t_2,....$ Any help would be much appreciated!","Let $X_1,X_2,...$ denote iid random variables such that $X_j$ has a Poisson distribution with mean $\lambda t_j$ where $\lambda$ > 0 and $t_1, t_2,...$are known positive constants. a)Find conditions on $t_1, t_2,...$so that $\Large Y_n = \frac{\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j - \lambda  }{\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)}$ converges in distribution to a standard normal variable. b) Suppose that, for each $j = 1,...,t_j$ lies in the interval $(a,b)$ where $0 < a < b < \infty$. Does it follow that $Y_n$ converges in distribution to a standard normal variable? c) Suppose that $t_j$ = j, j = 1,... Does it follow that $Y_n$ converges in distribution to a standard normal variable? Attempt at a): Since the characteristic function of a Poisson distribution with mean $\lambda $ is given by: $\hspace{15mm} \exp (\lambda[\exp(it)-1])$, we then have the following characteristic function of $Y_n$: $\hspace{15mm}$$\phi_n(t) = \exp ((\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^2\lambda[\exp(it/\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j))-(\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j))^2 - \operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)it]$ By Lemma 2.1 in Severini's ""Elements of Distribution Theory"": $\exp(it) = \sum\limits_{j=0}^n \frac{(it)^j}{j!} + R_n(t)$ where $\hspace{15mm}|R_n(t)|\leq \min(|t|^{n+1}/(n+1)!, 2|t|^n /n!$ Hence, $\hspace{15mm}exp(it/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)) = 1 + it/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j) - 1/2t^2/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^2 + R_2(t)$ where $\hspace{15mm} |R_2(t)|\leq 1/6t^3/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^{2/3}$. It follows that $\hspace{15mm}\phi_n(t) = exp(-t^2/2 + Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^2 R_2(t)$ and that $\hspace{15mm} \lim_{ Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)\to \infty}$ $Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)R_2(t) = 0$, $-\infty < t < \infty$. Hence, $\hspace{15mm}\lim_{ Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)\to \infty}$$\phi_n(t) = exp(-t^2/2), -\infty < t < \infty$,the characteristic function of a standard normal variable. However, I can not identify the constraints on $t_1,t_2,....$ Any help would be much appreciated!",,"['probability', 'probability-theory', 'random-variables', 'characteristic-functions', 'central-limit-theorem']"
93,probability distribution of X+Y,probability distribution of X+Y,,"Let a fair die be rolled 2 times. The 2 rolls are independent. Let X and Y be the outcomes of the first and second rolls, respectively. a. What is the probability distribution of X+Y? What is each unique possible value of X+Y and each possibility’s corresponding probability. b. What is the probability that X+Y is greater or equal to 10? Answer: I previously posted this without making an attempt. Here is my attempt to this: a) 2 happens 1 time, 3 - 2 times, 4 - 3 times, 5 - 4 times, 6 - 5 times, 7 - 6 times, 8 - 5 times, 9 - 4 times, 10 - 3 times, 11 - 2 times, 12 - 1 time. so the probability distribution is: 1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36 and 1/36, respectively. b) since 10 happens 3 times, 11 - 2 times, and 12 - 1 time, answer is 6/36.","Let a fair die be rolled 2 times. The 2 rolls are independent. Let X and Y be the outcomes of the first and second rolls, respectively. a. What is the probability distribution of X+Y? What is each unique possible value of X+Y and each possibility’s corresponding probability. b. What is the probability that X+Y is greater or equal to 10? Answer: I previously posted this without making an attempt. Here is my attempt to this: a) 2 happens 1 time, 3 - 2 times, 4 - 3 times, 5 - 4 times, 6 - 5 times, 7 - 6 times, 8 - 5 times, 9 - 4 times, 10 - 3 times, 11 - 2 times, 12 - 1 time. so the probability distribution is: 1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36 and 1/36, respectively. b) since 10 happens 3 times, 11 - 2 times, and 12 - 1 time, answer is 6/36.",,['probability']
94,Almost sure convergence of a sequence of random variables,Almost sure convergence of a sequence of random variables,,"Once again I've encountered a problem, which might not be difficult: I'm given a sequence of random variables $ (X_n) $, each with density function $g_n(x) = nx^{n-1} \textbf{1}_{(0,1]} $. I am to prove that this sequence converges almost surely. So to begin with, I think I am able to find the limit and prove convergence by probability. We have: $\mathbb{E} X_n = \int\limits_{0}^1 nx^n dx = \frac{n}{n+1} $ Applying Chebyshev inequality: $ \lim\limits_{n \rightarrow \infty}\mathbb{P}(1-X_n < \epsilon) = \lim\limits_{n \rightarrow \infty} (1 - \mathbb{P}(1- X_n \geq \epsilon)) \geq \lim\limits_{n \rightarrow \infty}(1- \frac{\mathbb{E}(1-X_n)}{\epsilon}) = \lim\limits_{n \rightarrow \infty} (1- \frac{1}{\epsilon}(1-\frac{n}{n+1})) = 1$ Thus, $ X_n \rightarrow 1 $ by probability. And there goes my question: how do I prove almost sure convergence? I've been trying to use the definition, but it doesn't seem to help. Thanks in advance","Once again I've encountered a problem, which might not be difficult: I'm given a sequence of random variables $ (X_n) $, each with density function $g_n(x) = nx^{n-1} \textbf{1}_{(0,1]} $. I am to prove that this sequence converges almost surely. So to begin with, I think I am able to find the limit and prove convergence by probability. We have: $\mathbb{E} X_n = \int\limits_{0}^1 nx^n dx = \frac{n}{n+1} $ Applying Chebyshev inequality: $ \lim\limits_{n \rightarrow \infty}\mathbb{P}(1-X_n < \epsilon) = \lim\limits_{n \rightarrow \infty} (1 - \mathbb{P}(1- X_n \geq \epsilon)) \geq \lim\limits_{n \rightarrow \infty}(1- \frac{\mathbb{E}(1-X_n)}{\epsilon}) = \lim\limits_{n \rightarrow \infty} (1- \frac{1}{\epsilon}(1-\frac{n}{n+1})) = 1$ Thus, $ X_n \rightarrow 1 $ by probability. And there goes my question: how do I prove almost sure convergence? I've been trying to use the definition, but it doesn't seem to help. Thanks in advance",,"['probability', 'probability-theory', 'convergence-divergence', 'random-variables']"
95,Central Limit Theorem for uncorrelated (non-independent) but bounded random variables,Central Limit Theorem for uncorrelated (non-independent) but bounded random variables,,"Given uncorrelated, discrete random variables $X_i$ that are bounded, e.g., they can only take on values $|X_i| \leq 4$, then is there a form of the central limit theorem that one can apply to the sum, $\sum_{i=1}^N X_i$? In other words, is there a form of central limit theorem that applies to identical, non-independent (but uncorrelated) random variables that are bounded? The best I've been able to find is the case of $M$-dependence for stationary RVs, where RVs more than $M$ apart (in time) can be assumed independent and thus CLT applies. I would greatly appreciate any suggestions or pointers! Background: Here is the background problem I am applying this to: Given the arrays $C=[C_1,C_2,...,C_N]$ and $S=[S_1,S_2,...,S_N]$  of lengths $N$ with elements that are discrete iid uniform distributed with equal probability (p=1/2) of being $\pm$1. Consider the sum below, for a constant $k \in [1,N]$: \begin{equation*}    A=\underset{m\neq l, n\neq l}{\underset{-l+m+n=k}{\sum_{l=1}^N \sum_{m=1}^N \sum_{n=1}^N}} C_lC_mC_n+S_lS_mC_n-C_lS_mS_n+S_lC_mS_n      \end{equation*} Each combination of $l, m, n$ results in a sum of four pairwise independent Bernoulli RVs, I denote this sum of four RVs as $X_i$ where $X_i=C_lC_mC_n+S_lS_mC_n-C_lS_mS_n+S_lC_mS_n$. The $X_i$ are thus identical, uncorrelated and bounded, $|X_i| \leq 4$. The other option I am considering is breaking $A$ into two parts but I am still working on it: \begin{equation*}    A=Y+Z=\underset{m\neq l, n\neq l}{\underset{-l+m+n=k}{\sum_{l=1}^N \sum_{m=1}^N \sum_{n=1}^N}} C_lC_mC_n+ \underset{m\neq l, n\neq l}{\underset{-l+m+n=k}{\sum_{l=1}^N \sum_{m=1}^N \sum_{n=1}^N}} (S_lS_mC_n-C_lS_mS_n+S_lC_mS_n)     \end{equation*} Simulation results show good match to a Normal distribution for $A$.","Given uncorrelated, discrete random variables $X_i$ that are bounded, e.g., they can only take on values $|X_i| \leq 4$, then is there a form of the central limit theorem that one can apply to the sum, $\sum_{i=1}^N X_i$? In other words, is there a form of central limit theorem that applies to identical, non-independent (but uncorrelated) random variables that are bounded? The best I've been able to find is the case of $M$-dependence for stationary RVs, where RVs more than $M$ apart (in time) can be assumed independent and thus CLT applies. I would greatly appreciate any suggestions or pointers! Background: Here is the background problem I am applying this to: Given the arrays $C=[C_1,C_2,...,C_N]$ and $S=[S_1,S_2,...,S_N]$  of lengths $N$ with elements that are discrete iid uniform distributed with equal probability (p=1/2) of being $\pm$1. Consider the sum below, for a constant $k \in [1,N]$: \begin{equation*}    A=\underset{m\neq l, n\neq l}{\underset{-l+m+n=k}{\sum_{l=1}^N \sum_{m=1}^N \sum_{n=1}^N}} C_lC_mC_n+S_lS_mC_n-C_lS_mS_n+S_lC_mS_n      \end{equation*} Each combination of $l, m, n$ results in a sum of four pairwise independent Bernoulli RVs, I denote this sum of four RVs as $X_i$ where $X_i=C_lC_mC_n+S_lS_mC_n-C_lS_mS_n+S_lC_mS_n$. The $X_i$ are thus identical, uncorrelated and bounded, $|X_i| \leq 4$. The other option I am considering is breaking $A$ into two parts but I am still working on it: \begin{equation*}    A=Y+Z=\underset{m\neq l, n\neq l}{\underset{-l+m+n=k}{\sum_{l=1}^N \sum_{m=1}^N \sum_{n=1}^N}} C_lC_mC_n+ \underset{m\neq l, n\neq l}{\underset{-l+m+n=k}{\sum_{l=1}^N \sum_{m=1}^N \sum_{n=1}^N}} (S_lS_mC_n-C_lS_mS_n+S_lC_mS_n)     \end{equation*} Simulation results show good match to a Normal distribution for $A$.",,"['probability', 'probability-theory', 'probability-distributions', 'normal-distribution', 'central-limit-theorem']"
96,A linear growth model with immigration,A linear growth model with immigration,,"Ill give some background first before asking questions.(the text below is straight out of the book) Each individual in the population is assumed give birth at an exponential rate of $\lambda$ in addition ,there is a an  exponential rate of increase $\theta$ due to external source of immigration. Hence the total birth rate where there are $n$ persons in the system is $n\lambda + \theta$ . Deaths are assume to occur at an exponential rate $\mu$ for each member of the population, so $\mu_n = n\mu$ . Let $X(t)$ denote the population size at time $t$ . Suppose $X(0)= i$ and let $M(t) = E[X(t)]$ . So they will determine $M(t)$ by deriving and then solving a differential equation that is satisfies. we start by deriving an equation for $M(t+h)$ by conditioning on $X(t)$ this yields: $$M(t+ h) = E[X(t+h)] = E[E[X(t+h)\vert X(t)]]$$ Now, given the size of the population at time $t$ then, ignoring  events whose probability is $o(h)$ , the population at time $t+h$ will either increase in size by 1 if a birth or immigration occurs in $ (t,t+h)$ , or, decrease by 1 if a death occurs in this interval, or remain the same if neither of these two possibilities occurs that is given $X(t)$ $$ X(t+h)= \begin{cases}  X(t) + 1, & \text{with probability} \quad [\theta + X(t)\lambda]h + o(h) \\  X(t) - 1, & \text{with probability} \quad X(t)\mu h + o(h)\\  X(t),     & \text{with probability} \quad 1-[\theta + X(t)\lambda + X(t)\mu]h +o(h) \end{cases} $$ therefore, $E[X(t+h) \vert X(t)] =  X(t) + [\theta + X(t)\lambda - X(t)\mu]h + o(h)$ ..... ..... .....(text continues) $\textbf{questions:}$ I understand the first two cases, but the last case i don' t quiet get: $X(t)$ , with-probability $1-[\theta + X(t)\lambda + X(t)\mu]h +o(h)$ . can someone explain this? How do i interpret this statement: $$E[X(t+h) \vert X(t)] =  X(t) + [\theta + X(t)\lambda - X(t)\mu]h + o(h)$$","Ill give some background first before asking questions.(the text below is straight out of the book) Each individual in the population is assumed give birth at an exponential rate of in addition ,there is a an  exponential rate of increase due to external source of immigration. Hence the total birth rate where there are persons in the system is . Deaths are assume to occur at an exponential rate for each member of the population, so . Let denote the population size at time . Suppose and let . So they will determine by deriving and then solving a differential equation that is satisfies. we start by deriving an equation for by conditioning on this yields: Now, given the size of the population at time then, ignoring  events whose probability is , the population at time will either increase in size by 1 if a birth or immigration occurs in , or, decrease by 1 if a death occurs in this interval, or remain the same if neither of these two possibilities occurs that is given therefore, ..... ..... .....(text continues) I understand the first two cases, but the last case i don' t quiet get: , with-probability . can someone explain this? How do i interpret this statement:","\lambda \theta n n\lambda + \theta \mu \mu_n = n\mu X(t) t X(0)= i M(t) = E[X(t)] M(t) M(t+h) X(t) M(t+ h) = E[X(t+h)] = E[E[X(t+h)\vert X(t)]] t o(h) t+h  (t,t+h) X(t) 
X(t+h)=
\begin{cases}
 X(t) + 1, & \text{with probability} \quad [\theta + X(t)\lambda]h + o(h) \\
 X(t) - 1, & \text{with probability} \quad X(t)\mu h + o(h)\\
 X(t),     & \text{with probability} \quad 1-[\theta + X(t)\lambda + X(t)\mu]h +o(h)
\end{cases}
 E[X(t+h) \vert X(t)] =  X(t) + [\theta + X(t)\lambda - X(t)\mu]h + o(h) \textbf{questions:} X(t) 1-[\theta + X(t)\lambda + X(t)\mu]h +o(h) E[X(t+h) \vert X(t)] =  X(t) + [\theta + X(t)\lambda - X(t)\mu]h + o(h)","['probability', 'statistics', 'stochastic-processes', 'markov-chains']"
97,Probability of finding a Hamilton circuit in a graph,Probability of finding a Hamilton circuit in a graph,,"In short, I would like to know either/both the probability that there exists a Hamiltonian circuit within a graph, or the number of circuits expected to exist. (Without actually finding all the circuits). If I run an algorithm to find all circuits, how many should I expect to find, if any? I am fine with a close approximation if it simplifies the calculations substantially. If I have a given number of vertices and the average number of edges, is this enough information? Each vertex may have many out-edges but no two vertices share more than one edge. Also, a vertex cannot belong to two circuits. Once a circuit is found, those vertices that comprise it are removed from the graph. My example graph has 10,000 vertices and each vertex has three out-edges to other vertices. And a follow up question: How could I formulate the question to figure out the minimum average number of out-edges per vertex to give me an arbitrary level of certainty that I would find at least one circuit? Stated another way, if I want 50% certainty in finding a circuit, and I have 10,000 vertices, what is the minimum number of out-edges each vertex should have? (not the average, but actual minimum) I have some scratchpad notes where I've worked this out, but would really appreciate the guidance of someone more knowledgeable. Thanks!","In short, I would like to know either/both the probability that there exists a Hamiltonian circuit within a graph, or the number of circuits expected to exist. (Without actually finding all the circuits). If I run an algorithm to find all circuits, how many should I expect to find, if any? I am fine with a close approximation if it simplifies the calculations substantially. If I have a given number of vertices and the average number of edges, is this enough information? Each vertex may have many out-edges but no two vertices share more than one edge. Also, a vertex cannot belong to two circuits. Once a circuit is found, those vertices that comprise it are removed from the graph. My example graph has 10,000 vertices and each vertex has three out-edges to other vertices. And a follow up question: How could I formulate the question to figure out the minimum average number of out-edges per vertex to give me an arbitrary level of certainty that I would find at least one circuit? Stated another way, if I want 50% certainty in finding a circuit, and I have 10,000 vertices, what is the minimum number of out-edges each vertex should have? (not the average, but actual minimum) I have some scratchpad notes where I've worked this out, but would really appreciate the guidance of someone more knowledgeable. Thanks!",,"['probability', 'graph-theory', 'random-graphs', 'hamiltonian-path']"
98,The Historical Importance of Keynes' A Treatise on Probability,The Historical Importance of Keynes' A Treatise on Probability,,A visiting speaker in Economics recently happened to mention that John Maynard Keynes' A Treatise on Probability revolutionized probability theory. I have not heard any such claim before and it struck me as strange. The Wikipedia page contains some effusive praise from Russell but nothing specific. This leads me to ask: 1) Is this claim approximately true? 2) In what specific ways did it impact probability theory? 3) What are some specific citations which demonstrate this?,A visiting speaker in Economics recently happened to mention that John Maynard Keynes' A Treatise on Probability revolutionized probability theory. I have not heard any such claim before and it struck me as strange. The Wikipedia page contains some effusive praise from Russell but nothing specific. This leads me to ask: 1) Is this claim approximately true? 2) In what specific ways did it impact probability theory? 3) What are some specific citations which demonstrate this?,,"['probability', 'math-history', 'economics']"
99,Probability of two independent random variables being equal,Probability of two independent random variables being equal,,"Assume that $X$ and $Y$ are two independent random variables that follow the binomial distribution of parameters $p$ (the probability of one success) and $n$ (the number of trials). I was wondering if there is a way of expressing the probability that $X=Y$, other than summing up all the cases when $X=Y=k$, with $k$ from $0$ to $n$, which will give the formula $$\sum_{k=0}^{n}\binom{n}{k}^{2}p^{2k}(1-p)^{2n-2k}.$$ Edit: I'm not interested in computing or rewriting the sum above using some algebraic tricks, but in finding another probabilistic or combinatorial approach to the problem that would yield another (maybe ""nicer"") answer.","Assume that $X$ and $Y$ are two independent random variables that follow the binomial distribution of parameters $p$ (the probability of one success) and $n$ (the number of trials). I was wondering if there is a way of expressing the probability that $X=Y$, other than summing up all the cases when $X=Y=k$, with $k$ from $0$ to $n$, which will give the formula $$\sum_{k=0}^{n}\binom{n}{k}^{2}p^{2k}(1-p)^{2n-2k}.$$ Edit: I'm not interested in computing or rewriting the sum above using some algebraic tricks, but in finding another probabilistic or combinatorial approach to the problem that would yield another (maybe ""nicer"") answer.",,"['probability', 'binomial-coefficients', 'random-variables']"
