,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is there a limit for this complex sequence?,Is there a limit for this complex sequence?,,"Interested by this question , I tried to work the more general problem of $$I_n=\int_0^\infty e^{-x}\log\big(1+\sin^{2n}(x)\big)\, dx$$ for which were found expressions of the type $$I_n=A_n  \,    _{2n+1}F_{2n}\left(1,1,\color{red}{\textbf{#}};\color{green}{\textbf{@}};-1\right)$$ in which $\color{red}{\textbf{ #}}$ and $\color{green}{\textbf{@}}$ show nice and simple patterns. The front coefficient is $$A_n=\int_0^\infty e^{-x} \sin^{2n}(x)\,dx=(-1)^n\,\frac{i \,  n\, \Gamma \left(\frac{i}{2}-n\right)\, \Gamma (2    n)}{4^n\,\Gamma \left(n+1+\frac{i}{2}\right)}$$ What I wonder is if $$L=\lim_{n\to \infty } \, \frac{I_n}{A_n}=\lim_{n\to \infty } \, \,    _{2n+1}F_{2n}\left(1,1,\color{red}{\textbf{#}};\color{green}{\textbf{@}};-1\right)$$ does exist or not. Could we somehow use the fact that, for $k \pi \leq x \leq (k+1)\pi$ , $\log\big(1+\sin^{2n}(x)\big)$ looks like a gaussian ? In the table below, I tabulated some of the numerical values I obtained $$\left( \begin{array}{cc}  n & \frac{I_n}{A_n} \\  1 & 0.76498434 \\  2 & 0.76742187 \\  3 & 0.76742296 \\  4 & 0.76718009 \\  5 & 0.76694124 \\  6 & 0.76673938 \\  7 & 0.76657308 \\  8 & 0.76643577 \\  9 & 0.76632132 \\  10 & 0.76622482 \\  20 & 0.76573433 \\  30 & 0.76554963 \\  40 & 0.76545318 \\  50 & 0.76539397 \\  60 & 0.76535394 \\  70 & 0.76532508 \\  80 & 0.76530328 \\  90 & 0.76528623 \\  100 & 0.76527254 \\ 200 & 0.76521029 \\  300 & 0.76518932 \\  400 & 0.76517879 \\  500 & 0.76517246 \\  600 & 0.76516823 \\  700 & 0.76516521 \\  800 & 0.76516294 \\  900 & 0.76516117 \\  1000 & 0.76515976 \end{array} \right)$$","Interested by this question , I tried to work the more general problem of for which were found expressions of the type in which and show nice and simple patterns. The front coefficient is What I wonder is if does exist or not. Could we somehow use the fact that, for , looks like a gaussian ? In the table below, I tabulated some of the numerical values I obtained","I_n=\int_0^\infty e^{-x}\log\big(1+\sin^{2n}(x)\big)\, dx I_n=A_n  \,
   _{2n+1}F_{2n}\left(1,1,\color{red}{\textbf{#}};\color{green}{\textbf{@}};-1\right) \color{red}{\textbf{ #}} \color{green}{\textbf{@}} A_n=\int_0^\infty e^{-x} \sin^{2n}(x)\,dx=(-1)^n\,\frac{i \,  n\, \Gamma \left(\frac{i}{2}-n\right)\, \Gamma (2
   n)}{4^n\,\Gamma \left(n+1+\frac{i}{2}\right)} L=\lim_{n\to \infty } \, \frac{I_n}{A_n}=\lim_{n\to \infty } \, \,
   _{2n+1}F_{2n}\left(1,1,\color{red}{\textbf{#}};\color{green}{\textbf{@}};-1\right) k \pi \leq x \leq (k+1)\pi \log\big(1+\sin^{2n}(x)\big) \left(
\begin{array}{cc}
 n & \frac{I_n}{A_n} \\
 1 & 0.76498434 \\
 2 & 0.76742187 \\
 3 & 0.76742296 \\
 4 & 0.76718009 \\
 5 & 0.76694124 \\
 6 & 0.76673938 \\
 7 & 0.76657308 \\
 8 & 0.76643577 \\
 9 & 0.76632132 \\
 10 & 0.76622482 \\
 20 & 0.76573433 \\
 30 & 0.76554963 \\
 40 & 0.76545318 \\
 50 & 0.76539397 \\
 60 & 0.76535394 \\
 70 & 0.76532508 \\
 80 & 0.76530328 \\
 90 & 0.76528623 \\
 100 & 0.76527254 \\
200 & 0.76521029 \\
 300 & 0.76518932 \\
 400 & 0.76517879 \\
 500 & 0.76517246 \\
 600 & 0.76516823 \\
 700 & 0.76516521 \\
 800 & 0.76516294 \\
 900 & 0.76516117 \\
 1000 & 0.76515976
\end{array}
\right)","['limits', 'definite-integrals']"
1,Calculate $\lim_{x\to{0^+}}\frac{\log_{\sin{x}}{\cos{x}}}{\log_{\sin{\frac{x}{2}}}\cos{\frac{x}{2}}}$,Calculate,\lim_{x\to{0^+}}\frac{\log_{\sin{x}}{\cos{x}}}{\log_{\sin{\frac{x}{2}}}\cos{\frac{x}{2}}},Calculate   $$\lim_{x\to{0^+}}\frac{\log_{\sin{x}}{\cos{x}}}{\log_{\sin{\frac{x}{2}}}\cos{\frac{x}{2}}}$$ My Attempt: $$\lim_{x\to{0^+}}\frac{\ln{(1-2\sin^2{\frac{x}{2}})}}{\ln{(1-2\sin^2{\frac{x}{4}})}}\cdot\frac{\ln{\sin{\frac{x}{2}}}}{\ln{\sin{x}}}$$ $$\lim_{x\to{0^+}}\frac{\ln{(1-2\sin^2{\frac{x}{2}})}}{\ln{(1-2\sin^2{\frac{x}{4}})}}\cdot\frac{\ln{\sin{\frac{x}{2}}}}{\ln{2\sin{\frac{x}{2}}\cos{\frac{x}{2}}}}$$ $$\lim_{x\to{0^+}}\frac{\ln{(1-2\sin^2{\frac{x}{2}})}}{\ln{(1-2\sin^2{\frac{x}{4}})}}\cdot\frac{\ln{\sin{\frac{x}{2}}}}{\ln{2\sin{\frac{x}{2}}\cos{\frac{x}{2}}}}$$ $$\lim_{x\to{0^+}}\frac{\ln{(1-2\sin^2{\frac{x}{2}})}}{\frac{-2\sin^2{\frac{x}{2}}}{-2\sin^2{\frac{x}{2}}}}\cdot\frac{\frac{-2\sin^2{\frac{x}{4}}}{-2\sin^2{\frac{x}{4}}}}{\ln{(1-2\sin^2{\frac{x}{4}})}}\cdot\frac{\ln{\sin{\frac{x}{2}}}}{\ln{\sin{\frac{x}{2}}}+\ln{2}}$$ $$\frac{1}{4}\cdot 16\cdot 1$$ $$=4$$ Am I solving this correct?,Calculate   $$\lim_{x\to{0^+}}\frac{\log_{\sin{x}}{\cos{x}}}{\log_{\sin{\frac{x}{2}}}\cos{\frac{x}{2}}}$$ My Attempt: $$\lim_{x\to{0^+}}\frac{\ln{(1-2\sin^2{\frac{x}{2}})}}{\ln{(1-2\sin^2{\frac{x}{4}})}}\cdot\frac{\ln{\sin{\frac{x}{2}}}}{\ln{\sin{x}}}$$ $$\lim_{x\to{0^+}}\frac{\ln{(1-2\sin^2{\frac{x}{2}})}}{\ln{(1-2\sin^2{\frac{x}{4}})}}\cdot\frac{\ln{\sin{\frac{x}{2}}}}{\ln{2\sin{\frac{x}{2}}\cos{\frac{x}{2}}}}$$ $$\lim_{x\to{0^+}}\frac{\ln{(1-2\sin^2{\frac{x}{2}})}}{\ln{(1-2\sin^2{\frac{x}{4}})}}\cdot\frac{\ln{\sin{\frac{x}{2}}}}{\ln{2\sin{\frac{x}{2}}\cos{\frac{x}{2}}}}$$ $$\lim_{x\to{0^+}}\frac{\ln{(1-2\sin^2{\frac{x}{2}})}}{\frac{-2\sin^2{\frac{x}{2}}}{-2\sin^2{\frac{x}{2}}}}\cdot\frac{\frac{-2\sin^2{\frac{x}{4}}}{-2\sin^2{\frac{x}{4}}}}{\ln{(1-2\sin^2{\frac{x}{4}})}}\cdot\frac{\ln{\sin{\frac{x}{2}}}}{\ln{\sin{\frac{x}{2}}}+\ln{2}}$$ $$\frac{1}{4}\cdot 16\cdot 1$$ $$=4$$ Am I solving this correct?,,"['limits', 'logarithms', 'limits-without-lhopital']"
2,Intuition behind proving that $f$ is constant,Intuition behind proving that  is constant,f,"Let $f: \mathbb R \to \mathbb R$ is a continuous function such that $\lim_{h \to 0^+} \frac{f(x+2h)-f(x+h)}{h}=0$. Prove that $f$ is constant. This is a question taken from the book Putnam and Beyond, question 389. I looked at the solution, which goes roughly as follows. Suppose on the contrary that there is $a < b$ with different image, say $f(a) > f(b)$. Define $g(x) =f(x)+ \lambda x$ where $\lambda >0$ is sufficiently small to make $g(a) > g(b)$. We have that $\lim_{h \to 0^+} \frac{g(x+2h)-g(x+h)}{h}=\lambda$. Since $g$ is continuous on $[a,b]$ a closed and bounded interval, $g$ attains a maximum, say $c \neq b$. fix $\epsilon >0, \epsilon < \lambda$. Then by continuity there is $\delta$ such that $0 < \lambda - \epsilon < \frac{g(x+2h)-g(x+h)}{h} < \lambda + \epsilon$ for all $0 < h< \delta$. Fix $0< h_0<min\{\delta, (b-c)/2\}$. Then $g(c+2h_0) >g(c+h_0) >...>g(c+\frac{h_0}{2^m})$... for any natural number $m$ so that, by taking the limit as $m$ goes to infinity, $g(c+2h_0) > g(c)$ contradicting the maximality of $g$ on $[a,b]$. Thus it must be that our initial assumption was false, and hence our conclusion. I get the proof, but I was wondering what is the intuition behind this solution. How would a problem solver come up with the idea for this solution? Please be more specific than 'it takes practice to recognize pattern'.","Let $f: \mathbb R \to \mathbb R$ is a continuous function such that $\lim_{h \to 0^+} \frac{f(x+2h)-f(x+h)}{h}=0$. Prove that $f$ is constant. This is a question taken from the book Putnam and Beyond, question 389. I looked at the solution, which goes roughly as follows. Suppose on the contrary that there is $a < b$ with different image, say $f(a) > f(b)$. Define $g(x) =f(x)+ \lambda x$ where $\lambda >0$ is sufficiently small to make $g(a) > g(b)$. We have that $\lim_{h \to 0^+} \frac{g(x+2h)-g(x+h)}{h}=\lambda$. Since $g$ is continuous on $[a,b]$ a closed and bounded interval, $g$ attains a maximum, say $c \neq b$. fix $\epsilon >0, \epsilon < \lambda$. Then by continuity there is $\delta$ such that $0 < \lambda - \epsilon < \frac{g(x+2h)-g(x+h)}{h} < \lambda + \epsilon$ for all $0 < h< \delta$. Fix $0< h_0<min\{\delta, (b-c)/2\}$. Then $g(c+2h_0) >g(c+h_0) >...>g(c+\frac{h_0}{2^m})$... for any natural number $m$ so that, by taking the limit as $m$ goes to infinity, $g(c+2h_0) > g(c)$ contradicting the maximality of $g$ on $[a,b]$. Thus it must be that our initial assumption was false, and hence our conclusion. I get the proof, but I was wondering what is the intuition behind this solution. How would a problem solver come up with the idea for this solution? Please be more specific than 'it takes practice to recognize pattern'.",,"['limits', 'continuity', 'soft-question', 'problem-solving']"
3,"Find $\lim\limits_{(x,y)\to (0,0)}{\frac{e^{x}+y-1}{x+y}}$",Find,"\lim\limits_{(x,y)\to (0,0)}{\frac{e^{x}+y-1}{x+y}}","Find $$\lim_{(x,y)\to (0,0)}{\dfrac{e^{x}+y-1}{x+y}}$$ I tried with different trajectories and I always get that the limit is $1$, but I cannot prove it, any help?","Find $$\lim_{(x,y)\to (0,0)}{\dfrac{e^{x}+y-1}{x+y}}$$ I tried with different trajectories and I always get that the limit is $1$, but I cannot prove it, any help?",,['limits']
4,A problem on limit involving greatest integer function,A problem on limit involving greatest integer function,,"If $$f(n)=\left[\sqrt{n}+\frac{1}{2}\right]$$ where $[\cdot]$ denotes the greatest integer function, then find the value of the limit $$\lim_{n\to\infty}\sum_{k=1}^n\left(\frac{2^{f(k)}+2^{-f(k)}}{2^{n}}\right).$$ My attempt: I tried to evaluate individual values of $f(n)$ for different values of n to get a pattern, e.g. $$f(1) = f(2)= 1,\quad  f(3) = f(4)= f(5) = f(6)= 2,\\ f(7) = f(8) = f(9) = f(10) = f(11) = f(12) = 3,\dots $$  but I feel there should be a generic way of handling this problem. Any help will be appreciated.","If $$f(n)=\left[\sqrt{n}+\frac{1}{2}\right]$$ where $[\cdot]$ denotes the greatest integer function, then find the value of the limit $$\lim_{n\to\infty}\sum_{k=1}^n\left(\frac{2^{f(k)}+2^{-f(k)}}{2^{n}}\right).$$ My attempt: I tried to evaluate individual values of $f(n)$ for different values of n to get a pattern, e.g. $$f(1) = f(2)= 1,\quad  f(3) = f(4)= f(5) = f(6)= 2,\\ f(7) = f(8) = f(9) = f(10) = f(11) = f(12) = 3,\dots $$  but I feel there should be a generic way of handling this problem. Any help will be appreciated.",,"['limits', 'limits-without-lhopital']"
5,Finding $\lim_{x\rightarrow 0}\lfloor \frac{2017 \sin x}{x} \rfloor +\lfloor \frac{2017 \tan x}{x} \rfloor $,Finding,\lim_{x\rightarrow 0}\lfloor \frac{2017 \sin x}{x} \rfloor +\lfloor \frac{2017 \tan x}{x} \rfloor ,"Finding value of $\displaystyle \lim_{x\rightarrow 0}\bigg\lfloor \frac{2017 \sin x}{x}\bigg \rfloor +\bigg\lfloor \frac{2017 \tan x}{x}\bigg \rfloor,$ where $\lfloor x \rfloor $ is floor function of $x$ Attempt as we know $\sin x< x < \tan x$ wan,t  be able to go further, could some help me, thanks","Finding value of $\displaystyle \lim_{x\rightarrow 0}\bigg\lfloor \frac{2017 \sin x}{x}\bigg \rfloor +\bigg\lfloor \frac{2017 \tan x}{x}\bigg \rfloor,$ where $\lfloor x \rfloor $ is floor function of $x$ Attempt as we know $\sin x< x < \tan x$ wan,t  be able to go further, could some help me, thanks",,"['limits', 'trigonometry', 'ceiling-and-floor-functions']"
6,Limit of $\left|\sin(n)\right|^{1/n}$,Limit of,\left|\sin(n)\right|^{1/n},"I'm having trouble showing rigorously what is the limit of $x_n=|\sin(n)|^{1/n}$ in a rigorous manner. What I have shown is that, $x_n$ cannot converge to $0$ and is bounded by $1$, and that should suffice to show that $x_n$ effectively converges to $1$. However, I can't figure out how to formalize this proof, and show it in a rigorous manner. My guess would be to try and show that the limit of $|a_n|^{1/n}$ can be $1$ if $|a_n|$ is bounded by $1$ and does not converge to $0$. I don't know if this more general statement holds, and if it would simplify or complexify the problem.","I'm having trouble showing rigorously what is the limit of $x_n=|\sin(n)|^{1/n}$ in a rigorous manner. What I have shown is that, $x_n$ cannot converge to $0$ and is bounded by $1$, and that should suffice to show that $x_n$ effectively converges to $1$. However, I can't figure out how to formalize this proof, and show it in a rigorous manner. My guess would be to try and show that the limit of $|a_n|^{1/n}$ can be $1$ if $|a_n|$ is bounded by $1$ and does not converge to $0$. I don't know if this more general statement holds, and if it would simplify or complexify the problem.",,['limits']
7,How to compute the mean average exponent of the naturals? What is the limit for large numbers?,How to compute the mean average exponent of the naturals? What is the limit for large numbers?,,"With a friend I was trying to get an understanding for why the expected gap between primes is logarithmic. With that motivation I tried to express the average exponent of numbers. By average exponent of a number I mean the following rational: If $p,q,r$ are some primes and a number $n$ has factorization $n=p^aq^br^c$, then in this case the average exponent would be $(a+b+c)/3$. For example the number $3087$ equals $3^2\,7^3$, a number where all exponents are bigger than one, and the average exponent is $(2+3)/2=2.5$. Similarly, the average exponent of $156=2^2\,3^113^1$ is $(2+1+1)/3=1.\dot 3$. We computed the average exponent for the first $10000$ numbers and, not too surprisingly, the value jumps quite a bit and the function isn't nice to look at. So next we plot a function of $n$ with value being the mean from the numbers $2$ up to $n$  (of the average exponents). The plot is below, it seems to stabilize to $\approx 4/3$ in this interval. How to interpret this? What is the behavior and more concretely the limit of the above construction? How to compute it?","With a friend I was trying to get an understanding for why the expected gap between primes is logarithmic. With that motivation I tried to express the average exponent of numbers. By average exponent of a number I mean the following rational: If $p,q,r$ are some primes and a number $n$ has factorization $n=p^aq^br^c$, then in this case the average exponent would be $(a+b+c)/3$. For example the number $3087$ equals $3^2\,7^3$, a number where all exponents are bigger than one, and the average exponent is $(2+3)/2=2.5$. Similarly, the average exponent of $156=2^2\,3^113^1$ is $(2+1+1)/3=1.\dot 3$. We computed the average exponent for the first $10000$ numbers and, not too surprisingly, the value jumps quite a bit and the function isn't nice to look at. So next we plot a function of $n$ with value being the mean from the numbers $2$ up to $n$  (of the average exponents). The plot is below, it seems to stabilize to $\approx 4/3$ in this interval. How to interpret this? What is the behavior and more concretely the limit of the above construction? How to compute it?",,"['elementary-number-theory', 'limits', 'prime-numbers', 'logarithms', 'average']"
8,Uniqueness of Weak Limit,Uniqueness of Weak Limit,,As we know that weak limit of a sequence of Borel probability measures on metric space is unique. Do we have this property for general sequence of signed Borel measures on metric space? Thank you.,As we know that weak limit of a sequence of Borel probability measures on metric space is unique. Do we have this property for general sequence of signed Borel measures on metric space? Thank you.,,"['analysis', 'measure-theory', 'limits', 'convergence-divergence']"
9,Are the Join and Meet operators on complete lattices both continuous?,Are the Join and Meet operators on complete lattices both continuous?,,"Suppose that $(A,\le)$ is a complete lattice, that means $(A,\wedge,\vee)$ is a lattice which satisfies $$\forall B \subseteq A[\bigwedge B\text{ and }\bigvee B\text{ exist}].$$ And of course $(\wp(A),\subseteq)$, in which $\wp(A)$ is the powerset of $A$, is a complete lattice too (let $\bigcap \emptyset=A$). Furthermore, Let $(D,\sqsubseteq)$ be a directed set, and $P \colon D \to \wp(A)$ s.t. $\forall \alpha,\beta \in D[\alpha \le \beta \Rightarrow P_{\alpha} \supseteq P_{\beta}]$.  Then if $\bigcap_{\alpha \in D}P_{\alpha} \ne \emptyset$, do $\bigvee \bigcap_{\alpha \in D}P_{\alpha}=\bigwedge_{\alpha \in D}\bigvee P_{\alpha}$? $\bigwedge \bigcap_{\alpha \in D}P_{\alpha}=\bigvee_{\alpha \in D}\bigwedge P_{\alpha}$? That is, in discrete topology, are the limit superior and limit inferior of a directed net exactly the supremum and infimum of this net's limit set respectively?","Suppose that $(A,\le)$ is a complete lattice, that means $(A,\wedge,\vee)$ is a lattice which satisfies $$\forall B \subseteq A[\bigwedge B\text{ and }\bigvee B\text{ exist}].$$ And of course $(\wp(A),\subseteq)$, in which $\wp(A)$ is the powerset of $A$, is a complete lattice too (let $\bigcap \emptyset=A$). Furthermore, Let $(D,\sqsubseteq)$ be a directed set, and $P \colon D \to \wp(A)$ s.t. $\forall \alpha,\beta \in D[\alpha \le \beta \Rightarrow P_{\alpha} \supseteq P_{\beta}]$.  Then if $\bigcap_{\alpha \in D}P_{\alpha} \ne \emptyset$, do $\bigvee \bigcap_{\alpha \in D}P_{\alpha}=\bigwedge_{\alpha \in D}\bigvee P_{\alpha}$? $\bigwedge \bigcap_{\alpha \in D}P_{\alpha}=\bigvee_{\alpha \in D}\bigwedge P_{\alpha}$? That is, in discrete topology, are the limit superior and limit inferior of a directed net exactly the supremum and infimum of this net's limit set respectively?",,"['limits', 'order-theory', 'lattice-orders']"
10,Why are there more prime factors of the form $4k-1$ than of the form $4k+1$?,Why are there more prime factors of the form  than of the form ?,4k-1 4k+1,"The density of primes of the form $4k-1$ and $4k+1$ is equal although slight discrepancy exists in the exact numbers also known as Chebyshev bias. All odd prime factors of a number will be either of the form $4k-1$ or $4k+1$ . If we take all natural numbers $n \le x$ and look at the prime factors of each of these numbers, the density of prime factors of $4k-1$ significantly higher than that of the form $4k+1$ , i.e. the bias is much stronger than Chebyshev bias. Experimental data shows that the difference between their densities is a constant. Let $a(n)$ = no. of distinct primes factors of $n$ which are of the form $4k-1$ and $b(n)$ = no. of distinct primes factors  of $n$ which are of the form $4k+1$ . Data at every checkpoint from $x = 10^6$ to $x = 10^9$ shows a consistent trend that $$ \frac{1}{x}\sum_{n \le x} [a(n) - b(n)] \approx 0.83498 $$ At a more granular level, we consider only odd numbers then the above constant is $\approx 0.33498$ and if we consider only even numbers then it is $\approx 1.33498$ . Question : What is the source of this bias and is there a closed form of $$ \lim_{x \to \infty}\frac{1}{x} \sum_{n \le x} [a(n) - b(n)] $$","The density of primes of the form and is equal although slight discrepancy exists in the exact numbers also known as Chebyshev bias. All odd prime factors of a number will be either of the form or . If we take all natural numbers and look at the prime factors of each of these numbers, the density of prime factors of significantly higher than that of the form , i.e. the bias is much stronger than Chebyshev bias. Experimental data shows that the difference between their densities is a constant. Let = no. of distinct primes factors of which are of the form and = no. of distinct primes factors  of which are of the form . Data at every checkpoint from to shows a consistent trend that At a more granular level, we consider only odd numbers then the above constant is and if we consider only even numbers then it is . Question : What is the source of this bias and is there a closed form of","4k-1 4k+1 4k-1 4k+1 n \le x 4k-1 4k+1 a(n) n 4k-1 b(n) n 4k+1 x = 10^6 x = 10^9 
\frac{1}{x}\sum_{n \le x} [a(n) - b(n)] \approx 0.83498
 \approx 0.33498 \approx 1.33498 
\lim_{x \to \infty}\frac{1}{x} \sum_{n \le x} [a(n) - b(n)]
","['limits', 'number-theory', 'elementary-number-theory', 'prime-numbers', 'analytic-number-theory']"
11,What does it mean that a functor preserves infinite limits?,What does it mean that a functor preserves infinite limits?,,What does it mean that a functor preservers infinite limits? Can you please give an example of a functor which preserves finite limits but not infinite ones?,What does it mean that a functor preservers infinite limits? Can you please give an example of a functor which preserves finite limits but not infinite ones?,,"['limits', 'category-theory', 'limits-colimits', 'functors']"
12,"If $V_n(a)$ counts sign changes in the sequence $\cos a, \cos2a,\cos3a,\ldots,\cos na,$ show that $\lim_{n\to\infty}\frac{V_n(a)}n=\frac{a}\pi$",If  counts sign changes in the sequence  show that,"V_n(a) \cos a, \cos2a,\cos3a,\ldots,\cos na, \lim_{n\to\infty}\frac{V_n(a)}n=\frac{a}\pi","Let $0\leq\alpha\leq \pi $ . $V_n (\alpha) $ denote the number of sign changes in the sequence $\cos\alpha,\cos2\alpha,\cos3\alpha,\ldots,\cos n\alpha $ . Then prove that $$\lim\limits_{n\to\infty}\dfrac{V_n (\alpha)}{n}=\dfrac{\alpha}{\pi}.$$ I saw a hint where $\dfrac{V_n (\alpha)}{n}$ is considered as the probability. I mean how this expression is a probability of something. If it is, how can I progress further in this way? Update: I have a solution to this problem In $n\alpha$ rotation the number of times full circle rotation occures $=\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor$ In one full circle rotation sign change occures 2 times. Hence in $\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor$ full rotation sign change occures $=2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor$ Now the rest angle is $n\alpha-\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor\times2\pi$ If we consider 0 as a change of sign in case of $\cos\left( \dfrac{\pi}{2}\right)$ and $\cos\left(\dfrac{3\pi}{2}\right)$ then:- (1) If $0\leq n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi<\dfrac{\pi}{2 }$ sign changes 0 times (2) If $\dfrac{\pi}{2 }\leq n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi<\dfrac{3\pi}{2 }$ sign changes 1 times (3) If $\dfrac{3\pi}{2 }\leq n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi<2\pi$ sign changes 2 times Let $f$ be a function such that $$f\left(\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor\right)=\begin{cases}0,\text{ when }\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor=0\\ 1,\text{ when }\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor=1\\ 1,\text{ when }\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor=2\\ 2,\text{ when } \left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor=3\end{cases}$$ Therefore $\dfrac{V_n(\alpha)}{n}=\dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor+ f\left(\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor\right)}{n}$ Hence $$\dfrac{V_n(\alpha)}{n}\geq \dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor}{n}$$ and $$\dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor+ 2}{n}\leq \dfrac{V_n(\alpha)}{n}$$ $\lim\limits_{n\to \infty}\dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor}{n}=\dfrac{\alpha}{\pi}$ and $\lim\limits_{n\to\infty} \dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor+ 2}{n}=\dfrac{\alpha}{\pi}$ Hence by Sandwich Theorem We get $\lim\limits_{n\to \infty}\dfrac{V_n(\alpha)}{n}=\dfrac{\alpha}{\pi}$ [Proved] Is this correct?","Let . denote the number of sign changes in the sequence . Then prove that I saw a hint where is considered as the probability. I mean how this expression is a probability of something. If it is, how can I progress further in this way? Update: I have a solution to this problem In rotation the number of times full circle rotation occures In one full circle rotation sign change occures 2 times. Hence in full rotation sign change occures Now the rest angle is If we consider 0 as a change of sign in case of and then:- (1) If sign changes 0 times (2) If sign changes 1 times (3) If sign changes 2 times Let be a function such that Therefore Hence and and Hence by Sandwich Theorem We get [Proved] Is this correct?","0\leq\alpha\leq \pi  V_n (\alpha)  \cos\alpha,\cos2\alpha,\cos3\alpha,\ldots,\cos n\alpha  \lim\limits_{n\to\infty}\dfrac{V_n (\alpha)}{n}=\dfrac{\alpha}{\pi}. \dfrac{V_n (\alpha)}{n} n\alpha =\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor \bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor =2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor n\alpha-\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor\times2\pi \cos\left( \dfrac{\pi}{2}\right) \cos\left(\dfrac{3\pi}{2}\right) 0\leq n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi<\dfrac{\pi}{2 } \dfrac{\pi}{2 }\leq n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi<\dfrac{3\pi}{2 } \dfrac{3\pi}{2 }\leq n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi<2\pi f f\left(\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor\right)=\begin{cases}0,\text{ when }\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor=0\\ 1,\text{ when }\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor=1\\ 1,\text{ when }\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor=2\\ 2,\text{ when } \left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor=3\end{cases} \dfrac{V_n(\alpha)}{n}=\dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor+ f\left(\left\lfloor \dfrac{n\alpha-\bigg\lfloor\dfrac{n\alpha }{2\pi }\bigg\rfloor\times 2\pi}{\dfrac{\pi}{2}}\right\rfloor\right)}{n} \dfrac{V_n(\alpha)}{n}\geq \dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor}{n} \dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor+ 2}{n}\leq \dfrac{V_n(\alpha)}{n} \lim\limits_{n\to \infty}\dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor}{n}=\dfrac{\alpha}{\pi} \lim\limits_{n\to\infty} \dfrac{2\bigg\lfloor\dfrac{n\alpha}{2\pi}\bigg\rfloor+ 2}{n}=\dfrac{\alpha}{\pi} \lim\limits_{n\to \infty}\dfrac{V_n(\alpha)}{n}=\dfrac{\alpha}{\pi}","['limits', 'trigonometry']"
13,Can nested limits be flattened into a single limit?,Can nested limits be flattened into a single limit?,,"Is it true that $$\lim_{x \to c}{\Bigl(\lim_{y \to x}{g(y)}\Bigr)}=L \implies \lim_{y \to c}{g(y)}=L$$ (assuming $\lim_{y \to x}{g(y)}$ exists for all $x$) The question crossed my mind when doing a problem to do with derivatives. Specifically, the problem of whether $$\lim_{x \to c}{f^\prime(x)} = L \implies f^\prime(c) = L$$ since expanding $f^\prime$ using the definition of a derivative yields something a lot like the expression this question asks about: $$\lim_{x \to c}{\Bigl(\lim_{y \to x}{\frac{f(y)-f(x)}{y-x}}\Bigr)}=L \implies \lim_{y \to c}{\frac{f(y)-f(c)}{y-c}}=L$$ (assuming that inner limit always exists, i.e. assuming that $f$ is differentiable for all $x$)","Is it true that $$\lim_{x \to c}{\Bigl(\lim_{y \to x}{g(y)}\Bigr)}=L \implies \lim_{y \to c}{g(y)}=L$$ (assuming $\lim_{y \to x}{g(y)}$ exists for all $x$) The question crossed my mind when doing a problem to do with derivatives. Specifically, the problem of whether $$\lim_{x \to c}{f^\prime(x)} = L \implies f^\prime(c) = L$$ since expanding $f^\prime$ using the definition of a derivative yields something a lot like the expression this question asks about: $$\lim_{x \to c}{\Bigl(\lim_{y \to x}{\frac{f(y)-f(x)}{y-x}}\Bigr)}=L \implies \lim_{y \to c}{\frac{f(y)-f(c)}{y-c}}=L$$ (assuming that inner limit always exists, i.e. assuming that $f$ is differentiable for all $x$)",,"['limits', 'derivatives']"
14,Why is $y_{n+1}=\frac{1}{2}(y_n+\sqrt{\frac{1}{2^{2n}}+y_n^2})$ giving the inverse of $\pi$?,Why is  giving the inverse of ?,y_{n+1}=\frac{1}{2}(y_n+\sqrt{\frac{1}{2^{2n}}+y_n^2}) \pi,"A simple and interesting recursion: $$y_{n+1}=\frac{1}{2}(y_n+\sqrt{\frac{1}{2^{2n}}+y_n^2})$$ has these curious solutions $$y_1=-\infty,y_{\infty}=\frac{1}{2\pi}$$ $$y_1=-\frac{1}{2},y_{\infty}=\frac{2}{3\pi}$$ $$y_1=0,y_{\infty}=\frac{1}{\pi} $$ $$y_1=\frac{1}{2},y_{\infty}=\frac{2}{\pi}$$ Cannot find it in the literature as such and it does not look like coming from AGM, but I suspect elliptic integrals. Still cannot start from anywhere for some time. Any ideas?","A simple and interesting recursion: $$y_{n+1}=\frac{1}{2}(y_n+\sqrt{\frac{1}{2^{2n}}+y_n^2})$$ has these curious solutions $$y_1=-\infty,y_{\infty}=\frac{1}{2\pi}$$ $$y_1=-\frac{1}{2},y_{\infty}=\frac{2}{3\pi}$$ $$y_1=0,y_{\infty}=\frac{1}{\pi} $$ $$y_1=\frac{1}{2},y_{\infty}=\frac{2}{\pi}$$ Cannot find it in the literature as such and it does not look like coming from AGM, but I suspect elliptic integrals. Still cannot start from anywhere for some time. Any ideas?",,['limits']
15,Evaluate the limit containing $\arctan{x}$ and $\arcsin{x}$,Evaluate the limit containing  and,\arctan{x} \arcsin{x},"Evaluate: $$\lim_{x\to{0}}\bigg(\frac{2}{x^3}.(\arcsin{x}-\arctan{x})\bigg)^{2/x^2}$$ I can just expand $\arcsin{x}$ and $\arctan{x}$ using their taylor expansions, but is there any other method?","Evaluate: $$\lim_{x\to{0}}\bigg(\frac{2}{x^3}.(\arcsin{x}-\arctan{x})\bigg)^{2/x^2}$$ I can just expand $\arcsin{x}$ and $\arctan{x}$ using their taylor expansions, but is there any other method?",,"['limits', 'limits-without-lhopital']"
16,Asymptotic behavior of digit sum of $2^{n}$,Asymptotic behavior of digit sum of,2^{n},Terence Tao in his brilliant book Solving Mathematical Problems: a Personal Perspective states (page 17): It is highly probable (though not proven!) that the digit-sum of $2^{n}$ is approximately $(4.5 \log_{10} 2)n≈1.355n$ for large $n$. This problem sounds very interesting to me! Do you know something more about this problem? What is its exact formulation (replacing word approximately with a limit)? Is it still not proven? I found only this which does not satisfy me enough. Thank you very much for your answers and have a nice week!,Terence Tao in his brilliant book Solving Mathematical Problems: a Personal Perspective states (page 17): It is highly probable (though not proven!) that the digit-sum of $2^{n}$ is approximately $(4.5 \log_{10} 2)n≈1.355n$ for large $n$. This problem sounds very interesting to me! Do you know something more about this problem? What is its exact formulation (replacing word approximately with a limit)? Is it still not proven? I found only this which does not satisfy me enough. Thank you very much for your answers and have a nice week!,,"['number-theory', 'elementary-number-theory', 'limits', 'decimal-expansion']"
17,Multivariable function limit,Multivariable function limit,,"How to approach this: $\lim\limits_{(x,y)\to(0,0)}\frac{x^2y}{x^2+y}$? Been able to grind $\lim\limits_{(x,y)\to(0,0)}\frac{x^2y}{x^2+y^2}$, it is in(link) finnish, but formulas and idea should be selfevident. However $\dot +y$ instead of $\dots+y^2$ in divisor confuses me. Or am I thinking in completely wrong direction?","How to approach this: $\lim\limits_{(x,y)\to(0,0)}\frac{x^2y}{x^2+y}$? Been able to grind $\lim\limits_{(x,y)\to(0,0)}\frac{x^2y}{x^2+y^2}$, it is in(link) finnish, but formulas and idea should be selfevident. However $\dot +y$ instead of $\dots+y^2$ in divisor confuses me. Or am I thinking in completely wrong direction?",,"['limits', 'multivariable-calculus']"
18,Path lengths on a unit square,Path lengths on a unit square,,"Suppose I'm at $(x=0,y=0)$ and I want to get to $(x=1,y=1)$. The shortest path is the diagonal and it has length $\sqrt{2}$. But what if I'm only allowed to make moves in coordinate directions---e.g., $1/2$ along $x$, $1/2$ along $y$, another $1/2$ along $x$, and a final $1/2$ along $y$. Then the length of my path is $2$. In fact, any coordinate-constrained path has length $2$. Let the path $p_n$ be $1/n$ along $x$, followed by $1/n$ along $y$, followed by $1/n$ along $x$, etc., until I get to $(1,1)$. Presumably, the limit of $p_n$ as $n\rightarrow\infty$ is the diagonal line. But the path length of each $p_n$ is $2$, while the path length of the limit is $\sqrt{2}$. Weird, right? Is this just an example that shows that you can't exchange limit and path length?","Suppose I'm at $(x=0,y=0)$ and I want to get to $(x=1,y=1)$. The shortest path is the diagonal and it has length $\sqrt{2}$. But what if I'm only allowed to make moves in coordinate directions---e.g., $1/2$ along $x$, $1/2$ along $y$, another $1/2$ along $x$, and a final $1/2$ along $y$. Then the length of my path is $2$. In fact, any coordinate-constrained path has length $2$. Let the path $p_n$ be $1/n$ along $x$, followed by $1/n$ along $y$, followed by $1/n$ along $x$, etc., until I get to $(1,1)$. Presumably, the limit of $p_n$ as $n\rightarrow\infty$ is the diagonal line. But the path length of each $p_n$ is $2$, while the path length of the limit is $\sqrt{2}$. Weird, right? Is this just an example that shows that you can't exchange limit and path length?",,['limits']
19,Does L'hopital work for one sided limits?,Does L'hopital work for one sided limits?,,"Simple question, to which I don't know the answer. Does it work the same even if we are only interested in one-sided limits, and it won't cause problems that the actual limit doesn't exist?","Simple question, to which I don't know the answer. Does it work the same even if we are only interested in one-sided limits, and it won't cause problems that the actual limit doesn't exist?",,['limits']
20,How prove this limits $\lim_{n\to\infty}\frac{v_{5}(1^1\cdot 2^2\cdot 3^3\cdot 4^4\cdots\cdot n^n)}{n^2}=\frac{1}{8}$,How prove this limits,\lim_{n\to\infty}\frac{v_{5}(1^1\cdot 2^2\cdot 3^3\cdot 4^4\cdots\cdot n^n)}{n^2}=\frac{1}{8},"Interesting Question: Let denote by $v_{p}(a)$ the exponent of the prime number $p$ in the prime factorization of $a$, show that   $$\lim_{n\to\infty}\dfrac{v_{5}(1^1\cdot 2^2\cdot 3^3\cdot 4^4\cdots\cdot n^n)}{n^2}=\dfrac{1}{8}$$ My some idea: since $$1^1\cdot 2^2\cdot 3^3\cdot 4^4\cdots\cdot n^n=\dfrac{(n!)^n}{1!\cdot 2!\cdot 3!\cdots (n-1)!}$$ and it is well know $$v_{5}(n!)=\lfloor \dfrac{n}{5}\rfloor+\lfloor\dfrac{n}{5^2}\rfloor+\lfloor\dfrac{n}{5^3}\rfloor+\cdots+\lfloor\dfrac{n}{5^k}\rfloor+\cdots=\sum_{i=1}^{\infty}\lfloor\dfrac{n}{5^k}\rfloor$$ so $$v_{5}(1^1\cdot 2^2\cdot 3^3\cdot 4^4\cdots\cdot n^n)=n\sum_{i=1}^{\infty}\lfloor\dfrac{n}{5^k}\rfloor-\sum_{i=1}^{n-1}\sum_{k=1}^{\infty}\left(\lfloor\dfrac{i}{5^k}\rfloor\right)$$ then I can't it. Thank you","Interesting Question: Let denote by $v_{p}(a)$ the exponent of the prime number $p$ in the prime factorization of $a$, show that   $$\lim_{n\to\infty}\dfrac{v_{5}(1^1\cdot 2^2\cdot 3^3\cdot 4^4\cdots\cdot n^n)}{n^2}=\dfrac{1}{8}$$ My some idea: since $$1^1\cdot 2^2\cdot 3^3\cdot 4^4\cdots\cdot n^n=\dfrac{(n!)^n}{1!\cdot 2!\cdot 3!\cdots (n-1)!}$$ and it is well know $$v_{5}(n!)=\lfloor \dfrac{n}{5}\rfloor+\lfloor\dfrac{n}{5^2}\rfloor+\lfloor\dfrac{n}{5^3}\rfloor+\cdots+\lfloor\dfrac{n}{5^k}\rfloor+\cdots=\sum_{i=1}^{\infty}\lfloor\dfrac{n}{5^k}\rfloor$$ so $$v_{5}(1^1\cdot 2^2\cdot 3^3\cdot 4^4\cdots\cdot n^n)=n\sum_{i=1}^{\infty}\lfloor\dfrac{n}{5^k}\rfloor-\sum_{i=1}^{n-1}\sum_{k=1}^{\infty}\left(\lfloor\dfrac{i}{5^k}\rfloor\right)$$ then I can't it. Thank you",,"['number-theory', 'limits']"
21,Limit $\lim\limits_{n \to \infty} n \cdot\ln(\sqrt{n^2+2n+5}-n)$,Limit,\lim\limits_{n \to \infty} n \cdot\ln(\sqrt{n^2+2n+5}-n),"How should this limit be solved ? $$\lim_{n \to \infty} n \cdot \ln(\sqrt{n^2+2n+5}-n)$$ I've tried to multiply and at the same time divide $\sqrt{n^2+2n+5}-n$ by $\sqrt{n^2+2n+5}+n$, and then make $n$ as the power of $\frac {2n+5}{\sqrt{n^2+2n+5}+n}$. But I got stuck.  I dont think it was the best idea.","How should this limit be solved ? $$\lim_{n \to \infty} n \cdot \ln(\sqrt{n^2+2n+5}-n)$$ I've tried to multiply and at the same time divide $\sqrt{n^2+2n+5}-n$ by $\sqrt{n^2+2n+5}+n$, and then make $n$ as the power of $\frac {2n+5}{\sqrt{n^2+2n+5}+n}$. But I got stuck.  I dont think it was the best idea.",,"['limits', 'radicals']"
22,"Finding $ \lim_{(x,y) \to (0,0)} \frac{\sin^2(xy)}{3x^2+2y^2} $",Finding," \lim_{(x,y) \to (0,0)} \frac{\sin^2(xy)}{3x^2+2y^2} ","$$ \lim_{(x,y) \to (0,0)} \frac{\sin^2(xy)}{3x^2+2y^2} $$ If I pick $ x = 0$ I get: $$ \lim_{(x,y) \to (0,0)} \frac{0}{2y^2} = 0$$ So if the limit exists it must be $0$ Now for ${(x,y) \to (0,0)}$ I have $xy \to 0$ So I can use the Taylor series of $sin(t) = t + o(t)$ where $t \to 0$ $$0 \leq \frac{\sin^2(xy)}{3x^2+2y^2} = \frac{x^2y^2 + 2o(x^2y^2) + o (x^2y^2)}{3x^2 + 2y^2} =$$ $$\frac{x^2y^2 + o (x^2y^2)}{3x^2 + 2y^2} = $$ Now I can use the polar coordinates: $$\frac{\rho^4 \cos^2(\theta)\sin^2(\theta) + o (\rho^4 \cos^2(\theta)\sin^2(\theta))}{3\rho^2 \cos^2(\theta) + 2\rho^2 \sin^2(\theta)}=$$ $$\frac{\rho^2 \cos^2(\theta)\sin^2(\theta)(1 + o (1))}{3 \cos^2(\theta) + 2 \sin^2(\theta)}=$$ $$\frac{\rho^2 \cos^2(\theta)\sin^2(\theta)(1 + o (1))}{3 - 3 \sin^2(\theta) + 2 \sin^2(\theta)}=$$ $$\frac{\rho^2 \cos^2(\theta)\sin^2(\theta)(1 + o (1))}{3 - \sin^2(\theta)}\leq$$ $\frac{\rho^2}{2} \to 0$ for $\rho \to 0$ I would like to know if it is solved in the right way","$$ \lim_{(x,y) \to (0,0)} \frac{\sin^2(xy)}{3x^2+2y^2} $$ If I pick $ x = 0$ I get: $$ \lim_{(x,y) \to (0,0)} \frac{0}{2y^2} = 0$$ So if the limit exists it must be $0$ Now for ${(x,y) \to (0,0)}$ I have $xy \to 0$ So I can use the Taylor series of $sin(t) = t + o(t)$ where $t \to 0$ $$0 \leq \frac{\sin^2(xy)}{3x^2+2y^2} = \frac{x^2y^2 + 2o(x^2y^2) + o (x^2y^2)}{3x^2 + 2y^2} =$$ $$\frac{x^2y^2 + o (x^2y^2)}{3x^2 + 2y^2} = $$ Now I can use the polar coordinates: $$\frac{\rho^4 \cos^2(\theta)\sin^2(\theta) + o (\rho^4 \cos^2(\theta)\sin^2(\theta))}{3\rho^2 \cos^2(\theta) + 2\rho^2 \sin^2(\theta)}=$$ $$\frac{\rho^2 \cos^2(\theta)\sin^2(\theta)(1 + o (1))}{3 \cos^2(\theta) + 2 \sin^2(\theta)}=$$ $$\frac{\rho^2 \cos^2(\theta)\sin^2(\theta)(1 + o (1))}{3 - 3 \sin^2(\theta) + 2 \sin^2(\theta)}=$$ $$\frac{\rho^2 \cos^2(\theta)\sin^2(\theta)(1 + o (1))}{3 - \sin^2(\theta)}\leq$$ $\frac{\rho^2}{2} \to 0$ for $\rho \to 0$ I would like to know if it is solved in the right way",,"['limits', 'multivariable-calculus']"
23,How to prove $\sum_{k=1}^n \frac{2^k}{k}< 3\frac{2^n}{n}$?,How to prove ?,\sum_{k=1}^n \frac{2^k}{k}< 3\frac{2^n}{n},"How to prove $$\sum_{k=1}^n \frac{2^k}{k}< 3\frac{2^n}{n}$$ and further $$\lim_{n\rightarrow \infty}\frac{n}{2^n}\sum_{k=1}^n  \frac{2^{k}}{k} = 2$$? These results are verified by computer, yet I can't figure out a neat proof.","How to prove $$\sum_{k=1}^n \frac{2^k}{k}< 3\frac{2^n}{n}$$ and further $$\lim_{n\rightarrow \infty}\frac{n}{2^n}\sum_{k=1}^n  \frac{2^{k}}{k} = 2$$? These results are verified by computer, yet I can't figure out a neat proof.",,"['analysis', 'limits', 'inequality']"
24,what is the limit of $l_p$ at p=0?,what is the limit of  at p=0?,l_p,"The p-norm is defined as: $$ \ \|x\|_p=\left(|x_1|^p+|x_2|^p+\dotsb+|x_n|^p\right)^{\frac{1}{p}} $$ When $p<1$, this is no longer a ""norm"" because it violates the triangle inequality (- it is super additive and not subadditive). However, it is still valid to ask, what is its limit when p goes to 0? My guess is that: If all coordinates are 0, then $l_p=0$, and it remains like this when p=0. If exactly one coordinate, say $x_i$, is non-zero, then $l_p=x_i$, and it remains like this when p=0. If more than one coordinate (say, $x_i$ and $x_j$) are non-zero, then $l_p>x_i$, and because the exponent goes to $\infty$, the value of $l_p$ also goes to $\infty$. Is this correct? (Note that this is not equal to the $l_0$ ""norm"" = the number of nonzero elements. This is also not equal to the scaled norm , in which there is an additional $1/n$ factor).","The p-norm is defined as: $$ \ \|x\|_p=\left(|x_1|^p+|x_2|^p+\dotsb+|x_n|^p\right)^{\frac{1}{p}} $$ When $p<1$, this is no longer a ""norm"" because it violates the triangle inequality (- it is super additive and not subadditive). However, it is still valid to ask, what is its limit when p goes to 0? My guess is that: If all coordinates are 0, then $l_p=0$, and it remains like this when p=0. If exactly one coordinate, say $x_i$, is non-zero, then $l_p=x_i$, and it remains like this when p=0. If more than one coordinate (say, $x_i$ and $x_j$) are non-zero, then $l_p>x_i$, and because the exponent goes to $\infty$, the value of $l_p$ also goes to $\infty$. Is this correct? (Note that this is not equal to the $l_0$ ""norm"" = the number of nonzero elements. This is also not equal to the scaled norm , in which there is an additional $1/n$ factor).",,"['limits', 'metric-spaces', 'normed-spaces']"
25,How find this$\lim_{n\to\infty}n^2\left(n\sin{(2e\pi\cdot n!)}-2\pi\right)=\frac{2\pi(2\pi^2-3)}{3}$,How find this,\lim_{n\to\infty}n^2\left(n\sin{(2e\pi\cdot n!)}-2\pi\right)=\frac{2\pi(2\pi^2-3)}{3},show  that $$\lim_{n\to\infty}n^2\left(n\sin{(2e\pi\cdot n!)}-2\pi\right)=\dfrac{2\pi(2\pi^2-3)}{3}$$ we are kown that $$\lim_{n\to\infty}n\sin{(2\pi e\cdot n!)}=2\pi$$ because we note $$e=1+\dfrac{1}{1!}+\dfrac{1}{2!}+\cdots+\dfrac{1}{n!}+\dfrac{1}{(n+1)!}+O(\dfrac{1}{(n+1)!})$$ then $$2e\pi\cdot n! =2k\pi+\dfrac{2\pi}{n+1}+o(\dfrac{1}{n+1}))$$ for this problem we  $$e=1+\dfrac{1}{1!}+\dfrac{1}{2!}+\cdots+\dfrac{1}{n!}+\dfrac{1}{(n+1)!}+\dfrac{1}{(n+2)!}+o(\dfrac{1}{(n+2)!})$$ so $$2\pi en!=2k\pi+\dfrac{2\pi}{n+1}+\dfrac{2\pi}{(n+1)(n+2)}+o(\dfrac{1}{(n+1)(n+2)})$$ and use $$\sin{x}=x-\dfrac{x^3}{6}+o(x^3)$$ But I can't work,show  that $$\lim_{n\to\infty}n^2\left(n\sin{(2e\pi\cdot n!)}-2\pi\right)=\dfrac{2\pi(2\pi^2-3)}{3}$$ we are kown that $$\lim_{n\to\infty}n\sin{(2\pi e\cdot n!)}=2\pi$$ because we note $$e=1+\dfrac{1}{1!}+\dfrac{1}{2!}+\cdots+\dfrac{1}{n!}+\dfrac{1}{(n+1)!}+O(\dfrac{1}{(n+1)!})$$ then $$2e\pi\cdot n! =2k\pi+\dfrac{2\pi}{n+1}+o(\dfrac{1}{n+1}))$$ for this problem we  $$e=1+\dfrac{1}{1!}+\dfrac{1}{2!}+\cdots+\dfrac{1}{n!}+\dfrac{1}{(n+1)!}+\dfrac{1}{(n+2)!}+o(\dfrac{1}{(n+2)!})$$ so $$2\pi en!=2k\pi+\dfrac{2\pi}{n+1}+\dfrac{2\pi}{(n+1)(n+2)}+o(\dfrac{1}{(n+1)(n+2)})$$ and use $$\sin{x}=x-\dfrac{x^3}{6}+o(x^3)$$ But I can't work,,['limits']
26,The limit of a recurrence relation (with resistors),The limit of a recurrence relation (with resistors),,"Background to problem (not too important): My proposed solution: The infinitely long element, , however complex, can be represented as a single resistor of resistance $R$.  Remembering the initial resistor near $A$, we know $R_{AB}= r+R$. However, as this is an infinitely long element, it is equivalent to a resistor of resistance $R$ attached  to the right of two resistors of resistance $r$ (the resistance $R$ is an intrinsic property of the element, so is unaffected by the fact that the further to the right it is, the lower the current passing through it). Thus, taking $R$ in series with $r$, then the result in parallel with $r$, then in series with $r$: $$R_{AB}=  r + \left (\frac{1}{\frac{1}{R+r}+\frac{1}{r}}  \right )$$ On the second iteration (moving $R$ further to the right): $$R_{AB}= r+ \frac{1}{\frac{1}{r}+\frac{1}{r + \left (\frac{1}{\frac{1}{R+r}+\frac{1}{r}}  \right )}}$$ Ad infinitum. I understand this may not be the fastest solution, but I'd like to know a little more about it nonetheless. The mathematics $$u_{1}=r+R$$ $$\large u_{n+1}=r+\frac{1}{\frac{1}{r}+\frac{1}{u_n}}$$ Does $\lim_{n \rightarrow \infty} (u_n)$ exist (important: is the limit a function of $R$?), and, if so, what is it? First cases $$u_{2}=\frac{3r^2+2rR}{R+2r}$$ $$u_{3}=\frac{8r^2+5rR}{3R+5r}$$ $$u_{4}=\frac{21r^2+13rR}{8R+13r}$$ $$u_{4}=\frac{55r^2+34rR}{21R+34r}$$ $$\lim _{n \rightarrow \infty} (u_n)\stackrel{?}{=}\varphi r$$ Seems the doing of Fibonnaci. How does one take the limit of this (I assume it requires knowledge of knowledge of the form of $f(n)=F_n$). Intuitively, why does Fibonnaci appear here? What are the rabbits in this case? Link to Wolfram's computation .","Background to problem (not too important): My proposed solution: The infinitely long element, , however complex, can be represented as a single resistor of resistance $R$.  Remembering the initial resistor near $A$, we know $R_{AB}= r+R$. However, as this is an infinitely long element, it is equivalent to a resistor of resistance $R$ attached  to the right of two resistors of resistance $r$ (the resistance $R$ is an intrinsic property of the element, so is unaffected by the fact that the further to the right it is, the lower the current passing through it). Thus, taking $R$ in series with $r$, then the result in parallel with $r$, then in series with $r$: $$R_{AB}=  r + \left (\frac{1}{\frac{1}{R+r}+\frac{1}{r}}  \right )$$ On the second iteration (moving $R$ further to the right): $$R_{AB}= r+ \frac{1}{\frac{1}{r}+\frac{1}{r + \left (\frac{1}{\frac{1}{R+r}+\frac{1}{r}}  \right )}}$$ Ad infinitum. I understand this may not be the fastest solution, but I'd like to know a little more about it nonetheless. The mathematics $$u_{1}=r+R$$ $$\large u_{n+1}=r+\frac{1}{\frac{1}{r}+\frac{1}{u_n}}$$ Does $\lim_{n \rightarrow \infty} (u_n)$ exist (important: is the limit a function of $R$?), and, if so, what is it? First cases $$u_{2}=\frac{3r^2+2rR}{R+2r}$$ $$u_{3}=\frac{8r^2+5rR}{3R+5r}$$ $$u_{4}=\frac{21r^2+13rR}{8R+13r}$$ $$u_{4}=\frac{55r^2+34rR}{21R+34r}$$ $$\lim _{n \rightarrow \infty} (u_n)\stackrel{?}{=}\varphi r$$ Seems the doing of Fibonnaci. How does one take the limit of this (I assume it requires knowledge of knowledge of the form of $f(n)=F_n$). Intuitively, why does Fibonnaci appear here? What are the rabbits in this case? Link to Wolfram's computation .",,"['limits', 'recurrence-relations']"
27,Is this limit correct: $\lim_{x \to+\infty} \frac{\log_{2}(x-1)}{x} = 0$?,Is this limit correct: ?,\lim_{x \to+\infty} \frac{\log_{2}(x-1)}{x} = 0,"Find $\space\ \begin{align*} \lim_ {x \to+\infty} \left [ \frac{\log_{2}(x-1)}{x}\right]   \end{align*}$. After some minutes around this limit I did it this way: $\log_{2}(x-1)=y \Leftrightarrow 2^y=x-1$ So,$\space x=2^y+1$. When $x \to +\infty$,$\space y \to +\infty$ also. By substitution: $\begin{align*} \lim_ {y \to+\infty} \left [ \frac{\log_{2}(2^y+1-1)}{2^y+1}\right]=\lim_ {y \to+\infty} \left [ \frac{\log_{2}(2^y)}{2^y+1}\right]=\end{align*}$ $\begin{align*}\lim_ {y \to+\infty} \left [ \frac{y}{2^y+1}\right]=\lim_ {y \to+\infty} \left [ \frac{1}{\frac{2^y+1}{y}}  \right]=\lim_ {y \to+\infty} \left [ \frac{1}{\frac{2^y}{y}+\frac{1}{y}}\right]= \frac{1}{+\infty+0}=0  \end{align*}$ Is this correct?Are there any other easy way to find this limit?Thanks","Find $\space\ \begin{align*} \lim_ {x \to+\infty} \left [ \frac{\log_{2}(x-1)}{x}\right]   \end{align*}$. After some minutes around this limit I did it this way: $\log_{2}(x-1)=y \Leftrightarrow 2^y=x-1$ So,$\space x=2^y+1$. When $x \to +\infty$,$\space y \to +\infty$ also. By substitution: $\begin{align*} \lim_ {y \to+\infty} \left [ \frac{\log_{2}(2^y+1-1)}{2^y+1}\right]=\lim_ {y \to+\infty} \left [ \frac{\log_{2}(2^y)}{2^y+1}\right]=\end{align*}$ $\begin{align*}\lim_ {y \to+\infty} \left [ \frac{y}{2^y+1}\right]=\lim_ {y \to+\infty} \left [ \frac{1}{\frac{2^y+1}{y}}  \right]=\lim_ {y \to+\infty} \left [ \frac{1}{\frac{2^y}{y}+\frac{1}{y}}\right]= \frac{1}{+\infty+0}=0  \end{align*}$ Is this correct?Are there any other easy way to find this limit?Thanks",,[]
28,Existence of a limit or misspelled.,Existence of a limit or misspelled.,,"If someone proposes the problem: Calculate the limit: $\lim_{x\rightarrow 2}\frac{x-2}{2-\sqrt{4}}$ For me the limit does not exist because in fact the function $\frac{x-2}{2-\sqrt{4}}$ does not exist. However, it is also true that the problem is misspelled. But my question is that if they already pose the problem to you like this, what is the correct thing to say, you cannot write such a limit (misspelled) or it does not exist.","If someone proposes the problem: Calculate the limit: For me the limit does not exist because in fact the function does not exist. However, it is also true that the problem is misspelled. But my question is that if they already pose the problem to you like this, what is the correct thing to say, you cannot write such a limit (misspelled) or it does not exist.",\lim_{x\rightarrow 2}\frac{x-2}{2-\sqrt{4}} \frac{x-2}{2-\sqrt{4}},['limits']
29,How to use inequalities to solve for multivariable limits?,How to use inequalities to solve for multivariable limits?,,"I am searching for a  methodological description on how to select the correct functions over several inequalities to find and prove that a function has a limit. I quote an example Find the limit of the given function: \begin{equation} \lim_{(x,y)\longrightarrow(0,0)}\frac{x^2y}{x^2+y^2} \end{equation} The solution, in terms of inequalities , is: \begin{equation} \bigg|\frac{x^2y}{x^2+y^2}\bigg|\leqslant|y|\leqslant\sqrt{x^2+y^2} \end{equation} where $\sqrt{x^2+y^2}$ approaches $0$ as $(x,y)\longrightarrow(0,0)$ . First of all, where does the author of this solution get those functions between the intervals, in the solution? What rationale does he use, when he constructs these functions? Apparently , there are many different functions that have limits that reach zero, so is this selection purely intuitive, and a subjective choice? If so, what is the objective method behind this? Thanks","I am searching for a  methodological description on how to select the correct functions over several inequalities to find and prove that a function has a limit. I quote an example Find the limit of the given function: The solution, in terms of inequalities , is: where approaches as . First of all, where does the author of this solution get those functions between the intervals, in the solution? What rationale does he use, when he constructs these functions? Apparently , there are many different functions that have limits that reach zero, so is this selection purely intuitive, and a subjective choice? If so, what is the objective method behind this? Thanks","\begin{equation}
\lim_{(x,y)\longrightarrow(0,0)}\frac{x^2y}{x^2+y^2}
\end{equation} \begin{equation}
\bigg|\frac{x^2y}{x^2+y^2}\bigg|\leqslant|y|\leqslant\sqrt{x^2+y^2}
\end{equation} \sqrt{x^2+y^2} 0 (x,y)\longrightarrow(0,0)","['limits', 'multivariable-calculus']"
30,Integral challenge,Integral challenge,,"The challenge is: if $f:\mathbb{R}\to\mathbb{R}$ is a continuous function, then $$\lim_{t\to0+}\frac{1}{\pi}\int_{-1}^1\frac{tf(x)}{t^2+(x-a)^2}\,\mathrm{d}x=f(a)$$ for every $a\in[-1,1]$ My attemps: Under certainly conditions, i put the limit symbol under the integral sign, but the limit would be $0$ . So it is a bad idea. Therefore, i think use Weierstrass theorem for $f$ in $[-1,1]$ , but i can't solve the problem in the case of $f(x)=x^n$ . What do you recommendme?","The challenge is: if is a continuous function, then for every My attemps: Under certainly conditions, i put the limit symbol under the integral sign, but the limit would be . So it is a bad idea. Therefore, i think use Weierstrass theorem for in , but i can't solve the problem in the case of . What do you recommendme?","f:\mathbb{R}\to\mathbb{R} \lim_{t\to0+}\frac{1}{\pi}\int_{-1}^1\frac{tf(x)}{t^2+(x-a)^2}\,\mathrm{d}x=f(a) a\in[-1,1] 0 f [-1,1] f(x)=x^n","['limits', 'definite-integrals']"
31,Why does this weird iteration converge to the square root ??,Why does this weird iteration converge to the square root ??,,"Let $1 < x < 4$ , $a_1 = x$ and $b_1 = 0$ . Now consider the (conditional) iterations if $a_n > b_n$ then $a_{n+1} = 4(a_n - b_n - 1)$ $b_{n+1} = 2(b_n + 2)$ else ( $a_n = b_n$ or $a_n < b_n$ ) $a_{n+1} = 4 a_n$ $b_{n+1} = 2 b_n$ Now consider $c_n = \frac{b_n}{2^n}$ Now define $f(x) = \lim_{n \to \infty} c_n $ Now apparently $ f(x)  = \sqrt x$ Despite being a simple limit of a conditional iteration, I do not get it. I am even surprised limits of conditional iterations can be analytic functions with respect to the starting value. I have never seen these type of iterations during my education nor in a book. Not even in books about numerical methods. Sure the algorithm converges slowly but it has benefits too and it does not use complicated functions. Im clearly missing the big picture here. Conditional iterations (or recursions) is a topic I know nothing about it seems. How and why does this algorithm give the square root ? What is the bigger picture ? How to generalize this ? I could be wrong, but is this related to the mediant when $x$ is rational ?","Let , and . Now consider the (conditional) iterations if then else ( or ) Now consider Now define Now apparently Despite being a simple limit of a conditional iteration, I do not get it. I am even surprised limits of conditional iterations can be analytic functions with respect to the starting value. I have never seen these type of iterations during my education nor in a book. Not even in books about numerical methods. Sure the algorithm converges slowly but it has benefits too and it does not use complicated functions. Im clearly missing the big picture here. Conditional iterations (or recursions) is a topic I know nothing about it seems. How and why does this algorithm give the square root ? What is the bigger picture ? How to generalize this ? I could be wrong, but is this related to the mediant when is rational ?",1 < x < 4 a_1 = x b_1 = 0 a_n > b_n a_{n+1} = 4(a_n - b_n - 1) b_{n+1} = 2(b_n + 2) a_n = b_n a_n < b_n a_{n+1} = 4 a_n b_{n+1} = 2 b_n c_n = \frac{b_n}{2^n} f(x) = \lim_{n \to \infty} c_n   f(x)  = \sqrt x x,"['limits', 'radicals', 'recursion', 'analyticity']"
32,What is the Ramanujan summation for the series $\sqrt[n]{2}$,What is the Ramanujan summation for the series,\sqrt[n]{2},"A Ramanujan summation is a technique invented by the mathematician Srinivasa Ramanujan for assigning a value to divergent infinite series In my case, I'm interested in assigning a value to the divergent series $$\sum_{n=1}^\infty f(n) \ \ \ \ \ \ \ \text{where}\ \ \ \ f(n)=\sqrt[n]{2}$$ According to the Wikipedia page (and my understanding), the Ramanujan summation is $$\sum_{n=1}^\mathfrak{R} f(n)=\lim_{N\to\infty}\Bigg[\sum_{n=1}^N f(n)-\int_{1}^N f(t)dt\Bigg]$$ Thus $$\sum_{n=1}^\mathfrak{R} \sqrt[n]{2}=\lim_{N\to\infty}\Bigg[\sum_{n=1}^N \sqrt[n]{2}-\int_{1}^N \sqrt[t]{2}dt\Bigg]$$ Taking the antiderivative $$\sum_{n=1}^\mathfrak{R} \sqrt[n]{2}=\lim_{N\to\infty}\Bigg[\sum_{n=1}^N \sqrt[n]{2}-\Bigg(\ln2\Big(\text{li}\ 2-\text{Ei}\frac{\ln2}{N}\Big)+N\sqrt[N]{2}-2\Bigg)\Bigg]$$ Moving some constants outside the limit $$\sum_{n=1}^\mathfrak{R} \sqrt[n]{2}=2-\ln2\cdot\text{li}\ 2+\lim_{N\to\infty}\Bigg[\sum_{n=1}^N \sqrt[n]{2}-\Bigg(N\sqrt[N]{2}-\ln2\cdot\text{Ei}\frac{\ln2}{N}\Bigg)\Bigg]$$ It's at this point I'm unsure of how to proceed. I'm not terribly confident what the limit converges to. From my computational estimates up to $N=10^8$ , I find that $$\sum_{n=1}^\mathfrak{R} \sqrt[n]{2}\approx1.6$$ But due to floating point errors or slow convergence, it deviates substantially enough for me to not be confident about any more digits. I'd like to know if this converges at all, and if it does, is there a (reasonably) closed form / relation to other constants?","A Ramanujan summation is a technique invented by the mathematician Srinivasa Ramanujan for assigning a value to divergent infinite series In my case, I'm interested in assigning a value to the divergent series According to the Wikipedia page (and my understanding), the Ramanujan summation is Thus Taking the antiderivative Moving some constants outside the limit It's at this point I'm unsure of how to proceed. I'm not terribly confident what the limit converges to. From my computational estimates up to , I find that But due to floating point errors or slow convergence, it deviates substantially enough for me to not be confident about any more digits. I'd like to know if this converges at all, and if it does, is there a (reasonably) closed form / relation to other constants?",\sum_{n=1}^\infty f(n) \ \ \ \ \ \ \ \text{where}\ \ \ \ f(n)=\sqrt[n]{2} \sum_{n=1}^\mathfrak{R} f(n)=\lim_{N\to\infty}\Bigg[\sum_{n=1}^N f(n)-\int_{1}^N f(t)dt\Bigg] \sum_{n=1}^\mathfrak{R} \sqrt[n]{2}=\lim_{N\to\infty}\Bigg[\sum_{n=1}^N \sqrt[n]{2}-\int_{1}^N \sqrt[t]{2}dt\Bigg] \sum_{n=1}^\mathfrak{R} \sqrt[n]{2}=\lim_{N\to\infty}\Bigg[\sum_{n=1}^N \sqrt[n]{2}-\Bigg(\ln2\Big(\text{li}\ 2-\text{Ei}\frac{\ln2}{N}\Big)+N\sqrt[N]{2}-2\Bigg)\Bigg] \sum_{n=1}^\mathfrak{R} \sqrt[n]{2}=2-\ln2\cdot\text{li}\ 2+\lim_{N\to\infty}\Bigg[\sum_{n=1}^N \sqrt[n]{2}-\Bigg(N\sqrt[N]{2}-\ln2\cdot\text{Ei}\frac{\ln2}{N}\Bigg)\Bigg] N=10^8 \sum_{n=1}^\mathfrak{R} \sqrt[n]{2}\approx1.6,"['limits', 'divergent-series', 'ramanujan-summation']"
33,Show that : $f(x)+f(1-x)\leq 2$,Show that :,f(x)+f(1-x)\leq 2,"I'm very proud to show one of my dream in term of inequalities . Claim Let $0.25\leq x\leq 0.75$ and $x\neq \frac{2k+1}{100}$ with $12\leq k\leq 37$ and $k$ a natural number then define the function : $$f(x)=x^{\frac{1}{\cos^2(x50\pi)}}+x^{\cos^2(x50\pi)}$$ then we have : $$f(x)+f(1-x)\leq 2$$ First we have $50$ (limit) equality cases as $x=\frac{25}{100},\frac{26}{100},\frac{27}{100},\cdots,\frac{73}{100},\frac{74}{100},\frac{75}{100}$ To prove it I have tried Bernoulli's inequality as we have : $$x^{\frac{1}{\cos^2(x50\pi)}}\leq \frac{1}{1+\Big(\frac{1}{x}-1\Big)\frac{1}{\cos^2(x50\pi)}}$$ And : $$x^{\cos^2(x50\pi)}\leq 1+(x-1)\cos^2(x50\pi)$$ But it doesn't work . I add a graph to convince you : Update as partial answer : It's an heavy method but it works numerically speaking . Well we show that the inequality is true for $x\in[0.307,0.31)$ and $x\in(0.31,0.313]$ . Firstly on these intervals we have : $$(1-x)^{\cos((1-x)50\pi)^2}+x^{\frac{1}{\cos(x50\pi)^2}}\leq 1\quad (1)$$ And $$x^{\cos(x50\pi)^2}+(1-x)^{\frac{1}{\cos((1-x)50\pi)^2}}\leq 1\quad(2)$$ Now we use the method used here General trick to factorize an inequality of the kind $a+b\leq 1$ . The problem becomes : $$\sin\Big(x^{\frac{1}{\cos(x50\pi)^2}}\frac{\pi}{2}\Big)\leq \cos\Big((1-x)^{\cos((1-x)50\pi)^2}\frac{\pi}{2}\Big)$$ Or : $$\ln\Big(x^{\frac{1}{\cos(x50\pi)^2}}\frac{\pi}{2}\Big)\leq \ln \Big(\sin^{-1}\Big(\cos\Big((1-x)^{\cos((1-x)50\pi)^2}\frac{\pi}{2}\Big)\Big)\Big)$$ We study the function : $$h(x)= \ln \Big(\sin^{-1}\Big(\cos\Big((1-x)^{\cos((1-x)50\pi)^2}\frac{\pi}{2}\Big)\Big)\Big)-\ln\Big(x^{\frac{1}{\cos(x50\pi)^2}}\frac{\pi}{2}\Big)$$ The derivative is here Studing this function we see that for $x\in[0.307,0.31)$ the function is increasing and decreasing for $x\in(0.31,0.313]$ But : $$f(0.307)>0 \quad \operatorname{and} \quad f(0.313)>0$$ Happy ending ! Question How to show my claim ? Thanks in advance ! Regards Max .",I'm very proud to show one of my dream in term of inequalities . Claim Let and with and a natural number then define the function : then we have : First we have (limit) equality cases as To prove it I have tried Bernoulli's inequality as we have : And : But it doesn't work . I add a graph to convince you : Update as partial answer : It's an heavy method but it works numerically speaking . Well we show that the inequality is true for and . Firstly on these intervals we have : And Now we use the method used here General trick to factorize an inequality of the kind $a+b\leq 1$ . The problem becomes : Or : We study the function : The derivative is here Studing this function we see that for the function is increasing and decreasing for But : Happy ending ! Question How to show my claim ? Thanks in advance ! Regards Max .,"0.25\leq x\leq 0.75 x\neq \frac{2k+1}{100} 12\leq k\leq 37 k f(x)=x^{\frac{1}{\cos^2(x50\pi)}}+x^{\cos^2(x50\pi)} f(x)+f(1-x)\leq 2 50 x=\frac{25}{100},\frac{26}{100},\frac{27}{100},\cdots,\frac{73}{100},\frac{74}{100},\frac{75}{100} x^{\frac{1}{\cos^2(x50\pi)}}\leq \frac{1}{1+\Big(\frac{1}{x}-1\Big)\frac{1}{\cos^2(x50\pi)}} x^{\cos^2(x50\pi)}\leq 1+(x-1)\cos^2(x50\pi) x\in[0.307,0.31) x\in(0.31,0.313] (1-x)^{\cos((1-x)50\pi)^2}+x^{\frac{1}{\cos(x50\pi)^2}}\leq 1\quad (1) x^{\cos(x50\pi)^2}+(1-x)^{\frac{1}{\cos((1-x)50\pi)^2}}\leq 1\quad(2) \sin\Big(x^{\frac{1}{\cos(x50\pi)^2}}\frac{\pi}{2}\Big)\leq \cos\Big((1-x)^{\cos((1-x)50\pi)^2}\frac{\pi}{2}\Big) \ln\Big(x^{\frac{1}{\cos(x50\pi)^2}}\frac{\pi}{2}\Big)\leq \ln \Big(\sin^{-1}\Big(\cos\Big((1-x)^{\cos((1-x)50\pi)^2}\frac{\pi}{2}\Big)\Big)\Big) h(x)= \ln \Big(\sin^{-1}\Big(\cos\Big((1-x)^{\cos((1-x)50\pi)^2}\frac{\pi}{2}\Big)\Big)\Big)-\ln\Big(x^{\frac{1}{\cos(x50\pi)^2}}\frac{\pi}{2}\Big) x\in[0.307,0.31) x\in(0.31,0.313] f(0.307)>0 \quad \operatorname{and} \quad f(0.313)>0","['limits', 'trigonometry', 'inequality', 'exponentiation']"
34,"Prove that $f(x,y)$ is derivable for all direction in $(0,0)$ but it is not differentiable at $(0,0)$",Prove that  is derivable for all direction in  but it is not differentiable at,"f(x,y) (0,0) (0,0)","Prove that $$f(x,y)=\begin{cases}\dfrac{x^2}{y}&\text{if $(x,y)\neq(x,0)$},\\f(x,0)=0\end{cases}$$ is derivable for all direction in $(0,0)$ but it is not differentiable at $(0,0)$ . I have 3 questions: I think that the function can be translated to $$f(x,y)=\begin{cases}\dfrac{x^2}{y}&\text{if $(x,y)\neq(x,0)$},\\\color{red}0&\color{red}{\text{if $(x,y)=(x,0)$}},\end{cases}$$ right? To prove that has directional derivative in all direction in $(0,0)$ we need to prove that the following limit exists: $$\lim_{h\to0}\frac{f(ah,bh)-f(0,0)}{h},$$ where $\check{v}=(a,b)\in\Bbb R^2$ and $a^2+b^2=1$ . Indeed, $$\lim_{h\to0}\frac{f(ah,bh)-f(0,0)}{h}=\lim_{h\to0}\frac{\frac{(ah)^2}{bh}-0}{h}=\lim_{h\to0}\frac{a^2h^2}{bh^2}=\frac{a^2}{b}=\begin{cases}\frac{a^2}{b}&\text{if $b\neq0$},\\\color{blue}0&\color{blue}{\text{if $b=0$}},\end{cases}$$ thus the limit exists for all direction. The text in $\color{blue}{\text{blue}}$ is correct because we know that $b$ goes in $y$ -direction, and $f(x,y)=0$ if $y=0$ ? To prove that $f$ is not differentiable at $(0,0)$ we can study the continuity of $f$ at $(0,0)$ : $f(0,0)=0$ , but $$\lim_{(x,y)\to(0,0)}f(x,y)=\lim_{(x,y)\to(0,0)}\frac{x^2}{y}\underbrace{=}_{(*)}\underset{y=x^2}{\lim_{x\to0}}\frac{x^2}{x^2}=1,$$ where in $(*)$ we have taken the curve of level $1$ of $f$ , thus $f$ is not continuous at $(0,0)$ . Hence, it is not differentiable at $(0,0)$ . Can we take the curve of level $1$ just ""imposing"" $\frac{x^2}{y}=1$ i.e. $y=x^2$ , or conversely, we need to prove that for all $(x,y)\in E^*(0,0)\cap\{(x,y)\in\Bbb R^2\mid(x,y)\neq(0,0)\}$ , it is $y=x^2$ ? Thanks!","Prove that is derivable for all direction in but it is not differentiable at . I have 3 questions: I think that the function can be translated to right? To prove that has directional derivative in all direction in we need to prove that the following limit exists: where and . Indeed, thus the limit exists for all direction. The text in is correct because we know that goes in -direction, and if ? To prove that is not differentiable at we can study the continuity of at : , but where in we have taken the curve of level of , thus is not continuous at . Hence, it is not differentiable at . Can we take the curve of level just ""imposing"" i.e. , or conversely, we need to prove that for all , it is ? Thanks!","f(x,y)=\begin{cases}\dfrac{x^2}{y}&\text{if (x,y)\neq(x,0)},\\f(x,0)=0\end{cases} (0,0) (0,0) f(x,y)=\begin{cases}\dfrac{x^2}{y}&\text{if (x,y)\neq(x,0)},\\\color{red}0&\color{red}{\text{if (x,y)=(x,0)}},\end{cases} (0,0) \lim_{h\to0}\frac{f(ah,bh)-f(0,0)}{h}, \check{v}=(a,b)\in\Bbb R^2 a^2+b^2=1 \lim_{h\to0}\frac{f(ah,bh)-f(0,0)}{h}=\lim_{h\to0}\frac{\frac{(ah)^2}{bh}-0}{h}=\lim_{h\to0}\frac{a^2h^2}{bh^2}=\frac{a^2}{b}=\begin{cases}\frac{a^2}{b}&\text{if b\neq0},\\\color{blue}0&\color{blue}{\text{if b=0}},\end{cases} \color{blue}{\text{blue}} b y f(x,y)=0 y=0 f (0,0) f (0,0) f(0,0)=0 \lim_{(x,y)\to(0,0)}f(x,y)=\lim_{(x,y)\to(0,0)}\frac{x^2}{y}\underbrace{=}_{(*)}\underset{y=x^2}{\lim_{x\to0}}\frac{x^2}{x^2}=1, (*) 1 f f (0,0) (0,0) 1 \frac{x^2}{y}=1 y=x^2 (x,y)\in E^*(0,0)\cap\{(x,y)\in\Bbb R^2\mid(x,y)\neq(0,0)\} y=x^2","['limits', 'multivariable-calculus', 'derivatives']"
35,Is answer of limit an exact value?,Is answer of limit an exact value?,,Suppose I am finding $$\lim_{x\rightarrow 2} \frac{x^2 - 4}{x - 2}$$ The answer comes out to be 4. Is '4' exact value or approaching value? Also we have $$\lim_{x\rightarrow 0} \frac{\sin x}{x}=1$$ I know that this value of $\frac{\sin x}{x}$ is slightly less than $1$ in neighborhood of $x=0$ so what if we are asked $$\lim_{x\rightarrow 0}\bigg\lfloor  \frac{\sin x}{x} \bigg\rfloor $$ Will answer be $1$ or $0$ and are $$\lim_{x\rightarrow 0}\bigg\lfloor  \frac{\sin x}{x} \bigg\rfloor $$ and  $$\bigg\lfloor  \lim_{x\rightarrow 0} \frac{\sin x}{x} \bigg\rfloor$$ same or different?,Suppose I am finding $$\lim_{x\rightarrow 2} \frac{x^2 - 4}{x - 2}$$ The answer comes out to be 4. Is '4' exact value or approaching value? Also we have $$\lim_{x\rightarrow 0} \frac{\sin x}{x}=1$$ I know that this value of $\frac{\sin x}{x}$ is slightly less than $1$ in neighborhood of $x=0$ so what if we are asked $$\lim_{x\rightarrow 0}\bigg\lfloor  \frac{\sin x}{x} \bigg\rfloor $$ Will answer be $1$ or $0$ and are $$\lim_{x\rightarrow 0}\bigg\lfloor  \frac{\sin x}{x} \bigg\rfloor $$ and  $$\bigg\lfloor  \lim_{x\rightarrow 0} \frac{\sin x}{x} \bigg\rfloor$$ same or different?,,"['limits', 'functions']"
36,On the existence of limits of multivariable rational functions,On the existence of limits of multivariable rational functions,,"Standard limit-related counterexamples in multivariable calculus include limits like $$\lim_{(x,y) \to (0,0)} \frac{2xy}{x^2 + y^2}$$ which tends to $0$ if the origin is approached along $x=0$ or $y=0$ , but approaches $1$ if the origin is approached along the line $x=y$ . This implies that the limit does not exist. Indeed, there's rational functions for which the limit exists (and is the same) along all lines containing $(x_0, y_0)$ , and yet the limit still fails to exist. For example, if we consider $$\lim_{(x,y) \to (0,0)} \frac{2xy^2}{x^2 + y^4}$$ the limit is $0$ along lines of the form $y=\alpha x$ but $1$ along the curve $y^2 = x$ . I was wondering if we could have a more general counterexample of this sort. Suppose $g(x,y)$ and $f(x,y)$ are two-variable polynomials defined on an open subset of $\mathbb{R}^2$ containing the origin such that $\lim_{(x,y) \to (0,0)} f(x,y) = \lim_{(x,y) \to (0,0)} g(x,y) = 0$ . In addition, suppose the rational function $$\frac{f(x,y)}{g(x,y)}$$ tends to some limit $L$ when $(0,0)$ is approached along curves of the form $y=\alpha x^{\beta}$ where $\alpha \in \mathbb{R}$ and $\beta>0$ (the limit $L$ is independent of the curve). Does it follow that $$\lim_{(x,y) \to (0,0)} \frac{f(x,y)}{g(x,y)} = L?$$","Standard limit-related counterexamples in multivariable calculus include limits like which tends to if the origin is approached along or , but approaches if the origin is approached along the line . This implies that the limit does not exist. Indeed, there's rational functions for which the limit exists (and is the same) along all lines containing , and yet the limit still fails to exist. For example, if we consider the limit is along lines of the form but along the curve . I was wondering if we could have a more general counterexample of this sort. Suppose and are two-variable polynomials defined on an open subset of containing the origin such that . In addition, suppose the rational function tends to some limit when is approached along curves of the form where and (the limit is independent of the curve). Does it follow that","\lim_{(x,y) \to (0,0)} \frac{2xy}{x^2 + y^2} 0 x=0 y=0 1 x=y (x_0, y_0) \lim_{(x,y) \to (0,0)} \frac{2xy^2}{x^2 + y^4} 0 y=\alpha x 1 y^2 = x g(x,y) f(x,y) \mathbb{R}^2 \lim_{(x,y) \to (0,0)} f(x,y) = \lim_{(x,y) \to (0,0)} g(x,y) = 0 \frac{f(x,y)}{g(x,y)} L (0,0) y=\alpha x^{\beta} \alpha \in \mathbb{R} \beta>0 L \lim_{(x,y) \to (0,0)} \frac{f(x,y)}{g(x,y)} = L?","['limits', 'multivariable-calculus']"
37,Limit of sum of periodic function,Limit of sum of periodic function,,"Let $f_1,f_2,...,f_n$ are periodic functions,if $\lim\limits_{x\rightarrow\infty}\sum_{i=1}^n f_i(x)$ is  existent  and bounded. How to show $\sum_{i=1}^n f_i(x)\equiv C$ ? $C$ is a constant.","Let $f_1,f_2,...,f_n$ are periodic functions,if $\lim\limits_{x\rightarrow\infty}\sum_{i=1}^n f_i(x)$ is  existent  and bounded. How to show $\sum_{i=1}^n f_i(x)\equiv C$ ? $C$ is a constant.",,"['analysis', 'limits', 'periodic-functions']"
38,A limit similar to the famous $\left(1 + \frac{1}{a_n}\right)^{a_n}$ one,A limit similar to the famous  one,\left(1 + \frac{1}{a_n}\right)^{a_n},"Let's consider two sequences $(a_n), (b_n)$ in $\mathbb{R}$ such that  $$\lim_{n \to +\infty} a_n, \lim_{n \to +\infty} b_n  = + \infty$$ Proposition: the sequence $$x_n = \left(1 + \frac{1}{a_n}\right)^{b_n}$$ has a limit if $\lim_{n \to +\infty} \frac{b_n}{a_n}$ exists. How can one prove it? What is this limit? Does $x_n$ have a limit if $\lim_{n \to +\infty} \frac{b_n}{a_n}$ does not exist?","Let's consider two sequences $(a_n), (b_n)$ in $\mathbb{R}$ such that  $$\lim_{n \to +\infty} a_n, \lim_{n \to +\infty} b_n  = + \infty$$ Proposition: the sequence $$x_n = \left(1 + \frac{1}{a_n}\right)^{b_n}$$ has a limit if $\lim_{n \to +\infty} \frac{b_n}{a_n}$ exists. How can one prove it? What is this limit? Does $x_n$ have a limit if $\lim_{n \to +\infty} \frac{b_n}{a_n}$ does not exist?",,['limits']
39,"Problem with multivariable calculus: $\lim_{(x,y)\to (0,0)} \frac{x^3 + y^3}{x^2 + y}$",Problem with multivariable calculus:,"\lim_{(x,y)\to (0,0)} \frac{x^3 + y^3}{x^2 + y}","Anyone can help me with this limit? $$\lim_{(x,y)\to (0,0)} \frac{x^3 + y^3}{x^2 + y}$$ I'm having trouble with proving that this limit really goes to $0$ thank you","Anyone can help me with this limit? $$\lim_{(x,y)\to (0,0)} \frac{x^3 + y^3}{x^2 + y}$$ I'm having trouble with proving that this limit really goes to $0$ thank you",,"['limits', 'multivariable-calculus']"
40,"Prove $ \ \frac{a}{x^3 + 2x^2 - 1} + \frac{b}{x^3 + x - 2} \ = \ 0 \ $ has a solution in $ \ (-1,1) $",Prove  has a solution in," \ \frac{a}{x^3 + 2x^2 - 1} + \frac{b}{x^3 + x - 2} \ = \ 0 \   \ (-1,1) ","If $a$ and $b$ are positive numbers, prove that the equation $$\frac{a}{x^3 + 2x^2 - 1} + \frac{b}{x^3 + x - 2} = 0$$ has at least one solution in the interval $ \ (-1,1) \ $ . The question is from the exercises section of a textbook chapter on limits/continuity. I've been stumped on this one for a couple of days. I've been trying to calculate $\lim _{x \to -1}$ and $\lim _{x \to 1}$ and then show the function is continuous to show a root must lie in the interval. Factorising the denominators gives... $$\frac{a}{(x+1)(x^2+x-1)} + \frac{b}{(x-1)(x^2+x+2)} = 0$$ So of course $x = 1$ and $x = -1$ are undefined and so the limits will be one-sided. Playing around with equation I haven't been able to find an equivalent function across $x \neq -1, x \neq 1$. The only thing I have been able to show is $$\frac{a}{b} = - \frac{(x+1)(x^2+x-1)}{(x-1)(x^2+x+2)}$$ and so $$\lim _{x \to -1} \frac{a}{b} = 0, \lim _{x \to 1} \frac{b}{a} = 0$$ but I'm not sure if this is significant or I'm overthinking things. Could anyone point me in the right direction?","If $a$ and $b$ are positive numbers, prove that the equation $$\frac{a}{x^3 + 2x^2 - 1} + \frac{b}{x^3 + x - 2} = 0$$ has at least one solution in the interval $ \ (-1,1) \ $ . The question is from the exercises section of a textbook chapter on limits/continuity. I've been stumped on this one for a couple of days. I've been trying to calculate $\lim _{x \to -1}$ and $\lim _{x \to 1}$ and then show the function is continuous to show a root must lie in the interval. Factorising the denominators gives... $$\frac{a}{(x+1)(x^2+x-1)} + \frac{b}{(x-1)(x^2+x+2)} = 0$$ So of course $x = 1$ and $x = -1$ are undefined and so the limits will be one-sided. Playing around with equation I haven't been able to find an equivalent function across $x \neq -1, x \neq 1$. The only thing I have been able to show is $$\frac{a}{b} = - \frac{(x+1)(x^2+x-1)}{(x-1)(x^2+x+2)}$$ and so $$\lim _{x \to -1} \frac{a}{b} = 0, \lim _{x \to 1} \frac{b}{a} = 0$$ but I'm not sure if this is significant or I'm overthinking things. Could anyone point me in the right direction?",,"['limits', 'continuity']"
41,Euler-Mascheroni constant [strategic proof],Euler-Mascheroni constant [strategic proof],,"I know two proofs about the approximation of Euler-Mascheroni constant $\gamma$ that are very technical.  So I would like to know if someone has a strategic proof to show that $0.5<\gamma< 0.6$. Let be $\gamma\in \mathbb{R}$ such that $$\large\gamma= \lim_{n\to +\infty}\left[\left(1+\frac{1}{2}+\cdots+\frac{1}{n}\right)-\log{(n+1)}\right].$$ Show that $0.5<\gamma< 0.6$ P.S.: In my book, the author use $\log{(n+1)}$ in the limit definition of $\gamma$.","I know two proofs about the approximation of Euler-Mascheroni constant $\gamma$ that are very technical.  So I would like to know if someone has a strategic proof to show that $0.5<\gamma< 0.6$. Let be $\gamma\in \mathbb{R}$ such that $$\large\gamma= \lim_{n\to +\infty}\left[\left(1+\frac{1}{2}+\cdots+\frac{1}{n}\right)-\log{(n+1)}\right].$$ Show that $0.5<\gamma< 0.6$ P.S.: In my book, the author use $\log{(n+1)}$ in the limit definition of $\gamma$.",,"['limits', 'alternative-proof', 'euler-mascheroni-constant']"
42,General proof of limit composition theorem on continuous function,General proof of limit composition theorem on continuous function,,"Let $A, B \subset \mathbb{R}$, $a, b, c \in  \overline{\mathbb{R}}$, $a$ and $b$ be limit points of $A$ and $B$. Let $f: A \rightarrow B$ and $g : B \rightarrow \mathbb{R}$. I have to prove that if $b \in B$ and $g$ is cointinous in $b$ and $\lim \limits_{x \to a}{f(x)} = b$ $\lim \limits_{y \to b}{g(y)} = c$ then $\lim \limits_{x \to a}{(g \circ f)(x)} = c$. How to make a proof to as general theorem as above?","Let $A, B \subset \mathbb{R}$, $a, b, c \in  \overline{\mathbb{R}}$, $a$ and $b$ be limit points of $A$ and $B$. Let $f: A \rightarrow B$ and $g : B \rightarrow \mathbb{R}$. I have to prove that if $b \in B$ and $g$ is cointinous in $b$ and $\lim \limits_{x \to a}{f(x)} = b$ $\lim \limits_{y \to b}{g(y)} = c$ then $\lim \limits_{x \to a}{(g \circ f)(x)} = c$. How to make a proof to as general theorem as above?",,['limits']
43,How to prove these two limits $\lim_{n\to\infty}\frac{a_{n}}{n}$ and $\lim_{n\to\infty}\frac{a_{n+1}-a_{n}}{n}$ exist?,How to prove these two limits  and  exist?,\lim_{n\to\infty}\frac{a_{n}}{n} \lim_{n\to\infty}\frac{a_{n+1}-a_{n}}{n},"Assume that $$\lim_{n\to\infty}(a_{n+2}-a_{n})=A$$ show that $\displaystyle \lim_{n\to\infty}\dfrac{a_{n}}{n}$and $\displaystyle\lim_{n\to\infty}\dfrac{a_{n+1}-a_{n}}{n}$ exist and find these limits. maybe this problem have some methods, Thank you. since  $$\lim_{n\to\infty}(a_{n+2}-a_{n})=A$$ so there exists $N$, and for $\forall \varepsilon>0$, such $$|a_{n+2}-a_{n}-A|\le\varepsilon$$","Assume that $$\lim_{n\to\infty}(a_{n+2}-a_{n})=A$$ show that $\displaystyle \lim_{n\to\infty}\dfrac{a_{n}}{n}$and $\displaystyle\lim_{n\to\infty}\dfrac{a_{n+1}-a_{n}}{n}$ exist and find these limits. maybe this problem have some methods, Thank you. since  $$\lim_{n\to\infty}(a_{n+2}-a_{n})=A$$ so there exists $N$, and for $\forall \varepsilon>0$, such $$|a_{n+2}-a_{n}-A|\le\varepsilon$$",,"['analysis', 'limits']"
44,"Why does $\lim_{x \rightarrow 0} B(x,y)$ exist and how is it calculated?",Why does  exist and how is it calculated?,"\lim_{x \rightarrow 0} B(x,y)","In evaluating integrals like (link to another example) $$I=\int_0^1\frac{\log(x) \log^2(1-x)dx}{x}$$ one can make the substitution $x=\sin^2(\theta)$ to obtain $$I=16\int_0^\frac{\pi}{2}\frac{\log(\sin(x)) \log^2(\cos(x)) \cos(x)dx}{\sin(x)}$$ which is the partial derivative of the beta function at $(x=0,y=1)$: $$I=\lim_{x \rightarrow 0^+}\partial_y^2\partial_x B(x,1)$$ because $$B(x,y)=2 \int_0^\frac{\pi}{2} \cos^{2x-1}(x)\sin^{2y-1}(x)dx$$ $$\partial^2_y\partial_xB(x,y)=16\int_0^\frac{\pi}{2} \log(\cos(x))^2\log(\sin(x)) \cos^{2x-1}(x)\sin^{2y-1}(x)dx.$$ My problem: $I$ is convergent, and taking the partial derivatives of $B(x,y)$ in the way above does yeild $2I$, however $B(x,y)$ is only defined for $\Re(x), \Re(y) >0$. So, how does one: Go about proving that the limit exists (directly using the partial derivatives of the beta function, without reference to $I$)? (Extra points for intuition, as I don't see how the partial derivative can exist at a place where the function doesn't). Find the limit in this case?","In evaluating integrals like (link to another example) $$I=\int_0^1\frac{\log(x) \log^2(1-x)dx}{x}$$ one can make the substitution $x=\sin^2(\theta)$ to obtain $$I=16\int_0^\frac{\pi}{2}\frac{\log(\sin(x)) \log^2(\cos(x)) \cos(x)dx}{\sin(x)}$$ which is the partial derivative of the beta function at $(x=0,y=1)$: $$I=\lim_{x \rightarrow 0^+}\partial_y^2\partial_x B(x,1)$$ because $$B(x,y)=2 \int_0^\frac{\pi}{2} \cos^{2x-1}(x)\sin^{2y-1}(x)dx$$ $$\partial^2_y\partial_xB(x,y)=16\int_0^\frac{\pi}{2} \log(\cos(x))^2\log(\sin(x)) \cos^{2x-1}(x)\sin^{2y-1}(x)dx.$$ My problem: $I$ is convergent, and taking the partial derivatives of $B(x,y)$ in the way above does yeild $2I$, however $B(x,y)$ is only defined for $\Re(x), \Re(y) >0$. So, how does one: Go about proving that the limit exists (directly using the partial derivatives of the beta function, without reference to $I$)? (Extra points for intuition, as I don't see how the partial derivative can exist at a place where the function doesn't). Find the limit in this case?",,"['limits', 'definite-integrals', 'special-functions']"
45,"Prove $0, \frac{1}{2}, 0, \frac{1}{3}, \frac{2}{3}, 0, \frac{1}{4}, \frac{2}{4}, ...$ equidistributed in $[0, 1)$",Prove  equidistributed in,"0, \frac{1}{2}, 0, \frac{1}{3}, \frac{2}{3}, 0, \frac{1}{4}, \frac{2}{4}, ... [0, 1)","Prove $0, \frac{1}{2}, 0, \frac{1}{3}, \frac{2}{3}, 0, \frac{1}{4}, \frac{2}{4}, ...$ equidistributed in $[0, 1)$. A sequence of numbers $\xi_1, \xi_2, \xi_3, ...$ in $[0, 1)$ is said to be equidistributed if for every   interval $(a, b) \subset [0, 1)$ $$\lim\limits_{N\to\infty} \frac {\bigl|\{1\le n\le N: \xi_n \in (a, b)\}\bigr|} {N} = b-a$$ It's from Chapter 4 in the book Fourier Analysis: An Introduction","Prove $0, \frac{1}{2}, 0, \frac{1}{3}, \frac{2}{3}, 0, \frac{1}{4}, \frac{2}{4}, ...$ equidistributed in $[0, 1)$. A sequence of numbers $\xi_1, \xi_2, \xi_3, ...$ in $[0, 1)$ is said to be equidistributed if for every   interval $(a, b) \subset [0, 1)$ $$\lim\limits_{N\to\infty} \frac {\bigl|\{1\le n\le N: \xi_n \in (a, b)\}\bigr|} {N} = b-a$$ It's from Chapter 4 in the book Fourier Analysis: An Introduction",,"['limits', 'equidistribution']"
46,"$\ \forall x_1,x_2,...,x_n \in \mathbb{R} (x_i\not=x_j)$ in the range of $[-1,1]$ prove:$\sum_{i=1}^{n}\frac{1}{\Pi_{k\not=i}|x_k-x_i|}\ge2^{n-2}$",in the range of  prove:,"\ \forall x_1,x_2,...,x_n \in \mathbb{R} (x_i\not=x_j) [-1,1] \sum_{i=1}^{n}\frac{1}{\Pi_{k\not=i}|x_k-x_i|}\ge2^{n-2}","$\ \forall$ $x_1,x_2,...,x_n$ $\in \mathbb{R}$ $(x_i\not=x_j)$ in the range of $[-1,1]$ prove : $$\sum_{i=1}^{n}\frac{1}{\Pi_{k\not=i}|x_k-x_i|}\ge2^{n-2}$$ my attempt : $$p(x) = \sum_{i=1}^{n}\left(p(x_i)\prod_{k\not=i}\frac{x-x_k}{x_i-x_k}\right)$$ by triangle inequality : $$\left|p(x)\right| \leq \sum_{i=1}^{n}\left|p(x_i)\right|\prod_{k\not=i}\bigg|\frac{x-x_k}{x_i-x_k}\bigg|$$ now if $p(x) = \sum_{i=0}^{n-1}a_ix^i$ then : $$\left|\frac{p(x)}{x^{n-1}}\right|\leq\sum_{k=1}^{n}\frac{\left|p(x_k)\right|}{\prod_{k\not=j}\left|x_k-x_j\right|}\Bigg|\prod_{k\not=j}(1-\frac{x_i}{x})\Bigg|$$ then if we $x\to\infty$ we get : $$\left|a_{n-1}\right|\leq\sum_{k=1}^{n}\frac{\left|p(x_k)\right|}{\prod_{k\not=i}\left|x_k-x_i\right|}$$",in the range of prove : my attempt : by triangle inequality : now if then : then if we we get :,"\ \forall x_1,x_2,...,x_n \in \mathbb{R} (x_i\not=x_j) [-1,1] \sum_{i=1}^{n}\frac{1}{\Pi_{k\not=i}|x_k-x_i|}\ge2^{n-2} p(x) = \sum_{i=1}^{n}\left(p(x_i)\prod_{k\not=i}\frac{x-x_k}{x_i-x_k}\right) \left|p(x)\right| \leq \sum_{i=1}^{n}\left|p(x_i)\right|\prod_{k\not=i}\bigg|\frac{x-x_k}{x_i-x_k}\bigg| p(x) = \sum_{i=0}^{n-1}a_ix^i \left|\frac{p(x)}{x^{n-1}}\right|\leq\sum_{k=1}^{n}\frac{\left|p(x_k)\right|}{\prod_{k\not=j}\left|x_k-x_j\right|}\Bigg|\prod_{k\not=j}(1-\frac{x_i}{x})\Bigg| x\to\infty \left|a_{n-1}\right|\leq\sum_{k=1}^{n}\frac{\left|p(x_k)\right|}{\prod_{k\not=i}\left|x_k-x_i\right|}","['limits', 'polynomials', 'lagrange-interpolation', 'triangle-inequality']"
47,Is $f(g(x))$ discontinuous?,Is  discontinuous?,f(g(x)),"Question: Let $f(x) = \frac{1}{15x^2+8x+1} $ and $ g(x)= \frac{1}{(x-1)(x-2)} $ , then the number of points of discontinuity of $f(g(x))$ is? The answer key claimed that the answer is $1$ , but I don't agree with it. I claim that the answer should be zero, since $f(g(x))$ simplifies to $h(x)=\frac{x^{2}-3x+2}{(5x^{2}-15x+11)(3x^{2}-9x+7)}$ . So $h(1)=h(2)=0$ , which upon plotting on Desmos gives rise to same results. However, there is a counter argument that since $g(x)$ is not defined at $x=1,2$ , how can $f(g(x))$ be defined at those points? And hence there are $2$ points of discontinuity. Which of the arguments is correct?","Question: Let and , then the number of points of discontinuity of is? The answer key claimed that the answer is , but I don't agree with it. I claim that the answer should be zero, since simplifies to . So , which upon plotting on Desmos gives rise to same results. However, there is a counter argument that since is not defined at , how can be defined at those points? And hence there are points of discontinuity. Which of the arguments is correct?","f(x) = \frac{1}{15x^2+8x+1}   g(x)= \frac{1}{(x-1)(x-2)}  f(g(x)) 1 f(g(x)) h(x)=\frac{x^{2}-3x+2}{(5x^{2}-15x+11)(3x^{2}-9x+7)} h(1)=h(2)=0 g(x) x=1,2 f(g(x)) 2","['limits', 'functions', 'continuity', 'function-and-relation-composition']"
48,Another strange limit which seems to converges to $\gamma$,Another strange limit which seems to converges to,\gamma,"Hi in trying to show that the Euler Mascheroni constant is irrational or not I find empiricaly : $$\lim_{n\to\infty,x\to 0}f_n(x)=\lim_{n\to\infty,x\to 0}\frac{x!!!...!^{x!!...!^{x!...!^{...^{x!}}}}-x!^{x!!^{x!!!^{...^{x!!!...!}}}}}{x}=^?\gamma=0.5772...$$ Some explanation : In the case $n=2$ we have : $$f_2(x)=\frac{x!!^{x!}-x!^{x!!}}{x}$$ In the case $n=3$ we have : $$f_3(x)=\frac{x!!!^{x!!^{x!}}-x!^{x!!^{x!!!}}}{x}$$ And so on... On the other hand we have : $$x!=\Gamma(x+1),x!!=\Gamma(\Gamma(x+1)+1)...$$ As clue we have : Let : $g(x)=\frac{d}{dx}x!$ Then : $$-g(0)=\gamma$$ When $k=2n$ , $n\geq 3$ an integer  it seems we have : $$\lim_{x\to 0}f_k=(-1+(1-\gamma)^{k-1})\gamma$$ And : $$\lim_{x\to 0}\frac{\left(x!!\right)^{ax!}-\left(x!\right)^{ax!!}}{x}=\gamma^2a$$ So there is a possible induction here . How to (dis)prove it ?","Hi in trying to show that the Euler Mascheroni constant is irrational or not I find empiricaly : Some explanation : In the case we have : In the case we have : And so on... On the other hand we have : As clue we have : Let : Then : When , an integer  it seems we have : And : So there is a possible induction here . How to (dis)prove it ?","\lim_{n\to\infty,x\to 0}f_n(x)=\lim_{n\to\infty,x\to 0}\frac{x!!!...!^{x!!...!^{x!...!^{...^{x!}}}}-x!^{x!!^{x!!!^{...^{x!!!...!}}}}}{x}=^?\gamma=0.5772... n=2 f_2(x)=\frac{x!!^{x!}-x!^{x!!}}{x} n=3 f_3(x)=\frac{x!!!^{x!!^{x!}}-x!^{x!!^{x!!!}}}{x} x!=\Gamma(x+1),x!!=\Gamma(\Gamma(x+1)+1)... g(x)=\frac{d}{dx}x! -g(0)=\gamma k=2n n\geq 3 \lim_{x\to 0}f_k=(-1+(1-\gamma)^{k-1})\gamma \lim_{x\to 0}\frac{\left(x!!\right)^{ax!}-\left(x!\right)^{ax!!}}{x}=\gamma^2a","['limits', 'derivatives', 'gamma-function', 'function-and-relation-composition', 'euler-mascheroni-constant']"
49,From $\sqrt{2\pi}$ to Glaisher-Kinkelin to what?,From  to Glaisher-Kinkelin to what?,\sqrt{2\pi},"I was reading about Glaisher-Kinkelin Constant and came across the following formulas $$ \sqrt{2\pi} = \lim_{n\rightarrow\infty} \frac{n!}{n^{\frac{2n+1}{2}}e^{-n}} $$ $$ A = \lim_{n\rightarrow\infty} \frac{H(n)}{n^{\frac{6n^2+6n+1}{12}}e^{-\frac{n^2}{4}}} $$ I came across the Stirling numbers of the second kind $S(p,k)$ in research, in the form of $a_{p,k} = k! S(p,k)$ . Now in the formulas above, we see that there are the polynomials $2n+1$ and $6n^2+6n+1$ , whose coefficients are $a_{2,\cdot}$ and $a_{3,\cdot}$ respectively. Is there a known constant that uses the polynomial $24n^3+36n^2+14n+1$ , the coefficients for $a_{4,\cdot}\ ?$ . My guess is that the numerator in the limit would have something like $H_2(n) = \prod k^{k^k}$ .","I was reading about Glaisher-Kinkelin Constant and came across the following formulas I came across the Stirling numbers of the second kind in research, in the form of . Now in the formulas above, we see that there are the polynomials and , whose coefficients are and respectively. Is there a known constant that uses the polynomial , the coefficients for . My guess is that the numerator in the limit would have something like .","
\sqrt{2\pi} = \lim_{n\rightarrow\infty} \frac{n!}{n^{\frac{2n+1}{2}}e^{-n}}
 
A = \lim_{n\rightarrow\infty} \frac{H(n)}{n^{\frac{6n^2+6n+1}{12}}e^{-\frac{n^2}{4}}}
 S(p,k) a_{p,k} = k! S(p,k) 2n+1 6n^2+6n+1 a_{2,\cdot} a_{3,\cdot} 24n^3+36n^2+14n+1 a_{4,\cdot}\ ? H_2(n) = \prod k^{k^k}",['limits']
50,Find a value of $\;\lim\limits_{n\rightarrow\infty}\frac{a_{n}}{n}$,Find a value of,\;\lim\limits_{n\rightarrow\infty}\frac{a_{n}}{n},"(If you're good at it, you can do it by heart.) Let $a_n$ be the average value of lengths of all the diagonal lines of regular n-gon whose side is 1. Find a value of $$\lim_{n\rightarrow\infty}\frac{a_{n}}{n}$$ Source: Fujino_Yusui After messing around with the cosine theorem and doing some calculations, I found the exact formula of $a_{n},$ so I did the rest of the calculations and the answer is $$\lim_{n\rightarrow\infty}\frac{a_{n}}{n}= \lim_{n\rightarrow\infty}\frac{2\cos\frac{\pi}{n}- 1}{\left ( \left ( 1- \cos\frac{\pi}{n} \right )n \right )\left ( n- 3 \right )}= \frac{2}{\pi^{2}}$$ But I want to see a shortcut that leads $a_{n}\sim\frac{n}{2\pi}\cdot\frac{4}{\pi}\,{\rm as}\,n\rightarrow\infty$ without cosine theorem, I need to the help.","(If you're good at it, you can do it by heart.) Let be the average value of lengths of all the diagonal lines of regular n-gon whose side is 1. Find a value of Source: Fujino_Yusui After messing around with the cosine theorem and doing some calculations, I found the exact formula of so I did the rest of the calculations and the answer is But I want to see a shortcut that leads without cosine theorem, I need to the help.","a_n \lim_{n\rightarrow\infty}\frac{a_{n}}{n} a_{n}, \lim_{n\rightarrow\infty}\frac{a_{n}}{n}= \lim_{n\rightarrow\infty}\frac{2\cos\frac{\pi}{n}- 1}{\left ( \left ( 1- \cos\frac{\pi}{n} \right )n \right )\left ( n- 3 \right )}= \frac{2}{\pi^{2}} a_{n}\sim\frac{n}{2\pi}\cdot\frac{4}{\pi}\,{\rm as}\,n\rightarrow\infty",['limits']
51,Conditions for function to be discontinuous at 0,Conditions for function to be discontinuous at 0,,"I'm supposed to find out the set of values of $m$ for which f is discontinuous at 0, for $f(x)=x^m\sin\frac{1}{x}$ . The solutions obviously mention the interval $(-\infty, 0]$ . However; In the left-side limit, where the $x$ is negative, i.e. $$ \lim_{x \to 0^-}x^m\sin\frac{1}{x}, $$ if $m$ is of the form $\frac{1}{2^n}$ where $n$ is any natural number, wouldn't the resultant number become complex? Wouldn't the function only be defined in 0 and $\mathbf R^+$ ? The left-hand limit for $0$ wouldn't exist. Wouldn't this be considered a discontinuity? If so, why isn't this set included with set $(-\infty, 0]$ ?","I'm supposed to find out the set of values of for which f is discontinuous at 0, for . The solutions obviously mention the interval . However; In the left-side limit, where the is negative, i.e. if is of the form where is any natural number, wouldn't the resultant number become complex? Wouldn't the function only be defined in 0 and ? The left-hand limit for wouldn't exist. Wouldn't this be considered a discontinuity? If so, why isn't this set included with set ?","m f(x)=x^m\sin\frac{1}{x} (-\infty, 0] x 
\lim_{x \to 0^-}x^m\sin\frac{1}{x},
 m \frac{1}{2^n} n \mathbf R^+ 0 (-\infty, 0]","['limits', 'continuity']"
52,Does $\sin\vartheta=2^n\sin\frac{\vartheta}{2^n}\prod\limits_{k=1}^n\cos\frac{\vartheta}{2^k}$ imply $\vartheta=1$?,Does  imply ?,\sin\vartheta=2^n\sin\frac{\vartheta}{2^n}\prod\limits_{k=1}^n\cos\frac{\vartheta}{2^k} \vartheta=1,"From the formula, $$\sin\vartheta = 2\cos\frac{\vartheta}2\sin\frac{\vartheta}2\tag1$$ by dividing both sides by $\cos\vartheta$ we could derive that $$\tan \vartheta = \frac 2{\cos \vartheta}\cos^2\frac{\vartheta}2\tan\frac{\vartheta}2$$ and hence by iteration through $\tan\vartheta\mapsto\tan\frac{\vartheta}2$ and simplifying, we can show that $(1)$ is a special case $n=1$ of the broader theorem, $$\sin\vartheta=2^n\sin\frac{\vartheta}{2^n}\prod_{k=1}^n\cos\frac{\vartheta}{2^k}\tag2$$ for a natural number $n\geqslant 1$ . When we iterate through $\frac{\sin\vartheta}{\vartheta}\mapsto\cfrac{\sin\frac{\vartheta}{2^n}}{\frac{\vartheta}{2^n}}$ , we obtain \begin{align}\frac{\sin\vartheta}{\vartheta}&=\bigg(\prod_{k=1}^n\cos\frac{\vartheta}{2^k}\bigg)\bigg(\prod_{k=1}^n\cos\frac{\vartheta}{2^{k+n}}\bigg)\bigg(\prod_{k=1}^n\cos\frac{\vartheta}{2^{k+2n}}\bigg)\cdots \\ &=\prod_{k=1}^\infty\cos\frac{\vartheta}{2^k}\tag3\end{align} and this is where I am stuck. By $(3)$ , wouldn't $(2)$ imply that $$\eta\sin\frac{\vartheta}{\eta}\stackrel{\eta\to\infty}{\longrightarrow}1$$ for some $\eta$ (in this case, $\eta=2^n$ ), which could only mean $\vartheta=1$ ? This is strange to me because $(2)$ is meant to work for all $\vartheta$ and not just $\vartheta=1$ . Thanks in advance, and apologies for the nonrigorous approach.","From the formula, by dividing both sides by we could derive that and hence by iteration through and simplifying, we can show that is a special case of the broader theorem, for a natural number . When we iterate through , we obtain and this is where I am stuck. By , wouldn't imply that for some (in this case, ), which could only mean ? This is strange to me because is meant to work for all and not just . Thanks in advance, and apologies for the nonrigorous approach.",\sin\vartheta = 2\cos\frac{\vartheta}2\sin\frac{\vartheta}2\tag1 \cos\vartheta \tan \vartheta = \frac 2{\cos \vartheta}\cos^2\frac{\vartheta}2\tan\frac{\vartheta}2 \tan\vartheta\mapsto\tan\frac{\vartheta}2 (1) n=1 \sin\vartheta=2^n\sin\frac{\vartheta}{2^n}\prod_{k=1}^n\cos\frac{\vartheta}{2^k}\tag2 n\geqslant 1 \frac{\sin\vartheta}{\vartheta}\mapsto\cfrac{\sin\frac{\vartheta}{2^n}}{\frac{\vartheta}{2^n}} \begin{align}\frac{\sin\vartheta}{\vartheta}&=\bigg(\prod_{k=1}^n\cos\frac{\vartheta}{2^k}\bigg)\bigg(\prod_{k=1}^n\cos\frac{\vartheta}{2^{k+n}}\bigg)\bigg(\prod_{k=1}^n\cos\frac{\vartheta}{2^{k+2n}}\bigg)\cdots \\ &=\prod_{k=1}^\infty\cos\frac{\vartheta}{2^k}\tag3\end{align} (3) (2) \eta\sin\frac{\vartheta}{\eta}\stackrel{\eta\to\infty}{\longrightarrow}1 \eta \eta=2^n \vartheta=1 (2) \vartheta \vartheta=1,"['limits', 'trigonometry', 'induction', 'recurrence-relations', 'infinite-product']"
53,$\lim\limits_{n \to \infty}\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}}}}}.$,,\lim\limits_{n \to \infty}\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}}}}}.,"Problem Evaluate $\lim\limits_{n \to \infty}T_n$ where $$T_n=\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}}}}}.$$ Analysis It's obvious that $T_n$ is increasing with a greater $n$ , since \begin{align*} T_{n+1}&=\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}+\sqrt{\frac{1}{(n+1)^2}}}}}}\\ &>\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}+0}}}}\\ &=T_n. \end{align*} Moreover, we can prove that $T_n$ is bounded upward, since \begin{align*} T_n&=\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}}}}}\\ &\leq \sqrt{1+\sqrt {1+\sqrt{1+\cdots+\sqrt{1}}}} \\ &\to \frac{\sqrt{5}+1}{2}. \end{align*} Therefore, $T_n$ is convergent as $n \to \infty$ , by the monotonicity convergence theorem. But where does it converge to on earth? Does the limit have a excact value? I have already computed the value using the former $20$ terms by Mathematica, it output:","Problem Evaluate where Analysis It's obvious that is increasing with a greater , since Moreover, we can prove that is bounded upward, since Therefore, is convergent as , by the monotonicity convergence theorem. But where does it converge to on earth? Does the limit have a excact value? I have already computed the value using the former terms by Mathematica, it output:","\lim\limits_{n \to \infty}T_n T_n=\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}}}}}. T_n n \begin{align*}
T_{n+1}&=\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}+\sqrt{\frac{1}{(n+1)^2}}}}}}\\
&>\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}+0}}}}\\
&=T_n.
\end{align*} T_n \begin{align*}
T_n&=\sqrt{1+\sqrt{\frac{1}{2^2}+\sqrt{\frac{1}{3^2}+\cdots+\sqrt{\frac{1}{n^2}}}}}\\
&\leq \sqrt{1+\sqrt {1+\sqrt{1+\cdots+\sqrt{1}}}} \\
&\to \frac{\sqrt{5}+1}{2}.
\end{align*} T_n n \to \infty 20","['limits', 'nested-radicals']"
54,Proving $\lim_{p\to\infty} $ $\left\lVert x \right\rVert_p = \left\lVert x \right\rVert_\infty$,Proving,\lim_{p\to\infty}  \left\lVert x \right\rVert_p = \left\lVert x \right\rVert_\infty,"How can one prove, that $\lim_{p\to\infty} $ $\left\lVert x \right\rVert_P = \left\lVert x \right\rVert_\infty$ applies to all $x \in \mathbb{R^n}$ ? I know that two norms $\left\lVert \cdot \right\rVert_a$ and $\left\lVert \cdot \right\rVert_b$ in $\mathbb{R^n}$ are equivalent, if there are constants $c_1,c_2 > 0 $ so that for all $x \in \mathbb{R^n}$ there is an inequation chain $c_1 \left\lVert x \right\rVert_a \leq \left\lVert x \right\rVert_b \leq c_2 \left\lVert x \right\rVert_a$ I think I have to use the inequation above somehow to prove the former, yet I don't know how","How can one prove, that applies to all ? I know that two norms and in are equivalent, if there are constants so that for all there is an inequation chain I think I have to use the inequation above somehow to prove the former, yet I don't know how","\lim_{p\to\infty}  \left\lVert x \right\rVert_P = \left\lVert x \right\rVert_\infty x \in \mathbb{R^n} \left\lVert \cdot \right\rVert_a \left\lVert \cdot \right\rVert_b \mathbb{R^n} c_1,c_2 > 0  x \in \mathbb{R^n} c_1 \left\lVert x \right\rVert_a \leq \left\lVert x \right\rVert_b \leq c_2 \left\lVert x \right\rVert_a",['limits']
55,"Using $\epsilon$-$\delta$ approach, prove that $\lim_{(x,y)\rightarrow (1,3)}\frac{x}{y}=\frac{1}{3} $","Using - approach, prove that","\epsilon \delta \lim_{(x,y)\rightarrow (1,3)}\frac{x}{y}=\frac{1}{3} ","How to prove that $$ \lim_{(x,y)\rightarrow (1,3)}\frac{x}{y}=\frac{1}{3}$$ By $\epsilon$-$\delta$ definition. What i did is this: Let $\epsilon$ be grater than zero; i need to find a $\delta(\epsilon)>0$ such that $|x/y-1/3|<\epsilon$ whenever $0<\sqrt{(x-1)^2+(y-3)^2}<\delta$. Then, rewriting  $$\bigg|\frac{x}{y}-\frac{1}{3}\bigg|=\bigg|\frac{3x-y}{3y}\bigg|= \bigg|\frac{3x-y+3-3}{3y}\bigg|= \bigg|\frac{3(x-1)+(-y+3)}{3y}\bigg| $$ Now, by triangle inequality $$\bigg|\frac{3(x-1)+(-y+3)}{3y}\bigg|\leq \frac{3|x-1|+|y-3|}{3|y|}$$ since $$|x-1|<\sqrt{(x-1)^2+(y-3)^2}<\delta \text{ and } |y-3|<\sqrt{(x-1)^2+(y-3)^2}<\delta$$ then $$\frac{3|x-1|+|y-3|}{3|y|}<\frac{3\delta+\delta}{3|y|}=\frac{4\delta}{3|y|}$$ But i have that $|y-3|<\sqrt{(x-1)^2+(y-3)^2}<\delta$, then $y\in (3-\delta,\delta+3)$. So i think the next step is to take $\delta =1/3$; if i do that i get $8/3<y$ that is $1/|y|<3/8$  then  $$\frac{4\delta}{3|y|}<\frac{3}{8}\frac{4\delta}{3}=\frac{\delta}{2}.$$ So, taking $\delta=\min\{1/3, 2\epsilon\}$, we have $$\bigg|\frac{x}{y}-\frac{1}{3} \bigg|< \frac{3}{8}\frac{4\delta}{3} = \frac{\delta}{2}= \frac{1}{2}2\epsilon = \epsilon. $$ is this reasoning right?","How to prove that $$ \lim_{(x,y)\rightarrow (1,3)}\frac{x}{y}=\frac{1}{3}$$ By $\epsilon$-$\delta$ definition. What i did is this: Let $\epsilon$ be grater than zero; i need to find a $\delta(\epsilon)>0$ such that $|x/y-1/3|<\epsilon$ whenever $0<\sqrt{(x-1)^2+(y-3)^2}<\delta$. Then, rewriting  $$\bigg|\frac{x}{y}-\frac{1}{3}\bigg|=\bigg|\frac{3x-y}{3y}\bigg|= \bigg|\frac{3x-y+3-3}{3y}\bigg|= \bigg|\frac{3(x-1)+(-y+3)}{3y}\bigg| $$ Now, by triangle inequality $$\bigg|\frac{3(x-1)+(-y+3)}{3y}\bigg|\leq \frac{3|x-1|+|y-3|}{3|y|}$$ since $$|x-1|<\sqrt{(x-1)^2+(y-3)^2}<\delta \text{ and } |y-3|<\sqrt{(x-1)^2+(y-3)^2}<\delta$$ then $$\frac{3|x-1|+|y-3|}{3|y|}<\frac{3\delta+\delta}{3|y|}=\frac{4\delta}{3|y|}$$ But i have that $|y-3|<\sqrt{(x-1)^2+(y-3)^2}<\delta$, then $y\in (3-\delta,\delta+3)$. So i think the next step is to take $\delta =1/3$; if i do that i get $8/3<y$ that is $1/|y|<3/8$  then  $$\frac{4\delta}{3|y|}<\frac{3}{8}\frac{4\delta}{3}=\frac{\delta}{2}.$$ So, taking $\delta=\min\{1/3, 2\epsilon\}$, we have $$\bigg|\frac{x}{y}-\frac{1}{3} \bigg|< \frac{3}{8}\frac{4\delta}{3} = \frac{\delta}{2}= \frac{1}{2}2\epsilon = \epsilon. $$ is this reasoning right?",,"['limits', 'multivariable-calculus', 'epsilon-delta']"
56,For what values of $a$ the number $1/a$ has a finite decimal representation?,For what values of  the number  has a finite decimal representation?,a 1/a,"I think is just for $a=2^p5^q$, with $p,q\geq 0 $ but I haven't a proof.  In particular, the exercise says: ""Let $N$ be a natural number and $S_N=\{a\in \mathbb{N} \; :\; 1\leq a \leq N \; , \; 1/a\; \text{has a finite decimal representation}\}$. Compute  $\displaystyle\lim_{N\to \infty} \frac{\vert S_N \vert}{\log^2N}$, where $\vert \cdot \vert$ is the cardinal number of a set. If is true that $1/a$ has a finite decimal representation iff $a=2^p 5^q $, then $2^p \leq N \leftrightarrow p\leq \frac{\log N} {\log 2}$ and $5^q \leq N \leftrightarrow q\leq \frac{\log N} {\log 5}$ and maybe for $N$ big $\vert S_N \vert \sim \frac{\log^2 N}{\log 5 \log 2 }$?","I think is just for $a=2^p5^q$, with $p,q\geq 0 $ but I haven't a proof.  In particular, the exercise says: ""Let $N$ be a natural number and $S_N=\{a\in \mathbb{N} \; :\; 1\leq a \leq N \; , \; 1/a\; \text{has a finite decimal representation}\}$. Compute  $\displaystyle\lim_{N\to \infty} \frac{\vert S_N \vert}{\log^2N}$, where $\vert \cdot \vert$ is the cardinal number of a set. If is true that $1/a$ has a finite decimal representation iff $a=2^p 5^q $, then $2^p \leq N \leftrightarrow p\leq \frac{\log N} {\log 2}$ and $5^q \leq N \leftrightarrow q\leq \frac{\log N} {\log 5}$ and maybe for $N$ big $\vert S_N \vert \sim \frac{\log^2 N}{\log 5 \log 2 }$?",,"['limits', 'fractions']"
57,Delta-epsilon proof of $\lim_{x\rightarrow\infty} \frac{x}{x+1} = 1$,Delta-epsilon proof of,\lim_{x\rightarrow\infty} \frac{x}{x+1} = 1,"I have an exercise where I'm supposed to show, by delta-epsilon proof that $\frac{x}{x+1}$ tends to 1 as $x$ goes to positive infinity. In our faculty and literature, for limits at infinity we usually call $\delta$ small omega ($\omega$) instead. So the definition I use is the following: $$x > \omega \Rightarrow |f(x)-A|\leq\epsilon$$ where $$x > 0,\; \omega(\epsilon),\; \epsilon > 0$$ So pretty standard definition. Now here's my attempted proof of: $$\lim_{x\rightarrow\infty} \frac{x}{x+1} = 1$$ We have $$\left|\frac{x}{x+1}-1\right|\Leftrightarrow \left|-\frac{1}{x+1}\right|$$ Also for positive $x$, $x + 1 > 0$ so: $$\frac{1}{x+1} \leq \epsilon$$ Which (again with assumption $x > 0$) gives: $$\frac{1}{\epsilon} - 1 \leq x$$ so we can use $\omega(\epsilon) = \frac{1}{\epsilon} - 1$ I am struggling somewhat in real analysis at the moment, so I have very low confidence that I'm not missing something important. It would be greatly appreciated if someone could take a look at my proof and give feedback.","I have an exercise where I'm supposed to show, by delta-epsilon proof that $\frac{x}{x+1}$ tends to 1 as $x$ goes to positive infinity. In our faculty and literature, for limits at infinity we usually call $\delta$ small omega ($\omega$) instead. So the definition I use is the following: $$x > \omega \Rightarrow |f(x)-A|\leq\epsilon$$ where $$x > 0,\; \omega(\epsilon),\; \epsilon > 0$$ So pretty standard definition. Now here's my attempted proof of: $$\lim_{x\rightarrow\infty} \frac{x}{x+1} = 1$$ We have $$\left|\frac{x}{x+1}-1\right|\Leftrightarrow \left|-\frac{1}{x+1}\right|$$ Also for positive $x$, $x + 1 > 0$ so: $$\frac{1}{x+1} \leq \epsilon$$ Which (again with assumption $x > 0$) gives: $$\frac{1}{\epsilon} - 1 \leq x$$ so we can use $\omega(\epsilon) = \frac{1}{\epsilon} - 1$ I am struggling somewhat in real analysis at the moment, so I have very low confidence that I'm not missing something important. It would be greatly appreciated if someone could take a look at my proof and give feedback.",,"['limits', 'epsilon-delta']"
58,"Rationalized limit denominator, still undefined (divide by zero), how to solve?","Rationalized limit denominator, still undefined (divide by zero), how to solve?",,"I am trying to solve: $$\lim_{x \to 2}\frac{\sqrt{x+2} - \sqrt{3x-2}}{\sqrt{4x+1} - \sqrt{5x-1}}$$ My first step is to multiply by the conjugate to rationalize the denominator. $$\lim_{x \to 2}\frac{\sqrt{x+2} - \sqrt{3x-2}}{\sqrt{4x+1} - \sqrt{5x-1}} \cdot \frac{\sqrt{4x+1} + \sqrt{5x-1}}{\sqrt{4x+1} + \sqrt{5x-1}}$$ Which gives $$\lim_{x \to 2}\frac {(\sqrt{x+2} - \sqrt{3x-2}) \cdot (\sqrt{4x+1} + \sqrt{5x-1})} {({4x+1}) - ({5x-1})} $$ Simplifying denominator $$\lim_{x \to 2}\frac {(\sqrt{x+2} - \sqrt{3x-2}) \cdot (\sqrt{4x+1} + \sqrt{5x-1})} {2-x} $$ Substituting $2$ for $x$ in the denominator and it's zero $$\lim_{x \to 2}\frac {(\sqrt{x+2} - \sqrt{3x-2}) \cdot (\sqrt{4x+1} + \sqrt{5x-1})} {2-2} $$ Did I make a calculation error, if so where, and / or did I use the wrong approach, if so what's a working approach?","I am trying to solve: $$\lim_{x \to 2}\frac{\sqrt{x+2} - \sqrt{3x-2}}{\sqrt{4x+1} - \sqrt{5x-1}}$$ My first step is to multiply by the conjugate to rationalize the denominator. $$\lim_{x \to 2}\frac{\sqrt{x+2} - \sqrt{3x-2}}{\sqrt{4x+1} - \sqrt{5x-1}} \cdot \frac{\sqrt{4x+1} + \sqrt{5x-1}}{\sqrt{4x+1} + \sqrt{5x-1}}$$ Which gives $$\lim_{x \to 2}\frac {(\sqrt{x+2} - \sqrt{3x-2}) \cdot (\sqrt{4x+1} + \sqrt{5x-1})} {({4x+1}) - ({5x-1})} $$ Simplifying denominator $$\lim_{x \to 2}\frac {(\sqrt{x+2} - \sqrt{3x-2}) \cdot (\sqrt{4x+1} + \sqrt{5x-1})} {2-x} $$ Substituting $2$ for $x$ in the denominator and it's zero $$\lim_{x \to 2}\frac {(\sqrt{x+2} - \sqrt{3x-2}) \cdot (\sqrt{4x+1} + \sqrt{5x-1})} {2-2} $$ Did I make a calculation error, if so where, and / or did I use the wrong approach, if so what's a working approach?",,"['limits', 'radicals']"
59,Is this correct and sufficient to show limit does not exist?,Is this correct and sufficient to show limit does not exist?,,"Find limit or show that it does not exist: $$\lim_{(x,y) \to (0,0)} \frac{ 2x^{2}y^{3/2} }{y^{2}+x^{8}}$$ using the path  $x=m y^{1/4}$: $$\lim_{(my^{1/4},y) \to (0,0)} \frac{ 2m^{2}y^{1/2}y^{3/2}}{y^{2}+m^{8}y^{2}}$$ $$\lim_{(my^{1/4},y) \to (0,0)} \frac{ 2m^{2}y^{2}}{y^{2}(1+m^{8})}$$ $$\lim_{(my^{1/4},y) \to (0,0)} \frac{ 2m^{2}}{1+m^{8}}$$ Does not exist, because limit is path dependent. I am asking because I have a test in a couple days.  I want to make sure I'm not committing some mortal math sin. Also, the Latex tutorial is great, I think I just wasted 20 minutes making that mess.","Find limit or show that it does not exist: $$\lim_{(x,y) \to (0,0)} \frac{ 2x^{2}y^{3/2} }{y^{2}+x^{8}}$$ using the path  $x=m y^{1/4}$: $$\lim_{(my^{1/4},y) \to (0,0)} \frac{ 2m^{2}y^{1/2}y^{3/2}}{y^{2}+m^{8}y^{2}}$$ $$\lim_{(my^{1/4},y) \to (0,0)} \frac{ 2m^{2}y^{2}}{y^{2}(1+m^{8})}$$ $$\lim_{(my^{1/4},y) \to (0,0)} \frac{ 2m^{2}}{1+m^{8}}$$ Does not exist, because limit is path dependent. I am asking because I have a test in a couple days.  I want to make sure I'm not committing some mortal math sin. Also, the Latex tutorial is great, I think I just wasted 20 minutes making that mess.",,"['limits', 'multivariable-calculus']"
60,How prove this $\lim_{x\to+\infty}(f'(x)+f(x))=l$,How prove this,\lim_{x\to+\infty}(f'(x)+f(x))=l,"let $f(x)$ is continous and $f'(x)$ is continous  on $[0,\infty)$,show that $$\lim_{x\to+\infty}(f'(x)+f(x))=l$$   if and only if: $\displaystyle\lim_{x\to+\infty}f(x)=l$ and $f'(x)$ is uniformly continuous on $[0,+\infty)$. How prove this it? Thank you. I can prove this if $$\lim_{x\to+\infty}(f'(x)+f(x))=l$$   then we have  $\displaystyle\lim_{x\to+\infty}f(x)=l$ My Part of the Solution : without loss of we let $l=0$,Give $\epsilon>0$,let $a>0$ be such that $|f(x)+f'(x)|<\epsilon$ for $x\ge a$ Then by the generalized mean value theorem there is $\xi\in (a,x)$ such that $$\dfrac{e^x f(x)-e^af(a)}{e^x-e^a}=f(\xi)+f'(\xi)$$ Thus $$|f(x)-f(a)e^{a-x}|<\epsilon|1-e^{a-x}|$$ so $$|f(x)|<|f(a)|e^{a-x}+\epsilon|1-e^{a-x}|$$ so $$|f(x)|<2\epsilon$$ for sufficiently large $x$. But How can prove $f'(x)$ is uniformly continuous on $[0,+\infty)$ and other question: How prove if$\displaystyle\lim_{x\to+\infty}f(x)=l$ and $f'(x)$ is uniformly continuous on $[0,+\infty)$ then we have $$\lim_{x\to+\infty}(f'(x)+f(x))=l$$","let $f(x)$ is continous and $f'(x)$ is continous  on $[0,\infty)$,show that $$\lim_{x\to+\infty}(f'(x)+f(x))=l$$   if and only if: $\displaystyle\lim_{x\to+\infty}f(x)=l$ and $f'(x)$ is uniformly continuous on $[0,+\infty)$. How prove this it? Thank you. I can prove this if $$\lim_{x\to+\infty}(f'(x)+f(x))=l$$   then we have  $\displaystyle\lim_{x\to+\infty}f(x)=l$ My Part of the Solution : without loss of we let $l=0$,Give $\epsilon>0$,let $a>0$ be such that $|f(x)+f'(x)|<\epsilon$ for $x\ge a$ Then by the generalized mean value theorem there is $\xi\in (a,x)$ such that $$\dfrac{e^x f(x)-e^af(a)}{e^x-e^a}=f(\xi)+f'(\xi)$$ Thus $$|f(x)-f(a)e^{a-x}|<\epsilon|1-e^{a-x}|$$ so $$|f(x)|<|f(a)|e^{a-x}+\epsilon|1-e^{a-x}|$$ so $$|f(x)|<2\epsilon$$ for sufficiently large $x$. But How can prove $f'(x)$ is uniformly continuous on $[0,+\infty)$ and other question: How prove if$\displaystyle\lim_{x\to+\infty}f(x)=l$ and $f'(x)$ is uniformly continuous on $[0,+\infty)$ then we have $$\lim_{x\to+\infty}(f'(x)+f(x))=l$$",,['analysis']
61,High school contest question,High school contest question,,Some work on it reveals the possibility of using gamma function. Is there any easy way to compute it? $$\lim_{n\to\infty}\left(\frac{1}{n!} \int_0^e \log^n x \ dx\right)^n$$,Some work on it reveals the possibility of using gamma function. Is there any easy way to compute it? $$\lim_{n\to\infty}\left(\frac{1}{n!} \int_0^e \log^n x \ dx\right)^n$$,,"['limits', 'contest-math']"
62,"Prove that if $\lim_{x\to \infty} f'(x) = 0$, then $\lim_{x\to \infty} f(x+1)-f(x) = 0$","Prove that if , then",\lim_{x\to \infty} f'(x) = 0 \lim_{x\to \infty} f(x+1)-f(x) = 0,"I'm working on this proof and I think I have a sketch but I'm not sure it's rigorous enough. Suppose $f:\Bbb R \to \Bbb R$ is differentiable and that $$\lim_{x\to \infty} f'(x) = 0$$ Prove that $$\lim_{x\to \infty} f(x+1)-f(x) = 0$$ Proof: We want to prove that for any $\epsilon > 0$ , there is an $x_0$ such that $|f(x+1)-f(x)|< \epsilon$ for all $x \ge x_0$ . By the Mean Value Theorem, there is some $c \in (x, x+1)$ such  that $f(x+1) - f(x) = f'(c)$ . By the convergence of $f'(x)$ , there is some $y_0$ such that $|f'(x)| < \epsilon$ for all $x \ge y_0$ . Thus $$x \ge y_0 \implies c>y_0 \implies |f'(c)| = |f(x+1) - f(x)| < \epsilon$$ and $x_0 = y_0$ . $\square$ Thanks!","I'm working on this proof and I think I have a sketch but I'm not sure it's rigorous enough. Suppose is differentiable and that Prove that Proof: We want to prove that for any , there is an such that for all . By the Mean Value Theorem, there is some such  that . By the convergence of , there is some such that for all . Thus and . Thanks!","f:\Bbb R \to \Bbb R \lim_{x\to \infty} f'(x) = 0 \lim_{x\to \infty} f(x+1)-f(x) = 0 \epsilon > 0 x_0 |f(x+1)-f(x)|< \epsilon x \ge x_0 c \in (x, x+1) f(x+1) - f(x) = f'(c) f'(x) y_0 |f'(x)| < \epsilon x \ge y_0 x \ge y_0 \implies c>y_0 \implies |f'(c)| = |f(x+1) - f(x)| < \epsilon x_0 = y_0 \square","['limits', 'solution-verification', 'proof-writing']"
63,Does the mean ratio of the bases of the largest prime factor exponents converge?,Does the mean ratio of the bases of the largest prime factor exponents converge?,,"Let $n = p_1^{a_1} p_2^{a_2} \cdots p_k^{a_k}$ and $H_n = \max(a_1, a_2, \ldots, a_k)$ be the largest exponent in the prime factorization of $n$ . It is possible that two or more prime factors can both be the bases of the largest exponent $H_n$ . Let $b_n$ and $B_n$ be the smallest and the largest prime factor of $n$ respectively for which the exponent is $H_n$ . Clearly, if there is only one distinct prime which have the largest exponent then $b_n = B_n$ otherwise $b_n < B_n$ . Example : If $n = 2^3 5^2$ then $b_n = B_n = 2$ and if $n = 2^2 3^2 5$ then $b_n = 2$ while $B_n = 3$ . Experimental data shows that the mean value of the ratios $\frac{b_n}{B_n}$ converges to some value close to $0.36$ . Conjecture : There is a constant $c \approx 0.36$ such that, $$ \lim_{n \to \infty} \frac{1}{n}\sum_{k = 1}^n \frac{b_k}{B_k} = c $$ Can this be proved or disproved?","Let and be the largest exponent in the prime factorization of . It is possible that two or more prime factors can both be the bases of the largest exponent . Let and be the smallest and the largest prime factor of respectively for which the exponent is . Clearly, if there is only one distinct prime which have the largest exponent then otherwise . Example : If then and if then while . Experimental data shows that the mean value of the ratios converges to some value close to . Conjecture : There is a constant such that, Can this be proved or disproved?","n = p_1^{a_1} p_2^{a_2} \cdots p_k^{a_k} H_n = \max(a_1, a_2, \ldots, a_k) n H_n b_n B_n n H_n b_n = B_n b_n < B_n n = 2^3 5^2 b_n = B_n = 2 n = 2^2 3^2 5 b_n = 2 B_n = 3 \frac{b_n}{B_n} 0.36 c \approx 0.36  \lim_{n \to \infty} \frac{1}{n}\sum_{k = 1}^n \frac{b_k}{B_k} = c ","['limits', 'number-theory', 'elementary-number-theory', 'prime-numbers', 'divisibility']"
64,Limiting behavior of $x + \sqrt{x} - \sqrt{x + \sqrt{x}}$,Limiting behavior of,x + \sqrt{x} - \sqrt{x + \sqrt{x}},"As $x$ and $y$ vary through the real numbers, how do the interval families $\left[ x, x + \sqrt{x} \right]$ and $\left[ y - \sqrt{y}, y \right]$ differ? Not by much, it turns out: consider the two maps: $f : x \mapsto x + \sqrt{x}$ , $g : y \mapsto y - \sqrt y$ . The composition $g \circ f$ rapidly converges to the the identity minus a constant: $$\lim_{x \rightarrow \infty} x - (g \circ f)(x) = \lim_{x \rightarrow \infty} x - \left( (x + \sqrt{x}) - \sqrt{x + \sqrt x)} \right) = 0.5.$$ Yet this fact is false for any exponent greater than 0.5. Indeed, for any fixed $\varepsilon > 0$ : $$\lim_{x \rightarrow \infty} = x - \left( (x + x^{0.5 + \varepsilon}) - (x + x^{0.5 + \varepsilon})^{0.5 + \varepsilon} \right) = \infty.$$ How can I understand this sudden change in behavior??? EDIT : another unusual observation. what if we add ceiling functions to both, so that $\hat{f} : \lceil x \mapsto x + \sqrt{x} \rceil $ , $\lceil g : y \mapsto y - \sqrt y \rceil$ . Then $g \circ f$ appears to oscillate between $-1$ and 0, though possibly converges to 0. I'd like to prove or disprove: does it always take the values either $-1$ or $0$ ? Is it ""eventually"" 0? Thanks.","As and vary through the real numbers, how do the interval families and differ? Not by much, it turns out: consider the two maps: , . The composition rapidly converges to the the identity minus a constant: Yet this fact is false for any exponent greater than 0.5. Indeed, for any fixed : How can I understand this sudden change in behavior??? EDIT : another unusual observation. what if we add ceiling functions to both, so that , . Then appears to oscillate between and 0, though possibly converges to 0. I'd like to prove or disprove: does it always take the values either or ? Is it ""eventually"" 0? Thanks.","x y \left[ x, x + \sqrt{x} \right] \left[ y - \sqrt{y}, y \right] f : x \mapsto x + \sqrt{x} g : y \mapsto y - \sqrt y g \circ f \lim_{x \rightarrow \infty} x - (g \circ f)(x) = \lim_{x \rightarrow \infty} x - \left( (x + \sqrt{x}) - \sqrt{x + \sqrt x)} \right) = 0.5. \varepsilon > 0 \lim_{x \rightarrow \infty} = x - \left( (x + x^{0.5 + \varepsilon}) - (x + x^{0.5 + \varepsilon})^{0.5 + \varepsilon} \right) = \infty. \hat{f} : \lceil x \mapsto x + \sqrt{x} \rceil  \lceil g : y \mapsto y - \sqrt y \rceil g \circ f -1 -1 0","['limits', 'radicals']"
65,Decide whether a sequence converges or not,Decide whether a sequence converges or not,,"There is a sequence $(a_{n})_n$ defined by relation: $a_{1} = 3 $ $2^{a_2} = 3^3$ $2^{2^{a_{3}}} = 3^{3^{3}}$ $2^{2^{2^{a_{4}}}} = 3^{3^{3^3}}$ Does $(a_{n})_n$ converge? So, I've tried to figure out what is an overall pattern for $(a_{n})_n$ . I did something like that: $a_1 = 3$ $2^{a_2} = 3^3$ $\log2^{a_2} = \log3^3$ $a_{2}\log2 = 3\log3$ $a_{2} = 3\frac{\log3}{\log2}$ But I don't know if it gets me anywhere, because I got $a_3 = \log(\frac{27}{2}\frac{\log3}{\log2})$ Have you got any idea?","There is a sequence defined by relation: Does converge? So, I've tried to figure out what is an overall pattern for . I did something like that: But I don't know if it gets me anywhere, because I got Have you got any idea?",(a_{n})_n a_{1} = 3  2^{a_2} = 3^3 2^{2^{a_{3}}} = 3^{3^{3}} 2^{2^{2^{a_{4}}}} = 3^{3^{3^3}} (a_{n})_n (a_{n})_n a_1 = 3 2^{a_2} = 3^3 \log2^{a_2} = \log3^3 a_{2}\log2 = 3\log3 a_{2} = 3\frac{\log3}{\log2} a_3 = \log(\frac{27}{2}\frac{\log3}{\log2}),"['limits', 'convergence-divergence']"
66,limit with nested power of $x$,limit with nested power of,x,"Evaluation of $$\lim_{x\rightarrow 1}\frac{x^{x^{x^{x^{x^{x}}}}}-x^{x^{x^{x^x}}}}{(x-1)^6}$$ Try:: I try to solve it using Binomial Index for fraction $\displaystyle x^x=\bigg[1+(x-1)\bigg]^x=1+x(x-1)+\frac{x(x-1)^2}{2}+\cdots $ Did not know how can i solve it, Could some help me , thanks","Evaluation of Try:: I try to solve it using Binomial Index for fraction Did not know how can i solve it, Could some help me , thanks",\lim_{x\rightarrow 1}\frac{x^{x^{x^{x^{x^{x}}}}}-x^{x^{x^{x^x}}}}{(x-1)^6} \displaystyle x^x=\bigg[1+(x-1)\bigg]^x=1+x(x-1)+\frac{x(x-1)^2}{2}+\cdots ,['limits']
67,Multivariable $\epsilon-\delta$ proof verification,Multivariable  proof verification,\epsilon-\delta,"Prove that $\lim\limits_{(x,y) \to (1,1)} xy=1$ Of course, I am aware that this is ""obvious"", but I want to add some rigor to it. When I searched around for multivariable limits using $\epsilon-\delta$, most of the examples had $(x,y) \rightarrow (0,0)$, but in this case I have $x$ and $y$ approaching something else. $(x,y) \rightarrow (1,1) \Leftrightarrow \lvert\lvert (x,y)-(1,1)\lvert\lvert \rightarrow 0$ which can be written as $0 < \sqrt {(x-1)^2+(y-1)^2} < \delta$ for some arbitrarily small $\delta >0$. Goal: show that $\forall$ $\epsilon>0$ $\exists$ $\delta>0$ such that $0 < \sqrt {(x-1)^2+(y-1)^2}<\delta\Rightarrow0<|xy-1|<\epsilon$ Proof: If $0 < \sqrt {(x-1)^2+(y-1)^2}<\delta$, then $|xy-1|=|xy-x-y+1+x+y-2|=|(x-1)(y-1)+(x-1)+(y-1)|$ $\le|(x-1)(y-1)|+|x-1| +|y-1|=|x-1||y-1|+|x-1|+|y-1|$ $=(\sqrt{(x-1)^2})(\sqrt{(y-1)^2})+\sqrt{(x-1)^2}+\sqrt{(y-1)^2}$ $\le(\sqrt{(x-1)^2+(y-1)^2})^2+2\sqrt{(x-1)^2+(y-1)^2}<\delta^2+2\delta$ If $\delta=$$\epsilon \over4$, then $\delta^2+2\delta=\frac{\epsilon^2}{16}+\frac{8\epsilon}{16}=\frac{\epsilon^2+8\epsilon}{16}$ Now, $\frac{\epsilon^2+8\epsilon}{16}<\epsilon \Leftrightarrow \epsilon^2+8\epsilon<16\epsilon\Leftrightarrow\epsilon(\epsilon-8)<0$ Since $\epsilon>0$, we have $\epsilon(\epsilon-8)<0$ if and only if $\epsilon<8$ So if we have $\epsilon<8$, then we can pick $\delta=\frac{\epsilon}{4}$ which gives us $\delta^2+2\delta<\epsilon$. If $\epsilon \ge8$, then we can pick $\delta=2$ which gives us $\delta^2+2\delta\le\epsilon$. Therefore, if we pick $\delta =$ min {${\frac{\epsilon}{4}, 2}$}, then $0 < \sqrt {(x-1)^2+(y-1)^2}<\delta$ implies $0<|xy-1|<\epsilon$ Thus, $\lim\limits_{(x,y) \to (1,1)} xy=1$","Prove that $\lim\limits_{(x,y) \to (1,1)} xy=1$ Of course, I am aware that this is ""obvious"", but I want to add some rigor to it. When I searched around for multivariable limits using $\epsilon-\delta$, most of the examples had $(x,y) \rightarrow (0,0)$, but in this case I have $x$ and $y$ approaching something else. $(x,y) \rightarrow (1,1) \Leftrightarrow \lvert\lvert (x,y)-(1,1)\lvert\lvert \rightarrow 0$ which can be written as $0 < \sqrt {(x-1)^2+(y-1)^2} < \delta$ for some arbitrarily small $\delta >0$. Goal: show that $\forall$ $\epsilon>0$ $\exists$ $\delta>0$ such that $0 < \sqrt {(x-1)^2+(y-1)^2}<\delta\Rightarrow0<|xy-1|<\epsilon$ Proof: If $0 < \sqrt {(x-1)^2+(y-1)^2}<\delta$, then $|xy-1|=|xy-x-y+1+x+y-2|=|(x-1)(y-1)+(x-1)+(y-1)|$ $\le|(x-1)(y-1)|+|x-1| +|y-1|=|x-1||y-1|+|x-1|+|y-1|$ $=(\sqrt{(x-1)^2})(\sqrt{(y-1)^2})+\sqrt{(x-1)^2}+\sqrt{(y-1)^2}$ $\le(\sqrt{(x-1)^2+(y-1)^2})^2+2\sqrt{(x-1)^2+(y-1)^2}<\delta^2+2\delta$ If $\delta=$$\epsilon \over4$, then $\delta^2+2\delta=\frac{\epsilon^2}{16}+\frac{8\epsilon}{16}=\frac{\epsilon^2+8\epsilon}{16}$ Now, $\frac{\epsilon^2+8\epsilon}{16}<\epsilon \Leftrightarrow \epsilon^2+8\epsilon<16\epsilon\Leftrightarrow\epsilon(\epsilon-8)<0$ Since $\epsilon>0$, we have $\epsilon(\epsilon-8)<0$ if and only if $\epsilon<8$ So if we have $\epsilon<8$, then we can pick $\delta=\frac{\epsilon}{4}$ which gives us $\delta^2+2\delta<\epsilon$. If $\epsilon \ge8$, then we can pick $\delta=2$ which gives us $\delta^2+2\delta\le\epsilon$. Therefore, if we pick $\delta =$ min {${\frac{\epsilon}{4}, 2}$}, then $0 < \sqrt {(x-1)^2+(y-1)^2}<\delta$ implies $0<|xy-1|<\epsilon$ Thus, $\lim\limits_{(x,y) \to (1,1)} xy=1$",,"['limits', 'multivariable-calculus', 'proof-verification', 'epsilon-delta']"
68,What is known of $\sum_{n=1}^{\infty}x^n/n^n$?,What is known of ?,\sum_{n=1}^{\infty}x^n/n^n,"What is $$\lim_{x\rightarrow\,-\infty}\sum_{n=1}^{\infty}\frac{x^n}{n^n}$$? What is known about specific values of this function at say $-2,-1,0,1,2,3$?","What is $$\lim_{x\rightarrow\,-\infty}\sum_{n=1}^{\infty}\frac{x^n}{n^n}$$? What is known about specific values of this function at say $-2,-1,0,1,2,3$?",,"['limits', 'functions']"
69,Show that if $f$ increases nicely and $x > 1$ then $\lim_{n \to \infty}\frac{f(n)}{x^n}\sum_{k=1}^n \frac{x^k}{f(k)} = \frac{x}{1-x}$,Show that if  increases nicely and  then,f x > 1 \lim_{n \to \infty}\frac{f(n)}{x^n}\sum_{k=1}^n \frac{x^k}{f(k)} = \frac{x}{1-x},"More precisely, suppose $f(k)$ is increasing, differentiable, $f(1) \ge 1$, and $f'(n)/f(n) \le d/n$ for some $d>0$. Then, for any $x > 1$, as $n \to \infty$, $$\dfrac{f(n)}{x^n}\sum_{k=1}^n \dfrac{x^k}{f(k)} \to \dfrac{x}{x-1}. $$ This is the most reasonable generalization I could find of my answer to Computing $\lim_n \frac{n}{2^n}\sum_{k=1}^n \frac{2^k}{k}$ . That question is the case $x=2, f(n) = n$. I have what I think is a proof, which uses the same technique as my answer referenced above. But it a little messy, and my hope is that someone can come up with a nicer proof. I will post my proof in a few days if no answer is given.","More precisely, suppose $f(k)$ is increasing, differentiable, $f(1) \ge 1$, and $f'(n)/f(n) \le d/n$ for some $d>0$. Then, for any $x > 1$, as $n \to \infty$, $$\dfrac{f(n)}{x^n}\sum_{k=1}^n \dfrac{x^k}{f(k)} \to \dfrac{x}{x-1}. $$ This is the most reasonable generalization I could find of my answer to Computing $\lim_n \frac{n}{2^n}\sum_{k=1}^n \frac{2^k}{k}$ . That question is the case $x=2, f(n) = n$. I have what I think is a proof, which uses the same technique as my answer referenced above. But it a little messy, and my hope is that someone can come up with a nicer proof. I will post my proof in a few days if no answer is given.",,"['limits', 'summation']"
70,"Is this proof of limit of $f(x,y)$ correct?",Is this proof of limit of  correct?,"f(x,y)","The limit is this: $$\lim\limits_{(x,y)\to(0,0)}\dfrac{\log\left(\dfrac{1}{\sqrt{x^2+y^2}}\right)}{\dfrac{1}{\sqrt{x^2+y^2}}}.$$ I think I did the proof well. Using that $\lim\limits_{z\to\infty}\dfrac{\log(z)}{z}=0$ $,\lim\limits_{t\to 0^+}\dfrac{1}{t}=\infty$ $,\lim\limits_{(x,y)\to(0,0)}\sqrt{x^2+y^2}=0,$ $ \sqrt{x^2+y^2}>0 \space$ and the characterization of limits with sequences, we obtain that $\lim\limits_{(x,y)\to(0,0)}\dfrac{\log\left(\dfrac{1}{\sqrt{x^2+y^2}}\right)}{\dfrac{1}{\sqrt{x^2+y^2}}}=0$.","The limit is this: $$\lim\limits_{(x,y)\to(0,0)}\dfrac{\log\left(\dfrac{1}{\sqrt{x^2+y^2}}\right)}{\dfrac{1}{\sqrt{x^2+y^2}}}.$$ I think I did the proof well. Using that $\lim\limits_{z\to\infty}\dfrac{\log(z)}{z}=0$ $,\lim\limits_{t\to 0^+}\dfrac{1}{t}=\infty$ $,\lim\limits_{(x,y)\to(0,0)}\sqrt{x^2+y^2}=0,$ $ \sqrt{x^2+y^2}>0 \space$ and the characterization of limits with sequences, we obtain that $\lim\limits_{(x,y)\to(0,0)}\dfrac{\log\left(\dfrac{1}{\sqrt{x^2+y^2}}\right)}{\dfrac{1}{\sqrt{x^2+y^2}}}=0$.",,"['limits', 'multivariable-calculus', 'limits-without-lhopital']"
71,A question on limit,A question on limit,,"Suppose that $p_k>0, k=1,2,\dots, $ and  $$ \lim_{n\to\infty} \frac{p_{n}}{p_1+p_2+\dots+p_n}=0,\quad \lim_{n\to\infty} a_n=a. $$ Show that  $$ \lim_{n\to\infty}\frac{p_1a_n+p_2a_{n-1}+\dots+p_na_1}{p_1+p_2+\dots+p_n}=a $$ The hints are much appreciated. I don't want complete proof. Thanks for your help.","Suppose that $p_k>0, k=1,2,\dots, $ and  $$ \lim_{n\to\infty} \frac{p_{n}}{p_1+p_2+\dots+p_n}=0,\quad \lim_{n\to\infty} a_n=a. $$ Show that  $$ \lim_{n\to\infty}\frac{p_1a_n+p_2a_{n-1}+\dots+p_na_1}{p_1+p_2+\dots+p_n}=a $$ The hints are much appreciated. I don't want complete proof. Thanks for your help.",,['limits']
72,"Why doesn't $ \lim_{(x,y)\rightarrow(0,0)} xy\sin(\frac{1}{xy}) $ exist?",Why doesn't  exist?," \lim_{(x,y)\rightarrow(0,0)} xy\sin(\frac{1}{xy}) ","I've tried to get the following limit: $$ \lim_{(x,y)\rightarrow(0,0)} xy\sin\left(\frac{1}{xy}\right) $$ wolfram claims it doesn't exist. How to show that? Why can't I take $z=xy$ and receive a known limit of one variable? $$ \lim_{z\rightarrow0} z \sin\left(\frac{1}{z}\right) $$","I've tried to get the following limit: $$ \lim_{(x,y)\rightarrow(0,0)} xy\sin\left(\frac{1}{xy}\right) $$ wolfram claims it doesn't exist. How to show that? Why can't I take $z=xy$ and receive a known limit of one variable? $$ \lim_{z\rightarrow0} z \sin\left(\frac{1}{z}\right) $$",,"['limits', 'multivariable-calculus', 'wolfram-alpha']"
73,Proof of Theorem 1.1 of Analytic Number Theory by Iwaniec & Kowalski,Proof of Theorem 1.1 of Analytic Number Theory by Iwaniec & Kowalski,,"I am not clear about the proof of Theorem 1.1 in the book `Analytic Number Theory' by the authors Iwaniec & Kowalski. They say that if a multiplicative function $f$ satisfies $$\sum_{n\le x}\Lambda_f(x) = \kappa\log x+O(1)$$ where $\Lambda_f(n)$ is given by corresponding Dirichlet series $-D'_f(s)/D_f(s)$ , $\kappa>-1/2$ is a constant, with $$\sum_{n\le x}|f(n)|\ll(\log x)^{|\kappa|},$$ then the Euler product $$\frac{D_f(s)}{\zeta(s+1)^{\kappa}} = \prod_{p}\left(1-\frac{1}{p^{s+1}}\right)^\kappa\left(1+\frac{f(p)}{p^s}+\frac{f(p^2)}{p^{2s}}+\cdots\right)$$ has limit $$\prod_{p}\left(1-\frac{1}{p}\right)^\kappa\left(1+f(p)+f(p^2)+\cdots\right)$$ as $s\to 0+$ , without further explanation (it is previously known that the function $D_f(s)/\zeta(s+1)^\kappa$ tends to a limit as $s\to 0+$ ). But I cannot see why. Below is my trial. (1) By means of Abel summation, it is known that if a Dirichlet series $D_g(s)$ converges at $s=s_0$ , then it is uniformly convergent in the sector $\{s\in\mathbb{C}|\textrm{Arg}(s-s_0)<\theta\lor s=s_0\}$ for a fixed $\theta\in(0,\pi/2)$ . Hence if we can show that the given Euler product converges absolutely(in the sense that we take absolute value for inner series, too), then we can write it as a corresponding Dirichlet series, and hence use continuity of the Euler product to conclude. But I couldn't show that the product converges at $s=0$ . I don't even know the series $1+f(p)+f(p^2)+\cdots$ converges or not. (2) I took logarithmic derivative of the quotient and see if the corresponding Dirichlet series converges (although it may not have direct relation...). Then we have $$-\frac{D'_f}{D_f}(s)+\kappa\frac{\zeta'}{\zeta}(s+1) = \sum_{n=1}^{\infty}\frac{\Lambda_f(n)-\Lambda(n)/n}{n^s},$$ where the coefficient has partial sum of growth $O(1)$ by the first condition (and by Mertens theorem $\sum_{n\le x}\Lambda(n)/n = \log x+O(1)$ ). This does not help too, since it only says that the series converges for $\Re s>0$ . Or by Abel summation this says that the LHS above is bounded near $s=0$ , but this is not enough as we don't have any information about possible continuation of $D_f(s)$ beyond the half-plane $\Re s>0$ . I am aware of the duplicate Question about a proof in Iwaniec-Kowalski's Analytic Number Theory book , but this does not answer my question, and it's too old post, so I cannot expect further answer even if I have written a comment. If you want, I can list my doubts on the answer above.","I am not clear about the proof of Theorem 1.1 in the book `Analytic Number Theory' by the authors Iwaniec & Kowalski. They say that if a multiplicative function satisfies where is given by corresponding Dirichlet series , is a constant, with then the Euler product has limit as , without further explanation (it is previously known that the function tends to a limit as ). But I cannot see why. Below is my trial. (1) By means of Abel summation, it is known that if a Dirichlet series converges at , then it is uniformly convergent in the sector for a fixed . Hence if we can show that the given Euler product converges absolutely(in the sense that we take absolute value for inner series, too), then we can write it as a corresponding Dirichlet series, and hence use continuity of the Euler product to conclude. But I couldn't show that the product converges at . I don't even know the series converges or not. (2) I took logarithmic derivative of the quotient and see if the corresponding Dirichlet series converges (although it may not have direct relation...). Then we have where the coefficient has partial sum of growth by the first condition (and by Mertens theorem ). This does not help too, since it only says that the series converges for . Or by Abel summation this says that the LHS above is bounded near , but this is not enough as we don't have any information about possible continuation of beyond the half-plane . I am aware of the duplicate Question about a proof in Iwaniec-Kowalski's Analytic Number Theory book , but this does not answer my question, and it's too old post, so I cannot expect further answer even if I have written a comment. If you want, I can list my doubts on the answer above.","f \sum_{n\le x}\Lambda_f(x) = \kappa\log x+O(1) \Lambda_f(n) -D'_f(s)/D_f(s) \kappa>-1/2 \sum_{n\le x}|f(n)|\ll(\log x)^{|\kappa|}, \frac{D_f(s)}{\zeta(s+1)^{\kappa}} = \prod_{p}\left(1-\frac{1}{p^{s+1}}\right)^\kappa\left(1+\frac{f(p)}{p^s}+\frac{f(p^2)}{p^{2s}}+\cdots\right) \prod_{p}\left(1-\frac{1}{p}\right)^\kappa\left(1+f(p)+f(p^2)+\cdots\right) s\to 0+ D_f(s)/\zeta(s+1)^\kappa s\to 0+ D_g(s) s=s_0 \{s\in\mathbb{C}|\textrm{Arg}(s-s_0)<\theta\lor s=s_0\} \theta\in(0,\pi/2) s=0 1+f(p)+f(p^2)+\cdots -\frac{D'_f}{D_f}(s)+\kappa\frac{\zeta'}{\zeta}(s+1) = \sum_{n=1}^{\infty}\frac{\Lambda_f(n)-\Lambda(n)/n}{n^s}, O(1) \sum_{n\le x}\Lambda(n)/n = \log x+O(1) \Re s>0 s=0 D_f(s) \Re s>0","['limits', 'analytic-number-theory', 'dirichlet-series', 'euler-product']"
74,Show that the limit equals $f'(x)$,Show that the limit equals,f'(x),"Assume that $f$ is continuous and differentiable. Futher, let $g(r,t)\geq0$ be such that for $t>x$ $$ \lim_{r \to \infty} \frac{g(r,t)}{g(r,x)} = 0. $$ Show that $$ \lim_{r \to \infty} \frac{\int_x^{\infty} (f(x)-f(t)) g(r,t)dt}{\int_x^{\infty} (x-t) g(r,t)dt} = f'(x), $$ where all the functions are also sufficiently integrable for the claim to make sense. Some notes: From the assumptions it follows that for $t\geq x$ $$ \lim_{r \to \infty} \frac{g(r,t)}{g(r,x)} = \delta_x, $$ where $\delta_x$ is the Dirac delta. Then we can divide the denominator and the numerator by $g(r,x)$ .  But I can't immediately see why that would reduce things to be the $f'(x)$ since the integrals are taken separately in the denominator and the numerator. Are some additional assumptions needed?","Assume that is continuous and differentiable. Futher, let be such that for Show that where all the functions are also sufficiently integrable for the claim to make sense. Some notes: From the assumptions it follows that for where is the Dirac delta. Then we can divide the denominator and the numerator by .  But I can't immediately see why that would reduce things to be the since the integrals are taken separately in the denominator and the numerator. Are some additional assumptions needed?","f g(r,t)\geq0 t>x 
\lim_{r \to \infty} \frac{g(r,t)}{g(r,x)} = 0.
 
\lim_{r \to \infty} \frac{\int_x^{\infty} (f(x)-f(t)) g(r,t)dt}{\int_x^{\infty} (x-t) g(r,t)dt} = f'(x),
 t\geq x 
\lim_{r \to \infty} \frac{g(r,t)}{g(r,x)} = \delta_x,
 \delta_x g(r,x) f'(x)","['limits', 'derivatives']"
75,How fast does the coprime probability converge to $6/\pi^2$?,How fast does the coprime probability converge to ?,6/\pi^2,"It is known that the probability that two positive integers are coprime is $6/\pi^2$ . This is an amazing result. I wanted to see experimentally how the probability converges to $6/\pi^2$ , but I found that the sequence converges terribly slow, and I would not believe that it converges unless I didn't know a proof that it actually does. Let $a(n)$ be the number of pairs $1 \leq a,b \leq n$ with $\mathrm{gcd}(a,b)=1$ . The ""probability"" in question is defined as a natural density here by $$\lim_{n\to \infty} a(n)/n^2.$$ It evaluates to $6/\pi^2$ . For computations it should be useful to have the formula $$a(n) = 1 + 2 \sum_{a=2}^{n} \varphi(a),$$ where $\varphi$ is the Euler totient function . I wrote a little program that computes the values of $a(n)/n^2$ , or actually $n \sqrt{6/a(n)}$ since that value should converge to $\pi$ , and I would like to see the digits of $\pi$ coming out. Here is a typical excerpt from the sequence (for $10000 \leq n \leq 10005$ ): 3.141534239016629 3.141342469859083 3.14148445699957 3.14135604503421 3.1414222455373713 3.14148184775969 The sequence ""wiggles"" and takes ""forever"" to get close to 3.14159... . Why is that? More precisely: What is the ""convergence speed"" of that sequence? This would be formalized with the order of convergence . If $d \geq 1$ , is there some $n_0$ such that for all $n \geq n_0$ the number $n \sqrt{6/a(n)}$ has the first $d$ digits of $\pi$ ? For example, is this true for $d=4$ , so that we have 3.1415... from some point on? Numerical experiments suggest that this indeed the case, but $n_0$ is very large. A bit more broader: can we adjust the sequence slightly, or at least find a different sequence related to the coprimality of integers, that converges to $\pi$ more fast?","It is known that the probability that two positive integers are coprime is . This is an amazing result. I wanted to see experimentally how the probability converges to , but I found that the sequence converges terribly slow, and I would not believe that it converges unless I didn't know a proof that it actually does. Let be the number of pairs with . The ""probability"" in question is defined as a natural density here by It evaluates to . For computations it should be useful to have the formula where is the Euler totient function . I wrote a little program that computes the values of , or actually since that value should converge to , and I would like to see the digits of coming out. Here is a typical excerpt from the sequence (for ): 3.141534239016629 3.141342469859083 3.14148445699957 3.14135604503421 3.1414222455373713 3.14148184775969 The sequence ""wiggles"" and takes ""forever"" to get close to 3.14159... . Why is that? More precisely: What is the ""convergence speed"" of that sequence? This would be formalized with the order of convergence . If , is there some such that for all the number has the first digits of ? For example, is this true for , so that we have 3.1415... from some point on? Numerical experiments suggest that this indeed the case, but is very large. A bit more broader: can we adjust the sequence slightly, or at least find a different sequence related to the coprimality of integers, that converges to more fast?","6/\pi^2 6/\pi^2 a(n) 1 \leq a,b \leq n \mathrm{gcd}(a,b)=1 \lim_{n\to \infty} a(n)/n^2. 6/\pi^2 a(n) = 1 + 2 \sum_{a=2}^{n} \varphi(a), \varphi a(n)/n^2 n \sqrt{6/a(n)} \pi \pi 10000 \leq n \leq 10005 d \geq 1 n_0 n \geq n_0 n \sqrt{6/a(n)} d \pi d=4 n_0 \pi","['limits', 'number-theory', 'analytic-number-theory', 'computational-mathematics', 'totient-function']"
76,Density of $\{\sin(x^n)|n\in\mathbb{N}\}$ for $x>1$,Density of  for,\{\sin(x^n)|n\in\mathbb{N}\} x>1,"While reading other topics, e,g, Is $n \sin n$ dense on the real line? or Is $\{ \sin n^m \mid n \in \mathbb{N} \}$ dense in $[-1,1]$ for every natural number $m$? , the following problem appeared in my head: is $\{\sin(x^n)|n\in\mathbb{N}\}$ dense in $[-1,1]$ for all $x>1$? or a weaker problem: if $x>1$, then $\lim_{n\to\infty} \sin(x^n)$ does not exist? I proved the second one for $x=2$ and $x=3$ (with use of sine/cosine multiple angle formulas) and have some thoughts for $x\in\mathbb{N}$, but I have completely no idea how to deal e.g. with $x=e$.","While reading other topics, e,g, Is $n \sin n$ dense on the real line? or Is $\{ \sin n^m \mid n \in \mathbb{N} \}$ dense in $[-1,1]$ for every natural number $m$? , the following problem appeared in my head: is $\{\sin(x^n)|n\in\mathbb{N}\}$ dense in $[-1,1]$ for all $x>1$? or a weaker problem: if $x>1$, then $\lim_{n\to\infty} \sin(x^n)$ does not exist? I proved the second one for $x=2$ and $x=3$ (with use of sine/cosine multiple angle formulas) and have some thoughts for $x\in\mathbb{N}$, but I have completely no idea how to deal e.g. with $x=e$.",,"['number-theory', 'limits', 'irrational-numbers', 'transcendental-numbers', 'transcendence-theory']"
77,Why does $\lim_{x \rightarrow a} \cos (x-a)=\lim_{x \rightarrow 0} \cos (x)$ without using continuity of $\cos$ function?,Why does  without using continuity of  function?,\lim_{x \rightarrow a} \cos (x-a)=\lim_{x \rightarrow 0} \cos (x) \cos,"Why does $\lim_{x \rightarrow a} \cos (x-a)=\lim_{x \rightarrow 0} \cos (x)$ without using continuity of $\cos$ function? In general when is it okay to ""switch"" the limit like this. There is obviously something going on that I am not aware about. Could anyone explain. Thanks.","Why does $\lim_{x \rightarrow a} \cos (x-a)=\lim_{x \rightarrow 0} \cos (x)$ without using continuity of $\cos$ function? In general when is it okay to ""switch"" the limit like this. There is obviously something going on that I am not aware about. Could anyone explain. Thanks.",,['limits']
78,Divisibility sequence resulting in limit with pi,Divisibility sequence resulting in limit with pi,,"Consider the following sequence of operations : Start with a natural number $n$ and then round it up to the closest multiple of $n-1$ .Then round up this new number to the closest multiple of $n-2$ and so on until you round to a multiple of $1$ . Call this last number $f(n)$ . For example for $n=11$ the sequence is : $11,20,27,32,35,36,40,40,42,42,42$ and this means that $f(11)=42$ At first it seemed to me that this sequence is extremely hard to predict because we can't know how the multiples are distributed . But to my amazement the following limit holds : Prove that: $$\lim_{n \to \infty} \frac{n^2}{f(n)}=\pi$$ What I found : If $k \leq \lfloor \frac{n}{2} \rfloor$ then after the $k$-th operation the number is $(k+1)(n-k)$ . This is not hard to prove by induction on $k$ . As an example the sequence for $n=11$ can be seen as : $$11,2 \cdot 10,3 \cdot 9,4 \cdot 8 ,5 \cdot 7 ,6 \cdot 6, \ldots $$ But after this we have $40=5 \cdot 8$ that breaks the pattern .I couldn't find any such patterns for $k>\lfloor \frac{n}{2} \rfloor$ and the sequence afterwards seems pretty arbitrary . I am still amazed by how $\pi$ plays a role in this pure number theoretic question and I'd love to see a proof of the limit (or at least something new about the sequence ). Thanks for everyone that can help me with this extraordinary problem .","Consider the following sequence of operations : Start with a natural number $n$ and then round it up to the closest multiple of $n-1$ .Then round up this new number to the closest multiple of $n-2$ and so on until you round to a multiple of $1$ . Call this last number $f(n)$ . For example for $n=11$ the sequence is : $11,20,27,32,35,36,40,40,42,42,42$ and this means that $f(11)=42$ At first it seemed to me that this sequence is extremely hard to predict because we can't know how the multiples are distributed . But to my amazement the following limit holds : Prove that: $$\lim_{n \to \infty} \frac{n^2}{f(n)}=\pi$$ What I found : If $k \leq \lfloor \frac{n}{2} \rfloor$ then after the $k$-th operation the number is $(k+1)(n-k)$ . This is not hard to prove by induction on $k$ . As an example the sequence for $n=11$ can be seen as : $$11,2 \cdot 10,3 \cdot 9,4 \cdot 8 ,5 \cdot 7 ,6 \cdot 6, \ldots $$ But after this we have $40=5 \cdot 8$ that breaks the pattern .I couldn't find any such patterns for $k>\lfloor \frac{n}{2} \rfloor$ and the sequence afterwards seems pretty arbitrary . I am still amazed by how $\pi$ plays a role in this pure number theoretic question and I'd love to see a proof of the limit (or at least something new about the sequence ). Thanks for everyone that can help me with this extraordinary problem .",,"['number-theory', 'elementary-number-theory']"
79,Limit of fractional part,Limit of fractional part,,"Prove that the limit as n tends to infinity from $\{n!\sqrt2\}$ does not exist. where {} denotes fractional part and ""!"" denotes factorial. I don't have many ideas. I would try to show that , given an arbitrary term $x_n$ we can find another term $x_m$, m>n such that $|x_n-x_m|>a$ where $a$ is some fixed number. And so the sequence cannot converge.","Prove that the limit as n tends to infinity from $\{n!\sqrt2\}$ does not exist. where {} denotes fractional part and ""!"" denotes factorial. I don't have many ideas. I would try to show that , given an arbitrary term $x_n$ we can find another term $x_m$, m>n such that $|x_n-x_m|>a$ where $a$ is some fixed number. And so the sequence cannot converge.",,['limits']
80,Shouldn't this function be discontinuous everywhere?,Shouldn't this function be discontinuous everywhere?,,"I was thinking about single point continuity and came across this function. $$ f(x) = \left\{         \begin{array}{ll}             x & \quad x\in \mathbb{Q}\\             2-x &  \quad x\notin \mathbb{Q}         \end{array}     \right. $$ We know this function is continuous only at $x=1$ . But doesn't that contradict our whole idea of continuity? A function is continuous if we are able to draw the function without lifting our pen or pencil. But here both the pieces of the function exist at specific places, so we have to lift our pen. Shouldn't the function be discontinuous everywhere? Looks like a stupid doubt though.","I was thinking about single point continuity and came across this function. $$ f(x) = \left\{         \begin{array}{ll}             x & \quad x\in \mathbb{Q}\\             2-x &  \quad x\notin \mathbb{Q}         \end{array}     \right. $$ We know this function is continuous only at $x=1$ . But doesn't that contradict our whole idea of continuity? A function is continuous if we are able to draw the function without lifting our pen or pencil. But here both the pieces of the function exist at specific places, so we have to lift our pen. Shouldn't the function be discontinuous everywhere? Looks like a stupid doubt though.",,['limits']
81,How to solve this limits question,How to solve this limits question,,I have a problem with this limit question. $$\lim_{x \to \infty} \frac{x^3-4x}{7-2x^3}$$ How can the answer become $-\frac12$?,I have a problem with this limit question. $$\lim_{x \to \infty} \frac{x^3-4x}{7-2x^3}$$ How can the answer become $-\frac12$?,,['limits']
82,Show that $\sqrt{n^2+1}-n$ converges to 0,Show that  converges to 0,\sqrt{n^2+1}-n,"I want to use the definition of the limit to show that $\sqrt{n^2+1}-n$ converges to 0. The definition is as follows: if $\sqrt{n^2+1}-n$ converges to 0, then $\forall \epsilon>0$, there exists an $N>0$ such that $n\ge N \implies \mid\sqrt{n^2+1}-n\mid<\epsilon$. Now I want to start backwords in order to figure out how to pick N. I know: $\mid\sqrt{n^2+1}-n\mid=\sqrt{n^2+1}-n$ since $n$ is a natural number and $\sqrt{n^2+1}>n$. So I need to pick an N such that $\sqrt{n^2+1}-n<\epsilon$. I tried multiplying $\sqrt{n^2+1}-n$ by $\frac{\sqrt{n^2+1}+n}{\sqrt{n^2+1}+n}$ but that didn't really seem to help. Do you have any ideas on how to find this N? Thanks","I want to use the definition of the limit to show that $\sqrt{n^2+1}-n$ converges to 0. The definition is as follows: if $\sqrt{n^2+1}-n$ converges to 0, then $\forall \epsilon>0$, there exists an $N>0$ such that $n\ge N \implies \mid\sqrt{n^2+1}-n\mid<\epsilon$. Now I want to start backwords in order to figure out how to pick N. I know: $\mid\sqrt{n^2+1}-n\mid=\sqrt{n^2+1}-n$ since $n$ is a natural number and $\sqrt{n^2+1}>n$. So I need to pick an N such that $\sqrt{n^2+1}-n<\epsilon$. I tried multiplying $\sqrt{n^2+1}-n$ by $\frac{\sqrt{n^2+1}+n}{\sqrt{n^2+1}+n}$ but that didn't really seem to help. Do you have any ideas on how to find this N? Thanks",,"['analysis', 'limits']"
83,$\lim_{x \to 0} \frac{e^{\sin2x}-e^{\sin x}}{x}$ without L'Hospital,without L'Hospital,\lim_{x \to 0} \frac{e^{\sin2x}-e^{\sin x}}{x},Anyone has an idea how to find $\displaystyle\lim_{x \to 0} \dfrac{e^{\sin2x}-e^{\sin x}}{x}$ without L'Hospital? I solved it with L'Hospital and the result is $1$ but the assignment is to find it without L'Hospital. Any idea?,Anyone has an idea how to find $\displaystyle\lim_{x \to 0} \dfrac{e^{\sin2x}-e^{\sin x}}{x}$ without L'Hospital? I solved it with L'Hospital and the result is $1$ but the assignment is to find it without L'Hospital. Any idea?,,"['real-analysis', 'limits']"
84,Find $\lim_{x \to 0} \frac{\ln (x^2+1)} {x^2} $ without L'hopital's rule,Find  without L'hopital's rule,\lim_{x \to 0} \frac{\ln (x^2+1)} {x^2} ,"I have to find the limit without L'hopital's rule : $$\lim_{x \to 0} \frac{\ln (x^2+1)} {x^2} $$ Is it possible?  I thought about using squeeze theorem or something, but it didn't work out. Hints are more than welcome! P.S -  I didn't study Taylor series or Integrals yet.","I have to find the limit without L'hopital's rule : $$\lim_{x \to 0} \frac{\ln (x^2+1)} {x^2} $$ Is it possible?  I thought about using squeeze theorem or something, but it didn't work out. Hints are more than welcome! P.S -  I didn't study Taylor series or Integrals yet.",,"['real-analysis', 'limits', 'limits-without-lhopital']"
85,Limit Computation of $(e^x+x)^{1/x}$ as $x$ approaches zero,Limit Computation of  as  approaches zero,(e^x+x)^{1/x} x,I need help computing the limit of $(e^x+x)^{1/x}$ as $x$ approaches zero. I just need help getting started with the computation. The only way I can think of rearranging the equation is distributing the $1/x$.,I need help computing the limit of $(e^x+x)^{1/x}$ as $x$ approaches zero. I just need help getting started with the computation. The only way I can think of rearranging the equation is distributing the $1/x$.,,['limits']
86,How can I claim a one-sided limit doesn't exist?,How can I claim a one-sided limit doesn't exist?,,"I have to find the limit $$\lim_{x\to 0^+} \frac{\ln(1+2x)\sin x}{\sqrt {x^3}} $$ Now, I tried using L'Hôpital's rule, but it doesn't lead anywhere. Manually trying to convert the functions to another form doesn't seem to go anywhere either, so I determined that the limit must be undefined. However, I cannot prove it. What can I do?","I have to find the limit Now, I tried using L'Hôpital's rule, but it doesn't lead anywhere. Manually trying to convert the functions to another form doesn't seem to go anywhere either, so I determined that the limit must be undefined. However, I cannot prove it. What can I do?",\lim_{x\to 0^+} \frac{\ln(1+2x)\sin x}{\sqrt {x^3}} ,"['real-analysis', 'limits', 'logarithms', 'proof-explanation', 'limits-without-lhopital']"
87,What is $\lim_{x\to 2} \frac{\sqrt{x+2}-2}{x-2}$?,What is ?,\lim_{x\to 2} \frac{\sqrt{x+2}-2}{x-2},"I tried multiplying by the conjugate which gave: $$\frac{x-2}{(x-2)\sqrt{x+2}+2x-4}$$ But i'm still gettting $\frac{0}{0}$. According to my textbook the answer should be $\frac{1}{4}$, but how do I get there?","I tried multiplying by the conjugate which gave: $$\frac{x-2}{(x-2)\sqrt{x+2}+2x-4}$$ But i'm still gettting $\frac{0}{0}$. According to my textbook the answer should be $\frac{1}{4}$, but how do I get there?",,['limits']
88,Evaluating the $\lim_{x\to0}\frac{4^x-1}{8^x-1}$ without L'Hopital Rule,Evaluating the  without L'Hopital Rule,\lim_{x\to0}\frac{4^x-1}{8^x-1},"How to evaluate $\displaystyle \lim_{x\to0}\left(\frac{4^x-1}{8^x-1}\right)$ without L'Hopital rule? When I evaluated this limit I got an indetermination, $\frac{0}{0}$. I learned that in a rational function when one get $\frac{0}{0}$ indeterminated form, one should look for the common terms between numerator and denominator by factoring. But I can't figure out how to find the common terms in this case. Can you help me? Thanks.","How to evaluate $\displaystyle \lim_{x\to0}\left(\frac{4^x-1}{8^x-1}\right)$ without L'Hopital rule? When I evaluated this limit I got an indetermination, $\frac{0}{0}$. I learned that in a rational function when one get $\frac{0}{0}$ indeterminated form, one should look for the common terms between numerator and denominator by factoring. But I can't figure out how to find the common terms in this case. Can you help me? Thanks.",,['limits']
89,Limit of $(\sum_{k=0}^{n}k^4)/n^5$,Limit of,(\sum_{k=0}^{n}k^4)/n^5,So i was trying to find this limit: $$\lim_{n\to\infty}\frac{  \sum_{k=0}^{n}k^4}{n^5}$$ which at first made me think it's zero but soon i realized that it's probably not. I tried expanding that but there's  no $n^5$ in the explansion. Eventialy i tried something like $$ \sum_{k=0}^{n+1}k^4 - \sum_{k=0}^{n}k^4=(x+1)^4= An^4+Bn^3+Cn^2+Dn+E$$ But again this has no $n^5$ involved.. If someone could provide a hint..,So i was trying to find this limit: $$\lim_{n\to\infty}\frac{  \sum_{k=0}^{n}k^4}{n^5}$$ which at first made me think it's zero but soon i realized that it's probably not. I tried expanding that but there's  no $n^5$ in the explansion. Eventialy i tried something like $$ \sum_{k=0}^{n+1}k^4 - \sum_{k=0}^{n}k^4=(x+1)^4= An^4+Bn^3+Cn^2+Dn+E$$ But again this has no $n^5$ involved.. If someone could provide a hint..,,"['limits', 'summation']"
90,"How do you show that $\lim_{(x,y)\to(0,0)} \frac{xy}{x^2+y}$ doesn't exist?",How do you show that  doesn't exist?,"\lim_{(x,y)\to(0,0)} \frac{xy}{x^2+y}","I have to prove that this limit doesn't exist. $$\lim_{(x,y)\to(0,0)} \frac{xy}{x^2+y}$$ I tried this parametrization: $\begin{cases} x = t \\ y = mt^\alpha\end{cases}$ obtaining as result that the previous limit in this specific case would be equivalent to $$\lim_{t\to0} \frac{mt}{t^{2-\alpha}+m}$$ which would be null for each value of $\alpha,m$. Using a polar coordinate system doesn't seem effective too. How do I prove that this doesn't exist?","I have to prove that this limit doesn't exist. $$\lim_{(x,y)\to(0,0)} \frac{xy}{x^2+y}$$ I tried this parametrization: $\begin{cases} x = t \\ y = mt^\alpha\end{cases}$ obtaining as result that the previous limit in this specific case would be equivalent to $$\lim_{t\to0} \frac{mt}{t^{2-\alpha}+m}$$ which would be null for each value of $\alpha,m$. Using a polar coordinate system doesn't seem effective too. How do I prove that this doesn't exist?",,['limits']
91,Using Taylor Expansion to evaluate limits,Using Taylor Expansion to evaluate limits,,"I am going through some lecture notes and I came across this limit: $$\lim_{x\to 0}\frac{\sinh x^4-x^4}{(x-\sin x)^4} $$ In the notes, it says (after introducing L'Hopital's Rule) that this would be difficult to evaluate using L'Hopital's Rule but can be done on sight using Taylor's Theorem. After reading the section on Taylor's Theorem, I don't understand how this can be done in sight. Would one need to calculate its Taylor expansion? If so, how would one go about doing that as its derivatives aren't defined at 0? I have used Wolfram to see the Taylor expansion is $216+O(x^2)$ which means the limit is equal to 216, but how does one calculate this Taylor expansion?","I am going through some lecture notes and I came across this limit: $$\lim_{x\to 0}\frac{\sinh x^4-x^4}{(x-\sin x)^4} $$ In the notes, it says (after introducing L'Hopital's Rule) that this would be difficult to evaluate using L'Hopital's Rule but can be done on sight using Taylor's Theorem. After reading the section on Taylor's Theorem, I don't understand how this can be done in sight. Would one need to calculate its Taylor expansion? If so, how would one go about doing that as its derivatives aren't defined at 0? I have used Wolfram to see the Taylor expansion is $216+O(x^2)$ which means the limit is equal to 216, but how does one calculate this Taylor expansion?",,"['limits', 'taylor-expansion', 'limits-without-lhopital']"
92,How to prove the following in general: $\lim\limits_{x\rightarrow a} \frac{x^n-a^n}{x-a}=na^{n-1}$?,How to prove the following in general: ?,\lim\limits_{x\rightarrow a} \frac{x^n-a^n}{x-a}=na^{n-1},To prove $$\lim_{x\rightarrow a} \frac{x^n-a^n}{x-a}=na^{n-1}$$ The proof is easy when we take $n$ as positive integer and $a$ any positive real number. In my book it is given that the result is true even when $n$ is any rational number and $a$ any positive real number. But the proof is not given. Please provide some hint to construct the proof for general case.,To prove $$\lim_{x\rightarrow a} \frac{x^n-a^n}{x-a}=na^{n-1}$$ The proof is easy when we take $n$ as positive integer and $a$ any positive real number. In my book it is given that the result is true even when $n$ is any rational number and $a$ any positive real number. But the proof is not given. Please provide some hint to construct the proof for general case.,,['limits']
93,why $ 1 - \cos^2x = \sin^2x $? [duplicate],why ? [duplicate], 1 - \cos^2x = \sin^2x ,This question already has answers here : Prove $\sin^2\theta + \cos^2\theta = 1$ (16 answers) Closed 8 years ago . I'm trying to prove this result $$\lim_{x\to 0} \frac{1 - \cos(x)}{x} = 0$$ In this process I have come across an identity $1-\cos^2x=\sin^2x$. Why should this hold ? Here are a few steps of my working: \begin{array}\\  \lim_{x\to 0} \dfrac{1 - \cos(x)}{x}\\ = \lim_{x\to 0} \left[\dfrac{1 - \cos(x)}{x} \times    \dfrac{1 + \cos(x)}{1 + \cos(x)}\right] \\ =\lim_{x\to 0} \left[\dfrac{1 - \cos^2(x)}{x(1+\cos(x))}\right]  \\ =\lim_{x\to 0} \left[\dfrac{\sin^2(x)}{x(1+\cos(x))}\right] \end{array},This question already has answers here : Prove $\sin^2\theta + \cos^2\theta = 1$ (16 answers) Closed 8 years ago . I'm trying to prove this result $$\lim_{x\to 0} \frac{1 - \cos(x)}{x} = 0$$ In this process I have come across an identity $1-\cos^2x=\sin^2x$. Why should this hold ? Here are a few steps of my working: \begin{array}\\  \lim_{x\to 0} \dfrac{1 - \cos(x)}{x}\\ = \lim_{x\to 0} \left[\dfrac{1 - \cos(x)}{x} \times    \dfrac{1 + \cos(x)}{1 + \cos(x)}\right] \\ =\lim_{x\to 0} \left[\dfrac{1 - \cos^2(x)}{x(1+\cos(x))}\right]  \\ =\lim_{x\to 0} \left[\dfrac{\sin^2(x)}{x(1+\cos(x))}\right] \end{array},,"['limits', 'trigonometry']"
94,Limits at infinity by rationalizing,Limits at infinity by rationalizing,,"I am trying to evaluate this limit for an assignment.  $$\lim_{x \to \infty} \sqrt{x^2-6x +1}-x$$ I have tried to rationalize the function: $$=\lim_{x \to \infty} \frac{(\sqrt{x^2-6x +1}-x)(\sqrt{x^2-6x +1}+x)}{\sqrt{x^2-6x +1}+x}$$ $$=\lim_{x \to \infty} \frac{-6x+1}{\sqrt{x^2-6x +1}+x}$$ Then I multiply the function by $$\frac{(\frac{1}{x})}{(\frac{1}{x})}$$ Leading to $$=\lim_{x \to \infty} \frac{-6+(\frac{1}{x})}{\sqrt{(\frac{-6}{x})+(\frac{1}{x^2})}+1}$$ Taking the limit, I see that all x terms tend to zero, leaving -6 as the answer. But -6 is not the answer. Why is that?","I am trying to evaluate this limit for an assignment.  $$\lim_{x \to \infty} \sqrt{x^2-6x +1}-x$$ I have tried to rationalize the function: $$=\lim_{x \to \infty} \frac{(\sqrt{x^2-6x +1}-x)(\sqrt{x^2-6x +1}+x)}{\sqrt{x^2-6x +1}+x}$$ $$=\lim_{x \to \infty} \frac{-6x+1}{\sqrt{x^2-6x +1}+x}$$ Then I multiply the function by $$\frac{(\frac{1}{x})}{(\frac{1}{x})}$$ Leading to $$=\lim_{x \to \infty} \frac{-6+(\frac{1}{x})}{\sqrt{(\frac{-6}{x})+(\frac{1}{x^2})}+1}$$ Taking the limit, I see that all x terms tend to zero, leaving -6 as the answer. But -6 is not the answer. Why is that?",,['limits']
95,Find $\lim\frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\ldots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right)$ [closed],Find  [closed],\lim\frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\ldots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right),"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Find $$\lim_{n\rightarrow\infty}\frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\ldots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right)$$","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Find $$\lim_{n\rightarrow\infty}\frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\ldots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right)$$",,['limits']
96,Limit of $\frac{1}{a} + \frac{2}{a^2} + \cdots + \frac{n}{a^n}$,Limit of,\frac{1}{a} + \frac{2}{a^2} + \cdots + \frac{n}{a^n},"What is the limit of this sequence $\frac{1}{a} + \frac{2}{a^2} + \cdots + \frac{n}{a^n}$? Where $a$ is a constant and $n \to \infty$. If answered  with proofs, it will be best.","What is the limit of this sequence $\frac{1}{a} + \frac{2}{a^2} + \cdots + \frac{n}{a^n}$? Where $a$ is a constant and $n \to \infty$. If answered  with proofs, it will be best.",,['limits']
97,Showing that $\lim_{x \to 1} \left(\frac{23}{1-x^{23}}-\frac{11}{1-x^{11}} \right)=6$,Showing that,\lim_{x \to 1} \left(\frac{23}{1-x^{23}}-\frac{11}{1-x^{11}} \right)=6,How does one evaluate the following limit? $$\lim_{x \to 1} \left(\frac{23}{1-x^{23}}-\frac{11}{1-x^{11}} \right)$$ The answer is $6$. How does one justify this answer? Edit: So it really was just combine the fraction and use L'hopital's rule twice (because function and its first derivative are of indeterminate form at $x=1$). This problem is more straightforward than it seems at first.,How does one evaluate the following limit? $$\lim_{x \to 1} \left(\frac{23}{1-x^{23}}-\frac{11}{1-x^{11}} \right)$$ The answer is $6$. How does one justify this answer? Edit: So it really was just combine the fraction and use L'hopital's rule twice (because function and its first derivative are of indeterminate form at $x=1$). This problem is more straightforward than it seems at first.,,['limits']
98,What kind of growing function has a constant as limit?,What kind of growing function has a constant as limit?,,My knowledge in mathematics are a bit old and I'm looking for functions with constant as limit. The function must always grow. The curve should be something similar to $\sqrt{x}$ or $\ln(x)$ but with $\lim _{x\to \infty \:}f\left(x\right)=\mathrm{constant}$ Could you please help to find this kind of functions?,My knowledge in mathematics are a bit old and I'm looking for functions with constant as limit. The function must always grow. The curve should be something similar to $\sqrt{x}$ or $\ln(x)$ but with $\lim _{x\to \infty \:}f\left(x\right)=\mathrm{constant}$ Could you please help to find this kind of functions?,,"['limits', 'functions']"
99,If $x_n = (\prod_{k=0}^n \binom{n}{k})^\frac{2}{n(n+1)}$ then $\lim_{n \to \infty} x_n = e$,If  then,x_n = (\prod_{k=0}^n \binom{n}{k})^\frac{2}{n(n+1)} \lim_{n \to \infty} x_n = e,"I try to prove the following: $$x_n = \left(\prod_{k=0}^n \binom{n}{k}\right)^\frac{2}{n(n+1)}$$ $$\lim_{n \to \infty} x_n = e$$ I want to use double sided theorem, so I've proven that $$x_n \ge \frac{n}{\sqrt[n]{n!}}$$ As it known, $\lim\limits_{n \to \infty} \frac{n}{\sqrt[n]{n!}} = e$. But I can't find such sequence $y_n$ that $x_n \le y_n$ and $\lim\limits_{n \to \infty} y_n = e$. There is proof for lower bound: $$x_n = \frac{(n!)^\frac{2}{n}}{(0!\cdot 1! \dots n!)^\frac{4}{n(n+1)}} \ge \frac{(n!)^\frac{2}{n}\cdot n}{(0!\cdot 1! \dots n!)^\frac{4}{n(n+1)}\cdot(n^n(n-1)^{n-1}(n-2)^{n-2}\dots2^2)^\frac{4}{n(n+1)}} = $$ $$= \frac{(n!)^\frac 2n \cdot n}{(n!)^\frac 4n} = \frac{n}{(n!)^\frac 2n} \ge \frac{n}{\sqrt[n]{n!}}$$","I try to prove the following: $$x_n = \left(\prod_{k=0}^n \binom{n}{k}\right)^\frac{2}{n(n+1)}$$ $$\lim_{n \to \infty} x_n = e$$ I want to use double sided theorem, so I've proven that $$x_n \ge \frac{n}{\sqrt[n]{n!}}$$ As it known, $\lim\limits_{n \to \infty} \frac{n}{\sqrt[n]{n!}} = e$. But I can't find such sequence $y_n$ that $x_n \le y_n$ and $\lim\limits_{n \to \infty} y_n = e$. There is proof for lower bound: $$x_n = \frac{(n!)^\frac{2}{n}}{(0!\cdot 1! \dots n!)^\frac{4}{n(n+1)}} \ge \frac{(n!)^\frac{2}{n}\cdot n}{(0!\cdot 1! \dots n!)^\frac{4}{n(n+1)}\cdot(n^n(n-1)^{n-1}(n-2)^{n-2}\dots2^2)^\frac{4}{n(n+1)}} = $$ $$= \frac{(n!)^\frac 2n \cdot n}{(n!)^\frac 4n} = \frac{n}{(n!)^\frac 2n} \ge \frac{n}{\sqrt[n]{n!}}$$",,"['limits', 'binomial-coefficients', 'exponential-function']"
