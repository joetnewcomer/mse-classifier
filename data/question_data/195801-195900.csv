,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What is the value of the constant C?,What is the value of the constant C?,,The curve $y=Cx^{\frac{1}{5}}$ (where  C is constant) is tangent to the line $y=\frac{x}{20}+\frac{32}{5}\:$ somewhere. What is the value of constant C?,The curve $y=Cx^{\frac{1}{5}}$ (where  C is constant) is tangent to the line $y=\frac{x}{20}+\frac{32}{5}\:$ somewhere. What is the value of constant C?,,"['calculus', 'derivatives']"
1,Show that the tangent only touches the graph in one point.,Show that the tangent only touches the graph in one point.,,"Let $f: \mathbb R\to \mathbb R$ be such that $f'$ is increasing. Show that for all $x$ the tangent line through the point $(x, f(x))$ only touches the graph in that point. So I'm kinda stuck with this problem. I know that if $f'$ is increasing then $f''>0$ and I suppose I have to use that somehow. Maybe a mean value theorem? I don't know. Thanks","Let $f: \mathbb R\to \mathbb R$ be such that $f'$ is increasing. Show that for all $x$ the tangent line through the point $(x, f(x))$ only touches the graph in that point. So I'm kinda stuck with this problem. I know that if $f'$ is increasing then $f''>0$ and I suppose I have to use that somehow. Maybe a mean value theorem? I don't know. Thanks",,"['calculus', 'derivatives']"
2,Prove the following equality regarding partial derivatives,Prove the following equality regarding partial derivatives,,"Let $f:\Omega\subset\mathbb{R^2\to\mathbb{R}}$ be a function such that $f\in\mathit{C^1}(\Omega)$. Now, consider the function: $$g(x,y,z):=x^4f(y/x,z/x)$$ Prove that $$x\frac{\partial g}{\partial x}+y\frac{\partial g}{\partial y}+z\frac{\partial g}{\partial z} = 4g$$ Now, I'm not sure whether I'm calculating those partial derivatives properly, but I conclude that: $$x\frac{\partial g}{\partial x}=4x^4f(y/x,z/x)+x\cdot x^4\frac{\partial f}{\partial x}$$ $$y\frac{\partial g}{\partial y}=y\cdot x^4\frac{\partial f}{\partial y}$$ $$z\frac{\partial g}{\partial z}=z\cdot x^4\frac{\partial f}{\partial z}$$ Now, note that $x\frac{\partial g}{\partial x}=4g+x^5\frac{\partial f}{\partial x}$, which means its enough to prove that: $$x\cdot x^4\frac{\partial f}{\partial x}+y\cdot x^4\frac{\partial f}{\partial y}+z\cdot x^4\frac{\partial f}{\partial z}=0$$ This is where I'm stuck, I have no clue how to proceed. I know that, since $f\in\mathit{C^1}(\Omega)$, it is differentiable. Not sure how to use this though. I'm expecting maybe all 3 partial derivatives are $0$, which would prove the statement. Or maybe they just compensate each other. Â¿Any ideas?","Let $f:\Omega\subset\mathbb{R^2\to\mathbb{R}}$ be a function such that $f\in\mathit{C^1}(\Omega)$. Now, consider the function: $$g(x,y,z):=x^4f(y/x,z/x)$$ Prove that $$x\frac{\partial g}{\partial x}+y\frac{\partial g}{\partial y}+z\frac{\partial g}{\partial z} = 4g$$ Now, I'm not sure whether I'm calculating those partial derivatives properly, but I conclude that: $$x\frac{\partial g}{\partial x}=4x^4f(y/x,z/x)+x\cdot x^4\frac{\partial f}{\partial x}$$ $$y\frac{\partial g}{\partial y}=y\cdot x^4\frac{\partial f}{\partial y}$$ $$z\frac{\partial g}{\partial z}=z\cdot x^4\frac{\partial f}{\partial z}$$ Now, note that $x\frac{\partial g}{\partial x}=4g+x^5\frac{\partial f}{\partial x}$, which means its enough to prove that: $$x\cdot x^4\frac{\partial f}{\partial x}+y\cdot x^4\frac{\partial f}{\partial y}+z\cdot x^4\frac{\partial f}{\partial z}=0$$ This is where I'm stuck, I have no clue how to proceed. I know that, since $f\in\mathit{C^1}(\Omega)$, it is differentiable. Not sure how to use this though. I'm expecting maybe all 3 partial derivatives are $0$, which would prove the statement. Or maybe they just compensate each other. Â¿Any ideas?",,['derivatives']
3,Rate of change of rectangle inside triangle,Rate of change of rectangle inside triangle,,"A rectangle is inscribed inside a right angled triangle with hypotenuse 50cm and an angle of 30 degrees. I have supplied a diagram below. The vertical line marked h is moving to the right at 3cm per second, such that db/dt = -3. We are asked to find the rate of change of area of the rectangle when the vertical line h is 20cm from the 30 degree angle i.e when y=20. My method is to use similar triangles to get the area in terms of b. My final answer is +5.72cm^2 per second, but I have no clue if this is right as the answer is not supplied.","A rectangle is inscribed inside a right angled triangle with hypotenuse 50cm and an angle of 30 degrees. I have supplied a diagram below. The vertical line marked h is moving to the right at 3cm per second, such that db/dt = -3. We are asked to find the rate of change of area of the rectangle when the vertical line h is 20cm from the 30 degree angle i.e when y=20. My method is to use similar triangles to get the area in terms of b. My final answer is +5.72cm^2 per second, but I have no clue if this is right as the answer is not supplied.",,"['calculus', 'derivatives']"
4,Finding derivative of the inverse without the inverse,Finding derivative of the inverse without the inverse,,"We are given a function $$f(x)=4\arcsin(\sqrt{x})+2\arcsin(\sqrt{1-x})$$ The derivative of $f$ is: $$f'(x)=\frac{1}{\sqrt{x-x^2}}$$ I would like to find the maximum value of $f^{-1}$. I think I have a solution, although I am not sure. Solution We know that $$\frac{d}{dx} f^{-1}(x)=\frac{1}{f'(f^{-1}(x))}$$ In the problem, we are to find when $$\frac{d}{dx} f^{-1}(x) =0$$ Thus, $$\frac{d}{dx} f^{-1}(x)= \frac{1}{\frac{1}{\sqrt{y-y^2}}}= \sqrt{y-y^2} = y(1-y)$$ It follows that $y=0$ or $y=1$, when the above expression is set to zero. Unsure I assume that since the inverse function gets us back to the original value, we can write this as $f(y)=x$. Is the solution I got above the maximum value or simply the point $x$ that I have to plug into $f^{-1}$ to get the maximum value?","We are given a function $$f(x)=4\arcsin(\sqrt{x})+2\arcsin(\sqrt{1-x})$$ The derivative of $f$ is: $$f'(x)=\frac{1}{\sqrt{x-x^2}}$$ I would like to find the maximum value of $f^{-1}$. I think I have a solution, although I am not sure. Solution We know that $$\frac{d}{dx} f^{-1}(x)=\frac{1}{f'(f^{-1}(x))}$$ In the problem, we are to find when $$\frac{d}{dx} f^{-1}(x) =0$$ Thus, $$\frac{d}{dx} f^{-1}(x)= \frac{1}{\frac{1}{\sqrt{y-y^2}}}= \sqrt{y-y^2} = y(1-y)$$ It follows that $y=0$ or $y=1$, when the above expression is set to zero. Unsure I assume that since the inverse function gets us back to the original value, we can write this as $f(y)=x$. Is the solution I got above the maximum value or simply the point $x$ that I have to plug into $f^{-1}$ to get the maximum value?",,"['calculus', 'derivatives', 'inverse']"
5,Concavity of function $F(x) = x^{1/5} (x+6)$,Concavity of function,F(x) = x^{1/5} (x+6),I was wondering when this function would curve upwards/downwards. I was having trouble finding the inflection points. Thank you. $$F(x) = x^{1/5} (x+6)$$ Progress I found the first derivative to be $\frac65 (x+1)  x^{4/5}$ and the second derivative to be $\frac{6}{25}(x-4) x^{9/5}$ . Is that right?,I was wondering when this function would curve upwards/downwards. I was having trouble finding the inflection points. Thank you. Progress I found the first derivative to be and the second derivative to be . Is that right?,F(x) = x^{1/5} (x+6) \frac65 (x+1)  x^{4/5} \frac{6}{25}(x-4) x^{9/5},"['calculus', 'derivatives']"
6,Inflection point not found for the function $f(x) = 2\arctan(x) - \dfrac{x^3}{x^2+1}$. Should it?,Inflection point not found for the function . Should it?,f(x) = 2\arctan(x) - \dfrac{x^3}{x^2+1},"$f'(x) = -\dfrac{x^4+x^2-2}{\left(x^2+1\right)^2} = \dfrac{(x+1)(x-1)(-x^2-2)}{\left(x^2+1\right)^2}$ This gives the critical points $x=-1 \quad\&\quad x=1$. Solving those with sign analysis; one finds two local extreme values at $x=-1\quad \&\quad x=1$. However, just watching the plot of the derivative makes me suspicious. I know that for an inflection point, the condition $f''(x) = 0$ is necessary but not sufficient , am I right here? So sure, I can't draw the conclusion from just that plot. However, looking at the plot of the original function it actually does look like the derivative $f'(x)$ does change signs at $x=0$. Am I in the complete wrong here? Should I trust my algebra or have I done it wrong?","$f'(x) = -\dfrac{x^4+x^2-2}{\left(x^2+1\right)^2} = \dfrac{(x+1)(x-1)(-x^2-2)}{\left(x^2+1\right)^2}$ This gives the critical points $x=-1 \quad\&\quad x=1$. Solving those with sign analysis; one finds two local extreme values at $x=-1\quad \&\quad x=1$. However, just watching the plot of the derivative makes me suspicious. I know that for an inflection point, the condition $f''(x) = 0$ is necessary but not sufficient , am I right here? So sure, I can't draw the conclusion from just that plot. However, looking at the plot of the original function it actually does look like the derivative $f'(x)$ does change signs at $x=0$. Am I in the complete wrong here? Should I trust my algebra or have I done it wrong?",,"['calculus', 'derivatives']"
7,"differentiability of a function f(x,y)","differentiability of a function f(x,y)",,"I've of $f(x,y)=\sqrt{x^2+y^2} \sin (2 \arctan {y\over x})$ for $x \ne 0$ and $0$ for $x=0$ The function is continuous in all $R^2$. In the points $(0,y_0)$ with $y_0 \ne 0$ the $\partial x f(0,y_0)$ is $2$ if $y_0>0$ and $-2$ if $y_0<0$?","I've of $f(x,y)=\sqrt{x^2+y^2} \sin (2 \arctan {y\over x})$ for $x \ne 0$ and $0$ for $x=0$ The function is continuous in all $R^2$. In the points $(0,y_0)$ with $y_0 \ne 0$ the $\partial x f(0,y_0)$ is $2$ if $y_0>0$ and $-2$ if $y_0<0$?",,['derivatives']
8,Differentiation to Find slope if tangent line Implicitly,Differentiation to Find slope if tangent line Implicitly,,"I have the equation $x^3+y^3-4xy=8$. I need to find the equation for the tangent line at $(2,0)$. When I derived the equation I came up with $$y'=\frac{3x^2-4x}{-3y^2-4y}$$ Obviously, if you plug in $x=2$ and $y=0$, your answer will be undefined. I think I differentiated improperly, can someone point out my mistake and enlighten me to the steps of proper differentiation for this equation?","I have the equation $x^3+y^3-4xy=8$. I need to find the equation for the tangent line at $(2,0)$. When I derived the equation I came up with $$y'=\frac{3x^2-4x}{-3y^2-4y}$$ Obviously, if you plug in $x=2$ and $y=0$, your answer will be undefined. I think I differentiated improperly, can someone point out my mistake and enlighten me to the steps of proper differentiation for this equation?",,"['calculus', 'derivatives', 'implicit-differentiation']"
9,Value of the sum (numerical analysis),Value of the sum (numerical analysis),,"Let $x_0, x_1, \dots, x_n$ are different real numbers and $\omega(x) = (x-x_0)(x-x_1)\dots(x-x_n)$. Then what is the value of the following sum: $$\sum_{k=0}^{n}\frac{\omega''(x_k)}{\omega'(x_k)}$$ I know that $\omega'(x_i) = (x_i-x_0)(x_i-x_1)\dots(x_i-x_{i-1})(x_i-x_{i+1})\dots(x_i-x_n)$, but have no clue for the second derivative...","Let $x_0, x_1, \dots, x_n$ are different real numbers and $\omega(x) = (x-x_0)(x-x_1)\dots(x-x_n)$. Then what is the value of the following sum: $$\sum_{k=0}^{n}\frac{\omega''(x_k)}{\omega'(x_k)}$$ I know that $\omega'(x_i) = (x_i-x_0)(x_i-x_1)\dots(x_i-x_{i-1})(x_i-x_{i+1})\dots(x_i-x_n)$, but have no clue for the second derivative...",,"['polynomials', 'derivatives', 'numerical-methods']"
10,Calculus Notation Question,Calculus Notation Question,,"What is the difference between $\frac{dy}{dx}$, $\frac{\delta y}{\delta x}$ and $\frac{\Delta y}{\Delta x}$? I was reading the derivation of a formula and when I came across this.. as $\Delta x$ approaches zero, $\frac{\Delta y}{\Delta x}$ approaches $\frac{dy}{dx}$. How can this be explained? And is there a geometrical explanation for this?","What is the difference between $\frac{dy}{dx}$, $\frac{\delta y}{\delta x}$ and $\frac{\Delta y}{\Delta x}$? I was reading the derivation of a formula and when I came across this.. as $\Delta x$ approaches zero, $\frac{\Delta y}{\Delta x}$ approaches $\frac{dy}{dx}$. How can this be explained? And is there a geometrical explanation for this?",,"['calculus', 'derivatives', 'notation']"
11,Differentiate y=CotÂ²(sinx),Differentiate y=CotÂ²(sinx),,$$ y = \cot^2(\sin x) $$ How do I differentiate that? I tried using chain rule but I don't understand how to differentiate $\cot^2(\sin x)$.,$$ y = \cot^2(\sin x) $$ How do I differentiate that? I tried using chain rule but I don't understand how to differentiate $\cot^2(\sin x)$.,,"['trigonometry', 'derivatives']"
12,Differentiation of $f(x)=2x(2+3x^2)^3$,Differentiation of,f(x)=2x(2+3x^2)^3,The question: Differentiate $f(x)=2x(2+3x^2)^3$. How do I approach this problem? Do I only have to use the product rule...? I have the answer but I don't know how to get there. Here is my attempt to this problem: $$\frac{df}{dx}=(2)(2+3x^2)^3 + (2x)(6x)(3)(2+3x^2)^2 = \\ =(2+3x^2)^2 [(2)(2+3x^2) + (2x)(6x)(3)] = \\ = (2+3x^2)^2 [(4+6x^2) + 36x^2] = \\ = (2+3x^2)^2 (42x^2+4)$$,The question: Differentiate $f(x)=2x(2+3x^2)^3$. How do I approach this problem? Do I only have to use the product rule...? I have the answer but I don't know how to get there. Here is my attempt to this problem: $$\frac{df}{dx}=(2)(2+3x^2)^3 + (2x)(6x)(3)(2+3x^2)^2 = \\ =(2+3x^2)^2 [(2)(2+3x^2) + (2x)(6x)(3)] = \\ = (2+3x^2)^2 [(4+6x^2) + 36x^2] = \\ = (2+3x^2)^2 (42x^2+4)$$,,"['calculus', 'derivatives']"
13,derivative problem. is it same?,derivative problem. is it same?,,"First derivative of $y=\ln(x)^{\cos x}$ is $-\sin x\ln x+\frac{\cos x}{x}$ or another answer? My friend gets another answer, but it's true? thanks.","First derivative of $y=\ln(x)^{\cos x}$ is $-\sin x\ln x+\frac{\cos x}{x}$ or another answer? My friend gets another answer, but it's true? thanks.",,['derivatives']
14,Differentiability - general function?,Differentiability - general function?,,"I know that a function is differentiable if the limit exists as $\Delta x \to 0$ of a certain limit. But how can one know this beforehand? I mean, we usually just differentiate using rules that we have derived using the limit definition, but then how we do know that the function we apply them to actually did pass the ""limit test"" and is differentiable? Is there some way to just look at a function and know whether it's differentiable or not? And not just for single variable, but for multivariables as well?","I know that a function is differentiable if the limit exists as $\Delta x \to 0$ of a certain limit. But how can one know this beforehand? I mean, we usually just differentiate using rules that we have derived using the limit definition, but then how we do know that the function we apply them to actually did pass the ""limit test"" and is differentiable? Is there some way to just look at a function and know whether it's differentiable or not? And not just for single variable, but for multivariables as well?",,['derivatives']
15,Can't get this implicit differentiation,Can't get this implicit differentiation,,"I've been working at this implicit differentiation problem for a little over an hour now, and I, nor my friends can figure it out. The question reads ""Find the equation of the tangent line to the curve (a lemniscate) $2(x^2+y^2)^2=25(x^2ây^2)$ at the point (3,1). Write the equation of the tangent line in the form $y=mx+b.$"" Every time that we do it we get a ridiculous number for the slope (${150}/{362}$)","I've been working at this implicit differentiation problem for a little over an hour now, and I, nor my friends can figure it out. The question reads ""Find the equation of the tangent line to the curve (a lemniscate) $2(x^2+y^2)^2=25(x^2ây^2)$ at the point (3,1). Write the equation of the tangent line in the form $y=mx+b.$"" Every time that we do it we get a ridiculous number for the slope (${150}/{362}$)",,"['calculus', 'derivatives']"
16,find equation of tangent line to y=1/x^2 at point where x=-1,find equation of tangent line to y=1/x^2 at point where x=-1,,"find equation of tangent line to y=1/x^2 at point where x=-1 I got the right answer by finding f'(-1)=2 and plugged (-1,1) and 2 as slope to get y-1=2(x+1) I know there's more complicated way of solving but just want to be sure if the way I did it is correct. This question does not meet our quality standard? I'm new to this and have no idea what this means.... please its easy question but our teacher didn't teach this specifically and I have a calculus test today.","find equation of tangent line to y=1/x^2 at point where x=-1 I got the right answer by finding f'(-1)=2 and plugged (-1,1) and 2 as slope to get y-1=2(x+1) I know there's more complicated way of solving but just want to be sure if the way I did it is correct. This question does not meet our quality standard? I'm new to this and have no idea what this means.... please its easy question but our teacher didn't teach this specifically and I have a calculus test today.",,"['calculus', 'derivatives']"
17,To show a function is not differentiable by sequential criterion,To show a function is not differentiable by sequential criterion,,"Define $$f: \mathbb{R} \to \mathbb{R}$$ by setting $$ f(x)=  \begin{cases}     0,& \text{if } x=\frac{1}{n} , n\in N \\     x,              & \text{otherwise} \end{cases}$$ The question is : Is $f$ differentiable at $0$?? Now $$\lim_{n \to \infty}\frac{f(\frac{1}{n})-f(0)}{\frac{1}{n}}=\lim_{n \to \infty}\frac{f(\frac{1}{n})}{\frac{1}{n}}=0$$ where as $$\lim_{n \to \infty}\frac{f(-\frac{1}{n})-f(0)}{-\frac{1}{n}}=\lim_{n\to \infty}\frac{f(-\frac{1}{n})}{-\frac{1}{n}}=1$$ What I am showing here is that the left hand derivative and the right hand derivative are not equal. Can this be generalized as :  If  there exists two sequences $\{x_n\}$ and $\{y_n\}$ such that $\{x_n\} \to a$ and $\{y_n\} \to a$, $$f'(a)=\lim_{n \to \infty}\frac{f(x_n)-f(a)}{x_n-a}\ne \lim_{n \to \infty} \frac{f(y_n)-f(a)}{y_n-a}=f'(a)$$, then $f$ is not differentiable at $a$?? Does there exist a  sequential criteria which would show something as not differentiable?? Like we have in uniform Continuity?? Thanks for the help!!","Define $$f: \mathbb{R} \to \mathbb{R}$$ by setting $$ f(x)=  \begin{cases}     0,& \text{if } x=\frac{1}{n} , n\in N \\     x,              & \text{otherwise} \end{cases}$$ The question is : Is $f$ differentiable at $0$?? Now $$\lim_{n \to \infty}\frac{f(\frac{1}{n})-f(0)}{\frac{1}{n}}=\lim_{n \to \infty}\frac{f(\frac{1}{n})}{\frac{1}{n}}=0$$ where as $$\lim_{n \to \infty}\frac{f(-\frac{1}{n})-f(0)}{-\frac{1}{n}}=\lim_{n\to \infty}\frac{f(-\frac{1}{n})}{-\frac{1}{n}}=1$$ What I am showing here is that the left hand derivative and the right hand derivative are not equal. Can this be generalized as :  If  there exists two sequences $\{x_n\}$ and $\{y_n\}$ such that $\{x_n\} \to a$ and $\{y_n\} \to a$, $$f'(a)=\lim_{n \to \infty}\frac{f(x_n)-f(a)}{x_n-a}\ne \lim_{n \to \infty} \frac{f(y_n)-f(a)}{y_n-a}=f'(a)$$, then $f$ is not differentiable at $a$?? Does there exist a  sequential criteria which would show something as not differentiable?? Like we have in uniform Continuity?? Thanks for the help!!",,"['real-analysis', 'derivatives']"
18,Differentiate $e^x+x^e$,Differentiate,e^x+x^e,"My answer was $e^x+ex^{e-1}$. As I understand it, the derivative of $e^x $ is $e^x$. As for $x^e$, I made this $e(x^{e-1})$ and simplified from there. Where was my error?","My answer was $e^x+ex^{e-1}$. As I understand it, the derivative of $e^x $ is $e^x$. As for $x^e$, I made this $e(x^{e-1})$ and simplified from there. Where was my error?",,"['calculus', 'derivatives']"
19,Is the function $y(t)$ is a solution of the equation $y'=\sin(yt)$?,Is the function  is a solution of the equation ?,y(t) y'=\sin(yt),"Is the function $y(t)$ a solution of the equation $y'=\sin(yt)$? any thought to start me up? I'm not sure what is the question asking. EDIT:  Someone tell me if I'm correct or not .  If I'm finding the general solution of the equation y'=ty, does this mean I'm finding the anti-derivative of that which is y=((t(y^2))/2)+C ? Very confused at what the question want.","Is the function $y(t)$ a solution of the equation $y'=\sin(yt)$? any thought to start me up? I'm not sure what is the question asking. EDIT:  Someone tell me if I'm correct or not .  If I'm finding the general solution of the equation y'=ty, does this mean I'm finding the anti-derivative of that which is y=((t(y^2))/2)+C ? Very confused at what the question want.",,"['ordinary-differential-equations', 'derivatives']"
20,What is the rule behind this derivative?,What is the rule behind this derivative?,,"$$\dfrac{\rm d}{{\rm d}t}\big(\sin^2(t)\big)=\sin(2t).$$ I don't understand what is the rule behind this derivation. I had tried to first rerivate sin() and then to derivate the square function, but apparently that's the wrong way.","$$\dfrac{\rm d}{{\rm d}t}\big(\sin^2(t)\big)=\sin(2t).$$ I don't understand what is the rule behind this derivation. I had tried to first rerivate sin() and then to derivate the square function, but apparently that's the wrong way.",,"['calculus', 'derivatives']"
21,How to differentiate an expression involving big-o notation?,How to differentiate an expression involving big-o notation?,,"From Apostol - Introduction to analytic number theory (Theorem 3.3) we have $$ x\geq1, \sum_{n\leq x}d(n)=x\log x+(2\gamma-1)x+O(\sqrt{x}):=E(x), $$ I want to differentiate $E$ -- to get a rough estimate for $d(n)$ -- but I don't know how to deal with the big-o part (even by proceeding with its rigorous definition doesn't get me anywhere). How to differentiate a function with a big-o? Thanks","From Apostol - Introduction to analytic number theory (Theorem 3.3) we have $$ x\geq1, \sum_{n\leq x}d(n)=x\log x+(2\gamma-1)x+O(\sqrt{x}):=E(x), $$ I want to differentiate $E$ -- to get a rough estimate for $d(n)$ -- but I don't know how to deal with the big-o part (even by proceeding with its rigorous definition doesn't get me anywhere). How to differentiate a function with a big-o? Thanks",,"['calculus', 'derivatives', 'asymptotics', 'analytic-number-theory']"
22,Strange claim by WA involving nth derivative,Strange claim by WA involving nth derivative,,"Playing a bit around with WA i found this Namely: $$\frac {d^n}{d^nx} \left(\frac x{f(x)}\right)^{n+1}=x\left(\frac 1{f(x)}\right)^{n+1}(2)_n$$ For $n\in\mathbb{N_0}$ and $n+1\ne x$ and $x \ne 0$ and $x\ne\frac1{f(x)}$ Where $(a)_n$ is the pochhammer symbol. It seems very weird to me that the n'th derivative could be expressed so simply. Is this correct, and if so how could it be proven?","Playing a bit around with WA i found this Namely: $$\frac {d^n}{d^nx} \left(\frac x{f(x)}\right)^{n+1}=x\left(\frac 1{f(x)}\right)^{n+1}(2)_n$$ For $n\in\mathbb{N_0}$ and $n+1\ne x$ and $x \ne 0$ and $x\ne\frac1{f(x)}$ Where $(a)_n$ is the pochhammer symbol. It seems very weird to me that the n'th derivative could be expressed so simply. Is this correct, and if so how could it be proven?",,"['derivatives', 'pochhammer-symbol']"
23,Does the symmetric decreasing rearrangement of a smooth function preserve smoothness?,Does the symmetric decreasing rearrangement of a smooth function preserve smoothness?,,"Let $A\subset \mathbb{R}^n$ a Borel set of finite Lebesgue measure. They define   $A^*$ to be the ball centered at 0 with the same measure that   $A$. The symmetric-decreasing rearrangement of a measurable function $f:\mathbb{R}^n \to \mathbb{R}$ is then defined by $$f^*(x):=\int_0^{\infty} \chi_{\{|f|>t\}^*}(x)dt,$$ by comparison to the ""layercake"" representation of $f$, namely   $$f(x)=\int_0^{\infty} \chi_{\{f>t\}}(x)dt.$$ Note that one can equally define $f^*$ to be the radial symmetric, decreasing function such that the level sets of $f^*$ and $f$ have the same measure (or volume). I don't know why, but it always occurs to me that the rearrangement process is a regularizing process. Here's my question: If $f$ is $k$ times continuously differentiable, does it follow that $f^*$ possesses the same regularity?","Let $A\subset \mathbb{R}^n$ a Borel set of finite Lebesgue measure. They define   $A^*$ to be the ball centered at 0 with the same measure that   $A$. The symmetric-decreasing rearrangement of a measurable function $f:\mathbb{R}^n \to \mathbb{R}$ is then defined by $$f^*(x):=\int_0^{\infty} \chi_{\{|f|>t\}^*}(x)dt,$$ by comparison to the ""layercake"" representation of $f$, namely   $$f(x)=\int_0^{\infty} \chi_{\{f>t\}}(x)dt.$$ Note that one can equally define $f^*$ to be the radial symmetric, decreasing function such that the level sets of $f^*$ and $f$ have the same measure (or volume). I don't know why, but it always occurs to me that the rearrangement process is a regularizing process. Here's my question: If $f$ is $k$ times continuously differentiable, does it follow that $f^*$ possesses the same regularity?",,"['real-analysis', 'measure-theory', 'derivatives', 'decreasing-rearrangements']"
24,$n$th derivative of $f(x)$ using limit definition,th derivative of  using limit definition,n f(x),"After playing around with the limit definition of the derivative for higher order derivatives, I noticed the following odd relationship to determine it for an nth order derivative: Let $F^n=f(x+nh)$ (is there a way to write this properly as an operator on $f(x)$?), then $$f^{(n)}(x)=\lim_{h\to0}\frac{(F-1)^n}{h^n}=\left(\lim_{h\to0} \frac{F-1}{h}\right)^n$$ Expanding the middle equality gives it in terms of $f(x+nh)$s. Notice that the inside of the bracket on the RHS is equal to $f'(x)$ (sort of). I have actually proven that this is indeed true using repeated use of L'Hopital's law and proof by induction, but I am unsatisfied. The result in the form above seems almost magical, and makes me think there is a very elegant reason why. Can someone explain why? Based on the result, I suspect umbral calculus gives a nice explanation, but I do not know a lot about it.  So can someone explain why the above has such an elegant form? NOTE : I realise that this is similar to this question , but that question is asking about if it's true; I already know it's true, but I'm asking why it's true based on the magical form above. Also, I don't care that this evaluates certain derivatives that shouldn't exist (but does correctly evaluate those that do), so do not worry about that.","After playing around with the limit definition of the derivative for higher order derivatives, I noticed the following odd relationship to determine it for an nth order derivative: Let $F^n=f(x+nh)$ (is there a way to write this properly as an operator on $f(x)$?), then $$f^{(n)}(x)=\lim_{h\to0}\frac{(F-1)^n}{h^n}=\left(\lim_{h\to0} \frac{F-1}{h}\right)^n$$ Expanding the middle equality gives it in terms of $f(x+nh)$s. Notice that the inside of the bracket on the RHS is equal to $f'(x)$ (sort of). I have actually proven that this is indeed true using repeated use of L'Hopital's law and proof by induction, but I am unsatisfied. The result in the form above seems almost magical, and makes me think there is a very elegant reason why. Can someone explain why? Based on the result, I suspect umbral calculus gives a nice explanation, but I do not know a lot about it.  So can someone explain why the above has such an elegant form? NOTE : I realise that this is similar to this question , but that question is asking about if it's true; I already know it's true, but I'm asking why it's true based on the magical form above. Also, I don't care that this evaluates certain derivatives that shouldn't exist (but does correctly evaluate those that do), so do not worry about that.",,"['calculus', 'limits', 'derivatives', 'operator-theory']"
25,Confirm right model,Confirm right model,,"Have a Khan problem I've been working under the ""Related Rates"" category. GIVEN: A 2 meter tall boy ""h"" is rollerskating away from a 5 meter  lantern at constant dx/dt = 2 meters per second. How fast is the tip of his shadow ""s"" moving away from the  lantern (ds/dt in meters per second) when the boy is 7 meters  from it? /GIVEN My model is ""s"", the solution model offered is s'. My model: 5/(s + x) = 2/s 5s/(s + x) = 2 5s = 2(s + x) 5s = 2s + 2x 3s = 2x s = 2x/3 d/dt(s) = d/dt(2x/3) d/dt(s) = 2/3*d/dt(x) ds/dt = 2/3*dx/dt dx/dt = 2 ds/dt = 2/3*2 ds/dt = [4/3] Solution Model: Let x be the distance from the base of the lantern to the boy; s be the distance from the base of the lantern to the tip  of the shadow. Then dx/dt = 2m/sec and ds/dt is the speed at which the  tip of the boy's shadow is moving away from the lantern. Based on similar triangles we know that: s/(lantern height) = (s â x)/(boy's height) That is, s/5 = (s â x)/2 We solve this equation for s in terms of x. 2s = 5s - 5x 5x = 3s s = 5x/3 Take the derivative with respect to time of both sides. ds/dt = 5/3*dx/dt Since we are given thatdx/dt = 2 msec, we conclude that ds/dt = 5/3*(2m/sec) = [10/3]m/sec ??? I maintain my model is more correct based on the constraints of the given information. I don't see how the actual shadow ""s"" can be set to the overall length as depicted with s'. Any thouhgts?","Have a Khan problem I've been working under the ""Related Rates"" category. GIVEN: A 2 meter tall boy ""h"" is rollerskating away from a 5 meter  lantern at constant dx/dt = 2 meters per second. How fast is the tip of his shadow ""s"" moving away from the  lantern (ds/dt in meters per second) when the boy is 7 meters  from it? /GIVEN My model is ""s"", the solution model offered is s'. My model: 5/(s + x) = 2/s 5s/(s + x) = 2 5s = 2(s + x) 5s = 2s + 2x 3s = 2x s = 2x/3 d/dt(s) = d/dt(2x/3) d/dt(s) = 2/3*d/dt(x) ds/dt = 2/3*dx/dt dx/dt = 2 ds/dt = 2/3*2 ds/dt = [4/3] Solution Model: Let x be the distance from the base of the lantern to the boy; s be the distance from the base of the lantern to the tip  of the shadow. Then dx/dt = 2m/sec and ds/dt is the speed at which the  tip of the boy's shadow is moving away from the lantern. Based on similar triangles we know that: s/(lantern height) = (s â x)/(boy's height) That is, s/5 = (s â x)/2 We solve this equation for s in terms of x. 2s = 5s - 5x 5x = 3s s = 5x/3 Take the derivative with respect to time of both sides. ds/dt = 5/3*dx/dt Since we are given thatdx/dt = 2 msec, we conclude that ds/dt = 5/3*(2m/sec) = [10/3]m/sec ??? I maintain my model is more correct based on the constraints of the given information. I don't see how the actual shadow ""s"" can be set to the overall length as depicted with s'. Any thouhgts?",,"['calculus', 'derivatives']"
26,Lyapunov function for non-autonomous non-linear differential equations,Lyapunov function for non-autonomous non-linear differential equations,,"I have read some lecture notes about Lyapunovâs Second Method for autonomous system. Now, I want to deal with the stability of a non-autonomous system. Suppose there is a non-autonomous non-linear differential equations: $$\frac{dx}{dt}=f(x,t)$$ In order to use Lyapunovâs Second Method for the system, the books state that Lyapunov function $W(x,t)$ is needed. I would like to know whether $W(x,t)$ can be constant of $t$. That is, $W(x,t)$ is just a positive definite $V(x)$ which does not involve $t$ certainly. Actually, I have constructed a $V(x)$ and shown that $\frac{dV(x)}{dt}=\frac{dV(x)}{dx}\cdot f(x,t)<0, \forall x$ and $\forall t>0$. Is this sufficient to show the system is Lyapunov stable and even asymptotically stable?","I have read some lecture notes about Lyapunovâs Second Method for autonomous system. Now, I want to deal with the stability of a non-autonomous system. Suppose there is a non-autonomous non-linear differential equations: $$\frac{dx}{dt}=f(x,t)$$ In order to use Lyapunovâs Second Method for the system, the books state that Lyapunov function $W(x,t)$ is needed. I would like to know whether $W(x,t)$ can be constant of $t$. That is, $W(x,t)$ is just a positive definite $V(x)$ which does not involve $t$ certainly. Actually, I have constructed a $V(x)$ and shown that $\frac{dV(x)}{dt}=\frac{dV(x)}{dx}\cdot f(x,t)<0, \forall x$ and $\forall t>0$. Is this sufficient to show the system is Lyapunov stable and even asymptotically stable?",,"['integration', 'ordinary-differential-equations', 'derivatives', 'special-functions', 'nonlinear-system']"
27,Extrema and inflection points of the function $y = \cos^2(x) - \cos(x)$,Extrema and inflection points of the function,y = \cos^2(x) - \cos(x),"Please help me find the extrema and inflection points of the function $y = \cos^2(x) - \cos(x)$. So far: $$y'=-2 \cos(x)\sin(x)+\sin(x)$$ $$y'' = 2\sin^2(x) - 2\cos^2(x) + \cos(x)$$ $y' = 0$ when $x = 0, \pi, \pi/3, 5\pi/3$ I plugged these values into $y''$ to find min/max which are as follows: $x = 0, \pi$ : MAX $x =  \pi/3$, $5\pi/3$ : MIN The issue I have is finding the inflection points, i used the quadratic formula to solve for $\cos(x)$ by converting (via trig ID's) $y'' = 2\sin^2(x) + 2\cos^2(x) + \cos(x)$ to $y'' = -2\cos^2(x) + \cos(x) = 0$ which gave me $\cos(x) = 0, 1/2$, and $x = \pi/2, 3\pi/2, \pi/3, 5\pi/3$ The solution shows that the inflection points are at $x = 32$ deg $32', 126$ deg $23', 233$ deg $37'$, and $327$ deg $28' $ Can you please help by showing how these inflection points were solved for? Where did I make my mistake? I have no idea how they got those degrees.","Please help me find the extrema and inflection points of the function $y = \cos^2(x) - \cos(x)$. So far: $$y'=-2 \cos(x)\sin(x)+\sin(x)$$ $$y'' = 2\sin^2(x) - 2\cos^2(x) + \cos(x)$$ $y' = 0$ when $x = 0, \pi, \pi/3, 5\pi/3$ I plugged these values into $y''$ to find min/max which are as follows: $x = 0, \pi$ : MAX $x =  \pi/3$, $5\pi/3$ : MIN The issue I have is finding the inflection points, i used the quadratic formula to solve for $\cos(x)$ by converting (via trig ID's) $y'' = 2\sin^2(x) + 2\cos^2(x) + \cos(x)$ to $y'' = -2\cos^2(x) + \cos(x) = 0$ which gave me $\cos(x) = 0, 1/2$, and $x = \pi/2, 3\pi/2, \pi/3, 5\pi/3$ The solution shows that the inflection points are at $x = 32$ deg $32', 126$ deg $23', 233$ deg $37'$, and $327$ deg $28' $ Can you please help by showing how these inflection points were solved for? Where did I make my mistake? I have no idea how they got those degrees.",,"['calculus', 'derivatives']"
28,maximum curvature of 2D Cubic Bezier,maximum curvature of 2D Cubic Bezier,,"Given a 2D cubic Bezier segment defined by $P_0, P_1, P_2, P_3$, here's what I want: A function that takes the segment and outputs the maximum curvature without using an iterative approach. I have a function that finds the maximum curvature at the moment, but does this using Brent's Method to search a range of $t$ on $[0, 1]$. It fails to find the maximum curvature $5\%$ of the time. In addition, I really need the Jacobian of the method to help my optimization algorithms. Brent's Method (or any kind of iterative search) makes this impossible. I recognize that this is a difficult function to deal with by hand, but perhaps someone with access to some nice software and a fancy machine could crank out a function to find the maximum curvature of a cubic Bezier? Something that symbolically returns the roots of solving the derivative of the curvature? Thanks for your time.","Given a 2D cubic Bezier segment defined by $P_0, P_1, P_2, P_3$, here's what I want: A function that takes the segment and outputs the maximum curvature without using an iterative approach. I have a function that finds the maximum curvature at the moment, but does this using Brent's Method to search a range of $t$ on $[0, 1]$. It fails to find the maximum curvature $5\%$ of the time. In addition, I really need the Jacobian of the method to help my optimization algorithms. Brent's Method (or any kind of iterative search) makes this impossible. I recognize that this is a difficult function to deal with by hand, but perhaps someone with access to some nice software and a fancy machine could crank out a function to find the maximum curvature of a cubic Bezier? Something that symbolically returns the roots of solving the derivative of the curvature? Thanks for your time.",,"['derivatives', 'curvature', 'bezier-curve']"
29,How to get the Normal line?,How to get the Normal line?,,"My book proposed to me to find the the Normal lines to the curve that pass through the origin.The answer must be the intersection points between them. The curve: $\dfrac{2}{1+x^2}$ My first idea is to get the derivative: $f'(x) = $ $\frac{-4x}{x^4 + 2x^2 + 1}$, then get the perpendicular of $f'(x)$, resulting in  $M = \dfrac{-1}{f'(x)}$ = $\dfrac{x^4 + 2x^2 + 1}{4x}$. The segment that pass through the origin with the angular coeficient $M$ is: $g(x) = M * (x - x0) + y0$; to $x0$ = 0 and $y0$ = 0. So, $g(x) = \dfrac{x^4 + 2x^2 + 1}{4}$ Finally to get the common points between $g(x)$ and $f(x)$, I have the equality: $f(x) = g(x)$. $\dfrac{x^4 + 2x^2 + 1}{4}$ = $\dfrac{2}{x^2 + 1}$ Resulting in two real solutions: $x = -1$ and $x = 1$ and another four complex roots. If you look carefully, we can see a ""hidden"" solution at x = 0. Is it the right way to procced to get the points !?","My book proposed to me to find the the Normal lines to the curve that pass through the origin.The answer must be the intersection points between them. The curve: $\dfrac{2}{1+x^2}$ My first idea is to get the derivative: $f'(x) = $ $\frac{-4x}{x^4 + 2x^2 + 1}$, then get the perpendicular of $f'(x)$, resulting in  $M = \dfrac{-1}{f'(x)}$ = $\dfrac{x^4 + 2x^2 + 1}{4x}$. The segment that pass through the origin with the angular coeficient $M$ is: $g(x) = M * (x - x0) + y0$; to $x0$ = 0 and $y0$ = 0. So, $g(x) = \dfrac{x^4 + 2x^2 + 1}{4}$ Finally to get the common points between $g(x)$ and $f(x)$, I have the equality: $f(x) = g(x)$. $\dfrac{x^4 + 2x^2 + 1}{4}$ = $\dfrac{2}{x^2 + 1}$ Resulting in two real solutions: $x = -1$ and $x = 1$ and another four complex roots. If you look carefully, we can see a ""hidden"" solution at x = 0. Is it the right way to procced to get the points !?",,"['calculus', 'derivatives']"
30,Sobolev Spaces and Derivative,Sobolev Spaces and Derivative,,"I need help on the problem 8.9 at page 238 of the book ""Functional Analysis, Sobolev Spaces and Partial Differential Equations"" by Haim Brezis. Set $I=(0,1)$. Let $u \in W^{2,p}(I)$ with $1<p<\infty$. Assume that $u(0)=u'(0)=0$. Show that  $$\frac{u(x)}{x^2}\in L^p(I)\quad\text{and}\quad \frac{u'(x)}{x}\in L^p(I),$$ with  $$\left|\left|\frac{u(x)}{x^2}\right|\right|_{L^p(I)}+ \left|\left|\frac{u'(x)}{x}\right|\right|_{L^p(I)} \leq C_p\left|\left|u''\right|\right|_{L^p(I)}.$$ Thank you in advance for any help.","I need help on the problem 8.9 at page 238 of the book ""Functional Analysis, Sobolev Spaces and Partial Differential Equations"" by Haim Brezis. Set $I=(0,1)$. Let $u \in W^{2,p}(I)$ with $1<p<\infty$. Assume that $u(0)=u'(0)=0$. Show that  $$\frac{u(x)}{x^2}\in L^p(I)\quad\text{and}\quad \frac{u'(x)}{x}\in L^p(I),$$ with  $$\left|\left|\frac{u(x)}{x^2}\right|\right|_{L^p(I)}+ \left|\left|\frac{u'(x)}{x}\right|\right|_{L^p(I)} \leq C_p\left|\left|u''\right|\right|_{L^p(I)}.$$ Thank you in advance for any help.",,"['functional-analysis', 'derivatives', 'sobolev-spaces']"
31,Help solving this related rates problem.,Help solving this related rates problem.,,"The question: A car leaves an intersection traveling east. Its position t sec later is given by  $x = t^2 + t$ ft. At the same time, another car leaves the same intersection heading north, traveling  $y = t^2 + 5t$ ft  in t sec. Find the rate at which the distance between the two cars will be changing 5 sec later. (Round your answer to one decimal place.) So what I have from this is $$x=30,y=50,\frac{dx}{dt}=10,\frac{dy}{dt}=15,z=\sqrt{3,400}$$ I found $\frac{dx}{dt}$and $\frac{dy}{dt}$ by differentiating $x = t^2 + t$ and $y = t^2 + 5t$ and then plugging in 5 for $t$. (Not sure if right) So I have $x^2+y^2=z^2$ so $$2x\frac{dx}{dt}+2y\frac{dy}{dt}=2z\frac{dz}{dt}$$ and after plugging in the values I THINK I know I end up with $$\frac{60(10)+100(15)}{2\sqrt{3,400}}$$ which is around 18.007 but the answer is 18.5 rounded. So where am I going wrong? All help is appreciated!","The question: A car leaves an intersection traveling east. Its position t sec later is given by  $x = t^2 + t$ ft. At the same time, another car leaves the same intersection heading north, traveling  $y = t^2 + 5t$ ft  in t sec. Find the rate at which the distance between the two cars will be changing 5 sec later. (Round your answer to one decimal place.) So what I have from this is $$x=30,y=50,\frac{dx}{dt}=10,\frac{dy}{dt}=15,z=\sqrt{3,400}$$ I found $\frac{dx}{dt}$and $\frac{dy}{dt}$ by differentiating $x = t^2 + t$ and $y = t^2 + 5t$ and then plugging in 5 for $t$. (Not sure if right) So I have $x^2+y^2=z^2$ so $$2x\frac{dx}{dt}+2y\frac{dy}{dt}=2z\frac{dz}{dt}$$ and after plugging in the values I THINK I know I end up with $$\frac{60(10)+100(15)}{2\sqrt{3,400}}$$ which is around 18.007 but the answer is 18.5 rounded. So where am I going wrong? All help is appreciated!",,"['calculus', 'derivatives', 'implicit-differentiation']"
32,Differentiation of a parametric function using MATLAB or Maple,Differentiation of a parametric function using MATLAB or Maple,,"I'm doing some mathematical calculation of some symbolic math that includes multiplication and differentiation of some matrices. Some of the parameters in my calculations are functions of time. for example I have sin(p) where p is a function of time and when differentiating, it should be like p(dot)*cos(p). There are very big matrices that have large expressions like this and I should differentiate them. The problem is that I can't perform this in MATLAB (symbolic math toolbox) or Maple.","I'm doing some mathematical calculation of some symbolic math that includes multiplication and differentiation of some matrices. Some of the parameters in my calculations are functions of time. for example I have sin(p) where p is a function of time and when differentiating, it should be like p(dot)*cos(p). There are very big matrices that have large expressions like this and I should differentiate them. The problem is that I can't perform this in MATLAB (symbolic math toolbox) or Maple.",,"['derivatives', 'matlab', 'maple']"
33,Derivative function went wrong,Derivative function went wrong,,"I am trying to take the derivative of this function but I am facing some difficulties. $$f(x)= e^{\ln(e^{7x^2+11})}$$ My answer was : $7e^{(7(x^2))}*14x$  I cancelled the $\ln$ with the $e$ first, then I downgrade the $7$ and keep the $\exp$. as it is, after that I took the derivative of the $7x^2$ and the result was the one on top.","I am trying to take the derivative of this function but I am facing some difficulties. $$f(x)= e^{\ln(e^{7x^2+11})}$$ My answer was : $7e^{(7(x^2))}*14x$  I cancelled the $\ln$ with the $e$ first, then I downgrade the $7$ and keep the $\exp$. as it is, after that I took the derivative of the $7x^2$ and the result was the one on top.",,"['calculus', 'derivatives']"
34,Derivative of rational function help.,Derivative of rational function help.,,"consider $$f(x)=\frac{1}{2x-4}$$ The derivative should be $\displaystyle -\frac{1}{2(2x-4)^2}$ However I get $\displaystyle -\frac{2}{(2x-4)^2}$ my workflow:  $$\begin{array}{} f'(x)&= &(2x-4)^{-1}  \\ &=&-1(2)(2x-4)^{-2}  \\ &=&-2(2x-4)^{-2}  \end{array}$$ So why does the -2 multiply the denominator and not the numerator? After all, $\displaystyle 2\frac{1}{2}$ is 1 not $\displaystyle \frac{1}{4}$. I feel like I'm missing the obvious. Thanks all.","consider $$f(x)=\frac{1}{2x-4}$$ The derivative should be $\displaystyle -\frac{1}{2(2x-4)^2}$ However I get $\displaystyle -\frac{2}{(2x-4)^2}$ my workflow:  $$\begin{array}{} f'(x)&= &(2x-4)^{-1}  \\ &=&-1(2)(2x-4)^{-2}  \\ &=&-2(2x-4)^{-2}  \end{array}$$ So why does the -2 multiply the denominator and not the numerator? After all, $\displaystyle 2\frac{1}{2}$ is 1 not $\displaystyle \frac{1}{4}$. I feel like I'm missing the obvious. Thanks all.",,"['calculus', 'derivatives', 'rational-functions']"
35,Find equation of a curve by tangent,Find equation of a curve by tangent,,"This is probaly easy. Find the equation of the tangent to a curve $y = u (x)$ is $y =(-2a+4)(x-a)+k$, where $k$ is a constant. Given that the curve touches the $x$-axis at $x =2$,  find the value of $k$ and the equation of the curve.","This is probaly easy. Find the equation of the tangent to a curve $y = u (x)$ is $y =(-2a+4)(x-a)+k$, where $k$ is a constant. Given that the curve touches the $x$-axis at $x =2$,  find the value of $k$ and the equation of the curve.",,['derivatives']
36,Proving that a function is nowhere differentiable,Proving that a function is nowhere differentiable,,"I'm just going over a bit of revision for an upcoming exam, and I just wanted to verify whether my working/argument was sound. I've been asked to show that $f(z) = \frac{1}{\overline{z}}$ is nowhere differentiable on $\mathbb{C} \setminus \{0\}$ I started by letting $z = re^{i\theta}$, with $\overline{z} = re^{-i\theta}$. Then, I have; $$f(z) = \frac{1}{re^{-i \theta}} = \frac{1}{r} \cdot e^{i\theta}$$ Then, I set; $$u = \frac{\cos(\theta)}{r}, v = \frac{\sin(\theta)}{r}$$ And used the Cauchy-Riemann equations for polar co-ordinates to show the following (I skipped out a lot of working, but I'm quite confident that I'm correct with it); $$\frac{\partial u}{\partial r} = \frac{1}{r} \cdot \frac{\partial v}{\partial \theta} \Rightarrow \frac{-\cos(\theta)}{r^2} = \frac{\cos(\theta)}{r^2} \Rightarrow 0 = 2 \cdot\cos(\theta) \Rightarrow \theta = \frac{\pi}{2} + n\pi$$ $$\frac{\partial v}{\partial r} = \frac{-1}{r} \cdot \frac{\partial u}{\partial \theta} \Rightarrow \frac{-\sin(\theta)}{r^2} = \frac{\sin(\theta)}{r^2} \Rightarrow 0 = 2 \cdot\sin(\theta) \Rightarrow \theta = n\pi$$ (In both cases, $n \in \mathbb{Z}$) Hence, for these equations to be satisfied, we must have $n\pi = \frac{\pi}{2} + n\pi$, which has no solutions, so $f(z)$ is nowhere differentiable. Is that sound enough?? Or should I be using a limit approach??","I'm just going over a bit of revision for an upcoming exam, and I just wanted to verify whether my working/argument was sound. I've been asked to show that $f(z) = \frac{1}{\overline{z}}$ is nowhere differentiable on $\mathbb{C} \setminus \{0\}$ I started by letting $z = re^{i\theta}$, with $\overline{z} = re^{-i\theta}$. Then, I have; $$f(z) = \frac{1}{re^{-i \theta}} = \frac{1}{r} \cdot e^{i\theta}$$ Then, I set; $$u = \frac{\cos(\theta)}{r}, v = \frac{\sin(\theta)}{r}$$ And used the Cauchy-Riemann equations for polar co-ordinates to show the following (I skipped out a lot of working, but I'm quite confident that I'm correct with it); $$\frac{\partial u}{\partial r} = \frac{1}{r} \cdot \frac{\partial v}{\partial \theta} \Rightarrow \frac{-\cos(\theta)}{r^2} = \frac{\cos(\theta)}{r^2} \Rightarrow 0 = 2 \cdot\cos(\theta) \Rightarrow \theta = \frac{\pi}{2} + n\pi$$ $$\frac{\partial v}{\partial r} = \frac{-1}{r} \cdot \frac{\partial u}{\partial \theta} \Rightarrow \frac{-\sin(\theta)}{r^2} = \frac{\sin(\theta)}{r^2} \Rightarrow 0 = 2 \cdot\sin(\theta) \Rightarrow \theta = n\pi$$ (In both cases, $n \in \mathbb{Z}$) Hence, for these equations to be satisfied, we must have $n\pi = \frac{\pi}{2} + n\pi$, which has no solutions, so $f(z)$ is nowhere differentiable. Is that sound enough?? Or should I be using a limit approach??",,"['complex-analysis', 'derivatives']"
37,Question about Differentials,Question about Differentials,,"I am reading the book ""Advanced Calculus"" written by Kaplan, and here is what I have: Suppose that $y(x)$ is a differentiable function at $x = x_0$ . Then, we can write $y(x_0+\Delta x) = y(x_0) + y'(x_0)\cdot \Delta x + \epsilon\cdot \Delta x, \, where \, \epsilon \rightarrow 0  \:  as \, \Delta x \rightarrow 0$ . We denote the differential of $y$ by $dy = y'(x_0)\cdot\Delta x$ . Now note that if $g(x) = x$ , then $g$ is clearly differentiable at $x = x_0$ , so we have $dg = dx = 1\cdot\Delta x$ , from which it follows that $dy =   y'(x_0)\cdot\Delta x=  y'(x_0)\cdot dx$ Also, if $y'(x_0) \neq 0 $ , we can write $dx = \dfrac{1}{y'(x_0)}dy$ I am uncomfortable with the last line $dx = \dfrac{1}{y'(x_0)}dy$ because I think that in order for this expression to be ""meaningful"", it must be true that x can be written as a function of y, and this function must be differentiable at $y = f(x_0)$ . But, as far as I know, mere existence of nonzero derivative of $f(x)$ at $x=x_0$ does not imply the invertibility of y(x), let alone its differentiability. To illustrate my point, say, for instance, that we have $y(2) = 1$ and $y'(2)= 3$ so that $dy = 3dx$ Then, according to Kaplan, we can write $dx = \dfrac{1}{3}dy$ . But then, if somone else sees only $dx = \dfrac{1}{3}dy$ at $(x,y) = (1,2)$ , then he/she would think that x is a function of y with $x(1) = 2$ and $x'(1) = \dfrac{1}{3}$ . But, the fact that $y(2) = 1$ and $y'(2) = 3$ does not imply $x(1) = 2$ and $x'(1) = \dfrac{1}{3}$ . Right? How can you freely move around $dy$ and $dx$ as if it does not matter which variable is an independent varible?","I am reading the book ""Advanced Calculus"" written by Kaplan, and here is what I have: Suppose that is a differentiable function at . Then, we can write . We denote the differential of by . Now note that if , then is clearly differentiable at , so we have , from which it follows that Also, if , we can write I am uncomfortable with the last line because I think that in order for this expression to be ""meaningful"", it must be true that x can be written as a function of y, and this function must be differentiable at . But, as far as I know, mere existence of nonzero derivative of at does not imply the invertibility of y(x), let alone its differentiability. To illustrate my point, say, for instance, that we have and so that Then, according to Kaplan, we can write . But then, if somone else sees only at , then he/she would think that x is a function of y with and . But, the fact that and does not imply and . Right? How can you freely move around and as if it does not matter which variable is an independent varible?","y(x) x = x_0 y(x_0+\Delta x) = y(x_0) + y'(x_0)\cdot \Delta x + \epsilon\cdot \Delta x, \, where \, \epsilon \rightarrow 0  \:  as \, \Delta x \rightarrow 0 y dy = y'(x_0)\cdot\Delta x g(x) = x g x = x_0 dg = dx = 1\cdot\Delta x dy =   y'(x_0)\cdot\Delta x=  y'(x_0)\cdot dx y'(x_0) \neq 0  dx = \dfrac{1}{y'(x_0)}dy dx = \dfrac{1}{y'(x_0)}dy y = f(x_0) f(x) x=x_0 y(2) = 1 y'(2)= 3 dy = 3dx dx = \dfrac{1}{3}dy dx = \dfrac{1}{3}dy (x,y) = (1,2) x(1) = 2 x'(1) = \dfrac{1}{3} y(2) = 1 y'(2) = 3 x(1) = 2 x'(1) = \dfrac{1}{3} dy dx","['calculus', 'real-analysis', 'derivatives']"
38,"Derivative of determinant, which is correct?","Derivative of determinant, which is correct?",,I've seen two different results on the derivatives of determinants of matrices: $$\frac{\partial |X|}{\partial X_{ij}}=X_{ij}.\tag1$$ $$\frac{\partial\det(X)}{\partial X}=|X|(X^{-1})^{T}.\tag2$$ These seem to imply different things. Which is right and why? Can't find it proven anywhere.,I've seen two different results on the derivatives of determinants of matrices: $$\frac{\partial |X|}{\partial X_{ij}}=X_{ij}.\tag1$$ $$\frac{\partial\det(X)}{\partial X}=|X|(X^{-1})^{T}.\tag2$$ These seem to imply different things. Which is right and why? Can't find it proven anywhere.,,"['linear-algebra', 'derivatives']"
39,Frechet/Gateaux differentiability of an integral operator $L^2 \rightarrow R$,Frechet/Gateaux differentiability of an integral operator,L^2 \rightarrow R,"Let $f: R \rightarrow R$ be a continuously differentiable function on the real numbers (if needed also infinitely many often differentiable). Define the Operator $F : L^2([0,1]) \rightarrow R$ for $x \in L^2([0,1])$ by $F(x)=\int_0^1 f(x(s)) ds $ We assume that $F(x)<AâBâ«x(s)^2 ds\leq A$ with constants $A,B>0$ . Hence it is bounded from above but not from below Question: Is $F$ now Frechet differentiable? Is $F$ Gateaux differentiable? Known: If we were looking at $F$ as an operator on $C([0,1])$ , then it is Frechet differentiable (as shown for example at wikipedia: http://de.wikipedia.org/wiki/FrÃ©chet-Ableitung#Integraloperator ) But they use that on this space they know that each function is bounded.","Let be a continuously differentiable function on the real numbers (if needed also infinitely many often differentiable). Define the Operator for by We assume that with constants . Hence it is bounded from above but not from below Question: Is now Frechet differentiable? Is Gateaux differentiable? Known: If we were looking at as an operator on , then it is Frechet differentiable (as shown for example at wikipedia: http://de.wikipedia.org/wiki/FrÃ©chet-Ableitung#Integraloperator ) But they use that on this space they know that each function is bounded.","f: R \rightarrow R F : L^2([0,1]) \rightarrow R x \in L^2([0,1]) F(x)=\int_0^1 f(x(s)) ds  F(x)<AâBâ«x(s)^2 ds\leq A A,B>0 F F F C([0,1])","['functional-analysis', 'derivatives', 'operator-theory', 'gateaux-derivative']"
40,Is a bounded continuous function defined on $\Bbb R$ differentiable?,Is a bounded continuous function defined on  differentiable?,\Bbb R,"Is a bounded continuous function defined on $\Bbb R$ differentiable? Why so? The query is fueled by the following question: Let $f : \Bbb R \rightarrow \Bbb R$ be a bounded continuous function. Define $ g : [0,\infty) \rightarrow \Bbb R$ by $$g(x) = \int_{-x}^x (2xt + 1)f(t)dt .$$ Show that $g$ is differentiable on $(0,\infty)$ and find the derivative of $g$.","Is a bounded continuous function defined on $\Bbb R$ differentiable? Why so? The query is fueled by the following question: Let $f : \Bbb R \rightarrow \Bbb R$ be a bounded continuous function. Define $ g : [0,\infty) \rightarrow \Bbb R$ by $$g(x) = \int_{-x}^x (2xt + 1)f(t)dt .$$ Show that $g$ is differentiable on $(0,\infty)$ and find the derivative of $g$.",,"['calculus', 'real-analysis', 'derivatives', 'examples-counterexamples']"
41,Is the function $f(x)=x$ on $\{\pm\frac1n:n\in\Bbb N\}$ differentiable at $0$?,Is the function  on  differentiable at ?,f(x)=x \{\pm\frac1n:n\in\Bbb N\} 0,"This is really a question of definitions. If a function $f$ is not defined on an open set containing $x$, how do we define the derivative of $f$? Is it sufficient to be locally approximable by linear functions on its points of definition, or do we consider the function not differentiable here? I am interested in defining a function $D:\Bbb R^{\subseteq\Bbb R}\to\Bbb R^{\subseteq\Bbb R}$ such that $x\in\operatorname{dom}D(f)$ and $D(f)(x)=f'(x)$ whenever $f$ is differentiable at $x$. When $f$ has a peculiar domain in the neighborhood of $x$, the exact definition of the limit is confusing me. What is the derivative at an isolated point? Edit: Here is my proposed definition for a derivative, defined as a predicate on possible limits, that makes sense when $x_0$ is an accumulation point of $A$, the domain of $f$, even if $x_0\notin A$: $f$ has derivative $L$ at $x_0$ iff for all $\varepsilon>0$, there is a $\delta$ such that for any $x,y$, $$x,y\in A\cap B(x_0,\delta)\wedge x\ne y\implies\left|\frac{f(x)-f(y)}{x-y}-L\right|<\varepsilon.$$ This definition actually makes sense even if $x_0$ is an isolated point or an exterior point of $A$, but in these cases $f$ has every number as a derivative (by contrast to when $f$ is genuinely not differentiable in the conventional sense, in which case no number is a derivative). If one adds the proviso ""$x_0$ is an interior point of $A\cup\{x_0\}$"", one recovers the conventional definition, except that the point $x_0$ is not required to be defined, which allows you to patch over removable singularities.","This is really a question of definitions. If a function $f$ is not defined on an open set containing $x$, how do we define the derivative of $f$? Is it sufficient to be locally approximable by linear functions on its points of definition, or do we consider the function not differentiable here? I am interested in defining a function $D:\Bbb R^{\subseteq\Bbb R}\to\Bbb R^{\subseteq\Bbb R}$ such that $x\in\operatorname{dom}D(f)$ and $D(f)(x)=f'(x)$ whenever $f$ is differentiable at $x$. When $f$ has a peculiar domain in the neighborhood of $x$, the exact definition of the limit is confusing me. What is the derivative at an isolated point? Edit: Here is my proposed definition for a derivative, defined as a predicate on possible limits, that makes sense when $x_0$ is an accumulation point of $A$, the domain of $f$, even if $x_0\notin A$: $f$ has derivative $L$ at $x_0$ iff for all $\varepsilon>0$, there is a $\delta$ such that for any $x,y$, $$x,y\in A\cap B(x_0,\delta)\wedge x\ne y\implies\left|\frac{f(x)-f(y)}{x-y}-L\right|<\varepsilon.$$ This definition actually makes sense even if $x_0$ is an isolated point or an exterior point of $A$, but in these cases $f$ has every number as a derivative (by contrast to when $f$ is genuinely not differentiable in the conventional sense, in which case no number is a derivative). If one adds the proviso ""$x_0$ is an interior point of $A\cup\{x_0\}$"", one recovers the conventional definition, except that the point $x_0$ is not required to be defined, which allows you to patch over removable singularities.",,"['real-analysis', 'derivatives', 'definition']"
42,"Calculate the derivative of $Î(z,v)$ with respect to $z$",Calculate the derivative of  with respect to,"Î(z,v) z","Let $Î(z,v)=â«_{v}^{+â}t^{z-1}e^{-t}dt$ be the incomplete $Î$-function. My question is: Calculate the derivative of $Î(z,v)$ with respect to $z$.","Let $Î(z,v)=â«_{v}^{+â}t^{z-1}e^{-t}dt$ be the incomplete $Î$-function. My question is: Calculate the derivative of $Î(z,v)$ with respect to $z$.",,"['derivatives', 'gamma-function']"
43,Find the derivative of $1/\sqrt{1+x^2-\cos^2x-e^{2\pi \cos(\sin 1/x)}}$,Find the derivative of,1/\sqrt{1+x^2-\cos^2x-e^{2\pi \cos(\sin 1/x)}},"(calculus) How can I prove that $$\frac{d}{dx}\frac{1}{\sqrt{1+x^2-\cos^2x-e^{2\pi \cos(\sin 1/x)}}}=\frac{-\frac{\displaystyle\pi\sin(\sin(1/x))\cos(1/x)e^{2\pi\cos(\sin(1/x))}}{x^2}+x+\sin x+\cos x}{(x^2-\cos^2x-e^{2\pi\cos(\sin(1/x))}+1)^{3/2}}$$ I have no idea how to start with, I've first simplified what's inside the square root to $\sin^2x+x^2-e^{2\pi\cos(\sin(1/x))}$ but then how to eradicate that square root? That's why I thought of using the chain rule where one of the functions is $1/\sqrt{x}$ but I'm having serious trouble!","(calculus) How can I prove that $$\frac{d}{dx}\frac{1}{\sqrt{1+x^2-\cos^2x-e^{2\pi \cos(\sin 1/x)}}}=\frac{-\frac{\displaystyle\pi\sin(\sin(1/x))\cos(1/x)e^{2\pi\cos(\sin(1/x))}}{x^2}+x+\sin x+\cos x}{(x^2-\cos^2x-e^{2\pi\cos(\sin(1/x))}+1)^{3/2}}$$ I have no idea how to start with, I've first simplified what's inside the square root to $\sin^2x+x^2-e^{2\pi\cos(\sin(1/x))}$ but then how to eradicate that square root? That's why I thought of using the chain rule where one of the functions is $1/\sqrt{x}$ but I'm having serious trouble!",,"['calculus', 'derivatives']"
44,implicit differentiating equation with $\cos$,implicit differentiating equation with,\cos,I need help getting $\frac{d^2y}{dx^2}$ for $yâ\cos y=2x$ Someone answered and got $(1+\sin y(x))3+4\cos y(x)$ but i was unable to follow their steps and didnt get how to do it.  any HELP?,I need help getting $\frac{d^2y}{dx^2}$ for $yâ\cos y=2x$ Someone answered and got $(1+\sin y(x))3+4\cos y(x)$ but i was unable to follow their steps and didnt get how to do it.  any HELP?,,"['calculus', 'derivatives', 'implicit-differentiation']"
45,"Prove that if $f$ is differentiable on $[a,b]$ and $f$ is Lipschitz, then $f$ has a bounded derivative.","Prove that if  is differentiable on  and  is Lipschitz, then  has a bounded derivative.","f [a,b] f f","Prove that if $f$ is differentiable on $[a,b]$ and $f$ is Lipschitz continuous (LC), then $f$ has a bounded derivative. My proof: $f$ is LC $\Rightarrow$ f has bounded a derivative: there exists $M\gt 0$ such that $$|f(x)-f(y)|\le M|x-y|, \forall x,y\in [a,b]$$ then $${|f(x)-f(y)|\over {|x-y|}}\le M$$(if $ x\neq y$) If $y\lt x$ (without loss of generality $x\lt y$) then $[y,x]\subseteq [a,b]$ and by hypothesis $f$ is differentiable on $[a,b]$ hence $f$ is differentiable on $[y,x]$. Then, using Mean Value Theorem there must exist $c\in (y,x)$ such that $$fÂ´(c)={f(x)-f(y)\over x-y}$$ hence $$|fÂ´(c)|\le M$$ As $x,y$ are arbitrary elements of $[a,b]$, then $c$ is also an arbitrary element but of $(a,b)$ therefore $$|fÂ´(c)|\le M$$ $$\forall  c\in (a,b)$$ but does this imply that $$|fÂ´(c)|\le M, \forall  c\in [a,b]?$$ I would really appreciate your help","Prove that if $f$ is differentiable on $[a,b]$ and $f$ is Lipschitz continuous (LC), then $f$ has a bounded derivative. My proof: $f$ is LC $\Rightarrow$ f has bounded a derivative: there exists $M\gt 0$ such that $$|f(x)-f(y)|\le M|x-y|, \forall x,y\in [a,b]$$ then $${|f(x)-f(y)|\over {|x-y|}}\le M$$(if $ x\neq y$) If $y\lt x$ (without loss of generality $x\lt y$) then $[y,x]\subseteq [a,b]$ and by hypothesis $f$ is differentiable on $[a,b]$ hence $f$ is differentiable on $[y,x]$. Then, using Mean Value Theorem there must exist $c\in (y,x)$ such that $$fÂ´(c)={f(x)-f(y)\over x-y}$$ hence $$|fÂ´(c)|\le M$$ As $x,y$ are arbitrary elements of $[a,b]$, then $c$ is also an arbitrary element but of $(a,b)$ therefore $$|fÂ´(c)|\le M$$ $$\forall  c\in (a,b)$$ but does this imply that $$|fÂ´(c)|\le M, \forall  c\in [a,b]?$$ I would really appreciate your help",,"['calculus', 'derivatives']"
46,Represent derivation as a standard matrix (Linear mapping)?,Represent derivation as a standard matrix (Linear mapping)?,,"Given a matrix $a$ of coefficients $\left( \begin{array}{cc} a_0 \\ a_1 \\ .. \\a_n\end{array} \right)$representing $a_0 + a_1 x + a_2 x^2 + ... a_n x^n$, how can I find a standard matrix D such that $[D] a$ will give me the coefficient matrix of the derivative of $a$? So the dimensions of D will be (n+1) by (n+1). I've tried to find a D using the standard basis of $R^{n+1}$ but that would just leave me with a zero matrix as D. For example, $\left( \begin{array}{cc} 1\\ 0\\ .. \\0\end{array} \right)$ would just leave me with $\left( \begin{array}{cc} 0\\ 0\\ .. \\0\end{array} \right)$ because the next term is set to $0$ per this basis.","Given a matrix $a$ of coefficients $\left( \begin{array}{cc} a_0 \\ a_1 \\ .. \\a_n\end{array} \right)$representing $a_0 + a_1 x + a_2 x^2 + ... a_n x^n$, how can I find a standard matrix D such that $[D] a$ will give me the coefficient matrix of the derivative of $a$? So the dimensions of D will be (n+1) by (n+1). I've tried to find a D using the standard basis of $R^{n+1}$ but that would just leave me with a zero matrix as D. For example, $\left( \begin{array}{cc} 1\\ 0\\ .. \\0\end{array} \right)$ would just leave me with $\left( \begin{array}{cc} 0\\ 0\\ .. \\0\end{array} \right)$ because the next term is set to $0$ per this basis.",,"['linear-algebra', 'matrices', 'derivatives']"
47,Let $f$ be a continuous function on an interval around $0$ and let $a_i=f(\frac{1}{i})$ (for large enough $i$),Let  be a continuous function on an interval around  and let  (for large enough ),f 0 a_i=f(\frac{1}{i}) i,"Let $f$ be a continuous function on an interval around $0$ and let $a_i=f(\frac{1}{i})$ (for large enough $i$) i) Suppose $\sum a_i$ converges. Must $f'(0)$ exist? ii) Suppose $f(0) = f'(0) = 0$. Must $\sum a_i$ converge? This is question #6 from Spivak Calculus 4th edition. I already showed that, if $\sum a_i$ converges, $f(0) = 0$, and also that, if $f'(0)$ exists and $\sum a_i$ converges, then $f'(0) = 0$, and also that if $f''(0)$ exists and $f'(0) = f(0) = 0$ then $\sum a_i$ converges.","Let $f$ be a continuous function on an interval around $0$ and let $a_i=f(\frac{1}{i})$ (for large enough $i$) i) Suppose $\sum a_i$ converges. Must $f'(0)$ exist? ii) Suppose $f(0) = f'(0) = 0$. Must $\sum a_i$ converge? This is question #6 from Spivak Calculus 4th edition. I already showed that, if $\sum a_i$ converges, $f(0) = 0$, and also that, if $f'(0)$ exists and $\sum a_i$ converges, then $f'(0) = 0$, and also that if $f''(0)$ exists and $f'(0) = f(0) = 0$ then $\sum a_i$ converges.",,"['sequences-and-series', 'derivatives', 'continuity']"
48,Solve the differential equation: $(y^2-xy)dx+x^2dy=0$,Solve the differential equation:,(y^2-xy)dx+x^2dy=0,$$(y^2-xy)dx+x^2dy=0$$ Need step by step answer. Thank you in advance for your help,$$(y^2-xy)dx+x^2dy=0$$ Need step by step answer. Thank you in advance for your help,,"['ordinary-differential-equations', 'derivatives']"
49,Find where the function $k(x):=|\sin(x)|$ is differentiable and calculate its derivative,Find where the function  is differentiable and calculate its derivative,k(x):=|\sin(x)|,"Find where the function$$k(x):=|\sin(x)|$$ is differentiable and calculate its derivative. I have started, by trying to make a function by parts, because of the absolute value, getting this: $$k(x):=\left\{\begin{matrix}  & \sin (x)& x>0 \\   & (-1) \sin (x) &  x<0\\   & 0 & x=0 \end{matrix}\right.$$ I have my doubts abut writing for $x=0$, but i really dont know hoy to do this excersice, can someone explain me and tell me how to write it correctly? The graph is like this:","Find where the function$$k(x):=|\sin(x)|$$ is differentiable and calculate its derivative. I have started, by trying to make a function by parts, because of the absolute value, getting this: $$k(x):=\left\{\begin{matrix}  & \sin (x)& x>0 \\   & (-1) \sin (x) &  x<0\\   & 0 & x=0 \end{matrix}\right.$$ I have my doubts abut writing for $x=0$, but i really dont know hoy to do this excersice, can someone explain me and tell me how to write it correctly? The graph is like this:",,"['real-analysis', 'derivatives']"
50,n-th derivative of $\sinh^{-1} x$,n-th derivative of,\sinh^{-1} x,"What is the n-th derivative of $\sinh^{-1} x$ ? I have been able to prove  that it is $p_n(x)(x^2+1)^{-n-1/2}$, where $p_n$ is a polynomial of degree $n-1$, and I have calculated it leading and constant coefficient, but I can't figure out the rest. Another similar topic is this .","What is the n-th derivative of $\sinh^{-1} x$ ? I have been able to prove  that it is $p_n(x)(x^2+1)^{-n-1/2}$, where $p_n$ is a polynomial of degree $n-1$, and I have calculated it leading and constant coefficient, but I can't figure out the rest. Another similar topic is this .",,['derivatives']
51,Implicit form of general equation,Implicit form of general equation,,"Find, in implicit form, the general solution of the differential equation:   $$\frac{dy}{dx}= \frac{2y^4e^{2x}}{3\left(e^{2x}+7\right)^2}$$ I am struggling to make any sense of this. What I have understood is that first I need to seperate the variables then integrate but I am not sure how to seperate the variables. The equations I have are : dy/dx=f(x)g(y) then divide both sides by g(y) to get: 1/g(y) dy/dx=f(x) I am just not sure which part of the equations would be the g(y) and f(x) pary. Any help greatly appreciated!","Find, in implicit form, the general solution of the differential equation:   $$\frac{dy}{dx}= \frac{2y^4e^{2x}}{3\left(e^{2x}+7\right)^2}$$ I am struggling to make any sense of this. What I have understood is that first I need to seperate the variables then integrate but I am not sure how to seperate the variables. The equations I have are : dy/dx=f(x)g(y) then divide both sides by g(y) to get: 1/g(y) dy/dx=f(x) I am just not sure which part of the equations would be the g(y) and f(x) pary. Any help greatly appreciated!",,"['calculus', 'integration', 'ordinary-differential-equations', 'derivatives', 'implicit-differentiation']"
52,Calc Optimization problem with open top,Calc Optimization problem with open top,,"A rectangular box with an open top has a volume of 4500 ft^3. The base is made of slate, and the sides are made of glass. Slate is 3 times the price of glass per sq. ft. What dimensions minimize the cost?","A rectangular box with an open top has a volume of 4500 ft^3. The base is made of slate, and the sides are made of glass. Slate is 3 times the price of glass per sq. ft. What dimensions minimize the cost?",,"['calculus', 'derivatives']"
53,I'm having trouble understanding this derivation,I'm having trouble understanding this derivation,,"In my notes I came across an equation: $$\ddot\theta = \frac{\mathrm d\dot\theta}{\mathrm dt} = \frac{\mathrm d}{\mathrm dt}\left(\frac{v\sin(\theta)}{r}\right) = \frac{\dot v \sin (\theta) }{r} + \frac{v\dot \theta \cos(\theta)}{r} - \frac{v\sin(\theta)}{r^2}\dot r$$ The last term doesn't make sense to me. The two terms before that clearly come from the chain rule, but how was the third derived? $v$ here is velocity, and $r$ is radius. If this isn't enough information, even knowing that would be very helpful. Thanks in advance for any help!","In my notes I came across an equation: $$\ddot\theta = \frac{\mathrm d\dot\theta}{\mathrm dt} = \frac{\mathrm d}{\mathrm dt}\left(\frac{v\sin(\theta)}{r}\right) = \frac{\dot v \sin (\theta) }{r} + \frac{v\dot \theta \cos(\theta)}{r} - \frac{v\sin(\theta)}{r^2}\dot r$$ The last term doesn't make sense to me. The two terms before that clearly come from the chain rule, but how was the third derived? $v$ here is velocity, and $r$ is radius. If this isn't enough information, even knowing that would be very helpful. Thanks in advance for any help!",,"['calculus', 'derivatives']"
54,$g(z) = \int_{0}^{2\pi}f(e^{i\theta})\frac{e^{-i\theta}}{e^{-i\theta}-\bar{z}}d\theta$ is antiholomorphic,is antiholomorphic,g(z) = \int_{0}^{2\pi}f(e^{i\theta})\frac{e^{-i\theta}}{e^{-i\theta}-\bar{z}}d\theta,"I 've encountered this fact: if $z \in D(0,1) $ and $f$ is continous on $\partial D(0,1) $ then $$g(z) = \int_{0}^{2\pi}f(e^{i\theta})\frac{e^{-i\theta}}{e^{-i\theta}-\bar{z}}d\theta$$ is antiholomorphic. Why is it true ?","I 've encountered this fact: if $z \in D(0,1) $ and $f$ is continous on $\partial D(0,1) $ then $$g(z) = \int_{0}^{2\pi}f(e^{i\theta})\frac{e^{-i\theta}}{e^{-i\theta}-\bar{z}}d\theta$$ is antiholomorphic. Why is it true ?",,"['integration', 'complex-analysis', 'analysis', 'derivatives']"
55,How do I determine between positive and negative inflection,How do I determine between positive and negative inflection,,"Is it possible to identify whether an inflection point such as this example, contained in y = x^3 from the wikipedia: Is positive or negatively oriented (i.e. the gradient leading up to, and away, from it) without visualising it or taking a point from either side? We went over determining between maximum, minimum and inflection points using second derivatives in AS mathematics today, and I felt that the method of taking a point on either side wasn't a very conclusive (Since, in theory, there could be a turning point very close to it, couldn't there? Which could affect this) or pure way of going about it, although I could well be wrong. I enquired about it to my lecturer but she stated that there's no method that's in the specification for our exam and that if there is one it's probably higher level. I did look around for information but it seems my vocabulary is too basic to find any relevant questions. I did find this on the Wikipedia: If x is an inflection point for f then the second derivative, fâ³(x), is equal to zero if it exists, but this condition does not provide a sufficient definition of a point of inflection. Source Which basically sums up what I already knew about second derivatives. It goes on to explain about determining between undulation and inflection points, however I found little resources on-line to explain what an undulation point is, and therefore am not sure if this is relevant to my question. Thanks very much, again, sorry if this question seems too basic to present here-- I'm just intensely curious about mathematical methods, and will be thinking about this for weeks otherwise. Note that I am only interested in 2D Cartesian geometry.","Is it possible to identify whether an inflection point such as this example, contained in y = x^3 from the wikipedia: Is positive or negatively oriented (i.e. the gradient leading up to, and away, from it) without visualising it or taking a point from either side? We went over determining between maximum, minimum and inflection points using second derivatives in AS mathematics today, and I felt that the method of taking a point on either side wasn't a very conclusive (Since, in theory, there could be a turning point very close to it, couldn't there? Which could affect this) or pure way of going about it, although I could well be wrong. I enquired about it to my lecturer but she stated that there's no method that's in the specification for our exam and that if there is one it's probably higher level. I did look around for information but it seems my vocabulary is too basic to find any relevant questions. I did find this on the Wikipedia: If x is an inflection point for f then the second derivative, fâ³(x), is equal to zero if it exists, but this condition does not provide a sufficient definition of a point of inflection. Source Which basically sums up what I already knew about second derivatives. It goes on to explain about determining between undulation and inflection points, however I found little resources on-line to explain what an undulation point is, and therefore am not sure if this is relevant to my question. Thanks very much, again, sorry if this question seems too basic to present here-- I'm just intensely curious about mathematical methods, and will be thinking about this for weeks otherwise. Note that I am only interested in 2D Cartesian geometry.",,"['geometry', 'polynomials', 'derivatives']"
56,Symmetry in partial derivatives.,Symmetry in partial derivatives.,,"I was wondering how the relationship $$x_j \partial_i f(x) = x_i \partial_j f(x)$$ means, that a function has rotational symmetry? I mean with rotational symmetric, that the value of $f$ at a point $x$ depends only on $\|x\|_2$. Or more precisely: Is there any $C_1(\mathbb{R}^n \backslash \{0\}; \mathbb{R})$ function, that has no rotational symmetry, but fulfills this equation for all $x \in \mathbb{R}^n\backslash\{0\}$?","I was wondering how the relationship $$x_j \partial_i f(x) = x_i \partial_j f(x)$$ means, that a function has rotational symmetry? I mean with rotational symmetric, that the value of $f$ at a point $x$ depends only on $\|x\|_2$. Or more precisely: Is there any $C_1(\mathbb{R}^n \backslash \{0\}; \mathbb{R})$ function, that has no rotational symmetry, but fulfills this equation for all $x \in \mathbb{R}^n\backslash\{0\}$?",,"['calculus', 'real-analysis']"
57,How to work out an integral with algebra.,How to work out an integral with algebra.,,"I'm a bit of a noob and I am only just starting to learn calculus. I know how to work out a derivative with algebra (instead of using those rules and shortcuts) but I don't know how or if you can do the same with integration. Here is the method I used to work out a derivative with algebra (and limits): $f(x) = x^2,$ $f'(x) = \lim_{h\to 0} \frac{f(x + h) - f(x)}{h}$ $      = \lim_{h\to 0} \frac{(x + h)^2 - x^2}{h}$ $      = \lim_{h\to 0} \frac{x^2 + 2xh + h^2 - x^2}{h}$ $      = \lim_{h\to 0} \frac{2xh + h^2}{h}$ $      = \lim_{h\to 0} 2x + h$ $      = 2x$ Otherwise I could just use the power rule for derivatives, but I want to know how and if I can work out the antiderivative (integral) using an algebraic method like the one above rather than using rules etc. e.g. how would I work out that x^2 is the antiderivative of 2x. I know there is methods where you just do long summations and get approximate values of the 'area under the curve' but I want to find out how and if I can get the actual antiderivative expression e.g. x^2 (in the case of 2x). I hope I am not out of my depth :)","I'm a bit of a noob and I am only just starting to learn calculus. I know how to work out a derivative with algebra (instead of using those rules and shortcuts) but I don't know how or if you can do the same with integration. Here is the method I used to work out a derivative with algebra (and limits): $f(x) = x^2,$ $f'(x) = \lim_{h\to 0} \frac{f(x + h) - f(x)}{h}$ $      = \lim_{h\to 0} \frac{(x + h)^2 - x^2}{h}$ $      = \lim_{h\to 0} \frac{x^2 + 2xh + h^2 - x^2}{h}$ $      = \lim_{h\to 0} \frac{2xh + h^2}{h}$ $      = \lim_{h\to 0} 2x + h$ $      = 2x$ Otherwise I could just use the power rule for derivatives, but I want to know how and if I can work out the antiderivative (integral) using an algebraic method like the one above rather than using rules etc. e.g. how would I work out that x^2 is the antiderivative of 2x. I know there is methods where you just do long summations and get approximate values of the 'area under the curve' but I want to find out how and if I can get the actual antiderivative expression e.g. x^2 (in the case of 2x). I hope I am not out of my depth :)",,"['calculus', 'integration', 'derivatives']"
58,Proving nondifferentiability at all points of a continuous function,Proving nondifferentiability at all points of a continuous function,,"Given: $f_1(x)=x$ if $x\le1/2$ $f_1(x)=1-x$ if $1/2\le x\le1$ $f_1(x+1)=f_1(x)$ $\forall n\ge2,f_n(x)=(1/2)*f_{n-1}(2x)$ Let $S_m(x)=\sum_{n=1}^m f_n(x)$ $S_m$ is a continuous function on $[0,\infty]$ $(S_m)_{m\in N}$ converges uniformly to a continuous function $S$ Task: Show that $S$ is not differentiable at any point in $(0,\infty)$ My work/question: After drawing out $f_1$, $f_2$, and $f_3$, it seems to me that at every $k/(2^n)$, where $k,n$ are natural numbers, f is not differentiable. I don't know if this is useful. Does this expression account for all rational numbers? It seems like a common thing to do with proving that a function is not differentiable is to consider the limit from the left and right. I don't really know where to go with this approach though. Per user117818's comment: $\lim_{h\to 0}(S_m(x+h)-S_m(x))/h=\lim_{h\to 0}(\sum_{n=1}^m [f_n(x+h)-f_n(x)])/h$ $= \sum_{n=1}^m (\lim_{h\to 0}(f_n(x+h)-f_n(x))/h)$ I guess this shows that, for every point $a$, if there exists an $n$ such that $f_n$ is not differentiable at $a$, then $S_m$ is not differentiable at this point either. Would it be possible to show that for every point $a$, there does indeed exist an $n$ that satisfies this condition?","Given: $f_1(x)=x$ if $x\le1/2$ $f_1(x)=1-x$ if $1/2\le x\le1$ $f_1(x+1)=f_1(x)$ $\forall n\ge2,f_n(x)=(1/2)*f_{n-1}(2x)$ Let $S_m(x)=\sum_{n=1}^m f_n(x)$ $S_m$ is a continuous function on $[0,\infty]$ $(S_m)_{m\in N}$ converges uniformly to a continuous function $S$ Task: Show that $S$ is not differentiable at any point in $(0,\infty)$ My work/question: After drawing out $f_1$, $f_2$, and $f_3$, it seems to me that at every $k/(2^n)$, where $k,n$ are natural numbers, f is not differentiable. I don't know if this is useful. Does this expression account for all rational numbers? It seems like a common thing to do with proving that a function is not differentiable is to consider the limit from the left and right. I don't really know where to go with this approach though. Per user117818's comment: $\lim_{h\to 0}(S_m(x+h)-S_m(x))/h=\lim_{h\to 0}(\sum_{n=1}^m [f_n(x+h)-f_n(x)])/h$ $= \sum_{n=1}^m (\lim_{h\to 0}(f_n(x+h)-f_n(x))/h)$ I guess this shows that, for every point $a$, if there exists an $n$ such that $f_n$ is not differentiable at $a$, then $S_m$ is not differentiable at this point either. Would it be possible to show that for every point $a$, there does indeed exist an $n$ that satisfies this condition?",,"['calculus', 'analysis', 'derivatives', 'continuity']"
59,Knowing if the real derivative exists,Knowing if the real derivative exists,,"The numerical derivative is valid only if the real derivative exists. Is it possible to know if the real derivative exists without using symbolic derivative, and using computer operations?","The numerical derivative is valid only if the real derivative exists. Is it possible to know if the real derivative exists without using symbolic derivative, and using computer operations?",,"['derivatives', 'numerical-methods']"
60,Tangent of curve which passes through origin. Finding unknown variable,Tangent of curve which passes through origin. Finding unknown variable,,"If the tangent to the graph of $y = e^{ax}$, $a \ne 0$, at $x = c$ passes through the origin, then $c$ is equal to?","If the tangent to the graph of $y = e^{ax}$, $a \ne 0$, at $x = c$ passes through the origin, then $c$ is equal to?",,"['calculus', 'derivatives']"
61,Finding the derivative of: $ y(x)=xâ\sin(x)+x^2â\cos(3x) $,Finding the derivative of:, y(x)=xâ\sin(x)+x^2â\cos(3x) ,"I am a student and I have a problem in solving this derivative, so please help me. The problem:     $$ y(x)=xâ\sin(x)+x^2â\cos(3x)$$ I give this problem to online derivative calculator like derivative-calculator.net but the answer is not equal to my teacher answer. online calc answer: $$ y^\prime(x)=â3x2â\sin(3x)+2xâ\cos(3x)+\sin(x)+xâ\cos(x) $$ teacher answer: $$ y^\prime(x)  =  1â\sin(x)+xâ\cos(x)+2xâ\cos(3x)-3x^2â\sin(3x) $$ what is the correct answer? thanks.","I am a student and I have a problem in solving this derivative, so please help me. The problem:     $$ y(x)=xâ\sin(x)+x^2â\cos(3x)$$ I give this problem to online derivative calculator like derivative-calculator.net but the answer is not equal to my teacher answer. online calc answer: $$ y^\prime(x)=â3x2â\sin(3x)+2xâ\cos(3x)+\sin(x)+xâ\cos(x) $$ teacher answer: $$ y^\prime(x)  =  1â\sin(x)+xâ\cos(x)+2xâ\cos(3x)-3x^2â\sin(3x) $$ what is the correct answer? thanks.",,['derivatives']
62,Differentiability of function defined as integral form,Differentiability of function defined as integral form,,"Let $H(t)=\displaystyle\int_{\Bbb R}\lvert\, f(x)+tg(x)\rvert^p\mathrm dx$ and $f,g\in L^p(\Bbb R)$. Then, how  to prove that $H$ is differentiable and find its derivative? I think it's impossible to find it by $\dfrac{H(t+h)-H(t)}{h}$. Should I show that $H$ is of bounded variation?","Let $H(t)=\displaystyle\int_{\Bbb R}\lvert\, f(x)+tg(x)\rvert^p\mathrm dx$ and $f,g\in L^p(\Bbb R)$. Then, how  to prove that $H$ is differentiable and find its derivative? I think it's impossible to find it by $\dfrac{H(t+h)-H(t)}{h}$. Should I show that $H$ is of bounded variation?",,"['real-analysis', 'derivatives', 'lebesgue-integral', 'normed-spaces']"
63,Derivative of function that includes norm,Derivative of function that includes norm,,"I was solving the problem: find the derivative of a function f : H â R, $f (x) = \sin ||x||^3$ (H is Hilbert space).  I got the answer $f'(x)=3\cos||x||^3 x||x||$. Is this correct or I am doing something wrong?","I was solving the problem: find the derivative of a function f : H â R, $f (x) = \sin ||x||^3$ (H is Hilbert space).  I got the answer $f'(x)=3\cos||x||^3 x||x||$. Is this correct or I am doing something wrong?",,['functional-analysis']
64,Derivative of antipodal map between $n$-spheres,Derivative of antipodal map between -spheres,n,"Let $S^{n-1}\subseteq \mathbb{R}^n$ denote the $(n-1)$-sphere $x_1^2+\ldots+x_n^2=1$. Let $f:S^{n-1}\rightarrow S^{n-1}$ be the map $f(x_1,\ldots,x_n)=(-x_1,\ldots,-x_n)$. What is the derivative of $f$ at $p\in S^{n-1}$? The derivative of $f$ at $p$ is the map from the tangent space $T_pS^{n-1}$ to the tangent space $T_{f(p)}S^{n-1}=T_{-p}S^{n-1}$. It takes the vector $(p,v(p))$ to the vector $(-p,Df(p)\cdot v(p))$. We have $$Df(p)\cdot v(p) = -I_{n\times n}\cdot v(p)=-v(p).$$ So the derivative of $f$ at $p$ takes $(p,v(p))$ to $(-p,-v(p))$. Is that right, and is there something else we can say?","Let $S^{n-1}\subseteq \mathbb{R}^n$ denote the $(n-1)$-sphere $x_1^2+\ldots+x_n^2=1$. Let $f:S^{n-1}\rightarrow S^{n-1}$ be the map $f(x_1,\ldots,x_n)=(-x_1,\ldots,-x_n)$. What is the derivative of $f$ at $p\in S^{n-1}$? The derivative of $f$ at $p$ is the map from the tangent space $T_pS^{n-1}$ to the tangent space $T_{f(p)}S^{n-1}=T_{-p}S^{n-1}$. It takes the vector $(p,v(p))$ to the vector $(-p,Df(p)\cdot v(p))$. We have $$Df(p)\cdot v(p) = -I_{n\times n}\cdot v(p)=-v(p).$$ So the derivative of $f$ at $p$ takes $(p,v(p))$ to $(-p,-v(p))$. Is that right, and is there something else we can say?",,"['derivatives', 'manifolds']"
65,Question about continuous differentiability,Question about continuous differentiability,,"Consider the function $f(x,y) = \frac{x}{1+\sqrt{x^2+y^2}}$. Its derivative with respect to $x$ can be calculated to be $\frac{1 + \frac{y^2}{\sqrt{x^2 + y^2}}}{1 + x^2 + y^2 + 2 \sqrt{x^2 + y^2}}$. Is it correct to say that $\frac{\partial f(x,y)} {\partial x}$ is continuous? I ask because it seems that if both $x$ and $y$ are zero, then the derivative is undefined.","Consider the function $f(x,y) = \frac{x}{1+\sqrt{x^2+y^2}}$. Its derivative with respect to $x$ can be calculated to be $\frac{1 + \frac{y^2}{\sqrt{x^2 + y^2}}}{1 + x^2 + y^2 + 2 \sqrt{x^2 + y^2}}$. Is it correct to say that $\frac{\partial f(x,y)} {\partial x}$ is continuous? I ask because it seems that if both $x$ and $y$ are zero, then the derivative is undefined.",,['derivatives']
66,How do I find a function to minimize another function?,How do I find a function to minimize another function?,,"I am given to constants $b, n \in \mathbb{N}$. The task is to find a function $r(b,n)$ such that $\text{range}(r)=[1,b]$ and the value of $\frac{b}{r(b,n)}(n+2^{r(b,n)})$ is minimal. Do I have to necessarily deal with PDE's, or I can reduce the task on setting $r$ constant and finding minimum of $f(r)=\frac{b}{r}(n+2^{r})$ (find roots of derivative and and then expressing $r$ through $b$ and $n$). My guess is that it should be $r=1$, so we reduce exponential part of the function, but I want to prove this rigorously. Thanks in advance!","I am given to constants $b, n \in \mathbb{N}$. The task is to find a function $r(b,n)$ such that $\text{range}(r)=[1,b]$ and the value of $\frac{b}{r(b,n)}(n+2^{r(b,n)})$ is minimal. Do I have to necessarily deal with PDE's, or I can reduce the task on setting $r$ constant and finding minimum of $f(r)=\frac{b}{r}(n+2^{r})$ (find roots of derivative and and then expressing $r$ through $b$ and $n$). My guess is that it should be $r=1$, so we reduce exponential part of the function, but I want to prove this rigorously. Thanks in advance!",,"['derivatives', 'optimization']"
67,Derivative of big O symbol,Derivative of big O symbol,,"Let's only work with functions $f(x)$ that have a series expansion at $x=0$. Is it true that: $$ {d O(1)\over d x} = O(1) $$ for all such functions $f(x)$? Here $O$ is the big-O notation and we are expanding around the point $x=0$ (i.e. not around $x\to\infty$). The only counter examples that I can find are of the type $f(x)=x^n\sin(1/x)$ where $n$ can be 0, 1, 2, ...., but these functions do not have a series expansion around $x=0$, so I am not interested in them.","Let's only work with functions $f(x)$ that have a series expansion at $x=0$. Is it true that: $$ {d O(1)\over d x} = O(1) $$ for all such functions $f(x)$? Here $O$ is the big-O notation and we are expanding around the point $x=0$ (i.e. not around $x\to\infty$). The only counter examples that I can find are of the type $f(x)=x^n\sin(1/x)$ where $n$ can be 0, 1, 2, ...., but these functions do not have a series expansion around $x=0$, so I am not interested in them.",,"['calculus', 'derivatives', 'asymptotics']"
68,Fourier and differentiation operators,Fourier and differentiation operators,,"For a function $f:\mathbb{R}\rightarrow\mathbb{R}$ in the Schwartz class, define $$Tf(y)=\dfrac{1}{\sqrt{2\pi}}\int_\mathbb{R}f(x)e^{-ixy}dx$$ We can show that $T^2f(y)=f(-y)$, and $T^4f(y)=f(y)$. Also, define $$Af(y)=yf(y)+\dfrac{d}{dy}f(y)$$ For what value of $a$ is  $TA=aAT$? Using $T^4Af(y)=Af(y)$, I can get $$a^4AT^4f(y)=a^4Af(y)=Af(y)$$ so $a^4=1$, so $a=\pm 1,\pm i$. But it doesn't really tell which values of $a$ work. What can I do to identify which values of $a$ work?","For a function $f:\mathbb{R}\rightarrow\mathbb{R}$ in the Schwartz class, define $$Tf(y)=\dfrac{1}{\sqrt{2\pi}}\int_\mathbb{R}f(x)e^{-ixy}dx$$ We can show that $T^2f(y)=f(-y)$, and $T^4f(y)=f(y)$. Also, define $$Af(y)=yf(y)+\dfrac{d}{dy}f(y)$$ For what value of $a$ is  $TA=aAT$? Using $T^4Af(y)=Af(y)$, I can get $$a^4AT^4f(y)=a^4Af(y)=Af(y)$$ so $a^4=1$, so $a=\pm 1,\pm i$. But it doesn't really tell which values of $a$ work. What can I do to identify which values of $a$ work?",,"['derivatives', 'fourier-analysis']"
69,Finding derivative using product and chain rule,Finding derivative using product and chain rule,,I need to find first derivative of $x\sqrt{2-x^2}$ . My approach Using product rule: $(2-x^2)^{1/2} + x\frac{\operatorname{d}(2-x^2)^{1/2}}{\operatorname{d}x}$ Using chain rule: $(2-x^2)^{1/2} + x\left[\frac{1}{2}(2-x^2)^{-1/2} (-2x)\right]$ Result: $(2-x^2)^{1/2} - x^2 (2-x^2)^{-1/2}$ Is that correct?,I need to find first derivative of . My approach Using product rule: Using chain rule: Result: Is that correct?,x\sqrt{2-x^2} (2-x^2)^{1/2} + x\frac{\operatorname{d}(2-x^2)^{1/2}}{\operatorname{d}x} (2-x^2)^{1/2} + x\left[\frac{1}{2}(2-x^2)^{-1/2} (-2x)\right] (2-x^2)^{1/2} - x^2 (2-x^2)^{-1/2},['derivatives']
70,Maxima/minima of $f(x)=\frac{\sin(\frac{1}{2} Nx) }{\sin(\frac{1}{2} x)}.$,Maxima/minima of,f(x)=\frac{\sin(\frac{1}{2} Nx) }{\sin(\frac{1}{2} x)}.,"How do I find: the $\bf maxima$ and  minima  of the function $f$ with $ f$ given by: $$f(x)=\frac{\sin(\frac{1}{2} Nx) }{\sin(\frac{1}{2} x)},  \;\;(N=1,2,3...)$$ What I did, is: Minima: I set: $\sin(\frac{1}{2} Nx)=0$ Can someone please tell me whether my method is right (and maybe provide me some more background)? I hope you can help.","How do I find: the $\bf maxima$ and  minima  of the function $f$ with $ f$ given by: $$f(x)=\frac{\sin(\frac{1}{2} Nx) }{\sin(\frac{1}{2} x)},  \;\;(N=1,2,3...)$$ What I did, is: Minima: I set: $\sin(\frac{1}{2} Nx)=0$ Can someone please tell me whether my method is right (and maybe provide me some more background)? I hope you can help.",,"['calculus', 'algebra-precalculus', 'derivatives', 'optimization']"
71,Formula for the first derivative of $\frac{x^n}{e^x}$,Formula for the first derivative of,\frac{x^n}{e^x},"I had a homework problem to calculate the derivative of $$\frac{x}{e^x}$$ which I did, successfully, but then I figured there would be a more general formula for the derivative of $\frac{x^n}{e^x}$, considering how easy it was to find this derivative. So I calculated a couple more derivatives with values of $n$ increasing by one i.e. $x^2, x^3 \ldots$ and found the following formula: $$f^{'}(x) = \frac{x^{n-1}(n-x)}{e^x}$$ This works for higher powers of $x$ too. For example, the derivative of $\frac{x^2}{e^x}$ is $$\begin{align} &f^{'}(x) = \frac{x^{n-1}(n-x)}{e^x} \\ &f^{'}(x) = \frac{x^{2-1}(2-x)}{e^x} \\ &f^{'}(x) = \frac{x(2-x)}{e^x} \end{align}$$ and if you check through W|A , it is correct. To verify that this is formula is correct, I took an arbitrary $n$. \begin{align} \require{cancel} f^{'}(x) &= \frac{x^{n}}{e^x} \\ &= \frac{nx^{n-1}e^x - x^ne^x}{(e^x)^2} \\ &= \frac{x^{n-1}e^x (n - x)}{e^{2x}} \\ &= \frac{x^{n-1}\cancel{e^x} (n-x)}{\cancel{e^{2x}}} \\ &= \frac{x^{n-1}(n-x)}{e^x} \\ \end{align} And there you have it. Is this a valid way to show the derivation of the formula? Also, is the formula correct? Thanks a bunch!","I had a homework problem to calculate the derivative of $$\frac{x}{e^x}$$ which I did, successfully, but then I figured there would be a more general formula for the derivative of $\frac{x^n}{e^x}$, considering how easy it was to find this derivative. So I calculated a couple more derivatives with values of $n$ increasing by one i.e. $x^2, x^3 \ldots$ and found the following formula: $$f^{'}(x) = \frac{x^{n-1}(n-x)}{e^x}$$ This works for higher powers of $x$ too. For example, the derivative of $\frac{x^2}{e^x}$ is $$\begin{align} &f^{'}(x) = \frac{x^{n-1}(n-x)}{e^x} \\ &f^{'}(x) = \frac{x^{2-1}(2-x)}{e^x} \\ &f^{'}(x) = \frac{x(2-x)}{e^x} \end{align}$$ and if you check through W|A , it is correct. To verify that this is formula is correct, I took an arbitrary $n$. \begin{align} \require{cancel} f^{'}(x) &= \frac{x^{n}}{e^x} \\ &= \frac{nx^{n-1}e^x - x^ne^x}{(e^x)^2} \\ &= \frac{x^{n-1}e^x (n - x)}{e^{2x}} \\ &= \frac{x^{n-1}\cancel{e^x} (n-x)}{\cancel{e^{2x}}} \\ &= \frac{x^{n-1}(n-x)}{e^x} \\ \end{align} And there you have it. Is this a valid way to show the derivation of the formula? Also, is the formula correct? Thanks a bunch!",,"['calculus', 'derivatives']"
72,Examples of a problem solved by a well-chosen derivative equaling zero,Examples of a problem solved by a well-chosen derivative equaling zero,,"What are examples of problems which are solved by taking a derivative of a well-chosen function, and finding that it is zero, therefore the function must be constant? I can think of a few: Show $\int_0^pf(t)dt = \int_a^{a+p}f(t)dt$ for $f$ periodic of period $p$. This can be solved by differentiating $\int_0^pf(t)dt - \int_a^{a+p}f(t)dt$ with respect to $a$, noting that it is zero, and noting that the function has value zero at $a=0$. Show that $\int_1^a \frac1t dt = \int_b^ab \frac1t dt$. This can be shown by differentiating $\int_1^a \frac1t dt - \int_b^ab \frac1t dt$ with respect to $b$, noting that it is zero, and noting that the function is zero ab $b=1$. A bounded harmonic function on $\mathbb{R}^n$ must be constant, since we can show by mean value property that $|\frac{\partial u}{\partial x_i}| \leq C/r \cdot \max_{\|x\| =r}|u|$ for any $r$, so sending $r$ to infinity shows $u$ is a constant. I note that both of these first two problems are similar in that what is of interest is in the limits of an integral. I was looking for some other examples, perhaps not sharing this similarity. I'm sure there are far too many examples to list, but who has some good ones?","What are examples of problems which are solved by taking a derivative of a well-chosen function, and finding that it is zero, therefore the function must be constant? I can think of a few: Show $\int_0^pf(t)dt = \int_a^{a+p}f(t)dt$ for $f$ periodic of period $p$. This can be solved by differentiating $\int_0^pf(t)dt - \int_a^{a+p}f(t)dt$ with respect to $a$, noting that it is zero, and noting that the function has value zero at $a=0$. Show that $\int_1^a \frac1t dt = \int_b^ab \frac1t dt$. This can be shown by differentiating $\int_1^a \frac1t dt - \int_b^ab \frac1t dt$ with respect to $b$, noting that it is zero, and noting that the function is zero ab $b=1$. A bounded harmonic function on $\mathbb{R}^n$ must be constant, since we can show by mean value property that $|\frac{\partial u}{\partial x_i}| \leq C/r \cdot \max_{\|x\| =r}|u|$ for any $r$, so sending $r$ to infinity shows $u$ is a constant. I note that both of these first two problems are similar in that what is of interest is in the limits of an integral. I was looking for some other examples, perhaps not sharing this similarity. I'm sure there are far too many examples to list, but who has some good ones?",,"['calculus', 'soft-question', 'derivatives']"
73,Sum of exponentials with Fourier coefficient,Sum of exponentials with Fourier coefficient,,"Let $f$ be a continuous function with period $2\pi$. Define $$u(r,\theta)=\sum_{n=-\infty}^\infty r^{|n|}\hat{f}(n)e^{in\theta}$$ for $r\in[0,1)$, where $\hat{f}(n)$ is the $n$th Fourier coefficient of $f$. a) Express $u$ as a series in $z=x+iy$ and $\bar{z}=x-iy$. b) Show that $u$ is infinitely differentiable in $x^2+y^2<1$. For a), I want to substitute in $r=\sqrt{x^2+y^2}$ and $\theta=\tan^{-1}(y/x)$. But this doesn't seem to yield a nice expression in terms of $z$ and $\bar{z}$. For b), since this is an infinite sum, if we take the derivative term by term, we have to worry about convergence. Also, there are two variables to differentiate with respect to ($r$ and $\theta$), which makes it more complicated.","Let $f$ be a continuous function with period $2\pi$. Define $$u(r,\theta)=\sum_{n=-\infty}^\infty r^{|n|}\hat{f}(n)e^{in\theta}$$ for $r\in[0,1)$, where $\hat{f}(n)$ is the $n$th Fourier coefficient of $f$. a) Express $u$ as a series in $z=x+iy$ and $\bar{z}=x-iy$. b) Show that $u$ is infinitely differentiable in $x^2+y^2<1$. For a), I want to substitute in $r=\sqrt{x^2+y^2}$ and $\theta=\tan^{-1}(y/x)$. But this doesn't seem to yield a nice expression in terms of $z$ and $\bar{z}$. For b), since this is an infinite sum, if we take the derivative term by term, we have to worry about convergence. Also, there are two variables to differentiate with respect to ($r$ and $\theta$), which makes it more complicated.",,"['sequences-and-series', 'derivatives', 'fourier-analysis']"
74,Sketch curve $y = (4x^3-2x^2+5)/(2x^2+x-3)$,Sketch curve,y = (4x^3-2x^2+5)/(2x^2+x-3),I'm trying to sketch the curve $$ y = (4x^3-2x^2+5)/(2x^2+x-3). $$ I tried to find the first and second derivative but I don't know how to find the roots of these. \begin{align} y' &= \frac{-5-8 x-38 x^2+8 x^3+8 x^4}{(-3+x+2 x^2)^2} &&\text{Fermat Theorem}\\ 0 &=  -5-8 x-38 x^2+8 x^3+8 x^4 &&\leftarrow\text{Stuck}\\ y'' &= \frac{34+276 x-24 x^2+64 x^3}{(-3+x+2 x^2)^3} \\ 0 &= (-5-8 x-38 x^2+8 x^3+8 x^4)(-3+x+2 x^2) &&\leftarrow\text{Stuck} \end{align} I am currently learning Calculus I.,I'm trying to sketch the curve $$ y = (4x^3-2x^2+5)/(2x^2+x-3). $$ I tried to find the first and second derivative but I don't know how to find the roots of these. \begin{align} y' &= \frac{-5-8 x-38 x^2+8 x^3+8 x^4}{(-3+x+2 x^2)^2} &&\text{Fermat Theorem}\\ 0 &=  -5-8 x-38 x^2+8 x^3+8 x^4 &&\leftarrow\text{Stuck}\\ y'' &= \frac{34+276 x-24 x^2+64 x^3}{(-3+x+2 x^2)^3} \\ 0 &= (-5-8 x-38 x^2+8 x^3+8 x^4)(-3+x+2 x^2) &&\leftarrow\text{Stuck} \end{align} I am currently learning Calculus I.,,"['calculus', 'derivatives']"
75,"Derivative of function raised to a power, using the chain rule","Derivative of function raised to a power, using the chain rule",,How do I find the derivative of the function $f(x)= (2x+1)^2$? I've tried doing this problem and am not fully sure that I am correct. I found the derivative to be $f'(x) = 8x+4$. Is that correct?,How do I find the derivative of the function $f(x)= (2x+1)^2$? I've tried doing this problem and am not fully sure that I am correct. I found the derivative to be $f'(x) = 8x+4$. Is that correct?,,"['calculus', 'derivatives']"
76,Derivative of a fraction with respect to another,Derivative of a fraction with respect to another,,I've found this derivative on a textbook $\dfrac{d(c_{t+1}/c_t)}{d(\dfrac{\gamma}{c_t}/\dfrac{1-\gamma}{c_{t+1}})}=\dfrac{1-\gamma}{\gamma} \dfrac{d(c_{t+1}/c_t)}{d(c_{t+1}/c_t)}=\dfrac{1-\gamma}{\gamma}$ I would like to understand the first passage. Was $\dfrac{1-\gamma}{\gamma}$ just brought out of the $d()$ at the denominator?,I've found this derivative on a textbook $\dfrac{d(c_{t+1}/c_t)}{d(\dfrac{\gamma}{c_t}/\dfrac{1-\gamma}{c_{t+1}})}=\dfrac{1-\gamma}{\gamma} \dfrac{d(c_{t+1}/c_t)}{d(c_{t+1}/c_t)}=\dfrac{1-\gamma}{\gamma}$ I would like to understand the first passage. Was $\dfrac{1-\gamma}{\gamma}$ just brought out of the $d()$ at the denominator?,,['derivatives']
77,Derivative of mixed matrix terms with inverse matrix,Derivative of mixed matrix terms with inverse matrix,,I've been trying to solve two matrix derivative terms including an inverse matrix but I am unable to find a clue : 1) Derivative of $KG^{-1}J$ with respect to $G$. 2) Derivative of $J^{T}G^{-T}KG^{-1}J$ with respect to $G$. Thanks in advance.,I've been trying to solve two matrix derivative terms including an inverse matrix but I am unable to find a clue : 1) Derivative of $KG^{-1}J$ with respect to $G$. 2) Derivative of $J^{T}G^{-T}KG^{-1}J$ with respect to $G$. Thanks in advance.,,"['linear-algebra', 'matrices', 'ordinary-differential-equations', 'derivatives']"
78,Confusion related to calculation of gradient,Confusion related to calculation of gradient,,I have this confusion about the calculation of gradient How is the following expression derived $\nabla_{\Lambda}(tr(\Lambda^{-1}U)) = -\Lambda^{-1}U\Lambda^{-1}$ I could only get $-U\Lambda^{-1}\Lambda^{-1}$,I have this confusion about the calculation of gradient How is the following expression derived $\nabla_{\Lambda}(tr(\Lambda^{-1}U)) = -\Lambda^{-1}U\Lambda^{-1}$ I could only get $-U\Lambda^{-1}\Lambda^{-1}$,,"['calculus', 'matrices', 'derivatives']"
79,Generalized Derivative:,Generalized Derivative:,,"Denote $d_U,l,f(x)$   as the expression: $$\lim:  \delta \rightarrow l, U(f(x), \delta )  $$ It's trivial to show that the standard derivative is simply a case of $l = 0$ and $U = \dfrac{f(x + \delta) - f(x)}{\delta}$ Are there other flavors of derivatives yielded by this notation? Can one then create different orders of calculus depending on the type of derivative utilized and create a general theory of Calculuses? Has this been done before and if so where should I look for more information?","Denote $d_U,l,f(x)$   as the expression: $$\lim:  \delta \rightarrow l, U(f(x), \delta )  $$ It's trivial to show that the standard derivative is simply a case of $l = 0$ and $U = \dfrac{f(x + \delta) - f(x)}{\delta}$ Are there other flavors of derivatives yielded by this notation? Can one then create different orders of calculus depending on the type of derivative utilized and create a general theory of Calculuses? Has this been done before and if so where should I look for more information?",,"['calculus', 'real-analysis', 'limits', 'derivatives']"
80,Derivatives and tangent to the line of a curve,Derivatives and tangent to the line of a curve,,"Find the equations of all tangent lines to the curve y=x/(x+1) that intersect the point (1,2). Note that the point (1,2) does not lie on the curve. Please simplify your final answer as much as possible. This is what I have done so far. I don't know if it is correct. 1/(x+1)= -x-2/(x-1) [cross-multiplied] to get, x-1=-x^2 -3x -2 I made it equal to zero to get a quadratic equation of x^2 + 4x + 1 = 0 to solve for x I got x = -2 +- root 3 I dont know what to do next.","Find the equations of all tangent lines to the curve y=x/(x+1) that intersect the point (1,2). Note that the point (1,2) does not lie on the curve. Please simplify your final answer as much as possible. This is what I have done so far. I don't know if it is correct. 1/(x+1)= -x-2/(x-1) [cross-multiplied] to get, x-1=-x^2 -3x -2 I made it equal to zero to get a quadratic equation of x^2 + 4x + 1 = 0 to solve for x I got x = -2 +- root 3 I dont know what to do next.",,"['calculus', 'derivatives']"
81,Evaluating the following expression,Evaluating the following expression,,"Why is the value of the following expression equal to 0? I have a feeling that I need to apply L'Hopital's rule, but I do not know where. $[-x(1-F_X(x)]\Big|_0^{\infty}$, where $F_X(x)$ is the cumulative distribution function of the random variable $X$. Thanks!","Why is the value of the following expression equal to 0? I have a feeling that I need to apply L'Hopital's rule, but I do not know where. $[-x(1-F_X(x)]\Big|_0^{\infty}$, where $F_X(x)$ is the cumulative distribution function of the random variable $X$. Thanks!",,['probability']
82,Derivative of an Integral?,Derivative of an Integral?,,"So I have $$ f(x) = \int_{0}^{1-x^2} e^{(t^2)} dt  $$ And I'm trying to get the derivative of it. I followed the example at the bottom of http://ltcconline.net/greenl/courses/105/antiderivatives/secfund.htm to do this. So first made $$u = 1-x^2$$ and $$y = \int_{0}^{u}e^{(t^2)} dt$$ then used the chain rule $$\frac{dy}{dx} = \frac{dy}{du} * \frac{du}{dx} = e^{u^2} * (-2x)$$ Then subbed u for 1-x^2 in, giving me $$= -2e^{(1-x^2)^2}x$$ But when I plug this in WolframAlpha, I get $$\frac{d}{dx}(\int_{0}^{1-x^2} e^{(t^2)}  dt) = -2 e^{(x^2-1)^2} x$$ In the exponent of e, mine is 1-x^2, but Wolfram gives me x^2-1?","So I have $$ f(x) = \int_{0}^{1-x^2} e^{(t^2)} dt  $$ And I'm trying to get the derivative of it. I followed the example at the bottom of http://ltcconline.net/greenl/courses/105/antiderivatives/secfund.htm to do this. So first made $$u = 1-x^2$$ and $$y = \int_{0}^{u}e^{(t^2)} dt$$ then used the chain rule $$\frac{dy}{dx} = \frac{dy}{du} * \frac{du}{dx} = e^{u^2} * (-2x)$$ Then subbed u for 1-x^2 in, giving me $$= -2e^{(1-x^2)^2}x$$ But when I plug this in WolframAlpha, I get $$\frac{d}{dx}(\int_{0}^{1-x^2} e^{(t^2)}  dt) = -2 e^{(x^2-1)^2} x$$ In the exponent of e, mine is 1-x^2, but Wolfram gives me x^2-1?",,"['integration', 'derivatives']"
83,On the existence of a notation in matrix calculus,On the existence of a notation in matrix calculus,,"Is there any especial operator on the function $f(x)$ to represent the following matrix: \begin{bmatrix} f & \frac{\mathrm{d}}{\mathrm{d} x}f & \frac{\mathrm{d^2}}{\mathrm{d} x^2}f & ... \\  f^2 & \frac{\mathrm{d}}{\mathrm{d} x} f^2 & \frac{\mathrm{d^2}}{\mathrm{d} x^2} f^2 & \cdots \\  f^3 & \frac{\mathrm{d} }{\mathrm{d} x}f^3 & \frac{\mathrm{d^2}}{\mathrm{d} x^2} f^3 & \cdots\\ \vdots  & \vdots  &\vdots &\ddots \end{bmatrix} If there is not such operator, how could we express this by means of available operators?","Is there any especial operator on the function $f(x)$ to represent the following matrix: \begin{bmatrix} f & \frac{\mathrm{d}}{\mathrm{d} x}f & \frac{\mathrm{d^2}}{\mathrm{d} x^2}f & ... \\  f^2 & \frac{\mathrm{d}}{\mathrm{d} x} f^2 & \frac{\mathrm{d^2}}{\mathrm{d} x^2} f^2 & \cdots \\  f^3 & \frac{\mathrm{d} }{\mathrm{d} x}f^3 & \frac{\mathrm{d^2}}{\mathrm{d} x^2} f^3 & \cdots\\ \vdots  & \vdots  &\vdots &\ddots \end{bmatrix} If there is not such operator, how could we express this by means of available operators?",,"['calculus', 'matrices', 'derivatives']"
84,Higher Derivatives of trigonometric functions,Higher Derivatives of trigonometric functions,,"The position of a particle is given by $s = 5 \cos (2t+ (\pi/4))$ at time $t$ . What are the maximum values of the displacement,the velocity,and the acceleration? The answers are displacement: $5$ velocity: $10$ acceleration: $20$ I tried to do it but I am not getting the right answer. Here is my solution: $s(t) = 5\cos(2t+ \pi/4)$ $s'(t) = -10 \sin(2t + \pi/4)$ $0= -10[\sin2t\cos\pi/4 + \cos2t\sin\pi/4]$ $-\sin2t(\sqrt{2}/2) = \cos2t(\sqrt{2}/2)$ $-1=\tan2t$ $\tan2t = 3\pi/8, 7\pi/8$ when I substitute the values, I get -5.  For the v(t).I got zero. please help thanks!","The position of a particle is given by $s = 5 \cos (2t+ (\pi/4))$ at time $t$ . What are the maximum values of the displacement,the velocity,and the acceleration? The answers are displacement: $5$ velocity: $10$ acceleration: $20$ I tried to do it but I am not getting the right answer. Here is my solution: $s(t) = 5\cos(2t+ \pi/4)$ $s'(t) = -10 \sin(2t + \pi/4)$ $0= -10[\sin2t\cos\pi/4 + \cos2t\sin\pi/4]$ $-\sin2t(\sqrt{2}/2) = \cos2t(\sqrt{2}/2)$ $-1=\tan2t$ $\tan2t = 3\pi/8, 7\pi/8$ when I substitute the values, I get -5.  For the v(t).I got zero. please help thanks!",,"['algebra-precalculus', 'trigonometry', 'derivatives', 'physics']"
85,Material derivative of a material vector field,Material derivative of a material vector field,,"On page 12 of An Introduction to Theoretical Fluid Dynamics , following the introduction of a material vector field $v_i(\mathbf a,t)=J_{ij}(\mathbf a,t)V_j(\mathbf a)$ the author wrote: $$     \frac{\mathrm D \mathbf v}{\mathrm D t}     =     \left. \frac{\partial \mathbf v}{\partial t} \right| _ {\mathbf x}   + \mathbf u \cdot \nabla \mathbf v   - \mathbf v \cdot \nabla \mathbf u     \equiv     v_t+\mathcal L_{\mathbf u} \mathbf v     = 0 $$ Question: Shouldn't the material derivative of $\mathbf v$ be the following? Where is the ""extra"" term with the negative sign from? $$     \frac{\mathrm D \mathbf v}{\mathrm D t}     =     \left. \frac{\partial \mathbf v}{\partial t} \right| _ {\mathbf x}   + \mathbf u \cdot \nabla \mathbf v $$ Update: I believe it has something to do with Eqn. (1.22) which states that $$     \left. \frac{\partial \mathbf v}{\partial t} \right |_{\mathbf a} =     \mathbf v\cdot\nabla\mathbf u $$","On page 12 of An Introduction to Theoretical Fluid Dynamics , following the introduction of a material vector field $v_i(\mathbf a,t)=J_{ij}(\mathbf a,t)V_j(\mathbf a)$ the author wrote: $$     \frac{\mathrm D \mathbf v}{\mathrm D t}     =     \left. \frac{\partial \mathbf v}{\partial t} \right| _ {\mathbf x}   + \mathbf u \cdot \nabla \mathbf v   - \mathbf v \cdot \nabla \mathbf u     \equiv     v_t+\mathcal L_{\mathbf u} \mathbf v     = 0 $$ Question: Shouldn't the material derivative of $\mathbf v$ be the following? Where is the ""extra"" term with the negative sign from? $$     \frac{\mathrm D \mathbf v}{\mathrm D t}     =     \left. \frac{\partial \mathbf v}{\partial t} \right| _ {\mathbf x}   + \mathbf u \cdot \nabla \mathbf v $$ Update: I believe it has something to do with Eqn. (1.22) which states that $$     \left. \frac{\partial \mathbf v}{\partial t} \right |_{\mathbf a} =     \mathbf v\cdot\nabla\mathbf u $$",,"['derivatives', 'fluid-dynamics']"
86,Derivative of the inverse of $y=(a+bx)e^{cx}$,Derivative of the inverse of,y=(a+bx)e^{cx},"I need to solve for the 1st derivative of the inverse of $y=(a+bx)e^{cx}$ but my calculus is a bit rusty. I know that to get the inverse function, I would have to use the Lambert W method but I think that the 1st derivative is different. Anyway, if I understand correctly, the 1st derivative of the inverse is just 1/y'(yinv). In this case that would make my answer: $$\frac 1{be^{cy}+ce^{cy}(a+by)}$$ If someone could verify this for me or point me in the right direction I would really appreciate it.","I need to solve for the 1st derivative of the inverse of $y=(a+bx)e^{cx}$ but my calculus is a bit rusty. I know that to get the inverse function, I would have to use the Lambert W method but I think that the 1st derivative is different. Anyway, if I understand correctly, the 1st derivative of the inverse is just 1/y'(yinv). In this case that would make my answer: $$\frac 1{be^{cy}+ce^{cy}(a+by)}$$ If someone could verify this for me or point me in the right direction I would really appreciate it.",,"['derivatives', 'inverse', 'exponential-function']"
87,Find force required for a launch between two points,Find force required for a launch between two points,,"Let me start by saying this is within a game environment, so gravity isn't 9.81m/s^2, and the unit of measure for distance will be ""blocks"". I'm attempting to find the amount of force needed in order to launch a player into the air, from point A to point B. For my example, I assumed that it was in a straight line of 60 blocks away, and attempted to work from there. Knowing that velocity is the derivative of distance, and acceleration the derivative of velocity, I mustered together those variables, along with others. In the game: Gravity pulls at 13 blocks/second Acceleration to the ground is at 22.48 blocks/second^2 A block is a distance of 1 meter. I have a general mockup of attempting to start the problem, but to be honest I'm completely stumped on where to take it. I need to find the initial velocity to launch at, as well as what angle to do it at. General mockup: https://i.sstatic.net/Vl6x4.jpg","Let me start by saying this is within a game environment, so gravity isn't 9.81m/s^2, and the unit of measure for distance will be ""blocks"". I'm attempting to find the amount of force needed in order to launch a player into the air, from point A to point B. For my example, I assumed that it was in a straight line of 60 blocks away, and attempted to work from there. Knowing that velocity is the derivative of distance, and acceleration the derivative of velocity, I mustered together those variables, along with others. In the game: Gravity pulls at 13 blocks/second Acceleration to the ground is at 22.48 blocks/second^2 A block is a distance of 1 meter. I have a general mockup of attempting to start the problem, but to be honest I'm completely stumped on where to take it. I need to find the initial velocity to launch at, as well as what angle to do it at. General mockup: https://i.sstatic.net/Vl6x4.jpg",,"['derivatives', 'physics']"
88,Inverse function theorem application,Inverse function theorem application,,I have to solve this question with this solution way. But I made some mistakes while solving. I cannot see thesemistakes. And I cannot reach the wanted result properly. Please somebody helps me. Thank you so much. I Will be happy to help me. ----- I added an example from my notebook. I need to solve the question 11.6.4(above picture) with this example's solution way. I tried to solve the question 11.6.4 with this solution way. But I failed. The example's photo is folowing..,I have to solve this question with this solution way. But I made some mistakes while solving. I cannot see thesemistakes. And I cannot reach the wanted result properly. Please somebody helps me. Thank you so much. I Will be happy to help me. ----- I added an example from my notebook. I need to solve the question 11.6.4(above picture) with this example's solution way. I tried to solve the question 11.6.4 with this solution way. But I failed. The example's photo is folowing..,,"['calculus', 'real-analysis', 'analysis', 'derivatives']"
89,Compare the approximation with the actual value of $\Delta w$,Compare the approximation with the actual value of,\Delta w,"Let $w=x^2y+z$ Use differentials to approximate $\Delta w$ as $(x,y,z)$ moves from $(1,2,1)$ to $(1.01, 1.98, 1.03)$ Compare your approximation with the actual value of $Delta w$ I calculated $dw=2xydx+ x^2dy+dz$ From there, how to calculate $\Delta w$ ? And how to compare? Please show me how to calculate step by step. Please write this clearly with formulas. Do not just give the result. Thank you.","Let $w=x^2y+z$ Use differentials to approximate $\Delta w$ as $(x,y,z)$ moves from $(1,2,1)$ to $(1.01, 1.98, 1.03)$ Compare your approximation with the actual value of $Delta w$ I calculated $dw=2xydx+ x^2dy+dz$ From there, how to calculate $\Delta w$ ? And how to compare? Please show me how to calculate step by step. Please write this clearly with formulas. Do not just give the result. Thank you.",,"['calculus', 'real-analysis', 'analysis', 'derivatives']"
90,differentiation under the integral sign,differentiation under the integral sign,,"Let $f \in L^1(R)$. Consider the function: $$ F(x) = \int_R e^{ixt}f(t) dt $$ If $|t|^kf(x) \in L^\infty(R)$ for all $k \ge 1$, show that $F$ is infinitely differentiable. Suppose in addition that $f$ is continuous, show that $\lim_{|x|\rightarrow \infty} F(x) = 0$. For the first part, it's easy to show that the first derivative of $F$ exist. Basically, we only need to show the following equality: $$ \lim_{|h|\rightarrow 0} \int_{R} \frac{e^{i(x+h)t} - e^{ixt}}{h} f(t)dt = \int_{R}\lim_{|h|\rightarrow 0} \frac{e^{i(x+h)t} - e^{ixt}}{h} f(t)dt $$ Since $f \in L^1$, the above can be achieved by the Dominated Convergence Theorem.  Similarly, to show $F$ is twice differentiable, we need to establish the following: $$ \lim_{|h|\rightarrow 0} \int_{R} \frac{e^{i(x+h)t} - e^{ixt}}{h} itf(t)dt = \int_{R}\lim_{|h|\rightarrow 0} \frac{e^{i(x+h)t} - e^{ixt}}{h} itf(t)dt $$ My question arises here: if we adapt the idea for showing $F$ is differentiable, then we need $itf(t)$ to be in $L^1$. But the assumption in the question is that $itf(t) \in L^\infty$. Thanks.","Let $f \in L^1(R)$. Consider the function: $$ F(x) = \int_R e^{ixt}f(t) dt $$ If $|t|^kf(x) \in L^\infty(R)$ for all $k \ge 1$, show that $F$ is infinitely differentiable. Suppose in addition that $f$ is continuous, show that $\lim_{|x|\rightarrow \infty} F(x) = 0$. For the first part, it's easy to show that the first derivative of $F$ exist. Basically, we only need to show the following equality: $$ \lim_{|h|\rightarrow 0} \int_{R} \frac{e^{i(x+h)t} - e^{ixt}}{h} f(t)dt = \int_{R}\lim_{|h|\rightarrow 0} \frac{e^{i(x+h)t} - e^{ixt}}{h} f(t)dt $$ Since $f \in L^1$, the above can be achieved by the Dominated Convergence Theorem.  Similarly, to show $F$ is twice differentiable, we need to establish the following: $$ \lim_{|h|\rightarrow 0} \int_{R} \frac{e^{i(x+h)t} - e^{ixt}}{h} itf(t)dt = \int_{R}\lim_{|h|\rightarrow 0} \frac{e^{i(x+h)t} - e^{ixt}}{h} itf(t)dt $$ My question arises here: if we adapt the idea for showing $F$ is differentiable, then we need $itf(t)$ to be in $L^1$. But the assumption in the question is that $itf(t) \in L^\infty$. Thanks.",,"['real-analysis', 'derivatives']"
91,second and first derivative growth function,second and first derivative growth function,,"I have a function I would like to take the first and second derivative from $$f(t)= a\left(1-\frac{1}{1+(b(t+i))^e+(c(t+i))^f+(d(t+i))^h)}\right)$$ I have taken the following steps $$u(t)={\left(\mathrm{b}\, \left(\mathrm{i} + t\right)\right)}^{\mathrm{e}} + {\left(\mathrm{c}\, \left(\mathrm{i} + t\right)\right)}^{\mathrm{f}} + {\left(\mathrm{d}\, \left(\mathrm{i} + t\right)\right)}^{\mathrm{h}} + 1$$ $f(t) = a (1-1/u(t))$ $f(t) = a ((u(t)-1)/u(t))$ for simplicity u(t) = u and f(t)=f f= a*(u-1)/u quotient rule dy = d(u-1) df = a*((du*u-du*(u-1))/u^2) df = a * du/u^2 quotient rule d2f = a*((d2u*u^2-du*d(u^2))/u^4) Is the above reasoning correct? df= (a*(b*e*(b*(i + t))^(e - 1) + c*f*(c*(i + t))^(f - 1) + d*h*(d*(i + t))^(h - 1)))/((b*(i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1)^2 d2f=(a*((b^2*e*(e - 1) (b (i + t))^(e - 2) + c^2*f*(f - 1) (c (i + t))^(f - 2) + d^2*h*(h - 1) (d (i + t))^(h - 2)) ((b (i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1)^2 - (2*(b*e*(b*(i + t))^(e - 1) + c*f*(c*(i + t))^(f - 1) + d*h*(d*(i + t))^(h - 1))^2 + 2*(b^2*e*(e - 1) (b (i + t))^(e - 2) + c^2*f*(f - 1) (c (i + t))^(f - 2) + d^2*h*(h - 1) (d (i + t))^(h - 2)) ((b (i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1))*(b*e*(b*(i + t))^(e - 1) + c*f*(c*(i + t))^(f - 1) + d*h*(d*(i + t))^(h - 1))))/((b*(i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1)^4 $\dfrac{d}{dt} f(t) = \frac{a\, \left(b\, e\, {\left(b\, \left(i + t\right)\right)}^{e - 1} + c\, f\, {\left(c\, \left(i + t\right)\right)}^{f - 1} + d\, h\, {\left(d\, \left(i + t\right)\right)}^{h - 1}\right)}{{\left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)}^2}$ $\dfrac{d2}{d2t} f(t) =\frac{a\, \left(\left(b^2\, e\, \left(e - 1\right)\, {\left(b\, \left(i + t\right)\right)}^{e - 2} + c^2\, f\, \left(f - 1\right)\, {\left(c\, \left(i + t\right)\right)}^{f - 2} + d^2\, h\, \left(h - 1\right)\, {\left(d\, \left(i + t\right)\right)}^{h - 2}\right)\, {\left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)}^2 - \left(2\, {\left(b\, e\, {\left(b\, \left(i + t\right)\right)}^{e - 1} + c\, f\, {\left(c\, \left(i + t\right)\right)}^{f - 1} + d\, h\, {\left(d\, \left(i + t\right)\right)}^{h - 1}\right)}^2 + 2\, \left(b^2\, e\, \left(e - 1\right)\, {\left(b\, \left(i + t\right)\right)}^{e - 2} + c^2\, f\, \left(f - 1\right)\, {\left(c\, \left(i + t\right)\right)}^{f - 2} + d^2\, h\, \left(h - 1\right)\, {\left(d\, \left(i + t\right)\right)}^{h - 2}\right)\, \left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)\right)\, \left(b\, e\, {\left(b\, \left(i + t\right)\right)}^{e - 1} + c\, f\, {\left(c\, \left(i + t\right)\right)}^{f - 1} + d\, h\, {\left(d\, \left(i + t\right)\right)}^{h - 1}\right)\right)}{{\left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)}^4}$","I have a function I would like to take the first and second derivative from $$f(t)= a\left(1-\frac{1}{1+(b(t+i))^e+(c(t+i))^f+(d(t+i))^h)}\right)$$ I have taken the following steps $$u(t)={\left(\mathrm{b}\, \left(\mathrm{i} + t\right)\right)}^{\mathrm{e}} + {\left(\mathrm{c}\, \left(\mathrm{i} + t\right)\right)}^{\mathrm{f}} + {\left(\mathrm{d}\, \left(\mathrm{i} + t\right)\right)}^{\mathrm{h}} + 1$$ $f(t) = a (1-1/u(t))$ $f(t) = a ((u(t)-1)/u(t))$ for simplicity u(t) = u and f(t)=f f= a*(u-1)/u quotient rule dy = d(u-1) df = a*((du*u-du*(u-1))/u^2) df = a * du/u^2 quotient rule d2f = a*((d2u*u^2-du*d(u^2))/u^4) Is the above reasoning correct? df= (a*(b*e*(b*(i + t))^(e - 1) + c*f*(c*(i + t))^(f - 1) + d*h*(d*(i + t))^(h - 1)))/((b*(i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1)^2 d2f=(a*((b^2*e*(e - 1) (b (i + t))^(e - 2) + c^2*f*(f - 1) (c (i + t))^(f - 2) + d^2*h*(h - 1) (d (i + t))^(h - 2)) ((b (i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1)^2 - (2*(b*e*(b*(i + t))^(e - 1) + c*f*(c*(i + t))^(f - 1) + d*h*(d*(i + t))^(h - 1))^2 + 2*(b^2*e*(e - 1) (b (i + t))^(e - 2) + c^2*f*(f - 1) (c (i + t))^(f - 2) + d^2*h*(h - 1) (d (i + t))^(h - 2)) ((b (i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1))*(b*e*(b*(i + t))^(e - 1) + c*f*(c*(i + t))^(f - 1) + d*h*(d*(i + t))^(h - 1))))/((b*(i + t))^e + (c*(i + t))^f + (d*(i + t))^h + 1)^4 $\dfrac{d}{dt} f(t) = \frac{a\, \left(b\, e\, {\left(b\, \left(i + t\right)\right)}^{e - 1} + c\, f\, {\left(c\, \left(i + t\right)\right)}^{f - 1} + d\, h\, {\left(d\, \left(i + t\right)\right)}^{h - 1}\right)}{{\left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)}^2}$ $\dfrac{d2}{d2t} f(t) =\frac{a\, \left(\left(b^2\, e\, \left(e - 1\right)\, {\left(b\, \left(i + t\right)\right)}^{e - 2} + c^2\, f\, \left(f - 1\right)\, {\left(c\, \left(i + t\right)\right)}^{f - 2} + d^2\, h\, \left(h - 1\right)\, {\left(d\, \left(i + t\right)\right)}^{h - 2}\right)\, {\left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)}^2 - \left(2\, {\left(b\, e\, {\left(b\, \left(i + t\right)\right)}^{e - 1} + c\, f\, {\left(c\, \left(i + t\right)\right)}^{f - 1} + d\, h\, {\left(d\, \left(i + t\right)\right)}^{h - 1}\right)}^2 + 2\, \left(b^2\, e\, \left(e - 1\right)\, {\left(b\, \left(i + t\right)\right)}^{e - 2} + c^2\, f\, \left(f - 1\right)\, {\left(c\, \left(i + t\right)\right)}^{f - 2} + d^2\, h\, \left(h - 1\right)\, {\left(d\, \left(i + t\right)\right)}^{h - 2}\right)\, \left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)\right)\, \left(b\, e\, {\left(b\, \left(i + t\right)\right)}^{e - 1} + c\, f\, {\left(c\, \left(i + t\right)\right)}^{f - 1} + d\, h\, {\left(d\, \left(i + t\right)\right)}^{h - 1}\right)\right)}{{\left({\left(b\, \left(i + t\right)\right)}^e + {\left(c\, \left(i + t\right)\right)}^f + {\left(d\, \left(i + t\right)\right)}^h + 1\right)}^4}$",,['derivatives']
92,Derivative of $x\times n - 2^{\log_2 {x \times n}}$,Derivative of,x\times n - 2^{\log_2 {x \times n}},"I have a problem with solving derivative of $f(x)$ in this case: $$f(x) = x\times 10^9 - 2^{\log_{10} x\times 10^9}$$ This is what I have: $$f^\prime(x) = \lim_{m\to0} {f(x+m) - f(x)\over m}$$ $$= \lim_{m\to0} {{((x+m)\times 10^9 - 2^{\log_{10} (x+m)\times 10^9}) - (x\times 10^9 - 2^{\log_{10} x\times 10^9})} \over m}$$ $$= \lim_{m\to0} {{m\times10^9 - 2^{\log_{10} (x+m)\times 10^9} + 2^{\log_{10} x\times10^9}} \over m}$$ From here I can't move. I can probably calculate ${m \over m}$ to have problem in this state $$= \lim_{m\to0} 10^9 + {{- 2^{\log_{10} (x+m)\times 10^9} + 2^{\log_{10} x\times10^9}} \over m}$$ But if $m$ becomes $0$, it looks like the result is... $$f^\prime(x) = 10^9+0$$ ...because ${x \over 0}=0$. What am I doing wrong? How can I solve this? Please help.","I have a problem with solving derivative of $f(x)$ in this case: $$f(x) = x\times 10^9 - 2^{\log_{10} x\times 10^9}$$ This is what I have: $$f^\prime(x) = \lim_{m\to0} {f(x+m) - f(x)\over m}$$ $$= \lim_{m\to0} {{((x+m)\times 10^9 - 2^{\log_{10} (x+m)\times 10^9}) - (x\times 10^9 - 2^{\log_{10} x\times 10^9})} \over m}$$ $$= \lim_{m\to0} {{m\times10^9 - 2^{\log_{10} (x+m)\times 10^9} + 2^{\log_{10} x\times10^9}} \over m}$$ From here I can't move. I can probably calculate ${m \over m}$ to have problem in this state $$= \lim_{m\to0} 10^9 + {{- 2^{\log_{10} (x+m)\times 10^9} + 2^{\log_{10} x\times10^9}} \over m}$$ But if $m$ becomes $0$, it looks like the result is... $$f^\prime(x) = 10^9+0$$ ...because ${x \over 0}=0$. What am I doing wrong? How can I solve this? Please help.",,"['limits', 'derivatives', 'logarithms', 'exponentiation']"
93,Product and Quotient rule for FrÃ©chet derivatives,Product and Quotient rule for FrÃ©chet derivatives,,"Does anyone know whether the product/quotient rule for FrÃ©chet derivatives still hold? For example, consider the evaluation operator: $$\rho_x : (C[a,b],\|\cdot\|_\infty) \rightarrow (\mathbb{R},|\cdot|)$$ where $\|\cdot\|_\infty$ is the sup-norm and $|\cdot|$ the Euclidean norm. Then I may define an operator: $T$ for $f\in C[a,b]$ acting as $$T(f) = \frac{\rho_x (f)}{\rho_y(f)} = \frac{f(x)}{f(y)}$$ (Assume the denominator is not zero). Knowing that the FrÃ©chet derivative of $\rho_x$ is $\rho_x$ itself at any point $f\in C[a,b]$, what can we say about the FrÃ©chet derivative of $T$? Guess: $DT(f)(\cdot) = \frac{\rho_y(f)\rho_x(\cdot) + \rho_x(f)\rho_y(\cdot) }{\rho_y(f)^2} \in L(C[a,b],\mathbb{R})$ Thanks for you answers!","Does anyone know whether the product/quotient rule for FrÃ©chet derivatives still hold? For example, consider the evaluation operator: $$\rho_x : (C[a,b],\|\cdot\|_\infty) \rightarrow (\mathbb{R},|\cdot|)$$ where $\|\cdot\|_\infty$ is the sup-norm and $|\cdot|$ the Euclidean norm. Then I may define an operator: $T$ for $f\in C[a,b]$ acting as $$T(f) = \frac{\rho_x (f)}{\rho_y(f)} = \frac{f(x)}{f(y)}$$ (Assume the denominator is not zero). Knowing that the FrÃ©chet derivative of $\rho_x$ is $\rho_x$ itself at any point $f\in C[a,b]$, what can we say about the FrÃ©chet derivative of $T$? Guess: $DT(f)(\cdot) = \frac{\rho_y(f)\rho_x(\cdot) + \rho_x(f)\rho_y(\cdot) }{\rho_y(f)^2} \in L(C[a,b],\mathbb{R})$ Thanks for you answers!",,"['calculus', 'real-analysis', 'functional-analysis', 'derivatives', 'operator-theory']"
94,Primitive of a rational function,Primitive of a rational function,,Does there exists some simple criteria to know when the primitive of a rational function of $\mathbb{C}[z]$ is still a rational function? In fact my question is more about the stability of this property. Let $P$ and  $Q$ two coprime polynomials and let $A$ and $B$ two coprime polynomials such that $$\frac{A}{B}= \left(\frac{P}{Q}\right)'= \frac{P'Q-PQ'}{Q^2}.$$ Then considering a pertubation $A^\varepsilon$ of $A$ (in the sense the roots of $A^\varepsilon$ converge to the one of $A$ with the same multiplicity as $\varepsilon$ goes to zero.): does $\dfrac{A^\varepsilon}{B}$ admit a primitive which is rational function?,Does there exists some simple criteria to know when the primitive of a rational function of $\mathbb{C}[z]$ is still a rational function? In fact my question is more about the stability of this property. Let $P$ and  $Q$ two coprime polynomials and let $A$ and $B$ two coprime polynomials such that $$\frac{A}{B}= \left(\frac{P}{Q}\right)'= \frac{P'Q-PQ'}{Q^2}.$$ Then considering a pertubation $A^\varepsilon$ of $A$ (in the sense the roots of $A^\varepsilon$ converge to the one of $A$ with the same multiplicity as $\varepsilon$ goes to zero.): does $\dfrac{A^\varepsilon}{B}$ admit a primitive which is rational function?,,"['derivatives', 'rational-functions']"
95,Directional derivative of multi-variable function,Directional derivative of multi-variable function,,"I have the next function: $f(x,y,z)=\sqrt{x^2+y^2+z^2}$ and i need to find it's directional derivative of the point $(0,0,0)$ and the vector $v=(\frac1{\sqrt{3}},-\frac1{\sqrt{3}},\frac1{\sqrt{3}})$ So I've started by finding the partial derivatives: ${f'}_x(x,y,z)=\frac x{\sqrt{x^2+y^2+z^2}}$, ${f'}_y(x,y,z)=\frac y{\sqrt{x^2+y^2+z^2}}$, ${f'}_z(x,y,z)=\frac z{\sqrt{x^2+y^2+z^2}}$ Now i'm pretty much stuck. Since placing $(0,0,0)$ makes an undefined expression, What can i do from this point on?","I have the next function: $f(x,y,z)=\sqrt{x^2+y^2+z^2}$ and i need to find it's directional derivative of the point $(0,0,0)$ and the vector $v=(\frac1{\sqrt{3}},-\frac1{\sqrt{3}},\frac1{\sqrt{3}})$ So I've started by finding the partial derivatives: ${f'}_x(x,y,z)=\frac x{\sqrt{x^2+y^2+z^2}}$, ${f'}_y(x,y,z)=\frac y{\sqrt{x^2+y^2+z^2}}$, ${f'}_z(x,y,z)=\frac z{\sqrt{x^2+y^2+z^2}}$ Now i'm pretty much stuck. Since placing $(0,0,0)$ makes an undefined expression, What can i do from this point on?",,"['calculus', 'derivatives']"
96,"Optimize a log det function with respect to a matrix, and the saddle point analysis","Optimize a log det function with respect to a matrix, and the saddle point analysis",,"Suppose I want to to find the local minima of a logdet function $\mathcal{L}$ with respect to a Matrix $\mathbf{A}$,  $$ \mathcal{L} = \log\vert \mathbf{I} + \mathbf{A}\mathbf{S} \vert - \mathbf{q}^T(\mathbf{A}^{-1} + \mathbf{S})^{-1} \mathbf{q}, $$ where $\mathbf{S}$ is a Symmetric Positive Semi-Definite Matrix, $\mathbf{q}$ is a column vector, $\mathbf{I}$ is an identity matrix. I could find the local minima of $\mathcal{L}$ by solving, $$ \min_\mathbf{A} \mathcal{L} \qquad \rightarrow \qquad \frac{\partial \mathcal{L}}{\partial \mathbf{A}} = \mathbf{0}. $$  the closed form solution of $\mathbf{A}$ ($\frac{\partial \mathcal{L}}{\partial \mathbf{A}} = \mathbf{0}$) can be derived,  $$ \mathbf{A} = \mathbf{S}^{-1}(\mathbf{S} - \mathbf{q}\mathbf{q}^T)\mathbf{S}^{-1} $$ The questions are Given $\mathbf{S}$ a positive definite matrix, $\mathbf{qq}^T$ a rank one positive semi-definite matrix, what's the condition that $\mathbf{A} = \mathbf{S}^{-1}(\mathbf{S} - \mathbf{q}\mathbf{q}^T)\mathbf{S}^{-1}$ being a PD(or PSD) matrix ? Is $\mathrm{Trace}[\mathbf{A}] > 0$ sufficient ? How to analyze the stationary point of the partial derivatives $\frac{\partial \mathcal{L}}{\partial \mathbf{A}} = \mathbf{0}$ ?","Suppose I want to to find the local minima of a logdet function $\mathcal{L}$ with respect to a Matrix $\mathbf{A}$,  $$ \mathcal{L} = \log\vert \mathbf{I} + \mathbf{A}\mathbf{S} \vert - \mathbf{q}^T(\mathbf{A}^{-1} + \mathbf{S})^{-1} \mathbf{q}, $$ where $\mathbf{S}$ is a Symmetric Positive Semi-Definite Matrix, $\mathbf{q}$ is a column vector, $\mathbf{I}$ is an identity matrix. I could find the local minima of $\mathcal{L}$ by solving, $$ \min_\mathbf{A} \mathcal{L} \qquad \rightarrow \qquad \frac{\partial \mathcal{L}}{\partial \mathbf{A}} = \mathbf{0}. $$  the closed form solution of $\mathbf{A}$ ($\frac{\partial \mathcal{L}}{\partial \mathbf{A}} = \mathbf{0}$) can be derived,  $$ \mathbf{A} = \mathbf{S}^{-1}(\mathbf{S} - \mathbf{q}\mathbf{q}^T)\mathbf{S}^{-1} $$ The questions are Given $\mathbf{S}$ a positive definite matrix, $\mathbf{qq}^T$ a rank one positive semi-definite matrix, what's the condition that $\mathbf{A} = \mathbf{S}^{-1}(\mathbf{S} - \mathbf{q}\mathbf{q}^T)\mathbf{S}^{-1}$ being a PD(or PSD) matrix ? Is $\mathrm{Trace}[\mathbf{A}] > 0$ sufficient ? How to analyze the stationary point of the partial derivatives $\frac{\partial \mathcal{L}}{\partial \mathbf{A}} = \mathbf{0}$ ?",,"['linear-algebra', 'matrices', 'derivatives', 'convex-analysis', 'convex-optimization']"
97,Wirtinger derivative of composition of functions,Wirtinger derivative of composition of functions,,"So I have a very basic question : let $h : \mathbb{R} \rightarrow \mathbb{R}$ be a $C^1$ function, and let $g : \mathbb{C} \rightarrow \mathbb{R}$ be defined by $g(z)=h(z \overline{z})$. I want to compute $\frac{\partial g}{\partial \overline{z}}$ (which is defined because $g$ is defined on $\mathbb{C}$). I know the chain rule for $\overline{\partial}$. However, it involves terms like $\frac{\partial h}{\partial z}$ and $\frac{\partial h}{\partial \overline{z}}$, which confuses me because $h$ is only defined on $\mathbb{R}$. Any help appreciated !","So I have a very basic question : let $h : \mathbb{R} \rightarrow \mathbb{R}$ be a $C^1$ function, and let $g : \mathbb{C} \rightarrow \mathbb{R}$ be defined by $g(z)=h(z \overline{z})$. I want to compute $\frac{\partial g}{\partial \overline{z}}$ (which is defined because $g$ is defined on $\mathbb{C}$). I know the chain rule for $\overline{\partial}$. However, it involves terms like $\frac{\partial h}{\partial z}$ and $\frac{\partial h}{\partial \overline{z}}$, which confuses me because $h$ is only defined on $\mathbb{R}$. Any help appreciated !",,"['complex-analysis', 'derivatives']"
98,"Suppose $f$ is a real-differentiable function on $[a,b]$ and suppose $f'(a)<c<f'(b)$. Prove then there is a point $x \in (a,b)$ such that $f'(x)=c$",Suppose  is a real-differentiable function on  and suppose . Prove then there is a point  such that,"f [a,b] f'(a)<c<f'(b) x \in (a,b) f'(x)=c","This is what i have: Put $g(t) = f(t) - ct$. Then $g'(a)<0$ so that $g(t_{1}) < g(a)$ for some $t_{1} \in (a,b)$ and  $g'(b)>0$ so that $g(t_{2}) < g(b)$ for some $t_{2} \in (a,b)$. Hence $g$ attains its minimum on $[a,b]$ at some point x such that $a<x<b$. Then, $g'(x)=0$, hence $f'(x)=c$","This is what i have: Put $g(t) = f(t) - ct$. Then $g'(a)<0$ so that $g(t_{1}) < g(a)$ for some $t_{1} \in (a,b)$ and  $g'(b)>0$ so that $g(t_{2}) < g(b)$ for some $t_{2} \in (a,b)$. Hence $g$ attains its minimum on $[a,b]$ at some point x such that $a<x<b$. Then, $g'(x)=0$, hence $f'(x)=c$",,['derivatives']
99,"Let $f$ be defined on $[a,b]$, Prove that if f has a local maximum at a point $x \in (a,b)$, and if $f'(x)$ exists, then $f'(x)=0$","Let  be defined on , Prove that if f has a local maximum at a point , and if  exists, then","f [a,b] x \in (a,b) f'(x) f'(x)=0","Is this proof correct: Let's choose a $\delta$ to that $a < x - \delta < x < x + \delta < b$ If $ x - \delta < t < x$ then $\frac {f(t) - f(x)} {t-x} \geq 0$ Letting $t \rightarrow x$, we see that $f'(x) \geq 0$ If $ x < t < x + \delta$, then $\frac {f(t) - f(x)} {t-x} \leq 0$ Which shows that $f'(x) \leq 0$. Hence $f'(x) = 0$","Is this proof correct: Let's choose a $\delta$ to that $a < x - \delta < x < x + \delta < b$ If $ x - \delta < t < x$ then $\frac {f(t) - f(x)} {t-x} \geq 0$ Letting $t \rightarrow x$, we see that $f'(x) \geq 0$ If $ x < t < x + \delta$, then $\frac {f(t) - f(x)} {t-x} \leq 0$ Which shows that $f'(x) \leq 0$. Hence $f'(x) = 0$",,"['derivatives', 'maximum-principle']"
