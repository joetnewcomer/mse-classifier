,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Closed plus finite dimensional in a TVS,Closed plus finite dimensional in a TVS,,"If $E$ is a topological vector space (TVS), $F_1$ a closed subspace of $E$, and $F_2$ a finite dimensional subspace of $E$, such that $F_1 \cap F_2=\{0\}$, is $F_1+F_2$ necessarily closed? If yes, are the projection from $F_1+F_2$ onto $F_1$ and $F_2$ respectively, continuous?","If $E$ is a topological vector space (TVS), $F_1$ a closed subspace of $E$, and $F_2$ a finite dimensional subspace of $E$, such that $F_1 \cap F_2=\{0\}$, is $F_1+F_2$ necessarily closed? If yes, are the projection from $F_1+F_2$ onto $F_1$ and $F_2$ respectively, continuous?",,"['general-topology', 'functional-analysis']"
1,Two contradictory results on unbounded linear operators?,Two contradictory results on unbounded linear operators?,,"I have known that if $A$ is a densely defined (unbounded) operator with domain $D(A)$ such that $\langle Ax,x\rangle=0$ for all $x\in D(A)$ , then this does imply that $Ax=0$ for all $x\in D(A)$ . This result may be found e.g. in Schmudgen's new book on unbounded self-adjoint operators. However the following is a purported counter-example in these notes: Consider the differential operator $T:x\mapsto \frac{dx}{dt}$ defined on $C_c^{\infty}(\mathbb{R})$ which is a dense subset of $L^2(\mathbb{R})$ . Suppose then $x\in C_c^{\infty}(\mathbb{R})$ , then $$ \int_{\mathbb{R}}\frac{dx}{dt} x\,dt = x^2\bigg|_{-\infty}^{\infty} - \int_{\mathbb{R}} x\frac{dx}{dt}\,dt. $$ Hence $\langle Tx,x\rangle = 0$ for all $x\in C_c^{\infty}(\mathbb{R})$ but $Tx\neq 0$ for some $x$ . Any help please! Cheers...","I have known that if is a densely defined (unbounded) operator with domain such that for all , then this does imply that for all . This result may be found e.g. in Schmudgen's new book on unbounded self-adjoint operators. However the following is a purported counter-example in these notes: Consider the differential operator defined on which is a dense subset of . Suppose then , then Hence for all but for some . Any help please! Cheers...","A D(A) \langle Ax,x\rangle=0 x\in D(A) Ax=0 x\in D(A) T:x\mapsto \frac{dx}{dt} C_c^{\infty}(\mathbb{R}) L^2(\mathbb{R}) x\in C_c^{\infty}(\mathbb{R})  \int_{\mathbb{R}}\frac{dx}{dt} x\,dt = x^2\bigg|_{-\infty}^{\infty} - \int_{\mathbb{R}} x\frac{dx}{dt}\,dt.  \langle Tx,x\rangle = 0 x\in C_c^{\infty}(\mathbb{R}) Tx\neq 0 x",['functional-analysis']
2,Orthogonality in Schwartz space,Orthogonality in Schwartz space,,"Let $S$ denote the Schwartz space of functions $\mathbb R\to\mathbb R$ with its usual topology. Let $S_e$ and $S_o$ denote the subspaces consisting of even and odd functions, respectively. Suppose I have a subspace $X\subset S$ (just a linear subspace without any topological assumptions) so that for any $f\in S$ $$ f\in S_o \iff \left(\int fg=0\text{ for all }g\in X\right) . $$ Does it follow that $X$ is dense in $S_e$? It is not hard to check that $X\subset S_e$ and I feel it should be dense, but I don't see how to prove it. If I replace $X$ with its closure, I get an alternative formulation of the question: ""Assume additionally that $X$ is closed. Does it follow that $X=S_e$?"" The density result is true if I replace $S$ with $L^2$, but $S$ is not complete under the $L^2$ inner product. Assuming the result is false, there is a function $h\in S_e\setminus\bar X$, and one could then project to the orthogonal complement of $\bar X$ to produce a nonzero function $h'\in S_e$ so that $\int h'g=0$ for all $g\in\bar X$, a contradiction. If one attacks the problem this way, the problem is in showing that the $L^2$-orthogonal projection from $S_e$ to $\bar X$ is well defined (actually maps Schwartz functions to Schwartz functions). The closures I have taken are in the natural topology of $S$, not $L^2$ topology, so it's not trivial to make sense of the projection.","Let $S$ denote the Schwartz space of functions $\mathbb R\to\mathbb R$ with its usual topology. Let $S_e$ and $S_o$ denote the subspaces consisting of even and odd functions, respectively. Suppose I have a subspace $X\subset S$ (just a linear subspace without any topological assumptions) so that for any $f\in S$ $$ f\in S_o \iff \left(\int fg=0\text{ for all }g\in X\right) . $$ Does it follow that $X$ is dense in $S_e$? It is not hard to check that $X\subset S_e$ and I feel it should be dense, but I don't see how to prove it. If I replace $X$ with its closure, I get an alternative formulation of the question: ""Assume additionally that $X$ is closed. Does it follow that $X=S_e$?"" The density result is true if I replace $S$ with $L^2$, but $S$ is not complete under the $L^2$ inner product. Assuming the result is false, there is a function $h\in S_e\setminus\bar X$, and one could then project to the orthogonal complement of $\bar X$ to produce a nonzero function $h'\in S_e$ so that $\int h'g=0$ for all $g\in\bar X$, a contradiction. If one attacks the problem this way, the problem is in showing that the $L^2$-orthogonal projection from $S_e$ to $\bar X$ is well defined (actually maps Schwartz functions to Schwartz functions). The closures I have taken are in the natural topology of $S$, not $L^2$ topology, so it's not trivial to make sense of the projection.",,"['functional-analysis', 'orthogonality', 'schwartz-space']"
3,"Difficult to read about different subjects simultaneously, should I leave one for now? [closed]","Difficult to read about different subjects simultaneously, should I leave one for now? [closed]",,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 8 years ago . Improve this question I learn math by reading books. Usually I read 3 books (about 3 different subjects) simultaneously and switch focus every couple of days. The books i'm studying right now are Rudin's functional analysis, Aluffi's algebra, and Jefferey Lee's Manifolds and differential geometry. Recently I find it very hard to switch to Rudin's book. It feels like a totally different realm and whenever I pick it up (again) I spend a lot of time building up my motivation and interest in the topic. Apart from being frustrating, it feels like an inefficient use of my time. Don't get me wrong, I Love functional analysis and think it's beautiful (and Rudin's book fits me quite well). It's just hard for me to routinely switch between these subjects since I'm still in the level where they don't interact that much. Whereas differential geometry and algebra are pretty much fused in my brain to a big blob that can grow in either direction. I'm not asking for examples where functional analysis touches algebra or differential geometry. I am very much aware of a lot of connections. (geometric analysis/operator algebras for example). What i'm asking is what of the 2 should i do: Leave Rudin's book for when you'll have a more concrete motivation to read it and pick up the next book on the list and read on some other topic you're passionate about (algebraic topology, algebraic curves). Something closer to your current mindset (but not too close since you do want to have experience with different types of math). Flow is important! Grind through this phase and continue to switch between the topics. Eventually you'll develop flexibility and it would be easier. You'll gain a lot from this. Flexibility is important! So, what should i do? I realize this is highly opinion based but i think a detailed answer about the pros and cons of learning about different subjects simultaneously will help many self learners like myself.","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 8 years ago . Improve this question I learn math by reading books. Usually I read 3 books (about 3 different subjects) simultaneously and switch focus every couple of days. The books i'm studying right now are Rudin's functional analysis, Aluffi's algebra, and Jefferey Lee's Manifolds and differential geometry. Recently I find it very hard to switch to Rudin's book. It feels like a totally different realm and whenever I pick it up (again) I spend a lot of time building up my motivation and interest in the topic. Apart from being frustrating, it feels like an inefficient use of my time. Don't get me wrong, I Love functional analysis and think it's beautiful (and Rudin's book fits me quite well). It's just hard for me to routinely switch between these subjects since I'm still in the level where they don't interact that much. Whereas differential geometry and algebra are pretty much fused in my brain to a big blob that can grow in either direction. I'm not asking for examples where functional analysis touches algebra or differential geometry. I am very much aware of a lot of connections. (geometric analysis/operator algebras for example). What i'm asking is what of the 2 should i do: Leave Rudin's book for when you'll have a more concrete motivation to read it and pick up the next book on the list and read on some other topic you're passionate about (algebraic topology, algebraic curves). Something closer to your current mindset (but not too close since you do want to have experience with different types of math). Flow is important! Grind through this phase and continue to switch between the topics. Eventually you'll develop flexibility and it would be easier. You'll gain a lot from this. Flexibility is important! So, what should i do? I realize this is highly opinion based but i think a detailed answer about the pros and cons of learning about different subjects simultaneously will help many self learners like myself.",,"['abstract-algebra', 'functional-analysis', 'differential-geometry', 'education', 'learning']"
4,Second differential of the norm in an infinite dimensional Hilbert space,Second differential of the norm in an infinite dimensional Hilbert space,,"Let $f: E \to \mathbb{R}$ sending  $x \mapsto \|x\|$ and make some simple hypothesis $E$ is a Hilbert Space Let's say that the norm $\|\cdot\|$ is derived from a scalar product [solved] So we can easily find the différential: $D\|\cdot\|(x)(h)=\langle x/\|x\|,h\rangle$ with $\nabla{ \|\cdot\|}(x)=x/\|x\| \, (grad)$ as shown below: http://www.les-mathematiques.net/phorum/file.php?4,file=43281 But computing the second order differential seems really complicated. I don't even know how to proceed! What about the 3rd order ? $D^3f(x)$ ?","Let $f: E \to \mathbb{R}$ sending  $x \mapsto \|x\|$ and make some simple hypothesis $E$ is a Hilbert Space Let's say that the norm $\|\cdot\|$ is derived from a scalar product [solved] So we can easily find the différential: $D\|\cdot\|(x)(h)=\langle x/\|x\|,h\rangle$ with $\nabla{ \|\cdot\|}(x)=x/\|x\| \, (grad)$ as shown below: http://www.les-mathematiques.net/phorum/file.php?4,file=43281 But computing the second order differential seems really complicated. I don't even know how to proceed! What about the 3rd order ? $D^3f(x)$ ?",,"['functional-analysis', 'derivatives', 'hilbert-spaces']"
5,Weak convergence and convergence almost everywhere,Weak convergence and convergence almost everywhere,,"If a bounded sequence $(u_n)$ converge weakly to $u$ in $W^{1,p}(\Omega)$ (where $\Omega$ is an open bounded subset of $\mathbb{R}^N$ with $N>p$), is it true that $u_n(x)$ converges to $u(x)$ for almost every $x\in \Omega$? thank you","If a bounded sequence $(u_n)$ converge weakly to $u$ in $W^{1,p}(\Omega)$ (where $\Omega$ is an open bounded subset of $\mathbb{R}^N$ with $N>p$), is it true that $u_n(x)$ converges to $u(x)$ for almost every $x\in \Omega$? thank you",,"['real-analysis', 'functional-analysis', 'sobolev-spaces', 'weak-convergence']"
6,What are some easy to understand applications of Banach Contraction Principle?,What are some easy to understand applications of Banach Contraction Principle?,,I know that Banach contraction principle guarantees a unique solution to problems of the form $$f(x) = x$$ But for the life of me I cannot understand why this problem is important at all. I don't remember encountering such a question in calculus or ODE (at least not the most important problems) Further more all the examples I can find that applies Banach contraction principle some way always involves tough integral equations (plus hardcore optimal control theory) and some proof that guarantees the uniqueness of the solution. To be honest I learned existence and uniqueness for ODE a long time ago and has never once in my life used it ever since. What are some simple to understand or physical applications of Banach contraction principle?,I know that Banach contraction principle guarantees a unique solution to problems of the form $$f(x) = x$$ But for the life of me I cannot understand why this problem is important at all. I don't remember encountering such a question in calculus or ODE (at least not the most important problems) Further more all the examples I can find that applies Banach contraction principle some way always involves tough integral equations (plus hardcore optimal control theory) and some proof that guarantees the uniqueness of the solution. To be honest I learned existence and uniqueness for ODE a long time ago and has never once in my life used it ever since. What are some simple to understand or physical applications of Banach contraction principle?,,"['calculus', 'functional-analysis', 'banach-spaces', 'self-learning', 'examples-counterexamples']"
7,Spectral theorem for compact and self-adjoint operators,Spectral theorem for compact and self-adjoint operators,,"I am looking at the proof of this theorem which states that if $H$ is a separable Hilbert space and $A:H\rightarrow H$ a compact self-adjoint operator, then there exists a sequence of real eigenvalues $(\lambda_n)$ converging to $0$, and an orthonormal basis $\{v_n\}$ of eigenvectors with $Av_n=\lambda_nv_n$ for all $n\geq1$. After he found that $V=\langle e_1,...\rangle$ and that $A\mid_{V^{\perp}}=0$, he uses the separability condition to choose an orthonormal basis for $V^{\perp}$ ""(which might be zero, in which case the theorem is already proved, or might be finite dimensional)"" and conclude saying that listing the orthonormal basis for $V^{\perp}$ with the one constructed of $V$ Proves the theorem. I think that it should be fine till now. The point is that as a remark he states that separability is used for making use of orthonormal basis. How would be the idea for the conclusion without the separability condition?","I am looking at the proof of this theorem which states that if $H$ is a separable Hilbert space and $A:H\rightarrow H$ a compact self-adjoint operator, then there exists a sequence of real eigenvalues $(\lambda_n)$ converging to $0$, and an orthonormal basis $\{v_n\}$ of eigenvectors with $Av_n=\lambda_nv_n$ for all $n\geq1$. After he found that $V=\langle e_1,...\rangle$ and that $A\mid_{V^{\perp}}=0$, he uses the separability condition to choose an orthonormal basis for $V^{\perp}$ ""(which might be zero, in which case the theorem is already proved, or might be finite dimensional)"" and conclude saying that listing the orthonormal basis for $V^{\perp}$ with the one constructed of $V$ Proves the theorem. I think that it should be fine till now. The point is that as a remark he states that separability is used for making use of orthonormal basis. How would be the idea for the conclusion without the separability condition?",,"['functional-analysis', 'hilbert-spaces', 'spectral-theory']"
8,What does it mean to convolve matrices of finite dimension?,What does it mean to convolve matrices of finite dimension?,,"If one is given two matrices $I$ and $K$ what does the notation: $$ I * K $$ mean rigorously/precisely? I do know the definition of convolution: $$ s[i, j] = (I * K)[i, j] = \sum_m \sum_n I[m,n] K[i - m, j - n]$$ However, I have some issues/doubts that I can't resolve between the two. First is that the definition of the convolution is in terms of functions rather than matrices or vectors. So I am having some difficulty understanding what $ I * K $ should mean if I am given two matrices alone. This seems to be common in convolutional neural networks for example and its confusing me. I am trying to come up with an example to make this concrete and not confusing. For example, if I had: $$ I=   \begin{bmatrix}     1 & 2 & 3 & 4 \\     5 & 6 & 7 & 8 \\     9 & 10 & 11 & 12 \\   \end{bmatrix} $$ and I had $$ K=   \begin{bmatrix}     1 & 2  \\     5 & 6     \end{bmatrix} $$ what would a convolution between the two mean? What type of mathematical object should it return? Would it be using the usual equation for convolution as I defined above with $s[i,j]$? Some of the issue I have with this is that the negative sign in the convolution is suppose to reflect around the y-axis, but with finite structures I don't think that makes sense. There is also a translation and the indices are discrete and I am not sure what translating means in this context. Just making cyclic shifts doesn't make sense to me as translation. All of those make sense with functions (and infinite dimensional vectors) to me, but I am not sure it makes sense to me in this context. Actually, after some though, I think one of the things that bother me the most about convolutions with finite vectors (that is NOT an issue with inner products) is this translation thing. The thing is that for example, for finite vectors, translating doesn't make sense to me because they are not indexed on a real line but with inner products, this issue never arises because we only compute products of corresponding elements! Also, if anyone can make explicit what the result would be of $ I * K$ with the specific example I provided, it would be very helpful. I suspect that the result would a matrix, but if one can show what the matrix is (and possible a few of its entries explicitly computed, it would be tremendously useful). For reference, here is where I saw this type of operations/notation being used: http://people.idsia.ch/~masci/papers/2011_icann.pdf and the section that uses this type of notation:","If one is given two matrices $I$ and $K$ what does the notation: $$ I * K $$ mean rigorously/precisely? I do know the definition of convolution: $$ s[i, j] = (I * K)[i, j] = \sum_m \sum_n I[m,n] K[i - m, j - n]$$ However, I have some issues/doubts that I can't resolve between the two. First is that the definition of the convolution is in terms of functions rather than matrices or vectors. So I am having some difficulty understanding what $ I * K $ should mean if I am given two matrices alone. This seems to be common in convolutional neural networks for example and its confusing me. I am trying to come up with an example to make this concrete and not confusing. For example, if I had: $$ I=   \begin{bmatrix}     1 & 2 & 3 & 4 \\     5 & 6 & 7 & 8 \\     9 & 10 & 11 & 12 \\   \end{bmatrix} $$ and I had $$ K=   \begin{bmatrix}     1 & 2  \\     5 & 6     \end{bmatrix} $$ what would a convolution between the two mean? What type of mathematical object should it return? Would it be using the usual equation for convolution as I defined above with $s[i,j]$? Some of the issue I have with this is that the negative sign in the convolution is suppose to reflect around the y-axis, but with finite structures I don't think that makes sense. There is also a translation and the indices are discrete and I am not sure what translating means in this context. Just making cyclic shifts doesn't make sense to me as translation. All of those make sense with functions (and infinite dimensional vectors) to me, but I am not sure it makes sense to me in this context. Actually, after some though, I think one of the things that bother me the most about convolutions with finite vectors (that is NOT an issue with inner products) is this translation thing. The thing is that for example, for finite vectors, translating doesn't make sense to me because they are not indexed on a real line but with inner products, this issue never arises because we only compute products of corresponding elements! Also, if anyone can make explicit what the result would be of $ I * K$ with the specific example I provided, it would be very helpful. I suspect that the result would a matrix, but if one can show what the matrix is (and possible a few of its entries explicitly computed, it would be tremendously useful). For reference, here is where I saw this type of operations/notation being used: http://people.idsia.ch/~masci/papers/2011_icann.pdf and the section that uses this type of notation:",,"['functional-analysis', 'functions', 'convolution', 'machine-learning']"
9,"Definition in Lax ""sequence of continuous functions tending to $\delta$"", are distributions needed for understanding?","Definition in Lax ""sequence of continuous functions tending to "", are distributions needed for understanding?",\delta,"I'm trying to read Lax's functional analysis. In chapter 11 he makes a definition which I don't like. A sequence of continuous functions ${k_n}$ on a $[-1,1]$ tends to $\delta$ if $\int_{-1}^{1} f(x)k_n(x)dx=f(0)$ for all $f \in C[-1,1]$ Within a proof where he establishes iff correspondence between this definition being valid for some ${k_n}$ and something similar to ${k_n}$ begin good kernels he refers to weak* convergence within the dual of $C[-1,1]$ which he declared to be the space of finite signed measures a few pages earlier. He says that the above statement with the integral is equal to $ $w*$ - \lim k_n= \delta$ I don't see how this is trivial. In what way or in which framework is the ""definition"" and its relation to weak* convergence clearer? Do I have to go all the way into distributions?","I'm trying to read Lax's functional analysis. In chapter 11 he makes a definition which I don't like. A sequence of continuous functions ${k_n}$ on a $[-1,1]$ tends to $\delta$ if $\int_{-1}^{1} f(x)k_n(x)dx=f(0)$ for all $f \in C[-1,1]$ Within a proof where he establishes iff correspondence between this definition being valid for some ${k_n}$ and something similar to ${k_n}$ begin good kernels he refers to weak* convergence within the dual of $C[-1,1]$ which he declared to be the space of finite signed measures a few pages earlier. He says that the above statement with the integral is equal to $ $w*$ - \lim k_n= \delta$ I don't see how this is trivial. In what way or in which framework is the ""definition"" and its relation to weak* convergence clearer? Do I have to go all the way into distributions?",,"['functional-analysis', 'distribution-theory']"
10,how to define that a nonlinear operator is bounded and continuous,how to define that a nonlinear operator is bounded and continuous,,We always see the definition of bounded and continuous linear operator. I am wondering how to define that a nonlinear operator is bounded and continuous. Is there any book providing this definition?,We always see the definition of bounded and continuous linear operator. I am wondering how to define that a nonlinear operator is bounded and continuous. Is there any book providing this definition?,,"['real-analysis', 'functional-analysis', 'operator-theory']"
11,"Operator on $L^2 (0,1)$ defined by convolution with $|x-y|^{-\alpha}$",Operator on  defined by convolution with,"L^2 (0,1) |x-y|^{-\alpha}","Define $A: L^2 (0,1) \to L^2(0,1)$ $$Af(x) = \int_0^1 f(y) \frac{1}{|x-y|^\alpha} dy \quad , \quad \alpha \in (0,1)$$ For what values of $\alpha$ is it well defined? Bounded? Compact? I tried doing the appropriate integrals but I really don't understand what am I supposed to do in this specific case.","Define $A: L^2 (0,1) \to L^2(0,1)$ $$Af(x) = \int_0^1 f(y) \frac{1}{|x-y|^\alpha} dy \quad , \quad \alpha \in (0,1)$$ For what values of $\alpha$ is it well defined? Bounded? Compact? I tried doing the appropriate integrals but I really don't understand what am I supposed to do in this specific case.",,"['functional-analysis', 'hilbert-spaces', 'lp-spaces', 'integral-operators']"
12,Triangle Inequality for norm integral $\|f\|_1=(\int_a^b [|f|^2+|f'|^2]\mathsf dx)^{1/2}$.,Triangle Inequality for norm integral .,\|f\|_1=(\int_a^b [|f|^2+|f'|^2]\mathsf dx)^{1/2},"Define $C_1^1[a,b]$ to be the space of continuously differentiable functions on $[a,b]$, with norm $$\|f\|_1=\left(\int_a^b[|f|^2+|f'|^2]\mathsf dx\right)^{1/2}.$$ Show that this is a proper definition of a norm. Is this normed space complete? I'm stuck on the triangle inequality part. I'm having a hard time showing that $$\|f+g\|_1\leq \|f\|_1+\|g\|_1.$$ Any hints or solutions are greatly appreciated.","Define $C_1^1[a,b]$ to be the space of continuously differentiable functions on $[a,b]$, with norm $$\|f\|_1=\left(\int_a^b[|f|^2+|f'|^2]\mathsf dx\right)^{1/2}.$$ Show that this is a proper definition of a norm. Is this normed space complete? I'm stuck on the triangle inequality part. I'm having a hard time showing that $$\|f+g\|_1\leq \|f\|_1+\|g\|_1.$$ Any hints or solutions are greatly appreciated.",,"['real-analysis', 'linear-algebra', 'functional-analysis', 'normed-spaces']"
13,Matrix-like Representation of any linear map using Hamel Basis,Matrix-like Representation of any linear map using Hamel Basis,,"Let $X$ and $Y$ be two arbitrary linear spaces over a field $\mathbb{K}$. Let $B=\{x_\alpha:\alpha \in S\}$ and $C=\{y_\beta:\beta \in T\}$ be Hamel basis for $X$ and $Y$ respectively. Denote the space of all the linear maps from $X$ into $Y$ by  $L(X,Y)$. For any set $Z$, consider $$C_{00}(Z)=\{(d_\gamma)_{\gamma\in Z}\in\mathbb{K}^Z:d_\gamma\neq0 \mbox{ only for a finite number of indexes }\gamma\}.$$ Let $F\in L(X,Y)$ and $x\in X$. Then there exist a unique $a=(a_\alpha)\in C_{00}(S)$ such that $x=\sum_\alpha a_\alpha x_\alpha$.  Also, for each $\alpha\in S$, there is a unique $M_\alpha=(b_{\beta,\alpha})_\beta\in C_{00}(T)$ such that $F(x_\alpha)=\sum_\beta b_{\beta,\alpha}y_\beta$.  Thus  $$F(x)=\sum_\alpha a_\alpha F(x_\alpha)=\sum_\alpha a_\alpha\bigg(\sum_\beta b_{\beta,\alpha}y_\beta\bigg)=\sum_\beta \bigg(\sum_\alpha b_{\beta,\alpha}a_\alpha\bigg)y_\beta$$ Consider the ""matrix-like array $M$ of size $|T|\times|S|$"" which columns are the $|T|$-tuples $M_\alpha$. Thus $M\in(C_{00}(T))^S$.  Now, for each $\beta\in T$, let $N_\beta$ be the ""$\beta$-row of $M$"", i.e. $N_\beta=(b_{\beta,\alpha})_{\alpha\in S}$. If we denote $\sum_\alpha b_{\beta,\alpha}a_\alpha$ by $\langle N_\beta,a\rangle$ for each $\beta \in T$, then $$F(x)=\sum_\beta\langle N_\beta,a\rangle y_\beta.$$ Questions: I think the ""matrix-like array $M$"" is uniquely determined by the linear map $F$ and conversely. In other words $L(X,Y)\cong(C_{00}(T))^S.$ Am I right? Is this representation for linear maps of any use? In spaces like $\ell^p$, we don't have any explicit Hamel basis, so (I guess) this approach doesn't allow us to get information about the continuity of any operator from its respective array. Am I wrong?","Let $X$ and $Y$ be two arbitrary linear spaces over a field $\mathbb{K}$. Let $B=\{x_\alpha:\alpha \in S\}$ and $C=\{y_\beta:\beta \in T\}$ be Hamel basis for $X$ and $Y$ respectively. Denote the space of all the linear maps from $X$ into $Y$ by  $L(X,Y)$. For any set $Z$, consider $$C_{00}(Z)=\{(d_\gamma)_{\gamma\in Z}\in\mathbb{K}^Z:d_\gamma\neq0 \mbox{ only for a finite number of indexes }\gamma\}.$$ Let $F\in L(X,Y)$ and $x\in X$. Then there exist a unique $a=(a_\alpha)\in C_{00}(S)$ such that $x=\sum_\alpha a_\alpha x_\alpha$.  Also, for each $\alpha\in S$, there is a unique $M_\alpha=(b_{\beta,\alpha})_\beta\in C_{00}(T)$ such that $F(x_\alpha)=\sum_\beta b_{\beta,\alpha}y_\beta$.  Thus  $$F(x)=\sum_\alpha a_\alpha F(x_\alpha)=\sum_\alpha a_\alpha\bigg(\sum_\beta b_{\beta,\alpha}y_\beta\bigg)=\sum_\beta \bigg(\sum_\alpha b_{\beta,\alpha}a_\alpha\bigg)y_\beta$$ Consider the ""matrix-like array $M$ of size $|T|\times|S|$"" which columns are the $|T|$-tuples $M_\alpha$. Thus $M\in(C_{00}(T))^S$.  Now, for each $\beta\in T$, let $N_\beta$ be the ""$\beta$-row of $M$"", i.e. $N_\beta=(b_{\beta,\alpha})_{\alpha\in S}$. If we denote $\sum_\alpha b_{\beta,\alpha}a_\alpha$ by $\langle N_\beta,a\rangle$ for each $\beta \in T$, then $$F(x)=\sum_\beta\langle N_\beta,a\rangle y_\beta.$$ Questions: I think the ""matrix-like array $M$"" is uniquely determined by the linear map $F$ and conversely. In other words $L(X,Y)\cong(C_{00}(T))^S.$ Am I right? Is this representation for linear maps of any use? In spaces like $\ell^p$, we don't have any explicit Hamel basis, so (I guess) this approach doesn't allow us to get information about the continuity of any operator from its respective array. Am I wrong?",,"['linear-algebra', 'abstract-algebra', 'functional-analysis', 'representation-theory', 'linear-transformations']"
14,Every nontrivial linear functional is open [duplicate],Every nontrivial linear functional is open [duplicate],,"This question already has answers here : Nonconstant linear functional on a topological vector space is an open mapping (4 answers) Closed 3 years ago . Let $X$ be a normed linear space and let $f:X\to \mathbb K$ be a nontrivial linear functional. I want to prove that $f$ is open. I tried as follows: Let $E$ be an open set in $X$ and let $y\in f(E)$. Then there is $x\in E$ such that $y=f(x)$. Since $E$ is open there exists $r>0$ such that $B_r(x)\subset E$. Let $z\in B_1(0)$ such that $f(z)=\delta>0$. If I can show that $(-\delta,\delta)\subset f(B_1(0))$, then I am through. But I could not show this. Please help me  to resolve this.","This question already has answers here : Nonconstant linear functional on a topological vector space is an open mapping (4 answers) Closed 3 years ago . Let $X$ be a normed linear space and let $f:X\to \mathbb K$ be a nontrivial linear functional. I want to prove that $f$ is open. I tried as follows: Let $E$ be an open set in $X$ and let $y\in f(E)$. Then there is $x\in E$ such that $y=f(x)$. Since $E$ is open there exists $r>0$ such that $B_r(x)\subset E$. Let $z\in B_1(0)$ such that $f(z)=\delta>0$. If I can show that $(-\delta,\delta)\subset f(B_1(0))$, then I am through. But I could not show this. Please help me  to resolve this.",,"['general-topology', 'functional-analysis', 'linear-transformations']"
15,Bounded linear map on topological vector spaces is continuous,Bounded linear map on topological vector spaces is continuous,,"Let $X$ and $Y$ be topological vector spaces and $T\colon X\to Y$ linear. Suppose that $T$ sends bounded sets to bounded sets and that $X$ is first countable. The claim is that $T$ is continuous. Here's what I've tried so far. Since $X$ is first countable, we need only show that $T$ is sequentially continuous and since $T$ is linear it suffices to show $T$ is continuous at $0$. Let $(x_n)$ be a sequence in $X$ with $x_n\to 0$. We want $Tx_n\to 0$ as well. $(x_n)$ is convergent, so $\{x_n:n\in\mathbf{N}\}$ is bounded in $X$. Hence $\{Tx_n:n\in\mathbf{N}\}$ is bounded in $Y$. Let $W$ be a neighborhood of $0$ in $Y$. Then there is $s>0$ with $\{Tx_n:n\in\mathbf{N}\}\subset sW$. So, $\{x_n:n\in\mathbf{N}\}\subset sT^{-1}(W)$. But I'm not sure how to/if I can continue successfully from here. Any thoughts?","Let $X$ and $Y$ be topological vector spaces and $T\colon X\to Y$ linear. Suppose that $T$ sends bounded sets to bounded sets and that $X$ is first countable. The claim is that $T$ is continuous. Here's what I've tried so far. Since $X$ is first countable, we need only show that $T$ is sequentially continuous and since $T$ is linear it suffices to show $T$ is continuous at $0$. Let $(x_n)$ be a sequence in $X$ with $x_n\to 0$. We want $Tx_n\to 0$ as well. $(x_n)$ is convergent, so $\{x_n:n\in\mathbf{N}\}$ is bounded in $X$. Hence $\{Tx_n:n\in\mathbf{N}\}$ is bounded in $Y$. Let $W$ be a neighborhood of $0$ in $Y$. Then there is $s>0$ with $\{Tx_n:n\in\mathbf{N}\}\subset sW$. So, $\{x_n:n\in\mathbf{N}\}\subset sT^{-1}(W)$. But I'm not sure how to/if I can continue successfully from here. Any thoughts?",,"['functional-analysis', 'topological-vector-spaces']"
16,show $\ell^p$ is dense in $\ell^q$,show  is dense in,\ell^p \ell^q,"I am trying to show $\ell^p$ is dense in $\ell^q$,  where p< q so  i need to  show  that any $\epsilon > 0$  for any $(x_i)\in\ell^q$ there is $(y_i) \in \ell^p$  such that $d((x_i),(y_i)) < \epsilon$.  Let be $(x_i) \in l^q$ and  $\epsilon$ be orbitrary. We know $\sum_{i=1}^\infty |x_i|^q <\infty$   this means $\exists$ n such that $\sum_{i=n+1}^\infty |x_i|^q < {(\epsilon)^p \over 2^p}$ . Consider $y=(y_1,y_2, . . .,y_n,0,0,. . .)$ and let  $(y_i) \in \ell^p$ and each $y_i$ is rational. Since the rationals are dense in $\Bbb{R}$ , for each $x_i$ there is rational $y_i$ close to it. Hence we can find a $y \in \ell^p$ satisfying $\sum_{i=1}^\infty |x_i-y_i|^q< {\epsilon^p\over 2^p}$. It follows that $d(x,y)=(\sum_{i=1}^\infty |x_i-y_i|^q)^{1\over p} < (\sum_{i=1}^n |x_i-y_i|^q + \sum_{i=n+1}^\infty |x_i|^q)^{1\over p} < \epsilon$ Is it true? If it is not true, can you show me the way to do it please? Thank you for your help.","I am trying to show $\ell^p$ is dense in $\ell^q$,  where p< q so  i need to  show  that any $\epsilon > 0$  for any $(x_i)\in\ell^q$ there is $(y_i) \in \ell^p$  such that $d((x_i),(y_i)) < \epsilon$.  Let be $(x_i) \in l^q$ and  $\epsilon$ be orbitrary. We know $\sum_{i=1}^\infty |x_i|^q <\infty$   this means $\exists$ n such that $\sum_{i=n+1}^\infty |x_i|^q < {(\epsilon)^p \over 2^p}$ . Consider $y=(y_1,y_2, . . .,y_n,0,0,. . .)$ and let  $(y_i) \in \ell^p$ and each $y_i$ is rational. Since the rationals are dense in $\Bbb{R}$ , for each $x_i$ there is rational $y_i$ close to it. Hence we can find a $y \in \ell^p$ satisfying $\sum_{i=1}^\infty |x_i-y_i|^q< {\epsilon^p\over 2^p}$. It follows that $d(x,y)=(\sum_{i=1}^\infty |x_i-y_i|^q)^{1\over p} < (\sum_{i=1}^n |x_i-y_i|^q + \sum_{i=n+1}^\infty |x_i|^q)^{1\over p} < \epsilon$ Is it true? If it is not true, can you show me the way to do it please? Thank you for your help.",,"['real-analysis', 'functional-analysis', 'lp-spaces']"
17,$T$ linear operator s.t. $\lim\limits_{n\to\infty}x_n{=}0_X$ $\Longrightarrow$ $\lim\limits_{n\to\infty}T(x_n){=}0_Y$ then $T$ is bounded,linear operator s.t.    then  is bounded,T \lim\limits_{n\to\infty}x_n{=}0_X \Longrightarrow \lim\limits_{n\to\infty}T(x_n){=}0_Y T,"Let $X$ and $Y$ be two normed spaces, with $X$ a reflexive space. I suppone that $T:X\rightarrow Y$ is an operator such that: $\lim\limits_{n\to\infty}x_n{=}0_X$ $\Longrightarrow$ $\lim\limits_{n\to\infty}T(x_n){=}0_Y$. I have to prove that $T$ is bounded. Here is my attempt: If $X$ is reflexive, I know that every bounded sequences in $X$ have a subsequence $\{ x_{n_k} \}$ such that $T(\{ x_{n_k} \})$ converges in $Y$. For the sake of contradiction I assume that $T$ is not bounded so there exists a vector $y_n$ such that $\| y_n\| \leq 1$ but $ \| T y_n\| > n^3$. Now let $x_n=\frac{1}{n} y_n$. I have proved in this way that exists a sequence $ (x_{n})_{n \in \mathbb{N}} $ in $ X $ that converges in norm to $ 0_{X} $ (therefore $(x_n)$ is bounded)  but for which $ \| T(x_{n}) \|_{Y} \geq n^{2} $ for all $ n \in \mathbb{N} $. So I have a contraddiction Is my solution correct? Moreover I was wondering if it necessary here the hypothesis that $X$ is a reflexive space. Is there a way to prove this proposition without it? Any help  will be greatly appreciated.","Let $X$ and $Y$ be two normed spaces, with $X$ a reflexive space. I suppone that $T:X\rightarrow Y$ is an operator such that: $\lim\limits_{n\to\infty}x_n{=}0_X$ $\Longrightarrow$ $\lim\limits_{n\to\infty}T(x_n){=}0_Y$. I have to prove that $T$ is bounded. Here is my attempt: If $X$ is reflexive, I know that every bounded sequences in $X$ have a subsequence $\{ x_{n_k} \}$ such that $T(\{ x_{n_k} \})$ converges in $Y$. For the sake of contradiction I assume that $T$ is not bounded so there exists a vector $y_n$ such that $\| y_n\| \leq 1$ but $ \| T y_n\| > n^3$. Now let $x_n=\frac{1}{n} y_n$. I have proved in this way that exists a sequence $ (x_{n})_{n \in \mathbb{N}} $ in $ X $ that converges in norm to $ 0_{X} $ (therefore $(x_n)$ is bounded)  but for which $ \| T(x_{n}) \|_{Y} \geq n^{2} $ for all $ n \in \mathbb{N} $. So I have a contraddiction Is my solution correct? Moreover I was wondering if it necessary here the hypothesis that $X$ is a reflexive space. Is there a way to prove this proposition without it? Any help  will be greatly appreciated.",,"['functional-analysis', 'normed-spaces', 'solution-verification']"
18,Functions in $L^p$ spaces,Functions in  spaces,L^p,"If I have a function $f:\mathbb{R} \rightarrow \mathbb{R}$ that belongs to $L^p(\mathbb{R})$ for all $p\geq 2$ including $p=\infty$, that is $$f \in \bigcap_{p\in [2,\infty]} L^p(\mathbb{R})$$ and all the norms have the same bound, let us say that for all $p\geq 2$ $$\|f\|_p \leq C$$ and $$\|f\|_\infty \leq C$$ Can we conclude that $f$ is also in $L^p(\mathbb{R})$ for $1< p <2$ and that  $$\|f\|_p \leq C?$$","If I have a function $f:\mathbb{R} \rightarrow \mathbb{R}$ that belongs to $L^p(\mathbb{R})$ for all $p\geq 2$ including $p=\infty$, that is $$f \in \bigcap_{p\in [2,\infty]} L^p(\mathbb{R})$$ and all the norms have the same bound, let us say that for all $p\geq 2$ $$\|f\|_p \leq C$$ and $$\|f\|_\infty \leq C$$ Can we conclude that $f$ is also in $L^p(\mathbb{R})$ for $1< p <2$ and that  $$\|f\|_p \leq C?$$",,"['calculus', 'real-analysis', 'integration', 'functional-analysis', 'inequality']"
19,$\|f\|_{L^{3}(\mathbb R)}^{3} \leq C \|f\|_{L^{2}(\mathbb R)} \|\nabla f\|_{L^{2}(\mathbb R)}^{3}$ ; for some constant $C$?,; for some constant ?,\|f\|_{L^{3}(\mathbb R)}^{3} \leq C \|f\|_{L^{2}(\mathbb R)} \|\nabla f\|_{L^{2}(\mathbb R)}^{3} C,"Let $f\in H^{1}(\mathbb R)$ ( Sobolev space ). My Question : Is it true that:    $\|f\|_{L^{3}(\mathbb R)}^{3} \leq C \|f\|_{L^{2}(\mathbb R)} \|\nabla f\|_{L^{2}(\mathbb R)}^{3}$ ; for some constant $C$?   [If it is true, then I guess some where I have to use Sobolev inequality  but I don't know all kinds of Sobolev inequality] Thanks,","Let $f\in H^{1}(\mathbb R)$ ( Sobolev space ). My Question : Is it true that:    $\|f\|_{L^{3}(\mathbb R)}^{3} \leq C \|f\|_{L^{2}(\mathbb R)} \|\nabla f\|_{L^{2}(\mathbb R)}^{3}$ ; for some constant $C$?   [If it is true, then I guess some where I have to use Sobolev inequality  but I don't know all kinds of Sobolev inequality] Thanks,",,"['real-analysis', 'analysis', 'functional-analysis', 'sobolev-spaces', 'lp-spaces']"
20,Riesz representation theorem in Sobolev spaces,Riesz representation theorem in Sobolev spaces,,"My question is about functionals on $W_{1,p}(\Omega)$ spaces, $\Omega$ is contained in $\mathbb R^n$ I am trying to figure out if there is a way to characterize all linear functionals on the above space. Is there any version of Riesz representation theorem in general Banach space?","My question is about functionals on $W_{1,p}(\Omega)$ spaces, $\Omega$ is contained in $\mathbb R^n$ I am trying to figure out if there is a way to characterize all linear functionals on the above space. Is there any version of Riesz representation theorem in general Banach space?",,"['functional-analysis', 'sobolev-spaces', 'riesz-representation-theorem']"
21,Is the injectivity of the operator equivalent to the surjectivity of its adjoint,Is the injectivity of the operator equivalent to the surjectivity of its adjoint,,"Let $X$ and $Y$ be two normed linear spaces. Let $T:X \to Y^*$ be a linear operator (not necessarily continuous) and let $T^*$ be its adjoint, i.e. $T^*:Y \to X^*$ is defined by $ \langle T^*y,x \rangle := \langle Tx,y \rangle ,$ where $\langle \cdot , \cdot \rangle$ is a proper duality pairing (i.e. between $X^*$ and $X$ on the left hand side and between $Y^*$ and $Y$ on the right hand side). Let $R(T)$ denote the range of $T$. Is it true that: $T$ is injective on $R(T)$ if and only if $T^*$ is surjective onto $X^*$?","Let $X$ and $Y$ be two normed linear spaces. Let $T:X \to Y^*$ be a linear operator (not necessarily continuous) and let $T^*$ be its adjoint, i.e. $T^*:Y \to X^*$ is defined by $ \langle T^*y,x \rangle := \langle Tx,y \rangle ,$ where $\langle \cdot , \cdot \rangle$ is a proper duality pairing (i.e. between $X^*$ and $X$ on the left hand side and between $Y^*$ and $Y$ on the right hand side). Let $R(T)$ denote the range of $T$. Is it true that: $T$ is injective on $R(T)$ if and only if $T^*$ is surjective onto $X^*$?",,"['functional-analysis', 'operator-theory']"
22,Is the unit ball in this sequence space compact?,Is the unit ball in this sequence space compact?,,"I have a set $X=\{\text{complex sequences } \{x_n\}: \sup\limits_{n}\sqrt{n}\left|x_n\right|\leq 1\}$ equipped with a metric $d(\{x_n\},\{y_n\})=\sup\limits_{n}|x_n-y_n|+\sup\limits_{n}\sqrt{n}|x_n-y_n|$. I want to show that the closed unit ball centered around $\{0\}$ is either compact or not compact, i.e. $N_1=\{\{x_n\}\in X: d(\{x_n\}, \{0\})\leq 1\}$. Closed unit balls are typically not compact (the only case of this is when $X$ is finite dimensional). I'd like to find a sequence in $N_1$, that is a sequence of sequences, that does not have a convergent subsequence. Alternatively, I can show that it isn't complete or totally bounded. The abundance of possibilities, as well as my unfamiliarity with sequence spaces, is confounding me. Can anyone help?","I have a set $X=\{\text{complex sequences } \{x_n\}: \sup\limits_{n}\sqrt{n}\left|x_n\right|\leq 1\}$ equipped with a metric $d(\{x_n\},\{y_n\})=\sup\limits_{n}|x_n-y_n|+\sup\limits_{n}\sqrt{n}|x_n-y_n|$. I want to show that the closed unit ball centered around $\{0\}$ is either compact or not compact, i.e. $N_1=\{\{x_n\}\in X: d(\{x_n\}, \{0\})\leq 1\}$. Closed unit balls are typically not compact (the only case of this is when $X$ is finite dimensional). I'd like to find a sequence in $N_1$, that is a sequence of sequences, that does not have a convergent subsequence. Alternatively, I can show that it isn't complete or totally bounded. The abundance of possibilities, as well as my unfamiliarity with sequence spaces, is confounding me. Can anyone help?",,"['real-analysis', 'sequences-and-series', 'functional-analysis', 'compactness']"
23,Verifying a Vector Space Via Given Axioms,Verifying a Vector Space Via Given Axioms,,"Let $X$ be the collection of all sequences $\{\alpha_n\}_{n=1}^{\infty}$ of scalars from $\mathbb{K}$ such that $\alpha_n=0$ for all but a finite number of values of $n$. Define addition and scalar multiplication on $X$ by $\{\alpha_n\} + \{\beta_n\} = \{\alpha_n + \beta_n \}$ and $\lambda \{\alpha_n\} = \{\lambda \alpha_n\}$. Verify that $X$ is a vector space over $\mathbb{K}$. According to my textbook which is being used for this problem, I need to verify the property of closure under addition and scalar multiplication as well as the following 8 axioms: 1). $x+(y+z)=(x+y)+z$ $\{\alpha_n\} + (\{\beta_n + \gamma_n\}) = \{\alpha_n + \beta_n + \gamma_n\}$ and similarly, $\{(\alpha_n + \beta_n)\} + \{\gamma_n\} = \{\alpha_n + \beta_n + \gamma_n\}$ by definition of addition on $X$. 2).$x+y=y+x$ $\{\alpha_n\} + \{\beta_n\} = \{\beta_n\} + \{\alpha_n\}$. Since $\{\alpha_n\} = 0$ for all but finitely many values of $n$, then $\{\alpha_n\} + \{\beta_n\} = 0+0 = \{\beta_n\} + \{\alpha_n\} = 0+0$. 3). $x+0 = x$. $\{\alpha_n\} + 0 = \{\alpha_n\}$. By the definition of addition on $X, \{\alpha_n\} + 0 = \{\alpha_n + 0\} = \{\alpha_n\}$. 4). $x+ (-1)x= 0$. $\{\alpha_n\} + (-1)\{\alpha_n\}=0$. Let $\lambda = -1$ and we use the definition of scalar multiplication:  $\{\alpha_n\}+ \lambda \{\alpha_n\} = \{\alpha_n\} + \{\lambda \alpha_n\}$. Using the definition of addition on $X$, we get $\{\alpha_n+ \lambda \alpha_n\} = \{\alpha_n - \alpha_n\}=0$. 5). $(\lambda + \mu)\{\alpha_n\} = \lambda \{\alpha_n\} + \mu \{\alpha_n\}$. Using the definition of scalar multiplication on $X$, we can write $(\lambda+\mu)\{\alpha_n\} = \{(\lambda + \mu)\alpha_n\} = \{\lambda \alpha_n + \mu \alpha_n\}$. Using addition on $X$, we can have $\{\lambda \alpha_n + \mu \alpha_n\} = \{\lambda \alpha_n\} + \{\mu \alpha_n\}$. Again using scalar multiplication, we have $\lambda \{\alpha_n\} + \mu \{\alpha_n\}$. 6). $\lambda \{\alpha_n + \beta_n\} = \lambda \{\alpha_n\}+ \lambda\{\beta_n\}$. By scalar multiplication on $X$,  $\lambda \{\alpha_n + \beta_n\} = \{\lambda(\alpha_n + \beta_n)\}$. Using addition, $\lambda\{\alpha_n+\beta_n\} = \lambda[\{\alpha_n\}+\{\beta_n\}]$. By scalar multiplication, $\lambda[\{\alpha_n\}+\{\beta_n\}] = \{\lambda \alpha_n\} + \{\lambda \beta_n\}$. Again by scalar multiplication, $\lambda\{ \alpha_n\} +\lambda \{ \beta_n\}$. 7). $(\lambda \mu)\{\alpha_n\} = \lambda (\mu \{\alpha_n\})$. By scalar multiplication, $(\lambda \mu)\{\alpha_n\} = \{(\lambda \mu)\alpha_n\}$. Writing $(\lambda \mu) = (\lambda)(\mu)$, we have $(\lambda)(\mu)\{\alpha_n\}$. By scalar multiplication, $(\lambda)(\mu)\{\alpha_n\} = \lambda\{\mu \alpha_n\}$. 8). $1 \cdot \{\alpha_n\} = \{\alpha_n\}$. Let $\lambda=1$. By scalar multiplication, $\lambda \{\alpha_n\} = \{\lambda \alpha_n\} = \{1 \cdot \alpha_n\} = \{\alpha_n\}$. I have not shown the property of closure under addition and scalar multiplication since I am unsure about how to do that with my given information. Any help/advice/suggestions will be greatly appreciated. Thanks in advance. The textbook I am using is Functional Analysis An Elementary Introduction by Markus Haase.","Let $X$ be the collection of all sequences $\{\alpha_n\}_{n=1}^{\infty}$ of scalars from $\mathbb{K}$ such that $\alpha_n=0$ for all but a finite number of values of $n$. Define addition and scalar multiplication on $X$ by $\{\alpha_n\} + \{\beta_n\} = \{\alpha_n + \beta_n \}$ and $\lambda \{\alpha_n\} = \{\lambda \alpha_n\}$. Verify that $X$ is a vector space over $\mathbb{K}$. According to my textbook which is being used for this problem, I need to verify the property of closure under addition and scalar multiplication as well as the following 8 axioms: 1). $x+(y+z)=(x+y)+z$ $\{\alpha_n\} + (\{\beta_n + \gamma_n\}) = \{\alpha_n + \beta_n + \gamma_n\}$ and similarly, $\{(\alpha_n + \beta_n)\} + \{\gamma_n\} = \{\alpha_n + \beta_n + \gamma_n\}$ by definition of addition on $X$. 2).$x+y=y+x$ $\{\alpha_n\} + \{\beta_n\} = \{\beta_n\} + \{\alpha_n\}$. Since $\{\alpha_n\} = 0$ for all but finitely many values of $n$, then $\{\alpha_n\} + \{\beta_n\} = 0+0 = \{\beta_n\} + \{\alpha_n\} = 0+0$. 3). $x+0 = x$. $\{\alpha_n\} + 0 = \{\alpha_n\}$. By the definition of addition on $X, \{\alpha_n\} + 0 = \{\alpha_n + 0\} = \{\alpha_n\}$. 4). $x+ (-1)x= 0$. $\{\alpha_n\} + (-1)\{\alpha_n\}=0$. Let $\lambda = -1$ and we use the definition of scalar multiplication:  $\{\alpha_n\}+ \lambda \{\alpha_n\} = \{\alpha_n\} + \{\lambda \alpha_n\}$. Using the definition of addition on $X$, we get $\{\alpha_n+ \lambda \alpha_n\} = \{\alpha_n - \alpha_n\}=0$. 5). $(\lambda + \mu)\{\alpha_n\} = \lambda \{\alpha_n\} + \mu \{\alpha_n\}$. Using the definition of scalar multiplication on $X$, we can write $(\lambda+\mu)\{\alpha_n\} = \{(\lambda + \mu)\alpha_n\} = \{\lambda \alpha_n + \mu \alpha_n\}$. Using addition on $X$, we can have $\{\lambda \alpha_n + \mu \alpha_n\} = \{\lambda \alpha_n\} + \{\mu \alpha_n\}$. Again using scalar multiplication, we have $\lambda \{\alpha_n\} + \mu \{\alpha_n\}$. 6). $\lambda \{\alpha_n + \beta_n\} = \lambda \{\alpha_n\}+ \lambda\{\beta_n\}$. By scalar multiplication on $X$,  $\lambda \{\alpha_n + \beta_n\} = \{\lambda(\alpha_n + \beta_n)\}$. Using addition, $\lambda\{\alpha_n+\beta_n\} = \lambda[\{\alpha_n\}+\{\beta_n\}]$. By scalar multiplication, $\lambda[\{\alpha_n\}+\{\beta_n\}] = \{\lambda \alpha_n\} + \{\lambda \beta_n\}$. Again by scalar multiplication, $\lambda\{ \alpha_n\} +\lambda \{ \beta_n\}$. 7). $(\lambda \mu)\{\alpha_n\} = \lambda (\mu \{\alpha_n\})$. By scalar multiplication, $(\lambda \mu)\{\alpha_n\} = \{(\lambda \mu)\alpha_n\}$. Writing $(\lambda \mu) = (\lambda)(\mu)$, we have $(\lambda)(\mu)\{\alpha_n\}$. By scalar multiplication, $(\lambda)(\mu)\{\alpha_n\} = \lambda\{\mu \alpha_n\}$. 8). $1 \cdot \{\alpha_n\} = \{\alpha_n\}$. Let $\lambda=1$. By scalar multiplication, $\lambda \{\alpha_n\} = \{\lambda \alpha_n\} = \{1 \cdot \alpha_n\} = \{\alpha_n\}$. I have not shown the property of closure under addition and scalar multiplication since I am unsure about how to do that with my given information. Any help/advice/suggestions will be greatly appreciated. Thanks in advance. The textbook I am using is Functional Analysis An Elementary Introduction by Markus Haase.",,"['functional-analysis', 'vector-spaces', 'proof-verification', 'proof-writing']"
24,Defining a distribution,Defining a distribution,,"We fix the space $\mathcal{D}=\mathcal{C}^\infty_0(\mathbb{R}^n)$ as space of testfunctions. Let $(f_n)$ be a sequence of distributions with $\lim_{n\to\infty} f_n(\varphi)$ existing for all $\varphi\in\mathcal{D}$. Define $f(\varphi):=\lim_{n\to\infty} f_n(\varphi)$. Then the claim is that $f$ is also a distribution. My question: For proving that this holds, how to see that $f$ is continuous w.r.t convergence in $\mathcal{D}$? (We define a sequence $(\varphi_n)$ in $\mathcal{D}$ to converge to some $\varphi\in\mathcal{D}$ iff there is some compact set $K\subset\mathbb{R}^n$, s.t. $\mathrm{supp}(\varphi_n)\subset K$ for each $n\in\mathbb{N}$ and $\|D^k\varphi_n-D^k\varphi\|_\mathrm{sup}\to 0$ as $n\to\infty$ for each $k\in\mathbb{N}_0^n$.) Thanks!","We fix the space $\mathcal{D}=\mathcal{C}^\infty_0(\mathbb{R}^n)$ as space of testfunctions. Let $(f_n)$ be a sequence of distributions with $\lim_{n\to\infty} f_n(\varphi)$ existing for all $\varphi\in\mathcal{D}$. Define $f(\varphi):=\lim_{n\to\infty} f_n(\varphi)$. Then the claim is that $f$ is also a distribution. My question: For proving that this holds, how to see that $f$ is continuous w.r.t convergence in $\mathcal{D}$? (We define a sequence $(\varphi_n)$ in $\mathcal{D}$ to converge to some $\varphi\in\mathcal{D}$ iff there is some compact set $K\subset\mathbb{R}^n$, s.t. $\mathrm{supp}(\varphi_n)\subset K$ for each $n\in\mathbb{N}$ and $\|D^k\varphi_n-D^k\varphi\|_\mathrm{sup}\to 0$ as $n\to\infty$ for each $k\in\mathbb{N}_0^n$.) Thanks!",,"['functional-analysis', 'partial-differential-equations', 'distribution-theory']"
25,Question about a proof in Rudin's book - annihilators,Question about a proof in Rudin's book - annihilators,,"I'm reading the proof of the following theorem in Rudin's ""Functional Analysis"": Let $M$ be a closed subspace of a Banach space $X$.  The Hahn-Banach theorem extends each $m^* \in M^*$ to a functional $x^* \in X^*$.  Define $\sigma (m^*) = x^* + M^{\perp}$.  Then $\sigma$ is an isometric isomorphism of $M^*$ onto $X^*/M^{\perp}$. My problem is this part of the proof: Fix $m^* \in M^*$. If $x^* \in X^*$ extends $m^*$, it is obvious that $||m^*|| \le ||x^*||$ The greatest lower bound of the numbers $||x^*||$ so obtained is $||x^* + M^{\perp}||$, by the  definition of the quotient norm. Hence  $||m^*|| \le || \sigma (m^*) ||  \le ||x^*||$  But Theorem 3.3 furnishes an extension $x^*$ of $m^*$ with $||x^*|| = ||m^*||$. It follows  that $|| \sigma( m^*)|| = ||m^*||$. 3.3 Theorem Suppose $M$ is a subspace of a vector space $X$, $p$ is a seminorm on $X$,  and $f$ is a linear functional on $M$ such that  $|f(x)| \le p(x) \ \  (x \in M)$.  Then $f$ extends to a linear functional $\Lambda$ on $X$ that satisfies  $| \Lambda x | \le p(x)$  $ \ \ (x \in X)$. What I don't see is how theorem 3.3 implies the equality of norms: $||x^*|| = ||m^*||$ and why is $||m^*|| \le ||x^*||$ (in the first line). It would be clear to me if $||x^*||$ was a regular norm of a linear mapping (we take the supremum over a bigger set) but I don't see it if it is a quotient norm. Could you explain that to me? Thank you","I'm reading the proof of the following theorem in Rudin's ""Functional Analysis"": Let $M$ be a closed subspace of a Banach space $X$.  The Hahn-Banach theorem extends each $m^* \in M^*$ to a functional $x^* \in X^*$.  Define $\sigma (m^*) = x^* + M^{\perp}$.  Then $\sigma$ is an isometric isomorphism of $M^*$ onto $X^*/M^{\perp}$. My problem is this part of the proof: Fix $m^* \in M^*$. If $x^* \in X^*$ extends $m^*$, it is obvious that $||m^*|| \le ||x^*||$ The greatest lower bound of the numbers $||x^*||$ so obtained is $||x^* + M^{\perp}||$, by the  definition of the quotient norm. Hence  $||m^*|| \le || \sigma (m^*) ||  \le ||x^*||$  But Theorem 3.3 furnishes an extension $x^*$ of $m^*$ with $||x^*|| = ||m^*||$. It follows  that $|| \sigma( m^*)|| = ||m^*||$. 3.3 Theorem Suppose $M$ is a subspace of a vector space $X$, $p$ is a seminorm on $X$,  and $f$ is a linear functional on $M$ such that  $|f(x)| \le p(x) \ \  (x \in M)$.  Then $f$ extends to a linear functional $\Lambda$ on $X$ that satisfies  $| \Lambda x | \le p(x)$  $ \ \ (x \in X)$. What I don't see is how theorem 3.3 implies the equality of norms: $||x^*|| = ||m^*||$ and why is $||m^*|| \le ||x^*||$ (in the first line). It would be clear to me if $||x^*||$ was a regular norm of a linear mapping (we take the supremum over a bigger set) but I don't see it if it is a quotient norm. Could you explain that to me? Thank you",,"['functional-analysis', 'normed-spaces']"
26,Compactly supported infinitely differentiable function constant on an interval,Compactly supported infinitely differentiable function constant on an interval,,"I know a typical example of compactly supported infinitely differentiable function to be defined by $$f(x) = \begin{cases} e^{\frac{1}{(\beta-x)(\alpha-x)}}, & \alpha<x<\beta \\ 0, &x\notin (\alpha,\beta) \end{cases}$$Can a compactly supported infinitely differentiable function be explicitly defined to be constant on a certain interval? I have not been able to get anything by using piecewise defined functions with exponentials. Thank you very much for any answer!","I know a typical example of compactly supported infinitely differentiable function to be defined by $$f(x) = \begin{cases} e^{\frac{1}{(\beta-x)(\alpha-x)}}, & \alpha<x<\beta \\ 0, &x\notin (\alpha,\beta) \end{cases}$$Can a compactly supported infinitely differentiable function be explicitly defined to be constant on a certain interval? I have not been able to get anything by using piecewise defined functions with exponentials. Thank you very much for any answer!",,"['real-analysis', 'functional-analysis']"
27,A corollary of Arzela-Ascoli Theorem,A corollary of Arzela-Ascoli Theorem,,"I have seen in a paper to claim the fact that due to Arzela-Ascoli theorem pointwise convergence with equicontinuity and uniform boundedness of a sequence of functions implies uniform convergence on compacts. This is not correct. The statement is true, but it is not due to arzela-ascoli as this theorem talks about existence of some subsequence. Am I correct ?","I have seen in a paper to claim the fact that due to Arzela-Ascoli theorem pointwise convergence with equicontinuity and uniform boundedness of a sequence of functions implies uniform convergence on compacts. This is not correct. The statement is true, but it is not due to arzela-ascoli as this theorem talks about existence of some subsequence. Am I correct ?",,"['real-analysis', 'sequences-and-series', 'functional-analysis']"
28,"Erwin Kreyszig's Introductory Functional Analysis With Applications, Section 2.8, Problem 3: What is the norm of this functional?","Erwin Kreyszig's Introductory Functional Analysis With Applications, Section 2.8, Problem 3: What is the norm of this functional?",,"What is the norm of the linear functional $f$ defined on the normed space $C[a, b]$ of all functions defined and continuous on the closed interval $[a,b]$ with the norm defined as  $$\Vert x \Vert \colon= \max_{t\in[a,b]} \vert x(t) \vert \; \; \; \forall x \in C[a,b]?$$ Let  $$ f(x) \colon= \int_a^{\frac{a+b}{2}} x(t) dt - \int_{\frac{a+b}{2}}^b x(t) dt \; \; \; \forall x \in C[a,b].$$ I know that $f$ is linear and bounded because for all $x \in C[a,b]$, we have  $$\vert f(x) \vert = \left\vert  \int_a^{\frac{a+b}{2}} x(t) dt - \int_{\frac{a+b}{2}}^b x(t) dt  \right\vert   \leq \left\vert  \int_a^{\frac{a+b}{2}} x(t) dt  \right\vert + \left\vert \int_{\frac{a+b}{2}}^b x(t) dt  \right\vert \\ \leq \int_a^{\frac{a+b}{2}} \vert x(t) \vert dt + \int_{\frac{a+b}{2}}^b \vert x(t) \vert dt  \leq \int_a^{\frac{a+b}{2}} \max_{\tau\in[a,b]} \vert x(\tau) \vert dt + \int_{\frac{a+b}{2}}^b \max_{\tau\in[a,b]} \vert x(\tau) \vert dt  \\ = \int_a^b \max_{\tau\in[a,b]} \vert x(\tau \vert dt = (b-a)\Vert x \Vert_{C[a,b]},$$  which shows that $f$ is bounded and that $$\Vert f \Vert \leq b-a.$$ What next? How to arrive at the reverse inequality?","What is the norm of the linear functional $f$ defined on the normed space $C[a, b]$ of all functions defined and continuous on the closed interval $[a,b]$ with the norm defined as  $$\Vert x \Vert \colon= \max_{t\in[a,b]} \vert x(t) \vert \; \; \; \forall x \in C[a,b]?$$ Let  $$ f(x) \colon= \int_a^{\frac{a+b}{2}} x(t) dt - \int_{\frac{a+b}{2}}^b x(t) dt \; \; \; \forall x \in C[a,b].$$ I know that $f$ is linear and bounded because for all $x \in C[a,b]$, we have  $$\vert f(x) \vert = \left\vert  \int_a^{\frac{a+b}{2}} x(t) dt - \int_{\frac{a+b}{2}}^b x(t) dt  \right\vert   \leq \left\vert  \int_a^{\frac{a+b}{2}} x(t) dt  \right\vert + \left\vert \int_{\frac{a+b}{2}}^b x(t) dt  \right\vert \\ \leq \int_a^{\frac{a+b}{2}} \vert x(t) \vert dt + \int_{\frac{a+b}{2}}^b \vert x(t) \vert dt  \leq \int_a^{\frac{a+b}{2}} \max_{\tau\in[a,b]} \vert x(\tau) \vert dt + \int_{\frac{a+b}{2}}^b \max_{\tau\in[a,b]} \vert x(\tau) \vert dt  \\ = \int_a^b \max_{\tau\in[a,b]} \vert x(\tau \vert dt = (b-a)\Vert x \Vert_{C[a,b]},$$  which shows that $f$ is bounded and that $$\Vert f \Vert \leq b-a.$$ What next? How to arrive at the reverse inequality?",,"['real-analysis', 'functional-analysis', 'operator-theory', 'normed-spaces']"
29,Definitions for L2 and Lp Spaces?,Definitions for L2 and Lp Spaces?,,"I am taking a course in Functional Analysis online, and unfortunately some important terms have not been well defined.  In particular, isn't L2 space just Lp space with p=2 ?  If so, why aren't continuous functions on closed intervals with the L2 norm Banach spaces (on finite dimensional spaces, by the Fischer-Riesz Theorem)?","I am taking a course in Functional Analysis online, and unfortunately some important terms have not been well defined.  In particular, isn't L2 space just Lp space with p=2 ?  If so, why aren't continuous functions on closed intervals with the L2 norm Banach spaces (on finite dimensional spaces, by the Fischer-Riesz Theorem)?",,['functional-analysis']
30,Closed Subspaces of Hilbert Spaces,Closed Subspaces of Hilbert Spaces,,"I read the following statements. But I do not know how to show it or any example to support it. Could anyone provide some explanation and examples, please? Thank you! The subspace $C^\infty$ functions inside $\mathcal L^2(\mathbb R)$ is not closed. The subspace of simple functions inside $\mathcal L^2(\mathbb R)$ is not closed. Polynomials inside $C^0$ is not closed. I can think of the following Not sure. In addition, how do we know that $C^\infty \subset \mathcal L^2(\mathbb R)$ in the first place, please? Consider a sequence of functions of the following form: $$f_n (x) := \frac{k}{n}\chi_{\left[\frac{k}{n}, \frac{k+1}{n}\right)}(x),$$ where $n \in \mathbb N$ and $k = 0, 1, \dots$. Each function $f_n$ is defined on $[0, 1)$ and is left continuous. This sequence converges in norm to $f=x\mathbb I_{[0, 1)}$ which is not a simple function. So the set of simple function is not closed. Is this a valid counter example, please? I know that polynomials are dense in continuous functions. But there are plenty of continuous functions which are not polynomials. Hence, it is true that polynomials are not closed. But any concrete example, please?","I read the following statements. But I do not know how to show it or any example to support it. Could anyone provide some explanation and examples, please? Thank you! The subspace $C^\infty$ functions inside $\mathcal L^2(\mathbb R)$ is not closed. The subspace of simple functions inside $\mathcal L^2(\mathbb R)$ is not closed. Polynomials inside $C^0$ is not closed. I can think of the following Not sure. In addition, how do we know that $C^\infty \subset \mathcal L^2(\mathbb R)$ in the first place, please? Consider a sequence of functions of the following form: $$f_n (x) := \frac{k}{n}\chi_{\left[\frac{k}{n}, \frac{k+1}{n}\right)}(x),$$ where $n \in \mathbb N$ and $k = 0, 1, \dots$. Each function $f_n$ is defined on $[0, 1)$ and is left continuous. This sequence converges in norm to $f=x\mathbb I_{[0, 1)}$ which is not a simple function. So the set of simple function is not closed. Is this a valid counter example, please? I know that polynomials are dense in continuous functions. But there are plenty of continuous functions which are not polynomials. Hence, it is true that polynomials are not closed. But any concrete example, please?",,"['analysis', 'functional-analysis', 'hilbert-spaces', 'self-learning', 'big-list']"
31,A question about local convexity of the weak operator topology,A question about local convexity of the weak operator topology,,"By definition, I know a locally convex space is a topological vector space whose topology is defined by a family of seminorms $\cal P$ such that  $$\bigcap_{p\in{\cal P}}\{x\colon p(x)=0\}=\{0\}.$$ Also I can easily show that a locally convex space by above definition separates the points and conversely. So this two properties are equivalent. Now I want to show weak operator topology (WOT) is locally convex. By above definition, suppose for every $\xi , \eta \in H$, $p_{\xi,\eta}(x) =0 $, thus $|(x\xi,\eta)|=0$ for every $\xi,\eta$. Put $\eta=x\xi$ we have $\|x\xi\|=0$ for every $\xi$ and we can conclude $x=0$. My problem is to show WOT is locally convex using the equivalent property. Suppose $x,y\in B(H)$ and $p_{h,k}(x) = p_{h,k}(y)$ for every $h,k\in H$. We have $|(xh,k)|=|(yh,k)|$. There are $r_x,r_y$ with $|r_x|=|r_y|=1$ such that $|(xh,k)|=r_x(xh,k)$ and $|(yh,k)|=r_y(yh,k)$ and in the end we can see $r_x x=r_y y$. In this way I can not conclude wot topology separates the points. Please help me to understand it. Thanks in advance.","By definition, I know a locally convex space is a topological vector space whose topology is defined by a family of seminorms $\cal P$ such that  $$\bigcap_{p\in{\cal P}}\{x\colon p(x)=0\}=\{0\}.$$ Also I can easily show that a locally convex space by above definition separates the points and conversely. So this two properties are equivalent. Now I want to show weak operator topology (WOT) is locally convex. By above definition, suppose for every $\xi , \eta \in H$, $p_{\xi,\eta}(x) =0 $, thus $|(x\xi,\eta)|=0$ for every $\xi,\eta$. Put $\eta=x\xi$ we have $\|x\xi\|=0$ for every $\xi$ and we can conclude $x=0$. My problem is to show WOT is locally convex using the equivalent property. Suppose $x,y\in B(H)$ and $p_{h,k}(x) = p_{h,k}(y)$ for every $h,k\in H$. We have $|(xh,k)|=|(yh,k)|$. There are $r_x,r_y$ with $|r_x|=|r_y|=1$ such that $|(xh,k)|=r_x(xh,k)$ and $|(yh,k)|=r_y(yh,k)$ and in the end we can see $r_x x=r_y y$. In this way I can not conclude wot topology separates the points. Please help me to understand it. Thanks in advance.",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'topological-vector-spaces']"
32,Why is this operator self-adoint,Why is this operator self-adoint,,"We have that $\lambda, \overline{\lambda} \in \rho(T)$ and $\lambda \in \mathbb{C}$. Now, I want to show that a symmetric operator and closed operator $T: \operatorname{dom(T)} \rightarrow H$ must be self-adjoint. Notice, that $T$ is not necessarily densily defined. Does anybody here have any ideas? Actually, I concluded the closedness of this operator from the fact that the resolvent is not empty by myself, so this may be somehow a tautology in this exercise.","We have that $\lambda, \overline{\lambda} \in \rho(T)$ and $\lambda \in \mathbb{C}$. Now, I want to show that a symmetric operator and closed operator $T: \operatorname{dom(T)} \rightarrow H$ must be self-adjoint. Notice, that $T$ is not necessarily densily defined. Does anybody here have any ideas? Actually, I concluded the closedness of this operator from the fact that the resolvent is not empty by myself, so this may be somehow a tautology in this exercise.",,['real-analysis']
33,Complex Measures: Integrability,Complex Measures: Integrability,,"Problem On the one hand, a complex measure decomposes into: $$\mu=\Re_+\mu-\Re_-\mu+i\Im_+\mu-i\Im_-\mu=:\sum_{\alpha=0\ldots3}i^\alpha\mu_\alpha$$ This gives rise to the integrability condition: $$f\in L(\mu)\iff f\in L(\mu_\alpha)\quad(\alpha=1,\ldots,3)$$ On the other hand, a complex measure admits a derivative: $$\mu(E)=\int_Eu\mathrm{d}|\mu|\quad(|u|=1)$$ This gives rise to the integrability condition: $$f\in L(\mu):\iff fu\in L(|\mu|)\iff f\in L(|\mu|)$$ So the question arises wether these approaches coincide:   $$f\in L(|\mu|)\iff f\in L(\mu_\alpha)\quad(\alpha=1,\ldots,3)$$ Attempt So far by construction it is: $$\mu_\alpha(E)=\int_Eu_\alpha\mathrm{d}|\mu|\quad(0\leq u_\alpha\leq1)$$ which gives for positive functions: $$\int|f|\mathrm{d}\mu_\alpha=\int|f|u_\alpha\mathrm{d}|\mu|\leq\int |f|\mathrm{d}|\mu|$$ That proves the inclusion: $$f\in L(|\mu|)\implies f\in L(\mu_\alpha)\quad(\alpha=1,\ldots,3)$$ But what about the converse? Related For a formal treatment see: Complex Measures: Integration For a related recapitulation see: Complex Measures: Variation For a similar problem see: Complex Functions: Integrability For a general problem see: Radon-Nikodym: Integrability?","Problem On the one hand, a complex measure decomposes into: $$\mu=\Re_+\mu-\Re_-\mu+i\Im_+\mu-i\Im_-\mu=:\sum_{\alpha=0\ldots3}i^\alpha\mu_\alpha$$ This gives rise to the integrability condition: $$f\in L(\mu)\iff f\in L(\mu_\alpha)\quad(\alpha=1,\ldots,3)$$ On the other hand, a complex measure admits a derivative: $$\mu(E)=\int_Eu\mathrm{d}|\mu|\quad(|u|=1)$$ This gives rise to the integrability condition: $$f\in L(\mu):\iff fu\in L(|\mu|)\iff f\in L(|\mu|)$$ So the question arises wether these approaches coincide:   $$f\in L(|\mu|)\iff f\in L(\mu_\alpha)\quad(\alpha=1,\ldots,3)$$ Attempt So far by construction it is: $$\mu_\alpha(E)=\int_Eu_\alpha\mathrm{d}|\mu|\quad(0\leq u_\alpha\leq1)$$ which gives for positive functions: $$\int|f|\mathrm{d}\mu_\alpha=\int|f|u_\alpha\mathrm{d}|\mu|\leq\int |f|\mathrm{d}|\mu|$$ That proves the inclusion: $$f\in L(|\mu|)\implies f\in L(\mu_\alpha)\quad(\alpha=1,\ldots,3)$$ But what about the converse? Related For a formal treatment see: Complex Measures: Integration For a related recapitulation see: Complex Measures: Variation For a similar problem see: Complex Functions: Integrability For a general problem see: Radon-Nikodym: Integrability?",,"['integration', 'functional-analysis', 'measure-theory', 'definition']"
34,What is the image of operator exponential?,What is the image of operator exponential?,,"Given a Banach space $V$ and a bounded linear operator $A:V\to V$, the operator $e^A$ is bounded and invertible. When $V$ is finite dimensional, every invertible operator is of the form $e^B$ (one can reduce the problem to Jordan blocks, and then to operators of the form $I+N$ with $N$ nilpotent, which follows from the power series for $\log$). What happens in the infinite dimensional case? What if we restrict to seperable Hilbert spaces? Is there a nice description of the operators in the image of the operator exponential?","Given a Banach space $V$ and a bounded linear operator $A:V\to V$, the operator $e^A$ is bounded and invertible. When $V$ is finite dimensional, every invertible operator is of the form $e^B$ (one can reduce the problem to Jordan blocks, and then to operators of the form $I+N$ with $N$ nilpotent, which follows from the power series for $\log$). What happens in the infinite dimensional case? What if we restrict to seperable Hilbert spaces? Is there a nice description of the operators in the image of the operator exponential?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'banach-spaces']"
35,Set of sequences which converge to zero is a closed subspace of $l^\infty$,Set of sequences which converge to zero is a closed subspace of,l^\infty,Prove that: $$c_0 = \{\{a_n\}_1^\infty:lim_{n\to\infty}a_n = 0\}$$ Is a closed subspace of $l^\infty$.,Prove that: $$c_0 = \{\{a_n\}_1^\infty:lim_{n\to\infty}a_n = 0\}$$ Is a closed subspace of $l^\infty$.,,"['functional-analysis', 'lp-spaces']"
36,An exercise about the spectrum of an element in Banach algebra.,An exercise about the spectrum of an element in Banach algebra.,,"An exercise of Banach algebra, section of spectrum  has wanted the proof of this statement: Let $A$ be a Banach algebra and $x\in A$. Show that for every open set $U$ in $\mathbb{C}$ that contains $\sigma(x)$, there exist a positive number $\delta$ such that $\sigma(y)\subset U$ whenever $y\in A$ satisfies $||y-x||<\delta$. How can I prove this statement? Thanks for your guidance.","An exercise of Banach algebra, section of spectrum  has wanted the proof of this statement: Let $A$ be a Banach algebra and $x\in A$. Show that for every open set $U$ in $\mathbb{C}$ that contains $\sigma(x)$, there exist a positive number $\delta$ such that $\sigma(y)\subset U$ whenever $y\in A$ satisfies $||y-x||<\delta$. How can I prove this statement? Thanks for your guidance.",,"['functional-analysis', 'operator-theory', 'spectral-theory', 'banach-algebras']"
37,Why is the weak operator closure of a commutative $\boldsymbol{C^*\!\!\!\!-}$algebra also commutative?,Why is the weak operator closure of a commutative algebra also commutative?,\boldsymbol{C^*\!\!\!\!-},"In a book on Operator Theory there is the following statement: If $\mathscr A$ is a commutative $C^*$-subalgebra of $\mathscr B(\mathcal H)$, where $\mathcal H$ is a Hilbert space, then the weak operator closure of $\mathscr A$ is also commutative. I can not prove this. Please help me. Thanks.","In a book on Operator Theory there is the following statement: If $\mathscr A$ is a commutative $C^*$-subalgebra of $\mathscr B(\mathcal H)$, where $\mathcal H$ is a Hilbert space, then the weak operator closure of $\mathscr A$ is also commutative. I can not prove this. Please help me. Thanks.",,"['analysis', 'functional-analysis', 'operator-theory', 'c-star-algebras', 'von-neumann-algebras']"
38,$A^{\ast}$ compact $\Rightarrow A$ compact,compact  compact,A^{\ast} \Rightarrow A,"I read that if $A:E\to E$ is a bounded linear operator where $E$ is a Banach space and $A^{\ast}$ is a compact operator , then $A$ is a compact operator. I know that the converse is true ( th. 4 here ), but I cannot prove the lemma above. I have tried to apply Arzelà's theorem, similarly to how it is done in the quoted th. 4, but I cannot get anything... Thank you so much for any help!!!","I read that if $A:E\to E$ is a bounded linear operator where $E$ is a Banach space and $A^{\ast}$ is a compact operator , then $A$ is a compact operator. I know that the converse is true ( th. 4 here ), but I cannot prove the lemma above. I have tried to apply Arzelà's theorem, similarly to how it is done in the quoted th. 4, but I cannot get anything... Thank you so much for any help!!!",,"['functional-analysis', 'banach-spaces', 'compact-operators']"
39,"Completeness and Separability of $C[0,\infty]$",Completeness and Separability of,"C[0,\infty]","Let $C[0,\infty]$ be the space of all continuous functions on $[0, \infty ]$ with metric    $$ \phi(\omega_1, \omega_2) = \sum^{\infty}_{n=1} \frac{1}{2^n}\max_{0{\leq} t {\leq} n}(|\omega_1(t)-\omega_2(t)|\wedge 1)$$  where $n  \in \mathbb{N}$. Show that the space $C[0,\infty]$ under $\phi$ is complete and separable. I proceeded as follows: suppose I have a Cauchy sequence $\{\omega_n\}$ in $C[0,\infty]$. Its limit exists in $\phi$ as $\phi$ is bounded. Let the limit be $\omega$, now I have to show that $\omega $ belongs to $C[0,\infty]$.","Let $C[0,\infty]$ be the space of all continuous functions on $[0, \infty ]$ with metric    $$ \phi(\omega_1, \omega_2) = \sum^{\infty}_{n=1} \frac{1}{2^n}\max_{0{\leq} t {\leq} n}(|\omega_1(t)-\omega_2(t)|\wedge 1)$$  where $n  \in \mathbb{N}$. Show that the space $C[0,\infty]$ under $\phi$ is complete and separable. I proceeded as follows: suppose I have a Cauchy sequence $\{\omega_n\}$ in $C[0,\infty]$. Its limit exists in $\phi$ as $\phi$ is bounded. Let the limit be $\omega$, now I have to show that $\omega $ belongs to $C[0,\infty]$.",,"['real-analysis', 'general-topology', 'functional-analysis', 'metric-spaces']"
40,It's the discrete topology.,It's the discrete topology.,,"I have to proof that if I have $(X,\tau)$ and $(Y,\delta)$ two topological spaces, if every function $f:X\longrightarrow Y$ is continuos then $\tau$ is the discrete topology. I don't know what is the way to solve this. Thanks!","I have to proof that if I have $(X,\tau)$ and $(Y,\delta)$ two topological spaces, if every function $f:X\longrightarrow Y$ is continuos then $\tau$ is the discrete topology. I don't know what is the way to solve this. Thanks!",,"['general-topology', 'functional-analysis']"
41,$\sup$ norm of a function,norm of a function,\sup,"The following is an example of Murphy's C*-algebras and operator theory: I do not know how he concludes $$\int_0^1 |k(s,t) - k(s',t)||f(t)| dt \leq \sup|k(s,t) - k(s',t)|||f||_\infty$$ Please help me. Thanks for your help.","The following is an example of Murphy's C*-algebras and operator theory: I do not know how he concludes $$\int_0^1 |k(s,t) - k(s',t)||f(t)| dt \leq \sup|k(s,t) - k(s',t)|||f||_\infty$$ Please help me. Thanks for your help.",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'normed-spaces', 'compact-operators']"
42,Topological and algebraic interiors,Topological and algebraic interiors,,"I read on a functional analysis book that in a normed, real or complex, space $V$ the algebraic interior of a set $S\subset V$ defined $J(S):=\{x\in S:\quad\forall y\in V\quad\exists \varepsilon(y)=\varepsilon>0:\forall t\in\mathbb{R}(|t|<\varepsilon\Rightarrow x+ty\in S)\}$ is the same of its topological interior $\mathring{S}$. I'm convinced that it is not true in general for a normed, either real or complex, vector space, but I see that for any such normed space the inclusion $\mathring{S}\subset J(S)$ is true, and I have also found the proof that, if $S$ is convex, then $\mathring{S}= J(S)$ holds in such spaces. Can it be proven, and how, that $\mathring{S}\subset J(S)$ in any topological vector space? If $S$ is convex, can it be proven, and how, that $\mathring{S}= J(S)$? I'm tremendously confused because my book states $\mathring{S}= J(S)$ for normed spaces and then appears to use the equality at least for convex sets, not only in normed spaces, but in general locally convex spaces... $\infty$ thanks for any answer!!!","I read on a functional analysis book that in a normed, real or complex, space $V$ the algebraic interior of a set $S\subset V$ defined $J(S):=\{x\in S:\quad\forall y\in V\quad\exists \varepsilon(y)=\varepsilon>0:\forall t\in\mathbb{R}(|t|<\varepsilon\Rightarrow x+ty\in S)\}$ is the same of its topological interior $\mathring{S}$. I'm convinced that it is not true in general for a normed, either real or complex, vector space, but I see that for any such normed space the inclusion $\mathring{S}\subset J(S)$ is true, and I have also found the proof that, if $S$ is convex, then $\mathring{S}= J(S)$ holds in such spaces. Can it be proven, and how, that $\mathring{S}\subset J(S)$ in any topological vector space? If $S$ is convex, can it be proven, and how, that $\mathring{S}= J(S)$? I'm tremendously confused because my book states $\mathring{S}= J(S)$ for normed spaces and then appears to use the equality at least for convex sets, not only in normed spaces, but in general locally convex spaces... $\infty$ thanks for any answer!!!",,"['general-topology', 'functional-analysis']"
43,"If $f \in L^{1}(d\mu)$, is it true that $\int \limits_{X} f\chi_{\{ f \neq 0 \} } \,d\mu = \int \limits_{X}f \,d(\chi_{\{ f\neq 0 \} }\,d\mu)$?","If , is it true that ?","f \in L^{1}(d\mu) \int \limits_{X} f\chi_{\{ f \neq 0 \} } \,d\mu = \int \limits_{X}f \,d(\chi_{\{ f\neq 0 \} }\,d\mu)","Ok, so we have $f \in L^{1}(d\mu)$, with $(X, \Sigma, \mu)$ a complete measure space. If we assume $f$ is nonnegative, we can define a measure $\rho(E) = \int \limits_{E} f \,d\mu$ for $E \in \Sigma$.  I call the measure $\rho$ as $fd\mu$. So, if we consider the function $f$, and look at the characteristic function $\chi_{ \{x \mid f(x) \neq 0 \} }$, then we have a measure induced by this function as described above.  I will call the measure $\chi_{ \{x \mid f(x) \neq 0 \} } \,d\mu$. Is it true that $\int \limits_{X} f\chi_{ \{ x \mid f(x) \neq 0 \}} \,d\mu = \int \limits_{X} f \,d(\chi_{ \{ x \mid f(x) \neq 0 \} } \,d\mu)$?  Note that the integral on the left hand side is with respect to the measure $\mu$ while the integral on the right hand side is with respect to the measure induced by the characteristic function. Thanks for your help.","Ok, so we have $f \in L^{1}(d\mu)$, with $(X, \Sigma, \mu)$ a complete measure space. If we assume $f$ is nonnegative, we can define a measure $\rho(E) = \int \limits_{E} f \,d\mu$ for $E \in \Sigma$.  I call the measure $\rho$ as $fd\mu$. So, if we consider the function $f$, and look at the characteristic function $\chi_{ \{x \mid f(x) \neq 0 \} }$, then we have a measure induced by this function as described above.  I will call the measure $\chi_{ \{x \mid f(x) \neq 0 \} } \,d\mu$. Is it true that $\int \limits_{X} f\chi_{ \{ x \mid f(x) \neq 0 \}} \,d\mu = \int \limits_{X} f \,d(\chi_{ \{ x \mid f(x) \neq 0 \} } \,d\mu)$?  Note that the integral on the left hand side is with respect to the measure $\mu$ while the integral on the right hand side is with respect to the measure induced by the characteristic function. Thanks for your help.",,"['real-analysis', 'functional-analysis', 'measure-theory']"
44,"If $f \in L^{1}(d\mu)$ is nonnegative, can we conclude $\mu( \{ x \mid f(x) \neq 0 \} ) < \infty$?","If  is nonnegative, can we conclude ?",f \in L^{1}(d\mu) \mu( \{ x \mid f(x) \neq 0 \} ) < \infty,"I am trying to prove a statement, and I need the fact that: If $f \in L^{1}(d\mu)$  is  a nonnegative function, then this implies $\mu( \{x \mid f(x) \neq 0 \} ) < \infty$. But I don't know if this is necessarily true. Here is my general idea for a proof that might work: Suppose $f \in L^{1}(d\mu)$ is a nonnegative function. Also, suppose by contradiction that $\mu( \{ x \mid f(x) \neq 0 \} ) = \infty$.  If $f$ attains a minimum positive value ( there is no guarantee that $f$ behaves this way.... ) then let $\alpha$ be that minimum value.  Define a simple function $s(x) = \begin{cases} \alpha & x \in \{ x \mid f(x) \neq 0 \} \\ 0 & x \not \in \{ x \mid f(x) \neq 0 \} \end{cases}$. Then $0 \leq s(x) \leq f(x)$ for all $x$, and $\int \limits_{X} s(x) \,d\mu = \infty$, implying $\int \limits_{X} f \,d\mu = \infty$, which is a contradiction to the assumption that $f \in L^{1}(d\mu)$. What if $f$ does not attain a minimum positive value (i.e., its infimum is $0$)?","I am trying to prove a statement, and I need the fact that: If $f \in L^{1}(d\mu)$  is  a nonnegative function, then this implies $\mu( \{x \mid f(x) \neq 0 \} ) < \infty$. But I don't know if this is necessarily true. Here is my general idea for a proof that might work: Suppose $f \in L^{1}(d\mu)$ is a nonnegative function. Also, suppose by contradiction that $\mu( \{ x \mid f(x) \neq 0 \} ) = \infty$.  If $f$ attains a minimum positive value ( there is no guarantee that $f$ behaves this way.... ) then let $\alpha$ be that minimum value.  Define a simple function $s(x) = \begin{cases} \alpha & x \in \{ x \mid f(x) \neq 0 \} \\ 0 & x \not \in \{ x \mid f(x) \neq 0 \} \end{cases}$. Then $0 \leq s(x) \leq f(x)$ for all $x$, and $\int \limits_{X} s(x) \,d\mu = \infty$, implying $\int \limits_{X} f \,d\mu = \infty$, which is a contradiction to the assumption that $f \in L^{1}(d\mu)$. What if $f$ does not attain a minimum positive value (i.e., its infimum is $0$)?",,"['real-analysis', 'functional-analysis', 'measure-theory']"
45,Banach spaces not isomorphic to $\ell^p(S)$?,Banach spaces not isomorphic to ?,\ell^p(S),"We know that every Hilbert space is unitarily equivalent to $\ell^2(S)$, for a set $S$ of suitable cardinality. Is there a Banach space which is NOT isomorphic to $L^p(X)$, for any $1\leq p \leq \infty$, and any measure space $X$?","We know that every Hilbert space is unitarily equivalent to $\ell^2(S)$, for a set $S$ of suitable cardinality. Is there a Banach space which is NOT isomorphic to $L^p(X)$, for any $1\leq p \leq \infty$, and any measure space $X$?",,['functional-analysis']
46,"Canonical inclusion $L^q(0,1) \to L^p(0,1)$ is compact?",Canonical inclusion  is compact?,"L^q(0,1) \to L^p(0,1)","Does there exist $q>p$ such that the canonical inclusion $L^q(0,1) \to L^p(0,1)$ is compact? My answer is no. Since we know that $L^\infty (0,1) \to L^p(0,1)$ is not compact, take $\{\sin(nx)\}$ as a counter example; this counter example will also work for $L^q$. Is my argument correct? And what if I change ""compact"" to ""weakly compact""? Because then my counter example would fail. Another question, is there any connection between the weak topology on $L^p$ and the strong topology on $L^q$? My guess is no, since the weak topology is not metrizable.","Does there exist $q>p$ such that the canonical inclusion $L^q(0,1) \to L^p(0,1)$ is compact? My answer is no. Since we know that $L^\infty (0,1) \to L^p(0,1)$ is not compact, take $\{\sin(nx)\}$ as a counter example; this counter example will also work for $L^q$. Is my argument correct? And what if I change ""compact"" to ""weakly compact""? Because then my counter example would fail. Another question, is there any connection between the weak topology on $L^p$ and the strong topology on $L^q$? My guess is no, since the weak topology is not metrizable.",,"['real-analysis', 'functional-analysis', 'lp-spaces', 'compact-operators']"
47,"Proof that this set $\{f\in X\mid \|f\|_\infty \le 1\}$ is not compact in $C[0,1]$ with the sup norm",Proof that this set  is not compact in  with the sup norm,"\{f\in X\mid \|f\|_\infty \le 1\} C[0,1]","Let $X=C[0,1]$ with the $\sup$ norm. Let $Y = \{f\in X\mid \|f\|_\infty \le 1\}$. It is my goal to show that $Y$ is not compact using the sequence defintion of compactness. Note that it is very easy to show it using the covering defintion: Let $0$ denote the constant $0$ function. Then $B(0, 1- {1\over n})$ is an open cover of $Y$ that does not admit a finite subcover. The sequence defintion states that a set is compact iff every sequence has a convergent subsequence. Therefore, to prove that $Y$ is not compact one must find a sequence that does not admit a convergent subsequence. I tried and failed. Then I looked for a solution and found this: let $f_n (x) = x^n$. I do understand that $f_n \in Y$. But it seems that these functions only converge pointwise because the limit function is discontinuous. But for this proof one wants a sequence that converges uniformly to something not in $Y$, no? So this is not an answer.","Let $X=C[0,1]$ with the $\sup$ norm. Let $Y = \{f\in X\mid \|f\|_\infty \le 1\}$. It is my goal to show that $Y$ is not compact using the sequence defintion of compactness. Note that it is very easy to show it using the covering defintion: Let $0$ denote the constant $0$ function. Then $B(0, 1- {1\over n})$ is an open cover of $Y$ that does not admit a finite subcover. The sequence defintion states that a set is compact iff every sequence has a convergent subsequence. Therefore, to prove that $Y$ is not compact one must find a sequence that does not admit a convergent subsequence. I tried and failed. Then I looked for a solution and found this: let $f_n (x) = x^n$. I do understand that $f_n \in Y$. But it seems that these functions only converge pointwise because the limit function is discontinuous. But for this proof one wants a sequence that converges uniformly to something not in $Y$, no? So this is not an answer.",,"['real-analysis', 'functional-analysis']"
48,Banach valued sequence spaces $\ell^p(X)$,Banach valued sequence spaces,\ell^p(X),"Let $X$ be a Banach space and $\ell^p(X)$ denote the space of sequences $x_i\in X$ for which the norm $\big(\sum_{i=1}^\infty\|x_i\|^p\big)^\frac1p$ is finite, when $X=\mathbb{R}$ we get the usual $\ell^p$. For $1<p<\infty$ and $\frac1p+\frac1q=1$ we have $(l^p)^*\simeq l^q$. Is it always true that $\ell^p(X)^*\simeq \ell^q(X^*)$ for $1<p<\infty$ and $\frac1p+\frac1q=1$? This fails for big $L_p([0,1];X)$ without some condition on $X$, like reflexivity. Does it hold for any $L_p(\Omega,\mu;X)$ when $X$ is reflexive? References appriciated.","Let $X$ be a Banach space and $\ell^p(X)$ denote the space of sequences $x_i\in X$ for which the norm $\big(\sum_{i=1}^\infty\|x_i\|^p\big)^\frac1p$ is finite, when $X=\mathbb{R}$ we get the usual $\ell^p$. For $1<p<\infty$ and $\frac1p+\frac1q=1$ we have $(l^p)^*\simeq l^q$. Is it always true that $\ell^p(X)^*\simeq \ell^q(X^*)$ for $1<p<\infty$ and $\frac1p+\frac1q=1$? This fails for big $L_p([0,1];X)$ without some condition on $X$, like reflexivity. Does it hold for any $L_p(\Omega,\mu;X)$ when $X$ is reflexive? References appriciated.",,"['functional-analysis', 'reference-request', 'banach-spaces', 'lp-spaces']"
49,$L^1(μ)$ is finite dimensional if it is reflexive,is finite dimensional if it is reflexive,L^1(μ),"If $(X,\Omega,\mu)$ is a $\sigma -$ finite measure space, show that if $L^1(X,\Omega,\mu)$ is reflexive then it is finite dimensional. My attempt: I want to show there is a copy of $\ell^1$ in $L^1(X,\Omega,\mu)$.  For this suppose $L^1(X,\Omega,\mu)$ is infinite dimensional. there is a sequence $\{x_n\}$ of disjoint points of $X$. For every n, Put $\chi_n:=\chi(x_n)$ (characteristic function ). define $\phi:\ell^1\to L^1(X,\Omega,\mu)$ such that $\phi(\{a_n\})=\Sigma a_n \chi_n$. But I can not show that $\phi$ is an isometry. I think I did not in a correct way. Please help me. Thanks in advance.","If $(X,\Omega,\mu)$ is a $\sigma -$ finite measure space, show that if $L^1(X,\Omega,\mu)$ is reflexive then it is finite dimensional. My attempt: I want to show there is a copy of $\ell^1$ in $L^1(X,\Omega,\mu)$.  For this suppose $L^1(X,\Omega,\mu)$ is infinite dimensional. there is a sequence $\{x_n\}$ of disjoint points of $X$. For every n, Put $\chi_n:=\chi(x_n)$ (characteristic function ). define $\phi:\ell^1\to L^1(X,\Omega,\mu)$ such that $\phi(\{a_n\})=\Sigma a_n \chi_n$. But I can not show that $\phi$ is an isometry. I think I did not in a correct way. Please help me. Thanks in advance.",,"['functional-analysis', 'banach-spaces']"
50,A question on nuclearity,A question on nuclearity,,"Definition 2.1.1. If $A$, $B$ are C*-algebra, a map $\theta: A\rightarrow B$ is called nuclear if there exist contractive completely positive maps $\phi_{n}: A\rightarrow M_{k(n)}(\mathbb{C})$ and $\psi_{n}: M_{k(n)}(\mathbb{C})\rightarrow B$ such that $\psi_{n}\circ\phi_{n}\rightarrow\theta$ in the point-norm topology for all $a\in A$. Definition 2.1.2. If $A$ is a C*-algebra and $N$ is a von Neumann algebra, a map $\theta: A\rightarrow N$ is call weakly nuclear if there exist contractive completely positive maps $\phi_{n}: A\rightarrow M_{k(n)}(\mathbb{C})$ and $\psi_{n}: M_{k(n)}(\mathbb{C})\rightarrow B$ such that $\psi_{n}\circ\phi_{n}\rightarrow\theta$ in the point-ultraweak topology: $$\eta(\psi_{n}\circ\phi_{n}(a))\rightarrow\eta(\theta(a)),$$ for all $a\in A$ and all normal functionals $\eta\in N_{*}$. My question is : If $\phi: A\rightarrow B\subset B^{**}$ is weakly nuclear, can we conclude that $\phi$ is nuclear?","Definition 2.1.1. If $A$, $B$ are C*-algebra, a map $\theta: A\rightarrow B$ is called nuclear if there exist contractive completely positive maps $\phi_{n}: A\rightarrow M_{k(n)}(\mathbb{C})$ and $\psi_{n}: M_{k(n)}(\mathbb{C})\rightarrow B$ such that $\psi_{n}\circ\phi_{n}\rightarrow\theta$ in the point-norm topology for all $a\in A$. Definition 2.1.2. If $A$ is a C*-algebra and $N$ is a von Neumann algebra, a map $\theta: A\rightarrow N$ is call weakly nuclear if there exist contractive completely positive maps $\phi_{n}: A\rightarrow M_{k(n)}(\mathbb{C})$ and $\psi_{n}: M_{k(n)}(\mathbb{C})\rightarrow B$ such that $\psi_{n}\circ\phi_{n}\rightarrow\theta$ in the point-ultraweak topology: $$\eta(\psi_{n}\circ\phi_{n}(a))\rightarrow\eta(\theta(a)),$$ for all $a\in A$ and all normal functionals $\eta\in N_{*}$. My question is : If $\phi: A\rightarrow B\subset B^{**}$ is weakly nuclear, can we conclude that $\phi$ is nuclear?",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
51,Approximation of the Heaviside Function whose derivative has a compact support,Approximation of the Heaviside Function whose derivative has a compact support,,"I am looking for a smooth approximation $H_\delta$ of the Heaviside function, which has the property that $$ \lim_{\delta\rightarrow 0^+}H_\delta =H $$ in the distribution sense, and $$ H_\delta(x)=1,\;\;{\mbox{for}}\;\;x>\delta,\;\;H_\delta(x)=0,\;\;{\mbox{for}}\;\;x<\delta. $$ Now, take the following function, which is a smooth approximation of the Dirac delta function with compact support:  $$ f=\left.\exp\left(-\frac{\delta^2}{\delta^2-x^2}\right)\right.,\;\;{\mbox{for}}\;\;|x|<\delta,\;\; {\mbox{and zero elsewhere.}} $$ The integral of $f$ from $-\delta$ to x divided by the integral of $f$ on $\mathbb{R}$  will do the trick. My question is this: is there a simpler way to answer this question than by writing it as an unevaluated integral?","I am looking for a smooth approximation $H_\delta$ of the Heaviside function, which has the property that $$ \lim_{\delta\rightarrow 0^+}H_\delta =H $$ in the distribution sense, and $$ H_\delta(x)=1,\;\;{\mbox{for}}\;\;x>\delta,\;\;H_\delta(x)=0,\;\;{\mbox{for}}\;\;x<\delta. $$ Now, take the following function, which is a smooth approximation of the Dirac delta function with compact support:  $$ f=\left.\exp\left(-\frac{\delta^2}{\delta^2-x^2}\right)\right.,\;\;{\mbox{for}}\;\;|x|<\delta,\;\; {\mbox{and zero elsewhere.}} $$ The integral of $f$ from $-\delta$ to x divided by the integral of $f$ on $\mathbb{R}$  will do the trick. My question is this: is there a simpler way to answer this question than by writing it as an unevaluated integral?",,"['calculus', 'functional-analysis', 'mathematical-physics', 'distribution-theory', 'dirac-delta']"
52,Find vector space $X$; so that vector space operations are not continuous,Find vector space ; so that vector space operations are not continuous,X,"How to choose $X$ to be a complex vector space with  a topology $\tau$ on $X$; so that vector space operations are not continuous  with respect to $\tau$; that is, the mappings, $X\times X \to X: (x,y)\mapsto x+y$ and $\mathbb C \times X : (\alpha, x)\mapsto \alpha x$ are not continuous ?","How to choose $X$ to be a complex vector space with  a topology $\tau$ on $X$; so that vector space operations are not continuous  with respect to $\tau$; that is, the mappings, $X\times X \to X: (x,y)\mapsto x+y$ and $\mathbb C \times X : (\alpha, x)\mapsto \alpha x$ are not continuous ?",,"['general-topology', 'functional-analysis']"
53,Is projection on a convex closed weakly-sequentially continuous?,Is projection on a convex closed weakly-sequentially continuous?,,"I think to have proved the following: Given $K$ a convex closed(maybe also limited is needed)subset(also curve not just subspaces) of an Hilbert space $H$, is well defined the projection operator $p_K:H \to K$. This operator is continuos for the norm topology. If i didn't miss something, my guess (is not a very formal proof) shows that is sequentially continuous for the weak topology. Is that true? My guess goes more or less like this: i write my convex set as intersection of half spaces, and i reduce in some way to those. Before to try to work it out more clearly i'd like to know if anybody knows if the result is actually true. Thanks","I think to have proved the following: Given $K$ a convex closed(maybe also limited is needed)subset(also curve not just subspaces) of an Hilbert space $H$, is well defined the projection operator $p_K:H \to K$. This operator is continuos for the norm topology. If i didn't miss something, my guess (is not a very formal proof) shows that is sequentially continuous for the weak topology. Is that true? My guess goes more or less like this: i write my convex set as intersection of half spaces, and i reduce in some way to those. Before to try to work it out more clearly i'd like to know if anybody knows if the result is actually true. Thanks",,"['functional-analysis', 'hilbert-spaces']"
54,"If we remove finite number of elements from a dense subset, will it be still dense?","If we remove finite number of elements from a dense subset, will it be still dense?",,"Let $D$ be a dense susbet of $X$. If we remove a finite number of elements from $D$, will it still be dense in $X$?","Let $D$ be a dense susbet of $X$. If we remove a finite number of elements from $D$, will it still be dense in $X$?",,"['general-topology', 'functional-analysis']"
55,Operator: not closable!,Operator: not closable!,,"Is there an operator between Banach spaces with the following properties: $$T:\mathcal{D}(T)\subseteq X\to Y:\text{ injective, dense range, continuously invertible, not closable!}$$ (Note that the ambient spaces should be really Banach spaces - otherwise this is trivial.) Obviously this operator must automatically satisfy: Operator must be unbounded Range must not be closed Closure of inverse must be not invertible The question is related to the alternative definition of: Resolvent: Definition","Is there an operator between Banach spaces with the following properties: $$T:\mathcal{D}(T)\subseteq X\to Y:\text{ injective, dense range, continuously invertible, not closable!}$$ (Note that the ambient spaces should be really Banach spaces - otherwise this is trivial.) Obviously this operator must automatically satisfy: Operator must be unbounded Range must not be closed Closure of inverse must be not invertible The question is related to the alternative definition of: Resolvent: Definition",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'banach-spaces', 'spectral-theory']"
56,"$T$ has a finite rank $\iff$ $\exists N \in \mathbb{N}$ such that $\lambda_n=0$, $\forall n \geq N$","has a finite rank   such that ,",T \iff \exists N \in \mathbb{N} \lambda_n=0 \forall n \geq N,"The question goes as follows: $T$ has a finite rank $\iff$ $\exists N \in \mathbb{N}$ such that $\lambda_n=0$, $\forall n \geq N$. Given is the data:  $X$ is a Hilbert space with an orthonormal basis $(e_n)$. The linear operator $T: X \rightarrow X$ is defined as;  $Tx=\sum\limits_{n=1}^{\infty} \lambda_n(x,e_n)e_n$. In a previous question I solved $T \in K(X)$ $\iff$ $\lambda_n \rightarrow 0$, which I`m supposed to use. My attempt: If $T$ is a compact operator with infinite rank, then $\lambda_n \rightarrow 0$ as $n \rightarrow \infty$. So if $T$ has rank $K$, with $K$ finite, then $\lambda_n \rightarrow 0$ still has to hold. But because no values of $\lambda_n$ are plugged in for $n > K$, thus for $N=K-1$ we have, $\lambda_n=0$ for all $N \in \mathbb{N}$ whenever $n \geq N$. The $\leftarrow$ way I understand.","The question goes as follows: $T$ has a finite rank $\iff$ $\exists N \in \mathbb{N}$ such that $\lambda_n=0$, $\forall n \geq N$. Given is the data:  $X$ is a Hilbert space with an orthonormal basis $(e_n)$. The linear operator $T: X \rightarrow X$ is defined as;  $Tx=\sum\limits_{n=1}^{\infty} \lambda_n(x,e_n)e_n$. In a previous question I solved $T \in K(X)$ $\iff$ $\lambda_n \rightarrow 0$, which I`m supposed to use. My attempt: If $T$ is a compact operator with infinite rank, then $\lambda_n \rightarrow 0$ as $n \rightarrow \infty$. So if $T$ has rank $K$, with $K$ finite, then $\lambda_n \rightarrow 0$ still has to hold. But because no values of $\lambda_n$ are plugged in for $n > K$, thus for $N=K-1$ we have, $\lambda_n=0$ for all $N \in \mathbb{N}$ whenever $n \geq N$. The $\leftarrow$ way I understand.",,"['functional-analysis', 'hilbert-spaces']"
57,"Uniform convergence of $f_n(x)=nx^n(1-x)$ for $x \in [0,1]$?",Uniform convergence of  for ?,"f_n(x)=nx^n(1-x) x \in [0,1]","I want to decide whether or not $f_n(x)=nx^n(1-x)$ is uniformly convergent or not. I have shown that $\lim_{n\to\infty} f_n(x)=0$ for $x \in [0,1]$. Now $f_n(0)=f_n(1)=0$. And in $(0,1)$, we have $f'_n(x)=n^2x^{n-1}-n(n+1)x^n$. Putting this to zero gives $x=\frac{n}{n+1}$. Also $f_n(\frac{n}{n+1})=(\frac{n}{n+1})^{n+1}$. But that tends to $\frac{1}{e}$ as $n$ tends to $\infty$ which is not $0$ so we don't have uniform convergence, right? Nonetheless we have $\lim_{n\to\infty} \int_0^1 f_n(x)dx=\lim_{n\to\infty} (\frac{n}{n+2}-\frac{n}{n+1})=0=\int_0^1 \lim_{n\to\infty} f_n(x)dx$. Is all this right? I have some doubts, I mostly doubt my intuition in analysis... Thank you!","I want to decide whether or not $f_n(x)=nx^n(1-x)$ is uniformly convergent or not. I have shown that $\lim_{n\to\infty} f_n(x)=0$ for $x \in [0,1]$. Now $f_n(0)=f_n(1)=0$. And in $(0,1)$, we have $f'_n(x)=n^2x^{n-1}-n(n+1)x^n$. Putting this to zero gives $x=\frac{n}{n+1}$. Also $f_n(\frac{n}{n+1})=(\frac{n}{n+1})^{n+1}$. But that tends to $\frac{1}{e}$ as $n$ tends to $\infty$ which is not $0$ so we don't have uniform convergence, right? Nonetheless we have $\lim_{n\to\infty} \int_0^1 f_n(x)dx=\lim_{n\to\infty} (\frac{n}{n+2}-\frac{n}{n+1})=0=\int_0^1 \lim_{n\to\infty} f_n(x)dx$. Is all this right? I have some doubts, I mostly doubt my intuition in analysis... Thank you!",,"['analysis', 'functional-analysis', 'uniform-convergence']"
58,The open sets in Banach space,The open sets in Banach space,,"Let $X$ and $Y$ be two Banach spaces. And we set $X\times Y=\{(x, y): x\in X$ and $ y\in Y\}$. If we take a open set $U$ in $X\times Y$, then does $U$ has the form $U_{X}\times U_{Y}$? Here $U_{X}$ and $U_{Y}$ are the open sets in $X$ and $Y$ respectively.","Let $X$ and $Y$ be two Banach spaces. And we set $X\times Y=\{(x, y): x\in X$ and $ y\in Y\}$. If we take a open set $U$ in $X\times Y$, then does $U$ has the form $U_{X}\times U_{Y}$? Here $U_{X}$ and $U_{Y}$ are the open sets in $X$ and $Y$ respectively.",,"['general-topology', 'functional-analysis']"
59,Find norm of operator,Find norm of operator,,"I have a linear functional $$A: L_2[0,2] \to \mathbb R, Ax = \int_0^2(t^2+2)x(t)dt$$ I need to find $C$, trying to measure $C$ and $||Ax||$ to find it, but how can I do it in this problem?","I have a linear functional $$A: L_2[0,2] \to \mathbb R, Ax = \int_0^2(t^2+2)x(t)dt$$ I need to find $C$, trying to measure $C$ and $||Ax||$ to find it, but how can I do it in this problem?",,"['functional-analysis', 'hilbert-spaces']"
60,"""Duality"" for weak $L^p$ spaces","""Duality"" for weak  spaces",L^p,"Let $1<p<\infty$. Denote by $L^{p,\infty}$ the weak $L^p$ space in $\mathbb{R}^n$ and let $f\in L^{p,\infty}$ where we define the weak $L^p$ quasinorm as $$\|f\|_{p,\infty} = \sup_{\lambda >0} \lambda\cdot m(\{ |f|>\lambda \})^{1/p}$$ where $m$ denotes the Lebesgue measure on $\mathbb{R}^n$. Question: Is it true that   $$\|f\|_{p,\infty}= \sup_{E} |E|^{-1/p^\prime} |\langle f,1_E\rangle|$$   where the supremum goes over all measurable sets $E$ of finite measure, $1_E$ denotes the characteristic function of $E$ and $\langle f,g\rangle=\int fg$ and $\frac{1}{p}+\frac{1}{p^\prime}=1$. I would already be very happy with ""$\le$"" and I also don't care if ""$\le$,$\ge$"" are maybe only true with additional multiplicative constants. To show ""$\le$"" I tried plugging in $E=\{|f|>\lambda\}$ for $\lambda>0$, but then I get $$|\langle f,1_E\rangle|=\left| \int_{\{|f|>\lambda\}} f \right|$$ The idea was to estimate this against $\lambda\cdot m(\{ |f|>\lambda\})$, but that doesn't work because the absolute value signs are outside instead of inside the integral. So I tried assuming that $f$ is positive, then its fine, but the application I have in mind needs $f$ complex-valued. Remark: The question is motivated by the fact that for (normal) $L^p$ spaces we have the duality statement $$\|f\|_p = \sup_{g\in L^{p^\prime}, g\not\equiv 0} \frac{|\langle f,g\rangle|}{\|g\|_{p^\prime}}$$","Let $1<p<\infty$. Denote by $L^{p,\infty}$ the weak $L^p$ space in $\mathbb{R}^n$ and let $f\in L^{p,\infty}$ where we define the weak $L^p$ quasinorm as $$\|f\|_{p,\infty} = \sup_{\lambda >0} \lambda\cdot m(\{ |f|>\lambda \})^{1/p}$$ where $m$ denotes the Lebesgue measure on $\mathbb{R}^n$. Question: Is it true that   $$\|f\|_{p,\infty}= \sup_{E} |E|^{-1/p^\prime} |\langle f,1_E\rangle|$$   where the supremum goes over all measurable sets $E$ of finite measure, $1_E$ denotes the characteristic function of $E$ and $\langle f,g\rangle=\int fg$ and $\frac{1}{p}+\frac{1}{p^\prime}=1$. I would already be very happy with ""$\le$"" and I also don't care if ""$\le$,$\ge$"" are maybe only true with additional multiplicative constants. To show ""$\le$"" I tried plugging in $E=\{|f|>\lambda\}$ for $\lambda>0$, but then I get $$|\langle f,1_E\rangle|=\left| \int_{\{|f|>\lambda\}} f \right|$$ The idea was to estimate this against $\lambda\cdot m(\{ |f|>\lambda\})$, but that doesn't work because the absolute value signs are outside instead of inside the integral. So I tried assuming that $f$ is positive, then its fine, but the application I have in mind needs $f$ complex-valued. Remark: The question is motivated by the fact that for (normal) $L^p$ spaces we have the duality statement $$\|f\|_p = \sup_{g\in L^{p^\prime}, g\not\equiv 0} \frac{|\langle f,g\rangle|}{\|g\|_{p^\prime}}$$",,"['real-analysis', 'functional-analysis', 'measure-theory']"
61,Range and kernel of linear operators,Range and kernel of linear operators,,"I have a compact linear operator $T$, and I would like to show $$\operatorname{range}(\lambda I-T)=(\ker(\overline{\lambda}I-T^*))^\perp.$$ I have shown the forward inclusion ""$\subset$"" directly by using the definition of adjoint. However, I'm having trouble with the reverse inclusion ""$\supset$""... it seems much harder to begin with the orthogonal complement with a kernel as well as to show that something is in a range. Any suggestions/hints would be appreciated. Thanks!","I have a compact linear operator $T$, and I would like to show $$\operatorname{range}(\lambda I-T)=(\ker(\overline{\lambda}I-T^*))^\perp.$$ I have shown the forward inclusion ""$\subset$"" directly by using the definition of adjoint. However, I'm having trouble with the reverse inclusion ""$\supset$""... it seems much harder to begin with the orthogonal complement with a kernel as well as to show that something is in a range. Any suggestions/hints would be appreciated. Thanks!",,"['functional-analysis', 'hilbert-spaces']"
62,Showing that a sequence converges in norm,Showing that a sequence converges in norm,,"I am trying to prove the following: Let $X$ be a normed linear space satisfying the property:  $\forall \left\{x_n\right\},  \left\{y_n\right\} \subseteq X $, we have  $\|x_n\|=\|y_n\|=1, \|x_n+y_n\|\rightarrow 2 \Rightarrow \|x_n-y_n\|\rightarrow 0.$ If $\left\{z_n\right\} \subseteq X$ converges to $z\in X$ weakly (meaning $\displaystyle \lim_{n\rightarrow \infty} f(z_n)=z$ for all $f\in X^*$) and $\|z_n\| \rightarrow \|z\|$, then $\|z_n-z\|\rightarrow 0$. Here is what I am trying to do: I can consider $\left\{z \right\}$ as a sequence in $X$. I want to show that $\|z_n+z\|\rightarrow 2$. Well, since $\|z_n\| \rightarrow \|z\|=1$, then since $\|z_n+z\|\leq\|z_n\|+\|z\|$, then $\displaystyle \lim_{n\rightarrow \infty} \|z_n+z\| \leq 2\|z\|=2$. I can't figure out how to possibly show that $\displaystyle \lim_{n\rightarrow \infty} \|z_n+z\| \geq 2$. How would I even incorporate the weak convergence assumption? Any help would be greatly appreciated! Thank you.","I am trying to prove the following: Let $X$ be a normed linear space satisfying the property:  $\forall \left\{x_n\right\},  \left\{y_n\right\} \subseteq X $, we have  $\|x_n\|=\|y_n\|=1, \|x_n+y_n\|\rightarrow 2 \Rightarrow \|x_n-y_n\|\rightarrow 0.$ If $\left\{z_n\right\} \subseteq X$ converges to $z\in X$ weakly (meaning $\displaystyle \lim_{n\rightarrow \infty} f(z_n)=z$ for all $f\in X^*$) and $\|z_n\| \rightarrow \|z\|$, then $\|z_n-z\|\rightarrow 0$. Here is what I am trying to do: I can consider $\left\{z \right\}$ as a sequence in $X$. I want to show that $\|z_n+z\|\rightarrow 2$. Well, since $\|z_n\| \rightarrow \|z\|=1$, then since $\|z_n+z\|\leq\|z_n\|+\|z\|$, then $\displaystyle \lim_{n\rightarrow \infty} \|z_n+z\| \leq 2\|z\|=2$. I can't figure out how to possibly show that $\displaystyle \lim_{n\rightarrow \infty} \|z_n+z\| \geq 2$. How would I even incorporate the weak convergence assumption? Any help would be greatly appreciated! Thank you.",,"['real-analysis', 'analysis', 'functional-analysis', 'normed-spaces']"
63,The difference between semicontinuity and hemicontinuity.,The difference between semicontinuity and hemicontinuity.,,"For a point-to-set function F, is ""upper hemicontinuous"" the same as ""upper semicontinuous""? If not, then what's the difference?","For a point-to-set function F, is ""upper hemicontinuous"" the same as ""upper semicontinuous""? If not, then what's the difference?",,"['general-topology', 'functional-analysis', 'functions', 'continuity']"
64,"Existence of Non-Trivial, Convex, Open Set in $C_{\mathbb{C}}[0,1]$ Under $L^{0}$ Metric","Existence of Non-Trivial, Convex, Open Set in  Under  Metric","C_{\mathbb{C}}[0,1] L^{0}","I've been struggling with this problem for the last four hours. The problem is to show that the space of $\mathbb{C}$-valued continuous functions on $[0,1]$ under the metric $d(f,g)=\int_{0}^{1}\frac{\vert f-g\vert}{1+\vert f-g\vert}dx$ has no non-trivial convex open sets. I refer to d as the $L^{0}$ metric since such a metric is often used on the space of random variables on a probability space. I've taken two thus far fruitless approaches. In the first approach, I assumed there existed such a non-trivial convex set U then  tried to show that any $f\in C_{\mathbb{C}}[0,1]$ can be expressed as convex combination of elements of U. Second thought was to use the fact that $C_{\mathbb{C}}[0,1]$ is a dense subspace of $L^{p}$, with $0<p<1$, under the $L^{0}$ metric. I wanted to show that since such a set does not exist in $L^{p}$ under this metric then it cannot exist in $C_{\mathbb{C}}[0,1]$. I was able to get as far as showing that these $L^{p}$-spaces have no non-trivial, convex, open sets under this metric.","I've been struggling with this problem for the last four hours. The problem is to show that the space of $\mathbb{C}$-valued continuous functions on $[0,1]$ under the metric $d(f,g)=\int_{0}^{1}\frac{\vert f-g\vert}{1+\vert f-g\vert}dx$ has no non-trivial convex open sets. I refer to d as the $L^{0}$ metric since such a metric is often used on the space of random variables on a probability space. I've taken two thus far fruitless approaches. In the first approach, I assumed there existed such a non-trivial convex set U then  tried to show that any $f\in C_{\mathbb{C}}[0,1]$ can be expressed as convex combination of elements of U. Second thought was to use the fact that $C_{\mathbb{C}}[0,1]$ is a dense subspace of $L^{p}$, with $0<p<1$, under the $L^{0}$ metric. I wanted to show that since such a set does not exist in $L^{p}$ under this metric then it cannot exist in $C_{\mathbb{C}}[0,1]$. I was able to get as far as showing that these $L^{p}$-spaces have no non-trivial, convex, open sets under this metric.",,"['functional-analysis', 'self-learning']"
65,"If composition with a linear functional is continuous, is the function continuous?","If composition with a linear functional is continuous, is the function continuous?",,"If $G$ is an open subset of $\mathbb{C}$ and $f:G \to X$ is a function such that for each $x^*$ in $X^*$, $x^*\circ f:G\to\mathbb{C}$ is analytic, then f is analytic. Will the statement still hold true if we replace both the instances of ""analytic"" with ""continuous""?","If $G$ is an open subset of $\mathbb{C}$ and $f:G \to X$ is a function such that for each $x^*$ in $X^*$, $x^*\circ f:G\to\mathbb{C}$ is analytic, then f is analytic. Will the statement still hold true if we replace both the instances of ""analytic"" with ""continuous""?",,"['functional-analysis', 'banach-algebras', 'analyticity']"
66,Squares of C*-algebras,Squares of C*-algebras,,"I'm reading a paper where it is claimed that every C*-algebra $A$ satisfies $A^2 = A$, ""for example, using Cohen's 1959 factorization theorem"". However, I don't see how to apply Cohen's factorization theorem to obtain this. Is there an easier proof that doesn't use Cohen's factorization theorem?","I'm reading a paper where it is claimed that every C*-algebra $A$ satisfies $A^2 = A$, ""for example, using Cohen's 1959 factorization theorem"". However, I don't see how to apply Cohen's factorization theorem to obtain this. Is there an easier proof that doesn't use Cohen's factorization theorem?",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
67,Can anyone give an example of two stably equivalent projections that are not Murray Von Neumann equivalent?,Can anyone give an example of two stably equivalent projections that are not Murray Von Neumann equivalent?,,"Two projections $P$, $Q$ are MvN equivalent in $C^*$-algebra $A$ when there is an element $u\in A$ such that $uu^*=P$ and $u^*u=Q$, and two projections $P$, $Q$ are stably equivalent if $P\oplus 1_n\overset{MvN}{\sim}Q\oplus1_n$, is there an example of two projections stably equivalent but not MvN equivalent?","Two projections $P$, $Q$ are MvN equivalent in $C^*$-algebra $A$ when there is an element $u\in A$ such that $uu^*=P$ and $u^*u=Q$, and two projections $P$, $Q$ are stably equivalent if $P\oplus 1_n\overset{MvN}{\sim}Q\oplus1_n$, is there an example of two projections stably equivalent but not MvN equivalent?",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras', 'k-theory']"
68,Is this differential form closed / exact?,Is this differential form closed / exact?,,"Could you check if I calculated the exterior derivative of this differential form $\omega$ correctly? $\omega \in \Omega_2 ^{\infty} (\mathbb{R}^3 \setminus \{0\})$ $\omega = (x^2 + y^2 + z^2)^{\frac{-3}{2}}(x \mbox{d}y \wedge \mbox{d}z + y \mbox{d}z \wedge \mbox{d}x + z \mbox{d}x \wedge \mbox{d}y)$ $\mbox{d} \omega = \mbox{d}( (x^2 + y^2 + z^2)^{\frac{-3}{2}}x (\mbox{d}y \wedge \mbox{d}z) + (x^2 + y^2 + z^2)^{\frac{-3}{2}}(y \mbox{d}z \wedge \mbox{d}x ) + (x^2 + y^2 + z^2)^{\frac{-3}{2}}( z \mbox{d}x \wedge \mbox{d}y))$ We differentiate the fist summand only by $x$, second only by $y$ and the third only by $z$, because in the other cases we get forms like $\mbox{d}x \wedge \mbox{d}x$, and due to the fact that exterior derivative is antisymmentric such forms are zero. So: $\mbox{d} \omega = \left( - \frac{3}{2} (x^2 + y^2 + z^2)^{\frac{-5}{2}} 2x \cdot x + (x^2 + y^2 + z^2)^{\frac{-3}{2}}\right) \wedge \mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z + \left( - \frac{3}{2} (x^2 + y^2 + z^2)^{\frac{-5}{2}} 2y \cdot y + (x^2 + y^2 + z^2)^{\frac{-3}{2}}\right) \wedge \mbox{d}y \wedge \mbox{d}z \wedge \mbox{d}x +  \left( - \frac{3}{2} (x^2 + y^2 + z^2)^{\frac{-5}{2}} 2z \cdot z + (x^2 + y^2 + z^2)^{\frac{-3}{2}}\right) \wedge  \mbox{d}z \wedge \mbox{d}x \wedge \mbox{d}y$ Because $\mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z = \mbox{d}y \wedge dz \wedge dx = \mbox{d}z \wedge \mbox{d}x \wedge \mbox{d}y$ (we need two transpositions), we have: $\mbox{d} \omega = \left( -3(x^2 + y^2 + z^2) ^{\frac{-5}{2}} (x^2 + y^2 + z^2) + (x^2 + y^2 + z^2) ^{\frac{-3}{2}} \right) \mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z$ But this isn't equal to zero. Are my calculations correct? I have one more question - how do determine if this form is exact? I know a differential form $\omega \in \Omega_n (U)$ is exact if there exists $\beta \in \Omega_{n+1} (U)$ s. t. $\omega = \mbox{d} \beta$. But I don't know how to guess such $\beta$. Could you help me? $\mbox{d} \omega = \left( -3(x^2 + y^2 + z^2) ^{\frac{-5}{2}} (x^2 + y^2 + z^2) + (x^2 + y^2 + z^2) ^{\frac{-3}{2}} \right) \mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z$ Thank you. EDIT: There is a mistake in my calculations: There should be $\mbox{d} \omega = \left( -3(x^2 + y^2 + z^2) ^{\frac{-5}{2}} (x^2 + y^2 + z^2) + 3(x^2 + y^2 + z^2) ^{\frac{-3}{2}} \right) \mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z$ and this is zero, so the form is closed.","Could you check if I calculated the exterior derivative of this differential form $\omega$ correctly? $\omega \in \Omega_2 ^{\infty} (\mathbb{R}^3 \setminus \{0\})$ $\omega = (x^2 + y^2 + z^2)^{\frac{-3}{2}}(x \mbox{d}y \wedge \mbox{d}z + y \mbox{d}z \wedge \mbox{d}x + z \mbox{d}x \wedge \mbox{d}y)$ $\mbox{d} \omega = \mbox{d}( (x^2 + y^2 + z^2)^{\frac{-3}{2}}x (\mbox{d}y \wedge \mbox{d}z) + (x^2 + y^2 + z^2)^{\frac{-3}{2}}(y \mbox{d}z \wedge \mbox{d}x ) + (x^2 + y^2 + z^2)^{\frac{-3}{2}}( z \mbox{d}x \wedge \mbox{d}y))$ We differentiate the fist summand only by $x$, second only by $y$ and the third only by $z$, because in the other cases we get forms like $\mbox{d}x \wedge \mbox{d}x$, and due to the fact that exterior derivative is antisymmentric such forms are zero. So: $\mbox{d} \omega = \left( - \frac{3}{2} (x^2 + y^2 + z^2)^{\frac{-5}{2}} 2x \cdot x + (x^2 + y^2 + z^2)^{\frac{-3}{2}}\right) \wedge \mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z + \left( - \frac{3}{2} (x^2 + y^2 + z^2)^{\frac{-5}{2}} 2y \cdot y + (x^2 + y^2 + z^2)^{\frac{-3}{2}}\right) \wedge \mbox{d}y \wedge \mbox{d}z \wedge \mbox{d}x +  \left( - \frac{3}{2} (x^2 + y^2 + z^2)^{\frac{-5}{2}} 2z \cdot z + (x^2 + y^2 + z^2)^{\frac{-3}{2}}\right) \wedge  \mbox{d}z \wedge \mbox{d}x \wedge \mbox{d}y$ Because $\mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z = \mbox{d}y \wedge dz \wedge dx = \mbox{d}z \wedge \mbox{d}x \wedge \mbox{d}y$ (we need two transpositions), we have: $\mbox{d} \omega = \left( -3(x^2 + y^2 + z^2) ^{\frac{-5}{2}} (x^2 + y^2 + z^2) + (x^2 + y^2 + z^2) ^{\frac{-3}{2}} \right) \mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z$ But this isn't equal to zero. Are my calculations correct? I have one more question - how do determine if this form is exact? I know a differential form $\omega \in \Omega_n (U)$ is exact if there exists $\beta \in \Omega_{n+1} (U)$ s. t. $\omega = \mbox{d} \beta$. But I don't know how to guess such $\beta$. Could you help me? $\mbox{d} \omega = \left( -3(x^2 + y^2 + z^2) ^{\frac{-5}{2}} (x^2 + y^2 + z^2) + (x^2 + y^2 + z^2) ^{\frac{-3}{2}} \right) \mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z$ Thank you. EDIT: There is a mistake in my calculations: There should be $\mbox{d} \omega = \left( -3(x^2 + y^2 + z^2) ^{\frac{-5}{2}} (x^2 + y^2 + z^2) + 3(x^2 + y^2 + z^2) ^{\frac{-3}{2}} \right) \mbox{d}x \wedge \mbox{d}y \wedge \mbox{d}z$ and this is zero, so the form is closed.",,"['functional-analysis', 'differential-forms']"
69,convergence of a series in the space of bounded linear operator,convergence of a series in the space of bounded linear operator,,"I need help in showing that: If $X$ is a Banach space and $T \in L(X,X)$ have $||T||<1$. Use the completeness of $L(X,X)$ to show that $\sum_{n=0}^{\infty}T^n$ converges in $L(X,X)$. where $L(X,X)$ is the space of bounded linear operators. thanx in advance.","I need help in showing that: If $X$ is a Banach space and $T \in L(X,X)$ have $||T||<1$. Use the completeness of $L(X,X)$ to show that $\sum_{n=0}^{\infty}T^n$ converges in $L(X,X)$. where $L(X,X)$ is the space of bounded linear operators. thanx in advance.",,['real-analysis']
70,A question on simple and unital $C^\star$-algebra,A question on simple and unital -algebra,C^\star,"There is a quotation of a book ""$C^\star$- algebras Finite-Dimensional Approximations "" Definition 1.7.4. A representation $\pi: A \rightarrow B(H)$ is called essential if $\pi(A)$ contains no nonzero compact operators. ($A$ is a $C^\star$-algebra.) My question is If $A$ is a simple and unital $C^\star$-algebra, then all the representations on $A$ will be faithful and essential?","There is a quotation of a book ""$C^\star$- algebras Finite-Dimensional Approximations "" Definition 1.7.4. A representation $\pi: A \rightarrow B(H)$ is called essential if $\pi(A)$ contains no nonzero compact operators. ($A$ is a $C^\star$-algebra.) My question is If $A$ is a simple and unital $C^\star$-algebra, then all the representations on $A$ will be faithful and essential?",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
71,"Is $L^2(0,T;H^{-1}(\Omega)) \subset \mathcal{D}^*((0,T)\times \Omega)$?",Is ?,"L^2(0,T;H^{-1}(\Omega)) \subset \mathcal{D}^*((0,T)\times \Omega)","Let $\Omega \subset \mathbb{R}^n$ be a domain. Consider the space of test functions $\mathcal{D}((0,T)\times \Omega)$ and the space of distributions $\mathcal{D}^*((0,T)\times \Omega).$ Is it true that $L^2(0,T;H^1(\Omega))^* = L^2(0,T;H^{-1}(\Omega))$ is a subset of $\mathcal{D}^*((0,T)\times \Omega)$? I've not been able to prove this. Given $f \in L^2(0,T;H^{-1}(\Omega))$, we have that $f \in \mathcal{D}^*((0,T)\times \Omega)$ if for $v_n \to v$ in $\mathcal{D}((0,T)\times \Omega)$, it holds that $f(v_n) \to f(v)$ in $\mathbb{R}$  (linearity is easy to check). How to show this? We know that $D^\alpha v_n \to D^\alpha v$ uniformly for all multiindices $\alpha$, but I can't get $L^p$ convergence from this. Help appreciated.","Let $\Omega \subset \mathbb{R}^n$ be a domain. Consider the space of test functions $\mathcal{D}((0,T)\times \Omega)$ and the space of distributions $\mathcal{D}^*((0,T)\times \Omega).$ Is it true that $L^2(0,T;H^1(\Omega))^* = L^2(0,T;H^{-1}(\Omega))$ is a subset of $\mathcal{D}^*((0,T)\times \Omega)$? I've not been able to prove this. Given $f \in L^2(0,T;H^{-1}(\Omega))$, we have that $f \in \mathcal{D}^*((0,T)\times \Omega)$ if for $v_n \to v$ in $\mathcal{D}((0,T)\times \Omega)$, it holds that $f(v_n) \to f(v)$ in $\mathbb{R}$  (linearity is easy to check). How to show this? We know that $D^\alpha v_n \to D^\alpha v$ uniformly for all multiindices $\alpha$, but I can't get $L^p$ convergence from this. Help appreciated.",,"['functional-analysis', 'sobolev-spaces', 'distribution-theory']"
72,Why the tempered distribution is zero?,Why the tempered distribution is zero?,,"My question is derived from the proof of the equation $\Delta f=f$ which has no nonzero solution in $\mathscr{S}'(\mathbb{R}^n)$. The ideal to solve this equation is to use the Fourier transform. By using Fourier transform, we have $-4\pi^2\left | \xi  \right |^2\mathscr{F}f(\xi)=\mathscr{F}f(\xi)$. Hence, the Fourier transform of $f$ must be zero at our first glance. However, I don't know the deep reason in tempered distribution sense. This question can be generalized as follows: Suppose $f\in \mathscr{S}'(\mathbb{R}^n)$ and $g\in \mathscr{O}^n_M$, where $$\mathscr{O}^n_M:=\left \{h(x)\in C^\infty(\mathbb{R}^n): \forall \alpha, \exists C(\alpha)>0, N(\alpha)\in\mathbb{N}\cup\{0\}, s.t.\quad |D^\alpha h(x)|\leq C(\alpha)(1+|x|^2)^{N(\alpha)}\right \} $$ is the multiplier of $\mathscr{S}'(\mathbb{R}^n)$. Then the product $``gf""$ is well defined by $<gf, \varphi>=<f, g\varphi>$, $\forall \varphi\in\mathscr{S}(\mathbb{R}^n)$. My question is: Fix a $g\in \mathscr{O}^n_M$ and $g\neq 0$, if every $\varphi\in\mathscr{S}(\mathbb{R}^n)$ we have $<gf, \varphi>=0$, then can we make a conclusion that $f=0$ in $\mathscr{S}'(\mathbb{R}^n)$ ?","My question is derived from the proof of the equation $\Delta f=f$ which has no nonzero solution in $\mathscr{S}'(\mathbb{R}^n)$. The ideal to solve this equation is to use the Fourier transform. By using Fourier transform, we have $-4\pi^2\left | \xi  \right |^2\mathscr{F}f(\xi)=\mathscr{F}f(\xi)$. Hence, the Fourier transform of $f$ must be zero at our first glance. However, I don't know the deep reason in tempered distribution sense. This question can be generalized as follows: Suppose $f\in \mathscr{S}'(\mathbb{R}^n)$ and $g\in \mathscr{O}^n_M$, where $$\mathscr{O}^n_M:=\left \{h(x)\in C^\infty(\mathbb{R}^n): \forall \alpha, \exists C(\alpha)>0, N(\alpha)\in\mathbb{N}\cup\{0\}, s.t.\quad |D^\alpha h(x)|\leq C(\alpha)(1+|x|^2)^{N(\alpha)}\right \} $$ is the multiplier of $\mathscr{S}'(\mathbb{R}^n)$. Then the product $``gf""$ is well defined by $<gf, \varphi>=<f, g\varphi>$, $\forall \varphi\in\mathscr{S}(\mathbb{R}^n)$. My question is: Fix a $g\in \mathscr{O}^n_M$ and $g\neq 0$, if every $\varphi\in\mathscr{S}(\mathbb{R}^n)$ we have $<gf, \varphi>=0$, then can we make a conclusion that $f=0$ in $\mathscr{S}'(\mathbb{R}^n)$ ?",,"['functional-analysis', 'distribution-theory', 'schwartz-space']"
73,Alternative definition of strong/weak operator topology.,Alternative definition of strong/weak operator topology.,,"Given two normed spaces $(X, ||\cdot||_X)$ and $(Y,||\cdot||_Y)$ the space of bounded linear maps $\mathcal{B}(X,Y)$ can be equipped with the strong operator topology (SOT) as follows: The initial topology with respect to [*] The topology induced by the family $S := \{s_x : x \in X\}$,   $$s_x : \begin{cases} &\mathcal{B}(X,Y) &\to &[0,\infty) \\ &T &\mapsto &||T(x)||_Y \end{cases} $$ (Definition taken from my lecture notes, but seem to coincide with Operator topologies - Wikipedia ) $S$ is a separating family of seminorms, so this yields a locally-convex topological vector space. In a similar fashion, we can define the weak operator topology (WOT) as The initial topology with respect to $W :=\{w_{x,y'} : x \in X, y' \in Y'\}$.   $$w_{x,y'} : \begin{cases} &\mathcal{B}(X,Y) &\to &\mathbb{C} \\ &T &\mapsto &y'(T(x)) \end{cases} $$   $Y'$ representing the topological dual space of $Y$. Now my questions are: Why do we have to go all the way to $[0,\infty)$ and $\mathbb{C}$, respectively?    Could these topologies be defined as the initial topologies with respect to the family   $P:= \{ p_x : x \in X\}$ of pointwise evaluation   $$p_x : \begin{cases} &\mathcal{B}(X,Y) &\to &(Y,\mathcal{T}) \\ &T &\mapsto &T(x) \end{cases} $$   only this time we equip $Y$ with either the norm topology $\mathcal{T} := \mathcal{T}_{||\cdot||_Y}$ or the weak topology $\mathcal{T} := \mathcal{T}_w$ instead? and also Wikipedia describes the weak-topology in a slightly different way, namely using extra absolute values   $$|W| :=\{|w_{x,y'}| : x \in X, y' \in Y'\}.$$   Are there any benefits in doing this? (I guess this has something to do with the connection of separating families of seminorms and point separating subspaces of the algebraic dual.) *Edit: As Daniel pointed out the ""topology induced by a family of seminorms"" is different from ""the initial topology with respect to the seminorms"".","Given two normed spaces $(X, ||\cdot||_X)$ and $(Y,||\cdot||_Y)$ the space of bounded linear maps $\mathcal{B}(X,Y)$ can be equipped with the strong operator topology (SOT) as follows: The initial topology with respect to [*] The topology induced by the family $S := \{s_x : x \in X\}$,   $$s_x : \begin{cases} &\mathcal{B}(X,Y) &\to &[0,\infty) \\ &T &\mapsto &||T(x)||_Y \end{cases} $$ (Definition taken from my lecture notes, but seem to coincide with Operator topologies - Wikipedia ) $S$ is a separating family of seminorms, so this yields a locally-convex topological vector space. In a similar fashion, we can define the weak operator topology (WOT) as The initial topology with respect to $W :=\{w_{x,y'} : x \in X, y' \in Y'\}$.   $$w_{x,y'} : \begin{cases} &\mathcal{B}(X,Y) &\to &\mathbb{C} \\ &T &\mapsto &y'(T(x)) \end{cases} $$   $Y'$ representing the topological dual space of $Y$. Now my questions are: Why do we have to go all the way to $[0,\infty)$ and $\mathbb{C}$, respectively?    Could these topologies be defined as the initial topologies with respect to the family   $P:= \{ p_x : x \in X\}$ of pointwise evaluation   $$p_x : \begin{cases} &\mathcal{B}(X,Y) &\to &(Y,\mathcal{T}) \\ &T &\mapsto &T(x) \end{cases} $$   only this time we equip $Y$ with either the norm topology $\mathcal{T} := \mathcal{T}_{||\cdot||_Y}$ or the weak topology $\mathcal{T} := \mathcal{T}_w$ instead? and also Wikipedia describes the weak-topology in a slightly different way, namely using extra absolute values   $$|W| :=\{|w_{x,y'}| : x \in X, y' \in Y'\}.$$   Are there any benefits in doing this? (I guess this has something to do with the connection of separating families of seminorms and point separating subspaces of the algebraic dual.) *Edit: As Daniel pointed out the ""topology induced by a family of seminorms"" is different from ""the initial topology with respect to the seminorms"".",,"['functional-analysis', 'operator-theory', 'definition']"
74,A closed ideal in a commutative Banach algebra $C(X)$,A closed ideal in a commutative Banach algebra,C(X),"Suppose that $A$ is a natural Banach function algebra on $K$, a compact Hausdorff space. So $A$ is realised as an algebra of continuous functions on $K$, is a Banach algebra for some norm (necessarily dominating the supremum norm) and each character on $A$ is given by evaluation at a point of $K$. If $F\subseteq K$ is closed, then how can we prove that $I(F)=\{f\in A\mid f(k)=0,\, k\in F\}$ is also closed?","Suppose that $A$ is a natural Banach function algebra on $K$, a compact Hausdorff space. So $A$ is realised as an algebra of continuous functions on $K$, is a Banach algebra for some norm (necessarily dominating the supremum norm) and each character on $A$ is given by evaluation at a point of $K$. If $F\subseteq K$ is closed, then how can we prove that $I(F)=\{f\in A\mid f(k)=0,\, k\in F\}$ is also closed?",,"['functional-analysis', 'banach-algebras']"
75,"Is the unit sphere in $(C[0,1], \| \cdot\|_1)$ compact?",Is the unit sphere in  compact?,"(C[0,1], \| \cdot\|_1)","Consider the normed space $(C[0,1], \| \cdot\|_1)$ where $C[0,1]=\{f:[0,1] \to \Bbb R : f$ is continuous$\}$ and $\|f\|_1 = \int_0^1|f(t)|dt$. I'm trying to find out if the unit sphere $S=\{f \in C[0,1] : \| f \|_1 = 1\}$ is compact or not. To prove it's not compact (I don't know if that's true or not) I was thinking of a sequence of functions $\{f_n\}$ whose graphs are triangles of base $1/n$ and height $2n$, and defined as zero elsewhere. So this triangles have constant area $1$, and then the functions have norm $1$. This sequence of functions converges pointwise to the function zero, and not uniformly. But now I'm struggling to prove that this sequence doesn't have a convergent subsequence in the metric induced by the norm (I was trying to prove that by proving that $\{f_n\}$ is not a Cauchy sequence). Maybe there's an easier counterexample, or maybe the sphere is compact, I don't know. I hope you can give me a counterexample so I can work on it or tell me if it's compact or not in order to know what I actually have to prove. Thanks.","Consider the normed space $(C[0,1], \| \cdot\|_1)$ where $C[0,1]=\{f:[0,1] \to \Bbb R : f$ is continuous$\}$ and $\|f\|_1 = \int_0^1|f(t)|dt$. I'm trying to find out if the unit sphere $S=\{f \in C[0,1] : \| f \|_1 = 1\}$ is compact or not. To prove it's not compact (I don't know if that's true or not) I was thinking of a sequence of functions $\{f_n\}$ whose graphs are triangles of base $1/n$ and height $2n$, and defined as zero elsewhere. So this triangles have constant area $1$, and then the functions have norm $1$. This sequence of functions converges pointwise to the function zero, and not uniformly. But now I'm struggling to prove that this sequence doesn't have a convergent subsequence in the metric induced by the norm (I was trying to prove that by proving that $\{f_n\}$ is not a Cauchy sequence). Maybe there's an easier counterexample, or maybe the sphere is compact, I don't know. I hope you can give me a counterexample so I can work on it or tell me if it's compact or not in order to know what I actually have to prove. Thanks.",,"['real-analysis', 'functional-analysis']"
76,Coercivity of bilinear form,Coercivity of bilinear form,,"I want to show that there is a unique solution for  $$-u''=f$$ with boundary condition $$-u'(0)+u(0)=u'(1)=0$$ so I define bilinear form $$a(v,w) = \int\limits_0^1 {v'} w'dx + v(0)w(0)$$ so I should show that this bilinear form is coercive. then I should show that $$a(v,v)\ge\alpha \|v\|^2_1$$","I want to show that there is a unique solution for  $$-u''=f$$ with boundary condition $$-u'(0)+u(0)=u'(1)=0$$ so I define bilinear form $$a(v,w) = \int\limits_0^1 {v'} w'dx + v(0)w(0)$$ so I should show that this bilinear form is coercive. then I should show that $$a(v,v)\ge\alpha \|v\|^2_1$$",,"['functional-analysis', 'partial-differential-equations', 'bilinear-form']"
77,Closed invariant subspace problem,Closed invariant subspace problem,,"Why does the invariant subspace problem only ask about closed invariant subpaces? I understand that if $W$ is an invariant subspace then the closure of $W$ is also invariant but if $W$ is dense in the space, the closure of $W$ is trivial.","Why does the invariant subspace problem only ask about closed invariant subpaces? I understand that if $W$ is an invariant subspace then the closure of $W$ is also invariant but if $W$ is dense in the space, the closure of $W$ is trivial.",,['linear-algebra']
78,Is the span of rationally independent real numbers dense in $\mathbb{R}$,Is the span of rationally independent real numbers dense in,\mathbb{R},"Define the subset $S\subset\mathbb{R}$ to be equal to $\{a_1\mathbb{Z} + a_2\mathbb{Z} +\cdots+ a_n\mathbb{Z} \}$, where $a_1,a_2\cdots,a_n\in\mathbb{R}$ are rationally independent and $2\leq n<\infty$ is an arbitrary index. Is $S$ dense in $\mathbb{R}$?","Define the subset $S\subset\mathbb{R}$ to be equal to $\{a_1\mathbb{Z} + a_2\mathbb{Z} +\cdots+ a_n\mathbb{Z} \}$, where $a_1,a_2\cdots,a_n\in\mathbb{R}$ are rationally independent and $2\leq n<\infty$ is an arbitrary index. Is $S$ dense in $\mathbb{R}$?",,"['real-analysis', 'functional-analysis']"
79,Why the image of a linear map is not always a Banach space?,Why the image of a linear map is not always a Banach space?,,I have a question: Let's think about the map $T:V \rightarrow \text{ran}(T)$ and $V$ be a Banach space. Then we have that this is the same as the quotient map $[T]:V \rightarrow V/\ker(T)$ where the latter space is also a Banach space and an isomorphism $\hat{T}:V/\ker(T) \rightarrow \text{ran}(T)$. This one is injective as we factored out the nullspace and surjective by definition of the image. But this would suggest that the image is always a Banach space? So where am I wrong?,I have a question: Let's think about the map $T:V \rightarrow \text{ran}(T)$ and $V$ be a Banach space. Then we have that this is the same as the quotient map $[T]:V \rightarrow V/\ker(T)$ where the latter space is also a Banach space and an isomorphism $\hat{T}:V/\ker(T) \rightarrow \text{ran}(T)$. This one is injective as we factored out the nullspace and surjective by definition of the image. But this would suggest that the image is always a Banach space? So where am I wrong?,,"['calculus', 'real-analysis']"
80,Closed range assumption in definition of Fredholm operators,Closed range assumption in definition of Fredholm operators,,"There are two definitions of Fredholm operators (on a Hilbert space) that are commonly used. The first is that $\dim\ker T<\infty$ and $\dim\,\mathrm{coker} T<\infty$. An argument using the open mapping theorem then shows that the range of $T$ is closed. The other definition is that $\dim\ker T<\infty$, $\dim\ker T^{*}<\infty$ and the range of $T$ is closed. I am trying to find an example where $T\in B(H)$ satisfies $\dim\ker T<\infty$ and $\dim\ker T^{*}<\infty$ but does not have closed range. I considered the following: $H=\ell^{2}(\mathbb{N})$ and $T$ is defined on basis elements $e_{n}$ by $Te_{n}=\frac{1}{n}e_{n}$. It seems to me that $T$ is injective, self-adjoint, and its range is not closed because the sequence $T(1,0,0,0,\ldots), T(1,1,0,0,\ldots), T(1,1,1,0,\ldots)$ converges in $H$ to $(1,\frac{1}{2},\frac{1}{3},\ldots)$, which is not in the range of $T$. I hope someone can check the example, or perhaps give a simpler example (or a correct one in the event that mine is wrong).","There are two definitions of Fredholm operators (on a Hilbert space) that are commonly used. The first is that $\dim\ker T<\infty$ and $\dim\,\mathrm{coker} T<\infty$. An argument using the open mapping theorem then shows that the range of $T$ is closed. The other definition is that $\dim\ker T<\infty$, $\dim\ker T^{*}<\infty$ and the range of $T$ is closed. I am trying to find an example where $T\in B(H)$ satisfies $\dim\ker T<\infty$ and $\dim\ker T^{*}<\infty$ but does not have closed range. I considered the following: $H=\ell^{2}(\mathbb{N})$ and $T$ is defined on basis elements $e_{n}$ by $Te_{n}=\frac{1}{n}e_{n}$. It seems to me that $T$ is injective, self-adjoint, and its range is not closed because the sequence $T(1,0,0,0,\ldots), T(1,1,0,0,\ldots), T(1,1,1,0,\ldots)$ converges in $H$ to $(1,\frac{1}{2},\frac{1}{3},\ldots)$, which is not in the range of $T$. I hope someone can check the example, or perhaps give a simpler example (or a correct one in the event that mine is wrong).",,"['functional-analysis', 'operator-theory']"
81,closed strong vs. closed in weak convergence,closed strong vs. closed in weak convergence,,Studying a chapter about weak topologies and weak convergence I though the following which I have no idea how to prove or disprove it. So here it is: Question: Does there exist  Banach space $X$ and a closed subset $F  \subset X$ such that $F$ is not closed with respect to weak   convergence? Any ideas?,Studying a chapter about weak topologies and weak convergence I though the following which I have no idea how to prove or disprove it. So here it is: Question: Does there exist  Banach space $X$ and a closed subset $F  \subset X$ such that $F$ is not closed with respect to weak   convergence? Any ideas?,,"['real-analysis', 'functional-analysis', 'weak-convergence']"
82,$x_n$ convergence to $x$ implies $f_n(x_n)$ convergence to $f(x)$. prove that $f$ is continuous,convergence to  implies  convergence to . prove that  is continuous,x_n x f_n(x_n) f(x) f,"Let $f$ and $f_n$ be functions from $\mathbb{R} \rightarrow \mathbb{R}$ Assume that $f_n (x_n) \rightarrow f (x)$ as $n\rightarrow \infty$ whenever $x_n \rightarrow x$. Prove that $f$ is   continuous. (Note: the functions $f_n$ are not assumed to be   continuous.) Here is my approach to prove it : Suppose $(x_n)\rightarrow x$. We want to prove $f(x_n)\rightarrow f(x)$ And perhaps we may write : $|f(x_n)- f(x)|\leq|f(x_n)- f_n(x_n)|+|f_n(x_n)-f(x)|$ We can control the second term in RHS, but I don't think there's a way to control the first absolute value. Another intuitive approach is working with diameter of the matrix of $f_n$ values.","Let $f$ and $f_n$ be functions from $\mathbb{R} \rightarrow \mathbb{R}$ Assume that $f_n (x_n) \rightarrow f (x)$ as $n\rightarrow \infty$ whenever $x_n \rightarrow x$. Prove that $f$ is   continuous. (Note: the functions $f_n$ are not assumed to be   continuous.) Here is my approach to prove it : Suppose $(x_n)\rightarrow x$. We want to prove $f(x_n)\rightarrow f(x)$ And perhaps we may write : $|f(x_n)- f(x)|\leq|f(x_n)- f_n(x_n)|+|f_n(x_n)-f(x)|$ We can control the second term in RHS, but I don't think there's a way to control the first absolute value. Another intuitive approach is working with diameter of the matrix of $f_n$ values.",,"['sequences-and-series', 'functional-analysis', 'convergence-divergence', 'continuity']"
83,Conjugate convex functions property,Conjugate convex functions property,,$E$ is normed vector space.Let $f\in E^*$ in a bounded linear functional from $E$ to $C$ and fix $x\in E$. We have $$\forall y\in E;\ \ \ \    f(y-x)\leq \frac{1}{2}\|y\|^2-\frac{1}{2}\|x\|^2$$  And I have proven $f(x)=\|x\|^2$ and $\|x\|\leq \|f\|$. Prove that $\|f\|=\|x\|$.,$E$ is normed vector space.Let $f\in E^*$ in a bounded linear functional from $E$ to $C$ and fix $x\in E$. We have $$\forall y\in E;\ \ \ \    f(y-x)\leq \frac{1}{2}\|y\|^2-\frac{1}{2}\|x\|^2$$  And I have proven $f(x)=\|x\|^2$ and $\|x\|\leq \|f\|$. Prove that $\|f\|=\|x\|$.,,"['real-analysis', 'analysis', 'functional-analysis', 'operator-theory', 'convex-analysis']"
84,Prove that $d_{1}$ and $d_{2}$ induce the same topology,Prove that  and  induce the same topology,d_{1} d_{2},"Suppose $d_{1}(x,y) = |x-y|$, $d_{2}(x, y) = |\phi(x) - \phi(y)|$, where $\phi(x) = \frac{x}{1 + |x|}$. Prove that $d_{1}$ and $d_{2}$ are metrics on $\mathbb{R}$ which induce the same topology. It's easy to prove that $d_{1}$ and $d_{2}$ are metrics. Call the topologies induced by them $\tau_{1}$ and $\tau_{2}$. I can prove that $\tau_{1}$ is finer than $\tau_{2}$, but I can't prove the inverse. Can any body please help me. Thanks","Suppose $d_{1}(x,y) = |x-y|$, $d_{2}(x, y) = |\phi(x) - \phi(y)|$, where $\phi(x) = \frac{x}{1 + |x|}$. Prove that $d_{1}$ and $d_{2}$ are metrics on $\mathbb{R}$ which induce the same topology. It's easy to prove that $d_{1}$ and $d_{2}$ are metrics. Call the topologies induced by them $\tau_{1}$ and $\tau_{2}$. I can prove that $\tau_{1}$ is finer than $\tau_{2}$, but I can't prove the inverse. Can any body please help me. Thanks",,"['general-topology', 'functional-analysis', 'metric-spaces', 'normed-spaces']"
85,Triangle inequality in product space of normed spaces,Triangle inequality in product space of normed spaces,,"Let $(X,\|\cdot\|_X)$ and $(Y,\|\cdot\|_Y)$ be normed spaces, then $\|(x,y)\|:=(\|x\|_X^p+\|y\|_Y^p)^{\frac{1}{p}}$ is a norm on $X \times Y$ . This is absolutely clear to me, but I have troubles to verify the triangle inequality for this norm. Does anybody know how to do this or have a good hint?","Let and be normed spaces, then is a norm on . This is absolutely clear to me, but I have troubles to verify the triangle inequality for this norm. Does anybody know how to do this or have a good hint?","(X,\|\cdot\|_X) (Y,\|\cdot\|_Y) \|(x,y)\|:=(\|x\|_X^p+\|y\|_Y^p)^{\frac{1}{p}} X \times Y","['real-analysis', 'linear-algebra']"
86,compute the spectrum of an operator,compute the spectrum of an operator,,Let $C_{0}(\mathbb R)$ be the space of complex continuous valued functions on $\mathbb R$ which vanish at $\infty$ equipped with the sup-norm. Let $S:C_{0}(\mathbb R) \to C_{0}(\mathbb R)$ given by $(Sf)(t)=f(t+s)$ for a fixed $s\in \mathbb R$.   Prove that the spectrum of $\sigma(S)$ is given by the set $\sigma(S)=\{z\in \mathbb C ; ||z||=1\}$. I proved that if $|\lambda|\ne 1$ then $\lambda \in p(T)$. I want to prove that if $|\lambda|=1$ then $\lambda \in \sigma(T)$ Since if $|\lambda|=1$ I proved that $\lambda I-T$ it's injective. It remains to prove that $\lambda I-T$ it's not surjective. Thanks for the tips! But it remains to prove that if $||z||=1$ then $z\in \sigma(T)$. And I don't know how,Let $C_{0}(\mathbb R)$ be the space of complex continuous valued functions on $\mathbb R$ which vanish at $\infty$ equipped with the sup-norm. Let $S:C_{0}(\mathbb R) \to C_{0}(\mathbb R)$ given by $(Sf)(t)=f(t+s)$ for a fixed $s\in \mathbb R$.   Prove that the spectrum of $\sigma(S)$ is given by the set $\sigma(S)=\{z\in \mathbb C ; ||z||=1\}$. I proved that if $|\lambda|\ne 1$ then $\lambda \in p(T)$. I want to prove that if $|\lambda|=1$ then $\lambda \in \sigma(T)$ Since if $|\lambda|=1$ I proved that $\lambda I-T$ it's injective. It remains to prove that $\lambda I-T$ it's not surjective. Thanks for the tips! But it remains to prove that if $||z||=1$ then $z\in \sigma(T)$. And I don't know how,,"['functional-analysis', 'banach-spaces']"
87,Reflexivity of a Banach space without the James map,Reflexivity of a Banach space without the James map,,"The reflexivity of a Banach space is usually defined as having to be enforced by a particular isometric isomorphism.  Namely the map that takes each element to the evaluation, which is already an injective linear isometry from a Banach space to its double dual.  It just isn't necessarily surjective. Are there examples of when a space is isometrically isomorphic to its double dual, but is not reflexive?  If $X$ is reflexive, is the same true of the $k^{th}$ dual of $X$? (Or maybe this property moves backwards instead?  As in maybe if the dual is reflexive then so is the original.  Separability does this too, but I'm not sure how to intuit when a property should pushforward and when it should pull back under the operation of taking a dual.)  Does being reflexive, or at least isometrically isomorphic to its double dual capture any information about the ""size"" of the space or any other intuitive concepts that are easy to picture?","The reflexivity of a Banach space is usually defined as having to be enforced by a particular isometric isomorphism.  Namely the map that takes each element to the evaluation, which is already an injective linear isometry from a Banach space to its double dual.  It just isn't necessarily surjective. Are there examples of when a space is isometrically isomorphic to its double dual, but is not reflexive?  If $X$ is reflexive, is the same true of the $k^{th}$ dual of $X$? (Or maybe this property moves backwards instead?  As in maybe if the dual is reflexive then so is the original.  Separability does this too, but I'm not sure how to intuit when a property should pushforward and when it should pull back under the operation of taking a dual.)  Does being reflexive, or at least isometrically isomorphic to its double dual capture any information about the ""size"" of the space or any other intuitive concepts that are easy to picture?",,"['analysis', 'functional-analysis', 'banach-spaces']"
88,"How to prove that $P^n(x,\cdot)\stackrel{w}{\rightarrow} \pi$ for all $x$, implies the equicontinuity of $\{P^n f\}_n$ on compact sets?","How to prove that  for all , implies the equicontinuity of  on compact sets?","P^n(x,\cdot)\stackrel{w}{\rightarrow} \pi x \{P^n f\}_n","Let $X$ be a separable and locally compact metric space and let $P\colon X\times \mathcal{B}(X) \rightarrow \mathbb{R}$ be the transition probabability kernel of a homogeneus Markov chain on $X$. Define $$Pf(x)=\int_{X} f(y)\,P(x,dy)\;\;\; (f\in C(X), x\in X),$$ where $C(X)$ is the space of bounded continuous functions $f:X\rightarrow \mathbb{R}$. We say that $P$ has the Feller property if $Pf \in C(X)$ for all $f\in C(X)$. My question is: how to prove the following theorem (Proposition 6.4.2, Meyn and Tweedie, Markov chains and stochastic stability : http://probability.ca/MT/Chap6.pdf ): Assume that $P$ has the Feller property, and that there exists a unique probility measure $\pi$ on $\mathcal{B}(X)$ such that for every $x\in X$: $$P^n(x,\cdot)\stackrel{w}{\rightarrow} \pi\;\;\;(n\to\infty).$$   Then the family $\{P^n f: n\in\mathbb{N}\}$ is equicontinuous on compact subsets of $X$ whenever $f\in C(X)$ ($\stackrel{w}{\rightarrow}$ denotes the weak convergence). The authors claim that it follows directly from Ascoli's Theorem. However I can not see this. In order to be able to apply Ascoli's theorem we need to know that for each compact set $C$ at least some subseqence $(P^{k_n} f)_{n}$ is uniformly convergent on $C$. Since $C$ is compact we may choose $x_n \in C$ such that $$|P^n f(x_n)-\pi(f)|=\max_{x\in C} |P^n f(x)-\pi(f)| \;\;\;(n\in\mathbb{N}),$$ where $\pi(f)=\int_X f(y)\,\pi(dy)$. So it suffices to show that there exists a strictly increasing sequence $(k_n)_{n\in\mathbb{N}}$ of natural numbers such that $$P^{k_n}f(x_{k_n})\to \pi(f)$$ but I have a problem in this place. I would be grateful for any ideas.","Let $X$ be a separable and locally compact metric space and let $P\colon X\times \mathcal{B}(X) \rightarrow \mathbb{R}$ be the transition probabability kernel of a homogeneus Markov chain on $X$. Define $$Pf(x)=\int_{X} f(y)\,P(x,dy)\;\;\; (f\in C(X), x\in X),$$ where $C(X)$ is the space of bounded continuous functions $f:X\rightarrow \mathbb{R}$. We say that $P$ has the Feller property if $Pf \in C(X)$ for all $f\in C(X)$. My question is: how to prove the following theorem (Proposition 6.4.2, Meyn and Tweedie, Markov chains and stochastic stability : http://probability.ca/MT/Chap6.pdf ): Assume that $P$ has the Feller property, and that there exists a unique probility measure $\pi$ on $\mathcal{B}(X)$ such that for every $x\in X$: $$P^n(x,\cdot)\stackrel{w}{\rightarrow} \pi\;\;\;(n\to\infty).$$   Then the family $\{P^n f: n\in\mathbb{N}\}$ is equicontinuous on compact subsets of $X$ whenever $f\in C(X)$ ($\stackrel{w}{\rightarrow}$ denotes the weak convergence). The authors claim that it follows directly from Ascoli's Theorem. However I can not see this. In order to be able to apply Ascoli's theorem we need to know that for each compact set $C$ at least some subseqence $(P^{k_n} f)_{n}$ is uniformly convergent on $C$. Since $C$ is compact we may choose $x_n \in C$ such that $$|P^n f(x_n)-\pi(f)|=\max_{x\in C} |P^n f(x)-\pi(f)| \;\;\;(n\in\mathbb{N}),$$ where $\pi(f)=\int_X f(y)\,\pi(dy)$. So it suffices to show that there exists a strictly increasing sequence $(k_n)_{n\in\mathbb{N}}$ of natural numbers such that $$P^{k_n}f(x_{k_n})\to \pi(f)$$ but I have a problem in this place. I would be grateful for any ideas.",,"['functional-analysis', 'probability-theory', 'convergence-divergence']"
89,exercise on the closed subspaces of an Hilbert spaces,exercise on the closed subspaces of an Hilbert spaces,,"I have a question regarding exercise 3.1.13 of ""Analysis Now"" by Pedersen volume 118 of the Springer GTM. The exercise aim to show that any closed subspace $X$ of  $L^2([0,1])\cap L^{\infty}([0,1])]$ is finite dimensional. I'd like to get whatever proof of this fact, however in the book there is a hint which is the following: There is a constant $\alpha$ such that $|| f||_\infty\leq \alpha\cdot ||f||_2$ for all $f\in X$. If $\{f_1,\dots,f_n\}\subset X$ is a family orthonormal vectors, there is a null set $N$ such that $ |f(t)|\leq\alpha\cdot ||f||_2  $ for all $t\in [0,1]\setminus N$ and $f$ in the linear span of  $\{f_1,\dots,f_n\}$. For all $t\in [0,1]\setminus N$ $ \Sigma_{k=1\dots n} |f_k(t)|^2\leq\alpha^2. $ Conclude that there cannot be a family of orthonormal vectors in $X$ of size larger than than $\alpha^2$. All items except item 3 are clear to me, however I cannot really understand what is the reason why from item 2 one can get item 3.","I have a question regarding exercise 3.1.13 of ""Analysis Now"" by Pedersen volume 118 of the Springer GTM. The exercise aim to show that any closed subspace $X$ of  $L^2([0,1])\cap L^{\infty}([0,1])]$ is finite dimensional. I'd like to get whatever proof of this fact, however in the book there is a hint which is the following: There is a constant $\alpha$ such that $|| f||_\infty\leq \alpha\cdot ||f||_2$ for all $f\in X$. If $\{f_1,\dots,f_n\}\subset X$ is a family orthonormal vectors, there is a null set $N$ such that $ |f(t)|\leq\alpha\cdot ||f||_2  $ for all $t\in [0,1]\setminus N$ and $f$ in the linear span of  $\{f_1,\dots,f_n\}$. For all $t\in [0,1]\setminus N$ $ \Sigma_{k=1\dots n} |f_k(t)|^2\leq\alpha^2. $ Conclude that there cannot be a family of orthonormal vectors in $X$ of size larger than than $\alpha^2$. All items except item 3 are clear to me, however I cannot really understand what is the reason why from item 2 one can get item 3.",,"['functional-analysis', 'hilbert-spaces']"
90,A question on multiplicative linear functional on Banach algebra.,A question on multiplicative linear functional on Banach algebra.,,"I am reading a book about C*-algebra. But i am confused with some of its content. It says Assume $A$ is a non-unital C*-algebra and $\tilde{A}$ is its unitization (the elements of the form $a+\lambda$). If $\phi: A\rightarrow \mathbb{C}$, is a nonzero homomorphism($\mathbb{C}$ denotes complex field), then $\tilde{\phi}(a+\lambda)=\phi(a)+\lambda~(a\in A$ and $\lambda\in \mathbb{C})$. Let $P(A)$ and $P(\tilde{A})$ denote the nonzero multiplicative linear functional on A and $\tilde{A}$, respectively. Thus, $P(A)$ is a subset of $P(\tilde{A})$. In fact, $P(A)=P(\tilde{A})\cup\{\pi\}$ , where $\pi$ is determined by $\tilde{A}/A=\mathbb{C}$, i.e., $\ker\pi=A$. Since $P(\tilde{A})$ is compact Hausdorff space, we conclude that $P(A)$ is a locally compact Hausdorff space. My question are Does the ""="" in the equation $P(A)=P(\tilde{A})\cup\{\pi\}$ is under the meaning of isomorphism? Is it topological isomorphism? Why? Why does the $P(\tilde{A})$ is compact Hausdorff space implies that $P(A)$ is a locally compact Hausdorff space?","I am reading a book about C*-algebra. But i am confused with some of its content. It says Assume $A$ is a non-unital C*-algebra and $\tilde{A}$ is its unitization (the elements of the form $a+\lambda$). If $\phi: A\rightarrow \mathbb{C}$, is a nonzero homomorphism($\mathbb{C}$ denotes complex field), then $\tilde{\phi}(a+\lambda)=\phi(a)+\lambda~(a\in A$ and $\lambda\in \mathbb{C})$. Let $P(A)$ and $P(\tilde{A})$ denote the nonzero multiplicative linear functional on A and $\tilde{A}$, respectively. Thus, $P(A)$ is a subset of $P(\tilde{A})$. In fact, $P(A)=P(\tilde{A})\cup\{\pi\}$ , where $\pi$ is determined by $\tilde{A}/A=\mathbb{C}$, i.e., $\ker\pi=A$. Since $P(\tilde{A})$ is compact Hausdorff space, we conclude that $P(A)$ is a locally compact Hausdorff space. My question are Does the ""="" in the equation $P(A)=P(\tilde{A})\cup\{\pi\}$ is under the meaning of isomorphism? Is it topological isomorphism? Why? Why does the $P(\tilde{A})$ is compact Hausdorff space implies that $P(A)$ is a locally compact Hausdorff space?",,"['functional-analysis', 'operator-algebras', 'banach-algebras', 'c-star-algebras']"
91,Measure spaces are proper subsets,Measure spaces are proper subsets,,"I want to prove that $L^2$ is of the first category in $L^1$, thus I have to prove that $L^2$ is the countable union of nowhere dense subsets. The hint I get is: Take $g_n(x)=n$ for $0\leq x\leq\frac{1}{n^3}$ and show $\int{fg_n}\rightarrow 0$ for all $f\in L^2$ but not for every $f\in L^1$. My question: What does this hint help for proving that $L^2$ is of the first category? I don't know how to use this hint. Can someone help me? :) Thanks","I want to prove that $L^2$ is of the first category in $L^1$, thus I have to prove that $L^2$ is the countable union of nowhere dense subsets. The hint I get is: Take $g_n(x)=n$ for $0\leq x\leq\frac{1}{n^3}$ and show $\int{fg_n}\rightarrow 0$ for all $f\in L^2$ but not for every $f\in L^1$. My question: What does this hint help for proving that $L^2$ is of the first category? I don't know how to use this hint. Can someone help me? :) Thanks",,"['functional-analysis', 'measure-theory', 'lp-spaces', 'baire-category']"
92,Support of Convolution and Smoothing,Support of Convolution and Smoothing,,"I just want to know how it follows that $v^{\epsilon} \in C^{\infty}(\bar{V})$? I could see how $v^{\epsilon} \in C^{\infty}(V)$ by using the translations, but I'm having difficulty seeing how it extends to $\bar{V}$, since it says that $u_{\epsilon}(x) := u(x^{\epsilon}) \text{ for } x \text{ in } V$, we are mollifying on $V$. I also don't think we can use the same type of extension as in the previous question I asked, since previously we extended a function that had already become zero to zero on the rest of the domain. Do you have any idea of how this follows? Thanks for the assistance.","I just want to know how it follows that $v^{\epsilon} \in C^{\infty}(\bar{V})$? I could see how $v^{\epsilon} \in C^{\infty}(V)$ by using the translations, but I'm having difficulty seeing how it extends to $\bar{V}$, since it says that $u_{\epsilon}(x) := u(x^{\epsilon}) \text{ for } x \text{ in } V$, we are mollifying on $V$. I also don't think we can use the same type of extension as in the previous question I asked, since previously we extended a function that had already become zero to zero on the rest of the domain. Do you have any idea of how this follows? Thanks for the assistance.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'convolution', 'regularization']"
93,Show that $\max_i\left\{|v_i| + |w_i|\right\} \leq \max_i\left\{|v_i|\right\} + \max_i\left\{|w_i|\right\}$.,Show that .,\max_i\left\{|v_i| + |w_i|\right\} \leq \max_i\left\{|v_i|\right\} + \max_i\left\{|w_i|\right\},"While trying to prove that the $\infty$-norm of a vector in $\mathbb{R}^n$ does satisfy the properties of being a norm, I inevitably came across the following inequality: $\max_i\left\{|v_i| + |w_i|\right\} \leq \max_i\left\{|v_i|\right\} + \max_i\left\{|w_i|\right\}$. I deduced from examples that the equality holds if and only if the indices of the largest elements of both vectors $\vec{v}$ and $\vec{w}$ are the same. But I do not know how to provide a general proof for the inequality without resorting to proof by example or case by case analysis. Could anyone shed some light?","While trying to prove that the $\infty$-norm of a vector in $\mathbb{R}^n$ does satisfy the properties of being a norm, I inevitably came across the following inequality: $\max_i\left\{|v_i| + |w_i|\right\} \leq \max_i\left\{|v_i|\right\} + \max_i\left\{|w_i|\right\}$. I deduced from examples that the equality holds if and only if the indices of the largest elements of both vectors $\vec{v}$ and $\vec{w}$ are the same. But I do not know how to provide a general proof for the inequality without resorting to proof by example or case by case analysis. Could anyone shed some light?",,"['linear-algebra', 'functional-analysis']"
94,Extending integrals from continuous functions to bounded Borel functions,Extending integrals from continuous functions to bounded Borel functions,,"Let $X$ be a compact, Hausdorff space. Let $B(X)$ be the Banach space of bounded, Borel-measurable, complex-valued functions on $X$ under the uniform norm. Let $C(X) \subset B(X)$ be the closed subspace of continuous, complex-valued functions. By the Riesz representation theorem, we have an isomorphism $M(X) \cong C(X)^*$ where $M(X)$ denotes the (finite) regular, complex Borel measures on $X$ under the total variation norm. The isomorphism sends $\mu \in M(X)$ to integration against $\mu$. By the Hahn-Banach theorem, the element of $C(X)^*$ corresponding to $\mu \in M(X)$ extends to an element of $B(X)^*$ with the same norm. In fact, since the functions in $B(X)$ can also be integrated against $\mu$, we have a rather canonical choice of extension. It is not difficult to see that $f \mapsto \int_X f \ d\mu$ is in $B(X)^*$ and has the same norm as its restriction to $C(X)$. Question: Is it true that every functional in $C(X)^*$ has a unique norm-preserving extension to $B(X)^*$ (given by integration against the corresponding measure)? Or, if not, what sort of functional analysis-type statements can be made in order to single out this extension which is obviously the preferred one from a measure theory standpoint?","Let $X$ be a compact, Hausdorff space. Let $B(X)$ be the Banach space of bounded, Borel-measurable, complex-valued functions on $X$ under the uniform norm. Let $C(X) \subset B(X)$ be the closed subspace of continuous, complex-valued functions. By the Riesz representation theorem, we have an isomorphism $M(X) \cong C(X)^*$ where $M(X)$ denotes the (finite) regular, complex Borel measures on $X$ under the total variation norm. The isomorphism sends $\mu \in M(X)$ to integration against $\mu$. By the Hahn-Banach theorem, the element of $C(X)^*$ corresponding to $\mu \in M(X)$ extends to an element of $B(X)^*$ with the same norm. In fact, since the functions in $B(X)$ can also be integrated against $\mu$, we have a rather canonical choice of extension. It is not difficult to see that $f \mapsto \int_X f \ d\mu$ is in $B(X)^*$ and has the same norm as its restriction to $C(X)$. Question: Is it true that every functional in $C(X)^*$ has a unique norm-preserving extension to $B(X)^*$ (given by integration against the corresponding measure)? Or, if not, what sort of functional analysis-type statements can be made in order to single out this extension which is obviously the preferred one from a measure theory standpoint?",,"['functional-analysis', 'measure-theory']"
95,Riesz representation theorem for bilinear forms,Riesz representation theorem for bilinear forms,,"Let $b:H \times H \to \mathbb{R}$ be a bounded bilinear form on Hilbert space $H$. Fix $u \in H$. Then $b(u, \cdot):H \to \mathbb{R}$ is bounded so $b(u,\cdot) \in H^*.$ Then $b(u,\cdot) = F_u(\cdot)$ where $F_u \in H^*$. Right? Isn't this a kind of Riesz representation theorem without coercivity?","Let $b:H \times H \to \mathbb{R}$ be a bounded bilinear form on Hilbert space $H$. Fix $u \in H$. Then $b(u, \cdot):H \to \mathbb{R}$ is bounded so $b(u,\cdot) \in H^*.$ Then $b(u,\cdot) = F_u(\cdot)$ where $F_u \in H^*$. Right? Isn't this a kind of Riesz representation theorem without coercivity?",,"['functional-analysis', 'hilbert-spaces', 'riesz-representation-theorem']"
96,Dense subset of a dual space norming?,Dense subset of a dual space norming?,,"I'm wondering if a dense subset of the dual space is always norming. Precisely, let $E$ be a Banach space. Then for all $e\in E$ , $$\|e\|=\sup\limits_{\substack{e'\in E'\\\|e'\|=1}}|e'(e)|.$$ Now assume that $D\subset E'$ is dense. Do we have $$\|e\|=\sup\limits_{\substack{e'\in D\\\|e'\|=1}}|e'(e)|?$$ If this is not true in this generality, is it at least valid if $E$ is reflexive?","I'm wondering if a dense subset of the dual space is always norming. Precisely, let be a Banach space. Then for all , Now assume that is dense. Do we have If this is not true in this generality, is it at least valid if is reflexive?",E e\in E \|e\|=\sup\limits_{\substack{e'\in E'\\\|e'\|=1}}|e'(e)|. D\subset E' \|e\|=\sup\limits_{\substack{e'\in D\\\|e'\|=1}}|e'(e)|? E,['functional-analysis']
97,closed subspace of normed vector space,closed subspace of normed vector space,,"Is every finite dimensional subspace of a normed vector space closed? If yes, please prove it or else give a counter example.","Is every finite dimensional subspace of a normed vector space closed? If yes, please prove it or else give a counter example.",,"['analysis', 'functional-analysis', 'vector-spaces', 'topological-vector-spaces']"
98,On the absolute integrability of radially symmetric functions,On the absolute integrability of radially symmetric functions,,"Let $\phi:\mathbb R\to\mathbb R$ be an smooth, even function and $\int_\mathbb R|\phi(t)|^p\,\mathrm dt<\infty$, that is, $\phi$ is pth-power integrable in $\mathbb R$ iff $p\geq p_0$ for $p_0\in\mathbb N$. Now let $\Phi(x):=\phi(|x|)$ with $x\in\mathbb R^n$. My question is: 1.) Which is the smallest $q$, such that $\int_{\mathbb R^n}|\Phi(x)|^q\, \mathrm dx<\infty$? I am aware of the fact that $(f\in L^p(\mathbb R^n)) \Rightarrow (f\in L^q(\mathbb R^n))$ for $p\leq q$ might not hold if the function support intervals get smaller and smaller with $|x|\to\infty$, but I'm interested in ""non-pathologic"" smooth functions, e.g. Bessel functions. I just don't know which function space I should use (just regarding analytic functions seems to restrictive for me). So the second part of my question is 2.) What is the appropriate function space to formulate question 1.) I started my calculations as follows:  \begin{align} \int_{\mathbb R^n}|\Phi(x)|dx &\,=\, \int_{\mathbb R^n}|\phi(|x|)|\,dx\\ &\,=\,\int_0^\infty\int_{S^{n-1}}|\phi(r)|\,\mathrm dS\,r^{n-1}\,\mathrm dr\\ &\,=\,\omega_{n-1}\int_0^\infty |\phi(r)|\,r^{n-1}\,\mathrm dr, \end{align} where $\omega_{n-1}$ is the surface of the unit sphere $S^{n-1}$ in $\mathbb R^n$. From this, it seems that the answer to my question is dimension-dependent, and that the needed $q$ will increase with the dimension $n$.","Let $\phi:\mathbb R\to\mathbb R$ be an smooth, even function and $\int_\mathbb R|\phi(t)|^p\,\mathrm dt<\infty$, that is, $\phi$ is pth-power integrable in $\mathbb R$ iff $p\geq p_0$ for $p_0\in\mathbb N$. Now let $\Phi(x):=\phi(|x|)$ with $x\in\mathbb R^n$. My question is: 1.) Which is the smallest $q$, such that $\int_{\mathbb R^n}|\Phi(x)|^q\, \mathrm dx<\infty$? I am aware of the fact that $(f\in L^p(\mathbb R^n)) \Rightarrow (f\in L^q(\mathbb R^n))$ for $p\leq q$ might not hold if the function support intervals get smaller and smaller with $|x|\to\infty$, but I'm interested in ""non-pathologic"" smooth functions, e.g. Bessel functions. I just don't know which function space I should use (just regarding analytic functions seems to restrictive for me). So the second part of my question is 2.) What is the appropriate function space to formulate question 1.) I started my calculations as follows:  \begin{align} \int_{\mathbb R^n}|\Phi(x)|dx &\,=\, \int_{\mathbb R^n}|\phi(|x|)|\,dx\\ &\,=\,\int_0^\infty\int_{S^{n-1}}|\phi(r)|\,\mathrm dS\,r^{n-1}\,\mathrm dr\\ &\,=\,\omega_{n-1}\int_0^\infty |\phi(r)|\,r^{n-1}\,\mathrm dr, \end{align} where $\omega_{n-1}$ is the surface of the unit sphere $S^{n-1}$ in $\mathbb R^n$. From this, it seems that the answer to my question is dimension-dependent, and that the needed $q$ will increase with the dimension $n$.",,"['analysis', 'functional-analysis', 'special-functions', 'lebesgue-integral']"
99,"If $T:X\to Y$ is continuous and $T^{t}:Y^{*}\to X^{*}$ is compact, is it true that $T$ is compact?","If  is continuous and  is compact, is it true that  is compact?",T:X\to Y T^{t}:Y^{*}\to X^{*} T,"I have a question. I have Banach spaces $X$ and $Y$, and $Y$ is reflexive. If $T:X\to Y$ is continuous, and $T^{t}:Y^{*}\to X^{*}, T^{t}(\phi)=\phi \circ T$ is compact, is it true that $T$ is compact? Thanks so much","I have a question. I have Banach spaces $X$ and $Y$, and $Y$ is reflexive. If $T:X\to Y$ is continuous, and $T^{t}:Y^{*}\to X^{*}, T^{t}(\phi)=\phi \circ T$ is compact, is it true that $T$ is compact? Thanks so much",,['functional-analysis']
