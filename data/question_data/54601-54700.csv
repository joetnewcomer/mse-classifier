,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Least prime divisor of $n!-1$ forms divergent series.,Least prime divisor of  forms divergent series.,n!-1,"If we have a sequence $\left\{\alpha_{n}\right\}_{n=3}^{\infty}$ such that $\alpha_{n}$ is the least prime divisors of $n !-1$ To Show: $$\sum_{n=3}^{\infty} \frac{1}{\alpha_{n}} \rightarrow \infty$$ I need help in completing my proof : $\Rightarrow$ Claim : The least prime divisor of $n!-1$ is greater than $n$ . If on the contrary we have prime $p$ s.t. $p \leq n$ then clearly $p \mid n !$ and if we assume $p$ also divides $n !-1$ then $p$ divides $n !-(n !-1)=1$ Hence contradiction. So the least prime divisor of $n !-1$ is greater than $n$ . Now how to prove that $\sum_{n=3}^{\infty} \frac{1}{\alpha_{n}} \rightarrow \infty$ once I have shown $\alpha_n \in \{n+1, \ldots, n !-1 \}$ .",If we have a sequence such that is the least prime divisors of To Show: I need help in completing my proof : Claim : The least prime divisor of is greater than . If on the contrary we have prime s.t. then clearly and if we assume also divides then divides Hence contradiction. So the least prime divisor of is greater than . Now how to prove that once I have shown .,"\left\{\alpha_{n}\right\}_{n=3}^{\infty} \alpha_{n} n !-1 \sum_{n=3}^{\infty} \frac{1}{\alpha_{n}} \rightarrow \infty \Rightarrow n!-1 n p p \leq n p \mid n ! p n !-1 p n !-(n !-1)=1 n !-1 n \sum_{n=3}^{\infty} \frac{1}{\alpha_{n}} \rightarrow \infty \alpha_n \in \{n+1, \ldots, n !-1 \}","['sequences-and-series', 'number-theory', 'elementary-number-theory']"
1,Prove closed form for $\sum_{n\in\Bbb N}\frac1{5n(5n-1)}$,Prove closed form for,\sum_{n\in\Bbb N}\frac1{5n(5n-1)},"While looking for solutions to a difficult geometric problem, I encountered this sum: $$ \sum_{n\in\Bbb N}\frac1{5n(5n-1)} = \frac1{4\cdot 5} + \frac1{9\cdot 10} + \frac1{14\cdot 15} + \ldots $$ A bit of numerical exploring has convinced me that the answer is $$ \sum_{n=1}^\infty\frac1{5n(5n-1)} = \frac14\log(5) + \frac{\sqrt{5}}{10}\log(\rho) -\frac{\pi}{10}\cot\left(\frac{\pi}{5} \right) $$ where $\rho$ is the ""Golden Ratio"" $\rho = \frac{1+\sqrt{5}}{2}$ . But I can't find a way to prove it. Prove $$ \sum_{n=1}^\infty\frac1{5n(5n-1)} = \frac14\log(5) + \frac{\sqrt{5}}{10}\log(\rho) -\frac{\pi}{10}\cot\left(\frac{\pi}{5} \right) $$","While looking for solutions to a difficult geometric problem, I encountered this sum: A bit of numerical exploring has convinced me that the answer is where is the ""Golden Ratio"" . But I can't find a way to prove it. Prove","
\sum_{n\in\Bbb N}\frac1{5n(5n-1)} = \frac1{4\cdot 5} + \frac1{9\cdot 10} + \frac1{14\cdot 15} + \ldots
 
\sum_{n=1}^\infty\frac1{5n(5n-1)} = \frac14\log(5) + \frac{\sqrt{5}}{10}\log(\rho) -\frac{\pi}{10}\cot\left(\frac{\pi}{5} \right)
 \rho \rho = \frac{1+\sqrt{5}}{2} 
\sum_{n=1}^\infty\frac1{5n(5n-1)} = \frac14\log(5) + \frac{\sqrt{5}}{10}\log(\rho) -\frac{\pi}{10}\cot\left(\frac{\pi}{5} \right)
",['sequences-and-series']
2,Show that $x_n = \sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} - \sqrt n$ is a bounded sequence.,Show that  is a bounded sequence.,x_n = \sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} - \sqrt n,Let $n\in \mathbb N$ and: $$ x_n = \sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} - \sqrt n $$ Show that $\{x_n\}$ is a bounded sequence. This sequence appears a bit tricky because it involves harmonic series. Below are steps I take. Lower bound: $$ \sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} \ge \sqrt{\sum_{k=1}^n\left(\frac{k}{k}\right)^2} = \sqrt{\sum_{k=1}^n1}=\sqrt{n}\implies\\ \implies x_n \ge \sqrt n - \sqrt n \ge 0 $$ Lower bound is simple. Upper bound: To get rid of radical lets use Cauchy-Schwarz (note the below is incorrect as shown in Zvi's answer): $$ \sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} \le \sqrt{\left(\sum_{k=1}^n\left(\frac{k+1}{k}\right)\right)^2} =\sum_{k=1}^n\left(\frac{k+1}{k}\right) = n+\sum_{k=1}^n{1\over k} = n + H_n $$ So this doesn't show $x_n$ is bounded above. I've tried another approach: $$ \sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} - \sqrt n = \frac{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2 - n}{\sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} + \sqrt n} $$ Consider nominator: $$ \sum_{k=1}^n\left(\frac{k+1}{k}\right)^2 - n=n+\sum_{k=1}^n{2\over k}+\sum_{k=1}^n{1\over k^2}-n = \sum_{k=1}^n{1\over k^2} + \sum_{k=1}^n{2\over k} $$ For denominator: $$ \sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} + \sqrt n = \sqrt{n + \sum_{k=1}^n{1\over k^2}+\sum_{k=1}^n{2\over k}} + \sqrt n $$ So $x_n$ is: $$ x_n = \frac{\sum_{k=1}^n{1\over k^2} + \sum_{k=1}^n{2\over k}}{ \sqrt{n + \sum_{k=1}^n{1\over k^2}+\sum_{k=1}^n{2\over k}} + \sqrt n } $$ But i don't see how to proceed from this point. What else could i try? How to show $x_n$ is bounded above? Please note the precalculus tag.,Let and: Show that is a bounded sequence. This sequence appears a bit tricky because it involves harmonic series. Below are steps I take. Lower bound: Lower bound is simple. Upper bound: To get rid of radical lets use Cauchy-Schwarz (note the below is incorrect as shown in Zvi's answer): So this doesn't show is bounded above. I've tried another approach: Consider nominator: For denominator: So is: But i don't see how to proceed from this point. What else could i try? How to show is bounded above? Please note the precalculus tag.,"n\in \mathbb N 
x_n = \sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} - \sqrt n
 \{x_n\} 
\sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} \ge \sqrt{\sum_{k=1}^n\left(\frac{k}{k}\right)^2} = \sqrt{\sum_{k=1}^n1}=\sqrt{n}\implies\\
\implies x_n \ge \sqrt n - \sqrt n \ge 0
 
\sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} \le \sqrt{\left(\sum_{k=1}^n\left(\frac{k+1}{k}\right)\right)^2} =\sum_{k=1}^n\left(\frac{k+1}{k}\right) = n+\sum_{k=1}^n{1\over k} = n + H_n
 x_n 
\sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} - \sqrt n = \frac{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2 - n}{\sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} + \sqrt n}
 
\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2 - n=n+\sum_{k=1}^n{2\over k}+\sum_{k=1}^n{1\over k^2}-n = \sum_{k=1}^n{1\over k^2} + \sum_{k=1}^n{2\over k}
 
\sqrt{\sum_{k=1}^n\left(\frac{k+1}{k}\right)^2} + \sqrt n = \sqrt{n + \sum_{k=1}^n{1\over k^2}+\sum_{k=1}^n{2\over k}} + \sqrt n
 x_n 
x_n = \frac{\sum_{k=1}^n{1\over k^2} + \sum_{k=1}^n{2\over k}}{ \sqrt{n + \sum_{k=1}^n{1\over k^2}+\sum_{k=1}^n{2\over k}} + \sqrt n }
 x_n","['sequences-and-series', 'algebra-precalculus', 'upper-lower-bounds']"
3,"""Bad"" Fourier Series derivation","""Bad"" Fourier Series derivation",,"Let $f(\theta)$ $2\pi$ -periodic such that $f(\theta)=e^{\theta}$ for $-\pi<0<\pi$ , and $$e^{\theta}=\sum_{n=-\infty}^{\infty}c_{n}e^{in\theta}\,\,\, \mathrm{for}\,\, |\theta|<\pi $$ it's  Fourier series. If we formally differentiate this equation, we obtain $$e^{\theta}=\sum_{n=-\infty}^{\infty}inc_{n}e^{in\theta}. $$ But this implies $c_{n}=inc_{n}$ or $(1-in)c_{n}=0$ , so, $c_{n}=0\,\forall n\in\mathbb{Z}$ . This is obviously wrong. Where is the mistake? The only thing that I could contest is the derivative of $f$ . I know a theorem saying that a sufficient condition is $f$ continuous and piecewise smooth, and $f$ is not continous. But it don't implies that I can't derivate term by term.","Let -periodic such that for , and it's  Fourier series. If we formally differentiate this equation, we obtain But this implies or , so, . This is obviously wrong. Where is the mistake? The only thing that I could contest is the derivative of . I know a theorem saying that a sufficient condition is continuous and piecewise smooth, and is not continous. But it don't implies that I can't derivate term by term.","f(\theta) 2\pi f(\theta)=e^{\theta} -\pi<0<\pi e^{\theta}=\sum_{n=-\infty}^{\infty}c_{n}e^{in\theta}\,\,\, \mathrm{for}\,\, |\theta|<\pi  e^{\theta}=\sum_{n=-\infty}^{\infty}inc_{n}e^{in\theta}.  c_{n}=inc_{n} (1-in)c_{n}=0 c_{n}=0\,\forall n\in\mathbb{Z} f f f","['sequences-and-series', 'fourier-analysis', 'fourier-series']"
4,Prove $\lim_{n\to\infty}(1+1/n)^n=e$,Prove,\lim_{n\to\infty}(1+1/n)^n=e,"I would like to show that $\lim_{n\to\infty}(1+1/n)^n=e$, using the binomial theorem and the power series expansion of $e$. So to be clear: I do not want to use that $e^x:=\lim_{n\to\infty}(1+x/n)^n$, because that's not how I've learned the definition of $e^x$. Basically I would like to show the following: $$ \lim_{n\to\infty}\sum_{k=0}^n\begin{pmatrix}n\\k\end{pmatrix}\left(\frac{1}{n}\right)^k=\sum_{k=0}^\infty\frac{1}{k!} $$ I'm guessing this should be possible. Maybe some rewriting could work: $$ \sum_{k=0}^n\begin{pmatrix}n\\k\end{pmatrix}\left(\frac{1}{n}\right)^k=\sum_{k=0}^n\frac{1}{k!}\cdot\frac{n!}{(n-k)!}\cdot\left(\frac{1}{n}\right)^k $$ EDIT (I was shown a mistake in the comments) So I have to show the following: $$ \lim_{n\to\infty}\sum_{k=0}^n\frac{1}{k!}\frac{n!}{(n-k)!}\cdot\left(\frac{1}{n}\right)^k=\lim_{n\to\infty}\sum_{k=0}^n\frac{1}{k!}. $$ This seems doable, given that I see the term $\begin{align}\frac{1}{k!}\end{align}$ at both sides. So what can I do with $\begin{align}\frac{n!}{(n-k)!}\cdot\left(\frac{1}{n}\right)^k\end{align}$?","I would like to show that $\lim_{n\to\infty}(1+1/n)^n=e$, using the binomial theorem and the power series expansion of $e$. So to be clear: I do not want to use that $e^x:=\lim_{n\to\infty}(1+x/n)^n$, because that's not how I've learned the definition of $e^x$. Basically I would like to show the following: $$ \lim_{n\to\infty}\sum_{k=0}^n\begin{pmatrix}n\\k\end{pmatrix}\left(\frac{1}{n}\right)^k=\sum_{k=0}^\infty\frac{1}{k!} $$ I'm guessing this should be possible. Maybe some rewriting could work: $$ \sum_{k=0}^n\begin{pmatrix}n\\k\end{pmatrix}\left(\frac{1}{n}\right)^k=\sum_{k=0}^n\frac{1}{k!}\cdot\frac{n!}{(n-k)!}\cdot\left(\frac{1}{n}\right)^k $$ EDIT (I was shown a mistake in the comments) So I have to show the following: $$ \lim_{n\to\infty}\sum_{k=0}^n\frac{1}{k!}\frac{n!}{(n-k)!}\cdot\left(\frac{1}{n}\right)^k=\lim_{n\to\infty}\sum_{k=0}^n\frac{1}{k!}. $$ This seems doable, given that I see the term $\begin{align}\frac{1}{k!}\end{align}$ at both sides. So what can I do with $\begin{align}\frac{n!}{(n-k)!}\cdot\left(\frac{1}{n}\right)^k\end{align}$?",,"['sequences-and-series', 'limits', 'power-series', 'limits-without-lhopital']"
5,"Limits, Taylor expansion","Limits, Taylor expansion",,"Find the limit:  $$  \lim_{x\to\infty} \frac{\displaystyle \sum\limits_{i = 0}^\infty \frac{x^{in}}{(in)!}}{\displaystyle\sum\limits_{j = 0}^\infty \frac{x^{jm}}{(jm)!}} $$  for $n$, $m$ natural numbers. It is easy to see that for elementary cases, like $n=0$ we just get the Taylor expansion for $e^x$. We get the limit equal to $1$ for $n=m$. Any idea how to find a general rule? Maybe we can use some sort of squeezing argument?","Find the limit:  $$  \lim_{x\to\infty} \frac{\displaystyle \sum\limits_{i = 0}^\infty \frac{x^{in}}{(in)!}}{\displaystyle\sum\limits_{j = 0}^\infty \frac{x^{jm}}{(jm)!}} $$  for $n$, $m$ natural numbers. It is easy to see that for elementary cases, like $n=0$ we just get the Taylor expansion for $e^x$. We get the limit equal to $1$ for $n=m$. Any idea how to find a general rule? Maybe we can use some sort of squeezing argument?",,"['sequences-and-series', 'limits']"
6,"""Indexes the sequence"" meaning in the definition of a subsequence","""Indexes the sequence"" meaning in the definition of a subsequence",,"Let $(a_n)$ be a sequence of real numbers, and let $n_1<n_2< n_3 <n_4 <n_5 <···$ be an increasing sequence of natural numbers. Then the sequence $a_{n_1},a_{n_2},a_{n_3},a_{n_4} ,···$ is called a subsequence of $(a_n)$ and is denoted by $(a_{n_j} )$, where $j ∈\mathbb{N}$ indexes the subsequence. What exactly is the meaning of ""indexes the subsequence"" ?","Let $(a_n)$ be a sequence of real numbers, and let $n_1<n_2< n_3 <n_4 <n_5 <···$ be an increasing sequence of natural numbers. Then the sequence $a_{n_1},a_{n_2},a_{n_3},a_{n_4} ,···$ is called a subsequence of $(a_n)$ and is denoted by $(a_{n_j} )$, where $j ∈\mathbb{N}$ indexes the subsequence. What exactly is the meaning of ""indexes the subsequence"" ?",,['sequences-and-series']
7,Double sum and zeta function,Double sum and zeta function,,"This is a personal research that came to an end , since the results were not those which were being anticipated. I was unable to come up with a solution therefore I post the topic here: Prove (it certainly holds because it was checked on a computer) that the following identity holds: $$\sum_{n=1}^{\infty}\sum_{k=1}^{\infty}\frac{1}{\left ( n^2+k^2 \right )^2}=\zeta(2)\sum_{n=1}^{\infty}(-1)^{n-1}\frac{1}{\left ( 2n-1 \right )^2}-\zeta(4)$$ wheras $\zeta$ represents the zeta function defined as $\displaystyle \zeta(s)=\sum_{n=1}^{\infty}\frac{1}{n^s}, \;\; \mathfrak{Re}(s)>1 $. Of course both values of $\zeta$ appearing here are known. For complete of sakeness i quote them : $$\zeta(2)=\frac{\pi^2}{6}, \;\; \zeta(4)=\frac{\pi^4}{90}$$ Now, one can also see (not trivial ) that: $$\sum_{n=1}^{\infty}\frac{1}{n^2 \sinh^2 \pi n}=\frac{4}{\pi^2}\sum_{n=1}^{\infty}\sum_{k=1}^{\infty}\frac{1}{\left ( n^2+k^2 \right )^2} -\frac{\pi^2}{60}$$ This equation also holds (checked by computer). The following result was extracted by using the known formulae $\displaystyle \sum_{n=-\infty}^{\infty}\frac{1}{z+n}=\frac{\pi}{\tan \pi z}$ and the known (?)  Fourier series: $$\displaystyle \frac{1}{\sinh^2 \pi z}=\frac{1}{\pi^2 z}+\frac{4z^2}{\pi^2}\sum_{k=1}^{\infty}\frac{1}{\left ( z^2+k^2 \right )^2}-\frac{2}{\pi^2}\sum_{k=1}^{\infty}\frac{1}{z^2+k^2} $$ Of course the last sum at the last equation can easily be computed via residues. What remains now is the proof for the first equation in the post. No-one can guarantee that is going to be an easy task. Some comments: 1. I came across the identity on a book. I checked the validity with a computer and yes it does hold. 2. I have ckecked enough books to see if there is in there somewhere , but unfortunately it was not. So, I speculate that it is not that famous. 3. It can also be linked with other sums (single or double). Unfortunately I don't have my papers in front of me in order to write them down. So, i think it is an interseting identity. I would appreciate your help.","This is a personal research that came to an end , since the results were not those which were being anticipated. I was unable to come up with a solution therefore I post the topic here: Prove (it certainly holds because it was checked on a computer) that the following identity holds: $$\sum_{n=1}^{\infty}\sum_{k=1}^{\infty}\frac{1}{\left ( n^2+k^2 \right )^2}=\zeta(2)\sum_{n=1}^{\infty}(-1)^{n-1}\frac{1}{\left ( 2n-1 \right )^2}-\zeta(4)$$ wheras $\zeta$ represents the zeta function defined as $\displaystyle \zeta(s)=\sum_{n=1}^{\infty}\frac{1}{n^s}, \;\; \mathfrak{Re}(s)>1 $. Of course both values of $\zeta$ appearing here are known. For complete of sakeness i quote them : $$\zeta(2)=\frac{\pi^2}{6}, \;\; \zeta(4)=\frac{\pi^4}{90}$$ Now, one can also see (not trivial ) that: $$\sum_{n=1}^{\infty}\frac{1}{n^2 \sinh^2 \pi n}=\frac{4}{\pi^2}\sum_{n=1}^{\infty}\sum_{k=1}^{\infty}\frac{1}{\left ( n^2+k^2 \right )^2} -\frac{\pi^2}{60}$$ This equation also holds (checked by computer). The following result was extracted by using the known formulae $\displaystyle \sum_{n=-\infty}^{\infty}\frac{1}{z+n}=\frac{\pi}{\tan \pi z}$ and the known (?)  Fourier series: $$\displaystyle \frac{1}{\sinh^2 \pi z}=\frac{1}{\pi^2 z}+\frac{4z^2}{\pi^2}\sum_{k=1}^{\infty}\frac{1}{\left ( z^2+k^2 \right )^2}-\frac{2}{\pi^2}\sum_{k=1}^{\infty}\frac{1}{z^2+k^2} $$ Of course the last sum at the last equation can easily be computed via residues. What remains now is the proof for the first equation in the post. No-one can guarantee that is going to be an easy task. Some comments: 1. I came across the identity on a book. I checked the validity with a computer and yes it does hold. 2. I have ckecked enough books to see if there is in there somewhere , but unfortunately it was not. So, I speculate that it is not that famous. 3. It can also be linked with other sums (single or double). Unfortunately I don't have my papers in front of me in order to write them down. So, i think it is an interseting identity. I would appreciate your help.",,"['sequences-and-series', 'fourier-series', 'riemann-zeta']"
8,How prove $\sum_{n=1}^{\infty}\dfrac{a_{n}}{\ln{(1+n)}}<+\infty$,How prove,\sum_{n=1}^{\infty}\dfrac{a_{n}}{\ln{(1+n)}}<+\infty,"Question: Define sequence $\{a_{n}\}$ such  $$0<a_{n}<1,n\in N^{+}$$ such   $$\sum_{n=1}^{\infty}\dfrac{a_{n}}{\ln{(a_{n})}}$$ is convergent. Show that   $$\sum_{n=1}^{\infty}\dfrac{a_{n}}{\ln{(1+n)}}<+\infty.$$ My idea:Use $$\ln{(1+x)}>\dfrac{x}{1+x}$$ $$0<a_{n}<1$$  so $$\dfrac{a_{n}}{\ln{(1+n)}}<\dfrac{(1+n)a_{n}}{n}$$ then I can't continue.Thank you.","Question: Define sequence $\{a_{n}\}$ such  $$0<a_{n}<1,n\in N^{+}$$ such   $$\sum_{n=1}^{\infty}\dfrac{a_{n}}{\ln{(a_{n})}}$$ is convergent. Show that   $$\sum_{n=1}^{\infty}\dfrac{a_{n}}{\ln{(1+n)}}<+\infty.$$ My idea:Use $$\ln{(1+x)}>\dfrac{x}{1+x}$$ $$0<a_{n}<1$$  so $$\dfrac{a_{n}}{\ln{(1+n)}}<\dfrac{(1+n)a_{n}}{n}$$ then I can't continue.Thank you.",,"['sequences-and-series', 'analysis']"
9,"How to prove all $c_{n},d_{n}$ to be integers if $(n+1)c_{n}=nc_{n-1}+2nd_{n-1}$ and $d_{n}=2c_{n-1}+d_{n-1}$?",How to prove all  to be integers if  and ?,"c_{n},d_{n} (n+1)c_{n}=nc_{n-1}+2nd_{n-1} d_{n}=2c_{n-1}+d_{n-1}","Let sequences $(c_n)$ and $(d_n)$ be given by $$c_0=0,\:d_0=1$$ and recursively for $n\ge 1$ by $$\begin{align} c_n & =\frac{n}{n+1}c_{n-1}+\frac{2n}{n+1}d_{n-1} \\[2ex] d_n & =2c_{n-1}+d_{n-1} \end{align}$$ I'd like to show that all $c_{n},d_{n}$ are integers. (Creat by wang yong xi） My try： Since $$\begin{align}(n+1)c_n & =nc_{n-1}+2nd_{n-1}\\[1ex] d_n & =2c_{n-1}+d_{n-1} \end{align}$$ we easily find $$c_{1}=1,\:d_{1}=1,\\ c_{2}=2,\:d_{2}=3,\\ c_{3}=6,\:d_{3}=7,$$ a.s.o.   How to prove that all the $c_{n},d_{n}$ are integers?",Let sequences and be given by and recursively for by I'd like to show that all are integers. (Creat by wang yong xi） My try： Since we easily find a.s.o.   How to prove that all the are integers?,"(c_n) (d_n) c_0=0,\:d_0=1 n\ge 1 \begin{align}
c_n & =\frac{n}{n+1}c_{n-1}+\frac{2n}{n+1}d_{n-1} \\[2ex]
d_n & =2c_{n-1}+d_{n-1}
\end{align} c_{n},d_{n} \begin{align}(n+1)c_n & =nc_{n-1}+2nd_{n-1}\\[1ex]
d_n & =2c_{n-1}+d_{n-1}
\end{align} c_{1}=1,\:d_{1}=1,\\
c_{2}=2,\:d_{2}=3,\\
c_{3}=6,\:d_{3}=7, c_{n},d_{n}","['sequences-and-series', 'recurrence-relations', 'systems-of-equations']"
10,"$a_1=1,a_{n+1}=\frac{n}{a_n}+\frac{a_n}{n}$. Prove that for $n\ge4$, $\lfloor{a_n^2}\rfloor=n$",". Prove that for ,","a_1=1,a_{n+1}=\frac{n}{a_n}+\frac{a_n}{n} n\ge4 \lfloor{a_n^2}\rfloor=n","Define a sequence $\left\lbrace a_{n}\right\rbrace$ by $\displaystyle{a_{1} = 1\,,\ a_{n + 1} = {n \over a_n} + {a_n \over n}.\quad}$ Prove that for $n \geq 4,\,\,\left\lfloor a_{n}^{2}\right\rfloor=n$ The substitution $b_{n} = a_{n}^{2}$ might be helpful, but I still haven't proved the assertion yet.","Define a sequence $\left\lbrace a_{n}\right\rbrace$ by $\displaystyle{a_{1} = 1\,,\ a_{n + 1} = {n \over a_n} + {a_n \over n}.\quad}$ Prove that for $n \geq 4,\,\,\left\lfloor a_{n}^{2}\right\rfloor=n$ The substitution $b_{n} = a_{n}^{2}$ might be helpful, but I still haven't proved the assertion yet.",,"['sequences-and-series', 'elementary-number-theory', 'recurrence-relations', 'contest-math', 'ceiling-and-floor-functions']"
11,Prove $\frac {1}{\cos 0^\circ \cdot \cos 1^\circ} + \ldots +\frac {1}{\cos 88^\circ \cdot \cos 89^\circ}= \frac{\cos 1^\circ}{\sin 1^\circ}$,Prove,\frac {1}{\cos 0^\circ \cdot \cos 1^\circ} + \ldots +\frac {1}{\cos 88^\circ \cdot \cos 89^\circ}= \frac{\cos 1^\circ}{\sin 1^\circ},"Prove the following identity: $$\frac {1}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {1}{\cos 88^{\circ} \cdot \cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ After hours of trying, I wasn't able to make any significant progress, that worth mentioning. Then I finally decided to look into the solution, but it seems that author had the same problem, the listed solution is obviously wrong. $$\sin 1^{\circ}\left(\frac {1}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {1}{\cos 88^{\circ} \cdot \cos 89^{\circ}}\right) = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin 1^{\circ}}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {\sin 1^{\circ}}{\cos 88^{\circ} \cdot \cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin (1^{\circ} - 0^{\circ})}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {\sin (89^{\circ} - 88^{\circ})}{\cos 88^{\circ} \cdot \cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin 1^{\circ}\cos0^{\circ} - \cos 1^{\circ}\sin 0^{\circ}}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {\sin 89^{\circ}\cos 88^{\circ} - \cos 89^{\circ}\sin 88^{\circ}}{\cos 88^{\circ} \cdot \cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin 1^{\circ}}{\cos 1^{\circ}} - \frac {\sin 0^{\circ}}{\cos 0^{\circ}} + \ldots +\frac {\sin 89^{\circ}}{\cos 89^{\circ}} - \frac {\sin 88^{\circ}}{\cos 88^{\circ}} + = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ I hope I'm clear till now, beacuse everything I do was just elementary alegraic and trigonometric transformation. So now it's just telescopic series. $$\frac {\sin 89^{\circ}}{\cos 89^{\circ}} - \frac {\sin 0^{\circ}}{\cos 0^{\circ}}= \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin 89^{\circ}}{\cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\cos 1^{\circ}}{\sin 1^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ Q.E.D. But I think this is actualy a counterproof, rather than a proof, because the identity that the author started the proof is different from the one we want. And obviously $\sin 1^{\circ} \neq 1$ My question is the identity wrong, is it a typo? Or am I missing something obvious?","Prove the following identity: $$\frac {1}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {1}{\cos 88^{\circ} \cdot \cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ After hours of trying, I wasn't able to make any significant progress, that worth mentioning. Then I finally decided to look into the solution, but it seems that author had the same problem, the listed solution is obviously wrong. $$\sin 1^{\circ}\left(\frac {1}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {1}{\cos 88^{\circ} \cdot \cos 89^{\circ}}\right) = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin 1^{\circ}}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {\sin 1^{\circ}}{\cos 88^{\circ} \cdot \cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin (1^{\circ} - 0^{\circ})}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {\sin (89^{\circ} - 88^{\circ})}{\cos 88^{\circ} \cdot \cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin 1^{\circ}\cos0^{\circ} - \cos 1^{\circ}\sin 0^{\circ}}{\cos 0^{\circ} \cdot \cos 1^{\circ}} + \ldots +\frac {\sin 89^{\circ}\cos 88^{\circ} - \cos 89^{\circ}\sin 88^{\circ}}{\cos 88^{\circ} \cdot \cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin 1^{\circ}}{\cos 1^{\circ}} - \frac {\sin 0^{\circ}}{\cos 0^{\circ}} + \ldots +\frac {\sin 89^{\circ}}{\cos 89^{\circ}} - \frac {\sin 88^{\circ}}{\cos 88^{\circ}} + = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ I hope I'm clear till now, beacuse everything I do was just elementary alegraic and trigonometric transformation. So now it's just telescopic series. $$\frac {\sin 89^{\circ}}{\cos 89^{\circ}} - \frac {\sin 0^{\circ}}{\cos 0^{\circ}}= \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\sin 89^{\circ}}{\cos 89^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ $$\frac {\cos 1^{\circ}}{\sin 1^{\circ}} = \frac{\cos 1^{\circ}}{\sin 1^{\circ}}$$ Q.E.D. But I think this is actualy a counterproof, rather than a proof, because the identity that the author started the proof is different from the one we want. And obviously $\sin 1^{\circ} \neq 1$ My question is the identity wrong, is it a typo? Or am I missing something obvious?",,"['sequences-and-series', 'trigonometry', 'proof-verification', 'fake-proofs']"
12,Question on geometrical proof of Geometric Series,Question on geometrical proof of Geometric Series,,"The following image is from Geometric Series Proofs: An Annotated Bibliography . Please explain why it is said that: ""$ON$ is the limit of the sum $1+x+\dots$."" Thank you. Edit: I guess what through me off was the word ""limit""!","The following image is from Geometric Series Proofs: An Annotated Bibliography . Please explain why it is said that: ""$ON$ is the limit of the sum $1+x+\dots$."" Thank you. Edit: I guess what through me off was the word ""limit""!",,"['sequences-and-series', 'geometry', 'algebra-precalculus']"
13,Sum of kth roots ($\sum\sqrt[k]{m}$),Sum of kth roots (),\sum\sqrt[k]{m},"I'm trying to find an asymptotic to $$S(n) = \sum_{k=1}^n\sqrt[k]{m}$$ From computational tests, it seems to grow nearly as slowly as $n$. However even $$\sum_{k=1}^\infty\sqrt[k]{m}-1$$ diverges (for $m\neq1$) by the comparison test. I'm thinking it might be something like $n\log{\log n}$, but I don't know how to show it. Update: So it turns out to be closer to $n\sqrt[n]{m}$. Does anybody know if there is a nice formula?","I'm trying to find an asymptotic to $$S(n) = \sum_{k=1}^n\sqrt[k]{m}$$ From computational tests, it seems to grow nearly as slowly as $n$. However even $$\sum_{k=1}^\infty\sqrt[k]{m}-1$$ diverges (for $m\neq1$) by the comparison test. I'm thinking it might be something like $n\log{\log n}$, but I don't know how to show it. Update: So it turns out to be closer to $n\sqrt[n]{m}$. Does anybody know if there is a nice formula?",,"['sequences-and-series', 'asymptotics', 'summation', 'divergent-series']"
14,Convergence of random variables (Durrett: Probability Theory and Examples),Convergence of random variables (Durrett: Probability Theory and Examples),,"I was working out some problems from Rick Durrett's Probability theory and Examples (2010 edition), when I came across a very unusual question(reproduced here ad-verbatim): If $X_n$ is ANY sequence of random variables, there are constants $c_n \to \infty$ so that $$\frac{X_n}{c_n} \to 0 \quad \mbox{a.s}$$ You will find it in Chapter 2: Laws of Large Numbers, under the section on Borel Cantelli Lemma. What makes this question unusual is that there are NO assumptions made on the random variables. My attempt: I rephrased the question equivalently as: If $X_n$ is ANY sequence of random variables, there are constants $a_n \to 0$ so that we need to show $$a_nX_n \to 0 \quad \mbox{a.s}$$ Then I showed that it was sufficient to assume $a_n > 0$ and $X_n \geq 0$. To see this, since the limit is going to , the sign of the constants do not matter, hence positivity of $a_n$ can be assumed w.l.o.g. As for an arbitrary r.v, any r.v can be written as: $$X_n = X_n^+ - X_n^-$$ where $X_n^+ = \max(X_n,0)$ and $X_n^- = \max(-X_n,0)$ Suppose we prove the result for non-negative random variables, then say we have  $$b_n X_n^+ \to 0 \quad c_n X_n^- \to 0 \quad \mbox{a.s}$$ Then pick $a_n = \min(b_n,c_n)$. Then this will ensure  $$a_nX_n \to 0 \quad \mbox{a.s}$$ For the non-negative case, I was able to prove the result for simple functions: If $X_n$ is simple, and $X_n = \sum_{k=1}^n s_k 1_{A_k}$, take $a_n = \frac{1}{2^{n} \sum_{k=1}^n s_k}$ would work, but only if all functions were simple. Now the tough part. Handling the non -ve measurable function case. I had difficulty here. Hence my question is: I'd like a hint/answer (preferably a hint) on how to solve this particular case. Right now I am looking at manipulating the lemma that every non-negative measurable function can be approximated by a monotone sequence of simple functions. Thank you. Note: I use measurable functions and random variables interchangeably. But note that the space is a probability space. Additionally, I didn't find any similar question (I typed convergence random variables). If it has been answered, kindly provide the link.","I was working out some problems from Rick Durrett's Probability theory and Examples (2010 edition), when I came across a very unusual question(reproduced here ad-verbatim): If $X_n$ is ANY sequence of random variables, there are constants $c_n \to \infty$ so that $$\frac{X_n}{c_n} \to 0 \quad \mbox{a.s}$$ You will find it in Chapter 2: Laws of Large Numbers, under the section on Borel Cantelli Lemma. What makes this question unusual is that there are NO assumptions made on the random variables. My attempt: I rephrased the question equivalently as: If $X_n$ is ANY sequence of random variables, there are constants $a_n \to 0$ so that we need to show $$a_nX_n \to 0 \quad \mbox{a.s}$$ Then I showed that it was sufficient to assume $a_n > 0$ and $X_n \geq 0$. To see this, since the limit is going to , the sign of the constants do not matter, hence positivity of $a_n$ can be assumed w.l.o.g. As for an arbitrary r.v, any r.v can be written as: $$X_n = X_n^+ - X_n^-$$ where $X_n^+ = \max(X_n,0)$ and $X_n^- = \max(-X_n,0)$ Suppose we prove the result for non-negative random variables, then say we have  $$b_n X_n^+ \to 0 \quad c_n X_n^- \to 0 \quad \mbox{a.s}$$ Then pick $a_n = \min(b_n,c_n)$. Then this will ensure  $$a_nX_n \to 0 \quad \mbox{a.s}$$ For the non-negative case, I was able to prove the result for simple functions: If $X_n$ is simple, and $X_n = \sum_{k=1}^n s_k 1_{A_k}$, take $a_n = \frac{1}{2^{n} \sum_{k=1}^n s_k}$ would work, but only if all functions were simple. Now the tough part. Handling the non -ve measurable function case. I had difficulty here. Hence my question is: I'd like a hint/answer (preferably a hint) on how to solve this particular case. Right now I am looking at manipulating the lemma that every non-negative measurable function can be approximated by a monotone sequence of simple functions. Thank you. Note: I use measurable functions and random variables interchangeably. But note that the space is a probability space. Additionally, I didn't find any similar question (I typed convergence random variables). If it has been answered, kindly provide the link.",,"['sequences-and-series', 'measure-theory', 'probability-theory']"
15,"Dense set in $[0,\infty)$",Dense set in,"[0,\infty)","I want to prove that $M=\{2^a 3^b: a,b \in\mathbb Z\}$ is dense $[0,\infty)$ Therefore I want to show that $\overline{M}=[0,\infty)$ $\overline{M}\subseteq[0,\infty)$ because $M\subseteq[0,\infty)$ For the other direction I have an element $x\in[0,\infty)$, now I need to show that $\exists (x_n)\in\overline{M}:x_n\rightarrow x$, i.e to show $\exists (a_n)(b_n)\in\mathbb Z:x_n=2^{a_n}3^{b_n}\rightarrow x$. Could you help me with that direction? EDIT: As discussed in the comments, of course there are different ways proving this result, but I would like to be most interested in the continuation of my approach. If you know different solution approaches it is also interesting to know them and discuss them.","I want to prove that $M=\{2^a 3^b: a,b \in\mathbb Z\}$ is dense $[0,\infty)$ Therefore I want to show that $\overline{M}=[0,\infty)$ $\overline{M}\subseteq[0,\infty)$ because $M\subseteq[0,\infty)$ For the other direction I have an element $x\in[0,\infty)$, now I need to show that $\exists (x_n)\in\overline{M}:x_n\rightarrow x$, i.e to show $\exists (a_n)(b_n)\in\mathbb Z:x_n=2^{a_n}3^{b_n}\rightarrow x$. Could you help me with that direction? EDIT: As discussed in the comments, of course there are different ways proving this result, but I would like to be most interested in the continuation of my approach. If you know different solution approaches it is also interesting to know them and discuss them.",,"['general-topology', 'sequences-and-series']"
16,A Question On Euler's Proof Of the Basel Problem,A Question On Euler's Proof Of the Basel Problem,,"I've studied the proof that Euler gave for the famous Basel Problem , and it would seem that while it is technically correct, he does not justify all of his steps properly. Namely, he assumes that $$\frac{\sin(x)}{x}=\left(1-\frac{x}{\pi}\right)\left(1+\frac{x}{\pi}\right)\left(1-\frac{x}{2\pi}\right)\left(1+\frac{x}{2\pi}\right)\dots$$ simply because they have the same roots, which is really not a strong enough condition. How do you really show that the equality holds? He then notices that if you use the above equality, and consider it against the Taylor expansion for $\frac{\sin(x)}{x}$, then you can equate the coefficients of the two infinite expansions at each order, and the result of the Basel problem follows. But how do you know that if you have two different expansions for a function, then their coefficients at each order must be equal? I would really appreciate if someone could show me how to make these two intuitive, yet informal, steps rigorous.","I've studied the proof that Euler gave for the famous Basel Problem , and it would seem that while it is technically correct, he does not justify all of his steps properly. Namely, he assumes that $$\frac{\sin(x)}{x}=\left(1-\frac{x}{\pi}\right)\left(1+\frac{x}{\pi}\right)\left(1-\frac{x}{2\pi}\right)\left(1+\frac{x}{2\pi}\right)\dots$$ simply because they have the same roots, which is really not a strong enough condition. How do you really show that the equality holds? He then notices that if you use the above equality, and consider it against the Taylor expansion for $\frac{\sin(x)}{x}$, then you can equate the coefficients of the two infinite expansions at each order, and the result of the Basel problem follows. But how do you know that if you have two different expansions for a function, then their coefficients at each order must be equal? I would really appreciate if someone could show me how to make these two intuitive, yet informal, steps rigorous.",,"['sequences-and-series', 'taylor-expansion', 'roots']"
17,Does $\sum_{n=0}^\infty\frac{\sin(2n+1)}{2n+1}=0$?,Does ?,\sum_{n=0}^\infty\frac{\sin(2n+1)}{2n+1}=0,"I've come to a bit of a sticking point in my answer to problem 14A given here http://www.maths.cam.ac.uk/undergrad/pastpapers/2011/ib/List_IB.pdf (note that this is a past paper that I am trying for myself and not homework) Anyway, things would maybe be ok if I could easily tell that $\sum_{n=0}^\infty\frac{\sin(2n+1)}{2n+1}=0$ Is this the case? If not what does the sum equal? Is it even convergent? Also, if anyone has any ideas about the end of the question  I posted, where it asks me to comment on my answer, that would be much appreciated.","I've come to a bit of a sticking point in my answer to problem 14A given here http://www.maths.cam.ac.uk/undergrad/pastpapers/2011/ib/List_IB.pdf (note that this is a past paper that I am trying for myself and not homework) Anyway, things would maybe be ok if I could easily tell that $\sum_{n=0}^\infty\frac{\sin(2n+1)}{2n+1}=0$ Is this the case? If not what does the sum equal? Is it even convergent? Also, if anyone has any ideas about the end of the question  I posted, where it asks me to comment on my answer, that would be much appreciated.",,"['sequences-and-series', 'fourier-series']"
18,Do the notions of weak and weak* convergence coincide for $\ell^1(\mathbb{N})$?,Do the notions of weak and weak* convergence coincide for ?,\ell^1(\mathbb{N}),"As my friends and I were studying for our real analysis final exam yesterday, we were playing with various examples and found ourselves asking this question: The space $\ell^1(\mathbb{N})$ is the dual of $c_0(\mathbb{N})$ , and the dual of $\ell^1(\mathbb{N})$ is $\ell^\infty(\mathbb{N})$ . Is it possible to have a sequence $\{b_n\}\in\ell^1(\mathbb{N})$ converge to $b\in\ell^1(\mathbb{N})$ weakly*, but not weakly? We knew that the weak and weak* topologies agree on a reflexive space, and because $\ell^1(\mathbb{N})$ is non-reflexive, we were wondering whether the weak and weak* topologies would agree. Parsing the definitions, this is just asking whether there is a sequence $\{b_n\}\in\ell^1(\mathbb{N})$ such that, for any $r\in c_0(\mathbb{N})$ , we have $$\sum_{k=1}^\infty (b_n)_kr_k\to\sum_{k=1}^\infty b_kr_k\quad \text{ as }n\to\infty,$$ but for some $s\in \ell^\infty(\mathbb{N})$ , $$\sum_{k=1}^\infty (b_n)_ks_k\nrightarrow\sum_{k=1}^\infty b_ks_k\quad \text{ as }n\to\infty.$$ WLOG, we can let take $b=0$ (just subtract $b$ from all the $b_n$ ), so this becomes: Is there a sequence $\{b_n\}\in\ell^1(\mathbb{N})$ such that, for any $r\in c_0(\mathbb{N})$ , we have $$\sum_{k=1}^\infty (b_n)_kr_k\to 0\quad \text{ as }n\to\infty,$$ but for some $s\in \ell^\infty(\mathbb{N})$ , $$\sum_{k=1}^\infty (b_n)_ks_k\nrightarrow 0\quad \text{ as }n\to\infty ?$$ We weren't able to come up with any examples, but of course that doesn't mean there aren't any. Also, just to double-check, were we correct in assuming that it would suffice to check whether weak and weak* convergence of sequences agreed in order to determine whether the weak and weak* topologies agreed?","As my friends and I were studying for our real analysis final exam yesterday, we were playing with various examples and found ourselves asking this question: The space is the dual of , and the dual of is . Is it possible to have a sequence converge to weakly*, but not weakly? We knew that the weak and weak* topologies agree on a reflexive space, and because is non-reflexive, we were wondering whether the weak and weak* topologies would agree. Parsing the definitions, this is just asking whether there is a sequence such that, for any , we have but for some , WLOG, we can let take (just subtract from all the ), so this becomes: Is there a sequence such that, for any , we have but for some , We weren't able to come up with any examples, but of course that doesn't mean there aren't any. Also, just to double-check, were we correct in assuming that it would suffice to check whether weak and weak* convergence of sequences agreed in order to determine whether the weak and weak* topologies agreed?","\ell^1(\mathbb{N}) c_0(\mathbb{N}) \ell^1(\mathbb{N}) \ell^\infty(\mathbb{N}) \{b_n\}\in\ell^1(\mathbb{N}) b\in\ell^1(\mathbb{N}) \ell^1(\mathbb{N}) \{b_n\}\in\ell^1(\mathbb{N}) r\in c_0(\mathbb{N}) \sum_{k=1}^\infty (b_n)_kr_k\to\sum_{k=1}^\infty b_kr_k\quad \text{ as }n\to\infty, s\in \ell^\infty(\mathbb{N}) \sum_{k=1}^\infty (b_n)_ks_k\nrightarrow\sum_{k=1}^\infty b_ks_k\quad \text{ as }n\to\infty. b=0 b b_n \{b_n\}\in\ell^1(\mathbb{N}) r\in c_0(\mathbb{N}) \sum_{k=1}^\infty (b_n)_kr_k\to 0\quad \text{ as }n\to\infty, s\in \ell^\infty(\mathbb{N}) \sum_{k=1}^\infty (b_n)_ks_k\nrightarrow 0\quad \text{ as }n\to\infty ?","['sequences-and-series', 'functional-analysis', 'topological-vector-spaces']"
19,Infinite series representation for root of polynomials?,Infinite series representation for root of polynomials?,,"Given a polynomial $p(x)=a_nx^n+\dots+a_1x+a_0$, can every root of the polynomial be represented as $\sum_{k=0}^\infty b_k$ with the $b_k$'s being a function of $a_0,\dots,a_n$ using only elementary operations of arithmetic and taking roots?","Given a polynomial $p(x)=a_nx^n+\dots+a_1x+a_0$, can every root of the polynomial be represented as $\sum_{k=0}^\infty b_k$ with the $b_k$'s being a function of $a_0,\dots,a_n$ using only elementary operations of arithmetic and taking roots?",,"['polynomials', 'sequences-and-series']"
20,"Is $\sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n}$ uniformly convergent on $(0,\pi)$?",Is  uniformly convergent on ?,"\sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n} (0,\pi)","I am trying to prove that the function $\sum_{n=1}^{\infty} \frac{\sin(n^2x)^2}{n^3}$ is not a fractal by showing that it has a well defined derivative (as fractals do not). In order to do that, I have to find out whether the function $\sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n}$ is uniformly convergent on the interval $(0,\pi)$ . If it is, the original function is not a fractal! It is clear that using the Weierstrass M-test it can be shown that: $\sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n^\alpha}$ where $\alpha > 1$ is uniformly convergent since $\sum_{n=1}^{\infty} \frac{1}{n^\alpha}$ converges and $|\frac{\sin(n^2x)}{n^\alpha}| \leq \frac{1}{n^\alpha}$ . Now the case where $\alpha = 1$ the function $\sum_{n=1}^{\infty} \frac{\sin(nx)}{n}$ (no $n^2$ in the sine) is the fourier trasnform of a sawtooth wave - so it converges uniformly everywhere except for when $x$ is a multiple of $\pi$ . I'm not sure if the function I'm investigating (with $n^2$ in the sine) would share a similar property. I have done quite a bit of research and it seems nobody has analysed this specific function yet and I'm a bit unsure as to how I can continue here. I believe that somehow the following substitution might help: $$\sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n} = \sum_{n=1}^{\infty} \frac{1}{2in} (e^{i n^2 x} - e^{-i n^2 x})$$ But I can't get to any results from here either. It would be amazing if you could give me some pointers as I'm making no progress (I'm a non-math PhD student who is stuck figuring this out) and am wasting ungodly amounts of time on this without a solution in sight. Thanks so much for your help in advance! EDIT: It can be proven that $\sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n}$ is pointwise convergent using Dirichlet's test fairly easily. <--- This is incorrect - there was a mistake in my derivation","I am trying to prove that the function is not a fractal by showing that it has a well defined derivative (as fractals do not). In order to do that, I have to find out whether the function is uniformly convergent on the interval . If it is, the original function is not a fractal! It is clear that using the Weierstrass M-test it can be shown that: where is uniformly convergent since converges and . Now the case where the function (no in the sine) is the fourier trasnform of a sawtooth wave - so it converges uniformly everywhere except for when is a multiple of . I'm not sure if the function I'm investigating (with in the sine) would share a similar property. I have done quite a bit of research and it seems nobody has analysed this specific function yet and I'm a bit unsure as to how I can continue here. I believe that somehow the following substitution might help: But I can't get to any results from here either. It would be amazing if you could give me some pointers as I'm making no progress (I'm a non-math PhD student who is stuck figuring this out) and am wasting ungodly amounts of time on this without a solution in sight. Thanks so much for your help in advance! EDIT: It can be proven that is pointwise convergent using Dirichlet's test fairly easily. <--- This is incorrect - there was a mistake in my derivation","\sum_{n=1}^{\infty} \frac{\sin(n^2x)^2}{n^3} \sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n} (0,\pi) \sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n^\alpha} \alpha > 1 \sum_{n=1}^{\infty} \frac{1}{n^\alpha} |\frac{\sin(n^2x)}{n^\alpha}| \leq \frac{1}{n^\alpha} \alpha = 1 \sum_{n=1}^{\infty} \frac{\sin(nx)}{n} n^2 x \pi n^2 \sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n} = \sum_{n=1}^{\infty} \frac{1}{2in} (e^{i n^2 x} - e^{-i n^2 x}) \sum_{n=1}^{\infty} \frac{\sin(n^2x)}{n}","['sequences-and-series', 'convergence-divergence', 'uniform-convergence']"
21,Inverse function of $x^{x^x}$,Inverse function of,x^{x^x},"How can I find the inverse function of $f(x)=x^{x^x}$ ? Has this inverse function ever been defined / studied? are there any asymptotic expansions? It would be nice if the inverse of $f(x)$ could be expressed in terms of standard mathematical functions, but it would be enough for me to know even just a few properties. The inverse of $x^{x^x}$ can be linked to the inverse of $(x + a)^x$ and to the inverse of $x e^x +a x$ , and many other functions, so knowing its properties can have many applications in solving a wide range of equations Thanks edit: The series expansion of $x^{x^x} $ at $x=0$ can be expressed as: $$x^{x^x}=x \sum_{j=0}^{\infty} \frac{\left( \ln(x^x)\right)^j}{j!}B_j\left( \ln(x)\right)\tag{1}$$ $B_j(x)$ is the Bell Polynomial. By the General Leibniz rule we have that the nth derivative of $x^{x^x}$ can be shown as $$\sum_{k=1}^n \binom{n}{k}f^{(n-k)}(x)P_j^{(k)}(\ln(x))$$ $$f(x)=x^{j+1}\Rightarrow f^{(n-k)}(x)=x^{j+1-n+k} \frac{(j+1)!}{(j+1-n+k)!}$$ $$P_j(\ln(x))=S_{j}^{(1)}\ln(x)^{j+1}+S_{j}^{(2)}\ln(x)^{j+2}+\dots+S_{j}^{(j)}\ln(x)^{j+j}$$ $S_j^{(k)}$ is the Stirling number of the second kind $$P^{(n)}_j(\ln(x))=\sum_{k=1}^j \ \sum_{r=n-k-j}^{n-1}\frac{(j+k)!}{(j+k-n+r)!}s_{n}^{(n-r)}S_{j}^{(k)}\frac{\ln(x)^{j+k-n+r}}{x^n}$$ $s_j^{(k)}$ is the Stirling number of the first kind $$P_j^{(n)}(\ln(1))=P_j^{(n)}(0)=\sum_{k=1}^j (j+k)!s_{n}^{(j+k)}S_{j}^{(k)}$$ Therefore the n th derivative of $x^{x^x}$ in $x = 1$ can be expressed as: $$D_n(1)=\sum_{j=1}^n\sum_{k=1}^n\sum_{h=1}^n(j+1)\frac{(h+j)!}{(j+1+k-n)!} \binom{n}{k}s_{n}^{(j+k)}S_{j}^{(k)}$$ With $n$ between $2$ and $10$ we have $D_n(1)={2,9,32,180,954,6524,45016,360144,3023640} $ A179230 obtaining an explicit form for the Taylor expansion coefficients for $x\to 1:$ $$ x^{x^x}=f(x)=x+\sum_{n=2}^{\infty}\frac{D_{n}(1)}{n!}(x-1)^n$$ Since the series has no constant terms, it is possible to express the inverse function $f^{-1} (x)$ by Series Reversion $$f^{-1}(x)=x-(-1+x)^2+ \frac{1}{2}(-1+x)^3+\frac{7}{6}(-1+x)^4-\frac{17}{4} (-1+x)^5+O(x^6) $$","How can I find the inverse function of ? Has this inverse function ever been defined / studied? are there any asymptotic expansions? It would be nice if the inverse of could be expressed in terms of standard mathematical functions, but it would be enough for me to know even just a few properties. The inverse of can be linked to the inverse of and to the inverse of , and many other functions, so knowing its properties can have many applications in solving a wide range of equations Thanks edit: The series expansion of at can be expressed as: is the Bell Polynomial. By the General Leibniz rule we have that the nth derivative of can be shown as is the Stirling number of the second kind is the Stirling number of the first kind Therefore the n th derivative of in can be expressed as: With between and we have A179230 obtaining an explicit form for the Taylor expansion coefficients for Since the series has no constant terms, it is possible to express the inverse function by Series Reversion","f(x)=x^{x^x} f(x) x^{x^x} (x + a)^x x e^x +a x x^{x^x}  x=0 x^{x^x}=x \sum_{j=0}^{\infty} \frac{\left( \ln(x^x)\right)^j}{j!}B_j\left( \ln(x)\right)\tag{1} B_j(x) x^{x^x} \sum_{k=1}^n \binom{n}{k}f^{(n-k)}(x)P_j^{(k)}(\ln(x)) f(x)=x^{j+1}\Rightarrow f^{(n-k)}(x)=x^{j+1-n+k} \frac{(j+1)!}{(j+1-n+k)!} P_j(\ln(x))=S_{j}^{(1)}\ln(x)^{j+1}+S_{j}^{(2)}\ln(x)^{j+2}+\dots+S_{j}^{(j)}\ln(x)^{j+j} S_j^{(k)} P^{(n)}_j(\ln(x))=\sum_{k=1}^j \ \sum_{r=n-k-j}^{n-1}\frac{(j+k)!}{(j+k-n+r)!}s_{n}^{(n-r)}S_{j}^{(k)}\frac{\ln(x)^{j+k-n+r}}{x^n} s_j^{(k)} P_j^{(n)}(\ln(1))=P_j^{(n)}(0)=\sum_{k=1}^j (j+k)!s_{n}^{(j+k)}S_{j}^{(k)} x^{x^x} x = 1 D_n(1)=\sum_{j=1}^n\sum_{k=1}^n\sum_{h=1}^n(j+1)\frac{(h+j)!}{(j+1+k-n)!} \binom{n}{k}s_{n}^{(j+k)}S_{j}^{(k)} n 2 10 D_n(1)={2,9,32,180,954,6524,45016,360144,3023640}  x\to 1:  x^{x^x}=f(x)=x+\sum_{n=2}^{\infty}\frac{D_{n}(1)}{n!}(x-1)^n f^{-1} (x) f^{-1}(x)=x-(-1+x)^2+ \frac{1}{2}(-1+x)^3+\frac{7}{6}(-1+x)^4-\frac{17}{4} (-1+x)^5+O(x^6) ","['sequences-and-series', 'functions', 'inverse', 'inverse-function']"
22,Finding result of composing operations many times,Finding result of composing operations many times,,"Consider the operator given by, $$ P = x \frac{d}{dx}$$ with, $$ P^2 = x \frac{d}{dx} ( x\frac{d}{dx}) = x \frac{d}{dx} + x^2 \frac{d^2}{dx^2}$$ or, $$ P^2 = x \frac{d}{dx} ( x\frac{d}{dx}) = x \frac{d}{dx} + x^2 \frac{d^2}{dx^2}$$ and on another application of the operator, $$ P^3 = [x \frac{d}{dx}] P^2 = x\frac{d}{dx}(x \frac{d}{dx}) + x \frac{d}{dx}( x^2 \frac{d^2}{dx^2}) = x \frac{d}{dx} + 3x^2 \frac{d^2}{dx^2} + x^3 \frac{d^3}{dx^3}  $$ I tried writing more iterations but I can't find / a general form of what $P^k$ should be. So my question is if you are given an operator as the one shown, is there any standard procedure to find the a formula for the kth iteration of the operator? The actual reason why I want to know about this Any help would be appreciated :D","Consider the operator given by, with, or, and on another application of the operator, I tried writing more iterations but I can't find / a general form of what should be. So my question is if you are given an operator as the one shown, is there any standard procedure to find the a formula for the kth iteration of the operator? The actual reason why I want to know about this Any help would be appreciated :D", P = x \frac{d}{dx}  P^2 = x \frac{d}{dx} ( x\frac{d}{dx}) = x \frac{d}{dx} + x^2 \frac{d^2}{dx^2}  P^2 = x \frac{d}{dx} ( x\frac{d}{dx}) = x \frac{d}{dx} + x^2 \frac{d^2}{dx^2}  P^3 = [x \frac{d}{dx}] P^2 = x\frac{d}{dx}(x \frac{d}{dx}) + x \frac{d}{dx}( x^2 \frac{d^2}{dx^2}) = x \frac{d}{dx} + 3x^2 \frac{d^2}{dx^2} + x^3 \frac{d^3}{dx^3}   P^k,"['sequences-and-series', 'operator-theory']"
23,Asymptotic behavior of $a_{n+1}=\frac{a_n^2+1}{2}$,Asymptotic behavior of,a_{n+1}=\frac{a_n^2+1}{2},"Define a sequence as follows: $$a_0=0$$ $$a_{n+1}=\frac{a_n^2+1}{2}$$ I would like to know the asymptotic behavior of $a_n$ . I already know (by roughly approximating $a_n$ with a differential equation) that $$a_n\sim 1-\frac{2}{n}$$ as $n\to\infty$ . However, my approximation is very crude. Can anyone find a couple more terms? I expect (from numerical data) that the next term is something like $\frac{\log(n)}{n^2}$ . In case anyone wants context for this problem, I am trying to find the optimal strategy for a game with the following rules: There are $n$ offers of money whose amounts are hidden from you, and whose quantities are random (independently and uniformly distributed from $0$ to $1$ ). One at a time, the offers are shown to you, and as you view each offer, you may either accept it or reject it. Once you accept an offer, the game is over and you may accept no more offers. It turns out that $a_n$ is the minimum value of the first offer for which you should accept that offer, in a game with $n+1$ offers. This is why I am interested in the asymptotic behavior of $a_n$ .","Define a sequence as follows: I would like to know the asymptotic behavior of . I already know (by roughly approximating with a differential equation) that as . However, my approximation is very crude. Can anyone find a couple more terms? I expect (from numerical data) that the next term is something like . In case anyone wants context for this problem, I am trying to find the optimal strategy for a game with the following rules: There are offers of money whose amounts are hidden from you, and whose quantities are random (independently and uniformly distributed from to ). One at a time, the offers are shown to you, and as you view each offer, you may either accept it or reject it. Once you accept an offer, the game is over and you may accept no more offers. It turns out that is the minimum value of the first offer for which you should accept that offer, in a game with offers. This is why I am interested in the asymptotic behavior of .",a_0=0 a_{n+1}=\frac{a_n^2+1}{2} a_n a_n a_n\sim 1-\frac{2}{n} n\to\infty \frac{\log(n)}{n^2} n 0 1 a_n n+1 a_n,"['sequences-and-series', 'recurrence-relations', 'asymptotics', 'approximation', 'iterated-function-system']"
24,How Euler arrived at power series for $a^x$ and $\ln x$,How Euler arrived at power series for  and,a^x \ln x,"I'm reading a book that reproduces Euler's arguments, and I have a few questions about a few things he does. Below are parts of the argument: Let $a > 1$.  Consider an ""infinitely small quantity"" $\omega$. $a^\omega$ $\approx$ $1$. Let $a^\omega$ = $1 + \psi$, for $\psi$ an ""infinitely small number"". Then, wishing to relate  $\psi$ and $\omega$. He says let $\psi$ = $k$$\omega$ for real number $k$. So we have $a^\omega$ = $1 + k$$\omega$. At this point apparently Euler computed some examples: for $a = 10$ and $\omega = 0.000001$ $k = 2.3026$. and for $a = 5$ and $\omega = 0.000001$ $k = 1.60944$. He then concluded that $k$ is a finite number that depends on the value of the base $a$. * Now for a finite number $x$ he sought the expansion of $a^x$. To do this he said let $j = \frac{x}{\omega}$ and expressed $x$ as $x = \omega j$, and continued. After he succeeded in finding an expansion for $a^x$ he sought the expansion for the natural logarithm (the inverse function of $a^x$ where the base $a$ is the one for which $k = 1$, in our (and Euler's) notation $a = e$). 1) How should one think of infinitely small and infinitely large numbers? 2) It's not clear to me that the value of $k$ in the derivation of a power series for $a^x$ doesn't also depend on $\omega$. As in for $a = 10$ if we take $\omega$ to be a different (small) value, it's not clear to me that $k$ wouldn't change. Unless the idea is that we let $\omega$ go to $0$ and and in the limit $a^\omega = 1 + k\omega$? 3)Not clear to me that a finite positive number $x$ can be expressed as $x = \omega j$ for some $j$, since $\omega$ is a mysterious ""infinitely small"" quantity 4)It's not clear to me that there should exist a unique base value $a$ for which $k = 1$ apriori, which Euler seems to assume exists, although I suppose the expansion of $a^x$ is in terms of $k$, and setting $x = 1$ and $k = 1$ we can compute the base $a$ for which $k = 1$ and see that it is the value we take our constant $e$ to be. Is this how Euler could've known there exists such a base? In his derivation for the expansion of $ln(1+x)$, he writes: Thus for ""infinitely small $\omega$"" $e^\omega = 1 + \omega$. Thus $ln(1 + \omega) = \omega$. So $j\omega = ln(1 + \omega)^j$ But $\omega$ although infinitely small is positive, so the larger the number chosen for $j$, the more $(1+\omega)^j$ will exceed $1$. So for any positive $x$, we can find $j$ so that $x = (1 + \omega)^j - 1$. From this we he concludes that $1 + x = (1 + \omega)^j$, and so $ln(1 + x) = j\omega$. And since $ln(1 + x)$ is finite and $\omega$ is infinitely small, $j$ must be infinitely large. 5) in deriving an expansion for $ln(1+x)$, Euler argues that $\omega$ although infinitely small is positive, so the larger the number chosen for $j$, the more $(1+\omega)^j$ will exceed $1$. So for any positive $x$, we can find $j$ so that $x = (1 + \omega)^j - 1$. This makes the infinitely small notion even more confusing, as $1 + \omega$ can be made arbitrarily large by raising $1 + \omega$ to higher powers, and so $\omega$ contributes a nonzero amount, and so how can it be infinitely small? It turns out that $j$ must be infinitely large, but we were told $(1 + \omega)^j$ is larger when a larger number is chosen for $j$. How can a larger number be chosen than an ""infinitely large"" number?","I'm reading a book that reproduces Euler's arguments, and I have a few questions about a few things he does. Below are parts of the argument: Let $a > 1$.  Consider an ""infinitely small quantity"" $\omega$. $a^\omega$ $\approx$ $1$. Let $a^\omega$ = $1 + \psi$, for $\psi$ an ""infinitely small number"". Then, wishing to relate  $\psi$ and $\omega$. He says let $\psi$ = $k$$\omega$ for real number $k$. So we have $a^\omega$ = $1 + k$$\omega$. At this point apparently Euler computed some examples: for $a = 10$ and $\omega = 0.000001$ $k = 2.3026$. and for $a = 5$ and $\omega = 0.000001$ $k = 1.60944$. He then concluded that $k$ is a finite number that depends on the value of the base $a$. * Now for a finite number $x$ he sought the expansion of $a^x$. To do this he said let $j = \frac{x}{\omega}$ and expressed $x$ as $x = \omega j$, and continued. After he succeeded in finding an expansion for $a^x$ he sought the expansion for the natural logarithm (the inverse function of $a^x$ where the base $a$ is the one for which $k = 1$, in our (and Euler's) notation $a = e$). 1) How should one think of infinitely small and infinitely large numbers? 2) It's not clear to me that the value of $k$ in the derivation of a power series for $a^x$ doesn't also depend on $\omega$. As in for $a = 10$ if we take $\omega$ to be a different (small) value, it's not clear to me that $k$ wouldn't change. Unless the idea is that we let $\omega$ go to $0$ and and in the limit $a^\omega = 1 + k\omega$? 3)Not clear to me that a finite positive number $x$ can be expressed as $x = \omega j$ for some $j$, since $\omega$ is a mysterious ""infinitely small"" quantity 4)It's not clear to me that there should exist a unique base value $a$ for which $k = 1$ apriori, which Euler seems to assume exists, although I suppose the expansion of $a^x$ is in terms of $k$, and setting $x = 1$ and $k = 1$ we can compute the base $a$ for which $k = 1$ and see that it is the value we take our constant $e$ to be. Is this how Euler could've known there exists such a base? In his derivation for the expansion of $ln(1+x)$, he writes: Thus for ""infinitely small $\omega$"" $e^\omega = 1 + \omega$. Thus $ln(1 + \omega) = \omega$. So $j\omega = ln(1 + \omega)^j$ But $\omega$ although infinitely small is positive, so the larger the number chosen for $j$, the more $(1+\omega)^j$ will exceed $1$. So for any positive $x$, we can find $j$ so that $x = (1 + \omega)^j - 1$. From this we he concludes that $1 + x = (1 + \omega)^j$, and so $ln(1 + x) = j\omega$. And since $ln(1 + x)$ is finite and $\omega$ is infinitely small, $j$ must be infinitely large. 5) in deriving an expansion for $ln(1+x)$, Euler argues that $\omega$ although infinitely small is positive, so the larger the number chosen for $j$, the more $(1+\omega)^j$ will exceed $1$. So for any positive $x$, we can find $j$ so that $x = (1 + \omega)^j - 1$. This makes the infinitely small notion even more confusing, as $1 + \omega$ can be made arbitrarily large by raising $1 + \omega$ to higher powers, and so $\omega$ contributes a nonzero amount, and so how can it be infinitely small? It turns out that $j$ must be infinitely large, but we were told $(1 + \omega)^j$ is larger when a larger number is chosen for $j$. How can a larger number be chosen than an ""infinitely large"" number?",,"['sequences-and-series', 'math-history', 'infinitesimals']"
25,a periodic sequence,a periodic sequence,,Let $w$ be a primitive $2m$th root of unity. Then the sequence generated by $$x_{n+2}=\frac{w^4x_n-(w^3+w^2)x_{n+1}-wx_nx_{n+1}}{-w-(w^3+1)x_n+w^2x_{n+1}}$$ appears to have period $2m$ for almost all initial terms. I can prove this for (very) small $m$ and check it numerically for other values of $m$. I should be grateful for any ideas regarding a general proof.,Let $w$ be a primitive $2m$th root of unity. Then the sequence generated by $$x_{n+2}=\frac{w^4x_n-(w^3+w^2)x_{n+1}-wx_nx_{n+1}}{-w-(w^3+1)x_n+w^2x_{n+1}}$$ appears to have period $2m$ for almost all initial terms. I can prove this for (very) small $m$ and check it numerically for other values of $m$. I should be grateful for any ideas regarding a general proof.,,['sequences-and-series']
26,What is the inverse of $\left[ \sum_{k=1}^{j} \left\lfloor \frac{i}{k} \right\rfloor \right]_{n \times n}$?,What is the inverse of ?,\left[ \sum_{k=1}^{j} \left\lfloor \frac{i}{k} \right\rfloor \right]_{n \times n},"For $n \in \mathbb{N}$, let $M_{n}$ denote the $n \times n$ integer matrix whereby the $(i, j)$-entry of $M_{n}$ is equal to $\sum_{k=1}^{j} \left\lfloor \frac{i}{k} \right\rfloor$, for all indices $i$ and $j$. For example, we have that:  $$ M_{5} = \left( \begin{array}{ccccc}  1 & 1 & 1 & 1 & 1 \\  2 & 3 & 3 & 3 & 3 \\  3 & 4 & 5 & 5 & 5 \\  4 & 6 & 7 & 8 & 8 \\  5 & 7 & 8 & 9 & 10 \\ \end{array} \right).$$ Since there are many important number-theoretic properties related to summations of the form $\sum_{k=1}^{n} \left\lfloor \frac{n}{k} \right\rfloor$ , it seems natural to consider generalizations and variants of such sums; this leads us to consider matrices of the form $M_{n} = \left[ \sum_{k=1}^{j} \left\lfloor \frac{i}{k} \right\rfloor \right]_{n \times n}$. Using elementary row operations inductively, it is easily seen that $M_{n}$ is invertible, and that the entries in $M_{n}^{-1}$ are in $\mathbb{Z}$. However, it is unclear as to how to construct an explicit formula for the entries of $M_{n}^{-1}$. It appears that the initial column in $M_{n}^{-1}$ may be evaluated in terms of the Möbius function , as indicated in the following proposition, which is given as a conjecture in the On-Line Encyclopedia of Integer Sequences entry labelled as A092155 . Proposition 1: For $n \in \mathbb{N}_{\geq 2}$, the first $n-1$ entries in the first column of $\left(-M_{n}\right)^{-1}$ are the same as the first $n-1$ entries in the sequence A092155 given by the first differences of $$\left(\mu(n)- \mu\left(\frac{n}{2}\right) : n \in \mathbb{N} \right),$$ letting $\mu$ denote the Möbius function, adopting the convention whereby $\mu(q)$ vanishes for $q$ in $\mathbb{Q} \setminus \mathbb{Z}.$ Why does does the above property hold for all $n \in \mathbb{N}_{\geq 2}$? This is an intriguing question, in part because the sequence A092673 given by expressions of the form $\mu(n)- \mu\left(\frac{n}{2}\right)$ is known to have interesting connections with other number-theoretic sequences such as the ruler function . To illustrate the conjecture noted above concerning A092155 , we begin by computing the inverse of $-M_{5}$: $$\left( -M_{5} \right)^{-1} = \left( \begin{array}{ccccc}  -3 & 1 & 0 & 0 & 0 \\  1 & -2 & 1 & 0 & 0 \\  2 & 0 & -2 & 1 & 0 \\  -2 & 1 & 1 & -2 & 1 \\  1 & 0 & 0 & 1 & -1 \\ \end{array} \right).$$ We thus observe that the first four entries along the first column of the above matrix are the same as the first four entries in A092155 , namely:  $-3$, $1$, $2$, and $-2$. Computing the inverse of  $$-M_{10} = \left( \begin{array}{cccccccccc}  -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 \\  -2 & -3 & -3 & -3 & -3 & -3 & -3 & -3 & -3 & -3 \\  -3 & -4 & -5 & -5 & -5 & -5 & -5 & -5 & -5 & -5 \\  -4 & -6 & -7 & -8 & -8 & -8 & -8 & -8 & -8 & -8 \\  -5 & -7 & -8 & -9 & -10 & -10 & -10 & -10 & -10 & -10 \\  -6 & -9 & -11 & -12 & -13 & -14 & -14 & -14 & -14 & -14 \\  -7 & -10 & -12 & -13 & -14 & -15 & -16 & -16 & -16 & -16 \\  -8 & -12 & -14 & -16 & -17 & -18 & -19 & -20 & -20 & -20 \\  -9 & -13 & -16 & -18 & -19 & -20 & -21 & -22 & -23 & -23 \\  -10 & -15 & -18 & -20 & -22 & -23 & -24 & -25 & -26 & -27 \\ \end{array} \right),$$ we obtain the matrix $$\left(-M_{10}\right)^{-1} = \left( \begin{array}{cccccccccc}  -3 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & -2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  2 & 0 & -2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\  -2 & 1 & 1 & -2 & 1 & 0 & 0 & 0 & 0 & 0 \\  3 & 0 & -1 & 1 & -2 & 1 & 0 & 0 & 0 & 0 \\  -3 & 0 & 1 & 0 & 1 & -2 & 1 & 0 & 0 & 0 \\  1 & 0 & 1 & -1 & 0 & 1 & -2 & 1 & 0 & 0 \\  0 & 1 & -2 & 1 & 0 & 0 & 1 & -2 & 1 & 0 \\  2 & -2 & 1 & 1 & -1 & 0 & 0 & 1 & -2 & 1 \\  -2 & 1 & 0 & -1 & 1 & 0 & 0 & 0 & 1 & -1 \\ \end{array} \right),$$   and we find that the first nine entries   $$ -3, 1, 2, -2, 3, -3, 1, 0, 2$$   are the same as the first nine entries of A092155 . Why are the entries of $M_{n}^{-1}$ above the super-diagonal all equal to $0$? It is not obvious why this would be true in general. What is the main diagonal of $M_{n}^{-1}$ of the form $3, 2, 2, ..., 2, 1$? It is not clear how this can be proven to be true for $\mathbb{N}_{\geq 3}$. A conjectured formula for the lower-left entry for $M_{n}^{-1}$ is given in A092673 . Proposition 2: The $(n, 1)$-entry of $M_{n}^{-1}$ is $\mu(n) - \mu\left(\frac{n}{2}\right)$ for $n \in \mathbb{N}$. How can we prove the above proposition, using known results concerning the Möbius function? It should be noted that there is a known formula for $\mu(n) - \mu\left(\frac{n}{2}\right)$ involving a summation containing the floor function, but it is not clear how this known identity can be used to attack the above propositions. In 2004, Jon Perry noted the following result on A092673 . Letting $x$ be an indeterminate and writing $s_{1} = x$, and letting   $$s_{i} = \binom{i+1}{2} - \sum_{j=1}^{i-1} s_{j}   \left\lfloor\frac{i}{j}\right\rfloor$$   for indices $i$ in $\mathbb{N}_{\geq 2}$, we have that the coefficient     of $x$ in $s_{n}$ is equal to $\mu(n) - \mu\left(\frac{n}{2}\right)$. How is this result related to the above propositions? We conclude with the following questions. Question 1: What is $M_{n}^{-1}$? Question 2: How can we find an explicit number-theoretic formula for a given entry in $M_{n}^{-1}$? Question 3: Have matrices of the form $M_{n}^{-1}$ been studied previously? Thank you, John M. Campbell","For $n \in \mathbb{N}$, let $M_{n}$ denote the $n \times n$ integer matrix whereby the $(i, j)$-entry of $M_{n}$ is equal to $\sum_{k=1}^{j} \left\lfloor \frac{i}{k} \right\rfloor$, for all indices $i$ and $j$. For example, we have that:  $$ M_{5} = \left( \begin{array}{ccccc}  1 & 1 & 1 & 1 & 1 \\  2 & 3 & 3 & 3 & 3 \\  3 & 4 & 5 & 5 & 5 \\  4 & 6 & 7 & 8 & 8 \\  5 & 7 & 8 & 9 & 10 \\ \end{array} \right).$$ Since there are many important number-theoretic properties related to summations of the form $\sum_{k=1}^{n} \left\lfloor \frac{n}{k} \right\rfloor$ , it seems natural to consider generalizations and variants of such sums; this leads us to consider matrices of the form $M_{n} = \left[ \sum_{k=1}^{j} \left\lfloor \frac{i}{k} \right\rfloor \right]_{n \times n}$. Using elementary row operations inductively, it is easily seen that $M_{n}$ is invertible, and that the entries in $M_{n}^{-1}$ are in $\mathbb{Z}$. However, it is unclear as to how to construct an explicit formula for the entries of $M_{n}^{-1}$. It appears that the initial column in $M_{n}^{-1}$ may be evaluated in terms of the Möbius function , as indicated in the following proposition, which is given as a conjecture in the On-Line Encyclopedia of Integer Sequences entry labelled as A092155 . Proposition 1: For $n \in \mathbb{N}_{\geq 2}$, the first $n-1$ entries in the first column of $\left(-M_{n}\right)^{-1}$ are the same as the first $n-1$ entries in the sequence A092155 given by the first differences of $$\left(\mu(n)- \mu\left(\frac{n}{2}\right) : n \in \mathbb{N} \right),$$ letting $\mu$ denote the Möbius function, adopting the convention whereby $\mu(q)$ vanishes for $q$ in $\mathbb{Q} \setminus \mathbb{Z}.$ Why does does the above property hold for all $n \in \mathbb{N}_{\geq 2}$? This is an intriguing question, in part because the sequence A092673 given by expressions of the form $\mu(n)- \mu\left(\frac{n}{2}\right)$ is known to have interesting connections with other number-theoretic sequences such as the ruler function . To illustrate the conjecture noted above concerning A092155 , we begin by computing the inverse of $-M_{5}$: $$\left( -M_{5} \right)^{-1} = \left( \begin{array}{ccccc}  -3 & 1 & 0 & 0 & 0 \\  1 & -2 & 1 & 0 & 0 \\  2 & 0 & -2 & 1 & 0 \\  -2 & 1 & 1 & -2 & 1 \\  1 & 0 & 0 & 1 & -1 \\ \end{array} \right).$$ We thus observe that the first four entries along the first column of the above matrix are the same as the first four entries in A092155 , namely:  $-3$, $1$, $2$, and $-2$. Computing the inverse of  $$-M_{10} = \left( \begin{array}{cccccccccc}  -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 \\  -2 & -3 & -3 & -3 & -3 & -3 & -3 & -3 & -3 & -3 \\  -3 & -4 & -5 & -5 & -5 & -5 & -5 & -5 & -5 & -5 \\  -4 & -6 & -7 & -8 & -8 & -8 & -8 & -8 & -8 & -8 \\  -5 & -7 & -8 & -9 & -10 & -10 & -10 & -10 & -10 & -10 \\  -6 & -9 & -11 & -12 & -13 & -14 & -14 & -14 & -14 & -14 \\  -7 & -10 & -12 & -13 & -14 & -15 & -16 & -16 & -16 & -16 \\  -8 & -12 & -14 & -16 & -17 & -18 & -19 & -20 & -20 & -20 \\  -9 & -13 & -16 & -18 & -19 & -20 & -21 & -22 & -23 & -23 \\  -10 & -15 & -18 & -20 & -22 & -23 & -24 & -25 & -26 & -27 \\ \end{array} \right),$$ we obtain the matrix $$\left(-M_{10}\right)^{-1} = \left( \begin{array}{cccccccccc}  -3 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & -2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  2 & 0 & -2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\  -2 & 1 & 1 & -2 & 1 & 0 & 0 & 0 & 0 & 0 \\  3 & 0 & -1 & 1 & -2 & 1 & 0 & 0 & 0 & 0 \\  -3 & 0 & 1 & 0 & 1 & -2 & 1 & 0 & 0 & 0 \\  1 & 0 & 1 & -1 & 0 & 1 & -2 & 1 & 0 & 0 \\  0 & 1 & -2 & 1 & 0 & 0 & 1 & -2 & 1 & 0 \\  2 & -2 & 1 & 1 & -1 & 0 & 0 & 1 & -2 & 1 \\  -2 & 1 & 0 & -1 & 1 & 0 & 0 & 0 & 1 & -1 \\ \end{array} \right),$$   and we find that the first nine entries   $$ -3, 1, 2, -2, 3, -3, 1, 0, 2$$   are the same as the first nine entries of A092155 . Why are the entries of $M_{n}^{-1}$ above the super-diagonal all equal to $0$? It is not obvious why this would be true in general. What is the main diagonal of $M_{n}^{-1}$ of the form $3, 2, 2, ..., 2, 1$? It is not clear how this can be proven to be true for $\mathbb{N}_{\geq 3}$. A conjectured formula for the lower-left entry for $M_{n}^{-1}$ is given in A092673 . Proposition 2: The $(n, 1)$-entry of $M_{n}^{-1}$ is $\mu(n) - \mu\left(\frac{n}{2}\right)$ for $n \in \mathbb{N}$. How can we prove the above proposition, using known results concerning the Möbius function? It should be noted that there is a known formula for $\mu(n) - \mu\left(\frac{n}{2}\right)$ involving a summation containing the floor function, but it is not clear how this known identity can be used to attack the above propositions. In 2004, Jon Perry noted the following result on A092673 . Letting $x$ be an indeterminate and writing $s_{1} = x$, and letting   $$s_{i} = \binom{i+1}{2} - \sum_{j=1}^{i-1} s_{j}   \left\lfloor\frac{i}{j}\right\rfloor$$   for indices $i$ in $\mathbb{N}_{\geq 2}$, we have that the coefficient     of $x$ in $s_{n}$ is equal to $\mu(n) - \mu\left(\frac{n}{2}\right)$. How is this result related to the above propositions? We conclude with the following questions. Question 1: What is $M_{n}^{-1}$? Question 2: How can we find an explicit number-theoretic formula for a given entry in $M_{n}^{-1}$? Question 3: Have matrices of the form $M_{n}^{-1}$ been studied previously? Thank you, John M. Campbell",,"['sequences-and-series', 'matrices', 'elementary-number-theory', 'ceiling-and-floor-functions', 'mobius-function']"
27,How to compute this constant with high precision $\sum_{n=1}^\infty \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)$,How to compute this constant with high precision,\sum_{n=1}^\infty \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right),"I'm interested in finding the following constant: $$b=\sum_{n=1}^\infty \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)$$ Where: $$a_1=2$$ $$a_{n+1}=a_n+\log a_n$$ This is related to my recent question where the sequence was first introduced and it was shown in the answer that: $$\lim_{n \to \infty} \frac{a_n}{n \ln n}=1$$ I wanted to see what the constant above looks like, because this is similar to how the Euler-Mascheroni constant is obtained from the harmonic series and the logarithm. The problem is, the convergence of the above series is extremely slow. And I mean so slow, that I'm not even sure what the first digit is. From Mathematica computations it seems that: $$0.1 <b <0.2$$ But I'm only sure about the upper bound, because $b$ becomes smaller as the number of terms increases. Note that even though initial partial sums are negative, $b$ becomes positive soon, because the sequence $a_n$ gets overtaken by $(n+1) \ln (n+1)$, even if they are of the same order. You can see that in the linked question. Then $a_n$ overtakes $(n+1) \ln (n+1)$ again, and partial sums start to decrease. Mathematica gives: $$\sum_{n=1}^{10^7}  \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)=0.18702446577 \dots$$ But at least the second digit is different from the true value of $b$, as can be seen by adding further terms. $$\sum_{n=1}^{10^8}  \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)=0.1738163796928 \dots$$ (In case it's important, I was keeping only $100$ digits of each $a_n$ while computing the recurrence terms. Maybe there's some loss of precision there as well). Update $$\sum_{n=1}^{10^9}  \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)=0.162 \dots$$ (I have more digits, but it's clear they don't matter at this point). And for some $10^9<N<10^{10}$ (aborted computation) we have: $$b<0.1599565$$ Can we find at least a few first digits of $b$? What methods would you suggest for accelerating the series or transforming it somehow for faster convergence? The motivation for this question is not the sequence itself (I don't believe it has any significance) but rather methods for solving this kind of problems. As a side question, can we at least prove that the series converges? I'm rather convinced it does, but just in case. For other series related to the sequence we have, reliably: $$\sum_{n=1}^\infty \frac{1}{a_n^2}=0.57409540\dots$$ $$\sum_{n=1}^\infty \frac{(-1)^{n+1}}{a_n}=0.285408\dots$$ The convergence is quite slow for these cases as well, which was expected by comparison with known series.","I'm interested in finding the following constant: $$b=\sum_{n=1}^\infty \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)$$ Where: $$a_1=2$$ $$a_{n+1}=a_n+\log a_n$$ This is related to my recent question where the sequence was first introduced and it was shown in the answer that: $$\lim_{n \to \infty} \frac{a_n}{n \ln n}=1$$ I wanted to see what the constant above looks like, because this is similar to how the Euler-Mascheroni constant is obtained from the harmonic series and the logarithm. The problem is, the convergence of the above series is extremely slow. And I mean so slow, that I'm not even sure what the first digit is. From Mathematica computations it seems that: $$0.1 <b <0.2$$ But I'm only sure about the upper bound, because $b$ becomes smaller as the number of terms increases. Note that even though initial partial sums are negative, $b$ becomes positive soon, because the sequence $a_n$ gets overtaken by $(n+1) \ln (n+1)$, even if they are of the same order. You can see that in the linked question. Then $a_n$ overtakes $(n+1) \ln (n+1)$ again, and partial sums start to decrease. Mathematica gives: $$\sum_{n=1}^{10^7}  \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)=0.18702446577 \dots$$ But at least the second digit is different from the true value of $b$, as can be seen by adding further terms. $$\sum_{n=1}^{10^8}  \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)=0.1738163796928 \dots$$ (In case it's important, I was keeping only $100$ digits of each $a_n$ while computing the recurrence terms. Maybe there's some loss of precision there as well). Update $$\sum_{n=1}^{10^9}  \left(\frac{1}{a_n}-\frac{1}{(n+1) \ln (n+1)} \right)=0.162 \dots$$ (I have more digits, but it's clear they don't matter at this point). And for some $10^9<N<10^{10}$ (aborted computation) we have: $$b<0.1599565$$ Can we find at least a few first digits of $b$? What methods would you suggest for accelerating the series or transforming it somehow for faster convergence? The motivation for this question is not the sequence itself (I don't believe it has any significance) but rather methods for solving this kind of problems. As a side question, can we at least prove that the series converges? I'm rather convinced it does, but just in case. For other series related to the sequence we have, reliably: $$\sum_{n=1}^\infty \frac{1}{a_n^2}=0.57409540\dots$$ $$\sum_{n=1}^\infty \frac{(-1)^{n+1}}{a_n}=0.285408\dots$$ The convergence is quite slow for these cases as well, which was expected by comparison with known series.",,"['sequences-and-series', 'logarithms', 'recurrence-relations', 'convergence-acceleration']"
28,Sequences with bounded iterated sums,Sequences with bounded iterated sums,,"Consider double sequences $a_{n,m}\in\mathbb R$ where $n,m\in\mathbb Z,$ satisfying $a_{n,m}=a_{n-1,m}+a_{n,m-1}$ for all $n,m\in\mathbb Z,$ and $\sup_\limits{m\in\mathbb Z}|a_{n,m}|<\infty$ for all $n\in\mathbb Z.$ An example solution is $a_{n,m}=(-1)^m2^{-n}.$ A more general solution is $$a_{n,m}=\int z^{-m}(1-z)^{-n} d\mu(z),\tag{x}$$ for a  finite signed measure $\mu$ supported on an arc of the unit circle $\{\exp(2\pi i\theta)\mid \theta\in[\epsilon,2\pi-\epsilon]\}$ with $\epsilon>0.$ I am curious if there is a characterization, but to make a specific question: Is there a solution of (1.) and (2.) not of the form (x)? My thoughts: Decreasing $n$ is taking the discrete backwards difference. Increasing $n$ is like choosing a discrete integral. Given a row $(a_{n,m})_{m\in\mathbb Z}$ such that $\sup_{m}|a_{n,m}|$ is finite, the previous row is always ok: $\sup_{m}|a_{n-1,m}|$ is automatically finite because $a_{n-1,m}=a_{n,m}-a_{n,m-1}$ Any row $(a_{n,m})_{m\in\mathbb Z}$ determines $(a_{n,m})_{n,m\in\mathbb Z}$ uniquely if a solution exists. To prove this, by linearity it suffices to show there is a unique solution of conditions 1 and 2 satisfying $a_{0,m}=0$ for all $m.$ Condition 1 gives $a_{1,m}=a_{1,m-1}$ so $a_{1,m}=a_{1,0}$ for all $m.$ This then gives $a_{2,m}=a_{1,0}+a_{2,m-1},$ so $a_{2,m}=a_{1,0}m+a_{2,0}$ for all $m.$ Condition 2 with $n=2$ forces $a_{1,0}=0,$ so $a_{1,m}=0$ for all $m.$ By induction, we get $a_{n,m}=0$ for all $n\geq 0.$ And $a_{n-1,m}=a_{n,m}-a_{n,m-1}$ implies $a_{n,m}=0$ for all $n=-1$ and hence all negative $n$ by induction.","Consider double sequences $a_{n,m}\in\mathbb R$ where $n,m\in\mathbb Z,$ satisfying $a_{n,m}=a_{n-1,m}+a_{n,m-1}$ for all $n,m\in\mathbb Z,$ and $\sup_\limits{m\in\mathbb Z}|a_{n,m}|<\infty$ for all $n\in\mathbb Z.$ An example solution is $a_{n,m}=(-1)^m2^{-n}.$ A more general solution is $$a_{n,m}=\int z^{-m}(1-z)^{-n} d\mu(z),\tag{x}$$ for a  finite signed measure $\mu$ supported on an arc of the unit circle $\{\exp(2\pi i\theta)\mid \theta\in[\epsilon,2\pi-\epsilon]\}$ with $\epsilon>0.$ I am curious if there is a characterization, but to make a specific question: Is there a solution of (1.) and (2.) not of the form (x)? My thoughts: Decreasing $n$ is taking the discrete backwards difference. Increasing $n$ is like choosing a discrete integral. Given a row $(a_{n,m})_{m\in\mathbb Z}$ such that $\sup_{m}|a_{n,m}|$ is finite, the previous row is always ok: $\sup_{m}|a_{n-1,m}|$ is automatically finite because $a_{n-1,m}=a_{n,m}-a_{n,m-1}$ Any row $(a_{n,m})_{m\in\mathbb Z}$ determines $(a_{n,m})_{n,m\in\mathbb Z}$ uniquely if a solution exists. To prove this, by linearity it suffices to show there is a unique solution of conditions 1 and 2 satisfying $a_{0,m}=0$ for all $m.$ Condition 1 gives $a_{1,m}=a_{1,m-1}$ so $a_{1,m}=a_{1,0}$ for all $m.$ This then gives $a_{2,m}=a_{1,0}+a_{2,m-1},$ so $a_{2,m}=a_{1,0}m+a_{2,0}$ for all $m.$ Condition 2 with $n=2$ forces $a_{1,0}=0,$ so $a_{1,m}=0$ for all $m.$ By induction, we get $a_{n,m}=0$ for all $n\geq 0.$ And $a_{n-1,m}=a_{n,m}-a_{n,m-1}$ implies $a_{n,m}=0$ for all $n=-1$ and hence all negative $n$ by induction.",,"['sequences-and-series', 'functional-analysis', 'measure-theory']"
29,Does this sequence have a limit?,Does this sequence have a limit?,,"Digit sums of numbers $3^m$ in base $10$ for $m=1,2,...,50$ are: $3,9,9,9,9,18,18,18,27,27,27,18,27,45,36,27,27,45,36,45,27,45,54,54,63,63,81,72,72,63,81,63,72,99,81,81,90,90,81,90,99,90,108,90,99,108,126,117,108,144$. Ratios $\dfrac {ds_{10}(3^m)}{ds_{10}(3^{m+1})}$ for $m=1,2,...,49$ to three decimal places are: $0.333,1.000,1.000,1.000,0.500,1.000,1.000,0.666,1.000,1.000,1.500,0.666,0.600,1.250,1.333,1.000,0.600,1.250,0.800,1.666,0.600,0.833,1.000,0.857,1.000,0.777,1.125,1.000,1.142,0.777,1.285,0.875,0.727,1.222,1.000,0.900,1.000,1.111,0.900,0.909,1.100,0.833,1.200,0.909,0.916,0.857,1.076,1.083,0.750$ Does there exist limit of the sequence $a(m)=\dfrac {ds_{10}(3^m)}{ds_{10}(3^{m+1})}$? I cannot resist to note some kind of chebyshevness of this question (if there is one) because we know that Chebyshev proved that if limit in the prime number theorem exists then it must be equal to $1$. It could be that this is also the case here. I also welcome any computational effort and results obtained from such an experimental work if the proof is out of reach.","Digit sums of numbers $3^m$ in base $10$ for $m=1,2,...,50$ are: $3,9,9,9,9,18,18,18,27,27,27,18,27,45,36,27,27,45,36,45,27,45,54,54,63,63,81,72,72,63,81,63,72,99,81,81,90,90,81,90,99,90,108,90,99,108,126,117,108,144$. Ratios $\dfrac {ds_{10}(3^m)}{ds_{10}(3^{m+1})}$ for $m=1,2,...,49$ to three decimal places are: $0.333,1.000,1.000,1.000,0.500,1.000,1.000,0.666,1.000,1.000,1.500,0.666,0.600,1.250,1.333,1.000,0.600,1.250,0.800,1.666,0.600,0.833,1.000,0.857,1.000,0.777,1.125,1.000,1.142,0.777,1.285,0.875,0.727,1.222,1.000,0.900,1.000,1.111,0.900,0.909,1.100,0.833,1.200,0.909,0.916,0.857,1.076,1.083,0.750$ Does there exist limit of the sequence $a(m)=\dfrac {ds_{10}(3^m)}{ds_{10}(3^{m+1})}$? I cannot resist to note some kind of chebyshevness of this question (if there is one) because we know that Chebyshev proved that if limit in the prime number theorem exists then it must be equal to $1$. It could be that this is also the case here. I also welcome any computational effort and results obtained from such an experimental work if the proof is out of reach.",,['sequences-and-series']
30,"Show that if $\sum\limits_nnE|X_{n}|^2$ converges for uncorrelated, mean zero $X_n$s, then $\sum\limits_{i=1}^{n}X_i$ converges almost surely","Show that if  converges for uncorrelated, mean zero s, then  converges almost surely",\sum\limits_nnE|X_{n}|^2 X_n \sum\limits_{i=1}^{n}X_i,"Let ($X_n$) be a sequence of uncorrelated random variables of mean zero such that  $$\sum_{n=1}^{\infty}nE|X_{n}|^2 < \infty $$ Show that $S_n = \sum_{i=1}^{n}X_i$ converges almost surely. This is the second problem of S.-T. Yau College Student Mathematics Contests 2014. I tried to solve the problem by using a similar inequality of Kolmogorov, but how to use the coefficient of $n$ before $E|X_n|^2$ makes me confused.","Let ($X_n$) be a sequence of uncorrelated random variables of mean zero such that  $$\sum_{n=1}^{\infty}nE|X_{n}|^2 < \infty $$ Show that $S_n = \sum_{i=1}^{n}X_i$ converges almost surely. This is the second problem of S.-T. Yau College Student Mathematics Contests 2014. I tried to solve the problem by using a similar inequality of Kolmogorov, but how to use the coefficient of $n$ before $E|X_n|^2$ makes me confused.",,"['sequences-and-series', 'probability-theory', 'convergence-divergence']"
31,Summing $\frac{1}{a}-\frac{1}{a^4}+\frac{1}{a^9}-\cdots$,Summing,\frac{1}{a}-\frac{1}{a^4}+\frac{1}{a^9}-\cdots,"This question comes from temperature at sphere center . I think it's a good idea to extract the essence and post a pure mathematical question to attract more thoughts. It is a physical problem and interested readers can go to the original post to find details. Anyway, after simplification the wanted value is $2 f(x)$ $$ f(x)= - \sum_{n=1}^{\infty}(-1)^n e^{-x n^2}  $$ Letting $x = \pi^2 D t /a^2$ gives the answer to the original question. If we further let $e^{x} = a$, we have a summation problem: $$ S=-\sum_{n=1}^{\infty}(-1)^n a^{-n^2} = \frac{1}{a}-\frac{1}{a^4}+\frac{1}{a^9}-\cdots $$ $a > 1$ so $S$ converges, but I don't now how to sum it. Any suggestions?","This question comes from temperature at sphere center . I think it's a good idea to extract the essence and post a pure mathematical question to attract more thoughts. It is a physical problem and interested readers can go to the original post to find details. Anyway, after simplification the wanted value is $2 f(x)$ $$ f(x)= - \sum_{n=1}^{\infty}(-1)^n e^{-x n^2}  $$ Letting $x = \pi^2 D t /a^2$ gives the answer to the original question. If we further let $e^{x} = a$, we have a summation problem: $$ S=-\sum_{n=1}^{\infty}(-1)^n a^{-n^2} = \frac{1}{a}-\frac{1}{a^4}+\frac{1}{a^9}-\cdots $$ $a > 1$ so $S$ converges, but I don't now how to sum it. Any suggestions?",,"['sequences-and-series', 'summation', 'asymptotics']"
32,Convergence to $\pi$,Convergence to,\pi,"Assume a square inscribed in a circle. Rotate it by $45^\circ$ and superimpose on the original square. Rotate by $22.5^\circ$ the resulting star like shape and superimpose on the previous shape. Continue this way, each time the rotation is half the previous one and superimpose on the last created shape. The area of the resulting shapes is converging to the area of the circle. Assuming the circle with radius of 1 (area is $\pi$), the sequence for computing the area of the resulting shape may be derived as follows: $$2^{n-1}[1-\tan(\pi /4-\pi /2^n)]$$ This converges to $\pi$, as $n \to \infty$, ""based"" on the geometrical process described. How is this proven by analytical means? A side note - you may start with any regular polygon and develop a a similar equation that converges to $\pi$ in a slightly different way. It is also interesting that the perimeter of the shapes is not converting to the expected $2\pi$.","Assume a square inscribed in a circle. Rotate it by $45^\circ$ and superimpose on the original square. Rotate by $22.5^\circ$ the resulting star like shape and superimpose on the previous shape. Continue this way, each time the rotation is half the previous one and superimpose on the last created shape. The area of the resulting shapes is converging to the area of the circle. Assuming the circle with radius of 1 (area is $\pi$), the sequence for computing the area of the resulting shape may be derived as follows: $$2^{n-1}[1-\tan(\pi /4-\pi /2^n)]$$ This converges to $\pi$, as $n \to \infty$, ""based"" on the geometrical process described. How is this proven by analytical means? A side note - you may start with any regular polygon and develop a a similar equation that converges to $\pi$ in a slightly different way. It is also interesting that the perimeter of the shapes is not converting to the expected $2\pi$.",,"['sequences-and-series', 'geometry']"
33,Conjecture: $\lim_{N \to +\infty}\frac{1}{N}\sum_{k=1}^{N}\frac{\phi(k)}{k}=\frac{6}{\pi^2}$,Conjecture:,\lim_{N \to +\infty}\frac{1}{N}\sum_{k=1}^{N}\frac{\phi(k)}{k}=\frac{6}{\pi^2},"I was playing around with the series $f(N)=\frac{1}{N}\sum_{k=1}^{N}\frac{\phi(k)}{k}$ and I found with Wolfram that $f(10,000)=0.607938$, which I noticed was very close to $\frac{6}{\pi^2}$. I am led to make the following Conjecture: $\lim_{N \to +\infty}\frac{1}{N}\sum_{k=1}^{N}\frac{\phi(k)}{k}=\frac{6}{\pi^2}$ Well, is it true? Note that its obvious that the sum is bounded above by $1$ (since $\phi(k)/k<1$), so it definitely doesn't diverge to infinity. Its also almost always decreasing. So it most likely converges.","I was playing around with the series $f(N)=\frac{1}{N}\sum_{k=1}^{N}\frac{\phi(k)}{k}$ and I found with Wolfram that $f(10,000)=0.607938$, which I noticed was very close to $\frac{6}{\pi^2}$. I am led to make the following Conjecture: $\lim_{N \to +\infty}\frac{1}{N}\sum_{k=1}^{N}\frac{\phi(k)}{k}=\frac{6}{\pi^2}$ Well, is it true? Note that its obvious that the sum is bounded above by $1$ (since $\phi(k)/k<1$), so it definitely doesn't diverge to infinity. Its also almost always decreasing. So it most likely converges.",,"['sequences-and-series', 'number-theory']"
34,Does $\sum_{k=0}^{\infty}\sin\left(\frac{\pi x}{2^k}\right)$ have a simple form with interesting properties?,Does  have a simple form with interesting properties?,\sum_{k=0}^{\infty}\sin\left(\frac{\pi x}{2^k}\right),"Does this sum converge to a simpler looking function? $$\sum\limits_{k=0}^{\infty}\sin\left(\frac{\pi x}{2^k}\right)$$ If there is no known closed form expression for this, what interesting properties does this sum have? I know this is not a concrete question, so I am just asking for opinions. Are there general series expansions for functions in terms of sinusoids with decreasing frequencies (like my example above)? What I have done so far: I tried plotting this in wolfram for a few terms(as much as the text box would allow me). I also wrote a program to numerically compute the sum up to a thousand terms. I could not find any recognizable patterns, but one interesting thing I observed (in answering my Q2 above) is that the curve is always positive on the right of y-axis and always negative on the left of y-axis. If I use positive integers for $k$ (i.e. $\frac{\pi x}{k}$) instead of using decreasing powers of two (i.e $\frac{\pi x}{2^k}$) for frequencies, I see that the curve crosses the x-axis (zero-crossing) at multiple places in both left and right planes. My thoughts on Q3. Since the highest frequency sinusoid has a frequency of $\frac{1}{2}$ in my expression, I don't expect that any function can be arbitrarily expressed using decreasing frequency sinusoids. I am merely wondering if there  is a small subset of functions that may be expressed this way (with a scaling factor for each sinusoid of course).","Does this sum converge to a simpler looking function? $$\sum\limits_{k=0}^{\infty}\sin\left(\frac{\pi x}{2^k}\right)$$ If there is no known closed form expression for this, what interesting properties does this sum have? I know this is not a concrete question, so I am just asking for opinions. Are there general series expansions for functions in terms of sinusoids with decreasing frequencies (like my example above)? What I have done so far: I tried plotting this in wolfram for a few terms(as much as the text box would allow me). I also wrote a program to numerically compute the sum up to a thousand terms. I could not find any recognizable patterns, but one interesting thing I observed (in answering my Q2 above) is that the curve is always positive on the right of y-axis and always negative on the left of y-axis. If I use positive integers for $k$ (i.e. $\frac{\pi x}{k}$) instead of using decreasing powers of two (i.e $\frac{\pi x}{2^k}$) for frequencies, I see that the curve crosses the x-axis (zero-crossing) at multiple places in both left and right planes. My thoughts on Q3. Since the highest frequency sinusoid has a frequency of $\frac{1}{2}$ in my expression, I don't expect that any function can be arbitrarily expressed using decreasing frequency sinusoids. I am merely wondering if there  is a small subset of functions that may be expressed this way (with a scaling factor for each sinusoid of course).",,"['sequences-and-series', 'summation', 'trigonometric-series']"
35,The doubly infinite series $\sum_{-\infty}^{+\infty} n$,The doubly infinite series,\sum_{-\infty}^{+\infty} n,"I have the following question from Function Theory of One Complex Variable - Greene/Krantz: Give an example of a series of complex coefficients $ a_n$ such that $\lim_{N \to + \infty} \sum_{n= -N}^{N} a_n$ exists but $\sum_{-\infty}^{+\infty} a_n$ does not converge. The answer key I have says that $a_n = n$ answers the question. I understand that $\lim_{N \to + \infty} \sum_{n= -N}^{N} n = \lim_{N\to+\infty}[-N + (-N+1) +...+ -1 +0+1+...(N-1)+N] = 0$,  as can be seen from each term cancelling. However, on the question of why $\sum_{-\infty}^{+\infty} n$ does not converge I'm a little stumped. Thinking about it intuitively, wouldn't you expect the same sort of cancellation of terms? If anyone can provide a formal proof of why this series doesn't converge, I'd be very grateful. Thanks in advance!","I have the following question from Function Theory of One Complex Variable - Greene/Krantz: Give an example of a series of complex coefficients $ a_n$ such that $\lim_{N \to + \infty} \sum_{n= -N}^{N} a_n$ exists but $\sum_{-\infty}^{+\infty} a_n$ does not converge. The answer key I have says that $a_n = n$ answers the question. I understand that $\lim_{N \to + \infty} \sum_{n= -N}^{N} n = \lim_{N\to+\infty}[-N + (-N+1) +...+ -1 +0+1+...(N-1)+N] = 0$,  as can be seen from each term cancelling. However, on the question of why $\sum_{-\infty}^{+\infty} n$ does not converge I'm a little stumped. Thinking about it intuitively, wouldn't you expect the same sort of cancellation of terms? If anyone can provide a formal proof of why this series doesn't converge, I'd be very grateful. Thanks in advance!",,"['sequences-and-series', 'complex-analysis', 'convergence-divergence']"
36,"Some heuristics about the Pisano Period, primes and Fibonacci primes. What reasons are behind them?","Some heuristics about the Pisano Period, primes and Fibonacci primes. What reasons are behind them?",,"I started to read about the Pisano Period , $\pi(n)$ , applied to the classic Fibonacci sequence and made some simple tests looking for possible properties of the sequence . I have observed the following ones, tested for the first 10000 terms : $\pi(n)=n-1 \implies n\in\Bbb P$ $\pi(n)=(n-1)/2 \implies n\in\Bbb P$ $\pi(n)=(n+1)\cdot 2 \implies n\in\Bbb P$ $k \gt 5\ ,\ F_k \in \Bbb P \implies \pi(F_k)/4=k$ I do not understand the reasons for the results: points $1\sim3$ would work as a primality test, but it does not detect all the possible primes, only a subset of them, e.g. $\{2, 5, 47, 107, 113, 139,\ldots\}$ do not comply with points $1\sim3$ and are not detected. And specially the last point, if the test is correct, would mean that the Pisano period of a Fibonacci prime is exactly four times the index of the Fibonacci prime in the Fibonacci sequence when the index is greater than $5$ (being $F_5=5$ ) . For instance: $\pi(1597)= 68$ and $\frac{68}{4}=17$ which is exactly the index of $1597$ in the Fibonacci sequence, $F_{17}=1597$ . I would like to ask the following questions: (a) Is there a counterexample? Initially I think the tests are correct, but I am not very sure about point 4. If somebody could confirm would be great. (b) What are the reasons behind the observations? I guess that it is related with the relationship of the Pisano periods and the divisibility of the Fibonacci numbers by prime numbers . (c) If the observations are correct, would we find pseudoprimes in the lists of primes detected by the rules $1 \sim 3$ ? Probably the reasons behind the observations (if no counterexamples are found) are based on some simple properties of the Fibonacci numbers, but I do not see it clearly. Any hints or ideas are very welcomed. Thank you! Update 2016/01/14 : I have modified the information about point $4$ just to keep the correct information. After testing again, there are other $n$ 's complying with $4$ and not being Fibonacci primes, so I have rewritten the statement: the Pisano period of a Fibonacci prime seems to be four times its Fibonacci index (position in the Fibonacci sequence) but that also holds for some other numbers. Addendum : Below is the graph $n \rightarrow \pi(n)$ including the fist $100$ numbers showing the rules $1\sim3$ . Rule $1$ : $\color{red}{Red}$ , Rule $2$ : $\color{blue}{Blue}$ , Rule $3$ : $\color{green}{Green}$ (click to widen).","I started to read about the Pisano Period , , applied to the classic Fibonacci sequence and made some simple tests looking for possible properties of the sequence . I have observed the following ones, tested for the first 10000 terms : I do not understand the reasons for the results: points would work as a primality test, but it does not detect all the possible primes, only a subset of them, e.g. do not comply with points and are not detected. And specially the last point, if the test is correct, would mean that the Pisano period of a Fibonacci prime is exactly four times the index of the Fibonacci prime in the Fibonacci sequence when the index is greater than (being ) . For instance: and which is exactly the index of in the Fibonacci sequence, . I would like to ask the following questions: (a) Is there a counterexample? Initially I think the tests are correct, but I am not very sure about point 4. If somebody could confirm would be great. (b) What are the reasons behind the observations? I guess that it is related with the relationship of the Pisano periods and the divisibility of the Fibonacci numbers by prime numbers . (c) If the observations are correct, would we find pseudoprimes in the lists of primes detected by the rules ? Probably the reasons behind the observations (if no counterexamples are found) are based on some simple properties of the Fibonacci numbers, but I do not see it clearly. Any hints or ideas are very welcomed. Thank you! Update 2016/01/14 : I have modified the information about point just to keep the correct information. After testing again, there are other 's complying with and not being Fibonacci primes, so I have rewritten the statement: the Pisano period of a Fibonacci prime seems to be four times its Fibonacci index (position in the Fibonacci sequence) but that also holds for some other numbers. Addendum : Below is the graph including the fist numbers showing the rules . Rule : , Rule : , Rule : (click to widen).","\pi(n) \pi(n)=n-1 \implies n\in\Bbb P \pi(n)=(n-1)/2 \implies n\in\Bbb P \pi(n)=(n+1)\cdot 2 \implies n\in\Bbb P k \gt 5\ ,\ F_k \in \Bbb P \implies \pi(F_k)/4=k 1\sim3 \{2, 5, 47, 107, 113, 139,\ldots\} 1\sim3 5 F_5=5 \pi(1597)= 68 \frac{68}{4}=17 1597 F_{17}=1597 1 \sim 3 4 n 4 n \rightarrow \pi(n) 100 1\sim3 1 \color{red}{Red} 2 \color{blue}{Blue} 3 \color{green}{Green}","['sequences-and-series', 'prime-numbers', 'fibonacci-numbers', 'primality-test', 'pseudoprimes']"
37,Does $\tan (x)$ equal $\frac{-1}{x-\frac{\pi}{2}}+\frac{-1}{x+\frac{\pi}{2}}+\frac{-1}{x-\frac{3\pi}{2}}+\frac{-1}{x+\frac{3\pi}{2}}+...$?,Does  equal ?,\tan (x) \frac{-1}{x-\frac{\pi}{2}}+\frac{-1}{x+\frac{\pi}{2}}+\frac{-1}{x-\frac{3\pi}{2}}+\frac{-1}{x+\frac{3\pi}{2}}+...,"I set my Year 12 students a question involving the sums of rational functions $\frac{1}{x-n}$. The graph of a sum of these functions looks an awful lot like a tan graph. This led me to ask: Does $\tan (x)$ equal $\frac{-1}{x-\frac{\pi}{2}}+\frac{-1}{x+\frac{\pi}{2}}+\frac{-1}{x-\frac{3\pi}{2}}+\frac{-1}{x+\frac{3\pi}{2}}+...$? I've played with it a little. I can show that the derivative of the right hand side is $1$ at $x=0$, which is promising. I haven't got any further. (I am assuming convergence of the RHS...) i. Might somebody have a delicious proof or disproof of this identity? ii. Varying the +s and -s in the sum seems to produce graphs that look like $\sec(x)$. Is there a general method to write a function that has vertical asymptotes as a sum of such reciprocal functions? Thanks!","I set my Year 12 students a question involving the sums of rational functions $\frac{1}{x-n}$. The graph of a sum of these functions looks an awful lot like a tan graph. This led me to ask: Does $\tan (x)$ equal $\frac{-1}{x-\frac{\pi}{2}}+\frac{-1}{x+\frac{\pi}{2}}+\frac{-1}{x-\frac{3\pi}{2}}+\frac{-1}{x+\frac{3\pi}{2}}+...$? I've played with it a little. I can show that the derivative of the right hand side is $1$ at $x=0$, which is promising. I haven't got any further. (I am assuming convergence of the RHS...) i. Might somebody have a delicious proof or disproof of this identity? ii. Varying the +s and -s in the sum seems to produce graphs that look like $\sec(x)$. Is there a general method to write a function that has vertical asymptotes as a sum of such reciprocal functions? Thanks!",,"['sequences-and-series', 'trigonometry', 'taylor-expansion', 'infinity', 'trigonometric-series']"
38,Convergence of $\prod_{n=1}^{\infty}\left(1-\frac{z^2}{n^2}\right)$,Convergence of,\prod_{n=1}^{\infty}\left(1-\frac{z^2}{n^2}\right),"I'm looking at some notes from my previous complex variables course and I need help verifying some things about the convergence of $$ \prod_{n=1}^{\infty}\left(1-\frac{z^2}{n^2}\right) $$ on compact subsets of $\mathbb{C}$ . My professor shows its convergence by using the property of infinite products which states that $\prod_{n=1}^{\infty}(1-a_n)$ converges if and only if $\sum_{n=1}^{\infty}\log(1-a_n)$ converges, given $a_n\neq 1$ for each $n$ . I have a few issues I would like to work out with this: $\mathbf{\frac{z^2}{n^2}=1}$ when $\mathbf{z=\pm n}$ , which one would think makes the property inapplicable . I believe I have maneuvered around this hurdle because if $z$ belongs to an arbitrary compact subset of $\mathbb{C}$ , then $\frac{z^2}{n^2}=1$ for only finitely many $n$ , there exists an $N\in\mathbb{N}$ such that $\frac{z^2}{n^2}\neq 1$ for all $n\geq N$ , and it suffices to check convergence of $\sum_{n=N}^{\infty}\log\left(1-\frac{z^2}{n^2}\right)$ . The only thing that concerns me is that this point wasn't mentioned in the notes whatsoever. Convergence $\mathbf{\sum_{n=1}^{\infty}\log\left(1-\frac{z^2}{n^2}\right)}$ is shown by noticing $\mathbf{\sum_{n=1}^{\infty}\left|\frac{z^2}{n^2}\right|}$ converges uniformly on compact subsets of $\mathbf{\mathbb{C}}$ (through the Weierstrass M-test, for example). I've thought this through but I don't see it at all. I was thinking it might be because $\log\left(1-\frac{z^2}{n^2}\right)$ , could be thought of as a function of $\frac{z^2}{n^2}$ , but this cannot hold always since $\sqrt{\frac{1}{n^2}}$ is a function of $\frac{1}{n^2}$ but the sum of these terms clearly does not converge. Any help on these points is greatly appreciated. Thanks in advance.","I'm looking at some notes from my previous complex variables course and I need help verifying some things about the convergence of on compact subsets of . My professor shows its convergence by using the property of infinite products which states that converges if and only if converges, given for each . I have a few issues I would like to work out with this: when , which one would think makes the property inapplicable . I believe I have maneuvered around this hurdle because if belongs to an arbitrary compact subset of , then for only finitely many , there exists an such that for all , and it suffices to check convergence of . The only thing that concerns me is that this point wasn't mentioned in the notes whatsoever. Convergence is shown by noticing converges uniformly on compact subsets of (through the Weierstrass M-test, for example). I've thought this through but I don't see it at all. I was thinking it might be because , could be thought of as a function of , but this cannot hold always since is a function of but the sum of these terms clearly does not converge. Any help on these points is greatly appreciated. Thanks in advance.","
\prod_{n=1}^{\infty}\left(1-\frac{z^2}{n^2}\right)
 \mathbb{C} \prod_{n=1}^{\infty}(1-a_n) \sum_{n=1}^{\infty}\log(1-a_n) a_n\neq 1 n \mathbf{\frac{z^2}{n^2}=1} \mathbf{z=\pm n} z \mathbb{C} \frac{z^2}{n^2}=1 n N\in\mathbb{N} \frac{z^2}{n^2}\neq 1 n\geq
N \sum_{n=N}^{\infty}\log\left(1-\frac{z^2}{n^2}\right) \mathbf{\sum_{n=1}^{\infty}\log\left(1-\frac{z^2}{n^2}\right)} \mathbf{\sum_{n=1}^{\infty}\left|\frac{z^2}{n^2}\right|} \mathbf{\mathbb{C}} \log\left(1-\frac{z^2}{n^2}\right) \frac{z^2}{n^2} \sqrt{\frac{1}{n^2}} \frac{1}{n^2}","['sequences-and-series', 'complex-analysis', 'convergence-divergence', 'compactness', 'infinite-product']"
39,Help me ID this weird $\pi$ formula,Help me ID this weird  formula,\pi,"I remembered, and managed to find, still gathering dust in a forgotten corner of the Internet, an old QuickBASIC program which, with a trick, can rapidly sum up a HUGE amount of terms of the famous Madhava-Gregory-Leibniz series (MGL, or just ""Gregory's series"") for pi: $$\frac{\pi}{4} = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} - \cdots$$ The old thing is located here: http://www.boo.net/~jasonp/suprgreg.bas and the comments at the beginning of the program claim that the following series can be found by some kind of ""transformation"" of the MGL series: $$\frac{\pi}{4} = \frac{5}{6} - \frac{11}{14} \frac{1 \cdot 2}{3 \cdot 5 \cdot 2} + \frac{17}{22} \frac{1 \cdot 2}{3 \cdot 5 \cdot 2} \frac{3 \cdot 4}{7 \cdot 9 \cdot 2} - \frac{23}{30} \frac{1 \cdot 2}{3 \cdot 5 \cdot 2} \frac{3 \cdot 4}{7 \cdot 9 \cdot 2} \frac{5 \cdot 6}{11 \cdot 13 \cdot 2} + \cdots$$ Where on earth does that come from?! EDIT: I used to say here that the formula did not converge correctly. It does -- I made a mistake when entering in the fractions to the calculation program to test the formula and misled myself. Assuming the pattern continues, this formula looks to be $$\frac{\pi}{4} = \sum_{n=0}^{\infty} (-1)^n \frac{5 + 6n}{6 + 8n} \prod_{j=0}^{n-1} \frac{(2j+1)(2j+2)}{2(4j+3)(4j+5)}$$ Does it ring a bell?","I remembered, and managed to find, still gathering dust in a forgotten corner of the Internet, an old QuickBASIC program which, with a trick, can rapidly sum up a HUGE amount of terms of the famous Madhava-Gregory-Leibniz series (MGL, or just ""Gregory's series"") for pi: $$\frac{\pi}{4} = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} - \cdots$$ The old thing is located here: http://www.boo.net/~jasonp/suprgreg.bas and the comments at the beginning of the program claim that the following series can be found by some kind of ""transformation"" of the MGL series: $$\frac{\pi}{4} = \frac{5}{6} - \frac{11}{14} \frac{1 \cdot 2}{3 \cdot 5 \cdot 2} + \frac{17}{22} \frac{1 \cdot 2}{3 \cdot 5 \cdot 2} \frac{3 \cdot 4}{7 \cdot 9 \cdot 2} - \frac{23}{30} \frac{1 \cdot 2}{3 \cdot 5 \cdot 2} \frac{3 \cdot 4}{7 \cdot 9 \cdot 2} \frac{5 \cdot 6}{11 \cdot 13 \cdot 2} + \cdots$$ Where on earth does that come from?! EDIT: I used to say here that the formula did not converge correctly. It does -- I made a mistake when entering in the fractions to the calculation program to test the formula and misled myself. Assuming the pattern continues, this formula looks to be $$\frac{\pi}{4} = \sum_{n=0}^{\infty} (-1)^n \frac{5 + 6n}{6 + 8n} \prod_{j=0}^{n-1} \frac{(2j+1)(2j+2)}{2(4j+3)(4j+5)}$$ Does it ring a bell?",,"['sequences-and-series', 'number-theory', 'pi']"
40,"Why can Bessel sequences be defined by the condition $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}<\infty$?",Why can Bessel sequences be defined by the condition ?,"\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}<\infty","A sequence $\{f_{k}\}_{k=1}^{\infty}$ is called a Bessel sequence in a Hilbert space $H$, if there exists $B>0$ such that  $$\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}\leq B\|f\|^{2}$$ for all $f\in H$. But my question is: is this an equivalent definition for if $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}<\infty$ for all $f\in H$, then $\{f_{k}\}_{k=1}^{\infty}$ is a Bessel sequence. If yes, how to show that if $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}<\infty$ for all $f\in H$, then $\{f_{k}\}_{k=1}^{\infty}$ is a Bessel sequence. How to relate the infinity with $||f||^2$? I was thinking can we use method of contradiction? Suppose $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}> B\|f\|^{2}$, so we have $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}=\infty$ (is this conclusion right?), so a contradiction. So we must have $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}\leq B\|f\|^{2}$. Does this make sense? Thanks in advance.","A sequence $\{f_{k}\}_{k=1}^{\infty}$ is called a Bessel sequence in a Hilbert space $H$, if there exists $B>0$ such that  $$\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}\leq B\|f\|^{2}$$ for all $f\in H$. But my question is: is this an equivalent definition for if $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}<\infty$ for all $f\in H$, then $\{f_{k}\}_{k=1}^{\infty}$ is a Bessel sequence. If yes, how to show that if $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}<\infty$ for all $f\in H$, then $\{f_{k}\}_{k=1}^{\infty}$ is a Bessel sequence. How to relate the infinity with $||f||^2$? I was thinking can we use method of contradiction? Suppose $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}> B\|f\|^{2}$, so we have $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}=\infty$ (is this conclusion right?), so a contradiction. So we must have $\sum_{k=1}^{\infty}|\langle f,f_{k}\rangle|^{2}\leq B\|f\|^{2}$. Does this make sense? Thanks in advance.",,"['sequences-and-series', 'functional-analysis', 'wavelets']"
41,Is this number rational or irrational?,Is this number rational or irrational?,,"Start writing down the Fibonacci numbers, using two digits for each one 01 01 02 03 05 08 13 21 34 55 ... Eventually you will reach three digit numbers. When that happens, any digits apart from the last two ""overflow"", and are carried back through the sequence like this ... 21 34 55 89           +     1 44           +        2 33      ----------------- = ... 21 34 55 90 46 3? ... This defines a real number, by concatenating the digits of the sequence $$\phi = 0.01\,01\,02\,03\,05\,08\,13\,21\,34\,55\,90\,46\,3\dots$$ Is $\phi$ rational or irrational?","Start writing down the Fibonacci numbers, using two digits for each one 01 01 02 03 05 08 13 21 34 55 ... Eventually you will reach three digit numbers. When that happens, any digits apart from the last two ""overflow"", and are carried back through the sequence like this ... 21 34 55 89           +     1 44           +        2 33      ----------------- = ... 21 34 55 90 46 3? ... This defines a real number, by concatenating the digits of the sequence $$\phi = 0.01\,01\,02\,03\,05\,08\,13\,21\,34\,55\,90\,46\,3\dots$$ Is $\phi$ rational or irrational?",,"['sequences-and-series', 'fibonacci-numbers']"
42,Does there exist an infinite number string without any 'refrain'?,Does there exist an infinite number string without any 'refrain'?,,"Let us consider an infinite or finite number string which consists of $0,1,2$. Then, let us call an adjacent pair of repeating number(s) ' a refrain '. For example, we have three refrains in the following string : $$01\overline{2}\ \overline{2}01202\overline{12}\  \overline{12}10\overline{201}\ \overline{201}02$$ Question : Does there exist an infinite number string without any refrain? Motivation : I've known that there exists an infinite number string which consists of $0,1,2,3$ without any refrain. This got me interested in the above expectation, but I'm facing difficutly. Can anyone help?","Let us consider an infinite or finite number string which consists of $0,1,2$. Then, let us call an adjacent pair of repeating number(s) ' a refrain '. For example, we have three refrains in the following string : $$01\overline{2}\ \overline{2}01202\overline{12}\  \overline{12}10\overline{201}\ \overline{201}02$$ Question : Does there exist an infinite number string without any refrain? Motivation : I've known that there exists an infinite number string which consists of $0,1,2,3$ without any refrain. This got me interested in the above expectation, but I'm facing difficutly. Can anyone help?",,['sequences-and-series']
43,"Let $X$ be a compact metric space. If $f:X\rightarrow \mathbb{R}$ is lower semi-continuous, then $f$ is bounded from below and attains its infimum.","Let  be a compact metric space. If  is lower semi-continuous, then  is bounded from below and attains its infimum.",X f:X\rightarrow \mathbb{R} f,"Let $X$ be a compact metric space. If $f:X\rightarrow \mathbb{R}$ is lower semi-continuous, then $f$ is bounded from below and attains its infimum. I want to prove this. This is my proof: Since $X$ is compact then it follows that $f(X)$ is compact therefore it is closed and bounded (because $f(K)$ is in $\mathbb{R}$) and therefore $f$ has an infimum, $m = \inf f(x)$. Let $(x_n)$ be a sequence in $X$. Since $X$ is compact by equivalence it is sequentially compact. There is a sub-sequence $(x_{n_k})$ of $(x_n)$ such that $f(x_{n_k})\rightarrow m \in\mathbb{R}$ since it is closed. Then by the lower semi-continuity of $f$ we have that $$m = \lim_{n\rightarrow\infty}\inf(x_n) =   \lim_{n\rightarrow\infty}\inf(x_{n_k})\geq f(x) \geq m. $$ Thus $$m\geq f(x) \geq m.$$ Hence $m = f(x)$. Therefore $f$ attains its minimum and is bounded below. (I did not assume $X$ was closed and bounded because it is not necessarily a subset of $\mathbb{R}^n$).  This also is not homework I am trying to prove the theorems my book left blank to see if I really understand concepts. Any help and comments would be greatly appreciated. Thank you in advance.","Let $X$ be a compact metric space. If $f:X\rightarrow \mathbb{R}$ is lower semi-continuous, then $f$ is bounded from below and attains its infimum. I want to prove this. This is my proof: Since $X$ is compact then it follows that $f(X)$ is compact therefore it is closed and bounded (because $f(K)$ is in $\mathbb{R}$) and therefore $f$ has an infimum, $m = \inf f(x)$. Let $(x_n)$ be a sequence in $X$. Since $X$ is compact by equivalence it is sequentially compact. There is a sub-sequence $(x_{n_k})$ of $(x_n)$ such that $f(x_{n_k})\rightarrow m \in\mathbb{R}$ since it is closed. Then by the lower semi-continuity of $f$ we have that $$m = \lim_{n\rightarrow\infty}\inf(x_n) =   \lim_{n\rightarrow\infty}\inf(x_{n_k})\geq f(x) \geq m. $$ Thus $$m\geq f(x) \geq m.$$ Hence $m = f(x)$. Therefore $f$ attains its minimum and is bounded below. (I did not assume $X$ was closed and bounded because it is not necessarily a subset of $\mathbb{R}^n$).  This also is not homework I am trying to prove the theorems my book left blank to see if I really understand concepts. Any help and comments would be greatly appreciated. Thank you in advance.",,"['sequences-and-series', 'analysis', 'continuity', 'compactness', 'supremum-and-infimum']"
44,Finite Series - reciprocals of sines,Finite Series - reciprocals of sines,,Find the sum of the finite series $$\sum _{k=1}^{k=89} \frac{1}{\sin(k^{\circ})\sin((k+1)^{\circ})}$$ This problem was asked in a test in my school. The answer seems to be $\dfrac{\cos1^{\circ}}{\sin^21^{\circ}}$ but I do not know how. I have tried reducing it using sum to product formulae and found out the actual value and it agrees well. Haven't been successful in telescoping it.,Find the sum of the finite series $$\sum _{k=1}^{k=89} \frac{1}{\sin(k^{\circ})\sin((k+1)^{\circ})}$$ This problem was asked in a test in my school. The answer seems to be $\dfrac{\cos1^{\circ}}{\sin^21^{\circ}}$ but I do not know how. I have tried reducing it using sum to product formulae and found out the actual value and it agrees well. Haven't been successful in telescoping it.,,"['sequences-and-series', 'trigonometry', 'summation', 'trigonometric-series']"
45,How find this arithmetic sequence of $n$,How find this arithmetic sequence of,n,"if there exist positive integer sequence $a_{1},a_{2},a_{3},\cdots,a_{n}$,such  that $$a_{1}a_{2},a_{2}a_{3},a_{3}a_{4},\cdots,a_{n-1}a_{n},a_{n}a_{1}$$ is arithmetic sequence,and the common difference $d=a_{i+1}a_{i+2}-a_{i}a_{i+1}\neq 0,i=1,\cdots,n-1.a_{n+1}=a_{1}$ find the value  $n$ I Think this problem is very nice,Thank you everyone. my idea: first, we have $n\ge 3$,and when $n=3$,then  $$2a_{2}a_{3}=a_{1}a_{2}+a_{3}a_{1}$$ $$\Longrightarrow \dfrac{2}{a_{1}}=\dfrac{1}{a_{2}}+\dfrac{1}{a_{3}}$$ and $$\dfrac{2}{5}=\dfrac{1}{3}+\dfrac{1}{15}$$ and when $n=4,5,\cdots,$? \ \ I think $n=2k-1$ is true,but I can't prove it","if there exist positive integer sequence $a_{1},a_{2},a_{3},\cdots,a_{n}$,such  that $$a_{1}a_{2},a_{2}a_{3},a_{3}a_{4},\cdots,a_{n-1}a_{n},a_{n}a_{1}$$ is arithmetic sequence,and the common difference $d=a_{i+1}a_{i+2}-a_{i}a_{i+1}\neq 0,i=1,\cdots,n-1.a_{n+1}=a_{1}$ find the value  $n$ I Think this problem is very nice,Thank you everyone. my idea: first, we have $n\ge 3$,and when $n=3$,then  $$2a_{2}a_{3}=a_{1}a_{2}+a_{3}a_{1}$$ $$\Longrightarrow \dfrac{2}{a_{1}}=\dfrac{1}{a_{2}}+\dfrac{1}{a_{3}}$$ and $$\dfrac{2}{5}=\dfrac{1}{3}+\dfrac{1}{15}$$ and when $n=4,5,\cdots,$? \ \ I think $n=2k-1$ is true,but I can't prove it",,['sequences-and-series']
46,Given $\Sigma a_n$ diverges show that $\Sigma \frac{a_n}{1+a_n}$ diverges. [duplicate],Given  diverges show that  diverges. [duplicate],\Sigma a_n \Sigma \frac{a_n}{1+a_n},"This question already has answers here : Positive series problem: $\sum\limits_{n\geq1}a_n=+\infty$ implies $\sum_{n\geq1}\frac{a_n}{1+a_n}=+\infty$ (7 answers) Closed 8 years ago . Intuitively speaking, I first thought that if the series $\Sigma a_n$ is divergent then $$\lim_{n \to \infty} a_n \ne 0$$ therefore it was clear that $\Sigma \frac{a_n}{1+a_n} $ would be divergent, but when I thought about it there are cases where the limit of the sequence does approach to $0$ and yet diverge, like the harmonic series. Then I tried to go with since the sequence diverges, the series is not Cauchy (I m not even 100% sure if this is true but I tried) $$|\sum_{i = m}^{n} a_n| \gt \epsilon$$ and derive the other series to not be Cauchy as well, only to not being able to reach. I appreciate all the help.","This question already has answers here : Positive series problem: $\sum\limits_{n\geq1}a_n=+\infty$ implies $\sum_{n\geq1}\frac{a_n}{1+a_n}=+\infty$ (7 answers) Closed 8 years ago . Intuitively speaking, I first thought that if the series $\Sigma a_n$ is divergent then $$\lim_{n \to \infty} a_n \ne 0$$ therefore it was clear that $\Sigma \frac{a_n}{1+a_n} $ would be divergent, but when I thought about it there are cases where the limit of the sequence does approach to $0$ and yet diverge, like the harmonic series. Then I tried to go with since the sequence diverges, the series is not Cauchy (I m not even 100% sure if this is true but I tried) $$|\sum_{i = m}^{n} a_n| \gt \epsilon$$ and derive the other series to not be Cauchy as well, only to not being able to reach. I appreciate all the help.",,"['sequences-and-series', 'analysis', 'cauchy-sequences']"
47,Taylor series for logarithm converges towards logarithm,Taylor series for logarithm converges towards logarithm,,"Is there a way to show that the Taylor series around 0 of $f(x) = \ln(1-x)$ converges towards $f$ on the interval $(-1,1)$, just by considering the remainder from the Taylor polynomial? I'm having a little trouble with this. The series is $ T_n(x) = - \sum_{k=1}^n \frac{x^k}{k}$ The convergence on $(-1,0]$ is not a problem, but on $[0,1)$ things start to get a little complicated. Let $0<x<1$. then $|f^{(n+1)}(t)| = \frac{n!}{(1-t)^{n+1}} \leq \frac{n!}{(1-x)^{n+1}}$ for all $t \in [0,x]$. The Lagrange form of the remainder then tells us that $|R_n(x)| \leq \frac{n!}{(1-x)^{n+1} (n+1)!}x^{n+1} = \frac{1}{n+1} \left( \frac{x}{1-x} \right)^n$ But if $x > 1/2$, this goes to infinity. I have tried to use the integral form of the remainder as well, but with no luck. Using the machinery of power series, it's easy to prove the convergence. But is there a way using only theory about Taylor polynomials?","Is there a way to show that the Taylor series around 0 of $f(x) = \ln(1-x)$ converges towards $f$ on the interval $(-1,1)$, just by considering the remainder from the Taylor polynomial? I'm having a little trouble with this. The series is $ T_n(x) = - \sum_{k=1}^n \frac{x^k}{k}$ The convergence on $(-1,0]$ is not a problem, but on $[0,1)$ things start to get a little complicated. Let $0<x<1$. then $|f^{(n+1)}(t)| = \frac{n!}{(1-t)^{n+1}} \leq \frac{n!}{(1-x)^{n+1}}$ for all $t \in [0,x]$. The Lagrange form of the remainder then tells us that $|R_n(x)| \leq \frac{n!}{(1-x)^{n+1} (n+1)!}x^{n+1} = \frac{1}{n+1} \left( \frac{x}{1-x} \right)^n$ But if $x > 1/2$, this goes to infinity. I have tried to use the integral form of the remainder as well, but with no luck. Using the machinery of power series, it's easy to prove the convergence. But is there a way using only theory about Taylor polynomials?",,"['sequences-and-series', 'taylor-expansion']"
48,Is it possible to use regularization methods on the Harmonic Series?,Is it possible to use regularization methods on the Harmonic Series?,,I recently learned about summation methods when dealing with divergent series to give them a finite value. An example of this isusing Cesàro summation on Grandi's series to get 1/2. However every method I know of is unable to sum the harmonic series. Are there any summation methods that work on the harmonic series or is it provably impossible to sum this series?,I recently learned about summation methods when dealing with divergent series to give them a finite value. An example of this isusing Cesàro summation on Grandi's series to get 1/2. However every method I know of is unable to sum the harmonic series. Are there any summation methods that work on the harmonic series or is it provably impossible to sum this series?,,[]
49,"How to solve the recurrence relation $a_{1}=2, a_{n}=\frac{a_{n-1}+2}{2 a_{n-1}+1}(n \geq 2)$ with generating functions?",How to solve the recurrence relation  with generating functions?,"a_{1}=2, a_{n}=\frac{a_{n-1}+2}{2 a_{n-1}+1}(n \geq 2)","There's already a way to solve it, called ""fixed point method"", that is, from the relation we define its characteristic equation as $x=\dfrac{x+2}{2x+1}$ ，then we have $x_1=1,x_2=-1$ . So the following relation established: $$ \frac{a_{n}-1}{a_{n}+1}=\frac{\frac{a_{n-1}+2}{2 a_{n-1}+1}-1}{\frac{a_{n-1}+2}{2 a_{n-1}+1}+1}=-\frac{1}{3} \cdot \frac{a_{n-1}-1}{a_{n-1}+1} $$ It is obvious that $\displaystyle \frac{a_{n}-1}{a_{n}+1}=\frac{1}{3} \cdot\left(-\frac{1}{3}\right)^{n-1}$ , and then we have $a_{n}=\dfrac{3^{n}-(-1)^{n}}{3^{n}+(-1)^{n}}$ . My question is, how to solve this kind of recurrence relations with generating functions ? Also, ""fixed points"" can be applied to solving recurrences like $a_{n+1}=\dfrac{a_{n}^{2}+b}{2 a_{n}+d}$ , which seems impossible to solve using generating functions.","There's already a way to solve it, called ""fixed point method"", that is, from the relation we define its characteristic equation as ，then we have . So the following relation established: It is obvious that , and then we have . My question is, how to solve this kind of recurrence relations with generating functions ? Also, ""fixed points"" can be applied to solving recurrences like , which seems impossible to solve using generating functions.","x=\dfrac{x+2}{2x+1} x_1=1,x_2=-1 
\frac{a_{n}-1}{a_{n}+1}=\frac{\frac{a_{n-1}+2}{2 a_{n-1}+1}-1}{\frac{a_{n-1}+2}{2 a_{n-1}+1}+1}=-\frac{1}{3} \cdot \frac{a_{n-1}-1}{a_{n-1}+1}
 \displaystyle \frac{a_{n}-1}{a_{n}+1}=\frac{1}{3} \cdot\left(-\frac{1}{3}\right)^{n-1} a_{n}=\dfrac{3^{n}-(-1)^{n}}{3^{n}+(-1)^{n}} a_{n+1}=\dfrac{a_{n}^{2}+b}{2 a_{n}+d}","['sequences-and-series', 'recurrence-relations', 'systems-of-equations', 'generating-functions']"
50,The limit $\lim_{x \to 0-} \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4} \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt$,The limit,\lim_{x \to 0-} \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4} \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt,"A while back I derived the following expression valid for $x>0$ : $$\sum_{n=1}^\infty e^{-(n+x)^2}= \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4}  \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt$$ While the integral doesn't converge for $x=0$ , it has a right limit: $$\lim_{x \to 0+} \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4}  \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt=\sum_{n=1}^\infty e^{-n^2}=\frac{1}{2} \left(\vartheta _3\left(0,\frac{1}{e}\right)-1\right)$$ But, despite the fact that the integral converges for $x<0$ , it converges to a different limit from the left side, as can be seen from the numerical plot by Mathematica: Surprisingly enough, by numerical integration with Mathematica, we seem to have: $$\lim_{x \to 0-} \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4}  \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt \approx -\frac{1}{2} \left(\vartheta _3\left(0,\frac{1}{e}\right)+1\right)$$ In other words, the limits are related as $L^- = -1-L^+$ . Is this correct? And why? Here's the derivation of the first equality https://math.stackexchange.com/a/2751575/269624 .","A while back I derived the following expression valid for : While the integral doesn't converge for , it has a right limit: But, despite the fact that the integral converges for , it converges to a different limit from the left side, as can be seen from the numerical plot by Mathematica: Surprisingly enough, by numerical integration with Mathematica, we seem to have: In other words, the limits are related as . Is this correct? And why? Here's the derivation of the first equality https://math.stackexchange.com/a/2751575/269624 .","x>0 \sum_{n=1}^\infty e^{-(n+x)^2}= \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4}  \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt x=0 \lim_{x \to 0+} \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4}  \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt=\sum_{n=1}^\infty e^{-n^2}=\frac{1}{2} \left(\vartheta _3\left(0,\frac{1}{e}\right)-1\right) x<0 \lim_{x \to 0-} \frac{e^{-x^2}}{\sqrt{\pi}} \int_0^\infty e^{-t^2/4}  \frac{e^{2x} \cos t-1}{e^{4x}-2e^{2x} \cos t+1 } dt \approx -\frac{1}{2} \left(\vartheta _3\left(0,\frac{1}{e}\right)+1\right) L^- = -1-L^+","['sequences-and-series', 'limits', 'definite-integrals']"
51,How to prove that $\sum_{n=1}^{\infty}\frac{\left ( -1 \right )^{n+1}n}{n^{2}+x^{2}}$ is always positive for all real $x$?,How to prove that  is always positive for all real ?,\sum_{n=1}^{\infty}\frac{\left ( -1 \right )^{n+1}n}{n^{2}+x^{2}} x,"How to prove that $$\sum_{n=1}^{\infty}\frac{\left ( -1 \right )^{n+1}n}{n^{2}+x^{2}}>0$$ for all real x? It may looks like a very easy problem, but as it is an alternating series and does NOT converge ABSOLUTELY, it seems very hard -- or even impossible -- to use any inequalities to estimate. Moreover, the limit $$\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\frac{\left ( -1 \right )^{n+1}nx^{2}}{n^{2}+x^{2}}=\frac{1}{4}$$. If we can prove this, it will be easier to prove that the series is positive. I used Abel transformation formula (summation by parts) and got that it is the same value as $$\sum_{n=1}^{\infty}\sum_{k=n}^{\infty}\frac{\left(-1\right)^{k+1}}{k^{2}+x^{2}}$$, and then I don't know if the problem get easier. Now we have to prove that $\displaystyle\left|\sum_{k=n}^{\infty}\frac{\left(-1\right)^{k+1}}{k^{2}+x^{2}}\right|$ is strictly decreasing for $n\in\mathbb{N}$, that is equivalent to prove that $$\frac{1}{n^2+x^2}\gt2\left|\sum_{k=n+1}^{\infty}\frac{\left(-1\right)^k}{k^2+x^2}\right|\quad \forall n\in\mathbb{N},x\in\mathbb{R}$$ Anyone has some ideas to contnue my proof?","How to prove that $$\sum_{n=1}^{\infty}\frac{\left ( -1 \right )^{n+1}n}{n^{2}+x^{2}}>0$$ for all real x? It may looks like a very easy problem, but as it is an alternating series and does NOT converge ABSOLUTELY, it seems very hard -- or even impossible -- to use any inequalities to estimate. Moreover, the limit $$\lim_{x\rightarrow\infty}\sum_{n=1}^{\infty}\frac{\left ( -1 \right )^{n+1}nx^{2}}{n^{2}+x^{2}}=\frac{1}{4}$$. If we can prove this, it will be easier to prove that the series is positive. I used Abel transformation formula (summation by parts) and got that it is the same value as $$\sum_{n=1}^{\infty}\sum_{k=n}^{\infty}\frac{\left(-1\right)^{k+1}}{k^{2}+x^{2}}$$, and then I don't know if the problem get easier. Now we have to prove that $\displaystyle\left|\sum_{k=n}^{\infty}\frac{\left(-1\right)^{k+1}}{k^{2}+x^{2}}\right|$ is strictly decreasing for $n\in\mathbb{N}$, that is equivalent to prove that $$\frac{1}{n^2+x^2}\gt2\left|\sum_{k=n+1}^{\infty}\frac{\left(-1\right)^k}{k^2+x^2}\right|\quad \forall n\in\mathbb{N},x\in\mathbb{R}$$ Anyone has some ideas to contnue my proof?",,"['sequences-and-series', 'analysis']"
52,Show that $\sum_{n=1}^\infty \frac{n^2}{(n+1)!}=e-1$,Show that,\sum_{n=1}^\infty \frac{n^2}{(n+1)!}=e-1,Show that: $$\sum^\infty_{n=1} \frac{n^2}{(n+1)!}=e-1$$ First I will re-define the sum: $$\sum^\infty_{n=1} \frac{n^2}{(n+1)!} = \sum^\infty_{n=1} \frac{n^2-1+1}{(n+1)!} - \sum^\infty_{n=1}\frac{n-1}{n!} + \sum^\infty_{n=1} \frac{1}{(nm)!}$$ Bow I will define e: $$e^2 = 1+ \frac{2}{1!} + \frac{x^2}{2!} + ... + \infty$$ $$e' = 1 + \frac{1}{1!} + \frac{1}{2!} + ... + \infty$$ $$(e'-2) = \sum^\infty_{n=1} \frac{1}{(n+1)!}$$ Now I need help.,Show that: $$\sum^\infty_{n=1} \frac{n^2}{(n+1)!}=e-1$$ First I will re-define the sum: $$\sum^\infty_{n=1} \frac{n^2}{(n+1)!} = \sum^\infty_{n=1} \frac{n^2-1+1}{(n+1)!} - \sum^\infty_{n=1}\frac{n-1}{n!} + \sum^\infty_{n=1} \frac{1}{(nm)!}$$ Bow I will define e: $$e^2 = 1+ \frac{2}{1!} + \frac{x^2}{2!} + ... + \infty$$ $$e' = 1 + \frac{1}{1!} + \frac{1}{2!} + ... + \infty$$ $$(e'-2) = \sum^\infty_{n=1} \frac{1}{(n+1)!}$$ Now I need help.,,"['sequences-and-series', 'exponential-function']"
53,"I derived a new formula related to arithmetic sequences, I think!","I derived a new formula related to arithmetic sequences, I think!",,"First of all, I am a 12th grader so I don't know how to write research notes. So please forgive me if my writing is not so impressive! I don't know what to do to tell the world about whatever I found. So, may be it's stupid, but I am posting my formula here in Stack Exchange. Recently I was trying to figure out how to find the nth term in a series, or sequence, where the differences ($d$) between the elements of the series are not constant, but if $d$ for each $A_n - A_{(n-1)}$ is written in a sequence, it gives an AP. For example, the sequence: $A = 7, 14, 28, 49, ... n$ is not in AP But taking the differences for all $A_n - A_{(n - 1)}$, where $n > 1$, we get an AP: $$A' = 7, 14, 21... $$ The above AP has a common difference of 7. In order to find $A_n$, We can use the below formula: $$A_n = \left(\frac {n - 1}{2} \{2a' + (n - 2) d' \}\right) + a_1$$ Where, $a_1$ is the first element in the sequence $$a' = a_2 - a_1$$ $$d' = a_3 - (a' + a_2)$$ I can't describe here how I get to that point. Here is the application of the formula in the following sequence: $$A = 7, 14, 28, 49, ... n$$ In sequence, let $n = 3$ and we have to find $A_n$ $$a_1 = 7$$ $$a' = 14 - 7 = 7$$ $$d' = 28 - (14 + 7) = 7$$ By formula: $$A_n = \frac {n - 1}{2} \{2a' + (n - 2) d' \} + a_1$$ $$A_3 = \frac {3 - 1}{2} \{2 \times 7 + (3 - 2) 7 \} + 7$$ $$A_3 = \frac {2}{2} \{14 + 7 \} + 7 = 28$$ Notes: 1) I am still testing it. 2) There are other methods exist to find $A_n$ in these type of sequences, may be they are easier, I don't know. 3) I am not sure if I am the first person to derive this formula, if I am not, then I apologize. Let me know, if someone has found something wrong with this.","First of all, I am a 12th grader so I don't know how to write research notes. So please forgive me if my writing is not so impressive! I don't know what to do to tell the world about whatever I found. So, may be it's stupid, but I am posting my formula here in Stack Exchange. Recently I was trying to figure out how to find the nth term in a series, or sequence, where the differences ($d$) between the elements of the series are not constant, but if $d$ for each $A_n - A_{(n-1)}$ is written in a sequence, it gives an AP. For example, the sequence: $A = 7, 14, 28, 49, ... n$ is not in AP But taking the differences for all $A_n - A_{(n - 1)}$, where $n > 1$, we get an AP: $$A' = 7, 14, 21... $$ The above AP has a common difference of 7. In order to find $A_n$, We can use the below formula: $$A_n = \left(\frac {n - 1}{2} \{2a' + (n - 2) d' \}\right) + a_1$$ Where, $a_1$ is the first element in the sequence $$a' = a_2 - a_1$$ $$d' = a_3 - (a' + a_2)$$ I can't describe here how I get to that point. Here is the application of the formula in the following sequence: $$A = 7, 14, 28, 49, ... n$$ In sequence, let $n = 3$ and we have to find $A_n$ $$a_1 = 7$$ $$a' = 14 - 7 = 7$$ $$d' = 28 - (14 + 7) = 7$$ By formula: $$A_n = \frac {n - 1}{2} \{2a' + (n - 2) d' \} + a_1$$ $$A_3 = \frac {3 - 1}{2} \{2 \times 7 + (3 - 2) 7 \} + 7$$ $$A_3 = \frac {2}{2} \{14 + 7 \} + 7 = 28$$ Notes: 1) I am still testing it. 2) There are other methods exist to find $A_n$ in these type of sequences, may be they are easier, I don't know. 3) I am not sure if I am the first person to derive this formula, if I am not, then I apologize. Let me know, if someone has found something wrong with this.",,"['sequences-and-series', 'discrete-mathematics']"
54,Closed form for $\sum_{n=1}^{\infty} \frac{1}{1+n+n^2+\cdots+n^a}$,Closed form for,\sum_{n=1}^{\infty} \frac{1}{1+n+n^2+\cdots+n^a},"Does anyone know if there happens to exist a closed form solution for this sum: $$\sum_{n=1}^{\infty} \frac{1}{1+n+n^2+\cdots+n^a}$$ For low values of $a$, Wolfram Alpha gives a closed form in terms of the polygamma function function of order $0$ (derivative of the logarithm of the gamma function), so I am wondering if there is a general closed form in terms of $a$. Thanks!","Does anyone know if there happens to exist a closed form solution for this sum: $$\sum_{n=1}^{\infty} \frac{1}{1+n+n^2+\cdots+n^a}$$ For low values of $a$, Wolfram Alpha gives a closed form in terms of the polygamma function function of order $0$ (derivative of the logarithm of the gamma function), so I am wondering if there is a general closed form in terms of $a$. Thanks!",,"['sequences-and-series', 'closed-form', 'polygamma']"
55,Generalizing the Fibonacci sum $\sum_{n=0}^{\infty}\frac{F_n}{10^n} = \frac{10}{89}$,Generalizing the Fibonacci sum,\sum_{n=0}^{\infty}\frac{F_n}{10^n} = \frac{10}{89},"Given the Fibonacci , tribonacci , and tetranacci numbers, $$F_n = 0,1,1,2,3,5,8\dots$$ $$T_n = 0, 1, 1, 2, 4, 7, 13, 24,\dots$$ $$U_n = 0, 1, 1, 2, 4, 8, 15, 29, \dots$$ and so on, how do we show that, $$\sum_{n=0}^{\infty}\frac{F_n}{10^n} = \frac{10}{89}$$ $$\sum_{n=0}^{\infty}\frac{T_n}{10^n} = \frac{100}{889}$$ $$\sum_{n=0}^{\infty}\frac{U_n}{10^n} = \frac{1000}{8889}$$ or, in general, $$\sum_{n=0}^{\infty}\frac{S_n}{p^n} = \frac{(1-p)p^{k-1}}{(2-p)p^k-1}$$ where the above were just the cases $k=2,3,4$, and $p=10$? P.S. Related post .","Given the Fibonacci , tribonacci , and tetranacci numbers, $$F_n = 0,1,1,2,3,5,8\dots$$ $$T_n = 0, 1, 1, 2, 4, 7, 13, 24,\dots$$ $$U_n = 0, 1, 1, 2, 4, 8, 15, 29, \dots$$ and so on, how do we show that, $$\sum_{n=0}^{\infty}\frac{F_n}{10^n} = \frac{10}{89}$$ $$\sum_{n=0}^{\infty}\frac{T_n}{10^n} = \frac{100}{889}$$ $$\sum_{n=0}^{\infty}\frac{U_n}{10^n} = \frac{1000}{8889}$$ or, in general, $$\sum_{n=0}^{\infty}\frac{S_n}{p^n} = \frac{(1-p)p^{k-1}}{(2-p)p^k-1}$$ where the above were just the cases $k=2,3,4$, and $p=10$? P.S. Related post .",,"['sequences-and-series', 'fibonacci-numbers']"
56,How to evaluate the following sum? $\sum_{i = 1}^n \left\lfloor \frac{3n-i}{2}\right\rfloor.$,How to evaluate the following sum?,\sum_{i = 1}^n \left\lfloor \frac{3n-i}{2}\right\rfloor.,"What is the value of the following sum?  $$\sum_{i = 1}^n \left\lfloor \dfrac{3n-i}{2}\right\rfloor.$$ Especially how to handle the sums with floors? This sum appeared while solving this problem . My work: I tried ignoring floor and assuming that it will count an extra $\frac12$ for exactly $\left\lfloor \tfrac n2 \right\rfloor$ times, but the values do not match for the small test cases that I solve with hand.","What is the value of the following sum?  $$\sum_{i = 1}^n \left\lfloor \dfrac{3n-i}{2}\right\rfloor.$$ Especially how to handle the sums with floors? This sum appeared while solving this problem . My work: I tried ignoring floor and assuming that it will count an extra $\frac12$ for exactly $\left\lfloor \tfrac n2 \right\rfloor$ times, but the values do not match for the small test cases that I solve with hand.",,"['sequences-and-series', 'summation']"
57,"Find the limits of ""Almost Divergent"" Series","Find the limits of ""Almost Divergent"" Series",,Find the following limits: $ \lim_{\varepsilon\rightarrow 0}\sum_{n=0}^{+\infty}\frac{(-1)^n}{1+n\epsilon} $ $ \lim_{\varepsilon\rightarrow 0}\sum_{n=0}^{+\infty}\frac{(-1)^n}{1+n^{2}\epsilon} $,Find the following limits: $ \lim_{\varepsilon\rightarrow 0}\sum_{n=0}^{+\infty}\frac{(-1)^n}{1+n\epsilon} $ $ \lim_{\varepsilon\rightarrow 0}\sum_{n=0}^{+\infty}\frac{(-1)^n}{1+n^{2}\epsilon} $,,['sequences-and-series']
58,"Find $\sum_{m=1}^{\infty}\frac{(2m-1)!!}{2^m \, m! \, m^{n+1}} $",Find,"\sum_{m=1}^{\infty}\frac{(2m-1)!!}{2^m \, m! \, m^{n+1}} ","I need to find the value of $$ S(n)=\sum_{m=1}^{\infty}\frac{(2m-1)!!}{2^m \, m! \, m^{n+1}} $$ where $n$ is an integer greater than or equal to $0$. Mathematica can do individual cases, $S(0) = \ln(4)$ for example, but it can't do the general case.","I need to find the value of $$ S(n)=\sum_{m=1}^{\infty}\frac{(2m-1)!!}{2^m \, m! \, m^{n+1}} $$ where $n$ is an integer greater than or equal to $0$. Mathematica can do individual cases, $S(0) = \ln(4)$ for example, but it can't do the general case.",,['sequences-and-series']
59,Proving the AM:GM inequality [duplicate],Proving the AM:GM inequality [duplicate],,This question already has answers here : Proofs of AM-GM inequality (27 answers) Closed 9 years ago . I am doing past exam papers preparing for the finals and I came across this questions about three times: Prove that: $$\frac{a_{1}+a_{2}+\cdots+a_{n}}{n}\geq \sqrt[n]{a_{1}.a_{2}...a_{n}}$$ Different papers require different approaches to proving it but most of them use induction. Can someone please explain to me how to prove it using induction? I can do the first steps but get stuck at proving that: $$\frac{a_{1}+a_{2}+\cdots+a_{k}+a_{k+1}}{k+1}\geq \left ( \frac{a_{1}+a_{2}+\cdots+a_{k}}{k} \right )^{\frac{1}{k+1}}\left ( a_{k+1} \right )^{\frac{1}{k+1}}$$,This question already has answers here : Proofs of AM-GM inequality (27 answers) Closed 9 years ago . I am doing past exam papers preparing for the finals and I came across this questions about three times: Prove that: $$\frac{a_{1}+a_{2}+\cdots+a_{n}}{n}\geq \sqrt[n]{a_{1}.a_{2}...a_{n}}$$ Different papers require different approaches to proving it but most of them use induction. Can someone please explain to me how to prove it using induction? I can do the first steps but get stuck at proving that: $$\frac{a_{1}+a_{2}+\cdots+a_{k}+a_{k+1}}{k+1}\geq \left ( \frac{a_{1}+a_{2}+\cdots+a_{k}}{k} \right )^{\frac{1}{k+1}}\left ( a_{k+1} \right )^{\frac{1}{k+1}}$$,,"['sequences-and-series', 'inequality', 'induction', 'products']"
60,Proving Newton's Binomial Theorem,Proving Newton's Binomial Theorem,,"So, I've done most of the problem to this point, but just cannot figure out the last piece.  I may just be missing the math skills needed to complete the proof (differential equations). Problem (from Rudin): If $\alpha$ is real and $-1 < x < 1$, prove Newton's binomial theorem; $(1+x)^\alpha$ = $1 + \sum{\frac{\alpha (\alpha-1) \dots(\alpha - n + 1)}{n!}}$$x^n$ Where the sum goes from $n=1$ to infinity.  The book suggests calling the right side $f(x)$, proving the series converges, proving $(1+x)f'(x) = \alpha f(x)$. I've done all this.  All that is left is solving this differential equation, which I simply cannot figure out.  Could anyone help with this last step?  It would be appreciated!","So, I've done most of the problem to this point, but just cannot figure out the last piece.  I may just be missing the math skills needed to complete the proof (differential equations). Problem (from Rudin): If $\alpha$ is real and $-1 < x < 1$, prove Newton's binomial theorem; $(1+x)^\alpha$ = $1 + \sum{\frac{\alpha (\alpha-1) \dots(\alpha - n + 1)}{n!}}$$x^n$ Where the sum goes from $n=1$ to infinity.  The book suggests calling the right side $f(x)$, proving the series converges, proving $(1+x)f'(x) = \alpha f(x)$. I've done all this.  All that is left is solving this differential equation, which I simply cannot figure out.  Could anyone help with this last step?  It would be appreciated!",,"['sequences-and-series', 'analysis', 'ordinary-differential-equations']"
61,Infinite series where each term is the square of the last,Infinite series where each term is the square of the last,,"Is there a closed-form, in terms of elementary functions or otherwise, for the power series $x+x^2+x^4+x^8+x^{16}+...$, where each term is the square of the last?","Is there a closed-form, in terms of elementary functions or otherwise, for the power series $x+x^2+x^4+x^8+x^{16}+...$, where each term is the square of the last?",,"['sequences-and-series', 'power-series']"
62,Does the series of squares of Legendre polynomials converge?,Does the series of squares of Legendre polynomials converge?,,"I am a physicist working on an electrostatic problem and this series popped up: $\sum^{\infty}_{l=0} (P_l(x))^2$ where $P_l$ is the $l$-th Legendre polynomial. Computing this numerically I think the series converges for $x\in(-1,1)$. I don't have the proper knowledge and experience to find out whether it really does. So: 1. Does the series converge? 2. If it does - what is the sum?","I am a physicist working on an electrostatic problem and this series popped up: $\sum^{\infty}_{l=0} (P_l(x))^2$ where $P_l$ is the $l$-th Legendre polynomial. Computing this numerically I think the series converges for $x\in(-1,1)$. I don't have the proper knowledge and experience to find out whether it really does. So: 1. Does the series converge? 2. If it does - what is the sum?",,"['sequences-and-series', 'special-functions']"
63,Common terms in general Fibonacci sequences,Common terms in general Fibonacci sequences,,"Mathworld notes that ""The Fibonacci and Lucas numbers have no common terms except 1 and 3,"" where the Fibonacci and Lucas numbers are defined by the recurrence relation $a_n=a_{n-1}+a_{n-2}$. For Fibonacci numbers, $a_1=a_2=1$; for Lucas numbers, $a_1=1$, $a_2=3$. How do you prove mathworld's statement?","Mathworld notes that ""The Fibonacci and Lucas numbers have no common terms except 1 and 3,"" where the Fibonacci and Lucas numbers are defined by the recurrence relation $a_n=a_{n-1}+a_{n-2}$. For Fibonacci numbers, $a_1=a_2=1$; for Lucas numbers, $a_1=1$, $a_2=3$. How do you prove mathworld's statement?",,"['sequences-and-series', 'elementary-number-theory', 'recurrence-relations', 'fibonacci-numbers', 'lucas-numbers']"
64,The map $N\rightarrow N^N\bmod (2N+1)$ and the number $13612$,The map  and the number,N\rightarrow N^N\bmod (2N+1) 13612,"Recently, i've been experimenting with the map $N \rightarrow N^N \bmod (2N+1)$ . What i would do is repeated apply this map to some numbers. There's a lot of cycles with this map, but i found a particularly massive one: $13612, 15106, 27724, 27553, 29074, 53239, 76162, 135319, 103369, 201064, 323761, 202351, 24889, 15556$ This cycle has a period of $14$ . It is very long and i couldn't find any other cycle that is nearly as long as this one (and not for lack of trying). The best i could find are $2$ cycles of length $7$ : $$554782, 923989, 578686, 1081525, 827113, 1001092, 634036$$ $$603229, 661333, 1166386, 1343245, 1772455, 1085395, 1819786$$ Can anyone prove or disprove the claim that the cycle starting with $13612$ is the largest cycle there is?","Recently, i've been experimenting with the map . What i would do is repeated apply this map to some numbers. There's a lot of cycles with this map, but i found a particularly massive one: This cycle has a period of . It is very long and i couldn't find any other cycle that is nearly as long as this one (and not for lack of trying). The best i could find are cycles of length : Can anyone prove or disprove the claim that the cycle starting with is the largest cycle there is?","N \rightarrow N^N \bmod (2N+1) 13612, 15106, 27724, 27553, 29074, 53239, 76162, 135319, 103369, 201064, 323761, 202351, 24889, 15556 14 2 7 554782, 923989, 578686, 1081525, 827113, 1001092, 634036 603229, 661333, 1166386, 1343245, 1772455, 1085395, 1819786 13612","['sequences-and-series', 'number-theory', 'elementary-number-theory', 'modular-arithmetic']"
65,Reference for anti-commutative Binomial Theorem,Reference for anti-commutative Binomial Theorem,,"Let $x,y$ be two elements of a ring satisfying $$xy=-yx.$$ Let $n \geq 0$ . Then we can calculate $(x+y)^n$ as follows: If $n$ is even, then $$(x+y)^n = \sum_{0 \leq k \leq n,\, k \text{ even}} \binom{n/2}{k/2} x^{n-k} y^k.$$ If $n$ is odd, then $$(x+y)^n = \sum_{0 \leq k \leq n} \binom{\lfloor n/2 \rfloor}{\lfloor k/2 \rfloor} x^{n-k} y^k.$$ The proof is an easy induction (and it is also possible to see it as a special case of $q$ -binomial coefficients for $q=-1$ , see the answer by mjqxxxx). I would like to know if someone knows a reference for precisely this anti-commutative binomial theorem. Please notice that I am not asking for a proof, and I am not asking for a reference for the $q$ -binomial theorem, unless it explicitly deduces and states the anti-commutative binomial theorem as stated above.","Let be two elements of a ring satisfying Let . Then we can calculate as follows: If is even, then If is odd, then The proof is an easy induction (and it is also possible to see it as a special case of -binomial coefficients for , see the answer by mjqxxxx). I would like to know if someone knows a reference for precisely this anti-commutative binomial theorem. Please notice that I am not asking for a proof, and I am not asking for a reference for the -binomial theorem, unless it explicitly deduces and states the anti-commutative binomial theorem as stated above.","x,y xy=-yx. n \geq 0 (x+y)^n n (x+y)^n = \sum_{0 \leq k \leq n,\, k \text{ even}} \binom{n/2}{k/2} x^{n-k} y^k. n (x+y)^n = \sum_{0 \leq k \leq n} \binom{\lfloor n/2 \rfloor}{\lfloor k/2 \rfloor} x^{n-k} y^k. q q=-1 q","['sequences-and-series', 'ring-theory', 'reference-request', 'noncommutative-algebra']"
66,Is this series for Pi correct?,Is this series for Pi correct?,,"The idea was to use an infinite series of triangles. The red then green then the... to get the area of this sector then the area of the circle is 16 times this. If it is a unit circle than area should equal Pi. Here is the series I got using Pythagorean’s theorem , is it correct? $$\begin{align} A&=3r^{2} + 12\sum_{ n=0}^{\infty}2^{n-1}x_{n}\left(1-\sqrt{r^{2}-\frac{x{_{n}}^{2}}{4}}\right),\\ x_{0}&=r\sqrt{2-\sqrt{3}} ,\\x_{n+1}&=\sqrt{2r^{2}-2r\sqrt{r^{2}-\frac{x{_{n}}^{2}}{4}}} \end{align}$$ So-for-a-unit-circle $$\begin{align} \pi&=3 + 12\sum_{ n=0}^{\infty}2^{n-1}x_{n}\left(1-\sqrt{1-\frac{x{_{n}}^{2}}{4}}\right),\\ x_{0}&=\sqrt{2-\sqrt{3}} ,\\x_{n+1}&=\sqrt{2-2\sqrt{1-\frac{x{_{n}}^{2}}{4}}} \end{align}$$","The idea was to use an infinite series of triangles. The red then green then the... to get the area of this sector then the area of the circle is 16 times this. If it is a unit circle than area should equal Pi. Here is the series I got using Pythagorean’s theorem , is it correct? So-for-a-unit-circle","\begin{align}
A&=3r^{2} + 12\sum_{ n=0}^{\infty}2^{n-1}x_{n}\left(1-\sqrt{r^{2}-\frac{x{_{n}}^{2}}{4}}\right),\\ x_{0}&=r\sqrt{2-\sqrt{3}}
,\\x_{n+1}&=\sqrt{2r^{2}-2r\sqrt{r^{2}-\frac{x{_{n}}^{2}}{4}}}
\end{align} \begin{align}
\pi&=3 + 12\sum_{ n=0}^{\infty}2^{n-1}x_{n}\left(1-\sqrt{1-\frac{x{_{n}}^{2}}{4}}\right),\\ x_{0}&=\sqrt{2-\sqrt{3}}
,\\x_{n+1}&=\sqrt{2-2\sqrt{1-\frac{x{_{n}}^{2}}{4}}}
\end{align}","['sequences-and-series', 'geometry', 'solution-verification']"
67,"'Spiky Periodic Things' - Do these objects have a name, and is there a method for finding the boundary curves?","'Spiky Periodic Things' - Do these objects have a name, and is there a method for finding the boundary curves?",,"This question was originally about evaluating the sum $\sum_{n=0}^\infty e^{nix}$ , but I figured out the answer about half way through writing it. So instead, I decided to ask a slightly different question. Now, obviously, the sum $\sum_{n=0}^\infty e^{nix}$ does not converge - however, the closure of the set of points $(x,z)$ given by $z=\sum_{n=0}^\omega e^{nix}$ is bounded for arbitrarily large $\omega$ ; the object formed by these points is well defined as $\omega\to\infty$ . This becomes clear when you break the sum into a real and imaginary part: $$\sum_{n=0}^\infty e^{nix}=\sum_{n=0}^\infty \cos{nx}+i\sum_{n=0}^\infty \sin{nx}$$ Both sums form bounded sets, and the boundary is clearly another periodic function with vertical asymptotes at integer multiples of $2\pi$ . The resulting object can be expressed (admittedly awkwardly) as a piece-wise set-valued function of a single real variable $x$ : $$r_1(x)=-\frac{1}{2}\csc{\frac{x}{2}}+\frac{1}{2}\qquad r_2(x)=\frac{1}{2}\csc{\frac{x}{2}}+\frac{1}{2}$$ $$m_1(x)=-\frac{1}{2}\tan{\frac{x}{4}}\qquad m_2(x)=\frac{1}{2}\cot{\frac{x}{4}}$$ $$f(x)=\begin{cases}[r_1(x),r_2(x)]+i[m_1(x),m_2(x)]&\cot{\frac{x}{4}}>0\\ \mathbb{C}&\cot{\frac{x}{4}}=0^{\pm1}\\ [r_2(x),r_1(x)]+i[m_2(x),m_1(x)]&\cot{\frac{x}{4}}<0\end{cases}$$ Using $0^{-1}=\pm\infty$ , $\quad Y_1+Y_2=\left\{y_1+y_2\mid y_1\in Y_1\land y_2\in Y_2\right\}$ , and $iY=\left\{iy\mid y\in Y\right\}$ . (If there is a more elegant way to write this, please tell me). Naturally my next question was whether or not other 'spiky summations' exist, so I played around with different periodic functions, trying to get the summation to 'converge' to a bounded shape. After experimenting for a while, it seems that there is an entire class of these objects - which have interesting geometric and statistical properties. Do these objects have a name? And is there a general method for finding the bounding curves given the summation used to generate them?","This question was originally about evaluating the sum , but I figured out the answer about half way through writing it. So instead, I decided to ask a slightly different question. Now, obviously, the sum does not converge - however, the closure of the set of points given by is bounded for arbitrarily large ; the object formed by these points is well defined as . This becomes clear when you break the sum into a real and imaginary part: Both sums form bounded sets, and the boundary is clearly another periodic function with vertical asymptotes at integer multiples of . The resulting object can be expressed (admittedly awkwardly) as a piece-wise set-valued function of a single real variable : Using , , and . (If there is a more elegant way to write this, please tell me). Naturally my next question was whether or not other 'spiky summations' exist, so I played around with different periodic functions, trying to get the summation to 'converge' to a bounded shape. After experimenting for a while, it seems that there is an entire class of these objects - which have interesting geometric and statistical properties. Do these objects have a name? And is there a general method for finding the bounding curves given the summation used to generate them?","\sum_{n=0}^\infty e^{nix} \sum_{n=0}^\infty e^{nix} (x,z) z=\sum_{n=0}^\omega e^{nix} \omega \omega\to\infty \sum_{n=0}^\infty e^{nix}=\sum_{n=0}^\infty \cos{nx}+i\sum_{n=0}^\infty \sin{nx} 2\pi x r_1(x)=-\frac{1}{2}\csc{\frac{x}{2}}+\frac{1}{2}\qquad r_2(x)=\frac{1}{2}\csc{\frac{x}{2}}+\frac{1}{2} m_1(x)=-\frac{1}{2}\tan{\frac{x}{4}}\qquad m_2(x)=\frac{1}{2}\cot{\frac{x}{4}} f(x)=\begin{cases}[r_1(x),r_2(x)]+i[m_1(x),m_2(x)]&\cot{\frac{x}{4}}>0\\ \mathbb{C}&\cot{\frac{x}{4}}=0^{\pm1}\\ [r_2(x),r_1(x)]+i[m_2(x),m_1(x)]&\cot{\frac{x}{4}}<0\end{cases} 0^{-1}=\pm\infty \quad Y_1+Y_2=\left\{y_1+y_2\mid y_1\in Y_1\land y_2\in Y_2\right\} iY=\left\{iy\mid y\in Y\right\}","['sequences-and-series', 'curves', 'periodic-functions']"
68,Closed form expression or asymptotic expansion for (periodic) generalized harmonic numbers?,Closed form expression or asymptotic expansion for (periodic) generalized harmonic numbers?,,"In contrast with the series $\sum_{k=1}^n k$ and $\sum_{k=1}^n1$ , there does not (as far as I know) exist a pure closed form expression (or a nice asymptotic expansion other than the Euler-Maclaurin expansion?) for the generalized harmonic numbers (and in fact the defining series for the Riemann zeta function) $$H_{s}(n)=\sum_{k=1}^n \frac{1}{k^s}\tag{1}$$ with $s\in\mathbb C$ (in particular $\Re(s)=\sigma\in(0,1)$ ). My question is however whether there might exist a closed form expression (or maybe an asymptotic expansion other than the Euler-Maclaurin expansion?) of which I call 'periodic generalized harmonic numbers' $P_{\sigma,t}(n)$ and $Q_{\sigma,t}(n)$ (however an expression for one of them would suffice) in which $$P_{\sigma,t}(n)=\sum_{k=1}^n \frac{\cos(t\ln(k))}{k^\sigma}\tag{2a}$$ and $$Q_{\sigma,t}(n)=\sum_{k=1}^n \frac{\sin(t\ln(k))}{k^\sigma}\tag{2b}$$ with $t\in\mathbb R$ and (in particular) $\sigma\in(0,1)$ . The reason why I'm not immediately interested in the Euler-Maclaurin expansion of the three concerning series is that all these expansions involve a complicated expression (involving Bernoulli numbers and derivatives of the concerning terms) which is in fact used to define the Riemann zeta function in some way.  I'm in particular looking for a method to derive information from the Riemann zeta function by using another type of asymptotic expansion or even the closed form of the defining series (1) or preferably the (maybe more nicely behaving) 'splitted versions' (2a) and (2b). Is e.g. Fourier analysis an obvious direction to think of? See for my motivation for this matter also in 4.1.2 of http://fse.studenttheses.ub.rug.nl/19062/1/bMATH_2019_vanderReijdenIS.pdf .","In contrast with the series and , there does not (as far as I know) exist a pure closed form expression (or a nice asymptotic expansion other than the Euler-Maclaurin expansion?) for the generalized harmonic numbers (and in fact the defining series for the Riemann zeta function) with (in particular ). My question is however whether there might exist a closed form expression (or maybe an asymptotic expansion other than the Euler-Maclaurin expansion?) of which I call 'periodic generalized harmonic numbers' and (however an expression for one of them would suffice) in which and with and (in particular) . The reason why I'm not immediately interested in the Euler-Maclaurin expansion of the three concerning series is that all these expansions involve a complicated expression (involving Bernoulli numbers and derivatives of the concerning terms) which is in fact used to define the Riemann zeta function in some way.  I'm in particular looking for a method to derive information from the Riemann zeta function by using another type of asymptotic expansion or even the closed form of the defining series (1) or preferably the (maybe more nicely behaving) 'splitted versions' (2a) and (2b). Is e.g. Fourier analysis an obvious direction to think of? See for my motivation for this matter also in 4.1.2 of http://fse.studenttheses.ub.rug.nl/19062/1/bMATH_2019_vanderReijdenIS.pdf .","\sum_{k=1}^n k \sum_{k=1}^n1 H_{s}(n)=\sum_{k=1}^n \frac{1}{k^s}\tag{1} s\in\mathbb C \Re(s)=\sigma\in(0,1) P_{\sigma,t}(n) Q_{\sigma,t}(n) P_{\sigma,t}(n)=\sum_{k=1}^n \frac{\cos(t\ln(k))}{k^\sigma}\tag{2a} Q_{\sigma,t}(n)=\sum_{k=1}^n \frac{\sin(t\ln(k))}{k^\sigma}\tag{2b} t\in\mathbb R \sigma\in(0,1)","['sequences-and-series', 'trigonometry', 'asymptotics', 'closed-form', 'riemann-hypothesis']"
69,Is it possible to mathematically skip numbers containing 666?,Is it possible to mathematically skip numbers containing 666?,,"I once had a project which involved taking actual real social security numbers and anonymizing them into unique real-looking fake SSNs. One of the rules for SSNs is that it cannot contain a run of 666 inside it. That raised the question, is it possible to do this mathematically? More generally, given this sequence $$S = 1, 2, 3, ..., 665, 667, 668, ..., 1665, 1667, ..., 6658, 6659, 6670, ...$$ Is it possible to get the $n$ th term without simply counting up to it?","I once had a project which involved taking actual real social security numbers and anonymizing them into unique real-looking fake SSNs. One of the rules for SSNs is that it cannot contain a run of 666 inside it. That raised the question, is it possible to do this mathematically? More generally, given this sequence Is it possible to get the th term without simply counting up to it?","S = 1, 2, 3, ..., 665, 667, 668, ..., 1665, 1667, ..., 6658, 6659, 6670, ... n","['sequences-and-series', 'integers']"
70,Convergence of a family of series,Convergence of a family of series,,"I want to show that for $D>0, D\equiv 0,1 \pmod4$ , $z \in \mathbb{C}$ with $ \operatorname{Im}(z)>0$ and $k>1$ the sum $$\sum_{a,b,c \in \mathbb{Z} \\ b^2-4ac=D}(az^2+bz+c)^{-k}$$ converges absolutely.","I want to show that for , with and the sum converges absolutely.","D>0, D\equiv 0,1 \pmod4 z \in \mathbb{C}  \operatorname{Im}(z)>0 k>1 \sum_{a,b,c \in \mathbb{Z} \\ b^2-4ac=D}(az^2+bz+c)^{-k}","['sequences-and-series', 'complex-analysis', 'convergence-divergence']"
71,Generating Function for the square of a sequence,Generating Function for the square of a sequence,,"Given any sequence $a_n$  and its generating function $A(x)$, how do I determine the generating function of $a_n^2$? Or more generally, can the generating function for $a_n^k$ be determined for any $k\in{\mathbb{R}}$? Thanks for the assistance.","Given any sequence $a_n$  and its generating function $A(x)$, how do I determine the generating function of $a_n^2$? Or more generally, can the generating function for $a_n^k$ be determined for any $k\in{\mathbb{R}}$? Thanks for the assistance.",,"['sequences-and-series', 'generating-functions']"
72,Jacobi triple product comes from the Weyl Character formula?,Jacobi triple product comes from the Weyl Character formula?,,"From the Weyl character formula says that the irreducible representation of Lie algebra $\mathfrak{g}$ with highest weight $\lambda$ has character $$\frac{1}{\prod(e^{\alpha/2}-e^{-\alpha/2})}\sum_{w\in W} (-1)^w e^{w(\lambda+\rho)}$$ where the product is over the positive roots and $\rho$ is half of the sum of the positive roots. The trivial (!) representation with $\mathfrak{g}=\mathfrak{sl}_n$ is the Vandermonde identity  $$\det \begin{pmatrix} x_1&x_2&\cdots&x_n\\ x_1^2&x_2^2&\cdots&x_n^2\\ \vdots&\vdots&&\vdots\\ x_1^n&x_2^n&\cdots&x_n^n \end{pmatrix}=\prod_{i<j}(x_j-x_i)$$ $$\text{}$$ I've heard* that the Jacobi Triple product identity $$\prod \left( 1 - x^{2n}\right) \left( 1 + x^{2n-1} y^2\right) \left( 1 +x^{2n-1}y^{-2}\right) \ = \ \sum x^{n^2} y^{2n}$$ is a trivial-representation case of a `Kac-Moody' version of the Weyl character formula. If this is true, what does this general character formula say, and what other classical identities like this does it imply? Is there geometric/representation theoretic content to these results? $$\text{}$$ $$\text{}$$ *In page 221 of 'Moonshine, Beyond the Monster'' (which gives the Kac-Moody character formula, but not its relation to such identities).","From the Weyl character formula says that the irreducible representation of Lie algebra $\mathfrak{g}$ with highest weight $\lambda$ has character $$\frac{1}{\prod(e^{\alpha/2}-e^{-\alpha/2})}\sum_{w\in W} (-1)^w e^{w(\lambda+\rho)}$$ where the product is over the positive roots and $\rho$ is half of the sum of the positive roots. The trivial (!) representation with $\mathfrak{g}=\mathfrak{sl}_n$ is the Vandermonde identity  $$\det \begin{pmatrix} x_1&x_2&\cdots&x_n\\ x_1^2&x_2^2&\cdots&x_n^2\\ \vdots&\vdots&&\vdots\\ x_1^n&x_2^n&\cdots&x_n^n \end{pmatrix}=\prod_{i<j}(x_j-x_i)$$ $$\text{}$$ I've heard* that the Jacobi Triple product identity $$\prod \left( 1 - x^{2n}\right) \left( 1 + x^{2n-1} y^2\right) \left( 1 +x^{2n-1}y^{-2}\right) \ = \ \sum x^{n^2} y^{2n}$$ is a trivial-representation case of a `Kac-Moody' version of the Weyl character formula. If this is true, what does this general character formula say, and what other classical identities like this does it imply? Is there geometric/representation theoretic content to these results? $$\text{}$$ $$\text{}$$ *In page 221 of 'Moonshine, Beyond the Monster'' (which gives the Kac-Moody character formula, but not its relation to such identities).",,"['sequences-and-series', 'representation-theory', 'lie-algebras']"
73,Pointwise and uniform convergence of $\sum\limits_{n=1}^{+\infty}\big({\frac{x}{1+x^n}}\big)^n$,Pointwise and uniform convergence of,\sum\limits_{n=1}^{+\infty}\big({\frac{x}{1+x^n}}\big)^n,"Examine the convergence of  the series of functions $$\displaystyle\mathop{\sum}\limits_{n=1}^{+\infty}\Big({\frac{x}{1+x^n}}\Big)^n$$  a) pointwise   in $[0,1]$, b) uniformly in $[0,1]$. My attempt for  pointwise convergence: For all $x\in[0,1)$ exists $n_0(x)\in{\mathbb{N}}$ such that for all $n\in\mathbb{N}$ with $n\geqslant n_0(x)$ : $$\displaystyle\Big|\Big({\frac{x}{1+x^n}}\Big)^n\Big|<\frac{1}{n^2}\,.$$ Because $\sum_{n=1}^{+\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$, we have that the series  $\sum_{n=1}^{+\infty}\big({\frac{x}{1+x^n}}\big)^n$ converges pointwise in  $[0,1)$. Also for  $x=1$ :  $\sum_{n=1}^{+\infty}\big({\frac{1}{1+1^n}}\big)^n=\sum_{n=1}^{+\infty}\big({\frac{1}{2}}\big)^n=1$. So, the series converges pointwise in $[0,1]$. I have no answer for uniform convergence. edit: This is not an answer for the uniform convergence issue. I'm just giving two plots which shows the behavior of the partial sums sequence $S_n=\sum_{k=1}^{n}\big({\frac{x}{1+x^k}}\big)^k$ near $1$, where is possible the non-uniform convergence of the series $\sum_{n=1}^{+\infty}\big({\frac{x}{1+x^n}}\big)^n$, for helping others to procced further. In the rest of the interval the series looks that converges uniformly.","Examine the convergence of  the series of functions $$\displaystyle\mathop{\sum}\limits_{n=1}^{+\infty}\Big({\frac{x}{1+x^n}}\Big)^n$$  a) pointwise   in $[0,1]$, b) uniformly in $[0,1]$. My attempt for  pointwise convergence: For all $x\in[0,1)$ exists $n_0(x)\in{\mathbb{N}}$ such that for all $n\in\mathbb{N}$ with $n\geqslant n_0(x)$ : $$\displaystyle\Big|\Big({\frac{x}{1+x^n}}\Big)^n\Big|<\frac{1}{n^2}\,.$$ Because $\sum_{n=1}^{+\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$, we have that the series  $\sum_{n=1}^{+\infty}\big({\frac{x}{1+x^n}}\big)^n$ converges pointwise in  $[0,1)$. Also for  $x=1$ :  $\sum_{n=1}^{+\infty}\big({\frac{1}{1+1^n}}\big)^n=\sum_{n=1}^{+\infty}\big({\frac{1}{2}}\big)^n=1$. So, the series converges pointwise in $[0,1]$. I have no answer for uniform convergence. edit: This is not an answer for the uniform convergence issue. I'm just giving two plots which shows the behavior of the partial sums sequence $S_n=\sum_{k=1}^{n}\big({\frac{x}{1+x^k}}\big)^k$ near $1$, where is possible the non-uniform convergence of the series $\sum_{n=1}^{+\infty}\big({\frac{x}{1+x^n}}\big)^n$, for helping others to procced further. In the rest of the interval the series looks that converges uniformly.",,"['sequences-and-series', 'uniform-convergence', 'pointwise-convergence']"
74,Closed form for $\sum\limits_{n=1}^\infty\frac{W(n^2)}{n^2}$,Closed form for,\sum\limits_{n=1}^\infty\frac{W(n^2)}{n^2},"Apologies if this has been asked before. I am wondering if the following series has a closed form : $$\alpha=\sum_{n=1}^\infty\frac{W(n^2)}{n^2}\tag{1}$$ where $W(x)$ is the Lambert W function . I am interested in this series as an extension of the series : $$\sum_{n=1}^\infty\frac{\ln{n^2}}{n^2}=-2\zeta'(2)=\frac{\pi^2}{3}\ln{\left(\frac{A^{12}}{2\pi e^\gamma}\right)}\tag{2}$$ since $W(x)$ is the product logarithm. Obviously $(1)$ must converge by comparison with $(2)$ since $W(x)e^{W(x)}=x$ so $W(x)e^{W(x)}<\ln(x)e^{\ln{x}}$ so $W(x)<\ln{x}$ for $x\ge1$ by monotonicity of $W(x)$. However, I am not sure what it converges to. A value (obtained by a couple of toy formal methods) is $\alpha\overset{!}{=}\sqrt{2\pi}-\frac{1}{2}$, but I do not think this is an  equality (although it is hard to tell since the series converges so slowly). Using Wolfram Alpha to sum to $10000$ terms, the partial sum appears to be $2.0142453>2.0066283=\sqrt{2\pi}-\frac{1}{2}$, but I do not know $\alpha$'s exact numerical value. Thus my question is: Is there a closed form for $\alpha$? If not, is there an expression for the error in the $\sqrt{2\pi}-\frac{1}{2}$ approximation? My attempts : (Note: I have only put the following here to show where I got the value of $\sqrt{2\pi}-\frac{1}{2}$ from; I assume that the methods are not properly correct) . In the first place, using this toy resummation formula I had derived, the formula $\int_0^\infty\frac{W(x^2)}{x^2}dx=\sqrt{2\pi}$ (derivable from $\int_0^\infty\frac{W(x)}{x\sqrt{x}}dx=\sqrt{8\pi}$ ) and the Taylor series of $W(x)$ I formally calculated $\alpha=\sqrt{2\pi}-\frac{1}{2}$. However, the given resummation formula often gives the wrong answer. I also attempted to evaluate the integral using the Abel-Plana formula (although I do not think $\frac{W(z^2)}{z^2}$ satisfies the conditions to apply it). Formally using the fact that $\lim\limits_{s\rightarrow0}\frac{W(s^2)}{s^2}=1$, I got: $$\sum_{n=1}^\infty\frac{W(n^2)}{n^2}=\int_{0}^\infty\frac{W(x^2)}{x^2}\;dx-\frac{1}{2}+i\int_0^\infty\frac{\frac{W(-t^2)}{-t^2}-\frac{W(-t^2)}{-t^2}}{e^{2\pi t}-1}\;dt=\sqrt{2\pi}-\frac{1}{2}$$ I assume that the occurrences of this incorrect value are to do with my incorrect applications of these rules missing some remainder term, but I do not know a good way of rectifying this. So my question is: does anyone know a way of evaluating $(*)$ exactly?","Apologies if this has been asked before. I am wondering if the following series has a closed form : $$\alpha=\sum_{n=1}^\infty\frac{W(n^2)}{n^2}\tag{1}$$ where $W(x)$ is the Lambert W function . I am interested in this series as an extension of the series : $$\sum_{n=1}^\infty\frac{\ln{n^2}}{n^2}=-2\zeta'(2)=\frac{\pi^2}{3}\ln{\left(\frac{A^{12}}{2\pi e^\gamma}\right)}\tag{2}$$ since $W(x)$ is the product logarithm. Obviously $(1)$ must converge by comparison with $(2)$ since $W(x)e^{W(x)}=x$ so $W(x)e^{W(x)}<\ln(x)e^{\ln{x}}$ so $W(x)<\ln{x}$ for $x\ge1$ by monotonicity of $W(x)$. However, I am not sure what it converges to. A value (obtained by a couple of toy formal methods) is $\alpha\overset{!}{=}\sqrt{2\pi}-\frac{1}{2}$, but I do not think this is an  equality (although it is hard to tell since the series converges so slowly). Using Wolfram Alpha to sum to $10000$ terms, the partial sum appears to be $2.0142453>2.0066283=\sqrt{2\pi}-\frac{1}{2}$, but I do not know $\alpha$'s exact numerical value. Thus my question is: Is there a closed form for $\alpha$? If not, is there an expression for the error in the $\sqrt{2\pi}-\frac{1}{2}$ approximation? My attempts : (Note: I have only put the following here to show where I got the value of $\sqrt{2\pi}-\frac{1}{2}$ from; I assume that the methods are not properly correct) . In the first place, using this toy resummation formula I had derived, the formula $\int_0^\infty\frac{W(x^2)}{x^2}dx=\sqrt{2\pi}$ (derivable from $\int_0^\infty\frac{W(x)}{x\sqrt{x}}dx=\sqrt{8\pi}$ ) and the Taylor series of $W(x)$ I formally calculated $\alpha=\sqrt{2\pi}-\frac{1}{2}$. However, the given resummation formula often gives the wrong answer. I also attempted to evaluate the integral using the Abel-Plana formula (although I do not think $\frac{W(z^2)}{z^2}$ satisfies the conditions to apply it). Formally using the fact that $\lim\limits_{s\rightarrow0}\frac{W(s^2)}{s^2}=1$, I got: $$\sum_{n=1}^\infty\frac{W(n^2)}{n^2}=\int_{0}^\infty\frac{W(x^2)}{x^2}\;dx-\frac{1}{2}+i\int_0^\infty\frac{\frac{W(-t^2)}{-t^2}-\frac{W(-t^2)}{-t^2}}{e^{2\pi t}-1}\;dt=\sqrt{2\pi}-\frac{1}{2}$$ I assume that the occurrences of this incorrect value are to do with my incorrect applications of these rules missing some remainder term, but I do not know a good way of rectifying this. So my question is: does anyone know a way of evaluating $(*)$ exactly?",,"['sequences-and-series', 'closed-form', 'lambert-w']"
75,Sum to closed form,Sum to closed form,,I need to evaluate the following summation: $$ \sum_{n\in\mathbb{Z}} \frac{-1}{i(2n+1)\pi -\mu} $$ where $n$ is summed over all the integers from $-\infty$ to $\infty$ including 0. Putting this into Mathematica gives $\frac{1}{2}\tanh\frac{\mu}{2}$. What is the intermediate steps to get from the summation to the closed form?,I need to evaluate the following summation: $$ \sum_{n\in\mathbb{Z}} \frac{-1}{i(2n+1)\pi -\mu} $$ where $n$ is summed over all the integers from $-\infty$ to $\infty$ including 0. Putting this into Mathematica gives $\frac{1}{2}\tanh\frac{\mu}{2}$. What is the intermediate steps to get from the summation to the closed form?,,"['sequences-and-series', 'summation', 'closed-form']"
76,Analytical proof for the convergence of a sequence,Analytical proof for the convergence of a sequence,,"Consider the following sequence $\Xi_N=N\sum\limits_{i=0}^{N-1} {N-1 \choose i} (-1)^{(i+1)} \log\left(i+1\right)$. I numerically compute the asymptotic behavior of sequence and it turns out that the sequence approaches to a non-zero value as N goes to infinity. Now, I want to analytically prove that this sequence converges to a non-zero value as N goes to infinity. Also, it can be proved that the sequence has another form as follows $\Xi_N=\sum\limits_{i=1}^{N} {N \choose i} (-1)^{(i)} i \log\left(i\right)$. Moreover, Using $\int_{0}^{1} \sum_{m=1}^{i} \frac{1}{x+m} dx=\log(i+1)$ Then $\Xi_N=N\sum_{m=1}^{N-1}{N-1 \choose m-1} (-1)^{m-1}\int_{0}^{1} \frac{1}{x+m} dx $ Could you give me some advice? Thanks","Consider the following sequence $\Xi_N=N\sum\limits_{i=0}^{N-1} {N-1 \choose i} (-1)^{(i+1)} \log\left(i+1\right)$. I numerically compute the asymptotic behavior of sequence and it turns out that the sequence approaches to a non-zero value as N goes to infinity. Now, I want to analytically prove that this sequence converges to a non-zero value as N goes to infinity. Also, it can be proved that the sequence has another form as follows $\Xi_N=\sum\limits_{i=1}^{N} {N \choose i} (-1)^{(i)} i \log\left(i\right)$. Moreover, Using $\int_{0}^{1} \sum_{m=1}^{i} \frac{1}{x+m} dx=\log(i+1)$ Then $\Xi_N=N\sum_{m=1}^{N-1}{N-1 \choose m-1} (-1)^{m-1}\int_{0}^{1} \frac{1}{x+m} dx $ Could you give me some advice? Thanks",,"['sequences-and-series', 'combinatorics', 'analysis', 'limits', 'convergence-divergence']"
77,Variety of proofs of a simple proposition in arithmetic,Variety of proofs of a simple proposition in arithmetic,,"I have a couple of simple proofs of a simple proposition and I'm curious to see the variety of different approaches others would take to prove the same thing. Definition: The dilation of a sequence $a_1, a_2, a_3,\ldots$ by a factor $n$ is the sequence $b_1,b_2,b_3,\ldots$ for which $$ \begin{cases} b_{kn} = a_k & \text{for } k=1,2,3,\ldots, \\ b_j = 0 & \text{if $j$ is not a multiple of $n$.} \end{cases} $$ Thus the dilation of $a_1,a_2,a_3,\ldots$ by a factor of $3$ is $$ 0,\ 0,\ a_1,\ 0,\ 0,\ a_2,\ 0,\ 0,\ a_3,\ 0,\ 0,\ a_4,\ \ldots $$ (This is not standard terminology as far as I know, so tell me if there's some standard name for this.) Now let $\{a_k\}_{k=1}^\infty$ consist of an infinite sequence of repetitions of $1,0,0,0,1,0$ (a $\text{“}1\text{''}$ in the $1$st and $5$th positions and $\text{“}0\text{''s}$ elsewhere).  In other words $a_k$ is just the indicator that $k$ is coprime to $6$. Now start by letting $c$ be an infinite sequence of $0$s and proceed as follows: 1. Let $n$ be the smallest index for which $c_n=0$ (thus initially $n=1$); 2. Let the new value of $c$ be $(c + \text{the dilation of } a \text{ by } n)$ (where the occurrence of $c$ inside the round brackets is the value of $c$ we had at the end of step $1$.); 3. Go back to step $1$. This goes on forever. Proposition: This process converges to an infinite sequence of $1$s.  (Thus, we never add $1$ to any position that was not $0$.) As I said, I have a couple of simple proofs and I am curious to see the variety of different approaches others would take to prove the same thing.","I have a couple of simple proofs of a simple proposition and I'm curious to see the variety of different approaches others would take to prove the same thing. Definition: The dilation of a sequence $a_1, a_2, a_3,\ldots$ by a factor $n$ is the sequence $b_1,b_2,b_3,\ldots$ for which $$ \begin{cases} b_{kn} = a_k & \text{for } k=1,2,3,\ldots, \\ b_j = 0 & \text{if $j$ is not a multiple of $n$.} \end{cases} $$ Thus the dilation of $a_1,a_2,a_3,\ldots$ by a factor of $3$ is $$ 0,\ 0,\ a_1,\ 0,\ 0,\ a_2,\ 0,\ 0,\ a_3,\ 0,\ 0,\ a_4,\ \ldots $$ (This is not standard terminology as far as I know, so tell me if there's some standard name for this.) Now let $\{a_k\}_{k=1}^\infty$ consist of an infinite sequence of repetitions of $1,0,0,0,1,0$ (a $\text{“}1\text{''}$ in the $1$st and $5$th positions and $\text{“}0\text{''s}$ elsewhere).  In other words $a_k$ is just the indicator that $k$ is coprime to $6$. Now start by letting $c$ be an infinite sequence of $0$s and proceed as follows: 1. Let $n$ be the smallest index for which $c_n=0$ (thus initially $n=1$); 2. Let the new value of $c$ be $(c + \text{the dilation of } a \text{ by } n)$ (where the occurrence of $c$ inside the round brackets is the value of $c$ we had at the end of step $1$.); 3. Go back to step $1$. This goes on forever. Proposition: This process converges to an infinite sequence of $1$s.  (Thus, we never add $1$ to any position that was not $0$.) As I said, I have a couple of simple proofs and I am curious to see the variety of different approaches others would take to prove the same thing.",,"['sequences-and-series', 'arithmetic']"
78,Absolutely convergent but not convergent,Absolutely convergent but not convergent,,"Here , Lemma $2.1$ states that A normed space $X$ is complete if and only if every absolutely   convergent series is convergent. I would like to know a series which is absolutely convergent but not convergent. Can someone give such example? I always thought that absolutely convergent series implies the series converges.","Here , Lemma $2.1$ states that A normed space $X$ is complete if and only if every absolutely   convergent series is convergent. I would like to know a series which is absolutely convergent but not convergent. Can someone give such example? I always thought that absolutely convergent series implies the series converges.",,['sequences-and-series']
79,A problem of Ramanujan's interest: closed form of $1 + 2\sum_{n=1}^{\infty} \frac{\cosh(n\theta)}{\cosh(n\pi)} $,A problem of Ramanujan's interest: closed form of,1 + 2\sum_{n=1}^{\infty} \frac{\cosh(n\theta)}{\cosh(n\pi)} ,"I am Brian Diaz, and I am new to the math.stackexchange community. I have been struggling with attempting to find a closed form of the following series: $$ \varphi(\theta) = 1 + 2\sum_{n=1}^{\infty} \frac{\cosh(n\theta)}{\cosh(n\pi)} $$ Admittedly, I attempted to convert it to a ""workable integral"", but to no avail. Heck, in the process of converting it to an integral, I am not even sure interchanging the sum and the integral was valid. Nevertheless, this was my result. $$\frac{1}{\pi}\int_{-\infty}^{\infty} \frac{\sin(x)}{\cosh(\theta) - \cos(x)} \frac{1}{\cosh(x)}dx $$ This was derived from a problem Ramanujan was working. For those who are interested in the source, you can visit http://mathworld.wolfram.com/RamanujanCosCoshIdentity.html . Note: Even if it does not have a closed form, I am still interested in valuable insight to the problem. In addition, I have been reported by my professor to consider applying residue theory, though he his not so sure what the result would be. Thank you so much for your support, and I hope you do have a blessed day!","I am Brian Diaz, and I am new to the math.stackexchange community. I have been struggling with attempting to find a closed form of the following series: $$ \varphi(\theta) = 1 + 2\sum_{n=1}^{\infty} \frac{\cosh(n\theta)}{\cosh(n\pi)} $$ Admittedly, I attempted to convert it to a ""workable integral"", but to no avail. Heck, in the process of converting it to an integral, I am not even sure interchanging the sum and the integral was valid. Nevertheless, this was my result. $$\frac{1}{\pi}\int_{-\infty}^{\infty} \frac{\sin(x)}{\cosh(\theta) - \cos(x)} \frac{1}{\cosh(x)}dx $$ This was derived from a problem Ramanujan was working. For those who are interested in the source, you can visit http://mathworld.wolfram.com/RamanujanCosCoshIdentity.html . Note: Even if it does not have a closed form, I am still interested in valuable insight to the problem. In addition, I have been reported by my professor to consider applying residue theory, though he his not so sure what the result would be. Thank you so much for your support, and I hope you do have a blessed day!",,"['sequences-and-series', 'improper-integrals', 'closed-form', 'hyperbolic-functions', 'trigonometric-series']"
80,"series from one of Coffey's papers involving digamma, $\gamma$, and binomial","series from one of Coffey's papers involving digamma, , and binomial",\gamma,"I was looking over one of Coffey's papers where is shows the following series, but with no evaluation. I am just wondering if anyone would know how to evaluate this series: $$\sum_{n=1}^{\infty}(-1)^{n}\left[1+\frac{2}{n+1}\right]\binom{x}{n+2}=\frac{1}{2}(2-x)(x-1)-x\left(1-2\gamma+x-2\psi(x+1)\right)$$ It is related to the derivation of the integral $$\int_{0}^{1}\left(\frac{1}{\ln(x)}+\frac{1}{1-x}\right)^{2}dx$$. It is in his paper entitled, ""certain log integrals, zeta values, and the Stieltjes constant"".","I was looking over one of Coffey's papers where is shows the following series, but with no evaluation. I am just wondering if anyone would know how to evaluate this series: $$\sum_{n=1}^{\infty}(-1)^{n}\left[1+\frac{2}{n+1}\right]\binom{x}{n+2}=\frac{1}{2}(2-x)(x-1)-x\left(1-2\gamma+x-2\psi(x+1)\right)$$ It is related to the derivation of the integral $$\int_{0}^{1}\left(\frac{1}{\ln(x)}+\frac{1}{1-x}\right)^{2}dx$$. It is in his paper entitled, ""certain log integrals, zeta values, and the Stieltjes constant"".",,['sequences-and-series']
81,How find this sequence $\{x_{n}\}$ such $\lim_{n\to \infty}x_{n}\left(1-\frac{n(1-na_{n})}{\ln{n}}\right)=1$,How find this sequence  such,\{x_{n}\} \lim_{n\to \infty}x_{n}\left(1-\frac{n(1-na_{n})}{\ln{n}}\right)=1,"Consider the sequence $\{a_{n}\}$ satisfying $a_{1}\in(0,1)$,such $$a_{n+1}=a_{n}(1-a_{n})$$ question: Find a sequence $\{x_{n}\}$ such that $$\lim_{n\to \infty}x_{n}\left(1-\dfrac{n(1-na_{n})}{\ln{n}}\right)=1$$ I have prove this $$\lim_{n\to \infty}\dfrac{n}{\ln{n}}(1-na_{n})=1$$ But I can't find this $x_{n}$  Thank you such as: How prove this $\displaystyle\lim_{n\to \infty}\frac{n}{\ln{(\ln{n}})}\left(1-a_{n}-\frac{n}{\ln{n}}\right)=-1$","Consider the sequence $\{a_{n}\}$ satisfying $a_{1}\in(0,1)$,such $$a_{n+1}=a_{n}(1-a_{n})$$ question: Find a sequence $\{x_{n}\}$ such that $$\lim_{n\to \infty}x_{n}\left(1-\dfrac{n(1-na_{n})}{\ln{n}}\right)=1$$ I have prove this $$\lim_{n\to \infty}\dfrac{n}{\ln{n}}(1-na_{n})=1$$ But I can't find this $x_{n}$  Thank you such as: How prove this $\displaystyle\lim_{n\to \infty}\frac{n}{\ln{(\ln{n}})}\left(1-a_{n}-\frac{n}{\ln{n}}\right)=-1$",,"['sequences-and-series', 'limits']"
82,"Sum $S(n,c) = \sum_{i=1}^{n-1}\dfrac{i}{ci+(n-i)}$",Sum,"S(n,c) = \sum_{i=1}^{n-1}\dfrac{i}{ci+(n-i)}","Consider the sum $$S(n,c) = \sum_{i=1}^{n-1}\dfrac{i}{ci+(n-i)}$$ where $0\le c\le 1$. When $c=0$, $S(n,c)$ grows asymptotically as $n\log n$. When $c=1$, $S(n,c)$ grows asymptotically as $n$. What about when $0<c<1$? Can we calculate $S(n,c)$ exactly? What about asymptotics? Can we find upper/lower bounds?","Consider the sum $$S(n,c) = \sum_{i=1}^{n-1}\dfrac{i}{ci+(n-i)}$$ where $0\le c\le 1$. When $c=0$, $S(n,c)$ grows asymptotically as $n\log n$. When $c=1$, $S(n,c)$ grows asymptotically as $n$. What about when $0<c<1$? Can we calculate $S(n,c)$ exactly? What about asymptotics? Can we find upper/lower bounds?",,"['sequences-and-series', 'inequality', 'asymptotics']"
83,Solve $a^3 + b^3 + c^3 = 6abc$,Solve,a^3 + b^3 + c^3 = 6abc,"Find solutions for  $a^3 + b^3 + c^3 = 6abc$ in  $\mathbb{N}$, such that $gcd(a,b,c) = 1$, except for $(1,2,3)$ and its permutations. Using trial and error I found out that if $a,b,c$ are solution of the equation, then they are in arithmetic progression. I've managed to prove that conjecture, assuming that $c>b>a$ and let $k$ be their common difference in the arithmetic progression. Then WLOG we have: $$b = c-k \quad \quad a = c-2k$$ Now the equation looks like: $$(c-2k)^3 + (c-k)^3 + c^3 = 6(c-2)(c-1)c$$ After expanding we have: $$c^3 - 6kc^2 + 12ck^2 - 8k^3 + c^3 - 3kc^2 + 3ck^2 -k^3 + c^3 = 6c^3 - 18kc^2 + 12ck^2$$ $$3c^3 - 9kc^2 + 15ck^2 - 9k^3 = 6c^3 - 18kc^2 + 12ck^2$$ $$c^3 - 3kc^2 + 5ck^2 - 3k^3 = 2c^3 - 6kc^2 + 4ck^2$$ $$-c^3 + 3kc^2 + ck^2 - 3k^3 = 0$$ Now it's easy to see that if $k=c$, then the LHS will be zero, so one of the zeroes of the polynomial is $c_1 = k$, now factorizing we have: $$(c-k)(3a^2 + 2ax - x^2) = 0$$ $$(c-k)(c+k)(c-3k) = 0$$ Now we have three distinct cases: Case 1: $c = k$ This implies that $b = 0$ and $a = -k$. But because $k \in \mathbb{N}$, both $a,b \not\in \mathbb{N}$, violating the initial conditions. Case 2: $c = -k$ Obviously the initial condition is already violated, becasue $k \in \mathbb{N}$, so from the relation $c \not\in \mathbb{N}$ Case 2: $c = 3k$ This implies that $b = 2k$ and $a = k$. Now we have one 3-tuple $(3k,2k,k)$ and it's permutation as solution, where $k \in \mathbb{N}$. But it's easy to note that $k$ is a common factor for $a,b,c$ so we have: $$gcd(a,b,c) = k$$ But because we want $gcd(a,b,c) = 1$, this implies that $k=1$, which means we have only one solution for  $a^3 + b^3 + c^3 = 6abc$ in  $\mathbb{N}$, such that $gcd(a,b,c) = 1$ and it $(1,2,3)$, solution that is already given. Now my question is what I'm missing. Is there really no other solutions such that $gcd(a,b,c) = 1$? Or maybe there is a different way to obtain solution except for my method using arithmetic progression?","Find solutions for  $a^3 + b^3 + c^3 = 6abc$ in  $\mathbb{N}$, such that $gcd(a,b,c) = 1$, except for $(1,2,3)$ and its permutations. Using trial and error I found out that if $a,b,c$ are solution of the equation, then they are in arithmetic progression. I've managed to prove that conjecture, assuming that $c>b>a$ and let $k$ be their common difference in the arithmetic progression. Then WLOG we have: $$b = c-k \quad \quad a = c-2k$$ Now the equation looks like: $$(c-2k)^3 + (c-k)^3 + c^3 = 6(c-2)(c-1)c$$ After expanding we have: $$c^3 - 6kc^2 + 12ck^2 - 8k^3 + c^3 - 3kc^2 + 3ck^2 -k^3 + c^3 = 6c^3 - 18kc^2 + 12ck^2$$ $$3c^3 - 9kc^2 + 15ck^2 - 9k^3 = 6c^3 - 18kc^2 + 12ck^2$$ $$c^3 - 3kc^2 + 5ck^2 - 3k^3 = 2c^3 - 6kc^2 + 4ck^2$$ $$-c^3 + 3kc^2 + ck^2 - 3k^3 = 0$$ Now it's easy to see that if $k=c$, then the LHS will be zero, so one of the zeroes of the polynomial is $c_1 = k$, now factorizing we have: $$(c-k)(3a^2 + 2ax - x^2) = 0$$ $$(c-k)(c+k)(c-3k) = 0$$ Now we have three distinct cases: Case 1: $c = k$ This implies that $b = 0$ and $a = -k$. But because $k \in \mathbb{N}$, both $a,b \not\in \mathbb{N}$, violating the initial conditions. Case 2: $c = -k$ Obviously the initial condition is already violated, becasue $k \in \mathbb{N}$, so from the relation $c \not\in \mathbb{N}$ Case 2: $c = 3k$ This implies that $b = 2k$ and $a = k$. Now we have one 3-tuple $(3k,2k,k)$ and it's permutation as solution, where $k \in \mathbb{N}$. But it's easy to note that $k$ is a common factor for $a,b,c$ so we have: $$gcd(a,b,c) = k$$ But because we want $gcd(a,b,c) = 1$, this implies that $k=1$, which means we have only one solution for  $a^3 + b^3 + c^3 = 6abc$ in  $\mathbb{N}$, such that $gcd(a,b,c) = 1$ and it $(1,2,3)$, solution that is already given. Now my question is what I'm missing. Is there really no other solutions such that $gcd(a,b,c) = 1$? Or maybe there is a different way to obtain solution except for my method using arithmetic progression?",,"['sequences-and-series', 'polynomials', 'factoring', 'divisibility']"
84,How to determine whether this series convergent or divergent?,How to determine whether this series convergent or divergent?,,"Does $$ \dfrac{7}{19}+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}\sqrt[3]{\dfrac{7}{19}}+\cdots+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}\sqrt[3]{\dfrac{7}{19}}\cdots\sqrt[n]{\dfrac{7}{19}}+\cdots $$ converge or diverge? The following is my idea: use $1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}>\ln{n}$ $$   \sum_{n=1}^{\infty}\left(\dfrac{7}{19}\right)^{(1+1/2+\cdots+1/n)} < \sum_{n=1}^{\infty}\left(\dfrac{7}{19}\right)^{\ln{n}} = \sum_{n=1}^{\infty}n^{-\ln(19/7)} $$ But $p=\ln{\dfrac{19}{7}}<1$, becasue $\dfrac{19}{7}\approx 2.71428<e=2.71828$ I guess the series is divergent because I use  $$1+1/2+\cdots+1/n\approx \ln{n}, n\to\infty$$ to find $$\sum_{n=1}^{\infty} (1/x)^{1+1/2+1/3+\cdots+1/n}$$ is convergent only if $x>e$. So, my question is: how do I determine whether $$ \dfrac{7}{19}+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}\sqrt[3]{\dfrac{7}{19}}+\cdots+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}\sqrt[3]{\dfrac{7}{19}}\cdots\sqrt[n]{\dfrac{7}{19}}+\cdots $$ converges or diverges? Thank you","Does $$ \dfrac{7}{19}+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}\sqrt[3]{\dfrac{7}{19}}+\cdots+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}\sqrt[3]{\dfrac{7}{19}}\cdots\sqrt[n]{\dfrac{7}{19}}+\cdots $$ converge or diverge? The following is my idea: use $1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}>\ln{n}$ $$   \sum_{n=1}^{\infty}\left(\dfrac{7}{19}\right)^{(1+1/2+\cdots+1/n)} < \sum_{n=1}^{\infty}\left(\dfrac{7}{19}\right)^{\ln{n}} = \sum_{n=1}^{\infty}n^{-\ln(19/7)} $$ But $p=\ln{\dfrac{19}{7}}<1$, becasue $\dfrac{19}{7}\approx 2.71428<e=2.71828$ I guess the series is divergent because I use  $$1+1/2+\cdots+1/n\approx \ln{n}, n\to\infty$$ to find $$\sum_{n=1}^{\infty} (1/x)^{1+1/2+1/3+\cdots+1/n}$$ is convergent only if $x>e$. So, my question is: how do I determine whether $$ \dfrac{7}{19}+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}\sqrt[3]{\dfrac{7}{19}}+\cdots+\dfrac{7}{19}\sqrt{\dfrac{7}{19}}\sqrt[3]{\dfrac{7}{19}}\cdots\sqrt[n]{\dfrac{7}{19}}+\cdots $$ converges or diverges? Thank you",,['sequences-and-series']
85,Does $\sum_{k=1}^{\infty} \frac{1}{8^k+2^k+1}$ have a closed form?,Does  have a closed form?,\sum_{k=1}^{\infty} \frac{1}{8^k+2^k+1},Is there a closed form for this infinite summation? $$\sum_{k=1}^{\infty} \frac{1}{8^k+2^k+1}$$,Is there a closed form for this infinite summation? $$\sum_{k=1}^{\infty} \frac{1}{8^k+2^k+1}$$,,['sequences-and-series']
86,How to decompose displaced Hermite-Gauss function into higher order HGs?,How to decompose displaced Hermite-Gauss function into higher order HGs?,,"The Hermite-Gauss functions appear commonly in physics.  These functions are formed from the product of a Hermite polynomial and a Gaussian: $$ u_n(x) = \left(\frac{2}{\pi w_0^2}\right)^{1/4} \frac{1}{\sqrt{n! 2^n}} H_n\left(\frac{\sqrt{2}x}{w_0}\right)\exp\left\{-\left(\frac{x}{w_0}\right)^2\right\}$$ and are orthonormal: $$ \int_{-\infty}^{\infty} u_n(x) u_m(x) dx = \delta_{n,m}$$ In a paper ( 2004 J. Opt. B 6 495 ) I found the following identity, which gives the decomposition of a displaced mode $u_0(x-a)$ in terms of a series over high-order Hermite-Gauss functions $u_n(x)$ : $$ \int_{-\infty}^{\infty} u_0(x - a) u_n(x) dx  = \frac{a^n}{w_0^n \sqrt{n!}} \exp\left\{ -\frac{a^2}{2 w_0^2}\right\} $$ How is this derived? (In addition to deriving it by hand, I would like to know how to coax Mathematica into giving it.) EDIT: Here is an animation showing the decomposition of a displaced Gaussian into higher-order Hermite-Gauss functions (modes):","The Hermite-Gauss functions appear commonly in physics.  These functions are formed from the product of a Hermite polynomial and a Gaussian: and are orthonormal: In a paper ( 2004 J. Opt. B 6 495 ) I found the following identity, which gives the decomposition of a displaced mode in terms of a series over high-order Hermite-Gauss functions : How is this derived? (In addition to deriving it by hand, I would like to know how to coax Mathematica into giving it.) EDIT: Here is an animation showing the decomposition of a displaced Gaussian into higher-order Hermite-Gauss functions (modes):"," u_n(x) = \left(\frac{2}{\pi w_0^2}\right)^{1/4} \frac{1}{\sqrt{n! 2^n}} H_n\left(\frac{\sqrt{2}x}{w_0}\right)\exp\left\{-\left(\frac{x}{w_0}\right)^2\right\}  \int_{-\infty}^{\infty} u_n(x) u_m(x) dx = \delta_{n,m} u_0(x-a) u_n(x)  \int_{-\infty}^{\infty} u_0(x - a) u_n(x) dx 
= \frac{a^n}{w_0^n \sqrt{n!}} \exp\left\{ -\frac{a^2}{2 w_0^2}\right\} ","['sequences-and-series', 'special-functions']"
87,"When is the weighted space $\ell^p(\mathbb{Z},\omega)$ a Banach algebra ($p>1$)?",When is the weighted space  a Banach algebra ()?,"\ell^p(\mathbb{Z},\omega) p>1","Let $\omega:\mathbb{Z}\to (0,\infty)$ and let $1\leq p<\infty$. Consider the space  $\ell^p(\mathbb{Z},\omega)$ of complex valued sequences $f=(a_n)_{n \in \mathbb{Z}}$ such that  $$\|f\|=\|f\|_{\ell^p(\mathbb{Z},\omega)}:=\left(\sum_{n\in\mathbb{Z}}|a_n|^p\omega(n)^p\right)^{1/p}<\infty.$$ Next, given two complex sequences $f=(a_n)_{n \in \mathbb{Z}}$ and $g=(b_n)_{n \in \mathbb{Z}}$ their formal convolution is defined by $f*g=(c_n)_{n\in\mathbb{Z}}$ where $c_n=\sum_{k\in\mathbb{Z}}a_kb_{n-k}$. The problem is to find necessary and sufficient conditions on $\omega$ such that $\ell^p(\mathbb{Z},\omega)$ is a Banach algebra.  In other words, if $f,g\in\ell^p(\mathbb{Z},\omega)$ then $f*g\in \ell^p(\mathbb{Z},\omega)$ and $\|f*g\|\leq\|f\|\cdot\|g\|$. For $p=1$ the condition is $\omega(n+k)\leq\omega(n)\omega(k)$. --- Reformulated the problem so that $f\in\ell^p(\omega)$ is the same as $f\omega\in\ell^p$. I believe this is an open problem, there are however sufficient conditions:  $\omega^{-p'}*\omega^{-p'}\leq \omega^{-p'}$ where $1/p̈́'+1/p=1$ (the history of the condition is hard to tell but it is given as Lemma 8.11 in Acta Mathematica Volume 174, Number 1, 1-84, ""Completeness of translates in weighted spaces on the half-line"" by Alexander Borichev and Håkan Hedenmalm). The proof is based on Hölder's inequality: $$\|f*g\|^p =\sum_n \left|\sum_k a_kb_{n-k}\right|^p\omega(n)^p\leq $$ $$\leq\sum_n \left(\sum_k |a_k|^p|b_{n-k}|^p\omega(n-k)^p\omega(k)^p\right)\left(\sum_k\frac{1}{\omega(n-k)^{p'}\omega(k)^{p'}}\right)^{\frac{p}{p'}}\omega(n)^p\leq $$ $$\qquad\leq\|f\|^p\|g\|^p$$","Let $\omega:\mathbb{Z}\to (0,\infty)$ and let $1\leq p<\infty$. Consider the space  $\ell^p(\mathbb{Z},\omega)$ of complex valued sequences $f=(a_n)_{n \in \mathbb{Z}}$ such that  $$\|f\|=\|f\|_{\ell^p(\mathbb{Z},\omega)}:=\left(\sum_{n\in\mathbb{Z}}|a_n|^p\omega(n)^p\right)^{1/p}<\infty.$$ Next, given two complex sequences $f=(a_n)_{n \in \mathbb{Z}}$ and $g=(b_n)_{n \in \mathbb{Z}}$ their formal convolution is defined by $f*g=(c_n)_{n\in\mathbb{Z}}$ where $c_n=\sum_{k\in\mathbb{Z}}a_kb_{n-k}$. The problem is to find necessary and sufficient conditions on $\omega$ such that $\ell^p(\mathbb{Z},\omega)$ is a Banach algebra.  In other words, if $f,g\in\ell^p(\mathbb{Z},\omega)$ then $f*g\in \ell^p(\mathbb{Z},\omega)$ and $\|f*g\|\leq\|f\|\cdot\|g\|$. For $p=1$ the condition is $\omega(n+k)\leq\omega(n)\omega(k)$. --- Reformulated the problem so that $f\in\ell^p(\omega)$ is the same as $f\omega\in\ell^p$. I believe this is an open problem, there are however sufficient conditions:  $\omega^{-p'}*\omega^{-p'}\leq \omega^{-p'}$ where $1/p̈́'+1/p=1$ (the history of the condition is hard to tell but it is given as Lemma 8.11 in Acta Mathematica Volume 174, Number 1, 1-84, ""Completeness of translates in weighted spaces on the half-line"" by Alexander Borichev and Håkan Hedenmalm). The proof is based on Hölder's inequality: $$\|f*g\|^p =\sum_n \left|\sum_k a_kb_{n-k}\right|^p\omega(n)^p\leq $$ $$\leq\sum_n \left(\sum_k |a_k|^p|b_{n-k}|^p\omega(n-k)^p\omega(k)^p\right)\left(\sum_k\frac{1}{\omega(n-k)^{p'}\omega(k)^{p'}}\right)^{\frac{p}{p'}}\omega(n)^p\leq $$ $$\qquad\leq\|f\|^p\|g\|^p$$",,"['sequences-and-series', 'functional-analysis', 'fourier-series', 'banach-algebras']"
88,Sets closed on addition,Sets closed on addition,,"Consider a set of positive real numbers $S$ which is closed on addition. Also if we have a set of positive real numbers $S_2$ such that each element in $S$ can be expressed as the sum of elements in $S_2$ , allowing an element to be used multiple times, then we say $S_2$ generates $S$ . For any set $S$ (of positive real numbers) closed on addition, we say element is special if it cannot be expressed as the finite sum of other elements (obviously, you can't use the element itself). Then, we call a set good if the set of special elements of $S$ generates $S$ . The problem in question was that if you are given an infinite sequence of positive reals $a_n$ that is decreasing and $a_i$ is in $S$ for all $i$ and $a_i - a_{i+1}$ is also in $S$ for all $i$ , can we find a subset of S closed on addition that is bad? (By the way, S is closed under addition as well) I think the answer is yes but couldn't prove it. Some things i tried to prove was that the set generated by numbers of the form $a_i$ and $a_{i}-a_{i+1}$ for all $i$ is a bad set, and obviously this is a subset of S, but this seemed to fail since i dont know how to express $a_i-a_{i+1}$ as the sum of other elements, but $a_i$ is easy as $a_i = (a_i -a_{i+1})+a_{i+1}$ Also something cool i found was that $a_i-a_{i+1}$ is eventually less than $c$ for any positive real number $c$ , which gives that for any open interval $(a,b)$ with $a<b$ , we have an infinite number of elements in that range","Consider a set of positive real numbers which is closed on addition. Also if we have a set of positive real numbers such that each element in can be expressed as the sum of elements in , allowing an element to be used multiple times, then we say generates . For any set (of positive real numbers) closed on addition, we say element is special if it cannot be expressed as the finite sum of other elements (obviously, you can't use the element itself). Then, we call a set good if the set of special elements of generates . The problem in question was that if you are given an infinite sequence of positive reals that is decreasing and is in for all and is also in for all , can we find a subset of S closed on addition that is bad? (By the way, S is closed under addition as well) I think the answer is yes but couldn't prove it. Some things i tried to prove was that the set generated by numbers of the form and for all is a bad set, and obviously this is a subset of S, but this seemed to fail since i dont know how to express as the sum of other elements, but is easy as Also something cool i found was that is eventually less than for any positive real number , which gives that for any open interval with , we have an infinite number of elements in that range","S S_2 S S_2 S_2 S S S S a_n a_i S i a_i - a_{i+1} S i a_i a_{i}-a_{i+1} i a_i-a_{i+1} a_i a_i = (a_i -a_{i+1})+a_{i+1} a_i-a_{i+1} c c (a,b) a<b","['sequences-and-series', 'semigroups']"
89,Solving the reduced sextic $z^6+z^2+az+b=0$ using the two-parameter Kampé de Fériet function?,Solving the reduced sextic  using the two-parameter Kampé de Fériet function?,z^6+z^2+az+b=0,"First, some background. I. One-Parameter forms The Bring-Jerrard quintic $x^5+x+\alpha=0$ has solution, $$x = -\alpha\sum_{k=0}^\infty(-1)^k\frac{(5k)!}{k!(4k+1)!}\;\alpha^{4k}$$ This series has a narrow radius of convergence, namely $|\alpha|<\left(\frac{4^4}{5^5}\right)^{1/4}\approx 0.53$ . But it can be extended via analytic continuation using the generalized hypergeometric function ${_pF_q},$ $$x = -\alpha\,{_4F_3}\Big(\frac15,\frac25,\frac35,\frac45;\,\frac24,\frac34,\frac54;\,-\frac{5^5}{4^4}\alpha^4\Big)$$ for more general $\alpha$ , thus solving the general quintic. II. Two-Parameter forms The quintic and sextic two-parameter equations, $$By^5+Ay^2+y+1 = 0$$ $$Bz^6+Az^2+z+1 = 0$$ can be solved as, $$y = -\sum_{j=0}^\infty \sum_{k=0}^\infty (-1)^k \frac{(2j+5k)!}{j!k!(j+4k+1)!}\;A^j B^k$$ $$z = -\sum_{j=0}^\infty \sum_{k=0}^\infty (+1)^k \frac{(2j+6k)!}{j!k! (j + 5 k + 1)!}\; A^j B^k$$ with the quintic root $y$ by Passare and Tsikh in this paper , and the sextic root $z$ by Robert Israel in this old MSE answer . The second equation is just the general sextic in disguise since the general sextic can be reduced to the form, $$z^6+z^2+\alpha z+\beta =0$$ Unfortunately, R. Israel's solution $z$ also has a narrow radius of convergence. So we are seeking an analytic continuation such that it will be valid for more general $(A,B)$ thus solving the general sextic. III. Questions If the analytic continuation for the quintic $x$ involves the one -parameter generalized hypergeometric function , does the analytic continuation for R. Israel's sextic $z$ involve the two -parameter Kampé de Fériet function ? Or is it some other two-parameter function, maybe like the Appell series , Humbert series , etc? The Kampé de Fériet function can solve the general sextic in its reduced form. In Mathematica syntax, what would be the input to solve, for example, $z^6+z^2+3z+2=0$ ?","First, some background. I. One-Parameter forms The Bring-Jerrard quintic has solution, This series has a narrow radius of convergence, namely . But it can be extended via analytic continuation using the generalized hypergeometric function for more general , thus solving the general quintic. II. Two-Parameter forms The quintic and sextic two-parameter equations, can be solved as, with the quintic root by Passare and Tsikh in this paper , and the sextic root by Robert Israel in this old MSE answer . The second equation is just the general sextic in disguise since the general sextic can be reduced to the form, Unfortunately, R. Israel's solution also has a narrow radius of convergence. So we are seeking an analytic continuation such that it will be valid for more general thus solving the general sextic. III. Questions If the analytic continuation for the quintic involves the one -parameter generalized hypergeometric function , does the analytic continuation for R. Israel's sextic involve the two -parameter Kampé de Fériet function ? Or is it some other two-parameter function, maybe like the Appell series , Humbert series , etc? The Kampé de Fériet function can solve the general sextic in its reduced form. In Mathematica syntax, what would be the input to solve, for example, ?","x^5+x+\alpha=0 x = -\alpha\sum_{k=0}^\infty(-1)^k\frac{(5k)!}{k!(4k+1)!}\;\alpha^{4k} |\alpha|<\left(\frac{4^4}{5^5}\right)^{1/4}\approx 0.53 {_pF_q}, x = -\alpha\,{_4F_3}\Big(\frac15,\frac25,\frac35,\frac45;\,\frac24,\frac34,\frac54;\,-\frac{5^5}{4^4}\alpha^4\Big) \alpha By^5+Ay^2+y+1 = 0 Bz^6+Az^2+z+1 = 0 y = -\sum_{j=0}^\infty \sum_{k=0}^\infty (-1)^k \frac{(2j+5k)!}{j!k!(j+4k+1)!}\;A^j B^k z = -\sum_{j=0}^\infty \sum_{k=0}^\infty (+1)^k \frac{(2j+6k)!}{j!k! (j + 5 k + 1)!}\; A^j B^k y z z^6+z^2+\alpha z+\beta =0 z (A,B) x z z^6+z^2+3z+2=0","['sequences-and-series', 'polynomials', 'special-functions', 'analytic-functions']"
90,Formula(s) for sharing multiple golden geese,Formula(s) for sharing multiple golden geese,,"Please have mercy on a simple, non-math person like me. I'm trying to find a formula (or even be told it's impossible) for a unique and difficult compound interest scenario pertaining to the Golden Goose. At least it's unique and difficult to me. Setup: Suppose I have a ""Golden Goose"" which is actually just a regular goose except it lays a solid gold egg every day. Also if I wait and accumulate 100 golden eggs, I can exchange them for another goose. Scenario: So I've got a golden goose and I've got a friend, Jimmy, that also has a golden goose! We agree to pool our eggs so we can collectively buy more geese more quickly. So instead of each of each us waiting 100 days to get another goose, we combine our eggs and reach 100 eggs in 50 days. Jimmy then buys a goose bringing us to 3 geese total. We wait 34 more days, combine our 100 eggs again and then I get a goose. So at the end of this 84 day egg-pooling-cycle we each finish with 1 more goose than we started with. We each got a 2nd goose 16 days earlier than if we waited on our own! Now let's try it again adding a 3rd friend with more geese than either of us. We have another friend, Sally, with 4 golden geese. So I have 2, Jimmy has 2, and Sally has 4, which brings us to 8 total. We decide to pool our eggs again to double our geese. Since Sally has double the geese we each do and is therefore contributing double the eggs, it's only fair that she gets double the geese during this next egg pooling cycle. So in 13 days (we're rounding up from 12.xxx days) we accumulate 100 eggs and Sally gets a goose, bring the new total to 9 geese. In 12 more days, I get a goose. New total = 10 geese In 10 more days, Sally gets a goose. New total = 11 geese In 10 more days, Jimmy gets a goose. New total = 12 geese In 9 more days, Sally gets a goose. New total = 13 geese In 8 more days, I gets a goose. New total = 14 geese In 8 more days, Sally gets a goose. New total = 15 geese In 7 more days, Jimmy gets a goose. Final total = 16 geese So at the end of this cycle, which lasted a total of about 77 days, Sally finishes with 8 geese, I have 4, and Jimmy has 4. So we all figure, wow! This is great! The more people with geese we pool together the more everyone gets geese more quickly. Right? Right? WRONG!! If Jimmy and I would have simply pooled our 4 geese without Sally (or if Sally would have accumulated on her own without us), we/she would have reached 8 total geese in 77 days still. We didn't save any time by adding Sally. So now we're left asking ourselves Was our math right and fair? Did everyone get the number of geese they were supposed to? Is there a scenario where pooling eggs is inefficient for some or all participants? What if it was 10 people each with 1 goose? 20 people each with 1 goose? 3 people each with 1 goose and 2 people with 4 geese? Is there a ratio for pooling eggs that is MOST efficient? And now the real question: What is a formula to find the best ratio and/or length of time for pooling eggs and gaining geese based on the number of participants AND the number of geese each participant begins with? Note : Assume the geese all lay one egg at the same time, in unison, in the morning. So if you acquired 100 geese in the morning after they had already laid their eggs for their previous owner, you would have to wait 1 full day for them to lay again next morning. I was surprised to know that there was already a question about the Golden Goose , but it's not super related.","Please have mercy on a simple, non-math person like me. I'm trying to find a formula (or even be told it's impossible) for a unique and difficult compound interest scenario pertaining to the Golden Goose. At least it's unique and difficult to me. Setup: Suppose I have a ""Golden Goose"" which is actually just a regular goose except it lays a solid gold egg every day. Also if I wait and accumulate 100 golden eggs, I can exchange them for another goose. Scenario: So I've got a golden goose and I've got a friend, Jimmy, that also has a golden goose! We agree to pool our eggs so we can collectively buy more geese more quickly. So instead of each of each us waiting 100 days to get another goose, we combine our eggs and reach 100 eggs in 50 days. Jimmy then buys a goose bringing us to 3 geese total. We wait 34 more days, combine our 100 eggs again and then I get a goose. So at the end of this 84 day egg-pooling-cycle we each finish with 1 more goose than we started with. We each got a 2nd goose 16 days earlier than if we waited on our own! Now let's try it again adding a 3rd friend with more geese than either of us. We have another friend, Sally, with 4 golden geese. So I have 2, Jimmy has 2, and Sally has 4, which brings us to 8 total. We decide to pool our eggs again to double our geese. Since Sally has double the geese we each do and is therefore contributing double the eggs, it's only fair that she gets double the geese during this next egg pooling cycle. So in 13 days (we're rounding up from 12.xxx days) we accumulate 100 eggs and Sally gets a goose, bring the new total to 9 geese. In 12 more days, I get a goose. New total = 10 geese In 10 more days, Sally gets a goose. New total = 11 geese In 10 more days, Jimmy gets a goose. New total = 12 geese In 9 more days, Sally gets a goose. New total = 13 geese In 8 more days, I gets a goose. New total = 14 geese In 8 more days, Sally gets a goose. New total = 15 geese In 7 more days, Jimmy gets a goose. Final total = 16 geese So at the end of this cycle, which lasted a total of about 77 days, Sally finishes with 8 geese, I have 4, and Jimmy has 4. So we all figure, wow! This is great! The more people with geese we pool together the more everyone gets geese more quickly. Right? Right? WRONG!! If Jimmy and I would have simply pooled our 4 geese without Sally (or if Sally would have accumulated on her own without us), we/she would have reached 8 total geese in 77 days still. We didn't save any time by adding Sally. So now we're left asking ourselves Was our math right and fair? Did everyone get the number of geese they were supposed to? Is there a scenario where pooling eggs is inefficient for some or all participants? What if it was 10 people each with 1 goose? 20 people each with 1 goose? 3 people each with 1 goose and 2 people with 4 geese? Is there a ratio for pooling eggs that is MOST efficient? And now the real question: What is a formula to find the best ratio and/or length of time for pooling eggs and gaining geese based on the number of participants AND the number of geese each participant begins with? Note : Assume the geese all lay one egg at the same time, in unison, in the morning. So if you acquired 100 geese in the morning after they had already laid their eggs for their previous owner, you would have to wait 1 full day for them to lay again next morning. I was surprised to know that there was already a question about the Golden Goose , but it's not super related.",,"['sequences-and-series', 'modular-arithmetic', 'problem-solving', 'economics', 'word-problem']"
91,"Is there a notion of Lucas/Fibonacci sequences beyond adding two numbers at a time, if so where could I read more about that?","Is there a notion of Lucas/Fibonacci sequences beyond adding two numbers at a time, if so where could I read more about that?",,"So I recently learned about lucas/fibbonaci sequences EG; 1,1,2,3,5,7 or 3,4,7,11,18... A fact I learned about these sequence is that the limit of the quotient of the terms approaches the golden ratio (1.61803398874989484820). What I found independently (somewhat) was that this ratio could also be understood as the root of the polynomial $x^2-x-1$ (this can be derived from the geometric definition of the golden ratio). In trying to understand the golden ratio further, I extended the notion first by finding a new version of the fibbonaci sequence starting with three terms. 1,1,1:3,5,9,17,31,57,105... The ratios of this sequence converge to roughly 1.83, which is also one of the real roots of the polynomial $x^3-x^2-x-1$ . At this point, I'm pretty sure that's an obvious pattern. After I found the ratio for the 3-fibbonaci/lucas sequence I began to wonder what the ratio of an inifnite version of this would converge to (if at all). So I wrote out a general notation for a sequence where you add up n terms starting with (x0,x1,x2,,,,,,xn). The first term of the sequence is the summation from k=0 to n or ""X sub K."" The second term is the earlier term plus the summation from k=1 to n. As you write out the terms, you can show that the ratio of the terms converges to 2. Lastly, does this imply that 2 is the root of the polynomial $x^n-x^{n-1}....-x-1?$","So I recently learned about lucas/fibbonaci sequences EG; 1,1,2,3,5,7 or 3,4,7,11,18... A fact I learned about these sequence is that the limit of the quotient of the terms approaches the golden ratio (1.61803398874989484820). What I found independently (somewhat) was that this ratio could also be understood as the root of the polynomial (this can be derived from the geometric definition of the golden ratio). In trying to understand the golden ratio further, I extended the notion first by finding a new version of the fibbonaci sequence starting with three terms. 1,1,1:3,5,9,17,31,57,105... The ratios of this sequence converge to roughly 1.83, which is also one of the real roots of the polynomial . At this point, I'm pretty sure that's an obvious pattern. After I found the ratio for the 3-fibbonaci/lucas sequence I began to wonder what the ratio of an inifnite version of this would converge to (if at all). So I wrote out a general notation for a sequence where you add up n terms starting with (x0,x1,x2,,,,,,xn). The first term of the sequence is the summation from k=0 to n or ""X sub K."" The second term is the earlier term plus the summation from k=1 to n. As you write out the terms, you can show that the ratio of the terms converges to 2. Lastly, does this imply that 2 is the root of the polynomial",x^2-x-1 x^3-x^2-x-1 x^n-x^{n-1}....-x-1?,"['sequences-and-series', 'number-theory', 'polynomials', 'recurrence-relations', 'golden-ratio']"
92,Prove that all elements of sequence $a_{n}=\frac{ \left(1+\sqrt{n^4-n^2+1}\right)^{n} + \left(1-\sqrt{n^4-n^2+1}\right)^{n}}{2^{n}}$ are integers.,Prove that all elements of sequence  are integers.,a_{n}=\frac{ \left(1+\sqrt{n^4-n^2+1}\right)^{n} + \left(1-\sqrt{n^4-n^2+1}\right)^{n}}{2^{n}},"$\textbf{PROBLEM}$ : Prove or disprove that all elements of sequence $a_{n}=\frac{ \left(1+\sqrt{n^4-n^2+1}\right)^{n} + \left(1-\sqrt{n^4-n^2+1}\right)^{n}}{2^{n}}$ are integers. $\textbf{MY THOUGHTS}$ : First thing to note is that $${\forall n \in \mathbb{N}~~~~~ \exists k \in \mathbb{Z}:~~~~~  \left( n^4-n^2 \right) = 4k}$$ Secondly, according to Binomial theorem, $$ a_{n}=\frac{\sum\limits_{i=0}^{\lfloor \frac n2 \rfloor} {n \choose 2i} \cdot \left(n^4-n^2+1 \right)^i}{2^{n-1}}$$ I've tried to prove statement by induction on $n$ , using facts above, but didn't manage to do it. I also thought about using the fact that $$\begin{cases} \left(1+\sqrt{n^4-n^2+1}\right) + \left(1-\sqrt{n^4-n^2+1}\right) = 2\\ \left(1+\sqrt{n^4-n^2+1}\right) \cdot \left(1-\sqrt{n^4-n^2+1}\right)= n^2 - n^4\end{cases}  $$ So, we could think about $\left(1+\sqrt{n^4-n^2+1}\right)$ and $\left(1-\sqrt{n^4-n^2+1}\right)$ as roots of $x^2 -2x + n^2 -n^4$ . In that case we can try to solve equivalent problem: Prove that $ \frac{x_1^n+x_2^n}{2^n}$ is integer if $x_1$ and $x_2$ are roots of $x^2 -2x + n^2 -n^4$ .",": Prove or disprove that all elements of sequence are integers. : First thing to note is that Secondly, according to Binomial theorem, I've tried to prove statement by induction on , using facts above, but didn't manage to do it. I also thought about using the fact that So, we could think about and as roots of . In that case we can try to solve equivalent problem: Prove that is integer if and are roots of .",\textbf{PROBLEM} a_{n}=\frac{ \left(1+\sqrt{n^4-n^2+1}\right)^{n} + \left(1-\sqrt{n^4-n^2+1}\right)^{n}}{2^{n}} \textbf{MY THOUGHTS} {\forall n \in \mathbb{N}~~~~~ \exists k \in \mathbb{Z}:~~~~~  \left( n^4-n^2 \right) = 4k}  a_{n}=\frac{\sum\limits_{i=0}^{\lfloor \frac n2 \rfloor} {n \choose 2i} \cdot \left(n^4-n^2+1 \right)^i}{2^{n-1}} n \begin{cases} \left(1+\sqrt{n^4-n^2+1}\right) + \left(1-\sqrt{n^4-n^2+1}\right) = 2\\ \left(1+\sqrt{n^4-n^2+1}\right) \cdot \left(1-\sqrt{n^4-n^2+1}\right)= n^2 - n^4\end{cases}   \left(1+\sqrt{n^4-n^2+1}\right) \left(1-\sqrt{n^4-n^2+1}\right) x^2 -2x + n^2 -n^4  \frac{x_1^n+x_2^n}{2^n} x_1 x_2 x^2 -2x + n^2 -n^4,"['sequences-and-series', 'elementary-number-theory', 'integers']"
93,A riddle involving series.,A riddle involving series.,,"Father has left to his children several identical gold coins. According to his will, the oldest child receives one coin and one-seventh of the remaining coins, the next child receives two coins and one-seventh of remaining coins, the third child receives three coins and one-seventh of the remaining coins, and so on through the youngest child. If every child inherits an integer number of coins then find the number of children and gold coins. I tried to write $x_k$ as some function of $k$ (where $x_k$ is the number of coins taken by the $k_{th}$ child) but failed. All I could write is $x_k= k + \frac{1}{7}(n-k- S_{k-1})$ where $S_k$ denotes the sum of first $k$ terms then $S_k=\frac{n}{7} + \frac{6}{7}(S_{k-1} +k)$ but I cannot proceed further, please help.","Father has left to his children several identical gold coins. According to his will, the oldest child receives one coin and one-seventh of the remaining coins, the next child receives two coins and one-seventh of remaining coins, the third child receives three coins and one-seventh of the remaining coins, and so on through the youngest child. If every child inherits an integer number of coins then find the number of children and gold coins. I tried to write as some function of (where is the number of coins taken by the child) but failed. All I could write is where denotes the sum of first terms then but I cannot proceed further, please help.",x_k k x_k k_{th} x_k= k + \frac{1}{7}(n-k- S_{k-1}) S_k k S_k=\frac{n}{7} + \frac{6}{7}(S_{k-1} +k),['sequences-and-series']
94,Limit of a sequenced defined by arithmetic mean and geometric mean.,Limit of a sequenced defined by arithmetic mean and geometric mean.,,"If $a_1 =\alpha$, $ a_2 = \beta$, and, for every $k$, $$a_{2k+1}= \frac{1} {2k}  \sum_{i=1}^{2k} a_i\qquad a_{2k+2}=\left(\prod_{i=1}^{2k+1} a_i\right)^{1/(2k+1)}$$   what is the limit of the sequence $(a_k)$?, That is, what is $\lim_{n\to\infty}{a_n}?$ I think this sequence converges, but i can't find a clue to figure out its limit. When $\alpha=\beta$, it is clear that $a_n=\alpha$ However, if $\alpha\neq\beta,$ I think i cannot calculate exactly wht $a_n$is, so I'm currently stuck. I know that for all $k$, $\alpha \le a_k \le \beta$, and I think that this sequence converges towards somewhere close to $\min(\alpha, \beta)$ because $a_1=\alpha$, $a_2=\beta$, $a_3=\frac{\alpha + \beta}{2}$, $a_4=(\frac{\alpha\beta(\alpha+\beta)}{2})^{1/3}$, but I can't figure out what to do next. For example, here is a sequence when $\alpha=2, \beta=4$: $$a_1=2, a_2=4, a_3=3, a_4=2.8845, a_5=2.9711, a_6=2.90162, a_7=2.95953, a_8=2.9098, a_9=2.95331, a_{10}=2.91462, a_{11}=2.9494, a_{12}=2.91776, a_{13}=2.9468, a_{14}=2.91998...$$ Edit: I think as $n$ increases, $$a_{2k+2}\le a_{2k+4}\le a_{2k+3}\le a_{2k+1}$$ Could anybody confirm this please? If this is right, $a_n$ converges to $2.9.....$ I found that the above inequality is right using mathematical induction Let $\alpha<\beta$, then $a_3=\frac{\alpha+\beta}{2}$, $a_4=\sqrt[3]{\alpha\beta\frac{\alpha+\beta}{2}}=\sqrt[3]{(\frac{\alpha+\beta}{2}+\frac{\beta-\alpha}{2})(\frac{\alpha+\beta}{2}-\frac{\beta-\alpha}{2})(\frac{\alpha+\beta}{2})}=\sqrt[3]{(\frac{\alpha+\beta}{2})^3-A}<\frac{\alpha+\beta}{2}=a_3$   If $a_{2k+1}>a_{2k+2}$,    $$a_{2k+3}=\frac{1}{2k+2}\sum_{i=1}^{2k+2}{a_i}=\frac{a_{2k+2}+a_{2k+1}+\sum_{i=1}^{2k}{a_i}}{2k+2}=\frac{a_{2k+2}+(2k+1)a_{2k+1}}{2k+2}\\\therefore a_{2k+2}<a_{2k+3}<a_{2k+1}\\a_{2k+4}=(\prod_{i=1}^{2k+3}{a_i})^{\frac{1}{2k+3}}=(a_{2k+3}\cdot (a_{2k+2})^{2k+2})^{\frac{1}{2k+3}}\\\therefore a_{2k+2}<a_{2k+4}<a_{2k+3}\\\therefore a_{2k+2}<a_{2k+4}<a_{2k+3}<a_{2k+1}$$By the mathematical induction, for all natural number $n$, $a_{2n+2}<a_{2n+4}<a_{2n+3}<a_{2n+1}$ This means that the sequence $\{a_{2n}\}$ and $\{a_{2n+1}\}$ converges, since the two sequences are monotone increasing and monotone decreasing, and the two sequences are bounded(since $\alpha<\{a_{2n}\}<\{a_{2n+1}\}<\beta$). Now I want to know whether the two limits of these two sequences are the same, which means $\{a_{n}\}$ converges.","If $a_1 =\alpha$, $ a_2 = \beta$, and, for every $k$, $$a_{2k+1}= \frac{1} {2k}  \sum_{i=1}^{2k} a_i\qquad a_{2k+2}=\left(\prod_{i=1}^{2k+1} a_i\right)^{1/(2k+1)}$$   what is the limit of the sequence $(a_k)$?, That is, what is $\lim_{n\to\infty}{a_n}?$ I think this sequence converges, but i can't find a clue to figure out its limit. When $\alpha=\beta$, it is clear that $a_n=\alpha$ However, if $\alpha\neq\beta,$ I think i cannot calculate exactly wht $a_n$is, so I'm currently stuck. I know that for all $k$, $\alpha \le a_k \le \beta$, and I think that this sequence converges towards somewhere close to $\min(\alpha, \beta)$ because $a_1=\alpha$, $a_2=\beta$, $a_3=\frac{\alpha + \beta}{2}$, $a_4=(\frac{\alpha\beta(\alpha+\beta)}{2})^{1/3}$, but I can't figure out what to do next. For example, here is a sequence when $\alpha=2, \beta=4$: $$a_1=2, a_2=4, a_3=3, a_4=2.8845, a_5=2.9711, a_6=2.90162, a_7=2.95953, a_8=2.9098, a_9=2.95331, a_{10}=2.91462, a_{11}=2.9494, a_{12}=2.91776, a_{13}=2.9468, a_{14}=2.91998...$$ Edit: I think as $n$ increases, $$a_{2k+2}\le a_{2k+4}\le a_{2k+3}\le a_{2k+1}$$ Could anybody confirm this please? If this is right, $a_n$ converges to $2.9.....$ I found that the above inequality is right using mathematical induction Let $\alpha<\beta$, then $a_3=\frac{\alpha+\beta}{2}$, $a_4=\sqrt[3]{\alpha\beta\frac{\alpha+\beta}{2}}=\sqrt[3]{(\frac{\alpha+\beta}{2}+\frac{\beta-\alpha}{2})(\frac{\alpha+\beta}{2}-\frac{\beta-\alpha}{2})(\frac{\alpha+\beta}{2})}=\sqrt[3]{(\frac{\alpha+\beta}{2})^3-A}<\frac{\alpha+\beta}{2}=a_3$   If $a_{2k+1}>a_{2k+2}$,    $$a_{2k+3}=\frac{1}{2k+2}\sum_{i=1}^{2k+2}{a_i}=\frac{a_{2k+2}+a_{2k+1}+\sum_{i=1}^{2k}{a_i}}{2k+2}=\frac{a_{2k+2}+(2k+1)a_{2k+1}}{2k+2}\\\therefore a_{2k+2}<a_{2k+3}<a_{2k+1}\\a_{2k+4}=(\prod_{i=1}^{2k+3}{a_i})^{\frac{1}{2k+3}}=(a_{2k+3}\cdot (a_{2k+2})^{2k+2})^{\frac{1}{2k+3}}\\\therefore a_{2k+2}<a_{2k+4}<a_{2k+3}\\\therefore a_{2k+2}<a_{2k+4}<a_{2k+3}<a_{2k+1}$$By the mathematical induction, for all natural number $n$, $a_{2n+2}<a_{2n+4}<a_{2n+3}<a_{2n+1}$ This means that the sequence $\{a_{2n}\}$ and $\{a_{2n+1}\}$ converges, since the two sequences are monotone increasing and monotone decreasing, and the two sequences are bounded(since $\alpha<\{a_{2n}\}<\{a_{2n+1}\}<\beta$). Now I want to know whether the two limits of these two sequences are the same, which means $\{a_{n}\}$ converges.",,"['sequences-and-series', 'convergence-divergence', 'means']"
95,"What is the name of the conjecture related to what Matt Parker has called ""The Square-Sum Problem""?","What is the name of the conjecture related to what Matt Parker has called ""The Square-Sum Problem""?",,"I read a book called Things to Make and Do in the Fourth Dimension , written by Australian mathe-matician and comedian, Matt Parker. In one part of the book, I remember him explaining about a conjecture such that for all $n\geqslant 89$, you can arrange the elements of the set $\{1, 2,\ldots,n\}$ in a certain way where each adjacent pair of elements sums to a squared number. For example, let $n = 17$. Al-though $17<89$, below is a good example to demonstrate what I mean: We have the set $\{1, 2, 3,\ldots, 17\}$ which can also be written as $\mathbb{N}_{\leqslant 17}$. How can we order each number in a certain way such that every adjacent pair of numbers in the ordered sequence add up to a squa-red number? Well, we order it like so: Let $S_{17} = [\ldots]$ be our sequence that orders the elements from $\{1, 2, 3,\ldots, 17\}$ in a certain way as mentioned in the foregoing then, $$S_{17} := \big[17, 8, 1, 15, 10, 6, 3, 13, 12, 4, 5, 11, 14, 2, 7, 9, 16\big].$$ Here, $17 + 8 = 5^2$, $8 + 1 = 3^2$, $1 + 15 = 4^2,\ldots$ The sequence in the sandbox above is a special case where it has $17$ elements and begins with $17$. Take the sequence $S_{16}$ then this sequence ends with $16$. In fact, it is exactly the same as $S_{17}$ except it does not start from $17$, but $8$ instead. However, the sequence $S_{18}$ does not exist, and there are many sequences with this property that do not exist. The conjecture is interesting because if true, it will prove that there are only finitely many sequences $S_n$ that do not exist, also proving the contrapo-sitive. I did some research and it seems like this is true for $89\leqslant n \leqslant 300$ thus far, but I do not know the name of this conjecture. Does it even have a name? I also haven’t stumbled across any attempts of proving this conjecture. Can it be done? I guess that is two questions, then. Thank you in advance.","I read a book called Things to Make and Do in the Fourth Dimension , written by Australian mathe-matician and comedian, Matt Parker. In one part of the book, I remember him explaining about a conjecture such that for all $n\geqslant 89$, you can arrange the elements of the set $\{1, 2,\ldots,n\}$ in a certain way where each adjacent pair of elements sums to a squared number. For example, let $n = 17$. Al-though $17<89$, below is a good example to demonstrate what I mean: We have the set $\{1, 2, 3,\ldots, 17\}$ which can also be written as $\mathbb{N}_{\leqslant 17}$. How can we order each number in a certain way such that every adjacent pair of numbers in the ordered sequence add up to a squa-red number? Well, we order it like so: Let $S_{17} = [\ldots]$ be our sequence that orders the elements from $\{1, 2, 3,\ldots, 17\}$ in a certain way as mentioned in the foregoing then, $$S_{17} := \big[17, 8, 1, 15, 10, 6, 3, 13, 12, 4, 5, 11, 14, 2, 7, 9, 16\big].$$ Here, $17 + 8 = 5^2$, $8 + 1 = 3^2$, $1 + 15 = 4^2,\ldots$ The sequence in the sandbox above is a special case where it has $17$ elements and begins with $17$. Take the sequence $S_{16}$ then this sequence ends with $16$. In fact, it is exactly the same as $S_{17}$ except it does not start from $17$, but $8$ instead. However, the sequence $S_{18}$ does not exist, and there are many sequences with this property that do not exist. The conjecture is interesting because if true, it will prove that there are only finitely many sequences $S_n$ that do not exist, also proving the contrapo-sitive. I did some research and it seems like this is true for $89\leqslant n \leqslant 300$ thus far, but I do not know the name of this conjecture. Does it even have a name? I also haven’t stumbled across any attempts of proving this conjecture. Can it be done? I guess that is two questions, then. Thank you in advance.",,"['sequences-and-series', 'conjectures']"
96,A list of Multiple Zeta values of depth three,A list of Multiple Zeta values of depth three,,"The multiple zeta function of depth three has a following integral representation:  \begin{eqnarray} \zeta(t^{-1},p,q,r) &:=& \sum\limits_{m_1 > m_2 > m_3 > 0} \frac{t^{m_1}}{m_1^p} \frac{1}{m_2^q} \frac{1}{m_3^r} \\ &=& \int\limits_0^t \frac{[\log(t/\xi)]^{p-1}}{(p-1)!} \int\limits_0^{\xi} \frac{[\log(\xi/\xi_1)]^{q-1}}{(q-1)!} \cdot \frac{Li_r(\xi_1)}{1-\xi_1} d\xi_1 \frac{1}{1-\xi} d\xi  \end{eqnarray} By using the formula above we calculated the following list of values at plus unity for weights from four to six. We have: \begin{eqnarray} \zeta(2,1,1) &=& \zeta(4)\\ \hline\\ \zeta(3,1,1) &=& -  \zeta(2) \zeta(3) + 2 \zeta(5)\\ \zeta(2,2,1) &=& + 3\zeta(2) \zeta(3) -\frac{11}{2} \zeta(5)\\ \zeta(2,1,2) &=& - 2\zeta(2) \zeta(3) + \frac{9}{2} \zeta(5)\\ \hline \\ \zeta(4,1,1) &=& -  \zeta(3)^2 + \frac{23}{16} \zeta(6)\\ \zeta(3,2,1) &=& +3  \zeta(3)^2 - \frac{203}{48} \zeta(6)\\ \zeta(3,1,2) &=& -\frac{3}{2}  \zeta(3)^2 + \frac{53}{24} \zeta(6)\\ \zeta(2,3,1) &=& -\frac{3}{2}  \zeta(3)^2 + \frac{53}{24} \zeta(6)\\ \zeta(2,2,2) &=& \frac{3}{16} \zeta(6) \\ \zeta(2,1,3) &=& + \zeta(3)^2 - \frac{13}{16} \zeta(6)\\ \hline \zeta(5,1,1)&=&-\frac{5}{4} \zeta(3) \zeta(4)-2 \zeta(2)\zeta(5) +5 \zeta(7)\\ \zeta(4,2,1)&=&+\frac{-236 \zeta(3) \zeta(2)^2+28776 \zeta(5) \zeta(2)+18902 \zeta(3) \zeta(4)-72267 \zeta(7)}{5232}\\ \zeta(4,1,2)&=&-\frac{451}{327} \zeta(3) \zeta(2)^2+\frac{5}{2} \zeta(5) \zeta(2)-\frac{395 \zeta(3) \zeta(4)}{1308}+\frac{5 \zeta(7)}{8}\\ \zeta(3,3,1)&=&-\frac{77}{109} \zeta(3)\zeta(2)^2-\frac{9}{2} \zeta(5) \zeta(2)+\frac{385}{218} \zeta(3) \zeta(4)+\frac{61 \zeta(7)}{8}\\ \zeta(3,2,2)&=&+\frac{15908 \zeta(3) \zeta(2)^2-39240 \zeta(5) \zeta(2)-27998 \zeta(3) \zeta(4)+51339 \zeta(7)}{5232}\\ \zeta(3,1,3)&=&+\frac{1600 \zeta(3) \zeta(2)^2-3673 \zeta(3) \zeta(4)-327\zeta(7)}{1308}\\ \zeta(2,4,1)&=&+\frac{59 \zeta(3) \zeta(2)^2}{1308}+5 \zeta(5) \zeta(2)-\frac{3565 \zeta(3) \zeta(4)}{2616}-\frac{109 \zeta(7)}{16}\\ \zeta(2,3,2)&=&-\frac{1519}{654} \zeta(3) \zeta(2)^2-\frac{11}{2} \zeta(5) \zeta(2)+\frac{7595 \zeta(3) \zeta(4)}{1308}+\frac{75 \zeta(7)}{8}\\ \zeta(2,2,3)&=&+\frac{844 \zeta(3) \zeta(2)^2+62784 \zeta(5) \zeta(2)-9958 \zeta(3) \zeta(4)-95157 \zeta(7)}{5232}\\ \zeta(2,1,4)&=&+\frac{1}{8} (14 \zeta(3) \zeta(4)-44 \zeta(2) \zeta(5)+61 \zeta(7))\\ \hline\\ \zeta(6,1,1)&=&+\frac{1}{2} \zeta (3)^2 \zeta(2)-3 \zeta (3) \zeta (5)+\frac{61 \zeta(8)}{24}\\ \zeta(5,2,1)&=&+\frac{7}{4} \zeta(6,2)-\zeta (3)^2 \zeta(2)+\frac{7 \zeta (3) \zeta (5)}{2}-\frac{289\zeta(8)}{144}\\ \zeta(5,1,2)&=&-\zeta(6,2)-\frac{3}{2} \zeta (3)^2 \zeta(2)+\frac{9 \zeta (3) \zeta (5)}{2}-\frac{145 \zeta(8)}{72}\\ \zeta(4,3,1)&=&-\frac{25}{4} \zeta(6,2)+\frac{1}{2} \zeta (3)^2\zeta(2)+\frac{21 \zeta (3) \zeta (5)}{2}-\frac{677 \zeta(8)}{48}\\ \zeta(4,2,2)&=&+\frac{9}{2} \zeta(6,2)+3 \zeta (3)^2 \zeta(2)-20 \zeta (3) \zeta (5)+\frac{1271\zeta(8)}{72}\\ \zeta(4,1,3)&=&+\frac{5}{2} \zeta(6,2)+\frac{1}{2} \zeta (3)^2 \zeta(2)-\frac{15 \zeta (3) \zeta (5)}{2}+\frac{583 \zeta(8)}{72}\\ \zeta(3,4,1)&=&+\frac{15}{4} \zeta(6,2)-2 \zeta (3)^2\zeta(2)+\frac{673 \zeta(8)}{144}\\ \zeta(3,3,2)&=&+\frac{13}{4} \zeta(6,2)+\frac{9}{2} \zeta (3)^2 \zeta(2)-23 \zeta (3) \zeta (5)+\frac{857 \zeta(8)}{48}\\ \zeta(3,2,3)&=&-10 \zeta(6,2)-6\zeta (3)^2 \zeta(2)+\frac{89 \zeta (3) \zeta (5)}{2}-\frac{245 \zeta(8)}{6}\\ \zeta(3,1,4)&=&+\frac{3}{2} \zeta (3)^2 \zeta(2)-\frac{11 \zeta (3) \zeta (5)}{2}+\frac{241\zeta(8)}{72}\\ \zeta(2,5,1)&=&+\frac{7}{4} \zeta(6,2)+2 \zeta (3)^2 \zeta(2)-12 \zeta (3) \zeta (5)+\frac{487 \zeta(8)}{48}\\ \zeta(2,4,2)&=&-10 \zeta(6,2)-5 \zeta (3)^2 \zeta(2)+40 \zeta (3)\zeta (5)-\frac{677 \zeta(8)}{18}\\ \zeta(2,3,3)&=&+\frac{27}{4} \zeta(6,2)+2 \zeta (3)^2 \zeta(2)-\frac{45 \zeta (3) \zeta (5)}{2}+\frac{1111 \zeta(8)}{48}\\ \zeta(2,2,4)&=&+\frac{11}{2} \zeta(6,2)+2\zeta (3)^2 \zeta(2)-20 \zeta (3) \zeta (5)+\frac{121 \zeta(8)}{6}\\ \zeta(2,1,5)&=&-\frac{5}{2} \zeta(6,2)-\zeta (3)^2 \zeta(2)+\frac{21 \zeta (3) \zeta (5)}{2}-\frac{181 \zeta(8)}{18}\\ \hline\\ \zeta(7,1,1)&=&-3 \zeta (7) \zeta(2)-\frac{9}{4} \zeta (5) \zeta(4)-\frac{7}{4} \zeta (3) \zeta(6)+\frac{28 \zeta (9)}{3}+\frac{\zeta (3)^3}{6}\\ \zeta(6,2,1)&=&+11 \zeta (7) \zeta(2)+\frac{13}{2} \zeta(5) \zeta(4)+\frac{9}{2} \zeta (3) \zeta(6)-\frac{2189 \zeta (9)}{72}-\frac{\zeta (3)^3}{3}\\ \zeta(6,1,2)&=&+7 \zeta (7) \zeta(2)-\frac{1}{4} \zeta (5) \zeta(4)-\frac{5}{3} \zeta (3)\zeta(6)-\frac{313 \zeta (9)}{36}-\frac{\zeta (3)^3}{3}\\ \zeta(5,3,1)&=&-17 \zeta (7) \zeta(2)-\frac{23}{4} \zeta (5) \zeta(4)-\frac{3}{4} \zeta (3) \zeta(6)+\frac{845 \zeta (9)}{24}+\frac{\zeta(3)^3}{6}\\ \zeta(5,2,2)&=&-21 \zeta (7) \zeta(2)+\frac{7}{4} \zeta (5) \zeta(4)-\frac{8}{3} \zeta (3) \zeta(6)+\frac{2513 \zeta (9)}{72}+\frac{2 \zeta (3)^3}{3}\\ \zeta(5,1,3)&=&-7 \zeta (7)\zeta(2)+\frac{1}{2} \zeta (5) \zeta(4)+\frac{5}{4} \zeta (3) \zeta(6)+\frac{121 \zeta (9)}{12}-\frac{\zeta (3)^3}{3}\\ \zeta(4,4,1)&=&+18 \zeta (7) \zeta(2)+5 \zeta (5) \zeta(4)+\frac{4}{3}\zeta (3) \zeta(6)-\frac{328 \zeta (9)}{9}-\frac{\zeta (3)^3}{3}\\ \zeta(4,3,2)&=&+14 \zeta (7) \zeta(2)-\frac{35}{2} \zeta (5) \zeta(4)-\frac{8}{3} \zeta (3) \zeta(6)-\frac{53 \zeta (9)}{36}+\frac{2\zeta (3)^3}{3}\\ \zeta(4,2,3)&=&+28 \zeta (7) \zeta(2)+10 \zeta (5) \zeta(4)+\frac{5}{3} \zeta (3) \zeta(6)-59 \zeta (9)-\frac{\zeta (3)^3}{3}\\ \zeta(4,1,4)&=&-3 \zeta (5) \zeta(4)-\frac{41}{12} \zeta (3)\zeta(6)+\frac{115 \zeta (9)}{18}+\frac{2 \zeta (3)^3}{3}\\ \zeta(3,5,1)&=&-10 \zeta (7) \zeta(2)+\frac{5}{4} \zeta (5) \zeta(4)+\frac{5}{4} \zeta (3) \zeta(6)+\frac{341 \zeta (9)}{24}-\frac{\zeta(3)^3}{3}\\ \zeta(3,4,2)&=&-14 \zeta (7) \zeta(2)+\frac{15}{2} \zeta (5) \zeta(4)-\frac{7}{3} \zeta (3) \zeta(6)+\frac{593 \zeta (9)}{36}+\frac{2 \zeta (3)^3}{3}\\ \zeta(3,3,3)&=&-\frac{1}{2} \zeta (3)\zeta(6)+\frac{\zeta (9)}{3}+\frac{\zeta (3)^3}{6}\\ \zeta(3,2,4)&=&-28 \zeta (7) \zeta(2)-\frac{11}{2} \zeta (5) \zeta(4)+\frac{29}{4} \zeta (3) \zeta(6)+46 \zeta (9)-\frac{4 \zeta(3)^3}{3}\\ \zeta(3,1,5)&=&+7 \zeta (7) \zeta(2)-\frac{1}{4} \zeta (5) \zeta(4)-\frac{1}{2} \zeta (3) \zeta(6)-\frac{131 \zeta (9)}{12}+\frac{\zeta (3)^3}{6}\\ \zeta(2,6,1)&=&+7 \zeta (7) \zeta(2)-\frac{7}{4}\zeta (5) \zeta(4)-\frac{43}{12} \zeta (3) \zeta(6)-\frac{461 \zeta (9)}{72}+\frac{2 \zeta (3)^3}{3}\\ \zeta(2,5,2)&=&-11 \zeta (7) \zeta(2)+\frac{41}{6} \zeta (3) \zeta(6)+\frac{439 \zeta(9)}{36}-\frac{4 \zeta (3)^3}{3}\\ \zeta(2,4,3)&=&+31 \zeta (7) \zeta(2)-\frac{15}{2} \zeta (5) \zeta(4)+\zeta (3) \zeta(6)-\frac{1567 \zeta (9)}{36}-\frac{\zeta (3)^3}{3}\\ \zeta(2,3,4)&=&-32 \zeta (7)\zeta(2)+12 \zeta (5) \zeta(4)-\frac{25}{6} \zeta (3) \zeta(6)+\frac{1567 \zeta (9)}{36}+\frac{2 \zeta (3)^3}{3}\\ \zeta(2,2,5)&=&+31 \zeta (7) \zeta(2)-\zeta (5) \zeta(4)-\frac{25}{6} \zeta (3)\zeta(6)-\frac{3319 \zeta (9)}{72}+\frac{2 \zeta (3)^3}{3}\\ \zeta(2,1,6)&=&-11 \zeta (7) \zeta(2)+\frac{1}{4} \zeta (5) \zeta(4)+\frac{37}{12} \zeta (3) \zeta(6)+\frac{551 \zeta (9)}{36}-\frac{\zeta(3)^3}{3}\\ \hline\\ \zeta(8,1,1)&=&+\zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2 \zeta(4)+\frac{333 \zeta(10)}{80}-4 \zeta (3) \zeta (7)-2 \zeta (5)^2\\ \zeta(7,2,1)&=&-\zeta (3)^2 \zeta(4)-\frac{377\zeta(10)}{60}-\zeta(2) \zeta(6,2)+\frac{9}{4} \zeta(8,2)+\frac{9 \zeta (3) \zeta (7)}{2}+\frac{9 \zeta (5)^2}{4}\\ \zeta(7,1,2)&=&-7 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2\zeta(4)-\frac{77 \zeta(10)}{48}+\zeta(2) \zeta(6,2)-\zeta(8,2)+10 \zeta (3) \zeta (7)+5 \zeta (5)^2\\ \zeta(6,3,1)&=&-4 \zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2\zeta(4)-\frac{3219 \zeta(10)}{160}+\frac{5}{2} \zeta(2) \zeta(6,2)-\frac{35}{4} \zeta(8,2)+\frac{29 \zeta (3) \zeta (7)}{2}+\frac{37 \zeta (5)^2}{4}\\ \zeta(6,2,2)&=&+8 \zeta (3) \zeta (5)\zeta(2)+2 \zeta (3)^2 \zeta(4)+\frac{539 \zeta(10)}{16}+\zeta(2) \zeta(6,2)+3 \zeta(8,2)-28 \zeta (3) \zeta (7)-18 \zeta (5)^2\\ \zeta(6,1,3)&=&+16 \zeta (3) \zeta (5)\zeta(2)-\frac{1}{2} \zeta (3)^2 \zeta(4)+\frac{511 \zeta(10)}{160}-\frac{7}{2} \zeta(2) \zeta(6,2)+\frac{7}{2} \zeta(8,2)-21 \zeta (3) \zeta (7)-9 \zeta (5)^2\\ \zeta(5,4,1)&=&-5 \zeta(3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)+\frac{9209 \zeta(10)}{240}+\frac{21}{2} \zeta(8,2)-10 \zeta (3) \zeta (7)-\frac{27 \zeta (5)^2}{2}\\ \zeta(5,3,2)&=&+35 \zeta (3) \zeta (5) \zeta(2)+2\zeta (3)^2 \zeta(4)-\frac{5683 \zeta(10)}{160}-\frac{25}{2} \zeta(2) \zeta(6,2)+\frac{19}{4} \zeta(8,2)-\frac{63 \zeta (3) \zeta (7)}{2}-\frac{3 \zeta (5)^2}{4}\\ \zeta(5,2,3)&=&-50 \zeta (3)\zeta (5) \zeta(2)-2 \zeta (3)^2 \zeta(4)-\frac{719 \zeta(10)}{20}+10 \zeta(2) \zeta(6,2)-\frac{49}{4} \zeta(8,2)+\frac{161 \zeta (3) \zeta (7)}{2}+\frac{163 \zeta(5)^2}{4}\\ \zeta(5,1,4)&=&-10 \zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2 \zeta(4)-\frac{1027 \zeta(10)}{480}+\frac{5}{2} \zeta(2) \zeta(6,2)-\frac{7}{2} \zeta(8,2)+14 \zeta (3)\zeta (7)+\frac{9 \zeta (5)^2}{2}\\ \zeta(4,5,1)&=&+15 \zeta (3) \zeta (5) \zeta(2)-\frac{1173 \zeta(10)}{32}-\frac{5}{2} \zeta(2) \zeta(6,2)-7 \zeta(8,2)-3 \zeta (3) \zeta (7)+9 \zeta(5)^2\\ \zeta(4,4,2)&=&-40 \zeta (3) \zeta (5) \zeta(2)+\frac{249 \zeta(10)}{40}+10 \zeta(2) \zeta(6,2)-\frac{15}{2} \zeta(8,2)+49 \zeta (3) \zeta (7)+15 \zeta (5)^2\\ \zeta(4,3,3)&=&-20 \zeta (3) \zeta(5) \zeta(2)+\frac{3233 \zeta(10)}{40}+10 \zeta(2) \zeta(6,2)+\frac{7}{2} \zeta(8,2)-7 \zeta (3) \zeta (7)-\frac{59 \zeta (5)^2}{2}\\ \zeta(4,2,4)&=&+80 \zeta (3) \zeta (5) \zeta(2)+\zeta(3)^2 \zeta(4)-\frac{\zeta(10)}{6}-20 \zeta(2) \zeta(6,2)+\frac{35}{2} \zeta(8,2)-105 \zeta (3) \zeta (7)-35 \zeta (5)^2\\ \zeta(4,1,5)&=&-11 \zeta (3) \zeta (5) \zeta(2)+\zeta (3)^2\zeta(4)+\frac{4937 \zeta(10)}{480}+\frac{5}{2} \zeta(2) \zeta(6,2)+7 \zeta (3) \zeta (7)+2 \zeta (5)^2\\ \zeta(3,6,1)&=&-13 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)+\frac{53\zeta(10)}{40}+\zeta(2) \zeta(6,2)+\frac{7}{4} \zeta(8,2)+\frac{35 \zeta (3) \zeta (7)}{2}+\frac{21 \zeta (5)^2}{4}\\ \zeta(3,5,2)&=&+20 \zeta (3) \zeta (5) \zeta(2)+2 \zeta (3)^2\zeta(4)+\frac{2303 \zeta(10)}{32}+\frac{5}{2} \zeta(2) \zeta(6,2)+\frac{13}{2} \zeta(8,2)-60 \zeta (3) \zeta (7)-\frac{81 \zeta (5)^2}{2}\\ \zeta(3,4,3)&=&+30 \zeta (3) \zeta (5)\zeta(2)-\frac{2703 \zeta(10)}{20}-20 \zeta(2) \zeta(6,2)+17 \zeta (3) \zeta (7)+50 \zeta (5)^2\\ \zeta(3,3,4)&=&-10 \zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2\zeta(4)+\frac{2191 \zeta(10)}{40}+10 \zeta(2) \zeta(6,2)-\frac{7}{2} \zeta(8,2)-11 \zeta (3) \zeta (7)-\frac{41 \zeta (5)^2}{2}\\ \zeta(3,2,5)&=&-52 \zeta (3) \zeta (5) \zeta(2)-4 \zeta(3)^2 \zeta(4)-\frac{241 \zeta(10)}{5}+10 \zeta(2) \zeta(6,2)-\frac{63}{4} \zeta(8,2)+\frac{195 \zeta (3) \zeta (7)}{2}+\frac{159 \zeta (5)^2}{4}\\ \zeta(3,1,6)&=&+17 \zeta (3) \zeta (5)\zeta(2)+\frac{1}{2} \zeta (3)^2 \zeta(4)+\frac{891 \zeta(10)}{160}-\frac{7}{2} \zeta(2) \zeta(6,2)+\frac{7}{2} \zeta(8,2)-25 \zeta (3) \zeta (7)-10 \zeta (5)^2\\ \zeta(2,7,1)&=&+6 \zeta(3) \zeta (5) \zeta(2)+2 \zeta (3)^2 \zeta(4)+\frac{419 \zeta(10)}{20}+\frac{9}{4} \zeta(8,2)-\frac{41 \zeta (3) \zeta (7)}{2}-\frac{43 \zeta (5)^2}{4}\\ \zeta(2,6,2)&=&-16 \zeta (3) \zeta (5)\zeta(2)-4 \zeta (3)^2 \zeta(4)-\frac{3249 \zeta(10)}{40}-\zeta(2) \zeta(6,2)-\frac{21}{2} \zeta(8,2)+63 \zeta (3) \zeta (7)+41 \zeta (5)^2\\ \zeta(2,5,3)&=&+20 \zeta (3) \zeta (5)\zeta(2)+\frac{5969 \zeta(10)}{80}+11 \zeta(8,2)-56 \zeta (3) \zeta (7)-\frac{89 \zeta (5)^2}{2}\\ \zeta(2,4,4)&=&-40 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)-\frac{289\zeta(10)}{48}+10 \zeta(2) \zeta(6,2)-10 \zeta(8,2)+56 \zeta (3) \zeta (7)+20 \zeta (5)^2\\ \zeta(2,3,5)&=&+28 \zeta (3) \zeta (5) \zeta(2)+2 \zeta (3)^2 \zeta(4)-\frac{425\zeta(10)}{16}-10 \zeta(2) \zeta(6,2)+\frac{23}{4} \zeta(8,2)-\frac{63 \zeta (3) \zeta (7)}{2}+\frac{17 \zeta (5)^2}{4}\\ \zeta(2,2,6)&=&+8 \zeta (3) \zeta (5) \zeta(2)+2 \zeta (3)^2\zeta(4)+\frac{3817 \zeta(10)}{80}+\frac{15}{2} \zeta(8,2)-35 \zeta (3) \zeta (7)-23 \zeta (5)^2\\ \zeta(2,1,7)&=&-6 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)-\frac{256\zeta(10)}{15}+\zeta(2) \zeta(6,2)-\frac{7}{2} \zeta(8,2)+18 \zeta (3) \zeta (7)+9 \zeta (5)^2\\ \hline\\ \end{eqnarray} For each weight it turns out that it is pretty easy to calculate the quantity on the very top and that the complexity increases as we move from the top to the bottom. Now my question is are all multiple zeta values defined above reduce-able to single zeta values and if not what is the lowest weight when this is not the case.  Another question is can we establish recurrence relations (just as we did in Calculating alternating Euler sums of odd powers for the respective quantities of depth two ) between those values and solve them for any given weight.","The multiple zeta function of depth three has a following integral representation:  \begin{eqnarray} \zeta(t^{-1},p,q,r) &:=& \sum\limits_{m_1 > m_2 > m_3 > 0} \frac{t^{m_1}}{m_1^p} \frac{1}{m_2^q} \frac{1}{m_3^r} \\ &=& \int\limits_0^t \frac{[\log(t/\xi)]^{p-1}}{(p-1)!} \int\limits_0^{\xi} \frac{[\log(\xi/\xi_1)]^{q-1}}{(q-1)!} \cdot \frac{Li_r(\xi_1)}{1-\xi_1} d\xi_1 \frac{1}{1-\xi} d\xi  \end{eqnarray} By using the formula above we calculated the following list of values at plus unity for weights from four to six. We have: \begin{eqnarray} \zeta(2,1,1) &=& \zeta(4)\\ \hline\\ \zeta(3,1,1) &=& -  \zeta(2) \zeta(3) + 2 \zeta(5)\\ \zeta(2,2,1) &=& + 3\zeta(2) \zeta(3) -\frac{11}{2} \zeta(5)\\ \zeta(2,1,2) &=& - 2\zeta(2) \zeta(3) + \frac{9}{2} \zeta(5)\\ \hline \\ \zeta(4,1,1) &=& -  \zeta(3)^2 + \frac{23}{16} \zeta(6)\\ \zeta(3,2,1) &=& +3  \zeta(3)^2 - \frac{203}{48} \zeta(6)\\ \zeta(3,1,2) &=& -\frac{3}{2}  \zeta(3)^2 + \frac{53}{24} \zeta(6)\\ \zeta(2,3,1) &=& -\frac{3}{2}  \zeta(3)^2 + \frac{53}{24} \zeta(6)\\ \zeta(2,2,2) &=& \frac{3}{16} \zeta(6) \\ \zeta(2,1,3) &=& + \zeta(3)^2 - \frac{13}{16} \zeta(6)\\ \hline \zeta(5,1,1)&=&-\frac{5}{4} \zeta(3) \zeta(4)-2 \zeta(2)\zeta(5) +5 \zeta(7)\\ \zeta(4,2,1)&=&+\frac{-236 \zeta(3) \zeta(2)^2+28776 \zeta(5) \zeta(2)+18902 \zeta(3) \zeta(4)-72267 \zeta(7)}{5232}\\ \zeta(4,1,2)&=&-\frac{451}{327} \zeta(3) \zeta(2)^2+\frac{5}{2} \zeta(5) \zeta(2)-\frac{395 \zeta(3) \zeta(4)}{1308}+\frac{5 \zeta(7)}{8}\\ \zeta(3,3,1)&=&-\frac{77}{109} \zeta(3)\zeta(2)^2-\frac{9}{2} \zeta(5) \zeta(2)+\frac{385}{218} \zeta(3) \zeta(4)+\frac{61 \zeta(7)}{8}\\ \zeta(3,2,2)&=&+\frac{15908 \zeta(3) \zeta(2)^2-39240 \zeta(5) \zeta(2)-27998 \zeta(3) \zeta(4)+51339 \zeta(7)}{5232}\\ \zeta(3,1,3)&=&+\frac{1600 \zeta(3) \zeta(2)^2-3673 \zeta(3) \zeta(4)-327\zeta(7)}{1308}\\ \zeta(2,4,1)&=&+\frac{59 \zeta(3) \zeta(2)^2}{1308}+5 \zeta(5) \zeta(2)-\frac{3565 \zeta(3) \zeta(4)}{2616}-\frac{109 \zeta(7)}{16}\\ \zeta(2,3,2)&=&-\frac{1519}{654} \zeta(3) \zeta(2)^2-\frac{11}{2} \zeta(5) \zeta(2)+\frac{7595 \zeta(3) \zeta(4)}{1308}+\frac{75 \zeta(7)}{8}\\ \zeta(2,2,3)&=&+\frac{844 \zeta(3) \zeta(2)^2+62784 \zeta(5) \zeta(2)-9958 \zeta(3) \zeta(4)-95157 \zeta(7)}{5232}\\ \zeta(2,1,4)&=&+\frac{1}{8} (14 \zeta(3) \zeta(4)-44 \zeta(2) \zeta(5)+61 \zeta(7))\\ \hline\\ \zeta(6,1,1)&=&+\frac{1}{2} \zeta (3)^2 \zeta(2)-3 \zeta (3) \zeta (5)+\frac{61 \zeta(8)}{24}\\ \zeta(5,2,1)&=&+\frac{7}{4} \zeta(6,2)-\zeta (3)^2 \zeta(2)+\frac{7 \zeta (3) \zeta (5)}{2}-\frac{289\zeta(8)}{144}\\ \zeta(5,1,2)&=&-\zeta(6,2)-\frac{3}{2} \zeta (3)^2 \zeta(2)+\frac{9 \zeta (3) \zeta (5)}{2}-\frac{145 \zeta(8)}{72}\\ \zeta(4,3,1)&=&-\frac{25}{4} \zeta(6,2)+\frac{1}{2} \zeta (3)^2\zeta(2)+\frac{21 \zeta (3) \zeta (5)}{2}-\frac{677 \zeta(8)}{48}\\ \zeta(4,2,2)&=&+\frac{9}{2} \zeta(6,2)+3 \zeta (3)^2 \zeta(2)-20 \zeta (3) \zeta (5)+\frac{1271\zeta(8)}{72}\\ \zeta(4,1,3)&=&+\frac{5}{2} \zeta(6,2)+\frac{1}{2} \zeta (3)^2 \zeta(2)-\frac{15 \zeta (3) \zeta (5)}{2}+\frac{583 \zeta(8)}{72}\\ \zeta(3,4,1)&=&+\frac{15}{4} \zeta(6,2)-2 \zeta (3)^2\zeta(2)+\frac{673 \zeta(8)}{144}\\ \zeta(3,3,2)&=&+\frac{13}{4} \zeta(6,2)+\frac{9}{2} \zeta (3)^2 \zeta(2)-23 \zeta (3) \zeta (5)+\frac{857 \zeta(8)}{48}\\ \zeta(3,2,3)&=&-10 \zeta(6,2)-6\zeta (3)^2 \zeta(2)+\frac{89 \zeta (3) \zeta (5)}{2}-\frac{245 \zeta(8)}{6}\\ \zeta(3,1,4)&=&+\frac{3}{2} \zeta (3)^2 \zeta(2)-\frac{11 \zeta (3) \zeta (5)}{2}+\frac{241\zeta(8)}{72}\\ \zeta(2,5,1)&=&+\frac{7}{4} \zeta(6,2)+2 \zeta (3)^2 \zeta(2)-12 \zeta (3) \zeta (5)+\frac{487 \zeta(8)}{48}\\ \zeta(2,4,2)&=&-10 \zeta(6,2)-5 \zeta (3)^2 \zeta(2)+40 \zeta (3)\zeta (5)-\frac{677 \zeta(8)}{18}\\ \zeta(2,3,3)&=&+\frac{27}{4} \zeta(6,2)+2 \zeta (3)^2 \zeta(2)-\frac{45 \zeta (3) \zeta (5)}{2}+\frac{1111 \zeta(8)}{48}\\ \zeta(2,2,4)&=&+\frac{11}{2} \zeta(6,2)+2\zeta (3)^2 \zeta(2)-20 \zeta (3) \zeta (5)+\frac{121 \zeta(8)}{6}\\ \zeta(2,1,5)&=&-\frac{5}{2} \zeta(6,2)-\zeta (3)^2 \zeta(2)+\frac{21 \zeta (3) \zeta (5)}{2}-\frac{181 \zeta(8)}{18}\\ \hline\\ \zeta(7,1,1)&=&-3 \zeta (7) \zeta(2)-\frac{9}{4} \zeta (5) \zeta(4)-\frac{7}{4} \zeta (3) \zeta(6)+\frac{28 \zeta (9)}{3}+\frac{\zeta (3)^3}{6}\\ \zeta(6,2,1)&=&+11 \zeta (7) \zeta(2)+\frac{13}{2} \zeta(5) \zeta(4)+\frac{9}{2} \zeta (3) \zeta(6)-\frac{2189 \zeta (9)}{72}-\frac{\zeta (3)^3}{3}\\ \zeta(6,1,2)&=&+7 \zeta (7) \zeta(2)-\frac{1}{4} \zeta (5) \zeta(4)-\frac{5}{3} \zeta (3)\zeta(6)-\frac{313 \zeta (9)}{36}-\frac{\zeta (3)^3}{3}\\ \zeta(5,3,1)&=&-17 \zeta (7) \zeta(2)-\frac{23}{4} \zeta (5) \zeta(4)-\frac{3}{4} \zeta (3) \zeta(6)+\frac{845 \zeta (9)}{24}+\frac{\zeta(3)^3}{6}\\ \zeta(5,2,2)&=&-21 \zeta (7) \zeta(2)+\frac{7}{4} \zeta (5) \zeta(4)-\frac{8}{3} \zeta (3) \zeta(6)+\frac{2513 \zeta (9)}{72}+\frac{2 \zeta (3)^3}{3}\\ \zeta(5,1,3)&=&-7 \zeta (7)\zeta(2)+\frac{1}{2} \zeta (5) \zeta(4)+\frac{5}{4} \zeta (3) \zeta(6)+\frac{121 \zeta (9)}{12}-\frac{\zeta (3)^3}{3}\\ \zeta(4,4,1)&=&+18 \zeta (7) \zeta(2)+5 \zeta (5) \zeta(4)+\frac{4}{3}\zeta (3) \zeta(6)-\frac{328 \zeta (9)}{9}-\frac{\zeta (3)^3}{3}\\ \zeta(4,3,2)&=&+14 \zeta (7) \zeta(2)-\frac{35}{2} \zeta (5) \zeta(4)-\frac{8}{3} \zeta (3) \zeta(6)-\frac{53 \zeta (9)}{36}+\frac{2\zeta (3)^3}{3}\\ \zeta(4,2,3)&=&+28 \zeta (7) \zeta(2)+10 \zeta (5) \zeta(4)+\frac{5}{3} \zeta (3) \zeta(6)-59 \zeta (9)-\frac{\zeta (3)^3}{3}\\ \zeta(4,1,4)&=&-3 \zeta (5) \zeta(4)-\frac{41}{12} \zeta (3)\zeta(6)+\frac{115 \zeta (9)}{18}+\frac{2 \zeta (3)^3}{3}\\ \zeta(3,5,1)&=&-10 \zeta (7) \zeta(2)+\frac{5}{4} \zeta (5) \zeta(4)+\frac{5}{4} \zeta (3) \zeta(6)+\frac{341 \zeta (9)}{24}-\frac{\zeta(3)^3}{3}\\ \zeta(3,4,2)&=&-14 \zeta (7) \zeta(2)+\frac{15}{2} \zeta (5) \zeta(4)-\frac{7}{3} \zeta (3) \zeta(6)+\frac{593 \zeta (9)}{36}+\frac{2 \zeta (3)^3}{3}\\ \zeta(3,3,3)&=&-\frac{1}{2} \zeta (3)\zeta(6)+\frac{\zeta (9)}{3}+\frac{\zeta (3)^3}{6}\\ \zeta(3,2,4)&=&-28 \zeta (7) \zeta(2)-\frac{11}{2} \zeta (5) \zeta(4)+\frac{29}{4} \zeta (3) \zeta(6)+46 \zeta (9)-\frac{4 \zeta(3)^3}{3}\\ \zeta(3,1,5)&=&+7 \zeta (7) \zeta(2)-\frac{1}{4} \zeta (5) \zeta(4)-\frac{1}{2} \zeta (3) \zeta(6)-\frac{131 \zeta (9)}{12}+\frac{\zeta (3)^3}{6}\\ \zeta(2,6,1)&=&+7 \zeta (7) \zeta(2)-\frac{7}{4}\zeta (5) \zeta(4)-\frac{43}{12} \zeta (3) \zeta(6)-\frac{461 \zeta (9)}{72}+\frac{2 \zeta (3)^3}{3}\\ \zeta(2,5,2)&=&-11 \zeta (7) \zeta(2)+\frac{41}{6} \zeta (3) \zeta(6)+\frac{439 \zeta(9)}{36}-\frac{4 \zeta (3)^3}{3}\\ \zeta(2,4,3)&=&+31 \zeta (7) \zeta(2)-\frac{15}{2} \zeta (5) \zeta(4)+\zeta (3) \zeta(6)-\frac{1567 \zeta (9)}{36}-\frac{\zeta (3)^3}{3}\\ \zeta(2,3,4)&=&-32 \zeta (7)\zeta(2)+12 \zeta (5) \zeta(4)-\frac{25}{6} \zeta (3) \zeta(6)+\frac{1567 \zeta (9)}{36}+\frac{2 \zeta (3)^3}{3}\\ \zeta(2,2,5)&=&+31 \zeta (7) \zeta(2)-\zeta (5) \zeta(4)-\frac{25}{6} \zeta (3)\zeta(6)-\frac{3319 \zeta (9)}{72}+\frac{2 \zeta (3)^3}{3}\\ \zeta(2,1,6)&=&-11 \zeta (7) \zeta(2)+\frac{1}{4} \zeta (5) \zeta(4)+\frac{37}{12} \zeta (3) \zeta(6)+\frac{551 \zeta (9)}{36}-\frac{\zeta(3)^3}{3}\\ \hline\\ \zeta(8,1,1)&=&+\zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2 \zeta(4)+\frac{333 \zeta(10)}{80}-4 \zeta (3) \zeta (7)-2 \zeta (5)^2\\ \zeta(7,2,1)&=&-\zeta (3)^2 \zeta(4)-\frac{377\zeta(10)}{60}-\zeta(2) \zeta(6,2)+\frac{9}{4} \zeta(8,2)+\frac{9 \zeta (3) \zeta (7)}{2}+\frac{9 \zeta (5)^2}{4}\\ \zeta(7,1,2)&=&-7 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2\zeta(4)-\frac{77 \zeta(10)}{48}+\zeta(2) \zeta(6,2)-\zeta(8,2)+10 \zeta (3) \zeta (7)+5 \zeta (5)^2\\ \zeta(6,3,1)&=&-4 \zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2\zeta(4)-\frac{3219 \zeta(10)}{160}+\frac{5}{2} \zeta(2) \zeta(6,2)-\frac{35}{4} \zeta(8,2)+\frac{29 \zeta (3) \zeta (7)}{2}+\frac{37 \zeta (5)^2}{4}\\ \zeta(6,2,2)&=&+8 \zeta (3) \zeta (5)\zeta(2)+2 \zeta (3)^2 \zeta(4)+\frac{539 \zeta(10)}{16}+\zeta(2) \zeta(6,2)+3 \zeta(8,2)-28 \zeta (3) \zeta (7)-18 \zeta (5)^2\\ \zeta(6,1,3)&=&+16 \zeta (3) \zeta (5)\zeta(2)-\frac{1}{2} \zeta (3)^2 \zeta(4)+\frac{511 \zeta(10)}{160}-\frac{7}{2} \zeta(2) \zeta(6,2)+\frac{7}{2} \zeta(8,2)-21 \zeta (3) \zeta (7)-9 \zeta (5)^2\\ \zeta(5,4,1)&=&-5 \zeta(3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)+\frac{9209 \zeta(10)}{240}+\frac{21}{2} \zeta(8,2)-10 \zeta (3) \zeta (7)-\frac{27 \zeta (5)^2}{2}\\ \zeta(5,3,2)&=&+35 \zeta (3) \zeta (5) \zeta(2)+2\zeta (3)^2 \zeta(4)-\frac{5683 \zeta(10)}{160}-\frac{25}{2} \zeta(2) \zeta(6,2)+\frac{19}{4} \zeta(8,2)-\frac{63 \zeta (3) \zeta (7)}{2}-\frac{3 \zeta (5)^2}{4}\\ \zeta(5,2,3)&=&-50 \zeta (3)\zeta (5) \zeta(2)-2 \zeta (3)^2 \zeta(4)-\frac{719 \zeta(10)}{20}+10 \zeta(2) \zeta(6,2)-\frac{49}{4} \zeta(8,2)+\frac{161 \zeta (3) \zeta (7)}{2}+\frac{163 \zeta(5)^2}{4}\\ \zeta(5,1,4)&=&-10 \zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2 \zeta(4)-\frac{1027 \zeta(10)}{480}+\frac{5}{2} \zeta(2) \zeta(6,2)-\frac{7}{2} \zeta(8,2)+14 \zeta (3)\zeta (7)+\frac{9 \zeta (5)^2}{2}\\ \zeta(4,5,1)&=&+15 \zeta (3) \zeta (5) \zeta(2)-\frac{1173 \zeta(10)}{32}-\frac{5}{2} \zeta(2) \zeta(6,2)-7 \zeta(8,2)-3 \zeta (3) \zeta (7)+9 \zeta(5)^2\\ \zeta(4,4,2)&=&-40 \zeta (3) \zeta (5) \zeta(2)+\frac{249 \zeta(10)}{40}+10 \zeta(2) \zeta(6,2)-\frac{15}{2} \zeta(8,2)+49 \zeta (3) \zeta (7)+15 \zeta (5)^2\\ \zeta(4,3,3)&=&-20 \zeta (3) \zeta(5) \zeta(2)+\frac{3233 \zeta(10)}{40}+10 \zeta(2) \zeta(6,2)+\frac{7}{2} \zeta(8,2)-7 \zeta (3) \zeta (7)-\frac{59 \zeta (5)^2}{2}\\ \zeta(4,2,4)&=&+80 \zeta (3) \zeta (5) \zeta(2)+\zeta(3)^2 \zeta(4)-\frac{\zeta(10)}{6}-20 \zeta(2) \zeta(6,2)+\frac{35}{2} \zeta(8,2)-105 \zeta (3) \zeta (7)-35 \zeta (5)^2\\ \zeta(4,1,5)&=&-11 \zeta (3) \zeta (5) \zeta(2)+\zeta (3)^2\zeta(4)+\frac{4937 \zeta(10)}{480}+\frac{5}{2} \zeta(2) \zeta(6,2)+7 \zeta (3) \zeta (7)+2 \zeta (5)^2\\ \zeta(3,6,1)&=&-13 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)+\frac{53\zeta(10)}{40}+\zeta(2) \zeta(6,2)+\frac{7}{4} \zeta(8,2)+\frac{35 \zeta (3) \zeta (7)}{2}+\frac{21 \zeta (5)^2}{4}\\ \zeta(3,5,2)&=&+20 \zeta (3) \zeta (5) \zeta(2)+2 \zeta (3)^2\zeta(4)+\frac{2303 \zeta(10)}{32}+\frac{5}{2} \zeta(2) \zeta(6,2)+\frac{13}{2} \zeta(8,2)-60 \zeta (3) \zeta (7)-\frac{81 \zeta (5)^2}{2}\\ \zeta(3,4,3)&=&+30 \zeta (3) \zeta (5)\zeta(2)-\frac{2703 \zeta(10)}{20}-20 \zeta(2) \zeta(6,2)+17 \zeta (3) \zeta (7)+50 \zeta (5)^2\\ \zeta(3,3,4)&=&-10 \zeta (3) \zeta (5) \zeta(2)+\frac{1}{2} \zeta (3)^2\zeta(4)+\frac{2191 \zeta(10)}{40}+10 \zeta(2) \zeta(6,2)-\frac{7}{2} \zeta(8,2)-11 \zeta (3) \zeta (7)-\frac{41 \zeta (5)^2}{2}\\ \zeta(3,2,5)&=&-52 \zeta (3) \zeta (5) \zeta(2)-4 \zeta(3)^2 \zeta(4)-\frac{241 \zeta(10)}{5}+10 \zeta(2) \zeta(6,2)-\frac{63}{4} \zeta(8,2)+\frac{195 \zeta (3) \zeta (7)}{2}+\frac{159 \zeta (5)^2}{4}\\ \zeta(3,1,6)&=&+17 \zeta (3) \zeta (5)\zeta(2)+\frac{1}{2} \zeta (3)^2 \zeta(4)+\frac{891 \zeta(10)}{160}-\frac{7}{2} \zeta(2) \zeta(6,2)+\frac{7}{2} \zeta(8,2)-25 \zeta (3) \zeta (7)-10 \zeta (5)^2\\ \zeta(2,7,1)&=&+6 \zeta(3) \zeta (5) \zeta(2)+2 \zeta (3)^2 \zeta(4)+\frac{419 \zeta(10)}{20}+\frac{9}{4} \zeta(8,2)-\frac{41 \zeta (3) \zeta (7)}{2}-\frac{43 \zeta (5)^2}{4}\\ \zeta(2,6,2)&=&-16 \zeta (3) \zeta (5)\zeta(2)-4 \zeta (3)^2 \zeta(4)-\frac{3249 \zeta(10)}{40}-\zeta(2) \zeta(6,2)-\frac{21}{2} \zeta(8,2)+63 \zeta (3) \zeta (7)+41 \zeta (5)^2\\ \zeta(2,5,3)&=&+20 \zeta (3) \zeta (5)\zeta(2)+\frac{5969 \zeta(10)}{80}+11 \zeta(8,2)-56 \zeta (3) \zeta (7)-\frac{89 \zeta (5)^2}{2}\\ \zeta(2,4,4)&=&-40 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)-\frac{289\zeta(10)}{48}+10 \zeta(2) \zeta(6,2)-10 \zeta(8,2)+56 \zeta (3) \zeta (7)+20 \zeta (5)^2\\ \zeta(2,3,5)&=&+28 \zeta (3) \zeta (5) \zeta(2)+2 \zeta (3)^2 \zeta(4)-\frac{425\zeta(10)}{16}-10 \zeta(2) \zeta(6,2)+\frac{23}{4} \zeta(8,2)-\frac{63 \zeta (3) \zeta (7)}{2}+\frac{17 \zeta (5)^2}{4}\\ \zeta(2,2,6)&=&+8 \zeta (3) \zeta (5) \zeta(2)+2 \zeta (3)^2\zeta(4)+\frac{3817 \zeta(10)}{80}+\frac{15}{2} \zeta(8,2)-35 \zeta (3) \zeta (7)-23 \zeta (5)^2\\ \zeta(2,1,7)&=&-6 \zeta (3) \zeta (5) \zeta(2)-\zeta (3)^2 \zeta(4)-\frac{256\zeta(10)}{15}+\zeta(2) \zeta(6,2)-\frac{7}{2} \zeta(8,2)+18 \zeta (3) \zeta (7)+9 \zeta (5)^2\\ \hline\\ \end{eqnarray} For each weight it turns out that it is pretty easy to calculate the quantity on the very top and that the complexity increases as we move from the top to the bottom. Now my question is are all multiple zeta values defined above reduce-able to single zeta values and if not what is the lowest weight when this is not the case.  Another question is can we establish recurrence relations (just as we did in Calculating alternating Euler sums of odd powers for the respective quantities of depth two ) between those values and solve them for any given weight.",,"['sequences-and-series', 'zeta-functions']"
97,"For all Dirichlet series, is $a_n$ unique to $f(s)$?","For all Dirichlet series, is  unique to ?",a_n f(s),"For any Dirichlet series, $$f(s)=\sum_{n=1}^\infty \frac{a_n}{n^s}$$ is the sequence, $a_n$, always unique to $f(s)$?  In other words, is it possible to show that $a_n$ is the only sequence that will ever satisfy the series being equal to $f(s)$? If this is not true, could someone try to provide a counter example if possible?","For any Dirichlet series, $$f(s)=\sum_{n=1}^\infty \frac{a_n}{n^s}$$ is the sequence, $a_n$, always unique to $f(s)$?  In other words, is it possible to show that $a_n$ is the only sequence that will ever satisfy the series being equal to $f(s)$? If this is not true, could someone try to provide a counter example if possible?",,"['sequences-and-series', 'number-theory', 'dirichlet-series']"
98,"Does $ \sum_{(m,n) \neq (0,0)} \frac{(-1)^{m+n}}{m^2 + n^2} $ have an exact value?",Does  have an exact value?," \sum_{(m,n) \neq (0,0)} \frac{(-1)^{m+n}}{m^2 + n^2} ","I am looking for an $\mathbb{Z}[i]$ analogue of the alternating harmonic series: $L(1,\chi)=\sum_{n=0}^\infty (-1)^n \frac{1}{n} = \frac{\pi}{4}$. If we try adding the reciprocals of the Gaussian integers we obtain a divergent series since there are too many terms: $$ \sum_{(m,n) \neq (0,0)} \frac{1}{m+ni} = 0$$ If instead we take the norm $|(m+ni)|^2 = (m+ni)(m-ni) = m^2 + n^2$. Then we get the Dedekind zeta function at $1$. $$ \zeta_{\mathbb{Z}[i]}(1) = \sum_{(m,n) \neq (0,0)} \frac{1}{m^2 + n^2} = \infty$$ This ""just barely diverges"" in the same way that Harmonic series gives logarithmic divergence .  What if we ""twist"" by factors of $(-1)$? $$ L_{\mathbb{Z}[i]}(\chi, 1) = \sum_{(m,n) \neq (0,0)} \frac{(-1)^{m+n}}{m^2 + n^2} $$ Does this series have an special value ?  In the case of $\mathbb{Z}$, the alternating Harmonic series is in $\mathbb{Q}\pi$, and for $\mathbb{Z}[i]$ I am guessing the value is in $\mathbb{Q}\pi^2$.  Possibly warrant a separate question. It has come to my attention the sum is not absolutely convergent . Even if no terms are rearranged, they may be re-ordered in funny ways to give different values.  In this 2-dimensional case, it may be possible that summing windows $[-M, M]\times [-N,N]$ may give different values as $M,N \to \infty$. Another problem is that actually $\sum (-1)^n \frac{1}{n} = \log 2$ [ 1 ] and $\sum  \frac{(-1)^n}{2n+1} = \sum  \frac{\chi(k)}{k} = \frac{\pi}{4}$ [ 2 ].  In  which case the correct analogy would be: $$ \sum_{(m,n) \in \mathbb{Z}^2} \frac{(-1)^{m+n}}{(2m+1)^2 + (2n+1)^2} \hspace{0.25in}\text{or}\hspace{0.25in}\sum_{m+in \in \mathbb{Z}[i]} \frac{\chi(m+in)}{|m+in|^2} $$ Then I am not sure what the corresponding Dirichlet character of $\mathbb{Z}[i]$ should be [ 3 ].","I am looking for an $\mathbb{Z}[i]$ analogue of the alternating harmonic series: $L(1,\chi)=\sum_{n=0}^\infty (-1)^n \frac{1}{n} = \frac{\pi}{4}$. If we try adding the reciprocals of the Gaussian integers we obtain a divergent series since there are too many terms: $$ \sum_{(m,n) \neq (0,0)} \frac{1}{m+ni} = 0$$ If instead we take the norm $|(m+ni)|^2 = (m+ni)(m-ni) = m^2 + n^2$. Then we get the Dedekind zeta function at $1$. $$ \zeta_{\mathbb{Z}[i]}(1) = \sum_{(m,n) \neq (0,0)} \frac{1}{m^2 + n^2} = \infty$$ This ""just barely diverges"" in the same way that Harmonic series gives logarithmic divergence .  What if we ""twist"" by factors of $(-1)$? $$ L_{\mathbb{Z}[i]}(\chi, 1) = \sum_{(m,n) \neq (0,0)} \frac{(-1)^{m+n}}{m^2 + n^2} $$ Does this series have an special value ?  In the case of $\mathbb{Z}$, the alternating Harmonic series is in $\mathbb{Q}\pi$, and for $\mathbb{Z}[i]$ I am guessing the value is in $\mathbb{Q}\pi^2$.  Possibly warrant a separate question. It has come to my attention the sum is not absolutely convergent . Even if no terms are rearranged, they may be re-ordered in funny ways to give different values.  In this 2-dimensional case, it may be possible that summing windows $[-M, M]\times [-N,N]$ may give different values as $M,N \to \infty$. Another problem is that actually $\sum (-1)^n \frac{1}{n} = \log 2$ [ 1 ] and $\sum  \frac{(-1)^n}{2n+1} = \sum  \frac{\chi(k)}{k} = \frac{\pi}{4}$ [ 2 ].  In  which case the correct analogy would be: $$ \sum_{(m,n) \in \mathbb{Z}^2} \frac{(-1)^{m+n}}{(2m+1)^2 + (2n+1)^2} \hspace{0.25in}\text{or}\hspace{0.25in}\sum_{m+in \in \mathbb{Z}[i]} \frac{\chi(m+in)}{|m+in|^2} $$ Then I am not sure what the corresponding Dirichlet character of $\mathbb{Z}[i]$ should be [ 3 ].",,"['sequences-and-series', 'special-functions']"
99,How to solve $P=\left(1+\frac{1}{3}\right)\left(1+\frac{1}{3^2}\right)\left(1+\frac{1}{3^3}\right)\ldots \infty$,How to solve,P=\left(1+\frac{1}{3}\right)\left(1+\frac{1}{3^2}\right)\left(1+\frac{1}{3^3}\right)\ldots \infty,How do I find the following product $$P=\left(1+\frac{1}{3}\right)\left(1+\frac{1}{3^2}\right)\left(1+\frac{1}{3^3}\right)\ldots \infty$$,How do I find the following product $$P=\left(1+\frac{1}{3}\right)\left(1+\frac{1}{3^2}\right)\left(1+\frac{1}{3^3}\right)\ldots \infty$$,,['sequences-and-series']
