,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Hypothesis testing from negative binomial data,Hypothesis testing from negative binomial data,,"For each trial I flip a coin until $3$ heads or $3$ tails occur, whichever comes first. Out of $10$ trials, $3$ trials result in $3$ flips, $3$ trials result in 4 flips, and $4$ trials result in $5$ flips. How can I use this data to test whether the coin is a fair coin?","For each trial I flip a coin until $3$ heads or $3$ tails occur, whichever comes first. Out of $10$ trials, $3$ trials result in $3$ flips, $3$ trials result in 4 flips, and $4$ trials result in $5$ flips. How can I use this data to test whether the coin is a fair coin?",,"['probability', 'statistics']"
1,First order Autoregressive model,First order Autoregressive model,,How do I solve this? How can I obtain the lag-one autocorrelation coefficients just from the data?? Following are $10$ years of observation of annual streamflows in millions of cubic meters: $$\begin{array}{|c|cl|}\hline\hline \text{Year}&1&2&3&4&5&6&7&8&\\\hline\text{Discharge}&145.78&95.43&116.66&96.12&122.09&175.02&101.98&146.14\\\hline \text{Year}&9&10\\\hline\text{Discharge}&126.01&132.73 \end{array}$$ Use the above data to estimate the parameters of an  first order Autoregressive model and the parameters of an first order Moving Average Model.,How do I solve this? How can I obtain the lag-one autocorrelation coefficients just from the data?? Following are $10$ years of observation of annual streamflows in millions of cubic meters: $$\begin{array}{|c|cl|}\hline\hline \text{Year}&1&2&3&4&5&6&7&8&\\\hline\text{Discharge}&145.78&95.43&116.66&96.12&122.09&175.02&101.98&146.14\\\hline \text{Year}&9&10\\\hline\text{Discharge}&126.01&132.73 \end{array}$$ Use the above data to estimate the parameters of an  first order Autoregressive model and the parameters of an first order Moving Average Model.,,['statistics']
2,How to calculate the variance of this maximum likelihood estimator,How to calculate the variance of this maximum likelihood estimator,,Suppose my likelihood function is (multiplication of $n$ Poisson function with $\lambda=\mu x$): $$L(\mu;x)=(e^{-\mu x})^a(1-e^{-\mu a})^{n-a}$$ I have calculated  $$\log L=-a\mu x+(n-a)\log (1-e^{-\mu x})$$ $$\frac{d\log}{d\mu}=-ax+\frac{n-a}{1-e^{-\mu x}}xe^{-\mu x}$$ $$\frac{d^2\log L}{d\mu ^2}=-(n-a)x^2(e^{\mu x}-1)^{-2}e^{\mu x}.$$ So  $$Var(\hat\mu)=\frac{1}{-\mathbb E(\frac{d^2\log L}{d\mu ^2})}.$$ But what is the expectation here equals to? I am stucked here.,Suppose my likelihood function is (multiplication of $n$ Poisson function with $\lambda=\mu x$): $$L(\mu;x)=(e^{-\mu x})^a(1-e^{-\mu a})^{n-a}$$ I have calculated  $$\log L=-a\mu x+(n-a)\log (1-e^{-\mu x})$$ $$\frac{d\log}{d\mu}=-ax+\frac{n-a}{1-e^{-\mu x}}xe^{-\mu x}$$ $$\frac{d^2\log L}{d\mu ^2}=-(n-a)x^2(e^{\mu x}-1)^{-2}e^{\mu x}.$$ So  $$Var(\hat\mu)=\frac{1}{-\mathbb E(\frac{d^2\log L}{d\mu ^2})}.$$ But what is the expectation here equals to? I am stucked here.,,['statistics']
3,Joint PDF over a uniform interval,Joint PDF over a uniform interval,,"A particle is emitted at time zero and undergoes a decay at some random time $S$. One of the decay products is then observed at time $T \geq S$. Suppose that $T$ has probability density function: $$ f_T(t) = \left\{      \begin{array}{lr}        \lambda^2te^{-\lambda t} & : t > 0\\        0 & : t \leq 0      \end{array}    \right.$$   For each $t > 0$ the conditional distribution of $S$ given that $T = t$ is uniform over the interval $(0, t)$. Find the joint probability density function of $S$ and $T$. Use this to ﬁnd the joint probability density function of $S$ and $W = T - S$. Determine if $S$ and $W$ are independent. I think the best option is to try and condition $f_T(t)$ on $S$ to solve for $f_{S,T}(s,t)$, but I can't figure how to go about doing that. Any help would be appreciated.","A particle is emitted at time zero and undergoes a decay at some random time $S$. One of the decay products is then observed at time $T \geq S$. Suppose that $T$ has probability density function: $$ f_T(t) = \left\{      \begin{array}{lr}        \lambda^2te^{-\lambda t} & : t > 0\\        0 & : t \leq 0      \end{array}    \right.$$   For each $t > 0$ the conditional distribution of $S$ given that $T = t$ is uniform over the interval $(0, t)$. Find the joint probability density function of $S$ and $T$. Use this to ﬁnd the joint probability density function of $S$ and $W = T - S$. Determine if $S$ and $W$ are independent. I think the best option is to try and condition $f_T(t)$ on $S$ to solve for $f_{S,T}(s,t)$, but I can't figure how to go about doing that. Any help would be appreciated.",,"['probability', 'statistics']"
4,Distribution of the rank statistic for an iid sample?,Distribution of the rank statistic for an iid sample?,,"For an iid sample $X_1, \dots, X_n$, its rank statistic is $(r_1, \dots, r_n)$ where $r_k$ is the rank of $X_k$ sorted in nondecreasing order. When there are ties, the ranks of the  ties are the same as the average of their random ranks. For example, in $1, 2, 2, 3$, the ranks of the two $2$'s are $(2+3)/2 = 2.5$. The pmf of the rank statistic of an iid sample of size $n$ and with a continuous distribution, is always $0$ if there is tie, and $1/n!$ if there is no tie. The marginal distribution of each $r_k$ is uniform over $\{1,\dots, n\}$. I was wondering how to decide its joint pmf and its marginal pmf when the distribution is discrete or other non-continuous case? I think there might already been some references covering my question. So could you recommend some? Thanks and regards!","For an iid sample $X_1, \dots, X_n$, its rank statistic is $(r_1, \dots, r_n)$ where $r_k$ is the rank of $X_k$ sorted in nondecreasing order. When there are ties, the ranks of the  ties are the same as the average of their random ranks. For example, in $1, 2, 2, 3$, the ranks of the two $2$'s are $(2+3)/2 = 2.5$. The pmf of the rank statistic of an iid sample of size $n$ and with a continuous distribution, is always $0$ if there is tie, and $1/n!$ if there is no tie. The marginal distribution of each $r_k$ is uniform over $\{1,\dots, n\}$. I was wondering how to decide its joint pmf and its marginal pmf when the distribution is discrete or other non-continuous case? I think there might already been some references covering my question. So could you recommend some? Thanks and regards!",,"['probability', 'statistics']"
5,Posterior density and posterior moments,Posterior density and posterior moments,,"I would be very grateful to get some help with the following problem. Let $X_1, ..., X_n$ be independent and uniformly distributed on the interval $(0,\theta)$ with $\theta>0$. Let the prior density of $\theta$ be the log-normal distribution with parameters $(\mu,\sigma^2)$ where $\mu \in \mathbb{R}$ and $\sigma>0$ are known constants. I'm looking for a) the posterior density of $\ln{\theta}$, b) the k-th posterior moment of $\theta$, c) the maximum of the posterior density of $\theta$. I tried to solve a) as follows. Let $p(\theta)$ be the prior density of $\theta$ and $L(x_1, ..., x_n|\theta)$ the likelihood function of $\theta$ given the outcome $X_1=x_1, ..., X_n=x_n$. Then the posterior density $f(\theta|X_1=x_1, ..., X_n=x_n)$ is given by $$\frac{L(x_1, ..., x_n|\theta)p(\theta)}{N}$$ where $$N=\int_0^\infty L(x_1, ..., x_n|\theta)p(\theta) d\theta$$ is a normalizing constant. I have $$p(\theta)=\frac{1}{\sqrt{2\pi}\sigma\theta}\exp \left(-\frac{(\ln{\theta}-\mu)^2}{2\sigma^2}\right)$$ and $$L(x_1, ..., x_n|\theta)=1/\theta^n$$ where $x_1, ..., x_n \in (0,\theta)$ and $0$ otherwise. Now I need to solve that integral, but I can't figure it out. Since we're asked to give the posterior density of $\ln{\theta}$, I tried to substitute $y=\ln{\theta}$ by using $$\theta^{-(n+1)}=\exp \left(\ln{\theta^{-(n+1)}}\right)=\exp \left(-(n+1)\ln{\theta}\right)$$ and simplifying the integral to $$N=\int_0^\infty \frac{1}{\sqrt{2\pi}\sigma}\exp \left(-(n+1)y+\frac{(y-\mu)^2}{2\sigma^2}\right)dy.$$ However, I still can't solve that integral and feeding it to Wolframalpha didn't yield a result as well. Have I done something wrong or do I need to choose a completely different approach? So far I didn't care much about b) and c) since I need to solve a) in order to do them, I think.","I would be very grateful to get some help with the following problem. Let $X_1, ..., X_n$ be independent and uniformly distributed on the interval $(0,\theta)$ with $\theta>0$. Let the prior density of $\theta$ be the log-normal distribution with parameters $(\mu,\sigma^2)$ where $\mu \in \mathbb{R}$ and $\sigma>0$ are known constants. I'm looking for a) the posterior density of $\ln{\theta}$, b) the k-th posterior moment of $\theta$, c) the maximum of the posterior density of $\theta$. I tried to solve a) as follows. Let $p(\theta)$ be the prior density of $\theta$ and $L(x_1, ..., x_n|\theta)$ the likelihood function of $\theta$ given the outcome $X_1=x_1, ..., X_n=x_n$. Then the posterior density $f(\theta|X_1=x_1, ..., X_n=x_n)$ is given by $$\frac{L(x_1, ..., x_n|\theta)p(\theta)}{N}$$ where $$N=\int_0^\infty L(x_1, ..., x_n|\theta)p(\theta) d\theta$$ is a normalizing constant. I have $$p(\theta)=\frac{1}{\sqrt{2\pi}\sigma\theta}\exp \left(-\frac{(\ln{\theta}-\mu)^2}{2\sigma^2}\right)$$ and $$L(x_1, ..., x_n|\theta)=1/\theta^n$$ where $x_1, ..., x_n \in (0,\theta)$ and $0$ otherwise. Now I need to solve that integral, but I can't figure it out. Since we're asked to give the posterior density of $\ln{\theta}$, I tried to substitute $y=\ln{\theta}$ by using $$\theta^{-(n+1)}=\exp \left(\ln{\theta^{-(n+1)}}\right)=\exp \left(-(n+1)\ln{\theta}\right)$$ and simplifying the integral to $$N=\int_0^\infty \frac{1}{\sqrt{2\pi}\sigma}\exp \left(-(n+1)y+\frac{(y-\mu)^2}{2\sigma^2}\right)dy.$$ However, I still can't solve that integral and feeding it to Wolframalpha didn't yield a result as well. Have I done something wrong or do I need to choose a completely different approach? So far I didn't care much about b) and c) since I need to solve a) in order to do them, I think.",,"['statistics', 'bayesian']"
6,"Given some data, how can I tell how well it fits a (continuous) uniform distribution?","Given some data, how can I tell how well it fits a (continuous) uniform distribution?",,"I have a set of $30$ real numbers between zero and one.  Let's say that the null hypothesis is that this data set fits a uniform distribution and that the alternative hypothesis is that this data set does not fit a uniform distribution.  How would I test this? My only ideas so far would be to divide the continuous distribution into a set of several categories so that the expected count in each category is at least five.  With a set of $30$ numbers, I would divide the interval $(0,1)$ into six equal sections, such as $(0,0.166)$, $(0.166,0.333)$, etc.  For each interval, I would count the quantity of data points that fall within the interval. Now that I have converted the original data into categorical data, I can run a chi-squared goodness-of-fit test with (in this case) $5$ degrees of freedom. The above paragraph is just speculation on my part.  Is there a better way to determine how well data fits a uniform distribution?","I have a set of $30$ real numbers between zero and one.  Let's say that the null hypothesis is that this data set fits a uniform distribution and that the alternative hypothesis is that this data set does not fit a uniform distribution.  How would I test this? My only ideas so far would be to divide the continuous distribution into a set of several categories so that the expected count in each category is at least five.  With a set of $30$ numbers, I would divide the interval $(0,1)$ into six equal sections, such as $(0,0.166)$, $(0.166,0.333)$, etc.  For each interval, I would count the quantity of data points that fall within the interval. Now that I have converted the original data into categorical data, I can run a chi-squared goodness-of-fit test with (in this case) $5$ degrees of freedom. The above paragraph is just speculation on my part.  Is there a better way to determine how well data fits a uniform distribution?",,['statistics']
7,Wisdom of the crowd in estimative calculation,Wisdom of the crowd in estimative calculation,,"This question came to mind when I was discussing a contest with a friend in which the challenge was to estimate the number of particles in a glass tube. The amount of particles (close to $5\cdot 10^4$) was large enough to have people give wrong estimates by more than 1 order of magnitude (i.e. $5\cdot 10^3$ and $5\cdot 10^5$). My question is: does the wisdom of the crowd still apply to this situation with orders of magnitude estimation errors? What I could imagine is that if there are equally many people off by an order of magnitude in the 'up' and 'down' directions you would rather need to take something like a logarithmic average. A second question is related to the way many people actually made the estimate. Instead of a random guess they made an estimative calculation saying: well, the length of the particle bed in the tube is $h_t\approx0.5$ m, the tube diameter is $d_t\approx 3 $ cm, the particles are approximately spherical with a diameter of $d_p\approx3$ mm and the void fraction will be about $\epsilon=40\%$ . Then they came up with a number based on the calculation: $$N_p=\frac{V}{V_p}=\frac{6(1-\epsilon)h_t d_t^2}{d_p^3} $$ My second question is: does the wisdom of the crowd still apply for this estimative calculation? Or should we rather start working with averages per variable (particle diameter, void fraction etc) and use those averages for the final calculation? Or will the analysis be flawed anyway if the guesses are calculated.","This question came to mind when I was discussing a contest with a friend in which the challenge was to estimate the number of particles in a glass tube. The amount of particles (close to $5\cdot 10^4$) was large enough to have people give wrong estimates by more than 1 order of magnitude (i.e. $5\cdot 10^3$ and $5\cdot 10^5$). My question is: does the wisdom of the crowd still apply to this situation with orders of magnitude estimation errors? What I could imagine is that if there are equally many people off by an order of magnitude in the 'up' and 'down' directions you would rather need to take something like a logarithmic average. A second question is related to the way many people actually made the estimate. Instead of a random guess they made an estimative calculation saying: well, the length of the particle bed in the tube is $h_t\approx0.5$ m, the tube diameter is $d_t\approx 3 $ cm, the particles are approximately spherical with a diameter of $d_p\approx3$ mm and the void fraction will be about $\epsilon=40\%$ . Then they came up with a number based on the calculation: $$N_p=\frac{V}{V_p}=\frac{6(1-\epsilon)h_t d_t^2}{d_p^3} $$ My second question is: does the wisdom of the crowd still apply for this estimative calculation? Or should we rather start working with averages per variable (particle diameter, void fraction etc) and use those averages for the final calculation? Or will the analysis be flawed anyway if the guesses are calculated.",,"['probability', 'statistics']"
8,Percolation networks in three dimensions by shapes of different sizes,Percolation networks in three dimensions by shapes of different sizes,,"Percolation is something which I feel I understand somewhat intuitively, but it is quite complex as far as I've read, and therefore my expectations may be wrong. It's related to my research in materials science, so I'd like to grasp it better if at all possible. It's likely that general aspects of the solution are enough to answer my question, so I don't have to force anyone to go into the gory details. My mathematical education also stopped somewhere around intermediate-level calculus, so go easy on me please! I am interested in percolation pathways between two parallel flat sheets, separated by a certain distance $d$ in empty 3D space. Imagine one were to start adding small non-intersecting flat planes of area $A$ (with largest ""diameter"" $\ll d$) in the empty space, with rotational freedom in any axis. Would there be a difference in the ""speed"" at which the distance would be percolated, if the size of the added planes were varied (though always smaller than the distance between the limiting parallel sheets)? For example, considering adding planes of a constant shape (such as squares of differing sizes), what would the relation between the average ""occupation density"" for a successful percolation to happen be, if we were to compare adding squares of area $A$ with squares of area $A/10$? Equivalently (or at least I think it is), if we were to compare adding $x$ square planes of area $A$, and $10x$ square planes of area $A/10$, in which case would the probability of percolating the distance $d$ be higher? My gut feeling is that using a lower amount of larger planes makes it easier to percolate than a higher amount of smaller planes. A detailed analysis of the problem in its full form is likely infeasible, so I assume that relaxed constraints are required, such as adding square planes to a 3D cubic grid. Is this approximation of the problem sufficient to provide reliable answers that can be transferred to the general version (i.e. adding arbitrary 1D/2D/3D shapes, arbitrary placement, arbitrary shape sizes, including largest ""diameters"" $\simeq d$ or even $>d$ )? Are these conclusions generally in line with those obtained for percolation of lines in 2D space, or do they fundamentally differ (such as with 2D vs. 3D random walks)?","Percolation is something which I feel I understand somewhat intuitively, but it is quite complex as far as I've read, and therefore my expectations may be wrong. It's related to my research in materials science, so I'd like to grasp it better if at all possible. It's likely that general aspects of the solution are enough to answer my question, so I don't have to force anyone to go into the gory details. My mathematical education also stopped somewhere around intermediate-level calculus, so go easy on me please! I am interested in percolation pathways between two parallel flat sheets, separated by a certain distance $d$ in empty 3D space. Imagine one were to start adding small non-intersecting flat planes of area $A$ (with largest ""diameter"" $\ll d$) in the empty space, with rotational freedom in any axis. Would there be a difference in the ""speed"" at which the distance would be percolated, if the size of the added planes were varied (though always smaller than the distance between the limiting parallel sheets)? For example, considering adding planes of a constant shape (such as squares of differing sizes), what would the relation between the average ""occupation density"" for a successful percolation to happen be, if we were to compare adding squares of area $A$ with squares of area $A/10$? Equivalently (or at least I think it is), if we were to compare adding $x$ square planes of area $A$, and $10x$ square planes of area $A/10$, in which case would the probability of percolating the distance $d$ be higher? My gut feeling is that using a lower amount of larger planes makes it easier to percolate than a higher amount of smaller planes. A detailed analysis of the problem in its full form is likely infeasible, so I assume that relaxed constraints are required, such as adding square planes to a 3D cubic grid. Is this approximation of the problem sufficient to provide reliable answers that can be transferred to the general version (i.e. adding arbitrary 1D/2D/3D shapes, arbitrary placement, arbitrary shape sizes, including largest ""diameters"" $\simeq d$ or even $>d$ )? Are these conclusions generally in line with those obtained for percolation of lines in 2D space, or do they fundamentally differ (such as with 2D vs. 3D random walks)?",,['statistics']
9,Convergence of $c_j = \sum_{k=1}^nx_k\cos(2\pi\frac{k-1}{n})j$,Convergence of,c_j = \sum_{k=1}^nx_k\cos(2\pi\frac{k-1}{n})j,"S. Kim, K, Umeno, and A. Hasegawa, Corrections of the NIST Statistical Test Suite for Randomness (available at http://arxiv.org/pdf/nlin/0401040.pdf ) mention page 8-9 that: $c_j = \sum_{k=1}^nx_k\cos(2\pi\frac{k-1}{n})j$ converges to the normal distribution with mean $0$ and variance $n/2$ for $x_k$ random and $x_k =\pm 1$. What is a proof for this?","S. Kim, K, Umeno, and A. Hasegawa, Corrections of the NIST Statistical Test Suite for Randomness (available at http://arxiv.org/pdf/nlin/0401040.pdf ) mention page 8-9 that: $c_j = \sum_{k=1}^nx_k\cos(2\pi\frac{k-1}{n})j$ converges to the normal distribution with mean $0$ and variance $n/2$ for $x_k$ random and $x_k =\pm 1$. What is a proof for this?",,"['statistics', 'convergence-divergence']"
10,Conditional distribution for a label given a scalar feature,Conditional distribution for a label given a scalar feature,,"I am trying to create a simple simulation setup for classifiers on toy data. Each data point can has a scalar feature $X$, which is uniformly distributed between -1 and 1. Depending on the feature, this data point is given a label $T \in\{-1,1\}$. One of the thing I want to specify in this scheme is the fraction of positive instances, $\theta$. Thus: $P(X=x)= 1/2, x\in [-1,1]$ $P(T=+1) = \theta$ and $P(T=-1) = 1-\theta$ What I am interested in is in the distribution of T, given X. This has to be analytically traceable. I define, somewhat arbitrary, $P(T=+1|X=x) = Ce^{ax}$, with $a$ a tuning parameter and $C$ a constant to make this distribution correct. Fill this in Bayes' rule: $$P(T=+1|X=x) = \frac{P(X=x|T=+1)P(T=+1)}{P(X=x)} $$  or $$Ce^{ax} = 2\theta P(X=x|T=+1) $$ integrate over $X$ gives: $$\int_{-1}^1Ce^{ax} dx= 2\theta \int_{-1}^1P(X=x|T=+1) dx$$ $$\frac{C}{a} (e^a-e^{-a})= 2\theta $$ So I get my constant $C$: $$P(T=+1|X=x) = \frac{\theta a}{\sinh (a)}$$ This is not a good distribution, because , for some values of $a$, for example 1, I obtain probabilities larger than 1: $P(T=+1|X=0.9) = 2.09\theta$, thus incorrect for fractions of positive examples larger than about 0.5. I have the feeling my reasoning is wrong because I mix probability mass functions with probability density functions. If I work with cumulative probability functions an analogue reasoning yields: $$P(T=+1|X\leq x) = \theta \frac{e^{a}-e^{-a}}{(x+1)\sinh (a) }$$ This seems more reasonable, but I don't see how to obtain a function of T, given X. Does someone see what is wrong with my reasoning? Any suggestions for a function of the probability of the label given the feature with the restrictions of the marginal distribution of X and T? Thanks in advance!","I am trying to create a simple simulation setup for classifiers on toy data. Each data point can has a scalar feature $X$, which is uniformly distributed between -1 and 1. Depending on the feature, this data point is given a label $T \in\{-1,1\}$. One of the thing I want to specify in this scheme is the fraction of positive instances, $\theta$. Thus: $P(X=x)= 1/2, x\in [-1,1]$ $P(T=+1) = \theta$ and $P(T=-1) = 1-\theta$ What I am interested in is in the distribution of T, given X. This has to be analytically traceable. I define, somewhat arbitrary, $P(T=+1|X=x) = Ce^{ax}$, with $a$ a tuning parameter and $C$ a constant to make this distribution correct. Fill this in Bayes' rule: $$P(T=+1|X=x) = \frac{P(X=x|T=+1)P(T=+1)}{P(X=x)} $$  or $$Ce^{ax} = 2\theta P(X=x|T=+1) $$ integrate over $X$ gives: $$\int_{-1}^1Ce^{ax} dx= 2\theta \int_{-1}^1P(X=x|T=+1) dx$$ $$\frac{C}{a} (e^a-e^{-a})= 2\theta $$ So I get my constant $C$: $$P(T=+1|X=x) = \frac{\theta a}{\sinh (a)}$$ This is not a good distribution, because , for some values of $a$, for example 1, I obtain probabilities larger than 1: $P(T=+1|X=0.9) = 2.09\theta$, thus incorrect for fractions of positive examples larger than about 0.5. I have the feeling my reasoning is wrong because I mix probability mass functions with probability density functions. If I work with cumulative probability functions an analogue reasoning yields: $$P(T=+1|X\leq x) = \theta \frac{e^{a}-e^{-a}}{(x+1)\sinh (a) }$$ This seems more reasonable, but I don't see how to obtain a function of T, given X. Does someone see what is wrong with my reasoning? Any suggestions for a function of the probability of the label given the feature with the restrictions of the marginal distribution of X and T? Thanks in advance!",,"['probability', 'statistics', 'bayesian', 'naive-bayes']"
11,integrating using student t distribution,integrating using student t distribution,,Evaluate the integral $\int_0^\infty\frac{1}{1+x^2}dx$ using the Student t distribution. I don't know where to start. I am assuming that I can't just do regular integration.  I don't know how I am supposed to use the Student T distribution.  Does it have to do with the pdf of  the Student T distribution? Can anyone help me?,Evaluate the integral $\int_0^\infty\frac{1}{1+x^2}dx$ using the Student t distribution. I don't know where to start. I am assuming that I can't just do regular integration.  I don't know how I am supposed to use the Student T distribution.  Does it have to do with the pdf of  the Student T distribution? Can anyone help me?,,"['probability', 'statistics', 'integration', 'probability-distributions']"
12,What is the difference between a zero-inflated and a zero-truncated poisson?,What is the difference between a zero-inflated and a zero-truncated poisson?,,"I'm trying to make sense of a question which uses a zero-inflated poisson model given by: $$ f(x; \lambda,\omega) = \begin{cases} \omega + (1-\omega)e^{-\lambda} &\mbox{if } x = 0    \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (1) \\ \frac{(1-\omega)e^{-\lambda}\lambda^x}{x!} & \mbox{if } x = 1,2,3,\dots \ \ \ \ \ \ \ (2)\end{cases}  $$ We are given a table of data,  x = 0, 1, 2, 3, 4 and the number of occurrences of each. In lectures we covered a very similar question, however it used a zero-truncated poisson, given by: $$  g(x; \theta) = \frac{e^{-\theta}\theta^x}{x!(1-e^{-\theta)}}  x = 1,2,3,\dots \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3) $$ Obviously if I equate $(2)$ with $(3)$ I get $(1-\omega) = (1-e^{-\theta})^{-1}$. Now the question asks me to find the log-likelihood functions for $\lambda$ and $\omega$, then show that the MLE for $\hat{\lambda}$ is given by $$\frac{\hat{\lambda}}{1-e^{-\hat{\lambda}}} = \bar{x}$$ (Here $\bar{x}$ is the mean for $x_i \neq 0$.) Now, this is the exact answer we got in lectures - and it's the answer I get here if I ignore (1) in my calculations. If I try to include both (1) and (2) in calculating the MLE, things get pretty messy. My question is, what happens to (1)? Is there actually a difference between these two distributions? Also, once I calculate $\lambda$ and $\omega$, and use (1) to get a value for the frequency of $x=0$, I get a value very close to zero, whereas the frequency in the original table is 97 (all the other frequencies calculated by the model tally closely, as expected). One other thing, if you are being kind enough to consider answering my question, is that I have no idea what a link-function is, and presume we are not expected to use it in answering this question.","I'm trying to make sense of a question which uses a zero-inflated poisson model given by: $$ f(x; \lambda,\omega) = \begin{cases} \omega + (1-\omega)e^{-\lambda} &\mbox{if } x = 0    \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (1) \\ \frac{(1-\omega)e^{-\lambda}\lambda^x}{x!} & \mbox{if } x = 1,2,3,\dots \ \ \ \ \ \ \ (2)\end{cases}  $$ We are given a table of data,  x = 0, 1, 2, 3, 4 and the number of occurrences of each. In lectures we covered a very similar question, however it used a zero-truncated poisson, given by: $$  g(x; \theta) = \frac{e^{-\theta}\theta^x}{x!(1-e^{-\theta)}}  x = 1,2,3,\dots \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3) $$ Obviously if I equate $(2)$ with $(3)$ I get $(1-\omega) = (1-e^{-\theta})^{-1}$. Now the question asks me to find the log-likelihood functions for $\lambda$ and $\omega$, then show that the MLE for $\hat{\lambda}$ is given by $$\frac{\hat{\lambda}}{1-e^{-\hat{\lambda}}} = \bar{x}$$ (Here $\bar{x}$ is the mean for $x_i \neq 0$.) Now, this is the exact answer we got in lectures - and it's the answer I get here if I ignore (1) in my calculations. If I try to include both (1) and (2) in calculating the MLE, things get pretty messy. My question is, what happens to (1)? Is there actually a difference between these two distributions? Also, once I calculate $\lambda$ and $\omega$, and use (1) to get a value for the frequency of $x=0$, I get a value very close to zero, whereas the frequency in the original table is 97 (all the other frequencies calculated by the model tally closely, as expected). One other thing, if you are being kind enough to consider answering my question, is that I have no idea what a link-function is, and presume we are not expected to use it in answering this question.",,['statistics']
13,Is there any complete mathematical model for demand prediction?,Is there any complete mathematical model for demand prediction?,,"Assuming that I have the history of the demand as a function of price $p \in [p_{min},p_{max}]$. I need a model better than the linear regression to predict the demand and its elasticity. The model should be able to select the most relevant historical informations (the minimum amount possible like in the compressive sampling theory). I will exploit this model to choose the prices that maximizes the revenue and explore prices that doesn't belong to $[p_{min},p_{max}]$ (bandit theory). Do you know any complete demand prediction model that fulfills those requirements? Thanks in advance","Assuming that I have the history of the demand as a function of price $p \in [p_{min},p_{max}]$. I need a model better than the linear regression to predict the demand and its elasticity. The model should be able to select the most relevant historical informations (the minimum amount possible like in the compressive sampling theory). I will exploit this model to choose the prices that maximizes the revenue and explore prices that doesn't belong to $[p_{min},p_{max}]$ (bandit theory). Do you know any complete demand prediction model that fulfills those requirements? Thanks in advance",,"['statistics', 'probability-distributions', 'machine-learning']"
14,How do we estimate binomial confidence intervals when there are zero successes or failures?,How do we estimate binomial confidence intervals when there are zero successes or failures?,,"Imagine I'm performing an experiment where I treat cells with some compound looking for toxicity.  I test $N$ identical cells with the compound and all cells die immediately.  As a function of $N$, how certain can I be that the next sampled cell will die when treated with the compound?","Imagine I'm performing an experiment where I treat cells with some compound looking for toxicity.  I test $N$ identical cells with the compound and all cells die immediately.  As a function of $N$, how certain can I be that the next sampled cell will die when treated with the compound?",,"['probability', 'statistics', 'statistical-inference']"
15,Why are log-probabilities of global states of Boltzmann machines linear in their energies?,Why are log-probabilities of global states of Boltzmann machines linear in their energies?,,"While going through the Wikipedia article about Boltzmann machines, I read the following on the probabilities of global states of Boltzmann machines in the ""Equilibrium state"" section ( http://en.wikipedia.org/wiki/Boltzmann_machine#Equilibrium_state ): The network is run by repeatedly choosing a unit and setting its state   according to the above formula. After running for long enough at a   certain temperature, the probability of a global state of the network   will depend only upon that global state's energy, according to a   Boltzmann distribution. This means that log-probabilities of global   states become linear in their energies . The probability of a global state is usually defined as: $$ P(x) = \frac{e^{-Energy(x)}}{Z}, $$ where the partition function Z is: $$ Z = \sum_u{e^{-Energy(u)}}. $$ However, taking log of P(x): $$ \log{P(x)} = -Energy(x) - \log{(\sum_u{e^{-Energy(u)}})},$$ we arrive at an expression of the log probability of a global state which is not linear. Could you tell me where I'm wrong?","While going through the Wikipedia article about Boltzmann machines, I read the following on the probabilities of global states of Boltzmann machines in the ""Equilibrium state"" section ( http://en.wikipedia.org/wiki/Boltzmann_machine#Equilibrium_state ): The network is run by repeatedly choosing a unit and setting its state   according to the above formula. After running for long enough at a   certain temperature, the probability of a global state of the network   will depend only upon that global state's energy, according to a   Boltzmann distribution. This means that log-probabilities of global   states become linear in their energies . The probability of a global state is usually defined as: $$ P(x) = \frac{e^{-Energy(x)}}{Z}, $$ where the partition function Z is: $$ Z = \sum_u{e^{-Energy(u)}}. $$ However, taking log of P(x): $$ \log{P(x)} = -Energy(x) - \log{(\sum_u{e^{-Energy(u)}})},$$ we arrive at an expression of the log probability of a global state which is not linear. Could you tell me where I'm wrong?",,"['statistics', 'dynamical-systems', 'machine-learning']"
16,Consider a bipartite graph and Deduce that there exist infinitely many bipartite graphs,Consider a bipartite graph and Deduce that there exist infinitely many bipartite graphs,,"Consider a bipartite graph $G=(X \cup Y, E)$ with both sides of equal size; we let $n$ denote $|X|=|Y|$ We are also given an integer $d\ge 3$ and we wish each vertex in $X$ to be adjacent to at most $d$ neighbors in $Y$ . For any, it is easy to construct arbitrarily large bipartite graphs with this property. It is not as easy to make a graph which also has the following expansion properties: $P_1$ : for each $S \subseteq X$ with $|X|\le\dfrac{n}{3d}$ we have $|N(S)|\ge\dfrac{|S|d}4$ $P_2$ : for each $S \subseteq X$ with $\dfrac{n}{3d} < |S|\le\dfrac{n}2$ we have $|N(S)|\ge |S| + \dfrac{n}{3d}$ Consider the following experiment. For each $v\in X$ , choose $d$ vertices in $Y$ independently at random, and make these vertices adjacent to $v$ . Let $G'$ be the resulting random graph. Prove that (if $n$ is sufficiently large with respect to $d$ ), then with probability greater than $0.75$ , Property $P_1$ holds for $G'$ . Deduce that there exist infinitely many bipartite graphs with these expansion properties.","Consider a bipartite graph with both sides of equal size; we let denote We are also given an integer and we wish each vertex in to be adjacent to at most neighbors in . For any, it is easy to construct arbitrarily large bipartite graphs with this property. It is not as easy to make a graph which also has the following expansion properties: : for each with we have : for each with we have Consider the following experiment. For each , choose vertices in independently at random, and make these vertices adjacent to . Let be the resulting random graph. Prove that (if is sufficiently large with respect to ), then with probability greater than , Property holds for . Deduce that there exist infinitely many bipartite graphs with these expansion properties.","G=(X \cup Y, E) n |X|=|Y| d\ge 3 X d Y P_1 S \subseteq X |X|\le\dfrac{n}{3d} |N(S)|\ge\dfrac{|S|d}4 P_2 S \subseteq X \dfrac{n}{3d} < |S|\le\dfrac{n}2 |N(S)|\ge |S| + \dfrac{n}{3d} v\in X d Y v G' n d 0.75 P_1 G'","['probability', 'statistics', 'probability-theory', 'discrete-mathematics']"
17,Does weak convergence of two independent sequences of random processes imply weak convergence of the couple sequence?,Does weak convergence of two independent sequences of random processes imply weak convergence of the couple sequence?,,"I consider sequences of random processes in the Skorohod space. Let $F_n$ and $G_n$ converge weakly to F and G, respectively, in $D[-\infty,\infty]$ endowed with the supnorm. I suppose that this implies that $(F_n,G_n)$ converges weakly to $(F,G)$ in $D[-\infty,\infty]^2$ with the $\max\{\|\|,\|\|\}$ norm.  My attempts: Using the portmanteau lemma I tried to check that $\liminf_{n\to\infty} P((X_n,G_n)\in U)\geq P((F,G)\in U)$ for all U open in $D[-\infty,\infty]^2$. Let first U be a product of open sets in $D[-\infty,\infty]$, $U=U_1\times U_2$: $$ \liminf_{n\to\infty}P((F_n,G_n)\in U)=\liminf_{n\to\infty}P(F_n\in U1)P(G_n\in U2)\geq P(F\in U1)P(G\in U2)=P((F,G)\in U) $$ (I applied the portmanteau lemma on the componentwise convergence and used the independence of the processes for each n and of the limit processes). For general U and disjoint unions of product sets with $\bigcup{U_{i,1}\times U_{i,2}}\subset U$, we have: $$ \liminf_{n\to\infty}P((F_n,G_n)\in U)\geq\liminf_{n\to\infty}P((F_n,G_n)\in \bigcup{U_{i,1}\times U_{i,2}})\geq \liminf\sum P((F_n,G_n)\in U_{i,1}\times U_{i,2})\geq \sum P((F,G)\in U_{i,1}\times U_{i,2})=P((F,G)\in \bigcup U_{i,1}\times U_{i,2}) $$ hence $$ \liminf_{n\to\infty}P((F_n,G_n)\in U)\geq \sup P((F,G)\in \bigcup U_{i,1}\times U_{i,2}) $$ where the sup goes over disjoint unions of product sets that are subsets of U. I assume that this last term is equal to $P((F,G)\in U)$. I know that $D[-\infty,\infty]^2$ is not separable, however I still have hope for that to be true, as we are allowed to take product sets not only of balls, but of general open sets in $D[-\infty,\infty]$ which might damp the lack of seperability.  Any ideas? Or am I simply wrong?","I consider sequences of random processes in the Skorohod space. Let $F_n$ and $G_n$ converge weakly to F and G, respectively, in $D[-\infty,\infty]$ endowed with the supnorm. I suppose that this implies that $(F_n,G_n)$ converges weakly to $(F,G)$ in $D[-\infty,\infty]^2$ with the $\max\{\|\|,\|\|\}$ norm.  My attempts: Using the portmanteau lemma I tried to check that $\liminf_{n\to\infty} P((X_n,G_n)\in U)\geq P((F,G)\in U)$ for all U open in $D[-\infty,\infty]^2$. Let first U be a product of open sets in $D[-\infty,\infty]$, $U=U_1\times U_2$: $$ \liminf_{n\to\infty}P((F_n,G_n)\in U)=\liminf_{n\to\infty}P(F_n\in U1)P(G_n\in U2)\geq P(F\in U1)P(G\in U2)=P((F,G)\in U) $$ (I applied the portmanteau lemma on the componentwise convergence and used the independence of the processes for each n and of the limit processes). For general U and disjoint unions of product sets with $\bigcup{U_{i,1}\times U_{i,2}}\subset U$, we have: $$ \liminf_{n\to\infty}P((F_n,G_n)\in U)\geq\liminf_{n\to\infty}P((F_n,G_n)\in \bigcup{U_{i,1}\times U_{i,2}})\geq \liminf\sum P((F_n,G_n)\in U_{i,1}\times U_{i,2})\geq \sum P((F,G)\in U_{i,1}\times U_{i,2})=P((F,G)\in \bigcup U_{i,1}\times U_{i,2}) $$ hence $$ \liminf_{n\to\infty}P((F_n,G_n)\in U)\geq \sup P((F,G)\in \bigcup U_{i,1}\times U_{i,2}) $$ where the sup goes over disjoint unions of product sets that are subsets of U. I assume that this last term is equal to $P((F,G)\in U)$. I know that $D[-\infty,\infty]^2$ is not separable, however I still have hope for that to be true, as we are allowed to take product sets not only of balls, but of general open sets in $D[-\infty,\infty]$ which might damp the lack of seperability.  Any ideas? Or am I simply wrong?",,"['statistics', 'probability-theory', 'stochastic-processes', 'weak-convergence']"
18,What are the constants in the relationship between point density and median point distance?,What are the constants in the relationship between point density and median point distance?,,"Given $\rho$ particles uniformly distributed on a plane within a unit square ($\rho > 1$), each particle has another particle that is closest to it; the median of those nearest distances is called $\tilde{d}$. Here's a graph where each point represents a random distribution of particles: Taking the mean $\tilde{d}$ for each value of $\rho$ produces a nice graph which aligns with this function: $\tilde{d} = \frac{k_1}{\rho}+\frac{k_2}{\sqrt{\rho}}$ The constants are estimated here to be: $k_1 \approx 0.1705$ $k_2 \approx 0.4649$ These constants have been calculated empirically (interpolating the empirical points to a function); is there a way to calculate them theoretically? In other words, is there a purely mathematical proof of a relationship between $\rho$ and $\tilde{d}$? EDIT: I managed to mathematically derive $\tilde{d}$ for $\rho = 2$; but this is by far the easiest and it's already a long formula:","Given $\rho$ particles uniformly distributed on a plane within a unit square ($\rho > 1$), each particle has another particle that is closest to it; the median of those nearest distances is called $\tilde{d}$. Here's a graph where each point represents a random distribution of particles: Taking the mean $\tilde{d}$ for each value of $\rho$ produces a nice graph which aligns with this function: $\tilde{d} = \frac{k_1}{\rho}+\frac{k_2}{\sqrt{\rho}}$ The constants are estimated here to be: $k_1 \approx 0.1705$ $k_2 \approx 0.4649$ These constants have been calculated empirically (interpolating the empirical points to a function); is there a way to calculate them theoretically? In other words, is there a purely mathematical proof of a relationship between $\rho$ and $\tilde{d}$? EDIT: I managed to mathematically derive $\tilde{d}$ for $\rho = 2$; but this is by far the easiest and it's already a long formula:",,['statistics']
19,Probability of Event Occurring in Time-Series,Probability of Event Occurring in Time-Series,,"So I'm trying to model email openings over the course of a day. For example, I have a data set for one individual that simply has a bunch of time-stamps of when he has opened an email. I don't care about the date, just the time of day. So over the course of a 24 hour day, there will be events along the time-series (X) axis. I want to model this so that I can plug in a time and it will give me the probability of the event (email opening) occurring at that specific time given the historical data. So the Y axis has no magnitude, it's just an event happened at that specific time or it didn't. Not sure how to represent this mathematically. Any help would be appreciated!","So I'm trying to model email openings over the course of a day. For example, I have a data set for one individual that simply has a bunch of time-stamps of when he has opened an email. I don't care about the date, just the time of day. So over the course of a 24 hour day, there will be events along the time-series (X) axis. I want to model this so that I can plug in a time and it will give me the probability of the event (email opening) occurring at that specific time given the historical data. So the Y axis has no magnitude, it's just an event happened at that specific time or it didn't. Not sure how to represent this mathematically. Any help would be appreciated!",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
20,Log-likelihood for multinominal normal distribution,Log-likelihood for multinominal normal distribution,,"Given $n$ jointly-normal random variables $X_1, X_2, \dots, X_n$, with  $$\mu_i=\mu\forall i \in\mathbb{N}^+$$ $$\sigma_i=\sigma\forall i$$ $$\rho_{i,j}=\rho\forall i,j \mbox{ with } i\neq j$$ what is their log-likelihood function? My idea is the following: Be $\mathbf{x}=(X_1,X_2, \dots,X_n)^T$ the vector of observed values and $\mu=(\mu, \dots,\mu)^T$ a $n\times1$-Vektor. Then the $n\times n$ covariance matrix is given by $\Sigma$ with all diagonal elements being $\sigma^2$ and all other entries $\rho\sigma^2$. The log-likelihood is given by: $$ L(\mu, \sigma, \rho) =\log [ exp(\frac{-1}{2}(\mathbf{x}-\mu)^T)\Sigma^{-1}(\mathbf{x}-\mu))]$$ Is this correct?","Given $n$ jointly-normal random variables $X_1, X_2, \dots, X_n$, with  $$\mu_i=\mu\forall i \in\mathbb{N}^+$$ $$\sigma_i=\sigma\forall i$$ $$\rho_{i,j}=\rho\forall i,j \mbox{ with } i\neq j$$ what is their log-likelihood function? My idea is the following: Be $\mathbf{x}=(X_1,X_2, \dots,X_n)^T$ the vector of observed values and $\mu=(\mu, \dots,\mu)^T$ a $n\times1$-Vektor. Then the $n\times n$ covariance matrix is given by $\Sigma$ with all diagonal elements being $\sigma^2$ and all other entries $\rho\sigma^2$. The log-likelihood is given by: $$ L(\mu, \sigma, \rho) =\log [ exp(\frac{-1}{2}(\mathbf{x}-\mu)^T)\Sigma^{-1}(\mathbf{x}-\mu))]$$ Is this correct?",,"['statistics', 'normal-distribution']"
21,"How to calculate $x_t$ from $ARIMA(1,2,0)$ (second difference $AR(1)$ process)?",How to calculate  from  (second difference  process)?,"x_t ARIMA(1,2,0) AR(1)",It sounds so simple but I'v struggled with this problem for a quite long time now. I have come to this: $$X_t = \phi(x_{t-1} - 2x_{t-2} + x_{t-3}) + 2x_{t-1} - x_{t-2} + \epsilon_t$$ it just doesn't give the right values..,It sounds so simple but I'v struggled with this problem for a quite long time now. I have come to this: $$X_t = \phi(x_{t-1} - 2x_{t-2} + x_{t-3}) + 2x_{t-1} - x_{t-2} + \epsilon_t$$ it just doesn't give the right values..,,"['probability', 'statistics', 'stochastic-processes']"
22,Poisson distribution normal approximation,Poisson distribution normal approximation,,"6.4.18. An experimenter takes a sample of size 1 from the Poisson probability model, pX (k) = e−λλk/k!, k = 0, 1, 2, . . . , and wishes to test H0: λ=6 versus H1:λ<6 by rejecting H0 if k ≤2. (a) Calculate the probability of committing a Type I error. Can someone explain what is the best way to approach this problem thank you","6.4.18. An experimenter takes a sample of size 1 from the Poisson probability model, pX (k) = e−λλk/k!, k = 0, 1, 2, . . . , and wishes to test H0: λ=6 versus H1:λ<6 by rejecting H0 if k ≤2. (a) Calculate the probability of committing a Type I error. Can someone explain what is the best way to approach this problem thank you",,['statistics']
23,Orthogonal intersection in a Riemannian manifold,Orthogonal intersection in a Riemannian manifold,,"Following is a question which I also asked in stats.stackexchange where I haven't got a response yet.  Here is a link . Let $S$ be the set of all probability distributions on $\mathbb{R}$ and $S_n=\{p_\theta\}$ be an $n$ dimensional submanifold of parameterized family of probability distributions on $\mathbb{R}$ where $\theta=(\theta_1,\dots, \theta_n)\in \Theta$ are called parameters of the probability density $p_\theta(x)$ and $\Theta$ is an open set homeomorphic to $\mathbb{R}^n$. It is also assumed that $p_\theta(x)>0$ for all $x$. For example, $$p_{\theta=(\mu,\sigma)}(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}$$ where $\mu\in \mathbb{R},\sigma>0$ forms a $2$-dimensional submanifold. On this manifold, a Riemannian metric is defined by the following, called Fisher information metric. $$ g_{i,j}(\partial_i,\partial_j)=\int \partial_i \log p_\theta(x) ~\partial_j \log p_\theta(x) ~p_\theta(x)~dx$$ where $\partial_i=\frac{\partial}{\partial \theta_i}$. My question is regarding a point in page 384 from this Ann. Stat. paper by Amari. In the above mentioned paper, when he says a curve $\{q_t(x)\}$ in $S$, where $q_0(x)=p_\theta(x)$ intersects orthogonally $S_n$ at $p_\theta(x)$, he means $$\int \partial_i \log p_\theta(x) ~\frac{d}{dt} \log q_t(x)\lvert_{t=0} ~q_0(x)~dx=0$$. Why? Could somebody make me understand by giving intuitive explanation of these concepts?","Following is a question which I also asked in stats.stackexchange where I haven't got a response yet.  Here is a link . Let $S$ be the set of all probability distributions on $\mathbb{R}$ and $S_n=\{p_\theta\}$ be an $n$ dimensional submanifold of parameterized family of probability distributions on $\mathbb{R}$ where $\theta=(\theta_1,\dots, \theta_n)\in \Theta$ are called parameters of the probability density $p_\theta(x)$ and $\Theta$ is an open set homeomorphic to $\mathbb{R}^n$. It is also assumed that $p_\theta(x)>0$ for all $x$. For example, $$p_{\theta=(\mu,\sigma)}(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}$$ where $\mu\in \mathbb{R},\sigma>0$ forms a $2$-dimensional submanifold. On this manifold, a Riemannian metric is defined by the following, called Fisher information metric. $$ g_{i,j}(\partial_i,\partial_j)=\int \partial_i \log p_\theta(x) ~\partial_j \log p_\theta(x) ~p_\theta(x)~dx$$ where $\partial_i=\frac{\partial}{\partial \theta_i}$. My question is regarding a point in page 384 from this Ann. Stat. paper by Amari. In the above mentioned paper, when he says a curve $\{q_t(x)\}$ in $S$, where $q_0(x)=p_\theta(x)$ intersects orthogonally $S_n$ at $p_\theta(x)$, he means $$\int \partial_i \log p_\theta(x) ~\frac{d}{dt} \log q_t(x)\lvert_{t=0} ~q_0(x)~dx=0$$. Why? Could somebody make me understand by giving intuitive explanation of these concepts?",,"['statistics', 'riemannian-geometry']"
24,Questions about distribution-free statistic,Questions about distribution-free statistic,,"If I understand correctly, a statistic $T$ is said to be distribution free, if the distribution of $T(X)$ doesn't depend on the distribution of $X$. Examples are Kolmogorov-Smirnov test statistic . To prove $T$ is distribution free, is it equvalent to showing that $T(F^{-1}(U)) = T(U)$, for a random variable $X$ with an arbitrary cdf $F$, and a uniform random variable $U$ over $(0,1)$? Are distribution free statistics always nonparametric statistics?","If I understand correctly, a statistic $T$ is said to be distribution free, if the distribution of $T(X)$ doesn't depend on the distribution of $X$. Examples are Kolmogorov-Smirnov test statistic . To prove $T$ is distribution free, is it equvalent to showing that $T(F^{-1}(U)) = T(U)$, for a random variable $X$ with an arbitrary cdf $F$, and a uniform random variable $U$ over $(0,1)$? Are distribution free statistics always nonparametric statistics?",,"['probability', 'statistics']"
25,Asymptotic behaviour of sums of covariances of RVs with LRD,Asymptotic behaviour of sums of covariances of RVs with LRD,,"Our assumptions are: $\left(X_t\right)_{t\geqslant 0}$ is a stationary sequence of standard normal random variables such that $\gamma _X (k)\sim L_{\gamma}(k)k^{2d-1}$ with $d \in (0,1/2)$, where $L_\gamma (k)$ is a slowly varying function. Let $Y_t:=G\left(X_t\right)$ with a real function $G$ such that $\mathbb{E}\left(G\left(X_1\right)\right)=0$ and $\mathbb{E}\left(G\left(X_1\right)^2\right)<\infty$.  We know that for the ACF holds $$\gamma_Y (k)\sim\frac{J(m)^2}{m!}L_\gamma^m(k)k^{m(2d-1)}$$ for $k\rightarrow \infty$, where $m$ is the Hermite rank of $G$, $J(m):=\mathbb{E}\left[G(X)H_m(X)\right]$ and $H_m$ is the $m$-th Hermite polynomial. What can we now say about the asymptotic behaviour of the sum of covariances $$\sum_{j=1}^{\ell}\sum_{k=\ell+1}^{n}\mathrm{Cov}\left(Y_{j}, Y_{k}\right)$$ for $n\rightarrow\infty$ and $\ell$ fixed?","Our assumptions are: $\left(X_t\right)_{t\geqslant 0}$ is a stationary sequence of standard normal random variables such that $\gamma _X (k)\sim L_{\gamma}(k)k^{2d-1}$ with $d \in (0,1/2)$, where $L_\gamma (k)$ is a slowly varying function. Let $Y_t:=G\left(X_t\right)$ with a real function $G$ such that $\mathbb{E}\left(G\left(X_1\right)\right)=0$ and $\mathbb{E}\left(G\left(X_1\right)^2\right)<\infty$.  We know that for the ACF holds $$\gamma_Y (k)\sim\frac{J(m)^2}{m!}L_\gamma^m(k)k^{m(2d-1)}$$ for $k\rightarrow \infty$, where $m$ is the Hermite rank of $G$, $J(m):=\mathbb{E}\left[G(X)H_m(X)\right]$ and $H_m$ is the $m$-th Hermite polynomial. What can we now say about the asymptotic behaviour of the sum of covariances $$\sum_{j=1}^{\ell}\sum_{k=\ell+1}^{n}\mathrm{Cov}\left(Y_{j}, Y_{k}\right)$$ for $n\rightarrow\infty$ and $\ell$ fixed?",,"['statistics', 'stochastic-processes', 'covariance', 'stationary-processes']"
26,Likelihod ratio test: $f_0(x)=2x$ vs $f_1(x)=3x^2$ : $2n$ degree of freedom?,Likelihod ratio test:  vs  :  degree of freedom?,f_0(x)=2x f_1(x)=3x^2 2n,"Let $\left\{ X_i \right \}$ be an $n$-sample with pdf $f$. Show that the likelihood ratio test statistic for \begin{align} H_0 &: f(x) = 2x \\ H_1 &: f(x)= 3x^2 \end{align} has a $\chi^2$ distribution with $2n$ degrees of freedom. The likelihood ratio test statistic is $$ \lambda = \frac{\prod f_0(x_i)}{\prod f_1(x_i)} =  \frac{(2/3)^n}{t^n}, $$ with $t=\prod x_i$. Then I should show $$ \lim_{n\to\infty} -2\ln \lambda \stackrel{d}= \chi^2(2n). $$ How can the degree of freedom be $2n$? I don't see any parameter in $H_0$ and $H_1$, to apply the theorem which says $$ \lim_{n\to\infty} -2\ln \lambda \stackrel{d}= \chi^2(\#\Theta_1-\#\Theta_0). $$","Let $\left\{ X_i \right \}$ be an $n$-sample with pdf $f$. Show that the likelihood ratio test statistic for \begin{align} H_0 &: f(x) = 2x \\ H_1 &: f(x)= 3x^2 \end{align} has a $\chi^2$ distribution with $2n$ degrees of freedom. The likelihood ratio test statistic is $$ \lambda = \frac{\prod f_0(x_i)}{\prod f_1(x_i)} =  \frac{(2/3)^n}{t^n}, $$ with $t=\prod x_i$. Then I should show $$ \lim_{n\to\infty} -2\ln \lambda \stackrel{d}= \chi^2(2n). $$ How can the degree of freedom be $2n$? I don't see any parameter in $H_0$ and $H_1$, to apply the theorem which says $$ \lim_{n\to\infty} -2\ln \lambda \stackrel{d}= \chi^2(\#\Theta_1-\#\Theta_0). $$",,['statistics']
27,How to determine the degrees of freedom of an inner-product matrix of two random matrices?,How to determine the degrees of freedom of an inner-product matrix of two random matrices?,,"I have two random matrices $A$ and $B$, with $N$ columns each. The columns of $A$ and $B$ are independent but not necessarily identically distributed. $A$ and $B$ may be considered as two instances of an underlying matrix, for example, they may represent two sets of data-driven basis functions learned from datasets of subjects $A$ and $B$. With this setup, it follows that $M < N$ columns of $A$ have corresponding columns in $B$. That is, the inner product $A_i \cdot B_j$ of columns $A_i$ and $B_j$ is close to $1$ for $M < N$ pairs $(i,j)$, where $M$ is unknown a priori. The above intuition suggests that all entries of the matrix $G$, where $G_{i,j} = A_i \cdot B_j$ , are not independent of each other. My question: if one were to model $A$ and $B$ as random orthogonal matrices, how many degrees of freedom would $G$ have? How does one go about addressing this problem? Analytically? By simulation? Can we derive bounds on this number? I don't have formal training in mathematical statistics, so any pointers for where to look would be appreciated. Thanks!","I have two random matrices $A$ and $B$, with $N$ columns each. The columns of $A$ and $B$ are independent but not necessarily identically distributed. $A$ and $B$ may be considered as two instances of an underlying matrix, for example, they may represent two sets of data-driven basis functions learned from datasets of subjects $A$ and $B$. With this setup, it follows that $M < N$ columns of $A$ have corresponding columns in $B$. That is, the inner product $A_i \cdot B_j$ of columns $A_i$ and $B_j$ is close to $1$ for $M < N$ pairs $(i,j)$, where $M$ is unknown a priori. The above intuition suggests that all entries of the matrix $G$, where $G_{i,j} = A_i \cdot B_j$ , are not independent of each other. My question: if one were to model $A$ and $B$ as random orthogonal matrices, how many degrees of freedom would $G$ have? How does one go about addressing this problem? Analytically? By simulation? Can we derive bounds on this number? I don't have formal training in mathematical statistics, so any pointers for where to look would be appreciated. Thanks!",,"['linear-algebra', 'probability-theory', 'statistics', 'random-matrices']"
28,Calculating Probabilities of a Random Variable Function,Calculating Probabilities of a Random Variable Function,,"The problem is: A mail-order computer business has six telephone lines. Let $X$ denote the number of lines in use at a specified time. Suppose the pmf of $X$ is as given in the accompanying table. $$\begin{array}{c|c|c} x & \text{0} & \text{1} & \text{2} & \text{3} & \text{4} & \text{5} & \text{6}\\  \hline \\p(x) & .10 & .15& .20 & .25 & .20 & .06 & .04 \end{array}$$ Calculate the probability of each of the following events. a. {at most three lines are in use} b. {fewer than three lines are in use} c. {at least three lines are in use} d. {between two and five lines, inclusive, are in use} e. {between two and four lines, inclusive, are not in use} f. {at least four lines are not in use} The only parts I was unable to do were parts e) and f). For part f), I removed the negation of the statement, hoping that that might make the original statement more clear. So, if we say that we want the probability of the at least being in use, that would be the probability of $4$ in use, $5$ in use, or $6$ in use. But we don't care to know that probability, we want to know the opposite: we want to know the probability of less than 4 lines in use. This process didn't get me the right answer, however. Could someone help me with those two parts?","The problem is: A mail-order computer business has six telephone lines. Let $X$ denote the number of lines in use at a specified time. Suppose the pmf of $X$ is as given in the accompanying table. $$\begin{array}{c|c|c} x & \text{0} & \text{1} & \text{2} & \text{3} & \text{4} & \text{5} & \text{6}\\  \hline \\p(x) & .10 & .15& .20 & .25 & .20 & .06 & .04 \end{array}$$ Calculate the probability of each of the following events. a. {at most three lines are in use} b. {fewer than three lines are in use} c. {at least three lines are in use} d. {between two and five lines, inclusive, are in use} e. {between two and four lines, inclusive, are not in use} f. {at least four lines are not in use} The only parts I was unable to do were parts e) and f). For part f), I removed the negation of the statement, hoping that that might make the original statement more clear. So, if we say that we want the probability of the at least being in use, that would be the probability of $4$ in use, $5$ in use, or $6$ in use. But we don't care to know that probability, we want to know the opposite: we want to know the probability of less than 4 lines in use. This process didn't get me the right answer, however. Could someone help me with those two parts?",,"['probability', 'statistics']"
29,More efficient estimator?,More efficient estimator?,,"I have this kind of problem: The market share $Z$ of a company is estimated in two independent survey polls. The sample sizes are $n_1=500$ and $n_2=2000$ with corresponding observed shares $p_1$ and $p_2$, respectively. These two results are to be combined. Two alternative estimators of $Z$ are presented as follows: $Z_a=\frac{p_1+p_2}{2}$ $Z_b=\frac{p_1+4p_1}{5}$ Are these estimators unbiased? Which one of these estimators is more efficient? I know that $E(Z)=0.2p_1+0.8p_2=E(Z_b)\rightarrow Z_b$ is unbiased and $E(Z_a)=0.5p_1+0.5p_2$ so $Z_b$ is biased. Still I can't calculate MSE of these estimator so I don't know which one of these estimators is more efficient","I have this kind of problem: The market share $Z$ of a company is estimated in two independent survey polls. The sample sizes are $n_1=500$ and $n_2=2000$ with corresponding observed shares $p_1$ and $p_2$, respectively. These two results are to be combined. Two alternative estimators of $Z$ are presented as follows: $Z_a=\frac{p_1+p_2}{2}$ $Z_b=\frac{p_1+4p_1}{5}$ Are these estimators unbiased? Which one of these estimators is more efficient? I know that $E(Z)=0.2p_1+0.8p_2=E(Z_b)\rightarrow Z_b$ is unbiased and $E(Z_a)=0.5p_1+0.5p_2$ so $Z_b$ is biased. Still I can't calculate MSE of these estimator so I don't know which one of these estimators is more efficient",,['statistics']
30,Prove that $\mathrm{E}[X\mid A] = \mathrm{E}[X]$ for an event $A$ independent of random variable $X$,Prove that  for an event  independent of random variable,\mathrm{E}[X\mid A] = \mathrm{E}[X] A X,"I am a novice at statistics. I have approached the problem in the following way: $$\mathrm{E}[X\mid A] = (x_1\mid A \cdot P[x1\mid A] +  x_2\mid A \cdot P[x_2\mid A] + \ldots + x_k\mid A \cdot P[x_k\mid A])$$ ( using the definition of expectation ) $$\mathrm{E}[X\mid A]= (x_1P(x_1) + x_2P(x_2) + \ldots + x_kP(x_k))$$      ( As the event $A$ is independent of r.v $X$ ) $$\mathrm{E}[X\mid A]= \mathrm{E}[X]$$   ( using definition of expectation ) Am I thinking in the right direction? As I am very new to this topic, any hints or suggestions would be helpful.","I am a novice at statistics. I have approached the problem in the following way: $$\mathrm{E}[X\mid A] = (x_1\mid A \cdot P[x1\mid A] +  x_2\mid A \cdot P[x_2\mid A] + \ldots + x_k\mid A \cdot P[x_k\mid A])$$ ( using the definition of expectation ) $$\mathrm{E}[X\mid A]= (x_1P(x_1) + x_2P(x_2) + \ldots + x_kP(x_k))$$      ( As the event $A$ is independent of r.v $X$ ) $$\mathrm{E}[X\mid A]= \mathrm{E}[X]$$   ( using definition of expectation ) Am I thinking in the right direction? As I am very new to this topic, any hints or suggestions would be helpful.",,"['probability', 'statistics']"
31,How to a sample of a time series of zeros and ones with given autocorrelation function?,How to a sample of a time series of zeros and ones with given autocorrelation function?,,"Let's say, I have an autocorrelation function: $$C(\text{lag}) = \text{lag}^{-\gamma}$$ How can I generate a sample of a time series of, say, $0$'s and $1$'s, such that their sample autocorrelation function matches the given one? The given function is just an example. I am seeking a procedure for any autocorrelation function.","Let's say, I have an autocorrelation function: $$C(\text{lag}) = \text{lag}^{-\gamma}$$ How can I generate a sample of a time series of, say, $0$'s and $1$'s, such that their sample autocorrelation function matches the given one? The given function is just an example. I am seeking a procedure for any autocorrelation function.",,['statistics']
32,Weighted Standard Deviation for Histogram Bin Height,Weighted Standard Deviation for Histogram Bin Height,,"I'm plotting some binned data in the form of a histogram. Say I have 10 data points, each composed of a bin to be placed in, and then a ""height"". Then I might have something like: Bin   Height 0   - 2.2 1   - 1.3 2   - 0.1 0   - 2.4 2   - 0.28 1   - 0.8 0   - 1.8 1   - 1.0 0   - 2.6 0   - 2.2 I want to plot this, with the height of each bin being the sum of the heights of the pieces in each bin (so above, the full height of bin 2 would be 0.38). I'd like to find the standard deviation in the height of a bin. I know that my sample is drawn from a uniform distribution, but set up so that 0 is more likely than 2, since the range in the uniform distribution that corresponds to 0 is wider than that for 2. I know these ranges. The heights aren't generated using the uniform distribution. Update: how I get the heights - I start off with everyone in some bin, say 0, with each person having height 1. Then through some process, I get probabilities to move each one into another bin: Bin to move to:  Weight to move: 0                1 1                0.4 2                0.2 So then I add these heights up to get 1.6 or something, and use my uniform distribution to move to another bin (or stay in 0, depending on what I get). Then the ""height"" of the person is 1.6. If I do this update procedure multiple times, the total height is the product of these sums for each step. I want to add up all these total heights for everyone in the bin, and get a standard deviation on that so I'd have something like 0 - 11.2 +/- ?? 1 - 3.1 +/- ?? 2 - 0.38 +/- ??","I'm plotting some binned data in the form of a histogram. Say I have 10 data points, each composed of a bin to be placed in, and then a ""height"". Then I might have something like: Bin   Height 0   - 2.2 1   - 1.3 2   - 0.1 0   - 2.4 2   - 0.28 1   - 0.8 0   - 1.8 1   - 1.0 0   - 2.6 0   - 2.2 I want to plot this, with the height of each bin being the sum of the heights of the pieces in each bin (so above, the full height of bin 2 would be 0.38). I'd like to find the standard deviation in the height of a bin. I know that my sample is drawn from a uniform distribution, but set up so that 0 is more likely than 2, since the range in the uniform distribution that corresponds to 0 is wider than that for 2. I know these ranges. The heights aren't generated using the uniform distribution. Update: how I get the heights - I start off with everyone in some bin, say 0, with each person having height 1. Then through some process, I get probabilities to move each one into another bin: Bin to move to:  Weight to move: 0                1 1                0.4 2                0.2 So then I add these heights up to get 1.6 or something, and use my uniform distribution to move to another bin (or stay in 0, depending on what I get). Then the ""height"" of the person is 1.6. If I do this update procedure multiple times, the total height is the product of these sums for each step. I want to add up all these total heights for everyone in the bin, and get a standard deviation on that so I'd have something like 0 - 11.2 +/- ?? 1 - 3.1 +/- ?? 2 - 0.38 +/- ??",,"['statistics', 'standard-deviation']"
33,Huffman minimum variance coding,Huffman minimum variance coding,,"it is well known that Huffman code with minimum variance is preferable. I've digged through entire Polish/English internet and this is what I found: to build Huffman code with minimum variance you need to break ties with one of the following methods (of course probability of node is the most important): Select node that represents shortest tree Select node that was created earliest (consider leafs as created at start). the problem is, that I couldn't find any proof of correctness of any of these methods. Can someone proof any of these? I will gladly clarify anything.","it is well known that Huffman code with minimum variance is preferable. I've digged through entire Polish/English internet and this is what I found: to build Huffman code with minimum variance you need to break ties with one of the following methods (of course probability of node is the most important): Select node that represents shortest tree Select node that was created earliest (consider leafs as created at start). the problem is, that I couldn't find any proof of correctness of any of these methods. Can someone proof any of these? I will gladly clarify anything.",,"['probability', 'statistics', 'coding-theory']"
34,Finding the cumulative distribution function for the double exponential,Finding the cumulative distribution function for the double exponential,,"Im considering the double exponential with parameter $\lambda$, $$g(x)=\frac{\lambda}{2}e^{\lambda x}, x<0; \frac{\lambda}{2}e^{-\lambda x}, \geq 0$$ Just simple one looking for the c.d.f, I can't for some reason get the expression for $\geq$ 0 as I get $1/2 -\frac{1}{2}e^{-\lambda x}$. Many thanks in advance.","Im considering the double exponential with parameter $\lambda$, $$g(x)=\frac{\lambda}{2}e^{\lambda x}, x<0; \frac{\lambda}{2}e^{-\lambda x}, \geq 0$$ Just simple one looking for the c.d.f, I can't for some reason get the expression for $\geq$ 0 as I get $1/2 -\frac{1}{2}e^{-\lambda x}$. Many thanks in advance.",,"['probability', 'statistics', 'probability-distributions']"
35,Probability involving Method of Moments,Probability involving Method of Moments,,"Considering a box containing balls labeled 1 through $m$ from which we sample $n$ balls (hence, a discrete uniform distribution on  $\{ 1,2, \ldots, m\}$ so the probability of picking $x_i$ is $\frac{1}{m}$). We randomly sample $n$ elements $x_1 $, $x_2$, $\ldots$, $x_n$ (without replacement, so $x_1\ne x_2$ etc). Using the method of moments to approximate $\theta$, I get $E(X)=\bar{x}$, so a estimator $\hat m$ for  $m $ can be found through solving  $\frac{\hat m}{2}=\bar{x}$, hence $\hat m=2\bar{x}$, where $\bar{x}=\frac{x_1+x_2+...+x_n}{n}$. I was asked to find $Pr(2\bar{x}<\max(x_1,x_2,...,x_n))$ for n=2 (since when this is true our estimate for $m$ is clearly incorrect). Of course, this is trivial, since we get $Pr(\frac{2(x_1+x_2)}{2}<\max(x_1,x_2))=Pr(x_1+x_2<x_1)\cup Pr(x_1+x_2<x_2)=0$. It's fairly obvious, however, that for values of $n$ greater than 2, this is not the case. In class my teacher mentioned solving for this probability by hand gets increasingly difficult as $n$ gets larger, but it should be fairly doable for $n=3$. I'm just curious as to how one would approach this. I'm not really sure what the joint pmf for $x_1+x_2+x_3$ is (they're not independent, I believe), and also a little confused as to where I would set the bounds on the triple integral that follows. (If its not clear, I'm looking for $Pr(x_1+x_2+x_3<\frac{3\max(x_1,x_2,x_3)}{2}))$ I realize that this is not a practical approach really (the book suggests using simulations for higher values of n to approximate the probability), and that the MOM is not a great way to do this in general, but I'm curious nonetheless! Any thoughts? Edit: While unable to actually come up with the proper integral, I used some simulations in R to determine that the proper answer is $\frac{1}{8}$, I'm not sure if that helps anything but I figured I'd put it up here just in case.","Considering a box containing balls labeled 1 through $m$ from which we sample $n$ balls (hence, a discrete uniform distribution on  $\{ 1,2, \ldots, m\}$ so the probability of picking $x_i$ is $\frac{1}{m}$). We randomly sample $n$ elements $x_1 $, $x_2$, $\ldots$, $x_n$ (without replacement, so $x_1\ne x_2$ etc). Using the method of moments to approximate $\theta$, I get $E(X)=\bar{x}$, so a estimator $\hat m$ for  $m $ can be found through solving  $\frac{\hat m}{2}=\bar{x}$, hence $\hat m=2\bar{x}$, where $\bar{x}=\frac{x_1+x_2+...+x_n}{n}$. I was asked to find $Pr(2\bar{x}<\max(x_1,x_2,...,x_n))$ for n=2 (since when this is true our estimate for $m$ is clearly incorrect). Of course, this is trivial, since we get $Pr(\frac{2(x_1+x_2)}{2}<\max(x_1,x_2))=Pr(x_1+x_2<x_1)\cup Pr(x_1+x_2<x_2)=0$. It's fairly obvious, however, that for values of $n$ greater than 2, this is not the case. In class my teacher mentioned solving for this probability by hand gets increasingly difficult as $n$ gets larger, but it should be fairly doable for $n=3$. I'm just curious as to how one would approach this. I'm not really sure what the joint pmf for $x_1+x_2+x_3$ is (they're not independent, I believe), and also a little confused as to where I would set the bounds on the triple integral that follows. (If its not clear, I'm looking for $Pr(x_1+x_2+x_3<\frac{3\max(x_1,x_2,x_3)}{2}))$ I realize that this is not a practical approach really (the book suggests using simulations for higher values of n to approximate the probability), and that the MOM is not a great way to do this in general, but I'm curious nonetheless! Any thoughts? Edit: While unable to actually come up with the proper integral, I used some simulations in R to determine that the proper answer is $\frac{1}{8}$, I'm not sure if that helps anything but I figured I'd put it up here just in case.",,"['probability', 'statistics', 'integration']"
36,Expected value of picking smallest k random variables out of n,Expected value of picking smallest k random variables out of n,,"The question is, I'm picking random variables from a normal distribution with mean $\mu$ and standard deviation $\sigma$. If I'm picking n random variables and sorting them in the ascending order, what is the expected value of first k variables (from the sorted n variables)? Can anyone help me to derive an expression for this expected value?","The question is, I'm picking random variables from a normal distribution with mean $\mu$ and standard deviation $\sigma$. If I'm picking n random variables and sorting them in the ascending order, what is the expected value of first k variables (from the sorted n variables)? Can anyone help me to derive an expression for this expected value?",,"['probability', 'statistics', 'probability-distributions']"
37,Creating indices,Creating indices,,"Is there a ""proper"" formula for creating indices? I need to compute series of numbers into a KPI that can be tracked over time. Example dataset is like this: A   B   C       D ----------------- 3   20  10000   ? 1   3   2000    ? 9   100 20000   ? 5   20  1000    ? I need to come up with a formula to distill A, B, C to D which is an index that indicates which row has the highest ""score"" based on following rules: Column A - Lower the better - 3rd most important factor Column B - Higher the better - 2nd most important factor Column C - Higher the better - 1st most important factor The problem I have is that how to come up with a proper weights in the formula so that it always follows the importance order.","Is there a ""proper"" formula for creating indices? I need to compute series of numbers into a KPI that can be tracked over time. Example dataset is like this: A   B   C       D ----------------- 3   20  10000   ? 1   3   2000    ? 9   100 20000   ? 5   20  1000    ? I need to come up with a formula to distill A, B, C to D which is an index that indicates which row has the highest ""score"" based on following rules: Column A - Lower the better - 3rd most important factor Column B - Higher the better - 2nd most important factor Column C - Higher the better - 1st most important factor The problem I have is that how to come up with a proper weights in the formula so that it always follows the importance order.",,"['statistics', 'economics']"
38,Statistical Data Reconstruction,Statistical Data Reconstruction,,"As I read an introductory statistics book, a question struck me which am curious to find a good answer for. Background The author teaches that statistical classification (understand this to mean organizing raw data into say classes -e.g by grouping the data into equal-sized categories, and assigning them frequencies, like what happens in preparation of a histogram) is a form of data compression. He further teaches that much as this compression approach aids in extraction and learning of the important information embedded in the data, he warns that certain approaches (e.g the use of the mode as a measure of central tendency) risk leaking away important information. Of significance, he states that the mean (a measure of central tendency) and variance (a measure of variation / dispersion) are most important. Problem Now, I wonder, assuming one was to follow this line of thinking, and given a data sample, proceeded to statistically-compress it (in the sense indicated above). What statistical compression mechanism is sufficient to be able to recover without any loss whatsoever, the original data? And assuming such a lossless recovery is not possible, how can one reconstruct the most statistically-close (a probably approximate ) approximation to the original data? Side-Note What compression information is sufficient to best reconstruct (or approximate) the original dataset: Only the mean and variance? Knowledge of the probability distribution of the mean and that of the variance? Or a smaller, but more representative sample of the original population? Or just the probability distribution of the data? Any other better mechanism? Illustration / Application / Clarification : Asume am given the following datasets (each line is a different dataset): 66, 66, 66, 67, 67, 67, 68, 69 52, 53, 61, 67, 71, 72, 78, 82 43, 44, 50, 54, 67, 90, 91, 97 Note that the mean for all three of the above samples is 67. Now, assume there was some statistical operation(s),$f$, such that applying it to any of the above samples would yield a (smaller) set of information,$s$, from which the original dataset could be reconstructed ( preferably without any loss -- but a probably approximate reconstruction is equally good for me). The problem in this case would be to find such a function $f$ that can yield the small set of information $s$, from which (via some reverse-transformation, $f'$), one can obtain the original data: $$f(Data) = s$$  such that  $$f'(s) = Data$$ And $f$ is an application of statistical methods.","As I read an introductory statistics book, a question struck me which am curious to find a good answer for. Background The author teaches that statistical classification (understand this to mean organizing raw data into say classes -e.g by grouping the data into equal-sized categories, and assigning them frequencies, like what happens in preparation of a histogram) is a form of data compression. He further teaches that much as this compression approach aids in extraction and learning of the important information embedded in the data, he warns that certain approaches (e.g the use of the mode as a measure of central tendency) risk leaking away important information. Of significance, he states that the mean (a measure of central tendency) and variance (a measure of variation / dispersion) are most important. Problem Now, I wonder, assuming one was to follow this line of thinking, and given a data sample, proceeded to statistically-compress it (in the sense indicated above). What statistical compression mechanism is sufficient to be able to recover without any loss whatsoever, the original data? And assuming such a lossless recovery is not possible, how can one reconstruct the most statistically-close (a probably approximate ) approximation to the original data? Side-Note What compression information is sufficient to best reconstruct (or approximate) the original dataset: Only the mean and variance? Knowledge of the probability distribution of the mean and that of the variance? Or a smaller, but more representative sample of the original population? Or just the probability distribution of the data? Any other better mechanism? Illustration / Application / Clarification : Asume am given the following datasets (each line is a different dataset): 66, 66, 66, 67, 67, 67, 68, 69 52, 53, 61, 67, 71, 72, 78, 82 43, 44, 50, 54, 67, 90, 91, 97 Note that the mean for all three of the above samples is 67. Now, assume there was some statistical operation(s),$f$, such that applying it to any of the above samples would yield a (smaller) set of information,$s$, from which the original dataset could be reconstructed ( preferably without any loss -- but a probably approximate reconstruction is equally good for me). The problem in this case would be to find such a function $f$ that can yield the small set of information $s$, from which (via some reverse-transformation, $f'$), one can obtain the original data: $$f(Data) = s$$  such that  $$f'(s) = Data$$ And $f$ is an application of statistical methods.",,['statistics']
39,Gaussian prior from feature to input space,Gaussian prior from feature to input space,,"if I have Gaussian prior ($\exp\left(\dfrac{-\sum_i w_i}{2\gamma^2}\right)$) on my weights in a linear classifier, how can I transform this so I can apply it for my kernel parameters $\alpha$? I have seen various papers mentioning this but I don't see how it's actually done. :/ Thanks!","if I have Gaussian prior ($\exp\left(\dfrac{-\sum_i w_i}{2\gamma^2}\right)$) on my weights in a linear classifier, how can I transform this so I can apply it for my kernel parameters $\alpha$? I have seen various papers mentioning this but I don't see how it's actually done. :/ Thanks!",,"['statistics', 'regression', 'machine-learning']"
40,What is the computational complexity of the EM algorithm?,What is the computational complexity of the EM algorithm?,,"In general, and more specifically for Bernoulli mixture model (aka Latent Class Analysis).","In general, and more specifically for Bernoulli mixture model (aka Latent Class Analysis).",,"['statistics', 'computational-complexity', 'machine-learning']"
41,Effective model for calculating momentum or growth rate for a time series,Effective model for calculating momentum or growth rate for a time series,,"I have a series of numbers tracking the performance of an entity on any given day.  It's nothing but a simple integer for each date.  For example, here's a series for Entity ""X"" 11/1/2012 - 11/30/2012 - 3000 (one month summary) 12/1/2012 - 123 12/2/2012 - 129 12/3/2012 - 131 12/4/2012 - 112 ... 12/31/2012 - 147 Ultimately I'm trying to output some form of momentum indicator for this entity for a day, week, and month.  My initial attempts were as follows: I could simply calculate the slope between two points.  For daily, I would compare day 1 versus day 2 and take the slope.  For weekly, the average count for week 1 and compare to average count for week 2, etc. Use a theoretical formula for detecting whether or not the count is ""breaking out"" of a local or global maxima (up) or minima (down) and assign a value based on the distance from the local or global maxima/minima.  Unfortunately I'm not sure how one would approach calculating this. An additional formula that determines whether or not the trend created in #2 is actually sustained. My question is this: in a very simple time series, is there a relatively straight-forward approach to coming up with a momentum indicator?  Obviously there are flaws with a simple equation but the more simple the better.  I can improve the equation over time. One assumption: There are no other variables to be taken into consideration aside from this number.  All other things are constant.","I have a series of numbers tracking the performance of an entity on any given day.  It's nothing but a simple integer for each date.  For example, here's a series for Entity ""X"" 11/1/2012 - 11/30/2012 - 3000 (one month summary) 12/1/2012 - 123 12/2/2012 - 129 12/3/2012 - 131 12/4/2012 - 112 ... 12/31/2012 - 147 Ultimately I'm trying to output some form of momentum indicator for this entity for a day, week, and month.  My initial attempts were as follows: I could simply calculate the slope between two points.  For daily, I would compare day 1 versus day 2 and take the slope.  For weekly, the average count for week 1 and compare to average count for week 2, etc. Use a theoretical formula for detecting whether or not the count is ""breaking out"" of a local or global maxima (up) or minima (down) and assign a value based on the distance from the local or global maxima/minima.  Unfortunately I'm not sure how one would approach calculating this. An additional formula that determines whether or not the trend created in #2 is actually sustained. My question is this: in a very simple time series, is there a relatively straight-forward approach to coming up with a momentum indicator?  Obviously there are flaws with a simple equation but the more simple the better.  I can improve the equation over time. One assumption: There are no other variables to be taken into consideration aside from this number.  All other things are constant.",,"['statistics', 'algorithms', 'regression']"
42,Distribution Probability Problem,Distribution Probability Problem,,"Let $X_1$ and $X_2$ denote the survival times of two computer components. Assume that $X_1, X_2 \sim \text{Exp}(1)$. Find the distribution of the total survival time of the two components ($T=X_1+X_2$) and the distribution of the ratio of the survival time of the first component and the total surviving time of the two components($R=X_1/(X_1+X_2)$) by deriving the joint pdf of $T$ and $R$ and integrating out $R$ and $T$ to the marginal pdfs of $T$ and $R$. Identify the two distributions. My professor told me the answer is $R \sim \text{Unit}[0,1]$ but it doesn't help me very much. Just shows me that I can't solve it. Any help would be greatly appreciated!","Let $X_1$ and $X_2$ denote the survival times of two computer components. Assume that $X_1, X_2 \sim \text{Exp}(1)$. Find the distribution of the total survival time of the two components ($T=X_1+X_2$) and the distribution of the ratio of the survival time of the first component and the total surviving time of the two components($R=X_1/(X_1+X_2)$) by deriving the joint pdf of $T$ and $R$ and integrating out $R$ and $T$ to the marginal pdfs of $T$ and $R$. Identify the two distributions. My professor told me the answer is $R \sim \text{Unit}[0,1]$ but it doesn't help me very much. Just shows me that I can't solve it. Any help would be greatly appreciated!",,"['probability', 'statistics', 'probability-theory']"
43,Probability of a matrix having determinant zero,Probability of a matrix having determinant zero,,What would be the probability of matrix having determinant zero out of all matrices with all entries being positive? How does one calculate such? Edit: Restriction to natural numbers and size of $n \times n$. Restriction to entries from 0 to 5 or from 0 to 10.,What would be the probability of matrix having determinant zero out of all matrices with all entries being positive? How does one calculate such? Edit: Restriction to natural numbers and size of $n \times n$. Restriction to entries from 0 to 5 or from 0 to 10.,,"['linear-algebra', 'matrices', 'statistics', 'probability-theory']"
44,Practice question...,Practice question...,,"Harvey the clumsy waiter is in trouble at work because he has been breaking too many dishes. Suppose that the number of dishes he breaks follows a Poisson distribution with a rate of 0.11 per hour. Harvey works an 8-hour shift today, and his boss has warned him that if he breaks any dishes during the shift, he will be red. What is the probability that Harvey will be red today? Wouldn't lambda be lambda*t = 0.11 x 8 = 0.88? Or did I get that twisted?","Harvey the clumsy waiter is in trouble at work because he has been breaking too many dishes. Suppose that the number of dishes he breaks follows a Poisson distribution with a rate of 0.11 per hour. Harvey works an 8-hour shift today, and his boss has warned him that if he breaks any dishes during the shift, he will be red. What is the probability that Harvey will be red today? Wouldn't lambda be lambda*t = 0.11 x 8 = 0.88? Or did I get that twisted?",,"['probability', 'statistics']"
45,Question Regarding Poisson and probability.,Question Regarding Poisson and probability.,,"i found this interesting question on the web but i am not quite sure if my solution is accurate. Honestly i would appreciate few opinions. Given Question: At a subway station, eastbound trains and northbound trains arrive   independently, both according to a Poisson process. On average, there   is one eastbound train every 12 minutes and one northbound train   every 8 minutes.   Suppose you arrive at the subway station at a certain point in time and   start observing trains. Question: Find the probability at most  2 trains to reach the station within the next 10 minutes. So my attempted solution is pretty straight forward: I have calculated the Probability for EastBound train and then the probability for NorthBound train.  So, where i am really stuck here is whether should i add those two probabilities or multiply them! For example i have calculated the probability for eastbound train as follows (in a very draft manner, please excuse me) $$\Bbb{P}_{east}= \big\{\Bbb{P}(N(10)=0)+\Bbb{P}(N(10)=1)+\Bbb{P}(N(10)=2)\big\}$$    . Thanks for the imput!","i found this interesting question on the web but i am not quite sure if my solution is accurate. Honestly i would appreciate few opinions. Given Question: At a subway station, eastbound trains and northbound trains arrive   independently, both according to a Poisson process. On average, there   is one eastbound train every 12 minutes and one northbound train   every 8 minutes.   Suppose you arrive at the subway station at a certain point in time and   start observing trains. Question: Find the probability at most  2 trains to reach the station within the next 10 minutes. So my attempted solution is pretty straight forward: I have calculated the Probability for EastBound train and then the probability for NorthBound train.  So, where i am really stuck here is whether should i add those two probabilities or multiply them! For example i have calculated the probability for eastbound train as follows (in a very draft manner, please excuse me) $$\Bbb{P}_{east}= \big\{\Bbb{P}(N(10)=0)+\Bbb{P}(N(10)=1)+\Bbb{P}(N(10)=2)\big\}$$    . Thanks for the imput!",,"['probability', 'statistics', 'stochastic-processes', 'stochastic-analysis']"
46,How to test null hypothesis for spatial distribution?,How to test null hypothesis for spatial distribution?,,"I am given a sample from a spatial distribution $X$. For example, my variable $X$ is the number of certain diseases per city per capita. Null hypothesis is that variable $X$ does not depend on the location directly (it might be dependent on another spatial distribution which is known say the amount of mercury in the water or other forms of pollution $Y$). How can I test this null hypothesis for a spatially distributed variable? What happens if I have very few samples? Say, for variable $x_1$ I have several million measurements but for variable $x_2$ I have 100 measurements? In case if I do not know $Y$, but I have other variables which I know are uniformly distributed ($X_i$ depends upon $Y$, but does not depends on location directly) how can I test null hypothesis? How can my test see the difference between cases A) when $X$ is a function of not only $Y$ everywhere B) $X$ is function of only $Y$ in some subregions, say the USA but it depends on other factors somewhere else?","I am given a sample from a spatial distribution $X$. For example, my variable $X$ is the number of certain diseases per city per capita. Null hypothesis is that variable $X$ does not depend on the location directly (it might be dependent on another spatial distribution which is known say the amount of mercury in the water or other forms of pollution $Y$). How can I test this null hypothesis for a spatially distributed variable? What happens if I have very few samples? Say, for variable $x_1$ I have several million measurements but for variable $x_2$ I have 100 measurements? In case if I do not know $Y$, but I have other variables which I know are uniformly distributed ($X_i$ depends upon $Y$, but does not depends on location directly) how can I test null hypothesis? How can my test see the difference between cases A) when $X$ is a function of not only $Y$ everywhere B) $X$ is function of only $Y$ in some subregions, say the USA but it depends on other factors somewhere else?",,['statistics']
47,Fisher Information and minimum variance estimators,Fisher Information and minimum variance estimators,,"I am trying to understand what can be proved about minimum variance estimators. I have changed the question to make it more specific. Let us assume we have some finite set $S$ of elements and we just want to estimate the cardinality $n$ of $S$. We know an upper bound $N$ for the cardinality. One method might be to sample with replacement and count the number of distinct elements and form one's estimate from this using the fact that $E(\text{number of distinct elements in sample})= n(1-(1-1/n)^x)$, where $x$ is the size of the sample. How do we compute the Fisher Information for this problem? Ultimately I would like to show a lower bound but this would be great first step.","I am trying to understand what can be proved about minimum variance estimators. I have changed the question to make it more specific. Let us assume we have some finite set $S$ of elements and we just want to estimate the cardinality $n$ of $S$. We know an upper bound $N$ for the cardinality. One method might be to sample with replacement and count the number of distinct elements and form one's estimate from this using the fact that $E(\text{number of distinct elements in sample})= n(1-(1-1/n)^x)$, where $x$ is the size of the sample. How do we compute the Fisher Information for this problem? Ultimately I would like to show a lower bound but this would be great first step.",,"['probability', 'statistics', 'parameter-estimation']"
48,Number of calls following a poisson distribution,Number of calls following a poisson distribution,,I'm new to statistics and having trouble with this question and was wondering if you guys could help me out. My question looks like this: The number of calls an officer receives during a working day is a Poisson(5) random variable. The officer misses a call with probability 0.01 independently from call to call. Find the probability that the officer answers exactly 10 calls in a working day. Thanks in advance!,I'm new to statistics and having trouble with this question and was wondering if you guys could help me out. My question looks like this: The number of calls an officer receives during a working day is a Poisson(5) random variable. The officer misses a call with probability 0.01 independently from call to call. Find the probability that the officer answers exactly 10 calls in a working day. Thanks in advance!,,"['probability', 'statistics']"
49,"Inverse Gaussian, Limiting Distributions","Inverse Gaussian, Limiting Distributions",,"I'm trying to understand the nature of limiting distributions and distributions, specifically $1/Z_n \longrightarrow ~?$ where $Z_n\longrightarrow Z -Gaussian(0,1)$ I understand that the gamma distribution converges to the gaussian for a large enough $n$, so would it be inverted gamma until the $n$ is sufficiently large? But the wikipedia article for Inverted Gamma and Inverse Gaussian are completely different, even though they're both written as $IG( ~, ~)$ But I also have the same distribution as Inverted Gamma with $\alpha,\beta$ as parameters Attempts:  Let $Y=1/N$ where $N=Gaussian(0,1)$ $F(Y)=P(Y<y)=P(1/N<y)=P(N>1/y)=1-F(1/y)$ But this gets me nothing that looks like what Wikipedia has http://en.wikipedia.org/wiki/Inverse_Gaussian_distribution","I'm trying to understand the nature of limiting distributions and distributions, specifically $1/Z_n \longrightarrow ~?$ where $Z_n\longrightarrow Z -Gaussian(0,1)$ I understand that the gamma distribution converges to the gaussian for a large enough $n$, so would it be inverted gamma until the $n$ is sufficiently large? But the wikipedia article for Inverted Gamma and Inverse Gaussian are completely different, even though they're both written as $IG( ~, ~)$ But I also have the same distribution as Inverted Gamma with $\alpha,\beta$ as parameters Attempts:  Let $Y=1/N$ where $N=Gaussian(0,1)$ $F(Y)=P(Y<y)=P(1/N<y)=P(N>1/y)=1-F(1/y)$ But this gets me nothing that looks like what Wikipedia has http://en.wikipedia.org/wiki/Inverse_Gaussian_distribution",,['statistics']
50,Diagnostic Tests and Expected Values,Diagnostic Tests and Expected Values,,"I have this question from my textbook I'm not sure how to answer. I got the first part but the second part is a bit confusing. It goes something like this: ""Two percent of the population has a certain condition for which there are two diagnostic tests. Test A which costs \$1 per person, gives positive results for 80% of persons with the condition and for 5% of persons without the condition. Test B, which costs $100 per person , gives positive results for all persons with the condition and negative results for all persons without it."" Suppose that 2000 persons are given test A, and then only those who test positive are given test B. Show that the expected cost is \$15,000 and the expected number of cases. I know the expected value of random variable X is defined as: $$E[X]=x_1p_1 + x_2p_2\dots+x_kp_k$$","I have this question from my textbook I'm not sure how to answer. I got the first part but the second part is a bit confusing. It goes something like this: ""Two percent of the population has a certain condition for which there are two diagnostic tests. Test A which costs \$1 per person, gives positive results for 80% of persons with the condition and for 5% of persons without the condition. Test B, which costs $100 per person , gives positive results for all persons with the condition and negative results for all persons without it."" Suppose that 2000 persons are given test A, and then only those who test positive are given test B. Show that the expected cost is \$15,000 and the expected number of cases. I know the expected value of random variable X is defined as: $$E[X]=x_1p_1 + x_2p_2\dots+x_kp_k$$",,"['probability', 'statistics']"
51,Which descriptive statistics are sufficient?,Which descriptive statistics are sufficient?,,"I was recently asked to choose from the basic set of descriptive statistics which ones are sufficient. Mean    Median    Mode    Standard deviation E. Variance    Range    IQR (or IR)    Skewness    Kurtosis This was a test question, and I guess I have the wrong idea about sufficiency because I was under the impression that it was on a per-distribution basis. Can someone explain to me how to generally classify statistics as sufficient or not, and why? I'll also add that I am very new to statistics, and the only explination of sufficiency offered is that a stat uses all available data. Thanks!","I was recently asked to choose from the basic set of descriptive statistics which ones are sufficient. Mean    Median    Mode    Standard deviation E. Variance    Range    IQR (or IR)    Skewness    Kurtosis This was a test question, and I guess I have the wrong idea about sufficiency because I was under the impression that it was on a per-distribution basis. Can someone explain to me how to generally classify statistics as sufficient or not, and why? I'll also add that I am very new to statistics, and the only explination of sufficiency offered is that a stat uses all available data. Thanks!",,['statistics']
52,Probability poser,Probability poser,,"We play a variation of 6 card brag but have a debate over the accurate ranking of the hands. 6 cards are dealt to each player. 2 hands of 3 cards must be made. Bearing in mind that each 3 card hand is derived from 6 cards, what is the correct ranking of hands using the traditional ideas of straight flush, straight, flush, three-of-a-kind, pair and high card? Thank you for your help.","We play a variation of 6 card brag but have a debate over the accurate ranking of the hands. 6 cards are dealt to each player. 2 hands of 3 cards must be made. Bearing in mind that each 3 card hand is derived from 6 cards, what is the correct ranking of hands using the traditional ideas of straight flush, straight, flush, three-of-a-kind, pair and high card? Thank you for your help.",,"['probability', 'statistics']"
53,Can a batsman's score be predicted in the sport of cricket?,Can a batsman's score be predicted in the sport of cricket?,,"I was browsing The Signal and the Noise in bookstore and chanced upon a chapter about predictions in baseball and found out about Moneyball and sabermetrics . I understand the closest to predicting a cricket match score comes via Duckworth-Lewis method and Jayadevan's system but going over these two following references: ( 1 ) ( 2 )  no work was found on an individual's innings . Probably this question is too soft for this site, but problem is I have basically no knowledge about statistics and I do not know what to search for to find out how bettors use algorithms to predict scores. Any help would be appreciated. Edit: Forgot to add this link which was a further inspiration for the question.","I was browsing The Signal and the Noise in bookstore and chanced upon a chapter about predictions in baseball and found out about Moneyball and sabermetrics . I understand the closest to predicting a cricket match score comes via Duckworth-Lewis method and Jayadevan's system but going over these two following references: ( 1 ) ( 2 )  no work was found on an individual's innings . Probably this question is too soft for this site, but problem is I have basically no knowledge about statistics and I do not know what to search for to find out how bettors use algorithms to predict scores. Any help would be appreciated. Edit: Forgot to add this link which was a further inspiration for the question.",,"['reference-request', 'statistics', 'soft-question']"
54,Bacteria Posson Distribution Problem,Bacteria Posson Distribution Problem,,"I'm having some difficulty two questions and was wondering if you could help me out. It goes something like this: a kind of bacteria is distributed in water according to a PPP (Poisson Point Process). It is known that the expected number of bacteria is 2 per liter. Samples of water are provided in bottles with volume 20 cc. If two bottles have altogether 10 bacteria, what is the probability that the one of them contains less than 3 bacteria? The second part of the question goes like this: Find the probability that a bottle with more than 2 bacteria in it has exactly 5 bacteria. Thanks in advance!","I'm having some difficulty two questions and was wondering if you could help me out. It goes something like this: a kind of bacteria is distributed in water according to a PPP (Poisson Point Process). It is known that the expected number of bacteria is 2 per liter. Samples of water are provided in bottles with volume 20 cc. If two bottles have altogether 10 bacteria, what is the probability that the one of them contains less than 3 bacteria? The second part of the question goes like this: Find the probability that a bottle with more than 2 bacteria in it has exactly 5 bacteria. Thanks in advance!",,"['probability', 'statistics']"
55,Skewness-adjusted t-statistic,Skewness-adjusted t-statistic,,"I've come across two different forms of a skewness-adjusted t-statistic, which was developed originally by Johnson (1978): $$ J = t + \frac{gt^2}{3n} + \frac{g}{6n} $$ and  $$ J = t + \frac{gt^2}{3\sqrt{n}} + \frac{g}{6\sqrt{n}}, $$ where $t$ is the conventional t-statistic, $n$ is the number of observations, and $g$ is the skewness estimate. The null hypothesis is zero mean. Could you advise me what's difference between the two forms? Many thanks, Dave","I've come across two different forms of a skewness-adjusted t-statistic, which was developed originally by Johnson (1978): $$ J = t + \frac{gt^2}{3n} + \frac{g}{6n} $$ and  $$ J = t + \frac{gt^2}{3\sqrt{n}} + \frac{g}{6\sqrt{n}}, $$ where $t$ is the conventional t-statistic, $n$ is the number of observations, and $g$ is the skewness estimate. The null hypothesis is zero mean. Could you advise me what's difference between the two forms? Many thanks, Dave",,['statistics']
56,Relation of mean of standard deviations and standard deviation,Relation of mean of standard deviations and standard deviation,,"Let $\{x_{i,j} : i=1..7,j=1,..n\}$ be a set of samples from $n$ weeks (where $i$ denotes the day of the week). Is there any interesting information to be gleaned from the relationship (ratio, difference, etc.) between $ \mathbb{E}_{i} [std(x_i)]$ and $std(x)$?","Let $\{x_{i,j} : i=1..7,j=1,..n\}$ be a set of samples from $n$ weeks (where $i$ denotes the day of the week). Is there any interesting information to be gleaned from the relationship (ratio, difference, etc.) between $ \mathbb{E}_{i} [std(x_i)]$ and $std(x)$?",,"['statistics', 'standard-deviation']"
57,How do I determine Heavy Tails on an empirical distribution?,How do I determine Heavy Tails on an empirical distribution?,,"How do you determine if an empirical distribution has a heavy tail?  What would I have to do in order to determine that? I'm currently using mathematica, so if you know of any coding, that would be very helpful. If not, then that's alright.","How do you determine if an empirical distribution has a heavy tail?  What would I have to do in order to determine that? I'm currently using mathematica, so if you know of any coding, that would be very helpful. If not, then that's alright.",,"['statistics', 'probability-distributions']"
58,Covariance matrix of a set of spherical coordinates,Covariance matrix of a set of spherical coordinates,,"How do I compute the covariance matrix of a set of spherical coordinates? I know that I can compute the mean of a set of spherical coordinates by transforming them to cartesian coordinates, compute the mean and then convert the mean value back to spherical. But how can I compute the covariance matrix correctly?","How do I compute the covariance matrix of a set of spherical coordinates? I know that I can compute the mean of a set of spherical coordinates by transforming them to cartesian coordinates, compute the mean and then convert the mean value back to spherical. But how can I compute the covariance matrix correctly?",,"['statistics', 'probability-distributions']"
59,Calculating a Poisson probability from the chacteristic function?,Calculating a Poisson probability from the chacteristic function?,,"In a previous homework assignment we were given a function that corresponds to an arbitrary angular distribution $A_{FB}=(F-B)/(F+B)=(F-B)/N$, where F = # of events in the forward hemisphere, B = # of events in the backward hemisphere and N = F + B = total # of events. We were told to assume F and B were two independent Poisson distributions, with the total # of events N given by F + B and hence N was variable (i.e. not fixed). $P_{A_{FB}}=P_{P}(F;v_{F})\cdot P_{P}(B;v_{B})=\frac{(v_{F})^{F}}{F!}e^{-v_{F}}\cdot\frac{(v_{B})^{B}}{B!}e^{-v_{B}}$ Now we want to use the characteristic function $\Phi_{n}(k;v_{n})=e^{-v_{n}(e^{ik}-1)}$ associated with the Poisson distribution to show that the total number of events N = F + B is also Poisson-distributed, (i.e. $P_{P}(N;v_{N})=\frac{(v_{N})^{N}}{N!}e^{-v_{N}}$ , with mean/expected number of events $v_{N}=v_{F}+v_{B}$ and variance $v_{N}=N=F+B$). My attempt at a solution: I know that the way this was expected to be solved was to leverage the fact that $\Phi_{N}(k;v_{n})=\Phi_{F+B}(k;v_{n})=\Phi_{F}(k;v_{F})\Phi_{B}(k;v_{B})$. We then determine:  $P_{P}(N;v_{N})=\sum_{k=0}^{\infty}e^{-ikN}\Phi_{F}(k;v_{F})\Phi_{B}(k;v_{B})= \sum_{k=0}^{\infty}e^{-ikF}\Phi_{F}(k;v_{F})e^{-ikB}\Phi_{B}(k;v_{B})=P_{P}(F;v_{F})\cdot P_{P}(B;v_{B})$ and monkey around with the algebra from there to prove the statement in the prompt. However, I wasted quite a bit of time trying to evaluate the infinite sum over k directly and prove it an alternate way: $P_{P}(N;v_{N})=\sum_{k=0}^{\infty}e^{-ikN}\Phi_{F}(k;v_{F})\Phi_{B}(k;v_{B}) =\sum_{k=0}^{\infty}e^{-ikN} e^{-(v_{F}+v_{B})(e^{ik}-1)}$. I tried to do this: ${e}^{(v_{F}+v_{B})}=\sum_{k=0}^{\infty}\frac{(v_{F}+v_{B})^{k}}{{k!}}$ and put this back into the expression like so:  $P_{P}(N;v_{N})=\sum_{k=0}^{\infty}\frac{(v_{F}+v_{B})^{k}}{{k!}}e^{-ikN}e^{-(v_{F}+v_{B})e^{ik}}$ But after this I could go no farther. Collecting these terms into something like $\frac{(expression)^{k}}{k!}$ to hopefully make it look like another exponent series expansion does not work because of the $e^{e^{ik}}$ term. -This is the first time I have ever seen any function that contains a double exponential. How does one usually deal with these? There seems to be no decent Taylor series representation, unless $e^{e^{x}}=\sum_{i=0}^{\infty}\frac{(e^{x})^{i}}{i!}$ but I am not sure is this is a useful sum or even allowed. -Is breaking down an exponent that does not depend on k (the index in the infinite sum) into an infinite series that does depend on k allowed, or do I have to use different indices, such as turning the exponential into an infinite sum over j? -How can I evaluate the probability I want by using Fourier inversion on the characteristic function with n=N and then solving the infinite sum over k? Every source I have looked up has not had a way to calculate a Poisson probability; it is usually given a priori. Any help?","In a previous homework assignment we were given a function that corresponds to an arbitrary angular distribution $A_{FB}=(F-B)/(F+B)=(F-B)/N$, where F = # of events in the forward hemisphere, B = # of events in the backward hemisphere and N = F + B = total # of events. We were told to assume F and B were two independent Poisson distributions, with the total # of events N given by F + B and hence N was variable (i.e. not fixed). $P_{A_{FB}}=P_{P}(F;v_{F})\cdot P_{P}(B;v_{B})=\frac{(v_{F})^{F}}{F!}e^{-v_{F}}\cdot\frac{(v_{B})^{B}}{B!}e^{-v_{B}}$ Now we want to use the characteristic function $\Phi_{n}(k;v_{n})=e^{-v_{n}(e^{ik}-1)}$ associated with the Poisson distribution to show that the total number of events N = F + B is also Poisson-distributed, (i.e. $P_{P}(N;v_{N})=\frac{(v_{N})^{N}}{N!}e^{-v_{N}}$ , with mean/expected number of events $v_{N}=v_{F}+v_{B}$ and variance $v_{N}=N=F+B$). My attempt at a solution: I know that the way this was expected to be solved was to leverage the fact that $\Phi_{N}(k;v_{n})=\Phi_{F+B}(k;v_{n})=\Phi_{F}(k;v_{F})\Phi_{B}(k;v_{B})$. We then determine:  $P_{P}(N;v_{N})=\sum_{k=0}^{\infty}e^{-ikN}\Phi_{F}(k;v_{F})\Phi_{B}(k;v_{B})= \sum_{k=0}^{\infty}e^{-ikF}\Phi_{F}(k;v_{F})e^{-ikB}\Phi_{B}(k;v_{B})=P_{P}(F;v_{F})\cdot P_{P}(B;v_{B})$ and monkey around with the algebra from there to prove the statement in the prompt. However, I wasted quite a bit of time trying to evaluate the infinite sum over k directly and prove it an alternate way: $P_{P}(N;v_{N})=\sum_{k=0}^{\infty}e^{-ikN}\Phi_{F}(k;v_{F})\Phi_{B}(k;v_{B}) =\sum_{k=0}^{\infty}e^{-ikN} e^{-(v_{F}+v_{B})(e^{ik}-1)}$. I tried to do this: ${e}^{(v_{F}+v_{B})}=\sum_{k=0}^{\infty}\frac{(v_{F}+v_{B})^{k}}{{k!}}$ and put this back into the expression like so:  $P_{P}(N;v_{N})=\sum_{k=0}^{\infty}\frac{(v_{F}+v_{B})^{k}}{{k!}}e^{-ikN}e^{-(v_{F}+v_{B})e^{ik}}$ But after this I could go no farther. Collecting these terms into something like $\frac{(expression)^{k}}{k!}$ to hopefully make it look like another exponent series expansion does not work because of the $e^{e^{ik}}$ term. -This is the first time I have ever seen any function that contains a double exponential. How does one usually deal with these? There seems to be no decent Taylor series representation, unless $e^{e^{x}}=\sum_{i=0}^{\infty}\frac{(e^{x})^{i}}{i!}$ but I am not sure is this is a useful sum or even allowed. -Is breaking down an exponent that does not depend on k (the index in the infinite sum) into an infinite series that does depend on k allowed, or do I have to use different indices, such as turning the exponential into an infinite sum over j? -How can I evaluate the probability I want by using Fourier inversion on the characteristic function with n=N and then solving the infinite sum over k? Every source I have looked up has not had a way to calculate a Poisson probability; it is usually given a priori. Any help?",,"['probability', 'statistics', 'fourier-analysis']"
60,conditional expectation and order statistic,conditional expectation and order statistic,,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space.Let $\ X=(X_1,..,X_n)$ a random vector, with$\ n$ independents random variables whose law is $\mu$ on $\mathbb{R}$. We define $T:\mathbb{R^n}\to\mathbb{R^n}$ such that $T(X_1,..,X_n)=(X_{(1)},..,X_{(n)})$ with  $X_{(k)}$ the k-th order statistic.Let $S_n$ set of all permutations $\sigma$ of set $ \left\{ 1,..,n \right\}$ and for any $f:\mathbb{R^n}\to\mathbb{R}$ we define $Sf(x_1...x_n)=\sum_{\sigma \in S^n}f(x_{\sigma(1)},..,x_{\sigma(n)})$. $\\$ Prove that: $\\$ $\mathbb{E}(f(X)|T(X))=S(f(X))$ a.s. and if $V(x_1,..,x_n)=(\sum_{i=1}^nx_i,\sum_{i<j;i,j=1}^nx_ix_j,....,x_1x_2..x_n)$ then conclude that $\mathbb{E}(f(X)|V(X))=S(f(X))$ a.s.","Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space.Let $\ X=(X_1,..,X_n)$ a random vector, with$\ n$ independents random variables whose law is $\mu$ on $\mathbb{R}$. We define $T:\mathbb{R^n}\to\mathbb{R^n}$ such that $T(X_1,..,X_n)=(X_{(1)},..,X_{(n)})$ with  $X_{(k)}$ the k-th order statistic.Let $S_n$ set of all permutations $\sigma$ of set $ \left\{ 1,..,n \right\}$ and for any $f:\mathbb{R^n}\to\mathbb{R}$ we define $Sf(x_1...x_n)=\sum_{\sigma \in S^n}f(x_{\sigma(1)},..,x_{\sigma(n)})$. $\\$ Prove that: $\\$ $\mathbb{E}(f(X)|T(X))=S(f(X))$ a.s. and if $V(x_1,..,x_n)=(\sum_{i=1}^nx_i,\sum_{i<j;i,j=1}^nx_ix_j,....,x_1x_2..x_n)$ then conclude that $\mathbb{E}(f(X)|V(X))=S(f(X))$ a.s.",,"['probability', 'statistics', 'measure-theory']"
61,Estimating the number of observations from a set of samples,Estimating the number of observations from a set of samples,,I repeatedly measure a value $S_n$ which is the sum of a set of $n$ hidden inputs.  The goal is to identify the number of hidden inputs. All of the hidden inputs are driven by an experimenter controlled stimulus.  The stimulus is quantal (consists of all or none events) but multiple events can occur in each input.  For each stimulus the probability density function of the input's activation level can be estimated.  The random result of this activation is then scaled by a variable input specific weight $w_n$ before being summed into $S_n$. If I use the central limit theorem then I can find $\sigma {\sqrt n}$ by a least squares curve fit of the sample's cumulative distribution to the standard normal cdf.  But I can't then solve for $n$ since the unknown set of $w_n$ makes $\sigma$ unknown. My current thought is to use the Berry-Esseen theorem to try and get another handle on $n$ based on the convergence rate to normality.  But I'm unsure how to proceed with the supremum in that function and would prefer to avoid the inequality (confidence intervals would be perfect). How would you proceed?,I repeatedly measure a value $S_n$ which is the sum of a set of $n$ hidden inputs.  The goal is to identify the number of hidden inputs. All of the hidden inputs are driven by an experimenter controlled stimulus.  The stimulus is quantal (consists of all or none events) but multiple events can occur in each input.  For each stimulus the probability density function of the input's activation level can be estimated.  The random result of this activation is then scaled by a variable input specific weight $w_n$ before being summed into $S_n$. If I use the central limit theorem then I can find $\sigma {\sqrt n}$ by a least squares curve fit of the sample's cumulative distribution to the standard normal cdf.  But I can't then solve for $n$ since the unknown set of $w_n$ makes $\sigma$ unknown. My current thought is to use the Berry-Esseen theorem to try and get another handle on $n$ based on the convergence rate to normality.  But I'm unsure how to proceed with the supremum in that function and would prefer to avoid the inequality (confidence intervals would be perfect). How would you proceed?,,"['probability', 'statistics', 'convergence-divergence', 'parameter-estimation', 'sampling']"
62,How do I find the mean with this exponential?,How do I find the mean with this exponential?,,"$$p(y) = \frac{c}{y^4}$$ I need to find the ""mean & variance"" of this exponential density function. Some pointers or thoughts that would explain would be most helpful. How relatively likely is it that $Y$ occurs in an interval about $y=2$_dy_ compared to $y=3$_dy_?","$$p(y) = \frac{c}{y^4}$$ I need to find the ""mean & variance"" of this exponential density function. Some pointers or thoughts that would explain would be most helpful. How relatively likely is it that $Y$ occurs in an interval about $y=2$_dy_ compared to $y=3$_dy_?",,"['statistics', 'exponential-function']"
63,Measuring Model Bias,Measuring Model Bias,,"If given the choice between two statistical models (for argument's sake, let's say Model 1 is $y = \beta_0 + \beta_1 x_1 + \epsilon$ and Model 2 is $y = \beta_0 + \beta_1 x^2_1 + \epsilon$), is there a way to select which model is more appropriate based upon an analysis of the residuals? Let's stipulate that the models have the same number of parameters, $k$, and that $SSE_{Model 1} = SSE_{Model 2}$.  The only difference is that residuals from Model 1 'appear' to be more systematic than those in Model 2.  That is, upon examining the residuals for Model 1 along the dimension $x$, it becomes clearly apparent that there are areas along $x$ where $Prob(\epsilon_i \ge 0 | x_i) > .5$ - and there are areas along $x$ where $Prob(\epsilon_j \ge 0 | x_j) < .5$. Since a test of just $SSE$ would rule that the two models are equivalent (as both models have the same overall error measurement) - and since the number of parameters, $k$, is the same for both models, the usual tests, Mallow's CP, Akaike's AIC & Schwarz's BIC wouldn't discriminate.  Yet, I can see with my eyes that one model has more (or at least a less-random pattern of) systematic error than the other. Yes, I know that this probably means that neither model is the 'correct' model, but I'm constrained to select between the given choices of models. I don't know of a test (other than just 'eyeballing' the residuals) that would allow me to decide between the alternatives. Is there a formal test, perhaps one based upon the pattern of residuals, that would allow me to discriminate?  I could see something that perhaps stepped through the various values of $x$ and tested as the null hypothesis that the residuals are such that $Prob(\epsilon_{segment} \ge 0|x_{segment}) = .5$. Perhaps the model where the cumulative stepwise test is most false would be the model that I should select against. Any ideas?","If given the choice between two statistical models (for argument's sake, let's say Model 1 is $y = \beta_0 + \beta_1 x_1 + \epsilon$ and Model 2 is $y = \beta_0 + \beta_1 x^2_1 + \epsilon$), is there a way to select which model is more appropriate based upon an analysis of the residuals? Let's stipulate that the models have the same number of parameters, $k$, and that $SSE_{Model 1} = SSE_{Model 2}$.  The only difference is that residuals from Model 1 'appear' to be more systematic than those in Model 2.  That is, upon examining the residuals for Model 1 along the dimension $x$, it becomes clearly apparent that there are areas along $x$ where $Prob(\epsilon_i \ge 0 | x_i) > .5$ - and there are areas along $x$ where $Prob(\epsilon_j \ge 0 | x_j) < .5$. Since a test of just $SSE$ would rule that the two models are equivalent (as both models have the same overall error measurement) - and since the number of parameters, $k$, is the same for both models, the usual tests, Mallow's CP, Akaike's AIC & Schwarz's BIC wouldn't discriminate.  Yet, I can see with my eyes that one model has more (or at least a less-random pattern of) systematic error than the other. Yes, I know that this probably means that neither model is the 'correct' model, but I'm constrained to select between the given choices of models. I don't know of a test (other than just 'eyeballing' the residuals) that would allow me to decide between the alternatives. Is there a formal test, perhaps one based upon the pattern of residuals, that would allow me to discriminate?  I could see something that perhaps stepped through the various values of $x$ and tested as the null hypothesis that the residuals are such that $Prob(\epsilon_{segment} \ge 0|x_{segment}) = .5$. Perhaps the model where the cumulative stepwise test is most false would be the model that I should select against. Any ideas?",,"['statistics', 'mathematical-modeling', 'mean-square-error']"
64,Probability / statistics calculation,Probability / statistics calculation,,"Lets say I have a series of 100 digits forming a number. 15 of those digits are always the same at the same place, 85 of those digits are randomly 1 to 5. I generate 10000 numbers this way. What would be the average lowest uniqueness of a random number compared to each other number where you start at 100% uniqueness and go -1% for each number that is the same on the same place. additional info with what I mean by average lowest uniqueness By lowest average uniqueness I mean, what would be the average uniqueness of all numbers compared to the one they have the most in common with. Kinda hard to explain example I generate 10.000 numbers with way, what would their average uniqueness be of those 10.000 numbers compared to the one they have to most in common with. So I take one number 1, find out it has the most in common with with number 7, being X% unique, now I do this for all numbers and then make an average of all those x% unique I get Real life application The real life application and reason why I ask is this. I write a 100 word text, and for each word I can find synonyms for I give them. for example : This is a {very,extremely} {difficult,complicated,hard} {question,equation}. Now when I generate 10000 texts based on this (with software) where it will each time take one of the options between brackets and put them online. Now google will try to see how unique my text is based on all the text that is online. I want for example to have my text be at least 60% unique compared to any text found online (only my text will really be a factor in this, seeing as I'm writing a 100 word text) I want to get an idea how many synonyms and text length I need to aim for given I want at least 60% uniqueness and I want to generate 5000, 10000 or even 20000 text. If I can get an idea how its calculated or what the value is for my example I can about guess how long and how many synonyms ill have to aim for in case I need 1000 5000 or even 20000 text generated.","Lets say I have a series of 100 digits forming a number. 15 of those digits are always the same at the same place, 85 of those digits are randomly 1 to 5. I generate 10000 numbers this way. What would be the average lowest uniqueness of a random number compared to each other number where you start at 100% uniqueness and go -1% for each number that is the same on the same place. additional info with what I mean by average lowest uniqueness By lowest average uniqueness I mean, what would be the average uniqueness of all numbers compared to the one they have the most in common with. Kinda hard to explain example I generate 10.000 numbers with way, what would their average uniqueness be of those 10.000 numbers compared to the one they have to most in common with. So I take one number 1, find out it has the most in common with with number 7, being X% unique, now I do this for all numbers and then make an average of all those x% unique I get Real life application The real life application and reason why I ask is this. I write a 100 word text, and for each word I can find synonyms for I give them. for example : This is a {very,extremely} {difficult,complicated,hard} {question,equation}. Now when I generate 10000 texts based on this (with software) where it will each time take one of the options between brackets and put them online. Now google will try to see how unique my text is based on all the text that is online. I want for example to have my text be at least 60% unique compared to any text found online (only my text will really be a factor in this, seeing as I'm writing a 100 word text) I want to get an idea how many synonyms and text length I need to aim for given I want at least 60% uniqueness and I want to generate 5000, 10000 or even 20000 text. If I can get an idea how its calculated or what the value is for my example I can about guess how long and how many synonyms ill have to aim for in case I need 1000 5000 or even 20000 text generated.",,"['probability', 'statistics']"
65,Consistent estimate using likelihood function,Consistent estimate using likelihood function,,"Let be $X$ a population with normal distribution. Using likelihood function I get the below expression  $\hat{\sigma_X}^2 = \sum_{i=1}^{n}{\dfrac{(X_i-\mu)^2}{n}}$ for variance. I want prove that expression is consistent, i.e. $E[\hat{\sigma_X}^2]=\sigma_X^2$. I begin ... $E[\hat{\sigma_X}^2]=\dfrac{1}{n}E[\sum_{i=1}^{n}{(X_i-\mu)^2}]$ $\dfrac{1}{n}(E[(X_1-\mu)^2]+E[(X_2-\mu)^2]\cdots E[(X_n-\mu)^2])$ I don't know what else to do. pdta: $\mu=\dfrac{1}{n}\sum_{i=0}^{n}{X_i}$","Let be $X$ a population with normal distribution. Using likelihood function I get the below expression  $\hat{\sigma_X}^2 = \sum_{i=1}^{n}{\dfrac{(X_i-\mu)^2}{n}}$ for variance. I want prove that expression is consistent, i.e. $E[\hat{\sigma_X}^2]=\sigma_X^2$. I begin ... $E[\hat{\sigma_X}^2]=\dfrac{1}{n}E[\sum_{i=1}^{n}{(X_i-\mu)^2}]$ $\dfrac{1}{n}(E[(X_1-\mu)^2]+E[(X_2-\mu)^2]\cdots E[(X_n-\mu)^2])$ I don't know what else to do. pdta: $\mu=\dfrac{1}{n}\sum_{i=0}^{n}{X_i}$",,['statistics']
66,proof using (fixed point theorem),proof using (fixed point theorem),,"I am seeking to solve for a Nash equilibrium in pure strategies $(d_2,d_2)$ involving two players, $1$ and $2$. Given that $h'(.)$ is s strictly decreasing and continuous function, $\Phi(d_1-d_2)$ denoting a convolution function, and $F(.)$ denoting a CDF, I want to prove for existence and uniqueness of equilibrium. My guess is that we we use a fixed point theorem to prove existence. The following is the first order condition for maximization. $$g_1(d_1) \equiv h'(d_1)-\gamma\Phi(d_1-d_2)-\eta(1-F(m-d_1))=0 \\ g_2(d_2)≡ h'(d_2)-\gamma[1-\Phi(d_1-d_2)]-\eta(1-F(m-d_2))=0 $$ Note that the parameters are all positive and $d_1$ & $d_2$ are continuous and $m$ is a constant.  I highly appreciate any suggestion towards the proof.","I am seeking to solve for a Nash equilibrium in pure strategies $(d_2,d_2)$ involving two players, $1$ and $2$. Given that $h'(.)$ is s strictly decreasing and continuous function, $\Phi(d_1-d_2)$ denoting a convolution function, and $F(.)$ denoting a CDF, I want to prove for existence and uniqueness of equilibrium. My guess is that we we use a fixed point theorem to prove existence. The following is the first order condition for maximization. $$g_1(d_1) \equiv h'(d_1)-\gamma\Phi(d_1-d_2)-\eta(1-F(m-d_1))=0 \\ g_2(d_2)≡ h'(d_2)-\gamma[1-\Phi(d_1-d_2)]-\eta(1-F(m-d_2))=0 $$ Note that the parameters are all positive and $d_1$ & $d_2$ are continuous and $m$ is a constant.  I highly appreciate any suggestion towards the proof.",,"['statistics', 'game-theory', 'economics']"
67,Relationship between Vapnik-Chervonenkis classes of sets and functions,Relationship between Vapnik-Chervonenkis classes of sets and functions,,"I'm reading van der Vaart's ""Asymptotic statistics"" and on page 275 the author introduces the concepts of Vapnik-Červonenkis (VC) classes of sets and functions and states a proposition which I can't prove. I'll write the definitions: A collection $\mathcal{C}$ of subsets of the set $\mathcal{X}$ is said to pick out a certain subset $A$ of the finite set $\{x_1,\ldots,x_n\}\subset\mathcal{X}$ if it can be written as $A=\{x_1,\ldots,x_n\}\cap C$ for some $C\in\mathcal{C}$. The collection $\mathcal{C}$ is said to shatter $\{x_1,\ldots,x_n\}$ if $\mathcal{C}$ picks out each of its $2^n$ subsets. The VC index $V(\mathcal{C})$ of $\mathcal{C}$ is the smallest $n$ for which no set of size $n$ is shattered by $\mathcal{C}$. A collection of sets is called a VC class if its VC index is finite. A collection of functions $\mathcal{F}:=\{f:\mathcal{X}\to\mathbb{R}\}$ is said to be a VC class of functions if the collection of all subgraphs $\{(x,t):f(x)<t\}$, if $f$ ranges over $\mathcal{F}$, forms a VC class of sets in $\mathcal{X}\times\mathbb{R}$. Then goes a proposition : A collection of sets $C$ is a VC class of sets if and only if the collection of corresponding indicator functions $1_C$ is a VC class of functions. It is said to be not difficult to see but I got stuck trying to prove it. Say $V(\mathcal{C})=n$. For $C\in\mathcal{C}$ denote $I_C:=\{(x,t)\subset\mathcal{X}\times\mathbb{R}:1_C(x)<t\}$ and $\mathcal{C}':=\{I_C:C\in\mathcal{C}\}$. My guess is that $V(\mathcal{C}')$ should also be $n$.","I'm reading van der Vaart's ""Asymptotic statistics"" and on page 275 the author introduces the concepts of Vapnik-Červonenkis (VC) classes of sets and functions and states a proposition which I can't prove. I'll write the definitions: A collection $\mathcal{C}$ of subsets of the set $\mathcal{X}$ is said to pick out a certain subset $A$ of the finite set $\{x_1,\ldots,x_n\}\subset\mathcal{X}$ if it can be written as $A=\{x_1,\ldots,x_n\}\cap C$ for some $C\in\mathcal{C}$. The collection $\mathcal{C}$ is said to shatter $\{x_1,\ldots,x_n\}$ if $\mathcal{C}$ picks out each of its $2^n$ subsets. The VC index $V(\mathcal{C})$ of $\mathcal{C}$ is the smallest $n$ for which no set of size $n$ is shattered by $\mathcal{C}$. A collection of sets is called a VC class if its VC index is finite. A collection of functions $\mathcal{F}:=\{f:\mathcal{X}\to\mathbb{R}\}$ is said to be a VC class of functions if the collection of all subgraphs $\{(x,t):f(x)<t\}$, if $f$ ranges over $\mathcal{F}$, forms a VC class of sets in $\mathcal{X}\times\mathbb{R}$. Then goes a proposition : A collection of sets $C$ is a VC class of sets if and only if the collection of corresponding indicator functions $1_C$ is a VC class of functions. It is said to be not difficult to see but I got stuck trying to prove it. Say $V(\mathcal{C})=n$. For $C\in\mathcal{C}$ denote $I_C:=\{(x,t)\subset\mathcal{X}\times\mathbb{R}:1_C(x)<t\}$ and $\mathcal{C}':=\{I_C:C\in\mathcal{C}\}$. My guess is that $V(\mathcal{C}')$ should also be $n$.",,"['combinatorics', 'statistics']"
68,sum with permutations,sum with permutations,,"Let $a$ be vector in $R^{2m}$. And let $S_{2m}$ be group of all permutations on the set $\{1,\dots,2m\}$. I would like to calculate  $$ \sup_{\pi\in S_{2m}}\sum_{d(\sigma, \pi)=2}\left(\left|\sum_{k=1}^ma_{\sigma(k)}-\sum_{k=m+1}^{2m}a_{\sigma(k)}\right|-\left|\sum_{k=1}^ma_{\pi(k)}-\sum_{k=m+1}^{2m}a_{\pi(k)}\right|\right)^2. $$ Here $\sigma(\cdot),\pi(\cdot)$ are a permutations on the set $\{1,...,2m\}$ with uniform distribution. Of course, I can open square: \begin{align} \sum_{d(\sigma, \pi)=2}\Big(\left|\sum_{k=1}^ma_{\sigma(k)}-\sum_{k=m+1}^{2m}a_{\sigma(k)}\right|^2&-2\left|\sum_{k=1}^ma_{\pi(k)}-\sum_{k=m+1}^{2m}a_{\pi(k)}\right|\left|\sum_{k=1}^ma_{\sigma(k)}-\sum_{k=m+1}^{2m}a_{\sigma(k)}\right|\\ &+\left|\sum_{k=1}^ma_{\pi(k)}-\sum_{k=m+1}^{2m}a_{\pi(k)}\right|^2\Big), \end{align} and now for the first and for the last terms $$ \left|\sum_{k=1}^ma_{\pi(k)}-\sum_{k=m+1}^{2m}a_{\pi(k)}\right|^2=\sum_{i=1}^{2m}a^2_{\pi_(i)}+2\sum_{i=1}^{2m}\sum_{i\neq k}a_{\pi(i)}a_{\pi(k)}-2\sum_{i=1}^{2m}\sum_{k=1}^{2m}a_{\pi(i)}a_{\pi(k)}. $$ But I don't know what to do with the second term of the sum and how to sum everything over $d(\pi, \sigma)$. Note here, $d(\sigma, \pi)=2$ means $\sigma=\pi \tau$, where $\tau$ is a transposition. Thank you for the help.","Let $a$ be vector in $R^{2m}$. And let $S_{2m}$ be group of all permutations on the set $\{1,\dots,2m\}$. I would like to calculate  $$ \sup_{\pi\in S_{2m}}\sum_{d(\sigma, \pi)=2}\left(\left|\sum_{k=1}^ma_{\sigma(k)}-\sum_{k=m+1}^{2m}a_{\sigma(k)}\right|-\left|\sum_{k=1}^ma_{\pi(k)}-\sum_{k=m+1}^{2m}a_{\pi(k)}\right|\right)^2. $$ Here $\sigma(\cdot),\pi(\cdot)$ are a permutations on the set $\{1,...,2m\}$ with uniform distribution. Of course, I can open square: \begin{align} \sum_{d(\sigma, \pi)=2}\Big(\left|\sum_{k=1}^ma_{\sigma(k)}-\sum_{k=m+1}^{2m}a_{\sigma(k)}\right|^2&-2\left|\sum_{k=1}^ma_{\pi(k)}-\sum_{k=m+1}^{2m}a_{\pi(k)}\right|\left|\sum_{k=1}^ma_{\sigma(k)}-\sum_{k=m+1}^{2m}a_{\sigma(k)}\right|\\ &+\left|\sum_{k=1}^ma_{\pi(k)}-\sum_{k=m+1}^{2m}a_{\pi(k)}\right|^2\Big), \end{align} and now for the first and for the last terms $$ \left|\sum_{k=1}^ma_{\pi(k)}-\sum_{k=m+1}^{2m}a_{\pi(k)}\right|^2=\sum_{i=1}^{2m}a^2_{\pi_(i)}+2\sum_{i=1}^{2m}\sum_{i\neq k}a_{\pi(i)}a_{\pi(k)}-2\sum_{i=1}^{2m}\sum_{k=1}^{2m}a_{\pi(i)}a_{\pi(k)}. $$ But I don't know what to do with the second term of the sum and how to sum everything over $d(\pi, \sigma)$. Note here, $d(\sigma, \pi)=2$ means $\sigma=\pi \tau$, where $\tau$ is a transposition. Thank you for the help.",,"['combinatorics', 'statistics', 'permutations', 'summation']"
69,A convex programming problem involving sum of logarithms of linear functions,A convex programming problem involving sum of logarithms of linear functions,,"Here is a convex programming problem I encountered while working on an estimation problem for a mixture of multinomial distributions. We have a matrix $A_{m \times n}$ containing non-negative real numbers. We seek to maximize $$ \sum_{i=1}^m \log (\sum_{j=1}^n a_{ij} \theta_j) $$ such that $$ \sum_{j=1}^n \theta_j = 1, \theta_j\geq 0 $$ I'm not sure if this has been studied extensively before, and I'd like to have some analytic results about this convex programming problem.","Here is a convex programming problem I encountered while working on an estimation problem for a mixture of multinomial distributions. We have a matrix $A_{m \times n}$ containing non-negative real numbers. We seek to maximize $$ \sum_{i=1}^m \log (\sum_{j=1}^n a_{ij} \theta_j) $$ such that $$ \sum_{j=1}^n \theta_j = 1, \theta_j\geq 0 $$ I'm not sure if this has been studied extensively before, and I'd like to have some analytic results about this convex programming problem.",,"['reference-request', 'statistics', 'optimization', 'convex-optimization', 'nonlinear-optimization']"
70,distribution of block occurrence of random vector in $\mathbb{Z}_2^n$,distribution of block occurrence of random vector in,\mathbb{Z}_2^n,"Given natural numbers $m, n \geq 2$ and a random vector $\mathbf{r}= (a_1,a_2,\cdots,a_n)\in\mathbb{Z}_2^n$. We define the $m$-circulant of $\mathbf{r}$ by the vector $$\overline{\mathbf{r}}_m=(a_1,a_2,\cdots,a_n,a_1,a_2,\cdots,a_{m-1})$$ Suppose we divide $\overline{\mathbf{r}}_n$ into $n$ overlapping blocks as follows $$\mathbf{b}_1=(a_1,\cdots,a_m),\quad \mathbf{b}_2=(a_2,\cdots,a_{m+1}),\quad \cdots \quad \mathbf{b}_{n}=(a_n,\cdots,a_{m-1})$$ For any $\mathbf{u}\in \mathbb{Z}_2^m$ define the random variable $$v_{\mathbf{u}}:=\text{the number of block $\mathbf{b}_j$ such that $\mathbf{b}_j=\mathbf{u}$}$$ Therefore there are exactly $2^m$ random variables and each of them depends on $n$, so we give the following index for each of them: $$v_1^{(n)},v_2^{(n)},\cdots,v_{2^m}^{(n)}$$ We can prove that $v_1^{(n)} \sim b\left(n,\frac{1}{2^m}\right)$ (binomial distribution). Define the $2^m \times 1$ random variable vector $\mathbf{Z}_n:=(Z_1^{(n)},\cdots,Z_{2^m}^{(n)})^T$, where $Z_i^{(n)}:=\frac{1}{\sqrt{n}}\left(v_i^{(n)}-\frac{n}{2^m}\right)$ Could we prove that for sufficiently large $n$, $\mathbf{Z}_n$ is asymtotically multivariate normal distribution? Edit [comment truncated]: My indication for the non-overlapping case: Define the indicator $$X_{\mathbf{u}j}:=1 \quad \text{if $\mathbf{u}=\mathbf{b}_j$ }$$ and equals $0$ otherwise.    $$v_{\mathbf{u}}=\sum_{j=1}^n X_{\mathbf{u}j},$$ where all   $X_{\mathbf{u}j}$ have bernoulli distribution with $p=\frac{1}{2^m}$.   We reindex the $X's$, where $X_{ij}^{(n)}$ is associated to   $v_i^{(n)}$ (as $X_{\mathbf{u}j}$ is associated to   $v_{\mathbf{u}}=v_i^{(n)}$) If we define $2^m \times 1$ vectors  $\mathbf{X}_j=\left(X_{1j} , \cdots, X_{2^m j}\right)^T$, then by the mean of bernoulli   distribution we have   $\mu=E[X_j]=\left(\frac{1}{2^m},\cdots,\frac{1}{2^m}\right)^T$ and so $$\mathbf{Z}_n=\frac{1}{\sqrt{n}} \sum_{j=1}^n [\mathbf{X}_j-E(\mathbf{X}_j)] = \sqrt{n} (\overline{X}_n -\mu)$$ for non-overlapping case, by the Central Limit Theorem, since each   $\mathbf{X}_j$ is independent, then we get the result. But clearly   they're not on my case. thanks.","Given natural numbers $m, n \geq 2$ and a random vector $\mathbf{r}= (a_1,a_2,\cdots,a_n)\in\mathbb{Z}_2^n$. We define the $m$-circulant of $\mathbf{r}$ by the vector $$\overline{\mathbf{r}}_m=(a_1,a_2,\cdots,a_n,a_1,a_2,\cdots,a_{m-1})$$ Suppose we divide $\overline{\mathbf{r}}_n$ into $n$ overlapping blocks as follows $$\mathbf{b}_1=(a_1,\cdots,a_m),\quad \mathbf{b}_2=(a_2,\cdots,a_{m+1}),\quad \cdots \quad \mathbf{b}_{n}=(a_n,\cdots,a_{m-1})$$ For any $\mathbf{u}\in \mathbb{Z}_2^m$ define the random variable $$v_{\mathbf{u}}:=\text{the number of block $\mathbf{b}_j$ such that $\mathbf{b}_j=\mathbf{u}$}$$ Therefore there are exactly $2^m$ random variables and each of them depends on $n$, so we give the following index for each of them: $$v_1^{(n)},v_2^{(n)},\cdots,v_{2^m}^{(n)}$$ We can prove that $v_1^{(n)} \sim b\left(n,\frac{1}{2^m}\right)$ (binomial distribution). Define the $2^m \times 1$ random variable vector $\mathbf{Z}_n:=(Z_1^{(n)},\cdots,Z_{2^m}^{(n)})^T$, where $Z_i^{(n)}:=\frac{1}{\sqrt{n}}\left(v_i^{(n)}-\frac{n}{2^m}\right)$ Could we prove that for sufficiently large $n$, $\mathbf{Z}_n$ is asymtotically multivariate normal distribution? Edit [comment truncated]: My indication for the non-overlapping case: Define the indicator $$X_{\mathbf{u}j}:=1 \quad \text{if $\mathbf{u}=\mathbf{b}_j$ }$$ and equals $0$ otherwise.    $$v_{\mathbf{u}}=\sum_{j=1}^n X_{\mathbf{u}j},$$ where all   $X_{\mathbf{u}j}$ have bernoulli distribution with $p=\frac{1}{2^m}$.   We reindex the $X's$, where $X_{ij}^{(n)}$ is associated to   $v_i^{(n)}$ (as $X_{\mathbf{u}j}$ is associated to   $v_{\mathbf{u}}=v_i^{(n)}$) If we define $2^m \times 1$ vectors  $\mathbf{X}_j=\left(X_{1j} , \cdots, X_{2^m j}\right)^T$, then by the mean of bernoulli   distribution we have   $\mu=E[X_j]=\left(\frac{1}{2^m},\cdots,\frac{1}{2^m}\right)^T$ and so $$\mathbf{Z}_n=\frac{1}{\sqrt{n}} \sum_{j=1}^n [\mathbf{X}_j-E(\mathbf{X}_j)] = \sqrt{n} (\overline{X}_n -\mu)$$ for non-overlapping case, by the Central Limit Theorem, since each   $\mathbf{X}_j$ is independent, then we get the result. But clearly   they're not on my case. thanks.",,"['statistics', 'normal-distribution']"
71,Example questions for bias/consistent estimators.,Example questions for bias/consistent estimators.,,"Now, I know how to do this particular one, but I was wondering if anyone had a place to get questions similar to this? I've tried googling, but have not come up with anything. Consider the regression model: $y=Bx + u$, where $\mathbb{E}(u)=0$, $\mathbb{Var}(u)=\sigma^2$. Is the following estimator an asymptotically unbiased estimator for $B$? $$    \mathbb{E}(B) = \frac{\mathbb{Var}(n u)}{\sigma^2 n} $$ Many thanks.","Now, I know how to do this particular one, but I was wondering if anyone had a place to get questions similar to this? I've tried googling, but have not come up with anything. Consider the regression model: $y=Bx + u$, where $\mathbb{E}(u)=0$, $\mathbb{Var}(u)=\sigma^2$. Is the following estimator an asymptotically unbiased estimator for $B$? $$    \mathbb{E}(B) = \frac{\mathbb{Var}(n u)}{\sigma^2 n} $$ Many thanks.",,['statistics']
72,Poisson Distribution,Poisson Distribution,,"I've a question here that I may possibly help with: ""Suppose that the number X of errors in an assignment submitted by each student in a certain group is a random variable that has a Poisson Distrubition with parameter Lambda = 4. Suppose also that all the assignments submitted are independent of one another. (a) What is the probability that a given submitted assignment contains no errors? (b) What is the probability that, among 10 assignments submitted, there are at least two that contain no errors? Now, our lecturer gave us the answer which is: Answer: Let Y = Number of assignments among the 10 submitted that contain no errors. Then Y has a binomial distribution with parameters n = 10 and p = P[X=0]. However, I would like to elaborate on this answer. Is this approach correct? Answer for (a): Let k = 0 and Lambda = 4 in our Poisson formula, yielding e^-4 (which I think is the probability that a given assignment contains no errors). for (b): Use the Binomial pmf (in the context mentioned above), with n=10, p=e^-4, 1-p = 1-e^-4 and compute the probabilities for k = 0 and 1 respectively. (i.e. No assignments are free of errors, only one assignment is free of errors) I obtained P(k=0) as 0.831225... and P(k=1) as 0.155085... Adding these two together should yield 0.98631.., now subtract this from one to find the probability of at least two assignments with no errors as 0.01369. Thank you. Just to clarify, this is not homework; it's just important I get the method right.","I've a question here that I may possibly help with: ""Suppose that the number X of errors in an assignment submitted by each student in a certain group is a random variable that has a Poisson Distrubition with parameter Lambda = 4. Suppose also that all the assignments submitted are independent of one another. (a) What is the probability that a given submitted assignment contains no errors? (b) What is the probability that, among 10 assignments submitted, there are at least two that contain no errors? Now, our lecturer gave us the answer which is: Answer: Let Y = Number of assignments among the 10 submitted that contain no errors. Then Y has a binomial distribution with parameters n = 10 and p = P[X=0]. However, I would like to elaborate on this answer. Is this approach correct? Answer for (a): Let k = 0 and Lambda = 4 in our Poisson formula, yielding e^-4 (which I think is the probability that a given assignment contains no errors). for (b): Use the Binomial pmf (in the context mentioned above), with n=10, p=e^-4, 1-p = 1-e^-4 and compute the probabilities for k = 0 and 1 respectively. (i.e. No assignments are free of errors, only one assignment is free of errors) I obtained P(k=0) as 0.831225... and P(k=1) as 0.155085... Adding these two together should yield 0.98631.., now subtract this from one to find the probability of at least two assignments with no errors as 0.01369. Thank you. Just to clarify, this is not homework; it's just important I get the method right.",,[]
73,Multiple linear regression with interaction,Multiple linear regression with interaction,,"I'm doing a multiple linear regression with interacting variables. I'll give you an example: $y$=value, $x_1$=material, $x_2$=weight, $x_3$=color $x_1$ and $x_2$ are interacting variables but $x_3$ is not. Right now I'm using something like: $$ y = a_0 + a_1x_1 + a_2x_2 + a_3x_3 + a_{12}x_1x_2 + u $$ I'm pretty new to regression analysis so I wonder if there is any way to convert this formula to something like  $$ y = a_0 + a_1x_1 + a_2x_2 + a_3x_3 + u $$ so I can see how much effect $x_1$ and $x_2$ have simply by looking at $a_1$ and $a_2$? What I want to do is to just be able to look at the equation and understand how much 1 kg of extra weight adds in value without needing to calculate y. Splitting up the interaction term $a_{12}$ and distributing the effect over $a_1$ and $a_2$ if you guys understand what I mean. Maybe it's not possible or maybe there is a better regression method that is more suited for this, I don't know. I'd love to get some pointers from you guys. Thanks.","I'm doing a multiple linear regression with interacting variables. I'll give you an example: $y$=value, $x_1$=material, $x_2$=weight, $x_3$=color $x_1$ and $x_2$ are interacting variables but $x_3$ is not. Right now I'm using something like: $$ y = a_0 + a_1x_1 + a_2x_2 + a_3x_3 + a_{12}x_1x_2 + u $$ I'm pretty new to regression analysis so I wonder if there is any way to convert this formula to something like  $$ y = a_0 + a_1x_1 + a_2x_2 + a_3x_3 + u $$ so I can see how much effect $x_1$ and $x_2$ have simply by looking at $a_1$ and $a_2$? What I want to do is to just be able to look at the equation and understand how much 1 kg of extra weight adds in value without needing to calculate y. Splitting up the interaction term $a_{12}$ and distributing the effect over $a_1$ and $a_2$ if you guys understand what I mean. Maybe it's not possible or maybe there is a better regression method that is more suited for this, I don't know. I'd love to get some pointers from you guys. Thanks.",,"['statistics', 'regression']"
74,Statistical Methods: Analysis of Normal Measurements,Statistical Methods: Analysis of Normal Measurements,,"Show that, if $\sigma$ is unknown, the likelihood ratio statistic for testing a value of $\alpha$ is given by $$D = n \log\left(1 + \frac{1}{n-1}T^2\right)\;,$$ where $$T = \frac{\hat{α} -\alpha}{\sqrt{s^2/n}}$$ So far, I have the following: $\hat\alpha=\overline{y}$ and $\hat\sigma=\sqrt{\frac{\sum \left ( y_i-\bar{y} \right )^2}{n-1}}$. Now, when I plug this in to my ratio, I have: $$D=2\left [ l(\hat{\mu}, \hat{\sigma})-l(\mu_0,\hat{\sigma}) \right ]=\frac{n(\bar{y}-\mu_0)^2}{\hat{\sigma}}=\frac{(\bar{y}-\mu_0)^2}{c\hat{\sigma}}\text{ where }c=\frac{1}{n}$$ So, just to clarify the following things: I accidentally typed $n-1$. I meant $n$ in the denominator for $\sigma$. My log-likelihood function is: $l(\mu, \sigma)=-n\log(\sigma)-\frac{\sum{(y_i-\bar{y})^2}}{2\sigma^2}$ When I expand my ratio statistic and simplify, the logs cancel because they are identical, and I am left with the equivalent expression of $T^2$. I don't understand how I am supposed to get the expression that I am asked for. Any ideas of what I am doing wrong?","Show that, if $\sigma$ is unknown, the likelihood ratio statistic for testing a value of $\alpha$ is given by $$D = n \log\left(1 + \frac{1}{n-1}T^2\right)\;,$$ where $$T = \frac{\hat{α} -\alpha}{\sqrt{s^2/n}}$$ So far, I have the following: $\hat\alpha=\overline{y}$ and $\hat\sigma=\sqrt{\frac{\sum \left ( y_i-\bar{y} \right )^2}{n-1}}$. Now, when I plug this in to my ratio, I have: $$D=2\left [ l(\hat{\mu}, \hat{\sigma})-l(\mu_0,\hat{\sigma}) \right ]=\frac{n(\bar{y}-\mu_0)^2}{\hat{\sigma}}=\frac{(\bar{y}-\mu_0)^2}{c\hat{\sigma}}\text{ where }c=\frac{1}{n}$$ So, just to clarify the following things: I accidentally typed $n-1$. I meant $n$ in the denominator for $\sigma$. My log-likelihood function is: $l(\mu, \sigma)=-n\log(\sigma)-\frac{\sum{(y_i-\bar{y})^2}}{2\sigma^2}$ When I expand my ratio statistic and simplify, the logs cancel because they are identical, and I am left with the equivalent expression of $T^2$. I don't understand how I am supposed to get the expression that I am asked for. Any ideas of what I am doing wrong?",,['statistics']
75,Designing an efficient sampling strategy,Designing an efficient sampling strategy,,"In a Monte Carlo simulation, my goal is to compute an estimate of the mean of a distribution via sampling. Traditional, straightforward statistics generates samples (via simulation) and computes the mean and variance of the samples, and uses the variance estimate divided by $n$ as an error estimate on the mean.  This all works and produces the desired estimate with error bounds on that estimate. But I know a little more about my problem. Abstracting the details, my simulation is actually picking samples from multiple independent distributions, each with a different probability of being picked.   Think of my sample as having two (or more) urns, each filled with its own distribution of values. Their means and distributions may be the same or completely different... I don't know, and that's why I'm sampling.  But I also don't care about the mean of each urn; at the end I only care about some weighted combination of their means. I can achieve the sampling easily by picking my samples randomly from one urn or the other with the appropriate weight, then computing the mean and variance of the final samples.  This all certainly works. But this is also throwing away a lot of information which may improve my estimates... I have this known stratification in my problem, and the random sampling is throwing that potential information away.  What if the urns have differing variances, and after pulling 100 samples from each, I can see one urn's variance is much higher than the others? Then I should start taking more samples from the high variance urn (and compensating by reducing the weight of each one of those samples.)  But that decision on the variance is in itself sampled, so I shouldn't trust it! In the worst case, I could take two samples and they happen to be identical, my variance estimate for that urn is 0.. but that doesn't mean I should trust that estimate and ignore the urn from now on! So my question is given  multiple distributions $D_i$ with unknown mean and variance each,  and a known set of weights $\alpha_i$, I want to sample values from these $D$ to efficiently form an unbiased estimate of $\sum \alpha_i \bar{D}_i$. In my problem, I'll typically sample 10,000 to 50,000 times, and I may have between 2 and 10,000 sub-distributions.  This may affect strategy, since I sometimes have so many distributions I can't even afford one sample for every one of them.. some have to be skipped! My current plan will work but it feels ad-hoc. I'll first take say 1000 samples from the distributions, where the number of samples for distribution $D_i$ is proportional to $\alpha_i$.  I'll then compute the estimated variance for each $D_i$ and continue sampling, this time with samples apprortioned proportionally to the measured variance of each $D$.   I think this will work pretty well, but it's not necessarily the most efficient.  And what happens if I have an $\alpha_i$ that's so small that I don't give many (or any) initial samples to the distribution? Should I start combining disparate low-$\alpha$ distributions into one so that they have a better chance of being sampled? My entire goal is to minimize the number of samples needed, but the strategy to apportion them is far from obvious.  Any thoughts or suggestions are welcome!","In a Monte Carlo simulation, my goal is to compute an estimate of the mean of a distribution via sampling. Traditional, straightforward statistics generates samples (via simulation) and computes the mean and variance of the samples, and uses the variance estimate divided by $n$ as an error estimate on the mean.  This all works and produces the desired estimate with error bounds on that estimate. But I know a little more about my problem. Abstracting the details, my simulation is actually picking samples from multiple independent distributions, each with a different probability of being picked.   Think of my sample as having two (or more) urns, each filled with its own distribution of values. Their means and distributions may be the same or completely different... I don't know, and that's why I'm sampling.  But I also don't care about the mean of each urn; at the end I only care about some weighted combination of their means. I can achieve the sampling easily by picking my samples randomly from one urn or the other with the appropriate weight, then computing the mean and variance of the final samples.  This all certainly works. But this is also throwing away a lot of information which may improve my estimates... I have this known stratification in my problem, and the random sampling is throwing that potential information away.  What if the urns have differing variances, and after pulling 100 samples from each, I can see one urn's variance is much higher than the others? Then I should start taking more samples from the high variance urn (and compensating by reducing the weight of each one of those samples.)  But that decision on the variance is in itself sampled, so I shouldn't trust it! In the worst case, I could take two samples and they happen to be identical, my variance estimate for that urn is 0.. but that doesn't mean I should trust that estimate and ignore the urn from now on! So my question is given  multiple distributions $D_i$ with unknown mean and variance each,  and a known set of weights $\alpha_i$, I want to sample values from these $D$ to efficiently form an unbiased estimate of $\sum \alpha_i \bar{D}_i$. In my problem, I'll typically sample 10,000 to 50,000 times, and I may have between 2 and 10,000 sub-distributions.  This may affect strategy, since I sometimes have so many distributions I can't even afford one sample for every one of them.. some have to be skipped! My current plan will work but it feels ad-hoc. I'll first take say 1000 samples from the distributions, where the number of samples for distribution $D_i$ is proportional to $\alpha_i$.  I'll then compute the estimated variance for each $D_i$ and continue sampling, this time with samples apprortioned proportionally to the measured variance of each $D$.   I think this will work pretty well, but it's not necessarily the most efficient.  And what happens if I have an $\alpha_i$ that's so small that I don't give many (or any) initial samples to the distribution? Should I start combining disparate low-$\alpha$ distributions into one so that they have a better chance of being sampled? My entire goal is to minimize the number of samples needed, but the strategy to apportion them is far from obvious.  Any thoughts or suggestions are welcome!",,"['probability', 'statistics', 'monte-carlo', 'sampling']"
76,Standard practice for identifying outlying spend amounts,Standard practice for identifying outlying spend amounts,,"Hope this is mathematical enough to qualify as a question - I'm no mathematician! I have a set of individuals travel & entertainment credit card spend, and I'd like to highlight any outliers that are worth scrutinizing further.  The type of info I have available are things like transaction date, category, dollar amount, the merchant's name, the user's description of the purchase, the person's manager, whether it was card or 'cash claim', comment text relating to the item, etc. My initial simple idea was to look at the average and stddev for each category (eg a 500 dollar plane fare is not unusual but a 500 dollar cab fare is), and report those above x standard deviations.  Or, divide them into deciles and report only the top ones. Is there any standard practice around using one of these methods, or a totally different one to do it? If anyone has any comments around possible other 'clever' ways to identify unusual or fraudulent transactions I'd appreciate it - eg clustering, frequency analysis, neural nets etc.  I will probably ask a separate question relating to applying benford's law to this type of data also. Many thanks! PS.  It's probably worth mentioning I have $60-100M worth of transactions, spanning 4 years across several thousand people in total.  So it should be enough records to do something interesting with!","Hope this is mathematical enough to qualify as a question - I'm no mathematician! I have a set of individuals travel & entertainment credit card spend, and I'd like to highlight any outliers that are worth scrutinizing further.  The type of info I have available are things like transaction date, category, dollar amount, the merchant's name, the user's description of the purchase, the person's manager, whether it was card or 'cash claim', comment text relating to the item, etc. My initial simple idea was to look at the average and stddev for each category (eg a 500 dollar plane fare is not unusual but a 500 dollar cab fare is), and report those above x standard deviations.  Or, divide them into deciles and report only the top ones. Is there any standard practice around using one of these methods, or a totally different one to do it? If anyone has any comments around possible other 'clever' ways to identify unusual or fraudulent transactions I'd appreciate it - eg clustering, frequency analysis, neural nets etc.  I will probably ask a separate question relating to applying benford's law to this type of data also. Many thanks! PS.  It's probably worth mentioning I have $60-100M worth of transactions, spanning 4 years across several thousand people in total.  So it should be enough records to do something interesting with!",,"['statistics', 'finance']"
77,Geometric interpretation of element by element division of one vector by another,Geometric interpretation of element by element division of one vector by another,,"This is my first post here, and I'm not a mathematician, so please go easy on me :) In statistics there is a geometric interpretation of correlation that uses basic vector geometry. This is fairly straight forward, even for me: each of two vectors of data are transformed so that the length of each new vector is equal to the standard deviation of the elements in the original vector. The i'th element of the new vector x is then: $x[i]=(X[i]-mean(X))/\sqrt{n-1}$ , where n is the number of elements in the vector and X is the original data vector. Then, the correlation between the two original vectors of data is then simply the cosine of the angle between the two transformed vectors. Neat ! Now, the really interesting (for me) thing is that if we have 3 independent vectors of data generated from the same probability distribution, let's call them X Y and Z, so the correlation between any 2 of them is close to zero, then the correlation between X/Z and Y/Z is usually close to 0.5-0.6, where X/Z is the element by element division of X by Z. I say ""usually"" because there are certain provisions, such that the data come from a probability distribution where near-zero values are impossible or highly unlikely (and some others which I won't go into here). So you are probably wondering why I am posting this here and not on stats.se. Well, that's because I'm trying to get a handle on the geometric interpretation of this, and in particular, the geometric interpretation of dividing one vector by another, element by element, and I guess this is more of a maths concept. EDIT/UPDATE: I was informed (in the real world) that it is not correct to try to interpret this element-by-element division of one vector by another geometrically. Instead, we should first take the natural log of the original data vectors (this is justified since the data are physical measurements), transform them as above, and then interpret the vectors $\ln (x)-\ln (z)$ and $\ln (y)-\ln (z)$ geometrically. Apparently ""it follows"" that the angle between them will be $\pi /3 $ giving the required correlation of 0.5. Unfortunately it didn't ""follow"" for me ! Could anyone help explain ? Thanks for reading.","This is my first post here, and I'm not a mathematician, so please go easy on me :) In statistics there is a geometric interpretation of correlation that uses basic vector geometry. This is fairly straight forward, even for me: each of two vectors of data are transformed so that the length of each new vector is equal to the standard deviation of the elements in the original vector. The i'th element of the new vector x is then: $x[i]=(X[i]-mean(X))/\sqrt{n-1}$ , where n is the number of elements in the vector and X is the original data vector. Then, the correlation between the two original vectors of data is then simply the cosine of the angle between the two transformed vectors. Neat ! Now, the really interesting (for me) thing is that if we have 3 independent vectors of data generated from the same probability distribution, let's call them X Y and Z, so the correlation between any 2 of them is close to zero, then the correlation between X/Z and Y/Z is usually close to 0.5-0.6, where X/Z is the element by element division of X by Z. I say ""usually"" because there are certain provisions, such that the data come from a probability distribution where near-zero values are impossible or highly unlikely (and some others which I won't go into here). So you are probably wondering why I am posting this here and not on stats.se. Well, that's because I'm trying to get a handle on the geometric interpretation of this, and in particular, the geometric interpretation of dividing one vector by another, element by element, and I guess this is more of a maths concept. EDIT/UPDATE: I was informed (in the real world) that it is not correct to try to interpret this element-by-element division of one vector by another geometrically. Instead, we should first take the natural log of the original data vectors (this is justified since the data are physical measurements), transform them as above, and then interpret the vectors $\ln (x)-\ln (z)$ and $\ln (y)-\ln (z)$ geometrically. Apparently ""it follows"" that the angle between them will be $\pi /3 $ giving the required correlation of 0.5. Unfortunately it didn't ""follow"" for me ! Could anyone help explain ? Thanks for reading.",,"['statistics', 'euclidean-geometry', 'correlation']"
78,Gamma Densities proof question,Gamma Densities proof question,,"I understand the first portion of the problem but then how do I conclude that $f_n(x)$ gives us a probability density function on $[0,\infty)$. If someone could point me in the right direction that would be a tremendous help! Suppose that $t \geq 0$ and $n$ is a non-negative integer.  For $x \geq 0$ define \begin{eqnarray*} f_n(x) & = & \frac{x^n}{n!}\exp(-x)\\ S_n(t) & = & \int_t^\infty f_n(x)\;dx \end{eqnarray*} Conclude that \begin{eqnarray*}S_{n+1}(0) = S_n(0) \end{eqnarray*} for each non-negative integer $n$, and use this observation to conclude that $f_n(x)$ gives us a probability density function on $[0,\infty)$. These densities are known as Gamma densities and $S_n$ is called a survival function . Conclude that\begin{eqnarray*} S_{n}(t) = \sum_{k=0}^{n} \frac{t^k}{k!}\exp(-t)\end{eqnarray*} Thus the survival function of a Gamma distribution is the distribution function of a Poisson distribution.","I understand the first portion of the problem but then how do I conclude that $f_n(x)$ gives us a probability density function on $[0,\infty)$. If someone could point me in the right direction that would be a tremendous help! Suppose that $t \geq 0$ and $n$ is a non-negative integer.  For $x \geq 0$ define \begin{eqnarray*} f_n(x) & = & \frac{x^n}{n!}\exp(-x)\\ S_n(t) & = & \int_t^\infty f_n(x)\;dx \end{eqnarray*} Conclude that \begin{eqnarray*}S_{n+1}(0) = S_n(0) \end{eqnarray*} for each non-negative integer $n$, and use this observation to conclude that $f_n(x)$ gives us a probability density function on $[0,\infty)$. These densities are known as Gamma densities and $S_n$ is called a survival function . Conclude that\begin{eqnarray*} S_{n}(t) = \sum_{k=0}^{n} \frac{t^k}{k!}\exp(-t)\end{eqnarray*} Thus the survival function of a Gamma distribution is the distribution function of a Poisson distribution.",,"['probability', 'statistics']"
79,Simultaneous equations for bacteria.,Simultaneous equations for bacteria.,,"I would like to calculate the value of bacteria on 4 surfaces $i=\{1..4\}$. A person touches some of those 4 surfaces at random and a count is made on their finger after each surface contact ($x_i$). Someone lost the bacteria count ($x_i$) after each surface but I do know the total count (X) on a person's finger after they've touched a number of surfaces. I also know which ones and in which order. What I know: Final bacteria count on a person's finger: $X$ Transfer efficiency from surface to finger: $PT_i=\displaystyle \frac{\text{Finger contact area}}{\text{Area of surface}_i}\frac{1}{\gamma_i}$ where $\gamma$ is a surface dependent constant. The number of times the person touched a particular surface: $h_i$. If I had surface counts $C_i$, the summation of bacteria is linear:  ie $\begin{eqnarray} h_1C_1PT_1&=&x_1\\ h_2C_2PT_2&=&x_2\\ \vdots\quad &=& \quad \vdots\\ h_iC_iPT_i&=&x_i \end{eqnarray}$ such that summing over all surfaces $i$ the total count x is: $\displaystyle \sum_i h_iC_iPT_i=\sum_i x_i=X$. Can I back calculate $C_i$, without $x_i$ even statistically? Best regards. ANSWER? so since the portion of X that belongs to each surface is: $\displaystyle \dfrac{h_i}{\sum^i h_i}X=x_i$ but $x_i=h_iC_iPT_i$ then $\displaystyle \dfrac{X}{\sum^i h_i}\dfrac{1}{PT_i}X=C_i$ It seems something is missing, because the answer only depends on PT and not $h_i$.  Any ideas?","I would like to calculate the value of bacteria on 4 surfaces $i=\{1..4\}$. A person touches some of those 4 surfaces at random and a count is made on their finger after each surface contact ($x_i$). Someone lost the bacteria count ($x_i$) after each surface but I do know the total count (X) on a person's finger after they've touched a number of surfaces. I also know which ones and in which order. What I know: Final bacteria count on a person's finger: $X$ Transfer efficiency from surface to finger: $PT_i=\displaystyle \frac{\text{Finger contact area}}{\text{Area of surface}_i}\frac{1}{\gamma_i}$ where $\gamma$ is a surface dependent constant. The number of times the person touched a particular surface: $h_i$. If I had surface counts $C_i$, the summation of bacteria is linear:  ie $\begin{eqnarray} h_1C_1PT_1&=&x_1\\ h_2C_2PT_2&=&x_2\\ \vdots\quad &=& \quad \vdots\\ h_iC_iPT_i&=&x_i \end{eqnarray}$ such that summing over all surfaces $i$ the total count x is: $\displaystyle \sum_i h_iC_iPT_i=\sum_i x_i=X$. Can I back calculate $C_i$, without $x_i$ even statistically? Best regards. ANSWER? so since the portion of X that belongs to each surface is: $\displaystyle \dfrac{h_i}{\sum^i h_i}X=x_i$ but $x_i=h_iC_iPT_i$ then $\displaystyle \dfrac{X}{\sum^i h_i}\dfrac{1}{PT_i}X=C_i$ It seems something is missing, because the answer only depends on PT and not $h_i$.  Any ideas?",,"['algebra-precalculus', 'statistics', 'dynamical-systems']"
80,"How can I compare two averages of imperfect measurements, with their std. deviations?","How can I compare two averages of imperfect measurements, with their std. deviations?",,"I have a process by which I measure the times it take to do something, (run some code), and this time varies, a lot. I'm trying to optimize this code, making small changes that sometimes have small impacts on performance, and I want to try and see whether the change actually made a difference or not (And if so, how much of a difference) What i'm doing right now is I run one code 10 times, time each of them, and take an average and a standard deviation. I do the same for the second code. And then... That's where I'm stuck. How can I compare two averages and their standard deviations, to know which one is greater and how greater, or to know they are actually the same (because the difference is not statistically significant) 2 examples: 1) Avg: 13577       Std Dev:    114 Avg: 13929       Std Dev:    220 2) Avg: 24759       Std Dev:    34 Avg:    24196       Std Dev:    110 The first case are two runs of the same code, so whatever I do to compare should tell me those two are just as fast. The second case are two runs of different codes, one of which had a ""feature"" disabled, which does make it a bit faster, I just don't know how much. How can I know whether one test was faster than the other? How can I know how much faster/slower? I'm doing 10 runs, ""just because"". How would I know if 10 runs is too little to know, and I need to have more runs per test? (or in other words, I believe, how do I know if my deviation is too big and I need to lower it?) UPDATE : Turns out my question is an exact duplicate of this: https://stats.stackexchange.com/questions/16018/how-can-i-determine-if-theres-a-statistically-significant-difference-between-tw","I have a process by which I measure the times it take to do something, (run some code), and this time varies, a lot. I'm trying to optimize this code, making small changes that sometimes have small impacts on performance, and I want to try and see whether the change actually made a difference or not (And if so, how much of a difference) What i'm doing right now is I run one code 10 times, time each of them, and take an average and a standard deviation. I do the same for the second code. And then... That's where I'm stuck. How can I compare two averages and their standard deviations, to know which one is greater and how greater, or to know they are actually the same (because the difference is not statistically significant) 2 examples: 1) Avg: 13577       Std Dev:    114 Avg: 13929       Std Dev:    220 2) Avg: 24759       Std Dev:    34 Avg:    24196       Std Dev:    110 The first case are two runs of the same code, so whatever I do to compare should tell me those two are just as fast. The second case are two runs of different codes, one of which had a ""feature"" disabled, which does make it a bit faster, I just don't know how much. How can I know whether one test was faster than the other? How can I know how much faster/slower? I'm doing 10 runs, ""just because"". How would I know if 10 runs is too little to know, and I need to have more runs per test? (or in other words, I believe, how do I know if my deviation is too big and I need to lower it?) UPDATE : Turns out my question is an exact duplicate of this: https://stats.stackexchange.com/questions/16018/how-can-i-determine-if-theres-a-statistically-significant-difference-between-tw",,"['statistics', 'average', 'standard-deviation']"
81,Statistics: question on transformations.,Statistics: question on transformations.,,"Suppose that $X$ has a pdf $f(x)=2x$ on $[0,1]$ (and zero otherwise), and let $U$ be a uniform random variable on $[0,1]$. Find a function $g$ such that $g(U)$ and $X$ have the same distribution (behaviour).","Suppose that $X$ has a pdf $f(x)=2x$ on $[0,1]$ (and zero otherwise), and let $U$ be a uniform random variable on $[0,1]$. Find a function $g$ such that $g(U)$ and $X$ have the same distribution (behaviour).",,"['probability', 'statistics', 'probability-distributions']"
82,Critical region and power function for hypothesis test,Critical region and power function for hypothesis test,,"Hi all I have a question about Hypothesis test, could you please help me? If $X_{1},X_{2},\ldots,X_{n}$  are independent, where $X_{i}$  is $N(\theta_{i},1)$ , find the critical region and power function for the Most Powerful test of size $\alpha$  of $H_{0}:\theta_{1}=\cdots=\theta_{n}=0$  against $H_{1}:\theta_{1}=\cdots=\theta_{r}=\frac{1}{2} , \theta_{r+1}=\cdots=\theta_{n}=-\frac{1}{2}$","Hi all I have a question about Hypothesis test, could you please help me? If $X_{1},X_{2},\ldots,X_{n}$  are independent, where $X_{i}$  is $N(\theta_{i},1)$ , find the critical region and power function for the Most Powerful test of size $\alpha$  of $H_{0}:\theta_{1}=\cdots=\theta_{n}=0$  against $H_{1}:\theta_{1}=\cdots=\theta_{r}=\frac{1}{2} , \theta_{r+1}=\cdots=\theta_{n}=-\frac{1}{2}$",,['statistics']
83,Correlation and Regression Question,Correlation and Regression Question,,"Two separate tests are designed to measure a students ability to solve problems. Several students are randomly selected to take both tests and the results are: $$ \begin{matrix} \text{Test A}(x) & 43 & 65 & 73 & 34 & 99 & 78 & 65 \\  \text{Test B}(y) & 39 & 60 & 62 & 20 & 85 & 70 & 54 \end{matrix} $$ Calculate $r$, the linear correlation  coefficient. My answer is always $1.07$ after I solve using the formula. $$r = \frac{n \sum x y - \sum x \sum y}{\sqrt{ n (\sum x^2) - (\sum x)^2}  \cdot \sqrt{n (\sum y^2) - (\sum y)^2}}$$ I don't have a linear calculator, so my numbers might be off due to that. If anyone needs my calculations for the formula that I have gotten, I can provide.","Two separate tests are designed to measure a students ability to solve problems. Several students are randomly selected to take both tests and the results are: $$ \begin{matrix} \text{Test A}(x) & 43 & 65 & 73 & 34 & 99 & 78 & 65 \\  \text{Test B}(y) & 39 & 60 & 62 & 20 & 85 & 70 & 54 \end{matrix} $$ Calculate $r$, the linear correlation  coefficient. My answer is always $1.07$ after I solve using the formula. $$r = \frac{n \sum x y - \sum x \sum y}{\sqrt{ n (\sum x^2) - (\sum x)^2}  \cdot \sqrt{n (\sum y^2) - (\sum y)^2}}$$ I don't have a linear calculator, so my numbers might be off due to that. If anyone needs my calculations for the formula that I have gotten, I can provide.",,"['statistics', 'regression', 'correlation']"
84,Find the PDF of $X+2Y$ given the PDFs of $X$ and $Y$,Find the PDF of  given the PDFs of  and,X+2Y X Y,"Let $X$ and $Y$ be two independent continuous random variables each uniformly distributed between $[0,1]$ (i.e., $f_x (a)=f_y (a)=1,0\leq a \leq 1$). Please find the density function of the sum of the random variables $X$ and $2Y$, i.e., $f_{X+2Y} (a)$. Am I doing this right? :[ As you can see, I get a little confused at the bottom, and I'm just kind of stuck. Any help would be greatly appreciated, thank you. My work. Cumulative distribution function of $X+ 2Y$: $$ \begin{align*} F_{X+2Y} (a)  &= P(X+2Y \leq a) \\ &= \iint_{x+ y \leq a} f_X(x) f_Y(y) ~ dy ~dx \\ &= \int_{-\infty}^{\infty} \int_{-\infty}^{a - 2y} f_X(x) f_Y(y) ~ dx ~dy \\ &= \int_{-\infty}^{\infty} \int_{-\infty}^{a - 2y} f_X(x)  ~ dx\ f_Y(y) ~dy \\ &= \int_{-\infty}^{\infty} F_X(a-2y)  f_Y(y) ~dy \end{align*} $$ The probability density function: $$ \begin{align*} f_{X+2Y}(a) &= \frac{d}{da} \int_{-\infty}^{+\infty} F_X(a-2y) f_Y(y) ~ dy  \\ &= \int_{-\infty}^{+\infty} \frac{d}{da} F_X(a-2y) f_Y(y) ~ dy \\ &= \int_{-\infty}^{+\infty} f_X(a-2y) f_Y(y) ~ dy \end{align*} $$ For $[0,1]$: $$ f_X(a) = f_Y(a) = \begin{cases} 1, & 0 \lt a \lt 1, \\ 0, &\text{otherwise}. \end{cases} $$ $$ f_{X + 2Y}(a) = \int_{-\infty}^{+\infty} f_X(a-2y) f_Y(y) ~ dy \quad \text{for } 0 \lt a \lt 1. $$ $$ f_{X + 2Y}(a-2) = \int_0^a dy = a. $$","Let $X$ and $Y$ be two independent continuous random variables each uniformly distributed between $[0,1]$ (i.e., $f_x (a)=f_y (a)=1,0\leq a \leq 1$). Please find the density function of the sum of the random variables $X$ and $2Y$, i.e., $f_{X+2Y} (a)$. Am I doing this right? :[ As you can see, I get a little confused at the bottom, and I'm just kind of stuck. Any help would be greatly appreciated, thank you. My work. Cumulative distribution function of $X+ 2Y$: $$ \begin{align*} F_{X+2Y} (a)  &= P(X+2Y \leq a) \\ &= \iint_{x+ y \leq a} f_X(x) f_Y(y) ~ dy ~dx \\ &= \int_{-\infty}^{\infty} \int_{-\infty}^{a - 2y} f_X(x) f_Y(y) ~ dx ~dy \\ &= \int_{-\infty}^{\infty} \int_{-\infty}^{a - 2y} f_X(x)  ~ dx\ f_Y(y) ~dy \\ &= \int_{-\infty}^{\infty} F_X(a-2y)  f_Y(y) ~dy \end{align*} $$ The probability density function: $$ \begin{align*} f_{X+2Y}(a) &= \frac{d}{da} \int_{-\infty}^{+\infty} F_X(a-2y) f_Y(y) ~ dy  \\ &= \int_{-\infty}^{+\infty} \frac{d}{da} F_X(a-2y) f_Y(y) ~ dy \\ &= \int_{-\infty}^{+\infty} f_X(a-2y) f_Y(y) ~ dy \end{align*} $$ For $[0,1]$: $$ f_X(a) = f_Y(a) = \begin{cases} 1, & 0 \lt a \lt 1, \\ 0, &\text{otherwise}. \end{cases} $$ $$ f_{X + 2Y}(a) = \int_{-\infty}^{+\infty} f_X(a-2y) f_Y(y) ~ dy \quad \text{for } 0 \lt a \lt 1. $$ $$ f_{X + 2Y}(a-2) = \int_0^a dy = a. $$",,"['statistics', 'probability-distributions']"
85,how to find correlation between 2 arrays of 1's and 0's?,how to find correlation between 2 arrays of 1's and 0's?,,"For my case, I have 2 arrays or sets of data, 100 elements, and the values are only 0 and 1. What test or procedure would measure the correlation or independence of the 2 sets? To give an example of the data, suppose one counted if it rained or not in 2 different cities over a period of 100 days. The data would be recorded as 0 for no rain that day, or 1 for any rain that day. After 100 days, CityA would have data of {0,1,0,0,1 ...} with 100 data points, and CityB would have data of {0,1,1,0,0, ...} also with 100 data points. The question is whether the rain in the 2 cities is correlated positively or negatively, or independent. If it's important, these data sets are time-series, or just that the order is fixed, and the event is mostly randomly distributed over the 100 days. One measure I found was the Phi Coefficient. But the example in my text book says it's for 2 dichotomous values a subject may have, eg smoking and cancer, male/female and pets, married and employed, etc. I was not sure if this applied to my case where it's 2 time series. thanks in advance, and I hope I've phrased my question clearly, if not feel free to ask for more details if needed, thanks","For my case, I have 2 arrays or sets of data, 100 elements, and the values are only 0 and 1. What test or procedure would measure the correlation or independence of the 2 sets? To give an example of the data, suppose one counted if it rained or not in 2 different cities over a period of 100 days. The data would be recorded as 0 for no rain that day, or 1 for any rain that day. After 100 days, CityA would have data of {0,1,0,0,1 ...} with 100 data points, and CityB would have data of {0,1,1,0,0, ...} also with 100 data points. The question is whether the rain in the 2 cities is correlated positively or negatively, or independent. If it's important, these data sets are time-series, or just that the order is fixed, and the event is mostly randomly distributed over the 100 days. One measure I found was the Phi Coefficient. But the example in my text book says it's for 2 dichotomous values a subject may have, eg smoking and cancer, male/female and pets, married and employed, etc. I was not sure if this applied to my case where it's 2 time series. thanks in advance, and I hope I've phrased my question clearly, if not feel free to ask for more details if needed, thanks",,['statistics']
86,What is the Cumulative distribution function for random variable X?,What is the Cumulative distribution function for random variable X?,,$$ x\quad|\quad 0\quad|\quad1\quad|\quad2\quad|\quad4 $$ $$ f_x(x)\quad|\quad1/27\quad|\quad8/27\quad|\quad10/27\quad|\quad8/27 $$ Okay I want to make sure I am doing this correctly: $$ F_x(0) = P(X\leq 0) = P(X=0) = 0.0370 $$ $$ F_x(1) = P(X\leq 1) = P(X=0) + P(X=1) = 0.0370 + 0.2963 = 0.3333 $$ $$ F_x(1) = P(X\leq 2) = P(X=0) + P(X=1) + P(X=2) = 0.0370 + 0.2963 + 0.3704 = 0.7037 $$ $$ F_x(1) = P(X\leq 4) = P(X=0) + P(X=1) + P(X=2) + P(X=4) = 0.0370 + 0.2963 + 0.3704 + 0.2963 = 1 $$ I believe this is how to do the CDF.,$$ x\quad|\quad 0\quad|\quad1\quad|\quad2\quad|\quad4 $$ $$ f_x(x)\quad|\quad1/27\quad|\quad8/27\quad|\quad10/27\quad|\quad8/27 $$ Okay I want to make sure I am doing this correctly: $$ F_x(0) = P(X\leq 0) = P(X=0) = 0.0370 $$ $$ F_x(1) = P(X\leq 1) = P(X=0) + P(X=1) = 0.0370 + 0.2963 = 0.3333 $$ $$ F_x(1) = P(X\leq 2) = P(X=0) + P(X=1) + P(X=2) = 0.0370 + 0.2963 + 0.3704 = 0.7037 $$ $$ F_x(1) = P(X\leq 4) = P(X=0) + P(X=1) + P(X=2) + P(X=4) = 0.0370 + 0.2963 + 0.3704 + 0.2963 = 1 $$ I believe this is how to do the CDF.,,['statistics']
87,Concrete examples concerning standard deviations and mean absolute deviations,Concrete examples concerning standard deviations and mean absolute deviations,,"Is there a simple (or not simple?) algorithm that will churn out examples of pairs of moderately small finite multisets (hereinafter calls ""sets"") of moderately small integers satisfying the following desiderata, or at least the first several of them, for suitable values of ""several""? The first set in the pair has a larger standard deviation and a smaller mean absolute deviation from the mean than the second; The SD and/or the MAD are, at least approximately, what I want them to be; The mean is an integer; The SD and/or the MAD is an integer; The are right-skewed or left-skewed or concentrated near the mean or approximately uniformly distributed according according to the user's choice. One can in other (specify) ways make them do one's bidding.","Is there a simple (or not simple?) algorithm that will churn out examples of pairs of moderately small finite multisets (hereinafter calls ""sets"") of moderately small integers satisfying the following desiderata, or at least the first several of them, for suitable values of ""several""? The first set in the pair has a larger standard deviation and a smaller mean absolute deviation from the mean than the second; The SD and/or the MAD are, at least approximately, what I want them to be; The mean is an integer; The SD and/or the MAD is an integer; The are right-skewed or left-skewed or concentrated near the mean or approximately uniformly distributed according according to the user's choice. One can in other (specify) ways make them do one's bidding.",,"['statistics', 'descriptive-statistics']"
88,How would I tackle statistics problems of these types?,How would I tackle statistics problems of these types?,,"Suppose you have a loaded coin, and we assume a priori that when you flip it you get heads 20% of the time and tails 80%. If I wanted to be 99% certain that this coin is a fraud, how many times do I need to flip? I know this involves some advanced statistics, but I can't recall?","Suppose you have a loaded coin, and we assume a priori that when you flip it you get heads 20% of the time and tails 80%. If I wanted to be 99% certain that this coin is a fraud, how many times do I need to flip? I know this involves some advanced statistics, but I can't recall?",,"['probability', 'combinatorics', 'statistics']"
89,Help with problem: Estimated Standard Deviation of Regression Equation (Simple Linear),Help with problem: Estimated Standard Deviation of Regression Equation (Simple Linear),,"This is a practice problem. I've solved part (a). I have provided verified answers (from the published key) to all parts (a), (b) and & (c). I need help solving (b) and (c). Consider a simple liner regression model of the form: Y = a + bX + error. Given are the following summed information: $\sum X = 383$ $\sum Y = 2495$ $\sum X^2 = 17443$ $\sum Y^2 = 757257$ $\sum (X*Y) = 114417$ and $n = 9$ (a) Find the regression equation of Y on X based on the above data. (Answer: $Y$ = -29.178 + 7.20 * (X) + error) (b) Calculate the estimated standard deviation of the regression equation error. (Answer: 29.8454) (c) Suppose the Durbin Watson statistic value for the regression is 1.5915. Then the approximate correlation between the residual and its first lag is given by? (Answer: 0.2043) Please help me understand how to solve part (b) and (c). Thoughts: I found the $R^2$ and Adjusted $R^2$ values from the SSE, SST, SSR calculations. The adjusted $R^2$ value is slightly lower (.89) than the $R^2$ value (.90).","This is a practice problem. I've solved part (a). I have provided verified answers (from the published key) to all parts (a), (b) and & (c). I need help solving (b) and (c). Consider a simple liner regression model of the form: Y = a + bX + error. Given are the following summed information: $\sum X = 383$ $\sum Y = 2495$ $\sum X^2 = 17443$ $\sum Y^2 = 757257$ $\sum (X*Y) = 114417$ and $n = 9$ (a) Find the regression equation of Y on X based on the above data. (Answer: $Y$ = -29.178 + 7.20 * (X) + error) (b) Calculate the estimated standard deviation of the regression equation error. (Answer: 29.8454) (c) Suppose the Durbin Watson statistic value for the regression is 1.5915. Then the approximate correlation between the residual and its first lag is given by? (Answer: 0.2043) Please help me understand how to solve part (b) and (c). Thoughts: I found the $R^2$ and Adjusted $R^2$ values from the SSE, SST, SSR calculations. The adjusted $R^2$ value is slightly lower (.89) than the $R^2$ value (.90).",,"['statistics', 'regression', 'standard-deviation']"
90,Likelihood Ratio Test,Likelihood Ratio Test,,"I am having a hard time understanding what this following question is asking. I do not have any clue pn how to start it. Any help would be great. Thanks in advance.  Let $X_1,X_2,...,X_n$ be a random sample, $X=(X_1,X_2,...,X_n)^T$, $X=x \in B \subset R^n$ be the observed sample set. Let $f(x|\theta)$ be the joint pdf of the given sample $X$, and let $\Theta$ be an entire parameter set in $R$. For $\Theta \neq \phi$,  define $$\lambda(x)=\frac{\text{sup}_{\Theta_0}L(\theta|x)}{\text{sup}_{\Theta}L(\theta|x)}$$ 1) Show that $0\leq \lambda(x) \leq 1$ for all $x\in B$. 2) As $\text{sup}_ \Theta$ $L(\theta|x)$ increases, $\lambda(x)$ decreases. 3) $$\lambda(x)=\frac{L(\hat{\theta}_{0}|x)}{L(\hat{\theta}|x)}$$ 4) $$\lambda(x)=\frac{\text{sup}_{\Theta_0}g(T(x)|\theta)}{\text{sup}_{\Theta}g(T(x)|\theta)}=\lambda^{*}(x)$$ where $T(X)$ is a sufficient statistics and $f(x|\theta)=g(T(x)|\theta)h(x).$ 5) As $\text{sup}_{\Theta}L(\theta|x)$ decreases, $\lambda(x)$ increases. 6) Under what conditions on $\Theta_{0}$ , $\lambda(X)$ is called the likelihood Ratio test statistic? 7) Assuming that $\lambda(X)$ is a Likelihood ratio test statistic, what can you say about $\{x: \lambda(x) \leq c \}$ for any number $c$ satisfying $0 \leq c \leq 1$?","I am having a hard time understanding what this following question is asking. I do not have any clue pn how to start it. Any help would be great. Thanks in advance.  Let $X_1,X_2,...,X_n$ be a random sample, $X=(X_1,X_2,...,X_n)^T$, $X=x \in B \subset R^n$ be the observed sample set. Let $f(x|\theta)$ be the joint pdf of the given sample $X$, and let $\Theta$ be an entire parameter set in $R$. For $\Theta \neq \phi$,  define $$\lambda(x)=\frac{\text{sup}_{\Theta_0}L(\theta|x)}{\text{sup}_{\Theta}L(\theta|x)}$$ 1) Show that $0\leq \lambda(x) \leq 1$ for all $x\in B$. 2) As $\text{sup}_ \Theta$ $L(\theta|x)$ increases, $\lambda(x)$ decreases. 3) $$\lambda(x)=\frac{L(\hat{\theta}_{0}|x)}{L(\hat{\theta}|x)}$$ 4) $$\lambda(x)=\frac{\text{sup}_{\Theta_0}g(T(x)|\theta)}{\text{sup}_{\Theta}g(T(x)|\theta)}=\lambda^{*}(x)$$ where $T(X)$ is a sufficient statistics and $f(x|\theta)=g(T(x)|\theta)h(x).$ 5) As $\text{sup}_{\Theta}L(\theta|x)$ decreases, $\lambda(x)$ increases. 6) Under what conditions on $\Theta_{0}$ , $\lambda(X)$ is called the likelihood Ratio test statistic? 7) Assuming that $\lambda(X)$ is a Likelihood ratio test statistic, what can you say about $\{x: \lambda(x) \leq c \}$ for any number $c$ satisfying $0 \leq c \leq 1$?",,['statistics']
91,calculate the rate of change,calculate the rate of change,,"I am trying to calculate the change frequency for a set of data. Each bit of data has the date-time it was created. I would like to say for a specific set of data the change frequency is hourly, daily, weekly, monthly or yearly. So far I have tried getting the list of dates and get the min/max which is easy to calculate an average from which can be converted into a human readable label such as hourly, daily etc How would i take into account the age of the last new bit of data. eg: say there were 50 dates all roughly an hour one after the other. This is hourly. but if the last one was 2 weeks ago, its not quite hourly. I am sure there is a formula to calculate this, but I don't know where to start. Thanks P.S. I took a guess at the tags, not sure if there are better ones to use for this question.","I am trying to calculate the change frequency for a set of data. Each bit of data has the date-time it was created. I would like to say for a specific set of data the change frequency is hourly, daily, weekly, monthly or yearly. So far I have tried getting the list of dates and get the min/max which is easy to calculate an average from which can be converted into a human readable label such as hourly, daily etc How would i take into account the age of the last new bit of data. eg: say there were 50 dates all roughly an hour one after the other. This is hourly. but if the last one was 2 weeks ago, its not quite hourly. I am sure there is a formula to calculate this, but I don't know where to start. Thanks P.S. I took a guess at the tags, not sure if there are better ones to use for this question.",,"['analysis', 'statistics', 'algorithms', 'approximation']"
92,Application of the CLT,Application of the CLT,,"Suppose we have $X_1,\cdots,X_n$ be a random sample with $X_i\backsim \chi^2(1)$. I'd like to show that as $n\rightarrow \infty$, $$\frac{\bar{X}-1}{\sqrt{\frac{2}{n}}}$$ is standard normal. Here's my attempt. Since $X_i\backsim \chi^2(1)$, we know that $\mathbb{E}(X_i)=1, \text{Var}(X_i)=2.$ As $n\rightarrow \infty $,the Central Limit Theorem says that, $\bar{X}$ is approximately $N(1,\frac{2}{n})$. So $$ \frac{\bar{X}-1}{\sqrt{\frac{2}{n}}}\rightarrow Z\backsim N(0,1).$$ Does my attempt pass as a genuine solution? Is there way of doing this using Mgf's? Thanks.","Suppose we have $X_1,\cdots,X_n$ be a random sample with $X_i\backsim \chi^2(1)$. I'd like to show that as $n\rightarrow \infty$, $$\frac{\bar{X}-1}{\sqrt{\frac{2}{n}}}$$ is standard normal. Here's my attempt. Since $X_i\backsim \chi^2(1)$, we know that $\mathbb{E}(X_i)=1, \text{Var}(X_i)=2.$ As $n\rightarrow \infty $,the Central Limit Theorem says that, $\bar{X}$ is approximately $N(1,\frac{2}{n})$. So $$ \frac{\bar{X}-1}{\sqrt{\frac{2}{n}}}\rightarrow Z\backsim N(0,1).$$ Does my attempt pass as a genuine solution? Is there way of doing this using Mgf's? Thanks.",,"['statistics', 'probability-distributions']"
93,Frequency $\times $ Midpoint = What?,Frequency  Midpoint = What?,\times ,"When finding the mean of grouped data, at some point you need to do: Frequency $\times $ Midpoint = ..... Could someone tell me the name of the answer, does it have a name? Its labeled as fx in a lot of places, but I don't actually know what to call it?","When finding the mean of grouped data, at some point you need to do: Frequency $\times $ Midpoint = ..... Could someone tell me the name of the answer, does it have a name? Its labeled as fx in a lot of places, but I don't actually know what to call it?",,['statistics']
94,Use of covariance matrix for the confidence interval,Use of covariance matrix for the confidence interval,,"I have a number of explanatory variables $x_1,...,x_n$ and an outcome variable $y = f(x_1,...,x_n)$. Here $f$ is assumed to be known (estimated). I heard that for a confidence interval for $y$ one can use a covariance matrix $C$ such that $c_{ij} = Cov(x_i,x_j)$. Could you please refer me to these methods?","I have a number of explanatory variables $x_1,...,x_n$ and an outcome variable $y = f(x_1,...,x_n)$. Here $f$ is assumed to be known (estimated). I heard that for a confidence interval for $y$ one can use a covariance matrix $C$ such that $c_{ij} = Cov(x_i,x_j)$. Could you please refer me to these methods?",,"['probability', 'statistics']"
95,Good Online Resources to learn Multivariate Statistics?,Good Online Resources to learn Multivariate Statistics?,,"Are there any good online resources to learn multivariate statistics? ( With topics such as Multiple Linear Regression, Principal Component Analysis, Factor Analysis, Cluster Analysis and Discriminant Analysis)","Are there any good online resources to learn multivariate statistics? ( With topics such as Multiple Linear Regression, Principal Component Analysis, Factor Analysis, Cluster Analysis and Discriminant Analysis)",,['statistics']
96,MinimizeVarianceIntuitively function or approach needed,MinimizeVarianceIntuitively function or approach needed,,"We have a problem the arises in asset management.  I think (and hope) it raises interesting enough questions for this forum to consider it.  We made pretty extensive searches of the literature and find things that talk around this question, but nothing directly dealing with the issue. Background We have time series data for assets, from which we calculate a correlation matrix.  For 5 assets using Mathematica it might look something like this: m = Correlation[data] {{1.0, 0.635562, 0.698852, 0.404792, -0.32746},  {0.635562, 1.0, 0.410075, 0.314375, -0.0636438},  {0.698852, 0.410075, 1.0, 0.374416, -0.260137},  {0.404792, 0.314375, 0.374416, 1.0, 0.293135},  {-0.32746, -0.0636438, -0.260137, 0.293135, 1.0}} m //TableForm 1.000000,   0.635562,   0.698852,  0.404792,  -0.32746 0.635562,   1.000000,   0.410075,  0.314375,  -0.0636438 0.698852,   0.410075,   1.000000,  0.374416,  -0.260137 0.404792,   0.314375,   0.374416, 1.000000,   0.293135 -0.32746,  -0.0636438, -0.260137,  0.293135,   1.000000 In asset management one wants diversification.  If two or more assets in a portfolio correlate too highly it concentrates rather than diversifying the risk. What we want We want an approach or method to construct a portfolio of assets that minimizes the portfolio’s “concentration” risk. I’ll illustrate concentration risk with a couple of examples below, but first... Why this is an interesting problem or question? A couple of things make this an interesting and challenging question: While related to “efficient frontier” we have no assumptions about future performance for the individual instruments to use. Minimizing variance gives an answer, but not an intuitively satisfying or even useful one. Principal Components Analysis seems a natural way to look at this, but also doesn’t appear to give us what we need. We’ve looked at using entropy maximization, but while one of our guys familiar with discrete entropy thought it seemed promising, when we tried thinking about this in terms of continuous entropy it proved a dead end. A couple of simple examples to illustrate concentration risk It's easiest to understand what we want to achieve if we look at a portfolio of 3 assets in a thought experiment.  Assume 2 of the instruments have correlations of 1 (100%) and the third at 0, it's correlation matrix would look like this: 1, 1, 0 1, 1, 0 0, 0, 1 From our perspective in this case, it would make sense to put 25% in each of the 2 correlated stocks and 50% in the uncorrelated one. 25%,   25%,   50% This offsets the risk of concentrating in correlated instruments, while recognizing that the 100% correlated assets are in fact still different instruments whose correlation in the future may change. One might make the case that as the two assets that have 100% correlation move the same, then a wide range of possible allocations could equally serve our purposes e.g: 50%,    0%,    50% 0%,     50%,   50% 10%,    40%,   50% ... or any such variations on the theme. But, as we don’t know how their future correlation will evolve, we think the best and most intuitive solution remains at: 25%,  25%,  50% Another example In a portfolio of 5 assets with 4 having 100% correlation and 1 having 0% correlation the correlation matrix would look like the following: 1, 1, 1, 1, 0 1, 1, 1, 1, 0 1, 1, 1, 1, 0 1, 1, 1, 1, 0 0, 0, 0, 0, 1 and the portfolio allocation we want would have the following proportions: 12.5%,   12.5%,   12.5%,   12.5%,   50% Of course the real world presents us with greater complication. Things we’ve tried Minimizing variance (promising but doesn’t work) Someone suggested minimizing variance to do this, but as one can see it doesn’t produce an intuitive solution: Some Mathematica code illustrating this follows: For 3 assets: m3 = {{1, 1, 0}, {1, 1, 0 }, { 0, 0 , 1}}; Array[x, Length@m3]; Minimize[{p.m3.p, Tr@p == 1 && And @@ Thread[p >= 0]}, p] {1/2, {x[1] -> 1/4, x[2] -> 1/4, x[3] -> 1/2}} This looks good.  It gives us: 25%,   25%,   50% but... For 5 assets: m5 = {{1, 1, 1, 1, 0}, {1 , 1, 1, 1, 0 }, {1 , 1, 1, 1, 0 }, {1 , 1,1, 1, 0 }, { 0, 0 , 0, 0, 1}}; p = Array[x, Length@m5]; Minimize[{p.m5.p, Tr@p == 1 && And @@ Thread[p >= 0]}, p] {1/2, {x[1] -> 1/16, x[2] -> 1/4, x[3] -> 1/8, x[4] -> 1/16, x[5] ->1/2}} Not so good as it gives us: 6.25%,   25%,   12.50%,   6.25%,   50% So, minimizing variance doesn’t work even for this simple (if artificial) case let alone something more realistic. A promising solution One contributor to our discussion suggested a promising approach - at least for cases that do not have any negative correlations.  Perhaps it would lead someone to suggest a more complete solution. Again with Mathematica code:   m = {{1, 1, 0}, {1, 1, 0}, {0, 0, 1}}; Tr /@ PseudoInverse[m]/Tr[ Tr /@ PseudoInverse[m]] {1/4, 1/4, 1/2} Exactly what we would want. Note: For those not familiar with Mathematica code the functions: “Tr” finds the trace of a matrix and “/@” maps a function to a list or matrix.  The rest probably makes sense. Another example for four assets:   m = {{1, 1, 1, 0}, {1, 1, 1, 0}, {1, 1, 1, 0}, {0, 0, 0, 1}}; Tr /@ PseudoInverse[m]/Tr[ Tr /@ PseudoInverse[m]] {1/6, 1/6, 1/6, 1/2} Again, exactly what we want. This works better than minimizing variance, but in a more real world example (the first one described in the post) we get something that doesn’t work: m = {{1.0, 0.635562, 0.698852, 0.404792, -0.32746},  {0.635562, 1.0, 0.410075, 0.314375, -0.0636438},  {0.698852, 0.410075, 1.0, 0.374416, -0.260137},  {0.404792, 0.314375, 0.374416, 1.0, 0.293135},  {-0.32746, -0.0636438, -0.260137, 0.293135, 1.0}} Tr /@ PseudoInverse[m]/Tr[ Tr /@ PseudoInverse[m]] {0.267806, 0.0898877, 0.22403, -0.0541658, 0.472441} In this case we have a negative allocation (-0.0541658) for the 4th asset, something that doesn’t make sense for what we want to achieve. Conclusion So, we need a kind of MinimizeVarianceIntuitively function.  I hope all of this describes what we want to achieve clearly enough.  Any suggestions or ideas for attacking this problem in completely different ways or for extending any of the things we’ve tried already much appreciated. Many thanks, Arun Garapata","We have a problem the arises in asset management.  I think (and hope) it raises interesting enough questions for this forum to consider it.  We made pretty extensive searches of the literature and find things that talk around this question, but nothing directly dealing with the issue. Background We have time series data for assets, from which we calculate a correlation matrix.  For 5 assets using Mathematica it might look something like this: m = Correlation[data] {{1.0, 0.635562, 0.698852, 0.404792, -0.32746},  {0.635562, 1.0, 0.410075, 0.314375, -0.0636438},  {0.698852, 0.410075, 1.0, 0.374416, -0.260137},  {0.404792, 0.314375, 0.374416, 1.0, 0.293135},  {-0.32746, -0.0636438, -0.260137, 0.293135, 1.0}} m //TableForm 1.000000,   0.635562,   0.698852,  0.404792,  -0.32746 0.635562,   1.000000,   0.410075,  0.314375,  -0.0636438 0.698852,   0.410075,   1.000000,  0.374416,  -0.260137 0.404792,   0.314375,   0.374416, 1.000000,   0.293135 -0.32746,  -0.0636438, -0.260137,  0.293135,   1.000000 In asset management one wants diversification.  If two or more assets in a portfolio correlate too highly it concentrates rather than diversifying the risk. What we want We want an approach or method to construct a portfolio of assets that minimizes the portfolio’s “concentration” risk. I’ll illustrate concentration risk with a couple of examples below, but first... Why this is an interesting problem or question? A couple of things make this an interesting and challenging question: While related to “efficient frontier” we have no assumptions about future performance for the individual instruments to use. Minimizing variance gives an answer, but not an intuitively satisfying or even useful one. Principal Components Analysis seems a natural way to look at this, but also doesn’t appear to give us what we need. We’ve looked at using entropy maximization, but while one of our guys familiar with discrete entropy thought it seemed promising, when we tried thinking about this in terms of continuous entropy it proved a dead end. A couple of simple examples to illustrate concentration risk It's easiest to understand what we want to achieve if we look at a portfolio of 3 assets in a thought experiment.  Assume 2 of the instruments have correlations of 1 (100%) and the third at 0, it's correlation matrix would look like this: 1, 1, 0 1, 1, 0 0, 0, 1 From our perspective in this case, it would make sense to put 25% in each of the 2 correlated stocks and 50% in the uncorrelated one. 25%,   25%,   50% This offsets the risk of concentrating in correlated instruments, while recognizing that the 100% correlated assets are in fact still different instruments whose correlation in the future may change. One might make the case that as the two assets that have 100% correlation move the same, then a wide range of possible allocations could equally serve our purposes e.g: 50%,    0%,    50% 0%,     50%,   50% 10%,    40%,   50% ... or any such variations on the theme. But, as we don’t know how their future correlation will evolve, we think the best and most intuitive solution remains at: 25%,  25%,  50% Another example In a portfolio of 5 assets with 4 having 100% correlation and 1 having 0% correlation the correlation matrix would look like the following: 1, 1, 1, 1, 0 1, 1, 1, 1, 0 1, 1, 1, 1, 0 1, 1, 1, 1, 0 0, 0, 0, 0, 1 and the portfolio allocation we want would have the following proportions: 12.5%,   12.5%,   12.5%,   12.5%,   50% Of course the real world presents us with greater complication. Things we’ve tried Minimizing variance (promising but doesn’t work) Someone suggested minimizing variance to do this, but as one can see it doesn’t produce an intuitive solution: Some Mathematica code illustrating this follows: For 3 assets: m3 = {{1, 1, 0}, {1, 1, 0 }, { 0, 0 , 1}}; Array[x, Length@m3]; Minimize[{p.m3.p, Tr@p == 1 && And @@ Thread[p >= 0]}, p] {1/2, {x[1] -> 1/4, x[2] -> 1/4, x[3] -> 1/2}} This looks good.  It gives us: 25%,   25%,   50% but... For 5 assets: m5 = {{1, 1, 1, 1, 0}, {1 , 1, 1, 1, 0 }, {1 , 1, 1, 1, 0 }, {1 , 1,1, 1, 0 }, { 0, 0 , 0, 0, 1}}; p = Array[x, Length@m5]; Minimize[{p.m5.p, Tr@p == 1 && And @@ Thread[p >= 0]}, p] {1/2, {x[1] -> 1/16, x[2] -> 1/4, x[3] -> 1/8, x[4] -> 1/16, x[5] ->1/2}} Not so good as it gives us: 6.25%,   25%,   12.50%,   6.25%,   50% So, minimizing variance doesn’t work even for this simple (if artificial) case let alone something more realistic. A promising solution One contributor to our discussion suggested a promising approach - at least for cases that do not have any negative correlations.  Perhaps it would lead someone to suggest a more complete solution. Again with Mathematica code:   m = {{1, 1, 0}, {1, 1, 0}, {0, 0, 1}}; Tr /@ PseudoInverse[m]/Tr[ Tr /@ PseudoInverse[m]] {1/4, 1/4, 1/2} Exactly what we would want. Note: For those not familiar with Mathematica code the functions: “Tr” finds the trace of a matrix and “/@” maps a function to a list or matrix.  The rest probably makes sense. Another example for four assets:   m = {{1, 1, 1, 0}, {1, 1, 1, 0}, {1, 1, 1, 0}, {0, 0, 0, 1}}; Tr /@ PseudoInverse[m]/Tr[ Tr /@ PseudoInverse[m]] {1/6, 1/6, 1/6, 1/2} Again, exactly what we want. This works better than minimizing variance, but in a more real world example (the first one described in the post) we get something that doesn’t work: m = {{1.0, 0.635562, 0.698852, 0.404792, -0.32746},  {0.635562, 1.0, 0.410075, 0.314375, -0.0636438},  {0.698852, 0.410075, 1.0, 0.374416, -0.260137},  {0.404792, 0.314375, 0.374416, 1.0, 0.293135},  {-0.32746, -0.0636438, -0.260137, 0.293135, 1.0}} Tr /@ PseudoInverse[m]/Tr[ Tr /@ PseudoInverse[m]] {0.267806, 0.0898877, 0.22403, -0.0541658, 0.472441} In this case we have a negative allocation (-0.0541658) for the 4th asset, something that doesn’t make sense for what we want to achieve. Conclusion So, we need a kind of MinimizeVarianceIntuitively function.  I hope all of this describes what we want to achieve clearly enough.  Any suggestions or ideas for attacking this problem in completely different ways or for extending any of the things we’ve tried already much appreciated. Many thanks, Arun Garapata",,"['analysis', 'statistics', 'matrices']"
97,"What are the advantages / disadvantages of using splines, smoothed splines, and gaussian process emulators?","What are the advantages / disadvantages of using splines, smoothed splines, and gaussian process emulators?",,"I am interested in learning (and implementing) an alternative to polynomial interpolation. However, I am having trouble finding a good description of how these methods work, how they relate, and how they compare. I would appreciate your input on the pros/cons/conditions under which these methods or alternatives would be useful, but some good references to texts, slides, or podcasts would be sufficient. note: I asked this question on stats.SE a few weeks ago and received the recommendation to ask here since I have not received an answer. Thanks!","I am interested in learning (and implementing) an alternative to polynomial interpolation. However, I am having trouble finding a good description of how these methods work, how they relate, and how they compare. I would appreciate your input on the pros/cons/conditions under which these methods or alternatives would be useful, but some good references to texts, slides, or podcasts would be sufficient. note: I asked this question on stats.SE a few weeks ago and received the recommendation to ask here since I have not received an answer. Thanks!",,"['statistics', 'approximation']"
98,Orthant probability / passage-time [closed],Orthant probability / passage-time [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I'm having a hard time solving this problem. Would appreciate any hint! (and special thanks to Byron Schmuland for answering my previous 2 questions. This 3rd question is different.) Let $e_t$: $e_1$,$e_2$,$\ldots$ be i.i.d. normal mean 0 and variance 1. Let $X_t := e_1+\ldots+e_t$, for $t=1,2,\ldots$ and $X_0 := 0$. (So we have a discrete-time random walk whose steps are i.i.d. $\mathcal{N}(0,1)$) Define passage time $T^\ast := \inf\{t>0 : X_t < -t\}$. What is the CDF of $T^\ast$, i.e. what is $\operatorname{Prob}(T^\ast \leqslant t)$ ? (Equivalently: let $e^\prime_t \sim \mathcal{N}(1,1)$, and $T^\ast$ above is simply $\inf\{t>0 : X^\prime_t < 0\}$.) Is there a closed form solution? (Remember we have zero correlation, just non-zero mean) Some reference: http://dl.dropbox.com/u/4260685/orthant.pdf THANK YOU!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I'm having a hard time solving this problem. Would appreciate any hint! (and special thanks to Byron Schmuland for answering my previous 2 questions. This 3rd question is different.) Let $e_t$: $e_1$,$e_2$,$\ldots$ be i.i.d. normal mean 0 and variance 1. Let $X_t := e_1+\ldots+e_t$, for $t=1,2,\ldots$ and $X_0 := 0$. (So we have a discrete-time random walk whose steps are i.i.d. $\mathcal{N}(0,1)$) Define passage time $T^\ast := \inf\{t>0 : X_t < -t\}$. What is the CDF of $T^\ast$, i.e. what is $\operatorname{Prob}(T^\ast \leqslant t)$ ? (Equivalently: let $e^\prime_t \sim \mathcal{N}(1,1)$, and $T^\ast$ above is simply $\inf\{t>0 : X^\prime_t < 0\}$.) Is there a closed form solution? (Remember we have zero correlation, just non-zero mean) Some reference: http://dl.dropbox.com/u/4260685/orthant.pdf THANK YOU!",,"['probability', 'statistics', 'stochastic-processes']"
99,Coefficient of $Y \sim X$ versus coefficient of $X \sim Y$,Coefficient of  versus coefficient of,Y \sim X X \sim Y,"Let's consider two variables $X, Y$ such that $EX = EY = 0$ , $VarX = VarY = 1$ Moreover, when considering OLS model without intercept $Y \sim X$ we obtained parameter $\beta$ . Thing that I want to investigate is connection between parameter $\beta$ and parameter $\hat \beta$ obtained from regression $X \sim Y$ . My solution If $\beta$ and $\hat \beta$ are solutions of OLS problems then we have that: $$\beta = (X^TX)^{-1}X^TY$$ $$\hat \beta = (Y^TY)^{-1}Y^TX$$ Then we have that: $$\beta \hat \beta = (X^TX)^{-1}X^TY(Y^TY)^{-1}Y^TX = X^{-1}X^TX^TYY^{-1}Y^TX = 1$$ So we have that $\hat \beta = \frac{1}{\beta}$ . And I'm not sure if my solution is correct since, I check it in R to obtain that: y <- rnorm(1000000) k <- rnorm(1000000) lm(y~ 0 + k) $coefficients == 1 / lm(k~0 + y)$ coefficients FALSE Could you please tell me where do I have an error? EDIT As I understood problem in my calculations is that I'm trying to invert vectors, which are invertible. So my another idea driven by @GoldenRatio is that we know that: $$\beta = \frac{\textrm{cov}(X, Y)}{\textrm{Var}X} = E[XY]$$ as well as $$\hat \beta = \frac{\textrm{cov}(X, Y)}{\textrm{Var}Y} = E[XY]$$ So out of it we would have that $\beta = \hat \beta$ . Is it right?","Let's consider two variables such that , Moreover, when considering OLS model without intercept we obtained parameter . Thing that I want to investigate is connection between parameter and parameter obtained from regression . My solution If and are solutions of OLS problems then we have that: Then we have that: So we have that . And I'm not sure if my solution is correct since, I check it in R to obtain that: y <- rnorm(1000000) k <- rnorm(1000000) lm(y~ 0 + k) coefficients FALSE Could you please tell me where do I have an error? EDIT As I understood problem in my calculations is that I'm trying to invert vectors, which are invertible. So my another idea driven by @GoldenRatio is that we know that: as well as So out of it we would have that . Is it right?","X, Y EX = EY = 0 VarX = VarY = 1 Y \sim X \beta \beta \hat \beta X \sim Y \beta \hat \beta \beta = (X^TX)^{-1}X^TY \hat \beta = (Y^TY)^{-1}Y^TX \beta \hat \beta = (X^TX)^{-1}X^TY(Y^TY)^{-1}Y^TX = X^{-1}X^TX^TYY^{-1}Y^TX = 1 \hat \beta = \frac{1}{\beta} coefficients == 1 / lm(k~0 + y) \beta = \frac{\textrm{cov}(X, Y)}{\textrm{Var}X} = E[XY] \hat \beta = \frac{\textrm{cov}(X, Y)}{\textrm{Var}Y} = E[XY] \beta = \hat \beta","['probability', 'statistics', 'linear-regression']"
