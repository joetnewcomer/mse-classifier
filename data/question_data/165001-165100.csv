,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Integrability/measurability of a map to the bounded operators on $L^2$,Integrability/measurability of a map to the bounded operators on,L^2,"For each $t\in [0,1]$ , let $T_t\colon L^2(\mathbb{R})\to L^2(\mathbb{R})$ be the operator that shifts everything to the right by $t$ , i.e. $$T_t f(x)=f(x-t)$$ for all $f\in L^2(\mathbb{R})$ . Then $t\mapsto T_t$ defines a map $$\gamma\colon[0,1]\to\mathcal{B}(L^2(\mathbb{R})).$$ Note that $\gamma$ is not continuous. Question: Is $\gamma$ Bochner-integrable, i.e. does the integral $$\int_{[0,1]}T_t\,dt$$ converge in $\mathcal{B}(L^2(\mathbb{R}))$ ? Thoughts: Since each operator $T_t$ has norm, the question is whether $\gamma$ is strongly measurable . In particular, there is a question of whether there exists a subset of $J\subseteq[0,1]$ of measure $1$ such that $\gamma(J)$ is separable. Certainly $\gamma([0,1])$ is not separable, and I suspect that no such subset $J$ exists, but I'm not sure how to show this.","For each , let be the operator that shifts everything to the right by , i.e. for all . Then defines a map Note that is not continuous. Question: Is Bochner-integrable, i.e. does the integral converge in ? Thoughts: Since each operator has norm, the question is whether is strongly measurable . In particular, there is a question of whether there exists a subset of of measure such that is separable. Certainly is not separable, and I suspect that no such subset exists, but I'm not sure how to show this.","t\in [0,1] T_t\colon L^2(\mathbb{R})\to L^2(\mathbb{R}) t T_t f(x)=f(x-t) f\in L^2(\mathbb{R}) t\mapsto T_t \gamma\colon[0,1]\to\mathcal{B}(L^2(\mathbb{R})). \gamma \gamma \int_{[0,1]}T_t\,dt \mathcal{B}(L^2(\mathbb{R})) T_t \gamma J\subseteq[0,1] 1 \gamma(J) \gamma([0,1]) J","['integration', 'functional-analysis', 'measure-theory', 'operator-algebras', 'c-star-algebras']"
1,Stein Shakarchi Real Analysis Exercise 3.5.2,Stein Shakarchi Real Analysis Exercise 3.5.2,,"I don't follow a couple parts of the proof of this problem. Problem 3.5.2 Suppose $\{K_\delta\}$ is a family of kernels that satisfies for all $\delta > 0$ : $|K_\delta(x)| \le A\delta^{-d}$ $|K_\delta(x)| \le A\delta/|x|^{d+1}$ $\int_{\mathbb{R}^d} K_\delta(x)dx = 0$ Show that if $f$ is lebesgue-integrable on $\Bbb R^d$ , then $$ (f*K_\delta)(x) \rightarrow 0 $$ for a.e. $x$ , as $\delta \rightarrow 0$ . Proof We have $$ (f*K_\delta(x) = \int f(x-y)K_\delta(y)dy $$ For convenience, let $$g(x,y,\delta) := |f(x-y)||K_\delta(y)|$$ Using the monotonicity of the integral, it suffices to show that $$ \int f(x-y)K_\delta(y)dy \le \int g(x,y,\delta)dy \rightarrow 0 $$ as $\delta \rightarrow 0$ We break up this integral as follows $$ \tag{1} \int g(x,y,\delta)dy = \int_{|y| \le \delta}g(x,y,\delta)dy + \sum_{k=0}^\infty \int_{2^k \delta < |y| \le 2^{k+1} \delta} g(x,y,\delta)dy $$ We use the property of good kernels to observe that $  \tag{2} \int_{|y| \le \delta}|K_\delta(y)|dy \rightarrow 0 $ as $\delta \rightarrow 0$ . Issue 1: For the second term, choose each term in the sum to be less than $\epsilon/2^k$ for any $\epsilon > 0$ . Issue 2: For the first term, use $\int K_\delta = 0$ and the two estimates of good kernels to see that $$ \int_{|y| \le \delta} g(x,y,\delta) \le CA\delta / \epsilon \int |f(x-y)| $$ Two issues Issue 1 For issue 1, I see that we can make the expression in (2) arbitrarily small for sufficiently small $\delta$ , but it's not clear to me that this is true when you multiply the integrand by $|f(x-y)|$ . For each term in the sum, since $f$ is integrable, I could say that $$ \int |f| = M < \infty $$ But it does not follow that $f$ is even bounded a.e., so I can't say $ \int g(x,y,\delta) \le M \int |K_\delta(y)|dy $ So I'm not sure how to bound the terms in the sum of (2). Issue 2 I don't follow this result, in particular how $\epsilon$ ends up in the denominator. It would help to see some intermediate steps.","I don't follow a couple parts of the proof of this problem. Problem 3.5.2 Suppose is a family of kernels that satisfies for all : Show that if is lebesgue-integrable on , then for a.e. , as . Proof We have For convenience, let Using the monotonicity of the integral, it suffices to show that as We break up this integral as follows We use the property of good kernels to observe that as . Issue 1: For the second term, choose each term in the sum to be less than for any . Issue 2: For the first term, use and the two estimates of good kernels to see that Two issues Issue 1 For issue 1, I see that we can make the expression in (2) arbitrarily small for sufficiently small , but it's not clear to me that this is true when you multiply the integrand by . For each term in the sum, since is integrable, I could say that But it does not follow that is even bounded a.e., so I can't say So I'm not sure how to bound the terms in the sum of (2). Issue 2 I don't follow this result, in particular how ends up in the denominator. It would help to see some intermediate steps.","\{K_\delta\} \delta > 0 |K_\delta(x)| \le A\delta^{-d} |K_\delta(x)| \le A\delta/|x|^{d+1} \int_{\mathbb{R}^d} K_\delta(x)dx = 0 f \Bbb R^d 
(f*K_\delta)(x) \rightarrow 0
 x \delta \rightarrow 0 
(f*K_\delta(x) = \int f(x-y)K_\delta(y)dy
 g(x,y,\delta) := |f(x-y)||K_\delta(y)| 
\int f(x-y)K_\delta(y)dy \le \int g(x,y,\delta)dy \rightarrow 0
 \delta \rightarrow 0 
\tag{1}
\int g(x,y,\delta)dy = \int_{|y| \le \delta}g(x,y,\delta)dy + \sum_{k=0}^\infty \int_{2^k \delta < |y| \le 2^{k+1} \delta} g(x,y,\delta)dy
  
\tag{2} \int_{|y| \le \delta}|K_\delta(y)|dy \rightarrow 0
 \delta \rightarrow 0 \epsilon/2^k \epsilon > 0 \int K_\delta = 0 
\int_{|y| \le \delta} g(x,y,\delta) \le CA\delta / \epsilon \int |f(x-y)|
 \delta |f(x-y)| f 
\int |f| = M < \infty
 f 
\int g(x,y,\delta) \le M \int |K_\delta(y)|dy
 \epsilon","['measure-theory', 'lebesgue-integral']"
2,Rudin RCA ch. 1 ex. 7: Monotone convergence theorem for decreasing sequence,Rudin RCA ch. 1 ex. 7: Monotone convergence theorem for decreasing sequence,,"Suppose $f_n:X\rightarrow[0,\infty]$ is measurable for $n=1,2,3,\dots$ , $f_1\geq f_2\geq f_3\geq\cdots\geq 0$ , $f_n(x)\rightarrow f(x)$ as $n\rightarrow\infty$ , for every $x\in X$ , and $f_1\in L^1(\mu)$ . Prove that then $$\tag{*}\lim_{n\rightarrow\infty}\int_X f_n\,d\mu=\int_X f\,d\mu$$ and show that this conclusion does not follow if the condition "" $f_1\in L^1(\mu)$ "" is omitted. Let $E$ consist of the points $x\in X$ at which $f_1(x)<\infty$ . By the dominated convergence theorem, $$\int_E f_n\,d\mu\rightarrow \int_E f\,d\mu\mbox{.}$$ Since $f_1\in L^1(\mu)$ , $\mu(E^c)=0$ , and hence (*) follows. Let $X=\{1,2,3,\dots\}$ , and let $\mu$ be the counting measure. For each $n$ , define $f_n:X\rightarrow[0,\infty]$ by $$f_n(x)=\left\{\begin{array}{ll}\infty&(x\geq n)\\0&(x<n).\end{array}\right.$$ Then $\lim f_n=0$ , and $\int_X f_n\,d\mu=\infty$ for all $n$ . Is this correct?","Suppose is measurable for , , as , for every , and . Prove that then and show that this conclusion does not follow if the condition "" "" is omitted. Let consist of the points at which . By the dominated convergence theorem, Since , , and hence (*) follows. Let , and let be the counting measure. For each , define by Then , and for all . Is this correct?","f_n:X\rightarrow[0,\infty] n=1,2,3,\dots f_1\geq f_2\geq f_3\geq\cdots\geq 0 f_n(x)\rightarrow f(x) n\rightarrow\infty x\in X f_1\in L^1(\mu) \tag{*}\lim_{n\rightarrow\infty}\int_X f_n\,d\mu=\int_X f\,d\mu f_1\in L^1(\mu) E x\in X f_1(x)<\infty \int_E f_n\,d\mu\rightarrow \int_E f\,d\mu\mbox{.} f_1\in L^1(\mu) \mu(E^c)=0 X=\{1,2,3,\dots\} \mu n f_n:X\rightarrow[0,\infty] f_n(x)=\left\{\begin{array}{ll}\infty&(x\geq n)\\0&(x<n).\end{array}\right. \lim f_n=0 \int_X f_n\,d\mu=\infty n",['measure-theory']
3,$E$ measurable implies $\forall \varepsilon>0\exists A\in\mathcal S_\delta$ s.t. $A\subseteq E$ and $\mu^*(E\smallsetminus A)<\varepsilon$.,measurable implies  s.t.  and .,E \forall \varepsilon>0\exists A\in\mathcal S_\delta A\subseteq E \mu^*(E\smallsetminus A)<\varepsilon,"From Royden's Real Analysis 4th edition, section 17.5, problem 36: Let $\mu$ be a finite premeasure on an algebra $\mathcal S$ , and $\mu^*$ the induced outer measure. Show that a subset $E$ of $X$ is $\mu^*$ -measurable if and only if for each $\varepsilon>0$ there is a set $A\in\mathcal S_\delta$ , $A\subseteq E$ , such that $\mu^*(E\smallsetminus A)<\varepsilon$ . Primarily my question is: is this even true?  This seems like it's stated backward.  I'm a noob so maybe I have this wrong, but since $\mathcal S_\delta$ is the set of all intersections of sets in $\mathcal S$ , then I would have thought that we were looking for a set $E\subseteq A$ .  When I try to do the proof that seems like the direction that pops out naturally.  Also, in section 2.4 where there is a corresponding proof for the Lebesgue measure, we claim ""There is a $G_\delta$ set $G$ containing $E$ for which ..."" But when I look up the errata, this is not mentioned in it. If the answer is ""the book stated it correctly"" then I'd appreciate a hint.  I've tried using the sequence of sets such that $\mu^*(E)-\varepsilon < \sum \mu^*(E_k)$ where $\{E_k\}$ covers $E$ .  Intersecting these seems like a dead-end.  I could union them, prove the theorem for $E\subseteq B$ , and then try to use $B$ to construct $A$ .  But any way that I can see of doing that, I lose the property that $A\in \mathcal S_\delta$ .","From Royden's Real Analysis 4th edition, section 17.5, problem 36: Let be a finite premeasure on an algebra , and the induced outer measure. Show that a subset of is -measurable if and only if for each there is a set , , such that . Primarily my question is: is this even true?  This seems like it's stated backward.  I'm a noob so maybe I have this wrong, but since is the set of all intersections of sets in , then I would have thought that we were looking for a set .  When I try to do the proof that seems like the direction that pops out naturally.  Also, in section 2.4 where there is a corresponding proof for the Lebesgue measure, we claim ""There is a set containing for which ..."" But when I look up the errata, this is not mentioned in it. If the answer is ""the book stated it correctly"" then I'd appreciate a hint.  I've tried using the sequence of sets such that where covers .  Intersecting these seems like a dead-end.  I could union them, prove the theorem for , and then try to use to construct .  But any way that I can see of doing that, I lose the property that .",\mu \mathcal S \mu^* E X \mu^* \varepsilon>0 A\in\mathcal S_\delta A\subseteq E \mu^*(E\smallsetminus A)<\varepsilon \mathcal S_\delta \mathcal S E\subseteq A G_\delta G E \mu^*(E)-\varepsilon < \sum \mu^*(E_k) \{E_k\} E E\subseteq B B A A\in \mathcal S_\delta,"['real-analysis', 'measure-theory', 'outer-measure']"
4,"How are we supposed to show existence of a delta function on a linear subspace of $C[0,1]$ without reference to the Riesz representation?",How are we supposed to show existence of a delta function on a linear subspace of  without reference to the Riesz representation?,"C[0,1]","Royden leaves the following as an exercise: Let $X$ be a linear subspace of $C[0,1]$ that is closed as a subset of $L^2[0,1]$ . $X$ is closed, and there is a constant $M$ such that $\|f\|_\infty\le M\|f\|_2,\,\|f\|_2\le\|f\|_\infty$ for all $f\in X$ . Show that for all $y\in[0,1]$ , there is a function $k_y\in L^2[0,1]$ with $f(y)=\int_0^1k_y(x)f(x)\,\mathrm{d}x$ for all $f\in X$ . This comes after a chapter on basic linear operator theory, with theorems like the open mapping and closed graph theorems covered, and some lemmas on when we can know if an operator is continuous/open, and also some theorems on the isomorphy of finite dimensional linear spaces with $\Bbb R^n$ . I have studied more measure theory than is covered thus far in Royden's book, and I have seen the proof of the Riesz representation theorem and I can tell you that since $T_y\in L^2[0,1]^*$ , $T_y:f\mapsto f(y)$ is a continuous linear functional on the subset $X$ (by extreme value theorem), it must have the representation $k_y\in L^2[0,1]$ as the $L^p$ -conjugate of $2$ is again $2$ - I hope I'm using this theorem right. So there is an immediate and rather too powerful solution. Royden does not cover this theorem until much later in the book I believe, yet he expects students to find, or show the existence of, such a delta-esque function $k_y$ using basic linear operator theory. What was the solution he had in mind? I'd be happy with any linear theoretic solution really, since knowing exactly what Royden intended is hard! I just expect one can get away with arguments weaker than the Riesz Representation theorem.","Royden leaves the following as an exercise: Let be a linear subspace of that is closed as a subset of . is closed, and there is a constant such that for all . Show that for all , there is a function with for all . This comes after a chapter on basic linear operator theory, with theorems like the open mapping and closed graph theorems covered, and some lemmas on when we can know if an operator is continuous/open, and also some theorems on the isomorphy of finite dimensional linear spaces with . I have studied more measure theory than is covered thus far in Royden's book, and I have seen the proof of the Riesz representation theorem and I can tell you that since , is a continuous linear functional on the subset (by extreme value theorem), it must have the representation as the -conjugate of is again - I hope I'm using this theorem right. So there is an immediate and rather too powerful solution. Royden does not cover this theorem until much later in the book I believe, yet he expects students to find, or show the existence of, such a delta-esque function using basic linear operator theory. What was the solution he had in mind? I'd be happy with any linear theoretic solution really, since knowing exactly what Royden intended is hard! I just expect one can get away with arguments weaker than the Riesz Representation theorem.","X C[0,1] L^2[0,1] X M \|f\|_\infty\le M\|f\|_2,\,\|f\|_2\le\|f\|_\infty f\in X y\in[0,1] k_y\in L^2[0,1] f(y)=\int_0^1k_y(x)f(x)\,\mathrm{d}x f\in X \Bbb R^n T_y\in L^2[0,1]^* T_y:f\mapsto f(y) X k_y\in L^2[0,1] L^p 2 2 k_y","['real-analysis', 'measure-theory', 'linear-transformations', 'operator-theory', 'riesz-representation-theorem']"
5,"A question about the ""dominated"" part of the DCT","A question about the ""dominated"" part of the DCT",,"Let $f_n:\mathbb{R}\to [0, \infty)$ be a sequence of measurable functions that converges to some function $f$ . Suppose that I show that for "" $n$ big enough"" we have $|f_n(x)|\le g(x)$ for all $x\in \mathbb{R}$ . Am I right in saying that I can still apply the DCT to conclude that $\displaystyle\lim\limits_{n\to\infty}\int_{\mathbb{R}}f_nd\lambda=\int_{\mathbb{R}}fd\lambda$ ? I think that I can do this simply because I am removing a finite number of terms from my sequence $\displaystyle \int_{\mathbb{R}}f_nd\lambda$ and then I am applying DCT. Is this right?","Let be a sequence of measurable functions that converges to some function . Suppose that I show that for "" big enough"" we have for all . Am I right in saying that I can still apply the DCT to conclude that ? I think that I can do this simply because I am removing a finite number of terms from my sequence and then I am applying DCT. Is this right?","f_n:\mathbb{R}\to [0, \infty) f n |f_n(x)|\le g(x) x\in \mathbb{R} \displaystyle\lim\limits_{n\to\infty}\int_{\mathbb{R}}f_nd\lambda=\int_{\mathbb{R}}fd\lambda \displaystyle \int_{\mathbb{R}}f_nd\lambda","['real-analysis', 'measure-theory']"
6,"If $f,g$ are measurable and $\Phi$ is continuous, then $\Phi(f(x),g(x))$ is measurable.","If  are measurable and  is continuous, then  is measurable.","f,g \Phi \Phi(f(x),g(x))","Let $E\subseteq\mathbb{R}^d$ be a (Lebesgue) measurable set and let $f,g$ be two measurable functions defined on E. I would like to show that if $\Phi$ is a continuous function on $\mathbb{R}^2$ , then the function $h:x\mapsto\Phi(f(x),g(x))$ is measurable. The proof remains unknown to me, but I can address the problem if it is only one-dimensional. Specifically, if $\Phi$ is a continuous function on $\mathbb{R}$ , then I can show that $\Phi\circ f$ is measurable. Indeed, since $\{\Phi<a\}$ is an open set $G$ , we can conclude that $\{\Phi\circ f<a\}=f^{-1}(G)$ is measurable. How about the two-dimensional problem? Does anyone have an idea? Thank you.","Let be a (Lebesgue) measurable set and let be two measurable functions defined on E. I would like to show that if is a continuous function on , then the function is measurable. The proof remains unknown to me, but I can address the problem if it is only one-dimensional. Specifically, if is a continuous function on , then I can show that is measurable. Indeed, since is an open set , we can conclude that is measurable. How about the two-dimensional problem? Does anyone have an idea? Thank you.","E\subseteq\mathbb{R}^d f,g \Phi \mathbb{R}^2 h:x\mapsto\Phi(f(x),g(x)) \Phi \mathbb{R} \Phi\circ f \{\Phi<a\} G \{\Phi\circ f<a\}=f^{-1}(G)","['real-analysis', 'measure-theory', 'lebesgue-measure']"
7,The domain of the Haar measure of the $n$-dimensional Torus,The domain of the Haar measure of the -dimensional Torus,n,"I'm trying to find the Haar measure of the $n$ -dimensional Torus. To find this measure I'm using the notion of pushforward measure of the Lebesgue measure. To understand my question please consider the information below: Let $\mathbb{T}^n:=\mathbb{R}^n/\mathbb{Z}^n$ be the quotient of the group $(\mathbb{R}^n,+)$ by the subgroup $(\mathbb{Z}^n,+)$ . Define $d _{\mathbb{T}^n}:\mathbb{T}^n\times \mathbb{T}^n\to\mathbb{R}$ by $d_{\mathbb{T}^n}(x+\mathbb{Z}^n,y+\mathbb{Z}^n) :=\inf \big\{\Vert x-y+ k\Vert _n:k\in\mathbb{Z}^n\big\}$ . We can show that $(\mathbb{T}^n,d _{\mathbb{T}^n})$ is a metric space and that $\mathbb{T}^n$ is a abelian compact group with respect to that metric. We can also show that $\pi  :\mathbb{R}^n\to \mathbb{T}^n$ given by $\pi (x):=x+\mathbb{Z}^n$ is an open Lipschitz continuous map. Define $\pi_\star \mathfrak{B}_n :=\big\{B\subseteq\mathbb{T}^n:\pi ^{-1}[B]\in \mathfrak{B}_n\big\} $ in which $\mathfrak{B}_n$ is the Borel $\sigma$ -algebra of $\mathbb{R}^n$ . Suppose that $\mathfrak{B}_{\mathbb{T}^n}$ is the Borel $\sigma$ -algebra of $(\mathbb{T}^n,d _{\mathbb{T}^n})$ . My question is: does the equality $\mathfrak{B}_{\mathbb{T}^n}=\pi _\star \mathfrak{B}_n$ hold? It's easy to show that $\mathfrak{B}_{\mathbb{T}^n}\subseteq \pi _\star \mathfrak{B}_n$ since $\pi$ is a measurable map. However I don't know if $\pi_\star \mathfrak{B}_n\subseteq \mathfrak{B}_{\mathbb{T}^n}$ . Thank you for your attention.",I'm trying to find the Haar measure of the -dimensional Torus. To find this measure I'm using the notion of pushforward measure of the Lebesgue measure. To understand my question please consider the information below: Let be the quotient of the group by the subgroup . Define by . We can show that is a metric space and that is a abelian compact group with respect to that metric. We can also show that given by is an open Lipschitz continuous map. Define in which is the Borel -algebra of . Suppose that is the Borel -algebra of . My question is: does the equality hold? It's easy to show that since is a measurable map. However I don't know if . Thank you for your attention.,"n \mathbb{T}^n:=\mathbb{R}^n/\mathbb{Z}^n (\mathbb{R}^n,+) (\mathbb{Z}^n,+) d _{\mathbb{T}^n}:\mathbb{T}^n\times \mathbb{T}^n\to\mathbb{R} d_{\mathbb{T}^n}(x+\mathbb{Z}^n,y+\mathbb{Z}^n) :=\inf \big\{\Vert x-y+ k\Vert _n:k\in\mathbb{Z}^n\big\} (\mathbb{T}^n,d _{\mathbb{T}^n}) \mathbb{T}^n \pi  :\mathbb{R}^n\to \mathbb{T}^n \pi (x):=x+\mathbb{Z}^n \pi_\star \mathfrak{B}_n :=\big\{B\subseteq\mathbb{T}^n:\pi ^{-1}[B]\in \mathfrak{B}_n\big\}  \mathfrak{B}_n \sigma \mathbb{R}^n \mathfrak{B}_{\mathbb{T}^n} \sigma (\mathbb{T}^n,d _{\mathbb{T}^n}) \mathfrak{B}_{\mathbb{T}^n}=\pi _\star \mathfrak{B}_n \mathfrak{B}_{\mathbb{T}^n}\subseteq \pi _\star \mathfrak{B}_n \pi \pi_\star \mathfrak{B}_n\subseteq \mathfrak{B}_{\mathbb{T}^n}","['measure-theory', 'measurable-functions', 'borel-sets', 'borel-measures', 'haar-measure']"
8,"What does ""almost everywhere invertible"" mean?","What does ""almost everywhere invertible"" mean?",,"I'm reading the paper On differentiability in the Wasserstein space and well-posedness for Hamilton–Jacobi equations in which there is a paragraph There is a special non-commutative group related to the isometry $\sharp: \mathbb{H} / \sharp \rightarrow \mathcal{P}_{2}\left(\mathbb{R}^{d}\right)$ , namely the set $\mathcal{G}(\Omega)$ of Borel maps $S: \Omega \rightarrow \Omega$ (they lie in $\mathbb{H}$ ) that are almost everywhere invertible and have the same law as the identity map $\operatorname{id}$ . Here $\Omega$ is the ball of unit volume in $\mathbb{R}^{d}$ , centered at the origin. $\mathbb{H}:=L^{2}\left(\Omega, \mathrm d x, \mathbb{R}^{d}\right)$ . My naïve guess is that ""almost everywhere invertible"" means the Lebesgue measure of $\{\omega \in \Omega \mid \operatorname{card}(S^{-1}(\omega)) \le 1\}$ is $1$ . Could you elaborate on this notion?","I'm reading the paper On differentiability in the Wasserstein space and well-posedness for Hamilton–Jacobi equations in which there is a paragraph There is a special non-commutative group related to the isometry , namely the set of Borel maps (they lie in ) that are almost everywhere invertible and have the same law as the identity map . Here is the ball of unit volume in , centered at the origin. . My naïve guess is that ""almost everywhere invertible"" means the Lebesgue measure of is . Could you elaborate on this notion?","\sharp: \mathbb{H} / \sharp \rightarrow \mathcal{P}_{2}\left(\mathbb{R}^{d}\right) \mathcal{G}(\Omega) S: \Omega \rightarrow \Omega \mathbb{H} \operatorname{id} \Omega \mathbb{R}^{d} \mathbb{H}:=L^{2}\left(\Omega, \mathrm d x, \mathbb{R}^{d}\right) \{\omega \in \Omega \mid \operatorname{card}(S^{-1}(\omega)) \le 1\} 1","['measure-theory', 'definition', 'inverse-function']"
9,Relation between absolute continuity with respect to lebesgue measure and integral,Relation between absolute continuity with respect to lebesgue measure and integral,,"Let $f:X \to \mathbb{R}$ be a continuous function on a compact metric space $X$ . Assume that a Borel probability measure $\mu$ is absolutely continuous with respect to Lebesgue measure $\text{Leb}.$ Is it true that if $f(x)<0$ for $\text{Leb}$ a.e. $x$ , then $\int f d\mu<0?$ I think it should be true as $\mu << \text{Leb}$ . Attempt: Assume that $\int fd\mu\geq 0$ . Then $f\geq 0$ $\mu$ a.e. $x$ . That means $\mu(\{x: f(x)>0\})>0$ . That implies $\text{Leb}((\{x: f(x)>0\})>0$ which is not true.","Let be a continuous function on a compact metric space . Assume that a Borel probability measure is absolutely continuous with respect to Lebesgue measure Is it true that if for a.e. , then I think it should be true as . Attempt: Assume that . Then a.e. . That means . That implies which is not true.",f:X \to \mathbb{R} X \mu \text{Leb}. f(x)<0 \text{Leb} x \int f d\mu<0? \mu << \text{Leb} \int fd\mu\geq 0 f\geq 0 \mu x \mu(\{x: f(x)>0\})>0 \text{Leb}((\{x: f(x)>0\})>0,"['functional-analysis', 'measure-theory']"
10,Question about an exercise in my Measure Theory book.,Question about an exercise in my Measure Theory book.,,"There's an exercise in my book that states the following: Let $\mu_0 (A) = \mu(A \cup A_0),\,A \in \mathcal{F}$ be a measure. Show that if $$\int f \,d\mu$$ exists, then $$\int_{A_0} f\,d\mu = \int f\,d_{\mu_0}$$ However, I think there's a typo in this exercise. $\mu_0$ isn't even a measure when $\mu(A_0) \neq 0$ , since $\mu_0(\varnothing) = \mu(A_0)$ . If it were $\mu_0(A) = \mu(A \cap A_0)$ , which I think that's what the author meant, I could prove it in the following way: For simple functions, $$\int_{A_0}f\,d\mu = \int f\mathbf{1}_{A_0}\,d\mu = \sum_{i=1}^{n} f_i \mathbf{1}_{A_0}\mu(A_i) =\sum_{i=1}^{n} f_i\mu(A_i \cap A_0) = \sum_{i=1}^{n} f_i \mu_0(A_i) = \int f\,d\mu_0$$ For a non-negative measurable function $f$ , there's a non-decreasing sequence of simple functions $(s_n)_{n \in \mathbb{N}}$ such that $s_n \rightarrow f$ , then $$\int_{A_0} f\,d\mu= \int f\mathbf{1}_{A_0}\,d\mu = \lim_{n \rightarrow \infty} \int s_n\mathbf{1}_{A_0}\,d\mu = \lim_{n \rightarrow \infty} \int s_n\,d\mu_0 = \int f\,d\mu_0$$ And finally, for any measurable function, we just use $f = f^{+} - f^{-}$ . So, which one is it, $\mu(A \cup A_0)$ or $\mu(A \cap A_0)$ ?","There's an exercise in my book that states the following: Let be a measure. Show that if exists, then However, I think there's a typo in this exercise. isn't even a measure when , since . If it were , which I think that's what the author meant, I could prove it in the following way: For simple functions, For a non-negative measurable function , there's a non-decreasing sequence of simple functions such that , then And finally, for any measurable function, we just use . So, which one is it, or ?","\mu_0 (A) = \mu(A \cup A_0),\,A \in \mathcal{F} \int f \,d\mu \int_{A_0} f\,d\mu = \int f\,d_{\mu_0} \mu_0 \mu(A_0) \neq 0 \mu_0(\varnothing) = \mu(A_0) \mu_0(A) = \mu(A \cap A_0) \int_{A_0}f\,d\mu = \int f\mathbf{1}_{A_0}\,d\mu = \sum_{i=1}^{n} f_i \mathbf{1}_{A_0}\mu(A_i) =\sum_{i=1}^{n} f_i\mu(A_i \cap A_0) = \sum_{i=1}^{n} f_i \mu_0(A_i) = \int f\,d\mu_0 f (s_n)_{n \in \mathbb{N}} s_n \rightarrow f \int_{A_0} f\,d\mu= \int f\mathbf{1}_{A_0}\,d\mu = \lim_{n \rightarrow \infty} \int s_n\mathbf{1}_{A_0}\,d\mu = \lim_{n \rightarrow \infty} \int s_n\,d\mu_0 = \int f\,d\mu_0 f = f^{+} - f^{-} \mu(A \cup A_0) \mu(A \cap A_0)","['measure-theory', 'lebesgue-integral']"
11,Bound on variation $|F(x)-F(y)|$ where $F$ is Cantor's function,Bound on variation  where  is Cantor's function,|F(x)-F(y)| F,"Let $F$ be Cantor's function. Prove that there exists some $C>0$ s.t for all $x,y\in[0,1]$ $$|F(x)-F(y)|\leq C|x-y|^\alpha$$ Where $\alpha=\log_3 2$ . My direction of thought was to use the definition of F as $$F(x):=\lim_{n\to\infty}\int_{0}^{x}g_n(t)dt$$ $$g_{n}(x):=\begin{cases} \left(\frac{3}{2}\right)^{n} & x\in C_{n}\\ 0 & x\notin C_{n} \end{cases}$$ and try to find some bound $A$ on the amount of sub-segments of $C_{n}$ contained in $[x,y]$ , as then we could say $$\left|F\left(x\right)-F\left(y\right)\right|=\lim_{n\to\infty}\int_{x}^{y}g_{n}(t)dt\leq A\cdot\left(\frac{3}{2}\right)^{n}\cdot3^{-n}$$ because the length of each segment in $C_n$ is $3^{-n}$","Let be Cantor's function. Prove that there exists some s.t for all Where . My direction of thought was to use the definition of F as and try to find some bound on the amount of sub-segments of contained in , as then we could say because the length of each segment in is","F C>0 x,y\in[0,1] |F(x)-F(y)|\leq C|x-y|^\alpha \alpha=\log_3 2 F(x):=\lim_{n\to\infty}\int_{0}^{x}g_n(t)dt g_{n}(x):=\begin{cases}
\left(\frac{3}{2}\right)^{n} & x\in C_{n}\\
0 & x\notin C_{n}
\end{cases} A C_{n} [x,y] \left|F\left(x\right)-F\left(y\right)\right|=\lim_{n\to\infty}\int_{x}^{y}g_{n}(t)dt\leq A\cdot\left(\frac{3}{2}\right)^{n}\cdot3^{-n} C_n 3^{-n}","['measure-theory', 'cantor-set']"
12,Measure-theoretic proof of the inverse Fourier transform,Measure-theoretic proof of the inverse Fourier transform,,"I would like to prove this statement: Proposition. (Inverse Fourier transform) Let $u \in L^1_\mathbb{R}(\lambda^n)$ and let us define its Fourier transform as $$\hat{u}(\xi):=(2\pi)^{-n}\int_{\mathbb{R}^n} u(x)e^{-i\langle x,\xi\rangle}dx,\,\xi \in \mathbb{R}^n$$ then if $\hat{u} \in L^1_\mathbb{C}(\lambda^n)$ we have the inversion formula $$u(x)=\int_{\mathbb{R}^n} \hat{u}(\xi)e^{i\langle x,\xi\rangle}d\xi$$ To prove this I would like to use the following lemma: Lemma. Let $\mu$ be a finite measure on $(\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n))$ and assume $$\hat{\mu}(\xi):=(2\pi)^{-n}\int_{\mathbb{R}^n}e^{-i\langle x,\xi\rangle}\mu(dx)\in L^1_\mathbb{C}(\lambda^n)$$ in this case, $\mu(dx)=u(x)dx$ where $$u(x)=\int_{\mathbb{R}^n}\hat{\mu}(\xi)e^{i\langle x,\xi\rangle}d\xi$$ I thought about decomposing $u\in L^1_\mathbb{R}(\lambda^n)$ in positive and negative parts, yielding $u=u^+-u^-$ . As $u^\pm\geq 0,\,u^\pm \in L^1_\mathbb{R}(\lambda^n)$ , we can construct the finite measures $\mu^\pm(dx)=u^\pm(x)dx$ . Assume $\widehat{\mu^\pm}\in L^1_\mathbb{C}(\lambda^n)$ . Using the above lemma: $$u(x)=\int_{\mathbb{R}^n} (\widehat{\mu^+}(\xi)-\widehat{\mu^-}(\xi))e^{i\langle x,\xi\rangle}d\xi$$ My idea is to show $\widehat{\mu^+}(\xi)-\widehat{\mu^-}(\xi)=\hat{u}(\xi)$ : $$\begin{aligned}\widehat{\mu^+}(\xi)-\widehat{\mu^-}(\xi)&=(2\pi)^{-n}\bigg(\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}\mu^+(dx)-\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}\mu^-(dx)\bigg)=\\ &=(2\pi)^{-n}\bigg(\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}u^+(x)dx-\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}u^-(x)dx\bigg)=\\ &=(2\pi)^{-n}\bigg(\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}(u^+(x)-u^-(x))dx\bigg)=\hat{u}(\xi)\end{aligned}$$ so assuming $\widehat{\mu^\pm}\in L^1_\mathbb{C}(\lambda^n)$ is equivalent to assuming $\hat{u}\in L^1_\mathbb{C}(\lambda^n)$ . Is this approach correct, or did I miss something? Thank you very much for your help.","I would like to prove this statement: Proposition. (Inverse Fourier transform) Let and let us define its Fourier transform as then if we have the inversion formula To prove this I would like to use the following lemma: Lemma. Let be a finite measure on and assume in this case, where I thought about decomposing in positive and negative parts, yielding . As , we can construct the finite measures . Assume . Using the above lemma: My idea is to show : so assuming is equivalent to assuming . Is this approach correct, or did I miss something? Thank you very much for your help.","u \in L^1_\mathbb{R}(\lambda^n) \hat{u}(\xi):=(2\pi)^{-n}\int_{\mathbb{R}^n} u(x)e^{-i\langle x,\xi\rangle}dx,\,\xi \in \mathbb{R}^n \hat{u} \in L^1_\mathbb{C}(\lambda^n) u(x)=\int_{\mathbb{R}^n} \hat{u}(\xi)e^{i\langle x,\xi\rangle}d\xi \mu (\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n)) \hat{\mu}(\xi):=(2\pi)^{-n}\int_{\mathbb{R}^n}e^{-i\langle x,\xi\rangle}\mu(dx)\in L^1_\mathbb{C}(\lambda^n) \mu(dx)=u(x)dx u(x)=\int_{\mathbb{R}^n}\hat{\mu}(\xi)e^{i\langle x,\xi\rangle}d\xi u\in L^1_\mathbb{R}(\lambda^n) u=u^+-u^- u^\pm\geq 0,\,u^\pm \in L^1_\mathbb{R}(\lambda^n) \mu^\pm(dx)=u^\pm(x)dx \widehat{\mu^\pm}\in L^1_\mathbb{C}(\lambda^n) u(x)=\int_{\mathbb{R}^n} (\widehat{\mu^+}(\xi)-\widehat{\mu^-}(\xi))e^{i\langle x,\xi\rangle}d\xi \widehat{\mu^+}(\xi)-\widehat{\mu^-}(\xi)=\hat{u}(\xi) \begin{aligned}\widehat{\mu^+}(\xi)-\widehat{\mu^-}(\xi)&=(2\pi)^{-n}\bigg(\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}\mu^+(dx)-\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}\mu^-(dx)\bigg)=\\
&=(2\pi)^{-n}\bigg(\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}u^+(x)dx-\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}u^-(x)dx\bigg)=\\
&=(2\pi)^{-n}\bigg(\int_{\mathbb{R}^n} e^{-i\langle x,\xi\rangle}(u^+(x)-u^-(x))dx\bigg)=\hat{u}(\xi)\end{aligned} \widehat{\mu^\pm}\in L^1_\mathbb{C}(\lambda^n) \hat{u}\in L^1_\mathbb{C}(\lambda^n)","['real-analysis', 'measure-theory', 'lebesgue-integral', 'fourier-transform']"
13,Why do we need hypothesis of complete measure in this version of Fubini's theorem?,Why do we need hypothesis of complete measure in this version of Fubini's theorem?,,"I'm reading below Fubini's theorem in page 3 of this lecture note. Let $(X, \mathcal{A}, \mu)$ and $(Y, \mathcal{B}, \nu)$ be complete measure spaces, let $\gamma$ be the product outer measure on $X \times Y$ constructed above, and suppose that $f: X \times Y \rightarrow \mathbb{R}$ is $\gamma$ -integrable. Then (i) $f(x, y)$ is a $\mu$ -integrable function of $x$ for $\nu$ -a.e. $y \in Y$ ; (ii) $\int_{X} f(x, y) d \mu(x)$ is a $\nu$ -integrable function of y; (iii) $\int_{Y}\left(\int_{X} f(x, y) d \mu(x)\right) d \nu(y)=\int_{X \times Y} f(x, y) d \gamma$ . In the proof, $C$ is a $\gamma$ -measurable set of finite measure. For all $j$ , $\left\{A_{i}^{j} \times B_{i}^{j}\mid i=1,2, \ldots\right\}$ is pairwise disjoint family of $\mathcal{A}, \mathcal{B}$ rectangles. $E=\cap_{j}\left(\cup_{i} A_{i}^{j} \times B_{i}^{j}\right) \setminus C$ . In my understanding, $E = \left [\cap_{j}\left(\cup_{i} A_{i}^{j} \times B_{i}^{j}\right) \right] \cap C^c$ is $\gamma$ -measurable. Hence the $y$ -slice $E_y$ of $E$ defined by $$E_y \triangleq \{x \in X \mid (x, y) \in E\}$$ is also measurable by the lemma in this question. I mean by this lemma that we don't need the hypothesis of measure completeness to obtain the measurability of $E_y$ . However, the author said that But $\left.E \subset \cap\left(\cup_{i} E_{i}^{j} \times F_{i}^{j}\right)\right)$ and $\nu$ is a complete measure , so the slice $\{x:(x, y) \in E\}$ is also in $\mathcal{A}$ and also has $\mu$ -measure zero for $\nu$ -a.e. $y \in E$ . So they mean the measure completeness is necessary for the slice $E_y$ to be measurable. Could you please elaborate on my confusion?","I'm reading below Fubini's theorem in page 3 of this lecture note. Let and be complete measure spaces, let be the product outer measure on constructed above, and suppose that is -integrable. Then (i) is a -integrable function of for -a.e. ; (ii) is a -integrable function of y; (iii) . In the proof, is a -measurable set of finite measure. For all , is pairwise disjoint family of rectangles. . In my understanding, is -measurable. Hence the -slice of defined by is also measurable by the lemma in this question. I mean by this lemma that we don't need the hypothesis of measure completeness to obtain the measurability of . However, the author said that But and is a complete measure , so the slice is also in and also has -measure zero for -a.e. . So they mean the measure completeness is necessary for the slice to be measurable. Could you please elaborate on my confusion?","(X, \mathcal{A}, \mu) (Y, \mathcal{B}, \nu) \gamma X \times Y f: X \times Y \rightarrow \mathbb{R} \gamma f(x, y) \mu x \nu y \in Y \int_{X} f(x, y) d \mu(x) \nu \int_{Y}\left(\int_{X} f(x, y) d \mu(x)\right) d \nu(y)=\int_{X \times Y} f(x, y) d \gamma C \gamma j \left\{A_{i}^{j} \times B_{i}^{j}\mid i=1,2, \ldots\right\} \mathcal{A}, \mathcal{B} E=\cap_{j}\left(\cup_{i} A_{i}^{j} \times B_{i}^{j}\right) \setminus C E = \left [\cap_{j}\left(\cup_{i} A_{i}^{j} \times B_{i}^{j}\right) \right] \cap C^c \gamma y E_y E E_y \triangleq \{x \in X \mid (x, y) \in E\} E_y \left.E \subset \cap\left(\cup_{i} E_{i}^{j} \times F_{i}^{j}\right)\right) \nu \{x:(x, y) \in E\} \mathcal{A} \mu \nu y \in E E_y","['measure-theory', 'proof-explanation', 'outer-measure', 'fubini-tonelli-theorems']"
14,Convergence in $\mathcal{M}$ implies convergence in measure on sets of finite measure,Convergence in  implies convergence in measure on sets of finite measure,\mathcal{M},"Let $(\Omega,\mathcal{A},\mu)$ be a $\sigma$ -finite measure space such that $\Omega= \bigcup_{n=1}^\infty A_n$ where $\mu(A_n)<\infty$ for all $n \in \mathbb{N}$ . Denote by $\mathcal{M}$ the set of all scalar valued $\mu$ -measurable functions on $\Omega$ that are finite $\mu$ -a.e. I know that $d(f,g)= \sum_{n=1}^{\infty} \frac{1}{2^n} \cdot \frac{1}{\mu(A_n)} \cdot \int_{A_n}\frac{|f-g|}{1+|f-g|}d\mu$ defines a metric in $\mathcal{M}$ and I want to prove that if $d(f_m,f) \rightarrow 0$ , then $f_m \rightarrow f$ in measure on sets of finite measure (I have already proved the converse). My attempt We assume that $d(f_m,f) \rightarrow 0$ as $m \rightarrow + \infty$ . Let $\varepsilon>0$ and $D \subset \Omega$ have finite measure. We can write $\{x \in D:|f_m(x)-f(x)| \geq \varepsilon\}= \bigcup_{n=1}^{\infty}(A_n \cap \{x \in D:|f_m(x)-f(x)|\geq \varepsilon\})$ so that \begin{equation} \begin{split} \frac{\varepsilon}{1+ \varepsilon} \mu(\{x \in D:|f_m(x)-f(x)| \geq \varepsilon\}) &\leq \sum_{n=1}^{\infty} \frac{\varepsilon}{1+ \varepsilon}\mu(A_n \cap \{x \in D:|f_m(x)-f(x)| \geq \varepsilon\})\\ &= \sum_{n=1}^{\infty} \int_{A_n \cap \{x \in D:|f_m(x)-f(x)| \geq \varepsilon\}} \frac{\varepsilon}{1+ \varepsilon} d\mu\\ &\leq \sum_{n=1}^{\infty} \int_{A_n } \frac{|f_m-f|}{1+ |f_m-f|} d\mu \end{split} \end{equation} where I don't know how to continue due to the lack of the terms $\frac{1}{2^n} \cdot \frac{1}{\mu(A_n)}$ . If those were inside the sum, then the assumption $d(f_m,f) \rightarrow 0$ would  give the desired result.","Let be a -finite measure space such that where for all . Denote by the set of all scalar valued -measurable functions on that are finite -a.e. I know that defines a metric in and I want to prove that if , then in measure on sets of finite measure (I have already proved the converse). My attempt We assume that as . Let and have finite measure. We can write so that where I don't know how to continue due to the lack of the terms . If those were inside the sum, then the assumption would  give the desired result.","(\Omega,\mathcal{A},\mu) \sigma \Omega= \bigcup_{n=1}^\infty A_n \mu(A_n)<\infty n \in \mathbb{N} \mathcal{M} \mu \Omega \mu d(f,g)= \sum_{n=1}^{\infty} \frac{1}{2^n} \cdot \frac{1}{\mu(A_n)} \cdot \int_{A_n}\frac{|f-g|}{1+|f-g|}d\mu \mathcal{M} d(f_m,f) \rightarrow 0 f_m \rightarrow f d(f_m,f) \rightarrow 0 m \rightarrow + \infty \varepsilon>0 D \subset \Omega \{x \in D:|f_m(x)-f(x)| \geq \varepsilon\}= \bigcup_{n=1}^{\infty}(A_n \cap \{x \in D:|f_m(x)-f(x)|\geq \varepsilon\}) \begin{equation}
\begin{split}
\frac{\varepsilon}{1+ \varepsilon} \mu(\{x \in D:|f_m(x)-f(x)| \geq \varepsilon\}) &\leq \sum_{n=1}^{\infty} \frac{\varepsilon}{1+ \varepsilon}\mu(A_n \cap \{x \in D:|f_m(x)-f(x)| \geq \varepsilon\})\\
&= \sum_{n=1}^{\infty} \int_{A_n \cap \{x \in D:|f_m(x)-f(x)| \geq \varepsilon\}} \frac{\varepsilon}{1+ \varepsilon} d\mu\\
&\leq \sum_{n=1}^{\infty} \int_{A_n } \frac{|f_m-f|}{1+ |f_m-f|} d\mu
\end{split}
\end{equation} \frac{1}{2^n} \cdot \frac{1}{\mu(A_n)} d(f_m,f) \rightarrow 0","['measure-theory', 'convergence-divergence', 'metric-spaces']"
15,Simplify: $[ (A_1 \cap B_1) \times A_2 \times \dotsb \times A_n ] \cup \dotsb \cup [ A_1 \times \dotsb \times A_{n-1} \times (A_n \cap B_n) ]$,Simplify:,[ (A_1 \cap B_1) \times A_2 \times \dotsb \times A_n ] \cup \dotsb \cup [ A_1 \times \dotsb \times A_{n-1} \times (A_n \cap B_n) ],"I've just started studying Measure Theory. I was a little bit stuck on simplifying a set theoretic expression when I tried to prove a little problem from my reference book. Here I pose my problem in a general set theoretic manner: Given two finite families of indexed sets $\{A_k\}_{k=1}^n$ and $\{B_k\}_{k=1}^n$ , for some $n \in \mathbb{N}$ . Can we simplify $$ \tag{1} \Big[ (A_1 \cap B_1) \times A_2 \times \dotsb \times A_n \Big] \cup \dotsb \cup \Big[ A_1 \times \dotsb \times A_{n-1} \times (A_n \cap B_n) \Big]  $$ into a form of large union operation? Here is my attempt: I directly put the large union operation into the following expression: $$ \tag{2} \bigcup_{k=1}^n \left[ \left( \prod_{\alpha=1}^{k - 1} A_\alpha \right) \times \big( A_k \cap B_k \big) \times \left( \prod_{\beta = k + 1}^{n} A_\beta \right) \right] $$ My concern is, when $k = 1$ , we have $$ \tag{3} \left( \prod_{\alpha = 1}^0 A_\alpha \right) \times (A_1 \cap B_1) \times \left( \prod_{\beta = 2}^n A_\beta \right) $$ and when $k = n$ we have $$ \tag{4} \left( \prod_{\alpha = 1}^{n-1} A_\alpha \right) \times (A_n \cap B_n) \times \left( \prod_{\beta = n+1}^n A_\beta \right) $$ within the square braces, each of which is syntactically error. I presume $$ \tag{5} \prod_{\alpha = 1}^0 A_\alpha = \prod_{\varnothing} A_\alpha $$ and $$ \tag{6} \prod_{\beta = n+1}^n A_\beta = \prod_{\varnothing} A_\beta $$ and hence expression $(2)$ is precisely equal to expression $(1)$ . My big question is: $\textbf{are these presumptions allowed?}$ If it's not the case, then is there any better solution instead of writing down expression $(1)$ ? Any help is highly appreciated. Thank you.","I've just started studying Measure Theory. I was a little bit stuck on simplifying a set theoretic expression when I tried to prove a little problem from my reference book. Here I pose my problem in a general set theoretic manner: Given two finite families of indexed sets and , for some . Can we simplify into a form of large union operation? Here is my attempt: I directly put the large union operation into the following expression: My concern is, when , we have and when we have within the square braces, each of which is syntactically error. I presume and and hence expression is precisely equal to expression . My big question is: If it's not the case, then is there any better solution instead of writing down expression ? Any help is highly appreciated. Thank you.","\{A_k\}_{k=1}^n \{B_k\}_{k=1}^n n \in \mathbb{N}  \tag{1}
\Big[ (A_1 \cap B_1) \times A_2 \times \dotsb \times A_n \Big] \cup \dotsb \cup
\Big[ A_1 \times \dotsb \times A_{n-1} \times (A_n \cap B_n) \Big] 
  \tag{2}
\bigcup_{k=1}^n \left[ \left( \prod_{\alpha=1}^{k - 1} A_\alpha \right) \times \big( A_k
\cap B_k \big) \times \left( \prod_{\beta = k + 1}^{n} A_\beta \right) \right]
 k = 1  \tag{3}
\left( \prod_{\alpha = 1}^0 A_\alpha \right) \times (A_1 \cap B_1) \times
\left( \prod_{\beta = 2}^n A_\beta \right)
 k = n  \tag{4}
\left( \prod_{\alpha = 1}^{n-1} A_\alpha \right) \times (A_n \cap B_n) \times
\left( \prod_{\beta = n+1}^n A_\beta \right)
  \tag{5}
\prod_{\alpha = 1}^0 A_\alpha = \prod_{\varnothing} A_\alpha
  \tag{6}
\prod_{\beta = n+1}^n A_\beta = \prod_{\varnothing} A_\beta
 (2) (1) \textbf{are these presumptions allowed?} (1)","['measure-theory', 'elementary-set-theory']"
16,Does positive joint probability imply positivity of a conditional event?,Does positive joint probability imply positivity of a conditional event?,,"I have very little experience with probability so apologies if the title is confusing!! Let $\mu, \nu$ be probability measures on measure spaces $X,Y$ (if helpful we can assume $X = Y$ are compact subsets of $\mathbb{R}^d$ , but I don't want to place any assumptions involving absolute continuity of $\mu, \nu$ w.r.t. Lebesgue). Let $\Gamma(\mu, \nu)$ denote the set of all probability measures on $X \times Y$ with marginals $\mu, \nu$ , i.e. for all $A \subseteq X$ and $B \subseteq Y$ we have $\gamma(A \times Y) = \mu(A)$ and $\gamma(X \times B) = \nu(B)$ . Fix an arbitrary $\gamma \in \Gamma(\mu, \nu)$ and let $E \subseteq X \times Y$ such that $\gamma(E) > 0$ . For all $x \in X$ and $y \in Y$ let $E_x = \{y \in Y \mid (x,y) \in E\}$ and $E^y = \{x \mid (x,y) \in E\}$ . Then does $\gamma(E) > 0$ give us that there always exist $x \in X$ (alternatively, $y \in Y$ ) such that $\nu(E_x) > 0$ (alternatively, $\mu(E^y) > 0$ )? I can see this is true when $\gamma$ is the product measure (see, e.g., Folland 2.36) but I'm not seeing how to generalize the proof. By the disintegration theorem ( https://en.wikipedia.org/wiki/Disintegration_theorem ) we can get things like $$ \gamma(E) = \int_Y \gamma_y(E)\ \mathrm{d} \nu(y) $$ and $$ \gamma(E) = \int_X \gamma_x(E)\ \mathrm{d} \mu(x), $$ whence we know $\gamma_y(E) > 0$ for $\nu$ -a.e. $y$ and $\gamma_x(E) > 0$ for $\mu$ -a.e. $x$ . But it's not clear to me how to turn these into statements about $\mu(E^y)$ and $\nu(E_x)$ , respectively...any advice? Thank you!!","I have very little experience with probability so apologies if the title is confusing!! Let be probability measures on measure spaces (if helpful we can assume are compact subsets of , but I don't want to place any assumptions involving absolute continuity of w.r.t. Lebesgue). Let denote the set of all probability measures on with marginals , i.e. for all and we have and . Fix an arbitrary and let such that . For all and let and . Then does give us that there always exist (alternatively, ) such that (alternatively, )? I can see this is true when is the product measure (see, e.g., Folland 2.36) but I'm not seeing how to generalize the proof. By the disintegration theorem ( https://en.wikipedia.org/wiki/Disintegration_theorem ) we can get things like and whence we know for -a.e. and for -a.e. . But it's not clear to me how to turn these into statements about and , respectively...any advice? Thank you!!","\mu, \nu X,Y X = Y \mathbb{R}^d \mu, \nu \Gamma(\mu, \nu) X \times Y \mu, \nu A \subseteq X B \subseteq Y \gamma(A \times Y) = \mu(A) \gamma(X \times B) = \nu(B) \gamma \in \Gamma(\mu, \nu) E \subseteq X \times Y \gamma(E) > 0 x \in X y \in Y E_x = \{y \in Y \mid (x,y) \in E\} E^y = \{x \mid (x,y) \in E\} \gamma(E) > 0 x \in X y \in Y \nu(E_x) > 0 \mu(E^y) > 0 \gamma 
\gamma(E) = \int_Y \gamma_y(E)\ \mathrm{d} \nu(y)
 
\gamma(E) = \int_X \gamma_x(E)\ \mathrm{d} \mu(x),
 \gamma_y(E) > 0 \nu y \gamma_x(E) > 0 \mu x \mu(E^y) \nu(E_x)","['probability', 'measure-theory', 'conditional-probability', 'marginal-probability']"
17,Definition of Sampling,Definition of Sampling,,"I am no expert in statistics, I know statistics at engineering level. I've been reading through measure theory and probability theory lately (still not an expert but definitely more solid than my statistics background at the moment). Suppose you have a measure space $(\Omega,\mathcal{F},\mu)$ where $\mu$ is a probability measure. Suppose $X$ is a random variable. What I am looking for is a rigorous (if there's any) definition of ""sampling"" of that random variable. Or maybe what I am looking is more how to get ""samples"" from a probability distribution (again a rigorous definition). I know a standard ""algorithm"" to perform sampling, however I am more looking for a mathematical definition of sampling. I am either looking for an answer or a some rigorous definition somewhere. Just to give an analogue in signal processing if you have a signal $s : \mathcal{T} \to \mathbb{R}$ (time set to real values) we can define the sampling at rate say $T = \frac{1}{f}$ as $\left\{ s(nT) \right\}_{n \in \mathbb{Z}}$ and this is a well understood mathematical definition to me which I can rephrase as composition of $s$ with the map $I_T : \mathbb{N} \to \mathcal{T}$ that given $n$ returns $nT$ hence $$ s(nT) = \left(s \circ I_T\right)(n) $$ I do struggle however with sampling in probability terms. Can you help?","I am no expert in statistics, I know statistics at engineering level. I've been reading through measure theory and probability theory lately (still not an expert but definitely more solid than my statistics background at the moment). Suppose you have a measure space where is a probability measure. Suppose is a random variable. What I am looking for is a rigorous (if there's any) definition of ""sampling"" of that random variable. Or maybe what I am looking is more how to get ""samples"" from a probability distribution (again a rigorous definition). I know a standard ""algorithm"" to perform sampling, however I am more looking for a mathematical definition of sampling. I am either looking for an answer or a some rigorous definition somewhere. Just to give an analogue in signal processing if you have a signal (time set to real values) we can define the sampling at rate say as and this is a well understood mathematical definition to me which I can rephrase as composition of with the map that given returns hence I do struggle however with sampling in probability terms. Can you help?","(\Omega,\mathcal{F},\mu) \mu X s : \mathcal{T} \to \mathbb{R} T = \frac{1}{f} \left\{ s(nT) \right\}_{n \in \mathbb{Z}} s I_T : \mathbb{N} \to \mathcal{T} n nT 
s(nT) = \left(s \circ I_T\right)(n)
","['probability', 'measure-theory', 'statistics', 'definition']"
18,"Rudin Real and Complex analysis - Step II theorem 2.14, Riesz","Rudin Real and Complex analysis - Step II theorem 2.14, Riesz",,"Trying to understand this very long theorem of which I think good understanding is very educational. I am going through all the steps specifically now there's a subtlety in the conclusion of step II which I cannot get. I am sure is a silly thing. I'll write the proof for reference Step II : If $K$ is compact, then $K \in \mathcal{M}_F$ and $$ \mu(K) = \inf\left\{\Lambda f : K  \prec f \right\} \;\;\;\; (7) $$ This implies assertion (b) of the theorem. Proof: If $K \prec f$ and $0 < \alpha < 1$ , let $V_\alpha = \left\{x : f(x) > \alpha \right\}$ . Then $K \subset V_\alpha$ and $\alpha g \leq f$ whenever $g \prec V_\alpha$ . Hence $$ \mu(K) \leq \mu(V_\alpha) = \sup \left\{ \Lambda g : g \prec V_\alpha \right\} \leq \alpha^{-1} \Lambda f $$ Let $\alpha \to 1$ to conclude that $$ \mu(K) \leq \Lambda f \;\;\;\; (8) $$ Thus $\mu(K) < \infty$ . Since $K$ evidently satisfies (3), $K \in \mathcal{M}_F$ . If $\epsilon > 0$ , there's $V, K \subset V$ with $\mu(V) < \mu(K) + \epsilon$ . By Urysohn's lemma $K \prec f \prec V$ for some $f$ . Thus $$ \Lambda f \leq \mu(V) < \mu(K) + \epsilon $$ which, combined with (8), gives (7) Here's the question or maybe clarification... combining (7) with (8) provides to me that $$ \mu(K) \leq \Lambda f \leq \mu(K) + \epsilon \;\;\;\; (9) $$ and bedause $\epsilon > 0$ is arbitrary we end up with $$ \mu(K) = \Lambda f $$ However in (8) the relationship $\mu(K) \leq \Lambda f$ holds for any $f$ with $K \prec f$ and specifically we have $$ \mu(K) \leq \inf \left\{ \Lambda f : K \prec f \right\} $$ On the other hand for $9$ the $f$ used depends on the open $V$ chosen therefore to me the combination of (8) and (9) to get (7) should be done as $$ \mu(K) \leq \inf \left\{\Lambda f : K \prec f \right\} \leq \Lambda f \leq \mu(K) + \epsilon \Rightarrow \mu(K) \leq \inf \left\{\Lambda f : K \prec f \right\} \leq \mu(K) + \epsilon  $$ and as $\epsilon \to 0$ we have $$ \mu(K) = \inf \left\{\Lambda f : K \prec f \right\} $$ Is this the right conclusion?","Trying to understand this very long theorem of which I think good understanding is very educational. I am going through all the steps specifically now there's a subtlety in the conclusion of step II which I cannot get. I am sure is a silly thing. I'll write the proof for reference Step II : If is compact, then and This implies assertion (b) of the theorem. Proof: If and , let . Then and whenever . Hence Let to conclude that Thus . Since evidently satisfies (3), . If , there's with . By Urysohn's lemma for some . Thus which, combined with (8), gives (7) Here's the question or maybe clarification... combining (7) with (8) provides to me that and bedause is arbitrary we end up with However in (8) the relationship holds for any with and specifically we have On the other hand for the used depends on the open chosen therefore to me the combination of (8) and (9) to get (7) should be done as and as we have Is this the right conclusion?","K K \in \mathcal{M}_F 
\mu(K) = \inf\left\{\Lambda f : K  \prec f \right\} \;\;\;\; (7)
 K \prec f 0 < \alpha < 1 V_\alpha = \left\{x : f(x) > \alpha \right\} K \subset V_\alpha \alpha g \leq f g \prec V_\alpha 
\mu(K) \leq \mu(V_\alpha) = \sup \left\{ \Lambda g : g \prec V_\alpha \right\} \leq \alpha^{-1} \Lambda f
 \alpha \to 1 
\mu(K) \leq \Lambda f \;\;\;\; (8)
 \mu(K) < \infty K K \in \mathcal{M}_F \epsilon > 0 V, K \subset V \mu(V) < \mu(K) + \epsilon K \prec f \prec V f 
\Lambda f \leq \mu(V) < \mu(K) + \epsilon
 
\mu(K) \leq \Lambda f \leq \mu(K) + \epsilon \;\;\;\; (9)
 \epsilon > 0 
\mu(K) = \Lambda f
 \mu(K) \leq \Lambda f f K \prec f 
\mu(K) \leq \inf \left\{ \Lambda f : K \prec f \right\}
 9 f V 
\mu(K) \leq \inf \left\{\Lambda f : K \prec f \right\} \leq \Lambda f \leq \mu(K) + \epsilon \Rightarrow
\mu(K) \leq \inf \left\{\Lambda f : K \prec f \right\} \leq \mu(K) + \epsilon 
 \epsilon \to 0 
\mu(K) = \inf \left\{\Lambda f : K \prec f \right\}
","['real-analysis', 'measure-theory', 'proof-explanation', 'riesz-representation-theorem']"
19,Can it be said that $E(A_1)E(A_2) = E(A_2) E(A_1) = 0$ for $A_1 \cap A_2 = \varnothing\ $?,Can it be said that  for ?,E(A_1)E(A_2) = E(A_2) E(A_1) = 0 A_1 \cap A_2 = \varnothing\ ,"Let $(X,\mathcal A)$ be a measurable space. Let $\mathcal H$ be a Hilbert space and $E : \mathcal A \longrightarrow \mathscr P (\mathcal H)$ be a projection valued map. For all $x \in \mathcal H$ with $\|x\| = 1$ define $\mu_x : \mathcal A \longrightarrow [0,\infty]$ by $\mu_x (A) = \left \langle x, E(A) x \right \rangle,$ $A \in \mathcal A.$ Suppose that $\mu_x$ is a probability measure for all $x \in \mathcal H$ with $\|x\| = 1.$ Then can we conclude the following $:$ If $A_1, A_2 \in \mathcal A$ with $A_1 \cap A_2 = \varnothing$ then $$E(A_1) E(A_2) = E(A_2) E(A_1) = 0.$$ Our instructor implicitly assuming this result to conclude that $E$ is countably additive but I can't figure out as to why it should be true. Do anybody have any idea about it? Thanks for your time.",Let be a measurable space. Let be a Hilbert space and be a projection valued map. For all with define by Suppose that is a probability measure for all with Then can we conclude the following If with then Our instructor implicitly assuming this result to conclude that is countably additive but I can't figure out as to why it should be true. Do anybody have any idea about it? Thanks for your time.,"(X,\mathcal A) \mathcal H E : \mathcal A \longrightarrow \mathscr P (\mathcal H) x \in \mathcal H \|x\| = 1 \mu_x : \mathcal A \longrightarrow [0,\infty] \mu_x (A) = \left \langle x, E(A) x \right \rangle, A \in \mathcal A. \mu_x x \in \mathcal H \|x\| = 1. : A_1, A_2 \in \mathcal A A_1 \cap A_2 = \varnothing E(A_1) E(A_2) = E(A_2) E(A_1) = 0. E","['functional-analysis', 'measure-theory', 'hilbert-spaces', 'projection']"
20,"Bochner integral of a function from $[0,1]$ to $c_0$",Bochner integral of a function from  to,"[0,1] c_0","I want to compute the Bochner integral of the function $$ f: [0,1]\to c_0\,, \quad f(x)= \left( \frac{\cos nx}{n} \right)_{n\in\mathbb N}. $$ First, I need to check for strong measurability. Since $c_0$ is separable, strong and weak measurability coincide. However, how do I check whether the preimages of Borel sets (or open sets) are Borel? It seems very hard to think about the preimages of sets of null sequences. For now, I'll just assume that it is measurable. Then $f$ is Bochner integrable if the function $$ x \mapsto \|f(x)\|_\infty = \sup_{n \in \mathbb N} \left\vert\frac{\cos nx}{n}\right\vert $$ is integrable. This is, of course, true because $\cos$ is bounded and thus $\cos(nx)/n \to 0$ . Now, how can I compute $ \int_{[0,1]} f\,\mathrm d\lambda$ ? By definition, I would need to find a sequence of simple functions $f_n: [0,1] \to c_0$ that converges to $f$ or the Hahn-Banach theorem could be used?","I want to compute the Bochner integral of the function First, I need to check for strong measurability. Since is separable, strong and weak measurability coincide. However, how do I check whether the preimages of Borel sets (or open sets) are Borel? It seems very hard to think about the preimages of sets of null sequences. For now, I'll just assume that it is measurable. Then is Bochner integrable if the function is integrable. This is, of course, true because is bounded and thus . Now, how can I compute ? By definition, I would need to find a sequence of simple functions that converges to or the Hahn-Banach theorem could be used?","
f: [0,1]\to c_0\,, \quad f(x)= \left( \frac{\cos nx}{n} \right)_{n\in\mathbb N}.
 c_0 f 
x \mapsto \|f(x)\|_\infty
= \sup_{n \in \mathbb N} \left\vert\frac{\cos nx}{n}\right\vert
 \cos \cos(nx)/n \to 0  \int_{[0,1]} f\,\mathrm d\lambda f_n: [0,1] \to c_0 f","['integration', 'functional-analysis', 'measure-theory', 'lebesgue-integral']"
21,Density of compactly supported smooth functions in Lp,Density of compactly supported smooth functions in Lp,,"This is an exercise in my Functional Analysis book; I tried to check my solution by referring to this site and elsewhere but nowhere have I found a similar argument to mine (which makes me skeptical about my solution; note that I have no access to an instructor and there's no available solutions to this book); the solutions that I have found seem to me more complicated than my following argument (these are just bullet points, not rigorous proof): First off if $K$ is a compact set (assume WLOG that $K$ is a ball of radius $r$ ), then note that given any $L^p$ function $f$ on $K$ we can arbitrarily approximate it (in the $L^p$ norm) with a continuous function $g$ . Next note that polynomials are uniformly dense in the set of continuous functions, hence there exists a polynomial $p$ which uniformly approximates $g$ on $K$ and hence it can arbitrarily approximate it in the norm (where the integral is taken over $K$ of course). Now if $f$ is in $L^p(R^n)$ then there exists a set of finite measure $K$ (which WLOG we assume is a ball of radius $r$ ) such that the integral of $f$ over $K$ is arbitrarily close to its integral over $R^n$ . Let us take the continuous function $g$ as above which vanishes outside of $K$ and let $\psi$ be a bump function which is $1$ on a ball of radius $r-\epsilon$ and is supported in $K$ , then clearly $p\psi$ can also arbitrarily approximate $g$ in the norm (just like $p$ can). Then by the triangle inequality we obtain the approximation of $f$ by $p\psi$ in the norm. Is there anything that I'm missing?","This is an exercise in my Functional Analysis book; I tried to check my solution by referring to this site and elsewhere but nowhere have I found a similar argument to mine (which makes me skeptical about my solution; note that I have no access to an instructor and there's no available solutions to this book); the solutions that I have found seem to me more complicated than my following argument (these are just bullet points, not rigorous proof): First off if is a compact set (assume WLOG that is a ball of radius ), then note that given any function on we can arbitrarily approximate it (in the norm) with a continuous function . Next note that polynomials are uniformly dense in the set of continuous functions, hence there exists a polynomial which uniformly approximates on and hence it can arbitrarily approximate it in the norm (where the integral is taken over of course). Now if is in then there exists a set of finite measure (which WLOG we assume is a ball of radius ) such that the integral of over is arbitrarily close to its integral over . Let us take the continuous function as above which vanishes outside of and let be a bump function which is on a ball of radius and is supported in , then clearly can also arbitrarily approximate in the norm (just like can). Then by the triangle inequality we obtain the approximation of by in the norm. Is there anything that I'm missing?",K K r L^p f K L^p g p g K K f L^p(R^n) K r f K R^n g K \psi 1 r-\epsilon K p\psi g p f p\psi,"['functional-analysis', 'measure-theory', 'banach-spaces', 'lp-spaces', 'approximation-theory']"
22,Sequence of random variables and limits,Sequence of random variables and limits,,"Let $X_1, X_2, \dots : \Omega \to \mathbb R$ be a sequence of random variables. I want to show that there exists a sequence $\{A_n\}$ , where $A_n > 0$ for all $n$ , such that: $$ P(\{ \omega \in \Omega: \lim_{n \to \infty}\frac{X_n(\omega)}{A_n}=0\}) =1.$$ For this I've been told that I should use $P(\{ |X_n|>\frac{A_n}{n} \})\leq \frac{1}{2^n}$ . My first question is: how to prove this? I have an intuition of why it is true, but don't know how to write it down. Then, I know that because of the Borel Cantelli lemma I can write $$ P(\{ \frac{|X_n|}{A_n} > \frac{1}{n}\ \quad \text{i.o.}\})=0 $$ which leads that there is some measurable set in which $P(\{ \frac{|X_n|}{A_n} \leq \frac{1}{n}\ \})=1$ . My second question is how to guarantee that this happens for some $n > N$ to take the limit and conclude the proof.","Let be a sequence of random variables. I want to show that there exists a sequence , where for all , such that: For this I've been told that I should use . My first question is: how to prove this? I have an intuition of why it is true, but don't know how to write it down. Then, I know that because of the Borel Cantelli lemma I can write which leads that there is some measurable set in which . My second question is how to guarantee that this happens for some to take the limit and conclude the proof.","X_1, X_2, \dots : \Omega \to \mathbb R \{A_n\} A_n > 0 n  P(\{ \omega \in \Omega: \lim_{n \to \infty}\frac{X_n(\omega)}{A_n}=0\}) =1. P(\{ |X_n|>\frac{A_n}{n} \})\leq \frac{1}{2^n} 
P(\{ \frac{|X_n|}{A_n} > \frac{1}{n}\ \quad \text{i.o.}\})=0
 P(\{ \frac{|X_n|}{A_n} \leq \frac{1}{n}\ \})=1 n > N","['real-analysis', 'measure-theory']"
23,$f$ is measurable $\iff$ $f^{-1}(G)$ is measurable for open $G$.,is measurable   is measurable for open .,f \iff f^{-1}(G) G,"$E$ : Lebesgue measurable set $f$ : $E \to \mathbb{R}$ I want to prove $f$ is Lebesgue-measurable function $\iff$ $f^{-1}(G)$ is Lebesgue measurable for all open set $G$ . ( $\Leftarrow$ ) is O.K. For all $a\in \mathbb{R}$ , $\{ f>a \} = \{x\in E | f(x)>a \} = f^{-1}((a, \infty)).$ Since $(a, \infty)$ is open, $f^{-1}((a, \infty))$ is Lebesugue-measurable and so is $\{ f>a \}$ . But I couldn't prove $(\Rightarrow)$ . My attempt is as following. Let $G$ open. Since $G$ is open, I can write $G=\cup_{n=1}^{\infty} O_n$ , where each $O_i$ is open interval and $O_i \cap O_j=\phi (i \neq j).$ $f^{-1}(G)= f^{-1}( \cup_{n=1}^{\infty} O_n)=\cup_{n=1}^{\infty} f^{-1}(O_n)$ . I cannot proceed from here. I would like you to give me some ideas.",": Lebesgue measurable set : I want to prove is Lebesgue-measurable function is Lebesgue measurable for all open set . ( ) is O.K. For all , Since is open, is Lebesugue-measurable and so is . But I couldn't prove . My attempt is as following. Let open. Since is open, I can write , where each is open interval and . I cannot proceed from here. I would like you to give me some ideas.","E f E \to \mathbb{R} f \iff f^{-1}(G) G \Leftarrow a\in \mathbb{R} \{ f>a \} = \{x\in E | f(x)>a \} = f^{-1}((a, \infty)). (a, \infty) f^{-1}((a, \infty)) \{ f>a \} (\Rightarrow) G G G=\cup_{n=1}^{\infty} O_n O_i O_i \cap O_j=\phi (i \neq j). f^{-1}(G)= f^{-1}( \cup_{n=1}^{\infty} O_n)=\cup_{n=1}^{\infty} f^{-1}(O_n)","['measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'measurable-functions']"
24,Show that $C^\infty$ is dense in the space of weakly differentiable $L^p$-functions,Show that  is dense in the space of weakly differentiable -functions,C^\infty L^p,"Let $\lambda$ denote the Lebesgue measure on $\mathcal B(\mathbb R)$ , $T>0$ , $I:=(0,T)$ , $X,Y$ be $\mathbb R$ -Banach spaces and $\iota$ be a continuous embedding of $X$ into $Y$ . If $p\in[1,\infty]$ , say $f\in\mathcal L^1(I,X)$ has a weak derivative in $L^p(I,Y)$ if there is a $g\in\mathcal L^p(I,Y)$ with $$\int_I\varphi'\iota f\:{\rm d}\lambda=-\int_I\varphi g\:{\rm d}\lambda\;\;\;\text{for all }\varphi\in C_c^\infty(I).$$ In that case, $f':=g$ . If $p,q\in[1,\infty]$ , let $E^{p,\:q}(I)$ denote the space of all $f\in\mathcal L^p(I,X)$ which admit a weak derivative in $L^q(I,Y)$ . Moreover, let $$\left\|f\right\|_{E^{p,\:q}}:=\left\|f\right\|_{L^p(I,\:X)}+\left\|f'\right\|_{L^p(I,\:Y)}\;\;\;\text{for }f\in E^{p,\:q}.$$ How can we show that if $p,q\in[1,\infty)$ , then $C^\infty(I,X)$ is a dense subset of $E^{p,\:q}$ ? There is a proof of this claim in Mathematical Tools for the Study of the Incompressible Navier-Stokes Equations and Related Models (Lemma II.5.10): The mentioned corollary is the (easy to verify) fact that $$\forall r\in[1,\infty):\forall g\in L^r(I,X):\left\|g\circ\tau_h-g\right\|_{L^r(I,\:X)}\xrightarrow{h\to\infty}0\tag2,$$ where $$\tau_h:\mathbb R\to\mathbb R\;,\;\;\;a\mapsto a+h$$ for $h\in\mathbb R$ . I don't understand the argumentation in the proof. How can we give a rigorous proof? And can we even find a suitable subspace "" $E_0^{p,\:q}(I)$ "" of $E^{p,\:q}$ s.t. $C_{\color{red}c}^\infty(I,X)$ is dense in $E_0^{p,\:q}(I)$ ? Let $f\in E^{p,\:q}(I)$ . We can clearly find $0\le\theta_i\in C_c^\infty(\mathbb R)$ (note that I'm not taking $\theta_i\in C^\infty(I)$ as in the book excerpt, since I think we need to $\theta_i$ to be defined on all of $\mathbb R$ in what follows, but please let me know in the comments if I'm missing something) with $\theta_1+\theta_2=1$ and $\operatorname{supp}\theta_1\subseteq\left[0,\frac23T\right]$ , $\operatorname{supp}\theta_2\subseteq\left[\frac13T,T\right]$ (although I'm not sure why exactly we need to consider these $\theta_i$ ). Now let $$g:=\begin{cases}\theta_1f&\text{on }I\\0&\text{on }\mathbb R\setminus I.\end{cases}$$ I'm not sure whether this will be important, but we should be able to show that $g\in E^{p,\:q}(\mathbb R)$ and $g'=\theta_1f'+\theta_1'\iota f$ . Now let $\eta$ be a ""mollifying kernel"", i.e. $\eta\in C_c^\infty(\mathbb R)$ with $\operatorname{supp}\eta\subseteq(-1,1)$ ; $\eta\ge0$ and $\int_{-\infty}^\infty\eta=1$ ; $\forall x,y\in\mathbb R:|x|=|y|\Rightarrow\eta(x)=\eta(y),$ and set $$\eta_\varepsilon(x):=\frac1\varepsilon\eta\left(\frac x\varepsilon\right)\;\;\;\text{for }x\in\mathbb R^d.$$ Note that $$g_h:=g\circ\tau_h\in L^p(\mathbb R)$$ and $$g_{h,\:\varepsilon}:=g_h\ast\eta_\varepsilon\in C^\infty(\mathbb R)$$ for all $h\in\mathbb R$ and $\varepsilon>0$ . Now, if I got the comment from daw in the comments below right, the idea is to show that $$\left\|g_{h,\:\varepsilon}-g\right\|_{E^{p,\:q}}\le\left\|g_h-g\right\|_{E^{p,\:q}}+\left\|g_{h,\:\varepsilon}-g_h\right\|_{E^{p,\:q}}\to0;\tag1$$ most probably as $h$ and $\varepsilon$ tend to $0$ (right?). However, the only things which are clear to me are $$\left\|g_h-g\right\|_{L^p(\mathbb R)}\xrightarrow{h\to0}0\tag2$$ and $$\forall h\in\mathbb R:\left\|g_{h,\:\varepsilon}-g_h\right\|_{L^p(\mathbb R)}\xrightarrow{\varepsilon\to0+}0\tag3.$$ And even if we can show $(1)$ , how does the claim for $f$ follow from that? From Jose27's comment below I suppose that there must be something crucial with the endpoints ...","Let denote the Lebesgue measure on , , , be -Banach spaces and be a continuous embedding of into . If , say has a weak derivative in if there is a with In that case, . If , let denote the space of all which admit a weak derivative in . Moreover, let How can we show that if , then is a dense subset of ? There is a proof of this claim in Mathematical Tools for the Study of the Incompressible Navier-Stokes Equations and Related Models (Lemma II.5.10): The mentioned corollary is the (easy to verify) fact that where for . I don't understand the argumentation in the proof. How can we give a rigorous proof? And can we even find a suitable subspace "" "" of s.t. is dense in ? Let . We can clearly find (note that I'm not taking as in the book excerpt, since I think we need to to be defined on all of in what follows, but please let me know in the comments if I'm missing something) with and , (although I'm not sure why exactly we need to consider these ). Now let I'm not sure whether this will be important, but we should be able to show that and . Now let be a ""mollifying kernel"", i.e. with ; and ; and set Note that and for all and . Now, if I got the comment from daw in the comments below right, the idea is to show that most probably as and tend to (right?). However, the only things which are clear to me are and And even if we can show , how does the claim for follow from that? From Jose27's comment below I suppose that there must be something crucial with the endpoints ...","\lambda \mathcal B(\mathbb R) T>0 I:=(0,T) X,Y \mathbb R \iota X Y p\in[1,\infty] f\in\mathcal L^1(I,X) L^p(I,Y) g\in\mathcal L^p(I,Y) \int_I\varphi'\iota f\:{\rm d}\lambda=-\int_I\varphi g\:{\rm d}\lambda\;\;\;\text{for all }\varphi\in C_c^\infty(I). f':=g p,q\in[1,\infty] E^{p,\:q}(I) f\in\mathcal L^p(I,X) L^q(I,Y) \left\|f\right\|_{E^{p,\:q}}:=\left\|f\right\|_{L^p(I,\:X)}+\left\|f'\right\|_{L^p(I,\:Y)}\;\;\;\text{for }f\in E^{p,\:q}. p,q\in[1,\infty) C^\infty(I,X) E^{p,\:q} \forall r\in[1,\infty):\forall g\in L^r(I,X):\left\|g\circ\tau_h-g\right\|_{L^r(I,\:X)}\xrightarrow{h\to\infty}0\tag2, \tau_h:\mathbb R\to\mathbb R\;,\;\;\;a\mapsto a+h h\in\mathbb R E_0^{p,\:q}(I) E^{p,\:q} C_{\color{red}c}^\infty(I,X) E_0^{p,\:q}(I) f\in E^{p,\:q}(I) 0\le\theta_i\in C_c^\infty(\mathbb R) \theta_i\in C^\infty(I) \theta_i \mathbb R \theta_1+\theta_2=1 \operatorname{supp}\theta_1\subseteq\left[0,\frac23T\right] \operatorname{supp}\theta_2\subseteq\left[\frac13T,T\right] \theta_i g:=\begin{cases}\theta_1f&\text{on }I\\0&\text{on }\mathbb R\setminus I.\end{cases} g\in E^{p,\:q}(\mathbb R) g'=\theta_1f'+\theta_1'\iota f \eta \eta\in C_c^\infty(\mathbb R) \operatorname{supp}\eta\subseteq(-1,1) \eta\ge0 \int_{-\infty}^\infty\eta=1 \forall x,y\in\mathbb R:|x|=|y|\Rightarrow\eta(x)=\eta(y), \eta_\varepsilon(x):=\frac1\varepsilon\eta\left(\frac x\varepsilon\right)\;\;\;\text{for }x\in\mathbb R^d. g_h:=g\circ\tau_h\in L^p(\mathbb R) g_{h,\:\varepsilon}:=g_h\ast\eta_\varepsilon\in C^\infty(\mathbb R) h\in\mathbb R \varepsilon>0 \left\|g_{h,\:\varepsilon}-g\right\|_{E^{p,\:q}}\le\left\|g_h-g\right\|_{E^{p,\:q}}+\left\|g_{h,\:\varepsilon}-g_h\right\|_{E^{p,\:q}}\to0;\tag1 h \varepsilon 0 \left\|g_h-g\right\|_{L^p(\mathbb R)}\xrightarrow{h\to0}0\tag2 \forall h\in\mathbb R:\left\|g_{h,\:\varepsilon}-g_h\right\|_{L^p(\mathbb R)}\xrightarrow{\varepsilon\to0+}0\tag3. (1) f","['functional-analysis', 'measure-theory', 'partial-differential-equations', 'sobolev-spaces', 'convolution']"
25,"Is there an isometry between the direct sum of $L^1(\mu_i)$ and $L^1(\nu)$, i.e. $\bigoplus_{i} L^1(\mu_i)\cong L^1(\nu)$?","Is there an isometry between the direct sum of  and , i.e. ?",L^1(\mu_i) L^1(\nu) \bigoplus_{i} L^1(\mu_i)\cong L^1(\nu),"In https://math.stackexchange.com/a/74877/653080 it is mentioned that $\mathcal{M}(K)\cong L^1(\nu)$ for some measure $\nu$ , whereas $\mathcal M(K)$ is an $\mathcal{l}_1-$sum of $L_1(\mu)$ spaces is it mentioned that $\mathcal{M}(K)\cong \bigoplus_{i\in I} L^1(\mu_i)$ for some mutually singular probability measures $\mu_i$ . This hints at that $\bigoplus_{i\in I} L^1(\mu_i)\cong L^1(\nu)$ . Does this mean that in general there exists a (probability) measure $\nu$ such that $\bigoplus_{i\in I} L^1(\mu_i)\cong L^1(\nu)$ , when $\mu_i$ are mutually singular probability measures $\mu_i$ ? If so, can we choose $\nu$ to be any probability measure $\nu$ with full support on $K$ ? The spaces $\bigoplus_{i\in I} L^1(\mu_i)$ and $L^1(\nu)$ are defined as $$    L^1(\nu) = \{f:K\to\mathbb{R}^d \;|\; \int_K|f(x)|d\nu(x) < \infty \} \\    \bigoplus_{i\in I} L^1(\mu_i) = \{ (f_1,f_2...) \;|\; f_i\in L^1(\mu_i)\} $$ with norms $$     ||f||_{L^1(\nu)} = \int_K|f(x)|d\nu(x) \\     ||f||_{\bigoplus_{i\in I} L^1(\mu_i)} = \sum_{i\in I}||f_i||_{L^1(\mu_i)} $$","In https://math.stackexchange.com/a/74877/653080 it is mentioned that for some measure , whereas $\mathcal M(K)$ is an $\mathcal{l}_1-$sum of $L_1(\mu)$ spaces is it mentioned that for some mutually singular probability measures . This hints at that . Does this mean that in general there exists a (probability) measure such that , when are mutually singular probability measures ? If so, can we choose to be any probability measure with full support on ? The spaces and are defined as with norms","\mathcal{M}(K)\cong L^1(\nu) \nu \mathcal{M}(K)\cong \bigoplus_{i\in I} L^1(\mu_i) \mu_i \bigoplus_{i\in I} L^1(\mu_i)\cong L^1(\nu) \nu \bigoplus_{i\in I} L^1(\mu_i)\cong L^1(\nu) \mu_i \mu_i \nu \nu K \bigoplus_{i\in I} L^1(\mu_i) L^1(\nu) 
   L^1(\nu) = \{f:K\to\mathbb{R}^d \;|\; \int_K|f(x)|d\nu(x) < \infty \} \\
   \bigoplus_{i\in I} L^1(\mu_i) = \{ (f_1,f_2...) \;|\; f_i\in L^1(\mu_i)\}
 
    ||f||_{L^1(\nu)} = \int_K|f(x)|d\nu(x) \\
    ||f||_{\bigoplus_{i\in I} L^1(\mu_i)} = \sum_{i\in I}||f_i||_{L^1(\mu_i)}
","['functional-analysis', 'measure-theory', 'banach-spaces', 'isometry', 'direct-sum']"
26,Proving Chebychev's Inequality using Markov's Inequality,Proving Chebychev's Inequality using Markov's Inequality,,"I am trying to prove: Suppose $(X, \mathcal S, \mu)$ is a measure space with $\mu(X) = 1$ and $h\in \mathcal L^1(\mu)$ . Prove that \begin{align}     \mu\left(\left\{ x\in X: \left|h(x) - \int h\; d\mu\right|\ge c     \right\}\right) \le     \frac{1}{c^2} \left(\int h^2 \; d\mu - \left(\int h \; d\mu     \right)^2\right) \end{align} for all $c>0$ . Attempt: Suppose $(X, \mathcal S, \mu)$ is a measure space with $\mu(X) = 1$ and $h\in \mathcal L^1(\mu)$ . Fix $c>0$ . Markov's Inequality: $\mu\left(\left\{x \in X: |f(x)|\ge c     \right\}\right) \le \frac{1}{c^2} \|f\|_1 = \frac{1}{c^2} \cdot \int\left|f\right|\; d\mu$ . Take $f(x) = h(x) - \int h \; d\mu$ in Markov's inequality: \begin{align*}     \mu\left(\left\{x \in X: \left|h(x) - \int h \; d\mu\right|\ge c \right\}\right)      &\le \frac{1}{c^2} \int\left|h(x) - \int h \; d\mu\right|\; d\mu \\     &\le \frac{1}{c^2} \int\left(h(x) - \int h \; d\mu\right)^2\; d\mu\\     &= \frac{1}{c^2} \int\left[ h^2(x) +\left(\int h \; d\mu\right)^2 - 2h(x) \int h(x) \; d\mu\right] d\mu \\     &= \frac{1}{c^2}\left( \int h^2(x)\; d\mu +\int\left[\left(\int h \; d\mu\right)^2 - 2h(x) \int h(x) \; d\mu\right] d\mu\right) \end{align*} I am not sure how to proceed from here. I also know that I still have to use $\mu(X) = 1$ . Intuitively, I think I should be using the property that integration is homogeneous, but $h(x)$ is not independent of $x$ , of course. Can someone please provide some hints?","I am trying to prove: Suppose is a measure space with and . Prove that for all . Attempt: Suppose is a measure space with and . Fix . Markov's Inequality: . Take in Markov's inequality: I am not sure how to proceed from here. I also know that I still have to use . Intuitively, I think I should be using the property that integration is homogeneous, but is not independent of , of course. Can someone please provide some hints?","(X, \mathcal S, \mu) \mu(X) = 1 h\in \mathcal L^1(\mu) \begin{align}
    \mu\left(\left\{ x\in X: \left|h(x) - \int h\; d\mu\right|\ge c
    \right\}\right) \le
    \frac{1}{c^2} \left(\int h^2 \; d\mu - \left(\int h \; d\mu
    \right)^2\right)
\end{align} c>0 (X, \mathcal S, \mu) \mu(X) = 1 h\in \mathcal L^1(\mu) c>0 \mu\left(\left\{x \in X: |f(x)|\ge c
    \right\}\right) \le \frac{1}{c^2} \|f\|_1 = \frac{1}{c^2} \cdot \int\left|f\right|\; d\mu f(x) = h(x) - \int h \; d\mu \begin{align*}
    \mu\left(\left\{x \in X: \left|h(x) - \int h \; d\mu\right|\ge c \right\}\right) 
    &\le \frac{1}{c^2} \int\left|h(x) - \int h \; d\mu\right|\; d\mu \\
    &\le \frac{1}{c^2} \int\left(h(x) - \int h \; d\mu\right)^2\; d\mu\\
    &= \frac{1}{c^2} \int\left[ h^2(x) +\left(\int h \; d\mu\right)^2 - 2h(x) \int h(x) \; d\mu\right] d\mu \\
    &= \frac{1}{c^2}\left( \int h^2(x)\; d\mu +\int\left[\left(\int h \; d\mu\right)^2 - 2h(x) \int h(x) \; d\mu\right] d\mu\right)
\end{align*} \mu(X) = 1 h(x) x","['real-analysis', 'measure-theory', 'proof-writing', 'solution-verification']"
27,Hausdorff Measure of a Compact segment in $\mathbb R$ has infinite hausdorff measure for $s < 1$,Hausdorff Measure of a Compact segment in  has infinite hausdorff measure for,\mathbb R s < 1,"This is probably obvious, but I'm having trouble with it. It is an exercise in Falconer: Show that $\mathcal{H}^s([0,1]) = \infty$ if $s \in [0,1)$ I can see that this should loosely be the case: consider a dyadic partition of $[0,1]$ , then $\sum_i 2^i \left(\frac 1 {2^i}\right)^s$ doesn't converge for $s < 1$ . This however gets me an upper bound on Hausdorff measure. How does one proceed?","This is probably obvious, but I'm having trouble with it. It is an exercise in Falconer: Show that if I can see that this should loosely be the case: consider a dyadic partition of , then doesn't converge for . This however gets me an upper bound on Hausdorff measure. How does one proceed?","\mathcal{H}^s([0,1]) = \infty s \in [0,1) [0,1] \sum_i 2^i \left(\frac 1 {2^i}\right)^s s < 1","['measure-theory', 'geometric-measure-theory', 'hausdorff-measure']"
28,"Let $(X, \mathcal{M})$ be a measurable space and $\mu : \mathcal{M} → [0, \infty]$. Show that $\mu$ is a measure.",Let  be a measurable space and . Show that  is a measure.,"(X, \mathcal{M}) \mu : \mathcal{M} → [0, \infty] \mu","Let $(X, \mathcal{M})$ be a measurable space and $\mu : \mathcal{M} → [0, \infty]$ such that (a) $µ (A) <\infty$ for some $A \in \mathcal{M}$ (b) $µ(A \cup B) = \mu(A) + \mu(B)$ if $A, B \in \mathcal{M}$ and $A \cap B = \emptyset$ , and (c) $\mu (\bigcup_{n=1}^{\infty} A_{n}) \leq \sum_{n=1}^{\infty}\mu(A_n) $ if $A_n \in \mathcal{M}$ for $n=1,2,3,...$ Show that $\mu$ is a measure. In my context, we define a measure as follows: Definition: A function µ is called a positive measure, defined in a $\sigma$ -algebra $\mathcal{M}$ with values in $[0, \infty]$ and which is countably additive. This means that if $\{E_i\}$ is a disjoint countable collection of elements of $\mathcal{M}$ , then $\mu (\bigcup_{i=1}^{\infty} E_{i}) = \sum_{i=1}^{\infty}\mu(E_i)$ . To avoid trivial cases, we will further assume that $\mu (A) < \infty $ for at least one $A \in \mathcal{M}$ My attempt: From the definition, it only remains for me to prove that $\mu$ is countably additive. To do this, let $\{A_n\}$ be a disjoint countable collection of elements of $\mathcal{M}$ . Then, $$ \bigcup_{n=1}^{\infty}A_n  \supset \bigcup_{n=1}^{N}A_n$$ And so $$\mu \left(\bigcup_{n=1}^{\infty}A_n \right)  \geq \mu \left(\bigcup_{n=1}^{N}A_n \right) = \sum_{n=1}^{N}\mu(A_n)$$ Since the left side of this inequality is independent of $N$ , we have $$\mu \left(\bigcup_{n=1}^{\infty}A_n \right)  \geq \sum_{n=1}^{\infty}\mu(A_n)$$ For part (c) we have the equality. First of all I want to know if there are any errors in my reasoning and, on the other hand, I don't see where I used the hypothesis of part (b) in my proof; This really does have me worried. I appreciate any help you can give me.","Let be a measurable space and such that (a) for some (b) if and , and (c) if for Show that is a measure. In my context, we define a measure as follows: Definition: A function µ is called a positive measure, defined in a -algebra with values in and which is countably additive. This means that if is a disjoint countable collection of elements of , then . To avoid trivial cases, we will further assume that for at least one My attempt: From the definition, it only remains for me to prove that is countably additive. To do this, let be a disjoint countable collection of elements of . Then, And so Since the left side of this inequality is independent of , we have For part (c) we have the equality. First of all I want to know if there are any errors in my reasoning and, on the other hand, I don't see where I used the hypothesis of part (b) in my proof; This really does have me worried. I appreciate any help you can give me.","(X, \mathcal{M}) \mu : \mathcal{M} → [0, \infty] µ (A) <\infty A \in \mathcal{M} µ(A \cup B) = \mu(A) + \mu(B) A, B \in \mathcal{M} A \cap B = \emptyset \mu (\bigcup_{n=1}^{\infty} A_{n}) \leq \sum_{n=1}^{\infty}\mu(A_n)  A_n \in \mathcal{M} n=1,2,3,... \mu \sigma \mathcal{M} [0, \infty] \{E_i\} \mathcal{M} \mu (\bigcup_{i=1}^{\infty} E_{i}) = \sum_{i=1}^{\infty}\mu(E_i) \mu (A) < \infty  A \in \mathcal{M} \mu \{A_n\} \mathcal{M}  \bigcup_{n=1}^{\infty}A_n  \supset \bigcup_{n=1}^{N}A_n \mu \left(\bigcup_{n=1}^{\infty}A_n \right)  \geq \mu \left(\bigcup_{n=1}^{N}A_n \right) = \sum_{n=1}^{N}\mu(A_n) N \mu \left(\bigcup_{n=1}^{\infty}A_n \right)  \geq \sum_{n=1}^{\infty}\mu(A_n)","['measure-theory', 'solution-verification', 'measurable-sets']"
29,"For an integrable function, does there exist a sequence of partitions with this property.","For an integrable function, does there exist a sequence of partitions with this property.",,"Assume you have the measurespace $([a,b],\mathcal{B}([a,b],l)$ , where $l$ is the Lebesgue measure. Assume also you have an integrable function $f [a,b]\rightarrow \mathbb{R}$ on the measure space. For a partition of $[a,b]$ , $\Pi=\{t_0=a<t_2,\cdots,t_n=b\}$ , define $$I(\Pi)=\sum\limits_{i=0}^{n-1}f(t_i)\cdot1_{\{x: |f(x)|<\infty\}}(t_i)(t_{i+1}-t_i).$$ For an arbitrary sequence of partitions, $\Pi_n$ , with $\max_{i \in \{0,\cdots n-1\}}(t_{i+1}-t_i)\rightarrow 0$ , I am quite sure it is not the case that $$\limsup\limits_{n \rightarrow \infty}I(\Pi_n)=\liminf\limits_{n \rightarrow \infty}I(\Pi_n)=\int_{[a,b]}f(x)dx.$$ But I am wondering what happens if we may choose a special sequence so that it holds, so what I am wondering is: Case 1: Does there exist a sequence of partitions where the above equality holds? Case 2: If for a partition $\Pi$ we define $$f_{\Pi}(t)=\sum\limits_{i=0}^{n-1}f(t_i)\cdot1_{\{x: |f(x)|<\infty\}}(t_i)1_{x \in [t_i,t_{i+1})}(t),$$ and we still assume that $f$ is integrable, does there exist a sequence of partitions $\{\Pi_n\}$ so that $$\int_{[a,b)}|f(t)-f_{\Pi_n}(t)|dt\rightarrow0?$$ Case 3 If we also assume that $f \in L^2([a,b])$ , and let $f_\Pi$ be as above, does there exist a sequence of partitions $\{\Pi_n\}$ such that $$\int_{[a,b)}|f(t)-f_{\Pi_n}(t)|^2dt\rightarrow0?$$","Assume you have the measurespace , where is the Lebesgue measure. Assume also you have an integrable function on the measure space. For a partition of , , define For an arbitrary sequence of partitions, , with , I am quite sure it is not the case that But I am wondering what happens if we may choose a special sequence so that it holds, so what I am wondering is: Case 1: Does there exist a sequence of partitions where the above equality holds? Case 2: If for a partition we define and we still assume that is integrable, does there exist a sequence of partitions so that Case 3 If we also assume that , and let be as above, does there exist a sequence of partitions such that","([a,b],\mathcal{B}([a,b],l) l f [a,b]\rightarrow \mathbb{R} [a,b] \Pi=\{t_0=a<t_2,\cdots,t_n=b\} I(\Pi)=\sum\limits_{i=0}^{n-1}f(t_i)\cdot1_{\{x: |f(x)|<\infty\}}(t_i)(t_{i+1}-t_i). \Pi_n \max_{i \in \{0,\cdots n-1\}}(t_{i+1}-t_i)\rightarrow 0 \limsup\limits_{n \rightarrow \infty}I(\Pi_n)=\liminf\limits_{n \rightarrow \infty}I(\Pi_n)=\int_{[a,b]}f(x)dx. \Pi f_{\Pi}(t)=\sum\limits_{i=0}^{n-1}f(t_i)\cdot1_{\{x: |f(x)|<\infty\}}(t_i)1_{x \in [t_i,t_{i+1})}(t), f \{\Pi_n\} \int_{[a,b)}|f(t)-f_{\Pi_n}(t)|dt\rightarrow0? f \in L^2([a,b]) f_\Pi \{\Pi_n\} \int_{[a,b)}|f(t)-f_{\Pi_n}(t)|^2dt\rightarrow0?","['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
30,Convergence of Stationary random variables,Convergence of Stationary random variables,,"We have a stationary sequence of random variables $X_{j}:j\geq 0$ and let $D$ be a Borel subset of $\mathbb{R}^{d}$ . For each n, let $Y_{n}$ be the number of indices $i \in \{0,1, \ldots, n-d\}$ such that $(X_{i+1}, X_{i+2}, \ldots X_{i+d}) \in D$ . Show that $\frac{Y_{n}}{n}$ converges $as$ . My attempt: Attempt 1: $Y_{n}=i$ has equal probability to be anything from the set ${0,1, \ldots, n-d}$ so we can say that $Y_{n}$ follows a uniform distribution with $P(Y_{n}=i) = \frac{1}{n-d+1}$ . Now, I know that I can if I can show that $Y_{n}$ is a subadditive process, stationary, and integrable, then I can use the sub-additive ergodic theorem to prove that it converges $as$ . I don't know to prove that $Y_{n}$ is integrable because nothing has been given about the random variables $X_{j}$ except that they form a stationary sequence. Attempt 2: Since nothing's given about the integrability, if I can prove that the transformation is ergodic then I can use the Birkhoff ergodic theorem to show that $Y_{n}/n$ converges $as$ . For a simple example, if I fix d=1, then for different values of n, the different values of $Y_{n}$ correspond to shifted set of random variables belong to $A$ . For $n=1$ , $i = {0,1}$ which corresponds to $(X_{1}) \in D$ or $(X_{2}) \in D$ but both of them have the same distribution because $X_{j}$ is a stationary sequence. But I cannot go further. Any help would be great.","We have a stationary sequence of random variables and let be a Borel subset of . For each n, let be the number of indices such that . Show that converges . My attempt: Attempt 1: has equal probability to be anything from the set so we can say that follows a uniform distribution with . Now, I know that I can if I can show that is a subadditive process, stationary, and integrable, then I can use the sub-additive ergodic theorem to prove that it converges . I don't know to prove that is integrable because nothing has been given about the random variables except that they form a stationary sequence. Attempt 2: Since nothing's given about the integrability, if I can prove that the transformation is ergodic then I can use the Birkhoff ergodic theorem to show that converges . For a simple example, if I fix d=1, then for different values of n, the different values of correspond to shifted set of random variables belong to . For , which corresponds to or but both of them have the same distribution because is a stationary sequence. But I cannot go further. Any help would be great.","X_{j}:j\geq 0 D \mathbb{R}^{d} Y_{n} i \in \{0,1, \ldots, n-d\} (X_{i+1}, X_{i+2}, \ldots X_{i+d}) \in D \frac{Y_{n}}{n} as Y_{n}=i {0,1, \ldots, n-d} Y_{n} P(Y_{n}=i) = \frac{1}{n-d+1} Y_{n} as Y_{n} X_{j} Y_{n}/n as Y_{n} A n=1 i = {0,1} (X_{1}) \in D (X_{2}) \in D X_{j}","['measure-theory', 'ergodic-theory', 'almost-everywhere', 'stationary-processes']"
31,"A ``continuous'' family of measurable subsets of [0,1], each with a positive measure, admits a ``continuous'' subfamily with non-empty intersection?","A ``continuous'' family of measurable subsets of [0,1], each with a positive measure, admits a ``continuous'' subfamily with non-empty intersection?",,"Let $\{Y_x\}$ be a family of measurable subsets of [0,1] indexed by $x \in [0,1]$ , and such that each set $Y_x$ has a positive (Lebesgue) measure. Is there always a subset $X \subseteq [0,1]$ with positive measure and such that $\bigcap\limits_{x \in X} Y_x$ is nonempty? Intuitively it seems to be true, possibly under some mild extra assumptions (say compactness of $Y_x$ 's).","Let be a family of measurable subsets of [0,1] indexed by , and such that each set has a positive (Lebesgue) measure. Is there always a subset with positive measure and such that is nonempty? Intuitively it seems to be true, possibly under some mild extra assumptions (say compactness of 's).","\{Y_x\} x \in [0,1] Y_x X \subseteq [0,1] \bigcap\limits_{x \in X} Y_x Y_x","['measure-theory', 'set-theory']"
32,"$A\subset\mathbb{R}, t\in\mathbb{R}\Rightarrow |tA|=|t||A|$",,"A\subset\mathbb{R}, t\in\mathbb{R}\Rightarrow |tA|=|t||A|","I have proved the following statement and I would like to know If I have made any mistakes, thanks. ""Suppose $A\subset\mathbb{R}$ and $t\in\mathbb{R}$ . Let $tA:=\{ta:a\in A\}$ . Prove that $|tA|=|t||A|$ . (Assume that $0\cdot\infty$ is defined to be $0$ )."" NOTE: $|\cdot|$ refers to outer measure, i.e. for $A\subset\mathbb{R},\ |A|:=\inf\{\sum_{k=1}^{\infty}l(I_k): I_1,I_2,\dots\text{ are open intervals such that }A\subset\bigcup_{k=1}^{\infty}I_k\}$ ; the length of an open interval $I\subset\mathbb{R}$ is defined as $\ell(I):=\begin{cases} b-a & \text{if }I=(a,b),\ a,b\in\mathbb{R}, a<b; \\ 0   & \text{if }I=\emptyset; \\ \infty & \text{if } I=(-\infty, a)\text{ or } I=(a,\infty);\\ \infty & \text{ if }I=(-\infty,\infty) \end{cases} $ My proof: If $t=0$ then $tA=\{0\}$ so $|tA|=0$ (since finite sets have outer measure $0$ ) and $|t||A|=\begin{cases}  0\cdot |A| =0 & \text{ if } |A|<\infty\\  0\cdot |A| =0 & \text{ if } |A|=\infty & \text{(since by hypothesis }0\cdot\infty=0) \end{cases}\ =0$ so $|tA|=|t||A|$ , as desired. Now, suppose $t\neq 0$ and let $I_1,I_2,\dots$ be a sequence of open intervals ( $I_k=(a_k,b_k),\ a_k\in\mathbb{R}\cup-\{\infty\}, b_k\in\mathbb{R}\cup \{+\infty\}, a_k<b_k$ or $I_k=\emptyset$ ) such that $A\subset\bigcup_{k=1}^{\infty}I_k$ : then $tI_1,tI_2,\dots $ is a sequence of open intervals such that $tA\subset\bigcup_{k=1}^{\infty}tI_K$ ( $a\in A\Rightarrow a\in I_K=(a_K,b_K)\ a_K<b_K$ for some $K\geq 1\Rightarrow a_K<a<b_K\Rightarrow   \begin{cases} ta_K<ta<tb_K & \text{ if } t>0 \\ tb_K<ta<ta_K &\text{ if } t<0 \end{cases}$ i.e. $ta\in tI_K$ ) and $$l(tI_k):=\begin{cases} tb_k-ta_k & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t>0; \\ ta_k-tb_k & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t<0; \\ 0   & \text{if }I_k=\emptyset; \\ \infty & \text{if } I_k=(-\infty, b_k)\text{ or } I_k=(a_k,\infty);\\ \infty & \text{ if }I_k=(-\infty,\infty) \end{cases}= \begin{cases} t(b_k-a_k) & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t>0; \\ -t(b_k-a_k) & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t<0; \\ 0   & \text{if }I_k=\emptyset; \\ \infty & \text{if } I_k=(-\infty, b_k)\text{ or } I_k=(a_k,\infty);\\ \infty & \text{ if }I_k=(-\infty,\infty) \end{cases}=\begin{cases} |t|(b_k-a_k) & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t\neq 0; \\ |t| 0   & \text{if }I_k=\emptyset; \\ |t|\infty & \text{if } I_k=(-\infty, b_k)\text{ or } I_k=(a_k,\infty);\\ |t|\infty & \text{ if }I_k=(-\infty,\infty) \end{cases}=|t|\begin{cases} (b_k-a_k) & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k; \\ 0   & \text{if }I_k=\emptyset; \\ \infty & \text{if } I_k=(-\infty, b_k)\text{ or } I_k=(a_k,\infty);\\ \infty & \text{ if }I_k=(-\infty,\infty) \end{cases}=|t|I_k$$ so $$|tA|\leq\sum_{k=1}^{\infty}\ell (tI_k)=\sum_{k=1}^{\infty}|t|\ell (I_k)=|t|\sum_{k=1}^{\infty}\ell (I_k)$$ and by taking the $\inf$ over all open coverings of $A$ we find that $$|tA|\leq |t||A|$$ From this inequality we also get $$\left| \frac{1}{t}tA \right| \leq \left| \frac{1}{t} \right||tA|\Rightarrow |A|\leq \frac{1}{|t|}|tA|\Rightarrow |t||A|\leq |tA|$$ thus $|tA|=|t||A|\ \forall t\in\mathbb{R}, A\subset\mathbb{R}$ , as desired.","I have proved the following statement and I would like to know If I have made any mistakes, thanks. ""Suppose and . Let . Prove that . (Assume that is defined to be )."" NOTE: refers to outer measure, i.e. for ; the length of an open interval is defined as My proof: If then so (since finite sets have outer measure ) and so , as desired. Now, suppose and let be a sequence of open intervals ( or ) such that : then is a sequence of open intervals such that ( for some i.e. ) and so and by taking the over all open coverings of we find that From this inequality we also get thus , as desired.","A\subset\mathbb{R} t\in\mathbb{R} tA:=\{ta:a\in A\} |tA|=|t||A| 0\cdot\infty 0 |\cdot| A\subset\mathbb{R},\ |A|:=\inf\{\sum_{k=1}^{\infty}l(I_k): I_1,I_2,\dots\text{ are open intervals such that }A\subset\bigcup_{k=1}^{\infty}I_k\} I\subset\mathbb{R} \ell(I):=\begin{cases}
b-a & \text{if }I=(a,b),\ a,b\in\mathbb{R}, a<b; \\
0   & \text{if }I=\emptyset; \\
\infty & \text{if } I=(-\infty, a)\text{ or } I=(a,\infty);\\
\infty & \text{ if }I=(-\infty,\infty)
\end{cases}  t=0 tA=\{0\} |tA|=0 0 |t||A|=\begin{cases}
 0\cdot |A| =0 & \text{ if } |A|<\infty\\
 0\cdot |A| =0 & \text{ if } |A|=\infty & \text{(since by hypothesis }0\cdot\infty=0)
\end{cases}\ =0 |tA|=|t||A| t\neq 0 I_1,I_2,\dots I_k=(a_k,b_k),\ a_k\in\mathbb{R}\cup-\{\infty\}, b_k\in\mathbb{R}\cup \{+\infty\}, a_k<b_k I_k=\emptyset A\subset\bigcup_{k=1}^{\infty}I_k tI_1,tI_2,\dots  tA\subset\bigcup_{k=1}^{\infty}tI_K a\in A\Rightarrow a\in I_K=(a_K,b_K)\ a_K<b_K K\geq 1\Rightarrow a_K<a<b_K\Rightarrow  
\begin{cases}
ta_K<ta<tb_K & \text{ if } t>0 \\
tb_K<ta<ta_K &\text{ if } t<0
\end{cases} ta\in tI_K l(tI_k):=\begin{cases}
tb_k-ta_k & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t>0; \\
ta_k-tb_k & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t<0; \\
0   & \text{if }I_k=\emptyset; \\
\infty & \text{if } I_k=(-\infty, b_k)\text{ or } I_k=(a_k,\infty);\\
\infty & \text{ if }I_k=(-\infty,\infty)
\end{cases}= \begin{cases}
t(b_k-a_k) & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t>0; \\
-t(b_k-a_k) & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t<0; \\
0   & \text{if }I_k=\emptyset; \\
\infty & \text{if } I_k=(-\infty, b_k)\text{ or } I_k=(a_k,\infty);\\
\infty & \text{ if }I_k=(-\infty,\infty)
\end{cases}=\begin{cases}
|t|(b_k-a_k) & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k, t\neq 0; \\
|t| 0   & \text{if }I_k=\emptyset; \\
|t|\infty & \text{if } I_k=(-\infty, b_k)\text{ or } I_k=(a_k,\infty);\\
|t|\infty & \text{ if }I_k=(-\infty,\infty)
\end{cases}=|t|\begin{cases}
(b_k-a_k) & \text{if }I_k=(a_k,b_k),\ a_k,b_k\in\mathbb{R}, a_k<b_k; \\
0   & \text{if }I_k=\emptyset; \\
\infty & \text{if } I_k=(-\infty, b_k)\text{ or } I_k=(a_k,\infty);\\
\infty & \text{ if }I_k=(-\infty,\infty)
\end{cases}=|t|I_k |tA|\leq\sum_{k=1}^{\infty}\ell (tI_k)=\sum_{k=1}^{\infty}|t|\ell (I_k)=|t|\sum_{k=1}^{\infty}\ell (I_k) \inf A |tA|\leq |t||A| \left| \frac{1}{t}tA \right| \leq \left| \frac{1}{t} \right||tA|\Rightarrow |A|\leq \frac{1}{|t|}|tA|\Rightarrow |t||A|\leq |tA| |tA|=|t||A|\ \forall t\in\mathbb{R}, A\subset\mathbb{R}","['real-analysis', 'measure-theory', 'solution-verification', 'outer-measure']"
33,Two different definitions of Lebesgue Integral in Royden,Two different definitions of Lebesgue Integral in Royden,,I am a bit puzzled by the different definitions used (by Royden) in defining integral of bounded function and of non-negative function. Why didn't he use the same definition for both types of function? Definition 1: Definition 2:,I am a bit puzzled by the different definitions used (by Royden) in defining integral of bounded function and of non-negative function. Why didn't he use the same definition for both types of function? Definition 1: Definition 2:,,"['real-analysis', 'measure-theory']"
34,Showing a set function is a premeasure,Showing a set function is a premeasure,,"Definition: Let $S$ be a collection of subsets of a set $X$ and $\mu\colon S\to[0,\infty]$ a set function. Then $\mu$ is called a premeasure provided $\mu$ is both finitely additive and countably monotone and, if $\emptyset$ belongs to $S$ , then $\mu(\emptyset) = 0$ . Question: Consider the collection $S = \{\emptyset, [0, 1], [0, 3], [2, 3]\}$ of subsets of $\mathbb{R}$ and define $\mu(\emptyset) = 0$ , $\mu([0, 1]) = 1$ , $\mu([0, 3]) = 1$ , $\mu([2, 3]) = 1$ . Show that $\mu\colon S\to[0,\infty]$ is a premeasure. Firstly, we'll show finite additivity. Notice, $\{\emptyset,[0, 1]\}$ , $\{\emptyset,[0, 3]\}$ , $\{\emptyset,[2, 3]\}$ , $\{\emptyset\}$ , $\{[0, 1]\}$ , $\{[0, 3]\}$ , $\{[2, 3]\}$ are all the finite collections of disjoint sets in $S$ whose unions of each induvial collection if back in $S$ . Further, notice for each induvial collection, $$\mu(\bigcup\{\emptyset,[0,1]\}) = \mu([0,1]) = 1  = 0 + 1 = \mu(\emptyset) + \mu(\{0,1\})$$ $$\mu(\bigcup\{\emptyset,[0,3]\}) = \mu([0,3]) = 1  = 0 + 1 = \mu(\emptyset) + \mu(\{0,3\})$$ $$\mu(\bigcup\{\emptyset,[2,3]\}) = \mu([2,3]) = 1  = 0 + 1 = \mu(\emptyset) + \mu(\{2,3\})$$ $$\mu(\bigcup\{\emptyset\}) = \mu(\emptyset) = 0  = \mu(\emptyset)$$ $$\mu(\bigcup\{[0,1]\}) = \mu([0,1]) = 1  = \mu([0,1])$$ $$\mu(\bigcup\{[0,3]\}) = \mu([0,3]) = 1  = \mu([0,3])$$ $$\mu(\bigcup\{[2,3]\}) = \mu([2,3]) = 1  = \mu([2,3]).$$ Therefore, the set function $\mu$ is finitely additive. Now, we'll show countably monotone. For $\emptyset$ any cover will have a sum of measure equal to $0$ or greater than $0$ . For $[0,1]$ any cover will have a sum of measure equal to $1$ or greater than $1$ . For $[0,3]$ any cover will have a sum of measure equal to $1$ or greater than $1$ . For $[2,3]$ any cover will have a sum of measure equal to $1$ or greater than $1$ . So, indeed whenever a set $E\in S$ is covered by a countable collection $\{E_k\}_{k=1}^{\infty}$ of sets in $S$ , then the measure of $E$ is less than the measure of the cover. Therefore, the set function $\mu$ is countably monotone. As $\emptyset$ belongs to $S$ , and $\mu(\emptyset)=0$ by construction, we have that $\mu$ is a premeasure. My question is, is the above correct?","Definition: Let be a collection of subsets of a set and a set function. Then is called a premeasure provided is both finitely additive and countably monotone and, if belongs to , then . Question: Consider the collection of subsets of and define , , , . Show that is a premeasure. Firstly, we'll show finite additivity. Notice, , , , , , , are all the finite collections of disjoint sets in whose unions of each induvial collection if back in . Further, notice for each induvial collection, Therefore, the set function is finitely additive. Now, we'll show countably monotone. For any cover will have a sum of measure equal to or greater than . For any cover will have a sum of measure equal to or greater than . For any cover will have a sum of measure equal to or greater than . For any cover will have a sum of measure equal to or greater than . So, indeed whenever a set is covered by a countable collection of sets in , then the measure of is less than the measure of the cover. Therefore, the set function is countably monotone. As belongs to , and by construction, we have that is a premeasure. My question is, is the above correct?","S X \mu\colon S\to[0,\infty] \mu \mu \emptyset S \mu(\emptyset) = 0 S = \{\emptyset, [0, 1], [0, 3], [2, 3]\} \mathbb{R} \mu(\emptyset) = 0 \mu([0, 1]) = 1 \mu([0, 3]) = 1 \mu([2, 3]) = 1 \mu\colon S\to[0,\infty] \{\emptyset,[0, 1]\} \{\emptyset,[0, 3]\} \{\emptyset,[2, 3]\} \{\emptyset\} \{[0, 1]\} \{[0, 3]\} \{[2, 3]\} S S \mu(\bigcup\{\emptyset,[0,1]\}) = \mu([0,1]) = 1  = 0 + 1 = \mu(\emptyset) + \mu(\{0,1\}) \mu(\bigcup\{\emptyset,[0,3]\}) = \mu([0,3]) = 1  = 0 + 1 = \mu(\emptyset) + \mu(\{0,3\}) \mu(\bigcup\{\emptyset,[2,3]\}) = \mu([2,3]) = 1  = 0 + 1 = \mu(\emptyset) + \mu(\{2,3\}) \mu(\bigcup\{\emptyset\}) = \mu(\emptyset) = 0  = \mu(\emptyset) \mu(\bigcup\{[0,1]\}) = \mu([0,1]) = 1  = \mu([0,1]) \mu(\bigcup\{[0,3]\}) = \mu([0,3]) = 1  = \mu([0,3]) \mu(\bigcup\{[2,3]\}) = \mu([2,3]) = 1  = \mu([2,3]). \mu \emptyset 0 0 [0,1] 1 1 [0,3] 1 1 [2,3] 1 1 E\in S \{E_k\}_{k=1}^{\infty} S E \mu \emptyset S \mu(\emptyset)=0 \mu","['real-analysis', 'measure-theory']"
35,Show $\mu_*$ is a measure,Show  is a measure,\mu_*,"Suppose $\mu$ is a finitely additive set function on Borel $\sigma$ algebra on $\mathbb R$ with $\mu(\mathbb R)<\infty$ . Define $\mu_*(A)=\sup \{\mu(K)|K\subset A,K$ compact $\}$ . Show that $\mu_*$ is a measure on Borel sets. I cannot even show $\mu_*$ is finitely additive. More specifically, I need help in the following direction. If A,B are disjoint Borel then $\mu_*(A\cup B)\leq \mu_*(A)+\mu_*(B)$ . The issue is, if I take any compact K subset of $A\cup B$ then I cannot split K to get compact sets K1 and K2 subsets of A and B respectively.","Suppose is a finitely additive set function on Borel algebra on with . Define compact . Show that is a measure on Borel sets. I cannot even show is finitely additive. More specifically, I need help in the following direction. If A,B are disjoint Borel then . The issue is, if I take any compact K subset of then I cannot split K to get compact sets K1 and K2 subsets of A and B respectively.","\mu \sigma \mathbb R \mu(\mathbb R)<\infty \mu_*(A)=\sup \{\mu(K)|K\subset A,K \} \mu_* \mu_* \mu_*(A\cup B)\leq \mu_*(A)+\mu_*(B) A\cup B","['real-analysis', 'measure-theory']"
36,Show the left shift $T$ and $T^{-1} $ are measurable.,Show the left shift  and  are measurable.,T T^{-1} ,"Let $X=\{0,1 \}^{\mathbb{Z}}$ . So an element of $X$ is given by a sequence $(x_i)_{i\in \mathbb{Z}}$ , where $x_i \in \{0,1 \}$ . Let $\mu_i$ be a probability measure on $(\{0,1 \}, \mathcal{P}(\{0,1 \}))$ , where $\mu_i(\{0\})= \mu_i (\{1 \})= \frac{1}{2}$ . Define $\mu = \Pi_{i\in \mathbb{Z}} \mu_i$ , and $B = \bigotimes_{i\in \mathbb{Z}} \mathcal{P}(\{0,1 \})$ . Let $T: X \rightarrow X$ be the Bernoulli shift defined by $T(x_i)=x_{i-1}$ for $i\in \mathbb{Z}$ . Show $T$ and $T^{-1}$ are measurable and $T$ is measure-preserving. Attempt: Let $A \in B$ . To show that $T$ is measurable, I want to show that $T^{-1}(A)= \{x_{i+1} :  (x_i)_{i\in \mathbb{Z}} \in A \} \in B$ . Define $H= \{A \subset X : T^{-1}(A) \in B \}$ . I showed that $H$ is a $\sigma$ -algebra. So $B \subset H$ . Thus, $T$ is measurable. To show that $T^{-1} $ is measurable, can I do the same thing using $\sigma$ -algebras? I'm not sure about this part. To show that $T$ is measure-preserving, I need to show that $\mu(A)= \mu(T^{-1}(A))$ for all $A\in B$ . I don't have any clues for this part either. Any help will be appreciated. Thank you!","Let . So an element of is given by a sequence , where . Let be a probability measure on , where . Define , and . Let be the Bernoulli shift defined by for . Show and are measurable and is measure-preserving. Attempt: Let . To show that is measurable, I want to show that . Define . I showed that is a -algebra. So . Thus, is measurable. To show that is measurable, can I do the same thing using -algebras? I'm not sure about this part. To show that is measure-preserving, I need to show that for all . I don't have any clues for this part either. Any help will be appreciated. Thank you!","X=\{0,1 \}^{\mathbb{Z}} X (x_i)_{i\in \mathbb{Z}} x_i \in \{0,1 \} \mu_i (\{0,1 \}, \mathcal{P}(\{0,1 \})) \mu_i(\{0\})= \mu_i (\{1 \})= \frac{1}{2} \mu = \Pi_{i\in \mathbb{Z}} \mu_i B = \bigotimes_{i\in \mathbb{Z}} \mathcal{P}(\{0,1 \}) T: X \rightarrow X T(x_i)=x_{i-1} i\in \mathbb{Z} T T^{-1} T A \in B T T^{-1}(A)= \{x_{i+1} :  (x_i)_{i\in \mathbb{Z}} \in A \} \in B H= \{A \subset X : T^{-1}(A) \in B \} H \sigma B \subset H T T^{-1}  \sigma T \mu(A)= \mu(T^{-1}(A)) A\in B","['measure-theory', 'lebesgue-measure', 'product-measure']"
37,Norm of the operator and Riesz-Markov-Kakutani measure - example functional,Norm of the operator and Riesz-Markov-Kakutani measure - example functional,,"Let $X = C[0,1]$ with supremum norm. Define linear functional: $$ \varphi(f) = \int_0^1f(x)cos(\pi x)dx - f(\frac{1}{2}) $$ Show that $\varphi$ is bounded and compute its norm. Using the Riesz–Markov–Kakutani representation theorem give the complex measure that is associated with that functional. My attempt was: Bounded: $$ \|\varphi\| = \sup_{\|f\|_{\infty}=1}|\varphi(f)| = \sup_{\|f\|_{\infty}=1}|\int_0^1f(x)cos(\pi x)dx - f(\frac{1}{2})| = \\ \leq \sup_{\|f\|_{\infty}=1}\int_0^1|f(x)cos(\pi x)|dx + |f(\frac{1}{2})| \\ \leq \sup_{\|f\|_{\infty}=1}\|f\|_{\infty}\int_0^1|cos(\pi x)|dx + \|f\|_{\infty} \leq 1 + 1 = 2 $$ Where last equation is due to cosine function being bounded by 1. Now the norm, letting $f = 2$ (constant): $$ \|\varphi(f)\| = |2\int_0^1cos(\pi x) - 2| = |0 - 2| = 2 $$ so the norm (taking the bound into account) is equal to 2. Lastly, the measure seems to be: $$ \mu(A) = \cos{(\pi x)}d\lambda(A) - \delta_{\frac{1}{2}}(A) $$ because then $$ \int_0^1fd\mu = \int_0^1fd\cos{(\pi x)}- \delta_{\frac{1}{2}} = \int_0^1f(x)cos(\pi x)dx - f(\frac{1}{2}) $$ It was an exam task and I only got half of the points. Could anyone show me the correct answer? I suppose my measure is wrong ( $\lambda(A)$ doesn't make much sense) but I didn't have better ideas that time.","Let with supremum norm. Define linear functional: Show that is bounded and compute its norm. Using the Riesz–Markov–Kakutani representation theorem give the complex measure that is associated with that functional. My attempt was: Bounded: Where last equation is due to cosine function being bounded by 1. Now the norm, letting (constant): so the norm (taking the bound into account) is equal to 2. Lastly, the measure seems to be: because then It was an exam task and I only got half of the points. Could anyone show me the correct answer? I suppose my measure is wrong ( doesn't make much sense) but I didn't have better ideas that time.","X = C[0,1] 
\varphi(f) = \int_0^1f(x)cos(\pi x)dx - f(\frac{1}{2})
 \varphi 
\|\varphi\| = \sup_{\|f\|_{\infty}=1}|\varphi(f)| = \sup_{\|f\|_{\infty}=1}|\int_0^1f(x)cos(\pi x)dx - f(\frac{1}{2})| = \\
\leq \sup_{\|f\|_{\infty}=1}\int_0^1|f(x)cos(\pi x)|dx + |f(\frac{1}{2})| \\
\leq \sup_{\|f\|_{\infty}=1}\|f\|_{\infty}\int_0^1|cos(\pi x)|dx + \|f\|_{\infty} \leq 1 + 1 = 2
 f = 2 
\|\varphi(f)\| = |2\int_0^1cos(\pi x) - 2| = |0 - 2| = 2
 
\mu(A) = \cos{(\pi x)}d\lambda(A) - \delta_{\frac{1}{2}}(A)
 
\int_0^1fd\mu = \int_0^1fd\cos{(\pi x)}- \delta_{\frac{1}{2}} = \int_0^1f(x)cos(\pi x)dx - f(\frac{1}{2})
 \lambda(A)","['functional-analysis', 'measure-theory']"
38,What Is This Measure Theory Rule Called? Is it Just the Substitution Rule in Disguise?,What Is This Measure Theory Rule Called? Is it Just the Substitution Rule in Disguise?,,"Let $(\Omega,\mathcal{F},\mu)$ be a measure space. For a $\mathcal{B}(\mathbb{R})$ -measurable function $f \geq 0 : \Omega \rightarrow \mathbb{R}$ one can define a measure $\nu$ by: $$ \nu(A) : = \int_A f d \mu = \int f \mathbb{1}_{A} d \mu $$ $\nu$ is provably a measure according to this answer . Now suppose we have some $\mathcal{B}(\mathbb{R})$ -measurable function $g : \Omega \rightarrow \mathbb{R}$ . And suppose $g$ is integrable w.r.t. $\nu$ . Question: Does this identity have a standard name in measure theory: $$\int gf d \mu = \int g d \nu$$ Note: maybe the exact identity above isn't a named result in measure theory, but can be shown via the application of one or two standard measure theory results? I think I can prove the identity using first principles of measure theory, but I'd rather use more standard results and my common sense is telling me the above is so simple it must have a standard name in measure theory that I'm just missing. The proof of the identity I imagine is to use the approximation theorem for integrals, which asserts that a sequence of increasing simple functions approximates $\int g d \nu$ . That is, we approximate with functions of the form: $$\sum_{i=1}^n a_i \nu(A_i) = \sum_{i=1}^n a_i \int_{A_i} f d \mu$$ We can then invoke the approximation theorem again for the integrals inside the sum: $$\sum_{i=1}^n a_i \sum_{j=1}^m b_{i,j} \mu(B_{i, j}) = \sum_{i=1}^n \sum_{j=1}^m a_ib_{i,j} \mu(B_{i, j})$$ Where $\bigcup_{j=1}^m B_{i, j} = A_i$ . Since all the $B_{i,j}$ are disjoint, then the above is a simple function. Moreover, our invocations of the approximation theorem guarantee us that: $\forall \omega \in B_{i,j} \subseteq A_i : a_i \leq g(\omega)$ $\forall \omega \in B_{i,j} : b_{i,j} \leq f(\omega)$ Therefore, we have: $$\forall \omega \in B_{i,j} : a_ib_{i,j} \leq gf(\omega)$$ And so the term on the RHS is the integral of a simple function which is bounded by $gf$ . And since the integral of $gf$ is the supremum over all such integrals of simple functions we have the bound: $$\int gf d \mu \geq \int g d \nu$$ OK... so this is just an inequality rather than an identify. But I believe the proof can be fixed & completed by invoking the approximation theorem more fully: this will give us a sequence of simple functions converging to $f$ and another sequence converging to $g$ . Then we can show that the resulting simple functions constructed above converges to $gf$ and so by the monotone convergence theorem the integrals will converge also. But rather than complete this result in my own clunky way, I'd rather first see if there is some known result or results that can be applied here rather than go right back to first principles and simple functions. Note: The induced measure $\nu$ is a measure on the original measurable space $(\Omega,\mathcal{F})$ - not a pushforward measure to $\mathcal{B}(\mathbb{R})$ . So I can't see how something like change of variables / substitution can be applied. Unless I'm just not being creative enough... Credit to this question for borrowed text.","Let be a measure space. For a -measurable function one can define a measure by: is provably a measure according to this answer . Now suppose we have some -measurable function . And suppose is integrable w.r.t. . Question: Does this identity have a standard name in measure theory: Note: maybe the exact identity above isn't a named result in measure theory, but can be shown via the application of one or two standard measure theory results? I think I can prove the identity using first principles of measure theory, but I'd rather use more standard results and my common sense is telling me the above is so simple it must have a standard name in measure theory that I'm just missing. The proof of the identity I imagine is to use the approximation theorem for integrals, which asserts that a sequence of increasing simple functions approximates . That is, we approximate with functions of the form: We can then invoke the approximation theorem again for the integrals inside the sum: Where . Since all the are disjoint, then the above is a simple function. Moreover, our invocations of the approximation theorem guarantee us that: Therefore, we have: And so the term on the RHS is the integral of a simple function which is bounded by . And since the integral of is the supremum over all such integrals of simple functions we have the bound: OK... so this is just an inequality rather than an identify. But I believe the proof can be fixed & completed by invoking the approximation theorem more fully: this will give us a sequence of simple functions converging to and another sequence converging to . Then we can show that the resulting simple functions constructed above converges to and so by the monotone convergence theorem the integrals will converge also. But rather than complete this result in my own clunky way, I'd rather first see if there is some known result or results that can be applied here rather than go right back to first principles and simple functions. Note: The induced measure is a measure on the original measurable space - not a pushforward measure to . So I can't see how something like change of variables / substitution can be applied. Unless I'm just not being creative enough... Credit to this question for borrowed text.","(\Omega,\mathcal{F},\mu) \mathcal{B}(\mathbb{R}) f \geq 0 : \Omega \rightarrow \mathbb{R} \nu 
\nu(A) : = \int_A f d \mu = \int f \mathbb{1}_{A} d \mu
 \nu \mathcal{B}(\mathbb{R}) g : \Omega \rightarrow \mathbb{R} g \nu \int gf d \mu = \int g d \nu \int g d \nu \sum_{i=1}^n a_i \nu(A_i) = \sum_{i=1}^n a_i \int_{A_i} f d \mu \sum_{i=1}^n a_i \sum_{j=1}^m b_{i,j} \mu(B_{i, j}) = \sum_{i=1}^n \sum_{j=1}^m a_ib_{i,j} \mu(B_{i, j}) \bigcup_{j=1}^m B_{i, j} = A_i B_{i,j} \forall \omega \in B_{i,j} \subseteq A_i : a_i \leq g(\omega) \forall \omega \in B_{i,j} : b_{i,j} \leq f(\omega) \forall \omega \in B_{i,j} : a_ib_{i,j} \leq gf(\omega) gf gf \int gf d \mu \geq \int g d \nu f g gf \nu (\Omega,\mathcal{F}) \mathcal{B}(\mathbb{R})","['integration', 'measure-theory', 'reference-request']"
39,Summable function that is not infinitesimal,Summable function that is not infinitesimal,,"This comes out from this exercise: Let $u$ Harmonic on $\mathbb{R}^n$ and $\int_{_{\mathbb{R}^n}}u(x)^2 dx<+\infty$ prove that $u(x)=0$ . I want to use that $\mathbb{R}^n$ and $\int_{_{\mathbb{R}^n}}u(x)^2 dx<+\infty$ implies $\lim_{|x|\to+\infty}|u(x)|=0$ . I am not sure of this property, is it real? I mean, one can prove the exercise and than it shows that is real, but to prove the exercise one use Cauchy Shwartz on $\langle 1,u\rangle$ (i can give more datails). So the question is when does $\mathbb{R}^n$ and $\int_{_{\mathbb{R}^n}}u(x)^2 dx<+\infty$ implies $\lim_{|x|\to+\infty}|u(x)|=0$ in general?","This comes out from this exercise: Let Harmonic on and prove that . I want to use that and implies . I am not sure of this property, is it real? I mean, one can prove the exercise and than it shows that is real, but to prove the exercise one use Cauchy Shwartz on (i can give more datails). So the question is when does and implies in general?","u \mathbb{R}^n \int_{_{\mathbb{R}^n}}u(x)^2 dx<+\infty u(x)=0 \mathbb{R}^n \int_{_{\mathbb{R}^n}}u(x)^2 dx<+\infty \lim_{|x|\to+\infty}|u(x)|=0 \langle 1,u\rangle \mathbb{R}^n \int_{_{\mathbb{R}^n}}u(x)^2 dx<+\infty \lim_{|x|\to+\infty}|u(x)|=0","['real-analysis', 'measure-theory', 'improper-integrals']"
40,Sufficient Conditions for Borel-Cantelli,Sufficient Conditions for Borel-Cantelli,,"The first Borel-Cantelli Lemma states If $\sum \mathbf{P}(A_n) < \infty$ then $\mathbf{P}(A_n i.o.) = 0$ Question : If $\mathbf{P}(A_n) \rightarrow 0$ and $\sum \mathbf{P}(A_{n+1} / A_{n}) < \infty$ then $\mathbf{P}(A_n i.o.) = 0$ Now of course $\sum \mathbf{P}(A_{n+1} / A_{n}) < \infty$ does not imply $\sum \mathbf{P}(A_n) < \infty$ . For example we can take $\mathbf{P}(A_n) = 1/n$ . So how can we takle such a problem. My approach: We can find indices $n_k$ s.t. $\sum_{n_k}^{n_{k+1}}\mathbf{P}(A_n) < 1/k^2$ $k = 1,2,3..$ Define an event $B_k = \cup_{n_k}^{n_{k+1}}\mathbf{P}(A_n) $ Then By Borel Cantelli $\mathbf{P}(B_n i.o.) = 0$ Thus as only a finite number of $B_n$ s happen we conclude on a finite number of $A_n$ s happen. Any help is appreciated",The first Borel-Cantelli Lemma states If then Question : If and then Now of course does not imply . For example we can take . So how can we takle such a problem. My approach: We can find indices s.t. Define an event Then By Borel Cantelli Thus as only a finite number of s happen we conclude on a finite number of s happen. Any help is appreciated,"\sum \mathbf{P}(A_n) < \infty \mathbf{P}(A_n i.o.) = 0 \mathbf{P}(A_n) \rightarrow 0 \sum \mathbf{P}(A_{n+1} / A_{n}) < \infty \mathbf{P}(A_n i.o.) = 0 \sum \mathbf{P}(A_{n+1} / A_{n}) < \infty \sum \mathbf{P}(A_n) < \infty \mathbf{P}(A_n) = 1/n n_k \sum_{n_k}^{n_{k+1}}\mathbf{P}(A_n) < 1/k^2 k = 1,2,3.. B_k = \cup_{n_k}^{n_{k+1}}\mathbf{P}(A_n)  \mathbf{P}(B_n i.o.) = 0 B_n A_n","['measure-theory', 'convergence-divergence', 'probability-limit-theorems', 'borel-cantelli-lemmas']"
41,Estimate volume of Tubes around a smooth hypersurface,Estimate volume of Tubes around a smooth hypersurface,,"Suppose $\Sigma \subset \mathbb{R}^n$ is a smooth compact hypersurface and the boundary of some set $\Omega$ .  Now set $\Sigma_r:=\{x \in \Omega^c: \inf_{y\in \Sigma} |x-y|\leq r\}$ to be a tube of radius $r$ around the hypersurface. I was wondering if it is possible to somehow estimate the volume of these tubes in terms of the area of $\Sigma$ , like for example $$ vol(\Sigma_r) \leq C_{\Sigma} \cdot r \cdot area(\Sigma).  $$ It should be possible for small $r$ due to this formula. There is of course a trivial bound like if I take some ball $B_R(y)$ such that $\Sigma \in B_R(y)$ then $ vol(\Sigma_r) \leq vol(B_{R+r}(y)). $ Is there something better?","Suppose is a smooth compact hypersurface and the boundary of some set .  Now set to be a tube of radius around the hypersurface. I was wondering if it is possible to somehow estimate the volume of these tubes in terms of the area of , like for example It should be possible for small due to this formula. There is of course a trivial bound like if I take some ball such that then Is there something better?","\Sigma \subset \mathbb{R}^n \Omega \Sigma_r:=\{x \in \Omega^c: \inf_{y\in \Sigma} |x-y|\leq r\} r \Sigma 
vol(\Sigma_r) \leq C_{\Sigma} \cdot r \cdot area(\Sigma). 
 r B_R(y) \Sigma \in B_R(y) 
vol(\Sigma_r) \leq vol(B_{R+r}(y)).
","['measure-theory', 'differential-geometry']"
42,Is the following an example of a non-measurable event?,Is the following an example of a non-measurable event?,,"Goodmorning everyone. I started reading DeGroot and Schervish's 'Probability and Statistics' (4th editon) and wondered,  is there an uncountable union of events, that is not an event? This question has been answered on this site. The topic of question is ""What is an uncountable union of events?"" (sorry ba I can't report the code or the link of the question that has already been answered). The responses were very illuminating, however, re-reading the example of an uncountable union of events that is not an event, I'm referring to Arthur's answer, I wonder if the example is adequate. This confuses me. I report the example referred to in the aforementioned answer and then I ask my question. Example: Assuming the Axiom of Choice (which is a very reasonable and common thing to do, but not universal), you can construct unions of events which, if allowed to be events themselves, will have a problematic probability of ocurring. Basically, it can't be 0 and it can't be positive. To see it in action, let's say your experiment is to pick a point uniformly at random on a circle. Then any point is an event. Using the AoC, we can construct (or more correctly, we can prove the existence of) a set of points A0 on the circle with a special property: Rotating the set along the circle by any rational angle α∈(0∘,360∘) results in a new set of points Aα. None of these Aα have any points in common with any of the others, but together they cover the entire circle. So, if we were to assign some probability p to picking a point in A0, then by rotational symmetry the same probability should apply to any of the Aα. And since they are all pairwise disjoint, and they together cover the circle, the sum of all those p's should be 1. Thus we have ∑α∈[0,360)∩Qp=1 But if p is 0, the sum is 0, and if p is positive, then the sum is infinite. So it is impossible to assign a probability to this union A0, and therefore we are better off not calling it an event. Question Why can't I consider the set of rational points to have zero measure? If I imagine the circle composed of rational and irrational points, why not assign a measure of nothing on the first (rational) and measure equal to 1 on the second (irrational)? so, having admitted the above, am I wrong if I consider the circle as a union of rational and irrational points? Thanks for any answer or clarification. Francesco.","Goodmorning everyone. I started reading DeGroot and Schervish's 'Probability and Statistics' (4th editon) and wondered,  is there an uncountable union of events, that is not an event? This question has been answered on this site. The topic of question is ""What is an uncountable union of events?"" (sorry ba I can't report the code or the link of the question that has already been answered). The responses were very illuminating, however, re-reading the example of an uncountable union of events that is not an event, I'm referring to Arthur's answer, I wonder if the example is adequate. This confuses me. I report the example referred to in the aforementioned answer and then I ask my question. Example: Assuming the Axiom of Choice (which is a very reasonable and common thing to do, but not universal), you can construct unions of events which, if allowed to be events themselves, will have a problematic probability of ocurring. Basically, it can't be 0 and it can't be positive. To see it in action, let's say your experiment is to pick a point uniformly at random on a circle. Then any point is an event. Using the AoC, we can construct (or more correctly, we can prove the existence of) a set of points A0 on the circle with a special property: Rotating the set along the circle by any rational angle α∈(0∘,360∘) results in a new set of points Aα. None of these Aα have any points in common with any of the others, but together they cover the entire circle. So, if we were to assign some probability p to picking a point in A0, then by rotational symmetry the same probability should apply to any of the Aα. And since they are all pairwise disjoint, and they together cover the circle, the sum of all those p's should be 1. Thus we have ∑α∈[0,360)∩Qp=1 But if p is 0, the sum is 0, and if p is positive, then the sum is infinite. So it is impossible to assign a probability to this union A0, and therefore we are better off not calling it an event. Question Why can't I consider the set of rational points to have zero measure? If I imagine the circle composed of rational and irrational points, why not assign a measure of nothing on the first (rational) and measure equal to 1 on the second (irrational)? so, having admitted the above, am I wrong if I consider the circle as a union of rational and irrational points? Thanks for any answer or clarification. Francesco.",,['measure-theory']
43,Induction of topological space by an $L^2$-space,Induction of topological space by an -space,L^2,"Let $(L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}),\langle\cdot,\cdot\rangle)$ be a Hilbert space, where $L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ denotes the set of all (equivalence classes of) $\boldsymbol{\Xi}$ -measurable $\mathbb{R}$ -valued functions that are square $\mu$ -integrable on $\Xi$ , and $\langle\cdot,\cdot\rangle:L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\times L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\to\mathbb{R}$ denotes its standard inner product given by $$\langle f,g\rangle=\int fg\,\mathrm{d}\mu.$$ I know that this Hilbert space induces a topological space whose induced standard topology $\mathcal{O}$ is the one generated by all open balls whose radii are measured using the induced standard metric $d:L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\times L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\to\mathbb{R}_0^+$ given by $$d(f,g)=\langle f-g,f-g\rangle^{\tfrac{1}{2}}.$$ My question is how to write this standard topology symbolically. At the moment I have defined the topological basis: $$\mathscr{B}=\{B_r(f)\subset L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\,\mid\, r\in\mathbb{R}^+,f\in L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\},$$ where $B_r(f):=\{g\in L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\mid d(f,g)<r\}$ is the open ball of radius $r$ centered at $f$ . Then, we define $\mathcal{O}=\varphi(\mathscr{B})$ . Here $\varphi$ represents a map which takes a topological basis as an input and returns a topology as an output. In measure theory, we have the map $\sigma$ which generates a $\sigma$ -algebra from a given collection of subsets. I thought that the same could be done here. However, I haven't found the actual symbol for performing such an operation on a topological basis yet. So, is this the correct way to write the induced standard topology symbolically? Also, is there a better way to write the same thing? Thank you, Frederick.","Let be a Hilbert space, where denotes the set of all (equivalence classes of) -measurable -valued functions that are square -integrable on , and denotes its standard inner product given by I know that this Hilbert space induces a topological space whose induced standard topology is the one generated by all open balls whose radii are measured using the induced standard metric given by My question is how to write this standard topology symbolically. At the moment I have defined the topological basis: where is the open ball of radius centered at . Then, we define . Here represents a map which takes a topological basis as an input and returns a topology as an output. In measure theory, we have the map which generates a -algebra from a given collection of subsets. I thought that the same could be done here. However, I haven't found the actual symbol for performing such an operation on a topological basis yet. So, is this the correct way to write the induced standard topology symbolically? Also, is there a better way to write the same thing? Thank you, Frederick.","(L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}),\langle\cdot,\cdot\rangle) L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}) \boldsymbol{\Xi} \mathbb{R} \mu \Xi \langle\cdot,\cdot\rangle:L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\times L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\to\mathbb{R} \langle f,g\rangle=\int fg\,\mathrm{d}\mu. \mathcal{O} d:L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\times L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\to\mathbb{R}_0^+ d(f,g)=\langle f-g,f-g\rangle^{\tfrac{1}{2}}. \mathscr{B}=\{B_r(f)\subset L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\,\mid\, r\in\mathbb{R}^+,f\in L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\}, B_r(f):=\{g\in L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\mid d(f,g)<r\} r f \mathcal{O}=\varphi(\mathscr{B}) \varphi \sigma \sigma","['real-analysis', 'general-topology', 'measure-theory', 'lp-spaces', 'measurable-functions']"
44,Lebesgue measure of $\partial A$ given $m(A^o) = m(\overline{A})$,Lebesgue measure of  given,\partial A m(A^o) = m(\overline{A}),"Suppose that $A \subseteq \mathbb{R}$ , and consider the Lebesgue outer measure $m: \mathcal{P}(\mathbb{R}) \to [0,\infty]$ on $\mathbb{R}$ . Denote by $A^o$ , $\overline{A}$ and $\partial A$ the interior, closure and boundary of $A$ , respectively. Suppose that $m(A^o) = m(\overline{A})$ . Is it then true that $m(\partial A) = 0$ ? This is certainly true if $m(A) < \infty$ . Since open sets and closed sets are Lebesgue measurable, we have that $A^o$ and $\overline{A}$ are Lebesgue measurable, and hence so is $\partial A = \overline{A} \setminus A^o$ . Therefore, we can write $m(\overline{A}) = m(A^o) + m(\partial A)$ . By the monotonicity of the Lebesgue outer measure, we also have that $m(A^o) < \infty$ . Hence, we can cancel to conclude. But what about the case $m(A) = \infty$ ? If we take for example $A = \bigcup_{n \geq 1} (n - 1, n)$ , then $m(A^0) = m(\overline{A}) = \infty$ , but $m(\partial A) = m(\mathbb{N}) = 0$ . Are there any counter examples?","Suppose that , and consider the Lebesgue outer measure on . Denote by , and the interior, closure and boundary of , respectively. Suppose that . Is it then true that ? This is certainly true if . Since open sets and closed sets are Lebesgue measurable, we have that and are Lebesgue measurable, and hence so is . Therefore, we can write . By the monotonicity of the Lebesgue outer measure, we also have that . Hence, we can cancel to conclude. But what about the case ? If we take for example , then , but . Are there any counter examples?","A \subseteq \mathbb{R} m: \mathcal{P}(\mathbb{R}) \to [0,\infty] \mathbb{R} A^o \overline{A} \partial A A m(A^o) = m(\overline{A}) m(\partial A) = 0 m(A) < \infty A^o \overline{A} \partial A = \overline{A} \setminus A^o m(\overline{A}) = m(A^o) + m(\partial A) m(A^o) < \infty m(A) = \infty A = \bigcup_{n \geq 1} (n - 1, n) m(A^0) = m(\overline{A}) = \infty m(\partial A) = m(\mathbb{N}) = 0",['real-analysis']
45,$L^p$ integrability condition,integrability condition,L^p,"I am trying to prove an equivalent condition for functions belonging in $L^p$ . It's convergence of $\sum_{n\in\mathbb{Z}}2^{np}m(|f|>2^n)$ . the one direction is an easy application of Chebyshev's inequality. However I am having trouble with the reverse direction. that is whenever the series converges, then $\|f\|_p<+\infty$ .","I am trying to prove an equivalent condition for functions belonging in . It's convergence of . the one direction is an easy application of Chebyshev's inequality. However I am having trouble with the reverse direction. that is whenever the series converges, then .",L^p \sum_{n\in\mathbb{Z}}2^{np}m(|f|>2^n) \|f\|_p<+\infty,"['functional-analysis', 'measure-theory']"
46,Every measurable set in $X \times Y$ is contained in a measurable rectangle,Every measurable set in  is contained in a measurable rectangle,X \times Y,"If $X$ and $Y$ are any two sets (not necessarily subsets of the same space), the Cartesian product $X \times Y$ is the set of all ordered pairs $(x,y)$ , where $x \in X$ and $y \in Y$ . Thus, for instance, if $A \subset X$ and $B \subset Y$ , we shall call the set $E = A \times B$ (a subset of $X \times Y$ ) a rectangle and we shall refer to the component sets $A$ and $B$ as its sides. In our context the word ""class"" should be understood as a set of sets. So the class of measurable rectangles refers to the set of measurable rectangles. So I want to use the fact that a rectangle $A \times B$ in the Cartesian product of two measurable spaces $(X, S)$ and $(Y, T)$ , (where $S$ and $T$ are $\sigma$ -rings of subsets of $X$ and $Y$ respectively), is measurable if $ A \in S $ and $ B \in T $ . I am reading the Measure Theory book by Paul Halmos, I have found this. Exercise (6) Section 33. If $(X,S)$ and $(Y,T)$ are measurable spaces, then every  measurable set in $X \times Y$ is contained in a measurable rectangle. My idea is the following: the class of all those sets which way be covered by a measurable rectangle is a $\sigma$ -Ring. I think this class contains every measurable set of $ X\times Y$ , on the other hand if I test that it is a $ \sigma $ -Ring I have finished","If and are any two sets (not necessarily subsets of the same space), the Cartesian product is the set of all ordered pairs , where and . Thus, for instance, if and , we shall call the set (a subset of ) a rectangle and we shall refer to the component sets and as its sides. In our context the word ""class"" should be understood as a set of sets. So the class of measurable rectangles refers to the set of measurable rectangles. So I want to use the fact that a rectangle in the Cartesian product of two measurable spaces and , (where and are -rings of subsets of and respectively), is measurable if and . I am reading the Measure Theory book by Paul Halmos, I have found this. Exercise (6) Section 33. If and are measurable spaces, then every  measurable set in is contained in a measurable rectangle. My idea is the following: the class of all those sets which way be covered by a measurable rectangle is a -Ring. I think this class contains every measurable set of , on the other hand if I test that it is a -Ring I have finished","X Y X \times Y (x,y) x \in X y \in Y A \subset X B \subset Y E = A \times B X \times Y A B A \times B (X, S) (Y, T) S T \sigma X Y  A \in S   B \in T  (X,S) (Y,T) X \times Y \sigma  X\times Y  \sigma ",['measure-theory']
47,"Borel $\sigma$-algebra is equivalent to the smallest $\sigma$-algebra containing (a,$\infty$)","Borel -algebra is equivalent to the smallest -algebra containing (a,)",\sigma \sigma \infty,"I'm trying to prove that the Borel $\sigma$ -algebra is equivalent to the smallest $\sigma$ -algebra containing (a, $\infty$ ). The approach I'm trying to use is to show that if A $\subset$ B and B $\subset$ A, then A=B. So far I think I have the first part: (a, $\infty$ ) = $\cup$ (a, n) and since each (a, n) is a finite open interval, then they are included in the Borel $\sigma$ -algebra and since a $\sigma$ -algebra is closed with respect to countable union, then the smallest $\sigma$ -algebra containing (a, $\infty$ ) $\subset$ Borel $\sigma$ -algebra. Looking at (a,b) it seems obvious that it would be contained within (a, $\infty$ ), but I'm not sure if it is sufficient to just say that for the second part of this proof or if there is a formal way to show that (a,b) is contained in (a, $\infty$ ).","I'm trying to prove that the Borel -algebra is equivalent to the smallest -algebra containing (a, ). The approach I'm trying to use is to show that if A B and B A, then A=B. So far I think I have the first part: (a, ) = (a, n) and since each (a, n) is a finite open interval, then they are included in the Borel -algebra and since a -algebra is closed with respect to countable union, then the smallest -algebra containing (a, ) Borel -algebra. Looking at (a,b) it seems obvious that it would be contained within (a, ), but I'm not sure if it is sufficient to just say that for the second part of this proof or if there is a formal way to show that (a,b) is contained in (a, ).",\sigma \sigma \infty \subset \subset \infty \cup \sigma \sigma \sigma \infty \subset \sigma \infty \infty,"['measure-theory', 'solution-verification']"
48,Prove $h_{p\mu+(1-p)\nu}(T)=ph_\mu(T)+(1-p)h_\nu(T)$,Prove,h_{p\mu+(1-p)\nu}(T)=ph_\mu(T)+(1-p)h_\nu(T),"Let $T:X\to X$ be a continuous map on a compact metric space. I'm trying to prove that for two $T$ -invariant probability measures $\mu,\nu$ we have $h_{p\mu+(1-p)\nu}(T)=ph_\mu(T)+(1-p)h_\nu(T)$ . Here $h_\mu(T)$ denotes the metric entropy of $T$ , also known as the measure theoretic entropy . I managed to show that we have $h_{p\mu+(1-p)\nu}(T)\geq ph_\mu(T)+(1-p)h_\nu(T)$ by defining $\Phi:[0,\infty)\to\mathbb R$ by $\Phi(x)=-x\log x$ for $x>0$ and $\Phi(0)=0$ ; then $\Phi$ is a concave function, hence by Jensen $$p\Phi(\mu(A))+(1-p)\Phi(\nu(A))\leq\Phi(p\mu(A)+(1-p)\nu(A))$$ for each measurable $A$ . Applying this to finite measurable partitions $\alpha$ gives $H_{p\mu+(1-p)\nu}(\alpha)\geq pH_\mu(\alpha)+(1-p)H_\nu(\alpha)$ . Next, we plug in $\bigvee_{i=0}^{n-1}T^{-i}\alpha$ , divide by $n$ and letting $n\to\infty$ and obtain $h_{p\mu+(1-p)\nu}(\alpha,T)\geq ph_\mu(\alpha,T)+(1-p)h_\nu(\alpha,T)$ . Then we find partitions $\alpha_\mu,\alpha_\nu$ such that $h_\mu(\alpha_\mu,T)\geq h_\mu(T)-\frac{\epsilon}{p}$ and $h_\mu(\alpha_\nu,T)\geq h_\nu(T)-\frac{\epsilon}{1-p}$ , yielding $$h_{p\mu+(1-p)\nu}(\alpha_\mu\vee\alpha_\nu,T)\geq ph_\mu(T)+(1-p)h_\nu(T)-\epsilon;$$ passing to the supremum over all measurable partition $\alpha$ on the left hand side gives the desired inequality. For the reverse inequality, I have no idea what to do. Any help is much appreciated!","Let be a continuous map on a compact metric space. I'm trying to prove that for two -invariant probability measures we have . Here denotes the metric entropy of , also known as the measure theoretic entropy . I managed to show that we have by defining by for and ; then is a concave function, hence by Jensen for each measurable . Applying this to finite measurable partitions gives . Next, we plug in , divide by and letting and obtain . Then we find partitions such that and , yielding passing to the supremum over all measurable partition on the left hand side gives the desired inequality. For the reverse inequality, I have no idea what to do. Any help is much appreciated!","T:X\to X T \mu,\nu h_{p\mu+(1-p)\nu}(T)=ph_\mu(T)+(1-p)h_\nu(T) h_\mu(T) T h_{p\mu+(1-p)\nu}(T)\geq ph_\mu(T)+(1-p)h_\nu(T) \Phi:[0,\infty)\to\mathbb R \Phi(x)=-x\log x x>0 \Phi(0)=0 \Phi p\Phi(\mu(A))+(1-p)\Phi(\nu(A))\leq\Phi(p\mu(A)+(1-p)\nu(A)) A \alpha H_{p\mu+(1-p)\nu}(\alpha)\geq pH_\mu(\alpha)+(1-p)H_\nu(\alpha) \bigvee_{i=0}^{n-1}T^{-i}\alpha n n\to\infty h_{p\mu+(1-p)\nu}(\alpha,T)\geq ph_\mu(\alpha,T)+(1-p)h_\nu(\alpha,T) \alpha_\mu,\alpha_\nu h_\mu(\alpha_\mu,T)\geq h_\mu(T)-\frac{\epsilon}{p} h_\mu(\alpha_\nu,T)\geq h_\nu(T)-\frac{\epsilon}{1-p} h_{p\mu+(1-p)\nu}(\alpha_\mu\vee\alpha_\nu,T)\geq ph_\mu(T)+(1-p)h_\nu(T)-\epsilon; \alpha","['measure-theory', 'entropy', 'ergodic-theory']"
49,Proving $\mu$ is a measure on $A$ iff for every decreasing sequence in $A$ $\mu(\cap_{n=1}^{\infty} E_n)= \lim_{n\to \infty} \mu(E_n)$,Proving  is a measure on  iff for every decreasing sequence in,\mu A A \mu(\cap_{n=1}^{\infty} E_n)= \lim_{n\to \infty} \mu(E_n),"Let $(X,A)$ a measurable space. $\mu: A\to [0,\infty]$ satisfying: $\mu(X)<\infty$ $\mu(\emptyset)=0$ $\forall{E,F}\in{A}$ disjoint sets, $\mu(E\cup F)=\mu(E)+\mu(F)$ Prove: $\mu$ is a measure on $A$ iff for every deceasing sequence $E_n$ in $A$ $\mu(\cap_{n=1}^{\infty} E_n)= \lim_{n\to \infty} \mu(E_n)$ . First: $\mu (\emptyset)=0$ (given). The forward case is obvious since $\mu$ is a measure by assuming, and $\mu(X) < \infty$ implies that $\mu(E) <\infty$ for all $E\in{A}$ . So using a theorem we finish it. The second condition is to show that for a sequence of disjoint sets $F_n \in{A}$ , $\mu(\cup_{n=1}^{\infty} F_n) =\sum_{n=1}^{\infty} \mu(F_n)$ . Let's define a new decreasing sequence $E_n$ . $E_n=X\setminus (\cup_{i=1}^{n} F_i)=\cap_{i=1}^{n} F_i ^{c}$ . $\mu(X)=\mu(E_n\cup E_n^{c})=(by 2)=\mu(E_n)+\mu(E_n^{c})$ . $\mu(E_n^{c})=\mu(\cup_{i=1}^{n} F_i)=\mu(X)-\mu(\cap_{i=1}^{n} F_i^{c})$ Now let n approaches infinity so: $\mu(\cup_{i=1}^{\infty} F_i)=\mu(X)-lim_{n\to \infty} \mu(\cap_{i=1}^{n} F_i^{c})=\mu(X)-lim_{n\to \infty} \mu(X\setminus \cup_{i=1}^{n} F_i)$ Then can I use that $\mu(lim)=lim(\mu)$ ? (Then I get $\mu(\cup_{i=1}^{\infty} F_i)=\mu(X)-\mu(lim_{n\to \infty} X\setminus {\cap_{i=1}^{n} F_i)}=\mu(X)-\mu(lim_{n\to \infty} \cup_{i=1}^{n}  F_i)$ . So I can reduce $\mu(X)$ with its limit since $\mu(X)$ is finite (by 2), and use 3 after it. Can someone help in this.","Let a measurable space. satisfying: disjoint sets, Prove: is a measure on iff for every deceasing sequence in . First: (given). The forward case is obvious since is a measure by assuming, and implies that for all . So using a theorem we finish it. The second condition is to show that for a sequence of disjoint sets , . Let's define a new decreasing sequence . . . Now let n approaches infinity so: Then can I use that ? (Then I get . So I can reduce with its limit since is finite (by 2), and use 3 after it. Can someone help in this.","(X,A) \mu: A\to [0,\infty] \mu(X)<\infty \mu(\emptyset)=0 \forall{E,F}\in{A} \mu(E\cup F)=\mu(E)+\mu(F) \mu A E_n A \mu(\cap_{n=1}^{\infty} E_n)= \lim_{n\to \infty} \mu(E_n) \mu (\emptyset)=0 \mu \mu(X) < \infty \mu(E) <\infty E\in{A} F_n \in{A} \mu(\cup_{n=1}^{\infty} F_n) =\sum_{n=1}^{\infty} \mu(F_n) E_n E_n=X\setminus (\cup_{i=1}^{n} F_i)=\cap_{i=1}^{n} F_i
^{c} \mu(X)=\mu(E_n\cup E_n^{c})=(by 2)=\mu(E_n)+\mu(E_n^{c}) \mu(E_n^{c})=\mu(\cup_{i=1}^{n} F_i)=\mu(X)-\mu(\cap_{i=1}^{n} F_i^{c}) \mu(\cup_{i=1}^{\infty} F_i)=\mu(X)-lim_{n\to \infty} \mu(\cap_{i=1}^{n} F_i^{c})=\mu(X)-lim_{n\to \infty} \mu(X\setminus \cup_{i=1}^{n} F_i) \mu(lim)=lim(\mu) \mu(\cup_{i=1}^{\infty} F_i)=\mu(X)-\mu(lim_{n\to \infty} X\setminus {\cap_{i=1}^{n} F_i)}=\mu(X)-\mu(lim_{n\to \infty} \cup_{i=1}^{n}  F_i) \mu(X) \mu(X)","['real-analysis', 'functional-analysis', 'measure-theory']"
50,Is Radon-Nikodym derivative with respect to a finite measure real-valued a.e.?,Is Radon-Nikodym derivative with respect to a finite measure real-valued a.e.?,,"This question comes from this question . The answer therein missed an argument that the Radon-Nikodym derivative is real-valued a.e. Without this, the proof in that answer has flaw because either the sum of $f_n$ is not equal to $f$ (a.e.) or the measure corresponds to $+\infty$ is not finite. The following is a complete formulation of my question. On an arbitrary measurable space $(E,\mathcal{E})$ , $\mu\ll\nu$ and $\nu$ is a finite measure. Let $p$ denote the Radon-Nikodym derivative $d\mu/d\nu$ . Show that $p$ is real-valued $\nu$ -almost everywhere. I can find no way to exclude the case that $\nu(\{x\in E|p(x)=+\infty\})=0$ . Can you please help me show that this measure is zero? Thanks a lot.","This question comes from this question . The answer therein missed an argument that the Radon-Nikodym derivative is real-valued a.e. Without this, the proof in that answer has flaw because either the sum of is not equal to (a.e.) or the measure corresponds to is not finite. The following is a complete formulation of my question. On an arbitrary measurable space , and is a finite measure. Let denote the Radon-Nikodym derivative . Show that is real-valued -almost everywhere. I can find no way to exclude the case that . Can you please help me show that this measure is zero? Thanks a lot.","f_n f +\infty (E,\mathcal{E}) \mu\ll\nu \nu p d\mu/d\nu p \nu \nu(\{x\in E|p(x)=+\infty\})=0","['measure-theory', 'almost-everywhere', 'absolute-continuity', 'radon-nikodym']"
51,Baby Rudin Exercise 11.15,Baby Rudin Exercise 11.15,,"I am working through the last chapter of baby Rudin I have a question about exercise 11.15. The question is Let $\mathfrak{R}$ be the ring of all elementary subsets of $(0,1]$ . If $0 < a \leq b \leq 1$ define $$\phi([a,b]) = \phi([a,b)) = \phi((a,b]) = \phi((a,b)) = b-a $$ but define $$\phi((0,b)) = \phi((0,b]) = 1+b $$ Show that this gives an additive set function $\phi$ on $\mathfrak{R}$ , which is $\textbf{not regular}$ and which cannot be extended to a countably additive set function on a $\sigma$ -ring. I have been looking at solutions, such as here , but I am having issues with the way it is proved that $\phi$ is not regular and I cannot think of an alternative proof. They say that $\phi$ is not regular because if we take a set like $(0, 0.5]$ then this cannot be approximated from below by a closed set because a closed set cant contain $0$ as the end point. But, isn't $(0, 0.5]$ closed in $(0,1]$ ? So it seems that this argument doesn't work. But, I also cannot think of an alternative argument to show that $\phi$ isn't regular.","I am working through the last chapter of baby Rudin I have a question about exercise 11.15. The question is Let be the ring of all elementary subsets of . If define but define Show that this gives an additive set function on , which is and which cannot be extended to a countably additive set function on a -ring. I have been looking at solutions, such as here , but I am having issues with the way it is proved that is not regular and I cannot think of an alternative proof. They say that is not regular because if we take a set like then this cannot be approximated from below by a closed set because a closed set cant contain as the end point. But, isn't closed in ? So it seems that this argument doesn't work. But, I also cannot think of an alternative argument to show that isn't regular.","\mathfrak{R} (0,1] 0 < a \leq b \leq 1 \phi([a,b]) = \phi([a,b)) = \phi((a,b]) = \phi((a,b)) = b-a  \phi((0,b)) = \phi((0,b]) = 1+b  \phi \mathfrak{R} \textbf{not regular} \sigma \phi \phi (0, 0.5] 0 (0, 0.5] (0,1] \phi","['real-analysis', 'measure-theory']"
52,Why Luzin's theorem can not be changed from $|\mathbb{R} \backslash B| < \epsilon$ to $|\mathbb{R} \backslash B| = 0$,Why Luzin's theorem can not be changed from  to,|\mathbb{R} \backslash B| < \epsilon |\mathbb{R} \backslash B| = 0,"I am looking to prove the following however I am struggling. Any help would be appreciated. Thanks in advance. We let $G$ be an open set so that $\mathbb{Q} \subseteq G$ and $|G| < 1$ , and let $f : \mathbb{R} \rightarrow \mathbb{R}$ be given by $f = \chi_G$ . I am wanting to show that there is no Borel set $B$ with $|\mathbb{R} \backslash B| = 0$ so that $f|B$ is continuous.","I am looking to prove the following however I am struggling. Any help would be appreciated. Thanks in advance. We let be an open set so that and , and let be given by . I am wanting to show that there is no Borel set with so that is continuous.",G \mathbb{Q} \subseteq G |G| < 1 f : \mathbb{R} \rightarrow \mathbb{R} f = \chi_G B |\mathbb{R} \backslash B| = 0 f|B,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'outer-measure']"
53,When is the continuous image of a measurable subset of a Polish space measurable?,When is the continuous image of a measurable subset of a Polish space measurable?,,"In page two of three of this note: http://math.iisc.ac.in/~manju/MartBM/RaoSrivastava_borelisomorphism.pdf It is said in the proof of Proposition 2, and in the section (ii) that ' $f$ is clearly bi-measurable.' It is clear to me that $f$ is continuous and injective, and that $Z$ is closed. But why is it clear that for any measurable subset of $Z$ , say $M$ , that $f(M)$ is a measurable subset of $X$ ? I can see that it is enough to show that for any open subset of $\prod_{n \geq 1} Z_n$ , $O$ , that $f(O \cap Z)$ is measurable, in an attempt to try to do so I noted that since $Z$ is closed, it is $G_{\sigma}$ (and Polish), so $O \cap Z$ is $G_{\sigma}$ , and $f(O \cap Z) = (f_0 \circ \pi_0)(O \cap Z)$ , and so it is enough to show (using that $f_0$ is bi-measurable) that $\pi_0(O \cap Z)$ is itself measurable, or in particular that the image of a $G_{\sigma}$ subset of $\prod_{n \geq 1} Z_n$ by $\pi_0$ is measurable. But I have been unable to show this.","In page two of three of this note: http://math.iisc.ac.in/~manju/MartBM/RaoSrivastava_borelisomorphism.pdf It is said in the proof of Proposition 2, and in the section (ii) that ' is clearly bi-measurable.' It is clear to me that is continuous and injective, and that is closed. But why is it clear that for any measurable subset of , say , that is a measurable subset of ? I can see that it is enough to show that for any open subset of , , that is measurable, in an attempt to try to do so I noted that since is closed, it is (and Polish), so is , and , and so it is enough to show (using that is bi-measurable) that is itself measurable, or in particular that the image of a subset of by is measurable. But I have been unable to show this.",f f Z Z M f(M) X \prod_{n \geq 1} Z_n O f(O \cap Z) Z G_{\sigma} O \cap Z G_{\sigma} f(O \cap Z) = (f_0 \circ \pi_0)(O \cap Z) f_0 \pi_0(O \cap Z) G_{\sigma} \prod_{n \geq 1} Z_n \pi_0,"['real-analysis', 'general-topology', 'measure-theory', 'descriptive-set-theory', 'polish-spaces']"
54,"If $\sigma(\mathcal B)=\sigma(\mathcal T)$ for every basis $\mathcal B$ of topological space $(X,\mathcal T)$, must $T$ be hereditarily Lindelöf?","If  for every basis  of topological space , must  be hereditarily Lindelöf?","\sigma(\mathcal B)=\sigma(\mathcal T) \mathcal B (X,\mathcal T) T","In the comments of this answer, someone claims: If topological space $(X,\mathcal T)$ is hereditarily Lindelöf, then $\sigma(\mathcal B)=\sigma(\mathcal T)$ for every basis $\mathcal B$ . Can this theorem be strengthened to read ""if and only if""? To clarify after some discussion in the comments, I'm introducing this terminology: A basis $\mathcal B$ for topology $\mathcal T$ has the ""Borel property"" if $\sigma(\mathcal B)=\sigma(\mathcal T)$ . A topology $\mathcal T$ has the ""strong Borel property"" if every basis for the topology has the Borel property. The conjecture then becomes: ""A topological space $(X,\mathcal T)$ is hereditarily Lindelöf if and only if $\mathcal T$ has the strong Borel property.""","In the comments of this answer, someone claims: If topological space is hereditarily Lindelöf, then for every basis . Can this theorem be strengthened to read ""if and only if""? To clarify after some discussion in the comments, I'm introducing this terminology: A basis for topology has the ""Borel property"" if . A topology has the ""strong Borel property"" if every basis for the topology has the Borel property. The conjecture then becomes: ""A topological space is hereditarily Lindelöf if and only if has the strong Borel property.""","(X,\mathcal T) \sigma(\mathcal B)=\sigma(\mathcal T) \mathcal B \mathcal B \mathcal T \sigma(\mathcal B)=\sigma(\mathcal T) \mathcal T (X,\mathcal T) \mathcal T","['general-topology', 'measure-theory', 'borel-sets']"
55,Regarding a potential generalisation of Krylov-Bogolubov theorem,Regarding a potential generalisation of Krylov-Bogolubov theorem,,"Let $(\mathbb{X},d)$ be a Compact Metric Space and $T:(\mathbb{X},d) \longrightarrow (\mathbb{X},d)$ be a Continuous Mapping . Let $B(\mathbb{X})$ be $\sigma$ - Algebra of all Borel subsets of $\mathbb{X}$ . It is well-known in Ergodic Theory that Krylov-Bogolubov theorem guarantees the existence of $T-$ invariant borel probability measure $\mu$ defined on $B(\mathbb{X})$ ( $T-$ invariant means $\mu(B) = \mu(T^{-1}(B))$ for every $B\in B(\mathbb{X})$ ). Via Riesz Representation Theorem we identify the set $M(\mathbb{X})$ (the set of all borel probability measures defined on $B(\mathbb{X})$ ) with a subset of the set of all positive normalised continuous linear functionals on $C(\mathbb{X})$ (the space of all real continuous functions defined on $\mathbb{X}$ ). Since Riesz Representation Theorem has been generalised for a Locally Compact Hausdorff topological space (that is called Riesz-Markov-Kakutani theorem). I would like to enquire whether it is possible to generalise Krylov-Bogolubov theorem for a Locally Compact Hausdorff topological space. To understand the whole image, you can consult An Introduction To Ergodic Theory , Peter Walters , 1982. Chapter 6 .","Let be a Compact Metric Space and be a Continuous Mapping . Let be - Algebra of all Borel subsets of . It is well-known in Ergodic Theory that Krylov-Bogolubov theorem guarantees the existence of invariant borel probability measure defined on ( invariant means for every ). Via Riesz Representation Theorem we identify the set (the set of all borel probability measures defined on ) with a subset of the set of all positive normalised continuous linear functionals on (the space of all real continuous functions defined on ). Since Riesz Representation Theorem has been generalised for a Locally Compact Hausdorff topological space (that is called Riesz-Markov-Kakutani theorem). I would like to enquire whether it is possible to generalise Krylov-Bogolubov theorem for a Locally Compact Hausdorff topological space. To understand the whole image, you can consult An Introduction To Ergodic Theory , Peter Walters , 1982. Chapter 6 .","(\mathbb{X},d) T:(\mathbb{X},d) \longrightarrow (\mathbb{X},d) B(\mathbb{X}) \sigma \mathbb{X} T- \mu B(\mathbb{X}) T- \mu(B) = \mu(T^{-1}(B)) B\in B(\mathbb{X}) M(\mathbb{X}) B(\mathbb{X}) C(\mathbb{X}) \mathbb{X}","['general-topology', 'functional-analysis', 'measure-theory', 'ergodic-theory']"
56,Is it possible to approximate any Borel measure with Dirac's Deltas?,Is it possible to approximate any Borel measure with Dirac's Deltas?,,"Given a complete separable metric space $(X,d)$ . My question is if it is true that for any finite positive Borel measure $\mu\in\mathcal{M}^+_b(X)$ there exists a sequence of finite atomic measures $a_n\in\mathcal M^+_b(X)$ such that $$ a_n\rightharpoonup \mu, $$ i.e. $a_n$ converges narrowly to $\mu$ . The most obvious guess is that given $x_n$ a dense sequence in $X$ and $U^i_n$ are disjoint open sets such that $$ \bigcup_i U^i_n=B(x_0,n) $$ we define $$ a_n=\sum_{i=1}^{g(n)}\delta_{x_i}\mu(U^i_n), $$ where $g$ should have the property $$ \lim_n \frac{g(n)}{\mu(B(x_0,n))}=C. $$ Then we should have that for any continuous bounded function we have $$ \int_X f\ da_n=\sum_{i=1}^{g(n)} f(x_i)\mu(U^i_n)\rightarrow\int_Xf\ d\mu. $$ It should happens because $$ \sum_{i=1}^{g(n)} \min_{U_n^i}(f)\chi_{U^i_n}\leq f\leq\sum_{i=1}^{g(n)} \max_{U_n^i}(f)\chi_{U^i_n} $$ but there is no reason to infer that the choice of $U_n^i$ is good enough to refine the step functions from above and below well enough to obtain the integrals. Because we would need the choice to be independent of the function $f$ . What am I missing? Is it possible to begin with? Where can I find this result in the literature?",Given a complete separable metric space . My question is if it is true that for any finite positive Borel measure there exists a sequence of finite atomic measures such that i.e. converges narrowly to . The most obvious guess is that given a dense sequence in and are disjoint open sets such that we define where should have the property Then we should have that for any continuous bounded function we have It should happens because but there is no reason to infer that the choice of is good enough to refine the step functions from above and below well enough to obtain the integrals. Because we would need the choice to be independent of the function . What am I missing? Is it possible to begin with? Where can I find this result in the literature?,"(X,d) \mu\in\mathcal{M}^+_b(X) a_n\in\mathcal M^+_b(X) 
a_n\rightharpoonup \mu,
 a_n \mu x_n X U^i_n 
\bigcup_i U^i_n=B(x_0,n)
 
a_n=\sum_{i=1}^{g(n)}\delta_{x_i}\mu(U^i_n),
 g 
\lim_n \frac{g(n)}{\mu(B(x_0,n))}=C.
 
\int_X f\ da_n=\sum_{i=1}^{g(n)} f(x_i)\mu(U^i_n)\rightarrow\int_Xf\ d\mu.
 
\sum_{i=1}^{g(n)} \min_{U_n^i}(f)\chi_{U^i_n}\leq f\leq\sum_{i=1}^{g(n)} \max_{U_n^i}(f)\chi_{U^i_n}
 U_n^i f","['real-analysis', 'integration', 'measure-theory', 'borel-measures']"
57,"Let $(X, S, \mu)$ a measure space, $f$ non negative function.","Let  a measure space,  non negative function.","(X, S, \mu) f","Let $(X, S, \mu)$ a finite measure space, $f$ non negative function. Show: $$\int f \,d\mu < +\infty$$ if only if $$\sum_{n=0}^\infty 2^{n}\mu(\{x\in X \mid f(x) \geq 2^n \}) < + \infty.$$ $(\implies)$ if $\int f \, d\mu = M < +\infty$ , $2^n$ is non-negative, by Chebyshev inequality: $$\mu(\{x\in X \mid f(x) \geq 2^n \} \leq \frac{M}{2^n}, \text{ where } \frac{M}{2^n} \rightarrow 0 \text{ when } n \rightarrow \infty.$$ $$\sum_{n=0}^\infty 2^n\mu(\{x\in X \mid f(x) \geq 2^n \}) \leq \sum_{n=0}^\infty 2^n \frac{M}{2^n} \rightarrow 0. $$ Then $$\sum_{n=0}^\infty 2^n\mu(\{x\in X \mid f(x) \geq 2^n \}) < +\infty.$$ ( $\Leftarrow$ ) If $$\sum_{n=0}^\infty 2^n \mu(\{x\in X \mid f(x) \geq 2^n \}) < + \infty.$$ Is the first implication correct? I am trying the other implication also.","Let a finite measure space, non negative function. Show: if only if if , is non-negative, by Chebyshev inequality: Then ( ) If Is the first implication correct? I am trying the other implication also.","(X, S, \mu) f \int f \,d\mu < +\infty \sum_{n=0}^\infty 2^{n}\mu(\{x\in X \mid f(x) \geq 2^n \}) < + \infty. (\implies) \int f \, d\mu = M < +\infty 2^n \mu(\{x\in X \mid f(x) \geq 2^n \} \leq \frac{M}{2^n}, \text{ where } \frac{M}{2^n} \rightarrow 0 \text{ when } n \rightarrow \infty. \sum_{n=0}^\infty 2^n\mu(\{x\in X \mid f(x) \geq 2^n \}) \leq \sum_{n=0}^\infty 2^n \frac{M}{2^n} \rightarrow 0.  \sum_{n=0}^\infty 2^n\mu(\{x\in X \mid f(x) \geq 2^n \}) < +\infty. \Leftarrow \sum_{n=0}^\infty 2^n \mu(\{x\in X \mid f(x) \geq 2^n \}) < + \infty.","['measure-theory', 'lebesgue-measure', 'measurable-functions']"
58,Is there a standard way of equipping a sigma-algebra with a sigma-algebra?,Is there a standard way of equipping a sigma-algebra with a sigma-algebra?,,"Suppose $(X, \mathcal X)$ is a measurable space. I'd like to say something about measurable functions taking values in $\mathcal X$ , but in order to do that, I need $\mathcal X$ to be equipped with a sigma-algebra. Is there a canonical way of equipping $\mathcal X$ with a sigma-algebra $\mathcal F_\mathcal X$ so that we can talk about measurable functions from $(X, \mathcal X)$ to $(\mathcal X, \mathcal F_\mathcal X)$ ? Some ideas that occurred to me: (1) $\mathcal F_\mathcal X = \{A \subset \mathcal X: \bigcup A \in \mathcal X\}$ . But I don't see that this is closed under complements. (2) $\mathcal F_\mathcal X = \{A \subset \mathcal X: \bigcup A \in \mathcal X \ \text{or} \ \bigcap A \in \mathcal X\}$ . But I don't see that this is closed under countable unions.","Suppose is a measurable space. I'd like to say something about measurable functions taking values in , but in order to do that, I need to be equipped with a sigma-algebra. Is there a canonical way of equipping with a sigma-algebra so that we can talk about measurable functions from to ? Some ideas that occurred to me: (1) . But I don't see that this is closed under complements. (2) . But I don't see that this is closed under countable unions.","(X, \mathcal X) \mathcal X \mathcal X \mathcal X \mathcal F_\mathcal X (X, \mathcal X) (\mathcal X, \mathcal F_\mathcal X) \mathcal F_\mathcal X = \{A \subset \mathcal X: \bigcup A \in \mathcal X\} \mathcal F_\mathcal X = \{A \subset \mathcal X: \bigcup A \in \mathcal X \ \text{or} \ \bigcap A \in \mathcal X\}","['measure-theory', 'reference-request']"
59,"Prove that $F(x)=\int_{x_{1}^{0}}^{x_1}\cdots \int_{x_{n}^{0}}^{x_n} f(y) \, dy_1 \cdots dy_n$ is continuous",Prove that  is continuous,"F(x)=\int_{x_{1}^{0}}^{x_1}\cdots \int_{x_{n}^{0}}^{x_n} f(y) \, dy_1 \cdots dy_n","Let $\Omega$ be a open subset of $\mathbb{R}^{n}$ , $f \in L_{\operatorname{loc}}^{1}(\Omega)$ and $x^0=(x_{1}^{0},\dots,x_{n}^{0})$ an arbitrary point of $\Omega$ . Define $$F(x)=\int_{x_{1}^{0}}^{x_1}\cdots \int_{x_{n}^{0}}^{x_n} f(y) \, dy_1 \cdots dy_n.$$ My question: How to prove that $F$ is a continuous function in a sufficiently small neighborhood of $x^0$ ? I started trying to prove this statement in the case $\Omega=\mathbb{R}$ . So, let $x_0 \in \mathbb{R}$ and $(x_n) \subset \mathbb{R}$ such that $x_n \rightarrow  x_0$ in $\mathbb{R}$ . Let $M>0$ such that $-M<x_n<M$ and $-M<x_1^0<M$ for all $n \in \mathbb{N}$ . Then, for $x^0=x_{0}^{1}$ $$F(x_n)=\int_{x_1^0}^{x_n}f(y)dy=\int_{\mathbb{R}} 1_{(x_1^0,x_n)}(y)f(y)\,dy. \tag{*}$$ Then, define $g_n(y)=1_{(x_1^0,x_n)}(y)f(y)$ . We have that $|g_n(y)|\leq 1_{(-M,M)}|f(y)|=g(y)$ and $g \in L^1(\mathbb{R})$ . If we prove that $$1_{(x_1^0,x_n)} \rightarrow 1_{(x_1^0,x_0)} \hbox{ a.e. in } \mathbb{R},$$ the result follows from the Dominated Convergence Theorem. (This is also a point that I have not been able to prove.) It's just weird to write (*) this because it can happen $x_{n_0-1}<x_1^0$ and $x_{n_0}>x_1^0$ for some $n_0 \in \mathbb{N}$ . PS: This question comes from Corollary 1, page 263 in Trèves book Topological Vector Spaces, Distributions and Kernels.","Let be a open subset of , and an arbitrary point of . Define My question: How to prove that is a continuous function in a sufficiently small neighborhood of ? I started trying to prove this statement in the case . So, let and such that in . Let such that and for all . Then, for Then, define . We have that and . If we prove that the result follows from the Dominated Convergence Theorem. (This is also a point that I have not been able to prove.) It's just weird to write (*) this because it can happen and for some . PS: This question comes from Corollary 1, page 263 in Trèves book Topological Vector Spaces, Distributions and Kernels.","\Omega \mathbb{R}^{n} f \in L_{\operatorname{loc}}^{1}(\Omega) x^0=(x_{1}^{0},\dots,x_{n}^{0}) \Omega F(x)=\int_{x_{1}^{0}}^{x_1}\cdots \int_{x_{n}^{0}}^{x_n} f(y) \, dy_1 \cdots dy_n. F x^0 \Omega=\mathbb{R} x_0 \in \mathbb{R} (x_n) \subset \mathbb{R} x_n \rightarrow  x_0 \mathbb{R} M>0 -M<x_n<M -M<x_1^0<M n \in \mathbb{N} x^0=x_{0}^{1} F(x_n)=\int_{x_1^0}^{x_n}f(y)dy=\int_{\mathbb{R}} 1_{(x_1^0,x_n)}(y)f(y)\,dy. \tag{*} g_n(y)=1_{(x_1^0,x_n)}(y)f(y) |g_n(y)|\leq 1_{(-M,M)}|f(y)|=g(y) g \in L^1(\mathbb{R}) 1_{(x_1^0,x_n)} \rightarrow 1_{(x_1^0,x_0)} \hbox{ a.e. in } \mathbb{R}, x_{n_0-1}<x_1^0 x_{n_0}>x_1^0 n_0 \in \mathbb{N}","['real-analysis', 'functional-analysis', 'measure-theory', 'continuity', 'lebesgue-integral']"
60,Understanding the Topology in a Proof about Ergodic/Recurrent Transformations,Understanding the Topology in a Proof about Ergodic/Recurrent Transformations,,"A portion of Lemma 3.7.2 of Silva's ""Invitation to Ergodic Theory"" states the following: Lemma. Let $(X, \mathcal{S}, \mu)$ be a $\sigma$ -finite measure space and let $T: X \to X$ be a measure-preserving transformation. Then, the following two statements are equivalent If $A$ and $B$ are sets of positive measure, then there exists an integer $n > 0$ such that $$T^{-n}(A) \cap B \neq \emptyset.$$ If $A$ and $B$ are sets of positive measure, then there exists an integer $n > 0$ such that $$\mu(T^{-n}(A) \cap B) > 0.$$ Clearly, only (1) $\implies$ (2) needs to be shown, and the proof is short: Let $A, B$ be sets of positive measure. For the sake of contradiction, suppose $\mu(T^{-n}(A) \cap B) =0 $ for all $n$ . Let $A_0 = A \backslash \bigcup_{n = 1}^\infty T^{-n}(A) \cap B$ . Then $\mu(A_0) > 0$ but $T^{-n}(A_0) \cap B = \emptyset$ , a contradiction. I'm having trouble seeing the argument for $$A_0 := A \backslash \bigcup_{n = 1}^\infty T^{-n}(A) \cap B \implies T^{-n}(A_0) \cap B = \emptyset.$$ What exactly is the reasoning for this claim? Any hints, discussion, and solutions are appreciated.","A portion of Lemma 3.7.2 of Silva's ""Invitation to Ergodic Theory"" states the following: Lemma. Let be a -finite measure space and let be a measure-preserving transformation. Then, the following two statements are equivalent If and are sets of positive measure, then there exists an integer such that If and are sets of positive measure, then there exists an integer such that Clearly, only (1) (2) needs to be shown, and the proof is short: Let be sets of positive measure. For the sake of contradiction, suppose for all . Let . Then but , a contradiction. I'm having trouble seeing the argument for What exactly is the reasoning for this claim? Any hints, discussion, and solutions are appreciated.","(X, \mathcal{S}, \mu) \sigma T: X \to X A B n > 0 T^{-n}(A) \cap B \neq \emptyset. A B n > 0 \mu(T^{-n}(A) \cap B) > 0. \implies A, B \mu(T^{-n}(A) \cap B) =0  n A_0 = A \backslash \bigcup_{n = 1}^\infty T^{-n}(A) \cap B \mu(A_0) > 0 T^{-n}(A_0) \cap B = \emptyset A_0 := A \backslash \bigcup_{n = 1}^\infty T^{-n}(A) \cap B \implies T^{-n}(A_0) \cap B = \emptyset.","['general-topology', 'measure-theory', 'ergodic-theory']"
61,regular Borel probability measure implying countable basis,regular Borel probability measure implying countable basis,,"Peter Walters' An Introduction to Ergodic Theory (page 10) says If $X$ is a metric space and ( $\mathscr{B}$ is the $\sigma$ -algebra of Borel subsets of $X$ ... and $m$ is any probability measure on $(X, \mathscr{B})$ then $(X, \mathscr{B},m)$ has a countable basis. (This follows from Theorem 6.1.) Therefore most of the spaces we shall deal with have $L^2(X, \mathscr{B}, m)$ separable. I do not see why $(X, \mathscr{B},m)$ has a countable basis. Here, $(X, \mathscr{B},m)$ is said to have a countable basis if there exists a sequence of elements $\{E_n\}_n^\infty\subset \mathscr{B}$ such that for every $\epsilon>0$ and every $B\in\mathscr{B}$ with $m(B)<\infty$ there is some $n$ with $$ m(B\triangle E_n)=m(B\setminus E_n)+m(E_n\setminus B)<\epsilon. $$ Theorem 6.1: (Theorem 6.1) A Borel probability measure $m$ on a metric space $X$ is regular (i.e., $\forall B\in\mathscr{B}(X)$ and $\forall \epsilon>0$ $\exists$ an open set $U_\epsilon$ , and a closed set $C_\epsilon$ , with $C_\epsilon\subset B\subset U_\epsilon$ and $m(U_\epsilon\setminus C_\epsilon) < \epsilon$ ). (Thoughts) For any $\epsilon>0$ and for any $B\in\mathscr{B}(X)$ , we can take $U_\epsilon$ , $C_\epsilon$ as above such that $$ m(B\setminus C_\epsilon)\leq m(U_\epsilon\setminus C_\epsilon) < \epsilon $$ and $$ m(C_\epsilon\setminus B)=m(\emptyset)=0 $$ but I do not see how only countably many $C_\epsilon$ would suffice. What is still confusing is that on page 45 Walters say If $X$ is a metric space with a countable topological base and $\mathscr{B}$ is the $\sigma$ -algebra of Borel subsets of $X$ then $(X, \mathscr{B},m)$ has a countable basis for any probability measure $m$ on $(X,\mathscr{B})$ . This follows from Theorem 6.1. Now we have an extra condition on $X$ ...","Peter Walters' An Introduction to Ergodic Theory (page 10) says If is a metric space and ( is the -algebra of Borel subsets of ... and is any probability measure on then has a countable basis. (This follows from Theorem 6.1.) Therefore most of the spaces we shall deal with have separable. I do not see why has a countable basis. Here, is said to have a countable basis if there exists a sequence of elements such that for every and every with there is some with Theorem 6.1: (Theorem 6.1) A Borel probability measure on a metric space is regular (i.e., and an open set , and a closed set , with and ). (Thoughts) For any and for any , we can take , as above such that and but I do not see how only countably many would suffice. What is still confusing is that on page 45 Walters say If is a metric space with a countable topological base and is the -algebra of Borel subsets of then has a countable basis for any probability measure on . This follows from Theorem 6.1. Now we have an extra condition on ...","X \mathscr{B} \sigma X m (X, \mathscr{B}) (X, \mathscr{B},m) L^2(X, \mathscr{B}, m) (X, \mathscr{B},m) (X, \mathscr{B},m) \{E_n\}_n^\infty\subset \mathscr{B} \epsilon>0 B\in\mathscr{B} m(B)<\infty n 
m(B\triangle E_n)=m(B\setminus E_n)+m(E_n\setminus B)<\epsilon.
 m X \forall B\in\mathscr{B}(X) \forall \epsilon>0 \exists U_\epsilon C_\epsilon C_\epsilon\subset B\subset U_\epsilon m(U_\epsilon\setminus C_\epsilon) < \epsilon \epsilon>0 B\in\mathscr{B}(X) U_\epsilon C_\epsilon 
m(B\setminus C_\epsilon)\leq m(U_\epsilon\setminus C_\epsilon) < \epsilon
 
m(C_\epsilon\setminus B)=m(\emptyset)=0
 C_\epsilon X \mathscr{B} \sigma X (X, \mathscr{B},m) m (X,\mathscr{B}) X","['general-topology', 'measure-theory', 'metric-spaces']"
62,Prove that $\mathcal A$ is a $\sigma$-algebra of subsets of $\Bbb R^2.$,Prove that  is a -algebra of subsets of,\mathcal A \sigma \Bbb R^2.,"Let $\textbf {x} = (x,y) \in \Bbb R^2.$ For any subset $E \subseteq \Bbb R^2$ define $\textbf {x} E$ as follows $:$ $$\textbf {x} E : = \left \{(ax,by)\ |\ (a,b) \in E \right \}.$$ Prove that $\mathcal A = \left \{E \in \mathcal L_{\Bbb R^2}\ |\ \textbf {x} E \in \mathcal L_{\Bbb R^2} \right \}$ is a $\sigma$ -algebra of subsets of $\Bbb R^2.$ It is easy to see that $\varnothing, \Bbb R^2 \in \mathcal A.$ Also $\mathcal A$ is closed under countable unions. For that let us take a sequence $\{E_n \}_{n = 1}^{\infty}$ of elements in $\mathcal A.$ Need to show that $E = \bigcup\limits_{n=1}^{\infty} E_n \in \mathcal A.$ For that we need only to show that $\textbf {x} E \in \mathcal L_{\Bbb R^2}.$ Claim $:$ $\textbf {x} E = \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n.$ Let $y \in \textbf {x} E.$ Then $\exists$ $(a,b) \in E$ such that $y = (ax,by).$ Since $(a,b) \in E,$ $\exists$ $i \in \Bbb N$ such that $(a,b) \in E_i.$ But then $y = (ax,by) \in \textbf {x} E_i.$ Hence $y \in \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n.$ This shows that $\textbf {x} E \subseteq \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n.\ \ \ \ \ \ \ \ (1)$ To prove the reverse inclusion let us take any $z \in \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n.$ Then $\exists$ $j \in \Bbb N$ such that $z \in \textbf {x} E_j.$ So $\exists$ $(p,q) \in E_j$ such that $z = \textbf {x} (p,q) = (px,qy).$ But since $E_j \subseteq \bigcup\limits_{n=1}^{\infty} E_n = E,$ it follows that $(p,q) \in E.$ This shows that $z=(px,qy) = \textbf {x} (p,q) \in \textbf {x} E.$ Hence $\bigcup\limits_{n=1}^{\infty} \textbf {x} E_n \subseteq \textbf {x} E.\ \ \ \ \ \  \ \ (2)$ From $(1)$ anf $(2)$ it follows that $\textbf {x} E = \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n.$ This proves the claim. Now since $E_n \in \mathcal A,$ for all $n \geq 1,$ it follows that $\textbf {x} E_n \in \mathcal L_{\Bbb R^2},$ for all $n \geq 1.$ Since $\mathcal L_{\Bbb R^2}$ is a $\sigma$ -algebra of subsets of $\Bbb R^2,$ we have $\textbf {x} E = \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n \in \mathcal L_{\Bbb R^2}.$ This shows that $E = \bigcup\limits_{n=1}^{\infty} E_n \in \mathcal A.$ Hence $\mathcal A$ is closed under countable unions. The last thing what we have to show is that $\mathcal A$ is closed under complimentation. For that let $E \in \mathcal A.$ Then $\textbf {x} E \in \mathcal L_{\Bbb R^2}.$ Now I'm trying to prove that $\left (\textbf {x} E \right )^c = \textbf {x} E^c.$ But I don't think it's true. For instance let $E = [0,1] \times [0,1]$ and $\textbf {x} = (1,0).$ Then $\textbf {x} E = \{(t,0)\ |\ t \in [0,1] \}.$ Now $\left (\frac  1 2,2 \right ) \in E^c.$ Therefore $\textbf {x} \left (\frac  1 2,2 \right ) = \left (\frac 1 2,0 \right ) \in \textbf {x} E^c.$ Therefore $\textbf {x} E^c \cap \textbf {x} E \neq \varnothing.$ Hence $\textbf {x} E^c \subsetneq \left (\textbf {x} E \right )^c.$ The equality can only occur if the both the components of $\textbf {x}$ are non-zero. So how do I prove that $\mathcal A$ is closed under complimentation in case both the components of $\textbf {x}$ are not simultaneously non-zero? Any help in this regard will be highly appreciated. Thanks in advance. Source $:$ https://youtu.be/CjewMbxZzEQ",Let For any subset define as follows Prove that is a -algebra of subsets of It is easy to see that Also is closed under countable unions. For that let us take a sequence of elements in Need to show that For that we need only to show that Claim Let Then such that Since such that But then Hence This shows that To prove the reverse inclusion let us take any Then such that So such that But since it follows that This shows that Hence From anf it follows that This proves the claim. Now since for all it follows that for all Since is a -algebra of subsets of we have This shows that Hence is closed under countable unions. The last thing what we have to show is that is closed under complimentation. For that let Then Now I'm trying to prove that But I don't think it's true. For instance let and Then Now Therefore Therefore Hence The equality can only occur if the both the components of are non-zero. So how do I prove that is closed under complimentation in case both the components of are not simultaneously non-zero? Any help in this regard will be highly appreciated. Thanks in advance. Source https://youtu.be/CjewMbxZzEQ,"\textbf {x} = (x,y) \in \Bbb R^2. E \subseteq \Bbb R^2 \textbf {x} E : \textbf {x} E : = \left \{(ax,by)\ |\ (a,b) \in E \right \}. \mathcal A = \left \{E \in \mathcal L_{\Bbb R^2}\ |\ \textbf {x} E \in \mathcal L_{\Bbb R^2} \right \} \sigma \Bbb R^2. \varnothing, \Bbb R^2 \in \mathcal A. \mathcal A \{E_n \}_{n = 1}^{\infty} \mathcal A. E = \bigcup\limits_{n=1}^{\infty} E_n \in \mathcal A. \textbf {x} E \in \mathcal L_{\Bbb R^2}. : \textbf {x} E = \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n. y \in \textbf {x} E. \exists (a,b) \in E y = (ax,by). (a,b) \in E, \exists i \in \Bbb N (a,b) \in E_i. y = (ax,by) \in \textbf {x} E_i. y \in \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n. \textbf {x} E \subseteq \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n.\ \ \ \ \ \ \ \ (1) z \in \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n. \exists j \in \Bbb N z \in \textbf {x} E_j. \exists (p,q) \in E_j z = \textbf {x} (p,q) = (px,qy). E_j \subseteq \bigcup\limits_{n=1}^{\infty} E_n = E, (p,q) \in E. z=(px,qy) = \textbf {x} (p,q) \in \textbf {x} E. \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n \subseteq \textbf {x} E.\ \ \ \ \ \  \ \ (2) (1) (2) \textbf {x} E = \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n. E_n \in \mathcal A, n \geq 1, \textbf {x} E_n \in \mathcal L_{\Bbb R^2}, n \geq 1. \mathcal L_{\Bbb R^2} \sigma \Bbb R^2, \textbf {x} E = \bigcup\limits_{n=1}^{\infty} \textbf {x} E_n \in \mathcal L_{\Bbb R^2}. E = \bigcup\limits_{n=1}^{\infty} E_n \in \mathcal A. \mathcal A \mathcal A E \in \mathcal A. \textbf {x} E \in \mathcal L_{\Bbb R^2}. \left (\textbf {x} E \right )^c = \textbf {x} E^c. E = [0,1] \times [0,1] \textbf {x} = (1,0). \textbf {x} E = \{(t,0)\ |\ t \in [0,1] \}. \left (\frac  1 2,2 \right ) \in E^c. \textbf {x} \left (\frac  1 2,2 \right ) = \left (\frac 1 2,0 \right ) \in \textbf {x} E^c. \textbf {x} E^c \cap \textbf {x} E \neq \varnothing. \textbf {x} E^c \subsetneq \left (\textbf {x} E \right )^c. \textbf {x} \mathcal A \textbf {x} :","['measure-theory', 'proof-writing']"
63,Separability of a $\sigma$-algebra generated by an algebra,Separability of a -algebra generated by an algebra,\sigma,"Let $X:(Ω,\mathcal{F})$ be a measurable set and $\mathcal{F}=\sigma(C)$ where $C$ is an algebra . Now We define $B_\mathcal{w}=\underset{\mathcal{w}∈A,A∈C}{\cap}A$ , which suggests the intersection of all sets in $C$ that contain $\mathcal{w}$ . Similarly, we define $\mathcal{F}_\mathcal{w}=\underset{\mathcal{w}∈A,A∈\mathcal{F}}{\cap}A$ ,which suggests the intersection of all sets in $\mathcal{F}$ that contain $\mathcal{w}$ . If there exists another element $x$ which does not equal to $\mathcal{w} $ and $x$ belongs to $B_\mathcal{w}$ . Now I think its trivial that $x$ belongs to $\mathcal{F}_\mathcal{w}$ but I couldn't give a precise proof. Moreover, could we replace the condition "" $C$ is an algebra"" by "" $C$ is an arbitrary set class which generates $\mathcal{F}$ "" and get the same conclusion?","Let be a measurable set and where is an algebra . Now We define , which suggests the intersection of all sets in that contain . Similarly, we define ,which suggests the intersection of all sets in that contain . If there exists another element which does not equal to and belongs to . Now I think its trivial that belongs to but I couldn't give a precise proof. Moreover, could we replace the condition "" is an algebra"" by "" is an arbitrary set class which generates "" and get the same conclusion?","X:(Ω,\mathcal{F}) \mathcal{F}=\sigma(C) C B_\mathcal{w}=\underset{\mathcal{w}∈A,A∈C}{\cap}A C \mathcal{w} \mathcal{F}_\mathcal{w}=\underset{\mathcal{w}∈A,A∈\mathcal{F}}{\cap}A \mathcal{F} \mathcal{w} x \mathcal{w}  x B_\mathcal{w} x \mathcal{F}_\mathcal{w} C C \mathcal{F}","['real-analysis', 'measure-theory']"
64,Cardinality of set of $a_r$?,Cardinality of set of ?,a_r,"Question So I conjectured a formula which was proven : Let $b_r = \sum_{d \mid r} a_d\mu(\frac{m}{d})$ . We prove that if the $b_r$ 's are small enough, the result is true. Claim: If $\lim_{n \to \infty} \frac{\log^2(n)}{n}\sum_{r=1}^n |b_r| = 0$ and $f$ is smooth, then $$\lim_{k \to \infty} \lim_{n \to \infty} \sum_{r=1}^n a_rf\left(\frac{kr}{n}\right)\frac{k}{n} = \left(\lim_{s \to 1} \frac{1}{\zeta(s)}\sum_{r=1}^\infty \frac{a_r}{r^s}\right)\int_0^\infty f(x)dx.$$ My question is what is the cardinality of the set of $a_r$ ? Reason for confusion Focusing on the L.H.S This seems to say for every point on the curve can be mapped to $f(x)$ which in turn can be mapped to a coefficient $a_r$ . $$ x \to f(x) \to a_r $$ Hence, the set has cardinality $ 2^{\aleph_0} $ Focusing on the R.H.S This seems to say the number of $a_r$ must must be the same as that of the natural numbers. Hence, the set has cardinality $ \aleph_0 $","Question So I conjectured a formula which was proven : Let . We prove that if the 's are small enough, the result is true. Claim: If and is smooth, then My question is what is the cardinality of the set of ? Reason for confusion Focusing on the L.H.S This seems to say for every point on the curve can be mapped to which in turn can be mapped to a coefficient . Hence, the set has cardinality Focusing on the R.H.S This seems to say the number of must must be the same as that of the natural numbers. Hence, the set has cardinality",b_r = \sum_{d \mid r} a_d\mu(\frac{m}{d}) b_r \lim_{n \to \infty} \frac{\log^2(n)}{n}\sum_{r=1}^n |b_r| = 0 f \lim_{k \to \infty} \lim_{n \to \infty} \sum_{r=1}^n a_rf\left(\frac{kr}{n}\right)\frac{k}{n} = \left(\lim_{s \to 1} \frac{1}{\zeta(s)}\sum_{r=1}^\infty \frac{a_r}{r^s}\right)\int_0^\infty f(x)dx. a_r f(x) a_r  x \to f(x) \to a_r   2^{\aleph_0}  a_r  \aleph_0 ,"['integration', 'measure-theory', 'elementary-set-theory', 'intuition']"
65,Find $\Omega$ s.t. $L^1_{loc}(\Omega)$ is a normed space,Find  s.t.  is a normed space,\Omega L^1_{loc}(\Omega),Is there any measurable $\Omega\subset\mathbb{R}^N$ for some $N\in\mathbb{N}$ with infinite Lebesgue-measure such that there exists a norm for $L^1_{loc}(\Omega)$ ?,Is there any measurable for some with infinite Lebesgue-measure such that there exists a norm for ?,\Omega\subset\mathbb{R}^N N\in\mathbb{N} L^1_{loc}(\Omega),"['real-analysis', 'functional-analysis', 'measure-theory']"
66,About essential range and essential supremum,About essential range and essential supremum,,"$\newcommand{\esssup}{\mathrm{ess\,sup}}$$\newcommand{\essrng}{\mathrm{ess\,range}}$ I am trying to prove that $\esssup(f) = \sup(\essrng(f))$ , where we define $$ \esssup(f) = \inf \{b \in \mathbb{R}_+ : \mu(f^{-1}((b, \infty))) = 0\}  $$ and similarly $$ \essrng(f) = \{w \in \mathbb{R}_+ : \mu(f^{-1}(B(w, \epsilon))) > 0\}. $$ Actually, I already showed that $\esssup(f) \leq \sup(\essrng(f))$ , but I have not been able to prove the other direction. The answer on this related question hasn't been useful for me to prove the desired reverse inequality. If you could give me a hint to prove it, I'll be really grateful.","I am trying to prove that , where we define and similarly Actually, I already showed that , but I have not been able to prove the other direction. The answer on this related question hasn't been useful for me to prove the desired reverse inequality. If you could give me a hint to prove it, I'll be really grateful.","\newcommand{\esssup}{\mathrm{ess\,sup}}\newcommand{\essrng}{\mathrm{ess\,range}} \esssup(f) = \sup(\essrng(f)) 
\esssup(f) = \inf \{b \in \mathbb{R}_+ : \mu(f^{-1}((b, \infty))) = 0\} 
 
\essrng(f) = \{w \in \mathbb{R}_+ : \mu(f^{-1}(B(w, \epsilon))) > 0\}.
 \esssup(f) \leq \sup(\essrng(f))","['measure-theory', 'lp-spaces', 'measurable-functions']"
67,"Proof that $f$ is Lebesgue-integrable in $[0,1]$.",Proof that  is Lebesgue-integrable in .,"f [0,1]","Let $f:[0,1]\to\mathbb{R}$ be a non-negative function. For all $\epsilon\in(0,1]\,$ , let $f$ be Riemann-integrable in $[\epsilon,1]$ . Show that $f\in L_{1}[0,1]\,$ iff $\,\,\lim_{\,\epsilon \to 0}\int_{\epsilon}^{1}f(x)\,dx\,$ exists. Moreover, in that case $$\int_{[0,1]}f\,d\lambda=\lim_{\,\epsilon \to 0}\,\int_{\epsilon}^{1}f(x)\,dx$$ My attempt: First, I want to show that $f$ is a measurable function. Since $f$ is Riemann-integrable in $[\epsilon,1]$ , it is also Lebesgue-integrable and, in particular, it is measurable. Letting $\epsilon\to 0$ , $f$ is a measurable function in $(0,1]$ . Now, given any $t\in\mathbb{R}$ , define the set $A$ by $$A:= \{x\in[0,1] : f(x) \ge t  \}$$ We want to show that $A$ is a measurable set. Let $A_{1}:=A\,\cap\{0\}$ and $A_{2}:=A\cap (0,1]$ . Since $f$ is measurable in $(0,1]$ , $A_{2}$ is measurable. Now, the set $A_{1}$ will be empty or $A_{1}=\{0\}$ , and in both cases is a measurable set. Hence, $A=A_{1}\cup A_{2}$ is measurable. So, $f$ is a measurable function in $[0,1]$ . Now, for all $n\ge 1$ , let $E_{n}:=[1/n,1]$ . Note that $E_{n} \subseteq E_{n+1}$ and $\bigcup E_{n}=(0,1]$ . Further, since $f$ is non-negative, $(\int_{1/n}^{1} f(x)dx)_{n\ge 1}$ is an increasing sequence. So, it will converge iff it is bounded above. The claim then follows from $$\lim_{\,\epsilon \to 0}\,\int_{\epsilon}^{1}f(x)\,dx=\lim_{\,n \to \infty}\,\int_{1/n}^{1}f(x)\,dx=\lim_{\,n \to \infty}\,\int_{E_{n}} f\,d\lambda=\int_{(0,1]} f\,d\lambda=\int_{[0,1]} f\,d\lambda< +\infty$$ Did I get this right?","Let be a non-negative function. For all , let be Riemann-integrable in . Show that iff exists. Moreover, in that case My attempt: First, I want to show that is a measurable function. Since is Riemann-integrable in , it is also Lebesgue-integrable and, in particular, it is measurable. Letting , is a measurable function in . Now, given any , define the set by We want to show that is a measurable set. Let and . Since is measurable in , is measurable. Now, the set will be empty or , and in both cases is a measurable set. Hence, is measurable. So, is a measurable function in . Now, for all , let . Note that and . Further, since is non-negative, is an increasing sequence. So, it will converge iff it is bounded above. The claim then follows from Did I get this right?","f:[0,1]\to\mathbb{R} \epsilon\in(0,1]\, f [\epsilon,1] f\in L_{1}[0,1]\, \,\,\lim_{\,\epsilon \to 0}\int_{\epsilon}^{1}f(x)\,dx\, \int_{[0,1]}f\,d\lambda=\lim_{\,\epsilon \to 0}\,\int_{\epsilon}^{1}f(x)\,dx f f [\epsilon,1] \epsilon\to 0 f (0,1] t\in\mathbb{R} A A:= \{x\in[0,1] : f(x) \ge t  \} A A_{1}:=A\,\cap\{0\} A_{2}:=A\cap (0,1] f (0,1] A_{2} A_{1} A_{1}=\{0\} A=A_{1}\cup A_{2} f [0,1] n\ge 1 E_{n}:=[1/n,1] E_{n} \subseteq E_{n+1} \bigcup E_{n}=(0,1] f (\int_{1/n}^{1} f(x)dx)_{n\ge 1} \lim_{\,\epsilon \to 0}\,\int_{\epsilon}^{1}f(x)\,dx=\lim_{\,n \to \infty}\,\int_{1/n}^{1}f(x)\,dx=\lim_{\,n \to \infty}\,\int_{E_{n}} f\,d\lambda=\int_{(0,1]} f\,d\lambda=\int_{[0,1]} f\,d\lambda< +\infty","['measure-theory', 'lebesgue-integral']"
68,matrix exponential change of variables,matrix exponential change of variables,,"Consider an integral over the space $P_n$ of symmetric positive definite $n \times n$ matrices, $$ I = \int_{P_n} f(X) \, (\det X)^{-\frac{n+1}{2}} \, dX \;, $$ where $dX = \prod_{i\le j} dx_{ij}$ and $dx_{ij}$ is the usual Lebesgue measure over $\mathbb{R}$ . It makes intuitive sense that there is a change of variables $X = \exp Y$ using the matrix exponential so that the integration can be carried out over the space $S_n$ of symmetric $n \times n$ matrices instead, $$ I = \int_{S_n} f(\exp Y) \, dY \;. $$ Is this true? Edit: This was my approach. I believe the first integral can be written in terms of the eigendecomposition $X = R\Lambda R^T$ as $$ I = c_n \int\limits_{{\rm O}(n)} \, \int\limits_{\mathbb{R}^n_+} \! f(R\Lambda R^T) \, (\det \Lambda)^{-\frac{n+1}{2}} \, \prod_{i<j} |\lambda_i - \lambda_j| \, d\Lambda \, dR \;, $$ with $c_n$ a constant, $d\Lambda = \prod_{i=1}^{n} d\lambda_i$ , and $dR$ the Haar measure on ${\rm O}(n)$ . The change of variables $X = \exp Y = R (\exp \Theta) R^T$ then gives $$ I = c_n \int\limits_{{\rm O}(n)} \, \int\limits_{\mathbb{R}^n} \! f(R(\exp \Theta)R^T) \, \prod_{i<j} 2 \sinh\bigl(\tfrac{|\theta_i-\theta_j|}{2}\bigr) \, d\Theta \, dR \;. $$ Guess: $dY = c_n \, \prod_{i<j} |\theta_i - \theta_j| \, d\Theta \, dR$ also holds for the space $S_n$ . Then it would appear that the second integrand needs to be $$ I = \int_{S_n} f(\exp Y) \, \prod_{i<j} \frac{\sinh(|\theta_i-\theta_j|/2)}{|\theta_i-\theta_j|/2} \, dY \;, $$ with $\theta_1, \ldots, \theta_n$ the eigenvalues of $Y$ . Is this true? If so, does the extra factor have a particular meaning?","Consider an integral over the space of symmetric positive definite matrices, where and is the usual Lebesgue measure over . It makes intuitive sense that there is a change of variables using the matrix exponential so that the integration can be carried out over the space of symmetric matrices instead, Is this true? Edit: This was my approach. I believe the first integral can be written in terms of the eigendecomposition as with a constant, , and the Haar measure on . The change of variables then gives Guess: also holds for the space . Then it would appear that the second integrand needs to be with the eigenvalues of . Is this true? If so, does the extra factor have a particular meaning?","P_n n \times n 
I = \int_{P_n} f(X) \, (\det X)^{-\frac{n+1}{2}} \, dX \;,
 dX = \prod_{i\le j} dx_{ij} dx_{ij} \mathbb{R} X = \exp Y S_n n \times n 
I = \int_{S_n} f(\exp Y) \, dY \;.
 X = R\Lambda R^T 
I = c_n \int\limits_{{\rm O}(n)} \, \int\limits_{\mathbb{R}^n_+} \! f(R\Lambda R^T) \, (\det \Lambda)^{-\frac{n+1}{2}} \, \prod_{i<j} |\lambda_i - \lambda_j| \, d\Lambda \, dR \;,
 c_n d\Lambda = \prod_{i=1}^{n} d\lambda_i dR {\rm O}(n) X = \exp Y = R (\exp \Theta) R^T 
I = c_n \int\limits_{{\rm O}(n)} \, \int\limits_{\mathbb{R}^n} \! f(R(\exp \Theta)R^T) \, \prod_{i<j} 2 \sinh\bigl(\tfrac{|\theta_i-\theta_j|}{2}\bigr) \, d\Theta \, dR \;.
 dY = c_n \, \prod_{i<j} |\theta_i - \theta_j| \, d\Theta \, dR S_n 
I = \int_{S_n} f(\exp Y) \, \prod_{i<j} \frac{\sinh(|\theta_i-\theta_j|/2)}{|\theta_i-\theta_j|/2} \, dY \;,
 \theta_1, \ldots, \theta_n Y","['linear-algebra', 'integration']"
69,A question regarding measurability,A question regarding measurability,,"The following is a problem from a text I (in portuguese) I am reading about Critical Point Theory: Let $\Omega \subset \Bbb{R}^N$ be an open set, $f: \overline \Omega \times \Bbb{R} \longrightarrow \Bbb{R}$ be a Carathéodory function and $F(x, t) = \int_0^t f(x, s) \ ds$ . Show that for every $u : \Omega \longrightarrow \Bbb{R}$ measurable the map $F(\cdot, u(\cdot))$ is measurable. Recall that $f$ is a Carathéodory function if (a) $x \mapsto f(x, s)$ is measurable for every $s$ and (b) $s \mapsto f(x, s)$ is continuous for almost every $x \in \Omega$ . I proceeded as follows: If $u$ is measurable there is a sequence of simple functions $(u_n)$ such that $u_n(x) \to u(x)$ for every $x \in \Omega$ . Write each $u_n$ as follows: $$ u_n = \sum_1^{k_n} z_{ni} \chi_{E_{ni}}. $$ Then $$ F(x, u_n(x)) = \int_0^{\sum_1^{k_n} z_{ni} \chi_{E_{ni}}(x)} f(x, s) \ ds = \int_0^{z_{nj}} f(x, s) \ ds \\ = \sum_1^{k_n} \left( \int_0^{z_{ni}} f(x, s) \ ds \right) \chi_{E_{ni}}(x) = \sum_i^{k_n} F(x, z_{ni}) \chi_{E_{ni}}(x) $$ Now, if each $F(x, z_{ni})$ is measurable then we have a sequence of measurable functions converging pointwise to $F(\cdot, u(\cdot))$ , and we are done. My question is: Is the above argument correct? If yes, how to show that $F(x, z_{ni})$ is measurable? If not, how does one solve this exercise? Thanks in advance and kind regards. EDIT I have made some progress with a hint by Gláucio Terra: By Tonelli's Theorem, we only have to show that $f$ is measurable with respect to the product $\sigma$ -algebra $\mathcal{L} \otimes \mathcal{B}$ , where $\mathcal{L}$ is the Lebesgue $\sigma$ -algebra in $\Bbb{R}^N$ and $\mathcal{B}$ is the Borel $\sigma$ -algebra in $\Bbb{R}$ . We also assume the Lebesgue $\sigma$ -algebra on the image $\Bbb{R}$ . Then $f^+$ and $f^-$ are measurable. By Tonelli's Theorem, the maps $\int_0^{z_{ni}}f^+(x, s) \ ds$ and $\int_0^{z_{ni}}f^-(x, s) \ ds$ are measurable and so also is $$ F(x, z_{ni}) =\int_0^{z_{ni}}f^+(x, s)- f^-(x, s) \ ds, $$ To show that $f$ is measurable, Gláucio suggested addapting Exercise 2.11 in Folland's Real Analysis . I tried as follows: For $n \in \Bbb{N}$ , define $f_n$ as follows. Given $i \in \Bbb{Z}$ , let $a_i^n = i/n$ and define $$ f_n(x, s) =  \sum_{i = - \infty}^{\infty} \frac{f(x, a_{i+1}^n) (s - a_i^n) - f(x, a_i^n)(s - a_{i + 1}^n)}{a_{i+1}^n - a_i^n} \chi_{[a_i^n, a_{i + 1}^n]}(s). $$ Note that, for all $i, n$ , $$ (x, s) \mapsto x \mapsto f(x, a_{i}^n) $$ is a composition of $\mathcal{L} \times \mathcal{B}$ -measurable maps and hence is measurable, and the map $(x, s) \mapsto (s - a_i^n)$ is continuous and hence $\mathcal{L} \otimes \mathcal{B}$ -measurable. Hence $f_n$ is measurable, and $f_n \to f$ almost everywhere. Now, to say that $f$ is measurable we need conevrgence everywhere . How to overcome this difficulty?","The following is a problem from a text I (in portuguese) I am reading about Critical Point Theory: Let be an open set, be a Carathéodory function and . Show that for every measurable the map is measurable. Recall that is a Carathéodory function if (a) is measurable for every and (b) is continuous for almost every . I proceeded as follows: If is measurable there is a sequence of simple functions such that for every . Write each as follows: Then Now, if each is measurable then we have a sequence of measurable functions converging pointwise to , and we are done. My question is: Is the above argument correct? If yes, how to show that is measurable? If not, how does one solve this exercise? Thanks in advance and kind regards. EDIT I have made some progress with a hint by Gláucio Terra: By Tonelli's Theorem, we only have to show that is measurable with respect to the product -algebra , where is the Lebesgue -algebra in and is the Borel -algebra in . We also assume the Lebesgue -algebra on the image . Then and are measurable. By Tonelli's Theorem, the maps and are measurable and so also is To show that is measurable, Gláucio suggested addapting Exercise 2.11 in Folland's Real Analysis . I tried as follows: For , define as follows. Given , let and define Note that, for all , is a composition of -measurable maps and hence is measurable, and the map is continuous and hence -measurable. Hence is measurable, and almost everywhere. Now, to say that is measurable we need conevrgence everywhere . How to overcome this difficulty?","\Omega \subset \Bbb{R}^N f: \overline \Omega \times \Bbb{R} \longrightarrow \Bbb{R} F(x, t) = \int_0^t f(x, s) \ ds u : \Omega \longrightarrow \Bbb{R} F(\cdot, u(\cdot)) f x \mapsto f(x, s) s s \mapsto f(x, s) x \in \Omega u (u_n) u_n(x) \to u(x) x \in \Omega u_n 
u_n = \sum_1^{k_n} z_{ni} \chi_{E_{ni}}.
 
F(x, u_n(x)) = \int_0^{\sum_1^{k_n} z_{ni} \chi_{E_{ni}}(x)} f(x, s) \ ds = \int_0^{z_{nj}} f(x, s) \ ds \\ = \sum_1^{k_n} \left( \int_0^{z_{ni}} f(x, s) \ ds \right) \chi_{E_{ni}}(x) = \sum_i^{k_n} F(x, z_{ni}) \chi_{E_{ni}}(x)
 F(x, z_{ni}) F(\cdot, u(\cdot)) F(x, z_{ni}) f \sigma \mathcal{L} \otimes \mathcal{B} \mathcal{L} \sigma \Bbb{R}^N \mathcal{B} \sigma \Bbb{R} \sigma \Bbb{R} f^+ f^- \int_0^{z_{ni}}f^+(x, s) \ ds \int_0^{z_{ni}}f^-(x, s) \ ds 
F(x, z_{ni}) =\int_0^{z_{ni}}f^+(x, s)- f^-(x, s) \ ds,
 f n \in \Bbb{N} f_n i \in \Bbb{Z} a_i^n = i/n 
f_n(x, s) =  \sum_{i = - \infty}^{\infty} \frac{f(x, a_{i+1}^n) (s - a_i^n) - f(x, a_i^n)(s - a_{i + 1}^n)}{a_{i+1}^n - a_i^n} \chi_{[a_i^n, a_{i + 1}^n]}(s).
 i, n 
(x, s) \mapsto x \mapsto f(x, a_{i}^n)
 \mathcal{L} \times \mathcal{B} (x, s) \mapsto (s - a_i^n) \mathcal{L} \otimes \mathcal{B} f_n f_n \to f f","['real-analysis', 'measure-theory', 'calculus-of-variations', 'measurable-functions']"
70,"Prove that $f(x)=\sum_{n=1}^\infty \max(0, 1-2^n|x-n|)$ is square integrable on $\mathbb{R}$.",Prove that  is square integrable on .,"f(x)=\sum_{n=1}^\infty \max(0, 1-2^n|x-n|) \mathbb{R}","In this post , @Post No Bulls claims that $$ f(x)=\sum_{n=1}^\infty \max(0, 1-2^n|x-n|) $$ is square integrable on $\mathbb R$ but $\limsup_{x\to\infty} f(x)=1$ , and $\lim_{x\to\infty} f(x)$ does not exist. How to prove that $f$ is square integrable on $\mathbb{R}?$","In this post , @Post No Bulls claims that is square integrable on but , and does not exist. How to prove that is square integrable on","
f(x)=\sum_{n=1}^\infty \max(0, 1-2^n|x-n|)
 \mathbb R \limsup_{x\to\infty} f(x)=1 \lim_{x\to\infty} f(x) f \mathbb{R}?","['real-analysis', 'calculus', 'integration', 'measure-theory', 'lebesgue-integral']"
71,Birkhoff averages convergence,Birkhoff averages convergence,,"Let be $(X,\mathcal{A},\mu)$ a probability space, $T:X\to X$ a measurable tranformation preserving $\mu$ and $f: X \rightarrow \mathbb C$ a measurable function. Show that for almost every $x \in X$ either: \begin{equation} \lim_{N \rightarrow \infty} \frac{1}{N} \sum_{n=0}^{N-1} |f(T^n(x))| = \infty \end{equation} or \begin{equation} \lim_{N \rightarrow \infty} \frac{1}{N} \sum_{n=0}^{N-1} f(T^n(x)) \quad\text{exists and it's finite.} \end{equation} My attempt : Since $f$ isn't necessarily integrable, i tried to applicate Birkhoff ergodic theorem to $f_m = f 1_{|f| \leq m} + m 1_{|f| > m}$ which is an integrable function. The problem that i have is that i can't seem to get an upper bound for $\int_E f $ , where $E = \{ x | \sup_N S_N^{|f|}(x) < + \infty \}$ where $S_N^f$ are the Birkhoff averages of $f$ . I have shown that $E$ an invariant set. Does $S_N^f(x)$ converge to $\int_E f d\mu$ or i am on a bad track?","Let be a probability space, a measurable tranformation preserving and a measurable function. Show that for almost every either: or My attempt : Since isn't necessarily integrable, i tried to applicate Birkhoff ergodic theorem to which is an integrable function. The problem that i have is that i can't seem to get an upper bound for , where where are the Birkhoff averages of . I have shown that an invariant set. Does converge to or i am on a bad track?","(X,\mathcal{A},\mu) T:X\to X \mu f: X \rightarrow \mathbb C x \in X \begin{equation}
\lim_{N \rightarrow \infty} \frac{1}{N} \sum_{n=0}^{N-1} |f(T^n(x))| = \infty
\end{equation} \begin{equation}
\lim_{N \rightarrow \infty} \frac{1}{N} \sum_{n=0}^{N-1} f(T^n(x)) \quad\text{exists and it's finite.}
\end{equation} f f_m = f 1_{|f| \leq m} + m 1_{|f| > m} \int_E f  E = \{ x | \sup_N S_N^{|f|}(x) < + \infty \} S_N^f f E S_N^f(x) \int_E f d\mu","['measure-theory', 'ergodic-theory']"
72,If the derivatives of two bounded variation functions are equal in $L_1$ then $F=G$ almost everywhere?,If the derivatives of two bounded variation functions are equal in  then  almost everywhere?,L_1 F=G,Suppose $F$ and $G$ are functions of bounded variation on a closed interval $I$ . Then we know that both functions are differentiable almost everywhere.Does it follow that If the derivative of $F$ and the derivative of $G$ belong in the same equivalence class in $L_1$ then $F=G$ almost everywhere? Thanks in advance,Suppose and are functions of bounded variation on a closed interval . Then we know that both functions are differentiable almost everywhere.Does it follow that If the derivative of and the derivative of belong in the same equivalence class in then almost everywhere? Thanks in advance,F G I F G L_1 F=G,['measure-theory']
73,Balls of minimal variance,Balls of minimal variance,,"Consider a metric space $(X, \rho)$ and let's say that $\mu$ is a Borel $\sigma$ -finite measure on this space. For every measurable set $A$ its variance is defined as $$ V_{\mu, \rho}(A) := \inf_{a'\in A}\int\limits_{A}\rho(a,a')\mu(\mathrm da'). $$ Here if minimum is attained at some $a'$ we can think of the latter as a mass center of $A$ with respect to $\mu$ and $\rho$ . Let's call a finite measure set $A$ good if there's no set with the at least that measure and lower variance. That is, $A$ is good iff $$ V_{\mu,\rho}(A) = \inf_{A':\mu(A') \geq \mu(A)}V_{\mu, \rho}(A'). $$ Intuitively it seems that if $\mu$ and $\rho$ are consistent in some way, then $A$ is good iff it is a $\rho$ -ball a.e. that is there exists $x\in X, r\geq 0$ such that $\mu(A\triangle B_\rho(x,r)) = 0$ where $\triangle$ denotes the symmetric difference between two sets. Are there any results of the latter kind known? In particular, let's say $X = \Bbb R^2$ endowed with the Euclidean metric $\rho$ and Lebesgue measure $\mu$ . Some particular questions would be Is that true that every ball is good? Are there any good sets that are not balls a.e.? What if $\rho(a,a')$ is a $q$ -norm for $q\neq 2$ ? What if $\rho$ is a Euclidean metric, but $\mu$ has a density of a standard normal random variable?","Consider a metric space and let's say that is a Borel -finite measure on this space. For every measurable set its variance is defined as Here if minimum is attained at some we can think of the latter as a mass center of with respect to and . Let's call a finite measure set good if there's no set with the at least that measure and lower variance. That is, is good iff Intuitively it seems that if and are consistent in some way, then is good iff it is a -ball a.e. that is there exists such that where denotes the symmetric difference between two sets. Are there any results of the latter kind known? In particular, let's say endowed with the Euclidean metric and Lebesgue measure . Some particular questions would be Is that true that every ball is good? Are there any good sets that are not balls a.e.? What if is a -norm for ? What if is a Euclidean metric, but has a density of a standard normal random variable?","(X, \rho) \mu \sigma A 
V_{\mu, \rho}(A) := \inf_{a'\in A}\int\limits_{A}\rho(a,a')\mu(\mathrm da').
 a' A \mu \rho A A 
V_{\mu,\rho}(A) = \inf_{A':\mu(A') \geq \mu(A)}V_{\mu, \rho}(A').
 \mu \rho A \rho x\in X, r\geq 0 \mu(A\triangle B_\rho(x,r)) = 0 \triangle X = \Bbb R^2 \rho \mu \rho(a,a') q q\neq 2 \rho \mu","['measure-theory', 'metric-spaces']"
74,Is a weakly$^*$ convergent net of positive(!) Radon measures eventually norm-bounded?,Is a weakly convergent net of positive(!) Radon measures eventually norm-bounded?,^*,"Let $X$ be a locally compact Hausdorff space and $C_0(X)$ the space of continuous functions vanishing at infinity. If $\mu_n$ is a sequence of positive Radon measures on $X$ such that $\mu_n \to \mu$ for the weak $^*$ topology $\sigma(M(X), C_0(X))$ then $\mu_n$ is norm-bounded. How does this generalize to nets? In contrast to sequences, a convergent net need not be bounded (""the initial parts of a net can be infinitely long""). Moreover, a weakly $^*$ convergent net (of signed Radon measures) need not be eventually bounded, see here .  Does positivity help out? If $\mu_\alpha \geq 0$ and $\mu_\alpha \to \mu$ for the weak $^*$ topology, does it follow that $\mu_\alpha$ is eventually norm-bounded, i.e. is there $\alpha_0$ such that $\sup_{\alpha \geq \alpha_0} \lVert \mu_\alpha \rVert = \sup_{\alpha \geq \alpha_0} \mu_\alpha(X) < \infty$ ? This is related to the question here , but may be of independent interest for the MSE community. Edit: Note that this is true if $X$ is compact, because $1_X \in C_0(X) = C(X)$ . Then $\mu_\alpha \to \mu$ weakly $^*$ implies $\mu_\alpha(X) \to \mu(X)$ , so that $\mu_\alpha(X)$ is a convergent net in $\mathbb{R}$ and therefore eventually bounded: for $\varepsilon = 1$ there is $\alpha_0$ such that $0 \leq \mu_\alpha(X) \leq \mu(X) + 1$ for all $\alpha \geq \alpha_0$ . In particular, this example of an unbounded weakly $^*$ convergent net of Radon measures does not work for positive measures/functionals.","Let be a locally compact Hausdorff space and the space of continuous functions vanishing at infinity. If is a sequence of positive Radon measures on such that for the weak topology then is norm-bounded. How does this generalize to nets? In contrast to sequences, a convergent net need not be bounded (""the initial parts of a net can be infinitely long""). Moreover, a weakly convergent net (of signed Radon measures) need not be eventually bounded, see here .  Does positivity help out? If and for the weak topology, does it follow that is eventually norm-bounded, i.e. is there such that ? This is related to the question here , but may be of independent interest for the MSE community. Edit: Note that this is true if is compact, because . Then weakly implies , so that is a convergent net in and therefore eventually bounded: for there is such that for all . In particular, this example of an unbounded weakly convergent net of Radon measures does not work for positive measures/functionals.","X C_0(X) \mu_n X \mu_n \to \mu ^* \sigma(M(X), C_0(X)) \mu_n ^* \mu_\alpha \geq 0 \mu_\alpha \to \mu ^* \mu_\alpha \alpha_0 \sup_{\alpha \geq \alpha_0} \lVert \mu_\alpha \rVert = \sup_{\alpha \geq \alpha_0} \mu_\alpha(X) < \infty X 1_X \in C_0(X) = C(X) \mu_\alpha \to \mu ^* \mu_\alpha(X) \to \mu(X) \mu_\alpha(X) \mathbb{R} \varepsilon = 1 \alpha_0 0 \leq \mu_\alpha(X) \leq \mu(X) + 1 \alpha \geq \alpha_0 ^*","['functional-analysis', 'measure-theory']"
75,Why is the following topology of probability measures Hausdorff?,Why is the following topology of probability measures Hausdorff?,,"Let $X$ be a Hausdorff topological space. Let $PX$ be the set of all Borel probability measures on $X$ . Bogachev's Measure Theory (vol. II, section 8.10.iv) defines the $A$ -topology on $PX$ to be the one generated by the following opens, $$ U(\mu, G, \varepsilon) := \{\nu \in PX : \mu(G) < \nu(G) + \varepsilon \}, $$ for all $\mu\in PX$ , $G\subseteq X$ open, and $\varepsilon > 0$ . It then says that since two Borel measures are equal if and only if they coincide on all open sets (Lemma 7.1.2 in there), the $A$ -topology is Hausdorff. This is not clear to me: how does the proof proceed, in more detail? Here is what I figured out so far. Suppose that $\mu,\nu\in PX$ are not equal. In other words, there exists an open set $G\subseteq X$ such that $\mu(G)\ne \nu(G)$ . Suppose, for example, that $\mu(G) > \nu(G)$ . Then there exists $\varepsilon>0$ such that $\mu(G) \ge \nu(G) + \varepsilon$ . Therefore $\nu\notin U(\mu, G, \varepsilon)$ , while clearly $\mu\in U(\mu, G, \varepsilon)$ . We have found an open neighborhood of $\mu$ that does not contain $\nu$ . But how can we find an open neighborhood of $\nu$ that does not contain $\mu$ ?","Let be a Hausdorff topological space. Let be the set of all Borel probability measures on . Bogachev's Measure Theory (vol. II, section 8.10.iv) defines the -topology on to be the one generated by the following opens, for all , open, and . It then says that since two Borel measures are equal if and only if they coincide on all open sets (Lemma 7.1.2 in there), the -topology is Hausdorff. This is not clear to me: how does the proof proceed, in more detail? Here is what I figured out so far. Suppose that are not equal. In other words, there exists an open set such that . Suppose, for example, that . Then there exists such that . Therefore , while clearly . We have found an open neighborhood of that does not contain . But how can we find an open neighborhood of that does not contain ?","X PX X A PX 
U(\mu, G, \varepsilon) := \{\nu \in PX : \mu(G) < \nu(G) + \varepsilon \},
 \mu\in PX G\subseteq X \varepsilon > 0 A \mu,\nu\in PX G\subseteq X \mu(G)\ne \nu(G) \mu(G) > \nu(G) \varepsilon>0 \mu(G) \ge \nu(G) + \varepsilon \nu\notin U(\mu, G, \varepsilon) \mu\in U(\mu, G, \varepsilon) \mu \nu \nu \mu","['general-topology', 'measure-theory', 'outer-measure']"
76,Does my proof show that the sequence of measures defined using mollifiers with shrinking support converges weakly to the Dirac measure?,Does my proof show that the sequence of measures defined using mollifiers with shrinking support converges weakly to the Dirac measure?,,"Following Evan's PDE book, Appendix C4, PP. 629, let's define the function: $\eta(x):=C\exp\left(\frac{1}{\|x\|^2 - 1} \right) \forall x \in \mathbb{R}^d$ when $\|x\|\leq 1$ and $0$ otherwise, where $C$ is a positive constant so that the integral of $\eta$ is $1$ . Define the mollifier $\eta_\varepsilon$ by : $\eta_\varepsilon(x): \frac{1}{\varepsilon^d}\eta(\frac{x}{\varepsilon})$ . Next, let's define the measure $P_\varepsilon$ by $dP_\varepsilon(x):=\eta_\varepsilon(x) \, dx$ , where $dx$ denotes the Lebesgue measure on $\mathbb{R}^d$ . I'm trying to prove (if true?!), that: $P_\varepsilon \to \delta_0$ weakly as $\varepsilon \to 0$ , where $\delta_0$ denotes the Dirac measure at $0$ . How do we prove this, if possible? So to start, I want to prove that $\forall f$ continuous, bounded on $\mathbb{R}^d$ , we must have: \begin{align} & \int_{\mathbb{R}^d} f(x)\, dP_\varepsilon(x) = \int_{\mathbb{R}^d} f(x)\eta_\varepsilon(x) \, dx \\ \to {} & f(0)=\int_{\mathbb{R}^d} f(x) \, d\delta_0(x) \end{align} as $\varepsilon \to 0$ . To achive this, I've done as follows: \begin{align} & \int_{\mathbb{R}^d}f(x) \eta_{\varepsilon}(x)\,dx - f(0) \\ = {} & \int_{\mathbb{R}^d}(f(x)-f(0)) \eta_\varepsilon(x) \, dx \\ = {} & \int_{B(0;\varepsilon)}(f(x)-f(0)) \eta_\varepsilon(x) \, dx, \end{align} as the support of $\eta_\varepsilon = \bar{B(0;\varepsilon)}$ . Fix any $\eta > 0$ . Using the continuity of $f$ at $0$ , we must have a $\varepsilon > 0$ so that for all $x$ with $\|x\|\leq \varepsilon$ , $|f(x)-f(0)|\leq \eta$ . Next, after we've taken the absolute values: \begin{align} & \left|\int_{B(0;\varepsilon)}(f(x)-f(0)) \eta_\varepsilon(x) \, dx \right| \\ \leq {} & \int_{B(0;\varepsilon)}|f(x)-f(0)| |\eta_\varepsilon(x)| \, dx \\ = {} & \int_{B(0;\varepsilon)}|f(x)-f(0)| \eta_\varepsilon(x) \, dx \\ \leq {} & \eta \int_{B(0;\varepsilon)} \eta_\varepsilon(x)\,dx \\ \leq {} & \eta \int_{\mathbb{R}^d} \eta_\varepsilon(x) \, dx \\ = {} & \eta \end{align} I think this finishes the proof, but if you could verify if it's correct, then it'd be greatly appreciated :)","Following Evan's PDE book, Appendix C4, PP. 629, let's define the function: when and otherwise, where is a positive constant so that the integral of is . Define the mollifier by : . Next, let's define the measure by , where denotes the Lebesgue measure on . I'm trying to prove (if true?!), that: weakly as , where denotes the Dirac measure at . How do we prove this, if possible? So to start, I want to prove that continuous, bounded on , we must have: as . To achive this, I've done as follows: as the support of . Fix any . Using the continuity of at , we must have a so that for all with , . Next, after we've taken the absolute values: I think this finishes the proof, but if you could verify if it's correct, then it'd be greatly appreciated :)","\eta(x):=C\exp\left(\frac{1}{\|x\|^2 - 1} \right) \forall x \in \mathbb{R}^d \|x\|\leq 1 0 C \eta 1 \eta_\varepsilon \eta_\varepsilon(x): \frac{1}{\varepsilon^d}\eta(\frac{x}{\varepsilon}) P_\varepsilon dP_\varepsilon(x):=\eta_\varepsilon(x) \, dx dx \mathbb{R}^d P_\varepsilon \to \delta_0 \varepsilon \to 0 \delta_0 0 \forall f \mathbb{R}^d \begin{align}
& \int_{\mathbb{R}^d} f(x)\, dP_\varepsilon(x) = \int_{\mathbb{R}^d} f(x)\eta_\varepsilon(x) \, dx \\
\to {} & f(0)=\int_{\mathbb{R}^d} f(x) \, d\delta_0(x)
\end{align} \varepsilon \to 0 \begin{align}
& \int_{\mathbb{R}^d}f(x) \eta_{\varepsilon}(x)\,dx - f(0) \\
= {} & \int_{\mathbb{R}^d}(f(x)-f(0)) \eta_\varepsilon(x) \, dx \\
= {} & \int_{B(0;\varepsilon)}(f(x)-f(0)) \eta_\varepsilon(x) \, dx,
\end{align} \eta_\varepsilon = \bar{B(0;\varepsilon)} \eta > 0 f 0 \varepsilon > 0 x \|x\|\leq \varepsilon |f(x)-f(0)|\leq \eta \begin{align}
& \left|\int_{B(0;\varepsilon)}(f(x)-f(0)) \eta_\varepsilon(x) \, dx \right| \\
\leq {} & \int_{B(0;\varepsilon)}|f(x)-f(0)| |\eta_\varepsilon(x)| \, dx \\
= {} & \int_{B(0;\varepsilon)}|f(x)-f(0)| \eta_\varepsilon(x) \, dx \\
\leq {} & \eta \int_{B(0;\varepsilon)} \eta_\varepsilon(x)\,dx \\
\leq {} & \eta \int_{\mathbb{R}^d} \eta_\varepsilon(x) \, dx \\
= {} & \eta
\end{align}","['probability', 'functional-analysis', 'measure-theory', 'probability-distributions', 'dirac-delta']"
77,"Show that $\left\{ f_{n}\right\} _{n=1}^{\infty}$ converges to $f$ in $L^{p}$, i.e., $\left|\left|f_{n}-f\right|\right|_{p}\to0$.","Show that  converges to  in , i.e., .",\left\{ f_{n}\right\} _{n=1}^{\infty} f L^{p} \left|\left|f_{n}-f\right|\right|_{p}\to0,"Let $1\leq p\leq\infty$ , $\alpha\in\mathbb{R}$ and $I=(0,1]$ with $2\alpha p<1$ . For $n\in\mathbb{N}$ , Define $f_{n}:I\to\mathbb{R}$ by $f_{n}\left(x\right)=\frac{n}{nx^{\alpha}+1}$ and that $f\left(x\right)=\lim_{n\to\infty}f_{n}\left(x\right)$ , $x\in I$ . Show that $\left\{ f_{n}\right\} _{n=1}^{\infty}$ converges to $f$ in $L^{p}$ , i.e., $\left|\left|f_{n}-f\right|\right|_{p}\to0$ . What I tried: Proof. WTS that $\lim_{n\to\infty}\int_{0}^{1}\left|f_{n}-f\right|^{p}=0$ . $f\left(x\right)=\lim_{n\to\infty}f_{n}\left(x\right)=\lim_{n\to\infty}\frac{n}{nx^{\alpha}+1}=\frac{1}{x^{\alpha}}.$ Now, $$\left|f_{n}-f\right|^{p}	=\left|\frac{n}{nx^{\alpha}+1}-\frac{1}{x^{\alpha}}\right|^{p} 	=\left|\frac{-1}{nx^{2\alpha}+x^{\alpha}}\right|^{p} 	\leq\frac{1}{nx^{2\alpha p}+x^{\alpha p}} 	\leq\frac{1}{nx^{2\alpha p}}$$ and this is where i don't know how to proceed. From what I have read, $\frac{1}{nx^2}$ is unbounded. So I'm guessing that $\frac{1}{nx^{2\alpha p}}$ is unbounded. But it says that $2\alpha p<1$ , this must have something to do with $\frac{1}{nx^{2\alpha p}}$ . Do you have any ideas guys? I will really appreciate it.","Let , and with . For , Define by and that , . Show that converges to in , i.e., . What I tried: Proof. WTS that . Now, and this is where i don't know how to proceed. From what I have read, is unbounded. So I'm guessing that is unbounded. But it says that , this must have something to do with . Do you have any ideas guys? I will really appreciate it.","1\leq p\leq\infty \alpha\in\mathbb{R} I=(0,1] 2\alpha p<1 n\in\mathbb{N} f_{n}:I\to\mathbb{R} f_{n}\left(x\right)=\frac{n}{nx^{\alpha}+1} f\left(x\right)=\lim_{n\to\infty}f_{n}\left(x\right) x\in I \left\{ f_{n}\right\} _{n=1}^{\infty} f L^{p} \left|\left|f_{n}-f\right|\right|_{p}\to0 \lim_{n\to\infty}\int_{0}^{1}\left|f_{n}-f\right|^{p}=0 f\left(x\right)=\lim_{n\to\infty}f_{n}\left(x\right)=\lim_{n\to\infty}\frac{n}{nx^{\alpha}+1}=\frac{1}{x^{\alpha}}. \left|f_{n}-f\right|^{p}	=\left|\frac{n}{nx^{\alpha}+1}-\frac{1}{x^{\alpha}}\right|^{p}
	=\left|\frac{-1}{nx^{2\alpha}+x^{\alpha}}\right|^{p}
	\leq\frac{1}{nx^{2\alpha p}+x^{\alpha p}}
	\leq\frac{1}{nx^{2\alpha p}} \frac{1}{nx^2} \frac{1}{nx^{2\alpha p}} 2\alpha p<1 \frac{1}{nx^{2\alpha p}}","['real-analysis', 'measure-theory', 'convergence-divergence', 'lp-spaces']"
78,Continuity requirements for Lebesgue-Stieltjes measure (Question 114X(b) in D.H. Fremlin),Continuity requirements for Lebesgue-Stieltjes measure (Question 114X(b) in D.H. Fremlin),,"My question has to do with continuity requirements for functions used to define a Lebesge-Stieltjes measure on $\mathbb{R}$ .  In Fremlin's first volume of Measure Theory , the Lebesgue measure on $\mathbb{R}$ is defined by considering half-open intervals of the form $[a,b)=\{x:a\leq x<b\}$ . The length $\lambda I$ of a half-open interval $I$ is defined by setting $$\lambda\varnothing = 0,\quad \lambda[a,b)=b-a\text{ if }a<b.$$ From there, the Lebesgue outer-measure $\theta:2^\mathbb{R}\to[0,\infty]$ is defined in the usual way by setting \begin{align*} \theta A= \inf\bigg\{\sum_{j=0}^\infty \lambda I_j:\langle I_j\rangle_{j\in\mathbb{N}}\text{ is a sequence of half-open intervals} \\ \text{such that } A\subseteq\bigcup_{j\in\mathbb{N}} I_j\bigg\} \end{align*} for any $A\subseteq \mathbb{R}$ . (Above, half-open specifically means open on the right and closed on the left.) One of the exercises in the book replaces $\lambda$ in the above definition with $\lambda_g$ , where $g\colon\mathbb{R}\to\mathbb{R}$ is an arbitrary non-decreasing function and $$\lambda_g\varnothing = 0,\quad\lambda_g[a,b)=\lim_{x\to b^-}g(x)-\lim_{x\to a^-} g(x)\text{ if }a<b.$$ The corresponding outer measure is denoted $\theta_g$ in the textbook. A subsequent question asks what happens if we were to naively define $\lambda_g[a,b)=g(b)-g(a)$ . I understand that in the first case, we still have a legitimate outer measure whose collection of measurable sets contains all Borel sets. Is it true that the same holds for the second case as well? I couldn't find much that would change, except in the second case, we would no longer have $\lambda_g I=\theta_g I$ for any half-open interval $I$ . If this is true, and the naive definition still defines a legitimate outer measure on $\mathbb{R}$ , is there any context in which the naive definition is worth studying (even if $g$ is not left-hand continuous)?","My question has to do with continuity requirements for functions used to define a Lebesge-Stieltjes measure on .  In Fremlin's first volume of Measure Theory , the Lebesgue measure on is defined by considering half-open intervals of the form . The length of a half-open interval is defined by setting From there, the Lebesgue outer-measure is defined in the usual way by setting for any . (Above, half-open specifically means open on the right and closed on the left.) One of the exercises in the book replaces in the above definition with , where is an arbitrary non-decreasing function and The corresponding outer measure is denoted in the textbook. A subsequent question asks what happens if we were to naively define . I understand that in the first case, we still have a legitimate outer measure whose collection of measurable sets contains all Borel sets. Is it true that the same holds for the second case as well? I couldn't find much that would change, except in the second case, we would no longer have for any half-open interval . If this is true, and the naive definition still defines a legitimate outer measure on , is there any context in which the naive definition is worth studying (even if is not left-hand continuous)?","\mathbb{R} \mathbb{R} [a,b)=\{x:a\leq x<b\} \lambda I I \lambda\varnothing = 0,\quad \lambda[a,b)=b-a\text{ if }a<b. \theta:2^\mathbb{R}\to[0,\infty] \begin{align*}
\theta A= \inf\bigg\{\sum_{j=0}^\infty \lambda I_j:\langle I_j\rangle_{j\in\mathbb{N}}\text{ is a sequence of half-open intervals} \\ \text{such that } A\subseteq\bigcup_{j\in\mathbb{N}} I_j\bigg\}
\end{align*} A\subseteq \mathbb{R} \lambda \lambda_g g\colon\mathbb{R}\to\mathbb{R} \lambda_g\varnothing = 0,\quad\lambda_g[a,b)=\lim_{x\to b^-}g(x)-\lim_{x\to a^-} g(x)\text{ if }a<b. \theta_g \lambda_g[a,b)=g(b)-g(a) \lambda_g I=\theta_g I I \mathbb{R} g","['measure-theory', 'lebesgue-measure', 'outer-measure']"
79,Can every Borel set be written as a disjoint union of elements in the algebra of half open intervals?,Can every Borel set be written as a disjoint union of elements in the algebra of half open intervals?,,"We know that the algebra $\mathcal{A}$ of finite disjoint unions of intervals of the form $(a,b]$ for $a, b \in \mathbb{R}$ generates the Borel $\sigma$ -algebra $\mathcal{B}_{\mathbb{R}}$ . Is it true that every Borel set $A \in \mathcal{B}_{\mathbb{R}}$ can be written as a countable disjoint union of elements in $\mathcal{A}$ ?",We know that the algebra of finite disjoint unions of intervals of the form for generates the Borel -algebra . Is it true that every Borel set can be written as a countable disjoint union of elements in ?,"\mathcal{A} (a,b] a, b \in \mathbb{R} \sigma \mathcal{B}_{\mathbb{R}} A \in \mathcal{B}_{\mathbb{R}} \mathcal{A}","['real-analysis', 'measure-theory']"
80,"Showing ""directly"" that a fat Cantor set contains a non-measurable subset","Showing ""directly"" that a fat Cantor set contains a non-measurable subset",,"Let $L$ be the Volterra set made by removing the middle open interval of length $5^{-\nu}$ at each step. In the limit, this will yield a perfect compact set of positive Lebesgue measure, i.e. a ""fat Cantor set"" (per a previous homework). I'm the grader in a basic measure theory class, and I'm writing a solution set for a homework problem that says to show that the fat Cantor set $L$ has a nonmeasurable subset. I know that in general, it's the case that any subset of $\mathbb{R}$ with positive measure contains a nonmeasurable subset, and that this can be shown through Steinhaus's Theorem, or at least I've seen it called that. My question in whether this could be done in this particular setting without reference to Steinhaus's Theorem, and without too much machinery. The text covers the ""construction"" of the Vitali set, but does nothing else with nonmeasurable sets until this problem. If there's a solution that doesn't stray too far from what the text has already covered, I wanna use that rather than the (in my opinion not at all intuitive) Steinhaus's Theorem. I have two thoughts for possible solutions. One thought was to devise a measure space equivalence between $L$ (equipped with a normalized measure) and an interval in $\mathbb{R}$ by factoring through $\{ 0 , 1 \}^{\mathbb{N}}$ , pulling a Vitali set back through this mapping to a nonmeasurable subset of $L$ , and then trying to rephrase all of this without the language of measure space isomorphism. I know this would be possible, but I feel like it'd take a lot of writing and it might not really be clear what's happening. Another thought I had was to just build a Vitali set contained entirely in $L$ , but I know that's not possible, since it'd imply that $\bigcup_{q \in \mathbb{Q}} (K + q) = \mathbb{R}$ , which I don't think should be possible if $K$ is nowhere-dense, since that'd mean $\mathbb{R}$ is a countable union of nowhere-dense sets. It's also possible that there's some other way of showing $L$ contains a non-measurable subset that's much simpler or intuitive than what I've considered. If so, I don't know what it'd be. Is there a more intuitive solution that I haven't considered here? Thanks in advance.","Let be the Volterra set made by removing the middle open interval of length at each step. In the limit, this will yield a perfect compact set of positive Lebesgue measure, i.e. a ""fat Cantor set"" (per a previous homework). I'm the grader in a basic measure theory class, and I'm writing a solution set for a homework problem that says to show that the fat Cantor set has a nonmeasurable subset. I know that in general, it's the case that any subset of with positive measure contains a nonmeasurable subset, and that this can be shown through Steinhaus's Theorem, or at least I've seen it called that. My question in whether this could be done in this particular setting without reference to Steinhaus's Theorem, and without too much machinery. The text covers the ""construction"" of the Vitali set, but does nothing else with nonmeasurable sets until this problem. If there's a solution that doesn't stray too far from what the text has already covered, I wanna use that rather than the (in my opinion not at all intuitive) Steinhaus's Theorem. I have two thoughts for possible solutions. One thought was to devise a measure space equivalence between (equipped with a normalized measure) and an interval in by factoring through , pulling a Vitali set back through this mapping to a nonmeasurable subset of , and then trying to rephrase all of this without the language of measure space isomorphism. I know this would be possible, but I feel like it'd take a lot of writing and it might not really be clear what's happening. Another thought I had was to just build a Vitali set contained entirely in , but I know that's not possible, since it'd imply that , which I don't think should be possible if is nowhere-dense, since that'd mean is a countable union of nowhere-dense sets. It's also possible that there's some other way of showing contains a non-measurable subset that's much simpler or intuitive than what I've considered. If so, I don't know what it'd be. Is there a more intuitive solution that I haven't considered here? Thanks in advance.","L 5^{-\nu} L \mathbb{R} L \mathbb{R} \{ 0 , 1 \}^{\mathbb{N}} L L \bigcup_{q \in \mathbb{Q}} (K + q) = \mathbb{R} K \mathbb{R} L","['real-analysis', 'measure-theory', 'lebesgue-measure', 'cantor-set', 'measurable-sets']"
81,Question from Exercise $1.8$ in Karatzas and Shreve. Representation of a filtration.,Question from Exercise  in Karatzas and Shreve. Representation of a filtration.,1.8,"This is Exercise $1.8$ from Karatzas and Shreve. Let $X$ be a process whose sample paths are RCLL a.s., and let $A$ be the event that $X$ is continuous on $[0,t_0)$ . Show that $A$ can fail to be in $\mathscr{F}^X_{t_0}$ . This is part of the solution given in the text. We first construct an example with $A \notin \mathscr{F}_{t_0}^X$ . The collection of sets of the form $\{(X_{t_1},X_{t_2},\dots)\in B\}$ , where $ B \in \mathscr{B}(\mathbb{R}^d) \otimes \mathscr{B}(\mathbb{R}^d) \otimes \cdots $ and $0\le t_1 < t_2 < \cdots \le t_0,$ forms a $\sigma$ -field and each such set is in $\mathscr{F}_{t_0}^X$ . Indeed, every set in $\mathscr{F}_{t_0}^X$ has such a representation. Choose $\Omega = [0,2), \mathscr{F}= \mathscr{B}([0,2))$ , and $P(F) = \operatorname{meas}(F \cap [0,1]);$ $F \in \mathscr{F}$ , where meas stands for ""Lebesgue measure."" For $\omega \in [0,1]$ , define $X_t(\omega)=0,$ $\forall t \ge 0;$ for $\omega \in (1,2),$ define $X_t(\omega)=0$ if $t \neq \omega$ , $X_\omega(\omega)=1$ . Choose $t_0=2.$ If $A \in \mathscr{F}_{t_0}^X$ , then for some $B \in \mathscr{B}(\mathbb{R}^d) \otimes \mathscr{B}(\mathbb{R}^d) \otimes \cdots $ and some sequence $t_k \in [0,2]$ , we have $A = \{(X_{t_1},X_{t_2},\dots)\in B\}.$ Choose $\bar{t} \in (1,2)$ , $\bar{t} \notin \{t_1, t_2, \dots\}.$ Since $\omega = \bar{t} $ is not in $A$ and $X_{t_k}(\bar{t})=0, k=1,2, \dots, $ we see that $(0,0,\dots) \notin B$ . But $X_{t_k}(\omega)=0,$ $k=1,2, \dots,$ for all $\omega \in [0,1]$ ; we conclude that $[0,1] \cap A = \phi$ , which contradicts the definition of $A$ and the construction of $X$ . I am not convinced by the bolded statement. How do we show that every set in a filtration is of the given form?","This is Exercise from Karatzas and Shreve. Let be a process whose sample paths are RCLL a.s., and let be the event that is continuous on . Show that can fail to be in . This is part of the solution given in the text. We first construct an example with . The collection of sets of the form , where and forms a -field and each such set is in . Indeed, every set in has such a representation. Choose , and , where meas stands for ""Lebesgue measure."" For , define for define if , . Choose If , then for some and some sequence , we have Choose , Since is not in and we see that . But for all ; we conclude that , which contradicts the definition of and the construction of . I am not convinced by the bolded statement. How do we show that every set in a filtration is of the given form?","1.8 X A X [0,t_0) A \mathscr{F}^X_{t_0} A \notin \mathscr{F}_{t_0}^X \{(X_{t_1},X_{t_2},\dots)\in B\}  B \in \mathscr{B}(\mathbb{R}^d) \otimes \mathscr{B}(\mathbb{R}^d) \otimes \cdots  0\le t_1 < t_2 < \cdots \le t_0, \sigma \mathscr{F}_{t_0}^X \mathscr{F}_{t_0}^X \Omega = [0,2), \mathscr{F}= \mathscr{B}([0,2)) P(F) = \operatorname{meas}(F \cap [0,1]); F \in \mathscr{F} \omega \in [0,1] X_t(\omega)=0, \forall t \ge 0; \omega \in (1,2), X_t(\omega)=0 t \neq \omega X_\omega(\omega)=1 t_0=2. A \in \mathscr{F}_{t_0}^X B \in \mathscr{B}(\mathbb{R}^d) \otimes \mathscr{B}(\mathbb{R}^d) \otimes \cdots  t_k \in [0,2] A = \{(X_{t_1},X_{t_2},\dots)\in B\}. \bar{t} \in (1,2) \bar{t} \notin \{t_1, t_2, \dots\}. \omega = \bar{t}  A X_{t_k}(\bar{t})=0, k=1,2, \dots,  (0,0,\dots) \notin B X_{t_k}(\omega)=0, k=1,2, \dots, \omega \in [0,1] [0,1] \cap A = \phi A X","['real-analysis', 'measure-theory', 'stochastic-processes', 'stochastic-calculus']"
82,Measurable function with parameters,Measurable function with parameters,,"Let $\mu_{y}$ a Borel probability on $\mathbb{R}^{n}$ indexed by a parameter $y \in \mathbb{R}^{d}$ . Let $A$ a borel set of $\mathbb{R}^{n}$ and suppose that the map $$ F \text{ : } y \rightarrow \mu_{y}(A) $$ is measurable (we equiped $\mathbb{R}$ with the borel algebra). Let $T_{y} \text{ : } \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}$ a family of measurable functions indexed by a parameter $y \in \mathbb{R}^{d}$ . My question is : Is the map $$ y \rightarrow \mu_{y}( T_{y} \in A) $$ measurable ? Thanks and regards. EDIT : We can suppose that $(x,y) \rightarrow T_{y}(x)$ is measurable if it helps. Maybe without this assumption we can say anything.",Let a Borel probability on indexed by a parameter . Let a borel set of and suppose that the map is measurable (we equiped with the borel algebra). Let a family of measurable functions indexed by a parameter . My question is : Is the map measurable ? Thanks and regards. EDIT : We can suppose that is measurable if it helps. Maybe without this assumption we can say anything.,"\mu_{y} \mathbb{R}^{n} y \in \mathbb{R}^{d} A \mathbb{R}^{n} 
F \text{ : } y \rightarrow \mu_{y}(A)
 \mathbb{R} T_{y} \text{ : } \mathbb{R}^{n} \rightarrow \mathbb{R}^{n} y \in \mathbb{R}^{d}  y \rightarrow \mu_{y}( T_{y} \in A)  (x,y) \rightarrow T_{y}(x)","['measure-theory', 'lebesgue-measure']"
83,"Given measurable sets $E_k$, find a measurable set $A$ with $0<\mu(E_k\cap A)<\mu(E_k)$","Given measurable sets , find a measurable set  with",E_k A 0<\mu(E_k\cap A)<\mu(E_k),"Let $\mu$ be the Lebesgue measure on $\mathbb{R}^n$ and $E_k\subseteq\mathbb{R}^n,k\in\mathbb{N}$ be measurable sets each having positive Lebesgue measure. How to find a measurable set $A\subseteq\mathbb{R}^n$ so that $0<\mu(E_k\cap A)<\mu(E_k)$ for every $k\in\mathbb{N}$ ?",Let be the Lebesgue measure on and be measurable sets each having positive Lebesgue measure. How to find a measurable set so that for every ?,"\mu \mathbb{R}^n E_k\subseteq\mathbb{R}^n,k\in\mathbb{N} A\subseteq\mathbb{R}^n 0<\mu(E_k\cap A)<\mu(E_k) k\in\mathbb{N}","['measure-theory', 'lebesgue-measure']"
84,Convolution $f*g(x)$ is continuous if $f \in L^1(\mathbb{R}^n)$ and $g \in L^\infty(\mathbb{R}^n)$,Convolution  is continuous if  and,f*g(x) f \in L^1(\mathbb{R}^n) g \in L^\infty(\mathbb{R}^n),"I am stuck in what I believe to be the last part of this problem. If $f \in L^1(\mathbb{R}^n)$ and $g \in L^\infty(\mathbb{R}^n)$ , then $f*g(x):=\int_{\mathbb{R}^n} f(x-y)g(y) \mathrm{d}y$ (Throughout this problem, we integrate with respect to $\mathbb{R}^n$ and the Lebesgue measure) Since $g \in L^\infty(\mathbb{R}^n)$ , then there exists a real number $M$ , such that $g \leq M \ \text{a.e.}$ Therefore, for $x, x_0 \in \mathbb{R}^n$ $$|f*g(x) - f*g(x_0)| = \left| \int f(x-y)g(y) \mathrm{d}y - \int f(x_0-y)g(y)\mathrm{d}y \right|$$ $$\leq M \left| \int \left( f(x-y)-f(x_0-y) \right) \mathrm{d}y \right|$$ and this is finite since $f \in L^1(\mathbb{R}^n)$ But, since we are not making any assumptions about the continuity of $f$ , I am stuck.","I am stuck in what I believe to be the last part of this problem. If and , then (Throughout this problem, we integrate with respect to and the Lebesgue measure) Since , then there exists a real number , such that Therefore, for and this is finite since But, since we are not making any assumptions about the continuity of , I am stuck.","f \in L^1(\mathbb{R}^n) g \in L^\infty(\mathbb{R}^n) f*g(x):=\int_{\mathbb{R}^n} f(x-y)g(y) \mathrm{d}y \mathbb{R}^n g \in L^\infty(\mathbb{R}^n) M g \leq M \ \text{a.e.} x, x_0 \in \mathbb{R}^n |f*g(x) - f*g(x_0)| = \left| \int f(x-y)g(y) \mathrm{d}y - \int f(x_0-y)g(y)\mathrm{d}y \right| \leq M \left| \int \left( f(x-y)-f(x_0-y) \right) \mathrm{d}y \right| f \in L^1(\mathbb{R}^n) f","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'convolution']"
85,Class of absolutely continuous probability measures is $G_\delta$,Class of absolutely continuous probability measures is,G_\delta,"Consider a Polish metric space $(X,d)$ and the class of Borel probability measures on it, endowed with the usual topology of weak convergence of measures, say $(\mathcal{P},\tau_W)$ . Then, it is well known that $(\mathcal{P},\tau_W)$ is separable and completely metrizable - e.g. via the Léevy-Prohorov metric, see https://en.wikipedia.org/wiki/Lévy –Prokhorov_metric For simplicity, let $X$ be a subset of an Euclidean space and denote by $\mathcal{P}_0\subset\mathcal{P}$ the subset of probability measures which are absolutely continuous with respect to the Lebesgue measure. Clearly, $\mathcal{P}_0$ is not closed, for a sequence of absolutely continuous measures can converge to a point mass. Is $\mathcal{P}_0$ a $G_\delta$ set in $(\mathcal{P},\tau_W)$ ? ADDENDUM: Let $\nu$ be the Lebesgue measure on $X$ and define $$ \Delta=\{f \in L_1(\nu):\, \int_Xf d\nu=1,\, f \geq  0 \,a.e.\}. $$ Then, in a 1989 paper, https://www.jstor.org/stable/pdf/4616132.pdf?refreqid=excelsior%3A4ad9120f5b9af9f4af6aa1c012f5b44a Gaudard and Hadwin argued that $\Delta$ is a closed subset of $L_1(\nu)$ (in fact, a Standard Borel subspace) and that the map $\Phi:\Delta\mapsto\mathcal{P} $ defined via $$ [\Phi(f)](D)=\int_Df d\nu, \quad \text{for all } D \text{ Borel subset of }X, $$ is $1-\text{to}-1$ and continuous. In particular, $\Phi$ is an isomorphism of $\Delta$ into $\Phi(\Delta)=\mathcal{P}_0$ . Is this of any help? Of course, the above arguments entail that $\mathcal{P}_0$ is a Borel subset of $(\mathcal{P},\tau_W)$ , but this, per se, does not guarantee that $\mathcal{P}_0$ is also $G_\delta$ .","Consider a Polish metric space and the class of Borel probability measures on it, endowed with the usual topology of weak convergence of measures, say . Then, it is well known that is separable and completely metrizable - e.g. via the Léevy-Prohorov metric, see https://en.wikipedia.org/wiki/Lévy –Prokhorov_metric For simplicity, let be a subset of an Euclidean space and denote by the subset of probability measures which are absolutely continuous with respect to the Lebesgue measure. Clearly, is not closed, for a sequence of absolutely continuous measures can converge to a point mass. Is a set in ? ADDENDUM: Let be the Lebesgue measure on and define Then, in a 1989 paper, https://www.jstor.org/stable/pdf/4616132.pdf?refreqid=excelsior%3A4ad9120f5b9af9f4af6aa1c012f5b44a Gaudard and Hadwin argued that is a closed subset of (in fact, a Standard Borel subspace) and that the map defined via is and continuous. In particular, is an isomorphism of into . Is this of any help? Of course, the above arguments entail that is a Borel subset of , but this, per se, does not guarantee that is also .","(X,d) (\mathcal{P},\tau_W) (\mathcal{P},\tau_W) X \mathcal{P}_0\subset\mathcal{P} \mathcal{P}_0 \mathcal{P}_0 G_\delta (\mathcal{P},\tau_W) \nu X 
\Delta=\{f \in L_1(\nu):\, \int_Xf d\nu=1,\, f \geq  0 \,a.e.\}.
 \Delta L_1(\nu) \Phi:\Delta\mapsto\mathcal{P}  
[\Phi(f)](D)=\int_Df d\nu, \quad \text{for all } D \text{ Borel subset of }X,
 1-\text{to}-1 \Phi \Delta \Phi(\Delta)=\mathcal{P}_0 \mathcal{P}_0 (\mathcal{P},\tau_W) \mathcal{P}_0 G_\delta","['measure-theory', 'lebesgue-measure', 'absolute-continuity', 'polish-spaces']"
86,show that there exists $f$ s.t. $\int_E(1-f)d\mu=\int_Efd\nu$,show that there exists  s.t.,f \int_E(1-f)d\mu=\int_Efd\nu,"Let $\mu$ and $\nu$ be finite measures on a measure space $(X,\mathcal{A})$ . Show that there is a nonnegative measurable function $f$ on $X$ such that for all $E \in \mathcal{A}$ , $$\int_E(1-f)d\mu=\int_Efd\nu$$ I have no clue how to show the above: I started using below but I stuck $$\mu(E)=\int_Efd\nu + \int_Efd\mu = \int_Efd(\nu+\mu)$$ defining $\psi=\nu+\mu$ , I have to show that $\mu\ll\psi$ ?","Let and be finite measures on a measure space . Show that there is a nonnegative measurable function on such that for all , I have no clue how to show the above: I started using below but I stuck defining , I have to show that ?","\mu \nu (X,\mathcal{A}) f X E \in \mathcal{A} \int_E(1-f)d\mu=\int_Efd\nu \mu(E)=\int_Efd\nu + \int_Efd\mu = \int_Efd(\nu+\mu) \psi=\nu+\mu \mu\ll\psi","['real-analysis', 'measure-theory', 'radon-nikodym']"
87,Show that the collection of subsets $A\subset\mathbb{Z}$ such that $A$ or $A^{c}$ is finite form an algebra but is not a $\sigma$-algebra,Show that the collection of subsets  such that  or  is finite form an algebra but is not a -algebra,A\subset\mathbb{Z} A A^{c} \sigma,"I am reviewing probability theory for my final exams in 7-9 weeks, and I am reading Durrett in detail. Then, in measure theory part, Example 1.1.6, he provides an example showing an algebra is not necessarily a $\sigma$ -algebra, as follows Let $\Omega=\mathbb{Z}$ , and $\mathcal{A}$ = the collection of $A\subset\mathbb{Z}$ so that $A$ or $A^{c}$ is finite. A related post is here . Firstly, I wanted to show that $\mathcal{A}$ is an algebra, but I got stuck in the end. Let $A\in\mathcal{A}$ , then if $A$ is finite, $(A^{c})^{c}$ is finite which implies that $A^{c}\in\mathcal{A}$ , if $A^{c}$ is finite, then $A^{c}\in\mathcal{A}$ immediately. For $A,B\in \mathcal{A}$ , if $A, B$ finite, then $A\cup B$ is finite so $A\cup B\in\mathcal{A}$ , if $A^{c}$ and $B^{c}$ are finite, then $(A\cup B)^{c}=A^{c}\cap B^{c}$ is finite, so $(A\cup B)\in\mathcal{A}$ . But I don't know how to show the case if $A$ is finite but $B^{c}$ is finite (or vice versa). How could I express $A\cup B$ as something with $A$ and $B^{c}$ ? To show it is not a $\sigma$ -algebra, consider the collection $\{A_{k}\}_{k=1}^{\infty}$ , where $A_{k}:=\{2k\}$ , which is a countable collection of subsets in $\mathcal{A}$ , since each $A_{k}$ is finite. Then, $B:=\bigcup_{k=1}^{\infty}A_{k}$ is countably infinite, but $B^{c}$ includes all the odd numbers which is also infinite. Thus, $B\notin\mathcal{A}$ , and thus $\mathcal{A}$ is not closed under countable union. Is my proof right? Thank you!","I am reviewing probability theory for my final exams in 7-9 weeks, and I am reading Durrett in detail. Then, in measure theory part, Example 1.1.6, he provides an example showing an algebra is not necessarily a -algebra, as follows Let , and = the collection of so that or is finite. A related post is here . Firstly, I wanted to show that is an algebra, but I got stuck in the end. Let , then if is finite, is finite which implies that , if is finite, then immediately. For , if finite, then is finite so , if and are finite, then is finite, so . But I don't know how to show the case if is finite but is finite (or vice versa). How could I express as something with and ? To show it is not a -algebra, consider the collection , where , which is a countable collection of subsets in , since each is finite. Then, is countably infinite, but includes all the odd numbers which is also infinite. Thus, , and thus is not closed under countable union. Is my proof right? Thank you!","\sigma \Omega=\mathbb{Z} \mathcal{A} A\subset\mathbb{Z} A A^{c} \mathcal{A} A\in\mathcal{A} A (A^{c})^{c} A^{c}\in\mathcal{A} A^{c} A^{c}\in\mathcal{A} A,B\in \mathcal{A} A, B A\cup B A\cup B\in\mathcal{A} A^{c} B^{c} (A\cup B)^{c}=A^{c}\cap B^{c} (A\cup B)\in\mathcal{A} A B^{c} A\cup B A B^{c} \sigma \{A_{k}\}_{k=1}^{\infty} A_{k}:=\{2k\} \mathcal{A} A_{k} B:=\bigcup_{k=1}^{\infty}A_{k} B^{c} B\notin\mathcal{A} \mathcal{A}","['measure-theory', 'proof-verification']"
88,Proving a possible corollary of the monotone convergence theorem,Proving a possible corollary of the monotone convergence theorem,,"Let $\{f_n\}$ be a sequence of nonnegative measurable functions on $E$ that converges point wise on $E$ to $f$ . Suppose $f_n \leq f$ for each $n$ . Show that: $$\lim_{n \rightarrow \infty} \int_E f_n = \int_E f.$$ So, I've already proved the monotone convergence theorem, the assumption of which is the same as what I'm trying to prove except for in the monotone convergence theorem the sequences of functions is increasing. I feel like there must be some clever trick to use the convergence theorem to prove this one... I've been thinking about it for awhile but I fear I'm stuck in tunnel vision. Insights appreciated!! Thanks!","Let be a sequence of nonnegative measurable functions on that converges point wise on to . Suppose for each . Show that: So, I've already proved the monotone convergence theorem, the assumption of which is the same as what I'm trying to prove except for in the monotone convergence theorem the sequences of functions is increasing. I feel like there must be some clever trick to use the convergence theorem to prove this one... I've been thinking about it for awhile but I fear I'm stuck in tunnel vision. Insights appreciated!! Thanks!",\{f_n\} E E f f_n \leq f n \lim_{n \rightarrow \infty} \int_E f_n = \int_E f.,['real-analysis']
89,"In Lebesgue world, is there $f=g$?","In Lebesgue world, is there ?",f=g,"As we develop the theory of Lebesgue integration, it seems every function being equal is no longer the equality in the Riemann world. The notion of ""almost everywhere"" seems to basically replace the notion of equalit between two real-valued functions. Is this correct? In other words, when you compare two real-valued functions defined on $E\subset\mathbb{R}^d$ , you always compare their equality including all negligible set. Hence the birth of the notion of equal almost everywhere. Is this a correct interpretation? So, there is no true equality in the Lebesgue world then?","As we develop the theory of Lebesgue integration, it seems every function being equal is no longer the equality in the Riemann world. The notion of ""almost everywhere"" seems to basically replace the notion of equalit between two real-valued functions. Is this correct? In other words, when you compare two real-valued functions defined on , you always compare their equality including all negligible set. Hence the birth of the notion of equal almost everywhere. Is this a correct interpretation? So, there is no true equality in the Lebesgue world then?",E\subset\mathbb{R}^d,"['real-analysis', 'measure-theory']"
90,Proof check for condition on being measurable,Proof check for condition on being measurable,,"I was wondering if the following proof works to prove the following statement: Prove the following are equivalent for $E \subseteq \mathbb{R}$ , where $m$ denotes the Lebesgue outer measure. (i) $E$ is measurable (definition taken to be satisfying the Caratheodory criterion). (ii) $m(B) = m(B \cap E) + m(B \cap E^c)$ for all Borel sets $B$ . (iii) $m(U) = m(U \cap E) + m(U \cap E^c)$ for all open sets $U$ . Proof: (i) $\Rightarrow$ (ii), (i) $\Rightarrow$ (iii), (ii) $\Rightarrow$ (iii) are all trivial. (iii) $\Rightarrow$ (ii) follows from the fact that the $\sigma$ -algebra generated by the open sets is equal to the Borel algebra. To see (iii) $\Rightarrow$ (i), cover $A$ by open intervals $I_k$ such that $m(A) + \epsilon \geq \sum_k I_k $ , then we have: $$ m(A) + \epsilon \geq m(\cup_k I_k) = m(\cup_k I_k \cap E) + m(\cup_k I_k \cap E^c) $$ by our hypothesis, but then since $A \subseteq \cup_k I_k$ we have that $m(\cup_k I_k \cap E) \geq m(A \cap E)$ and likewise for $E^c$ by monotonicity, thus giving: $$ m(A) + \epsilon \geq m(A \cap E) + m(A \cap E^c) $$ Letting $\epsilon \rightarrow 0$ thus gives the inequality and hence the result (reverse inequality trivially follows from countable sub-additivity). This completes the proof. I'm fairly new to measure theory so any feedback, corrections or help would be greatly appreciated!","I was wondering if the following proof works to prove the following statement: Prove the following are equivalent for , where denotes the Lebesgue outer measure. (i) is measurable (definition taken to be satisfying the Caratheodory criterion). (ii) for all Borel sets . (iii) for all open sets . Proof: (i) (ii), (i) (iii), (ii) (iii) are all trivial. (iii) (ii) follows from the fact that the -algebra generated by the open sets is equal to the Borel algebra. To see (iii) (i), cover by open intervals such that , then we have: by our hypothesis, but then since we have that and likewise for by monotonicity, thus giving: Letting thus gives the inequality and hence the result (reverse inequality trivially follows from countable sub-additivity). This completes the proof. I'm fairly new to measure theory so any feedback, corrections or help would be greatly appreciated!","E \subseteq \mathbb{R} m E m(B) = m(B \cap E) + m(B \cap E^c) B m(U) = m(U \cap E) + m(U \cap E^c) U \Rightarrow \Rightarrow \Rightarrow \Rightarrow \sigma \Rightarrow A I_k m(A) + \epsilon \geq \sum_k I_k  
m(A) + \epsilon \geq m(\cup_k I_k) = m(\cup_k I_k \cap E) + m(\cup_k I_k \cap E^c)
 A \subseteq \cup_k I_k m(\cup_k I_k \cap E) \geq m(A \cap E) E^c 
m(A) + \epsilon \geq m(A \cap E) + m(A \cap E^c)
 \epsilon \rightarrow 0","['real-analysis', 'measure-theory']"
91,Uniqueness of minimal $\infty$-norm polynomial,Uniqueness of minimal -norm polynomial,\infty,"From this proof it is clear to me that Chebyshev polynomial $\frac{1}{2^{n-1}} T_n(x)$ is minimum $\infty$ -norm in $[-1,1]$ among the monic polynomials of degree $n$ . How to prove the uniqueness (if true) of such minimizing polynomial? I found this question , but the answer is not completely related. I have no idea to start.","From this proof it is clear to me that Chebyshev polynomial is minimum -norm in among the monic polynomials of degree . How to prove the uniqueness (if true) of such minimizing polynomial? I found this question , but the answer is not completely related. I have no idea to start.","\frac{1}{2^{n-1}} T_n(x) \infty [-1,1] n","['measure-theory', 'polynomials', 'chebyshev-polynomials']"
92,"Help, A clearer picture of a messy proof on generated algebras.","Help, A clearer picture of a messy proof on generated algebras.",,"I am trying to self learn from a MIT-OCW course  on measure theoretic probability: this resource . However, one of their homework problems turns out to be very messy even in the solution provided (which is probably why it is optional). In their homework assignment 2 , question 7 the following shows up in their proof:  The very first part is where I have trouble, For a collection $C$ and a space $Ω$ let $α_Ω (C)$ denote the smallest algebra of sets in $Ω$ containing $C$ . Here $Ω_1 \subset Ω$ Claim: $α_{Ω_1} (C ∩ Ω_1) = α_Ω(C) ∩ Ω_1$ . I understand the intent to show the 2  are equal, by showing they are contained in one another but in doing so they arrive at the following step:  let $E∩Ω_1 ∈ α_Ω (C)∩Ω_1$ , then $$ (E ∩ Ω_1)^c=  Ω_1 -(E ∩ Ω_1 ) =  E^c ∩ Ω_1 ∈ α_Ω (C) ∩ Ω_1\text{, as } E ∈ α_Ω (C) $$ and $ α_Ω(C)$ is an algebra. As I understand , $(E ∩ Ω_1)^c$ = $ Ω_1 -(E ∩ Ω_1 )$ can only happen when $E \subset Ω_1$ holds, but this is not the general case. I am stuck here and cannot process rest of the proof, now I have spent 2 days trying to convince myself that the steps are right. Can someone provide some clarity? The proof is actually very badly written, with an attempt to squeeze in some general theorem about algebras and their intersection.","I am trying to self learn from a MIT-OCW course  on measure theoretic probability: this resource . However, one of their homework problems turns out to be very messy even in the solution provided (which is probably why it is optional). In their homework assignment 2 , question 7 the following shows up in their proof:  The very first part is where I have trouble, For a collection and a space let denote the smallest algebra of sets in containing . Here Claim: . I understand the intent to show the 2  are equal, by showing they are contained in one another but in doing so they arrive at the following step:  let , then and is an algebra. As I understand , = can only happen when holds, but this is not the general case. I am stuck here and cannot process rest of the proof, now I have spent 2 days trying to convince myself that the steps are right. Can someone provide some clarity? The proof is actually very badly written, with an attempt to squeeze in some general theorem about algebras and their intersection.","C Ω α_Ω (C) Ω C Ω_1 \subset Ω α_{Ω_1} (C ∩ Ω_1) = α_Ω(C) ∩ Ω_1 E∩Ω_1 ∈ α_Ω (C)∩Ω_1 
(E ∩ Ω_1)^c=  Ω_1 -(E ∩ Ω_1 ) =  E^c ∩ Ω_1 ∈ α_Ω (C) ∩ Ω_1\text{, as } E ∈ α_Ω (C)
  α_Ω(C) (E ∩ Ω_1)^c  Ω_1 -(E ∩ Ω_1 ) E \subset Ω_1","['measure-theory', 'proof-explanation', 'algebras']"
93,Can we approximate elements in $L^2$ via smooth maps while preserving a pointwise constraint on the derivatives?,Can we approximate elements in  via smooth maps while preserving a pointwise constraint on the derivatives?,L^2,"Let $\mathbb{D}^n \subseteq \mathbb{R}^n$ be the closed $n$ -dimensional unit ball. Suppose we are given an open connected* subset $U \subseteq \mathbb{D}^n$ of full measure in $\mathbb{D}^n$ , and a smooth bounded map $f:U \to \mathbb{R}^{k}$ , where $k>1$ . Note that $f \in L^2(\mathbb{D}^n, \mathbb{R}^{k})$ . Now, let $h:\mathbb{D}^n \to \mathbb{R}^{k}$ be a smooth map satisfying $h(x) \neq 0$ for every $x \in U$ (in particular $h(x) \neq 0$ a.e.). Assume that $ (df_x)^T\big(h(x)\big)=0$ for every $x \in U$ . Do there exist smooth maps $f_k:\mathbb{D}^n \to \mathbb{R}^{k}$ which converge to $f$ in $L^2$ and satisfy $ ((df_k)_x)^T\big(h(x)\big)=0$ ? Note that the derivatives of the original $f$ may explode when we approach $\partial U=\mathbb{D}^n \setminus U$ . I also don't assume that $f$ can be continuously extended to all of $\mathbb{D}^n$ or that it is a Sobolev map. Edit: Why $U$ must be connected in general: Take $h(x)=(1,0,...,0)$ to be constant. The condition $(df_x)^T\big(h(x)\big)=0$ is equivalent to $$ \langle\partial_j f(x),h(x)\rangle=\partial_jf^1(x)=0 \,\,\quad \forall j=1,...,n\quad\forall x \in U, $$ i.e. $\nabla f^1=0$ on $U$ . If $U$ is not connected, we can make $f^1$ to obtain two different constant values on different connected components of $U$ . Now, any smooth map $g:\mathbb{D}^n \to \mathbb{R}^{k}$ that satisfies $ (dg_x)^T\big(h(x)\big)=0$ on $\mathbb{D}^n$ must have constant first component, hence cannot approximate well our map $f$ . I guess a reasonable start would be to start with $h$ being constant: Suppose that $h(x)=(h^1,h^2,...,h^k)$ . Then our condition becomes $$ \langle\partial_j f(x),h(x)\rangle=\partial_j(\sum_{i=1}^k h^if^i)=0 \,\,\quad \forall j=1,...,n\quad\forall x \in U, $$ i.e. $\nabla (\sum_{i=1}^k h^if^i)=0$ on $U$ . Since $U$ is connected, this implies that $\sum_{i=1}^k h^if^i$ is constant. Now, the question is whether or not $f$ can be approximated by smooth maps $f_k$ with constant $\sum_{i=1}^k h^if_k^i$ .","Let be the closed -dimensional unit ball. Suppose we are given an open connected* subset of full measure in , and a smooth bounded map , where . Note that . Now, let be a smooth map satisfying for every (in particular a.e.). Assume that for every . Do there exist smooth maps which converge to in and satisfy ? Note that the derivatives of the original may explode when we approach . I also don't assume that can be continuously extended to all of or that it is a Sobolev map. Edit: Why must be connected in general: Take to be constant. The condition is equivalent to i.e. on . If is not connected, we can make to obtain two different constant values on different connected components of . Now, any smooth map that satisfies on must have constant first component, hence cannot approximate well our map . I guess a reasonable start would be to start with being constant: Suppose that . Then our condition becomes i.e. on . Since is connected, this implies that is constant. Now, the question is whether or not can be approximated by smooth maps with constant .","\mathbb{D}^n \subseteq \mathbb{R}^n n U \subseteq \mathbb{D}^n \mathbb{D}^n f:U \to \mathbb{R}^{k} k>1 f \in L^2(\mathbb{D}^n, \mathbb{R}^{k}) h:\mathbb{D}^n \to \mathbb{R}^{k} h(x) \neq 0 x \in U h(x) \neq 0  (df_x)^T\big(h(x)\big)=0 x \in U f_k:\mathbb{D}^n \to \mathbb{R}^{k} f L^2  ((df_k)_x)^T\big(h(x)\big)=0 f \partial U=\mathbb{D}^n \setminus U f \mathbb{D}^n U h(x)=(1,0,...,0) (df_x)^T\big(h(x)\big)=0  \langle\partial_j f(x),h(x)\rangle=\partial_jf^1(x)=0 \,\,\quad \forall j=1,...,n\quad\forall x \in U,  \nabla f^1=0 U U f^1 U g:\mathbb{D}^n \to \mathbb{R}^{k}  (dg_x)^T\big(h(x)\big)=0 \mathbb{D}^n f h h(x)=(h^1,h^2,...,h^k)  \langle\partial_j f(x),h(x)\rangle=\partial_j(\sum_{i=1}^k h^if^i)=0 \,\,\quad \forall j=1,...,n\quad\forall x \in U,  \nabla (\sum_{i=1}^k h^if^i)=0 U U \sum_{i=1}^k h^if^i f f_k \sum_{i=1}^k h^if_k^i","['real-analysis', 'measure-theory', 'lp-spaces', 'approximation-theory', 'geometric-measure-theory']"
94,Does $\int_{\mathbb R}x^2f_X(x)dx=\int_{\mathbb R}x^2f_X(x)^2dx$ or are they comparable?,Does  or are they comparable?,\int_{\mathbb R}x^2f_X(x)dx=\int_{\mathbb R}x^2f_X(x)^2dx,"Let $f_X$ a density function, i.e. $\mu(dx)=f_X(x)dx$ is an absolute continuous measure w.r.t. Lebesgue measure. We have that $$\int_{\mathbb R}x\mu(dx)=\int_\mathbb R xf_X(x)dx.$$ Using Jensen inequality, $$\left(\int_{\mathbb R}xf_X(x)dx\right)^2\leq \int_{\mathbb R}x^2f_X(x)^2dx$$ and $$\left(\int_{\mathbb R}x\mu(dx)\right)^2\leq \int_{\mathbb R}x^2\mu(dx)=\int_{\mathbb R}x^2f_X(x)dx.$$ In somehow, we have the same integral, but not the same upperbound. Does $$\int_{\mathbb R}x^2f_X(x)dx=\int_{\mathbb R}x^2f_X(x)^2dx\ \ ?$$ Or at least, are they comparable ? ( like, does $$\int_{\mathbb R}x^2f_X(x)dx\leq\int_{\mathbb R}x^2f_X(x)^2dx\quad \text{or}\quad \int_{\mathbb R}x^2f_X(x)dx\geq\int_{\mathbb R}x^2f_X(x)^2dx$$ hold ? May be my question has no sense, but I'm quite surprise that we have 2 differents ""optimal"" upperbound for the same integral. (by optimal, I mean that in some case, we can have equality).","Let a density function, i.e. is an absolute continuous measure w.r.t. Lebesgue measure. We have that Using Jensen inequality, and In somehow, we have the same integral, but not the same upperbound. Does Or at least, are they comparable ? ( like, does hold ? May be my question has no sense, but I'm quite surprise that we have 2 differents ""optimal"" upperbound for the same integral. (by optimal, I mean that in some case, we can have equality).",f_X \mu(dx)=f_X(x)dx \int_{\mathbb R}x\mu(dx)=\int_\mathbb R xf_X(x)dx. \left(\int_{\mathbb R}xf_X(x)dx\right)^2\leq \int_{\mathbb R}x^2f_X(x)^2dx \left(\int_{\mathbb R}x\mu(dx)\right)^2\leq \int_{\mathbb R}x^2\mu(dx)=\int_{\mathbb R}x^2f_X(x)dx. \int_{\mathbb R}x^2f_X(x)dx=\int_{\mathbb R}x^2f_X(x)^2dx\ \ ? \int_{\mathbb R}x^2f_X(x)dx\leq\int_{\mathbb R}x^2f_X(x)^2dx\quad \text{or}\quad \int_{\mathbb R}x^2f_X(x)dx\geq\int_{\mathbb R}x^2f_X(x)^2dx,['measure-theory']
95,"Non-negative integrable functions converging in measure on $[0,1]$ with $ \lim_{k\to\infty}\int_0^1 f_k(x)dx=\int_0^1 f(x)dx .$",Non-negative integrable functions converging in measure on  with,"[0,1]  \lim_{k\to\infty}\int_0^1 f_k(x)dx=\int_0^1 f(x)dx .","Suppose $\{f_k(x)\}$ is a sequence of nonnegative integrable functions on $[0,1]$ , and $f_k(x)$ converges to $f(x)$ in measure on $[0,1]$ . Suppose, in addition, that $$ \lim_{k\to\infty}\int_0^1 f_k(x)dx=\int_0^1 f(x)dx .$$ Prove that for any measurable subset $E$ of $[0,1]$ , $$ \lim_{k\to\infty}\int_E f_k(x)dx=\int_E f(x)dx .$$ My attempt: Since $f_k(x)$ converges to $f(x)$ in measure, we can select a subsequence $\{f_{k_i}\}$ such that $f_{k_i}$ converges to $f(x)$ almost everywhere. Now by Fatou's lemma, we have \begin{align} \int_0^1 f(x)dx&=\int_0^1\lim_{k_i\to\infty}f_{k_i}(x)dx\\ &\le\varliminf_{k_i\to\infty}\int_E f_{k_i}(x)dx+\varliminf_{k_i\to\infty}\int_{[0,1]\setminus E} f_{k_i}(x)dx\\ &\le\varliminf_{k_i\to\infty}\int_0^1 f_{k_i}(x)dx\\ &=\int_0^1 f(x)dx \end{align} by the condition that $ \lim_{k\to\infty}\int_0^1 f_k(x)dx=\int_0^1 f(x)dx $ . Hence, it follows that $$ \lim_{k_i\to\infty}\int_E f_{k_i}(x)dx=\int_E f(x)dx .$$ But now I get stuck in proving the limit is also correct for $f_k$ , not just a subsequence of it. Any idea is appreciated. Thanks. Edit : I think the question missed a hypothesis that $f\in L^1([0,1])$ which plays a vital role in the proof. Otherwise, we can construct a nice counterexample like the one discussed in the comment provided by Sangchul Lee.","Suppose is a sequence of nonnegative integrable functions on , and converges to in measure on . Suppose, in addition, that Prove that for any measurable subset of , My attempt: Since converges to in measure, we can select a subsequence such that converges to almost everywhere. Now by Fatou's lemma, we have by the condition that . Hence, it follows that But now I get stuck in proving the limit is also correct for , not just a subsequence of it. Any idea is appreciated. Thanks. Edit : I think the question missed a hypothesis that which plays a vital role in the proof. Otherwise, we can construct a nice counterexample like the one discussed in the comment provided by Sangchul Lee.","\{f_k(x)\} [0,1] f_k(x) f(x) [0,1]  \lim_{k\to\infty}\int_0^1 f_k(x)dx=\int_0^1 f(x)dx . E [0,1]  \lim_{k\to\infty}\int_E f_k(x)dx=\int_E f(x)dx . f_k(x) f(x) \{f_{k_i}\} f_{k_i} f(x) \begin{align}
\int_0^1 f(x)dx&=\int_0^1\lim_{k_i\to\infty}f_{k_i}(x)dx\\
&\le\varliminf_{k_i\to\infty}\int_E f_{k_i}(x)dx+\varliminf_{k_i\to\infty}\int_{[0,1]\setminus E} f_{k_i}(x)dx\\
&\le\varliminf_{k_i\to\infty}\int_0^1 f_{k_i}(x)dx\\
&=\int_0^1 f(x)dx
\end{align}  \lim_{k\to\infty}\int_0^1 f_k(x)dx=\int_0^1 f(x)dx   \lim_{k_i\to\infty}\int_E f_{k_i}(x)dx=\int_E f(x)dx . f_k f\in L^1([0,1])","['real-analysis', 'measure-theory', 'lebesgue-integral']"
96,Different definitions of Borel sigma-algebra,Different definitions of Borel sigma-algebra,,"Let $X$ be a locally compact Hausdorff space. Denote by $\mathcal{B}(X)$ the Borel $\sigma$ -algebra (generated by all open sets in $X$ ) and by $\mathcal{B}_c(X) \subseteq \mathcal{B}(X)$ the collection of all relatively compact Borel sets. Then $\mathcal{B}_c(X)$ forms a $\delta$ -ring. For a ring $\mathcal{R}$ on some set $S$ denote by $\mathcal{R}^{loc} := \{ E \subseteq S \mid E \cap A \in \mathcal{R} \textrm{ for all } A \in \mathcal{R} \}$ the collection of all sets $E \subseteq S$ that are locally in $\mathcal{R}$ . If $\mathcal{R}$ is a $\delta$ -ring then $\mathcal{R}^{loc}$ is a $\sigma$ -algebra that contains $\mathcal{R}$ . Back to the space $X$ . The $\sigma$ -algebra $\mathcal{B}_c(X)^{loc}$ contains all open sets of $X$ and therefore $\mathcal{B}(X) \subseteq \mathcal{B}_c(X)^{loc}$ [Dinculeanu, ""Vector Measures"", p. 291]. $\mathcal{B}_c^{loc}(X)$ is also sometimes referred to in the older literature as the $\sigma$ -algebra of Borel sets. (It is useful in the context of vector measures, because the total variation measure of a vector measure can be defined on all of $\mathcal{B}_c(X)^{loc}$ .) I am searching for an example of a locally compact Hausdorff space $X$ such that $\mathcal{B}(X) \subsetneq \mathcal{B}_c(X)^{loc}$ , i.e. these two definitions of a Borel $\sigma$ -algebra are different. Equivalently, is there a locally compact Hausdorff space $X$ and a non-Borel measurable $E \not\in \mathcal{B}(X)$ but such that $E \cap K \in \mathcal{B}_c(X)$ (i.e. is Borel-measurable) for all compact $K \subseteq X$ ? Edit: Just an idea: Consider the open ordinal space $X = [0, \omega_1)$ where $\omega_1$ is the first uncountable ordinal. Then $X$ is locally compact but not $\sigma$ -compact. The sets $[0, \alpha]$ , $0 \leq \alpha < \omega_1$ are compact sets and any compact set $K \subseteq [0, \omega_1)$ is contained in some $[0, \alpha]$ . If $E \in 2^{[0, \omega_1)} \setminus \mathcal{B}[0, \omega_1)$ is a non-Borel measurable set then $E \cap [0, \alpha]$ is a Borel measurable subset of $[0, \alpha]$ for all $\alpha < \omega_1$ since $\alpha$ is a countable ordinal and $\mathcal{B}[0, \alpha] = 2^{[0, \alpha]}$ . Hence $E \cap [0, \alpha]$ is a Borel measurable subset of $[0, \omega_1)$ . So the question is: Is $\mathcal{B}[0, \omega_1)$ strictly smaller than the power set $2^{[0, \omega_1)}$ ?","Let be a locally compact Hausdorff space. Denote by the Borel -algebra (generated by all open sets in ) and by the collection of all relatively compact Borel sets. Then forms a -ring. For a ring on some set denote by the collection of all sets that are locally in . If is a -ring then is a -algebra that contains . Back to the space . The -algebra contains all open sets of and therefore [Dinculeanu, ""Vector Measures"", p. 291]. is also sometimes referred to in the older literature as the -algebra of Borel sets. (It is useful in the context of vector measures, because the total variation measure of a vector measure can be defined on all of .) I am searching for an example of a locally compact Hausdorff space such that , i.e. these two definitions of a Borel -algebra are different. Equivalently, is there a locally compact Hausdorff space and a non-Borel measurable but such that (i.e. is Borel-measurable) for all compact ? Edit: Just an idea: Consider the open ordinal space where is the first uncountable ordinal. Then is locally compact but not -compact. The sets , are compact sets and any compact set is contained in some . If is a non-Borel measurable set then is a Borel measurable subset of for all since is a countable ordinal and . Hence is a Borel measurable subset of . So the question is: Is strictly smaller than the power set ?","X \mathcal{B}(X) \sigma X \mathcal{B}_c(X) \subseteq \mathcal{B}(X) \mathcal{B}_c(X) \delta \mathcal{R} S \mathcal{R}^{loc} := \{ E \subseteq S \mid E \cap A \in \mathcal{R} \textrm{ for all } A \in \mathcal{R} \} E \subseteq S \mathcal{R} \mathcal{R} \delta \mathcal{R}^{loc} \sigma \mathcal{R} X \sigma \mathcal{B}_c(X)^{loc} X \mathcal{B}(X) \subseteq \mathcal{B}_c(X)^{loc} \mathcal{B}_c^{loc}(X) \sigma \mathcal{B}_c(X)^{loc} X \mathcal{B}(X) \subsetneq \mathcal{B}_c(X)^{loc} \sigma X E \not\in \mathcal{B}(X) E \cap K \in \mathcal{B}_c(X) K \subseteq X X = [0, \omega_1) \omega_1 X \sigma [0, \alpha] 0 \leq \alpha < \omega_1 K \subseteq [0, \omega_1) [0, \alpha] E \in 2^{[0, \omega_1)} \setminus \mathcal{B}[0, \omega_1) E \cap [0, \alpha] [0, \alpha] \alpha < \omega_1 \alpha \mathcal{B}[0, \alpha] = 2^{[0, \alpha]} E \cap [0, \alpha] [0, \omega_1) \mathcal{B}[0, \omega_1) 2^{[0, \omega_1)}",['measure-theory']
97,Norm of an operator and topological groups,Norm of an operator and topological groups,,"$G=(0,+\infty)$ the multiplicative topological group (with respect to the standard topology of the real line) equipped  with the positive Haar measure $\mu=\frac{1}{x} dx$ For $1 \leq p< \infty$ , we define the operator $T:L^p(G) \to L^p(G)$ to be $T(f)(x)=(f\star K)(x)=\int_0^{\infty}K(t)f(\frac{x}{t})\frac{dt}{t}$ , where $K \in L^1(G)$ is  nonnegative. We must compute the norm of $T$ . Clearly from Minkowski's inequality we have that $||T|| \leq ||K||_1$ How can i prove that $||T||=||K||_1$ ? Can you give me a hint? $\text{EDIT}$ Ι can present my attempt when $p=1$ Let $0<\epsilon<1$ and $N>1$ Let $g_{N,\epsilon}=1_{(\epsilon,N)}$ and $K_N=K1_{(0,N)}$ $$(g_{N,\epsilon}\star K_N)(x)=\int_0^{\infty}K_N(t)1_{(\frac{x}{N},\frac{x}{\epsilon})}(t) \frac{dt}{t}$$ $||g_{N,\epsilon}||_1=\log{N}-\log{\epsilon}$ Also $1_{(\frac{x}{N},\frac{x}{\epsilon})}(t)=1$ if and only if $1_{(t\epsilon,tN)}(x)=1$ From this and Tonneli's  theorem we have that $$||g_{N,\epsilon}\star K_N||_1=\int_0^{\infty}\int_0^{\infty}K_N(t)1_{(\frac{x}{N},\frac{x}{\epsilon})}(t) \frac{dt}{t}\frac{dx}{x}$$ $$=\int_0^{\infty}\int_0^{\infty}K_N(t)1_{(t\epsilon,tN)}(x) \frac{dx}{x}\frac{dt}{t}=||K_N||_1(\log{N}-\log{\epsilon})$$ Using the definition of the norm of an operator and letting $N \to +\infty$ we have the desired inequality. Is this correct ? If it is, can someone help me adapting a similar idea to solve this for $p>1$ ? Thank you in advance.","the multiplicative topological group (with respect to the standard topology of the real line) equipped  with the positive Haar measure For , we define the operator to be , where is  nonnegative. We must compute the norm of . Clearly from Minkowski's inequality we have that How can i prove that ? Can you give me a hint? Ι can present my attempt when Let and Let and Also if and only if From this and Tonneli's  theorem we have that Using the definition of the norm of an operator and letting we have the desired inequality. Is this correct ? If it is, can someone help me adapting a similar idea to solve this for ? Thank you in advance.","G=(0,+\infty) \mu=\frac{1}{x} dx 1 \leq p< \infty T:L^p(G) \to L^p(G) T(f)(x)=(f\star K)(x)=\int_0^{\infty}K(t)f(\frac{x}{t})\frac{dt}{t} K \in L^1(G) T ||T|| \leq ||K||_1 ||T||=||K||_1 \text{EDIT} p=1 0<\epsilon<1 N>1 g_{N,\epsilon}=1_{(\epsilon,N)} K_N=K1_{(0,N)} (g_{N,\epsilon}\star K_N)(x)=\int_0^{\infty}K_N(t)1_{(\frac{x}{N},\frac{x}{\epsilon})}(t) \frac{dt}{t} ||g_{N,\epsilon}||_1=\log{N}-\log{\epsilon} 1_{(\frac{x}{N},\frac{x}{\epsilon})}(t)=1 1_{(t\epsilon,tN)}(x)=1 ||g_{N,\epsilon}\star K_N||_1=\int_0^{\infty}\int_0^{\infty}K_N(t)1_{(\frac{x}{N},\frac{x}{\epsilon})}(t) \frac{dt}{t}\frac{dx}{x} =\int_0^{\infty}\int_0^{\infty}K_N(t)1_{(t\epsilon,tN)}(x) \frac{dx}{x}\frac{dt}{t}=||K_N||_1(\log{N}-\log{\epsilon}) N \to +\infty p>1","['real-analysis', 'functional-analysis', 'measure-theory', 'lebesgue-measure', 'topological-groups']"
98,$\lim \int \sqrt[n]{f^{n} + g^{n}} d\mu$ exists as extended real number.,exists as extended real number.,\lim \int \sqrt[n]{f^{n} + g^{n}} d\mu,"Let $f, g$ be measurable on $(X, \mathcal{M}, \mu)$ with $0 \leq f \leq g$ a.e. Prove that $$\lim_{n\rightarrow \infty} \int \sqrt[n]{f^{n} + g^{n}} d\mu$$ exists as an extended real number. What is its value? So Far: We know $\sqrt[n]{f^{n} + g^{n}} \leq \sqrt[n]{2g^{n}} \leq 2g$ . Also, \begin{align} \log(g) &\leq \lim_{n\rightarrow \infty} \frac{\log(f^{n} + g^{n})}{n} \\ 	&= \lim_{n\rightarrow \infty} \frac{f^{n}\log(f) + g^{n}\log(g)}{f^{n} + g^{n}} & (\text{L'Hospital}) \\ 	&\leq \lim_{n\rightarrow \infty} \frac{f^{n}\log(g) + g^{n}\log(g)}{f^{n} + g^{n}} \\ 	&= \log(g), \end{align} whence $\sqrt[n]{f^{n} + g^{n}} \rightarrow g$ . Thus if $\int g d\mu < \infty$ then Dominated Convergence gives us $$\int \sqrt[n]{f^{n} + g^{n}} d\mu \longrightarrow \int g d\mu.$$ Where I'm Stuck: If $\int g$ is not finite, I'm not quite sure how to show the limit exists in $[-\infty, \infty]$ . According to Dominated Convergence Theorem on Wiki, it is necessary for $g$ to be integrable. So I cannot get an extended real number limit just from that theorem. I also tried integrating over the sets $\{f < 1\}$ and $\{f \geq 1\}$ . On the second set, $\frac{d}{dn}\sqrt[n]{f^{n} + g^{n}}$ is positive and I can apply Monotone Convergence Theorem over this set, which forgets about whether $\int g$ is infinite or not (if I remember correctly). But then integrating over the other set gets me at most $\int_{f< 1} \sqrt[n]{f^{n} + g^{n}} \leq \int_{f>1} \sqrt[n]{1 + g^{n}}$ .","Let be measurable on with a.e. Prove that exists as an extended real number. What is its value? So Far: We know . Also, whence . Thus if then Dominated Convergence gives us Where I'm Stuck: If is not finite, I'm not quite sure how to show the limit exists in . According to Dominated Convergence Theorem on Wiki, it is necessary for to be integrable. So I cannot get an extended real number limit just from that theorem. I also tried integrating over the sets and . On the second set, is positive and I can apply Monotone Convergence Theorem over this set, which forgets about whether is infinite or not (if I remember correctly). But then integrating over the other set gets me at most .","f, g (X, \mathcal{M}, \mu) 0 \leq f \leq g \lim_{n\rightarrow \infty} \int \sqrt[n]{f^{n} + g^{n}} d\mu \sqrt[n]{f^{n} + g^{n}} \leq \sqrt[n]{2g^{n}} \leq 2g \begin{align}
\log(g) &\leq \lim_{n\rightarrow \infty} \frac{\log(f^{n} + g^{n})}{n} \\
	&= \lim_{n\rightarrow \infty} \frac{f^{n}\log(f) + g^{n}\log(g)}{f^{n} + g^{n}} & (\text{L'Hospital}) \\
	&\leq \lim_{n\rightarrow \infty} \frac{f^{n}\log(g) + g^{n}\log(g)}{f^{n} + g^{n}} \\
	&= \log(g),
\end{align} \sqrt[n]{f^{n} + g^{n}} \rightarrow g \int g d\mu < \infty \int \sqrt[n]{f^{n} + g^{n}} d\mu \longrightarrow \int g d\mu. \int g [-\infty, \infty] g \{f < 1\} \{f \geq 1\} \frac{d}{dn}\sqrt[n]{f^{n} + g^{n}} \int g \int_{f< 1} \sqrt[n]{f^{n} + g^{n}} \leq \int_{f>1} \sqrt[n]{1 + g^{n}}","['integration', 'measure-theory']"
99,"There are no Lebesgue measurable sets $A,B \subset \mathbb{R}$ such that $A \times B \subset S$.",There are no Lebesgue measurable sets  such that .,"A,B \subset \mathbb{R} A \times B \subset S","Let $S = \mathbb{R}^2 \setminus \{ (x,y): x+y \in \mathbb{Q} \}.$ Show that there are no Lebesgue measurable sets $A, B \subset \mathbb{R}$ of positive Lebesgue measure for which $A \times B \subset S$ . I don't really know what I'm given and what to work with. It's obvious that $A, B$ cannot have any rational numbers. But I'm not sure how to start. Could someone help me with this?",Let Show that there are no Lebesgue measurable sets of positive Lebesgue measure for which . I don't really know what I'm given and what to work with. It's obvious that cannot have any rational numbers. But I'm not sure how to start. Could someone help me with this?,"S = \mathbb{R}^2 \setminus \{ (x,y): x+y \in \mathbb{Q} \}. A, B \subset \mathbb{R} A \times B \subset S A, B","['measure-theory', 'lebesgue-measure']"
