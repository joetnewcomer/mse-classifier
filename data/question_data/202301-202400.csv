,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Principal bundle automorphism generating global gauge transformations,Principal bundle automorphism generating global gauge transformations,,"Consider a principal $G$-bundle $P$ with connection form $\omega$. An automorphism $f$ of $P$ is by definition a (smooth) $G$-equivariant map: $f(p \cdot g) =f(p) \cdot g$ for all $p\in P$ and $g\in G$. If $ s$ is a local cross section over $U$, then $s^\prime\equiv f ^{-1}\circ s $ is also a cross section over $U$ and there exists a unique map $g:U\rightarrow G$ such that $s^\prime (x)=s (x)\cdot g(x)$. If $A=s^* \omega$, $A^\prime= s^\prime \omega $ then \begin{equation} A^\prime = g ^{-1} A g + g^{-1} \mathrm{d}g. \end{equation} My question is: which bundle automorphisms generate the global gauge transformations $A^\prime=g^{-1}Ag $, with $g\in G$ constant? Because of the property \begin{equation} R_g ^*\omega= g ^{-1}\omega g, \end{equation} I would have thought that they are generated by right multiplication by a group element but this transformation is not, somehow surprisingly for me, a bundle automorphism as, denoting by $f$ the right multiplication by $h\in G$, \begin{equation} f(p)\cdot g= p\cdot hg \neq f(p\cdot g) =p\cdot gh. \end{equation} Am I getting something wrong?","Consider a principal $G$-bundle $P$ with connection form $\omega$. An automorphism $f$ of $P$ is by definition a (smooth) $G$-equivariant map: $f(p \cdot g) =f(p) \cdot g$ for all $p\in P$ and $g\in G$. If $ s$ is a local cross section over $U$, then $s^\prime\equiv f ^{-1}\circ s $ is also a cross section over $U$ and there exists a unique map $g:U\rightarrow G$ such that $s^\prime (x)=s (x)\cdot g(x)$. If $A=s^* \omega$, $A^\prime= s^\prime \omega $ then \begin{equation} A^\prime = g ^{-1} A g + g^{-1} \mathrm{d}g. \end{equation} My question is: which bundle automorphisms generate the global gauge transformations $A^\prime=g^{-1}Ag $, with $g\in G$ constant? Because of the property \begin{equation} R_g ^*\omega= g ^{-1}\omega g, \end{equation} I would have thought that they are generated by right multiplication by a group element but this transformation is not, somehow surprisingly for me, a bundle automorphism as, denoting by $f$ the right multiplication by $h\in G$, \begin{equation} f(p)\cdot g= p\cdot hg \neq f(p\cdot g) =p\cdot gh. \end{equation} Am I getting something wrong?",,"['differential-geometry', 'principal-bundles', 'gauge-theory']"
1,"Higher order differential on a manifold, connections","Higher order differential on a manifold, connections",,"I am trying to understand how to define the second order differential of a map $f : M \rightarrow N$ between smooth manifolds. I came across this exact same question : Higher-order derivatives in manifolds The answers in the comments pointed towards jets, which I didn't know and shall learn about.I also thought that there should be a link with covariant derivatives : if you have a given covariant derivative on $M$, say the Levi-Civita connection of a certain Riemannian metric, isn't there any standard way to define higher order differentials, in a way that would yield a Taylor formula ? Or are jets really the only good way to look at these things ? Any comment or reference appreciated. I know this is almost a duplicate (almost because I am asking also about the link with covariant derivatives, if there is one) but the original question seems inactive, so... EDIT : As I suspected, a torsion-free covariant derivative $\nabla$ allows one to define the second order differential. Indeed, a covariant derivative $\nabla$ allows one to differentiate not only sections of $TM$ (ie vector fields) but also sections of  $TM^{\otimes p} \otimes T^*M^{\otimes q}$ along vector fields.  So the second order differential of a function $f : M \rightarrow \mathbb{R}$ is defined by $$\mathrm{Hess}(f) = \nabla df$$ and it is a section of $S^2 T^*M$. Reference : Gallot Hulin Lafontaine Related question : Definitions of Hessian in Riemannian Geometry The treatment in the reference I found is rather quick though. I am betting that the exponential map will yield a Taylor formula to order 2 with this definition, and that a similar definition holds for a map between manifolds (you probably need a Riemannian metric in both manifolds). I will work out the details for myself, and may or may not answer my own question to close it. If someone finds a reference where the following points are treated (and not just mentionned !) : definition of all high order differentials in the context of Riemannian geometry Taylor formula with the exponential map case of a map between smooth manifolds I will gladly accept hish/her answer.","I am trying to understand how to define the second order differential of a map $f : M \rightarrow N$ between smooth manifolds. I came across this exact same question : Higher-order derivatives in manifolds The answers in the comments pointed towards jets, which I didn't know and shall learn about.I also thought that there should be a link with covariant derivatives : if you have a given covariant derivative on $M$, say the Levi-Civita connection of a certain Riemannian metric, isn't there any standard way to define higher order differentials, in a way that would yield a Taylor formula ? Or are jets really the only good way to look at these things ? Any comment or reference appreciated. I know this is almost a duplicate (almost because I am asking also about the link with covariant derivatives, if there is one) but the original question seems inactive, so... EDIT : As I suspected, a torsion-free covariant derivative $\nabla$ allows one to define the second order differential. Indeed, a covariant derivative $\nabla$ allows one to differentiate not only sections of $TM$ (ie vector fields) but also sections of  $TM^{\otimes p} \otimes T^*M^{\otimes q}$ along vector fields.  So the second order differential of a function $f : M \rightarrow \mathbb{R}$ is defined by $$\mathrm{Hess}(f) = \nabla df$$ and it is a section of $S^2 T^*M$. Reference : Gallot Hulin Lafontaine Related question : Definitions of Hessian in Riemannian Geometry The treatment in the reference I found is rather quick though. I am betting that the exponential map will yield a Taylor formula to order 2 with this definition, and that a similar definition holds for a map between manifolds (you probably need a Riemannian metric in both manifolds). I will work out the details for myself, and may or may not answer my own question to close it. If someone finds a reference where the following points are treated (and not just mentionned !) : definition of all high order differentials in the context of Riemannian geometry Taylor formula with the exponential map case of a map between smooth manifolds I will gladly accept hish/her answer.",,"['reference-request', 'differential-geometry']"
2,is a plane smooth surface?,is a plane smooth surface?,,"let f(u,v)=a + u.p + v.q  : the equation of the plane where p,q are unit vectors perpendicular to each other. a a point on the plane. I do not understand how f can have partial derivatives of all orders, since derivative of wrt. u and v are p and q, respectively. after this, aren't the derivatives zero?","let f(u,v)=a + u.p + v.q  : the equation of the plane where p,q are unit vectors perpendicular to each other. a a point on the plane. I do not understand how f can have partial derivatives of all orders, since derivative of wrt. u and v are p and q, respectively. after this, aren't the derivatives zero?",,['differential-geometry']
3,area form of the Poincare half plane,area form of the Poincare half plane,,"For the upper half plane $\{(u,v)|v>0\}$, its area form is $du\wedge dv/v^2$. How to compute the area between the u axis and the curve  $\alpha(t)=(r\cos t, r\sin t)$, $0< t < \pi$? Is this area infinite?","For the upper half plane $\{(u,v)|v>0\}$, its area form is $du\wedge dv/v^2$. How to compute the area between the u axis and the curve  $\alpha(t)=(r\cos t, r\sin t)$, $0< t < \pi$? Is this area infinite?",,"['differential-geometry', 'hyperbolic-geometry']"
4,De Rham Cohomology of Hopf Surface,De Rham Cohomology of Hopf Surface,,How I calculate the De Rham coohomology of the Hopf surface? In particular I would like to know why the second Betti number is zero .,How I calculate the De Rham coohomology of the Hopf surface? In particular I would like to know why the second Betti number is zero .,,['differential-geometry']
5,Gauss map and shape operator,Gauss map and shape operator,,"Define the map $$\pi : (\mathbb{R}^3-\{(0,0,0)\})\to S^2$$ by   $\pi(p)=\frac{p}{||p||}.$ Show that if $\Sigma_R$ is the sphere of   radius $R>0$, then the Gauss map of $\Sigma_R$ is $\pi|_{\Sigma_R}$ (which means the map $\pi$ restricted to the surface $\Sigma_R$.)   Compute the shape operator and the Gauss curvature of the sphere. I know the Gauss maps a surface in $\mathbb{R}^3$ to the sphere $S^2,$ so $\pi(p)$ is a unit vector for all $p\in \sum$ such that $\pi(p)$ is orthogonal to the surface $\mathbb{R}^3$ at $p$. Also, we defined the Gauss curvature as: $ K(p) = \kappa_1 \kappa_2 .$ How can I do this problem?","Define the map $$\pi : (\mathbb{R}^3-\{(0,0,0)\})\to S^2$$ by   $\pi(p)=\frac{p}{||p||}.$ Show that if $\Sigma_R$ is the sphere of   radius $R>0$, then the Gauss map of $\Sigma_R$ is $\pi|_{\Sigma_R}$ (which means the map $\pi$ restricted to the surface $\Sigma_R$.)   Compute the shape operator and the Gauss curvature of the sphere. I know the Gauss maps a surface in $\mathbb{R}^3$ to the sphere $S^2,$ so $\pi(p)$ is a unit vector for all $p\in \sum$ such that $\pi(p)$ is orthogonal to the surface $\mathbb{R}^3$ at $p$. Also, we defined the Gauss curvature as: $ K(p) = \kappa_1 \kappa_2 .$ How can I do this problem?",,['differential-geometry']
6,On the definition of the exponential map,On the definition of the exponential map,,"The exponential map on a manifold $M$ is defined at a point $ p\in T_p(M)$ as $$exp_p:T_p(M)\rightarrow M \\ exp_p(v)=\gamma_v(1) $$ where $\gamma_v$ is the constant speed geodesic with initial velocity as $v$ Can anyone please tell me what the existence of an affine connection has to do with this definition and also why is the curve's value taken at the point 1? The latter probably has a simple answer, if so a hint would suffice.","The exponential map on a manifold $M$ is defined at a point $ p\in T_p(M)$ as $$exp_p:T_p(M)\rightarrow M \\ exp_p(v)=\gamma_v(1) $$ where $\gamma_v$ is the constant speed geodesic with initial velocity as $v$ Can anyone please tell me what the existence of an affine connection has to do with this definition and also why is the curve's value taken at the point 1? The latter probably has a simple answer, if so a hint would suffice.",,"['differential-geometry', 'manifolds']"
7,why $x^2 = y^3$ is not smooth?,why  is not smooth?,x^2 = y^3,"I read a definition of a smooth curve on the plane: A smooth curve is a map from $[a,b] \to \mathbb R^2: t\mapsto ( f(t),g(t) )$, where $f$ and $g$ are infinitely differentiable functions. According to this definition, $x^2 = y^3$ can be parametrized by $t \mapsto (t^2, t^3)$, so it should be smooth? But it has a special point at $(0,0)$? Can anyone help me please?","I read a definition of a smooth curve on the plane: A smooth curve is a map from $[a,b] \to \mathbb R^2: t\mapsto ( f(t),g(t) )$, where $f$ and $g$ are infinitely differentiable functions. According to this definition, $x^2 = y^3$ can be parametrized by $t \mapsto (t^2, t^3)$, so it should be smooth? But it has a special point at $(0,0)$? Can anyone help me please?",,"['calculus', 'differential-geometry', 'plane-curves']"
8,How to integrate this differential form on the boundary of the cube,How to integrate this differential form on the boundary of the cube,,"The setup. Assume $u = u_1+iu_2: \mathbb{R}^3 \to \mathbb{C}$ and we have the differential 1-forms $$ \star\xi=-x_2 dx_3 + x_3 dx_2 $$ and $$ u \times du = \sum_{i=1}^3 (u \times \partial_i u) dx_i = \sum_{i=1}^3 u_1 \partial_i u_2 - u_2 \partial_i u_1 dx_i.  $$ Assume further that $\Omega_n^3=[-\pi n, \pi n]^3$ which is a 3D cube. The problem. I want to integrate $(u \times du) \wedge \star \xi$ on the boundary of $\Omega_n^3$ to obtain $$ -\frac{1}{2} \int_{\partial \Omega_n^3} (u \times du)_\top \wedge (\star \xi)_\top = n\pi \sum_{i=2}^N \int_{C_i} u_2\partial_1 u_1 - u_1\partial_1 u_2 $$ where $$ C_2=[-\pi n, \pi n] \times \lbrace -\pi n, \pi n \rbrace \times [-\pi n, \pi n]$$ $$ C_3=[-\pi n, \pi n] \times [-\pi n, \pi n] \times \lbrace -\pi n, \pi n \rbrace. $$ This result is stated in this paper on page 55. For the definition of $\top$ see below. What I tried. As I understand it from this paper on page 70, we have $$ (\star\xi)_\top = x_3 dx_2 $$ and $$ (u \times du)_\top = \sum_{i=1}^2 u_1 \partial_i u_2 - u_2 \partial_i u_1 dx_i.$$ So I compute $$ (u \times du)_\top \wedge (\star \xi)_\top = (u_1 \partial_1 u_2 - u_2 \partial_1 u_1) x_3 dx_1 \wedge dx_2$$ and so $$ -\frac{1}{2} \int_{\partial \Omega_n^3} (u \times du)_\top \wedge (\star \xi)_\top = \frac{1}{2} \int_{\partial \Omega_n^3} (u_2 \partial_1 u_1 - u_1 \partial_1 u_2) x_3 dx_1 \wedge dx_2 $$ The question. Can anyone help me to proceed from here? I don't have any clue on how to integrate a wedge-product. EDIT: I'm terribly sorry, but I forgot to mention that $u$ is $\pi n$ periodic in every direction, i.e. it is the same on opposing faces of the torus.","The setup. Assume $u = u_1+iu_2: \mathbb{R}^3 \to \mathbb{C}$ and we have the differential 1-forms $$ \star\xi=-x_2 dx_3 + x_3 dx_2 $$ and $$ u \times du = \sum_{i=1}^3 (u \times \partial_i u) dx_i = \sum_{i=1}^3 u_1 \partial_i u_2 - u_2 \partial_i u_1 dx_i.  $$ Assume further that $\Omega_n^3=[-\pi n, \pi n]^3$ which is a 3D cube. The problem. I want to integrate $(u \times du) \wedge \star \xi$ on the boundary of $\Omega_n^3$ to obtain $$ -\frac{1}{2} \int_{\partial \Omega_n^3} (u \times du)_\top \wedge (\star \xi)_\top = n\pi \sum_{i=2}^N \int_{C_i} u_2\partial_1 u_1 - u_1\partial_1 u_2 $$ where $$ C_2=[-\pi n, \pi n] \times \lbrace -\pi n, \pi n \rbrace \times [-\pi n, \pi n]$$ $$ C_3=[-\pi n, \pi n] \times [-\pi n, \pi n] \times \lbrace -\pi n, \pi n \rbrace. $$ This result is stated in this paper on page 55. For the definition of $\top$ see below. What I tried. As I understand it from this paper on page 70, we have $$ (\star\xi)_\top = x_3 dx_2 $$ and $$ (u \times du)_\top = \sum_{i=1}^2 u_1 \partial_i u_2 - u_2 \partial_i u_1 dx_i.$$ So I compute $$ (u \times du)_\top \wedge (\star \xi)_\top = (u_1 \partial_1 u_2 - u_2 \partial_1 u_1) x_3 dx_1 \wedge dx_2$$ and so $$ -\frac{1}{2} \int_{\partial \Omega_n^3} (u \times du)_\top \wedge (\star \xi)_\top = \frac{1}{2} \int_{\partial \Omega_n^3} (u_2 \partial_1 u_1 - u_1 \partial_1 u_2) x_3 dx_1 \wedge dx_2 $$ The question. Can anyone help me to proceed from here? I don't have any clue on how to integrate a wedge-product. EDIT: I'm terribly sorry, but I forgot to mention that $u$ is $\pi n$ periodic in every direction, i.e. it is the same on opposing faces of the torus.",,"['differential-geometry', 'partial-differential-equations', 'exterior-algebra', 'hodge-theory']"
9,Whitney sum of vector bundles,Whitney sum of vector bundles,,I would like to know how to establish that $ \bigwedge^k ( E \oplus F ) = \bigoplus_{p+q=k} \bigwedge^p E \otimes \bigwedge^q F $ such that $ E $ and $ F $ are two vector bundles. Thanks a lot.,I would like to know how to establish that $ \bigwedge^k ( E \oplus F ) = \bigoplus_{p+q=k} \bigwedge^p E \otimes \bigwedge^q F $ such that $ E $ and $ F $ are two vector bundles. Thanks a lot.,,"['linear-algebra', 'differential-geometry', 'vector-bundles']"
10,hypersurface evolving with tangential velocity,hypersurface evolving with tangential velocity,,"If a hypersurface $S_t$ evolves with velocity only in the tangential direction, is $S_t \equiv S_0$ for all $S$? This is what I have read is true (or something very similar). Can someone give me an example so I can see this? I have no idea what tangential velocity means in 1D for example.","If a hypersurface $S_t$ evolves with velocity only in the tangential direction, is $S_t \equiv S_0$ for all $S$? This is what I have read is true (or something very similar). Can someone give me an example so I can see this? I have no idea what tangential velocity means in 1D for example.",,"['differential-geometry', 'surfaces']"
11,Existence of Lipschitz reparametrization,Existence of Lipschitz reparametrization,,"Suppose we are given a continuous path, $$\gamma:[0,1]\rightarrow (X,d)\text{,}$$ in a metric space $(X,d)$. When we deal with differentiable enough paths in Riemann manifolds we can give a parametrization that is $l$-Lipschitz, where $l$ is the length of the path. If have that $\gamma$ has finite length $l$ in the sense that $$l=\sup\left\{\sum_{i=0}^{n-1}d(\gamma(t_i),\gamma(t_{i+1}))\,|\, n\in \mathbb{N}; \forall i< n,t_i\in[0,1]\text{ and }t_i<t_{i+1};t_0=0;t_n=1\right\}$$ is finite, can we guarantee the existence of a parametrization that makes the path $l$-Lipschitz? Note: The necessity for this result comes that I need this fact to prove that certain sequences of path in metric spaces have nice properties in order to obtain a limit path. And in this way proving that compact path metric spaces are geodesic metric spaces.","Suppose we are given a continuous path, $$\gamma:[0,1]\rightarrow (X,d)\text{,}$$ in a metric space $(X,d)$. When we deal with differentiable enough paths in Riemann manifolds we can give a parametrization that is $l$-Lipschitz, where $l$ is the length of the path. If have that $\gamma$ has finite length $l$ in the sense that $$l=\sup\left\{\sum_{i=0}^{n-1}d(\gamma(t_i),\gamma(t_{i+1}))\,|\, n\in \mathbb{N}; \forall i< n,t_i\in[0,1]\text{ and }t_i<t_{i+1};t_0=0;t_n=1\right\}$$ is finite, can we guarantee the existence of a parametrization that makes the path $l$-Lipschitz? Note: The necessity for this result comes that I need this fact to prove that certain sequences of path in metric spaces have nice properties in order to obtain a limit path. And in this way proving that compact path metric spaces are geodesic metric spaces.",,"['differential-geometry', 'metric-spaces', 'parametric']"
12,Show that an Ehresmann connection on a principal G bundle is equivalent to a Lie Algebra Valued one form.,Show that an Ehresmann connection on a principal G bundle is equivalent to a Lie Algebra Valued one form.,,"Let $E$ be a smooth principal $G$-bundle on M. The vertical bundle $V$ is defined as $V=\ker(d\pi:TE\to \pi^*TM)$. An Ehresmann connection on $E$ is a smooth subbundle $H$ of $TE$ (also called the horizontal bundle), such that $TE=H\oplus V$. Now let $H$ be invariant with respect to the $G$ action on $E$, so $H_{eg}=d(R_g)_e(H_e)$ for all $e\in E$ and all $f \in G$, where $d(R_g)_e$ is the differential of the right action of $g$ at $e$. The Ehresmann connection, $H$ should be equal to a 1-form $\omega$ on $E$ with values in the Lie algebra $\mathfrak{g}$ of $G$. Can anyone provide me any insight as to why this is true and how one constructs this 1-form from the Ehresmann connection? I have poor knowledge of differential geometry.","Let $E$ be a smooth principal $G$-bundle on M. The vertical bundle $V$ is defined as $V=\ker(d\pi:TE\to \pi^*TM)$. An Ehresmann connection on $E$ is a smooth subbundle $H$ of $TE$ (also called the horizontal bundle), such that $TE=H\oplus V$. Now let $H$ be invariant with respect to the $G$ action on $E$, so $H_{eg}=d(R_g)_e(H_e)$ for all $e\in E$ and all $f \in G$, where $d(R_g)_e$ is the differential of the right action of $g$ at $e$. The Ehresmann connection, $H$ should be equal to a 1-form $\omega$ on $E$ with values in the Lie algebra $\mathfrak{g}$ of $G$. Can anyone provide me any insight as to why this is true and how one constructs this 1-form from the Ehresmann connection? I have poor knowledge of differential geometry.",,"['differential-geometry', 'lie-algebras', 'principal-bundles']"
13,Two results on the mean curvature of hypersurfaces,Two results on the mean curvature of hypersurfaces,,"I am a physicist, now I consider a physically meaningful $N-1$ dimensional hypersurface $M^{N-1}$ embedding in the flat Euclidean space $R^{N}$. We have an explicit form of the hypersurface in the following parametric form: $\mathbf{Y}(u)= (x_1(u), x_2(u), …, x_{N}(u))$, with $u$ denotes the $N-1$ local coordinates on the surface. I verified that two formulas for 2D surfaces as $div \mathbf{N}=-H $ (Eq. (8.24) of P.224 of Ref 1.) and $\nabla^2 \mathbf{Y}=H\mathbf{N} $ (Eq. (11.31) of P.305 of Ref 1.) that in fact holds true for some simple surface such as spherical surfaces in any dimensions. I then guess that it in fact holds true for any hyperfuace rather than those I know their explicit forms of $\mathbf{Y}(u)$. I use symbols $div$, $\nabla^2 $, $\mathbf{N} $, and $H$ to denote the surface divergence, the Laplace-Betrami (surface Laplacian as called in Ref 1), and normal vector, the mean curvature, respectively. Ref 1, T. Frankel, The geometry of Physics, (Cambridge, 2004) I have two questions: 1, Can the parametric form $\mathbf{Y}(u)$ of the surface be called the standard form in mathematical community? If yes, references wanted. 2, Can these two formulas $div \mathbf{N}=-H $, $\nabla^2 \mathbf{Y}=H\mathbf{N} $ really hold true for an arbitrary $N-1$ dimensional hypersurface $M^{N-1}$ embedding in the flat Euclidean space $R^{N}$? References wanted. Thanks you for your help!","I am a physicist, now I consider a physically meaningful $N-1$ dimensional hypersurface $M^{N-1}$ embedding in the flat Euclidean space $R^{N}$. We have an explicit form of the hypersurface in the following parametric form: $\mathbf{Y}(u)= (x_1(u), x_2(u), …, x_{N}(u))$, with $u$ denotes the $N-1$ local coordinates on the surface. I verified that two formulas for 2D surfaces as $div \mathbf{N}=-H $ (Eq. (8.24) of P.224 of Ref 1.) and $\nabla^2 \mathbf{Y}=H\mathbf{N} $ (Eq. (11.31) of P.305 of Ref 1.) that in fact holds true for some simple surface such as spherical surfaces in any dimensions. I then guess that it in fact holds true for any hyperfuace rather than those I know their explicit forms of $\mathbf{Y}(u)$. I use symbols $div$, $\nabla^2 $, $\mathbf{N} $, and $H$ to denote the surface divergence, the Laplace-Betrami (surface Laplacian as called in Ref 1), and normal vector, the mean curvature, respectively. Ref 1, T. Frankel, The geometry of Physics, (Cambridge, 2004) I have two questions: 1, Can the parametric form $\mathbf{Y}(u)$ of the surface be called the standard form in mathematical community? If yes, references wanted. 2, Can these two formulas $div \mathbf{N}=-H $, $\nabla^2 \mathbf{Y}=H\mathbf{N} $ really hold true for an arbitrary $N-1$ dimensional hypersurface $M^{N-1}$ embedding in the flat Euclidean space $R^{N}$? References wanted. Thanks you for your help!",,['differential-geometry']
14,curvature of the boundary of a convex set is positive,curvature of the boundary of a convex set is positive,,"Let's consider $J\subset \mathbb R^2$ such that J is convex and such that it's boundary it's a curve $\gamma$. Let's suppose that $\gamma$ is anti-clockwise oriented, let's consider it signed curvature $k_s$. I want to prove the intuitive following fact: $$ \int\limits_\alpha  {k_s } \left( s \right)ds \geqslant 0 $$ For every sub-curve $\alpha \subset \gamma $. And then prove that $k_s(s) \ge 0$ I have no idea how to attack this problem, intuitively I can see the result.","Let's consider $J\subset \mathbb R^2$ such that J is convex and such that it's boundary it's a curve $\gamma$. Let's suppose that $\gamma$ is anti-clockwise oriented, let's consider it signed curvature $k_s$. I want to prove the intuitive following fact: $$ \int\limits_\alpha  {k_s } \left( s \right)ds \geqslant 0 $$ For every sub-curve $\alpha \subset \gamma $. And then prove that $k_s(s) \ge 0$ I have no idea how to attack this problem, intuitively I can see the result.",,['differential-geometry']
15,How to find the area vector of a shape?,How to find the area vector of a shape?,,"If I have a simple $3-d$ shape like a square plate connected to an identical square plate at one edge and they are at an angle of $90\, ^{\circ}$, how would I find an area vector that describes it? I think it might involve finding a unit vector which points in the direction of the faces of the two plates and multiplying it by the area. Is this correct?","If I have a simple $3-d$ shape like a square plate connected to an identical square plate at one edge and they are at an angle of $90\, ^{\circ}$, how would I find an area vector that describes it? I think it might involve finding a unit vector which points in the direction of the faces of the two plates and multiplying it by the area. Is this correct?",,[]
16,Composite of an immersion with the inverse map of another immersion is a diffeomorphism,Composite of an immersion with the inverse map of another immersion is a diffeomorphism,,"Let $U\subset \mathbb{R}^k$ be an open set, $n>k$ and $\varphi_1,\varphi_2 : U\to \mathbb{R}^n$ be immersions, meaning continuously differentiable such that the differential taken in any point of $U$ is injective. Also, let $\varphi_1(U)=\varphi_2(U)=:U'$ and $\varphi_1$ and $\varphi_2$ be injective (and homeomorphisms $U\to U'$). Then $\varphi_1^{-1} \circ \varphi_2 : U\to U$ is a diffeomorphism. My problem is that $\varphi_1^{-1}$ need not be differentiable in the usual analysis sense, because $U'$ is not an open subset of $\mathbb{R}^n$. I am guessing that $d (\varphi_1^{-1}\circ \varphi_2)(x)$ should be $d(\varphi_1)(\varphi_1^{-1}(\varphi_2(x)))^{-1}\cdot d(\varphi_2)(x)$, because this is what happens if $k=n$ and it is still defined for $k<n$. However, I would need a way to apply the theorem on inverse functions to $\varphi_1$.","Let $U\subset \mathbb{R}^k$ be an open set, $n>k$ and $\varphi_1,\varphi_2 : U\to \mathbb{R}^n$ be immersions, meaning continuously differentiable such that the differential taken in any point of $U$ is injective. Also, let $\varphi_1(U)=\varphi_2(U)=:U'$ and $\varphi_1$ and $\varphi_2$ be injective (and homeomorphisms $U\to U'$). Then $\varphi_1^{-1} \circ \varphi_2 : U\to U$ is a diffeomorphism. My problem is that $\varphi_1^{-1}$ need not be differentiable in the usual analysis sense, because $U'$ is not an open subset of $\mathbb{R}^n$. I am guessing that $d (\varphi_1^{-1}\circ \varphi_2)(x)$ should be $d(\varphi_1)(\varphi_1^{-1}(\varphi_2(x)))^{-1}\cdot d(\varphi_2)(x)$, because this is what happens if $k=n$ and it is still defined for $k<n$. However, I would need a way to apply the theorem on inverse functions to $\varphi_1$.",,"['real-analysis', 'differential-geometry']"
17,Nilpotent Lie Group that is not simply connect nor product of Lie Groups?,Nilpotent Lie Group that is not simply connect nor product of Lie Groups?,,"I have been trying to find for days a non-abelian nilpotent Lie Group that is not simply connected nor product of Lie Groups, but haven't been able to succeed. Is there an example of this, or hints to this group, or is it fundamentally impossible? Cheers and thanks.","I have been trying to find for days a non-abelian nilpotent Lie Group that is not simply connected nor product of Lie Groups, but haven't been able to succeed. Is there an example of this, or hints to this group, or is it fundamentally impossible? Cheers and thanks.",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
18,Integral manifolds of a given distribution.,Integral manifolds of a given distribution.,,"Given $X_1=\frac{\partial}{\partial x}-yz\frac{\partial}{\partial z}$ and $X_2=x\frac{\partial}{\partial x}-y\frac{\partial}{\partial y}$ vector fields in $\mathbb{R}^3$, I know the integral curves through $(x_0,y_0,z_0)$ are respectively: $X_1$: $x(t)=x_0+t$, $y(t)=y_0$, $z(t)=z_0 e^{-y_0 t}$ $X_2$: $x(t)=x_0 e^s$, $y(t)=y_0 e^{-s}$, $z(t)=z_0$. On the other hand, since the distribution generated by both vector fields is involutive, I'm sure there is an integral manifold passing through each point of $\mathbb{R}^3$, which in particular contains the integral curves of both fields passing through that same point (right?). How may I, if not intuitively, obtain the expression for them? In this case I obtained them in a non-self-convincing way, by solving a PDE system, and they are of the form $z=\frac{z_0}{e^{-x_0 y_0}} e^{-xy}$, condition which is indeed satisfied by both families of integral curves above. The question is: how could I have obtained this last result in a smarter way? Any geometrical interpretations will do too, of course. Thank you.","Given $X_1=\frac{\partial}{\partial x}-yz\frac{\partial}{\partial z}$ and $X_2=x\frac{\partial}{\partial x}-y\frac{\partial}{\partial y}$ vector fields in $\mathbb{R}^3$, I know the integral curves through $(x_0,y_0,z_0)$ are respectively: $X_1$: $x(t)=x_0+t$, $y(t)=y_0$, $z(t)=z_0 e^{-y_0 t}$ $X_2$: $x(t)=x_0 e^s$, $y(t)=y_0 e^{-s}$, $z(t)=z_0$. On the other hand, since the distribution generated by both vector fields is involutive, I'm sure there is an integral manifold passing through each point of $\mathbb{R}^3$, which in particular contains the integral curves of both fields passing through that same point (right?). How may I, if not intuitively, obtain the expression for them? In this case I obtained them in a non-self-convincing way, by solving a PDE system, and they are of the form $z=\frac{z_0}{e^{-x_0 y_0}} e^{-xy}$, condition which is indeed satisfied by both families of integral curves above. The question is: how could I have obtained this last result in a smarter way? Any geometrical interpretations will do too, of course. Thank you.",,['differential-geometry']
19,Geodesics through two given points,Geodesics through two given points,,"For me, from the definition of a geodesic : Let $\gamma : t \rightarrow \gamma(t)$, $t \in I$, be a curve in a manifold $M$.   The curve $\gamma$  is called a geodesic if the family of tangent   vectors $\dot\gamma(t)$ is parallel with  respect to $\gamma$. it is not obvious, that for any two given points in a connected manifold $M$ there is a geodesic passing through them. Is this so?","For me, from the definition of a geodesic : Let $\gamma : t \rightarrow \gamma(t)$, $t \in I$, be a curve in a manifold $M$.   The curve $\gamma$  is called a geodesic if the family of tangent   vectors $\dot\gamma(t)$ is parallel with  respect to $\gamma$. it is not obvious, that for any two given points in a connected manifold $M$ there is a geodesic passing through them. Is this so?",,['differential-geometry']
20,induced connection on open sets,induced connection on open sets,,"Let $M$ be a smooth manifold. If $\nabla$ is a linear connection on $M$, I would like to induce a unique linear connection on an open subset $U\subseteq M$. I know that for all $p\in U$ there is  a natural isomorphism $T_pU\cong T_pM$, so I can restrict global vector fields to local vector fields on $U$. Unfortunately there are some local vector fields on $U$ that don't came from a restriction of global vector fields. For this reason I can't find a reasonable linear connection $\nabla^U$ over $U$ induced by $\nabla$. I need help.","Let $M$ be a smooth manifold. If $\nabla$ is a linear connection on $M$, I would like to induce a unique linear connection on an open subset $U\subseteq M$. I know that for all $p\in U$ there is  a natural isomorphism $T_pU\cong T_pM$, so I can restrict global vector fields to local vector fields on $U$. Unfortunately there are some local vector fields on $U$ that don't came from a restriction of global vector fields. For this reason I can't find a reasonable linear connection $\nabla^U$ over $U$ induced by $\nabla$. I need help.",,['differential-geometry']
21,"Proving $\nabla F(x,y,z)$ is normal to the surface $F(x,y,z)=0$",Proving  is normal to the surface,"\nabla F(x,y,z) F(x,y,z)=0","What would be a simple way to prove that $\nabla F(x,y,z)$ is normal to the surface $F(x,y,z)=0$? I was wondering if anyone had a simple way to do this. Thanks in advance","What would be a simple way to prove that $\nabla F(x,y,z)$ is normal to the surface $F(x,y,z)=0$? I was wondering if anyone had a simple way to do this. Thanks in advance",,['differential-geometry']
22,Wedge product with a non-degenerate form,Wedge product with a non-degenerate form,,"Let $\alpha$ be a non-degenerate form in $\Lambda^k(V)$ for some vector space $V$, $\dim V = n$. (Here non-degenerate means that if $x\in V$ is nonzero, then $(y_1 , ... , y_{k-1}) \mapsto \alpha(x , y_1 , ... , y_{k-1})$ is a nonzero form). Is it true that if $\beta$ is a nonzero $\ell$-form for $\ell  + k\leq n$, then $\alpha \wedge\beta \not=0$? Is this true under stricter conditions on $\beta$ (e.g. $\beta$ also non-degenerate)?","Let $\alpha$ be a non-degenerate form in $\Lambda^k(V)$ for some vector space $V$, $\dim V = n$. (Here non-degenerate means that if $x\in V$ is nonzero, then $(y_1 , ... , y_{k-1}) \mapsto \alpha(x , y_1 , ... , y_{k-1})$ is a nonzero form). Is it true that if $\beta$ is a nonzero $\ell$-form for $\ell  + k\leq n$, then $\alpha \wedge\beta \not=0$? Is this true under stricter conditions on $\beta$ (e.g. $\beta$ also non-degenerate)?",,"['differential-geometry', 'differential-forms', 'exterior-algebra']"
23,Hodge dual on orthonormal basis: two inconsistent answers,Hodge dual on orthonormal basis: two inconsistent answers,,"I'm trying to learn differential geometry using Göckeler & Schücker's book and I have some problems with the hodge star. As an example, say we have two orthonormal bases $e^i$ and $\widetilde{e}^j=\Lambda^j_{\ k}e^j$ with $g(e^i,e^j)=g(\widetilde{e}^i,\widetilde{e}^j)=\eta^{ij}$ and $i,j=1,2$ of a 2-dimensional vector space, so that $\Lambda\in SO(r,s)$ where $r+s=2$. The book defines the hodge star on an orthonormal basis as $*(e^{i_1}\wedge\cdots\wedge e^{i_p})=\epsilon_{i_1\ldots i_n}\eta^{i_1i_1}\cdots\eta^{i_ni_n}e^{i_{p+1}}\wedge\cdots\wedge e^{i_n}$ (no sum). My problem comes when I try to calculate the star of a basis form in two ways: $$*(\widetilde{e}^1)=\widetilde{\eta}^{11}\widetilde{e}^2=\eta^{11}\Lambda^2_{\ k}e^k=\eta^{11}(\Lambda^2_{\ 1}e^1+\Lambda^2_{\ 2}e^2),$$ and then using the linearity of the hodge star: $$*(\widetilde{e}^1)=\Lambda^1_{\ k}*(e^k)=\Lambda^1_{\ k}\epsilon_{kl}\eta^{kk}e^l=\Lambda^1_{\ 1}\eta^{11}e^2-\Lambda^1_{\ 2}\eta^{22}e^1.$$ These aren't equal, even using $\det(\Lambda)=1$. Can anyone see what I'm doing wrong? I first thought that using the linearity I also have to use the hodge star on $\Lambda^1_{\ k}$. But since the hodge star takes $0$-forms, or scalars, to $2$-forms(?), this would be a product of a $2$-form and a $1$-form and thus zero.","I'm trying to learn differential geometry using Göckeler & Schücker's book and I have some problems with the hodge star. As an example, say we have two orthonormal bases $e^i$ and $\widetilde{e}^j=\Lambda^j_{\ k}e^j$ with $g(e^i,e^j)=g(\widetilde{e}^i,\widetilde{e}^j)=\eta^{ij}$ and $i,j=1,2$ of a 2-dimensional vector space, so that $\Lambda\in SO(r,s)$ where $r+s=2$. The book defines the hodge star on an orthonormal basis as $*(e^{i_1}\wedge\cdots\wedge e^{i_p})=\epsilon_{i_1\ldots i_n}\eta^{i_1i_1}\cdots\eta^{i_ni_n}e^{i_{p+1}}\wedge\cdots\wedge e^{i_n}$ (no sum). My problem comes when I try to calculate the star of a basis form in two ways: $$*(\widetilde{e}^1)=\widetilde{\eta}^{11}\widetilde{e}^2=\eta^{11}\Lambda^2_{\ k}e^k=\eta^{11}(\Lambda^2_{\ 1}e^1+\Lambda^2_{\ 2}e^2),$$ and then using the linearity of the hodge star: $$*(\widetilde{e}^1)=\Lambda^1_{\ k}*(e^k)=\Lambda^1_{\ k}\epsilon_{kl}\eta^{kk}e^l=\Lambda^1_{\ 1}\eta^{11}e^2-\Lambda^1_{\ 2}\eta^{22}e^1.$$ These aren't equal, even using $\det(\Lambda)=1$. Can anyone see what I'm doing wrong? I first thought that using the linearity I also have to use the hodge star on $\Lambda^1_{\ k}$. But since the hodge star takes $0$-forms, or scalars, to $2$-forms(?), this would be a product of a $2$-form and a $1$-form and thus zero.",,"['differential-geometry', 'differential-forms', 'orthonormal']"
24,Possible lengths of geodecics,Possible lengths of geodecics,,"Let $M$ be a compact manifold (w/o boundary). Suppose that there is no closed geodesics on $M$ of length precisely $C$. I am trying to prove that there is an open cover $\{U_j\}$ of $M$ and $\epsilon  >0$ with the following property: if $\gamma$ is a unit speed geodesic in $M$, $C-\epsilon < t < C+\epsilon$, then $\gamma(0)$ and $\gamma(t)$ do not lie in the same $U_j$. It seems like this would be amenable to a compactness argument of some sort, perhaps using an exponential neighborhood at each point. But, I am not seeing a good way to do it. Any suggestions?","Let $M$ be a compact manifold (w/o boundary). Suppose that there is no closed geodesics on $M$ of length precisely $C$. I am trying to prove that there is an open cover $\{U_j\}$ of $M$ and $\epsilon  >0$ with the following property: if $\gamma$ is a unit speed geodesic in $M$, $C-\epsilon < t < C+\epsilon$, then $\gamma(0)$ and $\gamma(t)$ do not lie in the same $U_j$. It seems like this would be amenable to a compactness argument of some sort, perhaps using an exponential neighborhood at each point. But, I am not seeing a good way to do it. Any suggestions?",,"['differential-geometry', 'differential-topology', 'riemannian-geometry']"
25,Leibniz rule for exterior derivative of a contraction,Leibniz rule for exterior derivative of a contraction,,"If I have a contraction of a vector field with a 1-form valued 2-form, what would be the appropiate product rule? $$d_{\left[a\right.} \left(P_{[bc]i} v^i \right)_{\left. \right]} = \, ?$$ This expression should be torn appart to have some kind of $d v$ and $d P$. The underlying 3D manifold is a metric one. As far as I understand one will need to define an exterior derivative for vector-valued differential forms. In turn, that will require a connection, but which one?","If I have a contraction of a vector field with a 1-form valued 2-form, what would be the appropiate product rule? $$d_{\left[a\right.} \left(P_{[bc]i} v^i \right)_{\left. \right]} = \, ?$$ This expression should be torn appart to have some kind of $d v$ and $d P$. The underlying 3D manifold is a metric one. As far as I understand one will need to define an exterior derivative for vector-valued differential forms. In turn, that will require a connection, but which one?",,"['differential-geometry', 'differential-forms']"
26,Covariant derivative and surface gradient,Covariant derivative and surface gradient,,The surface gradient of a function defined on a surface $\Gamma \subset \mathbb{R}^n$ is defined $$\nabla_{\Gamma} f = \nabla f - (\nabla f \cdot N)N$$ where $N$ is the unit normal on $\Gamma.$ How do I obtain this from the covariant derivative operator $\nabla_X Y$?,The surface gradient of a function defined on a surface $\Gamma \subset \mathbb{R}^n$ is defined $$\nabla_{\Gamma} f = \nabla f - (\nabla f \cdot N)N$$ where $N$ is the unit normal on $\Gamma.$ How do I obtain this from the covariant derivative operator $\nabla_X Y$?,,['differential-geometry']
27,Kernel of adjoint of Lie algebra,Kernel of adjoint of Lie algebra,,"Let $G$ be a Lie group and $\mathfrak{g}$ its Lie algebra. The adjoint representation of the Lie algebra $\mathfrak{g}$ is defined as: $$ \text{ad: } \mathfrak{g} \rightarrow \text{End}(\mathfrak{g}), X \mapsto [X,\cdot] $$ Now, it holds true that $$ \text{ker ad} = \mathfrak{z}(\mathfrak{g}) = \{X \in \mathfrak{g} : [X,Y] = 0 \quad\forall\; Y \in \mathfrak{g}\}.$$ On the other hand, the definition of the kernel of this homomorphism is (at least in my mind) $$ \text{ker ad} = \{ X \in \mathfrak{g} : [X,\cdot] = \text{id}, \text{ i.e. } [X,Y] = Y \quad \forall \;Y \in \mathfrak{g} \}, $$ since the group identity in the endomorphism group is the identity-map. Evidently, the two sets are not the same, but where is my mistake?","Let $G$ be a Lie group and $\mathfrak{g}$ its Lie algebra. The adjoint representation of the Lie algebra $\mathfrak{g}$ is defined as: $$ \text{ad: } \mathfrak{g} \rightarrow \text{End}(\mathfrak{g}), X \mapsto [X,\cdot] $$ Now, it holds true that $$ \text{ker ad} = \mathfrak{z}(\mathfrak{g}) = \{X \in \mathfrak{g} : [X,Y] = 0 \quad\forall\; Y \in \mathfrak{g}\}.$$ On the other hand, the definition of the kernel of this homomorphism is (at least in my mind) $$ \text{ker ad} = \{ X \in \mathfrak{g} : [X,\cdot] = \text{id}, \text{ i.e. } [X,Y] = Y \quad \forall \;Y \in \mathfrak{g} \}, $$ since the group identity in the endomorphism group is the identity-map. Evidently, the two sets are not the same, but where is my mistake?",,"['differential-geometry', 'lie-algebras', 'lie-groups']"
28,minimal surface of revolution when endpoints on x-axis?,minimal surface of revolution when endpoints on x-axis?,,"What is the formula for the planar curve through $(\pm a,0)$ of fixed length $l$ which has minimal-area surface of revolution when rotated about the x-axis? I get the area of the surface to be $2\pi\int^a_{-a}y\sqrt{1+y'^2}dx$. Then the first integral of the Euler-Lagrange equation (Beltrami identity) is $y\sqrt{1+y'^2}-\frac{yy'^2}{\sqrt{1+y'^2}} = k$, which has general solution $y(x)=k\cosh(\frac{x-C}{k})$. But putting in the initial conditions $y(\pm a)=0$ gives no nontrivial solutions! Sources such as here say the general solution is indeed $y(x)=k\cosh(\frac{x-C}{k})$, but only when the endpoints of the curve are not on the x-axis. The question I'm looking at says the solution in this case is $y(x)=k(\cosh\frac{x}{k}-\cosh\frac{A}{k})$, but this doesn't seem to satisfy the right ODE! Many thanks for any help with this!","What is the formula for the planar curve through $(\pm a,0)$ of fixed length $l$ which has minimal-area surface of revolution when rotated about the x-axis? I get the area of the surface to be $2\pi\int^a_{-a}y\sqrt{1+y'^2}dx$. Then the first integral of the Euler-Lagrange equation (Beltrami identity) is $y\sqrt{1+y'^2}-\frac{yy'^2}{\sqrt{1+y'^2}} = k$, which has general solution $y(x)=k\cosh(\frac{x-C}{k})$. But putting in the initial conditions $y(\pm a)=0$ gives no nontrivial solutions! Sources such as here say the general solution is indeed $y(x)=k\cosh(\frac{x-C}{k})$, but only when the endpoints of the curve are not on the x-axis. The question I'm looking at says the solution in this case is $y(x)=k(\cosh\frac{x}{k}-\cosh\frac{A}{k})$, but this doesn't seem to satisfy the right ODE! Many thanks for any help with this!",,"['differential-geometry', 'calculus-of-variations']"
29,Non unique solution for Ricci flow equation,Non unique solution for Ricci flow equation,,"Why completeness is important for the uniqueness of solution to Ricci flow? For example, if $M$ is the open unit disk in $\mathbb{R}^2$ and $g(0)$ is the Euclidean metric, and hence not complete. Why the solution $g(t)$ to Ricci flow is not unique?","Why completeness is important for the uniqueness of solution to Ricci flow? For example, if $M$ is the open unit disk in $\mathbb{R}^2$ and $g(0)$ is the Euclidean metric, and hence not complete. Why the solution $g(t)$ to Ricci flow is not unique?",,"['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
30,Space Curve: Equation of normal plane at point...,Space Curve: Equation of normal plane at point...,,"If I have the space curve $r(t) = \langle t, t^2, t^3 \rangle$, how would I find an equation of the normal plane to $r(t)$ at the point $P(2,4,8)$?","If I have the space curve $r(t) = \langle t, t^2, t^3 \rangle$, how would I find an equation of the normal plane to $r(t)$ at the point $P(2,4,8)$?",,['differential-geometry']
31,"An exercise of the book ""Hamilton's Ricci Flow"" by Bennett Chow","An exercise of the book ""Hamilton's Ricci Flow"" by Bennett Chow",,"This is  remark 1.24 on p. 13 of the book Hamilton's Ricci Flow by Bennett Chow, but how to prove this conclusion? If $\varphi (t): M^n \to M^n$ is the $1$-parameter family of diffeomorphism and $\alpha$ is a tensor, then  $$ \frac{\partial}{\partial t} (\varphi(t)^\ast \alpha) = L_{X(t)} \varphi(t)^\ast \alpha  ,$$ where  $$ X(t_0) = \left. \frac{\partial}{\partial t} \right|_{t = t_0} (\varphi (t_0)^{-1} \circ \varphi(t)) .   $$","This is  remark 1.24 on p. 13 of the book Hamilton's Ricci Flow by Bennett Chow, but how to prove this conclusion? If $\varphi (t): M^n \to M^n$ is the $1$-parameter family of diffeomorphism and $\alpha$ is a tensor, then  $$ \frac{\partial}{\partial t} (\varphi(t)^\ast \alpha) = L_{X(t)} \varphi(t)^\ast \alpha  ,$$ where  $$ X(t_0) = \left. \frac{\partial}{\partial t} \right|_{t = t_0} (\varphi (t_0)^{-1} \circ \varphi(t)) .   $$",,['differential-geometry']
32,Understanding an immersion in $\mathbb{R}P^{2}$,Understanding an immersion in,\mathbb{R}P^{2},"Regarding the post: embedding of $\mathbb{RP}^2$ in $\mathbb{R}^4$ I want to understand why $F$ is an immersion. Since $\mathbb{R}P^{2}$ is the quotient of $\mathbb{S}^{2}$ by identifying the antipodal points and we have it suffices to show that the map $f: \mathbb{S}^{2} \subset \mathbb{R}^{3} \rightarrow \mathbb{R}^{4}$ given by $f(x,y,z)=(x^{2}-y^{2},yz,xz,xy)$ is an immersion right? because we have that $F \circ \pi= f$ where $\pi: \mathbb{S}^{2} \rightarrow \mathbb{R}P^{2} = \mathbb{S}^{2}$/~ is the projection map. OK so I compute the Jacobian and get: $\begin{bmatrix} 2x & -2y & 0 \\\ 0 & z &y \\ z & 0 & x \\ y & 0 & 0 \end{bmatrix}$ Would it suffice then to show this matrix has rank $3$? If this is not correct can you please explain why $F$ is an immersion? or any other approach is appreciated.","Regarding the post: embedding of $\mathbb{RP}^2$ in $\mathbb{R}^4$ I want to understand why $F$ is an immersion. Since $\mathbb{R}P^{2}$ is the quotient of $\mathbb{S}^{2}$ by identifying the antipodal points and we have it suffices to show that the map $f: \mathbb{S}^{2} \subset \mathbb{R}^{3} \rightarrow \mathbb{R}^{4}$ given by $f(x,y,z)=(x^{2}-y^{2},yz,xz,xy)$ is an immersion right? because we have that $F \circ \pi= f$ where $\pi: \mathbb{S}^{2} \rightarrow \mathbb{R}P^{2} = \mathbb{S}^{2}$/~ is the projection map. OK so I compute the Jacobian and get: $\begin{bmatrix} 2x & -2y & 0 \\\ 0 & z &y \\ z & 0 & x \\ y & 0 & 0 \end{bmatrix}$ Would it suffice then to show this matrix has rank $3$? If this is not correct can you please explain why $F$ is an immersion? or any other approach is appreciated.",,['differential-geometry']
33,Kirby-like diagrams for $M^n$ when $n > 4$,Kirby-like diagrams for  when,M^n n > 4,"Are there any attempts on constructing Kirby-like diagrams for representing manifolds $M^n$ with $n > 4$. What are the references on that ? I think you run out of dimension in which you can draw when $n > 4$. Further, I do not know whether you can represent the homology in such a structural way as in the $n = 3$ or $n = 4$ case. Needless to say is, that this is only possible when you can obtain an $M^n$ as a handlebody decomposition.","Are there any attempts on constructing Kirby-like diagrams for representing manifolds $M^n$ with $n > 4$. What are the references on that ? I think you run out of dimension in which you can draw when $n > 4$. Further, I do not know whether you can represent the homology in such a structural way as in the $n = 3$ or $n = 4$ case. Needless to say is, that this is only possible when you can obtain an $M^n$ as a handlebody decomposition.",,"['general-topology', 'differential-geometry', 'reference-request', 'low-dimensional-topology', 'kirby-diagram']"
34,"Covariant derivative of (1,1)-tensor","Covariant derivative of (1,1)-tensor",,"Suppose I have an endomorphism $J:TM \to TM$ and a connection on M. It is possible to define $\nabla_X J$ by transforming $J$ into a (1,1)-tensor and using the extension of $\nabla$ to tensors. Going back we get an endomorphism $\nabla_X J:TM \to TM$. Is there a way to define $\nabla_X J:TM \to TM$ directly?","Suppose I have an endomorphism $J:TM \to TM$ and a connection on M. It is possible to define $\nabla_X J$ by transforming $J$ into a (1,1)-tensor and using the extension of $\nabla$ to tensors. Going back we get an endomorphism $\nabla_X J:TM \to TM$. Is there a way to define $\nabla_X J:TM \to TM$ directly?",,['differential-geometry']
35,Helicoid and Catenoid,Helicoid and Catenoid,,"Let $X$ and $Y$ be isothermal parametrizations of minimal surfaces such that their component functions are pairwise harmonic conjugates, then $X$ and $Y$ are called conjugate minimal surfaces. My question is: Are the helicoid and the catenoid conjugate minimal surfaces? It seems to be impossible after a short calculation.","Let $X$ and $Y$ be isothermal parametrizations of minimal surfaces such that their component functions are pairwise harmonic conjugates, then $X$ and $Y$ are called conjugate minimal surfaces. My question is: Are the helicoid and the catenoid conjugate minimal surfaces? It seems to be impossible after a short calculation.",,['differential-geometry']
36,Prove using an admissible unit speed curve and a Frenet frame,Prove using an admissible unit speed curve and a Frenet frame,,"Assume $f:(a,b) \to \mathbb R^3$ is an admissible unit speed curve (hence $f^{\prime} \times f^{\prime\prime}$ is never zero) If $f$ lies on the sphere with center $a$ and radius $r$ prove that $f = a - (1/\kappa) \mathbf N - (1/\kappa)^{\prime} (1/\tau) \mathbf B$ With $|f^{\prime}| = 1$, $\mathbf T = f^{\prime}$ $\mathbf N = f^{\prime\prime}$ $\mathbf B = \mathbf T \times \mathbf N$ $\mathbf T^{\prime} = \kappa \mathbf N$ $\mathbf N^{\prime} = -\kappa \mathbf T + \tau\mathbf B$ $\mathbf B^{\prime} = -\tau\mathbf N$ I've been using the hint that since $f$ lies on the sphere then $(f-a) \cdot (f-a) = r^2$ And trying to differentiate it (three times) to get what I want but I'm not getting very far. I start with $(f-a) \cdot (f-a) = r^2$ Differentiate $2\mathbf T \cdot (f-a) = 0$ Differentiate $2 + 2\kappa\mathbf N \cdot (f-a) = 0$ Differentiate $\mathbf N \cdot \mathbf T + (-\kappa\mathbf T + \tau\mathbf B + 2(\kappa^{\prime}/\kappa)\mathbf N) \cdot (f-a) = 0$ Then I'm not sure where to go.","Assume $f:(a,b) \to \mathbb R^3$ is an admissible unit speed curve (hence $f^{\prime} \times f^{\prime\prime}$ is never zero) If $f$ lies on the sphere with center $a$ and radius $r$ prove that $f = a - (1/\kappa) \mathbf N - (1/\kappa)^{\prime} (1/\tau) \mathbf B$ With $|f^{\prime}| = 1$, $\mathbf T = f^{\prime}$ $\mathbf N = f^{\prime\prime}$ $\mathbf B = \mathbf T \times \mathbf N$ $\mathbf T^{\prime} = \kappa \mathbf N$ $\mathbf N^{\prime} = -\kappa \mathbf T + \tau\mathbf B$ $\mathbf B^{\prime} = -\tau\mathbf N$ I've been using the hint that since $f$ lies on the sphere then $(f-a) \cdot (f-a) = r^2$ And trying to differentiate it (three times) to get what I want but I'm not getting very far. I start with $(f-a) \cdot (f-a) = r^2$ Differentiate $2\mathbf T \cdot (f-a) = 0$ Differentiate $2 + 2\kappa\mathbf N \cdot (f-a) = 0$ Differentiate $\mathbf N \cdot \mathbf T + (-\kappa\mathbf T + \tau\mathbf B + 2(\kappa^{\prime}/\kappa)\mathbf N) \cdot (f-a) = 0$ Then I'm not sure where to go.",,['differential-geometry']
37,Computing pullback of the one form $dx$,Computing pullback of the one form,dx,"I have the following 1-form in $\mathbb{R}^2$ which is $\omega=dx$ , and it is given the map $$\varphi: \mathbb{R}^2 \to S^2 \setminus \lbrace N \rbrace  $$ $$ (x,y)\mapsto \left( \frac{2x}{x^2+y^2+1}, \frac{2y}{x^2+y^2+1}, 1 - \frac{2}{x^2+y^2+1} \right) $$ where N is the north, and I want to compute the pullback of $(\varphi^{-1})$ , where I found that is given by $$ \varphi^{-1}: S^2 \setminus \lbrace N \rbrace \to \mathbb{R}^2   $$ $$ (x,y,z) \mapsto \left( \frac{x}{1-z}, \frac{y}{1-z} \right)  $$ but using the definition that Do Carmo gives I don't understand how to compute the pullback, where it is said that if we have $f: \mathbb{R}^n \to \mathbb{R}^m$ a differentiable map, then the pullback is: $$ (f^{*}w)(p)(v_1, \ldots, v_k) = \omega(f(p))(df_p(v_1), \ldots, df_p(v_k)) $$ where $p \in \mathbb{R}^n$ , $v_1, \ldots, v_k \in \mathbb{R}_{p}^{n}$ , any help would be appreciated.","I have the following 1-form in which is , and it is given the map where N is the north, and I want to compute the pullback of , where I found that is given by but using the definition that Do Carmo gives I don't understand how to compute the pullback, where it is said that if we have a differentiable map, then the pullback is: where , , any help would be appreciated.","\mathbb{R}^2 \omega=dx \varphi: \mathbb{R}^2 \to S^2 \setminus \lbrace N \rbrace    (x,y)\mapsto \left( \frac{2x}{x^2+y^2+1}, \frac{2y}{x^2+y^2+1}, 1 - \frac{2}{x^2+y^2+1} \right)  (\varphi^{-1})  \varphi^{-1}: S^2 \setminus \lbrace N \rbrace \to \mathbb{R}^2     (x,y,z) \mapsto \left( \frac{x}{1-z}, \frac{y}{1-z} \right)   f: \mathbb{R}^n \to \mathbb{R}^m  (f^{*}w)(p)(v_1, \ldots, v_k) = \omega(f(p))(df_p(v_1), \ldots, df_p(v_k))  p \in \mathbb{R}^n v_1, \ldots, v_k \in \mathbb{R}_{p}^{n}","['differential-geometry', 'smooth-manifolds', 'differential-forms']"
38,Torsion Chern class,Torsion Chern class,,"Let $(Y, \lambda)$ be a closed, contact 3-manifold, and $\xi = \ker(\lambda)$ be the associated two-plane field. In Theorem 7.6 (Page 27) of this note , the author claims that there always exists $\Gamma \in H_1(Y; \mathbb{Z})$ such that $c_1(\xi) + 2PD(\Gamma) \in H^2(Y; \mathbb{Z})$ is torsion. I wonder why that is the case? Indeed, it suffices to find a complex line bundle $E$ such that $c_1(\xi \otimes E \otimes E) = c_1(\xi) + 2c_1(E)$ is torsion, since then we can take $\Gamma = PD(c_1(E))$ (or the homology class of the zero locus of a generic section of $E$ ). However, I fail to see why such an $E$ must exist. Does it have something to do with $TY$ being trivial (as mentioned earlier in the note)?","Let be a closed, contact 3-manifold, and be the associated two-plane field. In Theorem 7.6 (Page 27) of this note , the author claims that there always exists such that is torsion. I wonder why that is the case? Indeed, it suffices to find a complex line bundle such that is torsion, since then we can take (or the homology class of the zero locus of a generic section of ). However, I fail to see why such an must exist. Does it have something to do with being trivial (as mentioned earlier in the note)?","(Y, \lambda) \xi = \ker(\lambda) \Gamma \in H_1(Y; \mathbb{Z}) c_1(\xi) + 2PD(\Gamma) \in H^2(Y; \mathbb{Z}) E c_1(\xi \otimes E \otimes E) = c_1(\xi) + 2c_1(E) \Gamma = PD(c_1(E)) E E TY","['differential-geometry', 'algebraic-topology']"
39,Tensor product of a line bundle and its dual bundle,Tensor product of a line bundle and its dual bundle,,"Let $L$ be a complex line bundle over an $m$ -dimensional manifold $M$ , and $L^*$ its dual line bundle. (That is: the fibers of $L^*$ are linear maps from the fibers of $L$ into C.) How to show that $L \otimes L^*$ is a trivial line bundle?","Let be a complex line bundle over an -dimensional manifold , and its dual line bundle. (That is: the fibers of are linear maps from the fibers of into C.) How to show that is a trivial line bundle?",L m M L^* L^* L L \otimes L^*,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
40,Concatenation of $f$-related vector fields/tangent vectors,Concatenation of -related vector fields/tangent vectors,f,"This is probably a highly trivial question, but I just can't wrap my head around it. Let $M,N$ be two manifolds and $f: M \rightarrow N$ smooth. Let further $X^1, X^2$ be two smooth vector fields on $M$ and $Y^1, Y^2$ on $N$ . Further, $Y^i$ is $f$ -related to $X^i$ , that is for all $p \in M$ : $$Y^i_{f(p)} = D_pf(X^i_p).$$ Let $g \in \mathcal{C}^{\infty} (N)$ . Now, what exactly does the following concatenation (which is for example encountered in Lie brackets) mean? $$Y^1_{f(p)}(Y^2_{f(p)}(g))$$ If I try to ""unwrap"" it in terms of $X$ I always end up with ill-defined expressions: $$Y^1_{f(p)}(Y^2_{f(p)}(g)) = D_pf(X^1_p)(D_pf(X^2_p)(g)) \\ = D_pf(X^1_p)(X^2_p(g \circ f)) \\ = X^1_p(X^2_p(g \circ f)\circ f).$$ The problem is that $D_pf(X^i_p)(\cdot)$ expects some $g \in \mathcal{C}^{\infty} (N)$ . I understand that $X^2_p(g \circ f)$ is to be understood as $g \mapsto X^2_p(g \circ f)$ , but how can this be concatenated again with $f$ ? In what sense is $X^2_p(g \circ f) \in \mathcal{C}^{\infty} (N)$ so that $D_pf(X^1_p)(X^2_p(g \circ f))$ is well-defined?","This is probably a highly trivial question, but I just can't wrap my head around it. Let be two manifolds and smooth. Let further be two smooth vector fields on and on . Further, is -related to , that is for all : Let . Now, what exactly does the following concatenation (which is for example encountered in Lie brackets) mean? If I try to ""unwrap"" it in terms of I always end up with ill-defined expressions: The problem is that expects some . I understand that is to be understood as , but how can this be concatenated again with ? In what sense is so that is well-defined?","M,N f: M \rightarrow N X^1, X^2 M Y^1, Y^2 N Y^i f X^i p \in M Y^i_{f(p)} = D_pf(X^i_p). g \in \mathcal{C}^{\infty} (N) Y^1_{f(p)}(Y^2_{f(p)}(g)) X Y^1_{f(p)}(Y^2_{f(p)}(g)) = D_pf(X^1_p)(D_pf(X^2_p)(g)) \\
= D_pf(X^1_p)(X^2_p(g \circ f)) \\
= X^1_p(X^2_p(g \circ f)\circ f). D_pf(X^i_p)(\cdot) g \in \mathcal{C}^{\infty} (N) X^2_p(g \circ f) g \mapsto X^2_p(g \circ f) f X^2_p(g \circ f) \in \mathcal{C}^{\infty} (N) D_pf(X^1_p)(X^2_p(g \circ f))","['differential-geometry', 'lie-groups', 'smooth-manifolds', 'vector-fields']"
41,From algebra of smooth functions to a smooth manifold,From algebra of smooth functions to a smooth manifold,,"Suppose that the $\mathbb{R}$ -algebras $\mathcal{F}_1$ and $\mathcal{F}_2$ , as vector spaces, are isomorphic to the plane $\mathbb{R}^2$ . Let the multiplication in $\mathcal{F}_1$ and $\mathcal{F}_2$ be respectively given by the relations $(x_1, y_1) \cdot (x_2, y_2) = (x_1x_2, y_1y_2) $ $(x_1, y_1) \cdot (x_2, y_2) = (x_1x_2 + y_1y_2, x_1y_2 + x_2y_1) $ Find the manifold $M_i$ for which the algebra $\mathcal{F}_i$ , $i =1, 2$ , is the algebra of smooth functions, explicitly indicating what function on $M_i$ corresponds to the element $(x, y) \in \mathcal{F}_i$ . Are the algebras $\mathcal{F}_1$ and $\mathcal{F}_2$ isomorphic? This question has boggled me for a while. We are looking for manifolds $M_i$ for which $\mathcal{F}_i \cong C^\infty(M_i)$ . The problem I see here is that $C^\infty(M_i)$ is infinite-dimensional while $\mathcal{F}_i$ 's are both $2$ -dimensional so how can there exists such manifolds? The second thing is that the latter one looks like its almost the product we have with complex numbers except for the first $+$ sign which should probably be a $-$ sign? How should one go about solving this kinda problem?","Suppose that the -algebras and , as vector spaces, are isomorphic to the plane . Let the multiplication in and be respectively given by the relations Find the manifold for which the algebra , , is the algebra of smooth functions, explicitly indicating what function on corresponds to the element . Are the algebras and isomorphic? This question has boggled me for a while. We are looking for manifolds for which . The problem I see here is that is infinite-dimensional while 's are both -dimensional so how can there exists such manifolds? The second thing is that the latter one looks like its almost the product we have with complex numbers except for the first sign which should probably be a sign? How should one go about solving this kinda problem?","\mathbb{R} \mathcal{F}_1 \mathcal{F}_2 \mathbb{R}^2 \mathcal{F}_1 \mathcal{F}_2 (x_1, y_1) \cdot (x_2, y_2) = (x_1x_2, y_1y_2)  (x_1, y_1) \cdot (x_2, y_2) = (x_1x_2 + y_1y_2, x_1y_2 + x_2y_1)  M_i \mathcal{F}_i i =1, 2 M_i (x, y) \in \mathcal{F}_i \mathcal{F}_1 \mathcal{F}_2 M_i \mathcal{F}_i \cong C^\infty(M_i) C^\infty(M_i) \mathcal{F}_i 2 + -","['differential-geometry', 'smooth-manifolds']"
42,How to determine a basis for the tangent space given a local trivialization.,How to determine a basis for the tangent space given a local trivialization.,,"I heard the following: For a smooth submanifold $M \subseteq \mathbb{R}^n$ , given a local trivialization one can easily find a basis for the tangent space. I want to know how. So first I should maybe formalize the question: Suppose $M \subseteq \mathbb{R}^n$ is a smooth $k$ -dimensional submanifold and for $p \in M$ , $\phi:U \rightarrow V$ a local trivialization of $M$ such that $x \in M \cap U$ . Then there exist functions $b_1,...,b_k$ such that $B=\{b_1(x),...,b_k(x)\}$ form a basis of $T_xM$ . My idea: If $\phi:U \rightarrow V$ is a local trivialization, then $\frac{\partial}{\partial x_1} \phi(x)_{|x=p},...,\frac{\partial}{\partial x_k}\phi(x)_{|x=p}$ should be a basis for the tangent space $T_pM$ . My problems at the moment: I don't know how to explicitly show my assumption. I.e. I need to show that for $v \in T_pM$ , $v$ can be written as a linear combination of $\frac{\partial}{\partial x_1} \phi(x)_{|x=p},...,\frac{\partial}{\partial x_k}\phi(x)_{|x=p}$ . And I also need to show that $\frac{\partial}{\partial x_1} \phi(x)_{|x=p},...,\frac{\partial}{\partial x_k}\phi(x)_{|x=p}$ are linearly independent. Question: How do I show above-mentioned? Does my idea work or am I wrong? Edit: I wanted to add the Definitions I use: Let $M \subseteq \mathbb{R}^n$ . $M$ is a smooth $k$ -dimensional submanifold if for each $x \in M$ , there exists open subsets $U,V \subseteq \mathbb{R}^n$ were $x \in U$ and there exists a diffeomorphism $\phi:U\rightarrow V$ such that $\phi(U \cap M) = V \cap \mathbb{R}^k$ . I call $\phi$ a local trivialization. As far as I know, $\phi$ is sometimes also called a local parametrization. I want to show that there exist local coordinates $b_1(x),...,b_k(x)$ of the tangent space $T_xM$ .","I heard the following: For a smooth submanifold , given a local trivialization one can easily find a basis for the tangent space. I want to know how. So first I should maybe formalize the question: Suppose is a smooth -dimensional submanifold and for , a local trivialization of such that . Then there exist functions such that form a basis of . My idea: If is a local trivialization, then should be a basis for the tangent space . My problems at the moment: I don't know how to explicitly show my assumption. I.e. I need to show that for , can be written as a linear combination of . And I also need to show that are linearly independent. Question: How do I show above-mentioned? Does my idea work or am I wrong? Edit: I wanted to add the Definitions I use: Let . is a smooth -dimensional submanifold if for each , there exists open subsets were and there exists a diffeomorphism such that . I call a local trivialization. As far as I know, is sometimes also called a local parametrization. I want to show that there exist local coordinates of the tangent space .","M \subseteq \mathbb{R}^n M \subseteq \mathbb{R}^n k p \in M \phi:U \rightarrow V M x \in M \cap U b_1,...,b_k B=\{b_1(x),...,b_k(x)\} T_xM \phi:U \rightarrow V \frac{\partial}{\partial x_1} \phi(x)_{|x=p},...,\frac{\partial}{\partial x_k}\phi(x)_{|x=p} T_pM v \in T_pM v \frac{\partial}{\partial x_1} \phi(x)_{|x=p},...,\frac{\partial}{\partial x_k}\phi(x)_{|x=p} \frac{\partial}{\partial x_1} \phi(x)_{|x=p},...,\frac{\partial}{\partial x_k}\phi(x)_{|x=p} M \subseteq \mathbb{R}^n M k x \in M U,V \subseteq \mathbb{R}^n x \in U \phi:U\rightarrow V \phi(U \cap M) = V \cap \mathbb{R}^k \phi \phi b_1(x),...,b_k(x) T_xM","['differential-geometry', 'submanifold', 'tangent-spaces']"
43,Obtaining a connection on a trivial bundle by giving a matrix of $1$-forms,Obtaining a connection on a trivial bundle by giving a matrix of -forms,1,"I'm new to connections and I'm going over the page ( https://mathworld.wolfram.com/VectorBundleConnection.html ) in which they state the following For example, the trivial bundle $E=M\times \Bbb R^k$ admits a flat connection since any bundle section $s$ corresponds to a function $s:M\to \Bbb R^k$ . Then setting $\nabla s=ds$ gives the connection. Any connection on the trivial bundle is of the form $\nabla s=ds+s \otimes \alpha$ , where $\alpha$ is any one-form with values in $\text{Hom}(E,E)=E^*\otimes E$ , i.e., $\alpha$ is a matrix of one-forms. I understand from here that if $s: M \to E= M\times \Bbb R^k$ is a section of $E$ , then this is identifiable with a map $s :M \to \Bbb R^k$ . Now $ds$ is a bit ambiguous, but if I'm not mistaken this is under the identification $s=(s_1,\dots,s_k)$ with $s_i : M \to \Bbb R$ just $$ds=(ds_1,\dots,ds_k).$$ The second part of the paragraph is what confuses me a bit, they state that any connection on a trivial bundle is of the form $$\nabla s=ds +s\otimes \alpha$$ for $\alpha \in \Gamma(T^*M\otimes \text{Hom}(E,E))$ . Where is this coming from, why is any connection given by just giving a matrix of $1$ -forms? For example on the trivial bundle $M \times \Bbb R^2$ over $M$ , will something like $$\alpha = \begin{bmatrix}dx&0\\ 0&dy\end{bmatrix}$$ immediately give me a connection on $M \times \Bbb R^2$ ? A follow up to this would be that on a smooth manifold with a rank $k$ vector bundle $E \to M$ , given a trivializing open cover $\{U_i\}$ , can I define connections $\nabla_i$ on $E|_{U_i} \cong U_i \times \Bbb R^k$ and patch these together to get a connection on $E$ even if it isn't trivial itself?","I'm new to connections and I'm going over the page ( https://mathworld.wolfram.com/VectorBundleConnection.html ) in which they state the following For example, the trivial bundle admits a flat connection since any bundle section corresponds to a function . Then setting gives the connection. Any connection on the trivial bundle is of the form , where is any one-form with values in , i.e., is a matrix of one-forms. I understand from here that if is a section of , then this is identifiable with a map . Now is a bit ambiguous, but if I'm not mistaken this is under the identification with just The second part of the paragraph is what confuses me a bit, they state that any connection on a trivial bundle is of the form for . Where is this coming from, why is any connection given by just giving a matrix of -forms? For example on the trivial bundle over , will something like immediately give me a connection on ? A follow up to this would be that on a smooth manifold with a rank vector bundle , given a trivializing open cover , can I define connections on and patch these together to get a connection on even if it isn't trivial itself?","E=M\times \Bbb R^k s s:M\to \Bbb R^k \nabla s=ds \nabla s=ds+s \otimes \alpha \alpha \text{Hom}(E,E)=E^*\otimes E \alpha s: M \to E= M\times \Bbb R^k E s :M \to \Bbb R^k ds s=(s_1,\dots,s_k) s_i : M \to \Bbb R ds=(ds_1,\dots,ds_k). \nabla s=ds +s\otimes \alpha \alpha \in \Gamma(T^*M\otimes \text{Hom}(E,E)) 1 M \times \Bbb R^2 M \alpha = \begin{bmatrix}dx&0\\ 0&dy\end{bmatrix} M \times \Bbb R^2 k E \to M \{U_i\} \nabla_i E|_{U_i} \cong U_i \times \Bbb R^k E","['differential-geometry', 'vector-bundles', 'connections']"
44,Principal curvature of a surface defined by an equation,Principal curvature of a surface defined by an equation,,"Let be $S$ a set of points $ (x,y,z)\in\mathbb{R^3}$ that satisfy the equation $x^3+y^2+z^2=1$ . Calculate the main curvatures and Gaussian curvature at the points $p_1=(1,0,0)$ , $p_2=(0,1,0)$ e $p_3=(0,0,1)$ . I want to know if this is correct: We have that the tangent plane in $p_1$ is generated by $(0,1,0)$ and $(0,0,1)$ (from the Kernel of $dg_{p_1}$ where $g=x^3+y^2+z^2-1$ ), then we have that $k_1= <N(p_1),\gamma_1''(0)>$ and $k_2= <N(p_1),\gamma_2''(0)>$ (where $k_1$ and $k_2$ are the two main curvatures and $N$ is the Gauss Map, in this case $N=\frac{dg}{||dg||}$ ) where $\gamma_1,\gamma_2$ are two curves in $S$ that $\gamma_1(0)=\gamma_2(0)=p_1$ and $\gamma'_1(0)=(0,1,0)$ , $\gamma'_2(0)=(0,0,1)$ . We have $N(p_1)=(1,0,0)$ , if we choose $\gamma_1(t)=((1-t^2)^{1/3},t,0)$ and $\gamma_2(t)=((1-t^2)^{1/3},0,t)$ , we obtained $k_1=k_2=-2/3$ , then Gaussian curvature is $4/9$ . Doing the same with $p_2$ we obtained $k_1=0$ and $k_2=-1$ , so $K(p_2)=0$ and doing the same with $p_3$ we obtained $k_1=0$ and $k_2=-1$ , so $K(p_3)=0$ .","Let be a set of points that satisfy the equation . Calculate the main curvatures and Gaussian curvature at the points , e . I want to know if this is correct: We have that the tangent plane in is generated by and (from the Kernel of where ), then we have that and (where and are the two main curvatures and is the Gauss Map, in this case ) where are two curves in that and , . We have , if we choose and , we obtained , then Gaussian curvature is . Doing the same with we obtained and , so and doing the same with we obtained and , so .","S  (x,y,z)\in\mathbb{R^3} x^3+y^2+z^2=1 p_1=(1,0,0) p_2=(0,1,0) p_3=(0,0,1) p_1 (0,1,0) (0,0,1) dg_{p_1} g=x^3+y^2+z^2-1 k_1= <N(p_1),\gamma_1''(0)> k_2= <N(p_1),\gamma_2''(0)> k_1 k_2 N N=\frac{dg}{||dg||} \gamma_1,\gamma_2 S \gamma_1(0)=\gamma_2(0)=p_1 \gamma'_1(0)=(0,1,0) \gamma'_2(0)=(0,0,1) N(p_1)=(1,0,0) \gamma_1(t)=((1-t^2)^{1/3},t,0) \gamma_2(t)=((1-t^2)^{1/3},0,t) k_1=k_2=-2/3 4/9 p_2 k_1=0 k_2=-1 K(p_2)=0 p_3 k_1=0 k_2=-1 K(p_3)=0","['differential-geometry', 'surfaces', 'curvature']"
45,Calculate the Lie derivative using definition,Calculate the Lie derivative using definition,,"Definition: If $X$ and $Y$ are vector fields on a smooth manifold $M$ , the Lie derivative of $Y$ in the direction of $X$ is the vector field $$ \mathcal{L}_X Y := \frac{d}{dt}\bigg\vert_{t=0}(F^X_{-t})_\ast Y. $$ Here $F^X$ denotes the flow of $X$ . Using this definition, calculate the Lie derivative $\mathcal{L}_X Y$ where $X = \frac{\partial}{\partial x}$ and $Y = x \frac{\partial}{\partial y}$ (here $x,y$ are the standard coordinates on $\Bbb{R}^2$ ). My attempt: A previous exercise asked to calculate this via the Lie bracket, to which I found that $[X,Y] = \frac{\partial}{\partial y}$ , so I know the Lie derivative must equal this as well. I calculated the flow of $X$ as being $F^X: \Bbb{R}^2 \times \Bbb{R} \to \Bbb{R}: ((x,y),t) \mapsto (x+t,y)$ . Hence at a time $-t$ we get $F^X_{-t} = (x-t,y)$ . But when I calculate the derivative of this map, I just get that the derivative, $(F^X_{-t})_\ast = \operatorname{Id}$ . But this is independent of $t$ , so that would mean $\mathcal{L}_X Y = 0$ , which is not the correct answer. Where did I go wrong here? Is the flow correct? What about the derivative? Am I interpreting the notation incorrectly? Thanks in advance!","Definition: If and are vector fields on a smooth manifold , the Lie derivative of in the direction of is the vector field Here denotes the flow of . Using this definition, calculate the Lie derivative where and (here are the standard coordinates on ). My attempt: A previous exercise asked to calculate this via the Lie bracket, to which I found that , so I know the Lie derivative must equal this as well. I calculated the flow of as being . Hence at a time we get . But when I calculate the derivative of this map, I just get that the derivative, . But this is independent of , so that would mean , which is not the correct answer. Where did I go wrong here? Is the flow correct? What about the derivative? Am I interpreting the notation incorrectly? Thanks in advance!","X Y M Y X 
\mathcal{L}_X Y := \frac{d}{dt}\bigg\vert_{t=0}(F^X_{-t})_\ast Y.
 F^X X \mathcal{L}_X Y X = \frac{\partial}{\partial x} Y = x \frac{\partial}{\partial y} x,y \Bbb{R}^2 [X,Y] = \frac{\partial}{\partial y} X F^X: \Bbb{R}^2 \times \Bbb{R} \to \Bbb{R}: ((x,y),t) \mapsto (x+t,y) -t F^X_{-t} = (x-t,y) (F^X_{-t})_\ast = \operatorname{Id} t \mathcal{L}_X Y = 0","['differential-geometry', 'manifolds', 'smooth-manifolds', 'vector-fields', 'lie-derivative']"
46,Understanding's Wikipedia's definition of a spinor,Understanding's Wikipedia's definition of a spinor,,"I am trying to understand spinors from a mathematical view. I've seen similar questions on this website but I'm still unclear on what they are exactly. On Wikipedia they state: Although spinors can be defined purely as elements of a representation space of the spin group (or its Lie algebra of infinitesimal rotations), they are typically defined as elements of a vector space that carries a linear representation of the Clifford algebra. What confuses me is say we are working on space time so that $\mathbb{R}^4$ is our vector space. Going by the above passage, a spinor would be an element of $\mathbb{R}^4$ that carries a representation of the spin group, let us denote this pair as $(x, \rho)$ where $\rho$ is the representation. However $x$ is itself also a vector since $x \in \mathbb{R}^4$ . So why are vectors and spinors referred to as two different objects? In other words, how does the representation play any role in describing the spinor itself (which as I understand is simply a vector in the underlying vector space)? My current guess is that spinors are always to be taken as a pair consisting of a vector and a representation, for example $(x, \rho)$ above. Thus, spinors are actually also vectors, but the difference is that when you talk about rotations then spinors ""rotate"" differently than an ordinary vector in $\mathbb{R}^4$ . However I am not sure if this is right since most textbooks do not describe anything along these lines. For example, no physics textbook describes a spinor as a pair $(x, \rho)$ . Is this implicitly assumed?","I am trying to understand spinors from a mathematical view. I've seen similar questions on this website but I'm still unclear on what they are exactly. On Wikipedia they state: Although spinors can be defined purely as elements of a representation space of the spin group (or its Lie algebra of infinitesimal rotations), they are typically defined as elements of a vector space that carries a linear representation of the Clifford algebra. What confuses me is say we are working on space time so that is our vector space. Going by the above passage, a spinor would be an element of that carries a representation of the spin group, let us denote this pair as where is the representation. However is itself also a vector since . So why are vectors and spinors referred to as two different objects? In other words, how does the representation play any role in describing the spinor itself (which as I understand is simply a vector in the underlying vector space)? My current guess is that spinors are always to be taken as a pair consisting of a vector and a representation, for example above. Thus, spinors are actually also vectors, but the difference is that when you talk about rotations then spinors ""rotate"" differently than an ordinary vector in . However I am not sure if this is right since most textbooks do not describe anything along these lines. For example, no physics textbook describes a spinor as a pair . Is this implicitly assumed?","\mathbb{R}^4 \mathbb{R}^4 (x, \rho) \rho x x \in \mathbb{R}^4 (x, \rho) \mathbb{R}^4 (x, \rho)","['differential-geometry', 'representation-theory', 'mathematical-physics', 'clifford-algebras', 'spin-geometry']"
47,"$\iota_{[X,Y]}\omega = \mathcal{L}_X\iota_Y\omega - \iota_Y\mathcal{L}_X\omega$ for every $X, Y \in \mathfrak{X}(M)$ and $\omega \in \Omega^k(M)$.",for every  and .,"\iota_{[X,Y]}\omega = \mathcal{L}_X\iota_Y\omega - \iota_Y\mathcal{L}_X\omega X, Y \in \mathfrak{X}(M) \omega \in \Omega^k(M)","Prove that $\iota_{[X,Y]}\omega = \mathcal{L}_X\iota_Y\omega - \iota_Y\mathcal{L}_X\omega$ for every $X, Y \in \mathfrak{X}(M)$ and $\omega \in \Omega^k(M)$ . I know that $\mathcal{L}_X\iota_Y\omega - \iota_Y\mathcal{L}_X\omega=(\iota_X d\iota_Y\omega+d\iota_X\iota_Y\omega)-(\iota_Y d\iota_X\omega+\iota_Y\iota_X d\omega)$ For the another side $i_{[X,Y]}\omega = i_{L_X(Y)-L_Y(X)}\omega =i_{L_{X(Y)}}\omega-i_{L_{Y(X)}}\omega$ So, how much can I do?","Prove that for every and . I know that For the another side So, how much can I do?","\iota_{[X,Y]}\omega = \mathcal{L}_X\iota_Y\omega - \iota_Y\mathcal{L}_X\omega X, Y \in \mathfrak{X}(M) \omega \in \Omega^k(M) \mathcal{L}_X\iota_Y\omega - \iota_Y\mathcal{L}_X\omega=(\iota_X d\iota_Y\omega+d\iota_X\iota_Y\omega)-(\iota_Y d\iota_X\omega+\iota_Y\iota_X d\omega) i_{[X,Y]}\omega = i_{L_X(Y)-L_Y(X)}\omega =i_{L_{X(Y)}}\omega-i_{L_{Y(X)}}\omega","['differential-geometry', 'manifolds', 'lie-groups', 'smooth-manifolds', 'lie-derivative']"
48,Why is this subset associated to a $2$-tensor open and dense?,Why is this subset associated to a -tensor open and dense?,2,"Let $S$ be a symmetric $(0, 2)$ tensor on a Riemannian manifold $M$ . Define $E_S : M \to \mathbb{Z}$ by $E_S(x) = \left(\text{the number of distinct eigenvalues of } S_x\right)$ . I've seen the following claims in several papers: $M_S \doteq \left\{x \in M \ \vert \ E_s \text{ is constant in a neighbourhood of } x \right\}$ is an open dense subset of $M$ The eigenvalues of $S$ are distinct and smooth in each connected component $U$ of $M_S$ . I'm a having a hard time proving these facts in a rigorous enough manner. It ""feels"" true since in some sense the eigenvalues should be smooth, but I can't see how to formalize this precisely (smooth from where to where? how to prove smoothness?). I'd appreciate any help.","Let be a symmetric tensor on a Riemannian manifold . Define by . I've seen the following claims in several papers: is an open dense subset of The eigenvalues of are distinct and smooth in each connected component of . I'm a having a hard time proving these facts in a rigorous enough manner. It ""feels"" true since in some sense the eigenvalues should be smooth, but I can't see how to formalize this precisely (smooth from where to where? how to prove smoothness?). I'd appreciate any help.","S (0, 2) M E_S : M \to \mathbb{Z} E_S(x) = \left(\text{the number of distinct eigenvalues of } S_x\right) M_S \doteq \left\{x \in M \ \vert \ E_s \text{ is constant in a neighbourhood of } x \right\} M S U M_S","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
49,Intersection of a small Riemannian sphere and a submanifold,Intersection of a small Riemannian sphere and a submanifold,,"Suppose $N$ is a closed submanifold in a Riemannian manifold $(M, g)$ . For $q \in M \setminus N$ , consider the sphere $$S = S\big(q, d(q,N)\big) = \{x \in M | d(q, x) = d(q, N)\},$$ where $d(q,N) = \min \{d(q, y) | y \in N\}$ is the distance from $q$ to $N$ . Clearly, $S \cap N$ consists of precisely those points of $N$ where the distance $d(q,N)$ is attained. Now, it seems very intuitive to me that if $d(q, N)$ is sufficiently small, the intersection is a singleton. My reasoning is that for $d(q,N)$ sufficiently small, the sphere is ""too much curved"", compared to the (compact) submanifold $N$ , which makes sure that the sphere can only ""touch"" $N$ at a single point. Is my reasoning remotely correct? If so, could someone please point out how to make this rigorous, or maybe point to any reference? Thanks in advance. Cheers!","Suppose is a closed submanifold in a Riemannian manifold . For , consider the sphere where is the distance from to . Clearly, consists of precisely those points of where the distance is attained. Now, it seems very intuitive to me that if is sufficiently small, the intersection is a singleton. My reasoning is that for sufficiently small, the sphere is ""too much curved"", compared to the (compact) submanifold , which makes sure that the sphere can only ""touch"" at a single point. Is my reasoning remotely correct? If so, could someone please point out how to make this rigorous, or maybe point to any reference? Thanks in advance. Cheers!","N (M, g) q \in M \setminus N S = S\big(q, d(q,N)\big) = \{x \in M | d(q, x) = d(q, N)\}, d(q,N) = \min \{d(q, y) | y \in N\} q N S \cap N N d(q,N) d(q, N) d(q,N) N N","['differential-geometry', 'riemannian-geometry']"
50,Adjoint functors in analysis on manifolds,Adjoint functors in analysis on manifolds,,"I am doing some work on the topic ""Adjunction"" and my current interest is to give some examples. I've wanted to provide some examples connected to some basic concepts from analysis on manifolds if such exists. What I thought maybe would work is the following: Tangent space functor and cotangent space functor Tensor product functor and multilinear form functor Pushforward and pullback of differential form I am not sure if any of these are indeed adjoint functors, so if they are I would appreciate any help in proving such a thing.","I am doing some work on the topic ""Adjunction"" and my current interest is to give some examples. I've wanted to provide some examples connected to some basic concepts from analysis on manifolds if such exists. What I thought maybe would work is the following: Tangent space functor and cotangent space functor Tensor product functor and multilinear form functor Pushforward and pullback of differential form I am not sure if any of these are indeed adjoint functors, so if they are I would appreciate any help in proving such a thing.",,"['differential-geometry', 'category-theory', 'manifolds', 'smooth-manifolds']"
51,Elementary Differential Geometry - Reparametrization,Elementary Differential Geometry - Reparametrization,,"I started reading ""Elementary Differential Geometry"" by Andrew Pressley. I've been confused about Proposition 1.3.6, which reads: A parametrized curve has a unit-speed reparametrization if and only if it is regular. I've been looking over the converse portion of the proof. We're given a regular curve $\gamma: (\alpha, \beta) \rightarrow \mathbb{R}^n$ . The proof uses arc-length s to set up a reparametrization map $s^{-1} : (\tilde{\alpha}, \tilde{\beta}) \rightarrow (\alpha, \beta)$ After setting up the reparametrization map, however, the proof follows: We take $\phi = s^{-1}$ and let $\tilde{\gamma}$ be the corresponding reparametrization of $\gamma$ , so that $\tilde{\gamma}(s) = \gamma(t)$ . What I do not understand is how we're able to automatically assume the existence of reparametrization. I'm confused how we can ensure that the reparametrization would map to the same image of the original curve. The proof seems to imply that a reparametrization exists if we're given a reparametrization mapping. Another part of the proof that I'm confused about is establishing the arc-length as the unique unit-speed parameter on a regular curve. By the end of the proof, arc-length is confirmed to be the unit-speed parameter. However, I don't really understand its uniqueness as a unit-speed parameter.","I started reading ""Elementary Differential Geometry"" by Andrew Pressley. I've been confused about Proposition 1.3.6, which reads: A parametrized curve has a unit-speed reparametrization if and only if it is regular. I've been looking over the converse portion of the proof. We're given a regular curve . The proof uses arc-length s to set up a reparametrization map After setting up the reparametrization map, however, the proof follows: We take and let be the corresponding reparametrization of , so that . What I do not understand is how we're able to automatically assume the existence of reparametrization. I'm confused how we can ensure that the reparametrization would map to the same image of the original curve. The proof seems to imply that a reparametrization exists if we're given a reparametrization mapping. Another part of the proof that I'm confused about is establishing the arc-length as the unique unit-speed parameter on a regular curve. By the end of the proof, arc-length is confirmed to be the unit-speed parameter. However, I don't really understand its uniqueness as a unit-speed parameter.","\gamma: (\alpha, \beta) \rightarrow \mathbb{R}^n s^{-1} : (\tilde{\alpha}, \tilde{\beta}) \rightarrow (\alpha, \beta) \phi = s^{-1} \tilde{\gamma} \gamma \tilde{\gamma}(s) = \gamma(t)",['differential-geometry']
52,Symplectomorphism taking a Lagrangian to its isotopic copy,Symplectomorphism taking a Lagrangian to its isotopic copy,,"Suppose $\iota_0:L\xrightarrow{}M$ is a compact Lagrangian submanifold in a symplectic manifold $(M,\omega)$ . Let $\iota_t:L\times I\xrightarrow{} M$ be an isotopy and denote $\iota_1(L)$ by $L’$ . I wonder if there is a symplectomorphism $\varphi:M\xrightarrow{}M$ that takes $L$ to $L’$ . Such a diffeomorphism exists by the Isotopy Extension Theorem, but I don’t see a way to turn that into a symplectomorphism. Any negative results are also appreciated.","Suppose is a compact Lagrangian submanifold in a symplectic manifold . Let be an isotopy and denote by . I wonder if there is a symplectomorphism that takes to . Such a diffeomorphism exists by the Isotopy Extension Theorem, but I don’t see a way to turn that into a symplectomorphism. Any negative results are also appreciated.","\iota_0:L\xrightarrow{}M (M,\omega) \iota_t:L\times I\xrightarrow{} M \iota_1(L) L’ \varphi:M\xrightarrow{}M L L’","['differential-geometry', 'reference-request', 'differential-topology', 'symplectic-geometry']"
53,Question about notation of symmetry permutations in tensors,Question about notation of symmetry permutations in tensors,,"In Introduction to Smooth Manifolds, John Lee writes: $$ { }^\sigma \alpha\left(v_1, \ldots, v_k\right)=\alpha\left(v_{\sigma(1)}, \ldots, v_{\sigma(k)}\right) $$ Note that ${ }^\tau\left({ }^\sigma \alpha\right)={ }^{\tau \sigma} \alpha$ , where $\tau \sigma$ represents the composition of $\tau$ and $\sigma$ , that is, $\tau \sigma(i)=\tau(\sigma(i))$ . (This is the reason for putting $\sigma$ before $\alpha$ in the notation $\alpha$ , instead of after it.) Later on, he writes: If $\tau \in S_k$ is any permutation, then $$ \begin{aligned} (\operatorname{Sym} \alpha)\left(v_{\tau(1)}, \ldots, v_{\tau(k)}\right) & =\frac{1}{k !} \sum_{\sigma \in S_k} {}^{\sigma}\alpha\left(v_{\tau(1)}, \ldots, v_{\tau(k)}\right) \\ & =\frac{1}{k !} \sum_{\sigma \in S_k} {}^{\tau \sigma} \alpha\left(v_1, \ldots, v_k\right) \end{aligned} $$ Question: Why is it $\tau\sigma$ and not $\sigma\tau$ ? $\tau$ is being applied first and so it must stand second, right?","In Introduction to Smooth Manifolds, John Lee writes: Note that , where represents the composition of and , that is, . (This is the reason for putting before in the notation , instead of after it.) Later on, he writes: If is any permutation, then Question: Why is it and not ? is being applied first and so it must stand second, right?","
{ }^\sigma \alpha\left(v_1, \ldots, v_k\right)=\alpha\left(v_{\sigma(1)}, \ldots, v_{\sigma(k)}\right)
 { }^\tau\left({ }^\sigma \alpha\right)={ }^{\tau \sigma} \alpha \tau \sigma \tau \sigma \tau \sigma(i)=\tau(\sigma(i)) \sigma \alpha \alpha \tau \in S_k 
\begin{aligned}
(\operatorname{Sym} \alpha)\left(v_{\tau(1)}, \ldots, v_{\tau(k)}\right)
& =\frac{1}{k !} \sum_{\sigma \in S_k} {}^{\sigma}\alpha\left(v_{\tau(1)}, \ldots, v_{\tau(k)}\right) \\
& =\frac{1}{k !} \sum_{\sigma \in S_k} {}^{\tau \sigma} \alpha\left(v_1, \ldots, v_k\right)
\end{aligned}
 \tau\sigma \sigma\tau \tau","['differential-geometry', 'permutations', 'tensor-products', 'tensors']"
54,Proof that the tangent space at the neutral element of a Lie group carries the structure of a Lie algebra,Proof that the tangent space at the neutral element of a Lie group carries the structure of a Lie algebra,,"I am currently dealing with Lie groups. To show that the tangent space at the neutral element of a Lie group carries the structure of a Lie algebra I tried to prove the following Lemma: Let G be a Lie group of dimension n. (i) For every tanget vector $\xi \in T_{e}G$ there exists exactly one left-translation-invariant vector field $X^{\xi} \in \Gamma^{\infty}(TG)$ with $X^{\xi}(e)=\xi$ . It is given by \begin{equation} X^{\xi}(g) = d_{e}L_{g}(\xi) \end{equation} where $L_{g}:G \rightarrow G$ is defined as $L_{g}(x)=gx$ . In particular, the mapping $\xi \mapsto X^{\xi}$ is linear. (ii) The Lie bracket of two left-translation-invariant vector fields is again left-translation-invariant. For left-translation-invariant vector fields we have the following definition: Let $G$ be a Lie group. A vector field $X \in \Gamma^{\infty}(TG)$ is said to be left-translation-invariant, if \begin{equation} d_{p}L_{g}X(p) = X(L_{g}(p)) \quad \text{for all }p,g \in G \end{equation} In other words: $X$ is $L_{g}$ -related to itself. I came up with the following proof: (i) To show the existence of such a vector field, it is sufficient to show that $X^{\xi}(g)=d_{e}L_{g}(\xi)$ is a left-translation-invariant vector field with the property $X^{\xi}(e)=\xi$ . It is \begin{equation} X^{\xi}(e) = d_{e}L_{e}(\xi)=\xi \end{equation} Furthermore it holds \begin{align} d_{p}L_{g}X^{\xi}(p) &= d_{p}L_{g}(d_{e}L_{p}(\xi)) \\ &= d_{e}(L_{g}\circ L_{p})(\xi) \\ &= d_{e}L_{gp}(\xi) \\ &= X^{\xi}(gp) \\  &= X^{\xi}(L_{g}(p)) \end{align} So $X^{\xi}$ is such a vector field. To show the uniqueness, let $Y$ be another left- translation-invariant vector field with $Y(e)=\xi$ . Consider \begin{align} X^{\xi}(p)-Y(p) &= d_{e}L_{p}(X^{\xi}(e))-d_{e}L_{p}(Y(e)) \\ &= d_{e}L_{p}(X^{\xi}(e)-Y(e)) \\ &= d_{e}L_{p}(\xi-\xi) \\ &= d_{e}L_{p}(0) \\ &= 0 \end{align} The linearity of the map $\xi \mapsto X^{\xi}$ follows directly from the linearity of the differential: \begin{equation} X^{\lambda\xi+\eta}(g) = d_{e}L_{g}(\lambda\xi+\eta) = \lambda d_{e}L_{g}(\xi) + d_{e}L_{g}(\eta) = \lambda X^{\xi}(g)+X^{\eta}(g) \end{equation} This proves (i). (ii) follows directly from following statement on Lie brackets Let $F:M \rightarrow N$ be a smooth map between manifolds and let $X_{1}, X_{2} \in \Gamma^{\infty}(TM)$ and $Y_{1}, Y_{2} \in \Gamma^{\infty}(TN)$ be vector fields such that $X_{i}$ is F-related to $Y_{i}$ for $i=1,2$ . Then $[X_{1},X_{2}]$ is F-related to $[Y_{1},Y_{2}]$ . Although I think the proof is correct, I would be grateful if someone would look at it again.","I am currently dealing with Lie groups. To show that the tangent space at the neutral element of a Lie group carries the structure of a Lie algebra I tried to prove the following Lemma: Let G be a Lie group of dimension n. (i) For every tanget vector there exists exactly one left-translation-invariant vector field with . It is given by where is defined as . In particular, the mapping is linear. (ii) The Lie bracket of two left-translation-invariant vector fields is again left-translation-invariant. For left-translation-invariant vector fields we have the following definition: Let be a Lie group. A vector field is said to be left-translation-invariant, if In other words: is -related to itself. I came up with the following proof: (i) To show the existence of such a vector field, it is sufficient to show that is a left-translation-invariant vector field with the property . It is Furthermore it holds So is such a vector field. To show the uniqueness, let be another left- translation-invariant vector field with . Consider The linearity of the map follows directly from the linearity of the differential: This proves (i). (ii) follows directly from following statement on Lie brackets Let be a smooth map between manifolds and let and be vector fields such that is F-related to for . Then is F-related to . Although I think the proof is correct, I would be grateful if someone would look at it again.","\xi \in T_{e}G X^{\xi} \in \Gamma^{\infty}(TG) X^{\xi}(e)=\xi \begin{equation}
X^{\xi}(g) = d_{e}L_{g}(\xi)
\end{equation} L_{g}:G \rightarrow G L_{g}(x)=gx \xi \mapsto X^{\xi} G X \in \Gamma^{\infty}(TG) \begin{equation} d_{p}L_{g}X(p) = X(L_{g}(p)) \quad \text{for all }p,g \in G \end{equation} X L_{g} X^{\xi}(g)=d_{e}L_{g}(\xi) X^{\xi}(e)=\xi \begin{equation} X^{\xi}(e) = d_{e}L_{e}(\xi)=\xi \end{equation} \begin{align} d_{p}L_{g}X^{\xi}(p) &= d_{p}L_{g}(d_{e}L_{p}(\xi)) \\
&= d_{e}(L_{g}\circ L_{p})(\xi) \\
&= d_{e}L_{gp}(\xi) \\
&= X^{\xi}(gp) \\ 
&= X^{\xi}(L_{g}(p)) \end{align} X^{\xi} Y Y(e)=\xi \begin{align}
X^{\xi}(p)-Y(p) &= d_{e}L_{p}(X^{\xi}(e))-d_{e}L_{p}(Y(e)) \\
&= d_{e}L_{p}(X^{\xi}(e)-Y(e)) \\
&= d_{e}L_{p}(\xi-\xi) \\
&= d_{e}L_{p}(0) \\
&= 0
\end{align} \xi \mapsto X^{\xi} \begin{equation} X^{\lambda\xi+\eta}(g) = d_{e}L_{g}(\lambda\xi+\eta) = \lambda d_{e}L_{g}(\xi) + d_{e}L_{g}(\eta) = \lambda X^{\xi}(g)+X^{\eta}(g) \end{equation} F:M \rightarrow N X_{1}, X_{2} \in \Gamma^{\infty}(TM) Y_{1}, Y_{2} \in \Gamma^{\infty}(TN) X_{i} Y_{i} i=1,2 [X_{1},X_{2}] [Y_{1},Y_{2}]","['differential-geometry', 'solution-verification', 'lie-groups', 'lie-algebras']"
55,Restricted Cotangent Bundle,Restricted Cotangent Bundle,,"Let $(\mathcal{M},g)$ be a four-dimensional Lorentzian manifold and $\Sigma$ a Riemannian hypersurface such that $\mathcal{M}=\mathbb{R}\times\Sigma$ . How to show (if true) that $$T^{\ast}\mathcal{M}\vert_{\Sigma}\cong (\Sigma\times\mathbb{R})\oplus T^{\ast}\Sigma,$$ where $\Sigma\times\mathbb{R}$ denotes the trivial bundle. My motivation for this comes as follows: Lets take a section of $T^{\ast}\mathcal{M}$ , which is a $1$ -form $A=A_{\mu}\mathrm{d}x^{\mu}$ . Then, I can naturally write $A=A_{0}\mathrm{d}t+A_{\Sigma}$ (where $t$ is the ""time""-coordinate corresponding to $\mathbb{R}$ ), where $A_{0}\in C^{\infty}(\mathcal{M})$ and $A_{\Sigma}$ is a ""time-dependent"" $1$ -form on $\Sigma$ , i.e. a one-parameter family in $\Omega^{1}(\Sigma)$ labelled by the time-parameter $t$ . Now, if I restrict this section to $\Sigma$ , then I naturally get a map $$\Gamma^{\infty}(\Sigma,T^{\ast}\mathcal{M})=\Gamma^{\infty}(T^{\ast}\mathcal{M}\vert_{\Sigma})\xrightarrow{\cong}C^{\infty}(\Sigma)\oplus \Gamma^{\infty}(T^{\ast}\Sigma)\\ A=A_{0}\mathrm{d}t+A_{\Sigma}\mapsto (A_{0},A_{\Sigma}),$$ so I would expect the above splitting on the level of boundles.","Let be a four-dimensional Lorentzian manifold and a Riemannian hypersurface such that . How to show (if true) that where denotes the trivial bundle. My motivation for this comes as follows: Lets take a section of , which is a -form . Then, I can naturally write (where is the ""time""-coordinate corresponding to ), where and is a ""time-dependent"" -form on , i.e. a one-parameter family in labelled by the time-parameter . Now, if I restrict this section to , then I naturally get a map so I would expect the above splitting on the level of boundles.","(\mathcal{M},g) \Sigma \mathcal{M}=\mathbb{R}\times\Sigma T^{\ast}\mathcal{M}\vert_{\Sigma}\cong (\Sigma\times\mathbb{R})\oplus T^{\ast}\Sigma, \Sigma\times\mathbb{R} T^{\ast}\mathcal{M} 1 A=A_{\mu}\mathrm{d}x^{\mu} A=A_{0}\mathrm{d}t+A_{\Sigma} t \mathbb{R} A_{0}\in C^{\infty}(\mathcal{M}) A_{\Sigma} 1 \Sigma \Omega^{1}(\Sigma) t \Sigma \Gamma^{\infty}(\Sigma,T^{\ast}\mathcal{M})=\Gamma^{\infty}(T^{\ast}\mathcal{M}\vert_{\Sigma})\xrightarrow{\cong}C^{\infty}(\Sigma)\oplus \Gamma^{\infty}(T^{\ast}\Sigma)\\ A=A_{0}\mathrm{d}t+A_{\Sigma}\mapsto (A_{0},A_{\Sigma}),","['differential-geometry', 'riemannian-geometry', 'differential-topology', 'differential-forms', 'vector-bundles']"
56,Relation between flow and exponential map,Relation between flow and exponential map,,"In Proposition 1.7.12 in Hamilton's Mathematical Gauge Theory he states Let $G$ be a Lie group and $X$ a left-invariant vector field. Then its flow $\phi_t(p)$ through a point $p \in G$ is defined for all $t \in \mathbb{R}$ , $$\phi:\mathbb{R} \times G \rightarrow G\\ (t,p) \mapsto \phi_t(p),$$ and given by $$\phi_t(p) = p \cdot \exp tX = R_{\exp tX}(p) = L_p (\exp tX).$$ In his notation $L_x$ and $R_x$ are left and right multiplication by $x$ , and $D_e$ is the differential evaluated at $e$ . His proof is Define $\phi_t(p)$ for all $t \in \mathbb{R}$ by the right-hand side. It is clear that $$\phi_0(p) = p \cdot \exp(0) = p.$$ Furthermore, $$\frac{d}{dt}\Big|_{t = s} \phi_t(p) =   \frac{d}{d\tau} \Big|_{\tau = 0} L_p(\exp sX \cdot \exp \tau X)  \\ = D_e L_{p \exp sX}(X_e) \\ = X_{p \exp s X}  \\ = X_{\phi_s(p)},$$ since $X$ is left-invariant. This implies the claim by uniqueness of solutions of ordinary differential equations. I am having some trouble understanding what he did in the first two lines/equalities. The first seems to be a change of variables. The second appears to be using the chain rule, but I am not seeing how he obtains $X_e$ or why he is evaluating the differential at $e$ .","In Proposition 1.7.12 in Hamilton's Mathematical Gauge Theory he states Let be a Lie group and a left-invariant vector field. Then its flow through a point is defined for all , and given by In his notation and are left and right multiplication by , and is the differential evaluated at . His proof is Define for all by the right-hand side. It is clear that Furthermore, since is left-invariant. This implies the claim by uniqueness of solutions of ordinary differential equations. I am having some trouble understanding what he did in the first two lines/equalities. The first seems to be a change of variables. The second appears to be using the chain rule, but I am not seeing how he obtains or why he is evaluating the differential at .","G X \phi_t(p) p \in G t \in \mathbb{R} \phi:\mathbb{R} \times G \rightarrow G\\ (t,p) \mapsto \phi_t(p), \phi_t(p) = p \cdot \exp tX = R_{\exp tX}(p) = L_p (\exp tX). L_x R_x x D_e e \phi_t(p) t \in \mathbb{R} \phi_0(p) = p \cdot \exp(0) = p. \frac{d}{dt}\Big|_{t = s} \phi_t(p) = 
 \frac{d}{d\tau} \Big|_{\tau = 0} L_p(\exp sX \cdot \exp \tau X)  \\ = D_e L_{p \exp sX}(X_e) \\ = X_{p \exp s X}  \\ = X_{\phi_s(p)}, X X_e e","['differential-geometry', 'lie-groups', 'smooth-manifolds', 'vector-fields', 'differential']"
57,Why must integral manifolds be immersed submanifolds?,Why must integral manifolds be immersed submanifolds?,,"Given a manifold $M$ and a distribution $D \subset TM$ , an integral manifold of $D$ is defined as a nonempty immersed submanifold $N \subset M$ such that $T_pN = D_p$ for all $p \in N$ . Why are we not able to define an integral manifold as an embedded submanifold? My guess is that embeddings are too strict, but is there an intuitive geometric reason behind this?","Given a manifold and a distribution , an integral manifold of is defined as a nonempty immersed submanifold such that for all . Why are we not able to define an integral manifold as an embedded submanifold? My guess is that embeddings are too strict, but is there an intuitive geometric reason behind this?",M D \subset TM D N \subset M T_pN = D_p p \in N,"['differential-geometry', 'smooth-manifolds', 'submanifold']"
58,Diffeomorphism between complex hyperbolic space and unit ball,Diffeomorphism between complex hyperbolic space and unit ball,,"Let $h$ be the bilinear map: $$h:\mathbb{C}^{n+1}\times \mathbb{C}^{n+1}\to \mathbb{C},\ \ \ \ (z,w)\mapsto -z_0\overline{w_0}+\sum_{i>0} z_i\overline{w_i}$$ and let $\mathfrak{I}:h(z,z)=-1$ . There is an obvious left action of $S^1$ on $\mathfrak{I}$ and I wanna prove that $\mathfrak{I}/S^1$ is diffeomorphic to the open ball in $\mathbb{C}^n$ . My attempt It's pretty clear that every element of $\mathfrak{I}/S^1$ can be written (almost) uniquely as: $$z=(r_0,r_1e^{i\theta_1},...,r_ne^{i\theta_n})$$ so my idea was to define something like $z\mapsto (r_1,...,r_n,\theta_1,...,\theta_n)$ , but this clearly works only if we suppose that $r_i\neq 0$ for every $i>0$ (otherwise things get a bit messy, because $\theta_i$ is not even well defined). Is this the right track?","Let be the bilinear map: and let . There is an obvious left action of on and I wanna prove that is diffeomorphic to the open ball in . My attempt It's pretty clear that every element of can be written (almost) uniquely as: so my idea was to define something like , but this clearly works only if we suppose that for every (otherwise things get a bit messy, because is not even well defined). Is this the right track?","h h:\mathbb{C}^{n+1}\times \mathbb{C}^{n+1}\to \mathbb{C},\ \ \ \ (z,w)\mapsto -z_0\overline{w_0}+\sum_{i>0} z_i\overline{w_i} \mathfrak{I}:h(z,z)=-1 S^1 \mathfrak{I} \mathfrak{I}/S^1 \mathbb{C}^n \mathfrak{I}/S^1 z=(r_0,r_1e^{i\theta_1},...,r_ne^{i\theta_n}) z\mapsto (r_1,...,r_n,\theta_1,...,\theta_n) r_i\neq 0 i>0 \theta_i","['differential-geometry', 'riemannian-geometry', 'complex-geometry', 'hyperbolic-geometry', 'kahler-manifolds']"
59,Equivalence of two definitions of Laplace-Beltrami on differential forms,Equivalence of two definitions of Laplace-Beltrami on differential forms,,"I know of two ways of defining the (negative - depending on your convention) Laplace-Beltrami operator on the differential forms of a compact, orientable Riemannian manifold $M$ . The Levi-Civita connection extends to a connection tensor bundles by Leibniz rule $\nabla(a\otimes b)=\nabla a\otimes b + (-1)^aa\otimes\nabla b$ (and similarly for wedges) and by defining it on $1$ -forms by $$(\nabla\alpha)(X,Y) = \nabla_X\alpha(Y)-\nabla_Y\alpha(X)-\alpha([X,Y])$$ (is this correct?). In particular, we have a connection $\nabla:\Omega^k(M)\to\Gamma(M,T^*M\otimes\Lambda^kM)$ and another $\nabla:\Gamma(M,T^*M\otimes\Lambda^kM)\to\Gamma(M,T^*M^{\otimes 2}\otimes\Lambda^kM)$ . We can now concatenate them and take the negative of the trace with respect to the metric $$\Delta=-tr_g(\nabla\nabla).$$ Using Hodge theory, we can define $\Delta=-(dd^\star+d^\star d)$ . Is there an easy way to see whether these two definitions are equal (possibly without computing in coordinates)? A reference where it is done would be awesome!","I know of two ways of defining the (negative - depending on your convention) Laplace-Beltrami operator on the differential forms of a compact, orientable Riemannian manifold . The Levi-Civita connection extends to a connection tensor bundles by Leibniz rule (and similarly for wedges) and by defining it on -forms by (is this correct?). In particular, we have a connection and another . We can now concatenate them and take the negative of the trace with respect to the metric Using Hodge theory, we can define . Is there an easy way to see whether these two definitions are equal (possibly without computing in coordinates)? A reference where it is done would be awesome!","M \nabla(a\otimes b)=\nabla a\otimes b + (-1)^aa\otimes\nabla b 1 (\nabla\alpha)(X,Y) = \nabla_X\alpha(Y)-\nabla_Y\alpha(X)-\alpha([X,Y]) \nabla:\Omega^k(M)\to\Gamma(M,T^*M\otimes\Lambda^kM) \nabla:\Gamma(M,T^*M\otimes\Lambda^kM)\to\Gamma(M,T^*M^{\otimes 2}\otimes\Lambda^kM) \Delta=-tr_g(\nabla\nabla). \Delta=-(dd^\star+d^\star d)","['differential-geometry', 'laplacian', 'hodge-theory']"
60,Is there a canonical coordinate representation for Lie algebras?,Is there a canonical coordinate representation for Lie algebras?,,"If we are given a Lie algebra of vector fields $\{X_i\}_{i = 1} ^N$ on a manifold $M ^n$ , is it possible to determine in local coordinates the $X_i$ 's if we know the value of $m := \dim \text{span} \{X_i\}_{i = 1} ^N$ ? As a first example, consider $N= 2 = m$ , and $[X_1, X_2] = 0$ . Then by Frobenius we can find coordinates s.t. $X_i = \partial_i$ , so in this case it is indeed possible to determine $X_1$ and $X_2$ . If we had instead assumed that $[X_1, X_2] = X_1$ , Frobenius allows us to represent $X_1 = \partial_1$ and $X_2 = a \partial_1 + b \partial_2$ . The structure equations then show that $a = x ^1 + c(x ^2)$ and $b = b(x ^2)$ . Changing coordinates via \begin{align*}   x ^1 &= y ^1 + f(y ^2),   \\   x ^2 &= g(y ^2) \end{align*} transforms $X_1$ and $X_2$ into \begin{align*}   \tilde{X}_1 &= \partial_1,   \\   \tilde{X}_2 &= (y ^1 + f(y ^2) + c(g(y ^2)) + f'(y ^2)b(g(y ^2)))\partial_1 + b(g(y ^2))g'(y ^2) \partial_2. \end{align*} Since $X_1$ and $X_2$ are everywhere independent, $b$ is never zero, so on any small enough interval we can solve $g'(y ^2) = 1/b(g(y ^2))$ and then find $f$ solving the linear ODE $$ b(g(y ^2))f'(y ^2) + f(y ^2) + c(g(y ^2)) = 0, $$ implying $\tilde{X}_2 = y ^1 \partial_1 + \partial_2$ . In other words, for $N = 2 = m$ , we can indeed determine the $X_i$ 's from just the structure equations. However, consider the case $N = 3$ , $m = 2$ , and \begin{align*}   [X_1, X_2] &= X_3,   \\   [X_2, X_3] &= X_1,   \\   [X_3, X_1] &= X_2. \end{align*} By the Frobenius theorem, we can find a coordinate system $(x ^i)$ s.t. $$ X_1 = \partial_1, \quad X_2 = a \partial_1 + b \partial_2, \quad X_3 = c \partial_1 + d \partial_2. $$ The structure equations $[X_1, X_2] = X_3$ and $[X_1, X_3] = -X_2$ force \begin{align*}   \partial_1 a &= c, \quad -\partial_1 c = a \Rightarrow \partial_1 ^2                  a + a = 0,   \\   \partial_1 b &= d, \quad - \partial_1 d = b \Rightarrow \partial_1 ^2                  b + b = 0, \end{align*} from which we deduce that $a = a_1 \sin(x ^1) + a_2 \cos(x ^1)$ and $b = b_1 \sin(x ^1) + b_2 \cos(x ^1)$ . Plugging this into $[X_2, X_3] = X_1$ yields \begin{align*}   b_2 \partial_2a_1-b_1 \partial_2a_2-a_1^2-a_2^2&=1,                                                        \\  b_2 (\partial_2b_1-a_2)-b_1    (a_1+\partial_2b_2) &= 0. \end{align*} One can play around with different guesses for $a_1$ and $b_1$ to see that there are a wealth of solutions to these equations. Since there are no derivatives $\partial_{x ^i}$ with $i > 2$ , we further have great freedom in choosing the ''constants of integration'', which only results in even more families of solutions. It is not obvious how to choose new coordinates which ensure all of these families are equivalent like in the previous example. Thus, I am left with the following Question What additional information on the $X_i$ 's would be required to single out a canonical solution in general or ensure all solutions are equivalent (e.g. via a change of variables)?","If we are given a Lie algebra of vector fields on a manifold , is it possible to determine in local coordinates the 's if we know the value of ? As a first example, consider , and . Then by Frobenius we can find coordinates s.t. , so in this case it is indeed possible to determine and . If we had instead assumed that , Frobenius allows us to represent and . The structure equations then show that and . Changing coordinates via transforms and into Since and are everywhere independent, is never zero, so on any small enough interval we can solve and then find solving the linear ODE implying . In other words, for , we can indeed determine the 's from just the structure equations. However, consider the case , , and By the Frobenius theorem, we can find a coordinate system s.t. The structure equations and force from which we deduce that and . Plugging this into yields One can play around with different guesses for and to see that there are a wealth of solutions to these equations. Since there are no derivatives with , we further have great freedom in choosing the ''constants of integration'', which only results in even more families of solutions. It is not obvious how to choose new coordinates which ensure all of these families are equivalent like in the previous example. Thus, I am left with the following Question What additional information on the 's would be required to single out a canonical solution in general or ensure all solutions are equivalent (e.g. via a change of variables)?","\{X_i\}_{i = 1} ^N M ^n X_i m := \dim \text{span} \{X_i\}_{i = 1} ^N N= 2 = m [X_1, X_2] = 0 X_i = \partial_i X_1 X_2 [X_1, X_2] = X_1 X_1 = \partial_1 X_2 = a \partial_1 + b \partial_2 a = x ^1 + c(x ^2) b = b(x
^2) \begin{align*}
  x ^1 &= y ^1 + f(y ^2),
  \\
  x ^2 &= g(y ^2)
\end{align*} X_1 X_2 \begin{align*}
  \tilde{X}_1 &= \partial_1,
  \\
  \tilde{X}_2 &= (y ^1 + f(y ^2) + c(g(y ^2)) + f'(y ^2)b(g(y ^2)))\partial_1 + b(g(y ^2))g'(y ^2) \partial_2.
\end{align*} X_1 X_2 b g'(y ^2) = 1/b(g(y ^2)) f 
b(g(y ^2))f'(y ^2) + f(y ^2) + c(g(y ^2)) = 0,
 \tilde{X}_2 = y ^1 \partial_1 + \partial_2 N = 2 = m X_i N = 3 m = 2 \begin{align*}
  [X_1, X_2] &= X_3,
  \\
  [X_2, X_3] &= X_1,
  \\
  [X_3, X_1] &= X_2.
\end{align*} (x ^i) 
X_1 = \partial_1, \quad X_2 = a \partial_1 + b \partial_2, \quad X_3 = c \partial_1 + d \partial_2.
 [X_1, X_2] = X_3 [X_1, X_3] = -X_2 \begin{align*}
  \partial_1 a &= c, \quad -\partial_1 c = a \Rightarrow \partial_1 ^2
                 a + a = 0,
  \\
  \partial_1 b &= d, \quad - \partial_1 d = b \Rightarrow \partial_1 ^2
                 b + b = 0,
\end{align*} a = a_1 \sin(x ^1) + a_2 \cos(x ^1) b = b_1 \sin(x ^1) + b_2 \cos(x ^1) [X_2, X_3] = X_1 \begin{align*}
  b_2 \partial_2a_1-b_1 \partial_2a_2-a_1^2-a_2^2&=1,
                                                       \\
 b_2 (\partial_2b_1-a_2)-b_1
   (a_1+\partial_2b_2) &= 0.
\end{align*} a_1 b_1 \partial_{x ^i} i > 2 X_i","['differential-geometry', 'lie-algebras', 'vector-fields']"
61,How to exponentiate the vector field $v$?,How to exponentiate the vector field ?,v,"i didn't succed to exponentiate these vector field $$\boxed{v=\sqrt{x}\sqrt{y}\frac{\partial}{\partial x}-\sqrt{x}\sqrt{y}\frac{\partial}{\partial y}+2b\sqrt{x}\sqrt{y}u\frac{\partial}{\partial u}}$$ where $x,y,t$ are independents variables and $u$ is an dependant variable . this vector field is one of the basis element of a Lie algebra of symmetry associated to a certain pde .the solution of the pde is of the form $u(x,y,t)$ Remark : i succeded to exponentiate the vector field $$w=\sqrt{x}\sqrt{y}\frac{\partial}{\partial x}-\sqrt{x}\sqrt{y}\frac{\partial}{\partial y}$$ it gives $$\exp \left(\varepsilon w\right)(x,y, t, u)=(\tilde{x},\tilde{y},\tilde{t}, \tilde{u})=\left(\sqrt{x}\sqrt{y}\sin(\varepsilon)+(\frac{x-y}{2})\cos(\varepsilon)+(\frac{x+y}{2}),-\sqrt{x}\sqrt{y}\sin(\varepsilon)-(\frac{x-y}{2})\cos(\varepsilon)-(\frac{x+y}{2}),t,u\right) $$ where $exp : \mathfrak{g}\longrightarrow G$ and $\mathfrak{g}$ is the Lie algebra of $G$ . to exponentiate a vector field of the form $\mathbf{v}=\displaystyle{\sum_{k=1}^{p}\xi_{k}(x,u)\frac{\partial}{\partial x_{k}}+\sum_{i=1}^{q}\phi_{i}(x,u)\frac{\partial}{\partial u_{i}}}$ we solve the system of odes $ \displaystyle{\frac{d\tilde{x_{i}}}{d\varepsilon}=\xi_{i}(\tilde{x_{i}})\,\,,\,\, \frac{d\tilde{u}}{d\varepsilon}=\phi(\tilde{x},\tilde{t},\tilde{y})}$ with initial conditions $\tilde{x_{i}}(0)=x_{i}$ , $\tilde{u}(0)=u$ Or we can just develop this Lie series for the flow, given by $$ \exp (\varepsilon \mathbf{v}) \cdot x = x+\varepsilon \xi(x)+\frac{\varepsilon^2}{2} \mathbf{v}(\xi)(x)+\cdots=\sum_{k=0}^{\infty} \frac{\varepsilon^k}{k !} \mathbf{v}^k(x) $$ where $\xi=\left(\xi^1, \ldots, \xi^m\right), \mathbf{v}(\xi)=\left(\mathbf{v}\left(\xi^1\right), \ldots, \mathbf{v}\left(\xi^m\right)\right)$ , I tried to develop the serie but it's getting more and more complicated from order 3 i guess Thanks for the help !:)","i didn't succed to exponentiate these vector field where are independents variables and is an dependant variable . this vector field is one of the basis element of a Lie algebra of symmetry associated to a certain pde .the solution of the pde is of the form Remark : i succeded to exponentiate the vector field it gives where and is the Lie algebra of . to exponentiate a vector field of the form we solve the system of odes with initial conditions , Or we can just develop this Lie series for the flow, given by where , I tried to develop the serie but it's getting more and more complicated from order 3 i guess Thanks for the help !:)","\boxed{v=\sqrt{x}\sqrt{y}\frac{\partial}{\partial x}-\sqrt{x}\sqrt{y}\frac{\partial}{\partial y}+2b\sqrt{x}\sqrt{y}u\frac{\partial}{\partial u}} x,y,t u u(x,y,t) w=\sqrt{x}\sqrt{y}\frac{\partial}{\partial x}-\sqrt{x}\sqrt{y}\frac{\partial}{\partial y} \exp \left(\varepsilon w\right)(x,y, t, u)=(\tilde{x},\tilde{y},\tilde{t}, \tilde{u})=\left(\sqrt{x}\sqrt{y}\sin(\varepsilon)+(\frac{x-y}{2})\cos(\varepsilon)+(\frac{x+y}{2}),-\sqrt{x}\sqrt{y}\sin(\varepsilon)-(\frac{x-y}{2})\cos(\varepsilon)-(\frac{x+y}{2}),t,u\right)  exp : \mathfrak{g}\longrightarrow G \mathfrak{g} G \mathbf{v}=\displaystyle{\sum_{k=1}^{p}\xi_{k}(x,u)\frac{\partial}{\partial x_{k}}+\sum_{i=1}^{q}\phi_{i}(x,u)\frac{\partial}{\partial u_{i}}}  \displaystyle{\frac{d\tilde{x_{i}}}{d\varepsilon}=\xi_{i}(\tilde{x_{i}})\,\,,\,\, \frac{d\tilde{u}}{d\varepsilon}=\phi(\tilde{x},\tilde{t},\tilde{y})} \tilde{x_{i}}(0)=x_{i} \tilde{u}(0)=u 
\exp (\varepsilon \mathbf{v}) \cdot x = x+\varepsilon \xi(x)+\frac{\varepsilon^2}{2} \mathbf{v}(\xi)(x)+\cdots=\sum_{k=0}^{\infty} \frac{\varepsilon^k}{k !} \mathbf{v}^k(x)
 \xi=\left(\xi^1, \ldots, \xi^m\right), \mathbf{v}(\xi)=\left(\mathbf{v}\left(\xi^1\right), \ldots, \mathbf{v}\left(\xi^m\right)\right)","['differential-geometry', 'lie-groups', 'lie-algebras', 'exponentiation', 'vector-fields']"
62,Induced connections,Induced connections,,"Let $E\rightarrow M$ be a be a vector bundle. From this bundle, we can construct various other bundles such as $E^*$ , and $E\otimes E$ . I know that if we have a connection, or covariant derivative $\nabla:\Gamma(E)\rightarrow \Omega^1(M,E)$ , then there are induced connection on these bundles given by: $$(\nabla^*\Xi)(\Phi)=\nabla(\Xi(\Phi))-\Xi(\nabla\Phi)$$ $$\nabla^\otimes(\Phi\otimes \Psi)=\nabla\Phi\otimes \Psi+\Phi\otimes\nabla\Psi$$ where $\Xi\in\Gamma(E^*)$ , and $\Phi,\Psi\in \Gamma(E)$ . My question is then this, I can show that these are indeed connections on the aforementioned vector bundles, but is there a reason, other than verifying some version of the product rule, that these should be the induced connections on the vector bundles $E^*$ and $E\otimes E$ ? In other words, are these connections somehow uniquely/naturally/canonically determined given $\nabla$ ? It seems these definitions are pulled out of thin air, while, for example, the definition of the Lie derivative naturally extends to deducing relations such as the ones above.","Let be a be a vector bundle. From this bundle, we can construct various other bundles such as , and . I know that if we have a connection, or covariant derivative , then there are induced connection on these bundles given by: where , and . My question is then this, I can show that these are indeed connections on the aforementioned vector bundles, but is there a reason, other than verifying some version of the product rule, that these should be the induced connections on the vector bundles and ? In other words, are these connections somehow uniquely/naturally/canonically determined given ? It seems these definitions are pulled out of thin air, while, for example, the definition of the Lie derivative naturally extends to deducing relations such as the ones above.","E\rightarrow M E^* E\otimes E \nabla:\Gamma(E)\rightarrow \Omega^1(M,E) (\nabla^*\Xi)(\Phi)=\nabla(\Xi(\Phi))-\Xi(\nabla\Phi) \nabla^\otimes(\Phi\otimes \Psi)=\nabla\Phi\otimes \Psi+\Phi\otimes\nabla\Psi \Xi\in\Gamma(E^*) \Phi,\Psi\in \Gamma(E) E^* E\otimes E \nabla","['differential-geometry', 'differential-topology', 'smooth-manifolds', 'vector-bundles', 'connections']"
63,Jacobian of a 1-form on a manifold,Jacobian of a 1-form on a manifold,,"Let $X$ be a smooth vector field on a manifold $M$ . The Jacobian of $X$ at a critical point $x^*$ is the linear map $$X'(x^*): T_{x^*}M \rightarrow T_{x^*}M$$ where $T_{x^*}M$ is the tangent space to $M$ at $x^*$ , defined by $$X'(x^*) \cdot u = \frac{d}{dt} \left( \text{d}_{x^*}\Theta_t \cdot u \right)|_{t=0}$$ for any $u \in T_{x^*}M$ . Here $\Theta_t: M \rightarrow M$ is the flow of $X$ and $\text{d}_{x^*}$ is the differential, so $\text{d}_{x^*}\Theta_t$ is a linear map of $T_{x^*}$ to itself, since $x^*$ is a critical point: $$\text{d}_{x^*}\Theta_t: T_{x^*}M \rightarrow T_{\Theta_t(x^*)}M = T_{x^*}M$$ Chosen a local chart at $x^*$ , the matrix representation of this linear map is the usual Jacobian matrix: $$\left[ X'(x^*) \right]_{ij} = \left( \frac{\partial X^i}{\partial x^j} \right)_{x = x^*}$$ See e.g. Abraham-Marsden (1978), Foundations of mechanics, p. 72 (page attached below). Question Is there an analogue coordinates-independent definition for the ""Jacobian"" of a 1-form $\alpha$ on a manifold $M$ as a linear map on a cotangent space and such that the local representative is the usual Jacobian matrix?","Let be a smooth vector field on a manifold . The Jacobian of at a critical point is the linear map where is the tangent space to at , defined by for any . Here is the flow of and is the differential, so is a linear map of to itself, since is a critical point: Chosen a local chart at , the matrix representation of this linear map is the usual Jacobian matrix: See e.g. Abraham-Marsden (1978), Foundations of mechanics, p. 72 (page attached below). Question Is there an analogue coordinates-independent definition for the ""Jacobian"" of a 1-form on a manifold as a linear map on a cotangent space and such that the local representative is the usual Jacobian matrix?",X M X x^* X'(x^*): T_{x^*}M \rightarrow T_{x^*}M T_{x^*}M M x^* X'(x^*) \cdot u = \frac{d}{dt} \left( \text{d}_{x^*}\Theta_t \cdot u \right)|_{t=0} u \in T_{x^*}M \Theta_t: M \rightarrow M X \text{d}_{x^*} \text{d}_{x^*}\Theta_t T_{x^*} x^* \text{d}_{x^*}\Theta_t: T_{x^*}M \rightarrow T_{\Theta_t(x^*)}M = T_{x^*}M x^* \left[ X'(x^*) \right]_{ij} = \left( \frac{\partial X^i}{\partial x^j} \right)_{x = x^*} \alpha M,"['differential-geometry', 'reference-request', 'differential-forms', 'vector-fields', 'jacobian']"
64,What does it mean for a 1-form to be orthogonal to a 2-form?,What does it mean for a 1-form to be orthogonal to a 2-form?,,"In Baez & Munian's book Gauge Fields, Knots, and Gravity , when introducing the Hodge star operator, they say At any point $p$ in a 3-dimensional Riemannian manifold $M$ , the Hodge star operator maps a 1-form $\nu$ , which we draw as a little arrow, into a 2-form $\omega \wedge \mu$ that corresponds to an area element that is orthogonal to $\nu$ . Conversely, it maps $\omega \wedge \mu$ to $\nu$ . In general, in $n$ dimensions the Hodge star operator maps $p$ -forms to $(n-p)$ -forms in a very similar way, taking each ' $p$ -dimensional area element' to an orthogonal ' $(n-p)$ -dimensional area element'. I am unclear on what they mean by orthogonality here, I assume they mean the inner product $\langle \nu, \omega \wedge \mu \rangle = 0$ . Earlier they defined what it means to take the inner product of two differential forms of the same degree, but in the above passage they are different degrees. What does it mean for a 1-form to be orthogonal to a 2-form?","In Baez & Munian's book Gauge Fields, Knots, and Gravity , when introducing the Hodge star operator, they say At any point in a 3-dimensional Riemannian manifold , the Hodge star operator maps a 1-form , which we draw as a little arrow, into a 2-form that corresponds to an area element that is orthogonal to . Conversely, it maps to . In general, in dimensions the Hodge star operator maps -forms to -forms in a very similar way, taking each ' -dimensional area element' to an orthogonal ' -dimensional area element'. I am unclear on what they mean by orthogonality here, I assume they mean the inner product . Earlier they defined what it means to take the inner product of two differential forms of the same degree, but in the above passage they are different degrees. What does it mean for a 1-form to be orthogonal to a 2-form?","p M \nu \omega \wedge \mu \nu \omega \wedge \mu \nu n p (n-p) p (n-p) \langle \nu, \omega \wedge \mu \rangle = 0","['differential-geometry', 'riemannian-geometry', 'differential-forms', 'hodge-theory']"
65,Ham sandwich theorem.,Ham sandwich theorem.,,"Recently, I have been reading the Borsuk-Ulam theorem from Hatcher's algebraic topology book. In this book, there is an exercise as follows. Let $A_1, A_2, A_3$ be compact sets in $\mathbb{R}^3$ . Use the Borsuk–Ulam theorem to show that there is one plane $P \subset \mathbb{R}^3$ that simultaneously divides each $A_i$ into two pieces of equal measure. I have some doubts regarding the above statement; each $A_i$ divided equal measure this part I did not understand properly. $\mathbb{R}^3$ has its won Lebesgue measure say $\mu$ if I take one of $A_i$ suppose $A_1$ say a unit circle $S^1$ which is compact and $\mu(S^1)=0$ then no need to divided by two equal measure. Is this statement say when I am taking one of them as the lesser dimension, we must take the Lebesgue measure concerning that dimension? Can anyone suggest books or good references where I can find the statement of the ham sandwich theorem and its proofs?","Recently, I have been reading the Borsuk-Ulam theorem from Hatcher's algebraic topology book. In this book, there is an exercise as follows. Let be compact sets in . Use the Borsuk–Ulam theorem to show that there is one plane that simultaneously divides each into two pieces of equal measure. I have some doubts regarding the above statement; each divided equal measure this part I did not understand properly. has its won Lebesgue measure say if I take one of suppose say a unit circle which is compact and then no need to divided by two equal measure. Is this statement say when I am taking one of them as the lesser dimension, we must take the Lebesgue measure concerning that dimension? Can anyone suggest books or good references where I can find the statement of the ham sandwich theorem and its proofs?","A_1, A_2, A_3 \mathbb{R}^3 P \subset \mathbb{R}^3 A_i A_i \mathbb{R}^3 \mu A_i A_1 S^1 \mu(S^1)=0","['differential-geometry', 'probability-distributions', 'algebraic-topology', 'lebesgue-measure', 'geometric-measure-theory']"
66,Are Functions Smooth Sections?,Are Functions Smooth Sections?,,"In differential geometry we often identify $\Omega^0(M)$ with the smooth functions on a smooth manifold $M$ . But for every $i>0$ we know that: $$\Omega^i(M)=\Gamma(\Lambda^i(T^*M))$$ I imagine with $i=0$ then $\Lambda^i(T^*M)$ would be the trivial line bundle since constant functions exist on $M$ . So can we think about functions as smooth sections of this trivial line bundle? If this is true, does that mean for every smooth function $f$ there is a projection such that: $$\pi\circ f=\text{Id}_M$$ If so, it would be very helpful to a problem I am currently working on...","In differential geometry we often identify with the smooth functions on a smooth manifold . But for every we know that: I imagine with then would be the trivial line bundle since constant functions exist on . So can we think about functions as smooth sections of this trivial line bundle? If this is true, does that mean for every smooth function there is a projection such that: If so, it would be very helpful to a problem I am currently working on...",\Omega^0(M) M i>0 \Omega^i(M)=\Gamma(\Lambda^i(T^*M)) i=0 \Lambda^i(T^*M) M f \pi\circ f=\text{Id}_M,"['differential-geometry', 'smooth-manifolds', 'differential-forms', 'vector-bundles', 'smooth-functions']"
67,Canonical coordinates and tautological one-form: about a paragraph in the Wikipedia article on the Tautological One-form,Canonical coordinates and tautological one-form: about a paragraph in the Wikipedia article on the Tautological One-form,,"As @peek-a-boo wrote in one of his answer, ""the word ""momentum"" gets thrown around more often than candy during Halloween"". I found two definitions of momentum generalized coordinates I want to reconcile one way or another. We go with the usual adapted coordinate charts on a manifold $M$ : the ones on $TM$ are noted $(q, \dot{q})$ and the ones on $T^*M$ are noted $(q, p)$ . The first definition is given in the Wikipedia article about Canonical coordinates as a function on the set of vector fields on $M$ to the set of functions on $T^*M$ by $$X\to \mu_X(p)=p(X(\pi(p))$$ where $p\in T^*M$ and $\pi: T^*M\to M$ the projection. The second definition is a function on the set of functions on $TM$ to the set of one-forms on $TM$ given by $$f\to\Theta_f=(\text{F}f)^*\alpha$$ where $\alpha$ is the tautological one form defined on $T^*M$ , and $\text{F}f$ the Legendre transform of $f$ . We get $\mu_{\frac{\partial}{\partial q}}=p$ and I want to find a way to get $p$ using the second moment map $\Theta_{\dot{q}}$ if possible (here I have edited my question following the correction of @peek-a-boo in his comment). How can I do it?","As @peek-a-boo wrote in one of his answer, ""the word ""momentum"" gets thrown around more often than candy during Halloween"". I found two definitions of momentum generalized coordinates I want to reconcile one way or another. We go with the usual adapted coordinate charts on a manifold : the ones on are noted and the ones on are noted . The first definition is given in the Wikipedia article about Canonical coordinates as a function on the set of vector fields on to the set of functions on by where and the projection. The second definition is a function on the set of functions on to the set of one-forms on given by where is the tautological one form defined on , and the Legendre transform of . We get and I want to find a way to get using the second moment map if possible (here I have edited my question following the correction of @peek-a-boo in his comment). How can I do it?","M TM (q, \dot{q}) T^*M (q, p) M T^*M X\to \mu_X(p)=p(X(\pi(p)) p\in T^*M \pi: T^*M\to M TM TM f\to\Theta_f=(\text{F}f)^*\alpha \alpha T^*M \text{F}f f \mu_{\frac{\partial}{\partial q}}=p p \Theta_{\dot{q}}","['differential-geometry', 'symplectic-geometry', 'moment-map']"
68,Calculus Problem: polar-coordinate integration of a slice/wedge of a right circular cylinder,Calculus Problem: polar-coordinate integration of a slice/wedge of a right circular cylinder,,"This image states the problem: As shown in the diagram, a solid right circular cylinder of radius 12 cm is sliced by a plane that passes through the center of the base circle. Find the volume of the wedge-shaped piece that is created, given that its height is 16 cm (and its base has a radius of 12). 1 I realized the easiest way to do this is to integrate with triangles from each side but I was curious to see if it would be possible to integrate this using polar coordinates. I attempted to do this by integrating using the half-ellipses that are formed from the plane as cross sections and rotating that plane around the center of the base of the cylinder to create more ellipses. However, when I tried this I got $248$ instead of $\textbf{1536}$ (the correct answer). I'm confident in how I computed the integral--I think the mistake I made was in setting up the integration in the first place. Here is my working: Apologies if it's hard to follow Could anyone help me set it up properly? Can you spot what I did wrong? Thanks!","This image states the problem: As shown in the diagram, a solid right circular cylinder of radius 12 cm is sliced by a plane that passes through the center of the base circle. Find the volume of the wedge-shaped piece that is created, given that its height is 16 cm (and its base has a radius of 12). 1 I realized the easiest way to do this is to integrate with triangles from each side but I was curious to see if it would be possible to integrate this using polar coordinates. I attempted to do this by integrating using the half-ellipses that are formed from the plane as cross sections and rotating that plane around the center of the base of the cylinder to create more ellipses. However, when I tried this I got instead of (the correct answer). I'm confident in how I computed the integral--I think the mistake I made was in setting up the integration in the first place. Here is my working: Apologies if it's hard to follow Could anyone help me set it up properly? Can you spot what I did wrong? Thanks!",248 \textbf{1536},"['calculus', 'integration', 'differential-geometry', 'polar-coordinates']"
69,A Nonrectifiable Curve,A Nonrectifiable Curve,,"Do Carmo's book Page 11. Let $\alpha : [0,1] \to \mathbb{R}^2$ be given as $$\alpha(t)= \begin{cases}  (t,t \sin (\pi/t)) & \text{ for } t \ne 0\\ (0,0) & \text{ for } t=0 \,. \end{cases}$$ Show that the arc length of the portion of the curve corresponding to $\dfrac{1}{n+1} \leq t \leq \dfrac{1}{n}$ is at least $2/(n+1/2)$ . Use this to show that the length of the curve in the interval $1/N \leq t \leq 1$ is greater than $2 \sum_{n=1}^N 1/ (n+1)$ . For the first part, I considered the distance between $\bigl(\alpha(1/n), \alpha(2/(2n+1))\bigr)$ and $\bigl(\alpha(2/(2n+1)), \alpha(1/(n+1))\bigr)$ and proved that it should be at least $2/(n+1/2)$ . In the second part, we can see that \begin{align} [1/N, 1] & = [1/N, 1/(N-1)]\cup [1/(N-1), 1/(N-2)]\cup \dots \cup [1/2,1] \,. \end{align} Therefore, \begin{align} |\alpha(1)-\alpha(1/2)|+ \dots + |\alpha(1/(N-1))-\alpha(1/N)| & \geq \sum_{n=1}^{N-1}\dfrac{2}{n+1/2} \,, \end{align} and that won't give the desired solution. I don't know where I have made a mistake.","Do Carmo's book Page 11. Let be given as Show that the arc length of the portion of the curve corresponding to is at least . Use this to show that the length of the curve in the interval is greater than . For the first part, I considered the distance between and and proved that it should be at least . In the second part, we can see that Therefore, and that won't give the desired solution. I don't know where I have made a mistake.","\alpha : [0,1] \to \mathbb{R}^2 \alpha(t)=
\begin{cases} 
(t,t \sin (\pi/t)) & \text{ for } t \ne 0\\
(0,0) & \text{ for } t=0 \,.
\end{cases} \dfrac{1}{n+1} \leq t \leq \dfrac{1}{n} 2/(n+1/2) 1/N \leq t \leq 1 2 \sum_{n=1}^N 1/ (n+1) \bigl(\alpha(1/n), \alpha(2/(2n+1))\bigr) \bigl(\alpha(2/(2n+1)), \alpha(1/(n+1))\bigr) 2/(n+1/2) \begin{align}
[1/N, 1] & = [1/N, 1/(N-1)]\cup [1/(N-1), 1/(N-2)]\cup \dots \cup [1/2,1] \,.
\end{align} \begin{align}
|\alpha(1)-\alpha(1/2)|+ \dots + |\alpha(1/(N-1))-\alpha(1/N)| & \geq \sum_{n=1}^{N-1}\dfrac{2}{n+1/2} \,,
\end{align}","['sequences-and-series', 'differential-geometry']"
70,Why is a finitely sheeted covering space of $\mathbb{R}^n$ never compact?,Why is a finitely sheeted covering space of  never compact?,\mathbb{R}^n,"It is common to see the following consequence of Cartan-Hadamard stated as a significant result relating curvature and topology: Let $M$ be a compact Riemannian manifold with non-positive sectional curvature $K \leq 0$ . Then the fundamental group of $M$ is infinite. A common proof is using the Cartan-Hadamard theorem to guarantee that $M$ is a quotient of $\mathbb{R}^n$ and concluding by stating without proof that a finite quotient of $\mathbb{R}^n$ is  never compact. I have seen a proof of this consequence using geometrical means (a compact group acting on $M$ by isometries has a fixed point), but I would really like to see a purely topological proof.","It is common to see the following consequence of Cartan-Hadamard stated as a significant result relating curvature and topology: Let be a compact Riemannian manifold with non-positive sectional curvature . Then the fundamental group of is infinite. A common proof is using the Cartan-Hadamard theorem to guarantee that is a quotient of and concluding by stating without proof that a finite quotient of is  never compact. I have seen a proof of this consequence using geometrical means (a compact group acting on by isometries has a fixed point), but I would really like to see a purely topological proof.",M K \leq 0 M M \mathbb{R}^n \mathbb{R}^n M,"['general-topology', 'differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'covering-spaces']"
71,Complex differential forms and their integrals,Complex differential forms and their integrals,,"Recently, I was reading the book of J.M. Lee Introduction to smooth manifolds , more precisely, chapters 12, 14, 16 where (covariant) tensor fields on smooth manifolds, differential forms and finally integrals of differential forms were defined. While reading I thought about line integrals from classical analysis, in other words, integrals $\int_{\gamma} f(z)\,\mathrm{d}z$ , where $\gamma$ is a smooth curve in complex plane. Here, $f(z)\,\mathrm{d}z$ can be viewed as ""holomorphic 1-form"". S o, I was wondering whether one can generalize notion of integral for ""holomorphic $n$ -forms"", e.g., forms on complex $n$ -manifold having a local formula $f(z)\,\mathrm{d}z_1 \wedge\mathrm{d}z_2\wedge\dots\wedge\mathrm{d}z_n$ for $f$ complex-valued holomorphic map? This is not obvious for me, at least approach in the book I mentioned can not be generalized directly, for instance, because it uses smooth partitions of unity, while we can't expect analytic ones exist (however, this is not the only case that in my opinion can not be generalized directly).","Recently, I was reading the book of J.M. Lee Introduction to smooth manifolds , more precisely, chapters 12, 14, 16 where (covariant) tensor fields on smooth manifolds, differential forms and finally integrals of differential forms were defined. While reading I thought about line integrals from classical analysis, in other words, integrals , where is a smooth curve in complex plane. Here, can be viewed as ""holomorphic 1-form"". S o, I was wondering whether one can generalize notion of integral for ""holomorphic -forms"", e.g., forms on complex -manifold having a local formula for complex-valued holomorphic map? This is not obvious for me, at least approach in the book I mentioned can not be generalized directly, for instance, because it uses smooth partitions of unity, while we can't expect analytic ones exist (however, this is not the only case that in my opinion can not be generalized directly).","\int_{\gamma} f(z)\,\mathrm{d}z \gamma f(z)\,\mathrm{d}z n n f(z)\,\mathrm{d}z_1 \wedge\mathrm{d}z_2\wedge\dots\wedge\mathrm{d}z_n f","['differential-geometry', 'complex-geometry', 'differential-forms', 'complex-integration']"
72,Can every manifold be embedded into a compact manifold of the same dimension,Can every manifold be embedded into a compact manifold of the same dimension,,"Can every connected smooth boundary-less manifold be embedded into a compact smooth boundaryless manifold of the same dimension ? If not, can someone please provide me with  a counterexample ? Thank you","Can every connected smooth boundary-less manifold be embedded into a compact smooth boundaryless manifold of the same dimension ? If not, can someone please provide me with  a counterexample ? Thank you",,"['differential-geometry', 'differential-topology', 'examples-counterexamples']"
73,Why is an area preserving diffeomorphism a symplectomorphism (in $R^2$),Why is an area preserving diffeomorphism a symplectomorphism (in ),R^2,"Given this very simple sympletic vector space: $\left(\mathbb{R}^2, \mathrm{~d} x \wedge \mathrm{d} y\right)$ , how can we show that an area preserving diffeomorphism $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ defines a symplectomorphism? I believe an area-preserving diffeomorphism is a diffeomorphism that preserves the Lebesgue measure (please correct me if this is not the case or if there is a better definition in the context of symplectic geometry), but given that is the case, how can we relate preserving Lebesgue measure to showing that $\mathrm{~d} x \wedge \mathrm{d} y(u,v)=\mathrm{~d} x \wedge \mathrm{d} y (f(u),f(v))$ which is the definition of symplectomorphism where f is our area-preserving diffeomorphism.","Given this very simple sympletic vector space: , how can we show that an area preserving diffeomorphism defines a symplectomorphism? I believe an area-preserving diffeomorphism is a diffeomorphism that preserves the Lebesgue measure (please correct me if this is not the case or if there is a better definition in the context of symplectic geometry), but given that is the case, how can we relate preserving Lebesgue measure to showing that which is the definition of symplectomorphism where f is our area-preserving diffeomorphism.","\left(\mathbb{R}^2, \mathrm{~d} x \wedge \mathrm{d} y\right) f: \mathbb{R}^2 \rightarrow \mathbb{R}^2 \mathrm{~d} x \wedge \mathrm{d} y(u,v)=\mathrm{~d} x \wedge \mathrm{d} y (f(u),f(v))","['differential-geometry', 'symplectic-geometry', 'symplectic-linear-algebra']"
74,The components $W_{ij}^k$ of the difference $W=\nabla-\overline{\nabla}$ between two Levi-Civita connections,The components  of the difference  between two Levi-Civita connections,W_{ij}^k W=\nabla-\overline{\nabla},"The following text comes from the book Geometric Relativity written by Dan A. Lee. The expression $(\nabla_i-\overline{\nabla}_i)(v_j)$ may be a little perplexing, but according to what I've learned so far, that means $$\nabla_{v_i}v_j-\overline{\nabla}_{v_i}v_j.$$ Then we would have $$W_{ij}^k=\Gamma_{ij}^k-\overline{\Gamma}_{ij}^k=\frac{1}{2}g^{k\ell}(g_{\ell i,j}+g_{\ell j,i}-g_{ij,\ell})-\frac{1}{2}\overline{g}^{k\ell}(\overline{g}_{\ell i,j}+\overline{g}_{\ell j,i}-\overline{g}_{ij,\ell}).\tag{*}$$ Now I'd like to show that $$W_{ij}^k=\frac{1}{2}g^{k\ell}(\overline{\nabla}_i g_{\ell j}+\overline{\nabla}_j g_{i\ell}-\overline{\nabla}_\ell g_{ij}),\tag{**}$$ where $\overline{\nabla}_i g_{\ell j}$ is used to denote the components of $\overline{\nabla}g$ . My strategy is to expand the RHS of ( $**$ ) and try to arrive at ( $*$ ). The expansion is done by recalling that $$\overline{\nabla}_k g_{ij}=g_{ij,k}-\overline{\Gamma}_{ki}^\ell g_{\ell j}-\overline{\Gamma}_{kj}^\ell g_{\ell i}.$$ Then we see $$\overline{\nabla}_i g_{\ell j}+\overline{\nabla}_j g_{\ell i}-\overline{\nabla}_\ell g_{ij}=g_{\ell j,i}-\overline{\Gamma}_{i\ell}^k g_{kj}-\overline{\Gamma}_{ij}^k g_{k\ell} +g_{\ell i,j}-\overline{\Gamma}_{j\ell}^k g_{ki}-\overline{\Gamma}_{ji}^k g_{k\ell} -g_{ij,\ell}+\overline{\Gamma}_{\ell i}^k g_{kj}+\overline{\Gamma}_{\ell j}^k g_{ki}.$$ This is as far as I can go because I don't know how to get rid of the Christoffel symbols of $\overline{g}$ . Can someone tell me what to do next? Thank you. Edit 1. I'm very sorry. It seems that I have mixed up coordinate frames and the frame $\{v_1,\ldots,v_n\}$ . Let me think about it and fix it later. I apologize. Edit 2. As mentioned in Edit 1, I failed to rightly tell two different frames apart, so I will redo the problem here. Let me start from ( $*$ ). The connection coefficients $\Gamma_{ij}^k$ and $\overline{\Gamma}_{ij}^k$ are not necessarily the Christoffel symbols because $\{v_1,\ldots,v_n\}$ may not be a coordinate frame. Write $$g=g_{ij}e^i\otimes e^j\text{ and }\overline{g}=\overline{g}_{ij}e^i\otimes e^j$$ with $\{e^1,\ldots,e^n\}$ denoting the coframe dual to $\{v_1,\ldots,v_n\}$ . Then we have $$\begin{align} W_{ij}^k&=\Gamma_{ij}^k-\overline{\Gamma}_{ij}^k\\ &=\frac{1}{2}g^{k\ell}(v_i g_{j\ell}+v_j g_{i\ell}-v_\ell g_{ij}-g_{jm}c_{i\ell}^m-g_{\ell m}c_{ji}^m+g_{im}c_{\ell j}^m)\\ &\quad-\frac{1}{2}\overline{g}^{k\ell}(v_i \overline{g}_{j\ell}+v_j \overline{g}_{i\ell}-v_\ell \overline{g}_{ij}-\overline{g}_{jm}c_{i\ell}^m-\overline{g}_{\ell m}c_{ji}^m+\overline{g}_{im}c_{\ell j}^m),\tag{***} \end{align}$$ where $c_{ij}^m$ are the functions defined by $$[v_i,v_j]=c_{ij}^m v_m.$$ For more information, one can see the book Introduction to Riemannian manifolds by John M. Lee. Now, on the other hand, we have $$\overline{\nabla}_k g_{ij}=v_k g_{ij}-\overline{\Gamma}_{ki}^\ell g_{\ell j}-\overline{\Gamma}_{kj}^\ell g_{i\ell}.$$ This gives $$\frac{1}{2}g^{k\ell}(\overline{\nabla}_i g_{\ell j}+\overline{\nabla}_j g_{i\ell}-\overline{\nabla}_\ell g_{ij})=\frac{1}{2}(g^{k\ell}v_i g_{\ell j}-\overline{\Gamma}_{ij}^k-n\overline{\Gamma}_{ij}^k+g^{k\ell}v_j g_{i\ell}-n\overline{\Gamma}_{ji}^k-\overline{\Gamma}_{ji}^k-g^{k\ell}v_\ell g_{ij}+\overline{\Gamma}_{ji}^k+\overline{\Gamma}_{ij}^k).$$ Now the thing is, how do I dispense with $\overline{g}^{k\ell}$ in ( $***$ )? Thank you.","The following text comes from the book Geometric Relativity written by Dan A. Lee. The expression may be a little perplexing, but according to what I've learned so far, that means Then we would have Now I'd like to show that where is used to denote the components of . My strategy is to expand the RHS of ( ) and try to arrive at ( ). The expansion is done by recalling that Then we see This is as far as I can go because I don't know how to get rid of the Christoffel symbols of . Can someone tell me what to do next? Thank you. Edit 1. I'm very sorry. It seems that I have mixed up coordinate frames and the frame . Let me think about it and fix it later. I apologize. Edit 2. As mentioned in Edit 1, I failed to rightly tell two different frames apart, so I will redo the problem here. Let me start from ( ). The connection coefficients and are not necessarily the Christoffel symbols because may not be a coordinate frame. Write with denoting the coframe dual to . Then we have where are the functions defined by For more information, one can see the book Introduction to Riemannian manifolds by John M. Lee. Now, on the other hand, we have This gives Now the thing is, how do I dispense with in ( )? Thank you.","(\nabla_i-\overline{\nabla}_i)(v_j) \nabla_{v_i}v_j-\overline{\nabla}_{v_i}v_j. W_{ij}^k=\Gamma_{ij}^k-\overline{\Gamma}_{ij}^k=\frac{1}{2}g^{k\ell}(g_{\ell i,j}+g_{\ell j,i}-g_{ij,\ell})-\frac{1}{2}\overline{g}^{k\ell}(\overline{g}_{\ell i,j}+\overline{g}_{\ell j,i}-\overline{g}_{ij,\ell}).\tag{*} W_{ij}^k=\frac{1}{2}g^{k\ell}(\overline{\nabla}_i g_{\ell j}+\overline{\nabla}_j g_{i\ell}-\overline{\nabla}_\ell g_{ij}),\tag{**} \overline{\nabla}_i g_{\ell j} \overline{\nabla}g ** * \overline{\nabla}_k g_{ij}=g_{ij,k}-\overline{\Gamma}_{ki}^\ell g_{\ell j}-\overline{\Gamma}_{kj}^\ell g_{\ell i}. \overline{\nabla}_i g_{\ell j}+\overline{\nabla}_j g_{\ell i}-\overline{\nabla}_\ell g_{ij}=g_{\ell j,i}-\overline{\Gamma}_{i\ell}^k g_{kj}-\overline{\Gamma}_{ij}^k g_{k\ell}
+g_{\ell i,j}-\overline{\Gamma}_{j\ell}^k g_{ki}-\overline{\Gamma}_{ji}^k g_{k\ell}
-g_{ij,\ell}+\overline{\Gamma}_{\ell i}^k g_{kj}+\overline{\Gamma}_{\ell j}^k g_{ki}. \overline{g} \{v_1,\ldots,v_n\} * \Gamma_{ij}^k \overline{\Gamma}_{ij}^k \{v_1,\ldots,v_n\} g=g_{ij}e^i\otimes e^j\text{ and }\overline{g}=\overline{g}_{ij}e^i\otimes e^j \{e^1,\ldots,e^n\} \{v_1,\ldots,v_n\} \begin{align}
W_{ij}^k&=\Gamma_{ij}^k-\overline{\Gamma}_{ij}^k\\
&=\frac{1}{2}g^{k\ell}(v_i g_{j\ell}+v_j g_{i\ell}-v_\ell g_{ij}-g_{jm}c_{i\ell}^m-g_{\ell m}c_{ji}^m+g_{im}c_{\ell j}^m)\\
&\quad-\frac{1}{2}\overline{g}^{k\ell}(v_i \overline{g}_{j\ell}+v_j \overline{g}_{i\ell}-v_\ell \overline{g}_{ij}-\overline{g}_{jm}c_{i\ell}^m-\overline{g}_{\ell m}c_{ji}^m+\overline{g}_{im}c_{\ell j}^m),\tag{***}
\end{align} c_{ij}^m [v_i,v_j]=c_{ij}^m v_m. \overline{\nabla}_k g_{ij}=v_k g_{ij}-\overline{\Gamma}_{ki}^\ell g_{\ell j}-\overline{\Gamma}_{kj}^\ell g_{i\ell}. \frac{1}{2}g^{k\ell}(\overline{\nabla}_i g_{\ell j}+\overline{\nabla}_j g_{i\ell}-\overline{\nabla}_\ell g_{ij})=\frac{1}{2}(g^{k\ell}v_i g_{\ell j}-\overline{\Gamma}_{ij}^k-n\overline{\Gamma}_{ij}^k+g^{k\ell}v_j g_{i\ell}-n\overline{\Gamma}_{ji}^k-\overline{\Gamma}_{ji}^k-g^{k\ell}v_\ell g_{ij}+\overline{\Gamma}_{ji}^k+\overline{\Gamma}_{ij}^k). \overline{g}^{k\ell} ***","['differential-geometry', 'riemannian-geometry']"
75,Coordinate-free definition of the symplectic form on the cotangent bundle,Coordinate-free definition of the symplectic form on the cotangent bundle,,"Say we have a manifold $M$ with local coordinates $q_i$ . Then, $T^{\star}M$ has elements of the form $\sum_i p_i \mathrm{d}q_i$ , for $p_i \in \mathbb{R}$ ; so $T^{\star} M$ has local coordinates $(q_i, p_i)$ . Now, we define the $1$ -form $\lambda = \sum_i p_i \mathrm{d} q_i$ on $T^{\star} M$ (which means that $\lambda$ is a section of $T^{\star} T^{\star} M$ ), and $\mathrm{d}\lambda$ turns out to be symplectic. Now, nlab contains a coordinate-free definition , stating that $\lambda$ as above, is determined uniquely by the fact that for every $1$ -form $\sigma$ on $X$ , we have: \begin{equation*} \sigma^{*}\lambda = j\sigma \end{equation*} Where $j$ is the natural isomorphism $j : \Gamma(T^{\star} M) \overset{\sim}{\longrightarrow} \Omega^1(M)$ (where $\Gamma$ denotes the space of sections, and $\Omega^1(M)$ the space of $1$ -forms on $M$ )). I am trying to start from the coordinate expression of $\lambda$ ; to show that this holds (or the other way around, really. I'm trying to understand why these two definitions are equivalent). My working: Take $\sigma$ an arbitrary $1$ -form on $M$ . So $\sigma : M \to T^{\star}M$ ; and hence induces $\sigma^{\star} : \Omega^1(T^\star M) \to \Omega^1(M)$ . Now, an element of $\Omega^1(T^\star M)$ is a section of $T^\star T^\star M$ , hence a map $\alpha : \big(T^\star M \ni y \mapsto (\alpha_y : T_y T^\star M \to \mathbb{R})\big)$ . The natural way of pulling it back through $\sigma$ , should give us something like: $\sigma^{*} \alpha : M \to T^\star M : x \mapsto \alpha\big(\sigma(x)\big)$ Now, this is where I am getting a bit lost; I think I am getting confused between the different cotangent bundles. Ultimately, I want to show that this pullback above coincides with $j\alpha$ iff $\alpha = \lambda$ ; but I'm unsure how to proceed. I am mostly confused as to what the isomorphism $j : \Gamma(T^\star M) \to \Omega^1(M)$ looks like. In my head, I have always identified $\Gamma(T^\star M)$ and $\Omega^1(M)$ as being the same space; so unless $j$ is the identity (lol), I'm not really sure what it represents. Are $\Gamma(T^\star M)$ and $\Omega^1(M)$ ""presented differently"", even though they correspond to the same concept, which is why we need $j$ to bridge the gap between them?","Say we have a manifold with local coordinates . Then, has elements of the form , for ; so has local coordinates . Now, we define the -form on (which means that is a section of ), and turns out to be symplectic. Now, nlab contains a coordinate-free definition , stating that as above, is determined uniquely by the fact that for every -form on , we have: Where is the natural isomorphism (where denotes the space of sections, and the space of -forms on )). I am trying to start from the coordinate expression of ; to show that this holds (or the other way around, really. I'm trying to understand why these two definitions are equivalent). My working: Take an arbitrary -form on . So ; and hence induces . Now, an element of is a section of , hence a map . The natural way of pulling it back through , should give us something like: Now, this is where I am getting a bit lost; I think I am getting confused between the different cotangent bundles. Ultimately, I want to show that this pullback above coincides with iff ; but I'm unsure how to proceed. I am mostly confused as to what the isomorphism looks like. In my head, I have always identified and as being the same space; so unless is the identity (lol), I'm not really sure what it represents. Are and ""presented differently"", even though they correspond to the same concept, which is why we need to bridge the gap between them?","M q_i T^{\star}M \sum_i p_i \mathrm{d}q_i p_i \in \mathbb{R} T^{\star} M (q_i, p_i) 1 \lambda = \sum_i p_i \mathrm{d} q_i T^{\star} M \lambda T^{\star} T^{\star} M \mathrm{d}\lambda \lambda 1 \sigma X \begin{equation*}
\sigma^{*}\lambda = j\sigma
\end{equation*} j j : \Gamma(T^{\star} M) \overset{\sim}{\longrightarrow} \Omega^1(M) \Gamma \Omega^1(M) 1 M \lambda \sigma 1 M \sigma : M \to T^{\star}M \sigma^{\star} : \Omega^1(T^\star M) \to \Omega^1(M) \Omega^1(T^\star M) T^\star T^\star M \alpha : \big(T^\star M \ni y \mapsto (\alpha_y : T_y T^\star M \to \mathbb{R})\big) \sigma \sigma^{*} \alpha : M \to T^\star M : x \mapsto \alpha\big(\sigma(x)\big) j\alpha \alpha = \lambda j : \Gamma(T^\star M) \to \Omega^1(M) \Gamma(T^\star M) \Omega^1(M) j \Gamma(T^\star M) \Omega^1(M) j","['differential-geometry', 'differential-topology', 'symplectic-geometry']"
76,Functional distance in a manifold,Functional distance in a manifold,,"In Riemannian Geometry of Peter Petersen , he gave a definition of functional distance in a manifold $M$ as following: $$ d_F(p,q)=\sup\{|f(p)-f(q)|\ |f:M\to \mathbb{R} \text{ has } |\nabla f|\leq 1 \text{ on } M\}. $$ He said that the distance is always smaller than the arclength distance. But I can't understand it.","In Riemannian Geometry of Peter Petersen , he gave a definition of functional distance in a manifold as following: He said that the distance is always smaller than the arclength distance. But I can't understand it.","M 
d_F(p,q)=\sup\{|f(p)-f(q)|\ |f:M\to \mathbb{R} \text{ has } |\nabla f|\leq 1 \text{ on } M\}.
","['differential-geometry', 'riemannian-geometry']"
77,Question about covariant derivative on manifolds.,Question about covariant derivative on manifolds.,,"I am currently learning about the covariant derivative on smooth manifolds with the following definition: Definition. A covariant derivative of vector fields is an operation that associates to two vector fields $X$ and $Y$ a new vector field $\nabla_XY$ and satisfies the following properties. $\mathcal{C}^{\infty}(M)$ -linearity with respect to $X$ : $$ \nabla_{X_1+X_2}Y = \nabla_{X_1}Y + \nabla_{X_2}Y,\quad \nabla_{fX}Y = f\nabla_XY; $$ additivity and the Leibniz rule with respect to $Y$ : $$ \nabla_X(Y_1+y_2) = \nabla_XY_1+\nabla_XY_2,\quad \nabla_X(fY) = D_Xf\cdot Y + f\nabla_XY. $$ Then there is this theorem, for which I do not understand the proof. How am I supposed to understand the transfer the vectorfield via $\varphi$ part? Where does the covariant derivative on $U_i$ come from? Can you please explain me, what the first part with the chart means in exact terms? Thank you","I am currently learning about the covariant derivative on smooth manifolds with the following definition: Definition. A covariant derivative of vector fields is an operation that associates to two vector fields and a new vector field and satisfies the following properties. -linearity with respect to : additivity and the Leibniz rule with respect to : Then there is this theorem, for which I do not understand the proof. How am I supposed to understand the transfer the vectorfield via part? Where does the covariant derivative on come from? Can you please explain me, what the first part with the chart means in exact terms? Thank you","X Y \nabla_XY \mathcal{C}^{\infty}(M) X 
\nabla_{X_1+X_2}Y = \nabla_{X_1}Y + \nabla_{X_2}Y,\quad \nabla_{fX}Y = f\nabla_XY;
 Y 
\nabla_X(Y_1+y_2) = \nabla_XY_1+\nabla_XY_2,\quad \nabla_X(fY) = D_Xf\cdot Y + f\nabla_XY.
 \varphi U_i",['differential-geometry']
78,Proving or disproving that $M$ is a submanifold of the flag manifold of $G$,Proving or disproving that  is a submanifold of the flag manifold of,M G,"Let $G$ be a compact connected Lie group and let $T$ be a maximal torus of $G$ .  Denote by $\mathcal{F}=G/T$ the flag manifold of $G$ . Let $\theta : G \rightarrow G$ be an involution on $G$ . This involution induces an involution on the Lie algebra of $G$ , that we denote also by $\theta$ . Consider the natural action of $G$ on $\mathcal{F}$ . Let $x=gT \in \mathcal{F}$ , denote by $G_x$ the stabilizer of $x$ in $G$ and denote by $\mathfrak{g}_x$ its Lie algebra. (Note that $G_x =gTg^{-1}$ ). Consider the set $M:= \lbrace x \in \mathcal{F}, \theta(\mathfrak{g}_x)=\mathfrak{g}_x \rbrace  $ . $\textbf{Question}:$ Prove or disprove that $M$ is a submanifold of $\mathcal{F}$ . So far I didn't find any example for which $M$ is not a submanifold, and my thoughts are: Since the group $G$ acts transitively on the set $\tilde{\mathfrak{g}}:=\lbrace \mathfrak{g}_x , x \in \mathcal{F}\rbrace $ (this is because $\tilde{\mathfrak{g}}$ is the set of all cartan subalgebras of $\mathfrak{g}$ ) and since the set $M$ is a fixed point set of the involution $\theta$ , then using this On the proof of that fixed point set of an involution is a submanifold ), I conclude that $M$ is a submanifold. is this correct ? $\textbf{Edit:}$ $T$ is assumed to be stable by $\theta$ .","Let be a compact connected Lie group and let be a maximal torus of .  Denote by the flag manifold of . Let be an involution on . This involution induces an involution on the Lie algebra of , that we denote also by . Consider the natural action of on . Let , denote by the stabilizer of in and denote by its Lie algebra. (Note that ). Consider the set . Prove or disprove that is a submanifold of . So far I didn't find any example for which is not a submanifold, and my thoughts are: Since the group acts transitively on the set (this is because is the set of all cartan subalgebras of ) and since the set is a fixed point set of the involution , then using this On the proof of that fixed point set of an involution is a submanifold ), I conclude that is a submanifold. is this correct ? is assumed to be stable by .","G T G \mathcal{F}=G/T G \theta : G \rightarrow G G G \theta G \mathcal{F} x=gT \in \mathcal{F} G_x x G \mathfrak{g}_x G_x =gTg^{-1} M:= \lbrace x \in \mathcal{F}, \theta(\mathfrak{g}_x)=\mathfrak{g}_x \rbrace 
 \textbf{Question}: M \mathcal{F} M G \tilde{\mathfrak{g}}:=\lbrace \mathfrak{g}_x , x \in \mathcal{F}\rbrace  \tilde{\mathfrak{g}} \mathfrak{g} M \theta M \textbf{Edit:} T \theta","['differential-geometry', 'lie-groups', 'lie-algebras']"
79,Lifting diffeomorphisms in $S^2$ by the Hopf fibration.,Lifting diffeomorphisms in  by the Hopf fibration.,S^2,"Can you lift a diffeomorphism $f$ on $S^2$ to a diffeomorphism $F$ on $S^3$ preserving the Hopf fibration structure $\pi:S^3\mapsto S^2$ , i.e. such that $\pi\circ F=f\circ \pi$ . I think that if we take a rotation on $S^2$ around the $z$ -axis by angle $\theta$ then this can indeed be lifted to a diffeomorphism in $F:S^3\mapsto S^3$ given by $$F(z_1,z_2)=(e^{i\theta}z_1,z_2)$$ But I don't know if this holds for general diffeomorphisms on $S^2$ , or at least diffeomorphisms isotopic to the identity, this last case would be enough for me. So if anyone knows an answer to this I would be deeply grateful.","Can you lift a diffeomorphism on to a diffeomorphism on preserving the Hopf fibration structure , i.e. such that . I think that if we take a rotation on around the -axis by angle then this can indeed be lifted to a diffeomorphism in given by But I don't know if this holds for general diffeomorphisms on , or at least diffeomorphisms isotopic to the identity, this last case would be enough for me. So if anyone knows an answer to this I would be deeply grateful.","f S^2 F S^3 \pi:S^3\mapsto S^2 \pi\circ F=f\circ \pi S^2 z \theta F:S^3\mapsto S^3 F(z_1,z_2)=(e^{i\theta}z_1,z_2) S^2","['differential-geometry', 'algebraic-topology', 'differential-topology', 'geometric-topology']"
80,"What is the meaning of ""without referring back to the ambient space $R^3$ where the surface lies""?","What is the meaning of ""without referring back to the ambient space  where the surface lies""?",R^3,"I'm reading Do Carmo's Differential Geometry book, here: What is the meaning of ""without referring back to the ambient space $R^3$ where the surface lies""? Does it mean that we can compute it directly without appealing to some inverse mapping? If so, why don't we need to refer back? This concerns me because it seems that there are situations where we need to refer back to the ambient space and situations where we don't and up to now, It's not clear where we need it and where we don't, I just accepted the definitions and constructions without deeper thought because I still can't. This gives me a lot of curiosity, for example: In a definition I mentioned in a previous question: I noticed that this is defined referring back to a map between open sets in $R^2.$ Can we make this definition without this?","I'm reading Do Carmo's Differential Geometry book, here: What is the meaning of ""without referring back to the ambient space where the surface lies""? Does it mean that we can compute it directly without appealing to some inverse mapping? If so, why don't we need to refer back? This concerns me because it seems that there are situations where we need to refer back to the ambient space and situations where we don't and up to now, It's not clear where we need it and where we don't, I just accepted the definitions and constructions without deeper thought because I still can't. This gives me a lot of curiosity, for example: In a definition I mentioned in a previous question: I noticed that this is defined referring back to a map between open sets in Can we make this definition without this?",R^3 R^2.,['differential-geometry']
81,The third covariant of a tensor in Riemannian manifolds [closed],The third covariant of a tensor in Riemannian manifolds [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I'm reading Petersen's book ""Riemannian Geometry 3rd"", No.171 in GTM. On page 82, there's a formula reads: $$\nabla^3_{X,Y,Z}W=\nabla^2_{X,Y}(\nabla_ZW)-\nabla_{\nabla^2_{XY}Z}W$$ I'm quite puzzled with this formula. On the right hand site, it doesn't seem to be tensorial in the ""Z"" position. Is this formula false?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I'm reading Petersen's book ""Riemannian Geometry 3rd"", No.171 in GTM. On page 82, there's a formula reads: I'm quite puzzled with this formula. On the right hand site, it doesn't seem to be tensorial in the ""Z"" position. Is this formula false?","\nabla^3_{X,Y,Z}W=\nabla^2_{X,Y}(\nabla_ZW)-\nabla_{\nabla^2_{XY}Z}W","['differential-geometry', 'riemannian-geometry', 'tensors']"
82,"Let $f \in C^{\infty}(\mathbb{R}^n)$ be such that $\underline{0}$ is a local minimum point for every algebraic curve, is it $0$ a local minimum point?","Let  be such that  is a local minimum point for every algebraic curve, is it  a local minimum point?",f \in C^{\infty}(\mathbb{R}^n) \underline{0} 0,"Let $f \in C^{\infty}(\mathbb{R}^n)$ be a real function such that $\underline{0}$ is a local minimum point for $f$ on every algebraic curve, i.e. for every algebraic curve $C$ there exists an $\epsilon > 0$ such that if $x \in B_{\epsilon}(\underline{0}) \cap C$ then $f(0) \leq f(x)$ Where $B_{\epsilon}(0) := \{ x \in \mathbb{R}^n \; : \; ||x|| < \epsilon \}$ and $C$ is the set of points that belongs to the algebraic curve (Observe that $\epsilon$ depends on $C$ ). Is it true that $\underline{0}$ is necessarily local minimum point for $f$ ?","Let be a real function such that is a local minimum point for on every algebraic curve, i.e. for every algebraic curve there exists an such that if then Where and is the set of points that belongs to the algebraic curve (Observe that depends on ). Is it true that is necessarily local minimum point for ?",f \in C^{\infty}(\mathbb{R}^n) \underline{0} f C \epsilon > 0 x \in B_{\epsilon}(\underline{0}) \cap C f(0) \leq f(x) B_{\epsilon}(0) := \{ x \in \mathbb{R}^n \; : \; ||x|| < \epsilon \} C \epsilon C \underline{0} f,"['real-analysis', 'calculus', 'differential-geometry', 'maxima-minima', 'algebraic-curves']"
83,Two definitions of Evolute of a curve?,Two definitions of Evolute of a curve?,,"Recall, when the tangents to a curve $\gamma$ are normal to another curve, the second curve is called an involute of $\gamma.$ In literature, there are two seemingly different dual notions for involutes. Definition $1$ The evolute of a given curve $\gamma$ is another curve to which all the normals of $\gamma$ are tangent. Definition $2$ Given a $\gamma$ , another curve is called an evolute of $\gamma$ if it is an involute of the second. With the second definition, and arc-length parametrization, an internet source shows that its evolute as $$\gamma(s)+\rho(s)N(s)+\rho(s)\cot\left(\displaystyle\int\tau ds+c\right)B(s).$$ But, for a plane curve, the first definition yields the ""locus of all its centers of curvature"" $$\gamma(s)+\rho(s)N(s)$$ as the evolute. This doesn't seems agree with the other for $\tau=0.$ Are these two definitions actually inequivalent? If so, what is the correct terminology? Also, I would like to see a reference discussing these types of constructions in the theory of curves.","Recall, when the tangents to a curve are normal to another curve, the second curve is called an involute of In literature, there are two seemingly different dual notions for involutes. Definition The evolute of a given curve is another curve to which all the normals of are tangent. Definition Given a , another curve is called an evolute of if it is an involute of the second. With the second definition, and arc-length parametrization, an internet source shows that its evolute as But, for a plane curve, the first definition yields the ""locus of all its centers of curvature"" as the evolute. This doesn't seems agree with the other for Are these two definitions actually inequivalent? If so, what is the correct terminology? Also, I would like to see a reference discussing these types of constructions in the theory of curves.",\gamma \gamma. 1 \gamma \gamma 2 \gamma \gamma \gamma(s)+\rho(s)N(s)+\rho(s)\cot\left(\displaystyle\int\tau ds+c\right)B(s). \gamma(s)+\rho(s)N(s) \tau=0.,"['differential-geometry', 'curves', 'curvature', 'plane-curves', 'envelope']"
84,Let $\alpha$ be a regular curve of curvature and torsion not zero. Show that $\alpha$ is helix if and only if $\frac{k}{\tau}$ is constant.,Let  be a regular curve of curvature and torsion not zero. Show that  is helix if and only if  is constant.,\alpha \alpha \frac{k}{\tau},"Definition. A regular curve $\alpha: I \to \mathbb R^3$ is a helix if there is a unit vector $v$ that forms a constant angle with $\alpha'(t), \forall t \in I$ . We can assume $\alpha$ parameterized by arc length. If $\alpha$ is a helix, then there is a unit vector $v$ such that $\langle \alpha'(s), v \rangle$ is constant. So $\langle \alpha''(s),v \rangle = 0$ , that is $k(s)\langle n(s), v  \rangle = 0$ . As $k(s) \ne 0$ , it follows that $v$ belongs to the plan determined by $t(s)$ and $b(s)$ , for each $s \in I $ . So be $$ v= \cos\theta(s)\,t(s) + \sin\theta(s)\,b(s)$$ Differentiating and using Frenet's formulas, we get $$0 = -\sin\theta(s)\theta'(s)t(s) + (k(s)\cos\theta(s)+\tau(s)\sin\theta(s))n(s) + \cos\theta(s)\theta'(s)b(s)$$ Therefore, $\forall s \in I$ , $$\sin\theta(s)\theta'(s) = 0,$$ $$\cos\theta(s)\theta'(s) = 0,$$ $$k(s)\cos\theta(s) + \tau(s) \sin\theta(s) = 0$$ The first two equations determine $\theta'(s) = 0, \forall \in I$ . Therefore, $\theta(s)$ is constant. Also, the constant $\cos\theta$ is non-zero, otherwise we would have $\tau(s)=0$ , which contradicts the hypothesis. It follows from the third equality that $\frac{k}{\tau}$ is constant. Conversely, if $\frac{k}{\tau}$ is constant, we set $\theta$ such that $tg\theta = -\frac{k}{\tau}$ . So $$v=cos\theta t(s) + sin \theta b(s)$$ is a constant unit vector and $\forall s \in, \langle t(s), v \rangle = cos\theta $ is constant. So $\alpha$ is helix. Apparently the answer is correct but incomplete, I'm not able to complete it. Thanks for any help.","Definition. A regular curve is a helix if there is a unit vector that forms a constant angle with . We can assume parameterized by arc length. If is a helix, then there is a unit vector such that is constant. So , that is . As , it follows that belongs to the plan determined by and , for each . So be Differentiating and using Frenet's formulas, we get Therefore, , The first two equations determine . Therefore, is constant. Also, the constant is non-zero, otherwise we would have , which contradicts the hypothesis. It follows from the third equality that is constant. Conversely, if is constant, we set such that . So is a constant unit vector and is constant. So is helix. Apparently the answer is correct but incomplete, I'm not able to complete it. Thanks for any help.","\alpha: I \to \mathbb R^3 v \alpha'(t), \forall t \in I \alpha \alpha v \langle \alpha'(s), v \rangle \langle \alpha''(s),v \rangle = 0 k(s)\langle n(s), v
 \rangle = 0 k(s) \ne 0 v t(s) b(s) s \in I   v= \cos\theta(s)\,t(s) + \sin\theta(s)\,b(s) 0 = -\sin\theta(s)\theta'(s)t(s) + (k(s)\cos\theta(s)+\tau(s)\sin\theta(s))n(s) + \cos\theta(s)\theta'(s)b(s) \forall s \in I \sin\theta(s)\theta'(s) = 0, \cos\theta(s)\theta'(s) = 0, k(s)\cos\theta(s) + \tau(s) \sin\theta(s) = 0 \theta'(s) = 0, \forall \in I \theta(s) \cos\theta \tau(s)=0 \frac{k}{\tau} \frac{k}{\tau} \theta tg\theta = -\frac{k}{\tau} v=cos\theta t(s) + sin \theta b(s) \forall s \in, \langle t(s), v \rangle = cos\theta  \alpha","['differential-geometry', 'solution-verification', 'curves']"
85,Orientation on level set manifold,Orientation on level set manifold,,"Let $M$ be an orientable smooth manifold of dimension $n$ and $f:M\to \mathbb{R}$ smooth with $0$ as regular value. I want to show that the level set $f^{-1}(0)$ is orientable (we know it to be an embedded manifold of dimension $n-1$ ). I sketched a proof using differential forms and would like a review of it. I would also be interested in other proofs involving (or not) differential forms. Thanks in advance. Here's my attempt: Let $d$ denote the exterior derivative of differential forms. Let $\varphi=(\varphi^1,\cdots,\varphi^n)$ denote a chart map of $M$ . As $f$ is a $0$ -form, $df$ is a $1$ -form and since $f*_p$ is surjective when $p\in f^{-1}(0)$ we have that $df=\sum\limits_{k=1}^n \frac{\partial f\circ \varphi^{-1}}{\partial x^k}d\varphi^{k}$ is non zero in an open neighborhood of $f^{-1}(0)$ , which is an embedded orientable submanifold of $M$ that I shall call $N$ . Claim : Since $df$ is non zero in $N$ and $N$ is orientable, I can obtain a basis $\{\omega_1,\cdots, \omega_{n-1},df\}$ for $\Omega^1N $ (the space of differentiable 1-forms on $N$ ) such that $\eta=\omega_1\wedge\cdots\wedge \omega_{n-1}\wedge df$ is nowhere $0$ on $N$ . i.e. $\eta_p\neq 0$ for all $p\in N$ . Let $i:f^{-1}(0)\hookrightarrow N$ be the inclusion map. Since $\omega_1\wedge\cdots\wedge \omega_{n-1}$ is an $n-1$ -form on $N$ , the pull-back $$\rho = i^*(\omega_1\wedge\cdots\wedge \omega_{n-1})=i^*\omega_1\wedge\cdots\wedge i^*\omega_{n-1}=(\omega_1\circ i)\wedge\cdots\wedge (\omega_{n-1}\circ i)$$ is an $n-1$ -form on $f^{-1}(0)$ and is nowhere vanishing, for if $\rho_q=0$ then $\eta_{i(q)}=0$ Thus $\rho$ is a volume form (nowhere vanishing) on $f^{-1}(0)$ which we know to induce an orientation on $f^{-1}(0)$ . To prove my claim, I first extend $\{df\}$ to a basis using that every vector space has one (or should I treat $\Omega^1 N$ as a free $C^\infty$ -module?). Then I re-order the basis so that the volume form $\eta$ induces the same orientation as that of $N$ . To prove $\eta$ is a volume form I take for each $p\in N$ a basis $\{v_1,\cdots,v_n\}$ of $T_pN$ such that $\{\omega_1,\cdots,\omega_{n-1},df\}$ is it's dual basis. i.e. $\omega_{k}(v_j)=\delta_{kj}$ and $df(v_j)=\delta_{nj}$ then $\eta_p(v_1,\cdots,v_n)=1$ and thus non zero.","Let be an orientable smooth manifold of dimension and smooth with as regular value. I want to show that the level set is orientable (we know it to be an embedded manifold of dimension ). I sketched a proof using differential forms and would like a review of it. I would also be interested in other proofs involving (or not) differential forms. Thanks in advance. Here's my attempt: Let denote the exterior derivative of differential forms. Let denote a chart map of . As is a -form, is a -form and since is surjective when we have that is non zero in an open neighborhood of , which is an embedded orientable submanifold of that I shall call . Claim : Since is non zero in and is orientable, I can obtain a basis for (the space of differentiable 1-forms on ) such that is nowhere on . i.e. for all . Let be the inclusion map. Since is an -form on , the pull-back is an -form on and is nowhere vanishing, for if then Thus is a volume form (nowhere vanishing) on which we know to induce an orientation on . To prove my claim, I first extend to a basis using that every vector space has one (or should I treat as a free -module?). Then I re-order the basis so that the volume form induces the same orientation as that of . To prove is a volume form I take for each a basis of such that is it's dual basis. i.e. and then and thus non zero.","M n f:M\to \mathbb{R} 0 f^{-1}(0) n-1 d \varphi=(\varphi^1,\cdots,\varphi^n) M f 0 df 1 f*_p p\in f^{-1}(0) df=\sum\limits_{k=1}^n \frac{\partial f\circ \varphi^{-1}}{\partial x^k}d\varphi^{k} f^{-1}(0) M N df N N \{\omega_1,\cdots, \omega_{n-1},df\} \Omega^1N  N \eta=\omega_1\wedge\cdots\wedge \omega_{n-1}\wedge df 0 N \eta_p\neq 0 p\in N i:f^{-1}(0)\hookrightarrow N \omega_1\wedge\cdots\wedge \omega_{n-1} n-1 N \rho = i^*(\omega_1\wedge\cdots\wedge \omega_{n-1})=i^*\omega_1\wedge\cdots\wedge i^*\omega_{n-1}=(\omega_1\circ i)\wedge\cdots\wedge (\omega_{n-1}\circ i) n-1 f^{-1}(0) \rho_q=0 \eta_{i(q)}=0 \rho f^{-1}(0) f^{-1}(0) \{df\} \Omega^1 N C^\infty \eta N \eta p\in N \{v_1,\cdots,v_n\} T_pN \{\omega_1,\cdots,\omega_{n-1},df\} \omega_{k}(v_j)=\delta_{kj} df(v_j)=\delta_{nj} \eta_p(v_1,\cdots,v_n)=1","['differential-geometry', 'smooth-manifolds', 'differential-forms', 'orientation']"
86,$\mathbb{S}^n$ is a topological $n$-manifold.,is a topological -manifold.,\mathbb{S}^n n,"In Lee's ""Introduction to Smooth Manifolds"" he provides the following example showing that $\mathbb{S}^n$ is a topological $n$ -manifold. For each integer $n \geq 0$ , the unit $n$ -sphere $\mathbb{S}^n$ is Hausdorff and second-countable because it is a topological subspace of $\mathbb{R}^{n+1}$ . To show that it is locally Euclidean, for each index $i = 1, \ldots, n+1$ let $U_i^+$ denote the subset of $\mathbb{R}^{n+1}$ where the $i$ th coordinate is positive: $$U_i^+ = \big\{(x^1, \ldots, x^{n+1}) \in \mathbb{R}^{n+1}: x^i > 0\big\}.$$ Similarly, $U_i^-$ is the set where $x^i < 0$ . Let $f: \mathbb{B}^n \rightarrow \mathbb{R}$ be the continuous function $$f(u) = \sqrt{1-|u|^2}.$$ Then for each $i = 1, \ldots, n+1$ , it is easy to check that $U_i^+ \cap \mathbb{S}^n$ is the graph of the function $$x^i = f(x^1, \ldots, \hat{x}^i, \ldots, x^{n+1}),$$ where the hat indicates that $x^i$ is omitted. Similarly, $U_i^- \cap \mathbb{S}^n$ is the graph of the function $$x^i = -f(x^1, \ldots, \hat{x}^i, \ldots, x^{n+1}).$$ Thus, each subset $U_i^\pm \cap \mathbb{S}^n$ is locally Euclidean of dimension $n$ , and the maps $\varphi_i^\pm: U_i^\pm \cap \mathbb{S}^n \rightarrow \mathbb{B}^n$ given by $$\varphi_i^\pm(x^1, \ldots, x^{n+1}) = (x^1, \ldots, \hat{x}^i, \ldots, x^{n+1})$$ are graph coordinates for $\mathbb{S}^n$ . Since each point of $\mathbb{S}^n$ is in the domain of at least one of these $2n+2$ charts, $\mathbb{S}^n$ is a topolgoical $n$ -manifold. My question is perhaps more on notation, but how is $U_i^+ \cap \mathbb{S}^n$ (likewise for $U_i^- \cap \mathbb{S}^n$ ) a graph using the given definition? As I understand it, we are omitting $x^i$ when passing the point in $\mathbb{R}^{n+1}$ into $f$ , is the result of the function the new value for $x^i$ ? However, this seems incorrect as $\varphi$ doesn't seem to involve $f$ at all, so how does it follow that the maps are indeed graph coordinates (or more generally, coordinate maps)?","In Lee's ""Introduction to Smooth Manifolds"" he provides the following example showing that is a topological -manifold. For each integer , the unit -sphere is Hausdorff and second-countable because it is a topological subspace of . To show that it is locally Euclidean, for each index let denote the subset of where the th coordinate is positive: Similarly, is the set where . Let be the continuous function Then for each , it is easy to check that is the graph of the function where the hat indicates that is omitted. Similarly, is the graph of the function Thus, each subset is locally Euclidean of dimension , and the maps given by are graph coordinates for . Since each point of is in the domain of at least one of these charts, is a topolgoical -manifold. My question is perhaps more on notation, but how is (likewise for ) a graph using the given definition? As I understand it, we are omitting when passing the point in into , is the result of the function the new value for ? However, this seems incorrect as doesn't seem to involve at all, so how does it follow that the maps are indeed graph coordinates (or more generally, coordinate maps)?","\mathbb{S}^n n n \geq 0 n \mathbb{S}^n \mathbb{R}^{n+1} i = 1, \ldots, n+1 U_i^+ \mathbb{R}^{n+1} i U_i^+ = \big\{(x^1, \ldots, x^{n+1}) \in \mathbb{R}^{n+1}: x^i > 0\big\}. U_i^- x^i < 0 f: \mathbb{B}^n \rightarrow \mathbb{R} f(u) = \sqrt{1-|u|^2}. i = 1, \ldots, n+1 U_i^+ \cap \mathbb{S}^n x^i = f(x^1, \ldots, \hat{x}^i, \ldots, x^{n+1}), x^i U_i^- \cap \mathbb{S}^n x^i = -f(x^1, \ldots, \hat{x}^i, \ldots, x^{n+1}). U_i^\pm \cap \mathbb{S}^n n \varphi_i^\pm: U_i^\pm \cap \mathbb{S}^n \rightarrow \mathbb{B}^n \varphi_i^\pm(x^1, \ldots, x^{n+1}) = (x^1, \ldots, \hat{x}^i, \ldots, x^{n+1}) \mathbb{S}^n \mathbb{S}^n 2n+2 \mathbb{S}^n n U_i^+ \cap \mathbb{S}^n U_i^- \cap \mathbb{S}^n x^i \mathbb{R}^{n+1} f x^i \varphi f","['differential-geometry', 'manifolds', 'smooth-manifolds']"
87,Details of the self-map on $BO_\infty$ which exchanges tangential and stable-normal structures?,Details of the self-map on  which exchanges tangential and stable-normal structures?,BO_\infty,"According to Remark 2.14 in these notes , there is a self-map $s : BO_\infty \rightarrow BO_\infty$ which ""exchanges the stable normal and tangential structures"". As I understand it, this means for $X$ a smooth manifold, with tangent bundle classifying map $\tau : X \rightarrow BO_{\mathrm{dim}X} \hookrightarrow BO_\infty$ , and with stable normal bundle classifying map $\nu : X \rightarrow BO_\infty$ , then $\tau = s \circ \nu$ and $\nu = s\circ \tau$ (only up to homotopy?). (Here the stable normal bundle is the normal bundle to $X$ w.r.t. a smooth embedding of $X$ in some $S^m$ , for $m$ large enough that all embeddings of $X$ in $S^m$ are isotopic, modulo stable equivalence; the homotopy class of the resulting $X \rightarrow BO_\infty$ should be independent of the choice of $m$ and the embedding. As described in the notes linked above, such an $m$ depending only on $\mathrm{dim}X$ can be chosen following a theorem of Whitney.) Would anyone be able to suggest a hint on how to find such a map $s$ ? Or, could anyone suggest a source that explains the details of this construction?","According to Remark 2.14 in these notes , there is a self-map which ""exchanges the stable normal and tangential structures"". As I understand it, this means for a smooth manifold, with tangent bundle classifying map , and with stable normal bundle classifying map , then and (only up to homotopy?). (Here the stable normal bundle is the normal bundle to w.r.t. a smooth embedding of in some , for large enough that all embeddings of in are isotopic, modulo stable equivalence; the homotopy class of the resulting should be independent of the choice of and the embedding. As described in the notes linked above, such an depending only on can be chosen following a theorem of Whitney.) Would anyone be able to suggest a hint on how to find such a map ? Or, could anyone suggest a source that explains the details of this construction?",s : BO_\infty \rightarrow BO_\infty X \tau : X \rightarrow BO_{\mathrm{dim}X} \hookrightarrow BO_\infty \nu : X \rightarrow BO_\infty \tau = s \circ \nu \nu = s\circ \tau X X S^m m X S^m X \rightarrow BO_\infty m m \mathrm{dim}X s,"['differential-geometry', 'algebraic-topology', 'vector-bundles', 'principal-bundles', 'classifying-spaces']"
88,Is the fact $f$ is a Lipschitz function implies $|\text{grad} f| \leq 1$ true for functions on Riemannian manifolds?,Is the fact  is a Lipschitz function implies  true for functions on Riemannian manifolds?,f |\text{grad} f| \leq 1,"This fact is immediate if $M = \mathbb R^n$ since we can write $\partial_i f = \lim \frac{f(x+te_i) - f(x)}{t}$ . But I didn't know whether it holds for complete Riemannian manifolds. Recently, I'm reading Geometric Analysis by Peter Li. The proof of the Cheeger-Gromoll splitting theorem in his book(Theorem 4.4) is more simple than the one on Peterson's book, which avoid the application of smooth support functions, but I don't think it is rigorous enough, so I want some help. In the last few lines on Page 35, he said that ''By regularity theory, $\beta^+$ is a smooth harmonic function with $|\nabla \beta^+| \leq 1$ '', where $\beta^+$ denotes the Buseman function. Obviously, $\beta^+$ is Lipschitz, but I'm wondering how to derive the property that $|\nabla \beta^+| \leq 1$ . For your reference, the book can be found at https://www.cambridge.org/core/books/geometric-analysis/D0A2375D56122B91A0BA370530978248 After viewing the comments, it is true and can be proved as follows. We choose the normal coordinates centered at $x$ , then $|grad \beta(x)| = \sum_j (\partial_j \beta)^2$ . Suppose by contradiction that $|grad \beta(x)| > 1$ , then there exists a small neighborhood $U$ near $x$ such that $\sum_j (\partial_i \beta)^2 > 1$ for all $y\in U$ . Choose $y\in U$ such that the unique minimizing normal geodesic $\gamma$ with $\gamma(0) = x$ and $\gamma(1) = y$ satisfies $\dot\gamma_k(t) = \partial_k\beta(\gamma(t))$ for all $t\in [0,1]$ , $k = 1,\ldots, m$ . Then by the Lipschitz condition, $$   1\geq \frac{\beta(\gamma(t)) - \beta(x)}{t} = \frac1{t}\int_0^t \langle{\nabla \beta, \dot\gamma\rangle}\, ds    = \frac1{t}\int_0^t \sum_{k=1}^m \partial_k\beta \dot\gamma_k\, ds    = \frac1{t}\int_0^t \sum_k (\partial_k \beta)^2 > 1,   $$ which is a contradiction.","This fact is immediate if since we can write . But I didn't know whether it holds for complete Riemannian manifolds. Recently, I'm reading Geometric Analysis by Peter Li. The proof of the Cheeger-Gromoll splitting theorem in his book(Theorem 4.4) is more simple than the one on Peterson's book, which avoid the application of smooth support functions, but I don't think it is rigorous enough, so I want some help. In the last few lines on Page 35, he said that ''By regularity theory, is a smooth harmonic function with '', where denotes the Buseman function. Obviously, is Lipschitz, but I'm wondering how to derive the property that . For your reference, the book can be found at https://www.cambridge.org/core/books/geometric-analysis/D0A2375D56122B91A0BA370530978248 After viewing the comments, it is true and can be proved as follows. We choose the normal coordinates centered at , then . Suppose by contradiction that , then there exists a small neighborhood near such that for all . Choose such that the unique minimizing normal geodesic with and satisfies for all , . Then by the Lipschitz condition, which is a contradiction.","M = \mathbb R^n \partial_i f = \lim \frac{f(x+te_i) - f(x)}{t} \beta^+ |\nabla \beta^+| \leq 1 \beta^+ \beta^+ |\nabla \beta^+| \leq 1 x |grad \beta(x)| = \sum_j (\partial_j \beta)^2 |grad \beta(x)| > 1 U x \sum_j (\partial_i \beta)^2 > 1 y\in U y\in U \gamma \gamma(0) = x \gamma(1) = y \dot\gamma_k(t) = \partial_k\beta(\gamma(t)) t\in [0,1] k = 1,\ldots, m 
  1\geq \frac{\beta(\gamma(t)) - \beta(x)}{t} = \frac1{t}\int_0^t \langle{\nabla \beta, \dot\gamma\rangle}\, ds 
  = \frac1{t}\int_0^t \sum_{k=1}^m \partial_k\beta \dot\gamma_k\, ds 
  = \frac1{t}\int_0^t \sum_k (\partial_k \beta)^2 > 1,
  ","['real-analysis', 'differential-geometry', 'riemannian-geometry', 'lipschitz-functions']"
89,Regarding a proof that $T(M\times N) \cong TM\times TN$,Regarding a proof that,T(M\times N) \cong TM\times TN,"I want to ask about the answer in this link: Tangent Bundle of Product Manifold How is the identification $T_{(x,y)}(M\times N)=T_xM\oplus T_yN$ used in (*) ? And in writing $T(M\times N)$ and $TM\oplus TN$ this way as sets (lines 4-6), are we also using that $T_xM=R^m$ and $T_yN=R^n$ ? Why is $\phi$ a diffeomorphism? And is the last conclusion that ${\phi}^{\sim}$ a diffeomorphis a sort of a theorem? Thanks a lot","I want to ask about the answer in this link: Tangent Bundle of Product Manifold How is the identification used in (*) ? And in writing and this way as sets (lines 4-6), are we also using that and ? Why is a diffeomorphism? And is the last conclusion that a diffeomorphis a sort of a theorem? Thanks a lot","T_{(x,y)}(M\times N)=T_xM\oplus T_yN T(M\times N) TM\oplus TN T_xM=R^m T_yN=R^n \phi {\phi}^{\sim}","['differential-geometry', 'manifolds', 'tangent-bundle']"
90,Relating the Lie derivative to inner product of 2-tensors,Relating the Lie derivative to inner product of 2-tensors,,"Let $(M,g)$ be a Riemannian manifold. Let $f \in C^\infty(M)$ , $X$ be a vector field and $h$ be a (symmetric) covariant $2$ -tensor. Denote by $\langle \cdot, \cdot \rangle$ the inner product induced by the metric $g$ on the space of covariant $2$ -tensors. I would like to know why the following formula holds: $$\langle df \otimes df, \mathcal{L}_X(h)  \rangle = (\mathcal{L}_X(h))(\nabla f, \nabla f).$$ Here, $\mathcal{L}_X$ is the Lie derivative in the direction of $X$ and $\nabla f$ is the gradient of $f$ . I am sorry if this is a silly question, but I have never seen such identity.","Let be a Riemannian manifold. Let , be a vector field and be a (symmetric) covariant -tensor. Denote by the inner product induced by the metric on the space of covariant -tensors. I would like to know why the following formula holds: Here, is the Lie derivative in the direction of and is the gradient of . I am sorry if this is a silly question, but I have never seen such identity.","(M,g) f \in C^\infty(M) X h 2 \langle \cdot, \cdot \rangle g 2 \langle df \otimes df, \mathcal{L}_X(h) 
\rangle = (\mathcal{L}_X(h))(\nabla f, \nabla f). \mathcal{L}_X X \nabla f f","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'tensors']"
91,"The commutator $[\Delta, \nabla_i]$ of the Laplacian and covariant derivative",The commutator  of the Laplacian and covariant derivative,"[\Delta, \nabla_i]","Let $\nabla$ be a Riemannian connection, $\Delta$ be the Laplacian defined as $\text{tr}_g \nabla^2$ . The equation I want to show is $$ \Delta\nabla_i f = \nabla_i\Delta f + \sum_{j} Ric_{ij} \nabla_jf   $$ where $Ric$ is the Ricci curvature tensor, $f$ is a smooth function. The proof my text gives is (they use the convention that basically $g_{ij} = \delta_{ij}$ which I am not using) $$ \Delta \nabla_i f = \nabla_j\nabla_i\nabla_j f = \nabla_i\nabla_j\nabla_j f - R_{jijk} \nabla_k f $$ ...which I understand 0% about it. My guess is that the first interchange $$   \begin{align*}     \Delta\nabla_i f &= \sum_{j,k}g^{jk}\nabla_j\nabla_k\nabla_i f = \sum_{j,k}g^{jk}\nabla_j\nabla_i\nabla_k f    \end{align*} $$ is free since $\nabla_i\nabla_j f = \nabla_j \nabla_if$ and $\nabla$ has no torsion. But what about the second one (i.e. how do we interchange $\nabla_j$ and $\nabla_i$ ?) Edit: so I've found and use the Ricci identity for 1-forms $$   (\nabla_i \nabla_j - \nabla_j \nabla_i) w(\partial_k) = w(R(\partial_j,\partial_i)\partial_k) = \sum_{l} w^l R_{jik}^l $$ put $w = \nabla f$ says $$   (\nabla_i \nabla_j - \nabla_j \nabla_i) \nabla f(\partial_k) =   (\nabla_i \nabla_j - \nabla_j \nabla_i) \nabla_k f =  \sum_{l} (\nabla f)^l R_{jik}^l $$ and I don't know how to proceed to get $Ric$ .","Let be a Riemannian connection, be the Laplacian defined as . The equation I want to show is where is the Ricci curvature tensor, is a smooth function. The proof my text gives is (they use the convention that basically which I am not using) ...which I understand 0% about it. My guess is that the first interchange is free since and has no torsion. But what about the second one (i.e. how do we interchange and ?) Edit: so I've found and use the Ricci identity for 1-forms put says and I don't know how to proceed to get .","\nabla \Delta \text{tr}_g \nabla^2 
\Delta\nabla_i f = \nabla_i\Delta f + \sum_{j} Ric_{ij} \nabla_jf  
 Ric f g_{ij} = \delta_{ij} 
\Delta \nabla_i f = \nabla_j\nabla_i\nabla_j f = \nabla_i\nabla_j\nabla_j f - R_{jijk} \nabla_k f
 
  \begin{align*}
    \Delta\nabla_i f &= \sum_{j,k}g^{jk}\nabla_j\nabla_k\nabla_i f = \sum_{j,k}g^{jk}\nabla_j\nabla_i\nabla_k f 
  \end{align*}
 \nabla_i\nabla_j f = \nabla_j \nabla_if \nabla \nabla_j \nabla_i 
  (\nabla_i \nabla_j - \nabla_j \nabla_i) w(\partial_k) = w(R(\partial_j,\partial_i)\partial_k) = \sum_{l} w^l R_{jik}^l
 w = \nabla f 
  (\nabla_i \nabla_j - \nabla_j \nabla_i) \nabla f(\partial_k) =
  (\nabla_i \nabla_j - \nabla_j \nabla_i) \nabla_k f =  \sum_{l} (\nabla f)^l R_{jik}^l
 Ric","['differential-geometry', 'riemannian-geometry', 'tensors']"
92,Formula for the interior product of a p-form,Formula for the interior product of a p-form,,"Let $X: \mathbb{R}^n \to \mathbb{R}^n$ be a vector field and let $$\omega = \sum_{i_1 < \dots < i_p} f_{i_1\dots i_p} dx_{i_1} \wedge \dots \wedge dx_{i_p}$$ be a $p$ -form over $\mathbb{R}^n$ . I am interested in a formula for the interior product $i_X\omega$ . (Choose $n=3$ and $X(x,y,z) = (z,y,-x)$ for all examples below.) $p = 1$ : \begin{align} \omega &= \sum_i f_i dx_i &\Rightarrow \quad i_X\omega &= \sum_i f_iX_i\\ \omega &= dx + zdy + zdz &\Rightarrow \quad i_X \omega &= X_x + zX_y + zX_z\\ & & &= z + yz - xz \end{align} $p = 2$ : \begin{align} \omega &= \sum_{i < j} f_{ij} dx_i \wedge dx_j &\Rightarrow \quad i_X\omega &= \sum_{i < j} f_{ij} \left( X_i dx_j - X_j dx_i \right)\\ \omega &= dx \wedge dy + dx \wedge dz &\Rightarrow \quad i_X \omega &= X_xdy - X_ydx + X_xdz - X_zdx\\ & & &= zdy - ydx + zdz + xdx \\ & & &= \left( x - y \right)dx + zdy + zdz \end{align} $p = 3$ : \begin{align} \omega &= \sum_{i < j < k} f_{ijk} dx_i \wedge dx_j \wedge dx_k &&\Rightarrow \quad i_X\omega =\ ???\\ \omega &= 2zdx \wedge dy \wedge dz &&\Rightarrow \quad i_X\omega =\ ??? \end{align} Questions Are my formulas and examples for $p=1$ and $p=2$ correct? What is the formula for $p \geq 3$ ?",Let be a vector field and let be a -form over . I am interested in a formula for the interior product . (Choose and for all examples below.) : : : Questions Are my formulas and examples for and correct? What is the formula for ?,"X: \mathbb{R}^n \to \mathbb{R}^n \omega = \sum_{i_1 < \dots < i_p} f_{i_1\dots i_p} dx_{i_1} \wedge \dots \wedge dx_{i_p} p \mathbb{R}^n i_X\omega n=3 X(x,y,z) = (z,y,-x) p = 1 \begin{align}
\omega &= \sum_i f_i dx_i &\Rightarrow \quad i_X\omega &= \sum_i f_iX_i\\
\omega &= dx + zdy + zdz &\Rightarrow \quad i_X \omega &= X_x + zX_y + zX_z\\
& & &= z + yz - xz
\end{align} p = 2 \begin{align}
\omega &= \sum_{i < j} f_{ij} dx_i \wedge dx_j &\Rightarrow \quad i_X\omega &= \sum_{i < j} f_{ij} \left( X_i dx_j - X_j dx_i \right)\\
\omega &= dx \wedge dy + dx \wedge dz &\Rightarrow \quad i_X \omega &= X_xdy - X_ydx + X_xdz - X_zdx\\
& & &= zdy - ydx + zdz + xdx \\
& & &= \left( x - y \right)dx + zdy + zdz
\end{align} p = 3 \begin{align}
\omega &= \sum_{i < j < k} f_{ijk} dx_i \wedge dx_j \wedge dx_k &&\Rightarrow \quad i_X\omega =\ ???\\
\omega &= 2zdx \wedge dy \wedge dz &&\Rightarrow \quad i_X\omega =\ ???
\end{align} p=1 p=2 p \geq 3","['differential-geometry', 'differential-forms', 'vector-fields']"
93,Natural manifold topology vs. product topology,Natural manifold topology vs. product topology,,"Let $M = \mathbb{R} \times \mathbb{R}$ , where the first factor is endowed with the discrete topology and the second with the usual Euclidean topology and so $M$ has the resulting product topology. Show that $M$ admits a differentiable structure such that the natural manifold topology on $M$ is the product topology, hence in particular not second countable. While trying to solve this I encountered some contradiction. I am quite sure my reasoning fails somewhere, but I am not too sure where. Here's my approach: $${}$$ ( I ) $\enspace$ The product topology is the topology such that the canonical projections are all continuous. Equivalently, the preimages of open sets under the canonical projections form a subbasis. In the above case of $\mathbb{R} \times \mathbb{R}$ this means that the open sets are of the form $$ \{ x \} \times (a,b) \quad , \qquad x \in \mathbb{R},  \; a < b \quad . \tag{$\ast$}$$ and unions thereof. (Correct?) ( II ) $\enspace$ The natural manifold topology is the topology such that for a maximal atlas $A_{max} = \{ \, (\phi_i, U_i ) \; | \; i \in I \, \}$ the set $\{ U_i \}_{i \in I}$ forms a basis. ( III ) $\enspace$ I now define an atlas as $A = \{ \, (id_{\mathbb{R}^2}, V ) \; | \; V \in \tau_{\text{euclidean}} \, \}$ , which obviously consists of all identity maps on open sets with respect to Euclidean topology. I now want to show that all $V \in \tau_{\text{euclidean}}$ are also elements of $\tau_{\text{product}}$ . ( IV ) $\enspace$ In order to show said property, I just have to express an open ball (because every open set in Euclidean topology is the union of such balls) in terms of these ""sliced intervals"" in $(\ast)$ . So for an open Ball with radius $r > 0$ and center $(m_1,m_2) \in \mathbb{R}^2$ : $$ B_r(m) \enspace = \enspace \bigcup_{x \in (m_1-r,m_1+r)} \{x\} \times (m_2 - \varepsilon_x, m_2 + \varepsilon_x) \quad , \qquad \varepsilon_x = r \cdot \cos \big[ \tfrac{\pi}{2r}(x-m_1) \big] $$ Which shows that the open sets $V \in \tau_{\text{euclidean}}$ are also $V \in \tau_{\text{product}}$ and by the convenient choice of coordinate charts being the identity, these charts $id_{\mathbb{R}^2} : V \longrightarrow V$ are homeomorphisms with respect to $\tau_{\text{product}}$ . This, however, would mean that $\tau_{\text{euclidean}} = \tau_{\text{product}}$ , contradicting that $M$ is not second-countable. $${}$$ Where am I wrong? Which concept do I misunderstand?","Let , where the first factor is endowed with the discrete topology and the second with the usual Euclidean topology and so has the resulting product topology. Show that admits a differentiable structure such that the natural manifold topology on is the product topology, hence in particular not second countable. While trying to solve this I encountered some contradiction. I am quite sure my reasoning fails somewhere, but I am not too sure where. Here's my approach: ( I ) The product topology is the topology such that the canonical projections are all continuous. Equivalently, the preimages of open sets under the canonical projections form a subbasis. In the above case of this means that the open sets are of the form and unions thereof. (Correct?) ( II ) The natural manifold topology is the topology such that for a maximal atlas the set forms a basis. ( III ) I now define an atlas as , which obviously consists of all identity maps on open sets with respect to Euclidean topology. I now want to show that all are also elements of . ( IV ) In order to show said property, I just have to express an open ball (because every open set in Euclidean topology is the union of such balls) in terms of these ""sliced intervals"" in . So for an open Ball with radius and center : Which shows that the open sets are also and by the convenient choice of coordinate charts being the identity, these charts are homeomorphisms with respect to . This, however, would mean that , contradicting that is not second-countable. Where am I wrong? Which concept do I misunderstand?","M = \mathbb{R} \times \mathbb{R} M M M {} \enspace \mathbb{R} \times \mathbb{R}  \{ x \} \times (a,b) \quad , \qquad x \in \mathbb{R},  \; a < b \quad . \tag{\ast} \enspace A_{max} = \{ \, (\phi_i, U_i ) \; | \; i \in I \, \} \{ U_i \}_{i \in I} \enspace A = \{ \, (id_{\mathbb{R}^2}, V ) \; | \; V \in \tau_{\text{euclidean}} \, \} V \in \tau_{\text{euclidean}} \tau_{\text{product}} \enspace (\ast) r > 0 (m_1,m_2) \in \mathbb{R}^2  B_r(m) \enspace = \enspace \bigcup_{x \in (m_1-r,m_1+r)} \{x\} \times (m_2 - \varepsilon_x, m_2 + \varepsilon_x) \quad , \qquad \varepsilon_x = r \cdot \cos \big[ \tfrac{\pi}{2r}(x-m_1) \big]  V \in \tau_{\text{euclidean}} V \in \tau_{\text{product}} id_{\mathbb{R}^2} : V \longrightarrow V \tau_{\text{product}} \tau_{\text{euclidean}} = \tau_{\text{product}} M {}","['differential-geometry', 'differential-topology', 'smooth-manifolds']"
94,Concrete example of Lie derivative of a vector field,Concrete example of Lie derivative of a vector field,,"I am struggling a lot with the concept of Lie derivative. I am studying it just in $\mathbb{R}^n$ not in a general manifold context. I have that its definition is: $$[v,w]:= \frac{d}{dt}((g_v^{-t})_*w)|_{t=0}$$ where $v,w$ are vector fields on an open $U \subset R^n$ , $g_v^t$ is the ""phase flow"" of $v$ and where the lower star index denotes the ""push-forward map"". Could you please provide an example of its calculation? Maybe working in $\mathbb{R}^2$ and choosing simple vector fields. For instance, let $v$ be the vector field given by $v_{(x,y)} = x (d/dx) + y (d/dy)$ and $w_{(x,y)} = (d/dx) + (d/dy)$ . What does $[v,w]$ equal to here?","I am struggling a lot with the concept of Lie derivative. I am studying it just in not in a general manifold context. I have that its definition is: where are vector fields on an open , is the ""phase flow"" of and where the lower star index denotes the ""push-forward map"". Could you please provide an example of its calculation? Maybe working in and choosing simple vector fields. For instance, let be the vector field given by and . What does equal to here?","\mathbb{R}^n [v,w]:= \frac{d}{dt}((g_v^{-t})_*w)|_{t=0} v,w U \subset R^n g_v^t v \mathbb{R}^2 v v_{(x,y)} = x (d/dx) + y (d/dy) w_{(x,y)} = (d/dx) + (d/dy) [v,w]","['differential-geometry', 'lie-derivative']"
95,What is adjoint bundle for trivial bundle?,What is adjoint bundle for trivial bundle?,,"Let $P =M\times G\to M$ be a principal $G$ -bundle on $M$ (first coordinate projection) What is $ad(P)$ ? Here $ad(E) = E\times_{Ad}g$ is a vector bundle on $M$ [where $g$ = Lie $(G)$ , $E$ is any principal $G$ -bundle on $M$ ] . My expectation is that it is the trivial bundle on $M$ . Any element in $ad(P)$ is $[(m,g),v] \sim [(m,e).g,v] \sim [(m,e), Ad_{g}v]$ . I need an isomorphism from $ad(P) \to M\times g$ . Here $e$ is the identity element in $G$ . All spaces are smooth manifolds and groups are Lie groups. Edit : I am adding the wiki link for adjoint bundle to avoid any confusion. https://en.wikipedia.org/wiki/Adjoint_bundle","Let be a principal -bundle on (first coordinate projection) What is ? Here is a vector bundle on [where = Lie , is any principal -bundle on ] . My expectation is that it is the trivial bundle on . Any element in is . I need an isomorphism from . Here is the identity element in . All spaces are smooth manifolds and groups are Lie groups. Edit : I am adding the wiki link for adjoint bundle to avoid any confusion. https://en.wikipedia.org/wiki/Adjoint_bundle","P =M\times G\to M G M ad(P) ad(E) = E\times_{Ad}g M g (G) E G M M ad(P) [(m,g),v] \sim [(m,e).g,v] \sim [(m,e), Ad_{g}v] ad(P) \to M\times g e G","['differential-geometry', 'lie-groups', 'vector-bundles', 'principal-bundles']"
96,Connection on a principal $S^1$ bundle,Connection on a principal  bundle,S^1,"Let $\pi:M\to B$ be a principal $S^1$ -bundle over a symplectic manifold $(B,\omega)$ . Is it always possible to construct a vector field $R\in \mathfrak{X}(M)$ such that the $S^1$ action on $M$ is generated by the flow of $R$ ? If yes, how do you prove it? Given the existence of this vector field $R$ , is it true that a principal connection on this bundle is just a 1-form $\alpha\in \Omega^1M$ satisfying $\mathcal L_R\alpha=0$ and $\alpha(R)=1$ ? Is it equivalent to the usual conditions of equivariant and normalization?","Let be a principal -bundle over a symplectic manifold . Is it always possible to construct a vector field such that the action on is generated by the flow of ? If yes, how do you prove it? Given the existence of this vector field , is it true that a principal connection on this bundle is just a 1-form satisfying and ? Is it equivalent to the usual conditions of equivariant and normalization?","\pi:M\to B S^1 (B,\omega) R\in \mathfrak{X}(M) S^1 M R R \alpha\in \Omega^1M \mathcal L_R\alpha=0 \alpha(R)=1","['differential-geometry', 'connections', 'principal-bundles']"
97,"Proving that the tangent space, considered as a set of equivalence classes of contours, is a vector space.","Proving that the tangent space, considered as a set of equivalence classes of contours, is a vector space.",,"[Note: Before you simply paste a link, I've already read several other similarly-phrased posts on this site, none of which quite answer my question or phrase it in a way I understand.] Wikipedia defines the tangent space $T_xM$ of an $n$ -manifold $M$ at $x\in M$ as follows.  Let $\varphi:U\rightarrow \mathbb{R}^n$ a chart, where $U\ni x$ is an open subset of $M$ , and define $$X\varphi_x(\gamma):=\frac{d}{dt}\left[\varphi\circ \gamma\right]\Big\rvert_{t=0}$$ over the set $C_{U,x}$ of contours $\gamma:I_{\gamma}\rightarrow U$ , $I_{\gamma}$ a sufficiently small interval around 0, such that $\gamma(0) = x$ and $\varphi\circ\gamma$ is smooth.  Also, wlog, assume that $\varphi(x) = 0$ for simplicity. Then $T_xM$ is the set $C_{U,x}$ modulo $\sim$ , where $$\gamma_1\sim\gamma_2\quad\Leftrightarrow\quad X\varphi_x(\gamma_1) = X\varphi_x(\gamma_2).$$ (It is straightforward to show that this definition does not depend on the choice of $\varphi$ or $U$ .) Now, Wikipedia says that $X\varphi_x(\gamma)$ induces a bijective map from $T_xM$ to $\mathbb{R}^n$ , which gives a vector space structure to $T_xM$ .  I understand why the map is well-defined and injective, but I do not understand how to prove surjectivity without using the fact that $T_xM$ is a vector space, a fact that (so Wikipedia suggests) should follow from surjectivity of $X\varphi_x$ and not the other way round.  Here's my approach so far: Define $\gamma_k(t):= \varphi^{-1}(t\cdot e_k)$ , where $e_k$ is the unit vector in $\mathbb{R}^n$ with a $1$ as its $k^{th}$ component.  Then $$X\varphi_x(\gamma_k[t]) = e_k.$$ If $T_xM$ is defined as the free vector space with base $\{\gamma_1, \dots, \gamma_n\}$ and $X\varphi_x:T_xM\rightarrow\mathbb{R}^n$ is assumed to be a linear map, then the conclusion that $X\varphi_x$ is surjective follows from the universal property of free modules.  But as I write above, this seems like putting the cart before the horse, proving that the map is surjective from the fact that $T_xM$ is a vector space and not v.v. ; and even if this approach is correct, it's not clear that we are allowed to assume that $X\varphi_x$ is linear as a function of $T_xM$ (unless we extend it to be the unique homomorphism guaranteed by the universal property ). indeed, why does the map $X\varphi_x$ matter at all if we can show that $T_xM$ is a vector space another way? What am I missing?  Can I prove that $T_xM$ is a vector space using only the tangent vector definition ( i.e. , without also using the definition in terms of derivations)?","[Note: Before you simply paste a link, I've already read several other similarly-phrased posts on this site, none of which quite answer my question or phrase it in a way I understand.] Wikipedia defines the tangent space of an -manifold at as follows.  Let a chart, where is an open subset of , and define over the set of contours , a sufficiently small interval around 0, such that and is smooth.  Also, wlog, assume that for simplicity. Then is the set modulo , where (It is straightforward to show that this definition does not depend on the choice of or .) Now, Wikipedia says that induces a bijective map from to , which gives a vector space structure to .  I understand why the map is well-defined and injective, but I do not understand how to prove surjectivity without using the fact that is a vector space, a fact that (so Wikipedia suggests) should follow from surjectivity of and not the other way round.  Here's my approach so far: Define , where is the unit vector in with a as its component.  Then If is defined as the free vector space with base and is assumed to be a linear map, then the conclusion that is surjective follows from the universal property of free modules.  But as I write above, this seems like putting the cart before the horse, proving that the map is surjective from the fact that is a vector space and not v.v. ; and even if this approach is correct, it's not clear that we are allowed to assume that is linear as a function of (unless we extend it to be the unique homomorphism guaranteed by the universal property ). indeed, why does the map matter at all if we can show that is a vector space another way? What am I missing?  Can I prove that is a vector space using only the tangent vector definition ( i.e. , without also using the definition in terms of derivations)?","T_xM n M x\in M \varphi:U\rightarrow \mathbb{R}^n U\ni x M X\varphi_x(\gamma):=\frac{d}{dt}\left[\varphi\circ \gamma\right]\Big\rvert_{t=0} C_{U,x} \gamma:I_{\gamma}\rightarrow U I_{\gamma} \gamma(0) = x \varphi\circ\gamma \varphi(x) = 0 T_xM C_{U,x} \sim \gamma_1\sim\gamma_2\quad\Leftrightarrow\quad X\varphi_x(\gamma_1) = X\varphi_x(\gamma_2). \varphi U X\varphi_x(\gamma) T_xM \mathbb{R}^n T_xM T_xM X\varphi_x \gamma_k(t):= \varphi^{-1}(t\cdot e_k) e_k \mathbb{R}^n 1 k^{th} X\varphi_x(\gamma_k[t]) = e_k. T_xM \{\gamma_1, \dots, \gamma_n\} X\varphi_x:T_xM\rightarrow\mathbb{R}^n X\varphi_x T_xM X\varphi_x T_xM X\varphi_x T_xM T_xM","['differential-geometry', 'vector-spaces', 'differential-topology', 'tangent-spaces']"
98,"What is the point of the idea of ""contact"" in differential geometry?","What is the point of the idea of ""contact"" in differential geometry?",,"I've been having introductory lectures on differential geometry and we came to the idea of ""contact"". There are two definitions: Let $\alpha: I \to \Bbb{R}^3$ and $\beta: \overline{I} \to \Bbb{R}^3$ be regular curves such that $\alpha(t_0)=\beta (t_0)$ with $t_0 \in I \cap \overline{I}$ . We say $\alpha,\beta$ have contact of order $n$ in $t_0$ if all derivatives of order $\leq n$ of $\alpha,\beta$ coincide in $t_0$ and the derivatives of order $n+1$ in $t_0$ are distinct. Let $\alpha:I\to \Bbb{R}^3$ a regular curve and $\pi$ a plane in $\Bbb{R}^3$ with a point $p=\alpha(t_0)$ for some $t_0\in I$ . We say $\alpha$ and $\pi$ has contact of order $n$ in $p$ if there exists a regular curve $\beta: \overline{I} \to \Bbb{R}^3$ such that $\beta(\overline{I})\subset \pi$ and $\alpha,\beta$ haver contact of order $n$ in $t_0$ . And two theorems asserting that: The only straight line with contact $1$ in a point of a curve is the tangent line. The only plane with contact $2$ in a point in a curve is the osculating plane. But at least in the book I am reading, it seems it stops there. We just define ""contact"" and check that there are special lines and planes with a certain degrees of ""contact"". So I am curious: What is the point of the idea of ""contact""?","I've been having introductory lectures on differential geometry and we came to the idea of ""contact"". There are two definitions: Let and be regular curves such that with . We say have contact of order in if all derivatives of order of coincide in and the derivatives of order in are distinct. Let a regular curve and a plane in with a point for some . We say and has contact of order in if there exists a regular curve such that and haver contact of order in . And two theorems asserting that: The only straight line with contact in a point of a curve is the tangent line. The only plane with contact in a point in a curve is the osculating plane. But at least in the book I am reading, it seems it stops there. We just define ""contact"" and check that there are special lines and planes with a certain degrees of ""contact"". So I am curious: What is the point of the idea of ""contact""?","\alpha: I \to \Bbb{R}^3 \beta: \overline{I} \to \Bbb{R}^3 \alpha(t_0)=\beta (t_0) t_0 \in I \cap \overline{I} \alpha,\beta n t_0 \leq n \alpha,\beta t_0 n+1 t_0 \alpha:I\to \Bbb{R}^3 \pi \Bbb{R}^3 p=\alpha(t_0) t_0\in I \alpha \pi n p \beta: \overline{I} \to \Bbb{R}^3 \beta(\overline{I})\subset \pi \alpha,\beta n t_0 1 2",['differential-geometry']
99,Isometry groups of round three manifolds,Isometry groups of round three manifolds,,"I'm interested in isometry groups of round 3 manifolds, especially Riemannian homogeneous ones. Here are my thoughts so far: The round three sphere $ S^3 $ has isometry group $ O_4 $ . Round projective space is the sphere mod the antipodal isometry (which is a rotation for odd spheres) $$ \mathbb{R}P^3 \cong S^3/-I $$ Using the normalizer formula for the isometry group of a quotient of a simply connected manifold we have $$ \text{Iso}(\mathbb{R}P^3)\cong N_{\text{Iso}(S^3)}(-I)/-I=O_4/-I  $$ which further simplifies as $$  \text{Iso}(\mathbb{R}P^3) \cong (O_1 \ltimes SO_4)/-I \cong O_1 \ltimes (SO_4/-I) \cong O_1 \ltimes (SO_3 \times SO_3) $$ For a homogeneous lens space $ L_{p,1} \cong SU_2/C_p $ where $ C_p $ is $ p $ element cyclic subgroup the normalizer of $ C_p $ in $ SO_3 $ (or $ SU_2 $ ) is $ O_2 $ and $ O_2/C_p  \cong O_2 $ . So I think the isometry group should be something like $$ O_2 \times O_3 $$ Another reason I'm guessing $ \text{Iso}(L_{p,1}) \cong O_3 \times O_2 $ is that from the Hopf fibration $$ S^1 \to S^3 \to S^2 $$ we can mod out by $ C_p $ $$ S^1/C_p \to S^3/C_p \to S^2 $$ So we have $$ S^1 \to L_{p,1} \to S^2 $$ and then I am just taking the the direct product of the isometry group of the fiber and of the base. (I know you can't generally do that for nontrivial fiber bundles for example no metric on the Klein bottle has isometries $ O_2 \times O_2 $ but just noting here that it sort of agrees with my earlier guess from the normalizer perspective). The normalizers of other groups are $ D_{2n} \trianglelefteq D_{4n} $ for $ n \geq 3 $ , $ D_{4} \cong C_2 \times C_2 \trianglelefteq S_4 $ , $ A_4 \trianglelefteq S_4 $ , $ A_5 \trianglelefteq A_5 $ . The point is that all other discrete subgroups of $ SO_3 $ (and $ SU_2 $ ) have discrete normalizer with finite index. So for the homogeneous prism manifolds and three exceptional manifolds $ SU_2/ \Gamma $ I think roughly the normalizer of $ \Gamma $ is $ \Gamma \times SU_2 $ so the isometry group is roughly $ (SU_2 \times \Gamma) /\Gamma $ or rather $$ \text{Iso}(SU_2/\Gamma) \cong SU_2 \rtimes O_1  $$ to include orientation reversing isometries For round three manifolds that are not homogeneous I think they probably all have isometry group $ O_2 $ (just a guess)","I'm interested in isometry groups of round 3 manifolds, especially Riemannian homogeneous ones. Here are my thoughts so far: The round three sphere has isometry group . Round projective space is the sphere mod the antipodal isometry (which is a rotation for odd spheres) Using the normalizer formula for the isometry group of a quotient of a simply connected manifold we have which further simplifies as For a homogeneous lens space where is element cyclic subgroup the normalizer of in (or ) is and . So I think the isometry group should be something like Another reason I'm guessing is that from the Hopf fibration we can mod out by So we have and then I am just taking the the direct product of the isometry group of the fiber and of the base. (I know you can't generally do that for nontrivial fiber bundles for example no metric on the Klein bottle has isometries but just noting here that it sort of agrees with my earlier guess from the normalizer perspective). The normalizers of other groups are for , , , . The point is that all other discrete subgroups of (and ) have discrete normalizer with finite index. So for the homogeneous prism manifolds and three exceptional manifolds I think roughly the normalizer of is so the isometry group is roughly or rather to include orientation reversing isometries For round three manifolds that are not homogeneous I think they probably all have isometry group (just a guess)"," S^3   O_4  
\mathbb{R}P^3 \cong S^3/-I
 
\text{Iso}(\mathbb{R}P^3)\cong N_{\text{Iso}(S^3)}(-I)/-I=O_4/-I 
 
 \text{Iso}(\mathbb{R}P^3) \cong (O_1 \ltimes SO_4)/-I \cong O_1 \ltimes (SO_4/-I) \cong O_1 \ltimes (SO_3 \times SO_3)
  L_{p,1} \cong SU_2/C_p   C_p   p   C_p   SO_3   SU_2   O_2   O_2/C_p  \cong O_2  
O_2 \times O_3
  \text{Iso}(L_{p,1}) \cong O_3 \times O_2  
S^1 \to S^3 \to S^2
  C_p  
S^1/C_p \to S^3/C_p \to S^2
 
S^1 \to L_{p,1} \to S^2
  O_2 \times O_2   D_{2n} \trianglelefteq D_{4n}   n \geq 3   D_{4} \cong C_2 \times C_2 \trianglelefteq S_4   A_4 \trianglelefteq S_4   A_5 \trianglelefteq A_5   SO_3   SU_2   SU_2/ \Gamma   \Gamma   \Gamma \times SU_2   (SU_2 \times \Gamma) /\Gamma  
\text{Iso}(SU_2/\Gamma) \cong SU_2 \rtimes O_1 
  O_2 ","['differential-geometry', 'riemannian-geometry', 'lie-groups', 'smooth-manifolds', 'geometric-topology']"
