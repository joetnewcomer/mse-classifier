,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is there a geometry meaning of the commutator of a group?,Is there a geometry meaning of the commutator of a group?,,"Conjugation has a geometric meaning: $aba^{-1}$ is the transform $b$ under coordination change $a$ . For example in the symmetry of tetrahedron, let $a$ be the anti-clockwise $1/3$ round rotation around the altitude through vertex $A$ , $b$ be the reflection by the plane through edge $AB$ , the $aba^{-1}$ is the reflection of the plane through edge $AC$ , which is just $b$ after relabeling vertices $A$ $B$$C$ $D$ by $a$ . Is there a similar geometric meaning of the commutator, $aba^{-1}b^{-1}$ ?","Conjugation has a geometric meaning: is the transform under coordination change . For example in the symmetry of tetrahedron, let be the anti-clockwise round rotation around the altitude through vertex , be the reflection by the plane through edge , the is the reflection of the plane through edge , which is just after relabeling vertices by . Is there a similar geometric meaning of the commutator, ?",aba^{-1} b a a 1/3 A b AB aba^{-1} AC b A BC D a aba^{-1}b^{-1},"['abstract-algebra', 'geometry', 'lie-groups', 'lie-algebras']"
1,Do automorphisms of quotient fields preserve the underlying ring?,Do automorphisms of quotient fields preserve the underlying ring?,,"Suppose $R$ is an integral domain. Let $\gamma: \mathrm{Frac}(R) \rightarrow \mathrm{Frac}(R)$ be an automorphism of the quotient field. Is it true that $\gamma(R) = R?$ I don't think that this is true in general, but I cannot think of any examples. Are there examples for which this is not true?","Suppose is an integral domain. Let be an automorphism of the quotient field. Is it true that I don't think that this is true in general, but I cannot think of any examples. Are there examples for which this is not true?",R \gamma: \mathrm{Frac}(R) \rightarrow \mathrm{Frac}(R) \gamma(R) = R?,"['abstract-algebra', 'ring-theory']"
2,Where to go after Dummit and Foote?,Where to go after Dummit and Foote?,,"I am taking general abstract algebra soon and am covering most of Dummit and Foote’s book up to Galois Theory. If one wanted to continue their study of abstract algebra after this, would they read Serge Lang’s Algebra or Jacobson’s Basic Algebra I & II? How do they differ and what are pros and cons of each w.r.t. rigor, depth, and relevance? I only mention these two books because they are on my shelf. Thanks!","I am taking general abstract algebra soon and am covering most of Dummit and Foote’s book up to Galois Theory. If one wanted to continue their study of abstract algebra after this, would they read Serge Lang’s Algebra or Jacobson’s Basic Algebra I & II? How do they differ and what are pros and cons of each w.r.t. rigor, depth, and relevance? I only mention these two books because they are on my shelf. Thanks!",,['abstract-algebra']
3,"""Lifting"" an algebraic structure on a codomain to the set of functions into it.","""Lifting"" an algebraic structure on a codomain to the set of functions into it.",,"Let $ S$ be any set and $G$ be a group. The set of functions from $S$ to $G$ is clearly also a group. The identity element is the constant function whose value is the identity of $G$ , and the (group) inverse of any function $g$ is the function that maps $x \in S$ to the group inverse of $g(x)$ in $G$ . If we replaced ""group"" with ring (also commutative ring, ring with identity, and both), vector space, or algebra (assuming for the last two that a scalar field is given), the analogous statement is still true. This clearly isn't the case for fields though. Assuming we want to make this work, the ""zero function"" would be the one that maps identically to zero. A function $f$ , such that $f(x) = 0$ for at least one $x \in S$ , but is not $0$ for at least one other $x \in S$ , is not equal to the zero function, but also doesn't have a multiplicative inverse. Are there other algebraic structures for which this relationship holds or fails in interesting ways? Is there a specific field of mathematics that studies this?","Let be any set and be a group. The set of functions from to is clearly also a group. The identity element is the constant function whose value is the identity of , and the (group) inverse of any function is the function that maps to the group inverse of in . If we replaced ""group"" with ring (also commutative ring, ring with identity, and both), vector space, or algebra (assuming for the last two that a scalar field is given), the analogous statement is still true. This clearly isn't the case for fields though. Assuming we want to make this work, the ""zero function"" would be the one that maps identically to zero. A function , such that for at least one , but is not for at least one other , is not equal to the zero function, but also doesn't have a multiplicative inverse. Are there other algebraic structures for which this relationship holds or fails in interesting ways? Is there a specific field of mathematics that studies this?", S G S G G g x \in S g(x) G f f(x) = 0 x \in S 0 x \in S,['abstract-algebra']
4,"If $H$ is a subgroup, and $xHx^{-1} \subsetneq H$, for all $x$ in $G$, then is H a normal subgroup?","If  is a subgroup, and , for all  in , then is H a normal subgroup?",H xHx^{-1} \subsetneq H x G,"Here $xHx^{-1} \subsetneq H$ means $xHx^{-1}$ as to be a proper subset of $H$ . From Gallian, Contemporary Abstract Algebra: Normal Subgroup: A subgroup $H$ of a group $G$ is called a normal subgroup of $G$ if $aH = Ha$ for all $a$ in $G$ . We denote this by $H$ $\triangleleft$ $G$ ..... Normal Subgroup Test: A subgroup $H$ of $G$ is normal in $G$ if and only if $xHx^{-1} \subseteq H$ for all $x$ in $G$ . Proof If $H$ is normal in $G$ , then for any $x$ $\epsilon$ $G$ and $h $ $\epsilon$ $H$ there is an $h^{'}$ in   H such that $xh = h^{'}x$ . Thus, $xhx^{-1} = h^{'}$ , and therefore $xHx^{-1} \subseteq H$ . Conversely, if $xHx^{-1} \subseteq H$ for all $x$ , then, letting $x = a$ , we have $aHa^{-1} \subseteq H$ or $aH \subseteq Ha$ . On the other hand, letting $x = a^{-1}$ , we have $a^{-1}H(a^{-1})^{-1} = a^{-1}Ha \subseteq H$ or $Ha \subseteq aH$ . From above theorem of Normal subgroup test, if $1.$ $xHx^{-1} \subsetneq H$ or $2.$ $xHx^{-1}=H$ , $H$ will be a normal subgroup. But from the first definition of normal subgroups given above in the extract, $H$ seems to be normal only if $xH=Hx \implies xHx^{-1}=H$ . Then, if $H$ is a subgroup, and $xHx^{-1} \subsetneq H$ , for all $x$ in $G$ , is H a normal subgroup? If yes, is it not against the definition of normal subgroup?","Here means as to be a proper subset of . From Gallian, Contemporary Abstract Algebra: Normal Subgroup: A subgroup of a group is called a normal subgroup of if for all in . We denote this by ..... Normal Subgroup Test: A subgroup of is normal in if and only if for all in . Proof If is normal in , then for any and there is an in   H such that . Thus, , and therefore . Conversely, if for all , then, letting , we have or . On the other hand, letting , we have or . From above theorem of Normal subgroup test, if or , will be a normal subgroup. But from the first definition of normal subgroups given above in the extract, seems to be normal only if . Then, if is a subgroup, and , for all in , is H a normal subgroup? If yes, is it not against the definition of normal subgroup?","xHx^{-1} \subsetneq H xHx^{-1} H H G G aH =
Ha a G H \triangleleft G H G G xHx^{-1} \subseteq H x G H G x \epsilon G h
 \epsilon H h^{'} xh = h^{'}x xhx^{-1} = h^{'} xHx^{-1} \subseteq H xHx^{-1} \subseteq H x x = a aHa^{-1} \subseteq H aH \subseteq Ha x = a^{-1} a^{-1}H(a^{-1})^{-1} = a^{-1}Ha \subseteq H Ha \subseteq aH 1. xHx^{-1} \subsetneq H 2. xHx^{-1}=H H H xH=Hx \implies xHx^{-1}=H H xHx^{-1} \subsetneq H x G","['abstract-algebra', 'group-theory', 'normal-subgroups']"
5,"For a general ring $R$, if $R$ has a unique right-unity, then it has a unity.","For a general ring , if  has a unique right-unity, then it has a unity.",R R,"Problem: For a general ring $R$ I want to show that: if $R$ has a unique right unity, then it has an overall unity. Attempt: Suppose $e$ is the unique right unity of $R$ . Then for any $r \in R$ , we have that $re=r$ and so $er=ere$ and $er-ere=0$ . From here I feel the answer should be obvious but I'm not seeing it right away. Help appreciated.","Problem: For a general ring I want to show that: if has a unique right unity, then it has an overall unity. Attempt: Suppose is the unique right unity of . Then for any , we have that and so and . From here I feel the answer should be obvious but I'm not seeing it right away. Help appreciated.",R R e R r \in R re=r er=ere er-ere=0,"['abstract-algebra', 'ring-theory']"
6,Group cohomology of the natural action of automorphism group on a finitely generated abelian group,Group cohomology of the natural action of automorphism group on a finitely generated abelian group,,"It's well known that we can classify finitely generated abelian groups. Let $M$ be a finitely generated abelian group, in principle we can decide the group structure of $G=Aut(M)$ from $M$ . What about the group cohomology? In other words, what are the group structures of $H^i(G,M)$ ( $i \geq 0$ )? More modestly, what are the orders of $H^i(G,M)$ ? If we can't do things precisely, is there any bound?","It's well known that we can classify finitely generated abelian groups. Let be a finitely generated abelian group, in principle we can decide the group structure of from . What about the group cohomology? In other words, what are the group structures of ( )? More modestly, what are the orders of ? If we can't do things precisely, is there any bound?","M G=Aut(M) M H^i(G,M) i \geq 0 H^i(G,M)","['abstract-algebra', 'group-theory']"
7,Cayley Table of Elementary Abelian Group $E_8$,Cayley Table of Elementary Abelian Group,E_8,I read about elementary abelian group $E_8$ at https://groupprops.subwiki.org/wiki/Elementary_abelian_group:E8#Definition . I've performed some searches on other sites and have yet to come across a Cayley table for it. Any leads on where to find one?,I read about elementary abelian group at https://groupprops.subwiki.org/wiki/Elementary_abelian_group:E8#Definition . I've performed some searches on other sites and have yet to come across a Cayley table for it. Any leads on where to find one?,E_8,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups', 'cayley-table']"
8,Write the algebraic closure of $F_p$ as union of finite fields,Write the algebraic closure of  as union of finite fields,F_p,"In Field theory by Steven Roman Chapter 9 Exercise 20, if we write the algebraic closure of finite field $F_q$ as $\Gamma(q)$ and $a_n$ be any strictly increasing infinite sequence of positive integers, the exercise wants to prove that $\Gamma(q)=\bigcup_{n=0}^{\infty}GF(q^{a_n})$ . However, if $a_n$ is an arbitrary sequence, we are even unable to prove $\bigcup_{n=0}^{\infty}GF(q^{a_n})$ is a field. I wonder whether the exercise has omitted some condition since the equality doesn't hold under current conditions offered. Hope for answers!","In Field theory by Steven Roman Chapter 9 Exercise 20, if we write the algebraic closure of finite field as and be any strictly increasing infinite sequence of positive integers, the exercise wants to prove that . However, if is an arbitrary sequence, we are even unable to prove is a field. I wonder whether the exercise has omitted some condition since the equality doesn't hold under current conditions offered. Hope for answers!",F_q \Gamma(q) a_n \Gamma(q)=\bigcup_{n=0}^{\infty}GF(q^{a_n}) a_n \bigcup_{n=0}^{\infty}GF(q^{a_n}),"['abstract-algebra', 'field-theory', 'finite-fields']"
9,"decomposition group and inertia group, the minimal polynomial,surjectivity of the map $D_{M/P}\rightarrow Gal$","decomposition group and inertia group, the minimal polynomial,surjectivity of the map",D_{M/P}\rightarrow Gal,"Can anyone explain the underlined sentence? For notation, A:Dedekind domain, K=Frac(A), L/K:Galois extension, B:The integral closure of A in L, M:A maximal ideal of B, P:The intersection of M and A (hence the maximal ideal of A), $D_{M/P}$ :the decomposition group. I reckon the way we take $\alpha$ is the key, but cannot make it to the conclusion, 'we find that the only non-zero roots of...'. I read some of the close questions already answered but none of them was using this type of logic. Thank you in advance.","Can anyone explain the underlined sentence? For notation, A:Dedekind domain, K=Frac(A), L/K:Galois extension, B:The integral closure of A in L, M:A maximal ideal of B, P:The intersection of M and A (hence the maximal ideal of A), :the decomposition group. I reckon the way we take is the key, but cannot make it to the conclusion, 'we find that the only non-zero roots of...'. I read some of the close questions already answered but none of them was using this type of logic. Thank you in advance.",D_{M/P} \alpha,"['abstract-algebra', 'number-theory', 'galois-theory', 'algebraic-number-theory', 'arithmetic-geometry']"
10,Are the rings $\mathbb{R}^2$ and $\mathbb{R}^3$ isomorphic?,Are the rings  and  isomorphic?,\mathbb{R}^2 \mathbb{R}^3,"Are the rings $\mathbb{R}^2$ and $\mathbb{R}^3$ isomorphic, where $\mathbb{R}^2=\mathbb{R}\times\mathbb{R}$ is the set of all pairs $(a,b)$ with $a,b \in \mathbb{R}$ , and $\mathbb{R}^3=\mathbb{R}\times\mathbb{R}\times\mathbb{R}$ is the set of all triples $(a,b,c)$ with $a,b,c \in \mathbb{R}$ , using component wise addition and multiplication?","Are the rings and isomorphic, where is the set of all pairs with , and is the set of all triples with , using component wise addition and multiplication?","\mathbb{R}^2 \mathbb{R}^3 \mathbb{R}^2=\mathbb{R}\times\mathbb{R} (a,b) a,b \in \mathbb{R} \mathbb{R}^3=\mathbb{R}\times\mathbb{R}\times\mathbb{R} (a,b,c) a,b,c \in \mathbb{R}","['abstract-algebra', 'ring-isomorphism']"
11,Contraction of (non-prime) ideals in integral extensions,Contraction of (non-prime) ideals in integral extensions,,"If $A \subset B$ is an integral extension, then any prime $p \subset A$ is the contraction of some prime of $B$ (by lying-over property). Does this hold for more general ideals? That is, given an ideal $I \subset A$ , is there always an ideal $J \subset B$ such that $I = J^c$ ? If not, do we at least have $I^{ec} = I$ for all ideals $I$ of $A$ ? Possibly if we assume that $A \subset B$ is of finite type (hence finite)? Thank you!","If is an integral extension, then any prime is the contraction of some prime of (by lying-over property). Does this hold for more general ideals? That is, given an ideal , is there always an ideal such that ? If not, do we at least have for all ideals of ? Possibly if we assume that is of finite type (hence finite)? Thank you!",A \subset B p \subset A B I \subset A J \subset B I = J^c I^{ec} = I I A A \subset B,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals', 'integral-extensions']"
12,"Let $\theta$ be a root of $p(x)=x^3+9x+6$, find the inverse of $1+\theta$ in $\mathbb{Q(\theta)}$","Let  be a root of , find the inverse of  in",\theta p(x)=x^3+9x+6 1+\theta \mathbb{Q(\theta)},"Let $\theta$ be a root of $p(x)=x^3+9x+6$ , find the inverse of $1+\theta$ in $\mathbb{Q(\theta)}$ . So problems like this really annoy me but I did crappy on the last homework after making a lot of arithmetic mistakes so I want to run everything by you guys. This one isn't actually for homework it's just a suggested practice problem but okay lets go!!! So I'm not sure if the method I used to do this was standard or not, I don't remember my professor showing me, but what I did first was used the canonical euclidean algorithm in $\mathbb{Q[x]}$ and wrote: $x^3+9x+6$ $=(1+x)(x^2-x+10-\frac{4}{x+1})$ $=(1+x)(x^2-x+10)-4$ the reduced modulo  the minimal polynomial of $\theta$ i.e. $x^3+9x+6$ and so $4=(1+x)(x^2-x+10)$ $\rightarrow$ $1= \frac{1}{4}(1+x)(x^2-x+10)$ and sooo ah $(\theta^2-\theta+10)\frac{1}{4}$ is what I believe is the inverse of $(1+\theta)$ in the quotient field... Like i said I hate these problems but ehh is this correct? On a lighter note it's finally getting cool enough for me to go on proper runs here and so that's pretty bomb!","Let be a root of , find the inverse of in . So problems like this really annoy me but I did crappy on the last homework after making a lot of arithmetic mistakes so I want to run everything by you guys. This one isn't actually for homework it's just a suggested practice problem but okay lets go!!! So I'm not sure if the method I used to do this was standard or not, I don't remember my professor showing me, but what I did first was used the canonical euclidean algorithm in and wrote: the reduced modulo  the minimal polynomial of i.e. and so and sooo ah is what I believe is the inverse of in the quotient field... Like i said I hate these problems but ehh is this correct? On a lighter note it's finally getting cool enough for me to go on proper runs here and so that's pretty bomb!",\theta p(x)=x^3+9x+6 1+\theta \mathbb{Q(\theta)} \mathbb{Q[x]} x^3+9x+6 =(1+x)(x^2-x+10-\frac{4}{x+1}) =(1+x)(x^2-x+10)-4 \theta x^3+9x+6 4=(1+x)(x^2-x+10) \rightarrow 1= \frac{1}{4}(1+x)(x^2-x+10) (\theta^2-\theta+10)\frac{1}{4} (1+\theta),"['abstract-algebra', 'polynomials', 'ring-theory', 'gcd-and-lcm', 'euclidean-algorithm']"
13,"Abelian group operation on $(0, 1)$",Abelian group operation on,"(0, 1)","My Question is: is there a binary operation on $(0, 1)$ that makes this set into an abelian group in which the inverse for any $x$ is $1-x$ ? My approach to this was applying $f(x)=\pi(x-0.5)$ (which is bijective) so we map the given interval to $(-\pi/2, \pi/2)$ .For elements $x, y, z \in (-\pi/2, \pi/2)$ we define $$x \star y = z \Longleftrightarrow \tan(x) + \tan(y) = \tan(z).$$ This seems like a way to exploit the structure of $(\Bbb R, +)$ . My problem is that I don't know how to define the group operation explicitly. I have tried to put, for $x, y \in (0,1)$ , $$x \star y = f^{-1}(\arctan(\tan(f(x) + f(y))))$$ but this doesn't seem to be associative. How do I find an explicit definition? Is this approach valid at all?","My Question is: is there a binary operation on that makes this set into an abelian group in which the inverse for any is ? My approach to this was applying (which is bijective) so we map the given interval to .For elements we define This seems like a way to exploit the structure of . My problem is that I don't know how to define the group operation explicitly. I have tried to put, for , but this doesn't seem to be associative. How do I find an explicit definition? Is this approach valid at all?","(0, 1) x 1-x f(x)=\pi(x-0.5) (-\pi/2, \pi/2) x, y, z \in (-\pi/2, \pi/2) x \star y = z \Longleftrightarrow \tan(x) + \tan(y) = \tan(z). (\Bbb R, +) x, y \in (0,1) x \star y = f^{-1}(\arctan(\tan(f(x) + f(y))))","['abstract-algebra', 'group-theory', 'trigonometry']"
14,Is $ \mathrm{Aut}(\mathrm{Gal}(\bar{\mathbb{Q}}/\mathbb{Q})) $ known?,Is  known?, \mathrm{Aut}(\mathrm{Gal}(\bar{\mathbb{Q}}/\mathbb{Q})) ,"Following my previous question about the outer automorphism group, I would like to know if the structure of the automorphism group of the absolute Galois group of the rationals is known. Specifically, is it isomorphic to the cyclic group with two elements ?","Following my previous question about the outer automorphism group, I would like to know if the structure of the automorphism group of the absolute Galois group of the rationals is known. Specifically, is it isomorphic to the cyclic group with two elements ?",,"['abstract-algebra', 'group-theory', 'galois-theory']"
15,"How many homomorphisms from $\frac{\mathbb{Z}[x,y]}{(x^3+y^2-1)}$ to $\frac{\mathbb{Z}}{(7)}$?",How many homomorphisms from  to ?,"\frac{\mathbb{Z}[x,y]}{(x^3+y^2-1)} \frac{\mathbb{Z}}{(7)}","How many homomorphisms from $\displaystyle\frac{\mathbb{Z}[x,y]}{(x^3+y^2-1)}$ to $\displaystyle\frac{\mathbb{Z}}{(7)}$? I already checked that $x^3+y^2-1$ has these five integer roots: $(-2,3),(-2,-3),(0,1),(0,-1)$ and $(1,0)$, so it is not an irreducible polynomial in $\mathbb{Z}$. The ring $\displaystyle \frac{\mathbb{Z}}{(7)}$ is the same as $\displaystyle\frac{\mathbb{Z}}{7\mathbb{Z}}$, right? Since $7$ will generate $7\mathbb{Z}$, so this ring $\displaystyle \frac{\mathbb{Z}}{(7)}$ is a finite ring of $7$ elements. But then how can I find the number of homomorphisms? I am also failing to analyze the order of elements that will generate the domain ring. Thanks.","How many homomorphisms from $\displaystyle\frac{\mathbb{Z}[x,y]}{(x^3+y^2-1)}$ to $\displaystyle\frac{\mathbb{Z}}{(7)}$? I already checked that $x^3+y^2-1$ has these five integer roots: $(-2,3),(-2,-3),(0,1),(0,-1)$ and $(1,0)$, so it is not an irreducible polynomial in $\mathbb{Z}$. The ring $\displaystyle \frac{\mathbb{Z}}{(7)}$ is the same as $\displaystyle\frac{\mathbb{Z}}{7\mathbb{Z}}$, right? Since $7$ will generate $7\mathbb{Z}$, so this ring $\displaystyle \frac{\mathbb{Z}}{(7)}$ is a finite ring of $7$ elements. But then how can I find the number of homomorphisms? I am also failing to analyze the order of elements that will generate the domain ring. Thanks.",,"['abstract-algebra', 'polynomials']"
16,"Given any commutative ring $R$ with unity, $R[X]$ has infinitely many maximal ideals.","Given any commutative ring  with unity,  has infinitely many maximal ideals.",R R[X],"Hope this isn't a duplicate. I was trying to answer the following questions: (i) Let $k$ be any field. Then prove that $k[X]$ has infinitely many maximal ideals. (ii) Using (i) prove that, given any commutative ring $R$ with unity, $R[X]$ has infinitely many maximal ideals. My attempt: (i) If $k$ is  infinite, then the collection of ideals of the form $(x-a) \forall a \in k$ will suffice. For finite fields I argue by contradiction. Begin by assuming that there are only finitely many prime polynomials, a listing of them in $k[X]$ say, $p_1,\ldots,p_n$ . Next we define $p_{n+1} := p_{1} \cdots p_{n} +1$ then $p_{n+1} > p_{j} \forall 1\leq j\leq n $ and none of them divide it i. e. proceed like Euclid's argument for proving infinitely many primes. (ii) By Krull's theorem, any non-zero commutative ring with unity has a maximal ideal. Let $\mathscr{M}$ be a maximal ideal of $R$. Then $\frac{R}{\mathscr{M}}$ is a field, we consider $\frac{R}{\mathscr{M}} [X]$ , then by part (i), $\frac{R}{\mathscr{M}} [X]$ has infinitely many maximal ideals. Since,$\frac{R}{\mathscr{M}} [X] \cong \frac{R[X]}{\mathscr{M}[X]}$ , thus $\frac{R[X]}{\mathscr{M}[X]}$ must have maximal ideals. Now any ideal of $\frac{R[X]}{\mathscr{M}[X]}$ is of the form $\frac{I}{\mathscr{M}[X]}$ where $I$ is an ideal of $R[X]$ containing $\mathscr{M}[X]$. So any maximal ideal of $\frac{R[X]}{\mathscr{M}[X]}$ is an ideal of $R[X]$ containing ${\mathscr{M}[X]}$, say $J$. But I don't know whether $J$ is maximal in $R[X]$ or not. How to cross the hurdle? Also if there are mistakes in my arguments please point them out.","Hope this isn't a duplicate. I was trying to answer the following questions: (i) Let $k$ be any field. Then prove that $k[X]$ has infinitely many maximal ideals. (ii) Using (i) prove that, given any commutative ring $R$ with unity, $R[X]$ has infinitely many maximal ideals. My attempt: (i) If $k$ is  infinite, then the collection of ideals of the form $(x-a) \forall a \in k$ will suffice. For finite fields I argue by contradiction. Begin by assuming that there are only finitely many prime polynomials, a listing of them in $k[X]$ say, $p_1,\ldots,p_n$ . Next we define $p_{n+1} := p_{1} \cdots p_{n} +1$ then $p_{n+1} > p_{j} \forall 1\leq j\leq n $ and none of them divide it i. e. proceed like Euclid's argument for proving infinitely many primes. (ii) By Krull's theorem, any non-zero commutative ring with unity has a maximal ideal. Let $\mathscr{M}$ be a maximal ideal of $R$. Then $\frac{R}{\mathscr{M}}$ is a field, we consider $\frac{R}{\mathscr{M}} [X]$ , then by part (i), $\frac{R}{\mathscr{M}} [X]$ has infinitely many maximal ideals. Since,$\frac{R}{\mathscr{M}} [X] \cong \frac{R[X]}{\mathscr{M}[X]}$ , thus $\frac{R[X]}{\mathscr{M}[X]}$ must have maximal ideals. Now any ideal of $\frac{R[X]}{\mathscr{M}[X]}$ is of the form $\frac{I}{\mathscr{M}[X]}$ where $I$ is an ideal of $R[X]$ containing $\mathscr{M}[X]$. So any maximal ideal of $\frac{R[X]}{\mathscr{M}[X]}$ is an ideal of $R[X]$ containing ${\mathscr{M}[X]}$, say $J$. But I don't know whether $J$ is maximal in $R[X]$ or not. How to cross the hurdle? Also if there are mistakes in my arguments please point them out.",,['abstract-algebra']
17,Finitely generated $k$-algebra of Krull-dimension one has infinitely many primes,Finitely generated -algebra of Krull-dimension one has infinitely many primes,k,I am looking for a reference or a quick proof of the statement that Every finitely generated $k$-algebra of Krull-dimension one has infinitely many prime ideals. Here $k$ is a field.,I am looking for a reference or a quick proof of the statement that Every finitely generated $k$-algebra of Krull-dimension one has infinitely many prime ideals. Here $k$ is a field.,,"['abstract-algebra', 'algebraic-geometry', 'reference-request', 'commutative-algebra']"
18,If $N/M$ is a normal subgroup of $G/M$ then $N$ is a normal in $G$,If  is a normal subgroup of  then  is a normal in,N/M G/M N G,Is it true that if $N/M$ is a normal subgroup of $G/M$ then $N$ is a normal subgroup of $G$ itself? I would think that not necessarily because I would expect that under conjugation we could get a subgroup of $G$ isomorphic to $N$ but maybe not $N$ it self but a subgroup identical from $N$ except its elements be differing from $N$ by  elements of $M$. However I think the correspondence theorem says that $N$ is normal in $G$ so I am a bit confused is it normal after all?,Is it true that if $N/M$ is a normal subgroup of $G/M$ then $N$ is a normal subgroup of $G$ itself? I would think that not necessarily because I would expect that under conjugation we could get a subgroup of $G$ isomorphic to $N$ but maybe not $N$ it self but a subgroup identical from $N$ except its elements be differing from $N$ by  elements of $M$. However I think the correspondence theorem says that $N$ is normal in $G$ so I am a bit confused is it normal after all?,,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
19,Multiplicative inverse questions,Multiplicative inverse questions,,"This is my first time posting on Math exchange. I have been self-teaching myself Mathematics and recently started learning some Algebra. I was posed the following questions, in which I would like to answer before I proceed, but having some trouble finding proper solutions. So the format will be question, and my answer. What name do we give an element $a \in \mathbb{Z}_n$ that has a multiplicative inverse? A modular multiplicative inverse of an integer $a$ is an integer $x$ such that $ax \cong 1 (\mod m)$. This means that the remainder after dividing $ax$ by integer $m$ is equal to $1$. Give an example, for some $n \in \mathbb{N}$, of an element of $\mathbb{Z}_n$, that does not have a multiplicative inverse? This question is throwing me off because - does the $n$ we speak of matter for both $n \in \mathbb{N}$ and $\mathbb{Z}_n$ ot solely $n$? My guess here would be $0$ because we cannot have an inverse of $0$. Prove that multiplicative inverse are unique; an element $a \in \mathbb{Z}_n$ cannot have two multiplicative inverses. Suppose that an element $a\in\mathbb{Z}_n$ has an inverse $a'$. Next, suppose that $a^*$ is also an inverse of $a$. Then, $a'$ is a solution to $a \cdot_n x=1$, and similarly $a^*$ has a solution to $a \cdot_n x=1$. Lemma: Suppose $a'$ is multiplicative inverse of $a$ in $\mathbb{Z}_n$, then for any $b \in \mathbb{Z}_n$ the equation $a \cdot_n x=b$ has a unique solution, such that $x = a' \cdot_n b$. By Lemma, equation $a \cdot_n x = 1$ has a unique solution, namely $x=a'=a^*$. Therefore, an element $a\in \mathbb{Z}_n$ cannot have two multiplicative inverses. Thank you for the help. I would love any constructive feedback for these. If you can help me elaborate on some ideas, that would be really helpful also. Thank you very much!","This is my first time posting on Math exchange. I have been self-teaching myself Mathematics and recently started learning some Algebra. I was posed the following questions, in which I would like to answer before I proceed, but having some trouble finding proper solutions. So the format will be question, and my answer. What name do we give an element $a \in \mathbb{Z}_n$ that has a multiplicative inverse? A modular multiplicative inverse of an integer $a$ is an integer $x$ such that $ax \cong 1 (\mod m)$. This means that the remainder after dividing $ax$ by integer $m$ is equal to $1$. Give an example, for some $n \in \mathbb{N}$, of an element of $\mathbb{Z}_n$, that does not have a multiplicative inverse? This question is throwing me off because - does the $n$ we speak of matter for both $n \in \mathbb{N}$ and $\mathbb{Z}_n$ ot solely $n$? My guess here would be $0$ because we cannot have an inverse of $0$. Prove that multiplicative inverse are unique; an element $a \in \mathbb{Z}_n$ cannot have two multiplicative inverses. Suppose that an element $a\in\mathbb{Z}_n$ has an inverse $a'$. Next, suppose that $a^*$ is also an inverse of $a$. Then, $a'$ is a solution to $a \cdot_n x=1$, and similarly $a^*$ has a solution to $a \cdot_n x=1$. Lemma: Suppose $a'$ is multiplicative inverse of $a$ in $\mathbb{Z}_n$, then for any $b \in \mathbb{Z}_n$ the equation $a \cdot_n x=b$ has a unique solution, such that $x = a' \cdot_n b$. By Lemma, equation $a \cdot_n x = 1$ has a unique solution, namely $x=a'=a^*$. Therefore, an element $a\in \mathbb{Z}_n$ cannot have two multiplicative inverses. Thank you for the help. I would love any constructive feedback for these. If you can help me elaborate on some ideas, that would be really helpful also. Thank you very much!",,"['abstract-algebra', 'proof-verification', 'modular-arithmetic']"
20,"Prove that if $ \operatorname{Gal}(K/F) \simeq \Bbb{Z}/2\Bbb{Z}\times\Bbb{Z}/2\mathbb{Z}$, then $K = F(\sqrt{a},\sqrt{b})$ for some $a,b \in F$","Prove that if , then  for some"," \operatorname{Gal}(K/F) \simeq \Bbb{Z}/2\Bbb{Z}\times\Bbb{Z}/2\mathbb{Z} K = F(\sqrt{a},\sqrt{b}) a,b \in F","Let $F$ be a field of characteristic not $2$, and let $K$ be a Galois extension with $[K:F] = 4$. Prove that if $\operatorname{Gal}(K/F) \simeq \mathbb{Z}/2\mathbb{Z}\times\mathbb{Z}/2\mathbb{Z}$, then $K = F(\sqrt{a},\sqrt{b})$ for some $a,b \in F$ I showed that If $F$ is a field of characteristic not $2$, and $K$ is an extension   of $F$ with $[K: F] = 2$, then $K = F (\sqrt{a})$ for some $a \in F$. Using an idea like this . But I couldn't use that same idea to prove this case. Can someone help me? EDIT. Since $\operatorname{Gal}(K/F)$ is Klein group, there is subgroup $H$ of order $2$ and by the Fundamental Theorem of Galois Theory, there is a subfield $L$ of $K/F$ with $L \leftrightarrow H$ such that $[L:F] = [G:H] = 2$ and so, $[K:F] = [K:L][L:F] = [K:F(\sqrt{b})][F(\sqrt{b}):F]$. Can I to apply this result to $[K:F(\sqrt{b})]$ too?","Let $F$ be a field of characteristic not $2$, and let $K$ be a Galois extension with $[K:F] = 4$. Prove that if $\operatorname{Gal}(K/F) \simeq \mathbb{Z}/2\mathbb{Z}\times\mathbb{Z}/2\mathbb{Z}$, then $K = F(\sqrt{a},\sqrt{b})$ for some $a,b \in F$ I showed that If $F$ is a field of characteristic not $2$, and $K$ is an extension   of $F$ with $[K: F] = 2$, then $K = F (\sqrt{a})$ for some $a \in F$. Using an idea like this . But I couldn't use that same idea to prove this case. Can someone help me? EDIT. Since $\operatorname{Gal}(K/F)$ is Klein group, there is subgroup $H$ of order $2$ and by the Fundamental Theorem of Galois Theory, there is a subfield $L$ of $K/F$ with $L \leftrightarrow H$ such that $[L:F] = [G:H] = 2$ and so, $[K:F] = [K:L][L:F] = [K:F(\sqrt{b})][F(\sqrt{b}):F]$. Can I to apply this result to $[K:F(\sqrt{b})]$ too?",,"['abstract-algebra', 'galois-theory', 'extension-field']"
21,Minimal polynomial of $\sqrt{\sqrt[3]{7}-5}$,Minimal polynomial of,\sqrt{\sqrt[3]{7}-5},"I'm trying to find the minimal polynomial of $\alpha = \sqrt{\sqrt[3]{7}-5}$. Rather, I know that it will be $p(x) = x^6 +15x^4+75x^2+118$ by just squaring and then cubing appropriately, but I would like to verify that this is the minimal polynomial. The usual method I use (if for example, we have a square root inside the square root) is to verify that $[\mathbb{Q}(\alpha):\mathbb{Q}]=6$ by noting that  $$ \mathbb{Q} \subset \mathbb{Q}(\sqrt[3]{7}) \subset \mathbb{Q}(\alpha)  $$ and then showing that $\sqrt[3]{7} - 5$ is not a square inside $\mathbb{Q}(\sqrt[3]{7})$. But I can't get the usual method of supposing it is a square and then arriving at a contradiction to work. I.e. writing $\sqrt[3]{7} - 5 = (a + b \sqrt[3]{7})^2$ and conjugating with $-\sqrt[3]{7} - 5 = (a - b \sqrt[3]{7})^2$ and then multiplying the two doesn't really help us (because we have a cube root instead of a square root). So my question is whether there is a simple way to do this kind of question when we have a cube root inside the main root? Also, as a side question, I'd like to ask if we really have that, say $p(x)$, is a minimal polynomial for $\theta$ over $K$ a field is equivalent to $p(\theta)=0$ and $p(x)$ is irreducible? Or is this not enough for minimality? Do we also have to show that the degree is minimal? So if we could show that $p(x)$ in the question above is irreducible, would that be enough to show it's the minimal polynomial or would we still have to do some stuff for the degree? Many thanks for any help.","I'm trying to find the minimal polynomial of $\alpha = \sqrt{\sqrt[3]{7}-5}$. Rather, I know that it will be $p(x) = x^6 +15x^4+75x^2+118$ by just squaring and then cubing appropriately, but I would like to verify that this is the minimal polynomial. The usual method I use (if for example, we have a square root inside the square root) is to verify that $[\mathbb{Q}(\alpha):\mathbb{Q}]=6$ by noting that  $$ \mathbb{Q} \subset \mathbb{Q}(\sqrt[3]{7}) \subset \mathbb{Q}(\alpha)  $$ and then showing that $\sqrt[3]{7} - 5$ is not a square inside $\mathbb{Q}(\sqrt[3]{7})$. But I can't get the usual method of supposing it is a square and then arriving at a contradiction to work. I.e. writing $\sqrt[3]{7} - 5 = (a + b \sqrt[3]{7})^2$ and conjugating with $-\sqrt[3]{7} - 5 = (a - b \sqrt[3]{7})^2$ and then multiplying the two doesn't really help us (because we have a cube root instead of a square root). So my question is whether there is a simple way to do this kind of question when we have a cube root inside the main root? Also, as a side question, I'd like to ask if we really have that, say $p(x)$, is a minimal polynomial for $\theta$ over $K$ a field is equivalent to $p(\theta)=0$ and $p(x)$ is irreducible? Or is this not enough for minimality? Do we also have to show that the degree is minimal? So if we could show that $p(x)$ in the question above is irreducible, would that be enough to show it's the minimal polynomial or would we still have to do some stuff for the degree? Many thanks for any help.",,"['abstract-algebra', 'field-theory', 'extension-field', 'minimal-polynomials']"
22,Prove that only units of $\Bbb Z[\sqrt d] $ are $\pm 1$.,Prove that only units of  are .,\Bbb Z[\sqrt d]  \pm 1,Let $d(\in \Bbb Z)<-1$ such that $d$ is not divisible  by the square of a prime.   Prove that only units of $\Bbb Z[\sqrt d] $  are $\pm 1$. $$a+b\sqrt d \text{ is a unit }\implies (a+b\sqrt d)(c+e\sqrt d)=1\implies (a^2-db^2)(c^2-de^2)=1\implies a^2-db^2=\pm 1\implies a+b\sqrt d=\pm1\implies a+b\sqrt d \text{ is a unit}$$ Where did we use that $d$ is not divisible  by the square of a prime. Is my proof wrong?,Let $d(\in \Bbb Z)<-1$ such that $d$ is not divisible  by the square of a prime.   Prove that only units of $\Bbb Z[\sqrt d] $  are $\pm 1$. $$a+b\sqrt d \text{ is a unit }\implies (a+b\sqrt d)(c+e\sqrt d)=1\implies (a^2-db^2)(c^2-de^2)=1\implies a^2-db^2=\pm 1\implies a+b\sqrt d=\pm1\implies a+b\sqrt d \text{ is a unit}$$ Where did we use that $d$ is not divisible  by the square of a prime. Is my proof wrong?,,"['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
23,Is there a notion of minimal polynomial if the ring is not a field?,Is there a notion of minimal polynomial if the ring is not a field?,,"If $\alpha\notin R$ but $\alpha$ is the root of a polynomial in $R[x]$ do we study the “minimal polynomial” over $R$ for that root? (Would we still want it to be with leading coefficient 1? irreducibility uniqueness and minimal degree would be kept I guess) For example if you consider $2/3\notin\Bbb Z$, the only polynomial over that comes to mind is $3x-2$","If $\alpha\notin R$ but $\alpha$ is the root of a polynomial in $R[x]$ do we study the “minimal polynomial” over $R$ for that root? (Would we still want it to be with leading coefficient 1? irreducibility uniqueness and minimal degree would be kept I guess) For example if you consider $2/3\notin\Bbb Z$, the only polynomial over that comes to mind is $3x-2$",,"['abstract-algebra', 'ring-theory', 'field-theory', 'extension-field', 'minimal-polynomials']"
24,Is this extension of $\mathbb{Q}$ normal?,Is this extension of  normal?,\mathbb{Q},"Let $a = \sqrt{\sqrt2 + \sqrt3}$  Is $\mathbb{Q}(a)$ a normal extension of $\mathbb{Q}$? I thought the answer was no because the minimum polynomial of $a$ is $x^8 -10x^4 + 1$ so $[\mathbb{Q}(a):\mathbb{Q}] = 8$ and I read a similar question here where they say that is a normal extension iff the order of the Galois group is 4, but wouldn't this mean the order of the Galois group is 8?  Also, wouldn't an extension by $a$ not include anything imaginary and therefore only half of the other roots. I would almost definitely conclude that this extension is not normal, but part b of the question is to describe the Galois group $\operatorname{Gal}(\mathbb{Q}(a)/\mathbb{Q})$ up to isomorphism, which would mean that the extension would have to be normal","Let $a = \sqrt{\sqrt2 + \sqrt3}$  Is $\mathbb{Q}(a)$ a normal extension of $\mathbb{Q}$? I thought the answer was no because the minimum polynomial of $a$ is $x^8 -10x^4 + 1$ so $[\mathbb{Q}(a):\mathbb{Q}] = 8$ and I read a similar question here where they say that is a normal extension iff the order of the Galois group is 4, but wouldn't this mean the order of the Galois group is 8?  Also, wouldn't an extension by $a$ not include anything imaginary and therefore only half of the other roots. I would almost definitely conclude that this extension is not normal, but part b of the question is to describe the Galois group $\operatorname{Gal}(\mathbb{Q}(a)/\mathbb{Q})$ up to isomorphism, which would mean that the extension would have to be normal",,['abstract-algebra']
25,Examples of integral $k$-algebra,Examples of integral -algebra,k,"Definition : We say that a ring $R$ is an integral $k$-algebra if it is a $k$-algebra that is an integral domain. We say that a ring $R$ is an geometrically integral $k$-algebra if it is a $k$-algebra such that for every field extension $k'\supset k$, the ring $R\otimes_{k}k'$ is an integral $k'$-algebra. The first example I want to find is an integral $k$-algebra $R$ such that $k$ is a perfect field and $R$ is not a geometrically integral . Secondly, when $k$ is an imperfect field , I want to find an integral $k$-algebra $R$ such that for a field extension $k'\supset k$, the tensor product $k'\otimes_{k}R$ has nonzero nilpotent element . How can I find such examples? Thanks in advance.","Definition : We say that a ring $R$ is an integral $k$-algebra if it is a $k$-algebra that is an integral domain. We say that a ring $R$ is an geometrically integral $k$-algebra if it is a $k$-algebra such that for every field extension $k'\supset k$, the ring $R\otimes_{k}k'$ is an integral $k'$-algebra. The first example I want to find is an integral $k$-algebra $R$ such that $k$ is a perfect field and $R$ is not a geometrically integral . Secondly, when $k$ is an imperfect field , I want to find an integral $k$-algebra $R$ such that for a field extension $k'\supset k$, the tensor product $k'\otimes_{k}R$ has nonzero nilpotent element . How can I find such examples? Thanks in advance.",,"['abstract-algebra', 'algebraic-geometry']"
26,Ideal Class Group of $\mathbb{Q}(\sqrt{65})$,Ideal Class Group of,\mathbb{Q}(\sqrt{65}),"Let $O_K = \mathbb{Q}\left(\frac{1+\sqrt{65}}{2}\right)=\mathbb{Q}(\alpha)$ be the ring of algebraic integers of $K = \mathbb{Q}(\sqrt{65})$ . I want to find the Ideal Class Group $G$ of $O_K$ . The hint I am given is to try to show that every ideal of norm $10$ is principal. By Dedekind's criterion we can factor $$(2)=(2,\alpha)(2,\alpha+1)$$ $$(3) = (3)$$ $$(5) = (5,\alpha-3)(5,\alpha+2)$$ and the Minkowski Bound $\approx 5.1$ . Now I am having trouble showing that every ideal of norm $10$ is principal. Indeed, I am having trouble finding any ideal of norm $10$ as if $N(a+b\alpha) = a^2+ab-16b^2 = 10$ does not have any immediate solutions in mind. Even so, supposing we could show this, we would then that the class ideal group $G$ is generated by $a,b,c,d$ where $ac=ad=bc=bd=ab=bc=1$ , i.e. cyclic generated by $a$ . So we must determine the order of $a = (2,\alpha)$ in $G$ . This does not seem straightforward either. Perhaps it just requires a lot of trials case by case, but in any case, I feel I am at an impasse.","Let be the ring of algebraic integers of . I want to find the Ideal Class Group of . The hint I am given is to try to show that every ideal of norm is principal. By Dedekind's criterion we can factor and the Minkowski Bound . Now I am having trouble showing that every ideal of norm is principal. Indeed, I am having trouble finding any ideal of norm as if does not have any immediate solutions in mind. Even so, supposing we could show this, we would then that the class ideal group is generated by where , i.e. cyclic generated by . So we must determine the order of in . This does not seem straightforward either. Perhaps it just requires a lot of trials case by case, but in any case, I feel I am at an impasse.","O_K = \mathbb{Q}\left(\frac{1+\sqrt{65}}{2}\right)=\mathbb{Q}(\alpha) K = \mathbb{Q}(\sqrt{65}) G O_K 10 (2)=(2,\alpha)(2,\alpha+1) (3) = (3) (5) = (5,\alpha-3)(5,\alpha+2) \approx 5.1 10 10 N(a+b\alpha) = a^2+ab-16b^2 = 10 G a,b,c,d ac=ad=bc=bd=ab=bc=1 a a = (2,\alpha) G","['abstract-algebra', 'algebraic-number-theory', 'extension-field', 'dedekind-domain']"
27,Counter-example: If $J$ is prime then $f^{-1} (J) $ is prime. $f$ need not be unital.,Counter-example: If  is prime then  is prime.  need not be unital.,J f^{-1} (J)  f,"Let $R$ and $S$ be commutative with 1 and $ $ $ f:R\rightarrow S$ is a ring homomorphism which need not be surjective or unital i.e. $f(1_R)=1_S$ I know that for surjective or unital ring homomorphisms the statement - ""If $J$ is prime then $f^{-1} (J)$ is prime"" - holds true. However, if f need not be surjective or unital, are there any counter examples for the above statement?","Let $R$ and $S$ be commutative with 1 and $ $ $ f:R\rightarrow S$ is a ring homomorphism which need not be surjective or unital i.e. $f(1_R)=1_S$ I know that for surjective or unital ring homomorphisms the statement - ""If $J$ is prime then $f^{-1} (J)$ is prime"" - holds true. However, if f need not be surjective or unital, are there any counter examples for the above statement?",,"['abstract-algebra', 'maximal-and-prime-ideals', 'ring-homomorphism']"
28,"$a\cdot(b \cdot c) = d \cdot (e \cdot c) \implies b = (\bar{a}\cdot d) \cdot e$, then $(G, \cdot)$ is a group",", then  is a group","a\cdot(b \cdot c) = d \cdot (e \cdot c) \implies b = (\bar{a}\cdot d) \cdot e (G, \cdot)","Let $G$ be a non-empty set, $""\cdot""$ be a binary operation on $G$ and a single operation $x \mapsto \bar{x}$ such that $$a\cdot(b \cdot c) = d \cdot (e \cdot c) \implies b = (\bar{a}\cdot d) \cdot e, \forall a,b,c,d,e \in G.$$ Prove that $(G, \cdot)$ is a group. For $b = c = d = e = a \implies a = (\bar{a} \cdot a ) \cdot a, \forall a \in G$ . For $d = a, e = b \implies b = (\bar{a} \cdot a) \cdot b, \forall a,b \in G$ . Swapping $a$ and $b$ in the hypothesis equation and making $d = b, e = a$ we obtain that $b = (\bar{a} \cdot a) \cdot b$ and $a = (\bar{b} \cdot b) \cdot a$ . I think I need to show that $\bar{\bar{a}} = a, \forall a \in G$ and that $a \cdot \bar{a} = \bar{a} \cdot a = e$ (the identity element), but I don't know how. It would also help If I could prove that the binary operation is associative.","Let be a non-empty set, be a binary operation on and a single operation such that Prove that is a group. For . For . Swapping and in the hypothesis equation and making we obtain that and . I think I need to show that and that (the identity element), but I don't know how. It would also help If I could prove that the binary operation is associative.","G ""\cdot"" G x \mapsto \bar{x} a\cdot(b \cdot c) = d \cdot (e \cdot c) \implies b = (\bar{a}\cdot d) \cdot e, \forall a,b,c,d,e \in G. (G, \cdot) b = c = d = e = a \implies a = (\bar{a} \cdot a ) \cdot a, \forall a \in G d = a, e = b \implies b = (\bar{a} \cdot a) \cdot b, \forall a,b \in G a b d = b, e = a b = (\bar{a} \cdot a) \cdot b a = (\bar{b} \cdot b) \cdot a \bar{\bar{a}} = a, \forall a \in G a \cdot \bar{a} = \bar{a} \cdot a = e","['abstract-algebra', 'group-theory', 'binary-operations']"
29,"Dedekind domain with finite prime ideals is PID (a corollary on Serre's ""Local fields"" book).","Dedekind domain with finite prime ideals is PID (a corollary on Serre's ""Local fields"" book).",,"In the aforementioned book in p. 12 right under the approximation lemma there is a corollary stating that: ""A Dedeking domain $A$ with only finitely many prime ideals is principal"". I can find different proofs elsewhere but I am really interested in the way that it can be proved with what Serre has already proved. The proof goes like this: ""It is enough to show that every prime ideal is principal. Let $p$ be one, there exists an $x$ in $A$ with $v_p(x)=1$ and $v_q(x)=0$ for $q\neq p$. Hence $xA=p$."" Obviously the problem is how can such an $x$ be found, since the approx. lemma only gives inequalities. The statement of the approximation lemma can be found on a similar question, here . I would like to mention that up to now, Serre hasn't mentioned the so-called ""Strict triangle inequality"", neither the fact that in the approximation lemma the inequalities can be taken to be equalities.","In the aforementioned book in p. 12 right under the approximation lemma there is a corollary stating that: ""A Dedeking domain $A$ with only finitely many prime ideals is principal"". I can find different proofs elsewhere but I am really interested in the way that it can be proved with what Serre has already proved. The proof goes like this: ""It is enough to show that every prime ideal is principal. Let $p$ be one, there exists an $x$ in $A$ with $v_p(x)=1$ and $v_q(x)=0$ for $q\neq p$. Hence $xA=p$."" Obviously the problem is how can such an $x$ be found, since the approx. lemma only gives inequalities. The statement of the approximation lemma can be found on a similar question, here . I would like to mention that up to now, Serre hasn't mentioned the so-called ""Strict triangle inequality"", neither the fact that in the approximation lemma the inequalities can be taken to be equalities.",,"['abstract-algebra', 'commutative-algebra', 'algebraic-number-theory', 'local-field']"
30,how to prove $\mathbb Z_n$ has divisors of zero if and only if $n$ is not prime,how to prove  has divisors of zero if and only if  is not prime,\mathbb Z_n n,"A non-zero number $a \in \mathbb Z_n$ is called a divisor of zero if there is a non-zero number $b \in \mathbb Z_n$ such that $ab\equiv 0\pmod n.$ How can I prove $\mathbb Z_n$ has divisors of zero if and only if $n$ is not prime. I filled out the addition and multiplication tables for modulo 6 and 7 and tried to find out the relation, and it's definitely true. I know I need to prove it in both directions since it is an 'iff' question. But I still don't get it.","A non-zero number $a \in \mathbb Z_n$ is called a divisor of zero if there is a non-zero number $b \in \mathbb Z_n$ such that $ab\equiv 0\pmod n.$ How can I prove $\mathbb Z_n$ has divisors of zero if and only if $n$ is not prime. I filled out the addition and multiplication tables for modulo 6 and 7 and tried to find out the relation, and it's definitely true. I know I need to prove it in both directions since it is an 'iff' question. But I still don't get it.",,"['abstract-algebra', 'group-theory']"
31,Let $a$ be a non-unit in a ring $R$. Show that $a$ lies in a maximal ideal.,Let  be a non-unit in a ring . Show that  lies in a maximal ideal.,a R a,Let $a$ be a non-unit in a ring $R$. Show that $a$ lies in a maximal ideal. Is there a way to solve this without using Zorn's Lemma?,Let $a$ be a non-unit in a ring $R$. Show that $a$ lies in a maximal ideal. Is there a way to solve this without using Zorn's Lemma?,,"['abstract-algebra', 'ring-theory', 'maximal-and-prime-ideals']"
32,Show that every normal subgroup can be written as an intersection of $\ker \chi$'s for $\chi \in \operatorname{Irr}(G).$,Show that every normal subgroup can be written as an intersection of 's for,\ker \chi \chi \in \operatorname{Irr}(G).,"The question is as follows: This can be the third part of this question Linked to the results : Let $G$ be a finite group and $N$ a normal subgroup of $G$. c) Show that $N$ is the intersection of the sets of the form $\ker \xi$ that contain $N$ with $\xi \in \operatorname{Irr}(G)$. Some attempts: For the finite group $G$ and $\rho$ a representation with induced character $\chi_{\rho}$, we have $\ker \rho = \{ g \in G: \chi_{\rho}(g) = \chi_{\rho}(e) \} $ by Lemma 15.17; Isaacs ""Algebra: A Graduate Course"". Then it makes sense to define the kernel of the character $\chi$, denoted $\ker \chi$ by $\ker \chi = \{ g \in G: \chi(g) = \chi(e) \}$. In particular, we know that for every character $\chi$ one has that $\ker \chi \unlhd G.$ For the irreducible characters $\chi^{(\alpha)}$, $\alpha \in \hat{G}$, we give the special symbols $N^{(\alpha)}$ for $\ker \chi^{(\alpha)}$. Now what we are going to show is that knowing $N^{(\alpha)}$ for every $\alpha \in \hat{G}$ enables one to know $\ker \chi$ for every character $\chi$. Indeed, if we let $\chi$ be a character with representation as a linear combination of the irreducible characters $\chi = \sum_{\alpha \in \hat{G}} m^{(\alpha)}\chi^{(\alpha)}$, then we have  $$\ker \chi =\bigcap \{ N^{(\alpha)} :  m^{(\alpha)} > 0 \}.$$ Because if $\chi^{(\alpha)} (g) = d_{\alpha}$ for every $\alpha$ such that $m^{(\alpha)} > 0$ one sees that  $$\chi (g) = \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} \chi^{(\alpha)} (g) =  \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} \chi^{(\alpha)} (e) = \chi (e) $$ and so $g \in \ker \chi$. Conversely, since one evidently has that $|\chi^{(\alpha)} (g)| \le d_{\alpha}$ for every $\alpha \in \hat{G}$ we see that for $g \in \ker \chi$ one has that  \begin{align}  |\chi (g)| &= \left| \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} \chi^{(\alpha)} (g) \right|\\ &\le \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} \left| \chi^{(\alpha)} (g) \right| \\& \le  \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} d_{\alpha} \\ &= \chi(1)  = \chi(g)  \end{align} from where it follows from this that $\chi^{(\alpha)} (g)$ must be real and so if $\chi^{(\alpha)} (g) \le d_{\alpha}$ for any $\alpha \in \hat{G}$ then this would induce a strict inequality for $\chi(g)$  and $\chi(1)$. It follows that $\chi^{(\alpha)} (g) = d_{\alpha}$ for any $\alpha \in \hat{G}$ such that $m^{(\alpha)} >0$. Then the conclusion follows. Can someone please let me know if I am wrong and we cannot get the result through what I wrote? Thanks!","The question is as follows: This can be the third part of this question Linked to the results : Let $G$ be a finite group and $N$ a normal subgroup of $G$. c) Show that $N$ is the intersection of the sets of the form $\ker \xi$ that contain $N$ with $\xi \in \operatorname{Irr}(G)$. Some attempts: For the finite group $G$ and $\rho$ a representation with induced character $\chi_{\rho}$, we have $\ker \rho = \{ g \in G: \chi_{\rho}(g) = \chi_{\rho}(e) \} $ by Lemma 15.17; Isaacs ""Algebra: A Graduate Course"". Then it makes sense to define the kernel of the character $\chi$, denoted $\ker \chi$ by $\ker \chi = \{ g \in G: \chi(g) = \chi(e) \}$. In particular, we know that for every character $\chi$ one has that $\ker \chi \unlhd G.$ For the irreducible characters $\chi^{(\alpha)}$, $\alpha \in \hat{G}$, we give the special symbols $N^{(\alpha)}$ for $\ker \chi^{(\alpha)}$. Now what we are going to show is that knowing $N^{(\alpha)}$ for every $\alpha \in \hat{G}$ enables one to know $\ker \chi$ for every character $\chi$. Indeed, if we let $\chi$ be a character with representation as a linear combination of the irreducible characters $\chi = \sum_{\alpha \in \hat{G}} m^{(\alpha)}\chi^{(\alpha)}$, then we have  $$\ker \chi =\bigcap \{ N^{(\alpha)} :  m^{(\alpha)} > 0 \}.$$ Because if $\chi^{(\alpha)} (g) = d_{\alpha}$ for every $\alpha$ such that $m^{(\alpha)} > 0$ one sees that  $$\chi (g) = \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} \chi^{(\alpha)} (g) =  \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} \chi^{(\alpha)} (e) = \chi (e) $$ and so $g \in \ker \chi$. Conversely, since one evidently has that $|\chi^{(\alpha)} (g)| \le d_{\alpha}$ for every $\alpha \in \hat{G}$ we see that for $g \in \ker \chi$ one has that  \begin{align}  |\chi (g)| &= \left| \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} \chi^{(\alpha)} (g) \right|\\ &\le \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} \left| \chi^{(\alpha)} (g) \right| \\& \le  \sum_{\substack{\alpha \in \hat{G}\\ m^{(\alpha)} > 0 }} m^{(\alpha)} d_{\alpha} \\ &= \chi(1)  = \chi(g)  \end{align} from where it follows from this that $\chi^{(\alpha)} (g)$ must be real and so if $\chi^{(\alpha)} (g) \le d_{\alpha}$ for any $\alpha \in \hat{G}$ then this would induce a strict inequality for $\chi(g)$  and $\chi(1)$. It follows that $\chi^{(\alpha)} (g) = d_{\alpha}$ for any $\alpha \in \hat{G}$ such that $m^{(\alpha)} >0$. Then the conclusion follows. Can someone please let me know if I am wrong and we cannot get the result through what I wrote? Thanks!",,"['abstract-algebra', 'group-theory', 'finite-groups']"
33,"Rotman's Advanced Modern Algebra, Third Edition","Rotman's Advanced Modern Algebra, Third Edition",,"It has been not a long time since the monolithic Rotman's Advanced Modern Algebra has been re-published, in a reorganized, two volumes new edition. Do you know if and how the two volumes of this third edition differ in quality and quantity from the previous one? I read the respective tables of contents and I have only a vague idea about this. I think it would be useful if someone has a more concrete, fact-based opinion about possible differences between them, with also an (always personal, I know) judgement about which text would be preferable in which context.","It has been not a long time since the monolithic Rotman's Advanced Modern Algebra has been re-published, in a reorganized, two volumes new edition. Do you know if and how the two volumes of this third edition differ in quality and quantity from the previous one? I read the respective tables of contents and I have only a vague idea about this. I think it would be useful if someone has a more concrete, fact-based opinion about possible differences between them, with also an (always personal, I know) judgement about which text would be preferable in which context.",,"['abstract-algebra', 'book-recommendation']"
34,There exists a unique abelian extension such that $[K:\mathbb{Q}]=p$ and $disc(K)=p^n$,There exists a unique abelian extension such that  and,[K:\mathbb{Q}]=p disc(K)=p^n,"I am reading this PDF: http://www.math.uchicago.edu/~may/VIGRE/VIGRE2007/REUPapers/FINALFULL/Culler.pdf On page $7$ it states (and proves) the following assertion: If $p$ is an odd prime, then there is a unique abelian extension $K/\mathbb{Q}$ of degree $p$ with discriminant a power of $p$; in particular, it is the unique subﬁeld of $\mathbb{Q}\left (\zeta\right )$ of degree $p$ over $\mathbb{Q}$, where $\zeta$ is a $p^2$th root of unity. I am trying to read the proof but I really find it incomprehensible. The proof is the following, I will be stopping in order to explain which things I do not understand. Proof. Let $K$ be the unique subﬁeld of the $p^2$th cyclotomic ﬁeld of order $p$. Then $K$ is ramiﬁed only at the prime $p$, which shows existence of an extension with the desired properties. Now suppose that $K'$ is another such extension. We want to show that $K = K'$. To do this, ﬁrst take the composite $K'L$ with the $p$th cyclotomic ﬁeld $L = \mathbb{Q}(\zeta)$. Since $L$ contains the $p$th roots of unity, the standard results of Kummer theory apply, so $K'L = L( \sqrt[p]{\alpha})$ for some $\alpha \in L$. For example, if $K = K'$, then $\alpha$ could be $\zeta$, or a number of the form $\zeta^k\beta^p$ for some $k\in \mathbb{Z}$ not divisibleby $p$ and some $\beta \in L$. Well, here I think I understand. I really do not know too much about Kummer Theory, but I know that $K'L = L( \sqrt[p]{\alpha})$ because of Theorem 6.2 on Lang's Algebra, ""Cyclic extensions"" section. Also, because of what is going next, we need $\alpha$ integral, and we clearly can achieve this: there exists $m\in \mathbb{N}$ such that $m\alpha$ is integral, and $L( \sqrt[p]{\alpha})=L( m^p\sqrt[p]{\alpha})=L( \sqrt[p]{m\alpha})$. Let $\lambda=1-\zeta$. Then $N(\lambda)=p$, so $\lambda$ generates the unique prime ideal of $L$ lying over $p$. I did not understand this, but I know that if $\omega$ is a $p^n$-rooth of unity then $p\mathbb{Z}[\omega]=(1-\omega)^{\varphi\left (p^n\right )}$ so I am OK with that. We will show that $\alpha$ can be chosen to be an algebraic integer satisfying $\alpha\equiv 1\pmod {\lambda^p}$. First we show can choose $\alpha$ to be prime to $p$. To see this, we use the fact that $K'L$ is abelian. Consider a generator $\tau$ for $\text{Gal}(L/\mathbb{Q})$ and extend it to an automorphism $\tau\in \text{Gal}(K'L/L)$. Since $\sigma$ and $\tau$ commute, we have: $\sigma \tau(\sqrt[p]{\alpha})=\tau\sigma(\sqrt[p]{\alpha})=\tau(\zeta \sqrt[p]{\alpha})=\zeta^l\tau(\sqrt[p]{\alpha})$ for some primitive root modulo $p$. This shows that $\sqrt[p]{\alpha}$ is an eigenvector of $\sigma$ with eigenvalue $\zeta^l$. I think this last sentence is wrong. What is true is that $\sqrt[p]{\alpha}$ is an eigenvector of $\sigma$ with eigenvalue $\zeta$ and that $\tau (\sqrt[p]{\alpha})$ is an eigenvector of $\sigma$ with eigenvalue $\zeta^l$. So let's assume that and continue: Hence $\tau(\alpha)=\tau(\sqrt[p]{\alpha})^p=\left (c\sqrt[p]{\alpha^l}\right )^p=c^p\alpha^l$. Who is $c$? This is my attempt to explain what he tried to do: since the $L$-linear transformation $\sigma :K'L\to K'L$ between $p$-dimensional vector spaces admits $\sqrt[p]{\alpha}$ as an eigenvector with eigenvalue $\zeta$, then we easily obtain that $\sqrt[p]{\alpha^i}$ is an eigenvector with eigenvalue $\zeta^i$ for $i=0,1,\cdots ,p-1$. Since the $\zeta^i$ are all pairwise distinct because $\zeta$ is a primitive $p$th root of unity, we obtained $p$ different eigenvectors, and therefore each space of eigenvectors has dimension $1$. Since the eigenvectors with eigenvalue $\zeta^l$ are generated by $\sqrt[p]{\alpha^l}$ and $\tau (\sqrt[p]{\alpha})$ is an eigenvector of $\sigma$ with eigenvalue $\zeta^l$, then there exists $c\in L$ such that $\tau \left (\sqrt[p]{\alpha}\right )=c\sqrt[p]{\alpha^l}$. But this argument has a little problem: we need (because of what is going next) $c$ integral, and it is not clear to me that $c$ is an algebraic integer. Anyone? Now it is clear that $\alpha$ can be chosen to be prime to $p$. Simply replace $\alpha$ by $\frac{\tau(\alpha)}{\alpha}$. Since the ideal generated by $\lambda$ is invariant under $\tau$, any factor of $\lambda$ dividing $\alpha$ cancels out, leaving something prime to $p$. Note that once $\alpha$ is prime to $p$, we can also force $\alpha$ to be congruent to $1$ mod $\lambda$ by raising $\alpha$ to a suitable power, since the multiplicative group of a ﬁnite ﬁeld is cyclic. Why did he say that the multiplicative group of a ﬁnite ﬁeld is cyclic? I mean... Yes, it is true, but didn't it suffice to say just that it is a finite group and just use that $g^{|G|}=1$ for every $g$ in a finite group $G$? Also, using the fact that $\zeta^a\equiv 1-a\lambda\pmod{\lambda^2}$ we can force $\alpha$ to be congruent to $1$ mod $\lambda^2$ by multiplying by a suitable power of $\zeta$. Why? I mean, we know that $\alpha = 1+\lambda s$ with $s\in \mathbb{Z}[\zeta]$ and $\zeta^a\equiv 1-a\lambda\pmod{\lambda^2}$, therefore $\zeta^a\alpha \equiv 1+\lambda (s-a)\pmod {\lambda^2}$, hence we are saying that for every $s\in \mathbb{Z}[\zeta]$ there exists $a\in \mathbb{N}_0$ such that $\lambda \mid s-a$. Why it is true? Finally,  we use induction to obtain the desired congruence. Say we have already shown that $\alpha \equiv 1+ a\lambda^e\pmod{\lambda^{e+1}}$. Now we use again the fact that $K'L$ is abelian. We have the congruence $\sigma(\alpha)\equiv c^p\alpha^l\pmod{\lambda^{e+1}}$ which, given our assumption, gives that $c\equiv c^p\equiv 1\pmod{\lambda}$. And therefore $c^p\equiv 1\pmod p$. As a consequence we have $1+a(l\lambda)^e\equiv \sigma(\alpha)\equiv \alpha^l\equiv 1+al(\lambda^e)\pmod{\lambda^e}$ and hence $l^e\equiv l\pmod{\lambda}$. But $l$ was supposed to be a primitive root modulo $\lambda$, and $e$ was greater than $1$. The inductive step works as long as $e$ is less than $p$, so we have shown $\alpha\equiv 1+a\lambda^p\pmod{\lambda^{p+1}}$ or in other words, $\alpha \equiv 1\pmod {\lambda^p}$, as desired. I could not understand even a simple word. Why do we have the congruence $\sigma(\alpha)\equiv c^p\alpha^l\pmod{\lambda^{e+1}}$? Why does it imply that $c\equiv c^p\equiv 1\pmod{\lambda}$? And what is the meaning of $c^p\equiv 1\pmod p$? Wasn't $c$ an element in $L$? Who is $a$? As you may suspect, I have several questions about the rest of the argument. I really do not understand a simple step, so what I really need here is a detailed explanation. That $K=K'$ follows immediately from this. To see why, consider the number $\xi=\frac{1-\sqrt[p]{\alpha}}{\lambda}$. It is a root of the polynomial $f(x)=\left (x-\frac{1}{\lambda}\right )^p-\frac{\alpha}{\lambda^p}$. Well, I would take $f(x)=\left (x-\frac{1}{\lambda}\right )^p+\frac{\alpha}{\lambda^p}$ instead. It is clear that this polynomial is monic, and that all but the constant term are algebraic integers. But by the preceding argument, $1−\alpha$ is divisible by $\lambda^p$. Hence the constant term is also an algebraic integer. Hence $\xi$ is an algebraic integer. Since $\xi\in \mathcal{O}_{K'KL}$, the discriminant of $KK'L$ over $KL$ must contain the ideal generated by $\pm N(f'(\xi))=\pm N\left (p\left (\xi-\frac{1}{\lambda}\right )^{p-1}\right )=\epsilon \alpha^{p-1}$ for some unit $\epsilon$. I completely understood the first paragraph, but what about the second? It is clear that if $f(x)\in KL[x]$ then the discriminant of $KK'L$ over $KL$ must contain the ideal generated by $\pm N(f'(\xi))$, but why is it true that $f(x)\in KL[x]$? Moreover, why $\pm N\left (p\left (\xi-\frac{1}{\lambda}\right )^{p-1}\right )=\epsilon \alpha^{p-1}$ for some unit $\epsilon$? In particular, this discriminant is prime to $p$, so $p$ is unramiﬁed in the extension $KK'L/KL$. Hence $p$ is unramiﬁed in the inertial ﬁeld $T/\mathbb{Q}$, and this extension is nontrivial. But $p$ was the only ramiﬁed prime in $K$, $K'$, and $L$, and therefore no prime other than $p$ can be ramiﬁed in $T$. Hence $T/\mathbb{Q}$ is unramiﬁed. But this is a contradiction, since there are no nontrivial unramiﬁed extensions of $\mathbb{Q}$. I understood the argument, but we obtained a contradiction from what? What were we supposing that we obtained a contradiction? Since my questions are just too much (I really cannot understand anything of the proof, as you may have seen) I will summarize and enumerate them: 1) Why is $c$ an algebraic integer? 2) Why did he say that the multiplicative group of a ﬁnite ﬁeld is cyclic? Wasn't it enough to say that it was a finite group? 3) Why using the fact that $\zeta^a\equiv 1-a\lambda\pmod{\lambda^2}$ we can force $\alpha$ to be congruent to $1$ mod $\lambda^2$ by multiplying by a suitable power of $\zeta$? If for every $s\in \mathbb{Z}[\zeta]$ there exist $b\in \mathbb{N}_0$ such that $s\equiv b\pmod{\lambda}$ then we are done, but why it is true? 4) How did the author prove that $\alpha \equiv 1\pmod {\lambda^p}$? 5) Why $f(x)\in KL[x]$? 6) Why $\pm N\left (p\left (\xi-\frac{1}{\lambda}\right )^{p-1}\right )=\epsilon \alpha^{p-1}$ for some unit $\epsilon$? 7) The author says at the end that we obtained a contradiction. But I do not know which contradiction we achieved because I do not know which assumption we made in order to reach that contradiction. I suspect it must be that $K\neq K'$, but the author neither says something like ""let's assume that $K=K'$"" (or some other assumption) nor explicits where he is making use of that assumption. So... What assumption are we making and where are we making use of it?","I am reading this PDF: http://www.math.uchicago.edu/~may/VIGRE/VIGRE2007/REUPapers/FINALFULL/Culler.pdf On page $7$ it states (and proves) the following assertion: If $p$ is an odd prime, then there is a unique abelian extension $K/\mathbb{Q}$ of degree $p$ with discriminant a power of $p$; in particular, it is the unique subﬁeld of $\mathbb{Q}\left (\zeta\right )$ of degree $p$ over $\mathbb{Q}$, where $\zeta$ is a $p^2$th root of unity. I am trying to read the proof but I really find it incomprehensible. The proof is the following, I will be stopping in order to explain which things I do not understand. Proof. Let $K$ be the unique subﬁeld of the $p^2$th cyclotomic ﬁeld of order $p$. Then $K$ is ramiﬁed only at the prime $p$, which shows existence of an extension with the desired properties. Now suppose that $K'$ is another such extension. We want to show that $K = K'$. To do this, ﬁrst take the composite $K'L$ with the $p$th cyclotomic ﬁeld $L = \mathbb{Q}(\zeta)$. Since $L$ contains the $p$th roots of unity, the standard results of Kummer theory apply, so $K'L = L( \sqrt[p]{\alpha})$ for some $\alpha \in L$. For example, if $K = K'$, then $\alpha$ could be $\zeta$, or a number of the form $\zeta^k\beta^p$ for some $k\in \mathbb{Z}$ not divisibleby $p$ and some $\beta \in L$. Well, here I think I understand. I really do not know too much about Kummer Theory, but I know that $K'L = L( \sqrt[p]{\alpha})$ because of Theorem 6.2 on Lang's Algebra, ""Cyclic extensions"" section. Also, because of what is going next, we need $\alpha$ integral, and we clearly can achieve this: there exists $m\in \mathbb{N}$ such that $m\alpha$ is integral, and $L( \sqrt[p]{\alpha})=L( m^p\sqrt[p]{\alpha})=L( \sqrt[p]{m\alpha})$. Let $\lambda=1-\zeta$. Then $N(\lambda)=p$, so $\lambda$ generates the unique prime ideal of $L$ lying over $p$. I did not understand this, but I know that if $\omega$ is a $p^n$-rooth of unity then $p\mathbb{Z}[\omega]=(1-\omega)^{\varphi\left (p^n\right )}$ so I am OK with that. We will show that $\alpha$ can be chosen to be an algebraic integer satisfying $\alpha\equiv 1\pmod {\lambda^p}$. First we show can choose $\alpha$ to be prime to $p$. To see this, we use the fact that $K'L$ is abelian. Consider a generator $\tau$ for $\text{Gal}(L/\mathbb{Q})$ and extend it to an automorphism $\tau\in \text{Gal}(K'L/L)$. Since $\sigma$ and $\tau$ commute, we have: $\sigma \tau(\sqrt[p]{\alpha})=\tau\sigma(\sqrt[p]{\alpha})=\tau(\zeta \sqrt[p]{\alpha})=\zeta^l\tau(\sqrt[p]{\alpha})$ for some primitive root modulo $p$. This shows that $\sqrt[p]{\alpha}$ is an eigenvector of $\sigma$ with eigenvalue $\zeta^l$. I think this last sentence is wrong. What is true is that $\sqrt[p]{\alpha}$ is an eigenvector of $\sigma$ with eigenvalue $\zeta$ and that $\tau (\sqrt[p]{\alpha})$ is an eigenvector of $\sigma$ with eigenvalue $\zeta^l$. So let's assume that and continue: Hence $\tau(\alpha)=\tau(\sqrt[p]{\alpha})^p=\left (c\sqrt[p]{\alpha^l}\right )^p=c^p\alpha^l$. Who is $c$? This is my attempt to explain what he tried to do: since the $L$-linear transformation $\sigma :K'L\to K'L$ between $p$-dimensional vector spaces admits $\sqrt[p]{\alpha}$ as an eigenvector with eigenvalue $\zeta$, then we easily obtain that $\sqrt[p]{\alpha^i}$ is an eigenvector with eigenvalue $\zeta^i$ for $i=0,1,\cdots ,p-1$. Since the $\zeta^i$ are all pairwise distinct because $\zeta$ is a primitive $p$th root of unity, we obtained $p$ different eigenvectors, and therefore each space of eigenvectors has dimension $1$. Since the eigenvectors with eigenvalue $\zeta^l$ are generated by $\sqrt[p]{\alpha^l}$ and $\tau (\sqrt[p]{\alpha})$ is an eigenvector of $\sigma$ with eigenvalue $\zeta^l$, then there exists $c\in L$ such that $\tau \left (\sqrt[p]{\alpha}\right )=c\sqrt[p]{\alpha^l}$. But this argument has a little problem: we need (because of what is going next) $c$ integral, and it is not clear to me that $c$ is an algebraic integer. Anyone? Now it is clear that $\alpha$ can be chosen to be prime to $p$. Simply replace $\alpha$ by $\frac{\tau(\alpha)}{\alpha}$. Since the ideal generated by $\lambda$ is invariant under $\tau$, any factor of $\lambda$ dividing $\alpha$ cancels out, leaving something prime to $p$. Note that once $\alpha$ is prime to $p$, we can also force $\alpha$ to be congruent to $1$ mod $\lambda$ by raising $\alpha$ to a suitable power, since the multiplicative group of a ﬁnite ﬁeld is cyclic. Why did he say that the multiplicative group of a ﬁnite ﬁeld is cyclic? I mean... Yes, it is true, but didn't it suffice to say just that it is a finite group and just use that $g^{|G|}=1$ for every $g$ in a finite group $G$? Also, using the fact that $\zeta^a\equiv 1-a\lambda\pmod{\lambda^2}$ we can force $\alpha$ to be congruent to $1$ mod $\lambda^2$ by multiplying by a suitable power of $\zeta$. Why? I mean, we know that $\alpha = 1+\lambda s$ with $s\in \mathbb{Z}[\zeta]$ and $\zeta^a\equiv 1-a\lambda\pmod{\lambda^2}$, therefore $\zeta^a\alpha \equiv 1+\lambda (s-a)\pmod {\lambda^2}$, hence we are saying that for every $s\in \mathbb{Z}[\zeta]$ there exists $a\in \mathbb{N}_0$ such that $\lambda \mid s-a$. Why it is true? Finally,  we use induction to obtain the desired congruence. Say we have already shown that $\alpha \equiv 1+ a\lambda^e\pmod{\lambda^{e+1}}$. Now we use again the fact that $K'L$ is abelian. We have the congruence $\sigma(\alpha)\equiv c^p\alpha^l\pmod{\lambda^{e+1}}$ which, given our assumption, gives that $c\equiv c^p\equiv 1\pmod{\lambda}$. And therefore $c^p\equiv 1\pmod p$. As a consequence we have $1+a(l\lambda)^e\equiv \sigma(\alpha)\equiv \alpha^l\equiv 1+al(\lambda^e)\pmod{\lambda^e}$ and hence $l^e\equiv l\pmod{\lambda}$. But $l$ was supposed to be a primitive root modulo $\lambda$, and $e$ was greater than $1$. The inductive step works as long as $e$ is less than $p$, so we have shown $\alpha\equiv 1+a\lambda^p\pmod{\lambda^{p+1}}$ or in other words, $\alpha \equiv 1\pmod {\lambda^p}$, as desired. I could not understand even a simple word. Why do we have the congruence $\sigma(\alpha)\equiv c^p\alpha^l\pmod{\lambda^{e+1}}$? Why does it imply that $c\equiv c^p\equiv 1\pmod{\lambda}$? And what is the meaning of $c^p\equiv 1\pmod p$? Wasn't $c$ an element in $L$? Who is $a$? As you may suspect, I have several questions about the rest of the argument. I really do not understand a simple step, so what I really need here is a detailed explanation. That $K=K'$ follows immediately from this. To see why, consider the number $\xi=\frac{1-\sqrt[p]{\alpha}}{\lambda}$. It is a root of the polynomial $f(x)=\left (x-\frac{1}{\lambda}\right )^p-\frac{\alpha}{\lambda^p}$. Well, I would take $f(x)=\left (x-\frac{1}{\lambda}\right )^p+\frac{\alpha}{\lambda^p}$ instead. It is clear that this polynomial is monic, and that all but the constant term are algebraic integers. But by the preceding argument, $1−\alpha$ is divisible by $\lambda^p$. Hence the constant term is also an algebraic integer. Hence $\xi$ is an algebraic integer. Since $\xi\in \mathcal{O}_{K'KL}$, the discriminant of $KK'L$ over $KL$ must contain the ideal generated by $\pm N(f'(\xi))=\pm N\left (p\left (\xi-\frac{1}{\lambda}\right )^{p-1}\right )=\epsilon \alpha^{p-1}$ for some unit $\epsilon$. I completely understood the first paragraph, but what about the second? It is clear that if $f(x)\in KL[x]$ then the discriminant of $KK'L$ over $KL$ must contain the ideal generated by $\pm N(f'(\xi))$, but why is it true that $f(x)\in KL[x]$? Moreover, why $\pm N\left (p\left (\xi-\frac{1}{\lambda}\right )^{p-1}\right )=\epsilon \alpha^{p-1}$ for some unit $\epsilon$? In particular, this discriminant is prime to $p$, so $p$ is unramiﬁed in the extension $KK'L/KL$. Hence $p$ is unramiﬁed in the inertial ﬁeld $T/\mathbb{Q}$, and this extension is nontrivial. But $p$ was the only ramiﬁed prime in $K$, $K'$, and $L$, and therefore no prime other than $p$ can be ramiﬁed in $T$. Hence $T/\mathbb{Q}$ is unramiﬁed. But this is a contradiction, since there are no nontrivial unramiﬁed extensions of $\mathbb{Q}$. I understood the argument, but we obtained a contradiction from what? What were we supposing that we obtained a contradiction? Since my questions are just too much (I really cannot understand anything of the proof, as you may have seen) I will summarize and enumerate them: 1) Why is $c$ an algebraic integer? 2) Why did he say that the multiplicative group of a ﬁnite ﬁeld is cyclic? Wasn't it enough to say that it was a finite group? 3) Why using the fact that $\zeta^a\equiv 1-a\lambda\pmod{\lambda^2}$ we can force $\alpha$ to be congruent to $1$ mod $\lambda^2$ by multiplying by a suitable power of $\zeta$? If for every $s\in \mathbb{Z}[\zeta]$ there exist $b\in \mathbb{N}_0$ such that $s\equiv b\pmod{\lambda}$ then we are done, but why it is true? 4) How did the author prove that $\alpha \equiv 1\pmod {\lambda^p}$? 5) Why $f(x)\in KL[x]$? 6) Why $\pm N\left (p\left (\xi-\frac{1}{\lambda}\right )^{p-1}\right )=\epsilon \alpha^{p-1}$ for some unit $\epsilon$? 7) The author says at the end that we obtained a contradiction. But I do not know which contradiction we achieved because I do not know which assumption we made in order to reach that contradiction. I suspect it must be that $K\neq K'$, but the author neither says something like ""let's assume that $K=K'$"" (or some other assumption) nor explicits where he is making use of that assumption. So... What assumption are we making and where are we making use of it?",,"['abstract-algebra', 'field-theory', 'algebraic-number-theory', 'dedekind-domain']"
35,"Given a local field complete with respect to a discrete valuation, does that imply it is non-Archimedean?","Given a local field complete with respect to a discrete valuation, does that imply it is non-Archimedean?",,At the beginning of the section of a book I am reading it says $K$ is a local field complete with respect to a discrete valuation. Local fields can be archimedean or non-archimedean. Does the condition that it has a discrete valuation imply we are only dealing with non-archimedean local fields? Thank you very much.,At the beginning of the section of a book I am reading it says $K$ is a local field complete with respect to a discrete valuation. Local fields can be archimedean or non-archimedean. Does the condition that it has a discrete valuation imply we are only dealing with non-archimedean local fields? Thank you very much.,,"['abstract-algebra', 'valuation-theory', 'local-field', 'local-rings']"
36,Isomorphism between Endomorphisms of $R^n$ and $M_n(R^\mathrm{op})$,Isomorphism between Endomorphisms of  and,R^n M_n(R^\mathrm{op}),"My professor said in class that if we consider $R^n$ as an $R$-module, we get a bijection from the $\operatorname{End}(R^n)$ to the set of $n\times n$ matrices since we can regard any such homomorphism as a linear map from the vector space defined by $R^n$ onto itself. But what I don't get is the following, he said that this bijection is not a ring homomorphism, but there is a ring isomorphism between $\operatorname{End}(R^n)$ to $M_n(R^\mathrm{op})$ where $R^\mathrm{op}$ is the opposite ring. I know why this is true for a trivial module $M$ over $R$ where $M = R$. However I fail to see how this is the case for $R^n$ since I can simply identify a homomorphism from $R^n$ onto itself with a matrix, can anyone explain the technical details for how the opposite ring comes into the picture? Thanks.","My professor said in class that if we consider $R^n$ as an $R$-module, we get a bijection from the $\operatorname{End}(R^n)$ to the set of $n\times n$ matrices since we can regard any such homomorphism as a linear map from the vector space defined by $R^n$ onto itself. But what I don't get is the following, he said that this bijection is not a ring homomorphism, but there is a ring isomorphism between $\operatorname{End}(R^n)$ to $M_n(R^\mathrm{op})$ where $R^\mathrm{op}$ is the opposite ring. I know why this is true for a trivial module $M$ over $R$ where $M = R$. However I fail to see how this is the case for $R^n$ since I can simply identify a homomorphism from $R^n$ onto itself with a matrix, can anyone explain the technical details for how the opposite ring comes into the picture? Thanks.",,"['abstract-algebra', 'ring-theory', 'modules']"
37,Prime ideals of a finite direct product ring,Prime ideals of a finite direct product ring,,"Is it true that any prime ideal of a finite direct product ring $R=\prod_{i=1}^nR_i$ is of the form $P=\prod_{i=1}^nI_i$, where $I_j$ is a prime ideal of $R_j$ for some $j$ and $I_i=R_i$, for $i\neq j$? Any ideal of the form above is prime in $R$. Indeed, if $X=\prod_{i=1}^nA_i$ and $Y=\prod_{i=1}^nB_i$ are ideals of $R$ (where $A_i$'s and $B_i$'s are ideals of $R_i$) such that $XY\subseteq P$, then either $A_j$ or $B_j$ is a subset of a  prime ideal $I_j$, for some $j$. Hence either $X$ or $Y$ is a subset of $P$. Any help/suggestion would be appreciated!","Is it true that any prime ideal of a finite direct product ring $R=\prod_{i=1}^nR_i$ is of the form $P=\prod_{i=1}^nI_i$, where $I_j$ is a prime ideal of $R_j$ for some $j$ and $I_i=R_i$, for $i\neq j$? Any ideal of the form above is prime in $R$. Indeed, if $X=\prod_{i=1}^nA_i$ and $Y=\prod_{i=1}^nB_i$ are ideals of $R$ (where $A_i$'s and $B_i$'s are ideals of $R_i$) such that $XY\subseteq P$, then either $A_j$ or $B_j$ is a subset of a  prime ideal $I_j$, for some $j$. Hence either $X$ or $Y$ is a subset of $P$. Any help/suggestion would be appreciated!",,"['abstract-algebra', 'ring-theory', 'ideals', 'noncommutative-algebra']"
38,$P$ is a prime ideal of $R$ iff $R/P$ is an integral domain. : $P≠R$,is a prime ideal of  iff  is an integral domain. :,P R R/P P≠R,"Here is the theorem and proof in my textbook. Thm. Let $P$ be an ideal of a commutative ring $R$ with identity $1$.  Then $P$ is a prime ideal of $R$ if and only if $R/P$ is an integral domain. Proof. Suppose that $P$ is a prime ideal of a commutative ring $R$ with $1$.  Then $P$≠$R$ implies $1+P≠0+P$. Hence $R/P$ is a commutative ring $R$ with identity.  Assume that $(a+P)(b+P)=0+P$.  Then $ab+P=0+P$ and $ab∈P$.  By the definition of a prime ideal P we get $a∈P$ or $b∈P$.  That is, $a+P=0+P$ or $b+P=0+P$.  Thus $R/P$ is an integral domain. Conversely, if $R/P$ is an integral domain, then $1+P≠0+P$ and $R/P$ is a commutative ring $R$ which has no zero divisors.  Hence $P≠R$.  Assume $ab∈P$.  Then $ab+P=0+P$ and $(a+P)(b+P)=0+P$.  Since $R/P$ is an integral domain, we get $a+P=0+P$ or $b+P=0+P$.  So $a∈P$ or $b∈P$.  Thus $P$ is a prime ideal. I am having problems understanding proof with ""Conversely, if $R/P$ is an integral domain, then $1+P≠0+P$."". I know that $R/P$ has an identity. (cause it is ID) But, why doesn't ""$P$"" have an identity? Isn't there a case $P=R$? Please help me understanding. I think $P≠R$ should be with condition of Thm.. Thank you in advance.","Here is the theorem and proof in my textbook. Thm. Let $P$ be an ideal of a commutative ring $R$ with identity $1$.  Then $P$ is a prime ideal of $R$ if and only if $R/P$ is an integral domain. Proof. Suppose that $P$ is a prime ideal of a commutative ring $R$ with $1$.  Then $P$≠$R$ implies $1+P≠0+P$. Hence $R/P$ is a commutative ring $R$ with identity.  Assume that $(a+P)(b+P)=0+P$.  Then $ab+P=0+P$ and $ab∈P$.  By the definition of a prime ideal P we get $a∈P$ or $b∈P$.  That is, $a+P=0+P$ or $b+P=0+P$.  Thus $R/P$ is an integral domain. Conversely, if $R/P$ is an integral domain, then $1+P≠0+P$ and $R/P$ is a commutative ring $R$ which has no zero divisors.  Hence $P≠R$.  Assume $ab∈P$.  Then $ab+P=0+P$ and $(a+P)(b+P)=0+P$.  Since $R/P$ is an integral domain, we get $a+P=0+P$ or $b+P=0+P$.  So $a∈P$ or $b∈P$.  Thus $P$ is a prime ideal. I am having problems understanding proof with ""Conversely, if $R/P$ is an integral domain, then $1+P≠0+P$."". I know that $R/P$ has an identity. (cause it is ID) But, why doesn't ""$P$"" have an identity? Isn't there a case $P=R$? Please help me understanding. I think $P≠R$ should be with condition of Thm.. Thank you in advance.",,"['abstract-algebra', 'proof-writing', 'ideals', 'maximal-and-prime-ideals', 'integral-domain']"
39,$\alpha\in\mathbb{C}$ algebraic over $\mathbb{Q}$ iff $\alpha^n$ algebraic over $\mathbb{Q}$,algebraic over  iff  algebraic over,\alpha\in\mathbb{C} \mathbb{Q} \alpha^n \mathbb{Q},"Let $\alpha\in\mathbb{C}$ and $n\in\mathbb{N}$. Show, that $\alpha$ is algebraic over $\mathbb{Q}$, iff $\alpha^n$ is algebraic over $\mathbb{Q}$. Hello, I want to proof this, but get stuck really quick... I might need some help. ""$\Rightarrow$"" Suppose $\alpha$ is algebraic over $\mathbb{Q}$. Then there is $0\neq f\in\mathbb{Q}[X]$ with $f(\alpha)=0$. I have to show, that there is a $0\neq g\in\mathbb{Q}[X]$ with $g(\alpha^n)=0$ I tried severel things, but nothing of them should work. I want to construct $g$ by using $f$.  First i thought about division with remainder.  Then I tried to write $f(\alpha^n+\alpha-\alpha^n)$ and conclute something from there using the binomial theorem. I also thought about using the degree of the expansion $[\mathbb{Q}(\alpha):\mathbb{Q}]=\deg(f)$, where we can suppose that $f$ is the minimal polynomial of $\alpha$. Do you have a hint to get me started? Thanks in advance.","Let $\alpha\in\mathbb{C}$ and $n\in\mathbb{N}$. Show, that $\alpha$ is algebraic over $\mathbb{Q}$, iff $\alpha^n$ is algebraic over $\mathbb{Q}$. Hello, I want to proof this, but get stuck really quick... I might need some help. ""$\Rightarrow$"" Suppose $\alpha$ is algebraic over $\mathbb{Q}$. Then there is $0\neq f\in\mathbb{Q}[X]$ with $f(\alpha)=0$. I have to show, that there is a $0\neq g\in\mathbb{Q}[X]$ with $g(\alpha^n)=0$ I tried severel things, but nothing of them should work. I want to construct $g$ by using $f$.  First i thought about division with remainder.  Then I tried to write $f(\alpha^n+\alpha-\alpha^n)$ and conclute something from there using the binomial theorem. I also thought about using the degree of the expansion $[\mathbb{Q}(\alpha):\mathbb{Q}]=\deg(f)$, where we can suppose that $f$ is the minimal polynomial of $\alpha$. Do you have a hint to get me started? Thanks in advance.",,"['abstract-algebra', 'polynomials']"
40,How to prove that the Galois group of a polynomial is generated by transpositions?,How to prove that the Galois group of a polynomial is generated by transpositions?,,"Let $f_n(x)=x^n-x^{n-1}-....-x-1$ be the polynomial where $n$ is even. Now, $f_n(x)$ is an irreducible polynomial over $\mathbb{Q}$, so Galois group of $f_n(x)$, say Gal$(f_n)$ is a transitive subgroup of $S_n$. Also, Gal($f_n$) contains a transposition. Now, I need to show that Gal$(f_n)$ is generated by transpositions. How do I show that? Thanks!","Let $f_n(x)=x^n-x^{n-1}-....-x-1$ be the polynomial where $n$ is even. Now, $f_n(x)$ is an irreducible polynomial over $\mathbb{Q}$, so Galois group of $f_n(x)$, say Gal$(f_n)$ is a transitive subgroup of $S_n$. Also, Gal($f_n$) contains a transposition. Now, I need to show that Gal$(f_n)$ is generated by transpositions. How do I show that? Thanks!",,"['abstract-algebra', 'galois-theory', 'algebraic-number-theory']"
41,Proof of the Jordan Holder theorem from Serge Lang,Proof of the Jordan Holder theorem from Serge Lang,,"Why is there precisely one index $j$ such that $G_i/ G_{i+1} = G_{ij}/G_{i,j+1}$? How does the conclusion follow?","Why is there precisely one index $j$ such that $G_i/ G_{i+1} = G_{ij}/G_{i,j+1}$? How does the conclusion follow?",,"['abstract-algebra', 'group-theory']"
42,Isomorphism between $\mathbb{T}$ and $\mathbb{R} \oplus \mathbb{Q}/\mathbb{Z}$.,Isomorphism between  and .,\mathbb{T} \mathbb{R} \oplus \mathbb{Q}/\mathbb{Z},"I'm trying to prove that the circle group $\mathbb{T}$ is isomorphic to $\mathbb{R} \oplus \mathbb{Q}/\mathbb{Z}$ with a little bit of cardinal arithmetics. First, I know that $\mathbb{T}$ can be decomposed (structure theorem of divisible groups) as a direct sum of $\mathbb{Q}^X$ for some set $X$ and its torsion subgroup (which is isomorphic to $\mathbb{Q}/\mathbb{Z}$). I'd like to say that $|X| = |\mathbb{R}|$ (thus $\mathbb{Q}^X \cong \mathbb{R}$ as $\mathbb{Q}$ vector spaces and the desired result follows), however, I don't see how can I show this. My reasoning was: $|\mathbb{R}|=|\mathbb{T}|=|\mathbb{Q}^X||\mathbb{Q}/\mathbb{Z}|$, then it must be the case that $|\mathbb{T}|=|\mathbb{Q}^X|$ and $|\mathbb{R}|=|\mathbb{Q}^X|$, and here I'm stuck because I cannot conclude that $|X|$ must be $|\mathbb{R}|$ (as counterexample, $|\mathbb{R}| = |\mathbb{Q}^{\mathbb{N}}|$). Is there a way to prove that $|X| = |\mathbb{R}|$ or should I try another reasoning not involving cardinals? Edit: forgot $\mathbb{Q}^{X}$ is a direct sum of copies of $\mathbb{Q}$ (is not the whole direct product because $X$ cannot be finite), so my ""counterexample"" is useless but still cannot see the equality.","I'm trying to prove that the circle group $\mathbb{T}$ is isomorphic to $\mathbb{R} \oplus \mathbb{Q}/\mathbb{Z}$ with a little bit of cardinal arithmetics. First, I know that $\mathbb{T}$ can be decomposed (structure theorem of divisible groups) as a direct sum of $\mathbb{Q}^X$ for some set $X$ and its torsion subgroup (which is isomorphic to $\mathbb{Q}/\mathbb{Z}$). I'd like to say that $|X| = |\mathbb{R}|$ (thus $\mathbb{Q}^X \cong \mathbb{R}$ as $\mathbb{Q}$ vector spaces and the desired result follows), however, I don't see how can I show this. My reasoning was: $|\mathbb{R}|=|\mathbb{T}|=|\mathbb{Q}^X||\mathbb{Q}/\mathbb{Z}|$, then it must be the case that $|\mathbb{T}|=|\mathbb{Q}^X|$ and $|\mathbb{R}|=|\mathbb{Q}^X|$, and here I'm stuck because I cannot conclude that $|X|$ must be $|\mathbb{R}|$ (as counterexample, $|\mathbb{R}| = |\mathbb{Q}^{\mathbb{N}}|$). Is there a way to prove that $|X| = |\mathbb{R}|$ or should I try another reasoning not involving cardinals? Edit: forgot $\mathbb{Q}^{X}$ is a direct sum of copies of $\mathbb{Q}$ (is not the whole direct product because $X$ cannot be finite), so my ""counterexample"" is useless but still cannot see the equality.",,"['abstract-algebra', 'group-theory', 'cardinals', 'group-isomorphism', 'divisible-groups']"
43,Are field extensions faithfully flat? [closed],Are field extensions faithfully flat? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Is $\mathbb{C}$ a faithfully flat $\mathbb{R}$-module? In the general case, is it true that if $k$ is a field and $K$ is it's algebraic closure then $K$ is a faithfully flat $k$-module? Thank you for your time.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Is $\mathbb{C}$ a faithfully flat $\mathbb{R}$-module? In the general case, is it true that if $k$ is a field and $K$ is it's algebraic closure then $K$ is a faithfully flat $k$-module? Thank you for your time.",,['abstract-algebra']
44,Identities in groups having long proofs,Identities in groups having long proofs,,"I am looking for an example of a word in a finitely-presented group $G = \langle S | R \rangle$ which represents the identity, but for which the proof that this is so is quite long. That is, we need to cleverly insert a large number of relations, meanwhile increasing the size of the word, before we can discover that the word represents $1$. Not too long, though. I just want a nice explicit example for purposes of illustrating the phenomenon. I suppose I could set about trying to manufacture such an example, but I figure that standard examples are out there in the books, and why reinvent the wheel!","I am looking for an example of a word in a finitely-presented group $G = \langle S | R \rangle$ which represents the identity, but for which the proof that this is so is quite long. That is, we need to cleverly insert a large number of relations, meanwhile increasing the size of the word, before we can discover that the word represents $1$. Not too long, though. I just want a nice explicit example for purposes of illustrating the phenomenon. I suppose I could set about trying to manufacture such an example, but I figure that standard examples are out there in the books, and why reinvent the wheel!",,"['abstract-algebra', 'group-theory', 'finitely-generated']"
45,Group of units of direct sum of rings is isomorphic to direct sum of the groups of units,Group of units of direct sum of rings is isomorphic to direct sum of the groups of units,,"Let $R_{1}$, $R_{2}$, $\cdots$, $R_{m}$ be rings with identity. I need to prove that the following group isomorphism holds: $U(R_{1} \oplus R_{2} \oplus \cdots \oplus R_{n}) \simeq U(R_{1}) \oplus U(R_{2}) \oplus \cdots \oplus U(R_{n})$. I surmise that induction is going to be necessary here, but I'm having trouble even just getting started to prove it for just the base case, where $n = 2$:  $U(R_{1} \oplus R_{2}) \simeq U(R_{1}) \oplus U(R_{2})$. I have absolutely no idea where to begin, so any kind of point in the right direction would be appreciated. Just be willing to answer lots of follow-up questions, please. Thank you in advance.","Let $R_{1}$, $R_{2}$, $\cdots$, $R_{m}$ be rings with identity. I need to prove that the following group isomorphism holds: $U(R_{1} \oplus R_{2} \oplus \cdots \oplus R_{n}) \simeq U(R_{1}) \oplus U(R_{2}) \oplus \cdots \oplus U(R_{n})$. I surmise that induction is going to be necessary here, but I'm having trouble even just getting started to prove it for just the base case, where $n = 2$:  $U(R_{1} \oplus R_{2}) \simeq U(R_{1}) \oplus U(R_{2})$. I have absolutely no idea where to begin, so any kind of point in the right direction would be appreciated. Just be willing to answer lots of follow-up questions, please. Thank you in advance.",,"['abstract-algebra', 'ring-theory']"
46,"Let $N$ be an $R$-module, $I$ be a set and $\left \{ M_i:i \in I\right \}$ a collection of $R$-modules. Show that the injective functions...","Let  be an -module,  be a set and  a collection of -modules. Show that the injective functions...",N R I \left \{ M_i:i \in I\right \} R,"Let $N$ be an $R$-module, $I$ be a set and $\left \{ M_i:i \in I\right \}$ a collection of $R$-modules. Show that the injective functions $\iota_k:M_k\rightarrow \bigoplus_{i \in I}M_i$ induce a monomorphism of $R$-modules $$\bigoplus_{i \in I}\mathrm{Hom}(N, M_i)\rightarrow \mathrm{Hom}(N, \bigoplus_{i \in I} M_i),$$ and that is an isomorphism if $N$ is finitely generated. I have tried to do this by considering the function $\varphi  :\bigoplus_{i \in I}Hom (N, M_i)\rightarrow Hom(N, \bigoplus_{i \in I} M_i)$ given by $ \varphi (f_1 , f_2, ..., f_n) = f $ where each $ f_i: N \rightarrow M_i $ and $ f $ is the sum of each of the extensions $ \iota_j \circ f_j: N \rightarrow  \bigoplus_{i \in I} M_i$ of  $f_j $ but I do not know if this is okay, what do you say?","Let $N$ be an $R$-module, $I$ be a set and $\left \{ M_i:i \in I\right \}$ a collection of $R$-modules. Show that the injective functions $\iota_k:M_k\rightarrow \bigoplus_{i \in I}M_i$ induce a monomorphism of $R$-modules $$\bigoplus_{i \in I}\mathrm{Hom}(N, M_i)\rightarrow \mathrm{Hom}(N, \bigoplus_{i \in I} M_i),$$ and that is an isomorphism if $N$ is finitely generated. I have tried to do this by considering the function $\varphi  :\bigoplus_{i \in I}Hom (N, M_i)\rightarrow Hom(N, \bigoplus_{i \in I} M_i)$ given by $ \varphi (f_1 , f_2, ..., f_n) = f $ where each $ f_i: N \rightarrow M_i $ and $ f $ is the sum of each of the extensions $ \iota_j \circ f_j: N \rightarrow  \bigoplus_{i \in I} M_i$ of  $f_j $ but I do not know if this is okay, what do you say?",,"['abstract-algebra', 'commutative-algebra', 'modules']"
47,Prove that the union of two ideals is an ideal only if one of the ideals is contained within the other.,Prove that the union of two ideals is an ideal only if one of the ideals is contained within the other.,,"Here's my proof: Let the ideal $I = \{i_1, i_2,...\}$ and $J=\{j_1, j_2,...\}$ Then $I \cup J$ is an ideal only if for all $\nu, \mu$, $i_{\nu}+{j_\mu} \in I \cup J$. Let us assume that there exists an element $i_{\nu}$ of $I$ that does not belong to $J$. Then, for any $j_{\mu}$, either $i_{\nu}+{j_\mu} \in J$, which is a contradiction since it would imply that $i_{\nu} \in J$, or $i_{\nu}+{j_\mu} \in I$, which implies that $j_{\mu} \in I$. Letting $\mu$ run through the index of $J$, we get that $J \subset I$. Thus, our proof is complete. However, here are some things bothering me: There seems something fishy about this proof, but I can't point it out. Is my proof correct? Is this a constructive proof or a proof by contradiction? Does this proof use the Axiom of Choice? Thanks in advance for any help!","Here's my proof: Let the ideal $I = \{i_1, i_2,...\}$ and $J=\{j_1, j_2,...\}$ Then $I \cup J$ is an ideal only if for all $\nu, \mu$, $i_{\nu}+{j_\mu} \in I \cup J$. Let us assume that there exists an element $i_{\nu}$ of $I$ that does not belong to $J$. Then, for any $j_{\mu}$, either $i_{\nu}+{j_\mu} \in J$, which is a contradiction since it would imply that $i_{\nu} \in J$, or $i_{\nu}+{j_\mu} \in I$, which implies that $j_{\mu} \in I$. Letting $\mu$ run through the index of $J$, we get that $J \subset I$. Thus, our proof is complete. However, here are some things bothering me: There seems something fishy about this proof, but I can't point it out. Is my proof correct? Is this a constructive proof or a proof by contradiction? Does this proof use the Axiom of Choice? Thanks in advance for any help!",,"['abstract-algebra', 'ring-theory', 'ideals', 'proof-explanation', 'axiom-of-choice']"
48,Prove that $Gal(K/k) \cong \hat{\mathbb{Z}}$,Prove that,Gal(K/k) \cong \hat{\mathbb{Z}},"Let $K$ be the algebraic closure of a finite field $k$. Prove that $Gal(K/k) \cong \hat{\mathbb{Z}}$. From the definition in the book, here is how $\hat{\mathbb{Z}}$ is defined: Let $D = Cr(\mathbb{Z}_{p} | \; p \; prime)$, let $\delta: \mathbb{Z} \rightarrow D$ be the map taking $x \in \mathbb{Z}$ to the vector with all coordinates equal to $x$. Then the group $D$ together with the map $\delta$ is the profinite completion of $\mathbb{Z}$, denoted $\hat{\mathbb{Z}}$. There seem to be many sources online that cite this result as true, but I'm having trouble finding anywhere that shows a proof. This question is from Profinite Groups (Wilson), so I doubt that the solution is all that straight-forward. Could anyone offer me a solution or perhaps some insight on how to tackle this problem?","Let $K$ be the algebraic closure of a finite field $k$. Prove that $Gal(K/k) \cong \hat{\mathbb{Z}}$. From the definition in the book, here is how $\hat{\mathbb{Z}}$ is defined: Let $D = Cr(\mathbb{Z}_{p} | \; p \; prime)$, let $\delta: \mathbb{Z} \rightarrow D$ be the map taking $x \in \mathbb{Z}$ to the vector with all coordinates equal to $x$. Then the group $D$ together with the map $\delta$ is the profinite completion of $\mathbb{Z}$, denoted $\hat{\mathbb{Z}}$. There seem to be many sources online that cite this result as true, but I'm having trouble finding anywhere that shows a proof. This question is from Profinite Groups (Wilson), so I doubt that the solution is all that straight-forward. Could anyone offer me a solution or perhaps some insight on how to tackle this problem?",,"['abstract-algebra', 'group-theory', 'galois-theory', 'profinite-groups']"
49,normalizer of two p-Sylow intersection,normalizer of two p-Sylow intersection,,"Let $N(P_1 \cap P_2)$ be the intersection of 2 p-Sylow, $P_1$ and $P_2$. I have 2 questions (which I put in a single question here because connected, and I tried to prove the last one). First of all, given a group, is the intersection between p-Sylows always the same? (isomorphically) So if for instance I find two 2-Sylows of cardinality 8 whose intersection is a $\mathbb{Z}_2$, do I have that every intersection of every 2-Sylow is isomorphic to $\mathbb{Z}_2$? I had thought that if the action on the set of p-Sylow is double transitive then it's trivial, but is there some weaker criterion? Then I was wondering if given the example above it is always true that $P_1<N(P_1 \cap P_2)$, because my teacher once used this fact, but I am not sure if it is a general property or it worked only in the specific case. I have thought that since the conjugate of $P_1$ by the action of $P_1$ is itself, then the elements of $P_1 \cap P_2$ are bound to go on $P_1$, and so $P_2$ is bound to go on a $P_k$ whose intersection with $P_1$ is again $P_1 \cap P_2$. Would this be enough to prove that we always have $P_1<N(P_1 \cap P_2)$?","Let $N(P_1 \cap P_2)$ be the intersection of 2 p-Sylow, $P_1$ and $P_2$. I have 2 questions (which I put in a single question here because connected, and I tried to prove the last one). First of all, given a group, is the intersection between p-Sylows always the same? (isomorphically) So if for instance I find two 2-Sylows of cardinality 8 whose intersection is a $\mathbb{Z}_2$, do I have that every intersection of every 2-Sylow is isomorphic to $\mathbb{Z}_2$? I had thought that if the action on the set of p-Sylow is double transitive then it's trivial, but is there some weaker criterion? Then I was wondering if given the example above it is always true that $P_1<N(P_1 \cap P_2)$, because my teacher once used this fact, but I am not sure if it is a general property or it worked only in the specific case. I have thought that since the conjugate of $P_1$ by the action of $P_1$ is itself, then the elements of $P_1 \cap P_2$ are bound to go on $P_1$, and so $P_2$ is bound to go on a $P_k$ whose intersection with $P_1$ is again $P_1 \cap P_2$. Would this be enough to prove that we always have $P_1<N(P_1 \cap P_2)$?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
50,Peirce decomposition of a (not necessarily commutative) ring and the cartesian product,Peirce decomposition of a (not necessarily commutative) ring and the cartesian product,,"Let $R$ be a (not necessarily) commutative ring and $e \in R$ some idempotent. Then the Peirce decomposition writes $$  R=eRe \oplus (1-e)Re \oplus eR(1-e) \oplus (1-e)R(1-e). $$ I tried to construct such an isomorphism, specifically consider the cartesian product $eRe \times eR(1-e) \times (1-e)Re \times (1-e)R(1-e)$ , and the mapping $$  \varphi(r) = (ere, re - ere, er - ere, r - er - (re - ere)). $$ Then this is bijective. And also it is an isomorphism of $(R, +)$ and the additive group we get by componentwise addition on this cartesian product. But the only case that multiplication makes any sense is when $e$ is central, i.e. commutes with all elements, otherwise I am not even able to define multiplication componentwise in the above case. But the Pierce decomposition, for example also here and in the above link, does not require the idempotents to be central. So I am unable how this decomposition should work out, and I am surprised by the above inconsistencies? So could anyone explain them? Also for the preservation of the additive structure, and surjectivity and injectivity of $\varphi$ nowhere is it needed that we have $e^2 = e$ .","Let be a (not necessarily) commutative ring and some idempotent. Then the Peirce decomposition writes I tried to construct such an isomorphism, specifically consider the cartesian product , and the mapping Then this is bijective. And also it is an isomorphism of and the additive group we get by componentwise addition on this cartesian product. But the only case that multiplication makes any sense is when is central, i.e. commutes with all elements, otherwise I am not even able to define multiplication componentwise in the above case. But the Pierce decomposition, for example also here and in the above link, does not require the idempotents to be central. So I am unable how this decomposition should work out, and I am surprised by the above inconsistencies? So could anyone explain them? Also for the preservation of the additive structure, and surjectivity and injectivity of nowhere is it needed that we have .","R e \in R  
R=eRe \oplus (1-e)Re \oplus eR(1-e) \oplus (1-e)R(1-e).
 eRe \times eR(1-e) \times (1-e)Re \times (1-e)R(1-e) 
 \varphi(r) = (ere, re - ere, er - ere, r - er - (re - ere)).
 (R, +) e \varphi e^2 = e","['abstract-algebra', 'ring-theory', 'rngs']"
51,Every intermediate field of an infinite Galois extension is the union of finite extensions,Every intermediate field of an infinite Galois extension is the union of finite extensions,,I was stumbling upon this statement in my study of infinite Galois extensions but it had no further explanation. It seems true to me but I don't know how to construct these finite extensions. Thanks for the help in advance!,I was stumbling upon this statement in my study of infinite Galois extensions but it had no further explanation. It seems true to me but I don't know how to construct these finite extensions. Thanks for the help in advance!,,"['abstract-algebra', 'galois-theory', 'extension-field']"
52,Existence of an onto group homomorphism from $S_4$ to $\Bbb Z_4$,Existence of an onto group homomorphism from  to,S_4 \Bbb Z_4,"Let $S_n$ be the symmetric group of $n$ letters. Then does there exist an onto group homomorphism    from $S_4$ to $\Bbb Z_4$? My try : Suppose that  $f:S_4 \to \Bbb Z_4$ is a group homommorphism. Then $S_4/\ker f\cong \Bbb Z_4\implies o(\ker f)=6\implies \ker f$ is isomorphic to $S_3$ or $\Bbb Z_6$. If $\ker f=\Bbb Z_6\implies S_4\cong  \Bbb Z_6\times \Bbb Z_4$ which is false as $S_4$ is not commutative whereas $\Bbb Z_6\times \Bbb Z_4$ is. If $\ker f=S_3\implies S_3$ is a normal subgroup of $S_4$. Now take $S_3=\{e,(12),(23),(13),(123),(132)\}$.Then $(14)(123)(14)=(234)\notin S_3$.Hence $S_3$ is not normal. Is my solution correct??","Let $S_n$ be the symmetric group of $n$ letters. Then does there exist an onto group homomorphism    from $S_4$ to $\Bbb Z_4$? My try : Suppose that  $f:S_4 \to \Bbb Z_4$ is a group homommorphism. Then $S_4/\ker f\cong \Bbb Z_4\implies o(\ker f)=6\implies \ker f$ is isomorphic to $S_3$ or $\Bbb Z_6$. If $\ker f=\Bbb Z_6\implies S_4\cong  \Bbb Z_6\times \Bbb Z_4$ which is false as $S_4$ is not commutative whereas $\Bbb Z_6\times \Bbb Z_4$ is. If $\ker f=S_3\implies S_3$ is a normal subgroup of $S_4$. Now take $S_3=\{e,(12),(23),(13),(123),(132)\}$.Then $(14)(123)(14)=(234)\notin S_3$.Hence $S_3$ is not normal. Is my solution correct??",,"['abstract-algebra', 'group-theory', 'proof-verification', 'group-homomorphism']"
53,Question on proof that $|G| = pqr$ is not simple,Question on proof that  is not simple,|G| = pqr,"Assume $|G| = pqr$ where $p,q,r$ are primes with $p < q < r$. Then $G$   is not simple. I have a problem understanding the proof (see for example here ). In the proof one assumes that $n_p,n_q,n_r > 1$ (number of each $p,q,r$-Sylow subgroups respectively) and then by Sylow we have $$n_r | pq \qquad \text{and} \qquad n_r = 1 + kr, k\in \mathbb{N}_0$$ Now one deduces that $n_r = pq$, which I do not understand.","Assume $|G| = pqr$ where $p,q,r$ are primes with $p < q < r$. Then $G$   is not simple. I have a problem understanding the proof (see for example here ). In the proof one assumes that $n_p,n_q,n_r > 1$ (number of each $p,q,r$-Sylow subgroups respectively) and then by Sylow we have $$n_r | pq \qquad \text{and} \qquad n_r = 1 + kr, k\in \mathbb{N}_0$$ Now one deduces that $n_r = pq$, which I do not understand.",,['abstract-algebra']
54,Show that any cyclic group with square free order is the Galois group over $\mathbb{Q}$ of some field extension,Show that any cyclic group with square free order is the Galois group over  of some field extension,\mathbb{Q},"Show that any cyclic group with square free order is the Galois group over $\mathbb{Q}$ of some field extension. I'm curious because I (believe) know the proof when $G$ is a finite cyclic group of any order, so I'm wondering if perhaps the square-free case is easier. This is off an old qualifying exam, and the hint is to consider $x^n-1$ for suitable $n$. In any case, an outline of the proof for a cyclic group is as follows: $G \cong \mathbb{Z}_n$ for some $n$. Then, there exists a prime $p$ such that $n \mid p-1$. Writing $p-1=n\cdot m$, we know $\mathbb{Z}_{m}$ is a subgroup of $\mathbb{Z}_{p-1}$. Then one considers $\zeta$ a primitive $p$th root of unity. We know $Gal(\mathbb{Q}(\zeta)/\mathbb{Q}) \cong \mathbb{Z}_{p-1}$. As this is abelian, $\mathbb{Z}_m$ is a normal subgroup of this group, and so if $K$ is the fixed field of $\mathbb{Z}_m$, it has Galois group isomorphic to $Gal(\mathbb{Q}(\zeta)/\mathbb{Q}) / \mathbb{Z}_m \cong \mathbb{Z}_n \cong G$. Assuming the above is correct, how would square free order change this at all? Thanks!","Show that any cyclic group with square free order is the Galois group over $\mathbb{Q}$ of some field extension. I'm curious because I (believe) know the proof when $G$ is a finite cyclic group of any order, so I'm wondering if perhaps the square-free case is easier. This is off an old qualifying exam, and the hint is to consider $x^n-1$ for suitable $n$. In any case, an outline of the proof for a cyclic group is as follows: $G \cong \mathbb{Z}_n$ for some $n$. Then, there exists a prime $p$ such that $n \mid p-1$. Writing $p-1=n\cdot m$, we know $\mathbb{Z}_{m}$ is a subgroup of $\mathbb{Z}_{p-1}$. Then one considers $\zeta$ a primitive $p$th root of unity. We know $Gal(\mathbb{Q}(\zeta)/\mathbb{Q}) \cong \mathbb{Z}_{p-1}$. As this is abelian, $\mathbb{Z}_m$ is a normal subgroup of this group, and so if $K$ is the fixed field of $\mathbb{Z}_m$, it has Galois group isomorphic to $Gal(\mathbb{Q}(\zeta)/\mathbb{Q}) / \mathbb{Z}_m \cong \mathbb{Z}_n \cong G$. Assuming the above is correct, how would square free order change this at all? Thanks!",,"['abstract-algebra', 'field-theory', 'galois-theory']"
55,A basis of a Galois extension.,A basis of a Galois extension.,,"Let $f(x) = x^3 - 3x + 1 \in \mathbb{Q}[x]$. It is irreducible over $\mathbb{Q}$ since it is irreducible over $\mathbb{F}_2$. The discriminant of $f$ is $81 = 9^2$, so the Galois group of $f$ is isomorphic to $A_3$ and the splitting field of $f$ is $\mathbb{Q}(\alpha)$, where $\alpha$ is a root of $f$. Now I want to represent the elements of $G(\mathbb{Q}(\alpha)/\mathbb{Q})$ as matrices $3 \times 3$, but to do that I need a basis of $\mathbb{Q}(\alpha)$ over $\mathbb{Q}$. And the question is: What basis of $\mathbb{Q}(\alpha)/\mathbb{Q}$ is better to choose and how to express the roots $\alpha, \beta$ and $\gamma$ in terms of that basis? If I take ${1, \alpha, \alpha^2}$ as a basis, what is a good way of finding the coordinates of $\beta$ and $\gamma$?","Let $f(x) = x^3 - 3x + 1 \in \mathbb{Q}[x]$. It is irreducible over $\mathbb{Q}$ since it is irreducible over $\mathbb{F}_2$. The discriminant of $f$ is $81 = 9^2$, so the Galois group of $f$ is isomorphic to $A_3$ and the splitting field of $f$ is $\mathbb{Q}(\alpha)$, where $\alpha$ is a root of $f$. Now I want to represent the elements of $G(\mathbb{Q}(\alpha)/\mathbb{Q})$ as matrices $3 \times 3$, but to do that I need a basis of $\mathbb{Q}(\alpha)$ over $\mathbb{Q}$. And the question is: What basis of $\mathbb{Q}(\alpha)/\mathbb{Q}$ is better to choose and how to express the roots $\alpha, \beta$ and $\gamma$ in terms of that basis? If I take ${1, \alpha, \alpha^2}$ as a basis, what is a good way of finding the coordinates of $\beta$ and $\gamma$?",,"['abstract-algebra', 'number-theory', 'field-theory', 'galois-theory', 'algebraic-number-theory']"
56,"Where does ""Additivity"" show up besides measure theory?","Where does ""Additivity"" show up besides measure theory?",,"The properties of ""additivity"" or ""$\sigma$-additivity"" seem to be quite localized phenomenons at first glance, specific to measures or appropiate generalizations of those. Let $L$ be a lattice. Elements $x,y\in L$ are disjoint , if $x\wedge y = \bot$ (smallest element). A map $f : L \to M$ into some commutative monoid $M$ is additive , if $f(x \vee y) = x + y$ whenever $x,y$ are disjoint. Something similar can be done with $\sigma$-additivity, where $M$ is a complete monoid. I feel like there should be some interesting examples, where $L$ is not just a set of sets ordered by $\subseteq$. So: Where does ""Additivity"" show up besides measure theory? (A more basic problem is perhaps finding instances, where disjointness is useful. Here are two examples: $x,y\in \mathbb Z_{\geq 0}$ are disjoint w.r.t. to $\mid$, if they are coprime; subgroups $M,N\subseteq G$ are disjoint, if $M\cap N \cong 1$. In totally ordered sets, disjointness is of course quite boring).","The properties of ""additivity"" or ""$\sigma$-additivity"" seem to be quite localized phenomenons at first glance, specific to measures or appropiate generalizations of those. Let $L$ be a lattice. Elements $x,y\in L$ are disjoint , if $x\wedge y = \bot$ (smallest element). A map $f : L \to M$ into some commutative monoid $M$ is additive , if $f(x \vee y) = x + y$ whenever $x,y$ are disjoint. Something similar can be done with $\sigma$-additivity, where $M$ is a complete monoid. I feel like there should be some interesting examples, where $L$ is not just a set of sets ordered by $\subseteq$. So: Where does ""Additivity"" show up besides measure theory? (A more basic problem is perhaps finding instances, where disjointness is useful. Here are two examples: $x,y\in \mathbb Z_{\geq 0}$ are disjoint w.r.t. to $\mid$, if they are coprime; subgroups $M,N\subseteq G$ are disjoint, if $M\cap N \cong 1$. In totally ordered sets, disjointness is of course quite boring).",,"['abstract-algebra', 'lattice-orders']"
57,"Condition for an algebra to be finite, which does not use the underlying set","Condition for an algebra to be finite, which does not use the underlying set",,"I wonder whether there is any categorical property that picks out   exactly the finite algebras of some algebraic theory without referring to the underlying set. What I mean is: I don't want to use the the structure of a functor $\mathcal{A} \to \mathsf{Set}$ from my algebraic category. This is (obviously) not so interesting, but more importantly I want the property to make sense in the absence of any such structure too (obviously I could have a different interpretation then, I'm open to anything interesting). No cheating allowed, of course! You can't refer to the free object on a singleton, because that doesn't make any sense in a general category (e.g. you can't use $\mathcal{A}(\mathbb Z, G)$ to count the elements in a group $G$ as $\mathbb{Z}$ is determined by some property involving the functor $\mathcal{A} \to \mathsf{Set}$; even though you can characterise $\mathbb{Z}$ by different means, this probably doesn't make much sense for other kinds of algebras besides groups). Here are some necessary conditions for an algebra $A$ to be finite (but I don't see how any of them are sufficient): the poset of subobjects $\operatorname{Sub} A$ is finite $A$ is finitely generated ($\mathcal{A}(X,\_)$ preserves filtered colimits of monos) the monoid of endomorphisms $\operatorname{End} A$ is finite $A$ is Dedekind-finite, i.e.: every mono (injection) $A\to A$ is an isomorphism I'd also be interested in a property for some (not to small ) subclass of all theories or a statement, that what I'm trying to do is infeasible.","I wonder whether there is any categorical property that picks out   exactly the finite algebras of some algebraic theory without referring to the underlying set. What I mean is: I don't want to use the the structure of a functor $\mathcal{A} \to \mathsf{Set}$ from my algebraic category. This is (obviously) not so interesting, but more importantly I want the property to make sense in the absence of any such structure too (obviously I could have a different interpretation then, I'm open to anything interesting). No cheating allowed, of course! You can't refer to the free object on a singleton, because that doesn't make any sense in a general category (e.g. you can't use $\mathcal{A}(\mathbb Z, G)$ to count the elements in a group $G$ as $\mathbb{Z}$ is determined by some property involving the functor $\mathcal{A} \to \mathsf{Set}$; even though you can characterise $\mathbb{Z}$ by different means, this probably doesn't make much sense for other kinds of algebras besides groups). Here are some necessary conditions for an algebra $A$ to be finite (but I don't see how any of them are sufficient): the poset of subobjects $\operatorname{Sub} A$ is finite $A$ is finitely generated ($\mathcal{A}(X,\_)$ preserves filtered colimits of monos) the monoid of endomorphisms $\operatorname{End} A$ is finite $A$ is Dedekind-finite, i.e.: every mono (injection) $A\to A$ is an isomorphism I'd also be interested in a property for some (not to small ) subclass of all theories or a statement, that what I'm trying to do is infeasible.",,"['abstract-algebra', 'category-theory', 'universal-algebra']"
58,Coproduct of non-unital commutative algebras,Coproduct of non-unital commutative algebras,,"If $A,B$ are non-unital commutative algebras over a field $R$, what should their (categorical) coproduct? I know for unital algebras the tensor product is the coproduct, but I think the construction of tensor product as a coproduct only worked there because we could have a unit element in multiplication, so we could just send, for example, $a\otimes 1_B \to f(a)g(1_B)=f(a)$ for some morphisms $f:A\to C$, $g:B\to C$ where $C$ is another algebra. Apparently without unit element we can't do this anymore. So what would coproduct be in this case?","If $A,B$ are non-unital commutative algebras over a field $R$, what should their (categorical) coproduct? I know for unital algebras the tensor product is the coproduct, but I think the construction of tensor product as a coproduct only worked there because we could have a unit element in multiplication, so we could just send, for example, $a\otimes 1_B \to f(a)g(1_B)=f(a)$ for some morphisms $f:A\to C$, $g:B\to C$ where $C$ is another algebra. Apparently without unit element we can't do this anymore. So what would coproduct be in this case?",,"['abstract-algebra', 'category-theory']"
59,Stabilizers of the adjoint representation of $GL_n(\mathbb{C})$,Stabilizers of the adjoint representation of,GL_n(\mathbb{C}),"The Lie group of invertible matrices $GL_n(\mathbb{C})$ acts by conjugation on its Lie algebra $gl_n(\mathbb{C})$ of all matrices. Orbits of this action are in bijection with canonical forms of matrices: rational canonical forms or Jordan forms. But how one can compute stabilizers of this action? In concrete terms I want to find all invertible matrices commuting with a given matrix in its canonical form. Of course, this question has a general version for any Lie group and adjoint representation on its Lie algebra. Perhaps, it is possible to solve it in this generality, but the case of $GL_n(\mathbb{C})$ is already non-trivial for me. Update: Perhaps, it is easier to understand in terms of modules over $R=\mathbb{C}[t]$. Given an $n \times n$ matrix $A$ we can consider $M = \mathbb{C}^n$ as a $\mathbb{C}[t]$ module on length $n$. Matrices commuting with $A$ are $\text{End}_R(M)$, invertible matrices are invertible elements of this ring $\text{End}_R(M)^*$. Ring $R$ is a PID, and $M \cong \bigoplus_{i,j} R/(t-\lambda_i)^{n_{ij}}$. To compute the endomorphism ring we use $\text{Hom}_R(R/f,R/g) \cong R/\text{g.c.d.}(f,g)$. So $$ \text{Hom}(\bigoplus_{i,j} R/(t-\lambda_i)^{n_{ij}}, \bigoplus_{k,l} R/(t-\lambda_k)^{n_{kl}}) \cong \bigoplus_{i,j,l} R/(t-\lambda_i)^{\text{g.c.d.}(n_{ij}, n_{il})} $$ Then  $$ \text{End}_R(M)^* \cong \bigoplus_{i,j,l} (R/(t-\lambda_i)^{\text{g.c.d.}(n_{ij}, n_{il})})^* $$ Invertible elements of $R/(t-\lambda)^m$ are truncated polynomials with non-zero constant term.","The Lie group of invertible matrices $GL_n(\mathbb{C})$ acts by conjugation on its Lie algebra $gl_n(\mathbb{C})$ of all matrices. Orbits of this action are in bijection with canonical forms of matrices: rational canonical forms or Jordan forms. But how one can compute stabilizers of this action? In concrete terms I want to find all invertible matrices commuting with a given matrix in its canonical form. Of course, this question has a general version for any Lie group and adjoint representation on its Lie algebra. Perhaps, it is possible to solve it in this generality, but the case of $GL_n(\mathbb{C})$ is already non-trivial for me. Update: Perhaps, it is easier to understand in terms of modules over $R=\mathbb{C}[t]$. Given an $n \times n$ matrix $A$ we can consider $M = \mathbb{C}^n$ as a $\mathbb{C}[t]$ module on length $n$. Matrices commuting with $A$ are $\text{End}_R(M)$, invertible matrices are invertible elements of this ring $\text{End}_R(M)^*$. Ring $R$ is a PID, and $M \cong \bigoplus_{i,j} R/(t-\lambda_i)^{n_{ij}}$. To compute the endomorphism ring we use $\text{Hom}_R(R/f,R/g) \cong R/\text{g.c.d.}(f,g)$. So $$ \text{Hom}(\bigoplus_{i,j} R/(t-\lambda_i)^{n_{ij}}, \bigoplus_{k,l} R/(t-\lambda_k)^{n_{kl}}) \cong \bigoplus_{i,j,l} R/(t-\lambda_i)^{\text{g.c.d.}(n_{ij}, n_{il})} $$ Then  $$ \text{End}_R(M)^* \cong \bigoplus_{i,j,l} (R/(t-\lambda_i)^{\text{g.c.d.}(n_{ij}, n_{il})})^* $$ Invertible elements of $R/(t-\lambda)^m$ are truncated polynomials with non-zero constant term.",,"['abstract-algebra', 'matrices', 'proof-verification', 'lie-groups']"
60,Existence of coproducts and products in category,Existence of coproducts and products in category,,"I am very beginner in Category theory, and the question I am asking here is related with some example of category theory coming from simple theorems in ring theory. Fact: Let $R$ be a commutative ring with unity. If l.c.m. of $a,b$ in $R$ exists then $g.c.d.$ exists. Now let us move in Category theory theory with a specific example. Let $R$ be a ring with unity. Define a category as follows: Objects: members of $R$. Morphisms: if $a$ divides $b$ in $R$, let $k_a^b$ denote a morphism, o.w.  no morphism between $a$ and $b$. Thus, the set of morphisms between $a$ and $b$ is either singleton (when $a$ divides $b$) or empty. Then the co-product of two objects in this category is l.c.m. and product is g.c.d. Of course, the product or co-product of two objects may not exists in this category, for certain rings $R$. Now the fact mentioned in the beginning says that if co-product of two objects in the above category exists, then the product of the same  two objects also exists. My natural question is, whether such phenomena occurs in every category, i.e. Question: If $\mathcal{C}$ is any category, and if co-product of two objects $A,B$ in $\mathcal{C}$ exists, then is it necessary that the product of $A$ and $B$ also exists? Please do corrections in the setting if there are mistakes in presenting category theory statements; as said initially, I am very beginner in Category theory.","I am very beginner in Category theory, and the question I am asking here is related with some example of category theory coming from simple theorems in ring theory. Fact: Let $R$ be a commutative ring with unity. If l.c.m. of $a,b$ in $R$ exists then $g.c.d.$ exists. Now let us move in Category theory theory with a specific example. Let $R$ be a ring with unity. Define a category as follows: Objects: members of $R$. Morphisms: if $a$ divides $b$ in $R$, let $k_a^b$ denote a morphism, o.w.  no morphism between $a$ and $b$. Thus, the set of morphisms between $a$ and $b$ is either singleton (when $a$ divides $b$) or empty. Then the co-product of two objects in this category is l.c.m. and product is g.c.d. Of course, the product or co-product of two objects may not exists in this category, for certain rings $R$. Now the fact mentioned in the beginning says that if co-product of two objects in the above category exists, then the product of the same  two objects also exists. My natural question is, whether such phenomena occurs in every category, i.e. Question: If $\mathcal{C}$ is any category, and if co-product of two objects $A,B$ in $\mathcal{C}$ exists, then is it necessary that the product of $A$ and $B$ also exists? Please do corrections in the setting if there are mistakes in presenting category theory statements; as said initially, I am very beginner in Category theory.",,"['abstract-algebra', 'ring-theory', 'category-theory']"
61,Relation between braided Hopf algebra and usual Hopf algebra.,Relation between braided Hopf algebra and usual Hopf algebra.,,"What are the relations between braided Hopf algebra and usual Hopf algebra? Acoording to wikipedia , a braided Hopf algebra is defined as follows. Let H be a Hopf algebra over a field $k$, and assume that the antipode of $H$ is bijective. A Yetter–Drinfeld module $R$ over $H$ is called a braided bialgebra in the Yetter–Drinfeld category ${}_{H}^{H}{\mathcal  {YD}}$ if ${\displaystyle (R,\cdot ,\eta )}$ is a unital associative algebra, where the multiplication map ${\displaystyle \cdot :R\times R\to R}$ and the unit ${\displaystyle \eta :k\to R}$ are maps of Yetter–Drinfeld modules, ${\displaystyle (R,\Delta ,\varepsilon )}$ is a coassociative coalgebra with counit ${\displaystyle \varepsilon }$, and both $\Delta$  and ${\displaystyle \varepsilon }$  are maps of Yetter–Drinfeld modules, the maps ${\displaystyle \Delta :R\to R\otimes R}$ and ${\displaystyle \varepsilon :R\to k}$ are algebra maps in the category ${}_{H}^{H}{\mathcal  {YD}}$, where the algebra structure of ${\displaystyle R\otimes R}$ is determined by the unit ${\displaystyle \eta \otimes \eta (1):k\to R\otimes R}$ and the multiplication map \begin{align} (R\otimes R)\times (R\otimes R)\to R\otimes R,\quad (r\otimes s,t\otimes u)\mapsto \sum _{i}rt_{i}\otimes s_{i}u, \end{align} and $$ c(s\otimes t)=\sum _{i}t_{i}\otimes s_{i}. (R\otimes R)\times (R\otimes R)\to R\otimes R,\quad (r\otimes s,t\otimes u)\mapsto \sum _{i}rt_{i}\otimes s_{i}u, $$ and $$ c(s\otimes t)=\sum _{i}t_{i}\otimes s_{i}.  $$ Here $c$ is the canonical braiding in the Yetter–Drinfeld category ${\displaystyle {}_{H}^{H}{\mathcal {YD}}}$. A braided bialgebra in ${\displaystyle {}_{H}^{H}{\mathcal {YD}}}$ is called a braided Hopf algebra, if there is a morphism ${\displaystyle S:R\to R}$ of Yetter–Drinfeld modules such that $$ {\displaystyle S(r^{(1)})r^{(2)}=r^{(1)}S(r^{(2)})=\eta (\varepsilon (r))} {\displaystyle S(r^{(1)})r^{(2)}=r^{(1)}S(r^{(2)})=\eta (\varepsilon (r))}$$  for all ${\displaystyle r\in R,}$ where $${\displaystyle \Delta _{R}(r)=r^{(1)}\otimes r^{(2)}}$$ is the Sweedler notation. The usual Hopf algebra is a braided Hopf algebra when the braiding is permutation. Is this correct? Thank you very much.","What are the relations between braided Hopf algebra and usual Hopf algebra? Acoording to wikipedia , a braided Hopf algebra is defined as follows. Let H be a Hopf algebra over a field $k$, and assume that the antipode of $H$ is bijective. A Yetter–Drinfeld module $R$ over $H$ is called a braided bialgebra in the Yetter–Drinfeld category ${}_{H}^{H}{\mathcal  {YD}}$ if ${\displaystyle (R,\cdot ,\eta )}$ is a unital associative algebra, where the multiplication map ${\displaystyle \cdot :R\times R\to R}$ and the unit ${\displaystyle \eta :k\to R}$ are maps of Yetter–Drinfeld modules, ${\displaystyle (R,\Delta ,\varepsilon )}$ is a coassociative coalgebra with counit ${\displaystyle \varepsilon }$, and both $\Delta$  and ${\displaystyle \varepsilon }$  are maps of Yetter–Drinfeld modules, the maps ${\displaystyle \Delta :R\to R\otimes R}$ and ${\displaystyle \varepsilon :R\to k}$ are algebra maps in the category ${}_{H}^{H}{\mathcal  {YD}}$, where the algebra structure of ${\displaystyle R\otimes R}$ is determined by the unit ${\displaystyle \eta \otimes \eta (1):k\to R\otimes R}$ and the multiplication map \begin{align} (R\otimes R)\times (R\otimes R)\to R\otimes R,\quad (r\otimes s,t\otimes u)\mapsto \sum _{i}rt_{i}\otimes s_{i}u, \end{align} and $$ c(s\otimes t)=\sum _{i}t_{i}\otimes s_{i}. (R\otimes R)\times (R\otimes R)\to R\otimes R,\quad (r\otimes s,t\otimes u)\mapsto \sum _{i}rt_{i}\otimes s_{i}u, $$ and $$ c(s\otimes t)=\sum _{i}t_{i}\otimes s_{i}.  $$ Here $c$ is the canonical braiding in the Yetter–Drinfeld category ${\displaystyle {}_{H}^{H}{\mathcal {YD}}}$. A braided bialgebra in ${\displaystyle {}_{H}^{H}{\mathcal {YD}}}$ is called a braided Hopf algebra, if there is a morphism ${\displaystyle S:R\to R}$ of Yetter–Drinfeld modules such that $$ {\displaystyle S(r^{(1)})r^{(2)}=r^{(1)}S(r^{(2)})=\eta (\varepsilon (r))} {\displaystyle S(r^{(1)})r^{(2)}=r^{(1)}S(r^{(2)})=\eta (\varepsilon (r))}$$  for all ${\displaystyle r\in R,}$ where $${\displaystyle \Delta _{R}(r)=r^{(1)}\otimes r^{(2)}}$$ is the Sweedler notation. The usual Hopf algebra is a braided Hopf algebra when the braiding is permutation. Is this correct? Thank you very much.",,"['abstract-algebra', 'representation-theory', 'hopf-algebras']"
62,Checking that a torsion-free abelian group has finite rank,Checking that a torsion-free abelian group has finite rank,,"Suppose $G$ is a torsion-free abelian group and that $G \otimes_\mathbb{Z}\mathbb{Z}_l$ is free of finite rank as a $\mathbb{Z}_l$ -module, where $\mathbb{Z}_l$ denotes the $l$ -adic integers and $l $ is a fixed prime number. Can we conclude that $G$ is free of finite rank? Additionally, what if the statement is true for all primes $l$ ?","Suppose is a torsion-free abelian group and that is free of finite rank as a -module, where denotes the -adic integers and is a fixed prime number. Can we conclude that is free of finite rank? Additionally, what if the statement is true for all primes ?",G G \otimes_\mathbb{Z}\mathbb{Z}_l \mathbb{Z}_l \mathbb{Z}_l l l  G l,"['abstract-algebra', 'group-theory', 'tensor-products', 'abelian-groups']"
63,"$G$ is an abelian group of order $n$ with the property that $G$ has at most $d$ elements of order $d$, for any $d$ dividing $n$. Then $G$ is cyclic.","is an abelian group of order  with the property that  has at most  elements of order , for any  dividing . Then  is cyclic.",G n G d d d n G,"$G$ is an abelian group of order $n$ with the property that $G$ has at most $d$ elements of order $d$, for any $d$ dividing $n$. Then $G$ is cyclic. I am not getting any clue how to start. Please Help.","$G$ is an abelian group of order $n$ with the property that $G$ has at most $d$ elements of order $d$, for any $d$ dividing $n$. Then $G$ is cyclic. I am not getting any clue how to start. Please Help.",,"['abstract-algebra', 'group-theory', 'cyclic-groups']"
64,How to solve this equation for $x$ with XOR involved?,How to solve this equation for  with XOR involved?,x,"I have the following equation I need to solve for $x$: $$y = (21306107x - 27776373) \oplus (i - 29799480x) $$ Where: $\oplus$ is the XOR operator for 32-bit integers. Both $y$ and $i$ are known 32-bit integers. $x$ is some unknown 32-bit integer [Edit: $y$ and $i$ actually do vary, but are fixed for each unknown value of $x$]","I have the following equation I need to solve for $x$: $$y = (21306107x - 27776373) \oplus (i - 29799480x) $$ Where: $\oplus$ is the XOR operator for 32-bit integers. Both $y$ and $i$ are known 32-bit integers. $x$ is some unknown 32-bit integer [Edit: $y$ and $i$ actually do vary, but are fixed for each unknown value of $x$]",,"['abstract-algebra', 'computational-mathematics']"
65,"$R/(ab)\cong R/(a)\oplus R/(b)$, for $a$ and $b$ non-associate irreducible",", for  and  non-associate irreducible",R/(ab)\cong R/(a)\oplus R/(b) a b,"Let $a,b$ be non-associate irreducible elements in UFD $R$. Then     $$R/(ab)\cong R/(a)\oplus R/(b)$$ What is the isomorphism function I have to define? Does $f(r+(ab))=(r+(a),r+(b))$ works here? If yes, how to show it is surjective? I also need to understand something, Why do we need UFD?","Let $a,b$ be non-associate irreducible elements in UFD $R$. Then     $$R/(ab)\cong R/(a)\oplus R/(b)$$ What is the isomorphism function I have to define? Does $f(r+(ab))=(r+(a),r+(b))$ works here? If yes, how to show it is surjective? I also need to understand something, Why do we need UFD?",,"['abstract-algebra', 'ring-theory']"
66,"$R$ be a Noetherian domain , $t\in R$ be a non-zero , non-unit element , then is it true that $\cap_{n \ge 1} t^nR=\{0\}$?","be a Noetherian domain ,  be a non-zero , non-unit element , then is it true that ?",R t\in R \cap_{n \ge 1} t^nR=\{0\},"Let $R$ be a Noetherian domain, $t\in R$ be a non-zero, non-unit element, then is it true that $$\bigcap_{n \ge 1} t^nR=\{0\} \text{?} $$ It almost feels like the nilradical (which is zero for any domain) and intersection of prime ideals, but I can't quite crack it, possibly because I can't see where Noetherianness comes into play. Please help. Thanks in advance.","Let $R$ be a Noetherian domain, $t\in R$ be a non-zero, non-unit element, then is it true that $$\bigcap_{n \ge 1} t^nR=\{0\} \text{?} $$ It almost feels like the nilradical (which is zero for any domain) and intersection of prime ideals, but I can't quite crack it, possibly because I can't see where Noetherianness comes into play. Please help. Thanks in advance.",,"['abstract-algebra', 'commutative-algebra']"
67,An extension of $\mathbb{Q}$ which contains the $n$-th roots of every element,An extension of  which contains the -th roots of every element,\mathbb{Q} n,"Consider $\mathbb{Q}$, the field of rational numbers. Let $K_1\subseteq \mathbb{C}$ be the (minimal) splitting field of the family $\{x^n-a\colon a\in\mathbb{Q}, n\geq 1\}$. Let $K_2\subseteq \mathbb{C}$ be the splitting field of the family $\{x^n-a\colon a\in K_1, n\geq 1\}$. Contiinuing this we get an ascending chain $\mathbb{Q}\subseteq K_1\subseteq K_2\subseteq \cdots $ of subfields of $\mathbb{C}$. Notice that $K_1, K_2,\cdots$ are algebraic extension of $\mathbb{Q}$, hence they are infact subfields of $\overline{\mathbb{Q}}$, the algebraic closure of $\mathbb{Q}$ in $\mathbb{C}$. Thus, $K=\cup_i K_i$ is a subfield of $\overline{\mathbb{Q}}$. Question: Is $K=\cup_i K_i$  a proper subfield of $\overline{\mathbb{Q}}$.","Consider $\mathbb{Q}$, the field of rational numbers. Let $K_1\subseteq \mathbb{C}$ be the (minimal) splitting field of the family $\{x^n-a\colon a\in\mathbb{Q}, n\geq 1\}$. Let $K_2\subseteq \mathbb{C}$ be the splitting field of the family $\{x^n-a\colon a\in K_1, n\geq 1\}$. Contiinuing this we get an ascending chain $\mathbb{Q}\subseteq K_1\subseteq K_2\subseteq \cdots $ of subfields of $\mathbb{C}$. Notice that $K_1, K_2,\cdots$ are algebraic extension of $\mathbb{Q}$, hence they are infact subfields of $\overline{\mathbb{Q}}$, the algebraic closure of $\mathbb{Q}$ in $\mathbb{C}$. Thus, $K=\cup_i K_i$ is a subfield of $\overline{\mathbb{Q}}$. Question: Is $K=\cup_i K_i$  a proper subfield of $\overline{\mathbb{Q}}$.",,"['abstract-algebra', 'field-theory', 'extension-field']"
68,Bound for the degree,Bound for the degree,,"Let $K$ be a perfect field and let $f\in K[x]$ be a monic irreducible polynomial of degree $n$. Denote by $\alpha,\beta$ two distinct roots of $f$.  Is the following bound true? $$ [K(\alpha-\beta):K]\geq \frac n2 $$ If not, does someone know a similar bound (if it exists)?","Let $K$ be a perfect field and let $f\in K[x]$ be a monic irreducible polynomial of degree $n$. Denote by $\alpha,\beta$ two distinct roots of $f$.  Is the following bound true? $$ [K(\alpha-\beta):K]\geq \frac n2 $$ If not, does someone know a similar bound (if it exists)?",,"['abstract-algebra', 'galois-theory']"
69,Lower bound on dimension of fibres of a dominant mophism of irreducible affine varieties,Lower bound on dimension of fibres of a dominant mophism of irreducible affine varieties,,"Whilst doing exercise $11.4.B$ of Ravi Vakil's ""Foundations of Algebraic Geometry"", I got stuck with the following problem (although I think that many of the hypotheses are unnecessary and a more general statement can be proved by reducing to something like this case): Let $X=\rm{Spec}(A)$ and $Y=\rm{Spec}(B)$ be irreducible affine $k-$varieties of dimension $m,n$ respectively and $\pi:X\rightarrow Y$ be a dominant morphism. Then for any $q \in Y$, any irreducible component of the fibre $\pi^{-1}(q)$ has dimension at least $m-n$. I know that for irreducible varieties codimension is the difference of dimensions, and that for $p \in X$ with $\pi(p) = q$, $\rm{codim}_Xp\leq \rm{codim}_Yq + \rm{codim}_{\pi^{-1}(q)}p$. If we take $p$ corresponding to the generic point of an irreducible component of $\pi^{-1}(q)$ then, putting these together gives that $m-n \leq \rm{dim}\bar{\{p\}}-\rm{dim}\bar{\{q\}}$ where the closures are taken in $X$ and $Y$ respectively. I'm having trouble showing that the right hand side is a lower bound for the dimension of the closure of $p$ in $\pi^{-1}(q)$, which is the dimension of the irreducible component that we want a lower bound for. Algebraically this amounts to proving: given a prime $\mathfrak{q}$ of $B$ and a prime $\mathfrak{p}$ of $A$ lying over $\mathfrak{q}$, there is a chain of primes going up from $\mathfrak{p}$ that all lie over $\mathfrak{q}$, of length at least $\rm{dim}(A/\mathfrak{p})-\rm{dim}(B/\mathfrak{q})$. This is easy to prove if $\mathfrak{q}$ is maximal (since then any maximal length chain of primes over $\mathfrak{p}$ will work), otherwise this difference just gives a lower bound for the number of times two consecutive primes in any maximal chain over $\mathfrak{p}$ pull back to the same prime in $B$. Edit: A more general inequality than the one I gave in the second paragraph gives that for any $p$ mapping to $q$, $m-n \leq \rm{dim}\bar{p}-\rm{dim}\bar{q}+\rm{codim}_{\pi^{-1}(q)}p$. In particular, as suggested by Hoot in the comments, given a particular irreducible component of the fibre, one can take $p$ to correspond to a closed point lying in that component and no other, so that it's codimension is the dimension of that component. It then remains to show that $\rm{dim}\bar{\{p\}}-\rm{dim}\bar{\{q\}} \leq 0$.","Whilst doing exercise $11.4.B$ of Ravi Vakil's ""Foundations of Algebraic Geometry"", I got stuck with the following problem (although I think that many of the hypotheses are unnecessary and a more general statement can be proved by reducing to something like this case): Let $X=\rm{Spec}(A)$ and $Y=\rm{Spec}(B)$ be irreducible affine $k-$varieties of dimension $m,n$ respectively and $\pi:X\rightarrow Y$ be a dominant morphism. Then for any $q \in Y$, any irreducible component of the fibre $\pi^{-1}(q)$ has dimension at least $m-n$. I know that for irreducible varieties codimension is the difference of dimensions, and that for $p \in X$ with $\pi(p) = q$, $\rm{codim}_Xp\leq \rm{codim}_Yq + \rm{codim}_{\pi^{-1}(q)}p$. If we take $p$ corresponding to the generic point of an irreducible component of $\pi^{-1}(q)$ then, putting these together gives that $m-n \leq \rm{dim}\bar{\{p\}}-\rm{dim}\bar{\{q\}}$ where the closures are taken in $X$ and $Y$ respectively. I'm having trouble showing that the right hand side is a lower bound for the dimension of the closure of $p$ in $\pi^{-1}(q)$, which is the dimension of the irreducible component that we want a lower bound for. Algebraically this amounts to proving: given a prime $\mathfrak{q}$ of $B$ and a prime $\mathfrak{p}$ of $A$ lying over $\mathfrak{q}$, there is a chain of primes going up from $\mathfrak{p}$ that all lie over $\mathfrak{q}$, of length at least $\rm{dim}(A/\mathfrak{p})-\rm{dim}(B/\mathfrak{q})$. This is easy to prove if $\mathfrak{q}$ is maximal (since then any maximal length chain of primes over $\mathfrak{p}$ will work), otherwise this difference just gives a lower bound for the number of times two consecutive primes in any maximal chain over $\mathfrak{p}$ pull back to the same prime in $B$. Edit: A more general inequality than the one I gave in the second paragraph gives that for any $p$ mapping to $q$, $m-n \leq \rm{dim}\bar{p}-\rm{dim}\bar{q}+\rm{codim}_{\pi^{-1}(q)}p$. In particular, as suggested by Hoot in the comments, given a particular irreducible component of the fibre, one can take $p$ to correspond to a closed point lying in that component and no other, so that it's codimension is the dimension of that component. It then remains to show that $\rm{dim}\bar{\{p\}}-\rm{dim}\bar{\{q\}} \leq 0$.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'krull-dimension', 'dimension-theory-algebra']"
70,Rings in which $ab=0$ implies $axb=0$,Rings in which  implies,ab=0 axb=0,"I'm sure there must be some standard term for (not necessarily commutative) rings $R$ in which $ab=0$ implies $(\forall x)\, axb=0$ (for example, this is the case if $R$ is commutative or is a domain).  What is this term? Additionally, or alternatively, what about (two-sided) ideals $I$ such that $ab\in I$ implies $(\forall x)\, axb\in I$, i.e., ideals quotienting by which gives a ring as I just said?  Do they have a name? Edit: I should probably also mention the stronger condition that $ab=0$ implies $ba=0$: such rings are called ""reversible"" (Cohn, ""Reversible Rings"", Bull. London Math. Soc. 31 (1999), 641–648).  Clearly, commutative rings and domains are reversible, and reversible rings satisfy the property I'm looking for a name for (because in a reversible ring, if $ab=0$ then $ba=0$ so $bax=0$ so $axb=0$).","I'm sure there must be some standard term for (not necessarily commutative) rings $R$ in which $ab=0$ implies $(\forall x)\, axb=0$ (for example, this is the case if $R$ is commutative or is a domain).  What is this term? Additionally, or alternatively, what about (two-sided) ideals $I$ such that $ab\in I$ implies $(\forall x)\, axb\in I$, i.e., ideals quotienting by which gives a ring as I just said?  Do they have a name? Edit: I should probably also mention the stronger condition that $ab=0$ implies $ba=0$: such rings are called ""reversible"" (Cohn, ""Reversible Rings"", Bull. London Math. Soc. 31 (1999), 641–648).  Clearly, commutative rings and domains are reversible, and reversible rings satisfy the property I'm looking for a name for (because in a reversible ring, if $ab=0$ then $ba=0$ so $bax=0$ so $axb=0$).",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
71,Dihedral group $D_n$ is nilpotent iff $n=2^i$,Dihedral group  is nilpotent iff,D_n n=2^i,"I want to show that the dihedral group $D_n$ is nilpotent if and only if $n=2^i$ for some $i$. I have shown the direction $\Leftarrow$. Could you give me some hints for the direction $\Rightarrow$ ? We suppose that $D_n$ is nilpotent and $n=2^im$, where $2\not\mid m$, or not? How can we find a contradiction?","I want to show that the dihedral group $D_n$ is nilpotent if and only if $n=2^i$ for some $i$. I have shown the direction $\Leftarrow$. Could you give me some hints for the direction $\Rightarrow$ ? We suppose that $D_n$ is nilpotent and $n=2^im$, where $2\not\mid m$, or not? How can we find a contradiction?",,"['abstract-algebra', 'group-theory', 'dihedral-groups', 'nilpotence']"
72,Modules over ring of polynomials in several indeterminates.,Modules over ring of polynomials in several indeterminates.,,"I read this proposition and its proof in the Dummit's book (It's not exactly like this, but this is the idea of the proposition). Let $F$ be a field, $V$ a vector space over $F[x]$ and $T\in \mathcal{L}(V)$. Then $V$ can be seen as a $F[x]-$module defining    $$\left(\sum_{i=0}^na_ix^i\right)\cdot v=\sum_{i=0}^na_i T^i(v)$$   (Let's call this extension for now $V(F[x],T)$)   Furthermore, every module $M$ over $F[x]$ is a vector space over $F$, the transformation $T(v)=x\cdot v$ is a linear mapping of $M$ and, as a module, $M=M(F[x],T)$ This characterizes all the modules over $F[x]$ as vector spaces over $F$ with a linear mapping on them. Is there any analogous result for modules over $F[x_1,\cdots,x_r]$?","I read this proposition and its proof in the Dummit's book (It's not exactly like this, but this is the idea of the proposition). Let $F$ be a field, $V$ a vector space over $F[x]$ and $T\in \mathcal{L}(V)$. Then $V$ can be seen as a $F[x]-$module defining    $$\left(\sum_{i=0}^na_ix^i\right)\cdot v=\sum_{i=0}^na_i T^i(v)$$   (Let's call this extension for now $V(F[x],T)$)   Furthermore, every module $M$ over $F[x]$ is a vector space over $F$, the transformation $T(v)=x\cdot v$ is a linear mapping of $M$ and, as a module, $M=M(F[x],T)$ This characterizes all the modules over $F[x]$ as vector spaces over $F$ with a linear mapping on them. Is there any analogous result for modules over $F[x_1,\cdots,x_r]$?",,"['abstract-algebra', 'modules']"
73,"Integer multiplication vs. ""multiple"" notation in abstract algebra","Integer multiplication vs. ""multiple"" notation in abstract algebra",,"In my abstract algebra text, the author uses ""multiple"" notation. Say you have a field $F$ that contains $a,b$. Consider some equation like $a^2 + 2ab + b^2 = 0$. The $2ab$ is meant to be shorthand for $ab + ab$ rather than the literal integer $2$ multiplied to $ab$. In doing higher level computations in field theory, I encounter this notation and I'm always wondering whether or when I'm allowed to, say, divide both sides of $a^2+b^2 = -2ab$ by $2$. Can someone clarify the situations in which this multiple notation and integer multiplication coincide?","In my abstract algebra text, the author uses ""multiple"" notation. Say you have a field $F$ that contains $a,b$. Consider some equation like $a^2 + 2ab + b^2 = 0$. The $2ab$ is meant to be shorthand for $ab + ab$ rather than the literal integer $2$ multiplied to $ab$. In doing higher level computations in field theory, I encounter this notation and I'm always wondering whether or when I'm allowed to, say, divide both sides of $a^2+b^2 = -2ab$ by $2$. Can someone clarify the situations in which this multiple notation and integer multiplication coincide?",,"['abstract-algebra', 'notation']"
74,Classify groups of order $36$,Classify groups of order,36,"Question is to classify all groups of order $36$ . I do not even know if it is of my level. Let me try this. The Sylow theorems say that there are Sylow $2$ subgroups of order $4$ and Sylow $3$ subgroups of order $9$ . The possible numbers of Sylow $2$ subgroups are $1,3,9$ The possible numbers of Sylow $3$ subgroups are $1,4$ Suppose $G$ has $4$ Sylow $3$ subgroups, each subgroup has $8$ non identity elements, total $32$ non identity elements from $4$ Sylow subgroups. Remaining $4$ elements would become one Sylow $2$ subgroups. This says that if $G$ has $4$ Sylow $3$ subgroups then $G$ has $1$ Sylow $2$ subgroup and thus, this Sylow $2$ subgroup is normal and so $G$ is not simple. Suppose $G$ has $1$ Sylow $3$ subgroup then it is a normal subgroup and so $G$ is simple. In this case we can not decide on the number of Sylow $2$ subgroups.. It can be any one of $1,3,9$ .. I can classify abelian groups $\mathbb{Z}_4\times \mathbb{Z}_9$ $\mathbb{Z}_4\times \mathbb{Z}_3\times \mathbb{Z}_3$ $\mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}_9$ $\mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}_3\times \mathbb{Z}_3\cong \mathbb{Z}_6\times\mathbb{Z}_6$ One more piece of information is that if there are $4$ Sylow $3$ -subgroups then there is exactly one Sylow $2$ subgroup so normal.. If there is only one Sylow $3$ subgroups it is normal... So, any such group has either a normal Sylow $2$ subgroup or a Sylow $3$ subgroup.. I could not go beyond this.","Question is to classify all groups of order . I do not even know if it is of my level. Let me try this. The Sylow theorems say that there are Sylow subgroups of order and Sylow subgroups of order . The possible numbers of Sylow subgroups are The possible numbers of Sylow subgroups are Suppose has Sylow subgroups, each subgroup has non identity elements, total non identity elements from Sylow subgroups. Remaining elements would become one Sylow subgroups. This says that if has Sylow subgroups then has Sylow subgroup and thus, this Sylow subgroup is normal and so is not simple. Suppose has Sylow subgroup then it is a normal subgroup and so is simple. In this case we can not decide on the number of Sylow subgroups.. It can be any one of .. I can classify abelian groups One more piece of information is that if there are Sylow -subgroups then there is exactly one Sylow subgroup so normal.. If there is only one Sylow subgroups it is normal... So, any such group has either a normal Sylow subgroup or a Sylow subgroup.. I could not go beyond this.","36 2 4 3 9 2 1,3,9 3 1,4 G 4 3 8 32 4 4 2 G 4 3 G 1 2 2 G G 1 3 G 2 1,3,9 \mathbb{Z}_4\times \mathbb{Z}_9 \mathbb{Z}_4\times \mathbb{Z}_3\times \mathbb{Z}_3 \mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}_9 \mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}_3\times \mathbb{Z}_3\cong \mathbb{Z}_6\times\mathbb{Z}_6 4 3 2 3 2 3","['abstract-algebra', 'group-theory']"
75,Direct limit of completions of finitely generated submodules,Direct limit of completions of finitely generated submodules,,"Let $A$ be a noetherian, local, integral domain with maximal ideal $\mathfrak m$. Moreover let $M$ be an $A$-module; I'd like to know if there exists an explicit expression of the module: $$\varinjlim_{N\subseteq M} \widehat N$$ where $N$ varies among the finitely generated $A$-submodules of $M$ and $\widehat N$ is the $\mathfrak m$-adic completion of $N$. In particular what happens if $M$ is already finitely generated? I'm asking this question because it is well known that $$M\cong \varinjlim_{N\subseteq M}  N$$ so I'm interested in the behavior of the completions with respect to the direct limit. Many thanks in advance","Let $A$ be a noetherian, local, integral domain with maximal ideal $\mathfrak m$. Moreover let $M$ be an $A$-module; I'd like to know if there exists an explicit expression of the module: $$\varinjlim_{N\subseteq M} \widehat N$$ where $N$ varies among the finitely generated $A$-submodules of $M$ and $\widehat N$ is the $\mathfrak m$-adic completion of $N$. In particular what happens if $M$ is already finitely generated? I'm asking this question because it is well known that $$M\cong \varinjlim_{N\subseteq M}  N$$ so I'm interested in the behavior of the completions with respect to the direct limit. Many thanks in advance",,"['abstract-algebra', 'commutative-algebra', 'modules', 'formal-completions']"
76,Abstract Algebra - Finite Group [closed],Abstract Algebra - Finite Group [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let G be a non-trivial finite group. For every $a,b \in G$ that are not identities, there exist $c \in G$ such that $b=c^{-1}ac$. Show that $|G|=2$.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let G be a non-trivial finite group. For every $a,b \in G$ that are not identities, there exist $c \in G$ such that $b=c^{-1}ac$. Show that $|G|=2$.",,"['abstract-algebra', 'finite-groups']"
77,"Express the permutation $\sigma = \left({}^1_5\,{}^2_8 \,{}^3_3\,{}^4_6\,{}^5_7\,{}^6_4\,{}^7_1\,{}^8_2\right)$ as a product of transpositions",Express the permutation  as a product of transpositions,"\sigma = \left({}^1_5\,{}^2_8 \,{}^3_3\,{}^4_6\,{}^5_7\,{}^6_4\,{}^7_1\,{}^8_2\right)","$\newcommand{\lcm}{\operatorname{lcm}}$ I was hoping to get some feedback. Consider the permutation   $$\sigma = \begin{pmatrix} 1&2&3&4&5&6&7&8\\ 5&8&3&6&7&4&1&2 \end{pmatrix}.$$   (a) Describe the orbits of $\sigma$. (b) Express $\sigma$ as a product of disjoint cycles, and then as a product of transpositions. (c) What is the order of $\sigma$? Explain. (a) The orbits of $\sigma$ are $\{1,5,7\}, \{2,8\},\{3\},\{4,6\}$. (b) As a product of disjoint cycles: $\sigma = (1\;5\;7)(2\;8)(3)(4\;6)$ As a product of transpositions: $\sigma = (1\;7)(1\;5)(2\;8)\boxed{(3)\,}(4\,6)$ I am not sure if I should include $(3)$ since transpositions are cycles of length $2$. (c) I don't know what the order of a permutation is. My first guess was that it is the number of orbits of $\sigma$. So I would say $4$. But then I saw a post that used the $\lcm$. I infer that it is the $\lcm$ of the lengths of the orbits of $\sigma$; hence $\lcm(2,3) = 6$. Is this correct? If so, why is it the $\lcm$?","$\newcommand{\lcm}{\operatorname{lcm}}$ I was hoping to get some feedback. Consider the permutation   $$\sigma = \begin{pmatrix} 1&2&3&4&5&6&7&8\\ 5&8&3&6&7&4&1&2 \end{pmatrix}.$$   (a) Describe the orbits of $\sigma$. (b) Express $\sigma$ as a product of disjoint cycles, and then as a product of transpositions. (c) What is the order of $\sigma$? Explain. (a) The orbits of $\sigma$ are $\{1,5,7\}, \{2,8\},\{3\},\{4,6\}$. (b) As a product of disjoint cycles: $\sigma = (1\;5\;7)(2\;8)(3)(4\;6)$ As a product of transpositions: $\sigma = (1\;7)(1\;5)(2\;8)\boxed{(3)\,}(4\,6)$ I am not sure if I should include $(3)$ since transpositions are cycles of length $2$. (c) I don't know what the order of a permutation is. My first guess was that it is the number of orbits of $\sigma$. So I would say $4$. But then I saw a post that used the $\lcm$. I infer that it is the $\lcm$ of the lengths of the orbits of $\sigma$; hence $\lcm(2,3) = 6$. Is this correct? If so, why is it the $\lcm$?",,"['abstract-algebra', 'permutations']"
78,The kernel of a representation is a normal subgroup,The kernel of a representation is a normal subgroup,,"Let $X$ be a matrix representation. Let the kernel of $X$ be defined as $N = {\{g \in G: X(g) = I}\}$ . A representation is faithful if it's one to one. Show that $N$ is a normal subgroup of $G$ and find a condition on $N$ equivalent to the representation being faithful. Proof: Let $X : G → GL(V)$ be a group representation. Let $g_1 \in N$ and $g \in G$ . Then $$X(g^{-1}g_1g) = X(g^{-1})X(g_1)X(g) = X(g)^{-1}(I)X(g) = X(g)^{-1}X(g) = I.$$ Thus $g^{-1}g_1g \in N$ , so $N$ is a  normal subgroup of $G$ . Further, $X$ is faithful if and only if $N$ is the identity subgroup of $G$ . Can someone please verify, or give feedback on, this proof.","Let be a matrix representation. Let the kernel of be defined as . A representation is faithful if it's one to one. Show that is a normal subgroup of and find a condition on equivalent to the representation being faithful. Proof: Let be a group representation. Let and . Then Thus , so is a  normal subgroup of . Further, is faithful if and only if is the identity subgroup of . Can someone please verify, or give feedback on, this proof.",X X N = {\{g \in G: X(g) = I}\} N G N X : G → GL(V) g_1 \in N g \in G X(g^{-1}g_1g) = X(g^{-1})X(g_1)X(g) = X(g)^{-1}(I)X(g) = X(g)^{-1}X(g) = I. g^{-1}g_1g \in N N G X N G,"['abstract-algebra', 'representation-theory', 'solution-verification', 'normal-subgroups']"
79,Algebraic closure of a perfect field.,Algebraic closure of a perfect field.,,"I don't know if this result is true or not, if we are in the first case, how can I prove it ? $$k \subset \overline{k} \text{ is Galois Extension } \Leftrightarrow k \text{ is a perfect  field} $$","I don't know if this result is true or not, if we are in the first case, how can I prove it ? $$k \subset \overline{k} \text{ is Galois Extension } \Leftrightarrow k \text{ is a perfect  field} $$",,"['abstract-algebra', 'galois-theory']"
80,"The ""ring of characters"" of a finite group and its automorphisms","The ""ring of characters"" of a finite group and its automorphisms",,"Let $G$ be a finite group and let $C(G)$ denote the set of characters of $G$ (in my representation theory course the values these characters take are in $\mathbb{C}$, but this is one point I'd like to ask about later). Then $C(G)$ has quite a lot of algebraic structure; if $\rho$ and $\sigma$ are two representations of $G$ with corresponding characters $\chi_\rho$ and $\chi_\sigma$ then $\chi_\rho +\chi_\sigma$ is again a character of $G$ corresponding to the representation $\rho \oplus \sigma$. Further, $\chi_\rho \cdot \chi_\sigma$ is a character of $G$ corresponding to the representation $\operatorname{Hom}(V^*, W)$, where $V$ and $W$ are the carrier spaces of $\rho$ and $\sigma$ respectively. So we are allowed to add and multiply characters together within $C(G)$, giving two operations on $C(G)$ which I'd assume interact nicely and satisfy the ring axioms except for the fact that the additive structure is not complete - additive inverses don't exist! So I suppose the natural thing to do is define $\mathbb{Z}C(G)$ as the free abelian group on $C(G)$; then $\mathbb{Z} C(G)$ is a ring. Now I'm aware of one automorphism of this ring; namely, complex conjugation of characters: if $\chi$ is a character of some representation $\rho$ with carrier space $V$ then $\bar{\chi}$ is the character of the representation $\rho^*: G\rightarrow GL(V^*)$ defined by $\rho^* (\phi) (v) = \phi(\rho(g^{-1})(v))$. So my questions are: What is sort of object is $\mathbb{Z} C(G)$? Are there special cases where it is a field? I've written down one automorphism of $\mathbb{Z} C(G)$, namely complex conjugation of characters. Are there other automorphisms coming from different modifications to representations, perhaps in the case that we consider our characters to take values in some general field $K$ rather than just $\mathbb{C}$? Is there a ""Galois theory"" of these automorphisms?","Let $G$ be a finite group and let $C(G)$ denote the set of characters of $G$ (in my representation theory course the values these characters take are in $\mathbb{C}$, but this is one point I'd like to ask about later). Then $C(G)$ has quite a lot of algebraic structure; if $\rho$ and $\sigma$ are two representations of $G$ with corresponding characters $\chi_\rho$ and $\chi_\sigma$ then $\chi_\rho +\chi_\sigma$ is again a character of $G$ corresponding to the representation $\rho \oplus \sigma$. Further, $\chi_\rho \cdot \chi_\sigma$ is a character of $G$ corresponding to the representation $\operatorname{Hom}(V^*, W)$, where $V$ and $W$ are the carrier spaces of $\rho$ and $\sigma$ respectively. So we are allowed to add and multiply characters together within $C(G)$, giving two operations on $C(G)$ which I'd assume interact nicely and satisfy the ring axioms except for the fact that the additive structure is not complete - additive inverses don't exist! So I suppose the natural thing to do is define $\mathbb{Z}C(G)$ as the free abelian group on $C(G)$; then $\mathbb{Z} C(G)$ is a ring. Now I'm aware of one automorphism of this ring; namely, complex conjugation of characters: if $\chi$ is a character of some representation $\rho$ with carrier space $V$ then $\bar{\chi}$ is the character of the representation $\rho^*: G\rightarrow GL(V^*)$ defined by $\rho^* (\phi) (v) = \phi(\rho(g^{-1})(v))$. So my questions are: What is sort of object is $\mathbb{Z} C(G)$? Are there special cases where it is a field? I've written down one automorphism of $\mathbb{Z} C(G)$, namely complex conjugation of characters. Are there other automorphisms coming from different modifications to representations, perhaps in the case that we consider our characters to take values in some general field $K$ rather than just $\mathbb{C}$? Is there a ""Galois theory"" of these automorphisms?",,"['abstract-algebra', 'ring-theory', 'finite-groups', 'representation-theory']"
81,Characterize units in formal power series $R[[x]]$ [duplicate],Characterize units in formal power series  [duplicate],R[[x]],"This question already has answers here : If $a_0\in R$ is a unit, then  $\sum_{k=0}^{\infty}a_k x^k$ is a unit in $R[[x]]$ (3 answers) Closed 8 years ago . Suppose $R$ is a commutative ring with unity. Define $R[[x]]$ as ""formal power series in the variable $x$ with coefficients from $R$"". These are the infinite sums of the form  $     \sum_{n=0}^\infty a_ix^i,  a_i\in R. $ Is there any way to characterize all of the units in this ring $R[[x]]$?","This question already has answers here : If $a_0\in R$ is a unit, then  $\sum_{k=0}^{\infty}a_k x^k$ is a unit in $R[[x]]$ (3 answers) Closed 8 years ago . Suppose $R$ is a commutative ring with unity. Define $R[[x]]$ as ""formal power series in the variable $x$ with coefficients from $R$"". These are the infinite sums of the form  $     \sum_{n=0}^\infty a_ix^i,  a_i\in R. $ Is there any way to characterize all of the units in this ring $R[[x]]$?",,"['abstract-algebra', 'ring-theory']"
82,Exact sequence splitting naturally,Exact sequence splitting naturally,,"So I encountered a term that I don't quite recognize from lecture. The professor stated that a certain short exact sequence splits naturally, but I don't understand what the naturally condition is in this case. Does it means that the squares with the splitting maps in place commutes or what? Note that exact sequence is the exact sequence from the universal coefficient theorem. I know that there is another stackexchange topic on this, but the answer isn't what I was looking for. So I was wondering if my characterization was correct or not.","So I encountered a term that I don't quite recognize from lecture. The professor stated that a certain short exact sequence splits naturally, but I don't understand what the naturally condition is in this case. Does it means that the squares with the splitting maps in place commutes or what? Note that exact sequence is the exact sequence from the universal coefficient theorem. I know that there is another stackexchange topic on this, but the answer isn't what I was looking for. So I was wondering if my characterization was correct or not.",,"['abstract-algebra', 'algebraic-topology', 'category-theory']"
83,Do two permutations in $S_n$ generate a transitive subgroup of $S_n$?,Do two permutations in  generate a transitive subgroup of ?,S_n S_n,"On page 139 of Flajolet and Sedgewick's Analytic Combinatorics we read: ""To two permutations $\sigma,\tau$ of the same size, associate a graph $G_{\sigma,\tau}$ whose set vertices is $V=[1\ldots n],$ if $n = |σ| = |τ |,$ and set of edges is formed of all the pairs $(x,\sigma(x)), (x,\tau(x)),$ for $x\in V.$"" The claim is then made that the probability that such a random graph is connected is $$\frac1{n!}[x^n]\log\left(\sum_{n\geq0} n!x^n\right).$$ This cannot be correct. (I think the factor of $1/n!$ should be $1/n!^2$) ? I understand that the number of such graphs that are connected is the number of ordered pairs in $S_n$ that would generate a transitive group. In Sloane's OEIS A122949 we see a count of the number of ordered pairs of $n$-permutations that generate a transitive subgroup.  The exponential generating function (egf) is $\log(\sum_{n\geq0} n!x^n).$ I want to derive (via the symbolic method) an egf for the number of size $2$ (and then generally size $k$) subsets of $S_n$ that generate a transitive group.  Cf. A266910.  By brute force I managed to get Mathematica to count the number of such subsets of size $3$ in $S_n$ for $n = 3,4,5.$  They are $20,$ $1932,$ and $269040$ respectively. My specific questions are: Do you agree that the statement made in the book is an error? Can I utilize the egf for the connected graph objects (ordered pairs in $S_n$ that generate a transitive group) to derive an egf for size $k$ subsets of $S_n$ that generate a transitive group? Can GAP verify the three terms that I have computed above with Mathematica?","On page 139 of Flajolet and Sedgewick's Analytic Combinatorics we read: ""To two permutations $\sigma,\tau$ of the same size, associate a graph $G_{\sigma,\tau}$ whose set vertices is $V=[1\ldots n],$ if $n = |σ| = |τ |,$ and set of edges is formed of all the pairs $(x,\sigma(x)), (x,\tau(x)),$ for $x\in V.$"" The claim is then made that the probability that such a random graph is connected is $$\frac1{n!}[x^n]\log\left(\sum_{n\geq0} n!x^n\right).$$ This cannot be correct. (I think the factor of $1/n!$ should be $1/n!^2$) ? I understand that the number of such graphs that are connected is the number of ordered pairs in $S_n$ that would generate a transitive group. In Sloane's OEIS A122949 we see a count of the number of ordered pairs of $n$-permutations that generate a transitive subgroup.  The exponential generating function (egf) is $\log(\sum_{n\geq0} n!x^n).$ I want to derive (via the symbolic method) an egf for the number of size $2$ (and then generally size $k$) subsets of $S_n$ that generate a transitive group.  Cf. A266910.  By brute force I managed to get Mathematica to count the number of such subsets of size $3$ in $S_n$ for $n = 3,4,5.$  They are $20,$ $1932,$ and $269040$ respectively. My specific questions are: Do you agree that the statement made in the book is an error? Can I utilize the egf for the connected graph objects (ordered pairs in $S_n$ that generate a transitive group) to derive an egf for size $k$ subsets of $S_n$ that generate a transitive group? Can GAP verify the three terms that I have computed above with Mathematica?",,"['abstract-algebra', 'combinatorics', 'graph-theory', 'generating-functions', 'gap']"
84,"""Localizing"" commutative pointed monoids","""Localizing"" commutative pointed monoids",,"A pointed monoid is a commutative monoid $A$ with a distinguished element $0\in A$ such that $0\cdot A=0$.  Morphisms should preserve $0$. If $A$ is a commutative ring or pointed monoid, and $f\in A$, there is a localization $A\to A_f$ that is initial with respect to the following property: every map $\phi:A_f\to B$ into a nontrivial ring/pointed monoid $B$ has $\phi(f)\neq 0$. For both rings and monoids, we get this localization by formally adjoining $f^{-1}$. What if we have two elements, $f,g\in A$, and we want to study maps $\varphi: A\to B$ into a nontrivial objects $B$ such that $\varphi(f)\neq\varphi(g)$?  Is there a localization $A_{(f,g)}$ with a similar universal property? For rings, the answer is clear: we can define $A_{(f,g)} = A_{f-g}$.  But is there a more complicated construction that works for monoids? For example, if $fh=gh$ in $A$, then $h$ should most likely be nilpotent in $A_{f,g}$.","A pointed monoid is a commutative monoid $A$ with a distinguished element $0\in A$ such that $0\cdot A=0$.  Morphisms should preserve $0$. If $A$ is a commutative ring or pointed monoid, and $f\in A$, there is a localization $A\to A_f$ that is initial with respect to the following property: every map $\phi:A_f\to B$ into a nontrivial ring/pointed monoid $B$ has $\phi(f)\neq 0$. For both rings and monoids, we get this localization by formally adjoining $f^{-1}$. What if we have two elements, $f,g\in A$, and we want to study maps $\varphi: A\to B$ into a nontrivial objects $B$ such that $\varphi(f)\neq\varphi(g)$?  Is there a localization $A_{(f,g)}$ with a similar universal property? For rings, the answer is clear: we can define $A_{(f,g)} = A_{f-g}$.  But is there a more complicated construction that works for monoids? For example, if $fh=gh$ in $A$, then $h$ should most likely be nilpotent in $A_{f,g}$.",,"['abstract-algebra', 'commutative-algebra', 'monoid', 'localization']"
85,Find all the p-Sylow subgroups of $S_4$,Find all the p-Sylow subgroups of,S_4,"Im having a slight difficulty determining $p$-Sylow subgroups. I am asked to find all $p$-Sylow subgroups of $S_4$. Work: So |$S_4|=4!=24=2 \times 2 \times 2 \times 3$ Thus, I will have $2$-sylow subgroups and $3$-sylow subgroups. I also know that the order of a $p$-sylow subgroup is the highest power of $p$ that divides the order of the group.  So in this case, |$2$-sylow subgroup's|${}= 2^3=8$ (Since $8\mid 24$) and |$3$-sylow subgroup's|${}=3^1=3$ (since 3|24) I also know I will have $\frac{24}{2^3}=3$, $2$-sylow subgroups and $\frac {24}{3}=8$, 3-sylow subgroups (is this correct so far?) I am having difficulty actually finding out what these groups are.. Also, I am asked to find each $p$-sylow subgroups Normalizer. I know that the normalizer is $N_{S_4}=\{x \in S_4 \mid xS=Sx\}$ where $S$ is a $p$-sylow subgroup. Is there any quick way of determining the normalizer, or is it just trial and error? Do I need to compute all the combinations permutations to see which elements are in the normalizer of a $p$-sylow subgroup? Thanks!","Im having a slight difficulty determining $p$-Sylow subgroups. I am asked to find all $p$-Sylow subgroups of $S_4$. Work: So |$S_4|=4!=24=2 \times 2 \times 2 \times 3$ Thus, I will have $2$-sylow subgroups and $3$-sylow subgroups. I also know that the order of a $p$-sylow subgroup is the highest power of $p$ that divides the order of the group.  So in this case, |$2$-sylow subgroup's|${}= 2^3=8$ (Since $8\mid 24$) and |$3$-sylow subgroup's|${}=3^1=3$ (since 3|24) I also know I will have $\frac{24}{2^3}=3$, $2$-sylow subgroups and $\frac {24}{3}=8$, 3-sylow subgroups (is this correct so far?) I am having difficulty actually finding out what these groups are.. Also, I am asked to find each $p$-sylow subgroups Normalizer. I know that the normalizer is $N_{S_4}=\{x \in S_4 \mid xS=Sx\}$ where $S$ is a $p$-sylow subgroup. Is there any quick way of determining the normalizer, or is it just trial and error? Do I need to compute all the combinations permutations to see which elements are in the normalizer of a $p$-sylow subgroup? Thanks!",,['abstract-algebra']
86,What is a constant field?,What is a constant field?,,"I am looking at the following: Could you explain to me what a constant field is? $$$$ P.S. I found this in the paper of T. Honda, ""Algebraic differential equation"" (pages 170-176).","I am looking at the following: Could you explain to me what a constant field is? $$$$ P.S. I found this in the paper of T. Honda, ""Algebraic differential equation"" (pages 170-176).",,"['abstract-algebra', 'field-theory', 'extension-field', 'differential-algebra']"
87,"Why is it that for $n<60$, the simple groups are precisely the cyclic groups $\mathbb{Z}_N$ for prime $n$?","Why is it that for , the simple groups are precisely the cyclic groups  for prime ?",n<60 \mathbb{Z}_N n,"I was reading this Wikipedia article and came across this For groups of order $n<60$, the simple groups are precisely the cyclic groups $\mathbb{Z}_n$ for prime $n$. I was wondering, why is this true for $n<60$? What is so special about this value?","I was reading this Wikipedia article and came across this For groups of order $n<60$, the simple groups are precisely the cyclic groups $\mathbb{Z}_n$ for prime $n$. I was wondering, why is this true for $n<60$? What is so special about this value?",,['abstract-algebra']
88,Is tensor of chain complex commutative?,Is tensor of chain complex commutative?,,"Let $B_*$ and $C_*$ be chain complexes (say of $R$-modules). Then is $B_*\otimes_R C_*$ isomorphic as a chain complex to $C_*\otimes B_*$? There are lots of signs involved, and I am not sure if it can be possible to arrange them such that the two chain complexes are isomorphic.","Let $B_*$ and $C_*$ be chain complexes (say of $R$-modules). Then is $B_*\otimes_R C_*$ isomorphic as a chain complex to $C_*\otimes B_*$? There are lots of signs involved, and I am not sure if it can be possible to arrange them such that the two chain complexes are isomorphic.",,"['abstract-algebra', 'commutative-algebra', 'homological-algebra']"
89,Show that $\sigma\circ\phi : G_1 \to G_3$ is an isomorphism,Show that  is an isomorphism,\sigma\circ\phi : G_1 \to G_3,"Let $G_1, G_2$ and $G_3$ be groups.  Let $\phi: G_1 \to G_2$ and $\sigma: G_2 \to G_3$ be isomorphisms of groups.  Show that $$\sigma\circ\phi: G_1 \to G_3$$ is an isomorphism. I understand to prove the composition is a homomorphism (operation preserving) and a bijection.  I need help with notation and how to show the operation preserving, onto and one-to-one. Operation preserving:  $\sigma\circ\phi(ab)=\sigma(\phi(ab))=\sigma(\phi(a)\phi(b))=(\sigma\circ\phi(a))(\sigma\circ\phi(b))$ Am I on the right track?","Let $G_1, G_2$ and $G_3$ be groups.  Let $\phi: G_1 \to G_2$ and $\sigma: G_2 \to G_3$ be isomorphisms of groups.  Show that $$\sigma\circ\phi: G_1 \to G_3$$ is an isomorphism. I understand to prove the composition is a homomorphism (operation preserving) and a bijection.  I need help with notation and how to show the operation preserving, onto and one-to-one. Operation preserving:  $\sigma\circ\phi(ab)=\sigma(\phi(ab))=\sigma(\phi(a)\phi(b))=(\sigma\circ\phi(a))(\sigma\circ\phi(b))$ Am I on the right track?",,['abstract-algebra']
90,Surjection from $G$ into direct product $\prod_i G/H_i$,Surjection from  into direct product,G \prod_i G/H_i,"Let $G$ be a group with $H_1,\ldots,H_n$ normal subgroups. Define $\varphi:G\mapsto \prod_i G/H_i$ by $\varphi(x)=(xH_1,\ldots,xH_n).$ Prove: $\ker(\varphi)=\cap_i^n H_i$, If every $H_i$ has finite index in $G$, and $|G/H_i|$ and $|G/H_j|$ are relatively prime for $i\neq j$ then $\varphi$ is a surjection and $$[G:\cap_i^n H_i]=\prod_i |G/H_i|.$$ How do I prove $\varphi$ is a surjection? Part 1 is quite easy and the last equality follows from applying the first isomorphism theorem to $\varphi$ but I can't figure out how to use the relatively prime hypothesis to prove surjectivity. Any help would be appreciated.","Let $G$ be a group with $H_1,\ldots,H_n$ normal subgroups. Define $\varphi:G\mapsto \prod_i G/H_i$ by $\varphi(x)=(xH_1,\ldots,xH_n).$ Prove: $\ker(\varphi)=\cap_i^n H_i$, If every $H_i$ has finite index in $G$, and $|G/H_i|$ and $|G/H_j|$ are relatively prime for $i\neq j$ then $\varphi$ is a surjection and $$[G:\cap_i^n H_i]=\prod_i |G/H_i|.$$ How do I prove $\varphi$ is a surjection? Part 1 is quite easy and the last equality follows from applying the first isomorphism theorem to $\varphi$ but I can't figure out how to use the relatively prime hypothesis to prove surjectivity. Any help would be appreciated.",,"['abstract-algebra', 'group-theory', 'quotient-spaces', 'group-isomorphism']"
91,Exactness of the tensor product,Exactness of the tensor product,,considering the tensor products of abelian groups: could you tell me if (and why?) the following is true? For any free abelian group $A$ the functor $A\otimes (-)$ is exact. Thanks! [I extracted this Proposition from a step in a proof of some lectures notes that I dont understand.],considering the tensor products of abelian groups: could you tell me if (and why?) the following is true? For any free abelian group $A$ the functor $A\otimes (-)$ is exact. Thanks! [I extracted this Proposition from a step in a proof of some lectures notes that I dont understand.],,['abstract-algebra']
92,"If $y$ is a cycle of length $r$, show that $\sigma y \sigma^{-1}$ is also a cycle of length $r$.","If  is a cycle of length , show that  is also a cycle of length .",y r \sigma y \sigma^{-1} r,"I am trying to show that if $y$ is a cycle of length $r$, and $\sigma \in S_n$ then $\sigma y \sigma^{-1}$ is also a cycle of length $r$. More specifically, that if $y = (k_1\ \dots k_r)$ then $\sigma y \sigma^{-1} = (\sigma(k_1) \dots \sigma(k_r))$ I am not too sure how to show this. I know that $\sigma$ can be written as the product of disjoint cycles or length at least 2 by the cycle decomposition theorem, but am not sure how that helps.","I am trying to show that if $y$ is a cycle of length $r$, and $\sigma \in S_n$ then $\sigma y \sigma^{-1}$ is also a cycle of length $r$. More specifically, that if $y = (k_1\ \dots k_r)$ then $\sigma y \sigma^{-1} = (\sigma(k_1) \dots \sigma(k_r))$ I am not too sure how to show this. I know that $\sigma$ can be written as the product of disjoint cycles or length at least 2 by the cycle decomposition theorem, but am not sure how that helps.",,"['abstract-algebra', 'number-theory', 'permutations']"
93,How is Buchberger algorithm a generalization of the Euclid GCD algorithm?,How is Buchberger algorithm a generalization of the Euclid GCD algorithm?,,"It is said in many places (for example, on the Wikipedia article for Buchberger's algorithm ) that Buchberger's algorithm to find Groebner basis is a generalization of Euclid's GCD algorithm. This is not obvious to me. Just think about two polynomials  $f(x)=a_n x^n + \cdots a_0$, and $g(x)=b_m x^m + \cdots b_0$, with $n>m$. Start by finding the subtraction polynomial $S(f,g)$, here I do not see a clue of Euclid's algoritm and what does it have to do with Euclid's GCD algorithm. Please do not respond that both Euclid and Buchberger produce the same result. I already know that. I am questioning about how one algorithm (Buchberger's) reduce to the other (Euclid's) for univariate polynomials. Any clue? Thanks.","It is said in many places (for example, on the Wikipedia article for Buchberger's algorithm ) that Buchberger's algorithm to find Groebner basis is a generalization of Euclid's GCD algorithm. This is not obvious to me. Just think about two polynomials  $f(x)=a_n x^n + \cdots a_0$, and $g(x)=b_m x^m + \cdots b_0$, with $n>m$. Start by finding the subtraction polynomial $S(f,g)$, here I do not see a clue of Euclid's algoritm and what does it have to do with Euclid's GCD algorithm. Please do not respond that both Euclid and Buchberger produce the same result. I already know that. I am questioning about how one algorithm (Buchberger's) reduce to the other (Euclid's) for univariate polynomials. Any clue? Thanks.",,"['abstract-algebra', 'polynomials', 'groebner-basis']"
94,Isomorphism classes of $\mathbb{Z}[i]$ modules.,Isomorphism classes of  modules.,\mathbb{Z}[i],"$\textbf{Question:}$ How many isomorphism classes of $\mathbb{Z}[i]$-modules with exactly $5$ elements are there? $\textbf{My Attempt:}$ Since $\mathbb{Z}[i]$ is a P.I.D and any module with $5$ elements is finitely generated we can use the structure theorem. In the case of a finite abelian group, the isomorphism classes determined by the prime factorization of the order and then listing all invariant factors. In this case we have that $5 = (2-i)(2+i)$, but I don't know how to use the ideal $(2-i)$ and $(2+i)$ in the structure theorem... Any help working this problem or showing an example of a similar problem is appreciate.d","$\textbf{Question:}$ How many isomorphism classes of $\mathbb{Z}[i]$-modules with exactly $5$ elements are there? $\textbf{My Attempt:}$ Since $\mathbb{Z}[i]$ is a P.I.D and any module with $5$ elements is finitely generated we can use the structure theorem. In the case of a finite abelian group, the isomorphism classes determined by the prime factorization of the order and then listing all invariant factors. In this case we have that $5 = (2-i)(2+i)$, but I don't know how to use the ideal $(2-i)$ and $(2+i)$ in the structure theorem... Any help working this problem or showing an example of a similar problem is appreciate.d",,['abstract-algebra']
95,$\mathbb Z_n$ as $\mathbb Z[i]$-module,as -module,\mathbb Z_n \mathbb Z[i],"I am trying to find all $n$ such that $\mathbb Z_n$ is a $\mathbb Z[i]$-module, where $\mathbb Z[i]$ is the ring of Gaussian integers. I proved that any $\mathbb Z[i]$-module $M$ is just an Abelian group with hommomrphism $\psi:M\rightarrow M$ and $\psi^2=-I_M$ .","I am trying to find all $n$ such that $\mathbb Z_n$ is a $\mathbb Z[i]$-module, where $\mathbb Z[i]$ is the ring of Gaussian integers. I proved that any $\mathbb Z[i]$-module $M$ is just an Abelian group with hommomrphism $\psi:M\rightarrow M$ and $\psi^2=-I_M$ .",,"['abstract-algebra', 'modules']"
96,Show that $f$ is a homomorphism.,Show that  is a homomorphism.,f,"There is a group $G$ of order $p^3$, where $p>2$. Show that $f:G\rightarrow Z(G) $ with $f(x)=x^p$ is a homomorphism. My attempt: Case a): Suppose $|Z(G)|=p^3$. Then $G=Z(G)$, so $G$ is abelian, and $(x_1x_2)^p=x_1^px_2^p$ is obvious. Case b): Suppose $|Z(G)|=p^2$. Then  $|G/Z(G)|=p$ and is cyclic, so $G$ itself is abelian, which implies that $|G|=|Z(G)|=p^3$. Contradiction. Case c): Suppose $|Z(G)|=p$. Then $|G/Z(G)|=p^2$, so $G/Z(G)\cong\mathbb{Z_p}\times\mathbb{Z_p}$(otherwise $G/Z(G)$ is cyclic and $G$ is abelian. So... I don't even think that it is possible to finish my solution. It seems that there is better one, but this is just my unlucky try.","There is a group $G$ of order $p^3$, where $p>2$. Show that $f:G\rightarrow Z(G) $ with $f(x)=x^p$ is a homomorphism. My attempt: Case a): Suppose $|Z(G)|=p^3$. Then $G=Z(G)$, so $G$ is abelian, and $(x_1x_2)^p=x_1^px_2^p$ is obvious. Case b): Suppose $|Z(G)|=p^2$. Then  $|G/Z(G)|=p$ and is cyclic, so $G$ itself is abelian, which implies that $|G|=|Z(G)|=p^3$. Contradiction. Case c): Suppose $|Z(G)|=p$. Then $|G/Z(G)|=p^2$, so $G/Z(G)\cong\mathbb{Z_p}\times\mathbb{Z_p}$(otherwise $G/Z(G)$ is cyclic and $G$ is abelian. So... I don't even think that it is possible to finish my solution. It seems that there is better one, but this is just my unlucky try.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
97,"Is there an embedding of $\langle \mathbb{N} \setminus \{0\}, \leq, \times, 1 \rangle$ into $\langle \mathbb{N}, \leq, +, 0 \rangle$?",Is there an embedding of  into ?,"\langle \mathbb{N} \setminus \{0\}, \leq, \times, 1 \rangle \langle \mathbb{N}, \leq, +, 0 \rangle","This appears to be a common beginning exercise in model theory (I found it both in Chang & Keisler and also in Manzano's Model Theory ). It's not difficult to see that there is an embedding of $\langle \mathbb{N}, \leq, +, 0 \rangle$ into $\langle \mathbb{N}, \leq, \times, 1 \rangle$; just take the function $h(x) = 2^x$ (or something similar). On the other hand, it's also not very difficult (I think!) to see that the converse does not hold, for, if there were such an embedding $h$, then both $h(1) = 0$ and $h(0) = 0$, meaning that $h$ is not injective (and thus is not actually an embedding). But what about an embedding of $\langle \mathbb{N} \setminus \{0\}, \leq, \times, 1 \rangle$ into $\langle \mathbb{N}, \leq, +, 0 \rangle$? It seems to me that there is no such embedding as well, but I can't work out an argument showing this impossibility. Clearly the above argument won't work, because it depended on $h(0)$. I thought of trying to show that there is an existential formula that's verified by the latter but not by the former, or conversely a universal formula verified by the former but not by the latter, but couldn't think of anything. I suppose there are other ways of showing this? Any hints?","This appears to be a common beginning exercise in model theory (I found it both in Chang & Keisler and also in Manzano's Model Theory ). It's not difficult to see that there is an embedding of $\langle \mathbb{N}, \leq, +, 0 \rangle$ into $\langle \mathbb{N}, \leq, \times, 1 \rangle$; just take the function $h(x) = 2^x$ (or something similar). On the other hand, it's also not very difficult (I think!) to see that the converse does not hold, for, if there were such an embedding $h$, then both $h(1) = 0$ and $h(0) = 0$, meaning that $h$ is not injective (and thus is not actually an embedding). But what about an embedding of $\langle \mathbb{N} \setminus \{0\}, \leq, \times, 1 \rangle$ into $\langle \mathbb{N}, \leq, +, 0 \rangle$? It seems to me that there is no such embedding as well, but I can't work out an argument showing this impossibility. Clearly the above argument won't work, because it depended on $h(0)$. I thought of trying to show that there is an existential formula that's verified by the latter but not by the former, or conversely a universal formula verified by the former but not by the latter, but couldn't think of anything. I suppose there are other ways of showing this? Any hints?",,"['abstract-algebra', 'logic', 'model-theory']"
98,counterexamples on modules,counterexamples on modules,,"Prove or disprove: for any comm. ring $R $, For three $R $-modules $M $, $N $ and $P $, $M \oplus P \simeq N \oplus P $ implies $M \simeq N $. Let $f:M\to N $ and $g:N\to M $ be two $R $-module homomorphisms such that $gf=1_M $ (where $1_M = \operatorname{id}_M$ means the identity map on $M$). Then, $N\simeq\operatorname{Im}(f)\oplus\ker(g)$. If $R $ is a PID and the modules are f.g., 1 is true, but I have no idea on general cases.","Prove or disprove: for any comm. ring $R $, For three $R $-modules $M $, $N $ and $P $, $M \oplus P \simeq N \oplus P $ implies $M \simeq N $. Let $f:M\to N $ and $g:N\to M $ be two $R $-module homomorphisms such that $gf=1_M $ (where $1_M = \operatorname{id}_M$ means the identity map on $M$). Then, $N\simeq\operatorname{Im}(f)\oplus\ker(g)$. If $R $ is a PID and the modules are f.g., 1 is true, but I have no idea on general cases.",,"['abstract-algebra', 'commutative-algebra', 'modules']"
99,Groups of the from $gMg$ in a monoid where $g$ is an idempotent,Groups of the from  in a monoid where  is an idempotent,gMg g,"Let $(M, \cdot)$ be a finite monoid with identity $e$. It is easy to see that $gMg = \{ gxg : x \in M \}$ forms a monoid with identity $geg = g$ if $g$ is an idempotent. If $gMg$ contains no idempotent other than $g$, it must be a group, since it is finite. Suppose that $g, h \in M$ are distinct idempotents in $M$ such that both $gMg$ and $hMh$ are groups. Is it true that $gMg$ and $hMh$ are isomorphic?","Let $(M, \cdot)$ be a finite monoid with identity $e$. It is easy to see that $gMg = \{ gxg : x \in M \}$ forms a monoid with identity $geg = g$ if $g$ is an idempotent. If $gMg$ contains no idempotent other than $g$, it must be a group, since it is finite. Suppose that $g, h \in M$ are distinct idempotents in $M$ such that both $gMg$ and $hMh$ are groups. Is it true that $gMg$ and $hMh$ are isomorphic?",,"['abstract-algebra', 'group-theory', 'monoid']"
