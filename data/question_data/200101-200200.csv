,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Conflicting definitions of tensors?,Conflicting definitions of tensors?,,"I am currently taking a course in continuum mechanics using P. Chadwick's Continuum Mechanics: Concise Theory and Problems and I am having trouble reconciling the following definitions of a tensor: In the book, Chadwick defines a tensor in the following way: A tensor is a linear transformation or the Euclidean vector space $E$ into itself. Since I have some experience using tensors, the definition I am familiar with is: Let $V$ be a vector space and $V^*$ be its duel. Then a $(p,q)$ tensor is defined as $T:\underbrace{V^{*}\times...\times V^{*}}_\text{p-copies}\times \underbrace{V\times...\times V}_\text{q-copies} \to \mathbb{R}$ . In other words, a tensor is a multilinear map . Now that both of these definitions are on the table, here is my question: How does Chadwick's definition relate (if at all) to the definition that I am familiar with? To me his definition isn't very precise because according to what he wrote a tensor should be an object of the form $T : E \to E$ (linearly of course). Is there something that I am not seeing or is this another way of defining tensors? note: this class is centered towards engineers (I am a mathematician by training) if that helps put things in context a little better.","I am currently taking a course in continuum mechanics using P. Chadwick's Continuum Mechanics: Concise Theory and Problems and I am having trouble reconciling the following definitions of a tensor: In the book, Chadwick defines a tensor in the following way: A tensor is a linear transformation or the Euclidean vector space into itself. Since I have some experience using tensors, the definition I am familiar with is: Let be a vector space and be its duel. Then a tensor is defined as . In other words, a tensor is a multilinear map . Now that both of these definitions are on the table, here is my question: How does Chadwick's definition relate (if at all) to the definition that I am familiar with? To me his definition isn't very precise because according to what he wrote a tensor should be an object of the form (linearly of course). Is there something that I am not seeing or is this another way of defining tensors? note: this class is centered towards engineers (I am a mathematician by training) if that helps put things in context a little better.","E V V^* (p,q) T:\underbrace{V^{*}\times...\times V^{*}}_\text{p-copies}\times \underbrace{V\times...\times V}_\text{q-copies} \to \mathbb{R} T : E \to E","['linear-algebra', 'differential-geometry', 'tensors']"
1,Norm of Riemannian curvature tensor on an Einstein manifold under the RIcci flow,Norm of Riemannian curvature tensor on an Einstein manifold under the RIcci flow,,"I'm trying to prove that if $(M, g_0)$ is Einstein and $g(t) = (1-2\lambda t)g_0$ is a solution to its Ricci flow, then $\|\operatorname{Rm}(t)\|^2 = C R(t)^2$ , where $R$ is the scalar curvature and $C$ is a constant depending only on $g_0$ . This is a claim I've seen in a book but I'm not sure which norm they're using. Assuming it's the one induced by the metric, we have: $\|\operatorname{Rm}\|^2 = g^{ri}g^{sj}g^{pk}g^{q\ell}R_{rspq}R_{ijk\ell}$ , but how can we relate this to the Ricci tensor? I'd appreciate any help. This is the discussion in the book:","I'm trying to prove that if is Einstein and is a solution to its Ricci flow, then , where is the scalar curvature and is a constant depending only on . This is a claim I've seen in a book but I'm not sure which norm they're using. Assuming it's the one induced by the metric, we have: , but how can we relate this to the Ricci tensor? I'd appreciate any help. This is the discussion in the book:","(M, g_0) g(t) = (1-2\lambda t)g_0 \|\operatorname{Rm}(t)\|^2 = C R(t)^2 R C g_0 \|\operatorname{Rm}\|^2 = g^{ri}g^{sj}g^{pk}g^{q\ell}R_{rspq}R_{ijk\ell}","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
2,Making sense of 'Floppy' Structures on Manifolds,Making sense of 'Floppy' Structures on Manifolds,,"Roger Penrose in his book ""The Road to Reality"" (Section 14.8 - Symplectic Manifolds) loosely defines a ""floppy"" structure to be one which if we apply two variants of it on two copies of the same manifold, the two manifolds are locally isomorphic (and thus locally indistinguishable from one another). The example he brings is that of two symplectic manifolds with the same dimension and signature. I think what he is referring to (although he does not make it explicit) is Darboux's Theorem which again asserts that two symplectic manifolds of the same dimension are locally isomorphic (more accurately: symplectomorphic ). In his exact words and I quote: The local structure of a symplectic manifold is an example of what might be called a ‘Floppy’ structure. There is, for example, no notion of curvature for a symplectic manifold, which might serve to distinguish one symplectic manifold from another, locally. If we have two real symplectic manifolds of the same dimension (and the same ‘signature’, cf. §13.10), then they are locally completely identical (in the sense that for any point p in one manifold and any point q in the other, there are open sets of p and q that are identical). This is in stark contrast with the case of (pseudo-) Riemannian manifolds, or manifolds in which merely a connection is specified. In those cases, the curvature tensor (and, for example, its various covariant derivatives) defines some distinguishing local structure which is likely to be different for different such manifolds. This makes sense to me. Then he goes on to describe two more examples of manifolds one of which is floppy while the other isn't. In particular he makes the following two claims: Let $M_1$ be a real manifold with a nowhere vanishing vector field $F$ on it. Then $M_1$ is a floppy manifold. In contrast, let $M_2$ be a real manifold with two general vector fields. Then $M_2$ is NOT a floppy manifold Question 1: For the 1st part, I think the family of tori would be a good place to start since assigning a (smooth) nowhere vanishing vector field is always possible. I can also see how we can use $F$ to define a global frame on the entire $M_1$ starting by setting $\partial_1 := F \neq 0$ etc. However, in what sense are all tori (with $F$ ) locally indistinguishable? For example, shouldn't we able to (locally) distinguish a torus with circular cross sections versus one with elliptical just by looking at the difference in curvatures between a circle and an ellipse? Question 2: Now to his second claim. First of all, what do you think he means by ""general"" vector fields? Am I right to assume that they are linearly independent and by extension neither one of these can be anywhere vanishing (as this would violate independence)? And how does the existence of the second field makes them distinguishable?","Roger Penrose in his book ""The Road to Reality"" (Section 14.8 - Symplectic Manifolds) loosely defines a ""floppy"" structure to be one which if we apply two variants of it on two copies of the same manifold, the two manifolds are locally isomorphic (and thus locally indistinguishable from one another). The example he brings is that of two symplectic manifolds with the same dimension and signature. I think what he is referring to (although he does not make it explicit) is Darboux's Theorem which again asserts that two symplectic manifolds of the same dimension are locally isomorphic (more accurately: symplectomorphic ). In his exact words and I quote: The local structure of a symplectic manifold is an example of what might be called a ‘Floppy’ structure. There is, for example, no notion of curvature for a symplectic manifold, which might serve to distinguish one symplectic manifold from another, locally. If we have two real symplectic manifolds of the same dimension (and the same ‘signature’, cf. §13.10), then they are locally completely identical (in the sense that for any point p in one manifold and any point q in the other, there are open sets of p and q that are identical). This is in stark contrast with the case of (pseudo-) Riemannian manifolds, or manifolds in which merely a connection is specified. In those cases, the curvature tensor (and, for example, its various covariant derivatives) defines some distinguishing local structure which is likely to be different for different such manifolds. This makes sense to me. Then he goes on to describe two more examples of manifolds one of which is floppy while the other isn't. In particular he makes the following two claims: Let be a real manifold with a nowhere vanishing vector field on it. Then is a floppy manifold. In contrast, let be a real manifold with two general vector fields. Then is NOT a floppy manifold Question 1: For the 1st part, I think the family of tori would be a good place to start since assigning a (smooth) nowhere vanishing vector field is always possible. I can also see how we can use to define a global frame on the entire starting by setting etc. However, in what sense are all tori (with ) locally indistinguishable? For example, shouldn't we able to (locally) distinguish a torus with circular cross sections versus one with elliptical just by looking at the difference in curvatures between a circle and an ellipse? Question 2: Now to his second claim. First of all, what do you think he means by ""general"" vector fields? Am I right to assume that they are linearly independent and by extension neither one of these can be anywhere vanishing (as this would violate independence)? And how does the existence of the second field makes them distinguishable?",M_1 F M_1 M_2 M_2 F M_1 \partial_1 := F \neq 0 F,"['differential-geometry', 'soft-question', 'smooth-manifolds', 'mathematical-physics', 'symplectic-geometry']"
3,unit tangent bundle is connected if and only if $M$ is connected.,unit tangent bundle is connected if and only if  is connected.,M,"Let $M$ be a Riemannian manifold,and $UTM  = \{(p,v) \in TM\mid g(v,v) = 1\}$ be the unit tangent bundle,assume we have proved that is a embedded submanifold in $TM$ .Needs to prove that $UTM$ is connected if and only if $M$ is connected (provided that dim of $M$ is greater than 2 as here shows) One direction is easy that is $p:UTM \to M$ is continuous hence if $UTM$ is connected then $M$ is connected. I try to prove the other direction,and I hope there is some better idea: We only need to prove that $UTM$ is path connected if $M$ is since manifold is locally path connected and locally connected. To do this consider two point $(p,v)$ and $(q,u)$ on $UTM$ ,needs to find a continuous path.To do this it may be helpful to transport $v$ by some curve $\gamma$ to some other place that still preserved the length 1 that is $d\gamma (v) $ has lengith 1. But I have no idea how to construct such a curve,I try to do like this,first there is a finite chain of the neighborhood(which is given as local trivialization domain) that connect $p$ and $q$ (by the chain characterization of ""connectedness"" ) denote them $U_{x_1},...,U_{x_N}$ such that exist some $y_i \in U_{x_i} \cap U_{x_{i+1}} $ Then we construct local pieces of curve from $$p\to y_1\to x_2\to y_2\to....\to x_{N} \to q$$ Where $p^{-1}(U) \cong U\times S^{n-1} $ that is locally looks like $U\times S^{n-1}$ where we can construct the desired curve If $n\ge 2$ since then it's connected. Is there some better solution?","Let be a Riemannian manifold,and be the unit tangent bundle,assume we have proved that is a embedded submanifold in .Needs to prove that is connected if and only if is connected (provided that dim of is greater than 2 as here shows) One direction is easy that is is continuous hence if is connected then is connected. I try to prove the other direction,and I hope there is some better idea: We only need to prove that is path connected if is since manifold is locally path connected and locally connected. To do this consider two point and on ,needs to find a continuous path.To do this it may be helpful to transport by some curve to some other place that still preserved the length 1 that is has lengith 1. But I have no idea how to construct such a curve,I try to do like this,first there is a finite chain of the neighborhood(which is given as local trivialization domain) that connect and (by the chain characterization of ""connectedness"" ) denote them such that exist some Then we construct local pieces of curve from Where that is locally looks like where we can construct the desired curve If since then it's connected. Is there some better solution?","M UTM  = \{(p,v) \in TM\mid g(v,v) = 1\} TM UTM M M p:UTM \to M UTM M UTM M (p,v) (q,u) UTM v \gamma d\gamma (v)  p q U_{x_1},...,U_{x_N} y_i \in U_{x_i} \cap U_{x_{i+1}}  p\to y_1\to x_2\to y_2\to....\to x_{N} \to q p^{-1}(U) \cong U\times S^{n-1}  U\times S^{n-1} n\ge 2","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
4,$U(1)$ principal bundle over $\mathbb{S}^1$,principal bundle over,U(1) \mathbb{S}^1,"In this question , the accepted answer uses the fact that the only $U(1)$ principal bundle over $\mathbb{S}^1$ is the trivial bundle. I'm not quite familiar with the classification of bundles, so I don't quite understand why this is true. Any pointers or sketch of the proof would be appreciated.","In this question , the accepted answer uses the fact that the only principal bundle over is the trivial bundle. I'm not quite familiar with the classification of bundles, so I don't quite understand why this is true. Any pointers or sketch of the proof would be appreciated.",U(1) \mathbb{S}^1,"['differential-geometry', 'principal-bundles']"
5,Compact manifold and eigenvalues,Compact manifold and eigenvalues,,"Let $X$ be a compact manifold and $f : X \to X$ a smooth map. Show that $\{x \in X | f(x) =x,\ 1 \text{ is not an eigenvalue of }df_x : T_xX \to T_xX\}$ is a finite set. If $1$ isn't an eigenvalue then $\det(df_x - I)\neq 0$ which is an open set condition. So I guess we can do a ""open cover has finite subcover"" argument. But I didn't really use $f(x)=x$ condition.","Let be a compact manifold and a smooth map. Show that is a finite set. If isn't an eigenvalue then which is an open set condition. So I guess we can do a ""open cover has finite subcover"" argument. But I didn't really use condition.","X f : X \to X \{x \in X | f(x) =x,\ 1 \text{ is not an eigenvalue of }df_x : T_xX \to T_xX\} 1 \det(df_x - I)\neq 0 f(x)=x","['differential-geometry', 'differential-topology', 'smooth-manifolds']"
6,Example of Riemannian metric on sphere such that it become non strictly convex.,Example of Riemannian metric on sphere such that it become non strictly convex.,,"My understanding of strictly convexity of the compact set in Euclidean space is that if we take any straight line joining any two boundary points then the line must be in a compact set with out intersecting any other boundary point. But for compact Riemannian manifold $(M,g)$ , the definition of strict convexity is that the second fundamental form of boundary must be positive definite. Which depends upon metric. To better understand this concept in the Riemannian setup, I was trying to find an example of metric on Sphere such that in that case, it becomes non strictly convex. But I could not able to find it. Can anyone please help to relate the positive definiteness of the second fundamental form with strictly convexity in the Riemannian manifold? Any Help or hint will be greatly appreciated.","My understanding of strictly convexity of the compact set in Euclidean space is that if we take any straight line joining any two boundary points then the line must be in a compact set with out intersecting any other boundary point. But for compact Riemannian manifold , the definition of strict convexity is that the second fundamental form of boundary must be positive definite. Which depends upon metric. To better understand this concept in the Riemannian setup, I was trying to find an example of metric on Sphere such that in that case, it becomes non strictly convex. But I could not able to find it. Can anyone please help to relate the positive definiteness of the second fundamental form with strictly convexity in the Riemannian manifold? Any Help or hint will be greatly appreciated.","(M,g)","['differential-geometry', 'riemannian-geometry', 'examples-counterexamples', 'riemann-surfaces']"
7,What is the point of giving a tensor identity in normal coordinates?,What is the point of giving a tensor identity in normal coordinates?,,"I have been confused about this for some time. For example, the curvature tensor in general for the Levi-Civita connection of $g$ in the local frame $\{\partial_i\}$ induced by the coordinates $\{x^i\}$ is $R_{ijk}^l = \partial_i \Gamma_{jk}^l - \partial_j \Gamma_{ik}^l + \Gamma_{jk}^m \Gamma_{im}^l - \Gamma_{ik}^m\Gamma_{jm}^l$ and if you take the partials of the Christoffel symbols and grind through you can ultimately get $R_{ijk}^l = \frac{1}{2}g^{ls}(\partial_i \partial_k g_{js} - \partial_i \partial_s g_{jk} -\partial_j \partial_k g_{is} + \partial_j\partial_s g_{ik}) + g^{lm}g_{st}(\Gamma_{jm}^s\Gamma_{ik}^t - \Gamma_{im}^s\Gamma_{jk}^t)$ which is fine. But in every book I read everyone just says ""at a point $p$ in normal coordinates we have..."" $R_{ijk}^l = \frac{1}{2}g^{ls}(\partial_i \partial_k g_{js} - \partial_i \partial_s g_{jk} -\partial_j \partial_k g_{is} + \partial_j\partial_s g_{ik})$ which of course follows right away from what I already have, but what is the point of this second formula at all? Are they trying to tell me that if I change coordinates back to the coordinate frame in the latter formula that I'm supposed to get the former? I've been trying to do this with no success, am I failing because I'm making some computational mistake or because my logic is wrong altogether? Since $R$ is a tensor its value at a point $p$ does not depend on the coordinates: Does this mean that if $\tilde\partial_j$ is the frame induced by the coordinates $\{y^j\}$ then $g(R(\partial_i, \partial_j) \partial_k, \partial_l))=\tilde{g}(\tilde{R}(\tilde\partial_i, \tilde\partial_j)\tilde\partial_k,\tilde\partial_l)$ as real numbers at every point $p$ in the overlap of the two charts? Does this mean that if for some reason I wanted to integrate the component $R_{123}^4$ over some compact $M$ I could just integrate its formula in normal coordinates? If the questions seem vague its because I really am confused by this. Thanks for whatever clarification you can give.","I have been confused about this for some time. For example, the curvature tensor in general for the Levi-Civita connection of in the local frame induced by the coordinates is and if you take the partials of the Christoffel symbols and grind through you can ultimately get which is fine. But in every book I read everyone just says ""at a point in normal coordinates we have..."" which of course follows right away from what I already have, but what is the point of this second formula at all? Are they trying to tell me that if I change coordinates back to the coordinate frame in the latter formula that I'm supposed to get the former? I've been trying to do this with no success, am I failing because I'm making some computational mistake or because my logic is wrong altogether? Since is a tensor its value at a point does not depend on the coordinates: Does this mean that if is the frame induced by the coordinates then as real numbers at every point in the overlap of the two charts? Does this mean that if for some reason I wanted to integrate the component over some compact I could just integrate its formula in normal coordinates? If the questions seem vague its because I really am confused by this. Thanks for whatever clarification you can give.","g \{\partial_i\} \{x^i\} R_{ijk}^l = \partial_i \Gamma_{jk}^l - \partial_j \Gamma_{ik}^l + \Gamma_{jk}^m \Gamma_{im}^l - \Gamma_{ik}^m\Gamma_{jm}^l R_{ijk}^l = \frac{1}{2}g^{ls}(\partial_i \partial_k g_{js} - \partial_i \partial_s g_{jk} -\partial_j \partial_k g_{is} + \partial_j\partial_s g_{ik}) + g^{lm}g_{st}(\Gamma_{jm}^s\Gamma_{ik}^t - \Gamma_{im}^s\Gamma_{jk}^t) p R_{ijk}^l = \frac{1}{2}g^{ls}(\partial_i \partial_k g_{js} - \partial_i \partial_s g_{jk} -\partial_j \partial_k g_{is} + \partial_j\partial_s g_{ik}) R p \tilde\partial_j \{y^j\} g(R(\partial_i, \partial_j) \partial_k, \partial_l))=\tilde{g}(\tilde{R}(\tilde\partial_i, \tilde\partial_j)\tilde\partial_k,\tilde\partial_l) p R_{123}^4 M","['differential-geometry', 'riemannian-geometry', 'coordinate-systems', 'tensors', 'curvature']"
8,K-Theory Equivalence Classes,K-Theory Equivalence Classes,,"Let $M$ be a finite dimensional compact manifold and $(Vect(M),\oplus)$ be the abelian monoid of complex vector bundles on $M$ . I just read that it is possible to construct an equivalence relation on $Vect(M)^2$ by $$(E_1,F_1)\sim (E_2,F_2) \iff \exists N\in \mathbb N \, s.t. \, E_1\oplus F_2\oplus \mathbb C^N\cong E_2\oplus F_1\oplus \mathbb C^N$$ In the book i'm reading (Salomon's notes on SW theory), it says that ""the additional summand $\mathbb C^N$ is needed to obtain an equivalence relation"". It seems to me that the only problem of not having it could be the transitivity property: is it not necessarily true that if $E_1\oplus F_2\cong E_2\oplus F_1$ and $E_2\oplus F_3\cong E_3\oplus F_2$ , then $E_1\oplus F_3\cong E_3\oplus F_1$ ? I'm not able to prove the transitivity property also for the adjusted relation above. Can someone help me with that?","Let be a finite dimensional compact manifold and be the abelian monoid of complex vector bundles on . I just read that it is possible to construct an equivalence relation on by In the book i'm reading (Salomon's notes on SW theory), it says that ""the additional summand is needed to obtain an equivalence relation"". It seems to me that the only problem of not having it could be the transitivity property: is it not necessarily true that if and , then ? I'm not able to prove the transitivity property also for the adjusted relation above. Can someone help me with that?","M (Vect(M),\oplus) M Vect(M)^2 (E_1,F_1)\sim (E_2,F_2) \iff \exists N\in \mathbb N \, s.t. \, E_1\oplus F_2\oplus \mathbb C^N\cong E_2\oplus F_1\oplus \mathbb C^N \mathbb C^N E_1\oplus F_2\cong E_2\oplus F_1 E_2\oplus F_3\cong E_3\oplus F_2 E_1\oplus F_3\cong E_3\oplus F_1","['differential-geometry', 'k-theory', 'topological-k-theory']"
9,Second derivative of the Christoffel symbols in normal coordinates,Second derivative of the Christoffel symbols in normal coordinates,,"According to wikipedia the Taylor expansion of the Christoffel symbols of a Riemannian manifold $(M,g)$ in normal coordinates is given by $$ {\Gamma^{\lambda}}_{\mu\nu}(x)= -\frac 13 (R_{\lambda\nu\mu\tau}(0)+R_{\lambda\mu\nu\tau}(0))x^\tau+ O(|x|^2). $$ Is there any reference for the calculation of the $O(|x|^2)$ term? I did the computations as Yuval proposed and ended up with $$ 6\dfrac{\partial }{\partial x_v} \dfrac{\partial }{\partial x_w}{\Gamma^{n}}_{ij}(x)  \\= \frac 12 g^{nl} \left( \nabla_i R_{jvwl} + \nabla_i R_{jwvl} +\nabla_w R_{jivl} + \nabla_v R_{jiwl} + \nabla_w R_{jvil} + \nabla_v R_{jwil} \right) + \left( \nabla_j R_{ivwl} + \nabla_j R_{iwvl} +\nabla_w R_{ijvl} + \nabla_v R_{ijwl} + \nabla_w R_{ivjl} + \nabla_v R_{iwjl} \right) - \left( \nabla_l R_{ivwj} + \nabla_l R_{iwvj} +\nabla_w R_{ilvj} + \nabla_v R_{ilwj} + \nabla_w R_{ivlj} + \nabla_v R_{iwlj} \right) $$ If I apply the symmetries of the curvature tensor $$ \left( \nabla_i R_{jvwl} + \nabla_i R_{jwvl}  + 2\nabla_w R_{jvil} + 2\nabla_v R_{jwil} \right) + \left( \nabla_j R_{ivwl} + \nabla_j R_{iwvl}   + 2\nabla_w R_{ivjl} + 2\nabla_v R_{iwjl} \right) - \left( \nabla_l R_{ivwj} + \nabla_l R_{iwvj}  \right) $$ I feel like the derivatives involving derivatives in $i,j,l$ should somehow cancel out with the Bianchi identities but I don't get it to work.",According to wikipedia the Taylor expansion of the Christoffel symbols of a Riemannian manifold in normal coordinates is given by Is there any reference for the calculation of the term? I did the computations as Yuval proposed and ended up with If I apply the symmetries of the curvature tensor I feel like the derivatives involving derivatives in should somehow cancel out with the Bianchi identities but I don't get it to work.,"(M,g) 
{\Gamma^{\lambda}}_{\mu\nu}(x)= -\frac 13 (R_{\lambda\nu\mu\tau}(0)+R_{\lambda\mu\nu\tau}(0))x^\tau+ O(|x|^2).
 O(|x|^2) 
6\dfrac{\partial }{\partial x_v} \dfrac{\partial }{\partial x_w}{\Gamma^{n}}_{ij}(x) 
\\= \frac 12 g^{nl}
\left( \nabla_i R_{jvwl} + \nabla_i R_{jwvl} +\nabla_w R_{jivl} + \nabla_v R_{jiwl} + \nabla_w R_{jvil} + \nabla_v R_{jwil} \right) +
\left( \nabla_j R_{ivwl} + \nabla_j R_{iwvl} +\nabla_w R_{ijvl} + \nabla_v R_{ijwl} + \nabla_w R_{ivjl} + \nabla_v R_{iwjl} \right) -
\left( \nabla_l R_{ivwj} + \nabla_l R_{iwvj} +\nabla_w R_{ilvj} + \nabla_v R_{ilwj} + \nabla_w R_{ivlj} + \nabla_v R_{iwlj} \right)
 
\left( \nabla_i R_{jvwl} + \nabla_i R_{jwvl}  + 2\nabla_w R_{jvil} + 2\nabla_v R_{jwil} \right) +
\left( \nabla_j R_{ivwl} + \nabla_j R_{iwvl}   + 2\nabla_w R_{ivjl} + 2\nabla_v R_{iwjl} \right) -
\left( \nabla_l R_{ivwj} + \nabla_l R_{iwvj}  \right)
 i,j,l","['differential-geometry', 'riemannian-geometry']"
10,dot product in a general coordinate system,dot product in a general coordinate system,,"NOTE: Einstein summation is assumed. Also, the component expanded vector in the standard basis will be expressed with square brackets and in the curvilinear basis with round brackets. E.g, in the case of plane polar coordinates, $$\begin{bmatrix} 1\\ \sqrt{3} \end{bmatrix} =\begin{pmatrix} 2\\ \pi /3 \end{pmatrix}$$ Links to similar questions: 1 and 2 . The reason I'm asking this question is because the answers given in these posts were pretty unsatisfactory - I don't want to assume the coordinates are orthogonal and I'm ok with the result being somewhat circular in nature. All I'm looking for is a nice succinct formula that gives correct results. I'm currently studying differential geometry. I'm sure we are all aware of the formula for the inner product of two vectors in the standard basis $$\langle\underline{u},\underline{v}\rangle_{\text{std.}}=\delta_{ij}u^iv^j$$ However, this is only true if the vectors are expressed in the standard basis. For instance we know that in plane polar coordinates, the dot product is obviously not $r r'+\theta\theta'$ . Wikipedia cites the formula $$\langle\underline{u},\underline{v}\rangle_{\mathscr{C}}=g_{ij}u^iv^j$$ As the inner product for a general coordinate system $\mathscr{C}$ . Now obviously, it shouldn't matter what coordinate basis we take the inner product with respect to. The only reason for the above notation is to emphasize that the form of the inner product will change from one coordinate system to another, but indeed for a particular pair of vectors its value will not. However when this formula is applied to plane polar coordinates, this gives the strange formula $$\langle\underline{u},\underline{v}\rangle_{\text{polar}}=u_rv_r+r^2u_\theta v_\theta$$ Which doesn't really make sense. In this context, what even is $r$ ? In fact, the above formula fails for obvious reasons - the metric tensor varies from point to point, e.g for the vector $[~1~~~1~]^{\mathrm{T}}=(~\sqrt{2}~~~\pi/4~)^{\mathrm{T}}$ the metric tensor is $$\mathbf{g}(\sqrt{2},\pi/4)=\begin{bmatrix} \begin{bmatrix} 1 & 0 \end{bmatrix} & \begin{bmatrix} 0 & 2 \end{bmatrix} \end{bmatrix}$$ Whereas for the vector $[~5~~~12~]^{\mathrm{T}}=(~13~~~\arctan(12/5)~)^{\mathrm{T}}$ it is $$\mathbf{g}(13,\arctan(12/5))=\begin{bmatrix} \begin{bmatrix} 1 & 0 \end{bmatrix} & \begin{bmatrix} 0 & 169 \end{bmatrix} \end{bmatrix}$$ So what are Wiki referring to by $g_{ij}$ in the referenced formula? But , even if the two vectors have the same metric tensor, i.e, same $r$ component, the formula still fails, as we presumably get $$\langle(r,\theta_1),(r,\theta_2)\rangle_{\text{polar}}=r^2(1+\theta_1\theta_2)$$ Which is clearly not correct. So here is my question: Let's suppose we have two vectors in $\mathbb{R}^n$ which in the standard basis are $$\underline{v}=\begin{bmatrix} x^{1}\\ \vdots \\ x^{n} \end{bmatrix} \ ;\ \underline{v'} =\begin{bmatrix} {x'} ^{1}\\ \vdots \\ {x'} ^{n} \end{bmatrix}$$ And in some curvilinear basis are $$\underline{v}=\begin{pmatrix} q^{1}\\ \vdots \\ q^{n} \end{pmatrix}~;~\underline{v'}=\begin{pmatrix} {q'}^{1}\\ \vdots \\ {q'}^{n} \end{pmatrix}$$ Let's suppose we know the coordinate transformation functions $q^i=q^i(x^1,...,x^n)$ and also the reverse coordinate transformation functions $x^i=x^i(q^1,...,q^n)$ and we are given the explicit form of the metric tensor $\mathbf{g}$ for the coordinate transformation $[~x^1~~~...~~~x^n~]^{\mathrm{T}}\to(~q^1~~~...~~~q^n~)^{\mathrm{T}}$ . Given the two vectors in their curvilinear components , is there any way to work out $\langle\underline{v},\underline{v'}\rangle$ without resorting to converting back to the standard basis? That is, is there any magic formula $$\langle\underline{v},\underline{v'}\rangle_{\mathscr{C}}=f\left((q^1,...,q^n),({q'}^1,...,{q'}^n)\right)$$","NOTE: Einstein summation is assumed. Also, the component expanded vector in the standard basis will be expressed with square brackets and in the curvilinear basis with round brackets. E.g, in the case of plane polar coordinates, Links to similar questions: 1 and 2 . The reason I'm asking this question is because the answers given in these posts were pretty unsatisfactory - I don't want to assume the coordinates are orthogonal and I'm ok with the result being somewhat circular in nature. All I'm looking for is a nice succinct formula that gives correct results. I'm currently studying differential geometry. I'm sure we are all aware of the formula for the inner product of two vectors in the standard basis However, this is only true if the vectors are expressed in the standard basis. For instance we know that in plane polar coordinates, the dot product is obviously not . Wikipedia cites the formula As the inner product for a general coordinate system . Now obviously, it shouldn't matter what coordinate basis we take the inner product with respect to. The only reason for the above notation is to emphasize that the form of the inner product will change from one coordinate system to another, but indeed for a particular pair of vectors its value will not. However when this formula is applied to plane polar coordinates, this gives the strange formula Which doesn't really make sense. In this context, what even is ? In fact, the above formula fails for obvious reasons - the metric tensor varies from point to point, e.g for the vector the metric tensor is Whereas for the vector it is So what are Wiki referring to by in the referenced formula? But , even if the two vectors have the same metric tensor, i.e, same component, the formula still fails, as we presumably get Which is clearly not correct. So here is my question: Let's suppose we have two vectors in which in the standard basis are And in some curvilinear basis are Let's suppose we know the coordinate transformation functions and also the reverse coordinate transformation functions and we are given the explicit form of the metric tensor for the coordinate transformation . Given the two vectors in their curvilinear components , is there any way to work out without resorting to converting back to the standard basis? That is, is there any magic formula","\begin{bmatrix}
1\\
\sqrt{3}
\end{bmatrix} =\begin{pmatrix}
2\\
\pi /3
\end{pmatrix} \langle\underline{u},\underline{v}\rangle_{\text{std.}}=\delta_{ij}u^iv^j r r'+\theta\theta' \langle\underline{u},\underline{v}\rangle_{\mathscr{C}}=g_{ij}u^iv^j \mathscr{C} \langle\underline{u},\underline{v}\rangle_{\text{polar}}=u_rv_r+r^2u_\theta v_\theta r [~1~~~1~]^{\mathrm{T}}=(~\sqrt{2}~~~\pi/4~)^{\mathrm{T}} \mathbf{g}(\sqrt{2},\pi/4)=\begin{bmatrix}
\begin{bmatrix}
1 & 0
\end{bmatrix} & \begin{bmatrix}
0 & 2
\end{bmatrix}
\end{bmatrix} [~5~~~12~]^{\mathrm{T}}=(~13~~~\arctan(12/5)~)^{\mathrm{T}} \mathbf{g}(13,\arctan(12/5))=\begin{bmatrix}
\begin{bmatrix}
1 & 0
\end{bmatrix} & \begin{bmatrix}
0 & 169
\end{bmatrix}
\end{bmatrix} g_{ij} r \langle(r,\theta_1),(r,\theta_2)\rangle_{\text{polar}}=r^2(1+\theta_1\theta_2) \mathbb{R}^n \underline{v}=\begin{bmatrix}
x^{1}\\
\vdots \\
x^{n}
\end{bmatrix} \ ;\ \underline{v'} =\begin{bmatrix}
{x'} ^{1}\\
\vdots \\
{x'} ^{n}
\end{bmatrix} \underline{v}=\begin{pmatrix}
q^{1}\\
\vdots \\
q^{n}
\end{pmatrix}~;~\underline{v'}=\begin{pmatrix}
{q'}^{1}\\
\vdots \\
{q'}^{n}
\end{pmatrix} q^i=q^i(x^1,...,x^n) x^i=x^i(q^1,...,q^n) \mathbf{g} [~x^1~~~...~~~x^n~]^{\mathrm{T}}\to(~q^1~~~...~~~q^n~)^{\mathrm{T}} \langle\underline{v},\underline{v'}\rangle \langle\underline{v},\underline{v'}\rangle_{\mathscr{C}}=f\left((q^1,...,q^n),({q'}^1,...,{q'}^n)\right)","['differential-geometry', 'curvilinear-coordinates']"
11,"Bounds on the norm $|J'|$, where $J$ is a Jacobi field","Bounds on the norm , where  is a Jacobi field",|J'| J,"I am trying to understand the well known formula for the norm of Jacobi fields $J$ along a geodesic $\gamma(t)$ with $J(0)=0$ , i.e. $$ J''(t)+ R(J,\gamma'),\gamma'=0. $$ The formula $$  (\ast) \quad g(J(t),J(t)) = O(t^2) $$ holds on a Riemannian manifold $(M,g)$ (see e.g. here ). In this link the Jacobi equations are used to compute the first two derivatives in $t=0$ and then use a Taylor expansion to argue that the remainder is of higher order. But what I do not understand in this proof is how to make sense of the remainder because it involves $J(t)$ again: $$ (g(J(t),J(t)))''= 2(g(J''(t),J(t))+ g(J'(t),J'(t)). $$ So a Taylor expansion yields for some $s_t \in [0,t]$ $$ g(J(t),J(t))= 0+ t\cdot 0 + t^2 \cdot   (g( R(J,\gamma'(s_t)),\gamma'(s_t),J(s_t)))+ g(J'(s_t),J'(s_t)). $$ How do we estimate the term $g(J'(s_t),J'(s_t))$ ? For example, how do rule out that $$ g(J'(s_t),J'(s_t)) \geq \frac{1}{t}?  $$","I am trying to understand the well known formula for the norm of Jacobi fields along a geodesic with , i.e. The formula holds on a Riemannian manifold (see e.g. here ). In this link the Jacobi equations are used to compute the first two derivatives in and then use a Taylor expansion to argue that the remainder is of higher order. But what I do not understand in this proof is how to make sense of the remainder because it involves again: So a Taylor expansion yields for some How do we estimate the term ? For example, how do rule out that","J \gamma(t) J(0)=0 
J''(t)+ R(J,\gamma'),\gamma'=0.
 
 (\ast) \quad g(J(t),J(t)) = O(t^2)
 (M,g) t=0 J(t) 
(g(J(t),J(t)))''= 2(g(J''(t),J(t))+ g(J'(t),J'(t)).
 s_t \in [0,t] 
g(J(t),J(t))= 0+ t\cdot 0 + t^2 \cdot   (g( R(J,\gamma'(s_t)),\gamma'(s_t),J(s_t)))+ g(J'(s_t),J'(s_t)).
 g(J'(s_t),J'(s_t)) 
g(J'(s_t),J'(s_t)) \geq \frac{1}{t}? 
","['differential-geometry', 'taylor-expansion', 'riemannian-geometry']"
12,How to interpret the meaning of $\mathbf n d\sigma$ in terms of differential forms?,How to interpret the meaning of  in terms of differential forms?,\mathbf n d\sigma,"We often write stokes's formula in $\mathbb R^n$ as $$ \int_\Omega \nabla\cdot \mathbf f d\mu=\int_{\partial \Omega} \mathbf f \cdot \mathbf n d\sigma. $$ My questions is: what does $\mathbf n d\sigma$ mean? it is written as if it is a vector, but $d \sigma$ is essentially a $(n-1)$ -covector.  Multiplying a covector by $\mathbf n$ does not make sense. Interpreting $\mathbf f \cdot \mathbf n d\sigma$ as the product of a function and a $(n-1)$ -covector does not work as well, because when I calculate it in two dimensions, it does not work. Let's say that the normal vector is $(\sin \theta, -\cos \theta)$ , then $\mathbf f \cdot \mathbf n = f_1 \sin \theta -f_2 \cos \theta$ , and $d \sigma = \cos \theta dx_1 + \sin \theta dx_2$ . Multiplying $\mathbf f \cdot \mathbf n$ and $d \sigma$ does NOT lead to the expected expression $f_1 dx_2 -f_2 dx_1$ or something similar. So how could I translate $\mathbf n d\sigma$ to the language of differential form?","We often write stokes's formula in as My questions is: what does mean? it is written as if it is a vector, but is essentially a -covector.  Multiplying a covector by does not make sense. Interpreting as the product of a function and a -covector does not work as well, because when I calculate it in two dimensions, it does not work. Let's say that the normal vector is , then , and . Multiplying and does NOT lead to the expected expression or something similar. So how could I translate to the language of differential form?","\mathbb R^n 
\int_\Omega \nabla\cdot \mathbf f d\mu=\int_{\partial \Omega} \mathbf f \cdot \mathbf n d\sigma.
 \mathbf n d\sigma d \sigma (n-1) \mathbf n \mathbf f \cdot \mathbf n d\sigma (n-1) (\sin \theta, -\cos \theta) \mathbf f \cdot \mathbf n = f_1 \sin \theta -f_2 \cos \theta d \sigma = \cos \theta dx_1 + \sin \theta dx_2 \mathbf f \cdot \mathbf n d \sigma f_1 dx_2 -f_2 dx_1 \mathbf n d\sigma","['differential-geometry', 'differential-forms', 'stokes-theorem']"
13,Clarifying the chain rule terminology in differential geometry calculuations,Clarifying the chain rule terminology in differential geometry calculuations,,"Let $M$ be a manifold and $f:M\to\mathbb{R}$ a smooth function on it. Let $p\in M$ have the coordinates $\{x^i\}$ under the chart $(U,\phi)$ . Finally, let $\gamma:I\to M$ be a curve ( $I$ is an open interval in $\mathbb{R}$ ). Let $u$ be the generic argument of the $\gamma$ map, i.e. $u\in I$ . I'm trying to understand the chain rule: $$\frac{\partial f}{\partial u}=\frac{\partial f}{\partial x^i}\frac{\partial x^i}{\partial u}$$ Now I'm aware that the change in the function value as we move along the curve is $\frac{\partial f}{\partial u}\big|_{p\in M}$ , which is actually $\frac{\partial (f\circ\gamma)}{\partial u}\big|_{\gamma^{-1}(p)\in I}$ if we want to reconcile the domains. Similarly, $\frac{\partial f}{\partial x^i}\big|_{p\in M}$ is actually $\frac{\partial (f\circ\phi^{-1})}{\partial x^i}\big|_{\phi(p)\in \mathbb{R}^n}$ For the last term, I have two ways of looking at it: either $\frac{\partial x^i}{\partial u}\big|_{x^i(p)\in \mathbb{R}^n}$ , or $\frac{\partial x^i}{\partial u}\big|_{p\in M}$ . I'm not sure which is correct , so I'll leave that as is for now. The chain rule equation becomes $$\frac{\partial (f\circ\gamma)}{\partial u}\ \bigg|_{\gamma^{-1}(p)}=\frac{\partial (f\circ\phi^{-1})}{\partial x^i}\ \bigg|_{\phi(p)}\frac{\partial x^i}{\partial u}$$ My thought process was that I could express $f\circ\gamma$ as $(f\circ\phi^{-1})\circ(\phi\circ\gamma)$ , but I haven't been able to understand just how the chain rule is working out. I'd be grateful if someone could help me understand. I'm a beginner, so I would really appreciate a step by step answer meant for a beginner to the subject, without omitting any details .","Let be a manifold and a smooth function on it. Let have the coordinates under the chart . Finally, let be a curve ( is an open interval in ). Let be the generic argument of the map, i.e. . I'm trying to understand the chain rule: Now I'm aware that the change in the function value as we move along the curve is , which is actually if we want to reconcile the domains. Similarly, is actually For the last term, I have two ways of looking at it: either , or . I'm not sure which is correct , so I'll leave that as is for now. The chain rule equation becomes My thought process was that I could express as , but I haven't been able to understand just how the chain rule is working out. I'd be grateful if someone could help me understand. I'm a beginner, so I would really appreciate a step by step answer meant for a beginner to the subject, without omitting any details .","M f:M\to\mathbb{R} p\in M \{x^i\} (U,\phi) \gamma:I\to M I \mathbb{R} u \gamma u\in I \frac{\partial f}{\partial u}=\frac{\partial f}{\partial x^i}\frac{\partial x^i}{\partial u} \frac{\partial f}{\partial u}\big|_{p\in M} \frac{\partial (f\circ\gamma)}{\partial u}\big|_{\gamma^{-1}(p)\in I} \frac{\partial f}{\partial x^i}\big|_{p\in M} \frac{\partial (f\circ\phi^{-1})}{\partial x^i}\big|_{\phi(p)\in \mathbb{R}^n} \frac{\partial x^i}{\partial u}\big|_{x^i(p)\in \mathbb{R}^n} \frac{\partial x^i}{\partial u}\big|_{p\in M} \frac{\partial (f\circ\gamma)}{\partial u}\ \bigg|_{\gamma^{-1}(p)}=\frac{\partial (f\circ\phi^{-1})}{\partial x^i}\ \bigg|_{\phi(p)}\frac{\partial x^i}{\partial u} f\circ\gamma (f\circ\phi^{-1})\circ(\phi\circ\gamma)","['differential-geometry', 'chain-rule']"
14,Riemannian Exponential Map is a Homeomorphism outside the Cut Locus,Riemannian Exponential Map is a Homeomorphism outside the Cut Locus,,"Let $M$ be a connected and complete Riemannian manifold.  The Hopf-Rinow Theorem guarantees that $Exp_p$ , for any $p \in M$ , is defined on all of $T_p(M)$ .  Further, this map is a diffeomorphism on a neighbourhood of the origin. However, under the assumption of completeness and connectedness of $M$ is it a homeomorphism, is it a homeomorphism from $M-C_p$ to $T_p(M)$ ; where $C_p$ is the cut-locus of $p$ ?","Let be a connected and complete Riemannian manifold.  The Hopf-Rinow Theorem guarantees that , for any , is defined on all of .  Further, this map is a diffeomorphism on a neighbourhood of the origin. However, under the assumption of completeness and connectedness of is it a homeomorphism, is it a homeomorphism from to ; where is the cut-locus of ?",M Exp_p p \in M T_p(M) M M-C_p T_p(M) C_p p,['differential-geometry']
15,Lee - Introduction to Smooth Manifolds Problem 8-9,Lee - Introduction to Smooth Manifolds Problem 8-9,,"Proposition 8.19 Suppose $M$ and $N$ are smooth manifolds with or without boundary, and $F:M\to N$ is a diffeomorphism. For every $X\in\mathfrak{X}(M)$ , there is a unique smooth vector field on $N$ that is $F$ -related to $X$ . Problem 8-9. Show by finding a counterexample that Proposition 8.19 is false if we replace the assumption that $F$ is a smooth diffeomorphism by the weaker assumption that it is smooth and bijective. My solution: I started by thinking of a smooth bijection that is not a diffeomorphism. Let $M=\mathbb{R}=N$ . Then $F(x):=x^3$ is such a map, because its inverse is not smooth at $0$ . Let $X=d/dx$ . Then $$dF_x(X_x)f=\frac{d}{dx}(f\circ F)=\frac{d}{dx}(f(x^3))=3x^2\frac{df}{dx}\,.$$ Let $Y=\alpha(x)\frac{d}{dx}$ . Then $$Y_{F(x)}=\alpha(x^3)\frac{d}{dx}\,,$$ so for $Y$ to be $F$ -related to $X$ , we need $\alpha(x^3)=3x^2$ , which implies that $\alpha(x)=3x^{2/3}$ , so $\alpha$ is not smooth, and thus $Y\notin\mathfrak{X}(\mathbb{R})$ . Is this correct?","Proposition 8.19 Suppose and are smooth manifolds with or without boundary, and is a diffeomorphism. For every , there is a unique smooth vector field on that is -related to . Problem 8-9. Show by finding a counterexample that Proposition 8.19 is false if we replace the assumption that is a smooth diffeomorphism by the weaker assumption that it is smooth and bijective. My solution: I started by thinking of a smooth bijection that is not a diffeomorphism. Let . Then is such a map, because its inverse is not smooth at . Let . Then Let . Then so for to be -related to , we need , which implies that , so is not smooth, and thus . Is this correct?","M N F:M\to N X\in\mathfrak{X}(M) N F X F M=\mathbb{R}=N F(x):=x^3 0 X=d/dx dF_x(X_x)f=\frac{d}{dx}(f\circ F)=\frac{d}{dx}(f(x^3))=3x^2\frac{df}{dx}\,. Y=\alpha(x)\frac{d}{dx} Y_{F(x)}=\alpha(x^3)\frac{d}{dx}\,, Y F X \alpha(x^3)=3x^2 \alpha(x)=3x^{2/3} \alpha Y\notin\mathfrak{X}(\mathbb{R})","['differential-geometry', 'smooth-manifolds', 'vector-fields']"
16,How do we define the cotangent space as the quotient of ideals?,How do we define the cotangent space as the quotient of ideals?,,"I am interested in the definition of the cotangent space as the quotient space of ideals. The definition goes like this: Let $\mathcal M$ be a smooth manifold. $C^\infty (\mathcal M)$ is the ring of smooth scalar fields on $\mathcal M$ . Let $\mathcal I_p$ be the greatest subring of $C^\infty (\mathcal M)$ where $\phi (p)=0$ for all $\phi \in \mathcal I_p$ . $\mathcal I_p$ is an ideal. The square of this ideal is $\mathcal I_p^2=\{\sum_{i=1}^n \phi_i \psi_i | n\in \Bbb N, \phi_i,\psi_i\in\mathcal I_p \}$ . $\mathcal I_p$ and $\mathcal I_p^2$ are vector spaces. The quotient space of $\mathcal I_p$ and $\mathcal I_p^2$ is $\mathcal I_p/\mathcal I_p^2=\{\phi+\mathcal I_p^2|\phi\in\mathcal I_p\}$ . This quotient space is either equal to the cotangent space on $\mathcal M$ at $p$ or isomorphic to it. An element of $\mathcal I_p/\mathcal I_p^2$ could look like $\Phi=\{\phi + \psi \gamma, \phi + \eta \nu, \phi + \delta \upsilon  + \alpha \beta,... \}$ . How is $\Phi$ interpreted as a covector such as $\text d\phi_p$ ? Is $\Phi$ equal to $\text d \phi_p$ ?",I am interested in the definition of the cotangent space as the quotient space of ideals. The definition goes like this: Let be a smooth manifold. is the ring of smooth scalar fields on . Let be the greatest subring of where for all . is an ideal. The square of this ideal is . and are vector spaces. The quotient space of and is . This quotient space is either equal to the cotangent space on at or isomorphic to it. An element of could look like . How is interpreted as a covector such as ? Is equal to ?,"\mathcal M C^\infty (\mathcal M) \mathcal M \mathcal I_p C^\infty (\mathcal M) \phi (p)=0 \phi \in \mathcal I_p \mathcal I_p \mathcal I_p^2=\{\sum_{i=1}^n \phi_i \psi_i | n\in \Bbb N, \phi_i,\psi_i\in\mathcal I_p \} \mathcal I_p \mathcal I_p^2 \mathcal I_p \mathcal I_p^2 \mathcal I_p/\mathcal I_p^2=\{\phi+\mathcal I_p^2|\phi\in\mathcal I_p\} \mathcal M p \mathcal I_p/\mathcal I_p^2 \Phi=\{\phi + \psi \gamma, \phi + \eta \nu, \phi + \delta \upsilon  + \alpha \beta,... \} \Phi \text d\phi_p \Phi \text d \phi_p","['abstract-algebra', 'differential-geometry', 'ideals', 'differential-forms', 'co-tangent-space']"
17,A curve with constant curvature and torsion [duplicate],A curve with constant curvature and torsion [duplicate],,"This question already has answers here : Given the curvature and torsion, find the curve (3 answers) Closed 4 years ago . I'm trying to come up with an example of a curve that has constant curvature and torsion, both exactly 1. Let $\vec{r(t)}$ be a parametrization for the curve $\gamma$ . By calculating with formulas for curvature $\kappa$ and torsion $\tau$ I got that the length of the second derivative $\dot{\vec{r}} $ must be the square of the length of the first derivative. Similarly, I got that the length of the third derivative must be a cube of the first derivative. But I couldn't get this any further. I'm guessing it could be something like a spiral... that would give us a constant curvature. And this spiral should bend... What would be such an example? (For definition of the curvature and torsion: https://en.m.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas )","This question already has answers here : Given the curvature and torsion, find the curve (3 answers) Closed 4 years ago . I'm trying to come up with an example of a curve that has constant curvature and torsion, both exactly 1. Let be a parametrization for the curve . By calculating with formulas for curvature and torsion I got that the length of the second derivative must be the square of the length of the first derivative. Similarly, I got that the length of the third derivative must be a cube of the first derivative. But I couldn't get this any further. I'm guessing it could be something like a spiral... that would give us a constant curvature. And this spiral should bend... What would be such an example? (For definition of the curvature and torsion: https://en.m.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas )",\vec{r(t)} \gamma \kappa \tau \dot{\vec{r}} ,"['differential-geometry', 'vector-analysis', 'curves']"
18,"For a cordinate system $(U,x^1,\ldots , x^d)$ show that $[\partial / \partial x_i,\partial / \partial x_j]=0 $ on $U$.",For a cordinate system  show that  on .,"(U,x^1,\ldots , x^d) [\partial / \partial x_i,\partial / \partial x_j]=0  U","I'm working through Warner's Foundations of Differentiable Geometry and stuck on this question. Let $(U,x^1,\ldots x^d)$ be a coordinate system on $M$ , show that $[\partial / \partial x_i,\partial /\partial x_j]=0 $ on $U$ . I'm confused on what this question is asking. Are we supposed to apply $[\partial / \partial x_i,\partial /\partial x_j]$ to an arbitrary function $f$ defined on $U$ and use that partial derivatives commute? Or since $\partial /\partial x_i$ is a basis for a vector field on $M$ should we interpret $[\partial / \partial x_i,\partial /\partial x_j]$ a vector field and show that is it is zero on $U$ . If $[\partial / \partial x_i,\partial /\partial x_j]$ is not a vector field could you explain what kind of object it is in your answer.","I'm working through Warner's Foundations of Differentiable Geometry and stuck on this question. Let be a coordinate system on , show that on . I'm confused on what this question is asking. Are we supposed to apply to an arbitrary function defined on and use that partial derivatives commute? Or since is a basis for a vector field on should we interpret a vector field and show that is it is zero on . If is not a vector field could you explain what kind of object it is in your answer.","(U,x^1,\ldots x^d) M [\partial / \partial x_i,\partial /\partial x_j]=0  U [\partial / \partial x_i,\partial /\partial x_j] f U \partial /\partial x_i M [\partial / \partial x_i,\partial /\partial x_j] U [\partial / \partial x_i,\partial /\partial x_j]","['differential-geometry', 'smooth-manifolds']"
19,Does connection of vector bundle always take values in Lie Algebra,Does connection of vector bundle always take values in Lie Algebra,,"It is true that if connection $\omega$ in a vector bundle is $\mathfrak{g}$ -valued ( $\mathfrak{g}$ being Lie Algebra of the structure Lie Group $G$ ) in a patch $U$ , then it will be $\mathfrak{g}$ -valued in all other patches due to the transformation law: \begin{align} \omega_V = c^{-1}_{UV} \omega_U c_{UV} + c^{-1}_{UV} d c_{UV}. \end{align} However, I'm trying to understand if it must take values in Lie algebra in order to be a connection?","It is true that if connection in a vector bundle is -valued ( being Lie Algebra of the structure Lie Group ) in a patch , then it will be -valued in all other patches due to the transformation law: However, I'm trying to understand if it must take values in Lie algebra in order to be a connection?","\omega \mathfrak{g} \mathfrak{g} G U \mathfrak{g} \begin{align}
\omega_V = c^{-1}_{UV} \omega_U c_{UV} + c^{-1}_{UV} d c_{UV}.
\end{align}","['differential-geometry', 'lie-algebras', 'vector-bundles']"
20,Are manifold subsets submanifolds?,Are manifold subsets submanifolds?,,"New question: Can manifold subsets always be made into submanifolds? My book is An Introduction to Manifolds by Loring W. Tu. A. Regular/embedded submanifolds are manifolds. My question is about the converse. In algebra: B. Subset groups are equivalent to subgroups (at least with the same law, but I believe ""same identity"" is not required because they'll just turn out to have the same identity anyway). C. Rings not so much: For (commutative unital) rings, if $B$ is a ring and if $A \subseteq B$ and $A$ is a subring of $B$ , then $A$ is a ring (with the same laws and identity as $B$ because this is how subring is defined anyway). However conversely, if they are both rings (NOT necessarily with the same laws or identity), then $A$ is not necessarily a subring of $B$ . D. For example, $B$ has an idempotent element $e$ besides identity, and $A$ is the principal ideal generated by $e$ , where we have $e$ as the identity of $A$ but not of $B$ ( Algebra by Michael Artin Proposition 11.6.2 ). I think the laws of $A=(e)$ are the same as the one of $B$ , and the only thing lacking for $A$ to be a subring of $B$ is that $A$ has a different identity from $B$ (I understand that $A=(e)$ has a different identity from $B$ if and only if $A$ doesn't contain the identity of $B$ ). E. Based on what I think is the issue in (D) and based on my guess that manifolds have no such analogue for ""identity"", I expect manifold subsets to be regular/embedded submanifolds. Update : Based on Eric Wofsey's answer, I guess since there are indeed ways, that subset rings are not subrings, besides not sharing identity. I guess the ways are to do with the laws $+$ and $\times$ differing between $A$ and $B$ , kind of like in the above parenthetical remark for groups. Question: Let $A$ and $B$ be manifolds with respective dimensions $a$ and $b$ . If $A \subseteq B$ (given the subspace topology because apparently people don't just assume this), then is $A$ a regular / an embedded $a$ -submanifold of $B$ ? I'll just attempt to prove embedded (I won't prove regular directly). Please verify. $A$ is the image of the inclusion map $\iota: A \to B$ . I will show $\iota$ is an embedding, with this definition (Using this equivalent definition would be circular since such definition says ""smooth submanifold"" and not ""smooth manifold""): Smooth: An inclusion between two smooth manifolds is smooth. Edit: I guess this is the problem. I can't quite use Theorem 11.14 , but i think one can somehow modify the proof of Theorem 11.14 to prove ""If N is a (smooth) manifold subset of M, then the inclusion $i: N \to M, i(p) = p$ , is an embedding"" Immersion: Inclusions are the prototype of immersions. Edit: Oh, at least for Euclidean spaces. Topological embedding: The restriction $\tilde{\iota}: A \to \iota(A)=A$ is identity on $A$ , a homeomorphism of $A$ (because of subspace topology).","New question: Can manifold subsets always be made into submanifolds? My book is An Introduction to Manifolds by Loring W. Tu. A. Regular/embedded submanifolds are manifolds. My question is about the converse. In algebra: B. Subset groups are equivalent to subgroups (at least with the same law, but I believe ""same identity"" is not required because they'll just turn out to have the same identity anyway). C. Rings not so much: For (commutative unital) rings, if is a ring and if and is a subring of , then is a ring (with the same laws and identity as because this is how subring is defined anyway). However conversely, if they are both rings (NOT necessarily with the same laws or identity), then is not necessarily a subring of . D. For example, has an idempotent element besides identity, and is the principal ideal generated by , where we have as the identity of but not of ( Algebra by Michael Artin Proposition 11.6.2 ). I think the laws of are the same as the one of , and the only thing lacking for to be a subring of is that has a different identity from (I understand that has a different identity from if and only if doesn't contain the identity of ). E. Based on what I think is the issue in (D) and based on my guess that manifolds have no such analogue for ""identity"", I expect manifold subsets to be regular/embedded submanifolds. Update : Based on Eric Wofsey's answer, I guess since there are indeed ways, that subset rings are not subrings, besides not sharing identity. I guess the ways are to do with the laws and differing between and , kind of like in the above parenthetical remark for groups. Question: Let and be manifolds with respective dimensions and . If (given the subspace topology because apparently people don't just assume this), then is a regular / an embedded -submanifold of ? I'll just attempt to prove embedded (I won't prove regular directly). Please verify. is the image of the inclusion map . I will show is an embedding, with this definition (Using this equivalent definition would be circular since such definition says ""smooth submanifold"" and not ""smooth manifold""): Smooth: An inclusion between two smooth manifolds is smooth. Edit: I guess this is the problem. I can't quite use Theorem 11.14 , but i think one can somehow modify the proof of Theorem 11.14 to prove ""If N is a (smooth) manifold subset of M, then the inclusion , is an embedding"" Immersion: Inclusions are the prototype of immersions. Edit: Oh, at least for Euclidean spaces. Topological embedding: The restriction is identity on , a homeomorphism of (because of subspace topology).","B A \subseteq B A B A B A B B e A e e A B A=(e) B A B A B A=(e) B A B + \times A B A B a b A \subseteq B A a B A \iota: A \to B \iota i: N \to M, i(p) = p \tilde{\iota}: A \to \iota(A)=A A A","['proof-verification', 'differential-geometry']"
21,Coordinate basis of tangent space,Coordinate basis of tangent space,,"I am reading Carroll, Sean. An Introduction to General Relativity: Spacetime and Geometry . In the second chapter, he explains at length the concept of manifolds and tangent vector space at a point on the manifold, with a coordinate chart $x^\mu$ . The book explains how the basis of the tangent space is, $$\frac{\partial}{\partial x^\mu} \equiv\partial_\mu$$ This means that any directional derivative along any curve parametrized by $\lambda$ can be written as a linear combination of $\partial_\mu$ . So a vector can then be defined as, $$\text{X}=X^\mu \partial_\mu\equiv X^\mu \hat{e}_\mu$$ I get the abstract ideas, somewhat, which are being explained here. But I am having a hard time connecting these ideas to the usual ones taught about vectors in Euclidean geometry. For example, the definition of vectors as, $$\text{X}=X^\mu \partial_\mu$$ sort of looks like an operator, like its 'waiting' for something to act on for it to have a meaningful idea. I am not able to understand the link I am missing to make the connection from these abstract concepts to those in Euclidean geometry where vectors are simply written as $$\vec{V}=V_1 \hat{i}+V_2 \hat{j}+V_3\hat{k}$$ .","I am reading Carroll, Sean. An Introduction to General Relativity: Spacetime and Geometry . In the second chapter, he explains at length the concept of manifolds and tangent vector space at a point on the manifold, with a coordinate chart . The book explains how the basis of the tangent space is, This means that any directional derivative along any curve parametrized by can be written as a linear combination of . So a vector can then be defined as, I get the abstract ideas, somewhat, which are being explained here. But I am having a hard time connecting these ideas to the usual ones taught about vectors in Euclidean geometry. For example, the definition of vectors as, sort of looks like an operator, like its 'waiting' for something to act on for it to have a meaningful idea. I am not able to understand the link I am missing to make the connection from these abstract concepts to those in Euclidean geometry where vectors are simply written as .",x^\mu \frac{\partial}{\partial x^\mu} \equiv\partial_\mu \lambda \partial_\mu \text{X}=X^\mu \partial_\mu\equiv X^\mu \hat{e}_\mu \text{X}=X^\mu \partial_\mu \vec{V}=V_1 \hat{i}+V_2 \hat{j}+V_3\hat{k},"['differential-geometry', 'manifolds', 'tangent-spaces']"
22,Equation for geodesic in manifold of orthogonal matrices,Equation for geodesic in manifold of orthogonal matrices,,"From the following post Geodesic of Stiefel manifold it reads that a geodesic (under the canonical metric) in the manifold of orthogonal matrices can be expressed as $Y(t) = Q e^{Xt} I_{np}$ for some matrix $Q$ and $X$ , and for $I_{np} = I$ , since $n = p$ . 1) Does it follow that the geodesic between two orthogonal matrices $Y_1$ and $Y_2$ is given by $Y(t) = Y_1(Y^\top_2 Y_1)^{-t}$ , for $t \in [0,1]$ ? 2) Does this curve have constant speed?","From the following post Geodesic of Stiefel manifold it reads that a geodesic (under the canonical metric) in the manifold of orthogonal matrices can be expressed as for some matrix and , and for , since . 1) Does it follow that the geodesic between two orthogonal matrices and is given by , for ? 2) Does this curve have constant speed?","Y(t) = Q e^{Xt} I_{np} Q X I_{np} = I n = p Y_1 Y_2 Y(t) = Y_1(Y^\top_2 Y_1)^{-t} t \in [0,1]","['differential-geometry', 'manifolds']"
23,Vertical curve in a Riemannian warped product is a geodesic,Vertical curve in a Riemannian warped product is a geodesic,,"Let $(N,g_N)$ be Riemannian manifold, $I \subset \mathbb{R}$ open with coordinate $r$ and $M:= I \times N$ with metric $g=dr^2+f^2 g_N$ . Let $c_p: I \rightarrow M, (t \mapsto (t,p))$ for a fixed $p$ be a curve in $M$ .  I want to show that $c$ is a geodesic. To do that, I first look at local coordinates for $M$ , define $(y^1,....,y^{n+1})=((t,q) \mapsto t, x^1,...,x^n)$ where $x^i$ are local coordinates in $N$ . Now: $y^1 \circ c_p= (t \mapsto t)$ and $y^i \circ c_p=(t \mapsto x^i(p))$ for $i>1$ . I can conclude that $$\dfrac{\partial (y^1 \circ c_p)}{\partial t} =1,\quad \dfrac{\partial^2 (y^i \circ c_p))}{\partial t^2}=0 \ \forall i,\quad \dfrac{\partial (y^i \circ c_p)}{\partial t} =0 \ \forall i>1.$$ Now the equation for $\nabla_{c^{'}} c^{'}$ reduces to: $$\nabla_{c^{'}} c^{'}= \sum\limits_{i=1}^{n+1} \Gamma^i_{11} \dfrac{\partial}{\partial y_i} = \nabla_{\partial_1} \partial_1$$ Is it correct, that $ \nabla_{\partial_1} \partial_1=0$ (then my proof would be complete)? And if yes, why?","Let be Riemannian manifold, open with coordinate and with metric . Let for a fixed be a curve in .  I want to show that is a geodesic. To do that, I first look at local coordinates for , define where are local coordinates in . Now: and for . I can conclude that Now the equation for reduces to: Is it correct, that (then my proof would be complete)? And if yes, why?","(N,g_N) I \subset \mathbb{R} r M:= I \times N g=dr^2+f^2 g_N c_p: I \rightarrow M, (t \mapsto (t,p)) p M c M (y^1,....,y^{n+1})=((t,q) \mapsto t, x^1,...,x^n) x^i N y^1 \circ c_p= (t \mapsto t) y^i \circ c_p=(t \mapsto x^i(p)) i>1 \dfrac{\partial (y^1 \circ c_p)}{\partial t} =1,\quad \dfrac{\partial^2 (y^i \circ c_p))}{\partial t^2}=0 \ \forall i,\quad \dfrac{\partial (y^i \circ c_p)}{\partial t} =0 \ \forall i>1. \nabla_{c^{'}} c^{'} \nabla_{c^{'}} c^{'}= \sum\limits_{i=1}^{n+1} \Gamma^i_{11} \dfrac{\partial}{\partial y_i} = \nabla_{\partial_1} \partial_1  \nabla_{\partial_1} \partial_1=0","['differential-geometry', 'riemannian-geometry', 'curves', 'geodesic', 'connections']"
24,The Lie derivative does not determine a well-defined directional derivative,The Lie derivative does not determine a well-defined directional derivative,,"The errata for ""Riemannian Manifolds: An Introduction to Curvature"" by John Lee has for one of the problems the following correction below. Page 63, problem 4-3(b): Replace the first sentence by “Show that there are vector fields $V$ and $W$ on $R^2$ such that $V = W = \partial_1$ along the $x^1$ -axis, but the Lie derivatives $L_V(\partial_2)$ and $L_W(\partial_2)$ are   not equal on the $x^1$ -axis."" I don't understand how $L_V(\partial_2)$ and $L_W(\partial_2)$ can be different on the $x^1$ -axis. Shouldn't the flow at any point on the $x^1$ -axis be the same for V and W and therefore $L_V(\partial_2)=L_W(\partial_2)$ on the $x^1$ -axis.","The errata for ""Riemannian Manifolds: An Introduction to Curvature"" by John Lee has for one of the problems the following correction below. Page 63, problem 4-3(b): Replace the first sentence by “Show that there are vector fields and on such that along the -axis, but the Lie derivatives and are   not equal on the -axis."" I don't understand how and can be different on the -axis. Shouldn't the flow at any point on the -axis be the same for V and W and therefore on the -axis.",V W R^2 V = W = \partial_1 x^1 L_V(\partial_2) L_W(\partial_2) x^1 L_V(\partial_2) L_W(\partial_2) x^1 x^1 L_V(\partial_2)=L_W(\partial_2) x^1,['differential-geometry']
25,A vector field is differentiable if and only if the map $X: M \to TM$ is differentiable,A vector field is differentiable if and only if the map  is differentiable,X: M \to TM,"Let $X$ be a vector field defined on a manifold $M$. Then $X$ is differentiable if and only if the application $\psi:M\rightarrow TM$ such that $\psi(p)=(p,X_p)$ is differentiable. I have some problems trying to prove this. Any help is welcome.","Let $X$ be a vector field defined on a manifold $M$. Then $X$ is differentiable if and only if the application $\psi:M\rightarrow TM$ such that $\psi(p)=(p,X_p)$ is differentiable. I have some problems trying to prove this. Any help is welcome.",,"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds', 'vector-fields']"
26,Are Riemannian manifolds only referred to as diffeomorphic if the diffeomorphism is an isometry?,Are Riemannian manifolds only referred to as diffeomorphic if the diffeomorphism is an isometry?,,"Let $M$ and $N$ be Riemannian manifolds. My understanding is that strictly speaking, a diffeomorphism $\phi:M \to N$ only acts on the smooth manifold structure, not the metric tensor. But there is a natural action of $\phi$ on the metric tensor given by the pullback under the diffeomorphism, which in fact makes the diffeomorphism an isometry. If no diffeomorphism between $M$ and $N$ is an isometry, is it standard to still refer to the Riemannian manifolds as ""diffeomorphic""?","Let $M$ and $N$ be Riemannian manifolds. My understanding is that strictly speaking, a diffeomorphism $\phi:M \to N$ only acts on the smooth manifold structure, not the metric tensor. But there is a natural action of $\phi$ on the metric tensor given by the pullback under the diffeomorphism, which in fact makes the diffeomorphism an isometry. If no diffeomorphism between $M$ and $N$ is an isometry, is it standard to still refer to the Riemannian manifolds as ""diffeomorphic""?",,"['differential-geometry', 'terminology', 'manifolds', 'isometry', 'diffeomorphism']"
27,A natural isomorphism between the dual of k-th exterior power and the k-th exterior power of the dual?,A natural isomorphism between the dual of k-th exterior power and the k-th exterior power of the dual?,,"On the wikipedia page of Exterior Algebra under the section on alternating multilinear forms, it says: “... By the universal property of the exterior power, the space of alternating forms of degree $k$ on $V$ is naturally isomorphic with the dual vector space $\left( \Lambda^k V \right)^* $. If $V$ is finite-dimensional, then the latter is naturally isomorphic to $ \Lambda ^k \left(V^*\right) $. ...” I understand the first part, but I don’t see how the dual space of the $k$-th exterior power of $V$ is naturally isomorphic to the $k$-th exterior power of the dual of $V$? I get that they have the same dimension, but what’s the specific natural isomorphism? I want to know this because I don’t see how alternating multilinear forms correspond to exterior products of covectors.","On the wikipedia page of Exterior Algebra under the section on alternating multilinear forms, it says: “... By the universal property of the exterior power, the space of alternating forms of degree $k$ on $V$ is naturally isomorphic with the dual vector space $\left( \Lambda^k V \right)^* $. If $V$ is finite-dimensional, then the latter is naturally isomorphic to $ \Lambda ^k \left(V^*\right) $. ...” I understand the first part, but I don’t see how the dual space of the $k$-th exterior power of $V$ is naturally isomorphic to the $k$-th exterior power of the dual of $V$? I get that they have the same dimension, but what’s the specific natural isomorphism? I want to know this because I don’t see how alternating multilinear forms correspond to exterior products of covectors.",,"['differential-geometry', 'differential-forms']"
28,Prove $\int_{\Sigma_r} |\nabla\varphi|^2 d\sigma_r \ge \frac{2}{u(r)^2} \int_{\Sigma_r} (\varphi - \bar{\varphi})^2 d\sigma_r $,Prove,\int_{\Sigma_r} |\nabla\varphi|^2 d\sigma_r \ge \frac{2}{u(r)^2} \int_{\Sigma_r} (\varphi - \bar{\varphi})^2 d\sigma_r ,"Reference: this paper Given the deSitter-Schwarzschild metric with mass $m > 0$ and scalar   curvature equal to $2$ is the metric $$\bigg(  1 -\frac{r^2}{3}-\frac{2m}{r} \bigg)^{-1} dr^2 + r^2  dg_{\mathbb S^2} \tag{1}$$ defined on $(a_0 ,b_0) \times \mathbb S^2$, where $(a_0,b_0)=\{r>0:1  -\frac{r^2}{3}-\frac{2m}{r}>0 \}$ and $g_{\mathbb S^2}$ is the standard metric on $\mathbb S^2$ with constant Gauss curvature equal    to $1$. In order to deal with the metric in $(1)$, we use the warped product metric $g=dr^2 + u(r)^2 dg_{\mathbb S^2}$ on $\mathbb R \times \mathbb S^2$, where $u(r)$ is a positive real function. If we assume that $g$ has constant scalar curvature equal to $2$, then $u$ solves the following second-order differential equation $$u''(r)=\frac{1}{2}\bigg( \frac{1-u'(r)^2}{u(r)} - \frac{u(r)}{2}  \bigg) \tag{2}$$ Considering only positive solutions $u(r)$ to $(2)$ which are defined for all $r \in \mathbb R$, we get a one-parameter family of periodic rotationally symmetric metrics $g_a = dr^2 + u_a(r)^2 g_{\mathbb S^2}$ with constant scalar curvature equal to $2$, where $a \in (0,1)$ and $u_a(r)$ satisfies $u_a(0)=a= \text{min} ~u$ and $u'_a(0) =0$. These metrics are precisely the deSitter-Schwarzschild metrics on $\mathbb R \times \mathbb S^2$ defined in $(1)$. Next, let $(M,g)$ be a three-manifold and consider a two-sided compact surface $\Sigma \subset M$. The mass of $\Sigma \subset M$ is defined by $$m(\Sigma) =\ \bigg( \frac{|\Sigma|}{16\pi}  \bigg)^{1/2}  	\bigg( 1  - \frac{1}{ 16\pi } \int_{\Sigma} H^2 d\sigma   	- \frac{ \Lambda}{24\pi } |\Sigma|  \bigg) \tag{3}$$ where $\Lambda = \text{inf}_M ~ R$, $R$ is the scalar curvature of   $M$, $H$ is the mean curvature of $\Sigma$, $K_\Sigma$ is the Gauss   curvature of $\Sigma$, and $|\Sigma| = \int_\Sigma d\sigma$. The first variation of $m$: $$\frac{d}{dt}m(\Sigma(t))\bigg|_{t=0} = -  \frac{2|\Sigma|^{1/2}}{(16\pi)^{3/2}} \int_{\Sigma} \varphi  \Delta_\Sigma H d\sigma \\  + \frac{|\Sigma|^{1/2}}{(16\pi)^{3/2}} \int_{\Sigma} \bigg[ 2K_\Sigma - \frac{8\pi}{|\Sigma|  }+ \bigg( \frac{1}{2|\Sigma|}\int_\Sigma H^2 d\sigma - |A|^2 \bigg)   \bigg] H \phi d\sigma \\  + \frac{|\Sigma|^{1/2}}{(16\pi)^{3/2}} \int_\Sigma (\Lambda - R) H\varphi d\sigma \tag{4}$$ Remark $1$. It follows from $(4)$  that if a two-sphere $\Sigma \subset M$ is umbilic where $|A|^2 = \frac{H^2}{2}$ and has constant Gauss curvature and $M$ has constant scalar curvature equal to $2$ along $\Sigma$, then $\Sigma$ is a critical point of the mass in $(3)$. Denote by $\Sigma_r$ the slice $\{r\} \times \mathbb S^2$. By Remark $1$, $\Sigma_r$ is a critical point for the mass in $(\mathbb R \times \mathbb S^2 , g_a)$, for all $r \in \mathbb R$ and $a \in (0,1)$. Moreover the mass of $\Sigma_r \subset (\mathbb R \times \mathbb S^2 , g_a)$ is constant for all $r \in \mathbb R$. It follows by a straightforward computation: $$\frac{d}{dr} m(\Sigma_r) = \frac{1}{2} u'(r)(1-u'(r)-u(r)^2-2u(r)u''(r)) \tag{5}$$ which is zero once $u(r)$ solves $(2)$, we obtain therefore that $m(\Sigma_r)$ is constant equal to $m(\Sigma_0)$. Now, since $g_{\Sigma_r} = u(r)^2 g_{\mathbb S^2}$, by the Poincare inequality we have   $$ \int_{\Sigma_r} |\nabla\varphi|^2  d\sigma_r \ge \frac{2}{u(r)^2} \int_{\Sigma_r} (\varphi - \bar{\varphi})^2 d\sigma_r   = \frac{8\pi}{|\Sigma_r|}\int_{\Sigma_r} (\varphi - \bar{\varphi})^2 d\sigma_r \tag{6}$$ where $\varphi \in C^\infty(\Sigma_r)$. Question: Where does $(6)$ come from? Thank you.","Reference: this paper Given the deSitter-Schwarzschild metric with mass $m > 0$ and scalar   curvature equal to $2$ is the metric $$\bigg(  1 -\frac{r^2}{3}-\frac{2m}{r} \bigg)^{-1} dr^2 + r^2  dg_{\mathbb S^2} \tag{1}$$ defined on $(a_0 ,b_0) \times \mathbb S^2$, where $(a_0,b_0)=\{r>0:1  -\frac{r^2}{3}-\frac{2m}{r}>0 \}$ and $g_{\mathbb S^2}$ is the standard metric on $\mathbb S^2$ with constant Gauss curvature equal    to $1$. In order to deal with the metric in $(1)$, we use the warped product metric $g=dr^2 + u(r)^2 dg_{\mathbb S^2}$ on $\mathbb R \times \mathbb S^2$, where $u(r)$ is a positive real function. If we assume that $g$ has constant scalar curvature equal to $2$, then $u$ solves the following second-order differential equation $$u''(r)=\frac{1}{2}\bigg( \frac{1-u'(r)^2}{u(r)} - \frac{u(r)}{2}  \bigg) \tag{2}$$ Considering only positive solutions $u(r)$ to $(2)$ which are defined for all $r \in \mathbb R$, we get a one-parameter family of periodic rotationally symmetric metrics $g_a = dr^2 + u_a(r)^2 g_{\mathbb S^2}$ with constant scalar curvature equal to $2$, where $a \in (0,1)$ and $u_a(r)$ satisfies $u_a(0)=a= \text{min} ~u$ and $u'_a(0) =0$. These metrics are precisely the deSitter-Schwarzschild metrics on $\mathbb R \times \mathbb S^2$ defined in $(1)$. Next, let $(M,g)$ be a three-manifold and consider a two-sided compact surface $\Sigma \subset M$. The mass of $\Sigma \subset M$ is defined by $$m(\Sigma) =\ \bigg( \frac{|\Sigma|}{16\pi}  \bigg)^{1/2}  	\bigg( 1  - \frac{1}{ 16\pi } \int_{\Sigma} H^2 d\sigma   	- \frac{ \Lambda}{24\pi } |\Sigma|  \bigg) \tag{3}$$ where $\Lambda = \text{inf}_M ~ R$, $R$ is the scalar curvature of   $M$, $H$ is the mean curvature of $\Sigma$, $K_\Sigma$ is the Gauss   curvature of $\Sigma$, and $|\Sigma| = \int_\Sigma d\sigma$. The first variation of $m$: $$\frac{d}{dt}m(\Sigma(t))\bigg|_{t=0} = -  \frac{2|\Sigma|^{1/2}}{(16\pi)^{3/2}} \int_{\Sigma} \varphi  \Delta_\Sigma H d\sigma \\  + \frac{|\Sigma|^{1/2}}{(16\pi)^{3/2}} \int_{\Sigma} \bigg[ 2K_\Sigma - \frac{8\pi}{|\Sigma|  }+ \bigg( \frac{1}{2|\Sigma|}\int_\Sigma H^2 d\sigma - |A|^2 \bigg)   \bigg] H \phi d\sigma \\  + \frac{|\Sigma|^{1/2}}{(16\pi)^{3/2}} \int_\Sigma (\Lambda - R) H\varphi d\sigma \tag{4}$$ Remark $1$. It follows from $(4)$  that if a two-sphere $\Sigma \subset M$ is umbilic where $|A|^2 = \frac{H^2}{2}$ and has constant Gauss curvature and $M$ has constant scalar curvature equal to $2$ along $\Sigma$, then $\Sigma$ is a critical point of the mass in $(3)$. Denote by $\Sigma_r$ the slice $\{r\} \times \mathbb S^2$. By Remark $1$, $\Sigma_r$ is a critical point for the mass in $(\mathbb R \times \mathbb S^2 , g_a)$, for all $r \in \mathbb R$ and $a \in (0,1)$. Moreover the mass of $\Sigma_r \subset (\mathbb R \times \mathbb S^2 , g_a)$ is constant for all $r \in \mathbb R$. It follows by a straightforward computation: $$\frac{d}{dr} m(\Sigma_r) = \frac{1}{2} u'(r)(1-u'(r)-u(r)^2-2u(r)u''(r)) \tag{5}$$ which is zero once $u(r)$ solves $(2)$, we obtain therefore that $m(\Sigma_r)$ is constant equal to $m(\Sigma_0)$. Now, since $g_{\Sigma_r} = u(r)^2 g_{\mathbb S^2}$, by the Poincare inequality we have   $$ \int_{\Sigma_r} |\nabla\varphi|^2  d\sigma_r \ge \frac{2}{u(r)^2} \int_{\Sigma_r} (\varphi - \bar{\varphi})^2 d\sigma_r   = \frac{8\pi}{|\Sigma_r|}\int_{\Sigma_r} (\varphi - \bar{\varphi})^2 d\sigma_r \tag{6}$$ where $\varphi \in C^\infty(\Sigma_r)$. Question: Where does $(6)$ come from? Thank you.",,"['differential-geometry', 'riemannian-geometry', 'surfaces']"
29,Christoffel symbols for Poincare metric on unit disk,Christoffel symbols for Poincare metric on unit disk,,"The metric is $$g=\frac{4}{(1-(u^2+v^2))^2}\begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}$$ I have tried this like ten times and I just need someone to help me out. I don't think I totally understand this metric. I know I take derivatives of the entries to get the Christoffel symbols, yet everytime I put it together in the tensor $$k(g)=\frac{R(\frac{\partial}{\partial{x_1}},\frac{\partial}{\partial{x_2}})\frac{\partial}{\partial{x_2}}\bullet\frac{\partial}{\partial{x_1}}}{det(g)}$$  I can't get $-1$.  Someone elsewhere said I should get the Christoffel symbols $$\Gamma^1_{ij}=\frac{2}{1-u^2-v^2}\begin{pmatrix} u & v \\ v & -u \end{pmatrix}$$ $$\Gamma^2_{ij}=\frac{2}{1-u^2-v^2}\begin{pmatrix} -v & u \\ u & v \end{pmatrix}$$ But I don't understand how it's a matrix, I thought it was like a scalar function, so I have no clue how he got those. I'm uploading a pic of my formulas for the Christoffels and my calculations. This seems like a direct calculation, but I can't get it right. Hopefully someone can tell me what I'm doing wrong. Riemann Tensor my work excuse my handwriting.","The metric is $$g=\frac{4}{(1-(u^2+v^2))^2}\begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}$$ I have tried this like ten times and I just need someone to help me out. I don't think I totally understand this metric. I know I take derivatives of the entries to get the Christoffel symbols, yet everytime I put it together in the tensor $$k(g)=\frac{R(\frac{\partial}{\partial{x_1}},\frac{\partial}{\partial{x_2}})\frac{\partial}{\partial{x_2}}\bullet\frac{\partial}{\partial{x_1}}}{det(g)}$$  I can't get $-1$.  Someone elsewhere said I should get the Christoffel symbols $$\Gamma^1_{ij}=\frac{2}{1-u^2-v^2}\begin{pmatrix} u & v \\ v & -u \end{pmatrix}$$ $$\Gamma^2_{ij}=\frac{2}{1-u^2-v^2}\begin{pmatrix} -v & u \\ u & v \end{pmatrix}$$ But I don't understand how it's a matrix, I thought it was like a scalar function, so I have no clue how he got those. I'm uploading a pic of my formulas for the Christoffels and my calculations. This seems like a direct calculation, but I can't get it right. Hopefully someone can tell me what I'm doing wrong. Riemann Tensor my work excuse my handwriting.",,"['differential-geometry', 'riemannian-geometry', 'hyperbolic-geometry']"
30,Trying to understand the first fundamental form,Trying to understand the first fundamental form,,"I have read similar questions with regards to what the first fundamental form is. I couldn't find my answers due to them assuming extra knowledge and/or using a different book which presents the topics differently. I am studying differential geometry from Pressley (2nd ed.). Here is an excerpt from the book: I understand the first fundamental form is a dot product. It takes two vectors from the tangent space and outputs a number. Now, what does this have to do with $du$ and $dv$? And why would they name it so it coincides with the notation from integration? According to the definition provided, $du$ is a function that outputs the first component of a vector in your tangent plane, and $dv$ outputs the second component. Then he takes the dot product of the two vectors and now the dot product is written in terms of the basis vectors $\pmb\sigma_u$ and $\pmb\sigma_v$. (1) He says the first fundamental form is $Edu^2+2Fdudv+Gdv^2$, and says how the coefficients and $du$, $dv$ depend on the choice of surface patch, but the first fundamental form doesn't. How can that be? If the fundamental form is $Edu^2+2Fdudv+Gdv^2$ then surely it inherits the dependence of its components. Now we have the following: (2) What was the purpose of inventing all this machinery? So you can calculate the arc length using only the vectors that span the tangent plane? (3) Why is this property intrinsic? Someone living on the surface would calculate the length of the curve by looking at the curve and measuring the unit tangent vectors of the curve. But now it seems more complicated, that he somehow needs access to the surface patch parametrization ($\pmb\sigma$) in order to get $\pmb\sigma_u$ and $\pmb\sigma_v$ (4) Lastly, what is the connection between the $du$'s and integration? What is the relation between these two functions and the integrand we are used to seeing all the time. They are obviously functions, not infinitesimals.","I have read similar questions with regards to what the first fundamental form is. I couldn't find my answers due to them assuming extra knowledge and/or using a different book which presents the topics differently. I am studying differential geometry from Pressley (2nd ed.). Here is an excerpt from the book: I understand the first fundamental form is a dot product. It takes two vectors from the tangent space and outputs a number. Now, what does this have to do with $du$ and $dv$? And why would they name it so it coincides with the notation from integration? According to the definition provided, $du$ is a function that outputs the first component of a vector in your tangent plane, and $dv$ outputs the second component. Then he takes the dot product of the two vectors and now the dot product is written in terms of the basis vectors $\pmb\sigma_u$ and $\pmb\sigma_v$. (1) He says the first fundamental form is $Edu^2+2Fdudv+Gdv^2$, and says how the coefficients and $du$, $dv$ depend on the choice of surface patch, but the first fundamental form doesn't. How can that be? If the fundamental form is $Edu^2+2Fdudv+Gdv^2$ then surely it inherits the dependence of its components. Now we have the following: (2) What was the purpose of inventing all this machinery? So you can calculate the arc length using only the vectors that span the tangent plane? (3) Why is this property intrinsic? Someone living on the surface would calculate the length of the curve by looking at the curve and measuring the unit tangent vectors of the curve. But now it seems more complicated, that he somehow needs access to the surface patch parametrization ($\pmb\sigma$) in order to get $\pmb\sigma_u$ and $\pmb\sigma_v$ (4) Lastly, what is the connection between the $du$'s and integration? What is the relation between these two functions and the integrand we are used to seeing all the time. They are obviously functions, not infinitesimals.",,[]
31,Vector-valued forms inside the first jet bundle,Vector-valued forms inside the first jet bundle,,"On page 433 of ""Self-duality in four-dimensional Riemannian geometry"" by Atiyah, Hitchin and Singer, it is written that $p^*(E \otimes \Lambda^1) \subset p^*J_1(E)$, where $\Lambda^1 \to X$ is the bundle of $1$-forms, $p : E^* \to X$ is a vector bundle and $J_1(E) \to X$ is the first jet bundle of $E$. How exactly is this inclusion realized?","On page 433 of ""Self-duality in four-dimensional Riemannian geometry"" by Atiyah, Hitchin and Singer, it is written that $p^*(E \otimes \Lambda^1) \subset p^*J_1(E)$, where $\Lambda^1 \to X$ is the bundle of $1$-forms, $p : E^* \to X$ is a vector bundle and $J_1(E) \to X$ is the first jet bundle of $E$. How exactly is this inclusion realized?",,"['differential-geometry', 'gauge-theory', 'global-analysis']"
32,How are these two definitions of a fibre bundle equivalent?,How are these two definitions of a fibre bundle equivalent?,,"Let us recall that a smooth bundle is a triple $(E,\pi,M)$ where $E,M$ are smooth manfiolds and $\pi : E\to M$ a smooth surjection. Consider the following two definitions of a fibre bundle: A fibre bundle with typical fibre $F$ is a bundle $(E,\pi,M)$ such that for every $x\in M$ there is a diffeomorphism $\phi_x : \pi^{-1}(x)\to F$. A fibre bundle with typical fibre$F$ is a bundle $(E,\pi,M)$ such that for every $x\in M$ there is an open set $U\subset M$ with $x\in U$ and a diffeomorphism $\varphi : U\times F\to \pi^{-1}(U)$ such that $\pi\circ \varphi(x,a)=x$. The first definition simply states that every fibre is diffeomorphic to a standard manifold $F$. The second definition states that the bundle is localy trivial: around every point there is a neighborhood such that the bundle is isomorphic to the trivial bundle $U\times F$. I've read that these two are equivalent. That (2) implies (1) is obvious, by just restricting $\varphi$ to $\{x\}\times F$. The issue is with (1) implying (2). I mean, what I don't get, is how do we get around each $x$ a neighborhood with the required property. What the map will be seems (at least by now) clear. We must set $\varphi : U\times F\to \pi^{-1}(U)$ to be $$\varphi(x,v)=\phi_{x}^{-1}(v).$$ But where the $U$ comes from seems tricky. Is it true that these two definitions are equivalent? How can we prove that (1) implies (2)?","Let us recall that a smooth bundle is a triple $(E,\pi,M)$ where $E,M$ are smooth manfiolds and $\pi : E\to M$ a smooth surjection. Consider the following two definitions of a fibre bundle: A fibre bundle with typical fibre $F$ is a bundle $(E,\pi,M)$ such that for every $x\in M$ there is a diffeomorphism $\phi_x : \pi^{-1}(x)\to F$. A fibre bundle with typical fibre$F$ is a bundle $(E,\pi,M)$ such that for every $x\in M$ there is an open set $U\subset M$ with $x\in U$ and a diffeomorphism $\varphi : U\times F\to \pi^{-1}(U)$ such that $\pi\circ \varphi(x,a)=x$. The first definition simply states that every fibre is diffeomorphic to a standard manifold $F$. The second definition states that the bundle is localy trivial: around every point there is a neighborhood such that the bundle is isomorphic to the trivial bundle $U\times F$. I've read that these two are equivalent. That (2) implies (1) is obvious, by just restricting $\varphi$ to $\{x\}\times F$. The issue is with (1) implying (2). I mean, what I don't get, is how do we get around each $x$ a neighborhood with the required property. What the map will be seems (at least by now) clear. We must set $\varphi : U\times F\to \pi^{-1}(U)$ to be $$\varphi(x,v)=\phi_{x}^{-1}(v).$$ But where the $U$ comes from seems tricky. Is it true that these two definitions are equivalent? How can we prove that (1) implies (2)?",,"['differential-geometry', 'definition', 'smooth-manifolds', 'vector-bundles', 'fiber-bundles']"
33,Cohomology of Product of Spheres,Cohomology of Product of Spheres,,"I am trying to compute the De Rahm cohomology of $M = S^2 \times S^2$. I was able to compute $H^0(M), H^1(M),$ and $H^4(M)$, but am having trouble computing $H^2(M)$ and $H^3(M)$. I am using the Mayer Vietoris sequence, and I took $U = S^2 \times (S^2 \setminus \{p\})$ and $V  = S^2 \times (S^2 \setminus \{q\})$, so $U \cap V = S^2 \times S^1$. But I haven't been able to find any of the maps needed to compute $H^2$ or $H^3$. How can compute these groups?","I am trying to compute the De Rahm cohomology of $M = S^2 \times S^2$. I was able to compute $H^0(M), H^1(M),$ and $H^4(M)$, but am having trouble computing $H^2(M)$ and $H^3(M)$. I am using the Mayer Vietoris sequence, and I took $U = S^2 \times (S^2 \setminus \{p\})$ and $V  = S^2 \times (S^2 \setminus \{q\})$, so $U \cap V = S^2 \times S^1$. But I haven't been able to find any of the maps needed to compute $H^2$ or $H^3$. How can compute these groups?",,"['differential-geometry', 'algebraic-topology', 'homology-cohomology']"
34,Compactness argument for type I singularities of the mean curvature flow,Compactness argument for type I singularities of the mean curvature flow,,"My question is about the compactness argument to find a limiting self-similar solution to the mean curvature flow near a singularity. Consider a mean curvature flow $(M_t)_{t \in I}$ of $n$-dimensional immersed manifolds in $\mathbb{R}^{n+1}$ developing a type I singulartiy at the oringin at time $T$. We can rescale these surfaces as follows $$ \tilde{F}(p,s) = \frac{1}{\sqrt{2(T-t)}} F(p,t), \: \: \: s(t) = -\frac{1}{2} \text{ln}(T-t). $$ It is well known that all the covariant derivatives of the second fundamental form of $\tilde{F}$ are bounded for $s \in [-\frac12 \text{ln}(T), \infty)$. Then I would like to ask why Huisken, in his famous paper about singularities, used an unknown (at least to me) compactness theorem to show that $\tilde{F}$ tends, locally, to a smooth immersion for some subsequence $(s_j)$. Since to me, it doesn't seem to hard to show the boundedness of the Christoffel symbols and of the metric for $\tilde{F}$ for all points $p$ in a compact set where $\tilde{F}(p,s)$ remains bounded for $s \rightarrow \infty$. Then one can use the well-known Ascoli-Arzela theorem together with a diagonal subsequence argument to find such a smooth limiting surface. Edit: While thinking about this I found that proving the boundedness of the Christoffel symbols could in fact be not so easy. This is since the symbols of the original imersion evolves as $$ \frac{\partial \Gamma_{ij}^k}{\partial t} = A \ast \nabla A, $$ where the $\ast$ denotes a metric contraction of the two tensors. Also we know that $A$ blows up somewhere near a singularity and together with the fact that the christoffel symbols of the rescaled immersion are the same ones as the original immersion we may indeed get stuck. But still I'de like to have some explanation or confirmation why Huisken didn't use the Ascoli-Arzela compactness theorem.","My question is about the compactness argument to find a limiting self-similar solution to the mean curvature flow near a singularity. Consider a mean curvature flow $(M_t)_{t \in I}$ of $n$-dimensional immersed manifolds in $\mathbb{R}^{n+1}$ developing a type I singulartiy at the oringin at time $T$. We can rescale these surfaces as follows $$ \tilde{F}(p,s) = \frac{1}{\sqrt{2(T-t)}} F(p,t), \: \: \: s(t) = -\frac{1}{2} \text{ln}(T-t). $$ It is well known that all the covariant derivatives of the second fundamental form of $\tilde{F}$ are bounded for $s \in [-\frac12 \text{ln}(T), \infty)$. Then I would like to ask why Huisken, in his famous paper about singularities, used an unknown (at least to me) compactness theorem to show that $\tilde{F}$ tends, locally, to a smooth immersion for some subsequence $(s_j)$. Since to me, it doesn't seem to hard to show the boundedness of the Christoffel symbols and of the metric for $\tilde{F}$ for all points $p$ in a compact set where $\tilde{F}(p,s)$ remains bounded for $s \rightarrow \infty$. Then one can use the well-known Ascoli-Arzela theorem together with a diagonal subsequence argument to find such a smooth limiting surface. Edit: While thinking about this I found that proving the boundedness of the Christoffel symbols could in fact be not so easy. This is since the symbols of the original imersion evolves as $$ \frac{\partial \Gamma_{ij}^k}{\partial t} = A \ast \nabla A, $$ where the $\ast$ denotes a metric contraction of the two tensors. Also we know that $A$ blows up somewhere near a singularity and together with the fact that the christoffel symbols of the rescaled immersion are the same ones as the original immersion we may indeed get stuck. But still I'de like to have some explanation or confirmation why Huisken didn't use the Ascoli-Arzela compactness theorem.",,"['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'parabolic-pde', 'mean-curvature-flows']"
35,Why the covariant derivative does not depend of the parametrization?,Why the covariant derivative does not depend of the parametrization?,,"I'm studying Differential Geometry using the book ""Diferential Geometry of Curves and Surfaces - Manfredo P. do Carmo"", and he defines covariant derivative as: Let $S \subset \mathbb{R}^3$ a surface, $p \in S$ and $\omega:S \rightarrow \bigcup\limits_{p \in S} T_p S$ a field, such that $$\omega(p) \in T_pS, \hspace{0.1cm} \mbox{for all $p$ $\in S$}. $$ Consider a parametrization $\sigma : U\subset \mathbb{R}^2 \rightarrow V \cap S$, with $\sigma(q) = p$, and a curve  $\alpha(t) := \sigma(u(t),v(t))$, satisfying $$\alpha(0) = p $$ $$\alpha'(0) = u'(0) \frac{\partial\sigma}{\partial u}(q) +v'(0) \frac{\partial\sigma}{\partial u} (q) =   y \in T_pS. $$ Using the symbols above, we can write the $\omega$ field as follows $$\omega(\sigma(u,v)) = a(u,v) \frac{\partial\sigma}{\partial u} (u,v) + b(u,v)\frac{\partial\sigma}{\partial v}(u,v), $$ where $b, a: U \rightarrow \mathbb{R}$ $\in \mathcal{C}^{\infty} (U,\mathbb{R}) $ So, we define the covariant derivative of $\omega$ in the diretion $y$ ($D_y  \omega (p)$) as: $$D_y  \omega (p) = \pi_{T_pS}\circ \left(\left.\frac{d \omega(\alpha(t))}{dt}\right\rvert_{t=0} \right)$$ $=\left((a\circ\sigma^{-1} \circ \alpha)'(0) + \Gamma_{11}^1(q) a(q) u'(0) + \Gamma_{12}^1 (q) a(q) v'(0) + \Gamma_{12}^{1}(q) b(q) u'(0) + \Gamma_{22}^1(q) b(q) v'(0)  \right)\sigma_u(q) +   + \left((b\circ\sigma^{-1} \circ \alpha)'(0) + \Gamma_{11}^2(q) a(q) u'(0) + \Gamma_{12}^2(q) a(q) v'(0) + \Gamma_{12}^{2}(q) b(q) u'(0) + \Gamma_{22}^2(q) b(q) v'(0)  \right)\sigma_v(q). $ where $\pi_{T_pS}$ is the projection on $T_pS$ and $\Gamma_{ij}^{k}$ are the Christoffel symbols. Writing the covariant derivative in this form is clear that this definition does not depend of the  curve $\alpha$ chosen. But why this derivative does not depend on the parametrization $\sigma$? Can someone help me?","I'm studying Differential Geometry using the book ""Diferential Geometry of Curves and Surfaces - Manfredo P. do Carmo"", and he defines covariant derivative as: Let $S \subset \mathbb{R}^3$ a surface, $p \in S$ and $\omega:S \rightarrow \bigcup\limits_{p \in S} T_p S$ a field, such that $$\omega(p) \in T_pS, \hspace{0.1cm} \mbox{for all $p$ $\in S$}. $$ Consider a parametrization $\sigma : U\subset \mathbb{R}^2 \rightarrow V \cap S$, with $\sigma(q) = p$, and a curve  $\alpha(t) := \sigma(u(t),v(t))$, satisfying $$\alpha(0) = p $$ $$\alpha'(0) = u'(0) \frac{\partial\sigma}{\partial u}(q) +v'(0) \frac{\partial\sigma}{\partial u} (q) =   y \in T_pS. $$ Using the symbols above, we can write the $\omega$ field as follows $$\omega(\sigma(u,v)) = a(u,v) \frac{\partial\sigma}{\partial u} (u,v) + b(u,v)\frac{\partial\sigma}{\partial v}(u,v), $$ where $b, a: U \rightarrow \mathbb{R}$ $\in \mathcal{C}^{\infty} (U,\mathbb{R}) $ So, we define the covariant derivative of $\omega$ in the diretion $y$ ($D_y  \omega (p)$) as: $$D_y  \omega (p) = \pi_{T_pS}\circ \left(\left.\frac{d \omega(\alpha(t))}{dt}\right\rvert_{t=0} \right)$$ $=\left((a\circ\sigma^{-1} \circ \alpha)'(0) + \Gamma_{11}^1(q) a(q) u'(0) + \Gamma_{12}^1 (q) a(q) v'(0) + \Gamma_{12}^{1}(q) b(q) u'(0) + \Gamma_{22}^1(q) b(q) v'(0)  \right)\sigma_u(q) +   + \left((b\circ\sigma^{-1} \circ \alpha)'(0) + \Gamma_{11}^2(q) a(q) u'(0) + \Gamma_{12}^2(q) a(q) v'(0) + \Gamma_{12}^{2}(q) b(q) u'(0) + \Gamma_{22}^2(q) b(q) v'(0)  \right)\sigma_v(q). $ where $\pi_{T_pS}$ is the projection on $T_pS$ and $\Gamma_{ij}^{k}$ are the Christoffel symbols. Writing the covariant derivative in this form is clear that this definition does not depend of the  curve $\alpha$ chosen. But why this derivative does not depend on the parametrization $\sigma$? Can someone help me?",,"['differential-geometry', 'surfaces', 'parametrization']"
36,Curve with constant torsion and curvature is a circular helix.,Curve with constant torsion and curvature is a circular helix.,,"I am trying to find a proof for the 9th question of section 2.4, from the book Elementary Differential Geometry by Barrett O'Neill. I want to show that a curve $\alpha$ with curvature $\kappa$ and torsion $\tau$ both constant is a circular helix. My thoughts: I know $\alpha$ must be a cylindrical helix since $\tau/\kappa$ is a constant. Remains to show that it is circular. I'm not sure how to do this. I found this question here : Is the helix the unique path with constant curvature and constant torsion? where the answer gives a hint to prove N′′(s)=−(κ2+τ2)N(s). I can do this, but where does it head me toward? I cannot see where this will lead me. Random thought: It occurs to me that if I can project the curve $\alpha$ on the xz plane, it must be a circle. But I don't know how I would go about showing this. Any help is appreciated. Thank you for your time.","I am trying to find a proof for the 9th question of section 2.4, from the book Elementary Differential Geometry by Barrett O'Neill. I want to show that a curve $\alpha$ with curvature $\kappa$ and torsion $\tau$ both constant is a circular helix. My thoughts: I know $\alpha$ must be a cylindrical helix since $\tau/\kappa$ is a constant. Remains to show that it is circular. I'm not sure how to do this. I found this question here : Is the helix the unique path with constant curvature and constant torsion? where the answer gives a hint to prove N′′(s)=−(κ2+τ2)N(s). I can do this, but where does it head me toward? I cannot see where this will lead me. Random thought: It occurs to me that if I can project the curve $\alpha$ on the xz plane, it must be a circle. But I don't know how I would go about showing this. Any help is appreciated. Thank you for your time.",,['differential-geometry']
37,Show tensor $g_{ij}A^iB^j $ is invariant under coordinate change,Show tensor  is invariant under coordinate change,g_{ij}A^iB^j ,"The components of a $(0,2)$ tensor is $(g_{ij})$ and the components of a $(1,0)$ tensor is $A^i,B^j$ . How can I show that the quantity (using Einstein summation convention) $$g_{ij}A^iB^j $$ is invariant?  So I want to show that the value does not change when coordinate systems are changed. One hint that the textbook gives me is to use the Kronecker delta, so I know that is: $$\sum_{i=1}^n \frac{\partial\bar{x}^i}{\partial x^j}\frac{\partial x^k}{\partial\bar{x}^i} = \delta_{j}^k$$","The components of a tensor is and the components of a tensor is . How can I show that the quantity (using Einstein summation convention) is invariant?  So I want to show that the value does not change when coordinate systems are changed. One hint that the textbook gives me is to use the Kronecker delta, so I know that is:","(0,2) (g_{ij}) (1,0) A^i,B^j g_{ij}A^iB^j  \sum_{i=1}^n \frac{\partial\bar{x}^i}{\partial x^j}\frac{\partial x^k}{\partial\bar{x}^i} = \delta_{j}^k","['differential-geometry', 'tensors', 'index-notation']"
38,Betti numbers of quotients of spheres by circle actions,Betti numbers of quotients of spheres by circle actions,,"Suppose $X=\mathbb{S}^{n+1}/\mathbb{S}^1$, the action of $\mathbb{S}^1$ being isometric and with closed orbits, and $n=\dim X$ (as an Alexandrov space) being even . My question is: Is is true that all odd Betti numbers of $X$ vanish? I know this is true when the action is almost free because in this case $X$ is a weighted projective space, by the classification of riemannian $1$-foliations on spheres, but i think there must be some simpler way to show this in general.","Suppose $X=\mathbb{S}^{n+1}/\mathbb{S}^1$, the action of $\mathbb{S}^1$ being isometric and with closed orbits, and $n=\dim X$ (as an Alexandrov space) being even . My question is: Is is true that all odd Betti numbers of $X$ vanish? I know this is true when the action is almost free because in this case $X$ is a weighted projective space, by the classification of riemannian $1$-foliations on spheres, but i think there must be some simpler way to show this in general.",,"['differential-geometry', 'algebraic-topology', 'group-actions', 'geometric-topology']"
39,How to find orthonormal frame of given metric?,How to find orthonormal frame of given metric?,,"I want to find the orthonormal frame associated to the following Riemann metric on $\Bbb R^5$: $$g=\begin{pmatrix} 1+y^2+t^2 & yw &t&0&-y\\yw& 1+w^2+t^2&0&t&-w\\ t&0&1&0&0\\ 0&t&0&1&0\\-y&-w&0&0&1 \end{pmatrix},$$ where $(x,y,z,w,t)$ is local coordinate chart. It is clear to me that $e_5=\frac{\partial}{\partial t},e_4=\frac{\partial}{\partial w},e_3=\frac{\partial}{\partial z}$ but I don't know how to compute the $e_1$ and $e_2$?","I want to find the orthonormal frame associated to the following Riemann metric on $\Bbb R^5$: $$g=\begin{pmatrix} 1+y^2+t^2 & yw &t&0&-y\\yw& 1+w^2+t^2&0&t&-w\\ t&0&1&0&0\\ 0&t&0&1&0\\-y&-w&0&0&1 \end{pmatrix},$$ where $(x,y,z,w,t)$ is local coordinate chart. It is clear to me that $e_5=\frac{\partial}{\partial t},e_4=\frac{\partial}{\partial w},e_3=\frac{\partial}{\partial z}$ but I don't know how to compute the $e_1$ and $e_2$?",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'tensors', 'maple']"
40,Does positive Ricci curvature tensor on an orthonormal frame imply positive Ricci curvature tensor?,Does positive Ricci curvature tensor on an orthonormal frame imply positive Ricci curvature tensor?,,"Let $(M,g)$ be a Riemannian manifold and $Ric$ its Ricci curvature. Let $\{e_1,\cdots, e_n\}$ be specific orthonormal frame and in this frame we have: $$Ric(e_i,e_i)>0\quad \forall i=1,...,n$$ My question is Does this condition imply positive Ricci curvature tensor?i.e., $Ric(X,X)>0$ for all vector field $X$?","Let $(M,g)$ be a Riemannian manifold and $Ric$ its Ricci curvature. Let $\{e_1,\cdots, e_n\}$ be specific orthonormal frame and in this frame we have: $$Ric(e_i,e_i)>0\quad \forall i=1,...,n$$ My question is Does this condition imply positive Ricci curvature tensor?i.e., $Ric(X,X)>0$ for all vector field $X$?",,"['differential-geometry', 'riemannian-geometry']"
41,Tangent bundle of the quotient of matrix Lie groups,Tangent bundle of the quotient of matrix Lie groups,,"Let $G:=GL^+(n)$ (all invertible $n \times n$-matrices with positive determinant) and $K:=SO(n)$. Let $\mathfrak{g}, \mathfrak{k}$ denote their Lie algebras and $E:=\mathfrak{g}/\mathfrak{k}$. I would like to understand Why the (total space of) tangent space $T(G/K)$ of $G/K$ can be identified with $(G \times E)/K$. Some facts which are familiar for me: 0. $K$ acts on $E$ via adjoint representation and on $G$ via group multiplication. Thus one has a diagonal action of $K$ on $G \times E$ i.e. $a \cdot (g,x):=(ag,ad(a)x)$. I guess that $(G \times E)/K$ should be understood using this action. 1. if $G$ acts in such a way that $M/G$ is a manifold then we have a canonical identification for $x \in M$: $$T_xM/T_x(G \cdot x) \cong T_{\pi(x)}(M/G)$$ where $G \cdot x$ is the orbit of $x$ and $\pi$ is the canonical projection. In our case we have for $g \in G$: $$T_gG/T_g(K \cdot g) \cong T_{\pi(g)}(G/K).$$ Since this correspondence is canonical it should give rise to vector bundles isomorphism (but which bundles?). 2. Lie groups are parallelisable thus $TG \cong G \times \mathfrak{g}, TK \cong K \times \mathfrak{k}$.","Let $G:=GL^+(n)$ (all invertible $n \times n$-matrices with positive determinant) and $K:=SO(n)$. Let $\mathfrak{g}, \mathfrak{k}$ denote their Lie algebras and $E:=\mathfrak{g}/\mathfrak{k}$. I would like to understand Why the (total space of) tangent space $T(G/K)$ of $G/K$ can be identified with $(G \times E)/K$. Some facts which are familiar for me: 0. $K$ acts on $E$ via adjoint representation and on $G$ via group multiplication. Thus one has a diagonal action of $K$ on $G \times E$ i.e. $a \cdot (g,x):=(ag,ad(a)x)$. I guess that $(G \times E)/K$ should be understood using this action. 1. if $G$ acts in such a way that $M/G$ is a manifold then we have a canonical identification for $x \in M$: $$T_xM/T_x(G \cdot x) \cong T_{\pi(x)}(M/G)$$ where $G \cdot x$ is the orbit of $x$ and $\pi$ is the canonical projection. In our case we have for $g \in G$: $$T_gG/T_g(K \cdot g) \cong T_{\pi(g)}(G/K).$$ Since this correspondence is canonical it should give rise to vector bundles isomorphism (but which bundles?). 2. Lie groups are parallelisable thus $TG \cong G \times \mathfrak{g}, TK \cong K \times \mathfrak{k}$.",,"['differential-geometry', 'lie-groups', 'lie-algebras', 'vector-bundles', 'tangent-bundle']"
42,Converse of the fundamental theorem of Riemannian geometry?,Converse of the fundamental theorem of Riemannian geometry?,,"The fundamental theorem of Riemannian geometry says that for a manifold with a given metric, there is a unique torsion-free connection. Suppose instead that we are given a connection. According to answers to this question , a metric exists that induces that connection.  How much non-uniqueness is there in the metric? It seems that there is at least an ambiguity up to a constant factor, because if the connection is metric-compatible with the metric $g$ (i.e., $\nabla g=0$), then it's also compatible with $cg$. Does any of this change in the semi-Riemannian case?","The fundamental theorem of Riemannian geometry says that for a manifold with a given metric, there is a unique torsion-free connection. Suppose instead that we are given a connection. According to answers to this question , a metric exists that induces that connection.  How much non-uniqueness is there in the metric? It seems that there is at least an ambiguity up to a constant factor, because if the connection is metric-compatible with the metric $g$ (i.e., $\nabla g=0$), then it's also compatible with $cg$. Does any of this change in the semi-Riemannian case?",,[]
43,Is there a notion of a smallest (immersed) Lie subgroup containing a given set?,Is there a notion of a smallest (immersed) Lie subgroup containing a given set?,,"Let $G$ be a Lie group, $S \subseteq G$. Is there a smallest Lie subgroup of $G$ containing $S$? (i.e a Lie subgroup $H$ which is contained in every Lie subgroup which contains $S$). We need to distinguish between two cases: If we talk about embedded (equivalently closed ) Lie subgroups, then the answer is positive: Take $\tilde H=\cap \{H \, \, | \, \, H \text{  is a closed Lie subgroup of $G$ which contains $S$}\}$. Then $\tilde H$ is a closed subgroup, hence (by the closed subgroup theorem), it is a closed (embedded) Lie subgroup of $G$, so we are done. What happens if we allow immersed Lie subgroups? The definition I am using is that $H \le G$ is a Lie subgroup, if it is a subgroup endowed with some topology and smooth structure, making it a Lie group, and an immersed submanifold of $G$. Now if we try to repeat the ""intersection construction"" (with immersed subgroups), the result is a group, but it's not clear that it is an immersed submanifold. Is there in fact an example where the intersection won't be a Lie subgroup?","Let $G$ be a Lie group, $S \subseteq G$. Is there a smallest Lie subgroup of $G$ containing $S$? (i.e a Lie subgroup $H$ which is contained in every Lie subgroup which contains $S$). We need to distinguish between two cases: If we talk about embedded (equivalently closed ) Lie subgroups, then the answer is positive: Take $\tilde H=\cap \{H \, \, | \, \, H \text{  is a closed Lie subgroup of $G$ which contains $S$}\}$. Then $\tilde H$ is a closed subgroup, hence (by the closed subgroup theorem), it is a closed (embedded) Lie subgroup of $G$, so we are done. What happens if we allow immersed Lie subgroups? The definition I am using is that $H \le G$ is a Lie subgroup, if it is a subgroup endowed with some topology and smooth structure, making it a Lie group, and an immersed submanifold of $G$. Now if we try to repeat the ""intersection construction"" (with immersed subgroups), the result is a group, but it's not clear that it is an immersed submanifold. Is there in fact an example where the intersection won't be a Lie subgroup?",,"['differential-geometry', 'differential-topology', 'lie-groups', 'smooth-manifolds']"
44,1-Forms on $SO(3)$ and $S^2$,1-Forms on  and,SO(3) S^2,"The is a mistake somewhere in the following reasoning and I can't seem to detect which argument is wrong. Consider the lie group $SO(3)$ with $e_{1},e_{2},e_{3}$ as left invariant vector fields. Each of which generates an $S^1$ action. Quotienting by any one of these $S^1$ actions (say $e_1$), I should get a 2-sphere, $S^2$. Now the dual 1-forms, $e^2$ and $e^3$ are left invariant 1-forms and horizontal with respect to this quotient. So they should pass to the quotient space i.e. $S^2$. Now my problem is that these 1-forms are globally well-defined and nowhere vanishing on $S^2$ which contradicts the Hairy ball theorem.","The is a mistake somewhere in the following reasoning and I can't seem to detect which argument is wrong. Consider the lie group $SO(3)$ with $e_{1},e_{2},e_{3}$ as left invariant vector fields. Each of which generates an $S^1$ action. Quotienting by any one of these $S^1$ actions (say $e_1$), I should get a 2-sphere, $S^2$. Now the dual 1-forms, $e^2$ and $e^3$ are left invariant 1-forms and horizontal with respect to this quotient. So they should pass to the quotient space i.e. $S^2$. Now my problem is that these 1-forms are globally well-defined and nowhere vanishing on $S^2$ which contradicts the Hairy ball theorem.",,"['differential-geometry', 'lie-groups', 'homogeneous-spaces', 'cartan-geometry']"
45,Any quaternion Kählerian manifold of dimension $\geq 8$ is an Einstein space?,Any quaternion Kählerian manifold of dimension  is an Einstein space?,\geq 8,"I wan't to understand the proof this theorem: Any quaternion Kählerian manifold of dimension $\geq 8$ is an Einstein space. In the book ""Structures on manifolds"" by Kentaro Yano and Masahiro Kon is said that this fact is a corollary of these $2$ lemmas. Lemma $1.$ For any quaternion Kählerian manifold $M$ of dimension   $n \geq 8$, the Ricci tensor $S$ of $M$ is parallel. Lemma $2.$ Let $(M,g,V)$ be a quaternion Kählerian manifold of   dimension $\geq 8$. Then the Riemannian manifold $(M,g)$ is irreducible if   $(M,g)$ has non-vanishing Ricci tensor. However I can't see directly how to use them to prove the theorem using the lemmas, neither is it written in the book. Can someone please help me with that. Or tell me where can I read more detailed proof of the theorem? Thanks in advance!","I wan't to understand the proof this theorem: Any quaternion Kählerian manifold of dimension $\geq 8$ is an Einstein space. In the book ""Structures on manifolds"" by Kentaro Yano and Masahiro Kon is said that this fact is a corollary of these $2$ lemmas. Lemma $1.$ For any quaternion Kählerian manifold $M$ of dimension   $n \geq 8$, the Ricci tensor $S$ of $M$ is parallel. Lemma $2.$ Let $(M,g,V)$ be a quaternion Kählerian manifold of   dimension $\geq 8$. Then the Riemannian manifold $(M,g)$ is irreducible if   $(M,g)$ has non-vanishing Ricci tensor. However I can't see directly how to use them to prove the theorem using the lemmas, neither is it written in the book. Can someone please help me with that. Or tell me where can I read more detailed proof of the theorem? Thanks in advance!",,"['differential-geometry', 'riemannian-geometry', 'quaternions', 'kahler-manifolds']"
46,Existence and Uniqueness of Geodesics,Existence and Uniqueness of Geodesics,,"I'm reading the theorem 4.10 of the book ""Riemannian manifolds"" by John Lee. In proof, page 58, the author refers to the existence and uniqueness theorem for first-order ODEs [Boo86, Theorem IV.4.1]. Also in page 60, theorem 4.12 is about the Existence and Uniqueness for Linear ODEs. I want to know if this two theorem are the same? Is there any difference between them? Thanks!","I'm reading the theorem 4.10 of the book ""Riemannian manifolds"" by John Lee. In proof, page 58, the author refers to the existence and uniqueness theorem for first-order ODEs [Boo86, Theorem IV.4.1]. Also in page 60, theorem 4.12 is about the Existence and Uniqueness for Linear ODEs. I want to know if this two theorem are the same? Is there any difference between them? Thanks!",,"['differential-geometry', 'manifolds']"
47,"Reference for Universal covering of $Sp(2n,\mathbb{R})$?",Reference for Universal covering of ?,"Sp(2n,\mathbb{R})","Does anyone know any reference that treat $Sp(2n,\mathbb{R})$ detailedly? For $Sp(2n,\mathbb{R})$, I mean the subgroup of $GL(2n,\mathbb{R})$ that preserves the standard symplectic form $\sum_{i=0}^n dx_i \wedge dy_i$ on $\mathbb{R}^{2n}$. The Wikipedia or nLab pages state that $\pi_1 (Sp(2n,\mathbb{R}))\cong \mathbb{Z}$ without a proof. I guess this probably follows from some fibration but I cannot find reference for it. Also, does anyone know if there's a concrete geometric construction of the universal covering $\widetilde{Sp(2n,\mathbb{R})}$? Thank you.","Does anyone know any reference that treat $Sp(2n,\mathbb{R})$ detailedly? For $Sp(2n,\mathbb{R})$, I mean the subgroup of $GL(2n,\mathbb{R})$ that preserves the standard symplectic form $\sum_{i=0}^n dx_i \wedge dy_i$ on $\mathbb{R}^{2n}$. The Wikipedia or nLab pages state that $\pi_1 (Sp(2n,\mathbb{R}))\cong \mathbb{Z}$ without a proof. I guess this probably follows from some fibration but I cannot find reference for it. Also, does anyone know if there's a concrete geometric construction of the universal covering $\widetilde{Sp(2n,\mathbb{R})}$? Thank you.",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'lie-groups', 'symplectic-geometry']"
48,Space curve of Trefoil knot made of ideal flexible nonstretchable steel wire.,Space curve of Trefoil knot made of ideal flexible nonstretchable steel wire.,,"What space curve defines a Trefoil knot made of ideal flexible nonstretchable steel wire? By ideal flexible nonstretchable steel wire I mean wire that meets this requirements: a wire cannot shorten or extend but can be bend without limit a wire tends to straighten itself in every point a wire has zero friction with itself. Curve can be defined explicitly, implicitly, parametrized or numerically. EDIT: I uploaded an example of torus knot made of steel wire to show that the shape is unique. You can squeeze it and it returns into the same shape (of course the wire is real world and not ideal, but you can get the idea).","What space curve defines a Trefoil knot made of ideal flexible nonstretchable steel wire? By ideal flexible nonstretchable steel wire I mean wire that meets this requirements: a wire cannot shorten or extend but can be bend without limit a wire tends to straighten itself in every point a wire has zero friction with itself. Curve can be defined explicitly, implicitly, parametrized or numerically. EDIT: I uploaded an example of torus knot made of steel wire to show that the shape is unique. You can squeeze it and it returns into the same shape (of course the wire is real world and not ideal, but you can get the idea).",,['differential-geometry']
49,Differential Geometry and Categories,Differential Geometry and Categories,,"Is there such a thing as a category of manifolds? If so what is the functor from that category to the one of vector spaces? (It seems natural that this would correspond to the push-forwards), sounds like a free functor somehow but I have not been able to find sufficiently good treatments on that. Also any good references combining differential geometry and category theory would be appreciated.","Is there such a thing as a category of manifolds? If so what is the functor from that category to the one of vector spaces? (It seems natural that this would correspond to the push-forwards), sounds like a free functor somehow but I have not been able to find sufficiently good treatments on that. Also any good references combining differential geometry and category theory would be appreciated.",,"['differential-geometry', 'category-theory']"
50,Reparametrization of a curve,Reparametrization of a curve,,"Given a parametrized curve, we know that its arc length parametrization is its unit speed reparametrization. However, I wanted to know if there was any generic procedure to find any other reparametrizations of the same curve, which are not unit speed, and are non trivial?","Given a parametrized curve, we know that its arc length parametrization is its unit speed reparametrization. However, I wanted to know if there was any generic procedure to find any other reparametrizations of the same curve, which are not unit speed, and are non trivial?",,"['calculus', 'differential-geometry', 'vector-analysis']"
51,What does it mean intuitively for a metric and connection to be compatible?,What does it mean intuitively for a metric and connection to be compatible?,,"In General relativity, the metric tensor that satisfies Einstein's equations induces the Levi-Civita connection of that metric. It is said that this connection is somehow ""compatible"" with the metric. Technically Im told this means that straight lines (according to the connection) coincide with geodesics (according to the metric). However, this seems like an arbitrarily restrictive assumption from a mathematical point of view. Shouldn't it be possible for a single specific metric manifold with connection to have straight lines that are not necessarily geodesics? Why not? So my main question is: what does this notion of ""compatibility"" of metric and connection really mean intuitively? Does it mean there cannot exist a metric manifold with connection whose metric and connection are incompatible? (I.e. is it a necessary condition?). Why is the intuitiv enotion of ""compatibilty"" captured formally by the ""straight lines = geodesics"" criterium?","In General relativity, the metric tensor that satisfies Einstein's equations induces the Levi-Civita connection of that metric. It is said that this connection is somehow ""compatible"" with the metric. Technically Im told this means that straight lines (according to the connection) coincide with geodesics (according to the metric). However, this seems like an arbitrarily restrictive assumption from a mathematical point of view. Shouldn't it be possible for a single specific metric manifold with connection to have straight lines that are not necessarily geodesics? Why not? So my main question is: what does this notion of ""compatibility"" of metric and connection really mean intuitively? Does it mean there cannot exist a metric manifold with connection whose metric and connection are incompatible? (I.e. is it a necessary condition?). Why is the intuitiv enotion of ""compatibilty"" captured formally by the ""straight lines = geodesics"" criterium?",,"['differential-geometry', 'riemannian-geometry', 'intuition', 'general-relativity', 'connections']"
52,Lie's theorem about infinitesimal rigid motions and riemannian manifolds curvature,Lie's theorem about infinitesimal rigid motions and riemannian manifolds curvature,,"The theorem states that in a Riemannian connected finite dimensional manifold of 3 dimensions the existence of a 6-dimensional group of local isometries that determine infinitesimal rigid displacements implies that this manifold must possess a constant curva­ture(one can read the complete statement and proofs in Lie's ""Theorie der Transformationsgruppen, Vol. 3""). I'm interested in the conclusions one can derive from this restriction, for instance does this theorem imply some sort of limitation on Riemannian manifolds of variable curvature with respect to the existence of stationary points of functionals(variational principles) on the manifold? Added: To be more specific, if we use the language of principal G-bundles and consider a tangent frame bundle with the total space as the group of local isometries, the fiber G the point-stabilizer group and the base manifold that on wich the isometry group acts,  does this theorem limit the maximum number of dimensions of the total space to 6 for a 3-dimensional base manifold and to a finite number for any finite-dimensional base manifold? Also, do the infinitesimal rigid motions expressed by the local isometry group in a Riemannian manifold determine the maximum number of dimensions of the group of symmetries, defined as vanishing functional derivatives and corresponding Euler-Lagrange equations routinely used in multidimensional calculus of variations, of any objects defined on the manifold that undergo such rigid motions?","The theorem states that in a Riemannian connected finite dimensional manifold of 3 dimensions the existence of a 6-dimensional group of local isometries that determine infinitesimal rigid displacements implies that this manifold must possess a constant curva­ture(one can read the complete statement and proofs in Lie's ""Theorie der Transformationsgruppen, Vol. 3""). I'm interested in the conclusions one can derive from this restriction, for instance does this theorem imply some sort of limitation on Riemannian manifolds of variable curvature with respect to the existence of stationary points of functionals(variational principles) on the manifold? Added: To be more specific, if we use the language of principal G-bundles and consider a tangent frame bundle with the total space as the group of local isometries, the fiber G the point-stabilizer group and the base manifold that on wich the isometry group acts,  does this theorem limit the maximum number of dimensions of the total space to 6 for a 3-dimensional base manifold and to a finite number for any finite-dimensional base manifold? Also, do the infinitesimal rigid motions expressed by the local isometry group in a Riemannian manifold determine the maximum number of dimensions of the group of symmetries, defined as vanishing functional derivatives and corresponding Euler-Lagrange equations routinely used in multidimensional calculus of variations, of any objects defined on the manifold that undergo such rigid motions?",,"['differential-geometry', 'lie-groups', 'calculus-of-variations']"
53,Equivalent definition of orientability,Equivalent definition of orientability,,"I came across the following definition of orientability. Let $O$ be the ""$0$-section"" of the exterior n-bundle $\Lambda^nM^*$   with $M$ being a connected differentiable manifold of dimension $n$.   It is said that $M$ is orientable if $\Lambda^nM^* \smallsetminus O$   has two components; an orientation is a choice of one of the two   components of $\Lambda^nM^* \smallsetminus O$. It is said that $M$ is   non-orientable if $\Lambda^nM^* \smallsetminus O$ is connected. Now, this seems like a really good definition. But I have a problem understanding how it is equivalent to saying that an orientable manifold $M$ admits a nowhere-vanishing smooth $n$-form . In particular, if the definitions are to be equivalent, the following statement must be true. $$ \Gamma(\Lambda^nM^* \smallsetminus O) = \varnothing \Leftrightarrow \Lambda^nM^* \smallsetminus O \text{ is connected}$$ I don't see why that should be the case. For example, I could take a Möbius band (which can be seen as the $2$-dimensional cotangent bundle over the $1$-dimensional Möbius circle) and start cutting through it without touching the base circle (say a constant $2 cm$. off of it). I would go around twice before completing the section. So I do have a smooth non-vanishing $1$-form here, although I believe it is supposed to be non-orientable by the given definition. Another example could be an exterior $n$-bundle which has the topology of a torus (does that exist?) which clearly admits a smooth section of $\Lambda^nM^* \smallsetminus O$.","I came across the following definition of orientability. Let $O$ be the ""$0$-section"" of the exterior n-bundle $\Lambda^nM^*$   with $M$ being a connected differentiable manifold of dimension $n$.   It is said that $M$ is orientable if $\Lambda^nM^* \smallsetminus O$   has two components; an orientation is a choice of one of the two   components of $\Lambda^nM^* \smallsetminus O$. It is said that $M$ is   non-orientable if $\Lambda^nM^* \smallsetminus O$ is connected. Now, this seems like a really good definition. But I have a problem understanding how it is equivalent to saying that an orientable manifold $M$ admits a nowhere-vanishing smooth $n$-form . In particular, if the definitions are to be equivalent, the following statement must be true. $$ \Gamma(\Lambda^nM^* \smallsetminus O) = \varnothing \Leftrightarrow \Lambda^nM^* \smallsetminus O \text{ is connected}$$ I don't see why that should be the case. For example, I could take a Möbius band (which can be seen as the $2$-dimensional cotangent bundle over the $1$-dimensional Möbius circle) and start cutting through it without touching the base circle (say a constant $2 cm$. off of it). I would go around twice before completing the section. So I do have a smooth non-vanishing $1$-form here, although I believe it is supposed to be non-orientable by the given definition. Another example could be an exterior $n$-bundle which has the topology of a torus (does that exist?) which clearly admits a smooth section of $\Lambda^nM^* \smallsetminus O$.",,"['differential-geometry', 'smooth-manifolds']"
54,Spline interpolation in SE(3),Spline interpolation in SE(3),,"Given: a sequence ${A_i}_{i=1}^n$ of elements of the special Euclidean group, $SE(3)$; a sequence of times ${t_i}_{i=1}^n$, where $t_1 \leq t_2 \leq ... \leq t_n$; instantaneous body frame velocity given by a twist $v\in se(3)$ at time $t_1$ instantaneous body frame acceleration $\alpha$ at time $t_1$ I would like to find an interpolating curve $f(t) \in SE(3)$ that is twice differentiable such that $f(t_i) = A_i$ and $f'(t_1) = v$ and $f''(t_1) = \alpha$. One approach, as suggested by [1], is: Compute $\xi_1, ..., \xi_n \in se(3)$ where $\xi_i = \log(A_1^{-1} A_i)$. Compute an interpolating curve (e.g. using a B-spline) $\gamma(t)$ in Euclidean space $\mathbb R^6$ such that $\gamma(t_i) = \xi_i$. Then, the interpolating curve is $f(t) = A_1 \exp(\gamma(t))$. Unfortunately, this doesn't work well in most places except for a small neighbourhood around $A_1$, because $\exp$ i s a surjective map from $se(3)$ to $SE(3)$. For example, if we interpret the angular part of $\xi$ as an axis-angle representation in $so(3)$, you can flip the sign on the axis and replace the angle $\theta$ with $2\pi - \theta$ and it would represent the same element in $SO(3)$. As a consequence, if some elements $A_i$, $A_{i+1}$ happen to be close together in $SE(3)$ but cross over the $\pi$ threshold, $\xi_i$ and $\xi_{i+1}$ may not be close together in $\mathbb R^6$ and the interpolating curve may take an additional rotation than what would be ""natural"". An alternative is to interpolate separately in rotation and translation. However, most rotation formalisms fail in some case. For example, Gibbs vectors (used by [2]) suffer from the drawback that $180^\circ$ rotations cannot be represented. Quaternions (used by [3]) also have a sign ambiguity, so two elements close together in $SO(3)$ are also not guaranteed to be close in quaternion space. Also, an interpolating function in $\mathbb R^4$ may not be normalized in general, and may become singular if it passes through zero (though it is unlikely). I have no idea how the authors in the cited papers overcome these issues. Besides, using the exponential map is most natural when dealing with nonlinear optimization on the manifold, since the derivatives are easy to compute. Some help and insights for tackling this problem or working around the drawbacks would be appreciated. [1] Žefran, M., & Kumar, V. (1998). Interpolation schemes for rigid body motions. Computer-Aided Design, 30(3), 179-189 [2] Alismail, H., Baker, L. D., & Browning, B. (2014, May). Continuous trajectory estimation for 3D SLAM from actuated lidar. In 2014 IEEE International Conference on Robotics and Automation (ICRA) (pp. 6096-6101). IEEE. [3] Zlot, R., & Bosse, M. (2014). Efficient Large‐scale Three‐dimensional Mobile Mapping for Underground Mines. Journal of Field Robotics, 31(5), 758-779.","Given: a sequence ${A_i}_{i=1}^n$ of elements of the special Euclidean group, $SE(3)$; a sequence of times ${t_i}_{i=1}^n$, where $t_1 \leq t_2 \leq ... \leq t_n$; instantaneous body frame velocity given by a twist $v\in se(3)$ at time $t_1$ instantaneous body frame acceleration $\alpha$ at time $t_1$ I would like to find an interpolating curve $f(t) \in SE(3)$ that is twice differentiable such that $f(t_i) = A_i$ and $f'(t_1) = v$ and $f''(t_1) = \alpha$. One approach, as suggested by [1], is: Compute $\xi_1, ..., \xi_n \in se(3)$ where $\xi_i = \log(A_1^{-1} A_i)$. Compute an interpolating curve (e.g. using a B-spline) $\gamma(t)$ in Euclidean space $\mathbb R^6$ such that $\gamma(t_i) = \xi_i$. Then, the interpolating curve is $f(t) = A_1 \exp(\gamma(t))$. Unfortunately, this doesn't work well in most places except for a small neighbourhood around $A_1$, because $\exp$ i s a surjective map from $se(3)$ to $SE(3)$. For example, if we interpret the angular part of $\xi$ as an axis-angle representation in $so(3)$, you can flip the sign on the axis and replace the angle $\theta$ with $2\pi - \theta$ and it would represent the same element in $SO(3)$. As a consequence, if some elements $A_i$, $A_{i+1}$ happen to be close together in $SE(3)$ but cross over the $\pi$ threshold, $\xi_i$ and $\xi_{i+1}$ may not be close together in $\mathbb R^6$ and the interpolating curve may take an additional rotation than what would be ""natural"". An alternative is to interpolate separately in rotation and translation. However, most rotation formalisms fail in some case. For example, Gibbs vectors (used by [2]) suffer from the drawback that $180^\circ$ rotations cannot be represented. Quaternions (used by [3]) also have a sign ambiguity, so two elements close together in $SO(3)$ are also not guaranteed to be close in quaternion space. Also, an interpolating function in $\mathbb R^4$ may not be normalized in general, and may become singular if it passes through zero (though it is unlikely). I have no idea how the authors in the cited papers overcome these issues. Besides, using the exponential map is most natural when dealing with nonlinear optimization on the manifold, since the derivatives are easy to compute. Some help and insights for tackling this problem or working around the drawbacks would be appreciated. [1] Žefran, M., & Kumar, V. (1998). Interpolation schemes for rigid body motions. Computer-Aided Design, 30(3), 179-189 [2] Alismail, H., Baker, L. D., & Browning, B. (2014, May). Continuous trajectory estimation for 3D SLAM from actuated lidar. In 2014 IEEE International Conference on Robotics and Automation (ICRA) (pp. 6096-6101). IEEE. [3] Zlot, R., & Bosse, M. (2014). Efficient Large‐scale Three‐dimensional Mobile Mapping for Underground Mines. Journal of Field Robotics, 31(5), 758-779.",,"['differential-geometry', 'lie-groups', 'lie-algebras', 'interpolation', 'rigid-transformation']"
55,How can one define parallel transport on lie groups?,How can one define parallel transport on lie groups?,,"I want to transport a tangent vector $T_p$ at a point $p$ to some other point $q$ on a lie group. Do I have to use $log(p^{-1}q)$, which is also a tangent vector, to achieve the same?","I want to transport a tangent vector $T_p$ at a point $p$ to some other point $q$ on a lie group. Do I have to use $log(p^{-1}q)$, which is also a tangent vector, to achieve the same?",,"['differential-geometry', 'manifolds', 'lie-groups', 'lie-algebras']"
56,Maurer-Cartan form and left-invariant vector fields,Maurer-Cartan form and left-invariant vector fields,,"A left-invariant vector field on a Lie group $G$ satisfies $$ (L_g)_*X = X $$ for all $g\in G$. So we have in particular $\omega(X_p)=(L_{g^{-1}})X_p=X_e$ with $\omega$ the Maurer-Cartan form on $G$. Please have a look at this derivation of the Maurer-Cartan equation . It says that if $X$ and $Y$ are left-invariant vector fields, then they satisfy $$\tag{1}X(\omega(Y))=Y(\omega(X))=0$$ Why is that true? I only get $$ X(\omega(Y))=X(Y)=[X,Y] $$ so $$ X(\omega(Y))-Y(\omega(X))=X(Y)-Y(X)=[X,Y]-[Y,X]=2[X,Y] $$","A left-invariant vector field on a Lie group $G$ satisfies $$ (L_g)_*X = X $$ for all $g\in G$. So we have in particular $\omega(X_p)=(L_{g^{-1}})X_p=X_e$ with $\omega$ the Maurer-Cartan form on $G$. Please have a look at this derivation of the Maurer-Cartan equation . It says that if $X$ and $Y$ are left-invariant vector fields, then they satisfy $$\tag{1}X(\omega(Y))=Y(\omega(X))=0$$ Why is that true? I only get $$ X(\omega(Y))=X(Y)=[X,Y] $$ so $$ X(\omega(Y))-Y(\omega(X))=X(Y)-Y(X)=[X,Y]-[Y,X]=2[X,Y] $$",,"['differential-geometry', 'lie-groups', 'differential-forms']"
57,Can linear connections other than Levi-Civita connections be useful?,Can linear connections other than Levi-Civita connections be useful?,,Consider a smooth Riemann manifold such that a Levi-Civita connection is defined. I am wondering whether there are examples in mathematics or physics where the use of other linear connections is useful despite the fact that a Levi-Civita connection is available.,Consider a smooth Riemann manifold such that a Levi-Civita connection is defined. I am wondering whether there are examples in mathematics or physics where the use of other linear connections is useful despite the fact that a Levi-Civita connection is available.,,['differential-geometry']
58,A question on the non trivial rank three bundle on $S^2$,A question on the non trivial rank three bundle on,S^2,"We know that number of rank $3$ vector bundles on $S^2$ is just the number of equivalence classes of maps from $S^1$ to $SO(3)$. This implies that there is one and only one non trivial vector bundle on $S^2$. Also we know that this rank $3$ vector bundle can be written as a whitney sum of a rank $2$ and trivial line bundle. Now I was wondering which rank $2$ vector bundles on $S^2$ when added to a trivial line bundle yield the non trivial bundle. My try: There are an integer number of rank $2$ vector bundles. We know the trivial bundle and the tangent bundle do not give a non trivial bundle. Also I calculated the clutching function for the tangent bundle, I got it as $z \to z^2$ after doing the identification of $SO(2)$ with $S^1$. So I am guessing that all odd degree clutching functions give a non trivial bundle and the even ones give a trivial bundle. I am confused as to how one proves this. Thanks.","We know that number of rank $3$ vector bundles on $S^2$ is just the number of equivalence classes of maps from $S^1$ to $SO(3)$. This implies that there is one and only one non trivial vector bundle on $S^2$. Also we know that this rank $3$ vector bundle can be written as a whitney sum of a rank $2$ and trivial line bundle. Now I was wondering which rank $2$ vector bundles on $S^2$ when added to a trivial line bundle yield the non trivial bundle. My try: There are an integer number of rank $2$ vector bundles. We know the trivial bundle and the tangent bundle do not give a non trivial bundle. Also I calculated the clutching function for the tangent bundle, I got it as $z \to z^2$ after doing the identification of $SO(2)$ with $S^1$. So I am guessing that all odd degree clutching functions give a non trivial bundle and the even ones give a trivial bundle. I am confused as to how one proves this. Thanks.",,"['differential-geometry', 'algebraic-topology', 'differential-topology', 'homotopy-theory']"
59,Divergent Curves and Complete Manifolds,Divergent Curves and Complete Manifolds,,"I'm working on a problem in do Carmo's Riemannian geometry book (chapter 7, problem 5). He states that a divergent curve on a noncompact Riemannian manifold $M$ is a curve $\alpha: [0, \infty) \to M$ where given any compact $K \subset M$ we have there exists $T>0$ such that $\alpha(t) \not\in K$ for $t>T$.  Subsequently the length is defined in the usual sense for curves on a manifold: $$ L(\alpha) \;\; =\;\; \int_0^\infty ||\alpha'(t)|| dt. $$ The problem I'm trying to prove is Prove that a noncompact manifold is complete if and only if every divergent curve has unbounded (i.e. infinite) length. The ""forwards"" direction of the proof is easy; I'm having trouble with the other direction.  If I assume that every divergent curve $\alpha$ has infinite length, how do I show completeness of the manifold?  I'm borrowing one strategy from MIT OCW but I don't totally agree with their proof.  They claim that we can start with some arbitrary geodesic $\gamma:[0,\epsilon) \to M$ and assume that such a geodesic cannot be extended to the interval $[0,\infty)$.  The set $R$ of points $x$ on which $\gamma$ can be extended to $[0,x)$ is nonempty and bounded above, thus let $s = \sup R$.  Define a re-parameterization $\alpha(t) = \gamma(s(1-e^{-t}))$, which is defined on $[0,\infty)$ but is of finite length.  If we can show that $\alpha$ is a divergent curve we are done. The problem I have with the proof in the link is that they claim that $\gamma$ approaches a point on the ""boundary"" of $M$, but I find this claim problematic since it's not clear how to define a boundary unless $M$ is embedded/immersed in some ambient space.  Ultimately I would like to show that $\alpha$ escapes every compact subset of $M$, but I'm starting to think this proof might be problematic. Can anyone suggest a way to amend the above proof as stated, or provide an alternate proof strategy?","I'm working on a problem in do Carmo's Riemannian geometry book (chapter 7, problem 5). He states that a divergent curve on a noncompact Riemannian manifold $M$ is a curve $\alpha: [0, \infty) \to M$ where given any compact $K \subset M$ we have there exists $T>0$ such that $\alpha(t) \not\in K$ for $t>T$.  Subsequently the length is defined in the usual sense for curves on a manifold: $$ L(\alpha) \;\; =\;\; \int_0^\infty ||\alpha'(t)|| dt. $$ The problem I'm trying to prove is Prove that a noncompact manifold is complete if and only if every divergent curve has unbounded (i.e. infinite) length. The ""forwards"" direction of the proof is easy; I'm having trouble with the other direction.  If I assume that every divergent curve $\alpha$ has infinite length, how do I show completeness of the manifold?  I'm borrowing one strategy from MIT OCW but I don't totally agree with their proof.  They claim that we can start with some arbitrary geodesic $\gamma:[0,\epsilon) \to M$ and assume that such a geodesic cannot be extended to the interval $[0,\infty)$.  The set $R$ of points $x$ on which $\gamma$ can be extended to $[0,x)$ is nonempty and bounded above, thus let $s = \sup R$.  Define a re-parameterization $\alpha(t) = \gamma(s(1-e^{-t}))$, which is defined on $[0,\infty)$ but is of finite length.  If we can show that $\alpha$ is a divergent curve we are done. The problem I have with the proof in the link is that they claim that $\gamma$ approaches a point on the ""boundary"" of $M$, but I find this claim problematic since it's not clear how to define a boundary unless $M$ is embedded/immersed in some ambient space.  Ultimately I would like to show that $\alpha$ escapes every compact subset of $M$, but I'm starting to think this proof might be problematic. Can anyone suggest a way to amend the above proof as stated, or provide an alternate proof strategy?",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'geodesic']"
60,Definition of formal adjoint of covariant derivative,Definition of formal adjoint of covariant derivative,,"I read in Einstein Manifolds, L. Besse that the covariant derivative $D: \mathcal{J}^{(r,s)}(M)\to \Omega^1(M)\otimes\mathcal{J}^{(r,s)}(M)$ admit an formal adjoint $D^*:\Omega^1(M)\otimes\mathcal{J}^{(r,s)}(M) \to \mathcal{J}^{(r,s)}(M)$ as follows: $$D^*T(X_1,\cdots,X_r)=-tr \{(X,Y)\to D_XT(Y,X_1,\cdots,X_r)\}$$ where $X_i$ s are vector field and $T\in \Omega^1(M)\otimes\mathcal{J}^{(r,s)}(M)$ . In general, for every linear differential operator(LDO) $D:\Gamma(E)\to\Gamma(F)$ where $E$ and $F$ are vector bundle over $M$ , admit a formal adjoint operator $D^*:\Gamma(F)\to\Gamma(E)$ defined by: $$\int_M\left<D\xi,\eta\right>dvol_g=\int_M\left<\xi,D^*\eta\right>dvol_g$$ where $\xi\in\Gamma(F), \eta\in\Gamma(E) $ with compact support. (Difinition 2.2) Question : Which of the above difinition is related to the following equation: $$\nabla^*\circ \nabla=-tr\nabla^2$$ and how can I prove this equation? Related: Formal adjoint of the covariant derivative","I read in Einstein Manifolds, L. Besse that the covariant derivative admit an formal adjoint as follows: where s are vector field and . In general, for every linear differential operator(LDO) where and are vector bundle over , admit a formal adjoint operator defined by: where with compact support. (Difinition 2.2) Question : Which of the above difinition is related to the following equation: and how can I prove this equation? Related: Formal adjoint of the covariant derivative","D: \mathcal{J}^{(r,s)}(M)\to \Omega^1(M)\otimes\mathcal{J}^{(r,s)}(M) D^*:\Omega^1(M)\otimes\mathcal{J}^{(r,s)}(M) \to \mathcal{J}^{(r,s)}(M) D^*T(X_1,\cdots,X_r)=-tr \{(X,Y)\to D_XT(Y,X_1,\cdots,X_r)\} X_i T\in \Omega^1(M)\otimes\mathcal{J}^{(r,s)}(M) D:\Gamma(E)\to\Gamma(F) E F M D^*:\Gamma(F)\to\Gamma(E) \int_M\left<D\xi,\eta\right>dvol_g=\int_M\left<\xi,D^*\eta\right>dvol_g \xi\in\Gamma(F), \eta\in\Gamma(E)  \nabla^*\circ \nabla=-tr\nabla^2","['differential-geometry', 'differential-operators', 'connections']"
61,How to find the transition function for two overlapping charts of $\mathbb{R}P^2$?,How to find the transition function for two overlapping charts of ?,\mathbb{R}P^2,"The real 2-dim projective space $\mathbb{R}P^2$ can be covered by the following 3 sets of unoriented lines through the origin un $\mathbb{R}^3$: $ U_x \doteq $ { all lines not lying in the yz plane} $ U_y \doteq $ { all lines not lying in the xz plane} $ U_y \doteq $ { all lines not lying in the xy plane} The lines $L$ belonging to these patches can be parameterized as $L \in U_x: (u_1 = \frac{y}{x}, u_2 = z/x)$ $L \in U_y: (u_1 = \frac{x}{y}, u_2 = z/y)$ $L \in U_z: (u_1 = \frac{x}{z}, u_2 = y/z)$ How can I fand the transitions between two of these charts, in order to for example investigate differentiability of $\mathbb{R}P^2$ as a 2-dim manifold? Or would I need to investigate the transition function for two coordinate descriptions of a singly line, that differ only by a scaling factor, for that purpose?","The real 2-dim projective space $\mathbb{R}P^2$ can be covered by the following 3 sets of unoriented lines through the origin un $\mathbb{R}^3$: $ U_x \doteq $ { all lines not lying in the yz plane} $ U_y \doteq $ { all lines not lying in the xz plane} $ U_y \doteq $ { all lines not lying in the xy plane} The lines $L$ belonging to these patches can be parameterized as $L \in U_x: (u_1 = \frac{y}{x}, u_2 = z/x)$ $L \in U_y: (u_1 = \frac{x}{y}, u_2 = z/y)$ $L \in U_z: (u_1 = \frac{x}{z}, u_2 = y/z)$ How can I fand the transitions between two of these charts, in order to for example investigate differentiability of $\mathbb{R}P^2$ as a 2-dim manifold? Or would I need to investigate the transition function for two coordinate descriptions of a singly line, that differ only by a scaling factor, for that purpose?",,"['differential-geometry', 'manifolds', 'projective-space']"
62,Orientability of the level set of a map between abstract oriented manifold,Orientability of the level set of a map between abstract oriented manifold,,"Let M and N be oriented manifold and let $f:M\to N$ be a smooth map between them. Suppose $y \in N$ is a regular value for $f$, how can we show that $f^{-1}(y)$ is orientable? I've seen a solution for the case $N = \mathbb{R}$, but I fail in generalizing that proof.","Let M and N be oriented manifold and let $f:M\to N$ be a smooth map between them. Suppose $y \in N$ is a regular value for $f$, how can we show that $f^{-1}(y)$ is orientable? I've seen a solution for the case $N = \mathbb{R}$, but I fail in generalizing that proof.",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
63,Correspondence between vector bundles and locally free sheaves,Correspondence between vector bundles and locally free sheaves,,"I am trying to look at smooth manifolds in the context of locally ringed spaces. Vector bundles have a characterization in terms of sheaves of modules: if $X, \mathcal{O}_X$ is a topological (or smooth) manifold along with its structure sheaf, then a locally free $\mathcal{O}_X$ module of rank $n$ is the same thing as a vector bundle over $X$ of rank $n$. You can read about the correspondence in Ramanan chapter 2, for instance. Now forget about manifolds for a second, and suppose that $X, \mathcal{O}_X$ is just a locally ringed space, where all the stalks have residue field $\mathbb{R}$, and that $\mathcal{E}$ is a locally free $\mathcal{O}_X$ module, and suppose I try to form a vector bundle out of it, in the same way mentioned in the link above. My Question: Given a locally ringed space $X, \mathcal{O}_X$, where each stalk has residue field $\mathbb{R}$, and an $\mathcal{O}_X$ module   $\mathcal{E}$ which is locally free of rank $n$, how can I construct a   vector bundle from this information? Here is my attempt, and you can see where I run into problems. Attempt 1: (Via a basis) I'm trying to define a topology, so I may as well work locally. After passing to a smaller open set, I can assume that $\mathcal{E}\cong (\mathcal{O}_X)^n$ as $\mathcal{O}_X$ modules. (Then later I should worry about transition functions and stuff, but you'll see I don't even get that far.) As a set, my vector bundle $E$ will be the elements $\bigcup\limits_{x\in U} (\mathcal{E}_x/\mathfrak{m}_x\mathcal{E}_x)$, where $\mathfrak{m}_x \triangleleft \mathcal{O}_{X, x}$ is the maximal ideal. Now I topologize it by taking a basis for $\mathcal{E}$: suppose $\mathcal{E}(X)$ has a basis over $\mathcal{O}_X(X)$ given by $\mu^1, \dotsc, \mu^n$, and suppose I take as my basis for each $\mathcal{E}_x/\mathfrak{m}_x\mathcal{E}_x$ the images of $\mu^1_x, \dotsc, \mu^n_x \in \mathcal{E}_x$. Now I have specified a bijection  $a: U \times \mathbb{R}^n \to E$, and I can thereby put a topology on $E$, by declaring this to be a homeomorphism. (If I want to define a smooth structure on $E$, I can declare this to be a diffeomorphism.) Is this topology the same if I select a different basis? If I choose $\nu^i$ as a basis, then $\nu^i = \sum_j f^{ij} \mu^j$ for $f^{ij} \in \mathcal{O}_X(U)$. I ask myself whether the map  $$\mu_x \mapsto \sum_j \overline{f}^{ij}_x \mu_x$$ defines a self-homeomorphism from $E \to E$. (Here $\overline{f}^{ij}_x$ represents the image of $f^{ij}_x$ in $\mathcal{E}_x / \mathfrak{m}_x\mathcal{E}_x$.) In the case where $X$ is a manifold, and $\mathcal{O}_X$ is its sheaf of continuous (smooth) real-valued functions, then the $f^{ij}$ really are continuous (smooth) real-valued functions on $X$, and the above map $E \to E$ seems pretty clearly to be continuous (smooth). But in the general case, where $X, \mathcal{O}_X$ is just a locally ringed space, I don't really know how to interpret the above map. (Why is it continuous on the topology I've defined? I can define values for $f^{ij}$ in each $\mathcal{O}_{X,x}/\mathfrak{m}_x$, but what do they really have to do with each other?) What I suspect is going wrong: The spaces $\mathcal{E}_x/\mathfrak{m}_x \mathcal{E}_x$ at each point are all isomorphic to $\mathbb{R}^n$, but they don't have any canonical isomorphisms between them. To put a topology on $E$ I have to kind of decide on these canonical isomorphisms, and I can't just do it in any old way I want--the elements in the structure sheaf   have to have something to do with continuous functions $X \to \mathbb{R}$ for this   to work. Attempt 2: (Basis free) (Suggested by a friend): ( Edit: I don't think this works. As Eric Wofsey points out, the fibers would all be discrete.) Take $\mathcal{E}$, and form its etale space $\operatorname{Et}(\mathcal{E})$. The elements of the etale space are just all the germs. Let me describe a relation on germs by saying that two germs $\mu_x, \nu_x$ are related if they are in the same stalk and $\mu_x - \nu_x \in \mathfrak{m}_x\mathcal{E}_x$. Now just form the quotient topology by this relation. If I do this in the case where $X, \mathcal{O}_X$ is a manifold with its ring of smooth functions, it seems to give me the correct topology on $X \times \mathbb{R}^n$. So perhaps it works as a basis-free construction? Here are some related questions, but they don't really address my question: 1 , 2 , 3 , 4 .","I am trying to look at smooth manifolds in the context of locally ringed spaces. Vector bundles have a characterization in terms of sheaves of modules: if $X, \mathcal{O}_X$ is a topological (or smooth) manifold along with its structure sheaf, then a locally free $\mathcal{O}_X$ module of rank $n$ is the same thing as a vector bundle over $X$ of rank $n$. You can read about the correspondence in Ramanan chapter 2, for instance. Now forget about manifolds for a second, and suppose that $X, \mathcal{O}_X$ is just a locally ringed space, where all the stalks have residue field $\mathbb{R}$, and that $\mathcal{E}$ is a locally free $\mathcal{O}_X$ module, and suppose I try to form a vector bundle out of it, in the same way mentioned in the link above. My Question: Given a locally ringed space $X, \mathcal{O}_X$, where each stalk has residue field $\mathbb{R}$, and an $\mathcal{O}_X$ module   $\mathcal{E}$ which is locally free of rank $n$, how can I construct a   vector bundle from this information? Here is my attempt, and you can see where I run into problems. Attempt 1: (Via a basis) I'm trying to define a topology, so I may as well work locally. After passing to a smaller open set, I can assume that $\mathcal{E}\cong (\mathcal{O}_X)^n$ as $\mathcal{O}_X$ modules. (Then later I should worry about transition functions and stuff, but you'll see I don't even get that far.) As a set, my vector bundle $E$ will be the elements $\bigcup\limits_{x\in U} (\mathcal{E}_x/\mathfrak{m}_x\mathcal{E}_x)$, where $\mathfrak{m}_x \triangleleft \mathcal{O}_{X, x}$ is the maximal ideal. Now I topologize it by taking a basis for $\mathcal{E}$: suppose $\mathcal{E}(X)$ has a basis over $\mathcal{O}_X(X)$ given by $\mu^1, \dotsc, \mu^n$, and suppose I take as my basis for each $\mathcal{E}_x/\mathfrak{m}_x\mathcal{E}_x$ the images of $\mu^1_x, \dotsc, \mu^n_x \in \mathcal{E}_x$. Now I have specified a bijection  $a: U \times \mathbb{R}^n \to E$, and I can thereby put a topology on $E$, by declaring this to be a homeomorphism. (If I want to define a smooth structure on $E$, I can declare this to be a diffeomorphism.) Is this topology the same if I select a different basis? If I choose $\nu^i$ as a basis, then $\nu^i = \sum_j f^{ij} \mu^j$ for $f^{ij} \in \mathcal{O}_X(U)$. I ask myself whether the map  $$\mu_x \mapsto \sum_j \overline{f}^{ij}_x \mu_x$$ defines a self-homeomorphism from $E \to E$. (Here $\overline{f}^{ij}_x$ represents the image of $f^{ij}_x$ in $\mathcal{E}_x / \mathfrak{m}_x\mathcal{E}_x$.) In the case where $X$ is a manifold, and $\mathcal{O}_X$ is its sheaf of continuous (smooth) real-valued functions, then the $f^{ij}$ really are continuous (smooth) real-valued functions on $X$, and the above map $E \to E$ seems pretty clearly to be continuous (smooth). But in the general case, where $X, \mathcal{O}_X$ is just a locally ringed space, I don't really know how to interpret the above map. (Why is it continuous on the topology I've defined? I can define values for $f^{ij}$ in each $\mathcal{O}_{X,x}/\mathfrak{m}_x$, but what do they really have to do with each other?) What I suspect is going wrong: The spaces $\mathcal{E}_x/\mathfrak{m}_x \mathcal{E}_x$ at each point are all isomorphic to $\mathbb{R}^n$, but they don't have any canonical isomorphisms between them. To put a topology on $E$ I have to kind of decide on these canonical isomorphisms, and I can't just do it in any old way I want--the elements in the structure sheaf   have to have something to do with continuous functions $X \to \mathbb{R}$ for this   to work. Attempt 2: (Basis free) (Suggested by a friend): ( Edit: I don't think this works. As Eric Wofsey points out, the fibers would all be discrete.) Take $\mathcal{E}$, and form its etale space $\operatorname{Et}(\mathcal{E})$. The elements of the etale space are just all the germs. Let me describe a relation on germs by saying that two germs $\mu_x, \nu_x$ are related if they are in the same stalk and $\mu_x - \nu_x \in \mathfrak{m}_x\mathcal{E}_x$. Now just form the quotient topology by this relation. If I do this in the case where $X, \mathcal{O}_X$ is a manifold with its ring of smooth functions, it seems to give me the correct topology on $X \times \mathbb{R}^n$. So perhaps it works as a basis-free construction? Here are some related questions, but they don't really address my question: 1 , 2 , 3 , 4 .",,"['differential-geometry', 'algebraic-geometry', 'smooth-manifolds', 'vector-bundles', 'ringed-spaces']"
64,Vector field on manifold,Vector field on manifold,,I've only seen a vector field $V$ on a manifold $M$ as a mapping $V:M\to TM$. Is it true that they can also be seen as a mapping $V:C^{\infty}\left(M\right)\to C^{\infty}\left(M\right)$? How would $V$ work in the second case?,I've only seen a vector field $V$ on a manifold $M$ as a mapping $V:M\to TM$. Is it true that they can also be seen as a mapping $V:C^{\infty}\left(M\right)\to C^{\infty}\left(M\right)$? How would $V$ work in the second case?,,"['differential-geometry', 'manifolds']"
65,Existence of angle functions on the proper open subsets of $S^1$ [duplicate],Existence of angle functions on the proper open subsets of  [duplicate],S^1,"This question already has answers here : Existence of continuous angle function $\theta:S^1\to\mathbb{R}$ (3 answers) Closed 8 years ago . Here is the problem 1-8 in Lee's introduction to smooth manifolds: An angle function on a subset $U \subset S^1$ is a continuous     function $ \theta: U\to \mathbb R$ such that $e^{i\theta(z)}=z$ for all $z \in U$. Show that there exists an angle function on an open subset $U\subset S^1$ if and only if $U \neq S^1.$ For any such  angle function, show that $(U,\theta)$ is a smooth coordinate chart for $S^1$ with its standard smooth structure. I wonder if $U\ne S^1$ is sufficient for the existence of such a continuous angle function(I feel that the statement should be "" there exists an angle function on an open subset $U\subset S^1$ if and only if $U$ is not dense in $S^1.$ ""). Let's take a special case when $U=S^1-\{-1\}$. Suppose there is such a continuous angle function $ \theta: U\to \mathbb R$ such that $e^{i\theta(z)}=z$ for all $z \in U$. Then we must have $\theta(z)=arg(z)+2k\pi$. However, It seems that there will always be a ""jump"" somewhere on the circle making $\theta$ discontinuous. For example, if we define $\theta(z)=\arg(z)$, then when $z$ approaches $-1$ from the first quadrant and the four quadrant separately, $\theta(z)$ approaches to $\pi$ or $-\pi$.(This argument turns out to be wrong , see the answers and comments given below by repliers) Since professor Lee doesn't make any corrections to this problem, it should be correct as given. But how to define such a continuous angle function for arbitrary proper open subset of $S^1$? Thanks in advance!","This question already has answers here : Existence of continuous angle function $\theta:S^1\to\mathbb{R}$ (3 answers) Closed 8 years ago . Here is the problem 1-8 in Lee's introduction to smooth manifolds: An angle function on a subset $U \subset S^1$ is a continuous     function $ \theta: U\to \mathbb R$ such that $e^{i\theta(z)}=z$ for all $z \in U$. Show that there exists an angle function on an open subset $U\subset S^1$ if and only if $U \neq S^1.$ For any such  angle function, show that $(U,\theta)$ is a smooth coordinate chart for $S^1$ with its standard smooth structure. I wonder if $U\ne S^1$ is sufficient for the existence of such a continuous angle function(I feel that the statement should be "" there exists an angle function on an open subset $U\subset S^1$ if and only if $U$ is not dense in $S^1.$ ""). Let's take a special case when $U=S^1-\{-1\}$. Suppose there is such a continuous angle function $ \theta: U\to \mathbb R$ such that $e^{i\theta(z)}=z$ for all $z \in U$. Then we must have $\theta(z)=arg(z)+2k\pi$. However, It seems that there will always be a ""jump"" somewhere on the circle making $\theta$ discontinuous. For example, if we define $\theta(z)=\arg(z)$, then when $z$ approaches $-1$ from the first quadrant and the four quadrant separately, $\theta(z)$ approaches to $\pi$ or $-\pi$.(This argument turns out to be wrong , see the answers and comments given below by repliers) Since professor Lee doesn't make any corrections to this problem, it should be correct as given. But how to define such a continuous angle function for arbitrary proper open subset of $S^1$? Thanks in advance!",,"['real-analysis', 'differential-geometry', 'complex-numbers', 'smooth-manifolds']"
66,"Pullback metric, coordinate vector fields..","Pullback metric, coordinate vector fields..",,"I'm doing this computation on $\mathbb{R}^3$ with cylindrical coordinates $(r, \theta, z)$, (which aren't defined on the whole of $\mathbb{R}^3$, but I don't care about that) and I seem to get a contradiction. The problem is as follows. Make the following change of coordinates: $$\xi = r,~~\eta = \theta - z,~~\zeta = z.~~~(1)$$ My problem is simple: express the new coordinate vector fields $(\partial_{\xi}, \partial_{\eta}, \partial_{\zeta})$ in terms of the old ones $(\partial_{r}, \partial_{\theta}, \partial_{z})$. I'm getting confused because I actually have two ways of doing this, both seem right, but they disagree; so let me explain what I've tried. 1. From $(1)$, basically using the Chain Rule: $$\partial_{\xi} = \frac{\partial{\xi}}{\partial{r}}\partial_r + \frac{\partial{\xi}}{\partial{\theta}}\partial_{\theta} + \frac{\partial{\xi}}{\partial{z}}\partial_z = \partial_r,~~~~(2)\\ \partial_{\eta} = \partial_{\theta} - \partial_z, \\ \partial_{\zeta} = \partial_z. $$ 2. From $(1)$, compute the differentials first: $$d\xi = dr,~~d\eta = d\theta - dz,~~d\zeta = dz.~~~(3)$$ Now from $(3)$ and the general fact that $dx^i(\partial_j) = \delta_{ij}$, where $i, j = 1, 2, 3$ and $\delta_{ij}$ is the Kronecker delta, we must have $$\partial_{\xi} = \partial_r,~~\partial_{\eta} = \partial_{\theta},~~\partial_{\zeta} = \partial_z + \partial_{\theta}.~~~~(4)$$ But $(2)$ and $(4)$ disagree about who is $\partial_{\zeta}$, for instance. What is going on??","I'm doing this computation on $\mathbb{R}^3$ with cylindrical coordinates $(r, \theta, z)$, (which aren't defined on the whole of $\mathbb{R}^3$, but I don't care about that) and I seem to get a contradiction. The problem is as follows. Make the following change of coordinates: $$\xi = r,~~\eta = \theta - z,~~\zeta = z.~~~(1)$$ My problem is simple: express the new coordinate vector fields $(\partial_{\xi}, \partial_{\eta}, \partial_{\zeta})$ in terms of the old ones $(\partial_{r}, \partial_{\theta}, \partial_{z})$. I'm getting confused because I actually have two ways of doing this, both seem right, but they disagree; so let me explain what I've tried. 1. From $(1)$, basically using the Chain Rule: $$\partial_{\xi} = \frac{\partial{\xi}}{\partial{r}}\partial_r + \frac{\partial{\xi}}{\partial{\theta}}\partial_{\theta} + \frac{\partial{\xi}}{\partial{z}}\partial_z = \partial_r,~~~~(2)\\ \partial_{\eta} = \partial_{\theta} - \partial_z, \\ \partial_{\zeta} = \partial_z. $$ 2. From $(1)$, compute the differentials first: $$d\xi = dr,~~d\eta = d\theta - dz,~~d\zeta = dz.~~~(3)$$ Now from $(3)$ and the general fact that $dx^i(\partial_j) = \delta_{ij}$, where $i, j = 1, 2, 3$ and $\delta_{ij}$ is the Kronecker delta, we must have $$\partial_{\xi} = \partial_r,~~\partial_{\eta} = \partial_{\theta},~~\partial_{\zeta} = \partial_z + \partial_{\theta}.~~~~(4)$$ But $(2)$ and $(4)$ disagree about who is $\partial_{\zeta}$, for instance. What is going on??",,"['differential-geometry', 'coordinate-systems', 'polar-coordinates']"
67,Extrinsic Curvature of Surface of Codimension > 1,Extrinsic Curvature of Surface of Codimension > 1,,"We can define the extrinsic curvature of a codimension-one surface as $$K_{ab} = q_a^{\phantom{a}c} q_b^{\phantom{b}d} \nabla_c n_d,$$ where $n^d$ is the normal vector to the hypersurface and $q_{ab} = g_{ab} - n_a n_b$ is the induced metric (with $g_{ab}$ the ambient metric).  Here and below I'll assume the ambient geometry is Riemannian so that everything is spacelike.  Now, the above expression can also be written in terms of the Lie derivative as $$K_{ab} = \frac{1}{2}\mathcal{L}_n q_{ab}.$$ For a surface of codimension $n$, the extrinsic curvature can be defined in terms of the induced metric as $$K^c_{ab} = -q_a^{\phantom{a}d} q_b^{\phantom{b}e} \nabla_d q_e^{\phantom{d}c},$$ where now the induced metric can be written as $$q_{ab} = g_{ab} - \sum_i X^{(i)}_a X^{(i)}_b,$$ where the sum is over $n$ mutually orthogonal unit vectors normal to the surface.  It is relatively simple to show that for any such unit normal vector $X^a$, $$X_c K^c_{ab} = q_a^{\phantom{a}c} q_b^{\phantom{b}d} \nabla_c X_d.$$ My question is the following: can the above contraction be rewritten in terms of the Lie derivative, as it can in the codimension-one case?  Specifically, is it true that $$X_c K^c_{ab} = \frac{1}{2} \mathcal{L}_X q_{ab}?$$ I've been trying to derive the above expression for a while, but I've had no success.  I'd like to know if I've just been screwing up my algebra, or if it's just not true.","We can define the extrinsic curvature of a codimension-one surface as $$K_{ab} = q_a^{\phantom{a}c} q_b^{\phantom{b}d} \nabla_c n_d,$$ where $n^d$ is the normal vector to the hypersurface and $q_{ab} = g_{ab} - n_a n_b$ is the induced metric (with $g_{ab}$ the ambient metric).  Here and below I'll assume the ambient geometry is Riemannian so that everything is spacelike.  Now, the above expression can also be written in terms of the Lie derivative as $$K_{ab} = \frac{1}{2}\mathcal{L}_n q_{ab}.$$ For a surface of codimension $n$, the extrinsic curvature can be defined in terms of the induced metric as $$K^c_{ab} = -q_a^{\phantom{a}d} q_b^{\phantom{b}e} \nabla_d q_e^{\phantom{d}c},$$ where now the induced metric can be written as $$q_{ab} = g_{ab} - \sum_i X^{(i)}_a X^{(i)}_b,$$ where the sum is over $n$ mutually orthogonal unit vectors normal to the surface.  It is relatively simple to show that for any such unit normal vector $X^a$, $$X_c K^c_{ab} = q_a^{\phantom{a}c} q_b^{\phantom{b}d} \nabla_c X_d.$$ My question is the following: can the above contraction be rewritten in terms of the Lie derivative, as it can in the codimension-one case?  Specifically, is it true that $$X_c K^c_{ab} = \frac{1}{2} \mathcal{L}_X q_{ab}?$$ I've been trying to derive the above expression for a while, but I've had no success.  I'd like to know if I've just been screwing up my algebra, or if it's just not true.",,"['general-relativity', 'differential-geometry', 'curvature']"
68,Parallel Translation is Path Independent iff Manifold is Flat,Parallel Translation is Path Independent iff Manifold is Flat,,"Problem. Let $M$ be a smooth Riemannian manifold and $\nabla$ be the Levi-Civita connection. Then the following are equivalent $R(X,Y)Z=\nabla_X\nabla_YZ-\nabla_Y\nabla_XZ-\nabla_{[X,Y]}Z\equiv 0$ For all $p,q\in M$, parallel translation along a curve segment from $p$ to $q$ is independent of the curve. My attempt. I've tried for several hours now, but I'm out of ideas. Initially, I tried analyzing the differential equations which characterize  a vector field along a curve being parallel, but I couldn't get anything out of it. For the implication (2)$\implies$(1), it would be enough to show $R(\partial_i,\partial_j)\partial_k\equiv0$. Considering curves through some $p\in M$ which have the form $t\mapsto te_i$ in some chart around $p$ seemed promising but didn't get me far. In particular I'm also not sure how the fact that $\nabla$ is the Levi-Civita conncetion comes into play. I know that compatibility of $\nabla$ with the metric is equivalent to the parallel translation being an isometry. Can we use that? I would really appreciate some help.","Problem. Let $M$ be a smooth Riemannian manifold and $\nabla$ be the Levi-Civita connection. Then the following are equivalent $R(X,Y)Z=\nabla_X\nabla_YZ-\nabla_Y\nabla_XZ-\nabla_{[X,Y]}Z\equiv 0$ For all $p,q\in M$, parallel translation along a curve segment from $p$ to $q$ is independent of the curve. My attempt. I've tried for several hours now, but I'm out of ideas. Initially, I tried analyzing the differential equations which characterize  a vector field along a curve being parallel, but I couldn't get anything out of it. For the implication (2)$\implies$(1), it would be enough to show $R(\partial_i,\partial_j)\partial_k\equiv0$. Considering curves through some $p\in M$ which have the form $t\mapsto te_i$ in some chart around $p$ seemed promising but didn't get me far. In particular I'm also not sure how the fact that $\nabla$ is the Levi-Civita conncetion comes into play. I know that compatibility of $\nabla$ with the metric is equivalent to the parallel translation being an isometry. Can we use that? I would really appreciate some help.",,"['differential-geometry', 'riemannian-geometry']"
69,Proving smooth map between smooth manifolds is constant based on push forward being zero,Proving smooth map between smooth manifolds is constant based on push forward being zero,,"I have just me this problem in my class on smooth manifolds from Lee's introduction to smooth manifolds, from the chapter on the tangent bundle stating the following: Let $M, N$ be smooth manifolds, with $M$ being connected. Now we have a smooth map $  F : M \to N $ such that its push forward is the zero map. We are to show that the map $F$ is constant I thought about it for a while, I figured maybe I should assume to get contradiction the map is not constant that would entail that in a connected neighborhood of M the coordinate representation of this map is non constant so due to smoothness some derivation on it is not zero, but how would I connect this with the push forward known to be the zero map? This is where I am stcuk. I thank all helpers on this","I have just me this problem in my class on smooth manifolds from Lee's introduction to smooth manifolds, from the chapter on the tangent bundle stating the following: Let $M, N$ be smooth manifolds, with $M$ being connected. Now we have a smooth map $  F : M \to N $ such that its push forward is the zero map. We are to show that the map $F$ is constant I thought about it for a while, I figured maybe I should assume to get contradiction the map is not constant that would entail that in a connected neighborhood of M the coordinate representation of this map is non constant so due to smoothness some derivation on it is not zero, but how would I connect this with the push forward known to be the zero map? This is where I am stcuk. I thank all helpers on this",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
70,Understanding purpose of dual vector space,Understanding purpose of dual vector space,,"I am a beginner in differential geometry and have questions/confusion about dual vector space. I took a look at this and this questions. But both did not resolve my question. We have standard definition of a dual vector space as: Let $G,H$ are real vector spaces, we define vector space of all linear    maps $ f : G \rightarrow H$. Dual space $G^*$ is defined as $G^*: G  \rightarrow \mathbb R$ Sometimes notation $HOM(G,H)$ is used to indicate vector space of all linear maps. Does this have to do with homomorphism? Can someone comment what is role of homomorphism here? When $G,H$ are both real vector spaces, why can't we say dual space $G^*$ is   $G^*: G \rightarrow H$? I did not understand the purpose of defining another vector space mapping from original vector space to space of real numbers. I can guess, one such purpose is for non Cartesian coordinate systems. We have a vector as $ \overline{ a} = a_{i}e^i = a^je_j$. Here $e^i,e_j$ are dual basis vectors. Is this the purpose for dual vector space? I appreciate any inputs and thanks in advance!","I am a beginner in differential geometry and have questions/confusion about dual vector space. I took a look at this and this questions. But both did not resolve my question. We have standard definition of a dual vector space as: Let $G,H$ are real vector spaces, we define vector space of all linear    maps $ f : G \rightarrow H$. Dual space $G^*$ is defined as $G^*: G  \rightarrow \mathbb R$ Sometimes notation $HOM(G,H)$ is used to indicate vector space of all linear maps. Does this have to do with homomorphism? Can someone comment what is role of homomorphism here? When $G,H$ are both real vector spaces, why can't we say dual space $G^*$ is   $G^*: G \rightarrow H$? I did not understand the purpose of defining another vector space mapping from original vector space to space of real numbers. I can guess, one such purpose is for non Cartesian coordinate systems. We have a vector as $ \overline{ a} = a_{i}e^i = a^je_j$. Here $e^i,e_j$ are dual basis vectors. Is this the purpose for dual vector space? I appreciate any inputs and thanks in advance!",,"['linear-algebra', 'abstract-algebra', 'differential-geometry']"
71,Infinitesimal Generator of Local Group of Transformation,Infinitesimal Generator of Local Group of Transformation,,"I am stuck on concept of infinitesimal generator. I am reading Olver and i quote definitions from there Given a local group of transformation G acting on Manifold M via $g.x= \Psi(g,x)$ for $(g,x)\in \mathbb{U} \subset G\times M$. Then for every $v\in \mathbb{g}$ (the lie algebra of G) we define a vector field on M $$\begin{equation} \psi(v)|_{x} = \frac{d}{d\epsilon}\Bigg{|}_{\epsilon=0} \Psi(exp(\epsilon v),x) \tag{1} \end{equation}$$ Then it goes on to say that we identify $\mathbb{g}$ with $\psi{(\mathbb{g})}$ and this forms a Lie algebra of vector fields on M. In this language, ""we recover $\mathbb{g}$ from group transformations by the basic formula $$\begin{equation} v|_{x} = \frac{d}{d\epsilon}\Bigg{|}_{\epsilon=0}exp(\epsilon v)x   \tag{2} \end{equation}$$ A vector field $v$ in $\mathbb{g}$ is called an infinitesimal generator of the group action G. From what I understand, when it says that we recover $\mathbb{g}$ from group transformation is that we obtain that subset of vectorfields on M which is an image of lie algebra of G (determined by number of parameters specified in group transformation) under $\psi$. Is that correct ? For example if the given transformation is $(x,y) \mapsto (x+c\epsilon, y + \epsilon) $ then the underlying group is $R$. Eq (2) will give me $c\partial_x + \partial_y$ if i consider $exp(\epsilon v)(x,y)= (x+c \epsilon,y+\epsilon)$ with $v=\textbf{1}.\frac{d}{d\epsilon}$ i. This is the image of vector field ""$\textbf{1}.\frac{d}{d\epsilon}$"" on $R$ under $\psi$ by our first equation. So for a 1-d Group action can one say that image of the vector field ""$\textbf{1}.\frac{d}{d\epsilon}$"" is called infinitesimal generator. ii. What is the infinitesimal generator of $(x,y)\mapsto(\epsilon x, \epsilon^3 y)$? As per equation (2) i get $\partial_x$ but i think that is not the case. iii. how do we solve for infinitesimal generator if tranformation group has two parameters? say $(x,y)\mapsto(x+\mu + \epsilon, y + \epsilon)$. Here should i look for the image of the vector fields ""$\textbf{1}.\frac{d}{d\epsilon}$"" and ""$\textbf{1}.\frac{d}{d\mu}$"" ?","I am stuck on concept of infinitesimal generator. I am reading Olver and i quote definitions from there Given a local group of transformation G acting on Manifold M via $g.x= \Psi(g,x)$ for $(g,x)\in \mathbb{U} \subset G\times M$. Then for every $v\in \mathbb{g}$ (the lie algebra of G) we define a vector field on M $$\begin{equation} \psi(v)|_{x} = \frac{d}{d\epsilon}\Bigg{|}_{\epsilon=0} \Psi(exp(\epsilon v),x) \tag{1} \end{equation}$$ Then it goes on to say that we identify $\mathbb{g}$ with $\psi{(\mathbb{g})}$ and this forms a Lie algebra of vector fields on M. In this language, ""we recover $\mathbb{g}$ from group transformations by the basic formula $$\begin{equation} v|_{x} = \frac{d}{d\epsilon}\Bigg{|}_{\epsilon=0}exp(\epsilon v)x   \tag{2} \end{equation}$$ A vector field $v$ in $\mathbb{g}$ is called an infinitesimal generator of the group action G. From what I understand, when it says that we recover $\mathbb{g}$ from group transformation is that we obtain that subset of vectorfields on M which is an image of lie algebra of G (determined by number of parameters specified in group transformation) under $\psi$. Is that correct ? For example if the given transformation is $(x,y) \mapsto (x+c\epsilon, y + \epsilon) $ then the underlying group is $R$. Eq (2) will give me $c\partial_x + \partial_y$ if i consider $exp(\epsilon v)(x,y)= (x+c \epsilon,y+\epsilon)$ with $v=\textbf{1}.\frac{d}{d\epsilon}$ i. This is the image of vector field ""$\textbf{1}.\frac{d}{d\epsilon}$"" on $R$ under $\psi$ by our first equation. So for a 1-d Group action can one say that image of the vector field ""$\textbf{1}.\frac{d}{d\epsilon}$"" is called infinitesimal generator. ii. What is the infinitesimal generator of $(x,y)\mapsto(\epsilon x, \epsilon^3 y)$? As per equation (2) i get $\partial_x$ but i think that is not the case. iii. how do we solve for infinitesimal generator if tranformation group has two parameters? say $(x,y)\mapsto(x+\mu + \epsilon, y + \epsilon)$. Here should i look for the image of the vector fields ""$\textbf{1}.\frac{d}{d\epsilon}$"" and ""$\textbf{1}.\frac{d}{d\mu}$"" ?",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
72,How to show the inequation by using Hessian comparison.,How to show the inequation by using Hessian comparison.,,"In the below picture ,how to show the inequation 1? In fact,I'm not familiar with Hessian comparison.So, hope a detail answer , Thanks very much. The below picture is form 194th page of here ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~","In the below picture ,how to show the inequation 1? In fact,I'm not familiar with Hessian comparison.So, hope a detail answer , Thanks very much. The below picture is form 194th page of here ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~",,"['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
73,Is the total space of a principal bundle parallelizable?,Is the total space of a principal bundle parallelizable?,,"Given a smooth $G$-principal bundle $P \to M$, is $P$ in general parallelizable as a manifold? That is, is the tangent bundle $TP \to P$ trivial? In the case of Klein geometries, and more generally, Cartan geometries, the principal bundle is indeed parallelizable, but is this true for any principal bundle?","Given a smooth $G$-principal bundle $P \to M$, is $P$ in general parallelizable as a manifold? That is, is the tangent bundle $TP \to P$ trivial? In the case of Klein geometries, and more generally, Cartan geometries, the principal bundle is indeed parallelizable, but is this true for any principal bundle?",,"['differential-geometry', 'differential-topology', 'fiber-bundles', 'principal-bundles']"
74,Defining differentiability on a topological manifold,Defining differentiability on a topological manifold,,I am currently watching a series of lectures which are a part of International Winter School on Gravity and Light 2015 (by Prof. Frederick P. Schuller). In one of the lectures on differentiable manifolds he asks- Is the structure of a topological manifold enought to talk about differentiability of curves on the manifold?Can you construct from it a notion of differentiability? And he answers in the negative saying that the structure of a topological manifold is not good enough to define a notion of differentiability. Why is this true? What is missing in the structure of a topological manifold that is preventing us from defining differentiability on it? Here is the video lecture link. Go to 01:43,I am currently watching a series of lectures which are a part of International Winter School on Gravity and Light 2015 (by Prof. Frederick P. Schuller). In one of the lectures on differentiable manifolds he asks- Is the structure of a topological manifold enought to talk about differentiability of curves on the manifold?Can you construct from it a notion of differentiability? And he answers in the negative saying that the structure of a topological manifold is not good enough to define a notion of differentiability. Why is this true? What is missing in the structure of a topological manifold that is preventing us from defining differentiability on it? Here is the video lecture link. Go to 01:43,,"['differential-geometry', 'manifolds', 'differential-topology']"
75,Torsion and curvature of a curve,Torsion and curvature of a curve,,"A regular curve $\textbf{$\gamma$}$ in $\mathbb{R}^3$ with curvature $> 0$ is called a generalized helix if its tangent vector makes a fixed angle $\theta$ with a fixed unit vector $\textbf{a}$. Show that the torsion $\tau$ and curvature $\kappa$ of $\textbf{$\gamma$}$ are related by $\tau = ±\kappa \cot \theta$. Show conversely that, if the torsion and curvature of a regular curve are related by $\tau = \lambda \kappa$ where $\lambda$ is a constant, then the curve is a generalized helix. $$$$ I have done the following: $\textbf{a}$ is a fixed unit vector: $||\textbf{a}||=1$ and since it is fixed we have that $\textbf{a}'=0$. $$\textbf{a} \cdot \textbf{t}=||\textbf{a}|| ||\textbf{t}|| \cos \theta = ||\textbf{t}|| \cos \theta \\ \Rightarrow (\textbf{a} \cdot \textbf{t})'=0 \Rightarrow \textbf{a}' \cdot \textbf{t}+\textbf{a} \cdot \textbf{t}'=0 \Rightarrow \textbf{a} \cdot \kappa \textbf{n}=0 \overset{ \kappa >0 }{ \Rightarrow } \textbf{a} \cdot  \textbf{n}=0 \Rightarrow \textbf{a} \bot \textbf{n}$$ $\textbf{t}$, $\textbf{n}$ and $\textbf{b}$ consists an orthonormal basis of $\mathbb{R}^3$. So, $$\textbf{a}=A \textbf{t}+ B \textbf{n}+ C\textbf{b}$$ We have that $\textbf{a}$ is on the plane spanned by $\textbf{t}$ and $\textbf{b}$. So, $B=0$. Therefore, $$\textbf{a}=A \textbf{t}+C\textbf{b}$$ How could we continue?","A regular curve $\textbf{$\gamma$}$ in $\mathbb{R}^3$ with curvature $> 0$ is called a generalized helix if its tangent vector makes a fixed angle $\theta$ with a fixed unit vector $\textbf{a}$. Show that the torsion $\tau$ and curvature $\kappa$ of $\textbf{$\gamma$}$ are related by $\tau = ±\kappa \cot \theta$. Show conversely that, if the torsion and curvature of a regular curve are related by $\tau = \lambda \kappa$ where $\lambda$ is a constant, then the curve is a generalized helix. $$$$ I have done the following: $\textbf{a}$ is a fixed unit vector: $||\textbf{a}||=1$ and since it is fixed we have that $\textbf{a}'=0$. $$\textbf{a} \cdot \textbf{t}=||\textbf{a}|| ||\textbf{t}|| \cos \theta = ||\textbf{t}|| \cos \theta \\ \Rightarrow (\textbf{a} \cdot \textbf{t})'=0 \Rightarrow \textbf{a}' \cdot \textbf{t}+\textbf{a} \cdot \textbf{t}'=0 \Rightarrow \textbf{a} \cdot \kappa \textbf{n}=0 \overset{ \kappa >0 }{ \Rightarrow } \textbf{a} \cdot  \textbf{n}=0 \Rightarrow \textbf{a} \bot \textbf{n}$$ $\textbf{t}$, $\textbf{n}$ and $\textbf{b}$ consists an orthonormal basis of $\mathbb{R}^3$. So, $$\textbf{a}=A \textbf{t}+ B \textbf{n}+ C\textbf{b}$$ We have that $\textbf{a}$ is on the plane spanned by $\textbf{t}$ and $\textbf{b}$. So, $B=0$. Therefore, $$\textbf{a}=A \textbf{t}+C\textbf{b}$$ How could we continue?",,"['differential-geometry', 'curves', 'curvature']"
76,Area of a right angled hyperbolic triangle as function of side lengths,Area of a right angled hyperbolic triangle as function of side lengths,,"I was puzzeling with Area of hyperbolic triangle definition and could not figure it out, but then i thought there should be a (maybe solvable)  simpler problem so here it is: suppose: an hyperbolic plane with a Gaussian curvature of -1 on this surface there is a triangle $\triangle ABC$ $\angle C$ is a right angle Then given the lengths of sides a and b what is the area? Off course we could do: the area $ = \frac{\pi}{2} - \angle A -\angle B$ or $ \frac{\pi}{2} - arctan (\frac{\tanh(a)}{\sinh(b)} )- arctan (\frac{\tanh(b)}{\sinh(a)}) $ (free after http://en.wikipedia.org/wiki/Hyperbolic_triangle ) But is there not a  nicer formula that does not contain any or only one trigonometric function? (I guess the hyperbolic functions are needed) UPDATE 07/10/2015 following https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Arctangent_addition_formula $$ \arctan u + \arctan v = \arctan \left( \frac{u+v}{1-uv} \right) $$ and $$ \frac{\pi}{2} -arctan (\frac{u}{v}) = arctan (\frac{v}{u})$$ (complement tangent = cotangent) I get to $$ Area = arctan(\frac{ \sinh(a)\sinh(b) - \tanh(a)tanh(b)}{\sinh(a)\tanh(a)+ \sinh(b)\tanh(b)} )$$ Can this be simplified any further?  (Do i overlook the obvious again , or even did i make a mistake on the way somewhere?)","I was puzzeling with Area of hyperbolic triangle definition and could not figure it out, but then i thought there should be a (maybe solvable)  simpler problem so here it is: suppose: an hyperbolic plane with a Gaussian curvature of -1 on this surface there is a triangle $\triangle ABC$ $\angle C$ is a right angle Then given the lengths of sides a and b what is the area? Off course we could do: the area $ = \frac{\pi}{2} - \angle A -\angle B$ or $ \frac{\pi}{2} - arctan (\frac{\tanh(a)}{\sinh(b)} )- arctan (\frac{\tanh(b)}{\sinh(a)}) $ (free after http://en.wikipedia.org/wiki/Hyperbolic_triangle ) But is there not a  nicer formula that does not contain any or only one trigonometric function? (I guess the hyperbolic functions are needed) UPDATE 07/10/2015 following https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Arctangent_addition_formula $$ \arctan u + \arctan v = \arctan \left( \frac{u+v}{1-uv} \right) $$ and $$ \frac{\pi}{2} -arctan (\frac{u}{v}) = arctan (\frac{v}{u})$$ (complement tangent = cotangent) I get to $$ Area = arctan(\frac{ \sinh(a)\sinh(b) - \tanh(a)tanh(b)}{\sinh(a)\tanh(a)+ \sinh(b)\tanh(b)} )$$ Can this be simplified any further?  (Do i overlook the obvious again , or even did i make a mistake on the way somewhere?)",,"['differential-geometry', 'hyperbolic-geometry']"
77,Leibniz rule for covariant derivative of tensor fields,Leibniz rule for covariant derivative of tensor fields,,"Let M be a differentiable manifold. I want to define the covariant derivative $\nabla$ of tensor fields over M, as a derivation on a suitable algebra A of tensors, that is: 1) $\nabla$ is linear over tensors of the same order. 2) $\nabla$ increases the covariant order of the tensor by one. 3) $\nabla$ satisfies the Leibniz rule for arbitrary tensors of the algebra A with respect to the tensor product. My issue is with point 3. In Physics, usually one defines the covariant derivative of an arbitrary tensor by extending the covariant derivatives of vectors and covectors, requiring that it commutes with contraction and that it satisfies the Leibniz rule for the components. However, I want to work with the tensors themselves instead of just the components. If I do that, then the Leibniz rule doesn't seem to work. For example, say S is of order (1,0) (covariant) and T is of order (0,1) (contravariant), and that the covariant derivative stacks the additional covariant component at the beginning of the tensor. Writting the tensors in terms of a basis $\partial_{j}$ and its natural cobasis $dx^{j}$: $$ S = S_{j}dx^{j} $$ $$ T = T^{j}\partial_{j} $$ Let $\Gamma^{i}_{j,k}$ be the connection coefficients defining the covariant derivative in that particular coordinate system. Then one would have: $$ \nabla S = \partial_{i}(S_{j}) dx^{i} \otimes dx^{j} - S_{j}\Gamma^{j}_{k,l}dx^{l} \otimes dx^{k} $$ $$ \nabla T = \partial_{i}(T^{j}) dx^{i} \otimes \partial_{j} +  T^{j}\Gamma^{k}_{j,l}dx^{l} \otimes \partial_{k} $$ But then $\nabla T \otimes S$ has summands of the form $dx^{\alpha} \otimes \partial_{\beta} \otimes dx^{\gamma}$ while $ T \otimes \nabla S$ has summands of the form $\partial_{\alpha} \otimes dx^{\beta} \otimes dx^{\gamma}$, so the two cannot be summed to form $\nabla (T \otimes S )$ unless some shuffling is applied to the factors (the total number of covariant and contravariant components is the same in both). So my question is: is there a canonical way to order the covariant and contravariant parts in a product like this, so that $\nabla$ satisfies the Leibniz rule in the way I propose?","Let M be a differentiable manifold. I want to define the covariant derivative $\nabla$ of tensor fields over M, as a derivation on a suitable algebra A of tensors, that is: 1) $\nabla$ is linear over tensors of the same order. 2) $\nabla$ increases the covariant order of the tensor by one. 3) $\nabla$ satisfies the Leibniz rule for arbitrary tensors of the algebra A with respect to the tensor product. My issue is with point 3. In Physics, usually one defines the covariant derivative of an arbitrary tensor by extending the covariant derivatives of vectors and covectors, requiring that it commutes with contraction and that it satisfies the Leibniz rule for the components. However, I want to work with the tensors themselves instead of just the components. If I do that, then the Leibniz rule doesn't seem to work. For example, say S is of order (1,0) (covariant) and T is of order (0,1) (contravariant), and that the covariant derivative stacks the additional covariant component at the beginning of the tensor. Writting the tensors in terms of a basis $\partial_{j}$ and its natural cobasis $dx^{j}$: $$ S = S_{j}dx^{j} $$ $$ T = T^{j}\partial_{j} $$ Let $\Gamma^{i}_{j,k}$ be the connection coefficients defining the covariant derivative in that particular coordinate system. Then one would have: $$ \nabla S = \partial_{i}(S_{j}) dx^{i} \otimes dx^{j} - S_{j}\Gamma^{j}_{k,l}dx^{l} \otimes dx^{k} $$ $$ \nabla T = \partial_{i}(T^{j}) dx^{i} \otimes \partial_{j} +  T^{j}\Gamma^{k}_{j,l}dx^{l} \otimes \partial_{k} $$ But then $\nabla T \otimes S$ has summands of the form $dx^{\alpha} \otimes \partial_{\beta} \otimes dx^{\gamma}$ while $ T \otimes \nabla S$ has summands of the form $\partial_{\alpha} \otimes dx^{\beta} \otimes dx^{\gamma}$, so the two cannot be summed to form $\nabla (T \otimes S )$ unless some shuffling is applied to the factors (the total number of covariant and contravariant components is the same in both). So my question is: is there a canonical way to order the covariant and contravariant parts in a product like this, so that $\nabla$ satisfies the Leibniz rule in the way I propose?",,"['differential-geometry', 'tensor-products']"
78,Group actions on manifolds - exponential map,Group actions on manifolds - exponential map,,"Let $M$ be a smooth manifold. Suppose $K$ is a Lie group (with Lie algebra $\mathfrak{k}$) acting EDIT: TRANSITIVELY on $M$ from the left and $G$ is a Lie group (with Lie algebra $\mathfrak{g}$) acting on $M$ from the right. Suppose further these actions commute - ie $k(pg)=(kp)g=kpg$. Fix a point $x\in M$. Suppose $\phi(t)$ is some smooth curve in $M$ such that $\phi(0)=x$. Is it possible to find $X\in \mathfrak{k}$ and $A\in\mathfrak{g}$ such that \begin{align*} \frac{d}{dt}\bigg|_{t=0}\exp(tX)x\exp(tA)=\phi^{\prime}(0)?? \end{align*} And if so, how could you prove such a fact?","Let $M$ be a smooth manifold. Suppose $K$ is a Lie group (with Lie algebra $\mathfrak{k}$) acting EDIT: TRANSITIVELY on $M$ from the left and $G$ is a Lie group (with Lie algebra $\mathfrak{g}$) acting on $M$ from the right. Suppose further these actions commute - ie $k(pg)=(kp)g=kpg$. Fix a point $x\in M$. Suppose $\phi(t)$ is some smooth curve in $M$ such that $\phi(0)=x$. Is it possible to find $X\in \mathfrak{k}$ and $A\in\mathfrak{g}$ such that \begin{align*} \frac{d}{dt}\bigg|_{t=0}\exp(tX)x\exp(tA)=\phi^{\prime}(0)?? \end{align*} And if so, how could you prove such a fact?",,"['differential-geometry', 'manifolds', 'lie-groups', 'lie-algebras']"
79,Euclidean metric on a Riemannian manifold,Euclidean metric on a Riemannian manifold,,"Lets say we have a Euclidean configurations space $\mathbb E^n$ equipped with a smooth inner product $\langle \cdot ,\cdot \rangle$ with positive signature in the tangent space above each point. We have defined a Riemannian manifold. We can also call this inner product a metric tensor $g$, such that if $g$ acts on two vectors then $g(v,w)$ where $v,w\in T_p\mathbb E^n$ (tangent space to a point $p$). From general googling and piecing things together I am lead to write another expression for $g$, namely, \begin{equation} \boxed{ g(v,v)=g_{ij}\frac{dx^i}{dt}\frac{dx^j}{dt}}  \end{equation} Where,  \begin{equation} v=v^ie_i \end{equation} Is this something we can do? My reasoning is that $\|v\|=\sqrt{v\cdot  v}=\sqrt{g(v,v)}$ from wikipedia and I have seen (page 5) , \begin{equation} \|v\|=\sqrt{g_{ij}\frac{dx}{dt}\frac{dx}{dt}} \end{equation} Therefore is the boxed expression above correct? In addition I am assuming $v=\dot x$. If this is so then I assume that $v$ would have to be the representative of $x$ in $T_p\mathbb E^n$? For physical application I am trying to understand how the following simple Lagrangian is constructed,   \begin{equation} \mathscr L=\frac{1}{2}\sum _{ij}\text{g}_{ij}\dot q^i\dot q^j \end{equation} I would just add that I am not very confident with tensorial notation, while I realise that on the surface this may look correct I feel I may be trading over important details?","Lets say we have a Euclidean configurations space $\mathbb E^n$ equipped with a smooth inner product $\langle \cdot ,\cdot \rangle$ with positive signature in the tangent space above each point. We have defined a Riemannian manifold. We can also call this inner product a metric tensor $g$, such that if $g$ acts on two vectors then $g(v,w)$ where $v,w\in T_p\mathbb E^n$ (tangent space to a point $p$). From general googling and piecing things together I am lead to write another expression for $g$, namely, \begin{equation} \boxed{ g(v,v)=g_{ij}\frac{dx^i}{dt}\frac{dx^j}{dt}}  \end{equation} Where,  \begin{equation} v=v^ie_i \end{equation} Is this something we can do? My reasoning is that $\|v\|=\sqrt{v\cdot  v}=\sqrt{g(v,v)}$ from wikipedia and I have seen (page 5) , \begin{equation} \|v\|=\sqrt{g_{ij}\frac{dx}{dt}\frac{dx}{dt}} \end{equation} Therefore is the boxed expression above correct? In addition I am assuming $v=\dot x$. If this is so then I assume that $v$ would have to be the representative of $x$ in $T_p\mathbb E^n$? For physical application I am trying to understand how the following simple Lagrangian is constructed,   \begin{equation} \mathscr L=\frac{1}{2}\sum _{ij}\text{g}_{ij}\dot q^i\dot q^j \end{equation} I would just add that I am not very confident with tensorial notation, while I realise that on the surface this may look correct I feel I may be trading over important details?",,['differential-geometry']
80,Integral curves on immersed submanifold,Integral curves on immersed submanifold,,"An exercise of the book ""Introduction to smooth manifolds - John M. Lee"" asks to prove that if $S$ is a closed embedded submanifold of a manifold $M$, and $X$ is a vector field on $M$ tangent to $S$, then every integral curve of $X$ that intersect $S$ is contained in $S$. Can someone show me a counteresample in the ""closed-immersed"" case?","An exercise of the book ""Introduction to smooth manifolds - John M. Lee"" asks to prove that if $S$ is a closed embedded submanifold of a manifold $M$, and $X$ is a vector field on $M$ tangent to $S$, then every integral curve of $X$ that intersect $S$ is contained in $S$. Can someone show me a counteresample in the ""closed-immersed"" case?",,['differential-geometry']
81,Pushforward injective,Pushforward injective,,"Let $f : M \rightarrow N$ be a smooth surjective map between smooth manifolds. Now, consider a 2-form $\omega$ on $T_pN$. Does it now follow that the pullback satisfies? $f^* d \omega =0 \Rightarrow  d \omega=0$","Let $f : M \rightarrow N$ be a smooth surjective map between smooth manifolds. Now, consider a 2-form $\omega$ on $T_pN$. Does it now follow that the pullback satisfies? $f^* d \omega =0 \Rightarrow  d \omega=0$",,"['linear-algebra', 'differential-geometry', 'differential-forms']"
82,Do Carmo :Show a line of curvature C is a plane curve if osculating plane makes a constant angle,Do Carmo :Show a line of curvature C is a plane curve if osculating plane makes a constant angle,,"Here's the full problem: Assume that the osculating plane of a line of curvature $C \subset S$, which is nowhere tangent to an asymptotic direction, makes a constant angle with the tangent plane of $S$ along $C$. Prove that $C$ is a plane curve. My attempt: Let $\alpha : I \to S$ be some regular parametrization of $C$. Then the binormal vector $b(s)$ determines the osculating plane of $\alpha$, and the tangent plane to $S$ is determined by the normal vector $N$. Thus the stipulation is that $$b(s) \cdot N(s) = const$$ or $$ b'(s) \cdot N(s) + b(s) \cdot N'(s) = 0$$ Since $C$ is a line of curvature we have $N'(s) = \lambda(s) \alpha'(s)$ and so $b(s) \cdot N'(s) = 0$. Then we are left with $$\tau(s) n(s) \cdot N(s) = 0 $$ If I can show that $n(s) \cdot N(s) \neq 0$ then I have my result, since this means $\tau(s) = 0$. But I don't think this should be true in general, which means I've messed up somewhere. Any help would be greatly appreciated!","Here's the full problem: Assume that the osculating plane of a line of curvature $C \subset S$, which is nowhere tangent to an asymptotic direction, makes a constant angle with the tangent plane of $S$ along $C$. Prove that $C$ is a plane curve. My attempt: Let $\alpha : I \to S$ be some regular parametrization of $C$. Then the binormal vector $b(s)$ determines the osculating plane of $\alpha$, and the tangent plane to $S$ is determined by the normal vector $N$. Thus the stipulation is that $$b(s) \cdot N(s) = const$$ or $$ b'(s) \cdot N(s) + b(s) \cdot N'(s) = 0$$ Since $C$ is a line of curvature we have $N'(s) = \lambda(s) \alpha'(s)$ and so $b(s) \cdot N'(s) = 0$. Then we are left with $$\tau(s) n(s) \cdot N(s) = 0 $$ If I can show that $n(s) \cdot N(s) \neq 0$ then I have my result, since this means $\tau(s) = 0$. But I don't think this should be true in general, which means I've messed up somewhere. Any help would be greatly appreciated!",,['differential-geometry']
83,Volume form for a product manifold.,Volume form for a product manifold.,,"Given two Riemannian manifolds $(M,g^M)$ and $(N,g^N)$, we can construct a product Riemannian manifold $(M\times N,g^{M \times N})$ as described in Product of Riemannian manifolds? . Is there a simple description of the volume form of the product manifold in terms of the volume forms of $M$ and $N$? Dimensional reasons make me think the volume form of the product $\omega^{M \times N}$ should be something along the lines of $\omega^{M \times N} = \omega^M + \omega^N$, where $\omega^M$ and $\omega^N$ are the volume forms of $M$ and $N$ respectively, but I have no idea how to show this.","Given two Riemannian manifolds $(M,g^M)$ and $(N,g^N)$, we can construct a product Riemannian manifold $(M\times N,g^{M \times N})$ as described in Product of Riemannian manifolds? . Is there a simple description of the volume form of the product manifold in terms of the volume forms of $M$ and $N$? Dimensional reasons make me think the volume form of the product $\omega^{M \times N}$ should be something along the lines of $\omega^{M \times N} = \omega^M + \omega^N$, where $\omega^M$ and $\omega^N$ are the volume forms of $M$ and $N$ respectively, but I have no idea how to show this.",,"['differential-geometry', 'riemannian-geometry', 'differential-forms']"
84,when does the fact that the normal bundle $N(X)$ is trivial imply that the tangent bundle $TX$ is trivial too?,when does the fact that the normal bundle  is trivial imply that the tangent bundle  is trivial too?,N(X) TX,"Let $\varphi: X\longrightarrow \mathbb{R}^N$ be an submanifold immersed in $\mathbb{R}^N$, then everybody knows that $T\mathbb{R}^N\vert_X$= T(X)$\oplus N(X)$. It is clear that $T\mathbb{R}^N \vert_X$ is a trivial bundle over $X$. My question is: if we know that $N(X)$ is a trivial vector bundle over X does this implies that $TX$ is trivial? I know that in the general case ($X$ a submanifold of a Riemannian manifold $M$) $N(X)$ trivial does not implies that $TX$ is trivial, my guess is that the answer to my question is NO, however the fact $T\mathbb{R}^N \vert_X$ is a trivial bundle and $N(X)$ is a sub bundle makes me feel that there might be a chance for $TX$ to be trivial. Basic linear algebra shows that if {$v_1,..v_q$} is a global orthonormal frame of $N(X)$ then locally we can produce a local orthonormal frame for $TX$, however I think that there are problems if we try to construct a global frame for $TX$, however I am not sure if using that $T\mathbb{R}^N \vert_X$ is trivial we can construct such a global frame for $TX$. Many thanks for you help math folks!!","Let $\varphi: X\longrightarrow \mathbb{R}^N$ be an submanifold immersed in $\mathbb{R}^N$, then everybody knows that $T\mathbb{R}^N\vert_X$= T(X)$\oplus N(X)$. It is clear that $T\mathbb{R}^N \vert_X$ is a trivial bundle over $X$. My question is: if we know that $N(X)$ is a trivial vector bundle over X does this implies that $TX$ is trivial? I know that in the general case ($X$ a submanifold of a Riemannian manifold $M$) $N(X)$ trivial does not implies that $TX$ is trivial, my guess is that the answer to my question is NO, however the fact $T\mathbb{R}^N \vert_X$ is a trivial bundle and $N(X)$ is a sub bundle makes me feel that there might be a chance for $TX$ to be trivial. Basic linear algebra shows that if {$v_1,..v_q$} is a global orthonormal frame of $N(X)$ then locally we can produce a local orthonormal frame for $TX$, however I think that there are problems if we try to construct a global frame for $TX$, however I am not sure if using that $T\mathbb{R}^N \vert_X$ is trivial we can construct such a global frame for $TX$. Many thanks for you help math folks!!",,['differential-geometry']
85,Definition of connection on vector bundle,Definition of connection on vector bundle,,"A connection on a vector bundle $E$ is a map $ D:\Gamma(E)\rightarrow \Gamma(T^*(M)\otimes E)$ satisfying 1) For any $s_1,s_2\in \Gamma(E)$, $D(s_1+s_2)=Ds_1+Ds_2$ 2) For $s\in \Gamma(E)$ and $\alpha\in C^{\infty}(M)$, $D(\alpha s)=d\alpha \otimes s + \alpha Ds$ I am having trouble understanding these conditions. I don't understand the notation $d\alpha \otimes s$. I have only ever dealt with tensor products of linear functionals. Ie $v^*\otimes w^*(v,w)=v^*(v)w^*(w)$. The quantity $d\alpha \otimes s$ is the tensor product of the differential of $\alpha$ and a smooth section of $E$. How is this quantity defined? Can anyone shed any light here? Thanks in advance.","A connection on a vector bundle $E$ is a map $ D:\Gamma(E)\rightarrow \Gamma(T^*(M)\otimes E)$ satisfying 1) For any $s_1,s_2\in \Gamma(E)$, $D(s_1+s_2)=Ds_1+Ds_2$ 2) For $s\in \Gamma(E)$ and $\alpha\in C^{\infty}(M)$, $D(\alpha s)=d\alpha \otimes s + \alpha Ds$ I am having trouble understanding these conditions. I don't understand the notation $d\alpha \otimes s$. I have only ever dealt with tensor products of linear functionals. Ie $v^*\otimes w^*(v,w)=v^*(v)w^*(w)$. The quantity $d\alpha \otimes s$ is the tensor product of the differential of $\alpha$ and a smooth section of $E$. How is this quantity defined? Can anyone shed any light here? Thanks in advance.",,"['differential-geometry', 'manifolds', 'tensor-products', 'smooth-manifolds']"
86,Surface of revolution and curvatures,Surface of revolution and curvatures,,"Let $f(x)$ be a smooth function. Consider a surface of revolution, \begin{equation} M(u, v) = (f(v) \cos(u), f(v) \sin(u), v). \end{equation} (a) Calculate coefficients of the first and second fundamental forms for the surface; (b) Calculate principal curvatures κ1, κ2, the Gaussian curvature K and the mean curvature H; (c) Find the length of the portion of the normal line contained between a point of the surface and the axis of revolution (in the present case, the z-axis). I have obtained the first fundamental form and tried working out the second fundamental form and obtained the following: \begin{equation} \frac{1}{\sqrt{f^2(v)(1+f'^2(v))}}  (l du^2 + 2mdudv+n dv^2) \end{equation} where $l= \frac{(-f(v)\cos(u),-f(v)\sin(u),0)}{\sqrt{f^2(v)(1+f'^2(v))}}$, $m=\frac{(-f'(v)\sin(u),f'(v)\cos(u),0)}{\sqrt{f^2(v)(1+f'^2(v))}}$, $n=\frac{f''(v)\cos(u),f''(v)\sin(u),1)}{\sqrt{f^2(v)(1+f'^2(v))}}$ I am not too sure whether my values for $l, m$ and $n$ is correct because from what I know, numerator for all 3 of them should be scalar and not be in vector form. Any help would be appreciated.","Let $f(x)$ be a smooth function. Consider a surface of revolution, \begin{equation} M(u, v) = (f(v) \cos(u), f(v) \sin(u), v). \end{equation} (a) Calculate coefficients of the first and second fundamental forms for the surface; (b) Calculate principal curvatures κ1, κ2, the Gaussian curvature K and the mean curvature H; (c) Find the length of the portion of the normal line contained between a point of the surface and the axis of revolution (in the present case, the z-axis). I have obtained the first fundamental form and tried working out the second fundamental form and obtained the following: \begin{equation} \frac{1}{\sqrt{f^2(v)(1+f'^2(v))}}  (l du^2 + 2mdudv+n dv^2) \end{equation} where $l= \frac{(-f(v)\cos(u),-f(v)\sin(u),0)}{\sqrt{f^2(v)(1+f'^2(v))}}$, $m=\frac{(-f'(v)\sin(u),f'(v)\cos(u),0)}{\sqrt{f^2(v)(1+f'^2(v))}}$, $n=\frac{f''(v)\cos(u),f''(v)\sin(u),1)}{\sqrt{f^2(v)(1+f'^2(v))}}$ I am not too sure whether my values for $l, m$ and $n$ is correct because from what I know, numerator for all 3 of them should be scalar and not be in vector form. Any help would be appreciated.",,['differential-geometry']
87,How to evaluate this integral: $\oint dx$?,How to evaluate this integral: ?,\oint dx,"I am trying to understand differential forms. Now I tried to evaluate $$ \oint_{S^1}dx$$ I should get anything non-zero but I don't know how to do it (even though I know the result). If $S^1$ in the integral is one of the circles that goes around the torus, how do I go about actually calculating the integral? It's clear to me that the function I am integrating is $f(x,y)=1 $. Now it's not clear to me whether I can just choose any parametrisatioin of $S^1$ and then integrate, like for example $$ \int_0^{2\pi} 1 \cdot |r'(t)| dt = 2 \pi$$ where $r = (\cos t, \sin t)$. The reason why I think that this might be wrong is that it does not take into account any information about the space in which $S^1$ lies. But the shape of the space should determine whether a given $1$-form is exact or not. Edit In response to the comment by jflipp: If I use $d \theta = {x dy - y dx \over x^2 + y^2}$ then I can do it: I see that the integral is $2\pi$. Now I want to use either $dx$ or $dy$, the differential $1$-forms in the expression $d \theta = {x dy - y dx \over x^2 + y^2}$.","I am trying to understand differential forms. Now I tried to evaluate $$ \oint_{S^1}dx$$ I should get anything non-zero but I don't know how to do it (even though I know the result). If $S^1$ in the integral is one of the circles that goes around the torus, how do I go about actually calculating the integral? It's clear to me that the function I am integrating is $f(x,y)=1 $. Now it's not clear to me whether I can just choose any parametrisatioin of $S^1$ and then integrate, like for example $$ \int_0^{2\pi} 1 \cdot |r'(t)| dt = 2 \pi$$ where $r = (\cos t, \sin t)$. The reason why I think that this might be wrong is that it does not take into account any information about the space in which $S^1$ lies. But the shape of the space should determine whether a given $1$-form is exact or not. Edit In response to the comment by jflipp: If I use $d \theta = {x dy - y dx \over x^2 + y^2}$ then I can do it: I see that the integral is $2\pi$. Now I want to use either $dx$ or $dy$, the differential $1$-forms in the expression $d \theta = {x dy - y dx \over x^2 + y^2}$.",,"['differential-geometry', 'differential-forms']"
88,Discrete Gauß and geodesic curvature,Discrete Gauß and geodesic curvature,,"Imagine that you have an n-polygon $S$ and you wanted to calculated the discrete Gaussian or gedoesic curvature. How are they defined? If $p$ is a vertex of $S$ then Gauß-Bonnet suggests that the full integral $$\sum_{ p \in S} K(p) = 2\pi - \sum_{i=1}^n \theta_i ,$$ where $\theta_i$ are the external angles. Also, one is tempted to interpret $$\sum_{p \in S} \kappa_g(p) = \sum_{i=1}^n \theta_i$$ as the full geodesic curvature. Are these two equations correct and if yes, how is the Gaußian and geodesic curvature of a single point defined in the discrete case? If anything is unclear, please let me know.","Imagine that you have an n-polygon $S$ and you wanted to calculated the discrete Gaussian or gedoesic curvature. How are they defined? If $p$ is a vertex of $S$ then Gauß-Bonnet suggests that the full integral $$\sum_{ p \in S} K(p) = 2\pi - \sum_{i=1}^n \theta_i ,$$ where $\theta_i$ are the external angles. Also, one is tempted to interpret $$\sum_{p \in S} \kappa_g(p) = \sum_{i=1}^n \theta_i$$ as the full geodesic curvature. Are these two equations correct and if yes, how is the Gaußian and geodesic curvature of a single point defined in the discrete case? If anything is unclear, please let me know.",,"['discrete-mathematics', 'differential-geometry']"
89,Poincare' s inequality for vectorfields on the sphere,Poincare' s inequality for vectorfields on the sphere,,"Let $\mathbb{S}^2$ be the standard 2-sphere, and let $V$ be $\mathcal{C}^1$ vectorfield on it. I'd like to understand if it is true that there exists $C > 0$ such that, for all such $V$, we have $$ \int_{\mathbb{S}^2}|\nabla V|^2 \mbox{d}\sigma_{\mathbb{S}^2}\geq C \int_{\mathbb{S}^2}|V|^2 \mbox{d}\sigma_{\mathbb{S}^2}, $$ where $\nabla$ is the Levi-Civita connection associated to the standard metric, and $\sigma_{\mathbb{S}^2}$ is the standard volume form. My heuristic reasoning was the following: usually, for a Poincare' estimate on functions, you need either some condition on the support or on the integral mean of the function. Here, by the Hairy Ball Theorem, $V$ is ""pinned"" to be zero at one point, hence I wonder if this is sufficient to say something. In case it worked, I would also be interested in understanding if such an inequality holds for some subset of $H^1$-vectorfields on the sphere.","Let $\mathbb{S}^2$ be the standard 2-sphere, and let $V$ be $\mathcal{C}^1$ vectorfield on it. I'd like to understand if it is true that there exists $C > 0$ such that, for all such $V$, we have $$ \int_{\mathbb{S}^2}|\nabla V|^2 \mbox{d}\sigma_{\mathbb{S}^2}\geq C \int_{\mathbb{S}^2}|V|^2 \mbox{d}\sigma_{\mathbb{S}^2}, $$ where $\nabla$ is the Levi-Civita connection associated to the standard metric, and $\sigma_{\mathbb{S}^2}$ is the standard volume form. My heuristic reasoning was the following: usually, for a Poincare' estimate on functions, you need either some condition on the support or on the integral mean of the function. Here, by the Hairy Ball Theorem, $V$ is ""pinned"" to be zero at one point, hence I wonder if this is sufficient to say something. In case it worked, I would also be interested in understanding if such an inequality holds for some subset of $H^1$-vectorfields on the sphere.",,"['differential-geometry', 'inequality']"
90,The category of vector fields on smooth manifolds,The category of vector fields on smooth manifolds,,"In my differential geometry lecture today we learnt about the push-forward of a vector field by a diffeomorphism. I know some basic category theory and I noticed a functor popping up. Here's what I've got (in class at the moment we're only looking at open subsets of $\mathbb{R}^n$ but I think this ought to generalise): Let $U,V\subseteq \mathbb{R}^n$ be open, $F\in \text{Diff} (U,V)$ a diffeomorphism, and let $\mathbb{X}:U\rightarrow \mathbb{R}^n$ be a vector field on $U$ (which we have been thinking of just as a function to $\mathbb{R}^n$). Denote the set of all vector fields on $U$ by $\mathcal{X} (U)$. Then the push-forward of $\mathbb{X}$ by $F$ is the vector field $F_{*} \mathbb{X}\in\mathcal{X} (V)$ defined by $(F_{*} \mathbb{X})\circ F = F'\mathbb{X}$ where $F'$ is the derivative of $F$. In components, $(F_{*} \mathbb{X})^i (y) = \partial_j (F^i (F^{-1} (y)))\mathbb{X}^j (F^{-1} (y))$. You can check that ${id_U}_{*} = id_{\mathcal{X} (U)}$ and if $U\xrightarrow{F} V\xrightarrow{G} W$ is a sequence of diffeomorphisms then $(G\circ F)_{*}\mathbb{X} = G_{*} F_{*} \mathbb{X}$. Therefore we've got a covariant functor $h_{*}(F:U\rightarrow V) = F_{*} : \mathcal{X}(U)\rightarrow \mathcal{X}(V)$ from the category $\bf{Man}$ of smooth manifolds (here I just used open subsets of $\mathbb{R}^n$) to the category $\bf{VecFld}$ of vector fields on smooth manifolds. However, I don't have a clue what $\bf{VecFld}$ looks like as a category itself. What are the morphisms? Is every morphism $f:\mathcal{X}(V)\rightarrow \mathcal{X}(U)$ the pullback $f(\mathbb{X}) = \mathbb{X} \circ F$ of some diffeomorphism $F:U\rightarrow V$? Does $h_{*}$ have an adjoint? Any information on related questions would be greatly appreciated, and sorry if this is very basic; I hope to learn more about vector fields later in this course!","In my differential geometry lecture today we learnt about the push-forward of a vector field by a diffeomorphism. I know some basic category theory and I noticed a functor popping up. Here's what I've got (in class at the moment we're only looking at open subsets of $\mathbb{R}^n$ but I think this ought to generalise): Let $U,V\subseteq \mathbb{R}^n$ be open, $F\in \text{Diff} (U,V)$ a diffeomorphism, and let $\mathbb{X}:U\rightarrow \mathbb{R}^n$ be a vector field on $U$ (which we have been thinking of just as a function to $\mathbb{R}^n$). Denote the set of all vector fields on $U$ by $\mathcal{X} (U)$. Then the push-forward of $\mathbb{X}$ by $F$ is the vector field $F_{*} \mathbb{X}\in\mathcal{X} (V)$ defined by $(F_{*} \mathbb{X})\circ F = F'\mathbb{X}$ where $F'$ is the derivative of $F$. In components, $(F_{*} \mathbb{X})^i (y) = \partial_j (F^i (F^{-1} (y)))\mathbb{X}^j (F^{-1} (y))$. You can check that ${id_U}_{*} = id_{\mathcal{X} (U)}$ and if $U\xrightarrow{F} V\xrightarrow{G} W$ is a sequence of diffeomorphisms then $(G\circ F)_{*}\mathbb{X} = G_{*} F_{*} \mathbb{X}$. Therefore we've got a covariant functor $h_{*}(F:U\rightarrow V) = F_{*} : \mathcal{X}(U)\rightarrow \mathcal{X}(V)$ from the category $\bf{Man}$ of smooth manifolds (here I just used open subsets of $\mathbb{R}^n$) to the category $\bf{VecFld}$ of vector fields on smooth manifolds. However, I don't have a clue what $\bf{VecFld}$ looks like as a category itself. What are the morphisms? Is every morphism $f:\mathcal{X}(V)\rightarrow \mathcal{X}(U)$ the pullback $f(\mathbb{X}) = \mathbb{X} \circ F$ of some diffeomorphism $F:U\rightarrow V$? Does $h_{*}$ have an adjoint? Any information on related questions would be greatly appreciated, and sorry if this is very basic; I hope to learn more about vector fields later in this course!",,"['differential-geometry', 'category-theory']"
91,Exact definition of a circular helix,Exact definition of a circular helix,,"I know that a cylindrical helix is a curve $\alpha: I \to \Bbb R^3$, such that exists a constant vector $\bf u$ which makes a constant angle with the tangent vector $\bf T$ to the curve, at every point, that is, $\langle {\bf T}(s), {\bf u}\rangle = \cos \theta$, for all $s \in I$ (we can suppose that $\alpha$ is parametrized by arc-length). Then, there this a caracterization of cylindrical helices: a curve $\alpha$ with non-zero curvature is a cylindrical helix if and only if $\tau/\kappa$ is constant. Notice that $\kappa$ and $\tau$ need not be constant, only their ratio, though. Now, it is stated: A curve $\alpha$ is a circular helix if and only if both $\kappa$   and $\tau$ are constants. How am I supposed to prove this? Every book seems to think that it is so obvious what a circular helix is, but no one gives a straight definition for it. I am at a loss about what to do. I might as well define a circular helix being a curve with this property. If someone could tell me an exact definition for it, or give me a reference, I am thankful. Note: I found this question , but I don't think it was intended for the proof of this affirmation to become as complicated as in the answer there.","I know that a cylindrical helix is a curve $\alpha: I \to \Bbb R^3$, such that exists a constant vector $\bf u$ which makes a constant angle with the tangent vector $\bf T$ to the curve, at every point, that is, $\langle {\bf T}(s), {\bf u}\rangle = \cos \theta$, for all $s \in I$ (we can suppose that $\alpha$ is parametrized by arc-length). Then, there this a caracterization of cylindrical helices: a curve $\alpha$ with non-zero curvature is a cylindrical helix if and only if $\tau/\kappa$ is constant. Notice that $\kappa$ and $\tau$ need not be constant, only their ratio, though. Now, it is stated: A curve $\alpha$ is a circular helix if and only if both $\kappa$   and $\tau$ are constants. How am I supposed to prove this? Every book seems to think that it is so obvious what a circular helix is, but no one gives a straight definition for it. I am at a loss about what to do. I might as well define a circular helix being a curve with this property. If someone could tell me an exact definition for it, or give me a reference, I am thankful. Note: I found this question , but I don't think it was intended for the proof of this affirmation to become as complicated as in the answer there.",,"['differential-geometry', 'definition']"
92,Why is differential geometry called differential geometry?,Why is differential geometry called differential geometry?,,Why is differential geometry called differential geometry? Why it is not called differential and integral geometry? Isn't integration and finding areas as important as differentiation? Is it the case that  differential equations are more common and natural in mechanics than integral equations so as a result differential geometry as the language of mechanics is more concerned with differentiation?,Why is differential geometry called differential geometry? Why it is not called differential and integral geometry? Isn't integration and finding areas as important as differentiation? Is it the case that  differential equations are more common and natural in mechanics than integral equations so as a result differential geometry as the language of mechanics is more concerned with differentiation?,,"['differential-geometry', 'soft-question', 'big-picture']"
93,"Solution of eikonal equation is locally the distance from a hypersurface, up to a constant","Solution of eikonal equation is locally the distance from a hypersurface, up to a constant",,"Consider the Eikonal equation (with right handside 1) $$\sum_{i=1}^{n}(\frac{\partial u}{\partial x_i})^2=1$$ I want to see why any solution to this is locally the sum of a distance function from a hypersurface plus a constant. I think I came up with a way but I wonder if there is a simpler way to argue this. Here is what I did: Assume $u(x)$ is a solution which is smooth in some domain. Take a level set $N= u^{-1}(c)$ (restricted to this domain). Then we want to solve a first order non-linear partial differetial equation with the initial condition $u|_{N}=c$. The characteristic equation for this pde is $$\dot{x} = 2p$$ $$\dot{p} = 0$$ $$\dot{u} = 2p^2 = 2$$ We know that the full solution to this equation is a function $u(x)$ whose graph $(x,u(x),\nabla u(x))$ in fiber bundle of the jet of functions over the domain is the set of characteristics passing through $N$ (since $\nabla u$ is not the tanget space of the initial manifold). This means that locally in coordinates $p$ does not change since if $g(w,t)$ are the characteristics curves: $$p(g(w,t)) = p(w) + \int_{0}^{t} \dot{p}(g(w,s))ds = p(w)$$ for all $t$. This also means that if project a characteristic curve starting at $(x_0,u_0,p_0)$ down to the base manifold it is a straight line of the form $$x(t) = x_0 + 2tp_0 = x_0 + 2t\nabla u(x_0)$$ This proves that locally $\nabla u$ are aligned in straight lines and is of norm 1 that is level sets of $u$ are parallel translates of each other. Now it is easy to see that $u(x)$ can be locally written as distance from $N$ + c. Infact again by the characteristic equations $$u(t) = c + 2t$$ where $d(x(t),x_0)=2t$ by the equation above and the fact that characteristic lines projected down are straight lines.","Consider the Eikonal equation (with right handside 1) $$\sum_{i=1}^{n}(\frac{\partial u}{\partial x_i})^2=1$$ I want to see why any solution to this is locally the sum of a distance function from a hypersurface plus a constant. I think I came up with a way but I wonder if there is a simpler way to argue this. Here is what I did: Assume $u(x)$ is a solution which is smooth in some domain. Take a level set $N= u^{-1}(c)$ (restricted to this domain). Then we want to solve a first order non-linear partial differetial equation with the initial condition $u|_{N}=c$. The characteristic equation for this pde is $$\dot{x} = 2p$$ $$\dot{p} = 0$$ $$\dot{u} = 2p^2 = 2$$ We know that the full solution to this equation is a function $u(x)$ whose graph $(x,u(x),\nabla u(x))$ in fiber bundle of the jet of functions over the domain is the set of characteristics passing through $N$ (since $\nabla u$ is not the tanget space of the initial manifold). This means that locally in coordinates $p$ does not change since if $g(w,t)$ are the characteristics curves: $$p(g(w,t)) = p(w) + \int_{0}^{t} \dot{p}(g(w,s))ds = p(w)$$ for all $t$. This also means that if project a characteristic curve starting at $(x_0,u_0,p_0)$ down to the base manifold it is a straight line of the form $$x(t) = x_0 + 2tp_0 = x_0 + 2t\nabla u(x_0)$$ This proves that locally $\nabla u$ are aligned in straight lines and is of norm 1 that is level sets of $u$ are parallel translates of each other. Now it is easy to see that $u(x)$ can be locally written as distance from $N$ + c. Infact again by the characteristic equations $$u(t) = c + 2t$$ where $d(x(t),x_0)=2t$ by the equation above and the fact that characteristic lines projected down are straight lines.",,"['differential-geometry', 'partial-differential-equations']"
94,"Is $\mathbb{R}P^n$ ""two-sided"" in $\mathbb{R}P^{n+1}$","Is  ""two-sided"" in",\mathbb{R}P^n \mathbb{R}P^{n+1},"i.e. Does $\mathbb{R}P^n$ have a tubular neighborhood $N$ such that $N-\mathbb{R}P^n$ is disconnected. My guess is yes, but don't know how to show it convincingly ( or maybe only for $n$ odd, I'm using $\mathbb{R}P^1$ for inutition). Since $\mathbb{R}P^n$ is a smooth submanifold of $\mathbb{R}P^{n+1}$ I believe that guarantees us a tubular neighborhood.","i.e. Does $\mathbb{R}P^n$ have a tubular neighborhood $N$ such that $N-\mathbb{R}P^n$ is disconnected. My guess is yes, but don't know how to show it convincingly ( or maybe only for $n$ odd, I'm using $\mathbb{R}P^1$ for inutition). Since $\mathbb{R}P^n$ is a smooth submanifold of $\mathbb{R}P^{n+1}$ I believe that guarantees us a tubular neighborhood.",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'differential-topology', 'smooth-manifolds']"
95,"""Bundle of metrics"" on a principal bundle?","""Bundle of metrics"" on a principal bundle?",,"I've come across the term ""bundle of metrics"" on a principal bundle. In particular, my setting is that for $N\longrightarrow M$ a universal cover of a compact Riemann surface, $P\longrightarrow M$ a principal $GL(n,\mathbb{C})$-bundle, we can consider the ""bundle of metrics"" on the pullback of P along the universal covering map of M. I wasn't able to find any definitions for this bundle. Would somebody be able to explain it to me?","I've come across the term ""bundle of metrics"" on a principal bundle. In particular, my setting is that for $N\longrightarrow M$ a universal cover of a compact Riemann surface, $P\longrightarrow M$ a principal $GL(n,\mathbb{C})$-bundle, we can consider the ""bundle of metrics"" on the pullback of P along the universal covering map of M. I wasn't able to find any definitions for this bundle. Would somebody be able to explain it to me?",,"['differential-geometry', 'riemannian-geometry', 'riemann-surfaces', 'fiber-bundles', 'principal-bundles']"
96,Diffeomorphism between a regular surface and the plane,Diffeomorphism between a regular surface and the plane,,"Do Carmo states that (example 2, page 74) if $\mathbf x: U\subset\mathbb R^2\rightarrow S$ is a parameterization, then $\mathbf x^{-1}: \mathbf x(U)\rightarrow \mathbb R^2$ is differentiable. Why is this true, please? Thank you! Do Carmo continued to say that (same example) for any $p\in\mathbf x(U)$ and any parametrization $\mathbf y: V\subset\mathbb R^2\rightarrow S$ at $p$, we have that $\mathbf x^{-1}\circ\mathbf y: \mathbf y^{-1}(W)\rightarrow \mathbf x^{-1}(W)$, where $W=\mathbf x(U)\cap\mathbf y(V)$ is differentiable. This is understandable since it directly is from the definition of a differentiable function from a regular surface to another regular surface. However, Do Carmo said that this shows that $U$ and $\mathbf x(U)$ are diffeomorphic. Why is this true, please? Thank you!","Do Carmo states that (example 2, page 74) if $\mathbf x: U\subset\mathbb R^2\rightarrow S$ is a parameterization, then $\mathbf x^{-1}: \mathbf x(U)\rightarrow \mathbb R^2$ is differentiable. Why is this true, please? Thank you! Do Carmo continued to say that (same example) for any $p\in\mathbf x(U)$ and any parametrization $\mathbf y: V\subset\mathbb R^2\rightarrow S$ at $p$, we have that $\mathbf x^{-1}\circ\mathbf y: \mathbf y^{-1}(W)\rightarrow \mathbf x^{-1}(W)$, where $W=\mathbf x(U)\cap\mathbf y(V)$ is differentiable. This is understandable since it directly is from the definition of a differentiable function from a regular surface to another regular surface. However, Do Carmo said that this shows that $U$ and $\mathbf x(U)$ are diffeomorphic. Why is this true, please? Thank you!",,"['differential-geometry', 'self-learning', 'riemann-surfaces', 'surfaces']"
97,Does there exist a surface homemomorphic to a torus with positive Gaussian curvature?,Does there exist a surface homemomorphic to a torus with positive Gaussian curvature?,,"This is a problem from the my last exam in Differential Geometry II and I didn't solve it. I'm studying again, but without success. So I need help. Does there exist a surface $S \subset \mathbb{R}^3$ which is homeomorphic to the torus $\mathbb{T}^2$ and has Gaussian curvature $K \geq 0$? What I have to work with: Differential forms, Gauss-Bonnet Theorem, Stokes Theorem, Euler characteristic, etc. Can someone help me?","This is a problem from the my last exam in Differential Geometry II and I didn't solve it. I'm studying again, but without success. So I need help. Does there exist a surface $S \subset \mathbb{R}^3$ which is homeomorphic to the torus $\mathbb{T}^2$ and has Gaussian curvature $K \geq 0$? What I have to work with: Differential forms, Gauss-Bonnet Theorem, Stokes Theorem, Euler characteristic, etc. Can someone help me?",,['differential-geometry']
98,Christoffel Symbols as Tensors,Christoffel Symbols as Tensors,,"If you define a ""generalized"" Christoffel tensor as the following: $Chris(\omega; u, v) := (\nabla_u(\omega))(v) - (\tilde{\nabla}_u(\omega))(v)$ where $\omega$ is a dual vector, $u,v$ are vectors, and $\nabla$ and $\tilde{\nabla}$ are two covariant derivatives, then is $Chris$ a tensor field if you take $nabla$ to be the metric covariant derivative and $\tilde{\nabla}=\mathcal{L}$ to be the lie derivative? (as opposed to the Christoffel symbol not being a tensor when $\tilde{\nabla}$ is the ordinary partial derivative $\partial$) I guess also with $\tilde{\nabla}=\partial$, $Chris$ is a tensor (a multinear map from duals and vectors to the reals), but some people insist on defining a tensor as something that transforms in a certain way under a change of charts. I guess my question is then will it ""transform like a tensor"" in this case?","If you define a ""generalized"" Christoffel tensor as the following: $Chris(\omega; u, v) := (\nabla_u(\omega))(v) - (\tilde{\nabla}_u(\omega))(v)$ where $\omega$ is a dual vector, $u,v$ are vectors, and $\nabla$ and $\tilde{\nabla}$ are two covariant derivatives, then is $Chris$ a tensor field if you take $nabla$ to be the metric covariant derivative and $\tilde{\nabla}=\mathcal{L}$ to be the lie derivative? (as opposed to the Christoffel symbol not being a tensor when $\tilde{\nabla}$ is the ordinary partial derivative $\partial$) I guess also with $\tilde{\nabla}=\partial$, $Chris$ is a tensor (a multinear map from duals and vectors to the reals), but some people insist on defining a tensor as something that transforms in a certain way under a change of charts. I guess my question is then will it ""transform like a tensor"" in this case?",,['differential-geometry']
99,The approximation of star-shaped domain,The approximation of star-shaped domain,,"Let $\Omega$ be a star-shaped domain in $\mathbb R^n$, that is, $\Omega$ is an open set such that for any $x\in \Omega$, $tx \in \Omega $ for $0 \leq t\leq 1$. Can we find a sequence of star-shaped domains $\{\Omega_i\}_{i\geq 1}$ such that $\Omega_i$ has the smooth boundary and $\bigcup\limits_{i \ge 1} {{\Omega _i}}  = \Omega $?","Let $\Omega$ be a star-shaped domain in $\mathbb R^n$, that is, $\Omega$ is an open set such that for any $x\in \Omega$, $tx \in \Omega $ for $0 \leq t\leq 1$. Can we find a sequence of star-shaped domains $\{\Omega_i\}_{i\geq 1}$ such that $\Omega_i$ has the smooth boundary and $\bigcup\limits_{i \ge 1} {{\Omega _i}}  = \Omega $?",,['differential-geometry']
