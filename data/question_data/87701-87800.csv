,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Variational formulation, weak formulation","Variational formulation, weak formulation",,"I'd like to find the weak formulation of the problem $-u''+au=f$ on $(0,1)$ $u(0)=0$ $u'(1)=b$ $a>0$ and show that there exists a unique solution using Lax-Milgram. What I did: By multiplying the first term with a test function $v$ and doing partial integration I get that \begin{align} -\int_{0}^{1}u''(t)v(t)dt=-u'(1)v(1)+u'(0)v(0)+\int_{0}^{1}u'(t)v'(t)dt. \end{align} Since I want the first part of the equation to be zero, I set $v \in H_{0}^{1}$ . So the formulation of the problem is \begin{align} \int_{0}^{1}u'(t)v'(t)dt+a\int_{0}^{1}u(t)v(t)dt=\int_{0}^{1}f(t)v(t)dt \end{align} for all $v \in H^{1}_{0}$ Is that part correct? I'm confused where the boundary condition $u'(1)=b$ is taken into account. Is $u$ in $H^{1}_{0}$ as well or do I need to define a new space $ V=\{v \in L^2(0,1), v' \in L^2(0,1), v'(1)=b, v(0)=0\}$ ? For the second part of the question (uniqueness + existence of solution): Using Cauchy Schwarz I get for the bilinear form $a(u,v)$ \begin{align} |a(u,v)|=\int_{0}^{1}u'(t)v'(t)+au(t)v(t)dt \leq ||u'||_{L^2}||v'||_{L^2}+a||u||_{L^2}||v||_{L^2}\leq||u'||_{H^{1}_{0}}||v||_{H^{1}_{0}}+a||u||_{H^{1}_{0}}||v||_{H^{1}_{0}} \end{align} So this shows continuity of $a$ . I'm not sure though which norm to use for $u$ since I'm not sure which space to choose. Using Poincare I get \begin{align} |a(u,u)|=||u'||_{L^2}^2+a||u||_{L^2}^2 \geq ||u'||_{L^2}^2 \geq C ||u||_{L^2}^2 \end{align} showing that the bilinear form is coercive. The last thing I need to show is that $F$ , my linear functional, is continuous (bounded). This follows from \begin{align} |F(v)| \leq ||f||_{L^2}||v||_{L^2} \leq ||f||_{L^2}||v||_{H^1_0} \end{align} Hence, using Lax Milgram I've shown existence and uniqueness of a solution. Is it correct what I am doing? I am very new to this topic so I am not so sure about some steps, expecially how to choose the space for my $u$ .","I'd like to find the weak formulation of the problem on and show that there exists a unique solution using Lax-Milgram. What I did: By multiplying the first term with a test function and doing partial integration I get that Since I want the first part of the equation to be zero, I set . So the formulation of the problem is for all Is that part correct? I'm confused where the boundary condition is taken into account. Is in as well or do I need to define a new space ? For the second part of the question (uniqueness + existence of solution): Using Cauchy Schwarz I get for the bilinear form So this shows continuity of . I'm not sure though which norm to use for since I'm not sure which space to choose. Using Poincare I get showing that the bilinear form is coercive. The last thing I need to show is that , my linear functional, is continuous (bounded). This follows from Hence, using Lax Milgram I've shown existence and uniqueness of a solution. Is it correct what I am doing? I am very new to this topic so I am not so sure about some steps, expecially how to choose the space for my .","-u''+au=f (0,1) u(0)=0 u'(1)=b a>0 v \begin{align}
-\int_{0}^{1}u''(t)v(t)dt=-u'(1)v(1)+u'(0)v(0)+\int_{0}^{1}u'(t)v'(t)dt.
\end{align} v \in H_{0}^{1} \begin{align}
\int_{0}^{1}u'(t)v'(t)dt+a\int_{0}^{1}u(t)v(t)dt=\int_{0}^{1}f(t)v(t)dt
\end{align} v \in H^{1}_{0} u'(1)=b u H^{1}_{0}  V=\{v \in L^2(0,1), v' \in L^2(0,1), v'(1)=b, v(0)=0\} a(u,v) \begin{align}
|a(u,v)|=\int_{0}^{1}u'(t)v'(t)+au(t)v(t)dt \leq ||u'||_{L^2}||v'||_{L^2}+a||u||_{L^2}||v||_{L^2}\leq||u'||_{H^{1}_{0}}||v||_{H^{1}_{0}}+a||u||_{H^{1}_{0}}||v||_{H^{1}_{0}}
\end{align} a u \begin{align}
|a(u,u)|=||u'||_{L^2}^2+a||u||_{L^2}^2 \geq ||u'||_{L^2}^2 \geq C ||u||_{L^2}^2
\end{align} F \begin{align}
|F(v)| \leq ||f||_{L^2}||v||_{L^2} \leq ||f||_{L^2}||v||_{H^1_0}
\end{align} u","['functional-analysis', 'ordinary-differential-equations', 'boundary-value-problem']"
1,Use of Poincare inequality,Use of Poincare inequality,,"Suppose $\Omega \subset \mathbb{R}$ is a bounded domain. Then using Poincare-Wirtinger, one can prove that for functions $f \in W^{1,2}(\Omega)$ there exists $C>0$ such that $$\|u\|_{L^{2}}^{2} \le C\|u'\|_{L^{2}}^{2} + C\left( \int u(x)~dx  \right)^{2}.  $$ Question: Suppose we have a function $u$ which satisfies $$  \|u'\|_{L^{2}}^{2} + \left( \int u(x)~dx \right)^{2} \le C .            $$ Can we conclude that $u \in W^{1,2}(\Omega)$ ? The reason I am not sure is because in order for us to use the first inequality we need that $u \in W^{1,2}(\Omega)$ which a-priori we don't have. I think the statement could be true and we can prove it by some density argument but I am not sure how to proceed.","Suppose is a bounded domain. Then using Poincare-Wirtinger, one can prove that for functions there exists such that Question: Suppose we have a function which satisfies Can we conclude that ? The reason I am not sure is because in order for us to use the first inequality we need that which a-priori we don't have. I think the statement could be true and we can prove it by some density argument but I am not sure how to proceed.","\Omega \subset \mathbb{R} f \in W^{1,2}(\Omega) C>0 \|u\|_{L^{2}}^{2} \le C\|u'\|_{L^{2}}^{2} + C\left( \int u(x)~dx
 \right)^{2}.   u   \|u'\|_{L^{2}}^{2} + \left( \int u(x)~dx \right)^{2} \le C .          
  u \in W^{1,2}(\Omega) u \in W^{1,2}(\Omega)","['real-analysis', 'functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
2,"Character Space of $C^1[0,1]$ and Gelfand Representation",Character Space of  and Gelfand Representation,"C^1[0,1]","I have recently been working through some exercises in Murphy's ""C*-Algebras and Operator Theory,"" and I am having some trouble with Exercise 10 in Chapter 1. The exercise is as follows: Let $A = C^1[0,1]$ . Let $x: [0,1] \longrightarrow \mathbb{C}$ be the inclusion. Show that $x$ generates $A$ as a Banach algebra. If $t \in [0,1]$ , show that $\tau_t$ belongs to $\Omega(A)$ , where $\tau_t$ is defined by $\tau_t(f) = f(t)$ , and show that the map $[0,1] \longrightarrow \Omega(A)$ , $t \mapsto \tau_t$ , is a homeomorphism. Deduce that $r(f) = \|f\|_{\infty}$ ( $f\in A$ ). Show that the Gelfand representation is not surjective for this example. So far, I have been able to show that $x$ generates $A$ via Stone-Weierstrass. The claim that $\tau_t$ is in the character space seemed quite clear as well. I am having some trouble with the rest. To show the homeomorphism, it should be enough to show surjectivity, since continuity and injectivity should be clear, but I am not sure how to approach this. I am also not quite sure how to approach the last two claims either. Any help would be appreciated.","I have recently been working through some exercises in Murphy's ""C*-Algebras and Operator Theory,"" and I am having some trouble with Exercise 10 in Chapter 1. The exercise is as follows: Let . Let be the inclusion. Show that generates as a Banach algebra. If , show that belongs to , where is defined by , and show that the map , , is a homeomorphism. Deduce that ( ). Show that the Gelfand representation is not surjective for this example. So far, I have been able to show that generates via Stone-Weierstrass. The claim that is in the character space seemed quite clear as well. I am having some trouble with the rest. To show the homeomorphism, it should be enough to show surjectivity, since continuity and injectivity should be clear, but I am not sure how to approach this. I am also not quite sure how to approach the last two claims either. Any help would be appreciated.","A = C^1[0,1] x: [0,1] \longrightarrow \mathbb{C} x A t \in [0,1] \tau_t \Omega(A) \tau_t \tau_t(f) = f(t) [0,1] \longrightarrow \Omega(A) t \mapsto \tau_t r(f) = \|f\|_{\infty} f\in A x A \tau_t","['functional-analysis', 'spectral-theory', 'c-star-algebras', 'spectral-radius', 'gelfand-representation']"
3,"Explicit norm on $C([0,1])$ not dominated by $\|\cdot\|_\infty$?",Explicit norm on  not dominated by ?,"C([0,1]) \|\cdot\|_\infty","Can we provide an explicit example of a norm $\|\cdot\|$ on the vector space of continuous functions $C([0,1])$ such that there is no constant $M>0$ with the property $\|\cdot\| \le M\|\cdot\|_\infty$ ? Some comments: It is shown here that, without AC, any complete norm on $C([0,1])$ is necessarily equivalent to $\|\cdot\|_\infty$ . So there is no explicit example of a complete norm $\|\cdot\|$ not dominated by $\|\cdot\|_\infty$ . A simple example of such a norm is $\|f\| := \|f\|_\infty + |\phi(f)|$ where $\phi$ is a discontinuous linear functional on $(C([0,1]),\|\cdot\|_\infty)$ . But of course we cannot construct such a functional $\phi$ on a Banach space without AC. I would assume therefore that the answer is no, and in that case I'm not looking for a rigorous proof or anything of the sort as I probably wouldn't be able to understand it anyway. For context, I was inspired by this question which inquires whether the set $$E = \left\{f \in C([0,1]) : \int_0^1 f(t)\,dt = 0\right\}$$ is closed in $C([0,1])$ . An answer pointed out that the OP initially did not specify the norm on $C([0,1])$ but then I realized I couldn't think of an example of a norm with respect to which $E$ wouldn't be closed. Of course it exists since $E$ is a kernel of a linear functional so it suffices to provide a norm which makes the functional discontinuous but this is probably impossible without AC.","Can we provide an explicit example of a norm on the vector space of continuous functions such that there is no constant with the property ? Some comments: It is shown here that, without AC, any complete norm on is necessarily equivalent to . So there is no explicit example of a complete norm not dominated by . A simple example of such a norm is where is a discontinuous linear functional on . But of course we cannot construct such a functional on a Banach space without AC. I would assume therefore that the answer is no, and in that case I'm not looking for a rigorous proof or anything of the sort as I probably wouldn't be able to understand it anyway. For context, I was inspired by this question which inquires whether the set is closed in . An answer pointed out that the OP initially did not specify the norm on but then I realized I couldn't think of an example of a norm with respect to which wouldn't be closed. Of course it exists since is a kernel of a linear functional so it suffices to provide a norm which makes the functional discontinuous but this is probably impossible without AC.","\|\cdot\| C([0,1]) M>0 \|\cdot\| \le M\|\cdot\|_\infty C([0,1]) \|\cdot\|_\infty \|\cdot\| \|\cdot\|_\infty \|f\| := \|f\|_\infty + |\phi(f)| \phi (C([0,1]),\|\cdot\|_\infty) \phi E = \left\{f \in C([0,1]) : \int_0^1 f(t)\,dt = 0\right\} C([0,1]) C([0,1]) E E","['real-analysis', 'functional-analysis', 'set-theory', 'normed-spaces', 'axiom-of-choice']"
4,How to find a convex function such that $F$ is $C^2$?,How to find a convex function such that  is ?,F C^2,"Given the function $F(x)=\begin{cases}        1 & x\leq 1; \\       f(x) & 1\leq x\leq 3; \\       2x^2 & 3\leq x.\end{cases}$ I would like to know if there is a general method to find $f$ convex such that $F$ is $C^2$ . I directly tried to interpolate with $f$ a polynomial of degree 5 such that $f(1)=1,f'(1)=f''(1)=0$ and $f(3)=18,f'(3)=12,f''(3)=4$ . The problem is that $f''(x)\not\geq 0,\forall 1\leq x\leq 3$ .",Given the function I would like to know if there is a general method to find convex such that is . I directly tried to interpolate with a polynomial of degree 5 such that and . The problem is that .,"F(x)=\begin{cases} 
      1 & x\leq 1; \\
      f(x) & 1\leq x\leq 3; \\
      2x^2 & 3\leq x.\end{cases} f F C^2 f f(1)=1,f'(1)=f''(1)=0 f(3)=18,f'(3)=12,f''(3)=4 f''(x)\not\geq 0,\forall 1\leq x\leq 3","['real-analysis', 'calculus', 'functional-analysis', 'numerical-methods', 'interpolation']"
5,Definition of upper semi-continuous functions: limsup or liminf?,Definition of upper semi-continuous functions: limsup or liminf?,,"Notation: $\{f\geq c\}$ stands for $\{x\in x: fx\geq c\}$ . The standard definition of an upper semi-continuous function $f:X\to \bar{ \mathbb R}$ is: For each $c$ in $\mathbb R, \{f\geq c\}$ is closed Or equivalently For each net $x_a\to x, \limsup_a fx_a\leq fx$ It seems to me that the $ \limsup_a$ here can be substituted by $\liminf_a$ : For each net $x_a\to x, \liminf_a fx_a\leq fx$ or even by: For any $x_a\to x$ s.t. $fx_a$ converges, $\lim fx_a\leq fx$ . Of course 2) implies 3) and 4); FOR THE CONVERSE: Let $x_a$ be any net in $\{f\geq c\}$ with $x_a\to x$ , we have $fx\geq \liminf_afx_a\geq c$ , hence $\{f\geq c\}$ is closed. Is this true?","Notation: stands for . The standard definition of an upper semi-continuous function is: For each in is closed Or equivalently For each net It seems to me that the here can be substituted by : For each net or even by: For any s.t. converges, . Of course 2) implies 3) and 4); FOR THE CONVERSE: Let be any net in with , we have , hence is closed. Is this true?","\{f\geq c\} \{x\in x: fx\geq c\} f:X\to \bar{ \mathbb R} c \mathbb R, \{f\geq c\} x_a\to x, \limsup_a fx_a\leq fx  \limsup_a \liminf_a x_a\to x, \liminf_a fx_a\leq fx x_a\to x fx_a \lim fx_a\leq fx x_a \{f\geq c\} x_a\to x fx\geq \liminf_afx_a\geq c \{f\geq c\}","['functional-analysis', 'continuity', 'limsup-and-liminf', 'nets', 'semicontinuous-functions']"
6,Isometries of direct sums of Hilbert spaces,Isometries of direct sums of Hilbert spaces,,"If $H$ is a separable Hilbert space, then for any norm one vectors $x$ and $y$ we can find an surjective isometry $U$ such that $Ux=y$ . Is the same true for $H\oplus H$ , that is, the direct sum in $l_1$ sense? This space is isomorphic, but not isometric with $H$ , so I am not sure the property still holds. Of course, if we consider the direct sum $\oplus_2$ in $l_2$ sense, then the space is isometric to $H$ and the property again holds. I suspect it is not true, but I cannot come up with a pair of points for which it fails.","If is a separable Hilbert space, then for any norm one vectors and we can find an surjective isometry such that . Is the same true for , that is, the direct sum in sense? This space is isomorphic, but not isometric with , so I am not sure the property still holds. Of course, if we consider the direct sum in sense, then the space is isometric to and the property again holds. I suspect it is not true, but I cannot come up with a pair of points for which it fails.",H x y U Ux=y H\oplus H l_1 H \oplus_2 l_2 H,"['functional-analysis', 'hilbert-spaces', 'banach-spaces', 'isometry']"
7,When does the squeeze theorem fail?,When does the squeeze theorem fail?,,"In introduction real analysis course, we have squeeze theorem which is: let $f,g$ and $h$ are functions from $\mathbb R$ to $\mathbb R$ and $f(x)\leq g(x)\leq h(x)$ such that $\lim\limits_{x\to a} f(x)= \lim\limits_{x\to a} h(x)=L$ , $L\in\Bbb R$ , then $\lim\limits_{x\to a} g(x)=L.$ In this course, we consider $\Bbb R$ with usual metric, that is, $(\Bbb R, d(x,y)=|x-y|)$ . The question came to my mind is that Can we find a system such that  the squeeze theorem will not be correct that, means, $f,g$ and $h$ are functions from $\mathbb X$ to $\mathbb Y$ and $f(x)\leq g(x)\leq h(x)$ such that $\lim\limits_{x\to a} f(x)= \lim\limits_{x\to a} h(x)=L$ , $L\in\Bbb Y$ , but $\lim\limits_{x\to a} g(x)\neq L,$ $X$ and $Y$ can be any sets, that is, $X$ and $Y$ might not be subsets from $\Bbb R.$ Any idea","In introduction real analysis course, we have squeeze theorem which is: let and are functions from to and such that , , then In this course, we consider with usual metric, that is, . The question came to my mind is that Can we find a system such that  the squeeze theorem will not be correct that, means, and are functions from to and such that , , but and can be any sets, that is, and might not be subsets from Any idea","f,g h \mathbb R \mathbb R f(x)\leq g(x)\leq h(x) \lim\limits_{x\to a} f(x)= \lim\limits_{x\to a} h(x)=L L\in\Bbb R \lim\limits_{x\to a} g(x)=L. \Bbb R (\Bbb R, d(x,y)=|x-y|) f,g h \mathbb X \mathbb Y f(x)\leq g(x)\leq h(x) \lim\limits_{x\to a} f(x)= \lim\limits_{x\to a} h(x)=L L\in\Bbb Y \lim\limits_{x\to a} g(x)\neq L, X Y X Y \Bbb R.","['real-analysis', 'functional-analysis', 'limits', 'analysis']"
8,When are positive elements mapped to $1$ by same pure states,When are positive elements mapped to  by same pure states,1,"Let $\mathcal{A}$ be a unital C*-algebra, and $0\leq a\leq b\in\mathcal{A}$ be 2 positive elements with unit length, $\|a\|=\|b\|=1$ . Show $\|b-(1-a)\|=1$ . I'm trying to prove by finding a pure state $f$ such that $f(a)=f(b)=1$ . Does it always exist?","Let be a unital C*-algebra, and be 2 positive elements with unit length, . Show . I'm trying to prove by finding a pure state such that . Does it always exist?",\mathcal{A} 0\leq a\leq b\in\mathcal{A} \|a\|=\|b\|=1 \|b-(1-a)\|=1 f f(a)=f(b)=1,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
9,Eigenvectors spanning closed subspace in a Banach space,Eigenvectors spanning closed subspace in a Banach space,,"I'm looking for an example of a (bounded) linear operator $T$ on a Banach space $X$ with infinitely many eigenvalues such that $\sum_{\lambda\in\mathbb C}\ker(T-\lambda)$ is closed where the sum denotes the algebraic sum as vector spaces, i.e. the smallest vector space containing $\ker(T-\lambda)$ for all $\lambda\in\mathbb C$ . So far in the examples I've tried, it seems like this fails to be the case, at best this sum is dense in $X$ , for instance any normal operators on a Hilbert space. Since $\sum_{\lambda\in\mathbb C}\ker(T-\lambda)$ is closed, we know that it must have an uncountable dimension, so either there are uncountably many eigenvalues or the eigenspace has uncountable dimension. However this doesn't seem to help much. My intuition is that $X$ being complete would prevent this from happening but I can't seem to show that there must be an element in the closure that is not an eigenvector. So far my current attempt to show that $X$ need to have uncountably many eigenvalues is as follows: Let $\lambda_i$ be the set of eigenvalues of $T$ , i.e. $\{\lambda\in\mathbb C:\ker(T-\lambda)\neq\{0\}\}=\{\lambda_i\}_{i=0}^\infty$ . Then we want to show that $$\bigoplus_{i=0}^\infty\ker(T-\lambda_i)$$ is not closed. Choose arbitrary $x_i\in\ker(T-\lambda_i)$ such that $\left\lvert x_i\right\rvert<i^{-2}$ , then $$\sum_{i=0}^\infty x_i\in\overline{\bigoplus_{i=0}^\infty\ker(T-\lambda_i)}$$ However $$\alpha\sum_{i=0}^\infty x_i=\sum_{i=0}^\infty\lambda_ix_i$$ From here I'm hoping to show that $\sum_{i=0}^\infty x_i$ cannot be a finite sum of eigenvectors, but I'm not sure if the $\lambda_i$ on the RHS is the only way of expressing the LHS as a limit of scalar multiples of $x_i$ .","I'm looking for an example of a (bounded) linear operator on a Banach space with infinitely many eigenvalues such that is closed where the sum denotes the algebraic sum as vector spaces, i.e. the smallest vector space containing for all . So far in the examples I've tried, it seems like this fails to be the case, at best this sum is dense in , for instance any normal operators on a Hilbert space. Since is closed, we know that it must have an uncountable dimension, so either there are uncountably many eigenvalues or the eigenspace has uncountable dimension. However this doesn't seem to help much. My intuition is that being complete would prevent this from happening but I can't seem to show that there must be an element in the closure that is not an eigenvector. So far my current attempt to show that need to have uncountably many eigenvalues is as follows: Let be the set of eigenvalues of , i.e. . Then we want to show that is not closed. Choose arbitrary such that , then However From here I'm hoping to show that cannot be a finite sum of eigenvectors, but I'm not sure if the on the RHS is the only way of expressing the LHS as a limit of scalar multiples of .",T X \sum_{\lambda\in\mathbb C}\ker(T-\lambda) \ker(T-\lambda) \lambda\in\mathbb C X \sum_{\lambda\in\mathbb C}\ker(T-\lambda) X X \lambda_i T \{\lambda\in\mathbb C:\ker(T-\lambda)\neq\{0\}\}=\{\lambda_i\}_{i=0}^\infty \bigoplus_{i=0}^\infty\ker(T-\lambda_i) x_i\in\ker(T-\lambda_i) \left\lvert x_i\right\rvert<i^{-2} \sum_{i=0}^\infty x_i\in\overline{\bigoplus_{i=0}^\infty\ker(T-\lambda_i)} \alpha\sum_{i=0}^\infty x_i=\sum_{i=0}^\infty\lambda_ix_i \sum_{i=0}^\infty x_i \lambda_i x_i,"['functional-analysis', 'eigenvalues-eigenvectors', 'operator-theory', 'banach-spaces']"
10,Find solution of particular integral transform,Find solution of particular integral transform,,"Here's a (not so) fun problem I've encountered trying to complete a proof. I have some constants $b > 0$ , $k < 0$ , and $c_1, c_2 \in \mathbb R$ , and I need to find a function $f:[0, b] \to \mathbb R$ and constant $\lambda \in \mathbb R$ such that $$ c_1 \int_0^x e^{k(x - y)} f(y) ~dy + c_2 \int_x^{b} e^{-k(x - y)} f(y) ~dy = \lambda e^{-kx}, $$ for all $x \in [0, b]$ . Does anyone have an approach to find $f$ ?","Here's a (not so) fun problem I've encountered trying to complete a proof. I have some constants , , and , and I need to find a function and constant such that for all . Does anyone have an approach to find ?","b > 0 k < 0 c_1, c_2 \in \mathbb R f:[0, b] \to \mathbb R \lambda \in \mathbb R 
c_1 \int_0^x e^{k(x - y)} f(y) ~dy + c_2 \int_x^{b} e^{-k(x - y)} f(y) ~dy = \lambda e^{-kx},
 x \in [0, b] f","['integration', 'functional-analysis', 'problem-solving', 'integral-transforms']"
11,Homogeneity on Minkowski functional,Homogeneity on Minkowski functional,,"Let $ X $ be a vector space over a field $ \mathbb{K} = \mathbb{R}, \mathbb{C} $ and $ A \subseteq X $ convex and absorbing. Then $ \forall x, y \in X $ , $ \forall t > 0 $ $ \mu_A (x + y) \leq \mu_A (x) + \mu_A (y) $ $ \mu_A (tx) = t \mu_A (x) $ In Rudin's Functional Analysis, theorem 1.35, it states  that $ \mu_A $ is a seminorm if $ A $ is also balanced, so that one has to prove $ \forall \alpha \in \mathbb{C} $ $ \mu_A (\alpha x) = |\alpha| \mu_A (x) $ ; according to the book, it follows from 1. and 2., still I have no clue why. I suppose I may start with $ \mu_A (\alpha x) = \mu_A ((a+ib)x) \leq \mu_A (ax) + \mu_A (ibx) $ but I cannot go much further. Can anyone provide (a sketch of) a complete proof?","Let be a vector space over a field and convex and absorbing. Then , In Rudin's Functional Analysis, theorem 1.35, it states  that is a seminorm if is also balanced, so that one has to prove ; according to the book, it follows from 1. and 2., still I have no clue why. I suppose I may start with but I cannot go much further. Can anyone provide (a sketch of) a complete proof?"," X   \mathbb{K} = \mathbb{R}, \mathbb{C}   A \subseteq X   \forall x, y \in X   \forall t > 0   \mu_A (x + y) \leq \mu_A (x) + \mu_A (y)   \mu_A (tx) = t \mu_A (x)   \mu_A   A   \forall \alpha \in \mathbb{C}   \mu_A (\alpha x) = |\alpha| \mu_A (x)   \mu_A (\alpha x) = \mu_A ((a+ib)x) \leq \mu_A (ax) + \mu_A (ibx) ","['functional-analysis', 'proof-explanation', 'topological-vector-spaces']"
12,Does this linear operator tends to zero?,Does this linear operator tends to zero?,,"Let $X$ separable Hilbert space with basis $\{e_n\}$ , $U_N=\{e_1,...e_N \} \subset X$ , $P_N$ the projection operator over $U_N$ . Define $Q_N=I-P_N$ the orthogonal complement ( $I$ identity) and $B \colon X \to X$ compact linear operator. I want to prove that $$\lim_{N \to \infty}||BQ_N||= 0$$ I would proceed in the following way: For every $x \in X$ we have $P_N x \to x$ as $N \to \infty$ . Then $Q_N x \to 0$ so that $BQ_N x \to 0$ . Now since $B$ is compact we have that the set $$\overline{B Q_N \{ x \in X: |x|=1\}}=B Q_N \{ x\in X: |x|=1\} $$ is compact. This should imply that the convergence $BQ_N x \to 0$ is uniform in $\{x \in X, |x|=1 \}$ , i.e. $$\sup_{|x|=1} |B Q_Nx| \to 0$$ which implies my claim. How do I justify the uniform convergence in $\{x \in X, |x|=1 \}$ ?","Let separable Hilbert space with basis , , the projection operator over . Define the orthogonal complement ( identity) and compact linear operator. I want to prove that I would proceed in the following way: For every we have as . Then so that . Now since is compact we have that the set is compact. This should imply that the convergence is uniform in , i.e. which implies my claim. How do I justify the uniform convergence in ?","X \{e_n\} U_N=\{e_1,...e_N \} \subset X P_N U_N Q_N=I-P_N I B \colon X \to X \lim_{N \to \infty}||BQ_N||= 0 x \in X P_N x \to x N \to \infty Q_N x \to 0 BQ_N x \to 0 B \overline{B Q_N \{ x \in X: |x|=1\}}=B Q_N \{ x\in X: |x|=1\}  BQ_N x \to 0 \{x \in X, |x|=1 \} \sup_{|x|=1} |B Q_Nx| \to 0 \{x \in X, |x|=1 \}","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'banach-spaces']"
13,Best Embedding Constant for Weighted $L^p$ Space,Best Embedding Constant for Weighted  Space,L^p,"Let $\Omega \subset \mathbb{R}^n$ be a bounded Lebesgue measurable set of positive measure. Fix a function $A: \Omega \to \mathbb{R}$ such that $A \in L^{\infty}(\Omega)$ and there is a constant $a$ such that $A(x)>a>0$ for almost every $x \in \Omega$ . Fix also a $p \in [1,\infty)$ . We can norm the space $L^p(\Omega)$ in the following two ways: for every $f: \Omega \to \mathbb{R}$ , we set : \begin{equation*} \|f\| = (\int_{\Omega}|f(x)|^pdx)^{\frac{1}{p}}; \|f\|_A = (\int_{\Omega}|f(x)|^pA(x)dx)^{\frac{1}{p}} \end{equation*} Clearly $\|kf\|_A=|k|\|f\|_A$ for every $k \in \mathbb{R}$ . By viewing $A(x)dx$ as a measure, Minkowski's inequality shows that $\|f+g\|_A\leq\|f\|_A+\|g\|_A$ . Also, if $\|f\|_A=0$ , then by the condition $A(x)>a>0$ almost everywhere we get $f=0$ almost everywhere. Therefore, $\|\cdot\|_A$ is a norm. Clearly, one always has: \begin{equation*} \|f\|_A \leq (\|A\|_{\infty})^{\frac{1}{p}} \|f\| \end{equation*} By assumption, $\|A\|_{\infty} \in (0,\infty)$ . Therefore, $\| \cdot \|$ and $\| \cdot \|_A$ are equivalent norms in the Banach space $L^p(\Omega)$ . The following best embedding constants are well-defined and finite: \begin{equation*} c = \inf \frac{\|f\|_A}{\|f\|}; d = \inf \frac{\|f\|}{\|f\|_A} \end{equation*} The infinums are taken over every nonzero $f\in L^p(\Omega)$ . My goal is to compute $c$ and $d$ by expressing them in terms of $\Omega$ and $A$ (or even better to find an $f$ attaining these infinums but this is not required). So let us just focus on computing $c$ . Set $f(x)=1$ for every $x \in \Omega$ we see that: \begin{equation*} c \leqslant (\frac{1}{m(\Omega)}\int_{\Omega}A(x)dx)^{\frac{1}{p}} \end{equation*} My conjecture is that $c=(\frac{1}{m(\Omega)}\int_{\Omega}A(x)dx)^{\frac{1}{p}}$ . But I cannot play it out using Hölder's inequalities or find counterexamples. How do I proceed? Note1: as pointed out by Ryszard Szwarc, $A>0$ is not sufficient to make sure norms are equivalent: let $\Omega=(0,1)$ and $A(x)=1-x.$ For $f_n(x)=x^{n/2}$ we have $$\|f_n\|^2={1\over n+1},\qquad \|f_n\|^2_A={1\over (n+1)(n+2)}$$ In general let $$ U_n=\{x\in \Omega\,:\, |A(x)|\le n^{-1/2}\},\qquad m(U_n)>0$$ . Then for $f_n=\chi_{U_n}$ we have $$\|f_n\|^2=m(U_n), \qquad \|f_n\|^2_A\le {m(U_n)\over n}$$ I have updated the question to add the assumption that $A$ is bounded away from $0$ . Note2: if it is ever needed we can work in stronger set of hypothesis: $p \in (1,\infty)$ , $\Omega$ open connected with smooth boundary or even $\Omega$ is a unit ball. But I guess these conditions do not really matter.","Let be a bounded Lebesgue measurable set of positive measure. Fix a function such that and there is a constant such that for almost every . Fix also a . We can norm the space in the following two ways: for every , we set : Clearly for every . By viewing as a measure, Minkowski's inequality shows that . Also, if , then by the condition almost everywhere we get almost everywhere. Therefore, is a norm. Clearly, one always has: By assumption, . Therefore, and are equivalent norms in the Banach space . The following best embedding constants are well-defined and finite: The infinums are taken over every nonzero . My goal is to compute and by expressing them in terms of and (or even better to find an attaining these infinums but this is not required). So let us just focus on computing . Set for every we see that: My conjecture is that . But I cannot play it out using Hölder's inequalities or find counterexamples. How do I proceed? Note1: as pointed out by Ryszard Szwarc, is not sufficient to make sure norms are equivalent: let and For we have In general let . Then for we have I have updated the question to add the assumption that is bounded away from . Note2: if it is ever needed we can work in stronger set of hypothesis: , open connected with smooth boundary or even is a unit ball. But I guess these conditions do not really matter.","\Omega \subset \mathbb{R}^n A: \Omega \to \mathbb{R} A \in L^{\infty}(\Omega) a A(x)>a>0 x \in \Omega p \in [1,\infty) L^p(\Omega) f: \Omega \to \mathbb{R} \begin{equation*}
\|f\| = (\int_{\Omega}|f(x)|^pdx)^{\frac{1}{p}}; \|f\|_A = (\int_{\Omega}|f(x)|^pA(x)dx)^{\frac{1}{p}}
\end{equation*} \|kf\|_A=|k|\|f\|_A k \in \mathbb{R} A(x)dx \|f+g\|_A\leq\|f\|_A+\|g\|_A \|f\|_A=0 A(x)>a>0 f=0 \|\cdot\|_A \begin{equation*}
\|f\|_A \leq (\|A\|_{\infty})^{\frac{1}{p}} \|f\|
\end{equation*} \|A\|_{\infty} \in (0,\infty) \| \cdot \| \| \cdot \|_A L^p(\Omega) \begin{equation*}
c = \inf \frac{\|f\|_A}{\|f\|}; d = \inf \frac{\|f\|}{\|f\|_A}
\end{equation*} f\in L^p(\Omega) c d \Omega A f c f(x)=1 x \in \Omega \begin{equation*}
c \leqslant (\frac{1}{m(\Omega)}\int_{\Omega}A(x)dx)^{\frac{1}{p}}
\end{equation*} c=(\frac{1}{m(\Omega)}\int_{\Omega}A(x)dx)^{\frac{1}{p}} A>0 \Omega=(0,1) A(x)=1-x. f_n(x)=x^{n/2} \|f_n\|^2={1\over n+1},\qquad \|f_n\|^2_A={1\over (n+1)(n+2)}  U_n=\{x\in \Omega\,:\, |A(x)|\le n^{-1/2}\},\qquad m(U_n)>0 f_n=\chi_{U_n} \|f_n\|^2=m(U_n), \qquad \|f_n\|^2_A\le {m(U_n)\over n} A 0 p \in (1,\infty) \Omega \Omega","['real-analysis', 'functional-analysis', 'optimization', 'lebesgue-integral', 'lp-spaces']"
14,Is 'Jensen type inquality' true in the following form $h\circ(g*f)\leq g* (h\circ f)$,Is 'Jensen type inquality' true in the following form,h\circ(g*f)\leq g* (h\circ f),"Given a convex function $h$ and some other  integrable functions $g$ and $f$ , is it true that $$h\circ(g*f)\leq g* (h\circ f)\;?$$ If not, which additional assumption would lead to the statement holding? Note that $\circ$ denotes composition, while $*$ denotes convolution. My idea: $$ h\bigg(\int_{0}^{t}g(t-s)f(s)ds\bigg)=h\bigg(\int_{0}^{t}f(s)\mu_{g}(ds)\bigg),$$ where $\mu_{g}$ is the measure with density $g(s)$ with respect to the Lebesgue measure. I assume now we can apply Jensen, and then we are done?","Given a convex function and some other  integrable functions and , is it true that If not, which additional assumption would lead to the statement holding? Note that denotes composition, while denotes convolution. My idea: where is the measure with density with respect to the Lebesgue measure. I assume now we can apply Jensen, and then we are done?","h g f h\circ(g*f)\leq g* (h\circ f)\;? \circ *  h\bigg(\int_{0}^{t}g(t-s)f(s)ds\bigg)=h\bigg(\int_{0}^{t}f(s)\mu_{g}(ds)\bigg), \mu_{g} g(s)","['real-analysis', 'integration', 'functional-analysis', 'inequality', 'convex-analysis']"
15,What is the mathematical definition of the integrals seen in quantum mechanics?,What is the mathematical definition of the integrals seen in quantum mechanics?,,"Given a separable Hilbert space, we can find a Hilbert basis,which is countable and each element can be expressed as an infinite linear combination with $l^2$ coefficients. Ok this is clear and well-known in maths. But in QM, they also use uncoutnable family of states and state that each element of the Hilbert can be written as an integral of those with ""coefficients"" a function in $L^2$ My question : what is the name of this, mathematically ? It is not an instance of Lebesgue integral, since the function we are integrating is not complex valued.","Given a separable Hilbert space, we can find a Hilbert basis,which is countable and each element can be expressed as an infinite linear combination with coefficients. Ok this is clear and well-known in maths. But in QM, they also use uncoutnable family of states and state that each element of the Hilbert can be written as an integral of those with ""coefficients"" a function in My question : what is the name of this, mathematically ? It is not an instance of Lebesgue integral, since the function we are integrating is not complex valued.",l^2 L^2,"['functional-analysis', 'quantum-mechanics']"
16,"Stone-Weierstrass theorem with ""nowhere-vanishing"" premise","Stone-Weierstrass theorem with ""nowhere-vanishing"" premise",,"Let $K$ be a compact space and $\mathscr A\subseteq C(K,\mathbb R)$ be a subalgebra. Let us assume the ""usual"" form of the real Stone-Weierstrass theorem: If $\mathscr A$ separates points in $K$ and contains a nonzero constant function , then it is uniformly dense in $C(K,\mathbb R)$ . Rudin proves this with weaker premises (hence, his version is stronger), namely, replacing the bold part with the requirement that the $\mathscr A$ vanish nowhere (baby Rudin, Theorem 7.32). I'd like to prove Rudin's stronger version, but in the fastest way possible, given that I've already proven the usual form given above. In particular, I only need to prove that $1\in\overline{\mathscr A}$ . I think this can be done without repeating all of Rudin's proof. Current progress/idea: Repeat the first part of Rudin's proof, which uses the Weierstrass theorem (for polynomials) to show that $f,g\in\overline{\mathscr A}\implies\max(f,g)\in\overline{\mathscr A}$ . The nowhere-vanishing condition can be used to find functions $f_x\in\mathscr A$ such that $f_x(x)=1.$ Using compactness of $K$ and closure of $\mathscr A$ under finite maximums, we can constrct a function $f\in\mathscr A$ such that $f(x)>1-\varepsilon$ for small $\varepsilon>0$ . Using some constructions like this and combining them appropriately, I imagine we can find a function that falls uniformly within $\varepsilon$ of $1$ , but so far I'm stuck here.","Let be a compact space and be a subalgebra. Let us assume the ""usual"" form of the real Stone-Weierstrass theorem: If separates points in and contains a nonzero constant function , then it is uniformly dense in . Rudin proves this with weaker premises (hence, his version is stronger), namely, replacing the bold part with the requirement that the vanish nowhere (baby Rudin, Theorem 7.32). I'd like to prove Rudin's stronger version, but in the fastest way possible, given that I've already proven the usual form given above. In particular, I only need to prove that . I think this can be done without repeating all of Rudin's proof. Current progress/idea: Repeat the first part of Rudin's proof, which uses the Weierstrass theorem (for polynomials) to show that . The nowhere-vanishing condition can be used to find functions such that Using compactness of and closure of under finite maximums, we can constrct a function such that for small . Using some constructions like this and combining them appropriately, I imagine we can find a function that falls uniformly within of , but so far I'm stuck here.","K \mathscr A\subseteq C(K,\mathbb R) \mathscr A K C(K,\mathbb R) \mathscr A 1\in\overline{\mathscr A} f,g\in\overline{\mathscr A}\implies\max(f,g)\in\overline{\mathscr A} f_x\in\mathscr A f_x(x)=1. K \mathscr A f\in\mathscr A f(x)>1-\varepsilon \varepsilon>0 \varepsilon 1","['real-analysis', 'functional-analysis', 'analysis', 'weierstrass-approximation']"
17,"Why is ""weak convergence of a sequence to $0$"" equivalent to ""accumulation points of the sequence are all $0$"" in the proof of mean ergodic theorem?","Why is ""weak convergence of a sequence to "" equivalent to ""accumulation points of the sequence are all "" in the proof of mean ergodic theorem?",0 0,"For some context, I am referring to a proof of the Mean Ergodic Theorem from Ergodic Theory and Dynamical Systems by Yves Coudene. Suppose $H$ is a Hilbert space, and let $U \colon H \to H$ be a linear map with $|| Uf || \leq ||f||$ . Set $$S_n(f) = \sum_{k=0}^{n-1} U^k f \qquad Inv = \{ f \in H : Uf = f\}.$$ Then $$ \frac{1}{n} S_n(f) \to Pf $$ where $P$ is the orthogonal projection onto $Inv$ . We want to prove that $|| \tfrac{1}{n}S_n (f) || \to 0$ if $f \in Inv^\perp$ . The statement I am having difficulty understanding is We have the equality $$ || \tfrac{1}{n}S_n (f) ||^2 = \langle f, \tfrac{1}{n}{S_n}^*\tfrac{1}{n}S_n(f)\rangle. $$ We must therefore verify, for every $f \in Inv^\perp$ , that the sequence $\tfrac{1}{n}{S_n}^*\tfrac{1}{n}S_n(f)$ converges weakly to $0$ , or equivalently that the accumulation points of this sequence are all $0$ . Now I do not understand the equivalence here. The left to right implication is clear.","For some context, I am referring to a proof of the Mean Ergodic Theorem from Ergodic Theory and Dynamical Systems by Yves Coudene. Suppose is a Hilbert space, and let be a linear map with . Set Then where is the orthogonal projection onto . We want to prove that if . The statement I am having difficulty understanding is We have the equality We must therefore verify, for every , that the sequence converges weakly to , or equivalently that the accumulation points of this sequence are all . Now I do not understand the equivalence here. The left to right implication is clear.","H U \colon H \to H || Uf || \leq ||f|| S_n(f) = \sum_{k=0}^{n-1} U^k f \qquad Inv = \{ f \in H : Uf = f\}.  \frac{1}{n} S_n(f) \to Pf  P Inv || \tfrac{1}{n}S_n (f) || \to 0 f \in Inv^\perp  || \tfrac{1}{n}S_n (f) ||^2 = \langle f, \tfrac{1}{n}{S_n}^*\tfrac{1}{n}S_n(f)\rangle.  f \in Inv^\perp \tfrac{1}{n}{S_n}^*\tfrac{1}{n}S_n(f) 0 0","['functional-analysis', 'hilbert-spaces', 'weak-convergence', 'ergodic-theory']"
18,how to show an inequality from P.D.E,how to show an inequality from P.D.E,,"Let $\Omega$ a regular bounded open subset of $\mathbb{R}^N$ .  Let $T>0$ , $u_0 \in L^2$ , $b \in L^{\infty}(]0,T[\, \times\, \Omega)^N$ , and $c \in L^{\infty}(]0,T[\, \times\, \Omega)$ . We consider the following equation on $]0,T[\, \times\, \Omega$ . $\partial_{t} u+b \cdot \nabla u+c u-\Delta u=0$ $u|_{\partial \Omega} =0$ and $u|_{t=0}=u_0$ . Question : Show that if $u \in C^1([0,T],C^2(\Omega)) $ is a   solution then $\frac{d}{d t}\|u(t)\|_{L^{2}(\Omega)}^{2}+\int_{\Omega}|\nabla u(t, x)|^{2} d x \leq\left(2\|c\|_{\infty}+\|b\|^2_{\infty}\right)\|u(t)\|_{L^{2}(\Omega)}^{2}$ . My attempt :  I can show that $$\frac 12 \frac{d}{d t}\|u(t)\|_{L^{2}(\Omega)}^{2}+\int_{\Omega}|\nabla u(t, x)|^{2} d x \leq\|c\|_{\infty}\|u(t)\|_{L^{2}(\Omega)}^{2}+|\int_{\Omega} (b \cdot \nabla u)u |$$ How to continue with this term $|\int_{\Omega} (b \cdot \nabla u)u |$ ?","Let a regular bounded open subset of .  Let , , , and . We consider the following equation on . and . Question : Show that if is a   solution then . My attempt :  I can show that How to continue with this term ?","\Omega \mathbb{R}^N T>0 u_0 \in L^2 b \in L^{\infty}(]0,T[\, \times\, \Omega)^N c \in L^{\infty}(]0,T[\, \times\, \Omega) ]0,T[\, \times\, \Omega \partial_{t} u+b \cdot \nabla u+c u-\Delta u=0 u|_{\partial \Omega} =0 u|_{t=0}=u_0 u \in C^1([0,T],C^2(\Omega))  \frac{d}{d t}\|u(t)\|_{L^{2}(\Omega)}^{2}+\int_{\Omega}|\nabla u(t, x)|^{2} d x \leq\left(2\|c\|_{\infty}+\|b\|^2_{\infty}\right)\|u(t)\|_{L^{2}(\Omega)}^{2} \frac 12 \frac{d}{d t}\|u(t)\|_{L^{2}(\Omega)}^{2}+\int_{\Omega}|\nabla u(t, x)|^{2} d x \leq\|c\|_{\infty}\|u(t)\|_{L^{2}(\Omega)}^{2}+|\int_{\Omega} (b \cdot \nabla u)u | |\int_{\Omega} (b \cdot \nabla u)u |","['functional-analysis', 'partial-differential-equations']"
19,Showing the polarization of (complex) quadratic form is sesquilinear. [duplicate],Showing the polarization of (complex) quadratic form is sesquilinear. [duplicate],,"This question already has answers here : Can we define an inner product in terms of the norm induced by it? (1 answer) Polarization of quadratic form yields sesquilinear form (1 answer) Closed 2 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Let $q: V\times V \to \mathbb{C}$ on a complex vector space $V$ be a quadratic form. Define $\tilde q$ by the polarization identity: $$ \begin{equation} \tilde q(\phi,\psi)  = \frac{1}{4} [q(\phi + \psi) -q(\phi - \psi) + iq(\phi + i\psi) - iq(\phi - i\psi)]   \end{equation} $$ My question is how can I show that $\tilde q$ is sesquilinear? My plan is to show that (1) $\tilde q$ is skew-symmetric, and (2) linear in the second argument. However, to show (2), I'm not exactly sure how to do so given that $q$ is defined in complex space. I found a hint that tells me to show that a. $\tilde q(\phi, 2\psi) = 2\tilde q(\phi, \psi)$ b. $\tilde q(\phi, \psi + \psi') = \tilde q(\phi, \psi) + \tilde q(\phi, \psi')$ c. $\tilde q(\phi, \pm i\psi ) = \pm i\tilde q(\phi, \psi)$ d. $\tilde q(\phi, \alpha\psi ) = \alpha\tilde q(\phi, \psi )$ for all dyadic rationals in $\mathbb C$ . It makes sense to me that we need to take the complex part into account for $c$ and $d$ . However, I have no idea what $d$ means. Also for $a$ , is the number 2 just some random real integer? PS: Here's the definition I want to use for (complex) quadratic form: $q(\lambda x) = |\lambda|^2q(x)\quad \forall \lambda\in\mathbb C, x\in V$ $q(\phi+\psi) + q(\phi-\psi) = 2q(\psi)+2q(\phi)$ From 2, we could rewrite the polarization identity as $$ \tilde q(\phi,\psi) = \frac{1}{2}[q(\phi+i\psi)-q(\phi)-q(\psi)] - \frac{i}{2}[q(\phi+i\psi)-q(\phi)-q(i\psi)] $$ But I'm unsure if that's helpful for showing $\tilde q$ is sesquilinear. Thanks for the help!","This question already has answers here : Can we define an inner product in terms of the norm induced by it? (1 answer) Polarization of quadratic form yields sesquilinear form (1 answer) Closed 2 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Let on a complex vector space be a quadratic form. Define by the polarization identity: My question is how can I show that is sesquilinear? My plan is to show that (1) is skew-symmetric, and (2) linear in the second argument. However, to show (2), I'm not exactly sure how to do so given that is defined in complex space. I found a hint that tells me to show that a. b. c. d. for all dyadic rationals in . It makes sense to me that we need to take the complex part into account for and . However, I have no idea what means. Also for , is the number 2 just some random real integer? PS: Here's the definition I want to use for (complex) quadratic form: From 2, we could rewrite the polarization identity as But I'm unsure if that's helpful for showing is sesquilinear. Thanks for the help!","q: V\times V \to \mathbb{C} V \tilde q 
\begin{equation}
\tilde q(\phi,\psi)  = \frac{1}{4} [q(\phi + \psi) -q(\phi - \psi) + iq(\phi + i\psi) - iq(\phi - i\psi)]  
\end{equation}
 \tilde q \tilde q q \tilde q(\phi, 2\psi) = 2\tilde q(\phi, \psi) \tilde q(\phi, \psi + \psi') = \tilde q(\phi, \psi) + \tilde q(\phi, \psi') \tilde q(\phi, \pm i\psi ) = \pm i\tilde q(\phi, \psi) \tilde q(\phi, \alpha\psi ) = \alpha\tilde q(\phi, \psi ) \mathbb C c d d a q(\lambda x) = |\lambda|^2q(x)\quad \forall \lambda\in\mathbb C, x\in V q(\phi+\psi) + q(\phi-\psi) = 2q(\psi)+2q(\phi) 
\tilde q(\phi,\psi) = \frac{1}{2}[q(\phi+i\psi)-q(\phi)-q(\psi)] - \frac{i}{2}[q(\phi+i\psi)-q(\phi)-q(i\psi)]
 \tilde q","['functional-analysis', 'hilbert-spaces', 'quadratic-forms', 'riesz-representation-theorem', 'sesquilinear-forms']"
20,Externalizing A Concrete Application of Double Negation Toposes,Externalizing A Concrete Application of Double Negation Toposes,,"I'm trying to come up with concrete problems which can be solved via topos theory, and I've found a good case study which has been really instructive. I've spent the past few weeks trying to understand how it interacts with double negation sheaves, but I can't quite get it straight in my head. Hopefully somebody here will be able to help ^_^. For completeness, recall the Weierstrass Approximation Theorem, which says $$\forall f : C \big ( [0,1], \ \mathbb{R} \big ) . \ \forall \epsilon : \mathbb{R}_{> 0} . \ \exists p : \mathbb{R}[t] . \ \forall t : [0,1] . \ | f(t) - p(t) | < \epsilon$$ Now say we have a continuous family of functions $f_x : [0,1] \to \mathbb{R}$ instead. so $f : X \times [0,1] \to \mathbb{R}$ for some topological space $X$ . It's reasonable to ask if the polynomials $p_x$ approximating $f_x$ vary continuously in $X$ . We might expect the Weierstrass Approximation Theorem to be constructive. After all, the argument by Bernstein Polynomials actually gives us a sequence in-hand of approximating polynomials. Then, inside the topos $\mathsf{Sh}(X)$ , the theorem is true, and externally we would be able to see that For all $f : X \times [0,1] \to \mathbb{R}$ continuous, for all $\epsilon > 0$ , there is an open cover $U_\alpha$ of $X$ and polynomials $p_\alpha$ with coefficients continuous on $U_\alpha$ so that $|f(x,t) - p_\alpha(x,t)| < \epsilon$ for every $t \in [0,1]$ . which gives us a local solution to our problem. Unfortunately, in the usual proof that the bernstein polynomials really do approximate $f$ we do the standard analysis trick of separating into ""good"" and ""bad"" parts, then we show the good parts are small, and there aren't many bad parts. This uses LEM when we assert that every summand is either good or bad. From here, it's reasonable to pass to the double negation sheaves $\mathsf{Sh}_{\lnot \lnot}(X)$ , where the argument goes through... But I can't figure out how to externalize the claim! I know that $\mathsf{Sh}_{\lnot \lnot}(X)$ is equivalent to sheaves on the locale of regular opens. But usually this is a pointfree locale, and I'm not sure how the (dedekind) real numbers there (which, I think, are continuous maps from the locale of regular opens to the locale $\mathbb{R}$ ) relates to the real numbers in $\mathsf{Sh}(X)$ (which are continuous maps $X \to \mathbb{R}$ ). I've heard that truth in the double negation sheaves is the same as ""truth on a dense open set"", so that our claim reads something like ""there is a dense open set $V$ and an open cover $U_\alpha$ of $V$ so that ...."" but I'm still not sure if that works. Any guidance on externalizing statements from the double negation sheaves would be fantastic! Ideally a concrete example like this, with some explanation as to how the translation goes. (Also, I'm aware of the truly constructive proof in Bridges Constructive Functional Analysis , Chapter $4.3$ , which gets us out of this hole. But this is a good case study in working with double negation sheaves, so I would still like to know how to externalize the claim in the more complicated way.)","I'm trying to come up with concrete problems which can be solved via topos theory, and I've found a good case study which has been really instructive. I've spent the past few weeks trying to understand how it interacts with double negation sheaves, but I can't quite get it straight in my head. Hopefully somebody here will be able to help ^_^. For completeness, recall the Weierstrass Approximation Theorem, which says Now say we have a continuous family of functions instead. so for some topological space . It's reasonable to ask if the polynomials approximating vary continuously in . We might expect the Weierstrass Approximation Theorem to be constructive. After all, the argument by Bernstein Polynomials actually gives us a sequence in-hand of approximating polynomials. Then, inside the topos , the theorem is true, and externally we would be able to see that For all continuous, for all , there is an open cover of and polynomials with coefficients continuous on so that for every . which gives us a local solution to our problem. Unfortunately, in the usual proof that the bernstein polynomials really do approximate we do the standard analysis trick of separating into ""good"" and ""bad"" parts, then we show the good parts are small, and there aren't many bad parts. This uses LEM when we assert that every summand is either good or bad. From here, it's reasonable to pass to the double negation sheaves , where the argument goes through... But I can't figure out how to externalize the claim! I know that is equivalent to sheaves on the locale of regular opens. But usually this is a pointfree locale, and I'm not sure how the (dedekind) real numbers there (which, I think, are continuous maps from the locale of regular opens to the locale ) relates to the real numbers in (which are continuous maps ). I've heard that truth in the double negation sheaves is the same as ""truth on a dense open set"", so that our claim reads something like ""there is a dense open set and an open cover of so that ...."" but I'm still not sure if that works. Any guidance on externalizing statements from the double negation sheaves would be fantastic! Ideally a concrete example like this, with some explanation as to how the translation goes. (Also, I'm aware of the truly constructive proof in Bridges Constructive Functional Analysis , Chapter , which gets us out of this hole. But this is a good case study in working with double negation sheaves, so I would still like to know how to externalize the claim in the more complicated way.)","\forall f : C \big ( [0,1], \ \mathbb{R} \big ) . \ \forall \epsilon : \mathbb{R}_{> 0} . \ \exists p : \mathbb{R}[t] . \ \forall t : [0,1] . \ | f(t) - p(t) | < \epsilon f_x : [0,1] \to \mathbb{R} f : X \times [0,1] \to \mathbb{R} X p_x f_x X \mathsf{Sh}(X) f : X \times [0,1] \to \mathbb{R} \epsilon > 0 U_\alpha X p_\alpha U_\alpha |f(x,t) - p_\alpha(x,t)| < \epsilon t \in [0,1] f \mathsf{Sh}_{\lnot \lnot}(X) \mathsf{Sh}_{\lnot \lnot}(X) \mathbb{R} \mathsf{Sh}(X) X \to \mathbb{R} V U_\alpha V 4.3","['functional-analysis', 'sheaf-theory', 'topos-theory', 'constructive-mathematics', 'weierstrass-approximation']"
21,Sobolev space counterexample,Sobolev space counterexample,,"Is there an example of a smooth function $u:\mathbb{R}\to\mathbb{R}$ with compact support such that $|u|$ fails to lie in the Sobolev space $H^s(\mathbb{R})$ for every $s>1$ ? Clearly $|u|$ can fail to lie in $W^{s,\infty}$ , but it isn't clear to me that the singularities that arise in the $L^{\infty}$ case can't be ""integrated"" away in the $H^s$ case. Am I missing an obvious example?","Is there an example of a smooth function with compact support such that fails to lie in the Sobolev space for every ? Clearly can fail to lie in , but it isn't clear to me that the singularities that arise in the case can't be ""integrated"" away in the case. Am I missing an obvious example?","u:\mathbb{R}\to\mathbb{R} |u| H^s(\mathbb{R}) s>1 |u| W^{s,\infty} L^{\infty} H^s","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
22,"For which $p \in [1, \infty]$ the sequence is Cauchy",For which  the sequence is Cauchy,"p \in [1, \infty]","Let $f_n (x) = \frac{n}{1+n\sqrt{x}}$ , for $x \in (0,1)$ . I am asked to find for which $p \in [1, \infty]$ $(f_n)_n$ is a Cauchy sequence with respect to $L^p$ norm. First of all, I observed that $(L^p(0,1), ||\cdot||_{L^p})$ is a Banach space for all $1 \le p \le \infty$ . Thus, $(f_n)_n$ is a Cauchy sequence $\Leftrightarrow$ $(f_n)_n$ is convergent in $L^p(0,1)$ . Moreover, since $\lim_{n \rightarrow \infty} f_n (x) = f(x) := \frac{1}{\sqrt{x}} \in L^p(0,1), 1 \le p < 2$ , for all $x \in (0,1)$ , the strong limit - if it exists - must coincide with $f$ . The case $p=1$ is easy, as it is possible to show that $||f_n - f||_{L^1} = \int_{0}^{1} \frac{1}{\sqrt{x} + nx} dx = \frac{2 log(n+1)}{n} \rightarrow 0$ as $n$ approaches infinity. Hence, the sequence being convergent in $L^p(0,1)$ is Cauchy. For the case $1 < p < \infty$ (and similarly for $p=\infty$ ), I proceeded in a similar way. However, in this case I end up with an integral that does not converge for all $n \in \mathbb{N}$ , that is $||f_n - f||_{L^1} = \int_{0}^{1} \frac{1}{\sqrt{x} + nx}^p dx = \left.\frac{1}{n} \frac{(t + n t^2)^{1-p}}{p-1}\,\right|_{0}^{1} \rightarrow \infty$ as $x \rightarrow 0$ . Is it correct to state that in this case the sequence does not converge (and thus it can't be a Cauchy sequence)? My doubt here concerns the fact that I am not able to estimate this integral with something that is convergent as $x$ approaches $0$ and hence I cannot take the limit for $n \rightarrow \infty$ and conclude. If anyone could give me a feedback on my reasoning or suggest a more straight-forward way to solve the problem, it would be greatly appreciated.","Let , for . I am asked to find for which is a Cauchy sequence with respect to norm. First of all, I observed that is a Banach space for all . Thus, is a Cauchy sequence is convergent in . Moreover, since , for all , the strong limit - if it exists - must coincide with . The case is easy, as it is possible to show that as approaches infinity. Hence, the sequence being convergent in is Cauchy. For the case (and similarly for ), I proceeded in a similar way. However, in this case I end up with an integral that does not converge for all , that is as . Is it correct to state that in this case the sequence does not converge (and thus it can't be a Cauchy sequence)? My doubt here concerns the fact that I am not able to estimate this integral with something that is convergent as approaches and hence I cannot take the limit for and conclude. If anyone could give me a feedback on my reasoning or suggest a more straight-forward way to solve the problem, it would be greatly appreciated.","f_n (x) = \frac{n}{1+n\sqrt{x}} x \in (0,1) p \in [1, \infty] (f_n)_n L^p (L^p(0,1), ||\cdot||_{L^p}) 1 \le p \le \infty (f_n)_n \Leftrightarrow (f_n)_n L^p(0,1) \lim_{n \rightarrow \infty} f_n (x) = f(x) := \frac{1}{\sqrt{x}} \in L^p(0,1), 1 \le p < 2 x \in (0,1) f p=1 ||f_n - f||_{L^1} = \int_{0}^{1} \frac{1}{\sqrt{x} + nx} dx = \frac{2 log(n+1)}{n} \rightarrow 0 n L^p(0,1) 1 < p < \infty p=\infty n \in \mathbb{N} ||f_n - f||_{L^1} = \int_{0}^{1} \frac{1}{\sqrt{x} + nx}^p dx = \left.\frac{1}{n} \frac{(t + n t^2)^{1-p}}{p-1}\,\right|_{0}^{1} \rightarrow \infty x \rightarrow 0 x 0 n \rightarrow \infty","['functional-analysis', 'lp-spaces', 'cauchy-sequences']"
23,What's the role of domain compactness in the Ascoli-Arzela theorem?,What's the role of domain compactness in the Ascoli-Arzela theorem?,,"The problem From what I've read in the literature I get the idea that domain compactness is quite crucial in the theorem, and yet looking at the proof it seems to me as an unnecessary assumption. I surmise I'm probably missing an important part of the picture. In order to fix some notation and say what I mean precisely, allow me to repeat the proof down here. I will assume we are all familiar with the notions of equicontinuity and uniform boundedness. The theorem If a family $\mathcal{F}$ of functions from [a,b] to $\mathbb{R}$ is uniformly bounded and  uniformly equicontinuous, then every sequence of functions in $\mathcal{F}$ admits a convergent subsequence. Proof. Let us fix a sequence $(f_n)\subseteq\mathcal{F}$ and an enumeration $(q_n)$ of the rationals in $[a,b]$ . Since the numeric sequence $\big(f_n(q_0)\big)_{n\in\mathbb{N}}$ is bounded, by the Bolzano-Weierstrass theorem, it admits a convergent subsequence $\big(f_{n_k}(q_0)\big)_{k\in\mathbb{N}}$ , which defines a corresponding subsequence of functions $(f_{n_k})_{k\in\mathbb{N}}$ . By the same token, the numeric sequence $\big(f_{n_k}(q_1)\big)_{k\in\mathbb{N}}$ admits a convergent subsequence $\big(f_{n_k}^{(1)}(q_1)\big)_{k\in\mathbb{N}}$ , to which corresponds the subsequence of functions $(f_{n_k}^{(1)})_{k\in\mathbb{N}}$ , and so on. Iterating this process by induction, we get an infinite chain of nested subsequences \begin{equation} (f_{n_k})_{k\in\mathbb{N}}\supseteq (f_{n_k}^{(1)})_{k\in\mathbb{N}}\supseteq (f_{n_k}^{(2)})_{k\in\mathbb{N}}\supseteq (f_{n_k}^{(3)})_{k\in\mathbb{N}}\supseteq \,... \end{equation} Consider now the `diagonal' subsequence $(f_{n_k}^{(k)})_{k\in\mathbb{N}}$ . By construction, this sequence of functions converges at all rational points in $[a,b]$ . Therefore, given a $q_m$ and an $\epsilon>0$ there is a $\nu\in\mathbb{N}$ such that \begin{equation} |f_{n_k}^{(k)}(q_m)-f_{n_h}^{(h)}(q_m)| \le \frac{\epsilon}{3}, \end{equation} for all $k,h\ge\nu$ . Furthermore by the uniform equicontinuity of $\mathcal{F}$ , for any $x\in [a,b]$ there is an interval $J_x$ such that \begin{equation} |f_{n_k}^{(k)}(y)-f_{n_k}^{(k)}(z)| \le \frac{\epsilon}{3}, \end{equation} for all $y,z\in J_x$ and all $k\in\mathbb{N}$ . (#) These intervals form an open cover of $[a,b]$ from which we can extract a finite subcover $\{J_{x_1},\,...,J_{x_p}\}$ . By the density of $\mathbb{Q}$ , each of these intervals contains a point of $(q_m)$ , and thus there is an $M\in\mathbb{N}$ such that every interval of the finite subcover contains a rational $q_m$ with $0\le m\le M$ . Moreover, for any $x\in[a,b]$ there is a $J_{x_j}$ with $1\le j\le p$ containing a $q_m$ with $1\le m\le M$ . (#) But then, chosen a $q_m$ lying in the same interval as $x$ and $k,h$ sufficiently large, \begin{align} &|f_{n_k}^{(k)}(x)-f_{n_h}^{(h)}(x)| \le\nonumber\\ &|f_{n_k}^{(k)}(x)-f_{n_k}^{(h)}(q_m)| + |f_{n_k}^{(k)}(q_m)-f_{n_h}^{(h)}(q_m)| + |f_{n_h}^{(h)}(q_m)-f_{n_h}^{(h)}(x)| \le\nonumber\\ &\hspace{3.5cm}\le\frac{\epsilon}{3} + \frac{\epsilon}{3} + \frac{\epsilon}{3} = \epsilon, \end{align} therefore the sequence is uniformly Cauchy and thus $(f_{n_k}^{(k)})_{k\in\mathbb{N}}$ converges uniformly. The question The entire part enclosed by the symbol (#) seems completely inessential to me. Why can't we just say that by the density of rationals, $J_x$ contains some $q_m$ and be done with it? If that was the case we would not even need to assume compactness to begin with! What am I missing here?","The problem From what I've read in the literature I get the idea that domain compactness is quite crucial in the theorem, and yet looking at the proof it seems to me as an unnecessary assumption. I surmise I'm probably missing an important part of the picture. In order to fix some notation and say what I mean precisely, allow me to repeat the proof down here. I will assume we are all familiar with the notions of equicontinuity and uniform boundedness. The theorem If a family of functions from [a,b] to is uniformly bounded and  uniformly equicontinuous, then every sequence of functions in admits a convergent subsequence. Proof. Let us fix a sequence and an enumeration of the rationals in . Since the numeric sequence is bounded, by the Bolzano-Weierstrass theorem, it admits a convergent subsequence , which defines a corresponding subsequence of functions . By the same token, the numeric sequence admits a convergent subsequence , to which corresponds the subsequence of functions , and so on. Iterating this process by induction, we get an infinite chain of nested subsequences Consider now the `diagonal' subsequence . By construction, this sequence of functions converges at all rational points in . Therefore, given a and an there is a such that for all . Furthermore by the uniform equicontinuity of , for any there is an interval such that for all and all . (#) These intervals form an open cover of from which we can extract a finite subcover . By the density of , each of these intervals contains a point of , and thus there is an such that every interval of the finite subcover contains a rational with . Moreover, for any there is a with containing a with . (#) But then, chosen a lying in the same interval as and sufficiently large, therefore the sequence is uniformly Cauchy and thus converges uniformly. The question The entire part enclosed by the symbol (#) seems completely inessential to me. Why can't we just say that by the density of rationals, contains some and be done with it? If that was the case we would not even need to assume compactness to begin with! What am I missing here?","\mathcal{F} \mathbb{R} \mathcal{F} (f_n)\subseteq\mathcal{F} (q_n) [a,b] \big(f_n(q_0)\big)_{n\in\mathbb{N}} \big(f_{n_k}(q_0)\big)_{k\in\mathbb{N}} (f_{n_k})_{k\in\mathbb{N}} \big(f_{n_k}(q_1)\big)_{k\in\mathbb{N}} \big(f_{n_k}^{(1)}(q_1)\big)_{k\in\mathbb{N}} (f_{n_k}^{(1)})_{k\in\mathbb{N}} \begin{equation}
(f_{n_k})_{k\in\mathbb{N}}\supseteq (f_{n_k}^{(1)})_{k\in\mathbb{N}}\supseteq (f_{n_k}^{(2)})_{k\in\mathbb{N}}\supseteq (f_{n_k}^{(3)})_{k\in\mathbb{N}}\supseteq \,...
\end{equation} (f_{n_k}^{(k)})_{k\in\mathbb{N}} [a,b] q_m \epsilon>0 \nu\in\mathbb{N} \begin{equation}
|f_{n_k}^{(k)}(q_m)-f_{n_h}^{(h)}(q_m)| \le \frac{\epsilon}{3},
\end{equation} k,h\ge\nu \mathcal{F} x\in [a,b] J_x \begin{equation}
|f_{n_k}^{(k)}(y)-f_{n_k}^{(k)}(z)| \le \frac{\epsilon}{3},
\end{equation} y,z\in J_x k\in\mathbb{N} [a,b] \{J_{x_1},\,...,J_{x_p}\} \mathbb{Q} (q_m) M\in\mathbb{N} q_m 0\le m\le M x\in[a,b] J_{x_j} 1\le j\le p q_m 1\le m\le M q_m x k,h \begin{align}
&|f_{n_k}^{(k)}(x)-f_{n_h}^{(h)}(x)| \le\nonumber\\
&|f_{n_k}^{(k)}(x)-f_{n_k}^{(h)}(q_m)| + |f_{n_k}^{(k)}(q_m)-f_{n_h}^{(h)}(q_m)| + |f_{n_h}^{(h)}(q_m)-f_{n_h}^{(h)}(x)| \le\nonumber\\
&\hspace{3.5cm}\le\frac{\epsilon}{3} + \frac{\epsilon}{3} + \frac{\epsilon}{3} = \epsilon,
\end{align} (f_{n_k}^{(k)})_{k\in\mathbb{N}} J_x q_m","['real-analysis', 'functional-analysis', 'compactness', 'arzela-ascoli']"
24,"$(A_K^*f)(x) = \int_0^1 K^*(x,y) f(y)\, dy$ for all $f\in L^2[0,1]$ - Fubini's theorem?",for all  - Fubini's theorem?,"(A_K^*f)(x) = \int_0^1 K^*(x,y) f(y)\, dy f\in L^2[0,1]","Let $K$ be a square-integrable kernel on $[0,1] \times [0,1]$ , i.e. $$\int_0^1 \int_0^1 |K(x,y)|^2\, dx\, dy < \infty$$ and let $A_K$ be the integral operator induced by it on $L^2[0,1]$ , i.e. $$(A_K f)(x) = \int_0^1 K(x,y) f(y)\, dy$$ for all $f\in L^2[0,1]$ . Define $K^*(x,y) = \overline{K(y,x)}$ . Show that the adjoint operator $A_K^*$ is the integral operator induced by the kernel $K^*$ . Hint: Fubini's theorem. My thoughts: In mathy language, we want to prove that $$(A_K^*f)(x) = \int_0^1 K^*(x,y) f(y)\, dy = \int_0^1 \overline{K(y,x)} f(y)\, dy$$ By definition of the adjoint, we have $\langle A_K f,g\rangle = \langle f, A_K^*g\rangle$ for all $f,g\in L^2[0,1]$ . The usual inner product on $L^2[0,1]$ is defined by $\langle f,g\rangle = \int_0^1 f(x) \overline {g(x)}\, dx$ for all $f,g\in L^2[0,1]$ . Thus, we have $$\langle A_K^* g, f \rangle = \int _0^1 g(x) \overline{\int_0^1 K(x,y) f(y)\, dy}\, dx = \int_0^1 \int_0^1 g(x) \overline{K(x,y)} \overline{f(y)}\, dy \, dx$$ Swapping $x$ and $y$ in the last (definite) integral, i.e. via a change of variables, we have $$\int_0^1 \int_0^1 g(x) \overline{K(x,y)} \overline{f(y)}\, dy \, dx = \int_0^1 \int_0^1 g(y) K^*(x,y) \overline{f(x)}\, dx \, dy$$ Also, $$\langle A_K^* g, f \rangle = \int_0^1 (A_K^*g)(x) \overline{f(x)}\, dx$$ Certainly, the constant function equal to $1$ on $[0,1]$ is in $L^2[0,1]$ , so putting $f = 1$ we get $$\int_0^1 (A_K^*g)(x) \, dx = \int_0^1 \int_0^1 g(y) K^*(x,y)\, dx \, dy$$ for all $g\in L^2[0,1]$ . Thanks!","Let be a square-integrable kernel on , i.e. and let be the integral operator induced by it on , i.e. for all . Define . Show that the adjoint operator is the integral operator induced by the kernel . Hint: Fubini's theorem. My thoughts: In mathy language, we want to prove that By definition of the adjoint, we have for all . The usual inner product on is defined by for all . Thus, we have Swapping and in the last (definite) integral, i.e. via a change of variables, we have Also, Certainly, the constant function equal to on is in , so putting we get for all . Thanks!","K [0,1] \times [0,1] \int_0^1 \int_0^1 |K(x,y)|^2\, dx\, dy < \infty A_K L^2[0,1] (A_K f)(x) = \int_0^1 K(x,y) f(y)\, dy f\in L^2[0,1] K^*(x,y) = \overline{K(y,x)} A_K^* K^* (A_K^*f)(x) = \int_0^1 K^*(x,y) f(y)\, dy = \int_0^1 \overline{K(y,x)} f(y)\, dy \langle A_K f,g\rangle = \langle f, A_K^*g\rangle f,g\in L^2[0,1] L^2[0,1] \langle f,g\rangle = \int_0^1 f(x) \overline {g(x)}\, dx f,g\in L^2[0,1] \langle A_K^* g, f \rangle = \int _0^1 g(x) \overline{\int_0^1 K(x,y) f(y)\, dy}\, dx = \int_0^1 \int_0^1 g(x) \overline{K(x,y)} \overline{f(y)}\, dy \, dx x y \int_0^1 \int_0^1 g(x) \overline{K(x,y)} \overline{f(y)}\, dy \, dx = \int_0^1 \int_0^1 g(y) K^*(x,y) \overline{f(x)}\, dx \, dy \langle A_K^* g, f \rangle = \int_0^1 (A_K^*g)(x) \overline{f(x)}\, dx 1 [0,1] L^2[0,1] f = 1 \int_0^1 (A_K^*g)(x) \, dx = \int_0^1 \int_0^1 g(y) K^*(x,y)\, dx \, dy g\in L^2[0,1]","['functional-analysis', 'analysis', 'operator-theory', 'hilbert-spaces', 'fubini-tonelli-theorems']"
25,Is there a reason that test functions are chosen to have a compact support?,Is there a reason that test functions are chosen to have a compact support?,,"If $f$ is a distribution, we choose test functions from $C^\infty_c(\mathbb R^n)$ . My question is, Is there a reason that we want test function to be smooth? Why do we want the function to have a compact support? Can't we have replace the condition to be $f \in L^1(\mathbb R^n)$ (or $L^p$ )? Thank you in advance.","If is a distribution, we choose test functions from . My question is, Is there a reason that we want test function to be smooth? Why do we want the function to have a compact support? Can't we have replace the condition to be (or )? Thank you in advance.",f C^\infty_c(\mathbb R^n) f \in L^1(\mathbb R^n) L^p,"['real-analysis', 'functional-analysis', 'distribution-theory']"
26,"Showing that $C^1([0,1])$ space with the norm $||f||^2=\int_{0}^{1}|f|^2+\int_0^{1}|f'|^2$ is not a Banach Space",Showing that  space with the norm  is not a Banach Space,"C^1([0,1]) ||f||^2=\int_{0}^{1}|f|^2+\int_0^{1}|f'|^2","I am given the $C^1([0,1])$ space containing $f$ -s such that $f,f'\in C[0,1]$ , with the norm $||f||^2=\int_{0}^{1}|f|^2+\int_0^{1}|f'|^2$ and asked to show that it is not a Banach Space. What I am not so sure about is how; do I need to find $f_n$ such that $\int_0^{1}|f_n'|^2$ is infinite, or should I rather find $f'_n$ such that $\lim_{n\to \infty}f'n\notin C[0,1]$ , or is any of the two will be sufficient? I am having trouble to find ANY Cauchy sequence of functions, especially the conditioned ones. Should I start looking for derivatives sequence and integrate them?","I am given the space containing -s such that , with the norm and asked to show that it is not a Banach Space. What I am not so sure about is how; do I need to find such that is infinite, or should I rather find such that , or is any of the two will be sufficient? I am having trouble to find ANY Cauchy sequence of functions, especially the conditioned ones. Should I start looking for derivatives sequence and integrate them?","C^1([0,1]) f f,f'\in C[0,1] ||f||^2=\int_{0}^{1}|f|^2+\int_0^{1}|f'|^2 f_n \int_0^{1}|f_n'|^2 f'_n \lim_{n\to \infty}f'n\notin C[0,1]","['functional-analysis', 'banach-spaces', 'complete-spaces']"
27,Boundedness of a subset using linear functionals,Boundedness of a subset using linear functionals,,"Let $S$ be a subset of the $\mathbb K-$ normed vector space $V$ such that $$\sup_{x\in S}|T(x)|<\infty$$ for any $T\in\mathcal L(V,\mathbb K)$ . Prove that $S$ is a limited subset of $V$ . Hello everyone, I found this exercise but I can't have ideas to start with, I have assumed that $S$ is not bounded, therefore for all $M>0$ exists $x_0\in S$ such that $\|x_0\|_V>M$ . Or I can say that there is a sequence that converges to infinity. But since $\sup_{x\in S}|T(x)|<\infty$ , then there is a sub-succession $(x_{n_j})$ such that $T(x_{n_j})$ is convergent. Then I don't know what to do. Any ideas please. I found this but I don't understand it well.","Let be a subset of the normed vector space such that for any . Prove that is a limited subset of . Hello everyone, I found this exercise but I can't have ideas to start with, I have assumed that is not bounded, therefore for all exists such that . Or I can say that there is a sequence that converges to infinity. But since , then there is a sub-succession such that is convergent. Then I don't know what to do. Any ideas please. I found this but I don't understand it well.","S \mathbb K- V \sup_{x\in S}|T(x)|<\infty T\in\mathcal L(V,\mathbb K) S V S M>0 x_0\in S \|x_0\|_V>M \sup_{x\in S}|T(x)|<\infty (x_{n_j}) T(x_{n_j})","['functional-analysis', 'normed-spaces', 'dual-spaces']"
28,Least squares in polynomial space?,Least squares in polynomial space?,,"Problem. Use linear algebra to find $f(x) \in \mathcal{P}_2(\mathbb{R}) = \{ f \in \mathbb{R}[x] \mid \text{deg}(f) \leq 2\}$ such that $f'(0) = 0$ and $f(x)$ minimizes $$\int_0^1 (2x - f(x))^2 dx.$$ This problem came up on my qualifying exam, and I would like to understand it. It looks suspiciously like a least squares problem, wherein we attempt to minimize $\| b - Ax \|$ for some overdetermined system of equations $A$ . Driving my suspicion is the fact that I recognize that the integral is the $L^2$ norm. So $2x$ could be serving the role of $b$ , and $f(x)$ would be serving the role of $Ax$ . One more fact I think I have gathered is that the condition $f'(0) = 0$ means that $f(x)$ will be of the form $f(x) = ax^2 + 0x + b$ . If this is a least squares problem, then I think the solution is found by simply solving $A^* b = 0$ , though I will need to do more research to be sure. So if all of the above is correct, then I am struggling to understand what $A$ and $x$ are in this problem. In particular, how does $f(x) = ax^2 + b$ represent an overdetermined system of equations $A$ multiplied by some vector $x$ ?","Problem. Use linear algebra to find such that and minimizes This problem came up on my qualifying exam, and I would like to understand it. It looks suspiciously like a least squares problem, wherein we attempt to minimize for some overdetermined system of equations . Driving my suspicion is the fact that I recognize that the integral is the norm. So could be serving the role of , and would be serving the role of . One more fact I think I have gathered is that the condition means that will be of the form . If this is a least squares problem, then I think the solution is found by simply solving , though I will need to do more research to be sure. So if all of the above is correct, then I am struggling to understand what and are in this problem. In particular, how does represent an overdetermined system of equations multiplied by some vector ?",f(x) \in \mathcal{P}_2(\mathbb{R}) = \{ f \in \mathbb{R}[x] \mid \text{deg}(f) \leq 2\} f'(0) = 0 f(x) \int_0^1 (2x - f(x))^2 dx. \| b - Ax \| A L^2 2x b f(x) Ax f'(0) = 0 f(x) f(x) = ax^2 + 0x + b A^* b = 0 A x f(x) = ax^2 + b A x,"['linear-algebra', 'functional-analysis', 'least-squares']"
29,Every $\ell^p$ space with $p\ne 2$ has a subspace without a Schauder basis,Every  space with  has a subspace without a Schauder basis,\ell^p p\ne 2,"Rajendra Bhatia's Notes on Functional Analysis (Texts and Readings in Mathematics), Pg. $14$ states (without proof) that: Every $\ell^p$ space ( $1\le p \le \infty)$ with $p\ne 2$ has a subspace without a Schauder basis. where $\ell^p$ denotes the sequence space with the $p$ -norm. What is the proof of this fact? I have been trying for a while now, and it seems more difficult than I had imagined. Also, I would be interested to see why every subspace of $\ell^2$ has a Schauder basis. P.S. If the proof is doable with some hints, then just hints would be great too! Update: The proof of the main assertion is found in Lindenstrauss and Tzafriri's Classical Banach Spaces I and II , as mentioned by David Mitra in the comments.","Rajendra Bhatia's Notes on Functional Analysis (Texts and Readings in Mathematics), Pg. states (without proof) that: Every space ( with has a subspace without a Schauder basis. where denotes the sequence space with the -norm. What is the proof of this fact? I have been trying for a while now, and it seems more difficult than I had imagined. Also, I would be interested to see why every subspace of has a Schauder basis. P.S. If the proof is doable with some hints, then just hints would be great too! Update: The proof of the main assertion is found in Lindenstrauss and Tzafriri's Classical Banach Spaces I and II , as mentioned by David Mitra in the comments.",14 \ell^p 1\le p \le \infty) p\ne 2 \ell^p p \ell^2,"['real-analysis', 'functional-analysis', 'lp-spaces', 'schauder-basis']"
30,Suggestions for textbooks for measures and integration theory on Banach space,Suggestions for textbooks for measures and integration theory on Banach space,,"Traditional book deals with real valued function and now I want to study the case in which the range of a function is in Banach space, can anyone recommend some books about it, thank you in advance","Traditional book deals with real valued function and now I want to study the case in which the range of a function is in Banach space, can anyone recommend some books about it, thank you in advance",,"['real-analysis', 'functional-analysis', 'banach-spaces', 'book-recommendation']"
31,$A$ is compact if and only if $e^{itA}-I$ is compact for all $t$,is compact if and only if  is compact for all,A e^{itA}-I t,"Suppose $\mathcal{H}$ is a Hilbert space, $A\in \mathcal{L}(\mathcal{H})$ is self adjoint, and define $U(t)=e^{itA}$ . Show that $U(t)-I$ is compact for all $t\in \mathbb{R}$ if and only if $A$ is compact. One direction is relatively straightforward: if $A$ is compact, write $$ U(t)-I=A\big(itI+\frac{(it)^2}{2!}A+\frac{(it)^3}{3!}A^2+\dots\big), $$ from which it is apparent that $U(t)-I$ is itself compact. However, I am having trouble with the other direction. One notes that as $A$ is self adjoint, $U(t)$ is unitary, but I am not sure where to head from here. I have also attempted to apply the spectral theorem, but to no avail. A hint would be appreciated!","Suppose is a Hilbert space, is self adjoint, and define . Show that is compact for all if and only if is compact. One direction is relatively straightforward: if is compact, write from which it is apparent that is itself compact. However, I am having trouble with the other direction. One notes that as is self adjoint, is unitary, but I am not sure where to head from here. I have also attempted to apply the spectral theorem, but to no avail. A hint would be appreciated!","\mathcal{H} A\in \mathcal{L}(\mathcal{H}) U(t)=e^{itA} U(t)-I t\in \mathbb{R} A A 
U(t)-I=A\big(itI+\frac{(it)^2}{2!}A+\frac{(it)^3}{3!}A^2+\dots\big),
 U(t)-I A U(t)","['functional-analysis', 'compact-operators']"
32,Simple proof of Krein-Smulian,Simple proof of Krein-Smulian,,"I have a question concerning a simple and short proof of Krein-Shmulian, the proof can be found here https://people.math.ethz.ch/~jteichma/slides_ftap.pdf on page 35/36. Here the proof: Let $X$ be a Banach space. The Krein-Smulian theorem tells that a convex subset $C\subset X^∗$ is weak-∗-closed if and only if its intersections with balls in $X^∗$ are weak-∗-closed. We can conclude this theorem from a separation theorem (see Conways’ book on functional analysis): assume that for a convex set $C \subset X^*$ all its intersections with balls in $X^*$ are weak-∗-closed, and assume that the intersection of $C$ with the unit ball (centered at $0$ ) is empty, then there is $x \in X$ such that $(x,x∗)\geq 1$ for all $x^* \in C$ . From this we can conclude immediately:  let $x^* \in X^*$ be in the weak-∗=closure of $C$ but not in $C$ , then – due to the fact that $C$ is norm closed (prove it!)  – there is a ball of radius $r$ around $x^∗$ which does not intersect $C$ .  Whence $r^{−1}(C−x^*)$ does not intersect the unit ball centered at $0$ . By the previous separation statement this however means that $x^*$ cannot lie in the weak-∗-closure of $C$ . While the statements on the first page are clear to me, I have some problems with page 36: First, it is a well known fact that if $S \subset X$ and convex ( $X$ being a vector space carrying a norm) is a weak closed convex set if and only if $S$ is also strongly closed. But how one get's that that if $C$ is a convex set where its intersection with balls in $X^*$ are weak*-closed, then $C$ is norm closed ? And further, having this fact, why we can find a ball of radius $r$ around $x^*$ (where $x^*$ is in the weak*-closure but not in $C$ ) which does not intersect $C$ ? And why this finally implies the statement ?","I have a question concerning a simple and short proof of Krein-Shmulian, the proof can be found here https://people.math.ethz.ch/~jteichma/slides_ftap.pdf on page 35/36. Here the proof: Let be a Banach space. The Krein-Smulian theorem tells that a convex subset is weak-∗-closed if and only if its intersections with balls in are weak-∗-closed. We can conclude this theorem from a separation theorem (see Conways’ book on functional analysis): assume that for a convex set all its intersections with balls in are weak-∗-closed, and assume that the intersection of with the unit ball (centered at ) is empty, then there is such that for all . From this we can conclude immediately:  let be in the weak-∗=closure of but not in , then – due to the fact that is norm closed (prove it!)  – there is a ball of radius around which does not intersect .  Whence does not intersect the unit ball centered at . By the previous separation statement this however means that cannot lie in the weak-∗-closure of . While the statements on the first page are clear to me, I have some problems with page 36: First, it is a well known fact that if and convex ( being a vector space carrying a norm) is a weak closed convex set if and only if is also strongly closed. But how one get's that that if is a convex set where its intersection with balls in are weak*-closed, then is norm closed ? And further, having this fact, why we can find a ball of radius around (where is in the weak*-closure but not in ) which does not intersect ? And why this finally implies the statement ?","X C\subset X^∗ X^∗ C \subset X^* X^* C 0 x \in X (x,x∗)\geq 1 x^* \in C x^* \in X^* C C C r x^∗ C r^{−1}(C−x^*) 0 x^* C S \subset X X S C X^* C r x^* x^* C C",['functional-analysis']
33,Sobolev space on composite domain,Sobolev space on composite domain,,"Let $\Omega_1$ and $\Omega_2$ be two sufficiently smooth domains in $\mathbb R^2$ . Consider the composite domain $\Omega =Ω_1 \cup Ω_2$ . Also, consider the sobolev space $H_0^1 (Ω)$ .  Let $ Y_1 = H_0^1(Ω_1) $ and $ Y_2 = H_0^1(Ω_2)$ . View $Y_1$ and $Y_2$ as closed subspaces of $H_0^1(Ω)$ (by extending functions on $Ω$ to be  zero.) I am looking for a reference to the fact that $Y_1 + Y_2$ is dense in $H_0^1 (Ω)$ . Thanks for any help.","Let and be two sufficiently smooth domains in . Consider the composite domain . Also, consider the sobolev space .  Let and . View and as closed subspaces of (by extending functions on to be  zero.) I am looking for a reference to the fact that is dense in . Thanks for any help.",\Omega_1 \Omega_2 \mathbb R^2 \Omega =Ω_1 \cup Ω_2 H_0^1 (Ω)  Y_1 = H_0^1(Ω_1)   Y_2 = H_0^1(Ω_2) Y_1 Y_2 H_0^1(Ω) Ω Y_1 + Y_2 H_0^1 (Ω),"['functional-analysis', 'reference-request', 'sobolev-spaces']"
34,Uniform convergence of integral function,Uniform convergence of integral function,,Let $f \in \mathcal{C}^{\infty}_{K}(\mathbb{R})$ be a smooth function with compact support and $t \geq0$ . Then $ g_{t}(x) =\frac{1}{t}\int_{\mathbb{R}}(f(x+\sqrt{t}z)-f(x)-\frac{t}{2}f^{''}(x))e^{-\frac{1}{2}z^2}dz \rightarrow 0 $ uniformly for $t \rightarrow 0$ holds. I am really struggling to show this and would be grateful for hints or a solution.,Let be a smooth function with compact support and . Then uniformly for holds. I am really struggling to show this and would be grateful for hints or a solution.,"f \in \mathcal{C}^{\infty}_{K}(\mathbb{R}) t \geq0 
g_{t}(x) =\frac{1}{t}\int_{\mathbb{R}}(f(x+\sqrt{t}z)-f(x)-\frac{t}{2}f^{''}(x))e^{-\frac{1}{2}z^2}dz \rightarrow 0
 t \rightarrow 0","['real-analysis', 'functional-analysis', 'limits', 'analysis', 'limits-without-lhopital']"
35,"If every bounded sequence has a weakly convergent subsequence, then the inner product space is Hilbert","If every bounded sequence has a weakly convergent subsequence, then the inner product space is Hilbert",,"We can prove that in Hilbert space, bounded space has a weakly convergent subsequence, as we can see here or there . Does the converse hold? That is, in an inner product space $H$ , if every bounded sequence has a weakly convergent subsequence, is $H$ complete? My work: I thought it is a good start to look at a bounded sequence in an incomplete inner product space. As we see here , the space of the sequence which has finitely non-zero element is incomplete. Then I tried to make a bounded (but not weakly convergent) sequence in this space, but I am failing to do so. How can I proceed from here?","We can prove that in Hilbert space, bounded space has a weakly convergent subsequence, as we can see here or there . Does the converse hold? That is, in an inner product space , if every bounded sequence has a weakly convergent subsequence, is complete? My work: I thought it is a good start to look at a bounded sequence in an incomplete inner product space. As we see here , the space of the sequence which has finitely non-zero element is incomplete. Then I tried to make a bounded (but not weakly convergent) sequence in this space, but I am failing to do so. How can I proceed from here?",H H,"['functional-analysis', 'hilbert-spaces', 'inner-products', 'weak-convergence']"
36,Relation between $Y$ and $Y^{\perp}$ in a Banach space,Relation between  and  in a Banach space,Y Y^{\perp},"Given any normed linear space $X$ let $Y$ be a subspace of $X$ . Define $$Y^\perp:=\{f\in X^* :~ f(y)=0~\forall~y\in Y\}.$$ I have stuck in a problem which asks to show that if $Y$ is closed, then $$Y=\bigcap\limits_{g\in Y^\perp} \ker g.$$ As a hint: it says apply geometric Hahn-Banach Theorem or Mazur's separation Theorem. I do not know, how to proceed. EDIT I did the forward $\subseteq$ part in the comment. I am trying the reverse part following the comment of UmbertoP. Let $W=\bigcap\limits_{g\in Y^\perp} \ker g$ and let $x\in W\setminus Y$ . Then due to the closedness of $Y$ and compactness of $\{y\}$ , we can find a convex neighborhood about the zero vector say $V$ such that $$(Y+V)\cap (x+V)=\emptyset.$$ In particular, $Y$ is disjoint from a convex open set $(x+V)$ . By Mazur's Theorem, there exists a closed hyperplane $H$ containing $Y$ and disjoint from $(x+V)$ . Consider a linear functional $h$ with $\ker h=H$ . Then this $h$ is continuous, annihilates $Y$ . So, $h\in Y^\perp$ but $x\notin \ker h$ , a contradiction. Please help me regarding this.","Given any normed linear space let be a subspace of . Define I have stuck in a problem which asks to show that if is closed, then As a hint: it says apply geometric Hahn-Banach Theorem or Mazur's separation Theorem. I do not know, how to proceed. EDIT I did the forward part in the comment. I am trying the reverse part following the comment of UmbertoP. Let and let . Then due to the closedness of and compactness of , we can find a convex neighborhood about the zero vector say such that In particular, is disjoint from a convex open set . By Mazur's Theorem, there exists a closed hyperplane containing and disjoint from . Consider a linear functional with . Then this is continuous, annihilates . So, but , a contradiction. Please help me regarding this.",X Y X Y^\perp:=\{f\in X^* :~ f(y)=0~\forall~y\in Y\}. Y Y=\bigcap\limits_{g\in Y^\perp} \ker g. \subseteq W=\bigcap\limits_{g\in Y^\perp} \ker g x\in W\setminus Y Y \{y\} V (Y+V)\cap (x+V)=\emptyset. Y (x+V) H Y (x+V) h \ker h=H h Y h\in Y^\perp x\notin \ker h,"['real-analysis', 'functional-analysis']"
37,What is $e^{\frac d{dx}}$?,What is ?,e^{\frac d{dx}},"At the end of this video , 3blue1brown suggests it is possible to take $e^{\frac d{dx}}$ . So, what does $e^{\frac d{dx}}$ equal?","At the end of this video , 3blue1brown suggests it is possible to take . So, what does equal?",e^{\frac d{dx}} e^{\frac d{dx}},"['functional-analysis', 'derivatives', 'exponential-function', 'popular-math']"
38,Non-existence of surjections from $L^p$ to $L^q$,Non-existence of surjections from  to,L^p L^q,"Let $1 \leq p, q \leq \infty$ and suppose there exists a continuous linear surjection $$ T : L^p[0,1] \longrightarrow L^q[0,1]. $$ Does it necessarily follow that $q \leq p?$ In the case of sequence spaces $\ell_p$ the result holds if we swap $p,q$ by Pitt's theorem, which asserts that for $q<p$ any bounded linear operator $T:\ell_p \to \ell_q$ is compact. In the $L^p$ context I suspect the notions of type/cotype may relevant, but as a non-specialist it isn't obvious to me how these can be applied. This question is mainly out of curiosity, and any references would be appreciated.","Let and suppose there exists a continuous linear surjection Does it necessarily follow that In the case of sequence spaces the result holds if we swap by Pitt's theorem, which asserts that for any bounded linear operator is compact. In the context I suspect the notions of type/cotype may relevant, but as a non-specialist it isn't obvious to me how these can be applied. This question is mainly out of curiosity, and any references would be appreciated.","1 \leq p, q \leq \infty  T : L^p[0,1] \longrightarrow L^q[0,1].  q \leq p? \ell_p p,q q<p T:\ell_p \to \ell_q L^p","['functional-analysis', 'banach-spaces', 'lp-spaces']"
39,"Given a normed vector space $X$, can you always define a bounded linear functional $f$ which is bounded above and below by the norm?","Given a normed vector space , can you always define a bounded linear functional  which is bounded above and below by the norm?",X f,"Let $X$ be a (possibly infinite-dimensional) normed vector space over $\mathbb{R}$ , whose norm is denoted $|| \cdot ||$ . Given two non-negative scalars, say $M, N \in \mathbb{R}$ with $M < N$ , can you always find a bounded linear functional $f: X \to \mathbb{R}$ such that $M||x|| \leq | f(x) | \leq N || x||$ for all $x \in X$ ? Obviously, if $f$ is bounded then $|f(x)| \leq ||f||_{op} || x|| \leq K || x||$ for some non-negative $K \in \mathbb{R}$ . But this fact is kind of going in the ""wrong direction"" so I'm not too sure if this is helpful. It does seem like there are several corollaries to the Hahn-Banach theorem that might also be related, but again, I'm not sure if there are additional assumptions that I would need to make to force this question to have a positive answer.","Let be a (possibly infinite-dimensional) normed vector space over , whose norm is denoted . Given two non-negative scalars, say with , can you always find a bounded linear functional such that for all ? Obviously, if is bounded then for some non-negative . But this fact is kind of going in the ""wrong direction"" so I'm not too sure if this is helpful. It does seem like there are several corollaries to the Hahn-Banach theorem that might also be related, but again, I'm not sure if there are additional assumptions that I would need to make to force this question to have a positive answer.","X \mathbb{R} || \cdot || M, N \in \mathbb{R} M < N f: X \to \mathbb{R} M||x|| \leq | f(x) | \leq N || x|| x \in X f |f(x)| \leq ||f||_{op} || x|| \leq K || x|| K \in \mathbb{R}","['functional-analysis', 'normed-spaces']"
40,Do antilinear maps have adjoints?,Do antilinear maps have adjoints?,,"Let $T: H \to H$ be a continuous antilinear map on a Hilbert space $H$ , that is $T(\alpha \xi + \eta)= \overline{\alpha} T \xi + T \eta$ for $\xi, \eta \in H$ and $\alpha \in \mathbb{C}$ . Does there exist an antilinear map $T^*: H \to H$ such that $$\langle T^* \xi, \eta\rangle = \langle \xi, T\eta\rangle$$ for all $\xi, \eta \in H$ (or a variation on this). I could try to mimique the ""usual"" proof for bounded linear maps, but maybe there is a smart way to avoid this kind of work by reducing to this case?","Let be a continuous antilinear map on a Hilbert space , that is for and . Does there exist an antilinear map such that for all (or a variation on this). I could try to mimique the ""usual"" proof for bounded linear maps, but maybe there is a smart way to avoid this kind of work by reducing to this case?","T: H \to H H T(\alpha \xi + \eta)= \overline{\alpha} T \xi + T \eta \xi, \eta \in H \alpha \in \mathbb{C} T^*: H \to H \langle T^* \xi, \eta\rangle = \langle \xi, T\eta\rangle \xi, \eta \in H",['functional-analysis']
41,Does a $\mathrm{C}^*$-algebra generated by projections contain support projections,Does a -algebra generated by projections contain support projections,\mathrm{C}^*,"I think we have for a (normal?) state $\varphi$ on a von Neumann algebra $\mathcal{M}$ a projection $p_\varphi$ with some nice properties called its support. It arises as follows: Define the following null space: $$N_\varphi=\left\{g\in \mathcal{M}\,|\,\varphi(|g|^2)=0\right\}.$$ This set is a $\sigma$ -weakly closed left ideal. Therefore there exists a projection $q_\varphi$ such that $N_\varphi=\mathcal{M}q_\varphi$ . Some properties include the fact that $g\in N_\varphi$ if and only if $gq_\varphi=g$ . Also, for all $f\in \mathcal{M}$ we have $$\varphi(q_\varphi)=\varphi(fq_\varphi)=\nu(q_\varphi f)=0.$$ Also if we define the projection $p_\varphi:=1_{\mathcal{M}}-q_\varphi$ . We have $$\varphi(f)=\varphi(fp_\varphi)=\varphi(p_\varphi f)=\varphi(p_\varphi fp_\varphi),$$ and $\varphi(p_\varphi)=1$ . I understand that a $\mathrm{C}^*$ -algebra generated by projections is not necessarily a von Neumann algebra... but Question: Does a $\mathrm{C}^*$ -algebra generated by projections have support projections?","I think we have for a (normal?) state on a von Neumann algebra a projection with some nice properties called its support. It arises as follows: Define the following null space: This set is a -weakly closed left ideal. Therefore there exists a projection such that . Some properties include the fact that if and only if . Also, for all we have Also if we define the projection . We have and . I understand that a -algebra generated by projections is not necessarily a von Neumann algebra... but Question: Does a -algebra generated by projections have support projections?","\varphi \mathcal{M} p_\varphi N_\varphi=\left\{g\in \mathcal{M}\,|\,\varphi(|g|^2)=0\right\}. \sigma q_\varphi N_\varphi=\mathcal{M}q_\varphi g\in N_\varphi gq_\varphi=g f\in \mathcal{M} \varphi(q_\varphi)=\varphi(fq_\varphi)=\nu(q_\varphi f)=0. p_\varphi:=1_{\mathcal{M}}-q_\varphi \varphi(f)=\varphi(fp_\varphi)=\varphi(p_\varphi f)=\varphi(p_\varphi fp_\varphi), \varphi(p_\varphi)=1 \mathrm{C}^* \mathrm{C}^*","['functional-analysis', 'operator-algebras', 'c-star-algebras', 'dual-spaces', 'von-neumann-algebras']"
42,"A doubt on the Sobolev space $W_0^{1,p}(\Omega)$",A doubt on the Sobolev space,"W_0^{1,p}(\Omega)","Let $\Omega \subset \Bbb R^d$ be open and $1\leq p<\infty$ . Recall that $W_0^{1,p}(\Omega)$ is the closure of $C_c^\infty(\Omega)$ (smooth function with compact support in $\Omega$ ) in $W^{1,p}(\Omega)$ where $$W^{1,p}(\Omega)= \{u\in L^p(\Omega): \nabla u \in L^p(\Omega) \}$$ is equiped with the norm $$\|u\|^p_{W^{1,p}(\Omega)}= \|u\|^p_{L^p(\Omega)} + \|\nabla u\|^p_{L^p(\Omega)}$$ Define $$W_\Omega= \{u\in W^{1,p}(\Bbb R^d): u =0 ~~a.e.~~ on~~ \Bbb R^d\setminus \Omega \}$$ Clearly $W_\Omega$ is closed subspace of $W^{1,p}(\Bbb R^d)$ and we have $W_0^{1,p}(\Omega)\subset W_\Omega$ Question: Do we have $W_0^{1,p}(\Omega)= W_\Omega$ ? Or is there  a counter example?",Let be open and . Recall that is the closure of (smooth function with compact support in ) in where is equiped with the norm Define Clearly is closed subspace of and we have Question: Do we have ? Or is there  a counter example?,"\Omega \subset \Bbb R^d 1\leq p<\infty W_0^{1,p}(\Omega) C_c^\infty(\Omega) \Omega W^{1,p}(\Omega) W^{1,p}(\Omega)= \{u\in L^p(\Omega): \nabla u \in L^p(\Omega) \} \|u\|^p_{W^{1,p}(\Omega)}= \|u\|^p_{L^p(\Omega)} + \|\nabla u\|^p_{L^p(\Omega)} W_\Omega= \{u\in W^{1,p}(\Bbb R^d): u =0 ~~a.e.~~ on~~ \Bbb R^d\setminus \Omega \} W_\Omega W^{1,p}(\Bbb R^d) W_0^{1,p}(\Omega)\subset W_\Omega W_0^{1,p}(\Omega)= W_\Omega","['functional-analysis', 'analysis', 'partial-differential-equations', 'sobolev-spaces', 'trace-map']"
43,reachability of the norm by the operator,reachability of the norm by the operator,,"$A: \ell^1 \to \mathbb{R}$ , where $$Ax= \sum\limits_{k=0}^\infty((2+\cos(\pi(1/3)^{k+1})\xi_{k+1}).$$ \begin{aligned} ||Ax||_{\mathbb{R}} &= |Ax| = |(2+\cos(\pi(1/3))\xi_1) + (2+\cos(\pi(1/9))\xi_2)+(2+\cos(\pi(1/27))\xi_3) + \dots| \\ &\leq |(2+\cos(\pi(1/3))\xi_1)|+|(2+\cos(\pi(1/9))\xi_2)|+|(2+\cos(\pi(1/27))\xi_3)|+\dots \\ &\leq 3|\xi_1|+3|\xi_2|+3|\xi_3|+\dots \\ &=3||x||_{\ell^1} \end{aligned} I have already shown the limit, but I can't prove that the norm is not reached.",", where I have already shown the limit, but I can't prove that the norm is not reached.","A: \ell^1 \to \mathbb{R} Ax= \sum\limits_{k=0}^\infty((2+\cos(\pi(1/3)^{k+1})\xi_{k+1}). \begin{aligned}
||Ax||_{\mathbb{R}} &= |Ax| = |(2+\cos(\pi(1/3))\xi_1) + (2+\cos(\pi(1/9))\xi_2)+(2+\cos(\pi(1/27))\xi_3) + \dots| \\
&\leq |(2+\cos(\pi(1/3))\xi_1)|+|(2+\cos(\pi(1/9))\xi_2)|+|(2+\cos(\pi(1/27))\xi_3)|+\dots \\
&\leq 3|\xi_1|+3|\xi_2|+3|\xi_3|+\dots \\
&=3||x||_{\ell^1}
\end{aligned}","['functional-analysis', 'normed-spaces']"
44,A problem connecting Hilbert spaces and normed linear spaces,A problem connecting Hilbert spaces and normed linear spaces,,"The problem is the following: Let $X$ be a normed linear space and $Y$ be a Hilbert space. Let $ A : X \rightarrow Y$ be a linear operator. For $y \in Y \, $ , let $ \, S_y = \{ x \in X : \| Ax − y \| \le \|Au − y \|, \, \forall \, u \in X \} $ Show that $S_y$ is nonempty if and only if $ \, y \in R(A) + R(A)^{\bot}$ . In addition, if $X$ is Hilbert and $N(A)$ is a closed subspace, show that for every $y \in R(A) + R(A)^{\bot}$ , there is a unique $x_y \in S_y$ such that $ \| x_y \| = inf \{ \| x \|: x \in S_y \}$ . My attempt: I guess that if I prove that $S_y$ is a convex subset of $Y$ , and as $Y$ is Hilbert, I can say that $ \exists ! \, x_y \in S_y $ , as required in the second part. For the first part. I'm not quite sure how to go about it.","The problem is the following: Let be a normed linear space and be a Hilbert space. Let be a linear operator. For , let Show that is nonempty if and only if . In addition, if is Hilbert and is a closed subspace, show that for every , there is a unique such that . My attempt: I guess that if I prove that is a convex subset of , and as is Hilbert, I can say that , as required in the second part. For the first part. I'm not quite sure how to go about it.","X Y  A : X \rightarrow Y y \in Y \,   \, S_y = \{ x \in X : \| Ax − y \| \le \|Au − y \|, \, \forall \, u \in X \}  S_y  \, y \in R(A) + R(A)^{\bot} X N(A) y \in R(A) + R(A)^{\bot} x_y \in S_y  \| x_y \| = inf \{ \| x \|: x \in S_y \} S_y Y Y  \exists ! \, x_y \in S_y ","['functional-analysis', 'analysis', 'hilbert-spaces']"
45,Functional derivative of the square of a functional,Functional derivative of the square of a functional,,"How should I compute the functional derivative of the following functional: $$ F(p(x)) = \left[\int\cos(x)p(x)dx - \int\cos(y)q(y)dy\right]^2 $$ I know that the functional derivative $\frac{\delta F}{\delta p(x)}$ is defined as $$ \left[\frac{d}{d\epsilon}F(p +\epsilon\phi)\right]_{\epsilon=0} = \int \frac{\delta F}{\delta p(x)}\phi(x)dx $$ but I am not sure how the chain rule is defined here in the case of a function of a functional, i.e., what's the functional derivative of $F = g(H(p(x)))$ where $g$ is a differentiable function and $H$ is a functional.","How should I compute the functional derivative of the following functional: I know that the functional derivative is defined as but I am not sure how the chain rule is defined here in the case of a function of a functional, i.e., what's the functional derivative of where is a differentiable function and is a functional.","
F(p(x)) = \left[\int\cos(x)p(x)dx - \int\cos(y)q(y)dy\right]^2
 \frac{\delta F}{\delta p(x)} 
\left[\frac{d}{d\epsilon}F(p +\epsilon\phi)\right]_{\epsilon=0} = \int \frac{\delta F}{\delta p(x)}\phi(x)dx
 F = g(H(p(x))) g H","['functional-analysis', 'calculus-of-variations', 'functional-calculus']"
46,Eigenvalues and eigenvectors of integral operator,Eigenvalues and eigenvectors of integral operator,,"I am trying  to find the eigenvalues and eigenvectors for the following integral operator in $L^{2}[0,1]$ : $T:H \rightarrow H$ is defined as follows: $$ T[f(x)]= \int_{1-x}^{1} f(t) dt $$ . Here is my procedure until now: Let $g(x)$ be an eigenvector associated with the eigenvalue $\lambda$ , then $$T[g(x)]  = \lambda g(x) $$ . Solving this problem is equivalent to solving the following integral equation $$\int_{1-x}^{1} g(t) dt - \lambda g(x) = 0 $$ Differentiating twice the previous equation, we get $$ g(1-x)=\lambda \frac{dg(x) }{dx}  $$ But i couldn't find any way to solve the last differential equation. Is the previous procedure correct? And is there any way to solve the last equation?","I am trying  to find the eigenvalues and eigenvectors for the following integral operator in : is defined as follows: . Here is my procedure until now: Let be an eigenvector associated with the eigenvalue , then . Solving this problem is equivalent to solving the following integral equation Differentiating twice the previous equation, we get But i couldn't find any way to solve the last differential equation. Is the previous procedure correct? And is there any way to solve the last equation?","L^{2}[0,1] T:H \rightarrow H  T[f(x)]= \int_{1-x}^{1} f(t) dt  g(x) \lambda T[g(x)]  = \lambda g(x)  \int_{1-x}^{1} g(t) dt - \lambda g(x) = 0   g(1-x)=\lambda \frac{dg(x) }{dx}  ","['functional-analysis', 'eigenvalues-eigenvectors']"
47,Integral of a function times a Fourier transform is zero,Integral of a function times a Fourier transform is zero,,"This comes from Hall's Quantum Theory for Mathematicians , Lemma 9.33. I'm having trouble with one of the arguments in the proof. I believe it boils down to the following: Let $f\colon \mathbb{R}^n \to \mathbb{R}$ such that $\int f(x) \hat g(x) \,\mathrm{d}x = 0$ for all smooth $g$ with compact support, where $\hat g$ denotes the Fourier transform of $g$ . I then want to show that $f = 0$ . In the proof $f$ is a difference of an $L^2$ -function and an $L^2$ -function times a coordinate function. Hall cites the Stone-Weierstrass theorem and the theorem about density of continuous functions with compact support in $L^p$ , but he's not super clear. (He also starts talking about the functions as if they are defined on $\mathbb{R}$ , so I don't know what is going on.) Also, do feel free to change the title to something more descriptive, I wasn't sure how to title my question.","This comes from Hall's Quantum Theory for Mathematicians , Lemma 9.33. I'm having trouble with one of the arguments in the proof. I believe it boils down to the following: Let such that for all smooth with compact support, where denotes the Fourier transform of . I then want to show that . In the proof is a difference of an -function and an -function times a coordinate function. Hall cites the Stone-Weierstrass theorem and the theorem about density of continuous functions with compact support in , but he's not super clear. (He also starts talking about the functions as if they are defined on , so I don't know what is going on.) Also, do feel free to change the title to something more descriptive, I wasn't sure how to title my question.","f\colon \mathbb{R}^n \to \mathbb{R} \int f(x) \hat g(x) \,\mathrm{d}x = 0 g \hat g g f = 0 f L^2 L^2 L^p \mathbb{R}","['functional-analysis', 'fourier-analysis']"
48,"Given $\|x\| \leq 1$ in an infinite dimensional Hilbert space, show there exists a orthonormal sequence that converges weakly to $x$","Given  in an infinite dimensional Hilbert space, show there exists a orthonormal sequence that converges weakly to",\|x\| \leq 1 x,"Let $H$ be an infinite dimensional Hilbert space. Given $x\in H$ with $\| x\| \leq1$ , show there exists an orthonormal sequence $(x_n)$ such that $(x_n)$ converges weakly to $x$ . Below are my ideas and thoughts so far: I thought about using the orthonormal basis to construct such sequence. But since we don't know if $H$ is countable, we can't assume there exists an orthonormal basis. Also note that using Bessel's inequality, if we have an orthonormal sequence we have $\sum_{n} |\langle x,x_n\rangle|^2 \leq \| x\|^2=1$ . So $\lim _{n \rightarrow\infty} \langle x,x_n\rangle^2 =0$ . Hence $\lim _{n \rightarrow\infty} \langle x,x_n\rangle =0$ , which tells us $x_n$ converges weakly to zero. But I'm not sure if this helps us with the question... Any hints or ideas will be appreciated! Thank you","Let be an infinite dimensional Hilbert space. Given with , show there exists an orthonormal sequence such that converges weakly to . Below are my ideas and thoughts so far: I thought about using the orthonormal basis to construct such sequence. But since we don't know if is countable, we can't assume there exists an orthonormal basis. Also note that using Bessel's inequality, if we have an orthonormal sequence we have . So . Hence , which tells us converges weakly to zero. But I'm not sure if this helps us with the question... Any hints or ideas will be appreciated! Thank you","H x\in H \| x\| \leq1 (x_n) (x_n) x H \sum_{n} |\langle x,x_n\rangle|^2 \leq \| x\|^2=1 \lim _{n \rightarrow\infty} \langle x,x_n\rangle^2 =0 \lim _{n \rightarrow\infty} \langle x,x_n\rangle =0 x_n","['functional-analysis', 'hilbert-spaces', 'weak-convergence']"
49,"When does convergence in $L^2$ imply convergence in $C[0,1]$",When does convergence in  imply convergence in,"L^2 C[0,1]","Suppose $f_n: [0,1] \mapsto \mathbb{R} $ are continuous functions. I'm interested in knowing under what conditions does $f_n \stackrel{L^2[0,1]}{\to}f$ imply $\sup_{x \in [0,1]} |f_n(x)-f(x)| \to 0$ . Clearly one example that implies this is if each $f_n$ is uniformly bounded, and has uniformly bounded first and second derivatives (the result follows from Arzela-Ascoli in this case, Does Lp-convergence and uniform boundedness in $C^2$, imply $C^{1}$ convergence? ). Is this basically necessary and sufficient? Or are there weaker conditions under which convergence in mean-square implies convergence uniformly?","Suppose are continuous functions. I'm interested in knowing under what conditions does imply . Clearly one example that implies this is if each is uniformly bounded, and has uniformly bounded first and second derivatives (the result follows from Arzela-Ascoli in this case, Does Lp-convergence and uniform boundedness in $C^2$, imply $C^{1}$ convergence? ). Is this basically necessary and sufficient? Or are there weaker conditions under which convergence in mean-square implies convergence uniformly?","f_n: [0,1] \mapsto \mathbb{R}  f_n \stackrel{L^2[0,1]}{\to}f \sup_{x \in [0,1]} |f_n(x)-f(x)| \to 0 f_n","['real-analysis', 'functional-analysis', 'probability-theory']"
50,"Show that if $\langle Tx,x\rangle \geq 2\left\| x \right\|^2$, then $T$ has dense image","Show that if , then  has dense image","\langle Tx,x\rangle \geq 2\left\| x \right\|^2 T","Exercise: Let $H$ be an inner product space and $T:H \to H$ be a linear operator, such that: $$\langle Tx,x\rangle \geq 2\left\| x \right\|^2, \quad \forall x \in H.$$ Show that $T$ has dense image. Discussion: My initial thought was working with the given condition in order to construct an expression, such as for all $x \in H$ and $\varepsilon >0$ , $y \in H$ it holds: $\left\| Tx - Ty \right\| < \varepsilon$ . Then the image space spanned by the operator would be dense. I tried working around with Cauchy Scwarz, yielding: $$\left\| Tx\right\|\left\|x\right\| \geq \left| \langle Tx, x\rangle \right| \geq 2\left\|x\right\|^2 \implies \left\|Tx\right\| \geq 2\left\|x\right\|, \quad \forall x \in H.$$ Then, since $T$ is linear, let $x:= x-y \in H$ and: $$\left\|Tx - Ty\right\| \geq 2 \left\|x-y\right\|$$ By the Triangle Inequality, we can write: $$\left\|Tx \right\| + \left\|Ty\right\| \geq\left\| Tx - Ty\right\| \geq 2\left\|x-y\right\|$$ I don't know if that helps though. I know that by the condition given, we can easily show that the operator is $""1-1""$ - not sure if that can help though. Any hints or help will be appreciated!","Exercise: Let be an inner product space and be a linear operator, such that: Show that has dense image. Discussion: My initial thought was working with the given condition in order to construct an expression, such as for all and , it holds: . Then the image space spanned by the operator would be dense. I tried working around with Cauchy Scwarz, yielding: Then, since is linear, let and: By the Triangle Inequality, we can write: I don't know if that helps though. I know that by the condition given, we can easily show that the operator is - not sure if that can help though. Any hints or help will be appreciated!","H T:H \to H \langle Tx,x\rangle \geq 2\left\| x \right\|^2, \quad \forall x \in H. T x \in H \varepsilon >0 y \in H \left\| Tx - Ty \right\| < \varepsilon \left\| Tx\right\|\left\|x\right\| \geq \left| \langle Tx, x\rangle \right| \geq 2\left\|x\right\|^2 \implies \left\|Tx\right\| \geq 2\left\|x\right\|, \quad \forall x \in H. T x:= x-y \in H \left\|Tx - Ty\right\| \geq 2 \left\|x-y\right\| \left\|Tx \right\| + \left\|Ty\right\| \geq\left\| Tx - Ty\right\| \geq 2\left\|x-y\right\| ""1-1""","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
51,Showing a normed vector space is the direct sum of a closed subspace and a one dimensional subspace.,Showing a normed vector space is the direct sum of a closed subspace and a one dimensional subspace.,,"Below is exercise 7 from chaper IV Banach spaces in Lang's Real and Functional Analysis: Let $F$ be a closed subspace of a normed vector space $E$ , and let $v\in E, v\notin F$ . Show that $F+ \Bbb{R}v$ is closed. If $E=F+ \Bbb{R}v$ , show that $E$ is the direct sum of $F$ and $\Bbb Rv$ (meaning the map $\phi(f,rv)= f+rv$ is a toplinear isomorphism from $F\times \Bbb Rv$ to $E$ , i.e. a homeomorphism and isomorphism). I can prove $F+ \Bbb{R}v$ is closed by looking at the quotient space $E/F$ . As the image of $F+ \Bbb{R}v$ under the quotient map $\rho$ is homeomorphic to $\Bbb R$ , it is automatically closed in $E/F$ , whose inverse image is closed in $E$ by continuity of $\rho$ . But $\rho^{-1}(\rho(F+ \Bbb{R}v))=F+ \Bbb{R}v$ , thereby proving the closeness of $F+ \Bbb{R}v$ . But I am stuck at showing the latter statement. It suffices to show that $\phi$ is an open map, which amounts to showing $U_1+U_2$ is open if $U_1$ and $U_2$ are open subsets of $F$ and $\Bbb Rv$ , respectively. Lang mentions that this is an easy consequence of the open mapping theorem, which is a more general result. However, doesn't that assume completeness of $E$ ? I try to use the quotient space technique, but that doesn't seem to apply here as $U_1+U_2$ needs not be saturated. How should I proceed? Thanks in advance.","Below is exercise 7 from chaper IV Banach spaces in Lang's Real and Functional Analysis: Let be a closed subspace of a normed vector space , and let . Show that is closed. If , show that is the direct sum of and (meaning the map is a toplinear isomorphism from to , i.e. a homeomorphism and isomorphism). I can prove is closed by looking at the quotient space . As the image of under the quotient map is homeomorphic to , it is automatically closed in , whose inverse image is closed in by continuity of . But , thereby proving the closeness of . But I am stuck at showing the latter statement. It suffices to show that is an open map, which amounts to showing is open if and are open subsets of and , respectively. Lang mentions that this is an easy consequence of the open mapping theorem, which is a more general result. However, doesn't that assume completeness of ? I try to use the quotient space technique, but that doesn't seem to apply here as needs not be saturated. How should I proceed? Thanks in advance.","F E v\in E, v\notin F F+ \Bbb{R}v E=F+ \Bbb{R}v E F \Bbb Rv \phi(f,rv)= f+rv F\times \Bbb Rv E F+ \Bbb{R}v E/F F+ \Bbb{R}v \rho \Bbb R E/F E \rho \rho^{-1}(\rho(F+ \Bbb{R}v))=F+ \Bbb{R}v F+ \Bbb{R}v \phi U_1+U_2 U_1 U_2 F \Bbb Rv E U_1+U_2","['functional-analysis', 'banach-spaces', 'direct-sum', 'open-map']"
52,Banach space of continuous and discontinuous functions on R,Banach space of continuous and discontinuous functions on R,,"The set $C(\mathbb{R})$ of bounded continuous functions on $\mathbb{R}$ is a Banach space when equipped with the sup norm. In my understanding, it just follows from the fact that a Cauchy sequence of continuous functions converges uniformly to a continuous function. How about the set, which I will denote $C_{\rm{d}}(\mathbb{R})$ , of bounded functions, which are continuous except at $x=0$ , where a jump discontinuity is allowed, i.e. $\displaystyle{\lim_{x\rightarrow 0^\pm}f(x)=f^\pm}$ both exist. Is that a Banach space under the sup norm? It seems like yes, since I can apply the Cauchy argument to both intervals $(-\infty,0]$ and $[0,\infty)$ and conclude that a Cauchy sequence on $C_{\rm{d}}(\mathbb{R})$ will uniformly limit to a function, which is continuous on both intervals individually. Am I right or completely wrong? If I am right, is there a name for such a space?","The set of bounded continuous functions on is a Banach space when equipped with the sup norm. In my understanding, it just follows from the fact that a Cauchy sequence of continuous functions converges uniformly to a continuous function. How about the set, which I will denote , of bounded functions, which are continuous except at , where a jump discontinuity is allowed, i.e. both exist. Is that a Banach space under the sup norm? It seems like yes, since I can apply the Cauchy argument to both intervals and and conclude that a Cauchy sequence on will uniformly limit to a function, which is continuous on both intervals individually. Am I right or completely wrong? If I am right, is there a name for such a space?","C(\mathbb{R}) \mathbb{R} C_{\rm{d}}(\mathbb{R}) x=0 \displaystyle{\lim_{x\rightarrow 0^\pm}f(x)=f^\pm} (-\infty,0] [0,\infty) C_{\rm{d}}(\mathbb{R})","['real-analysis', 'functional-analysis', 'banach-spaces', 'cauchy-sequences', 'complete-spaces']"
53,"Show that the $L^1$ and $L^2$ norms are not equivalent on the set of continuous functions from $[0,1]$ to $\mathbb{R}$",Show that the  and  norms are not equivalent on the set of continuous functions from  to,"L^1 L^2 [0,1] \mathbb{R}","Let $E$ be the vector space of continuous functions on $[0,1]$ . Show that the $L^1$ -norm is not equivalent to the $L^2$ -norm. My thought was that, given a sequence of functions $f_n\in E$ which converges to the function $\frac{1}{\sqrt{x}}$ , we can see that $$||f_n||_1=\int_0^1|f_n|dx \to \int_{0}^1 \frac{1}{\sqrt{x}}dx=2\sqrt{0}+2\sqrt{1}=2 $$ However, $$||f_n||_2=\left(\int_{0}^1 (f_n)^2 dx \right)^{1/2}\to \left(\int_0^1 \frac{1}{x}dx\right)^{1/2}$$ Since this sequence converges with respect to one norm but not the other we can conclude that they are not equivalent. Does this argument make any sense? It feels like it doesn't make sense to talk about the norm of a function that isn't in the space $E$ since $\frac{1}{\sqrt{x}}\notin E$ . But the hint for the problem says to consider truncating said function near 0.","Let be the vector space of continuous functions on . Show that the -norm is not equivalent to the -norm. My thought was that, given a sequence of functions which converges to the function , we can see that However, Since this sequence converges with respect to one norm but not the other we can conclude that they are not equivalent. Does this argument make any sense? It feels like it doesn't make sense to talk about the norm of a function that isn't in the space since . But the hint for the problem says to consider truncating said function near 0.","E [0,1] L^1 L^2 f_n\in E \frac{1}{\sqrt{x}} ||f_n||_1=\int_0^1|f_n|dx \to \int_{0}^1 \frac{1}{\sqrt{x}}dx=2\sqrt{0}+2\sqrt{1}=2  ||f_n||_2=\left(\int_{0}^1 (f_n)^2 dx \right)^{1/2}\to \left(\int_0^1 \frac{1}{x}dx\right)^{1/2} E \frac{1}{\sqrt{x}}\notin E","['functional-analysis', 'solution-verification', 'normed-spaces', 'lp-spaces']"
54,Closure of range of injective compact operator on a Hilbert space,Closure of range of injective compact operator on a Hilbert space,,Let $\mathcal{H}$ be a separable Hilbert space and $C$ a compact operator on $\mathcal{H}$ . Assume that $C$ is injective. Is it then true that the closure of the range of $C$ is $\mathcal{H}$ ?,Let be a separable Hilbert space and a compact operator on . Assume that is injective. Is it then true that the closure of the range of is ?,\mathcal{H} C \mathcal{H} C C \mathcal{H},['functional-analysis']
55,"Let $X$ be a normed vector space. Let $T,S$ be bounded linear operators such that $T^2=T,S^2=S,ST=TS$. Show either $T=S$ or $\|T-S\|\geq 1$",Let  be a normed vector space. Let  be bounded linear operators such that . Show either  or,"X T,S T^2=T,S^2=S,ST=TS T=S \|T-S\|\geq 1","Let $X$ be a normed vector space.  Let $T,S$ be bounded linear operators such that $T^2=T,S^2=S,ST=TS$ . Show either $T=S$ or $\|T-S\|\geq 1$ . My observations: $1\leq\|S\|,1\leq \|T\|$ $\|T-S\|=\|T^2-S^2\|\leq\|T-S\|\|T+S\|$ Thus $1\leq \|T+S\|$ I am not sure how to proceed from here.",Let be a normed vector space.  Let be bounded linear operators such that . Show either or . My observations: Thus I am not sure how to proceed from here.,"X T,S T^2=T,S^2=S,ST=TS T=S \|T-S\|\geq 1 1\leq\|S\|,1\leq \|T\| \|T-S\|=\|T^2-S^2\|\leq\|T-S\|\|T+S\| 1\leq \|T+S\|",['functional-analysis']
56,Is the composition of closed operators closed?,Is the composition of closed operators closed?,,"Let $K,G,H$ be Hilbert spaces with $D_A \subseteq K$ , $D_B \subseteq G$ (possibly not dense) subspaces and let $A: D_A \rightarrow K$ and $B:D_B \rightarrow H$ be closed linear operators. Then is the linear operator $B \circ A: A^{-1}(D_B) \rightarrow H$ a closed linear operator? where $A^{-1}(D_B)$ denotes the preimage of the domain of $B$ . Claim: This is the case when $D_A$ is complete and $A$ is bounded (see e.g. here ). More generally, this is true when for any convergent sequence $(x_n)_{n \in \mathbb{N}}$ with $x_n \rightarrow x \in K$ we have $Ax_n \rightarrow y$ for some $y \in G$ . Proof of claim: Let $x_n \rightarrow x$ and $BAx_n \rightarrow y'$ for some $y' \in K$ . Then by assumption $Ax_n \rightarrow y$ . So since $A$ is closed, $x \in D_A$ and $Ax = y$ . But now since $B$ is closed and $Ax_n \rightarrow y$ and $BAx_n \rightarrow y'$ we have $y \in D_B$ and $y' = By = B A x$ , which proves the claim. So I suspect that the answer to the original question is negative, but I have not been able to construct a counter example. Partial answers and pointers to literature are very welcome. Thank you very much in advance.","Let be Hilbert spaces with , (possibly not dense) subspaces and let and be closed linear operators. Then is the linear operator a closed linear operator? where denotes the preimage of the domain of . Claim: This is the case when is complete and is bounded (see e.g. here ). More generally, this is true when for any convergent sequence with we have for some . Proof of claim: Let and for some . Then by assumption . So since is closed, and . But now since is closed and and we have and , which proves the claim. So I suspect that the answer to the original question is negative, but I have not been able to construct a counter example. Partial answers and pointers to literature are very welcome. Thank you very much in advance.","K,G,H D_A \subseteq K D_B \subseteq G A: D_A \rightarrow K B:D_B \rightarrow H B \circ A: A^{-1}(D_B) \rightarrow H A^{-1}(D_B) B D_A A (x_n)_{n \in \mathbb{N}} x_n \rightarrow x \in K Ax_n \rightarrow y y \in G x_n \rightarrow x BAx_n \rightarrow y' y' \in K Ax_n \rightarrow y A x \in D_A Ax = y B Ax_n \rightarrow y BAx_n \rightarrow y' y \in D_B y' = By = B A x","['functional-analysis', 'operator-theory', 'examples-counterexamples']"
57,$W^2_0$ Poincaré inequality,Poincaré inequality,W^2_0,"Let $\Omega \subset \mathbb R^n$ be a bounded set. Taking the Hilbert space $$W^2=\{v\in \mathcal S'(\Omega):\ v\in L^2,\ |\nabla v|\in L^2,\ \|D^2v\|\in L^2\ \}$$ in order to prove an analogue of the Poincaré inequality $$\exists C:\ \forall v\in ?\subset W^2(\Omega)\qquad \|v\|_{W^2}\le C\|\Delta v\|_{L^2}$$ we have to restrict to a subspace where: the functions take value zero at the boundary? the functions and their normal derivatives take value zero at the boundary? I would expect the second option, nevertheless, even for $\Omega=(-1,1)$ I cannot find an example of function $v\in W^2(\Omega)$ where the boundary value is zero and $$\|v\|_{W^2}>>\|v''\|_{L^2}\qquad v(-1)=v(1)=0$$ so I wonder if we can have a control of the norm even in case 1.","Let be a bounded set. Taking the Hilbert space in order to prove an analogue of the Poincaré inequality we have to restrict to a subspace where: the functions take value zero at the boundary? the functions and their normal derivatives take value zero at the boundary? I would expect the second option, nevertheless, even for I cannot find an example of function where the boundary value is zero and so I wonder if we can have a control of the norm even in case 1.","\Omega \subset \mathbb R^n W^2=\{v\in \mathcal S'(\Omega):\ v\in L^2,\ |\nabla v|\in L^2,\ \|D^2v\|\in L^2\ \} \exists C:\ \forall v\in ?\subset W^2(\Omega)\qquad \|v\|_{W^2}\le C\|\Delta v\|_{L^2} \Omega=(-1,1) v\in W^2(\Omega) \|v\|_{W^2}>>\|v''\|_{L^2}\qquad v(-1)=v(1)=0","['functional-analysis', 'sobolev-spaces']"
58,Strong convergence with comparable speed implies uniform convergence,Strong convergence with comparable speed implies uniform convergence,,"Let $X$ be a Banach space and $(T_n)_n$ a sequence of bounded operators on $X$ . Suppose there is a sequence $(q_n)_n$ in $\mathbb R$ converging to $0$ such that for each $x \in X$ there is $M_x > 0$ such that $\lVert T_n x \rVert \leq M_x q_n$ . I want to show that this implies $T_n \to 0$ uniformly. I thought Baire's theorem should do the trick: Let $\varepsilon > 0$ and consider the sets $A_k := \{x \in X : \forall n \geq k: \lVert T_n x \rVert \leq \varepsilon \}$ . Then it is clear that the $A_k$ 's are closed, $A_k \subseteq A_{k + 1}$ and $X = \bigcup_{k \in \mathbb N} A_k$ . Hence, there is $K \in \mathbb N$ such that $A_K$ has non-empty interior. In particular, there is $x_0 \in X$ and $r_0 > 0$ such that $B(x_0, r_0) \subseteq A_K$ . Now for $x \in B[0, 1]$ and $0 < r < r_0$ I estimate as follows: $$\lVert T_n x \rVert \leq \frac 1 r (\lVert T_n x_0 \rVert + \lVert T_n (rx + x_0) \rVert) \leq \frac{2\varepsilon}{r} \overset{r \to r_0} \longrightarrow \frac{2\varepsilon}{r_0}$$ and hence $\lVert T_n \rVert \leq \frac{2\varepsilon}{r_0}$ for all $n \geq K$ . But $r_0$ depends on $\varepsilon$ so this does not give me the desired conclusion. I also tried other set families $(A_k)_k$ but I seem to struggle to find the right one. I think my main problem is that my $A_k$ 's do not make use of the fact that $\lVert T_n x \rVert \leq M_x \varepsilon$ for big $n$ .","Let be a Banach space and a sequence of bounded operators on . Suppose there is a sequence in converging to such that for each there is such that . I want to show that this implies uniformly. I thought Baire's theorem should do the trick: Let and consider the sets . Then it is clear that the 's are closed, and . Hence, there is such that has non-empty interior. In particular, there is and such that . Now for and I estimate as follows: and hence for all . But depends on so this does not give me the desired conclusion. I also tried other set families but I seem to struggle to find the right one. I think my main problem is that my 's do not make use of the fact that for big .","X (T_n)_n X (q_n)_n \mathbb R 0 x \in X M_x > 0 \lVert T_n x \rVert \leq M_x q_n T_n \to 0 \varepsilon > 0 A_k := \{x \in X : \forall n \geq k: \lVert T_n x \rVert \leq \varepsilon \} A_k A_k \subseteq A_{k + 1} X = \bigcup_{k \in \mathbb N} A_k K \in \mathbb N A_K x_0 \in X r_0 > 0 B(x_0, r_0) \subseteq A_K x \in B[0, 1] 0 < r < r_0 \lVert T_n x \rVert \leq \frac 1 r (\lVert T_n x_0 \rVert + \lVert T_n (rx + x_0) \rVert) \leq \frac{2\varepsilon}{r} \overset{r \to r_0} \longrightarrow \frac{2\varepsilon}{r_0} \lVert T_n \rVert \leq \frac{2\varepsilon}{r_0} n \geq K r_0 \varepsilon (A_k)_k A_k \lVert T_n x \rVert \leq M_x \varepsilon n","['real-analysis', 'functional-analysis', 'metric-spaces']"
59,Limit of resolvent in terms of limit of semigroup,Limit of resolvent in terms of limit of semigroup,,"Let $(T_t)_{t\geq 0}$ be a $C_0$ -semigroup on a Banach space $X$ with generator $A$ such that the spectral bound $s(A)=0.$ Suppose there exists an operator $P$ on $X$ such that $$T(t) \stackrel{t\to \infty}{\to} P \text{ strongly }.$$ Then I was able to show that $$\lim_{\lambda\to 0}\lambda R(\lambda,A)f \text{ exists for each } f\in X \qquad\qquad (1).$$ I was told the converse is true if the semigroup is holomorphic. However, I'm wondering what can be said about the limit in $(1).$ I know that if $0$ is an isolated spectral value and a pole, then the limit in $(1)$ is the spectral projection associated to $0.$ What happens when it is not an isolated spectral value? Is the limit in $(1)$ equal to $P?$ Edit: Let $\lambda>0.$ Since $T(t) \to P,$ therefore $\mathrm{Im}\, P=\ker A$ and $\overline{\mathrm{Im}\, A}\subseteq \ker P.$ The first implies that $$\lambda R(\lambda,A)P=P$$ and the second implies that $$\lim_{\lambda \to 0}\lambda R(\lambda,A)=0 \text{ on a closed subspace of } \ker P.$$ Can we now conclude by the existence of limit that, infact $$\lim_{\lambda \to 0}\lambda R(\lambda,A)=0 \text{ on } \ker P$$ and hence $$\lim_{\lambda \to 0}\lambda R(\lambda,A)=P?$$","Let be a -semigroup on a Banach space with generator such that the spectral bound Suppose there exists an operator on such that Then I was able to show that I was told the converse is true if the semigroup is holomorphic. However, I'm wondering what can be said about the limit in I know that if is an isolated spectral value and a pole, then the limit in is the spectral projection associated to What happens when it is not an isolated spectral value? Is the limit in equal to Edit: Let Since therefore and The first implies that and the second implies that Can we now conclude by the existence of limit that, infact and hence","(T_t)_{t\geq 0} C_0 X A s(A)=0. P X T(t) \stackrel{t\to \infty}{\to} P \text{ strongly }. \lim_{\lambda\to 0}\lambda R(\lambda,A)f \text{ exists for each } f\in X \qquad\qquad (1). (1). 0 (1) 0. (1) P? \lambda>0. T(t) \to P, \mathrm{Im}\, P=\ker A \overline{\mathrm{Im}\, A}\subseteq \ker P. \lambda R(\lambda,A)P=P \lim_{\lambda \to 0}\lambda R(\lambda,A)=0 \text{ on a closed subspace of } \ker P. \lim_{\lambda \to 0}\lambda R(\lambda,A)=0 \text{ on } \ker P \lim_{\lambda \to 0}\lambda R(\lambda,A)=P?","['functional-analysis', 'semigroup-of-operators']"
60,Proof check about bounded operator,Proof check about bounded operator,,"Let $X$ and $Y$ be Banach spaces, and fix a bounded linear operator $A \in \mathcal{B}(X, Y)$ . Choose $\mu \in Y^{*}$ ,  and define a functional $A^{*} \mu: X \rightarrow \mathbf{F}$ by $\left(A^{*} \mu\right)(x)=\mu(A x)$ ,  for $x \in X$ . I want to show that the mapping $A^*\colon \mu \mapsto A^{*} \mu$ is a bounded linear mapping of $Y^{*}$ into $X^*$ . Linear part is easy and my thought about bounded part is \begin{align}\|A^*\|&=\sup_{\|\mu\|=1}\|A^*\mu\|=\sup_{\|\mu\|=1}(\sup_{\|x\|=1}\|(A^*\mu)(x)\|)\\&=\sup_{\|\mu\|=1}(\sup_{\|x\|=1}\|\mu(Ax)\|)=\sup_{\|\mu\|=1}\|\mu A\|=\|A\| \end{align} Is that correct?  Also, is there a way to show $\|A\|=\|A^*\|$ ?Any help is appreciated.","Let and be Banach spaces, and fix a bounded linear operator . Choose ,  and define a functional by ,  for . I want to show that the mapping is a bounded linear mapping of into . Linear part is easy and my thought about bounded part is Is that correct?  Also, is there a way to show ?Any help is appreciated.","X Y A \in \mathcal{B}(X, Y) \mu \in Y^{*} A^{*} \mu: X \rightarrow \mathbf{F} \left(A^{*} \mu\right)(x)=\mu(A x) x \in X A^*\colon \mu \mapsto A^{*} \mu Y^{*} X^* \begin{align}\|A^*\|&=\sup_{\|\mu\|=1}\|A^*\mu\|=\sup_{\|\mu\|=1}(\sup_{\|x\|=1}\|(A^*\mu)(x)\|)\\&=\sup_{\|\mu\|=1}(\sup_{\|x\|=1}\|\mu(Ax)\|)=\sup_{\|\mu\|=1}\|\mu A\|=\|A\|
\end{align} \|A\|=\|A^*\|",['functional-analysis']
61,"Non-triviality of ""Weak closures of $*$-subalgebras are von Neumann algebras""","Non-triviality of ""Weak closures of -subalgebras are von Neumann algebras""",*,"I suspect there is a slight error in Murphy's C*-algebras and Operator Theory: Murphy defines a von Neumann algebra on a Hilbert space $H$ as a $*$ -subalgebra of $B(H)$ that is strongly closed. I mention that because others define von Neumann algebras as those that are equal to their double commutants (if $id_H\in A$ , the definitions are equivalent by the double commutant theorem, but if not, they are not the same; we can reduce to this definition by considering the unit of $A$ though, which is a projection and compressing to that subspace). Anyway, after a number of results on von Neumann algebras and the strong and weak operator topologies, Murphy says ""If $A$ is a $*$ -subalgebra of $B(H)$ , then its weak closure is a von Neumann algebra."" and he refers to this as a simple observation BEFORE moving on to Kaplansky's density theorem. He also says that this will be used in the proof of Kaplansky's theorem (but I cannot spot where he uses it). I don't think this is trivial without Kaplansky's help. I mean, obviously, since convex sets have equal strong and weak closures, if $A$ is a $*$ -subalgebra of $B(H)$ then $\overline{A}^{WOT}=\overline{A}^{SOT}$ , so this is indeed strongly closed. By weak continuity of involution, it is a self-adjoint set. It is obviously a linear subspace. But why is this a subalgebra ? Using Kaplansky's theorem, I can see why this is true: If $u,v\in\overline{A}^{SOT}$ , then we can find a norm-bounded (by Kaplansky) net $(u_\lambda)\subset A$ with $u_\lambda\xrightarrow{SOT}u$ and let $(v_\lambda)\subset A$ be a net with $v_\lambda\xrightarrow{SOT}v$ . Then since multiplication restricted on $S\times B(H)\to B(H)$ where $S$ is a bounded subset of $B(H)$ is strongly continuous, we get that $uv\in\overline{A}^{SOT}$ and we are done. Is there something that obvious that I am missing out?","I suspect there is a slight error in Murphy's C*-algebras and Operator Theory: Murphy defines a von Neumann algebra on a Hilbert space as a -subalgebra of that is strongly closed. I mention that because others define von Neumann algebras as those that are equal to their double commutants (if , the definitions are equivalent by the double commutant theorem, but if not, they are not the same; we can reduce to this definition by considering the unit of though, which is a projection and compressing to that subspace). Anyway, after a number of results on von Neumann algebras and the strong and weak operator topologies, Murphy says ""If is a -subalgebra of , then its weak closure is a von Neumann algebra."" and he refers to this as a simple observation BEFORE moving on to Kaplansky's density theorem. He also says that this will be used in the proof of Kaplansky's theorem (but I cannot spot where he uses it). I don't think this is trivial without Kaplansky's help. I mean, obviously, since convex sets have equal strong and weak closures, if is a -subalgebra of then , so this is indeed strongly closed. By weak continuity of involution, it is a self-adjoint set. It is obviously a linear subspace. But why is this a subalgebra ? Using Kaplansky's theorem, I can see why this is true: If , then we can find a norm-bounded (by Kaplansky) net with and let be a net with . Then since multiplication restricted on where is a bounded subset of is strongly continuous, we get that and we are done. Is there something that obvious that I am missing out?","H * B(H) id_H\in A A A * B(H) A * B(H) \overline{A}^{WOT}=\overline{A}^{SOT} u,v\in\overline{A}^{SOT} (u_\lambda)\subset A u_\lambda\xrightarrow{SOT}u (v_\lambda)\subset A v_\lambda\xrightarrow{SOT}v S\times B(H)\to B(H) S B(H) uv\in\overline{A}^{SOT}","['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
62,isolated point of spectrum of compact self-adjoint linear operator on infinite-dimensional separable Hilbert space.,isolated point of spectrum of compact self-adjoint linear operator on infinite-dimensional separable Hilbert space.,,"Let $H$ be an infinite-dimensional separable Hilbert space over $\mathbb{R}$ , and let $K : H \to H$ be a compact self-adjoint linear operator. Prove that if $0$ is an isolated point of the spectrum of $K$ , then $0$ is an eigenvalue of $K$ with infinite-dimensional eigenspace. My attempt: since $K$ is compact operator on  an infinite dimensional hilber space we have that $0\in \sigma(K)$ and $\sigma(K)=\sigma_p(K) \cup\{0\}$ .  Suppose that $0 \notin \sigma_p(K)$ , then it must be that there exists some sequence $(\lambda_j)_{j\ge 1}\in \sigma_p(K)$ such that $\lim_{j\to \infty}\lambda_j = 0 $ . But since $0$ is an isolated point of the spectrum , such sequence cannot exists. Hence , $0\in \sigma_p(K)$ . Also, Since $H$ is separable let $(e_n)_{n\ge 1}$ be the orthonormal basis then since $\lambda =0$ is an eigenvalue of $K$ , we have that $\forall e_n \implies K(e_n)=0(e_n)$ , so all basis vectors (which are countably infinite) can be the eigenvectors for the eigenvalue $0$ , so dimension of the eigenspace is also infinite.","Let be an infinite-dimensional separable Hilbert space over , and let be a compact self-adjoint linear operator. Prove that if is an isolated point of the spectrum of , then is an eigenvalue of with infinite-dimensional eigenspace. My attempt: since is compact operator on  an infinite dimensional hilber space we have that and .  Suppose that , then it must be that there exists some sequence such that . But since is an isolated point of the spectrum , such sequence cannot exists. Hence , . Also, Since is separable let be the orthonormal basis then since is an eigenvalue of , we have that , so all basis vectors (which are countably infinite) can be the eigenvectors for the eigenvalue , so dimension of the eigenspace is also infinite.",H \mathbb{R} K : H \to H 0 K 0 K K 0\in \sigma(K) \sigma(K)=\sigma_p(K) \cup\{0\} 0 \notin \sigma_p(K) (\lambda_j)_{j\ge 1}\in \sigma_p(K) \lim_{j\to \infty}\lambda_j = 0  0 0\in \sigma_p(K) H (e_n)_{n\ge 1} \lambda =0 K \forall e_n \implies K(e_n)=0(e_n) 0,"['functional-analysis', 'analysis', 'solution-verification', 'spectral-theory', 'compact-operators']"
63,Embedding Sobolev $H^1$ into $L^\infty$ space,Embedding Sobolev  into  space,H^1 L^\infty,"My question is to eventually prove the following inequality: for $f\in H^1(\mathbb{R})=\{f,f'\in L^2\}$ $$\|f\|_{L^\infty}\leq a\|f\|_{L^2}+\frac{1}{a}\|f'\|_{L^2}, \forall a>0.$$ Here are my thoughts: 1). Sobolev embedding tells us: $$ H^1(\mathbb{R})\hookrightarrow C^{0,1/2}(\mathbb{R}),$$ for $\Omega$ being a compact subset of $\mathbb{R}$ . 2). Coverage in $C^{0,1/2}$ implies Converge in $L^\infty$ (still need compact support?) 3). It seems that we may have now $\|f\|_{L^\infty}\leq C\|f\|_{H^1}$ over any compact subset. My confusion is how to remove the compactness requirement (Lebesgue Dominated convergence theorem?) and how to prove the final version of that inequality? New thoughts : suppose $f_n=f \chi_{[-n.n]}$ , then via FTC, we have $$f_n(z)=\int^z_af'(s)ds+f(a),$$ here we can choose $a$ such that $|f(a)|\leq \frac{1}{2n}\int_{-n}^n|f(s)|ds$ , then by Cauchy-Schwartz inequality, $$|f_n(z)|\leq \sqrt{2n}\|f'\|_{L^2}+\frac{1}{\sqrt{2n}}\|f\|_{L^2}.$$ Then I try to apply DCT, which is not allowed in this case.","My question is to eventually prove the following inequality: for Here are my thoughts: 1). Sobolev embedding tells us: for being a compact subset of . 2). Coverage in implies Converge in (still need compact support?) 3). It seems that we may have now over any compact subset. My confusion is how to remove the compactness requirement (Lebesgue Dominated convergence theorem?) and how to prove the final version of that inequality? New thoughts : suppose , then via FTC, we have here we can choose such that , then by Cauchy-Schwartz inequality, Then I try to apply DCT, which is not allowed in this case.","f\in H^1(\mathbb{R})=\{f,f'\in L^2\} \|f\|_{L^\infty}\leq a\|f\|_{L^2}+\frac{1}{a}\|f'\|_{L^2}, \forall a>0.  H^1(\mathbb{R})\hookrightarrow C^{0,1/2}(\mathbb{R}), \Omega \mathbb{R} C^{0,1/2} L^\infty \|f\|_{L^\infty}\leq C\|f\|_{H^1} f_n=f \chi_{[-n.n]} f_n(z)=\int^z_af'(s)ds+f(a), a |f(a)|\leq \frac{1}{2n}\int_{-n}^n|f(s)|ds |f_n(z)|\leq \sqrt{2n}\|f'\|_{L^2}+\frac{1}{\sqrt{2n}}\|f\|_{L^2}.","['complex-analysis', 'functional-analysis', 'sobolev-spaces', 'integral-inequality']"
64,How to show convolution is associative?,How to show convolution is associative?,,"Consider a semigroup $\Gamma$ and the space $$l^1(\Gamma) := \left\{f: \Gamma \to \mathbb{C}: \sum_{x \in \Gamma} |f(x)| < \infty\right\}$$ where the summation is understood as in the following definition: Let $S$ be any set. Let $f: S \to \mathbb{C}$ be a function. We say $\sum_{n \in S}f(n)$ converges to $F\in \mathbb{C}$ if the following   condition is satisfied: For all $\epsilon > 0$ , there is a finite subset $T_0$ of $S$ such   that if $T\supseteq T_0$ and $T$ is a finite subset of $S$ , then $$\left|\sum_{n \in T} f(n)-F\right| < \epsilon$$ I know the basic properties of this summation, i.e. Fubini etc. Define the convolution $f * g$ by $$(f*g)(x) = \sum_{\{(y,z)\in \Gamma^2: yz = x\}} f(y)g(z)$$ I'm trying to prove that $$((f*g)*h)(x)=(f*(g*h))(x)$$ or equivalently $$\sum_{ab=x}\sum_{st = a}f(s)g(t)h(b) = \sum_{ab=x}\sum_{st=b}f(a)g(s)h(t)$$ but I can't formally justify why these two sums must coincide. Any help is appreciated!","Consider a semigroup and the space where the summation is understood as in the following definition: Let be any set. Let be a function. We say converges to if the following   condition is satisfied: For all , there is a finite subset of such   that if and is a finite subset of , then I know the basic properties of this summation, i.e. Fubini etc. Define the convolution by I'm trying to prove that or equivalently but I can't formally justify why these two sums must coincide. Any help is appreciated!","\Gamma l^1(\Gamma) := \left\{f: \Gamma \to \mathbb{C}: \sum_{x \in \Gamma} |f(x)| < \infty\right\} S f: S \to \mathbb{C} \sum_{n \in S}f(n) F\in \mathbb{C} \epsilon > 0 T_0 S T\supseteq T_0 T S \left|\sum_{n \in T} f(n)-F\right| < \epsilon f * g (f*g)(x) = \sum_{\{(y,z)\in \Gamma^2: yz = x\}} f(y)g(z) ((f*g)*h)(x)=(f*(g*h))(x) \sum_{ab=x}\sum_{st = a}f(s)g(t)h(b) = \sum_{ab=x}\sum_{st=b}f(a)g(s)h(t)","['functional-analysis', 'measure-theory']"
65,"Is the convex combination of a convex and strictly convex set, strictly convex?","Is the convex combination of a convex and strictly convex set, strictly convex?",,"Let $S \subset C \subset \mathbb{R}^d$ be two subsets of $\mathbb{R}^d$ , one included in the other. For the sake of simplicity, assume that they are both compact and $\boldsymbol{0}$ belongs to both of their interiors. My question is the following. If $C$ is convex and $S$ is strictly convex, is it true that for all $\lambda \in [0,1)$ , their convex combination $$ (1-\lambda)S + \lambda C = \bigl\{(1-\lambda) \boldsymbol{s} + \lambda\boldsymbol{c} : \boldsymbol{s} \in S, \boldsymbol{c} \in C \bigr\} $$ is strictly convex? It is known that the Minkowski sum $A+B = \{a+b:a\in A, b\in B\}$ of any two convex sets is itself convex, but my intuition (see pic. below) tells me that (at least under the assumptions above) the strict convexity of just one of them should imply the strict convexity of the convex combination.","Let be two subsets of , one included in the other. For the sake of simplicity, assume that they are both compact and belongs to both of their interiors. My question is the following. If is convex and is strictly convex, is it true that for all , their convex combination is strictly convex? It is known that the Minkowski sum of any two convex sets is itself convex, but my intuition (see pic. below) tells me that (at least under the assumptions above) the strict convexity of just one of them should imply the strict convexity of the convex combination.","S \subset C \subset \mathbb{R}^d \mathbb{R}^d \boldsymbol{0} C S \lambda \in [0,1) 
(1-\lambda)S + \lambda C = \bigl\{(1-\lambda) \boldsymbol{s} + \lambda\boldsymbol{c} : \boldsymbol{s} \in S, \boldsymbol{c} \in C \bigr\}
 A+B = \{a+b:a\in A, b\in B\}","['functional-analysis', 'convex-analysis', 'normed-spaces', 'convex-geometry', 'convex-hulls']"
66,"(Proof Updated, Verification in Need) Show that $(s,t)\mapsto t\wedge s$ for $s,t\geq 0$ and $(s,t)\mapsto e^{-|t-s|}$ are positive semi-definite.","(Proof Updated, Verification in Need) Show that  for  and  are positive semi-definite.","(s,t)\mapsto t\wedge s s,t\geq 0 (s,t)\mapsto e^{-|t-s|}","We say a positive symmetric $n\times n$ matrix $M$ over $\mathbb{R}^n$ is semi-definite if $v^{\intercal}Mv\geq 0$ for all nonzero $v\in\mathbb{R}^n$ . We say a function $f:\mathbb{T}^2\longrightarrow\mathbb{R}$ to be positive semi-definite if $\Big(f(t_k, t_j)\Big)_{k,j=1}^n$ is a positive semi-definite matrix for all $(t_k)_{k=1}^n\in\mathbb{T}^n$ With this definition, I am working on an exercise asking me to show $(1)$ the function $f:(s,t)\mapsto t\wedge s$ defined for $s,t\geq 0$ is positive semi-definite; $(2)$ the function $c:(s,t)\mapsto e^{-|t-s|}$ is positive semi-definite. For the first one, I tried to use the fact that $$\int_{\mathbb{R}^{+}}\mathbb{1}_{[0,t]}\mathbb{1}_{[0,s]} \,d\mu = t\wedge s,$$ so that each term in the matrix is of the form $b_{i,j}:=f(t_i,t_j)=\int_{\mathbb{R}^{+}}\mathbb{1}_{[0,t_{j}]} \mathbb{1}_{[0,t_{}} \, d\mu$ , for $t,j=1,\cdots,n$ . Let $v=(v_1,\ldots, v_n)\in\mathbb{R}^n$ , then $$v^{\intercal} Mv=a_1 \sum_{i=1}^n a_i b_{i,1}+a_2\sum_{i=1}^n a_i b_{i,2} + a_3 \sum_{i=1}^n a_i b_{i,3}+\cdots+a_n \sum_{i=1}^n a_i b_{i,n}.$$ But then I don't know what to do next.. For the second one, the exercise gives an hint: using an auxiliary Hilbert space $H$ and a $h_t\in H$ such that $\langle h_t, h_s\rangle=c(s,t)\ldots$ I don't really know how to use this hint... I really need an answer with some details, since this is an exercise in Stochastic Process, instead of functional analysis and so forth, so I don't have enough background of this... Thank you so much! Edit 1: (Proof of the first one) Following MaoWao 's suggestion, I think I proved the first one. Firstly let me claim that if $H$ is a Hilbert space, then its corresponding inner product $\langle\cdot, \cdot\rangle_H:H\times H\longrightarrow\mathbb{R}$ is positive semi-definite. Indeed, we have for any $n\in\mathbb{N}$ , $x_1,\ldots, x_n \in H$ and $c_1,\ldots, c_n \in\mathbb{R}$ that $$\sum_{i,j=1}^n c_i c_j \langle x_i,x_j\rangle_H = \left<\sum_{i=1}^n c_i x_i,\sum_{j=1}^n c_j x_j \right>_H =\Big\|\sum_{i=1}^n c_i x_i\Big\|_H^2\geq 0.$$ In fact, the above result also holds for pre-Hilbert space, since the notion of completeness was not involved in the above argument. Thus, we only need to find a specific (pre-)Hilbert Space $H$ and a $h_{t}\in H$ such that $\langle h_t, h_s\rangle_H = t\wedge s$ . But this is easy, let's consider $H:=L^2(\mathbb{R}_{+})$ , and $h_t:=\mathbb{1}_{[0,t]}$ . It is clear that $h_t\in H$ , and for any $t,s\geq 0$ , we have $$\langle h_t, h_s\rangle_{L^2(\mathbb{R}_{+})} = \int_{\mathbb{R}_{+}}\mathbb{1}_{[0,t]} \mathbb{1}_{[0,s]} \, d\mu=t\wedge s,$$ and thus we are done. Edit 2: (Proof of the second one) I've searched all over the places. The function in $(2)$ is Abel kernel, but it is rarely discussed since Abel kernel is closely related to Poisson kernel, and most of the discussions are on the latter. Later, I found a really close one: the Gaussian kernel and here is a link about the proof of Gaussian kernel is really a kernel. That is, it is positive semidefinite. https://stats.stackexchange.com/questions/35634/how-to-prove-that-the-radial-basis-function-is-a-kernel In this link, one answer used the characteristic function. This greatly inspired me. I also found a characteristic function, which is the one for Cauchy distribution. Below is the proof: Recall the Cauchy Distribution $(x_{0},\gamma)$ with $\gamma>0$ has the characteristic function $$\varphi(t)=e^{ix_{0}t-\gamma|t|}.$$ Using this, we can write $c(s,t)=h(s-t)$ where $h(t):=e^{-|t|}=\mathbb{E}e^{itZ}$ is the characteristic function of a random variable $Z$ with Cauchy $(0,1)$ distribution. Then for real numbers $x_{1},\cdots, x_{n}$ and $a_{1},\cdots, a_{n}$ , we have \begin{align*} \sum_{j,k=1}^{n}a_{j}a_{k}h(x_{j}-x_{k})&=\sum_{j,k=1}^{n}a_{j}a_{k}\mathbb{E}e^{i(x_{j}-x_{k})Z}\\ &=\mathbb{E}\Big(\sum_{j,k=1}^{n}a_{j}e^{ix_{j}Z}a_{k}e^{-ix_{k}Z}\Big)\\ &=\mathbb{E}\Big(\Big|\sum_{j=1}^{n}a_{j}e^{ix_{j}Z}\Big|^{2}\Big)\geq 0. \end{align*} Thus, $c$ is positive semi-definite. It seems that I did not use the hint at all for part $(2)$ , so I believe there must be another way. I do need someone to check if my proof in the edit 1 and edit 2 is correct. I am gonna open a bounty in 19 hours later, for proof checking and possible new proof. Thank you!","We say a positive symmetric matrix over is semi-definite if for all nonzero . We say a function to be positive semi-definite if is a positive semi-definite matrix for all With this definition, I am working on an exercise asking me to show the function defined for is positive semi-definite; the function is positive semi-definite. For the first one, I tried to use the fact that so that each term in the matrix is of the form , for . Let , then But then I don't know what to do next.. For the second one, the exercise gives an hint: using an auxiliary Hilbert space and a such that I don't really know how to use this hint... I really need an answer with some details, since this is an exercise in Stochastic Process, instead of functional analysis and so forth, so I don't have enough background of this... Thank you so much! Edit 1: (Proof of the first one) Following MaoWao 's suggestion, I think I proved the first one. Firstly let me claim that if is a Hilbert space, then its corresponding inner product is positive semi-definite. Indeed, we have for any , and that In fact, the above result also holds for pre-Hilbert space, since the notion of completeness was not involved in the above argument. Thus, we only need to find a specific (pre-)Hilbert Space and a such that . But this is easy, let's consider , and . It is clear that , and for any , we have and thus we are done. Edit 2: (Proof of the second one) I've searched all over the places. The function in is Abel kernel, but it is rarely discussed since Abel kernel is closely related to Poisson kernel, and most of the discussions are on the latter. Later, I found a really close one: the Gaussian kernel and here is a link about the proof of Gaussian kernel is really a kernel. That is, it is positive semidefinite. https://stats.stackexchange.com/questions/35634/how-to-prove-that-the-radial-basis-function-is-a-kernel In this link, one answer used the characteristic function. This greatly inspired me. I also found a characteristic function, which is the one for Cauchy distribution. Below is the proof: Recall the Cauchy Distribution with has the characteristic function Using this, we can write where is the characteristic function of a random variable with Cauchy distribution. Then for real numbers and , we have Thus, is positive semi-definite. It seems that I did not use the hint at all for part , so I believe there must be another way. I do need someone to check if my proof in the edit 1 and edit 2 is correct. I am gonna open a bounty in 19 hours later, for proof checking and possible new proof. Thank you!","n\times n M \mathbb{R}^n v^{\intercal}Mv\geq 0 v\in\mathbb{R}^n f:\mathbb{T}^2\longrightarrow\mathbb{R} \Big(f(t_k, t_j)\Big)_{k,j=1}^n (t_k)_{k=1}^n\in\mathbb{T}^n (1) f:(s,t)\mapsto t\wedge s s,t\geq 0 (2) c:(s,t)\mapsto e^{-|t-s|} \int_{\mathbb{R}^{+}}\mathbb{1}_{[0,t]}\mathbb{1}_{[0,s]} \,d\mu = t\wedge s, b_{i,j}:=f(t_i,t_j)=\int_{\mathbb{R}^{+}}\mathbb{1}_{[0,t_{j}]} \mathbb{1}_{[0,t_{}} \, d\mu t,j=1,\cdots,n v=(v_1,\ldots, v_n)\in\mathbb{R}^n v^{\intercal} Mv=a_1 \sum_{i=1}^n a_i b_{i,1}+a_2\sum_{i=1}^n a_i b_{i,2} + a_3 \sum_{i=1}^n a_i b_{i,3}+\cdots+a_n \sum_{i=1}^n a_i b_{i,n}. H h_t\in H \langle h_t, h_s\rangle=c(s,t)\ldots H \langle\cdot, \cdot\rangle_H:H\times H\longrightarrow\mathbb{R} n\in\mathbb{N} x_1,\ldots, x_n \in H c_1,\ldots, c_n \in\mathbb{R} \sum_{i,j=1}^n c_i c_j \langle x_i,x_j\rangle_H = \left<\sum_{i=1}^n c_i x_i,\sum_{j=1}^n c_j x_j \right>_H =\Big\|\sum_{i=1}^n c_i x_i\Big\|_H^2\geq 0. H h_{t}\in H \langle h_t, h_s\rangle_H = t\wedge s H:=L^2(\mathbb{R}_{+}) h_t:=\mathbb{1}_{[0,t]} h_t\in H t,s\geq 0 \langle h_t, h_s\rangle_{L^2(\mathbb{R}_{+})} = \int_{\mathbb{R}_{+}}\mathbb{1}_{[0,t]} \mathbb{1}_{[0,s]} \, d\mu=t\wedge s, (2) (x_{0},\gamma) \gamma>0 \varphi(t)=e^{ix_{0}t-\gamma|t|}. c(s,t)=h(s-t) h(t):=e^{-|t|}=\mathbb{E}e^{itZ} Z (0,1) x_{1},\cdots, x_{n} a_{1},\cdots, a_{n} \begin{align*}
\sum_{j,k=1}^{n}a_{j}a_{k}h(x_{j}-x_{k})&=\sum_{j,k=1}^{n}a_{j}a_{k}\mathbb{E}e^{i(x_{j}-x_{k})Z}\\
&=\mathbb{E}\Big(\sum_{j,k=1}^{n}a_{j}e^{ix_{j}Z}a_{k}e^{-ix_{k}Z}\Big)\\
&=\mathbb{E}\Big(\Big|\sum_{j=1}^{n}a_{j}e^{ix_{j}Z}\Big|^{2}\Big)\geq 0.
\end{align*} c (2)","['linear-algebra', 'functional-analysis', 'stochastic-processes', 'operator-theory', 'positive-semidefinite']"
67,"Spectrum of $-\frac{d^2}{dx^2}$ with respect to space of continuous periodic functions on $[0,2\pi]$",Spectrum of  with respect to space of continuous periodic functions on,"-\frac{d^2}{dx^2} [0,2\pi]","Let $\mathcal{B}$ denote the Banach space of all continuous functions $f: [0,2\pi] \to \mathbb{C}$ such that $f(0) = f(2\pi)$ . Let $A$ denote the operator $$Af = -f'', \qquad \text{Dom}(A) = \{ f \in \mathcal{B} : f \in C^2[0,2\pi] \}.$$ I would like to find the spectrum of $A$ . So far, I've been trying to compute the spectrum by hand, and I conjecture that $\text{spec}(A)$ is $\{n^2 : n = 0,1, 2, \dots\}$ . We get one inclusion simply by noticing that, for each $n = 0, 1, 2, \dots$ , $n^2$ is an eigenvalue of $A$ with periodic eigenfunction $e^{inx}$ . Showing the other inclusion is where I have gotten stuck. By factoring $$-\frac{d^2}{dx^2}- \lambda^2 = (D_x - \lambda)(D_x + \lambda), \qquad D_x = \frac{1}{i} \frac{d}{dx}, \, \lambda \neq 1, 2, \dots $$ and using the integrating factor method twice, we find that the solution $u$ to the equation $$(A - \lambda^2)u = f \in \mathcal{B},$$ is given by $$u(x) = c_2 e^{-i\lambda t} + \frac{c_1}{i2\lambda}e^{i\lambda t} + F(x), $$ for some $c_1, c_2 \in \mathbb{C}$ and where $$F(x) = \int_0^x e^{i2\lambda t} \int^s_0 e^{-i\lambda t} f(t) dt ds.$$ So the above expression for $u$ is our proposed formula for $(A - \lambda^2)^{-1}f$ , but it remains to show that $(A - \lambda^2)^{-1}$ is bounded and that $u$ can indeed be made periodic. Requiring that $u$ be periodic gives rise to a linear system to solve for $c_1$ and $c_2$ . It appears this system has a unique solution unless $\lambda$ is an integer or half-integer. So, it may be that the spectrum consists of more than eigenvalues above. But I'm not sure how to decide if the half-integers are indeed in the spectrum or not. Hints or solutions are greatly appreciated!","Let denote the Banach space of all continuous functions such that . Let denote the operator I would like to find the spectrum of . So far, I've been trying to compute the spectrum by hand, and I conjecture that is . We get one inclusion simply by noticing that, for each , is an eigenvalue of with periodic eigenfunction . Showing the other inclusion is where I have gotten stuck. By factoring and using the integrating factor method twice, we find that the solution to the equation is given by for some and where So the above expression for is our proposed formula for , but it remains to show that is bounded and that can indeed be made periodic. Requiring that be periodic gives rise to a linear system to solve for and . It appears this system has a unique solution unless is an integer or half-integer. So, it may be that the spectrum consists of more than eigenvalues above. But I'm not sure how to decide if the half-integers are indeed in the spectrum or not. Hints or solutions are greatly appreciated!","\mathcal{B} f: [0,2\pi] \to \mathbb{C} f(0) = f(2\pi) A Af = -f'', \qquad \text{Dom}(A) = \{ f \in \mathcal{B} : f \in C^2[0,2\pi] \}. A \text{spec}(A) \{n^2 : n = 0,1, 2, \dots\} n = 0, 1, 2, \dots n^2 A e^{inx} -\frac{d^2}{dx^2}- \lambda^2 = (D_x - \lambda)(D_x + \lambda), \qquad D_x = \frac{1}{i} \frac{d}{dx}, \, \lambda \neq 1, 2, \dots  u (A - \lambda^2)u = f \in \mathcal{B}, u(x) = c_2 e^{-i\lambda t} + \frac{c_1}{i2\lambda}e^{i\lambda t} + F(x),  c_1, c_2 \in \mathbb{C} F(x) = \int_0^x e^{i2\lambda t} \int^s_0 e^{-i\lambda t} f(t) dt ds. u (A - \lambda^2)^{-1}f (A - \lambda^2)^{-1} u u c_1 c_2 \lambda","['functional-analysis', 'ordinary-differential-equations', 'spectral-theory']"
68,Isometry between $L^\infty$ and $(L^1)^*$,Isometry between  and,L^\infty (L^1)^*,"I know that for $p \in (1,\infty] \,$ , $L^q(\Omega,\mathcal{M},\mu)$ is isometric to $(L^p(\Omega,\mathcal{M},\mu))^*$ with $\frac{1}{p}+\frac{1}{q}=1$ , namely that the operator: $$ T:L^q \to (L^p)^*, \;\; T: g \mapsto L_{g}, \;\; L_{g}f = \int_{\Omega}{fg \:d\mu} \;\; \forall f\in L^p$$ is an isometry. Indeed: $ ||L_{g}||_{*} \leq ||g||_{L^q} $ and we can find $f_{0} \in L^p \,$ s.t. $ |L_{g}f_{0}| = ||g||_{L^q} $ So $ ||Tg||_*  = ||L_{g}||_{*} = ||g||_{L^q} $ and we have an isometry. Moreover, if $p \in (1,\infty)$ , $T$ is surjective and thus it is an isomorphism. This is also the case for $p=1$ if $\mu$ is $\sigma$ -finite. I 'm trying to understand if $L^\infty$ is isometric to $(L^1)^*$ even if $\mu$ is not $\sigma$ -finite. Clearly: $ ||L_{g}||_{*} \leq ||g||_{L^\infty} $ , I'm struggling in finding $f_{0} \in L^1 $ s.t. $ |L_{g}f_{0}| \geq ||g||_{L^\infty} $ , and I'm questioning if such $f_{0}$ even exists.","I know that for , is isometric to with , namely that the operator: is an isometry. Indeed: and we can find s.t. So and we have an isometry. Moreover, if , is surjective and thus it is an isomorphism. This is also the case for if is -finite. I 'm trying to understand if is isometric to even if is not -finite. Clearly: , I'm struggling in finding s.t. , and I'm questioning if such even exists.","p \in (1,\infty] \, L^q(\Omega,\mathcal{M},\mu) (L^p(\Omega,\mathcal{M},\mu))^* \frac{1}{p}+\frac{1}{q}=1  T:L^q \to (L^p)^*, \;\; T: g \mapsto L_{g}, \;\; L_{g}f = \int_{\Omega}{fg \:d\mu} \;\; \forall f\in L^p  ||L_{g}||_{*} \leq ||g||_{L^q}  f_{0} \in L^p \,  |L_{g}f_{0}| = ||g||_{L^q}   ||Tg||_*  = ||L_{g}||_{*} = ||g||_{L^q}  p \in (1,\infty) T p=1 \mu \sigma L^\infty (L^1)^* \mu \sigma  ||L_{g}||_{*} \leq ||g||_{L^\infty}  f_{0} \in L^1   |L_{g}f_{0}| \geq ||g||_{L^\infty}  f_{0}","['functional-analysis', 'operator-theory', 'lp-spaces', 'isometry', 'dual-spaces']"
69,"Condensation of Singularities, Principle of Uniform Boundedness","Condensation of Singularities, Principle of Uniform Boundedness",,"Let $X$ , $Y$ be Banach spaces and $\{T_{j,k} : j,k \in\Bbb N\}$ be bounded linear maps from $X$ to $Y$ . Suppose that for each $k$ there exists $x\in X$ such that $\sup\{\lVert T_{j,k} x\rVert : j \in\Bbb N\} =+\infty$ . Then there is an $x$ such that $\sup\{\lVert T_{j,k} x\rVert : j \in\Bbb N\} =+ \infty$ for all $k$ . How can i argue by contradiction, and apply Baire categories theorem to $$ F_{k,n}=\bigcap_{j\in \mathbb{N}} \{x\in X , \lVert T_{j,k} (x)\rVert_Y \leq n\}  $$","Let , be Banach spaces and be bounded linear maps from to . Suppose that for each there exists such that . Then there is an such that for all . How can i argue by contradiction, and apply Baire categories theorem to","X Y \{T_{j,k} : j,k \in\Bbb N\} X Y k x\in X \sup\{\lVert T_{j,k} x\rVert : j \in\Bbb N\} =+\infty x \sup\{\lVert T_{j,k} x\rVert : j \in\Bbb N\} =+ \infty k  F_{k,n}=\bigcap_{j\in \mathbb{N}} \{x\in X , \lVert T_{j,k} (x)\rVert_Y \leq n\}  ","['functional-analysis', 'operator-theory', 'banach-spaces', 'normed-spaces', 'baire-category']"
70,"Orthogonal projections on $M$, $L$ and $M\cap L$ in Hilbert space","Orthogonal projections on ,  and  in Hilbert space",M L M\cap L,"I'm dealing with this functional analysis exercise: Let $H$ be a Hilbert space and $M,L$ are two closed subspaces of $H$ . $P_M$ is the orthogonal projection operator. Prove $P_MP_L=P_{M\cap L} \iff P_MP_L=P_LP_M$ . "" $\Longrightarrow$ "" part is easy: $P_LP_M=P_{L\cap M}=P_{M\cap L}=P_MP_L$ . But for the "" $\Longleftarrow$ "" part, denote $P=P_MP_L=P_LP_M$ . Then $Px=P_M(P_Lx)\in M$ and similarly in $L$ . Therefore $Px\in L\cap M$ . But how can I prove it is an orthogonal projection on $L\cap M$ ?","I'm dealing with this functional analysis exercise: Let be a Hilbert space and are two closed subspaces of . is the orthogonal projection operator. Prove . "" "" part is easy: . But for the "" "" part, denote . Then and similarly in . Therefore . But how can I prove it is an orthogonal projection on ?","H M,L H P_M P_MP_L=P_{M\cap L} \iff P_MP_L=P_LP_M \Longrightarrow P_LP_M=P_{L\cap M}=P_{M\cap L}=P_MP_L \Longleftarrow P=P_MP_L=P_LP_M Px=P_M(P_Lx)\in M L Px\in L\cap M L\cap M","['functional-analysis', 'hilbert-spaces']"
71,Stone's theorem and the spectral theorem,Stone's theorem and the spectral theorem,,"I am struggling to formally derive the expression found in the Stone's theorem for one-parameter unitary groups. I am aware that this can be done by using the spectral theorem. I am mostly interested in the discrete 'version' of the spectral theorem. Here's a short statement of Stone's theorem: If ${\cal H}$ is a Hilbert space and $U(t)$ is a strongly-continuous, one-parameter unitary group, then $U(t)=\exp\bigl(-itH\bigr)$ , where $H$ is self-adjoint. Can anyone help me out or point me to some reference where this is explicitly done?","I am struggling to formally derive the expression found in the Stone's theorem for one-parameter unitary groups. I am aware that this can be done by using the spectral theorem. I am mostly interested in the discrete 'version' of the spectral theorem. Here's a short statement of Stone's theorem: If is a Hilbert space and is a strongly-continuous, one-parameter unitary group, then , where is self-adjoint. Can anyone help me out or point me to some reference where this is explicitly done?",{\cal H} U(t) U(t)=\exp\bigl(-itH\bigr) H,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory', 'quantum-mechanics']"
72,On the Bourbaki Measures and Radon Measures,On the Bourbaki Measures and Radon Measures,,"The way that Bourbaki defined the measure is highly unusual: Let $C_{0}(\mathbb{R}^{n})$ be the space of all continuous functions with compact supports. A linear functional $I$ is said to be a measure if $I:C_{0}(\mathbb{R}^{n})\rightarrow{\mathbb{R}}$ is continuous with respect to the inductive topology for $C_{0}(\mathbb{R}^{n})$ : \begin{align*} |I(f)|\leq C_{K}\sup_{x\in K}|f(x)| \end{align*} for each compact set $K$ and $\text{supp}(f)\subseteq K$ , $C_{K}$ is a constant depending only on $K$ . Then the integral is simply defined by $I(f)$ , but Bourbaki used to write \begin{align*} \left<f,\mu\right>=\int fd\mu \end{align*} instead of $I$ . Folland suggests the name for Bourbaki measure as pseudo-measure, yet, he admits that there is no standard name for Bourbaki one. And he proves that \begin{align*} I(f)=\int fd\mu_{K} \end{align*} where $\mu_{K}$ is really the usual Radon measure that we are familiar in the sense that if the measures that we learned are from, say, Royden, Rudin references. Here $\mu_{K}$ corresponds to each $K$ , and $\mu_{K+1}|_{B(K)}=\mu_{K}$ , where $B(K)$ is the Borel subsets of $K$ . Nothing really said more about the features of the pseudo-measure by Folland. But I have ever seen some author claims that \begin{align*} I(f)=\int fd\mu \end{align*} for some Radon measure $\mu$ . Note that Folland does not show that there is a universal Radon measure to realize the pseudo-measure, instead, he shows that there is an ""exhaustion"" of Radon measures $\mu_{K}$ , each depends on the compact set $K$ , to have such a realization. Therefore I am doubt the author's claim that there is such a universal one. I am looking for counterexample. The best we can say is the following: Bourbaki proves that such an $I$ can have positive and negative parts: \begin{align*} I(f)=I^{+}(f)-I^{-}(f). \end{align*} And by usual Riesz Representation Theorem one has for some nonnegative measures $\mu_{1},\mu_{2}$ that \begin{align*} I^{+}(f)&=\int fd\mu_{1},\\ I^{-}(f)&=\int fd\mu_{2}, \end{align*} one may think of the candidate is simply $\mu=\mu_{1}-\mu_{2}$ . This may have some flaw. Recall that for a Radon measure $\mu$ one must have either for every $S$ , \begin{align*} \mu(S)\in(-\infty,\infty] \end{align*} or for every $S$ , \begin{align*} \mu(S)\in[-\infty,\infty) \end{align*} but not both. On the other hand, we cannot even be sure that $\mu_{1}-\mu_{2}$ is well-defined in the sense that $\infty-\infty$ could possibly occur. This is the reason that I think the universal Radon measure may not exist, or else, the genius Folland must have proved that, for what is the point to have less user friendly, that the exhaustion of measures?","The way that Bourbaki defined the measure is highly unusual: Let be the space of all continuous functions with compact supports. A linear functional is said to be a measure if is continuous with respect to the inductive topology for : for each compact set and , is a constant depending only on . Then the integral is simply defined by , but Bourbaki used to write instead of . Folland suggests the name for Bourbaki measure as pseudo-measure, yet, he admits that there is no standard name for Bourbaki one. And he proves that where is really the usual Radon measure that we are familiar in the sense that if the measures that we learned are from, say, Royden, Rudin references. Here corresponds to each , and , where is the Borel subsets of . Nothing really said more about the features of the pseudo-measure by Folland. But I have ever seen some author claims that for some Radon measure . Note that Folland does not show that there is a universal Radon measure to realize the pseudo-measure, instead, he shows that there is an ""exhaustion"" of Radon measures , each depends on the compact set , to have such a realization. Therefore I am doubt the author's claim that there is such a universal one. I am looking for counterexample. The best we can say is the following: Bourbaki proves that such an can have positive and negative parts: And by usual Riesz Representation Theorem one has for some nonnegative measures that one may think of the candidate is simply . This may have some flaw. Recall that for a Radon measure one must have either for every , or for every , but not both. On the other hand, we cannot even be sure that is well-defined in the sense that could possibly occur. This is the reason that I think the universal Radon measure may not exist, or else, the genius Folland must have proved that, for what is the point to have less user friendly, that the exhaustion of measures?","C_{0}(\mathbb{R}^{n}) I I:C_{0}(\mathbb{R}^{n})\rightarrow{\mathbb{R}} C_{0}(\mathbb{R}^{n}) \begin{align*}
|I(f)|\leq C_{K}\sup_{x\in K}|f(x)|
\end{align*} K \text{supp}(f)\subseteq K C_{K} K I(f) \begin{align*}
\left<f,\mu\right>=\int fd\mu
\end{align*} I \begin{align*}
I(f)=\int fd\mu_{K}
\end{align*} \mu_{K} \mu_{K} K \mu_{K+1}|_{B(K)}=\mu_{K} B(K) K \begin{align*}
I(f)=\int fd\mu
\end{align*} \mu \mu_{K} K I \begin{align*}
I(f)=I^{+}(f)-I^{-}(f).
\end{align*} \mu_{1},\mu_{2} \begin{align*}
I^{+}(f)&=\int fd\mu_{1},\\
I^{-}(f)&=\int fd\mu_{2},
\end{align*} \mu=\mu_{1}-\mu_{2} \mu S \begin{align*}
\mu(S)\in(-\infty,\infty]
\end{align*} S \begin{align*}
\mu(S)\in[-\infty,\infty)
\end{align*} \mu_{1}-\mu_{2} \infty-\infty","['real-analysis', 'functional-analysis', 'analysis', 'lebesgue-integral', 'lebesgue-measure']"
73,Prove that Solution of Integral Equation Is Solution of Differential Equation (Convection-Diffusion),Prove that Solution of Integral Equation Is Solution of Differential Equation (Convection-Diffusion),,"We are interested in the following initial-value problem for the Convection-Diffusion Equation: $\partial_t u(t,x) - \Delta u(t,x) = a\cdot\nabla u(t,x)^3 $ , for all $t \in (0,T)$ , $x \in \mathbb{R}^N$ $u(0,x) = u_0(x) \in L^1(\mathbb{R}^N) \cap L^\infty(\mathbb{R}^N) $ . Note this is similar to the Heat Equation, but we have replaced the usual $0$ on the right-hand side with the term $a\cdot\nabla u(t,x)^3$ , where $a \in \mathbb{R}^N $ is a constant. So far, we have successfully found a solution to the following integral equation: $u(t) = G(t) \ast u_0 + \int_{0}^{t} a\cdot \nabla G(t-s) \ast u(s)^3 \,ds$ , where $G(t,x) = \dfrac{1}{(4 \pi t)^{N/2}} \,\exp\left(\dfrac{-|x|^2}{4t}\right) $ is the Heat Kernel. $\ast$ denotes convolution over space: $\displaystyle (G(t) \ast u_0)(x) = \int_{\mathbb{R}^N} G(t, x-y)\,u_0(y) \,dy.$ We have shown that the solution to the above integral solution is unique in the set $C([0,T] ; L^1(\mathbb{R}^N) \cap L^\infty(\mathbb{R}^N) )$ for some sufficiently small $T > 0$ , and is bounded in the following sense: $\displaystyle\sup_{t\in [0,T]} \|u(t)\|_{L^1} + \|u(t)\|_{L^\infty} < R$ , for some constant $R > \|u_0\|_{L^1} + \|u_0\|_{L^\infty}$ . Finally, we have successfully shown some regularity results in this integral solution $u$ . We have shown that $ u \in C([0,T] ; L^1(\mathbb{R}^N) \cap L^\infty(\mathbb{R}^N) ) \cap C([0,T] ; W^{2,p}(\mathbb{R}^N) ) $ . Our claim is that this solution $u$ to the integral equation is also a solution to the differential equation. In order to prove this, we try to take the time-derivative of $u$ directly. Using the integral equation, we know that $\partial_t u(t) = \partial_t G(t) \ast u_0 + \partial_t \int^{t}_{0} a\cdot\nabla G(t-s) \ast u(s)^3 \,ds$ . Using the definition of the Heat Kernel, it's clear to see that $\partial_t G(t) \ast u_0 = \Delta_x G(t) \ast u_0$ . We are concerned with the second term $\partial_t \int^{t}_{0} a\cdot\nabla G(t-s) \ast u(s)^3 \,ds$ . First, using the property of convolution $f \ast g = g \ast f$ , we can move the gradient $\partial_t \int^{t}_{0} a\cdot\nabla G(t-s) \ast u(s)^3 \,ds = \partial_t \int^{t}_{0} G(t-s) \ast a\cdot\nabla u(s)^3 \,ds$ Next, we know the following property of the heat kernel $\displaystyle\lim_{t \rightarrow 0} \int_{\mathbb{R}^N} G(t,y) f(x-y) \,dy = \int_{\mathbb{R}^N} \delta(x) f(x-y) \,dy = f(x)$ . I have been told this is enough to say that: $ \displaystyle\partial_t \int^{t}_{0} G(t-s) \ast a\cdot\nabla u(s)^3 \,ds = a\cdot\nabla u(s)^3 + \int^{t}_{0} \partial_t G(t-s) \ast a\cdot\nabla u(s)^3 \,ds $ . I can't quite understand this last step. Could someone please explain it to me? Thank you very much.","We are interested in the following initial-value problem for the Convection-Diffusion Equation: , for all , . Note this is similar to the Heat Equation, but we have replaced the usual on the right-hand side with the term , where is a constant. So far, we have successfully found a solution to the following integral equation: , where is the Heat Kernel. denotes convolution over space: We have shown that the solution to the above integral solution is unique in the set for some sufficiently small , and is bounded in the following sense: , for some constant . Finally, we have successfully shown some regularity results in this integral solution . We have shown that . Our claim is that this solution to the integral equation is also a solution to the differential equation. In order to prove this, we try to take the time-derivative of directly. Using the integral equation, we know that . Using the definition of the Heat Kernel, it's clear to see that . We are concerned with the second term . First, using the property of convolution , we can move the gradient Next, we know the following property of the heat kernel . I have been told this is enough to say that: . I can't quite understand this last step. Could someone please explain it to me? Thank you very much.","\partial_t u(t,x) - \Delta u(t,x) = a\cdot\nabla u(t,x)^3  t \in (0,T) x \in \mathbb{R}^N u(0,x) = u_0(x) \in L^1(\mathbb{R}^N) \cap L^\infty(\mathbb{R}^N)  0 a\cdot\nabla u(t,x)^3 a \in \mathbb{R}^N  u(t) = G(t) \ast u_0 + \int_{0}^{t} a\cdot \nabla G(t-s) \ast u(s)^3 \,ds G(t,x) = \dfrac{1}{(4 \pi t)^{N/2}} \,\exp\left(\dfrac{-|x|^2}{4t}\right)  \ast \displaystyle (G(t) \ast u_0)(x) = \int_{\mathbb{R}^N} G(t, x-y)\,u_0(y) \,dy. C([0,T] ; L^1(\mathbb{R}^N) \cap L^\infty(\mathbb{R}^N) ) T > 0 \displaystyle\sup_{t\in [0,T]} \|u(t)\|_{L^1} + \|u(t)\|_{L^\infty} < R R > \|u_0\|_{L^1} + \|u_0\|_{L^\infty} u  u \in C([0,T] ; L^1(\mathbb{R}^N) \cap L^\infty(\mathbb{R}^N) ) \cap C([0,T] ; W^{2,p}(\mathbb{R}^N) )  u u \partial_t u(t) = \partial_t G(t) \ast u_0 + \partial_t \int^{t}_{0} a\cdot\nabla G(t-s) \ast u(s)^3 \,ds \partial_t G(t) \ast u_0 = \Delta_x G(t) \ast u_0 \partial_t \int^{t}_{0} a\cdot\nabla G(t-s) \ast u(s)^3 \,ds f \ast g = g \ast f \partial_t \int^{t}_{0} a\cdot\nabla G(t-s) \ast u(s)^3 \,ds = \partial_t \int^{t}_{0} G(t-s) \ast a\cdot\nabla u(s)^3 \,ds \displaystyle\lim_{t \rightarrow 0} \int_{\mathbb{R}^N} G(t,y) f(x-y) \,dy = \int_{\mathbb{R}^N} \delta(x) f(x-y) \,dy = f(x)  \displaystyle\partial_t \int^{t}_{0} G(t-s) \ast a\cdot\nabla u(s)^3 \,ds = a\cdot\nabla u(s)^3 + \int^{t}_{0} \partial_t G(t-s) \ast a\cdot\nabla u(s)^3 \,ds ","['real-analysis', 'integration', 'functional-analysis', 'ordinary-differential-equations', 'lp-spaces']"
74,Some basic questions about weak-metrizable subsets,Some basic questions about weak-metrizable subsets,,"Sorry to bother but I'm having some problems proving some properties in my way to prove some others weak and weak-* metrizability properties. First If I got a Banach space $X$ , wich its dual $X^{*}$ is separable. Then the closed unit ball of the dual is separable with respect to the norm of $X^{*}$ which is the usual. In this case, I think I have to find a dense and countable family which fulfills what we need Second Once we prove the above statement, lets suppose that the countable dense family we found is $\phi$ contained in the closed unit ball of the dual. Then if we define: $d(x,y)=\sum_{k=1}^{\infty} 2^{-k}|\phi_{k}(x-y)|$ for $x,y\in X$ Im having problems proving that is in fact a metric. In particular, I'm struggling with the implication $d(x,y)=0 \implies x=y$ . Thanks so much for your help!","Sorry to bother but I'm having some problems proving some properties in my way to prove some others weak and weak-* metrizability properties. First If I got a Banach space , wich its dual is separable. Then the closed unit ball of the dual is separable with respect to the norm of which is the usual. In this case, I think I have to find a dense and countable family which fulfills what we need Second Once we prove the above statement, lets suppose that the countable dense family we found is contained in the closed unit ball of the dual. Then if we define: for Im having problems proving that is in fact a metric. In particular, I'm struggling with the implication . Thanks so much for your help!","X X^{*} X^{*} \phi d(x,y)=\sum_{k=1}^{\infty} 2^{-k}|\phi_{k}(x-y)| x,y\in X d(x,y)=0 \implies x=y","['real-analysis', 'functional-analysis', 'weak-convergence']"
75,"A bounded, self-adjoint, positive operator $T$ induces a positive semidefinite quadratic form $\langle Tx,x\rangle$.","A bounded, self-adjoint, positive operator  induces a positive semidefinite quadratic form .","T \langle Tx,x\rangle","Let $H$ be a Hilbert space and $T\in \mathcal B(H)$ be a bounded, self-adjoint linear operator that is positive in the sense that $\sigma(T) \subset [0,\infty)$ . Is there an elementary method of proving that $T$ induces a positive semidefinite quadratic form, i.e. $$ \langle Tx,x\rangle \ge 0 $$ for all $x\in H$ ? The proof of this statement (and its converse) can be found in this post . However, while the converse can be proved by an elementary mean, the proof of the statement that I want relies on the spectral theorem for self-adjoint operators. I want to know if there is a more rudimentary way to do it (i.e. without using these high-tech theorems).","Let be a Hilbert space and be a bounded, self-adjoint linear operator that is positive in the sense that . Is there an elementary method of proving that induces a positive semidefinite quadratic form, i.e. for all ? The proof of this statement (and its converse) can be found in this post . However, while the converse can be proved by an elementary mean, the proof of the statement that I want relies on the spectral theorem for self-adjoint operators. I want to know if there is a more rudimentary way to do it (i.e. without using these high-tech theorems).","H T\in \mathcal B(H) \sigma(T) \subset [0,\infty) T 
\langle Tx,x\rangle \ge 0
 x\in H","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
76,Is equicontinuity independent of the chosen metric of the state space,Is equicontinuity independent of the chosen metric of the state space,,"There already exist several posts on similar questions, but I could not find any, which really gives a precise answer to my problem. Let $A \subseteq C([0,T],E)$ , where $E$ is a topological space and C $([0,T],E)$ denotes the set of all continuous functions from $[0,T]$ to $E$ . Assume I am given a metric on $E$ , let me call it $d$ , which induces the prescribed topology on $E$ . Then, equicontinuity of $A$ means $sup_{f \in A}d(f_{t_n},f_t) \to 0$ for each $t \in [0,T], (t_n)_{n \in \mathbb{N}}$ converging to $t$ . One usually does not find this as the definition of equicontinuity, but I think this is an equivalent way to express it, right? Now, suppose someone considers a topologically (i.e. ""weakly"") equivalent metric, $\rho$ , on $E$ . Is equicontinuity of $A$ invariant under switching between such equivalent metrics? Intuitively, this should be the case, but I would very much like to have clarification for it. Thanks in advance!","There already exist several posts on similar questions, but I could not find any, which really gives a precise answer to my problem. Let , where is a topological space and C denotes the set of all continuous functions from to . Assume I am given a metric on , let me call it , which induces the prescribed topology on . Then, equicontinuity of means for each converging to . One usually does not find this as the definition of equicontinuity, but I think this is an equivalent way to express it, right? Now, suppose someone considers a topologically (i.e. ""weakly"") equivalent metric, , on . Is equicontinuity of invariant under switching between such equivalent metrics? Intuitively, this should be the case, but I would very much like to have clarification for it. Thanks in advance!","A \subseteq C([0,T],E) E ([0,T],E) [0,T] E E d E A sup_{f \in A}d(f_{t_n},f_t) \to 0 t \in [0,T], (t_n)_{n \in \mathbb{N}} t \rho E A","['functional-analysis', 'analysis', 'metric-spaces', 'equicontinuity']"
77,Duality of Vector Spaces and Topological Vector Spaces,Duality of Vector Spaces and Topological Vector Spaces,,"Let $K$ be a field, and put $K \text{-vect}$ for the category of $K$ -vector spaces. There is an adjunction $[-, K]_{K \text{-vect}} : K \text{-vect}^{op} \leftrightarrow K \text{-vect} : [-, K]_{K \text{-vect}}$ where $[-, K]_{K \text{-vect}}$ sends a vector space $V$ to $[V, K ]_{K \text{-vect}}$ , the $K$ vector space of linear maps from $V$ to $K$ . Evidently, the vector space structure on $V^*$ alone is not enough to recover $V$ . I wonder, though, about putting a topology on it. For each $a \in V$ , there is a map $\hat{a} : V^* \rightarrow K$ sending $\phi$ to $\phi(a)$ . Give $V^*$ the weakest topology such that $\hat{a}$ is continuous for each $a \in V$ . Question: form $[V^*, K]_{K \text{-topvect}}$ , the vector space of continuous linear maps of topological vector spaces from $V^*$ to $K$ . Is this vector space isomorphic to $V$ ? If this turns out to be true, then we have a functor $F : K \text{-vect}^{op} \rightarrow K \text{-topvect}$ and a functor $G : K \text{-topvect} \rightarrow K \text{-vect}^{op}$ , such that $G \circ F \cong 1_{K \text{-vect}^{op}}$","Let be a field, and put for the category of -vector spaces. There is an adjunction where sends a vector space to , the vector space of linear maps from to . Evidently, the vector space structure on alone is not enough to recover . I wonder, though, about putting a topology on it. For each , there is a map sending to . Give the weakest topology such that is continuous for each . Question: form , the vector space of continuous linear maps of topological vector spaces from to . Is this vector space isomorphic to ? If this turns out to be true, then we have a functor and a functor , such that","K K \text{-vect} K [-, K]_{K \text{-vect}} : K \text{-vect}^{op} \leftrightarrow K \text{-vect} : [-, K]_{K \text{-vect}} [-, K]_{K \text{-vect}} V [V, K ]_{K \text{-vect}} K V K V^* V a \in V \hat{a} : V^* \rightarrow K \phi \phi(a) V^* \hat{a} a \in V [V^*, K]_{K \text{-topvect}} V^* K V F : K \text{-vect}^{op} \rightarrow K \text{-topvect} G : K \text{-topvect} \rightarrow K \text{-vect}^{op} G \circ F \cong 1_{K \text{-vect}^{op}}","['functional-analysis', 'vector-spaces']"
78,Is this spectrum-shifting operator well-defined?,Is this spectrum-shifting operator well-defined?,,"Consider a separable Hilbert space (over $\mathbb{C}$ ), and let $U(t)$ be a one-parameter group of unitary operators so that $$ 	U(t)=e^{iHt} \tag{1} $$ for some densely-defined operator $H$ as in Stone's theorem. Let $A$ be any bounded (everywhere-defined) operator on the Hilbert space, and define $$ 	A(t) = U(t)A U(-t). \tag{2} $$ For real numbers $\omega$ and $\epsilon$ with $\epsilon>0$ , I want to define $$ 	B :=  		\int_{-\infty}^\infty dt\  			 \exp(-i\omega t-\epsilon t^2) A(t). \tag{3} $$ Question: Is $B$ a well-defined operator on the Hilbert space? If not, is it at least densely defined? If the answer is ""it depends,"" then is there a simple necessary-and-sufficient condition on $A$ and $H$ such that $B$ is at least densely defined for all $\omega$ and all $\epsilon>0$ ? For whatever it's worth, here's the reason for the words ""spectrum-shifting"" in the title of the question: At least naively, equation (3) implies $HB=B(H+\omega)+O(\epsilon)$ . In physics jargon, if $H$ is the energy operator, then applying $B$ to an ""eigenstate"" of $H$ shifts its energy by $\omega$ , up to an arbitrarily small term of order $\epsilon$ . That's the motive, but I don't know when (3) is actually well-defined.","Consider a separable Hilbert space (over ), and let be a one-parameter group of unitary operators so that for some densely-defined operator as in Stone's theorem. Let be any bounded (everywhere-defined) operator on the Hilbert space, and define For real numbers and with , I want to define Question: Is a well-defined operator on the Hilbert space? If not, is it at least densely defined? If the answer is ""it depends,"" then is there a simple necessary-and-sufficient condition on and such that is at least densely defined for all and all ? For whatever it's worth, here's the reason for the words ""spectrum-shifting"" in the title of the question: At least naively, equation (3) implies . In physics jargon, if is the energy operator, then applying to an ""eigenstate"" of shifts its energy by , up to an arbitrarily small term of order . That's the motive, but I don't know when (3) is actually well-defined.","\mathbb{C} U(t) 
	U(t)=e^{iHt}
\tag{1}
 H A 
	A(t) = U(t)A U(-t).
\tag{2}
 \omega \epsilon \epsilon>0 
	B := 
		\int_{-\infty}^\infty dt\ 
			 \exp(-i\omega t-\epsilon t^2) A(t).
\tag{3}
 B A H B \omega \epsilon>0 HB=B(H+\omega)+O(\epsilon) H B H \omega \epsilon","['functional-analysis', 'hilbert-spaces', 'operator-algebras']"
79,Does a set of nested subspaces in a Hilbert space have a concise name?,Does a set of nested subspaces in a Hilbert space have a concise name?,,"Let ${\cal H}$ be a Hilbert space (separable, if it matters), and let $X$ be a set of closed subspaces with the property that for all ${\cal P},{\cal Q}\in X$ , we have either ${\cal P}\subset {\cal Q}$ or ${\cal Q}\subset {\cal P}$ . We can assume that $X$ includes the trivial subspaces ${\cal H}$ and $\varnothing$ if that makes a difference. The set $X$ of closed subspaces is not necessarily countable. Does such an $X$ have a concise name? I'm not a mathematician. I tried searching for keywords like ""sequence of subspaces"", ""nested subspaces"", and ""filter"" (just guessing), but I didn't recognize anything relevant. I also tried looking in the context of ""resolution of the identity,"" which I suppose is what $X$ would be called if it were described in terms of projection operators instead of subspaces, but I didn't find any clear statements about whether or not that name still applies when $X$ is described in terms of closed subspaces.","Let be a Hilbert space (separable, if it matters), and let be a set of closed subspaces with the property that for all , we have either or . We can assume that includes the trivial subspaces and if that makes a difference. The set of closed subspaces is not necessarily countable. Does such an have a concise name? I'm not a mathematician. I tried searching for keywords like ""sequence of subspaces"", ""nested subspaces"", and ""filter"" (just guessing), but I didn't recognize anything relevant. I also tried looking in the context of ""resolution of the identity,"" which I suppose is what would be called if it were described in terms of projection operators instead of subspaces, but I didn't find any clear statements about whether or not that name still applies when is described in terms of closed subspaces.","{\cal H} X {\cal P},{\cal Q}\in X {\cal P}\subset {\cal Q} {\cal Q}\subset {\cal P} X {\cal H} \varnothing X X X X","['functional-analysis', 'terminology', 'hilbert-spaces']"
80,Compactness when mapping into a higher $L^p$ space and then back,Compactness when mapping into a higher  space and then back,L^p,"Question: Let $q>p \ge 1$ and let $T:L^p[0,1] \to L^q[0,1]$ be a bounded linear operator. Let $i: L^q[0,1] \to L^p[0,1]$ be the inclusion map (which is bounded). Is the composition $i\circ T$ necessarily a compact operator on $L^p$ ? We can assume $p\in (1,\infty)$ if the uniform convexity of the underlying space helps in some way, though the boundary cases might be interesting themselves. Context: This was inspired by this question , where the accepted answer covers the case $q=\infty$ (in that case the composition is indeed always compact). I've been at it for a couple days trying to prove and also to disprove it. It might be trivial with a silly oversight on my part (because I don't know too many explicit examples of bounded operators from $L_p \to L_q$ ), but on the other hand it could be inherently nontrivial as well, and I was hoping to learn some new funfact about the geometry of Banach spaces in case of the latter. Ideas: To prove that it is compact, here are a couple of ideas that I played around with. One suggestion is to somehow translate the problem to a statement about $\ell^p$ spaces and then apply Pitt's theorem . Unfortunately there seems to be no clear way to do this, for example any attempt at using a Fourier transform (which boundedly sends $L^p \to \ell^{\frac{p}{p-1}}$ and $\ell^p \to L^{\frac{p}{p-1}}$ for $1< p < 2$ ) will somehow ""go the wrong way."" A second idea is to try to find a Banach space $X$ which has the Dunford-Pettis property (e.g. a $L^1(\mu)$ or $C(K)$ space) and which nests in between $L^p$ and $L^q$ , i.e., $L^q \subset X \subset L^p$ . This would easily show compactness of $i\circ T$ , but finding such $X$ seems not too easy. A third idea is to try to mimic the proof of Pitt's theorem adapted to this $L^p$ context. Basically suppose $i\circ T$ was not compact. Then we can find $f_n \in L^p$ with $\|f_n\|_p=1$ and $f_n \to 0$ weakly, and also $\|Tf_n\|_p \ge \delta>0$ . Then (after perhaps passing to a subsequence) one may try to show that $T$ is bounded below on the closed linear span of the $f_n$ , which would imply that the image of $T$ contains a closed infinite-dimensional subspace of $L^p$ . And I'm farily certain that such a subspace cannot be contained in $L^q$ (never mind: this turns out to be false, see answer below). But formalizing these ideas might take some work. A fourth idea is to try to use type-cotype considerations which I don't know much about, but have been powerful in the context of classifying $L_p$ spaces up to isomorphism. On the other hand, here are some ideas for potential counterexamples if it turns out to be false. For one idea let us identify $L^p[0,1] \simeq L^p(\Bbb R)$ and consider the Fourier transform $\mathcal F:L^p(\Bbb R) \to L^{\frac{p}{p-1}}(\Bbb R)$ , where $p<2$ . I've shown that $\mathcal F$ is not a compact operator. Hence there is at least a noncompact operator from $L^p[0,1] \to L^{\frac{p}{p-1}}[0,1]$ for $p<2$ (which brings up another question of what if we restrict attention to $q>p^*$ , then can we say that $T$ itself is compact?... but perhaps that's for another day). However, the difficult thing is to show that it remains noncompact when we compose it with the inclusion map, and I think that it actually becomes false. I played around with the Hermite functions $\psi_n$ which orthonormally diagonalize $\mathcal F$ on $L^2(\Bbb R)$ , and I was able to compute that $\|\psi_n\|_{L^p(\Bbb R)} \sim_n C_p n^{\frac1{3p}-\frac16}$ , so while these converge weakly to $0$ in $L^2(\Bbb R)$ they fail to do so in $L^p(\Bbb R)$ for $p<2$ , hence they are useless for us. A second idea is to use some of the abstract mappings mentioned in this MO thread and the subsequent comments . Actually this might all be trivial from some proposition in Albiac-Kalton but I can't access the book at the moment.","Question: Let and let be a bounded linear operator. Let be the inclusion map (which is bounded). Is the composition necessarily a compact operator on ? We can assume if the uniform convexity of the underlying space helps in some way, though the boundary cases might be interesting themselves. Context: This was inspired by this question , where the accepted answer covers the case (in that case the composition is indeed always compact). I've been at it for a couple days trying to prove and also to disprove it. It might be trivial with a silly oversight on my part (because I don't know too many explicit examples of bounded operators from ), but on the other hand it could be inherently nontrivial as well, and I was hoping to learn some new funfact about the geometry of Banach spaces in case of the latter. Ideas: To prove that it is compact, here are a couple of ideas that I played around with. One suggestion is to somehow translate the problem to a statement about spaces and then apply Pitt's theorem . Unfortunately there seems to be no clear way to do this, for example any attempt at using a Fourier transform (which boundedly sends and for ) will somehow ""go the wrong way."" A second idea is to try to find a Banach space which has the Dunford-Pettis property (e.g. a or space) and which nests in between and , i.e., . This would easily show compactness of , but finding such seems not too easy. A third idea is to try to mimic the proof of Pitt's theorem adapted to this context. Basically suppose was not compact. Then we can find with and weakly, and also . Then (after perhaps passing to a subsequence) one may try to show that is bounded below on the closed linear span of the , which would imply that the image of contains a closed infinite-dimensional subspace of . And I'm farily certain that such a subspace cannot be contained in (never mind: this turns out to be false, see answer below). But formalizing these ideas might take some work. A fourth idea is to try to use type-cotype considerations which I don't know much about, but have been powerful in the context of classifying spaces up to isomorphism. On the other hand, here are some ideas for potential counterexamples if it turns out to be false. For one idea let us identify and consider the Fourier transform , where . I've shown that is not a compact operator. Hence there is at least a noncompact operator from for (which brings up another question of what if we restrict attention to , then can we say that itself is compact?... but perhaps that's for another day). However, the difficult thing is to show that it remains noncompact when we compose it with the inclusion map, and I think that it actually becomes false. I played around with the Hermite functions which orthonormally diagonalize on , and I was able to compute that , so while these converge weakly to in they fail to do so in for , hence they are useless for us. A second idea is to use some of the abstract mappings mentioned in this MO thread and the subsequent comments . Actually this might all be trivial from some proposition in Albiac-Kalton but I can't access the book at the moment.","q>p \ge 1 T:L^p[0,1] \to L^q[0,1] i: L^q[0,1] \to L^p[0,1] i\circ T L^p p\in (1,\infty) q=\infty L_p \to L_q \ell^p L^p \to \ell^{\frac{p}{p-1}} \ell^p \to L^{\frac{p}{p-1}} 1< p < 2 X L^1(\mu) C(K) L^p L^q L^q \subset X \subset L^p i\circ T X L^p i\circ T f_n \in L^p \|f_n\|_p=1 f_n \to 0 \|Tf_n\|_p \ge \delta>0 T f_n T L^p L^q L_p L^p[0,1] \simeq L^p(\Bbb R) \mathcal F:L^p(\Bbb R) \to L^{\frac{p}{p-1}}(\Bbb R) p<2 \mathcal F L^p[0,1] \to L^{\frac{p}{p-1}}[0,1] p<2 q>p^* T \psi_n \mathcal F L^2(\Bbb R) \|\psi_n\|_{L^p(\Bbb R)} \sim_n C_p n^{\frac1{3p}-\frac16} 0 L^2(\Bbb R) L^p(\Bbb R) p<2","['real-analysis', 'functional-analysis', 'fourier-analysis', 'banach-spaces', 'lp-spaces']"
81,If $f_n \to f$ in $L^p$ and $g_n \xrightarrow{a.e.} g$ in $L^\infty$ then $f_ng_n \to fg$ in $L^p$,If  in  and  in  then  in,f_n \to f L^p g_n \xrightarrow{a.e.} g L^\infty f_ng_n \to fg L^p,"Exercise : Let $\Omega \subseteq \mathbb R^n$ be open and bounded, $\{f_n\}_{n \geq 1} \subseteq L^p(\Omega)$ with $1<p< \infty$ and $\{g_n\}_{n \geq 1} \subseteq L^\infty(\Omega)$ . If it is $f_n \to f$ in $L^p(\Omega)$ and $g_n \xrightarrow{a.e.} g$ in $L^\infty(\Omega)$ while $\{g_n\}_{n \geq 1}$ is also bounded then show $f_ng_n \to fg$ in $L^p(\Omega)$ . Attempt : Since $\{g_n\}_{n \geq 1}$ is bounded, then it would be $\|g_n\|_\infty \leq M$ for some $M>0$ and thus for the $p$ -norm it would be $\|g_n\|_p \leq M$ as well. Now, it is : \begin{align*} \|fg - f_ng_n\|_p &= \|fg - fg_n + fg_n - f_ng_n\|_p \\ &\leq \|fg-fg_n\|_p + \|g_n(f-f_n)\|_p \\ &\leq \|fg-fg_n\|_p + M\|f-f_n\|_p  \end{align*} The second term goes to $0$ as $f_n \to f$ in $L^p(\Omega)$ . Now, since $g_n \xrightarrow{a.e.} g$ we can also deduce that $\|g_n\|_\infty \xrightarrow{a.e.} \|g\|_\infty$ . For the first term : \begin{align*} \|fg-fg_n\|_p &= \left(\int_\Omega|fg-fg_n|^p\mathrm{d}x \right)^{1/p} \\ &\leq \left[ \int_\Omega \left(|fg| + |fg_n|\right)^p\mathrm{d}x\right]^{1/p} \\ &\leq \left[ \int_\Omega \left(|fg| + M|f|\right)^p\mathrm{d}x\right]^{1/p} \end{align*} I can't see how to continue on though to prove that this term can become arbitrarily small, thus that $\|fg-f_ng_n\|_p \to 0$ and thus the desired convergence. Any hints or elaborations will be greatly appreciated ! Edit : I worked it around myself as such : \begin{align*} \|f(g_n-g)\|_p &= \left(\int_\Omega |(g_n-g)f|^p\mathrm{d}x\right)^{1/p} \\ &\leq \left(\int_\Omega ||g_n-g\|_\infty^p|f|^p\mathrm{d}x\right)^p \\ &= \|g_n-g\|_\infty\left(\int_\Omega |f|^p\mathrm{d}x \right)^p \to 0 \end{align*} So finally we get $\|fg-f_ng_n\|_p \to 0 \Leftrightarrow f_ng_n \to fg$ στον $L^p(\Omega)$ .","Exercise : Let be open and bounded, with and . If it is in and in while is also bounded then show in . Attempt : Since is bounded, then it would be for some and thus for the -norm it would be as well. Now, it is : The second term goes to as in . Now, since we can also deduce that . For the first term : I can't see how to continue on though to prove that this term can become arbitrarily small, thus that and thus the desired convergence. Any hints or elaborations will be greatly appreciated ! Edit : I worked it around myself as such : So finally we get στον .","\Omega \subseteq \mathbb R^n \{f_n\}_{n \geq 1} \subseteq L^p(\Omega) 1<p< \infty \{g_n\}_{n \geq 1} \subseteq L^\infty(\Omega) f_n \to f L^p(\Omega) g_n \xrightarrow{a.e.} g L^\infty(\Omega) \{g_n\}_{n \geq 1} f_ng_n \to fg L^p(\Omega) \{g_n\}_{n \geq 1} \|g_n\|_\infty \leq M M>0 p \|g_n\|_p \leq M \begin{align*}
\|fg - f_ng_n\|_p &= \|fg - fg_n + fg_n - f_ng_n\|_p \\ &\leq \|fg-fg_n\|_p + \|g_n(f-f_n)\|_p \\ &\leq \|fg-fg_n\|_p + M\|f-f_n\|_p 
\end{align*} 0 f_n \to f L^p(\Omega) g_n \xrightarrow{a.e.} g \|g_n\|_\infty \xrightarrow{a.e.} \|g\|_\infty \begin{align*}
\|fg-fg_n\|_p &= \left(\int_\Omega|fg-fg_n|^p\mathrm{d}x \right)^{1/p} \\ &\leq \left[ \int_\Omega \left(|fg| + |fg_n|\right)^p\mathrm{d}x\right]^{1/p} \\ &\leq \left[ \int_\Omega \left(|fg| + M|f|\right)^p\mathrm{d}x\right]^{1/p}
\end{align*} \|fg-f_ng_n\|_p \to 0 \begin{align*}
\|f(g_n-g)\|_p &= \left(\int_\Omega |(g_n-g)f|^p\mathrm{d}x\right)^{1/p} \\ &\leq \left(\int_\Omega ||g_n-g\|_\infty^p|f|^p\mathrm{d}x\right)^p \\ &= \|g_n-g\|_\infty\left(\int_\Omega |f|^p\mathrm{d}x \right)^p \to 0
\end{align*} \|fg-f_ng_n\|_p \to 0 \Leftrightarrow f_ng_n \to fg L^p(\Omega)","['functional-analysis', 'measure-theory', 'convergence-divergence', 'lebesgue-integral', 'lebesgue-measure']"
82,Showing that $0\leq A\leq B$ and $B \in \mathcal{L}_c(H)$ implies that $A \in \mathcal{L}_c(H)$.,Showing that  and  implies that .,0\leq A\leq B B \in \mathcal{L}_c(H) A \in \mathcal{L}_c(H),"Exercise : Let $H$ be a Hilbert space and $A,B \in \mathcal{L}(H)$ be self-adjoint operators with $0 \leq A \leq B$ and $B \in \mathcal{L}_c(H)$ . Show that $A \in \mathcal{L}_c(H)$ . Thoughts : Relying only on the definition of a compact operator, we essentialy need to conclude that $A$ transfers bounded sets to relatively compact sets (compact closure). Now, since $B$ is compact and self adjoint, I know that also $B^*B$ is compact. This may be of use since the property of $A$ and $B$ being self adjoint is noted in the exercise. I think that $A \leq B \implies \|A\| \leq \|B\|$ since they are both bounded  and we could take $\mathbf{1} \in H$ which yields that $$\|A(\mathbf{1})\| \leq \|A\|\|1\| \equiv \|A\| \quad \text{and} \quad \|B(\mathbf{1})\| \leq \|B\|\|1\| \equiv \|B\|$$ and since $0 \leq A \leq B$ implies that their values follow the inequality for any $x \in H$ thus the implied result. Request : Beyond these points, I sadly do not have an intuition for a head-start, so I would really appreciate any hints or elaborations.","Exercise : Let be a Hilbert space and be self-adjoint operators with and . Show that . Thoughts : Relying only on the definition of a compact operator, we essentialy need to conclude that transfers bounded sets to relatively compact sets (compact closure). Now, since is compact and self adjoint, I know that also is compact. This may be of use since the property of and being self adjoint is noted in the exercise. I think that since they are both bounded  and we could take which yields that and since implies that their values follow the inequality for any thus the implied result. Request : Beyond these points, I sadly do not have an intuition for a head-start, so I would really appreciate any hints or elaborations.","H A,B \in \mathcal{L}(H) 0 \leq A \leq B B \in \mathcal{L}_c(H) A \in \mathcal{L}_c(H) A B B^*B A B A \leq B \implies \|A\| \leq \|B\| \mathbf{1} \in H \|A(\mathbf{1})\| \leq \|A\|\|1\| \equiv \|A\| \quad \text{and} \quad \|B(\mathbf{1})\| \leq \|B\|\|1\| \equiv \|B\| 0 \leq A \leq B x \in H","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'compact-operators']"
83,Are there trilinear inner products?,Are there trilinear inner products?,,"Is there such a thing as a ""trilinear inner product""? The definition of an inner product is: Let $H$ be a vector space over $\mathbb{K}\in \{\mathbb{R,C}\}$ . An inner product is a map $\langle \cdot|\cdot\rangle: H^2 \to \mathbb{K}$ such that for all $x,y,z \in H$ and $\lambda \in \mathbb{K}$ the following properties hold: Bilinearity: $\langle x+\lambda y | z\rangle = \langle x|z\rangle + \lambda \langle y|z\rangle $ Complex conjugacy: $\overline{\langle y | x \rangle} = \langle x | y \rangle$ Positive definiteness: $||x||^2:=\langle x | x \rangle$ > 0 if $x \neq 0$ Can this be modified to have a trilinear map $\langle \cdot |\cdot| \cdot \rangle : H^3 \to \mathbb{K}$ ? Would it for example be possible to make $L^3$ into a ""trilinear inner product space"" like $L^2$ is a ""bilinear inner product space""? What is so special about the number $2$ in this context? Of course $2$ is the only number that is conjugate to itself in the sense that $\frac{1}{2}+\frac{1}{2}$ , so there would be no nice identification of this trilinear inner product space with its dual. I guess that there is no useful notion because the complex conjugacy can't be modified to get a trilinear inner product: $\mathbb{C}$ is a field extension of degree $2$ of $\mathbb{R}$ , but there is no field extension of degree $3$ of the reals this inner product could be defined over. What if the ""trilinear space"" is solely defined over $\mathbb{R}$ ?","Is there such a thing as a ""trilinear inner product""? The definition of an inner product is: Let be a vector space over . An inner product is a map such that for all and the following properties hold: Bilinearity: Complex conjugacy: Positive definiteness: > 0 if Can this be modified to have a trilinear map ? Would it for example be possible to make into a ""trilinear inner product space"" like is a ""bilinear inner product space""? What is so special about the number in this context? Of course is the only number that is conjugate to itself in the sense that , so there would be no nice identification of this trilinear inner product space with its dual. I guess that there is no useful notion because the complex conjugacy can't be modified to get a trilinear inner product: is a field extension of degree of , but there is no field extension of degree of the reals this inner product could be defined over. What if the ""trilinear space"" is solely defined over ?","H \mathbb{K}\in \{\mathbb{R,C}\} \langle \cdot|\cdot\rangle: H^2 \to \mathbb{K} x,y,z \in H \lambda \in \mathbb{K} \langle x+\lambda y | z\rangle = \langle x|z\rangle + \lambda \langle y|z\rangle  \overline{\langle y | x \rangle} = \langle x | y \rangle ||x||^2:=\langle x | x \rangle x \neq 0 \langle \cdot |\cdot| \cdot \rangle : H^3 \to \mathbb{K} L^3 L^2 2 2 \frac{1}{2}+\frac{1}{2} \mathbb{C} 2 \mathbb{R} 3 \mathbb{R}","['linear-algebra', 'functional-analysis', 'inner-products', 'multilinear-algebra']"
84,Wiener's tauberian theorem for Hardy space,Wiener's tauberian theorem for Hardy space,,"For $a>0$ let us define $$H^2(-a,a)=\{f \ \mbox{is analytic in the strip $|\Im(z)|<a$}: \sup_{y\in [-a,a]}\int_{\mathbb{R}}|f(x+iy)|^2\,dx<\infty\}.$$ For $f\in H^2(-a,a)$ , define $\|f\|=\sup_{y\in (-a,a)}\int_{\mathbb{R}}|f(x+iy)|^2\,dx<\infty$ . We note that the function $e^{-z^2}\in H^2(-a,a)$ for any $a>0$ . Can we have that $\operatorname{span}(\{e^{-(z-b)^2}: \ b\in\mathbb{R}\})$ is dense in $H^2(-a,a)$ with respect to the norm $\|\cdot\|$ ?","For let us define For , define . We note that the function for any . Can we have that is dense in with respect to the norm ?","a>0 H^2(-a,a)=\{f \ \mbox{is analytic in the strip |\Im(z)|<a}: \sup_{y\in [-a,a]}\int_{\mathbb{R}}|f(x+iy)|^2\,dx<\infty\}. f\in H^2(-a,a) \|f\|=\sup_{y\in (-a,a)}\int_{\mathbb{R}}|f(x+iy)|^2\,dx<\infty e^{-z^2}\in H^2(-a,a) a>0 \operatorname{span}(\{e^{-(z-b)^2}: \ b\in\mathbb{R}\}) H^2(-a,a) \|\cdot\|","['complex-analysis', 'functional-analysis', 'fourier-analysis', 'hardy-spaces', 'wieners-tauberian-theorem']"
85,Proving Ito Isometry using Functional Analysis,Proving Ito Isometry using Functional Analysis,,"I would like to know whether it is possible to give a proof of Ito Isometry using a tool which I like to call ""the functional analysis""-way. Let me explain the settings first. What we did is the following. Let $(\Omega,\mathcal F,(\mathcal F_t)_{t\geq 0},\mathbb P)$ be a filtered probability space. We defined a space \begin{align} \mathcal M:=\{ M=(M)_{t\geq 0}\ | \ M \text{ is } \mathcal F_t\text{-martingale with continuous paths},\ M_0=0, M \text{ is bounded in } L^2(\mathbb P)\}  \end{align} We said for all $M\in\mathcal M$ we have the existence of $M_\infty^2$ and $\langle M\rangle_\infty$ , where $\langle \cdot\rangle $ is the quadratic variation process. Now we may define an innerproduct on $\mathcal M$ as follows: \begin{align} (M,N):=\mathbb E[\langle M,N\rangle_\infty] \end{align} The space $\mathcal M$ with the given innnerproduct is a Hilbert space. We say $H\in L^2(M)$ iff $H$ is progressively measurable and \begin{align} \|H\|_{L^2(M)}^2:=\mathbb E\left[ \int^\infty_0 H_s^2\,d\langle M\rangle_s\right]<\infty \end{align} Let us fix $H\in L^2(M)$ and define a functional $f_H$ on $\mathcal M$ as follows \begin{align} f_H(N)=\mathbb E\left[\int^\infty_0 H_s\,d\langle M,N\rangle_s \right] \end{align} Using Kunita Watanabe we can get \begin{align} |f_H(N)|\leq \|H\|_{L^2(M)}\|N\|_{\mathcal M} \end{align} We can use Riesz to get an element which we will call $H\bullet M\in\mathcal M$ the integral of $H$ with respect to $M$ , and \begin{align} f_H(N)=(H\bullet M, N) \end{align} but more importantly is that we also get for free that the operator norm of $f_H$ satisfies $\|f_H\|=\|H\bullet M\|_{\mathcal M}$ . Problem. Prove that $\|H\|_{L^2(M)}=\|H\bullet M\|_{\mathcal M}$ . I can prove this using properties of $H\bullet M$ and Lebesgue-Stieltjes integral. But I want to prove it using $\|f_H\|=\|H\|_{L^2(M)}$ . Question. How to prove that $\|f_H\|=\|H\|_{L^2(M)}$ not knowing about the integral $H\bullet M$ and everything related to that? I mean only by looking at the functional $f$ itself. I already have the inequality $\|f_H\|\leq \|H\|_{L^2(M)}$ . So we either need to find $N$ for which $|f_H(N)|=\|H\|_{L^2(M)}\|N\|_{\mathcal M}$ or a sequence of $X^{(n)}$ for which $\|X^{(n)}\|_{\mathcal M}=1$ and \begin{align} |f_H(X^{(n)})|\to \|H\|_{L^2(M)} \end{align} I want to do this because I believe that it may increase my knowledge about elements of $\mathcal M$ and dealing with such operators on that space. The answer that I'm seeking is from the following perspective. Consider yourself as someone who never saw ito integral and just knows the space $\mathcal M$ and $L^2(M)$ and the functional $f_H$ . How would you then find the norm of $f_H$ ? Edit. I would be also satisfied if someone provides a solution for a possible simple case where $M$ is a (nicely, but not too trivial) stopped Brownian motion, for example $B_{t\wedge 1}$ or so.","I would like to know whether it is possible to give a proof of Ito Isometry using a tool which I like to call ""the functional analysis""-way. Let me explain the settings first. What we did is the following. Let be a filtered probability space. We defined a space We said for all we have the existence of and , where is the quadratic variation process. Now we may define an innerproduct on as follows: The space with the given innnerproduct is a Hilbert space. We say iff is progressively measurable and Let us fix and define a functional on as follows Using Kunita Watanabe we can get We can use Riesz to get an element which we will call the integral of with respect to , and but more importantly is that we also get for free that the operator norm of satisfies . Problem. Prove that . I can prove this using properties of and Lebesgue-Stieltjes integral. But I want to prove it using . Question. How to prove that not knowing about the integral and everything related to that? I mean only by looking at the functional itself. I already have the inequality . So we either need to find for which or a sequence of for which and I want to do this because I believe that it may increase my knowledge about elements of and dealing with such operators on that space. The answer that I'm seeking is from the following perspective. Consider yourself as someone who never saw ito integral and just knows the space and and the functional . How would you then find the norm of ? Edit. I would be also satisfied if someone provides a solution for a possible simple case where is a (nicely, but not too trivial) stopped Brownian motion, for example or so.","(\Omega,\mathcal F,(\mathcal F_t)_{t\geq 0},\mathbb P) \begin{align}
\mathcal M:=\{ M=(M)_{t\geq 0}\ | \ M \text{ is } \mathcal F_t\text{-martingale with continuous paths},\ M_0=0, M \text{ is bounded in } L^2(\mathbb P)\} 
\end{align} M\in\mathcal M M_\infty^2 \langle M\rangle_\infty \langle \cdot\rangle  \mathcal M \begin{align}
(M,N):=\mathbb E[\langle M,N\rangle_\infty]
\end{align} \mathcal M H\in L^2(M) H \begin{align}
\|H\|_{L^2(M)}^2:=\mathbb E\left[ \int^\infty_0 H_s^2\,d\langle M\rangle_s\right]<\infty
\end{align} H\in L^2(M) f_H \mathcal M \begin{align}
f_H(N)=\mathbb E\left[\int^\infty_0 H_s\,d\langle M,N\rangle_s \right]
\end{align} \begin{align}
|f_H(N)|\leq \|H\|_{L^2(M)}\|N\|_{\mathcal M}
\end{align} H\bullet M\in\mathcal M H M \begin{align}
f_H(N)=(H\bullet M, N)
\end{align} f_H \|f_H\|=\|H\bullet M\|_{\mathcal M} \|H\|_{L^2(M)}=\|H\bullet M\|_{\mathcal M} H\bullet M \|f_H\|=\|H\|_{L^2(M)} \|f_H\|=\|H\|_{L^2(M)} H\bullet M f \|f_H\|\leq \|H\|_{L^2(M)} N |f_H(N)|=\|H\|_{L^2(M)}\|N\|_{\mathcal M} X^{(n)} \|X^{(n)}\|_{\mathcal M}=1 \begin{align}
|f_H(X^{(n)})|\to \|H\|_{L^2(M)}
\end{align} \mathcal M \mathcal M L^2(M) f_H f_H M B_{t\wedge 1}","['functional-analysis', 'stochastic-calculus', 'martingales', 'stochastic-integrals', 'stochastic-analysis']"
86,Family of (Semi)norms?,Family of (Semi)norms?,,"Let $\mathcal{D}_K(\Omega)$ denote the smooth functions with compact support, $\mathrm{supp}(u) \subset K \subset \Omega \subset \mathbb{R}^n$ with $K$ compact. When studying this space, many texts provide a family of seminorms, given by: $$ \|\phi\|_{K,j} = \max_{|\alpha| \leq j}\max_{x\in K} \left|\frac{\partial^{\alpha}\phi}{\partial x^\alpha}\right| $$ My question is, why are these seminorms instead of proper norms? If we have $\|\phi\|_{K,j} = 0$ , is it not then the case that for $\alpha$ with $|\alpha| = 0$ (i.e $\alpha = 0$ so that we may consider the function itself) that: $$ \max_{x\in K}\left|\frac{\partial^0\phi}{\partial x^0}\right| = \|\phi\|_\infty = 0 $$ which only happens if $\phi$ is identically $0$ . Am I missing something here?","Let denote the smooth functions with compact support, with compact. When studying this space, many texts provide a family of seminorms, given by: My question is, why are these seminorms instead of proper norms? If we have , is it not then the case that for with (i.e so that we may consider the function itself) that: which only happens if is identically . Am I missing something here?","\mathcal{D}_K(\Omega) \mathrm{supp}(u) \subset K \subset \Omega \subset \mathbb{R}^n K 
\|\phi\|_{K,j} = \max_{|\alpha| \leq j}\max_{x\in K} \left|\frac{\partial^{\alpha}\phi}{\partial x^\alpha}\right|
 \|\phi\|_{K,j} = 0 \alpha |\alpha| = 0 \alpha = 0 
\max_{x\in K}\left|\frac{\partial^0\phi}{\partial x^0}\right| = \|\phi\|_\infty = 0
 \phi 0","['functional-analysis', 'distribution-theory']"
87,Is the identity functor naturally isomorphic to a covariant dual functor?,Is the identity functor naturally isomorphic to a covariant dual functor?,,"It is often said that vector spaces are not naturally isomorphic to dual spaces, because the dual functor is not naturally isomorphic to the identity functor.  But the latter is a rather trivial statement, because you can’t have a natural transformation between a contravariant functor and a covariant functor.  So I’d like to see if it it can be modified into something less trivial. Let $VectIso$ be the category with vector spaces as objects and bijective linear transformations as morphisms.  Let $D:VectIso\rightarrow VectIso$ be a covariant functor defined by $D(V)=V^*$ for any vector space $V$ and $D(T)(f)=f\circ T^{-1}$ for any bijective linear transformation $T:V\rightarrow W$ and any linear functional $f\in V^*$ . Then my question is, is $D$ naturally isomorphic to the identity functor?  I assume the answer is no, but how would you prove it?","It is often said that vector spaces are not naturally isomorphic to dual spaces, because the dual functor is not naturally isomorphic to the identity functor.  But the latter is a rather trivial statement, because you can’t have a natural transformation between a contravariant functor and a covariant functor.  So I’d like to see if it it can be modified into something less trivial. Let be the category with vector spaces as objects and bijective linear transformations as morphisms.  Let be a covariant functor defined by for any vector space and for any bijective linear transformation and any linear functional . Then my question is, is naturally isomorphic to the identity functor?  I assume the answer is no, but how would you prove it?",VectIso D:VectIso\rightarrow VectIso D(V)=V^* V D(T)(f)=f\circ T^{-1} T:V\rightarrow W f\in V^* D,"['functional-analysis', 'category-theory', 'dual-spaces', 'functors', 'natural-transformations']"
88,Weak-$*$ topology on algebraic dual,Weak- topology on algebraic dual,*,"I was looking at Izzo, Alexander J. , A functional analysis proof of the existence of Haar measure on locally compact Abelian groups , Proc. Am. Math. Soc. 115, No. 2, 581-583 (1992). ZBL0777.28006 . which proves existence of the Haar-measure for locally compact abelian groups using the Markov-Kakutani theorem. What I find strange is that the Haar measure is constructed as an element of the dual of $C_c(X)$ . But for noncompact $X$ (such as $X$ being the real numbers $\Bbb R$ ) this must be an unbounded functional (as the Lebesgue-measure on $\Bbb R$ is not finite). It seems like the author has no problem with this, and (without mentioning it further) goes on to define a weak-* topology for this case and even uses Banach-Alaoglu. I have not seen this being done this way before, am I misunderstanding something or can one define a weak-* topology on the algebraic dual of a TVS without any problems?","I was looking at Izzo, Alexander J. , A functional analysis proof of the existence of Haar measure on locally compact Abelian groups , Proc. Am. Math. Soc. 115, No. 2, 581-583 (1992). ZBL0777.28006 . which proves existence of the Haar-measure for locally compact abelian groups using the Markov-Kakutani theorem. What I find strange is that the Haar measure is constructed as an element of the dual of . But for noncompact (such as being the real numbers ) this must be an unbounded functional (as the Lebesgue-measure on is not finite). It seems like the author has no problem with this, and (without mentioning it further) goes on to define a weak-* topology for this case and even uses Banach-Alaoglu. I have not seen this being done this way before, am I misunderstanding something or can one define a weak-* topology on the algebraic dual of a TVS without any problems?",C_c(X) X X \Bbb R \Bbb R,"['functional-analysis', 'harmonic-analysis', 'haar-measure']"
89,Find all metrics on a set $X$ consisting of two points. Consisting of one point.,Find all metrics on a set  consisting of two points. Consisting of one point.,X,"First, this is an exercise in the first section of Kreyszig's introductory functional analysis text. In this section he has already given several examples of metric spaces, including: $l^\infty$ , $C[a,b]$ , and an example of a discrete metric space. In this section he has stated that we can interpret things like infinite but bounded sequences (for $l^\infty$ ) as points, or continuous functions on closed intervals (for $C[a,b]$ ) as points. So, I think I should interpret this question as all possible metrics for any type of abstract set $X$ , which only has two things--points--in it. Attempt: No matter what the set $X$ considered is, as long as the metric $d$ defined on $X$ is maps $(x,y) \in X \times X$ to the nonnegative real numbers, (not including $+ \infty$ ), maps zero to zero, and is a non-affine function of $(x-y)$ it will suffice as a metric. ... ...all of these assumptions I'm making will just build to the definition of a metric it seems like. Maybe the author means a traditional set of points, i.e., finite tuples? I think I'm missing the spirit of the question.","First, this is an exercise in the first section of Kreyszig's introductory functional analysis text. In this section he has already given several examples of metric spaces, including: , , and an example of a discrete metric space. In this section he has stated that we can interpret things like infinite but bounded sequences (for ) as points, or continuous functions on closed intervals (for ) as points. So, I think I should interpret this question as all possible metrics for any type of abstract set , which only has two things--points--in it. Attempt: No matter what the set considered is, as long as the metric defined on is maps to the nonnegative real numbers, (not including ), maps zero to zero, and is a non-affine function of it will suffice as a metric. ... ...all of these assumptions I'm making will just build to the definition of a metric it seems like. Maybe the author means a traditional set of points, i.e., finite tuples? I think I'm missing the spirit of the question.","l^\infty C[a,b] l^\infty C[a,b] X X d X (x,y) \in X \times X + \infty (x-y)","['real-analysis', 'functional-analysis', 'metric-spaces']"
90,Showing that an integral operator on $L^p$ spaces has a certain norm,Showing that an integral operator on  spaces has a certain norm,L^p,"Let $X$ be a sigma-finite measure space, and let $k$ be a measurable function on $X\times X$ .  Suppose that $F(x)=\int |k(x,y)| dy$ and $G(y)=\int |k(x,y)| dx$ are in $L^\infty$ .  Let $1<p<\infty$ and let $K:L^p\rightarrow L^\infty$ be defined by $K(f)(x)=\int k(x,y) f(y) dy$ .  Show that $K$ is bounded with operator norm less than or equal to $||F||_\infty^{1/p}||G||_\infty^{1/q}$ , where $\frac{1}{p}+\frac{1}{q}=1$ . I’m not sure how to approach this.  I need to show that for any $f\in L^p$ , we have $||K(f)||_\infty\leq||F||_\infty^{1/p}||G||_\infty^{1/q}||f||_p$ .  I was thinking of using Holder’s inequality, since that involves $p$ and $q$ , but we have an $L_\infty$ norm here rather than an $L_1$ norm.","Let be a sigma-finite measure space, and let be a measurable function on .  Suppose that and are in .  Let and let be defined by .  Show that is bounded with operator norm less than or equal to , where . I’m not sure how to approach this.  I need to show that for any , we have .  I was thinking of using Holder’s inequality, since that involves and , but we have an norm here rather than an norm.","X k X\times X F(x)=\int |k(x,y)| dy G(y)=\int |k(x,y)| dx L^\infty 1<p<\infty K:L^p\rightarrow L^\infty K(f)(x)=\int k(x,y) f(y) dy K ||F||_\infty^{1/p}||G||_\infty^{1/q} \frac{1}{p}+\frac{1}{q}=1 f\in L^p ||K(f)||_\infty\leq||F||_\infty^{1/p}||G||_\infty^{1/q}||f||_p p q L_\infty L_1","['functional-analysis', 'measure-theory', 'operator-theory', 'lp-spaces', 'holder-inequality']"
91,Is this estimate true for functionals on Frechet spaces?,Is this estimate true for functionals on Frechet spaces?,,"In class the other day my professor made the following claim about the Schwartz class $\mathcal S$ : Let $u: \mathcal S \to \mathbb C$ be linear. $u$ is continuous iff there exist $C,N>0$ such that for all $\varphi \in \mathcal S$ , $$|u(\varphi)| \leq C \sup_{|\alpha|,|\beta| \leq N} ||x^\alpha D^\beta \varphi||_{L^\infty}$$ where $\alpha,\beta$ denote multiindices. (so $||x^\alpha D^\beta \varphi||_{L^\infty}$ is just the $(\alpha,\beta)$ th seminorm of $\mathcal S$ ). He claims this follows immediately from uniform boundedness for Frechet spaces. I'm largely unfamiliar with this area of functional analysis, so it isn't at all clear to me. In particular, I don't see why we'd only need to use finitely many seminorms. So, is the claim Let $F$ be a Frechet space with seminorms $||\cdot||_j$ . A linear map $u: F \to \mathbb C$ is continuous iff there exist $C,N>0$ such that for all $f \in F$ , $$|u(f)| \leq  C\sup_{j \leq N}  ||f||_j$$ valid, or is this just something true for the Schwartz class? Does it follow from Banach-Steinhaus?","In class the other day my professor made the following claim about the Schwartz class : Let be linear. is continuous iff there exist such that for all , where denote multiindices. (so is just the th seminorm of ). He claims this follows immediately from uniform boundedness for Frechet spaces. I'm largely unfamiliar with this area of functional analysis, so it isn't at all clear to me. In particular, I don't see why we'd only need to use finitely many seminorms. So, is the claim Let be a Frechet space with seminorms . A linear map is continuous iff there exist such that for all , valid, or is this just something true for the Schwartz class? Does it follow from Banach-Steinhaus?","\mathcal S u: \mathcal S \to \mathbb C u C,N>0 \varphi \in \mathcal S |u(\varphi)| \leq C \sup_{|\alpha|,|\beta| \leq N} ||x^\alpha D^\beta \varphi||_{L^\infty} \alpha,\beta ||x^\alpha D^\beta \varphi||_{L^\infty} (\alpha,\beta) \mathcal S F ||\cdot||_j u: F \to \mathbb C C,N>0 f \in F |u(f)| \leq  C\sup_{j \leq N}  ||f||_j","['functional-analysis', 'distribution-theory', 'topological-vector-spaces']"
92,Representation of linear operator between $L^p$ spaces.,Representation of linear operator between  spaces.,L^p,"I was wondering where I could find a reference to the a characterization of continuous linear operators: $$T:L^p(X,\mu)\to L^q(Y,\eta)$$ of the form $T(f)(y)=\int_{X} k(x,y)f(x)d\mu$ for some $k$ satisfying some properties.",I was wondering where I could find a reference to the a characterization of continuous linear operators: of the form for some satisfying some properties.,"T:L^p(X,\mu)\to L^q(Y,\eta) T(f)(y)=\int_{X} k(x,y)f(x)d\mu k","['functional-analysis', 'reference-request', 'banach-spaces', 'normed-spaces', 'lp-spaces']"
93,Boundedness of a linear operator,Boundedness of a linear operator,,"Let $X$ be a real normed linear space of all real sequences which are eventually zero with the 'sup' norm and $T:X \to X$ be a bijective linear operator defined by $$T(x_1,x_2,x_3,....)=\left(x_1,\frac{x_2}{2^2},\frac{x_3}{3^2},....\right)$$ How to check whether $T$ and $T^{-1}$ is bounded or not ? $$\left\lVert Tx\right\rVert=\sup \Big\{\vert x_1 \vert,\frac{\vert x_2 \vert}{2^2},...\Big\}=\sup_n\Big\{\frac{\vert x_n \vert}{n^2}\Big\} \leq \sup_n\Big\{\frac{\vert x_n \vert}{n}\Big\}$$ How to make the RHS of above in the form $K \vert\vert x \vert \vert$ if possible ? Any hint ? On the otherhand, $T^{-1}:X \to X$ is a map by $$T^{-1}(x_1.x_2,...)=(x_1,2^2x_2,3^2x_3,...)$$ $$\left\lVert T^{-1}x\right\rVert=\sup_n\Big\{n^2 \vert x_n \vert\Big\} \geq n$$ so $T^{-1}$ is not bounded. Am I right? Any help ?","Let be a real normed linear space of all real sequences which are eventually zero with the 'sup' norm and be a bijective linear operator defined by How to check whether and is bounded or not ? How to make the RHS of above in the form if possible ? Any hint ? On the otherhand, is a map by so is not bounded. Am I right? Any help ?","X T:X \to X T(x_1,x_2,x_3,....)=\left(x_1,\frac{x_2}{2^2},\frac{x_3}{3^2},....\right) T T^{-1} \left\lVert Tx\right\rVert=\sup \Big\{\vert x_1 \vert,\frac{\vert x_2 \vert}{2^2},...\Big\}=\sup_n\Big\{\frac{\vert x_n \vert}{n^2}\Big\} \leq \sup_n\Big\{\frac{\vert x_n \vert}{n}\Big\} K \vert\vert x \vert \vert T^{-1}:X \to X T^{-1}(x_1.x_2,...)=(x_1,2^2x_2,3^2x_3,...) \left\lVert T^{-1}x\right\rVert=\sup_n\Big\{n^2 \vert x_n \vert\Big\} \geq n T^{-1}","['functional-analysis', 'operator-theory']"
94,Asymptotic behaviour of gradient flows for $t \to \infty$,Asymptotic behaviour of gradient flows for,t \to \infty,"I have often heard about the asymptotics of gradient flows converging to some ""equilibrium point"" as $t \to \infty$ . This concept has come to my ear by word of mouth multiple times and is often verified by direct calculations e.g. as for the 1-dimensional heat equation. It also has come to my attention that minimizing movements as described in e.g. Braides Book on $\Gamma$ -convergence try to use this concept. I would like to learn more about it, but can not find a good point to start. As for the notation in this question, $\partial $ denotes the subdifferential and $'$ the derivative with respect to the time. Let's consider a a gradient flow in the euclidean space, for simplicity and let $F:\mathbb{R}^n \to \mathbb{R}$ be a $\lambda$ -convex function (for $\lambda > 0$ the function $F(x)-\frac{\lambda}{2} |x|^2$ is convex) and lets for simplicity assume it has a gradient $\nabla F$ . Then consider the smooth solution of the IVP: $$ u'(t)=-\nabla F(u(t)) \\ u(0)=u_0 $$ You can estimate the difference of two solutions by their initial conditions; i.e. $$ |u_1(t)-u_2(t)|\leq e^{-\lambda t }|u_1(0)-u_2(0)| $$ So taking the limit $t\to \infty$ yields that both solutions seem to converge to the same point, that is: $\lim_{t \to \infty} u_1(t)=\lim_{t \to \infty} u_2(t)$ . Now let say $F$ has 1 critical point $c \in \mathbb{R}^n$ such that $\nabla F(c)=0$ . Now we can consider the problem with inital condition $u_3(0)=c$ . Now the function $u_3(t)=c$ solves the IVP and so we get $$ \lim_{t \to \infty} u(t)=c $$ for all solutions of the problem. So we found some sort of equilibrium point and described the asymptotic behaviour of the function $u$ using $F$ . The question that I have now is if this concept still holds if I replace $\mathbb{R}^n$ with a Hilbert space (as for metric spaces, I might explore them later). For example, the heat equation in a suitable domain, suitable initial/boundary conditions with the Dirichlet energy $E(u)=\int \frac{1}{2}|\nabla u|^2$ statsifies $$ u'=-\nabla_{L^2}E(u) \\ u(0,x)=g(x) \\  u(t,x)|_{\partial \Omega}=f(x)  $$ and we have that $u$ converges as $t \to \infty$ to the solution of the Laplace equation, a critical point of $E(u)$ : $$ \Delta u=0 \\ u|_{\partial \Omega}(t,x)=f(x)  $$ Now consider the setting for gradient flows as in Evans PDE; if you have a similar or more general setting, feel free to use it. Let $H$ be a real Hilbert space, $I:H \to (-\infty,+\infty]$ be convex, proper and lower semicontinouos and the domain of the subdifferential statisifies $\overline{D(\partial I)}=H$ .Then for each $g \in {D(\partial I)}$ there exists a unique function $$ u \in C([0,\infty);H) \; u'\in L^\infty(0,\infty;H) $$ such that $u(0)=g$ , $u(t) \in D(\partial I)$ for each $t>0$ as well as $u'(t)\in-\partial I(u(t))$ . So is there any way or estimate to describe the existence (and maybe uniqueness) of $$ \lim_{t \to \infty}u(t)=h \in H $$ where the limit is taken with respect to the Hilbert space $H$ ? Is $h$ a critical value of $I$ ? Is there some sort of ""exponential decay"" estimate like $||u(t)-h||_H\leq Ce^{-t}||u(0)-h||_H$ ? I am thankful for every reference, hint or answer covering any of the aspects of my question. If you need to modify the assumptions, feel free to do so. Any textbook suggestions are appreciated, as I want to learn more about this topic in a more rigorous way!","I have often heard about the asymptotics of gradient flows converging to some ""equilibrium point"" as . This concept has come to my ear by word of mouth multiple times and is often verified by direct calculations e.g. as for the 1-dimensional heat equation. It also has come to my attention that minimizing movements as described in e.g. Braides Book on -convergence try to use this concept. I would like to learn more about it, but can not find a good point to start. As for the notation in this question, denotes the subdifferential and the derivative with respect to the time. Let's consider a a gradient flow in the euclidean space, for simplicity and let be a -convex function (for the function is convex) and lets for simplicity assume it has a gradient . Then consider the smooth solution of the IVP: You can estimate the difference of two solutions by their initial conditions; i.e. So taking the limit yields that both solutions seem to converge to the same point, that is: . Now let say has 1 critical point such that . Now we can consider the problem with inital condition . Now the function solves the IVP and so we get for all solutions of the problem. So we found some sort of equilibrium point and described the asymptotic behaviour of the function using . The question that I have now is if this concept still holds if I replace with a Hilbert space (as for metric spaces, I might explore them later). For example, the heat equation in a suitable domain, suitable initial/boundary conditions with the Dirichlet energy statsifies and we have that converges as to the solution of the Laplace equation, a critical point of : Now consider the setting for gradient flows as in Evans PDE; if you have a similar or more general setting, feel free to use it. Let be a real Hilbert space, be convex, proper and lower semicontinouos and the domain of the subdifferential statisifies .Then for each there exists a unique function such that , for each as well as . So is there any way or estimate to describe the existence (and maybe uniqueness) of where the limit is taken with respect to the Hilbert space ? Is a critical value of ? Is there some sort of ""exponential decay"" estimate like ? I am thankful for every reference, hint or answer covering any of the aspects of my question. If you need to modify the assumptions, feel free to do so. Any textbook suggestions are appreciated, as I want to learn more about this topic in a more rigorous way!","t \to \infty \Gamma \partial  ' F:\mathbb{R}^n \to \mathbb{R} \lambda \lambda > 0 F(x)-\frac{\lambda}{2} |x|^2 \nabla F 
u'(t)=-\nabla F(u(t)) \\
u(0)=u_0
 
|u_1(t)-u_2(t)|\leq e^{-\lambda t }|u_1(0)-u_2(0)|
 t\to \infty \lim_{t \to \infty} u_1(t)=\lim_{t \to \infty} u_2(t) F c \in \mathbb{R}^n \nabla F(c)=0 u_3(0)=c u_3(t)=c 
\lim_{t \to \infty} u(t)=c
 u F \mathbb{R}^n E(u)=\int \frac{1}{2}|\nabla u|^2 
u'=-\nabla_{L^2}E(u) \\
u(0,x)=g(x) \\ 
u(t,x)|_{\partial \Omega}=f(x) 
 u t \to \infty E(u) 
\Delta u=0 \\
u|_{\partial \Omega}(t,x)=f(x) 
 H I:H \to (-\infty,+\infty] \overline{D(\partial I)}=H g \in {D(\partial I)} 
u \in C([0,\infty);H) \; u'\in L^\infty(0,\infty;H)
 u(0)=g u(t) \in D(\partial I) t>0 u'(t)\in-\partial I(u(t)) 
\lim_{t \to \infty}u(t)=h \in H
 H h I ||u(t)-h||_H\leq Ce^{-t}||u(0)-h||_H","['functional-analysis', 'partial-differential-equations', 'soft-question', 'calculus-of-variations', 'gradient-flows']"
95,What is the Gelfand-Naimark representation of functions that don't vanish at infinity?,What is the Gelfand-Naimark representation of functions that don't vanish at infinity?,,"The Gelfand-Naimark theorem says that every commutative C*-algebra is isometrically isomorphic to $C_0(X)$ , the set of continuous functions $f:X\rightarrow\mathbb{C}$ that vanish at infinity, for some locally compact Hausdorff space $X$ . What happens when we apply this construction to a commutative C*-algebra that looks almost like $C_0(X)$ , but we relax one of the requirements? For example, we can consider the C*-algebra $C_b(Y)$ , the set of bounded continuous functions $f:Y\rightarrow\mathbb{C}$ , with no requirement they vanish at infinity. Is there any relation between the the space $Y$ of the original C*-algebra and the space $X$ that we generate using Gelfand-Naimark? Bonus followup: What if Y is not Hausdorff? Or not locally compact?","The Gelfand-Naimark theorem says that every commutative C*-algebra is isometrically isomorphic to , the set of continuous functions that vanish at infinity, for some locally compact Hausdorff space . What happens when we apply this construction to a commutative C*-algebra that looks almost like , but we relax one of the requirements? For example, we can consider the C*-algebra , the set of bounded continuous functions , with no requirement they vanish at infinity. Is there any relation between the the space of the original C*-algebra and the space that we generate using Gelfand-Naimark? Bonus followup: What if Y is not Hausdorff? Or not locally compact?",C_0(X) f:X\rightarrow\mathbb{C} X C_0(X) C_b(Y) f:Y\rightarrow\mathbb{C} Y X,"['abstract-algebra', 'functional-analysis', 'algebras', 'gelfand-representation']"
96,Geometric Hahn Banach implies Analytic Hahn Banach.,Geometric Hahn Banach implies Analytic Hahn Banach.,,"I want to prove that the geometric Hahn Banach theorem implies the analytic one. Edit:  To avoid confusion I will state the vesion of H.B theorems im familiar with: Analytic H.B: Let $X$ be a linear space(over $\Bbb R$ ) and $Y\subset X$ a subspace. Let $p:X \to \Bbb R$ be a sub-additive function. Suppose $f:Y\to \Bbb R$ is a linear map s.t $f(y) \le p(y)$ for all $y\in Y$ then there exists an extention $g:X\to \Bbb R$ of $f$ s.t. $g(x)\le p(x) $ for all $x\in X$ . Geometric H.B: Let $X$ be a linear space. $K \subset X$ convex s.t. each point in $K$ is an internal point. Let $D$ be a plane disjoint from $K$ then there exists hyperplane that contains $D$ and disjoint from $K$ . In my problem $X$ is NOT a normed space so there are no open sets. Given $X$ a linear space and $Y\subset X$ a subspace $p:X\to \Bbb R$ sub-additive, and $f:Y\to \Bbb R$ linear s.t $f(y)\le p(y)$ for $y\in Y$ we need to extend $f$ to $g:X\to \Bbb R $ and $g(x)\le p(x)$ fo r all $x\in X$ So, we look at $X \times \Bbb R $ and define $K = \{(x,t) : t>p(x)\}$ . The fact that $K$ is convex is easy. How can I show directly that every point in $K$ is internal? (can't say that $K$ is open). Now after showing that, we can look at $Graph(f)$ and observe that $Graph(f)\cap K = \emptyset$ . So by the geometric H.B theorem we have a hyperplane (which is a maximal subspace in this case because $(0,0)\in Graph(f)$ ) M containing $Graph(f) $ and disjoint from $K$ . Now my problem is to show that each $x\in X$ has a unique $t\in \Bbb R$ s.t. $(x,t) \in M$ .  (I need it in order to extend $f$ ). I know that if we take $v_0\notin M$ then each $v \in X \times \Bbb R$ has a unique representation as $v = \alpha v_0 + m$ for $m \in M$ , this is because $M$ is a maximal subspace. not sure if that helps. Thanks for helping!","I want to prove that the geometric Hahn Banach theorem implies the analytic one. Edit:  To avoid confusion I will state the vesion of H.B theorems im familiar with: Analytic H.B: Let be a linear space(over ) and a subspace. Let be a sub-additive function. Suppose is a linear map s.t for all then there exists an extention of s.t. for all . Geometric H.B: Let be a linear space. convex s.t. each point in is an internal point. Let be a plane disjoint from then there exists hyperplane that contains and disjoint from . In my problem is NOT a normed space so there are no open sets. Given a linear space and a subspace sub-additive, and linear s.t for we need to extend to and fo r all So, we look at and define . The fact that is convex is easy. How can I show directly that every point in is internal? (can't say that is open). Now after showing that, we can look at and observe that . So by the geometric H.B theorem we have a hyperplane (which is a maximal subspace in this case because ) M containing and disjoint from . Now my problem is to show that each has a unique s.t. .  (I need it in order to extend ). I know that if we take then each has a unique representation as for , this is because is a maximal subspace. not sure if that helps. Thanks for helping!","X \Bbb R Y\subset X p:X \to \Bbb R f:Y\to \Bbb R f(y) \le p(y) y\in Y g:X\to \Bbb R f g(x)\le p(x)  x\in X X K \subset X K D K D K X X Y\subset X p:X\to \Bbb R f:Y\to \Bbb R f(y)\le p(y) y\in Y f g:X\to \Bbb R  g(x)\le p(x) x\in X X \times \Bbb R  K = \{(x,t) : t>p(x)\} K K K Graph(f) Graph(f)\cap K = \emptyset (0,0)\in Graph(f) Graph(f)  K x\in X t\in \Bbb R (x,t) \in M f v_0\notin M v \in X \times \Bbb R v = \alpha v_0 + m m \in M M",[]
97,Adjoint of bounded linear map is isometric isomorphism implies original map is isometric isomorphism?,Adjoint of bounded linear map is isometric isomorphism implies original map is isometric isomorphism?,,"Suppose $X$ and $Y$ are normed spaces. Let $T$ be a bounded linear map from $X$ to $Y$ . Let $T^*$ be the adjoint map from $Y^{*}$ to $X^{*}$ defined by $T^{*}(y^*) = y^* T$ . A straightforward calculation shows: Theorem 1. If $T$ is an isometric isomorphism from $X$ onto $Y$ , then $T^*$ is an isometric isomorphism from $Y^*$ onto $X^*$ . I'm trying to prove the converse. But the best I can get is the following. (It comes by applying the above theorem with $T^*$ in place of $T$ and using that $T^{**}$ extends $T$ [if $X$ is identified with a subspace of $X^{**}$ in the natural way]). Theorem 2. If $T^*$ is an isometric isomorphism from $Y^*$ onto $X^*$ , then $T$ is an isometric isomorphism from $X$ into $Y$ and $T(X)$ is dense in $Y$ . I cannot seem to strengthen the conclusion to $T$ is surjective. If $X$ is complete, or, more generally, if $T(X)$ is closed in $Y$ , then $T$ is surjective. But what happens if $X$ is not complete or $T(X)$ is not closed? In the discussion of the following question, the OP claims to be able to prove that $T^{∗}$ being an isomorphism implies $T$ is surjective, but I don't see how: $T$ is surjective if and only if the adjoint $T^*$ is an isomorphism (onto its image) There are also some Hilbert space examples in the following links, but they don't address what I am asking about: $T$ surjective iff $T^*$ injective in infinite-dimensional Hilbert space? Example: operator injective, then the adjoint is NOT surjective","Suppose and are normed spaces. Let be a bounded linear map from to . Let be the adjoint map from to defined by . A straightforward calculation shows: Theorem 1. If is an isometric isomorphism from onto , then is an isometric isomorphism from onto . I'm trying to prove the converse. But the best I can get is the following. (It comes by applying the above theorem with in place of and using that extends [if is identified with a subspace of in the natural way]). Theorem 2. If is an isometric isomorphism from onto , then is an isometric isomorphism from into and is dense in . I cannot seem to strengthen the conclusion to is surjective. If is complete, or, more generally, if is closed in , then is surjective. But what happens if is not complete or is not closed? In the discussion of the following question, the OP claims to be able to prove that being an isomorphism implies is surjective, but I don't see how: is surjective if and only if the adjoint is an isomorphism (onto its image) There are also some Hilbert space examples in the following links, but they don't address what I am asking about: surjective iff injective in infinite-dimensional Hilbert space? Example: operator injective, then the adjoint is NOT surjective",X Y T X Y T^* Y^{*} X^{*} T^{*}(y^*) = y^* T T X Y T^* Y^* X^* T^* T T^{**} T X X^{**} T^* Y^* X^* T X Y T(X) Y T X T(X) Y T X T(X) T^{∗} T T T^* T T^*,"['functional-analysis', 'analysis', 'operator-theory', 'dual-spaces']"
98,Continuity of the functional on the space $L_1$.,Continuity of the functional on the space .,L_1,"The norm of the space $\mathbb E = L_1(0,1)$ is $$\Vert f \Vert = \int_{0}^1 \vert f(t) \vert dt.$$ We have $$Tf(t) = \int_{0}^t f(t)dt. $$ Show that T is continuous. I started from: $\Vert Tf(t) \Vert = \int_{0}^1 \vert Tf(t) \vert dt =   \int_{0}^1 \vert \int_{0}^t f(t) dt\vert dt \le  \int_{0}^1 \int_{0}^t \vert f(t) \vert  dt dt = \int_{0}^t \int_{0}^1 \vert f(t) \vert  dt dt = \int_{0}^t \Vert f \Vert dt = \Vert f \Vert \int_{0}^t dt = \Vert f \Vert t. $ I get $ \Vert f \Vert t $ lastly. But I need to get $\Vert Tf(t) \Vert \le M \Vert f \Vert$ , where $M>0$ (const). Can someone tell me where I made mistake?","The norm of the space is We have Show that T is continuous. I started from: I get lastly. But I need to get , where (const). Can someone tell me where I made mistake?","\mathbb E = L_1(0,1) \Vert f \Vert = \int_{0}^1 \vert f(t) \vert dt. Tf(t) = \int_{0}^t f(t)dt.  \Vert Tf(t) \Vert = \int_{0}^1 \vert Tf(t) \vert dt =   \int_{0}^1 \vert \int_{0}^t f(t) dt\vert dt \le  \int_{0}^1 \int_{0}^t \vert f(t) \vert  dt dt = \int_{0}^t \int_{0}^1 \vert f(t) \vert  dt dt = \int_{0}^t \Vert f \Vert dt = \Vert f \Vert \int_{0}^t dt = \Vert f \Vert t.   \Vert f \Vert t  \Vert Tf(t) \Vert \le M \Vert f \Vert M>0","['functional-analysis', 'continuity', 'operator-theory']"
99,Is the set $\{|f(0)|: \int_{0}^{1}|f(t)|dt\le1\}$ bounded?,Is the set  bounded?,\{|f(0)|: \int_{0}^{1}|f(t)|dt\le1\},"Let $x_0 \in [0,1]$ and define $T:C[0,1] \rightarrow \mathbb{R}$ by $T_{x_0}(f)=f(x_0)$ . Let $||\cdot||_1$ be a norm on $C[0,1]$ . Is $T_0$ bounded or not? That is, is the set $$ \left\{|T_{0}(f)|:||f||_1 \leq 1\right\}=\{|f(0)|:||f||_1 \leq 1,f \in C[0,1]\} $$ bounded? Since $||f||_1:=\int_{0}^{1}|f(t)|dt$ , the question may be equivalent to the following: Let $f:[0,1] \rightarrow \mathbb{R}$ be continuous. Is the set $$\left\{|f(0)|: \int_{0}^{1}|f(t)|dt \leq 1\right\}$$ bounded? I guess the answer is no. Because, for example, we can have a function whose graph is a narrow spike at the origin but with infinite height. The area enclosed by the graph may be 1 but the value at the origin $f(0)$ which is its height is infinite. But how can I prove this formally?","Let and define by . Let be a norm on . Is bounded or not? That is, is the set bounded? Since , the question may be equivalent to the following: Let be continuous. Is the set bounded? I guess the answer is no. Because, for example, we can have a function whose graph is a narrow spike at the origin but with infinite height. The area enclosed by the graph may be 1 but the value at the origin which is its height is infinite. But how can I prove this formally?","x_0 \in [0,1] T:C[0,1] \rightarrow \mathbb{R} T_{x_0}(f)=f(x_0) ||\cdot||_1 C[0,1] T_0 
\left\{|T_{0}(f)|:||f||_1 \leq 1\right\}=\{|f(0)|:||f||_1 \leq 1,f \in C[0,1]\}
 ||f||_1:=\int_{0}^{1}|f(t)|dt f:[0,1] \rightarrow \mathbb{R} \left\{|f(0)|: \int_{0}^{1}|f(t)|dt \leq 1\right\} f(0)","['calculus', 'real-analysis', 'functional-analysis', 'analysis']"
