,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Complex analysis and generating functions problem or question,Complex analysis and generating functions problem or question,,"I've been studying some complex analysis lately and I find very intriguing the relation between this field and generating functions. I've seen this video by 3Blue1Brown and it's really fascinating. Essentially, I'd like to find some kind of problem or question in which I could use this types of techniques in order to ilustrate the procedures for a project. I'd like to remark that this is a project, not actual research, so I just need to find a problem  so I can apply this techniques and show some further applications. Ideally, the problem is cloesly related to something like computer science, or anything that allows me to create something, since the project is meant to be original and I'm not so naive to belive that with my knowledge I could discover something new.","I've been studying some complex analysis lately and I find very intriguing the relation between this field and generating functions. I've seen this video by 3Blue1Brown and it's really fascinating. Essentially, I'd like to find some kind of problem or question in which I could use this types of techniques in order to ilustrate the procedures for a project. I'd like to remark that this is a project, not actual research, so I just need to find a problem  so I can apply this techniques and show some further applications. Ideally, the problem is cloesly related to something like computer science, or anything that allows me to create something, since the project is meant to be original and I'm not so naive to belive that with my knowledge I could discover something new.",,"['complex-analysis', 'generating-functions']"
1,Do all holomorphic functions on $\{z^2 + w^2 = 1\}$ extend to $\mathbb{C}^2$?,Do all holomorphic functions on  extend to ?,\{z^2 + w^2 = 1\} \mathbb{C}^2,"Let $$X = \{(z, w) \in \mathbb{C}^2 : z^2 + w^2 = 1\}.$$ Is there a holomorphic function $f : X \to \mathbb{C}$ which do not extend to a holomorphic function on all of $\mathbb{C}^2$ ? I tried to find an example of the form $f(z, w) = \frac{1}{g(z, w)}$ , where $g(z, w)$ is a holomorphic function which has zeros, but none that lie in $X$ . But I couldn't find any.","Let Is there a holomorphic function which do not extend to a holomorphic function on all of ? I tried to find an example of the form , where is a holomorphic function which has zeros, but none that lie in . But I couldn't find any.","X = \{(z, w) \in \mathbb{C}^2 : z^2 + w^2 = 1\}. f : X \to \mathbb{C} \mathbb{C}^2 f(z, w) = \frac{1}{g(z, w)} g(z, w) X","['complex-analysis', 'algebraic-geometry', 'complex-geometry', 'several-complex-variables']"
2,Solving equation involving roots and powers .,Solving equation involving roots and powers .,,"I'm trying to solve this equation : $\sqrt{3}\sqrt{237x^2 + \frac{224}{x^2}}x^7 + \frac{35293}{222}x^8 + \frac{2}{999}\sqrt{3}{(\sqrt{237x^2 + \frac{224}{x^2}})}^3x^5 - \frac{44968}{111}x^4 + \frac{12544}{333}=0$ . It looks pretty complicated to me, but the computer gives me exact solutions. For example one real solution is $\frac{2}{\sqrt{3}}$ , and another : $-\frac{2}{3^{\frac{3}{4}}\sqrt[4]{7}}$ and so on. Does anyone know how to obtain the exact solutions to the above equation? Thanks in advance! EDIT: This came from fooling around with functions that describe surfaces spanned by the roots of polynomials $x^4+c_2x^2+c_3x+c_4$ in 3 dimensions. So here $r_1+r_2+r_3+r_4=0$ . Newton's identity $r_1^4+r_2^4+r_3^4+r_4^4 = 4$ (the 4 here is randomly chosen) can thus be represented as a 2D surface in 3D. With some other transformations this gives : $-\frac{1}{3}\sqrt{6}\sqrt{3}x_1x_2^2x_3 + \frac{1}{9}\sqrt{6}\sqrt{3}x_1x_3^3 + \frac{7}{12}x_1^4 + \frac{1}{2}x_1^2x_2^2 + \frac{1}{2}x_2^4 + \frac{1}{2}x_1^2x_3^2 + x_2^2x_3^2 + \frac{1}{2}x_3^4 = 4$ . This surface looks somewhat like an octahedron. To find the extrema on the surface I used Lagrange multipliers leading to the equation in question. So I guess it's not very surprising that this has an exact solution. But I was surprised that the computer could find them so easily..","I'm trying to solve this equation : . It looks pretty complicated to me, but the computer gives me exact solutions. For example one real solution is , and another : and so on. Does anyone know how to obtain the exact solutions to the above equation? Thanks in advance! EDIT: This came from fooling around with functions that describe surfaces spanned by the roots of polynomials in 3 dimensions. So here . Newton's identity (the 4 here is randomly chosen) can thus be represented as a 2D surface in 3D. With some other transformations this gives : . This surface looks somewhat like an octahedron. To find the extrema on the surface I used Lagrange multipliers leading to the equation in question. So I guess it's not very surprising that this has an exact solution. But I was surprised that the computer could find them so easily..",\sqrt{3}\sqrt{237x^2 + \frac{224}{x^2}}x^7 + \frac{35293}{222}x^8 + \frac{2}{999}\sqrt{3}{(\sqrt{237x^2 + \frac{224}{x^2}})}^3x^5 - \frac{44968}{111}x^4 + \frac{12544}{333}=0 \frac{2}{\sqrt{3}} -\frac{2}{3^{\frac{3}{4}}\sqrt[4]{7}} x^4+c_2x^2+c_3x+c_4 r_1+r_2+r_3+r_4=0 r_1^4+r_2^4+r_3^4+r_4^4 = 4 -\frac{1}{3}\sqrt{6}\sqrt{3}x_1x_2^2x_3 + \frac{1}{9}\sqrt{6}\sqrt{3}x_1x_3^3 + \frac{7}{12}x_1^4 + \frac{1}{2}x_1^2x_2^2 + \frac{1}{2}x_2^4 + \frac{1}{2}x_1^2x_3^2 + x_2^2x_3^2 + \frac{1}{2}x_3^4 = 4,"['real-analysis', 'complex-analysis', 'polynomials', 'roots']"
3,Show $|f(0)| \le e$ for holomorphic function satisfying $ |f(e^{i\pi t})|\leq e^{t}$,Show  for holomorphic function satisfying,|f(0)| \le e  |f(e^{i\pi t})|\leq e^{t},"Let f be a holomorphic function on the closed unit disk such that : $$ | f(e^{i\pi t})| \leq e^{t}, \forall t \in [0,2] \, .$$ Show that $$ | f(0)| \leq e \, .$$ I tried to use this relation to use the average value of $f$ in $0$ $$ f(0)=\frac{1}{2\pi}\int_{0}^{2\pi}f(e^{it})dt= \frac{1}{2}\int_{0}^{2}f(e^{i\pi t})dt$$ so $$ | f(0)| \leq \frac{e^2-1}{2}$$ which is far from the desired inequality.",Let f be a holomorphic function on the closed unit disk such that : Show that I tried to use this relation to use the average value of in so which is far from the desired inequality.," | f(e^{i\pi t})| \leq e^{t}, \forall t \in [0,2] \, .  | f(0)| \leq e \, . f 0  f(0)=\frac{1}{2\pi}\int_{0}^{2\pi}f(e^{it})dt= \frac{1}{2}\int_{0}^{2}f(e^{i\pi t})dt  | f(0)| \leq \frac{e^2-1}{2}",['complex-analysis']
4,Can the poles of a complex function $f(z)$ be defined as the locations where $\lvert f(z) \rvert = \infty$?,Can the poles of a complex function  be defined as the locations where ?,f(z) \lvert f(z) \rvert = \infty,"According to Wikipedia , A zero of a meromorphic function $f$ is a complex number $z$ such that $f(z) = 0$ . A pole of $f$ is a zero of $1/f$ . Is there a reason why a pole cannot be defined as the location where $\lvert f(z) \rvert = \infty$ ? I was imagining this to be the case based on this plot of the magnitude of the complex gamma function:","According to Wikipedia , A zero of a meromorphic function is a complex number such that . A pole of is a zero of . Is there a reason why a pole cannot be defined as the location where ? I was imagining this to be the case based on this plot of the magnitude of the complex gamma function:",f z f(z) = 0 f 1/f \lvert f(z) \rvert = \infty,['complex-analysis']
5,Calculating $\int_0^\infty \frac{1}{(x^2+1)^n}dx$,Calculating,\int_0^\infty \frac{1}{(x^2+1)^n}dx,"I am trying to determine a closed form expression of the integral $I_n := \int_0^\infty \frac{1}{(x^2+1)^n}dx$ , where $n \in \mathbb{N}$ . I'd like to use residue calculus to solve this problem. I have come up with the following: Let $f_n(x) := \frac{1}{(x^2+1)^n}$ . Since $f_n$ is an even function, we have $$ 2I_n = \int_\mathbb{R}\frac{1}{(x^2+1)^n}dx. $$ Next, consider the function $f_n$ with a complex argument $z \in \mathbb{C}$ . This gives us $$ f_n(z) = \frac{1}{(z^2+1)^n} = \frac{1}{(z+i)^n(z-i)^n}. $$ Let $r>0$ , $t \in [0,\pi]$ and define the contour $\Gamma := [-r,r] \cup \gamma_r$ , i.e. $\Gamma$ consists of the straight line from $-r$ to $r$ along the real axis, and then the half circle $\gamma_r$ (counterclockwise, with radius $r$ ) from $r$ to $-r$ , i.e. $\gamma_r(t) := re^{it}$ . Then, by the residue theorem: $$ \oint_\Gamma f_n(z)\,dz = \int_{-r}^rf_n(z)\,dz + \int_{\gamma_r}f_n(z)\,dz = 2\pi i \text{Res}(f_n,i), $$ since $i$ lies within the contour $\Gamma$ . We see that $\lim_{r\to\infty}\int_{\gamma_r}f_n(z)\,dz = 0$ , since \begin{align} \left|\int_{\gamma_r}f_n(z)\,dz\right| &= \left| \int_0^\pi f_n(\gamma_r(t))\gamma_r'(t)\,dt \right|\\ &= \left| \int_0^\pi \frac{rie^{it}}{(r^2e^{2it}+1)^n}dt \right|\\ &\leq r \int_0^\pi \frac{1}{|r^2e^{2it}+1|^n}dt\\ &\leq r \int_0^\pi \frac{1}{|r^2-1|^n}dt = \frac{\pi r}{|r^2-1|^n} \xrightarrow{\;r \to \infty\;} 0. \end{align} Hence, we get that $$ 2I_n = \lim_{r\to\infty}\oint_\Gamma f_n(z)\,dz = 2\pi i \text{Res}(f_n,i) \implies I_n = \pi i \text{Res}(f_n,i). $$ Now, we calculate $\text{Res}(f_n,i)$ . Since $i$ is a pole of order $n$ of $f_n$ , we can write $$ \text{Res}(f_n,i) = \frac{1}{(n-1)!}\lim_{z\to i} \frac{\partial^{n-1}}{\partial z^{n-1}}[(z-i)^nf_n(z)] = \frac{1}{(n-1)!}\lim_{z\to i} \frac{\partial^{n-1}}{\partial z^{n-1}} \left[ \frac{1}{(z+i)^n} \right]. $$ Then, we see that \begin{align} \frac{\partial^{n-1}}{\partial z^{n-1}} \left[ \frac{1}{(z+i)^n} \right] &= n(n+1)(n+2)\cdots(2n-3)(2n-2)\frac{p(n-1)}{(z+i)^{2n-1}} \qquad\qquad (*) \end{align} where $p$ denotes the ""parity-function"" defined by $$ p : \mathbb{N} \to \{-1,1\}, \qquad n \mapsto  \begin{cases} 1 & n \text{ even}\\ -1 & n \text{ odd} \end{cases}. $$ Then, we get \begin{align} \frac{1}{(n-1)!}n(n+1)(n+2)\cdots(2n-3)(2n-2)\frac{p(n-1)}{(z+i)^{2n-1}} =\frac{(2n-2)!}{((n-1)!)^2}\frac{z+i}{(z+i)^{2n}}p(n-1), \end{align} and finally, by letting $z \to i$ , we obtain $$ \text{Res}(f_n,i) = \frac{(2n-2)!}{((n-1)!)^2}\frac{2i}{(2i)^{2n}}p(n-1) = -\frac{(2n-2)!}{((n-1)!)^2}\frac{2i}{4^n}, $$ where the last equality follows from comparing the signs of $p(n-1)$ and $(2i)^{2n} = (-4)^n$ for different $n \in \mathbb{N}$ . Since $I_n = \pi i \text{Res}(f_n,i)$ , we get $$ I_n = \frac{(2n-2)!}{((n-1)!)^2}\frac{2\pi}{4^n}. $$ My questions are: Is this formula for $I_n$ correct? Are there any flaws in my proof? I'm not sure that equation $(*)$ is correct. I simply calculated the derivative for $n=1,2, 3$ and then loosely used an inductive argument for the general case. Is there a mistake here?","I am trying to determine a closed form expression of the integral , where . I'd like to use residue calculus to solve this problem. I have come up with the following: Let . Since is an even function, we have Next, consider the function with a complex argument . This gives us Let , and define the contour , i.e. consists of the straight line from to along the real axis, and then the half circle (counterclockwise, with radius ) from to , i.e. . Then, by the residue theorem: since lies within the contour . We see that , since Hence, we get that Now, we calculate . Since is a pole of order of , we can write Then, we see that where denotes the ""parity-function"" defined by Then, we get and finally, by letting , we obtain where the last equality follows from comparing the signs of and for different . Since , we get My questions are: Is this formula for correct? Are there any flaws in my proof? I'm not sure that equation is correct. I simply calculated the derivative for and then loosely used an inductive argument for the general case. Is there a mistake here?","I_n := \int_0^\infty \frac{1}{(x^2+1)^n}dx n \in \mathbb{N} f_n(x) := \frac{1}{(x^2+1)^n} f_n 
2I_n = \int_\mathbb{R}\frac{1}{(x^2+1)^n}dx.
 f_n z \in \mathbb{C} 
f_n(z) = \frac{1}{(z^2+1)^n} = \frac{1}{(z+i)^n(z-i)^n}.
 r>0 t \in [0,\pi] \Gamma := [-r,r] \cup \gamma_r \Gamma -r r \gamma_r r r -r \gamma_r(t) := re^{it} 
\oint_\Gamma f_n(z)\,dz = \int_{-r}^rf_n(z)\,dz + \int_{\gamma_r}f_n(z)\,dz = 2\pi i \text{Res}(f_n,i),
 i \Gamma \lim_{r\to\infty}\int_{\gamma_r}f_n(z)\,dz = 0 \begin{align}
\left|\int_{\gamma_r}f_n(z)\,dz\right| &= \left| \int_0^\pi f_n(\gamma_r(t))\gamma_r'(t)\,dt \right|\\
&= \left| \int_0^\pi \frac{rie^{it}}{(r^2e^{2it}+1)^n}dt \right|\\
&\leq r \int_0^\pi \frac{1}{|r^2e^{2it}+1|^n}dt\\
&\leq r \int_0^\pi \frac{1}{|r^2-1|^n}dt = \frac{\pi r}{|r^2-1|^n} \xrightarrow{\;r \to \infty\;} 0.
\end{align} 
2I_n = \lim_{r\to\infty}\oint_\Gamma f_n(z)\,dz = 2\pi i \text{Res}(f_n,i) \implies I_n = \pi i \text{Res}(f_n,i).
 \text{Res}(f_n,i) i n f_n 
\text{Res}(f_n,i) = \frac{1}{(n-1)!}\lim_{z\to i} \frac{\partial^{n-1}}{\partial z^{n-1}}[(z-i)^nf_n(z)] = \frac{1}{(n-1)!}\lim_{z\to i} \frac{\partial^{n-1}}{\partial z^{n-1}} \left[ \frac{1}{(z+i)^n} \right].
 \begin{align}
\frac{\partial^{n-1}}{\partial z^{n-1}} \left[ \frac{1}{(z+i)^n} \right] &= n(n+1)(n+2)\cdots(2n-3)(2n-2)\frac{p(n-1)}{(z+i)^{2n-1}} \qquad\qquad (*)
\end{align} p 
p : \mathbb{N} \to \{-1,1\}, \qquad n \mapsto 
\begin{cases}
1 & n \text{ even}\\
-1 & n \text{ odd}
\end{cases}.
 \begin{align}
\frac{1}{(n-1)!}n(n+1)(n+2)\cdots(2n-3)(2n-2)\frac{p(n-1)}{(z+i)^{2n-1}}
=\frac{(2n-2)!}{((n-1)!)^2}\frac{z+i}{(z+i)^{2n}}p(n-1),
\end{align} z \to i 
\text{Res}(f_n,i) = \frac{(2n-2)!}{((n-1)!)^2}\frac{2i}{(2i)^{2n}}p(n-1) = -\frac{(2n-2)!}{((n-1)!)^2}\frac{2i}{4^n},
 p(n-1) (2i)^{2n} = (-4)^n n \in \mathbb{N} I_n = \pi i \text{Res}(f_n,i) 
I_n = \frac{(2n-2)!}{((n-1)!)^2}\frac{2\pi}{4^n}.
 I_n (*) n=1,2, 3","['complex-analysis', 'solution-verification', 'contour-integration', 'complex-integration', 'residue-calculus']"
6,Sokhotski–Plemelj theorem for the real line,Sokhotski–Plemelj theorem for the real line,,"The Sokhotski–Plemelj theorem for the real line is stated at https://en.wikipedia.org/wiki/Sokhotski–Plemelj_theorem : Sokhotski–Plemelj theorem. Let $f$ be a complex-valued function that is defined and continuous on the real line, and let $a$ , $b$ , and $x_0$ be real constants with ${\displaystyle a<x_0<b}$ . Then $${\displaystyle \lim _{\varepsilon \to 0^{+}}\int _{a}^{b}{\frac {f(x)}{x-x_0\pm i\varepsilon }}\,dx=\mp i\pi f(x_0)+{\mathcal {P}}\int _{a}^{b}{\frac {f(x)}{x-x_0}}\,dx.}$$ I also gather from Confusion concerning the Sokhotski–Plemelj theorem: two different values for the same real integral that there is a more general version  of the theorem that is valid over the whole real line, so that, under some mild hypotheses on $f(x)$ , one has $${\displaystyle \lim _{\varepsilon \to 0^{+}}\int _{-\infty}^{\infty}{\frac {f(x)}{x-x_0\pm i\varepsilon }}\,dx=\mp i\pi f(x_0)+{\mathcal {P}}\int _{-\infty}^{\infty}{\frac {f(x)}{x-x_0}}\,dx.}$$ My question is: what (mild) hypotheses on $f(x)$ are sufficient for the more general version stated above to hold?  I'm also looking for a proof or appropriate reference.","The Sokhotski–Plemelj theorem for the real line is stated at https://en.wikipedia.org/wiki/Sokhotski–Plemelj_theorem : Sokhotski–Plemelj theorem. Let be a complex-valued function that is defined and continuous on the real line, and let , , and be real constants with . Then I also gather from Confusion concerning the Sokhotski–Plemelj theorem: two different values for the same real integral that there is a more general version  of the theorem that is valid over the whole real line, so that, under some mild hypotheses on , one has My question is: what (mild) hypotheses on are sufficient for the more general version stated above to hold?  I'm also looking for a proof or appropriate reference.","f a b x_0 {\displaystyle a<x_0<b} {\displaystyle \lim _{\varepsilon \to 0^{+}}\int _{a}^{b}{\frac {f(x)}{x-x_0\pm i\varepsilon }}\,dx=\mp i\pi f(x_0)+{\mathcal {P}}\int _{a}^{b}{\frac {f(x)}{x-x_0}}\,dx.} f(x) {\displaystyle \lim _{\varepsilon \to 0^{+}}\int _{-\infty}^{\infty}{\frac {f(x)}{x-x_0\pm i\varepsilon }}\,dx=\mp i\pi f(x_0)+{\mathcal {P}}\int _{-\infty}^{\infty}{\frac {f(x)}{x-x_0}}\,dx.} f(x)",['complex-analysis']
7,Is polynomially convex strictly weaker than convex?,Is polynomially convex strictly weaker than convex?,,"Define the polynomially convex hull of a compact set $K$ to be the set $K\hat{} = \{ z \in \mathbb{C}: |p(z)| \le \max_{x \in K} |p(x)| \text{ for every polynomial } p \}$ If $K\hat{} = K$ then $K$ is polynomially convex . I'm wondering to what extent does this agree with the ""normal"" sense of convexity in the Complex plane, that is containing all its line segments. I believe that for example the polynomially convex hull of two points is not the line segment between them, since a polynomial could obtain a max on the midpoint between them, thus be less than the maximum of the two points. Given that, is it correct to say we can recover the ""normal"" definition by considering only linear functions, which would make this a generalization and weakening of the concept (since it'd be harder to find points where this was true, thus the hull is smaller)?","Define the polynomially convex hull of a compact set to be the set If then is polynomially convex . I'm wondering to what extent does this agree with the ""normal"" sense of convexity in the Complex plane, that is containing all its line segments. I believe that for example the polynomially convex hull of two points is not the line segment between them, since a polynomial could obtain a max on the midpoint between them, thus be less than the maximum of the two points. Given that, is it correct to say we can recover the ""normal"" definition by considering only linear functions, which would make this a generalization and weakening of the concept (since it'd be harder to find points where this was true, thus the hull is smaller)?",K K\hat{} = \{ z \in \mathbb{C}: |p(z)| \le \max_{x \in K} |p(x)| \text{ for every polynomial } p \} K\hat{} = K K,"['complex-analysis', 'geometry']"
8,"Calculate $\int_{-\infty}^{\infty}\frac{\cos^2(x)}{x^2}e^{-ikx}dx$ for $k\in[0,2]$",Calculate  for,"\int_{-\infty}^{\infty}\frac{\cos^2(x)}{x^2}e^{-ikx}dx k\in[0,2]","After some alegbra, we find that the integral equals: $$\frac{1}{4}\int_{-\infty}^{\infty}\frac{2e^{-ikx}+e^{i(2-k)x}+e^{-i(2+k)x}}{x^2}dx$$ . Now since $k\in[0,2]$ , for contour integration, we consider the LHP for the first and third term in the integrand and then the UHP for the second term. If we call $C_{\epsilon,U}$ the semi-circle of radius $\epsilon$ in the UHP, $C_{\epsilon,L}$ the semi-circle of radius $\epsilon$ in the LHP, $C_{R,U}$ the semi-circle of radius $R$ in the UHP, $C_{R,L}$ the semi-circle of radius $R$ in the UHP, with closed contours $\Gamma_{U}$ and $\Gamma_{L}$ , we have: $$\int_{-\infty}^{\infty}=\lim_{R\to\infty}\lim_{\epsilon\to 0}\Bigg(\int_{\Gamma_U}-\int_{C_{\epsilon,U}} -\int_{C_{R,U}}\Bigg) \text{ for the second term}$$ $$\int_{-\infty}^{\infty}=\lim_{R\to\infty}\lim_{\epsilon\to 0}\Bigg(-\int_{\Gamma_L}-\int_{C_{\epsilon,L}} -\int_{C_{R,L}}\Bigg) \text{ for the remaining terms}$$ (Note the negative sign in line 2 due to negative orientation of $\Gamma_L$ ) No poles lie inside the closed $\Gamma_U$ and $\Gamma_L$ so the first integral on the RHS of each line is zero, and the last integral on the RHS each line $\to 0$ as $R\to \infty$ . So, for the top line, we're left with: $$ \frac{1}{4}\int_{-\infty}^{\infty}\frac{e^{i(2-k)x}}{x^2}dx=-\frac{1}{4}\lim_{\epsilon\to 0}\int_{C_{\epsilon,U}}\frac{e^{i(2-k)z}}{z^2}dz=-\frac{1}{4}\lim_{\epsilon\to 0}\int_{\pi}^{0}\frac{e^{i(2-k)\epsilon e^{i\theta}}}{\epsilon^2e^{2i\theta}}i\epsilon e^{i\theta}d\theta$$ . Expanding $e^{i(2-k)\epsilon e^{i\theta}}=1+i(2-k)\epsilon e^{i\theta}+...$ (can ignore higher order terms as they tend to $0$ as $\epsilon \to 0$ ). So we get (for the second term in the original integrand): $$\frac{1}{4}\lim_{\epsilon\to 0}\int_{0}^{\pi}\frac{1+i(2-k)\epsilon e^{i\theta}}{\epsilon^2e^{2i\theta}}i\epsilon e^{i\theta}d\theta=\frac{1}{4}\lim_{\epsilon\to 0}\int_{0}^{\pi}\frac{ie^{-i\theta}}{\epsilon}d\theta-\frac{1}{4}\int_{0}^{\pi}(2-k)d\theta=\frac{1}{4}\lim_{\epsilon\to 0}\int_{0}^{\pi}\frac{ie^{-i\theta}}{\epsilon}d\theta-\frac{1}{4}(2-k)\pi$$ But surely this is divergent? Have I gone wrong somewhere with this? When I consider the remaining terms (the 1st and 3rd terms in the original integrand, using the LHP), using the same method I get: $$=-\frac{3}{4}\lim_{\epsilon\to 0}\int_{-\pi}^{0}\frac{ie^{-i\theta}}{\epsilon}d\theta-\frac{1}{4}(2k+2)\pi$$ which again is divergent. So summing these two results would mean that the original integral in my question is divergent (assuming my method is correct - which I don't think it is)?","After some alegbra, we find that the integral equals: . Now since , for contour integration, we consider the LHP for the first and third term in the integrand and then the UHP for the second term. If we call the semi-circle of radius in the UHP, the semi-circle of radius in the LHP, the semi-circle of radius in the UHP, the semi-circle of radius in the UHP, with closed contours and , we have: (Note the negative sign in line 2 due to negative orientation of ) No poles lie inside the closed and so the first integral on the RHS of each line is zero, and the last integral on the RHS each line as . So, for the top line, we're left with: . Expanding (can ignore higher order terms as they tend to as ). So we get (for the second term in the original integrand): But surely this is divergent? Have I gone wrong somewhere with this? When I consider the remaining terms (the 1st and 3rd terms in the original integrand, using the LHP), using the same method I get: which again is divergent. So summing these two results would mean that the original integral in my question is divergent (assuming my method is correct - which I don't think it is)?","\frac{1}{4}\int_{-\infty}^{\infty}\frac{2e^{-ikx}+e^{i(2-k)x}+e^{-i(2+k)x}}{x^2}dx k\in[0,2] C_{\epsilon,U} \epsilon C_{\epsilon,L} \epsilon C_{R,U} R C_{R,L} R \Gamma_{U} \Gamma_{L} \int_{-\infty}^{\infty}=\lim_{R\to\infty}\lim_{\epsilon\to 0}\Bigg(\int_{\Gamma_U}-\int_{C_{\epsilon,U}} -\int_{C_{R,U}}\Bigg) \text{ for the second term} \int_{-\infty}^{\infty}=\lim_{R\to\infty}\lim_{\epsilon\to 0}\Bigg(-\int_{\Gamma_L}-\int_{C_{\epsilon,L}} -\int_{C_{R,L}}\Bigg) \text{ for the remaining terms} \Gamma_L \Gamma_U \Gamma_L \to 0 R\to \infty  \frac{1}{4}\int_{-\infty}^{\infty}\frac{e^{i(2-k)x}}{x^2}dx=-\frac{1}{4}\lim_{\epsilon\to 0}\int_{C_{\epsilon,U}}\frac{e^{i(2-k)z}}{z^2}dz=-\frac{1}{4}\lim_{\epsilon\to 0}\int_{\pi}^{0}\frac{e^{i(2-k)\epsilon e^{i\theta}}}{\epsilon^2e^{2i\theta}}i\epsilon e^{i\theta}d\theta e^{i(2-k)\epsilon e^{i\theta}}=1+i(2-k)\epsilon e^{i\theta}+... 0 \epsilon \to 0 \frac{1}{4}\lim_{\epsilon\to 0}\int_{0}^{\pi}\frac{1+i(2-k)\epsilon e^{i\theta}}{\epsilon^2e^{2i\theta}}i\epsilon e^{i\theta}d\theta=\frac{1}{4}\lim_{\epsilon\to 0}\int_{0}^{\pi}\frac{ie^{-i\theta}}{\epsilon}d\theta-\frac{1}{4}\int_{0}^{\pi}(2-k)d\theta=\frac{1}{4}\lim_{\epsilon\to 0}\int_{0}^{\pi}\frac{ie^{-i\theta}}{\epsilon}d\theta-\frac{1}{4}(2-k)\pi =-\frac{3}{4}\lim_{\epsilon\to 0}\int_{-\pi}^{0}\frac{ie^{-i\theta}}{\epsilon}d\theta-\frac{1}{4}(2k+2)\pi","['integration', 'complex-analysis', 'definite-integrals', 'improper-integrals', 'contour-integration']"
9,Prove that $\overline{e^{ix}}=e^{-ix}$,Prove that,\overline{e^{ix}}=e^{-ix},"I am trying to construct properly the imaginary exponential as an extension of the real exponential. For this, I need to show that $\overline{e^{ix}}=e^{-ix}$ . I know that there is a very simple proof using an infinite sum of powers. But I am really looking for something purely algebraic using mainly if not only the properties of the real exponential extended to complex numbers. One can easily show that $1=e^{ix}\cdot e^{-ix}$ and therefore that if $z=e^{ix}$ , then $e^{-ix}=\lambda\cdot \overline z$ with $\lambda\in\mathbb R$ , but how can we show that $\lambda=1$ ? Once again, I am really looking for a proof that doesn't use any infinite sum.","I am trying to construct properly the imaginary exponential as an extension of the real exponential. For this, I need to show that . I know that there is a very simple proof using an infinite sum of powers. But I am really looking for something purely algebraic using mainly if not only the properties of the real exponential extended to complex numbers. One can easily show that and therefore that if , then with , but how can we show that ? Once again, I am really looking for a proof that doesn't use any infinite sum.",\overline{e^{ix}}=e^{-ix} 1=e^{ix}\cdot e^{-ix} z=e^{ix} e^{-ix}=\lambda\cdot \overline z \lambda\in\mathbb R \lambda=1,['complex-analysis']
10,Value of $i^\sqrt3$,Value of,i^\sqrt3,Find all values of $i^\sqrt3$ . I am trying to apply de Moivre's formula here but cannot find a way to do so. I am not sure if i am approaching this wrong.,Find all values of . I am trying to apply de Moivre's formula here but cannot find a way to do so. I am not sure if i am approaching this wrong.,i^\sqrt3,"['complex-analysis', 'complex-numbers', 'exponentiation']"
11,Density and distributions of those numerically or analytically KNOWN solutions of Riemann $\zeta(1/2 + r i)=0?$,Density and distributions of those numerically or analytically KNOWN solutions of Riemann,\zeta(1/2 + r i)=0?,"We know the conjecture about the Riemann hypothesis is about the nontrivial zeros are on $$(1/2 + r i)$$ for some $r \in \mathbb{R}$ of Riemann zeta function. My question is how much is known about the density and the distributions of those numerically or analytically KNOWN solutions of $$\zeta(1/2 + r i)=0?$$ I found a related post but it was about 8 years ago, so maybe we have a better update? Mean density of the nontrivial zeros of the Riemann zeta function","We know the conjecture about the Riemann hypothesis is about the nontrivial zeros are on for some of Riemann zeta function. My question is how much is known about the density and the distributions of those numerically or analytically KNOWN solutions of I found a related post but it was about 8 years ago, so maybe we have a better update? Mean density of the nontrivial zeros of the Riemann zeta function",(1/2 + r i) r \in \mathbb{R} \zeta(1/2 + r i)=0?,"['complex-analysis', 'number-theory', 'riemann-hypothesis']"
12,Residue Theorem Integral of $\frac{1}{\sinh(x)-1}$,Residue Theorem Integral of,\frac{1}{\sinh(x)-1},"I need help with the integral: $$\int_{-\infty}^\infty\frac{x}{\sinh(x)-1}dx,$$ and I (unfortunately) have to use contour integration techniques. I know how to do the integral $$\int_{-\infty}^\infty\frac{1}{\sinh(x)}dx,$$ so using a similar strategy, I tried integrating $$f(z):=\frac{z}{\sinh(z)-1}$$ around a box of width $2R$ and height $\pi $ centered at the origin. However, $\frac{1}{\sinh(x)-1}$ has poles at $z_n=\ln(2\pm\sqrt{2})+2\pi i n,$ for $n\in\mathbb{N}$ , and so we must make $\epsilon$ bumps around $\log(2\pm\sqrt{2})$ . However, around these bumps, $$\int_{C_\epsilon}f(z)dz=\int_0^\pi\frac{2\log(1\pm\sqrt{2})+2\epsilon e^{-i\theta}}{\log(1\pm \sqrt{2})[e^{\epsilon e^{i\theta}}-e^{-\epsilon e^{-\theta}}]-1}\cdot -i\epsilon e^{-i\theta}d\theta$$ Does this simplify? I'm not sure how to tackle this. I also thought about making a substitution $x\mapsto \ln(x)$ at the very beginning, but the integration bounds that I get confuse me (I get from $-\infty +i\pi$ to $\infty$ ).","I need help with the integral: and I (unfortunately) have to use contour integration techniques. I know how to do the integral so using a similar strategy, I tried integrating around a box of width and height centered at the origin. However, has poles at for , and so we must make bumps around . However, around these bumps, Does this simplify? I'm not sure how to tackle this. I also thought about making a substitution at the very beginning, but the integration bounds that I get confuse me (I get from to ).","\int_{-\infty}^\infty\frac{x}{\sinh(x)-1}dx, \int_{-\infty}^\infty\frac{1}{\sinh(x)}dx, f(z):=\frac{z}{\sinh(z)-1} 2R \pi  \frac{1}{\sinh(x)-1} z_n=\ln(2\pm\sqrt{2})+2\pi i n, n\in\mathbb{N} \epsilon \log(2\pm\sqrt{2}) \int_{C_\epsilon}f(z)dz=\int_0^\pi\frac{2\log(1\pm\sqrt{2})+2\epsilon e^{-i\theta}}{\log(1\pm \sqrt{2})[e^{\epsilon e^{i\theta}}-e^{-\epsilon e^{-\theta}}]-1}\cdot -i\epsilon e^{-i\theta}d\theta x\mapsto \ln(x) -\infty +i\pi \infty","['complex-analysis', 'contour-integration']"
13,Proving $\frac1{2\pi} \int_0^{2\pi} \frac{R^2-r^2}{R^2-2Rr\cos\theta+r^2} d\theta =1$ by integrating $\frac{R+z}{z(R-z)}$ without residue theorem.,Proving  by integrating  without residue theorem.,\frac1{2\pi} \int_0^{2\pi} \frac{R^2-r^2}{R^2-2Rr\cos\theta+r^2} d\theta =1 \frac{R+z}{z(R-z)},"I was given the function: $$ \frac{R+z}{z(R-z)} $$ And I was asked to integrate it around a closed contour to prove: $$\frac1{2\pi} \int_0^{2\pi} \frac{R^2-r^2}{R^2-2Rr\cos\theta+r^2} d\theta =1$$ I've seen people get a proof quite easily by using the residue theorem, but I have not studied it yet so I am not supposed to do it. My attempt: Let $\gamma = re^{it}$ , $$\int_\gamma f dz = \int_\gamma \frac1z + \frac2{R-z} dz$$ $$\Rightarrow \int_\gamma f dz = \int_0^{2\pi} \frac{ire^{it}}{re^{it}}dt + \int_0^{2\pi} \frac{2ire^{it}}{R-re^{it}}dt$$ $$ = 2\pi i + \int_0^{2\pi} \frac{2Rr\cos t + 2r}{R^2+2Rr\cos t + r^2} dt$$ But I don't know what else should I do. Any ideas? Edit: Sorry I had a typo, the function to integrate was $ \frac{R+z}{z(R-z)} $ and not $ \frac{R-z}{z(R-z)} $","I was given the function: And I was asked to integrate it around a closed contour to prove: I've seen people get a proof quite easily by using the residue theorem, but I have not studied it yet so I am not supposed to do it. My attempt: Let , But I don't know what else should I do. Any ideas? Edit: Sorry I had a typo, the function to integrate was and not", \frac{R+z}{z(R-z)}  \frac1{2\pi} \int_0^{2\pi} \frac{R^2-r^2}{R^2-2Rr\cos\theta+r^2} d\theta =1 \gamma = re^{it} \int_\gamma f dz = \int_\gamma \frac1z + \frac2{R-z} dz \Rightarrow \int_\gamma f dz = \int_0^{2\pi} \frac{ire^{it}}{re^{it}}dt + \int_0^{2\pi} \frac{2ire^{it}}{R-re^{it}}dt  = 2\pi i + \int_0^{2\pi} \frac{2Rr\cos t + 2r}{R^2+2Rr\cos t + r^2} dt  \frac{R+z}{z(R-z)}   \frac{R-z}{z(R-z)} ,"['complex-analysis', 'complex-integration']"
14,Complex Analysis Prelim Question,Complex Analysis Prelim Question,,"This is a complex analysis qualifying examination question. I'm an incoming grad student and we get the opportunity to have a freebie attempt on one qualifying exam. I have $\textit{some}$ experience in complex analysis from undergrad, and some of the advanced topics that were not covered have been tricky to learn on my own. So here goes. Let $\mathcal{F}$ be a family of analytic functions on $\mathbb{D}$ (the unit disk).  Suppose that for all $0<r<1$ , \begin{equation}M_r:=\sup_{f\in \mathcal{F}}\int_{\lvert z\rvert=r}\lvert f(z)\rvert \lvert dz\rvert<\infty.\end{equation} Prove that $\mathcal{F}$ is a normal family. From my understanding, this means that I must show that for any sequence $f_n$ in $\mathcal{F}$ , there exists an analytic function $f:\mathbb{D}\rightarrow \mathbb{C}$ and a subsequence $(n_k)$ such that $f_{n_k}\to f$ uniformly on any compact $K\subset \mathbb{D}$ . Here is my proof attempt. Let $f_n$ be a given sequence in $\mathcal{F}$ and $K$ be a compact subset of $\mathbb{D}$ . My goal is to use the Arzela-Ascoli Theorem on $\mathcal{F}$ to prove the existence of the required subsequence and limit function $f$ . We must show that $\mathcal{F}$ is uniformly bounded and equicontinuous. I will only show equicontinuity since uniform boundedness is the same technique. Let $f\in \mathcal{F}$ and $z_1,z_2\in K$ be given. Let also $\varepsilon>0$ be given. Since $K$ is compact, there exists an $r<1$ such that $K\subset \{\lvert z\rvert <r\}$ . Since both $K$ and $\{\lvert z\rvert =r\}$ are compact and disjoint, $d:=\text{dist}(K,\{\lvert z\rvert =r\})>0$ . Pick $\delta=\varepsilon\frac{2\pi d^2}{M_r}$ and suppose $\lvert z_1-z_2\rvert <\delta$ . Then, by Cauchy's Integral Formula, we have \begin{equation} \begin{split} \lvert f(z_1)-f(z_2)\rvert =& \frac{1}{2\pi}\lvert \int_{\lvert z\rvert =r} f(z)\left(\frac{1}{z-z_1}-\frac{1}{z-z_2}\right)dz\rvert\\ \leq & \frac{1}{2\pi}\int_{\lvert z\rvert =r}\lvert f(z)\frac{z_1-z_2}{(z-z_1)(z-z_2)}\rvert \lvert dz\rvert\\ \leq &\frac{\lvert z_1-z_2\rvert}{2\pi d^2}\int_{\lvert z\rvert =r}\lvert f(z)\rvert \lvert dz\rvert \\ \leq &\frac{M_r}{2\pi d^2}\lvert z_1-z_2\rvert \\ <& \varepsilon. \end{split} \end{equation} Then, since $\mathcal{F}$ is equicontinuous and uniformly bounded, by Arzela-Ascoli's theorem, we should be done. However, it only tells me that there is a continuous limit function $f:K\rightarrow \mathbb{C}$ and a subsequence $f_{n_k}\rightarrow f$ uniformly on $K$ . How can I show that this limit function can be extended to all of $\mathbb{D}$ , that it is independent of $K$ and that it is also analytic? I think I'm not seeing whats going on with this whole normal family buisness. Any help is appreciated.","This is a complex analysis qualifying examination question. I'm an incoming grad student and we get the opportunity to have a freebie attempt on one qualifying exam. I have experience in complex analysis from undergrad, and some of the advanced topics that were not covered have been tricky to learn on my own. So here goes. Let be a family of analytic functions on (the unit disk).  Suppose that for all , Prove that is a normal family. From my understanding, this means that I must show that for any sequence in , there exists an analytic function and a subsequence such that uniformly on any compact . Here is my proof attempt. Let be a given sequence in and be a compact subset of . My goal is to use the Arzela-Ascoli Theorem on to prove the existence of the required subsequence and limit function . We must show that is uniformly bounded and equicontinuous. I will only show equicontinuity since uniform boundedness is the same technique. Let and be given. Let also be given. Since is compact, there exists an such that . Since both and are compact and disjoint, . Pick and suppose . Then, by Cauchy's Integral Formula, we have Then, since is equicontinuous and uniformly bounded, by Arzela-Ascoli's theorem, we should be done. However, it only tells me that there is a continuous limit function and a subsequence uniformly on . How can I show that this limit function can be extended to all of , that it is independent of and that it is also analytic? I think I'm not seeing whats going on with this whole normal family buisness. Any help is appreciated.","\textit{some} \mathcal{F} \mathbb{D} 0<r<1 \begin{equation}M_r:=\sup_{f\in \mathcal{F}}\int_{\lvert z\rvert=r}\lvert f(z)\rvert \lvert dz\rvert<\infty.\end{equation} \mathcal{F} f_n \mathcal{F} f:\mathbb{D}\rightarrow \mathbb{C} (n_k) f_{n_k}\to f K\subset \mathbb{D} f_n \mathcal{F} K \mathbb{D} \mathcal{F} f \mathcal{F} f\in \mathcal{F} z_1,z_2\in K \varepsilon>0 K r<1 K\subset \{\lvert z\rvert <r\} K \{\lvert z\rvert =r\} d:=\text{dist}(K,\{\lvert z\rvert =r\})>0 \delta=\varepsilon\frac{2\pi d^2}{M_r} \lvert z_1-z_2\rvert <\delta \begin{equation}
\begin{split}
\lvert f(z_1)-f(z_2)\rvert =& \frac{1}{2\pi}\lvert \int_{\lvert z\rvert =r} f(z)\left(\frac{1}{z-z_1}-\frac{1}{z-z_2}\right)dz\rvert\\
\leq & \frac{1}{2\pi}\int_{\lvert z\rvert =r}\lvert f(z)\frac{z_1-z_2}{(z-z_1)(z-z_2)}\rvert \lvert dz\rvert\\
\leq &\frac{\lvert z_1-z_2\rvert}{2\pi d^2}\int_{\lvert z\rvert =r}\lvert f(z)\rvert \lvert dz\rvert \\
\leq &\frac{M_r}{2\pi d^2}\lvert z_1-z_2\rvert \\
<& \varepsilon.
\end{split}
\end{equation} \mathcal{F} f:K\rightarrow \mathbb{C} f_{n_k}\rightarrow f K \mathbb{D} K",['complex-analysis']
15,Eigenvalues and eigenspaces of almost complex structures under each other [closed],Eigenvalues and eigenspaces of almost complex structures under each other [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Improve this question I started studying the book of Daniel Huybrechts, Complex Geometry An Introduction. I tried studying backwards as much as possible, but I have been stuck on the concepts of almost complex structures and complexification . I have studied several books and articles on the matter including ones by Keith Conrad , Jordan Bell , Gregory W. Moore , Steven Roman , Suetin, Kostrikin and Mainin , Gauthier I have several questions on the concepts of almost complex structures and complexification. Here are some: Let $L$ be $\mathbb C$ -vector space. Let $L_{\mathbb R}$ be its realification, and let the $(L_{\mathbb R})^{\mathbb C} = (L_{\mathbb R}^2,J)$ be the complexification of its realification with almost complex structure $J(l,m):=(-m,l)$ on $L_{\mathbb R}^2$ . For every almost complex structure $K$ on $L_{\mathbb R}$ , $K \oplus K$ is an almost complex structure on $L_{\mathbb R}^2$ . Then $K^{\mathbb C} := (K \oplus K)^J$ (see notation and definitions here , in particular the bullet below 'Definition 4') is $\mathbb C$ -linear, i.e. $K \oplus K$ and $J$ commute. Based on this question , it appears we have that for $K=i^{\sharp}$ , we have that $(K \oplus K)^J$ has the same eigenvalues as $J^{K \oplus K}$ Question 1. For any almost complex structure $K$ on $L_{\mathbb R}$ , does $(K \oplus K)^J$ always have the same eigenvalues as $J^{K \oplus K}$ ? Question 2. For any eigenvalues $(K \oplus K)^J$ and $J^{K \oplus K}$ have in common, do the corresponding eigenspaces have the same underlying sets? I think the answer to both questions is yes and that this need not be only for the case where we have an almost complex structure on $L_{\mathbb R}^2$ that is the realification of a complexification of a map on $L_{\mathbb R}$ (such map must, I think , be an almost complex structure on $L_{\mathbb R}$ ): Question 3. For any almost complex structure $H$ on $L_{\mathbb R}^2$ (not necessarily the realification of a complexification of a map on $L_{\mathbb R}$ ) such that $H$ and $J$ commute, does $H^J$ always have the same eigenvalues as $J^H$ ? Question 4. For any eigenvalues $H^J$ and $J^H$ have in common, do the corresponding eigenspaces have the same underlying sets? Additional questions: Question 5. For any almost complex structures $K$ and $M$ on $L_{\mathbb R}^2$ that commute, are the eigenvalues of $K^M$ a subset of $\{ \pm i\}$ ? Question 6. If yes to Question 5, then is it that $K^K$ has $i$ as its only eigenvalue if $L \ne 0$ and has no eigenvalues if $L=0$ ? (I assume $L=0$ iff $L_{\mathbb R} = 0$ iff $(L_{\mathbb R})^{\mathbb C} = 0$ iff $L_{\mathbb R}^2 = 0$ )","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Improve this question I started studying the book of Daniel Huybrechts, Complex Geometry An Introduction. I tried studying backwards as much as possible, but I have been stuck on the concepts of almost complex structures and complexification . I have studied several books and articles on the matter including ones by Keith Conrad , Jordan Bell , Gregory W. Moore , Steven Roman , Suetin, Kostrikin and Mainin , Gauthier I have several questions on the concepts of almost complex structures and complexification. Here are some: Let be -vector space. Let be its realification, and let the be the complexification of its realification with almost complex structure on . For every almost complex structure on , is an almost complex structure on . Then (see notation and definitions here , in particular the bullet below 'Definition 4') is -linear, i.e. and commute. Based on this question , it appears we have that for , we have that has the same eigenvalues as Question 1. For any almost complex structure on , does always have the same eigenvalues as ? Question 2. For any eigenvalues and have in common, do the corresponding eigenspaces have the same underlying sets? I think the answer to both questions is yes and that this need not be only for the case where we have an almost complex structure on that is the realification of a complexification of a map on (such map must, I think , be an almost complex structure on ): Question 3. For any almost complex structure on (not necessarily the realification of a complexification of a map on ) such that and commute, does always have the same eigenvalues as ? Question 4. For any eigenvalues and have in common, do the corresponding eigenspaces have the same underlying sets? Additional questions: Question 5. For any almost complex structures and on that commute, are the eigenvalues of a subset of ? Question 6. If yes to Question 5, then is it that has as its only eigenvalue if and has no eigenvalues if ? (I assume iff iff iff )","L \mathbb C L_{\mathbb R} (L_{\mathbb R})^{\mathbb C} = (L_{\mathbb R}^2,J) J(l,m):=(-m,l) L_{\mathbb R}^2 K L_{\mathbb R} K \oplus K L_{\mathbb R}^2 K^{\mathbb C} := (K \oplus K)^J \mathbb C K \oplus K J K=i^{\sharp} (K \oplus K)^J J^{K \oplus K} K L_{\mathbb R} (K \oplus K)^J J^{K \oplus K} (K \oplus K)^J J^{K \oplus K} L_{\mathbb R}^2 L_{\mathbb R} L_{\mathbb R} H L_{\mathbb R}^2 L_{\mathbb R} H J H^J J^H H^J J^H K M L_{\mathbb R}^2 K^M \{ \pm i\} K^K i L \ne 0 L=0 L=0 L_{\mathbb R} = 0 (L_{\mathbb R})^{\mathbb C} = 0 L_{\mathbb R}^2 = 0","['linear-algebra', 'abstract-algebra', 'complex-analysis', 'complex-geometry', 'almost-complex']"
16,What is an example of a complex function with a zero of infinite order (other than the zero map $z \to 0$)?,What is an example of a complex function with a zero of infinite order (other than the zero map )?,z \to 0,"I can't find any example other than the zero map which may very well be because there isn't any other. From Taylor's theorem, it seems obvious that the only possible example is the zero map, since the only power series with only zero coefficients is zero.  Is this correct? (The order of a zero is defined here .)","I can't find any example other than the zero map which may very well be because there isn't any other. From Taylor's theorem, it seems obvious that the only possible example is the zero map, since the only power series with only zero coefficients is zero.  Is this correct? (The order of a zero is defined here .)",,['complex-analysis']
17,Looking for a proof for the value of the residue.,Looking for a proof for the value of the residue.,,"Trying to simplify a calculation I have found by numerical experiments the following interesting result: $$ \underset{z=1}{\operatorname{Res}}\frac{z^{p-1}}{(z^n-1)^q}= \frac qp\frac{\left(\frac pn\right)^{\underline{q}}}{q!} \equiv\frac qp\binom{\frac pn}q, $$ where $p,q,n$ are positive integers and $x^{\underline r}=x(x-1)\cdots(x-r+1)$ means the falling factorial. Is there a simple way to prove this?",Trying to simplify a calculation I have found by numerical experiments the following interesting result: where are positive integers and means the falling factorial. Is there a simple way to prove this?,"
\underset{z=1}{\operatorname{Res}}\frac{z^{p-1}}{(z^n-1)^q}=
\frac qp\frac{\left(\frac pn\right)^{\underline{q}}}{q!}
\equiv\frac qp\binom{\frac pn}q,
 p,q,n x^{\underline r}=x(x-1)\cdots(x-r+1)","['complex-analysis', 'residue-calculus', 'laurent-series']"
18,Riemann Sphere as extended complex plane,Riemann Sphere as extended complex plane,,"I was reading some Complex Analysis, and came across this concept that; says you have the extended complex plane which is illustrated as the $x,y$ -plane as the complex plane, and the $z$ -plane is added, so that $(0,0,1)$ is $\infty$ . The book says, "" the hemisphere $z<0$ corresponds to the disk $|z|<1$ and the hemisphere $z>0$ to its outside $|z|>1$ . "" I don't understand why we are considering the entire sphere, when I understood that the extended complex plane was just the x-y-plane, and then we add on the point $(0,0,1)$ . Even if we considered everything in $3$ dimensions, how is it that the top of the sphere corresponds to the inside of a circle on the complex plane, and the bottom half to the outside? Thank you for your explanations/clarifications!","I was reading some Complex Analysis, and came across this concept that; says you have the extended complex plane which is illustrated as the -plane as the complex plane, and the -plane is added, so that is . The book says, "" the hemisphere corresponds to the disk and the hemisphere to its outside . "" I don't understand why we are considering the entire sphere, when I understood that the extended complex plane was just the x-y-plane, and then we add on the point . Even if we considered everything in dimensions, how is it that the top of the sphere corresponds to the inside of a circle on the complex plane, and the bottom half to the outside? Thank you for your explanations/clarifications!","x,y z (0,0,1) \infty z<0 |z|<1 z>0 |z|>1 (0,0,1) 3","['complex-analysis', 'riemann-surfaces', 'riemann-sphere']"
19,a contour integration involving $5$th roots of unity,a contour integration involving th roots of unity,5,"Let $\gamma$ be the circle of radius $2$ with centre at the origin in   the complex plane oriented in the anti-clockwise direction, then the   integral $$\oint_\gamma \frac{dz}{(z-3)(z^5-1)}$$ equals $(a)$ $\displaystyle{\frac{2\pi i}{3^5-1}}$ . $(b)$ $\displaystyle{\frac{2\pi i}{3^4-1}}$ . $(c)$ $\displaystyle{-\frac{2\pi i}{3^5-1}}$ . $(d)$ $0$ . Clearly by Rouche's theorem, all the zeroes of $z^5-1$ lies on the circle $|z|=1$ . So if we count those zeroes by $z_k$ where $k=0,1,2,3,4$ we have, by Residue theorem $$\oint_\gamma \frac{dz}{(z-3)(z^5-1)}=-\frac{2\pi i}{5}\sum_{k=0}^4 \frac{1}{3{z_k}^4-1}$$ which is a nightmare to simplify algebraically. Can someone help in this regard if I have done something wrong? Thanks in advance.","Let be the circle of radius with centre at the origin in   the complex plane oriented in the anti-clockwise direction, then the   integral equals . . . . Clearly by Rouche's theorem, all the zeroes of lies on the circle . So if we count those zeroes by where we have, by Residue theorem which is a nightmare to simplify algebraically. Can someone help in this regard if I have done something wrong? Thanks in advance.","\gamma 2 \oint_\gamma \frac{dz}{(z-3)(z^5-1)} (a) \displaystyle{\frac{2\pi i}{3^5-1}} (b) \displaystyle{\frac{2\pi i}{3^4-1}} (c) \displaystyle{-\frac{2\pi i}{3^5-1}} (d) 0 z^5-1 |z|=1 z_k k=0,1,2,3,4 \oint_\gamma \frac{dz}{(z-3)(z^5-1)}=-\frac{2\pi i}{5}\sum_{k=0}^4 \frac{1}{3{z_k}^4-1}",['complex-analysis']
20,Find the value of $\int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+x^2} dx$ . [duplicate],Find the value of  . [duplicate],\int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+x^2} dx,"This question already has answers here : Methods to solve $\int_{0}^{\infty} \frac{e^{-x^2}}{x^2 + 1}\:dx$ (3 answers) Closed last year . Find the value of $\int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+x^2} dx$ My attempt First, I know the existence of this integral since $$ \mid \int_{-a}^{a} \frac{e^{-x^2}}{1+x^2} dx \mid \;\; \leq\;\;  \mid \int_{-a}^{a} \frac{1}{1+x^2} dx \mid$$ Next, let $R >0 $ be an arbitrary and $\gamma_1(t) = -R(1-t) + Rt , \;\; 0 \leq t \leq1$ and $\gamma_2(t)= Re^{i\pi (t-1)}, \;\; 1 \leq t \leq 2 $ . So, take $f(z) = \frac{e^{-z^2}}{1+z^2}$ . I tried to find the value or upper bound of norm of $$\int_{\gamma_2} \frac{e^{-z^2}}{1+z^2} dz$$ . However, $$ \lvert\int_{\gamma_2} \frac{e^{-z^2}}{1+z^2} dz\rvert \leq  \frac{\text{max}\lvert e^{-z^2}\rvert}{R^2-1}\pi R = \frac{e^{R^2}}{R^2-1}\pi R $$ So, I can't proceed this. May I ask you how to solve this?","This question already has answers here : Methods to solve $\int_{0}^{\infty} \frac{e^{-x^2}}{x^2 + 1}\:dx$ (3 answers) Closed last year . Find the value of My attempt First, I know the existence of this integral since Next, let be an arbitrary and and . So, take . I tried to find the value or upper bound of norm of . However, So, I can't proceed this. May I ask you how to solve this?","\int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+x^2} dx  \mid \int_{-a}^{a} \frac{e^{-x^2}}{1+x^2} dx \mid \;\; \leq\;\;  \mid \int_{-a}^{a} \frac{1}{1+x^2} dx \mid R >0  \gamma_1(t) = -R(1-t) + Rt , \;\; 0 \leq t \leq1 \gamma_2(t)= Re^{i\pi (t-1)}, \;\; 1 \leq t \leq 2  f(z) = \frac{e^{-z^2}}{1+z^2} \int_{\gamma_2} \frac{e^{-z^2}}{1+z^2} dz  \lvert\int_{\gamma_2} \frac{e^{-z^2}}{1+z^2} dz\rvert \leq  \frac{\text{max}\lvert e^{-z^2}\rvert}{R^2-1}\pi R = \frac{e^{R^2}}{R^2-1}\pi R ","['complex-analysis', 'complex-integration']"
21,How to solve this? (Argument of the complex number in complex plane),How to solve this? (Argument of the complex number in complex plane),,"Let the $z \in C$ s.t. $|z-10i|= 6 $ $\newcommand{\Arg}{\operatorname{Arg}}$ Say the $\theta = \Arg(z)$ Find the maximum and minimum value of the $8\sin \theta + 6\cos \theta$ My trial) Trying to solve by picture and graph, I considered $8i\sin \theta + 6\cos \theta$ instead of the $8\sin \theta + 6\cos \theta$ Then, locus of the $8i \sin \theta + 6\cos \theta$ is the tangent line of the  circle $|z-10i|= 6 $ (Surely $ {-4\over 3} \leq \tan \theta \leq {4 \over 3}  $ ) So the question is I can't figure out the next step. P.s.) The answer sheet said ""it is clear that when the case $\cos \theta = \pm{3 \over 5}  $ is maximum and minimum"" But this word totally unclear for me. Why does that case have a max or min value?","Let the s.t. Say the Find the maximum and minimum value of the My trial) Trying to solve by picture and graph, I considered instead of the Then, locus of the is the tangent line of the  circle (Surely ) So the question is I can't figure out the next step. P.s.) The answer sheet said ""it is clear that when the case is maximum and minimum"" But this word totally unclear for me. Why does that case have a max or min value?",z \in C |z-10i|= 6  \newcommand{\Arg}{\operatorname{Arg}} \theta = \Arg(z) 8\sin \theta + 6\cos \theta 8i\sin \theta + 6\cos \theta 8\sin \theta + 6\cos \theta 8i \sin \theta + 6\cos \theta |z-10i|= 6   {-4\over 3} \leq \tan \theta \leq {4 \over 3}   \cos \theta = \pm{3 \over 5}  ,"['complex-analysis', 'optimization', 'complex-numbers', 'maxima-minima', 'cauchy-schwarz-inequality']"
22,"Fourier coefficients are exponentially bounded for a real analytic, periodic function","Fourier coefficients are exponentially bounded for a real analytic, periodic function",,"This question popped up in my exam today, I am curious for a solution. Let $f:\mathbb{R}\to\mathbb{C}$ a real analytic, $2\pi$ -periodic function that is integrable on $[-\pi,\pi]$ . Its Fourier coefficients $c_k$ for $k\in\mathbb{Z}$ are given by $$ c_k=\frac{1}{2\pi}\int_{-\pi}^{\pi}f(x)e^{ikx}dx $$ Then there exists $\Gamma>0$ and $\eta>0$ such that $|c_k|\leq \Gamma e^{-\frac{1}{2}|k|\eta}$ for all $k\in\mathbb{Z}$ .","This question popped up in my exam today, I am curious for a solution. Let a real analytic, -periodic function that is integrable on . Its Fourier coefficients for are given by Then there exists and such that for all .","f:\mathbb{R}\to\mathbb{C} 2\pi [-\pi,\pi] c_k k\in\mathbb{Z} 
c_k=\frac{1}{2\pi}\int_{-\pi}^{\pi}f(x)e^{ikx}dx
 \Gamma>0 \eta>0 |c_k|\leq \Gamma e^{-\frac{1}{2}|k|\eta} k\in\mathbb{Z}","['real-analysis', 'complex-analysis', 'fourier-analysis', 'fourier-series']"
23,Möbius transformations and groups,Möbius transformations and groups,,"I have two questions regarding Möbius transformations and groups. In my notes there are two statements, which I can't prove/understand why they hold. The subgroup of Möbius Transformations which maps the set $\{z_1,z_2,z_3\}$ to itself is isomorphic to $S_3$ , the permutation group of three elements. It is clear that the size of this subgroup and $S_3$ is the same, but what group isomorphism should I use between them? Also, The subgroup of Möbius transformations for which $f(z_1)=z_1$ and $f(z_2)=z_2$ is isomorphic to $\Bbb{C}^*$ where this is the group of $\Bbb{C}\setminus \{0\}$ , under $\times$ . This has really confused me, I'm just not sure how I should be constructing these isomorphisms. Any help appreciated, thanks.","I have two questions regarding Möbius transformations and groups. In my notes there are two statements, which I can't prove/understand why they hold. The subgroup of Möbius Transformations which maps the set to itself is isomorphic to , the permutation group of three elements. It is clear that the size of this subgroup and is the same, but what group isomorphism should I use between them? Also, The subgroup of Möbius transformations for which and is isomorphic to where this is the group of , under . This has really confused me, I'm just not sure how I should be constructing these isomorphisms. Any help appreciated, thanks.","\{z_1,z_2,z_3\} S_3 S_3 f(z_1)=z_1 f(z_2)=z_2 \Bbb{C}^* \Bbb{C}\setminus \{0\} \times","['complex-analysis', 'group-theory', 'conformal-geometry', 'mobius-transformation']"
24,Does complex integration only depend on endpoints?,Does complex integration only depend on endpoints?,,"I have been watching some videos on Complex Analysis and from my understanding, integrating an analytic function over a curve only depends on the endpoints of the curve. If that is true, why does $\int dz/z$ evaluated along the unit circle equal $2\pi i$ instead of $0$ ?","I have been watching some videos on Complex Analysis and from my understanding, integrating an analytic function over a curve only depends on the endpoints of the curve. If that is true, why does evaluated along the unit circle equal instead of ?",\int dz/z 2\pi i 0,"['complex-analysis', 'contour-integration', 'complex-integration']"
25,Apply Green's theorem to prove Goursat's theorem,Apply Green's theorem to prove Goursat's theorem,,"Suppose $f$ is continuously complex differentiable on $\Omega$ , and $T \subset \Omega$ is a triangle whose interior is also contained in $\Omega$ . Apply Green's theorem to show that $$\int_T f(z) \, dz=0$$ This is an exercise in Stein's complex analysis Page $65$ . My attempt: Let $f(z)=u(x,y)+iv(x,y)$ , $dz=dx+idy$ then apply Green's theorem I can get the desire conclusion . But I can not prove that $dz=dx+idy$ , since the definition of integral along a curve only has one variable . $$\int_T f(z) \, dz=\int_a^b f(g(t)) g'(t) \, dt$$","Suppose is continuously complex differentiable on , and is a triangle whose interior is also contained in . Apply Green's theorem to show that This is an exercise in Stein's complex analysis Page . My attempt: Let , then apply Green's theorem I can get the desire conclusion . But I can not prove that , since the definition of integral along a curve only has one variable .","f \Omega T \subset \Omega \Omega \int_T f(z) \, dz=0 65 f(z)=u(x,y)+iv(x,y) dz=dx+idy dz=dx+idy \int_T f(z) \, dz=\int_a^b f(g(t)) g'(t) \, dt",['complex-analysis']
26,Justification for notation of line integrals,Justification for notation of line integrals,,"I am having trouble with notation, specifically how certain substitutions are rigorously made when going back and forth between a line or contour integral and a definite integral. For example if: $$ \phi(\tau) = t \\ \alpha \leq \tau \leq \beta $$ then: $$ \int_a^bw(t)dt = \int_{\alpha}^{\beta}w(\phi(\tau))\phi'(\tau)d\tau $$ It appears that $dt = \phi(\tau)d\tau$ But I always thought $dt$ was just a symbol that told us which variable we are integrating with respect to. So it seems very wishy-washy to make this substitution. Question: How can I understand this rigorously enough that I don't feel guilty making the substitution when I am working problems? Also, how do I justify the change of variables on the bounds? To clarify my question, I am seeking a rigorous algebraic explanation. I vaguely understand the larger idea behind the paramaterization, but I want to see all the substitutions made rigorously, step by step with no hand waving. This seems to have been neglected in my classes, and it's killing me.","I am having trouble with notation, specifically how certain substitutions are rigorously made when going back and forth between a line or contour integral and a definite integral. For example if: then: It appears that But I always thought was just a symbol that told us which variable we are integrating with respect to. So it seems very wishy-washy to make this substitution. Question: How can I understand this rigorously enough that I don't feel guilty making the substitution when I am working problems? Also, how do I justify the change of variables on the bounds? To clarify my question, I am seeking a rigorous algebraic explanation. I vaguely understand the larger idea behind the paramaterization, but I want to see all the substitutions made rigorously, step by step with no hand waving. This seems to have been neglected in my classes, and it's killing me.","
\phi(\tau) = t \\ \alpha \leq \tau \leq \beta
 
\int_a^bw(t)dt = \int_{\alpha}^{\beta}w(\phi(\tau))\phi'(\tau)d\tau
 dt = \phi(\tau)d\tau dt","['complex-analysis', 'multivariable-calculus']"
27,Gradient of a complex valued matrix function but with real domain,Gradient of a complex valued matrix function but with real domain,,"Let $f: \mathbb{C}^{N\times M}\rightarrow \mathbb{R}$ and $g: \mathbb{R}^{N\times M}\rightarrow \mathbb{C}^{N \times M}, N\geq M $ and $F = f \circ g$ . I am trying to compute the gradient of $F$ w.r.t. $\mathbf{X} \in \mathbb{R}^{N\times M}$ , i.e., $\nabla_\mathbf{X} f(g(\mathbf{X}))$ but I am struggling with the chain rule because of the complex domain. What is the dimension of the final gradient matrix? As an example, I have: $g(\mathbf{X})=e^{i\mathbf{X}}$ and $f(\mathbf{Y})=|| \mathbf{A}-\mathbf{YB}||_F^2$ ( $\mathbf{A}$ and $\mathbf{B}$ complex as well). Thank you in advance.","Let and and . I am trying to compute the gradient of w.r.t. , i.e., but I am struggling with the chain rule because of the complex domain. What is the dimension of the final gradient matrix? As an example, I have: and ( and complex as well). Thank you in advance.","f: \mathbb{C}^{N\times M}\rightarrow \mathbb{R} g: \mathbb{R}^{N\times M}\rightarrow \mathbb{C}^{N \times M}, N\geq M  F = f \circ g F \mathbf{X} \in \mathbb{R}^{N\times M} \nabla_\mathbf{X} f(g(\mathbf{X})) g(\mathbf{X})=e^{i\mathbf{X}} f(\mathbf{Y})=|| \mathbf{A}-\mathbf{YB}||_F^2 \mathbf{A} \mathbf{B}","['linear-algebra', 'complex-analysis', 'matrix-calculus']"
28,Nonstandard Complex Numbers,Nonstandard Complex Numbers,,"There is an aspect of Non-Standard Analysis that for quite some time I cannot get my head around. I have done some research on this platform to avoid an exact double answer, or one that could be derived, but I still find my question unanswered. I'm happy to receive links to the threads I missed. So, one can construct Non-Standard reals, say via an ultrafilter. Then, infinitesimals in the nonstandard realm are the equivalence classes of null sequences. Infinite nonstandard reals are equivalence classes of real sequences that are unbounded (positive and negative sign) For alternating sequences like (-1, +1, -1, +1,...), there is an infinite set in the ultrafilter that does determine which of the +1, -1 it is. So all hyperreals are (representatives of equivalence classes of) sequences. Now, as so many other questions ask, what happens with $\mathbb{C}$? It is clear that the hyperreals are elementary equivalent to the reals, and categoricity for the complex numbers make them isomorphic to any completion of the hyperreals in that same sense. So what happens to all the infinitesimals? Do the hyperreal non-zero infinitesimals suddenly become hyperreal complex null-sequences? While when going the 'standard way' they should be zero all along? In particular, what is the function $f$ in the following diagram: $\require{AMScd}$ \begin{CD}     \mathbb{R} @>N>> \mathbb{R}^*\\     @Vc  V V @VV  CV\\     \mathbb{C} @>>f> \mathbb{C}\equiv\mathbb{C}^{*} \end{CD} Here, $N$ is the usual ultrapower embedding, $c$ and $C$ are the respective algebraic completions. The particular question is, what happens to $(1/n)_{n\in\mathbb{N}}$? That is a non-zero infinitesimal, equivalent to zero taking standard parts, so it should be a zero non-standard complex number, but cannot be going the non-standard complex way. What is wrong with this? Or rather, what implicit projection are we missing? And for the set theorists, what kind of cardinal do we need to exist for this to work?","There is an aspect of Non-Standard Analysis that for quite some time I cannot get my head around. I have done some research on this platform to avoid an exact double answer, or one that could be derived, but I still find my question unanswered. I'm happy to receive links to the threads I missed. So, one can construct Non-Standard reals, say via an ultrafilter. Then, infinitesimals in the nonstandard realm are the equivalence classes of null sequences. Infinite nonstandard reals are equivalence classes of real sequences that are unbounded (positive and negative sign) For alternating sequences like (-1, +1, -1, +1,...), there is an infinite set in the ultrafilter that does determine which of the +1, -1 it is. So all hyperreals are (representatives of equivalence classes of) sequences. Now, as so many other questions ask, what happens with $\mathbb{C}$? It is clear that the hyperreals are elementary equivalent to the reals, and categoricity for the complex numbers make them isomorphic to any completion of the hyperreals in that same sense. So what happens to all the infinitesimals? Do the hyperreal non-zero infinitesimals suddenly become hyperreal complex null-sequences? While when going the 'standard way' they should be zero all along? In particular, what is the function $f$ in the following diagram: $\require{AMScd}$ \begin{CD}     \mathbb{R} @>N>> \mathbb{R}^*\\     @Vc  V V @VV  CV\\     \mathbb{C} @>>f> \mathbb{C}\equiv\mathbb{C}^{*} \end{CD} Here, $N$ is the usual ultrapower embedding, $c$ and $C$ are the respective algebraic completions. The particular question is, what happens to $(1/n)_{n\in\mathbb{N}}$? That is a non-zero infinitesimal, equivalent to zero taking standard parts, so it should be a zero non-standard complex number, but cannot be going the non-standard complex way. What is wrong with this? Or rather, what implicit projection are we missing? And for the set theorists, what kind of cardinal do we need to exist for this to work?",,"['real-analysis', 'complex-analysis', 'logic', 'set-theory', 'nonstandard-analysis']"
29,"Angle Function - Problem 1-8, Lee","Angle Function - Problem 1-8, Lee",,"This is Problem 1-8 from Lee's Introduction To Smooth Manifolds . I'm having trouble with this problem. Here are some strategies I've thought of: For the forward direction, I was thinking of assuming on the contrary that $U = \mathbb{S}^1$ and showing a contradiction that $\text{Image}(\theta)$ is not closed and hence not compact in $\mathbb{R}$ but $\mathbb{S}^1$ is compact, $\theta$ is continuous, and $\theta$ is surjective from $\mathbb{S}^1$ to $\text{Image}(\theta)$. I've thought about using complex logarithms to solve for $\theta(z)$ and note that the logarithm has a branch cut, but I don't think that's a good approach because there are many ways to solve a complex exponential equation, other than using logarithms. For the backward direction, I think I know what to do: Assume $U \neq \mathbb{S}^1$, which means that $U$ fails to contain at least one point in $\mathbb{S}^1$. We can find a complex logarithm which has a branch cut at this missing point and solve for $\theta(z)$, where it is continuous everywhere except this branch cut point. For the last problem, I'm not sure what to do.","This is Problem 1-8 from Lee's Introduction To Smooth Manifolds . I'm having trouble with this problem. Here are some strategies I've thought of: For the forward direction, I was thinking of assuming on the contrary that $U = \mathbb{S}^1$ and showing a contradiction that $\text{Image}(\theta)$ is not closed and hence not compact in $\mathbb{R}$ but $\mathbb{S}^1$ is compact, $\theta$ is continuous, and $\theta$ is surjective from $\mathbb{S}^1$ to $\text{Image}(\theta)$. I've thought about using complex logarithms to solve for $\theta(z)$ and note that the logarithm has a branch cut, but I don't think that's a good approach because there are many ways to solve a complex exponential equation, other than using logarithms. For the backward direction, I think I know what to do: Assume $U \neq \mathbb{S}^1$, which means that $U$ fails to contain at least one point in $\mathbb{S}^1$. We can find a complex logarithm which has a branch cut at this missing point and solve for $\theta(z)$, where it is continuous everywhere except this branch cut point. For the last problem, I'm not sure what to do.",,"['complex-analysis', 'differential-geometry']"
30,Existence and uniqueness of 2nd order linear differential equations,Existence and uniqueness of 2nd order linear differential equations,,"I know that the equation $$\frac{d^{2}x}{dt^{2}}+p\left(t\right)\frac{dx}{dt}+q\left(t\right)x=g\left(t\right),$$ has a unique solution on open sets where $p\left(t\right),q\left(t\right)$ and $g\left(t\right)$ are continuous.  What I was wondering if this fact could be derived from the Picard's Theorem on Uniqueness and Existence of First ODE making the usual substitution $y=x'$ and $y_0=x(t_0)$. If so, why  $p\left(t\right),q\left(t\right)$ do not need to be Lipschitz and only need to be continuous?","I know that the equation $$\frac{d^{2}x}{dt^{2}}+p\left(t\right)\frac{dx}{dt}+q\left(t\right)x=g\left(t\right),$$ has a unique solution on open sets where $p\left(t\right),q\left(t\right)$ and $g\left(t\right)$ are continuous.  What I was wondering if this fact could be derived from the Picard's Theorem on Uniqueness and Existence of First ODE making the usual substitution $y=x'$ and $y_0=x(t_0)$. If so, why  $p\left(t\right),q\left(t\right)$ do not need to be Lipschitz and only need to be continuous?",,"['real-analysis', 'complex-analysis', 'ordinary-differential-equations', 'analysis']"
31,Fibres of a Holomorphic Function,Fibres of a Holomorphic Function,,"Let $f$ : $U\rightarrow V$ be a proper holomorphic map where $U$ and $V$ are open subsets of $\mathbb{C}$ with $V$ connected. Show that the cardinality of the fibres of $f$, i.e. $f^{-1}(\{z\})$ counted with the multiplicities are the same for each $z \in$ $V$. This looks like the property of covering maps and so I was trying to prove if $f$ is a local homeomorphism or a covering map, but to no avail. Thanks for any help.","Let $f$ : $U\rightarrow V$ be a proper holomorphic map where $U$ and $V$ are open subsets of $\mathbb{C}$ with $V$ connected. Show that the cardinality of the fibres of $f$, i.e. $f^{-1}(\{z\})$ counted with the multiplicities are the same for each $z \in$ $V$. This looks like the property of covering maps and so I was trying to prove if $f$ is a local homeomorphism or a covering map, but to no avail. Thanks for any help.",,['complex-analysis']
32,Zeroes of the Fourier transform of bump functions,Zeroes of the Fourier transform of bump functions,,"$f(x)$ is a 1D bump function which real, even and compactly supported in the interval $[-a,a]$, and strictly positive within that interval. Are there any guarantees on the Fourier transform of $f(x)$, $$ \hat{f}(s) = \int_{-\infty}^{\infty} f(x) \exp(-2 \pi i x s)  dx $$ having at least one root in the interval $[-\frac{1}{a},\frac{1}{a}]$? Given that $f(x)$ is real and even, $|\hat{f}(s)|$ will also be real, and my intuition leads me to believe the above is true but I didn't find any theorem related to it. I've moved the followup question to a new page so I could mark the answer to the first one here.","$f(x)$ is a 1D bump function which real, even and compactly supported in the interval $[-a,a]$, and strictly positive within that interval. Are there any guarantees on the Fourier transform of $f(x)$, $$ \hat{f}(s) = \int_{-\infty}^{\infty} f(x) \exp(-2 \pi i x s)  dx $$ having at least one root in the interval $[-\frac{1}{a},\frac{1}{a}]$? Given that $f(x)$ is real and even, $|\hat{f}(s)|$ will also be real, and my intuition leads me to believe the above is true but I didn't find any theorem related to it. I've moved the followup question to a new page so I could mark the answer to the first one here.",,"['complex-analysis', 'fourier-analysis', 'roots', 'harmonic-analysis']"
33,"Evaluating definite integral $\int_0^{2\pi} \frac{1}{13-5\sin\theta}\,\mathrm{d}\theta$",Evaluating definite integral,"\int_0^{2\pi} \frac{1}{13-5\sin\theta}\,\mathrm{d}\theta","Question : $$\int_0^{2\pi} \frac{1}{13-5\sin\theta}\,\mathrm{d}\theta$$ is equals to (a) $-\frac\pi6$ (b) $-\frac{\pi}{12}$ (c) $\frac\pi{12}$ (d) $\frac\pi6$ My attempt : Denoting given integral by $I$ and letting $z=e^{iθ}$ then given integral becomes, \begin{align*} I&=\int_C\frac{1}{13-5(\frac{z-\bar{z}}{2i})}\frac{\mathrm dz}{iz}\\ &=\frac{1}{i}\int_C\frac{2i}{26iz-5z^2+5|z|^2}\mathrm dz\\ &=2\int_C\frac{\mathrm dz}{-5z^2+26iz+5}\hspace{0.5in}\text{As }C: |z|=1\\ &=2\int_C \frac{\mathrm dz}{(z-5i)(z-i/5)}\\ &=2\left(\frac{5}{24i}\int_C\frac{1}{z-5i}-\frac{5}{24i}\int_C \frac{1}{z-i/5}\right) \end{align*} Now as point $z=5i$ lies outside $C$ so it's integral evaluates to $0$ and by Cauchy integral formula, above becomes, $$I=0-2\frac{5}{24i}2\pi i = -\frac{5\pi}{6}$$ But none of the given answer matches with mine. So is am i incorrect? Please help me..stuck on this from hours...","Question : $$\int_0^{2\pi} \frac{1}{13-5\sin\theta}\,\mathrm{d}\theta$$ is equals to (a) $-\frac\pi6$ (b) $-\frac{\pi}{12}$ (c) $\frac\pi{12}$ (d) $\frac\pi6$ My attempt : Denoting given integral by $I$ and letting $z=e^{iθ}$ then given integral becomes, \begin{align*} I&=\int_C\frac{1}{13-5(\frac{z-\bar{z}}{2i})}\frac{\mathrm dz}{iz}\\ &=\frac{1}{i}\int_C\frac{2i}{26iz-5z^2+5|z|^2}\mathrm dz\\ &=2\int_C\frac{\mathrm dz}{-5z^2+26iz+5}\hspace{0.5in}\text{As }C: |z|=1\\ &=2\int_C \frac{\mathrm dz}{(z-5i)(z-i/5)}\\ &=2\left(\frac{5}{24i}\int_C\frac{1}{z-5i}-\frac{5}{24i}\int_C \frac{1}{z-i/5}\right) \end{align*} Now as point $z=5i$ lies outside $C$ so it's integral evaluates to $0$ and by Cauchy integral formula, above becomes, $$I=0-2\frac{5}{24i}2\pi i = -\frac{5\pi}{6}$$ But none of the given answer matches with mine. So is am i incorrect? Please help me..stuck on this from hours...",,"['complex-analysis', 'definite-integrals', 'line-integrals', 'cauchy-integral-formula']"
34,Elliptic points are isolated?,Elliptic points are isolated?,,"I'm reading A First Course in Modular Forms by Diamond and Shurman and am confused on a small point in Chapter 2.  Let $\Gamma$ be a congruence subgroup of $\operatorname{SL}_2(\mathbb Z)$ . $\gamma \in \mathscr H$ is called an elliptic point for $\Gamma$ if the stablizer of $\gamma$ in $\operatorname{PSL}_2$ is nontrivial. Proposition 2.1.1 Let $\tau_1, \tau_2 \in \mathscr H$ be given.  There exist open neighborhoods $U_i$ of $\tau_i$ in $\mathscr H$ such that if $\gamma \in \operatorname{SL}_2(\mathbb Z), \gamma(U_1) \cap U_2 \neq \emptyset$ , then $\gamma(\tau_1) = \tau_2$ . Corollary 2.2.3 Let $\Gamma$ be a congruence subgroup of $\operatorname{SL}_2(\mathbb Z)$ .  Each point $\tau \in \mathscr H$ has a neighborhood $U$ in $\mathscr H$ such that $\gamma \in \Gamma, \gamma(U) \cap U \neq \emptyset$ implies $\gamma \in \operatorname{Stab} \tau$ .  Such a neighborhood has no elliptic points except possibly $\tau$ . Taking $\tau = \tau_1 = \tau_2$ and $U = U_1 \cap U_2$ in the proposition implies everything in the corollary except for the last sentence.  How do we know that we can choose $U$ small enough to exclude all elliptic points?  In other words, how do we know that the elliptic points in $\mathscr H$ form a discrete set?","I'm reading A First Course in Modular Forms by Diamond and Shurman and am confused on a small point in Chapter 2.  Let be a congruence subgroup of . is called an elliptic point for if the stablizer of in is nontrivial. Proposition 2.1.1 Let be given.  There exist open neighborhoods of in such that if , then . Corollary 2.2.3 Let be a congruence subgroup of .  Each point has a neighborhood in such that implies .  Such a neighborhood has no elliptic points except possibly . Taking and in the proposition implies everything in the corollary except for the last sentence.  How do we know that we can choose small enough to exclude all elliptic points?  In other words, how do we know that the elliptic points in form a discrete set?","\Gamma \operatorname{SL}_2(\mathbb Z) \gamma \in \mathscr H \Gamma \gamma \operatorname{PSL}_2 \tau_1, \tau_2 \in \mathscr H U_i \tau_i \mathscr H \gamma \in \operatorname{SL}_2(\mathbb Z), \gamma(U_1) \cap U_2 \neq \emptyset \gamma(\tau_1) = \tau_2 \Gamma \operatorname{SL}_2(\mathbb Z) \tau \in \mathscr H U \mathscr H \gamma \in \Gamma, \gamma(U) \cap U \neq \emptyset \gamma \in \operatorname{Stab} \tau \tau \tau = \tau_1 = \tau_2 U = U_1 \cap U_2 U \mathscr H","['complex-analysis', 'number-theory', 'modular-forms']"
35,Existence of distinct roots of a shifted complex polynomial,Existence of distinct roots of a shifted complex polynomial,,"Question: Let $f(x)\in \mathbb{C}[x]$. Does there always exist some $\alpha \in \mathbb{C}$ such that $g(x):=f(x)-\alpha$ has distinct roots? My intuition leads me to believe this is true. For a simple example, if $f(x)=x^n$ then we can set $\alpha=1$ so that the roots of $g(x)$ are the $n$th roots of unity. Proceeding via contradiction, if there were some $f(x)$ such that for all $\alpha\in \mathbb{C}$, $g(x)$ does not have distinct roots, what goes wrong? Taking this route, such a $g(x)$ would be inseparable, so for any $\alpha$ we see that $g(x)$ would always have a common root with its derivative. Can anyone find a contradiction? Is there a simple direct proof? Is the statement incorrect and can someone provide a counterexample?","Question: Let $f(x)\in \mathbb{C}[x]$. Does there always exist some $\alpha \in \mathbb{C}$ such that $g(x):=f(x)-\alpha$ has distinct roots? My intuition leads me to believe this is true. For a simple example, if $f(x)=x^n$ then we can set $\alpha=1$ so that the roots of $g(x)$ are the $n$th roots of unity. Proceeding via contradiction, if there were some $f(x)$ such that for all $\alpha\in \mathbb{C}$, $g(x)$ does not have distinct roots, what goes wrong? Taking this route, such a $g(x)$ would be inseparable, so for any $\alpha$ we see that $g(x)$ would always have a common root with its derivative. Can anyone find a contradiction? Is there a simple direct proof? Is the statement incorrect and can someone provide a counterexample?",,"['abstract-algebra', 'complex-analysis', 'geometry', 'analysis', 'factoring']"
36,How to find the set of $c$ for which the Julia set of $x^2+c$ completely lies in $\mathbb{R}$?,How to find the set of  for which the Julia set of  completely lies in ?,c x^2+c \mathbb{R},"How to find the set of $c$ for which the Julia set of $x^2+c$ completely lies in $\mathbb{R}$? I know that $c=-2$ must satisfies this because $J(x^2-2)=[-2,2]\in \mathbb{R}$. However, for other $c$, it's quite hard to analyze. Also, Is the part of a $J$ in $\mathbb{R}$ always a fractal except for $c=0$ or $c=-2$?","How to find the set of $c$ for which the Julia set of $x^2+c$ completely lies in $\mathbb{R}$? I know that $c=-2$ must satisfies this because $J(x^2-2)=[-2,2]\in \mathbb{R}$. However, for other $c$, it's quite hard to analyze. Also, Is the part of a $J$ in $\mathbb{R}$ always a fractal except for $c=0$ or $c=-2$?",,"['complex-analysis', 'fractals', 'complex-dynamics']"
37,Cauchy's Theorem on Path Integrals,Cauchy's Theorem on Path Integrals,,"Cauchy's Integral theorem: Let $U$ be a convex open set and suppose $f$ is a function which is analytic on $U$, except possibly at one point, where it is at least continuous. Then $$\int_{\gamma} f(z) dz=0$$ for every closed path in $U$. Let $\gamma$ trace the unit circle centered at $0+0i$ in the anticlockwise direction on the set $\mathbb{C}$. Then, $\int_{\gamma} \frac{1}{z^2} dz = 0$, which makes sense. But then why does $\int_{\gamma} \frac{1}{z} dz = 2\pi i$? Both $\frac{1}{z}$ and $\frac{1}{z^2}$ are not defined at $z=0$, but then how does Cauchy's theorem only apply to the latter?","Cauchy's Integral theorem: Let $U$ be a convex open set and suppose $f$ is a function which is analytic on $U$, except possibly at one point, where it is at least continuous. Then $$\int_{\gamma} f(z) dz=0$$ for every closed path in $U$. Let $\gamma$ trace the unit circle centered at $0+0i$ in the anticlockwise direction on the set $\mathbb{C}$. Then, $\int_{\gamma} \frac{1}{z^2} dz = 0$, which makes sense. But then why does $\int_{\gamma} \frac{1}{z} dz = 2\pi i$? Both $\frac{1}{z}$ and $\frac{1}{z^2}$ are not defined at $z=0$, but then how does Cauchy's theorem only apply to the latter?",,"['complex-analysis', 'complex-numbers']"
38,Compute the Integral via Residue Theorem,Compute the Integral via Residue Theorem,,"My goal is to compute $$I=\int_{0}^{+∞}\frac{\cos{ax}}{1+x^2}dx$$ where $a>0$. $$I=\frac{1}{2}\int_{-∞}^{+∞}\frac{\cos{ax}}{1+x^2}dx=\frac{1}{2}Re\bigg(\int_{-∞}^{+∞}\frac{e^{iax}}{1+x^2}dx\bigg)$$. Let $f(z)=\frac{e^{iaz}}{1+z^2}$. By Residue Theorem, $\int_{-R}^{R}\frac{e^{iax}}{1+x^2}dx+\int_{\gamma_R}\frac{e^{iaz}}{1+z^2}dz=2\pi Res(f,i)=\frac{e^{-a}}{2i}$, where $\gamma_R$ denotes the upper semi-circle centered at $O$ with radius $R$. As $R$—>$+∞$, $\int_{-R}^{R}\frac{e^{iax}}{1+x^2}dx$ —> $\int_{-∞}^{+∞}\frac{e^{iax}}{1+x^2}dx$ Now, I am stuck on how to prove $\int_{\gamma_R}\frac{e^{iaz}}{1+z^2}dz$ goes to $0$ as $R$ goes to infinity. Anyone know how to do it? Many thanks.","My goal is to compute $$I=\int_{0}^{+∞}\frac{\cos{ax}}{1+x^2}dx$$ where $a>0$. $$I=\frac{1}{2}\int_{-∞}^{+∞}\frac{\cos{ax}}{1+x^2}dx=\frac{1}{2}Re\bigg(\int_{-∞}^{+∞}\frac{e^{iax}}{1+x^2}dx\bigg)$$. Let $f(z)=\frac{e^{iaz}}{1+z^2}$. By Residue Theorem, $\int_{-R}^{R}\frac{e^{iax}}{1+x^2}dx+\int_{\gamma_R}\frac{e^{iaz}}{1+z^2}dz=2\pi Res(f,i)=\frac{e^{-a}}{2i}$, where $\gamma_R$ denotes the upper semi-circle centered at $O$ with radius $R$. As $R$—>$+∞$, $\int_{-R}^{R}\frac{e^{iax}}{1+x^2}dx$ —> $\int_{-∞}^{+∞}\frac{e^{iax}}{1+x^2}dx$ Now, I am stuck on how to prove $\int_{\gamma_R}\frac{e^{iaz}}{1+z^2}dz$ goes to $0$ as $R$ goes to infinity. Anyone know how to do it? Many thanks.",,"['complex-analysis', 'improper-integrals', 'residue-calculus', 'complex-integration']"
39,Prove the solutions to the equation $z^n=1$.,Prove the solutions to the equation .,z^n=1,"Fix a positive integer $n$. Prove that the solutions to the equation $z^n=1$ are precisely $$z=e^{2\pi i \frac{m}{n}}$$ where $m \in \mathbb Z$. $Hint:$ To show that every solution of $z^n=1$ is of this form, first prove that it must be of the form $z=e^{2\pi i \frac{a}{n}}$ for some $a \in \mathbb R$, then write $a=m+b$ for some integer $m$ and some real number $0 \leq b <1$, and then argue $b=0$. I am confused about the hint, since by writing out $$1=e^{i2m\pi}$$ where $m \in \mathbb Z$ we can get $$z=e^{2\pi i \frac{m}{n}}$$ immediately. So what does the hint mean? Thank you for any help!","Fix a positive integer $n$. Prove that the solutions to the equation $z^n=1$ are precisely $$z=e^{2\pi i \frac{m}{n}}$$ where $m \in \mathbb Z$. $Hint:$ To show that every solution of $z^n=1$ is of this form, first prove that it must be of the form $z=e^{2\pi i \frac{a}{n}}$ for some $a \in \mathbb R$, then write $a=m+b$ for some integer $m$ and some real number $0 \leq b <1$, and then argue $b=0$. I am confused about the hint, since by writing out $$1=e^{i2m\pi}$$ where $m \in \mathbb Z$ we can get $$z=e^{2\pi i \frac{m}{n}}$$ immediately. So what does the hint mean? Thank you for any help!",,"['complex-analysis', 'complex-numbers']"
40,"If $a,b,c$ are three complex numbers Find possible values of $\lvert a+b+c \rvert$ [duplicate]",If  are three complex numbers Find possible values of  [duplicate],"a,b,c \lvert a+b+c \rvert","This question already has an answer here : Find the possible values of |A + B + C | (1 answer) Closed 6 years ago . Given three complex numbers $a,b,c$ such that $\lvert a \rvert=\lvert b \rvert=\lvert c \rvert=1$ and $$\frac{a^2}{bc}+\frac{b^2}{ac}+\frac{c^2}{ab}=-1$$ Find which of the following are possible values of $\lvert a+b+c \rvert$ A)0 B)2 C)1.5 D)3 My try: I assumed $a=e^{ix}$,$b=e^{iy}$, $c=e^{iz}$ Then we have $$\cos (2x-y-z)+\cos (2y-x-z)+\cos (2z-x-y)=-1$$ $$\sin(2x-y-z)+\sin (2y-x-z)+\sin (2z-x-y)=0$$ Squaring and adding we get $$3+2(\cos(3x-3y)+\cos(3y-3z)+\cos (3z-3x)=1$$ So $$\cos(3x-3y)+\cos(3y-3z)+\cos (3z-3x)=-1$$ any clue here?","This question already has an answer here : Find the possible values of |A + B + C | (1 answer) Closed 6 years ago . Given three complex numbers $a,b,c$ such that $\lvert a \rvert=\lvert b \rvert=\lvert c \rvert=1$ and $$\frac{a^2}{bc}+\frac{b^2}{ac}+\frac{c^2}{ab}=-1$$ Find which of the following are possible values of $\lvert a+b+c \rvert$ A)0 B)2 C)1.5 D)3 My try: I assumed $a=e^{ix}$,$b=e^{iy}$, $c=e^{iz}$ Then we have $$\cos (2x-y-z)+\cos (2y-x-z)+\cos (2z-x-y)=-1$$ $$\sin(2x-y-z)+\sin (2y-x-z)+\sin (2z-x-y)=0$$ Squaring and adding we get $$3+2(\cos(3x-3y)+\cos(3y-3z)+\cos (3z-3x)=1$$ So $$\cos(3x-3y)+\cos(3y-3z)+\cos (3z-3x)=-1$$ any clue here?",,"['complex-analysis', 'trigonometry', 'complex-numbers']"
41,"A function $f$ is analytic in $ D=D(0,1)$ and $f(0)=f'(0)=0$",A function  is analytic in  and,"f  D=D(0,1) f(0)=f'(0)=0","A function $f$ is analytic in $ D=D(0,1)$ and $f(0)=f'(0)=0$ and that $|f'(z)|\leq 1$ for every $z \in D.$ Prove that $|f(z)|\leq |z|^2/2$ for every $z \in D.$ I always have problems to get an inequality for $f$ from $f'.$ I can note this is similar to one version of Schwarz's Lemma: ""If $f$ is analytic in the unitary disk $\mathbb D$ and $f(0)=0$ and for every $z \in \mathbb D$ then $|f(z)|\leq |z|.$ Thanks so much!","A function is analytic in and and that for every Prove that for every I always have problems to get an inequality for from I can note this is similar to one version of Schwarz's Lemma: ""If is analytic in the unitary disk and and for every then Thanks so much!","f  D=D(0,1) f(0)=f'(0)=0 |f'(z)|\leq 1 z \in D. |f(z)|\leq |z|^2/2 z \in D. f f'. f \mathbb D f(0)=0 z \in \mathbb D |f(z)|\leq |z|.","['complex-analysis', 'maximum-principle']"
42,Proving $\int_{0}^\pi \frac{2\cos 2\theta + \cos 3\theta}{5+4\cos\theta} = \frac{\pi}{8}$,Proving,\int_{0}^\pi \frac{2\cos 2\theta + \cos 3\theta}{5+4\cos\theta} = \frac{\pi}{8},"Given that $$\int_{|z|=1|}\frac{z^2}{2z+1} dz = \frac{i\pi}{4}$$, show $$\int_{0}^\pi \frac{2\cos 2 \theta + \cos 3\theta}{5+4\cos\theta} = \frac{\pi}{8}$$. I saw the bounds of the latter integral and thought that I should try and parametrize using $z = e^{2i\theta}$ where $\theta \in [0,\pi]$. This doesn't seem to simplify easily. i saw this thread: Show that $\int_0^\pi\frac{2\cos(2\theta)+\cos(3\theta)}{5+4\cos(\theta)}d\theta=\frac{\pi}{8}$ and the top answer says: $$\begin{align} \int_0^\pi \frac{2\cos(2\theta)+\cos(3\theta)}{5+4\cos(\theta)}\,d\theta&=\frac12\text{Re}\left(\oint_{|z|=1}\frac{2z^2+z^3}{5+2(z+z^{-1})}\,\frac{1}{iz}\,dz\right)\\\\\end{align}$$ which I don't understand. How does multiplying a half to the integral with contour $|z|=1$ (parametrized by $z = e^{i\theta}, \theta\in [0,2\pi]$) give the LHS? I tried looking at it by taking the latter integral and using the substitution $u=\pi + \theta$, in hopes that the integrand simplifies to stay the same but it doesn't, so I can't see why the integral with bounds $0,\pi$ is half the integral that would have bounds $0,2\pi$ (since we would use the parametrization $z=e^{i\theta}$).","Given that $$\int_{|z|=1|}\frac{z^2}{2z+1} dz = \frac{i\pi}{4}$$, show $$\int_{0}^\pi \frac{2\cos 2 \theta + \cos 3\theta}{5+4\cos\theta} = \frac{\pi}{8}$$. I saw the bounds of the latter integral and thought that I should try and parametrize using $z = e^{2i\theta}$ where $\theta \in [0,\pi]$. This doesn't seem to simplify easily. i saw this thread: Show that $\int_0^\pi\frac{2\cos(2\theta)+\cos(3\theta)}{5+4\cos(\theta)}d\theta=\frac{\pi}{8}$ and the top answer says: $$\begin{align} \int_0^\pi \frac{2\cos(2\theta)+\cos(3\theta)}{5+4\cos(\theta)}\,d\theta&=\frac12\text{Re}\left(\oint_{|z|=1}\frac{2z^2+z^3}{5+2(z+z^{-1})}\,\frac{1}{iz}\,dz\right)\\\\\end{align}$$ which I don't understand. How does multiplying a half to the integral with contour $|z|=1$ (parametrized by $z = e^{i\theta}, \theta\in [0,2\pi]$) give the LHS? I tried looking at it by taking the latter integral and using the substitution $u=\pi + \theta$, in hopes that the integrand simplifies to stay the same but it doesn't, so I can't see why the integral with bounds $0,\pi$ is half the integral that would have bounds $0,2\pi$ (since we would use the parametrization $z=e^{i\theta}$).",,['complex-analysis']
43,If $f$ is holomorphic on an open unit disc. Then $|f'(z)|\le \frac{1}{1-|z|}$,If  is holomorphic on an open unit disc. Then,f |f'(z)|\le \frac{1}{1-|z|},"Let $f$ be a holomorphic map of the open unit disc into itself. Then $$|f'(z)|\le \frac{1}{1-|z|}$$ We can write $$f(z)=\sum_{n=0}^\infty a_nz^n,\ |z|<1.$$ Also, $|f(z)|<1$. After this how I conclude that $|f'(z)|\le \frac{1}{1-|z|}$","Let $f$ be a holomorphic map of the open unit disc into itself. Then $$|f'(z)|\le \frac{1}{1-|z|}$$ We can write $$f(z)=\sum_{n=0}^\infty a_nz^n,\ |z|<1.$$ Also, $|f(z)|<1$. After this how I conclude that $|f'(z)|\le \frac{1}{1-|z|}$",,['complex-analysis']
44,Why do you require connection in the open mapping theorem and maximum modulus principle?,Why do you require connection in the open mapping theorem and maximum modulus principle?,,"I cannot understand why we require the connection in these two theorems (or at least I've been taught this way, and also in some books you have it). The first states that every non-constant analytic function defined from an open and connected subset $U$ of $\mathbb{C}$ to $\mathbb{C}$ is open. The second says that if the norm of an analytic function defined in an open and connected subset $U$ of the complex plane has a real maximum in a point internal to $U$, then the function is constant. I'll try to prove these two theorems without using connection (or maybe I use that without realising). First, I want to prove that for every  analytic function $f$ defined in an open subset $U$ such that $f(z) \ne 0 \forall z \in U$ and $\forall n$ positive integers, there is an analytic function $g$ such that $f(z)=g(z)^{n}$.(Here the teacher supposed $U$ to be connected or maybe even simply connected, it isn't clear in my notes). You just have to consider a primitive $F$ of $\frac{f'}{f}$ and than it is easy to verify that $e^{(F(z)-c)/n}$ for some constant $c$ works. The only thing here that I'm not sure about (and it's where I think the problem is) is that I don't know if I can consider that primitive $F$. I don't see why I shouldn't though, as $f$ is uniquely representable by a power series in balls contained in $U$, and so I should also be able to define a primitive of $f$ locally. Ok, so let's try to prove the open mapping theorem To prove that, you suppose $0 \in U$, consider an open ball $B$ contained in $U$ and require $f(0)=0$ (it shouldn't change anything, it's just translations). $f(z)=z^{k}g(z)$, where $k$ is the order of $f$, that is the minimum integer for which the coefficent of $z^k$ isn't 0. Then you have $g(z)$ an holomorpic function in $B$ such that $g(0) \ne 0$. By continuity, there is an open neighborhood  where $g$ is never 0. Using the result proven above, I can write $g(z)=(h(z))^{k}$, and so $f(z)=(zh(z))^k$. You can verify that $(zh)'(0) \ne 0$ and then using the inverse function theorem and the fact that $z \to z^k$ is an open mapping, you conclude. The second theorem is now trivial, as for every point $a$ in the internal part of $U$ you can send an open neighborhood of $a$ in an open neighborhood of $f(a)$, and so  $f(a)$ cannot be a maximum. I don't see why these proofs shouldn't work, or where I've used unconsiously the connection. thanks for the help.","I cannot understand why we require the connection in these two theorems (or at least I've been taught this way, and also in some books you have it). The first states that every non-constant analytic function defined from an open and connected subset $U$ of $\mathbb{C}$ to $\mathbb{C}$ is open. The second says that if the norm of an analytic function defined in an open and connected subset $U$ of the complex plane has a real maximum in a point internal to $U$, then the function is constant. I'll try to prove these two theorems without using connection (or maybe I use that without realising). First, I want to prove that for every  analytic function $f$ defined in an open subset $U$ such that $f(z) \ne 0 \forall z \in U$ and $\forall n$ positive integers, there is an analytic function $g$ such that $f(z)=g(z)^{n}$.(Here the teacher supposed $U$ to be connected or maybe even simply connected, it isn't clear in my notes). You just have to consider a primitive $F$ of $\frac{f'}{f}$ and than it is easy to verify that $e^{(F(z)-c)/n}$ for some constant $c$ works. The only thing here that I'm not sure about (and it's where I think the problem is) is that I don't know if I can consider that primitive $F$. I don't see why I shouldn't though, as $f$ is uniquely representable by a power series in balls contained in $U$, and so I should also be able to define a primitive of $f$ locally. Ok, so let's try to prove the open mapping theorem To prove that, you suppose $0 \in U$, consider an open ball $B$ contained in $U$ and require $f(0)=0$ (it shouldn't change anything, it's just translations). $f(z)=z^{k}g(z)$, where $k$ is the order of $f$, that is the minimum integer for which the coefficent of $z^k$ isn't 0. Then you have $g(z)$ an holomorpic function in $B$ such that $g(0) \ne 0$. By continuity, there is an open neighborhood  where $g$ is never 0. Using the result proven above, I can write $g(z)=(h(z))^{k}$, and so $f(z)=(zh(z))^k$. You can verify that $(zh)'(0) \ne 0$ and then using the inverse function theorem and the fact that $z \to z^k$ is an open mapping, you conclude. The second theorem is now trivial, as for every point $a$ in the internal part of $U$ you can send an open neighborhood of $a$ in an open neighborhood of $f(a)$, and so  $f(a)$ cannot be a maximum. I don't see why these proofs shouldn't work, or where I've used unconsiously the connection. thanks for the help.",,"['complex-analysis', 'analyticity', 'holomorphic-functions', 'analytic-functions']"
45,Radius of convergence is the point at which the function ceases to be analytic: false for $k \neq \mathbb{C}$?,Radius of convergence is the point at which the function ceases to be analytic: false for ?,k \neq \mathbb{C},"Theorem : Let $U$ be an open set in $\mathbb{C}$, $f$ an analytic function on $U$, and $z_0 \in U$.  Then $f$ has a power series expansion centered at $z_0$.  If $r$ is a positive real number, and $U$ contains the disc of radius $r$ centered at $z_0$, then the radius of convergence of that power series is at least $r$. Any analytic continuation of $f$ to a larger open set $W$ containing $U$ is unique, so the same result holds with $U$ replaced by $W$. In other words, the boundary of the disc of convergence of a local power series expansion of an analytic function is the point at which the given function ceases to be analytic. The definition of an analytic function has a natural generalization to any topological field $k$ which is complete with respect to some absolute value (the main examples are $k = \mathbb{R}$ or a finite extension of $\mathbb{Q}_p$).  For $U$ an open set of $k^n$, an analytic function $f: U \rightarrow k$ is one which has a local power series expansion about every point of $U$.  This is defined in Serre, Lie Groups and Lie Algebras . When $k = \mathbb{R}$, the theorem is false.  Let $U = k$, and define $f: k \rightarrow k$ by $f(x) = \frac{1}{1+x^2}$.  Interpreting $f$ as the restriction to $\mathbb{R}$ of a complex analytic function, we see that $f$ is analytic, and about $z_0 = 0$ has the power series expansion $$1 - x^2 + x^4 - \cdots$$ which has radius of convergence $1$ (which follows from the Theorem and the fact that $\frac{1}{1+z^2}$ is meromorphic on $\mathbb{C}$ with singularities at $i, -i$. What about when $k$ is a finite extension of $\mathbb{Q}_p$?  Is the theorem still true?","Theorem : Let $U$ be an open set in $\mathbb{C}$, $f$ an analytic function on $U$, and $z_0 \in U$.  Then $f$ has a power series expansion centered at $z_0$.  If $r$ is a positive real number, and $U$ contains the disc of radius $r$ centered at $z_0$, then the radius of convergence of that power series is at least $r$. Any analytic continuation of $f$ to a larger open set $W$ containing $U$ is unique, so the same result holds with $U$ replaced by $W$. In other words, the boundary of the disc of convergence of a local power series expansion of an analytic function is the point at which the given function ceases to be analytic. The definition of an analytic function has a natural generalization to any topological field $k$ which is complete with respect to some absolute value (the main examples are $k = \mathbb{R}$ or a finite extension of $\mathbb{Q}_p$).  For $U$ an open set of $k^n$, an analytic function $f: U \rightarrow k$ is one which has a local power series expansion about every point of $U$.  This is defined in Serre, Lie Groups and Lie Algebras . When $k = \mathbb{R}$, the theorem is false.  Let $U = k$, and define $f: k \rightarrow k$ by $f(x) = \frac{1}{1+x^2}$.  Interpreting $f$ as the restriction to $\mathbb{R}$ of a complex analytic function, we see that $f$ is analytic, and about $z_0 = 0$ has the power series expansion $$1 - x^2 + x^4 - \cdots$$ which has radius of convergence $1$ (which follows from the Theorem and the fact that $\frac{1}{1+z^2}$ is meromorphic on $\mathbb{C}$ with singularities at $i, -i$. What about when $k$ is a finite extension of $\mathbb{Q}_p$?  Is the theorem still true?",,"['complex-analysis', 'number-theory', 'manifolds', 'p-adic-number-theory', 'analyticity']"
46,Accumulation points of a holomorphic function.,Accumulation points of a holomorphic function.,,"I am reviewing some complex analysis and I have just gotten to the portion on analytic continuation. My question is about the proof of the following theorem: Theorem. Suppose $f$ is a holomorphic function in a region $\Omega$ that vanishes on a sequence of distinct points with a limit point in $\Omega$. The $f$ is identically zero. Proof. Suppose $z_0 \in \Omega$ is a limit point for the sequence $\{w_k\}$ and $f(w_k) = 0$. Chose a disc $D \subset \Omega$ centered on $z_0$, and consider the power series expansion of $f$ in $D$  $$f(z) = \sum a_n(z-z_0)^n$$ If $f$ is not identically 0, there exists a smallest $m$ such that $a_m\neq 0$. Then, $f$ can be rewritten as  $$f(z) = a_m(z-z_0)^m(1+g(z-z_0))$$ where $g(z-z_0) \to 0$ as $z \to z_0$. Taking $z = w_k$, we obtain a contradiction since $a_m(w_k-z_0)^m \neq 0$ and $g(w_k-z_0) \neq 0$, but $f(w_k) = 0$ ... $\blacksquare$ The proof concludes the argument by using the connectedness of $\Omega$. However, my question is why must $1+g(w_k-z_0) \neq 0$.","I am reviewing some complex analysis and I have just gotten to the portion on analytic continuation. My question is about the proof of the following theorem: Theorem. Suppose $f$ is a holomorphic function in a region $\Omega$ that vanishes on a sequence of distinct points with a limit point in $\Omega$. The $f$ is identically zero. Proof. Suppose $z_0 \in \Omega$ is a limit point for the sequence $\{w_k\}$ and $f(w_k) = 0$. Chose a disc $D \subset \Omega$ centered on $z_0$, and consider the power series expansion of $f$ in $D$  $$f(z) = \sum a_n(z-z_0)^n$$ If $f$ is not identically 0, there exists a smallest $m$ such that $a_m\neq 0$. Then, $f$ can be rewritten as  $$f(z) = a_m(z-z_0)^m(1+g(z-z_0))$$ where $g(z-z_0) \to 0$ as $z \to z_0$. Taking $z = w_k$, we obtain a contradiction since $a_m(w_k-z_0)^m \neq 0$ and $g(w_k-z_0) \neq 0$, but $f(w_k) = 0$ ... $\blacksquare$ The proof concludes the argument by using the connectedness of $\Omega$. However, my question is why must $1+g(w_k-z_0) \neq 0$.",,"['complex-analysis', 'holomorphic-functions', 'analytic-continuation']"
47,Bounding the derivative of a function,Bounding the derivative of a function,,"Let $f(x) = \frac{\exp(ax)}{1+\exp(ax)}$ for some $a > 0$ be a logistic function. I am looking for an upper bound on the $k$-th derivative of $f$, i.e. $|f^{(k)}(x)|$ on $\mathbb{R}$. Using Cauchy's integral formula I only obtain a bound of order $k! / (\pi-\epsilon)^{k+1}$ for $a=1$. Is it possible to get below $k!$ and obtain a growth rate that is just exponential? Thanks!","Let $f(x) = \frac{\exp(ax)}{1+\exp(ax)}$ for some $a > 0$ be a logistic function. I am looking for an upper bound on the $k$-th derivative of $f$, i.e. $|f^{(k)}(x)|$ on $\mathbb{R}$. Using Cauchy's integral formula I only obtain a bound of order $k! / (\pi-\epsilon)^{k+1}$ for $a=1$. Is it possible to get below $k!$ and obtain a growth rate that is just exponential? Thanks!",,"['complex-analysis', 'inequality', 'cauchy-integral-formula', 'upper-lower-bounds']"
48,Finding Laurent Series-is it possible without contour integral,Finding Laurent Series-is it possible without contour integral,,"I have to find the Laurent Series expansion for $$ f(z)= \frac {z^2 +1}  {2z-1} $$ around $ 1 \over 2$. I know that I can write $f(z)= \sum_{-\infty}^{+\infty} a_n(z- \frac{1}{2})^n $ , where $a_n = \frac{1}{2πi} \oint_γ \frac{f(z)dz}{(z-\frac{1}{2})^{n+1}} $  (γ is a closed path around 1/2). Can I find the series expansion in a more ""crude"" way, using the geometric series? Can I split the fraction in such a way to form something like $1\over z-1$ , or do I have to use the contour integral? Moreover, in rational functions like f, is there always a way for building the expansion using the geometric series?","I have to find the Laurent Series expansion for $$ f(z)= \frac {z^2 +1}  {2z-1} $$ around $ 1 \over 2$. I know that I can write $f(z)= \sum_{-\infty}^{+\infty} a_n(z- \frac{1}{2})^n $ , where $a_n = \frac{1}{2πi} \oint_γ \frac{f(z)dz}{(z-\frac{1}{2})^{n+1}} $  (γ is a closed path around 1/2). Can I find the series expansion in a more ""crude"" way, using the geometric series? Can I split the fraction in such a way to form something like $1\over z-1$ , or do I have to use the contour integral? Moreover, in rational functions like f, is there always a way for building the expansion using the geometric series?",,"['complex-analysis', 'laurent-series']"
49,$\int_{0}^{\infty} {x^{\alpha} \over \left(x + 1\right)}dx$,,\int_{0}^{\infty} {x^{\alpha} \over \left(x + 1\right)}dx,I need some help to evaluate the following integral. $$\int_{0}^{\infty} {x^{\alpha} \over \left(x + 1\right)}dx$$ I know you need to use a branch cut but not sure how to start. Any help is always appreciated. Edit: Need Help to Establish the Cauchy Principle for the improper integral if that provides any direction.,I need some help to evaluate the following integral. $$\int_{0}^{\infty} {x^{\alpha} \over \left(x + 1\right)}dx$$ I know you need to use a branch cut but not sure how to start. Any help is always appreciated. Edit: Need Help to Establish the Cauchy Principle for the improper integral if that provides any direction.,,['complex-analysis']
50,Let $f(z)$ be an entire function satisfying $z\dfrac{f^{'}(z)}{f(z)} = z^{2}\dfrac{f^{'}(z^{2})}{f(z^{2})}$ show that $f(z) = cz^{m}$.,Let  be an entire function satisfying  show that .,f(z) z\dfrac{f^{'}(z)}{f(z)} = z^{2}\dfrac{f^{'}(z^{2})}{f(z^{2})} f(z) = cz^{m},"a) Let $f(z)$ be an entire function satisfying the condition $$z\dfrac{f^{'}(z)}{f(z)} = z^{2}\dfrac{f^{'}(z^{2})}{f(z^{2})}$$ whenever $f(z) \neq 0$. Show that if $f(0) = 0$, then $$z\dfrac{f^{'}(z)}{f(z)}$$  is a function that is analytic at $z=0$. b) Show that $$f(z) = cz^{m}$$ for some constant $c \in \mathbb{C}$ and positive integer $m$. For part a), please see if i did correctly,since we are given that $f(0) = 0$, we know that $f$ has a zero of order $m$ at $0$. Hence we can write $$f(z) = z^{m}g(z)$$ where $g(z)$ is analytic at $0$ and $g(0) \neq 0$. It follows that $$f^{'}(z) = mz^{m-1}g(z)+z^{m}g^{'}(z)$$ Hence by subsituting we derive $$z\dfrac{f^{'}(z)}{f(z)} =m+\frac{zg^{'}(z)}{g(z)}$$ Hence this function is analytic at $z=0$ because $g(z)$ is analytic at $0$. (Can someone explain to me: $g(z)$ analytic at $0$  means $g(z)$ is analytic in a small neighborhood of $0$. But how can i ensure that $g(z)$ does not have zeroes in this small neighborhood? If $g(z)$ has zero inside, then the expression $m+\frac{zg^{'}(z)}{g(z)}$  is not analytic at $0$. And for part $b$, anyone can write out their solution? I do have a model answer from my professor but find it hard to understand.","a) Let $f(z)$ be an entire function satisfying the condition $$z\dfrac{f^{'}(z)}{f(z)} = z^{2}\dfrac{f^{'}(z^{2})}{f(z^{2})}$$ whenever $f(z) \neq 0$. Show that if $f(0) = 0$, then $$z\dfrac{f^{'}(z)}{f(z)}$$  is a function that is analytic at $z=0$. b) Show that $$f(z) = cz^{m}$$ for some constant $c \in \mathbb{C}$ and positive integer $m$. For part a), please see if i did correctly,since we are given that $f(0) = 0$, we know that $f$ has a zero of order $m$ at $0$. Hence we can write $$f(z) = z^{m}g(z)$$ where $g(z)$ is analytic at $0$ and $g(0) \neq 0$. It follows that $$f^{'}(z) = mz^{m-1}g(z)+z^{m}g^{'}(z)$$ Hence by subsituting we derive $$z\dfrac{f^{'}(z)}{f(z)} =m+\frac{zg^{'}(z)}{g(z)}$$ Hence this function is analytic at $z=0$ because $g(z)$ is analytic at $0$. (Can someone explain to me: $g(z)$ analytic at $0$  means $g(z)$ is analytic in a small neighborhood of $0$. But how can i ensure that $g(z)$ does not have zeroes in this small neighborhood? If $g(z)$ has zero inside, then the expression $m+\frac{zg^{'}(z)}{g(z)}$  is not analytic at $0$. And for part $b$, anyone can write out their solution? I do have a model answer from my professor but find it hard to understand.",,"['complex-analysis', 'ordinary-differential-equations', 'functional-equations']"
51,How to prove this integral $\iint_{D} \frac{\mathrm{d}\bar{z}\mathrm{d}z}{z-\zeta} = - 2{\pi}i{\bar{\zeta}} $,How to prove this integral,\iint_{D} \frac{\mathrm{d}\bar{z}\mathrm{d}z}{z-\zeta} = - 2{\pi}i{\bar{\zeta}} ,"I am reading this paper and there is an integral in it: $$\iint_{D} \frac{\mathrm{d}\bar{z}\mathrm{d}z}{z-\zeta} = - 2{\pi}i{\bar{\zeta}},$$ where $D$ is a disc of radius $R$ and $\zeta$ is a point in $D$. I write the left in definition. Let $\zeta = a+ i b$, then \begin{align*}\iint_{D} \frac{\mathrm{d}\bar{z}\mathrm{d}z}{z-\zeta} &=2i \iint_{D}\frac{\mathrm{d}x\mathrm{d}y}{(x+iy)-(a+ib)}   \\&=2 \iint_{D}\frac{(y-b)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2} +2i\iint_{D}\frac{(x-a)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2}, \end{align*} and it should be $$\iint_{D}\frac{(x-a)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2}=-{\pi}a.$$ Using polar coordinates and change variable to $t = \tan\frac{\theta}{2}$, \begin{align*} &\mathrel{\phantom{=}}\iint_{D}\frac{(x-a)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2}\\ &= \int^R_0\mathrm{d}r\int^{\pi}_{-\pi}\frac{r(r\cos\theta -a)}{(r\cos\theta-a)^2+(r\sin\theta - b)^2}\,\mathrm{d}\theta\\ &=\iint\frac{(r(\cos^2 \frac{\theta}{2}-\sin^2 \frac{\theta}{2})-a(\cos^2\frac{\theta}{2}+\sin^2\frac{\theta}{2}))\,\mathrm{d}\theta\mathrm{d}r}{(r^2+a^2+b^2)(\cos^2\frac{\theta}{2}+\sin^2\frac{\theta}{2})-2ra(\cos^2\frac{\theta}{2}-\sin^2\frac{\theta}{2}) -4rb\sin\frac{\theta}{2}\cos\frac{\theta}{2}}\\ &=\int^R_02r\,\mathrm{d}r\int^{+\infty}_{-\infty}\frac{r(1-t^2)-a(1+t^2)}{((r^2+a^2+b^2)(1+t^2)-2ra(1-t^2)-4rbt))(1+t^2)}\,\mathrm{d}t \end{align*} and I don't know how to continue. Did I do something wrong? And I think the author use complex language for convenience. I calculate in real is the wrong way but I don't know how to do it in complex. Thank you!","I am reading this paper and there is an integral in it: $$\iint_{D} \frac{\mathrm{d}\bar{z}\mathrm{d}z}{z-\zeta} = - 2{\pi}i{\bar{\zeta}},$$ where $D$ is a disc of radius $R$ and $\zeta$ is a point in $D$. I write the left in definition. Let $\zeta = a+ i b$, then \begin{align*}\iint_{D} \frac{\mathrm{d}\bar{z}\mathrm{d}z}{z-\zeta} &=2i \iint_{D}\frac{\mathrm{d}x\mathrm{d}y}{(x+iy)-(a+ib)}   \\&=2 \iint_{D}\frac{(y-b)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2} +2i\iint_{D}\frac{(x-a)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2}, \end{align*} and it should be $$\iint_{D}\frac{(x-a)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2}=-{\pi}a.$$ Using polar coordinates and change variable to $t = \tan\frac{\theta}{2}$, \begin{align*} &\mathrel{\phantom{=}}\iint_{D}\frac{(x-a)\,\mathrm{d}x\mathrm{d}y}{(x-a)^2+(y-b)^2}\\ &= \int^R_0\mathrm{d}r\int^{\pi}_{-\pi}\frac{r(r\cos\theta -a)}{(r\cos\theta-a)^2+(r\sin\theta - b)^2}\,\mathrm{d}\theta\\ &=\iint\frac{(r(\cos^2 \frac{\theta}{2}-\sin^2 \frac{\theta}{2})-a(\cos^2\frac{\theta}{2}+\sin^2\frac{\theta}{2}))\,\mathrm{d}\theta\mathrm{d}r}{(r^2+a^2+b^2)(\cos^2\frac{\theta}{2}+\sin^2\frac{\theta}{2})-2ra(\cos^2\frac{\theta}{2}-\sin^2\frac{\theta}{2}) -4rb\sin\frac{\theta}{2}\cos\frac{\theta}{2}}\\ &=\int^R_02r\,\mathrm{d}r\int^{+\infty}_{-\infty}\frac{r(1-t^2)-a(1+t^2)}{((r^2+a^2+b^2)(1+t^2)-2ra(1-t^2)-4rbt))(1+t^2)}\,\mathrm{d}t \end{align*} and I don't know how to continue. Did I do something wrong? And I think the author use complex language for convenience. I calculate in real is the wrong way but I don't know how to do it in complex. Thank you!",,"['integration', 'complex-analysis']"
52,"Significance of ""virtual"" zeroes/poles introduced by the Pade expansion of $e^{sT}$","Significance of ""virtual"" zeroes/poles introduced by the Pade expansion of",e^{sT},"Let $s$ be a complex parameter and $T$ a real. The function $e^{sT}$ is entire. It can also be expanded in a Pade approximant via $$ e^{sT} = \frac{e^{sT/2}}{e^{-sT/2}} = \frac{1+ sT/2 + \frac{(sT/2)^2}{2!}+ \cdots}{1 - sT/2 + \frac{(sT/2)^2}{2!} - \cdots}, $$ which upon truncation to first order yields the bilinear mapping $$ \frac{2+sT}{2-sT}. $$ Approximations of the exponential function by bilinear mappings are found frequently in digital signal processing, linearized analysis of delay systems, and other applications in systems theory, where they are known as ""Tustin's method"" or sometimes ""Tustin's approximation"". In all of these applications, poles and zeros introduced into a system transfer function are important factors which determine system stability, transient characteristics, and frequency response. The character of a system, say $e^{sT}H(s)$, where $H(s)$ is an arbitrary rational transfer function, may in fact be changed considerably if the exponential factor is approximated by Tustin's method, despite the fact that numerically the two are close when the latter is defined and nonzero, since the introduction of the pole-zero combination affects relative stability margins and the shape of the system's frequency response. Clearly the pole-zero combination is ""virtual"" in the sense that they do not arise from physical considerations, but it is unclear to me what their exact significance is.","Let $s$ be a complex parameter and $T$ a real. The function $e^{sT}$ is entire. It can also be expanded in a Pade approximant via $$ e^{sT} = \frac{e^{sT/2}}{e^{-sT/2}} = \frac{1+ sT/2 + \frac{(sT/2)^2}{2!}+ \cdots}{1 - sT/2 + \frac{(sT/2)^2}{2!} - \cdots}, $$ which upon truncation to first order yields the bilinear mapping $$ \frac{2+sT}{2-sT}. $$ Approximations of the exponential function by bilinear mappings are found frequently in digital signal processing, linearized analysis of delay systems, and other applications in systems theory, where they are known as ""Tustin's method"" or sometimes ""Tustin's approximation"". In all of these applications, poles and zeros introduced into a system transfer function are important factors which determine system stability, transient characteristics, and frequency response. The character of a system, say $e^{sT}H(s)$, where $H(s)$ is an arbitrary rational transfer function, may in fact be changed considerably if the exponential factor is approximated by Tustin's method, despite the fact that numerically the two are close when the latter is defined and nonzero, since the introduction of the pole-zero combination affects relative stability margins and the shape of the system's frequency response. Clearly the pole-zero combination is ""virtual"" in the sense that they do not arise from physical considerations, but it is unclear to me what their exact significance is.",,"['complex-analysis', 'dynamical-systems', 'control-theory', 'linear-control']"
53,Residue for quotient of functions,Residue for quotient of functions,,"Let $f, g$ be holomorphic functions on a disk $\mathbb{D}(z_0,r)$ centered at $z_0$ and of radius $r>0$. Suppose $f$ has a simple zero at $z_0$. I want to find an expression for $Res(g/f, z_0)$. But I'm not sure what this expression should look like. Here's my guess: Since $f$ has a simple zero at $z_0$, $\exists h(z)$ holomorphic on $\mathbb{D}(z_0,r)$ such that $f(z)=(z-z_0)h(z)$ and $h(z_0)\ne 0$. So that we can represent $g/f = \frac{g(z)}{(z-z_0)h(z)}$, where we observe that $z_0$ is a pole of order 1 of $g/f$. This implies that we can express $$g/f=\frac{a_{-1}}{z-z_0}+\sum\limits_{n=0}^\infty a_n(z-z_0)^n$$ Hence, $$a_{-1}=\frac{g(z)}{f(z)}(z-z_0)-\sum\limits_{n=0}^\infty a_n(z-z_0)^{n+1}$$ Does this look like a correct approach? I think that this expression is too general because of the infinite series on the right-hand side. Is there a clue I'm missing? Update: Another approach might be this: $$g/f = \frac{g(z)}{(z-z_0)h(z)}=\frac{c_0+c_1(z-z_0)+\dots}{d_1(z-z_0)+\dots}=\frac{c_0}{d_1(z-z_0)+\dots}\\ +\frac{c_1(z-z_0)+\dots}{d_1(z-z_0)+\dots}=\frac{a_{-1}}{z-z_0}+\sum a_n(z-z_0)^n$$ But what next?","Let $f, g$ be holomorphic functions on a disk $\mathbb{D}(z_0,r)$ centered at $z_0$ and of radius $r>0$. Suppose $f$ has a simple zero at $z_0$. I want to find an expression for $Res(g/f, z_0)$. But I'm not sure what this expression should look like. Here's my guess: Since $f$ has a simple zero at $z_0$, $\exists h(z)$ holomorphic on $\mathbb{D}(z_0,r)$ such that $f(z)=(z-z_0)h(z)$ and $h(z_0)\ne 0$. So that we can represent $g/f = \frac{g(z)}{(z-z_0)h(z)}$, where we observe that $z_0$ is a pole of order 1 of $g/f$. This implies that we can express $$g/f=\frac{a_{-1}}{z-z_0}+\sum\limits_{n=0}^\infty a_n(z-z_0)^n$$ Hence, $$a_{-1}=\frac{g(z)}{f(z)}(z-z_0)-\sum\limits_{n=0}^\infty a_n(z-z_0)^{n+1}$$ Does this look like a correct approach? I think that this expression is too general because of the infinite series on the right-hand side. Is there a clue I'm missing? Update: Another approach might be this: $$g/f = \frac{g(z)}{(z-z_0)h(z)}=\frac{c_0+c_1(z-z_0)+\dots}{d_1(z-z_0)+\dots}=\frac{c_0}{d_1(z-z_0)+\dots}\\ +\frac{c_1(z-z_0)+\dots}{d_1(z-z_0)+\dots}=\frac{a_{-1}}{z-z_0}+\sum a_n(z-z_0)^n$$ But what next?",,"['complex-analysis', 'proof-verification', 'residue-calculus', 'laurent-series']"
54,Contour integral of $\int_0^\infty \frac{x^{1/3}}{(x+1)(x+2)}dx$,Contour integral of,\int_0^\infty \frac{x^{1/3}}{(x+1)(x+2)}dx,So far I've found that this integral $I$ can be represented with $I' = \oint_C \frac{z^{1/3}}{(z+1)(z+2)}dz$ where $z = re^{i\theta}$ with a branch cut along the x-axis. This gives $$\int_0^\infty \frac{r^{1/3}}{(r+1)(r+2)}dr + \int_\infty^0 \frac{r^{1/3}e^{2/3 \pi i}}{(r+1)(r+2)}dr$$ $$=I-e^{2/3 \pi i}I$$ however I am unsure where to go from here. Any help completing this problem is appreiated!,So far I've found that this integral $I$ can be represented with $I' = \oint_C \frac{z^{1/3}}{(z+1)(z+2)}dz$ where $z = re^{i\theta}$ with a branch cut along the x-axis. This gives $$\int_0^\infty \frac{r^{1/3}}{(r+1)(r+2)}dr + \int_\infty^0 \frac{r^{1/3}e^{2/3 \pi i}}{(r+1)(r+2)}dr$$ $$=I-e^{2/3 \pi i}I$$ however I am unsure where to go from here. Any help completing this problem is appreiated!,,"['complex-analysis', 'contour-integration', 'branch-cuts']"
55,If $f$ is holomorphic and $\left| f \right|$ is constant then $f$ is constant,If  is holomorphic and  is constant then  is constant,f \left| f \right| f,"Given that $f:D\to \mathbb{C}$ is holomorphic on $D$ and $\left| f \right|$ is constant on $D$, then $f$ is constant on $D$. Where $D$ is a connected open set. My approach: Write $f=u(x,y)+iv(x,y)$. Since $f$ is holomorphic on $D$, it is complex-differentiable on $D$, which implies that the $\mathbb{R}^2$-Jacobian of $f$ is defined on all of $D$. That is, $$Df=\begin{bmatrix} u_x & v_x \\  u_y & v_y \end{bmatrix}$$ Now, since $\left| f \right|$ is constant, it must be true that $$\left| Df \right|=\det\left(\begin{bmatrix} u_x & v_x \\  u_y & v_y \end{bmatrix}\right)=u_xv_y-v_xu_y=0 \text{  (*)}$$ Since $f$ is $\mathbb{C}$-differentiable on $D$, the Cauchy-Riemann equations hold for $f$. Thus, $$ u_xv_y-v_xu_y=u_x^2+u_y^2=0 \iff u_x^2=-u_y^2$$ Thus $u_x=u_y\equiv 0 \implies u(x,y)$ is constant. Similarly, we can make the substitutions in (*) to obtain $v_y^2=-v_x^2$ and $v_x=v_y\equiv 0$. This implies that both $u$ and $v$ are constant, and thus $f$ is constant. Please let me know if my approach is correct. I'm just a little concerned about my treatment of the Jacobian of $\left|f\right|$ as the determinant of the Jacobian of $f$, but I think this should be correct.","Given that $f:D\to \mathbb{C}$ is holomorphic on $D$ and $\left| f \right|$ is constant on $D$, then $f$ is constant on $D$. Where $D$ is a connected open set. My approach: Write $f=u(x,y)+iv(x,y)$. Since $f$ is holomorphic on $D$, it is complex-differentiable on $D$, which implies that the $\mathbb{R}^2$-Jacobian of $f$ is defined on all of $D$. That is, $$Df=\begin{bmatrix} u_x & v_x \\  u_y & v_y \end{bmatrix}$$ Now, since $\left| f \right|$ is constant, it must be true that $$\left| Df \right|=\det\left(\begin{bmatrix} u_x & v_x \\  u_y & v_y \end{bmatrix}\right)=u_xv_y-v_xu_y=0 \text{  (*)}$$ Since $f$ is $\mathbb{C}$-differentiable on $D$, the Cauchy-Riemann equations hold for $f$. Thus, $$ u_xv_y-v_xu_y=u_x^2+u_y^2=0 \iff u_x^2=-u_y^2$$ Thus $u_x=u_y\equiv 0 \implies u(x,y)$ is constant. Similarly, we can make the substitutions in (*) to obtain $v_y^2=-v_x^2$ and $v_x=v_y\equiv 0$. This implies that both $u$ and $v$ are constant, and thus $f$ is constant. Please let me know if my approach is correct. I'm just a little concerned about my treatment of the Jacobian of $\left|f\right|$ as the determinant of the Jacobian of $f$, but I think this should be correct.",,"['complex-analysis', 'proof-verification', 'holomorphic-functions', 'jacobian']"
56,"Compute $\int_{\gamma}{Log(z)\over z}dz$ for $\gamma(t)=e^{it}$, $t\in[0,2\pi]$","Compute  for ,","\int_{\gamma}{Log(z)\over z}dz \gamma(t)=e^{it} t\in[0,2\pi]","Compute $\int_{\gamma}{Log(z)\over z}dz$ for $\gamma(t)=e^{it}$, $0\le t\le (2\pi)$. (Why is it that using ""\le"" code suddenly creates ""2""?). Before you vote to close this question, know that its duplicate has a confirmed answer understood to the OP but unfamiliar to me in its method. And this is a way for me to, through this question, to better understand the nature of integrals and Logarithm in an adjustable and convenient format. The use of $\text{Log(z)}$ probably refer to the principal logarithm, but it is defined on $(-\pi,\pi]$. If I split the integral, what should be done with the second part? Another exercise looking at $e^{it},t\in[0,\pi]$ stated that $Log(e^{it})$ is simply $it$ in a well-defined manner, but here it is quite confusing. I don't understand why and how to change this contour to another. Can you please contribute some theory regarding that problem?","Compute $\int_{\gamma}{Log(z)\over z}dz$ for $\gamma(t)=e^{it}$, $0\le t\le (2\pi)$. (Why is it that using ""\le"" code suddenly creates ""2""?). Before you vote to close this question, know that its duplicate has a confirmed answer understood to the OP but unfamiliar to me in its method. And this is a way for me to, through this question, to better understand the nature of integrals and Logarithm in an adjustable and convenient format. The use of $\text{Log(z)}$ probably refer to the principal logarithm, but it is defined on $(-\pi,\pi]$. If I split the integral, what should be done with the second part? Another exercise looking at $e^{it},t\in[0,\pi]$ stated that $Log(e^{it})$ is simply $it$ in a well-defined manner, but here it is quite confusing. I don't understand why and how to change this contour to another. Can you please contribute some theory regarding that problem?",,['complex-analysis']
57,Help with this simple complex integral on the conjugate,Help with this simple complex integral on the conjugate,,"I am currently trying to calculate $$\int_{|z| = 2} \overline{z} dz.$$ Take $\overline{z} = f(z).$ I see that for $z = re^{i\theta} = r\cos(\theta) + r\sin(\theta)i,$ We see that $$\overline{z} = r\cos(\theta) - r\sin(\theta)i = r\cos(-\theta) + r\sin(-\theta)i = re^{-i\theta}.$$ Thus, $$\{z | |z| = 2\} = \{2e^{i\theta}, \theta \in [0,2\pi)\}.$$ Take $q(\theta) = 2e^{i\theta}.$ We can see that $$\int_{|z| = 2} f(z) dz = \int_{0}^{2\pi} f(q(\theta))q'(\theta) d\theta$$ $$=\int_0^{2\pi} f(2e^{i\theta})(2e^{i\theta} \cdot i) d\theta$$ $$=2i \int_0^{2\pi} 2e^{-i\theta} e^{i\theta} d\theta$$ $$=2i \int_0^{2\pi} 2 d\theta = 2i(4\pi) = 8\pi i.$$ However, I am not entirely sure if this calculation is correct. Any recommendations on how to check this?","I am currently trying to calculate $$\int_{|z| = 2} \overline{z} dz.$$ Take $\overline{z} = f(z).$ I see that for $z = re^{i\theta} = r\cos(\theta) + r\sin(\theta)i,$ We see that $$\overline{z} = r\cos(\theta) - r\sin(\theta)i = r\cos(-\theta) + r\sin(-\theta)i = re^{-i\theta}.$$ Thus, $$\{z | |z| = 2\} = \{2e^{i\theta}, \theta \in [0,2\pi)\}.$$ Take $q(\theta) = 2e^{i\theta}.$ We can see that $$\int_{|z| = 2} f(z) dz = \int_{0}^{2\pi} f(q(\theta))q'(\theta) d\theta$$ $$=\int_0^{2\pi} f(2e^{i\theta})(2e^{i\theta} \cdot i) d\theta$$ $$=2i \int_0^{2\pi} 2e^{-i\theta} e^{i\theta} d\theta$$ $$=2i \int_0^{2\pi} 2 d\theta = 2i(4\pi) = 8\pi i.$$ However, I am not entirely sure if this calculation is correct. Any recommendations on how to check this?",,"['complex-analysis', 'complex-numbers', 'complex-integration']"
58,"Suppose that $f$ is an analytic function from the Riemann sphere to the Riemann sphere, must f be a rational function?","Suppose that  is an analytic function from the Riemann sphere to the Riemann sphere, must f be a rational function?",f,"Then Riemann sphere is defined by charts $(\mathbb C,Id_{\mathbb C})$ and $(\mathbb C-\{0\}\cup\{\infty\},\phi)$, $\phi(z) = \frac{1}{z},$ if $z \neq 0$, $\phi(z) = 0$ if $z = \infty$. I was told that if $f$ is an analytic function from the Riemann sphere to the Riemann sphere, then $f$ can only be a rational function. However, I think about defining$\ $ $f(z)= e^z$, when $z \in \mathbb C$ and $f(z) = \infty$ when $z = \infty$. Isn't this a well-defined holomorphic function between Riemann spheres?","Then Riemann sphere is defined by charts $(\mathbb C,Id_{\mathbb C})$ and $(\mathbb C-\{0\}\cup\{\infty\},\phi)$, $\phi(z) = \frac{1}{z},$ if $z \neq 0$, $\phi(z) = 0$ if $z = \infty$. I was told that if $f$ is an analytic function from the Riemann sphere to the Riemann sphere, then $f$ can only be a rational function. However, I think about defining$\ $ $f(z)= e^z$, when $z \in \mathbb C$ and $f(z) = \infty$ when $z = \infty$. Isn't this a well-defined holomorphic function between Riemann spheres?",,['complex-analysis']
59,Solving $\sin z = i$,Solving,\sin z = i,I know that $$\sin z = \frac{e^{iz}-e^{-iz}}{2i}$$ so: $$\frac{e^{iz}-e^{-iz}}{2i} = i\implies e^{iz}-e^{-iz} = -2$$ but I can't take anything useful from here. How do I solve such equations? What about $\tan z = 1$? Is there any solutions?,I know that $$\sin z = \frac{e^{iz}-e^{-iz}}{2i}$$ so: $$\frac{e^{iz}-e^{-iz}}{2i} = i\implies e^{iz}-e^{-iz} = -2$$ but I can't take anything useful from here. How do I solve such equations? What about $\tan z = 1$? Is there any solutions?,,"['calculus', 'complex-analysis']"
60,Show that $f^{n}(0)=0$ for infinitely many $n\ge 0$.,Show that  for infinitely many .,f^{n}(0)=0 n\ge 0,"Let $f$ be an entire function. Suppose that for each $a\in \Bbb R$ there exists at least one coefficient $c_n$ in $f(z)=\sum_{n=0}^\infty c_n(z-a)^n$ which is zero. Then: $f^{n}(0)=0$ for infinitely many $n\ge 0$. $f^{2n}(0)=0$ for every $n\ge 0$. $f^{2n+1}(0)=0$ for every $n\ge 0$. $\exists  k\ge 0$  such that $f^{n}(0)=0$ for all $n\ge k$. My try : Since $a\in \Bbb R$ is uncountable and $c_n$ is countable so there exists $b\in \Bbb R$ such that $c_n=0$ for infinitely many $n$ where $c_n=\dfrac{f^{n}(b)}{n!}\implies f^{n}(b)=0$. So  I feel that the correct options should be $1,4$. But how can I show that $f^{n}(0)=0$ for infinitely many $n\ge 0$. I only have $f^{n}(b)=0$ for infinitely many $n\ge 0$.But the question demands $f^{n}(0)=0$ for infinitely many $n\ge 0$. Please give some hints.","Let $f$ be an entire function. Suppose that for each $a\in \Bbb R$ there exists at least one coefficient $c_n$ in $f(z)=\sum_{n=0}^\infty c_n(z-a)^n$ which is zero. Then: $f^{n}(0)=0$ for infinitely many $n\ge 0$. $f^{2n}(0)=0$ for every $n\ge 0$. $f^{2n+1}(0)=0$ for every $n\ge 0$. $\exists  k\ge 0$  such that $f^{n}(0)=0$ for all $n\ge k$. My try : Since $a\in \Bbb R$ is uncountable and $c_n$ is countable so there exists $b\in \Bbb R$ such that $c_n=0$ for infinitely many $n$ where $c_n=\dfrac{f^{n}(b)}{n!}\implies f^{n}(b)=0$. So  I feel that the correct options should be $1,4$. But how can I show that $f^{n}(0)=0$ for infinitely many $n\ge 0$. I only have $f^{n}(b)=0$ for infinitely many $n\ge 0$.But the question demands $f^{n}(0)=0$ for infinitely many $n\ge 0$. Please give some hints.",,"['complex-analysis', 'entire-functions']"
61,How to prove a power series can be analytically continued?,How to prove a power series can be analytically continued?,,"Consider the complex function $f(z)=\sum_{n=1}^{\infty} \frac{(-1)^n}{2n+1}z^{2n+1} \, .$ (i) Determine its domain. (ii) Let $\Gamma = \{iy:y\in\mathbb{R}, |y| \geq 1 \}$, show that there exists an analytic continuation of $f$ to $\mathbb{C}-\Gamma$. (iii) (optional) Discuss the existence of other maximal analytical continuations of $f$ to domains of the Riemann sphere $\mathbb{C} \cup \{\infty\}$ of the form $D= (\mathbb{C} \cup \{\infty\})-\Gamma',$ where $\Gamma'$ is a compact set of $\mathbb{C}$. For the first part: I think the radius of convergence is $1$. And I can see it converges when $z=1$, but I don't know about the rest of the border $S^1$. However, the real problem is point (ii). Is there a general way to tackle this kind of problem?","Consider the complex function $f(z)=\sum_{n=1}^{\infty} \frac{(-1)^n}{2n+1}z^{2n+1} \, .$ (i) Determine its domain. (ii) Let $\Gamma = \{iy:y\in\mathbb{R}, |y| \geq 1 \}$, show that there exists an analytic continuation of $f$ to $\mathbb{C}-\Gamma$. (iii) (optional) Discuss the existence of other maximal analytical continuations of $f$ to domains of the Riemann sphere $\mathbb{C} \cup \{\infty\}$ of the form $D= (\mathbb{C} \cup \{\infty\})-\Gamma',$ where $\Gamma'$ is a compact set of $\mathbb{C}$. For the first part: I think the radius of convergence is $1$. And I can see it converges when $z=1$, but I don't know about the rest of the border $S^1$. However, the real problem is point (ii). Is there a general way to tackle this kind of problem?",,"['complex-analysis', 'power-series']"
62,a self adjoint in complex vector space,a self adjoint in complex vector space,,"Let $V$ be a complex vector space, with Hermitian inner product $\langle z,w\rangle$ . Let $T : V → V$ be a linear transformation. Show that $T$ is self adjoint if and only if $\langle Tz,z\rangle$ is real for every $z ∈ V$ . My solution is: In the left side: $T$ is self-adjoint $\Leftrightarrow$ $T=T^*$ $\Leftrightarrow$ $T=UAU^*$ where $UU^*=I$ and A is a diagonal matrix. In the right side: $\langle Tz,z\rangle$ is real for every $z ∈ V$ $\Leftrightarrow$ $z'T'\overline{z}$ is real $\Leftrightarrow$ $T=UU^*$ . So there is some discrepency between the two sides. Can you tell me which step is wrong?","Let be a complex vector space, with Hermitian inner product . Let be a linear transformation. Show that is self adjoint if and only if is real for every . My solution is: In the left side: is self-adjoint where and A is a diagonal matrix. In the right side: is real for every is real . So there is some discrepency between the two sides. Can you tell me which step is wrong?","V \langle z,w\rangle T : V → V T \langle Tz,z\rangle z ∈ V T \Leftrightarrow T=T^* \Leftrightarrow T=UAU^* UU^*=I \langle Tz,z\rangle z ∈ V \Leftrightarrow z'T'\overline{z} \Leftrightarrow T=UU^*","['complex-analysis', 'vector-spaces']"
63,Finding the principal part for the Laurent series,Finding the principal part for the Laurent series,,How can I find the principal part of the Laurent series for  $f(z)=\dfrac{\pi^2}{(\sin \pi z)^2}$ centered at $k$ where $k \in \mathbb{Z}$. I think there are two ways to do it either use the formula $a_k$ for Laurent coefficients or expand manipulate $\sin^2 \pi z$ and solve for the coefficients. I am not sure if any of these ways are efficient.,How can I find the principal part of the Laurent series for  $f(z)=\dfrac{\pi^2}{(\sin \pi z)^2}$ centered at $k$ where $k \in \mathbb{Z}$. I think there are two ways to do it either use the formula $a_k$ for Laurent coefficients or expand manipulate $\sin^2 \pi z$ and solve for the coefficients. I am not sure if any of these ways are efficient.,,"['real-analysis', 'complex-analysis']"
64,The cylinder does not embed into $\Bbb C^n$,The cylinder does not embed into,\Bbb C^n,"The cylinder $\Bbb R\times S^1$ can be viewed as a complex manifold with a flat metric by viewing it has the quotient $\Bbb R\times\Bbb R/\Bbb Z$, where $\Bbb R\times\Bbb R=\Bbb C$. (In fact it makes the cylinder into a Kähler manifold.) Problem: Show that there is no isometric holomorphic embedding   $$\varphi:\Bbb R\times S^1\hookrightarrow \Bbb C^n,$$   for any $n$, where $\Bbb C^n$ has the standard Kähler structure. Motivation: I was trying to answer another of my questions here , and after some research I found this mathoverflow post of Peter Kronheimer claiming the above. He gives the following reason. Hint: Apply the maximum modulus principle to the derivative of $\varphi$. I tried this approach without any success. Does anybody know how it works?","The cylinder $\Bbb R\times S^1$ can be viewed as a complex manifold with a flat metric by viewing it has the quotient $\Bbb R\times\Bbb R/\Bbb Z$, where $\Bbb R\times\Bbb R=\Bbb C$. (In fact it makes the cylinder into a Kähler manifold.) Problem: Show that there is no isometric holomorphic embedding   $$\varphi:\Bbb R\times S^1\hookrightarrow \Bbb C^n,$$   for any $n$, where $\Bbb C^n$ has the standard Kähler structure. Motivation: I was trying to answer another of my questions here , and after some research I found this mathoverflow post of Peter Kronheimer claiming the above. He gives the following reason. Hint: Apply the maximum modulus principle to the derivative of $\varphi$. I tried this approach without any success. Does anybody know how it works?",,"['complex-analysis', 'differential-geometry', 'riemannian-geometry', 'complex-geometry']"
65,"If $f$ is a real valued function, complex differentiable at $z_0$, then $f'(z_0)=0$","If  is a real valued function, complex differentiable at , then",f z_0 f'(z_0)=0,"Cannot understand this proof that a real-valued function which is complex differentiable must have derivative at that point equal to zero. I just don't understand how the last statement in bold is validated. If $f$ is complex differentiable at $z_0$ then there exists a complex number $\xi_0$ such that $$\frac{f(z)-f(z_0)}{z-z_0} \rightarrow \xi_0\;\; \text{as} \;\; (z-z_0)\rightarrow 0$$   Let $\text{Re}(z-z_0)=s$ and $\text{Im}(z-z_0)=t$, so that $s+it=z-z_0$. Then taking $t=0$ and letting $s\rightarrow 0$ we have that $$\frac{f(z)-f(z_0)}{s} \rightarrow \xi_0\;\; \text{as} \;\; s\rightarrow 0$$ Since $f$ is real valued then we have that Im($\xi_0)=0$. Now taking $s=0$ and letting $t\rightarrow 0$ we have $$\frac{f(z)-f(z_0)}{it} \rightarrow \xi_0\;\; \text{as} \;\; t\rightarrow 0$$   $\textbf{Which implies that Re($\xi_0$)=0.}$","Cannot understand this proof that a real-valued function which is complex differentiable must have derivative at that point equal to zero. I just don't understand how the last statement in bold is validated. If $f$ is complex differentiable at $z_0$ then there exists a complex number $\xi_0$ such that $$\frac{f(z)-f(z_0)}{z-z_0} \rightarrow \xi_0\;\; \text{as} \;\; (z-z_0)\rightarrow 0$$   Let $\text{Re}(z-z_0)=s$ and $\text{Im}(z-z_0)=t$, so that $s+it=z-z_0$. Then taking $t=0$ and letting $s\rightarrow 0$ we have that $$\frac{f(z)-f(z_0)}{s} \rightarrow \xi_0\;\; \text{as} \;\; s\rightarrow 0$$ Since $f$ is real valued then we have that Im($\xi_0)=0$. Now taking $s=0$ and letting $t\rightarrow 0$ we have $$\frac{f(z)-f(z_0)}{it} \rightarrow \xi_0\;\; \text{as} \;\; t\rightarrow 0$$   $\textbf{Which implies that Re($\xi_0$)=0.}$",,"['complex-analysis', 'derivatives']"
66,"$f,g$ holomorphic functions and $|\,f(z)|^2+|\,f(z)|=|g(z)|^2+|g(z)|$",holomorphic functions and,"f,g |\,f(z)|^2+|\,f(z)|=|g(z)|^2+|g(z)|","If $f$, $g$ are holomorphic in a certain region of the complex plane and $$|\,f(z)|^2+|\,f(z)|=|g(z)|^2+|g(z)|$$  find the simplest possible relation between $f$ and $g$. I tried to differentiate both sides, but i did not get any result.","If $f$, $g$ are holomorphic in a certain region of the complex plane and $$|\,f(z)|^2+|\,f(z)|=|g(z)|^2+|g(z)|$$  find the simplest possible relation between $f$ and $g$. I tried to differentiate both sides, but i did not get any result.",,"['complex-analysis', 'analyticity']"
67,$f$ is bounded iff $\Omega $ is bounded,is bounded iff  is bounded,f \Omega ,"Let $\Omega \subseteq \Bbb C$ be an open and connected set  and let $f:\Omega \to \Bbb C$ be an analytic function .Pick out true ones: $f$ is bounded if $\Omega  $ is bounded 2.$f$ is bounded only if $\Omega  $ is bounded 3.$f$ is bounded iff $\Omega  $ is bounded. For $3$ I took $\Omega=\Bbb C$ and I took the map $z\mapsto e^{iy}$ where $z=x+iy $. Then $|f(z)|=1$ which is bounded but $\Omega=\Bbb C$  is not. Am I right? For $1,2$ I am not getting any examples .Any help will behelpful","Let $\Omega \subseteq \Bbb C$ be an open and connected set  and let $f:\Omega \to \Bbb C$ be an analytic function .Pick out true ones: $f$ is bounded if $\Omega  $ is bounded 2.$f$ is bounded only if $\Omega  $ is bounded 3.$f$ is bounded iff $\Omega  $ is bounded. For $3$ I took $\Omega=\Bbb C$ and I took the map $z\mapsto e^{iy}$ where $z=x+iy $. Then $|f(z)|=1$ which is bounded but $\Omega=\Bbb C$  is not. Am I right? For $1,2$ I am not getting any examples .Any help will behelpful",,['complex-analysis']
68,Find the value of $\frac{i}{4-\pi}\int_{|z|=4}\frac{1}{z\cos{z}}dz$,Find the value of,\frac{i}{4-\pi}\int_{|z|=4}\frac{1}{z\cos{z}}dz,"Find the value of $$\frac{i}{4-\pi}\int_{|z|=4}\frac{1}{z\cos{z}}dz$$. My attempt: The integrand has singularities at $z=0, \frac{\pi}{2}, \frac{-\pi}{2}$, so  $$\frac{i}{4-\pi}\int_{|z|=4}\frac{1}{z\cos{z}}dz=\frac{i}{4-\pi}2\pi i ~Res_{z=z_k}\phi(z)=\frac{-2\pi}{4-\pi}\{Res_{z=0}\frac{1}{\cos(z)}+Res_{z=\pi/2}\frac{1}{z}+Res_{z=-\pi/2}\frac{1}{z}\}=\frac{-2\pi}{4-\pi}$$ But the given answer is $2$. Where did I made mistake? Please help me out.","Find the value of $$\frac{i}{4-\pi}\int_{|z|=4}\frac{1}{z\cos{z}}dz$$. My attempt: The integrand has singularities at $z=0, \frac{\pi}{2}, \frac{-\pi}{2}$, so  $$\frac{i}{4-\pi}\int_{|z|=4}\frac{1}{z\cos{z}}dz=\frac{i}{4-\pi}2\pi i ~Res_{z=z_k}\phi(z)=\frac{-2\pi}{4-\pi}\{Res_{z=0}\frac{1}{\cos(z)}+Res_{z=\pi/2}\frac{1}{z}+Res_{z=-\pi/2}\frac{1}{z}\}=\frac{-2\pi}{4-\pi}$$ But the given answer is $2$. Where did I made mistake? Please help me out.",,"['complex-analysis', 'residue-calculus']"
69,Problem Requiring Little Picard's Theorem,Problem Requiring Little Picard's Theorem,,"While preparing for an exam I got stuck on the following question. Let $f$ and $g$ be entire functions such that $f(0) = g(0)$ and let $p$ and $q$ be polynomials such that the following equality holds: $e^{f(z)}+p(z) = e^{g(z)}+q(z)$. Prove, using the Picard's Little Theorem, that $f = g$ and $p=q$. I know the objective is to construct a function which omits two values, yet I don't have any solid idea how to begin. Any hint would be really appreciated.","While preparing for an exam I got stuck on the following question. Let $f$ and $g$ be entire functions such that $f(0) = g(0)$ and let $p$ and $q$ be polynomials such that the following equality holds: $e^{f(z)}+p(z) = e^{g(z)}+q(z)$. Prove, using the Picard's Little Theorem, that $f = g$ and $p=q$. I know the objective is to construct a function which omits two values, yet I don't have any solid idea how to begin. Any hint would be really appreciated.",,['complex-analysis']
70,"Branch points and Riemann surfaces (analytic continuation),","Branch points and Riemann surfaces (analytic continuation),",,"Take probably the most typical example: $$f(z) = \sqrt{1-z^2}$$ This function uses the (complex) logarithm to define it: $$e^{\large \frac{1}{2}\log(1-z^2)}$$ $$e^{\large \frac{1}{2}[\ln|1-z^2| + i\arg(1-z^2)]}$$ And so we can see that the function is not defined at $\pm1$.  They are so-called ""branch points"", and this function requires two branch cuts. So, my questions are: a)  is every point along the branch cut also called a ""branch point"", or is it just the ""starting point"" in the branch cut that is called a branch point? b) needing two branch cuts, does this mean we have two functions?  Way before seeing a function such as this one, we learn that for multi-valued ""functions"", once we specify a branch, it then becomes a well-defined, single-valued, genuine function.  But we usually only make one branch cut, though.  Or is the example I gave above just...one function requiring two branch cuts?  Then, making two branch cuts, does this mean we have chosen one branch of $f(z) = \sqrt{1-z^2}$? ...it doesn't mean that we have chosen two branches of the function, right? Thanks,","Take probably the most typical example: $$f(z) = \sqrt{1-z^2}$$ This function uses the (complex) logarithm to define it: $$e^{\large \frac{1}{2}\log(1-z^2)}$$ $$e^{\large \frac{1}{2}[\ln|1-z^2| + i\arg(1-z^2)]}$$ And so we can see that the function is not defined at $\pm1$.  They are so-called ""branch points"", and this function requires two branch cuts. So, my questions are: a)  is every point along the branch cut also called a ""branch point"", or is it just the ""starting point"" in the branch cut that is called a branch point? b) needing two branch cuts, does this mean we have two functions?  Way before seeing a function such as this one, we learn that for multi-valued ""functions"", once we specify a branch, it then becomes a well-defined, single-valued, genuine function.  But we usually only make one branch cut, though.  Or is the example I gave above just...one function requiring two branch cuts?  Then, making two branch cuts, does this mean we have chosen one branch of $f(z) = \sqrt{1-z^2}$? ...it doesn't mean that we have chosen two branches of the function, right? Thanks,",,"['complex-analysis', 'logarithms', 'analyticity', 'branch-cuts', 'branch-points']"
71,Can I use complex analysis to solve a vector calculus problem?,Can I use complex analysis to solve a vector calculus problem?,,"This is a question from a non-mathematician, so excuse me if I use a more plain language. Why can't I use complex analysis methods to solve a problem in vector calculus in 2 dimensions? Say we are in 2 dimensions; we have unit vectors $\hat{i}$ and $\hat{j}$ at the $x$ and $y$ axis respectively. If we replace the $\hat{j}$ with $\hat{i}$ and we make the y axis the imaginary axis, then what is the difference between solving a problem with complex analysis methods and solving it with vector calculus methods? Edit: I know that there should a difference but I do not know what it is.","This is a question from a non-mathematician, so excuse me if I use a more plain language. Why can't I use complex analysis methods to solve a problem in vector calculus in 2 dimensions? Say we are in 2 dimensions; we have unit vectors $\hat{i}$ and $\hat{j}$ at the $x$ and $y$ axis respectively. If we replace the $\hat{j}$ with $\hat{i}$ and we make the y axis the imaginary axis, then what is the difference between solving a problem with complex analysis methods and solving it with vector calculus methods? Edit: I know that there should a difference but I do not know what it is.",,"['complex-analysis', 'vector-spaces', 'vectors', 'vector-analysis']"
72,Local degree of a polynomial defined on the Riemann sphere at a root,Local degree of a polynomial defined on the Riemann sphere at a root,,"I'm working on a problem from Hatcher's Algebraic Topology, and I want to show that if we take polynomial $f(x)$ definded on the Riemann sphere mapping to the Riemann sphere, the local degree of the map (when viewed as a map $S^2 \to S^2$) at a root is equal to the multiplicity of the root. Intuitively this seems obvious because if we look at a neighborhood of some root with multiplicity $n$ and translate the function to the origin, we get a map that kind of looks like the map $z \to z^n$, given a sufficiently small neighborhood, which has degree $n$ as desired. My problem is making my claim rigorous because the polynomial does not map perfectly from $z \to z^n$ in the neighborhood. I'm not sure how to compute the local degree directly. I know it means looking at the induced map $H_2(U,U-x_0) \to H_2(f(U), f(U)-0)$ where $x_0$ is a root and $U$ is a neighborhood of $x_0$.","I'm working on a problem from Hatcher's Algebraic Topology, and I want to show that if we take polynomial $f(x)$ definded on the Riemann sphere mapping to the Riemann sphere, the local degree of the map (when viewed as a map $S^2 \to S^2$) at a root is equal to the multiplicity of the root. Intuitively this seems obvious because if we look at a neighborhood of some root with multiplicity $n$ and translate the function to the origin, we get a map that kind of looks like the map $z \to z^n$, given a sufficiently small neighborhood, which has degree $n$ as desired. My problem is making my claim rigorous because the polynomial does not map perfectly from $z \to z^n$ in the neighborhood. I'm not sure how to compute the local degree directly. I know it means looking at the induced map $H_2(U,U-x_0) \to H_2(f(U), f(U)-0)$ where $x_0$ is a root and $U$ is a neighborhood of $x_0$.",,"['complex-analysis', 'algebraic-topology']"
73,Does there exist a $C^1$-path path-homotopic to a rectifiable curve?,Does there exist a -path path-homotopic to a rectifiable curve?,C^1,"Related: https://math.stackexchange.com/questions/1441725/winding-number-and-cauchy-integral-formula Let $G$ be an open connected subset of $\mathbb{C}$. Let $\gamma:[0,1]\rightarrow G$ be a rectifiable curve. Then, does there exist a $C^1$-curve  $\Gamma:[0,1]\rightarrow G$ such that $\gamma$ and $\Gamma$ are homotopic relative to $\{0,1\}$ in $G$?","Related: https://math.stackexchange.com/questions/1441725/winding-number-and-cauchy-integral-formula Let $G$ be an open connected subset of $\mathbb{C}$. Let $\gamma:[0,1]\rightarrow G$ be a rectifiable curve. Then, does there exist a $C^1$-curve  $\Gamma:[0,1]\rightarrow G$ such that $\gamma$ and $\Gamma$ are homotopic relative to $\{0,1\}$ in $G$?",,"['complex-analysis', 'algebraic-topology']"
74,Laurent series of $e^{z+1/z}$,Laurent series of,e^{z+1/z},"What is the Laurent series  of $e^{z+1/z}$? I had used $$a_k= \frac{1}{2\pi i}\int_c \frac{f(z)}{z^{k+1}}\,dz $$ for a curve $c$ in which we can use $e^z$ as an analytic func. and expanded the $e^{1/z}$ series expansion.","What is the Laurent series  of $e^{z+1/z}$? I had used $$a_k= \frac{1}{2\pi i}\int_c \frac{f(z)}{z^{k+1}}\,dz $$ for a curve $c$ in which we can use $e^z$ as an analytic func. and expanded the $e^{1/z}$ series expansion.",,"['complex-analysis', 'laurent-series']"
75,Rigorous meaning of the expression $dz = dx + idy$,Rigorous meaning of the expression,dz = dx + idy,"Many complex analysis books just define $dz$ by $dz = dx + idy$. In smooth manifold theory, the expressions like $dx$, $dy$, $df$ have precise meaning: covector field. My question is: What is the precise meaning of the expression '$dz = dx + idy$'? Do we understand this expression in terms of linear functionals on tangent space?","Many complex analysis books just define $dz$ by $dz = dx + idy$. In smooth manifold theory, the expressions like $dx$, $dy$, $df$ have precise meaning: covector field. My question is: What is the precise meaning of the expression '$dz = dx + idy$'? Do we understand this expression in terms of linear functionals on tangent space?",,['complex-analysis']
76,single valued analytic branch of multivalued function,single valued analytic branch of multivalued function,,Consider $f(z)=\sqrt{z\sin z}$. Can $f(z)$ be defined near the origin as a single valued analytic function? How do we choose the branch cut. The answer is here http://math.nyu.edu/student_resources/wwiki/index.php/Complex_Variables:_1999_September:_Problem_4 but this is not comprehensible,Consider $f(z)=\sqrt{z\sin z}$. Can $f(z)$ be defined near the origin as a single valued analytic function? How do we choose the branch cut. The answer is here http://math.nyu.edu/student_resources/wwiki/index.php/Complex_Variables:_1999_September:_Problem_4 but this is not comprehensible,,"['real-analysis', 'complex-analysis', 'branch-cuts', 'multivalued-functions']"
77,Regarding a complex analysis problem.,Regarding a complex analysis problem.,,"I'm trying to do this problem from Gamelin's book: Let $f_n(z)$ be a sequence of analytic functions on a domain (= open connected set) $D$ such that $f_n(D) \subset D,$ and suppose that $f_n$ converges to $f$ uniformly on each compact subset of $D$. Show that either $f(D)\subset D$, or $f(D)$ consists of a single point in $\partial D$. Now, I can see that $f(D) \subset D\cup \partial D$. If $f$ is not constant, then by open mapping theorem, $f(D)$ is open, so no point in the boundary can be in the image of $f$, hence in this case $f(D) \subset D$. But if $f$ is constant, I can't figure out why the mage of $f$ must be a point in the boundary. Why can't the image be in $D$? Thanks in advance.","I'm trying to do this problem from Gamelin's book: Let $f_n(z)$ be a sequence of analytic functions on a domain (= open connected set) $D$ such that $f_n(D) \subset D,$ and suppose that $f_n$ converges to $f$ uniformly on each compact subset of $D$. Show that either $f(D)\subset D$, or $f(D)$ consists of a single point in $\partial D$. Now, I can see that $f(D) \subset D\cup \partial D$. If $f$ is not constant, then by open mapping theorem, $f(D)$ is open, so no point in the boundary can be in the image of $f$, hence in this case $f(D) \subset D$. But if $f$ is constant, I can't figure out why the mage of $f$ must be a point in the boundary. Why can't the image be in $D$? Thanks in advance.",,['complex-analysis']
78,Fourier transforms of $f(t)=\frac{\sin{at}}{t}$,Fourier transforms of,f(t)=\frac{\sin{at}}{t},"I want to derive the following pair of Fourier transforms: First: $$f(t)=\dfrac{\sin{at}}{t}$$ $$F(\lambda)= \begin{cases}     \sqrt{\dfrac{\pi}{2}}, & \text{if } |\lambda|<a \\     0, & \text{if } |\lambda|>a \end{cases}$$ Second: $$f(t)=(a^2+t^2)^{-1}$$ $$F(\lambda)=\sqrt{\dfrac{\pi}{2}}\cdot\dfrac{e^{-a|\lambda|}}{a}$$ What I have done: I have started using the definition of $F(\lambda)$, the fourier transform of $f(t)$, as: $$F(\lambda)=\dfrac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}{e^{i\lambda \tau}f(\tau)d\tau}$$ So, for the first function: $f(t)=\dfrac{\sin{at}}{t}$ $$\implies F(\lambda)=\dfrac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}{e^{i\lambda \tau}\dfrac{\sin{a\tau}}{\tau}d\tau}$$ But I don't know how to integrate this.","I want to derive the following pair of Fourier transforms: First: $$f(t)=\dfrac{\sin{at}}{t}$$ $$F(\lambda)= \begin{cases}     \sqrt{\dfrac{\pi}{2}}, & \text{if } |\lambda|<a \\     0, & \text{if } |\lambda|>a \end{cases}$$ Second: $$f(t)=(a^2+t^2)^{-1}$$ $$F(\lambda)=\sqrt{\dfrac{\pi}{2}}\cdot\dfrac{e^{-a|\lambda|}}{a}$$ What I have done: I have started using the definition of $F(\lambda)$, the fourier transform of $f(t)$, as: $$F(\lambda)=\dfrac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}{e^{i\lambda \tau}f(\tau)d\tau}$$ So, for the first function: $f(t)=\dfrac{\sin{at}}{t}$ $$\implies F(\lambda)=\dfrac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}{e^{i\lambda \tau}\dfrac{\sin{a\tau}}{\tau}d\tau}$$ But I don't know how to integrate this.",,"['complex-analysis', 'fourier-analysis']"
79,Evaluate $\Im \left (\frac{1}{100\times 2^{100}}(e^{2\iota x} -1)^{100}\right )$,Evaluate,\Im \left (\frac{1}{100\times 2^{100}}(e^{2\iota x} -1)^{100}\right ),"I was trying to evaluate $$\int \sin(101x)\sin^{99}(x) dx$$ I managed to work it out to $$\Im  \left (\frac{1}{100\times 2^{100}}(e^{2\iota x} -1)^{100}\right )$$ However, I got stuck over here. Another hint that was given to me was to factor out $e^{100\iota x}$ . However, I cannot even understand how to factor this out (sorry but my factorization has always been weak no matter how much I practice). In fact, I couldn't even understand how or why factoring this out would help. $$$$ I would be truly grateful for any assistance in factoring out $e^{100 \iota x}$ and also explaining why this helps. Many, many thanks in advance! $$$$ Edit: Upon factoring, I seem to be getting $$\Im  \left(\frac{1}{100\times 2^{100}}(e^{100\iota x})^{100}(e^{-98\iota x} -e^{-100\iota x})^{100}\right )$$ Unfortunately I cannot understand what to do next.","I was trying to evaluate I managed to work it out to However, I got stuck over here. Another hint that was given to me was to factor out . However, I cannot even understand how to factor this out (sorry but my factorization has always been weak no matter how much I practice). In fact, I couldn't even understand how or why factoring this out would help. I would be truly grateful for any assistance in factoring out and also explaining why this helps. Many, many thanks in advance! Edit: Upon factoring, I seem to be getting Unfortunately I cannot understand what to do next.",\int \sin(101x)\sin^{99}(x) dx \Im  \left (\frac{1}{100\times 2^{100}}(e^{2\iota x} -1)^{100}\right ) e^{100\iota x}  e^{100 \iota x}  \Im  \left(\frac{1}{100\times 2^{100}}(e^{100\iota x})^{100}(e^{-98\iota x} -e^{-100\iota x})^{100}\right ),"['calculus', 'integration', 'complex-analysis', 'definite-integrals']"
80,Non Existence of a proper holomorphic map from the punctured unit disc to an Annulus,Non Existence of a proper holomorphic map from the punctured unit disc to an Annulus,,Show that there is no proper holomorphic map from the punctured unit disc to an annulus  $A_r=\{z \in \mathbb C:1 <|z| < r \}$. Def :A map $f: X \to Y$ is called proper if $f^{-1}(K)$ is compact for every compact set $K$ in Y. please give some hints/ideas to prove this.Can someone please give a reference for reading about construction of proper maps between different domains in $ \mathbb C$ ?,Show that there is no proper holomorphic map from the punctured unit disc to an annulus  $A_r=\{z \in \mathbb C:1 <|z| < r \}$. Def :A map $f: X \to Y$ is called proper if $f^{-1}(K)$ is compact for every compact set $K$ in Y. please give some hints/ideas to prove this.Can someone please give a reference for reading about construction of proper maps between different domains in $ \mathbb C$ ?,,['complex-analysis']
81,Understanding angle-preserving definition,Understanding angle-preserving definition,,"My book (Real and complex analysis, by Rudin) gives the following definition: Let $A(z) = \frac z{|z|}$. Then we say $f$ preserves angles at $z_0$ if $$\lim_{r \to 0}e^{-i\theta} A[f(z_0 + re^{i\theta} )- f(z_0)] \ \ \ \ (r > 0)$$ exists and it is independent of $\theta$. It then adds The requirements is that fr any two rays $L'$ and $L''$ starting at   $z_0$, the angles which their images $f(L')$ and $f(L'')$ make at   $f(z_0)$ is the same as that made by $L'$ and $L''$ in size as well   orientation I am trying to understand why the definition says that. Does anyone know of a cool geometric interpretation? My thoughts $A(z)$ returns a complex number on the unit circle whose argument is the argument of $z$. So $A(z - w)$ basically is a measure of the angle between $z$ and $w$. Now in the definition I take the angle between $f(z_0 + re^{i \theta})$ and $f(z_0)$, and divide it by $e^{i \theta}$ (meaning I rotate by $-\theta$ our number). Since the original angle between $z_0$ and $z_0 + re^{i \theta}$ is $\theta$, if I want angles to be preserved, I would like the result to have an argument of $0$, right? Why is instead required the limit to exists and be independent of $\theta$? Moreover, the reason why we take the limit is because we only care about local properties of the function, right? Finally, why was it defined this way? I mean one could be naive and define it like $$\lim_{r \to 0} \arg(f(z_0 + re^{i\theta}) - f(z_0)) = \theta$$. What's the reason this isn't a good definition for our purposes?","My book (Real and complex analysis, by Rudin) gives the following definition: Let $A(z) = \frac z{|z|}$. Then we say $f$ preserves angles at $z_0$ if $$\lim_{r \to 0}e^{-i\theta} A[f(z_0 + re^{i\theta} )- f(z_0)] \ \ \ \ (r > 0)$$ exists and it is independent of $\theta$. It then adds The requirements is that fr any two rays $L'$ and $L''$ starting at   $z_0$, the angles which their images $f(L')$ and $f(L'')$ make at   $f(z_0)$ is the same as that made by $L'$ and $L''$ in size as well   orientation I am trying to understand why the definition says that. Does anyone know of a cool geometric interpretation? My thoughts $A(z)$ returns a complex number on the unit circle whose argument is the argument of $z$. So $A(z - w)$ basically is a measure of the angle between $z$ and $w$. Now in the definition I take the angle between $f(z_0 + re^{i \theta})$ and $f(z_0)$, and divide it by $e^{i \theta}$ (meaning I rotate by $-\theta$ our number). Since the original angle between $z_0$ and $z_0 + re^{i \theta}$ is $\theta$, if I want angles to be preserved, I would like the result to have an argument of $0$, right? Why is instead required the limit to exists and be independent of $\theta$? Moreover, the reason why we take the limit is because we only care about local properties of the function, right? Finally, why was it defined this way? I mean one could be naive and define it like $$\lim_{r \to 0} \arg(f(z_0 + re^{i\theta}) - f(z_0)) = \theta$$. What's the reason this isn't a good definition for our purposes?",,"['complex-analysis', 'analysis', 'complex-numbers', 'conformal-geometry']"
82,Let f be analytic on ∆,Let f be analytic on ∆,,"The problem is: let $f$ be an analytic function on $\Delta$ and satisfy $|f|<1$. Prove that if $f(1/2)=f(−1/2)=0$, then $|f'(0)|\le 1/4$. I tried to expand $f$ at $0$ and then plug in $1/2$ and $-1/2$ to evaluate the bound. It is quite straight forward if I use $f^{(n)}(0)/n! < 1$. But I got the bound to be $1/3$. Is there some key I am missing here?","The problem is: let $f$ be an analytic function on $\Delta$ and satisfy $|f|<1$. Prove that if $f(1/2)=f(−1/2)=0$, then $|f'(0)|\le 1/4$. I tried to expand $f$ at $0$ and then plug in $1/2$ and $-1/2$ to evaluate the bound. It is quite straight forward if I use $f^{(n)}(0)/n! < 1$. But I got the bound to be $1/3$. Is there some key I am missing here?",,['complex-analysis']
83,prove that 2 by 2 Jacobian is equal to $|f'(z_0)|^2$,prove that 2 by 2 Jacobian is equal to,|f'(z_0)|^2,"This is a question in Complex Analysis for Mathematical Science and Engineering by Saff and Snider. It's on pg 62. Question: The Jacobian of a mapping $u = u(x,y)$ $v = v(x,y)$ from the xy-plane to the uv-plane is defined to be the determinant  $$ J(x_0,y_0) := \begin{vmatrix} \frac{\partial{u}}{\partial{x}} &&  \frac{\partial{u}}{\partial{y}} \\ \frac{\partial{v}}{\partial{x}} &&  \frac{\partial{v}}{\partial{y}} \end{vmatrix}$$ Where the derivatives are all evaluated at $(x_0, y_0)$. Show that if $f = u + iv$ is analytic at $z_0 = x_0 + iy_0$, then $J(x_0,y_0) = |f'(z_0)|^2$. My attempt to answer: Given f'(z) is analytic $f'(z) = \frac{\partial{u}}{\partial{x}} + i\frac{\partial{v}}{\partial{x}}$ which leads us to $|f'(z_0)|^2 = \frac{\partial{u}}{\partial{x}}^2 - \frac{\partial{v}}{\partial{x}}^2$. We can now use the Cauchy-Riemann equations as substitutions;  $$|f'(z_0)|^2 = \frac{\partial{u}}{\partial{x}}\left(\frac{\partial{y}}{\partial{y}} \right)- \frac{\partial{v}}{\partial{x}}\left(-\frac{\partial{v}}{\partial{x}}\right) $$ But now the minus signs in the second term cancel and it is positive. The second term from the determinant should be negative. What did I do wrong?","This is a question in Complex Analysis for Mathematical Science and Engineering by Saff and Snider. It's on pg 62. Question: The Jacobian of a mapping $u = u(x,y)$ $v = v(x,y)$ from the xy-plane to the uv-plane is defined to be the determinant  $$ J(x_0,y_0) := \begin{vmatrix} \frac{\partial{u}}{\partial{x}} &&  \frac{\partial{u}}{\partial{y}} \\ \frac{\partial{v}}{\partial{x}} &&  \frac{\partial{v}}{\partial{y}} \end{vmatrix}$$ Where the derivatives are all evaluated at $(x_0, y_0)$. Show that if $f = u + iv$ is analytic at $z_0 = x_0 + iy_0$, then $J(x_0,y_0) = |f'(z_0)|^2$. My attempt to answer: Given f'(z) is analytic $f'(z) = \frac{\partial{u}}{\partial{x}} + i\frac{\partial{v}}{\partial{x}}$ which leads us to $|f'(z_0)|^2 = \frac{\partial{u}}{\partial{x}}^2 - \frac{\partial{v}}{\partial{x}}^2$. We can now use the Cauchy-Riemann equations as substitutions;  $$|f'(z_0)|^2 = \frac{\partial{u}}{\partial{x}}\left(\frac{\partial{y}}{\partial{y}} \right)- \frac{\partial{v}}{\partial{x}}\left(-\frac{\partial{v}}{\partial{x}}\right) $$ But now the minus signs in the second term cancel and it is positive. The second term from the determinant should be negative. What did I do wrong?",,['complex-analysis']
84,Cauchy's Integral parametric conjugate,Cauchy's Integral parametric conjugate,,"By considering the conjugate of its parametric form, evaluate $$\frac{1}{2\pi i}\int_{\gamma(0;1)}\frac{\overline{f(z)}}{z-a}dz$$ when $|a|<1$ and $|a|>1$, where $f$ is holomorphic in in the disk $(0;R),  R>1$. Typically when doing these kinds of integration and parametrization, $|z|=n$ is given, but it's different in this case (or is it not?). Can someone help me out?","By considering the conjugate of its parametric form, evaluate $$\frac{1}{2\pi i}\int_{\gamma(0;1)}\frac{\overline{f(z)}}{z-a}dz$$ when $|a|<1$ and $|a|>1$, where $f$ is holomorphic in in the disk $(0;R),  R>1$. Typically when doing these kinds of integration and parametrization, $|z|=n$ is given, but it's different in this case (or is it not?). Can someone help me out?",,"['complex-analysis', 'complex-integration']"
85,"suppose $|a|<1$, show that $\frac{z-a}{1-\overline{a}z}$ is a mobius transformation that sends $B(0,1)$ to itself.","suppose , show that  is a mobius transformation that sends  to itself.","|a|<1 \frac{z-a}{1-\overline{a}z} B(0,1)","Suppose $|a|<1$, show that $f(x) = \frac{z-a}{1-\overline{a}z}$ is a mobius transformation that sends $B(0,1)$ to itself. To make such a mobius transformation i tried to send 3 points on the edge to 3 points of the edge. so filling $i,1,-1$ in $f(x)$ we should get on the edges of the unit ball. But i don't seem to know how to calculate these exactly: $$f(1) = \frac{1-a}{1-\overline{a}1}$$ $$f(-1) = \frac{-1-a}{1+\overline{a}}$$ $$f(1) = \frac{i-a}{1-\overline{a}i}$$ I don't seem to get how i could write these formula's in such a way that i get into the edges of the circle. Anyone can help me? Kees","Suppose $|a|<1$, show that $f(x) = \frac{z-a}{1-\overline{a}z}$ is a mobius transformation that sends $B(0,1)$ to itself. To make such a mobius transformation i tried to send 3 points on the edge to 3 points of the edge. so filling $i,1,-1$ in $f(x)$ we should get on the edges of the unit ball. But i don't seem to know how to calculate these exactly: $$f(1) = \frac{1-a}{1-\overline{a}1}$$ $$f(-1) = \frac{-1-a}{1+\overline{a}}$$ $$f(1) = \frac{i-a}{1-\overline{a}i}$$ I don't seem to get how i could write these formula's in such a way that i get into the edges of the circle. Anyone can help me? Kees",,"['complex-analysis', 'transformation', 'linear-transformations']"
86,Ahlfors method for partial fraction decomposition,Ahlfors method for partial fraction decomposition,,"On page 31 in Complex Analysis by Ahlfors, he discusses decomposing a rational function into  $$ R(z) = G(z) + H(z)\tag{12} $$  where $G(z)$ is a polynomial without a constant term and is the singular part. Then he goes on to say let $\beta_i$ be the distinct finite poles of $R(z)$. The function $R(\beta_i + 1/\zeta)$ is a rational function of $\zeta$ with a pole at $\infty$. By use of the decomposition of $(12)$, we can write $$ R(\beta_i+1/\zeta) = G_i(\zeta) + H_i(\zeta) $$  or with a change of variables $$ R(z) = G_i(1/(z-\beta_i)) + H_i(1/(z-\beta_i)) $$  Using the method developed in the text, write  $$ \frac{z^4}{z^3-1} $$  in partial fractions. If I just do division, I get $$ \frac{z^4}{z^3-1} = z + \frac{z}{z^3-1} $$ and the solution is quick and efficient. If I try to use the method developed in the text, (1) I am not able to get the correct answer and (2) it seems to hold no advantage to polynomial division. The poles are $z=1, e^{2\pi i/3}, e^{4\pi i/3}$ so $$ R(1+1/\zeta) = \frac{(1+1/\zeta)^4}{(1+1/\zeta)^3 - 1} $$ Should I expand the polynomials or multiple through by $\zeta^4$ and then expand? Both methods for the first pole would take more time then just polynomial division so I am under the impression there has to be an option three or this method wouldn't be of benefit to learn.","On page 31 in Complex Analysis by Ahlfors, he discusses decomposing a rational function into  $$ R(z) = G(z) + H(z)\tag{12} $$  where $G(z)$ is a polynomial without a constant term and is the singular part. Then he goes on to say let $\beta_i$ be the distinct finite poles of $R(z)$. The function $R(\beta_i + 1/\zeta)$ is a rational function of $\zeta$ with a pole at $\infty$. By use of the decomposition of $(12)$, we can write $$ R(\beta_i+1/\zeta) = G_i(\zeta) + H_i(\zeta) $$  or with a change of variables $$ R(z) = G_i(1/(z-\beta_i)) + H_i(1/(z-\beta_i)) $$  Using the method developed in the text, write  $$ \frac{z^4}{z^3-1} $$  in partial fractions. If I just do division, I get $$ \frac{z^4}{z^3-1} = z + \frac{z}{z^3-1} $$ and the solution is quick and efficient. If I try to use the method developed in the text, (1) I am not able to get the correct answer and (2) it seems to hold no advantage to polynomial division. The poles are $z=1, e^{2\pi i/3}, e^{4\pi i/3}$ so $$ R(1+1/\zeta) = \frac{(1+1/\zeta)^4}{(1+1/\zeta)^3 - 1} $$ Should I expand the polynomials or multiple through by $\zeta^4$ and then expand? Both methods for the first pole would take more time then just polynomial division so I am under the impression there has to be an option three or this method wouldn't be of benefit to learn.",,"['complex-analysis', 'polynomials', 'partial-fractions']"
87,Cauchy-Riemann conditions satisfying the Laplacian,Cauchy-Riemann conditions satisfying the Laplacian,,"How does one convert the Cauchy-Riemann conditions  into the form: $$\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2u}{\partial y^2} = 0, \qquad \frac{\partial^2 v}{\partial x^2} + \frac{\partial^2v}{\partial y^2} = 0$$ from $$\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}, \qquad \frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x}$$ to show that a differentiable complex function has real and imaginary parts that separately satisfy the Laplace equation? The book that I'm working with says that by ""differentiating first with respect to x and then with respect to y, one easily obtains (equation 2)"", but my calc3 is weak and I fail to see it.","How does one convert the Cauchy-Riemann conditions  into the form: $$\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2u}{\partial y^2} = 0, \qquad \frac{\partial^2 v}{\partial x^2} + \frac{\partial^2v}{\partial y^2} = 0$$ from $$\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}, \qquad \frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x}$$ to show that a differentiable complex function has real and imaginary parts that separately satisfy the Laplace equation? The book that I'm working with says that by ""differentiating first with respect to x and then with respect to y, one easily obtains (equation 2)"", but my calc3 is weak and I fail to see it.",,"['complex-analysis', 'multivariable-calculus', 'derivatives']"
88,Simplify $\frac{\Gamma(n)}{\Gamma(n+a)}$ with $a\in\mathbb C$.,Simplify  with .,\frac{\Gamma(n)}{\Gamma(n+a)} a\in\mathbb C,"How can simplify the following expression? $$\frac{\Gamma(n)}{\Gamma(n+a)}\sim \cdots\text{ ?}$$ Where $a\in\mathbb C$, $n\in \mathbb N$. Any suggestions please? I propose the following. We have the classical Stirling's   approximation formula for the Gamma-Function in the form: $$   \Gamma(z)=\sqrt{2\pi}e^{-z}z^{z-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right)  $$ for $|\arg(z)|<\pi$ as $|z|\to\infty$. And, from another question here there is also the shifted   Stirling's approximation for the Gamma-Function due to C. Rowe that   says: $$   \Gamma(z+a)=\sqrt{2\pi}e^{-z}z^{z+a-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ Therefore $$   \frac{\Gamma(z)}{\Gamma(z+a)}=\frac{\sqrt{2\pi}e^{-z}z^{z-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right)}{\sqrt{2\pi}e^{-z}z^{z+a-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right)}=\frac{\left(1+O\left(\frac{1}{|z|}\right)\right)}{z^a\left(1+O\left(\frac{1}{|z|}\right)\right)} $$ and: $$   \frac{\Gamma(n)}{\Gamma(n+a)}\sim n^{-a} \ \ \ (n\rightarrow \infty) $$ I would appreciate some corrections on this procedure. Thanks.","How can simplify the following expression? $$\frac{\Gamma(n)}{\Gamma(n+a)}\sim \cdots\text{ ?}$$ Where $a\in\mathbb C$, $n\in \mathbb N$. Any suggestions please? I propose the following. We have the classical Stirling's   approximation formula for the Gamma-Function in the form: $$   \Gamma(z)=\sqrt{2\pi}e^{-z}z^{z-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right)  $$ for $|\arg(z)|<\pi$ as $|z|\to\infty$. And, from another question here there is also the shifted   Stirling's approximation for the Gamma-Function due to C. Rowe that   says: $$   \Gamma(z+a)=\sqrt{2\pi}e^{-z}z^{z+a-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ Therefore $$   \frac{\Gamma(z)}{\Gamma(z+a)}=\frac{\sqrt{2\pi}e^{-z}z^{z-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right)}{\sqrt{2\pi}e^{-z}z^{z+a-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right)}=\frac{\left(1+O\left(\frac{1}{|z|}\right)\right)}{z^a\left(1+O\left(\frac{1}{|z|}\right)\right)} $$ and: $$   \frac{\Gamma(n)}{\Gamma(n+a)}\sim n^{-a} \ \ \ (n\rightarrow \infty) $$ I would appreciate some corrections on this procedure. Thanks.",,"['complex-analysis', 'special-functions']"
89,Proving $\Gamma(x)$ is holomorphic,Proving  is holomorphic,\Gamma(x),"My professor defined Gamma function in the following way:$$\Gamma(z)= \lim \limits_{n \rightarrow \infty} \frac{n!n^z}{z(z+1)....(z+n)}$$ Now we first observe that $f_n(z)= \frac{n!n^z}{z(z+1)....(z+n)}$ is holomorphic in ${\operatorname{Re} z>0}$. Then we have to show that the limit exists and also that $f_n$ converge uniformly. But I am unable to show that limit exists also I cannot prove that $f_n$ converge uniformly. If anyone can give a hint, it would be really great. Thank you.","My professor defined Gamma function in the following way:$$\Gamma(z)= \lim \limits_{n \rightarrow \infty} \frac{n!n^z}{z(z+1)....(z+n)}$$ Now we first observe that $f_n(z)= \frac{n!n^z}{z(z+1)....(z+n)}$ is holomorphic in ${\operatorname{Re} z>0}$. Then we have to show that the limit exists and also that $f_n$ converge uniformly. But I am unable to show that limit exists also I cannot prove that $f_n$ converge uniformly. If anyone can give a hint, it would be really great. Thank you.",,"['complex-analysis', 'limits', 'uniform-convergence', 'gamma-function']"
90,Is the Riemann sphere conformal equivalent to the 2-sphere?,Is the Riemann sphere conformal equivalent to the 2-sphere?,,"Today I stumbled across the calculation (mentioned in this post ) of the transition maps of the stereographic projections from the 2-sphere to the plane. And I wondered about the result that the last transition map is $1/z^*$ (I guess that the $^*$ stands here for complex conjugation) and not $1/z$. That means one can only show (with these projections) that the 2-sphere $\mathbb{S}^2$ and the Riemann sphere $\mathbb{\bar C}$ are ""just"" diffeomorphic. But is there any biholomorphic map between $\mathbb{S}^2$ and $\mathbb{\bar C}$?","Today I stumbled across the calculation (mentioned in this post ) of the transition maps of the stereographic projections from the 2-sphere to the plane. And I wondered about the result that the last transition map is $1/z^*$ (I guess that the $^*$ stands here for complex conjugation) and not $1/z$. That means one can only show (with these projections) that the 2-sphere $\mathbb{S}^2$ and the Riemann sphere $\mathbb{\bar C}$ are ""just"" diffeomorphic. But is there any biholomorphic map between $\mathbb{S}^2$ and $\mathbb{\bar C}$?",,"['complex-analysis', 'riemann-surfaces', 'stereographic-projections']"
91,"Integral along a contour is $0$, how?","Integral along a contour is , how?",0,"I recently had an extremely failed attempt at asking the same question, so I am posting the same question more or less to hope that someone can give me feedback. Consider the integral: $$\int_{0}^{\infty} \frac{\log^2(x)}{x^2 + 1} dx$$ $\hskip1in$ Image taken and modified from: Complex Analysis Solution (Please Read for background information). $R$ is the big radius, $\delta$ is the small radius. Actually, lets consider $u$ the small radius. Let $\delta = u$ Ultimately the goal is to let $u \to 0$ We can parametrize, $$z = ue^{i\theta}$$ $$\int_{\delta} f(z)dz = (-)\cdot\int_{0}^{\pi} \frac{(i\theta + \log(u))^2\cdot (uie^{i\theta})}{(ue^{i\theta})^2 + 1} d\theta$$ $$\left |  \int_{0}^{\pi} \frac{(i\theta + \log(u))^2\cdot (uie^{i\theta})}{(ue^{i\theta})^2 + 1} d\theta  \right | \le \int_{0}^{\pi} \frac{|(i\theta + \log(u))|^2\cdot(u)}{|(ue^{i\theta})^2 + 1  |} d\theta$$ $$|(ue^{i\theta})^2 + 1  | <  u^2 + 1 $$ $$\frac{1}{u^2 + 1} < \frac{1}{|(ue^{i\theta})^2 + 1  |}$$ Since the maximum value of $\theta$ is $\theta = \pi$ $$|(i\theta + \log(u))| = \sqrt{\log^2(u) - \theta^2} \le \sqrt{\log^2(u) + \pi^2}$$ So: $$|(i\theta + \log(u))|^2 \le \log^2(u) + \pi^2$$ Then: $$|(i\theta + \log(u))|^2 \le \log^2(u) + \pi^2$$ For values $u$ near $0$. $$(u)|(i\theta + \log(u))|^2 \le (\log^2(u) + \pi^2)u \le (\pi^2)u + 5\pi^2$$ Therefore, $$\frac{|\log(z)|}{|z^2 + 1|} \le \frac{(\pi^2)u + 5\pi^2}{u^2 + 1}$$ Then we take the limit as $u \to 0$ which makes the RHS of the inequality 0. hence the LHS upperbound is $0$. So is the contour integral around the small semi circle $\delta = 0$? How do I do this? Thanks","I recently had an extremely failed attempt at asking the same question, so I am posting the same question more or less to hope that someone can give me feedback. Consider the integral: $$\int_{0}^{\infty} \frac{\log^2(x)}{x^2 + 1} dx$$ $\hskip1in$ Image taken and modified from: Complex Analysis Solution (Please Read for background information). $R$ is the big radius, $\delta$ is the small radius. Actually, lets consider $u$ the small radius. Let $\delta = u$ Ultimately the goal is to let $u \to 0$ We can parametrize, $$z = ue^{i\theta}$$ $$\int_{\delta} f(z)dz = (-)\cdot\int_{0}^{\pi} \frac{(i\theta + \log(u))^2\cdot (uie^{i\theta})}{(ue^{i\theta})^2 + 1} d\theta$$ $$\left |  \int_{0}^{\pi} \frac{(i\theta + \log(u))^2\cdot (uie^{i\theta})}{(ue^{i\theta})^2 + 1} d\theta  \right | \le \int_{0}^{\pi} \frac{|(i\theta + \log(u))|^2\cdot(u)}{|(ue^{i\theta})^2 + 1  |} d\theta$$ $$|(ue^{i\theta})^2 + 1  | <  u^2 + 1 $$ $$\frac{1}{u^2 + 1} < \frac{1}{|(ue^{i\theta})^2 + 1  |}$$ Since the maximum value of $\theta$ is $\theta = \pi$ $$|(i\theta + \log(u))| = \sqrt{\log^2(u) - \theta^2} \le \sqrt{\log^2(u) + \pi^2}$$ So: $$|(i\theta + \log(u))|^2 \le \log^2(u) + \pi^2$$ Then: $$|(i\theta + \log(u))|^2 \le \log^2(u) + \pi^2$$ For values $u$ near $0$. $$(u)|(i\theta + \log(u))|^2 \le (\log^2(u) + \pi^2)u \le (\pi^2)u + 5\pi^2$$ Therefore, $$\frac{|\log(z)|}{|z^2 + 1|} \le \frac{(\pi^2)u + 5\pi^2}{u^2 + 1}$$ Then we take the limit as $u \to 0$ which makes the RHS of the inequality 0. hence the LHS upperbound is $0$. So is the contour integral around the small semi circle $\delta = 0$? How do I do this? Thanks",,"['calculus', 'real-analysis', 'integration', 'complex-analysis', 'proof-writing']"
92,"What conditions are necessary on $a,b,c,d$ so that the Möbius transformation $w=\frac{az-b}{cz-d}$ has only one fixed point?",What conditions are necessary on  so that the Möbius transformation  has only one fixed point?,"a,b,c,d w=\frac{az-b}{cz-d}","Question: What conditions are necessary on $a,b,c,d$ so that the Möbius transformation $w=\frac{az-b}{cz-d}$ has only one fixed point? Attempt: We examine $$ z=\frac{az-b}{cz-d}$$ to find that any fixed point of a Möbius transformation must satisfy $$cz^2 + (d-a)z - b =0.$$ Hence, there are either one or two fixed points in $\mathbb{R}$ OR two fixed points in $\mathbb{C}$ which are all characterized by $$z = \frac{(a-d) \pm \sqrt{(d-a)^2+4bc}}{2c}.$$ Hence, there can only be a fixed point when the discriminant $(d-a)^2+4bc$ is zero. Further, if there is only one fixed point, it must be in $\mathbb{R}$. Can someone with more knowledge than me comment on if my approach is right? Is there a better way to solve this question?","Question: What conditions are necessary on $a,b,c,d$ so that the Möbius transformation $w=\frac{az-b}{cz-d}$ has only one fixed point? Attempt: We examine $$ z=\frac{az-b}{cz-d}$$ to find that any fixed point of a Möbius transformation must satisfy $$cz^2 + (d-a)z - b =0.$$ Hence, there are either one or two fixed points in $\mathbb{R}$ OR two fixed points in $\mathbb{C}$ which are all characterized by $$z = \frac{(a-d) \pm \sqrt{(d-a)^2+4bc}}{2c}.$$ Hence, there can only be a fixed point when the discriminant $(d-a)^2+4bc$ is zero. Further, if there is only one fixed point, it must be in $\mathbb{R}$. Can someone with more knowledge than me comment on if my approach is right? Is there a better way to solve this question?",,"['complex-analysis', 'mobius-transformation']"
93,Mandelbrot and Julia Set,Mandelbrot and Julia Set,,"Consider a dynamical system  $$z_{n+1}=\frac{\alpha+z_n}{1+z_{n-1}}$$ for $n=0,1,2,\dots$ In other words the system is $$z_{n+1}=f_{\alpha}(z_n,z_{n-1})$$ where $f_{\alpha}$ is defined from $B(z,r)\times B(z,r)$ to $B(z,r)$ as $f_{\alpha}(z,w)=\frac{\alpha+z}{1+w}$. $B(z,r)$ is an open ball in complex plane. How can we find out the Mandelbrot and Julia sets for this system?","Consider a dynamical system  $$z_{n+1}=\frac{\alpha+z_n}{1+z_{n-1}}$$ for $n=0,1,2,\dots$ In other words the system is $$z_{n+1}=f_{\alpha}(z_n,z_{n-1})$$ where $f_{\alpha}$ is defined from $B(z,r)\times B(z,r)$ to $B(z,r)$ as $f_{\alpha}(z,w)=\frac{\alpha+z}{1+w}$. $B(z,r)$ is an open ball in complex plane. How can we find out the Mandelbrot and Julia sets for this system?",,"['complex-analysis', 'complex-dynamics']"
94,Find the Fourier transform of $u(x) = \frac{x \cos(2x)}{(1+x^2)^2}$,Find the Fourier transform of,u(x) = \frac{x \cos(2x)}{(1+x^2)^2},"Find the Fourier transform of $$u(x) = \frac{x \cos(2x)}{(1+x^2)^2}$$ My work Okay so we want $$\int_\mathbb R \frac{e^{-ixt}x\cos(2x)}{(1+x^2)^2}dx$$ Of course we want to apply the residue theorem on the function $\displaystyle f(z) = \frac{e^{-izt}z\cos(2z)}{(1+z^2)^2}$ But on which path? I thought; let $z = \rho (\cos \theta + i \sin \theta)$, we know  that we will want eventually $\rho \to \infty$ to find our integral over $\mathbb R$. But $$|f(z)| \le \frac{e^{(t-2)\rho\sin\theta} + e^{(t+2)\rho\sin\theta}}{2\rho^3}$$ So if $t < -2$, we can integrate over the positive semicircle as we see that $|f(z)| \to 0$ If $t > 2$, we can integrate over the negative semicircle; again $|f(z)| \to 0$. But if $-2 < t < 2$? Circles are out of the question; our only hope is to maintain $\rho \sin \theta = \text{Im }(z)$ bounded, so the function still tends to $0$ as those exponential are bounded. So I thought: let's take the rectangle $[-R, R] \times [0, \frac 12]$. The contour integral will be $0$. I think I also know how to show that it vanishes over the vertical lines, but I'm having trouble in calculating the upper integral. My questions 1) Is this line of thinking useful? I mean looking when the modulus of $f$ vanishes to find proper path over which integrating 2) How to finish the exercise? Integrating on the upper part seems a mess. 3) Are there easier ways to find this Fourier transform?","Find the Fourier transform of $$u(x) = \frac{x \cos(2x)}{(1+x^2)^2}$$ My work Okay so we want $$\int_\mathbb R \frac{e^{-ixt}x\cos(2x)}{(1+x^2)^2}dx$$ Of course we want to apply the residue theorem on the function $\displaystyle f(z) = \frac{e^{-izt}z\cos(2z)}{(1+z^2)^2}$ But on which path? I thought; let $z = \rho (\cos \theta + i \sin \theta)$, we know  that we will want eventually $\rho \to \infty$ to find our integral over $\mathbb R$. But $$|f(z)| \le \frac{e^{(t-2)\rho\sin\theta} + e^{(t+2)\rho\sin\theta}}{2\rho^3}$$ So if $t < -2$, we can integrate over the positive semicircle as we see that $|f(z)| \to 0$ If $t > 2$, we can integrate over the negative semicircle; again $|f(z)| \to 0$. But if $-2 < t < 2$? Circles are out of the question; our only hope is to maintain $\rho \sin \theta = \text{Im }(z)$ bounded, so the function still tends to $0$ as those exponential are bounded. So I thought: let's take the rectangle $[-R, R] \times [0, \frac 12]$. The contour integral will be $0$. I think I also know how to show that it vanishes over the vertical lines, but I'm having trouble in calculating the upper integral. My questions 1) Is this line of thinking useful? I mean looking when the modulus of $f$ vanishes to find proper path over which integrating 2) How to finish the exercise? Integrating on the upper part seems a mess. 3) Are there easier ways to find this Fourier transform?",,"['complex-analysis', 'fourier-analysis', 'improper-integrals', 'contour-integration', 'residue-calculus']"
95,"How to integrate $\int_C{\frac{\sin\pi z}{(z^2-1)^2}}dz$, where $C: |z-1|=1$ using Cauchy's formula?","How to integrate , where  using Cauchy's formula?",\int_C{\frac{\sin\pi z}{(z^2-1)^2}}dz C: |z-1|=1,"How can evaluate $$\int_C{\frac{\sin\pi z}{(z^2-1)^2}}dz$$, where $$C: |z-1|=1$$ by using Cauchy's formula. I have to use Cauchy's formula. Cauchy's formula $$f(z_0)=\frac{1}{2\pi i}\oint_L\frac{f(z)dz}{z-z_0}$$ requires me to have denominator in form of $(z-z_0)^n$. I am confused about how to get denominator to fit formula.","How can evaluate $$\int_C{\frac{\sin\pi z}{(z^2-1)^2}}dz$$, where $$C: |z-1|=1$$ by using Cauchy's formula. I have to use Cauchy's formula. Cauchy's formula $$f(z_0)=\frac{1}{2\pi i}\oint_L\frac{f(z)dz}{z-z_0}$$ requires me to have denominator in form of $(z-z_0)^n$. I am confused about how to get denominator to fit formula.",,"['complex-analysis', 'contour-integration', 'complex-integration']"
96,On a property of polylogarithm,On a property of polylogarithm,,"I have an observation, and I don't know that the following statement is true or not. If not give a counterexample, if it is true prove it, or give a reference about it. Let $n \in \mathbb{R}$, $z \in \mathbb{C}$ and denote the polylogarithm function with $\operatorname{Li}_n$. $(a)$ If $\Im z \neq 0$, then $\Im \operatorname{Li}_n(z) + \Im \operatorname{Li}_n\left({\overline z}\right) = 0,$ $(b)$ $\Re \operatorname{Li}_n(z) - \Re \operatorname{Li}_n\left({\overline z}\right) = 0,$ where $\Im$ denotes the imaginary part of a complex number, $\Re$ denotes the real part of a complex number and ${\overline z}$ denotes the complex conjugate of $z$. If you can tell us something just about special cases you're also welcome. The most preferred and interesting case for me is $\operatorname{Li}_3$.","I have an observation, and I don't know that the following statement is true or not. If not give a counterexample, if it is true prove it, or give a reference about it. Let $n \in \mathbb{R}$, $z \in \mathbb{C}$ and denote the polylogarithm function with $\operatorname{Li}_n$. $(a)$ If $\Im z \neq 0$, then $\Im \operatorname{Li}_n(z) + \Im \operatorname{Li}_n\left({\overline z}\right) = 0,$ $(b)$ $\Re \operatorname{Li}_n(z) - \Re \operatorname{Li}_n\left({\overline z}\right) = 0,$ where $\Im$ denotes the imaginary part of a complex number, $\Re$ denotes the real part of a complex number and ${\overline z}$ denotes the complex conjugate of $z$. If you can tell us something just about special cases you're also welcome. The most preferred and interesting case for me is $\operatorname{Li}_3$.",,"['calculus', 'complex-analysis', 'polylogarithm']"
97,Using Cauchy's Integral Theorem to evaluate integral?,Using Cauchy's Integral Theorem to evaluate integral?,,"I'm going through Stein's Complex Analysis, and I'm a bit confused at one of the classical examples of using Cauchy's theorem to evaluate an integral. The example is: $$\int_0^{\infty}\frac{1-\cos{x}}{x^2}dx = \frac{\pi}{2}$$ The book says (and I'll add my thoughts & questions in bold as they come up): Here we consider the function $f(z) = (1 - e^{iz})/z^2$, and we integrate over the indented semicircle in the upper half-plane positioned on the $x$-axis, as shown in the figure below: Why precisely do we consider the function $f(z) = (1-e^{iz})/z^2$? I get that $e^{ix} = \cos{x} + i\sin{x}$ and $\cos{z} = (e^{iz}-e^{iz})/2$, but how precisely do we get $f(z) = (1 - e^{iz})/z^2$ from this? Why precisely are we integrating over the indented semicircle in the upper half-plane positioned on the $x$-axis? As a follow-up, are we creating a hole around 0 because the integral cannot be evaluated at x = 0? [back to book] If we denote $\gamma_{\epsilon}^+$ and $\gamma_R^+$ the semicircles of radii $\epsilon$ and $R$ with negative and positive orientations respectively, Cauchy's theorem gives: $$\int_{-R}^{-\epsilon}\frac{1-e^{ix}}{x^2}dx + \int_{\gamma_{\epsilon}^+}\frac{1-e^{iz}}{z^2}dz + \int_{\epsilon}^R\frac{1-e^{ix}}{x^2}dx + \int_{\gamma_R^+}\frac{1-e^{iz}}{z^2}dz = 0$$ First we let $R \rightarrow \infty$ and observe that: $$\mid\frac{1-e^{iz}}{z^2}\mid \ \leq \ \frac{2}{\mid z\mid^2}$$ so the integral over $\gamma_R^+$ goes to 0. Therefore: $$\int_{\mid x \mid \geq \epsilon}\frac{1-e^{ix}}{x^2}dx = -\int_{\gamma_{\epsilon}^+}\frac{1-e^{iz}}{z^2}dz$$ Why does letting $R \rightarrow \infty$ lead to the above inequality? What does $R \rightarrow \infty$ mean in the scope of the diagram, and why does the integral over $\gamma_R^+$ go to zero? Not really sure how the last equality is formulated as well... [back to book] Next, note that: $$f(z) = \frac{iz}{z^2} + E(z)$$ where $E(z)$ is bounded as $z \rightarrow 0$, while on $\gamma_{\epsilon}^+$ we have $z = \epsilon e^{i\theta}$ and $dz = i\epsilon e^{i \theta}d\theta$. Thus, $$\int_{\gamma_{\epsilon}^+}\frac{1 - e^{iz}}{z^2}dz \rightarrow \int_{\pi}{0}(-ii)d\theta = -\pi$$ as $\epsilon \rightarrow 0$. Taking real parts then yields: $$\int_{-\infty}^{\infty}\frac{1-\cos{x}}{x^2}dx = \pi$$ Since the integrand is even, the desired formula is proved. I don't quite follow the first part of this, but I think more importantly, how does solving all of this help us solve the original integral? What exactly am I taking the ""real parts"" of? Sorry, I know it's a lot, but any sort of walkthrough would be appreciated.","I'm going through Stein's Complex Analysis, and I'm a bit confused at one of the classical examples of using Cauchy's theorem to evaluate an integral. The example is: $$\int_0^{\infty}\frac{1-\cos{x}}{x^2}dx = \frac{\pi}{2}$$ The book says (and I'll add my thoughts & questions in bold as they come up): Here we consider the function $f(z) = (1 - e^{iz})/z^2$, and we integrate over the indented semicircle in the upper half-plane positioned on the $x$-axis, as shown in the figure below: Why precisely do we consider the function $f(z) = (1-e^{iz})/z^2$? I get that $e^{ix} = \cos{x} + i\sin{x}$ and $\cos{z} = (e^{iz}-e^{iz})/2$, but how precisely do we get $f(z) = (1 - e^{iz})/z^2$ from this? Why precisely are we integrating over the indented semicircle in the upper half-plane positioned on the $x$-axis? As a follow-up, are we creating a hole around 0 because the integral cannot be evaluated at x = 0? [back to book] If we denote $\gamma_{\epsilon}^+$ and $\gamma_R^+$ the semicircles of radii $\epsilon$ and $R$ with negative and positive orientations respectively, Cauchy's theorem gives: $$\int_{-R}^{-\epsilon}\frac{1-e^{ix}}{x^2}dx + \int_{\gamma_{\epsilon}^+}\frac{1-e^{iz}}{z^2}dz + \int_{\epsilon}^R\frac{1-e^{ix}}{x^2}dx + \int_{\gamma_R^+}\frac{1-e^{iz}}{z^2}dz = 0$$ First we let $R \rightarrow \infty$ and observe that: $$\mid\frac{1-e^{iz}}{z^2}\mid \ \leq \ \frac{2}{\mid z\mid^2}$$ so the integral over $\gamma_R^+$ goes to 0. Therefore: $$\int_{\mid x \mid \geq \epsilon}\frac{1-e^{ix}}{x^2}dx = -\int_{\gamma_{\epsilon}^+}\frac{1-e^{iz}}{z^2}dz$$ Why does letting $R \rightarrow \infty$ lead to the above inequality? What does $R \rightarrow \infty$ mean in the scope of the diagram, and why does the integral over $\gamma_R^+$ go to zero? Not really sure how the last equality is formulated as well... [back to book] Next, note that: $$f(z) = \frac{iz}{z^2} + E(z)$$ where $E(z)$ is bounded as $z \rightarrow 0$, while on $\gamma_{\epsilon}^+$ we have $z = \epsilon e^{i\theta}$ and $dz = i\epsilon e^{i \theta}d\theta$. Thus, $$\int_{\gamma_{\epsilon}^+}\frac{1 - e^{iz}}{z^2}dz \rightarrow \int_{\pi}{0}(-ii)d\theta = -\pi$$ as $\epsilon \rightarrow 0$. Taking real parts then yields: $$\int_{-\infty}^{\infty}\frac{1-\cos{x}}{x^2}dx = \pi$$ Since the integrand is even, the desired formula is proved. I don't quite follow the first part of this, but I think more importantly, how does solving all of this help us solve the original integral? What exactly am I taking the ""real parts"" of? Sorry, I know it's a lot, but any sort of walkthrough would be appreciated.",,['complex-analysis']
98,Useful device in complex analysis (Perron's formula),Useful device in complex analysis (Perron's formula),,"I've come across the following useful device from complex analysis: $$\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}{\frac{y^z}{z}}{dz} = \left\{\begin{array}{lll} 0 & \text{if} & 0<y<1 \\ \frac{1}{2} & \text{if} &y=1 \\ 1 & \text{if} & y > 1\end{array}\right.,$$ where $\text{Re}(c)>0$ is conveniently chosen. I understand, amongst other applications, this can be used (is essential?) in the accepted proof of the Prime Number Theorem. I'd just like some clarification I'm on the right track with how to use this device. For example, suppose we were to have the following: $$f(z;y) = \frac{y^z}{z},$$ and I could see it would be beneficial to use the above device. Then I can write $$\int_{c-i\infty}^{c+i\infty}f(z;y)dz = \int_{c-i\infty}^{c+i\infty}\frac{y^z}{z}dz.$$ However, am I correct in thinking I can't just go ahead and use the information in the curly brace. Instead, loosely speaking, I have to create a (probably square) contour, two corners of which are $c+i\infty$ and $c-i\infty$. Then I would need to check the top, bottom, and left line integrals go to zero (or else compute their values), and furthermore account for all residues at poles within the contour of the meromorphic function. Only then would I be able to use the information on the line integral given in the curly brace? EDIT Now I know the name of this device, I have found a related post . After reading this post, Perron's formula may come from the Mellin transform?... EDIT As mentioned by @FelixMarin in a comment to @robjohn's answer, it is possible to view this function as the Heaviside step function. See comment for further information.","I've come across the following useful device from complex analysis: $$\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}{\frac{y^z}{z}}{dz} = \left\{\begin{array}{lll} 0 & \text{if} & 0<y<1 \\ \frac{1}{2} & \text{if} &y=1 \\ 1 & \text{if} & y > 1\end{array}\right.,$$ where $\text{Re}(c)>0$ is conveniently chosen. I understand, amongst other applications, this can be used (is essential?) in the accepted proof of the Prime Number Theorem. I'd just like some clarification I'm on the right track with how to use this device. For example, suppose we were to have the following: $$f(z;y) = \frac{y^z}{z},$$ and I could see it would be beneficial to use the above device. Then I can write $$\int_{c-i\infty}^{c+i\infty}f(z;y)dz = \int_{c-i\infty}^{c+i\infty}\frac{y^z}{z}dz.$$ However, am I correct in thinking I can't just go ahead and use the information in the curly brace. Instead, loosely speaking, I have to create a (probably square) contour, two corners of which are $c+i\infty$ and $c-i\infty$. Then I would need to check the top, bottom, and left line integrals go to zero (or else compute their values), and furthermore account for all residues at poles within the contour of the meromorphic function. Only then would I be able to use the information on the line integral given in the curly brace? EDIT Now I know the name of this device, I have found a related post . After reading this post, Perron's formula may come from the Mellin transform?... EDIT As mentioned by @FelixMarin in a comment to @robjohn's answer, it is possible to view this function as the Heaviside step function. See comment for further information.",,"['complex-analysis', 'analytic-number-theory']"
99,'Identity theorem' for Meromorphic functions,'Identity theorem' for Meromorphic functions,,"If $f_1,f_2$ are meromorphic functions in $D$ and there exists a sequence of pairwise distinct points $z_n \in D$ such that $z_n \to z_o \in D$ and $f_1(z_n)=f_2(z_n),$ then $f_{1} \equiv f_2$ on $D.$ Appreciate if someone could advise me on how to prove this. Thank you.","If $f_1,f_2$ are meromorphic functions in $D$ and there exists a sequence of pairwise distinct points $z_n \in D$ such that $z_n \to z_o \in D$ and $f_1(z_n)=f_2(z_n),$ then $f_{1} \equiv f_2$ on $D.$ Appreciate if someone could advise me on how to prove this. Thank you.",,['complex-analysis']
