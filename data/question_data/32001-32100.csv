,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Unknown distribution for birthday problem,Unknown distribution for birthday problem,,"Coming from Blitzstein's book: In the birthday problem, we assumed that all 365 days of the year are equally likely (and excluded February 29). In reality, some days are slightly more likely as birthdays than others. For example, scientists have long struggled to understand why more babies are born 9 months after a holiday. Let $\textbf{p}= (p_1, p_2, ..., p_{365})$ be the vector of birthday probabilities, with $p_j$ the probability of being born on the $j$ th day of the year (February 29 is still excluded, with no offense intended to Leap Dayers). The $k$ th elementary symmetric polynomial in the variables $x_1,..., x_n$ is defined by $e_k(x_1, ..., x_n) = \sum_{1 \leq j_1 < j_n < ... < j_k \leq n}{x_{j_i} ... x_{j_k}}$ . This just says to add up all of the $n \choose k$ terms we can get by choosing and multiplying $k$ of the variables. For example, $e_1(x_1, x_2, x_3) = x_1 + x_2 + x_3$ and $e_2(x_1, x_2, x_3) = x_1x_2 + x_1x_3 + x_2x_3$ . Now let $k \geq 2$ be the number of people. a) Find a simple expression for the probability there is at least one birthday match, in terms of $\textbf{p}$ and an elementary symmetric polynomial. I am confused how to do this problem; I've tried a couple approaches. Let $x_j$ be the the day of the year ( $x_1$ = January 1, $x_{364}$ = December 30th, etc..). PIE $P$ (at least one match) = $P$ (match on $x_1 \cup$ match on $x_2 \cup  ... \cup $ match on $x_{365}$ . Now if we look at this with two people, is is a simple: $\textbf{p} \cdot \textbf{p}$ because person 1 can have each birthday $x_i$ with $P(x_i) = p_i$ and for there to be a match person 2 must also have the birthday on $x_i$ . Each event is disjoint, so we have $\textbf{p} \cdot \textbf{p}$ . With 3 people, it becomes a little more confusing with $P$ (match on $x_i$ ) = ${3 \choose 2} p_i^2(1-p_i)^1  + {3\choose3} (p_i)^3$ , which I arrived to by saying a birthday on $x_i$ is a success with $P(x_i) = p_i$ and continued as a binomial distribution for 2 or 3 successes. Note: This can easily be extended that given n $n$ people, the probability 2 or more share a birthday on $x_i$ is the sum from $j=2$ to $n$ successes in a binomial distribution: $\sum_{j=2}^{n} {n \choose j}p_i^j(1-p_i)^{n-j}$ So for 3 people, we still have disjoint events and we have $\textbf{p}_{k=3} = {{3 \choose 2} p_i^2(1-p_i)^1  + {3\choose3} (p_i)^3}_{1 \leq i \leq 365}$ and the probability of intersecting birthdays is $\textbf{p}_{k=3} \cdot \textbf{p}_{k=3}$ . Once we get to four people, the work becomes really messy as PIE has to start getting used, and honestly my math is probably either A) wrong or B) messy. So, I decided to not take PIE approach. Counting compliment Again, with 2 people it is the trivial $1 - (\textbf{p} \cdot (\textbf{1 - p}))$ Immediately, with 3 people and more I realized there is a brutal tree structure where we effectively turn everything into cases, which definitely seemed like the wrong approach. Could someone help me with what the approach might be for this question? The other post related to this did not help me very much. Thank you in advance!","Coming from Blitzstein's book: In the birthday problem, we assumed that all 365 days of the year are equally likely (and excluded February 29). In reality, some days are slightly more likely as birthdays than others. For example, scientists have long struggled to understand why more babies are born 9 months after a holiday. Let be the vector of birthday probabilities, with the probability of being born on the th day of the year (February 29 is still excluded, with no offense intended to Leap Dayers). The th elementary symmetric polynomial in the variables is defined by . This just says to add up all of the terms we can get by choosing and multiplying of the variables. For example, and . Now let be the number of people. a) Find a simple expression for the probability there is at least one birthday match, in terms of and an elementary symmetric polynomial. I am confused how to do this problem; I've tried a couple approaches. Let be the the day of the year ( = January 1, = December 30th, etc..). PIE (at least one match) = (match on match on match on . Now if we look at this with two people, is is a simple: because person 1 can have each birthday with and for there to be a match person 2 must also have the birthday on . Each event is disjoint, so we have . With 3 people, it becomes a little more confusing with (match on ) = , which I arrived to by saying a birthday on is a success with and continued as a binomial distribution for 2 or 3 successes. Note: This can easily be extended that given n people, the probability 2 or more share a birthday on is the sum from to successes in a binomial distribution: So for 3 people, we still have disjoint events and we have and the probability of intersecting birthdays is . Once we get to four people, the work becomes really messy as PIE has to start getting used, and honestly my math is probably either A) wrong or B) messy. So, I decided to not take PIE approach. Counting compliment Again, with 2 people it is the trivial Immediately, with 3 people and more I realized there is a brutal tree structure where we effectively turn everything into cases, which definitely seemed like the wrong approach. Could someone help me with what the approach might be for this question? The other post related to this did not help me very much. Thank you in advance!","\textbf{p}= (p_1, p_2, ..., p_{365}) p_j j k x_1,..., x_n e_k(x_1, ..., x_n) = \sum_{1 \leq j_1 < j_n < ... < j_k \leq n}{x_{j_i} ... x_{j_k}} n \choose k k e_1(x_1, x_2, x_3) = x_1 + x_2 + x_3 e_2(x_1, x_2, x_3) = x_1x_2 + x_1x_3 + x_2x_3 k \geq 2 \textbf{p} x_j x_1 x_{364} P P x_1 \cup x_2 \cup  ... \cup  x_{365} \textbf{p} \cdot \textbf{p} x_i P(x_i) = p_i x_i \textbf{p} \cdot \textbf{p} P x_i {3 \choose 2} p_i^2(1-p_i)^1  + {3\choose3} (p_i)^3 x_i P(x_i) = p_i n x_i j=2 n \sum_{j=2}^{n} {n \choose j}p_i^j(1-p_i)^{n-j} \textbf{p}_{k=3} = {{3 \choose 2} p_i^2(1-p_i)^1  + {3\choose3} (p_i)^3}_{1 \leq i \leq 365} \textbf{p}_{k=3} \cdot \textbf{p}_{k=3} 1 - (\textbf{p} \cdot (\textbf{1 - p}))","['probability', 'birthday']"
1,Six-sided and four-sided dice question contradiction,Six-sided and four-sided dice question contradiction,,"Suppose we have two fair dice, with six sides (numbered 1 to 6) and with four sides (numbered 1 to 4). Suppose we pick a die at random and throw it, the result is announced to be 2 and the die is discarded. Then we pick the remaining die and throw it. What is the expectation of the second throw? On the one hand, us getting 2 on the first throw, does not provide us with information on whether the first die was six-sided or four-sided, so we could argue that by total expectation the expectation of the second throw is just the average of expectations: $$ E(X)=(3.5)\frac{1}{2} + (2.5)\frac{1}{2}=3 $$ On the other hand, we know that we got 2 on the first throw, so the expectation of the second throw is: $$ E(X)=(1)\frac{2}{9} + (2)\frac{1}{9} + (3)\frac{2}{9} + (4)\frac{2}{9} + (5)\frac{1}{9} + (6)\frac{1}{9}=3.22 $$ It seems to me that there is a contradiction?","Suppose we have two fair dice, with six sides (numbered 1 to 6) and with four sides (numbered 1 to 4). Suppose we pick a die at random and throw it, the result is announced to be 2 and the die is discarded. Then we pick the remaining die and throw it. What is the expectation of the second throw? On the one hand, us getting 2 on the first throw, does not provide us with information on whether the first die was six-sided or four-sided, so we could argue that by total expectation the expectation of the second throw is just the average of expectations: On the other hand, we know that we got 2 on the first throw, so the expectation of the second throw is: It seems to me that there is a contradiction?","
E(X)=(3.5)\frac{1}{2} + (2.5)\frac{1}{2}=3
 
E(X)=(1)\frac{2}{9} + (2)\frac{1}{9} + (3)\frac{2}{9} + (4)\frac{2}{9} + (5)\frac{1}{9} + (6)\frac{1}{9}=3.22
","['probability', 'dice']"
2,Convergence in probability implies a.s. convergence in a countable space,Convergence in probability implies a.s. convergence in a countable space,,"Let be $(\Omega, \mathcal{F}, \mathcal{P})$ a probability space, $(X_{n})$ a sequence of randiom variables and $X$ a random variable. Let be $\Omega$ countable and $\mathcal{F}$ a power set of $\Omega$ . Show that $X_n\xrightarrow{p} X, n \rightarrow \infty \ \ \implies X_n \xrightarrow{a.s.} X, n \rightarrow \infty$ I have done some research and I have found out that the statement is not true in general but I have no idea how to prove it for this special case. I appreciate your help in advance a lot.","Let be a probability space, a sequence of randiom variables and a random variable. Let be countable and a power set of . Show that I have done some research and I have found out that the statement is not true in general but I have no idea how to prove it for this special case. I appreciate your help in advance a lot.","(\Omega, \mathcal{F}, \mathcal{P}) (X_{n}) X \Omega \mathcal{F} \Omega X_n\xrightarrow{p} X, n \rightarrow \infty \ \ \implies X_n \xrightarrow{a.s.} X, n \rightarrow \infty","['probability', 'probability-theory', 'probability-limit-theorems']"
3,Visually explaining this probability union rule,Visually explaining this probability union rule,,"I'm trying to visually wrap my head around the following equivalence of the union probability rule: $$ P(A)+P(B)-P(A)P(B)=P(A)+(1-P(A))P(B) $$ I understand that $(1-P(A))=P(A')$ and the whole equivalence makes sense to me algabraically. However, I have sketched these Venn diagrams to try and visualise the equivalence, and what I am struggling to understand is that if I was to combine the Venn diagrams for $P(A)$ and $P(A')P(B)$ then I would have $P(A)+P(B)$ , not $P(A)+P(B)-P(A)P(B)$ . Where am I tripping up in my reasoning?","I'm trying to visually wrap my head around the following equivalence of the union probability rule: I understand that and the whole equivalence makes sense to me algabraically. However, I have sketched these Venn diagrams to try and visualise the equivalence, and what I am struggling to understand is that if I was to combine the Venn diagrams for and then I would have , not . Where am I tripping up in my reasoning?","
P(A)+P(B)-P(A)P(B)=P(A)+(1-P(A))P(B)
 (1-P(A))=P(A') P(A) P(A')P(B) P(A)+P(B) P(A)+P(B)-P(A)P(B)","['probability', 'discrete-mathematics', 'inclusion-exclusion']"
4,"Language and probability - ""given that""","Language and probability - ""given that""",,"In the book ""An Undergraduate Introduction to Financial Mathematics"" there is a following simple problem: ""Suppose cards will be drawn without replacement from a standard 52-card deck. What is the probability that the fourth card drawn will be an ace given that the first three cards drawn were all aces?"" The correct answer in the book is given as 4/52 * 3/51 * 2/50 * 1/49 - What strikes me a bit odd is that we already know that the first three draws are aces (""given that""). Why is the correct answer not simply 1/49? I mean first three draws came and went and we are only concerned about the probability of drawing the ace on the fourth draw. To me the answer would be for question ""What is the probability that first four cards drawn from the card deck without replacements are all aces?""","In the book ""An Undergraduate Introduction to Financial Mathematics"" there is a following simple problem: ""Suppose cards will be drawn without replacement from a standard 52-card deck. What is the probability that the fourth card drawn will be an ace given that the first three cards drawn were all aces?"" The correct answer in the book is given as 4/52 * 3/51 * 2/50 * 1/49 - What strikes me a bit odd is that we already know that the first three draws are aces (""given that""). Why is the correct answer not simply 1/49? I mean first three draws came and went and we are only concerned about the probability of drawing the ace on the fourth draw. To me the answer would be for question ""What is the probability that first four cards drawn from the card deck without replacements are all aces?""",,['probability']
5,When should I stop playing this dice game?,When should I stop playing this dice game?,,"The rules are as follows: You start with \$1 and roll a six-sided die. If you roll anything but a 1, you double your money (so \$2 for the first roll, $4 for the second, and so on). If you roll a 1, you lose all your money. What is the optimal number of times you should roll the die to make the most money? My initial theory: The probability of rolling 2-6 consecutively $n$ times is $(\frac{5}{6})^n$ ; and the probability of rolling a 1 is just $\frac{1}{6}$ . So, the expected value is going to be: $$ E = (\frac{5}{6})^n2^n-\frac{1}{6}2^n \\ =2^n(\frac{5}{6}^n-\frac{1}{6}) $$ Now, if I solve for $n_{L}$ where $E=0$ : $$ 0=2^{n_{L}}(\frac{5}{6}^{n_{L}}-\frac{1}{6}) \\ \frac{1}{6}=\frac{5}{6}^{n_{L}} \\ n_{L}=log_{5/6}\frac{1}{6}\\ \approx9.8 $$ Which means I should roll around 9 times to maximize my profit (or maybe 10 if I'm feeling lucky). However, I tried running a quick simulation and got $n_{L}=5.01 \pm 0.05$ after 10,000 games. Where did I go wrong? Thank you! For reference: import random import numpy as np  def dice():                                                                         return random.randint(1,6)   ns=np.array([]) for i in range(10000):     n=0      while dice() != 1:         n+=1     ns=np.append(ns,[n]) print(np.average(ns)) print(np.std(ns)/100) Output 5.0093 0.05511008393207182 Edit: Here's a more accurate simulation that reflects Ross Millikan's answer for my own reference. import random import numpy as np                                                                                 def dice():     return random.randint(1,6)      trials=np.array([[]]) for i in range(30):     moneys=np.array([])     for j in range(100):         money=1         numrolls=0         while numrolls <= i:             numrolls+=1             if dice() != 1:                 money=2*money             else:                 money=0                 break         moneys = np.append(moneys,[money])     print(""i: ""+str(i))     trial = np.array([i,np.average(moneys)])     print(""money: ""+str(np.average(moneys)))     trials = np.append(trials,trial) Output i: 0 money: 1.74 i: 1 money: 2.48 i: 2 money: 4.88 i: 3 money: 6.56 i: 4 money: 14.08 i: 5 money: 28.8 i: 6 money: 32.0 i: 7 money: 40.96 i: 8 money: 81.92 i: 9 money: 112.64 i: 10 money: 245.76 i: 11 money: 737.28 i: 12 money: 1146.88 i: 13 money: 327.68 i: 14 money: 2293.76 i: 15 money: 3276.8 i: 16 money: 6553.6 i: 17 money: 13107.2 i: 18 money: 26214.4 i: 19 money: 52428.8 i: 20 money: 20971.52 i: 21 money: 0.0 i: 22 money: 83886.08 i: 23 money: 335544.32 i: 24 money: 335544.32 i: 25 money: 671088.64 i: 26 money: 1342177.28 i: 27 money: 8053063.68 i: 28 money: 0.0 i: 29 money: 0.0","The rules are as follows: You start with \$1 and roll a six-sided die. If you roll anything but a 1, you double your money (so \$2 for the first roll, $4 for the second, and so on). If you roll a 1, you lose all your money. What is the optimal number of times you should roll the die to make the most money? My initial theory: The probability of rolling 2-6 consecutively times is ; and the probability of rolling a 1 is just . So, the expected value is going to be: Now, if I solve for where : Which means I should roll around 9 times to maximize my profit (or maybe 10 if I'm feeling lucky). However, I tried running a quick simulation and got after 10,000 games. Where did I go wrong? Thank you! For reference: import random import numpy as np  def dice():                                                                         return random.randint(1,6)   ns=np.array([]) for i in range(10000):     n=0      while dice() != 1:         n+=1     ns=np.append(ns,[n]) print(np.average(ns)) print(np.std(ns)/100) Output 5.0093 0.05511008393207182 Edit: Here's a more accurate simulation that reflects Ross Millikan's answer for my own reference. import random import numpy as np                                                                                 def dice():     return random.randint(1,6)      trials=np.array([[]]) for i in range(30):     moneys=np.array([])     for j in range(100):         money=1         numrolls=0         while numrolls <= i:             numrolls+=1             if dice() != 1:                 money=2*money             else:                 money=0                 break         moneys = np.append(moneys,[money])     print(""i: ""+str(i))     trial = np.array([i,np.average(moneys)])     print(""money: ""+str(np.average(moneys)))     trials = np.append(trials,trial) Output i: 0 money: 1.74 i: 1 money: 2.48 i: 2 money: 4.88 i: 3 money: 6.56 i: 4 money: 14.08 i: 5 money: 28.8 i: 6 money: 32.0 i: 7 money: 40.96 i: 8 money: 81.92 i: 9 money: 112.64 i: 10 money: 245.76 i: 11 money: 737.28 i: 12 money: 1146.88 i: 13 money: 327.68 i: 14 money: 2293.76 i: 15 money: 3276.8 i: 16 money: 6553.6 i: 17 money: 13107.2 i: 18 money: 26214.4 i: 19 money: 52428.8 i: 20 money: 20971.52 i: 21 money: 0.0 i: 22 money: 83886.08 i: 23 money: 335544.32 i: 24 money: 335544.32 i: 25 money: 671088.64 i: 26 money: 1342177.28 i: 27 money: 8053063.68 i: 28 money: 0.0 i: 29 money: 0.0","n (\frac{5}{6})^n \frac{1}{6} 
E = (\frac{5}{6})^n2^n-\frac{1}{6}2^n \\
=2^n(\frac{5}{6}^n-\frac{1}{6})
 n_{L} E=0 
0=2^{n_{L}}(\frac{5}{6}^{n_{L}}-\frac{1}{6}) \\
\frac{1}{6}=\frac{5}{6}^{n_{L}} \\
n_{L}=log_{5/6}\frac{1}{6}\\
\approx9.8
 n_{L}=5.01 \pm 0.05","['probability', 'expected-value', 'dice', 'gambling']"
6,Convergence of sums of $\sin(kY)$ where Y is uniform,Convergence of sums of  where Y is uniform,\sin(kY),"Let $Y$ be uniformly distributed on $[0,2\pi]$ . Let $X_k=\sin(kY)$ . I want to show that $\frac{X_1+X_2+\cdots+X_n}{n}\to 0$ almost surely. I thought of using the strong law of large numbers but it requires the $X_k$ 's to be identically distributed.",Let be uniformly distributed on . Let . I want to show that almost surely. I thought of using the strong law of large numbers but it requires the 's to be identically distributed.,"Y [0,2\pi] X_k=\sin(kY) \frac{X_1+X_2+\cdots+X_n}{n}\to 0 X_k","['probability', 'probability-theory']"
7,Being the first to pick 1 of 2 cards out of a deck of 52 that will win you 1 million dollars.,Being the first to pick 1 of 2 cards out of a deck of 52 that will win you 1 million dollars.,,"Contestants in a game show are asked to from a line. One by one, each of them will be given one card (face up) from a deck of 52 until someone gets either an Ace of Spades or an Ace of Clubs. The first person who gets one of those cards will receive a sum of 1 million dollars. Before the game begins, you have the chance of choosing where in the line to position yourself in. How will you find out where to which position will be the one most likely to be the first to receive one of the 2 black Ace cards. My first thought was to do a mock version of this and count how many cards were laid out before the first black Ace appeared. I repeated this for 25 times while recording the results for each trial to hopefully get an estimate to the average number of cards distributed before one of the black Aces appeared.","Contestants in a game show are asked to from a line. One by one, each of them will be given one card (face up) from a deck of 52 until someone gets either an Ace of Spades or an Ace of Clubs. The first person who gets one of those cards will receive a sum of 1 million dollars. Before the game begins, you have the chance of choosing where in the line to position yourself in. How will you find out where to which position will be the one most likely to be the first to receive one of the 2 black Ace cards. My first thought was to do a mock version of this and count how many cards were laid out before the first black Ace appeared. I repeated this for 25 times while recording the results for each trial to hopefully get an estimate to the average number of cards distributed before one of the black Aces appeared.",,['probability']
8,Edge probability and expected number of edges in the configuration model,Edge probability and expected number of edges in the configuration model,,"This question is related to question: Probability that exists at least an edge in the configuration model There is something I do not understand about the computation of the expected number of edges between $i$ and $j$ nodes in the configurational model , $p_{ij}$ . The argument given everywhere I've seen is: There are $2m$ stubs in the network, with $k_i$ in node $i$ and $k_j$ in node $j$ . Taking one stub from node $i$ , there are $k_j$ possible stubs to connect it to node $j$ , so the probability to connect it to node $j$ is $\frac{k_j}{2m-1}$ , the $2m-1$ because you can not connect it to the same stub you are coming from. There are $k_i$ stubs in node i, so the expected number of edges is just adding up the different probabilities and $p_{ij} = k_i \times \frac{k_j}{2m-1}$ . I do not understand step 3. I would think once there has been an edge between nodes $i$ and $j$ , the probability to connect the next stub should change accordingly because there is one less available stub at node $j$ : $\frac{k_j-1}{2m-3}$ . But also, each new stub considered in node $i$ has two less possible stubs to be connected (because every other edge already connected has two stub ends), so the total available edges in the denominator should decrease as well: $2m-3$ , $2m-5$ , ..., $2m-2k_i-1$ . Instead, I'd proceed in this way: $$p_{ij} = 1 - \bar{p}_{ij}, $$ where $\bar{p}_{ij}$ is the probability there isn't any edge between nodes $i$ and $j$ . Then, $$\bar{p}_{ij} = \bar{p}_{{i_1}j} \times \bar{p}_{{i_2}j}\times \dots  \times \bar{p}_{{i_{k_i}}j}, $$ where $\bar{p}_{{i_1}j}$ is the probability there isn't an edge between the first stub in node $i$ to node $j$ and $\bar{p}_{{i_1}j} = \frac{2m-1-k_j}{2m-1}$ . Analogously for the other stubs, we get $$\bar{p}_{ij} = \frac{2m-1-k_j}{2m-1}  \frac{2m-3-k_j}{2m-3} \dots \frac{2m-2k_i-1-k_j}{2m-2k_i-1} = \left( 1 - \frac{k_j}{2m-1} \right)   \left( 1 - \frac{k_j}{2m-3} \right)  \dots \left( 1 - \frac{k_j}{2m-2k_i-1} \right).  $$ So $$p_{ij} = 1- \left( 1 - \frac{k_j}{2m-1} \right)   \left( 1 - \frac{k_j}{2m-3} \right)  ... \left( 1 - \frac{k_j}{2m-2k_i-1} \right).$$ I can recover from this expression the other one in the large number of edges limit $m \to \infty$ , then $2m-2k_i-1 \simeq ... \simeq 2m - 3 \simeq 2m - 1$ and $$p_{ij} \simeq 1- \left( 1 - \frac{k_j}{2m-1} \right)^{k_i} \simeq 1 - \left( 1 - \frac{k_i k_j}{2m-1} \right) = \frac{k_i k_j}{2m-1},$$ where in the second step I have used the series expansion $(1 - x)^a = 1 - ax + \mathcal{O}(x^2)$ for $x \to 0$ . Question: Does this mean that only the expected number of edges between $i$ and $j$ nodes in the configurational model is $p_{ij} = \frac{k_i k_j}{2m-1}$ in the large number of edges $m$ limit? If that is the case, I find it strange because they don't specify it in any of the sources I've looked. Instead, they seem to say $p_{ij} = \frac{k_i k_j}{2m-1}$ is the general expression which in the large number of edges limit becomes $p_{ij} = \frac{k_i k_j}{2m}$ .","This question is related to question: Probability that exists at least an edge in the configuration model There is something I do not understand about the computation of the expected number of edges between and nodes in the configurational model , . The argument given everywhere I've seen is: There are stubs in the network, with in node and in node . Taking one stub from node , there are possible stubs to connect it to node , so the probability to connect it to node is , the because you can not connect it to the same stub you are coming from. There are stubs in node i, so the expected number of edges is just adding up the different probabilities and . I do not understand step 3. I would think once there has been an edge between nodes and , the probability to connect the next stub should change accordingly because there is one less available stub at node : . But also, each new stub considered in node has two less possible stubs to be connected (because every other edge already connected has two stub ends), so the total available edges in the denominator should decrease as well: , , ..., . Instead, I'd proceed in this way: where is the probability there isn't any edge between nodes and . Then, where is the probability there isn't an edge between the first stub in node to node and . Analogously for the other stubs, we get So I can recover from this expression the other one in the large number of edges limit , then and where in the second step I have used the series expansion for . Question: Does this mean that only the expected number of edges between and nodes in the configurational model is in the large number of edges limit? If that is the case, I find it strange because they don't specify it in any of the sources I've looked. Instead, they seem to say is the general expression which in the large number of edges limit becomes .","i j p_{ij} 2m k_i i k_j j i k_j j j \frac{k_j}{2m-1} 2m-1 k_i p_{ij} = k_i \times \frac{k_j}{2m-1} i j j \frac{k_j-1}{2m-3} i 2m-3 2m-5 2m-2k_i-1 p_{ij} = 1 - \bar{p}_{ij},  \bar{p}_{ij} i j \bar{p}_{ij} = \bar{p}_{{i_1}j} \times \bar{p}_{{i_2}j}\times \dots  \times \bar{p}_{{i_{k_i}}j},  \bar{p}_{{i_1}j} i j \bar{p}_{{i_1}j} = \frac{2m-1-k_j}{2m-1} \bar{p}_{ij} = \frac{2m-1-k_j}{2m-1}  \frac{2m-3-k_j}{2m-3} \dots \frac{2m-2k_i-1-k_j}{2m-2k_i-1} = \left( 1 - \frac{k_j}{2m-1} \right)   \left( 1 - \frac{k_j}{2m-3} \right)  \dots \left( 1 - \frac{k_j}{2m-2k_i-1} \right).   p_{ij} = 1- \left( 1 - \frac{k_j}{2m-1} \right)   \left( 1 - \frac{k_j}{2m-3} \right)  ... \left( 1 - \frac{k_j}{2m-2k_i-1} \right). m \to \infty 2m-2k_i-1 \simeq ... \simeq 2m - 3 \simeq 2m - 1 p_{ij} \simeq 1- \left( 1 - \frac{k_j}{2m-1} \right)^{k_i} \simeq 1 - \left( 1 - \frac{k_i k_j}{2m-1} \right) = \frac{k_i k_j}{2m-1}, (1 - x)^a = 1 - ax + \mathcal{O}(x^2) x \to 0 i j p_{ij} = \frac{k_i k_j}{2m-1} m p_{ij} = \frac{k_i k_j}{2m-1} p_{ij} = \frac{k_i k_j}{2m}","['probability', 'probability-theory', 'graph-theory', 'random-graphs', 'network']"
9,"How do we make the ""intuitive calculation"" of conditional probability, rigorous?","How do we make the ""intuitive calculation"" of conditional probability, rigorous?",,"The definition of Conditional Probability for events $A$ and $B$ in sample space $S$ is $$\mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}.$$ Sometimes, we use a rearranged version of this formula to calculate the probability of the intersection of events - called the multiplicative law of probability: $$\mathbb{P}(A\cap B)=\mathbb{P}(A|B)\times \mathbb{P}(B)$$ When using this formula, how does one calculate $\mathbb{P}(A|B)?$ Since by definition the intersection is required to find the conditional probability? Is there an alternative definition/way to compute the conditional probability when you don't know the intersection? I have calculated the conditional probability through intuition many times (E.g. picking Red/Blue marbles out of a bag, without replacement), but I was wondering if there was some sort of standard convention on how calculate the conditional probability when you don't know the intersection? Example. Say we have three people (Alex, Bob, Carol) with their three hats. Say I take all their hats, mix them up, and then return one to each person. What is the probability that person A and B get exactly their own hat back? ""Solution"" : The way I would think of it is: Let $E_A$ and $E_B$ be the events that Alex and Bob get their hats back respectively. Then, $$\mathbb{P}(E_A\cap E_B)= \mathbb{P}(E_B)\times \mathbb{P}(E_A|E_B)$$ The probability of $E_B$ would be $\frac{1}{3}$ . Now, the way I would calculate $\mathbb{P}(E_A|E_B) $ intuitively , even though I don't know what the intersection is (because that's what I'm trying to find), is ""Since Bob has his hat, I have two hats left, which gives a probability of $\frac{1}{2}$ for Alex to get his hat back."" This intuitive logic of getting to the conditional probability directly, when I didn't use/bypassed the definition, is what I would like to clarify/formalise.","The definition of Conditional Probability for events and in sample space is Sometimes, we use a rearranged version of this formula to calculate the probability of the intersection of events - called the multiplicative law of probability: When using this formula, how does one calculate Since by definition the intersection is required to find the conditional probability? Is there an alternative definition/way to compute the conditional probability when you don't know the intersection? I have calculated the conditional probability through intuition many times (E.g. picking Red/Blue marbles out of a bag, without replacement), but I was wondering if there was some sort of standard convention on how calculate the conditional probability when you don't know the intersection? Example. Say we have three people (Alex, Bob, Carol) with their three hats. Say I take all their hats, mix them up, and then return one to each person. What is the probability that person A and B get exactly their own hat back? ""Solution"" : The way I would think of it is: Let and be the events that Alex and Bob get their hats back respectively. Then, The probability of would be . Now, the way I would calculate intuitively , even though I don't know what the intersection is (because that's what I'm trying to find), is ""Since Bob has his hat, I have two hats left, which gives a probability of for Alex to get his hat back."" This intuitive logic of getting to the conditional probability directly, when I didn't use/bypassed the definition, is what I would like to clarify/formalise.",A B S \mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}. \mathbb{P}(A\cap B)=\mathbb{P}(A|B)\times \mathbb{P}(B) \mathbb{P}(A|B)? E_A E_B \mathbb{P}(E_A\cap E_B)= \mathbb{P}(E_B)\times \mathbb{P}(E_A|E_B) E_B \frac{1}{3} \mathbb{P}(E_A|E_B)  \frac{1}{2},"['probability', 'definition', 'conditional-probability']"
10,"Limit superior of $Y_1 + \ldots, Y_n$ with $Y_i$ bounded, i.i.d. and $\Pr(Y_1 \neq 0)>0$.","Limit superior of  with  bounded, i.i.d. and .","Y_1 + \ldots, Y_n Y_i \Pr(Y_1 \neq 0)>0","I am looking to establish that if $Y_1, Y_2, \ldots$ are bounded i.i.d. random variables satisfying $E(Y_1) = 0$ and $\Pr(Y_1 \neq 0) >0$ then for $X_n = Y_1 + \ldots, Y_n$ , with probability one $$ \limsup_n X_n= \infty \quad \text{and} \quad \liminf_n X_n = -\infty  $$ . Now, obviously these are tail events and as a result they have probability either zero or one. Hence it suffices to show that the probability is positive. For this, $$\Pr(\limsup_n X_n \geq M) \geq \limsup_n  \Pr(X_n \geq M) $$ so that it suffices to show that the right hand side is positive and this is where I am stuck since I cannot translate this into a statement for the $Y_i$ . Could you please give me a hint? I know that this may be done with the help of the Central Limit Theorem but I am looking for a solution that avoids this.","I am looking to establish that if are bounded i.i.d. random variables satisfying and then for , with probability one . Now, obviously these are tail events and as a result they have probability either zero or one. Hence it suffices to show that the probability is positive. For this, so that it suffices to show that the right hand side is positive and this is where I am stuck since I cannot translate this into a statement for the . Could you please give me a hint? I know that this may be done with the help of the Central Limit Theorem but I am looking for a solution that avoids this.","Y_1, Y_2, \ldots E(Y_1) = 0 \Pr(Y_1 \neq 0) >0 X_n = Y_1 + \ldots, Y_n  \limsup_n X_n= \infty \quad \text{and} \quad \liminf_n X_n = -\infty   \Pr(\limsup_n X_n \geq M) \geq \limsup_n  \Pr(X_n \geq M)  Y_i","['probability', 'probability-theory', 'convergence-divergence']"
11,Why is this method incorrect?,Why is this method incorrect?,,"A man is to be executed at random time between 00:00 and 01:00. The   firing squad's accuracy decreases linearly, so that at 00:00 they   shoot perfectly, at 00:30 miss half the time, and at 01:00 miss   always. Also, with probability 1/2, a blank round of shots will be   used. Given that the man survived, what is the probability that he faced a   live round? At first I drew a diagram with time on x-axis, a horizontal line at $y=1/2$ with ""blind round"" above it and ""live round"" below. Then I divided that lower region with a diagonal to represent the falling accuracy, and got the answer $\frac{1}{4} / (\frac{1}{4}+\frac{1}{2}) = \frac{1}{3}$ which a simulation seems to confirm. I'm not sure why the following method gives an incorrect answer: at time $\theta$ , $P_\theta (\text{survived})=\theta/2 + 1/2$ and $P_\theta(\text{live rounds and survived}) = \theta/2$ . Therefore $P_\theta(\text{live rounds | survived}) = \frac{\theta}{\theta+1}$ . Now integrate to get $\int_0^1 P_\theta d\theta = \int_0^1 \frac{d\theta . \theta}{\theta+1} = 1-\log 2 \approx 0.3069$ .","A man is to be executed at random time between 00:00 and 01:00. The   firing squad's accuracy decreases linearly, so that at 00:00 they   shoot perfectly, at 00:30 miss half the time, and at 01:00 miss   always. Also, with probability 1/2, a blank round of shots will be   used. Given that the man survived, what is the probability that he faced a   live round? At first I drew a diagram with time on x-axis, a horizontal line at with ""blind round"" above it and ""live round"" below. Then I divided that lower region with a diagonal to represent the falling accuracy, and got the answer which a simulation seems to confirm. I'm not sure why the following method gives an incorrect answer: at time , and . Therefore . Now integrate to get .",y=1/2 \frac{1}{4} / (\frac{1}{4}+\frac{1}{2}) = \frac{1}{3} \theta P_\theta (\text{survived})=\theta/2 + 1/2 P_\theta(\text{live rounds and survived}) = \theta/2 P_\theta(\text{live rounds | survived}) = \frac{\theta}{\theta+1} \int_0^1 P_\theta d\theta = \int_0^1 \frac{d\theta . \theta}{\theta+1} = 1-\log 2 \approx 0.3069,"['probability', 'probability-distributions']"
12,What is the base measure in measure theory?,What is the base measure in measure theory?,,"I see the term ""base measure"" used frequently about measures. I do not completely get what that exactly means: Some examples are: Let $\cal F$ be the space of all probability density functions with   respect to a base measure $\nu$ What is the base measure? Sometimes when a probabilistic function is integrated, the dx is called a base measure. $$\int_{\cal X}  ....  dx$$ Can someone explain in simple words or refer me to a simple reference to read about ""base measures"".","I see the term ""base measure"" used frequently about measures. I do not completely get what that exactly means: Some examples are: Let be the space of all probability density functions with   respect to a base measure What is the base measure? Sometimes when a probabilistic function is integrated, the dx is called a base measure. Can someone explain in simple words or refer me to a simple reference to read about ""base measures"".",\cal F \nu \int_{\cal X}  ....  dx,"['probability', 'measure-theory', 'reference-request']"
13,PMF of throwing a die 4 times,PMF of throwing a die 4 times,,"We throw a fair 6-sided die independently four times and let $X$ denote the minimal value rolled. What is the probability that $X \ge 4$ ? Compute the PMF of $X$ . Determine the mean and variance of $X$ . My attempt: $(1/2)^4$ because that means each of the $4$ rolls, you either get a $4, 5$ or $6$ . for $X=1: (1/6)(6/6)(6/6)(6/6)$ for $X=2: (1/6)(5/6)(5/6)(5/6)$ for $X=3: (1/6)(4/6)(4/6)(4/6)$ for $X=4: (1/6)(3/6)(3/6)(3/6)$ for $X=5: (1/6)(2/6)(2/6)(2/6)$ for $X=6: (1/6)(1/6)(1/6)(1/6)$ I can calculate this once I know I did the PMF correctly Did I do (1) and (2) correctly?","We throw a fair 6-sided die independently four times and let denote the minimal value rolled. What is the probability that ? Compute the PMF of . Determine the mean and variance of . My attempt: because that means each of the rolls, you either get a or . for for for for for for I can calculate this once I know I did the PMF correctly Did I do (1) and (2) correctly?","X X \ge 4 X X (1/2)^4 4 4, 5 6 X=1: (1/6)(6/6)(6/6)(6/6) X=2: (1/6)(5/6)(5/6)(5/6) X=3: (1/6)(4/6)(4/6)(4/6) X=4: (1/6)(3/6)(3/6)(3/6) X=5: (1/6)(2/6)(2/6)(2/6) X=6: (1/6)(1/6)(1/6)(1/6)","['probability', 'probability-distributions', 'dice']"
14,"What is $\mathbb P\{W\leq x,Y\leq y\}$ ?Is it $\mathbb P\{\omega \in \Omega : X(\omega )\leq x,Y(\omega )\leq y\}$?",What is  ?Is it ?,"\mathbb P\{W\leq x,Y\leq y\} \mathbb P\{\omega \in \Omega : X(\omega )\leq x,Y(\omega )\leq y\}","Let $(\Omega ,\mathbb F,\mathbb P)$ . I'm confuse about something : Let $X,Y:\Omega \to \mathbb R$ r.v. What is $$\mathbb P\{X\leq x,Y\leq y\} \ \ ?\tag{1}$$ Is it, $$\mathbb P\{\omega \in \Omega \mid X(\omega )\leq x,Y(\omega )\leq y\}$$ or $$\mathbb P\{(\omega ,\omega ')\in \Omega ^2\mid X(\omega )\leq x,Y(\omega ')\leq y\} \ \ ?\tag{2}$$ I say the notation $$\mathbb P\{X\leq x,Y\leq y\}=\mathbb P\{\{\omega \in \Omega \mid X(\omega )\leq x\}\cap \{\omega \in \Omega \mid Y(\omega )\leq x\}\},$$ but in otherhand, I know that $\mathbb P\{X\in A,Y\in B\}$ is a product measure on $\mathbb R^2$ , so may be we also have a product measure on $\Omega ^2$ ? I'm a bit confuse... Espacially that if $(\Omega ',\mathcal F',\mathbb P')$ , and $X:\Omega \to \mathbb R$ , $Y:\Omega '\to \mathbb R$ , then $$\mathbb P\otimes \mathbb P'\{X\leq x, Y\leq y\}=\mathbb P\otimes\mathbb P'\{(\omega ,\omega ')\in \Omega \times \Omega '\mid X(\omega )\leq x, Y(\omega ' )\leq y\}=\mathbb P\{X\leq x\}\mathbb P'\{Y\leq y\},$$ which is a measure on $\mathbb R^2$ . That's why I would think that $(é)$ is true but not $(1)$ . What do you think ?","Let . I'm confuse about something : Let r.v. What is Is it, or I say the notation but in otherhand, I know that is a product measure on , so may be we also have a product measure on ? I'm a bit confuse... Espacially that if , and , , then which is a measure on . That's why I would think that is true but not . What do you think ?","(\Omega ,\mathbb F,\mathbb P) X,Y:\Omega \to \mathbb R \mathbb P\{X\leq x,Y\leq y\} \ \ ?\tag{1} \mathbb P\{\omega \in \Omega \mid X(\omega )\leq x,Y(\omega )\leq y\} \mathbb P\{(\omega ,\omega ')\in \Omega ^2\mid X(\omega )\leq x,Y(\omega ')\leq y\} \ \ ?\tag{2} \mathbb P\{X\leq x,Y\leq y\}=\mathbb P\{\{\omega \in \Omega \mid X(\omega )\leq x\}\cap \{\omega \in \Omega \mid Y(\omega )\leq x\}\}, \mathbb P\{X\in A,Y\in B\} \mathbb R^2 \Omega ^2 (\Omega ',\mathcal F',\mathbb P') X:\Omega \to \mathbb R Y:\Omega '\to \mathbb R \mathbb P\otimes \mathbb P'\{X\leq x, Y\leq y\}=\mathbb P\otimes\mathbb P'\{(\omega ,\omega ')\in \Omega \times \Omega '\mid X(\omega )\leq x, Y(\omega ' )\leq y\}=\mathbb P\{X\leq x\}\mathbb P'\{Y\leq y\}, \mathbb R^2 (é) (1)","['probability', 'measure-theory']"
15,"Chance of losing a biased ""Random Walk"" game","Chance of losing a biased ""Random Walk"" game",,"Consider a game where you start with 1 point. Then you flip a fair coin infinitely many times. For each heads, you gain 2 points. For each tails, you lose 1 point. What is the probability that your score never goes below 1? edit: I am looking specifically for the answer with flipping infinitely many times, not the probability after $N$ flips as $N$ approaches infinity.","Consider a game where you start with 1 point. Then you flip a fair coin infinitely many times. For each heads, you gain 2 points. For each tails, you lose 1 point. What is the probability that your score never goes below 1? edit: I am looking specifically for the answer with flipping infinitely many times, not the probability after $N$ flips as $N$ approaches infinity.",,"['probability', 'random-walk']"
16,Finding the standard deviation of a probability distribution.,Finding the standard deviation of a probability distribution.,,"Here is the question: The time, to the nearest whole minute, that a city bus takes to go from one end of its route to the other has the probability distribution shown.   As sometimes happens with probabilities computed as empirical relative frequencies, probabilities in the table add up only to a value other than $1.00$ because of round-off error.   $$   \begin{array}{c|cccccc}       x     & 42     & 43     & 44     & 45     & 46     & 47     \\     \hline       P(x)     & 0.10     & 0.23     & 0.34     & 0.25     & 0.05     & 0.02     \\   \end{array} $$   a. Find the average time the bus takes to drive the length of its route. b. Find the standard deviation of the length of time the bus takes to drive the length of its route. (Original image here .) I did the first part and got $E(X)=43.54$, which is the correct answer. However, for the second part, I use the formula $\sigma = \sqrt{(\sum x^{2}P(x))-E(X)^{2}}$ and get approximately $4.517$. The answer is $1.204$. Where did I go wrong?","Here is the question: The time, to the nearest whole minute, that a city bus takes to go from one end of its route to the other has the probability distribution shown.   As sometimes happens with probabilities computed as empirical relative frequencies, probabilities in the table add up only to a value other than $1.00$ because of round-off error.   $$   \begin{array}{c|cccccc}       x     & 42     & 43     & 44     & 45     & 46     & 47     \\     \hline       P(x)     & 0.10     & 0.23     & 0.34     & 0.25     & 0.05     & 0.02     \\   \end{array} $$   a. Find the average time the bus takes to drive the length of its route. b. Find the standard deviation of the length of time the bus takes to drive the length of its route. (Original image here .) I did the first part and got $E(X)=43.54$, which is the correct answer. However, for the second part, I use the formula $\sigma = \sqrt{(\sum x^{2}P(x))-E(X)^{2}}$ and get approximately $4.517$. The answer is $1.204$. Where did I go wrong?",,['probability']
17,Random variable with exponential distribution.,Random variable with exponential distribution.,,"Let $X$ be random variable with exponential distribution $\mathcal{E}(2)$ and let $Y$ be another random variable such that $$Y=\max\left(X^2, \frac{X+1}{2} \right).$$ Find the distribution for random variable $Y$. Distribution for $X$ is $f_X(x)= 2e^{-2x}, x>0$ and zero otherwise. Now, for variable $Y$ we have that it's distribution is zero whenever $y \leq \frac{1}{4}$ For $y=t> \frac{1}{2}$ we have the following: $F_Y(t)=\int_0^{2t-1} f_X(x)dx= 1- e^{2-4t}$ Similarly, for $y=t>1$ we have $F_Y(t)=\int_0^{\sqrt{t}} f_X(x)dx= 1- e^{-2\sqrt{t}}$ But, i cannot understand what happens in case that $y$ takes random value on interval $(\frac{1}{4}, \frac{1}{2})$. It's the black line on the graph. How can i handle situations like this? Any help appreciated!","Let $X$ be random variable with exponential distribution $\mathcal{E}(2)$ and let $Y$ be another random variable such that $$Y=\max\left(X^2, \frac{X+1}{2} \right).$$ Find the distribution for random variable $Y$. Distribution for $X$ is $f_X(x)= 2e^{-2x}, x>0$ and zero otherwise. Now, for variable $Y$ we have that it's distribution is zero whenever $y \leq \frac{1}{4}$ For $y=t> \frac{1}{2}$ we have the following: $F_Y(t)=\int_0^{2t-1} f_X(x)dx= 1- e^{2-4t}$ Similarly, for $y=t>1$ we have $F_Y(t)=\int_0^{\sqrt{t}} f_X(x)dx= 1- e^{-2\sqrt{t}}$ But, i cannot understand what happens in case that $y$ takes random value on interval $(\frac{1}{4}, \frac{1}{2})$. It's the black line on the graph. How can i handle situations like this? Any help appreciated!",,"['probability', 'probability-distributions', 'exponential-distribution']"
18,What is the probability that you chose the coin B,What is the probability that you chose the coin B,,"Question Suppose you have two coins A and B the probability of head in A is $\frac{1}{4}$ and the probability of head in B is $\frac{3}{4}$ . Now, suppose you have chosen a coin and tossed it two times. The output was head and head. What is the probability that you chose the coin B. My Approach I used Bayes' theorem , Let Event, $\text{output to be Head Head}=E$ Req'd probability= $P({B}\mid{E})$ $$P({B}\mid{E})=\frac{P({E}\mid{B})\times P(B)}{P({E}\mid{B})\times P(B)+P({E}\mid{A})\times P(A)}$$ $$=\frac{\frac{3}{4} \times \frac{3}{4}  \times \frac{1}{2}} {{\frac{3}{4} \times \frac{3}{4}  \times \frac{1}{2}}+{\frac{1}{4} \times \frac{1}{4}  \times \frac{1}{2}}}$$ $$=\frac{9}{10}$$ Am i correct?","Question Suppose you have two coins A and B the probability of head in A is and the probability of head in B is . Now, suppose you have chosen a coin and tossed it two times. The output was head and head. What is the probability that you chose the coin B. My Approach I used Bayes' theorem , Let Event, Req'd probability= Am i correct?",\frac{1}{4} \frac{3}{4} \text{output to be Head Head}=E P({B}\mid{E}) P({B}\mid{E})=\frac{P({E}\mid{B})\times P(B)}{P({E}\mid{B})\times P(B)+P({E}\mid{A})\times P(A)} =\frac{\frac{3}{4} \times \frac{3}{4}  \times \frac{1}{2}} {{\frac{3}{4} \times \frac{3}{4}  \times \frac{1}{2}}+{\frac{1}{4} \times \frac{1}{4}  \times \frac{1}{2}}} =\frac{9}{10},['probability']
19,Sum of random variables is equal to zero infinitely often,Sum of random variables is equal to zero infinitely often,,"$X_1,\dots ,X_n$ are i.i.d random variables with $P(X_1=1)=p$, $P(X_1=-1)=1-p$, $p\neq\frac{1}{2}$. And $S_n=\sum_{k=1}^nX_k$. I need to show that $P(\limsup_{n\to\infty}\{S_n=0\})\in\{0,1\}$. It seems to me that $\limsup_{n\to\infty}\{S_n=0\}$ is not in tail sigma-algebra. Without this, i don't know how to proceed with it.","$X_1,\dots ,X_n$ are i.i.d random variables with $P(X_1=1)=p$, $P(X_1=-1)=1-p$, $p\neq\frac{1}{2}$. And $S_n=\sum_{k=1}^nX_k$. I need to show that $P(\limsup_{n\to\infty}\{S_n=0\})\in\{0,1\}$. It seems to me that $\limsup_{n\to\infty}\{S_n=0\}$ is not in tail sigma-algebra. Without this, i don't know how to proceed with it.",,"['probability', 'probability-theory']"
20,chi squared divergence and Kullback Leibler divergence,chi squared divergence and Kullback Leibler divergence,,"$\def\KL#1#2{\operatorname{KL}(#1 \| #2)}$ $\def\chisq#1#2{\operatorname{\chi^2}(#1 \| #2)}$ I am asked to prove that given two discrete random variables (or probability measures) $P \ll Q$ i.e. $P$ is absolutely continuous with respect to $Q$ (so that the Radon-Nikodym derivative is just $\frac{P(x)}{Q(x)}$ where defined. We will call this $g(x)$ ), we have $\KL P Q \leq \chisq P Q$ where both are defined. The definitions are: $\KL P Q  = \mathbb E_Q[g(x) \ln g(x)]$ , and $\chisq P Q = \mathbb E_Q[(g(x) - 1)^2]$ . Now, one way of proving the inequality is to show $(y-1)^2 \geq y \ln y$ everywhere on $[0,\infty)$ , since this is the range of $g$ . However, this is not true, for example with $y = 2$ . So this makes me wonder if what I have got is wrong. Is it not possible that I can find $P$ and $Q$ such that $g$ is supported in  the region where the inequality above does not hold, so that I can get a counterexample? I know I am doing something very wrong here, something very silly. I would like to be pointed out what I am doing incorrectly.","I am asked to prove that given two discrete random variables (or probability measures) i.e. is absolutely continuous with respect to (so that the Radon-Nikodym derivative is just where defined. We will call this ), we have where both are defined. The definitions are: , and . Now, one way of proving the inequality is to show everywhere on , since this is the range of . However, this is not true, for example with . So this makes me wonder if what I have got is wrong. Is it not possible that I can find and such that is supported in  the region where the inequality above does not hold, so that I can get a counterexample? I know I am doing something very wrong here, something very silly. I would like to be pointed out what I am doing incorrectly.","\def\KL#1#2{\operatorname{KL}(#1 \| #2)} \def\chisq#1#2{\operatorname{\chi^2}(#1 \| #2)} P \ll Q P Q \frac{P(x)}{Q(x)} g(x) \KL P Q \leq \chisq P Q \KL P Q  = \mathbb E_Q[g(x) \ln g(x)] \chisq P Q = \mathbb E_Q[(g(x) - 1)^2] (y-1)^2 \geq y \ln y [0,\infty) g y = 2 P Q g","['probability', 'probability-theory']"
21,Quick question about a picture - area under a normal distribution is always 1,Quick question about a picture - area under a normal distribution is always 1,,"Check out the picture below. It's from this site: http://mathworld.wolfram.com/Convolution.html All 3 curves (red, blue, green) are normal distributions [Edit and solution to my question (thanks Hyperplane): Turns out they are not the curves of a normal distribution. I learned ""Gaussian"" does not necessarily mean a probability density function] . Green is the convolution of blue and red. My question I know the area under all normal curves is one (axiom of probability). But it seems like the red curve has the biggest area. I know the convolution of two normals has a variance equal to the sum of the variance of $f$ and $g$... I feel this is a bad picture, but I know I'm wrong to accuse wolfram of that. Can you fix my intuiton? Is it really just all in the tails? Sorry if this is the dumbest question ever.","Check out the picture below. It's from this site: http://mathworld.wolfram.com/Convolution.html All 3 curves (red, blue, green) are normal distributions [Edit and solution to my question (thanks Hyperplane): Turns out they are not the curves of a normal distribution. I learned ""Gaussian"" does not necessarily mean a probability density function] . Green is the convolution of blue and red. My question I know the area under all normal curves is one (axiom of probability). But it seems like the red curve has the biggest area. I know the convolution of two normals has a variance equal to the sum of the variance of $f$ and $g$... I feel this is a bad picture, but I know I'm wrong to accuse wolfram of that. Can you fix my intuiton? Is it really just all in the tails? Sorry if this is the dumbest question ever.",,"['probability', 'statistics']"
22,Are Parabolas With Two x-Intercepts More Numerous Than Parabolas With No x-Intercepts?,Are Parabolas With Two x-Intercepts More Numerous Than Parabolas With No x-Intercepts?,,"Suppose we randomly assign values to a , b and c in the equation $y=ax^2 + bx + c$. Whenever the discriminant $(b^2-4ac)$ is positive, the parabola will have two x-intercepts. This will happen whenever $4ac<b^2$, or more explicitly, whenever: $4ac<0$, $4ac=0$ & $0<b^2$, or $0<4ac<b^2$ Let’s distinguish the question of whether $4ac=0$. If our discussion is limited to quadratic equations (in which a cannot equal $0$), $4ac=0$ only when $c=0$. I don’t know what probability to assign to that case, but I don’t think that the question of probability will be important. If $4ac=0$, a parabola usually has two x-intercepts: When $b=0$, $b^2=0$, discriminant=$0$, and the parabola has 1 x-intercept When b is not $0$, $b^2>0$ and the parabola has 2 x-intercepts If 4ac does not equal $0$, a parabola usually has two x-intercepts: 4ac < 0             4ac > 0 |4ac|< b2   Two x-intercepts    Two x-intercepts |4ac|= b2   Two x-intercepts    One x-intercept |4ac|> b2   Two x-intercepts    No x-intercept (I'm assuming that these columns are equally likely, not that the rows are. There are two x-intercepts whenever $4ac<0$ (50% of the time) and sometimes even if $4ac>0$ (some positive percent of the time). So that seems to be a greater-than-50% chance.) So regardless of whether $4ac=0$, parabolas usually have two x-intercepts. But that must be wrong. A randomly selected parabola must have the same probability of two x-intercepts as of no x-intercepts. Parabolas can open up or down (with equal probability), with vertex above or below the x-axis (with equal probability). Vertex is above x-axis  Vertex is below x-axis Parabola opens up   No x-intercepts         Two x-intercepts Parabola opens down Two x-intercepts        No x-intercept No? SOME REFLECTIONS ON THE RESPONSE SO FAR As happens with painful regularity, the response is a bit too sophisticated for me to understand totally. But I believe there are two major lines of analysis going: (1) doubt that randomly selected values of a , b and c create an equal likelihood that the parabola's vertex lies above or below the x -axis; and (2) doubt about the concept of selection ""at random."" Let's consider that first question first. In an equation in the form $y=ax^2 + bx + c$, the axis of symmetry is the line $x=-b/2a$, and the y-coordinate of the vertex is the y-value associated with that x-value: $y = a(x)^2 + b(x) + c$ $y = a(-b/2a)^2 + b(-b/2a) + c$ $y = ab^2/4a^2 – b^2/2a + c$ $y = b^2/4a – b^2/2a + c$ $y = b^2/4a – 2b^2/4a + 4ac/4a$ $y = (b^2 – 2b^2 + 4ac)/4a$ $y = (– 1b^2 + 4ac)/4a$ When will y be positive? What seems fairly clear to me is that those four alternatives should be equally numerous. I admit to some confusion about the sign of y in those cases where a and c are either both positive or both negative, but it does seem to me that the top-left case should supply some number of positive- y results, the bottom-right case should supply an equal number of negative- y results, and as a whole the table suggests an equal probability that y is positive or negative. But in any event, even if this analysis is wrong, and a random selection of a , b and c DOES NOT allow an equal likelihood of the vertex above or below the x -axis, doesn't it remain the case that the parabola is equally likely to open up or down, so that half of all parabolas (whether vertex-above or vertex-below) will open towards the x -axis and create two x -intercepts? As to the second concern, about random selection, I just don't understand the issue. I read the referenced page about probability distributions, and the only thing that strikes me is the paucity of examples with neither greatest nor least possible value, cases like mine in which a , b and c can be any number. Would it improve the question to consider the random selection of an integer, instead of all real numbers? Do I need to constrain the question to values within a certain interval? What is to be done?","Suppose we randomly assign values to a , b and c in the equation $y=ax^2 + bx + c$. Whenever the discriminant $(b^2-4ac)$ is positive, the parabola will have two x-intercepts. This will happen whenever $4ac<b^2$, or more explicitly, whenever: $4ac<0$, $4ac=0$ & $0<b^2$, or $0<4ac<b^2$ Let’s distinguish the question of whether $4ac=0$. If our discussion is limited to quadratic equations (in which a cannot equal $0$), $4ac=0$ only when $c=0$. I don’t know what probability to assign to that case, but I don’t think that the question of probability will be important. If $4ac=0$, a parabola usually has two x-intercepts: When $b=0$, $b^2=0$, discriminant=$0$, and the parabola has 1 x-intercept When b is not $0$, $b^2>0$ and the parabola has 2 x-intercepts If 4ac does not equal $0$, a parabola usually has two x-intercepts: 4ac < 0             4ac > 0 |4ac|< b2   Two x-intercepts    Two x-intercepts |4ac|= b2   Two x-intercepts    One x-intercept |4ac|> b2   Two x-intercepts    No x-intercept (I'm assuming that these columns are equally likely, not that the rows are. There are two x-intercepts whenever $4ac<0$ (50% of the time) and sometimes even if $4ac>0$ (some positive percent of the time). So that seems to be a greater-than-50% chance.) So regardless of whether $4ac=0$, parabolas usually have two x-intercepts. But that must be wrong. A randomly selected parabola must have the same probability of two x-intercepts as of no x-intercepts. Parabolas can open up or down (with equal probability), with vertex above or below the x-axis (with equal probability). Vertex is above x-axis  Vertex is below x-axis Parabola opens up   No x-intercepts         Two x-intercepts Parabola opens down Two x-intercepts        No x-intercept No? SOME REFLECTIONS ON THE RESPONSE SO FAR As happens with painful regularity, the response is a bit too sophisticated for me to understand totally. But I believe there are two major lines of analysis going: (1) doubt that randomly selected values of a , b and c create an equal likelihood that the parabola's vertex lies above or below the x -axis; and (2) doubt about the concept of selection ""at random."" Let's consider that first question first. In an equation in the form $y=ax^2 + bx + c$, the axis of symmetry is the line $x=-b/2a$, and the y-coordinate of the vertex is the y-value associated with that x-value: $y = a(x)^2 + b(x) + c$ $y = a(-b/2a)^2 + b(-b/2a) + c$ $y = ab^2/4a^2 – b^2/2a + c$ $y = b^2/4a – b^2/2a + c$ $y = b^2/4a – 2b^2/4a + 4ac/4a$ $y = (b^2 – 2b^2 + 4ac)/4a$ $y = (– 1b^2 + 4ac)/4a$ When will y be positive? What seems fairly clear to me is that those four alternatives should be equally numerous. I admit to some confusion about the sign of y in those cases where a and c are either both positive or both negative, but it does seem to me that the top-left case should supply some number of positive- y results, the bottom-right case should supply an equal number of negative- y results, and as a whole the table suggests an equal probability that y is positive or negative. But in any event, even if this analysis is wrong, and a random selection of a , b and c DOES NOT allow an equal likelihood of the vertex above or below the x -axis, doesn't it remain the case that the parabola is equally likely to open up or down, so that half of all parabolas (whether vertex-above or vertex-below) will open towards the x -axis and create two x -intercepts? As to the second concern, about random selection, I just don't understand the issue. I read the referenced page about probability distributions, and the only thing that strikes me is the paucity of examples with neither greatest nor least possible value, cases like mine in which a , b and c can be any number. Would it improve the question to consider the random selection of an integer, instead of all real numbers? Do I need to constrain the question to values within a certain interval? What is to be done?",,"['probability', 'algebraic-geometry', 'conic-sections']"
23,Sleeping beauty problem and Monty Hall paradox,Sleeping beauty problem and Monty Hall paradox,,"I read this argument on the internet about how the solution to the sleeping beauty problem is $\frac{1}{3}$: All these events are equally likely in the experiment : Coin landed Heads, it's Monday and Beauty is awake Coin landed Heads, it's Tuesday and Beauty is asleep Coin landed Tails, it's Monday and Beauty is awake Coin landed Tails, it's Tuesday and Beauty is awake All these are mutually exclusive and exhaustive and also equally likely. So, all four of these events have a probability $\frac{1}{4}$. But when Beauty is awakened, she knows that she isn't asleep. So, the second possibility can be ruled out. The rest three are still equally likely with a probability $\frac{1}{3}$. Hence the probability that the coin landed Heads is $\frac{1}{3}$. But I remember something from the Monty Hall problem and this situation looks somewhat similar. The solution assumes that when possibility no. 2 is ruled out, the remaining three remain equally likely. This doesn't happen in the Monty Hall problem. For example, there are 100 doors. A prize is behind one of them. Clearly, all the doors are equally likely to have the prize. We pick one random door. The probability that it has the prize is $\frac{1}{100}$. The probability that the prize is in one of the remaining doors is $\frac{99}{100}$. When doors from the set of remaining 99 doors are ruled out one by one, all the doors no longer remain equally likely. Our door still has the probability $\frac{1}{100}$ while the group of remaining doors still hold a  probability of $\frac{99}{100}$. Could this be true for the Sleeping Beauty Problem too? I mean the possibilities 1. and 2. that I've listed collectively hold a probability of $\frac{1}{2}$ and even when possibility no.2 is ruled out, it's probability gets transferred to possibility no.1, so that it still has a probability of $\frac{1}{2}$. EDIT: Suppose Beauty is the contestant on the Monty Hall Show. She is presented four doors in front of her, A, B, C, D. Clearly, all the door currently have a winning probability of $\frac{1}{4}$. But she knows that before the prize was put behind one of the doors, a coin was tossed. If it landed heads, the prize was placed in one of the doors A or B and in case it was tails, the prize was put in C or D. Beauty knows this. Now, the host rules out door B as a possibility (which is equivalent to Beauty ruling out possibility 2). Do the doors A, C and D remain equally likely to have the prize or is it safer to choose A? I think it's safer to choose A because either you can assume the coin landed tails and further burden yourself in choosing between C and D or you can assume the coin landed heads and then choose A, the only remaining Heads door.","I read this argument on the internet about how the solution to the sleeping beauty problem is $\frac{1}{3}$: All these events are equally likely in the experiment : Coin landed Heads, it's Monday and Beauty is awake Coin landed Heads, it's Tuesday and Beauty is asleep Coin landed Tails, it's Monday and Beauty is awake Coin landed Tails, it's Tuesday and Beauty is awake All these are mutually exclusive and exhaustive and also equally likely. So, all four of these events have a probability $\frac{1}{4}$. But when Beauty is awakened, she knows that she isn't asleep. So, the second possibility can be ruled out. The rest three are still equally likely with a probability $\frac{1}{3}$. Hence the probability that the coin landed Heads is $\frac{1}{3}$. But I remember something from the Monty Hall problem and this situation looks somewhat similar. The solution assumes that when possibility no. 2 is ruled out, the remaining three remain equally likely. This doesn't happen in the Monty Hall problem. For example, there are 100 doors. A prize is behind one of them. Clearly, all the doors are equally likely to have the prize. We pick one random door. The probability that it has the prize is $\frac{1}{100}$. The probability that the prize is in one of the remaining doors is $\frac{99}{100}$. When doors from the set of remaining 99 doors are ruled out one by one, all the doors no longer remain equally likely. Our door still has the probability $\frac{1}{100}$ while the group of remaining doors still hold a  probability of $\frac{99}{100}$. Could this be true for the Sleeping Beauty Problem too? I mean the possibilities 1. and 2. that I've listed collectively hold a probability of $\frac{1}{2}$ and even when possibility no.2 is ruled out, it's probability gets transferred to possibility no.1, so that it still has a probability of $\frac{1}{2}$. EDIT: Suppose Beauty is the contestant on the Monty Hall Show. She is presented four doors in front of her, A, B, C, D. Clearly, all the door currently have a winning probability of $\frac{1}{4}$. But she knows that before the prize was put behind one of the doors, a coin was tossed. If it landed heads, the prize was placed in one of the doors A or B and in case it was tails, the prize was put in C or D. Beauty knows this. Now, the host rules out door B as a possibility (which is equivalent to Beauty ruling out possibility 2). Do the doors A, C and D remain equally likely to have the prize or is it safer to choose A? I think it's safer to choose A because either you can assume the coin landed tails and further burden yourself in choosing between C and D or you can assume the coin landed heads and then choose A, the only remaining Heads door.",,['probability']
24,Markov inequality on tossing a fair die n times,Markov inequality on tossing a fair die n times,,I am tossing a fair die $n$ times. What is the the probability that the sum of the numbers is at most $2n$. I am doing this in the following way: I found $\mathbb E[X] = 3.5n$ So  $$\Pr[X\leq 2n] = 1 - P[X > 2n]$$ According to Markov inequality: $$P[X>2n] \leq E[X]/2n = 3.5n/2n = 3.5/2 =1.75$$ So $P[X \leq 2n] > 1 - 1.75 = -0.75$. I am not sure where I am going wrong? How a probability can be negative?,I am tossing a fair die $n$ times. What is the the probability that the sum of the numbers is at most $2n$. I am doing this in the following way: I found $\mathbb E[X] = 3.5n$ So  $$\Pr[X\leq 2n] = 1 - P[X > 2n]$$ According to Markov inequality: $$P[X>2n] \leq E[X]/2n = 3.5n/2n = 3.5/2 =1.75$$ So $P[X \leq 2n] > 1 - 1.75 = -0.75$. I am not sure where I am going wrong? How a probability can be negative?,,"['probability', 'inequality', 'random-variables']"
25,Change of variable on a probability density function - $\sin(x)$,Change of variable on a probability density function -,\sin(x),"Problem: Let $y = \sin{X}$, where $X$ is a uniformly distributed over $(0, 2 \pi)$. Find the pdf of $Y$. Answer: In this case we have: \begin{eqnarray*} f_x(x) &=& \frac{1}{2 \pi} \\ h(x) &=& \sin(x) \\ \end{eqnarray*} We know that: \begin{eqnarray*} f_y(y) &=& f_y(x) \Big| \frac{dx}{dy} \Big| \\ \end{eqnarray*} \begin{eqnarray*} \sin^{-1}y &=& x \\ \frac{dx}{dy} &=& \frac{1}{\sqrt{1 - y^2}} \\ f_y(y) &=& \frac{1}{2 \pi} \Big| \frac{1}{\sqrt{1 - y^2}} \Big| \\ \end{eqnarray*} Now we have to consider the limits. The maximum value of $\sin(x)$ is $1$. The minimum value of $\sin(x)$ is $-1$. \begin{eqnarray*} f_y(y) = \begin{cases} \frac{1}{2 \pi \sqrt{1 - y^2}} & -1< y < 1 \\ 0	& otherwise \\ \end{cases} \end{eqnarray*} However, the book gets: \begin{eqnarray*} f_y(y) &=& \begin{cases} \frac{1}{\pi \sqrt{1 - y^2}} & -1 < y < 1 \\ 0	& otherwise \\ \end{cases} \end{eqnarray*} What am I missing? Thanks, Bob","Problem: Let $y = \sin{X}$, where $X$ is a uniformly distributed over $(0, 2 \pi)$. Find the pdf of $Y$. Answer: In this case we have: \begin{eqnarray*} f_x(x) &=& \frac{1}{2 \pi} \\ h(x) &=& \sin(x) \\ \end{eqnarray*} We know that: \begin{eqnarray*} f_y(y) &=& f_y(x) \Big| \frac{dx}{dy} \Big| \\ \end{eqnarray*} \begin{eqnarray*} \sin^{-1}y &=& x \\ \frac{dx}{dy} &=& \frac{1}{\sqrt{1 - y^2}} \\ f_y(y) &=& \frac{1}{2 \pi} \Big| \frac{1}{\sqrt{1 - y^2}} \Big| \\ \end{eqnarray*} Now we have to consider the limits. The maximum value of $\sin(x)$ is $1$. The minimum value of $\sin(x)$ is $-1$. \begin{eqnarray*} f_y(y) = \begin{cases} \frac{1}{2 \pi \sqrt{1 - y^2}} & -1< y < 1 \\ 0	& otherwise \\ \end{cases} \end{eqnarray*} However, the book gets: \begin{eqnarray*} f_y(y) &=& \begin{cases} \frac{1}{\pi \sqrt{1 - y^2}} & -1 < y < 1 \\ 0	& otherwise \\ \end{cases} \end{eqnarray*} What am I missing? Thanks, Bob",,"['probability', 'probability-theory']"
26,Proof of the delta method,Proof of the delta method,,"The classical, well known delta method states the following: If $\sqrt{n}(X_{n}-\theta)\overset{law}{\longrightarrow}N(0,\sigma^{2})$. Then the following holds: $\sqrt{n}(g(X_{n})-g(\theta))\overset{law}{\longrightarrow}N(0,\sigma^{2}(g'(\theta))^{2})$ for any function $g$ satisfying the property that $g'(\theta)$ exists and is non-zero valued.  The key step, proving this result, is the following expression: $g(X_{n})=g(\theta)+g'(\overline{\theta})(X_{n}-\theta)$ for some intermediate value $\overline{\theta}$ with $X_{n}<\overline{\theta}<\theta$.  What exactly ensures the existence of such a $\overline{\theta}$? It should follow using Taylor's theorem, but I am not able to argue rigorously.","The classical, well known delta method states the following: If $\sqrt{n}(X_{n}-\theta)\overset{law}{\longrightarrow}N(0,\sigma^{2})$. Then the following holds: $\sqrt{n}(g(X_{n})-g(\theta))\overset{law}{\longrightarrow}N(0,\sigma^{2}(g'(\theta))^{2})$ for any function $g$ satisfying the property that $g'(\theta)$ exists and is non-zero valued.  The key step, proving this result, is the following expression: $g(X_{n})=g(\theta)+g'(\overline{\theta})(X_{n}-\theta)$ for some intermediate value $\overline{\theta}$ with $X_{n}<\overline{\theta}<\theta$.  What exactly ensures the existence of such a $\overline{\theta}$? It should follow using Taylor's theorem, but I am not able to argue rigorously.",,"['probability', 'probability-theory', 'statistics']"
27,"What is the number of binary strings of length N with exactly R runs of ones, with C total ones?","What is the number of binary strings of length N with exactly R runs of ones, with C total ones?",,"I'm concerned with the total number of ones, and the total number of runs, but not with the size of any of the runs. For example, $N=8$, $R=3$, $C=5$ includes 11101010, 01101011 among the 24 total possible strings. I can compute these for small $N$ easily enough, but I am specifically interested in the distribution for $N=65536$. As this will result in very large integers, the log probability distribution is equally useful. I found [1] and [2], which includes this: Let $N_{n;g_k,s_k}$ denote the number of binary strings which contain for given $g_k$ and $s_k$, $g_k=0,1,…,⌊\frac{s_k}{k}⌋$, $s_k=0,k,k+1,…,n$, exactly $g_k$ runs of 1’s of length at least $k$ with total number of 1’s (with sum of lengths of runs of 1’s) exactly equal to $s_k$ in all possible binary strings of length $n$. An expression for this is given in eq. (24): $N_{n;g_k,s_k} = \sum_{y=0}^{n-s_k} {y+1 \choose g_k } {s_k-(k-1)g_k-1 \choose g_k-1} \sum_{j=0}^{⌊\frac{n-y-s_k}{k}⌋} (-1)^j {y+1-g_k \choose j} {n-s_k-kj-g_k \choose n-s_k-kj-y} $ for $g_k \in \{1, ..., ⌊\frac{s_k}{k}⌋\}$, $s_k \in \{k, k+1, ..., n\}$. I think this is exactly what I'm looking for, with $k = 1$, $s_k = C$ and $g_k = R$. However, when I implemented this I did not get the expected results (Python shown below, edge cases omitted), based on comparing to counting all strings for N=8. I am working backwards to try to understand where I might have gone wrong, but not having much luck yet. I wonder if I am misunderstanding the result. def F(x, y, n):     # x = C or s_k (cardinality)     # y = R or g_k (runCount)     # n = N (total bits)      a1 = 0     for z in range(n-x+1):         b1 = choose(z+1, y) * choose(x-1, y-1)         a2 = 0         for j in range(n-z-x+1):             a2 += (-1) ** j * choose(z+1-y, j) * choose(n-x-j-y, n-x-j-z)         a1 += b1 * a2      return a1 Note that the choose function uses factorial, which I realize won't work for larger $N$ - but should be fine for $N=8$. Edit: corrected a sign error typo in eq. (24) and the equivalent error in the python code. [1] Counting Runs of Ones and Ones in Runs of Ones in Binary Strings, Frosso S. Makri, Zaharias M. Psillakis, Nikolaos Kollas https://file.scirp.org/pdf/OJAppS_2013011110241057.pdf [2] On success runs of a fixed length in Bernoulli sequences: Exact and asymptotic results, Frosso S.Makria, Zaharias M.Psillakis http://www.sciencedirect.com/science/article/pii/S0898122110009284","I'm concerned with the total number of ones, and the total number of runs, but not with the size of any of the runs. For example, $N=8$, $R=3$, $C=5$ includes 11101010, 01101011 among the 24 total possible strings. I can compute these for small $N$ easily enough, but I am specifically interested in the distribution for $N=65536$. As this will result in very large integers, the log probability distribution is equally useful. I found [1] and [2], which includes this: Let $N_{n;g_k,s_k}$ denote the number of binary strings which contain for given $g_k$ and $s_k$, $g_k=0,1,…,⌊\frac{s_k}{k}⌋$, $s_k=0,k,k+1,…,n$, exactly $g_k$ runs of 1’s of length at least $k$ with total number of 1’s (with sum of lengths of runs of 1’s) exactly equal to $s_k$ in all possible binary strings of length $n$. An expression for this is given in eq. (24): $N_{n;g_k,s_k} = \sum_{y=0}^{n-s_k} {y+1 \choose g_k } {s_k-(k-1)g_k-1 \choose g_k-1} \sum_{j=0}^{⌊\frac{n-y-s_k}{k}⌋} (-1)^j {y+1-g_k \choose j} {n-s_k-kj-g_k \choose n-s_k-kj-y} $ for $g_k \in \{1, ..., ⌊\frac{s_k}{k}⌋\}$, $s_k \in \{k, k+1, ..., n\}$. I think this is exactly what I'm looking for, with $k = 1$, $s_k = C$ and $g_k = R$. However, when I implemented this I did not get the expected results (Python shown below, edge cases omitted), based on comparing to counting all strings for N=8. I am working backwards to try to understand where I might have gone wrong, but not having much luck yet. I wonder if I am misunderstanding the result. def F(x, y, n):     # x = C or s_k (cardinality)     # y = R or g_k (runCount)     # n = N (total bits)      a1 = 0     for z in range(n-x+1):         b1 = choose(z+1, y) * choose(x-1, y-1)         a2 = 0         for j in range(n-z-x+1):             a2 += (-1) ** j * choose(z+1-y, j) * choose(n-x-j-y, n-x-j-z)         a1 += b1 * a2      return a1 Note that the choose function uses factorial, which I realize won't work for larger $N$ - but should be fine for $N=8$. Edit: corrected a sign error typo in eq. (24) and the equivalent error in the python code. [1] Counting Runs of Ones and Ones in Runs of Ones in Binary Strings, Frosso S. Makri, Zaharias M. Psillakis, Nikolaos Kollas https://file.scirp.org/pdf/OJAppS_2013011110241057.pdf [2] On success runs of a fixed length in Bernoulli sequences: Exact and asymptotic results, Frosso S.Makria, Zaharias M.Psillakis http://www.sciencedirect.com/science/article/pii/S0898122110009284",,"['probability', 'combinatorics', 'binary', 'polya-urn-model', 'bit-strings']"
28,Probability of getting at least one ace,Probability of getting at least one ace,,You have a normal 52 card deck. Note that your hand does not depend on order. You are dealt two cards. What is the probability you will get at least one ace? How do I approach this problem?,You have a normal 52 card deck. Note that your hand does not depend on order. You are dealt two cards. What is the probability you will get at least one ace? How do I approach this problem?,,"['probability', 'probability-theory', 'discrete-mathematics']"
29,Test of Hypothesis with Binomial Distribution,Test of Hypothesis with Binomial Distribution,,"It is known that 40% of a certain species of birds have characteristic B. Twelve birds of this species are captured in an unusual environment and 4 of them are found to have characteristic B. Is it reasonable to assume that the birds in this environment have a smaller probability than that the species in general has? I assumed that this is a binomial case with $p=0.4$ and $n=12.$ Then to figure out if the assumption of the birds having smaller probability than the species is correct, I tried to do it using hypothesis testing and finding the P-value, but I got confused. Any help will be appreciated!","It is known that 40% of a certain species of birds have characteristic B. Twelve birds of this species are captured in an unusual environment and 4 of them are found to have characteristic B. Is it reasonable to assume that the birds in this environment have a smaller probability than that the species in general has? I assumed that this is a binomial case with $p=0.4$ and $n=12.$ Then to figure out if the assumption of the birds having smaller probability than the species is correct, I tried to do it using hypothesis testing and finding the P-value, but I got confused. Any help will be appreciated!",,"['probability', 'computational-mathematics', 'hypothesis-testing']"
30,Trouble understanding conditional probability question,Trouble understanding conditional probability question,,"This is a solved example in Introduction to  Probability by Tsitsiklis, page 26, example 1.11 A Class consists of 4 graduate and 12 undergraduate students is randomly divided into 4 groups of 4. What is the probability that each includes a graduate student? I understand the combinatorial way to do this problem using multinomial theorem. I am here interested in the conditional probability approach. Solution: Let us denote the four graduate students by 1,2,3,4 and consider the events $A_1$ ={students 1 and 2 are in different groups} $A_2$ = {students 1,2 and 3 are in different groups} $A_3$ ={students 1,2,3 and 4 are in different groups} We will calculate $P(A_3) = P(A_1 \cap A_2\cap A_3)= P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)$ We have $P(A_1) =\frac{12}{15}$ since there are 12 students slot in groups other than the one of the student 1, and there are 15 student slots overall, excluding student 1. Similarly $P(A_2|A_1) =\frac{8}{14}$ and $P(A_3|A_1\cap A_2) =\frac{4}{13}$ and so $P(A_3) = \frac{12}{15} \times \frac{8}{14} \times \frac{4}{13}$ The question I have is how did he get $P(A_1)=\frac{12}{15}$ ? I understand that there are 4 graduate students who need to be in 4 different groups and along with 3 undergraduate students. I understand the reason for finding $P(A_1 \cap A_2 \cap A_3)$.  What I don't understand is how he got $P(A_1) = \frac{12}{15}$. Do we have two groups of 4 students each with two graduate students in two different groups ? Can someone explain to me the size of the two groups we have so formed with $A_1$ and similarly with $A_2$ and $A_3$? If i have calculate $P(A_1),P(A_2|A_1),P(A_3|A_1\cap A_2)$ probabilities using counting how will i come to these numbers ? Thank you.","This is a solved example in Introduction to  Probability by Tsitsiklis, page 26, example 1.11 A Class consists of 4 graduate and 12 undergraduate students is randomly divided into 4 groups of 4. What is the probability that each includes a graduate student? I understand the combinatorial way to do this problem using multinomial theorem. I am here interested in the conditional probability approach. Solution: Let us denote the four graduate students by 1,2,3,4 and consider the events $A_1$ ={students 1 and 2 are in different groups} $A_2$ = {students 1,2 and 3 are in different groups} $A_3$ ={students 1,2,3 and 4 are in different groups} We will calculate $P(A_3) = P(A_1 \cap A_2\cap A_3)= P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)$ We have $P(A_1) =\frac{12}{15}$ since there are 12 students slot in groups other than the one of the student 1, and there are 15 student slots overall, excluding student 1. Similarly $P(A_2|A_1) =\frac{8}{14}$ and $P(A_3|A_1\cap A_2) =\frac{4}{13}$ and so $P(A_3) = \frac{12}{15} \times \frac{8}{14} \times \frac{4}{13}$ The question I have is how did he get $P(A_1)=\frac{12}{15}$ ? I understand that there are 4 graduate students who need to be in 4 different groups and along with 3 undergraduate students. I understand the reason for finding $P(A_1 \cap A_2 \cap A_3)$.  What I don't understand is how he got $P(A_1) = \frac{12}{15}$. Do we have two groups of 4 students each with two graduate students in two different groups ? Can someone explain to me the size of the two groups we have so formed with $A_1$ and similarly with $A_2$ and $A_3$? If i have calculate $P(A_1),P(A_2|A_1),P(A_3|A_1\cap A_2)$ probabilities using counting how will i come to these numbers ? Thank you.",,['probability']
31,Is $cY$ lognormal?,Is  lognormal?,cY,"For $X$~$N(u,v^2)$ and $Y=e^{x}$, is $cY$ lognormal? (where $c>0$ is a constant). I have already found the pdf of $Y=e^{x}$, which gives us the lognormal distribution. However, I don't know how to see if $cY$ is lognormal. Am I supposed to plug in $cY$ in for $y$? What does it mean for something to be lognormal? Any help is greatly appreciated, thank you!","For $X$~$N(u,v^2)$ and $Y=e^{x}$, is $cY$ lognormal? (where $c>0$ is a constant). I have already found the pdf of $Y=e^{x}$, which gives us the lognormal distribution. However, I don't know how to see if $cY$ is lognormal. Am I supposed to plug in $cY$ in for $y$? What does it mean for something to be lognormal? Any help is greatly appreciated, thank you!",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
32,"Why is the random variable $X-Y$ almost sure constant if it is independent of $X$ and $Y$? Is this valid for a general random variable $f(X,Y)$?",Why is the random variable  almost sure constant if it is independent of  and ? Is this valid for a general random variable ?,"X-Y X Y f(X,Y)","Good day, In class we said that if a random variable $X-Y$ is independent of random variables $X$ and $Y$ then $X-Y$ is almost sure constant, i.e. there exists a $c \in \mathbb{R}$ such that $P(X-Y=c)=1$ . First, I don't exactly how to prove this. I know that $X$ is constant if it is independent of itself. Therefore I could prove that $X-Y$ is independent of itself (But the other directions doesn't hold I suppose). Do I know that $X-Y$ is independent of itself? Is it correct to say: If $Z$ is independent of $X$ and $Y$ then it is independent of $g(X,Y)$ where $g$ is a measurable function. I don't think so. The definition of independence doesn't give this property. Then how do I prove that $X-Y$ is almost sure constant? Another approach through expectations: $$E(X-Y|X)=E(X-Y|Y)=E(X-Y)=EX-EY $$ But is seems not leading me to a goal. So: Why is the random variable $X-Y$ almost sure constant if it is independent of $X$ and $Y$ ? Is this valid for a general random variable $f(X,Y)$ (where $f$ is measurable for example)? i.e. $f(X,Y)$ is almost sure constant it it is independent of $X$ and $Y$ ? If not I would ask for a counterexample. Thanks a lot for your help, Marvin","Good day, In class we said that if a random variable is independent of random variables and then is almost sure constant, i.e. there exists a such that . First, I don't exactly how to prove this. I know that is constant if it is independent of itself. Therefore I could prove that is independent of itself (But the other directions doesn't hold I suppose). Do I know that is independent of itself? Is it correct to say: If is independent of and then it is independent of where is a measurable function. I don't think so. The definition of independence doesn't give this property. Then how do I prove that is almost sure constant? Another approach through expectations: But is seems not leading me to a goal. So: Why is the random variable almost sure constant if it is independent of and ? Is this valid for a general random variable (where is measurable for example)? i.e. is almost sure constant it it is independent of and ? If not I would ask for a counterexample. Thanks a lot for your help, Marvin","X-Y X Y X-Y c \in \mathbb{R} P(X-Y=c)=1 X X-Y X-Y Z X Y g(X,Y) g X-Y E(X-Y|X)=E(X-Y|Y)=E(X-Y)=EX-EY  X-Y X Y f(X,Y) f f(X,Y) X Y","['probability', 'probability-theory']"
33,"Example of a Distribution that is not symmetric, but has a skewness of zero.","Example of a Distribution that is not symmetric, but has a skewness of zero.",,"In my probably class we saw that if a distribution is symmetric then the skewness will be zero. Intuitively this makes sense to me since if a data set is symmetric than for each point that is distance 'd' above the mean there will be a point that is distance 'd' below the mean (Although, in practice this is probably just very close to zero and actually zero). However, it was implied in class that the converse is not true. That is, there may exist a distribution which is not symmetric, or skewed, but the skewness is zero. Can anyone give me an actual example of a distribution that is skewed, but the values of the skewness equals zero? Cheers","In my probably class we saw that if a distribution is symmetric then the skewness will be zero. Intuitively this makes sense to me since if a data set is symmetric than for each point that is distance 'd' above the mean there will be a point that is distance 'd' below the mean (Although, in practice this is probably just very close to zero and actually zero). However, it was implied in class that the converse is not true. That is, there may exist a distribution which is not symmetric, or skewed, but the skewness is zero. Can anyone give me an actual example of a distribution that is skewed, but the values of the skewness equals zero? Cheers",,"['probability', 'statistics', 'probability-distributions']"
34,"Creating unusual probabilities with a single dice, using the minimal number of expected rolls","Creating unusual probabilities with a single dice, using the minimal number of expected rolls",,"Problem I want to create an 'event' with probability of $\frac{1}{7}$ with a single dice as efficiently as possible (to roll the dice as little as possible). To give you some better understanding of the question, if I would like an event with probability of $\frac{1}{9}$ , I could easily do it in various ways. One way is to see whether the sum of two rolls is $5$ . Another way is to roll the dice twice and see whether they are both not higher than $2$ . If I had to choose $\frac{1}{5}$ , we can do this 'trick': success on drawing $1$ , but if we draw $6$ just disregard it and roll again, until we draw a number which is not $6$ . In that case the expected number of rolls is $\frac{6}{5}$ . So, one way to get probability of $\frac{1}{7}$ is basically the same, choosing $7$ predefined ordered pairs of 2 rolls to be the success set, and disregard any other combination (and to roll the dice twice again, if other combination occurs). In that case, the expected number of dice rolls needed is $\frac{72}{7}$ which seems pretty bad to me and makes we wonder... is there a better way? Generalization In general, if we have a $k$ -sided dice what is the optimal way of obtaining an event with probability $\frac1m$ using the least expected dice rolls? And what if we want to simulate an $m$ -side dice and not just one event?","Problem I want to create an 'event' with probability of with a single dice as efficiently as possible (to roll the dice as little as possible). To give you some better understanding of the question, if I would like an event with probability of , I could easily do it in various ways. One way is to see whether the sum of two rolls is . Another way is to roll the dice twice and see whether they are both not higher than . If I had to choose , we can do this 'trick': success on drawing , but if we draw just disregard it and roll again, until we draw a number which is not . In that case the expected number of rolls is . So, one way to get probability of is basically the same, choosing predefined ordered pairs of 2 rolls to be the success set, and disregard any other combination (and to roll the dice twice again, if other combination occurs). In that case, the expected number of dice rolls needed is which seems pretty bad to me and makes we wonder... is there a better way? Generalization In general, if we have a -sided dice what is the optimal way of obtaining an event with probability using the least expected dice rolls? And what if we want to simulate an -side dice and not just one event?",\frac{1}{7} \frac{1}{9} 5 2 \frac{1}{5} 1 6 6 \frac{6}{5} \frac{1}{7} 7 \frac{72}{7} k \frac1m m,"['probability', 'dice']"
35,Linear Transformation of Poisson Point Process,Linear Transformation of Poisson Point Process,,"Suppose we have a random variable that follows a Poisson Point Process: $ X \sim poisson(\lambda t) $ and a function $f(x) = ax + b $ where $a,b \in \mathbb{R}$. What is the pdf of $Y = aX + b$? I know for continuous random variables if $f(x)$ is strictly increasing: $$f_y(Y = y) = \frac{1}{|a|} f_x\left(\frac{y-b}{a}\right)$$ However I am having trouble doing this for the discrete case. My attempt is as follows suppose for simplicity $t = 1$, thus $X \sim poisson(\lambda)$, Now we have: \begin{align*} P(Y \leq y)  &= P(aX + b \leq y)\\ &= P\left(X \leq \frac{y - b}{a}\right)\\ &= F_x\left(\frac{y-b}{a}\right)\\ \\ P(Y = k) &= P(Y \leq k) - P(Y \leq k - 1)\\ &=F_y(Y = k) - F_y(Y =  k - 1)\\ &= F_x(\frac{k-b}{a}) - F_x(\frac{k-1-b}{a}) \\ &= \sum_{n = 0}^{\frac{k-b}{a}} e^{\lambda} \frac{\lambda^n}{n!} - \sum_{n = 0}^{\frac{k-1 -b}{a}} e^{\lambda} \frac{\lambda^n}{n!} \end{align*} At this point I am stuck because clearly the factorials could take noninteger values, so this difference seems to be meaningless. Can anyone give me a hint as to how to continue?","Suppose we have a random variable that follows a Poisson Point Process: $ X \sim poisson(\lambda t) $ and a function $f(x) = ax + b $ where $a,b \in \mathbb{R}$. What is the pdf of $Y = aX + b$? I know for continuous random variables if $f(x)$ is strictly increasing: $$f_y(Y = y) = \frac{1}{|a|} f_x\left(\frac{y-b}{a}\right)$$ However I am having trouble doing this for the discrete case. My attempt is as follows suppose for simplicity $t = 1$, thus $X \sim poisson(\lambda)$, Now we have: \begin{align*} P(Y \leq y)  &= P(aX + b \leq y)\\ &= P\left(X \leq \frac{y - b}{a}\right)\\ &= F_x\left(\frac{y-b}{a}\right)\\ \\ P(Y = k) &= P(Y \leq k) - P(Y \leq k - 1)\\ &=F_y(Y = k) - F_y(Y =  k - 1)\\ &= F_x(\frac{k-b}{a}) - F_x(\frac{k-1-b}{a}) \\ &= \sum_{n = 0}^{\frac{k-b}{a}} e^{\lambda} \frac{\lambda^n}{n!} - \sum_{n = 0}^{\frac{k-1 -b}{a}} e^{\lambda} \frac{\lambda^n}{n!} \end{align*} At this point I am stuck because clearly the factorials could take noninteger values, so this difference seems to be meaningless. Can anyone give me a hint as to how to continue?",,"['probability', 'probability-distributions']"
36,Expected number of blocks of identical weather,Expected number of blocks of identical weather,,"The problem is as follows: On a given day, the weather can either be sunny (with probability $0.4$), cloudy (with probability $0.4$), or rainy (with probability $0.2$). Assume weather is independent across days. Define blocks of weather to be the largest possible groups of consecutive days in which the weather is the same. For example, if it rained for eight days, followed by a day of sun, then a day of rain, we'd have three blocks. Across a ten-day period, what's the expected number of blocks of identical weather? Hint: rather than calculating the probability of each possible number of blocks, try defining the answer as a sum and using linearity of expectation. Even with the hint, I'm not sure how to approach it past the 1 block case.","The problem is as follows: On a given day, the weather can either be sunny (with probability $0.4$), cloudy (with probability $0.4$), or rainy (with probability $0.2$). Assume weather is independent across days. Define blocks of weather to be the largest possible groups of consecutive days in which the weather is the same. For example, if it rained for eight days, followed by a day of sun, then a day of rain, we'd have three blocks. Across a ten-day period, what's the expected number of blocks of identical weather? Hint: rather than calculating the probability of each possible number of blocks, try defining the answer as a sum and using linearity of expectation. Even with the hint, I'm not sure how to approach it past the 1 block case.",,['probability']
37,On expectation of maximum of gaussians,On expectation of maximum of gaussians,,"Let $X_1,\ldots,X_n$ be i.i.d $\mathcal{N}(0,1)$ random variables. I am trying to prove that \begin{align} (a)\ \   \mathbb{E} \left[ \max_{i}X_i\right] & \asymp\mathbb{E} \left[ \max_{i}|X_i|\right] \asymp \sqrt{\log n},\\ (b) \ \ \mathbb{E} \left[ \max_{i}X_i\right] &= \sqrt{2 \log n}+o(1) \end{align} where $A \asymp B$ means there exists universal constants $m,M >0$ such that $mA \leq B \leq MA$. For part (a), I was able to prove the upper bound that $\mathbb{E} \left[ \max_{i}X_i\right] \leq \sqrt{2 \log n}$ using Jensen's inequality. How do I prove the lower bound and the fact that the two expectations are equivalent? I've been given the following hint: $\mathbb{P}(\max_{i}X_i \geq t)=1-\mathbb{P}(X_1 \leq t)^n$.","Let $X_1,\ldots,X_n$ be i.i.d $\mathcal{N}(0,1)$ random variables. I am trying to prove that \begin{align} (a)\ \   \mathbb{E} \left[ \max_{i}X_i\right] & \asymp\mathbb{E} \left[ \max_{i}|X_i|\right] \asymp \sqrt{\log n},\\ (b) \ \ \mathbb{E} \left[ \max_{i}X_i\right] &= \sqrt{2 \log n}+o(1) \end{align} where $A \asymp B$ means there exists universal constants $m,M >0$ such that $mA \leq B \leq MA$. For part (a), I was able to prove the upper bound that $\mathbb{E} \left[ \max_{i}X_i\right] \leq \sqrt{2 \log n}$ using Jensen's inequality. How do I prove the lower bound and the fact that the two expectations are equivalent? I've been given the following hint: $\mathbb{P}(\max_{i}X_i \geq t)=1-\mathbb{P}(X_1 \leq t)^n$.",,"['probability', 'normal-distribution', 'order-statistics']"
38,Finding the expectation and variance from a probability generating function,Finding the expectation and variance from a probability generating function,,"For the probability generating function $G_X(z) = \frac{p}{1-qz}$ where $q=1-p$ , use $G_X(z)$ to deduce that $$E[X] = \frac{1-p}{p}\quad \text{ and } \quad Var(X) = \frac{1-p}{p^2}$$ Do I need to differentiate with respect to $z$ for the expectation?","For the probability generating function where , use to deduce that Do I need to differentiate with respect to for the expectation?",G_X(z) = \frac{p}{1-qz} q=1-p G_X(z) E[X] = \frac{1-p}{p}\quad \text{ and } \quad Var(X) = \frac{1-p}{p^2} z,"['probability', 'expected-value', 'generating-functions', 'variance']"
39,First to the sequence HT between two players,First to the sequence HT between two players,,"Two players, A and B, alternatively toss a fair coin (A tosses first and then B). The sequence of heads and tails is recorded. If there is a head followed by a tail (HT subsequence), the game ends and the person who tosses the tail wins. What is the probability that A wins the game? The solutions states that $P(A) = 1/2*P(A|H) + 1/2*P(A|T)$ and takes $P(A|T) = 1-P(A)$ which makes sense. However, I can't understand why it takes $P(A|H) = 1/2*(1-P(A|H))$. I know the part $(1-P(A|H))$ has to do with the case when B gets a H, but I don't understand the logic behind this term. Thank You Thank You","Two players, A and B, alternatively toss a fair coin (A tosses first and then B). The sequence of heads and tails is recorded. If there is a head followed by a tail (HT subsequence), the game ends and the person who tosses the tail wins. What is the probability that A wins the game? The solutions states that $P(A) = 1/2*P(A|H) + 1/2*P(A|T)$ and takes $P(A|T) = 1-P(A)$ which makes sense. However, I can't understand why it takes $P(A|H) = 1/2*(1-P(A|H))$. I know the part $(1-P(A|H))$ has to do with the case when B gets a H, but I don't understand the logic behind this term. Thank You Thank You",,['probability']
40,Prove if $P(A | B^c) = P(A | B)$ then the events A and B are independent.,Prove if  then the events A and B are independent.,P(A | B^c) = P(A | B),So I've started by saying that since $P(A | B^c) = P(A | B)$ we know that $\frac{P(A \cap B^c)}{P(B^c)} = \frac{P(A \cap B)}{P(B)}$. However I'm not sure where to go from there. Any help would be great!,So I've started by saying that since $P(A | B^c) = P(A | B)$ we know that $\frac{P(A \cap B^c)}{P(B^c)} = \frac{P(A \cap B)}{P(B)}$. However I'm not sure where to go from there. Any help would be great!,,['probability']
41,The probability of two consecutive non-leap years having 52 Fridays each is $\frac{5}{7}$. How?,The probability of two consecutive non-leap years having 52 Fridays each is . How?,\frac{5}{7},"I took a test on probabilities, and there was this question about finding the probability of two consecutive non-leap years having 52 Fridays each. I figured it would be $\frac{6}{7} \times \frac{5}{7}$, which is the product of the probability of there being 52 Fridays in a non-leap year and the probability of there being 52 Fridays in the successive year if the previous year had 52 Fridays. The teacher told me the answer was $\frac{36}{49}$, which is obviously incorrect. I explained my reasoning, but he didn't budge. I got home and actually analysed years from 1800 to 2000 to find out what the correct answer is. It is actually $\frac{5}{7}$. I cannot seem to figure out how, though, but it must have something to do with the leap years not being taken into consideration. A year is a leap year if it is divisible by 4. If it is divisible by 100, but not by 400, it is not a leap year. I changed $\frac{2}{3}$ in my original question to $\frac{5}{7}$ because that is actually the correct answer (which Christian Blatter proves correct in his answer). The $\frac{2}{3}$ came about due to faulty coding.","I took a test on probabilities, and there was this question about finding the probability of two consecutive non-leap years having 52 Fridays each. I figured it would be $\frac{6}{7} \times \frac{5}{7}$, which is the product of the probability of there being 52 Fridays in a non-leap year and the probability of there being 52 Fridays in the successive year if the previous year had 52 Fridays. The teacher told me the answer was $\frac{36}{49}$, which is obviously incorrect. I explained my reasoning, but he didn't budge. I got home and actually analysed years from 1800 to 2000 to find out what the correct answer is. It is actually $\frac{5}{7}$. I cannot seem to figure out how, though, but it must have something to do with the leap years not being taken into consideration. A year is a leap year if it is divisible by 4. If it is divisible by 100, but not by 400, it is not a leap year. I changed $\frac{2}{3}$ in my original question to $\frac{5}{7}$ because that is actually the correct answer (which Christian Blatter proves correct in his answer). The $\frac{2}{3}$ came about due to faulty coding.",,"['probability', 'statistics']"
42,How do I calculate the odds of a given set of dice results occurring before another given set?,How do I calculate the odds of a given set of dice results occurring before another given set?,,"Dice odds seem simple at first glance, but I've never taken a Calculus based statistics course or game theory, and I think I may need to in order to solve some of the things I'm trying to solve. I can hammer out the odds in some of the more straight-forward scenarios, but when it comes to calculating the odds of a series of dice events with variable conditions... I get lost in the numbers. I've tried different, seemingly legit methods... only to return vastly different figures each time. Casino craps tables have a great variety of bets and hedge bets you can make. Some of the bets you make can sit on the table for half an hour or more, through dozens and dozens of dice throws, waiting on a resolution. It's technically possible (in theory not fact) that some of these bets could go on forever without being resolved. I would really like a decent approach to calculating these odds myself... hopefully by presenting a particular scenario, I can pick up enough tid-bits from your answers to piece together the methodology: We're throwing two six-sided dice at a time. Each side of each dice has equal probability on any given throw. There exists a tracking list with the numbers: 2, 3, 4, 5, 6, 8, 9, 10, 11, 12. ( Note : 7 is not in this list.) When the dice are thrown and their total is a number other than 7, the number is crossed off the tracking list and the dice are rolled again. When the dice are thrown and their total is a number that's already been crossed off the tracking list, the dice are rolled again. At any point if the dice are thrown and their total is 7, the series is resolved as a loss. At any point if all ten numbers are crossed off the tracking list, the series is resolved as a win. What's the probability of crossing all ten numbers off the list (winning) before throwing a 7 (losing)? This is the""All or Nothing at All"" bonus bet newly popular at many casinos. It pays 175 to 1. There are also ""All Small"" and ""All Tall"" bonus bets that pay 34 to 1 for throwing 2 thru 6 or 8 thru 12 respectively before throwing the 7. There's also a ""Fire Bet"" I'd like to break apart, but the rules are quite different. It will require a new post if I can't cull some new insights from the answers here... Please bear in mind, I'm wanting to know how to calculate conditional dice probability (where instantaneous probability shifts depending on your progression from throw to throw), not just know the odds in this particular case. I've taken mathematics courses up through CalcIII, so I can understand discussions involving limits and summation. Again, I've never takes statistics, probability, or game theory. Sorry for the long post, I know I talk too much....","Dice odds seem simple at first glance, but I've never taken a Calculus based statistics course or game theory, and I think I may need to in order to solve some of the things I'm trying to solve. I can hammer out the odds in some of the more straight-forward scenarios, but when it comes to calculating the odds of a series of dice events with variable conditions... I get lost in the numbers. I've tried different, seemingly legit methods... only to return vastly different figures each time. Casino craps tables have a great variety of bets and hedge bets you can make. Some of the bets you make can sit on the table for half an hour or more, through dozens and dozens of dice throws, waiting on a resolution. It's technically possible (in theory not fact) that some of these bets could go on forever without being resolved. I would really like a decent approach to calculating these odds myself... hopefully by presenting a particular scenario, I can pick up enough tid-bits from your answers to piece together the methodology: We're throwing two six-sided dice at a time. Each side of each dice has equal probability on any given throw. There exists a tracking list with the numbers: 2, 3, 4, 5, 6, 8, 9, 10, 11, 12. ( Note : 7 is not in this list.) When the dice are thrown and their total is a number other than 7, the number is crossed off the tracking list and the dice are rolled again. When the dice are thrown and their total is a number that's already been crossed off the tracking list, the dice are rolled again. At any point if the dice are thrown and their total is 7, the series is resolved as a loss. At any point if all ten numbers are crossed off the tracking list, the series is resolved as a win. What's the probability of crossing all ten numbers off the list (winning) before throwing a 7 (losing)? This is the""All or Nothing at All"" bonus bet newly popular at many casinos. It pays 175 to 1. There are also ""All Small"" and ""All Tall"" bonus bets that pay 34 to 1 for throwing 2 thru 6 or 8 thru 12 respectively before throwing the 7. There's also a ""Fire Bet"" I'd like to break apart, but the rules are quite different. It will require a new post if I can't cull some new insights from the answers here... Please bear in mind, I'm wanting to know how to calculate conditional dice probability (where instantaneous probability shifts depending on your progression from throw to throw), not just know the odds in this particular case. I've taken mathematics courses up through CalcIII, so I can understand discussions involving limits and summation. Again, I've never takes statistics, probability, or game theory. Sorry for the long post, I know I talk too much....",,"['probability', 'statistics', 'probability-theory', 'game-theory', 'dice']"
43,probability that the $100^{th}$ ball you pick is black given the details inside,probability that the  ball you pick is black given the details inside,100^{th},"We begin with a bag containing 3 white balls and another 5 black balls. After each ball is picked, it is returned AND you add to the bag another 4 balls of the same color. For example, the probability that the second ball I pick is black is: $\frac{3}{8}\cdot \frac{5}{12} + \frac{5}{8} \cdot \frac{9}{12}$. $\frac{3}{8} \cdot \frac{5}{12}$ -- picking a white ball first, so in the second pick we have a bag of 12 balls, that only 5 of them are black. $\frac{5}{8} \cdot \frac{9}{12}$ -- picking a black ball first, so in the second pick we have a bag of 12 balls, that only 9 of them are black. I hope that simple example explains all the details in the question. Now, the question is: What is the probability that the $100^{th}$ ball you pick is black? I'm not looking for the final answer, but for the way of solving such questions, as what makes this question complicated for me is that the probability for picking a black ball changes in each pick.","We begin with a bag containing 3 white balls and another 5 black balls. After each ball is picked, it is returned AND you add to the bag another 4 balls of the same color. For example, the probability that the second ball I pick is black is: $\frac{3}{8}\cdot \frac{5}{12} + \frac{5}{8} \cdot \frac{9}{12}$. $\frac{3}{8} \cdot \frac{5}{12}$ -- picking a white ball first, so in the second pick we have a bag of 12 balls, that only 5 of them are black. $\frac{5}{8} \cdot \frac{9}{12}$ -- picking a black ball first, so in the second pick we have a bag of 12 balls, that only 9 of them are black. I hope that simple example explains all the details in the question. Now, the question is: What is the probability that the $100^{th}$ ball you pick is black? I'm not looking for the final answer, but for the way of solving such questions, as what makes this question complicated for me is that the probability for picking a black ball changes in each pick.",,['probability']
44,Expected values of a dice game with a 30-sided die and a 20-sided die.,Expected values of a dice game with a 30-sided die and a 20-sided die.,,"Two people, $A$ and $B$, have a $30$-sided and $20$-sided die, respectively. Each rolls their die, and the person with the highest roll wins. ($B$ also wins in the event of a tie.) The loser pays the winner the value on the winner's die. Question: What is expected value for player $A$? How does the expected value of the game for player $A$ change when player $B$ can re-roll? How much is it worth for player $A$ to get a re-roll in this scenario, where player $B$ can have the re-roll? If you remove player $A$ re-roll. How many re-rolls does player $B$ need in order for him to be a favorite in the game? I took the average score for player $A$ to be $15.5$ and for player $B$ to be $10.5$. I am assuming this to be expected return for player $A$ so $15.5 - 10.5 = 5$. We also need to take into account when $X = Y$ when $A$ loses to $B$ on draw so $5 - (7/20) = 4.65$. What I do not understand is how to factor in for when player $B$ can re-roll. I understand that $B$ would re-roll if he gets a value $< 10.5$ which happens $\frac 12$ of the time. Nor can I seem to grasp how to set up the  follow-up questions.","Two people, $A$ and $B$, have a $30$-sided and $20$-sided die, respectively. Each rolls their die, and the person with the highest roll wins. ($B$ also wins in the event of a tie.) The loser pays the winner the value on the winner's die. Question: What is expected value for player $A$? How does the expected value of the game for player $A$ change when player $B$ can re-roll? How much is it worth for player $A$ to get a re-roll in this scenario, where player $B$ can have the re-roll? If you remove player $A$ re-roll. How many re-rolls does player $B$ need in order for him to be a favorite in the game? I took the average score for player $A$ to be $15.5$ and for player $B$ to be $10.5$. I am assuming this to be expected return for player $A$ so $15.5 - 10.5 = 5$. We also need to take into account when $X = Y$ when $A$ loses to $B$ on draw so $5 - (7/20) = 4.65$. What I do not understand is how to factor in for when player $B$ can re-roll. I understand that $B$ would re-roll if he gets a value $< 10.5$ which happens $\frac 12$ of the time. Nor can I seem to grasp how to set up the  follow-up questions.",,"['probability', 'probability-theory', 'discrete-mathematics']"
45,Videogame (Dota 2) probability,Videogame (Dota 2) probability,,"In Dota 2 after you launch a spell you usually have a cooldown time you need to wait before being able to launch that spell again. In the Year Beast Brawl anyway powerful beasts can have Refresher Aura: Refresher Aura: When an allied hero casts a spell within 900 range of the Beast, that spell has a 50% chance to be instantly refreshed. Given that my hero has Refresher Aura active,the probability of having my spell instantly refreshed(no cooldown) $n$ times in a row is: $\frac{1}{2}^n$. Now my question is: What is the probability of having my spell instantly refreshed $n$ times in a row if I have Refresher Orb (Orb gives the ability to reset the cooldowns of all your items and abilities) given that Refresher Orb can be instantly refreshed by Refresher Aura too? Edit to make the question more clear: What is the probability of being able to cast the spell(Orb has no cooldown or spell has no cooldown or both have no cooldown) after $n$ consecutive spell casts?","In Dota 2 after you launch a spell you usually have a cooldown time you need to wait before being able to launch that spell again. In the Year Beast Brawl anyway powerful beasts can have Refresher Aura: Refresher Aura: When an allied hero casts a spell within 900 range of the Beast, that spell has a 50% chance to be instantly refreshed. Given that my hero has Refresher Aura active,the probability of having my spell instantly refreshed(no cooldown) $n$ times in a row is: $\frac{1}{2}^n$. Now my question is: What is the probability of having my spell instantly refreshed $n$ times in a row if I have Refresher Orb (Orb gives the ability to reset the cooldowns of all your items and abilities) given that Refresher Orb can be instantly refreshed by Refresher Aura too? Edit to make the question more clear: What is the probability of being able to cast the spell(Orb has no cooldown or spell has no cooldown or both have no cooldown) after $n$ consecutive spell casts?",,['probability']
46,Show that $P(X > \lambda) \geq \frac{(EX - \lambda)^2}{EX^2}$,Show that,P(X > \lambda) \geq \frac{(EX - \lambda)^2}{EX^2},"Question: Let X be a nonnegative random variable and $0 < \lambda \leq EX$.  Show that $P(X > \lambda) \geq \frac{(EX - \lambda)^2}{EX^2}$ At first glance I thought I could use some variation of Markov's Inequality. However, I'm not entirely sure where to start.","Question: Let X be a nonnegative random variable and $0 < \lambda \leq EX$.  Show that $P(X > \lambda) \geq \frac{(EX - \lambda)^2}{EX^2}$ At first glance I thought I could use some variation of Markov's Inequality. However, I'm not entirely sure where to start.",,"['real-analysis', 'probability', 'measure-theory', 'statistics', 'probability-theory']"
47,Exclusive-Or probability calculation,Exclusive-Or probability calculation,,"For independent, non-mutually exclusive events, calculate the probability that $A$ or $B$ will be true, but not both. That is, $P(A \oplus B)$. I thought of two ways to compute this probability, but they give different results. Both methods take the union and ""remove"" the intersection, but they do it in different ways. The first (subtraction): $$ P(A \oplus B) = P(A \cup B) - P(A \cap B) \\= P(A) + P(B) - 2P(A)P(B) $$ The second (set operators): $$ P(A \oplus B) = P( (A \cup B) \cap (A \cap B)' \\=[P(A)+P(B)-P(A)P(B)]\cdot [1-P(A)P(B)] $$ But take, as an example, $P(A) = 0.3$ and $P(B) = 0.7$. The first method gives 0.58, while the second gives 0.6241. Which method is wrong, and why?","For independent, non-mutually exclusive events, calculate the probability that $A$ or $B$ will be true, but not both. That is, $P(A \oplus B)$. I thought of two ways to compute this probability, but they give different results. Both methods take the union and ""remove"" the intersection, but they do it in different ways. The first (subtraction): $$ P(A \oplus B) = P(A \cup B) - P(A \cap B) \\= P(A) + P(B) - 2P(A)P(B) $$ The second (set operators): $$ P(A \oplus B) = P( (A \cup B) \cap (A \cap B)' \\=[P(A)+P(B)-P(A)P(B)]\cdot [1-P(A)P(B)] $$ But take, as an example, $P(A) = 0.3$ and $P(B) = 0.7$. The first method gives 0.58, while the second gives 0.6241. Which method is wrong, and why?",,"['probability', 'elementary-set-theory']"
48,"Prove the probability to even number of ""Heads"" is $\frac{1}{2}$.","Prove the probability to even number of ""Heads"" is .",\frac{1}{2},"Let $n$ coins, where at least one of them is a fair coin. Each one of the $n$ coins is tossed - Prove the probability to get even number of ""Heads"" is $\frac{1}{2}$. I'd be glad for a direction. Thanks.","Let $n$ coins, where at least one of them is a fair coin. Each one of the $n$ coins is tossed - Prove the probability to get even number of ""Heads"" is $\frac{1}{2}$. I'd be glad for a direction. Thanks.",,['probability']
49,"Probability that the second-best player finishes second in a single-elimination tournament, given that better players always defeat weaker players?","Probability that the second-best player finishes second in a single-elimination tournament, given that better players always defeat weaker players?",,"A chess tournament (single-elimination format) has 16 players. Suppose that no two players have the same strength, and that each player always defeats the players weaker than himself/herself (i.e. no draws). The loser of the final round becomes the runner-up. What is the chance that the second-best player turns out to be the runner-up? What if there are $2^n$ players? I'm not sure how to approach this. Would it be correct to think that the the probability is $\frac{14}{15} \times \frac{6}{7} \times \frac{2}{3}$, since at each round, there is only one person who can cause the player not to advance, and the number of players in each round is halved? How then, would I approach the follow-up question, where I am supposed to answer this in the general case?","A chess tournament (single-elimination format) has 16 players. Suppose that no two players have the same strength, and that each player always defeats the players weaker than himself/herself (i.e. no draws). The loser of the final round becomes the runner-up. What is the chance that the second-best player turns out to be the runner-up? What if there are $2^n$ players? I'm not sure how to approach this. Would it be correct to think that the the probability is $\frac{14}{15} \times \frac{6}{7} \times \frac{2}{3}$, since at each round, there is only one person who can cause the player not to advance, and the number of players in each round is halved? How then, would I approach the follow-up question, where I am supposed to answer this in the general case?",,"['probability', 'combinatorics']"
50,Which is the correct way to calculate the expected value of a shared lottery jackpot?,Which is the correct way to calculate the expected value of a shared lottery jackpot?,,"I want to calculate the expected value of a ticket in a lottery game which gives players a probability $p$ of winning a jackpot prize of $j$ dollars. The total number of tickets in play is $t$. If every winning ticket gets the full prize amount, the expected value for a ticket is given by $jp$. However, if winners must evenly split the prize in case of multiple winners, then the expected value depends on the number of winners $W$. The expected number of winners is $tp$. The probability that the number of winners $W$ is $w = 0, 1, 2, \dotsc$, follows a Poisson distribution with the expected number of winners as its parameter: $$P(W=w) \sim Pois(tp) = \frac{tp^we^{-tp}}{w!}$$ I don't know how to get from there to calculating an accurate expected value for the ticket as a function of the number of tickets in play. In reading online, I've found two different methods each used by several sources. If I'm following them correctly, then they give different results. My question is 1) which one is correct? 2) what is the error in reasoning (or in my understanding/implementation) in the incorrect method? Method 1: Number of Winners The first method calculates the probability that the number of winners $W$ will be $w = 0, 1, \dotsc, t$, given that there is at least one winner: $$P(W=w | W>0) = \frac{P(W>0|W=w)P(W=w)}{P(W>0)}$$ Where, $P(W>0|W=w)$ is $\left\{      \begin{array}{lr}        0 & : w = 0\\        1 & : w > 0      \end{array}    \right.$ $P(W=w)$ is the probability of $w$ winners: $\frac{tp^we^{-tp}}{w!}$ $P(W>0)$ is the probability of more than one winner: $1 - P(W=0)$ So the expected value of the ticket is given by: $$p\sum_{w=1}^{t} \frac{j}{w}\frac{P(W=w)}{1-P(W=0)}$$ For a numerical example, we'll tabulate the first few values of $P(W=w)$ for a lottery with a 1/34,220 chance of winning \$100,000 jackpot, with 6,000 tickets in play, so $p = 1/34,220; j = 100,000; \text{and } t = 6,000$ $$\begin{array}{c|c|c|c|c|}  \text{Winners} & \text{Probability} & \text{Conditional Probability} & \text{Share} & \text{Contribution } \\ w & P(W=w) & P(W=w|W>0) & j/w & (j/w)P(W=w|W>0) \\ \hline 0 & 0.839 & 0 & \text{\$0} & \text{\$0} \\ \hline 1 & 0.147 & 0.913 & \text{\$100,000} & \text{\$91,300} \\ \hline 2 & 0.013 & 0.081 & \text{\$50,000} & \text{\$4,050} \\ \hline \end{array}$$ Summing the contribution column and multiplying by $p$ gives an expected value of $2.79 . Online resources which use Method 1 ""Powerball Odds"" by Durango Bill - see the section titled ""Sample Calculation to Find the Expected Shared Jackpot Amount When a Large Number of Tickets are in Play"" ""I Am A Statistician and I Buy Lottery Tickets"" by DC Woods. ""Is it Ever Worth it to play Mega Millions?"" by David Torbert Method 2: Number of Other Winners The second method calculates the probability that the number of total winners $W$ is $w = 0, 1, \dotsc, t$, given that our ticket is a winner: $$P(W=w|Winner) = \frac{P(Winner|W=w)P(W=w)}{P(Winner)}$$ Where, $P(Winner)$ is the probability that our ticket is a winner: $p$ $P(Winner|W=w)$ is the probability that our ticket is a winner given $w$ winning tickets: $w/t$ $P(W=w)$ is the probability of $w$ winners: $\frac{tp^we^{-tp}}{w!}$ Plugging those figures in shows that $P(W=w|Winner)$ reduces to $P(W=w-1)$: $$\frac{w}{t}\frac{P(W=w)}{p} = \frac{tp^{w-1}e^{-tp}}{(w-1)!} =  P(W=w-1)$$ So the expected value is given by: $$p\sum_{w=1}^{t}\frac{j}{w}\frac{tp^{w-1}e^{-tp}}{(w-1)!}$$ Using the same lottery numbers as above, the first few values of $w$ are given in the following table. $$\begin{array}{c|c|c|c|c|}  \text{Winners} & \text{Probability} & \text{Conditional Probability} & \text{Share} & \text{Contribution } \\ w & P(W=w) & P(W=w|Winner) & j/w & (j/w)P(W=w|Winner) \\ \hline 0 & 0.839 & 0  & \text{n/a} & \text{\$0} \\ \hline 1 & 0.147 & 0.839  & \text{\$100,000} & \text{\$83,900} \\ \hline 2 & 0.013 & 0.147 & \text{\$50,000} & \text{\$7,350} \\ \hline \end{array}$$ Summing the contribution column and multiplying by $p$ gives an expected value of $2.67 . Online Resources Which Use Method 2 ""Mega Millions and Powerball Odds: Can You Ever Expect a Ticket to be Profitable?"" by Jeremy Elson. See especially his ""Computing the Expected Jackpot: The Gory Details"" . The accepted answer for the math.stackoverflow question, ""What's the expected value of a lottery ticket?"" , gives a nice formula which is equivalent to Method 2: $\dfrac j t (1-(1-p)^t)$ Mark Adler's answer to the math.stackexchange question ""Is Mega Millions Positive Expected Value?"" Clearly the expected payout for the example lottery above cannot be both \$2.79 and \$2.67, but I'm having a difficult time reasoning my way to the correct method. Any hints will be appreciated!","I want to calculate the expected value of a ticket in a lottery game which gives players a probability $p$ of winning a jackpot prize of $j$ dollars. The total number of tickets in play is $t$. If every winning ticket gets the full prize amount, the expected value for a ticket is given by $jp$. However, if winners must evenly split the prize in case of multiple winners, then the expected value depends on the number of winners $W$. The expected number of winners is $tp$. The probability that the number of winners $W$ is $w = 0, 1, 2, \dotsc$, follows a Poisson distribution with the expected number of winners as its parameter: $$P(W=w) \sim Pois(tp) = \frac{tp^we^{-tp}}{w!}$$ I don't know how to get from there to calculating an accurate expected value for the ticket as a function of the number of tickets in play. In reading online, I've found two different methods each used by several sources. If I'm following them correctly, then they give different results. My question is 1) which one is correct? 2) what is the error in reasoning (or in my understanding/implementation) in the incorrect method? Method 1: Number of Winners The first method calculates the probability that the number of winners $W$ will be $w = 0, 1, \dotsc, t$, given that there is at least one winner: $$P(W=w | W>0) = \frac{P(W>0|W=w)P(W=w)}{P(W>0)}$$ Where, $P(W>0|W=w)$ is $\left\{      \begin{array}{lr}        0 & : w = 0\\        1 & : w > 0      \end{array}    \right.$ $P(W=w)$ is the probability of $w$ winners: $\frac{tp^we^{-tp}}{w!}$ $P(W>0)$ is the probability of more than one winner: $1 - P(W=0)$ So the expected value of the ticket is given by: $$p\sum_{w=1}^{t} \frac{j}{w}\frac{P(W=w)}{1-P(W=0)}$$ For a numerical example, we'll tabulate the first few values of $P(W=w)$ for a lottery with a 1/34,220 chance of winning \$100,000 jackpot, with 6,000 tickets in play, so $p = 1/34,220; j = 100,000; \text{and } t = 6,000$ $$\begin{array}{c|c|c|c|c|}  \text{Winners} & \text{Probability} & \text{Conditional Probability} & \text{Share} & \text{Contribution } \\ w & P(W=w) & P(W=w|W>0) & j/w & (j/w)P(W=w|W>0) \\ \hline 0 & 0.839 & 0 & \text{\$0} & \text{\$0} \\ \hline 1 & 0.147 & 0.913 & \text{\$100,000} & \text{\$91,300} \\ \hline 2 & 0.013 & 0.081 & \text{\$50,000} & \text{\$4,050} \\ \hline \end{array}$$ Summing the contribution column and multiplying by $p$ gives an expected value of $2.79 . Online resources which use Method 1 ""Powerball Odds"" by Durango Bill - see the section titled ""Sample Calculation to Find the Expected Shared Jackpot Amount When a Large Number of Tickets are in Play"" ""I Am A Statistician and I Buy Lottery Tickets"" by DC Woods. ""Is it Ever Worth it to play Mega Millions?"" by David Torbert Method 2: Number of Other Winners The second method calculates the probability that the number of total winners $W$ is $w = 0, 1, \dotsc, t$, given that our ticket is a winner: $$P(W=w|Winner) = \frac{P(Winner|W=w)P(W=w)}{P(Winner)}$$ Where, $P(Winner)$ is the probability that our ticket is a winner: $p$ $P(Winner|W=w)$ is the probability that our ticket is a winner given $w$ winning tickets: $w/t$ $P(W=w)$ is the probability of $w$ winners: $\frac{tp^we^{-tp}}{w!}$ Plugging those figures in shows that $P(W=w|Winner)$ reduces to $P(W=w-1)$: $$\frac{w}{t}\frac{P(W=w)}{p} = \frac{tp^{w-1}e^{-tp}}{(w-1)!} =  P(W=w-1)$$ So the expected value is given by: $$p\sum_{w=1}^{t}\frac{j}{w}\frac{tp^{w-1}e^{-tp}}{(w-1)!}$$ Using the same lottery numbers as above, the first few values of $w$ are given in the following table. $$\begin{array}{c|c|c|c|c|}  \text{Winners} & \text{Probability} & \text{Conditional Probability} & \text{Share} & \text{Contribution } \\ w & P(W=w) & P(W=w|Winner) & j/w & (j/w)P(W=w|Winner) \\ \hline 0 & 0.839 & 0  & \text{n/a} & \text{\$0} \\ \hline 1 & 0.147 & 0.839  & \text{\$100,000} & \text{\$83,900} \\ \hline 2 & 0.013 & 0.147 & \text{\$50,000} & \text{\$7,350} \\ \hline \end{array}$$ Summing the contribution column and multiplying by $p$ gives an expected value of $2.67 . Online Resources Which Use Method 2 ""Mega Millions and Powerball Odds: Can You Ever Expect a Ticket to be Profitable?"" by Jeremy Elson. See especially his ""Computing the Expected Jackpot: The Gory Details"" . The accepted answer for the math.stackoverflow question, ""What's the expected value of a lottery ticket?"" , gives a nice formula which is equivalent to Method 2: $\dfrac j t (1-(1-p)^t)$ Mark Adler's answer to the math.stackexchange question ""Is Mega Millions Positive Expected Value?"" Clearly the expected payout for the example lottery above cannot be both \$2.79 and \$2.67, but I'm having a difficult time reasoning my way to the correct method. Any hints will be appreciated!",,['probability']
51,Generating function: Probability regarding coin toss,Generating function: Probability regarding coin toss,,"If a coin is flipped 25 times with eight tails occurring, what is the probability that no run of six (or more) consecutive heads occur? Wasn't sure how to approach this and am quite positive my generating function is incorrect. My attempted work: Consider $e_H,e_T$ s.t $e_H$ denotes the number of times our coin lands on heads and $e_T$ is the number of times our coin lands on tails. We want the number of integer solutions to:    $$e_H+e_T=25$$   where $e_H \in [9,25]$ and $e_T=8$. It follows that our generating function $h$ is   $$h(x)=(x^9+x^{10}+...x^{25})x^8$$   where we want to find the coefficient of $x^{25}$. Now, observe that $h$ can re-written as   $$h(x)=x^{17}(1+x+...x^{16})$$   where we want to find the coefficient of $x^{16}$ now. Using the formula for finite geometric series, we see that $h$ becomes    $$h(x)=x^{17}(\frac{1-x^{17}}{1-x})$$   $$=x^{17}(1-x^{17})(\frac{1}{1-x})$$   where using the formula for infinite geometric series gives us   $$x^{17}(1-x^{17})(1+x+...+x^n+...)$$   Finally, using the formula $h(x)=f(x)g(x)=c_0 + c_1x+...+c_rx^r+...$ where $c_r=a_0b_r+a_1b_{r-1}+...a_rb_0$, we find    $$f(x)=(1-x^{17}),g(x)=(1+x+...)$$   $$\implies a_0b_16=1*1=1$$   so it follows that the coefficient attached to $x^{16}$ is 1. Can someone help lead me down the right path? If my work is actually correct, where do I proceed from here?","If a coin is flipped 25 times with eight tails occurring, what is the probability that no run of six (or more) consecutive heads occur? Wasn't sure how to approach this and am quite positive my generating function is incorrect. My attempted work: Consider $e_H,e_T$ s.t $e_H$ denotes the number of times our coin lands on heads and $e_T$ is the number of times our coin lands on tails. We want the number of integer solutions to:    $$e_H+e_T=25$$   where $e_H \in [9,25]$ and $e_T=8$. It follows that our generating function $h$ is   $$h(x)=(x^9+x^{10}+...x^{25})x^8$$   where we want to find the coefficient of $x^{25}$. Now, observe that $h$ can re-written as   $$h(x)=x^{17}(1+x+...x^{16})$$   where we want to find the coefficient of $x^{16}$ now. Using the formula for finite geometric series, we see that $h$ becomes    $$h(x)=x^{17}(\frac{1-x^{17}}{1-x})$$   $$=x^{17}(1-x^{17})(\frac{1}{1-x})$$   where using the formula for infinite geometric series gives us   $$x^{17}(1-x^{17})(1+x+...+x^n+...)$$   Finally, using the formula $h(x)=f(x)g(x)=c_0 + c_1x+...+c_rx^r+...$ where $c_r=a_0b_r+a_1b_{r-1}+...a_rb_0$, we find    $$f(x)=(1-x^{17}),g(x)=(1+x+...)$$   $$\implies a_0b_16=1*1=1$$   so it follows that the coefficient attached to $x^{16}$ is 1. Can someone help lead me down the right path? If my work is actually correct, where do I proceed from here?",,"['probability', 'combinatorics']"
52,"Probability that $5 \mid x^4 - y^4$ for random $x, y$",Probability that  for random,"5 \mid x^4 - y^4 x, y","Two numbers $x$ and $y$ are chosen at random without replacement from the set $\{1,2,3,\cdots,100\}$. Find the probability that $x^4 - y^4$ is divisible by $5$. I don't know how to proceed with this problem. So any help would be appreciated.","Two numbers $x$ and $y$ are chosen at random without replacement from the set $\{1,2,3,\cdots,100\}$. Find the probability that $x^4 - y^4$ is divisible by $5$. I don't know how to proceed with this problem. So any help would be appreciated.",,"['probability', 'contest-math']"
53,"If $X$ and $Y$ are uniformly distributed on $(0,1)$, what is the distribution of $\max(X,Y)/\min(X,Y)$?","If  and  are uniformly distributed on , what is the distribution of ?","X Y (0,1) \max(X,Y)/\min(X,Y)","Suppose that $X$ and $Y$ are chosen randomly and independently according to the uniform distribution from $(0,1)$ . Define $$ Z=\frac{\max(X,Y)}{\min(X,Y)}.$$ Compute the probability distribution function of $Z$ . Can anyone give me some hints on how to proceed? I can only note that $\mathbb{P}[Z\geq 1]=1$ and $$F_Z(t)= \mathbb{P}[Z \leq t]=\mathbb{P}[X\leq Y, Y\leq tX]+\mathbb{P}[Y \leq X, x\leq tY]$$",Suppose that and are chosen randomly and independently according to the uniform distribution from . Define Compute the probability distribution function of . Can anyone give me some hints on how to proceed? I can only note that and,"X Y (0,1)  Z=\frac{\max(X,Y)}{\min(X,Y)}. Z \mathbb{P}[Z\geq 1]=1 F_Z(t)= \mathbb{P}[Z \leq t]=\mathbb{P}[X\leq Y, Y\leq tX]+\mathbb{P}[Y \leq X, x\leq tY]","['probability', 'probability-distributions', 'uniform-distribution']"
54,"If $A$ and $B$ are independent, what can we say about $P(X\mid A,B)$?","If  and  are independent, what can we say about ?","A B P(X\mid A,B)","Given two independent events A and B, what can we say about $P(X\mid A,B)$ ? Is the following correct ? $$P(X\mid A,B) = \frac{P(A,B\mid X)P(X)}{P(A,B)}\tag{Bayes}$$ $$P(X\mid A,B) = \frac{P(A\mid X)P(B\mid X)P(X)}{P(A)P(B)} \tag{Independence}$$ $$P(X\mid A,B) = \frac{\frac{P(X\mid A)P(A)}{P(X)}\frac{P(X\mid B)P(B)}{P(X)}P(X)}{P(A)P(B)} \tag{Bayes}$$ $$P(X\mid A,B) = \frac{P(X\mid A)P(X\mid B)}{P(X)}$$","Given two independent events A and B, what can we say about $P(X\mid A,B)$ ? Is the following correct ? $$P(X\mid A,B) = \frac{P(A,B\mid X)P(X)}{P(A,B)}\tag{Bayes}$$ $$P(X\mid A,B) = \frac{P(A\mid X)P(B\mid X)P(X)}{P(A)P(B)} \tag{Independence}$$ $$P(X\mid A,B) = \frac{\frac{P(X\mid A)P(A)}{P(X)}\frac{P(X\mid B)P(B)}{P(X)}P(X)}{P(A)P(B)} \tag{Bayes}$$ $$P(X\mid A,B) = \frac{P(X\mid A)P(X\mid B)}{P(X)}$$",,['probability']
55,Independent Events- Indicator Functions,Independent Events- Indicator Functions,,I can't seem to prove that two events are independent iff their indicator functions are independent discrete random variables. I was hoping to see a proof of this as I cant seem to find a proof in any of my notes nor online. Thanks,I can't seem to prove that two events are independent iff their indicator functions are independent discrete random variables. I was hoping to see a proof of this as I cant seem to find a proof in any of my notes nor online. Thanks,,['probability']
56,Integral of a Gaussian process has Gaussian Distribution,Integral of a Gaussian process has Gaussian Distribution,,"(1) How can we prove that the integral i.e. $\int_{a}^{b} X(t) dt$  (or any linear functional) of a Gaussian process $X(t)$ has Gaussian distribution? (2) And how can we find that distribution in the case of integral? Appreciate any insight, thanks. Edit: (per comment) $$\lim_{\Delta t \to 0}\sum_{a}^{b}X(t)\Delta t$$","(1) How can we prove that the integral i.e. $\int_{a}^{b} X(t) dt$  (or any linear functional) of a Gaussian process $X(t)$ has Gaussian distribution? (2) And how can we find that distribution in the case of integral? Appreciate any insight, thanks. Edit: (per comment) $$\lim_{\Delta t \to 0}\sum_{a}^{b}X(t)\Delta t$$",,"['probability', 'probability-theory']"
57,I.I.D what does this stand for?,I.I.D what does this stand for?,,"So almost everywhere in the book it's written ""random variables are IID"", what does this mean? I think it means independent and identically distributed but not sure. So by definition A and B R.V are independent means that: $p(A\cup B)=p(A)+p(B)$ right? But what does identically distributed mean? Does it mean that the variables have the exact same distribution? Thanks a lot!","So almost everywhere in the book it's written ""random variables are IID"", what does this mean? I think it means independent and identically distributed but not sure. So by definition A and B R.V are independent means that: $p(A\cup B)=p(A)+p(B)$ right? But what does identically distributed mean? Does it mean that the variables have the exact same distribution? Thanks a lot!",,"['probability', 'statistics', 'information-theory', 'independence']"
58,How to convert a histogram to a PDF,How to convert a histogram to a PDF,,"I know this may be an easy question, but due to lack of math knowledge I do not know the answer. Would you please explain to me with a simple example that how can I find PDF from a histogram. Thank you a lot.","I know this may be an easy question, but due to lack of math knowledge I do not know the answer. Would you please explain to me with a simple example that how can I find PDF from a histogram. Thank you a lot.",,"['probability', 'probability-theory', 'probability-distributions']"
59,"Find the distribution of X, EX, and VarX.","Find the distribution of X, EX, and VarX.",,"Suppose that the random variable $X$ is uniformly distributed symmetrically around zero, but in such a way that the parameter is uniform on $(0,1)$; that is, suppose that $$X\mid A=a\in U(-a,a) \text{ with } A\in U(0,1).$$ Find the distribution of $X$, $EX$, and $\operatorname{Var}X$. The answers in the book are $f_X(x)=-\frac{1}{2} \log|x|, \; -1<x<1; \; EX=0, \text{ and } \operatorname{Var}X=\frac{1}{9}$. Any help on how to work this type of problem would be greatly appreciated.","Suppose that the random variable $X$ is uniformly distributed symmetrically around zero, but in such a way that the parameter is uniform on $(0,1)$; that is, suppose that $$X\mid A=a\in U(-a,a) \text{ with } A\in U(0,1).$$ Find the distribution of $X$, $EX$, and $\operatorname{Var}X$. The answers in the book are $f_X(x)=-\frac{1}{2} \log|x|, \; -1<x<1; \; EX=0, \text{ and } \operatorname{Var}X=\frac{1}{9}$. Any help on how to work this type of problem would be greatly appreciated.",,"['probability', 'random-variables']"
60,What's the optimal strategy of this dice game?,What's the optimal strategy of this dice game?,,"I'm working on a dynamic programming problem. I want to find the optimal strategy and simulate it. The game's description: The player rolls two dice. If the numbers shown by the two dice are different then the player will add the sum given ($2+3$ for example) to the cumulative rewards he has. If the numbers shown by the two dice are equal then the player will loose all his reward. I started modeling the problem. The state of the system is as follow:  I chose one random number (300 for example) that may be the maximum reward for $N$ rounds game. The state is $V_k(S,D)$ where $S$ is the cumulative sum and $D$ is the sum of the two numbers shown on the two dice. If we suppose that the numbers of rounds is finite, what will be the optimal strategy in a simple form? In the case of infinite game what's the mean of the reward? Reference : http://people.brandeis.edu/~igusa/Math56aS08/Math56a_S08_notes041.pdf Thank you in advance guys :)","I'm working on a dynamic programming problem. I want to find the optimal strategy and simulate it. The game's description: The player rolls two dice. If the numbers shown by the two dice are different then the player will add the sum given ($2+3$ for example) to the cumulative rewards he has. If the numbers shown by the two dice are equal then the player will loose all his reward. I started modeling the problem. The state of the system is as follow:  I chose one random number (300 for example) that may be the maximum reward for $N$ rounds game. The state is $V_k(S,D)$ where $S$ is the cumulative sum and $D$ is the sum of the two numbers shown on the two dice. If we suppose that the numbers of rounds is finite, what will be the optimal strategy in a simple form? In the case of infinite game what's the mean of the reward? Reference : http://people.brandeis.edu/~igusa/Math56aS08/Math56a_S08_notes041.pdf Thank you in advance guys :)",,"['probability', 'dice', 'dynamic-programming']"
61,Probability of two integers' square sum divisible by $10$,Probability of two integers' square sum divisible by,10,"Given two random integers $a$, $b$ calculate probability of $a^2$ + $b^2$ is divisible by $10$. I've tried to simulate this process and got a result about $0.18$ (maybe incorrect), but have no idea why.","Given two random integers $a$, $b$ calculate probability of $a^2$ + $b^2$ is divisible by $10$. I've tried to simulate this process and got a result about $0.18$ (maybe incorrect), but have no idea why.",,['probability']
62,True Randomness and repetition,True Randomness and repetition,,"I do not have a degree in any field of mathematics; however I would like to get an input perhaps from those who do. I argued a point with one of my children the other day that if all of the arguments against a system that could generate true random numbers were moot (algorithms, entropy salt, etc), that a given system could in theory produce the same output every time as logically as any other number, because the odds of it ever arriving at that one are both exactly the same as every other number it could produce, and therefore just as likely. So on said system I could request a purely random number between 1 and 10 and it would consistently produce 5, not in error, so if asked to repeat this ten times  5,5,5,5,5,5,5,5,5,5 or 1,2,3,4,5,6,7,8,9,10 is just as likely as any other outcome. If this is not correct please correct me. If so, does this theory or law have a name?","I do not have a degree in any field of mathematics; however I would like to get an input perhaps from those who do. I argued a point with one of my children the other day that if all of the arguments against a system that could generate true random numbers were moot (algorithms, entropy salt, etc), that a given system could in theory produce the same output every time as logically as any other number, because the odds of it ever arriving at that one are both exactly the same as every other number it could produce, and therefore just as likely. So on said system I could request a purely random number between 1 and 10 and it would consistently produce 5, not in error, so if asked to repeat this ten times  5,5,5,5,5,5,5,5,5,5 or 1,2,3,4,5,6,7,8,9,10 is just as likely as any other outcome. If this is not correct please correct me. If so, does this theory or law have a name?",,['probability']
63,"Randomly picking increasing numbers in $\{ 1, \dots, n\}$",Randomly picking increasing numbers in,"\{ 1, \dots, n\}","Consider the following procedure (whose input is $N$) that picks increasing numbers from the set $\{ 1, \dots, N \}$ until it picks $N$: i := 0 K_i := 1 while K_i < N     pick a number K_{i+1} from the set { K_i, ..., N } uniformly at random     i = i + 1 How many times do we expect the loop to be executed? I expect $O(\log N)$ times myself: every round, we expect about half of the remaining numbers to be removed, which should result in $O(\log N)$ rounds. Unfortunately, I have no idea how to prove this. Markov's inequality trivially gives you that you will only throw away a constant fraction with constant probability, but if you wish this to happen $O(\log N)$ times in a row, your probability estimate goes to 0 as $N$ goes to infinity. Apparently (while I was randomly looking through books for help) the above problem is quite suited to a Markov chain formulation, except I am not familiar with them and have no idea how to use that to get the expected value I want. When the book told me I was supposed to evaluate determinants through Cramer's rule and provided an example which was not at all clear to me, I gave up. The above problem came up when analyzing a probable counterexample for an algorithm I have been working on. The actual probabilities involved are not uniformly random, but I think the above problem captures the essence of my problems, so an answer would probably help me enough to solve my own problem. If the number of rounds indeed increases as $N$ increases, then my (counter)example would indeed be a counterexample.","Consider the following procedure (whose input is $N$) that picks increasing numbers from the set $\{ 1, \dots, N \}$ until it picks $N$: i := 0 K_i := 1 while K_i < N     pick a number K_{i+1} from the set { K_i, ..., N } uniformly at random     i = i + 1 How many times do we expect the loop to be executed? I expect $O(\log N)$ times myself: every round, we expect about half of the remaining numbers to be removed, which should result in $O(\log N)$ rounds. Unfortunately, I have no idea how to prove this. Markov's inequality trivially gives you that you will only throw away a constant fraction with constant probability, but if you wish this to happen $O(\log N)$ times in a row, your probability estimate goes to 0 as $N$ goes to infinity. Apparently (while I was randomly looking through books for help) the above problem is quite suited to a Markov chain formulation, except I am not familiar with them and have no idea how to use that to get the expected value I want. When the book told me I was supposed to evaluate determinants through Cramer's rule and provided an example which was not at all clear to me, I gave up. The above problem came up when analyzing a probable counterexample for an algorithm I have been working on. The actual probabilities involved are not uniformly random, but I think the above problem captures the essence of my problems, so an answer would probably help me enough to solve my own problem. If the number of rounds indeed increases as $N$ increases, then my (counter)example would indeed be a counterexample.",,['probability']
64,Finding the probability that a student is a random guesser,Finding the probability that a student is a random guesser,,"I want to find the probability that my student is a random guesser. On a 360-item multiple choice test with four choices for each question, he got 28.5% or 103 of the questions correctly. Here is what I have so far. As everyone knows, the expected score is 25% or 90 items. Assuming that he is indeed a random guesser, I used the binomial distribution to get the variance np(1-p) = 360(.25)(.75) = 67.5; hence, a standard deviation of 8.22. Further assuming that random guessers are normally distributed, his z-score is (103-90)/8.22 = 1.58, making him an outlier. This places him in the top 6% of random guessers. This suggest that either (1) he is a very good guesser,  (2) he is a very lucky guesser, or (3) he is NOT a random guesser at all. Now I don't know what other concepts to use to find the probability that he is a random guesser. I don't even know if there is enough information; nor do I know whether all my computations and assumptions make any sense. I hope you can help. Cheers! PS: I only had a 3-unit statistics course way back in college. ""Dummifying"" your explanations would surely be appreciated. Cheers! :-) Edit: Thanks for all your help. So I guess it's really not that easy to get a good approximation on the said probability. Having said that, is there a relatively simple way to get even a very crude approximation of the answer? For instance, even before posting the question here, I actually considered the Bayesian probability mentioned above. To make things simple, I assumed that P(getting 103|guesser) is simply ${{360}\choose{103}}*.25^{103}*.75^{360-103}.$ And just to have a starting point, let's just say that 1 out of 5 students are random guessers, so P(guesser) is 0.2. What would be a reasonable initial estimate, albeit inaccurate, for P(getting 103)? Then maybe we can play around with the assumed values later to get a spectrum of possibilities.","I want to find the probability that my student is a random guesser. On a 360-item multiple choice test with four choices for each question, he got 28.5% or 103 of the questions correctly. Here is what I have so far. As everyone knows, the expected score is 25% or 90 items. Assuming that he is indeed a random guesser, I used the binomial distribution to get the variance np(1-p) = 360(.25)(.75) = 67.5; hence, a standard deviation of 8.22. Further assuming that random guessers are normally distributed, his z-score is (103-90)/8.22 = 1.58, making him an outlier. This places him in the top 6% of random guessers. This suggest that either (1) he is a very good guesser,  (2) he is a very lucky guesser, or (3) he is NOT a random guesser at all. Now I don't know what other concepts to use to find the probability that he is a random guesser. I don't even know if there is enough information; nor do I know whether all my computations and assumptions make any sense. I hope you can help. Cheers! PS: I only had a 3-unit statistics course way back in college. ""Dummifying"" your explanations would surely be appreciated. Cheers! :-) Edit: Thanks for all your help. So I guess it's really not that easy to get a good approximation on the said probability. Having said that, is there a relatively simple way to get even a very crude approximation of the answer? For instance, even before posting the question here, I actually considered the Bayesian probability mentioned above. To make things simple, I assumed that P(getting 103|guesser) is simply ${{360}\choose{103}}*.25^{103}*.75^{360-103}.$ And just to have a starting point, let's just say that 1 out of 5 students are random guessers, so P(guesser) is 0.2. What would be a reasonable initial estimate, albeit inaccurate, for P(getting 103)? Then maybe we can play around with the assumed values later to get a spectrum of possibilities.",,"['probability', 'random']"
65,Show that $X$ is independent of $\mathcal{G}$ given $E(X|\mathcal{G})$,Show that  is independent of  given,X \mathcal{G} E(X|\mathcal{G}),"Given that $\mathcal{G}$ is a sub-sigma field. $Z=\mathbb E(X|\mathcal{G})$, how can we show that $X$ is independent of $\mathcal{G}$ given $Z$? I am struggling about the interpretation of this result. By definition, we only need to show that given $A\in \sigma(X)$, $B\in \mathcal{G}$ that $\mathbb P(AB|\sigma(Z))=\mathbb P(A|\sigma(Z))\mathbb P(B|\sigma(Z))$ , but I don't know how to deal with it then..","Given that $\mathcal{G}$ is a sub-sigma field. $Z=\mathbb E(X|\mathcal{G})$, how can we show that $X$ is independent of $\mathcal{G}$ given $Z$? I am struggling about the interpretation of this result. By definition, we only need to show that given $A\in \sigma(X)$, $B\in \mathcal{G}$ that $\mathbb P(AB|\sigma(Z))=\mathbb P(A|\sigma(Z))\mathbb P(B|\sigma(Z))$ , but I don't know how to deal with it then..",,"['probability', 'probability-theory']"
66,Probability of cycle in random graph,Probability of cycle in random graph,,"I create a random directed graph, with N vertices and N edges, in the following process: A. Each vertex has a single outgoing edge. B. The target of that edge is selected at random from all N vertices (self loops are possible). What is the probability that a certain edge, selected at random, will be a part of a directed cycle? FYI: This problem comes from the following model of land trade: http://ccl.northwestern.edu/netlogo/models/community/land-random . The meaning of an edge ""being a part of a cycle"" is that the relevant land-plot will not be returned to its original owner. My simulations show that this probability is quite low - about 3.9% in average. I would like to understand why, so I am looking for a theoretic solution.","I create a random directed graph, with N vertices and N edges, in the following process: A. Each vertex has a single outgoing edge. B. The target of that edge is selected at random from all N vertices (self loops are possible). What is the probability that a certain edge, selected at random, will be a part of a directed cycle? FYI: This problem comes from the following model of land trade: http://ccl.northwestern.edu/netlogo/models/community/land-random . The meaning of an edge ""being a part of a cycle"" is that the relevant land-plot will not be returned to its original owner. My simulations show that this probability is quite low - about 3.9% in average. I would like to understand why, so I am looking for a theoretic solution.",,"['probability', 'graph-theory']"
67,Coupon Collector Problem with Batched Selections,Coupon Collector Problem with Batched Selections,,"I am trying to solve a variation on the coupon collector's problem . In this scenario, someone is selecting coupons at random with replacement from n different possible coupons. However, the person is not selecting coupons one at a time, but instead, in batches . Here's an example problem formulation: There are 100 distinct coupons. A person makes selections in 10-coupon batches at random (each coupon with replacement). What is the expected number of batches necessary to have selected 80 unique coupons? I have been able to determine the expected number of selections necessary to have selected k unique coupons when selecting one at a time (much like Henry's answer to a similar question ), but I'm a bit stumped as to how to go about solving it with this particular wrinkle. Any tips/guidance would be greatly appreciated.","I am trying to solve a variation on the coupon collector's problem . In this scenario, someone is selecting coupons at random with replacement from n different possible coupons. However, the person is not selecting coupons one at a time, but instead, in batches . Here's an example problem formulation: There are 100 distinct coupons. A person makes selections in 10-coupon batches at random (each coupon with replacement). What is the expected number of batches necessary to have selected 80 unique coupons? I have been able to determine the expected number of selections necessary to have selected k unique coupons when selecting one at a time (much like Henry's answer to a similar question ), but I'm a bit stumped as to how to go about solving it with this particular wrinkle. Any tips/guidance would be greatly appreciated.",,"['probability', 'combinatorics', 'discrete-mathematics', 'coupon-collector']"
68,What's the probability that there's at least one ball in every bin if 2n balls are placed into n bins?,What's the probability that there's at least one ball in every bin if 2n balls are placed into n bins?,,"I've been working on this all day long. Here's what I've done until now.The denominator is easy. It's $n^{2n}$. I compute the numerator as follows. All $n$ bins have at least one ball = $n$ bins must have one of the $2n$ balls each + the remaining $n$ balls are placed in any of the bins in any fashion. Now I solve the first part. $n$ balls can be chosen out of $2n$ balls in $\binom{2n}{n}$ ways, and they can be placed in $n!$ ways in the $n$ bins. Hence multiplying them yields $(n+1)(n+2)\cdots(2n)$. I have no clue how to proceed with the second part. Please help. Also please correct if I am wrong in the way I've proceeded so far.","I've been working on this all day long. Here's what I've done until now.The denominator is easy. It's $n^{2n}$. I compute the numerator as follows. All $n$ bins have at least one ball = $n$ bins must have one of the $2n$ balls each + the remaining $n$ balls are placed in any of the bins in any fashion. Now I solve the first part. $n$ balls can be chosen out of $2n$ balls in $\binom{2n}{n}$ ways, and they can be placed in $n!$ ways in the $n$ bins. Hence multiplying them yields $(n+1)(n+2)\cdots(2n)$. I have no clue how to proceed with the second part. Please help. Also please correct if I am wrong in the way I've proceeded so far.",,['probability']
69,"Probability for roots of quadratic equation to be real, with coefficients being dice rolls.","Probability for roots of quadratic equation to be real, with coefficients being dice rolls.",,"I really need help with this question. The coefficients $a,b,c$ of the quadratic equation $ax^2+bx+c=0$ are determined by throwing $3$ dice and reading off the value shown on the uppermost face of each die, so that the first die gives $a$ , the second $b$ and and third $c$ . Find the probabilities that the roots the equations are real, complex and equal. I was thinking about using the fundamental formula but i'm not sure how to go about doing it. Help would be greatly appreciated.","I really need help with this question. The coefficients of the quadratic equation are determined by throwing dice and reading off the value shown on the uppermost face of each die, so that the first die gives , the second and and third . Find the probabilities that the roots the equations are real, complex and equal. I was thinking about using the fundamental formula but i'm not sure how to go about doing it. Help would be greatly appreciated.","a,b,c ax^2+bx+c=0 3 a b c","['probability', 'statistics', 'quadratics', 'dice', 'faq']"
70,One vs multiple servers - problem,One vs multiple servers - problem,,"Consider the following problem: We have a simple queueing system with $\lambda%$ - probabilistic intensity of queries per some predefined time interval. Now, we can arrange the system as a single high-end server ($M/M/1$, which can handle the queries with the intensity of $2\mu$) or as two low-end servers ($M/M/2$, each server working with intensity of $\mu$). So, the question is - which variant is better in terms of overall performance? I suspect that it's the first one, but, unfortunately, my knowledge of queuing / probability theory isn't enough. Thank you.","Consider the following problem: We have a simple queueing system with $\lambda%$ - probabilistic intensity of queries per some predefined time interval. Now, we can arrange the system as a single high-end server ($M/M/1$, which can handle the queries with the intensity of $2\mu$) or as two low-end servers ($M/M/2$, each server working with intensity of $\mu$). So, the question is - which variant is better in terms of overall performance? I suspect that it's the first one, but, unfortunately, my knowledge of queuing / probability theory isn't enough. Thank you.",,"['probability', 'probability-theory', 'optimization', 'queueing-theory']"
71,Distribution of the normal cdf,Distribution of the normal cdf,,"I am wondering what is the probability density function for the normal cdf $\Phi (aX+b)$, where $\phi$ is the usual standard normal cumulative distribution function I want to calculate $\mathbb{E}[\Phi(aX+b)]$ but i am stuck on how to get the distribution. thank you =] note: X is normally distributed","I am wondering what is the probability density function for the normal cdf $\Phi (aX+b)$, where $\phi$ is the usual standard normal cumulative distribution function I want to calculate $\mathbb{E}[\Phi(aX+b)]$ but i am stuck on how to get the distribution. thank you =] note: X is normally distributed",,"['probability', 'probability-distributions', 'normal-distribution', 'expected-value']"
72,"Sorting through ""algebra of random variables,"" vs. ""probability space,"" etc","Sorting through ""algebra of random variables,"" vs. ""probability space,"" etc",,"I have been reading through Wikipedia pages, and I'm still really confused.  What is the difference between "" algebra of random variables "" and "" probability space. ""?  Are they just different words for describing the same thing, or are there fundamental differences? At the bottom of the Probability Space page, it says that a prodability measure is a probability density of a random variable.  However, near the top, it says, ""The prominent Soviet mathematician Andrey Kolmogorov introduced the notion of probability space, together with other axioms of probability, in the 1930s. Nowadays alternative approaches for axiomatization of probability theory exist; see “Algebra of random variables”, for example."" Which suggests two me that they are two competing approaches/theories. Can anyone explain to me how these terms and ideas fit together -- What are the primary conceptual differences between the two and the advantages/disadvantages of each? I know that this question probably won't make sense to someone who actually understands what the terms really mean -- so please try to imagine a beginner who is just trying to make sense of the field, and understand why there are different terms that seem to apply to the same concepts.","I have been reading through Wikipedia pages, and I'm still really confused.  What is the difference between "" algebra of random variables "" and "" probability space. ""?  Are they just different words for describing the same thing, or are there fundamental differences? At the bottom of the Probability Space page, it says that a prodability measure is a probability density of a random variable.  However, near the top, it says, ""The prominent Soviet mathematician Andrey Kolmogorov introduced the notion of probability space, together with other axioms of probability, in the 1930s. Nowadays alternative approaches for axiomatization of probability theory exist; see “Algebra of random variables”, for example."" Which suggests two me that they are two competing approaches/theories. Can anyone explain to me how these terms and ideas fit together -- What are the primary conceptual differences between the two and the advantages/disadvantages of each? I know that this question probably won't make sense to someone who actually understands what the terms really mean -- so please try to imagine a beginner who is just trying to make sense of the field, and understand why there are different terms that seem to apply to the same concepts.",,"['probability', 'terminology', 'intuition']"
73,Definition of random,Definition of random,,"Suppose that you has to guess given a set of numbers If they are random. The mathematical expectation Is there a definition of randomness that allow this prove/test? Is even possible? if so: How many value would be enough ? Example: If numbers come from a coin experiment, results could be coded as 0 or 1, 000100010110100011..... Then how many ""bits"" are enough to ""test"" variable randomness? According to the law of large numbers, the average of the results (adding the results and dividing by the number of trials) should become closer and closer to the expected value as more trials are performed. But if we don't know where those numbers come from then we don't know what to expect! What are the law of large numbers hypothesis? Does the definition of random cointain a reference to average and to the expected value? It is deeply confusing to me, thanks in advance for any information","Suppose that you has to guess given a set of numbers If they are random. The mathematical expectation Is there a definition of randomness that allow this prove/test? Is even possible? if so: How many value would be enough ? Example: If numbers come from a coin experiment, results could be coded as 0 or 1, 000100010110100011..... Then how many ""bits"" are enough to ""test"" variable randomness? According to the law of large numbers, the average of the results (adding the results and dividing by the number of trials) should become closer and closer to the expected value as more trials are performed. But if we don't know where those numbers come from then we don't know what to expect! What are the law of large numbers hypothesis? Does the definition of random cointain a reference to average and to the expected value? It is deeply confusing to me, thanks in advance for any information",,"['probability', 'probability-theory', 'probability-distributions', 'random', 'average']"
74,Independence of sums of gaussian random variables,Independence of sums of gaussian random variables,,"Say, I have independent gaussian random variables $t1, t2, t3, t4, t5$ and I have two new random variables $S = t1 + t2 - t3$ and $K = t3 + t4$. Are $S$ and $K$ independent or is there any theorem about independece of random variables formed by sum of independent gaussians ?","Say, I have independent gaussian random variables $t1, t2, t3, t4, t5$ and I have two new random variables $S = t1 + t2 - t3$ and $K = t3 + t4$. Are $S$ and $K$ independent or is there any theorem about independece of random variables formed by sum of independent gaussians ?",,['probability']
75,Do asymmetric random walks also return to the origin infinitely?,Do asymmetric random walks also return to the origin infinitely?,,Do asymmetric random walks also return to the origin infinitely?,Do asymmetric random walks also return to the origin infinitely?,,"['probability', 'stochastic-processes']"
76,probability question related to pattern in coin tossing [closed],probability question related to pattern in coin tossing [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question If I toss a fair coin $n$ times, calculate the probability that no pattern HHTHTHH occurs.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question If I toss a fair coin $n$ times, calculate the probability that no pattern HHTHTHH occurs.",,['probability']
77,A few questions regarding random points on a disk.,A few questions regarding random points on a disk.,,"Today a few questions popped up in my head, and I'm curious to know the answers. a). Let $C$ be a disk of radius $R$ centered at the origin. Given a point on the disk $P = (x,y)$ , what is the expected distance between $P$ and $P'$ , where $P'$ is a point chosen uniformly at random somewhere on the disk. b). Let $C,R,P $ and $P'$ be as above. What is the probability that the distance between $P$ and $P'$ is $\geq r$ , with $r\in [0,2R]$ . Help with either would be greatly appreciated, thanks in advance!","Today a few questions popped up in my head, and I'm curious to know the answers. a). Let be a disk of radius centered at the origin. Given a point on the disk , what is the expected distance between and , where is a point chosen uniformly at random somewhere on the disk. b). Let and be as above. What is the probability that the distance between and is , with . Help with either would be greatly appreciated, thanks in advance!","C R P = (x,y) P P' P' C,R,P  P' P P' \geq r r\in [0,2R]","['probability', 'statistics', 'probability-distributions']"
78,What is the probability that the triangle formed by three uniformly random points on the sphere contains its circumcentre?,What is the probability that the triangle formed by three uniformly random points on the sphere contains its circumcentre?,,"In answering Conjecture: If $A,B,C$ are random points on a sphere, then $E\left(\frac{\text{Area}_{\triangle ABC}}{\text{Area}_{\bigcirc ABC}}\right)=\frac14$. it turned out that if you choose three points uniformly randomly on the sphere, the density distribution of their angles on the circle they form is proportional to the area of the triangle they form. So these points tend to be spaced further apart on the circle than points randomly uniformly chosen on the circle. (That makes sense, since on the sphere the probability distribution of the distance between two points vanishes at distance $0$ .) Since that seemed like a nice result, I wanted to do something else with it. A question often asked about random points on a circle is about the probability that the triangle they form contains the centre of the circle. If the points are uniformly distributed on the circle, that probability is $\frac14$ (see e.g. Probability that n points on a circle are in one semicircle ). If the points are spaced further apart, this probability should be higher. So what is it for points uniformly randomly chosen on a sphere? I’m posting this as a self-answered question , but I merely worked out the integrals and would be happy to see a more elegant solution that explains the simplicity of the answer with a symmetry argument.","In answering Conjecture: If $A,B,C$ are random points on a sphere, then $E\left(\frac{\text{Area}_{\triangle ABC}}{\text{Area}_{\bigcirc ABC}}\right)=\frac14$. it turned out that if you choose three points uniformly randomly on the sphere, the density distribution of their angles on the circle they form is proportional to the area of the triangle they form. So these points tend to be spaced further apart on the circle than points randomly uniformly chosen on the circle. (That makes sense, since on the sphere the probability distribution of the distance between two points vanishes at distance .) Since that seemed like a nice result, I wanted to do something else with it. A question often asked about random points on a circle is about the probability that the triangle they form contains the centre of the circle. If the points are uniformly distributed on the circle, that probability is (see e.g. Probability that n points on a circle are in one semicircle ). If the points are spaced further apart, this probability should be higher. So what is it for points uniformly randomly chosen on a sphere? I’m posting this as a self-answered question , but I merely worked out the integrals and would be happy to see a more elegant solution that explains the simplicity of the answer with a symmetry argument.",0 \frac14,"['probability', 'geometry', 'triangles', 'spheres', 'geometric-probability']"
79,Fair price: receive sum of the last decreasing sequence,Fair price: receive sum of the last decreasing sequence,,"This is a Jane Street Interview question. What is the fair price of a game in which you shuffle nine cards labeled 1 through 9 then keep choosing whether to open the next card or stop, given that you will receive the sum of the last decreasing sequence? So far, I have solved for the expected value of having $2$ cards which is $\frac12 \times 3$ and the expected value of having $3$ cards, which is $2 \times \frac23$ . My question is, how do we even determine the expected value of the decreasing sequence in the first place. I cannot find anything online about this. After solving that, I believe we can simply compare expected values to determine optimal stopping.","This is a Jane Street Interview question. What is the fair price of a game in which you shuffle nine cards labeled 1 through 9 then keep choosing whether to open the next card or stop, given that you will receive the sum of the last decreasing sequence? So far, I have solved for the expected value of having cards which is and the expected value of having cards, which is . My question is, how do we even determine the expected value of the decreasing sequence in the first place. I cannot find anything online about this. After solving that, I believe we can simply compare expected values to determine optimal stopping.",2 \frac12 \times 3 3 2 \times \frac23,"['probability', 'sequences-and-series', 'expected-value', 'problem-solving', 'game-theory']"
80,Conditional Probability With a Madman,Conditional Probability With a Madman,,"There are three six-chambered revolvers. The first has no bullets; the second has one bullet; and the third has two bullets in consecutive chambers. The cylinder advances automatically as the trigger is pulled. A madman grabs a revolver at random, aims it at his own head, pulls the trigger t times, and no shot is fired. He then aims at your head and pulls the trigger once. What is the probability that you are shot given t? The provided answers are $[0.167 (t = 0), 0.133 (t = 1), 0.154 (t = 2), 0.182 (t = 3), 0.222 (t = 4), 0.143 (t = 5), 0 (t ≥ 6)]$ I can't seem to match it. Can someone tell me where I'm wrong? My attempt: $\Pr(S|t = 0) = \dfrac{1}{3}[0 + 1/6 + 2/6] = 0.167$ $\Pr(S|t = 1) = \dfrac{1}{3}[0 + (5/6)(1/6) + (4/6)(2/6)] = 0.144..$ $\Pr(S|t = 2) = \dfrac{1}{3}[0 + (5/6)(4/5)(1/4) + (4/6)(3/5)(2/4)] = 0.122..$ I stopped here cause my answers weren't matching.","There are three six-chambered revolvers. The first has no bullets; the second has one bullet; and the third has two bullets in consecutive chambers. The cylinder advances automatically as the trigger is pulled. A madman grabs a revolver at random, aims it at his own head, pulls the trigger t times, and no shot is fired. He then aims at your head and pulls the trigger once. What is the probability that you are shot given t? The provided answers are I can't seem to match it. Can someone tell me where I'm wrong? My attempt: I stopped here cause my answers weren't matching.","[0.167 (t = 0), 0.133 (t = 1), 0.154 (t = 2), 0.182 (t = 3), 0.222 (t = 4), 0.143 (t = 5), 0 (t ≥ 6)] \Pr(S|t = 0) = \dfrac{1}{3}[0 + 1/6 + 2/6] = 0.167 \Pr(S|t = 1) = \dfrac{1}{3}[0 + (5/6)(1/6) + (4/6)(2/6)] = 0.144.. \Pr(S|t = 2) = \dfrac{1}{3}[0 + (5/6)(4/5)(1/4) + (4/6)(3/5)(2/4)] = 0.122..","['probability', 'conditional-probability']"
81,Splitting six friends into two pairs and two singles,Splitting six friends into two pairs and two singles,,"Six friends agree to meet at the hotel Acropolis in Athens. It happens that there are four hotels with the same name. Each of the six friends picks one hotel at random and goes there. What is the probability that two friends end up alone and the rest four in pairs? My solution: Since we have 6 friends and 4 possible choices for each the sample space consists of $4^6$ possible events. There are $\binom{6}{2}$ choices for the first pair and $4$ hotel choices. There are $\binom{4}{2}$ choices for the second pair and $3$ hotel choices. There $\binom{2}{1}$ choices for the first single person and $2$ hotel choices. The last person has only one hotel choice. Since we have four groups and we do not care about order, we have to divide our results by $4!$ . Putting it all together: $$ P(A) = \frac{\frac{4\binom{6}{2}3\binom{4}{2}2\binom{2}{1}1}{4!}}{4^6} \approx 0.0439 $$ The author finds $$ P(A) = \frac{12\binom{6}{2}\binom{4}{2}}{4^6} \approx 0.2637 $$ Who is correct?","Six friends agree to meet at the hotel Acropolis in Athens. It happens that there are four hotels with the same name. Each of the six friends picks one hotel at random and goes there. What is the probability that two friends end up alone and the rest four in pairs? My solution: Since we have 6 friends and 4 possible choices for each the sample space consists of possible events. There are choices for the first pair and hotel choices. There are choices for the second pair and hotel choices. There choices for the first single person and hotel choices. The last person has only one hotel choice. Since we have four groups and we do not care about order, we have to divide our results by . Putting it all together: The author finds Who is correct?","4^6 \binom{6}{2} 4 \binom{4}{2} 3 \binom{2}{1} 2 4! 
P(A) = \frac{\frac{4\binom{6}{2}3\binom{4}{2}2\binom{2}{1}1}{4!}}{4^6} \approx 0.0439
 
P(A) = \frac{12\binom{6}{2}\binom{4}{2}}{4^6} \approx 0.2637
","['probability', 'combinatorics']"
82,Writing proofs and solutions completely but concisely [closed],Writing proofs and solutions completely but concisely [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 6 months ago . Improve this question I have a university lecturer that puts a lot of emphasis on the writing quality of an answer, not just if its correct. He wants our answers to be 5 things, Clear, Complete, Concise, Coherent and Correct. He says he doesn't believe in perfect answers so can be very nit-picky over our solutions, but it also means he can be contradictory. For example in one of my solutions he said i had been repetitive but firstly, the repeated line (which was something like, ""by the law of total variance"") was there to help the narrative of the answer - which he puts so much emphasis on - and it was repeated from part 1 of a question after quite a few lines of integration. But secondly and more importantly, in his very own solution, he had the exact same repetition. And he said my answer was very good and he was being really nitpicky but that i could at some point write more detail, like write ""the pdf of X is f(x)=..."" rather than just go straight into ""f(x)=..."" So my question is how do you strike a balance between explaining enough and becoming too laborious? Also what are some good connecting words in proofs and 'show me' questions and when do you use which? Because i just tend to stick in 'and', 'because', 'so' 'thus' etc, when prehaps sometimes it isn't strictly true (but does get the point across) An example of such a question: Let X~Gamma( $\alpha,\beta$ ) where $\beta$ is a rate parameter. Find the MGF of X and use this to show that $\Bbb{E}(X)=\frac{\alpha}{\beta}$ and $var(X)=\frac{\alpha}{\beta^2}$ Let X~Gamma( $\alpha , \beta$ ) Then the PDF of X is: $$f(x)=\frac{\beta^\alpha}{\Gamma(\alpha)}x^{(\alpha-1)}e^{-\beta x}dx $$ ,for $x>0$ and 0 otherwise, where $$\Gamma(\alpha)=\int_0^\inf t^{\alpha-1}e^{-t}dt$$ $$M_X(t)=\mathbb{E}(e^{tX})=\int_0^\inf e^{tx}f(x)dx$$ $$=\frac{\beta^\alpha}{\Gamma(\alpha)}\int_0^\inf e^{tx}x^{\alpha-1}e^{-\beta x}dx$$ $$=\frac{\beta^\alpha}{\Gamma(\alpha)}int_0^\inf x^{\alpha-1}e^{-(\beta-t) x}dx$$ Let $$u=(\beta-t)x$$ $$\iff x=\frac{u}{\beta-t}$$ $$\implies dx=(\beta-t)du$$ So $$M_X(t)=\frac{\beta^\alpha}{\Gamma(\alpha)}\int_0^\inf (\frac{u}{\beta-t})^{\alpha-1}e^-u(\beta-t)du$$ $$=\frac{\beta^\alpha}{\Gamma(\alpha)}(\frac{1}{\beta-t})^{\alpha}\int_0^\inf u^{\alpha-1}e^{-u}du$$ $$\frac{\beta^\alpha}{(\beta-t)^\alpha}$$ To show that $\Bbb{E}(X)=\frac{\alpha}{\beta}$ and $var(X)=\frac{\alpha}{\beta^2}$ : Using differentiation gives us: $$M'(t)=\frac{\alpha\beta^\alpha}{(\beta-t)^{\alpha+1}}$$ and $$ M''(t)=\frac{\alpha(\alpha+1)\beta^\alpha}{(\beta-t)^{\alpha+21}}$$ It follows that $$\Bbb{E}(X)=M'(0)=\frac{\alpha\beta^\alpha}{\beta^{\alpha+1}}=\frac{\alpha}{\beta}$$ and $$\Bbb{E}(X^2)=M''(0)=\frac{\alpha(\alpha+1)\beta^\alpha}{\beta^{\alpha+21}}=\frac{\alpha(\alpha+1)}{\beta^2}$$ Hence $$ var(X)=\Bbb{E}(X^2)-\Bbb{E}(X)^2$$ $$=\frac{\alpha(\alpha+1)}{\beta^2}-\frac{\alpha^2}{\beta^2}$$ $$=\frac{\alpha}{\beta^2}$$ as required I know i need connecting words before i calculate the M(t) but i have no idea what to put, plus I'm not sure if where I've put ""it follows that"" is strictly true, also i feel like where i've used ""So"" there might be a better word to use but i can't think what","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 6 months ago . Improve this question I have a university lecturer that puts a lot of emphasis on the writing quality of an answer, not just if its correct. He wants our answers to be 5 things, Clear, Complete, Concise, Coherent and Correct. He says he doesn't believe in perfect answers so can be very nit-picky over our solutions, but it also means he can be contradictory. For example in one of my solutions he said i had been repetitive but firstly, the repeated line (which was something like, ""by the law of total variance"") was there to help the narrative of the answer - which he puts so much emphasis on - and it was repeated from part 1 of a question after quite a few lines of integration. But secondly and more importantly, in his very own solution, he had the exact same repetition. And he said my answer was very good and he was being really nitpicky but that i could at some point write more detail, like write ""the pdf of X is f(x)=..."" rather than just go straight into ""f(x)=..."" So my question is how do you strike a balance between explaining enough and becoming too laborious? Also what are some good connecting words in proofs and 'show me' questions and when do you use which? Because i just tend to stick in 'and', 'because', 'so' 'thus' etc, when prehaps sometimes it isn't strictly true (but does get the point across) An example of such a question: Let X~Gamma( ) where is a rate parameter. Find the MGF of X and use this to show that and Let X~Gamma( ) Then the PDF of X is: ,for and 0 otherwise, where Let So To show that and : Using differentiation gives us: and It follows that and Hence as required I know i need connecting words before i calculate the M(t) but i have no idea what to put, plus I'm not sure if where I've put ""it follows that"" is strictly true, also i feel like where i've used ""So"" there might be a better word to use but i can't think what","\alpha,\beta \beta \Bbb{E}(X)=\frac{\alpha}{\beta} var(X)=\frac{\alpha}{\beta^2} \alpha , \beta f(x)=\frac{\beta^\alpha}{\Gamma(\alpha)}x^{(\alpha-1)}e^{-\beta x}dx  x>0 \Gamma(\alpha)=\int_0^\inf t^{\alpha-1}e^{-t}dt M_X(t)=\mathbb{E}(e^{tX})=\int_0^\inf e^{tx}f(x)dx =\frac{\beta^\alpha}{\Gamma(\alpha)}\int_0^\inf e^{tx}x^{\alpha-1}e^{-\beta x}dx =\frac{\beta^\alpha}{\Gamma(\alpha)}int_0^\inf x^{\alpha-1}e^{-(\beta-t) x}dx u=(\beta-t)x \iff x=\frac{u}{\beta-t} \implies dx=(\beta-t)du M_X(t)=\frac{\beta^\alpha}{\Gamma(\alpha)}\int_0^\inf (\frac{u}{\beta-t})^{\alpha-1}e^-u(\beta-t)du =\frac{\beta^\alpha}{\Gamma(\alpha)}(\frac{1}{\beta-t})^{\alpha}\int_0^\inf u^{\alpha-1}e^{-u}du \frac{\beta^\alpha}{(\beta-t)^\alpha} \Bbb{E}(X)=\frac{\alpha}{\beta} var(X)=\frac{\alpha}{\beta^2} M'(t)=\frac{\alpha\beta^\alpha}{(\beta-t)^{\alpha+1}}  M''(t)=\frac{\alpha(\alpha+1)\beta^\alpha}{(\beta-t)^{\alpha+21}} \Bbb{E}(X)=M'(0)=\frac{\alpha\beta^\alpha}{\beta^{\alpha+1}}=\frac{\alpha}{\beta} \Bbb{E}(X^2)=M''(0)=\frac{\alpha(\alpha+1)\beta^\alpha}{\beta^{\alpha+21}}=\frac{\alpha(\alpha+1)}{\beta^2}  var(X)=\Bbb{E}(X^2)-\Bbb{E}(X)^2 =\frac{\alpha(\alpha+1)}{\beta^2}-\frac{\alpha^2}{\beta^2} =\frac{\alpha}{\beta^2}","['probability', 'proof-writing', 'soft-question']"
83,"We construct 4-digit numbers, which are chosen from any of the following seven digits: 0, 1, 3, 5, 7, 8, 9.","We construct 4-digit numbers, which are chosen from any of the following seven digits: 0, 1, 3, 5, 7, 8, 9.",,"So basically, we construct 4-digit numbers, which are chosen from any of the following seven digits: 0, 1, 3, 5, 7, 8, 9. What is the probability of a number having no digit ‘7’ and containing two or more identical digits? 4 digit numbers that starts with 0s count too, like 0177 For the moment I have the number of 4 digits numbers that uses these 7 digits : $7^4 = 2401$ . Then I have the number of 4 digits numbers with at least 2 identical numbers which is : $2401 - 840 = 1561$ the 840 comes from the $P(n,r) = \frac{n!}{(n-r)!}$ Then I have the number of 4 digit numbers without the digit 7 which is $6^4 = 1296$ But then I don't really know where to start to find the probability they ask.","So basically, we construct 4-digit numbers, which are chosen from any of the following seven digits: 0, 1, 3, 5, 7, 8, 9. What is the probability of a number having no digit ‘7’ and containing two or more identical digits? 4 digit numbers that starts with 0s count too, like 0177 For the moment I have the number of 4 digits numbers that uses these 7 digits : . Then I have the number of 4 digits numbers with at least 2 identical numbers which is : the 840 comes from the Then I have the number of 4 digit numbers without the digit 7 which is But then I don't really know where to start to find the probability they ask.","7^4 = 2401 2401 - 840 = 1561 P(n,r) = \frac{n!}{(n-r)!} 6^4 = 1296","['probability', 'combinatorics', 'permutations']"
84,Prove that the characteristic function of a random variable is uniformly continuous.,Prove that the characteristic function of a random variable is uniformly continuous.,,"The definition of the characteristic function of a random variable $X$ is $$\varphi(\lambda)=E[e^{i\lambda X}]=\int_{-\infty}^\infty e^{i\lambda x}\,dP(x),$$ where $dP$ is the distribution of the random variable. Prove that the characteristic function of a random variable is uniformly continuous. My attempt of the proof is: $$|\varphi(\lambda) -\varphi(\lambda') | = |\int_{-\infty}^\infty (e^{i\lambda x} -e^{i\lambda' x} ) dP(x)|  $$ $$\leq    |\int_{-\infty}^\infty e^{i\lambda' x} (e^{i(\lambda - \lambda') x}-1)  dP(x)|  $$ $$\leq  \int_{-\infty}^\infty   |e^{i\lambda' x}|   |e^{i(\lambda - \lambda') x}-1|    dP(x)      $$ Then use the fact that the absolute value of a complex exponential is 1. $$=  \int_{-\infty}^\infty      |e^{i(\lambda - \lambda') x}-1|    dP(x)      $$ Then use the inequality that the inequality $|e^{ihx}-1|\le |hx|$ . $$\leq  \int_{-\infty}^\infty      |(\lambda - \lambda') x|    dP(x)      $$ I don't know how to do next. The textbook said I need to use Lebesgue Dominated Convergence Theorem. I don't know how to use that. I think I am stuck that how to prove one function is uniformly continuous. I only know this definition of uniformly continuous: Given $\epsilon > 0$ , we want to find $\delta > 0$ such that $$ |f(x) - f(y)| < \epsilon \quad  \text{whenever} \quad |x-y| < \delta $$ and $\delta$ is independent of $x$ and $y$ .","The definition of the characteristic function of a random variable is where is the distribution of the random variable. Prove that the characteristic function of a random variable is uniformly continuous. My attempt of the proof is: Then use the fact that the absolute value of a complex exponential is 1. Then use the inequality that the inequality . I don't know how to do next. The textbook said I need to use Lebesgue Dominated Convergence Theorem. I don't know how to use that. I think I am stuck that how to prove one function is uniformly continuous. I only know this definition of uniformly continuous: Given , we want to find such that and is independent of and .","X \varphi(\lambda)=E[e^{i\lambda X}]=\int_{-\infty}^\infty e^{i\lambda x}\,dP(x), dP |\varphi(\lambda) -\varphi(\lambda') | = |\int_{-\infty}^\infty (e^{i\lambda x} -e^{i\lambda' x} ) dP(x)|   \leq    |\int_{-\infty}^\infty e^{i\lambda' x} (e^{i(\lambda - \lambda') x}-1)  dP(x)|   \leq  \int_{-\infty}^\infty   |e^{i\lambda' x}|   |e^{i(\lambda - \lambda') x}-1|    dP(x)       =  \int_{-\infty}^\infty      |e^{i(\lambda - \lambda') x}-1|    dP(x)       |e^{ihx}-1|\le |hx| \leq  \int_{-\infty}^\infty      |(\lambda - \lambda') x|    dP(x)       \epsilon > 0 \delta > 0 
|f(x) - f(y)| < \epsilon \quad  \text{whenever} \quad |x-y| < \delta
 \delta x y","['real-analysis', 'probability', 'probability-theory']"
85,Optimal strategy in a coin game has unexpected symmetry?,Optimal strategy in a coin game has unexpected symmetry?,,"The game: I am going to toss a fair coin and you are trying to determine if I tossed a Head or Tail. You do this using the rule I follow when I toss my coin: I have before me $2$ $\color{red}{\text{red}}$ boxes each with a $\color{red}{\text{red}}$ marble inside them, I also have $2$ $\color{blue}{\text{blue}}$ boxes each with a $\color{blue}{\text{blue}}$ marble inside of them. Finally, there are two empty white boxes. If I toss a Head I must move a $\color{red}{\text{red}}$ marble from a $\color{red}{\text{red}}$ box into an empty white box. Similarly, if I toss a Tail I must move a $\color{blue}{\text{blue}}$ marble from a $\color{blue}{\text{blue}}$ box into an empty white box. To aid you in your guess of my toss, once I have moved a marble, you are then permitted to open and examine the contents of a single $\color{red}{\text{red}}$ , $\color{blue}{\text{blue}}$ or white box. The strategy: In this primitive instance of two boxes of each color, we are actually indifferent between what box we peek into. We have 75% probability of correctly guessing the toss. Consider now we have $R$ , $\color{red}{\text{red}}$ boxes, $B$ $\color{blue}{\text{blue}}$ boxes and $W$ white boxes. The optimal strategy is to peak into min{ $R,B,W$ }. I was curious as to why we have symmetry between the colored and white boxes and simply follow the heuristic of the minimum number of boxes, is there a nice transformation of the game that makes this symmetry more obvious? Thanks","The game: I am going to toss a fair coin and you are trying to determine if I tossed a Head or Tail. You do this using the rule I follow when I toss my coin: I have before me boxes each with a marble inside them, I also have boxes each with a marble inside of them. Finally, there are two empty white boxes. If I toss a Head I must move a marble from a box into an empty white box. Similarly, if I toss a Tail I must move a marble from a box into an empty white box. To aid you in your guess of my toss, once I have moved a marble, you are then permitted to open and examine the contents of a single , or white box. The strategy: In this primitive instance of two boxes of each color, we are actually indifferent between what box we peek into. We have 75% probability of correctly guessing the toss. Consider now we have , boxes, boxes and white boxes. The optimal strategy is to peak into min{ }. I was curious as to why we have symmetry between the colored and white boxes and simply follow the heuristic of the minimum number of boxes, is there a nice transformation of the game that makes this symmetry more obvious? Thanks","2 \color{red}{\text{red}} \color{red}{\text{red}} 2 \color{blue}{\text{blue}} \color{blue}{\text{blue}} \color{red}{\text{red}} \color{red}{\text{red}} \color{blue}{\text{blue}} \color{blue}{\text{blue}} \color{red}{\text{red}} \color{blue}{\text{blue}} R \color{red}{\text{red}} B \color{blue}{\text{blue}} W R,B,W","['probability', 'statistics', 'game-theory']"
86,"Why is the probability of drawing two cards, one of a specific suit and one of a specific rank equal to the probability of drawing a specific card?","Why is the probability of drawing two cards, one of a specific suit and one of a specific rank equal to the probability of drawing a specific card?",,(Suppose the specific suit is Diamond and the specific rank is Queen.) Suppose we draw two cards without replacement. We are asked to calculate the probability that the first one is a Queen and the second one is a Diamond. To calculate this there are two cases: First card is Queen of Diamond. First card is a Queen but not a Diamond. In the first case the probability of drawing first card Queen of Diamond then second card a Diamond is $$\frac{1}{52} \cdot \frac{12}{51}.$$ In the second case the probability of drawing first card a Queen but not a Diamond then second card a Diamond is $$\frac{3}{52} \cdot \frac{13}{51}.$$ Add them up and we get $$\frac{1}{52}.$$ This is equal to drawing just one card of the Queen of Diamond. Why is that?,(Suppose the specific suit is Diamond and the specific rank is Queen.) Suppose we draw two cards without replacement. We are asked to calculate the probability that the first one is a Queen and the second one is a Diamond. To calculate this there are two cases: First card is Queen of Diamond. First card is a Queen but not a Diamond. In the first case the probability of drawing first card Queen of Diamond then second card a Diamond is In the second case the probability of drawing first card a Queen but not a Diamond then second card a Diamond is Add them up and we get This is equal to drawing just one card of the Queen of Diamond. Why is that?,\frac{1}{52} \cdot \frac{12}{51}. \frac{3}{52} \cdot \frac{13}{51}. \frac{1}{52}.,"['probability', 'card-games']"
87,"How to show that $\frac{1}{X_n}\to 1/c \, \mbox{ in probability} $?",How to show that ?,"\frac{1}{X_n}\to 1/c \, \mbox{ in probability} ","If a random variable $X_n$ converges to a non-zero constant $c$ in probability, then $ \dfrac{1}{X_n}\to \dfrac{1}{c}$ in probability.  I try to prove this statement by definition. Here we want to prove that for every $\epsilon>0$ , as $n\to\infty$ , $P \left( \bigg \lvert \dfrac{1}{X_n} - \dfrac{1}{c} \bigg \rvert \ge \epsilon \right) \to 0$ . Note that $\bigg \lvert \dfrac{1}{X_n} - \dfrac{1}{c} \bigg \rvert = \dfrac{\lvert c - X_n \rvert}{\lvert c X_n \rvert}$ . Then $\displaystyle P \left( \bigg \lvert \frac{1}{X_n} - \frac{1}{c} \bigg \rvert \ge \epsilon \right) = P \left( \frac{\lvert c - X_n \rvert}{\lvert c X_n \rvert} \ge \epsilon \right) = P( \lvert c - X_n \rvert \ge \lvert c X_n \rvert \epsilon)$ . But it seems that we need $E \lvert X \rvert < \infty$ ?","If a random variable converges to a non-zero constant in probability, then in probability.  I try to prove this statement by definition. Here we want to prove that for every , as , . Note that . Then . But it seems that we need ?","X_n c 
\dfrac{1}{X_n}\to \dfrac{1}{c} \epsilon>0 n\to\infty P \left( \bigg \lvert \dfrac{1}{X_n} - \dfrac{1}{c} \bigg \rvert \ge \epsilon \right) \to 0 \bigg \lvert \dfrac{1}{X_n} - \dfrac{1}{c} \bigg \rvert = \dfrac{\lvert c - X_n \rvert}{\lvert c X_n \rvert} \displaystyle P \left( \bigg \lvert \frac{1}{X_n} - \frac{1}{c} \bigg \rvert \ge \epsilon \right) = P \left( \frac{\lvert c - X_n \rvert}{\lvert c X_n \rvert} \ge \epsilon \right) = P( \lvert c - X_n \rvert \ge \lvert c X_n \rvert \epsilon) E \lvert X \rvert < \infty","['probability', 'probability-limit-theorems']"
88,Convergence in probability implies convergence in quantile of inverse quantile.,Convergence in probability implies convergence in quantile of inverse quantile.,,"I'm having some problems proving the following result. Let $F_{n}, n=0,1,2, \ldots$ , be c.d.f.'s such that $F_{n}  \rightarrow{ }_{w} F_{0} .$ Let $G_{n}(U)=$ $\sup \left\{x: F_{n}(x)  \leq U\right\}, n=0,1,2, \ldots$ , where $U$ is a random variable having the uniform $U(0,1)$ distribution. Show that $G_{n}(U)  \rightarrow{ }_{p} G_{0}(U)$ . Here I think G represents a sort of inverse quantile functions. If we assume that the r.v. are continuous, then G is just the random variables themselves. However, I have no idea how to prove this general case when it's not assumed that the inverse quantile exists. Any help is appreciated. Thanks.","I'm having some problems proving the following result. Let , be c.d.f.'s such that Let , where is a random variable having the uniform distribution. Show that . Here I think G represents a sort of inverse quantile functions. If we assume that the r.v. are continuous, then G is just the random variables themselves. However, I have no idea how to prove this general case when it's not assumed that the inverse quantile exists. Any help is appreciated. Thanks.","F_{n}, n=0,1,2, \ldots F_{n}
 \rightarrow{ }_{w} F_{0} . G_{n}(U)= \sup \left\{x: F_{n}(x)
 \leq U\right\}, n=0,1,2, \ldots U U(0,1) G_{n}(U)
 \rightarrow{ }_{p} G_{0}(U)","['probability', 'measure-theory', 'probability-distributions', 'convergence-divergence']"
89,Doubt on Interpreting Conditional Probability,Doubt on Interpreting Conditional Probability,,"I have a doubt about interpreting this question. I will post the question and my attempt. I get two different answers. ""A box contains $3$ red balls, $4$ blue balls, and $5$ white balls. Three balls are drawn at random from the box, one by one, without replacement. Find the probability that the second red ball appears on the third draw."" Hence we have $3$ red and $9$ non-red balls. If I interpret it as an unconditional probability problem, we obtain $$P(R_1 ~R_2' ~R_3 \cup  R_1 '~ R_2~ R_3)  \\~\\ = P(R_1 ~R_2'~ R_3) + P(R_1 ' ~R_2~ R_3) \\~\\  = \frac{3}{12}\cdot \frac{9}{11}\cdot \frac{2}{10}+  \frac{9}{12}\cdot \frac{3}{11} \cdot \frac{2}{10} = \frac{9}{110} $$ where $R_i$ is the event of drawing a red and $R_i'$ is the event of not drawing a red on the $i$ 'th draw. If I interpret it as a conditional probability problem I get $$ P\left(R_3 ~\mid~  \left( R_1~R_2' ~\cup~ R_1'~R_2  \right) \right) \\~\\ = \frac{P(R_3~ \cap ~\left( R_1~R_2' ~\cup~ R_1'~R_2  \right) ) }{P\left( R_1~R_2' ~\cup~ R_1'~R_2  \right)}  \\~\\ = \frac{P(R_1 ~R_2' ~R_3 \cup  R_1 '~ R_2~ R_3)}{P\left( R_1~R_2' ~\cup~ R_1'~R_2  \right)}  \\~\\ = \frac{P(R_1 ~R_2'~ R_3) + P(R_1 ' ~R_2~ R_3)}{P(R_1 ~R_2')  + P(R_1' ~R_2) }   \\~\\ = \frac{\frac{3}{12}\cdot \frac{9}{11}\cdot \frac{2}{10}+  \frac{9}{12}\cdot \frac{3}{11} \cdot \frac{2}{10}}{\frac{3}{12}\cdot \frac{9}{11}+  \frac{9}{12}\cdot \frac{3}{11} } = \frac{1}{5} $$","I have a doubt about interpreting this question. I will post the question and my attempt. I get two different answers. ""A box contains red balls, blue balls, and white balls. Three balls are drawn at random from the box, one by one, without replacement. Find the probability that the second red ball appears on the third draw."" Hence we have red and non-red balls. If I interpret it as an unconditional probability problem, we obtain where is the event of drawing a red and is the event of not drawing a red on the 'th draw. If I interpret it as a conditional probability problem I get","3 4 5 3 9 P(R_1 ~R_2' ~R_3 \cup  R_1 '~ R_2~ R_3) 
\\~\\ = P(R_1 ~R_2'~ R_3) + P(R_1 ' ~R_2~ R_3)
\\~\\  = \frac{3}{12}\cdot \frac{9}{11}\cdot \frac{2}{10}+  \frac{9}{12}\cdot \frac{3}{11} \cdot \frac{2}{10} = \frac{9}{110}  R_i R_i' i  P\left(R_3 ~\mid~  \left( R_1~R_2' ~\cup~ R_1'~R_2  \right) \right)
\\~\\
= \frac{P(R_3~ \cap ~\left( R_1~R_2' ~\cup~ R_1'~R_2  \right) ) }{P\left( R_1~R_2' ~\cup~ R_1'~R_2  \right)} 
\\~\\ = \frac{P(R_1 ~R_2' ~R_3 \cup  R_1 '~ R_2~ R_3)}{P\left( R_1~R_2' ~\cup~ R_1'~R_2  \right)} 
\\~\\ = \frac{P(R_1 ~R_2'~ R_3) + P(R_1 ' ~R_2~ R_3)}{P(R_1 ~R_2')  + P(R_1' ~R_2) }  
\\~\\ = \frac{\frac{3}{12}\cdot \frac{9}{11}\cdot \frac{2}{10}+  \frac{9}{12}\cdot \frac{3}{11} \cdot \frac{2}{10}}{\frac{3}{12}\cdot \frac{9}{11}+  \frac{9}{12}\cdot \frac{3}{11} } = \frac{1}{5}
","['probability', 'conditional-probability']"
90,Hitting a target with a die: finding a better closed form of the recursive formula,Hitting a target with a die: finding a better closed form of the recursive formula,,"Roll a k -sided die over and over and sum the results. What's the probability that the result will eventually hit exactly n ? The recursive formula is: $$ p_{k,n}= \begin{cases} \begin{array}{cc}  0 & n<0 \\  1 & n=0 \\  \sum _{x=1}^k \frac{p_{k,n-x}}{k} & n>0 \\ \end{array}  \\ \end{cases} $$ Through extremely tedious trial and error, I found the closed form: $$ p_{k,n}= \frac{(k+1)^{n-1}}{k^n}+\sum_{x=1}^{\lfloor{n/(k+1)}\rfloor}(-1)^x\frac{n\cdot (kx+x)^{n-kx-x-1}\cdot x^{kx+x-n}\cdot(n-kx-1)!}{k^{n-kx}\cdot(x-1)!\cdot(n-kx-x)!} $$ Mathematica: closed[k_,n_]:=(k+1)^(n-1)/k^n+Sum[(-1)^y*n*(k*y+y)^(n-k*y-y-1)*y^(k*y+y-n)*(n-k*y-1)!/k^(n-k*y)/(y-1)!/(n-k*y-y)!,{y,1,Floor[n/(k+1)]}] Does a cleaner closed form exist? Is there a general approach that works well on recursive formulas with multiple base cases?","Roll a k -sided die over and over and sum the results. What's the probability that the result will eventually hit exactly n ? The recursive formula is: Through extremely tedious trial and error, I found the closed form: Mathematica: closed[k_,n_]:=(k+1)^(n-1)/k^n+Sum[(-1)^y*n*(k*y+y)^(n-k*y-y-1)*y^(k*y+y-n)*(n-k*y-1)!/k^(n-k*y)/(y-1)!/(n-k*y-y)!,{y,1,Floor[n/(k+1)]}] Does a cleaner closed form exist? Is there a general approach that works well on recursive formulas with multiple base cases?","
p_{k,n}=
\begin{cases}
\begin{array}{cc}
 0 & n<0 \\
 1 & n=0 \\
 \sum _{x=1}^k \frac{p_{k,n-x}}{k} & n>0 \\
\end{array}
 \\
\end{cases}
 
p_{k,n}=
\frac{(k+1)^{n-1}}{k^n}+\sum_{x=1}^{\lfloor{n/(k+1)}\rfloor}(-1)^x\frac{n\cdot (kx+x)^{n-kx-x-1}\cdot x^{kx+x-n}\cdot(n-kx-1)!}{k^{n-kx}\cdot(x-1)!\cdot(n-kx-x)!}
","['probability', 'recurrence-relations', 'closed-form', 'recursion']"
91,Having difficult time understanding the solution to this probability problem,Having difficult time understanding the solution to this probability problem,,"So, the task says: there are 12 passengers and 4 wagons, what is probability that 3 passengers entered every wagon? this is the answer $\frac{\binom{12}{3}\binom{9}{3}\binom{6}{3}\binom{3}{3}}{4^{12}}$ but why instead of $4^{12}$ it doesn't go $12^{4}$ ? I understand that for first wagon we chose 3 out of 12 passenger and hence $\binom{12}{3}$ and so on, but should the same logic be applied for the denominator, shouldn't it be, for the first vagon we can chose 12 passener, for the second the same, and so on? Thank you!","So, the task says: there are 12 passengers and 4 wagons, what is probability that 3 passengers entered every wagon? this is the answer but why instead of it doesn't go ? I understand that for first wagon we chose 3 out of 12 passenger and hence and so on, but should the same logic be applied for the denominator, shouldn't it be, for the first vagon we can chose 12 passener, for the second the same, and so on? Thank you!",\frac{\binom{12}{3}\binom{9}{3}\binom{6}{3}\binom{3}{3}}{4^{12}} 4^{12} 12^{4} \binom{12}{3},"['probability', 'combinatorics']"
92,12 distinct objects are distributed into 10 distinct box such that each box is non-empty. Find probability that no box contain 3 elements,12 distinct objects are distributed into 10 distinct box such that each box is non-empty. Find probability that no box contain 3 elements,,"My thinking :- $n(\text{Sample space})=10^{12}-\binom{10}{1}(10-1)^{12}+\binom{10}{2}(10-2)^{12}-...-\binom{10}{9}(10-9)^{12}$ (Found by principle of inclusion and exclusion). Now we see that one box cannot have more than $3$ objects. for example if one box has $4$ objects then we have to divide $8$ objects into $9$ boxes such that each is non-empty which is not possible. Also no two boxes can have $3$ objects as then we would have to divide $6$ objects into $8$ box such that none is empty which is also not possible. So by my logic the only possibility we have to think about is that one box has $3$ elements and the other $9$ objects are divided into 9 box such that each is non empty. And then the probability of our required event is just $1-$ the probability of the above event. If I view that I have to put 9 distinct object into 9 box such that none is empty , then I am just looking at permutation of 9 things(sort of like defining a bijective function from a set of 9 elements to another).I am concluding this from the fact that no box cannot have more than 1 element(as it would lead to 7 objects into 8 box) Now the possibilities of the above event is just:- $\binom{10}{1}\cdot9!=10!$ . But If I view this again from principle of inclusion and exclusion then I am getting the expression:- $\binom{10}{1}\cdot(\displaystyle\sum_{k=0}^{9}\binom{9}{k}(-1)^{k}(9-k)^{9})$ . Now I know that these to are equal. Can someone suggest me how to prove that this summation also equals to $9!$ ?. So anyways....the probability would just equal:- $$\displaystyle 1-\frac{10!}{(\sum_{k=0}^{10}\binom{10}{k}(-1)^{k}(10-k)^{12})}$$ Is my reasoning correct? . Did I miss some cases? . Also how to prove the summation is same as the factorial? ( Not in a intuitive way . I know that the 9 object in 9 box is 9!, I want to show the summation equals 9!).","My thinking :- (Found by principle of inclusion and exclusion). Now we see that one box cannot have more than objects. for example if one box has objects then we have to divide objects into boxes such that each is non-empty which is not possible. Also no two boxes can have objects as then we would have to divide objects into box such that none is empty which is also not possible. So by my logic the only possibility we have to think about is that one box has elements and the other objects are divided into 9 box such that each is non empty. And then the probability of our required event is just the probability of the above event. If I view that I have to put 9 distinct object into 9 box such that none is empty , then I am just looking at permutation of 9 things(sort of like defining a bijective function from a set of 9 elements to another).I am concluding this from the fact that no box cannot have more than 1 element(as it would lead to 7 objects into 8 box) Now the possibilities of the above event is just:- . But If I view this again from principle of inclusion and exclusion then I am getting the expression:- . Now I know that these to are equal. Can someone suggest me how to prove that this summation also equals to ?. So anyways....the probability would just equal:- Is my reasoning correct? . Did I miss some cases? . Also how to prove the summation is same as the factorial? ( Not in a intuitive way . I know that the 9 object in 9 box is 9!, I want to show the summation equals 9!).",n(\text{Sample space})=10^{12}-\binom{10}{1}(10-1)^{12}+\binom{10}{2}(10-2)^{12}-...-\binom{10}{9}(10-9)^{12} 3 4 8 9 3 6 8 3 9 1- \binom{10}{1}\cdot9!=10! \binom{10}{1}\cdot(\displaystyle\sum_{k=0}^{9}\binom{9}{k}(-1)^{k}(9-k)^{9}) 9! \displaystyle 1-\frac{10!}{(\sum_{k=0}^{10}\binom{10}{k}(-1)^{k}(10-k)^{12})},"['probability', 'combinatorics', 'inclusion-exclusion', 'balls-in-bins']"
93,Obtaining irrational probabilities,Obtaining irrational probabilities,,"Let me start with a story. Our mathematics teacher asked us this question: Suppose I give you two balls, one black and the other white, then can you give me the white ball with $1/2$ probability? The answer was easy, we just toss a fair coin and if it lands Heads , we give the black ball, else we give the white one. Then, we were asked a second question: Suppose I give you two balls, one black and the other white, then can you give me the white ball with any fractional probability that I tell you? The probability can be like $2/3$ or $7/10$ or $12/100$ ? We can answer this question by making {denominator} number of equal pieces of paper and writing White on {numerator} number of pieces and Black on the remaining ones, and then mix all the papers together and take a piece of paper randomly from them. For example, if we want to give the White ball with a probability of $7/10$ , we make 10 paper pieces and write White on 7 of them and Black on the remaining three. Now we randomly pick up a piece of paper and then give the ball which has the colour same as that of written on the paper. Now, I have another question: If I want to have the white ball with a (well-defined) irrational probability (like $1/\sqrt2$ , $\sqrt{12}/\sqrt{33}$ or $1/\pi$ ), what should be the answer? By well-defined, I mean that the number should be obtainable by fairly common mathematical methods and not man-made irrational numbers like $0.1234567891011121314151617181920...$ , though, if any technique can obtain such a number, then better.","Let me start with a story. Our mathematics teacher asked us this question: Suppose I give you two balls, one black and the other white, then can you give me the white ball with probability? The answer was easy, we just toss a fair coin and if it lands Heads , we give the black ball, else we give the white one. Then, we were asked a second question: Suppose I give you two balls, one black and the other white, then can you give me the white ball with any fractional probability that I tell you? The probability can be like or or ? We can answer this question by making {denominator} number of equal pieces of paper and writing White on {numerator} number of pieces and Black on the remaining ones, and then mix all the papers together and take a piece of paper randomly from them. For example, if we want to give the White ball with a probability of , we make 10 paper pieces and write White on 7 of them and Black on the remaining three. Now we randomly pick up a piece of paper and then give the ball which has the colour same as that of written on the paper. Now, I have another question: If I want to have the white ball with a (well-defined) irrational probability (like , or ), what should be the answer? By well-defined, I mean that the number should be obtainable by fairly common mathematical methods and not man-made irrational numbers like , though, if any technique can obtain such a number, then better.",1/2 2/3 7/10 12/100 7/10 1/\sqrt2 \sqrt{12}/\sqrt{33} 1/\pi 0.1234567891011121314151617181920...,"['probability', 'irrational-numbers']"
94,Joint to marginal distribution does not make sense,Joint to marginal distribution does not make sense,,"Let the joint distribution of $X$ and $Y$ be $$ f_{X,Y}(x,y) =  \begin{cases} cxe^{-2y} &0\leq x\leq 1, y> 0 \\ c(2-x)e^{-2y} &1\leq x\leq 2, y> 0 \\ 0 &\mathrm{else} \end{cases} $$ Find the value of $c$ . $$\underbrace{\int _1^2\int_0^\infty c(2-x) e^{-2y} \, dy \, dx}_{c/4} +  \underbrace{\int _0^1\int_0^\infty cxe^{-2y} \, dy \, dx}_{c/4} = 1 \implies c=2 $$ Are $X$ and $Y$ independent, are $X$ and $Y$ uncorrelated? Hence, I calculated $f_X(x)=c=2$ , but this does not make any sense because now $1 = \int_{-\infty}^{+\infty} f_X(x) \, dx= \int_0^2 f_X(x) \, dx= \Big[2x\Big]^2_0 = 4$ .","Let the joint distribution of and be Find the value of . Are and independent, are and uncorrelated? Hence, I calculated , but this does not make any sense because now .","X Y 
f_{X,Y}(x,y) = 
\begin{cases}
cxe^{-2y} &0\leq x\leq 1, y> 0 \\
c(2-x)e^{-2y} &1\leq x\leq 2, y> 0 \\
0 &\mathrm{else}
\end{cases}
 c \underbrace{\int _1^2\int_0^\infty c(2-x) e^{-2y} \, dy \, dx}_{c/4} +  \underbrace{\int _0^1\int_0^\infty cxe^{-2y} \, dy \, dx}_{c/4} = 1 \implies c=2  X Y X Y f_X(x)=c=2 1 = \int_{-\infty}^{+\infty} f_X(x) \, dx= \int_0^2 f_X(x) \, dx= \Big[2x\Big]^2_0 = 4",['probability']
95,Chi Squared Clarification,Chi Squared Clarification,,"Suppose you have $Z_1, Z_2, Z_3$ which are all independent standard Gaussian variables. Suppose you have $$A=\frac{(Z_1-2Z_2+Z_3)^2}{12}+\frac{(Z_1-Z_3)^2}{4}+\frac{(Z_1-Z_2)^2}{4}+\frac{(Z_1+Z_2-2Z_3)^2}{12}.$$ $A$ is $\chi_2^2$ , but I don't see how this is the case. Particularly since $\operatorname{Var}\left(\frac{Z_1-2Z_2+Z_3}{\sqrt{12}}\right)$${}=\frac{1}{2}$ , which is the same issue with the other terms, i.e since none of the terms, by themselves, are standard normal before you square them. However, I do see how: $$B=\frac{(Z_1-2Z_2+Z_3)^2}{6}+\frac{(Z_1-Z_3)^2}{2}.$$ follows the $\chi_2^2$ distribution. I can also see that the first two terms of $A$ multiplied by $2$ is equal to $B.$ Any feedback would be appreciated.","Suppose you have which are all independent standard Gaussian variables. Suppose you have is , but I don't see how this is the case. Particularly since , which is the same issue with the other terms, i.e since none of the terms, by themselves, are standard normal before you square them. However, I do see how: follows the distribution. I can also see that the first two terms of multiplied by is equal to Any feedback would be appreciated.","Z_1, Z_2, Z_3 A=\frac{(Z_1-2Z_2+Z_3)^2}{12}+\frac{(Z_1-Z_3)^2}{4}+\frac{(Z_1-Z_2)^2}{4}+\frac{(Z_1+Z_2-2Z_3)^2}{12}. A \chi_2^2 \operatorname{Var}\left(\frac{Z_1-2Z_2+Z_3}{\sqrt{12}}\right){}=\frac{1}{2} B=\frac{(Z_1-2Z_2+Z_3)^2}{6}+\frac{(Z_1-Z_3)^2}{2}. \chi_2^2 A 2 B.","['probability', 'statistics', 'normal-distribution', 'gaussian', 'chi-squared']"
96,$P(\text{duck})$ given $P(\text{look})$ and $P(\text{swim})$ and $P(\text{quack})$,given  and  and,P(\text{duck}) P(\text{look}) P(\text{swim}) P(\text{quack}),"""If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck"" We have the 3 probabilities: $P(\text{look}) = 80\%$ $P(\text{swim}) = 70\%$ $P(\text{quack}) = 90\%$ I would assume then that $P(\text{duck}) = P(\text{look})·P(\text{swim})·P(\text{quack})$ $= 0.8 · 0.7 · 0.9$ $= 0.504$ This is obviously dead wrong. Common sense expects the resulted probability close to $1$ . What would be right operation among the individual probabilities to represent the original saying correctly? Update: Giving some context: We have a problem in an industrial environment, where we have to validate if our calculated values are true or not. We can conduct a few independent measurements, each addresses a different aspect of the same setup and each measurment returns a yes or no with a probability. Then we have to summarize them and compare to the theoretical calculations. What we do is duck typing. Update 2: While reading up the answers did hit me: the more independent measurement events we do on properties of the duck, should prove or disprove the ""duckness"" of the object. Should we have 6 independent measurements (look, swim, quack, fly, eat, walk), each around probability of 0.1, our calculation should conclude that this is certainly not a duck. Should we get confirming measurements (higher than 0.5), I expect higher ""duckness"" probability.","""If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck"" We have the 3 probabilities: I would assume then that This is obviously dead wrong. Common sense expects the resulted probability close to . What would be right operation among the individual probabilities to represent the original saying correctly? Update: Giving some context: We have a problem in an industrial environment, where we have to validate if our calculated values are true or not. We can conduct a few independent measurements, each addresses a different aspect of the same setup and each measurment returns a yes or no with a probability. Then we have to summarize them and compare to the theoretical calculations. What we do is duck typing. Update 2: While reading up the answers did hit me: the more independent measurement events we do on properties of the duck, should prove or disprove the ""duckness"" of the object. Should we have 6 independent measurements (look, swim, quack, fly, eat, walk), each around probability of 0.1, our calculation should conclude that this is certainly not a duck. Should we get confirming measurements (higher than 0.5), I expect higher ""duckness"" probability.",P(\text{look}) = 80\% P(\text{swim}) = 70\% P(\text{quack}) = 90\% P(\text{duck}) = P(\text{look})·P(\text{swim})·P(\text{quack}) = 0.8 · 0.7 · 0.9 = 0.504 1,"['probability', 'statistics', 'statistical-inference']"
97,"Why are the random variables $X+Y$ and $X-Y$ independent when $X$ and $Y$ are i.i.d $N(0,1)$?",Why are the random variables  and  independent when  and  are i.i.d ?,"X+Y X-Y X Y N(0,1)","$X,Y\sim N(0,1)$ and are independent, consider $X+Y$ and $X-Y$ . I can see why $X+Y$ and $X-Y$ are independent based on the fact that their joint distribution is equal to the product of their marginal distributions. Just, I'm having trouble understanding intuitively why this is so. This is how I see it :  When you look at $X+Y=u$ , the set $\{(x,u-x)|x\in\mathbb{R}\}$ is the list of possibilities for $X$ and $Y$ . And intuitively, I understand independence of two random variables $A$ and $B$ as, the probability of the event $A=a$ being completely unaffected by the event $B=b$ happening. But when you look at $X+Y=u$ given that $X-Y=v$ , the set of possibilities has only one value $(\frac{u+v}{2},\frac{u-v}{2})$ . So, $\mathbb{P}(X+Y=u|X-Y=v)\neq \mathbb{P}(X+Y=u)$ . Doesn't this mean that $X+Y$ is affected by the occurrance of $X-Y$ ? So, they would have to be dependent? I'm sorry if this comes off as really stupid, it has been driving me crazy, even though I am sure that they are independent, it just doesn't feel right. Thank you.","and are independent, consider and . I can see why and are independent based on the fact that their joint distribution is equal to the product of their marginal distributions. Just, I'm having trouble understanding intuitively why this is so. This is how I see it :  When you look at , the set is the list of possibilities for and . And intuitively, I understand independence of two random variables and as, the probability of the event being completely unaffected by the event happening. But when you look at given that , the set of possibilities has only one value . So, . Doesn't this mean that is affected by the occurrance of ? So, they would have to be dependent? I'm sorry if this comes off as really stupid, it has been driving me crazy, even though I am sure that they are independent, it just doesn't feel right. Thank you.","X,Y\sim N(0,1) X+Y X-Y X+Y X-Y X+Y=u \{(x,u-x)|x\in\mathbb{R}\} X Y A B A=a B=b X+Y=u X-Y=v (\frac{u+v}{2},\frac{u-v}{2}) \mathbb{P}(X+Y=u|X-Y=v)\neq \mathbb{P}(X+Y=u) X+Y X-Y","['probability', 'normal-distribution', 'independence']"
98,Probability - Book with typos problem,Probability - Book with typos problem,,"In a book, $250$ printing errors are randomly and independently distributed on $500$ pages. What is the probability that there will be at least three printing errors on page $317$ ? Is binomial distribution a good way to tackle this problem? My second idea was to use Poisson distribution to approximate the probability. What is the better approach? Any help would be much appreciated.","In a book, printing errors are randomly and independently distributed on pages. What is the probability that there will be at least three printing errors on page ? Is binomial distribution a good way to tackle this problem? My second idea was to use Poisson distribution to approximate the probability. What is the better approach? Any help would be much appreciated.",250 500 317,"['probability', 'probability-distributions']"
99,Expected winning amounts for $2$ players with different number of sided dice,Expected winning amounts for  players with different number of sided dice,2,"The following is an interview question. Given $2$ fair dice. My dice consists of $20$ sides with number from $1$ to $20$ . The other player has a $30$ -sided die with numbers from $1$ to $30$ . We both flip our own die. If my number is bigger, then the other player gave me my number of dollars and vice versa. But if we got the same number, I will pay the other player the number of dollars. What is the expected value of my winning or lost? My attempt: Let $X$ and $Y$ be the score obtained by my die and my opponent respectively. Therefore, for each $2\leq i\leq 20,$ $$P(I \text{ win } i \text{ amount}) = P(Y<i)\cdot P(X=i) = \frac{(i-1)\times 1}{30\times 20}.$$ On the other hand, for each $-30\leq j\leq -1,$ we have $$P(I \text{ lose } j \text{ amount}) = P(X=j)P(Y\geq j) = \frac{1}{20} \frac{30-j+1}{30}$$ It follows that my expected wining amounts is $$-\sum_{j=-30}^{-1} j P(I \text{ lose } j \text{ amount}) + \sum_{i=2}^{30} i P(I \text{ win } i \text{ amount}).$$ I am not sure whether I am on the right track.","The following is an interview question. Given fair dice. My dice consists of sides with number from to . The other player has a -sided die with numbers from to . We both flip our own die. If my number is bigger, then the other player gave me my number of dollars and vice versa. But if we got the same number, I will pay the other player the number of dollars. What is the expected value of my winning or lost? My attempt: Let and be the score obtained by my die and my opponent respectively. Therefore, for each On the other hand, for each we have It follows that my expected wining amounts is I am not sure whether I am on the right track.","2 20 1 20 30 1 30 X Y 2\leq i\leq 20, P(I \text{ win } i \text{ amount}) = P(Y<i)\cdot P(X=i) = \frac{(i-1)\times 1}{30\times 20}. -30\leq j\leq -1, P(I \text{ lose } j \text{ amount}) = P(X=j)P(Y\geq j) = \frac{1}{20} \frac{30-j+1}{30} -\sum_{j=-30}^{-1} j P(I \text{ lose } j \text{ amount}) + \sum_{i=2}^{30} i P(I \text{ win } i \text{ amount}).","['probability', 'combinatorics', 'discrete-mathematics']"
